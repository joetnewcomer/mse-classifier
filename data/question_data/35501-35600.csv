,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Ratio of cubic and quadratic form is approximately normal?,Ratio of cubic and quadratic form is approximately normal?,,"Let be $x_{1},x_{2},x_{3}$ i.i.d. random variables following a normal distribution with $\mu=0$ and $\sigma=1$ . I'm intrigued by the following random variable, which is a ratio of a cubic form and a quadratic form: $$\frac{1}{\sqrt 2}\frac{x_1 x_2^2 + x_1 x_3^2 + x_2 x_1^2 +x_2 x_3^2 + x_3 x_1^2 + x_3 x_2^2 - 6x_1 x_2 x_3}{x_1^2  + x_2^2 + x_3^2 - x_1 x_2 - x_1 x_3 - x_2 x_3 }$$ When sampling the variable, it looks very close to normal (1m samples, 100 bins): I'm trying to understand how it can be so close, but the distribution of cubic forms in random variables isn't well documented or developed, and exact calculations for the ratio of forms seem to be very complicated, even in the case of two quadratic forms. Is there any simple approach to see why the variable distribution might be close to a normal? Cross with stats.SE","Let be i.i.d. random variables following a normal distribution with and . I'm intrigued by the following random variable, which is a ratio of a cubic form and a quadratic form: When sampling the variable, it looks very close to normal (1m samples, 100 bins): I'm trying to understand how it can be so close, but the distribution of cubic forms in random variables isn't well documented or developed, and exact calculations for the ratio of forms seem to be very complicated, even in the case of two quadratic forms. Is there any simple approach to see why the variable distribution might be close to a normal? Cross with stats.SE","x_{1},x_{2},x_{3} \mu=0 \sigma=1 \frac{1}{\sqrt 2}\frac{x_1 x_2^2 + x_1 x_3^2 + x_2 x_1^2 +x_2 x_3^2 + x_3 x_1^2 + x_3 x_2^2 - 6x_1 x_2 x_3}{x_1^2  + x_2^2 + x_3^2 - x_1 x_2 - x_1 x_3 - x_2 x_3 }","['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'quadratic-forms']"
1,"Probability of 3 Aces, Last Picked is an Ace","Probability of 3 Aces, Last Picked is an Ace",,"""Aaron picks an integer $k \in [1,52]$ . Then, he draws the first $k$ cards from a standard, shuffled 52-card deck. Aaron wins a prize if the last card he draws is an ace and if there exists exactly one ace in the remaining cards. What $k$ should Aaron pick?"" I am struggling to understand how to get to the probability that Aaron wins with this approach: We need to have 2 aces in the first $k-1$ cards, ${k-1 \choose 2}$ , then the $k^{th}$ card needs to be an ace. Then we need to count the ways of positioning the last remaining ace, which is ${52-k \choose 1}$ . Finally, there are $4!$ ways of ordering the 4 aces. This aims to count all combinations of the 52 cards in the deck that lead to a win. I would then simply divide this by $52!$ the number of possible combinations. But the solution I found takes a different calculation, $\frac{{k-1 \choose 2}{52-k \choose 1}}{{52 \choose 4}}$ . Could you please help me understand this? Then I understand the optimisation step to get to the optimal $k$ , no issue there. Is there a way to approach this problem ignoring cards values, and thinking of it in terms of 52 balls, 48 black and 4 white? Thank you!","""Aaron picks an integer . Then, he draws the first cards from a standard, shuffled 52-card deck. Aaron wins a prize if the last card he draws is an ace and if there exists exactly one ace in the remaining cards. What should Aaron pick?"" I am struggling to understand how to get to the probability that Aaron wins with this approach: We need to have 2 aces in the first cards, , then the card needs to be an ace. Then we need to count the ways of positioning the last remaining ace, which is . Finally, there are ways of ordering the 4 aces. This aims to count all combinations of the 52 cards in the deck that lead to a win. I would then simply divide this by the number of possible combinations. But the solution I found takes a different calculation, . Could you please help me understand this? Then I understand the optimisation step to get to the optimal , no issue there. Is there a way to approach this problem ignoring cards values, and thinking of it in terms of 52 balls, 48 black and 4 white? Thank you!","k \in [1,52] k k k-1 {k-1 \choose 2} k^{th} {52-k \choose 1} 4! 52! \frac{{k-1 \choose 2}{52-k \choose 1}}{{52 \choose 4}} k","['probability', 'problem-solving', 'puzzle']"
2,Convergence of this Doob Martingale Sequence,Convergence of this Doob Martingale Sequence,,"Let $U$ be a Uniform $[0,1]$ variate and conditioned on $U$ , let $\{X_{n}\}_{n\geq 1}$ be iid $\operatorname{Bern}(U)$ variates. Then  show that $E(U|\sigma(X_{1},...,X_{n}))\xrightarrow{a.s.} U$ My attempt(s): Firstly, I can immediately notice that $Y_{n}=E(U|\sigma(X_{1},...,X_{n}))$ is a Doob Martingale sequence that is uniformly bounded (by $1$ ) in $L^{\infty}$ . So, by Martingale convergence theorem $Y_{n}\xrightarrow{a.s\, ,\, L^{p},\,p<\infty} X $ for some $X\in L^{p}$ for all $p<\infty$ . But I don't know how to show that $X$ is equal to $U$ . I also tried to use the method of moments as $U$ is compactly supported. I tried to show that $E(U^{m})=E(E(U^{m}|X_{1},...,X_{n}))\to E(X^{m})$ but the issue is that I need to consider $\bigg(E(U|X_{1},...,X_{n})\bigg)^{m}$ instead of $E(U^{m})$ and that we only have $\bigg(E(U|X_{1},...,X_{n})\bigg)^{m}\xrightarrow{L^{m}} X^{m}$ . This does not give us that $X^{m}$ has the same moments as $U^{m}$ . I also know from the Convergence Theory that $Y_{n}=E(X|X_{1},...,X_{n})$ which would mean that $E(X|X_{1},...,X_{n})=E(U|X_{1},...,X_{n})$ . From this can we conclude that $X=U$ as we have that $\int_{A} (X-U)\,dP=0$ for all $A\in \sigma(X_{1},...,X_{n})$ . I am very unsure about this as I am not using any property of $X_{1},...,X_{n}$ let alone the fact that conditioned on $U$ , they are iid Bernoulli $(U)$ variates. Since $X_{n}$ are iid, I tried to think of using Kolmogorov's Zero-One law but I couldn't see how that could help. Can anyone provide a hint or help me with this?","Let be a Uniform variate and conditioned on , let be iid variates. Then  show that My attempt(s): Firstly, I can immediately notice that is a Doob Martingale sequence that is uniformly bounded (by ) in . So, by Martingale convergence theorem for some for all . But I don't know how to show that is equal to . I also tried to use the method of moments as is compactly supported. I tried to show that but the issue is that I need to consider instead of and that we only have . This does not give us that has the same moments as . I also know from the Convergence Theory that which would mean that . From this can we conclude that as we have that for all . I am very unsure about this as I am not using any property of let alone the fact that conditioned on , they are iid Bernoulli variates. Since are iid, I tried to think of using Kolmogorov's Zero-One law but I couldn't see how that could help. Can anyone provide a hint or help me with this?","U [0,1] U \{X_{n}\}_{n\geq 1} \operatorname{Bern}(U) E(U|\sigma(X_{1},...,X_{n}))\xrightarrow{a.s.} U Y_{n}=E(U|\sigma(X_{1},...,X_{n})) 1 L^{\infty} Y_{n}\xrightarrow{a.s\, ,\, L^{p},\,p<\infty} X  X\in L^{p} p<\infty X U U E(U^{m})=E(E(U^{m}|X_{1},...,X_{n}))\to E(X^{m}) \bigg(E(U|X_{1},...,X_{n})\bigg)^{m} E(U^{m}) \bigg(E(U|X_{1},...,X_{n})\bigg)^{m}\xrightarrow{L^{m}} X^{m} X^{m} U^{m} Y_{n}=E(X|X_{1},...,X_{n}) E(X|X_{1},...,X_{n})=E(U|X_{1},...,X_{n}) X=U \int_{A} (X-U)\,dP=0 A\in \sigma(X_{1},...,X_{n}) X_{1},...,X_{n} U (U) X_{n}","['probability', 'probability-theory', 'conditional-expectation', 'martingales', 'uniform-distribution']"
3,Intuitions for $\mathbb{E}|\sum_{i=1}^n\mathbf{X}_i|= n{n-1\choose (n-1)/2}2^{1-n}$,Intuitions for,\mathbb{E}|\sum_{i=1}^n\mathbf{X}_i|= n{n-1\choose (n-1)/2}2^{1-n},"Suppose $\{\mathbf{X}_1,\mathbf{X}_2,\cdots,\mathbf{X}_n\}$ are $n$ iid random variables uniformly drawn from $\{-1,1\}$ and $n$ is odd. Then \begin{align}  \mathbb{E}|\sum_{i=1}^n\mathbf{X}_i|= 2\sum_{k=0}^{(n-1)/2} {n\choose k}(2n-k)2^{-n}=n{n-1\choose (n-1)/2}2^{1-n} \end{align} The above can be verified by some calculations. Why does it hold that every $\mathbf{X}_i$ 's contribution to $\mathbb{E}|\sum_{i=1}^n\mathbf{X}_i|$ is the probability that exactly half of the other random variables are taken $1$ and half are taken $-1$ ? This can be seen from simply do some calculations but are there any intuitive explanations?",Suppose are iid random variables uniformly drawn from and is odd. Then The above can be verified by some calculations. Why does it hold that every 's contribution to is the probability that exactly half of the other random variables are taken and half are taken ? This can be seen from simply do some calculations but are there any intuitive explanations?,"\{\mathbf{X}_1,\mathbf{X}_2,\cdots,\mathbf{X}_n\} n \{-1,1\} n \begin{align}
 \mathbb{E}|\sum_{i=1}^n\mathbf{X}_i|= 2\sum_{k=0}^{(n-1)/2} {n\choose k}(2n-k)2^{-n}=n{n-1\choose (n-1)/2}2^{1-n}
\end{align} \mathbf{X}_i \mathbb{E}|\sum_{i=1}^n\mathbf{X}_i| 1 -1","['probability', 'combinatorics', 'expected-value', 'intuition']"
4,I do not understand why do we divide with the k! that is used in nCk when multiplying two combinations or more combinations that has the same k value,I do not understand why do we divide with the k! that is used in nCk when multiplying two combinations or more combinations that has the same k value,,"I recently started studying Permutations and Combinations and following is one interesting question I came across. There are 8 students in a class. The class teacher wants to divide divide those students into four teams. The sizes of teams need not all be equal and a team may consist of even one person. Show that the required team can be formed in 1701 ways. How I approached the problem We can select students in following 5 ways, 5 Students, 1 Student, 1 Student, 1 Student 4 Students, 2 Students, 1 Student, 1 Student 3 Students, 3 Students, 1 Student, 1 Student 3 Students, 2 Students, 2 Students, 1 Student 2 Students, 2 Students, 2 Students, 2 Students Then we can find combinations as below for the given five cases, $\binom{8}{5} \cdot \binom{3}{1} \cdot \binom{2}{1} \cdot \binom{1}{1}$ $\binom{8}{4} \cdot \binom{4}{2} \cdot \binom{2}{1} \cdot \binom{2}{1}$ $\binom{8}{3} \cdot \binom{5}{3} \cdot \binom{2}{1} \cdot \binom{2}{1}$ $\binom{8}{3} \cdot \binom{5}{2} \cdot \binom{3}{2} \cdot \binom{1}{1}$ $\binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2}$ But above answer has been wrong and the correct answer is $\binom{8}{5}$ $\binom{8}{4} \cdot \binom{4}{2}$ $\binom{8}{3} \cdot \binom{5}{3}$ divided by 2! $\binom{8}{3} \cdot \binom{5}{2} \cdot \binom{3}{2}$ divided by 2! $\binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2}$ divided by 4! Now I have 2 questions, How come second one is correct? Why aren't we choosing in the scenarios where 1 student is present? Why are we dividing with 2! and 4! etc... in second secnario? More importantly how to recognise when to divide with 2! and 4! etc in problems...?","I recently started studying Permutations and Combinations and following is one interesting question I came across. There are 8 students in a class. The class teacher wants to divide divide those students into four teams. The sizes of teams need not all be equal and a team may consist of even one person. Show that the required team can be formed in 1701 ways. How I approached the problem We can select students in following 5 ways, 5 Students, 1 Student, 1 Student, 1 Student 4 Students, 2 Students, 1 Student, 1 Student 3 Students, 3 Students, 1 Student, 1 Student 3 Students, 2 Students, 2 Students, 1 Student 2 Students, 2 Students, 2 Students, 2 Students Then we can find combinations as below for the given five cases, But above answer has been wrong and the correct answer is divided by 2! divided by 2! divided by 4! Now I have 2 questions, How come second one is correct? Why aren't we choosing in the scenarios where 1 student is present? Why are we dividing with 2! and 4! etc... in second secnario? More importantly how to recognise when to divide with 2! and 4! etc in problems...?",\binom{8}{5} \cdot \binom{3}{1} \cdot \binom{2}{1} \cdot \binom{1}{1} \binom{8}{4} \cdot \binom{4}{2} \cdot \binom{2}{1} \cdot \binom{2}{1} \binom{8}{3} \cdot \binom{5}{3} \cdot \binom{2}{1} \cdot \binom{2}{1} \binom{8}{3} \cdot \binom{5}{2} \cdot \binom{3}{2} \cdot \binom{1}{1} \binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2} \binom{8}{5} \binom{8}{4} \cdot \binom{4}{2} \binom{8}{3} \cdot \binom{5}{3} \binom{8}{3} \cdot \binom{5}{2} \cdot \binom{3}{2} \binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2} \cdot \binom{8}{2},"['probability', 'combinatorics', 'permutations', 'combinations', 'binomial-theorem']"
5,Can a Markov chain be used to compute probabilities of sets of draws?,Can a Markov chain be used to compute probabilities of sets of draws?,,"Problem statement Consider the following scenario: We have an extremely large bag of glass marbles and metallic balls. We do not know how many items are in the bag, but we do know the percentage of the total for each type of metal ball: Color Percentage Gold 1% Silver 2% Copper 5% We are drawing a single ball at a time, replacing it, and mixing up the bag. It is not possible to distinguish what we are drawing by feel, so what we draw is random. Our goal is to draw (see) each metal at least once, and we want to examine the probability of having completed the set over the first thousand draws. Just to give us some specific values to compute, let's say we'll look at the probabilities at 50, 100, 250, 500, and 1000 draws. Solution, according to my understanding I believe we can approach this problem using a Markov chain. We can model the problem by having each state be a subset of metals that we have encountered, and the transition matrix will be the probability of drawing any unseen metal. While there is no interesting long term steady state (The probability of each state will asymptotically approach 0 except for the completed set which will approach 1.), the chain will at the very least help organize the computations in a much simpler way than trying to perform them ad hoc. To get our states, we can take the power set of the metals, and we can use some abbreviations to shorten things: Seen Abbreviation {} $ \emptyset $ {Gold} G {Silver} S {Copper} C {Gold,Silver} GS {Gold,Copper} GC {Silver,Copper} SC {Gold,Silver,Copper} GSC Before we lay out our transition matrix, let's compute the probability of drawing a glass marble. This value will be useful for constructing the transition matrix: $$ 1 - (0.01 + 0.02 + 0.05) = 0.92 $$ For our transition matrix, we will use the $ X_n = P X_{n+1} $ convention, meaning each column will represent a current state and each row will represent the next state. So our transition matrix $ P $ , with some labels to make interpreting it easier, looks like this: $$ \newcommand\pad[1]{\rlap{#1}\phantom{0000}}\begin{matrix} From: & \begin{array}{*8c} \pad{\emptyset} & \pad{\text{G}} & \pad{\text{S}} & \pad{\text{C}} & \pad{\text{GS}} & \pad{\text{GC}} & \pad{\text{SC}} & \pad{\text{GSC}} \end{array} &   \\   &   & To: \\   & \begin{bmatrix} \pad{0.92} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0.01} & \pad{0.93} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0.02} & \pad{0} & \pad{0.94} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0.05} & \pad{0} & \pad{0} & \pad{0.97} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0} & \pad{0.02} & \pad{0.01} & \pad{0} & \pad{0.95} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0} & \pad{0.05} & \pad{0} & \pad{0.01} & \pad{0} & \pad{0.98} & \pad{0} & \pad{0} \\ \pad{0} & \pad{0} & \pad{0.05} & \pad{0.02} & \pad{0} & \pad{0} & \pad{0.99} & \pad{0} \\ \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0.05} & \pad{0.02} & \pad{0.01} & \pad{1} \\ \end{bmatrix} & \begin{array}{*8wc100} \pad{\emptyset} \\ \pad{\text{G}} \\ \pad{\text{S}} \\ \pad{\text{C}} \\ \pad{\text{GS}} \\ \pad{\text{GC}} \\ \pad{\text{SC}} \\ \pad{\text{GSC}} \end{array} \end{matrix} \\ $$ The initial state $ X_0 $ is simple: we start with the empty set 100% of the time. So it's just an 8 element matrix where the first element is 1 and the remaining elements are 0. With these two matrices in hand, computing the probability of having drawn all metals is just a matter of matrix multiplication and extracting the value of interest. $$ \begin{align} X_{50} &= P^{50} X_{0} \\ X_{100} &= P^{100 - 50} X_{50} = P^{50} X_{50} \\ X_{250} &= P^{250 - 100} X_{100} = P^{150} X_{100} \\ X_{500} &= P^{500 - 250} X_{250} = P^{250} X_{250} \\ X_{1000} &= P^{1000 - 500} X_{500} = P^{500} X_{500} \\ \end{align} $$ And we find that the probabilities for completion are: Draws Probability 50 0.22836397 = 22.8364% 100 0.54550092 = 54.5501% 250 0.91302709 = 91.3027% 500 0.99338874 = 99.3389% 1000 0.99995683 = 99.9957% Is this analysis correct? Motivation If anyone is wondering, this is not a homework problem. I'm planning to apply the technique to analyzing gacha game probabilities, and I'd like to be certain that the approach I'm using actually works. If this approach is correct, I am interested in generalizing to more complex situations. For example, I want to examine the effect of having two bags to choose from (where you decide which bag to draw from based on the seen set you already have). I may also be interested in the probabilities of the various subsets, as well. But before I get into those, I wanted to be certain that the approach is valid. Additional properties? Given the context, are there any well known properties that a Markov chain exhibits that might be of interest in this sort of problem space? I can go read about them on my own, but it would help if I know what to look for. Extra details I chose to distinguish the items of interest as metals rather than colors because not having to distinguish between colors of interest and colors not of interest made writing the problem simpler. I've omitted the actual computations of the final probabilities because I used Python and numpy to perform them rather than do them by hand. If you'd like to perform computations yourself, here's the transition matrix in code form (with the assumption you've done the conventional import numpy as np ): np.array([[0.92, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],           [0.01, 0.93, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],           [0.02, 0.  , 0.94, 0.  , 0.  , 0.  , 0.  , 0.  ],           [0.05, 0.  , 0.  , 0.97, 0.  , 0.  , 0.  , 0.  ],           [0.  , 0.02, 0.01, 0.  , 0.95, 0.  , 0.  , 0.  ],           [0.  , 0.05, 0.  , 0.01, 0.  , 0.98, 0.  , 0.  ],           [0.  , 0.  , 0.05, 0.02, 0.  , 0.  , 0.99, 0.  ],           [0.  , 0.  , 0.  , 0.  , 0.05, 0.02, 0.01, 1.  ]])","Problem statement Consider the following scenario: We have an extremely large bag of glass marbles and metallic balls. We do not know how many items are in the bag, but we do know the percentage of the total for each type of metal ball: Color Percentage Gold 1% Silver 2% Copper 5% We are drawing a single ball at a time, replacing it, and mixing up the bag. It is not possible to distinguish what we are drawing by feel, so what we draw is random. Our goal is to draw (see) each metal at least once, and we want to examine the probability of having completed the set over the first thousand draws. Just to give us some specific values to compute, let's say we'll look at the probabilities at 50, 100, 250, 500, and 1000 draws. Solution, according to my understanding I believe we can approach this problem using a Markov chain. We can model the problem by having each state be a subset of metals that we have encountered, and the transition matrix will be the probability of drawing any unseen metal. While there is no interesting long term steady state (The probability of each state will asymptotically approach 0 except for the completed set which will approach 1.), the chain will at the very least help organize the computations in a much simpler way than trying to perform them ad hoc. To get our states, we can take the power set of the metals, and we can use some abbreviations to shorten things: Seen Abbreviation {} {Gold} G {Silver} S {Copper} C {Gold,Silver} GS {Gold,Copper} GC {Silver,Copper} SC {Gold,Silver,Copper} GSC Before we lay out our transition matrix, let's compute the probability of drawing a glass marble. This value will be useful for constructing the transition matrix: For our transition matrix, we will use the convention, meaning each column will represent a current state and each row will represent the next state. So our transition matrix , with some labels to make interpreting it easier, looks like this: The initial state is simple: we start with the empty set 100% of the time. So it's just an 8 element matrix where the first element is 1 and the remaining elements are 0. With these two matrices in hand, computing the probability of having drawn all metals is just a matter of matrix multiplication and extracting the value of interest. And we find that the probabilities for completion are: Draws Probability 50 0.22836397 = 22.8364% 100 0.54550092 = 54.5501% 250 0.91302709 = 91.3027% 500 0.99338874 = 99.3389% 1000 0.99995683 = 99.9957% Is this analysis correct? Motivation If anyone is wondering, this is not a homework problem. I'm planning to apply the technique to analyzing gacha game probabilities, and I'd like to be certain that the approach I'm using actually works. If this approach is correct, I am interested in generalizing to more complex situations. For example, I want to examine the effect of having two bags to choose from (where you decide which bag to draw from based on the seen set you already have). I may also be interested in the probabilities of the various subsets, as well. But before I get into those, I wanted to be certain that the approach is valid. Additional properties? Given the context, are there any well known properties that a Markov chain exhibits that might be of interest in this sort of problem space? I can go read about them on my own, but it would help if I know what to look for. Extra details I chose to distinguish the items of interest as metals rather than colors because not having to distinguish between colors of interest and colors not of interest made writing the problem simpler. I've omitted the actual computations of the final probabilities because I used Python and numpy to perform them rather than do them by hand. If you'd like to perform computations yourself, here's the transition matrix in code form (with the assumption you've done the conventional import numpy as np ): np.array([[0.92, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],           [0.01, 0.93, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],           [0.02, 0.  , 0.94, 0.  , 0.  , 0.  , 0.  , 0.  ],           [0.05, 0.  , 0.  , 0.97, 0.  , 0.  , 0.  , 0.  ],           [0.  , 0.02, 0.01, 0.  , 0.95, 0.  , 0.  , 0.  ],           [0.  , 0.05, 0.  , 0.01, 0.  , 0.98, 0.  , 0.  ],           [0.  , 0.  , 0.05, 0.02, 0.  , 0.  , 0.99, 0.  ],           [0.  , 0.  , 0.  , 0.  , 0.05, 0.02, 0.01, 1.  ]])"," \emptyset   1 - (0.01 + 0.02 + 0.05) = 0.92   X_n = P X_{n+1}   P  
\newcommand\pad[1]{\rlap{#1}\phantom{0000}}\begin{matrix}
From: & \begin{array}{*8c} \pad{\emptyset} & \pad{\text{G}} & \pad{\text{S}} & \pad{\text{C}} & \pad{\text{GS}} & \pad{\text{GC}} & \pad{\text{SC}} & \pad{\text{GSC}} \end{array} &   \\
  &   & To: \\
  & \begin{bmatrix} \pad{0.92} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0.01} & \pad{0.93} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0.02} & \pad{0} & \pad{0.94} & \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0.05} & \pad{0} & \pad{0} & \pad{0.97} & \pad{0} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0} & \pad{0.02} & \pad{0.01} & \pad{0} & \pad{0.95} & \pad{0} & \pad{0} & \pad{0} \\ \pad{0} & \pad{0.05} & \pad{0} & \pad{0.01} & \pad{0} & \pad{0.98} & \pad{0} & \pad{0} \\ \pad{0} & \pad{0} & \pad{0.05} & \pad{0.02} & \pad{0} & \pad{0} & \pad{0.99} & \pad{0} \\ \pad{0} & \pad{0} & \pad{0} & \pad{0} & \pad{0.05} & \pad{0.02} & \pad{0.01} & \pad{1} \\ \end{bmatrix} & \begin{array}{*8wc100} \pad{\emptyset} \\ \pad{\text{G}} \\ \pad{\text{S}} \\ \pad{\text{C}} \\ \pad{\text{GS}} \\ \pad{\text{GC}} \\ \pad{\text{SC}} \\ \pad{\text{GSC}} \end{array}
\end{matrix} \\
  X_0  
\begin{align}
X_{50} &= P^{50} X_{0} \\
X_{100} &= P^{100 - 50} X_{50} = P^{50} X_{50} \\
X_{250} &= P^{250 - 100} X_{100} = P^{150} X_{100} \\
X_{500} &= P^{500 - 250} X_{250} = P^{250} X_{250} \\
X_{1000} &= P^{1000 - 500} X_{500} = P^{500} X_{500} \\
\end{align}
","['probability', 'markov-chains']"
6,Mean of Medians? Median of Means?,Mean of Medians? Median of Means?,,"This is a question I have wondered about for a long time and have never been able to find a full mathematical explanation behind this. Suppose there are 100 countries. As an experiment: We give Person A the median income of each country We give Person B the mean income of each country Now, suppose the following happens: Person A decides to take the mean of all median incomes Person B decides to take the median of all mean incomes Person C shows up out of nowhere and decides to take the median of all median incomes My Question: Using mathematics, we can we demonstrate that perhaps some of these calculations are not very ""meaningful""? For example, can we somehow show that some of these calculations lack important mathematical properties and are basically arbitrary? Thanks!","This is a question I have wondered about for a long time and have never been able to find a full mathematical explanation behind this. Suppose there are 100 countries. As an experiment: We give Person A the median income of each country We give Person B the mean income of each country Now, suppose the following happens: Person A decides to take the mean of all median incomes Person B decides to take the median of all mean incomes Person C shows up out of nowhere and decides to take the median of all median incomes My Question: Using mathematics, we can we demonstrate that perhaps some of these calculations are not very ""meaningful""? For example, can we somehow show that some of these calculations lack important mathematical properties and are basically arbitrary? Thanks!",,"['probability', 'means', 'median']"
7,Coupon collector's problem with increasing number of coupons needed,Coupon collector's problem with increasing number of coupons needed,,"In the ordinary coupon collector's problem, there are $n$ types of coupons, and we pick coupons uniformly at random until we get at least one of each coupon. https://en.wikipedia.org/wiki/Coupon_collector's_problem It is well known that the expected time to collect all coupons $k$ times (for a fixed integer $k$ ) is $ n \log n + (k - 1) n \log\log n + O(n)$ . But what if we need to collect all coupons $n$ times? Is the expected time $\omega(n^2)$ ?","In the ordinary coupon collector's problem, there are types of coupons, and we pick coupons uniformly at random until we get at least one of each coupon. https://en.wikipedia.org/wiki/Coupon_collector's_problem It is well known that the expected time to collect all coupons times (for a fixed integer ) is . But what if we need to collect all coupons times? Is the expected time ?",n k k  n \log n + (k - 1) n \log\log n + O(n) n \omega(n^2),"['probability', 'combinatorics', 'coupon-collector']"
8,Find the probability that no students from country B are in classroom 2,Find the probability that no students from country B are in classroom 2,,"We have a school with students from countries A and B, 155 and 35 respectively. We have 4 classrooms that can accommodate 80, 35, 35, 40 students. If each student is assigned to a class independently and uniformly, compute the probability that classroom 2 has no students from country B. I have in my mind two possible solutions that reach completely different answers and I don't know which one holds. Each student has probability $3/4$ that he/she does not end up in classroom 2. So in total $$p = (3/4)^{35}=0.0000423$$ There are $\binom{190}{35}$ in which we can assign students from country B in total and there are $\binom{155}{35}$ ways that we can assign we can assign students from country B in classes except classroom 2 (so in 1, 3, 4). $$ p = \frac{C(155, 35)}{C(190, 35)} \approx 0.00035$$ There are $C(35+3-1, 35)$ ways to distribute student's of country B to the 3 other classrooms and $C(35+4-1, 35)$ way to distribute them in the 4 classrooms in total. $$ p = \frac{C(37, 35)}{C(38, 35)}=0.07894 $$","We have a school with students from countries A and B, 155 and 35 respectively. We have 4 classrooms that can accommodate 80, 35, 35, 40 students. If each student is assigned to a class independently and uniformly, compute the probability that classroom 2 has no students from country B. I have in my mind two possible solutions that reach completely different answers and I don't know which one holds. Each student has probability that he/she does not end up in classroom 2. So in total There are in which we can assign students from country B in total and there are ways that we can assign we can assign students from country B in classes except classroom 2 (so in 1, 3, 4). There are ways to distribute student's of country B to the 3 other classrooms and way to distribute them in the 4 classrooms in total.","3/4 p = (3/4)^{35}=0.0000423 \binom{190}{35} \binom{155}{35}  p = \frac{C(155, 35)}{C(190, 35)} \approx 0.00035 C(35+3-1, 35) C(35+4-1, 35)  p = \frac{C(37, 35)}{C(38, 35)}=0.07894 ","['probability', 'combinatorics', 'probability-theory', 'combinations']"
9,Randomly landing on every member of a set while the set is growing: Does it help to play before all items are added?,Randomly landing on every member of a set while the set is growing: Does it help to play before all items are added?,,"This question has come up with me in two different Final Fantasy games, where you want or need to collect every memory or skill through random selection where not all memories/skills are available until late in the (main) game (not in the random selection ""game""). Collecting a memory/skill does not remove it from the set (you can randomly land on it again) My question is: In terms of getting every entity in the set, does it help (in terms of the expected number of plays to pick every entity) to play this sub-game before all entities have been added to the set (assuming even probability distribution over all entities)? If what I am asking doesn't make sense to you, please ask let me know in a comment and I will try to clarify the question.","This question has come up with me in two different Final Fantasy games, where you want or need to collect every memory or skill through random selection where not all memories/skills are available until late in the (main) game (not in the random selection ""game""). Collecting a memory/skill does not remove it from the set (you can randomly land on it again) My question is: In terms of getting every entity in the set, does it help (in terms of the expected number of plays to pick every entity) to play this sub-game before all entities have been added to the set (assuming even probability distribution over all entities)? If what I am asking doesn't make sense to you, please ask let me know in a comment and I will try to clarify the question.",,"['probability', 'statistics']"
10,Existence of a weird cumulative function,Existence of a weird cumulative function,,Does it exist a non discrete random variable with CDF $F$ with the following hypothesis : $F$ is constant in a neighborhood of each point of continuity I had the idea of Cantor function but it does not work in my case...,Does it exist a non discrete random variable with CDF with the following hypothesis : is constant in a neighborhood of each point of continuity I had the idea of Cantor function but it does not work in my case...,F F,"['probability', 'cumulative-distribution-functions']"
11,Probability of seeing HTTH before THTH in coin flips,Probability of seeing HTTH before THTH in coin flips,,"I'm doing a past paper question and trying to use Doob's Optional Stopping to find the probability that for independent identical $(X_n)$ uniform on $\{0,1\}$ we see the pattern $a = (1,0,0,1)$ before the pattern $b = (0,1,0,1)$ , and so wonder whether this is correct, and/or an efficient method since applying Doob's twice doesn't necessarily seem like the quickest way. We consider stopping times $\tau_w = \text{inf}\{n \in \mathbb N \mid (X_{n-3},\dots,X_n) = w\}$ for $w \in \{a,b\}$ , and $\tau = \tau_a \wedge \tau_b$ . As usual we'll set up gamblers entering a casino, all bets double or nothing gambler $A^i$ entering at time $i$ starting with $1$ and betting on the first letter for $a$ , then second, etc., gambler $B^i$ starting with $1$ and betting on consecutive letters for $b$ . Then let $M_n = \sum_{i=1}^n A^i_n + B^i_n - 2n$ earnings of $A^i_n$ and $B^i_n$ , and $N_n = \sum_{i=1}^n A^i_n + 2 \cdot B^i_n - 3n$ earnings for $A^i_n$ and $2 \cdot B^i_n$ . Then it follows that these are martingales as a (infinite) sum of martingales starting at 0 ( $A^i_n - 1$ for instance is such a martingale, and is $0$ for $n < i$ ) since the game is fair. Then we have that $\tau$ has finite expectation since $$ \mathbb P(\tau > 4n) \leq \mathbb P\bigg((X_{4m-3},\dots,X_m) \not = a \ \forall m \leq n\bigg) \leq (15/16)^n $$ and so since both $M_n$ and $N_n$ have increments bounded by $32 \cdot 4 \cdot 2$ , we apply Doob's twice: At $\tau_a$ , we have a gambler with 4 correct letters on $a$ , one with 1 correct letter on $a$ , and one with 2 correct letters on $b$ . At $\tau_b$ , we have a gambler with 4 correct letters on $b$ , one with 2 correct letters on $b$ , and one with 1 correct letter on $a$ . So applying Doob's to both $M_n^\tau$ and $N_n^\tau$ , writing $p = \mathbb P(\tau = \tau_a)$ , and splitting the first expectation based on whether $\tau = \tau_a$ or $\tau = \tau_b$ : $$ \begin{align*} 0 &= \mathbb E[M_0]= \mathbb E[M_\tau]\\ &= \mathbb E\left[\sum_{i=1}^\tau A^i_n + B^i_n\right] - 2* \cdot \mathbb E[\tau]\\ &= p \cdot (2^4 + 2^1 + 2^2) + q \cdot (2^1+2^4+2^2) - 2 \mathbb E[\tau]\\ &= 2 \cdot (11 - \mathbb E[\tau]) \end{align*} $$ so that $\mathbb E[\tau] = 11$ , and then doing the same again $$ \begin{align*} 0 &= \mathbb E[N_0]= \mathbb E[N_\tau]\\ &= \mathbb E\left[\sum_{i=1}^\tau A^i_n + 2\cdot B^i_n\right] - 3* \cdot \mathbb E[\tau]\\ &= p \cdot (2^4 + 2^1 + 2\cdot 2^2) + q \cdot (2^1+2\cdot 2^4+2\cdot 2^2) - 3\cdot 11\\ &= 26p +42q - 33\\ &= 42-33-16p \end{align*} $$ so that $p = \dfrac{9}{16}$ . The denominator of $16$ makes me think maybe there's a much quicker combinatorial/Markov chain way of getting to the same answer? Any thoughts are appreciated!","I'm doing a past paper question and trying to use Doob's Optional Stopping to find the probability that for independent identical uniform on we see the pattern before the pattern , and so wonder whether this is correct, and/or an efficient method since applying Doob's twice doesn't necessarily seem like the quickest way. We consider stopping times for , and . As usual we'll set up gamblers entering a casino, all bets double or nothing gambler entering at time starting with and betting on the first letter for , then second, etc., gambler starting with and betting on consecutive letters for . Then let earnings of and , and earnings for and . Then it follows that these are martingales as a (infinite) sum of martingales starting at 0 ( for instance is such a martingale, and is for ) since the game is fair. Then we have that has finite expectation since and so since both and have increments bounded by , we apply Doob's twice: At , we have a gambler with 4 correct letters on , one with 1 correct letter on , and one with 2 correct letters on . At , we have a gambler with 4 correct letters on , one with 2 correct letters on , and one with 1 correct letter on . So applying Doob's to both and , writing , and splitting the first expectation based on whether or : so that , and then doing the same again so that . The denominator of makes me think maybe there's a much quicker combinatorial/Markov chain way of getting to the same answer? Any thoughts are appreciated!","(X_n) \{0,1\} a = (1,0,0,1) b = (0,1,0,1) \tau_w = \text{inf}\{n \in \mathbb N \mid (X_{n-3},\dots,X_n) = w\} w \in \{a,b\} \tau = \tau_a \wedge \tau_b A^i i 1 a B^i 1 b M_n = \sum_{i=1}^n A^i_n + B^i_n - 2n A^i_n B^i_n N_n = \sum_{i=1}^n A^i_n + 2 \cdot B^i_n - 3n A^i_n 2 \cdot B^i_n A^i_n - 1 0 n < i \tau 
\mathbb P(\tau > 4n) \leq \mathbb P\bigg((X_{4m-3},\dots,X_m) \not = a \ \forall m \leq n\bigg) \leq (15/16)^n
 M_n N_n 32 \cdot 4 \cdot 2 \tau_a a a b \tau_b b b a M_n^\tau N_n^\tau p = \mathbb P(\tau = \tau_a) \tau = \tau_a \tau = \tau_b 
\begin{align*}
0 &= \mathbb E[M_0]= \mathbb E[M_\tau]\\
&= \mathbb E\left[\sum_{i=1}^\tau A^i_n + B^i_n\right] - 2* \cdot \mathbb E[\tau]\\
&= p \cdot (2^4 + 2^1 + 2^2) + q \cdot (2^1+2^4+2^2) - 2 \mathbb E[\tau]\\
&= 2 \cdot (11 - \mathbb E[\tau])
\end{align*}
 \mathbb E[\tau] = 11 
\begin{align*}
0 &= \mathbb E[N_0]= \mathbb E[N_\tau]\\
&= \mathbb E\left[\sum_{i=1}^\tau A^i_n + 2\cdot B^i_n\right] - 3* \cdot \mathbb E[\tau]\\
&= p \cdot (2^4 + 2^1 + 2\cdot 2^2) + q \cdot (2^1+2\cdot 2^4+2\cdot 2^2) - 3\cdot 11\\
&= 26p +42q - 33\\
&= 42-33-16p
\end{align*}
 p = \dfrac{9}{16} 16","['probability', 'probability-theory', 'solution-verification', 'martingales', 'stopping-times']"
12,Correlation between dependent variables (binomial distribution),Correlation between dependent variables (binomial distribution),,"Good afternoon. I have the following problem concerning Poisson and binomial distributions. Let $X_1, ..., X_n, n\geq 2$ be independent random variables, Poisson distributed with a parameter $\lambda >0$ . Let $k \geq 2$ . Let $(Z_1, ..., Z_n)$ be a random vector with the following distribution: $P(Z_1=x_1,..., Z_n = x_n) = P(X_1 = x_1, ..., X_n = x_n|X_1+...+X_n=k)$ . Calculate the correlation coefficient between $Z_1$ and $Z_2$ . I have already calculated $P(Z_1 = t) =P(X_1 = t|X_1+...+X_n = k)$ and found that it has binomial distrubution with parameters $(k, \frac{1}{n})$ . The same holds true for $P(Z_2 =  t) =P(X_2 = t|X_1+...+X_n = k)$ . If I'm right, I should be calculating $E(Z_1 Z_2)$ right now. Can someone please explain to me how to use the fact that these two variables are dependent to calculate that expected value?","Good afternoon. I have the following problem concerning Poisson and binomial distributions. Let be independent random variables, Poisson distributed with a parameter . Let . Let be a random vector with the following distribution: . Calculate the correlation coefficient between and . I have already calculated and found that it has binomial distrubution with parameters . The same holds true for . If I'm right, I should be calculating right now. Can someone please explain to me how to use the fact that these two variables are dependent to calculate that expected value?","X_1, ..., X_n, n\geq 2 \lambda >0 k \geq 2 (Z_1, ..., Z_n) P(Z_1=x_1,..., Z_n = x_n) = P(X_1 = x_1, ..., X_n = x_n|X_1+...+X_n=k) Z_1 Z_2 P(Z_1 = t) =P(X_1 = t|X_1+...+X_n = k) (k, \frac{1}{n}) P(Z_2 =  t) =P(X_2 = t|X_1+...+X_n = k) E(Z_1 Z_2)","['probability', 'statistics']"
13,Number of Draws Needed to Win a Raffle,Number of Draws Needed to Win a Raffle,,"I was at a summer bbq picnic on the weekend and there was a raffle draw. There were different prizes on the table.  Everyone had a ticket and they would randomly pick tickets - when a ticket was called, the recipient would come and pick up their prize. Their ticket would then be removed from the raffle and they would keep going. Obviously the ""better prizes"" would be picked first and the ""less desirable prizes"" would remain until the end. At the same time, there were popsicles in another part of the picnic area that were going fast! But if I went to go get a popsicle, I might miss my ticket being called! But if I stayed at the raffle area and my ticket was never called, I would miss out on the popsicles! I was trying to calculate: based on how many tickets/prizes were remaining in the raffle - would it be worth sticking around for my number to be called? I tried to think of it this way: Suppose there were 100 tickets (i.e. 100 people) - on average, from the very beginning of the raffle -  how many tickets would need to be drawn before mine showed up? Is there a mathematical formula for this? A wild guess - I say that 50 on average need to be drawn but I dont think this is correct? Thanks!","I was at a summer bbq picnic on the weekend and there was a raffle draw. There were different prizes on the table.  Everyone had a ticket and they would randomly pick tickets - when a ticket was called, the recipient would come and pick up their prize. Their ticket would then be removed from the raffle and they would keep going. Obviously the ""better prizes"" would be picked first and the ""less desirable prizes"" would remain until the end. At the same time, there were popsicles in another part of the picnic area that were going fast! But if I went to go get a popsicle, I might miss my ticket being called! But if I stayed at the raffle area and my ticket was never called, I would miss out on the popsicles! I was trying to calculate: based on how many tickets/prizes were remaining in the raffle - would it be worth sticking around for my number to be called? I tried to think of it this way: Suppose there were 100 tickets (i.e. 100 people) - on average, from the very beginning of the raffle -  how many tickets would need to be drawn before mine showed up? Is there a mathematical formula for this? A wild guess - I say that 50 on average need to be drawn but I dont think this is correct? Thanks!",,['probability']
14,"Finding pdf p(x,1) from p(x,0) given sde Xt","Finding pdf p(x,1) from p(x,0) given sde Xt",,"Assume $X_t$ satisfies the SDE: $$dX_t = X_tdt + dW_t$$ , where $W_t$ is standard normal. If we know that $X_0 = 1$ and there exists some pdf of $X_t$ , $p(x,0)$ , how can I find the the pdf of $X_t$ at time 1, $p(x,1)?$ I tried to use Fokker–Planck equation $$ \frac{\partial}{\partial t}p(x,t)= -\frac{\partial}{\partial x}[\mu(x,t)p(x,t)]+\frac12\frac{\partial^2}{\partial x^2}[\sigma^2(x,t)p(x,t)] $$ , but I am not sure how I can utilize this equation without explicitly knowing $p(x,0)$ . Could you guys give me an advice on this problem? :D","Assume satisfies the SDE: , where is standard normal. If we know that and there exists some pdf of , , how can I find the the pdf of at time 1, I tried to use Fokker–Planck equation , but I am not sure how I can utilize this equation without explicitly knowing . Could you guys give me an advice on this problem? :D","X_t dX_t = X_tdt + dW_t W_t X_0 = 1 X_t p(x,0) X_t p(x,1)? 
\frac{\partial}{\partial t}p(x,t)= -\frac{\partial}{\partial x}[\mu(x,t)p(x,t)]+\frac12\frac{\partial^2}{\partial x^2}[\sigma^2(x,t)p(x,t)]
 p(x,0)","['probability', 'partial-differential-equations', 'stochastic-processes', 'stochastic-calculus']"
15,"Proof that $L^2 (Ω, F, P)$ is a Hilbert space",Proof that  is a Hilbert space,"L^2 (Ω, F, P)","I'm working on the probabilistic space of square random variables ( $L^2 (Ω, F, P)$ ). I need to prove that it is a Hibert Space (the exercise doesn't say with which norm). The usual inner product is $<X,Y>=\mathbb{E}[XY]$ , it verifies the necessary properties. So I decide to consider the norm $\lVert X\rVert_2=\sqrt{\mathbb{E}[X^2]}$ . So I know that I need to prove that this space is complete with relation to that norm, and that's what I can't seem to do. I need to consider a Cauchy sequence $\{X_n\}$ in $L^2 (Ω, F, P)$ . So for every $\epsilon>0$ , there is a N such that for all $n,m>N$ we have : $\lVert X_n-X_m\rVert_2=\sqrt {\mathbb{E}[(X_n-X_m)^2]}\leq \varepsilon$ . I need to prove that there is a X in $L^2 (Ω, F, P)$ such that $\lim_{n\to\infty}\lVert X_n-X\rVert_2=0$ And now from there I don't really know where to go, I saw things about the dominated convergence theorem but I'm unsure about how to use it in this siuation. I hope my question is not too dumb.","I'm working on the probabilistic space of square random variables ( ). I need to prove that it is a Hibert Space (the exercise doesn't say with which norm). The usual inner product is , it verifies the necessary properties. So I decide to consider the norm . So I know that I need to prove that this space is complete with relation to that norm, and that's what I can't seem to do. I need to consider a Cauchy sequence in . So for every , there is a N such that for all we have : . I need to prove that there is a X in such that And now from there I don't really know where to go, I saw things about the dominated convergence theorem but I'm unsure about how to use it in this siuation. I hope my question is not too dumb.","L^2 (Ω, F, P) <X,Y>=\mathbb{E}[XY] \lVert X\rVert_2=\sqrt{\mathbb{E}[X^2]} \{X_n\} L^2 (Ω, F, P) \epsilon>0 n,m>N \lVert X_n-X_m\rVert_2=\sqrt {\mathbb{E}[(X_n-X_m)^2]}\leq \varepsilon L^2 (Ω, F, P) \lim_{n\to\infty}\lVert X_n-X\rVert_2=0","['probability', 'hilbert-spaces']"
16,Marginal density function involving exponential and uniform distributions,Marginal density function involving exponential and uniform distributions,,"for my probability homework I was given the following question. Let $Y \sim$ Exponential(2) and let $X \sim$ Uniform $(0, e^{Y})$ . This means that $(X, Y)$ is a bivariate continuous random variabele with joint density function $f_{X, Y}: \mathbb{R}^{2} \rightarrow \mathbb{R}$ given by: \begin{align*} f_{X, Y}(x, y) = \begin{cases} 2e^{-3y}, & 0 < x < e^{y}, y > 0; \\ 0, & \text{otherwise}.  \end{cases} \end{align*} For the third question I had to determine the marginal density function $f_{X}(x)$ . I know that I have to integrate the above function over the support of $Y$ , however, they gave the hint that I have to distinguish two different cases, which makes me unsure about what to do. Originally I would just integrate from 0 to $\infty$ , but now I am not sure. I tried to make a plot of the bounds and thought I would have to approach two different cases involving $x$ between 0 and 1, and $x$ > 1, but I am not sure how I would approach this in the integral. I would greatly appreciate if anybody could help!.","for my probability homework I was given the following question. Let Exponential(2) and let Uniform . This means that is a bivariate continuous random variabele with joint density function given by: For the third question I had to determine the marginal density function . I know that I have to integrate the above function over the support of , however, they gave the hint that I have to distinguish two different cases, which makes me unsure about what to do. Originally I would just integrate from 0 to , but now I am not sure. I tried to make a plot of the bounds and thought I would have to approach two different cases involving between 0 and 1, and > 1, but I am not sure how I would approach this in the integral. I would greatly appreciate if anybody could help!.","Y \sim X \sim (0, e^{Y}) (X, Y) f_{X, Y}: \mathbb{R}^{2} \rightarrow \mathbb{R} \begin{align*}
f_{X, Y}(x, y) =
\begin{cases}
2e^{-3y}, & 0 < x < e^{y}, y > 0; \\
0, & \text{otherwise}. 
\end{cases}
\end{align*} f_{X}(x) Y \infty x x","['probability', 'probability-distributions']"
17,What is the probability of choosing a white ball again,What is the probability of choosing a white ball again,,"I am struggling with the math conditional probability task: There are two boxes. One has 14 white and 32 black balls, another has 23 white and 43 black balls. Choosing a box randomly, we choose a white ball. What is a probability, that from the same box we will choose a white ball again? My solution: In general, there are 46 balls in the first box, and 66 box in the second one. There is a condition, that we already chose a white ball and we gonna choose from the same box white ball. So, to choose a ball from the first box again, we have a probability: $$\frac{14-1}{46-1} \cdot \frac{1}{2}$$ and from the second box: $$\frac{23-1}{66-1} \cdot \frac{1}{2}$$ I know, that If I sum these two probabilities the result will be wrong because I did not specify a condition. I believe I need to use Bayes' theorem. Thus: $$P(A \mid B) = \frac{P(A~\text{and}~B)}{P(B)}$$ A is event of choosing a white ball again from the same box knowing that B is true (B = firstly we chose a white ball from the random box) $$P(A~\text{and}~B) = P(A) \cdot P(B)$$ Then we have: $$\frac{1}{2} \cdot \frac{P(\text{Probability of choosing a white ball})}{P(\text{Probability of choosing a white ball in general})}$$ I am getting a wrong result and I am struggling with the correctness of my solution","I am struggling with the math conditional probability task: There are two boxes. One has 14 white and 32 black balls, another has 23 white and 43 black balls. Choosing a box randomly, we choose a white ball. What is a probability, that from the same box we will choose a white ball again? My solution: In general, there are 46 balls in the first box, and 66 box in the second one. There is a condition, that we already chose a white ball and we gonna choose from the same box white ball. So, to choose a ball from the first box again, we have a probability: and from the second box: I know, that If I sum these two probabilities the result will be wrong because I did not specify a condition. I believe I need to use Bayes' theorem. Thus: A is event of choosing a white ball again from the same box knowing that B is true (B = firstly we chose a white ball from the random box) Then we have: I am getting a wrong result and I am struggling with the correctness of my solution",\frac{14-1}{46-1} \cdot \frac{1}{2} \frac{23-1}{66-1} \cdot \frac{1}{2} P(A \mid B) = \frac{P(A~\text{and}~B)}{P(B)} P(A~\text{and}~B) = P(A) \cdot P(B) \frac{1}{2} \cdot \frac{P(\text{Probability of choosing a white ball})}{P(\text{Probability of choosing a white ball in general})},"['probability', 'conditional-probability']"
18,convergence in probability (uniform),convergence in probability (uniform),,"${{X}_{1}},{{X}_{2}},...,{{X}_{n}} \text{ iid }\sim U(0,a)$ $Z=\max \{{{X}_{1}},...{{X}_{n}}\}$ I found that ${{Z}_{n}}\xrightarrow{i.p.}a$ but the question asks for me to prove ${{Z}_{n}}\xrightarrow{i.p.}\sqrt{a}$ What is the actual value ${{Z}_{n}}$ converges in probability?",I found that but the question asks for me to prove What is the actual value converges in probability?,"{{X}_{1}},{{X}_{2}},...,{{X}_{n}} \text{ iid }\sim U(0,a) Z=\max \{{{X}_{1}},...{{X}_{n}}\} {{Z}_{n}}\xrightarrow{i.p.}a {{Z}_{n}}\xrightarrow{i.p.}\sqrt{a} {{Z}_{n}}","['probability', 'statistics', 'convergence-divergence']"
19,Show that $X$ is finite and $E(|X|)<\infty$,Show that  is finite and,X E(|X|)<\infty,"Let $\left(X_{n}\right)_{n \geq 0}$ is a martingale with $X_{0}=0$ . Assume $$\sum_{n=1}^{\infty} E\left(\left(X_{n}-X_{n-1}\right)^{2}\right)<\infty .$$ Show $X=\lim _{n \rightarrow \infty} X_{n}$ (and it is finite) and $E(|X|)<\infty$ I have shown that the martingale is uniformly integrable and thus $X=\lim _{n \rightarrow \infty} X_{n}$ with the convergence happening in $L^1$ (even though I also have shown it is bounded in $L^2$ ). Now, I do not know how to argue for that $X$ is finite a.s and that $E|X|<\infty$ . For the first one: I am thinking since the convergence happens in $L^1$ , then $X$ must be finite? For the second one: I have a result saying that if $L$ is a vector space and expectation is a linear map on it then $|X|\in L \Leftrightarrow X \in L$ but I am not sure if that helps me in any way. I think a finite random variable implies a finite expectation, but the reverse implication is not necessarily true but if I could show that the absolut value of it is finite then part 2 is solved.","Let is a martingale with . Assume Show (and it is finite) and I have shown that the martingale is uniformly integrable and thus with the convergence happening in (even though I also have shown it is bounded in ). Now, I do not know how to argue for that is finite a.s and that . For the first one: I am thinking since the convergence happens in , then must be finite? For the second one: I have a result saying that if is a vector space and expectation is a linear map on it then but I am not sure if that helps me in any way. I think a finite random variable implies a finite expectation, but the reverse implication is not necessarily true but if I could show that the absolut value of it is finite then part 2 is solved.",\left(X_{n}\right)_{n \geq 0} X_{0}=0 \sum_{n=1}^{\infty} E\left(\left(X_{n}-X_{n-1}\right)^{2}\right)<\infty . X=\lim _{n \rightarrow \infty} X_{n} E(|X|)<\infty X=\lim _{n \rightarrow \infty} X_{n} L^1 L^2 X E|X|<\infty L^1 X L |X|\in L \Leftrightarrow X \in L,"['probability', 'probability-theory', 'lp-spaces', 'probability-limit-theorems', 'uniform-integrability']"
20,Conditional expectation and the Monotone Class Theorem,Conditional expectation and the Monotone Class Theorem,,"I'm trapped by the following problem 1.5 from Exercises in Probability A Guided Tour from Measure Theory to Random Processes, via Conditioning In probability space $(\Omega,\mathcal{F},\mathbb{P})$ , let $\mathcal{G}_{}\subset \mathcal{F}$ and $Y\in \mathcal{G}$ , If $\mathop{{}\mathbb{E}}_{\mathcal{G}}g(X)=g(Y)$ for any bounded positive $g$ , show that $X = Y \text{ a.s. }$ . Where $\mathbb{E}_{\mathcal{G}}$ is expectation conditioning in $\mathcal{G}$ The solution is extend the identity to $$ \mathop{{}\mathbb{E}}_{\mathcal{G}} G(X,Y)=G(Y,Y) $$ by monotone class theorem, then taking $G(x,y)=\mathbf{1}_{x \neq y}$ . But I'm confused how to get this from MCT. My attempt is to prove all $G$ forms a monotone class $\mathcal{H}$ , then I have to prove $\mathbf{1}_{A}(x,y)$ belong to this class for any borel $A\in \mathcal{B}(\mathbb{R}^2)$ . The section $\mathbf{1}_{A}(X,y)$ is bounded and positive thus belong to $\mathcal{H}$ , but how to proceed to say $\mathbf{1}_{A}$ also belong to $\mathcal{H}$ ?","I'm trapped by the following problem 1.5 from Exercises in Probability A Guided Tour from Measure Theory to Random Processes, via Conditioning In probability space , let and , If for any bounded positive , show that . Where is expectation conditioning in The solution is extend the identity to by monotone class theorem, then taking . But I'm confused how to get this from MCT. My attempt is to prove all forms a monotone class , then I have to prove belong to this class for any borel . The section is bounded and positive thus belong to , but how to proceed to say also belong to ?","(\Omega,\mathcal{F},\mathbb{P}) \mathcal{G}_{}\subset \mathcal{F} Y\in \mathcal{G} \mathop{{}\mathbb{E}}_{\mathcal{G}}g(X)=g(Y) g X = Y \text{ a.s. } \mathbb{E}_{\mathcal{G}} \mathcal{G} 
\mathop{{}\mathbb{E}}_{\mathcal{G}} G(X,Y)=G(Y,Y)
 G(x,y)=\mathbf{1}_{x \neq y} G \mathcal{H} \mathbf{1}_{A}(x,y) A\in \mathcal{B}(\mathbb{R}^2) \mathbf{1}_{A}(X,y) \mathcal{H} \mathbf{1}_{A} \mathcal{H}","['probability', 'measure-theory', 'conditional-expectation', 'measurable-functions', 'monotone-class-theorem']"
21,Waiting times between record observations,Waiting times between record observations,,"Let $\{X_i\}_{i=1}^\infty$ be a sequence of i.i.d. random variables with a continuous CDF. Let $V_1:=\min \{n\in\mathbb N\, \vert \,X_n>X_1\}$ . Let $V_{r+1}:=\min \{ n\in \mathbb N \,|\, n>V_r \mbox{ and } X_n>X_{V_r} \}$ for all $r\ge 1$ . Define $\Delta_1 :=V_1$ and $\Delta_{r+1}:=V_{r+1} -V_r$ for all $r\geq 1$ . Now I want to show that $$\frac{\log \Delta_r}{r}\to 1 \,\,\mbox{ almost surely.}$$ This is supposed to be easy because it is in the warmups of a sequence of exercises, but I could not think of a easy way to solve it. I can prove the convergence above by proving that $\Delta_r \to e^r$ almost surely. However, the proof is quite long and will use many external results. Actually the first proof of that $\Delta_r \to e^r$ almost surely was published in the 60's in a journal. The desired inequality above shall be much weaker and easier to be proved but I just couldn't think of an easy way... Thanks for any comment/hint/answer.","Let be a sequence of i.i.d. random variables with a continuous CDF. Let . Let for all . Define and for all . Now I want to show that This is supposed to be easy because it is in the warmups of a sequence of exercises, but I could not think of a easy way to solve it. I can prove the convergence above by proving that almost surely. However, the proof is quite long and will use many external results. Actually the first proof of that almost surely was published in the 60's in a journal. The desired inequality above shall be much weaker and easier to be proved but I just couldn't think of an easy way... Thanks for any comment/hint/answer.","\{X_i\}_{i=1}^\infty V_1:=\min \{n\in\mathbb N\, \vert \,X_n>X_1\} V_{r+1}:=\min \{ n\in \mathbb N \,|\, n>V_r \mbox{ and } X_n>X_{V_r} \} r\ge 1 \Delta_1 :=V_1 \Delta_{r+1}:=V_{r+1} -V_r r\geq 1 \frac{\log \Delta_r}{r}\to 1 \,\,\mbox{ almost surely.} \Delta_r \to e^r \Delta_r \to e^r","['probability', 'probability-theory', 'probability-limit-theorems', 'almost-everywhere']"
22,How do I find probability that a poker hand contains 4 black cards and 2 spades,How do I find probability that a poker hand contains 4 black cards and 2 spades,,"Suppose 5 cards are drawn from the standard deck of 52 cards. Denote random variables $X$ to be the number of black cards in the hand and $Y$ to be the number of spades in the hand. How do I calculate $P(X=4,Y=2)$ , the probability that a poker hand contains 4 black cards and 2 spades? My attempt: $$P(X=4,Y=2)=\frac{{13\choose2}{13\choose2}{26\choose1}}{{52\choose5}}$$ where ${13\choose2}$ is the number of ways to select 2 spades, ${13\choose2}$ is the number of ways to select the remaining 2 black cards excluding spades, and ${26\choose1}$ is the number of ways to choose a red card.","Suppose 5 cards are drawn from the standard deck of 52 cards. Denote random variables to be the number of black cards in the hand and to be the number of spades in the hand. How do I calculate , the probability that a poker hand contains 4 black cards and 2 spades? My attempt: where is the number of ways to select 2 spades, is the number of ways to select the remaining 2 black cards excluding spades, and is the number of ways to choose a red card.","X Y P(X=4,Y=2) P(X=4,Y=2)=\frac{{13\choose2}{13\choose2}{26\choose1}}{{52\choose5}} {13\choose2} {13\choose2} {26\choose1}","['probability', 'card-games']"
23,Can the probability density be defined variationally?,Can the probability density be defined variationally?,,"Define a random variable $X \in \mathbb{R}$ . Suppose that the distribution of $X$ is dominated by the Lebesgue measure and hence admits a density (pdf) $f^*(x)$ at each $x \in \mathbb{R}$ . Is it possible to define $f^*$ variationally? For example, does there exist a function class $\mathcal{F}$ and a loss $L$ such that $f^* = \arg\min_{f \in \mathcal{F}} E[L\{X, f(X)\}]$ ? I'd prefer an (e.g.) $L$ to be as well behaved as possible. I've searched through books and papers online and have not had any luck towards resolving my question.","Define a random variable . Suppose that the distribution of is dominated by the Lebesgue measure and hence admits a density (pdf) at each . Is it possible to define variationally? For example, does there exist a function class and a loss such that ? I'd prefer an (e.g.) to be as well behaved as possible. I've searched through books and papers online and have not had any luck towards resolving my question.","X \in \mathbb{R} X f^*(x) x \in \mathbb{R} f^* \mathcal{F} L f^* = \arg\min_{f \in \mathcal{F}} E[L\{X, f(X)\}] L","['probability', 'probability-theory', 'convex-optimization', 'density-function']"
24,Expectation of the stopping time for certain random walk,Expectation of the stopping time for certain random walk,,"Consider a random walk on $\mathbb Z^2 \subset \mathbb C$ starting from the orgin $(0,0)$ . At each step, it randomly go one of the $4$ directions with length $1$ (i.e. $\pm 1, \pm \sqrt{-1}$ ). It stops if it hits one of the $4$ points $(\pm 5 ,\pm 5)$ in the first time. The question is, what is the expectation of the stopping time? I can write down explicitly the number of paths of hitting any given point at the $k$ -th step. Then the expectation can be written down as a summation of infinite sequences. However, I wonder if there is a simple expression, and I would like to know if there is a more elegant approach to this. Thanks in advance!","Consider a random walk on starting from the orgin . At each step, it randomly go one of the directions with length (i.e. ). It stops if it hits one of the points in the first time. The question is, what is the expectation of the stopping time? I can write down explicitly the number of paths of hitting any given point at the -th step. Then the expectation can be written down as a summation of infinite sequences. However, I wonder if there is a simple expression, and I would like to know if there is a more elegant approach to this. Thanks in advance!","\mathbb Z^2 \subset \mathbb C (0,0) 4 1 \pm 1, \pm \sqrt{-1} 4 (\pm 5 ,\pm 5) k","['probability', 'expected-value', 'random-walk', 'stopping-times']"
25,Characteristic function of a random variable with P({X=k}) = $2^{-k}$,Characteristic function of a random variable with P({X=k}) =,2^{-k},"Find the characteristic function of a random variable X such that P({X=k}) = $2^{-k}$ , $k =1,2,3,4,5, \ldots$ What I was doing is: $$ \phi_x(t) = E(e^{itx}) = \sum^{\infty}_{k=1} 2^{-k} * e^{itk} = \sum^{\infty}_{k=0} \left(\frac{e^{it}}{2}\right)^k -1 $$ From that, I don't know what else to do.","Find the characteristic function of a random variable X such that P({X=k}) = , What I was doing is: From that, I don't know what else to do.","2^{-k} k =1,2,3,4,5, \ldots 
\phi_x(t) = E(e^{itx}) = \sum^{\infty}_{k=1} 2^{-k} * e^{itk} = \sum^{\infty}_{k=0} \left(\frac{e^{it}}{2}\right)^k -1
","['probability', 'characteristic-functions', 'geometric-series']"
26,Calculating $\mathbb E\left[\sum_{k=1}^TX_k\right]$ where $(X_k)$ where $T$ is a stopping time,Calculating  where  where  is a stopping time,\mathbb E\left[\sum_{k=1}^TX_k\right] (X_k) T,"Let $(X_k)_{k\in\mathbb N^*}$ be integrable random variables and $(\mathcal F_k)_{k\in\mathbb N^*}$ a filtration such that $(X_k)$ is $(\mathcal F_k)$ -adapted. Let $T$ be an integrable $(\mathcal F_k)$ -stopping time. Suppose that for $k\ge1$ , $\mathbb E[X_{k+1}\mid\mathcal F_k]=\mathbb E[X_1]$ . Show that : $$\mathbb E\left[\sum_{k=1}^TX_k\right]=\mathbb E[T]\mathbb E[X_1]$$ The case where $T$ and $(X_k)$ is very simple but I can't quite slove this version of the problem. The natural way to solve this problem seems to be taking : $$Y_n=\sum_{k=1}^nX_k,\quad n\ge1$$ Such that the quantity we wish to determine is $\mathbb E[Y_T]$ . We have $\mathbb E[Y_{n+1}\mid \mathcal F_n]=Y_n+\mathbb E[X_1]$ and so depending on the value of $\mathbb E[X_1]$ , $(Y_n)$ is either a martingale, submartingale or supermartingale. Next I looked at the decomposition : $$Y_{T\wedge n}=Y_{T\wedge n}\mathbf1_{\{T<+\infty\}}+Y_{T\wedge n}\mathbf 1_{\{T=+\infty\}}\implies \mathbb E[Y_{T\wedge n}]=\mathbb E[Y_{T\wedge n}\mathbf1_{\{T<+\infty\}}]+\mathbb E[Y_{T\wedge n}\mathbf 1_{\{T=+\infty\}}]$$ where $x\wedge y=\min(x,y)$ . Since we supposed that $T$ was integrable, we get that $\mathbb P(T=+\infty)=0$ because $T$ is positive. Therefore : $$\mathbb E[Y_{T\wedge n}\mathbf 1_{\{T=+\infty\}}]=\int_{\{\omega,T(\omega=+\infty\}}Y_{T(\omega)\wedge n}(\omega)\mathbb P(d\omega)=0$$ Hence : $$\mathbb E[Y_{T\wedge n}]=\mathbb E[Y_{T\wedge n}\mathbf1_{\{T<+\infty\}}]$$ Then I would like to let $n\rightarrow\infty$ and use a result like dominated convergence to get $\mathbb E[Y_T]$ but since there isn't really any link between $T$ and the $(Y_n)$ I don't really know how to continue from there. Any help would be greatly appreciated !","Let be integrable random variables and a filtration such that is -adapted. Let be an integrable -stopping time. Suppose that for , . Show that : The case where and is very simple but I can't quite slove this version of the problem. The natural way to solve this problem seems to be taking : Such that the quantity we wish to determine is . We have and so depending on the value of , is either a martingale, submartingale or supermartingale. Next I looked at the decomposition : where . Since we supposed that was integrable, we get that because is positive. Therefore : Hence : Then I would like to let and use a result like dominated convergence to get but since there isn't really any link between and the I don't really know how to continue from there. Any help would be greatly appreciated !","(X_k)_{k\in\mathbb N^*} (\mathcal F_k)_{k\in\mathbb N^*} (X_k) (\mathcal F_k) T (\mathcal F_k) k\ge1 \mathbb E[X_{k+1}\mid\mathcal F_k]=\mathbb E[X_1] \mathbb E\left[\sum_{k=1}^TX_k\right]=\mathbb E[T]\mathbb E[X_1] T (X_k) Y_n=\sum_{k=1}^nX_k,\quad n\ge1 \mathbb E[Y_T] \mathbb E[Y_{n+1}\mid \mathcal F_n]=Y_n+\mathbb E[X_1] \mathbb E[X_1] (Y_n) Y_{T\wedge n}=Y_{T\wedge n}\mathbf1_{\{T<+\infty\}}+Y_{T\wedge n}\mathbf 1_{\{T=+\infty\}}\implies \mathbb E[Y_{T\wedge n}]=\mathbb E[Y_{T\wedge n}\mathbf1_{\{T<+\infty\}}]+\mathbb E[Y_{T\wedge n}\mathbf 1_{\{T=+\infty\}}] x\wedge y=\min(x,y) T \mathbb P(T=+\infty)=0 T \mathbb E[Y_{T\wedge n}\mathbf 1_{\{T=+\infty\}}]=\int_{\{\omega,T(\omega=+\infty\}}Y_{T(\omega)\wedge n}(\omega)\mathbb P(d\omega)=0 \mathbb E[Y_{T\wedge n}]=\mathbb E[Y_{T\wedge n}\mathbf1_{\{T<+\infty\}}] n\rightarrow\infty \mathbb E[Y_T] T (Y_n)","['probability', 'probability-theory', 'expected-value', 'martingales', 'stopping-times']"
27,Convergence of moments,Convergence of moments,,"Suppose $\left(X_{n},n\in \mathbb {N}\right)$ is a sequence of random variables taking values in $[0,1]$ . Suppose that for every $k\in \mathbb {N}$ , $$ \lim_{n\to \infty}\mathbb {E}\left(X^{k}_{n}\right)=\int x^{k}\, d\mu, $$ for some probability measure $\mu$ . Then show that $(X_{n})$ converges to $\mu$ weakly. I think this should be straightforward by the following theorem: where $\Rightarrow$ means weak convergence or convergence in distribution. I wonder what if I have the following instead: $$ \lim_{n\to \infty}\mathbb {E}\left(X^{k}_{n}\right)=\frac {a}{k+a}, $$ for some $a>0$ and every $k\in \mathbb {N}$ .","Suppose is a sequence of random variables taking values in . Suppose that for every , for some probability measure . Then show that converges to weakly. I think this should be straightforward by the following theorem: where means weak convergence or convergence in distribution. I wonder what if I have the following instead: for some and every .","\left(X_{n},n\in \mathbb {N}\right) [0,1] k\in \mathbb {N} 
\lim_{n\to \infty}\mathbb {E}\left(X^{k}_{n}\right)=\int x^{k}\, d\mu,
 \mu (X_{n}) \mu \Rightarrow 
\lim_{n\to \infty}\mathbb {E}\left(X^{k}_{n}\right)=\frac {a}{k+a},
 a>0 k\in \mathbb {N}","['probability', 'weak-convergence']"
28,Representation of a martingale as a stochastic integral,Representation of a martingale as a stochastic integral,,"Let $\xi_{1},\xi_{2},\dots$ be an i.i.d. sequence that takes values $\pm 1$ with equal probabilities. Define the simple symmetric random walk with $X_{0}=0$ , and $X_{n}=\sum_{i=1}^{n}\xi_{i}$ . Define the filtration $\mathcal {F}_{n}=\sigma\left(X_{1},\dots, X_{n}\right)=\sigma(\xi_{1},\dots,\xi_{n})$ . Let $\mathcal {F}_{\infty}=\sigma\left(\cup_{n=1}^{\infty}\mathcal {F}_{n}\right)$ . Let $T\in \mathcal {F}_{\infty}$ be an integrable random variable. I want to show that there is a martingale sequence ( $M_{n},n\in \mathbb {N}$ ) such that $M_{n}\to T$ almost surely. Furthermore, I can always write $M_{n}$ as $$ M_{n}=\mathbb {E}(T)+\sum_{i=1}^{n}A_{i}\left(X_{i}-X_{i-1}\right), $$ for some predictable sequence $(A_{i},i\in \mathbb {N})$ . Seeking for some hints on doing both.","Let be an i.i.d. sequence that takes values with equal probabilities. Define the simple symmetric random walk with , and . Define the filtration . Let . Let be an integrable random variable. I want to show that there is a martingale sequence ( ) such that almost surely. Furthermore, I can always write as for some predictable sequence . Seeking for some hints on doing both.","\xi_{1},\xi_{2},\dots \pm 1 X_{0}=0 X_{n}=\sum_{i=1}^{n}\xi_{i} \mathcal {F}_{n}=\sigma\left(X_{1},\dots, X_{n}\right)=\sigma(\xi_{1},\dots,\xi_{n}) \mathcal {F}_{\infty}=\sigma\left(\cup_{n=1}^{\infty}\mathcal {F}_{n}\right) T\in \mathcal {F}_{\infty} M_{n},n\in \mathbb {N} M_{n}\to T M_{n} 
M_{n}=\mathbb {E}(T)+\sum_{i=1}^{n}A_{i}\left(X_{i}-X_{i-1}\right),
 (A_{i},i\in \mathbb {N})","['probability', 'martingales']"
29,Show that distribution doesn't belong to Exponential Family,Show that distribution doesn't belong to Exponential Family,,"Let $X$ be distributed by the following density function $$f_X(x;\gamma)=\frac{1}{\pi((x-\gamma)^2+1)}, \ \ \ \ \ x,\gamma\in\mathbb{R}$$ Then we want to show that $\{f_X(x;\gamma): \gamma\in\mathbb{R}\}$ is not a one dimensional exponential family. We have that if there exists $h:\mathbb{R}\to\mathbb{R}_+,g:\mathbb{R}\to\mathbb{R}_+, \eta:\mathbb{R}\to\mathbb{R}$ and $T:\mathbb{R}\to\mathbb{R}$ such that $$f_X(x;\gamma)=h(x)g(\gamma)\exp(\eta(\gamma)T(x))$$ then $\{f_X(x;\gamma): \gamma\in\mathbb{R}\}$ is a one dimensional exponential family. But I can't seem to show that this distribution doesn't belong to the exponential family. Any help is greatly appreciated.",Let be distributed by the following density function Then we want to show that is not a one dimensional exponential family. We have that if there exists and such that then is a one dimensional exponential family. But I can't seem to show that this distribution doesn't belong to the exponential family. Any help is greatly appreciated.,"X f_X(x;\gamma)=\frac{1}{\pi((x-\gamma)^2+1)}, \ \ \ \ \ x,\gamma\in\mathbb{R} \{f_X(x;\gamma): \gamma\in\mathbb{R}\} h:\mathbb{R}\to\mathbb{R}_+,g:\mathbb{R}\to\mathbb{R}_+,
\eta:\mathbb{R}\to\mathbb{R} T:\mathbb{R}\to\mathbb{R} f_X(x;\gamma)=h(x)g(\gamma)\exp(\eta(\gamma)T(x)) \{f_X(x;\gamma): \gamma\in\mathbb{R}\}","['probability', 'probability-theory', 'statistics']"
30,"$\exists f$ such that $f(X,Y)$ is independent of $X+Y$?",such that  is independent of ?,"\exists f f(X,Y) X+Y","Let $X,Y$ be independent continous random variables. Does there exist a non-constant measurable function $f$ such that $f(X,Y)$ is independent of $X+Y$ ? I am only interested in existence (and not the form of $f$ ). I suppose that it can depend on the distributions of $X,Y$ . It would be interesting to see at least an example when $f$ either exists or it can be proven that it does not exist. My thoughts are that a transformation $(X,Y)\to X+Y$ starts from independent components, so there should be another ""perpendicular"" transformation that will be independent of $X+Y$ .","Let be independent continous random variables. Does there exist a non-constant measurable function such that is independent of ? I am only interested in existence (and not the form of ). I suppose that it can depend on the distributions of . It would be interesting to see at least an example when either exists or it can be proven that it does not exist. My thoughts are that a transformation starts from independent components, so there should be another ""perpendicular"" transformation that will be independent of .","X,Y f f(X,Y) X+Y f X,Y f (X,Y)\to X+Y X+Y","['probability', 'probability-theory', 'probability-distributions', 'statistical-inference']"
31,Probability of red balls present in the urn,Probability of red balls present in the urn,,"There are n total balls in the urn containing red and blue colors with unknown ratios. k red balls can be anywhere from 0 to n being equally likely and the remaining n - k will be blue balls. What is the probability of k red balls in the urn if the first ball drawn is red? What is the probability of k red balls in the urn if the first ball drawn is red without replacement and the second ball drawn is blue? I know that Bayes's rule will be applied to find out the probability of red balls present in the given. I think P(k red balls) = 1/( n +1) and P( n - k blue balls) = n / n +1 Further, Bayes's formula will be applied so that P( k red balls|ball drawn is red) = {P(ball drawn is red | k red balls)*P( k red balls)}/P (ball drawn is red) But I am stuck as to how to use this to find the answer.","There are n total balls in the urn containing red and blue colors with unknown ratios. k red balls can be anywhere from 0 to n being equally likely and the remaining n - k will be blue balls. What is the probability of k red balls in the urn if the first ball drawn is red? What is the probability of k red balls in the urn if the first ball drawn is red without replacement and the second ball drawn is blue? I know that Bayes's rule will be applied to find out the probability of red balls present in the given. I think P(k red balls) = 1/( n +1) and P( n - k blue balls) = n / n +1 Further, Bayes's formula will be applied so that P( k red balls|ball drawn is red) = {P(ball drawn is red | k red balls)*P( k red balls)}/P (ball drawn is red) But I am stuck as to how to use this to find the answer.",,['probability']
32,Using binomial distribution to solve packet-switching and circuit-switching problem,Using binomial distribution to solve packet-switching and circuit-switching problem,,"I have the following problem that I'm really stuck on. I attempted to do part b) and c) but I think I am very wrong since I didn't get the results required in part d). And part (a) I am also stuck on. Can someone please help me solve this problem? In networks, we use physical cables/wires to send electromagnetic signals from point to point (the signals carry information). You can only fit so many signals on a wire at once, however. There are two approaches towards sharing a cable/wire to transmit data in a network: packet switching and circuit switching. In packet switching, users randomly send information over the wire whenever they feel like it whereas in circuit switching, users reserve a fixed percent of the resources on the wire (regardless of whether they're actively using it). Assume each user uses 10% of the wire's resources when they send information on the wire and users are randomly active $p$ % of the time. If more than 100% of the wire's resources are used at a point in time, we declare a ""collision"" and no work gets done. Define the utilization of the wire as the average percent of its resources being used over time (utilization during a collision is 0). a) in the circuit switching scenario, how many users can share this wire as a function of $p$ ? What is the utilization? Max users = 10 Utilization is p% b) In the packet-switching scenario, how many users can share this wire, assuming we want to keep the probability of collision less than 0.1%? What is the utilization? (Write an equation that would let you solve for the number of users/utilization given p Max users = $$\sum_{k=0}^{10} {n\choose k} p^k(1-p)^{n-k} \geq 0.999$$ Utilization = $$\sum_{k=0}^{10} {n\choose k} \frac{k}{10} p^k(1-p)^{n-k} $$ c) Solve for the previous two answers with p=50 percent and p=5 percent $p=0.5$ : $$\sum_{k=0}^{10} {11 \choose k} (0.5)^k(1-0.5)^{11-k} >0.999$$ $$\sum_{k=0}^{10} {12 \choose k} (0.5)^k(1-0.5)^{12-k} <0.999$$ so max users is 11. utilization: $$\sum_{k=0}^{10} {11\choose k} \frac{k}{10} p^k(1-p)^{11-k} \approx 0.55$$ $p=0.05$ $$\sum_{k=0}^{10} {73 \choose k} (0.5)^k(1-0.5)^{73-k} >0.999$$ $$\sum_{k=0}^{10} {74 \choose k} (0.5)^k(1-0.5)^{74-k} <0.999$$ so max users is 73 Utilization is: $$\sum_{k=0}^{10} {73\choose k} \frac{k}{10} p^k(1-p)^{73-k} \approx 0.36$$ d) You should have found that for p=5 percent, the packet-switched network can support more users than for p=50 percent. Why, then, does the expected utilization decrease when p=5 percent? I found that p=5 supports more users than p=50 but the expected utilization doesnt decrease.","I have the following problem that I'm really stuck on. I attempted to do part b) and c) but I think I am very wrong since I didn't get the results required in part d). And part (a) I am also stuck on. Can someone please help me solve this problem? In networks, we use physical cables/wires to send electromagnetic signals from point to point (the signals carry information). You can only fit so many signals on a wire at once, however. There are two approaches towards sharing a cable/wire to transmit data in a network: packet switching and circuit switching. In packet switching, users randomly send information over the wire whenever they feel like it whereas in circuit switching, users reserve a fixed percent of the resources on the wire (regardless of whether they're actively using it). Assume each user uses 10% of the wire's resources when they send information on the wire and users are randomly active % of the time. If more than 100% of the wire's resources are used at a point in time, we declare a ""collision"" and no work gets done. Define the utilization of the wire as the average percent of its resources being used over time (utilization during a collision is 0). a) in the circuit switching scenario, how many users can share this wire as a function of ? What is the utilization? Max users = 10 Utilization is p% b) In the packet-switching scenario, how many users can share this wire, assuming we want to keep the probability of collision less than 0.1%? What is the utilization? (Write an equation that would let you solve for the number of users/utilization given p Max users = Utilization = c) Solve for the previous two answers with p=50 percent and p=5 percent : so max users is 11. utilization: so max users is 73 Utilization is: d) You should have found that for p=5 percent, the packet-switched network can support more users than for p=50 percent. Why, then, does the expected utilization decrease when p=5 percent? I found that p=5 supports more users than p=50 but the expected utilization doesnt decrease.",p p \sum_{k=0}^{10} {n\choose k} p^k(1-p)^{n-k} \geq 0.999 \sum_{k=0}^{10} {n\choose k} \frac{k}{10} p^k(1-p)^{n-k}  p=0.5 \sum_{k=0}^{10} {11 \choose k} (0.5)^k(1-0.5)^{11-k} >0.999 \sum_{k=0}^{10} {12 \choose k} (0.5)^k(1-0.5)^{12-k} <0.999 \sum_{k=0}^{10} {11\choose k} \frac{k}{10} p^k(1-p)^{11-k} \approx 0.55 p=0.05 \sum_{k=0}^{10} {73 \choose k} (0.5)^k(1-0.5)^{73-k} >0.999 \sum_{k=0}^{10} {74 \choose k} (0.5)^k(1-0.5)^{74-k} <0.999 \sum_{k=0}^{10} {73\choose k} \frac{k}{10} p^k(1-p)^{73-k} \approx 0.36,"['probability', 'probability-distributions', 'binomial-distribution']"
33,Convergence of Random Power series,Convergence of Random Power series,,"Q) Let $X_1,X_2,..$ be i.i.d. and not $\equiv 0$ . Show that the radius of convergence of the power series $\sum_{n\geq 1}X_nz^n$ is $1$ a.s. or $0$ a.s. according as $E\text{ log}^+|X_1|<\infty \text{ or } = \infty$ , where $\text{log}^+x = \text{max(log }x,0)$ . I am trying to understand the proof of the question given here here but I fail to understand the portion when $E[\log_{+}(|X_{1}|)]<\infty$ . Btw I am posting this as a new question because this is too long for a comment and it is most likely to be ignored as it is a fairly old post. It says that $\sum_{n=1}^{\infty}P(\log_{+}(|X_{n}|)\geq \epsilon n)=\infty$ for any $\epsilon>0$ and hence $|X_{n}|< e^{\epsilon n} $ for large $n$ with probability $1$ . But why is that the case? .  If the above holds , then we have by BC lemma 2 that $\log_{+}(|X_{n}|)\geq \epsilon n$ for infinitely many $n$ with probability $1$ . I think since we need $|X_{n}|<e^{\epsilon n}$ for large $n$ , i.e. for all but finitely mane $n$ , we should consider $\sum_{n=1}^{\infty}P(\log_{+}|X_{n}|\geq \epsilon n)$ and show that it converges and hence by BC lemma 1 we would have $|X_{n}|\geq e^{\epsilon n} $ occurs infinitely often with probability $0$ , Or in other words $|X_{n}|\leq e^{\epsilon n}$ occurs for all but finitely many $n$ with probability $1$ . Explicitly , I mean that if $A_{n}= \{|X_{n}|< e^{\epsilon n}\}$ then $P(\lim\inf A_{n})=1-P(\lim\sup A_{n}^{c})$ . But then again, I run into a problem of how to at all show $\sum_{n=1}^{\infty}P(\log_{+}|X_{n}|>\epsilon n)<\infty$ . I would want to use Markov's inequality, but that would require something like $n^{1+\epsilon}$ . That is I can atmost show $$\sum_{n=1}^{\infty}P(\log_{+}|X_{n}|>\epsilon n^{1+\epsilon}) \leq \sum_{n=1}^{\infty}\frac{E[\log_{+}X_{1}]}{\epsilon n^{\epsilon+1}}\leq M\sum_{n=1}^{\infty}\frac{1}{n^{\epsilon+1}}<\infty$$ for all $\epsilon>0$ . This would allow me to conclude $\large |X_{n}|<e^{\epsilon n^{1+\epsilon}}$ for all large $n$ . But this does not really help with the problem as @KaviRamaMurthy 's answer uses $|X_nz^{n}| \leq e^{n\epsilon} |z|^{n}=(e^{\epsilon}|z|)^{n}$ as a term for the geometric series to show convergence. However for any $\epsilon$ , we have $\large e^{n^{1+\epsilon}}$ would outgrow $e^{n}$ . In any case I am not using the independence with this approach so there must be something wrong . Question : Can anybody tell me how to show the required $|X_{n}|<e^{\epsilon n}$ for large $n$ with probability $1$ in this or some other way? .","Q) Let be i.i.d. and not . Show that the radius of convergence of the power series is a.s. or a.s. according as , where . I am trying to understand the proof of the question given here here but I fail to understand the portion when . Btw I am posting this as a new question because this is too long for a comment and it is most likely to be ignored as it is a fairly old post. It says that for any and hence for large with probability . But why is that the case? .  If the above holds , then we have by BC lemma 2 that for infinitely many with probability . I think since we need for large , i.e. for all but finitely mane , we should consider and show that it converges and hence by BC lemma 1 we would have occurs infinitely often with probability , Or in other words occurs for all but finitely many with probability . Explicitly , I mean that if then . But then again, I run into a problem of how to at all show . I would want to use Markov's inequality, but that would require something like . That is I can atmost show for all . This would allow me to conclude for all large . But this does not really help with the problem as @KaviRamaMurthy 's answer uses as a term for the geometric series to show convergence. However for any , we have would outgrow . In any case I am not using the independence with this approach so there must be something wrong . Question : Can anybody tell me how to show the required for large with probability in this or some other way? .","X_1,X_2,.. \equiv 0 \sum_{n\geq 1}X_nz^n 1 0 E\text{ log}^+|X_1|<\infty \text{ or } = \infty \text{log}^+x = \text{max(log }x,0) E[\log_{+}(|X_{1}|)]<\infty \sum_{n=1}^{\infty}P(\log_{+}(|X_{n}|)\geq \epsilon n)=\infty \epsilon>0 |X_{n}|< e^{\epsilon n}  n 1 \log_{+}(|X_{n}|)\geq \epsilon n n 1 |X_{n}|<e^{\epsilon n} n n \sum_{n=1}^{\infty}P(\log_{+}|X_{n}|\geq \epsilon n) |X_{n}|\geq e^{\epsilon n}  0 |X_{n}|\leq e^{\epsilon n} n 1 A_{n}= \{|X_{n}|< e^{\epsilon n}\} P(\lim\inf A_{n})=1-P(\lim\sup A_{n}^{c}) \sum_{n=1}^{\infty}P(\log_{+}|X_{n}|>\epsilon n)<\infty n^{1+\epsilon} \sum_{n=1}^{\infty}P(\log_{+}|X_{n}|>\epsilon n^{1+\epsilon}) \leq \sum_{n=1}^{\infty}\frac{E[\log_{+}X_{1}]}{\epsilon n^{\epsilon+1}}\leq M\sum_{n=1}^{\infty}\frac{1}{n^{\epsilon+1}}<\infty \epsilon>0 \large |X_{n}|<e^{\epsilon n^{1+\epsilon}} n |X_nz^{n}| \leq e^{n\epsilon} |z|^{n}=(e^{\epsilon}|z|)^{n} \epsilon \large e^{n^{1+\epsilon}} e^{n} |X_{n}|<e^{\epsilon n} n 1","['probability', 'probability-theory', 'convergence-divergence', 'expected-value', 'borel-cantelli-lemmas']"
34,Conditional covariance of two independent normal variables when their sum is fixed,Conditional covariance of two independent normal variables when their sum is fixed,,"I am reading through Brady Neal's ""Introduction to Causality"" course textbook and have got to Section 3.6 where Berkson's paradox is discussed. Neal provides the following toy example: $$ X_{1} = \mathcal{N}(0,1) \\  X_{3} = \mathcal{N}(0,1) \\ X_{2} = X_{1} + X_{3} $$ He then proceeds to compute the covariance of $X_{1}$ and $X_{3}$ as a sanity check: $$ \text{Cov}(X_{1}, X_{3}) = \mathbb{E}[X_{1}X_{3}] - \mathbb{E}[X_{1}]\mathbb{E}[X_{3}] =  \mathbb{E}[X_{1}X_{3}] = \mathbb{E}[X_{1}]\mathbb{E}[X_{3}] = 0 $$ where we used independence. Next Neal computes the conditional covariance given that $X_{2} = x$ . $$ \text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3} \,|\, X_{2} = x] =  \mathbb{E}[X_{1}(x  - X_{1})] = x\mathbb{E}[X_{1}] - \mathbb{E}[X^{2}_{1}] = -1 $$ Is this correct? When I do my own calculation I seem to get the following result: $$ \text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] $$ Consider each factor separately in the second term: $$ \mathbb{E}[X_{1} \,|\, X_{2} = x] = \mathbb{E}[X_{1} \,|\, X_{1} + X_{3} = x] = \mathbb{E}[x - X_{3}] = x - \mathbb{E}[X_{3}] $$ Likewise we have $$ \mathbb{E}[X_{3} \,|\, X_{2} = x] = x - \mathbb{E}[X_{1}] $$ Multiplying both terms we have: $$ \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] = (x - \mathbb{E}[X_{3}])(x - \mathbb{E}[X_{1}]) = x^{2} $$ Now consider the first term: $$ \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \mathbb{E}[X_{1}X_{3}\,|\, X_{1} + X_{3} = x] = \\ \mathbb{E}[X_{1}(x - X_{1})] = x\mathbb{E}[X_{1}] - \mathbb{E}[X_{1}^{2}] = 0 - 1 = -1 $$ Putting everything together we have: $$ \text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] = -1 - x^{2} $$ Am I doing something wrong? I am concerned the author is forgetting that the expectations in the second term are conditional leading them to set the second term to zero as in the unconditioned case. I may also be using the wrong definition for conditional covariance, although no explicit definition is provided in the book. Note that this example is an attempt to model a collider where $X_{1}$ and $X_{3}$ are parents of $X_{2}$ . EDIT: Both myself and the textbook are wrong! Thanks to Henry for pointing this out, whose answer I have accepted below. I thought I would correct my approach using Henry's working to highlight my errors. As before we have: $$ \text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] $$ Let's deal with the second term first. Clearly we have: $$ \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{1}\,|\,X_{2}=x] =  \mathbb{E}[X_{1}\,|\,X_{2}=x]^{2} $$ Applying the first formula derived by Henry in this question we have $$ \mathbb{E}[X_{1}\,|\,X_{2}=x]^{2} = \frac{x^{2}}{4} $$ Now for the first term we have $$ \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \mathbb{E}[(x-X_{3})X_{3}\,|\, X_{2} = x] = x\mathbb{E}[X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{3}^{2}\,|\, X_{2} = x] $$ Note how the conditional in the expectation remains as $X_{3}$ is still conditioned on $X_{2}$ . This is what caused the issue with my analysis! Following a similar logic as above with $X_{3}$ in place of $X_{1}$ we have: $$ \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - \mathbb{E}[X_{3}^{2}\,|\, X_{2} = x] $$ Adding and subtracting $\mathbb{E}[X_{3}\,|\,X_{2} = x]^{2}$ we have $$ \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - (\mathbb{E}[X_{3}^{2}\,|\, X_{2} = x] - \mathbb{E}[X_{3}\,|\,X_{2} = x]^{2}) - \mathbb{E}[X_{3}\,|\,X_{2} = x]^{2} $$ Observe that the term in the brackets is simply the conditional variance of $X_{3}$ . Hence, using the second identity provided by Henry in the aforementioned question we have: $$ \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - \frac{1}{2} - \mathbb{E}[X_{3}\,|\,X_{2} = x]^{2} $$ Recall that we calculated the leftover term (with $X_{1}$ in place of $X_{3}$ . Plugging in our solution we have: $$ \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - \frac{1}{2} - \frac{x^{2}}{4} = \frac{x^{2}}{2} - 1/2 $$ Putting everything together we end up with: $$ \text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] \\ = \frac{x^{2}}{2} - 1/2 - \frac{x^{2}}{4} = -1/2 $$ Finally, we arrive at the correct result! Note that I have left some details out regarding how the conditional expectations and variances used from Henry's question are calculated. Although, I believe a question which presents the working for a similar problem is linked there. I may add these derivations later but for now I am happy to assume that Henry is a divine oracle capable of correctly computing the conditional moments of normal distributions :).","I am reading through Brady Neal's ""Introduction to Causality"" course textbook and have got to Section 3.6 where Berkson's paradox is discussed. Neal provides the following toy example: He then proceeds to compute the covariance of and as a sanity check: where we used independence. Next Neal computes the conditional covariance given that . Is this correct? When I do my own calculation I seem to get the following result: Consider each factor separately in the second term: Likewise we have Multiplying both terms we have: Now consider the first term: Putting everything together we have: Am I doing something wrong? I am concerned the author is forgetting that the expectations in the second term are conditional leading them to set the second term to zero as in the unconditioned case. I may also be using the wrong definition for conditional covariance, although no explicit definition is provided in the book. Note that this example is an attempt to model a collider where and are parents of . EDIT: Both myself and the textbook are wrong! Thanks to Henry for pointing this out, whose answer I have accepted below. I thought I would correct my approach using Henry's working to highlight my errors. As before we have: Let's deal with the second term first. Clearly we have: Applying the first formula derived by Henry in this question we have Now for the first term we have Note how the conditional in the expectation remains as is still conditioned on . This is what caused the issue with my analysis! Following a similar logic as above with in place of we have: Adding and subtracting we have Observe that the term in the brackets is simply the conditional variance of . Hence, using the second identity provided by Henry in the aforementioned question we have: Recall that we calculated the leftover term (with in place of . Plugging in our solution we have: Putting everything together we end up with: Finally, we arrive at the correct result! Note that I have left some details out regarding how the conditional expectations and variances used from Henry's question are calculated. Although, I believe a question which presents the working for a similar problem is linked there. I may add these derivations later but for now I am happy to assume that Henry is a divine oracle capable of correctly computing the conditional moments of normal distributions :).","
X_{1} = \mathcal{N}(0,1) \\ 
X_{3} = \mathcal{N}(0,1) \\
X_{2} = X_{1} + X_{3}
 X_{1} X_{3} 
\text{Cov}(X_{1}, X_{3}) = \mathbb{E}[X_{1}X_{3}] - \mathbb{E}[X_{1}]\mathbb{E}[X_{3}] = 
\mathbb{E}[X_{1}X_{3}] = \mathbb{E}[X_{1}]\mathbb{E}[X_{3}] = 0
 X_{2} = x 
\text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3} \,|\, X_{2} = x] = 
\mathbb{E}[X_{1}(x  - X_{1})] = x\mathbb{E}[X_{1}] - \mathbb{E}[X^{2}_{1}] = -1
 
\text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x]
 
\mathbb{E}[X_{1} \,|\, X_{2} = x] = \mathbb{E}[X_{1} \,|\, X_{1} + X_{3} = x] =
\mathbb{E}[x - X_{3}] = x - \mathbb{E}[X_{3}]
 
\mathbb{E}[X_{3} \,|\, X_{2} = x] = x - \mathbb{E}[X_{1}]
 
\mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] = (x - \mathbb{E}[X_{3}])(x - \mathbb{E}[X_{1}]) = x^{2}
 
\mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] =
\mathbb{E}[X_{1}X_{3}\,|\, X_{1} + X_{3} = x] = \\
\mathbb{E}[X_{1}(x - X_{1})] =
x\mathbb{E}[X_{1}] - \mathbb{E}[X_{1}^{2}] = 0 - 1 = -1
 
\text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] = -1 - x^{2}
 X_{1} X_{3} X_{2} 
\text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x]
 
\mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{1}\,|\,X_{2}=x] = 
\mathbb{E}[X_{1}\,|\,X_{2}=x]^{2}
 
\mathbb{E}[X_{1}\,|\,X_{2}=x]^{2} = \frac{x^{2}}{4}
 
\mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \mathbb{E}[(x-X_{3})X_{3}\,|\, X_{2} = x] = x\mathbb{E}[X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{3}^{2}\,|\, X_{2} = x]
 X_{3} X_{2} X_{3} X_{1} 
\mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - \mathbb{E}[X_{3}^{2}\,|\, X_{2} = x]
 \mathbb{E}[X_{3}\,|\,X_{2} = x]^{2} 
\mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - (\mathbb{E}[X_{3}^{2}\,|\, X_{2} = x] - \mathbb{E}[X_{3}\,|\,X_{2} = x]^{2}) - \mathbb{E}[X_{3}\,|\,X_{2} = x]^{2}
 X_{3} 
\mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - \frac{1}{2} - \mathbb{E}[X_{3}\,|\,X_{2} = x]^{2}
 X_{1} X_{3} 
\mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] = \frac{x^{2}}{2} - \frac{1}{2} - \frac{x^{2}}{4} = \frac{x^{2}}{2} - 1/2
 
\text{Cov}(X_{1}, X_{3} \,|\, X_{2} = x) = \mathbb{E}[X_{1}X_{3}\,|\, X_{2} = x] - \mathbb{E}[X_{1} \,|\,X_{2}=x]\mathbb{E}[X_{3}\,|\,X_{2}=x] \\ = \frac{x^{2}}{2} - 1/2 - \frac{x^{2}}{4} = -1/2
","['probability', 'statistics', 'causality']"
35,Stuck at the beginning of the proof of uniform convergence in probability.,Stuck at the beginning of the proof of uniform convergence in probability.,,"If $X_1, \ldots, X_n$ are i.i.d. $p(x; \theta_0) \in \{p(x; \theta) : \theta\in \Theta\}$ , $\Theta$ is compact, $\log p(x; \theta)$ is continuous in $\theta$ for all $\theta \in \Theta$ and all $x \in X$ , and if there exists a function $d(x)$ such that $|\log p(x; \theta)| \le d(x)$ for all $\theta \in \Theta$ and $x \in X$ . and we also know that the uniform continuity also implies that $\Delta(x, \delta) = \underset{{\{(\theta_1,\theta_2):||\theta_1−\theta_2||<\delta\}}}{\sup} \log p(x; \theta_1) − \log p(x; \theta_2)|\to 0$ as $\delta \to 0 $ My question is why do we have $\Delta(x, \delta) \le 2d(x)$ and how to prove that , by the dominated convergence theorem we have that $E_{\theta_0}[\Delta(X, \delta)] \to 0$ as $\delta \to 0$ . thank you very much in advance","If are i.i.d. , is compact, is continuous in for all and all , and if there exists a function such that for all and . and we also know that the uniform continuity also implies that as My question is why do we have and how to prove that , by the dominated convergence theorem we have that as . thank you very much in advance","X_1, \ldots, X_n p(x; \theta_0) \in \{p(x; \theta) : \theta\in \Theta\} \Theta \log p(x; \theta) \theta \theta \in \Theta x \in X d(x) |\log p(x; \theta)| \le d(x) \theta \in \Theta x \in X \Delta(x, \delta) = \underset{{\{(\theta_1,\theta_2):||\theta_1−\theta_2||<\delta\}}}{\sup} \log p(x; \theta_1) − \log p(x; \theta_2)|\to 0 \delta \to 0  \Delta(x, \delta) \le 2d(x) E_{\theta_0}[\Delta(X, \delta)] \to 0 \delta \to 0","['real-analysis', 'probability', 'probability-theory', 'uniform-convergence']"
36,Probability of point being inside triangle formed by 3 other points on boundary of square.,Probability of point being inside triangle formed by 3 other points on boundary of square.,,"I was trying this problem which I'll restate here: ""Three points are chosen uniformly at random from the boundary of a square and a fourth point is chosen uniformly at random from the interior. The probability that the 4th point lies in the triangle formed by the other 3 points can be expressed as $\frac{a}{b}$ where $a$ and $b$ are coprime positive integers. What is the value of $a+b$ ?"" I thought I solved this correctly, but my casework probabilities don't agree with the community solutions. Essentially, this problem is asking for the average area of a triangle formed by 3 points on the boundary of a square. To calculate this, I broke it up into cases. Consider the events: $E_1$ : All points on different sides. $E_2$ : 2 points on same side, 1 point on adjacent side $E_3$ : 2 points on same side, 1 point on opposite side $E_4$ : 3 points on same side of square Then, $$\mathbb{E}[\text{Area}]= \sum_i \mathbb{E}[\text{Area}|E_i]P(E_i)$$ After some lengthy calculations I get $\mathbb{E}[\text{Area}|E_i]=\frac{1}{4},\frac{1}{12},\frac{1}{6},0$ for $i=1,2,3,4$ respectively, which agree with the solutions. However, I got $P(E_1)=P(E_3)=P(E_4)=\frac{1}{5}$ and $P(E_2)=\frac{2}{5}$ which doesn't agree with the solutions. I arrived at this by counting the total number of arrangements of points as ${3+(4-1) \choose 3}=20$ by Stars and bars . Then I simply counted that there are 4 ways to get $E_1,E_3,E_4$ , and 8 ways to get $E_2$ . I confirmed this by exhaustively drawing out all 20 possibilities. However, the solutions give $P(E_1)=\frac{3}{8}$ , $P(E_2)=\frac{3}{8}$ , $P(E_3)=\frac{3}{16}$ , and $P(E_4)=\frac{1}{16}$ . As part of this it is stated that there are $4^3$ total arrangements of points. But doesn't this assume that the points are distinguishable? I thought the point of using stars and bars was for arranging indistinguishable items, and points surely seem to count as indistinguishable.","I was trying this problem which I'll restate here: ""Three points are chosen uniformly at random from the boundary of a square and a fourth point is chosen uniformly at random from the interior. The probability that the 4th point lies in the triangle formed by the other 3 points can be expressed as where and are coprime positive integers. What is the value of ?"" I thought I solved this correctly, but my casework probabilities don't agree with the community solutions. Essentially, this problem is asking for the average area of a triangle formed by 3 points on the boundary of a square. To calculate this, I broke it up into cases. Consider the events: : All points on different sides. : 2 points on same side, 1 point on adjacent side : 2 points on same side, 1 point on opposite side : 3 points on same side of square Then, After some lengthy calculations I get for respectively, which agree with the solutions. However, I got and which doesn't agree with the solutions. I arrived at this by counting the total number of arrangements of points as by Stars and bars . Then I simply counted that there are 4 ways to get , and 8 ways to get . I confirmed this by exhaustively drawing out all 20 possibilities. However, the solutions give , , , and . As part of this it is stated that there are total arrangements of points. But doesn't this assume that the points are distinguishable? I thought the point of using stars and bars was for arranging indistinguishable items, and points surely seem to count as indistinguishable.","\frac{a}{b} a b a+b E_1 E_2 E_3 E_4 \mathbb{E}[\text{Area}]= \sum_i \mathbb{E}[\text{Area}|E_i]P(E_i) \mathbb{E}[\text{Area}|E_i]=\frac{1}{4},\frac{1}{12},\frac{1}{6},0 i=1,2,3,4 P(E_1)=P(E_3)=P(E_4)=\frac{1}{5} P(E_2)=\frac{2}{5} {3+(4-1) \choose 3}=20 E_1,E_3,E_4 E_2 P(E_1)=\frac{3}{8} P(E_2)=\frac{3}{8} P(E_3)=\frac{3}{16} P(E_4)=\frac{1}{16} 4^3","['probability', 'geometry']"
37,Why do I need Fubini to evaluate these integrals of products of functions?,Why do I need Fubini to evaluate these integrals of products of functions?,,"I am currently reading a book on applied mathematics, and the current chapter is proving some statements related to probability theory. I'm stuck with one step in a derivation, because the author claims to use Fubini('s theorem), but I do not see why he would need it. Concretely, consider continuous random variables $X, Y$ on $\mathcal{X}$ with probability densities $p(x), q(y)$ , respectively, as well as a function $\phi:\mathcal{X}\rightarrow\mathbb{R}^N$ . The steps in question are $$\mathbb{E}_p[\phi(X)^T]\mathbb{E}_p[\phi(X)]=\int\phi(x)^Tp(x)dx\int\phi(x')p(x')dx'=\int\int\phi(x)^T\phi(x')p(x)p(x')dxdx'$$ and $$\mathbb{E}_p[\phi(X)^T]\mathbb{E}_q[\phi(Y)]=\int\phi(x)^Tp(x)dx\int\phi(y)q(y)dy=\int\phi(x)^T\phi(y)p(x)q(y)dxdy$$ I can not figure out why there would be any need to use Fubini in either step. What's more, I think that the order of integration wouldn't matter either way, since according to my understanding I can just do (e.g. in the second case): $$\int\phi(x)^Tp(x)dx\int\phi(y)q(y)dy=\int\left(\int\phi(y)q(y)dy\right)\phi(x)^Tp(x)dx=\int\left(\int\phi(y)q(y)\phi(x)^Tp(x)dy\right)dx$$ where in the first step I used that the integral in parentheses exists and hence has a constant value, and in the second step that $\phi(x)^Tp(x)$ is constant with respect to $y$ . Analogously, $$\int\phi(x)^Tp(x)dx\int\phi(y)q(y)dy=\int\left(\int\phi(x)^Tp(x)dx\right)\phi(y)q(y)dy=\int\left(\int\phi(y)q(y)\phi(x)^Tp(x)dx\right)dy$$ Which means the order of integration does not matter. (I understand that this would be different if the integrand were e.g. a function $h(x,y)$ for which I wouldn't just have $h(x,y)=f(x)g(y)$ for some appropriate $f,g$ , and then I would need Fubini. Does anybody see why the author would write that one needs Fubini?","I am currently reading a book on applied mathematics, and the current chapter is proving some statements related to probability theory. I'm stuck with one step in a derivation, because the author claims to use Fubini('s theorem), but I do not see why he would need it. Concretely, consider continuous random variables on with probability densities , respectively, as well as a function . The steps in question are and I can not figure out why there would be any need to use Fubini in either step. What's more, I think that the order of integration wouldn't matter either way, since according to my understanding I can just do (e.g. in the second case): where in the first step I used that the integral in parentheses exists and hence has a constant value, and in the second step that is constant with respect to . Analogously, Which means the order of integration does not matter. (I understand that this would be different if the integrand were e.g. a function for which I wouldn't just have for some appropriate , and then I would need Fubini. Does anybody see why the author would write that one needs Fubini?","X, Y \mathcal{X} p(x), q(y) \phi:\mathcal{X}\rightarrow\mathbb{R}^N \mathbb{E}_p[\phi(X)^T]\mathbb{E}_p[\phi(X)]=\int\phi(x)^Tp(x)dx\int\phi(x')p(x')dx'=\int\int\phi(x)^T\phi(x')p(x)p(x')dxdx' \mathbb{E}_p[\phi(X)^T]\mathbb{E}_q[\phi(Y)]=\int\phi(x)^Tp(x)dx\int\phi(y)q(y)dy=\int\phi(x)^T\phi(y)p(x)q(y)dxdy \int\phi(x)^Tp(x)dx\int\phi(y)q(y)dy=\int\left(\int\phi(y)q(y)dy\right)\phi(x)^Tp(x)dx=\int\left(\int\phi(y)q(y)\phi(x)^Tp(x)dy\right)dx \phi(x)^Tp(x) y \int\phi(x)^Tp(x)dx\int\phi(y)q(y)dy=\int\left(\int\phi(x)^Tp(x)dx\right)\phi(y)q(y)dy=\int\left(\int\phi(y)q(y)\phi(x)^Tp(x)dx\right)dy h(x,y) h(x,y)=f(x)g(y) f,g","['real-analysis', 'probability', 'integration', 'measure-theory', 'fubini-tonelli-theorems']"
38,"Two biased coins. You pick a coin, flip it, and it lands heads. What is the probability it will be heads on the next flip?","Two biased coins. You pick a coin, flip it, and it lands heads. What is the probability it will be heads on the next flip?",,"You have a bag with two coins. One will come up heads $40\%$ of the time, and the other will come up heads $60\%$ . You pick a coin randomly, flip it and get a head. What is the probability it will be heads on the next flip? My approach to the problem is the following one. We want to compute the probability $\mathbb{P}(hh\mid h)$ . By Bayes, this is equivalent to $$\frac{\mathbb{P}(h\mid hh)\cdot\mathbb{P}(hh)}{\mathbb{P}(h)}$$ It is immediate that $\mathbb{P}(h\mid hh)=1$ . On the other hand $$\mathbb{P}(hh)=1/2\cdot (0.6)^2 + 1/2 \cdot (0.4)^2=0.26$$ and $$\mathbb{P}(h)=1/2\cdot 0.6+1/2\cdot 0.4=0.5$$ Therefore, $$\mathbb{P}(hh\mid h)=0.52$$ Is my approach correct?","You have a bag with two coins. One will come up heads of the time, and the other will come up heads . You pick a coin randomly, flip it and get a head. What is the probability it will be heads on the next flip? My approach to the problem is the following one. We want to compute the probability . By Bayes, this is equivalent to It is immediate that . On the other hand and Therefore, Is my approach correct?",40\% 60\% \mathbb{P}(hh\mid h) \frac{\mathbb{P}(h\mid hh)\cdot\mathbb{P}(hh)}{\mathbb{P}(h)} \mathbb{P}(h\mid hh)=1 \mathbb{P}(hh)=1/2\cdot (0.6)^2 + 1/2 \cdot (0.4)^2=0.26 \mathbb{P}(h)=1/2\cdot 0.6+1/2\cdot 0.4=0.5 \mathbb{P}(hh\mid h)=0.52,['probability']
39,Probability that sum of random variables is positive does not approach $1$ in the limit,Probability that sum of random variables is positive does not approach  in the limit,1,"Say we have independent random variables $X_i$ , with: $$ X_i =  \begin{cases} 1,~\text{with probability}~\frac{1}{2}+ 2^{-i},\\ -1,~\text{with probability}~\frac{1}{2}-2^{-i}. \end{cases} $$ I'm interested in showing that $\lim_{n\rightarrow \infty}\mathbb{P}[X_1+\dots+X_n > 0]\neq 1$ . I've seen an argument for this using the Central Limit Theorem ( here , pp. 2-3). I was wondering: is there perhaps a simpler (more elegant?) argument---perhaps using some more elementary methods, or a well-chosen concentration inequality---that could work well on an audience with less than exhaustive knowledge of statistics? I tried explicitly spelling out the probability that a majority of the $X_i$ 's have value $1$ , with the hope of bounding the sum with some inequalities, but with limited success. So am looking for another angle.","Say we have independent random variables , with: I'm interested in showing that . I've seen an argument for this using the Central Limit Theorem ( here , pp. 2-3). I was wondering: is there perhaps a simpler (more elegant?) argument---perhaps using some more elementary methods, or a well-chosen concentration inequality---that could work well on an audience with less than exhaustive knowledge of statistics? I tried explicitly spelling out the probability that a majority of the 's have value , with the hope of bounding the sum with some inequalities, but with limited success. So am looking for another angle.","X_i 
X_i = 
\begin{cases}
1,~\text{with probability}~\frac{1}{2}+ 2^{-i},\\
-1,~\text{with probability}~\frac{1}{2}-2^{-i}.
\end{cases}
 \lim_{n\rightarrow \infty}\mathbb{P}[X_1+\dots+X_n > 0]\neq 1 X_i 1","['probability', 'random-variables']"
40,Negative moment of the number of arrivals in a renewal process,Negative moment of the number of arrivals in a renewal process,,"Suppose $\{X_1, \ldots, X_n,\ldots\}$ are i.i.d. non-negative random variables with $\mathbb{E}[X_1]= \mu <\infty$ , and $N(t):= \sup\{k: \sum_{i=1}^k X_i < t\}$ . Notice that $X_i$ may not have higher order moments. The classical renewal theorem tells us $$ \frac{\mathbb{E}[N(t)]}{t}\rightarrow \frac{1}{\mu} $$ as $t\to \infty$ . I am interested in whether: $$ \mathbb{E}\left[\frac{t}{\max\{N(t),1\}}\right]\to \mu. $$ as $t\to \infty$ ? Or at least is $$ \limsup_{t\to \infty}    \mathbb{E}\left[\frac{t}{\max\{N(t),1\}}\right] \leq C\mu $$ for some constant $C$ ? (From Jensen's inequality one can easily see $ \liminf_{t\rightarrow\infty } \mathbb{E}[\frac{t}{N(t)}]\geq \mu.) $ Thanks!","Suppose are i.i.d. non-negative random variables with , and . Notice that may not have higher order moments. The classical renewal theorem tells us as . I am interested in whether: as ? Or at least is for some constant ? (From Jensen's inequality one can easily see Thanks!","\{X_1, \ldots, X_n,\ldots\} \mathbb{E}[X_1]= \mu <\infty N(t):= \sup\{k: \sum_{i=1}^k X_i < t\} X_i 
\frac{\mathbb{E}[N(t)]}{t}\rightarrow \frac{1}{\mu}
 t\to \infty 
\mathbb{E}\left[\frac{t}{\max\{N(t),1\}}\right]\to \mu.
 t\to \infty 
\limsup_{t\to \infty}
   \mathbb{E}\left[\frac{t}{\max\{N(t),1\}}\right]
\leq C\mu
 C 
\liminf_{t\rightarrow\infty } \mathbb{E}[\frac{t}{N(t)}]\geq \mu.)
","['probability', 'probability-theory', 'stochastic-processes', 'renewal-processes']"
41,maximal number of independent subsets (bitstrings with uniform distribution)?,maximal number of independent subsets (bitstrings with uniform distribution)?,,"Let $B=\{0,1\}^n$ be the set of length $n$ bit-strings with the uniform distribution, and let $\mathcal{F}=\{f:B\to \{0,1\}\}$ be the set of all binary functions on $B$ . What is the maximal size of an independent collection of functions from $\mathcal{F}$ ?  I.e., what is the largest $N$ such that there exist $f_i\in\mathcal{F}$ with $$ \mathbb{P}(f_i=\epsilon_i, i\in I)=\prod_{i\in I}\mathbb{P}(f_i=\epsilon_i) $$ for all choices $\epsilon_i\in\{0,1\}$ and subsets $I\subseteq\{1,\ldots, N\}$ ? I guess this is equivalent to asking for the maximal number of independent subsets of $B$ , i.e. what is the largest number $N$ such that there exist $A_i\subseteq B$ with $$ \mathbb{P}\left(\bigcap_{i\in I}A_i\right)=\prod_{i\in I}\mathbb{P}(A_i), $$ for all $I\subseteq\{1,\ldots, N\}$ , where $\mathbb{P}(A)=|A|/2^n$ ? I don't see any way to count these off the top of my head, although there are maybe some obvious sets of independent functions (e.g. the coordinate functionals).  Perhaps this is the best one can do, the intuition being "" $n$ independent bits $\Leftrightarrow$ $n$ independent subsets""? (Disregarding the ""trivial"" events $\emptyset$ , $B$ , corresponding to constant functions.) The paper Independent Events in a Discrete Uniform Probability Space considers the problem more generally, with the uniform distribution on finite sets. Theorem 5 there backs up the ""intuitive"" answer $N=n$ to my question (ignoring constant functions/(co)null sets).","Let be the set of length bit-strings with the uniform distribution, and let be the set of all binary functions on . What is the maximal size of an independent collection of functions from ?  I.e., what is the largest such that there exist with for all choices and subsets ? I guess this is equivalent to asking for the maximal number of independent subsets of , i.e. what is the largest number such that there exist with for all , where ? I don't see any way to count these off the top of my head, although there are maybe some obvious sets of independent functions (e.g. the coordinate functionals).  Perhaps this is the best one can do, the intuition being "" independent bits independent subsets""? (Disregarding the ""trivial"" events , , corresponding to constant functions.) The paper Independent Events in a Discrete Uniform Probability Space considers the problem more generally, with the uniform distribution on finite sets. Theorem 5 there backs up the ""intuitive"" answer to my question (ignoring constant functions/(co)null sets).","B=\{0,1\}^n n \mathcal{F}=\{f:B\to \{0,1\}\} B \mathcal{F} N f_i\in\mathcal{F} 
\mathbb{P}(f_i=\epsilon_i, i\in I)=\prod_{i\in I}\mathbb{P}(f_i=\epsilon_i)
 \epsilon_i\in\{0,1\} I\subseteq\{1,\ldots, N\} B N A_i\subseteq B 
\mathbb{P}\left(\bigcap_{i\in I}A_i\right)=\prod_{i\in I}\mathbb{P}(A_i),
 I\subseteq\{1,\ldots, N\} \mathbb{P}(A)=|A|/2^n n \Leftrightarrow n \emptyset B N=n","['probability', 'combinatorics', 'reference-request', 'combinatorial-designs']"
42,Probability that a pencil is blunt,Probability that a pencil is blunt,,"Suppose a student has $n$ pencils, each of them sharpened. He has his final exams lined up. Each day, before the exam, he randomly chooses a pencil to write the test. What is the probability that on the $k$ -th day, the pencil he picks up is (still) sharp? Note that once a pencil is used, it becomes blunt and a blunt pencil is never re-sharpened. The answer that's given is $\left(1-\frac{1}{n}\right)^{k-1}$ . My understanding is that if $P(k)$ is the probability that the pencil chosen on the $k$ th day is sharp: Then, $P(k=1) = 1$ since every pencil is sharp. For $k>1,$ $\displaystyle P(k) = \sum_{i=1}^{k-1} \frac{n-i}{n}$ since we can have $i=1,2, \cdots k-1$ blunt pencils. But this is clearly wrong as probability can not exceed $1$ which it does here. Questions: Where did I go wrong? I see the recursion $P(k) = P(k-1) \left(1-\frac{1}{n}\right)$ which may be of use. Can I solve it using this recursion?","Suppose a student has pencils, each of them sharpened. He has his final exams lined up. Each day, before the exam, he randomly chooses a pencil to write the test. What is the probability that on the -th day, the pencil he picks up is (still) sharp? Note that once a pencil is used, it becomes blunt and a blunt pencil is never re-sharpened. The answer that's given is . My understanding is that if is the probability that the pencil chosen on the th day is sharp: Then, since every pencil is sharp. For since we can have blunt pencils. But this is clearly wrong as probability can not exceed which it does here. Questions: Where did I go wrong? I see the recursion which may be of use. Can I solve it using this recursion?","n k \left(1-\frac{1}{n}\right)^{k-1} P(k) k P(k=1) = 1 k>1, \displaystyle P(k) = \sum_{i=1}^{k-1} \frac{n-i}{n} i=1,2, \cdots k-1 1 P(k) = P(k-1) \left(1-\frac{1}{n}\right)","['probability', 'combinatorics', 'discrete-mathematics']"
43,Permuted Hamming distance,Permuted Hamming distance,,"Suppose Alice wants to send a message to Bob, they agree on a $n$ letters alphabet $\Omega = \{a_1, \cdots, a_n\}$ and they both agree on a shared secret $\omega=\omega_1 \cdots \omega_m$ $\omega_i \in \Omega \,\forall i$ that must be sent before the message. Unfortunately, Bob forgets the encoding of $\Omega$ and is only able to decode a message over a permuted alphabet $\sigma(\Omega) = \{\sigma(a_1), \cdots, \sigma(a_n)\}$ where $\sigma$ is a permutation of $\Omega$ . If e.g. $\Omega$ are bits, it means that 0 and 1 could be flipped or not. Suppose Alice wants to prove her identity to Bob, so she sends their shared secret $\omega$ to Bob, so Bob will decode the message $m := \sigma(\omega) = \sigma(\omega_1) \cdots \sigma (\omega_n)$ . Bob will accept the message iff there exists a permutation $\tau$ s.t. $\tau (m) = \omega$ . Now suppose that the channel over which Bob receives messages is noisy, Bob wants to know how close a message is close to a secret, so he computes: $$ d_H^S (m,\omega) := \min_{\tau} \left(d_H (\tau(m), \omega)= \sum_i d_H(\tau(m_i), \omega_i)\right)  $$ and accept the message iff $d_H^S (m,\omega)$ is smaller than some threshold $C$ . As an example if $\Omega=\{0,1\}$ , $d_H^S(00,11) = 0$ (bits are flipped) while $d_H^S(00,10) = 1$ (whether or not bits are flipped, distance is one). Now suppose Charlie wants to fake the identity of Alice, he then sends random messages to Bob. To compute the threshold $C$ , the natural question emerges: Question: What could be the average value of $d_H^S (a,b)$ between two random words $a$ and $b$ of $n$ letters?","Suppose Alice wants to send a message to Bob, they agree on a letters alphabet and they both agree on a shared secret that must be sent before the message. Unfortunately, Bob forgets the encoding of and is only able to decode a message over a permuted alphabet where is a permutation of . If e.g. are bits, it means that 0 and 1 could be flipped or not. Suppose Alice wants to prove her identity to Bob, so she sends their shared secret to Bob, so Bob will decode the message . Bob will accept the message iff there exists a permutation s.t. . Now suppose that the channel over which Bob receives messages is noisy, Bob wants to know how close a message is close to a secret, so he computes: and accept the message iff is smaller than some threshold . As an example if , (bits are flipped) while (whether or not bits are flipped, distance is one). Now suppose Charlie wants to fake the identity of Alice, he then sends random messages to Bob. To compute the threshold , the natural question emerges: Question: What could be the average value of between two random words and of letters?","n \Omega = \{a_1, \cdots, a_n\} \omega=\omega_1 \cdots \omega_m \omega_i \in \Omega \,\forall i \Omega \sigma(\Omega) = \{\sigma(a_1), \cdots, \sigma(a_n)\} \sigma \Omega \Omega \omega m := \sigma(\omega) = \sigma(\omega_1) \cdots \sigma (\omega_n) \tau \tau (m) = \omega 
d_H^S (m,\omega) := \min_{\tau} \left(d_H (\tau(m), \omega)= \sum_i d_H(\tau(m_i), \omega_i)\right) 
 d_H^S (m,\omega) C \Omega=\{0,1\} d_H^S(00,11) = 0 d_H^S(00,10) = 1 C d_H^S (a,b) a b n","['probability', 'discrete-mathematics', 'information-theory', 'cryptography']"
44,Sampling distribution with intelligence quotient,Sampling distribution with intelligence quotient,,The Intelligence Quotient of adults follows normal distribution with mean $m = 100$ and standard deviation $σ = 10$ . Consider a sample of 27 adults and calculate the probability for the IQ of the sample to be less than 98. What I've tried so far: $Z = \frac{\bar X - m}{σ/\sqrt{n}} = \frac{98 - 100}{19.245} = 0.1039$ . So from z-score tables the required probability is $0.555$ . I don't know if it's correct and I also need some explanation on what exactly we compute by this. I am very new to statistics and distributions. Thank you.,The Intelligence Quotient of adults follows normal distribution with mean and standard deviation . Consider a sample of 27 adults and calculate the probability for the IQ of the sample to be less than 98. What I've tried so far: . So from z-score tables the required probability is . I don't know if it's correct and I also need some explanation on what exactly we compute by this. I am very new to statistics and distributions. Thank you.,m = 100 σ = 10 Z = \frac{\bar X - m}{σ/\sqrt{n}} = \frac{98 - 100}{19.245} = 0.1039 0.555,"['probability', 'statistics', 'normal-distribution']"
45,Question on Chernoff bound type probability argument.,Question on Chernoff bound type probability argument.,,"The following result was given in the research article ( claim 6 ) and no justification was provided for the proof. I have presented the claim in simple terms below. Basically, I want to understand what theorems were used and how to prove the following two (To prove) parts. We have two devices $\mathscr{A}$ and $\mathscr{B}$ far apart. $\mathscr{A}$ takes input $x_i \in \{0,1,2\}$ and $\mathscr{B}$ takes input $y_i \in \{0,1\}$ . They both give random outputs $a_i, b_i \in \{0,1\}$ respectively for $i$ th input. Uniformly $m$ random input pairs are selected $$I=\{ (x_i,y_i) \mid x_i \in \{0,1,2\}, y_i \in \{0,1\} \text{ for } 1\leq i \leq m\}$$ and outputs are collected in the set $\mathbb{O}$ . Let $C$ denotes the set of inputs such that $(x_i,y_i) = (2,1)$ i.e., $C=\{ (x_i,y_i) \mid x_i = 2, y_i = 1 \}$ . At random for $0 < \gamma <1$ , a total of $\gamma m$ $\in \mathbb{N}$ inputs are selected from $I$ . Lets denote this set as $B$ . To Prove 1: The randomly chosen set $B$ contains a fraction of at least $\gamma /2$ fractions from the elements of the set $C$ , except with probability at most $e^{- \gamma |C| /8}$ . Let $C_B$ denotes the elements of $C$ in the set $B$ . If for $C_B$ the outputs satisfies $a_i \neq b_i$ for at most $\eta$ fractions of times. Then To Prove 2: With probability at least $1-e^{- \gamma |C| /200}$ the total fraction of rounds in $C$ such that $a_i \neq b_i$ is at most $1.1 \eta$ .","The following result was given in the research article ( claim 6 ) and no justification was provided for the proof. I have presented the claim in simple terms below. Basically, I want to understand what theorems were used and how to prove the following two (To prove) parts. We have two devices and far apart. takes input and takes input . They both give random outputs respectively for th input. Uniformly random input pairs are selected and outputs are collected in the set . Let denotes the set of inputs such that i.e., . At random for , a total of inputs are selected from . Lets denote this set as . To Prove 1: The randomly chosen set contains a fraction of at least fractions from the elements of the set , except with probability at most . Let denotes the elements of in the set . If for the outputs satisfies for at most fractions of times. Then To Prove 2: With probability at least the total fraction of rounds in such that is at most .","\mathscr{A} \mathscr{B} \mathscr{A} x_i \in \{0,1,2\} \mathscr{B} y_i \in \{0,1\} a_i, b_i \in \{0,1\} i m I=\{ (x_i,y_i) \mid x_i \in \{0,1,2\}, y_i \in \{0,1\} \text{ for } 1\leq i \leq m\} \mathbb{O} C (x_i,y_i) = (2,1) C=\{ (x_i,y_i) \mid x_i = 2, y_i = 1 \} 0 < \gamma <1 \gamma m \in \mathbb{N} I B B \gamma /2 C e^{- \gamma |C| /8} C_B C B C_B a_i \neq b_i \eta 1-e^{- \gamma |C| /200} C a_i \neq b_i 1.1 \eta","['probability', 'statistics', 'cryptography']"
46,The conditions for $\lim_{x\to\infty}{g(x)\bar{F}(x)}=0$,The conditions for,\lim_{x\to\infty}{g(x)\bar{F}(x)}=0,"Let $X$ be a nonnegative random variable with distribution $F$ , and $g$ is a continuous function such that $E[g(X)]< \infty$ . Is $$ \lim_{x\to\infty}{g(x)\bar{F}(x)} = 0 $$ always true, where $\bar{F}(x) = 1-F(x)$ is the survival function? If not, what other conditions should $g$ have?","Let be a nonnegative random variable with distribution , and is a continuous function such that . Is always true, where is the survival function? If not, what other conditions should have?","X F g E[g(X)]< \infty 
\lim_{x\to\infty}{g(x)\bar{F}(x)} = 0
 \bar{F}(x) = 1-F(x) g","['probability', 'probability-theory', 'measure-theory']"
47,"$\limsup \frac{X_n}{a_n}=1 \Leftrightarrow \limsup \frac{\max\{X_1,...,X_n\}}{a_n}=1$",,"\limsup \frac{X_n}{a_n}=1 \Leftrightarrow \limsup \frac{\max\{X_1,...,X_n\}}{a_n}=1","$\{X_n\}_{n=1}^\infty$ is non-negative random variables, $0\leq a_n \uparrow\infty$ . Then: \begin{equation} \limsup \frac{X_n}{a_n}=1 \quad a.s.\Leftrightarrow \limsup \frac{\max\{X_1,...,X_n\}}{a_n}=1 \quad a.s. \end{equation} My ideas so far: Since $X_n$ and $a_n$ are non-negative, we have: \begin{equation} 0\leq \frac{X_n}{a_n}\leq \frac{\max\{X_1,...,X_n\}}{a_n} \end{equation} So, if $\limsup \frac{\max\{X_1,...,X_n\}}{a_n}=1$ , then $\limsup\frac{X_n}{a_n}\leq 1.$ But I cannot going on to prove $\limsup\frac{X_n}{a_n}\geq 1.$ Thanks in advance for any help!","is non-negative random variables, . Then: My ideas so far: Since and are non-negative, we have: So, if , then But I cannot going on to prove Thanks in advance for any help!","\{X_n\}_{n=1}^\infty 0\leq a_n \uparrow\infty \begin{equation}
\limsup \frac{X_n}{a_n}=1 \quad a.s.\Leftrightarrow \limsup \frac{\max\{X_1,...,X_n\}}{a_n}=1 \quad a.s.
\end{equation} X_n a_n \begin{equation}
0\leq \frac{X_n}{a_n}\leq \frac{\max\{X_1,...,X_n\}}{a_n}
\end{equation} \limsup \frac{\max\{X_1,...,X_n\}}{a_n}=1 \limsup\frac{X_n}{a_n}\leq 1. \limsup\frac{X_n}{a_n}\geq 1.","['real-analysis', 'probability', 'sequences-and-series', 'probability-theory']"
48,Alternative strategy to choose the largest random number,Alternative strategy to choose the largest random number,,"I want to discuss a strategy to determine what is the largest number of a random sample. Suppose that we generate a random sample of $n$ distinct numbers from $0$ to $1$ according to a uniform distribution. The sample generated will be labeled as $I = \{d_1,...,d_n\}$ where $0\leq d_1 < d_2 < ... < d_n\leq 1$ (I have sorted the sample for simplicity). Let us randomly shuffle the sample. This would give us a particular permutation of $I$ that I will label as $$ S = \{z_1,z_2,...,z_n\} $$ Each of the elements $z_i$ is shown one by one to a person who has to decide whether $z_i$ is the maximum of the whole sample. If this person chooses $z_i$ as the maximum and they are right, they win, otherwise, they lose. If this person doesn't choose $z_i$ , then they need to make a decision about $z_{i+1}$ . They can accept $z_{i+1}$ as the maximum, and check if they win, or they refuse $z_{i+1}$ and check $z_{i+2}$ and so on. I want to test the following strategy to make a decision. Notice that I am not sure if the following strategy is optimal in any sense (and I don't care at this point). Assume that we refuse the first $k-1$ elements. If the $k$ -th element $z_k$ is greater than all the others drawn so far, we consider $z_k$ as a candidate for the maximum. If $z_k$ is a candidate, the probability that the next $n-k$ elements are smaller than $z_k$ is $z_k^{n-k}$ . I decide the element $z_k$ is the maximum if $z_k^{n-k}\geq r$ for some cut-off $r$ that maximizes the probability of winning the game under such strategy. Ultimately, I want then to find the value of such cut-off $r$ . Let me define the following events $$ A_k : z_k = d_n \\ B_k: z_k^{n-k}\geq r\, \cap\,z_k > z_i \forall i = 1,..,k-1  $$ I think that the probability of winning under these conditions is $$ P(r) = \sum_{k=1}^{n}p(B_k)p(A_k|B_k)\,. $$ Question: Is the expression for $P(r)$ right? By means of the Bayes theorem, $P(r)$ takes the form $$ P(r) =\sum_{k=1}^{n}p(A_k)p(B_k|A_k)\,. $$ Now, $$p(A_k)= 1/n$$ and $P(B_k|A_k)$ is simply the probability that $d_n^{n-k}\geq r$ , since $d_n > z_i \forall i = 1,..,k-1 $ is always true, therefore $$ P(B_k|A_k) = (1-r^\frac{1}{n-k}) $$ and therefore I get $$ P(r) = \sum_{k=1}^{n}\frac{1}{n}(1-r^\frac{1}{n-k}) $$ However, this cannot be correct. For $r=0$ , this last equation says that $P(0)=1$ , which is really wrong. I have the feeling I have messed around with the formulae and fundamental concepts of probability. Can anyone help me? EDIT I have implemented this strategy numerically on Mathematica for $n=100$ . Look at the following code checkStrategy[r_, n_] := Module[{win = 0, loss = 0, list, max, k, i},   For[i = 1, i <= 1000, i++,    list = RandomSample[Range[10 n], n]/(10 n) // N;    max = Max[list];    For[k = 1, k <= n, k++,     If[list[[k]]^(n - k) >= r && list[[k]] > Max[list[[1 ;; k - 1]]],       If[list[[k]] == max, win = win + 1; k = n + 1, k = n + 1];]     ];    ];   loss = 1000 - win;   Return[{r, win/(win + loss), loss/(win + loss)} // N]]  SeedRandom[42]; points = Table[checkStrategy[s, 100], {s, 0, 0.99, 0.01}]; points[[All, 1 ;; 2]] // ListPlot which returns the following plot As you can see, the probability has a maximum for values of $r$ between 0.4 and 0.6. Notice that this is Problem 48 of the book ""Fifty Challenging Problems in Probability with Solutions"". In this book, the authors give a strategy whose probability of success is 0.58 at large $n$ (not so different from what I have found numerically).","I want to discuss a strategy to determine what is the largest number of a random sample. Suppose that we generate a random sample of distinct numbers from to according to a uniform distribution. The sample generated will be labeled as where (I have sorted the sample for simplicity). Let us randomly shuffle the sample. This would give us a particular permutation of that I will label as Each of the elements is shown one by one to a person who has to decide whether is the maximum of the whole sample. If this person chooses as the maximum and they are right, they win, otherwise, they lose. If this person doesn't choose , then they need to make a decision about . They can accept as the maximum, and check if they win, or they refuse and check and so on. I want to test the following strategy to make a decision. Notice that I am not sure if the following strategy is optimal in any sense (and I don't care at this point). Assume that we refuse the first elements. If the -th element is greater than all the others drawn so far, we consider as a candidate for the maximum. If is a candidate, the probability that the next elements are smaller than is . I decide the element is the maximum if for some cut-off that maximizes the probability of winning the game under such strategy. Ultimately, I want then to find the value of such cut-off . Let me define the following events I think that the probability of winning under these conditions is Question: Is the expression for right? By means of the Bayes theorem, takes the form Now, and is simply the probability that , since is always true, therefore and therefore I get However, this cannot be correct. For , this last equation says that , which is really wrong. I have the feeling I have messed around with the formulae and fundamental concepts of probability. Can anyone help me? EDIT I have implemented this strategy numerically on Mathematica for . Look at the following code checkStrategy[r_, n_] := Module[{win = 0, loss = 0, list, max, k, i},   For[i = 1, i <= 1000, i++,    list = RandomSample[Range[10 n], n]/(10 n) // N;    max = Max[list];    For[k = 1, k <= n, k++,     If[list[[k]]^(n - k) >= r && list[[k]] > Max[list[[1 ;; k - 1]]],       If[list[[k]] == max, win = win + 1; k = n + 1, k = n + 1];]     ];    ];   loss = 1000 - win;   Return[{r, win/(win + loss), loss/(win + loss)} // N]]  SeedRandom[42]; points = Table[checkStrategy[s, 100], {s, 0, 0.99, 0.01}]; points[[All, 1 ;; 2]] // ListPlot which returns the following plot As you can see, the probability has a maximum for values of between 0.4 and 0.6. Notice that this is Problem 48 of the book ""Fifty Challenging Problems in Probability with Solutions"". In this book, the authors give a strategy whose probability of success is 0.58 at large (not so different from what I have found numerically).","n 0 1 I = \{d_1,...,d_n\} 0\leq d_1 < d_2 < ... < d_n\leq 1 I 
S = \{z_1,z_2,...,z_n\}
 z_i z_i z_i z_i z_{i+1} z_{i+1} z_{i+1} z_{i+2} k-1 k z_k z_k z_k n-k z_k z_k^{n-k} z_k z_k^{n-k}\geq r r r 
A_k : z_k = d_n \\
B_k: z_k^{n-k}\geq r\, \cap\,z_k > z_i \forall i = 1,..,k-1 
 
P(r) = \sum_{k=1}^{n}p(B_k)p(A_k|B_k)\,.
 P(r) P(r) 
P(r) =\sum_{k=1}^{n}p(A_k)p(B_k|A_k)\,.
 p(A_k)= 1/n P(B_k|A_k) d_n^{n-k}\geq r d_n > z_i \forall i = 1,..,k-1  
P(B_k|A_k) = (1-r^\frac{1}{n-k})
 
P(r) = \sum_{k=1}^{n}\frac{1}{n}(1-r^\frac{1}{n-k})
 r=0 P(0)=1 n=100 r n","['probability', 'probability-theory', 'conditional-probability']"
49,Every boolean function is multiplicative with probability greater than $1/2$,Every boolean function is multiplicative with probability greater than,1/2,"Let $f:\left\{-1,1\right\}^n\to\left\{-1,1\right\}$ . How to show that $$ P_{{x,y,z}} \{f(xyz)=f(x)f(y)f(z)\} \ge 1/2? $$ where $x,y,z$ are distributed uniformly and independently on $\left\{-1,1\right\}^n$ . Equivalently, the set $$ \{(x,y,z)\in (\left\{-1,1\right\}^n)^3 \,|\,f(xyz)=f(x)f(y)f(z)\} $$ has at least $2^n\times 2^n\times 2^{n-1}$ elements. I think there should be a simple argument that I am missing. Edit: I forgot to define: $$ (xy)_i:=x_iy_i, \,\,\, (xyz)_i:=x_iy_iz_i, $$ so the product is component-wise.","Let . How to show that where are distributed uniformly and independently on . Equivalently, the set has at least elements. I think there should be a simple argument that I am missing. Edit: I forgot to define: so the product is component-wise.","f:\left\{-1,1\right\}^n\to\left\{-1,1\right\} 
P_{{x,y,z}} \{f(xyz)=f(x)f(y)f(z)\} \ge 1/2?
 x,y,z \left\{-1,1\right\}^n 
\{(x,y,z)\in (\left\{-1,1\right\}^n)^3 \,|\,f(xyz)=f(x)f(y)f(z)\}
 2^n\times 2^n\times 2^{n-1} 
(xy)_i:=x_iy_i, \,\,\, (xyz)_i:=x_iy_iz_i,
","['probability', 'combinatorics', 'discrete-mathematics', 'computer-science', 'boolean-algebra']"
50,A problem with two shuffled decks of cards and the expectation value,A problem with two shuffled decks of cards and the expectation value,,"I found this problem while preparing for interviews. The same problem is asked here . You have two decks of (52) distinct cards. You shuffle each deck. Now you keep drawing the top card from each of the two decks and you compare the two top cards. If they are the same card, you get one point. Otherwise, you get zero points. You then throw the two cards away (so there is no repetition). You keep drawing cards until both decks are exhausted (so 52 times in total). What is the expected number of points you receive? I have an idea on how to approach this and it would be great to get some feedback and/or alternative ideas. I draw one card for the left deck and I ask what's the probability that the card drawn from the right deck matches. I define $X_i$ the random variable that for the $i$ -th draw is equal to 1 if the cards are the same and 0 otherwise. The total number of points is therefore $N=\sum_{i=1}^{52} X_i$ , with $E[N]=\sum_{i=1}^{52} E[X_i]$ . Now I could use the fact that for the expectation value $E[X_i]$ it holds that $E[X_i]=\sum P(Y_i)E[X_i|Y_i]$ , where $Y_i$ is the random variable associated to the event that the matching card is present in the right deck at the $i$ -th draw. The probability $P(Y_i)$ is $\frac{53-i}{52}$ and we have that $E[X_i|Y_i]=\frac{1}{53-i}\cdot 1$ , being $\frac{1}{53-i}$ the probability to draw the same card from the right deck at the $i$ -th draw. Therefore $E[X_i]=\frac{53-i}{52}\cdot \frac{1}{53-i}=\frac{1}{52}$ . The requested expected number of points is then $E[N]=\sum_{i=1}^{52}\frac{1}{52}=1$ . Many thanks for any comments.","I found this problem while preparing for interviews. The same problem is asked here . You have two decks of (52) distinct cards. You shuffle each deck. Now you keep drawing the top card from each of the two decks and you compare the two top cards. If they are the same card, you get one point. Otherwise, you get zero points. You then throw the two cards away (so there is no repetition). You keep drawing cards until both decks are exhausted (so 52 times in total). What is the expected number of points you receive? I have an idea on how to approach this and it would be great to get some feedback and/or alternative ideas. I draw one card for the left deck and I ask what's the probability that the card drawn from the right deck matches. I define the random variable that for the -th draw is equal to 1 if the cards are the same and 0 otherwise. The total number of points is therefore , with . Now I could use the fact that for the expectation value it holds that , where is the random variable associated to the event that the matching card is present in the right deck at the -th draw. The probability is and we have that , being the probability to draw the same card from the right deck at the -th draw. Therefore . The requested expected number of points is then . Many thanks for any comments.",X_i i N=\sum_{i=1}^{52} X_i E[N]=\sum_{i=1}^{52} E[X_i] E[X_i] E[X_i]=\sum P(Y_i)E[X_i|Y_i] Y_i i P(Y_i) \frac{53-i}{52} E[X_i|Y_i]=\frac{1}{53-i}\cdot 1 \frac{1}{53-i} i E[X_i]=\frac{53-i}{52}\cdot \frac{1}{53-i}=\frac{1}{52} E[N]=\sum_{i=1}^{52}\frac{1}{52}=1,"['probability', 'solution-verification']"
51,Confusion about curved exponential family in Casella & Berger,Confusion about curved exponential family in Casella & Berger,,"In Definition 3.4.7 of Statistical Inference by Casella & Berger, 2nd ed., a curved exponential family is defined to be a family of the form $$ f(x \vert \boldsymbol\theta) = h(x)c(\boldsymbol\theta)\exp\left(\sum_{i=1}^{k}w_i(\boldsymbol\theta)t_i(x)\right) $$ for which the dimension of the vector $\boldsymbol\theta$ is equal to $d<k$ . A normal $n(\theta, \theta)$ (i.e. mean and variance are both $\theta$ ) is used in problem 3.33 and in Example 3.4.9 as an example of a curved exponential family. But I'm having trouble seeing why this is a curved family. Since there is only one parameter, $d=1$ . Working out the form of the exponential family to which this belongs, I get $$ \frac{1}{\sqrt{2\pi\theta}}\exp\left(\frac{\theta}{2}\right)\exp(x)\exp\left(-\frac{x^2}{2\theta}\right) $$ so that $h(x) = \exp(x)$ , $c(\theta) = \frac{\exp\left(\frac{\theta}{2}\right)}{\sqrt{2\pi\theta}}$ , and $w_1(\theta) = -1/2\theta$ , $t_1(x) = x^2$ . In that case, $k=1$ . So we have a situation where $d=k$ , which does not meet the condition for a curved exponential family according to the above definition. I'm confused about why the text considers it a curved family in Example 3.4.9 and Exercise 3.33(a). Can anyone clarify this for me?","In Definition 3.4.7 of Statistical Inference by Casella & Berger, 2nd ed., a curved exponential family is defined to be a family of the form for which the dimension of the vector is equal to . A normal (i.e. mean and variance are both ) is used in problem 3.33 and in Example 3.4.9 as an example of a curved exponential family. But I'm having trouble seeing why this is a curved family. Since there is only one parameter, . Working out the form of the exponential family to which this belongs, I get so that , , and , . In that case, . So we have a situation where , which does not meet the condition for a curved exponential family according to the above definition. I'm confused about why the text considers it a curved family in Example 3.4.9 and Exercise 3.33(a). Can anyone clarify this for me?","
f(x \vert \boldsymbol\theta) = h(x)c(\boldsymbol\theta)\exp\left(\sum_{i=1}^{k}w_i(\boldsymbol\theta)t_i(x)\right)
 \boldsymbol\theta d<k n(\theta, \theta) \theta d=1 
\frac{1}{\sqrt{2\pi\theta}}\exp\left(\frac{\theta}{2}\right)\exp(x)\exp\left(-\frac{x^2}{2\theta}\right)
 h(x) = \exp(x) c(\theta) = \frac{\exp\left(\frac{\theta}{2}\right)}{\sqrt{2\pi\theta}} w_1(\theta) = -1/2\theta t_1(x) = x^2 k=1 d=k","['probability', 'probability-distributions', 'statistical-inference']"
52,Why does this matrix multiplication converge? [Example of people averaging beliefs],Why does this matrix multiplication converge? [Example of people averaging beliefs],,"Converging to average I am pretty new to linear algebra and am working through a problem like this: There is a true value, $\theta=0$ Five people have initial guesses for $\theta$ that are drawn from a uniform distribution $[-1, 1]$ : At each round, people update their guess to an average of the other peoople's guesses I found that eventually all people converge to the average of the initial guesses. Matrix Notation W is a matrix representing the weights that person $i$ puts on person $j$ 's guess. $G_t$ represents the guesses of each individual at time $t$ . $G_t$ = $W^t \times G_0$ $$ W = \begin{pmatrix} 0.00 & 0.25 & 0.25 & 0.25 & 0.25 \\ 0.25 & 0.00 & 0.25 & 0.25 & 0.25 \\ 0.25 & 0.25 & 0.00 & 0.25 & 0.25 \\ 0.25 & 0.25 & 0.25 & 0.00 & 0.25 \\ 0.25 & 0.25 & 0.25 & 0.25 & 0.00 \\ \end{pmatrix} $$ $$  G_o = \begin{pmatrix} \hat{\theta_1}  \\ \hat{\theta_2} \\ \hat{\theta_3}   \\ \hat{\theta_4}  \\ \hat{\theta_5}  \\ \end{pmatrix} $$ For large $t$ , $W^t \times G_0$ approaches the average of the values in $G_0$ . Why is that? Simulation import numpy as np  import random   # True value  theta = 0  # Number of guessers n = 5  # Generate guesses around true value np.random.seed(seed=100) guesses = np.matrix(np.random.uniform(-1, 1, size=n))  # Weights mat = np.matrix([[1/(n-1) for x in range(1,n+1)]]*n) np.fill_diagonal(mat, 0)  # Update beliefs temp_guess = guesses.copy() for i in range(10000):     temp_guess = (np.matmul(mat, temp_guess.T)).T      print(""Final matrix"", temp_guess) print(""Average of initial guesses"", np.sum(guesses)/n)","Converging to average I am pretty new to linear algebra and am working through a problem like this: There is a true value, Five people have initial guesses for that are drawn from a uniform distribution : At each round, people update their guess to an average of the other peoople's guesses I found that eventually all people converge to the average of the initial guesses. Matrix Notation W is a matrix representing the weights that person puts on person 's guess. represents the guesses of each individual at time . = For large , approaches the average of the values in . Why is that? Simulation import numpy as np  import random   # True value  theta = 0  # Number of guessers n = 5  # Generate guesses around true value np.random.seed(seed=100) guesses = np.matrix(np.random.uniform(-1, 1, size=n))  # Weights mat = np.matrix([[1/(n-1) for x in range(1,n+1)]]*n) np.fill_diagonal(mat, 0)  # Update beliefs temp_guess = guesses.copy() for i in range(10000):     temp_guess = (np.matmul(mat, temp_guess.T)).T      print(""Final matrix"", temp_guess) print(""Average of initial guesses"", np.sum(guesses)/n)","\theta=0 \theta [-1, 1] i j G_t t G_t W^t \times G_0 
W = \begin{pmatrix}
0.00 & 0.25 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.00 & 0.25 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.00 & 0.25 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.00 & 0.25 \\
0.25 & 0.25 & 0.25 & 0.25 & 0.00 \\
\end{pmatrix}
  
G_o = \begin{pmatrix}
\hat{\theta_1}  \\
\hat{\theta_2} \\
\hat{\theta_3}   \\
\hat{\theta_4}  \\
\hat{\theta_5}  \\
\end{pmatrix}
 t W^t \times G_0 G_0","['linear-algebra', 'probability', 'markov-chains']"
53,How to fix a proof of $g\left( X_{n} \right) \rightarrow g\left(X\right)$ in probability?,How to fix a proof of  in probability?,g\left( X_{n} \right) \rightarrow g\left(X\right),"If $g$ is a continuous function and $X_{n}\rightarrow X$ in probability, where $X_{n}$ is a sequence of random variable, then $g\left( X_{n} \right) \rightarrow g\left(X\right)$ in probability. For a special case $X=c$ for a constant $c$ , I know how to prove it. Since $f$ is continuous at $c$ , given any $\epsilon>0$ , there exists $\delta>0$ s.t. $|f(X_n)-f(c)|\le \epsilon$ whenever $|X_n-c|\le \delta$ . Thus, $$P(|X_n-c|\le \delta)\le P(|f(X_n)-f(c)|\le \epsilon) $$ which implies $$P(|f(X_n)-f(c)|\ge \epsilon)\le P(|X_n-c|\le \delta)\to 0. $$ But how about a general case $X$ ? Can we fix this proof?","If is a continuous function and in probability, where is a sequence of random variable, then in probability. For a special case for a constant , I know how to prove it. Since is continuous at , given any , there exists s.t. whenever . Thus, which implies But how about a general case ? Can we fix this proof?","g X_{n}\rightarrow X X_{n} g\left( X_{n} \right) \rightarrow g\left(X\right) X=c c f c \epsilon>0 \delta>0 |f(X_n)-f(c)|\le \epsilon |X_n-c|\le \delta P(|X_n-c|\le \delta)\le P(|f(X_n)-f(c)|\le \epsilon)
 P(|f(X_n)-f(c)|\ge \epsilon)\le P(|X_n-c|\le \delta)\to 0.
 X","['probability', 'analysis']"
54,Martingales and Markov chain,Martingales and Markov chain,,"Let $(X_n)_{n\geq0}$ be a Markov chain in $ \mathbb{N}$ with following transition probabilities: $$P(k, k+1) = p_k = 1-P(k, k-1), k \geq 1, p_k \in (0,1) $$ $$P(0,1) = p_0 := 1$$ Let $q_k = 1-p_k$ . For which functions $f : \mathbb{N}  \rightarrow \mathbb{R}$ the process $(f(X_n))_{n\geq0}$ is a martingale (for natural filtration)? My reasoning: knowing $X_{n-1}$ we can move either to the right or to the left: $$\mathbb{E}[f(X_n)|\mathcal{F}_{n-1}]=f(X_{n-1}+1)p_{n-1}+f(X_{n-1}-1)(1-p_{n-1})$$ At the same time we want $(f(X_n))_{n\geq0}$ to be a martingale: $$\mathbb{E}[f(X_n)|\mathcal{F}_{n-1}] = f(X_{n-1})$$ Thus we want to solve a functional equation: $\forall k \in \mathbb{N} , \forall p \in (0,1)$ $$f(k+1)p+f(k-1)(1-p)=f(k)$$ Am I right? If yes, it can be solved as $$f(k)=C_1+C_2(\frac{1-p}{p})^k, p\neq\frac{1}{2}$$ $$f(k) = C_1+C_2k, p=1/2$$ And we don't have any conditions to find $C_1, C_2$ . So what's the real solution?","Let be a Markov chain in with following transition probabilities: Let . For which functions the process is a martingale (for natural filtration)? My reasoning: knowing we can move either to the right or to the left: At the same time we want to be a martingale: Thus we want to solve a functional equation: Am I right? If yes, it can be solved as And we don't have any conditions to find . So what's the real solution?","(X_n)_{n\geq0}  \mathbb{N} P(k, k+1) = p_k = 1-P(k, k-1), k \geq 1, p_k \in (0,1)  P(0,1) = p_0 := 1 q_k = 1-p_k f : \mathbb{N}  \rightarrow \mathbb{R} (f(X_n))_{n\geq0} X_{n-1} \mathbb{E}[f(X_n)|\mathcal{F}_{n-1}]=f(X_{n-1}+1)p_{n-1}+f(X_{n-1}-1)(1-p_{n-1}) (f(X_n))_{n\geq0} \mathbb{E}[f(X_n)|\mathcal{F}_{n-1}] = f(X_{n-1}) \forall k \in \mathbb{N} , \forall p \in (0,1) f(k+1)p+f(k-1)(1-p)=f(k) f(k)=C_1+C_2(\frac{1-p}{p})^k, p\neq\frac{1}{2} f(k) = C_1+C_2k, p=1/2 C_1, C_2","['probability', 'probability-theory', 'markov-chains', 'conditional-expectation', 'martingales']"
55,Counterexample to Jensen's Inequality when the convex function admits values in the extended real set,Counterexample to Jensen's Inequality when the convex function admits values in the extended real set,,"Let $(X,A,\mu)$ be a set, a $\sigma$ -algebra and a measure. Suppose that $\mu(X) = 1$ . Let $u : X \rightarrow {\mathbb{R}}$ and $f : \mathbb{R} \rightarrow \mathbb{R} \, \cup \, \{+\infty \} $ be an integrable function and a convex, lower semi-continous function respectively. Then $$\int_{X} f \circ u \, d\mu \geq f \left( \int_{X} u \, d\mu \right)$$ This is the version of Jensen's Inequality I'm working with (note that convex functions with values in $\mathbb{R} \cup {+\infty}$ are not automatically continous and that LSC is required in order to have the lower affine approximants required to prove the theorem). I'd like to find a counterexample to this inequality when $f$ is convex but not necessarily lower semi-continous. I expected it to be quite easy to find, but the fact that $E = \{ x \in \mathbb{R} | f(x) < +\infty \}$ has to be an interval and that $u(x)$ has to be in $E$ for almost every $x \in X$ for the left-hand side of the equation not to be $+\infty$ is kinda annoying!","Let be a set, a -algebra and a measure. Suppose that . Let and be an integrable function and a convex, lower semi-continous function respectively. Then This is the version of Jensen's Inequality I'm working with (note that convex functions with values in are not automatically continous and that LSC is required in order to have the lower affine approximants required to prove the theorem). I'd like to find a counterexample to this inequality when is convex but not necessarily lower semi-continous. I expected it to be quite easy to find, but the fact that has to be an interval and that has to be in for almost every for the left-hand side of the equation not to be is kinda annoying!","(X,A,\mu) \sigma \mu(X) = 1 u : X \rightarrow {\mathbb{R}} f : \mathbb{R} \rightarrow \mathbb{R} \, \cup \, \{+\infty \}  \int_{X} f \circ u \, d\mu \geq f \left( \int_{X} u \, d\mu \right) \mathbb{R} \cup {+\infty} f E = \{ x \in \mathbb{R} | f(x) < +\infty \} u(x) E x \in X +\infty","['probability', 'analysis', 'jensen-inequality']"
56,"Given an ergodic property that guarantees convergence of sample means to an expectation, how can I bound the Cesàro Mean of expectation of terms?","Given an ergodic property that guarantees convergence of sample means to an expectation, how can I bound the Cesàro Mean of expectation of terms?",,"I have a sequence of (not iid) random variables $\{E_{i}\}$ that converge in distribution (actually, in total variation) as well as in $\mathcal{L}^{2}$ to $E_{\infty}$ . For all nonnegative functions $f$ with $\mathbb{E}[f(E_{\infty})]<\infty$ , it's established that \begin{align} \lim_{T\rightarrow\infty}\frac{1}{T}\sum_{n=1}^{T}f(E_{n}) \overset{\mathrm{a.s.}}{=}\mathbb{E}[f(E_{\infty})]. \end{align} I would like to bound (again for a nonnegative $f$ ) \begin{align} \underset{T\rightarrow\infty}{\lim\sup}\text{ }\frac{1}{T}\sum_{n=1}^{T}\mathbb{E}[f(E_{n})]. \end{align} In my particular case, I've been unable to uniformly bound the random variables $f(E_{i})$ , so I cannot use, for example, the reverse Fatou's Lemma to interchange the limit and expectation to show something like $\underset{T\rightarrow\infty}{\lim\sup}\text{ }\mathbb{E}[\frac{1}{T}\sum_{n=1}^{T}f(E_{n})] \le \mathbb{E}[\underset{T\rightarrow\infty}{\lim\sup}\text{ }\frac{1}{T}\sum_{n=1}^{T}f(E_{n})]$ . Does anyone have any advice for how I could try to proceed-- in particular ideas for how to interchange the limit and expectation without some kind of uniform bound? The thing is that I don't much about the function $f$ . I do know some potentially relevant facts. I can prove that $\mathbb{E}[f(E_{n})]$ is always finite.","I have a sequence of (not iid) random variables that converge in distribution (actually, in total variation) as well as in to . For all nonnegative functions with , it's established that I would like to bound (again for a nonnegative ) In my particular case, I've been unable to uniformly bound the random variables , so I cannot use, for example, the reverse Fatou's Lemma to interchange the limit and expectation to show something like . Does anyone have any advice for how I could try to proceed-- in particular ideas for how to interchange the limit and expectation without some kind of uniform bound? The thing is that I don't much about the function . I do know some potentially relevant facts. I can prove that is always finite.","\{E_{i}\} \mathcal{L}^{2} E_{\infty} f \mathbb{E}[f(E_{\infty})]<\infty \begin{align}
\lim_{T\rightarrow\infty}\frac{1}{T}\sum_{n=1}^{T}f(E_{n}) \overset{\mathrm{a.s.}}{=}\mathbb{E}[f(E_{\infty})].
\end{align} f \begin{align}
\underset{T\rightarrow\infty}{\lim\sup}\text{ }\frac{1}{T}\sum_{n=1}^{T}\mathbb{E}[f(E_{n})].
\end{align} f(E_{i}) \underset{T\rightarrow\infty}{\lim\sup}\text{ }\mathbb{E}[\frac{1}{T}\sum_{n=1}^{T}f(E_{n})] \le \mathbb{E}[\underset{T\rightarrow\infty}{\lim\sup}\text{ }\frac{1}{T}\sum_{n=1}^{T}f(E_{n})] f \mathbb{E}[f(E_{n})]","['probability', 'probability-theory', 'measure-theory', 'ergodic-theory', 'probability-limit-theorems']"
57,Product measure and its marginals,Product measure and its marginals,,"I have this question that's bothering me. The answer (I think) should be trivial but I am new in measure theory. Let $m$ be Radon measure on a compact product space $\Omega=X\times X$ such that $m$ is symmetric (I guess this means that $m(dx,dy)=m(dy,dx)$ and let $\lambda$ be a symmetric strictly positive function $\lambda:X\times X \rightarrow \mathbb{R}$ . The question is the following: does it always exist a measure $\mu$ defined on $X$ such that $$\mu(dx)\mu(dy)= c\frac{m(dx,dy)}{\lambda(x,y)},$$ where $c$ is a positive constant? How do you find it? Is it possible to say that it is a probability measure? My immediate answer would be yes and $$\mu(dx)=\int \frac{m(\cdot,dy)}{\lambda(x,y)}$$ and it is a probability measure just because it can be rescalated (being $X$ a compact set) Am I wrong? If so, can you give me a counterexample? Thanks in advance","I have this question that's bothering me. The answer (I think) should be trivial but I am new in measure theory. Let be Radon measure on a compact product space such that is symmetric (I guess this means that and let be a symmetric strictly positive function . The question is the following: does it always exist a measure defined on such that where is a positive constant? How do you find it? Is it possible to say that it is a probability measure? My immediate answer would be yes and and it is a probability measure just because it can be rescalated (being a compact set) Am I wrong? If so, can you give me a counterexample? Thanks in advance","m \Omega=X\times X m m(dx,dy)=m(dy,dx) \lambda \lambda:X\times X \rightarrow \mathbb{R} \mu X \mu(dx)\mu(dy)= c\frac{m(dx,dy)}{\lambda(x,y)}, c \mu(dx)=\int \frac{m(\cdot,dy)}{\lambda(x,y)} X","['probability', 'measure-theory']"
58,Connection between the Gamma function and gamma distribution,Connection between the Gamma function and gamma distribution,,"The Gamma function is a generalization of the factorial ( $\Gamma(n)=(n-1)!$ ). It is also the normalizing constant for the Gamma distribution and this happens to be (when its rate parameter is $1$ ) the time of the $n$ -th event in a standard Poisson process (with rate $1$ ). Is there any connection between these two facts? Perhaps relating to the fact that if we switched the order of the events in the Poisson process, the time until the $n$ -th event wouldn't change?","The Gamma function is a generalization of the factorial ( ). It is also the normalizing constant for the Gamma distribution and this happens to be (when its rate parameter is ) the time of the -th event in a standard Poisson process (with rate ). Is there any connection between these two facts? Perhaps relating to the fact that if we switched the order of the events in the Poisson process, the time until the -th event wouldn't change?",\Gamma(n)=(n-1)! 1 n 1 n,"['probability', 'gamma-function', 'gamma-distribution']"
59,Poincare inequality for Poisson random variables,Poincare inequality for Poisson random variables,,"My question comes from exercise 3.21 in this monograph . Specifically, let $f$ be a real-valued function defined on the set of non-negative integers and denote its ""discrete derivative"" by $Df(x) = f(x+1)-f(x)$ . Let $X$ be a Poisson random variable with parameter $\mathbb E[X] = \mu$ . Prove that $$\mathrm{Var}(f(X)) \leq \mu\,\mathbb E\left[(Df(X))^2\right].$$ The hint is to use the Efron-Stein inequality and the infinite divisibility of the Poisson distribution. My attempt: the infinite divisibility of the Poisson distribution means that we can write $X := \sum_{i=1}^n X_i$ , where $X_i$ 's are i.i.d. with Poisson distribution $\mathrm{Poisson}(\mu/n)$ . However, I do not see how the Efron-Stein inequality (Theorem 3.1) $$\mathrm{Var}(f(X)) \leq \sum_{i=1}^n \mathbb{E}\left[\left(f(X) - \mathbb{E}^{(i)}f(X)\right)^2\right] $$ will lead us to the advertised inequality. Here the conditional expectation operator $\mathbb{E}^{(i)}$ means that we are taking the expectation of $f(X)$ with respect to $X_i$ (while keeping $X_1,\ldots,X_{i-1},X_{i+1},\ldots,X_n$ fixed). Any help will be greatly appreciated!","My question comes from exercise 3.21 in this monograph . Specifically, let be a real-valued function defined on the set of non-negative integers and denote its ""discrete derivative"" by . Let be a Poisson random variable with parameter . Prove that The hint is to use the Efron-Stein inequality and the infinite divisibility of the Poisson distribution. My attempt: the infinite divisibility of the Poisson distribution means that we can write , where 's are i.i.d. with Poisson distribution . However, I do not see how the Efron-Stein inequality (Theorem 3.1) will lead us to the advertised inequality. Here the conditional expectation operator means that we are taking the expectation of with respect to (while keeping fixed). Any help will be greatly appreciated!","f Df(x) = f(x+1)-f(x) X \mathbb E[X] = \mu \mathrm{Var}(f(X)) \leq \mu\,\mathbb E\left[(Df(X))^2\right]. X := \sum_{i=1}^n X_i X_i \mathrm{Poisson}(\mu/n) \mathrm{Var}(f(X)) \leq \sum_{i=1}^n \mathbb{E}\left[\left(f(X) - \mathbb{E}^{(i)}f(X)\right)^2\right]  \mathbb{E}^{(i)} f(X) X_i X_1,\ldots,X_{i-1},X_{i+1},\ldots,X_n","['probability', 'inequality', 'poisson-distribution']"
60,What is the probability that all faces have appeared in some order in some six consecutive rolls?,What is the probability that all faces have appeared in some order in some six consecutive rolls?,,We roll a 6-sided die n times. What is the probability that all faces have appeared in some order in some six consecutive rolls? Is there a way to do this without resorting to markov chains?,We roll a 6-sided die n times. What is the probability that all faces have appeared in some order in some six consecutive rolls? Is there a way to do this without resorting to markov chains?,,"['probability', 'probability-theory', 'dice']"
61,A combinatorics problem with applications for optimizing Huffman Compression Algorithms,A combinatorics problem with applications for optimizing Huffman Compression Algorithms,,"I am currently working on a Huffman data compression algorithm and struck a problem when trying to optimize space-efficiency by changing the set of symbols the algorithm uses. I will give more context, but if you only care about the mathematical problem itself, skip this next section. Context I found that given a file and a complete set of symbols, it seems that making an algorithm that takes the set of symbols and the file and spits out what the exact compressed file size would be when pushed through the Huffman Compression algorithm cannot be done without actually putting the file through the Huffman Compression algorithm itself or by just giving a rough estimation that is closer to a guess than anything else. This would not be a problem if for a complete sets of symbols, running the program did not take hours for a 100Mb file. The problem comes down to that to have a time-efficient algorithm, you cannot guarantee be sure that it is very space-efficient. However, it is certain that the most space-efficient algorithm will be very time-inefficient relative to the time-efficient algorithm. One solution to this trade-off is to make this algorithm pick a complete set of symbols such that it produces the most space-efficient algorithm for a file its size on average . Since this calculation of probability is relatively short, this gives a relatively time-efficient algorithm that produces a more optimized Huffman compression on average. I have found a way to describe this calculation step in a mathematical way, but I am struggling with finding its solution. Here is the problem: Let S be a set of y unique symbols. Let b be a random sequence of symbols from S that is x symbols long such that x $\ge$ y. (symbols can repeat in b) Finally, let T be the set of unique symbols used in b. Given x and y, what is the probability that the number of elements in T is less than some z $\in \mathbb{Z}$ , y $\ge$ z $\ge$ 2. Simple Example It could be that S has 3 unique symbols and b is 3 characters long. For argument sake, lets say that S = {A, B, C}. If we were to ask what is the probability that the number of unique symbols used in b is 1 then either b = AAA, BBB, or CCC. Of course, there are 27 different 3-symbol long words we can made with S. Therefore, the probability that b consists of only 1 symbol from S is $\frac{1}{9}$ . In this case, z = 2 Final Remarks I have tried more complicated examples, but the difficulty of the combinatorics logic seems to grow very complicated very quick. Is there a general solution to this problem given x, y, z?","I am currently working on a Huffman data compression algorithm and struck a problem when trying to optimize space-efficiency by changing the set of symbols the algorithm uses. I will give more context, but if you only care about the mathematical problem itself, skip this next section. Context I found that given a file and a complete set of symbols, it seems that making an algorithm that takes the set of symbols and the file and spits out what the exact compressed file size would be when pushed through the Huffman Compression algorithm cannot be done without actually putting the file through the Huffman Compression algorithm itself or by just giving a rough estimation that is closer to a guess than anything else. This would not be a problem if for a complete sets of symbols, running the program did not take hours for a 100Mb file. The problem comes down to that to have a time-efficient algorithm, you cannot guarantee be sure that it is very space-efficient. However, it is certain that the most space-efficient algorithm will be very time-inefficient relative to the time-efficient algorithm. One solution to this trade-off is to make this algorithm pick a complete set of symbols such that it produces the most space-efficient algorithm for a file its size on average . Since this calculation of probability is relatively short, this gives a relatively time-efficient algorithm that produces a more optimized Huffman compression on average. I have found a way to describe this calculation step in a mathematical way, but I am struggling with finding its solution. Here is the problem: Let S be a set of y unique symbols. Let b be a random sequence of symbols from S that is x symbols long such that x y. (symbols can repeat in b) Finally, let T be the set of unique symbols used in b. Given x and y, what is the probability that the number of elements in T is less than some z , y z 2. Simple Example It could be that S has 3 unique symbols and b is 3 characters long. For argument sake, lets say that S = {A, B, C}. If we were to ask what is the probability that the number of unique symbols used in b is 1 then either b = AAA, BBB, or CCC. Of course, there are 27 different 3-symbol long words we can made with S. Therefore, the probability that b consists of only 1 symbol from S is . In this case, z = 2 Final Remarks I have tried more complicated examples, but the difficulty of the combinatorics logic seems to grow very complicated very quick. Is there a general solution to this problem given x, y, z?",\ge \in \mathbb{Z} \ge \ge \frac{1}{9},"['probability', 'combinatorics', 'combinatorial-proofs']"
62,Expected value of a stopping time of the sum of exponential random variables,Expected value of a stopping time of the sum of exponential random variables,,"Let $X_1, X_2,...$ be a sequence of independent exponential random variables, each with mean 1. Given a positive real number $k$ , let $k$ be defined by $N=\min\left\{ n: \sum_{i=1}^n X_i >k \right\}$ . That is, $N$ is the smallest number for which the sum of the first $N$ of the $X_i$ is larger than $k$ . I want to compute $E[N]$ . I attempt to apply Wald's equation $E[\sum_{i=1}^N X_i]=E[N]E[X]$ , but I have no idea to obtain $E[\sum_{i=1}^N X_i]$ .","Let be a sequence of independent exponential random variables, each with mean 1. Given a positive real number , let be defined by . That is, is the smallest number for which the sum of the first of the is larger than . I want to compute . I attempt to apply Wald's equation , but I have no idea to obtain .","X_1, X_2,... k k N=\min\left\{ n: \sum_{i=1}^n X_i >k \right\} N N X_i k E[N] E[\sum_{i=1}^N X_i]=E[N]E[X] E[\sum_{i=1}^N X_i]","['probability', 'stochastic-processes']"
63,"If you sum all possible subsets of peoples' birthday dates in a group of 7 people, will two sets always have the same sum?","If you sum all possible subsets of peoples' birthday dates in a group of 7 people, will two sets always have the same sum?",,"Suppose for a set $S$ of 7 people, $f(s)=$ the birthday date of the person for each person in $S$ . For example if their birthday is May 17th then $f(s)=17$ . Now for every subset $T \subset S$ let $g(T)$ be the sum of all $f(s)$ with $s \in T$ . Is the function $g$ ever an injection? In other words, prove whether or not two distinct subsets of $S$ will always have the same $g$ value. This was a bonus problem on the final exam of an introductory proofs class I took last year, and it has been bothering me ever since then because no solution was ever posted. I think this would be reasonably simple to check with a computer using brute force, but that was besides the point of the class. A similar problem where $S$ is instead a set of 8 people is trivial to prove using the Pigeonhole Principle. In that case, the codomain of $g$ will have $8 \cdot 31 =248$ elements while $\mathcal{P}(S)$ will have $2^8 = 256$ elements, so therefore $g$ is not injective. Clearly this same strategy does not apply to a group of 7 people, but is there another way of approaching this problem in order to prove whether or not $g$ is injective? My first thought was that even though $2^7 = 128 < 217=31 \cdot{7}$ , there could maybe be some way to analytically reduce the 217 possible sums until there are less than 128? It seems intuitively like there should exist an $S$ where $g$ is injective, but without using brute force I couldn't produce one.","Suppose for a set of 7 people, the birthday date of the person for each person in . For example if their birthday is May 17th then . Now for every subset let be the sum of all with . Is the function ever an injection? In other words, prove whether or not two distinct subsets of will always have the same value. This was a bonus problem on the final exam of an introductory proofs class I took last year, and it has been bothering me ever since then because no solution was ever posted. I think this would be reasonably simple to check with a computer using brute force, but that was besides the point of the class. A similar problem where is instead a set of 8 people is trivial to prove using the Pigeonhole Principle. In that case, the codomain of will have elements while will have elements, so therefore is not injective. Clearly this same strategy does not apply to a group of 7 people, but is there another way of approaching this problem in order to prove whether or not is injective? My first thought was that even though , there could maybe be some way to analytically reduce the 217 possible sums until there are less than 128? It seems intuitively like there should exist an where is injective, but without using brute force I couldn't produce one.",S f(s)= S f(s)=17 T \subset S g(T) f(s) s \in T g S g S g 8 \cdot 31 =248 \mathcal{P}(S) 2^8 = 256 g g 2^7 = 128 < 217=31 \cdot{7} S g,"['probability', 'functions', 'proof-writing', 'pigeonhole-principle']"
64,Expected covered area as integral of the probability of being covered?,Expected covered area as integral of the probability of being covered?,,"If I have a disk $\mathcal{D}$ , where each point is ""covered"" randomly with probability given by $$P(x \text{ is covered}) = p(x)$$ so that each point of the disk has a position-dependent probability of being covered, I understand I can write that the expected value of the total covered area $$\mathbb{E}(\text{total covered area}) = \int_{\mathcal{D}}P(x \text{ is covered})  \mathrm{d}x$$ but I am not sure how this relates to the definition of expected value. It seems relatively clear but I'm not sure how to prove it. Does it follow straightforwardly?","If I have a disk , where each point is ""covered"" randomly with probability given by so that each point of the disk has a position-dependent probability of being covered, I understand I can write that the expected value of the total covered area but I am not sure how this relates to the definition of expected value. It seems relatively clear but I'm not sure how to prove it. Does it follow straightforwardly?",\mathcal{D} P(x \text{ is covered}) = p(x) \mathbb{E}(\text{total covered area}) = \int_{\mathcal{D}}P(x \text{ is covered})  \mathrm{d}x,"['probability', 'geometry']"
65,Conditional probability and probability space,Conditional probability and probability space,,"I have two exercises where I have got troubles with define probability/measurable space $(\Omega,S)$ . ( $1$ ) We have two dices. One dice is fair, it means that each number from $1,2,3,4,5,6$ falls with probability $\frac{1}{6}$ . The second dice is not fair. The probability of falling 6 is $\frac{1}{2} $ and the probability of falling number from $ 1,2,3,4,5 $ is $\frac{1}{10}$ . Randomly we choose one dice and we roll it $4$ -times. The number $6$ falls twice. What is the probability that chosen dice is not fair. I can compute probablity but I have been trying to build $(\Omega,S)$ . I have been trying somethink like that $$\Omega=\{(D_F; 1,1,1,1),(D_F; 2,1,1,1),(D_F; 1,2,1,1),\dots,(D_F; 6,6,6,5),(D_{F}; 6,6,6,6),(D_{notF}; 1,1,1,1),(D_{notF}; 2,1,1,1),(D_{notF}; 1,2,1,1),\dots,(D_{notF}; 6,6,6,5),(D_{notF}; 6,6,6,6)\},$$ where $D_F$ -fair dice, $D_{notF}$ -not fair dice. I would like to now if I am correct. ( $2$ ) Two shooters, independently of each other, shoot at a common target, one shot each. The probability that the fisrts shooters shoot the target is $\frac{8}{10}$ . The probability that the second shooters shoot the target is $\frac{4}{10}$ . We know that only one hit the target. What is the probability, that the target was hit by first shooter. I think that $\Omega$ can look likes $$\Omega=\{(A_H,B_H),(A_H,B_{notH}),(A_{notH},B_H),(A_{notH},B_{notH})\},$$ where $A_{H}$ - the first shooter hits the target, $A_{notH}$ - the first shooter does not hit the target, $B_{H}$ - the second shooter hits the target, $B_{notH}$ - the second shooter does not hit the target. Probability that the first ( $A$ ) shooter hits target is $\frac{8}{10}$ , it means that $$P\left(\{(A_H,B_H),(A_H,B_{notH})\}\right)=P\left(X\right)=\frac{8}{10},$$ and $$P\left(\{(A_{notH},B_{H}),(A_{notH},B_{notH})\}\right)=P\left(X^c\right)=\frac{2}{10},$$ Probability that the second ( $B$ ) shooter hits target is $\frac{4}{10}$ , it means that $$P\left(\{(A_H,B_H),(A_{notH},B_H)\}\right)=P\left(Y\right)=\frac{4}{10},$$ and $$P\left(\{(A_{notH},B_{notH}),(A_{H},B_{notH})\}\right)=P\left(Y^c\right)=\frac{6}{10},$$ The probability, that the target was hit by first shooter if we know that only one shooter hit formally is $$P(\{(A_H,B_H),(A_H,B_{notH})\}|\{(A_H,B_{notH}),(A_{notH},B_H)\})=P\left(X|Z\right).$$ I would like to compute this probability by using Bayes theorem, but I am little bit confused. I have been trying somthink like that $$P(X|Z)=\frac{P(Z|X)P(X)}{P(Z|X)P(X)+P(Z|X^c)P(X^c)},$$ but I am stuck.","I have two exercises where I have got troubles with define probability/measurable space . ( ) We have two dices. One dice is fair, it means that each number from falls with probability . The second dice is not fair. The probability of falling 6 is and the probability of falling number from is . Randomly we choose one dice and we roll it -times. The number falls twice. What is the probability that chosen dice is not fair. I can compute probablity but I have been trying to build . I have been trying somethink like that where -fair dice, -not fair dice. I would like to now if I am correct. ( ) Two shooters, independently of each other, shoot at a common target, one shot each. The probability that the fisrts shooters shoot the target is . The probability that the second shooters shoot the target is . We know that only one hit the target. What is the probability, that the target was hit by first shooter. I think that can look likes where - the first shooter hits the target, - the first shooter does not hit the target, - the second shooter hits the target, - the second shooter does not hit the target. Probability that the first ( ) shooter hits target is , it means that and Probability that the second ( ) shooter hits target is , it means that and The probability, that the target was hit by first shooter if we know that only one shooter hit formally is I would like to compute this probability by using Bayes theorem, but I am little bit confused. I have been trying somthink like that but I am stuck.","(\Omega,S) 1 1,2,3,4,5,6 \frac{1}{6} \frac{1}{2}   1,2,3,4,5  \frac{1}{10} 4 6 (\Omega,S) \Omega=\{(D_F; 1,1,1,1),(D_F; 2,1,1,1),(D_F; 1,2,1,1),\dots,(D_F; 6,6,6,5),(D_{F}; 6,6,6,6),(D_{notF}; 1,1,1,1),(D_{notF}; 2,1,1,1),(D_{notF}; 1,2,1,1),\dots,(D_{notF}; 6,6,6,5),(D_{notF}; 6,6,6,6)\}, D_F D_{notF} 2 \frac{8}{10} \frac{4}{10} \Omega \Omega=\{(A_H,B_H),(A_H,B_{notH}),(A_{notH},B_H),(A_{notH},B_{notH})\}, A_{H} A_{notH} B_{H} B_{notH} A \frac{8}{10} P\left(\{(A_H,B_H),(A_H,B_{notH})\}\right)=P\left(X\right)=\frac{8}{10}, P\left(\{(A_{notH},B_{H}),(A_{notH},B_{notH})\}\right)=P\left(X^c\right)=\frac{2}{10}, B \frac{4}{10} P\left(\{(A_H,B_H),(A_{notH},B_H)\}\right)=P\left(Y\right)=\frac{4}{10}, P\left(\{(A_{notH},B_{notH}),(A_{H},B_{notH})\}\right)=P\left(Y^c\right)=\frac{6}{10}, P(\{(A_H,B_H),(A_H,B_{notH})\}|\{(A_H,B_{notH}),(A_{notH},B_H)\})=P\left(X|Z\right). P(X|Z)=\frac{P(Z|X)P(X)}{P(Z|X)P(X)+P(Z|X^c)P(X^c)},","['probability', 'probability-theory', 'conditional-probability']"
66,Probability of having exactly $v$ different letters in password,Probability of having exactly  different letters in password,v,"Consider a password with $t$ characters, with a character set of length $n^2$ . What is the probability there are $v$ distinct letters in the password. So if the password was ""abccdadde"" $v$ would be $5$ and $t=9$ . So far I have deduced if $t=n=v$ the probability is given by: $$\frac{n^{2}!}{\left(n^{2}-n\right)!n^{2n}}$$ And when $t=v+1=n+1$ the probability is given by: $$\frac{n\left(n+1\right)!n^{2}!}{2n!\left(n^{2}-n\right)!n^{2\left(n+1\right)}}$$","Consider a password with characters, with a character set of length . What is the probability there are distinct letters in the password. So if the password was ""abccdadde"" would be and . So far I have deduced if the probability is given by: And when the probability is given by:",t n^2 v v 5 t=9 t=n=v \frac{n^{2}!}{\left(n^{2}-n\right)!n^{2n}} t=v+1=n+1 \frac{n\left(n+1\right)!n^{2}!}{2n!\left(n^{2}-n\right)!n^{2\left(n+1\right)}},"['probability', 'combinatorics', 'functions', 'summation']"
67,Probability of One Event Less Than Probability of Second Event,Probability of One Event Less Than Probability of Second Event,,"I am having a bit of trouble proving some cases when one probability is smaller than the other probability for all positive integers $a, b$ , so some suggestions would be appreciated. Here is the problem: For all $a, b \in \mathbb{Z}^+$ , if $P(A) = \dfrac{a^2 - a + b^2 - b}{a^2 + 2ab + b^2 - a - b}$ and $P(B) = \dfrac{a^2 + b^2}{a^2 + 2ab + b^2}$ , prove that $P(A) < P(B)$ . So I attempted using cases. Case 1: If $a = b \neq 0$ , then we want to show that $P(A) < P(B)$ \begin{align*} P(A) = \dfrac{a^2 - a + b^2 - b}{a^2 + 2ab + b^2 - a - b} = \dfrac{2a^2 - 2a}{4a^2 - 2a} < \dfrac{a^2 + b^2}{a^2 + 2ab + b^2} = \dfrac{2a^2}{4a^2} = \dfrac{1}{2} = P(B) \end{align*} Thus, this implies that $P(A) < P(B)$ for all $a, b \in \mathbb{Z}^+$ The next two cases are the cases I am having trouble with. Case 2: If $a > b > 0$ , then we want to show that $P(A) < P(B)$ . Case 3: If $b > a > 0$ , then we want to show that $P(A) < P(B)$ . I am not sure how to approach cases 2 and 3. But case 3 should follow from case 2. So some assistance would be appreciated. Thanks","I am having a bit of trouble proving some cases when one probability is smaller than the other probability for all positive integers , so some suggestions would be appreciated. Here is the problem: For all , if and , prove that . So I attempted using cases. Case 1: If , then we want to show that Thus, this implies that for all The next two cases are the cases I am having trouble with. Case 2: If , then we want to show that . Case 3: If , then we want to show that . I am not sure how to approach cases 2 and 3. But case 3 should follow from case 2. So some assistance would be appreciated. Thanks","a, b a, b \in \mathbb{Z}^+ P(A) = \dfrac{a^2 - a + b^2 - b}{a^2 + 2ab + b^2 - a - b} P(B) = \dfrac{a^2 + b^2}{a^2 + 2ab + b^2} P(A) < P(B) a = b \neq 0 P(A) < P(B) \begin{align*}
P(A) = \dfrac{a^2 - a + b^2 - b}{a^2 + 2ab + b^2 - a - b} = \dfrac{2a^2 - 2a}{4a^2 - 2a} < \dfrac{a^2 + b^2}{a^2 + 2ab + b^2} = \dfrac{2a^2}{4a^2} = \dfrac{1}{2} = P(B)
\end{align*} P(A) < P(B) a, b \in \mathbb{Z}^+ a > b > 0 P(A) < P(B) b > a > 0 P(A) < P(B)","['probability', 'proof-writing', 'solution-verification']"
68,Standard Monty Hall problem: proof that switching is optimal?,Standard Monty Hall problem: proof that switching is optimal?,,"I have a model of the Monty Hall problem that as far as I know is standard: three doors, the contestant chooses one at random, then if Monty has a choice (i.e., the contestant has chosen the door with a car) he chooses his door to open at random, and events are generally independent. For the contestant, a strategy of always switching doors gives a $2/3$ probability of winning, and a strategy of never switching doors has a $1/3$ probability of winning. Intuitively the switching strategy is better because in order to win, you need to have choosen a door with a goat behind it; for the non-switching strategy, in order to win you need to have choosen the door with a car behind it. Since you're more likely to choose a goat door than the car door, you're better off switching. I have two further questions about this: I think it's clear that the contestant's ""gain"" from adopting a switching strategy is 2, in the sense that over many trials, the contestant is twice as likely to win by using the switching strategy. However, is there a way to compute a ""gain"" given that the contestant will only play the game once? How would we prove that the strategy of switching is optimal? I have searched but not found anything. Obviously if you only consider the two strategies, then computing the $2/3$ and $1/3$ probabilities above constitutes the proof. However, you could open up the model to allow for weird strategies like ""Always switch when selecting door 1 and Monty opens door 3, but switch only half the time when Monty selects door 2"", and so on. I am not sure how to consider these strategies given my model of the problem.","I have a model of the Monty Hall problem that as far as I know is standard: three doors, the contestant chooses one at random, then if Monty has a choice (i.e., the contestant has chosen the door with a car) he chooses his door to open at random, and events are generally independent. For the contestant, a strategy of always switching doors gives a probability of winning, and a strategy of never switching doors has a probability of winning. Intuitively the switching strategy is better because in order to win, you need to have choosen a door with a goat behind it; for the non-switching strategy, in order to win you need to have choosen the door with a car behind it. Since you're more likely to choose a goat door than the car door, you're better off switching. I have two further questions about this: I think it's clear that the contestant's ""gain"" from adopting a switching strategy is 2, in the sense that over many trials, the contestant is twice as likely to win by using the switching strategy. However, is there a way to compute a ""gain"" given that the contestant will only play the game once? How would we prove that the strategy of switching is optimal? I have searched but not found anything. Obviously if you only consider the two strategies, then computing the and probabilities above constitutes the proof. However, you could open up the model to allow for weird strategies like ""Always switch when selecting door 1 and Monty opens door 3, but switch only half the time when Monty selects door 2"", and so on. I am not sure how to consider these strategies given my model of the problem.",2/3 1/3 2/3 1/3,"['probability', 'monty-hall']"
69,Fit cube in a circular hole (only 50% of the time),Fit cube in a circular hole (only 50% of the time),,"QUESTION: You have a hole in the shape of a circle with radius R and a cube with side 1. If the probability that the cube will enter the hole is 50%, what is the  radius R of the circle? Examples of three different orientations of the cube exactly (if one would connect the center of the cube and the center of the hole, they would form a vertical line) above the hole: What I've tried: I know the longest straight line distance in the cube will be √3. And then I thought, starting with that distance representing the diameter of a circle and now rotate it either clock-wise or counter clock-wise (don't matter obv). But here I'm stuck. It seems that I should rotate it x many degrees so that it will fit exactly only 50% of the time. But can't come up with the answer. Maybe it's not even the right approach and you have a different approach and can come up with an answer. Thanks.","QUESTION: You have a hole in the shape of a circle with radius R and a cube with side 1. If the probability that the cube will enter the hole is 50%, what is the  radius R of the circle? Examples of three different orientations of the cube exactly (if one would connect the center of the cube and the center of the hole, they would form a vertical line) above the hole: What I've tried: I know the longest straight line distance in the cube will be √3. And then I thought, starting with that distance representing the diameter of a circle and now rotate it either clock-wise or counter clock-wise (don't matter obv). But here I'm stuck. It seems that I should rotate it x many degrees so that it will fit exactly only 50% of the time. But can't come up with the answer. Maybe it's not even the right approach and you have a different approach and can come up with an answer. Thanks.",,"['probability', 'geometry']"
70,Generating 3 random numbers that sum to 1 with two different methods.,Generating 3 random numbers that sum to 1 with two different methods.,,"I am looking at ways to generate three random numbers that sum to $1$ . I came up with two different methods and played around with some code and they seem to have very different distributions. Method 1 Generate $3$ Uniform $[0,1]$ variables and then divide by their sum : Method 2 For this method I imagined picking 2 points on a stick of length 1, ensuring that their sum would always be 1, and then using the two points to break the stick into 3 pieces. Quick look at the methods It is clear to see in Method 1 the distribution of all three outputs will be the same, that is all three outputs are completely symmetrical. This is also true for Method 2 but takes some more thinking to see why. It should be clear by another reflection/symmetry argument that min and 1 - max have the same distribution and by a bijective reflection around max/2 it is clear to see that max - min has the same distribution as min. Breakdown and Problem I then ran a few thousand simulations of each method and we get vastly different results. Results method 1 Results method 2 The question Method 1 seems somewhat poisson like whereas method 2 feels to be more uniform. What is the correct way to generate n numbers that sum to 1? Why are these results so different? Have we constricted the ability to be random by demanding they sum to 1?","I am looking at ways to generate three random numbers that sum to . I came up with two different methods and played around with some code and they seem to have very different distributions. Method 1 Generate Uniform variables and then divide by their sum : Method 2 For this method I imagined picking 2 points on a stick of length 1, ensuring that their sum would always be 1, and then using the two points to break the stick into 3 pieces. Quick look at the methods It is clear to see in Method 1 the distribution of all three outputs will be the same, that is all three outputs are completely symmetrical. This is also true for Method 2 but takes some more thinking to see why. It should be clear by another reflection/symmetry argument that min and 1 - max have the same distribution and by a bijective reflection around max/2 it is clear to see that max - min has the same distribution as min. Breakdown and Problem I then ran a few thousand simulations of each method and we get vastly different results. Results method 1 Results method 2 The question Method 1 seems somewhat poisson like whereas method 2 feels to be more uniform. What is the correct way to generate n numbers that sum to 1? Why are these results so different? Have we constricted the ability to be random by demanding they sum to 1?","1 3 [0,1]","['probability', 'statistics']"
71,probability of a single student not being accepted into any college,probability of a single student not being accepted into any college,,"There are $n$ students applying to n colleges. Each college has a ranking over all students (i.e. a permutation) which, for all we know, is completely random and independent of other colleges. College number $i$ will admit the first $k_{i}$ students in its ranking. If a student is not admitted to any college, he or she might file a complaint against the board of colleges, and colleges want to avoid that as much as possible. (a) If for all $i, k_i = 1$ (i.e. if every college only admits the top student on its list), what is the probability that all students will be admitted to at least one college? (b) What is the probability that a particular student, Alice, does not get admitted to any college? Prove that if the average of all $k_i$ 's is at least $2*\log(n)$ , then this probability is at most $\frac{1}{n^{2}}$ . (Hint: use the inequality $1 —x \leq e^{-x})$ (Just to clarify, it says that the average of all $k_i$ is at least $2\ln n,$ NOT $21nn$ .) I'm having some problem trying to figure out part b. First I tried picking an arbitrary college $i$ , which accepts $k_i$ students. The college has $n!$ ways of ranking all the students. For Alice to note get admitted, we can select the $k_i$ students $(n-1) P k_i$ ways. Then the probability simplifies down to $\frac{1}{(n-1-k_i)!}$ Now I want to extrapolate this, and the problem also gives that $\frac{k1 + \cdots + kn}{n} = 2 \ln n,$ but I'm not sure how to use that to give the result the problem wants. Any help would really be appreciated!","There are students applying to n colleges. Each college has a ranking over all students (i.e. a permutation) which, for all we know, is completely random and independent of other colleges. College number will admit the first students in its ranking. If a student is not admitted to any college, he or she might file a complaint against the board of colleges, and colleges want to avoid that as much as possible. (a) If for all (i.e. if every college only admits the top student on its list), what is the probability that all students will be admitted to at least one college? (b) What is the probability that a particular student, Alice, does not get admitted to any college? Prove that if the average of all 's is at least , then this probability is at most . (Hint: use the inequality (Just to clarify, it says that the average of all is at least NOT .) I'm having some problem trying to figure out part b. First I tried picking an arbitrary college , which accepts students. The college has ways of ranking all the students. For Alice to note get admitted, we can select the students ways. Then the probability simplifies down to Now I want to extrapolate this, and the problem also gives that but I'm not sure how to use that to give the result the problem wants. Any help would really be appreciated!","n i k_{i} i, k_i = 1 k_i 2*\log(n) \frac{1}{n^{2}} 1 —x \leq e^{-x}) k_i 2\ln n, 21nn i k_i n! k_i (n-1) P k_i \frac{1}{(n-1-k_i)!} \frac{k1 + \cdots + kn}{n} = 2 \ln n,","['probability', 'combinatorics', 'permutations']"
72,"In a tournament of $2^n$ people, what is the probability of player $i$ and player $j$ meet at $k$-th round","In a tournament of  people, what is the probability of player  and player  meet at -th round",2^n i j k,"In a knock-out tournament of $2^n$ people, where if $i < j$ , player $i$ is better than player $j$ and will beat her in any parts of the tournament. What is the probability of player $i$ and player $j$ will meet at $k$ -th round for any $1 \leq i \leq j \leq 2^n$ , $1 \leq k \leq n$ (assuming the positions of player at the start of tournament are all random)? This problem is inspired by the case $i=1,j=2,k=n$ , where the probability is $\frac{2^{n-1}}{2^n-1}$ , determined by the probability that player $2$ is at the different half of the player $1$ during the start. Similarly, player 3 will meet with player $1$ at the final tournament by probability $\frac{2^{n-1}-1}{2^n-1}\frac{2^{n-1}}{2^n-2}$ (player $2$ meet player $1$ first). And similarly for all other players by applying same logic. I'm curious about the general case that player $i$ and player $j$ will meet at $k$ -th round and am wondering if my rationale below is correct. We know that the situation happens only when player $i$ is the best player among the $2^k$ nearest player and player $j$ is the best in her $2^{k-1}$ nearest player. By combinatorics, it's equivalent to that fixed $i, j$ , among the $2^k-2$ numbers that are nearest to player $i$ during the contest, the random $2^{k-1}-1$ numbers are all greater than $j$ and the remaining $2^{k-1}-1$ are both greater than $i$ . So it's $$P(i,j,k) = \frac{\binom{2^n-j}{2^{k-1}-1}\binom{2^n-i - 2^{k-1}-1}{2^{k-1}-1}}{\binom{2^n}{2^{k}-2}} \frac{1}{2^{n-k+1}}$$ Where the $\frac{1}{2^{n-k+1}}$ is the additional probability that $i, j$ are in the two nearest $2^{k-1}$ groups. Is this correct?","In a knock-out tournament of people, where if , player is better than player and will beat her in any parts of the tournament. What is the probability of player and player will meet at -th round for any , (assuming the positions of player at the start of tournament are all random)? This problem is inspired by the case , where the probability is , determined by the probability that player is at the different half of the player during the start. Similarly, player 3 will meet with player at the final tournament by probability (player meet player first). And similarly for all other players by applying same logic. I'm curious about the general case that player and player will meet at -th round and am wondering if my rationale below is correct. We know that the situation happens only when player is the best player among the nearest player and player is the best in her nearest player. By combinatorics, it's equivalent to that fixed , among the numbers that are nearest to player during the contest, the random numbers are all greater than and the remaining are both greater than . So it's Where the is the additional probability that are in the two nearest groups. Is this correct?","2^n i < j i j i j k 1 \leq i \leq j \leq 2^n 1 \leq k \leq n i=1,j=2,k=n \frac{2^{n-1}}{2^n-1} 2 1 1 \frac{2^{n-1}-1}{2^n-1}\frac{2^{n-1}}{2^n-2} 2 1 i j k i 2^k j 2^{k-1} i, j 2^k-2 i 2^{k-1}-1 j 2^{k-1}-1 i P(i,j,k) = \frac{\binom{2^n-j}{2^{k-1}-1}\binom{2^n-i - 2^{k-1}-1}{2^{k-1}-1}}{\binom{2^n}{2^{k}-2}} \frac{1}{2^{n-k+1}} \frac{1}{2^{n-k+1}} i, j 2^{k-1}","['probability', 'combinatorics', 'puzzle']"
73,"Let $U=X+Y$, $V=X-Y$, while $X,Y\sim U[0,1]$ and independent. Prove or disprove..","Let , , while  and independent. Prove or disprove..","U=X+Y V=X-Y X,Y\sim U[0,1]","Let $U=X+Y$ , $V=X-Y$ , while $X,Y\sim U[0,1]$ and independent. Prove or disprove: $(U,V)$ has a uniform distribution on some area in the plane. $U$ and $V+1$ are distributed the same (sorry if the translation is bad, would be happy to know how it's usually written). $U,V$ are independent. $U,V$ are (uncoordinated - not sure of the translation), but what it means is $Cov(U,V)=0$ My work: For first statement: Intuitively this is true, but I wanted to find the CDF: $F_{U,V}(u,v)=P(X+Y \le u, X-Y \le v)=P(Y \le u-X)P(X \le v+Y)=(u-X)(v+Y)$ whenever $u,v\le 1$ . I'm confused if what I did is correct and would love to hear feedback. For second statement: $P(V+1 \le v)=P(V \le v-1)=0$ $P(U \le u) = P(X+Y \le u)=P(X \le u-Y)=$ .. I'm a little stuck here, what does it mean that $X$ is less than $u-Y$ since $Y$ could be anything, this is giving me some problems. For third statement: I need to  either prove that $F_UF_V=F_{U,V}$ or disprove it. My intuition says that they're dependent, since they both depend on $X,Y$ . $F_U(u)F_V(v)=P(X+Y \le u , X-Y \le v) $ , again I'm struggling with calculating these, How do I reach $X,Y$ or stuff that I know how to deal with, without complicating myself? The last one was not hard, all I've done is $Cov(X+Y,X-Y)=Var(X)-Var(Y)=0$ . Any help and feedback is really appreciated, thanks in advance.","Let , , while and independent. Prove or disprove: has a uniform distribution on some area in the plane. and are distributed the same (sorry if the translation is bad, would be happy to know how it's usually written). are independent. are (uncoordinated - not sure of the translation), but what it means is My work: For first statement: Intuitively this is true, but I wanted to find the CDF: whenever . I'm confused if what I did is correct and would love to hear feedback. For second statement: .. I'm a little stuck here, what does it mean that is less than since could be anything, this is giving me some problems. For third statement: I need to  either prove that or disprove it. My intuition says that they're dependent, since they both depend on . , again I'm struggling with calculating these, How do I reach or stuff that I know how to deal with, without complicating myself? The last one was not hard, all I've done is . Any help and feedback is really appreciated, thanks in advance.","U=X+Y V=X-Y X,Y\sim U[0,1] (U,V) U V+1 U,V U,V Cov(U,V)=0 F_{U,V}(u,v)=P(X+Y \le u, X-Y \le v)=P(Y \le u-X)P(X \le v+Y)=(u-X)(v+Y) u,v\le 1 P(V+1 \le v)=P(V \le v-1)=0 P(U \le u) = P(X+Y \le u)=P(X \le u-Y)= X u-Y Y F_UF_V=F_{U,V} X,Y F_U(u)F_V(v)=P(X+Y \le u , X-Y \le v)  X,Y Cov(X+Y,X-Y)=Var(X)-Var(Y)=0","['probability', 'independence', 'uniform-distribution']"
74,If $P(X\in A)=0$ or $1$ then $X$ has a degenerate distribution,If  or  then  has a degenerate distribution,P(X\in A)=0 1 X,"Let $X$ be a real random variable on a probability space. Suppose that $P(X\in A)=0$ or $1$ for all $A\in\mathcal B(\mathbb R)$ . Is true that $X$ has a degenerate distribution? Is it also true if $X$ takes values in a more general space? Regarding the real case I did the following: Consider the partition $\mathbb R=\bigcup_{n \in\mathbb Z} [n,n+1)$ . By $\sigma$ -additivity we have $\sum_{n \in\mathbb Z}P_X\big([n,n+1)\big)=1$ . Therefore there exists some integer $n$ such that $X\in[n,n+1]$ almost surely. Using additivity again we get $P_X\big([n,n+1/2)\big)+P_X\big([n+1/2,n+1]\big)=1$ , so either $X\in[n,n+1/2]$ almost surely or $X\in[n+1/2,n+1]$ almost surely . Continuing inductively, we obtain a decreasing sequence of closed intervals $I_k$ , each  with length $|I_k|=1/k$ and $P_X(I_k)=1$ . By the nested interval theorem we have $$\bigcap_{k=1}^\infty I_k=\{x\}$$ for some $x\in\mathbb R$ . Moreover, by the properties of measures, we have $P_X(\{x\})=\lim_{k\to\infty} P_X(I_k)=1$ . Hence $X=x$ almost surely. Is this correct?","Let be a real random variable on a probability space. Suppose that or for all . Is true that has a degenerate distribution? Is it also true if takes values in a more general space? Regarding the real case I did the following: Consider the partition . By -additivity we have . Therefore there exists some integer such that almost surely. Using additivity again we get , so either almost surely or almost surely . Continuing inductively, we obtain a decreasing sequence of closed intervals , each  with length and . By the nested interval theorem we have for some . Moreover, by the properties of measures, we have . Hence almost surely. Is this correct?","X P(X\in A)=0 1 A\in\mathcal B(\mathbb R) X X \mathbb R=\bigcup_{n \in\mathbb Z} [n,n+1) \sigma \sum_{n \in\mathbb Z}P_X\big([n,n+1)\big)=1 n X\in[n,n+1] P_X\big([n,n+1/2)\big)+P_X\big([n+1/2,n+1]\big)=1 X\in[n,n+1/2] X\in[n+1/2,n+1] I_k |I_k|=1/k P_X(I_k)=1 \bigcap_{k=1}^\infty I_k=\{x\} x\in\mathbb R P_X(\{x\})=\lim_{k\to\infty} P_X(I_k)=1 X=x","['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'random-variables']"
75,Sum of iid variables where number of summands is random,Sum of iid variables where number of summands is random,,"Let $(X_n)$ be a sequence of iid random variables with mean $\mu$ and variance $\sigma^2\lt \infty$ . Set $S_0=0$ and $S_n=X_1+...+X_n$ for $n\ge 1$ . Let $N$ be a bounded non-negative integer-valued random variable which is independent of the sequence $(X_n)$ . a) Show $E(S_N)=\mu E(N)$ . b) Find $E(S^2_N)$ and $\text{Var}( S_N)$ in terms of $\text{Var}(N)$ . Now consider the case where $X_1$ only takes values $1$ and $-1$ . Fix $a\ge 0$ and set $T=\min\{n\ge 0:|S_n|=a\}$ . c) Show $E(S_T)=\mu E(T)$ and find $\text{Var}(S_T)$ I've solved a) and b) using the law of total expectation but I'm at a loss as to why we need the assumption that $N$ is independent of the sequence $(X_n)$ and this is preventing me from making sense of c). For instance, my steps for a) are essentially $E(S_N)=E(E(S_N|N=n))$ $E(S_N)=\sum_n E(S_n)P(N=n)$ $E(S_N)=\sum_n \mu nP(N=n)$ $E(S_N)=\mu E(N)$ The steps for b) are very similar with only algebraic manipulation beyond the above. To the best of my knowledge, every step above did not care about what $N$ is independent of, so, I could just replace $T$ with $N$ thus the results for c) are the same in terms of $E(T)$ and $\text{Var}(T)$ ?(but surely the question setter would not do that). Please don't answer this problem for me, I will be very grateful for a small nudge in the right direction just so I can proceed with the question myself. EDIT: I am interested in whether this question has not been answered because I have explained my intentions poorly or if my case is plausible? Please leave me a comment either way.","Let be a sequence of iid random variables with mean and variance . Set and for . Let be a bounded non-negative integer-valued random variable which is independent of the sequence . a) Show . b) Find and in terms of . Now consider the case where only takes values and . Fix and set . c) Show and find I've solved a) and b) using the law of total expectation but I'm at a loss as to why we need the assumption that is independent of the sequence and this is preventing me from making sense of c). For instance, my steps for a) are essentially The steps for b) are very similar with only algebraic manipulation beyond the above. To the best of my knowledge, every step above did not care about what is independent of, so, I could just replace with thus the results for c) are the same in terms of and ?(but surely the question setter would not do that). Please don't answer this problem for me, I will be very grateful for a small nudge in the right direction just so I can proceed with the question myself. EDIT: I am interested in whether this question has not been answered because I have explained my intentions poorly or if my case is plausible? Please leave me a comment either way.",(X_n) \mu \sigma^2\lt \infty S_0=0 S_n=X_1+...+X_n n\ge 1 N (X_n) E(S_N)=\mu E(N) E(S^2_N) \text{Var}( S_N) \text{Var}(N) X_1 1 -1 a\ge 0 T=\min\{n\ge 0:|S_n|=a\} E(S_T)=\mu E(T) \text{Var}(S_T) N (X_n) E(S_N)=E(E(S_N|N=n)) E(S_N)=\sum_n E(S_n)P(N=n) E(S_N)=\sum_n \mu nP(N=n) E(S_N)=\mu E(N) N T N E(T) \text{Var}(T),"['probability', 'conditional-expectation']"
76,How to prove the following $L^2$ convergence,How to prove the following  convergence,L^2,"I have encountered this several times, but have no idea why its true. Let $(\Omega,\mathcal{F},P)$ be a probability space. Let $H(s,\omega): [0,t]\times \Omega\rightarrow \mathbb{R}$ be $\mathscr{B}[0,t]\times \mathcal{F}$ measurable. Moreover, for each fixed $\omega\in \Omega$ , $H(s,\omega)$ is continuous on $[0,t]$ . We assume that \begin{align*} E\int_0^t H(s,\omega)^2\ ds < \infty \end{align*} Define $H_n(s,\omega)$ as \begin{align*} \textstyle H_n(s,\omega)= H(\frac{kt}{n}, \omega), \qquad \frac{kt}{n}\leq s< \frac{(k+1)t}{n}, 0\leq k\leq n-1 \end{align*} Then we have \begin{align*} \lim_{n\rightarrow\infty}E\int_0^t (H_n(s,\omega)- H(s,\omega))^2\ ds= 0 \end{align*} It's clear that $H_n\rightarrow H$ a.s. We can't apply dominated convergence since this is Riemann type approximation. I tried to prove the sequence $H_n$ is cauchy in $L^2$ , but it seems does not work. Does anyone have any idea or comments?","I have encountered this several times, but have no idea why its true. Let be a probability space. Let be measurable. Moreover, for each fixed , is continuous on . We assume that Define as Then we have It's clear that a.s. We can't apply dominated convergence since this is Riemann type approximation. I tried to prove the sequence is cauchy in , but it seems does not work. Does anyone have any idea or comments?","(\Omega,\mathcal{F},P) H(s,\omega): [0,t]\times \Omega\rightarrow \mathbb{R} \mathscr{B}[0,t]\times \mathcal{F} \omega\in \Omega H(s,\omega) [0,t] \begin{align*}
E\int_0^t H(s,\omega)^2\ ds < \infty
\end{align*} H_n(s,\omega) \begin{align*}
\textstyle H_n(s,\omega)= H(\frac{kt}{n}, \omega), \qquad \frac{kt}{n}\leq s< \frac{(k+1)t}{n}, 0\leq k\leq n-1
\end{align*} \begin{align*}
\lim_{n\rightarrow\infty}E\int_0^t (H_n(s,\omega)- H(s,\omega))^2\ ds= 0
\end{align*} H_n\rightarrow H H_n L^2","['probability', 'measure-theory', 'stochastic-calculus']"
77,Mean and Variance of norm of multivariate normal,Mean and Variance of norm of multivariate normal,,"Let $a\in\mathbb{C}^n$ be some complex vector, and let $Y \sim \mathbb{C}\mathcal{N}(0, \sigma^2I)$ , i want to find the mean and variance of this random variable: $$ X = \left\lVert Y \right\rVert_2^2 - \left\lVert Y - a \right\rVert_2^2. $$ This is a random variable describing the distance of $Y$ to its mean versus another specific point. I was able to calculate the mean of $X$ as $$ -\left\lVert a \right\rVert_2^2. $$ But the variance computations has proven to be quite complicated. Can someone help with this? Edit: Work I've done so far To compute $E[X^2]$ , we have that: $$ X^2 = \left\lVert Y \right\rVert^4 + \left\lVert Y - a \right\rVert^4 - 2\left\lVert Y \right\rVert^2 \left\lVert Y - a \right\rVert^2.$$ Computing the terms one at a time, we start with: \begin{align}  \left\lVert Y - a \right\rVert^4 = {} & ( \left\lVert Y\right\rVert^2  +  \left\lVert a \right\rVert^2 - 2\Re \left\langle Y, a \right\rangle)^2 \\  = {} & \left\lVert Y\right\rVert^4 + \left\lVert a\right\rVert^4 + 4\left(\Re \langle Y,a\rangle\right)^2 \\  &+ 2\left\lVert Y\right\rVert^2\left\lVert a\right\rVert^2 \\  &- 4 \left\lVert Y\right\rVert^2 \Re\left\langle Y, a \right\rangle \\  &\underbrace{ {} - 4 \left\lVert g\right\rVert^2 \Re\left\langle Y, a \right\rangle}_{E[\cdot]= 0} \end{align} Moreover, we have that: \begin{align} \left\lVert Y\right\rVert^2 \left\lVert Y - a \right\rVert^2  &= \left\lVert Y\right\rVert^4  +  \left\lVert Y \right\rVert^2\left\lVert a \right\rVert^2 - 2\left\lVert Y \right\rVert^2\Re \langle Y,a \rangle \\ \end{align} Subtracting $E[X]^2 = \left\lVert a \right\rVert_2^4$ from $E[X^2]$ , and removing all the terms that cancel out: \begin{align} \operatorname{Var} &= E[X^2] - E[X]^2 \\ &= E\left[\left\lVert a\right\rVert_2^4 + 4(\Re\langle Y,a\rangle)^2\right] -  \left\lVert a\right\rVert_2^4 \\ &= E\left[4(\Re \langle Y,a\rangle )^2\right] \\ &= E\left[\big(\langle Y,a \rangle + \langle a,Y\rangle\big)^2\right] \end{align} I'm stuck on what to do with the expression above.","Let be some complex vector, and let , i want to find the mean and variance of this random variable: This is a random variable describing the distance of to its mean versus another specific point. I was able to calculate the mean of as But the variance computations has proven to be quite complicated. Can someone help with this? Edit: Work I've done so far To compute , we have that: Computing the terms one at a time, we start with: Moreover, we have that: Subtracting from , and removing all the terms that cancel out: I'm stuck on what to do with the expression above.","a\in\mathbb{C}^n Y \sim \mathbb{C}\mathcal{N}(0, \sigma^2I) 
X = \left\lVert Y \right\rVert_2^2 - \left\lVert Y - a \right\rVert_2^2.
 Y X 
-\left\lVert a \right\rVert_2^2.
 E[X^2]  X^2 = \left\lVert Y \right\rVert^4 + \left\lVert Y - a \right\rVert^4 - 2\left\lVert Y \right\rVert^2 \left\lVert Y - a \right\rVert^2. \begin{align}
 \left\lVert Y - a \right\rVert^4 = {} & ( \left\lVert Y\right\rVert^2  +  \left\lVert a \right\rVert^2 - 2\Re \left\langle Y, a \right\rangle)^2 \\
 = {} & \left\lVert Y\right\rVert^4 + \left\lVert a\right\rVert^4 + 4\left(\Re \langle Y,a\rangle\right)^2 \\
 &+ 2\left\lVert Y\right\rVert^2\left\lVert a\right\rVert^2 \\
 &- 4 \left\lVert Y\right\rVert^2 \Re\left\langle Y, a \right\rangle \\
 &\underbrace{ {} - 4 \left\lVert g\right\rVert^2 \Re\left\langle Y, a \right\rangle}_{E[\cdot]= 0}
\end{align} \begin{align}
\left\lVert Y\right\rVert^2 \left\lVert Y - a \right\rVert^2 
&= \left\lVert Y\right\rVert^4  +  \left\lVert Y \right\rVert^2\left\lVert a \right\rVert^2 - 2\left\lVert Y \right\rVert^2\Re \langle Y,a \rangle \\
\end{align} E[X]^2 = \left\lVert a \right\rVert_2^4 E[X^2] \begin{align}
\operatorname{Var} &= E[X^2] - E[X]^2 \\
&= E\left[\left\lVert a\right\rVert_2^4 + 4(\Re\langle Y,a\rangle)^2\right] -  \left\lVert a\right\rVert_2^4 \\
&= E\left[4(\Re \langle Y,a\rangle )^2\right] \\
&= E\left[\big(\langle Y,a \rangle + \langle a,Y\rangle\big)^2\right]
\end{align}","['probability', 'statistics', 'normal-distribution', 'normed-spaces']"
78,Probability conditioned on two independent events,Probability conditioned on two independent events,,"Let $B$ and $C$ be independent events. We are interested in $P[A|B \cap C]$ . We know what $P[A|B]$ and $P[A|C]$ are. How do we use these two to find the answer? What additional missing pieces, if any, do we need? I arrived at $$ P[A|B \cap C] = \frac{P[A \cap B \cap C]}{P[B]P[C]}. $$ But I have not been able to make use of the given quantities in some way.","Let and be independent events. We are interested in . We know what and are. How do we use these two to find the answer? What additional missing pieces, if any, do we need? I arrived at But I have not been able to make use of the given quantities in some way.",B C P[A|B \cap C] P[A|B] P[A|C]  P[A|B \cap C] = \frac{P[A \cap B \cap C]}{P[B]P[C]}. ,"['probability', 'conditional-probability', 'bayes-theorem']"
79,Limsup of random variables vs limsup of events,Limsup of random variables vs limsup of events,,"In 2.7 of this notes, it is shown that, using Borel-Cantelli lemma, if $E_n = \left\{\frac{X_n}{\log n} \geq 1\right\}$ then $\mathbb{P}(\limsup \ E_n) = 1$ but why does author conclude that if $Y = \limsup \frac{X_n}{\log n}$ , then $\mathbb{P}(Y \geq 1) = 1$ ? My question is Borel-cantelli lemma says events $\limsup$ of some events is 0 or 1, but in most books and online notes, an event in terms of random variable $\limsup X_n$ concluded to have probability 0 or 1. Can someone clarify the confusion ?","In 2.7 of this notes, it is shown that, using Borel-Cantelli lemma, if then but why does author conclude that if , then ? My question is Borel-cantelli lemma says events of some events is 0 or 1, but in most books and online notes, an event in terms of random variable concluded to have probability 0 or 1. Can someone clarify the confusion ?",E_n = \left\{\frac{X_n}{\log n} \geq 1\right\} \mathbb{P}(\limsup \ E_n) = 1 Y = \limsup \frac{X_n}{\log n} \mathbb{P}(Y \geq 1) = 1 \limsup \limsup X_n,"['probability', 'probability-theory']"
80,Probability that the sum of the numbers shown is a multiple of $5$,Probability that the sum of the numbers shown is a multiple of,5,"A regular die is rolled $n$ times such that $5|n$ . Probability such that the sum of the numbers shown is a multiple of $5$ is given by $$\frac{a^n+b}{c\cdot d^n}.$$ Find $a,b,c$ and $d$ . What I thought is that we need to find coefficient of all those exponents of $x$ which are multiples of $5$ in the expansion of $(x+x^2+....+ x^6)^n$ . Thereafter I am unable to solve it further.",A regular die is rolled times such that . Probability such that the sum of the numbers shown is a multiple of is given by Find and . What I thought is that we need to find coefficient of all those exponents of which are multiples of in the expansion of . Thereafter I am unable to solve it further.,"n 5|n 5 \frac{a^n+b}{c\cdot d^n}. a,b,c d x 5 (x+x^2+....+ x^6)^n","['probability', 'binomial-coefficients']"
81,A Law of Large Numbers for Conditional Expectations,A Law of Large Numbers for Conditional Expectations,,"Let $(\Omega,\mathcal F,P)$ be a probability space, and suppose that we are given, for each $\gamma \in[0,1]$ , an iid sequence of real integrable random variables $\{X_n(\gamma)\}_{n=1}^\infty$ . Let $Y$ be a random variable taking values in $[0,1]$ which is independent from $X_n(\gamma)$ for all $n,\gamma$ . How can I show that $$\frac{1}{n}\sum_{k=1}^n X_k(Y)\to E[X_n(Y)| \sigma(Y)] \,\,\text{ as } \,\,n\to \infty$$ in probability? EDIT: Assume the following additional condition: for all $\delta>0$ we have $$\sup_{\gamma\in[0,1]} P\bigg(\bigg|\frac{1}{n}\sum_{k=1}^n \Big(X_k(\gamma)-E[X_k(\gamma)] \Big) \bigg|>\delta\bigg)\to 0 \,\,\text{ as } \,\,n\to \infty.$$","Let be a probability space, and suppose that we are given, for each , an iid sequence of real integrable random variables . Let be a random variable taking values in which is independent from for all . How can I show that in probability? EDIT: Assume the following additional condition: for all we have","(\Omega,\mathcal F,P) \gamma \in[0,1] \{X_n(\gamma)\}_{n=1}^\infty Y [0,1] X_n(\gamma) n,\gamma \frac{1}{n}\sum_{k=1}^n X_k(Y)\to E[X_n(Y)| \sigma(Y)] \,\,\text{ as } \,\,n\to \infty \delta>0 \sup_{\gamma\in[0,1]} P\bigg(\bigg|\frac{1}{n}\sum_{k=1}^n \Big(X_k(\gamma)-E[X_k(\gamma)] \Big) \bigg|>\delta\bigg)\to 0 \,\,\text{ as } \,\,n\to \infty.","['probability', 'probability-theory', 'measure-theory', 'ergodic-theory', 'law-of-large-numbers']"
82,"From game RNG to statistics, how to calculate the expected outcome?","From game RNG to statistics, how to calculate the expected outcome?",,"Description I play a war turn-based game, where attacks only have two variables that are visible before a strike: The attacker's military strength $f_{a}$ and the defender's military strength $f_{d}$ . Whether an attack is successful or not is determined by a series of $3$ rolls . Each roll the attacker and defender will be given a random ( uniform ) multiplier $r_{a}$ and $r_{d}$ respectively, where $$0.4<r<1.0$$ For a roll to be successful this must hold: $$f_{a}r_{a}>f_{d}r_{d}$$ At the end of all $3$ rolls the resulting Victory Type will be determined as follows: Rolls Won $3$ / $3$ $2$ / $3$ $1$ / $3$ $0$ / $3$ Victory Type Immense Triumph (I) Moderate Victory (M) Pyrrhic Victory (P) Utter Failure (U) Casualties are also calculated through the rolls, in each roll the attacker's and defender's casualties are given respectively by $$c_{a} = 0.01·f_{d}r_{d} \,\,\,\,\,\,\,\,\,\,\,\, c_{d} = 0.018337·f_{a}r_{a}$$ Importantly, casualties are only applied after all rolls, therefor all rolls are independent events . At the end of the 3 rolls, the number of casualties is rounded to the nearest integer. What I have worked out My knowledge in statistics isn't great, but through experimentation and some intuition I managed to ( after a while ) find that for a given $f_{a}$ and $f_{d}$ where $f_{a} < f_{d}$ the probability of a successful roll can be given by: $$P(f_{a}r_{a}>f_{d}r_{d})=\int_{0}^{1}{\frac{1}{0.6}\int_{0.4}^{max(\frac{f_{a}}{f_{d}}x,\,\,0.4)}{\frac{1}{0.6}\,dt}\,dx}$$ Which can be simplified to: $$P(f_{a}r_{a}>f_{d}r_{d})=\frac{25}{9}\left ( \frac{2f_{d}}{25f_{a}} + \frac{f_{a}}{2f_{d}} - \frac{2}{5} \right )$$ And thus, if $p$ is the probabilty of a successful roll, the probabilities for each victory type given $f_{a} < f_{d}$ are as follows: $$I=\begin{pmatrix}3\\3\end{pmatrix}p^{3}(1-p)^{0}$$ $$M=\begin{pmatrix}3\\2\end{pmatrix}p^{2}(1-p)^{1}$$ $$P=\begin{pmatrix}3\\1\end{pmatrix}p^{1}(1-p)^{2}$$ $$U=\begin{pmatrix}3\\0\end{pmatrix}p^{0}(1-p)^{3}$$ What I haven't worked out So all of this leads me to my question, I have been trying to figure out what the expected number of casualties is for a specified victory type, that is, given $f_{a}$ and $f_{d}$ where $f_{a} < f_{d}$ what are the $E(C_{a}\mid I)$ , $E(C_{d}\mid I)$ , $E(C_{a}\mid M)$ , $E(C_{d}\mid M)$ and so on... So far I understand that if I were to set $r_{a}=1$ this would be true (or at least I think): $$E(C_{a}\mid I) = 3\int_{0.4}^{\frac{f_{a}}{f_{d}}}{\frac{1}{\frac{f_{a}}{f_{d}}-0.4}\,\frac{f_{d}r_{d}}{100}\,dr_{d}}$$ However given that the bounds of $r_{a}$ are dependent on $r_{d}$ and vise versa, since all the possible rolls that would result in a successful roll must follow these: $$0.4<r_{d}<\frac{f_{a}}{f_{d}}r_{a}$$ $$\frac{f_{d}}{f_{a}r_{d}}0.4<r_{a}<1$$ I have not been able to figure out how to calculates these expected values when both $r_{a}$ and $r_{d}$ are free to take all possible values they can. Double checking If anyone knows the solution, I wrote a little Python script that ran through the same scenario $1\times 10^{8}$ times where $f_{a}=3000$ and $f_{d}=4500$ and these were the results: Victory Type Immense Triumph (I) Moderate Victory (M) Pyrrhic Victory (P) Utter Failure (U) Total Outcomes $325513$ $5608873$ $32249407$ $61816207$ Total Attackers Casualties $21321676$ $429922319$ $2831691198$ $6117015520$ Average Attackers Casualties $65.5018$ $76.6504$ $87.8060$ $98.9549$ Total Defenders Casualties $46393770$ $739083939$ $3902378593$ $6814545685$ Average Defenders Casualties $142.5251$ $131.7705$ $121.0062$ $110.2388$ So whatever the right formula is, when $f_{a}=3000$ and $f_{d}=4500$ the expected casualties should match the averages computed above.","Description I play a war turn-based game, where attacks only have two variables that are visible before a strike: The attacker's military strength and the defender's military strength . Whether an attack is successful or not is determined by a series of rolls . Each roll the attacker and defender will be given a random ( uniform ) multiplier and respectively, where For a roll to be successful this must hold: At the end of all rolls the resulting Victory Type will be determined as follows: Rolls Won / / / / Victory Type Immense Triumph (I) Moderate Victory (M) Pyrrhic Victory (P) Utter Failure (U) Casualties are also calculated through the rolls, in each roll the attacker's and defender's casualties are given respectively by Importantly, casualties are only applied after all rolls, therefor all rolls are independent events . At the end of the 3 rolls, the number of casualties is rounded to the nearest integer. What I have worked out My knowledge in statistics isn't great, but through experimentation and some intuition I managed to ( after a while ) find that for a given and where the probability of a successful roll can be given by: Which can be simplified to: And thus, if is the probabilty of a successful roll, the probabilities for each victory type given are as follows: What I haven't worked out So all of this leads me to my question, I have been trying to figure out what the expected number of casualties is for a specified victory type, that is, given and where what are the , , , and so on... So far I understand that if I were to set this would be true (or at least I think): However given that the bounds of are dependent on and vise versa, since all the possible rolls that would result in a successful roll must follow these: I have not been able to figure out how to calculates these expected values when both and are free to take all possible values they can. Double checking If anyone knows the solution, I wrote a little Python script that ran through the same scenario times where and and these were the results: Victory Type Immense Triumph (I) Moderate Victory (M) Pyrrhic Victory (P) Utter Failure (U) Total Outcomes Total Attackers Casualties Average Attackers Casualties Total Defenders Casualties Average Defenders Casualties So whatever the right formula is, when and the expected casualties should match the averages computed above.","f_{a} f_{d} 3 r_{a} r_{d} 0.4<r<1.0 f_{a}r_{a}>f_{d}r_{d} 3 3 3 2 3 1 3 0 3 c_{a} = 0.01·f_{d}r_{d} \,\,\,\,\,\,\,\,\,\,\,\, c_{d} = 0.018337·f_{a}r_{a} f_{a} f_{d} f_{a} < f_{d} P(f_{a}r_{a}>f_{d}r_{d})=\int_{0}^{1}{\frac{1}{0.6}\int_{0.4}^{max(\frac{f_{a}}{f_{d}}x,\,\,0.4)}{\frac{1}{0.6}\,dt}\,dx} P(f_{a}r_{a}>f_{d}r_{d})=\frac{25}{9}\left ( \frac{2f_{d}}{25f_{a}} + \frac{f_{a}}{2f_{d}} - \frac{2}{5} \right ) p f_{a} < f_{d} I=\begin{pmatrix}3\\3\end{pmatrix}p^{3}(1-p)^{0} M=\begin{pmatrix}3\\2\end{pmatrix}p^{2}(1-p)^{1} P=\begin{pmatrix}3\\1\end{pmatrix}p^{1}(1-p)^{2} U=\begin{pmatrix}3\\0\end{pmatrix}p^{0}(1-p)^{3} f_{a} f_{d} f_{a} < f_{d} E(C_{a}\mid I) E(C_{d}\mid I) E(C_{a}\mid M) E(C_{d}\mid M) r_{a}=1 E(C_{a}\mid I) = 3\int_{0.4}^{\frac{f_{a}}{f_{d}}}{\frac{1}{\frac{f_{a}}{f_{d}}-0.4}\,\frac{f_{d}r_{d}}{100}\,dr_{d}} r_{a} r_{d} 0.4<r_{d}<\frac{f_{a}}{f_{d}}r_{a} \frac{f_{d}}{f_{a}r_{d}}0.4<r_{a}<1 r_{a} r_{d} 1\times 10^{8} f_{a}=3000 f_{d}=4500 325513 5608873 32249407 61816207 21321676 429922319 2831691198 6117015520 65.5018 76.6504 87.8060 98.9549 46393770 739083939 3902378593 6814545685 142.5251 131.7705 121.0062 110.2388 f_{a}=3000 f_{d}=4500","['probability', 'statistics', 'bayes-theorem']"
83,Finding the probability density function of the $n$th largest random variable.,Finding the probability density function of the th largest random variable.,n,"Let $X_1,...,X_{25}$ be independent Unif $[0,1]$ random variables. Let $Y$ be the $13$ th largest of the $25$ random variables. Find the probability density function of $Y$ . I already know the answer for this one, but the answer that was provided just told me to use a formula to get the answer without much explanation as to why I should use that formula. This was the answer I was given: Formula: $g(x_\gamma)=\frac{n!}{(\gamma-1)!(n-\gamma)!}[F(x)]^{\gamma-1}\cdot f(x)\cdot[1-F(x)]^{n-\gamma}$ Then since $X_1,X_2,\ldots,X_{25}\sim Unif[0,1]$ , we have $$ f(x)= \begin{cases}  1 & \text{if } 0\leq x\leq 1 \\ 0 & \text{otherwise} \end{cases} $$ and $$ F(x)=\int^x_01~dx= \begin{cases} 0 & \text{if } x<0\\ x & \text{if } 0\leq x\leq 1\\ 1 &\text{if } x>1 \end{cases} $$ Then $Y=X_{(13)}$ so $$f(y)=\frac{25!}{(13-1)!(25-13)!}(x)^{13-1}\cdot1\cdot(1-x)^{25-13}$$ $$={^{25}C_{13}}13(x)^{12}(1-x)^{12}$$ Thus, the p.d.f. is $$ g(Y)= \begin{cases} {^{25}C_{13}}13(x)^{12}(1-x)^{12} & \text{if } 0\leq x\leq 1\\ 0 & \text{otherwise} \end{cases} $$ Could I get an explanation of why I should use this formula or if there is another way to get the answer that is more clear? Thank you.","Let be independent Unif random variables. Let be the th largest of the random variables. Find the probability density function of . I already know the answer for this one, but the answer that was provided just told me to use a formula to get the answer without much explanation as to why I should use that formula. This was the answer I was given: Formula: Then since , we have and Then so Thus, the p.d.f. is Could I get an explanation of why I should use this formula or if there is another way to get the answer that is more clear? Thank you.","X_1,...,X_{25} [0,1] Y 13 25 Y g(x_\gamma)=\frac{n!}{(\gamma-1)!(n-\gamma)!}[F(x)]^{\gamma-1}\cdot f(x)\cdot[1-F(x)]^{n-\gamma} X_1,X_2,\ldots,X_{25}\sim Unif[0,1] 
f(x)=
\begin{cases} 
1 & \text{if } 0\leq x\leq 1 \\
0 & \text{otherwise}
\end{cases}
 
F(x)=\int^x_01~dx=
\begin{cases}
0 & \text{if } x<0\\
x & \text{if } 0\leq x\leq 1\\
1 &\text{if } x>1
\end{cases}
 Y=X_{(13)} f(y)=\frac{25!}{(13-1)!(25-13)!}(x)^{13-1}\cdot1\cdot(1-x)^{25-13} ={^{25}C_{13}}13(x)^{12}(1-x)^{12} 
g(Y)=
\begin{cases}
{^{25}C_{13}}13(x)^{12}(1-x)^{12} & \text{if } 0\leq x\leq 1\\
0 & \text{otherwise}
\end{cases}
","['probability', 'probability-distributions', 'uniform-distribution', 'density-function', 'order-statistics']"
84,How to split a pot of $100 when a game of flipping coins until first person gets 10 heads is interrupted.(A variation of the points problem),How to split a pot of $100 when a game of flipping coins until first person gets 10 heads is interrupted.(A variation of the points problem),,"Question : Andy and Beth are playing a game worth $100. They take turns flipping a penny. The first person to get 10 heads will win. But they just realized that they have to be in math class right away and are forced to stop the game. Andy had four heads and Beth had seven heads. How should they divide the pot? This is a question from the book Probability: With Applications and R by Robert P. Dobrow .Now the given answer is : P(Andy wins) = 0.1445. Andy gets $14.45 \;and\; Beth\; gets\; $ 85.55 But I am not getting this answer . So can someone check my solution and tell me where I am wrong , or else provide a better solution . Thanks in advance. Proposed Solution : Let Andy be A and Beth B:  A needs 6 heads to win, and B needs 3 heads to win. Let $X_a$ be the number of times A needs to flip the coin to get 6 wins , and $X_b$ be the number of flips for B to get 3 wins . Both $X_a$ and $X_b$ are Negative Binomial Variables with the $X_a$ having parameters 6 and $p=\frac{1}{2}$ and $X_b$ having parameters 3 and $p=\frac{1}{2}$ . Now if A needs $k$ flips to win. Then the required probability is : $P(A \;wins) = P(X_a = k)*P(X_b > k)$ (i.e A wins in $k$ moves and B gets 3 heads after $k$ flips) $P(X_a = k)=(^{k-1}C_5)*(\frac{1}{2})^6(\frac{1}{2})^{k-6}=(^{k-1}C_5)*(\frac{1}{2})^k$ (Negative Binomial Distribution formula) $P(X_b > k) =$ The 3rd head should come after $k$ trails , therefore until $k$ trails only $0\;or\;1\;or\;2$ heads can occur. Therefore : $P(X_b>k) = \sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^i(\frac{1}{2})^{k-i}=\sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^k$ So $P(A\;wins) = (^{k-1}C_5*(\frac{1}{2})^k) * (\sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^k) $ . Now minimum 6 tries are required for A to win, so $k:6 \to \infty$ $\begin{equation} P(A\;wins) = \sum_{k=6}^{\infty}\biggl( (^{k-1}C_5*(\frac{1}{2})^k) * (\sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^k) \biggr)  \\ = \sum_{k=6}^{\infty}\biggl((\frac{1}{2})^{2k}*(^{k-1}C_5)*(^kC_0+^kC_1+^kC_2)) \biggr) \\ =\sum_{k=6}^{\infty}\biggl(\frac{1}{2^{2k+1}}*(^{k-1}C_5)*(k^2+k+2)\biggr) \end{equation}$ Now I calculated the sum on my calculator for $k : 6 \to 150$ and it is converging to 0.052. Which is very far off from the given answer of $P(Andy\; wins) = 0.1445$ . So is my method wrong ? Or is the sum convergence slow ? Can someone solve this question , employing an entirely different method if necessary.","Question : Andy and Beth are playing a game worth $100. They take turns flipping a penny. The first person to get 10 heads will win. But they just realized that they have to be in math class right away and are forced to stop the game. Andy had four heads and Beth had seven heads. How should they divide the pot? This is a question from the book Probability: With Applications and R by Robert P. Dobrow .Now the given answer is : P(Andy wins) = 0.1445. Andy gets 85.55 But I am not getting this answer . So can someone check my solution and tell me where I am wrong , or else provide a better solution . Thanks in advance. Proposed Solution : Let Andy be A and Beth B:  A needs 6 heads to win, and B needs 3 heads to win. Let be the number of times A needs to flip the coin to get 6 wins , and be the number of flips for B to get 3 wins . Both and are Negative Binomial Variables with the having parameters 6 and and having parameters 3 and . Now if A needs flips to win. Then the required probability is : (i.e A wins in moves and B gets 3 heads after flips) (Negative Binomial Distribution formula) The 3rd head should come after trails , therefore until trails only heads can occur. Therefore : So . Now minimum 6 tries are required for A to win, so Now I calculated the sum on my calculator for and it is converging to 0.052. Which is very far off from the given answer of . So is my method wrong ? Or is the sum convergence slow ? Can someone solve this question , employing an entirely different method if necessary.","14.45 \;and\; Beth\; gets\;  X_a X_b X_a X_b X_a p=\frac{1}{2} X_b p=\frac{1}{2} k P(A \;wins) = P(X_a = k)*P(X_b > k) k k P(X_a = k)=(^{k-1}C_5)*(\frac{1}{2})^6(\frac{1}{2})^{k-6}=(^{k-1}C_5)*(\frac{1}{2})^k P(X_b > k) = k k 0\;or\;1\;or\;2 P(X_b>k) = \sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^i(\frac{1}{2})^{k-i}=\sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^k P(A\;wins) = (^{k-1}C_5*(\frac{1}{2})^k) * (\sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^k)  k:6 \to \infty \begin{equation}
P(A\;wins) = \sum_{k=6}^{\infty}\biggl( (^{k-1}C_5*(\frac{1}{2})^k) * (\sum_{i=0}^2{^{k}C_i}*(\frac{1}{2})^k) \biggr) 
\\
= \sum_{k=6}^{\infty}\biggl((\frac{1}{2})^{2k}*(^{k-1}C_5)*(^kC_0+^kC_1+^kC_2)) \biggr)
\\
=\sum_{k=6}^{\infty}\biggl(\frac{1}{2^{2k+1}}*(^{k-1}C_5)*(k^2+k+2)\biggr)
\end{equation} k : 6 \to 150 P(Andy\; wins) = 0.1445","['probability', 'probability-distributions', 'negative-binomial']"
85,"Knowing that the first test was positive, what is the probability the second test will be positive?","Knowing that the first test was positive, what is the probability the second test will be positive?",,"Suppose that 5% of the employees of a certain company use illegal drugs. The company performs random drug tests that return positive results 98% of the time if the person is a drug user. However, it also has a 4% false-positive rate. The results of the test are independent from test to test for a given person. An employee at the company has a positive test. What is the probability that he uses drugs? Knowing that the first test was positive, what is the probability the second test will be positive? Suppose that the second test is also positive. What is the probability he uses drugs? My Attempt This one is straightforward.. From the problem, we know $$\mathbb{P}(positive|\;uses\;drugs)=0.98$$ $$\mathbb{P}(uses\;drugs)=0.05$$ $$\mathbb{P}(positive|doesn't\;use\;drugs)=0.04$$ $$\mathbb{P}(doesn't\;use\;drugs)=0.95$$ Then using Baye's Theorem, we have $$\mathbb{P}(Uses\;drugs)=\frac{(0.98)(0.05)}{(0.98)(0.05)+(0.04)(0.95)}=0.56$$ For this one, we are trying to find $\mathbb{P}(Second\;positive|first\;positive)$ . Since the results are independent from each other, we know that $\mathbb{P}(Second\;positive|first\;positive)=\mathbb{P}(second\;positive)$ . Would this mean that the second test being positive has the same probability as the first one? Intuitively, I would think that the probability is the same because the events are independent of each other, but I am not sure how to prove this. Edit: I think I can use the definition of conditional probability and the law of total probability to solve this problem. What I had above is wrong. I can use the following to solve: $$\mathbb{P}(B\;|\;A)= \frac{\mathbb{P}(B\cap A)}{\mathbb{P}(A)}= \frac{\mathbb{P}(B\cap A\;|\;D)\mathbb{P}(D)+\mathbb{P}(B\cap A\;|\;D^c)\mathbb{P}(D^c)}{\mathbb{P}(A\;|\;D)\mathbb{P}(D)+\mathbb{P}(A\;|\;D^c)\mathbb{P}(D^c)}$$ For this one, I am trying to find $\mathbb{P}(Uses\;drugs|first\;positive\;\cap\;second\; positive)$ . I think I can use Baye's rule for this one again and the definition of conditional independence.","Suppose that 5% of the employees of a certain company use illegal drugs. The company performs random drug tests that return positive results 98% of the time if the person is a drug user. However, it also has a 4% false-positive rate. The results of the test are independent from test to test for a given person. An employee at the company has a positive test. What is the probability that he uses drugs? Knowing that the first test was positive, what is the probability the second test will be positive? Suppose that the second test is also positive. What is the probability he uses drugs? My Attempt This one is straightforward.. From the problem, we know Then using Baye's Theorem, we have For this one, we are trying to find . Since the results are independent from each other, we know that . Would this mean that the second test being positive has the same probability as the first one? Intuitively, I would think that the probability is the same because the events are independent of each other, but I am not sure how to prove this. Edit: I think I can use the definition of conditional probability and the law of total probability to solve this problem. What I had above is wrong. I can use the following to solve: For this one, I am trying to find . I think I can use Baye's rule for this one again and the definition of conditional independence.",\mathbb{P}(positive|\;uses\;drugs)=0.98 \mathbb{P}(uses\;drugs)=0.05 \mathbb{P}(positive|doesn't\;use\;drugs)=0.04 \mathbb{P}(doesn't\;use\;drugs)=0.95 \mathbb{P}(Uses\;drugs)=\frac{(0.98)(0.05)}{(0.98)(0.05)+(0.04)(0.95)}=0.56 \mathbb{P}(Second\;positive|first\;positive) \mathbb{P}(Second\;positive|first\;positive)=\mathbb{P}(second\;positive) \mathbb{P}(B\;|\;A)= \frac{\mathbb{P}(B\cap A)}{\mathbb{P}(A)}= \frac{\mathbb{P}(B\cap A\;|\;D)\mathbb{P}(D)+\mathbb{P}(B\cap A\;|\;D^c)\mathbb{P}(D^c)}{\mathbb{P}(A\;|\;D)\mathbb{P}(D)+\mathbb{P}(A\;|\;D^c)\mathbb{P}(D^c)} \mathbb{P}(Uses\;drugs|first\;positive\;\cap\;second\; positive),"['probability', 'statistics', 'conditional-probability', 'independence', 'bayes-theorem']"
86,Throwing a $6$ in the $n+1$th throw,Throwing a  in the th throw,6 n+1,"A fair die is thrown repeatedly until a six appears for the first time. Let $A_n$ be the event that a six appears for the first time on the $n$ -th throw. Let $B_r$ be the event that a five appears $r$ times before a six appears for the first time. a) Explain why $$\operatorname{Pr}(B_r)=\sum_{n=r}^{\infty}\operatorname{Pr}(A_{n+1})\operatorname{Pr}(B_r \mid A_{n+1})$$ b) Using a), show that $$\operatorname{Pr}(B_r)=\left(\frac{1}{2}\right)^{r+1}$$ I have tried to expand the summation, but I keep on getting $(\frac{1}{6})^{r}$ and the expansion is something like $$\binom{n}{r} \left(\frac{1}{6}\right)^{r} \frac{1}{6}+ \binom{n+1}{r} \left(\frac{1}{6}\right)^{r} \frac{1}{6} \frac{4}{6}+ \cdot \cdot \cdot$$ but I have no idea how to simplify. I am totally stuck on b), any help is appreciated thank you.","A fair die is thrown repeatedly until a six appears for the first time. Let be the event that a six appears for the first time on the -th throw. Let be the event that a five appears times before a six appears for the first time. a) Explain why b) Using a), show that I have tried to expand the summation, but I keep on getting and the expansion is something like but I have no idea how to simplify. I am totally stuck on b), any help is appreciated thank you.",A_n n B_r r \operatorname{Pr}(B_r)=\sum_{n=r}^{\infty}\operatorname{Pr}(A_{n+1})\operatorname{Pr}(B_r \mid A_{n+1}) \operatorname{Pr}(B_r)=\left(\frac{1}{2}\right)^{r+1} (\frac{1}{6})^{r} \binom{n}{r} \left(\frac{1}{6}\right)^{r} \frac{1}{6}+ \binom{n+1}{r} \left(\frac{1}{6}\right)^{r} \frac{1}{6} \frac{4}{6}+ \cdot \cdot \cdot,['probability']
87,Finding maximum likelihood estimate under certain conditions,Finding maximum likelihood estimate under certain conditions,,"Let $X_1, \ldots X_n$ be an i.i.d. sample from the p.d.f. $f(x; \theta) = 1 + \theta(1 - 2x)$ for $0 \leq x \leq 1$ and $0$ otherwise where $-1 \leq \theta \leq 1$ . (a) Show $\theta_{mle}$ , the maximum likelihood estimate of $\theta$ , exists and is unique. (b) What is $\theta_{mle}$ when $\sum_i \left(\frac{1}{X_i} - 2\right) \leq 0$ ? (c) What is $\theta_{mle}$ when $\sum_{i} ((1 - 2X_i)/(1 - X_i)) \geq 0$ ? I got the loglikelihood function is $\log(\prod_i (1 + \theta(1 - 2x_i))) = \sum_i \log(1 + \theta(1 - 2x_i))$ For $(a)$ , I thought that I need to show the second derivative of the expression above w.r.t. $\theta$ is strictly positive. I differentiated to get $\sum_i \frac{(1 - 2x_i)}{1 + \theta(1 - 2x_i)}$ , and I differentiated again to get $\sum_i -\frac{(1 - 2x_i)^2}{(1 + \theta(1 - 2x_i))^2}$ but this is always zero or negative. I'm also pretty clueless on $(b)$ and $(c)$ . I can see where the inequality might come into play since there's a $(1 - 2x_i)$ in the numerator for (c) but I'm entirely lost for (b). I tried equating the derivative of the log likelihood function to zero, but I can't figure out how to solve for $\theta$ . Any help is appreciated.","Let be an i.i.d. sample from the p.d.f. for and otherwise where . (a) Show , the maximum likelihood estimate of , exists and is unique. (b) What is when ? (c) What is when ? I got the loglikelihood function is For , I thought that I need to show the second derivative of the expression above w.r.t. is strictly positive. I differentiated to get , and I differentiated again to get but this is always zero or negative. I'm also pretty clueless on and . I can see where the inequality might come into play since there's a in the numerator for (c) but I'm entirely lost for (b). I tried equating the derivative of the log likelihood function to zero, but I can't figure out how to solve for . Any help is appreciated.","X_1, \ldots X_n f(x; \theta) = 1 + \theta(1 - 2x) 0 \leq x \leq 1 0 -1 \leq \theta \leq 1 \theta_{mle} \theta \theta_{mle} \sum_i \left(\frac{1}{X_i} - 2\right) \leq 0 \theta_{mle} \sum_{i} ((1 - 2X_i)/(1 - X_i)) \geq 0 \log(\prod_i (1 + \theta(1 - 2x_i))) = \sum_i \log(1 + \theta(1 - 2x_i)) (a) \theta \sum_i \frac{(1 - 2x_i)}{1 + \theta(1 - 2x_i)} \sum_i -\frac{(1 - 2x_i)^2}{(1 + \theta(1 - 2x_i))^2} (b) (c) (1 - 2x_i) \theta","['calculus', 'probability']"
88,"Best strategy for cheating in the ""cheating royal riddle""","Best strategy for cheating in the ""cheating royal riddle""",,"I watched a video awhile ago from Ted-Ed called the ""cheating royal riddle"": https://www.youtube.com/watch?v=hk9c7sJ08Bg . The riddle is as follows: You're the advisor in a competition where four contestants roll both dice 20 times, in private, and add up the results. The red die has the numbers 2, 7, 7, 12, 12, and 17 on the six sides, and the blue die has 3, 8, 8, 13, 13, and 18 . The dice are fair. A contestant should be disqualified by you, the advisor, if you're at least 90% sure that the score they reported wasn't actually their total. The highest-scoring player who wasn't disqualified is the winner. In the video, the contestants A , B , C , and D , reported values 385 , 840 , 700 , and 423 , respectively. B was disqualified for not being possible (too high). C was disqualified or being improbable (would require rolling highest numbers on all 20 rolls), and D was disqualified for not being possible (not a multiple of 5 ). A was the only one left not disqualified, so she won. My Question What would the optimal strategy look like for this game if you were one of the contestants and wanted to cheat and not be detected by the advisor? My first attempt is to honestly play the game mostly, but have a ""cheat"" round every 3 rounds, where I take the lowest number rolled and manually flip it to the highest number on that die. But I cannot figure out how to calculate the odds of that strategy on average. I guess there is perhaps a calculable number that you can just calculate and report, but it would be interesting to also know if there is an optimal strategy to ""play the game out"" and be very likely to score higher than your opponents but not too high as to exceed the advisor's 90% threshold for cheating; that strategy would work even if you were observed by a proctor. I guess if you ""play the game out"", there is always a possibility that you get extremely lucky and are disqualified for cheating even if you didn't, so any strategy to improve your odds will make that situation more likely, so perhaps the best strategy is to just calculate the number and report it to ensure you're right below the threshold of being disqualified. I'm working on a simulator for this just out of curiosity, but I figured I would ask here. I am new to this SE (normally on SO), but ""Solving mathematical puzzles"" showed up on the on-topic help ( https://math.stackexchange.com/help/on-topic ) for this SE, so I hope this is an appropriate place to put this question.","I watched a video awhile ago from Ted-Ed called the ""cheating royal riddle"": https://www.youtube.com/watch?v=hk9c7sJ08Bg . The riddle is as follows: You're the advisor in a competition where four contestants roll both dice 20 times, in private, and add up the results. The red die has the numbers 2, 7, 7, 12, 12, and 17 on the six sides, and the blue die has 3, 8, 8, 13, 13, and 18 . The dice are fair. A contestant should be disqualified by you, the advisor, if you're at least 90% sure that the score they reported wasn't actually their total. The highest-scoring player who wasn't disqualified is the winner. In the video, the contestants A , B , C , and D , reported values 385 , 840 , 700 , and 423 , respectively. B was disqualified for not being possible (too high). C was disqualified or being improbable (would require rolling highest numbers on all 20 rolls), and D was disqualified for not being possible (not a multiple of 5 ). A was the only one left not disqualified, so she won. My Question What would the optimal strategy look like for this game if you were one of the contestants and wanted to cheat and not be detected by the advisor? My first attempt is to honestly play the game mostly, but have a ""cheat"" round every 3 rounds, where I take the lowest number rolled and manually flip it to the highest number on that die. But I cannot figure out how to calculate the odds of that strategy on average. I guess there is perhaps a calculable number that you can just calculate and report, but it would be interesting to also know if there is an optimal strategy to ""play the game out"" and be very likely to score higher than your opponents but not too high as to exceed the advisor's 90% threshold for cheating; that strategy would work even if you were observed by a proctor. I guess if you ""play the game out"", there is always a possibility that you get extremely lucky and are disqualified for cheating even if you didn't, so any strategy to improve your odds will make that situation more likely, so perhaps the best strategy is to just calculate the number and report it to ensure you're right below the threshold of being disqualified. I'm working on a simulator for this just out of curiosity, but I figured I would ask here. I am new to this SE (normally on SO), but ""Solving mathematical puzzles"" showed up on the on-topic help ( https://math.stackexchange.com/help/on-topic ) for this SE, so I hope this is an appropriate place to put this question.",,"['probability', 'statistics', 'puzzle', 'game-theory']"
89,Whats the odds of getting my letters?,Whats the odds of getting my letters?,,"I am trying to find the odds of getting the letters I need. We start with 2 groups A B C D      A B C D E F G H      E F G H The group is random so its not always A..H in that order When you use a letter its taken out of the group. I can only take letters out that are in the first 4 (or top row) in the group. So if I took ""C"" then one letter from the 2nd row moves up into the ""C"" Positon. May look like this A B G D    A B E D E F H      F G H where a random letter is moved up , not always the same but can be in each group. My question is Whats the odds of both players being able to take A, B, C, D, E in that order from the top row with out skipping a turn. Not sure what Tag to add if you know please let me know and ill add it. Thanks","I am trying to find the odds of getting the letters I need. We start with 2 groups A B C D      A B C D E F G H      E F G H The group is random so its not always A..H in that order When you use a letter its taken out of the group. I can only take letters out that are in the first 4 (or top row) in the group. So if I took ""C"" then one letter from the 2nd row moves up into the ""C"" Positon. May look like this A B G D    A B E D E F H      F G H where a random letter is moved up , not always the same but can be in each group. My question is Whats the odds of both players being able to take A, B, C, D, E in that order from the top row with out skipping a turn. Not sure what Tag to add if you know please let me know and ill add it. Thanks",,"['probability', 'statistics']"
90,Zero probability condition: Thinking about '$P(H)=\int_{b \in \mathbb R}P(H|B=b)f_B(b)$',Zero probability condition: Thinking about '',P(H)=\int_{b \in \mathbb R}P(H|B=b)f_B(b),"Let $B$ be a continuous random variable. Let $H$ be an event. Am I right to think it does not necessarily make sense to say ' $P(H)=\int_{b \in \mathbb R}P(H|B=b)f_B(b)$ '? My guess: Well based on Wiki , I think yes, i.e. we cannot do this for just any $H$ because $P(H|B=b)$ need not be defined. Furthermore, even if we somehow define $P(H|B=b)$ , I think we'll still have to think about defining the integral $\int_{b \in \mathbb R}P(H|B=b)f_B(b)$ , depending on the definition of $P(H|B=b)$ . Is ' $P(H|B=b)$ ' well-defined if $H=\{Y \in U\}$ for any continuous random variable $Y$ s.t. $Y$ and $B$ have a continuous joint pdf and for any interval $U$ ? (I forgot if any 2 continuous random variables necessarily have a well-defined joint pdf. Also, I'm trying not think of $U$ as an arbitrary Borel set.) With the same conditions as in (2) and assuming the answer to (2) is affirmative, does it necessarily make sense to say $P(H)=\int_{b \in \mathbb R}P(H|B=b)f_B(b)$ , and is such equation correct? My guess: I believe it makes sense and then is correct: Pretend $U=(1,7)$ . Then: $LHS = P(H)=\int_1^7 f_Y(y) dy$ . $RHS= \int_{b \in \mathbb R}P(Y \in (1,7)|B=b)f_B(b) db = \int_{b \in \mathbb R} \int_1^7 f_{Y|B=b}(y) f_B(b) dy db = \int_{b \in \mathbb R} \int_1^7 f_{Y,B}(y,b) dy db$ Then pretend I know what Fubini's theorem is to get $=  \int_1^7 \int_{b \in \mathbb R} f_{Y,B}(y,b)  db dy$ $=  \int_1^7 f_{Y}(y) dy$ Re Fubini's theorem, is there a way to argue this at an elementary probability level?","Let be a continuous random variable. Let be an event. Am I right to think it does not necessarily make sense to say ' '? My guess: Well based on Wiki , I think yes, i.e. we cannot do this for just any because need not be defined. Furthermore, even if we somehow define , I think we'll still have to think about defining the integral , depending on the definition of . Is ' ' well-defined if for any continuous random variable s.t. and have a continuous joint pdf and for any interval ? (I forgot if any 2 continuous random variables necessarily have a well-defined joint pdf. Also, I'm trying not think of as an arbitrary Borel set.) With the same conditions as in (2) and assuming the answer to (2) is affirmative, does it necessarily make sense to say , and is such equation correct? My guess: I believe it makes sense and then is correct: Pretend . Then: . Then pretend I know what Fubini's theorem is to get Re Fubini's theorem, is there a way to argue this at an elementary probability level?","B H P(H)=\int_{b \in \mathbb R}P(H|B=b)f_B(b) H P(H|B=b) P(H|B=b) \int_{b \in \mathbb R}P(H|B=b)f_B(b) P(H|B=b) P(H|B=b) H=\{Y \in U\} Y Y B U U P(H)=\int_{b \in \mathbb R}P(H|B=b)f_B(b) U=(1,7) LHS = P(H)=\int_1^7 f_Y(y) dy RHS= \int_{b \in \mathbb R}P(Y \in (1,7)|B=b)f_B(b) db = \int_{b \in \mathbb R} \int_1^7 f_{Y|B=b}(y) f_B(b) dy db = \int_{b \in \mathbb R} \int_1^7 f_{Y,B}(y,b) dy db =  \int_1^7 \int_{b \in \mathbb R} f_{Y,B}(y,b)  db dy =  \int_1^7 f_{Y}(y) dy","['calculus', 'probability', 'probability-distributions', 'conditional-probability']"
91,Conditional Expectation: $E(X|Y) \geq Y$ and $E(Y|X) \geq X$ implies $X=Y$ a.e.,Conditional Expectation:  and  implies  a.e.,E(X|Y) \geq Y E(Y|X) \geq X X=Y,Suppose for random variables $X$ and $Y$ with finite expectation we he have $E(X|Y) \geq Y$ and $E(Y|X) \geq X$ .  We want to show that $X=Y$ almost everywhere. My attempt: Let $A \in \sigma(X)$ and $B \in \sigma(Y)$ .  Then we have $\int_B X = \int_B E(X | Y) \geq \int_B Y$ and $\int_A Y = \int_B E(Y | X) \geq \int_A X$ . My idea now is to consider sets of the form $\{X>a>Y\}$ for $a$ rational but I'm having trouble with getting the other variable involved.  The issue seems to be that $\{X>a\}$ is in $\sigma(X)$ but not necessarily in $\sigma(Y)$ and it seems like we cannot get the other inequality working.  Any help would be appreciated.,Suppose for random variables and with finite expectation we he have and .  We want to show that almost everywhere. My attempt: Let and .  Then we have and . My idea now is to consider sets of the form for rational but I'm having trouble with getting the other variable involved.  The issue seems to be that is in but not necessarily in and it seems like we cannot get the other inequality working.  Any help would be appreciated.,X Y E(X|Y) \geq Y E(Y|X) \geq X X=Y A \in \sigma(X) B \in \sigma(Y) \int_B X = \int_B E(X | Y) \geq \int_B Y \int_A Y = \int_B E(Y | X) \geq \int_A X \{X>a>Y\} a \{X>a\} \sigma(X) \sigma(Y),"['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'statistics']"
92,How to find the Expected height of a randomly built binary tree,How to find the Expected height of a randomly built binary tree,,"I would like to find out the Expected height of a binary tree where the insertions are based on a random function. I.e. for each node I visit, there is a $\frac{1}{2}$ probability of choosing right or left. I know that the following property holds for height $h$ , but it's difficult to add the probability: $$h_{tree}= 1+max(h_{left}, h_{right})$$ I think that this version/random tree differs from the random (search) tree mentioned in CLRS chapter 12.4, where you pick a random element from a sorted list $\{1,\dots, n\}$ and insert based on whether the visited node is greater or less than the inserted element. Because, here we choose each path on each visited node to be random. Note: the binary tree has all its elements at the leafs and internal nodes are only used for routing. //pseudocode insert(i, tree):     if at leaf v:         split(); //Create a parent u and set its children to be the leaf v and element i.     else:         int left = random()         int right = random()         if (left > right):             insert(i, left-subtree):         else:             insert(i, right-subtree) See this figure (also in the link on CS stackexhange - https://cs.stackexchange.com/questions/136582/how-to-find-the-expected-height-of-a-randomly-built-binary-tree )","I would like to find out the Expected height of a binary tree where the insertions are based on a random function. I.e. for each node I visit, there is a probability of choosing right or left. I know that the following property holds for height , but it's difficult to add the probability: I think that this version/random tree differs from the random (search) tree mentioned in CLRS chapter 12.4, where you pick a random element from a sorted list and insert based on whether the visited node is greater or less than the inserted element. Because, here we choose each path on each visited node to be random. Note: the binary tree has all its elements at the leafs and internal nodes are only used for routing. //pseudocode insert(i, tree):     if at leaf v:         split(); //Create a parent u and set its children to be the leaf v and element i.     else:         int left = random()         int right = random()         if (left > right):             insert(i, left-subtree):         else:             insert(i, right-subtree) See this figure (also in the link on CS stackexhange - https://cs.stackexchange.com/questions/136582/how-to-find-the-expected-height-of-a-randomly-built-binary-tree )","\frac{1}{2} h h_{tree}= 1+max(h_{left}, h_{right}) \{1,\dots, n\}","['probability', 'algorithms', 'computer-science', 'expected-value', 'algorithmic-randomness']"
93,"Conditions for which $P(Y\le Y'|X,Z,X',Z') = P(Y\le Y'|Z,Z')$",Conditions for which,"P(Y\le Y'|X,Z,X',Z') = P(Y\le Y'|Z,Z')","Given two independent draws $(X,Z,Y)$ and $(X',Z',Y')$ from some distribution $P$ , I would like to understand under which conditions does the following hold: $$ P(Y\le Y'|X,Z,X',Z') = P(Y\le Y'|Z,Z'). $$ This clearly holds when $X \perp Y | Z$ for example, but I want to be able to say that the above statement holds if and only if some condition is met.","Given two independent draws and from some distribution , I would like to understand under which conditions does the following hold: This clearly holds when for example, but I want to be able to say that the above statement holds if and only if some condition is met.","(X,Z,Y) (X',Z',Y') P 
P(Y\le Y'|X,Z,X',Z') = P(Y\le Y'|Z,Z').
 X \perp Y | Z","['probability', 'probability-theory', 'conditional-probability']"
94,Calculation of Confidence Interval,Calculation of Confidence Interval,,"We randomly choose 1000 people and run a survey on whether they prefer Apples or Berries. The results are $71\%$ for Apples and $29\%$ for Berries. We want to calculate the Margin of error of the poll, with confidence level $90\%$ . My attempt, as I have just started to study probability and statistics (out of personal interest - I am not a student): For confidence level of $90\%$ , we get the value of $z = 1.645$ . So the MOE is $z*\sqrt{\frac{p(1-p)}{n}} = 1.645*\sqrt{\frac{0.71(0.29)}{1000}} = 2.36\%$ ? Thank you!","We randomly choose 1000 people and run a survey on whether they prefer Apples or Berries. The results are for Apples and for Berries. We want to calculate the Margin of error of the poll, with confidence level . My attempt, as I have just started to study probability and statistics (out of personal interest - I am not a student): For confidence level of , we get the value of . So the MOE is ? Thank you!",71\% 29\% 90\% 90\% z = 1.645 z*\sqrt{\frac{p(1-p)}{n}} = 1.645*\sqrt{\frac{0.71(0.29)}{1000}} = 2.36\%,['probability']
95,Estimate the number of sides of the die,Estimate the number of sides of the die,,"Suppose you have a fair die with an unknown number of sides, $T$ . Each side is distinct, marked with a complex symbol. Given enough rolls, can you estimate $T$ ? My intuition is that can do this via a generalization of the mark and recapture procedure . Roll the die some large number of times, keeping track of all the sides that you have rolled and the number of times you have rolled them. Since the probability of rolling a previously rolled side in $N$ rolls is completely determined by $N$ and $T$ , then expected proportion of unique to total sides $p$ should also be determined by $N$ and $T$ . What is the relationship between $p$ , $N$ , and $T$ ? As pointed out by Don Thousand, you can save yourself a lot of overhead and just track one arbitrarily picked side. Since the probability of rolling the chosen side on any one roll is $T^{-1}$ , you expect that you would see the side repeated $NT^{-1}$ times. You can use standard statistical techniques to determine how precise this estimate likely is. If you have reasonably strong priors about the likely size of the population, within an order of magnitude or so, you can probably figure out how big of an $N$ you need to satisfy your requirements. However, this procedure is inefficient, since we will likely have re-rolls of sides other than the one we have picked. The frequency of those re-rolls is almost equally as informative. How can we combine all the information we have to arrive at an estimate for $T$ ?","Suppose you have a fair die with an unknown number of sides, . Each side is distinct, marked with a complex symbol. Given enough rolls, can you estimate ? My intuition is that can do this via a generalization of the mark and recapture procedure . Roll the die some large number of times, keeping track of all the sides that you have rolled and the number of times you have rolled them. Since the probability of rolling a previously rolled side in rolls is completely determined by and , then expected proportion of unique to total sides should also be determined by and . What is the relationship between , , and ? As pointed out by Don Thousand, you can save yourself a lot of overhead and just track one arbitrarily picked side. Since the probability of rolling the chosen side on any one roll is , you expect that you would see the side repeated times. You can use standard statistical techniques to determine how precise this estimate likely is. If you have reasonably strong priors about the likely size of the population, within an order of magnitude or so, you can probably figure out how big of an you need to satisfy your requirements. However, this procedure is inefficient, since we will likely have re-rolls of sides other than the one we have picked. The frequency of those re-rolls is almost equally as informative. How can we combine all the information we have to arrive at an estimate for ?",T T N N T p N T p N T T^{-1} NT^{-1} N T,"['probability', 'sampling']"
96,Linear combination of random variables and independence,Linear combination of random variables and independence,,"Given a set of real-valued normally distributed random variables $X_1, \dots, X_n$ , how do we show the following are equivalent? Any linear combination of $X_1, \dots, X_n$ is normally distributed There is a linear mapping $A$ such that the transformed random variables $AX_1, \dots, AX_n$ are independent Motivation: I want to reconcile two definitions of jointly Gaussian random variables. I believe a set of scalar Gaussian rvs $\{X_i\}$ can be shown jointly Gaussian under two characterizations: 1) $\{X_i\}$ are independent under some linear transformation, or 2) all linear combinations of $\{X_i\}$ are Gaussian-distributed. I don't know why these are equivalent, or how to prove this property for a given set of rvs $\{X_i\}$ . Edit: if the covariance matrix is known, how does this help? I think one case where 1 and 2 don't hold is if the covariance is singular.","Given a set of real-valued normally distributed random variables , how do we show the following are equivalent? Any linear combination of is normally distributed There is a linear mapping such that the transformed random variables are independent Motivation: I want to reconcile two definitions of jointly Gaussian random variables. I believe a set of scalar Gaussian rvs can be shown jointly Gaussian under two characterizations: 1) are independent under some linear transformation, or 2) all linear combinations of are Gaussian-distributed. I don't know why these are equivalent, or how to prove this property for a given set of rvs . Edit: if the covariance matrix is known, how does this help? I think one case where 1 and 2 don't hold is if the covariance is singular.","X_1, \dots, X_n X_1, \dots, X_n A AX_1, \dots, AX_n \{X_i\} \{X_i\} \{X_i\} \{X_i\}","['probability', 'probability-distributions', 'random-variables', 'independence']"
97,Probabilistic recursion,Probabilistic recursion,,"I have the following recursion: $$p_{t+1} = \begin{cases} 1 \text{ with probability } 1-p_t \\ \alpha p_t \text{ with probability } p_t \end{cases}$$ for $0<\alpha<1$ . Numerical simulations show that $\mathbb{E}[p_t]$ converges to a steady-state value as $t\rightarrow \infty$ , irrespective of the initial condition, only dependent on $\alpha$ . I'm not sure how to approach solving it in closed-form. It seems like it should be possible. I have tried solving it by imposing a self-consistent condition, i.e. $$\mathbb{E}[p_{\infty}] = \begin{cases} 1 \text{ with probability } 1-\mathbb{E}[p_{\infty}] \\ \alpha \mathbb{E}[p_{\infty}] \text{ with probability } \mathbb{E}[p_{\infty}] \end{cases}$$ I'm not sure if this or the next step is valid, I can neither justify it nor state exactly what's going wrong (but something is wrong, as the answer I get does not match my simuluations). Setting $\mathbb{E}[p_{\infty}] = 1\cdot(1-\mathbb{E}[p_{\infty}]) + \alpha \mathbb{E}[p_{\infty}] \cdot \mathbb{E}[p_{\infty}]$ and solving for $\mathbb{E}[p_{\infty}]$ gives a value which is different from simulations. Can someone provide a solution or a resource for solving such probabilistic recurrences, or let me know where I'm going wrong and how to proceed?","I have the following recursion: for . Numerical simulations show that converges to a steady-state value as , irrespective of the initial condition, only dependent on . I'm not sure how to approach solving it in closed-form. It seems like it should be possible. I have tried solving it by imposing a self-consistent condition, i.e. I'm not sure if this or the next step is valid, I can neither justify it nor state exactly what's going wrong (but something is wrong, as the answer I get does not match my simuluations). Setting and solving for gives a value which is different from simulations. Can someone provide a solution or a resource for solving such probabilistic recurrences, or let me know where I'm going wrong and how to proceed?",p_{t+1} = \begin{cases} 1 \text{ with probability } 1-p_t \\ \alpha p_t \text{ with probability } p_t \end{cases} 0<\alpha<1 \mathbb{E}[p_t] t\rightarrow \infty \alpha \mathbb{E}[p_{\infty}] = \begin{cases} 1 \text{ with probability } 1-\mathbb{E}[p_{\infty}] \\ \alpha \mathbb{E}[p_{\infty}] \text{ with probability } \mathbb{E}[p_{\infty}] \end{cases} \mathbb{E}[p_{\infty}] = 1\cdot(1-\mathbb{E}[p_{\infty}]) + \alpha \mathbb{E}[p_{\infty}] \cdot \mathbb{E}[p_{\infty}] \mathbb{E}[p_{\infty}],"['probability', 'stochastic-processes', 'recurrence-relations', 'recursion', 'stochastic-differential-equations']"
98,Probability of at least $2$ balls in random bin when distributing $K$ identical balls to $N$ distinct bins?,Probability of at least  balls in random bin when distributing  identical balls to  distinct bins?,2 K N,"If we distribute $k$ identical balls to $n$ distinct bins, what is the probability a randomly selected bin will contain at least 2 balls, assuming all balls have a uniform probability of being placed in any bin and $k < n$ . Since it's probability, not ""number of ways to arrange,"" and all distributions have equal probability, first I found the total number of distributions by assuming $k$ distinct balls, $n^k$ , which means there are $n^{k+1}$ bins across all distributions. I can figure out that if there are $k < n$ balls, the number of distributions where every bin has at most $1$ ball is $k \choose n$ (we have $k$ balls and each chooses 1 distinct bin), so guaranteed ${k \choose n} n$ bins across all distributions have fewer than $2$ balls. But I'm not sure how to figure out how many of the $n$ bins contain fewer than $2$ balls in the cases where some bins have $2$ or more balls. I could easily be going about this from the wrong angle completely though.","If we distribute identical balls to distinct bins, what is the probability a randomly selected bin will contain at least 2 balls, assuming all balls have a uniform probability of being placed in any bin and . Since it's probability, not ""number of ways to arrange,"" and all distributions have equal probability, first I found the total number of distributions by assuming distinct balls, , which means there are bins across all distributions. I can figure out that if there are balls, the number of distributions where every bin has at most ball is (we have balls and each chooses 1 distinct bin), so guaranteed bins across all distributions have fewer than balls. But I'm not sure how to figure out how many of the bins contain fewer than balls in the cases where some bins have or more balls. I could easily be going about this from the wrong angle completely though.",k n k < n k n^k n^{k+1} k < n 1 k \choose n k {k \choose n} n 2 n 2 2,"['probability', 'balls-in-bins']"
99,"Why is $\int_0^t g(s)dB_s \sim \mathcal{N}\left(0, \int_0^t g^2(s) ds\right)$",Why is,"\int_0^t g(s)dB_s \sim \mathcal{N}\left(0, \int_0^t g^2(s) ds\right)","I've found in different references that $\int_0^t g(s)dB_s$ is a Wiener integral, where $g(s)$ is a bounded, continuous function and $dB_s$ is the standard Brownian Motion. Also, that $\int_0^t g(s)dB_s \sim \mathcal{N}(0, \int_0^t g^2(s) ds)$ . Why is this? My attempt so far, is to approximate it as a series of normal random variables. Since the increments $B_{t_{i+1}}-B_{t_i}$ have a distribution $\mathcal{N}(0, t_{i+1}-t_i)$ and they are pairwise independent. Then, thinking it as a Riemann integral $\sum_{i=0}^{\infty} g_i(s) (B_{t_{i+1}}-B_{t_i}) \sim \mathcal{N}(0, \sum_{i=0}^{\infty} g_i^2(s)(t_{i+1}-t_i))$ for some $s\in [t_i, t_{i+1}]$ . My question is, is it posible to take the limit $\lim_{t_{i+1} \to t_i} \sum_{i=0}^{\infty} g_i^2(s) (t_{i+1}-t_i) = \int_0^t g^2(s)ds$ in this case? Why?","I've found in different references that is a Wiener integral, where is a bounded, continuous function and is the standard Brownian Motion. Also, that . Why is this? My attempt so far, is to approximate it as a series of normal random variables. Since the increments have a distribution and they are pairwise independent. Then, thinking it as a Riemann integral for some . My question is, is it posible to take the limit in this case? Why?","\int_0^t g(s)dB_s g(s) dB_s \int_0^t g(s)dB_s \sim \mathcal{N}(0, \int_0^t g^2(s) ds) B_{t_{i+1}}-B_{t_i} \mathcal{N}(0, t_{i+1}-t_i) \sum_{i=0}^{\infty} g_i(s) (B_{t_{i+1}}-B_{t_i}) \sim \mathcal{N}(0, \sum_{i=0}^{\infty} g_i^2(s)(t_{i+1}-t_i)) s\in [t_i, t_{i+1}] \lim_{t_{i+1} \to t_i} \sum_{i=0}^{\infty} g_i^2(s) (t_{i+1}-t_i) = \int_0^t g^2(s)ds","['probability', 'normal-distribution', 'stochastic-calculus', 'brownian-motion']"
