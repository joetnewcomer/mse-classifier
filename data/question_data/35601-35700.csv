,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Which is the algorithm for knn density estimator?,Which is the algorithm for knn density estimator?,,"I am reading Pattern Recognition and Machine Learning by Christopher Bishop. In chapter two he talk about using knn to density estimation. I want to replicate a plot using python/R/matlab.  He is doing it with synthetic data, but I do not know how to update the value V (volume of Region containing X from p(x)) in the following formula $$P(x)=\frac{K}{NV}$$ . I could not find any implementation of this algorithm for density estimation. This is the plot:","I am reading Pattern Recognition and Machine Learning by Christopher Bishop. In chapter two he talk about using knn to density estimation. I want to replicate a plot using python/R/matlab.  He is doing it with synthetic data, but I do not know how to update the value V (volume of Region containing X from p(x)) in the following formula . I could not find any implementation of this algorithm for density estimation. This is the plot:",P(x)=\frac{K}{NV},"['probability', 'statistics', 'probability-distributions', 'machine-learning', 'pattern-recognition']"
1,Optimal transport as a metric between two color images,Optimal transport as a metric between two color images,,"I am trying to characterize a distance between two images in relation to the colors present in these images. Therefore I would like to solve Earth mover's distance/1-st Wasserstein distance with entropic regularization (for a quick approximate solution) between the 3D histograms (RGB) of the two images. We resolve $\min_P \langle P,C \rangle - \epsilon H(P)$ s.t $P1=a, P^T1=b$ where $P$ is the optimal transport plan, $H$ is the entropy, $a$ and $b$ are the histograms of the two images and $\epsilon$ is the regularization term. Each entry $C_{ij}$ in this matrix contains the cost of moving point $i$ in the support of $a$ to point $j$ in the support of $b$ . It is said that the 1-st Wasserstein distance is given by the solution of the optimisation problem above if $C_{ij}=||X_i-Y_j||_2$ . So I understand this as the distance between two pixels of the two images in RGB space. Only since in dimension > 1 there is no more order relation, can I order my points $X_i$ and $Y_j$ anyhow?","I am trying to characterize a distance between two images in relation to the colors present in these images. Therefore I would like to solve Earth mover's distance/1-st Wasserstein distance with entropic regularization (for a quick approximate solution) between the 3D histograms (RGB) of the two images. We resolve s.t where is the optimal transport plan, is the entropy, and are the histograms of the two images and is the regularization term. Each entry in this matrix contains the cost of moving point in the support of to point in the support of . It is said that the 1-st Wasserstein distance is given by the solution of the optimisation problem above if . So I understand this as the distance between two pixels of the two images in RGB space. Only since in dimension > 1 there is no more order relation, can I order my points and anyhow?","\min_P \langle P,C \rangle - \epsilon H(P) P1=a, P^T1=b P H a b \epsilon C_{ij} i a j b C_{ij}=||X_i-Y_j||_2 X_i Y_j","['probability', 'probability-distributions', 'entropy', 'image-processing', 'optimal-transport']"
2,Limit of two uncorrelated random variables,Limit of two uncorrelated random variables,,"Let $\{X_n\}$ and $\{Y_n\}$ be two sequences of uncorrelated random variables with finite fourth moments. Also, let $$ X_n \xrightarrow{d} X \text{    and    } Y_n\xrightarrow{d} Y, $$ where $X$ and $Y$ are standard normal random variables. Can we conclude $(X_n,Y_n)\xrightarrow{d} (X',Y')$ such that $X'$ and $Y'$ are independent standard normal random variables? If not, can you please provide some sufficient conditions? Thanks for the help.","Let and be two sequences of uncorrelated random variables with finite fourth moments. Also, let where and are standard normal random variables. Can we conclude such that and are independent standard normal random variables? If not, can you please provide some sufficient conditions? Thanks for the help.","\{X_n\} \{Y_n\} 
X_n \xrightarrow{d} X \text{    and    } Y_n\xrightarrow{d} Y,
 X Y (X_n,Y_n)\xrightarrow{d} (X',Y') X' Y'","['probability', 'probability-theory', 'probability-distributions', 'weak-convergence']"
3,Permutation involving 4 cups and 4 saucers.,Permutation involving 4 cups and 4 saucers.,,"I study maths as a hobby.  I have come across this problem: On a shelf there are 4 saucers of different colours and 4 matching cups. In how many ways can the cups be arranged on the saucer so that no cup is on a matching saucer? I start off by saying the first cup can be placed on any of 3 saucers.  For the second cup, there are 3 choices, unless the first cup was placed on the second cup’s matching saucer, in which case there are only 2 choices.  That gives 8 outcomes so far.  But the answer in the book is 9.  So I know my method is wrong. I have seen similar problems posted on here but the solutions were too complex for me.","I study maths as a hobby.  I have come across this problem: On a shelf there are 4 saucers of different colours and 4 matching cups. In how many ways can the cups be arranged on the saucer so that no cup is on a matching saucer? I start off by saying the first cup can be placed on any of 3 saucers.  For the second cup, there are 3 choices, unless the first cup was placed on the second cup’s matching saucer, in which case there are only 2 choices.  That gives 8 outcomes so far.  But the answer in the book is 9.  So I know my method is wrong. I have seen similar problems posted on here but the solutions were too complex for me.",,['probability']
4,13 cards randomly dealt to 4 players. What's the probability of 1 player being dealt quads/four-of-a-kind?,13 cards randomly dealt to 4 players. What's the probability of 1 player being dealt quads/four-of-a-kind?,,"Inspired by the Vietnamese game Tiến lên where you are dealt $13$ cards. One specific rule states if you are dealt quads 2 (four 2's), you automatically win that round. I want to find the probability of that happening. My method: $\frac{4}{52} \times \frac{3}{51} \times \frac{2}{50} \times \frac{1}{49} \times {}^{13}C_4 = 0.264\%$ The first 4 terms are the probability of being dealt quads 2 in 1 particular order. We have 13c4 of these equivalent orders, so I multiply it by 13c4. 2 questions: Is my answer correct? I tried to use another approach: P(I have quads 2) = 1 - P(3 other players have no 2's). I tried to calculate the subtracted probability by doing 48/52 * 47/51 * ... * 11/15 * 10/14 but it seems that it's wrong. How would I go about doing this? Thanks!","Inspired by the Vietnamese game Tiến lên where you are dealt cards. One specific rule states if you are dealt quads 2 (four 2's), you automatically win that round. I want to find the probability of that happening. My method: The first 4 terms are the probability of being dealt quads 2 in 1 particular order. We have 13c4 of these equivalent orders, so I multiply it by 13c4. 2 questions: Is my answer correct? I tried to use another approach: P(I have quads 2) = 1 - P(3 other players have no 2's). I tried to calculate the subtracted probability by doing 48/52 * 47/51 * ... * 11/15 * 10/14 but it seems that it's wrong. How would I go about doing this? Thanks!",13 \frac{4}{52} \times \frac{3}{51} \times \frac{2}{50} \times \frac{1}{49} \times {}^{13}C_4 = 0.264\%,"['probability', 'combinatorics', 'combinations', 'card-games']"
5,"Analytic expression for $\mathbb E_X[(X^\top u)^p (X^\top v)^p]$, where $u$ and $v$ are fixed vectors in $\mathbb R^d$ and $X$ is uniform on sphere","Analytic expression for , where  and  are fixed vectors in  and  is uniform on sphere",\mathbb E_X[(X^\top u)^p (X^\top v)^p] u v \mathbb R^d X,"Let $u$ and $v$ be fixed vectors in $\mathbb R^d$ . Let $X$ be a random vector uniformly distributed on the unit-sphere in $\mathbb R^d$ , and let $f_p$ be a real polynomial of degree $p \ge 1$ (for simplicity, we might simply consider $f_p(t) \equiv t^p$ ). Question. What is an analytic expression for the correlatetion $c(u,v) := \mathbb E_X[f(X^\top u)f(X^\top v)]$ ? Special case $p=1$ In this case, a simple computation gives $$ c(u,v) = \mathbb E[X^\top uv^\top X] = \mbox{trace}(\mbox{cov}(X)uv^\top) = \mbox{trace}((1/d) I_d uv^\top) = \frac{u^\top v}{d} $$ Is it too crazy to conjecture that in general, $c(u,v) = K_{d,p} \cdot (u^\top v)^p$ , for some constant $K_{d,p}$ which only depends on $d$ and $p$ ?","Let and be fixed vectors in . Let be a random vector uniformly distributed on the unit-sphere in , and let be a real polynomial of degree (for simplicity, we might simply consider ). Question. What is an analytic expression for the correlatetion ? Special case In this case, a simple computation gives Is it too crazy to conjecture that in general, , for some constant which only depends on and ?","u v \mathbb R^d X \mathbb R^d f_p p \ge 1 f_p(t) \equiv t^p c(u,v) := \mathbb E_X[f(X^\top u)f(X^\top v)] p=1 
c(u,v) = \mathbb E[X^\top uv^\top X] = \mbox{trace}(\mbox{cov}(X)uv^\top) = \mbox{trace}((1/d) I_d uv^\top) = \frac{u^\top v}{d}
 c(u,v) = K_{d,p} \cdot (u^\top v)^p K_{d,p} d p","['probability', 'functional-analysis', 'statistics', 'tensors', 'covariance']"
6,Question on $\mathbb E_{X_{t_{n-2}}}[1_{B_{n-1}}(X_{t_{n-1}-t_{n-2}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]]$,Question on,\mathbb E_{X_{t_{n-2}}}[1_{B_{n-1}}(X_{t_{n-1}-t_{n-2}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]],"I have a question on these lecture notes: http://page.math.tu-berlin.de/~scheutzow/WT3main.pdf Page 46-47 Lemma 4.15 In this proof, we use, amongst other things that: $\mathbb E_{x}[1_{B_{n-1}}(X_{t_{n-1}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]\lvert \mathcal{F}_{t_{n-2}}]=\mathbb E_{X_{t_{n-2}}}[1_{B_{n-1}}(X_{t_{n-1}-t_{n-2}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]](*)$ which comes from the Markov Property which states for any and bounded measurable function $f$ we have: $\mathbb E_{x}[f((X_{t+h})_{t\geq 0})\lvert \mathcal{F}_{h}]=\mathbb E_{X_{h}}[f((X_{t})_{t\geq 0})]$ But my issue in $(*)$ would be that in our case the function $f$ is indeed: $f(X_{t_{n-1}})=1_{B_{n-1}}(X_{t_{n-1}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]$ and thus $\mathbb E_{x}[f(X_{t_{n-1}})\lvert \mathcal{F}_{t_{n-2}}]=\mathbb E_{X_{t_{n-2}}}[f(X_{t_{n-1}-t_{n-2}})]=\mathbb E_{X_{t_{n-2}}}[1_{B_{n-1}}(X_{t_{n-1}-t_{n-2}})\mathbb E_{X_{t_{n-1}-t_{n-2}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]]$ Note the difference in this computation compared to $(*)$ . My question is rather why would $\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]$ remain the same when evaluated under $\mathcal{F}_{t_{n-2}}$ even though it is a function of $f(X_{t_{n-1}})$ . Is this a mistake or am I simply missing something?","I have a question on these lecture notes: http://page.math.tu-berlin.de/~scheutzow/WT3main.pdf Page 46-47 Lemma 4.15 In this proof, we use, amongst other things that: which comes from the Markov Property which states for any and bounded measurable function we have: But my issue in would be that in our case the function is indeed: and thus Note the difference in this computation compared to . My question is rather why would remain the same when evaluated under even though it is a function of . Is this a mistake or am I simply missing something?",\mathbb E_{x}[1_{B_{n-1}}(X_{t_{n-1}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]\lvert \mathcal{F}_{t_{n-2}}]=\mathbb E_{X_{t_{n-2}}}[1_{B_{n-1}}(X_{t_{n-1}-t_{n-2}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]](*) f \mathbb E_{x}[f((X_{t+h})_{t\geq 0})\lvert \mathcal{F}_{h}]=\mathbb E_{X_{h}}[f((X_{t})_{t\geq 0})] (*) f f(X_{t_{n-1}})=1_{B_{n-1}}(X_{t_{n-1}})\mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})] \mathbb E_{x}[f(X_{t_{n-1}})\lvert \mathcal{F}_{t_{n-2}}]=\mathbb E_{X_{t_{n-2}}}[f(X_{t_{n-1}-t_{n-2}})]=\mathbb E_{X_{t_{n-2}}}[1_{B_{n-1}}(X_{t_{n-1}-t_{n-2}})\mathbb E_{X_{t_{n-1}-t_{n-2}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})]] (*) \mathbb E_{X_{t_{n-1}}}[1_{B_{n}}(X_{t_{n}-t_{n-1}})] \mathcal{F}_{t_{n-2}} f(X_{t_{n-1}}),"['probability', 'probability-theory', 'stochastic-processes', 'markov-chains', 'stochastic-calculus']"
7,Probability: Shoes in a row,Probability: Shoes in a row,,"20 shoes, from 10 pairs of shoes, are lined randomly. What is the probability that there is a set of 10 consecutive shoes with 5 shoes left and 5 right shoes? I thought that would be a good idea imagine 10 shoes as one unique object, as follow: Instead enumerate 20 objects, let's separate 10 shoes and think them as another object (call it X), so that there is 11 in total. There is 11! ways to permute each objects. The problem is to know how to count X. I mean, the first way i thought was: $|X| = \frac{10!}{5!}\frac{10!}{5!}$ , so that the answer would be: $\frac{\frac{10!}{5!}\frac{10!}{5!}*11!}{20!}$ . But so i realized that |X| that i counted was wrong, what actually i counted for |X| was counting first the 5 possible right shoes, and after this, the 5 possible let shoes. So i am stuck in how to count |X| right. I thought that we could first choose $C_{10,5} = 10!/(5!5!)$ right shoes, $C_{10,5}$ left shoes. Now the probability for one aleatory choice of X is: $\frac{\frac{10!}{5!}*11!}{20!}$ , but X have more than one option, so the probability will be the sum of all possibility for X, namely $C_{10,5}*C_{10,5}*\frac{{10!}*11!}{20!}$ . But this is greater than 1 (...), i have no idea what to do now.","20 shoes, from 10 pairs of shoes, are lined randomly. What is the probability that there is a set of 10 consecutive shoes with 5 shoes left and 5 right shoes? I thought that would be a good idea imagine 10 shoes as one unique object, as follow: Instead enumerate 20 objects, let's separate 10 shoes and think them as another object (call it X), so that there is 11 in total. There is 11! ways to permute each objects. The problem is to know how to count X. I mean, the first way i thought was: , so that the answer would be: . But so i realized that |X| that i counted was wrong, what actually i counted for |X| was counting first the 5 possible right shoes, and after this, the 5 possible let shoes. So i am stuck in how to count |X| right. I thought that we could first choose right shoes, left shoes. Now the probability for one aleatory choice of X is: , but X have more than one option, so the probability will be the sum of all possibility for X, namely . But this is greater than 1 (...), i have no idea what to do now.","|X| = \frac{10!}{5!}\frac{10!}{5!} \frac{\frac{10!}{5!}\frac{10!}{5!}*11!}{20!} C_{10,5} = 10!/(5!5!) C_{10,5} \frac{\frac{10!}{5!}*11!}{20!} C_{10,5}*C_{10,5}*\frac{{10!}*11!}{20!}","['probability', 'combinatorics']"
8,Conditional Expectation for the Exponential Distribution -- solution verification,Conditional Expectation for the Exponential Distribution -- solution verification,,"A device that continuously measures and records seismic activity is placed in a remote region. The time, $T,$ to failure of this device is exponentially distributed with mean $3$ years. Since the device will not be monitored during its first two years of service, the time to discovery of its failure is $X = \max(T, 2)$ . Determine $E(X)$ . My attempt : $$E[X] = E[X\mid T\ge 2] \cdot P(T \ge 2) + E[X\mid T< 2] \cdot P(T< 2)$$ $$= E[T\mid T\ge 2] \cdot P(T \ge 2) + E[2\mid T< 2] \cdot P(T< 2) $$ Using the memoryless property of the Exponential distribution, we have: $$ = E(T) \cdot P(T\ge 2) + E(2) \cdot P(T<2)$$ $$ = 3[1-P(T<2)] + 2\cdot P(T<2)$$ (Edited based on commments) Now, $P(T<2)=\int_0^2 \frac{1}{3} e^{-t/3} \; dt = 1- e^{-2/3}$ . These calculations do not lead to the correct answer. Can someone please point out what I did incorrectly? As pointed out in the answer by Michael Hardy, for the benefit of anyone who visits this post in the future, this is how the solution should go: $$E[T\mid T\ge 2] \cdot P(T \ge 2) + E[2\mid T< 2] \cdot P(T< 2) = \int_2^\infty \frac{t}{3} e^{-t/3}\; \text{d}t + 2 \cdot [1- e^{-2/3}]$$ $$= 5e^{-2/3} + 2 - 2e^{-2/3} = \boxed{3e^{-2/3} +2}$$","A device that continuously measures and records seismic activity is placed in a remote region. The time, to failure of this device is exponentially distributed with mean years. Since the device will not be monitored during its first two years of service, the time to discovery of its failure is . Determine . My attempt : Using the memoryless property of the Exponential distribution, we have: (Edited based on commments) Now, . These calculations do not lead to the correct answer. Can someone please point out what I did incorrectly? As pointed out in the answer by Michael Hardy, for the benefit of anyone who visits this post in the future, this is how the solution should go:","T, 3 X = \max(T, 2) E(X) E[X] = E[X\mid T\ge 2] \cdot P(T \ge 2) + E[X\mid T< 2] \cdot P(T< 2) = E[T\mid T\ge 2] \cdot P(T \ge 2) + E[2\mid T< 2] \cdot P(T< 2)   = E(T) \cdot P(T\ge 2) + E(2) \cdot P(T<2)  = 3[1-P(T<2)] + 2\cdot P(T<2) P(T<2)=\int_0^2 \frac{1}{3} e^{-t/3} \; dt = 1- e^{-2/3} E[T\mid T\ge 2] \cdot P(T \ge 2) + E[2\mid T< 2] \cdot P(T< 2) = \int_2^\infty \frac{t}{3} e^{-t/3}\; \text{d}t + 2 \cdot [1- e^{-2/3}] = 5e^{-2/3} + 2 - 2e^{-2/3} = \boxed{3e^{-2/3} +2}","['probability', 'statistics', 'solution-verification', 'actuarial-science']"
9,"MLE for $p$ in Geometric distribution from Exponential distribution (two methods, two results)","MLE for  in Geometric distribution from Exponential distribution (two methods, two results)",p,"Let $Y_n$ given as $\mathrm{ceil}(X_n)$ , where $\mathrm{ceil}(x):=$ the least integer greater than or equal to $x$ and $(X_n)$ is a sequence of iid random variables from $\mathrm{Exp}(\theta),~\theta>0$ . Then $Y_n\sim Geo(p)$ , where $p=p(\theta):=1-e^{-\theta}$ and since the maximum likelihood estimator (mle) for $\theta$ is given as $\frac{1}{\overline{X}}$ , the mle for $p(\theta)$ is $1-e^{-\frac{1}{\overline{X}}}$ . If we compute directly the mle for $p$ using $\mathbb{P}(Y_1=y)=(1-p)^{y-1}p$ for $y\in \mathbb{N}$ , we get that the maximum likelihood estimator for $p$ is given as $\frac{1}{\overline{Y}}=\frac{1}{\overline{\mathrm{ceil}(X)}} $ , which is not the same as the previous result. Is there some contradiction in these two results, or some fallacy? Thank for the help.","Let given as , where the least integer greater than or equal to and is a sequence of iid random variables from . Then , where and since the maximum likelihood estimator (mle) for is given as , the mle for is . If we compute directly the mle for using for , we get that the maximum likelihood estimator for is given as , which is not the same as the previous result. Is there some contradiction in these two results, or some fallacy? Thank for the help.","Y_n \mathrm{ceil}(X_n) \mathrm{ceil}(x):= x (X_n) \mathrm{Exp}(\theta),~\theta>0 Y_n\sim Geo(p) p=p(\theta):=1-e^{-\theta} \theta \frac{1}{\overline{X}} p(\theta) 1-e^{-\frac{1}{\overline{X}}} p \mathbb{P}(Y_1=y)=(1-p)^{y-1}p y\in \mathbb{N} p \frac{1}{\overline{Y}}=\frac{1}{\overline{\mathrm{ceil}(X)}} ","['probability', 'statistics', 'parameter-estimation']"
10,All possible tournament pairing such that you get no pair from the same group.,All possible tournament pairing such that you get no pair from the same group.,,"I thought about this problem for a while, but I have no idea how to approach it. You have 8 groups, with 4 of the groups having 6 people and rest of the 4 groups having 3 people. So you have 36 people in total. Now we want to pick 18 pairs from 36 people to form a tournament. I believe there are $\frac{36!}{18! 2^{18}}$ (I don't really understand how to get this number though) as can be seen here: Number of ways you can form pairs with a group of people when certain people cannot be paired with each other. Now, I want pairings to be such that no people from the same group play against each other. How many possible pairings exist under this constraint? This is a very similar question: UEFA Champions League quarterfinals 2018 draw - pairing of same country teams However, I don't think the approach there would work. Thanks! EDIT: The most general form of this question would be to let the number of groups and number of people in each group vary, and to find the formula for this. I am now wondering if such a formula exists. So for example, what if you have 11 groups, and 4 of them have 5 people, 5 of them have 4 people, and 2 of them have 12 people. EDIT: I ran some simulation, I keep getting about 0.11 instead of Henry's 0.245. Here is my code. team_list = c(rep(1:6, 4), rep(1:3,4))  for (i in 1:6){   team_list[i] = paste(""A"", team_list[i], sep = """") }  for (i in 7:12){   team_list[i] = paste(""B"", team_list[i], sep = """") }  for (i in 13:18){   team_list[i] = paste(""C"", team_list[i], sep = """") }  for (i in 19:24){   team_list[i] = paste(""D"", team_list[i], sep = """") }  for (i in 25:27){   team_list[i] = paste(""E"", team_list[i], sep = """") }  for (i in 28:30){   team_list[i] = paste(""F"", team_list[i], sep = """") }  for (i in 31:33){   team_list[i] = paste(""G"", team_list[i], sep = """") }  for (i in 34:36){   team_list[i] = paste(""H"", team_list[i], sep = """") }    check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }   count = 0  for (i in 1:10000){   x = sample(team_list, size = 36)   if (!check_pair(x)){     count = count+1   } }  count/10000      team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""C2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }   count = 0  for (i in 1:10000){   x = sample(team_list, size = 6)   if (!check_pair(x)){     count = count+1   } }  count/10000  team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""D1"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }   count = 0  for (i in 1:10000){   x = sample(team_list, size = 6)   if (!check_pair(x)){     count = count+1   } }  count/10000   z = pair_combn(team_list)     team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""D1"", ""E1"", ""E2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  combination = pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }  count = 0 for (i in 1:105){   to_check = as.vector(unlist(combination[[i]]))   if (!check_pair(to_check)){     count = count+1   } }  print (count)   count = 0  for (i in 1:10000){   x = sample(team_list, size = 8)   if (!check_pair(x)){     count = count+1   } }  count/10000    team_list = c(""A1"", ""A2"", ""A3"", ""A4"", ""B1"", ""B2"", ""C1"", ""C2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  combination = pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }  count = 0 for (i in 1:105){   to_check = as.vector(unlist(combination[[i]]))   if (!check_pair(to_check)){     count = count+1   } }  print (count)   count = 0  for (i in 1:10000){   x = sample(team_list, size = 8)   if (!check_pair(x)){     count = count+1   } }  count/10000    team_list = c(""A1"", ""A2"", ""A3"", ""B1"", ""B2"", ""B3"", ""C1"", ""C2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  combination = pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }  count = 0 for (i in 1:105){   to_check = as.vector(unlist(combination[[i]]))   if (!check_pair(to_check)){     count = count+1   } }  print (count)   count = 0  for (i in 1:10000){   x = sample(team_list, size = 8)   if (!check_pair(x)){     count = count+1   } }  count/10000 And some results I get: For 3 group of 4 people, 2 people, and 2 people, I get 24 out of 105 For 3 group of 3 people, 3 people and 2 people, I get 36 out of 105 For 5 group of 2 people, 2 people, 2 people, 1 person and 1 person, I get 68 out of 105.","I thought about this problem for a while, but I have no idea how to approach it. You have 8 groups, with 4 of the groups having 6 people and rest of the 4 groups having 3 people. So you have 36 people in total. Now we want to pick 18 pairs from 36 people to form a tournament. I believe there are (I don't really understand how to get this number though) as can be seen here: Number of ways you can form pairs with a group of people when certain people cannot be paired with each other. Now, I want pairings to be such that no people from the same group play against each other. How many possible pairings exist under this constraint? This is a very similar question: UEFA Champions League quarterfinals 2018 draw - pairing of same country teams However, I don't think the approach there would work. Thanks! EDIT: The most general form of this question would be to let the number of groups and number of people in each group vary, and to find the formula for this. I am now wondering if such a formula exists. So for example, what if you have 11 groups, and 4 of them have 5 people, 5 of them have 4 people, and 2 of them have 12 people. EDIT: I ran some simulation, I keep getting about 0.11 instead of Henry's 0.245. Here is my code. team_list = c(rep(1:6, 4), rep(1:3,4))  for (i in 1:6){   team_list[i] = paste(""A"", team_list[i], sep = """") }  for (i in 7:12){   team_list[i] = paste(""B"", team_list[i], sep = """") }  for (i in 13:18){   team_list[i] = paste(""C"", team_list[i], sep = """") }  for (i in 19:24){   team_list[i] = paste(""D"", team_list[i], sep = """") }  for (i in 25:27){   team_list[i] = paste(""E"", team_list[i], sep = """") }  for (i in 28:30){   team_list[i] = paste(""F"", team_list[i], sep = """") }  for (i in 31:33){   team_list[i] = paste(""G"", team_list[i], sep = """") }  for (i in 34:36){   team_list[i] = paste(""H"", team_list[i], sep = """") }    check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }   count = 0  for (i in 1:10000){   x = sample(team_list, size = 36)   if (!check_pair(x)){     count = count+1   } }  count/10000      team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""C2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }   count = 0  for (i in 1:10000){   x = sample(team_list, size = 6)   if (!check_pair(x)){     count = count+1   } }  count/10000  team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""D1"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }   count = 0  for (i in 1:10000){   x = sample(team_list, size = 6)   if (!check_pair(x)){     count = count+1   } }  count/10000   z = pair_combn(team_list)     team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""D1"", ""E1"", ""E2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  combination = pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }  count = 0 for (i in 1:105){   to_check = as.vector(unlist(combination[[i]]))   if (!check_pair(to_check)){     count = count+1   } }  print (count)   count = 0  for (i in 1:10000){   x = sample(team_list, size = 8)   if (!check_pair(x)){     count = count+1   } }  count/10000    team_list = c(""A1"", ""A2"", ""A3"", ""A4"", ""B1"", ""B2"", ""C1"", ""C2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  combination = pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }  count = 0 for (i in 1:105){   to_check = as.vector(unlist(combination[[i]]))   if (!check_pair(to_check)){     count = count+1   } }  print (count)   count = 0  for (i in 1:10000){   x = sample(team_list, size = 8)   if (!check_pair(x)){     count = count+1   } }  count/10000    team_list = c(""A1"", ""A2"", ""A3"", ""B1"", ""B2"", ""B3"", ""C1"", ""C2"")  pair_combn <- function(x) {   Filter(function(e) all(unique(x) %in% unlist(e)),          combn(as.data.frame(combn(x, 2)),                length(x)/2, simplify = FALSE)) }  combination = pair_combn(team_list)   check_pair = function(x){   for (i in seq(from = 1, to = length(x), by = 2)){     if (substr(x[i],1,1) == substr(x[i+1],1,1)){       return (TRUE)     }   }   return (FALSE) }  count = 0 for (i in 1:105){   to_check = as.vector(unlist(combination[[i]]))   if (!check_pair(to_check)){     count = count+1   } }  print (count)   count = 0  for (i in 1:10000){   x = sample(team_list, size = 8)   if (!check_pair(x)){     count = count+1   } }  count/10000 And some results I get: For 3 group of 4 people, 2 people, and 2 people, I get 24 out of 105 For 3 group of 3 people, 3 people and 2 people, I get 36 out of 105 For 5 group of 2 people, 2 people, 2 people, 1 person and 1 person, I get 68 out of 105.",\frac{36!}{18! 2^{18}},"['probability', 'combinatorics', 'combinations']"
11,"Prove $A, B, C, D$ are $N(0,1)$ random variables",Prove  are  random variables,"A, B, C, D N(0,1)","$A$ and $B$ are i.i.d RVs, assume $\mathbb{E}[A^2]$ exists, $\mathrm{var}{A}=1$ , and that MGF of $A$ exists near zero. $C=(A+B)/\sqrt{2}$ and $D=(A-B)/\sqrt{2}$ . Now prove that if. $C$ and $D$ are i.i.d., $A, B, C, D$ are $N(0,1)$ random variables. Basic computation got me to figure out that the expectation and variance of all four RVs are 0 and 1 respectively, and I also know that RVs that have an MGF such that $M(2s)=(M(s))^4$ have a normal distribution, but I am not sure how to proceed from there.","and are i.i.d RVs, assume exists, , and that MGF of exists near zero. and . Now prove that if. and are i.i.d., are random variables. Basic computation got me to figure out that the expectation and variance of all four RVs are 0 and 1 respectively, and I also know that RVs that have an MGF such that have a normal distribution, but I am not sure how to proceed from there.","A B \mathbb{E}[A^2] \mathrm{var}{A}=1 A C=(A+B)/\sqrt{2} D=(A-B)/\sqrt{2} C D A, B, C, D N(0,1) M(2s)=(M(s))^4","['probability', 'probability-distributions', 'normal-distribution', 'moment-generating-functions']"
12,Sampling inspection - Joint distribution,Sampling inspection - Joint distribution,,"I am self-learning probability theory from William Feller's Introduction to Probability theory and its applications . I would like to ask for some help in deriving the correct solution to the below very interesting problem. Problem IX.12 Suppose that items with a probability $p$ of being acceptable are subject to inspection in such a way, that the probability of an item being inspected is $p'$ . We have four classes, namely, ""acceptable and inspected"", ""acceptable but not inspected"" and so forth with probabilities $pp'$ , $pq'$ , $p'q$ and $qq'$ . We are concerned with double Bernoulli trials. Let $N$ be the number of items passing the inspection desk (both inspected and uninspected) before the first defective is found, and let $K$ be the (undiscovered) number of defectives among them.  Find the joint distributions of $N$ and $K$ , and the marginal distributions. Solution (My Attempt). We have, \begin{array}{c|cc} & \text{Acceptable} & \text{Defective}\\ \hline \text{Inspected} & pp' & qp'\\ \text{Undiscovered} & pq' & qq'\\ \end{array} The first defective item is found at trial number $(n+1)$ , if the preceding $n$ items were either acceptable or uninspected. $P\{\text{Acceptable} \cup \text{Uninspected}\} = P\{\text{Defective},\text{Inspected}\}^C = 1 - qp'$ $N$ is the waiting time to the first defective. $N$ follows a geometric distribution. $P\{N = n\} = (1 - qp')^n qp' \tag{1}$ $K$ is the number of undiscovered defectives among these $n$ trials. So, given that we waited for time $n$ to find the first defective, the probability that the number of defectives equals $k$ is given by, $P\{K = k \vert N = n\} = {n \choose k} (qq')^k p^{n-k}$ Thus, the joint distribution \begin{align*} P\{K = k, N = N\} &= P \{K = k \vert N =n \} \cdot P \{N = n\}\\ &= {n \choose k} (qq')^k p^{n-k} (1 - qp')^n qp' \end{align*} However, the textbook states the expression for the joint distribution as, $$ P\{K = k, N = n\} ={n \choose k}(qq')^k p^{n-k} qp' $$ Also, how to sum over all $n$ to derive an expression for the marginal distribution of $N$ ?","I am self-learning probability theory from William Feller's Introduction to Probability theory and its applications . I would like to ask for some help in deriving the correct solution to the below very interesting problem. Problem IX.12 Suppose that items with a probability of being acceptable are subject to inspection in such a way, that the probability of an item being inspected is . We have four classes, namely, ""acceptable and inspected"", ""acceptable but not inspected"" and so forth with probabilities , , and . We are concerned with double Bernoulli trials. Let be the number of items passing the inspection desk (both inspected and uninspected) before the first defective is found, and let be the (undiscovered) number of defectives among them.  Find the joint distributions of and , and the marginal distributions. Solution (My Attempt). We have, The first defective item is found at trial number , if the preceding items were either acceptable or uninspected. is the waiting time to the first defective. follows a geometric distribution. is the number of undiscovered defectives among these trials. So, given that we waited for time to find the first defective, the probability that the number of defectives equals is given by, Thus, the joint distribution However, the textbook states the expression for the joint distribution as, Also, how to sum over all to derive an expression for the marginal distribution of ?","p p' pp' pq' p'q qq' N K N K \begin{array}{c|cc}
& \text{Acceptable} & \text{Defective}\\
\hline
\text{Inspected} & pp' & qp'\\
\text{Undiscovered} & pq' & qq'\\
\end{array} (n+1) n P\{\text{Acceptable} \cup \text{Uninspected}\} = P\{\text{Defective},\text{Inspected}\}^C = 1 - qp' N N P\{N = n\} = (1 - qp')^n qp' \tag{1} K n n k P\{K = k \vert N = n\} = {n \choose k} (qq')^k p^{n-k} \begin{align*}
P\{K = k, N = N\} &= P \{K = k \vert N =n \} \cdot P \{N = n\}\\
&= {n \choose k} (qq')^k p^{n-k} (1 - qp')^n qp'
\end{align*} 
P\{K = k, N = n\} ={n \choose k}(qq')^k p^{n-k} qp'
 n N","['probability', 'solution-verification', 'binomial-distribution']"
13,"Optimality of Khintchine's inequality, convergence in distribution and convergence of moments","Optimality of Khintchine's inequality, convergence in distribution and convergence of moments",,"Let $b_1,..b_n$ be real numbers and $\varepsilon_1,...,\varepsilon_n$ be independant Rademacher random variables. The Khintchine's inequality states that $$\mathrm{E}\left [ \left (  \sum_{i=1}^{n} b_i\varepsilon_i \right )^{2p}\right ]\leqslant \frac{\left ( 2p \right )!}{2^pp!}\left ( \sum_{i=1}^{n}b_i^2 \right )^p$$ for every integer $p \geqslant 1$ . I'm trying to prove that the constant $\frac{\left ( 2p \right )!}{2^pp!}$ is optimal, in the sense that it is impossible to obtain an inequality that holds for every Rademacher sum with a strictly smaller constant that does not depend on the dimension $n$ . Since $\frac{\left ( 2p \right )!}{2^pp!}$ is the $2p$ -th moment of a standard normal variable, my idea was to approximate a well chosen Rademacher sum with a standard normal variable to obtain the optimality. Let $b_1=...=b_n=1$ . The central limit theorem ensures that $Z_n=\frac{1}{\sqrt{n}}\sum_{i=1}^{n}\varepsilon_i$ converges in distribution towards a random variable $X$ of distribution $\mathcal{N}(0,1)$ . If that implied that $$\lim_{n\rightarrow\infty}\mathrm{E}[Z_n^{2p}] = \mathrm{E}[X^{2p}]$$ then we would have $$\lim_{n\rightarrow\infty}\frac{1}{n^p}\mathrm{E}\left [  \left ( \sum_{i=1}^{n}\varepsilon_i \right )^{2p}\right ] = \frac{\left ( 2p \right )!}{2^pp!}$$ which proves the optimality. So my question really is : is it true that $\lim_{n\rightarrow\infty}\mathrm{E}[Z_n^{2p}] = \mathrm{E}[X^{2p}]$ ? I don't think the dominated convergence theorem works here since $Z_n$ is not bounded. The interpretation of convergence in distribution in terms of pointwise convergence of the characteristic functions yields $\forall t \in \mathbb{R}, \lim_{n\rightarrow\infty} \cos(\frac{t}{\sqrt{n}})^n=e^{-\frac{t^2}{2}}$ . Could that be of any use ?","Let be real numbers and be independant Rademacher random variables. The Khintchine's inequality states that for every integer . I'm trying to prove that the constant is optimal, in the sense that it is impossible to obtain an inequality that holds for every Rademacher sum with a strictly smaller constant that does not depend on the dimension . Since is the -th moment of a standard normal variable, my idea was to approximate a well chosen Rademacher sum with a standard normal variable to obtain the optimality. Let . The central limit theorem ensures that converges in distribution towards a random variable of distribution . If that implied that then we would have which proves the optimality. So my question really is : is it true that ? I don't think the dominated convergence theorem works here since is not bounded. The interpretation of convergence in distribution in terms of pointwise convergence of the characteristic functions yields . Could that be of any use ?","b_1,..b_n \varepsilon_1,...,\varepsilon_n \mathrm{E}\left [ \left (  \sum_{i=1}^{n} b_i\varepsilon_i \right )^{2p}\right ]\leqslant \frac{\left ( 2p \right )!}{2^pp!}\left ( \sum_{i=1}^{n}b_i^2 \right )^p p \geqslant 1 \frac{\left ( 2p \right )!}{2^pp!} n \frac{\left ( 2p \right )!}{2^pp!} 2p b_1=...=b_n=1 Z_n=\frac{1}{\sqrt{n}}\sum_{i=1}^{n}\varepsilon_i X \mathcal{N}(0,1) \lim_{n\rightarrow\infty}\mathrm{E}[Z_n^{2p}] = \mathrm{E}[X^{2p}] \lim_{n\rightarrow\infty}\frac{1}{n^p}\mathrm{E}\left [  \left ( \sum_{i=1}^{n}\varepsilon_i \right )^{2p}\right ] = \frac{\left ( 2p \right )!}{2^pp!} \lim_{n\rightarrow\infty}\mathrm{E}[Z_n^{2p}] = \mathrm{E}[X^{2p}] Z_n \forall t \in \mathbb{R}, \lim_{n\rightarrow\infty} \cos(\frac{t}{\sqrt{n}})^n=e^{-\frac{t^2}{2}}","['probability', 'probability-theory', 'inequality', 'concentration-of-measure']"
14,"Bessel function, characteristic function, semicircle distribution","Bessel function, characteristic function, semicircle distribution",,"I am trying to prove that $\dfrac{1}{x} J_1(2x)$ , where $J_n$ is the Bessel function of order n, is the characteristic function of the semicircle distribution, i.e. $σ(x)=\dfrac{1}{2π}\sqrt{4-x^2}   \textbf{1}_{|x|<2} $ . Basically, I would like to calculate the integral $$\dfrac{1}{2π} \displaystyle\int_{\mathbb{R}}{\dfrac{1}{t}J(2t)}e^{-itx} dt $$ So, I do not want to calculate the characteristic equation of $σ$ , I want to find $σ$ when I am given the characteristic function. I have tried some integral forms of $J_1$ but can't seem to find what I am looking for. Any hints?","I am trying to prove that , where is the Bessel function of order n, is the characteristic function of the semicircle distribution, i.e. . Basically, I would like to calculate the integral So, I do not want to calculate the characteristic equation of , I want to find when I am given the characteristic function. I have tried some integral forms of but can't seem to find what I am looking for. Any hints?","\dfrac{1}{x} J_1(2x) J_n σ(x)=\dfrac{1}{2π}\sqrt{4-x^2} 
 \textbf{1}_{|x|<2}  \dfrac{1}{2π} \displaystyle\int_{\mathbb{R}}{\dfrac{1}{t}J(2t)}e^{-itx} dt  σ σ J_1","['probability', 'integration', 'bessel-functions']"
15,Conditional probability and independent sigma algebras,Conditional probability and independent sigma algebras,,"Exercise: Given a random variable $X$ , sigma algebras $\mathcal{G},\mathcal{H}$ such that $\mathcal{H}$ is independent from both $\mathcal{G}$ and $X$ prove that $\operatorname{E}[X\mid\sigma(\mathcal{G},\mathcal{H})]=\operatorname{E}[X\mid\mathcal{G}]$ . I've proven that $\sigma(\mathcal{G},\mathcal{H})=\sigma(S)$ where $S=\{ H\cap G \vert H\in\mathcal{H},G\in\mathcal{G}\}$ . Obviously $\operatorname{E}[X\mid\mathcal{G}]$ is $\sigma(\mathcal{G},\mathcal{H})$ -mesurable.  I've also proven that $\forall A\in S ,\ \operatorname{E}[X\mid\mathcal{G}]$ satisfies the conditional expectation property, i.e. $\int_AX=\int_A\operatorname{E}[X\mid\mathcal{G}]$ I would like to know if i can conclude using a criteria for coincidence of finite measures: given $A\in\sigma(\mathcal{G},\mathcal{H})$ the maps that send $A \rightarrow \int_AX$ and $A \rightarrow \int_A\operatorname{E}[X\mid\mathcal{G}]$ are well defined finite measures on $\sigma(\mathcal{G},\mathcal{H})$ and both coincide on $S$ which is a set of generators for $\sigma(\mathcal{G},\mathcal{H})$ and it is also stable under finite intersection, thus such measures coincide on $\sigma(\mathcal{G},\mathcal{H})$ which is equivalent with what i want to show. Thank you","Exercise: Given a random variable , sigma algebras such that is independent from both and prove that . I've proven that where . Obviously is -mesurable.  I've also proven that satisfies the conditional expectation property, i.e. I would like to know if i can conclude using a criteria for coincidence of finite measures: given the maps that send and are well defined finite measures on and both coincide on which is a set of generators for and it is also stable under finite intersection, thus such measures coincide on which is equivalent with what i want to show. Thank you","X \mathcal{G},\mathcal{H} \mathcal{H} \mathcal{G} X \operatorname{E}[X\mid\sigma(\mathcal{G},\mathcal{H})]=\operatorname{E}[X\mid\mathcal{G}] \sigma(\mathcal{G},\mathcal{H})=\sigma(S) S=\{ H\cap G \vert H\in\mathcal{H},G\in\mathcal{G}\} \operatorname{E}[X\mid\mathcal{G}] \sigma(\mathcal{G},\mathcal{H}) \forall A\in S ,\ \operatorname{E}[X\mid\mathcal{G}] \int_AX=\int_A\operatorname{E}[X\mid\mathcal{G}] A\in\sigma(\mathcal{G},\mathcal{H}) A \rightarrow \int_AX A \rightarrow \int_A\operatorname{E}[X\mid\mathcal{G}] \sigma(\mathcal{G},\mathcal{H}) S \sigma(\mathcal{G},\mathcal{H}) \sigma(\mathcal{G},\mathcal{H})","['probability', 'measure-theory', 'random-variables', 'conditional-expectation', 'independence']"
16,Whats the intuitive difference between ${n \choose 2}$ and taking ${n \choose 1} {{n-1} \choose 1}$?,Whats the intuitive difference between  and taking ?,{n \choose 2} {n \choose 1} {{n-1} \choose 1},Example: I am trying to find the number of combinations of full house in poker. In that case I take ${13 \choose 1}{4 \choose 3} {12 \choose 1}  {4 \choose 2}$ . In a different scenario suppose I want to find the number of combinations of two pairs. There I take ${13 \choose 2}  {4\choose 2}  {4 \choose 2}$ . Why shouldn't I take ${13 \choose 1}$ and then ${12 \choose 1}$ like in the previous case?,Example: I am trying to find the number of combinations of full house in poker. In that case I take . In a different scenario suppose I want to find the number of combinations of two pairs. There I take . Why shouldn't I take and then like in the previous case?,{13 \choose 1}{4 \choose 3} {12 \choose 1}  {4 \choose 2} {13 \choose 2}  {4\choose 2}  {4 \choose 2} {13 \choose 1} {12 \choose 1},"['probability', 'combinatorics', 'binomial-coefficients', 'intuition', 'poker']"
17,"Birthday problem with large $n, d$ values",Birthday problem with large  values,"n, d","In the Birthday problem , the formulas $${\displaystyle {\begin{aligned}p(n;d)&={\begin{cases}1-\displaystyle \prod _{k=1}^{n-1}\left(1-{\frac {k}{d}}\right)&n\leq d\\1&n>d\end{cases}}&\approx 1-e^{-{\frac {n(n-1)}{2d}}}&\approx 1-\left({\frac {d-1}{d}}\right)^{\frac {n(n-1)}{2}}\end{aligned}}}$$ work well for $d = 365$ and $n=23$ , and gives the usual estimation that if you have 23 people in the same room, the probability to have at least two people born the same day is $\geq 50 \%$ . Question: what formula is available for $p(n; d)$ with more precise error terms? Concrete application: I'm using random 5-alphanumeric-character identifiers for an inventory of objects. Example: V4QH7, WYJ9X, LK6H4, etc. If I have $n = 10,000$ objects, what is the probability that at least 2 objects have the same ID? Note: the last formula (the one after the one with exponential function above) gives Error, numeric exception: overflow in Maple when I take $d=(26+10)^5=60,466,176$ and $n=10,000$ . The formula with exp gives $p \approx 3.8 \%$ but since no error term is given, I don't know if this is accurate. Edit: Mistake: $p \approx 3.8 \%$ was obtained when I took $d=33^6$ (6-alphanumeric characters with a few letters removed for easier identification: I vs 1, etc.). With $d=36^5$ , we get $56.3 \%$ probability of having a collision with the exp formula above, which is in accordance with the accepted answer.","In the Birthday problem , the formulas work well for and , and gives the usual estimation that if you have 23 people in the same room, the probability to have at least two people born the same day is . Question: what formula is available for with more precise error terms? Concrete application: I'm using random 5-alphanumeric-character identifiers for an inventory of objects. Example: V4QH7, WYJ9X, LK6H4, etc. If I have objects, what is the probability that at least 2 objects have the same ID? Note: the last formula (the one after the one with exponential function above) gives Error, numeric exception: overflow in Maple when I take and . The formula with exp gives but since no error term is given, I don't know if this is accurate. Edit: Mistake: was obtained when I took (6-alphanumeric characters with a few letters removed for easier identification: I vs 1, etc.). With , we get probability of having a collision with the exp formula above, which is in accordance with the accepted answer.","{\displaystyle {\begin{aligned}p(n;d)&={\begin{cases}1-\displaystyle \prod _{k=1}^{n-1}\left(1-{\frac {k}{d}}\right)&n\leq d\\1&n>d\end{cases}}&\approx 1-e^{-{\frac {n(n-1)}{2d}}}&\approx 1-\left({\frac {d-1}{d}}\right)^{\frac {n(n-1)}{2}}\end{aligned}}} d = 365 n=23 \geq 50 \% p(n; d) n = 10,000 d=(26+10)^5=60,466,176 n=10,000 p \approx 3.8 \% p \approx 3.8 \% d=33^6 d=36^5 56.3 \%","['probability', 'probability-theory', 'birthday']"
18,"The U.S. Senate consists of $100$ senators, with $2$ from each of the $50$ states","The U.S. Senate consists of  senators, with  from each of the  states",100 2 50,"The U.S. Senate consists of $100$ senators, with $2$ from each of the $50$ states. There are $50$ Democrats in the Senate. A committee of size $10$ is formed, by picking a random set of senators such that all sets of size $10$ are equally likely. a) Find the expected number of Democrats on the committee. b) Find the expected number of states represented on the committee (by at least one senator). c) Find the expected number of states such that both of the state’s senators are on the committee. For part a), I defined $D$ as a random variable for democrats, got the Hypergeometric Distribution to be $D$ ~ $(100, c, d),$ and the expectation to be $E(D) = c(\frac{d}{100}) = \frac{cd}{100}$ . Then I plugged in $10$ for $c$ and $50$ for $d$ and got $E(D) = 5.$ For part b), I defined $I_j$ as the random variable for the j-th state represented/ not represented in the committee, got $P(I_j = 1) = 1 - P(I_j = 0) = 1 - \frac{\binom{98}{c}}{\binom{100}{c}} = 1 - \frac{(100 - c)(99 - c)}{(100)(99)}$ , and finally $E(\sum_{j} I_j) = \sum_{j}E(I_j) = \sum_{j}P(I_j = 1) = 50(1 - \frac{(100 - c)(99 - c)}{(100)(99)})$ . Then I plugged in $10$ for $c$ and got $P(I_j = 1) = 1 - \frac{8010}{9900}$ = $\frac{21}{110}$ and $E(\sum_{j} I_j) = 50(1 - \frac{(100 - 10)(99 - 10)}{(100)(99)})$ = $50(\frac{21}{110})$ = $\frac{105}{11} $ For part c), I defined $K_j$ as the random variable for both being from/ not from j-th state in the committee, got $P(K_j = 1) = \frac{\binom{98}{c}}{\binom{100}{c}} = \frac{(100 - c)(99 - c)}{(100)(99)}$ and finally $E(\sum_{j} K_j) = \sum_{j}E(K_j) = \sum_{j}P(K_j = 1) = 50( \frac{(100 - c)(99 - c)}{(100)(99)})$ Then I plugged in $10$ for $c$ and got $P(K_j = 1) = \frac{8010}{9900}$ = $\frac{89}{110}$ and $E(\sum_{j} K_j) = 50(\frac{(100 - 10)(99 - 10)}{(100)(99)})$ = $50(\frac{89}{110})$ = $\frac{445}{11} $ . However, I am not sure if my answers are correct. Any help would be much appreciated!","The U.S. Senate consists of senators, with from each of the states. There are Democrats in the Senate. A committee of size is formed, by picking a random set of senators such that all sets of size are equally likely. a) Find the expected number of Democrats on the committee. b) Find the expected number of states represented on the committee (by at least one senator). c) Find the expected number of states such that both of the state’s senators are on the committee. For part a), I defined as a random variable for democrats, got the Hypergeometric Distribution to be ~ and the expectation to be . Then I plugged in for and for and got For part b), I defined as the random variable for the j-th state represented/ not represented in the committee, got , and finally . Then I plugged in for and got = and = = For part c), I defined as the random variable for both being from/ not from j-th state in the committee, got and finally Then I plugged in for and got = and = = . However, I am not sure if my answers are correct. Any help would be much appreciated!","100 2 50 50 10 10 D D (100, c, d), E(D) = c(\frac{d}{100}) = \frac{cd}{100} 10 c 50 d E(D) = 5. I_j P(I_j = 1) = 1 - P(I_j = 0) = 1 - \frac{\binom{98}{c}}{\binom{100}{c}} = 1 - \frac{(100 - c)(99 - c)}{(100)(99)} E(\sum_{j} I_j) = \sum_{j}E(I_j) = \sum_{j}P(I_j = 1) = 50(1 - \frac{(100 - c)(99 - c)}{(100)(99)}) 10 c P(I_j = 1) = 1 - \frac{8010}{9900} \frac{21}{110} E(\sum_{j} I_j) = 50(1 - \frac{(100 - 10)(99 - 10)}{(100)(99)}) 50(\frac{21}{110}) \frac{105}{11}  K_j P(K_j = 1) = \frac{\binom{98}{c}}{\binom{100}{c}} = \frac{(100 - c)(99 - c)}{(100)(99)} E(\sum_{j} K_j) = \sum_{j}E(K_j) = \sum_{j}P(K_j = 1) = 50( \frac{(100 - c)(99 - c)}{(100)(99)}) 10 c P(K_j = 1) = \frac{8010}{9900} \frac{89}{110} E(\sum_{j} K_j) = 50(\frac{(100 - 10)(99 - 10)}{(100)(99)}) 50(\frac{89}{110}) \frac{445}{11} ",['probability']
19,Equivalent definitions of Brownian local time,Equivalent definitions of Brownian local time,,"To keep this question simple, we only consider the local time of a standard Brownian motion $B_t$ at zero, we denote it as $L_t^0$ . Generally, we define $$\tag{1} L_t^0(B)=\lim_{\varepsilon\to\infty}\dfrac{1}{2\varepsilon}\int_0^t1_{(-\varepsilon,\varepsilon)}(B_s)\,ds. $$ Another definition is given by $$L_t^0(B)= |B_t|-\int_0^t\text{sgn}(B_s)\,dB_s\tag{2}.$$ We can approximate $|B_t|$ pointwise by $\sqrt{\varepsilon+B_t^2}$ by taking $\varepsilon\to0$ . Applying Ito formula to $\sqrt{\varepsilon+B_t^2}$ we get, $$\sqrt{\varepsilon+B_t^2}=\sqrt{\varepsilon}+\int_0^t\dfrac{B_s}{\sqrt{\varepsilon+B_s^2}}\,dB_s+\dfrac{1}{2}\int_0^t\dfrac{\varepsilon}{(\varepsilon+B_s^2)^{3/2}}\,ds. $$ If we take the limit, the above formula suggests that $$L_t^0(B)=\lim_{\varepsilon\to0}\dfrac{1}{2}\int_0^t\dfrac{\varepsilon}{(\varepsilon+B_s^2)^{3/2}}\,ds\tag{3}.$$ My question is can we show that by direct computation that equation (3) and (1) are the same?","To keep this question simple, we only consider the local time of a standard Brownian motion at zero, we denote it as . Generally, we define Another definition is given by We can approximate pointwise by by taking . Applying Ito formula to we get, If we take the limit, the above formula suggests that My question is can we show that by direct computation that equation (3) and (1) are the same?","B_t L_t^0 \tag{1} L_t^0(B)=\lim_{\varepsilon\to\infty}\dfrac{1}{2\varepsilon}\int_0^t1_{(-\varepsilon,\varepsilon)}(B_s)\,ds.  L_t^0(B)= |B_t|-\int_0^t\text{sgn}(B_s)\,dB_s\tag{2}. |B_t| \sqrt{\varepsilon+B_t^2} \varepsilon\to0 \sqrt{\varepsilon+B_t^2} \sqrt{\varepsilon+B_t^2}=\sqrt{\varepsilon}+\int_0^t\dfrac{B_s}{\sqrt{\varepsilon+B_s^2}}\,dB_s+\dfrac{1}{2}\int_0^t\dfrac{\varepsilon}{(\varepsilon+B_s^2)^{3/2}}\,ds.  L_t^0(B)=\lim_{\varepsilon\to0}\dfrac{1}{2}\int_0^t\dfrac{\varepsilon}{(\varepsilon+B_s^2)^{3/2}}\,ds\tag{3}.","['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
20,"Probability task, dispersion","Probability task, dispersion",,"$N$ men are sitting at the table. Each of them tosses the dice. Let $A$ be the random variable representing number of people, who got rolled number that is equal to both neighbour's . Find $\mathbb{E}X$ and $\mathbb{D}X$ . ( $\mathbb{D}$ - stands for dispersion/variance here). I managed to calculate $\mathbb{E}X$ , still haven't found $\mathbb{D}X$ . May you help me with $\mathbb{D}X$ ? I've been thinking about using somehow the following property: It is known that $\mathbb{D}X=\mathbb{E}X^2-(\mathbb{E}X)^2$ While knowing what $\mathbb{E}X$ is equal to we may find $(\mathbb{E}X)^2$ easily, in order to find $\mathbb{E}X^2$ I want to use following property: for $B= \varphi (A): \mathbb{E} B= \sum_{k} \varphi (x_k) \cdot P(ξ = x_k) $","men are sitting at the table. Each of them tosses the dice. Let be the random variable representing number of people, who got rolled number that is equal to both neighbour's . Find and . ( - stands for dispersion/variance here). I managed to calculate , still haven't found . May you help me with ? I've been thinking about using somehow the following property: It is known that While knowing what is equal to we may find easily, in order to find I want to use following property: for",N A \mathbb{E}X \mathbb{D}X \mathbb{D} \mathbb{E}X \mathbb{D}X \mathbb{D}X \mathbb{D}X=\mathbb{E}X^2-(\mathbb{E}X)^2 \mathbb{E}X (\mathbb{E}X)^2 \mathbb{E}X^2 B= \varphi (A): \mathbb{E} B= \sum_{k} \varphi (x_k) \cdot P(ξ = x_k) ,"['probability', 'random-variables', 'variance']"
21,What is the probability that the coriander and basil are on the same side of the parsley?,What is the probability that the coriander and basil are on the same side of the parsley?,,"Jack has seven unlabelled seeds for different herbs (coriander, basil, parsley, sage, thyme, oregano and mint). He plants the seeds in one row. What is the probability that the coriander and basil are on the same side of the parsley? I have looked at this and I'm wondering if the probabilities are the same based on the reasoning given?","Jack has seven unlabelled seeds for different herbs (coriander, basil, parsley, sage, thyme, oregano and mint). He plants the seeds in one row. What is the probability that the coriander and basil are on the same side of the parsley? I have looked at this and I'm wondering if the probabilities are the same based on the reasoning given?",,['probability']
22,What is ${\cal P}(A ) \cap A$?,What is ?,{\cal P}(A ) \cap A,"I need some clarification I am not sure but what is : ${\cal P}(A ) \cap  A$ equal to the empty set? For any $A$ ? If not how can we prove it ? Dir example $A=\{1,2\}$ , ${\cal P}(A) = \{ \{1\},\{2\},\{1,2\}, \emptyset \}$ . Then ${\cal P}(A) \cap A = A$ ?","I need some clarification I am not sure but what is : equal to the empty set? For any ? If not how can we prove it ? Dir example , . Then ?","{\cal P}(A ) \cap  A A A=\{1,2\} {\cal P}(A) = \{ \{1\},\{2\},\{1,2\}, \emptyset \} {\cal P}(A) \cap A = A","['probability', 'elementary-set-theory']"
23,Why uniform distribution is not memoryless?,Why uniform distribution is not memoryless?,,"The exponential and geometric distributions have the memoryless property, meaning that the distribution of the waiting times between the events does not depend on how much time has elapsed already. But I'm trying to intuitively understand why uniform distribution is not memoryless. Can someone please help me with that? Maybe this example will explain what is my concern: Scenario 1: We have a room, to which $k$ identical people arrived (the arrived at different times). Each person stayed in the room a random amount of time $x$ , where $x$ is from exponential distribution. Now, I observe one person leaving - the probability that this person is the same one who entered the room first, is the same as the probability it was the second one, the third one etc. So, the person leaving the room can be with equal chances any of the $k$ people. Scenario 2: I have the same story, but now the people do not wait random exponential time. Instead, when the people enter the room one person is picked uniformly at random to leave the room. Then the next one, and the next one. So, given the uniform distribution is not memoryless, in the second scenario can I somehow tell which of the incoming persons is no leaving? If not, how is this different from the memoryless property?","The exponential and geometric distributions have the memoryless property, meaning that the distribution of the waiting times between the events does not depend on how much time has elapsed already. But I'm trying to intuitively understand why uniform distribution is not memoryless. Can someone please help me with that? Maybe this example will explain what is my concern: Scenario 1: We have a room, to which identical people arrived (the arrived at different times). Each person stayed in the room a random amount of time , where is from exponential distribution. Now, I observe one person leaving - the probability that this person is the same one who entered the room first, is the same as the probability it was the second one, the third one etc. So, the person leaving the room can be with equal chances any of the people. Scenario 2: I have the same story, but now the people do not wait random exponential time. Instead, when the people enter the room one person is picked uniformly at random to leave the room. Then the next one, and the next one. So, given the uniform distribution is not memoryless, in the second scenario can I somehow tell which of the incoming persons is no leaving? If not, how is this different from the memoryless property?",k x x k,"['probability', 'probability-distributions', 'uniform-distribution', 'exponential-distribution']"
24,Number of integers that do not show up,Number of integers that do not show up,,"An integer is repeatedly drawn at random from $1, 2, . . . , 10$ . What are the expected value and the standard deviation of the number of integers from $1, 2, . . . , 10$ that do not show up in $20$ drawings? Let $X_i$ be the random variable that assumes value $1$ if the number $i$ doesn't show up in $20$ drawings and $0$ otherwise. So $\mathbb{P}(X_i=1)=(\frac{9}{10})^{20}$ . Since $\mathbb{E}[X_i]=0\cdot (\frac{1}{10})^{20}+1\cdot (\frac{9}{10})^{20}=(\frac{9}{10})^{20}$ , I know that: $\mathbb{E}[X]=\mathbb{E}[X_1]+...+\mathbb{E}[X_{10}]=(\frac{9}{10})^{20}+...+(\frac{9}{10})^{20}=10\cdot (\frac{9}{10})^{20}=1,216$ $\operatorname{Var}[X]=\mathbb{E}[X^2]-\mathbb{E}[X]^2=\space{?}-(1,216)^2$ How do I find $\mathbb{E}[X^2]$ ? EDIT:","An integer is repeatedly drawn at random from . What are the expected value and the standard deviation of the number of integers from that do not show up in drawings? Let be the random variable that assumes value if the number doesn't show up in drawings and otherwise. So . Since , I know that: How do I find ? EDIT:","1, 2, . . . , 10 1, 2, . . . , 10 20 X_i 1 i 20 0 \mathbb{P}(X_i=1)=(\frac{9}{10})^{20} \mathbb{E}[X_i]=0\cdot (\frac{1}{10})^{20}+1\cdot (\frac{9}{10})^{20}=(\frac{9}{10})^{20} \mathbb{E}[X]=\mathbb{E}[X_1]+...+\mathbb{E}[X_{10}]=(\frac{9}{10})^{20}+...+(\frac{9}{10})^{20}=10\cdot (\frac{9}{10})^{20}=1,216 \operatorname{Var}[X]=\mathbb{E}[X^2]-\mathbb{E}[X]^2=\space{?}-(1,216)^2 \mathbb{E}[X^2]",['probability']
25,How does meeting probability on a finite $d$-dimensional grid depend on the dimension?,How does meeting probability on a finite -dimensional grid depend on the dimension?,d,"At the beginning, we put two people $A$ and $B$ randomly on a finite $d$ -dimensional closed grid. Along each dimension there are $2^n$ positions $p_k$ , so $p_{2^n}=p_0$ . Think of a circle if $d=1$ or a torus if $d=2$ and so on... Let's say $m$ is the minimal number of steps to reach each other. $m$ is unknown to $A$ and $B$ . Now both start to move step by step along a randomly chosen direction on the grid. If we wait for less than $m/2$ steps, it is not be possible for them to meet at all. If we wait for infinitely many steps, I would expect them to meet somewhen for sure. How does the meeting probability as a function of steps on a finite $d$ -dimensional grid depend on the dimension?","At the beginning, we put two people and randomly on a finite -dimensional closed grid. Along each dimension there are positions , so . Think of a circle if or a torus if and so on... Let's say is the minimal number of steps to reach each other. is unknown to and . Now both start to move step by step along a randomly chosen direction on the grid. If we wait for less than steps, it is not be possible for them to meet at all. If we wait for infinitely many steps, I would expect them to meet somewhen for sure. How does the meeting probability as a function of steps on a finite -dimensional grid depend on the dimension?",A B d 2^n p_k p_{2^n}=p_0 d=1 d=2 m m A B m/2 d,"['probability', 'random-walk']"
26,Find the probability that at least one valve is defective when two valves are drawn at random.,Find the probability that at least one valve is defective when two valves are drawn at random.,,"Problem Statement: A factory A produces $10\ \%$ defective valves and another factory $B$ produces $\mbox{$20\ \%$}$ defective valves. A bag contains $4$ valves of factory $A$ and $5$ valves of factory B. If two valves are drawn at random from the bag, find the probability that at least one valve is defective. This question has been asked here once. Find the probability that atleast one valve is defective. Now, clearly Probability of drawing atleast one defective valve)=1- Probability that both valves drawn are non-defective valves Using this, the required probability is $ =1-\left(\frac{\binom{4}{2}}{\binom{9}{2}}(0.9)^2+\frac{\binom{5}{2}}{\binom{9}{2}}(0.8)^2+\frac{\binom{4}{1}\binom{5}{1}}{\binom{9}{2}}(0.9)(0.8)\right)=\frac{517}{1800}, \label{1}\tag{1} $ as OP has also shown in the above linked post. However, this is where the confusion arises: Alternatively, let's consider the following mutually exclusive events: Both valves are defective and are from factory $A$ Both valves are defective and are from factory $B$ Both valves are defective (one from $A$ and the other from $B$ ) One valve is drawn from $A$ and is defective while the other is drawn from $B$ and is non-defective. One valve is drawn from $B$ and is defective while the other is drawn from $A$ and is non-defective. Now the required probability = Sum of all the probabilities of mutually exclusive events listed above. Let's denote probability for the ith event listed above by $P(i)$ , where $i=1,2,3,4,5$ $P(1)=\frac{^4C_2}{^9C_2}(0.1)^2\;\;,P(2)=\frac{^5C_2}{^9C_2}(0.2)^2\;\;,P(3)=\frac{^4C_1 \times ^5C_1}{^9C_2}(0.1)(0.2)\;\;$ $P(4)=\frac{^4C_1\times ^5C_1}{^9C_2}(0.1)(0.8)\;\; ,P(5)=\frac{^4C_1 \times ^5C_1}{^9C_2}(0.9)(0.2)\;\;$ Therefore, the required probability is $$P=\sum_{i=1}^{5}P(i)=1/600+1/90+1/90+2/45+1/10=303/1800 \label{2}\tag{2}$$ I want to know why answers in (\ref{1}) and (\ref{2}) above are different . In fact, in the link above, OP had mentioned that answer given in his book was $303/1800$ , whereas the comments and answers to that post mentioned the answer as wrong. But $(2)$ clearly shows that there is nothing wrong with the answer. Please help. Thanks.","Problem Statement: A factory A produces defective valves and another factory produces defective valves. A bag contains valves of factory and valves of factory B. If two valves are drawn at random from the bag, find the probability that at least one valve is defective. This question has been asked here once. Find the probability that atleast one valve is defective. Now, clearly Probability of drawing atleast one defective valve)=1- Probability that both valves drawn are non-defective valves Using this, the required probability is as OP has also shown in the above linked post. However, this is where the confusion arises: Alternatively, let's consider the following mutually exclusive events: Both valves are defective and are from factory Both valves are defective and are from factory Both valves are defective (one from and the other from ) One valve is drawn from and is defective while the other is drawn from and is non-defective. One valve is drawn from and is defective while the other is drawn from and is non-defective. Now the required probability = Sum of all the probabilities of mutually exclusive events listed above. Let's denote probability for the ith event listed above by , where Therefore, the required probability is I want to know why answers in (\ref{1}) and (\ref{2}) above are different . In fact, in the link above, OP had mentioned that answer given in his book was , whereas the comments and answers to that post mentioned the answer as wrong. But clearly shows that there is nothing wrong with the answer. Please help. Thanks.","10\ \% B \mbox{20\ \%} 4 A 5 
=1-\left(\frac{\binom{4}{2}}{\binom{9}{2}}(0.9)^2+\frac{\binom{5}{2}}{\binom{9}{2}}(0.8)^2+\frac{\binom{4}{1}\binom{5}{1}}{\binom{9}{2}}(0.9)(0.8)\right)=\frac{517}{1800},
\label{1}\tag{1}
 A B A B A B B A P(i) i=1,2,3,4,5 P(1)=\frac{^4C_2}{^9C_2}(0.1)^2\;\;,P(2)=\frac{^5C_2}{^9C_2}(0.2)^2\;\;,P(3)=\frac{^4C_1 \times ^5C_1}{^9C_2}(0.1)(0.2)\;\; P(4)=\frac{^4C_1\times ^5C_1}{^9C_2}(0.1)(0.8)\;\; ,P(5)=\frac{^4C_1 \times ^5C_1}{^9C_2}(0.9)(0.2)\;\; P=\sum_{i=1}^{5}P(i)=1/600+1/90+1/90+2/45+1/10=303/1800
\label{2}\tag{2} 303/1800 (2)","['probability', 'combinatorics', 'solution-verification']"
27,From pointwise convergence in probability to uniform convergence in probability for non-decreasing random processes,From pointwise convergence in probability to uniform convergence in probability for non-decreasing random processes,,"I have a sequence of non-decreasing random processes $D_n:[0,1]\rightarrow \mathbb{R}$ (for each $n\geq 1$ , $u\leq v$ implies $D_n(u)\leq D_n(v)$ ) such that $D_n(0)=0$ a.s. and for every $t\in [0,1]$ the following convergence holds: $D_n(t)\overset{\mathbb{P}}{\underset{n\to\infty}{\longrightarrow}}t$ (in fact I can even prove it in $\mathbb{L}^2$ , but it doesn't seem necessary). I want to prove a uniform convergence in probability, i.e. $\sup_{t\in [0,1]}  \vert D_n(t) -t\vert \overset{\mathbb{P}}{\underset{n\to\infty}{\longrightarrow}}0$ . I managed to prove it (more details below), but the idea is pretty similar to the proof of a standard analytic result (see Julian's answer for more details) : pointwise convergence of monotonous functions on a compact set to a continuous limit implies uniform convergence. I am asking : Is there a way to apply directly (without rewritting the proof) this theorem in such context, even if the functions are random  ? If not, is there an ersatz of Dini's Theorem for convergence in probability ? It seems too obvious for not having been done yet... N.B: The ""standard analytic result"" mentioned above is called ""second Dini's Theorem"" in french, but seems to have no english name or source. My proof: Let $\varepsilon >0$ , consider an integer $m>\frac{2}{\varepsilon}$ . Then $\Big( \vert D_n(\frac{k}{m})-\frac{k}{m}\vert \leq \frac{\varepsilon}{2} \ \forall \ k=0,\dots, m\Big)$ implies $\sup_{t\in [0,1]}\vert D_n(t)-t\vert \leq \varepsilon$ (because the random functions $D_n$ are non-decreasing). Thus the probability of the first event is smaller or equal to the probability of the second, i.e.: $$\mathbb{P}\left(\left\vert D_n\left(\frac{k}{m}\right)-\frac{k}{m}\right\vert \leq \frac{\varepsilon}{2} \ \forall \ k=0,\dots, m\right)\leq \mathbb{P}\left(\sup_{t\in [0,1]}\vert D_n(t)-t\vert \leq \varepsilon\right).$$ If I consider the complementary events, I can use the union bound to get $$\mathbb{P}\left(\sup_{t\in [0,1]}\vert D_n(t)-t\vert > \varepsilon\right)\leq \sum_{k=0}^m \mathbb{P}\left( \left\vert D_n\left(\frac{k}{m}\right)-\frac{k}{m}\right\vert > \frac{\varepsilon}{2}\right).$$ The sum in the right-hand side converges to $0$ since it is a sum of finitely many terms going to $0$ (the choice of $m$ only depends on $\varepsilon$ , not on $n$ ).","I have a sequence of non-decreasing random processes (for each , implies ) such that a.s. and for every the following convergence holds: (in fact I can even prove it in , but it doesn't seem necessary). I want to prove a uniform convergence in probability, i.e. . I managed to prove it (more details below), but the idea is pretty similar to the proof of a standard analytic result (see Julian's answer for more details) : pointwise convergence of monotonous functions on a compact set to a continuous limit implies uniform convergence. I am asking : Is there a way to apply directly (without rewritting the proof) this theorem in such context, even if the functions are random  ? If not, is there an ersatz of Dini's Theorem for convergence in probability ? It seems too obvious for not having been done yet... N.B: The ""standard analytic result"" mentioned above is called ""second Dini's Theorem"" in french, but seems to have no english name or source. My proof: Let , consider an integer . Then implies (because the random functions are non-decreasing). Thus the probability of the first event is smaller or equal to the probability of the second, i.e.: If I consider the complementary events, I can use the union bound to get The sum in the right-hand side converges to since it is a sum of finitely many terms going to (the choice of only depends on , not on ).","D_n:[0,1]\rightarrow \mathbb{R} n\geq 1 u\leq v D_n(u)\leq D_n(v) D_n(0)=0 t\in [0,1] D_n(t)\overset{\mathbb{P}}{\underset{n\to\infty}{\longrightarrow}}t \mathbb{L}^2 \sup_{t\in [0,1]}  \vert D_n(t) -t\vert \overset{\mathbb{P}}{\underset{n\to\infty}{\longrightarrow}}0 \varepsilon >0 m>\frac{2}{\varepsilon} \Big( \vert D_n(\frac{k}{m})-\frac{k}{m}\vert \leq \frac{\varepsilon}{2} \ \forall \ k=0,\dots, m\Big) \sup_{t\in [0,1]}\vert D_n(t)-t\vert \leq \varepsilon D_n \mathbb{P}\left(\left\vert D_n\left(\frac{k}{m}\right)-\frac{k}{m}\right\vert \leq \frac{\varepsilon}{2} \ \forall \ k=0,\dots, m\right)\leq \mathbb{P}\left(\sup_{t\in [0,1]}\vert D_n(t)-t\vert \leq \varepsilon\right). \mathbb{P}\left(\sup_{t\in [0,1]}\vert D_n(t)-t\vert > \varepsilon\right)\leq \sum_{k=0}^m \mathbb{P}\left( \left\vert D_n\left(\frac{k}{m}\right)-\frac{k}{m}\right\vert > \frac{\varepsilon}{2}\right). 0 0 m \varepsilon n","['probability', 'convergence-divergence', 'stochastic-processes', 'uniform-convergence']"
28,Interested in a closed form for this recursive sequence.,Interested in a closed form for this recursive sequence.,,"Consider the following game: you start with $ n $ coins.  You flip all of your coins.  Any coins that come up heads you ""remove"" from the game, while any coins that come up tails you keep in the game.  You continue this process until you have removed all coins from the game.  Let your score $ s $ be defined as the number of rounds of flipping before the game was over (including the last flip, say). Let $ a_n $ be the expected value of the score when you start with $ n $ coins.  It is not hard to see that $$ a_n = \frac{1}{2^n - 1} \left(1 + \sum_{m=0}^{n-1}{{n\choose m} (a_m + 1)}\right) $$ Are there any generating functionology wizards out there who know if this could be turned into a closed-form formula for $ a_n $ ? Note, this question was asked here: You are flipping n fair coins, putting aside those that come up heads after each flip. What's the expected number of rounds? , but the answer is entirely unsatisfactory; they only provide a heuristic which is asymptotically correct. Edit: here is a quick mathematica experiment: Edit 2: While investigating the first differences of this function, we find a lovely pattern.  I plotted the following function $$ g(n) := n \left( \frac{1}{\log(2)} - n (a_{n+1} - a_{n}) \right) $$ resulting in the following plot, clearly oscillating about $ 1/\log(2) $ : (Here, ""dev[n]"" is the first-difference function $ a_{n+1} - a_n $ .)","Consider the following game: you start with coins.  You flip all of your coins.  Any coins that come up heads you ""remove"" from the game, while any coins that come up tails you keep in the game.  You continue this process until you have removed all coins from the game.  Let your score be defined as the number of rounds of flipping before the game was over (including the last flip, say). Let be the expected value of the score when you start with coins.  It is not hard to see that Are there any generating functionology wizards out there who know if this could be turned into a closed-form formula for ? Note, this question was asked here: You are flipping n fair coins, putting aside those that come up heads after each flip. What's the expected number of rounds? , but the answer is entirely unsatisfactory; they only provide a heuristic which is asymptotically correct. Edit: here is a quick mathematica experiment: Edit 2: While investigating the first differences of this function, we find a lovely pattern.  I plotted the following function resulting in the following plot, clearly oscillating about : (Here, ""dev[n]"" is the first-difference function .)"," n   s   a_n   n  
a_n = \frac{1}{2^n - 1} \left(1 + \sum_{m=0}^{n-1}{{n\choose m} (a_m + 1)}\right)
  a_n  
g(n) := n \left( \frac{1}{\log(2)} - n (a_{n+1} - a_{n}) \right)
  1/\log(2)   a_{n+1} - a_n ","['probability', 'generating-functions']"
29,"Random walk : probability of return in $\leq N$ steps, equivalent as $N\to\infty$","Random walk : probability of return in  steps, equivalent as",\leq N N\to\infty,"It is well known that in dimension 1, the probability of at least one return to the origin in $N$ steps or less is $$ q_{N}=1-{1 \over {2^{2N}}}{\binom {2N}{N}}\,.$$ Using Stirling's formula one has the equivalent $$ q_{N}\sim  1 - {1 \over {\sqrt {\pi N}}} $$ which explains that the convergence is slowish, and is consistent with the fact that the expected number of steps (which is actually $\sum 1-q_N$ ) needed to return to the origin is not finite. I was wondering if we could obtain a similar equivalent in dimension 2 ? I expect convergence to be much slower, maybe involving $\frac 1{\log(N)}$ or even $\frac 1{\log(\log(N))}$ ? If one writes $u_n$ for the probability to be at the origin at step $n$ and $f_n$ for the probability of a first return at step $n$ , then the sequences $u$ and $f$ are linked through a generating series, as already pointed out in Tom Boardman's answer here Proving that 1- and 2-d simple symmetric random walks return to the origin with probability 1 In the document Tom Boardman linked http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter12.pdf , pages 3-8 the $f_n$ are computed in dimension $1$ but not $2$ . Knowing the $f_n$ , we would just have to compute an equivalent of their sum from $1$ to $N$ as $N\to \infty$ (the series $w$ in the document), but I'm not sure these computations are ""easily"" doable. Does anybody know if this has already been done, or if there is an easier way to answer my question in bold ? Thanks a lot","It is well known that in dimension 1, the probability of at least one return to the origin in steps or less is Using Stirling's formula one has the equivalent which explains that the convergence is slowish, and is consistent with the fact that the expected number of steps (which is actually ) needed to return to the origin is not finite. I was wondering if we could obtain a similar equivalent in dimension 2 ? I expect convergence to be much slower, maybe involving or even ? If one writes for the probability to be at the origin at step and for the probability of a first return at step , then the sequences and are linked through a generating series, as already pointed out in Tom Boardman's answer here Proving that 1- and 2-d simple symmetric random walks return to the origin with probability 1 In the document Tom Boardman linked http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter12.pdf , pages 3-8 the are computed in dimension but not . Knowing the , we would just have to compute an equivalent of their sum from to as (the series in the document), but I'm not sure these computations are ""easily"" doable. Does anybody know if this has already been done, or if there is an easier way to answer my question in bold ? Thanks a lot","N  q_{N}=1-{1 \over {2^{2N}}}{\binom {2N}{N}}\,.  q_{N}\sim  1 - {1 \over {\sqrt {\pi N}}}  \sum 1-q_N \frac 1{\log(N)} \frac 1{\log(\log(N))} u_n n f_n n u f f_n 1 2 f_n 1 N N\to \infty w","['probability', 'probability-theory', 'random-walk']"
30,Odds of an Unwinnable Game of Rummikub,Odds of an Unwinnable Game of Rummikub,,"I was playing the game Rummikub with my family the other day and the tiles were drawn in such a way that the game could not end. Here are the rules: There are 106 tiles in the game which at the game's start are face down; there are two full ""decks"" of cards (represented by colors instead of suit and 11,12,13 instead of face cards) and two jokers, which act as wild cards. Tiles placed on the board remain there, face up, for the rest of the game, and can be manipulated in the ways described in rule #4. This is a ""rummy"" style game, meaning that legal groupings of tiles are either sets of a number or straights of a single color. Members of sets are unique, meaning that groupings of this kind are at most size 4. The minimum size for any grouping is 3. Groupings are created from the tiles in a player's hand, either (A) entirely from the player's hand, (B) adding one or more tiles to an existing grouping, or (C) breaking up and reforming groupings already present on the board such that method (B) may be used. Note that method (C) is legal even if an illegal grouping is created before the player adds their tile, such that after their turn all groupings on the board are legal. Jokers may be used by their initial player as a stand-in for any tile on the board, and any player on the board may use them afterward by replacing them with the tile they stand in for. A joker which exists on the board must be played by the end of a player's turn and may not be returned to that player's hand. A player wins when they have no tiles in their hand. There are maximum four players to the game, and minimum two. Each player begins the game with 14 tiles. There is no limit as to the number of tiles a player can play during their turn. If a player cannot play a tile during their turn, they draw a tile. Before they begin regular play, each player must ""go down"", meaning create groupings entirely from their hand such that the sum of the tiles of all their groupings is greater than or equal to 30. Each player ""goes down"" separately, meaning that some players may be in the midst of regular play while others are stuck with usable tiles in their hand that do not exceed 30. Jokers cannot be used to ""go down"". There are additional irrelevant rules which deal with scoring. My question is: what are the odds that such a game will end without anyone winning, i.e. all players have no available moves and there are no more face down tiles on the board.? My suspicion is that the odds of this are astronomically low; in fact, I would have bet against it being possible until it happened to me the other night. I do not have extensive mathematical experience but I am towards the end of an undergraduate degree of mathematics, so if you can manage, please form your answers with this in mind. Please let me know if you need clarification on the rules.","I was playing the game Rummikub with my family the other day and the tiles were drawn in such a way that the game could not end. Here are the rules: There are 106 tiles in the game which at the game's start are face down; there are two full ""decks"" of cards (represented by colors instead of suit and 11,12,13 instead of face cards) and two jokers, which act as wild cards. Tiles placed on the board remain there, face up, for the rest of the game, and can be manipulated in the ways described in rule #4. This is a ""rummy"" style game, meaning that legal groupings of tiles are either sets of a number or straights of a single color. Members of sets are unique, meaning that groupings of this kind are at most size 4. The minimum size for any grouping is 3. Groupings are created from the tiles in a player's hand, either (A) entirely from the player's hand, (B) adding one or more tiles to an existing grouping, or (C) breaking up and reforming groupings already present on the board such that method (B) may be used. Note that method (C) is legal even if an illegal grouping is created before the player adds their tile, such that after their turn all groupings on the board are legal. Jokers may be used by their initial player as a stand-in for any tile on the board, and any player on the board may use them afterward by replacing them with the tile they stand in for. A joker which exists on the board must be played by the end of a player's turn and may not be returned to that player's hand. A player wins when they have no tiles in their hand. There are maximum four players to the game, and minimum two. Each player begins the game with 14 tiles. There is no limit as to the number of tiles a player can play during their turn. If a player cannot play a tile during their turn, they draw a tile. Before they begin regular play, each player must ""go down"", meaning create groupings entirely from their hand such that the sum of the tiles of all their groupings is greater than or equal to 30. Each player ""goes down"" separately, meaning that some players may be in the midst of regular play while others are stuck with usable tiles in their hand that do not exceed 30. Jokers cannot be used to ""go down"". There are additional irrelevant rules which deal with scoring. My question is: what are the odds that such a game will end without anyone winning, i.e. all players have no available moves and there are no more face down tiles on the board.? My suspicion is that the odds of this are astronomically low; in fact, I would have bet against it being possible until it happened to me the other night. I do not have extensive mathematical experience but I am towards the end of an undergraduate degree of mathematics, so if you can manage, please form your answers with this in mind. Please let me know if you need clarification on the rules.",,"['probability', 'combinatorics', 'card-games']"
31,Is this like the Birthday Problem? Poisson Halloween Party,Is this like the Birthday Problem? Poisson Halloween Party,,"Suppose that there are n guests at a Halloween party, and that each is wearing one of 200 possible costumes available at local store, uniformly at random and independently of all other guests. Using Poisson approximation and the value $\sqrt{\log{2}}$ = $0.83$ , show that only about n = 17 guests are needed to ensure that some pair of guests are wearing the same costume with probabiliy at least 50%. The hint I received for this question was: ""This approximation is quite accurate. It can be shown that, when $n = 17$ , the true probability of a match is $1 − (200)_{17}/200^{17}$ = 50.3%."" I interpreted this question as one similar to the ""Birthday Problem"" often discussed in probability theory courses. But I'm not sure how to handle/incorporate the Poisson approximation and 'uniformly at random' aspects of this problem. It would be great to hear any insight as to how I could possibly structure this problem—thank you!","Suppose that there are n guests at a Halloween party, and that each is wearing one of 200 possible costumes available at local store, uniformly at random and independently of all other guests. Using Poisson approximation and the value = , show that only about n = 17 guests are needed to ensure that some pair of guests are wearing the same costume with probabiliy at least 50%. The hint I received for this question was: ""This approximation is quite accurate. It can be shown that, when , the true probability of a match is = 50.3%."" I interpreted this question as one similar to the ""Birthday Problem"" often discussed in probability theory courses. But I'm not sure how to handle/incorporate the Poisson approximation and 'uniformly at random' aspects of this problem. It would be great to hear any insight as to how I could possibly structure this problem—thank you!",\sqrt{\log{2}} 0.83 n = 17 1 − (200)_{17}/200^{17},"['probability', 'statistics']"
32,"Let $Z\in \mathcal{N}(0,I)$ and $A=\{(x_1,x_2,x_3): x_1\le x_2 \le x_3 \}$. Show $P(Z+\mu \in A) \le P(Z \in A)$ is $\mu \notin A$.",Let  and . Show  is .,"Z\in \mathcal{N}(0,I) A=\{(x_1,x_2,x_3): x_1\le x_2 \le x_3 \} P(Z+\mu \in A) \le P(Z \in A) \mu \notin A","Suppose that $A=\{(x_1,x_2,x_3):  x_1\le x_2 \le x_3 \}$ .  Let $Z \in \mathbb{R}^3$ be a standard normal random vector. I am trying to see if the following inequality is true \begin{align} P(Z+\mu \in A) \le  P(Z \in A) \end{align} for all $\mu \notin A$ . My intuition: I am thinking of $Z$ as a ball centered at zero and $A$ as a cone starting at zero.  If we move a center of the ball farther from the cone, then the intersection (probability) should go down.","Suppose that .  Let be a standard normal random vector. I am trying to see if the following inequality is true for all . My intuition: I am thinking of as a ball centered at zero and as a cone starting at zero.  If we move a center of the ball farther from the cone, then the intersection (probability) should go down.","A=\{(x_1,x_2,x_3):  x_1\le x_2 \le x_3 \} Z \in \mathbb{R}^3 \begin{align}
P(Z+\mu \in A) \le  P(Z \in A)
\end{align} \mu \notin A Z A","['probability', 'probability-theory']"
33,For the case n=200 use the Central Limit Theorem to approximate the probability.,For the case n=200 use the Central Limit Theorem to approximate the probability.,,"The first part of this question I thought was pretty easy. It was: The random variables $X_1,X_2,…$ are independent and identically distributed with the Probability Mass Function $Pr(X=−1)=Pr(X=3)=0.5$ Find the mean: $-1*0.5+3*0.5=1$ Find the Variance: $((-1)^2*0.5+3^2*0.5)-E[X]^2=5-1=4$ Now for the second part, I am asked: a) For the case $n=200$ use the Central Limit Theorem to approximate the probability $Pr(ln(\bar X>0)$ , where: $$\bar X=(1/200)\sum_{i=1}^{200} X_i $$ is the sample mean and ln denotes the natural logarithm (i.e., logarithm with base e). b) Find the minimum n for which: $$Pr(\sum_{i=1}^n X_i>190)>0.99$$ I am really struggling when using the central limit theorem as my teacher has not explained it to me very well. I find this question especially hard due to the ln in the probability for part a. And also finding the minimum value in part b as we have not been taught this. Could anyone help by providing useful links to help me solve these or work them through with me? Any help would be massively appreciated. Thank you!","The first part of this question I thought was pretty easy. It was: The random variables are independent and identically distributed with the Probability Mass Function Find the mean: Find the Variance: Now for the second part, I am asked: a) For the case use the Central Limit Theorem to approximate the probability , where: is the sample mean and ln denotes the natural logarithm (i.e., logarithm with base e). b) Find the minimum n for which: I am really struggling when using the central limit theorem as my teacher has not explained it to me very well. I find this question especially hard due to the ln in the probability for part a. And also finding the minimum value in part b as we have not been taught this. Could anyone help by providing useful links to help me solve these or work them through with me? Any help would be massively appreciated. Thank you!","X_1,X_2,… Pr(X=−1)=Pr(X=3)=0.5 -1*0.5+3*0.5=1 ((-1)^2*0.5+3^2*0.5)-E[X]^2=5-1=4 n=200 Pr(ln(\bar X>0) \bar X=(1/200)\sum_{i=1}^{200} X_i  Pr(\sum_{i=1}^n X_i>190)>0.99","['probability', 'statistics']"
34,Incorrect theorem: $\lambda$-system implies $\sigma$-algebra. What's wrong?,Incorrect theorem: -system implies -algebra. What's wrong?,\lambda \sigma,"I am currently taking a course on probability theory for mathematicians where we're doing some measure theory. I've been thinking about how it is that if $\mathcal{L}$ is a $\lambda$ -system and a $\pi$ -system, then $\mathcal{L}$ is a $\sigma$ -algebra (the converse is very straightforward). Before explaining what I mean, I should point out that we have taken the following definition of $\lambda$ -system. $\mathcal{L} \in \mathcal{P}(\Omega) $ is a $\lambda$ -system iff $\Omega \in \mathcal{L}$ $A, B \in \mathcal{L}$ and $A \subseteq B \Rightarrow B \setminus A \in \mathcal{L}$ $A_1, A_2, \ldots \in\mathcal{L}$ such that $A_n \uparrow A \Rightarrow A \in \mathcal{L}$ Suppose $\mathcal{L}$ is a $\lambda$ -system. For $\mathcal{L}$ to be a $\sigma$ -algebra, in addition to the easy-to-check fact that for any set in $\mathcal{L}$ , its complement is also in $\mathcal{L}$ , the enumerable union of an arbitrary collection of sets in $\mathcal{L}$ must also be in $\mathcal{L}$ . So I started by taking two arbitrary sets. Let $A, B \in \mathcal{L}$ . Suppose $D_1 = A, D_j = A \cup B, \forall j \in \mathbb{N}-\{1\}$ . Then $D_1 \subseteq D_2 \subseteq D_3 \subseteq \ldots $ and clearly $\cup_{j \in \mathbb{N}} D_j = A \cup B$ . This would mean that $D_j \uparrow (A \cup B)$ , so property $(3)$ above would imply that $A \cup B \in \mathcal{L}$ . But then if I already had this for two sets, I could generalize for finite unions. Moreover, if $A_1, A_2, \ldots \in L$ , then $$\bigcup\limits_{j=1}^n A_j \uparrow \bigcup\limits_{j=1}^\infty A_j. $$ Again, property $(3)$ would imply that $\bigcup\limits_{j=1}^\infty A_j \in \mathcal{L}$ . Clearly there is something wrong, since not all $\lambda$ -systems are $\sigma$ -algebras . I would really appreciate that you point out any mistakes in the reasoning above.","I am currently taking a course on probability theory for mathematicians where we're doing some measure theory. I've been thinking about how it is that if is a -system and a -system, then is a -algebra (the converse is very straightforward). Before explaining what I mean, I should point out that we have taken the following definition of -system. is a -system iff and such that Suppose is a -system. For to be a -algebra, in addition to the easy-to-check fact that for any set in , its complement is also in , the enumerable union of an arbitrary collection of sets in must also be in . So I started by taking two arbitrary sets. Let . Suppose . Then and clearly . This would mean that , so property above would imply that . But then if I already had this for two sets, I could generalize for finite unions. Moreover, if , then Again, property would imply that . Clearly there is something wrong, since not all -systems are -algebras . I would really appreciate that you point out any mistakes in the reasoning above.","\mathcal{L} \lambda \pi \mathcal{L} \sigma \lambda \mathcal{L} \in \mathcal{P}(\Omega)  \lambda \Omega \in \mathcal{L} A, B \in \mathcal{L} A \subseteq B \Rightarrow B \setminus A \in \mathcal{L} A_1, A_2, \ldots \in\mathcal{L} A_n \uparrow A \Rightarrow A \in \mathcal{L} \mathcal{L} \lambda \mathcal{L} \sigma \mathcal{L} \mathcal{L} \mathcal{L} \mathcal{L} A, B \in \mathcal{L} D_1 = A, D_j = A \cup B, \forall j \in \mathbb{N}-\{1\} D_1 \subseteq D_2 \subseteq D_3 \subseteq \ldots  \cup_{j \in \mathbb{N}} D_j = A \cup B D_j \uparrow (A \cup B) (3) A \cup B \in \mathcal{L} A_1, A_2, \ldots \in L \bigcup\limits_{j=1}^n A_j \uparrow \bigcup\limits_{j=1}^\infty A_j.  (3) \bigcup\limits_{j=1}^\infty A_j \in \mathcal{L} \lambda \sigma","['probability', 'measure-theory']"
35,The Probability Generating Functional of a Poisson Point Process,The Probability Generating Functional of a Poisson Point Process,,"In [1], the author wrote: If $\mathit{\Xi}$ is a Poisson point process (PPP) with intensity function $\lambda(x)$ , then $$ G_{\mathit{\Xi}}(f) = \exp \left[ \int_{\cal R} (f(x) - 1) \lambda(x) \, dx \right]. \tag{1} $$ Here $G_{\mathit{\Xi}}(f)$ is the probability generating functional of $\mathit{\Xi}$ . $f(x)$ is a function such that $0 < f(x) \leq 1$ . Does anyone know how to prove (1)? Thank you very much. References [1] Roy L. Streit, Poisson Point Processes: Imaging, Tracking, and Sensing , Springer, 2010.","In [1], the author wrote: If is a Poisson point process (PPP) with intensity function , then Here is the probability generating functional of . is a function such that . Does anyone know how to prove (1)? Thank you very much. References [1] Roy L. Streit, Poisson Point Processes: Imaging, Tracking, and Sensing , Springer, 2010.","\mathit{\Xi} \lambda(x) 
G_{\mathit{\Xi}}(f) = \exp \left[ \int_{\cal R} (f(x) - 1) \lambda(x) \, dx \right]. \tag{1}
 G_{\mathit{\Xi}}(f) \mathit{\Xi} f(x) 0 < f(x) \leq 1","['probability', 'generating-functions', 'poisson-process']"
36,A variation of Doob's maximal inequality,A variation of Doob's maximal inequality,,"I'm looking for a proof for the following proposition, stated in ""Brownian Motion, Martingales, and Stochastic Calculus"" by Le Gall (page 263): Let $X=(X_n)_{n\in\mathbb{N}}$ be a supermartingale. For any $n\in\mathbb{N}$ and any $\lambda>0$ - $$\lambda\mathbb{P}\left(\sup_{k\le n}\left|X_k\right|>\lambda\right)\le \mathbb{E}\left[\left|X_0\right|\right]+2\mathbb{E}\left[\left|X_n\right|\right]$$ He writes that a proof can be found in ""Discrete-Parameter Martingales"" by Neveu, but I couldn't find it there. Not only I've failed proving it, I moreover got results that made me a bit suspicious about the above proposition. For example, I can show that whether $X$ is a supermartingale or a submartingle - $$\lambda\mathbb{P}\left(\sup_{k\le n}\left|X_k\right|>\lambda\right)\le 12\mathbb{E}\left[|X_0|\right]+9\mathbb{E}\left[|X_n|\right]$$ (note that at the RHS the coefficient of $\mathbb{E}\left[|X_0|\right]$ is larger than the coefficient of $\mathbb{E}\left[|X_n|\right]$ , while in the proposition above it's the other way around.)","I'm looking for a proof for the following proposition, stated in ""Brownian Motion, Martingales, and Stochastic Calculus"" by Le Gall (page 263): Let be a supermartingale. For any and any - He writes that a proof can be found in ""Discrete-Parameter Martingales"" by Neveu, but I couldn't find it there. Not only I've failed proving it, I moreover got results that made me a bit suspicious about the above proposition. For example, I can show that whether is a supermartingale or a submartingle - (note that at the RHS the coefficient of is larger than the coefficient of , while in the proposition above it's the other way around.)","X=(X_n)_{n\in\mathbb{N}} n\in\mathbb{N} \lambda>0 \lambda\mathbb{P}\left(\sup_{k\le n}\left|X_k\right|>\lambda\right)\le
\mathbb{E}\left[\left|X_0\right|\right]+2\mathbb{E}\left[\left|X_n\right|\right] X \lambda\mathbb{P}\left(\sup_{k\le n}\left|X_k\right|>\lambda\right)\le
12\mathbb{E}\left[|X_0|\right]+9\mathbb{E}\left[|X_n|\right] \mathbb{E}\left[|X_0|\right] \mathbb{E}\left[|X_n|\right]","['probability', 'probability-theory', 'reference-request', 'stochastic-processes', 'martingales']"
37,How many normal distribution random numbers' sum exceeds $r$?,How many normal distribution random numbers' sum exceeds ?,r,"There is a random number generator that obeys the standard normal distribution $X \sim N(\mu,\sigma^2)$ , and then calculates the sum of the numbers generated until the sum is greater than $r$ . Specifically, it means to generate a random number, and then stop if it exceeds $r$ , otherwise generate another random number. Sum all generated random numbers, stop if exceeds $r$ , otherwise continue How to find the expectation of the stop time $\mathbb{E}_r[X]$ . Similar to this question","There is a random number generator that obeys the standard normal distribution , and then calculates the sum of the numbers generated until the sum is greater than . Specifically, it means to generate a random number, and then stop if it exceeds , otherwise generate another random number. Sum all generated random numbers, stop if exceeds , otherwise continue How to find the expectation of the stop time . Similar to this question","X \sim N(\mu,\sigma^2) r r r \mathbb{E}_r[X]","['probability', 'normal-distribution', 'random', 'stopping-times']"
38,"How do we prove that $\max\{x_1 + x_2+ \ldots + x_n - n + 1,0\} \leq C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}$?",How do we prove that ?,"\max\{x_1 + x_2+ \ldots + x_n - n + 1,0\} \leq C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}","I am interested in proving the generalized version of the Fréchet-Hoeffding inequality. Precisely speaking, given a $n$ -copula $C:[0,1]^{n}\rightarrow[0,1]$ , how do we demonstrate that $$ \max\{x_1 + x_2 + \ldots + x_n - n + 1, 0\} \leq C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\} $$ MY ATTEMPT Since $\textbf{x} = (x_1,x_2,\ldots,x_n) \leq (1,1,\ldots,1)$ , I have been able to prove the upper bound inequality as next \begin{align*} C(\textbf{x}) & \leq C(x_1,x_2,\ldots,x_{n-1},1)\\ & \leq C(x_1,x_2,\ldots,1,1) \leq \ldots\\ & \leq C(x_1,1,\ldots,1,1) = x_1 \end{align*} because copulas are non-decreasing in each argument and have uniform margins. Once the same reasoning applies to each coordinate, the result $C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}$ follows. But what about the first inequality? Any help is appreciated.","I am interested in proving the generalized version of the Fréchet-Hoeffding inequality. Precisely speaking, given a -copula , how do we demonstrate that MY ATTEMPT Since , I have been able to prove the upper bound inequality as next because copulas are non-decreasing in each argument and have uniform margins. Once the same reasoning applies to each coordinate, the result follows. But what about the first inequality? Any help is appreciated.","n C:[0,1]^{n}\rightarrow[0,1] 
\max\{x_1 + x_2 + \ldots + x_n - n + 1, 0\} \leq C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}
 \textbf{x} = (x_1,x_2,\ldots,x_n) \leq (1,1,\ldots,1) \begin{align*}
C(\textbf{x}) & \leq C(x_1,x_2,\ldots,x_{n-1},1)\\
& \leq C(x_1,x_2,\ldots,1,1) \leq \ldots\\
& \leq C(x_1,1,\ldots,1,1) = x_1
\end{align*} C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}","['probability', 'analysis', 'statistics', 'copula']"
39,Birthday problem-Probability exactly $2$ triples and $4$ pairs if $20$ people in room,Birthday problem-Probability exactly  triples and  pairs if  people in room,2 4 20,"Say there are 20 people in a room. What is the probability there are exactly 2 triples and 4 pairs. Is my answer shown below correct? Assume 365 days in the year. $P= \dfrac{\binom{365}{2}\binom{363}{4}\binom{20}{3}\binom{17}{3}\binom{14}{2}\binom{12}{2}\binom{10}{2}\binom{8}{2} \cdot 359 \cdot 358 \cdot 357 \cdot 356 \cdot 355 \cdot 354}{365^{20}}$ ? Term $365C2$ chooses the $2$ birthdays for the $2$ triples. Each triple has a different birthday. Term $363C4$ chooses the $4$ birthdays for the $4$ pairs. Each pair has different birthdays. Term $20C3$ selects the $3$ people for the first triple and $17C3$ the $3$ people for the second triple. Term $14C2$ picks the $2$ people for first pair, $12C2$ for second pair, $10C2$ the third pair, and finally $8C2$ for the fourth pair. The term $(359 \cdot 358 \cdot 357 \cdot 356 \cdot 355 \cdot 354)$ is the birthdays for the remaining $6$ people, which do not match. I start with $359$ because $6$ birthdays have taken by the $2$ triples and the $4$ pairs. All this is then divided by the total number of possible birthday selections $365^{20}$ . I am wondering if the selection of the people for the $2$ triples should be $20C6$ instead of $20C3 \cdot 17C3$ as I show. I believe my method is the correct one. Please let me know.","Say there are 20 people in a room. What is the probability there are exactly 2 triples and 4 pairs. Is my answer shown below correct? Assume 365 days in the year. ? Term chooses the birthdays for the triples. Each triple has a different birthday. Term chooses the birthdays for the pairs. Each pair has different birthdays. Term selects the people for the first triple and the people for the second triple. Term picks the people for first pair, for second pair, the third pair, and finally for the fourth pair. The term is the birthdays for the remaining people, which do not match. I start with because birthdays have taken by the triples and the pairs. All this is then divided by the total number of possible birthday selections . I am wondering if the selection of the people for the triples should be instead of as I show. I believe my method is the correct one. Please let me know.",P= \dfrac{\binom{365}{2}\binom{363}{4}\binom{20}{3}\binom{17}{3}\binom{14}{2}\binom{12}{2}\binom{10}{2}\binom{8}{2} \cdot 359 \cdot 358 \cdot 357 \cdot 356 \cdot 355 \cdot 354}{365^{20}} 365C2 2 2 363C4 4 4 20C3 3 17C3 3 14C2 2 12C2 10C2 8C2 (359 \cdot 358 \cdot 357 \cdot 356 \cdot 355 \cdot 354) 6 359 6 2 4 365^{20} 2 20C6 20C3 \cdot 17C3,"['probability', 'combinatorics', 'birthday']"
40,Proof with uniform distribution and probabilty,Proof with uniform distribution and probabilty,,"I have the following exercise: Some students make homework with two exercises which are graded with extremely high accuracy. The scores are $a_i, b_i \in [0, 1]$ for exercises one and two respectively. A student is ‘among the best’ if there is no other student with a better score in both exercises. Of course, the students do not cheat, so you can assume that the students' scores on both exercises are independent for each student. The exercises themselves have little relation to each other, so the scores a student gets to either exercise are completely independent as well. Given $n$ , the number of students, and assuming that $a_i$ and $b_i$ of each student is uniformly distributed in $[0, 1]$ , show that there are $O(\log n)$ students worthy of an award, with high probability (which means that the probability that the winners are asymptotically more than $\log n$ goes to zero quickly as $n$ goes to infinity Do you have any ideas on how to prove this?","I have the following exercise: Some students make homework with two exercises which are graded with extremely high accuracy. The scores are for exercises one and two respectively. A student is ‘among the best’ if there is no other student with a better score in both exercises. Of course, the students do not cheat, so you can assume that the students' scores on both exercises are independent for each student. The exercises themselves have little relation to each other, so the scores a student gets to either exercise are completely independent as well. Given , the number of students, and assuming that and of each student is uniformly distributed in , show that there are students worthy of an award, with high probability (which means that the probability that the winners are asymptotically more than goes to zero quickly as goes to infinity Do you have any ideas on how to prove this?","a_i, b_i \in [0, 1] n a_i b_i [0, 1] O(\log n) \log n n","['probability', 'algorithms']"
41,"What is missing in my solution of ""from PDF to CDF and $P(X > 0.5)$""?","What is missing in my solution of ""from PDF to CDF and ""?",P(X > 0.5),"Task: The continuous random variable $X$ is described with the following   probability density function (pdf): $$f_X(x) = \begin{cases} \frac{1}{9}\big(3 + 2x - x^2 \big) \; : 0  \leq x \leq 3 \\ 0 \; \;: x < 0 \; \lor \; x > 3\end{cases}$$ Find cumulative distribution function $F_X$ and probability $P(X >  0.5)$ . The task is started by verifying if the pdf is in fact correct pdf. I am checking two conditions: Is the pdf nonnegative on all of its domain? Yes, hence we can write: $$\forall_{x \in \mathbb{R}}\;f_X(x) \geq 0$$ The pdf has to be integrable and its total area under the curve has to be equal $1$ : $$\begin{align*} &\int_{\mathbb{R}}f_X = 1 \\ &\color{red}{\int_{-\infty}^{\infty}f_X(x)dx = 1} \\ \end{align*}$$ (for now assume the condition is true) PDF plot: Computing CDF which is defined as: $$F_X(x) = \int_{-\infty}^{x}f_X(t)dt$$ Therefore: If $x < 0$ : $$F_X(x) = \int_{-\infty}^{x} 0dt = 0$$ If $x \geq 0 \; \land \; x \leq 3$ : $$\begin{align*}F_X(x) &= \int_{-\infty}^{0}0dt + \int_{0}^{x}\frac{1}{9}\big(3 + 2t - t^2\big)dt = \\ &= 0 + \frac{1}{9}\Big(3t + t^2 - \frac{1}{3}t^3 \Big)\Bigg|^{x}_0 = \\ &= \frac{1}{9} \Big(3x + x^2 - \frac{1}{3}x^3 \Big)\end{align*}$$ If $x \geq 3$ : $$\begin{align*} F_X(x) &= \int_{-\infty}^{0}0dt + \int_{0}^{3}\frac{1}{9}\Big(3 + 2t - t^2 \Big)dt + \int_{3}^{x}0dt \\ &= 0 + \frac{1}{9}\Big(3t + t^2 - \frac{1}{3}t^3 \Big)\Bigg|^3_0 + 0 = \\ &= 1 \end{align*}$$ (this implicitly confirms the $\color{red}{\text{red}}$ condition) Finally the CDF is defined as: $$F_X(x) = \begin{cases} 0 \; \; : x < 0 \\ \frac{1}{9} \Big(3x + x^2 - \frac{1}{3}x^3 \Big) \; \; : x \geq 0 \; \land \; x \leq 3 \\ 1 \; \; : x > 3 \end{cases}$$ The CDF result agrees with: $$\lim_{x \to \infty}F_X(x) = 1 \; \land \; \lim_{x \to -\infty}F_X(x) = 0 $$ Also the function is non-decreasing and continuous. CDF plot: Calculating $P(X > 0.5)$ : $$\begin{align*}P(X > 0.5) &= \int_{0.5}^{\infty}f_X(x)dx = \\ &= \int_{0.5}^{3}\frac{1}{9}(3+2x-x^2)dx + \int_{3}^{\infty}0dx = \\ &= \frac{1}{9} \Big(3x + x^2 - \frac{1}{3}x^3 \Big)\Bigg|^3_{0.5} + 0 = \\ &= \frac{175}{216} \approx 0.81\end{align*}$$ This probability solution does not agree with the book's solution. The book says $P(X > 0.5) = 1 - F_X(0.5) = \frac{41}{216} \approx 0.19$ , so it's my solution ""complemented"". My questions: Which final probability solution is correct? Is this any special kind of probability distribution, e.g. Poisson or Chi Square (well, not these)? Can you please point out all minor or major mistakes I have made along the way? (perhaps aside from plots that are not perfect). This is the most important for me. What have I forget to mention or calculate for my solution to make more sense? Especially something theoretical, perhaps e.g. definition for $X$ .","Task: The continuous random variable is described with the following   probability density function (pdf): Find cumulative distribution function and probability . The task is started by verifying if the pdf is in fact correct pdf. I am checking two conditions: Is the pdf nonnegative on all of its domain? Yes, hence we can write: The pdf has to be integrable and its total area under the curve has to be equal : (for now assume the condition is true) PDF plot: Computing CDF which is defined as: Therefore: If : If : If : (this implicitly confirms the condition) Finally the CDF is defined as: The CDF result agrees with: Also the function is non-decreasing and continuous. CDF plot: Calculating : This probability solution does not agree with the book's solution. The book says , so it's my solution ""complemented"". My questions: Which final probability solution is correct? Is this any special kind of probability distribution, e.g. Poisson or Chi Square (well, not these)? Can you please point out all minor or major mistakes I have made along the way? (perhaps aside from plots that are not perfect). This is the most important for me. What have I forget to mention or calculate for my solution to make more sense? Especially something theoretical, perhaps e.g. definition for .","X f_X(x) = \begin{cases} \frac{1}{9}\big(3 + 2x - x^2 \big) \; : 0
 \leq x \leq 3 \\ 0 \; \;: x < 0 \; \lor \; x > 3\end{cases} F_X P(X >
 0.5) \forall_{x \in \mathbb{R}}\;f_X(x) \geq 0 1 \begin{align*} &\int_{\mathbb{R}}f_X = 1 \\ &\color{red}{\int_{-\infty}^{\infty}f_X(x)dx = 1} \\ \end{align*} F_X(x) = \int_{-\infty}^{x}f_X(t)dt x < 0 F_X(x) = \int_{-\infty}^{x} 0dt = 0 x \geq 0 \; \land \; x \leq 3 \begin{align*}F_X(x) &= \int_{-\infty}^{0}0dt + \int_{0}^{x}\frac{1}{9}\big(3 + 2t - t^2\big)dt = \\ &= 0 + \frac{1}{9}\Big(3t + t^2 - \frac{1}{3}t^3 \Big)\Bigg|^{x}_0 = \\ &= \frac{1}{9} \Big(3x + x^2 - \frac{1}{3}x^3 \Big)\end{align*} x \geq 3 \begin{align*} F_X(x) &= \int_{-\infty}^{0}0dt + \int_{0}^{3}\frac{1}{9}\Big(3 + 2t - t^2 \Big)dt + \int_{3}^{x}0dt \\ &= 0 + \frac{1}{9}\Big(3t + t^2 - \frac{1}{3}t^3 \Big)\Bigg|^3_0 + 0 = \\ &= 1 \end{align*} \color{red}{\text{red}} F_X(x) = \begin{cases} 0 \; \; : x < 0 \\ \frac{1}{9} \Big(3x + x^2 - \frac{1}{3}x^3 \Big) \; \; : x \geq 0 \; \land \; x \leq 3 \\ 1 \; \; : x > 3 \end{cases} \lim_{x \to \infty}F_X(x) = 1 \; \land \; \lim_{x \to -\infty}F_X(x) = 0  P(X > 0.5) \begin{align*}P(X > 0.5) &= \int_{0.5}^{\infty}f_X(x)dx = \\ &= \int_{0.5}^{3}\frac{1}{9}(3+2x-x^2)dx + \int_{3}^{\infty}0dx = \\ &= \frac{1}{9} \Big(3x + x^2 - \frac{1}{3}x^3 \Big)\Bigg|^3_{0.5} + 0 = \\ &= \frac{175}{216} \approx 0.81\end{align*} P(X > 0.5) = 1 - F_X(0.5) = \frac{41}{216} \approx 0.19 X","['probability', 'probability-distributions', 'density-function']"
42,Probability density function of harmonic oscillation,Probability density function of harmonic oscillation,,"This is within the domain of physics, but I am interested in this problem from a mathematical / probability perspective. Suppose a mass on a spring is pulled to a length A and released. The mass undergoes harmonic oscillation. I know that the motion is of the form: $$x(t) = A \cos(\omega t + \phi) $$ Now I am interested in finding the probability density function of the position $x$ at time $t$ , assuming time is a random variable uniformly distributed along the period of oscillation. How can this be done, given the above formula?","This is within the domain of physics, but I am interested in this problem from a mathematical / probability perspective. Suppose a mass on a spring is pulled to a length A and released. The mass undergoes harmonic oscillation. I know that the motion is of the form: Now I am interested in finding the probability density function of the position at time , assuming time is a random variable uniformly distributed along the period of oscillation. How can this be done, given the above formula?",x(t) = A \cos(\omega t + \phi)  x t,['probability']
43,Probability terminology: determining events based on random variable evaluations,Probability terminology: determining events based on random variable evaluations,,"I am reading a paper right now on a constructive proof for the Lovasz Local Lemma and I want to sanity check my understanding on some of their terminology that is unfamiliar to myself. I will include a passage that illustrates what I'm concerned with: So the first piece of terminology here I want to make sure I understand is first the discussion about the events $A$ determined by values of some subset of random variables $S$ of $\mathcal{P}$ . My understanding can be expressed with an example. Suppose we have a probability space $\Omega = \lbrace \omega_1, \omega_2, \omega_3, \omega_4 \rbrace$ . Further, define our set of random variables $\mathcal{P} = \lbrace X_1, X_2 \rbrace$ where we define the two random variables to be \begin{align} X_1(\omega) &= \begin{cases} 2 & \text{if } \omega \in \lbrace \omega_1, \omega_2 \rbrace \\ 1 & \text{if } \omega \in \lbrace \omega_3 \rbrace \\ 0 & \text{otherwise} \end{cases} \\ X_2(\omega) &= \begin{cases} 1 & \text{if } \omega \in \lbrace \omega_2 \rbrace \\ 0 & \text{otherwise} \end{cases} \end{align} Now my suspicion is an event $A$ is determined by some set of random variables $\lbrace X_1, X_2 \rbrace$ by making $A$ equal to the intersection of the events that make $X_1$ and $X_2$ output some values. So for example, if $X_1 = 2$ and $X_2 = 1$ , we would say the event $A$ determined by the values of these two random variables is $A = \lbrace \omega_1, \omega_2 \rbrace \cap \lbrace \omega_2 \rbrace = \lbrace \omega_2 \rbrace$ . It is also appears that within this example, $\lbrace X_2 \rbrace \subset \mathcal{P}$ is a minimal subset needed to determine $A$ , so it seems that $\text{vbl}(A) = \lbrace X_2 \rbrace$ . Is all of this correct so far? Also, I just want to make sure I understand their use of ""evaluating"" a random variable. Is an evaluation of a random variable really just choosing a value for it? So if I choose $X_1 = 1$ , that's an evaluation of the random variable $X_1$ ? If so, it seems the passage is saying that an evaluation of a set $S$ of random variables violates $A$ if we have some evaluation for the random variables and this evaluation determines some event $\mathcal{E}$ such that $\mathcal{E} \subseteq A$ , since this determined event should imply that $A$ should happen. Does this seem reasonable? If so, I do not think I understand why they claim there's a unique minimal subset that determines $A$ . Seems to me there need not be a unique minimal subset but that there could be multiple subsets that achieve the smallest cardinality possible that can determine $A$ with an appropriate evaluation. Thus, I suspect I am understanding their terminology incorrectly. Any help one can provide to help me understand the terminology and few concepts would be great.","I am reading a paper right now on a constructive proof for the Lovasz Local Lemma and I want to sanity check my understanding on some of their terminology that is unfamiliar to myself. I will include a passage that illustrates what I'm concerned with: So the first piece of terminology here I want to make sure I understand is first the discussion about the events determined by values of some subset of random variables of . My understanding can be expressed with an example. Suppose we have a probability space . Further, define our set of random variables where we define the two random variables to be Now my suspicion is an event is determined by some set of random variables by making equal to the intersection of the events that make and output some values. So for example, if and , we would say the event determined by the values of these two random variables is . It is also appears that within this example, is a minimal subset needed to determine , so it seems that . Is all of this correct so far? Also, I just want to make sure I understand their use of ""evaluating"" a random variable. Is an evaluation of a random variable really just choosing a value for it? So if I choose , that's an evaluation of the random variable ? If so, it seems the passage is saying that an evaluation of a set of random variables violates if we have some evaluation for the random variables and this evaluation determines some event such that , since this determined event should imply that should happen. Does this seem reasonable? If so, I do not think I understand why they claim there's a unique minimal subset that determines . Seems to me there need not be a unique minimal subset but that there could be multiple subsets that achieve the smallest cardinality possible that can determine with an appropriate evaluation. Thus, I suspect I am understanding their terminology incorrectly. Any help one can provide to help me understand the terminology and few concepts would be great.","A S \mathcal{P} \Omega = \lbrace \omega_1, \omega_2, \omega_3, \omega_4 \rbrace \mathcal{P} = \lbrace X_1, X_2 \rbrace \begin{align}
X_1(\omega) &= \begin{cases} 2 & \text{if } \omega \in \lbrace \omega_1, \omega_2 \rbrace \\
1 & \text{if } \omega \in \lbrace \omega_3 \rbrace \\
0 & \text{otherwise}
\end{cases} \\
X_2(\omega) &= \begin{cases} 1 & \text{if } \omega \in \lbrace \omega_2 \rbrace \\
0 & \text{otherwise}
\end{cases}
\end{align} A \lbrace X_1, X_2 \rbrace A X_1 X_2 X_1 = 2 X_2 = 1 A A = \lbrace \omega_1, \omega_2 \rbrace \cap \lbrace \omega_2 \rbrace = \lbrace \omega_2 \rbrace \lbrace X_2 \rbrace \subset \mathcal{P} A \text{vbl}(A) = \lbrace X_2 \rbrace X_1 = 1 X_1 S A \mathcal{E} \mathcal{E} \subseteq A A A A","['probability', 'terminology']"
44,Show $\limsup _{t \to \infty} \frac{B_t}{\sqrt{t \ln t}} \leq 1 $ using the fact that $\frac{e^{B_t ^2 / (1+2t)}}{\sqrt{1+2t}}$ is a martingale.,Show  using the fact that  is a martingale.,\limsup _{t \to \infty} \frac{B_t}{\sqrt{t \ln t}} \leq 1  \frac{e^{B_t ^2 / (1+2t)}}{\sqrt{1+2t}},"For a standard Brownian motion $(B_t)_{t \geq 0}$ , I want to show that $$\limsup _{t \to \infty} \frac{B_t}{\sqrt{t \ln t}} \leq 1 \ \ \text{a.s.}$$ using the fact that $\frac{\exp(B_t ^2 / (1+2t))} { \sqrt{1+2t}}$ is a martingale. It suffices to show $\limsup _{t \to \infty} \frac{B_t ^2}{t \ln t} \leq 1 \ \ \text{a.s.}$ and I know that $\frac{B_t ^2}{t \ln t} \leq \frac{B_t ^2} {1+2t}$ for large $t$ , but I don't see any further. Any help is appreciated.","For a standard Brownian motion , I want to show that using the fact that is a martingale. It suffices to show and I know that for large , but I don't see any further. Any help is appreciated.",(B_t)_{t \geq 0} \limsup _{t \to \infty} \frac{B_t}{\sqrt{t \ln t}} \leq 1 \ \ \text{a.s.} \frac{\exp(B_t ^2 / (1+2t))} { \sqrt{1+2t}} \limsup _{t \to \infty} \frac{B_t ^2}{t \ln t} \leq 1 \ \ \text{a.s.} \frac{B_t ^2}{t \ln t} \leq \frac{B_t ^2} {1+2t} t,"['probability', 'stochastic-processes', 'brownian-motion', 'martingales']"
45,probability of rolling a 6,probability of rolling a 6,,"Select a die from a bag containing 2 dice, one die has 6 on all faces, and the other is a fair sided die. Choosing one die at random, roll it, and get a 6. If you roll the same die, what is the probability that the next roll is also a 6? Would this be (0.5)(1) + (.5)(1/6) = 0.5833, as picking one of the two dice is equally likely and the probability of obtaining the result is what follows.","Select a die from a bag containing 2 dice, one die has 6 on all faces, and the other is a fair sided die. Choosing one die at random, roll it, and get a 6. If you roll the same die, what is the probability that the next roll is also a 6? Would this be (0.5)(1) + (.5)(1/6) = 0.5833, as picking one of the two dice is equally likely and the probability of obtaining the result is what follows.",,['probability']
46,Strong Markov Property: Having Trouble Understanding Proof Using Strong Markov,Strong Markov Property: Having Trouble Understanding Proof Using Strong Markov,,"I'm having trouble understanding this proof of Example 1.4.4 From Norris' Markov Chains: Let $X_n$ be a DTMC, with transition matrix P and state-space $I$ . Let $Y_m=X_{T_m}$ for $m \in \mathbb{N}$ . Show $Y_m$ is a DTMC. Define $$T_0=\inf\{n\geq0:X_n\in J\subset I\}$$ and $$T_{m+1}=\inf\{n> T_{m}:X_n\in J\subset I\}$$ For $i_0,...,i_{m+1} \in J$ we have \begin{align*} &P(Y_{m+1}=i_{m+1}|Y_0=i_0, ..., Y_m=i_m)\\ &=P(X_{T_{m+1}}=i_{m+1}|X_{T_{0}}=i_0,...,X_{T_{m}} =i_m)\\ &=P(X_{T_{m+1}}=i_{m+1}|X_{T_m}=i_m)\\ &=P(X_{T_{1}}=i_{m+1}|X_{0}=i_m) \end{align*} I'm confused by several lines of the proof. Does the second equality follow from the fact that $X_n$ is a DTMC and thus by Markov property? Does the third equality follow form the fact that $T_m$ is a stopping time so by Strong Markov Property Markov Chain regenerates at $T_m$ so its like starting from $0$ and hitting for first time. So shouldn't it be $X_{T_{0}}=i_{m+1}$ and not $X_{T_{1}}=i_{m+1}$ ? (Really confused about this). Also I don't get how the proof shows that $Y_m$ is a Markov chain. We showed that $P(Y_{m+1}=i_{m+1}|Y_0=i_0, ..., Y_m=i_m)=P(X_{T_{1}}=i_{m+1}|X_{0}=i_m)$ . How does this show that $Y_m$ is a Markov chain and has the Markov property?","I'm having trouble understanding this proof of Example 1.4.4 From Norris' Markov Chains: Let be a DTMC, with transition matrix P and state-space . Let for . Show is a DTMC. Define and For we have I'm confused by several lines of the proof. Does the second equality follow from the fact that is a DTMC and thus by Markov property? Does the third equality follow form the fact that is a stopping time so by Strong Markov Property Markov Chain regenerates at so its like starting from and hitting for first time. So shouldn't it be and not ? (Really confused about this). Also I don't get how the proof shows that is a Markov chain. We showed that . How does this show that is a Markov chain and has the Markov property?","X_n I Y_m=X_{T_m} m \in \mathbb{N} Y_m T_0=\inf\{n\geq0:X_n\in J\subset I\} T_{m+1}=\inf\{n> T_{m}:X_n\in J\subset I\} i_0,...,i_{m+1} \in J \begin{align*}
&P(Y_{m+1}=i_{m+1}|Y_0=i_0, ..., Y_m=i_m)\\
&=P(X_{T_{m+1}}=i_{m+1}|X_{T_{0}}=i_0,...,X_{T_{m}}
=i_m)\\
&=P(X_{T_{m+1}}=i_{m+1}|X_{T_m}=i_m)\\
&=P(X_{T_{1}}=i_{m+1}|X_{0}=i_m)
\end{align*} X_n T_m T_m 0 X_{T_{0}}=i_{m+1} X_{T_{1}}=i_{m+1} Y_m P(Y_{m+1}=i_{m+1}|Y_0=i_0, ..., Y_m=i_m)=P(X_{T_{1}}=i_{m+1}|X_{0}=i_m) Y_m","['real-analysis', 'probability', 'probability-theory', 'stochastic-processes', 'markov-chains']"
47,Limit of probability in stars and bars,Limit of probability in stars and bars,,"Let $n$ and $r$ be integers. Compute the number of solutions to the equation $$x_1 + x_2 + \cdots + x_r = n,$$ where $x_i \geq 0$ are integers. Next, assuming the uniform distribution on the space of solutions, find $P(x_1 = a)$ and its limit as $r\to\infty, n\to\infty, n/r\to \rho > 0$ . The first part of the question is just stars and bars. One can easily get ${}n + r - 1 \choose r - 1$ . Now I'm not so sure how to find $P(x_1 = a)$ or the limit.  This is from a Probability and Measure Theory book, so I am trying to prove everything formally (particularly the limit portion). I tried to come up with something to condition on, and I got nowhere. I'm pretty sure it'll be a function of $n$ and $r$ because of the limit question that follows it. Does anyone have any ideas?","Let and be integers. Compute the number of solutions to the equation where are integers. Next, assuming the uniform distribution on the space of solutions, find and its limit as . The first part of the question is just stars and bars. One can easily get . Now I'm not so sure how to find or the limit.  This is from a Probability and Measure Theory book, so I am trying to prove everything formally (particularly the limit portion). I tried to come up with something to condition on, and I got nowhere. I'm pretty sure it'll be a function of and because of the limit question that follows it. Does anyone have any ideas?","n r x_1 + x_2 + \cdots + x_r = n, x_i \geq 0 P(x_1 = a) r\to\infty, n\to\infty, n/r\to \rho > 0 {}n + r - 1 \choose r - 1 P(x_1 = a) n r","['probability', 'combinatorics']"
48,Generalized inverse gamma distribution,Generalized inverse gamma distribution,,"If $X \sim \Gamma(\alpha,\beta)$ , $\alpha, \beta >0$ , is a $\Gamma$ -distributed r.v. with $$f^{X}(x;\alpha,\beta)= \begin{cases} \frac{\alpha^\beta}{\Gamma(\beta)}x^{\beta-1}e^{-\alpha x}, &x > 0,\\ 0, &x \le 0,\end{cases}$$ it is a known result that $X^r$ , $r>0$ , has the generalized $\Gamma$ -distribution with density $$f^{GG}(x;\alpha,\beta, \delta)= \begin{cases} \frac{\delta \alpha^\beta}{\Gamma\left(\frac{\beta}{\delta}\right)}x^{\beta-1}e^{-(\alpha x)^{\delta}}, &x > 0,\\ 0, &x \le 0,\end{cases}$$ and $X^{-1}$ follows the inverse $\Gamma$ -distribution with density $$f^{IG}(x;\alpha,\beta)= \begin{cases} \frac{\alpha^\beta}{\Gamma(\beta)}\left(\frac{1}{x}\right)^{\beta+1}e^{-\frac{\alpha}{x}}, &x > 0,\\ 0, &x \le 0.\end{cases}$$ I am able to show that $X^{-r}$ , $r>0$ , has a density of the form $$f(x;\alpha,\beta,\delta)= \begin{cases} \frac{\delta\alpha^\beta}{\Gamma\left(\frac{\beta}{\delta}\right)}\left(\frac{1}{x}\right)^{\beta+1}e^{-\left(\frac{\alpha}{x}\right)^{\delta}}, &x > 0,\\ 0, &x \le 0.\end{cases}$$ It seems like the latter should be a known density of something like the generalized inverse $\Gamma$ -distribution but in the literature I only find links to the Stacy- or to the Amoroso-distribution which correspond to $f^{GG}$ . Question : Does anyone know the name of this distribution and a reference to it?","If , , is a -distributed r.v. with it is a known result that , , has the generalized -distribution with density and follows the inverse -distribution with density I am able to show that , , has a density of the form It seems like the latter should be a known density of something like the generalized inverse -distribution but in the literature I only find links to the Stacy- or to the Amoroso-distribution which correspond to . Question : Does anyone know the name of this distribution and a reference to it?","X \sim \Gamma(\alpha,\beta) \alpha, \beta >0 \Gamma f^{X}(x;\alpha,\beta)= \begin{cases} \frac{\alpha^\beta}{\Gamma(\beta)}x^{\beta-1}e^{-\alpha x}, &x > 0,\\ 0, &x \le 0,\end{cases} X^r r>0 \Gamma f^{GG}(x;\alpha,\beta, \delta)= \begin{cases} \frac{\delta \alpha^\beta}{\Gamma\left(\frac{\beta}{\delta}\right)}x^{\beta-1}e^{-(\alpha x)^{\delta}}, &x > 0,\\ 0, &x \le 0,\end{cases} X^{-1} \Gamma f^{IG}(x;\alpha,\beta)= \begin{cases} \frac{\alpha^\beta}{\Gamma(\beta)}\left(\frac{1}{x}\right)^{\beta+1}e^{-\frac{\alpha}{x}}, &x > 0,\\ 0, &x \le 0.\end{cases} X^{-r} r>0 f(x;\alpha,\beta,\delta)= \begin{cases} \frac{\delta\alpha^\beta}{\Gamma\left(\frac{\beta}{\delta}\right)}\left(\frac{1}{x}\right)^{\beta+1}e^{-\left(\frac{\alpha}{x}\right)^{\delta}}, &x > 0,\\ 0, &x \le 0.\end{cases} \Gamma f^{GG}","['probability', 'gamma-distribution']"
49,Convergence in $L_p$ implies convergence in $L_1$,Convergence in  implies convergence in,L_p L_1,"I am trying to solve the following problem from “a course in probability theory “ by kai lai chung. If $X_n \to X$ in $L_p$ and $Y_n \to Y$ in $L_q$ where $p>1$ and $\frac{1}{p}+\frac{1}{q} = 1$ , then $X_nY_n \to XY$ in $L_1$ . My attempt:  I can see that I have to somehow use holder’s inequality but can’t get the correct form where I can use it $\mathbb{E}|X_nY_n-XY| = \mathbb{E}|X_nY_n -X_nY +X_nY -XY| \leq \mathbb{E}|X_n(Y_n -Y)| + \mathbb{E}|Y(X_n-X)|$ Now I could use holder for each term individually but that still leaves the single $X_n$ and $Y$ . So can someone please provide the solution. Also does anybody know where I can find a solution manual or just solutions to kai lai chung?","I am trying to solve the following problem from “a course in probability theory “ by kai lai chung. If in and in where and , then in . My attempt:  I can see that I have to somehow use holder’s inequality but can’t get the correct form where I can use it Now I could use holder for each term individually but that still leaves the single and . So can someone please provide the solution. Also does anybody know where I can find a solution manual or just solutions to kai lai chung?",X_n \to X L_p Y_n \to Y L_q p>1 \frac{1}{p}+\frac{1}{q} = 1 X_nY_n \to XY L_1 \mathbb{E}|X_nY_n-XY| = \mathbb{E}|X_nY_n -X_nY +X_nY -XY| \leq \mathbb{E}|X_n(Y_n -Y)| + \mathbb{E}|Y(X_n-X)| X_n Y,"['probability', 'convergence-divergence', 'lp-spaces', 'weak-convergence']"
50,"Customers arrive as Poisson process, while served exponentially. (Poisson process problem)","Customers arrive as Poisson process, while served exponentially. (Poisson process problem)",,"Suppose customers arrive in a 24hour cashier according to a Poisson process, at rate $\lambda$ (per hour), while their service time is exponential, of parameter $\alpha$ (independent from each other). Customers are served one at a time. Let $X_n$ be the number of customers in line, waiting to be served, when the $n$ -th customer arrives. 1) Find the transition probabilities of $\{X_n\}$ . 2) Find the limit distribution (if exists). 3) What is the probability $k$ customers wait in line at 10.00 in the morning? Attempt. 1) Since $X_{n+1}=X_n+1-E_{n+1}$ , where $E_n$ is the number of customers served between the $n-1$ -th and $n$ -th customer arrival, we get: $$p_{k,m}=P(E_{n+1}=k+1-m)=\left(\frac{\alpha}{\alpha+\lambda}\right)^{k+1-m}\frac{\lambda}{\alpha+\lambda}$$ for $k=0,1,2,\ldots$ and $m=0,1,\ldots,k+1.$ 2) Do we seek the limit as $n\to +\infty$ of $p(X_{n}=m|X_0=k)$ ? If so, i am not sure how to approach this. 3)  I am not sure how to approach this, either. I am having a difficulty turning the problem in terms of $X_n.$ Thanks in advance for the help.","Suppose customers arrive in a 24hour cashier according to a Poisson process, at rate (per hour), while their service time is exponential, of parameter (independent from each other). Customers are served one at a time. Let be the number of customers in line, waiting to be served, when the -th customer arrives. 1) Find the transition probabilities of . 2) Find the limit distribution (if exists). 3) What is the probability customers wait in line at 10.00 in the morning? Attempt. 1) Since , where is the number of customers served between the -th and -th customer arrival, we get: for and 2) Do we seek the limit as of ? If so, i am not sure how to approach this. 3)  I am not sure how to approach this, either. I am having a difficulty turning the problem in terms of Thanks in advance for the help.","\lambda \alpha X_n n \{X_n\} k X_{n+1}=X_n+1-E_{n+1} E_n n-1 n p_{k,m}=P(E_{n+1}=k+1-m)=\left(\frac{\alpha}{\alpha+\lambda}\right)^{k+1-m}\frac{\lambda}{\alpha+\lambda} k=0,1,2,\ldots m=0,1,\ldots,k+1. n\to +\infty p(X_{n}=m|X_0=k) X_n.","['probability', 'stochastic-processes', 'poisson-process', 'exponential-distribution']"
51,Pigeon Hole Principle - Minimum customers needed such that at least one is a winner,Pigeon Hole Principle - Minimum customers needed such that at least one is a winner,,"I was reading about pigeon-hole principle from this paper . If n items are put into m pigeonholes with n > m ( m,n ∈ N ∗ ), then at least one pigeonhole must contain more than one item. One of the applications of the principle is stated as: Pitter is the boss of a lotto games company, the lottery is a number which contains 5 digits. Every month, the machine picks up 1 number randomly and the owner of the lottery ticket with the same number will win one million dollars. In order to demonstrate the justice of the lottery, there must be at least one winner every month. Based on the former condition, calculate the minimum number of customers should this ticket be sold to. which has the solution as: Since every digit of the number varies from 0 to 9, there are 10⁵ numbers in total. As a result of it, according to the Pigeonhole Principle, the number of customers should be at least 10⁵ + 1 = 100001. So, as far as I understand the question and try to relate it with the basics of the principle: The possible lottery tickets are holes here. Customers are pigeon here. We need to find the minimum pigeons (customers) required such that one hole (ticket) is occupied by more than one pigeon. This evaluates to: $100001$ customer required such that two of them share the same ticket. But I cannot understand the solution as it tries to evaluate minimum number of customer required to make the game ""justified"" or ""such that there is at least one winner"". The machine can pickup any random number (of $5$ digits) and if a lottery number can be assigned only to a single customer, then $10^5$ is least number of customers required such that at least one wins. And in this case, there are no ticket left so $10^5+1$ ( $1$ extra customer) is out of question. If more than one customer is allowed to pick up same tickets, then $10^5+1$ customers can also pickup the same ticket (obviously, very low probability) and there could be no winner. I'm sure I'm missing something here.","I was reading about pigeon-hole principle from this paper . If n items are put into m pigeonholes with n > m ( m,n ∈ N ∗ ), then at least one pigeonhole must contain more than one item. One of the applications of the principle is stated as: Pitter is the boss of a lotto games company, the lottery is a number which contains 5 digits. Every month, the machine picks up 1 number randomly and the owner of the lottery ticket with the same number will win one million dollars. In order to demonstrate the justice of the lottery, there must be at least one winner every month. Based on the former condition, calculate the minimum number of customers should this ticket be sold to. which has the solution as: Since every digit of the number varies from 0 to 9, there are 10⁵ numbers in total. As a result of it, according to the Pigeonhole Principle, the number of customers should be at least 10⁵ + 1 = 100001. So, as far as I understand the question and try to relate it with the basics of the principle: The possible lottery tickets are holes here. Customers are pigeon here. We need to find the minimum pigeons (customers) required such that one hole (ticket) is occupied by more than one pigeon. This evaluates to: customer required such that two of them share the same ticket. But I cannot understand the solution as it tries to evaluate minimum number of customer required to make the game ""justified"" or ""such that there is at least one winner"". The machine can pickup any random number (of digits) and if a lottery number can be assigned only to a single customer, then is least number of customers required such that at least one wins. And in this case, there are no ticket left so ( extra customer) is out of question. If more than one customer is allowed to pick up same tickets, then customers can also pickup the same ticket (obviously, very low probability) and there could be no winner. I'm sure I'm missing something here.",100001 5 10^5 10^5+1 1 10^5+1,"['probability', 'pigeonhole-principle', 'lotteries']"
52,Using entropy to determine if a sentence is likely to be valid English,Using entropy to determine if a sentence is likely to be valid English,,"During my course of study for a cryptography class, I had to develop a simple Python script that would ""bruteforce"" the ciphertext for a Caesar Cipher. As an additional exercise, I wanted the script to also automatically determine which of the 26 outputs is most likely to be the correct answer. To do this, I decided to calculate the bits of entropy for each calculated string to see if I can use this to highlight the correct answer. The specific equation being: $H(X) = -\sum p_c \times log_2(p_c)$ , where $p_c$ is the probability of a letter appearing in an English word according to a letter frequency chart. (i.e. http://pi.math.cornell.edu/~mec/2003-2004/cryptography/subs/frequencies.html ) This approach appears to have worked. In all of my test cases, the correct answer was the one with the highest entropy. For example: Ciphertext: QNYYQJ UNLLD BJSY YT YMJ RFWPJY Most Likely Plaintext (ROT 5): LITTLE PIGGY WENT TO THE MARKET (H = 6.365) ---------------------- ROT 0:  QNYYQJ UNLLD BJSY YT YMJ RFWPJY (H = 3.399) ROT 1:  PMXXPI TMKKC AIRX XS XLI QEVOIX (H = 3.946) ROT 2:  OLWWOH SLJJB ZHQW WR WKH PDUNHW (H = 3.993) ROT 3:  NKVVNG RKIIA YGPV VQ VJG OCTMGV (H = 3.734) ROT 4:  MJUUMF QJHHZ XFOU UP UIF NBSLFU (H = 3.655) ROT 5:  LITTLE PIGGY WENT TO THE MARKET (H = 6.365) ROT 6:  KHSSKD OHFFX VDMS SN SGD LZQJDS (H = 4.224) ...snip... ROT 24: SPAASL WPNNF DLUA AV AOL THYRLA (H = 5.611) ROT 25: ROZZRK VOMME CKTZ ZU ZNK SGXQKZ (H = 3.275) So it appears to work, at least for these few test cases. What I'm confused about is, why does it work and what exactly am I measuring? I initially assumed that the correct answer would have the lowest entropy since it ""would be the least random"". But it turned out to be the one with the highest. Did I happen to use the entropy formula to calculate something that appears to be useful but isn't actually entropy at all? Edit: The function in question. # Calculate the bits of entropy for the given string based on English letter frequencies def entropy(input_string):     # Letter Frequency Chart for English     freq = { 'E': 0.1202, 'T': 0.091, ...snip... }      # Using the frequency of a letter as p(x), calculate entropy of the string using the formula:     # H = -sum of (p(x) * log[p(x)]_2)     total_entropy = 0     for letter in input_string:         total_entropy += freq[letter] * math.log(freq[letter], 2)      return -(total_entropy) Example Output: >>> entropy(""LITTLE PIGGY WENT TO THE MARKET"") 6.365324803946881 >>> entropy(""QNYYQJ UNLLD BJSY YT YMJ RFWPJY"") 3.398563530183954 Final Edit: Just adding the final function for any future students who may stumble across this question. def entropy(s):     # Letter Frequency Chart for English     freq = {          'E': 0.1202, 'T': 0.091, 'A': 0.0812, 'O': 0.0768, 'I': 0.0731,         'N': 0.0695, 'S': 0.0628, 'R': 0.0602, 'H': 0.0592, 'D': 0.0432,          'L': 0.0398, 'U': 0.0288, 'C': .0271, 'M': 0.0261, 'F': 0.023,          'Y': 0.0211, 'W': 0.0209, 'G': 0.0203, 'P': 0.0182, 'B': 0.0149,          'V': 0.0111, 'K': 0.0069, 'X': 0.0017, 'Q': 0.0011, 'J': 0.001,          'Z': 0.0007      }     ascii_range = (65, 90)      # Ensure the string's case matches the dictionary keys     s = s.upper()      # Using the frequency of a letter as p(x), calculate entropy of the string using the formula:     # H = [sum of (-log[p(x)]_2)] / len(s)     total_entropy = 0     for c in s:         if(ord(c) >= ascii_range[0] and ord(c) <= ascii_range[1]): # Only compute for values of A-Z             total_entropy += -math.log(freq[c], 2)      total_entropy = total_entropy / len(s)      return total_entropy Example Output: >>> entropy(""TEST"") 3.491390529605717 >>> entropy(""ZLYZ"") 7.794603966207939","During my course of study for a cryptography class, I had to develop a simple Python script that would ""bruteforce"" the ciphertext for a Caesar Cipher. As an additional exercise, I wanted the script to also automatically determine which of the 26 outputs is most likely to be the correct answer. To do this, I decided to calculate the bits of entropy for each calculated string to see if I can use this to highlight the correct answer. The specific equation being: , where is the probability of a letter appearing in an English word according to a letter frequency chart. (i.e. http://pi.math.cornell.edu/~mec/2003-2004/cryptography/subs/frequencies.html ) This approach appears to have worked. In all of my test cases, the correct answer was the one with the highest entropy. For example: Ciphertext: QNYYQJ UNLLD BJSY YT YMJ RFWPJY Most Likely Plaintext (ROT 5): LITTLE PIGGY WENT TO THE MARKET (H = 6.365) ---------------------- ROT 0:  QNYYQJ UNLLD BJSY YT YMJ RFWPJY (H = 3.399) ROT 1:  PMXXPI TMKKC AIRX XS XLI QEVOIX (H = 3.946) ROT 2:  OLWWOH SLJJB ZHQW WR WKH PDUNHW (H = 3.993) ROT 3:  NKVVNG RKIIA YGPV VQ VJG OCTMGV (H = 3.734) ROT 4:  MJUUMF QJHHZ XFOU UP UIF NBSLFU (H = 3.655) ROT 5:  LITTLE PIGGY WENT TO THE MARKET (H = 6.365) ROT 6:  KHSSKD OHFFX VDMS SN SGD LZQJDS (H = 4.224) ...snip... ROT 24: SPAASL WPNNF DLUA AV AOL THYRLA (H = 5.611) ROT 25: ROZZRK VOMME CKTZ ZU ZNK SGXQKZ (H = 3.275) So it appears to work, at least for these few test cases. What I'm confused about is, why does it work and what exactly am I measuring? I initially assumed that the correct answer would have the lowest entropy since it ""would be the least random"". But it turned out to be the one with the highest. Did I happen to use the entropy formula to calculate something that appears to be useful but isn't actually entropy at all? Edit: The function in question. # Calculate the bits of entropy for the given string based on English letter frequencies def entropy(input_string):     # Letter Frequency Chart for English     freq = { 'E': 0.1202, 'T': 0.091, ...snip... }      # Using the frequency of a letter as p(x), calculate entropy of the string using the formula:     # H = -sum of (p(x) * log[p(x)]_2)     total_entropy = 0     for letter in input_string:         total_entropy += freq[letter] * math.log(freq[letter], 2)      return -(total_entropy) Example Output: >>> entropy(""LITTLE PIGGY WENT TO THE MARKET"") 6.365324803946881 >>> entropy(""QNYYQJ UNLLD BJSY YT YMJ RFWPJY"") 3.398563530183954 Final Edit: Just adding the final function for any future students who may stumble across this question. def entropy(s):     # Letter Frequency Chart for English     freq = {          'E': 0.1202, 'T': 0.091, 'A': 0.0812, 'O': 0.0768, 'I': 0.0731,         'N': 0.0695, 'S': 0.0628, 'R': 0.0602, 'H': 0.0592, 'D': 0.0432,          'L': 0.0398, 'U': 0.0288, 'C': .0271, 'M': 0.0261, 'F': 0.023,          'Y': 0.0211, 'W': 0.0209, 'G': 0.0203, 'P': 0.0182, 'B': 0.0149,          'V': 0.0111, 'K': 0.0069, 'X': 0.0017, 'Q': 0.0011, 'J': 0.001,          'Z': 0.0007      }     ascii_range = (65, 90)      # Ensure the string's case matches the dictionary keys     s = s.upper()      # Using the frequency of a letter as p(x), calculate entropy of the string using the formula:     # H = [sum of (-log[p(x)]_2)] / len(s)     total_entropy = 0     for c in s:         if(ord(c) >= ascii_range[0] and ord(c) <= ascii_range[1]): # Only compute for values of A-Z             total_entropy += -math.log(freq[c], 2)      total_entropy = total_entropy / len(s)      return total_entropy Example Output: >>> entropy(""TEST"") 3.491390529605717 >>> entropy(""ZLYZ"") 7.794603966207939",H(X) = -\sum p_c \times log_2(p_c) p_c,"['probability', 'entropy', 'python']"
53,How sub-Gaussian is a Truncated Normal?,How sub-Gaussian is a Truncated Normal?,,"We say the expectation random variable $X$ is $C$ -subgussian to mean $$\mathbb E[e^{\lambda X - \mathbb E [X]}] \le e^{C\lambda^2}$$ for all $\lambda \in \mathbb R$ . One slightly different definition is that $$P(X-\mathbb E [X] > \lambda) \le e^{-D \lambda^2} \text{ and } P(X-\mathbb E [X] < \lambda) \le e^{-D \lambda^2}$$ for some $D$ . The constants $C$ and $D$ can be bounded in terms of each other. It is well-known a $N(0,\sigma^2)$ variable $X$ satisfies the above with $C= \sigma^2/2$ and $D = 1/2 \sigma^2$ . Suppose we truncate the variable to some finite interval $[a,b]$ that contains $E [X] $ . For $Y$ the truncated variable it is straightforward to show say $$P(|Y-E [X] | < \lambda) \ge 1-2e^{-D \lambda^2}$$ for $D = 1/2 \sigma^2$ whenever $a \le -\lambda \le \lambda \le b $ . This is because the PDF of $Y$ is just the PDF of $X$ set to zero outside $[a,b]$ and then scaled upwards to make it a probability distribution. However this does not give a subgaussian constant for $Y$ since $Y$ may not have expectation $\mathbb E [X] $ . Are there any ways to get a good subgaussian constant for $Y$ in terms of $a,b$ ? Note Hoeffding's lemma gives the constant $(b-a)^2/8$ but I would like something in terms of $\sigma^2$ that ideally tends to the original constant as $a,-b \to \infty$ .",We say the expectation random variable is -subgussian to mean for all . One slightly different definition is that for some . The constants and can be bounded in terms of each other. It is well-known a variable satisfies the above with and . Suppose we truncate the variable to some finite interval that contains . For the truncated variable it is straightforward to show say for whenever . This is because the PDF of is just the PDF of set to zero outside and then scaled upwards to make it a probability distribution. However this does not give a subgaussian constant for since may not have expectation . Are there any ways to get a good subgaussian constant for in terms of ? Note Hoeffding's lemma gives the constant but I would like something in terms of that ideally tends to the original constant as .,"X C \mathbb E[e^{\lambda X - \mathbb E [X]}] \le e^{C\lambda^2} \lambda \in \mathbb R P(X-\mathbb E [X] > \lambda) \le e^{-D \lambda^2} \text{ and } P(X-\mathbb E [X] < \lambda) \le e^{-D \lambda^2} D C D N(0,\sigma^2) X C= \sigma^2/2 D = 1/2 \sigma^2 [a,b] E [X]  Y P(|Y-E [X] | < \lambda) \ge 1-2e^{-D \lambda^2} D = 1/2 \sigma^2 a \le -\lambda \le \lambda \le b  Y X [a,b] Y Y \mathbb E [X]  Y a,b (b-a)^2/8 \sigma^2 a,-b \to \infty","['probability', 'normal-distribution']"
54,Distribution of digits across all factorials,Distribution of digits across all factorials,,"Show that the distribution of zeroes across all digits of all n! for $n\in \mathbb{N}$ converges to $ \frac{1}{6} $ and hence, $\frac{5}{54}$ for all other digits 1 through 9 . In other words, let's say we take the factorial of 1,2,3 and 4. We get the digits 1,2,2,4 and 6. In this case the probability of 2 would be $\frac{2}{5}$ . We can keep doing this all the way to infinity. I wrote a python script and checked from 0 to 10000, and all probabilities converge to 0.09259259259.. = $\frac{5}{54}$ except zero, which converges to 0.16666... = $\frac{1}{6}$ . Can you prove mathematically why this is the case?","Show that the distribution of zeroes across all digits of all n! for converges to and hence, for all other digits 1 through 9 . In other words, let's say we take the factorial of 1,2,3 and 4. We get the digits 1,2,2,4 and 6. In this case the probability of 2 would be . We can keep doing this all the way to infinity. I wrote a python script and checked from 0 to 10000, and all probabilities converge to 0.09259259259.. = except zero, which converges to 0.16666... = . Can you prove mathematically why this is the case?",n\in \mathbb{N}  \frac{1}{6}  \frac{5}{54} \frac{2}{5} \frac{5}{54} \frac{1}{6},"['probability', 'probability-distributions', 'proof-writing', 'factorial']"
55,How do Regular Conditional Probabilities assign values to $P(A|B)$ when $P(B) = 0$? [duplicate],How do Regular Conditional Probabilities assign values to  when ? [duplicate],P(A|B) P(B) = 0,"This question already has answers here : Probability, conditional on a zero probability event (3 answers) Closed 4 years ago . Yeah, like in the title, how do Regular Conditional Probabilities assign values to $P(A|B)$ when $P(B) = 0$ ? Because I am not trained in advanced probability, please explain it as simply as possible. It'll be great if you can demonstrate with an example. Let $X$ be a random variable between $[0, 1]$ . What is the $P(X=\frac{2}{3}|X=\frac{2}{3})$ ? Also, can it also assign values to $P(A|B)$ in finite spaces? For example, imagine you throw a die, and you observe that the die landed on an odd number at 12 noon. So letting $O$ be the event that the die landed odd, $P(O)$ changes from $\frac{1}{2}$ to $1$ after noon. Hence, after noon, letting $E$ be the event that the die landed even, $P(E)$ changes to $0$ . But even after 12 noon, I still intuitively want to say that $P(E|E)$ is still $1$ . It seems to me that for any non-empty set $A$ in the sigma-algebra, $P(A|A) = 1$ . Can regular conditional probabilities assign $P(E|E)$ a value of $1$ ? Is it possible? Or do I need to give that intuition up? Thanks for your help. Edit: I think my question is different from this: Probability, conditional on a zero probability event Because I'm asking about finite spaces too. Also, I'm asking for a demonstration of how regular conditional probabilities assign value to $P(X=\frac{2}{3}|X=\frac{2}{3})$ . Edit 2: Let the sample space in the dice example be {1, 2, 3, 4, 5, 6}. Edit 3: The sample space for the dice example is {1, 2, 3, 4, 5, 6}. The initial probability function before noon is $P$ . After noon, the probability function becomes $P'$ . So $P(O)$ = $P(E)$ = 0.5. But $P'(O) = 1$ and $P'(E) = 0$ . Still, I want to say that $P'(E|E) = 1$ .","This question already has answers here : Probability, conditional on a zero probability event (3 answers) Closed 4 years ago . Yeah, like in the title, how do Regular Conditional Probabilities assign values to when ? Because I am not trained in advanced probability, please explain it as simply as possible. It'll be great if you can demonstrate with an example. Let be a random variable between . What is the ? Also, can it also assign values to in finite spaces? For example, imagine you throw a die, and you observe that the die landed on an odd number at 12 noon. So letting be the event that the die landed odd, changes from to after noon. Hence, after noon, letting be the event that the die landed even, changes to . But even after 12 noon, I still intuitively want to say that is still . It seems to me that for any non-empty set in the sigma-algebra, . Can regular conditional probabilities assign a value of ? Is it possible? Or do I need to give that intuition up? Thanks for your help. Edit: I think my question is different from this: Probability, conditional on a zero probability event Because I'm asking about finite spaces too. Also, I'm asking for a demonstration of how regular conditional probabilities assign value to . Edit 2: Let the sample space in the dice example be {1, 2, 3, 4, 5, 6}. Edit 3: The sample space for the dice example is {1, 2, 3, 4, 5, 6}. The initial probability function before noon is . After noon, the probability function becomes . So = = 0.5. But and . Still, I want to say that .","P(A|B) P(B) = 0 X [0, 1] P(X=\frac{2}{3}|X=\frac{2}{3}) P(A|B) O P(O) \frac{1}{2} 1 E P(E) 0 P(E|E) 1 A P(A|A) = 1 P(E|E) 1 P(X=\frac{2}{3}|X=\frac{2}{3}) P P' P(O) P(E) P'(O) = 1 P'(E) = 0 P'(E|E) = 1","['probability', 'conditional-probability']"
56,Power of Two Choices: Picking the Heavier Bin,Power of Two Choices: Picking the Heavier Bin,,"Suppose there are $m$ balls and $n$ bins. We use the Power of Two Choices except we pick the heavier bin instead of the lighter bin: i.e. given a set of $n$ bins, the balls are thrown sequentially and two bins are picked uniformly at random (with replacement) and the ball is thrown into the bin with more balls out of the picked bins each time. I want to know what is the expected number of empty bins in this case. Does anyone know if the behavior of the Power of Two Choices has been studied in the context of picking the heavier instead of the lighter bin?","Suppose there are balls and bins. We use the Power of Two Choices except we pick the heavier bin instead of the lighter bin: i.e. given a set of bins, the balls are thrown sequentially and two bins are picked uniformly at random (with replacement) and the ball is thrown into the bin with more balls out of the picked bins each time. I want to know what is the expected number of empty bins in this case. Does anyone know if the behavior of the Power of Two Choices has been studied in the context of picking the heavier instead of the lighter bin?",m n n,"['probability', 'combinatorics', 'discrete-mathematics', 'balls-in-bins']"
57,What does it mean for a transition kernel to be a density with respect to a sigma-finite measure?,What does it mean for a transition kernel to be a density with respect to a sigma-finite measure?,,"My background in math (never took a course on measure theory) is weak, but I have been studying it for probability theory here and there as needed. I like to think I understand what a measure, probability measure, and $\sigma$ -finite measure is (as a user), but I am reading a paper on Markov chain Monte Carlo, and in its excerpt on convergence theory, it states the following: Let $X = (X^0, \dots, X^t, \dots)$ , $X^t \in E \subseteq \mathbb{R}^n$ be a Markov chain with transition kernel $K:E\times E \rightarrow \mathbb{R}^n$ such that, with respect to a $\sigma$ -finite measure $\nu$ on $\mathbb{R}^n$ , $$P(X^t \in A \mid X^{t-1} = x) = \int_A K(x,x') d\nu(x') + r(x) I[x\in A]$$ If we define $K^{(t)}(x,x') = \int K^{(t-1)}(x,y)K(y,x')d\nu(y)+K^{(t-1)}(x,x')r(x') + \{1-r(x)\}^{t-1}K(x,x')$ then $K^{(t)}(x_0, \cdot)$ is the density (with respect to $\nu$ ) of $X^t$ given $X^0 = x_0$ This really threw me off. I understood measures as functions that map $\sigma$ -algebra (sets) to the non-negative real numbers. My question is, what does ""with respect to a $\sigma$ -finite measure $\nu$ on $\mathbb{R}^n$ "" mean? From the definitions I have studied about measures on $\sigma$ -algebra, I do not how a density is defined ""with respect to"" one.","My background in math (never took a course on measure theory) is weak, but I have been studying it for probability theory here and there as needed. I like to think I understand what a measure, probability measure, and -finite measure is (as a user), but I am reading a paper on Markov chain Monte Carlo, and in its excerpt on convergence theory, it states the following: Let , be a Markov chain with transition kernel such that, with respect to a -finite measure on , If we define then is the density (with respect to ) of given This really threw me off. I understood measures as functions that map -algebra (sets) to the non-negative real numbers. My question is, what does ""with respect to a -finite measure on "" mean? From the definitions I have studied about measures on -algebra, I do not how a density is defined ""with respect to"" one.","\sigma X = (X^0, \dots, X^t, \dots) X^t \in E \subseteq \mathbb{R}^n K:E\times E \rightarrow \mathbb{R}^n \sigma \nu \mathbb{R}^n P(X^t \in A \mid X^{t-1} = x) = \int_A K(x,x') d\nu(x') + r(x) I[x\in A] K^{(t)}(x,x') = \int K^{(t-1)}(x,y)K(y,x')d\nu(y)+K^{(t-1)}(x,x')r(x') + \{1-r(x)\}^{t-1}K(x,x') K^{(t)}(x_0, \cdot) \nu X^t X^0 = x_0 \sigma \sigma \nu \mathbb{R}^n \sigma","['probability', 'probability-theory', 'measure-theory', 'markov-chains', 'monte-carlo']"
58,"Show, that $\frac {E[Xg(X)]}{E[g(X)]} \ge E[X]$ when $g$ strictly monotonic increasing","Show, that  when  strictly monotonic increasing",\frac {E[Xg(X)]}{E[g(X)]} \ge E[X] g,"Let $g:\mathbb R \to (0,\infty), X$ real valued random variable and $g(X) \in \mathcal L^2$ and $g$ strictly monotonic increasing. Show, that $\frac {E[Xg(X)]}{E[g(X)]} \ge E[X]$ I tried something with expected values and their correlation with covariance, but I don't get the final result.","Let real valued random variable and and strictly monotonic increasing. Show, that I tried something with expected values and their correlation with covariance, but I don't get the final result.","g:\mathbb R \to (0,\infty), X g(X) \in \mathcal L^2 g \frac {E[Xg(X)]}{E[g(X)]} \ge E[X]","['probability', 'expected-value', 'covariance']"
59,A generalization of coupon collector's problem: take an adjacent pair each time.,A generalization of coupon collector's problem: take an adjacent pair each time.,,"We have $n$ distinct kinds of coupons (of unlimited supply), the categories are denoted $1\dots n$ .Each time we could draw two coupons, but the two must be of adjacent kind (it could be any of $\{(1,2),(2,3)...,(n-1,n),(n,1)\}$ , the probability of drawing any pair is equal). What is the expected number of draws before collecting all $n$ distinct coupons? Some progress: This is different than just drawing two coupons with replacement randomly, where I already know a formula. And the ""pattern"" of selecting does not matter, this means drawing $\{(1,3),(2,4)...,(n-1,1),(n,2)\}$ yields the same result.","We have distinct kinds of coupons (of unlimited supply), the categories are denoted .Each time we could draw two coupons, but the two must be of adjacent kind (it could be any of , the probability of drawing any pair is equal). What is the expected number of draws before collecting all distinct coupons? Some progress: This is different than just drawing two coupons with replacement randomly, where I already know a formula. And the ""pattern"" of selecting does not matter, this means drawing yields the same result.","n 1\dots n \{(1,2),(2,3)...,(n-1,n),(n,1)\} n \{(1,3),(2,4)...,(n-1,1),(n,2)\}","['probability', 'expected-value', 'coupon-collector']"
60,Find Mistake: Independence of two Events,Find Mistake: Independence of two Events,,"Assume we have a black and a red cube with 6 sides. We definite two  events A = ""the black dice shows 5"", B = ""The product of the number of pips is a prime number"". We roll the dice. So $P[A] = \frac{1}{6}$ and $P[B] = \frac{1}{6}$ right ? Now i want to check, if  A and B are independent. So $P[A \cap B] = \frac{1}{36} = \frac{1}{6} * \frac{1}{6} = P[A]P[B]$ so A and B are independent. My instincts tell me the events are dependent. Where is my mistake ?","Assume we have a black and a red cube with 6 sides. We definite two  events A = ""the black dice shows 5"", B = ""The product of the number of pips is a prime number"". We roll the dice. So and right ? Now i want to check, if  A and B are independent. So so A and B are independent. My instincts tell me the events are dependent. Where is my mistake ?",P[A] = \frac{1}{6} P[B] = \frac{1}{6} P[A \cap B] = \frac{1}{36} = \frac{1}{6} * \frac{1}{6} = P[A]P[B],"['probability', 'probability-theory', 'independence']"
61,Probability distributions on topologically nontrivial manifolds,Probability distributions on topologically nontrivial manifolds,,"I'm wondering if anyone could tell if there exists a widely accepted theory of probability distributions defined on topologically nontrivial manifolds? If so, as a physicist, I would appreciate providing some explanations using the, possibly, simplest example, a circle $S^2$ . Here are my thoughts. Generally, for a manifold $\mathcal M$ , I see no problem in defining some 'distribution' $f(x)$ with $x\in\mathcal M$ , such that ${\int_{\mathcal M} f(x)d\mu(x)=}1$ . Obviously, this definition is metric-dependent. Still, oftentimes we have a canonical definition of the metric, e.g. borrowed from $\mathbb R^n$ in the case if some canonical embedding is given, which is often the case. However, we face serious difficulties when try to define 'averaged' quantities. (And in physics that's what we typically want to do). Assume, given some 'distribution' $f(\vec{n})$ , we want to calculate its mean value. One option would be to define it as follows: $$ \langle \vec n \rangle = \dfrac{\int \limits_{S^2} \vec{n} f(\vec n) ds}{\left|\int \limits_{S^2} \vec{n} f(\vec n) ds\right|^2} $$ The good thing about this definition is that it gives somewhat expected results, especially in the case of sharply-peaked distributions. However, we immediately face a huge number of problems. First of all, there exist a wide range of 'distributions' for which $\langle\vec n\rangle$ is undefined (all the shells whose center of mass is at the origin). Second, excluding such 'bad' 'distributions' from the consideration does not really save us, for such an exclusion may be be 'quantity'-dependent (were we averaging not $\vec n$ but smth else, we would have to exclude other distributions). Moreover, even if we exclude all the 'bad' ones (for a particular quantity of interest), we still cannot even define the sum for the remaining 'good' ones, for, again, the sum of 'good' distributions may be a 'bad' one. OK, let's now consider a totally different approach suggested by the discrete probability theory. What is the mean value for the random variable which in a half cases gives $-1$ , and in another half - $+1$ ? Well, clearly it's $0$ , you would say. But wait, in terms of a 'discrete guy' who only deals with two objects in the universe, $-1$ and $+1$ , this does not make any sense. There's no such object as $0$ in his universe. Nonetheless, this definition oftentimes makes sense. Why? Because we know that both $-1$ and $+1$ have a natural inclusion into $\mathbb R^n$ where the mean value can be defined. Let us stop for a second and appreciate this fact - we allowed the 'mean' value of a distribution defined on the the set $\mathcal S=\{-1,+1\}$ to take values on a different set $\mathcal{S}' = [-1,1]$ . (On the contrary, as of 03/2019, the canonical way of embedding heads and tails into $\mathbb R^n$ is still not known, and, so, their mean value does not make much sense.) Generalising this procedure to our example is straightforward: $$ \langle \vec n \rangle = \int \limits_{S^2} \vec{n} f(\vec n) ds $$ Which basically gives us a mean value of a distribution defined on $\mathcal S'$ (again, by inclusion). An obvious downside - the averaged quantities have now no meaning for inhabitants of the $\mathcal S$ manifold. Is any of these approaches dominant? Or maybe smth else? Is there a theory for general, more complicated manifolds? Any comments and /simple/ references are welcome.","I'm wondering if anyone could tell if there exists a widely accepted theory of probability distributions defined on topologically nontrivial manifolds? If so, as a physicist, I would appreciate providing some explanations using the, possibly, simplest example, a circle . Here are my thoughts. Generally, for a manifold , I see no problem in defining some 'distribution' with , such that . Obviously, this definition is metric-dependent. Still, oftentimes we have a canonical definition of the metric, e.g. borrowed from in the case if some canonical embedding is given, which is often the case. However, we face serious difficulties when try to define 'averaged' quantities. (And in physics that's what we typically want to do). Assume, given some 'distribution' , we want to calculate its mean value. One option would be to define it as follows: The good thing about this definition is that it gives somewhat expected results, especially in the case of sharply-peaked distributions. However, we immediately face a huge number of problems. First of all, there exist a wide range of 'distributions' for which is undefined (all the shells whose center of mass is at the origin). Second, excluding such 'bad' 'distributions' from the consideration does not really save us, for such an exclusion may be be 'quantity'-dependent (were we averaging not but smth else, we would have to exclude other distributions). Moreover, even if we exclude all the 'bad' ones (for a particular quantity of interest), we still cannot even define the sum for the remaining 'good' ones, for, again, the sum of 'good' distributions may be a 'bad' one. OK, let's now consider a totally different approach suggested by the discrete probability theory. What is the mean value for the random variable which in a half cases gives , and in another half - ? Well, clearly it's , you would say. But wait, in terms of a 'discrete guy' who only deals with two objects in the universe, and , this does not make any sense. There's no such object as in his universe. Nonetheless, this definition oftentimes makes sense. Why? Because we know that both and have a natural inclusion into where the mean value can be defined. Let us stop for a second and appreciate this fact - we allowed the 'mean' value of a distribution defined on the the set to take values on a different set . (On the contrary, as of 03/2019, the canonical way of embedding heads and tails into is still not known, and, so, their mean value does not make much sense.) Generalising this procedure to our example is straightforward: Which basically gives us a mean value of a distribution defined on (again, by inclusion). An obvious downside - the averaged quantities have now no meaning for inhabitants of the manifold. Is any of these approaches dominant? Or maybe smth else? Is there a theory for general, more complicated manifolds? Any comments and /simple/ references are welcome.","S^2 \mathcal M f(x) x\in\mathcal M {\int_{\mathcal M} f(x)d\mu(x)=}1 \mathbb R^n f(\vec{n}) 
\langle \vec n \rangle = \dfrac{\int \limits_{S^2} \vec{n} f(\vec n) ds}{\left|\int \limits_{S^2} \vec{n} f(\vec n) ds\right|^2}
 \langle\vec n\rangle \vec n -1 +1 0 -1 +1 0 -1 +1 \mathbb R^n \mathcal S=\{-1,+1\} \mathcal{S}' = [-1,1] \mathbb R^n 
\langle \vec n \rangle = \int \limits_{S^2} \vec{n} f(\vec n) ds
 \mathcal S' \mathcal S","['probability', 'probability-theory', 'probability-distributions', 'manifolds', 'smooth-manifolds']"
62,What is the largest possible expectation of difference between two i.i.d. random vectors in the separable Hilbert space?,What is the largest possible expectation of difference between two i.i.d. random vectors in the separable Hilbert space?,,"Suppose $M$ is a compact subset of the separable Hilbert space $l_2$ . Suppose, $X$ and $Y$ are i.i.d. random vectors with support in $M$ . What is the largest possible $E \| X - Y \| $ ? Suppose $M$ is a compact subset of the separable Hilbert space $l_2$ . Then $M$ is closed and bounded, and there exist such $x$ and $y$ in $M$ , such, that $\| x - y \| = \operatorname{diam}(M)$ . Now, suppose $X$ and $Y$ are i.i.d. random vectors, such that $P(X = x) = P(X = y) = \frac{1}{2}$ . One can see, that $$E\| X - Y \| = \frac{1}{4}\| x - x \| + \frac{1}{4}\| x - y \| + \frac{1}{4}\| y - x\| + \frac{1}{4}\| y - y \| = \frac{1}{2}\operatorname{diam}(M)$$ Now let’s prove that it is the maximal possible expected distance, or to be more exact, that if $X = (X_n)_{i = 1}^{\infty}$ and $Y = (Y_n)_{i = 1}^{\infty}$ are i.i.d. random vectors with support in $M$ , then $E\| X - Y \| \leq \frac{1}{2}\operatorname{diam}(M)$ . By Hölder inequality: $$E\| X - Y \| \leq \left(E(\| X - Y \|^2)\right)^{\frac{1}{2}}.$$ And one can see, that \begin{align*} E(\| X - Y \|^2) &= E\langle X - Y, X - Y \rangle  = 2E\langle X, X \rangle - 2E\langle X, Y \rangle \\ &= 2\left(\sum_{n = 1}^\infty E(X_n)^2 - \sum_{n = 1}^\infty EX_n Y_n \right) \\ &= 2\left(\sum_{n = 1}^\infty E(X_n)^2 - \sum_{n = 1}^\infty EX_n EX_n\right ) \\ &\leq 2\left(\sum_{n = 1}^\infty E(X_n)^2 \right) \\ &= 2E\langle X, X \rangle = 2E(\| X  \|^2) \end{align*} Now, suppose, that the least closed ball containing $M$ is the closed ball with radius $\frac{1}{2}$ and center $0$ . That will result in $\| X  \|$ being a random variable on $[-1, 1]$ . So, its second moment does not exceed $\frac{1}{4}$ (There are several proofs of this fact here: What is the largest possible variance of a random variable on $[0; 1]$? ), and we get $E\| X - Y \| \leq \frac{1}{\sqrt{2}}$ . And now let’s return to the general case. Suppose $z$ is the center of the least closed ball containing $M$ . Then $\frac{M - z}{\operatorname{diam}(M)}$ is such a subset, that the least closed ball containing it is the closed ball with radius $\frac{1}{2}$ and center $0$ . So $$E\| X - Y \| = \operatorname{diam}(M)E \left\| \frac{X - z}{\operatorname{diam}(M)} - \frac{Y - z}{\operatorname{diam}(M)}\right\| \leq \frac{1}{\sqrt{2}}\operatorname{diam}(M)$$ So we know, that the largest possible $E\| X - Y \|$ we search is certainly $\geq \frac{1}{2}\operatorname{diam}(M)$ and certainly $\leq \frac{1}{\sqrt{2}}\operatorname{diam}(M)$ . However, I do not know, how to find its exact value. This question is partially inspired by the following question: Probability distribution to maximize the expected distance between two points","Suppose is a compact subset of the separable Hilbert space . Suppose, and are i.i.d. random vectors with support in . What is the largest possible ? Suppose is a compact subset of the separable Hilbert space . Then is closed and bounded, and there exist such and in , such, that . Now, suppose and are i.i.d. random vectors, such that . One can see, that Now let’s prove that it is the maximal possible expected distance, or to be more exact, that if and are i.i.d. random vectors with support in , then . By Hölder inequality: And one can see, that Now, suppose, that the least closed ball containing is the closed ball with radius and center . That will result in being a random variable on . So, its second moment does not exceed (There are several proofs of this fact here: What is the largest possible variance of a random variable on $[0; 1]$? ), and we get . And now let’s return to the general case. Suppose is the center of the least closed ball containing . Then is such a subset, that the least closed ball containing it is the closed ball with radius and center . So So we know, that the largest possible we search is certainly and certainly . However, I do not know, how to find its exact value. This question is partially inspired by the following question: Probability distribution to maximize the expected distance between two points","M l_2 X Y M E \| X - Y \|  M l_2 M x y M \| x - y \| = \operatorname{diam}(M) X Y P(X = x) = P(X = y) = \frac{1}{2} E\| X - Y \| = \frac{1}{4}\| x - x \| + \frac{1}{4}\| x - y \| + \frac{1}{4}\| y - x\| + \frac{1}{4}\| y - y \| = \frac{1}{2}\operatorname{diam}(M) X = (X_n)_{i = 1}^{\infty} Y = (Y_n)_{i = 1}^{\infty} M E\| X - Y \| \leq \frac{1}{2}\operatorname{diam}(M) E\| X - Y \| \leq \left(E(\| X - Y \|^2)\right)^{\frac{1}{2}}. \begin{align*}
E(\| X - Y \|^2)
&= E\langle X - Y, X - Y \rangle
 = 2E\langle X, X \rangle - 2E\langle X, Y \rangle \\
&= 2\left(\sum_{n = 1}^\infty E(X_n)^2 - \sum_{n = 1}^\infty EX_n Y_n \right) \\
&= 2\left(\sum_{n = 1}^\infty E(X_n)^2 - \sum_{n = 1}^\infty EX_n EX_n\right ) \\
&\leq 2\left(\sum_{n = 1}^\infty E(X_n)^2 \right) \\
&= 2E\langle X, X \rangle = 2E(\| X  \|^2)
\end{align*} M \frac{1}{2} 0 \| X  \| [-1, 1] \frac{1}{4} E\| X - Y \| \leq \frac{1}{\sqrt{2}} z M \frac{M - z}{\operatorname{diam}(M)} \frac{1}{2} 0 E\| X - Y \| = \operatorname{diam}(M)E \left\| \frac{X - z}{\operatorname{diam}(M)} - \frac{Y - z}{\operatorname{diam}(M)}\right\| \leq \frac{1}{\sqrt{2}}\operatorname{diam}(M) E\| X - Y \| \geq \frac{1}{2}\operatorname{diam}(M) \leq \frac{1}{\sqrt{2}}\operatorname{diam}(M)","['linear-algebra', 'probability', 'probability-theory', 'hilbert-spaces', 'expected-value']"
63,Conditional Probability Problem about identical twins,Conditional Probability Problem about identical twins,,"Assume that $\frac{1}{3}$ of all twins are identical twins. You learn that Miranda is expecting twins, but you have no other information. a) Find the probability that Miranda will have two girls. b) You learn that Miranda gave birth to two girls. What is the probability that the girls are identical twins? For a), we have, letting $A$ be the event that Miranda will have two girls, and assuming that the probability a child is a girl at birth is $\frac{1}{2},$ we have $P(A)=\frac{1}{2}\cdot \frac{1}{2}=\frac{1}{4}.$ For b), letting $B$ be the event that the girls are identical twins, then we find that $P(A\cap B)=P(B|A)\cdot P(A)=\frac{1}{3}\cdot \frac{1}{4}=\frac{1}{12}.$ Is the above reasoning correct? I think that I have assumed that $\frac{1}{3}$ of twins which are girls are identical twins. Would that be incorrect, since it is also stated to explain any assumptions one makes? Thank you for your time and appreciate the feedback.","Assume that of all twins are identical twins. You learn that Miranda is expecting twins, but you have no other information. a) Find the probability that Miranda will have two girls. b) You learn that Miranda gave birth to two girls. What is the probability that the girls are identical twins? For a), we have, letting be the event that Miranda will have two girls, and assuming that the probability a child is a girl at birth is we have For b), letting be the event that the girls are identical twins, then we find that Is the above reasoning correct? I think that I have assumed that of twins which are girls are identical twins. Would that be incorrect, since it is also stated to explain any assumptions one makes? Thank you for your time and appreciate the feedback.","\frac{1}{3} A \frac{1}{2}, P(A)=\frac{1}{2}\cdot \frac{1}{2}=\frac{1}{4}. B P(A\cap B)=P(B|A)\cdot P(A)=\frac{1}{3}\cdot \frac{1}{4}=\frac{1}{12}. \frac{1}{3}","['probability', 'proof-verification']"
64,Bounded 3 values random walk,Bounded 3 values random walk,,"I have an array of size M, for each shift one random variable $X_i$ enter and one exit. The $X_i$ r.v. are iid and $X_i = \pm1$ with $p=\frac{1}{2}$ . Assuming that the sum of the $M$ $X_i$ random variables starts from $0$ , what is the probability that after $n$ shifts has ""revisited"" $0$ ? I've tried to solve this considering the random walk $\sum_{i}\varepsilon_i$ where $\varepsilon_i=\pm2$ with $p=\frac{1}{4}$ and $\varepsilon_i=0$ with $p=\frac{1}{2}$ , could you please help me? As a start I can ignore that the array is bounded. Any hint is well accepted (if there is a solution that uses the generating functions it's even better, as these are more familiar to me), thank you all.","I have an array of size M, for each shift one random variable enter and one exit. The r.v. are iid and with . Assuming that the sum of the random variables starts from , what is the probability that after shifts has ""revisited"" ? I've tried to solve this considering the random walk where with and with , could you please help me? As a start I can ignore that the array is bounded. Any hint is well accepted (if there is a solution that uses the generating functions it's even better, as these are more familiar to me), thank you all.",X_i X_i X_i = \pm1 p=\frac{1}{2} M X_i 0 n 0 \sum_{i}\varepsilon_i \varepsilon_i=\pm2 p=\frac{1}{4} \varepsilon_i=0 p=\frac{1}{2},"['probability', 'random-walk']"
65,Geometric mean of a Fréchet distributed r.v.,Geometric mean of a Fréchet distributed r.v.,,"I want to compute the geometric mean of a random variable $X\sim\mathrm{Fr\acute{e}chet}(\nu=1,s>0,m=0)$ , where the geometric mean of a continuous non-negative r.v. $X$ is defined as $GM(X):=\exp\{\mathbb{E}[\ln(X)]\}$ (reference for the Fréchet-distribution ). I computed the CDF of $\ln(X)$ as $$F_{\ln(X)}(x)=\exp\{-s\,e^{-x}\}, ~x>0,$$ and if we differentiate the above CDF we obtain the pdf $$f_{\ln(X)}(x)=s\,\exp\{-s\,e^{-x}-x\},~x>0.$$ Now I would like to compute $$\mathbb{E}[\ln(X)]=\int\limits_{0}^{\infty}\ln(x)\,s\,\exp\{-s\,e^{-x}-x\}\,\mathrm{dx}.$$ I think the solution is $$\mathbb{E}[\ln(X)]=\ln(s)+\gamma,$$ where $\gamma$ is the Euler-Masceroni constant . A quick simulation confirms this result. However I would like to compute it analytically somehow. Maybe there is also a complete other way to find this geometric mean, any ideas?","I want to compute the geometric mean of a random variable , where the geometric mean of a continuous non-negative r.v. is defined as (reference for the Fréchet-distribution ). I computed the CDF of as and if we differentiate the above CDF we obtain the pdf Now I would like to compute I think the solution is where is the Euler-Masceroni constant . A quick simulation confirms this result. However I would like to compute it analytically somehow. Maybe there is also a complete other way to find this geometric mean, any ideas?","X\sim\mathrm{Fr\acute{e}chet}(\nu=1,s>0,m=0) X GM(X):=\exp\{\mathbb{E}[\ln(X)]\} \ln(X) F_{\ln(X)}(x)=\exp\{-s\,e^{-x}\}, ~x>0, f_{\ln(X)}(x)=s\,\exp\{-s\,e^{-x}-x\},~x>0. \mathbb{E}[\ln(X)]=\int\limits_{0}^{\infty}\ln(x)\,s\,\exp\{-s\,e^{-x}-x\}\,\mathrm{dx}. \mathbb{E}[\ln(X)]=\ln(s)+\gamma, \gamma","['probability', 'probability-theory']"
66,My simulation of the Central Limit Theorem does not converge to correct value,My simulation of the Central Limit Theorem does not converge to correct value,,"The Lindeberg–Lévy CLT states: Assume $\\{ X_1, X_2, \dots \\}$ is a sequence of i.i.d. random variables with $\mathbb{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$ . And let $S_n = \frac{X_1 + X_2 + \dots + X_n}{n}$ . Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n − \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$ . I have written a small numerical simulation to check my understanding, and it does not do what I hypothesized. Each red dot is the estimated $\sigma^2$ for 2000 samples of $\sqrt{n}(S_n - \mu)$ from the uniform distribution. The blue line is the true $\sigma^2$ for the uniform distribution. I would expect that as $n$ increases, the red dots converge to towards the blue line. But that is not what happens. What's wrong with my understanding of the CLT? Here is the code that generated the figure. import numpy as np import matplotlib.pyplot as plt from   scipy.stats import norm  a = 0 b = 1 mu_lim  = 1/2.  * (a + b) var_lim = 1/12. * (b - a)**2 reps = 2000 fig, axes  = plt.subplots(1) variances = [] x = range(1, 1000, 10)  for n in x:     rvs = []     for _ in range(reps):         Sn = np.random.uniform(a, b, n).mean()         rvs.append(np.sqrt(n) * (Sn - mu_lim))     _, std = norm.fit(rvs)     variances.append(std**2)  plt.plot(x, [var_lim for _ in x]) plt.scatter(x, variances) plt.show()","The Lindeberg–Lévy CLT states: Assume is a sequence of i.i.d. random variables with and . And let . Then as approaches infinity, the random variables converge in distribution to a normal . I have written a small numerical simulation to check my understanding, and it does not do what I hypothesized. Each red dot is the estimated for 2000 samples of from the uniform distribution. The blue line is the true for the uniform distribution. I would expect that as increases, the red dots converge to towards the blue line. But that is not what happens. What's wrong with my understanding of the CLT? Here is the code that generated the figure. import numpy as np import matplotlib.pyplot as plt from   scipy.stats import norm  a = 0 b = 1 mu_lim  = 1/2.  * (a + b) var_lim = 1/12. * (b - a)**2 reps = 2000 fig, axes  = plt.subplots(1) variances = [] x = range(1, 1000, 10)  for n in x:     rvs = []     for _ in range(reps):         Sn = np.random.uniform(a, b, n).mean()         rvs.append(np.sqrt(n) * (Sn - mu_lim))     _, std = norm.fit(rvs)     variances.append(std**2)  plt.plot(x, [var_lim for _ in x]) plt.scatter(x, variances) plt.show()","\\{ X_1, X_2, \dots \\} \mathbb{E}[X_i] = \mu \text{Var}[X_i] = \sigma^2 < \infty S_n = \frac{X_1 + X_2 + \dots + X_n}{n} n \sqrt{n}(S_n − \mu) \mathcal{N}(0, \sigma^2) \sigma^2 \sqrt{n}(S_n - \mu) \sigma^2 n","['probability', 'central-limit-theorem']"
67,Biased coin question,Biased coin question,,"You have a biased coin, where the probability of flipping a heads is $70%$ . You flip once, and the coin comes up tails. What is the expected number of flips from that point (so counting that as flip $\#0$ ) until the number of heads flipped in total equals the number of tails? I think the answer should be $0.3x+1 = 0.7x \implies x=2.5$ but I am not sure.","You have a biased coin, where the probability of flipping a heads is . You flip once, and the coin comes up tails. What is the expected number of flips from that point (so counting that as flip ) until the number of heads flipped in total equals the number of tails? I think the answer should be but I am not sure.",70% \#0 0.3x+1 = 0.7x \implies x=2.5,['probability']
68,Is the following application of the CLT correct?,Is the following application of the CLT correct?,,"I am new to probability theory and still have a problem understanding some things. I came across the following problem that I am unsure on how to solve. Here it is: Suppose that in a city with $100,000$ cars a shop sells tires for cars. It has been observed that in an interval of $3$ months the percentage of cars that come to the shop for the replacement of all their tires is $0.5$ %. What is the least number of tires that the shop has to order so that it can satisfy all its customers in a $3$ month interval with probability $\geq 95$ %? And here is my attempt: Let $X$ be the random variable of cars coming at the shop in a $3$ month interval. Then $X$ is a discrete random variable following binomial distribution $B(100,000; 0.005)$ . We would like to find the least $x\in\mathbb{N}$ satisfying $P(X\leq x)\geq95$ %. Since (I assume) every car has $4$ tires, our answer is going to be $4x$ . Now since we have a large number of cars, by the Central limit theorem, we have that $X\sim N(\mu,\sigma^2)$ , where $\mu, \sigma^2$ are the expected value and the variance of $B(100,000; 0.005)$ and therefore, by calculating, it is $\mu=500, \sigma^2=475$ . Now we have $P(X\leq x)=P\big{(}\displaystyle{\frac{X-500}{\sqrt{475}}\leq\frac{x-500}{\sqrt{475}}\big{)}=P\big{(}Z\leq\frac{x-500}{\sqrt{475}}\big{)}}$ , where $Z\sim N(0,1)$ . Now our $x$ will satisfy $\displaystyle{P\big{(}Z\leq\frac{x-500}{\sqrt{475}}\big{)}}=0.95$ , therefore $\displaystyle{P\big{(}0<Z\leq\frac{x-500}{\sqrt{475}}\big{)}}=0.45$ hence (by the tables) it is $\displaystyle{\frac{x-500}{\sqrt{475}}=1.645}$ , which yields $x=535.85..$ and since $x$ is supposed to be an integer we have that $x=536$ . therefore the least number of tires is $2144$ . Is my solution correct? if not, what should I have used? Comment: I know that the $x=$ fractional is not correct since i specified that $x\in\mathbb{N}$ , but you get the point.","I am new to probability theory and still have a problem understanding some things. I came across the following problem that I am unsure on how to solve. Here it is: Suppose that in a city with cars a shop sells tires for cars. It has been observed that in an interval of months the percentage of cars that come to the shop for the replacement of all their tires is %. What is the least number of tires that the shop has to order so that it can satisfy all its customers in a month interval with probability %? And here is my attempt: Let be the random variable of cars coming at the shop in a month interval. Then is a discrete random variable following binomial distribution . We would like to find the least satisfying %. Since (I assume) every car has tires, our answer is going to be . Now since we have a large number of cars, by the Central limit theorem, we have that , where are the expected value and the variance of and therefore, by calculating, it is . Now we have , where . Now our will satisfy , therefore hence (by the tables) it is , which yields and since is supposed to be an integer we have that . therefore the least number of tires is . Is my solution correct? if not, what should I have used? Comment: I know that the fractional is not correct since i specified that , but you get the point.","100,000 3 0.5 3 \geq 95 X 3 X B(100,000; 0.005) x\in\mathbb{N} P(X\leq x)\geq95 4 4x X\sim N(\mu,\sigma^2) \mu, \sigma^2 B(100,000; 0.005) \mu=500, \sigma^2=475 P(X\leq x)=P\big{(}\displaystyle{\frac{X-500}{\sqrt{475}}\leq\frac{x-500}{\sqrt{475}}\big{)}=P\big{(}Z\leq\frac{x-500}{\sqrt{475}}\big{)}} Z\sim N(0,1) x \displaystyle{P\big{(}Z\leq\frac{x-500}{\sqrt{475}}\big{)}}=0.95 \displaystyle{P\big{(}0<Z\leq\frac{x-500}{\sqrt{475}}\big{)}}=0.45 \displaystyle{\frac{x-500}{\sqrt{475}}=1.645} x=535.85.. x x=536 2144 x= x\in\mathbb{N}","['probability', 'probability-theory', 'statistics']"
69,"Help bounding a ""norm""","Help bounding a ""norm""",,"In Weak Convergence and Stochastic Processes, the authors introduce the following notation: $$\|\xi\|_{2,1} = \int_0^\infty \sqrt{P(\xi > x)}\,\mathrm dx$$ They then admit that this is technically not a norm but is equivalent to one. To substantiate this, exercise 1 in the chapter is the following: Show that for any $r > 2$ and random variable $\xi$ , $$\frac12\|\xi\|_2 \leq \|\xi\|_{2,1} \leq \frac{r}{r-2}\|\xi\|_r$$ The first inequality can be shown as follows: $$\begin{align*}\|\xi\|_2^2 = \int P(\xi > x^2)\,\mathrm dx &= \int P(\xi > x)2x\,\mathrm dx \\ &\leq \int \sqrt{P(\xi > x)}\,\mathrm dx\cdot \sup_x 2x\sqrt{P(\xi>x)} \\ &\leq 2\|\xi\|_{2,1}\|\xi\|_2 \end{align*} $$ where the first inequality is Hölder and the second follows by Markov. However, I am having considerably more trouble showing the second part. My intuition has been to use Hölder (or perhaps reverse Hölder) again, but all of my efforts to do so lead to dead ends. For example, I have considered $$\|\xi\|_{2,1} = \frac{1}{(1-r)^{1/r}}\int P(\xi > x)^{1/r}(r-1)^{1/r}x\cdot \left(P(\xi>x)^{1/2-1/r}\right)\frac{1}{x} \,\mathrm dx$$ which can then be bounded by $\|\xi\|_r$ times a nasty integral by the use of Hölder's inequality. I have also considered trying something like a reverse Hölder inequality on an explicit expression for $\|\xi\|_r^r$ , also with little progress. Any thoughts on where to proceed? Is Hölder even the right approach here?","In Weak Convergence and Stochastic Processes, the authors introduce the following notation: They then admit that this is technically not a norm but is equivalent to one. To substantiate this, exercise 1 in the chapter is the following: Show that for any and random variable , The first inequality can be shown as follows: where the first inequality is Hölder and the second follows by Markov. However, I am having considerably more trouble showing the second part. My intuition has been to use Hölder (or perhaps reverse Hölder) again, but all of my efforts to do so lead to dead ends. For example, I have considered which can then be bounded by times a nasty integral by the use of Hölder's inequality. I have also considered trying something like a reverse Hölder inequality on an explicit expression for , also with little progress. Any thoughts on where to proceed? Is Hölder even the right approach here?","\|\xi\|_{2,1} = \int_0^\infty \sqrt{P(\xi > x)}\,\mathrm dx r > 2 \xi \frac12\|\xi\|_2 \leq \|\xi\|_{2,1} \leq \frac{r}{r-2}\|\xi\|_r \begin{align*}\|\xi\|_2^2 = \int P(\xi > x^2)\,\mathrm dx &= \int P(\xi > x)2x\,\mathrm dx \\ &\leq \int \sqrt{P(\xi > x)}\,\mathrm dx\cdot \sup_x 2x\sqrt{P(\xi>x)} \\ &\leq 2\|\xi\|_{2,1}\|\xi\|_2 \end{align*}  \|\xi\|_{2,1} = \frac{1}{(1-r)^{1/r}}\int P(\xi > x)^{1/r}(r-1)^{1/r}x\cdot \left(P(\xi>x)^{1/2-1/r}\right)\frac{1}{x} \,\mathrm dx \|\xi\|_r \|\xi\|_r^r","['probability', 'inequality', 'lp-spaces', 'integral-inequality']"
70,Existence of MLE,Existence of MLE,,"I have a problem with MLE's definition: Casella Berger in Statistical Inference and Nitis Mukhopadhyay in Probability and Statistics said that MLE for a parameter $\theta\in\Theta$ is respectively $\arg\sup_{\theta\in\Theta}\{L(\theta\mid x)\}$ or $\arg\max_{\theta\in\Theta}\{L(\theta\mid x)\}$ . But this estimator is a supremum or a maximum? If it is a supremum why we don't call it supremum likelihood estimator? Conversely if it is a maximum, the likelihood function must be continuous and the parametric space must be compact (sufficient condition for the existence of maximum) What is the truth or the minimal condition for the existence of MLE?","I have a problem with MLE's definition: Casella Berger in Statistical Inference and Nitis Mukhopadhyay in Probability and Statistics said that MLE for a parameter is respectively or . But this estimator is a supremum or a maximum? If it is a supremum why we don't call it supremum likelihood estimator? Conversely if it is a maximum, the likelihood function must be continuous and the parametric space must be compact (sufficient condition for the existence of maximum) What is the truth or the minimal condition for the existence of MLE?",\theta\in\Theta \arg\sup_{\theta\in\Theta}\{L(\theta\mid x)\} \arg\max_{\theta\in\Theta}\{L(\theta\mid x)\},"['probability', 'statistics', 'statistical-inference', 'estimation', 'maximum-likelihood']"
71,"Order statistics, what am I doing wrong","Order statistics, what am I doing wrong",,"From SOA sample 138: A machine consists of two components, whose lifetimes have the joint density function $$f(x,y)= \begin{cases} {1\over50}, & \text{for }x>0,y>0,x+y<10 \\ 0, & \text{otherwise} \end{cases}$$ The machine operates until both components fail.   Calculate the expected operational time of the machine. I know there is a simpler way to solve this, but I would like to solve it using order statistics. This is what I have so far: If I am understanding correctly, I need to find probability $P(max(X,Y) \le  k)=P(X \le k)P(Y \le k)$ , and then differentiate to find the density of $k$ , and from there find the expected value of $k$ . So first I will find the marginal density of $X$ and $Y$ : $$f(x) = \int_0^{10-x}{1\over50}dy$$ $$f(x) = {{10-x}\over50} $$ Then $P(X \le k)$ is $$P(X \le k) = \int_0^{k}{{10-x}\over50}dx $$ $$ = \left({10x\over50}-{x^2\over100}\right)\bigg|_0^k$$ $$ = \left({10k\over50}-{k^2\over100}\right)$$ I can do the same thing for $y$ , so $P(X \le k)P(Y \le k)$ is $$\left({10k\over50}-{k^2\over100}\right)^2$$ $$={100k^2\over2500}-{20k^3\over5000}+{k^4\over10000}$$ I will now take the derivative to get $f(k)$ $${200k\over2500}-{60k^2\over5000}+{4k^3\over10000}$$ And now I can integrate to the limit of $k$ to get $E(K)$ $$E(K)=\int_0^{10} k\left({200k\over2500}-{60k^2\over5000}+{4k^3\over10000}\right)dk$$ $$=\int_0^{10} {200k^2\over2500}-{60k^3\over5000}+{4k^4\over10000}dk$$ $$=\left( {200k^3\over7500}-{60k^4\over20000}+{4k^5\over50000}\right)\bigg|_0^{10}$$ $$=4.666$$ However the true solution is $5$ , where did I go wrong?","From SOA sample 138: A machine consists of two components, whose lifetimes have the joint density function The machine operates until both components fail.   Calculate the expected operational time of the machine. I know there is a simpler way to solve this, but I would like to solve it using order statistics. This is what I have so far: If I am understanding correctly, I need to find probability , and then differentiate to find the density of , and from there find the expected value of . So first I will find the marginal density of and : Then is I can do the same thing for , so is I will now take the derivative to get And now I can integrate to the limit of to get However the true solution is , where did I go wrong?","f(x,y)=
\begin{cases}
{1\over50}, & \text{for }x>0,y>0,x+y<10 \\
0, & \text{otherwise}
\end{cases} P(max(X,Y) \le  k)=P(X \le k)P(Y \le k) k k X Y f(x) = \int_0^{10-x}{1\over50}dy f(x) = {{10-x}\over50}  P(X \le k) P(X \le k) = \int_0^{k}{{10-x}\over50}dx   = \left({10x\over50}-{x^2\over100}\right)\bigg|_0^k  = \left({10k\over50}-{k^2\over100}\right) y P(X \le k)P(Y \le k) \left({10k\over50}-{k^2\over100}\right)^2 ={100k^2\over2500}-{20k^3\over5000}+{k^4\over10000} f(k) {200k\over2500}-{60k^2\over5000}+{4k^3\over10000} k E(K) E(K)=\int_0^{10} k\left({200k\over2500}-{60k^2\over5000}+{4k^3\over10000}\right)dk =\int_0^{10} {200k^2\over2500}-{60k^3\over5000}+{4k^4\over10000}dk =\left( {200k^3\over7500}-{60k^4\over20000}+{4k^5\over50000}\right)\bigg|_0^{10} =4.666 5","['probability', 'statistics', 'order-statistics']"
72,Expectation value of the average displacement squared in a random walk,Expectation value of the average displacement squared in a random walk,,"Consider a simple 1D random walk, with equal probability of going to the right (toward positive x) by one unit of distance and to the left (toward negative x) with one unit of distance. Let x=0 be the initial position of the particle and  D be the position of the particle at the end of the walk. If the random walk consist of N steps, then $<D^2>=N$ . So my question is why exactly is $<D^2>$ equal to N. I have seen mathematical proofs as to why this is the case  and so I am not really looking for one. I am more looking for an intuitive answer, as my intuition tells me that $<D^2>$ should be 0, since the particle shouldn't really be moving away from the origin as the probability of going to the right or left is the same, so it should really oscillate near the origin. Does anyone have an intuitive reason as to why this is not the case? Thank you.","Consider a simple 1D random walk, with equal probability of going to the right (toward positive x) by one unit of distance and to the left (toward negative x) with one unit of distance. Let x=0 be the initial position of the particle and  D be the position of the particle at the end of the walk. If the random walk consist of N steps, then . So my question is why exactly is equal to N. I have seen mathematical proofs as to why this is the case  and so I am not really looking for one. I am more looking for an intuitive answer, as my intuition tells me that should be 0, since the particle shouldn't really be moving away from the origin as the probability of going to the right or left is the same, so it should really oscillate near the origin. Does anyone have an intuitive reason as to why this is not the case? Thank you.",<D^2>=N <D^2> <D^2>,"['probability', 'brownian-motion']"
73,Upper Bound on Expected Value of $n$ i.i.d. Poisson random variables.,Upper Bound on Expected Value of  i.i.d. Poisson random variables.,n,"Let $\{X_i \}_{i=1}^n$ be i.i.d. from a Poisson random variable with mean $\lambda$ and let $$M_n = \max_{1 \le i \le n} X_i.$$ What is a tight upper bound on $\mathbb{E}[M_n]$ ? I can prove that \begin{equation} \mathbb{E}[M_n] \le \frac{(\lambda+1) \log n}{\log \log n} + O \left( \frac{1}{\log \log n} \right) \end{equation} but numerically this bound is not tight. Can someone give a tighter analysis or point to a reference with one? Proof of my bound: Let $s > 0$ . Then by Jensen's inequality, $$ e^{s \mathbb{E}[M_n]} \le \mathbb{E}[e^{sM_n}] \le \sum_{i-1}^n \mathbb{E}[e^{sX_i}] = ne^{\lambda(e^s-1)}$$ from the moment generating function. Then taking the logarithm of both sides gives $$ \mathbb{E}[M_n] \le \frac{\log n}s + \frac{\lambda(e^s-1)}{s}.$$ Finally, the minimum of the function on the right hand side should be around $s = \log \log n$ which gives the bound above.","Let be i.i.d. from a Poisson random variable with mean and let What is a tight upper bound on ? I can prove that but numerically this bound is not tight. Can someone give a tighter analysis or point to a reference with one? Proof of my bound: Let . Then by Jensen's inequality, from the moment generating function. Then taking the logarithm of both sides gives Finally, the minimum of the function on the right hand side should be around which gives the bound above.","\{X_i \}_{i=1}^n \lambda M_n = \max_{1 \le i \le n} X_i. \mathbb{E}[M_n] \begin{equation}
\mathbb{E}[M_n] \le \frac{(\lambda+1) \log n}{\log \log n} + O \left( \frac{1}{\log \log n} \right)
\end{equation} s > 0  e^{s \mathbb{E}[M_n]} \le \mathbb{E}[e^{sM_n}] \le \sum_{i-1}^n \mathbb{E}[e^{sX_i}] = ne^{\lambda(e^s-1)}  \mathbb{E}[M_n] \le \frac{\log n}s + \frac{\lambda(e^s-1)}{s}. s = \log \log n","['probability', 'probability-distributions', 'expected-value']"
74,Where is my flaw with the calculation of this cdf?,Where is my flaw with the calculation of this cdf?,,"I want to calculate the ratio distribution $X/Y$ of two continuous random variables $X$ and $Y$ with each having support $(0, \infty)$ I was starting like that: $$\mathbb P\left(\frac{X}{Y}\leq z\right)=\int_{0}^\infty f_Y(y) F_{X\mid Y}(zy \mid y)dy$$ Now: $$F_{X\mid Y}(zy \mid y)=\int_{0}^{zy} \frac{f_{X,Y}(x,y)}{f_Y(y)}dx   =\frac{\frac{dF_{X,Y}(zy,y)}{dy}}{f_Y(y)}$$ and hence: $$\mathbb P\left(\frac{X}{Y}\leq z\right)=\int_{0}^\infty \frac{dF_{X,Y}(zy,y)}{dy}dy=\left[F(zy,y)\right]_0^\infty=1,$$ which of course is not correct. Anyone can see my mistake? Thank you very much in advance",I want to calculate the ratio distribution of two continuous random variables and with each having support I was starting like that: Now: and hence: which of course is not correct. Anyone can see my mistake? Thank you very much in advance,"X/Y X Y (0, \infty) \mathbb P\left(\frac{X}{Y}\leq z\right)=\int_{0}^\infty f_Y(y) F_{X\mid Y}(zy \mid y)dy F_{X\mid Y}(zy \mid y)=\int_{0}^{zy} \frac{f_{X,Y}(x,y)}{f_Y(y)}dx   =\frac{\frac{dF_{X,Y}(zy,y)}{dy}}{f_Y(y)} \mathbb P\left(\frac{X}{Y}\leq z\right)=\int_{0}^\infty \frac{dF_{X,Y}(zy,y)}{dy}dy=\left[F(zy,y)\right]_0^\infty=1,",['probability']
75,"Polar form of normal random vector , angle and length are independent ,and angle is spherical distribution","Polar form of normal random vector , angle and length are independent ,and angle is spherical distribution",,"Represent $g \sim N(0,I_n)$ in polar form as $g=r \theta$ where $r = \|g\|_2$ is the length  and $\theta = \frac{g}{\|g\|_2} $ is the direction prove that $r$ and $\theta$ are independent ? prove that $\theta$ is uniformly distributed on sphere $S^{n-1}$ for first one : The only things I know how to do is to show the product pdf of both of $\theta$ and $r$ is same as  n-dimeinal pdf of of standard Gaussian vector ? but  how to find pdf of $\|g\|_2$ ? I have some problem in trasformation of random variable in this case . since the transformationare not bijective , is any simple way to do that?","Represent in polar form as where is the length  and is the direction prove that and are independent ? prove that is uniformly distributed on sphere for first one : The only things I know how to do is to show the product pdf of both of and is same as  n-dimeinal pdf of of standard Gaussian vector ? but  how to find pdf of ? I have some problem in trasformation of random variable in this case . since the transformationare not bijective , is any simple way to do that?","g \sim N(0,I_n) g=r \theta r = \|g\|_2 \theta = \frac{g}{\|g\|_2}  r \theta \theta S^{n-1} \theta r \|g\|_2","['probability', 'probability-theory', 'random-variables', 'normal-distribution', 'independence']"
76,What is the probability of three consecutive results X and two results Y in an event?,What is the probability of three consecutive results X and two results Y in an event?,,"I have N number of days where three different events X,Y,Z can occur in each day. A is a set of possible occurrences of length N . I want to calculate the number of ways where: Y does NOT happen twice or more in these number of days N X does NOT happen three times consecutively in these number of days N So, one acceptable way where N=5 is A=[Z,Z,Z,Y,Z] . One unacceptable way is where A=[X,X,X,Z,Z] . I was just going to find the number of days where Y can occur two time, plus the number of days where x happens three times consecutively, add then and subtract that from the total number of days possible, but that wouldn't give me the right answer because it is possible for there to be overlap in those days. I don't remember the right formula I need.","I have N number of days where three different events X,Y,Z can occur in each day. A is a set of possible occurrences of length N . I want to calculate the number of ways where: Y does NOT happen twice or more in these number of days N X does NOT happen three times consecutively in these number of days N So, one acceptable way where N=5 is A=[Z,Z,Z,Y,Z] . One unacceptable way is where A=[X,X,X,Z,Z] . I was just going to find the number of days where Y can occur two time, plus the number of days where x happens three times consecutively, add then and subtract that from the total number of days possible, but that wouldn't give me the right answer because it is possible for there to be overlap in those days. I don't remember the right formula I need.",,['probability']
77,"Let $X,Y $ be two independent random variables with exponential distribution and parameter $\lambda > 0$.",Let  be two independent random variables with exponential distribution and parameter .,"X,Y  \lambda > 0","Let $X,Y$ be two independent random variables with exponential distribution with parameter $\lambda > 0$ . Let $S = X + Y$ and $T = \frac{X}{S}$ . I want to find the joint density function of $(S,T)$ . I want then to calculate the marginals and say whether or not $S$ and $T$ are independent.  I start  by finding the density function of $S$ using the convolution: $$ f_S(s) = \int_{-\infty}^{+\infty}f_X(s-t)f_Y(t)dt $$ $$ = \int_{0}^{s} \lambda^2 e^{-\lambda s} dt  = \lambda^2 e^{-\lambda s}$$ Then I tried to calculate the density function of $T $ but I am stuck here: $$ F_T(t) = \mathbb{P}(T \leq t) = \mathbb{P}\left(\frac{X}{X+Y} \leq t\right).$$ Is this the right method of solving this? Should I find the joint density first? (The problem is that I do not know how to to that)",Let be two independent random variables with exponential distribution with parameter . Let and . I want to find the joint density function of . I want then to calculate the marginals and say whether or not and are independent.  I start  by finding the density function of using the convolution: Then I tried to calculate the density function of but I am stuck here: Is this the right method of solving this? Should I find the joint density first? (The problem is that I do not know how to to that),"X,Y \lambda > 0 S = X + Y T = \frac{X}{S} (S,T) S T S  f_S(s) = \int_{-\infty}^{+\infty}f_X(s-t)f_Y(t)dt   = \int_{0}^{s} \lambda^2 e^{-\lambda s} dt  = \lambda^2 e^{-\lambda s} T   F_T(t) = \mathbb{P}(T \leq t) = \mathbb{P}\left(\frac{X}{X+Y} \leq t\right).","['probability', 'probability-distributions', 'random-variables', 'density-function']"
78,Expected time before Farmer Brown is abducted?,Expected time before Farmer Brown is abducted?,,"Farmer Brown is standing in the middle of his perfectly circular field feeling very content. It is midnight and there is no moon and unknown to the farmer, Martian zoologists are landing randomly at points on the circumference of his field. They land at one minute intervals, starting at midnight. As soon as there are martians at points A,B,C such that triangle ABC contains the center of the field, Farmer Brown will be teleported to the waiting space-ship and transported off to spend the rest of his life as an exhibit in a Martian zoo. What is the expected time until he is abducted? My approach: If lets say the farmer gets abducted after k Martians land. This implies that the first k-1 martians all lie in the same semicircle. Also, the kth martian lies on the circle such that the far away martians in the initial k-1 martians, and the kth martian form a triangle that contains the center of the circle. The probability that the first (k-1) martians don't contain the center of the circle is (see here ). Also, the probability that the kth martian makes the center lie in a triangle formed by the kth martian and the ends of initial k-1 martians should be 1/4, since this is equivalent to the situation of only 3 martians. So the expected value of k, i.e. no. of martians after which the farmer gets abducted, should be The answer I get from this, is 3.5. Whereas the actual answer is 5. In the solution in that link, I don't understand where does the right hand side of the  probability equation come from. Where is my approach wrong?","Farmer Brown is standing in the middle of his perfectly circular field feeling very content. It is midnight and there is no moon and unknown to the farmer, Martian zoologists are landing randomly at points on the circumference of his field. They land at one minute intervals, starting at midnight. As soon as there are martians at points A,B,C such that triangle ABC contains the center of the field, Farmer Brown will be teleported to the waiting space-ship and transported off to spend the rest of his life as an exhibit in a Martian zoo. What is the expected time until he is abducted? My approach: If lets say the farmer gets abducted after k Martians land. This implies that the first k-1 martians all lie in the same semicircle. Also, the kth martian lies on the circle such that the far away martians in the initial k-1 martians, and the kth martian form a triangle that contains the center of the circle. The probability that the first (k-1) martians don't contain the center of the circle is (see here ). Also, the probability that the kth martian makes the center lie in a triangle formed by the kth martian and the ends of initial k-1 martians should be 1/4, since this is equivalent to the situation of only 3 martians. So the expected value of k, i.e. no. of martians after which the farmer gets abducted, should be The answer I get from this, is 3.5. Whereas the actual answer is 5. In the solution in that link, I don't understand where does the right hand side of the  probability equation come from. Where is my approach wrong?",,['probability']
79,Expected value of playing a game,Expected value of playing a game,,A game has probability $\frac13$ of winning. Someone would like to play this game and continue to play until he loses two in a row. What is the expected number of playing the game?,A game has probability of winning. Someone would like to play this game and continue to play until he loses two in a row. What is the expected number of playing the game?,\frac13,['probability']
80,(Random Walk) Compute average relative number of consecutive cookies eaten from the right side of the gap,(Random Walk) Compute average relative number of consecutive cookies eaten from the right side of the gap,,"Currently I am reading the paper ' Excited Random Walk in One Dimension .' At page $8$ left column, the authors obtain the following: Probability that the walk eats precisely $r > 0$ consecutive cookies (we term this event a single “meal”) from the right edge of the cookie-free region is $$P(r) = 2q \frac{\Gamma(L)}{\Gamma(L-2q)} \frac{\Gamma(L+r-1-2q)}{\Gamma(L+r)}$$ where $L-2$ refers to cookie-free gap and $p$ refers to probability of the walk moving to the right and $q$ is the probability of the walk moving to the left. However, when they calculate the average relative number of consecutive cookies eaten from the right side of the gap, they compute $$\int_0^\infty \tilde{r} \tilde{P}(\tilde{r})\,d\tilde{r}$$ where $\tilde{r} = \frac{r}{L}$ and $\tilde{P} = LP(r).$ Question: Why do they integrate with respect to $\tilde{r}$ with integrand $\tilde{P}?$ I thought to find the average number of cookie eaten, one just needs to compute $$\int_0^\infty r P(r)\, dr$$ instead of the above.","Currently I am reading the paper ' Excited Random Walk in One Dimension .' At page left column, the authors obtain the following: Probability that the walk eats precisely consecutive cookies (we term this event a single “meal”) from the right edge of the cookie-free region is where refers to cookie-free gap and refers to probability of the walk moving to the right and is the probability of the walk moving to the left. However, when they calculate the average relative number of consecutive cookies eaten from the right side of the gap, they compute where and Question: Why do they integrate with respect to with integrand I thought to find the average number of cookie eaten, one just needs to compute instead of the above.","8 r > 0 P(r) = 2q \frac{\Gamma(L)}{\Gamma(L-2q)} \frac{\Gamma(L+r-1-2q)}{\Gamma(L+r)} L-2 p q \int_0^\infty \tilde{r} \tilde{P}(\tilde{r})\,d\tilde{r} \tilde{r} = \frac{r}{L} \tilde{P} = LP(r). \tilde{r} \tilde{P}? \int_0^\infty r P(r)\, dr","['probability', 'stochastic-processes', 'random-walk', 'density-function', 'expected-value']"
81,Dice game - how do find the expected number of rounds?,Dice game - how do find the expected number of rounds?,,"I've been struggling trying to find an analytical solution to this problem. Let's say we have a dice game, played with n players rolling n , k sided dice, with k >= n .  The dice determine the order of winning players:  each player is assigned a number, from 1 to n, and all roll their k-sided dice simultaneously.  Winners are selected each round if the number they roll is unique amongst the n players.  If a players roll is matched by another player, then both must continue to the next round, and there can be more than one winner each round, or zero winners.  All players roll their dice even if they have already won.  All players keep rolling until all have won at least once.  The problem is to find the average and expected number of rounds each games last as a function of n and k . For example, if we had a game of 4 players, each rolling 4-sided dice, a potential game might proceed like this: Roll 1 - (1,1,3,3) : no winning players, since no player rolled a unique number Roll 2 - (1,2,2,3) : player 1 and player 4 win, since each rolled a unique number Roll 3 - (1,1,3,4) : player 3 and player 4 win Roll 4 - (1,3,3,4) : player 1 and 4 win Roll 5 - (2,3,2,2) : player 2 wins Each player has won at least once, so this game ends in 5 rounds. It would make sense that as k becomes >> n, then the expected number of rounds would converge at 1 (since the probability of there being any matching number for a large sided dice tends towards zero for a large number of sides). This is a simple problem to simulate, and running each game 1 million times shows the following result: 4 players, rolling 4-sided dice -> average number of rounds = 4.17346 4 players, rolling 10-sided dice -> average number of rounds = 1.806924 6 players, rolling 6-sided dice -> average number of rounds = 5.225997 6 players, rolling 10-sided dice -> average number of rounds = 3.043941 6 players, rolling 100-sided dice -> average number of rounds = 1.15475 This does not seem to be model-able with a Markov Chain, since the number of states is not fixed from game to game with a given n and k . NOTE: this is not homework, but I came across this game in a PDF full of dice games and haven't been able to find or work-out a solution. EDIT: with @SteveKass's suggestion, I realize that we can model this game as a Markov process, with $n+1$ states.  Each state represents the number of players who have 'won' - so state $S_0$ means no players have won, and state $S_i$ means exactly i players have won.  Thus state $S_n$ means the game is done, which is an absorbing state. So the state transition probabilities for 4 players with 4 dice from state zero can be computed: P(no progress) = P(all the same number) + P(even number of collisions) So these rolls have the form 1111, or 2222, or 1122, or 3434.  So there are 10 combinations of collision rolls:  4 where all numbers match, and 36 where two numbers appear an even number of times.  So the state transition matrix probability for S(0,0) (meaning we are at the beginning of the game, but stay in state zero because the rolls don't advance the game), is $\frac{40}{256}$ (there are ${4 \choose 1}$ ways to roll all the same number, and ${4 \choose 2}$ ways to select two numbers, and ${4 \choose 2}$ ways to distribute those numbers into rolls, hence $4+36=40$ over $4^4$ total possible rolls). However I see no generalized way of counting the number of collision possibilities.  For 4 players, it is only AAAA, AABB, or ABAB.  For 5 players, it is AABBB, or AAAAA, AAABB, or ABBAAA, etc.  For 10 players, it is any even partitioning of the rolls that results in an even number of conflicts, like AABBBBBBBB, AAAABBBBBB, AAAAAABBBB, AAAAAAAABB, AABBAAAAAA, and AAAABBAAAA, etc.  I don't know of any equation that will tell me the number of possible collision possibilities as $n$ becomes large.","I've been struggling trying to find an analytical solution to this problem. Let's say we have a dice game, played with n players rolling n , k sided dice, with k >= n .  The dice determine the order of winning players:  each player is assigned a number, from 1 to n, and all roll their k-sided dice simultaneously.  Winners are selected each round if the number they roll is unique amongst the n players.  If a players roll is matched by another player, then both must continue to the next round, and there can be more than one winner each round, or zero winners.  All players roll their dice even if they have already won.  All players keep rolling until all have won at least once.  The problem is to find the average and expected number of rounds each games last as a function of n and k . For example, if we had a game of 4 players, each rolling 4-sided dice, a potential game might proceed like this: Roll 1 - (1,1,3,3) : no winning players, since no player rolled a unique number Roll 2 - (1,2,2,3) : player 1 and player 4 win, since each rolled a unique number Roll 3 - (1,1,3,4) : player 3 and player 4 win Roll 4 - (1,3,3,4) : player 1 and 4 win Roll 5 - (2,3,2,2) : player 2 wins Each player has won at least once, so this game ends in 5 rounds. It would make sense that as k becomes >> n, then the expected number of rounds would converge at 1 (since the probability of there being any matching number for a large sided dice tends towards zero for a large number of sides). This is a simple problem to simulate, and running each game 1 million times shows the following result: 4 players, rolling 4-sided dice -> average number of rounds = 4.17346 4 players, rolling 10-sided dice -> average number of rounds = 1.806924 6 players, rolling 6-sided dice -> average number of rounds = 5.225997 6 players, rolling 10-sided dice -> average number of rounds = 3.043941 6 players, rolling 100-sided dice -> average number of rounds = 1.15475 This does not seem to be model-able with a Markov Chain, since the number of states is not fixed from game to game with a given n and k . NOTE: this is not homework, but I came across this game in a PDF full of dice games and haven't been able to find or work-out a solution. EDIT: with @SteveKass's suggestion, I realize that we can model this game as a Markov process, with states.  Each state represents the number of players who have 'won' - so state means no players have won, and state means exactly i players have won.  Thus state means the game is done, which is an absorbing state. So the state transition probabilities for 4 players with 4 dice from state zero can be computed: P(no progress) = P(all the same number) + P(even number of collisions) So these rolls have the form 1111, or 2222, or 1122, or 3434.  So there are 10 combinations of collision rolls:  4 where all numbers match, and 36 where two numbers appear an even number of times.  So the state transition matrix probability for S(0,0) (meaning we are at the beginning of the game, but stay in state zero because the rolls don't advance the game), is (there are ways to roll all the same number, and ways to select two numbers, and ways to distribute those numbers into rolls, hence over total possible rolls). However I see no generalized way of counting the number of collision possibilities.  For 4 players, it is only AAAA, AABB, or ABAB.  For 5 players, it is AABBB, or AAAAA, AAABB, or ABBAAA, etc.  For 10 players, it is any even partitioning of the rolls that results in an even number of conflicts, like AABBBBBBBB, AAAABBBBBB, AAAAAABBBB, AAAAAAAABB, AABBAAAAAA, and AAAABBAAAA, etc.  I don't know of any equation that will tell me the number of possible collision possibilities as becomes large.",n+1 S_0 S_i S_n \frac{40}{256} {4 \choose 1} {4 \choose 2} {4 \choose 2} 4+36=40 4^4 n,"['probability', 'combinatorics', 'random-variables', 'dice', 'expected-value']"
82,Combinatorics dance class,Combinatorics dance class,,"I have a problem that ím trying to solve and I am not completely sure if my answer is correct, I tried looking for it on the web but i cant find a problem quite like it. I am translating the question into English, and im doing my best to translate it correct, but im sorry if there are some stupid grammar mistakes. „During a dance class 4 pairs (a pair consists of one man and one woman) are chosen from 4 men and 7 women. Romeo and Juliet are students in this class, what is the probability that the two will form a pair. My answer would be $$  \frac{\binom{6}{3}3!}{ \binom{7}{4}4!} $$ My thought process is as follows, There is only one possibility two choose Rome and Juliet, and 1 Possibility to choose the 3 men, so im not writing them down. But there are 6C3 possible ways to choose the 3 women left, and 3!  possibilities to assign them to the 3 men. And there are 7C4 ways to choose the 4 women in total and then 4! Ways to form different pairs. Is this correct? And if not, where did i make a mistake. Many thanks for reading this and helping me out Ps I tried writing it down in mathjax but wasn’t very successful with that - sorry","I have a problem that ím trying to solve and I am not completely sure if my answer is correct, I tried looking for it on the web but i cant find a problem quite like it. I am translating the question into English, and im doing my best to translate it correct, but im sorry if there are some stupid grammar mistakes. „During a dance class 4 pairs (a pair consists of one man and one woman) are chosen from 4 men and 7 women. Romeo and Juliet are students in this class, what is the probability that the two will form a pair. My answer would be $$  \frac{\binom{6}{3}3!}{ \binom{7}{4}4!} $$ My thought process is as follows, There is only one possibility two choose Rome and Juliet, and 1 Possibility to choose the 3 men, so im not writing them down. But there are 6C3 possible ways to choose the 3 women left, and 3!  possibilities to assign them to the 3 men. And there are 7C4 ways to choose the 4 women in total and then 4! Ways to form different pairs. Is this correct? And if not, where did i make a mistake. Many thanks for reading this and helping me out Ps I tried writing it down in mathjax but wasn’t very successful with that - sorry",,"['probability', 'combinatorics', 'self-learning']"
83,Expected value of number of trials to get k SUCCESSIVE successes,Expected value of number of trials to get k SUCCESSIVE successes,,"Independent trials, each of which is a success with probability p, are performed until there are k consecutive successes. What is the mean of the number of the necessary trials? Let $N_k$ be the number of trials needed to get k successive successes. While I am convinced that to answer this problem we should start by  doing $$M_k = E[N_k]= E[E[N_k|N_{k-1}]]$$ like explained in another post on StackExchange(See Expectation by conditioning )  I don't understand how to complete the solution. The  suggested solution is  $$\begin{align} M_k &= E[N_k]\ (line1 ) \\&= E[E[N_k|N_{k-1}]] \ (Line 2) \\&=E[p(N_{k-1}+1)+q[N_{k-1}+1+E[N_k]]] \ (line3)  \\ &=E[N_{k-1}+1+qE[N_k]] \ (Line 4 )  \\ &=E[N_{k-1}]+1+qE[N_k] \ (Line 5 )  \\&= M_{k-1}+1+qM_{k} \ (Line 6 )  \\&=\frac{1}{p}+\frac{M_{k-1}}{p} \ (Line 7 ), M_0=0 \end{align}$$ What I don't understand is $(line3)$ especially $ q* [N_{k-1}+1+E[N_k]]$ Please someone could provide me an explanation ? Thank you","Independent trials, each of which is a success with probability p, are performed until there are k consecutive successes. What is the mean of the number of the necessary trials? Let $N_k$ be the number of trials needed to get k successive successes. While I am convinced that to answer this problem we should start by  doing $$M_k = E[N_k]= E[E[N_k|N_{k-1}]]$$ like explained in another post on StackExchange(See Expectation by conditioning )  I don't understand how to complete the solution. The  suggested solution is  $$\begin{align} M_k &= E[N_k]\ (line1 ) \\&= E[E[N_k|N_{k-1}]] \ (Line 2) \\&=E[p(N_{k-1}+1)+q[N_{k-1}+1+E[N_k]]] \ (line3)  \\ &=E[N_{k-1}+1+qE[N_k]] \ (Line 4 )  \\ &=E[N_{k-1}]+1+qE[N_k] \ (Line 5 )  \\&= M_{k-1}+1+qM_{k} \ (Line 6 )  \\&=\frac{1}{p}+\frac{M_{k-1}}{p} \ (Line 7 ), M_0=0 \end{align}$$ What I don't understand is $(line3)$ especially $ q* [N_{k-1}+1+E[N_k]]$ Please someone could provide me an explanation ? Thank you",,"['probability', 'probability-theory', 'probability-distributions', 'conditional-probability']"
84,A curious variant of the classical 2D random walk: allowing duplication and vanishing,A curious variant of the classical 2D random walk: allowing duplication and vanishing,,"Background. Recall the standard random walk on a 2D grid (i.e. $\mathbb{Z}^2$). A person starts at the origin. At every iteration, the person moves in one of the four directions (up, down, left, or right), each with a probability $1/4$. It is well-known that the person will at some point return to the origin with probability $1$. We now consider the following variant.  A person starts at the origin. At the first iteration, for each of the four points surrounding the person, a 'duplicate' of the original person is placed at this point with probability $1/4$; we remove the person at the origin. We do not require that there be exactly one duplicate. It can happen that there are more than one, or even that there are none altogether (in which case the simulation halts). At the following iterations, we repeat the process for each of the duplicates that we have: at each of the four points surrounding a given duplicate, a new duplicate is placed with probability $1/4$, and the original duplicate is removed. Example. A process could go as follows: $$\{(0,0)\} \Rightarrow \{(0,1)\} \Rightarrow \{(0,0),(0,2)\} \Rightarrow \{(0,1),(0,1)\} \Rightarrow \{(1,1)\} \Rightarrow \{\}.$$ Notice that it can happen that more than one duplicate is at the same spot, and that the process halts after the duplicate on $(1,1)$ no longer formed any new duplicates. Question. We simulate the random walk described above. Throughout the simulation, we count the number of times that a duplicate is formed at the origin. What is the probability that at least one duplicate will return to the origin? Follow-up question. What is the probability distribution for the number of returns to the origin, and can we derive from this the expected number of returns? What I know. I am vaguely aware that the simulation will halt (because there are no more duplicates) in a finite amount of time with probability $1$. (This is probably a well-known result for the set people working within this area, but I am not an element thereof.) So we need not worry about the number of returns being infinite. The probability that the simulation halts at the first iteration is $(3/4)^4 \approx 0.32$, thus giving a trivial (and weak) upper bound for the probability of returning at least once, at about $0.68$. I have run the simulation 1.000.000 times in Python. The numerical results are as follows. It states the number of simulations that yielded a given number of returns to the origin. \begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|} \hline \text{Returns} & 0 & 1 & 2 & 3 & 4 &5&6&7&8&9&10& >10 \\ \hline \text{Runs} & 682919 & 143705 & 56318 & 29616 & 17856 & 11876 & 8512 & 6342 & 4898 & 3964 & 3312 & 30682 \\ \hline \end{array} Here's a plot of the first 80 values. The $x$-axis represents the number of returns; the $y$-value represents the number of runs with $x$ returns. The values at $x = 0,1$ have been cut off from the image so as to make the rest visible. We find that the probability of returning at least once is approximately $0.317$. Remarkably, there are also a bunch of extreme outliers. When I ran 100.000 runs without artificial termination, about one in a hundred simulations yielded more than a hundred returns. Two runs even yielded thousands of returns. (One yielded $8205$ returns. It lasted for $23230$ iterations, and at its peak there were $13769$ duplicates on the grid. The other gave even more: $13823$ returns after $70578$ iterations, with a peak number of $44232$ duplicates.) These outliers strongly influence the expected value. Estimates of the expected value are inconsistent. Though in the comments, user joriki gives a compelling argument in the comments that we should expect the value to be infinite.","Background. Recall the standard random walk on a 2D grid (i.e. $\mathbb{Z}^2$). A person starts at the origin. At every iteration, the person moves in one of the four directions (up, down, left, or right), each with a probability $1/4$. It is well-known that the person will at some point return to the origin with probability $1$. We now consider the following variant.  A person starts at the origin. At the first iteration, for each of the four points surrounding the person, a 'duplicate' of the original person is placed at this point with probability $1/4$; we remove the person at the origin. We do not require that there be exactly one duplicate. It can happen that there are more than one, or even that there are none altogether (in which case the simulation halts). At the following iterations, we repeat the process for each of the duplicates that we have: at each of the four points surrounding a given duplicate, a new duplicate is placed with probability $1/4$, and the original duplicate is removed. Example. A process could go as follows: $$\{(0,0)\} \Rightarrow \{(0,1)\} \Rightarrow \{(0,0),(0,2)\} \Rightarrow \{(0,1),(0,1)\} \Rightarrow \{(1,1)\} \Rightarrow \{\}.$$ Notice that it can happen that more than one duplicate is at the same spot, and that the process halts after the duplicate on $(1,1)$ no longer formed any new duplicates. Question. We simulate the random walk described above. Throughout the simulation, we count the number of times that a duplicate is formed at the origin. What is the probability that at least one duplicate will return to the origin? Follow-up question. What is the probability distribution for the number of returns to the origin, and can we derive from this the expected number of returns? What I know. I am vaguely aware that the simulation will halt (because there are no more duplicates) in a finite amount of time with probability $1$. (This is probably a well-known result for the set people working within this area, but I am not an element thereof.) So we need not worry about the number of returns being infinite. The probability that the simulation halts at the first iteration is $(3/4)^4 \approx 0.32$, thus giving a trivial (and weak) upper bound for the probability of returning at least once, at about $0.68$. I have run the simulation 1.000.000 times in Python. The numerical results are as follows. It states the number of simulations that yielded a given number of returns to the origin. \begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|} \hline \text{Returns} & 0 & 1 & 2 & 3 & 4 &5&6&7&8&9&10& >10 \\ \hline \text{Runs} & 682919 & 143705 & 56318 & 29616 & 17856 & 11876 & 8512 & 6342 & 4898 & 3964 & 3312 & 30682 \\ \hline \end{array} Here's a plot of the first 80 values. The $x$-axis represents the number of returns; the $y$-value represents the number of runs with $x$ returns. The values at $x = 0,1$ have been cut off from the image so as to make the rest visible. We find that the probability of returning at least once is approximately $0.317$. Remarkably, there are also a bunch of extreme outliers. When I ran 100.000 runs without artificial termination, about one in a hundred simulations yielded more than a hundred returns. Two runs even yielded thousands of returns. (One yielded $8205$ returns. It lasted for $23230$ iterations, and at its peak there were $13769$ duplicates on the grid. The other gave even more: $13823$ returns after $70578$ iterations, with a peak number of $44232$ duplicates.) These outliers strongly influence the expected value. Estimates of the expected value are inconsistent. Though in the comments, user joriki gives a compelling argument in the comments that we should expect the value to be infinite.",,"['probability', 'probability-theory', 'stochastic-processes', 'recreational-mathematics', 'random-walk']"
85,Optimal stopping time for coin toss with unkown bias,Optimal stopping time for coin toss with unkown bias,,"I am working on a question that involves uncertainty and decision making, but I realized I am not making progress for a long time. That is why I formulated a more basic problem in the hope that I can make progress but I still don't know how to proceed. Suppose there is a game where at each stage $t$ we get a stochastic reward/loss. We can also choose to stop at any stage $t$ and move away with rewards collected until that stage. Let $X_t$ be the random variable that denotes the reward we get at $t$'th stage. $$ X_t = +1 \text{ with probability } p\\ X_t = -1 \text{ with probability } 1 -p $$ with $p$ unkown . We want to find $\tau$ such that $$ \sum_{t = 0}^{\tau} \mathop{\mathbb{E}}[X_t] $$ is maximized. If $p$ were known, this would not be an interesting problem because the decision of continuing or stopping does not depend on the outcomes of the coin. But since we do not know $p$, our decision depends on the previous outcomes, for example, we might find out that it was not logical to play the game at all ! The problem is similar to other exploration-exploitation problems but I could not find anything related to my problem. I tried estimating $p$ and then tried to find a threshold for stopping the game but could not succeed. I would appreciate any kind of comment, suggestion or references.","I am working on a question that involves uncertainty and decision making, but I realized I am not making progress for a long time. That is why I formulated a more basic problem in the hope that I can make progress but I still don't know how to proceed. Suppose there is a game where at each stage $t$ we get a stochastic reward/loss. We can also choose to stop at any stage $t$ and move away with rewards collected until that stage. Let $X_t$ be the random variable that denotes the reward we get at $t$'th stage. $$ X_t = +1 \text{ with probability } p\\ X_t = -1 \text{ with probability } 1 -p $$ with $p$ unkown . We want to find $\tau$ such that $$ \sum_{t = 0}^{\tau} \mathop{\mathbb{E}}[X_t] $$ is maximized. If $p$ were known, this would not be an interesting problem because the decision of continuing or stopping does not depend on the outcomes of the coin. But since we do not know $p$, our decision depends on the previous outcomes, for example, we might find out that it was not logical to play the game at all ! The problem is similar to other exploration-exploitation problems but I could not find anything related to my problem. I tried estimating $p$ and then tried to find a threshold for stopping the game but could not succeed. I would appreciate any kind of comment, suggestion or references.",,"['probability', 'stopping-times', 'optimal-control']"
86,Giving 1 apple to 1 of 3 children fairly with a coinflip,Giving 1 apple to 1 of 3 children fairly with a coinflip,,"I wish to give an apple to 1 of 3 children fairly using a coin flip game. Each child calls heads or tails, and I flip the coin once for each child. If exactly one child calls correctly, that child gets the apple. If there is no one who calls correctly the game repeats. If two children call correctly, the game repeats between the 2 children until only of them calls correctly. Is this game fair; i.e., does each child have the same probability of winning? I am assuming yes intuitively. What about a game in which I only flip the coin once, and each child calls. Is this game fair? I am assuming yes intuitively. What is the expected number of coinflips in my original game? I recursively got 6: Let $N_3, N_2$ be the number of flips for three and two children respectively.  Then for three children: $$P(0\space correct\space calls) = 1/8 $$ $$P(1\space correct\space call) = 3/8 $$ $$P(2\space correct\space calls) = 3/8 $$ $$P(3\space correct\space calls) = 1/8 $$ Hence: $E(N_3) = \frac{3}{8} \cdot3 + \frac{2}{8}\cdot (3 + E(N_3)) + \frac{3}{8}\cdot(3 + E(N_2))$ For two children: $$P(0\space correct\space calls) = 1/4$$ $$P(1\space correct\space call) = 2/4$$ $$P(2\space correct\space calls) = 1/4$$ Hence: $E(N_2) = \frac{1}{2}\cdot 2 + \frac{1}{2}\cdot (2 + E(N_2))$ Thus: $E(N_2) = 4$ and $E(N_3) = 6$ For the curious, I am trying to see if this ""tournament game"" is ""isomorphic"" to randomly assigning ""T"" to a child, then doing 3 coinflips until a permutation of {T,H,H} is achieved and hence the assigned child gets the apple, as described by Tim Crack in Heard On the Street (17e) . That ""assignment game"" expects 8 coinflips whereas I am getting 6 in my ""tournament game."" I am probably misinterpreting his description of ""tournament game"" or incorrectly calculating 6.","I wish to give an apple to 1 of 3 children fairly using a coin flip game. Each child calls heads or tails, and I flip the coin once for each child. If exactly one child calls correctly, that child gets the apple. If there is no one who calls correctly the game repeats. If two children call correctly, the game repeats between the 2 children until only of them calls correctly. Is this game fair; i.e., does each child have the same probability of winning? I am assuming yes intuitively. What about a game in which I only flip the coin once, and each child calls. Is this game fair? I am assuming yes intuitively. What is the expected number of coinflips in my original game? I recursively got 6: Let $N_3, N_2$ be the number of flips for three and two children respectively.  Then for three children: $$P(0\space correct\space calls) = 1/8 $$ $$P(1\space correct\space call) = 3/8 $$ $$P(2\space correct\space calls) = 3/8 $$ $$P(3\space correct\space calls) = 1/8 $$ Hence: $E(N_3) = \frac{3}{8} \cdot3 + \frac{2}{8}\cdot (3 + E(N_3)) + \frac{3}{8}\cdot(3 + E(N_2))$ For two children: $$P(0\space correct\space calls) = 1/4$$ $$P(1\space correct\space call) = 2/4$$ $$P(2\space correct\space calls) = 1/4$$ Hence: $E(N_2) = \frac{1}{2}\cdot 2 + \frac{1}{2}\cdot (2 + E(N_2))$ Thus: $E(N_2) = 4$ and $E(N_3) = 6$ For the curious, I am trying to see if this ""tournament game"" is ""isomorphic"" to randomly assigning ""T"" to a child, then doing 3 coinflips until a permutation of {T,H,H} is achieved and hence the assigned child gets the apple, as described by Tim Crack in Heard On the Street (17e) . That ""assignment game"" expects 8 coinflips whereas I am getting 6 in my ""tournament game."" I am probably misinterpreting his description of ""tournament game"" or incorrectly calculating 6.",,['probability']
87,Independent sums of independent random variables,Independent sums of independent random variables,,"Suppose $X=X_1 + X_2$ and $Y=Y_1 + Y_2$ are independent random variables such that $X_1,X_2$ are independent and $Y_1,Y_2$ are independent. Does this imply that $X_i,Y_j$ (for $i,j\in \{1,2\}$) are independent? I'm asking this question because I'm a little confused about the accepted answer for Sum of two independent binomial variables ; in the last part of the proof, it's clear that the $B_i(i=1,\ldots,n+m)$ are binomially distributed, but it's not apparent to me why they are all independent (which somehow follows from the fact that $B_1,\ldots, B_n$ are independent, $B_{n+1}, \ldots, B_{n+m}$ are independent, and $X=B_1+\cdots+B_n,Y=B_{n+1}+\cdots+B_{n+m}$ are independent). Edit: Added some motivation.","Suppose $X=X_1 + X_2$ and $Y=Y_1 + Y_2$ are independent random variables such that $X_1,X_2$ are independent and $Y_1,Y_2$ are independent. Does this imply that $X_i,Y_j$ (for $i,j\in \{1,2\}$) are independent? I'm asking this question because I'm a little confused about the accepted answer for Sum of two independent binomial variables ; in the last part of the proof, it's clear that the $B_i(i=1,\ldots,n+m)$ are binomially distributed, but it's not apparent to me why they are all independent (which somehow follows from the fact that $B_1,\ldots, B_n$ are independent, $B_{n+1}, \ldots, B_{n+m}$ are independent, and $X=B_1+\cdots+B_n,Y=B_{n+1}+\cdots+B_{n+m}$ are independent). Edit: Added some motivation.",,"['probability', 'random-variables', 'independence']"
88,How many cards out of a standard deck would you need to draw to ensure two of them are different suits?,How many cards out of a standard deck would you need to draw to ensure two of them are different suits?,,"I believe that we are determining, in a worst case scenario, how many cards must we pick to draw a two different suit. My thought process is that we must get rid of all 13 cards to deplete an entire suit before we would be able to ensure the next card drawn is of a different suit. If this is so, then would the correct answer be to draw 14 cards(13 same suit and 1 different suit) to ensure a different suit? Followup Question for Clarification What is the probability that we will pick two cards with two different suits?  I know we are able to pick any card for first one so I believe that means we have a 52/52 possibility for the first card. For the second card would we then have a 39/51 possibility (where 39 is the remaining number of cards that are not the suit)?","I believe that we are determining, in a worst case scenario, how many cards must we pick to draw a two different suit. My thought process is that we must get rid of all 13 cards to deplete an entire suit before we would be able to ensure the next card drawn is of a different suit. If this is so, then would the correct answer be to draw 14 cards(13 same suit and 1 different suit) to ensure a different suit? Followup Question for Clarification What is the probability that we will pick two cards with two different suits?  I know we are able to pick any card for first one so I believe that means we have a 52/52 possibility for the first card. For the second card would we then have a 39/51 possibility (where 39 is the remaining number of cards that are not the suit)?",,['probability']
89,Random Walk Probability number line,Random Walk Probability number line,,"I am stuck on this question, ""In a symmetric random walk of a particle on integer number line, starting from origin, what is the probability that it hits $-9$ before $+6$"" Here symmetric implies: P(going left at each step) = 1/2 and ditto for going right. I could not think of a method for this, I just know that the expected number of steps to reach an integer $k$ can be defined recursively as: Let $f(k)$ denote the expected number of steps starting from $k$, $f(0)$ = $\frac{1}{2}$$(1+f(-1))$ + $\frac{1}{2}$$(1+f(1))$ In general,  $f(k)$ = $\frac{1}{2}$$(1+f(k-1))$ + $\frac{1}{2}$$(1+f(k+1))$ But how do I relate this or without relating this to the required probability.  Please help me with this. Thanks in advance! PS: Please excuse me for the poor LaTeX syntax, I'm new to it.","I am stuck on this question, ""In a symmetric random walk of a particle on integer number line, starting from origin, what is the probability that it hits $-9$ before $+6$"" Here symmetric implies: P(going left at each step) = 1/2 and ditto for going right. I could not think of a method for this, I just know that the expected number of steps to reach an integer $k$ can be defined recursively as: Let $f(k)$ denote the expected number of steps starting from $k$, $f(0)$ = $\frac{1}{2}$$(1+f(-1))$ + $\frac{1}{2}$$(1+f(1))$ In general,  $f(k)$ = $\frac{1}{2}$$(1+f(k-1))$ + $\frac{1}{2}$$(1+f(k+1))$ But how do I relate this or without relating this to the required probability.  Please help me with this. Thanks in advance! PS: Please excuse me for the poor LaTeX syntax, I'm new to it.",,"['probability', 'stochastic-processes', 'expectation', 'random-walk']"
90,Equality in distribution of Cauchy random variables,Equality in distribution of Cauchy random variables,,"Let $X$ be a Cauchy $C(1)$ random variable and let $Y_a = \frac{1+aX}{a-X}$, where $a$ is a real number. I need to prove that $(s+t)X \stackrel{d}{=}sX - \frac{t}{X}$ for $s,t>0$ using the fact that $Y_a \stackrel{d}{=} X$ for any real $a$.","Let $X$ be a Cauchy $C(1)$ random variable and let $Y_a = \frac{1+aX}{a-X}$, where $a$ is a real number. I need to prove that $(s+t)X \stackrel{d}{=}sX - \frac{t}{X}$ for $s,t>0$ using the fact that $Y_a \stackrel{d}{=} X$ for any real $a$.",,"['probability', 'probability-theory']"
91,Conditional expectation from joint distribution,Conditional expectation from joint distribution,,"I am new to probability and trying to convince myself of the correctness of the equations in this paper on factor analysis. There is a step I am missing. I'll give my understanding so far and then highlight the question below. Given a $p$-dimensional vector $\textbf{x}$ modeled using a $k$-dimensional factor $\textbf{z}$ where typically $k < p$, the model for factor analysis is: $$ \textbf{x} = \Lambda \textbf{z} + \textbf{u} $$ Where $\Lambda$ is a matrix, $\textbf{u} \sim \mathcal{N}(0, \Psi)$, and $\textbf{z} \sim \mathcal{N}(0, I)$. This means $\textbf{x} \sim \mathcal{N}(0, \Lambda \Lambda^{\top} + \Psi)$ because: $$ \begin{align} \textbf{x} &= \Lambda \textbf{z} + \textbf{u} \\ &= \Lambda \mathcal{N}(0, I_k) + \mathcal{N}(0, \Psi) \\ &= \mathcal{N}(0, \Lambda \Lambda^{\top} + \Psi) \end{align} $$ Now, we have the joint distribution: $$ P\bigg( \begin{bmatrix} \textbf{x} \\ \textbf{z} \end{bmatrix} \bigg) = \mathcal{N}\bigg( \begin{bmatrix} 0 \\ 0 \end{bmatrix} , \begin{bmatrix} \Lambda \Lambda^{\top} + \Psi & \Lambda \\ \Lambda^{\top} & I \end{bmatrix} \bigg) $$ I can convince myself that this is correct and fairly easily. $\text{Var}(\textbf{x})$ and $\text{Var}(\textbf{z})$ come from their definitions, while $\text{Cov}(\textbf{x}, \textbf{z})$ and $\text{Cov}(\textbf{z}, \textbf{x})$ are easy enough to compute, e.g.: $$ \begin{align} \text{Cov}(\textbf{x}, \textbf{z}) &= \mathbb{E}[(\textbf{x} - \mathbb{E}[\textbf{x}])(\textbf{z} - \mathbb{E}[\textbf{z}])^{\top}] \\ &= \mathbb{E}[(\textbf{x} - 0)(\textbf{z} - 0)^{\top}] \\ &= \mathbb{E}[(\Lambda \textbf{z} + \textbf{u})(\textbf{z})^{\top}] \\ &= \mathbb{E}[\Lambda \textbf{z} \textbf{z}^{\top} + \textbf{u} \textbf{z}^{\top}] \\ &= \Lambda \mathbb{E}[\textbf{z} \textbf{z}^{\top}] + \mathbb{E}[\textbf{u} \textbf{z}^{\top}] \\ &= \Lambda \end{align} $$ Where $\mathbb{E}[\textbf{u} \textbf{z}^{\top}] = \mathbb{E}[\textbf{u}]\mathbb{E}[\textbf{z}^{\top}] = 0 \cdot 0$ and $\mathbb{E}[\textbf{z}\textbf{z}^{\top}] = I_k$ because: $$ \begin{align} \text{Var}(\textbf{z}) &= \mathbb{E}[\textbf{z}\textbf{z}^{\top}] + \mathbb{E}[\textbf{z}] \mathbb{E}[\textbf{z}]^{\top} \\ I_k &= \mathbb{E}[\textbf{z}\textbf{z}^{\top}] + 0 \end{align} $$ So far so good. Question The authors then claim that the conditional expectation of the first and second moments of the factors are: $$ \begin{align} \mathbb{E}[\textbf{z} \mid \textbf{x}] &= \Lambda^{\top} (\Psi + \Lambda \Lambda^{\top})^{-1} \textbf{x} \\ \\ \mathbb{E}[\textbf{z} \textbf{z}^{\top} \mid \textbf{x}] &= I_k - (\Lambda^{\top} \Psi + \Lambda \Lambda^{\top})^{-1} \Lambda + \Lambda^{\top} (\Psi + \Lambda \Lambda^{\top})^{-1} \Lambda^{\top} \textbf{x} \textbf{x}^{\top} ((\Psi + \Lambda \Lambda^{\top})^{-1})^{\top}  \end{align} $$ The authors claim that this comes from ""the joint normality of data and factors"". How was this computed? I've gone through the Wikipedia page on conditional expectation, but I don't see anything that defines it in terms of the joint distribution or conditional distribution.","I am new to probability and trying to convince myself of the correctness of the equations in this paper on factor analysis. There is a step I am missing. I'll give my understanding so far and then highlight the question below. Given a $p$-dimensional vector $\textbf{x}$ modeled using a $k$-dimensional factor $\textbf{z}$ where typically $k < p$, the model for factor analysis is: $$ \textbf{x} = \Lambda \textbf{z} + \textbf{u} $$ Where $\Lambda$ is a matrix, $\textbf{u} \sim \mathcal{N}(0, \Psi)$, and $\textbf{z} \sim \mathcal{N}(0, I)$. This means $\textbf{x} \sim \mathcal{N}(0, \Lambda \Lambda^{\top} + \Psi)$ because: $$ \begin{align} \textbf{x} &= \Lambda \textbf{z} + \textbf{u} \\ &= \Lambda \mathcal{N}(0, I_k) + \mathcal{N}(0, \Psi) \\ &= \mathcal{N}(0, \Lambda \Lambda^{\top} + \Psi) \end{align} $$ Now, we have the joint distribution: $$ P\bigg( \begin{bmatrix} \textbf{x} \\ \textbf{z} \end{bmatrix} \bigg) = \mathcal{N}\bigg( \begin{bmatrix} 0 \\ 0 \end{bmatrix} , \begin{bmatrix} \Lambda \Lambda^{\top} + \Psi & \Lambda \\ \Lambda^{\top} & I \end{bmatrix} \bigg) $$ I can convince myself that this is correct and fairly easily. $\text{Var}(\textbf{x})$ and $\text{Var}(\textbf{z})$ come from their definitions, while $\text{Cov}(\textbf{x}, \textbf{z})$ and $\text{Cov}(\textbf{z}, \textbf{x})$ are easy enough to compute, e.g.: $$ \begin{align} \text{Cov}(\textbf{x}, \textbf{z}) &= \mathbb{E}[(\textbf{x} - \mathbb{E}[\textbf{x}])(\textbf{z} - \mathbb{E}[\textbf{z}])^{\top}] \\ &= \mathbb{E}[(\textbf{x} - 0)(\textbf{z} - 0)^{\top}] \\ &= \mathbb{E}[(\Lambda \textbf{z} + \textbf{u})(\textbf{z})^{\top}] \\ &= \mathbb{E}[\Lambda \textbf{z} \textbf{z}^{\top} + \textbf{u} \textbf{z}^{\top}] \\ &= \Lambda \mathbb{E}[\textbf{z} \textbf{z}^{\top}] + \mathbb{E}[\textbf{u} \textbf{z}^{\top}] \\ &= \Lambda \end{align} $$ Where $\mathbb{E}[\textbf{u} \textbf{z}^{\top}] = \mathbb{E}[\textbf{u}]\mathbb{E}[\textbf{z}^{\top}] = 0 \cdot 0$ and $\mathbb{E}[\textbf{z}\textbf{z}^{\top}] = I_k$ because: $$ \begin{align} \text{Var}(\textbf{z}) &= \mathbb{E}[\textbf{z}\textbf{z}^{\top}] + \mathbb{E}[\textbf{z}] \mathbb{E}[\textbf{z}]^{\top} \\ I_k &= \mathbb{E}[\textbf{z}\textbf{z}^{\top}] + 0 \end{align} $$ So far so good. Question The authors then claim that the conditional expectation of the first and second moments of the factors are: $$ \begin{align} \mathbb{E}[\textbf{z} \mid \textbf{x}] &= \Lambda^{\top} (\Psi + \Lambda \Lambda^{\top})^{-1} \textbf{x} \\ \\ \mathbb{E}[\textbf{z} \textbf{z}^{\top} \mid \textbf{x}] &= I_k - (\Lambda^{\top} \Psi + \Lambda \Lambda^{\top})^{-1} \Lambda + \Lambda^{\top} (\Psi + \Lambda \Lambda^{\top})^{-1} \Lambda^{\top} \textbf{x} \textbf{x}^{\top} ((\Psi + \Lambda \Lambda^{\top})^{-1})^{\top}  \end{align} $$ The authors claim that this comes from ""the joint normality of data and factors"". How was this computed? I've gone through the Wikipedia page on conditional expectation, but I don't see anything that defines it in terms of the joint distribution or conditional distribution.",,"['probability', 'conditional-expectation']"
92,"Find CDF of $X+Y$ for independent $U[0,1]$ variables $X$ and $Y$",Find CDF of  for independent  variables  and,"X+Y U[0,1] X Y","There are several ways to find the CDF of $Z=X+Y$ with $X$ and $Y$ independent RVs. I want to use the general answer included in this question CDF of two variable to find the CDF when $X$ and $Y$ are continuous and uniform distributed over $[0,1]$. In this case, I use the two densities to the be $1$. The result is $z^2/2$ when $0\le z\le1$ and this I know is correct. The result is $z-\frac{1}{2}$ when $1\le z \le2$ that is not correct, it should be: $1- \frac{1}{2}(2-z)^2$. Where is the mistake, in the cited solution or when I use it? Can you elaborate?","There are several ways to find the CDF of $Z=X+Y$ with $X$ and $Y$ independent RVs. I want to use the general answer included in this question CDF of two variable to find the CDF when $X$ and $Y$ are continuous and uniform distributed over $[0,1]$. In this case, I use the two densities to the be $1$. The result is $z^2/2$ when $0\le z\le1$ and this I know is correct. The result is $z-\frac{1}{2}$ when $1\le z \le2$ that is not correct, it should be: $1- \frac{1}{2}(2-z)^2$. Where is the mistake, in the cited solution or when I use it? Can you elaborate?",,"['probability', 'probability-distributions', 'random-variables']"
93,Estimate the volume of Voronoi cell,Estimate the volume of Voronoi cell,,"Let given a ball of radius $\alpha$ centered in point $u$ in $d$-dimensional space. Let given a sample of $n$ uniformly distributed vectors $x_i$ ($i = 1,\dots,n$) inside the ball. For each vector $x_i$ we connect points $u$ and $x_i$ by a segment and build a hyperplane $P_i$ through the middle of the segment and orthogonal to it. In the general case, the constructed hyperplanes bound a polyhedron in $\mathbb{R}^d$. I need to estimate from above the probability that uniformly distributed vector $q$ fall into this polyhedron. In some cases the constructed polyhedron can be unbounded. More precisely, as far as I know it can be if and only if $u$ is not contained in the convex hull of $x_i$. This probability can be estimated, see for example here . Then I can write down $\mathbb{P}( q$ in polyhedron $) \le \mathbb{P}(u$ in convex hull$) \mathbb{P}(q$ in polyhedron$|u$ in convex hull$) + \mathbb{P}(u$ not in convex hull$) \mathbb{P}(q$ in polyhedron$|u$ not in convex hull$) \le \mathbb{P}(q$ in polyhedron$|u$ in convex hull$) + \mathbb{P}(u$ not in convex hull$)$. In such a way the problem of an unbounded polyhedron is overcome and we only need to estimate $\mathbb{P}(q$ in polyhedron$|u$ in convex hull$)$. One more idea is that w.l.o.g. we can assume that $x_i$ is uniformly distributed on the sphere. Then we know the radius of sphere inscribed in our polyhedron, which is exactly equal to $\alpha / 2$. There is another interpretation of this problem, maybe it can help. It is easy to see that our polyhedron is exactly the Voronoi cell of point $u$, so we need to estimate the volume of Voronoi cell. It is obvious that when $n$ tends to infinity, then polyhedron volume tends to zero, so there has to be some rate of converges, but I do not know how to estimate it. Thank you very much for any ideas, proofs, estimates, papers and so on!","Let given a ball of radius $\alpha$ centered in point $u$ in $d$-dimensional space. Let given a sample of $n$ uniformly distributed vectors $x_i$ ($i = 1,\dots,n$) inside the ball. For each vector $x_i$ we connect points $u$ and $x_i$ by a segment and build a hyperplane $P_i$ through the middle of the segment and orthogonal to it. In the general case, the constructed hyperplanes bound a polyhedron in $\mathbb{R}^d$. I need to estimate from above the probability that uniformly distributed vector $q$ fall into this polyhedron. In some cases the constructed polyhedron can be unbounded. More precisely, as far as I know it can be if and only if $u$ is not contained in the convex hull of $x_i$. This probability can be estimated, see for example here . Then I can write down $\mathbb{P}( q$ in polyhedron $) \le \mathbb{P}(u$ in convex hull$) \mathbb{P}(q$ in polyhedron$|u$ in convex hull$) + \mathbb{P}(u$ not in convex hull$) \mathbb{P}(q$ in polyhedron$|u$ not in convex hull$) \le \mathbb{P}(q$ in polyhedron$|u$ in convex hull$) + \mathbb{P}(u$ not in convex hull$)$. In such a way the problem of an unbounded polyhedron is overcome and we only need to estimate $\mathbb{P}(q$ in polyhedron$|u$ in convex hull$)$. One more idea is that w.l.o.g. we can assume that $x_i$ is uniformly distributed on the sphere. Then we know the radius of sphere inscribed in our polyhedron, which is exactly equal to $\alpha / 2$. There is another interpretation of this problem, maybe it can help. It is easy to see that our polyhedron is exactly the Voronoi cell of point $u$, so we need to estimate the volume of Voronoi cell. It is obvious that when $n$ tends to infinity, then polyhedron volume tends to zero, so there has to be some rate of converges, but I do not know how to estimate it. Thank you very much for any ideas, proofs, estimates, papers and so on!",,"['probability', 'geometry', 'convex-geometry', 'geometric-probability', 'convex-hulls']"
94,Uniqueness of Finite Additive Measure,Uniqueness of Finite Additive Measure,,"I know that for two measures defined on the Borel set of real line $\mu_1$ and $\mu_2$, if $\mu_1((a,b))=\mu_2((a,b))$ for all real numbers a and b, then $\mu_1=\mu_2$. Curious on whether similar conditions hold for finite-additive, but not countably additive measures. If $v_1(A)$, $v_2(A)$ are two finitely-additive measures and $v_1(A)$ and $v_2(A)$ are equal for all $A \in \beta$, in which $\beta$ is a collection of Borel sets. What is the 'smallest' $\beta$ to ensure that these two measures are equal? You can assume $\mu(\Omega)=1$ as non-standard probability theory if that's necessary. If it takes a long story to answer, a book/paper name and author is also welcomed. Many thanks for that.","I know that for two measures defined on the Borel set of real line $\mu_1$ and $\mu_2$, if $\mu_1((a,b))=\mu_2((a,b))$ for all real numbers a and b, then $\mu_1=\mu_2$. Curious on whether similar conditions hold for finite-additive, but not countably additive measures. If $v_1(A)$, $v_2(A)$ are two finitely-additive measures and $v_1(A)$ and $v_2(A)$ are equal for all $A \in \beta$, in which $\beta$ is a collection of Borel sets. What is the 'smallest' $\beta$ to ensure that these two measures are equal? You can assume $\mu(\Omega)=1$ as non-standard probability theory if that's necessary. If it takes a long story to answer, a book/paper name and author is also welcomed. Many thanks for that.",,"['probability', 'measure-theory']"
95,Is probability-raising closed under union?,Is probability-raising closed under union?,,"Suppose that $\Pr(X \mid A) > \Pr(X)$, and that $\Pr(X \mid B) > \Pr(X)$.  Does it follow that $\Pr(X \mid A \cup B) > \Pr(X)$? $\Pr(X \mid A \cup B) > \Pr(X)$ holds just in case  $$ [\Pr(X A) - \Pr(X) \cdot \Pr(A)] + [\Pr(XB) - \Pr(X) \cdot \Pr(B)] > \Pr(X A B) - \Pr(X) \cdot \Pr(A B) $$ ($XA$ is the intersection of $X$ and $A$).  Both of the differences on the left-hand-side are positive, so the left-hand-side is positive.  But the difference on the right-hand-side could also be positive, and I don't see why it couldn't be more positive than the sum on the left.  I went looking for simple counterexamples, but couldn't find any.","Suppose that $\Pr(X \mid A) > \Pr(X)$, and that $\Pr(X \mid B) > \Pr(X)$.  Does it follow that $\Pr(X \mid A \cup B) > \Pr(X)$? $\Pr(X \mid A \cup B) > \Pr(X)$ holds just in case  $$ [\Pr(X A) - \Pr(X) \cdot \Pr(A)] + [\Pr(XB) - \Pr(X) \cdot \Pr(B)] > \Pr(X A B) - \Pr(X) \cdot \Pr(A B) $$ ($XA$ is the intersection of $X$ and $A$).  Both of the differences on the left-hand-side are positive, so the left-hand-side is positive.  But the difference on the right-hand-side could also be positive, and I don't see why it couldn't be more positive than the sum on the left.  I went looking for simple counterexamples, but couldn't find any.",,['probability']
96,Odds of Coming Out Ahead in Roulette,Odds of Coming Out Ahead in Roulette,,"I have an interesting roulette problem that I initially thought was easy but now I'm second guessing my self. The problem is as follows: A friend of yours thinks that he has devised a purely mathematical way of beating the standard European roulette wheel, which has 37 pockets. His plan is to come to the roulette table with 100 units with which to bet. On each spin, he places a one-unit, single-number bet. (Recall that winning such a bet returns 36 units to the winner.) He will make exactly 100 bets, no matter how much he wins or loses. He claims that this strategy results in a greater than 50% chance that he will come out ahead at the end of 100 spins, so using this strategy repeatedly will make him a winner. a) Does he have a greater than 50% chance of coming away with more money than he started with? b) If the answer to the previous question is yes, then does that make his strategy a winning one, meaning that it will lead to a long-term increase in bankroll? So for part A I think he does have a greater than 50% chance of coming away ahead. He needs to win at least 3 times in order to walk away with more than he started with. And the probability of winning at least three times is 50.939% (I did 1 - the probability of winning 0, once, or twice with p=(1/37).) So based on that it seems like he does have a greater than 50% chance of walking away ahead... This goes against my intuition, especially for part b. If everyone could do this strategy and come out ahead then they would. But surely it can't be this simple... I don't see how this would lead to a long term increase in bank roll. Any thoughts?","I have an interesting roulette problem that I initially thought was easy but now I'm second guessing my self. The problem is as follows: A friend of yours thinks that he has devised a purely mathematical way of beating the standard European roulette wheel, which has 37 pockets. His plan is to come to the roulette table with 100 units with which to bet. On each spin, he places a one-unit, single-number bet. (Recall that winning such a bet returns 36 units to the winner.) He will make exactly 100 bets, no matter how much he wins or loses. He claims that this strategy results in a greater than 50% chance that he will come out ahead at the end of 100 spins, so using this strategy repeatedly will make him a winner. a) Does he have a greater than 50% chance of coming away with more money than he started with? b) If the answer to the previous question is yes, then does that make his strategy a winning one, meaning that it will lead to a long-term increase in bankroll? So for part A I think he does have a greater than 50% chance of coming away ahead. He needs to win at least 3 times in order to walk away with more than he started with. And the probability of winning at least three times is 50.939% (I did 1 - the probability of winning 0, once, or twice with p=(1/37).) So based on that it seems like he does have a greater than 50% chance of walking away ahead... This goes against my intuition, especially for part b. If everyone could do this strategy and come out ahead then they would. But surely it can't be this simple... I don't see how this would lead to a long term increase in bank roll. Any thoughts?",,"['probability', 'combinatorics', 'gambling']"
97,Approximating a discrete probability distribution with a standard normal distribution,Approximating a discrete probability distribution with a standard normal distribution,,"Let us approximate a discrete distribution by a standard normal distribution, without using a continuity correction factor. Let $X$ be a random variable with discrete distribution, and $Y$ be a random variable with standard normal distribution. Since we did not use a continuity correction factor, can we say that the $P(X \geq x)$ is always greater than or equal to its approximated probability by the standard normal distribution?","Let us approximate a discrete distribution by a standard normal distribution, without using a continuity correction factor. Let $X$ be a random variable with discrete distribution, and $Y$ be a random variable with standard normal distribution. Since we did not use a continuity correction factor, can we say that the $P(X \geq x)$ is always greater than or equal to its approximated probability by the standard normal distribution?",,"['probability', 'statistics', 'normal-distribution']"
98,Understanding solution to probability problem,Understanding solution to probability problem,,"I came across following problem A basketball team consists of 6 frontcourt and 4 backcourt players. If players are divided into roommates at random, what is the probability that there will be exactly two roommate pairs made up of a backcourt and a frontcourt player? I solved the problem and checked the final solution given. I was wrong. After giving a bit of thought I realized I solved it stupidly. However I was not able to solve it again correctly. So I went through the full description given in the answer. But I was not able to understand it either. There are $(10)!/2^5$ different divisions of the 10 players into a first roommate pair, a second roommate pair, and so on. Hence, there are $(10)!/(5!2^5)$ divisions into 5 roommate pairs. There are $\binom{6}{2}\binom{4}{2}$ ways of choosing the frontcourt and backcourt   players to be in the mixed roommate pairs, and then 2 ways of pairing them up. As there is then 1 way to pair up the remaining two backcourt, and $4!/(2!2^2) = 3$ ways of making two roommate pairs from the remaining four frontcourt players, we see that the desired probability is $$P(\text{2 mixed pairs})=\frac{\binom{6}{2}\binom{4}{2}(2)(3)}{(10)!/(5!2^5)}=.5714$$ I was not able to understand following sentences There are $(10)!/2^5$ different divisions of the 10 players into a first roommate pair, a second roommate pair, and so on. Hence, there are $(10)!/(5!2^5)$ divisions into 5 roommate pairs. $4!/(2!2^2) = 3$ ways of making two roommate pairs from the remaining four frontcourt players Both seem to follow same logic, but seems that either I was never came across it or its something simple but I am stupidly not able to get it.","I came across following problem A basketball team consists of 6 frontcourt and 4 backcourt players. If players are divided into roommates at random, what is the probability that there will be exactly two roommate pairs made up of a backcourt and a frontcourt player? I solved the problem and checked the final solution given. I was wrong. After giving a bit of thought I realized I solved it stupidly. However I was not able to solve it again correctly. So I went through the full description given in the answer. But I was not able to understand it either. There are $(10)!/2^5$ different divisions of the 10 players into a first roommate pair, a second roommate pair, and so on. Hence, there are $(10)!/(5!2^5)$ divisions into 5 roommate pairs. There are $\binom{6}{2}\binom{4}{2}$ ways of choosing the frontcourt and backcourt   players to be in the mixed roommate pairs, and then 2 ways of pairing them up. As there is then 1 way to pair up the remaining two backcourt, and $4!/(2!2^2) = 3$ ways of making two roommate pairs from the remaining four frontcourt players, we see that the desired probability is $$P(\text{2 mixed pairs})=\frac{\binom{6}{2}\binom{4}{2}(2)(3)}{(10)!/(5!2^5)}=.5714$$ I was not able to understand following sentences There are $(10)!/2^5$ different divisions of the 10 players into a first roommate pair, a second roommate pair, and so on. Hence, there are $(10)!/(5!2^5)$ divisions into 5 roommate pairs. $4!/(2!2^2) = 3$ ways of making two roommate pairs from the remaining four frontcourt players Both seem to follow same logic, but seems that either I was never came across it or its something simple but I am stupidly not able to get it.",,"['probability', 'combinatorics']"
99,variation of random variable greater or equal than sum sum variations of two independent conditional expectations,variation of random variable greater or equal than sum sum variations of two independent conditional expectations,,"I found the following problem, which seems very simple, but I'm stuck concerning the ideas I can use. The statement is as follows: Let $X$ be a random variable with finite expectation and let $\mathcal{G}_1$ and $\mathcal{G}_2$ be two $\sigma$-algebras which are independent of each other. Let $X_1=E[X|\mathcal{G}_1]$ and $X_2=E[X|\mathcal{G}_2]$. Show that $Var(X) \geq Var(X_1) + Var(X_2)$. Use an example to show that independence of $\mathcal{G}_1$ and $\mathcal{G}_2$ is crucial. It's obvious that if $\mathcal{G}_1=\mathcal{G}_2$ and $X$ is $\mathcal{G}_1$-measurable the inequality does not hold. If I use the law of total variation I can find one of the terms on the r.h.s., but I'm clueless regarding how to get from one sigma-algebra to the other and use their independence. I also thought about somehow using Jensen to get an inequality or conditioning w.r.t. $\sigma(\mathcal{G}_1, \mathcal{G}_2)$, but arrived nowhere. Any clues? Help is greatly appreciated.","I found the following problem, which seems very simple, but I'm stuck concerning the ideas I can use. The statement is as follows: Let $X$ be a random variable with finite expectation and let $\mathcal{G}_1$ and $\mathcal{G}_2$ be two $\sigma$-algebras which are independent of each other. Let $X_1=E[X|\mathcal{G}_1]$ and $X_2=E[X|\mathcal{G}_2]$. Show that $Var(X) \geq Var(X_1) + Var(X_2)$. Use an example to show that independence of $\mathcal{G}_1$ and $\mathcal{G}_2$ is crucial. It's obvious that if $\mathcal{G}_1=\mathcal{G}_2$ and $X$ is $\mathcal{G}_1$-measurable the inequality does not hold. If I use the law of total variation I can find one of the terms on the r.h.s., but I'm clueless regarding how to get from one sigma-algebra to the other and use their independence. I also thought about somehow using Jensen to get an inequality or conditioning w.r.t. $\sigma(\mathcal{G}_1, \mathcal{G}_2)$, but arrived nowhere. Any clues? Help is greatly appreciated.",,"['probability', 'conditional-expectation', 'variance']"
