,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is it possible that the die is fair?,Is it possible that the die is fair?,,"You visit your grandparents and notice an old die and notebook. The die is handmade and the edges are worn. Grandpa explains that he rolled this die 10,000 times, independently and under the same conditions, when he was a prisoner of war and recorded the results of the die rolls in his notebook: Side of the die         1    2        3       4         5    6 Number of outcomes   2607    1633    1148    1839    2552    221 He adds that he used to run an illegal gambling ring and that he fashioned this die out of bone himself. Which of the following follow from these observations? I. The data suggests the die has a much lower probability of producing a ‘6’ compared to other outcomes. II. It is possible, though very unlikely, that the die is fair. How do I determine if the die is fair? The P(6) here is 0.0221 and if I'm not wrong, both options I and II are correct?","You visit your grandparents and notice an old die and notebook. The die is handmade and the edges are worn. Grandpa explains that he rolled this die 10,000 times, independently and under the same conditions, when he was a prisoner of war and recorded the results of the die rolls in his notebook: Side of the die         1    2        3       4         5    6 Number of outcomes   2607    1633    1148    1839    2552    221 He adds that he used to run an illegal gambling ring and that he fashioned this die out of bone himself. Which of the following follow from these observations? I. The data suggests the die has a much lower probability of producing a ‘6’ compared to other outcomes. II. It is possible, though very unlikely, that the die is fair. How do I determine if the die is fair? The P(6) here is 0.0221 and if I'm not wrong, both options I and II are correct?",,"['probability', 'statistics', 'dice']"
1,Is this procedure a Simple Random Sample?,Is this procedure a Simple Random Sample?,,"Page 62 Question 3 of Sampling: Design and Analysis Each of the 10,000 shelves in a certain library is 300 cm long. To estimate how many   books in the library need rebinding, a librarian takes a sample of 50 books using the   following procedure: He first generates a random integer between 1 and 10,000 to   select a shelf, and then generates a random number between 0 and 300 to select a   location on that shelf. Thus, the pair of random numbers (2531, 25.4) would tell the   librarian to include the book that is above the location 25.4 cm from the left end of   shelf number 2531 in the sample. Does this procedure generate an SRS of the books   in the library? My thoughts: In order to be an SRS, every unit in population has the same probability of being in the sample of size n. As a result, I believe that this method would in fact generate an SRS, as each book has the same probability of being selected. Is this correct to assume?","Page 62 Question 3 of Sampling: Design and Analysis Each of the 10,000 shelves in a certain library is 300 cm long. To estimate how many   books in the library need rebinding, a librarian takes a sample of 50 books using the   following procedure: He first generates a random integer between 1 and 10,000 to   select a shelf, and then generates a random number between 0 and 300 to select a   location on that shelf. Thus, the pair of random numbers (2531, 25.4) would tell the   librarian to include the book that is above the location 25.4 cm from the left end of   shelf number 2531 in the sample. Does this procedure generate an SRS of the books   in the library? My thoughts: In order to be an SRS, every unit in population has the same probability of being in the sample of size n. As a result, I believe that this method would in fact generate an SRS, as each book has the same probability of being selected. Is this correct to assume?",,"['statistics', 'sampling']"
2,"What distribution does X/(X+Y), follow, when X and Y are gamma distributed. Prove that the R.V is independent of (X+Y)","What distribution does X/(X+Y), follow, when X and Y are gamma distributed. Prove that the R.V is independent of (X+Y)",,"What distribution does the following r.v follow: $$X/(X+Y)$$ $$X \sim  Gamma(a,1)$$ $$ Y \sim Gamma(b,1)$$ and the variables are independent. Further, how to prove that the random variable is independent of: $X+Y \sim Gamma(a+b,1)$? I am sure there is some kind of a hack to get the result without using the convolution technique, and only relying on the moment generating functions. But I can't come up with it.","What distribution does the following r.v follow: $$X/(X+Y)$$ $$X \sim  Gamma(a,1)$$ $$ Y \sim Gamma(b,1)$$ and the variables are independent. Further, how to prove that the random variable is independent of: $X+Y \sim Gamma(a+b,1)$? I am sure there is some kind of a hack to get the result without using the convolution technique, and only relying on the moment generating functions. But I can't come up with it.",,"['probability', 'statistics', 'random-variables']"
3,Show E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big] = \frac{(n-1)p((1-p)}{n^2}$,Show E,\big[\frac{\bar{X}(1-\bar{X})}{n}\big] = \frac{(n-1)p((1-p)}{n^2},"I am trying to show E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big] = \frac{(n-1)p((1-p)}{n^2}$, for $X_1, X_2,\ldots, X_n\sim\operatorname{b}(1,p)$. I can get to E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big]$ = $\frac{1}{n^2}(np) - (\frac{1}{n}E\big[\bar{X}^2\big])$,which I'm pretty sure is correct, but I'm having trouble simplifying E$\big[\bar{X}^2\big]$. I have: \begin{align}  \frac{1}{n} E\big[\bar{X}^2\big] &= \frac{1}{n^3} E\big[\sum_{i=1}^n X_i^2\big]\\  &= \frac{1}{n^3} E\big[(\sum_{i=1}^n X_i)(\sum_{i=1}^{n}X_i)\big]\\  &= \frac{1}{n^3} \Big(\sum_{i=1}^n\big(E(X_i)E(X_i)\Big)\\ &= \frac{1}{n^3} \Big(\sum_{i=1}^n(np)^2\Big)\\ &= \frac{1}{n^3} (n^3p^2)\\ &= p^2 \end{align}   If I use $p^2$, however, then I get $(\frac{1}{n^2})np - p^2 = \frac{p(1-np)}{n}$, which is incorrect. If someone could explain where I've gone wrong I'd greatly appreciate the help. Thank you very much.","I am trying to show E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big] = \frac{(n-1)p((1-p)}{n^2}$, for $X_1, X_2,\ldots, X_n\sim\operatorname{b}(1,p)$. I can get to E$\big[\frac{\bar{X}(1-\bar{X})}{n}\big]$ = $\frac{1}{n^2}(np) - (\frac{1}{n}E\big[\bar{X}^2\big])$,which I'm pretty sure is correct, but I'm having trouble simplifying E$\big[\bar{X}^2\big]$. I have: \begin{align}  \frac{1}{n} E\big[\bar{X}^2\big] &= \frac{1}{n^3} E\big[\sum_{i=1}^n X_i^2\big]\\  &= \frac{1}{n^3} E\big[(\sum_{i=1}^n X_i)(\sum_{i=1}^{n}X_i)\big]\\  &= \frac{1}{n^3} \Big(\sum_{i=1}^n\big(E(X_i)E(X_i)\Big)\\ &= \frac{1}{n^3} \Big(\sum_{i=1}^n(np)^2\Big)\\ &= \frac{1}{n^3} (n^3p^2)\\ &= p^2 \end{align}   If I use $p^2$, however, then I get $(\frac{1}{n^2})np - p^2 = \frac{p(1-np)}{n}$, which is incorrect. If someone could explain where I've gone wrong I'd greatly appreciate the help. Thank you very much.",,['statistics']
4,"Using importance sampling to simulate the mean of a normal distribution truncated to interval [0,1]","Using importance sampling to simulate the mean of a normal distribution truncated to interval [0,1]",,"So in these notes it says that importance sampling is: $$\int_F sf(s)ds = \int_G s \frac{f(s)}{g(s)}g(s)ds$$ And then it proceeds to give the following example: In this example, if we draw from $f(x)$, are we effectively drawing from the truncated standard normal distribution? Also, can someone explain why it says that $g(x)=1$ if we draw $x$ from $U[0,1]$?","So in these notes it says that importance sampling is: $$\int_F sf(s)ds = \int_G s \frac{f(s)}{g(s)}g(s)ds$$ And then it proceeds to give the following example: In this example, if we draw from $f(x)$, are we effectively drawing from the truncated standard normal distribution? Also, can someone explain why it says that $g(x)=1$ if we draw $x$ from $U[0,1]$?",,"['probability', 'statistics', 'normal-distribution', 'sampling', 'simulation']"
5,Independent/mutually excl. probability,Independent/mutually excl. probability,,"Suppose a large # of students are surveyed about how they travel, $G - 0.5$ , $B - 0.4$ , $W = 0.8$ Given that: $W$ is independent of $G$ and $W$ is independent of $B$ , but $B$ is mutually exclusive of $G$ , what is the probability that a random student does none of them? We want $P(\overline{W} \cap \overline{G} \cap \overline{B})$ , but how can I split it?","Suppose a large # of students are surveyed about how they travel, , , Given that: is independent of and is independent of , but is mutually exclusive of , what is the probability that a random student does none of them? We want , but how can I split it?",G - 0.5 B - 0.4 W = 0.8 W G W B B G P(\overline{W} \cap \overline{G} \cap \overline{B}),"['probability', 'statistics']"
6,Which events are independent?,Which events are independent?,,"You toss a fair coin 3x, events: A = ""first flip H"" B = ""second flip T"" C = ""all flips H"" D = ""at least 2 flips T"" Q: Which events are independent? From the informal def. it is where one doesnt affect the other. So in this case, $AB$ seem independent? Any others?","You toss a fair coin 3x, events: A = ""first flip H"" B = ""second flip T"" C = ""all flips H"" D = ""at least 2 flips T"" Q: Which events are independent? From the informal def. it is where one doesnt affect the other. So in this case, $AB$ seem independent? Any others?",,"['probability', 'statistics']"
7,Minimize Expected squared Prediction Error (EPE),Minimize Expected squared Prediction Error (EPE),,"I have difficulty understanding when minimizing expected squared prediction error: $$\operatorname{EPE}(\beta)=\int (y-x^T \beta)^2 \Pr(dx, dy),$$ how to reach the solution that $$\operatorname{E}[yx]-\operatorname{E}[xx^{T}\beta]=0.$$ From A Solution Manual and Notes for the Text: The Elements of Statistical Learning (page 2), I noticed the formula (2): $$\frac{\partial \operatorname{EPE}}{\partial \beta}=\int 2(y-x^T\beta)(-1) x \Pr(dx, dy).$$ I understand chain rule is used here to solve the derivative, but why the last part is $x$ instead of $x^T$? As $x$ is a column vector and the Jacobian of a constant w.r.t. $x$ should be a row vector. $$\frac{\partial x^T\beta}{\partial \beta}=x^T.$$ What is missing in my analysis? According to the Jacobian matrix , shouldn't the $\frac{\partial x^T\beta}{\partial \beta}$ be a row vector instead of a column vector? $$\frac{\partial EPE}{\partial \mathbf{\beta}}=  \left (\frac{\partial EPE}{\partial \beta_{1}}, \frac{\partial EPE}{\partial \beta_{2}}, \dots, \frac{\partial EPE}{\partial \beta_{N}}  \right )$$","I have difficulty understanding when minimizing expected squared prediction error: $$\operatorname{EPE}(\beta)=\int (y-x^T \beta)^2 \Pr(dx, dy),$$ how to reach the solution that $$\operatorname{E}[yx]-\operatorname{E}[xx^{T}\beta]=0.$$ From A Solution Manual and Notes for the Text: The Elements of Statistical Learning (page 2), I noticed the formula (2): $$\frac{\partial \operatorname{EPE}}{\partial \beta}=\int 2(y-x^T\beta)(-1) x \Pr(dx, dy).$$ I understand chain rule is used here to solve the derivative, but why the last part is $x$ instead of $x^T$? As $x$ is a column vector and the Jacobian of a constant w.r.t. $x$ should be a row vector. $$\frac{\partial x^T\beta}{\partial \beta}=x^T.$$ What is missing in my analysis? According to the Jacobian matrix , shouldn't the $\frac{\partial x^T\beta}{\partial \beta}$ be a row vector instead of a column vector? $$\frac{\partial EPE}{\partial \mathbf{\beta}}=  \left (\frac{\partial EPE}{\partial \beta_{1}}, \frac{\partial EPE}{\partial \beta_{2}}, \dots, \frac{\partial EPE}{\partial \beta_{N}}  \right )$$",,['statistics']
8,Is the following data discrete or continuous?,Is the following data discrete or continuous?,,"Here are the finishing times taken for a race in seconds. $$10.1,10.6,11.2,12.1,10.9,11.3$$ Is this data discrete or continuous? My understanding is that time is continuous data but these data are presented in a to-one-decimal-place form. Are they now discrete?","Here are the finishing times taken for a race in seconds. $$10.1,10.6,11.2,12.1,10.9,11.3$$ Is this data discrete or continuous? My understanding is that time is continuous data but these data are presented in a to-one-decimal-place form. Are they now discrete?",,"['statistics', 'data-analysis']"
9,Intuitive explanantion for random vectors and estimation theory,Intuitive explanantion for random vectors and estimation theory,,"Suppose $X$ is a random vector and $X \sim f_\theta(x)$. I have a question about random vectors. Q1. Why do we consider each entry of a random vector to be $X_i \sim f_\theta(x_i)$? I think I can visualise it as being a vector in space, so its exact position is random. Each of its coordinates will be randomly chosen. Each entry has a probability distribution. Is this the correct intuition? I think I am getting confused by the use of $f_\theta(x_i)$, so can someone explain? Q2. Further, is there some intuition behind why joint probability density becomes the product when each entry is independent? Q3. Why is each observation considered to be an entry of a random vector during parameter estimation? In this case, why can't each entry be drawn simply from a distribution $X_i \sim f_\theta(x_i)$ which is exactly the same for all $i$? Why do we assume that the random variable is different for different measurements?","Suppose $X$ is a random vector and $X \sim f_\theta(x)$. I have a question about random vectors. Q1. Why do we consider each entry of a random vector to be $X_i \sim f_\theta(x_i)$? I think I can visualise it as being a vector in space, so its exact position is random. Each of its coordinates will be randomly chosen. Each entry has a probability distribution. Is this the correct intuition? I think I am getting confused by the use of $f_\theta(x_i)$, so can someone explain? Q2. Further, is there some intuition behind why joint probability density becomes the product when each entry is independent? Q3. Why is each observation considered to be an entry of a random vector during parameter estimation? In this case, why can't each entry be drawn simply from a distribution $X_i \sim f_\theta(x_i)$ which is exactly the same for all $i$? Why do we assume that the random variable is different for different measurements?",,"['statistics', 'random-variables', 'statistical-inference']"
10,Statistics Homework Question (Binomial Distribution),Statistics Homework Question (Binomial Distribution),,"Problem: In a binomial experiment with 45 trials, the probability of more than 25 successes can be approximated by $P(z > \frac{(25-27)}{3.29}$) What is the probability of success of a single trial of this experiment? Choices: 0.07 0.56 0.79 0.61 0.6 My Solution: Since the experiment can be approximated by a normal distribution, I evaluated P(z) using NormalCdf on my calculator. $$P(z > \frac{25-27}{3.29}) = NormCdf(\frac{25-27}{3.29},\infty, 0, 1) = 0.72834 $$ Then, I set up the binomialCdf expression as $binomCdf(45, p, 26, 45)$ using 26 as the minimum number of successes as the question specifies it to be more than 25. Through inspection, I found p to be 0.61 . However, the answer key says otherwise. Can someone check the error in my work? Thank you!","Problem: In a binomial experiment with 45 trials, the probability of more than 25 successes can be approximated by $P(z > \frac{(25-27)}{3.29}$) What is the probability of success of a single trial of this experiment? Choices: 0.07 0.56 0.79 0.61 0.6 My Solution: Since the experiment can be approximated by a normal distribution, I evaluated P(z) using NormalCdf on my calculator. $$P(z > \frac{25-27}{3.29}) = NormCdf(\frac{25-27}{3.29},\infty, 0, 1) = 0.72834 $$ Then, I set up the binomialCdf expression as $binomCdf(45, p, 26, 45)$ using 26 as the minimum number of successes as the question specifies it to be more than 25. Through inspection, I found p to be 0.61 . However, the answer key says otherwise. Can someone check the error in my work? Thank you!",,['statistics']
11,How do I solve this permutations/combinations problem?,How do I solve this permutations/combinations problem?,,"I have $7$ yoghurts to last the week. Two are strawberry, three raspberry and two peach. I select one yoghurt each day. In how many different orders can I eat the yoghurts? If I select a yoghurt at random each day, what is the probability that I eat the two strawberry ones on consecutive days? I thought just going for $7!$ would work but I got the wrong answer. How do I figure this out?","I have yoghurts to last the week. Two are strawberry, three raspberry and two peach. I select one yoghurt each day. In how many different orders can I eat the yoghurts? If I select a yoghurt at random each day, what is the probability that I eat the two strawberry ones on consecutive days? I thought just going for would work but I got the wrong answer. How do I figure this out?",7 7!,"['statistics', 'permutations', 'combinations']"
12,test for equality of population means at a 10% level of significance,test for equality of population means at a 10% level of significance,,"Independent random samples, each of size n (i.e. observe {$X_i$}$_{i=1,...n}$ and {$Y_j$}$_{j=1,...,n}$), are to be taken from 2 exponential distributions with unknown means $\theta_1$ and $\theta_2$ respectfully. a) Derive a likelihood ratio test for $H_0: \theta_1 = \theta_2$ against $H_1: \theta_1 \not = \theta_2$ and in doing so show that the quotient $Q=\frac{\sum_{i=1}^n X_i}{\sum_{j=1}^n Y_j} = \frac{\over X}{\over Y}$ is an appropriate test statistic to use. $$\text{I think I got this part correct but I will show you what I did.}$$ $$ \text{Please correct any mistakes. My real question is about part (b)}$$ When $H_0$ true ($\theta \in \omega$) $$\theta_1 = \theta_2 = \theta$$ $$\hat \theta_{MLE} = \frac{\bar X + \bar Y}{2} \text{ (with proper derivation)}$$ When $H_1$true ($\theta \in Ω$) $$\theta_1 \not = \theta_2$$ $$\hat \theta_{1 MLE} = \bar X \text{ and } \hat \theta_{2 MLE} = \bar Y \text{ (with proper derivations)}$$ Now to work out $\lambda$ $$\lambda = \frac{L(\hat \omega)}{L(\hat Ω)} = \frac{[\prod _{i=1}^n \frac{2}{\bar X + \bar Y}e^{-\frac{2X_i}{\bar X + \bar Y}}][\prod _{j=1}^n \frac{2}{\bar X + \bar Y}e^{-\frac{2Y_i}{\bar X + \bar Y}}]}{[\prod _{i=1}^n \frac{1}{\bar X}e^{-\frac{X_i}{\bar X}}][\prod _{j=1}^n \frac{1}{\bar Y}e^{-\frac{Y_i}{\bar Y}}]} = ... = [\frac{2 \sqrt Q}{1+Q}]^{2n} \leq K_\alpha$$ b) Two samples, each of size n=3, are obtained from independent exponential distributions yielding: 0.13, 0.15, 3.30 and 1.29, 2.03, 2.31, respectively. Test for equality of population means at the 10% level of significance. Hint: if $W$ follows Gamma$(\alpha, \theta)$ then $\frac{2W}{\theta}$ follows $\chi^2_{2 \alpha}$ Now I did a sketch of say $f(Q) = [\frac{2 \sqrt Q}{1+Q}]^{2n}$ and see that it has a max where $Q=1$ and tends to zero as Q gets larger so: $$\lambda \leq K_\alpha \text{ when }\frac{\bar X}{\bar Y} \leq c_1 \text{ or } \frac{\bar X}{\bar Y} \geq c_2$$ So the thing I am most confused with is the whole $\frac{\bar X}{\bar Y}$ thing because if it was just $\bar X$ for example then $\sum_{i=1}^n X_i$ of an exponential distribution is a Gamma distribution (using moment generating functions or some other method) but I can't see how to proceed here with this Q.","Independent random samples, each of size n (i.e. observe {$X_i$}$_{i=1,...n}$ and {$Y_j$}$_{j=1,...,n}$), are to be taken from 2 exponential distributions with unknown means $\theta_1$ and $\theta_2$ respectfully. a) Derive a likelihood ratio test for $H_0: \theta_1 = \theta_2$ against $H_1: \theta_1 \not = \theta_2$ and in doing so show that the quotient $Q=\frac{\sum_{i=1}^n X_i}{\sum_{j=1}^n Y_j} = \frac{\over X}{\over Y}$ is an appropriate test statistic to use. $$\text{I think I got this part correct but I will show you what I did.}$$ $$ \text{Please correct any mistakes. My real question is about part (b)}$$ When $H_0$ true ($\theta \in \omega$) $$\theta_1 = \theta_2 = \theta$$ $$\hat \theta_{MLE} = \frac{\bar X + \bar Y}{2} \text{ (with proper derivation)}$$ When $H_1$true ($\theta \in Ω$) $$\theta_1 \not = \theta_2$$ $$\hat \theta_{1 MLE} = \bar X \text{ and } \hat \theta_{2 MLE} = \bar Y \text{ (with proper derivations)}$$ Now to work out $\lambda$ $$\lambda = \frac{L(\hat \omega)}{L(\hat Ω)} = \frac{[\prod _{i=1}^n \frac{2}{\bar X + \bar Y}e^{-\frac{2X_i}{\bar X + \bar Y}}][\prod _{j=1}^n \frac{2}{\bar X + \bar Y}e^{-\frac{2Y_i}{\bar X + \bar Y}}]}{[\prod _{i=1}^n \frac{1}{\bar X}e^{-\frac{X_i}{\bar X}}][\prod _{j=1}^n \frac{1}{\bar Y}e^{-\frac{Y_i}{\bar Y}}]} = ... = [\frac{2 \sqrt Q}{1+Q}]^{2n} \leq K_\alpha$$ b) Two samples, each of size n=3, are obtained from independent exponential distributions yielding: 0.13, 0.15, 3.30 and 1.29, 2.03, 2.31, respectively. Test for equality of population means at the 10% level of significance. Hint: if $W$ follows Gamma$(\alpha, \theta)$ then $\frac{2W}{\theta}$ follows $\chi^2_{2 \alpha}$ Now I did a sketch of say $f(Q) = [\frac{2 \sqrt Q}{1+Q}]^{2n}$ and see that it has a max where $Q=1$ and tends to zero as Q gets larger so: $$\lambda \leq K_\alpha \text{ when }\frac{\bar X}{\bar Y} \leq c_1 \text{ or } \frac{\bar X}{\bar Y} \geq c_2$$ So the thing I am most confused with is the whole $\frac{\bar X}{\bar Y}$ thing because if it was just $\bar X$ for example then $\sum_{i=1}^n X_i$ of an exponential distribution is a Gamma distribution (using moment generating functions or some other method) but I can't see how to proceed here with this Q.",,"['probability-theory', 'statistics', 'probability-distributions', 'maximum-likelihood', 'log-likelihood']"
13,PDF of a ratio of functions of order statistics,PDF of a ratio of functions of order statistics,,"Question : Let $X_1,\dots,X_n$ be iid from a distribution with cdf $F(\cdot)$. Find the pdf of $\dfrac{1-F(X_{(2)})}{1-F(X_{(1)})}$. I know that $F(X) \sim \mathcal{U}(0,1)$ for any r.v. $X$, so in this case, we're looking for the pdf of $\dfrac{1- U_{(2)}}{1-U_{(1)}}$, where $U_1,U_2,\dots,U_n$ are standard uniform. From here, I'm sort of stuck. This is a test question, so it was meant to be reasonably quick. Some ideas: I can calculate $f_{U_{(1)}, U_{(2)}} (u,v) = n(n-1) \cdot \left[ 1 - v \right]^{n-2}\cdot  \mathbb{1}[0 <  u < v< 1] $. Then I suppose I could find $P \left( \frac{1-U_{(2)}}{1-U_{(1)}} \le x \right) $ by integrating and go from there. The hint was that for $U_1,\dots,U_n \stackrel{iid}{\sim} \mathcal{U}(0,1)$, we have the following fact: given $ U_{(n)} = u$, $(U_{(1)},\dots,U_{(n-1)})$ is conditionally distributed as order statistics on $[0,u]$. So I could condition on $U_{(3)}$? This is still a pain, though. The above hint makes me think there's a typo, as it doesn't seem to help. Is there a clever way to do this problem?","Question : Let $X_1,\dots,X_n$ be iid from a distribution with cdf $F(\cdot)$. Find the pdf of $\dfrac{1-F(X_{(2)})}{1-F(X_{(1)})}$. I know that $F(X) \sim \mathcal{U}(0,1)$ for any r.v. $X$, so in this case, we're looking for the pdf of $\dfrac{1- U_{(2)}}{1-U_{(1)}}$, where $U_1,U_2,\dots,U_n$ are standard uniform. From here, I'm sort of stuck. This is a test question, so it was meant to be reasonably quick. Some ideas: I can calculate $f_{U_{(1)}, U_{(2)}} (u,v) = n(n-1) \cdot \left[ 1 - v \right]^{n-2}\cdot  \mathbb{1}[0 <  u < v< 1] $. Then I suppose I could find $P \left( \frac{1-U_{(2)}}{1-U_{(1)}} \le x \right) $ by integrating and go from there. The hint was that for $U_1,\dots,U_n \stackrel{iid}{\sim} \mathcal{U}(0,1)$, we have the following fact: given $ U_{(n)} = u$, $(U_{(1)},\dots,U_{(n-1)})$ is conditionally distributed as order statistics on $[0,u]$. So I could condition on $U_{(3)}$? This is still a pain, though. The above hint makes me think there's a typo, as it doesn't seem to help. Is there a clever way to do this problem?",,['statistics']
14,Obtaining a level-$\alpha$ likelihood ratio test for $H_0: \theta = \theta_0$ vs. $H_1: \theta \neq \theta_0$ for $f_\theta (x) = \theta x^{\theta-1}$,Obtaining a level- likelihood ratio test for  vs.  for,\alpha H_0: \theta = \theta_0 H_1: \theta \neq \theta_0 f_\theta (x) = \theta x^{\theta-1},"Suppose I have a sequence of iid random variables $X_1, \ldots, X_n$ following the pdf: $$ f_\theta (x) = \theta x^{\theta-1} $$ for $\theta >0$ and $0 <x<1$. I would like to obtain a level-$\alpha$ likelihood ratio test for the null hypothesis $H_0: \theta = \theta_0$ versus the two-sided alternative $H_1: \theta \neq \theta_0$ where $\theta_0$ is a known constant. MY ATTEMPT: I first construct the ratio: \begin{align} \lambda(x) &= \frac{\sup_{\theta=\theta_0}L(\theta\mid X)}{\sup_{\theta\neq\theta_0}L(\theta\mid X)} \\[10pt] &= \frac{\theta_0^n \left(e^{\sum \log x_i}\right)^{\theta_0-1}}{\left(\frac n {-\sum \log x_i}\right)^n \left(e^{\sum \log x_i}\right)^{\left(\frac n {-\sum \log x_i} - 1\right)}} \\[10pt] &= \left(\frac{-\theta_0 \sum \log x_i} n \right)^n e^{n+\theta_0 \sum \log x_i} \end{align} The denominator is calculated using the MLE of $\theta$ which is $\theta^\text{MLE} = \frac n {-\sum \log x_i}$. Now, I'd like to find the likelihood ratio test, in that I would like to choose a constant $c$ such that: $$ \alpha = \sup_{\theta = \theta_0} P_\theta (\lambda(x) \leq c) $$ Now, $-\sum \log x_i \sim \operatorname{Gamma}(n, \theta)$ but I CANNOT isolate the above equation due to the $\log$ form. What is the right answer here? Thanks!","Suppose I have a sequence of iid random variables $X_1, \ldots, X_n$ following the pdf: $$ f_\theta (x) = \theta x^{\theta-1} $$ for $\theta >0$ and $0 <x<1$. I would like to obtain a level-$\alpha$ likelihood ratio test for the null hypothesis $H_0: \theta = \theta_0$ versus the two-sided alternative $H_1: \theta \neq \theta_0$ where $\theta_0$ is a known constant. MY ATTEMPT: I first construct the ratio: \begin{align} \lambda(x) &= \frac{\sup_{\theta=\theta_0}L(\theta\mid X)}{\sup_{\theta\neq\theta_0}L(\theta\mid X)} \\[10pt] &= \frac{\theta_0^n \left(e^{\sum \log x_i}\right)^{\theta_0-1}}{\left(\frac n {-\sum \log x_i}\right)^n \left(e^{\sum \log x_i}\right)^{\left(\frac n {-\sum \log x_i} - 1\right)}} \\[10pt] &= \left(\frac{-\theta_0 \sum \log x_i} n \right)^n e^{n+\theta_0 \sum \log x_i} \end{align} The denominator is calculated using the MLE of $\theta$ which is $\theta^\text{MLE} = \frac n {-\sum \log x_i}$. Now, I'd like to find the likelihood ratio test, in that I would like to choose a constant $c$ such that: $$ \alpha = \sup_{\theta = \theta_0} P_\theta (\lambda(x) \leq c) $$ Now, $-\sum \log x_i \sim \operatorname{Gamma}(n, \theta)$ but I CANNOT isolate the above equation due to the $\log$ form. What is the right answer here? Thanks!",,"['statistics', 'statistical-inference', 'hypothesis-testing', 'maximum-likelihood']"
15,"If $X,Y,Z$ are independent random variables having identical density functions",If  are independent random variables having identical density functions,"X,Y,Z","If $X,Y,Z$ are independent random variables having identical density functions $f(x) = e^{-x} $ , $0 < x < \infty$ , derive the joint probability density of the vector $(U,V,W)$ , where \begin{align} U &= X + Y \\ V &= X + Z \\ W &= Y + Z \end{align} I'm not sure on how to do this but, if were to find the joint probability density... I would do moment generate function for each $U,$ $V$ and $W$  and then multiple those.","If $X,Y,Z$ are independent random variables having identical density functions $f(x) = e^{-x} $ , $0 < x < \infty$ , derive the joint probability density of the vector $(U,V,W)$ , where \begin{align} U &= X + Y \\ V &= X + Z \\ W &= Y + Z \end{align} I'm not sure on how to do this but, if were to find the joint probability density... I would do moment generate function for each $U,$ $V$ and $W$  and then multiple those.",,"['statistics', 'random-variables', 'density-function']"
16,How to calculate standard deviation of event without knowing probability.,How to calculate standard deviation of event without knowing probability.,,"So, I've been bowling recently, and I realized I had an odd conundrum. I knew how to do binomial distributions with coin flips and whatnot, because we knew the probability. However, when I tried to do strike chance analysis, I realized I was a bit lost. For example, I bowled 5 games. I had 52 shots at all 10 pins, and 13 of those ended up as strikes. I know the total number of chances, and the number of successes, but since I don't know the actual probability of me getting a strike, I don't know how to find the standard deviation of my true strike rate. If I had $A$ chances to strike, and striked $B$ times, I have a strike rate of $A/B$. Do I, for statistical purposes, presume that $A/B$ is the true probability? Or is there another formula for how to make estimates like that when the true probability is unknown, and I want to find the standard deviation of the true probability, and find the confidence intervals of my strike rate.","So, I've been bowling recently, and I realized I had an odd conundrum. I knew how to do binomial distributions with coin flips and whatnot, because we knew the probability. However, when I tried to do strike chance analysis, I realized I was a bit lost. For example, I bowled 5 games. I had 52 shots at all 10 pins, and 13 of those ended up as strikes. I know the total number of chances, and the number of successes, but since I don't know the actual probability of me getting a strike, I don't know how to find the standard deviation of my true strike rate. If I had $A$ chances to strike, and striked $B$ times, I have a strike rate of $A/B$. Do I, for statistical purposes, presume that $A/B$ is the true probability? Or is there another formula for how to make estimates like that when the true probability is unknown, and I want to find the standard deviation of the true probability, and find the confidence intervals of my strike rate.",,"['statistics', 'probability-distributions', 'standard-deviation']"
17,"$X_i \sim \operatorname{Unif}(0,1)$, and for $\varepsilon >0$, $P(|X_{(n)}-1|\geq \varepsilon) =(1-\varepsilon)^n$. Must we bound $\varepsilon$?",", and for , . Must we bound ?","X_i \sim \operatorname{Unif}(0,1) \varepsilon >0 P(|X_{(n)}-1|\geq \varepsilon) =(1-\varepsilon)^n \varepsilon","Suppose $X_1, \ldots, X_n \sim \operatorname{Unif}(0,1)$ are iid random variables and we define $X_{(n)} = \max X_i$ as the largest order statistic. I would like to show that $X_{(n)}$ converges in probability to $1$. To do so, I have: For all $\varepsilon >0$, $$ P(|X_{(n)}-1|\geq \varepsilon) = \prod_{i} P(X_i <1-\varepsilon) = (1-\varepsilon)^n $$ Now, to take the limit, I have an issue in that for $0<\varepsilon \leq 1$, as $n \to \infty$, $P(|X_{(n)}-1|\geq \varepsilon)\to 0$. But for $\varepsilon >1$, it blows up. What is the correct way of doing this problem here ? Is there a bound on $\varepsilon$? Would it be valid to write: $$ P(X_{(n)}\leq 1-\varepsilon) = P(X_{(n)}\leq 1-\varepsilon)\mathbb{1}_{\varepsilon>1} + P(X_{(n)}\leq 1-\varepsilon) \mathbb{1}_{\varepsilon\leq 1} \text{ ?} $$","Suppose $X_1, \ldots, X_n \sim \operatorname{Unif}(0,1)$ are iid random variables and we define $X_{(n)} = \max X_i$ as the largest order statistic. I would like to show that $X_{(n)}$ converges in probability to $1$. To do so, I have: For all $\varepsilon >0$, $$ P(|X_{(n)}-1|\geq \varepsilon) = \prod_{i} P(X_i <1-\varepsilon) = (1-\varepsilon)^n $$ Now, to take the limit, I have an issue in that for $0<\varepsilon \leq 1$, as $n \to \infty$, $P(|X_{(n)}-1|\geq \varepsilon)\to 0$. But for $\varepsilon >1$, it blows up. What is the correct way of doing this problem here ? Is there a bound on $\varepsilon$? Would it be valid to write: $$ P(X_{(n)}\leq 1-\varepsilon) = P(X_{(n)}\leq 1-\varepsilon)\mathbb{1}_{\varepsilon>1} + P(X_{(n)}\leq 1-\varepsilon) \mathbb{1}_{\varepsilon\leq 1} \text{ ?} $$",,"['probability', 'probability-theory', 'statistics', 'statistical-inference']"
18,How do they simplify these regression formulas,How do they simplify these regression formulas,,My book writes $$\text{SSres}=\sum (y_j-\hat y_j)^2$$ $$=\sum y^{2}_{j}-n \bar y ^{2} - \beta_{1}  Sxy$$ How is this the same formula?,My book writes $$\text{SSres}=\sum (y_j-\hat y_j)^2$$ $$=\sum y^{2}_{j}-n \bar y ^{2} - \beta_{1}  Sxy$$ How is this the same formula?,,"['statistics', 'regression']"
19,Iterated Law of Expectation in Linear Regression,Iterated Law of Expectation in Linear Regression,,Suppose $E(Y|X)$ exists. There exists a disturbance term $\epsilon$ such that $Y=E(Y|X)+\epsilon$ where $E(\epsilon|X)=0$. I have trouble understanding the following simplifying process: $E(Y-E(Y|X)|X)=E(Y|X)-E(E(Y|X)|X)$. The second term on RHS simplifies to: $E(Y|X)$. Can someone explain this in detail? Thanks.,Suppose $E(Y|X)$ exists. There exists a disturbance term $\epsilon$ such that $Y=E(Y|X)+\epsilon$ where $E(\epsilon|X)=0$. I have trouble understanding the following simplifying process: $E(Y-E(Y|X)|X)=E(Y|X)-E(E(Y|X)|X)$. The second term on RHS simplifies to: $E(Y|X)$. Can someone explain this in detail? Thanks.,,"['probability', 'statistics', 'expectation', 'regression']"
20,Likelihood Function is a random variable,Likelihood Function is a random variable,,"I am taking my first statistics course and we are talking about finding a good estimate to unknown parameter $\theta$ given a sample $X_{1},...X_{n}\sim F_{\theta}$, and we talked about the likelihood function $L(\theta)$ and he claimed the maximum of likelihood function $L(\theta)$ is a random variable and the lecturer gave the example of two consecutive coin tosses. So we have $(T,T),(T,H),(H,T),(H,H)$. Assuming the probability of getting $T$ is an unknown parameter $p$. Then we will have to maximize $p^2,p(1-p),(1-p)^2$ respectively to find which $p$ is more likely to give us the  given sample space  and as a result we had $\hat{p}=\begin{cases} 1 & \left(T,T\right)\\ \frac{1}{2} & (H,T)\,or\,(T,H)\\ 0 & \left(H,H\right) \end{cases}$ But I didn't really understand how to see this as random variable. I mean if I look at $P(\hat{p}=1)=p^2$, it doesn't really makes sense since p is an unknow parameter. Now we are talking about given two estimations (two random variables), which gives a better estimation (Mean Squarred Error etc.) and we are usng the fact that the estimations are random variables, but since I don't get why it's a random variable it creates a problem for my understanding. Can someone explain why this is a random variable, or if I am misunderstanding something? Thanks","I am taking my first statistics course and we are talking about finding a good estimate to unknown parameter $\theta$ given a sample $X_{1},...X_{n}\sim F_{\theta}$, and we talked about the likelihood function $L(\theta)$ and he claimed the maximum of likelihood function $L(\theta)$ is a random variable and the lecturer gave the example of two consecutive coin tosses. So we have $(T,T),(T,H),(H,T),(H,H)$. Assuming the probability of getting $T$ is an unknown parameter $p$. Then we will have to maximize $p^2,p(1-p),(1-p)^2$ respectively to find which $p$ is more likely to give us the  given sample space  and as a result we had $\hat{p}=\begin{cases} 1 & \left(T,T\right)\\ \frac{1}{2} & (H,T)\,or\,(T,H)\\ 0 & \left(H,H\right) \end{cases}$ But I didn't really understand how to see this as random variable. I mean if I look at $P(\hat{p}=1)=p^2$, it doesn't really makes sense since p is an unknow parameter. Now we are talking about given two estimations (two random variables), which gives a better estimation (Mean Squarred Error etc.) and we are usng the fact that the estimations are random variables, but since I don't get why it's a random variable it creates a problem for my understanding. Can someone explain why this is a random variable, or if I am misunderstanding something? Thanks",,"['statistics', 'maximum-likelihood']"
21,What is the meaning of log moment,What is the meaning of log moment,,"In the basic probability and statistics, we are familiar with the meanings of the first moment and the second moment: $$\mathbb{E}[X]\mathrm{: the~average~of~}X$$ $$\mathbb{E}[X^2]-\mathbb{E}[X]^2\mathrm{: the~variance~of~}X$$ However, for the log moment, $$\mathbb{E}[\log X]$$ it is somehow esoteric to figure out its meaning. Actually, I come up with this question because I learned that the maximum entropy distribution subject to the following constraints is the gamma distribution. $$\mathbb{E}[X]=g_1$$ $$\mathbb{E}[\log X]=g_2$$ where $g_1$ and $g_2$ are some constant. Maybe some realization of the random variable $X$ has specific meanings in both of its first moment and log moment so that the gamma distribution can be its maximum entropy distribution. For more information about the maximum entropy distribution, please refers to http://www.mtm.ufsc.br/~taneja/book/node14.html Thanks","In the basic probability and statistics, we are familiar with the meanings of the first moment and the second moment: However, for the log moment, it is somehow esoteric to figure out its meaning. Actually, I come up with this question because I learned that the maximum entropy distribution subject to the following constraints is the gamma distribution. where and are some constant. Maybe some realization of the random variable has specific meanings in both of its first moment and log moment so that the gamma distribution can be its maximum entropy distribution. For more information about the maximum entropy distribution, please refers to http://www.mtm.ufsc.br/~taneja/book/node14.html Thanks",\mathbb{E}[X]\mathrm{: the~average~of~}X \mathbb{E}[X^2]-\mathbb{E}[X]^2\mathrm{: the~variance~of~}X \mathbb{E}[\log X] \mathbb{E}[X]=g_1 \mathbb{E}[\log X]=g_2 g_1 g_2 X,"['probability', 'statistics', 'probability-distributions']"
22,Why does the second order delta method approximation to the variance of Bernoulli r.v. result in a negative chi-square?,Why does the second order delta method approximation to the variance of Bernoulli r.v. result in a negative chi-square?,,"Let $Y_1, \ldots, Y_n$ be iid Bernoulli random variables with parameter $p$. Suppose we estimate the variance $Var(Y_1) = p(1-p)$ using $\hat{p}(1-\hat{p})$ where $\hat{p}=\bar{Y}_n$. I am trying to obtain the asymptotic distribution for this estimator specifically in the case where $p=\frac{1}{2}$. In the $p = \frac{1}{2}$ case, the first derivative is zero, hence we use the second order delta method: Suppose that $\sqrt{n}(T_n-\theta_0) \to_D Z$ and that we are interested in $g(T_n)$ where $g'(\theta_0) = 0$ but $g''$ is continuous and nonzero in a neighborhood of $\theta_0$. Then $\sqrt{n}(g(T_n)-g(\theta_0))$ has a degenerate limiting distribution, but: $$ $\sqrt{n}(g(T_n)-g(\theta_0)) \to_D \frac{g''(\theta_0)}{2}Z^2 $$ So, using this I have that for $p =\frac{1}{2}$, $g'(p) = 0$, but $g''(p) = -2 \neq 0$, so: $$ n\left(\hat{p}(1-\hat{p})-\frac{1}{4}\right) \to_D -\frac{1}{4}\chi^2_1 $$ I am wondering why this negative limit makes sense. I read in a footnote somewhere that this makes sense since $p(1-p)$ is maximized at $p=\frac{1}{2}$, but this doesn't really register with me. Can anyone help me here? thanks.","Let $Y_1, \ldots, Y_n$ be iid Bernoulli random variables with parameter $p$. Suppose we estimate the variance $Var(Y_1) = p(1-p)$ using $\hat{p}(1-\hat{p})$ where $\hat{p}=\bar{Y}_n$. I am trying to obtain the asymptotic distribution for this estimator specifically in the case where $p=\frac{1}{2}$. In the $p = \frac{1}{2}$ case, the first derivative is zero, hence we use the second order delta method: Suppose that $\sqrt{n}(T_n-\theta_0) \to_D Z$ and that we are interested in $g(T_n)$ where $g'(\theta_0) = 0$ but $g''$ is continuous and nonzero in a neighborhood of $\theta_0$. Then $\sqrt{n}(g(T_n)-g(\theta_0))$ has a degenerate limiting distribution, but: $$ $\sqrt{n}(g(T_n)-g(\theta_0)) \to_D \frac{g''(\theta_0)}{2}Z^2 $$ So, using this I have that for $p =\frac{1}{2}$, $g'(p) = 0$, but $g''(p) = -2 \neq 0$, so: $$ n\left(\hat{p}(1-\hat{p})-\frac{1}{4}\right) \to_D -\frac{1}{4}\chi^2_1 $$ I am wondering why this negative limit makes sense. I read in a footnote somewhere that this makes sense since $p(1-p)$ is maximized at $p=\frac{1}{2}$, but this doesn't really register with me. Can anyone help me here? thanks.",,"['probability', 'probability-theory', 'statistics']"
23,Interpreting a (function of) probability distribution as a random variable?,Interpreting a (function of) probability distribution as a random variable?,,"Consider, for example, Wikipedia's definition of the entropy of of a discrete random variable $X$ : $$H(X) = \mathbb{E}[I(X)] = \mathbb{E}[-ln(P(X))]$$ Here $\mathbb{E}$   is the expected value operator, and $I$ is the information content of   $X$. $I(X)$ is itself a random variable. Since $I(X)$ is a function of $P(X)$, the PMF $P(X)$ itself is considered to be a random variable that takes on the value $P(x)$ in the event $X=x$. Is my interpretation correct? A bit of a background: I see this kind of thing a lot in statistics problems dealing with KL divergence (e.g. in EM or variational inference where we often deal with $\mathbb{E}_{q(z)}[logp(z|\theta)]$), and I've always treated the expected value operator like a ""macro"" where I substitute $\mathbb{E}_{q(z)}[\cdot]$ with $\sum_z \cdot q(z)$ or $\int \cdot q(z) dz$ provided that the argument is some function of some random variable. I'm not sure if this treatment is correct, considering the formal definition of the ""expected value operator"".","Consider, for example, Wikipedia's definition of the entropy of of a discrete random variable $X$ : $$H(X) = \mathbb{E}[I(X)] = \mathbb{E}[-ln(P(X))]$$ Here $\mathbb{E}$   is the expected value operator, and $I$ is the information content of   $X$. $I(X)$ is itself a random variable. Since $I(X)$ is a function of $P(X)$, the PMF $P(X)$ itself is considered to be a random variable that takes on the value $P(x)$ in the event $X=x$. Is my interpretation correct? A bit of a background: I see this kind of thing a lot in statistics problems dealing with KL divergence (e.g. in EM or variational inference where we often deal with $\mathbb{E}_{q(z)}[logp(z|\theta)]$), and I've always treated the expected value operator like a ""macro"" where I substitute $\mathbb{E}_{q(z)}[\cdot]$ with $\sum_z \cdot q(z)$ or $\int \cdot q(z) dz$ provided that the argument is some function of some random variable. I'm not sure if this treatment is correct, considering the formal definition of the ""expected value operator"".",,"['probability', 'measure-theory', 'statistics', 'random-variables', 'entropy']"
24,Rock drawing possibility [closed],Rock drawing possibility [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question In the latest episode of Survivor there were 6 people and they had to draw rocks from a bag. In the bag were 6 rocks, 5 white rocks and 1 black rock.  First person drew a rock and kept it in his hand. Then the second person drew a rock. Last person took the only rock that left. Then they all showed what they got at the same time. Was the possibility to draw a black rock for each person 1/6 or what was it?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question In the latest episode of Survivor there were 6 people and they had to draw rocks from a bag. In the bag were 6 rocks, 5 white rocks and 1 black rock.  First person drew a rock and kept it in his hand. Then the second person drew a rock. Last person took the only rock that left. Then they all showed what they got at the same time. Was the possibility to draw a black rock for each person 1/6 or what was it?",,['statistics']
25,Existence of complete sufficient statistic,Existence of complete sufficient statistic,,"I'm trying to solve a problem in problem list of qualifying exam. Here is my problem : Let $X_1, \ldots, X_n$ be a random sample from a p.d.f $f(x,\theta) = \theta f_1(x) 1_{(-\infty,0)} + (1-\theta) f_2(x) 1_{(0,\infty)}$ where $f_1 \geq 0 , f_2 \geq 0$ and $\int_{-\infty}^0 f_1=0$,  $\int_0^\infty f_2=0.$ Prove or disprove that there exists a complete sufficient statistic for $\theta$. I'm trying to show that there is only one sufficient statistic $T(X_1, \ldots, X_n) =(X_1, \ldots, X_n)$ for $\theta$ and that such $T$ is not complete. But I cannot even show the uniqueness of such sufficient statistic. Anyone can help me?","I'm trying to solve a problem in problem list of qualifying exam. Here is my problem : Let $X_1, \ldots, X_n$ be a random sample from a p.d.f $f(x,\theta) = \theta f_1(x) 1_{(-\infty,0)} + (1-\theta) f_2(x) 1_{(0,\infty)}$ where $f_1 \geq 0 , f_2 \geq 0$ and $\int_{-\infty}^0 f_1=0$,  $\int_0^\infty f_2=0.$ Prove or disprove that there exists a complete sufficient statistic for $\theta$. I'm trying to show that there is only one sufficient statistic $T(X_1, \ldots, X_n) =(X_1, \ldots, X_n)$ for $\theta$ and that such $T$ is not complete. But I cannot even show the uniqueness of such sufficient statistic. Anyone can help me?",,['statistics']
26,Computing reverse percentile,Computing reverse percentile,,"I am actually looking for a way to indicate a certain point on an interpolated curve in a plot (see this question ), but judging by the amount of answers there, that's just not possible. So is there a way to compute the missing coordinate of that point? More formally: Given the 1st, 25th, 50th, 75th, 99th and 100th percentile of some data and a value y , how do I compute x s.t. y is the x-th percentile (i.e. s.t. (x, y) lies on the curve interpolated from the aforementioned percentiles)? If not, can I compute it if I have access to the data? example percentiles: 0.01    1.4 0.25    1.4 0.5     1.5 0.75    1.5 0.99    8.9 1   18907.4  mean:   8.0722091348 stdev: 220.0677459302","I am actually looking for a way to indicate a certain point on an interpolated curve in a plot (see this question ), but judging by the amount of answers there, that's just not possible. So is there a way to compute the missing coordinate of that point? More formally: Given the 1st, 25th, 50th, 75th, 99th and 100th percentile of some data and a value y , how do I compute x s.t. y is the x-th percentile (i.e. s.t. (x, y) lies on the curve interpolated from the aforementioned percentiles)? If not, can I compute it if I have access to the data? example percentiles: 0.01    1.4 0.25    1.4 0.5     1.5 0.75    1.5 0.99    8.9 1   18907.4  mean:   8.0722091348 stdev: 220.0677459302",,"['statistics', 'interpolation', 'percentile']"
27,Exponential distribution between two numbers,Exponential distribution between two numbers,,"I must calculate the probability : $P(43 < X < 63)$ How do we even calculate the probability between two numbers ? I have a formula for the situation when : $P(X > a)= e^{‐λa}$. Must I use the density function in this situation ? By the way, $λ =\dfrac{1}{25}$. My guess is that I'll have to do some substraction of areas but I'm not sure ....","I must calculate the probability : $P(43 < X < 63)$ How do we even calculate the probability between two numbers ? I have a formula for the situation when : $P(X > a)= e^{‐λa}$. Must I use the density function in this situation ? By the way, $λ =\dfrac{1}{25}$. My guess is that I'll have to do some substraction of areas but I'm not sure ....",,"['probability', 'statistics', 'random-variables', 'exponential-distribution']"
28,Marginal Density vs Probability Density,Marginal Density vs Probability Density,,"So for my weekly homework assignment for my probability class, there is a question that I am unsure about. Typically, a question usually begins with something along the lines of ""Suppose X and Y are random variables with joint density..."" and asks to find something along the lines of ""find the marginal density of X."" Now that's all fine and good; it's easy enough to do. What i'm confused about is a similar question that begins in a similar fashion, but instead asks ""find the probability density function of X."" My main concern is this: is there a difference between the marginal density and probability density? are they the same thing? It is confusing because the question still involves a joint density function of X and Y. If there is a need for clarification on my question let me know and i'll try to create an example that is not my exact homework problem because that wouldn't encourage my learning. Thanks!","So for my weekly homework assignment for my probability class, there is a question that I am unsure about. Typically, a question usually begins with something along the lines of ""Suppose X and Y are random variables with joint density..."" and asks to find something along the lines of ""find the marginal density of X."" Now that's all fine and good; it's easy enough to do. What i'm confused about is a similar question that begins in a similar fashion, but instead asks ""find the probability density function of X."" My main concern is this: is there a difference between the marginal density and probability density? are they the same thing? It is confusing because the question still involves a joint density function of X and Y. If there is a need for clarification on my question let me know and i'll try to create an example that is not my exact homework problem because that wouldn't encourage my learning. Thanks!",,"['probability', 'statistics', 'probability-distributions']"
29,"Finding the distribution of $Y$, the minimum of some IID random variables","Finding the distribution of , the minimum of some IID random variables",Y,"As I'm learning multivariate distributions and some special distributions such as gamma, chi-sqaure, I'm having a hard time understanding the concepts between the two questions i'm about to write. Following questions are from a textbook from hogg $Q_1$ : Let $X_1,X_2,X_3,X_4$ be four independent random variables, each with pdf    $$f(x) =\begin{cases} 3(1-x)^2, & 0 < x < 1,\\ 0,& \text{elsewhere}. \end{cases}$$   If $Y$ is the minimum of these four variables, find the cdf and the pdf of $Y$. Hint: $P(Y>y) = P(X_i > y, i=1,\dotsc,4)$. $Q_2$ : Let $X_1,X_2,X_3$ be iid random variables, each with pdf    $$f(x) =\begin{cases} e^{-x},& 0 < x < \infty,\\ 0, & \text{elsewhere}. \end{cases}.$$   Find the distribution of $Y = \min(X_1,X_2,X_3)$. Hint: $P(Y \le y) = 1 - P(Y>y) = 1 - P(X_i > y, i=1,2,3)$ From these two questions above, I don't quite understand how both question is asking for the minimum, yet their hints are totally opposite. Could someone explain this?","As I'm learning multivariate distributions and some special distributions such as gamma, chi-sqaure, I'm having a hard time understanding the concepts between the two questions i'm about to write. Following questions are from a textbook from hogg $Q_1$ : Let $X_1,X_2,X_3,X_4$ be four independent random variables, each with pdf    $$f(x) =\begin{cases} 3(1-x)^2, & 0 < x < 1,\\ 0,& \text{elsewhere}. \end{cases}$$   If $Y$ is the minimum of these four variables, find the cdf and the pdf of $Y$. Hint: $P(Y>y) = P(X_i > y, i=1,\dotsc,4)$. $Q_2$ : Let $X_1,X_2,X_3$ be iid random variables, each with pdf    $$f(x) =\begin{cases} e^{-x},& 0 < x < \infty,\\ 0, & \text{elsewhere}. \end{cases}.$$   Find the distribution of $Y = \min(X_1,X_2,X_3)$. Hint: $P(Y \le y) = 1 - P(Y>y) = 1 - P(X_i > y, i=1,2,3)$ From these two questions above, I don't quite understand how both question is asking for the minimum, yet their hints are totally opposite. Could someone explain this?",,"['probability', 'statistics', 'probability-distributions', 'order-statistics']"
30,Moment generating function of exponential family,Moment generating function of exponential family,,"How does one show, that the moment generating function of $T=(T_1, \ldots, T_k)$ of an natural parameterized $k-$ dimensional exponential family has the following form: $$ \psi(t) = E[exp(t^{\top}T)] = \dfrac{C(\theta_1, \ldots, \theta_k)}{C(\theta_1+t_1, \ldots, \theta_k+t_k)}$$ for $t=(t_1, \ldots, t_k) \in \mathbb{R}^k$.","How does one show, that the moment generating function of $T=(T_1, \ldots, T_k)$ of an natural parameterized $k-$ dimensional exponential family has the following form: $$ \psi(t) = E[exp(t^{\top}T)] = \dfrac{C(\theta_1, \ldots, \theta_k)}{C(\theta_1+t_1, \ldots, \theta_k+t_k)}$$ for $t=(t_1, \ldots, t_k) \in \mathbb{R}^k$.",,"['probability-theory', 'statistics', 'moment-generating-functions']"
31,Number of different possibilities including repeats,Number of different possibilities including repeats,,"so in one of my math classes, we're learning about counting and using this operation called ""n choose k"" $\binom{n}{k}=\frac{n!}{k!(n-k)!}$, however this operation does not account for the possibilities of repeats, and answers with repeating variables. An analogy would be that you want to buy a pizza with the following conditions: up to 3 toppings on each pizza 7 toppings to choose from The pizza toppings must be unique—double or triple toppings are not allowed. The arrangement of the toppings on each pizza does not matter; e.g., tomatoes on top of pepperoni is the same as pepperoni on top of tomatoes. What is the total number of possibilities for a pizza order in this deal? And we learned that the answer would be $x=\binom{7}{0} + \binom{7}{1} + \binom{7}{2}+\binom{7}{3}=64$. However, how would you find how many pizzas you could order with double or triple toppings.  So pretty much using this ""choose"" function, but allowing for those doubles and triples to come up in the count.  I tried this manually, by writing down all the possibilities and I found that the ""choose"" did not account for a pretty significant amount of doubles and triples. Ex: $\binom{7}{3}=35$, and when I drew out all the possibilities for lets say the 3 toppings were A, B, C, D, E, F, G.  I found there to be an extra 49 pizzas which could be accounted for (if there are repeated toppings, like AA, BB etc...). Another Ex: For $\binom{7}{2}=21$, if we draw the two by two table you can see that the diagonal is the only place where two of the same variables meet, and this ""choose"" function does not account for them. So essentially my question is, how do you account for these without doing what I did, by manually drawing out all the tables, and physically finding all the possibilities which can have 2 or 3 repeated values? Like is there a mathematical way of finding this? And to conclude from what I found then there would be a total of $64+49+7+7=127 $ ways to get a pizza with the 2nd condition.  The extra 7 I added in there is intuitively there can only be 7 pizzas which have the same toppings, like AAA, BBB, CCC, DDD, EEE, FFF, GGG.","so in one of my math classes, we're learning about counting and using this operation called ""n choose k"" $\binom{n}{k}=\frac{n!}{k!(n-k)!}$, however this operation does not account for the possibilities of repeats, and answers with repeating variables. An analogy would be that you want to buy a pizza with the following conditions: up to 3 toppings on each pizza 7 toppings to choose from The pizza toppings must be unique—double or triple toppings are not allowed. The arrangement of the toppings on each pizza does not matter; e.g., tomatoes on top of pepperoni is the same as pepperoni on top of tomatoes. What is the total number of possibilities for a pizza order in this deal? And we learned that the answer would be $x=\binom{7}{0} + \binom{7}{1} + \binom{7}{2}+\binom{7}{3}=64$. However, how would you find how many pizzas you could order with double or triple toppings.  So pretty much using this ""choose"" function, but allowing for those doubles and triples to come up in the count.  I tried this manually, by writing down all the possibilities and I found that the ""choose"" did not account for a pretty significant amount of doubles and triples. Ex: $\binom{7}{3}=35$, and when I drew out all the possibilities for lets say the 3 toppings were A, B, C, D, E, F, G.  I found there to be an extra 49 pizzas which could be accounted for (if there are repeated toppings, like AA, BB etc...). Another Ex: For $\binom{7}{2}=21$, if we draw the two by two table you can see that the diagonal is the only place where two of the same variables meet, and this ""choose"" function does not account for them. So essentially my question is, how do you account for these without doing what I did, by manually drawing out all the tables, and physically finding all the possibilities which can have 2 or 3 repeated values? Like is there a mathematical way of finding this? And to conclude from what I found then there would be a total of $64+49+7+7=127 $ ways to get a pizza with the 2nd condition.  The extra 7 I added in there is intuitively there can only be 7 pizzas which have the same toppings, like AAA, BBB, CCC, DDD, EEE, FFF, GGG.",,"['probability', 'combinatorics', 'statistics']"
32,Finding the lower bound using Chebyshev's theorem,Finding the lower bound using Chebyshev's theorem,,"If the probability density of $X$ is given by   $$f(x)= \begin{cases} 630x^4(1-x)^4&& \text{for } 0 <x<1\\   0 && \text{elsewhere.}\\ \end{cases}$$   Find the probability that it will take on a value within two standard deviations of the mean and compare this probability with the lower-bounded provided by Chebyshev's theorem. Let $\sigma$ be the standard deviation and $\mu$ be the mean. How does one find the variance? $\sigma^2$. I know one must use the formula $\sigma^2= \mu^{'}_{2}-\mu^{2}$ In order to solve this one must integrate. = $\int 630x^4(1-x)^4dx$ I cannot go any further than this as I do not know how to find the upper and lowerbounds. EDIT After doing some extensive math I figured out that $\mu = .5$ because $\mu = \int^{1}_{0} x\cdot630x^4(1-x)^4 dx = .5$ $\mu_{2} =\int_0^1 x^2\cdot630x^4(1-x)^4dx= \frac{3}{11}$ $\sigma^2= \mu_{2}-u^{2} = \frac{3}{11}-(\frac{1}{2})^2=.0227 \rightarrow \sqrt{.0227} =  .20 \text{ or } .15$ So $\int_{.20} 630x^4(1-x)^4$ Now in order to finish the problem we must find what the upperbound is and this where I am lost. Chebyshev’s Theorem If $\mu$ and $\sigma$ are the mean and the standard deviation of a random variable X, then for any positive constant k the probability is at least $1- \frac{1}{k^2}$ that X will take on a value within k standard deviations of the mean; symbolically $$P(|x-\mu|<k \sigma) \ge 1- \frac{1}{k^2}, \sigma \neq 0$$ Proof $$\sigma^2 = E[(X-\mu)^2] = \int^{\infty}_{-\infty} (x-\mu)^2f(x)dx$$ Diagram for Chebyshev’s theorem. Then dividing the integral into three parts as shown above $$\sigma^2 = \int^{\mu-k\sigma}_{-\infty} (x-\mu)^2f(x)dx+ \int^{\mu + k\sigma}_{\mu-k\sigma}(x-\mu)^2f(x)dx+\int^{\infty}_{\mu+k\sigma} (x-\mu)^2f(x)dx$$ Since the integrand $(x-\mu)^2f(x)$ is nonnegative we can from the inequality $$\sigma^2 \ge \int^{\mu-k\sigma}_{-\infty} (x-\mu)^2f(x)dx+\int^{\infty}_{\mu+k \sigma} (x-\mu)^2f(x)dx $$ by deleting the second integral. Therefore since $(x-\mu)^2 \ge k^2\sigma^2 \text{ for } x \le \mu -k\sigma \text{ or }  x \ge \mu+k\sigma \text{ it follows that }$ $$(\sigma)^2 \ge \int^{\mu-k\sigma}_{-\infty} k^2\sigma^2f(x)dx+\int^{\infty}_{\mu+k\sigma} k^2\sigma^2f(x)dx$$ and hence that $$\frac{1}{k^2} \ge \int^{\mu-k\sigma}_{-\infty} f(x)dx+ \int^{\infty}_{\mu+k\sigma}f(x)dx$$ provide $\sigma^2 \neq 0$ Since the sum of the two integrals on the right-hand side is the probability that X will take on a value less than or equal to $\mu-k\sigma$ or greater than or equal to $\mu+k\sigma$, we have thus shown that $$P(|X-\mu| \ge k\sigma) \le \frac{1}{k^2}$$ and it follows that $$P(|X-\mu| \lt k\sigma) \ge 1 - \frac{1}{k^2}$$","If the probability density of $X$ is given by   $$f(x)= \begin{cases} 630x^4(1-x)^4&& \text{for } 0 <x<1\\   0 && \text{elsewhere.}\\ \end{cases}$$   Find the probability that it will take on a value within two standard deviations of the mean and compare this probability with the lower-bounded provided by Chebyshev's theorem. Let $\sigma$ be the standard deviation and $\mu$ be the mean. How does one find the variance? $\sigma^2$. I know one must use the formula $\sigma^2= \mu^{'}_{2}-\mu^{2}$ In order to solve this one must integrate. = $\int 630x^4(1-x)^4dx$ I cannot go any further than this as I do not know how to find the upper and lowerbounds. EDIT After doing some extensive math I figured out that $\mu = .5$ because $\mu = \int^{1}_{0} x\cdot630x^4(1-x)^4 dx = .5$ $\mu_{2} =\int_0^1 x^2\cdot630x^4(1-x)^4dx= \frac{3}{11}$ $\sigma^2= \mu_{2}-u^{2} = \frac{3}{11}-(\frac{1}{2})^2=.0227 \rightarrow \sqrt{.0227} =  .20 \text{ or } .15$ So $\int_{.20} 630x^4(1-x)^4$ Now in order to finish the problem we must find what the upperbound is and this where I am lost. Chebyshev’s Theorem If $\mu$ and $\sigma$ are the mean and the standard deviation of a random variable X, then for any positive constant k the probability is at least $1- \frac{1}{k^2}$ that X will take on a value within k standard deviations of the mean; symbolically $$P(|x-\mu|<k \sigma) \ge 1- \frac{1}{k^2}, \sigma \neq 0$$ Proof $$\sigma^2 = E[(X-\mu)^2] = \int^{\infty}_{-\infty} (x-\mu)^2f(x)dx$$ Diagram for Chebyshev’s theorem. Then dividing the integral into three parts as shown above $$\sigma^2 = \int^{\mu-k\sigma}_{-\infty} (x-\mu)^2f(x)dx+ \int^{\mu + k\sigma}_{\mu-k\sigma}(x-\mu)^2f(x)dx+\int^{\infty}_{\mu+k\sigma} (x-\mu)^2f(x)dx$$ Since the integrand $(x-\mu)^2f(x)$ is nonnegative we can from the inequality $$\sigma^2 \ge \int^{\mu-k\sigma}_{-\infty} (x-\mu)^2f(x)dx+\int^{\infty}_{\mu+k \sigma} (x-\mu)^2f(x)dx $$ by deleting the second integral. Therefore since $(x-\mu)^2 \ge k^2\sigma^2 \text{ for } x \le \mu -k\sigma \text{ or }  x \ge \mu+k\sigma \text{ it follows that }$ $$(\sigma)^2 \ge \int^{\mu-k\sigma}_{-\infty} k^2\sigma^2f(x)dx+\int^{\infty}_{\mu+k\sigma} k^2\sigma^2f(x)dx$$ and hence that $$\frac{1}{k^2} \ge \int^{\mu-k\sigma}_{-\infty} f(x)dx+ \int^{\infty}_{\mu+k\sigma}f(x)dx$$ provide $\sigma^2 \neq 0$ Since the sum of the two integrals on the right-hand side is the probability that X will take on a value less than or equal to $\mu-k\sigma$ or greater than or equal to $\mu+k\sigma$, we have thus shown that $$P(|X-\mu| \ge k\sigma) \le \frac{1}{k^2}$$ and it follows that $$P(|X-\mu| \lt k\sigma) \ge 1 - \frac{1}{k^2}$$",,"['calculus', 'probability', 'integration', 'statistics']"
33,Ordinal vs nominal variables,Ordinal vs nominal variables,,"Im studying data analysis and Im with a doubt between nominal and ordinal variables, because sometimes it seems difficult to understand really what kind a variable is. For example, about nominal variables there is no meaningful rank between the categories, for example color of the eyes, or gender. And ordinal data where there is a meaningful rank between the categories, for example satisfaction with a service ""Very unsatisfied,..,..,.., very satisfied"". But this is always like this? For example if I have a varialble ""errortype"" that can have one of this values: (200,404,403,500) this is nominal right? But its strange, because there is some kind of meaningful rank, for example code 200 is better then 404, and so on. Other example is, If Im analysing a dataset to compare the performance of some servers and I have a variable server that can be one of this values (serverX, serverY, serverZ) and one server can have more capacity then oher, tihs is also nominal? Or because there is some kind of order, one server is better than other its ordinal?","Im studying data analysis and Im with a doubt between nominal and ordinal variables, because sometimes it seems difficult to understand really what kind a variable is. For example, about nominal variables there is no meaningful rank between the categories, for example color of the eyes, or gender. And ordinal data where there is a meaningful rank between the categories, for example satisfaction with a service ""Very unsatisfied,..,..,.., very satisfied"". But this is always like this? For example if I have a varialble ""errortype"" that can have one of this values: (200,404,403,500) this is nominal right? But its strange, because there is some kind of meaningful rank, for example code 200 is better then 404, and so on. Other example is, If Im analysing a dataset to compare the performance of some servers and I have a variable server that can be one of this values (serverX, serverY, serverZ) and one server can have more capacity then oher, tihs is also nominal? Or because there is some kind of order, one server is better than other its ordinal?",,['statistics']
34,Calculate present value of a continuous stream of payments with variable force of interest.,Calculate present value of a continuous stream of payments with variable force of interest.,,"The continuous rate of payments is $\rho(t)= \begin{cases}        0 & t< 1 \\       12 & 1\leq t\leq 2 \\       10+t & 2\leq x\leq 5 \\       15 & 5\leq t\leq 6 \\       0 & t>6    \end{cases}, $ and the force of interest is $\delta(t)= \begin{cases} 0.08 & t\leq 2 \\ \frac{1}{10+t} & 2<t\leq 5 \\ 0.06 & t>5 \end{cases} $. The question is: What is the present value of the payments at time, $t = 0$? I know that the present value is: $$\int_{0}^{T} \rho(s) e^{ -\int_0^s \delta(u) du} ds$$ However, I cannot figure out how to evaluate this integral using the two piecewise functions. The main problem is understanding which part of $\delta(t)$ function I should use in the exponent and how to integrate from $0$ to $s$ when we don't know what the value of $s$ is. Thanks for any help.","The continuous rate of payments is $\rho(t)= \begin{cases}        0 & t< 1 \\       12 & 1\leq t\leq 2 \\       10+t & 2\leq x\leq 5 \\       15 & 5\leq t\leq 6 \\       0 & t>6    \end{cases}, $ and the force of interest is $\delta(t)= \begin{cases} 0.08 & t\leq 2 \\ \frac{1}{10+t} & 2<t\leq 5 \\ 0.06 & t>5 \end{cases} $. The question is: What is the present value of the payments at time, $t = 0$? I know that the present value is: $$\int_{0}^{T} \rho(s) e^{ -\int_0^s \delta(u) du} ds$$ However, I cannot figure out how to evaluate this integral using the two piecewise functions. The main problem is understanding which part of $\delta(t)$ function I should use in the exponent and how to integrate from $0$ to $s$ when we don't know what the value of $s$ is. Thanks for any help.",,"['statistics', 'definite-integrals', 'finance', 'actuarial-science']"
35,How does smashing a statue impact the odds that an object is hidden in one of the other statues in a set?,How does smashing a statue impact the odds that an object is hidden in one of the other statues in a set?,,"The title is a bit confusing, I'm not sure of a better way to sum it up. Let's say there is a group of 5 statues and a missing jewel. There's a 50% chance that the jewel is hidden in one of the 5 statues. This should mean that there's a 10% chance it's in each individual statue. If you smash one statue and prove that the jewel is not hidden in the one you smashed, do the odds that the jewel is in each of the other statues increase, because there are only 4 left? Or do they decrease, because the jewel wasn't in the one you smashed?","The title is a bit confusing, I'm not sure of a better way to sum it up. Let's say there is a group of 5 statues and a missing jewel. There's a 50% chance that the jewel is hidden in one of the 5 statues. This should mean that there's a 10% chance it's in each individual statue. If you smash one statue and prove that the jewel is not hidden in the one you smashed, do the odds that the jewel is in each of the other statues increase, because there are only 4 left? Or do they decrease, because the jewel wasn't in the one you smashed?",,"['probability', 'statistics']"
36,Proof for why the conceptual and computation formulas for Sum of Squared Deviates formula are equivalent?,Proof for why the conceptual and computation formulas for Sum of Squared Deviates formula are equivalent?,,"The Sum of Squared Deviates has a conceptual formula of: $SS = ∑(Xi — Mx)^2$ (where $Mx$ is the sample mean) The corresponding computational formula is: $$SS = ∑Xi^2 —\frac{(∑Xi)^2}{N}$$ How are they algebraically equivalent? I cant seem to figure out (proof) how to convert from one to the other. Also, what is the point of having a ""computational formula"" if the mathematical result is the same?","The Sum of Squared Deviates has a conceptual formula of: $SS = ∑(Xi — Mx)^2$ (where $Mx$ is the sample mean) The corresponding computational formula is: $$SS = ∑Xi^2 —\frac{(∑Xi)^2}{N}$$ How are they algebraically equivalent? I cant seem to figure out (proof) how to convert from one to the other. Also, what is the point of having a ""computational formula"" if the mathematical result is the same?",,"['algebra-precalculus', 'statistics']"
37,"Determine the number of towers of the form $\varnothing \subseteq A \subseteq B \subseteq \{1, 2, 3, \ldots, n\}$",Determine the number of towers of the form,"\varnothing \subseteq A \subseteq B \subseteq \{1, 2, 3, \ldots, n\}","Determine the number of towers of the form  $\varnothing \subseteq  A \subseteq B \subseteq \{1, 2, 3, \ldots, n\}$. It is an exercise problem in Richard's Introductory combinatorics. My thought : There are $n$ Choose $k$ (length) subsets of $B$. Then, there are $2^k$ subsets $A$ of $B$. Thus, the total number of subsets is $\sum_k\binom{n}k\cdot 2^k$. Is this correct idea? Note that: there is no meaning to the word ""towers"" other than what is given: subsets empty contained in $A$ contained in $B$ contained in $\{1,2,\ldots,n\}$.","Determine the number of towers of the form  $\varnothing \subseteq  A \subseteq B \subseteq \{1, 2, 3, \ldots, n\}$. It is an exercise problem in Richard's Introductory combinatorics. My thought : There are $n$ Choose $k$ (length) subsets of $B$. Then, there are $2^k$ subsets $A$ of $B$. Thus, the total number of subsets is $\sum_k\binom{n}k\cdot 2^k$. Is this correct idea? Note that: there is no meaning to the word ""towers"" other than what is given: subsets empty contained in $A$ contained in $B$ contained in $\{1,2,\ldots,n\}$.",,"['probability', 'combinatorics', 'statistics']"
38,Expectation of a sample variance,Expectation of a sample variance,,"Let $Y_1$ and $Y_2$ be two independent realizations of the random variable $Y$ such that $E(Y_1)=E(Y_2)=E(Y)$ and $Var(Y_1)=Var(Y_2)=Var(Y)$. With $Y_1$ and $Y_2$ as our sample, the sample variance is written as $\sum (Y_i-\overline Y)^2$. I want to write the sample variance in terms of $Y_1$ and $Y_2$ only, is it correct to state that $\overline Y=E(Y_1)=E(Y_2)=E(Y)$ and then get as sample variance: $$[Y_1-E(Y_1)]^2+[Y_2-E(Y_2)]^2$$ If so, I am asked to show that $E(\text{sample variance})=Var(Y)$ but I am only able to show that it is equal to $2Var(Y)$.","Let $Y_1$ and $Y_2$ be two independent realizations of the random variable $Y$ such that $E(Y_1)=E(Y_2)=E(Y)$ and $Var(Y_1)=Var(Y_2)=Var(Y)$. With $Y_1$ and $Y_2$ as our sample, the sample variance is written as $\sum (Y_i-\overline Y)^2$. I want to write the sample variance in terms of $Y_1$ and $Y_2$ only, is it correct to state that $\overline Y=E(Y_1)=E(Y_2)=E(Y)$ and then get as sample variance: $$[Y_1-E(Y_1)]^2+[Y_2-E(Y_2)]^2$$ If so, I am asked to show that $E(\text{sample variance})=Var(Y)$ but I am only able to show that it is equal to $2Var(Y)$.",,"['statistics', 'random-variables', 'expectation', 'sampling', 'variance']"
39,Reference request: Strong Law of Large Numbers for V-statistics,Reference request: Strong Law of Large Numbers for V-statistics,,"I'm requesting a reference for a Strong Law of Large Numbers theorem for V-statistics (similar to Hoeffding's 1961 paper for U-statistics). That is, I am searching for an almost sure convergence theorem, saying $$ V_n = \frac{1}{n^k}\sum_{i_1=1}^n \cdots \sum_{i_k=1}^n h\left(X_{i_1},...,X_{i_k}\right) \stackrel{\mbox{a.s.}}{\longrightarrow}_n \quad? $$ where $(X_n)$ is an i.i.d. sequence of random elements with values in some space $\mathcal{X}$ and $h:\mathcal{X}^k \to \mathbb{R}$ is a symmetric kernel with some moment requirements. If Hoeffdings SSLN for U-statistics can be used to derive this result, an explanation of how this is done, would also more than suffice.","I'm requesting a reference for a Strong Law of Large Numbers theorem for V-statistics (similar to Hoeffding's 1961 paper for U-statistics). That is, I am searching for an almost sure convergence theorem, saying where is an i.i.d. sequence of random elements with values in some space and is a symmetric kernel with some moment requirements. If Hoeffdings SSLN for U-statistics can be used to derive this result, an explanation of how this is done, would also more than suffice.","
V_n = \frac{1}{n^k}\sum_{i_1=1}^n \cdots \sum_{i_k=1}^n h\left(X_{i_1},...,X_{i_k}\right) \stackrel{\mbox{a.s.}}{\longrightarrow}_n \quad?
 (X_n) \mathcal{X} h:\mathcal{X}^k \to \mathbb{R}","['probability-theory', 'statistics', 'reference-request', 'asymptotics', 'law-of-large-numbers']"
40,Testing hypothesis using Extra Sum of Squares (F-Test),Testing hypothesis using Extra Sum of Squares (F-Test),,The full model is given by $E(Y_i\mid x)=\beta_0+\beta_1 x_{i1}+\beta_2 x_{i2} + \beta_3 x_{i3}$ Test the hypothesis that $E(Y_i\mid x)=x_{i1}$ is a good model. I calculated the FULL Residual SS to be $RSS_{f}=0.765$ The Simple Residual SS is $RSS_s=1689.21$ Now I was to test that $\beta_0=\beta_2=\beta_3=0$ and $\beta_1=1$ My notes suggest to put it in the form $C\beta=d$ where $C$ is $c\times 4$ matrix. Then I can do an F-test: $$f=\frac{(RSS_s-RSS_f)/c}{RSS_f/(n-4)}$$ Can somebody help me with building the $C\beta=d$ part? What is the value of $c$ ? Intuitively I think it's $c=1$,The full model is given by Test the hypothesis that is a good model. I calculated the FULL Residual SS to be The Simple Residual SS is Now I was to test that and My notes suggest to put it in the form where is matrix. Then I can do an F-test: Can somebody help me with building the part? What is the value of ? Intuitively I think it's,E(Y_i\mid x)=\beta_0+\beta_1 x_{i1}+\beta_2 x_{i2} + \beta_3 x_{i3} E(Y_i\mid x)=x_{i1} RSS_{f}=0.765 RSS_s=1689.21 \beta_0=\beta_2=\beta_3=0 \beta_1=1 C\beta=d C c\times 4 f=\frac{(RSS_s-RSS_f)/c}{RSS_f/(n-4)} C\beta=d c c=1,"['statistics', 'regression', 'hypothesis-testing']"
41,chi squared additive property + subtraction property question,chi squared additive property + subtraction property question,,so I got questions a + b right but when I got to c I made a couple of mistakes. Can someone tell me how to do c? I thought I was doing it right but I got the degree of freedom wrong and the symbols. old answer:,so I got questions a + b right but when I got to c I made a couple of mistakes. Can someone tell me how to do c? I thought I was doing it right but I got the degree of freedom wrong and the symbols. old answer:,,['statistics']
42,"How to find Var($\bar{X}-\bar{Y}$) , the variance of the difference between the sample means?","How to find Var() , the variance of the difference between the sample means?",\bar{X}-\bar{Y},"So I tried to do this my own way but I'm not sure if it's correct. I used the equation for variance to get this answer, but I'm not sure if it matches up with what the answer is. Also to be honest, I'm not sure why I'm dividing by m+n? I just sort of guessed but I don't really get why. I thought I'd have to multiply by m and n, not divide. I'm guessing that's because you take out the constant when you calculate variance?","So I tried to do this my own way but I'm not sure if it's correct. I used the equation for variance to get this answer, but I'm not sure if it matches up with what the answer is. Also to be honest, I'm not sure why I'm dividing by m+n? I just sort of guessed but I don't really get why. I thought I'd have to multiply by m and n, not divide. I'm guessing that's because you take out the constant when you calculate variance?",,"['probability', 'statistics', 'random-variables']"
43,"what's the probability that in a building of 10 floors and 5 people in elevator, the elevator would reach exactly until the 5th floor and no higher?","what's the probability that in a building of 10 floors and 5 people in elevator, the elevator would reach exactly until the 5th floor and no higher?",,"the question goes like this: ""In a building of 10 floors, 5 people get inside an elevator on the entry floor. every one of them push independently a button of one of the 10 floors. what's the probability that the elevator would get exactly to the 5th floor and no higher?"" I thought of two ways to solve it, and each one gets me another result. so probably I do something wrong, would appreciate your help. first solution - let's choose the person that hits the 5th floor such that the elevator will reach this floor. $\binom{5}{1}$ options for that. for the rest, there're $5^4$ options to choose a floor. the probability space is $10^5$ for number of ways to choose floors (out of 10 floors) independently for 5 people. so the final result would be $\frac{\binom{5}{1} 5^4}{10^5}$ second solution - let's notice there're $5^5$ ways to hit buttons in elevator such that the elevator would get at the most to 5th floor, and $4^5$ ways to hit buttons in elevator such that the elevator would get at the most to 4th floor. so the number of ways the elevator would reach exactly the 5th floor is $5^5-4^5$ and then the result is $\frac{5^5-4^5}{10^5}$","the question goes like this: ""In a building of 10 floors, 5 people get inside an elevator on the entry floor. every one of them push independently a button of one of the 10 floors. what's the probability that the elevator would get exactly to the 5th floor and no higher?"" I thought of two ways to solve it, and each one gets me another result. so probably I do something wrong, would appreciate your help. first solution - let's choose the person that hits the 5th floor such that the elevator will reach this floor. $\binom{5}{1}$ options for that. for the rest, there're $5^4$ options to choose a floor. the probability space is $10^5$ for number of ways to choose floors (out of 10 floors) independently for 5 people. so the final result would be $\frac{\binom{5}{1} 5^4}{10^5}$ second solution - let's notice there're $5^5$ ways to hit buttons in elevator such that the elevator would get at the most to 5th floor, and $4^5$ ways to hit buttons in elevator such that the elevator would get at the most to 4th floor. so the number of ways the elevator would reach exactly the 5th floor is $5^5-4^5$ and then the result is $\frac{5^5-4^5}{10^5}$",,"['probability', 'combinatorics', 'statistics']"
44,Generating smooth function from a histogram.,Generating smooth function from a histogram.,,"I'm working in a census-like project, where most of our old data is stored with histograms, and this make some of the analysis we need to make difficult, so this problem arose: Given a histogram (a sequence $(x_1,...,x_N), x_i \in \Bbb Z$), generate a function $f: \Bbb R\to \Bbb R$ with $f(i)=x_i$, $f\in C^\infty$ and $f(\pm\infty)= 0$. Is this possible? It would be really helpful! Note: Interpolating polynomials are no good, as they diverge at infinity.","I'm working in a census-like project, where most of our old data is stored with histograms, and this make some of the analysis we need to make difficult, so this problem arose: Given a histogram (a sequence $(x_1,...,x_N), x_i \in \Bbb Z$), generate a function $f: \Bbb R\to \Bbb R$ with $f(i)=x_i$, $f\in C^\infty$ and $f(\pm\infty)= 0$. Is this possible? It would be really helpful! Note: Interpolating polynomials are no good, as they diverge at infinity.",,"['statistics', 'statistical-inference', 'descriptive-statistics']"
45,What distributions generate random unit vectors,What distributions generate random unit vectors,,"I was reading about generating random unit vectors for n-dimensional space. I read one method in which the person suggested that we can take n-random samples from standard normal distribution and if we normalize it then we will get a random vector. The reason he gave was that Gaussian distribution is spherically symmetric. Then I thought of another method , If we pick values from uniform distribution from  $-\infty$  to $+\infty$ and then also after normalizing it, We will get a random vector. Since,probability for each point to be getting selected is same then probability for each random vector will be also same. So ,I was wondering whether what I thought is correct or not? and also what are all distributions for which this will work and if normal distribution is the only distribution for which it will work then what is the reason behind it?","I was reading about generating random unit vectors for n-dimensional space. I read one method in which the person suggested that we can take n-random samples from standard normal distribution and if we normalize it then we will get a random vector. The reason he gave was that Gaussian distribution is spherically symmetric. Then I thought of another method , If we pick values from uniform distribution from  $-\infty$  to $+\infty$ and then also after normalizing it, We will get a random vector. Since,probability for each point to be getting selected is same then probability for each random vector will be also same. So ,I was wondering whether what I thought is correct or not? and also what are all distributions for which this will work and if normal distribution is the only distribution for which it will work then what is the reason behind it?",,"['probability', 'statistics', 'analytic-geometry']"
46,"How to Calculate: How many draws must I attempt, to get 90% of getting at least 1 of every 18 colour balls?","How to Calculate: How many draws must I attempt, to get 90% of getting at least 1 of every 18 colour balls?",,"this is beyond my Mathematical skill, I apologise.... and I seek your help. Say there are 18 differently-coloured balls in an urn. You can draw one ball each time, with replacement. The goal is to get at least one ball of every colour. (So getting more than once of the same colour is okay) I wish to calculate, how many drawings must I attempt, to get a 90% chance of getting at least one of each colour. Can anyone help me?","this is beyond my Mathematical skill, I apologise.... and I seek your help. Say there are 18 differently-coloured balls in an urn. You can draw one ball each time, with replacement. The goal is to get at least one ball of every colour. (So getting more than once of the same colour is okay) I wish to calculate, how many drawings must I attempt, to get a 90% chance of getting at least one of each colour. Can anyone help me?",,"['statistics', 'permutations', 'combinations', 'random', 'percentages']"
47,Show $y^Ty-n^{-1}(\sum y_i)^2=y^T(I-n^{-1}1_n1_n^T)y=\sum(y_i-\bar y)^2$?,Show ?,y^Ty-n^{-1}(\sum y_i)^2=y^T(I-n^{-1}1_n1_n^T)y=\sum(y_i-\bar y)^2,Here is the picture of my notes: How does $y^Ty-n^{-1}(\sum y_i)^2=\sum(y_i-\bar y)^2$? I can see that: $y^Ty-n^{-1}(\sum y_i)^2=y^T(I-n^{-1}1_n1_n^T)y$ I also see that $\frac{n}{n^2}(\sum y_i)^2=n\bar y^2$,Here is the picture of my notes: How does $y^Ty-n^{-1}(\sum y_i)^2=\sum(y_i-\bar y)^2$? I can see that: $y^Ty-n^{-1}(\sum y_i)^2=y^T(I-n^{-1}1_n1_n^T)y$ I also see that $\frac{n}{n^2}(\sum y_i)^2=n\bar y^2$,,"['statistics', 'least-squares', 'linear-regression']"
48,Correction factor for Hyperbolic Curve,Correction factor for Hyperbolic Curve,,"I have generated several data sets under varying experimental conditions, that are plotted as hyperbolic curves. I have two experiments that were done under identical conditions, but the curve is not the same. I'll call experiment A the ""ideal"". The equation for this line is: y=(435.6*S)/(0.333*S). In experiment B, I would expect the same result but instead the equation I get is: y=(390.1S)/(0.3176+S) I'd like to generate a correction factor to shift equation B to match equation A, and then apply that correction factor to other data sets within experiment B. Is this possible? How would I go about finding the correction factor?","I have generated several data sets under varying experimental conditions, that are plotted as hyperbolic curves. I have two experiments that were done under identical conditions, but the curve is not the same. I'll call experiment A the ""ideal"". The equation for this line is: y=(435.6*S)/(0.333*S). In experiment B, I would expect the same result but instead the equation I get is: y=(390.1S)/(0.3176+S) I'd like to generate a correction factor to shift equation B to match equation A, and then apply that correction factor to other data sets within experiment B. Is this possible? How would I go about finding the correction factor?",,"['statistics', 'curves']"
49,Bayesian approach to polling sample uncertainty,Bayesian approach to polling sample uncertainty,,"Suppose I have a three-way election between candidates A, B, and C, with 1,000,000 voters. A national poll on a fair sample of N=1000 yields the following breakdown, with a margin of error at ±3%: A - 50% B - 40% C - 10% Now suppose I pick a voter at random from the whole population, not necessarily the sample. What prior probabilities do I assign to that voter choosing A, B, or C? The reason I'm hung up here is that the prior probabilities given to the individual voter are related to the posterior probability distribution of the entire population after taking the sample - e.g. the population parameter. If we knew the exact population parameter, we'd know what prior probability distribution to assign to the individual voter - but we don't. Instead, we have a probability distribution of population parameters consistent with the sample, so we have a probability distribution of probability distributions to give to the voter. The way I'm doing it in my head is to create a massive joint probability distribution - one random variable is the population parameter, the other is the voter breakdown for each hypothetical population. Then, to figure out the overall prior probability I should assign to a random person in the population picking ""A"", ""B"", or ""C"", I just compute the marginal probabilities and call it a day. However, is this the right approach? These samples are usually done using the frequentist ""confidence interval"" approach to quantify error, whereas I'm thinking in Bayesian terms which uses ""credible intervals"" instead. Is there some frequentist/Bayesian subtlety here that can throw me off by mixing them?","Suppose I have a three-way election between candidates A, B, and C, with 1,000,000 voters. A national poll on a fair sample of N=1000 yields the following breakdown, with a margin of error at ±3%: A - 50% B - 40% C - 10% Now suppose I pick a voter at random from the whole population, not necessarily the sample. What prior probabilities do I assign to that voter choosing A, B, or C? The reason I'm hung up here is that the prior probabilities given to the individual voter are related to the posterior probability distribution of the entire population after taking the sample - e.g. the population parameter. If we knew the exact population parameter, we'd know what prior probability distribution to assign to the individual voter - but we don't. Instead, we have a probability distribution of population parameters consistent with the sample, so we have a probability distribution of probability distributions to give to the voter. The way I'm doing it in my head is to create a massive joint probability distribution - one random variable is the population parameter, the other is the voter breakdown for each hypothetical population. Then, to figure out the overall prior probability I should assign to a random person in the population picking ""A"", ""B"", or ""C"", I just compute the marginal probabilities and call it a day. However, is this the right approach? These samples are usually done using the frequentist ""confidence interval"" approach to quantify error, whereas I'm thinking in Bayesian terms which uses ""credible intervals"" instead. Is there some frequentist/Bayesian subtlety here that can throw me off by mixing them?",,"['probability', 'statistics', 'statistical-inference', 'bayesian']"
50,"Probability that $\operatorname{Erlang}(2,\mu _2)$ is greater than $\exp(\mu _1)$",Probability that  is greater than,"\operatorname{Erlang}(2,\mu _2) \exp(\mu _1)","I'm trying to work out that, given that $X\sim \exp(\mu_1)$ and $Y\sim \operatorname{Erlang}(2,\mu _2)$, what is $\mathbb{P}(X<Y)$? So far I have: $$\mathbb{P}(X<Y)=\int_0^{\infty}\mathbb{P}(X<t \mid Y\in dt)\mathbb{P}(Y \in dt)$$ $$=\int_0^{\infty}(1-e^{-\mu _1t}){\mu _2}^2te^{-\mu _2t}dt$$ I can do this integral, but it looks like it will be a great big mess. Am I on the right track?","I'm trying to work out that, given that $X\sim \exp(\mu_1)$ and $Y\sim \operatorname{Erlang}(2,\mu _2)$, what is $\mathbb{P}(X<Y)$? So far I have: $$\mathbb{P}(X<Y)=\int_0^{\infty}\mathbb{P}(X<t \mid Y\in dt)\mathbb{P}(Y \in dt)$$ $$=\int_0^{\infty}(1-e^{-\mu _1t}){\mu _2}^2te^{-\mu _2t}dt$$ I can do this integral, but it looks like it will be a great big mess. Am I on the right track?",,"['probability', 'statistics', 'gamma-distribution']"
51,Extension of Likelihood-density,Extension of Likelihood-density,,"Given an observation scheme, say $(X_1,X_2,\ldots,X_n)$ where $X_i$ evolves to one measure, one can define the likelihood function, a parameter dependend density of the form $$ L_n:=L(X_1,\ldots,X_n\mid\theta) $$ This is a density wrt to a  measure say $P^n$. Thus there exists a measure e $Q^n$, such that $L_n$ is the radon-nikodym-derivative. However, for assumptions about consistency of an estimator one lets $n\rightarrow \infty$ can we expect a measure $Q^{\infty}?$","Given an observation scheme, say $(X_1,X_2,\ldots,X_n)$ where $X_i$ evolves to one measure, one can define the likelihood function, a parameter dependend density of the form $$ L_n:=L(X_1,\ldots,X_n\mid\theta) $$ This is a density wrt to a  measure say $P^n$. Thus there exists a measure e $Q^n$, such that $L_n$ is the radon-nikodym-derivative. However, for assumptions about consistency of an estimator one lets $n\rightarrow \infty$ can we expect a measure $Q^{\infty}?$",,"['probability', 'probability-theory', 'statistics', 'stochastic-processes', 'statistical-inference']"
52,Jointly normal and correlated normal random variables,Jointly normal and correlated normal random variables,,"Is is true that if two normal random variables are correlated, then they are jointly normally distributed? I am not sure how to prove or disprove it.","Is is true that if two normal random variables are correlated, then they are jointly normally distributed? I am not sure how to prove or disprove it.",,"['statistics', 'normal-distribution']"
53,Probability to see all 6 numbers on a die after n throws,Probability to see all 6 numbers on a die after n throws,,"I am trying to work out the probability of seeing all 6 numbers on a fair die at least once after n throws, where n > 6. So I found a related question: Probability of rolling a dice 8 times before all numbers are shown. and a part of the provided answer seems to work for n = 7, but the problem I have is I don't know how to generalize this to work with all n > 6. Would be nice if someone could explain the general approach to such a problem.","I am trying to work out the probability of seeing all 6 numbers on a fair die at least once after n throws, where n > 6. So I found a related question: Probability of rolling a dice 8 times before all numbers are shown. and a part of the provided answer seems to work for n = 7, but the problem I have is I don't know how to generalize this to work with all n > 6. Would be nice if someone could explain the general approach to such a problem.",,['statistics']
54,OLS under Mean Independence,OLS under Mean Independence,,"Assume mean independence of the error term. Show that the OLS estimator is unbiased. Hint: use the Law of Iterated Expectations I am not quite sure if I understood the concept of 'mean independence'. So we have that $\mathbb{E}[\varepsilon \mid X]=0$. My proof would be as follows: $$\hat{\beta}=(X^TX)^{-1}X^Ty$$$$=(X^TX)^{-1}X^T(X\beta+\varepsilon )$$ $$=(X^TX)^{-1}X^TX\beta+(X^TX)^{-1}X^T\varepsilon $$ $$=\beta+(X^TX)^{-1}X^T\varepsilon$$ $$\implies\mathbb{E}[\hat{\beta}]=\beta+\mathbb{E}[(X^TX)^{-1}X^T\varepsilon]$$ $$=\beta+\mathbb{E}[(X^TX)^{-1}X^T]\mathbb{E}[\varepsilon]$$ $$=\beta$$ My problem is whether I can write $\mathbb{E}[(X^TX)^{-1}X^T\varepsilon]=\mathbb{E}[(X^TX)^{-1}X^T]\mathbb{E}[\varepsilon]$. My intuition says yes, because mean independence implies zero covariance and hence we can write the expectation as a product. However, I haven't used the LIE. Could anyone help me here?","Assume mean independence of the error term. Show that the OLS estimator is unbiased. Hint: use the Law of Iterated Expectations I am not quite sure if I understood the concept of 'mean independence'. So we have that $\mathbb{E}[\varepsilon \mid X]=0$. My proof would be as follows: $$\hat{\beta}=(X^TX)^{-1}X^Ty$$$$=(X^TX)^{-1}X^T(X\beta+\varepsilon )$$ $$=(X^TX)^{-1}X^TX\beta+(X^TX)^{-1}X^T\varepsilon $$ $$=\beta+(X^TX)^{-1}X^T\varepsilon$$ $$\implies\mathbb{E}[\hat{\beta}]=\beta+\mathbb{E}[(X^TX)^{-1}X^T\varepsilon]$$ $$=\beta+\mathbb{E}[(X^TX)^{-1}X^T]\mathbb{E}[\varepsilon]$$ $$=\beta$$ My problem is whether I can write $\mathbb{E}[(X^TX)^{-1}X^T\varepsilon]=\mathbb{E}[(X^TX)^{-1}X^T]\mathbb{E}[\varepsilon]$. My intuition says yes, because mean independence implies zero covariance and hence we can write the expectation as a product. However, I haven't used the LIE. Could anyone help me here?",,"['probability', 'statistics']"
55,"Find $E(Y)$ and $Var(Y)$ of $\log Y \sim N (\mu,\sigma^2)$",Find  and  of,"E(Y) Var(Y) \log Y \sim N (\mu,\sigma^2)","Find $E(Y)$ and $Var(Y)$ of $\log Y \sim N (\mu,\sigma^2)$ I tried solving this in 2 different ways. The second way is what I am stuck on: 1st Way: Let $Y=e^X$ where $X \sim N (\mu,\sigma^2)$. Then $X=\mu+\sigma Z$ $$E(e^{tZ})=\int e^{tz}\frac{1}{\sqrt{2\pi \sigma^2}}\exp{\frac{-z^2}{2}}dz$$ $$=\int \frac{1}{\sqrt{2\pi \sigma^2}}\exp({\frac{-z^2+2tz-t^2}{2}+t^2/2)}dz$$ $$=e^{t^2/2}$$ Hence $$E(e^X)=E(e^{\mu+\sigma Z})=e^\mu E(e^{\sigma Z})=e^\mu e^{\sigma^2/2}$$ and $$E(e^{2X})=E(e^{2\mu+2\sigma Z})=e^{2\mu} E(e^{2\sigma Z})=e^{2\mu} e^{2\sigma^2}$$ However. The second way: I begin by writing the pdf of $\log Y$: Let $f(x)$ be the pdf of a normally distributed variable with $(\mu,\sigma ^2)$ $$P(Y<y)=P(\log Y<\log y)=P(X< \log y)=\int_{-\infty}^{\log y}f(x)dx$$ Hence the pdf of $Y$ is $$d/dy \int_{-\infty}^{\log y}f(x)dx=\frac{f(\log y)}{y}$$ Now to find the $E(Y)$ I simply need to integrate: $$E(Y)=\int \frac{f(\log y)}{y} \times y dy$$ Can anyone help me solve this integral? And also $$E(Y^2)=\int \frac{f(\log y)}{y} \times y^2 dy$$","Find $E(Y)$ and $Var(Y)$ of $\log Y \sim N (\mu,\sigma^2)$ I tried solving this in 2 different ways. The second way is what I am stuck on: 1st Way: Let $Y=e^X$ where $X \sim N (\mu,\sigma^2)$. Then $X=\mu+\sigma Z$ $$E(e^{tZ})=\int e^{tz}\frac{1}{\sqrt{2\pi \sigma^2}}\exp{\frac{-z^2}{2}}dz$$ $$=\int \frac{1}{\sqrt{2\pi \sigma^2}}\exp({\frac{-z^2+2tz-t^2}{2}+t^2/2)}dz$$ $$=e^{t^2/2}$$ Hence $$E(e^X)=E(e^{\mu+\sigma Z})=e^\mu E(e^{\sigma Z})=e^\mu e^{\sigma^2/2}$$ and $$E(e^{2X})=E(e^{2\mu+2\sigma Z})=e^{2\mu} E(e^{2\sigma Z})=e^{2\mu} e^{2\sigma^2}$$ However. The second way: I begin by writing the pdf of $\log Y$: Let $f(x)$ be the pdf of a normally distributed variable with $(\mu,\sigma ^2)$ $$P(Y<y)=P(\log Y<\log y)=P(X< \log y)=\int_{-\infty}^{\log y}f(x)dx$$ Hence the pdf of $Y$ is $$d/dy \int_{-\infty}^{\log y}f(x)dx=\frac{f(\log y)}{y}$$ Now to find the $E(Y)$ I simply need to integrate: $$E(Y)=\int \frac{f(\log y)}{y} \times y dy$$ Can anyone help me solve this integral? And also $$E(Y^2)=\int \frac{f(\log y)}{y} \times y^2 dy$$",,"['probability', 'statistics', 'normal-distribution', 'density-function']"
56,Calculating variance for a window of samples which already contains pre-calculated variances,Calculating variance for a window of samples which already contains pre-calculated variances,,"In a previous answer , the following solution was given for calculating the variance from a stream of sample values (from Knuth via John D. Cook ): $$ \begin{align*} m_k&=m_{k-1}+\frac{x_k-m_{k-1}}k \\ v_k&=v_{k-1}+(x_k-m_{k-1})(x_k-m_k) \end{align*} $$ with variance $$\sigma^2=\frac{v_k}{k-1}$$ If we kept track of $m_k$, $v_k$, and $\sigma^2$ for each sample, then could we easily compute the variance for a given window of samples between $i$ and $i+j$ with a simple manipulation of those saved values?","In a previous answer , the following solution was given for calculating the variance from a stream of sample values (from Knuth via John D. Cook ): $$ \begin{align*} m_k&=m_{k-1}+\frac{x_k-m_{k-1}}k \\ v_k&=v_{k-1}+(x_k-m_{k-1})(x_k-m_k) \end{align*} $$ with variance $$\sigma^2=\frac{v_k}{k-1}$$ If we kept track of $m_k$, $v_k$, and $\sigma^2$ for each sample, then could we easily compute the variance for a given window of samples between $i$ and $i+j$ with a simple manipulation of those saved values?",,"['statistics', 'algorithms', 'variance']"
57,Distribution of the minimum,Distribution of the minimum,,"I have the following problem, given a random variable $X$ with density $$f(x)=2x\text{ for }x\in(0,1)$$ and a r.s.s. $X_1, X_2, X_3$. I have to calculate the probability that $X_{(1)}=\min\{X_1,X_2,X_3\}$ exceeds the median $M$. Previously I have computed the distribution of $X_{(1)}$, so I get this $$P(X_{(1)}>M)=1-F_{X_{(1)}}(M)=(1-F(M))^3=\frac{1}{8}$$ since by definition $F(M)=\frac{1}{2}$. The thing that makes me doubt about my result is that I haven't used the density of $f$ at all, does that mean this is true for every random variable, or am I missing something?","I have the following problem, given a random variable $X$ with density $$f(x)=2x\text{ for }x\in(0,1)$$ and a r.s.s. $X_1, X_2, X_3$. I have to calculate the probability that $X_{(1)}=\min\{X_1,X_2,X_3\}$ exceeds the median $M$. Previously I have computed the distribution of $X_{(1)}$, so I get this $$P(X_{(1)}>M)=1-F_{X_{(1)}}(M)=(1-F(M))^3=\frac{1}{8}$$ since by definition $F(M)=\frac{1}{2}$. The thing that makes me doubt about my result is that I haven't used the density of $f$ at all, does that mean this is true for every random variable, or am I missing something?",,"['statistics', 'probability-distributions', 'random-variables']"
58,Proof by contradidction that the mean of a set cannot be greater than the greatest value in that set.,Proof by contradidction that the mean of a set cannot be greater than the greatest value in that set.,,"I want to prove that given a set of values $x_1, x_2, ..., x_n$, the mean of those values cannot be greater than the greatest of those values. Let the mean $\frac{x_1 + x_2 +... + x_n}{n} = a$ Assume that $a > x_1, x_2, ..., x_n$ and let $x_1 + x_2 +... + x_n = b$ Then $b < a \cdot n$ Therefore $\frac{b}{n} < \frac{a \cdot n}{n}$, so that $\frac{b}{n} < a$ But since by definition $\frac{b}{n} = a$, this is a contradction. QED(?)","I want to prove that given a set of values $x_1, x_2, ..., x_n$, the mean of those values cannot be greater than the greatest of those values. Let the mean $\frac{x_1 + x_2 +... + x_n}{n} = a$ Assume that $a > x_1, x_2, ..., x_n$ and let $x_1 + x_2 +... + x_n = b$ Then $b < a \cdot n$ Therefore $\frac{b}{n} < \frac{a \cdot n}{n}$, so that $\frac{b}{n} < a$ But since by definition $\frac{b}{n} = a$, this is a contradction. QED(?)",,"['statistics', 'proof-verification', 'means']"
59,Notation for minimum,Notation for minimum,,"I'm reading Huber's Robust Statistics right now, and at the beginning of Chapter 3, he writes the following notation: $$\sum \rho(x_i;T_n) = \min!$$ Similarly, a few lines down, he writes: $$\sum \rho(x_i - T_n) = \min!$$ Can someone help me understand what this $\min!$ notation means? Thanks!","I'm reading Huber's Robust Statistics right now, and at the beginning of Chapter 3, he writes the following notation: $$\sum \rho(x_i;T_n) = \min!$$ Similarly, a few lines down, he writes: $$\sum \rho(x_i - T_n) = \min!$$ Can someone help me understand what this $\min!$ notation means? Thanks!",,"['statistics', 'notation', 'robust-statistics']"
60,Probability that n-digit number is divisible by some number(s)?,Probability that n-digit number is divisible by some number(s)?,,"I have came across a number of problems in our probability course that deal with this kind of question. And for two digit numbers I have always ""brute-forced"" the solution by writing them all out and dividing each. For three digit numbers this is too exhaustive. What is the correct way to approach this kind problem? Examples: What is the probability of three digit number being divisible by 3 or 13? What is the probability of three digit number being divisible by 9 or 11?","I have came across a number of problems in our probability course that deal with this kind of question. And for two digit numbers I have always ""brute-forced"" the solution by writing them all out and dividing each. For three digit numbers this is too exhaustive. What is the correct way to approach this kind problem? Examples: What is the probability of three digit number being divisible by 3 or 13? What is the probability of three digit number being divisible by 9 or 11?",,"['probability', 'combinatorics', 'statistics']"
61,Trying to find the MLE of $\tau$,Trying to find the MLE of,\tau,"Let $\tau = \int x \,dF(x),$ and I want to find the MLE of $\tau$ given $X_1,\ldots,X_n \sim \mathrm{Uniform}(a,b).$ I am not entirely sure, but I would imagine that $\tau = \int x \, dF(x) = \int_a^b x \,dx = \left. \frac{1}{2}x^2 \right|_a^b = \frac{1}{2}(a^2+b^2).$ This, by equivariance of estimators, suggests to me that $$\hat{\tau} = \frac{1}{2}(\hat{a}^2 + \hat{b}^2),$$ and thus this problem comes down to finding the MLEs $\hat{a}$ and $\hat{b}.$ I can take the likelihood of seeing that data as $$L(X^n,a,b) = \prod_{i=1}^n f(x_i \mid  a,b) = \prod_{i=1}^n \frac{1}{b-a} = \left(\frac{1}{b-a}\right)^n$$ $$\implies \log(L(X^n,a,b)) = -n\log(b-a).$$ However, I am having issues solving for the MLEs of $b$ and $a$ given their dependence on each other in this problem. Any suggestions on how to fix this?","Let $\tau = \int x \,dF(x),$ and I want to find the MLE of $\tau$ given $X_1,\ldots,X_n \sim \mathrm{Uniform}(a,b).$ I am not entirely sure, but I would imagine that $\tau = \int x \, dF(x) = \int_a^b x \,dx = \left. \frac{1}{2}x^2 \right|_a^b = \frac{1}{2}(a^2+b^2).$ This, by equivariance of estimators, suggests to me that $$\hat{\tau} = \frac{1}{2}(\hat{a}^2 + \hat{b}^2),$$ and thus this problem comes down to finding the MLEs $\hat{a}$ and $\hat{b}.$ I can take the likelihood of seeing that data as $$L(X^n,a,b) = \prod_{i=1}^n f(x_i \mid  a,b) = \prod_{i=1}^n \frac{1}{b-a} = \left(\frac{1}{b-a}\right)^n$$ $$\implies \log(L(X^n,a,b)) = -n\log(b-a).$$ However, I am having issues solving for the MLEs of $b$ and $a$ given their dependence on each other in this problem. Any suggestions on how to fix this?",,"['statistics', 'parameter-estimation']"
62,Significance of Convex Sets for I-Projection,Significance of Convex Sets for I-Projection,,"I have been reviewing the literature on information theoretic methods in statistics, and in particular, the method of I-projections . Given a discrete, finite alphabet $\mathcal{X}$, let $\prod$ denote a set of probability mass functions (pmfs) on $\mathcal{X}$. Suppose $Q$ is a pmf on $\mathcal{X}$ which does not belong to $\prod$. The I-projection of $Q$ on $\prod$ is defined as the element $P^{*}\in \prod$ such that \begin{eqnarray}P^{*}=\arg \min \limits_{P\in \prod} D(P||Q),\end{eqnarray} where $D(P||Q)$ denotes the Kullback-Leibler divergence (KL-divergence) between pmfs $P$ and $Q$, defined as \begin{eqnarray}D(P||Q)=\sum\limits_{x\in \mathcal{X}} P(x)\log\left(\frac{P(x)}{Q(x)}\right).\end{eqnarray} A sufficient condition for the existence of a $P^{*}$ as above requires $\prod$ to be closed. In addition, in the literature, $\prod$ is considered to be a convex set. For example, the family \begin{eqnarray} \mathcal{P}=\lbrace P: \sum\limits_{x\in \mathcal{X}} P(x)f_{i}(x)=\alpha_{i}, ~1\leq i\leq k\rbrace, \end{eqnarray} where $f_{i}:\mathcal{X}\rightarrow \mathbb{R}$ are measurable functions and $\alpha_{i}\in \mathbb{R}$, called a linear family of pmfs, is typically considered in place of $\prod$ in the literature. Question: Can someone please explain the significance of using convex sets? Do things fail if we do not consider convex sets?","I have been reviewing the literature on information theoretic methods in statistics, and in particular, the method of I-projections . Given a discrete, finite alphabet $\mathcal{X}$, let $\prod$ denote a set of probability mass functions (pmfs) on $\mathcal{X}$. Suppose $Q$ is a pmf on $\mathcal{X}$ which does not belong to $\prod$. The I-projection of $Q$ on $\prod$ is defined as the element $P^{*}\in \prod$ such that \begin{eqnarray}P^{*}=\arg \min \limits_{P\in \prod} D(P||Q),\end{eqnarray} where $D(P||Q)$ denotes the Kullback-Leibler divergence (KL-divergence) between pmfs $P$ and $Q$, defined as \begin{eqnarray}D(P||Q)=\sum\limits_{x\in \mathcal{X}} P(x)\log\left(\frac{P(x)}{Q(x)}\right).\end{eqnarray} A sufficient condition for the existence of a $P^{*}$ as above requires $\prod$ to be closed. In addition, in the literature, $\prod$ is considered to be a convex set. For example, the family \begin{eqnarray} \mathcal{P}=\lbrace P: \sum\limits_{x\in \mathcal{X}} P(x)f_{i}(x)=\alpha_{i}, ~1\leq i\leq k\rbrace, \end{eqnarray} where $f_{i}:\mathcal{X}\rightarrow \mathbb{R}$ are measurable functions and $\alpha_{i}\in \mathbb{R}$, called a linear family of pmfs, is typically considered in place of $\prod$ in the literature. Question: Can someone please explain the significance of using convex sets? Do things fail if we do not consider convex sets?",,"['statistics', 'information-theory']"
63,Product of two uniform random variables/ expectation of the products,Product of two uniform random variables/ expectation of the products,,"Suppose I want the expectation, $E\Phi(X-\mu)\Phi(\mu-X)$, where $\Phi(.)$ represents the Normal CDF, and X is $Normal(\beta,1)$. Consequently $\Phi(.)$'s are uniform[0,1] and at the same time two uniforms are negatively correlated (antithetic variables). Let, $E\Phi(X-\mu)\Phi(\mu-X)=EU(1-U)=EUV$, which is basically a product of two uniforms. Now if I use the cdfs as uniformly distributed and find the expectation based on uniform distribution, i.e., finding distribution of UV and use that to compute $EUV$, I loose information about $\beta$. Does anyone have any idea how to get the expectation without loosing any information about $\beta$? Thank you","Suppose I want the expectation, $E\Phi(X-\mu)\Phi(\mu-X)$, where $\Phi(.)$ represents the Normal CDF, and X is $Normal(\beta,1)$. Consequently $\Phi(.)$'s are uniform[0,1] and at the same time two uniforms are negatively correlated (antithetic variables). Let, $E\Phi(X-\mu)\Phi(\mu-X)=EU(1-U)=EUV$, which is basically a product of two uniforms. Now if I use the cdfs as uniformly distributed and find the expectation based on uniform distribution, i.e., finding distribution of UV and use that to compute $EUV$, I loose information about $\beta$. Does anyone have any idea how to get the expectation without loosing any information about $\beta$? Thank you",,"['calculus', 'statistics', 'multivariable-calculus', 'discrete-mathematics', 'statistical-inference']"
64,Question on Probability. What is my Z-Score 20?,Question on Probability. What is my Z-Score 20?,,"I have this homework but I am getting a z-score of 20?  Why?  Is my calculation wrong? The question is Without assuming that the diameters of apple pies are distributed according to the normal distributions, estimated the probability that the mean diameter is larger than 32 cm.  The sample standard deviation is estimated to be 2.  The sample mean is 28 and the sample size is 100. When I used CLT (because the sample size is >30).  I am getting a z score of 20?  Is this correct?","I have this homework but I am getting a z-score of 20?  Why?  Is my calculation wrong? The question is Without assuming that the diameters of apple pies are distributed according to the normal distributions, estimated the probability that the mean diameter is larger than 32 cm.  The sample standard deviation is estimated to be 2.  The sample mean is 28 and the sample size is 100. When I used CLT (because the sample size is >30).  I am getting a z score of 20?  Is this correct?",,"['probability', 'statistics', 'central-limit-theorem']"
65,Is covariance preserved under transformation?,Is covariance preserved under transformation?,,"Let $X_1,X_2$ be normally distributed random variables with $\rho = 0.5$, mean equal to $0$ and variance equal to $1$. Let $U_i = \Phi(X_i)$ where $\Phi$ is the marginal distribution of $X_1,X_2$. We know that $U_1$ and $U_2$ are then correlated. Is it true that $E[U_1 U_2] = 0.5$? I am just curious I've been looking at various books but can't find anything related to this. I just happened to think of this as I was about to simulate correlated random variables for an experiment.","Let $X_1,X_2$ be normally distributed random variables with $\rho = 0.5$, mean equal to $0$ and variance equal to $1$. Let $U_i = \Phi(X_i)$ where $\Phi$ is the marginal distribution of $X_1,X_2$. We know that $U_1$ and $U_2$ are then correlated. Is it true that $E[U_1 U_2] = 0.5$? I am just curious I've been looking at various books but can't find anything related to this. I just happened to think of this as I was about to simulate correlated random variables for an experiment.",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
66,covariance of random variables,covariance of random variables,,"Suppose X, Y, W are independent random variables such that X ∼ GAM(2,3), Y ∼ N(1,4) and W ∼ BIN(10,1/4). Let U = 2X − 3Y and V = Y − W . Find cov(U, V ). I know that cov(U, V) = E(U, V) - E(U)E(V). I've found E(U) and E(V) but I don't know how to find E(U, V).","Suppose X, Y, W are independent random variables such that X ∼ GAM(2,3), Y ∼ N(1,4) and W ∼ BIN(10,1/4). Let U = 2X − 3Y and V = Y − W . Find cov(U, V ). I know that cov(U, V) = E(U, V) - E(U)E(V). I've found E(U) and E(V) but I don't know how to find E(U, V).",,"['probability', 'statistics', 'covariance']"
67,Confidence Itervals; $Z_{\alpha}$ & $Z_{\alpha/2}$,Confidence Itervals;  &,Z_{\alpha} Z_{\alpha/2},"I'm confused about what exactly $Z_{\alpha}$ is, does there exist a formula for it in terms of $\alpha$? IF so, is there also one for $Z_{\alpha/2}$?","I'm confused about what exactly $Z_{\alpha}$ is, does there exist a formula for it in terms of $\alpha$? IF so, is there also one for $Z_{\alpha/2}$?",,"['statistics', 'normal-distribution', 'confidence-interval']"
68,How to show some random variables are multivariate normal?,How to show some random variables are multivariate normal?,,"I've got several series of random data, which can be denoted as x1,x2,...,xn. How do I show that they are subjected to multivariate normal distribution? I refered to statistics textbooks but only got definations and properties. Do I have to estimate their density functions? Or is there any other necessary conditions? Thanks in advance!","I've got several series of random data, which can be denoted as x1,x2,...,xn. How do I show that they are subjected to multivariate normal distribution? I refered to statistics textbooks but only got definations and properties. Do I have to estimate their density functions? Or is there any other necessary conditions? Thanks in advance!",,['statistics']
69,What is the domain and range of the sum of two random variables?,What is the domain and range of the sum of two random variables?,,"Let $(\Omega, \mathcal{F}, P)$ be  a probability space s.t. $\Omega = \{0,1\}$. Let $X_1: \Omega \rightarrow \{0,1\}$, $X_2: \Omega \rightarrow \{0,1\}$ be two random variables over $\Omega$ (i.e., we're in the context of a Bernouli trial with, say, a coin flip). In fact, we can let $X_1$ and $X_2$ be $id$ in this context. We can suppose further that they are $i.i.d.$ Question: When people write $X_1 + X_2$, what do they mean? In particular, what is the domain and range of $X_1 + X_2$? I'm assuming that its probability distribution forms a convolution of $X_1$ and $X_2$. As I see it, the options for the domain and range are as follows: $X_1 +X_2$ is a function from $\Omega = \{0, 1\}$ to $\{0, 2\}$ s.t. $(X_1 + X_2)(0) = 0 + 0 = 0$ and $X_1 \rightarrow X_2(1) = 1 + 1 = 0$. $X_1 + X_2$ is a function from $\{(0,0), (0,1), (1,0), (1,1)\}$ to $\{0, 1, 2\}$ s.t. $(X_1 + X_2)(i,k) = i + k$. Notice how in (2) the domain of $X_1 + X_2$ is no longer equal to the domain of $X_1$ and $X_2$. So, with those options laid out, is $X_1 + X_2$ (1), (2), or something else entirely?","Let $(\Omega, \mathcal{F}, P)$ be  a probability space s.t. $\Omega = \{0,1\}$. Let $X_1: \Omega \rightarrow \{0,1\}$, $X_2: \Omega \rightarrow \{0,1\}$ be two random variables over $\Omega$ (i.e., we're in the context of a Bernouli trial with, say, a coin flip). In fact, we can let $X_1$ and $X_2$ be $id$ in this context. We can suppose further that they are $i.i.d.$ Question: When people write $X_1 + X_2$, what do they mean? In particular, what is the domain and range of $X_1 + X_2$? I'm assuming that its probability distribution forms a convolution of $X_1$ and $X_2$. As I see it, the options for the domain and range are as follows: $X_1 +X_2$ is a function from $\Omega = \{0, 1\}$ to $\{0, 2\}$ s.t. $(X_1 + X_2)(0) = 0 + 0 = 0$ and $X_1 \rightarrow X_2(1) = 1 + 1 = 0$. $X_1 + X_2$ is a function from $\{(0,0), (0,1), (1,0), (1,1)\}$ to $\{0, 1, 2\}$ s.t. $(X_1 + X_2)(i,k) = i + k$. Notice how in (2) the domain of $X_1 + X_2$ is no longer equal to the domain of $X_1$ and $X_2$. So, with those options laid out, is $X_1 + X_2$ (1), (2), or something else entirely?",,"['probability-theory', 'statistics', 'random-variables']"
70,Continuous Uniform Distribution Problem,Continuous Uniform Distribution Problem,,"Let $ X $ be a continuous random variable on the interval $ (a,b) $. The mean of $ X $ is $ 800 $ and the variance of $ X $ is $ 120,000 $. Calculate the range of $ (a,b) $. My default approach was to proceed as follows: $$ E(X) = \frac{(a+b)}{2} = 800 .$$ $$ Var(X) = \frac{(b-a)^2}{12} = 120,000. $$ Therefore $$ \frac{Var(X)}{E(X)} = \frac{2(b-a)}{12} = 150, $$ and so $ b-a = 900 $. However, the solutions in the back of the book take an alternative approach, and attain different results. $$ b + a = 1,600. $$ Therefore $$ \frac{(1600 - 2a)^2}{12} = 120,000 ,$$ and so $$ 4a^2 -6,400a +1,120,000 = 0 .$$ Solving with the quadratic equation we get $ a = 200 $ and $ b = 1,400 $, giving a range OF 1,200 $. Can anyone see why we get diferent results?","Let $ X $ be a continuous random variable on the interval $ (a,b) $. The mean of $ X $ is $ 800 $ and the variance of $ X $ is $ 120,000 $. Calculate the range of $ (a,b) $. My default approach was to proceed as follows: $$ E(X) = \frac{(a+b)}{2} = 800 .$$ $$ Var(X) = \frac{(b-a)^2}{12} = 120,000. $$ Therefore $$ \frac{Var(X)}{E(X)} = \frac{2(b-a)}{12} = 150, $$ and so $ b-a = 900 $. However, the solutions in the back of the book take an alternative approach, and attain different results. $$ b + a = 1,600. $$ Therefore $$ \frac{(1600 - 2a)^2}{12} = 120,000 ,$$ and so $$ 4a^2 -6,400a +1,120,000 = 0 .$$ Solving with the quadratic equation we get $ a = 200 $ and $ b = 1,400 $, giving a range OF 1,200 $. Can anyone see why we get diferent results?",,['statistics']
71,moment generating function from given PMF?,moment generating function from given PMF?,,"I just a quick question from a book, generating Moment generating function from given PMF: $$f(x) = \frac1n $$  where $$x \in {a, a+1, \ldots , a+n-1}$$","I just a quick question from a book, generating Moment generating function from given PMF: $$f(x) = \frac1n $$  where $$x \in {a, a+1, \ldots , a+n-1}$$",,"['probability', 'statistics']"
72,Convert a joint entropy matrix to a contidional entropy matrix.,Convert a joint entropy matrix to a contidional entropy matrix.,,"I've only barely started to learn about Entropy and Information Theory as a part of a course I'm taking in Systems Theory / Cybernetics. The thing is, I'm terrible at math! Say I have a joint probability matrix as follows: y1    y2   ---------- x1| 1/2  1/4 x2| 0    1/4 In other words: the probability of x1 and y1 occurring is 0.5 the probability of x1 and y2 occurring is .25 the probability of x2 and y1 occurring is 0 the probabiltiy of x2 and y2 occurring is .25 Apparently, this corresponds to the following conditional probability matrix (Y conditioned by X): y1   y2   ----------- x1| 2/3  1/3 x2| 0    1 In other words: If we know x1 will occur, then there is a 2/3 chance y1 will occur and a 1/3 chance y2 will occur. If we know x2 will occur, then there is a 100% chance that y2 will occur. So, I have 2 questions. Are my interpretations correct? How was the second matrix derived from the first? I'm sure the formula is embarrassingly simple as all the material I'm reading seems to assume the conversion function is self-evident. In other words, for each row, I need to maintain the ratio of each value to each other, but scale all the values so that they add to 1. (I think)","I've only barely started to learn about Entropy and Information Theory as a part of a course I'm taking in Systems Theory / Cybernetics. The thing is, I'm terrible at math! Say I have a joint probability matrix as follows: y1    y2   ---------- x1| 1/2  1/4 x2| 0    1/4 In other words: the probability of x1 and y1 occurring is 0.5 the probability of x1 and y2 occurring is .25 the probability of x2 and y1 occurring is 0 the probabiltiy of x2 and y2 occurring is .25 Apparently, this corresponds to the following conditional probability matrix (Y conditioned by X): y1   y2   ----------- x1| 2/3  1/3 x2| 0    1 In other words: If we know x1 will occur, then there is a 2/3 chance y1 will occur and a 1/3 chance y2 will occur. If we know x2 will occur, then there is a 100% chance that y2 will occur. So, I have 2 questions. Are my interpretations correct? How was the second matrix derived from the first? I'm sure the formula is embarrassingly simple as all the material I'm reading seems to assume the conversion function is self-evident. In other words, for each row, I need to maintain the ratio of each value to each other, but scale all the values so that they add to 1. (I think)",,"['probability', 'statistics', 'information-theory', 'entropy']"
73,Weighted average of multiple weighted factors,Weighted average of multiple weighted factors,,"Lets say a factory machine runs as follows: Day 1: $3$ widgets per minute $\times 1000$ minutes $\times 1$ kg per widget $= 3000$ kg. Day 2: $5$ widgets per minute $\times 800$ minutes $\times 1.5$ kg per widget $= 6000$ kg. Day 3: $8$ widgets per minute $\times 300$ minutes $\times 0.5$ kg per widget $= 1200$ kg. So, over the $3$ days the factory machine has run for $2100$ minutes. I am assuming that if I multiply the weighted average number of widgets with the weighted average kg per widget and multiply this by the number of minutes over the three days $(2100)$ this should equal $10,200$ kg $(3000+6000+1200)$. My weighting calculation is below for widgets per minute and kg per widget. $$(3\cdot1000\cdot1)+(5\cdot800\cdot1.5)+(8\cdot300\cdot0.5)/(1000\cdot1)+(800\cdot1.5)+(300\cdot0.5) = 4.833$$ widgets per minute. $$(3\cdot1000\cdot1)+(5\cdot800\cdot1.5)+(8\cdot300\cdot0.5)/(3\cdot1000\cdot1)+(5\cdot800\cdot1.5) = 1.085$$ kg per widget. However $4.833$ widgets $\times 1.085$ kg per widget $\times 2100$ mins $= 11,012$ kg over the three days. Not the correct $10,200$kg. Why is this the case? I have tried weighting by total for the day and this still does not produce the correct answer. I have been using Excel and have noticed that if I keep either ""widgets per minute"" or ""kg per widget"" the same across all three days and only change the other variable I get a correct answer. However when both variable differ across the three days the total becomes distorted as you can see from the example above. Is it not possible to find a weighted average using more than one weighting factor? I can't get my head around this. Thank you in advance for any answers.","Lets say a factory machine runs as follows: Day 1: $3$ widgets per minute $\times 1000$ minutes $\times 1$ kg per widget $= 3000$ kg. Day 2: $5$ widgets per minute $\times 800$ minutes $\times 1.5$ kg per widget $= 6000$ kg. Day 3: $8$ widgets per minute $\times 300$ minutes $\times 0.5$ kg per widget $= 1200$ kg. So, over the $3$ days the factory machine has run for $2100$ minutes. I am assuming that if I multiply the weighted average number of widgets with the weighted average kg per widget and multiply this by the number of minutes over the three days $(2100)$ this should equal $10,200$ kg $(3000+6000+1200)$. My weighting calculation is below for widgets per minute and kg per widget. $$(3\cdot1000\cdot1)+(5\cdot800\cdot1.5)+(8\cdot300\cdot0.5)/(1000\cdot1)+(800\cdot1.5)+(300\cdot0.5) = 4.833$$ widgets per minute. $$(3\cdot1000\cdot1)+(5\cdot800\cdot1.5)+(8\cdot300\cdot0.5)/(3\cdot1000\cdot1)+(5\cdot800\cdot1.5) = 1.085$$ kg per widget. However $4.833$ widgets $\times 1.085$ kg per widget $\times 2100$ mins $= 11,012$ kg over the three days. Not the correct $10,200$kg. Why is this the case? I have tried weighting by total for the day and this still does not produce the correct answer. I have been using Excel and have noticed that if I keep either ""widgets per minute"" or ""kg per widget"" the same across all three days and only change the other variable I get a correct answer. However when both variable differ across the three days the total becomes distorted as you can see from the example above. Is it not possible to find a weighted average using more than one weighting factor? I can't get my head around this. Thank you in advance for any answers.",,"['probability', 'statistics', 'logic', 'average']"
74,Estimate of Proportion,Estimate of Proportion,,"An airline is interested in determining the proportion of its customers who are flying for reasons of business. If they want to be 90 percent certain that their estimate will be correct to within two percent, how large a random sample should they select? This involves using the Z-distribution to find the 90% confidence interval of the actual value of the proportion. But for this to be done, there needs to be an estimate of the proportion, which is not given. How do we find this out?ie (p)*(1-p)*z a/2 ⁄ n =0.0004 How do we find the value of p?","An airline is interested in determining the proportion of its customers who are flying for reasons of business. If they want to be 90 percent certain that their estimate will be correct to within two percent, how large a random sample should they select? This involves using the Z-distribution to find the 90% confidence interval of the actual value of the proportion. But for this to be done, there needs to be an estimate of the proportion, which is not given. How do we find this out?ie (p)*(1-p)*z a/2 ⁄ n =0.0004 How do we find the value of p?",,"['statistics', 'statistical-inference', 'confidence-interval']"
75,Question about joint cdf calculated by ratio of areas,Question about joint cdf calculated by ratio of areas,,"If a point $(X,Y)$ is equally likely to fall anywhere in a circle/triangle/square or whatever, is it true that the joint CDF of $X Y$ is the ratio of bounded area (bounded by $X\le x$,and $Y\le y$) and the total area (bounded by the range of $x$ and $y$)? Because I calculated the joint CDF using double integral of joint PDF and find it is the same as the ratio. Could someone explain the reason? And is it also true that if the joint PDF is a constant, then the CDF is just that ratio multiplied by that constant value?","If a point $(X,Y)$ is equally likely to fall anywhere in a circle/triangle/square or whatever, is it true that the joint CDF of $X Y$ is the ratio of bounded area (bounded by $X\le x$,and $Y\le y$) and the total area (bounded by the range of $x$ and $y$)? Because I calculated the joint CDF using double integral of joint PDF and find it is the same as the ratio. Could someone explain the reason? And is it also true that if the joint PDF is a constant, then the CDF is just that ratio multiplied by that constant value?",,"['probability', 'statistics']"
76,"Correlation of sum of independent variables with its parts. if Z=X+Y, what is Cor(Z,X)?","Correlation of sum of independent variables with its parts. if Z=X+Y, what is Cor(Z,X)?",,"If $Z = X + Y$,  where $X$ & $Y$ are independent random variables, is there some formula to work out $\rho(Z,X)$, based on $\sigma_X$, $\sigma_Y$? For example, I've noticed that for $\sigma_X$ = $\sigma_Y$, over many samples, $\rho(Z,X)$ ~= $\rho(Z,Y)$ ~= $0.7065$ I expect $Z$ to be correlated to $X$ & $Y$, but what is the maths? $X$ & $Y$ are roughly normally distributed if that makes a difference? Sorry if it's a stupid question, help much appreciated!","If $Z = X + Y$,  where $X$ & $Y$ are independent random variables, is there some formula to work out $\rho(Z,X)$, based on $\sigma_X$, $\sigma_Y$? For example, I've noticed that for $\sigma_X$ = $\sigma_Y$, over many samples, $\rho(Z,X)$ ~= $\rho(Z,Y)$ ~= $0.7065$ I expect $Z$ to be correlated to $X$ & $Y$, but what is the maths? $X$ & $Y$ are roughly normally distributed if that makes a difference? Sorry if it's a stupid question, help much appreciated!",,"['probability-theory', 'statistics', 'random-variables', 'correlation']"
77,Calculating the Payout of an Unusual Digital Slot Machine,Calculating the Payout of an Unusual Digital Slot Machine,,"Say you have a digital slot machine. Rather than using virtual reels, this slot machine generates results using predetermined probabilities for a given symbol appearing in any position. Given: Five 'reels' (positions for a symbol to appear) Wild symbols exist (and have their own probability of appearing) Matches must be left-aligned How does one calculate the probability of each possible number of matches, 0-5, for a given symbol? (A 'match' of 1 would mean a symbol appears in the left-most position, but is not followed by itself or a Wild.) Please include in your response a formula which is readable by a layman (I'm no mathemetician). What follows is a description of my attempts to solve this problem. As an example: the Cherries symbol pays 4x the bet for 3 matches. In any given position, Cherries has a 20% chance of appearing, and Wild has a 2% chance of appearing. My first attempt at calculating this probability was $0.2 * (0.2 + 0.02)^2 = 0.00968$. At least one Cherries, plus two more symbols which are either Cherries or Wild. $4 * 0.00968 = 3.872%$ pay for 3 Cherries. It then occurred to me that this probability would seem to also include the probability of getting a match of 4 Cherries and would need to exclude the chance of the next symbol being Cherries or Wild. Thus, I updated the calculation to be $0.2 * (0.2 + 0.02)^2 - (0.2 * (0.2 + 0.02)^3) = .0075504$, giving a payout of ~3.020%. (This step is skipped if we are testing for 5 matches, since 6 matches is impossible.) Is this correct?","Say you have a digital slot machine. Rather than using virtual reels, this slot machine generates results using predetermined probabilities for a given symbol appearing in any position. Given: Five 'reels' (positions for a symbol to appear) Wild symbols exist (and have their own probability of appearing) Matches must be left-aligned How does one calculate the probability of each possible number of matches, 0-5, for a given symbol? (A 'match' of 1 would mean a symbol appears in the left-most position, but is not followed by itself or a Wild.) Please include in your response a formula which is readable by a layman (I'm no mathemetician). What follows is a description of my attempts to solve this problem. As an example: the Cherries symbol pays 4x the bet for 3 matches. In any given position, Cherries has a 20% chance of appearing, and Wild has a 2% chance of appearing. My first attempt at calculating this probability was $0.2 * (0.2 + 0.02)^2 = 0.00968$. At least one Cherries, plus two more symbols which are either Cherries or Wild. $4 * 0.00968 = 3.872%$ pay for 3 Cherries. It then occurred to me that this probability would seem to also include the probability of getting a match of 4 Cherries and would need to exclude the chance of the next symbol being Cherries or Wild. Thus, I updated the calculation to be $0.2 * (0.2 + 0.02)^2 - (0.2 * (0.2 + 0.02)^3) = .0075504$, giving a payout of ~3.020%. (This step is skipped if we are testing for 5 matches, since 6 matches is impossible.) Is this correct?",,"['probability', 'statistics']"
78,Determining Sample Size for a Desired Margin of Error,Determining Sample Size for a Desired Margin of Error,,"I'm trying to study for a test in my AP Statistics course. My lecturer spent the majority of the unit going over the various proportion tests. On my review, I was presented with the following question: Suppose that you wanted to estimate p, the true proportion of students at your school who have a tattoo with 98% confidence and a margin of error no more than 0.10. How many students should you survey? What I'm not understanding is what should be substituted for p . In the given problem, no value for p is given, but yet I need to find n using the following formula: $$ ME = (z\ast )(\sqrt{\frac{p(1-p)}{n}}) $$ How can I determine a value for n ?","I'm trying to study for a test in my AP Statistics course. My lecturer spent the majority of the unit going over the various proportion tests. On my review, I was presented with the following question: Suppose that you wanted to estimate p, the true proportion of students at your school who have a tattoo with 98% confidence and a margin of error no more than 0.10. How many students should you survey? What I'm not understanding is what should be substituted for p . In the given problem, no value for p is given, but yet I need to find n using the following formula: $$ ME = (z\ast )(\sqrt{\frac{p(1-p)}{n}}) $$ How can I determine a value for n ?",,['statistics']
79,What is the covariance between two random variables?,What is the covariance between two random variables?,,What does the covariance of two random variables actually tell us? I've looked everywhere and I can't find a clear answer that I fully understand.,What does the covariance of two random variables actually tell us? I've looked everywhere and I can't find a clear answer that I fully understand.,,"['probability', 'statistics']"
80,Two and four engine probability problem,Two and four engine probability problem,,"Austen, a rocket designer, has come to Chris, a reliability expert, with the following problem: “The vehicle is designed.  We can use two large engines or four small engines and get the same thrust and the same weight.  However, we know that the engines are subject to catastrophic failure, and we have designed the vehicle so that we will still get into orbit if half of the engines fail.  Now, if you tell me the probability of an engine failing in the time required to get into orbit, I can decide whether to use two or four.” Chris replied, “We have analyzed the test data on the engines and have found that the large and small engines have the same probability of failing in a given time.  I can assure you that it makes no difference whether you use two or four engines.  However, this failure probability is classified top secret and I cannot give it to anyone.” Austen said, “Never mind.  From what you have just told me, I can calculate by myself the failure probabilities of an engine and of the rocket.” a.  What is the failure probability for a single engine? My answer: 0.5? b.  What is the failure probability for the rocket? My answer 0.5?","Austen, a rocket designer, has come to Chris, a reliability expert, with the following problem: “The vehicle is designed.  We can use two large engines or four small engines and get the same thrust and the same weight.  However, we know that the engines are subject to catastrophic failure, and we have designed the vehicle so that we will still get into orbit if half of the engines fail.  Now, if you tell me the probability of an engine failing in the time required to get into orbit, I can decide whether to use two or four.” Chris replied, “We have analyzed the test data on the engines and have found that the large and small engines have the same probability of failing in a given time.  I can assure you that it makes no difference whether you use two or four engines.  However, this failure probability is classified top secret and I cannot give it to anyone.” Austen said, “Never mind.  From what you have just told me, I can calculate by myself the failure probabilities of an engine and of the rocket.” a.  What is the failure probability for a single engine? My answer: 0.5? b.  What is the failure probability for the rocket? My answer 0.5?",,"['probability', 'statistics']"
81,why we use uniform distribution on accept reject method?,why we use uniform distribution on accept reject method?,,"the accept-reject method have the following algorithm: Given known random number generators $U \sim Unif(0,1)$ and $X \sim g$, we can generate $Y \sim f$ by the following algorithm. Let $c$ be a constant such that $f(x) \leq cg(x)$ for all $x$. Step 1. Generate $X \sim g$, $U \sim Unif(0,1)$. Step 2. Accept $Y = X$ if $U \leq \frac{f(X)}{cg(X)}$ otherwise go to Step 1. I don't understand why we generate $U \sim \mathcal{U}(0,1)$ Can anybody help me? Thanks.","the accept-reject method have the following algorithm: Given known random number generators $U \sim Unif(0,1)$ and $X \sim g$, we can generate $Y \sim f$ by the following algorithm. Let $c$ be a constant such that $f(x) \leq cg(x)$ for all $x$. Step 1. Generate $X \sim g$, $U \sim Unif(0,1)$. Step 2. Accept $Y = X$ if $U \leq \frac{f(X)}{cg(X)}$ otherwise go to Step 1. I don't understand why we generate $U \sim \mathcal{U}(0,1)$ Can anybody help me? Thanks.",,"['probability', 'probability-theory', 'statistics', 'monte-carlo']"
82,Likelihood function and MLE,Likelihood function and MLE,,Please let me know how to find the likelihood function and MLE for the function $$f(x;θ) = (θ+1)(x^θ)$$ I have tried using the general formula for likelihood function $L(θ)$ however not sure how to proceed further. Please assist.,Please let me know how to find the likelihood function and MLE for the function $$f(x;θ) = (θ+1)(x^θ)$$ I have tried using the general formula for likelihood function $L(θ)$ however not sure how to proceed further. Please assist.,,['statistics']
83,Calculating transformation of normal random variables.,Calculating transformation of normal random variables.,,"Let's say you have 4 i.i.d $N(0, 1)$ random variables $X_1 ,X_2, X_3, X_4$, how would you compute the pdf of $\frac{X_1}{\sqrt{X_1^2 + X_2^2 + X_3^2 + X_4^2}}$. I am also interested in the general approach for doing these kind of calculations and if there is a way to do it without running into really messy integrals.","Let's say you have 4 i.i.d $N(0, 1)$ random variables $X_1 ,X_2, X_3, X_4$, how would you compute the pdf of $\frac{X_1}{\sqrt{X_1^2 + X_2^2 + X_3^2 + X_4^2}}$. I am also interested in the general approach for doing these kind of calculations and if there is a way to do it without running into really messy integrals.",,"['probability', 'statistics', 'random-variables', 'normal-distribution']"
84,Find the probability distribution of the random variable X.,Find the probability distribution of the random variable X.,,"A fair coin is flipped $3$ times. Consider a random variable $X$ which is the number of runs. Number of runs is the number of changes of letter $H$ and $T$. For example, $HHH$ has one run, $TTH$ has two runs and $THT$ has three runs. Find the probability distribution of the random variable $X$. My work: I don't understand the phrasing of this question. In examples in my textbook and online $X$ is defined as the number of heads or tails. But I can't follow where the example in this question is going. I would think that $TTH$ and $THT$ would both have 2 runs since $HHH$ only has one. I don't know what zero runs would be either. Can anyone give me guidance on what exactly this question means? I'm pretty sure I can solve it once I understand what the number of runs means. The outcomes would be: $HHH$ $X=1$ $HTH$ $HHT$ $THH$ $TTH$ $X=2$ $HTT$ $THT$ $X=3$ $TTT$ I don't know what number of $X$ would correspond with each.","A fair coin is flipped $3$ times. Consider a random variable $X$ which is the number of runs. Number of runs is the number of changes of letter $H$ and $T$. For example, $HHH$ has one run, $TTH$ has two runs and $THT$ has three runs. Find the probability distribution of the random variable $X$. My work: I don't understand the phrasing of this question. In examples in my textbook and online $X$ is defined as the number of heads or tails. But I can't follow where the example in this question is going. I would think that $TTH$ and $THT$ would both have 2 runs since $HHH$ only has one. I don't know what zero runs would be either. Can anyone give me guidance on what exactly this question means? I'm pretty sure I can solve it once I understand what the number of runs means. The outcomes would be: $HHH$ $X=1$ $HTH$ $HHT$ $THH$ $TTH$ $X=2$ $HTT$ $THT$ $X=3$ $TTT$ I don't know what number of $X$ would correspond with each.",,"['probability', 'probability-theory', 'statistics']"
85,"Accuracy of GPS bearing, given two locations and their accuracies","Accuracy of GPS bearing, given two locations and their accuracies",,"For an Android app I need to determine the accuracy of the bearing returned by the GPS. Android supplies the following data, among others: The GPS position The accuracy of the GPS position, expressed in meters, which corresponds to $\sigma$, assuming a Gaussian distribution The bearing Note that no accuracy information is supplied for the bearing. Since the only thing the GPS receiver calculates directly is the position, while bearing is inferred from two subsequent position, my approach is to take two subsequent positions and their accuracy to determine an accuracy for the bearing. Let $P_0$ and $P_1$ be two subsequent positions, $\epsilon_0$ and $\epsilon_1$ their respective accuracies in meters, $\psi_1$ the bearing reported at $P_1$, $d$ the distance between $P_0$ and $P_1$ in meters, $\psi_\epsilon$ the unknown accuracy of the bearing, expressed in the same unit as the bearing (degrees or radians at your option) We can visualize this as a line segment from $P_0$ to $P_1$ having length $d$, and circles around each point, their radii being $\epsilon_0$ and $\epsilon_1$, respectively. As long as $\epsilon_0 + \epsilon_1 <= d$, $\psi_\epsilon$ reaches its maximum when the actual locations are located just on these circles, so that the line segment connecting them lies on the common tangent of the two circles which intersects $d$. Together with the two line segments connecting each measured location with the (presumed) actual location, this becomes a figure of two similar rectangular triangles. Then: $$\epsilon_0 + \epsilon_1 = d * \sin (\psi_\epsilon)$$ and thus: $$\psi_\epsilon = \arcsin (\frac{\epsilon_0 + \epsilon_1}{d})$$ The limit is reached when $\epsilon_0 + \epsilon_1 = d$, in which case $\psi_\epsilon$ is 90°. As soon as $\epsilon_0 + \epsilon_1 > d$, the above formula is no longer defined. Visualizing the situation, the accuracy circles overlap, which means that the actual locations can be any pair of points that is entirely within both circles and thus any bearing is possible, hence $\psi_\epsilon = 180°$. The issues here is the sudden ""jump"" from 90° to 180°; also I probably haven't paid proper attention to probability here. Is there a better formula for calculating bearing accuracy, given two positions and their accuracy? EDIT: It's been pointed out that bearing accuracy is influenced by several factors. The one that springs to my mind is that the GPS assumes the receiver has travelled along a straight line from $P_0$ and $P_1$, which will result in errors while turning. Those need to be considered separately – for now, I just need to know how the accuracy of the bearing depends on positional accuracy, without challenging any of the assumptions made by the GPS.","For an Android app I need to determine the accuracy of the bearing returned by the GPS. Android supplies the following data, among others: The GPS position The accuracy of the GPS position, expressed in meters, which corresponds to $\sigma$, assuming a Gaussian distribution The bearing Note that no accuracy information is supplied for the bearing. Since the only thing the GPS receiver calculates directly is the position, while bearing is inferred from two subsequent position, my approach is to take two subsequent positions and their accuracy to determine an accuracy for the bearing. Let $P_0$ and $P_1$ be two subsequent positions, $\epsilon_0$ and $\epsilon_1$ their respective accuracies in meters, $\psi_1$ the bearing reported at $P_1$, $d$ the distance between $P_0$ and $P_1$ in meters, $\psi_\epsilon$ the unknown accuracy of the bearing, expressed in the same unit as the bearing (degrees or radians at your option) We can visualize this as a line segment from $P_0$ to $P_1$ having length $d$, and circles around each point, their radii being $\epsilon_0$ and $\epsilon_1$, respectively. As long as $\epsilon_0 + \epsilon_1 <= d$, $\psi_\epsilon$ reaches its maximum when the actual locations are located just on these circles, so that the line segment connecting them lies on the common tangent of the two circles which intersects $d$. Together with the two line segments connecting each measured location with the (presumed) actual location, this becomes a figure of two similar rectangular triangles. Then: $$\epsilon_0 + \epsilon_1 = d * \sin (\psi_\epsilon)$$ and thus: $$\psi_\epsilon = \arcsin (\frac{\epsilon_0 + \epsilon_1}{d})$$ The limit is reached when $\epsilon_0 + \epsilon_1 = d$, in which case $\psi_\epsilon$ is 90°. As soon as $\epsilon_0 + \epsilon_1 > d$, the above formula is no longer defined. Visualizing the situation, the accuracy circles overlap, which means that the actual locations can be any pair of points that is entirely within both circles and thus any bearing is possible, hence $\psi_\epsilon = 180°$. The issues here is the sudden ""jump"" from 90° to 180°; also I probably haven't paid proper attention to probability here. Is there a better formula for calculating bearing accuracy, given two positions and their accuracy? EDIT: It's been pointed out that bearing accuracy is influenced by several factors. The one that springs to my mind is that the GPS assumes the receiver has travelled along a straight line from $P_0$ and $P_1$, which will result in errors while turning. Those need to be considered separately – for now, I just need to know how the accuracy of the bearing depends on positional accuracy, without challenging any of the assumptions made by the GPS.",,"['statistics', 'trigonometry', 'error-propagation']"
86,Is $X^2$ independent from $XY$ where $X$ and $Y$ are standard normals?,Is  independent from  where  and  are standard normals?,X^2 XY X Y,"I'm thinking they can somehow be expressed as functions of $X-Y$ and $X+Y$, but I haven't quite found out how. Bonus questions: Is it correct that they are both Chi square distributed? And so, would $X^2 + XY$ also be Chi square distributed? What would be the distribution of $a(X_0^2+Y_0^2) + b(X_0X_1+Y_0Y_1)$?","I'm thinking they can somehow be expressed as functions of $X-Y$ and $X+Y$, but I haven't quite found out how. Bonus questions: Is it correct that they are both Chi square distributed? And so, would $X^2 + XY$ also be Chi square distributed? What would be the distribution of $a(X_0^2+Y_0^2) + b(X_0X_1+Y_0Y_1)$?",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
87,Probability density function and the minimal sufficient statistics for two samples from normal distribution,Probability density function and the minimal sufficient statistics for two samples from normal distribution,,"Suppose $X_1,\ldots, X_m$  is a random sample of size $m$ from the normal distribution $N(\mu_1,\sigma^2)$  with mean $\mu_1$ and standard deviation $\sigma$, and that $Y_1,\ldots, Y_n$ is a random sample of size $n$ from the normal distribution $N(\mu_2,\sigma^2)$ with mean $\mu_2$ and standard deviation $\sigma$. Also, suppose that the samples $X$ and $Y$ are independent. What are the  probability density function and the minimal sufficient statistic for $(\mu_1,\mu_2,\sigma)$?.","Suppose $X_1,\ldots, X_m$  is a random sample of size $m$ from the normal distribution $N(\mu_1,\sigma^2)$  with mean $\mu_1$ and standard deviation $\sigma$, and that $Y_1,\ldots, Y_n$ is a random sample of size $n$ from the normal distribution $N(\mu_2,\sigma^2)$ with mean $\mu_2$ and standard deviation $\sigma$. Also, suppose that the samples $X$ and $Y$ are independent. What are the  probability density function and the minimal sufficient statistic for $(\mu_1,\mu_2,\sigma)$?.",,"['probability', 'statistics', 'normal-distribution', 'statistical-inference']"
88,Imposing non-negativity constraint on a linear regression function,Imposing non-negativity constraint on a linear regression function,,"Suppose I am interested in estimating the linear regression model $$ Y_i = g(X_i)^T\beta + \epsilon_i $$ where $Y_i$ is a scalar outcome of interest, $X_i$ is a scalar covariate with support on the unit interval, $g(\cdot)$ is a $K$-dimensional vector of known functions that are not perfectly colinear, $\beta$ is a $K$-dimensional vector of parameters to be estimated, and $E(g(X_i) \epsilon_i) = 0$.  Suppose I know that $\Pr(Y \geq 0) = 1$, so I'd like to impose the condition $$ \beta^T g(x) \geq 0 \qquad \text{for all $x \in [0,1]$} $$ when estimating $\beta$. How would I go about doing this?","Suppose I am interested in estimating the linear regression model $$ Y_i = g(X_i)^T\beta + \epsilon_i $$ where $Y_i$ is a scalar outcome of interest, $X_i$ is a scalar covariate with support on the unit interval, $g(\cdot)$ is a $K$-dimensional vector of known functions that are not perfectly colinear, $\beta$ is a $K$-dimensional vector of parameters to be estimated, and $E(g(X_i) \epsilon_i) = 0$.  Suppose I know that $\Pr(Y \geq 0) = 1$, so I'd like to impose the condition $$ \beta^T g(x) \geq 0 \qquad \text{for all $x \in [0,1]$} $$ when estimating $\beta$. How would I go about doing this?",,"['statistics', 'regression', 'regression-analysis', 'linear-regression']"
89,Is this a valid proof for the divergence of $E\left( \frac{1}{\bar{X}} \right)$ for a Normal distribution?,Is this a valid proof for the divergence of  for a Normal distribution?,E\left( \frac{1}{\bar{X}} \right),"I have come across this proof and I was wondering if it is valid. What troubles me is the inequality $e^{-\frac{n}{2} \theta^2} > \frac{1}{2}$ as it's not obvious to me how one gets there. I know that $e^{-x} \geq 1-x$ but other than that I am stuck. All help would be greatly appreciated, thank you.","I have come across this proof and I was wondering if it is valid. What troubles me is the inequality $e^{-\frac{n}{2} \theta^2} > \frac{1}{2}$ as it's not obvious to me how one gets there. I know that $e^{-x} \geq 1-x$ but other than that I am stuck. All help would be greatly appreciated, thank you.",,"['probability', 'statistics', 'probability-distributions', 'expectation']"
90,Proving a Trick to More Quickly Calculate N-Step Transition Probabilities,Proving a Trick to More Quickly Calculate N-Step Transition Probabilities,,"So, I have been working on a homework problem all day that asks me to prove that: $P^n= \Pi +Q^n$ where P is the transition matrix of a finite-state regular Markov Chain, $\Pi$ is a matrix whose rows are the stationary distribution of P, and $Q = P - \Pi$. The fundamental relation that I have been attempting to show is that $(P-\Pi)^n=P^n-\Pi$. I'm not sure if there is a relevant matrix product property here that would allow me to establish this relation but I can't figure out how to proceed. Also, for those who have math backgrounds but not necessarily statistics backgrounds, the stationary distribution is just a left eigenvector with eigenvalue 1, and P is a stochastic matrix (rows summing to 1). Originally, I was attempting to rewrite the matrix product relation in sigma notation and try to achieve some sort of simplification. I didn't find anything by doing that, so here is my most current attempt: $P^n= \Pi +Q^n$ Substituting in for Q to get to the relation I referred to earlier: $P^n=\Pi+(P-\Pi)^n$ $P^n-\Pi=(P-\Pi)^n$ Then, I use the property that the eigenvalue of $\Pi$ is 1 to rewrite P as $\Pi*P$. $(\Pi*P-\Pi)^n=P^n-\Pi$ $\Pi^n*(P-1)^n=P^n-\Pi$ From here, I am unsure how to proceed but believe that this is a natural way to use the eigenvalue to alter the relation.","So, I have been working on a homework problem all day that asks me to prove that: $P^n= \Pi +Q^n$ where P is the transition matrix of a finite-state regular Markov Chain, $\Pi$ is a matrix whose rows are the stationary distribution of P, and $Q = P - \Pi$. The fundamental relation that I have been attempting to show is that $(P-\Pi)^n=P^n-\Pi$. I'm not sure if there is a relevant matrix product property here that would allow me to establish this relation but I can't figure out how to proceed. Also, for those who have math backgrounds but not necessarily statistics backgrounds, the stationary distribution is just a left eigenvector with eigenvalue 1, and P is a stochastic matrix (rows summing to 1). Originally, I was attempting to rewrite the matrix product relation in sigma notation and try to achieve some sort of simplification. I didn't find anything by doing that, so here is my most current attempt: $P^n= \Pi +Q^n$ Substituting in for Q to get to the relation I referred to earlier: $P^n=\Pi+(P-\Pi)^n$ $P^n-\Pi=(P-\Pi)^n$ Then, I use the property that the eigenvalue of $\Pi$ is 1 to rewrite P as $\Pi*P$. $(\Pi*P-\Pi)^n=P^n-\Pi$ $\Pi^n*(P-1)^n=P^n-\Pi$ From here, I am unsure how to proceed but believe that this is a natural way to use the eigenvalue to alter the relation.",,"['probability', 'matrices', 'statistics', 'stochastic-processes', 'markov-chains']"
91,Finding of $\hat{\theta}_{MLE}$ of $f(x; \theta) = (\theta + 1)x^\theta$,Finding of  of,\hat{\theta}_{MLE} f(x; \theta) = (\theta + 1)x^\theta,"Let $X_1, \cdots, X_n$ be a random sample from the PDF: $f(x;\theta) = (\theta + 1) x^{\theta}$ with $0<x<1$ and $\theta > -1$. The likelihood function is: \begin{align} L(\theta) &= f(x_1, \cdots, x_n; \theta) \mathbb{1}\{0<x<1\} \mathbb{1}\{\theta >-1\}\\ &= \prod_{i=1}^{n}{f(x_i ; \theta)}\mathbb{1}\{0<x<1\} \mathbb{1}\{\theta >-1\}\\ &= \prod_{i=1}^{n}{(\theta+1)x_i^{\theta}}\mathbb{1}\{0<x<1\} \mathbb{1}\{\theta >-1\} \\ &=(\theta+1)^n \left( \prod_{i=1}^n{x_i}\right)^\theta \end{align} We look at the log likelihood $l(\theta)$ and take the derivative of this since it is easier to deal with and it is allowed because the log is monotonic: \begin{align} l(\theta) = n\log(\theta+1) + \theta \left( \sum_{i=1}^n{\log(x_i)} \right) \end{align} $\implies \frac{d}{d\theta} = \frac{n}{\theta+1} + \sum_{i=1}^n{\log(x_i)} = 0$ $\implies \hat{\theta}_{MLE} = -\frac{n}{\sum_{i=1}^n{\log(x_i)}} - 1$ However, this doesn't look right.","Let $X_1, \cdots, X_n$ be a random sample from the PDF: $f(x;\theta) = (\theta + 1) x^{\theta}$ with $0<x<1$ and $\theta > -1$. The likelihood function is: \begin{align} L(\theta) &= f(x_1, \cdots, x_n; \theta) \mathbb{1}\{0<x<1\} \mathbb{1}\{\theta >-1\}\\ &= \prod_{i=1}^{n}{f(x_i ; \theta)}\mathbb{1}\{0<x<1\} \mathbb{1}\{\theta >-1\}\\ &= \prod_{i=1}^{n}{(\theta+1)x_i^{\theta}}\mathbb{1}\{0<x<1\} \mathbb{1}\{\theta >-1\} \\ &=(\theta+1)^n \left( \prod_{i=1}^n{x_i}\right)^\theta \end{align} We look at the log likelihood $l(\theta)$ and take the derivative of this since it is easier to deal with and it is allowed because the log is monotonic: \begin{align} l(\theta) = n\log(\theta+1) + \theta \left( \sum_{i=1}^n{\log(x_i)} \right) \end{align} $\implies \frac{d}{d\theta} = \frac{n}{\theta+1} + \sum_{i=1}^n{\log(x_i)} = 0$ $\implies \hat{\theta}_{MLE} = -\frac{n}{\sum_{i=1}^n{\log(x_i)}} - 1$ However, this doesn't look right.",,"['statistics', 'parameter-estimation', 'maximum-likelihood', 'log-likelihood']"
92,Birth-death Process/Extinction,Birth-death Process/Extinction,,"Random processes in Continuous time. Given that $\beta = \frac{4}{5}*\mu$ I have calculated that the birth rate $= 0.4$ and the death rate $= 0.5$. If the initial population $X(0)=6$, how many events (births and deaths) are there until the population dies out? This is an embedded process $\{X_n;\:n=0,1,...\}$. Is this possible to work out with so little information? It's all I have.","Random processes in Continuous time. Given that $\beta = \frac{4}{5}*\mu$ I have calculated that the birth rate $= 0.4$ and the death rate $= 0.5$. If the initial population $X(0)=6$, how many events (births and deaths) are there until the population dies out? This is an embedded process $\{X_n;\:n=0,1,...\}$. Is this possible to work out with so little information? It's all I have.",,"['probability', 'statistics', 'random-walk']"
93,Moment generating function of sample mean of bernoulli random variables,Moment generating function of sample mean of bernoulli random variables,,"Let $p \in (0,1)$ and $n \in \mathbb{N}$. We consider a sample of $n$ i.i.d. Bernoulli variables $X_1,\dots,X_n$ with parameter p. Computer $E[e^{\lambda\bar{X_n}}]$ such that $\bar{X_n}= \frac{1}{n} \sum_{i=1}^n X_i$ $E[e^{\lambda\bar{X_n}}]=E[e^{\frac{\lambda}{n} \sum_{i=1}^n X_i}]=e^{\frac{1}{n}}E[e^{\lambda\sum_{i=1}^n X_i}]= e^{\frac{1}{n}}E[e^{\lambda X_1}]\dots E[e^{\lambda X_n}]=e^{\frac{1}{n}}(1-p+pe^{\lambda})^n$ Is it correct ?","Let $p \in (0,1)$ and $n \in \mathbb{N}$. We consider a sample of $n$ i.i.d. Bernoulli variables $X_1,\dots,X_n$ with parameter p. Computer $E[e^{\lambda\bar{X_n}}]$ such that $\bar{X_n}= \frac{1}{n} \sum_{i=1}^n X_i$ $E[e^{\lambda\bar{X_n}}]=E[e^{\frac{\lambda}{n} \sum_{i=1}^n X_i}]=e^{\frac{1}{n}}E[e^{\lambda\sum_{i=1}^n X_i}]= e^{\frac{1}{n}}E[e^{\lambda X_1}]\dots E[e^{\lambda X_n}]=e^{\frac{1}{n}}(1-p+pe^{\lambda})^n$ Is it correct ?",,"['probability', 'statistics']"
94,Show that $\hat{\theta}$ is an unbiased estimator of $\theta$,Show that  is an unbiased estimator of,\hat{\theta} \theta,"Let $f(x, \theta) = \frac{1}{\theta} x^{\frac{1-\theta}{\theta}}$, where $0 < x < 1$ and $\theta > 0$. Let $X_1, \dots, X_n$ be iid with density $f$. Taking the log likelihood, I found $$ l(\theta) = -n\ln{\theta} + \frac{1-\theta}{\theta}\sum_{i=1}^n{\ln{X_i}}  $$ $$ l'(\theta) = -\frac{n}{\theta} - \frac{1}{\theta^2}\sum{\ln{X_i}}$$ Setting $l'(\theta) = 0$ yields the MLE of $$\hat{\theta} = -\frac{1}{n}\sum{\ln(X_i)}$$ But I don't know how to show that $E(\hat{\theta}) = \theta$, i.e. it's an unbiased estimator. I tried taking the estimate of both sides as follows: $$ E(\hat{\theta}) = -\frac{1}{n}\sum{\ln{E(X_i)}} = -\frac{1}{n}\sum{\ln{\frac{1}{1 + \theta}}} = \ln(1 + \theta)$$ where I found $E(X_i)$ as follows: $$ E(X) = \int_0^1{x f(x, \theta) dx} = \frac{1}{\theta}\int_0^1{x^{1/\theta}} = \frac{1}{1 + \theta} x^{\frac{1 + \theta} {\theta}}{\huge\rvert}_0^1 = \frac{1}{1 + \theta}$$ Okay, thanks to @CommongerG for pointing out my mistake in his answer. We have  $$E(\hat{\theta}) = -\frac{1}{n}\sum{E(\ln{X})} = -E(\ln{X})$$ So I need to show $E(\ln{X}) = -\theta$. Well, $$ E(\ln{X}) = \int_0^1{\ln{x} f(x, \theta) dx} = \theta^{-1}\int_0^1{x^{\frac{1-\theta}{\theta}}\ln{x}dx}$$ Thank you @MlleM for pointing out my calculus error. I finally got the desired result. Letting $u = \ln{x}$ and $dv = \theta^{-1}x^{\frac{1-\theta}{\theta}} dx$, we have $du = \frac{dx}{x}$ and $v = x^{\frac{1}{\theta}}$. Then this solves as: $$ E(\ln{X}) = x^{\frac{1}{\theta}}\ln(x){\large\rvert}_0^1 - \int_0^1{x^{\frac{1}{\theta}}dx}{\huge\rvert}_0^1 = 0 - \theta x^{\frac{1}{\theta}} {\huge\rvert}_0^1 = - \theta$$","Let $f(x, \theta) = \frac{1}{\theta} x^{\frac{1-\theta}{\theta}}$, where $0 < x < 1$ and $\theta > 0$. Let $X_1, \dots, X_n$ be iid with density $f$. Taking the log likelihood, I found $$ l(\theta) = -n\ln{\theta} + \frac{1-\theta}{\theta}\sum_{i=1}^n{\ln{X_i}}  $$ $$ l'(\theta) = -\frac{n}{\theta} - \frac{1}{\theta^2}\sum{\ln{X_i}}$$ Setting $l'(\theta) = 0$ yields the MLE of $$\hat{\theta} = -\frac{1}{n}\sum{\ln(X_i)}$$ But I don't know how to show that $E(\hat{\theta}) = \theta$, i.e. it's an unbiased estimator. I tried taking the estimate of both sides as follows: $$ E(\hat{\theta}) = -\frac{1}{n}\sum{\ln{E(X_i)}} = -\frac{1}{n}\sum{\ln{\frac{1}{1 + \theta}}} = \ln(1 + \theta)$$ where I found $E(X_i)$ as follows: $$ E(X) = \int_0^1{x f(x, \theta) dx} = \frac{1}{\theta}\int_0^1{x^{1/\theta}} = \frac{1}{1 + \theta} x^{\frac{1 + \theta} {\theta}}{\huge\rvert}_0^1 = \frac{1}{1 + \theta}$$ Okay, thanks to @CommongerG for pointing out my mistake in his answer. We have  $$E(\hat{\theta}) = -\frac{1}{n}\sum{E(\ln{X})} = -E(\ln{X})$$ So I need to show $E(\ln{X}) = -\theta$. Well, $$ E(\ln{X}) = \int_0^1{\ln{x} f(x, \theta) dx} = \theta^{-1}\int_0^1{x^{\frac{1-\theta}{\theta}}\ln{x}dx}$$ Thank you @MlleM for pointing out my calculus error. I finally got the desired result. Letting $u = \ln{x}$ and $dv = \theta^{-1}x^{\frac{1-\theta}{\theta}} dx$, we have $du = \frac{dx}{x}$ and $v = x^{\frac{1}{\theta}}$. Then this solves as: $$ E(\ln{X}) = x^{\frac{1}{\theta}}\ln(x){\large\rvert}_0^1 - \int_0^1{x^{\frac{1}{\theta}}dx}{\huge\rvert}_0^1 = 0 - \theta x^{\frac{1}{\theta}} {\huge\rvert}_0^1 = - \theta$$",,"['statistics', 'proof-verification', 'maximum-likelihood', 'log-likelihood']"
95,Statistics in circuits,Statistics in circuits,,"I have a circuit, in order for it to work the electricity has to travel from point $A$ to point $B$, but on its way there it encounters $4$ independent switches. If any one of them is closed the system will function properly. the probability of a switch being closed is $.3$ for all $4$ switches, what is the overall probability that the system functions. Currently I tried using a tree diagram but that offered me no help and quickly just made it more confusing. im not sure where to even begin or what to start with","I have a circuit, in order for it to work the electricity has to travel from point $A$ to point $B$, but on its way there it encounters $4$ independent switches. If any one of them is closed the system will function properly. the probability of a switch being closed is $.3$ for all $4$ switches, what is the overall probability that the system functions. Currently I tried using a tree diagram but that offered me no help and quickly just made it more confusing. im not sure where to even begin or what to start with",,['statistics']
96,Problems using Rejection Sampling method,Problems using Rejection Sampling method,,"I'm supposed to generate random numbers from the following distribution: $$ f(x) = \begin{cases} \frac{3}{4}(2x-x^2) &\mbox{if } x \in (0,2) \\  0 & \mbox{else} \end{cases} $$ I'm given the following algorithm in my script, which looks slightly different from those that I have found in the literature: Simulate $ U \sim U(0,1)$ Simulate $Y \sim q$ Accept $X=Y$ if $ U \leq \dfrac{1}{M}\dfrac{f(Y)}{q(Y)}$, otherwise go to step 1. Now first I have to find a function q which is easier to sample from, such that there exists a $M \in \mathbb{R}$, so that $Mq(x) \geq f(x), \forall x \in (0,2)$. I decided to pick $q \sim U(0,2)$ and have $M := \sup_{x \in (0,2)} f(x) = \frac{3}{4}$ Now I sample from $U(0,1)$, for which I get $U = 0.32$, then I sample from $Y \sim q \Rightarrow 1.28$ and now I'm supposed to accept the sampled value $y$ from step 2 if $ U \leq \frac{1}{M} \frac{f(Y)}{q(Y)}$ which in my case gives me: $0.32 \leq \frac{4}{3}f(1.29)=0.92$, so I'm supposed to accept $X=1.28$, however $1.28$ can hardly be from $f$. So what am I doing wrong.","I'm supposed to generate random numbers from the following distribution: $$ f(x) = \begin{cases} \frac{3}{4}(2x-x^2) &\mbox{if } x \in (0,2) \\  0 & \mbox{else} \end{cases} $$ I'm given the following algorithm in my script, which looks slightly different from those that I have found in the literature: Simulate $ U \sim U(0,1)$ Simulate $Y \sim q$ Accept $X=Y$ if $ U \leq \dfrac{1}{M}\dfrac{f(Y)}{q(Y)}$, otherwise go to step 1. Now first I have to find a function q which is easier to sample from, such that there exists a $M \in \mathbb{R}$, so that $Mq(x) \geq f(x), \forall x \in (0,2)$. I decided to pick $q \sim U(0,2)$ and have $M := \sup_{x \in (0,2)} f(x) = \frac{3}{4}$ Now I sample from $U(0,1)$, for which I get $U = 0.32$, then I sample from $Y \sim q \Rightarrow 1.28$ and now I'm supposed to accept the sampled value $y$ from step 2 if $ U \leq \frac{1}{M} \frac{f(Y)}{q(Y)}$ which in my case gives me: $0.32 \leq \frac{4}{3}f(1.29)=0.92$, so I'm supposed to accept $X=1.28$, however $1.28$ can hardly be from $f$. So what am I doing wrong.",,"['probability', 'statistics']"
97,"What are ""moments"" in Moment Generating Function ?","What are ""moments"" in Moment Generating Function ?",,"I read What is the use of moments in statistics but it didn't necessarily answer my question I'm following the logic in https://en.wikipedia.org/wiki/Moment-generating_function https://en.wikipedia.org/wiki/Moment_(mathematics) says ""moments"" for probability distribution functions (p.d.f.): ""If the points represent probability density, then the zeroth moment is the total probability (i.e. one), the first moment is the mean, the second moment is the variance, the third moment is the skewness, and the fourth moment (with normalization and shift) is the kurtosis."" These are the parts that confuse me: What exactly is t , or ""moment"", when applying this to p.d.f.s? Are these ""moments"" mathematically defined or are they arbitrarily assigned?","I read What is the use of moments in statistics but it didn't necessarily answer my question I'm following the logic in https://en.wikipedia.org/wiki/Moment-generating_function https://en.wikipedia.org/wiki/Moment_(mathematics) says ""moments"" for probability distribution functions (p.d.f.): ""If the points represent probability density, then the zeroth moment is the total probability (i.e. one), the first moment is the mean, the second moment is the variance, the third moment is the skewness, and the fourth moment (with normalization and shift) is the kurtosis."" These are the parts that confuse me: What exactly is t , or ""moment"", when applying this to p.d.f.s? Are these ""moments"" mathematically defined or are they arbitrarily assigned?",,"['probability', 'statistics', 'moment-generating-functions', 'means']"
98,Implications of zero second moment condition,Implications of zero second moment condition,,"I have a question related to the implications of a zero second moment conditions. Consider a real-valued random variable $X$ defined on the probability space $(\Omega, \mathcal{F}, P)$. As we can read here , $E(X^2)=0 \rightarrow E(X)=0$. If we keep to write the implications, we have $E(X^2)=0 \rightarrow E(X)=0\rightarrow Var(X)=0\leftrightarrow X(\omega)=K \text{ }\forall \omega \in \Omega, K \in \mathbb{R} \leftrightarrow E(X)=X$ Can we conclude that $E(X^2)=0 \rightarrow X=0$?","I have a question related to the implications of a zero second moment conditions. Consider a real-valued random variable $X$ defined on the probability space $(\Omega, \mathcal{F}, P)$. As we can read here , $E(X^2)=0 \rightarrow E(X)=0$. If we keep to write the implications, we have $E(X^2)=0 \rightarrow E(X)=0\rightarrow Var(X)=0\leftrightarrow X(\omega)=K \text{ }\forall \omega \in \Omega, K \in \mathbb{R} \leftrightarrow E(X)=X$ Can we conclude that $E(X^2)=0 \rightarrow X=0$?",,"['probability', 'statistics', 'expectation']"
99,"Determine the asymptotic distribution of $\bar X_n$, properly centered and $\sqrt n$ scaled","Determine the asymptotic distribution of , properly centered and  scaled",\bar X_n \sqrt n,"Let $X_1, X_2,...X_n$ be i.i.d. with $P(X_i =1)=1-P(X_i =0)=p,p \in (0,1)$. (a) Show that $\bar X_n$ is the MLE of p. (b) Find the mean $\mu_n$ and variance $\sigma^{2}_n$ of $\bar X_n$ and invoke the CLT to determine the asymptotic distribution of $\bar X_n$, properly centered and $\sqrt n$ scaled. Thoughts: I know how to solve part (a) and also know the mean and variance of part (b). The question that bothers me is the second part of part (b). I don't know to apply CLT here with $\sqrt n$ scaled. Any explicit explanation of this part would be much appreciated.","Let $X_1, X_2,...X_n$ be i.i.d. with $P(X_i =1)=1-P(X_i =0)=p,p \in (0,1)$. (a) Show that $\bar X_n$ is the MLE of p. (b) Find the mean $\mu_n$ and variance $\sigma^{2}_n$ of $\bar X_n$ and invoke the CLT to determine the asymptotic distribution of $\bar X_n$, properly centered and $\sqrt n$ scaled. Thoughts: I know how to solve part (a) and also know the mean and variance of part (b). The question that bothers me is the second part of part (b). I don't know to apply CLT here with $\sqrt n$ scaled. Any explicit explanation of this part would be much appreciated.",,"['probability', 'statistics', 'statistical-inference', 'central-limit-theorem']"
