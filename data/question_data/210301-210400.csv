,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,I need to prove a formula but I'm not sure how,I need to prove a formula but I'm not sure how,,"I'm working on a problem with the goal of finding a general formula and proof for the number of ways to arrange a string of 2n bits so that the number of 1's is strictly greater than the number of 0's I've figured out how to do it, but I don't know how to prove it. Here's what I have so far. To calculate it for a given number, in this case let's say 5, 2*5 = 10 so I need to do 10c6 + 10c7 +...+ 10c10 = 386 I've broken that down to (2^2n - 2n c(comb) n) / 2 For the case above that'd be (2^2(5) - 2(5) c(comb) n) /2 = (1024 - 252) / 2 = 386 Once again, my problem is I don't know how to prove it. I figure it's probably by induction, but I don't know how to do it.","I'm working on a problem with the goal of finding a general formula and proof for the number of ways to arrange a string of 2n bits so that the number of 1's is strictly greater than the number of 0's I've figured out how to do it, but I don't know how to prove it. Here's what I have so far. To calculate it for a given number, in this case let's say 5, 2*5 = 10 so I need to do 10c6 + 10c7 +...+ 10c10 = 386 I've broken that down to (2^2n - 2n c(comb) n) / 2 For the case above that'd be (2^2(5) - 2(5) c(comb) n) /2 = (1024 - 252) / 2 = 386 Once again, my problem is I don't know how to prove it. I figure it's probably by induction, but I don't know how to do it.",,"['probability', 'discrete-mathematics']"
1,Prove that: $2^{n+1}|k^{2^n}-1$,Prove that:,2^{n+1}|k^{2^n}-1,Let's denote that $k$ is an odd number and $n\in \mathbb{N}$. Prove that: $$2^{n+1}|k^{2^n}-1$$ Could you give me any HINT how to start with this?,Let's denote that $k$ is an odd number and $n\in \mathbb{N}$. Prove that: $$2^{n+1}|k^{2^n}-1$$ Could you give me any HINT how to start with this?,,"['elementary-number-theory', 'discrete-mathematics']"
2,Recurrence Relations for $c_1$ and $c_2$,Recurrence Relations for  and,c_1 c_2,"For the following recurrence relation: $a_n = 3a_{n-1}+4a_{n-2}$, where $a_0=3$ and $a_1=2$ I solved it using quadratic equation by $x^2+3x-4$. So I got to $a_n = 4^nc_1 + c_2(-1)^n$. Now to find $c_1$ and $c_2$, my book says that $c_1 =1$ and $c_2=2$. I am so confused as to where that answers came from. I know that $$a_0=3=c_1+c_2$$ and $$a_1=2=4c_1-c_2$$ but cant see the solution for $c_1$ and $c_2$.","For the following recurrence relation: $a_n = 3a_{n-1}+4a_{n-2}$, where $a_0=3$ and $a_1=2$ I solved it using quadratic equation by $x^2+3x-4$. So I got to $a_n = 4^nc_1 + c_2(-1)^n$. Now to find $c_1$ and $c_2$, my book says that $c_1 =1$ and $c_2=2$. I am so confused as to where that answers came from. I know that $$a_0=3=c_1+c_2$$ and $$a_1=2=4c_1-c_2$$ but cant see the solution for $c_1$ and $c_2$.",,"['discrete-mathematics', 'recurrence-relations']"
3,How do you figure out what are all the possible numbers that four variables can be for a given N?,How do you figure out what are all the possible numbers that four variables can be for a given N?,,"I know what I want to do but I do not know how to do it. This is complication that I have, there are four variables A, B, C, D which all are ≥ 1. So in the equation (A+B+C+D)=N where I know what N equal to; how do I find the possible values of A, B, C, D? EDIT: To clarify A, B, C, D are four variables with the value of ≥ 1 and the relationship that they have the sum of one number. So, in the equation... (A+B+C+D)=N How do you figure out what are all the possible numbers that A, B, C, D can be for a given N? P.S. I have just started learning mathematics with a new passion, I really enjoy it and have been relearning and learning a lot of stuff. If you could also point me in the direction of information that work with problems like these, that would be great!","I know what I want to do but I do not know how to do it. This is complication that I have, there are four variables A, B, C, D which all are ≥ 1. So in the equation (A+B+C+D)=N where I know what N equal to; how do I find the possible values of A, B, C, D? EDIT: To clarify A, B, C, D are four variables with the value of ≥ 1 and the relationship that they have the sum of one number. So, in the equation... (A+B+C+D)=N How do you figure out what are all the possible numbers that A, B, C, D can be for a given N? P.S. I have just started learning mathematics with a new passion, I really enjoy it and have been relearning and learning a lot of stuff. If you could also point me in the direction of information that work with problems like these, that would be great!",,"['combinatorics', 'discrete-mathematics']"
4,Conjugate Ferrers diagrams,Conjugate Ferrers diagrams,,"Let $\pi=\langle \pi_1,\pi_2,... \rangle , \ \pi_1\ge\pi_2\ge...,$ be a partition of a number and $\pi'=\langle \pi_1',\pi_2',... \rangle$ be a partition conjugated to $\pi$ , which means that Ferrers diagram for $\pi'$ is transposed Ferrers diagram for $\pi$ . For example partition conjugated to $\langle 4,4,2,1 \rangle$ is $\langle 4,3,2,2 \rangle$ . Prove identities: $\displaystyle\sum_{i}\left\lceil \frac{\pi_{2i-1}}{2} \right\rceil = \sum_{i}\left\lceil \frac{\pi'_{2i-1}}{2} \right\rceil$ $\displaystyle\sum_{i}\left\lfloor \frac{\pi_{2i-1}}{2} \right\rfloor = \sum_{i}\left\lceil \frac{\pi'_{2i}}{2} \right\rceil$ $\displaystyle\sum_{i}\left\lfloor \frac{\pi_{2i}}{2} \right\rfloor = \sum_{i}\left\lfloor \frac{\pi'_{2i}}{2} \right\rfloor$ No idea how to even start. Nice observation is that $\pi_1'$ is the number of the elements in $\pi$ but it gives us nothing I think.","Let be a partition of a number and be a partition conjugated to , which means that Ferrers diagram for is transposed Ferrers diagram for . For example partition conjugated to is . Prove identities: No idea how to even start. Nice observation is that is the number of the elements in but it gives us nothing I think.","\pi=\langle \pi_1,\pi_2,... \rangle , \ \pi_1\ge\pi_2\ge..., \pi'=\langle \pi_1',\pi_2',... \rangle \pi \pi' \pi \langle 4,4,2,1 \rangle \langle 4,3,2,2 \rangle \displaystyle\sum_{i}\left\lceil \frac{\pi_{2i-1}}{2} \right\rceil = \sum_{i}\left\lceil \frac{\pi'_{2i-1}}{2} \right\rceil \displaystyle\sum_{i}\left\lfloor \frac{\pi_{2i-1}}{2} \right\rfloor = \sum_{i}\left\lceil \frac{\pi'_{2i}}{2} \right\rceil \displaystyle\sum_{i}\left\lfloor \frac{\pi_{2i}}{2} \right\rfloor = \sum_{i}\left\lfloor \frac{\pi'_{2i}}{2} \right\rfloor \pi_1' \pi","['discrete-mathematics', 'integer-partitions']"
5,Eccentricity of vertices in a graph,Eccentricity of vertices in a graph,,This question is related to my last question about regular graphs Eccentricity of vertices in a regular graph . I got the required answer but I am having a doubt. Can we put restriction on number of vertices and regularity so that the graph contains vertices of same eccentricity?,This question is related to my last question about regular graphs Eccentricity of vertices in a regular graph . I got the required answer but I am having a doubt. Can we put restriction on number of vertices and regularity so that the graph contains vertices of same eccentricity?,,"['combinatorics', 'graph-theory', 'discrete-mathematics', 'computer-science']"
6,to check the required property of a given graph.,to check the required property of a given graph.,,Can a graph be self-centered if it contains a vertex of degree one. The simplest counter example that came to my mind is Path. But how to prove the statement if we consider any graph with a vertex of degree one. A self-centered graph is a graph whose diameter equals its radius. Or where the eccentricity of every vertex is the same.,Can a graph be self-centered if it contains a vertex of degree one. The simplest counter example that came to my mind is Path. But how to prove the statement if we consider any graph with a vertex of degree one. A self-centered graph is a graph whose diameter equals its radius. Or where the eccentricity of every vertex is the same.,,"['combinatorics', 'graph-theory', 'discrete-mathematics', 'computer-science']"
7,"Probability question, not sure if I'm doing this right... at least vs exactly.","Probability question, not sure if I'm doing this right... at least vs exactly.",,"So I'm trying to figure a few things out with probability/counting. These a probability questions, but my understanding of the counting behind them is a little fuzzy still. For example, The probability of getting 3 of a kind out of a 5 card poker hand is: COMBIN(13, 1) to choose 1 kind of out the 4 kinds COMBIN(4, 3) to choose 3 cards out of the 1 kind COMBIN(12, 2) to choose the 2 kinds for the last 2 cards (the first card took 1 kind already, so it's 12 instead of 13) (COMBIN(4,1))^2 to choose the 2 cards out the the last kind(s) So, the answer is: (COMBIN(13,1)*COMBIN(4,3) COMBIN(12,2) (COMBIN(4,1))^2)/(COMBIN(52,2)) How would this change if I were to look for AT LEAST 3 cards of the same kind instead of EXACTLY 3 cards of the same kind?","So I'm trying to figure a few things out with probability/counting. These a probability questions, but my understanding of the counting behind them is a little fuzzy still. For example, The probability of getting 3 of a kind out of a 5 card poker hand is: COMBIN(13, 1) to choose 1 kind of out the 4 kinds COMBIN(4, 3) to choose 3 cards out of the 1 kind COMBIN(12, 2) to choose the 2 kinds for the last 2 cards (the first card took 1 kind already, so it's 12 instead of 13) (COMBIN(4,1))^2 to choose the 2 cards out the the last kind(s) So, the answer is: (COMBIN(13,1)*COMBIN(4,3) COMBIN(12,2) (COMBIN(4,1))^2)/(COMBIN(52,2)) How would this change if I were to look for AT LEAST 3 cards of the same kind instead of EXACTLY 3 cards of the same kind?",,"['probability', 'combinatorics', 'discrete-mathematics']"
8,Trouble with proof of Euler's theorem using Multiplicative Inverses,Trouble with proof of Euler's theorem using Multiplicative Inverses,,"I am trying to understand a proof of Euler's theorem, namely the one that states $\gcd(a,n)=1 \implies a^{\phi(n)} = 1 \pmod n$. Here is how my teacher proved an important lemma that leads to the proof of Euler's theorem. Define set $X = \left\{ m \in \mathbb{N} : m \leq n, \gcd(m,n)=1 \right\}$. Now choose $a \in X$. Define $aX = \left\{ ax \pmod n : x \in X \right\}$. Lemma: $aX = X$. Proof: (i) $X \subseteq aX$: Given $x \in X$ we must show $x \in aX$. Consider the number $a^{-1}x \mod n$ ($a^{-1}$ is the multiplicative inverse of $a$ and exists since $a$ is relatively prime to $n$). We claim that $a^{-1}x \mod n \in X$ since it has the multiplicative inverse $x^{-1}a$. Thus $a(a^{-1}x) \equiv x \pmod n \in aX$. ... I'll leave out part two of the lemma, because there is already something I'm not getting. ""We claim that $a^{-1}x \mod n \in X$ since it has the multiplicative inverse $x^{-1}a$."" How does the right half of that sentence imply the left half? I simply don't understand it at all. Would someone care to explain?","I am trying to understand a proof of Euler's theorem, namely the one that states $\gcd(a,n)=1 \implies a^{\phi(n)} = 1 \pmod n$. Here is how my teacher proved an important lemma that leads to the proof of Euler's theorem. Define set $X = \left\{ m \in \mathbb{N} : m \leq n, \gcd(m,n)=1 \right\}$. Now choose $a \in X$. Define $aX = \left\{ ax \pmod n : x \in X \right\}$. Lemma: $aX = X$. Proof: (i) $X \subseteq aX$: Given $x \in X$ we must show $x \in aX$. Consider the number $a^{-1}x \mod n$ ($a^{-1}$ is the multiplicative inverse of $a$ and exists since $a$ is relatively prime to $n$). We claim that $a^{-1}x \mod n \in X$ since it has the multiplicative inverse $x^{-1}a$. Thus $a(a^{-1}x) \equiv x \pmod n \in aX$. ... I'll leave out part two of the lemma, because there is already something I'm not getting. ""We claim that $a^{-1}x \mod n \in X$ since it has the multiplicative inverse $x^{-1}a$."" How does the right half of that sentence imply the left half? I simply don't understand it at all. Would someone care to explain?",,"['elementary-number-theory', 'discrete-mathematics', 'modular-arithmetic']"
9,probability of hand with at least 2 kings,probability of hand with at least 2 kings,,"A hand $H$ of 5 cards is chosen randomly from a standard deck of 52. Let $E_1$ be the event that H has at least one King and let $E_2$ be the event that $H$ has at least 2 Kings. What is the conditional probability $\mathbb P(E_2|E_1)$ ? Solution: $$\mathbb P(E_2|E_1)=1-\frac{4\binom{48}4}{\binom{52}5-\binom{48}5}.$$ Would this be a correct solution (obtained by looking at a similar problem)? I'm a bit confused by this solution, can someone walk me through it so I can understand.","A hand of 5 cards is chosen randomly from a standard deck of 52. Let be the event that H has at least one King and let be the event that has at least 2 Kings. What is the conditional probability ? Solution: Would this be a correct solution (obtained by looking at a similar problem)? I'm a bit confused by this solution, can someone walk me through it so I can understand.",H E_1 E_2 H \mathbb P(E_2|E_1) \mathbb P(E_2|E_1)=1-\frac{4\binom{48}4}{\binom{52}5-\binom{48}5}.,"['probability', 'combinatorics', 'discrete-mathematics']"
10,Total length of pieces after splitting,Total length of pieces after splitting,,"If I consider the number line from $0$ to $n$ and cut it into $x$ pieces, it is well known that there is at least one stretch of length at least $n/x$. My question is what is the minimum total length of all the pieces of length at least $y$. For example, if I split the line into three pieces and set $y = \frac{n}{3}$ then by making one piece fractionally greater than $\frac{n}{3}$ and the other two smaller, we can make the total length fractionally greater than $\frac{n}{3}$. If we set $y=\frac{n}{4}$ keeping $x=3$ then the minimum total length seems to be just over  $\frac{n}{2}$.  From this one can guess an answer of $n-(x-1)y$. Is this the correct answer and how can one prove it?","If I consider the number line from $0$ to $n$ and cut it into $x$ pieces, it is well known that there is at least one stretch of length at least $n/x$. My question is what is the minimum total length of all the pieces of length at least $y$. For example, if I split the line into three pieces and set $y = \frac{n}{3}$ then by making one piece fractionally greater than $\frac{n}{3}$ and the other two smaller, we can make the total length fractionally greater than $\frac{n}{3}$. If we set $y=\frac{n}{4}$ keeping $x=3$ then the minimum total length seems to be just over  $\frac{n}{2}$.  From this one can guess an answer of $n-(x-1)y$. Is this the correct answer and how can one prove it?",,['combinatorics']
11,determining the independence of coin flips,determining the independence of coin flips,,"i'm a bit confused by this example. what confuses me the most is how to calculate Pr(E 1 ), Pr(E 2 ), Pr(E 3 ), can someone explain A fair coin is flipped 3 times. If (F 1 , F 2 , F 3 ) denotes a typical flip sequence, let E 1 denote the event that at least two of the F i 's are Heads, let E 2 denote the event that exactly two of the F i 's are Heads, and let E 3 denote the event that all the F i are the same. Which of the pairs of these three events are independent? Solution: The only pair that is independent is E 1 and E 3 . Since Pr(E 1 ) = (1/2) 3 + (3 choose 2)(1/2) 3 = 1/2 and Pr(E 3 ) = 2* (1/2) 3 = 1/4, so Pr(E 1 ∩ E 3 ) = Pr(all heads) = 1/8 = Pr(E 1 )Pr(E 3 ), while Pr(E 1 ∩ E 2 )=Pr(E 2 ) and Pr (E 2 ∩ E 3 )=0","i'm a bit confused by this example. what confuses me the most is how to calculate Pr(E 1 ), Pr(E 2 ), Pr(E 3 ), can someone explain A fair coin is flipped 3 times. If (F 1 , F 2 , F 3 ) denotes a typical flip sequence, let E 1 denote the event that at least two of the F i 's are Heads, let E 2 denote the event that exactly two of the F i 's are Heads, and let E 3 denote the event that all the F i are the same. Which of the pairs of these three events are independent? Solution: The only pair that is independent is E 1 and E 3 . Since Pr(E 1 ) = (1/2) 3 + (3 choose 2)(1/2) 3 = 1/2 and Pr(E 3 ) = 2* (1/2) 3 = 1/4, so Pr(E 1 ∩ E 3 ) = Pr(all heads) = 1/8 = Pr(E 1 )Pr(E 3 ), while Pr(E 1 ∩ E 2 )=Pr(E 2 ) and Pr (E 2 ∩ E 3 )=0",,"['probability', 'combinatorics', 'discrete-mathematics']"
12,Where is the flaw in the following proof?,Where is the flaw in the following proof?,,"Where is the flaw in the following proof, that if a language is Turing recognizable then we can enumerate it? Proof Let $TM1$ be a Turing machine for language $L$. We can create an enumerator $E$ for $L$ as follows: Repeat the following for $i = 1, 2, 3, \dots$ Run $TM1$ on $S_i$ If accepted, print out $S_i$ Other than the proof being incomplete by not showing an Turing state machine, I cannot think of any flaws in the proof. I would appreciate any help with this problem as I have spent hours on it and don't seem to be making any progress. Many thanks in advance!","Where is the flaw in the following proof, that if a language is Turing recognizable then we can enumerate it? Proof Let $TM1$ be a Turing machine for language $L$. We can create an enumerator $E$ for $L$ as follows: Repeat the following for $i = 1, 2, 3, \dots$ Run $TM1$ on $S_i$ If accepted, print out $S_i$ Other than the proof being incomplete by not showing an Turing state machine, I cannot think of any flaws in the proof. I would appreciate any help with this problem as I have spent hours on it and don't seem to be making any progress. Many thanks in advance!",,"['discrete-mathematics', 'proof-writing', 'turing-machines']"
13,Counting equivalence relations on set of $n$ elements,Counting equivalence relations on set of  elements,n,"I know for a fact that the number of equivalence relations on a n element set is defined by the Bell Number. For the case of $n=4$ the number would be then 15. But question is how do we count them? If I understood correctly, equivalence relations in this case comprise of only 2 elements per relation? So I start off with $(1,2), (1,3), (1,4), (2,3),(2,4), (3,4)$ and multiply by 2 because of symmetry and add $(1,1)...(4,4)$ to account for reflexivity. Transitivity has been accounted for when we multiplied the first step by 2. Wouldn't I then get 16 instead of 15? Or is my understanding of the concept wrong?","I know for a fact that the number of equivalence relations on a n element set is defined by the Bell Number. For the case of $n=4$ the number would be then 15. But question is how do we count them? If I understood correctly, equivalence relations in this case comprise of only 2 elements per relation? So I start off with $(1,2), (1,3), (1,4), (2,3),(2,4), (3,4)$ and multiply by 2 because of symmetry and add $(1,1)...(4,4)$ to account for reflexivity. Transitivity has been accounted for when we multiplied the first step by 2. Wouldn't I then get 16 instead of 15? Or is my understanding of the concept wrong?",,"['elementary-set-theory', 'discrete-mathematics']"
14,Are these statements logically equivalent? (quantifiers),Are these statements logically equivalent? (quantifiers),,"Is $\forall x(P(x) \vee Q(y))$ the same as $(\forall x P(x)) \vee Q(y)$? I understand that if I had $\forall x(P(x) \vee Q(x))$, that it is not the same as $(\forall x P(x)) \vee (\forall x Q(x))$. However the presence of a second variable is really throwing me off, and I don't understand how to think up an example to see if they are equivalent.","Is $\forall x(P(x) \vee Q(y))$ the same as $(\forall x P(x)) \vee Q(y)$? I understand that if I had $\forall x(P(x) \vee Q(x))$, that it is not the same as $(\forall x P(x)) \vee (\forall x Q(x))$. However the presence of a second variable is really throwing me off, and I don't understand how to think up an example to see if they are equivalent.",,"['logic', 'discrete-mathematics', 'quantifiers']"
15,Proving a language is regular or irregular,Proving a language is regular or irregular,,"I am having a really difficult time writing proofs for these problems. I would greatly appreciate any suggestions for a strategy on how to look at such problems and begin writing a proof. Trying to create a DFA for L1, I found that the language is in fact regular. But I am unsure how to begin to prove it. L1: {w | contains the same number of occurrences of 01 as 10} L2: {w | contains the same number of occurrences of 00 as 11} I appreciate any help with these. Many Thanks in advance.","I am having a really difficult time writing proofs for these problems. I would greatly appreciate any suggestions for a strategy on how to look at such problems and begin writing a proof. Trying to create a DFA for L1, I found that the language is in fact regular. But I am unsure how to begin to prove it. L1: {w | contains the same number of occurrences of 01 as 10} L2: {w | contains the same number of occurrences of 00 as 11} I appreciate any help with these. Many Thanks in advance.",,"['discrete-mathematics', 'formal-languages', 'regular-language']"
16,"Let $G=(V=X \cup Y,E)$ be a bipartite graph.Show that G has a matching which matches every vertex of X.",Let  be a bipartite graph.Show that G has a matching which matches every vertex of X.,"G=(V=X \cup Y,E)","I have a similar question to this on my test tomorrow. Any help towards this question will help Let $G=(V=X \cup  Y,E)$ be a bipartite graph. Suppose that the degree of each vertex d(v)≥1. Assume also that for each edge xy with x∈ X, we have d(x)≥d(y). Show that G has a matching which matches every vertex of X. Hint. It is enough to show that Hall's condition holds on the X-side, since if a matching has an unmatched X-vertex, we can then use our algorithmic proof of Hall's Theorem to make it larger (and saturating one extra vertex of X)","I have a similar question to this on my test tomorrow. Any help towards this question will help Let $G=(V=X \cup  Y,E)$ be a bipartite graph. Suppose that the degree of each vertex d(v)≥1. Assume also that for each edge xy with x∈ X, we have d(x)≥d(y). Show that G has a matching which matches every vertex of X. Hint. It is enough to show that Hall's condition holds on the X-side, since if a matching has an unmatched X-vertex, we can then use our algorithmic proof of Hall's Theorem to make it larger (and saturating one extra vertex of X)",,"['combinatorics', 'graph-theory', 'discrete-mathematics']"
17,Consider the sequence 01110100...,Consider the sequence 01110100...,,"Consider the sequence 01110100 as being arranged in a circular pattern. Notice that every one of the eight possible binary triples: 000, 001, 011, . . . , 111 appear exactly once in the circular list. Can you construct a similar list of length 16 where all the four binary digit patterns appear exactly once each? Any ideas would be greatly appreciated. Thank's.","Consider the sequence 01110100 as being arranged in a circular pattern. Notice that every one of the eight possible binary triples: 000, 001, 011, . . . , 111 appear exactly once in the circular list. Can you construct a similar list of length 16 where all the four binary digit patterns appear exactly once each? Any ideas would be greatly appreciated. Thank's.",,"['probability', 'graph-theory', 'discrete-mathematics']"
18,Discrete Mathematics - Ice Cream random samples,Discrete Mathematics - Ice Cream random samples,,"How would you solve the following problem with Discrete Mathematics, and what is the answer? Suppose there are 5 different types of ice cream you like. How many random samples ice cream must be eaten to guarantee that you have had at least 7 samples of one type?","How would you solve the following problem with Discrete Mathematics, and what is the answer? Suppose there are 5 different types of ice cream you like. How many random samples ice cream must be eaten to guarantee that you have had at least 7 samples of one type?",,"['discrete-mathematics', 'pigeonhole-principle']"
19,Length of Shortest Path in a Generated Binary Tree,Length of Shortest Path in a Generated Binary Tree,,"Let's say I have a binary tree of $2$-tuples of positive integers starting with $(1,1)$. The left-child of any element $(A,B)$ is $(A,A+B)$, and the right-child of any element is $(A+B,A)$. Hence, the parent of $(A,B)$ is $(\min(A,B), |A-B|)$. Is there an expression for the length of the shortest path from $(A,B)$ to $(1,1)$, in terms of just $A$ and $B$? There is an obvious recursive algorithm, but I am more interested in a closed-form expression.","Let's say I have a binary tree of $2$-tuples of positive integers starting with $(1,1)$. The left-child of any element $(A,B)$ is $(A,A+B)$, and the right-child of any element is $(A+B,A)$. Hence, the parent of $(A,B)$ is $(\min(A,B), |A-B|)$. Is there an expression for the length of the shortest path from $(A,B)$ to $(1,1)$, in terms of just $A$ and $B$? There is an obvious recursive algorithm, but I am more interested in a closed-form expression.",,"['discrete-mathematics', 'trees']"
20,Combination Problem With Relations?,Combination Problem With Relations?,,"The question is, ""How many nonzero entries does the matrix representing the relation $R$ on  $A = \{1,2,3,...,100\}$ consisting of the first $100$ positive integers have if $R = \{(a, b)|a>b\}$ Well, I know that $|A\times A|=100^2$. I also know that any of the ordered pairs where the first element in the pair is one won't won't be in the relation. There is only one ordered pair where 2 is the first element in the ordered pair, and satisfies the condition to be admitted into the relation, namely, $(2,1)$;in a similar fashion, for three, there are only the ordered-pairs $(3, 1)$ and $(3, 2)$. I know that I am required to use some sort of counting techniques, but I am not sure how to implement them. I would appreciate your help, thank you! I have another one, the relation is still on the same set, except the condition for an ordered-pair to be in the relation is different: $\{(a,b)|a=b+1\}$. I rewrote the condition as  $a-b=1$, just because it was a little more comprehensive. I reasoned that, for the first row, there will be all in zeros in it; because if $a=1$ and $b=1$, the difference would be zero, which wouldn't satisfy the condition; furthermore, the b values, from then on, become increasingly larger, resulting in negative number differences. I knew from this that the rest of the ninety-nine rows would have at least one  element in the row that was one. But as I went out to the fourth row, things became a little more tricky than I suspected. In the forth row, the first element is a zero, (4, 1) doesn't satisfy the condition; but the third element in the fourth row is a 1, (4,3) satisfies the condition. So, I am having a little trouble seeing the pattern.","The question is, ""How many nonzero entries does the matrix representing the relation $R$ on  $A = \{1,2,3,...,100\}$ consisting of the first $100$ positive integers have if $R = \{(a, b)|a>b\}$ Well, I know that $|A\times A|=100^2$. I also know that any of the ordered pairs where the first element in the pair is one won't won't be in the relation. There is only one ordered pair where 2 is the first element in the ordered pair, and satisfies the condition to be admitted into the relation, namely, $(2,1)$;in a similar fashion, for three, there are only the ordered-pairs $(3, 1)$ and $(3, 2)$. I know that I am required to use some sort of counting techniques, but I am not sure how to implement them. I would appreciate your help, thank you! I have another one, the relation is still on the same set, except the condition for an ordered-pair to be in the relation is different: $\{(a,b)|a=b+1\}$. I rewrote the condition as  $a-b=1$, just because it was a little more comprehensive. I reasoned that, for the first row, there will be all in zeros in it; because if $a=1$ and $b=1$, the difference would be zero, which wouldn't satisfy the condition; furthermore, the b values, from then on, become increasingly larger, resulting in negative number differences. I knew from this that the rest of the ninety-nine rows would have at least one  element in the row that was one. But as I went out to the fourth row, things became a little more tricky than I suspected. In the forth row, the first element is a zero, (4, 1) doesn't satisfy the condition; but the third element in the fourth row is a 1, (4,3) satisfies the condition. So, I am having a little trouble seeing the pattern.",,"['combinatorics', 'discrete-mathematics', 'relations']"
21,How does this prove that P(k) of every k is true?,How does this prove that P(k) of every k is true?,,"This is an example from my textbook. I'm very rusty with simplifying algebraic expression so i hope you'll forgive me for that. The textbook says there are two rules to Mathematical Induction: 1) We must first prove that $P(1)$ is true. 2) We must then assume that $P(k)$ is true and prove that $P(k+1)$ is true. Show that if n is a positive integer, then $1 + 2+· · ·+n =\frac{ n(n + 1)} 2$ For the inductive hypothesis we assume that P(k) holds for an arbitrary positive integer k. That is, we assume that $1 + 2+· · ·+k = \frac{k(k + 1)}  2$ . Under this assumption, it must be shown that P(k + 1) is true, namely, that $1 + 2+· · ·+k + (k + 1) =\frac {(k + 1)((k + 1) + 1)} 2= \frac{(k + 1)(k + 2)} 2$ is also true. When we add $k + 1$ to both sides of the equation in P(k), we obtain $1 + 2+· · ·+k + (k + 1)  =\frac{k(k + 1)} 2 + (k + 1) = \frac{k(k + 1) + 2(k + 1)} 2$ $= \frac{(k + 1)(k + 2)} 2$ . This last equation shows that P(k + 1) is true under the assumption that P(k) is true. This completes the inductive step. My question is how this proves that $P(k+1)$ is true? Also, why does textbook add $k+1$ to both sides of the equation?","This is an example from my textbook. I'm very rusty with simplifying algebraic expression so i hope you'll forgive me for that. The textbook says there are two rules to Mathematical Induction: 1) We must first prove that $P(1)$ is true. 2) We must then assume that $P(k)$ is true and prove that $P(k+1)$ is true. Show that if n is a positive integer, then $1 + 2+· · ·+n =\frac{ n(n + 1)} 2$ For the inductive hypothesis we assume that P(k) holds for an arbitrary positive integer k. That is, we assume that $1 + 2+· · ·+k = \frac{k(k + 1)}  2$ . Under this assumption, it must be shown that P(k + 1) is true, namely, that $1 + 2+· · ·+k + (k + 1) =\frac {(k + 1)((k + 1) + 1)} 2= \frac{(k + 1)(k + 2)} 2$ is also true. When we add $k + 1$ to both sides of the equation in P(k), we obtain $1 + 2+· · ·+k + (k + 1)  =\frac{k(k + 1)} 2 + (k + 1) = \frac{k(k + 1) + 2(k + 1)} 2$ $= \frac{(k + 1)(k + 2)} 2$ . This last equation shows that P(k + 1) is true under the assumption that P(k) is true. This completes the inductive step. My question is how this proves that $P(k+1)$ is true? Also, why does textbook add $k+1$ to both sides of the equation?",,"['algebra-precalculus', 'discrete-mathematics', 'induction']"
22,Why are choices expressed the way they are?,Why are choices expressed the way they are?,,"When I see a problem such as ""Given a rod of length $n$ inches, how many ways can you cut it? Components after the cut should have integer inch lengths."", I immediately know that the answer is $2^{n-1}$ since we have an independent option of cutting or not cutting at distance $i$ inches from the left end. However, I have forgotten why is it so? I know I have 2 options, and I know that we have $n-1$ points where the rod can be cut (or not). But, why is $n-1$ the exponent of $2$?","When I see a problem such as ""Given a rod of length $n$ inches, how many ways can you cut it? Components after the cut should have integer inch lengths."", I immediately know that the answer is $2^{n-1}$ since we have an independent option of cutting or not cutting at distance $i$ inches from the left end. However, I have forgotten why is it so? I know I have 2 options, and I know that we have $n-1$ points where the rod can be cut (or not). But, why is $n-1$ the exponent of $2$?",,"['combinatorics', 'discrete-mathematics']"
23,"An Upper Bound for an $[n,k,d]$ Linear Binary Code.",An Upper Bound for an  Linear Binary Code.,"[n,k,d]","I've been reading about the various upper bounds for different types of codes. Recently, I came across a statement that is similar to the Singleton Upper Bound that I am having trouble proving. The statement is as follows. Let $\mathcal{C}$ be an $[n, k, d]$ linear binary code. If $k \geq 5$ and $d \geq 3$, then $k \leq n - d - 1$. My strategy has been to assume $k > n - d - 1$ and arrive at a contradiction using the fact that $d \geq 3$ and $k \geq 5$, but I'm not having any luck. Any suggestions would be greatly appreciated. Thank you! EDIT Instead of my original strategy, I've been looking at the $k \times n$ generator matrix $G$ of $\mathcal{C}$ in standard form along with the $(n-k) \times n$ parity check matrix $H$ and using the fact that $d \geq 3$ means that the columns in $H$ are nonzero and distinct. Since $H$ has $n-k$ rows, then it can have at most $2^{n-k} - 1$ columns. I haven't been able to make any progress from this point using the fact that $k \geq 5$.","I've been reading about the various upper bounds for different types of codes. Recently, I came across a statement that is similar to the Singleton Upper Bound that I am having trouble proving. The statement is as follows. Let $\mathcal{C}$ be an $[n, k, d]$ linear binary code. If $k \geq 5$ and $d \geq 3$, then $k \leq n - d - 1$. My strategy has been to assume $k > n - d - 1$ and arrive at a contradiction using the fact that $d \geq 3$ and $k \geq 5$, but I'm not having any luck. Any suggestions would be greatly appreciated. Thank you! EDIT Instead of my original strategy, I've been looking at the $k \times n$ generator matrix $G$ of $\mathcal{C}$ in standard form along with the $(n-k) \times n$ parity check matrix $H$ and using the fact that $d \geq 3$ means that the columns in $H$ are nonzero and distinct. Since $H$ has $n-k$ rows, then it can have at most $2^{n-k} - 1$ columns. I haven't been able to make any progress from this point using the fact that $k \geq 5$.",,"['combinatorics', 'discrete-mathematics', 'upper-lower-bounds', 'coding-theory', 'binary']"
24,What Precalculus knowledge is required before learning Discrete Math Computer Science topics?,What Precalculus knowledge is required before learning Discrete Math Computer Science topics?,,"Below I've listed the chapters from a Precalculus book as well as the author recommended Computer Science chapters from a Discrete Mathematics book. Although these chapters are from two specific books on these subjects I believe the topics are generally the same between any Precalc or Discrete Math book. What Precalculus topics should one know before starting these Discrete Math Computer Science topics?: Discrete Mathematics CS Chapters 1.1 Propositional Logic 1.2 Propositional Equivalences 1.3 Predicates and Quantifiers 1.4 Nested Quantifiers 1.5 Rules of Inference 1.6 Introduction to Proofs 1.7 Proof Methods and Strategy  2.1 Sets 2.2 Set Operations 2.3 Functions 2.4 Sequences and Summations  3.1 Algorithms 3.2 The Growths of Functions 3.3 Complexity of Algorithms 3.4 The Integers and Division 3.5 Primes and Greatest Common Divisors 3.6 Integers and Algorithms 3.8 Matrices  4.1 Mathematical Induction 4.2 Strong Induction and Well-Ordering 4.3 Recursive Definitions and Structural Induction 4.4 Recursive Algorithms 4.5 Program Correctness  5.1 The Basics of Counting 5.2 The Pigeonhole Principle 5.3 Permutations and Combinations 5.6 Generating Permutations and Combinations  6.1 An Introduction to Discrete Probability 6.4 Expected Value and Variance  7.1 Recurrence Relations 7.3 Divide-and-Conquer Algorithms and Recurrence Relations 7.5 Inclusion-Exclusion  8.1 Relations and Their Properties 8.2 n-ary Relations and Their Applications 8.3 Representing Relations 8.5 Equivalence Relations  9.1 Graphs and Graph Models 9.2 Graph Terminology and Special Types of Graphs 9.3 Representing Graphs and Graph Isomorphism 9.4 Connectivity 9.5 Euler and Hamilton Ptahs  10.1 Introduction to Trees 10.2 Application of Trees 10.3 Tree Traversal  11.1 Boolean Functions 11.2 Representing Boolean Functions 11.3 Logic Gates 11.4 Minimization of Circuits  12.1 Language and Grammars 12.2 Finite-State Machines with Output 12.3 Finite-State Machines with No Output 12.4 Language Recognition 12.5 Turing Machines Precalculus R.1 The Real-Number System R.2 Integer Exponents, Scientific Notation, and Order of Operations R.3 Addition, Subtraction, and Multiplication of Polynomials R.4 Factoring R.5 Rational Expressions R.6 Radical Notation and Rational Exponents R.7 The Basics of Equation Solving  1.1 Functions, Graphs, Graphers 1.2 Linear Functions, Slope, and Applications 1.3 Modeling: Data Analysis, Curve Fitting, and Linear Regression 1.4 More on Functions 1.5 Symmetry and Transformations 1.6 Variation and Applications 1.7 Distance, Midpoints, and Circles  2.1 Zeros of Linear Functions and Models 2.2 The Complex Numbers 2.3 Zeros of Quadratic Functions and Models 2.4 Analyzing Graphs of Quadratic Functions 2.5 Modeling: Data Analysis, Curve Fitting, and Quadratic Regression 2.6 Zeros and More Equation Solving 2.7 Solving Inequalities  3.1 Polynomial Functions and Modeling 3.2 Polynomial Division; The Remainder and Factor Theorems 3.3 Theorems about Zeros of Polynomial Funtions 3.4 Rational Functions 3.5 Polynomial and Rational Inequalities  4.1 Composite and Inverse Functions 4.2 Exponential Functions and Graphs 4.3 Logarithmic Functions and Graphs 4.4 Properties of Logarithmic Functions 4.5 Solving Exponential and Logarithmic Equations 4.6 Applications and Models: Growth and Decay  5.1 Systems of Equations in Two Variables 5.2 System of Equations in Three Variables 5.3 Matrices and Systems of Equations 5.4 Matrix Operations 5.5 Inverses of Matrices 5.6 System of Inequalities and Linear Programming 5.7 Partial Fractions  6.1 The Parabola 6.2 The Circle and Ellipse 6.3 The Hyperbola 6.4 Nonlinear Systems of Equations  7.1 Sequences and Series 7.2 Arithmetic Sequences and Series 7.3 Geometric Sequences and Series 7.4 Mathematical Induction 7.5 Combinatorics: Permutations 7.6 Combinatorics: Combinations 7.7 The Binomial Theorem 7.8 Probability","Below I've listed the chapters from a Precalculus book as well as the author recommended Computer Science chapters from a Discrete Mathematics book. Although these chapters are from two specific books on these subjects I believe the topics are generally the same between any Precalc or Discrete Math book. What Precalculus topics should one know before starting these Discrete Math Computer Science topics?: Discrete Mathematics CS Chapters 1.1 Propositional Logic 1.2 Propositional Equivalences 1.3 Predicates and Quantifiers 1.4 Nested Quantifiers 1.5 Rules of Inference 1.6 Introduction to Proofs 1.7 Proof Methods and Strategy  2.1 Sets 2.2 Set Operations 2.3 Functions 2.4 Sequences and Summations  3.1 Algorithms 3.2 The Growths of Functions 3.3 Complexity of Algorithms 3.4 The Integers and Division 3.5 Primes and Greatest Common Divisors 3.6 Integers and Algorithms 3.8 Matrices  4.1 Mathematical Induction 4.2 Strong Induction and Well-Ordering 4.3 Recursive Definitions and Structural Induction 4.4 Recursive Algorithms 4.5 Program Correctness  5.1 The Basics of Counting 5.2 The Pigeonhole Principle 5.3 Permutations and Combinations 5.6 Generating Permutations and Combinations  6.1 An Introduction to Discrete Probability 6.4 Expected Value and Variance  7.1 Recurrence Relations 7.3 Divide-and-Conquer Algorithms and Recurrence Relations 7.5 Inclusion-Exclusion  8.1 Relations and Their Properties 8.2 n-ary Relations and Their Applications 8.3 Representing Relations 8.5 Equivalence Relations  9.1 Graphs and Graph Models 9.2 Graph Terminology and Special Types of Graphs 9.3 Representing Graphs and Graph Isomorphism 9.4 Connectivity 9.5 Euler and Hamilton Ptahs  10.1 Introduction to Trees 10.2 Application of Trees 10.3 Tree Traversal  11.1 Boolean Functions 11.2 Representing Boolean Functions 11.3 Logic Gates 11.4 Minimization of Circuits  12.1 Language and Grammars 12.2 Finite-State Machines with Output 12.3 Finite-State Machines with No Output 12.4 Language Recognition 12.5 Turing Machines Precalculus R.1 The Real-Number System R.2 Integer Exponents, Scientific Notation, and Order of Operations R.3 Addition, Subtraction, and Multiplication of Polynomials R.4 Factoring R.5 Rational Expressions R.6 Radical Notation and Rational Exponents R.7 The Basics of Equation Solving  1.1 Functions, Graphs, Graphers 1.2 Linear Functions, Slope, and Applications 1.3 Modeling: Data Analysis, Curve Fitting, and Linear Regression 1.4 More on Functions 1.5 Symmetry and Transformations 1.6 Variation and Applications 1.7 Distance, Midpoints, and Circles  2.1 Zeros of Linear Functions and Models 2.2 The Complex Numbers 2.3 Zeros of Quadratic Functions and Models 2.4 Analyzing Graphs of Quadratic Functions 2.5 Modeling: Data Analysis, Curve Fitting, and Quadratic Regression 2.6 Zeros and More Equation Solving 2.7 Solving Inequalities  3.1 Polynomial Functions and Modeling 3.2 Polynomial Division; The Remainder and Factor Theorems 3.3 Theorems about Zeros of Polynomial Funtions 3.4 Rational Functions 3.5 Polynomial and Rational Inequalities  4.1 Composite and Inverse Functions 4.2 Exponential Functions and Graphs 4.3 Logarithmic Functions and Graphs 4.4 Properties of Logarithmic Functions 4.5 Solving Exponential and Logarithmic Equations 4.6 Applications and Models: Growth and Decay  5.1 Systems of Equations in Two Variables 5.2 System of Equations in Three Variables 5.3 Matrices and Systems of Equations 5.4 Matrix Operations 5.5 Inverses of Matrices 5.6 System of Inequalities and Linear Programming 5.7 Partial Fractions  6.1 The Parabola 6.2 The Circle and Ellipse 6.3 The Hyperbola 6.4 Nonlinear Systems of Equations  7.1 Sequences and Series 7.2 Arithmetic Sequences and Series 7.3 Geometric Sequences and Series 7.4 Mathematical Induction 7.5 Combinatorics: Permutations 7.6 Combinatorics: Combinations 7.7 The Binomial Theorem 7.8 Probability",,"['algebra-precalculus', 'discrete-mathematics', 'computer-science']"
25,Tautology Proof without truth table,Tautology Proof without truth table,,How would I go about proving this without a truth table? $[(p \lor q) \implies r ] \implies [ \neg r \implies (\neg p \land \neg q)]$,How would I go about proving this without a truth table? $[(p \lor q) \implies r ] \implies [ \neg r \implies (\neg p \land \neg q)]$,,"['discrete-mathematics', 'propositional-calculus']"
26,Equivalence Relation problem?,Equivalence Relation problem?,,"I need help with this problem: Suppose $\sim$ is a relation on a set $S$ which is both symmetric and transitive. Let $A = \{x∈S\ \vert \text{ for some }y∈S, x\sim y\}$. Prove that $\sim$ is an equivalence relation on $A$. could anyone assist me with this or send me some place that will help me understand?","I need help with this problem: Suppose $\sim$ is a relation on a set $S$ which is both symmetric and transitive. Let $A = \{x∈S\ \vert \text{ for some }y∈S, x\sim y\}$. Prove that $\sim$ is an equivalence relation on $A$. could anyone assist me with this or send me some place that will help me understand?",,"['discrete-mathematics', 'equivalence-relations']"
27,"Find the necessary and sufficient conditions on $a$, $b$ so that $ax^2 + b = 0$ has a real solution.","Find the necessary and sufficient conditions on ,  so that  has a real solution.",a b ax^2 + b = 0,"This question is really confusing me, and I'd love some help but not the answer. :D Is it asking: What values of $a$ and $b$ result in a real solution for the equation $ax^2 + b = 0$? $a = b = 0$ would obviously work, but how does $x$ come into play? There'd be infinitely many solutions if $x$ can vary as well ($a = 1$, $x = 1$, $b = -1$, etc.). I understand how necessary and sufficient conditions work in general, but how would it apply here? I know it takes the form of ""If $p$ then $q$"" but I don't see how I could apply that to the question. Is ""If $ax^2 + b = 0$ has a real solution, then $a$ and $b =$ ..."" it?","This question is really confusing me, and I'd love some help but not the answer. :D Is it asking: What values of $a$ and $b$ result in a real solution for the equation $ax^2 + b = 0$? $a = b = 0$ would obviously work, but how does $x$ come into play? There'd be infinitely many solutions if $x$ can vary as well ($a = 1$, $x = 1$, $b = -1$, etc.). I understand how necessary and sufficient conditions work in general, but how would it apply here? I know it takes the form of ""If $p$ then $q$"" but I don't see how I could apply that to the question. Is ""If $ax^2 + b = 0$ has a real solution, then $a$ and $b =$ ..."" it?",,['discrete-mathematics']
28,Proving that a sequence is decreasing,Proving that a sequence is decreasing,,"How could I prove the following statement without using induction? I've been staring at this for the better part of an hour. (To be fair, I'm not very good at proof writing) Thanks in advance! Define a sequence $a_n, n \ge 0,$ inductively by $a_0 = 2,$ and for all $n \ge 0, a_{n+1} = \sqrt{a_n + 1}.$ Using the fact that the polynomial $x^2 - x - 1 < 0$ if and only if $\frac{1-\sqrt{5}}{2} < x < \frac{1+\sqrt{5}}{2}$, prove that for every $n \ge 0, a_n > a_{n+1}.$","How could I prove the following statement without using induction? I've been staring at this for the better part of an hour. (To be fair, I'm not very good at proof writing) Thanks in advance! Define a sequence $a_n, n \ge 0,$ inductively by $a_0 = 2,$ and for all $n \ge 0, a_{n+1} = \sqrt{a_n + 1}.$ Using the fact that the polynomial $x^2 - x - 1 < 0$ if and only if $\frac{1-\sqrt{5}}{2} < x < \frac{1+\sqrt{5}}{2}$, prove that for every $n \ge 0, a_n > a_{n+1}.$",,['sequences-and-series']
29,Proving properties of a sequence,Proving properties of a sequence,,"I just received my first assignment for a mathematical proofs course I am taking this year. We just began the course, and we have so far only covered examples of proofs (how to prove if-then statements in different ways) and the mathematical principle of induction. Here is the question I am having difficulty with: ""Define a sequence $a_n, n \ge 0,$ inductively by $a_0 = 2,$ and for all $n \ge 0, a_{n+1} = \sqrt{a_n + 1}.$ a) Prove that for every $n \ge 0, a_n > \frac{1+\sqrt{5}}{2}.$ b) Prove that for every $n \ge 0, a_n > a_{n+1}.$ (You may use the fact that the polynomial $x^2 - x - 1 < 0$ if and only if $\frac{1-\sqrt{5}}{2} < x < \frac{1+\sqrt{5}}{2}.$ What would be the best proof technique for these questions? Should I prove both using induction, or is there a simpler/better way?","I just received my first assignment for a mathematical proofs course I am taking this year. We just began the course, and we have so far only covered examples of proofs (how to prove if-then statements in different ways) and the mathematical principle of induction. Here is the question I am having difficulty with: ""Define a sequence $a_n, n \ge 0,$ inductively by $a_0 = 2,$ and for all $n \ge 0, a_{n+1} = \sqrt{a_n + 1}.$ a) Prove that for every $n \ge 0, a_n > \frac{1+\sqrt{5}}{2}.$ b) Prove that for every $n \ge 0, a_n > a_{n+1}.$ (You may use the fact that the polynomial $x^2 - x - 1 < 0$ if and only if $\frac{1-\sqrt{5}}{2} < x < \frac{1+\sqrt{5}}{2}.$ What would be the best proof technique for these questions? Should I prove both using induction, or is there a simpler/better way?",,[]
30,"The number of ways to represent $(n^2+n)/4$ as a sum of $n/2$ distinct integers in $1,\dots,n$",The number of ways to represent  as a sum of  distinct integers in,"(n^2+n)/4 n/2 1,\dots,n","For any positive integer $n$ (using integer division only), let $P(n)$ denote the number of ways in which the integer $(n^2+n)/4$ can be expressed as a sum of exactly $n /2$ distinct elements of the set $\{1,2,3,\dots, n\}$ . What is $P(n)$ in terms of n? Specifically, how exponential is it? Is this less than $2^{n/2}$ ?","For any positive integer (using integer division only), let denote the number of ways in which the integer can be expressed as a sum of exactly distinct elements of the set . What is in terms of n? Specifically, how exponential is it? Is this less than ?","n P(n) (n^2+n)/4 n /2 \{1,2,3,\dots, n\} P(n) 2^{n/2}","['combinatorics', 'number-theory', 'discrete-mathematics', 'summation']"
31,Question about Cyclic Group,Question about Cyclic Group,,"$(G,\star)$ is a $n$-order cyclic group, the generator is $x$,   Prove: 1) For any factor $d$ of $n$ exists only one $d$-order subgroup. 2) $b=x^k$ is $G$'s generator if and only if $\gcd(n,k)=1$. 1)Suppose $n=d\cdot m$, then $a^m$ 's order is $d$, but I don't know how to prove there is only one subgroup. 2)I feel the question is too hard for me, but really want to solve it. :) Any ideas? thanks.","$(G,\star)$ is a $n$-order cyclic group, the generator is $x$,   Prove: 1) For any factor $d$ of $n$ exists only one $d$-order subgroup. 2) $b=x^k$ is $G$'s generator if and only if $\gcd(n,k)=1$. 1)Suppose $n=d\cdot m$, then $a^m$ 's order is $d$, but I don't know how to prove there is only one subgroup. 2)I feel the question is too hard for me, but really want to solve it. :) Any ideas? thanks.",,"['group-theory', 'discrete-mathematics']"
32,Defining n-fold Composition of f with itself.,Defining n-fold Composition of f with itself.,,"This is a question on the test review packet I have for discrete mathematics. Given: $f = \{(a, b), (b, a), (c, b)\}$ a function from $X = \{a, b, c\}$ to $X.$ (a) Write $f \circ f$ and $f \circ f \circ f$ as sets of ordered pairs. (b) Define $f^n = f \circ f \circ \ldots \circ f$ to be the $n$-fold composition of $f$ with itself. Write $f^9$ and $f^{623}$ as sets of ordered pairs. For part (a), I believe: $$ f(a) = b\\ f(b) = a\\ f(c) = b\\ f(f) = \{(a, a), (b, b), (c, a)\} \\ f(f(f)) = \{(a, b), (b, a), (c, b)\}$$ I think there is a pattern here with even exponents being equal to $$ f(f) = \{(a, a), (b, b), (c, a)\}$$ and odd being equal to $$f(f(f)) = \{(a, b), (b, a), (c, b)\}.$$ So how do we define $f^n = f \circ f \circ \ldots \circ f$ to be the $n$-fold composition of $f$ with itself? Also I believe, $f^9$ and $f^{623}$ would both be $\{(a, b), (b, a), (c, b)\}.$","This is a question on the test review packet I have for discrete mathematics. Given: $f = \{(a, b), (b, a), (c, b)\}$ a function from $X = \{a, b, c\}$ to $X.$ (a) Write $f \circ f$ and $f \circ f \circ f$ as sets of ordered pairs. (b) Define $f^n = f \circ f \circ \ldots \circ f$ to be the $n$-fold composition of $f$ with itself. Write $f^9$ and $f^{623}$ as sets of ordered pairs. For part (a), I believe: $$ f(a) = b\\ f(b) = a\\ f(c) = b\\ f(f) = \{(a, a), (b, b), (c, a)\} \\ f(f(f)) = \{(a, b), (b, a), (c, b)\}$$ I think there is a pattern here with even exponents being equal to $$ f(f) = \{(a, a), (b, b), (c, a)\}$$ and odd being equal to $$f(f(f)) = \{(a, b), (b, a), (c, b)\}.$$ So how do we define $f^n = f \circ f \circ \ldots \circ f$ to be the $n$-fold composition of $f$ with itself? Also I believe, $f^9$ and $f^{623}$ would both be $\{(a, b), (b, a), (c, b)\}.$",,['discrete-mathematics']
33,Organising a Tournament,Organising a Tournament,,"Imagine the following Problem. The Student Union wants to organise a tournament with 2k participants ( $k \in \mathbb{N}$ ). There are to be m rounds and in each round players should be paired according to some rule s.t. no pair that already met meets again in the same tournament  (i.e. it s not an elimination tournament; each player plays once in each round and gets ranked at the end or whatever ... ) The committee is concerned that after a certain number of rounds a clash will be unavoidable, so they want to come up with the clever way to pair players to avoid this. My question is, how many legal rounds can we be sure of even if we organise it without any consideration for later rounds on an ad-hoc basis round by round. Whats the way to maximise the number of legal rounds and what is that maximum number ? I am also very interested in the way people would model this situation and the reasoning/motivation that leads them to a proof/result.","Imagine the following Problem. The Student Union wants to organise a tournament with 2k participants ( $k \in \mathbb{N}$ ). There are to be m rounds and in each round players should be paired according to some rule s.t. no pair that already met meets again in the same tournament  (i.e. it s not an elimination tournament; each player plays once in each round and gets ranked at the end or whatever ... ) The committee is concerned that after a certain number of rounds a clash will be unavoidable, so they want to come up with the clever way to pair players to avoid this. My question is, how many legal rounds can we be sure of even if we organise it without any consideration for later rounds on an ad-hoc basis round by round. Whats the way to maximise the number of legal rounds and what is that maximum number ? I am also very interested in the way people would model this situation and the reasoning/motivation that leads them to a proof/result.",,"['combinatorics', 'algorithms', 'soft-question', 'graph-theory', 'discrete-mathematics']"
34,Pigeonhole principle to prove division,Pigeonhole principle to prove division,,"Here's a little question that we were shown in class: Let $S = \{1,2,\ldots,200\}$ and let $A \subseteq S$  such that $|A| = 101$.   Prove that there are two elements of $A$ such that one is a divisor of   the other. The proof was fairly easy: the pigeonholes were the pattern $(2k+1)2^i$. You have a $100$ of those and therefor two elements must be in the same pigeonhole. My question: Why a $100$ pigeonholes? Other than that face that this is comfortable and it works, is there any other reason? Can I do the same for $50$ and still be able to give such representation to every number? Thanks","Here's a little question that we were shown in class: Let $S = \{1,2,\ldots,200\}$ and let $A \subseteq S$  such that $|A| = 101$.   Prove that there are two elements of $A$ such that one is a divisor of   the other. The proof was fairly easy: the pigeonholes were the pattern $(2k+1)2^i$. You have a $100$ of those and therefor two elements must be in the same pigeonhole. My question: Why a $100$ pigeonholes? Other than that face that this is comfortable and it works, is there any other reason? Can I do the same for $50$ and still be able to give such representation to every number? Thanks",,"['discrete-mathematics', 'pigeonhole-principle']"
35,Discrete Structures: Bit Strings,Discrete Structures: Bit Strings,,"So my professor gave us an HW assignment which includes this question: ""How many bit strings consist of 1 through 5 bits. (Note 10 and 00010 are considered distinct even though they are both representations for 2)"" My answer is 62. Is this correct? Thanks","So my professor gave us an HW assignment which includes this question: ""How many bit strings consist of 1 through 5 bits. (Note 10 and 00010 are considered distinct even though they are both representations for 2)"" My answer is 62. Is this correct? Thanks",,['discrete-mathematics']
36,"Find formula, which certain truth table","Find formula, which certain truth table",,"I have this truth table, and I must find the right formula. (T = TRUE , V = FALSE) Where should I start with this? I first wrote out everything : A&B&C&D v A&B&C&-D v -A&-B&C&-D etc... But then I was told, that I can solve this even easier. Any suggetions? EDIT: the last column A is the truth value of the correct formula.","I have this truth table, and I must find the right formula. (T = TRUE , V = FALSE) Where should I start with this? I first wrote out everything : A&B&C&D v A&B&C&-D v -A&-B&C&-D etc... But then I was told, that I can solve this even easier. Any suggetions? EDIT: the last column A is the truth value of the correct formula.",,['discrete-mathematics']
37,Hamilton Path properties,Hamilton Path properties,,As I understand a graph has a Hamilton Circuit if It has $n \ge 3$ vertexes degree of every vertex is at least $n/2$ $\deg u + \deg v \ge n$ for every pair of nonadjacent vertices $u$ and $v$ in the graph I can't seem to find a concrete set of properties for deciding if a graph has a Hamilton Path . Can anyone help me out? Please add some references/sources :),As I understand a graph has a Hamilton Circuit if It has $n \ge 3$ vertexes degree of every vertex is at least $n/2$ $\deg u + \deg v \ge n$ for every pair of nonadjacent vertices $u$ and $v$ in the graph I can't seem to find a concrete set of properties for deciding if a graph has a Hamilton Path . Can anyone help me out? Please add some references/sources :),,['discrete-mathematics']
38,"Show that $\mathcal{F}_{G}$ is an Independence System, but in general is no Matroid","Show that  is an Independence System, but in general is no Matroid",\mathcal{F}_{G},"Let $k\in\mathbb{N}$ and $G$ be a graph. Define $$\mathcal{F}_{G}:=\{F\subset E(G): \Delta((V(G),F))\leq k\}$$ I want to show, that $(E(G),\mathcal{F}_{G})$ is always an Independence System but in general $(E(G),\mathcal{F}_{G})$ is no Matroid. My approach: The empty set is always in $\mathcal{F}_{G}$ for every $k$ since the maximum degree $\Delta((V(G),\emptyset))$ is always zero and there for smaller then any valid $k$. Let $B\in\mathcal{F}_{G}$ and $A\subset B$. Since $B\in\mathcal{F}_{G}$ it is true that the maximum degree $\Delta((V(G),B))\leq k$. And because $A$ is a subset of edges of $B$ it is true, that for every node $v\in A$: $\delta(v)_A\leq\delta(v)_B$, meaning $\Delta((V(G),A))\leq\Delta((V(G),B))\leq k$. To show, that this construction does not hold in general for Matroids, I tried to build an example, that breaks the exchange property ( M3 ) of Matroids. So have to find a set $A$ and a set $B$ such that $|A|>|B|$ and there is no edge e in $A$, that I can add to $B$ such that $\Delta((V(G),B\cup\{e\}))\leq k$ is true. Right? I considered loops and double edges in my counter examples, but I couldn't find one that actually breaks the property. Any suggestions?","Let $k\in\mathbb{N}$ and $G$ be a graph. Define $$\mathcal{F}_{G}:=\{F\subset E(G): \Delta((V(G),F))\leq k\}$$ I want to show, that $(E(G),\mathcal{F}_{G})$ is always an Independence System but in general $(E(G),\mathcal{F}_{G})$ is no Matroid. My approach: The empty set is always in $\mathcal{F}_{G}$ for every $k$ since the maximum degree $\Delta((V(G),\emptyset))$ is always zero and there for smaller then any valid $k$. Let $B\in\mathcal{F}_{G}$ and $A\subset B$. Since $B\in\mathcal{F}_{G}$ it is true that the maximum degree $\Delta((V(G),B))\leq k$. And because $A$ is a subset of edges of $B$ it is true, that for every node $v\in A$: $\delta(v)_A\leq\delta(v)_B$, meaning $\Delta((V(G),A))\leq\Delta((V(G),B))\leq k$. To show, that this construction does not hold in general for Matroids, I tried to build an example, that breaks the exchange property ( M3 ) of Matroids. So have to find a set $A$ and a set $B$ such that $|A|>|B|$ and there is no edge e in $A$, that I can add to $B$ such that $\Delta((V(G),B\cup\{e\}))\leq k$ is true. Right? I considered loops and double edges in my counter examples, but I couldn't find one that actually breaks the property. Any suggestions?",,"['graph-theory', 'discrete-mathematics', 'matroids']"
39,"Determine whether the relations are symmetric or partially ordered, or totally ordered?","Determine whether the relations are symmetric or partially ordered, or totally ordered?",,"Determine whether the relations $R$ on the real numbers $x, y$ given below are symmetric or partially ordered. Are they totally ordered? $x \geq y$","Determine whether the relations $R$ on the real numbers $x, y$ given below are symmetric or partially ordered. Are they totally ordered? $x \geq y$",,"['discrete-mathematics', 'relations', 'order-theory']"
40,Issue with permutation problem,Issue with permutation problem,,"The question is: Given a licence plate that can have either 2 or 3 letters followed by either 2 or 3 numbers, how many different license plates can be printed. My math is as such $(26^2 + 26^3)*(9^2+9^3)$ which comes to 14,784,120 but the book says the answer is 20,077,200. What am I doing wrong here?","The question is: Given a licence plate that can have either 2 or 3 letters followed by either 2 or 3 numbers, how many different license plates can be printed. My math is as such $(26^2 + 26^3)*(9^2+9^3)$ which comes to 14,784,120 but the book says the answer is 20,077,200. What am I doing wrong here?",,"['discrete-mathematics', 'permutations']"
41,Constructing Paths in a Connected Graph with Odd-Degree Vertices,Constructing Paths in a Connected Graph with Odd-Degree Vertices,,"I am working on a problem and would appreciate some insights or suggestions on how to approach it. Problem: Let G = (V, E) be a connected graph where n is the number of vertices in V that are of odd degree. How can one construct n/2 trails in G such that each edge in E is contained in exactly one of these trails? (edit: replaced path with trail) My solution: By the Handshaking Lemma, the number of vertices of odd degree is even; thus, n/2 will always be a positive integer. Construct pairs of vertices of odd degree such that no vertex of odd degree is left unpaired. Construct a path between each pair such that the path contains only vertices of even degree between the start and end vertices. According to the theorem discussed in the lecture, it follows that this path is Eulerian. Now, remove the edges of the Eulerian path from the graph and repeat the process with all remaining pairs of vertices.","I am working on a problem and would appreciate some insights or suggestions on how to approach it. Problem: Let G = (V, E) be a connected graph where n is the number of vertices in V that are of odd degree. How can one construct n/2 trails in G such that each edge in E is contained in exactly one of these trails? (edit: replaced path with trail) My solution: By the Handshaking Lemma, the number of vertices of odd degree is even; thus, n/2 will always be a positive integer. Construct pairs of vertices of odd degree such that no vertex of odd degree is left unpaired. Construct a path between each pair such that the path contains only vertices of even degree between the start and end vertices. According to the theorem discussed in the lecture, it follows that this path is Eulerian. Now, remove the edges of the Eulerian path from the graph and repeat the process with all remaining pairs of vertices.",,"['discrete-mathematics', 'graph-theory', 'eulerian-path']"
42,Proving (p → r) ∨ (q → r) ≡ (p ∧ q) → r,Proving (p → r) ∨ (q → r) ≡ (p ∧ q) → r,,"So I do understand that this could be much more easily proven using basic logical equivalences as follows: (p → r) ∨ (q → r) ≡ (¬p ∨ r) ∨ (¬q ∨ r) ≡ (¬p ∨ ¬q) ∨ r ≡ ¬(p ∧ q) ∨ r ≡ (p ∧ q) → r However, since (p → r) ∨ (q → r) ≡ (p ∧ q) → r is the same as (p → r) ∨ (q → r) ↔ (p ∧ q) → r being a tautology, I thought why not try proving the bi-conditional statement by doing direct proof both directions: For the ((p → r) ∨ (q → r)) → ((p ∧ q) → r) part: To prove this conditional, we'd have to assume (p → r) ∨ (q → r) is true and show (p ∧ q) → r becomes true from it. To show (p ∧ q) → r is true, we'd have to assume (p ∧ q) is true and r is true. Hence, we'd be assuming both (p → r) ∨ (q → r) and (p ∧ q) are true. (p → r) ∨ (q → r) means at least one of the 2 implications that give the consequence of r is true, and since both p and q are true this means r must also be true. Hence proof complete for forward implication. For the ((p ∧ q) → r) → ((p → r) ∨ (q → r)) part: This one was the main point of confusion (and what my question is all about) . Proving a implication with a disjunction as the consequent was something I was unsure how to do (and what I've seen many other people have asked too online unsure about). So I just did some logical equivalences (where for propositions x, y, and z, [x → (y ∨ z)] ≡ [(x ∧ ¬y) -> z]). to get this expression is equivalent to ((p ∧ q) → r) ∧ p ∧ ¬r) → (q → r). Therefore, I first assumed LHS was true, then assume q is true. Assuming LHS true means all propositions in conjunction are true, meaning p and ¬r should be true (meaning r is false). So LHS is hence ((T ∧ T) → F) ∧ T ∧ T) = F ∧ T ∧ T = F. Hence there's a contradiction. This last part/contradiction is what's confusing me here. What do I take from this part of the proof exactly? Is the entire implication now proven true vacuously or something? I'm lost here essentially. Kindly please let me know.","So I do understand that this could be much more easily proven using basic logical equivalences as follows: (p → r) ∨ (q → r) ≡ (¬p ∨ r) ∨ (¬q ∨ r) ≡ (¬p ∨ ¬q) ∨ r ≡ ¬(p ∧ q) ∨ r ≡ (p ∧ q) → r However, since (p → r) ∨ (q → r) ≡ (p ∧ q) → r is the same as (p → r) ∨ (q → r) ↔ (p ∧ q) → r being a tautology, I thought why not try proving the bi-conditional statement by doing direct proof both directions: For the ((p → r) ∨ (q → r)) → ((p ∧ q) → r) part: To prove this conditional, we'd have to assume (p → r) ∨ (q → r) is true and show (p ∧ q) → r becomes true from it. To show (p ∧ q) → r is true, we'd have to assume (p ∧ q) is true and r is true. Hence, we'd be assuming both (p → r) ∨ (q → r) and (p ∧ q) are true. (p → r) ∨ (q → r) means at least one of the 2 implications that give the consequence of r is true, and since both p and q are true this means r must also be true. Hence proof complete for forward implication. For the ((p ∧ q) → r) → ((p → r) ∨ (q → r)) part: This one was the main point of confusion (and what my question is all about) . Proving a implication with a disjunction as the consequent was something I was unsure how to do (and what I've seen many other people have asked too online unsure about). So I just did some logical equivalences (where for propositions x, y, and z, [x → (y ∨ z)] ≡ [(x ∧ ¬y) -> z]). to get this expression is equivalent to ((p ∧ q) → r) ∧ p ∧ ¬r) → (q → r). Therefore, I first assumed LHS was true, then assume q is true. Assuming LHS true means all propositions in conjunction are true, meaning p and ¬r should be true (meaning r is false). So LHS is hence ((T ∧ T) → F) ∧ T ∧ T) = F ∧ T ∧ T = F. Hence there's a contradiction. This last part/contradiction is what's confusing me here. What do I take from this part of the proof exactly? Is the entire implication now proven true vacuously or something? I'm lost here essentially. Kindly please let me know.",,"['discrete-mathematics', 'logic', 'propositional-calculus', 'alternative-proof', 'natural-deduction']"
43,Multicolor Ramsey Number - prove lower bound,Multicolor Ramsey Number - prove lower bound,,"Prove lower bound $R(3, n, m) > 2 R(n, m) - 2$ where $m, n > 2$ I guess if we wanna prove that $R(3, n, m) > N$ we need to show an example of construction that would have $N$ vertices and would not match the definition. But I can't come up with such an example",Prove lower bound where I guess if we wanna prove that we need to show an example of construction that would have vertices and would not match the definition. But I can't come up with such an example,"R(3, n, m) > 2 R(n, m) - 2 m, n > 2 R(3, n, m) > N N","['discrete-mathematics', 'graph-theory', 'ramsey-theory']"
44,Derivation of the characteristic polynomial for homogenous difference equations,Derivation of the characteristic polynomial for homogenous difference equations,,"I'm struggling to find a resource that proves every solution to the homogenous difference equation $$ a_n = c_1a_{n-1} + c_2a_{n-2} + \dots + c_da_{n-d}.  $$ is of the form $$ a_n = k_1n^{p_1}r^n + k_2n^{p_2}r^n + \dots + k_nn^{p_n}r^n.  $$ where $r$ is a root of the characteristic polynomial $$ q(\lambda) = \lambda^d + a_1\lambda^{d-1} + a_2\lambda^{d-2} + \dots + a_d $$ and and $p_i$ is an integer of at least zero, but less than the multiplicity of $r$ . From this Wikipedia article it seems one can do this using matrices / eigenvalues or generating functions, but I can't find how. I understand that from the first-order $a_n = ra_{n-1}$ we can easily see $a_n = r^na_0$ and we can ""ansatz"" from there, but I would really like to see a proof that shows how you arrive here or at least how to start. Thanks.","I'm struggling to find a resource that proves every solution to the homogenous difference equation is of the form where is a root of the characteristic polynomial and and is an integer of at least zero, but less than the multiplicity of . From this Wikipedia article it seems one can do this using matrices / eigenvalues or generating functions, but I can't find how. I understand that from the first-order we can easily see and we can ""ansatz"" from there, but I would really like to see a proof that shows how you arrive here or at least how to start. Thanks.","
a_n = c_1a_{n-1} + c_2a_{n-2} + \dots + c_da_{n-d}. 
 
a_n = k_1n^{p_1}r^n + k_2n^{p_2}r^n + \dots + k_nn^{p_n}r^n. 
 r 
q(\lambda) = \lambda^d + a_1\lambda^{d-1} + a_2\lambda^{d-2} + \dots + a_d
 p_i r a_n = ra_{n-1} a_n = r^na_0","['linear-algebra', 'combinatorics', 'discrete-mathematics', 'recurrence-relations']"
45,"How many six-digit numbers, formed by using digits from $1$ to $6$ with repetititon, are divisible by 3？","How many six-digit numbers, formed by using digits from  to  with repetititon, are divisible by 3？",1 6,The six-digit number can be formed by any number between $1$ and $6$ . The digits can be repeated. My question is how many six-digit numbers like this are divisible by $3$ ? The answer is $2 \cdot 6^5$ . I cannot understand how to deduce it.,The six-digit number can be formed by any number between and . The digits can be repeated. My question is how many six-digit numbers like this are divisible by ? The answer is . I cannot understand how to deduce it.,1 6 3 2 \cdot 6^5,"['combinatorics', 'discrete-mathematics', 'permutations']"
46,Are these two notions of weak well-foundedness equivalent?,Are these two notions of weak well-foundedness equivalent?,,"Background (optional): I have a state transition system $Q$ with two ""kinds"" of transitions: progress-making ( $\delta_P : Q \times \Sigma \rightarrow Q$ ) and non-progress making ( $\delta_N : Q \times \Sigma \rightarrow Q$ ). I want to say that it is not possible for the system to undergo a progress making transition infinitely many times without ever terminating. However, in my case, it would be much simpler to deal with a well-founded relation on an encoding of the state which always decreases when progress is made. I have simplified the mathematical content of my situation into the following: suppose we have two relations on $Q$ : $\approx$ and $>$ (despite the notation, they are not necessarily transitive, reflexive, etc.). Are the following two equivalent: There is no infinite sequence $q_1 > q_2 \approx q_3 \approx q_4 > q_5 > \cdots$ where each $q_{i+1}$ is either $q_i > q_{i+1}$ or $q_i \approx q_{i+1}$ , and $q_i > q_{i+1}$ infinitely often. There is some function $f : Q \rightarrow R$ and a relation $>_R$ on $R$ such that $>_R$ is well-founded in the usual sense for any $q_a > q_b$ , we have $f(q_a) >_R f(q_b)$ for any $q_a \approx q_b$ , either $f(q_a) >_R f(q_b)$ or $f(q_a) = f(q_b)$ It is clear that (2) implies (1), since any sequence $q_1 > q_2 \approx q_3 > \cdots$ would satisfy $f(q_1) >_R f(q_2) = f(q_3) >_R \cdots$ . Even after contracting the equalities, which are a subset of the relations that were originally $\approx$ , we are still left with an infinite decreasing sequence, contradicting $>_R$ 's well-foundedness. On the other hand, I'm not sure that (1) implies (2). In the third bullet point, if we disallow $f(q_a) >_R f(q_b)$ , for example, then $R$ is essentially forced to be $Q/\approx$ , and there is the following counter example: *     * --> * |     |     |       ... V     V     V  * --> *     * --> * In the example above, all the vertical arrows are part of the $\approx$ relation, while the horizontal arrows are part of the $>$ relation. These relations satisfy (1), because the maximum length of any $>,\approx$ -path is 3, but if we merged the top and bottom lines, there would be an infinite descending sequence so we cannot have $R = Q/\approx$ . However, it is not a counterexample because we can instead choose $R = Q$ and let $>_R$ be the union of the two relations $>$ and $\approx$ . If (1) is indeed weaker than (2), is it possible to modify the third bullet point in a natural way so that they become equivalent?","Background (optional): I have a state transition system with two ""kinds"" of transitions: progress-making ( ) and non-progress making ( ). I want to say that it is not possible for the system to undergo a progress making transition infinitely many times without ever terminating. However, in my case, it would be much simpler to deal with a well-founded relation on an encoding of the state which always decreases when progress is made. I have simplified the mathematical content of my situation into the following: suppose we have two relations on : and (despite the notation, they are not necessarily transitive, reflexive, etc.). Are the following two equivalent: There is no infinite sequence where each is either or , and infinitely often. There is some function and a relation on such that is well-founded in the usual sense for any , we have for any , either or It is clear that (2) implies (1), since any sequence would satisfy . Even after contracting the equalities, which are a subset of the relations that were originally , we are still left with an infinite decreasing sequence, contradicting 's well-foundedness. On the other hand, I'm not sure that (1) implies (2). In the third bullet point, if we disallow , for example, then is essentially forced to be , and there is the following counter example: *     * --> * |     |     |       ... V     V     V  * --> *     * --> * In the example above, all the vertical arrows are part of the relation, while the horizontal arrows are part of the relation. These relations satisfy (1), because the maximum length of any -path is 3, but if we merged the top and bottom lines, there would be an infinite descending sequence so we cannot have . However, it is not a counterexample because we can instead choose and let be the union of the two relations and . If (1) is indeed weaker than (2), is it possible to modify the third bullet point in a natural way so that they become equivalent?","Q \delta_P : Q \times \Sigma \rightarrow Q \delta_N : Q \times \Sigma \rightarrow Q Q \approx > q_1 > q_2 \approx q_3 \approx q_4 > q_5 > \cdots q_{i+1} q_i > q_{i+1} q_i \approx q_{i+1} q_i > q_{i+1} f : Q \rightarrow R >_R R >_R q_a > q_b f(q_a) >_R f(q_b) q_a \approx q_b f(q_a) >_R f(q_b) f(q_a) = f(q_b) q_1 > q_2 \approx q_3 > \cdots f(q_1) >_R f(q_2) = f(q_3) >_R \cdots \approx >_R f(q_a) >_R f(q_b) R Q/\approx \approx > >,\approx R = Q/\approx R = Q >_R > \approx","['discrete-mathematics', 'set-theory', 'well-orders']"
47,Expectation of the power of random graph's adjacency matrix,Expectation of the power of random graph's adjacency matrix,,"I am trying to find the power of the random graph's adjacency matrix. Consider the $2N$ number of nodes, where $N \geq 2$ is a fixed natural number. WLOG, let nodes with index $1$ to $N$ belong to Group 1, and nodes with index $N + 1$ to $2N$ belong to Group 2. Then, for a node pair within the same group, a pair of nodes form an edge with the probability of $p$ (i.e., $P(\{v_{i},v_{j}\} \in \mathcal{E}) = p$ if $v_{i}$ and $v_{j}$ belong to the same group.) Else, for a node pair in the different groups, a pair of nodes form an edge with the probability of $1-p$ (i.e., $P(\{v_{i},v_{j}\} \in \mathcal{E}) = 1-p$ if $v_{i}$ and $v_{j}$ belong to the different groups.) We do not allow the self-loop. You may think this is a variant of the Erods-Renyi random graph, where there are two disjoint node groups. Note that this is an undirected graph. Let $A$ be an adjacency matrix of this random graph. My question is: What is the closed-form solution to the expectation of 4-power and 3-power of $A$ ? That is: $\mathbb{E}_{A}[A^{3}]$ and $\mathbb{E}_{A}[A^{4}]$ . In other words, what would be the expected number of length-3 and length-4 paths between node $v_{i}$ and $v_{j}$ (this would differ whether $v_{i}$ and $v_{j}$ belong to the same group or not)? Thank you.","I am trying to find the power of the random graph's adjacency matrix. Consider the number of nodes, where is a fixed natural number. WLOG, let nodes with index to belong to Group 1, and nodes with index to belong to Group 2. Then, for a node pair within the same group, a pair of nodes form an edge with the probability of (i.e., if and belong to the same group.) Else, for a node pair in the different groups, a pair of nodes form an edge with the probability of (i.e., if and belong to the different groups.) We do not allow the self-loop. You may think this is a variant of the Erods-Renyi random graph, where there are two disjoint node groups. Note that this is an undirected graph. Let be an adjacency matrix of this random graph. My question is: What is the closed-form solution to the expectation of 4-power and 3-power of ? That is: and . In other words, what would be the expected number of length-3 and length-4 paths between node and (this would differ whether and belong to the same group or not)? Thank you.","2N N \geq 2 1 N N + 1 2N p P(\{v_{i},v_{j}\} \in \mathcal{E}) = p v_{i} v_{j} 1-p P(\{v_{i},v_{j}\} \in \mathcal{E}) = 1-p v_{i} v_{j} A A \mathbb{E}_{A}[A^{3}] \mathbb{E}_{A}[A^{4}] v_{i} v_{j} v_{i} v_{j}","['discrete-mathematics', 'graph-theory', 'expected-value', 'adjacency-matrix']"
48,Combination Theory solve for case where $x_i \leq 1$,Combination Theory solve for case where,x_i \leq 1,"I am studying computer science and take a discrete math modules, right now trying to learn combinational theory. I know how to solve when cases are $\geq 1$ and x's are all positive but not sure how to solve for cases such as these. How many solutions $(x_1, x_2, x_3, x_4, x_5)$ are there to the equation $x_1 - x_2 - x_3 + x_4 + x_5 = 3 $ where each $x_i$ is an integer and \begin{align*} x_1 &\leq 1, \\ x_2 &\geq 2, \\ x_3 &\geq 1, \\ x_i &\leq -1 + 4i \text{ for } i \in \{4,5\}? \end{align*} I try $-x_1 \geq -1$ $x_2 \geq 2$ $x_3 \geq 1$ $-x_4 \geq -15$ $-x_5 \geq -19$ Thus $y_1 = x_1 + 2$ $y_2 = -x_2 + 1$ $y_3 = -x_3$ $y_4 = x_4 + 16$ $y_5 = x_5 + 20$ Getting $y_1 + y_2 + y_3 + y_4 + y_5 = x_1 - x_2 - x_3 + x_4 + x_5 + 2 + 1 + 16 + 20$ = 42 Thus getting $\binom{41}{4}$ However the solution is $\binom{40}{4}$ and I don't know what's the mistake I made to not get the correct answer.","I am studying computer science and take a discrete math modules, right now trying to learn combinational theory. I know how to solve when cases are and x's are all positive but not sure how to solve for cases such as these. How many solutions are there to the equation where each is an integer and I try Thus Getting = 42 Thus getting However the solution is and I don't know what's the mistake I made to not get the correct answer.","\geq 1 (x_1, x_2, x_3, x_4, x_5) x_1 - x_2 - x_3 + x_4 + x_5 = 3  x_i \begin{align*}
x_1 &\leq 1, \\
x_2 &\geq 2, \\
x_3 &\geq 1, \\
x_i &\leq -1 + 4i \text{ for } i \in \{4,5\}?
\end{align*} -x_1 \geq -1 x_2 \geq 2 x_3 \geq 1 -x_4 \geq -15 -x_5 \geq -19 y_1 = x_1 + 2 y_2 = -x_2 + 1 y_3 = -x_3 y_4 = x_4 + 16 y_5 = x_5 + 20 y_1 + y_2 + y_3 + y_4 + y_5 = x_1 - x_2 - x_3 + x_4 + x_5 + 2 + 1 + 16 + 20 \binom{41}{4} \binom{40}{4}","['discrete-mathematics', 'combinations']"
49,"Imagine you have points on a circle labeled $0,1,2,...,126$, so point $126$ is followed by point $0$.","Imagine you have points on a circle labeled , so point  is followed by point .","0,1,2,...,126 126 0","Imagine you have points on a circle labeled $0,1,2,...,126$ , so point $126$ is followed by point $0$ . You start at point $0$ , and you repeatedly jump by $5$ , so you first land on point $5$ , then $10$ , then $15$ , etc... How many jumps do you need to land on point $1$ ? Try to think about the mathematical concept needed to figure this out without guessing. What I did Based on the fact that this is a Discrete Mathematics question, I am assuming the concept that they are trying to convey is divisibility/mod. I am thinking of finding the solution through this equation: $$5n\equiv 1\pmod{127}$$ I think that in some way, this will lead to the number of jumps to land on point $1$ . Is it $51$ ?","Imagine you have points on a circle labeled , so point is followed by point . You start at point , and you repeatedly jump by , so you first land on point , then , then , etc... How many jumps do you need to land on point ? Try to think about the mathematical concept needed to figure this out without guessing. What I did Based on the fact that this is a Discrete Mathematics question, I am assuming the concept that they are trying to convey is divisibility/mod. I am thinking of finding the solution through this equation: I think that in some way, this will lead to the number of jumps to land on point . Is it ?","0,1,2,...,126 126 0 0 5 5 10 15 1 5n\equiv 1\pmod{127} 1 51",['discrete-mathematics']
50,Help with stars and bars,Help with stars and bars,,"I have 2 questions, which I need to check: How many ways can you add up 7 numbers (each >=0), so that they total to 37, but the first three numbers add up to 6. My answer: $C^8_6*C^{34}_{31} = 335104$ I used theorem two from the following , to find ways which 4 numbers add up to 31 and 3 numbers add up to 6 and multiplied them. A message consists of 12 packets and 45 blank spaces (blank spaces must be between packets), each packet must have a minimum of 3 blank spaces between them, how many ways can a message be sent this way? My answer: $12!*C^{22}_{12} = \frac{22!}{10!}$ There are 12! factorial ways to shuffle the packets and for each combination of packets there are 12 (45-33 bcs 3 min between each packet) spaces that need to be kept in between 11 spaces(between 12 packets), so same theorem two of stars and bars ( $s_1+s_2+...+s_{11}=12$ ).","I have 2 questions, which I need to check: How many ways can you add up 7 numbers (each >=0), so that they total to 37, but the first three numbers add up to 6. My answer: I used theorem two from the following , to find ways which 4 numbers add up to 31 and 3 numbers add up to 6 and multiplied them. A message consists of 12 packets and 45 blank spaces (blank spaces must be between packets), each packet must have a minimum of 3 blank spaces between them, how many ways can a message be sent this way? My answer: There are 12! factorial ways to shuffle the packets and for each combination of packets there are 12 (45-33 bcs 3 min between each packet) spaces that need to be kept in between 11 spaces(between 12 packets), so same theorem two of stars and bars ( ).",C^8_6*C^{34}_{31} = 335104 12!*C^{22}_{12} = \frac{22!}{10!} s_1+s_2+...+s_{11}=12,"['combinatorics', 'discrete-mathematics']"
51,Counting the amount of injective functions with restriction,Counting the amount of injective functions with restriction,,"First I will say that the exact same question has been uploaded to the site already few years ago but it seems no final answer were given there. Let $$X = \{a,b,c\}, \quad Y = \{1,2,3,4,5,6,7\}.$$ I need to count how many injective functions $f: X\to Y$ there are such that $$f(a)\ne 1,2,\quad  f(b)\ne 2 ,\quad f(c) \ne 3.$$ My instictive approach to this was counting all the injective functions $X\to Y$ without restrictions which is $7 \cdot 6 \cdot 5 = 210$ and subtracting from this the amount of ""illegal"" functions. My issue is counting the illegal functions Intried to use inclusion exclusion since $f(a)$ and $f(b)$ share a restriction but I reached a dead end. Is there a simpler way to approach this question?","First I will say that the exact same question has been uploaded to the site already few years ago but it seems no final answer were given there. Let I need to count how many injective functions there are such that My instictive approach to this was counting all the injective functions without restrictions which is and subtracting from this the amount of ""illegal"" functions. My issue is counting the illegal functions Intried to use inclusion exclusion since and share a restriction but I reached a dead end. Is there a simpler way to approach this question?","X = \{a,b,c\}, \quad Y = \{1,2,3,4,5,6,7\}. f: X\to Y f(a)\ne 1,2,\quad  f(b)\ne 2 ,\quad f(c) \ne 3. X\to Y 7 \cdot 6 \cdot 5 = 210 f(a) f(b)","['combinatorics', 'discrete-mathematics', 'inclusion-exclusion']"
52,Prove that a critical graph $G$ satisfies $\chi(G) \leq \delta + 1$,Prove that a critical graph  satisfies,G \chi(G) \leq \delta + 1,"Let $G = (V, E)$ a critical graph; i.e. a graph s.t. for any subgraph $H \subseteq G$ we have $\chi(H) < \chi(G)$ . I was requested to prove that $\chi(G) \leq \delta + 1$ , where $\delta$ is the degree of the vertex (or vertices) of lesser degree in $G$ . I presume that I need to relate a sub-graph $H$ that involves the vertex (or vertices) of $G$ whose degree is $\delta$ and somehow prove that the chromatic number of this subgraph is $\delta$ . Then the property follows from the fact that $G$ is critical. However, I was unable to construct such subgraph. Am I taking the wrong approach? Any hints/suggestions are appreciated.","Let a critical graph; i.e. a graph s.t. for any subgraph we have . I was requested to prove that , where is the degree of the vertex (or vertices) of lesser degree in . I presume that I need to relate a sub-graph that involves the vertex (or vertices) of whose degree is and somehow prove that the chromatic number of this subgraph is . Then the property follows from the fact that is critical. However, I was unable to construct such subgraph. Am I taking the wrong approach? Any hints/suggestions are appreciated.","G = (V, E) H \subseteq G \chi(H) < \chi(G) \chi(G) \leq \delta + 1 \delta G H G \delta \delta G","['discrete-mathematics', 'graph-theory', 'coloring']"
53,Why can a compound biconditional statement whose individual statements don't all have the same truth values be true?,Why can a compound biconditional statement whose individual statements don't all have the same truth values be true?,,"Why can $P_1 ⇔  P_2  ⇔ P_3 ⇔ \ldots ⇔ P_n$ be true when not all the $P$ ’s have the same truth value? For example: If P1 = T P2 = T P3 = F P4 = F would this be true? T(P1) ⇔  T(P2) ⇔  F(P3) ⇔  F(P4) = T(P1&2) ⇔ F(P3) ⇔  F(P4) = F(P1,2,3) ⇔ F(P4) = True If so how can an evaluation for a series of compound biconditionals with index n and x (individual truth values) be represented as a formula? Potentially statement is true with known x = 0; x = n; ?","Why can be true when not all the ’s have the same truth value? For example: If P1 = T P2 = T P3 = F P4 = F would this be true? T(P1) ⇔  T(P2) ⇔  F(P3) ⇔  F(P4) = T(P1&2) ⇔ F(P3) ⇔  F(P4) = F(P1,2,3) ⇔ F(P4) = True If so how can an evaluation for a series of compound biconditionals with index n and x (individual truth values) be represented as a formula? Potentially statement is true with known x = 0; x = n; ?",P_1 ⇔  P_2  ⇔ P_3 ⇔ \ldots ⇔ P_n P,"['discrete-mathematics', 'logic', 'propositional-calculus', 'boolean-algebra']"
54,Question regarding set notation,Question regarding set notation,,"In an academic research paper in computer science,  I have a formula using the set builder notation in order to define a set $A$ , as follows: $$A = \{ y(b_i)=a_i | b_i \in B \}.$$ In the particular example, I want to convey in a concise way that each element $a_i \in A$ results from the transformation given by the function $y(b_i)$ for all $b_i \in B$ . Is that an appropriate and correct formulation, especially the part on the left-hand side (LHS) of the set builder? That is, in set theory, is it allowed/correct to use an equality on the LHS of the set builder in the same way as above?","In an academic research paper in computer science,  I have a formula using the set builder notation in order to define a set , as follows: In the particular example, I want to convey in a concise way that each element results from the transformation given by the function for all . Is that an appropriate and correct formulation, especially the part on the left-hand side (LHS) of the set builder? That is, in set theory, is it allowed/correct to use an equality on the LHS of the set builder in the same way as above?",A A = \{ y(b_i)=a_i | b_i \in B \}. a_i \in A y(b_i) b_i \in B,"['discrete-mathematics', 'notation', 'set-theory']"
55,How to prove that $[(p→q)∧(q→r)]→(p→r)$ is a tautology without using a truth table?,How to prove that  is a tautology without using a truth table?,[(p→q)∧(q→r)]→(p→r),How to prove that [(p→q)∧(q→r)]→(p→r) is a tautology without using the truth table? I did these steps but i did not know how to continue ≡ [ (¬p ∨ q )  ∧  ( q → r ) ] → ( p → r )  By conditional law ≡ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] → ( p → r )  By conditional law ≡ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] → ( ¬p ∨ r )  By conditional law ≡ ¬ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] ∨ ( ¬p ∨ r )  By conditional law ≡ ¬ (¬p ∨ q )  ∨ ¬( ¬q ∨  r ) ∨ ( ¬p ∨ r )  By DeMorgan’s ≡ p ∧ ¬ q  ∨ ¬( ¬q ∨  r ) ∨ ( ¬p ∨ r )  By DeMorgan’s ≡ p ∧ ¬ q  ∨ q ∧  ¬ r  ∨  ¬p ∨ r  By DeMorgan’s,How to prove that [(p→q)∧(q→r)]→(p→r) is a tautology without using the truth table? I did these steps but i did not know how to continue ≡ [ (¬p ∨ q )  ∧  ( q → r ) ] → ( p → r )  By conditional law ≡ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] → ( p → r )  By conditional law ≡ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] → ( ¬p ∨ r )  By conditional law ≡ ¬ [ (¬p ∨ q )  ∧  ( ¬q ∨  r ) ] ∨ ( ¬p ∨ r )  By conditional law ≡ ¬ (¬p ∨ q )  ∨ ¬( ¬q ∨  r ) ∨ ( ¬p ∨ r )  By DeMorgan’s ≡ p ∧ ¬ q  ∨ ¬( ¬q ∨  r ) ∨ ( ¬p ∨ r )  By DeMorgan’s ≡ p ∧ ¬ q  ∨ q ∧  ¬ r  ∨  ¬p ∨ r  By DeMorgan’s,,"['discrete-mathematics', 'logic']"
56,Proving that a Graph without 6-cycles has subgraph without 4-cycle,Proving that a Graph without 6-cycles has subgraph without 4-cycle,,"I am currently trying to prove that for every graph G such that the 6-cycle $C_6$ is not a subgraph of G, there exists a subgraph H with $|E(H)|\geq|E(G)|/2$ (with E(G) being the edge set of G) which doesnt contain a 4-Cycle. I first tried to attack this by constructing subgraphs using random 2-colorings and then deleting monocolored edges, but this yielded a worse approximation for the size of the edge set. Furthermore, I tried to rewrite the claim (however i am unsure if this is even correct): $$ex(n, C_6)\leq2ex(n, C_4)$$ I found a result (by Erdős, Rényi and Sós among others) which says that $ex(n,C_4)=1/2n^{3/2}+o(n^{3/2})$ and $ex(n,C_6)=𝛩(n^{4/3})$ , which would then imply (assuming i reworded the claim correctly) that there are two positive constants a,b with b<1 such that $a\cdot n^{4/3}≤n^{3/2}(1+2b)$ , which is equivalent to $a\leq n^{1/6}(1+2b)$ . This above result is the only one I found in my graph theory material (not just my own notes, but also the lecture notes and the lecture script), which is why it seems to me that i am on the right path. However, this is where i am unsure if it would already be proven and if not i am a bit lost on what to do next, so any help would be appreciated!","I am currently trying to prove that for every graph G such that the 6-cycle is not a subgraph of G, there exists a subgraph H with (with E(G) being the edge set of G) which doesnt contain a 4-Cycle. I first tried to attack this by constructing subgraphs using random 2-colorings and then deleting monocolored edges, but this yielded a worse approximation for the size of the edge set. Furthermore, I tried to rewrite the claim (however i am unsure if this is even correct): I found a result (by Erdős, Rényi and Sós among others) which says that and , which would then imply (assuming i reworded the claim correctly) that there are two positive constants a,b with b<1 such that , which is equivalent to . This above result is the only one I found in my graph theory material (not just my own notes, but also the lecture notes and the lecture script), which is why it seems to me that i am on the right path. However, this is where i am unsure if it would already be proven and if not i am a bit lost on what to do next, so any help would be appreciated!","C_6 |E(H)|\geq|E(G)|/2 ex(n, C_6)\leq2ex(n, C_4) ex(n,C_4)=1/2n^{3/2}+o(n^{3/2}) ex(n,C_6)=𝛩(n^{4/3}) a\cdot n^{4/3}≤n^{3/2}(1+2b) a\leq n^{1/6}(1+2b)","['discrete-mathematics', 'graph-theory']"
57,How the comparison of the cardinalities of sets affects the cardinalities of their powersets [duplicate],How the comparison of the cardinalities of sets affects the cardinalities of their powersets [duplicate],,"This question already has an answer here : Do sets, whose power sets have the same cardinality, have the same cardinality? (1 answer) Closed 5 months ago . In my question, I denote by $|\cdot|$ the cardinality of any set. Moreover, if $f: X \to Y$ , we denote by $\mathcal{P}f$ its direct image, i.e. $\mathcal{P}f(A)=\{f(a) : a \in A\}$ . Let $X,Y$ be two sets. Is it true that $|X| \le |Y| \iff |\mathcal{P}(X)| \le |\mathcal{P}(Y)|$ ? My attempt. Assume first that $|X| \le |Y|$ . Then there exists an injective function $f: X \to Y$ . Hence we may easily check that the direct image $\mathcal{P}f: \mathcal{P}(X) \to \mathcal{P}(Y)$ is also injective, so that $|\mathcal{P}(X)| \le |\mathcal{P}(Y)|$ . [Actually, we should have $|X| < |Y| \implies |\mathcal{P}(X)| < |\mathcal{P}(Y)|$ because if the direct image $\mathcal{P}g$ of some function $g: X \to Y$ is surjective, then also $g$ is a surjection] Conversely, assume that $|\mathcal{P}(X)| \le |\mathcal{P}(Y)|$ and suppose by contradiction that $|X|>|Y|$ . Then by the above step we should have $|\mathcal{P}(X)| > |\mathcal{P}(Y)|$ , absurd. Is my argument correct? Furthermore, is it also true that $|\mathcal{P}(X)| < |\mathcal{P}(Y)| \implies |X| < |Y|$ ?","This question already has an answer here : Do sets, whose power sets have the same cardinality, have the same cardinality? (1 answer) Closed 5 months ago . In my question, I denote by the cardinality of any set. Moreover, if , we denote by its direct image, i.e. . Let be two sets. Is it true that ? My attempt. Assume first that . Then there exists an injective function . Hence we may easily check that the direct image is also injective, so that . [Actually, we should have because if the direct image of some function is surjective, then also is a surjection] Conversely, assume that and suppose by contradiction that . Then by the above step we should have , absurd. Is my argument correct? Furthermore, is it also true that ?","|\cdot| f: X \to Y \mathcal{P}f \mathcal{P}f(A)=\{f(a) : a \in A\} X,Y |X| \le |Y| \iff |\mathcal{P}(X)| \le |\mathcal{P}(Y)| |X| \le |Y| f: X \to Y \mathcal{P}f: \mathcal{P}(X) \to \mathcal{P}(Y) |\mathcal{P}(X)| \le |\mathcal{P}(Y)| |X| < |Y| \implies |\mathcal{P}(X)| < |\mathcal{P}(Y)| \mathcal{P}g g: X \to Y g |\mathcal{P}(X)| \le |\mathcal{P}(Y)| |X|>|Y| |\mathcal{P}(X)| > |\mathcal{P}(Y)| |\mathcal{P}(X)| < |\mathcal{P}(Y)| \implies |X| < |Y|","['discrete-mathematics', 'elementary-set-theory', 'set-theory', 'cardinals']"
58,What is the number of possibilities to interpret a litteral number string? [closed],What is the number of possibilities to interpret a litteral number string? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 months ago . Improve this question Me and some friends came up with the following problem : Given a string of numbers of length $n$ , what is the number of possibilities to interpret this string as digits (while not accounting for pelling problems) ? For example with ""one three two one"", $n = 4$ , we could interpret it as "" $1321$ "", or even "" $311$ "" (one three and two ones). To simplify a bit, some additionnal rules are that two consecutive numbers cannot be the same, and that a digit can only demultiply the one after him, for example ""two three one"" cannot be interpreted as "" $3131$ "" (two times three one). This might be related to the look and say sequence, we just don't now in what way. Our conjecture is that this number is fibonacci( $n$ ) (with fibonacci( $0$ ) = fibonacci( $1$ ) = $1$ ). This works up to n = 30, but we did not manage to complete a proof $\forall$$n\in$$\mathbb{N}$ . Our idea was to represent the string of length n by a sequence $A_1 A_2 A_3...A_n$ , with $A_i\in \{\{1, 1*\}, \{2, 2*\},\dots\}$ $\forall$$i\gt 1$ , and $A_1\in \{\{1\}, \{2\},\dots\}$ . A number ""star"" would represent a number that got itself demultiplied by the previous one. This representation is probably really bad (and maybe doesn't even work), but at least we can represent all the sequences of length $n$ as the set $A_1\times A_2\times \dots \times A_n$ minus the possibilities where two number ""stars"" are consecutive. After a bit of research on the internet, we didn't manage to find anything related to this, and so here we are. What are your thoughts on this, is our conjecture reasonable ? if yes, how could we prove it ? (We tried by induction, without success...) I also want to apologize if this post is not well-written, doesn't follow the math.stackexchange rules, or if the problem is not well formulated. As second year computer science students, this is totally new to us. Thank you !","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 months ago . Improve this question Me and some friends came up with the following problem : Given a string of numbers of length , what is the number of possibilities to interpret this string as digits (while not accounting for pelling problems) ? For example with ""one three two one"", , we could interpret it as "" "", or even "" "" (one three and two ones). To simplify a bit, some additionnal rules are that two consecutive numbers cannot be the same, and that a digit can only demultiply the one after him, for example ""two three one"" cannot be interpreted as "" "" (two times three one). This might be related to the look and say sequence, we just don't now in what way. Our conjecture is that this number is fibonacci( ) (with fibonacci( ) = fibonacci( ) = ). This works up to n = 30, but we did not manage to complete a proof . Our idea was to represent the string of length n by a sequence , with , and . A number ""star"" would represent a number that got itself demultiplied by the previous one. This representation is probably really bad (and maybe doesn't even work), but at least we can represent all the sequences of length as the set minus the possibilities where two number ""stars"" are consecutive. After a bit of research on the internet, we didn't manage to find anything related to this, and so here we are. What are your thoughts on this, is our conjecture reasonable ? if yes, how could we prove it ? (We tried by induction, without success...) I also want to apologize if this post is not well-written, doesn't follow the math.stackexchange rules, or if the problem is not well formulated. As second year computer science students, this is totally new to us. Thank you !","n n = 4 1321 311 3131 n 0 1 1 \foralln\in\mathbb{N} A_1 A_2 A_3...A_n A_i\in \{\{1, 1*\}, \{2, 2*\},\dots\} \foralli\gt 1 A_1\in \{\{1\}, \{2\},\dots\} n A_1\times A_2\times \dots \times A_n","['combinatorics', 'discrete-mathematics']"
59,How many words with 4 different consonants and 3 different syllables can be created if we have 9 consonants and 6 syllables available such that...,How many words with 4 different consonants and 3 different syllables can be created if we have 9 consonants and 6 syllables available such that...,,"We have $9$ different consonants and $6$ different vowels available. How many words (not necessarily actual words) can be created using $4$ different consonants and $3$ different vowels such that no two vowels stands next to each other? Here's what I've got so far: The number of words with 4 different consonants and 3 different vowels is $\binom{9}{4}.\binom{6}{3}.7!$ To solve for the case where we don't want any two vowels next to each other, we want to put every vowel between at least two consonants. First we choose our $4$ consonants and shuffle them. That can be done in $\binom{9}{4}.4!$ ways. Let's labels our consonants $C$ . Then there are $5$ gaps (labeled $X$ ) where we can potentially place our vowel. (X C X C X C X C X) Choosing $3$ gaps out of $5$ and choosing $3$ consonants out of $6$ + shuffling them can be done in $\binom{5}{3}.\binom{6}{3}.3!$ ways. Hence the answer to the question is: $\binom{9}{4}.\binom{5}{3}.\binom{6}{3}.4!3!$ Could that be a correct approach? I've considered using principle of exclusion and inclusion but I couldn't figure iut what would the sets themselves represent.","We have different consonants and different vowels available. How many words (not necessarily actual words) can be created using different consonants and different vowels such that no two vowels stands next to each other? Here's what I've got so far: The number of words with 4 different consonants and 3 different vowels is To solve for the case where we don't want any two vowels next to each other, we want to put every vowel between at least two consonants. First we choose our consonants and shuffle them. That can be done in ways. Let's labels our consonants . Then there are gaps (labeled ) where we can potentially place our vowel. (X C X C X C X C X) Choosing gaps out of and choosing consonants out of + shuffling them can be done in ways. Hence the answer to the question is: Could that be a correct approach? I've considered using principle of exclusion and inclusion but I couldn't figure iut what would the sets themselves represent.",9 6 4 3 \binom{9}{4}.\binom{6}{3}.7! 4 \binom{9}{4}.4! C 5 X 3 5 3 6 \binom{5}{3}.\binom{6}{3}.3! \binom{9}{4}.\binom{5}{3}.\binom{6}{3}.4!3!,"['combinatorics', 'discrete-mathematics', 'permutations']"
60,How far can I downsample two sets A and B to compute the Jaccard Index of A and B?,How far can I downsample two sets A and B to compute the Jaccard Index of A and B?,,"Let be $A$ and $B$ two sets such that $|A|=N_A$ and $|B|=N_B$ . Let be $(A_n)_{1\leq n \leq N_A}$ a sequence of sets such that $A_n \subset A$ , $|A_n|=n$ . Analogously, consider the sequence $(B_n)_{1\leq n\leq N_B}$ . Denoting $J$ the Jaccard Index, $J(E,F) = 2 \frac{|E \cap F|}{|E| + |F|}$ , how to choose $r$ and $s$ such that $\mathbb{P}(|J(A_r, B_s) - J(A, B)| \leq \varepsilon) > 1 - \eta$ ? Note that, $N_A \gg 1$ and $N_B \gg 1$ , I don't know if it may help. But that's the case I am considering. Moreover, $J(A,B)$ is known. I could compute $J(A_r, B_s)$ as well, but the value of this quantity depends on how $A_r$ and $B_s$ are defined. I would assume that $A_r$ and $B_s$ are built by randomly downsampling $A$ and $B$ (without replacement), and I hope to be able to estimate the probability numerically with some Monte-Carlo simulations, because I don't think we can come up with an analytic estimation. Does it make sense ? Can you help me to better formulate this probabilistic problem ? Feel free to suggest anything to clarify this question.","Let be and two sets such that and . Let be a sequence of sets such that , . Analogously, consider the sequence . Denoting the Jaccard Index, , how to choose and such that ? Note that, and , I don't know if it may help. But that's the case I am considering. Moreover, is known. I could compute as well, but the value of this quantity depends on how and are defined. I would assume that and are built by randomly downsampling and (without replacement), and I hope to be able to estimate the probability numerically with some Monte-Carlo simulations, because I don't think we can come up with an analytic estimation. Does it make sense ? Can you help me to better formulate this probabilistic problem ? Feel free to suggest anything to clarify this question.","A B |A|=N_A |B|=N_B (A_n)_{1\leq n \leq N_A} A_n \subset A |A_n|=n (B_n)_{1\leq n\leq N_B} J J(E,F) = 2 \frac{|E \cap F|}{|E| + |F|} r s \mathbb{P}(|J(A_r, B_s) - J(A, B)| \leq \varepsilon) > 1 - \eta N_A \gg 1 N_B \gg 1 J(A,B) J(A_r, B_s) A_r B_s A_r B_s A B","['probability-theory', 'discrete-mathematics', 'convergence-divergence']"
61,Which is correct Euler path or Euler trail?,Which is correct Euler path or Euler trail?,,"Since path cannot have repeated vertices, the definition for A graph which exactly two vertices have odd degree, and all of its vertices with nonzero degree belong to a single connected component seems to must refer to Euler trail. Is Euler path sth else and if it is? (I think it can just be a path graph.) Another question is, An undirected graph has an Eulerian trail if and only if exactly zero or two vertices have odd degree, and all of its vertices with nonzero degree belong to a single connected component this is from Wikipedia, How can a graph with zero  odd-degree vertices has an Eulerian trail?","Since path cannot have repeated vertices, the definition for A graph which exactly two vertices have odd degree, and all of its vertices with nonzero degree belong to a single connected component seems to must refer to Euler trail. Is Euler path sth else and if it is? (I think it can just be a path graph.) Another question is, An undirected graph has an Eulerian trail if and only if exactly zero or two vertices have odd degree, and all of its vertices with nonzero degree belong to a single connected component this is from Wikipedia, How can a graph with zero  odd-degree vertices has an Eulerian trail?",,"['discrete-mathematics', 'graph-theory', 'eulerian-path']"
62,How many numbers between 10 and 100 are divisible by 3 but not 2 nor 7?,How many numbers between 10 and 100 are divisible by 3 but not 2 nor 7?,,"My working: Let $|M_3|$ denote the number of integers between 10 and 100 that divides 3. So we have $$|M_3|= \lfloor \frac{100}{3} \rfloor-3=30$$ , and similarly, $$|M_2|=\lfloor \frac{100}{2}\rfloor-4=46$$ , $$|M_7|=\lfloor \frac{100}{7}\rfloor-1=13.$$ Thus, we want to find $|M_3 \cap (M_2 \cup M_7)'|=$ . From a venn diagram, we deduce that this is equivalent to finding $$|M_3|-|M_3 \cap M_7| - |M_3 \cap M_2| + |M_3 \cap M_7 \cap M_2|=30-4-15+2=13.$$ But the tecaher said that this is incorrect, but close. After reviewing my solution, I am confused to as what I am getting wrong? Is it the interpretation of ""between"" 10 and 100? i.e., I minused away all integers $1≤n<10$ for each of the $M_i$ , i.e., the four integers $2,3,6,8$ are not counted in $|M_2|$ , but $10$ is.","My working: Let denote the number of integers between 10 and 100 that divides 3. So we have , and similarly, , Thus, we want to find . From a venn diagram, we deduce that this is equivalent to finding But the tecaher said that this is incorrect, but close. After reviewing my solution, I am confused to as what I am getting wrong? Is it the interpretation of ""between"" 10 and 100? i.e., I minused away all integers for each of the , i.e., the four integers are not counted in , but is.","|M_3| |M_3|= \lfloor \frac{100}{3} \rfloor-3=30 |M_2|=\lfloor \frac{100}{2}\rfloor-4=46 |M_7|=\lfloor \frac{100}{7}\rfloor-1=13. |M_3 \cap (M_2 \cup M_7)'|= |M_3|-|M_3 \cap M_7| - |M_3 \cap M_2| + |M_3 \cap M_7 \cap M_2|=30-4-15+2=13. 1≤n<10 M_i 2,3,6,8 |M_2| 10","['combinatorics', 'discrete-mathematics', 'problem-solving', 'inclusion-exclusion']"
63,Color regions generated by circles with one chord (Induction),Color regions generated by circles with one chord (Induction),,"I am trying to learn Algorithms by reading the book Introduction to Algorithms: A Creative Approach by Udi Manber. I just want to solve this question: Prove (by induction) that regions formed by $n$ circles in the plane, each with one chord,can be colored with three colors such that any neighboring regions are colored differently. My guess is that when adding the new circle with its chord, we should start coloring the regions that have a neighbor colored. In other words, we should first color the regions with the lowest number of available colors. However, I cannot prove that in this way, we can color all regions.","I am trying to learn Algorithms by reading the book Introduction to Algorithms: A Creative Approach by Udi Manber. I just want to solve this question: Prove (by induction) that regions formed by circles in the plane, each with one chord,can be colored with three colors such that any neighboring regions are colored differently. My guess is that when adding the new circle with its chord, we should start coloring the regions that have a neighbor colored. In other words, we should first color the regions with the lowest number of available colors. However, I cannot prove that in this way, we can color all regions.",n,"['discrete-mathematics', 'graph-theory', 'algorithms', 'induction', 'coloring']"
64,How to prove the tautology for the inference rule of hypothetical syllogism using a chain of logical identities?,How to prove the tautology for the inference rule of hypothetical syllogism using a chain of logical identities?,,"Let $p$ , $q$ , and $r$ be any propositions. Then, using a chain of logical equivalences, how to establish the following logical identity? $$ \big( (p \rightarrow q) \land (q \rightarrow r) \big) \rightarrow \big( p \rightarrow r \big) \ \equiv \ T. $$ My Attempt: In the following chain of equivalences, I will be using the same nomenclature as that used in Table 6, Sec. 1.3, of the book Discrete Mathematics and Its Applications by Kenneth H. Rosen, 8th edition. We note that $$ \begin{align} &\qquad \big( (p \rightarrow q) \land (q \rightarrow r) \big) \rightarrow \big( p \rightarrow r \big) \\  &\equiv \left( \overline{ \left( \overline{p} \lor q \right) \land \left( \overline{q} \lor r \right) } \right) \lor \left( \overline{p} \lor r \right)  \\  & \qquad \mbox{[ using the conditional-disjunction equivalence ]} \\ &\equiv \left( \left( \overline{ \overline{p} \lor q } \right) \lor \left( \overline{ \overline{q} \lor r } \right) \right) \lor \left( \overline{p} \lor r \right) \\ &\qquad \mbox{[ using a DeMorgan's law ]} \\  &\equiv \left( \left( \overline{ \overline{p}} \land  \overline{q}  \right) \lor \left( \overline{ \overline{q}} \land \overline{r} \right) \right) \lor \left( \overline{p} \lor r \right) \\ &\qquad \mbox{[ using a DeMorgan's law ]} \\  &\equiv \left( \left( p \land  \overline{q}  \right) \lor \left( q \land \overline{r} \right) \right) \lor \left( \overline{p} \lor r \right) \\  &\qquad \mbox{[ using the double-negation law ]} \\ &\equiv \left( \left( p \land  \overline{q}  \right) \lor \overline{p} \right) \ \lor \  \left( \left( q \land \overline{r} \right) \lor r \right) \\  &\qquad \mbox{[ using the associativity and commutativity of $\lor$ ]} \\  &\equiv \left( \left( p \lor \overline{p} \right) \land \left( \overline{q} \lor \overline{p} \right) \right) \ \lor \ \left( \left( q \lor r \right) \land \left( \overline{r} \lor r \right) \right) \\  &\qquad \mbox{[ using the distributivity of $\lor$ over $\land$ ]} \\ &\equiv \left( T \land \left( \overline{q} \lor \overline{p} \right) \right) \ \lor \ \left( \left( q \lor r \right) \land T \right) \\  &\qquad \mbox{[ using a negation law ]} \\ &\equiv \left(  \overline{q} \lor \overline{p}  \right) \ \lor \ \left( q \lor r \right) \\  &\qquad \mbox{[ using an identity  law ]} \\ &\equiv \left( \overline{q} \lor q \right)\  \lor \ \left( \overline{p} \lor r \right) \\   &\qquad \mbox{[ using the associativity and commutativity of $\lor$ ]} \\ &\equiv T \  \lor \ \left( \overline{p} \lor r \right) \\   &\qquad \mbox{[ using a negation law ]} \\ &\equiv T. \\  &\qquad \mbox{[ using a domination law ]} \end{align} $$ Is the above calculation correct and clear enough? If so, is this the shortest possible chain of logical equivalences necessary for establishing the tautology in question, using the same machinary as developed by Rosen up to Sec. 1.3? Or, are there any issues?","Let , , and be any propositions. Then, using a chain of logical equivalences, how to establish the following logical identity? My Attempt: In the following chain of equivalences, I will be using the same nomenclature as that used in Table 6, Sec. 1.3, of the book Discrete Mathematics and Its Applications by Kenneth H. Rosen, 8th edition. We note that Is the above calculation correct and clear enough? If so, is this the shortest possible chain of logical equivalences necessary for establishing the tautology in question, using the same machinary as developed by Rosen up to Sec. 1.3? Or, are there any issues?","p q r 
\big( (p \rightarrow q) \land (q \rightarrow r) \big) \rightarrow \big( p \rightarrow r \big) \ \equiv \ T.
 
\begin{align}
&\qquad \big( (p \rightarrow q) \land (q \rightarrow r) \big) \rightarrow \big( p \rightarrow r \big) \\ 
&\equiv \left( \overline{ \left( \overline{p} \lor q \right) \land \left( \overline{q} \lor r \right) } \right) \lor \left( \overline{p} \lor r \right) 
\\ 
& \qquad \mbox{[ using the conditional-disjunction equivalence ]} \\
&\equiv \left( \left( \overline{ \overline{p} \lor q } \right) \lor \left( \overline{ \overline{q} \lor r } \right) \right) \lor \left( \overline{p} \lor r \right) \\
&\qquad \mbox{[ using a DeMorgan's law ]} \\ 
&\equiv \left( \left( \overline{ \overline{p}} \land  \overline{q}  \right) \lor \left( \overline{ \overline{q}} \land \overline{r} \right) \right) \lor \left( \overline{p} \lor r \right) \\
&\qquad \mbox{[ using a DeMorgan's law ]} \\ 
&\equiv \left( \left( p \land  \overline{q}  \right) \lor \left( q \land \overline{r} \right) \right) \lor \left( \overline{p} \lor r \right) \\ 
&\qquad \mbox{[ using the double-negation law ]} \\
&\equiv \left( \left( p \land  \overline{q}  \right) \lor \overline{p} \right) \ \lor \  \left( \left( q \land \overline{r} \right) \lor r \right) \\ 
&\qquad \mbox{[ using the associativity and commutativity of \lor ]} \\ 
&\equiv \left( \left( p \lor \overline{p} \right) \land \left( \overline{q} \lor \overline{p} \right) \right) \ \lor \ \left( \left( q \lor r \right) \land \left( \overline{r} \lor r \right) \right) \\ 
&\qquad \mbox{[ using the distributivity of \lor over \land ]} \\
&\equiv \left( T \land \left( \overline{q} \lor \overline{p} \right) \right) \ \lor \ \left( \left( q \lor r \right) \land T \right) \\ 
&\qquad \mbox{[ using a negation law ]} \\
&\equiv \left(  \overline{q} \lor \overline{p}  \right) \ \lor \ \left( q \lor r \right) \\ 
&\qquad \mbox{[ using an identity  law ]} \\
&\equiv \left( \overline{q} \lor q \right)\  \lor \ \left( \overline{p} \lor r \right) \\  
&\qquad \mbox{[ using the associativity and commutativity of \lor ]} \\
&\equiv T \  \lor \ \left( \overline{p} \lor r \right) \\  
&\qquad \mbox{[ using a negation law ]} \\
&\equiv T. \\ 
&\qquad \mbox{[ using a domination law ]}
\end{align}
","['discrete-mathematics', 'logic', 'solution-verification', 'propositional-calculus']"
65,The smallest cardinality of a set such that it is transitive,The smallest cardinality of a set such that it is transitive,,"I am currently stuck on a set theory problem. Suppose we have set S = $ \{1, 2, 3, 4, 5 \}$ and set A $\subseteq S * S$ given by $A = \{ (1, 1), (1, 4), (2, 1), (2, 2), (2, 4), (3, 5), (4, 3), (4, 4), (5, 2) \} $ . Now, suppose $B \subseteq S * S$ and is a transitive relation such that $A \subseteq B$ . What is the smallest cardinality of $B$ ? My working was as follows: For $B$ to be transitive, for every $(a, b) \in B$ and $(b, c) \in B$ there must be $(a, c) \in B$ . As $A \subseteq B$ , we can get the smallest set if we consider the elements in $A$ which already hold a transitive relation and simply add any 'missing' elements to fulfil the remaining elements that lack this relation. There's an issue though. Once we add those 'missing' elements, they become part of the set and so need to hold the transitive relation for themselves. For example, we have from $A$ , $(1,4)$ and $(4,3)$ . Therefore we need to add $(1, 3)$ to complete the transitive relation between those two. However, this creates another issue - $(1, 3)$ (the added 'missing' element) and $(3, 5)$ (from set $A$ ) do not satisfy the transitive relation (i.e. there is a missing $(1, 5)$ ). Once I got this impression, it made me believe that manually determining all the pairs to add to $B$ in order to satisfy the transitive requirement for the set may take a while. The given solution says the answer is '25' (i.e. the entirety of the elements of $S * S$ ). Is this verifiable without manually crunching all the pairs required to satisfy the requirement? If so, it would be funny that the 'smallest' possible cardinality is the entire set.","I am currently stuck on a set theory problem. Suppose we have set S = and set A given by . Now, suppose and is a transitive relation such that . What is the smallest cardinality of ? My working was as follows: For to be transitive, for every and there must be . As , we can get the smallest set if we consider the elements in which already hold a transitive relation and simply add any 'missing' elements to fulfil the remaining elements that lack this relation. There's an issue though. Once we add those 'missing' elements, they become part of the set and so need to hold the transitive relation for themselves. For example, we have from , and . Therefore we need to add to complete the transitive relation between those two. However, this creates another issue - (the added 'missing' element) and (from set ) do not satisfy the transitive relation (i.e. there is a missing ). Once I got this impression, it made me believe that manually determining all the pairs to add to in order to satisfy the transitive requirement for the set may take a while. The given solution says the answer is '25' (i.e. the entirety of the elements of ). Is this verifiable without manually crunching all the pairs required to satisfy the requirement? If so, it would be funny that the 'smallest' possible cardinality is the entire set."," \{1, 2, 3, 4, 5 \} \subseteq S * S A = \{ (1, 1), (1, 4), (2, 1), (2, 2), (2, 4), (3, 5), (4, 3), (4, 4), (5, 2) \}  B \subseteq S * S A \subseteq B B B (a, b) \in B (b, c) \in B (a, c) \in B A \subseteq B A A (1,4) (4,3) (1, 3) (1, 3) (3, 5) A (1, 5) B S * S","['discrete-mathematics', 'elementary-set-theory', 'relations']"
66,Find $P(B|L)$ and $P(L|B)$,Find  and,P(B|L) P(L|B),"A deck of cards has $3$ orange cards and $7$ blue cards. Two cards are selected a random without replacement. $B=$ both cards are blue, $L=$ at least one card is blue. $n(S)= C(10,2)$ a) find $P(B|L)$ b) find $P(L|B)$ Attempt: $P(B∣L)=\frac{P(L)} {P(B∩L)}$ $P(B∩L)=P(B)$ ​ Not sure how to proceed.","A deck of cards has orange cards and blue cards. Two cards are selected a random without replacement. both cards are blue, at least one card is blue. a) find b) find Attempt: ​ Not sure how to proceed.","3 7 B= L= n(S)= C(10,2) P(B|L) P(L|B) P(B∣L)=\frac{P(L)}
{P(B∩L)} P(B∩L)=P(B)","['probability', 'discrete-mathematics']"
67,Why does $\mathbb{P}[X_i=j]= (\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1)$ here?,Why does  here?,\mathbb{P}[X_i=j]= (\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1),"I am asking this to understand the coupon collector's problem better. Say that we are trying to collect $n$ coupons, and every time we obtain a box of cereal, we get a coupon, which has an equal probability of giving us any of the $n$ coupons. I am trying to understand why if we let $X_i$ be a random variable which returns the amount of boxes we bought until we got the $i$ th new card, measured from the boxes we bought right after getting the $(i-1)$ st new card, that $\mathbb{P}[X_i=j]= (\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1)$ . My chief difficulty in understanding this is that the sample points we have vary in terms of which coupons their $i$ th first element and $(i-1)$ st first element are, as well as which boxes it were on which we have found the $i$ th first element and $(i-1)$ st first element. If the question simply was, what is the probability of finding coupon $a$ on the $b$ th box we have opened, and to open $j-1$ boxes after this and still get coupon $a$ , and then to on the $j$ th box after this to get coupon $b$ , I could see that $(\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1)$ is the probability; but because these things vary on each sample point I am not seeing this. So far, I have tried thinking that the question is essentially that given we have grabbed $i-1$ different things out of $n$ available choices, what’s the probability that for the next $j-1$ grabbings, we grab the same thing, and for the jth grabbing, grab something different? However, the matter is still rather unclear for me- even when I phrase the question like this, I am not seeing how to relate this to the sample points which vary in terms of how many boxes it took to obtain the $i$ th new coupon and which coupons is the $i$ th, etc. So why does $\mathbb{P}[X_i=j]= (\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1)$ here?","I am asking this to understand the coupon collector's problem better. Say that we are trying to collect coupons, and every time we obtain a box of cereal, we get a coupon, which has an equal probability of giving us any of the coupons. I am trying to understand why if we let be a random variable which returns the amount of boxes we bought until we got the th new card, measured from the boxes we bought right after getting the st new card, that . My chief difficulty in understanding this is that the sample points we have vary in terms of which coupons their th first element and st first element are, as well as which boxes it were on which we have found the th first element and st first element. If the question simply was, what is the probability of finding coupon on the th box we have opened, and to open boxes after this and still get coupon , and then to on the th box after this to get coupon , I could see that is the probability; but because these things vary on each sample point I am not seeing this. So far, I have tried thinking that the question is essentially that given we have grabbed different things out of available choices, what’s the probability that for the next grabbings, we grab the same thing, and for the jth grabbing, grab something different? However, the matter is still rather unclear for me- even when I phrase the question like this, I am not seeing how to relate this to the sample points which vary in terms of how many boxes it took to obtain the th new coupon and which coupons is the th, etc. So why does here?",n n X_i i (i-1) \mathbb{P}[X_i=j]= (\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1) i (i-1) i (i-1) a b j-1 a j b (\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1) i-1 n j-1 i i \mathbb{P}[X_i=j]= (\frac 1 n)^{j-1} \cdot (\frac {n-i +1} 1),"['probability', 'discrete-mathematics', 'geometric-distribution']"
68,Giving some numbers to people to satify given condition,Giving some numbers to people to satify given condition,,"When I read a math  book by myself, I have encounter with a question. I tried to solve it but my answer seems wrong according to my sense. Moreover, there is not any answer key because of the question number is even. The question roughly says that we want to disperse two primes for each person in the world.Moreover, those primes must exactly have the length of a hundred.Each person must get distinct numbers to be secured. We also assume that the primes numbers selected randomly. Then, what is the probability of being non-secured ? (Assume that eight billion people live in world). What I did: I firstly calculated the number of primes with length of a hundred using prime number theorem s.t $$\pi(10^{100})-\pi(10^{99})=\frac{10^{100}}{\ln(10^{100})}-\frac{10^{99}}{\ln(10^{99})} \approx3.9 \times10^{97}$$ So, the total answer is all - secured situation: $$1-\frac{\binom{39 \times 10^{96}}{2}\binom{(39 \times 10^{96})-2}{2}...\binom{(39 \times 10^{96})-{16,000,000,000}}{2}}{(39 \times 10^{96})^{8,000,000,000}}$$ However, the result would be big . According to my friends, the probability of being non-secured must be very small. Can you help me ?","When I read a math  book by myself, I have encounter with a question. I tried to solve it but my answer seems wrong according to my sense. Moreover, there is not any answer key because of the question number is even. The question roughly says that we want to disperse two primes for each person in the world.Moreover, those primes must exactly have the length of a hundred.Each person must get distinct numbers to be secured. We also assume that the primes numbers selected randomly. Then, what is the probability of being non-secured ? (Assume that eight billion people live in world). What I did: I firstly calculated the number of primes with length of a hundred using prime number theorem s.t So, the total answer is all - secured situation: However, the result would be big . According to my friends, the probability of being non-secured must be very small. Can you help me ?","\pi(10^{100})-\pi(10^{99})=\frac{10^{100}}{\ln(10^{100})}-\frac{10^{99}}{\ln(10^{99})} \approx3.9 \times10^{97} 1-\frac{\binom{39 \times 10^{96}}{2}\binom{(39 \times 10^{96})-2}{2}...\binom{(39 \times 10^{96})-{16,000,000,000}}{2}}{(39 \times 10^{96})^{8,000,000,000}}","['probability', 'combinatorics']"
69,Solving a floored recurrence relation $F_n = c \cdot \left\lfloor \frac{F_{n-1}}{d} \right\rfloor$,Solving a floored recurrence relation,F_n = c \cdot \left\lfloor \frac{F_{n-1}}{d} \right\rfloor,"I initially wanted to solve the following recurrence relation: $$F_n = c \cdot \left\lfloor \frac{F_{n-1}}{d} \right\rfloor \text{ for } F_0, c, d \in \mathbb{N} \tag{1}$$ Out of interest, I've also approached the problem more generally: \begin{align*} F_n &= a \cdot \lfloor b \cdot F_{n-1} \rfloor + c \tag{2} \\ C_n &= a \cdot \lceil b \cdot C_{n-1} \rceil + c, \text{ for } a,b,c \in \mathbb{Q}^+ \end{align*} I wish to solve these generally. Special case for (1) where $d|c$ and $c|d$ A special case for (1) where $c | d$ and $d|c$ can be found relatively easily. If $d | c$ , then: $$F_n = c \left(\frac{c}{d}\right)^{c-1} \left\lfloor \frac{F_0}{d} \right\rfloor$$ If $c|d$ , then: $$F_n = c \left\lfloor \left(\frac{c}{d}\right)^{n-1} \frac{F_0}{d} \right\rfloor$$ The first is proven by using $d | c \implies \frac{c}{d} \in \mathbb{Z}$ , and $\forall n,m \in \mathbb{Z} \left(\lfloor nm \rfloor = nm\right)$ on: $$F_n = c \cdot \left\lfloor \frac{c}{d} \cdot  \left\lfloor \frac{F_{n-2}}{d} \right\rfloor \right\rfloor = c \cdot \frac{c}{d} \cdot  \left\lfloor \frac{F_{n-2}}{d} \right\rfloor $$ The second is proven using $c|d \implies \exists n \in \mathbb{Z} \left(\frac{d}{c} = \frac{1}{n}\right)$ and the property $\left\lfloor \frac{\lfloor x / m \rfloor}{n} \right\rfloor = \left\lfloor \frac{x}{mn} \right\rfloor$ : $$F_n = c \cdot \left\lfloor \frac{c}{d} \cdot  \left\lfloor \frac{F_{n-2}}{d} \right\rfloor \right\rfloor = c \cdot \left\lfloor \frac{c}{d} \cdot  \frac{F_{n-2}}{d} \right\rfloor $$ Example for (1) where $c=3, d=2$ The simplest case with some interesting behaviour is $c = 3$ and $d = 2$ . Despite different initial conditions $F_0$ , quite a few of sequences become the same sequence when they share the same values: e.g.: $F_0 = 4, F_1 = 6, F_2 = 9,\color{red}{F_3 = 12, F_4 = 18,\dots}$ $F_0 = 8 ,\color{red}{F_1 = 12, F_2 = 18,\dots}$ For clarity, I'll refer to the sequence $F_0, F_1, F_2, \dots$ as $\mathscr{F}(F_0)$ (e.g.: So $\mathscr{F}(4)$ is the sequence $4, 6, 9, \dots$ ) Some observations that can be made are: Given sequence $(F_i)$ the following sequences share values: $\mathscr{F}(F_i)$ $\mathscr{F}\left(\frac{2}{3}F_i\right)$ if $\frac{2}{3}F_i \in \mathbb{N}$ $\mathscr{F}(F_i + 1)$ if $F_i$ is even It also seems every $\mathscr{F}(4 + 6n)$ is always a ""new"" sequence? It seems that if $\mathscr{F}(n)$ where $n < 4 + 6n$ Then $\mathscr{F}(n)$ and $\mathscr{F}(4 + 6n)$ do not share any values. Keeping track of every time an odd number appears in $\mathscr{F}(4)$ results in A087791 . Special case for (2) A special case for (2) can be solved using Theorem 3.10 from Concrete Mathematics: Let $f(x)$ be any continuous, monotonically increasing function with the property that: $$f(x) \in \mathbb{Z} \implies x \in \mathbb{Z}$$ Then: $$\left\lfloor f(x) \right \rfloor = \left\lfloor f(\lfloor x \rfloor) \right\rfloor$$ Using $f(x) = abx + bc$ , we can prove by induction that: $$F_n = a\lfloor f^n(bF_0) \rfloor +c \text{ where } f^n(x) = f(\underbrace{f(f(\dots))}_\textrm{n times}$$ We can then prove $f^n(x_0) = (ab)^n x_0 + \frac{1-(ab)^n}{1-ab}cb$ , and obtain the special case solution: If $a,b,c \in \mathbb{R^+}$ satisfies $\left(abx + bc \in \mathbb{Z} \implies x \in \mathbb{Z}\right)$ Then $$F_n = a \left\lfloor (ab)^{n-1} bF_0 + \frac{1-(ab)^{n-1}}{1-ab}cb \right\rfloor + c $$ Admittedly, I'm not quite happy with this result as the conditions are incredibly restrictive. It also does not solve my original problem (even for cases $d|c$ or $c|d$ ?) Are there general solutions to my problem?","I initially wanted to solve the following recurrence relation: Out of interest, I've also approached the problem more generally: I wish to solve these generally. Special case for (1) where and A special case for (1) where and can be found relatively easily. If , then: If , then: The first is proven by using , and on: The second is proven using and the property : Example for (1) where The simplest case with some interesting behaviour is and . Despite different initial conditions , quite a few of sequences become the same sequence when they share the same values: e.g.: For clarity, I'll refer to the sequence as (e.g.: So is the sequence ) Some observations that can be made are: Given sequence the following sequences share values: if if is even It also seems every is always a ""new"" sequence? It seems that if where Then and do not share any values. Keeping track of every time an odd number appears in results in A087791 . Special case for (2) A special case for (2) can be solved using Theorem 3.10 from Concrete Mathematics: Let be any continuous, monotonically increasing function with the property that: Then: Using , we can prove by induction that: We can then prove , and obtain the special case solution: If satisfies Then Admittedly, I'm not quite happy with this result as the conditions are incredibly restrictive. It also does not solve my original problem (even for cases or ?) Are there general solutions to my problem?","F_n = c \cdot \left\lfloor \frac{F_{n-1}}{d} \right\rfloor \text{ for } F_0, c, d \in \mathbb{N} \tag{1} \begin{align*}
F_n &= a \cdot \lfloor b \cdot F_{n-1} \rfloor + c \tag{2}
\\
C_n &= a \cdot \lceil b \cdot C_{n-1} \rceil + c, \text{ for } a,b,c \in \mathbb{Q}^+
\end{align*} d|c c|d c | d d|c d | c F_n = c \left(\frac{c}{d}\right)^{c-1} \left\lfloor \frac{F_0}{d} \right\rfloor c|d F_n = c \left\lfloor \left(\frac{c}{d}\right)^{n-1} \frac{F_0}{d} \right\rfloor d | c \implies \frac{c}{d} \in \mathbb{Z} \forall n,m \in \mathbb{Z} \left(\lfloor nm \rfloor = nm\right) F_n = c \cdot \left\lfloor \frac{c}{d} \cdot  \left\lfloor \frac{F_{n-2}}{d} \right\rfloor \right\rfloor = c \cdot \frac{c}{d} \cdot  \left\lfloor \frac{F_{n-2}}{d} \right\rfloor  c|d \implies \exists n \in \mathbb{Z} \left(\frac{d}{c} = \frac{1}{n}\right) \left\lfloor \frac{\lfloor x / m \rfloor}{n} \right\rfloor = \left\lfloor \frac{x}{mn} \right\rfloor F_n = c \cdot \left\lfloor \frac{c}{d} \cdot  \left\lfloor \frac{F_{n-2}}{d} \right\rfloor \right\rfloor = c \cdot \left\lfloor \frac{c}{d} \cdot  \frac{F_{n-2}}{d} \right\rfloor  c=3, d=2 c = 3 d = 2 F_0 F_0 = 4, F_1 = 6, F_2 = 9,\color{red}{F_3 = 12, F_4 = 18,\dots} F_0 = 8 ,\color{red}{F_1 = 12, F_2 = 18,\dots} F_0, F_1, F_2, \dots \mathscr{F}(F_0) \mathscr{F}(4) 4, 6, 9, \dots (F_i) \mathscr{F}(F_i) \mathscr{F}\left(\frac{2}{3}F_i\right) \frac{2}{3}F_i \in \mathbb{N} \mathscr{F}(F_i + 1) F_i \mathscr{F}(4 + 6n) \mathscr{F}(n) n < 4 + 6n \mathscr{F}(n) \mathscr{F}(4 + 6n) \mathscr{F}(4) f(x) f(x) \in \mathbb{Z} \implies x \in \mathbb{Z} \left\lfloor f(x) \right \rfloor = \left\lfloor f(\lfloor x \rfloor) \right\rfloor f(x) = abx + bc F_n = a\lfloor f^n(bF_0) \rfloor +c \text{ where } f^n(x) = f(\underbrace{f(f(\dots))}_\textrm{n times} f^n(x_0) = (ab)^n x_0 + \frac{1-(ab)^n}{1-ab}cb a,b,c \in \mathbb{R^+} \left(abx + bc \in \mathbb{Z} \implies x \in \mathbb{Z}\right) F_n = a \left\lfloor (ab)^{n-1} bF_0 + \frac{1-(ab)^{n-1}}{1-ab}cb \right\rfloor + c  d|c c|d","['discrete-mathematics', 'recurrence-relations', 'ceiling-and-floor-functions']"
70,Does this prove the union of countably many countable sets is countable?,Does this prove the union of countably many countable sets is countable?,,"I am wondering if the following argument proves that the union of countably many sets is countable. Number each set  in the union by a number of zeroes, assigning an arbitrary set $0$ , the next set we pick $00$ , the next $000$ etc. And then assign each element in each of the sets a number of $1$ 's in the same manner- and then have an injection from this union and the set of all binary strings, by our function conjoining the set whence an element came and its position in that set to get a binary string (if an element is in multiple sets we arbitrarily pick one set and its position therein to map it to). Then this union is countable due to the set of finite binary strings being countable. I am unsure because proofs of this statement I have seen, such as this , use an argument which is more complicated, leading me to believe there is a fallacy in this seemingly simpler argument.","I am wondering if the following argument proves that the union of countably many sets is countable. Number each set  in the union by a number of zeroes, assigning an arbitrary set , the next set we pick , the next etc. And then assign each element in each of the sets a number of 's in the same manner- and then have an injection from this union and the set of all binary strings, by our function conjoining the set whence an element came and its position in that set to get a binary string (if an element is in multiple sets we arbitrarily pick one set and its position therein to map it to). Then this union is countable due to the set of finite binary strings being countable. I am unsure because proofs of this statement I have seen, such as this , use an argument which is more complicated, leading me to believe there is a fallacy in this seemingly simpler argument.",0 00 000 1,"['discrete-mathematics', 'elementary-set-theory', 'solution-verification']"
71,Number of bitstrings where any subpattern repeats at most $d$ times,Number of bitstrings where any subpattern repeats at most  times,d,"The following problem has come up in the context of unitary equivalence of sets of matrices. However, here I will omit the context and state it as a standalone combinatorial problem. Consider bitstrings, i.e., words made of 0's and 1's. The rule is: No sub-pattern can repeat more than $d$ times and the boundary conditions are periodic. Some examples of invalid bitstrings for $d=2$ : 000 (repetition), 0100 (repetition across boundary), 0101101101 (repetition of sub-pattern 101) Here are examples of valid string: 101, 010011011 Update : To clarify: a repetition only counts if the repetitions are adjacent to each other. For example, 010011011 is valid even though 01 appears multiple times, but never three times in a row. The questions are: Are there infinitely many valid strings or not? If not, can one give an upper bound to the number of valid strings? Our first impression is that one can get very long bit strings. However, we have neither been able to show that one can generate infinitely many, nor that there are only finitely many.","The following problem has come up in the context of unitary equivalence of sets of matrices. However, here I will omit the context and state it as a standalone combinatorial problem. Consider bitstrings, i.e., words made of 0's and 1's. The rule is: No sub-pattern can repeat more than times and the boundary conditions are periodic. Some examples of invalid bitstrings for : 000 (repetition), 0100 (repetition across boundary), 0101101101 (repetition of sub-pattern 101) Here are examples of valid string: 101, 010011011 Update : To clarify: a repetition only counts if the repetitions are adjacent to each other. For example, 010011011 is valid even though 01 appears multiple times, but never three times in a row. The questions are: Are there infinitely many valid strings or not? If not, can one give an upper bound to the number of valid strings? Our first impression is that one can get very long bit strings. However, we have neither been able to show that one can generate infinitely many, nor that there are only finitely many.",d d=2,"['combinatorics', 'discrete-mathematics', 'tiling', 'decidability']"
72,"Counting $\{a,a,b,b,c,c,d,d,d \}$ derangements. [duplicate]",Counting  derangements. [duplicate],"\{a,a,b,b,c,c,d,d,d \}","This question already has an answer here : Derangement formula for multisets (1 answer) Closed 10 months ago . Exam question: Let $D(d_{1},d_{2},...,d_{k})$ denote the number of derangements of a multiset where there are $d_{i}$ copies of elements of the $i$ -th kind, for $i=1,...,k$ . This means the arrangements of elements of this multiset in a sequence such that in the first $d_{1}$ positions there is no element of the first kind, in the next $d_{2}$ positions there is no element of the second kind, and so on. For example: $D(1,2)=0, D(2,2)=1, D(1,1,2)=2$ . The only derangements of the multiset $\{a,b,c,c\}$ are $\langle c,c,a,b \rangle$ and $\langle c,c,b,a \rangle$ . Find $D(2,2,2,3)$ . The WolframAlpha website might be useful for calculations. Initially, I was thinking about the principle of inclusion and exclusion: $ \frac{9!}{2! \cdot 2! \cdot 2! \cdot 3!} - 6 \binom{8}{1} \binom{7}{2} \binom{5}{2} - 3 \binom{8}{2} \binom{6}{2} \binom{4}{2} + \left( 3 \cdot 2 \cdot 2 \cdot \binom{6}{1} \cdot \binom{6}{1} \cdot \binom{5}{2} + 3 \binom{7}{2} \binom{5}{2} \right) + \left( 3 \cdot 3 \cdot 2 \cdot \binom{7}{1} \binom{6}{2} \binom{4}{2} + 3 \cdot \binom{7}{1} \binom{6}{2} \binom{4}{2} \right)-... $ Where in the first parenthesis I subtract situations when one of the letters a, b, c is in the wrong position, in the second parenthesis when d is in the wrong position, in the third parenthesis pairs but without the letter d and dividing into situations when the pair consists of two identical letters (both letters a, a are in the wrong positions) or two different ones (e.g., a, b). The fourth is the same as the third but is a case for pairs with the letter d. The problem is that there are still seven cases to consider left, and each subsequent one is worse. Brute force approach gives me $D(2,2,2,3)= 564$ . I have found similar questions Derangement formula for multisets , Derangements of a multiset with ""don't cares""? and I tried using the given formula but it doesn't seem to work: WolframAplha . How can one count these combinations?","This question already has an answer here : Derangement formula for multisets (1 answer) Closed 10 months ago . Exam question: Let denote the number of derangements of a multiset where there are copies of elements of the -th kind, for . This means the arrangements of elements of this multiset in a sequence such that in the first positions there is no element of the first kind, in the next positions there is no element of the second kind, and so on. For example: . The only derangements of the multiset are and . Find . The WolframAlpha website might be useful for calculations. Initially, I was thinking about the principle of inclusion and exclusion: Where in the first parenthesis I subtract situations when one of the letters a, b, c is in the wrong position, in the second parenthesis when d is in the wrong position, in the third parenthesis pairs but without the letter d and dividing into situations when the pair consists of two identical letters (both letters a, a are in the wrong positions) or two different ones (e.g., a, b). The fourth is the same as the third but is a case for pairs with the letter d. The problem is that there are still seven cases to consider left, and each subsequent one is worse. Brute force approach gives me . I have found similar questions Derangement formula for multisets , Derangements of a multiset with ""don't cares""? and I tried using the given formula but it doesn't seem to work: WolframAplha . How can one count these combinations?","D(d_{1},d_{2},...,d_{k}) d_{i} i i=1,...,k d_{1} d_{2} D(1,2)=0, D(2,2)=1, D(1,1,2)=2 \{a,b,c,c\} \langle c,c,a,b \rangle \langle c,c,b,a \rangle D(2,2,2,3) 
\frac{9!}{2! \cdot 2! \cdot 2! \cdot 3!} - 6 \binom{8}{1} \binom{7}{2} \binom{5}{2} - 3 \binom{8}{2} \binom{6}{2} \binom{4}{2} + \left( 3 \cdot 2 \cdot 2 \cdot \binom{6}{1} \cdot \binom{6}{1} \cdot \binom{5}{2} + 3 \binom{7}{2} \binom{5}{2} \right) + \left( 3 \cdot 3 \cdot 2 \cdot \binom{7}{1} \binom{6}{2} \binom{4}{2} + 3 \cdot \binom{7}{1} \binom{6}{2} \binom{4}{2} \right)-...
 D(2,2,2,3)= 564","['combinatorics', 'discrete-mathematics', 'inclusion-exclusion', 'derangements']"
73,How many paths of length $n$ with given beginning and end are there in the graph?,How many paths of length  with given beginning and end are there in the graph?,n,"Given a graph $G = (V, E)$ , with a set of vertices: $V = \mathcal{P}( \{1, 2, 3 \})$ and a set of edges: $$E = \{ \{A, B \} : A, B \subseteq \{1, 2, 3 \} \wedge |A \bigtriangleup B| = 1 \}$$ *where: $A \bigtriangleup B = (A \setminus B) \cup (B \setminus A)$ is the symmetric difference of sets $A$ and $B$ $\mathcal{P}(X)$ is a set of all subsets of $X$ How many paths $(A_0, A_1, ... A_n)$ of length $n \geq 3$ are there in the graph $G$ with a beginning at vertex $A_0 = \{ 1, 2, 3 \}$ and an end at vertex $A_n = \emptyset$ (all vertices, including the end vertex, may repeat)? As I understand it - we have vertices $8$ vertices, those are: { {1, 2, 3}, {1, 2}, {1, 3}, {2, 3}, {1}, {2}, {3}, { } }. We have $12$ edges and those are: $\{1, 2, 3\} - \{1, 2\}$ , $\{1, 2, 3\} - \{1, 3\}$ , $\{1, 2, 3\} - \{2, 3\}$ , $\{1, 2 \} - \{1 \}$ , $\{1, 2 \} - \{2 \}$ , $\{1, 3 \} - \{1 \}$ , $\{1, 3 \} - \{3 \}$ , $\{2, 3 \} - \{2 \}$ , $\{2, 3 \} - \{3 \}$ , $\{1 \} - \{ \}$ , $\{2 \} - \{ \}$ , $\{3 \} - \{ \}$ . The graph should therefore look like that: The paths that I see working for $n = 3$ are: $\{1, 2, 3\} - \{1, 3\} - \{ 3 \} - \{ \}$ , $\{1, 2, 3\} - \{1, 3\} - \{ 1 \} - \{ \}$ , $\{1, 2, 3\} - \{2, 3\} - \{ 3 \} - \{ \}$ , $\{1, 2, 3\} - \{2, 3\} - \{ 2 \} - \{ \}$ , $\{1, 2, 3\} - \{1, 2\} - \{ 1 \} - \{ \}$ , $\{1, 2, 3\} - \{1, 2\} - \{ 2 \} - \{ \}$ , There are $6$ of them. Hovever, I don't see any clever way to count them for a chosen $n$ . Edit: The adjacency matrix of that graph looks like that: the rows / columns: $\{1, 2, 3\}$ $\{1, 2\}$ $\{1, 3\}$ $\{2, 3\}$ $\{1 \}$ $\{2 \}$ $\{3 \}$ $\{ \}$ Therefore the matrix looks like that: $ M =  \begin{pmatrix} 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\ 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0\\ 1 & 0 & 0 & 0 & 1 & 0 & 1 & 0\\ 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0\\ 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0\\ 0 & 1 & 0 & 1 & 0 & 0 & 0 & 1\\ 0 & 0 & 1 & 1 & 0 & 0 & 0 & 1\\ 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1\\ \end{pmatrix} $ But then it's tp hard to diagonalize...","Given a graph , with a set of vertices: and a set of edges: *where: is the symmetric difference of sets and is a set of all subsets of How many paths of length are there in the graph with a beginning at vertex and an end at vertex (all vertices, including the end vertex, may repeat)? As I understand it - we have vertices vertices, those are: { {1, 2, 3}, {1, 2}, {1, 3}, {2, 3}, {1}, {2}, {3}, { } }. We have edges and those are: , , , , , , , , , , , . The graph should therefore look like that: The paths that I see working for are: , , , , , , There are of them. Hovever, I don't see any clever way to count them for a chosen . Edit: The adjacency matrix of that graph looks like that: the rows / columns: Therefore the matrix looks like that: But then it's tp hard to diagonalize...","G = (V, E) V = \mathcal{P}( \{1, 2, 3 \}) E = \{ \{A, B \} : A, B \subseteq \{1, 2, 3 \} \wedge |A \bigtriangleup B| = 1 \} A \bigtriangleup B = (A \setminus B) \cup (B \setminus A) A B \mathcal{P}(X) X (A_0, A_1, ... A_n) n \geq 3 G A_0 = \{ 1, 2, 3 \} A_n = \emptyset 8 12 \{1, 2, 3\} - \{1, 2\} \{1, 2, 3\} - \{1, 3\} \{1, 2, 3\} - \{2, 3\} \{1, 2 \} - \{1 \} \{1, 2 \} - \{2 \} \{1, 3 \} - \{1 \} \{1, 3 \} - \{3 \} \{2, 3 \} - \{2 \} \{2, 3 \} - \{3 \} \{1 \} - \{ \} \{2 \} - \{ \} \{3 \} - \{ \} n = 3 \{1, 2, 3\} - \{1, 3\} - \{ 3 \} - \{ \} \{1, 2, 3\} - \{1, 3\} - \{ 1 \} - \{ \} \{1, 2, 3\} - \{2, 3\} - \{ 3 \} - \{ \} \{1, 2, 3\} - \{2, 3\} - \{ 2 \} - \{ \} \{1, 2, 3\} - \{1, 2\} - \{ 1 \} - \{ \} \{1, 2, 3\} - \{1, 2\} - \{ 2 \} - \{ \} 6 n \{1, 2, 3\} \{1, 2\} \{1, 3\} \{2, 3\} \{1 \} \{2 \} \{3 \} \{ \} 
M = 
\begin{pmatrix}
0 & 1 & 1 & 1 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 1 & 1 & 0 & 0\\
1 & 0 & 0 & 0 & 1 & 0 & 1 & 0\\
1 & 0 & 0 & 0 & 0 & 1 & 1 & 0\\
0 & 1 & 1 & 0 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 1 & 0 & 0 & 0 & 1\\
0 & 0 & 1 & 1 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 1 & 1 & 1 & 1\\
\end{pmatrix}
","['discrete-mathematics', 'graph-theory']"
74,Understanding a Specific Instance of Leibniz's Law in Discrete Mathematics,Understanding a Specific Instance of Leibniz's Law in Discrete Mathematics,,"I'm currently studying discrete mathematics and working on exercises related to Leibniz's law: $$\frac{X=Y}{E[z:=X]=E[z:=Y]}$$ I've come across a particular problem that I'm struggling to understand: Below, are a number of instantiations of Leibniz, with parts missing. Fill in the missing parts and write down what the expression $E$ is. $$\frac{7=y+1}{7\cdot{x}+7\cdot{y}=?}$$ Here's what I've tried so far: Step 1. $$E=x\cdot z+y\cdot z$$ Step 2. $$\frac{7=y+1}{E[z:=7]=E[z:=y+1]}$$ Step 3. $$\frac{7=y+1}{7\cdot x+7\cdot y=x\cdot (y+1)+y\cdot (y+1)}$$ $${\mathrm{Answer:}}\ x\cdot (y+1)+y\cdot (y+1)$$ But according to the textbook, there should be three answers. Could someone please explain the logic behind this problem and how to approach it using Leibniz's law? Are there any underlying principles or theorems that I should be aware of to solve this problem? My textbook is ""A Logical Approach to Discrete Mathematics"" . Any insights, explanations, or references to relevant material would be greatly appreciated.","I'm currently studying discrete mathematics and working on exercises related to Leibniz's law: I've come across a particular problem that I'm struggling to understand: Below, are a number of instantiations of Leibniz, with parts missing. Fill in the missing parts and write down what the expression is. Here's what I've tried so far: Step 1. Step 2. Step 3. But according to the textbook, there should be three answers. Could someone please explain the logic behind this problem and how to approach it using Leibniz's law? Are there any underlying principles or theorems that I should be aware of to solve this problem? My textbook is ""A Logical Approach to Discrete Mathematics"" . Any insights, explanations, or references to relevant material would be greatly appreciated.",\frac{X=Y}{E[z:=X]=E[z:=Y]} E \frac{7=y+1}{7\cdot{x}+7\cdot{y}=?} E=x\cdot z+y\cdot z \frac{7=y+1}{E[z:=7]=E[z:=y+1]} \frac{7=y+1}{7\cdot x+7\cdot y=x\cdot (y+1)+y\cdot (y+1)} {\mathrm{Answer:}}\ x\cdot (y+1)+y\cdot (y+1),"['discrete-mathematics', 'logic']"
75,Maximal set of independent random variables on a discrete probability space,Maximal set of independent random variables on a discrete probability space,,"Suppose we have a finite discrete probability space $(\Omega, P)$ (say $|\Omega| = n$ ). What is the maximum number of random variables on this space that are mutually independent? With a bit of work we can find random variables $X_1, \ldots, X_n$ so that $\mathrm{cov}(X_i, X_j) = 0$ for $i \neq j$ . It is not the case, however, that covariance $0$ implies independence. -e- I changed the notation to be consistent with what it seems is more used.","Suppose we have a finite discrete probability space (say ). What is the maximum number of random variables on this space that are mutually independent? With a bit of work we can find random variables so that for . It is not the case, however, that covariance implies independence. -e- I changed the notation to be consistent with what it seems is more used.","(\Omega, P) |\Omega| = n X_1, \ldots, X_n \mathrm{cov}(X_i, X_j) = 0 i \neq j 0","['probability', 'discrete-mathematics', 'independence']"
76,Constructing a Kripke model where $p \rightarrow \Box \Diamond q$ is false.,Constructing a Kripke model where  is false.,p \rightarrow \Box \Diamond q,"I have constructed the following Kripke model for this problem: My idea is the following: Implication is false iff we have $ \top \implies \bot$ . For world $0$ , we have that $p$ is true. Now we need to evaluate $\Box \Diamond q$ . For world $0$ , $\Box \Diamond q$ is true iff $\Diamond q$ is  true in every world which is reachable from world $0$ (that would be world $1$ ). Now, in world $1$ , $\Diamond q$ is true if $q$ is true in at least one world reachable from world $1$ , and the only such world is $2$ . Now, since $q$ is false in world $2$ , we can say that $\Diamond q$ is false in $1$ , and so $\Box \Diamond q$ is false in $0$ . We have our implication $\top \implies \bot$ . My questions are: Obviously, the value of $q$ in world $1$ is $\neg q$ . However, we don't really need that value for anything because we only use world $1$ as an ""intermediary"" world of sorts, right? Can different worlds in the same Kripke model have the same truth values for the same variables? I.e., could I have added a world $3$ with $p,q$ as values for $p,q$ ?","I have constructed the following Kripke model for this problem: My idea is the following: Implication is false iff we have . For world , we have that is true. Now we need to evaluate . For world , is true iff is  true in every world which is reachable from world (that would be world ). Now, in world , is true if is true in at least one world reachable from world , and the only such world is . Now, since is false in world , we can say that is false in , and so is false in . We have our implication . My questions are: Obviously, the value of in world is . However, we don't really need that value for anything because we only use world as an ""intermediary"" world of sorts, right? Can different worlds in the same Kripke model have the same truth values for the same variables? I.e., could I have added a world with as values for ?"," \top \implies \bot 0 p \Box \Diamond q 0 \Box \Diamond q \Diamond q 0 1 1 \Diamond q q 1 2 q 2 \Diamond q 1 \Box \Diamond q 0 \top \implies \bot q 1 \neg q 1 3 p,q p,q","['discrete-mathematics', 'logic', 'propositional-calculus', 'modal-logic', 'kripke-models']"
77,Find the number of subsets of n chairs in a circle containing at least three adjacent chairs,Find the number of subsets of n chairs in a circle containing at least three adjacent chairs,,"Find the number of subsets of $n$ chairs in a circle containing at least three adjacent chairs. I know that the answer for $n=10$ is $581$ , and the solution is here for instance. I'm not sure if it's possible to derive a recurrence relation for this problem, but if it is, it would be very useful for the general case. In the case of 10 chairs, there are only two disjoint groups of four chairs, where in each group the first chair is not in the subset and the next three are in the subset, while for the general case, there could be arbitrarily many such groups. Such groups of four chairs exist iff not all chairs are filled, where a chair is filled if it's in a given subset. It seems that the principle of inclusion and exclusion would be too unwieldy for this problem; one could consider the number of subsets where adjacent chairs appear in groups of 1 or 2 and there is at least one group of 2 and the number of subsets where no chairs are adjacent. Note that the latter value is much easier to find than the former value and the latter value equals $\sum_k {n-k+1\choose k} - {n-k-3\choose k-2},$ where the sum is over nonnnegative integers k using the convention that ${n\choose k}=0$ for $n<k$ . Is there a recurrent relation for the general case?","Find the number of subsets of chairs in a circle containing at least three adjacent chairs. I know that the answer for is , and the solution is here for instance. I'm not sure if it's possible to derive a recurrence relation for this problem, but if it is, it would be very useful for the general case. In the case of 10 chairs, there are only two disjoint groups of four chairs, where in each group the first chair is not in the subset and the next three are in the subset, while for the general case, there could be arbitrarily many such groups. Such groups of four chairs exist iff not all chairs are filled, where a chair is filled if it's in a given subset. It seems that the principle of inclusion and exclusion would be too unwieldy for this problem; one could consider the number of subsets where adjacent chairs appear in groups of 1 or 2 and there is at least one group of 2 and the number of subsets where no chairs are adjacent. Note that the latter value is much easier to find than the former value and the latter value equals where the sum is over nonnnegative integers k using the convention that for . Is there a recurrent relation for the general case?","n n=10 581 \sum_k {n-k+1\choose k} - {n-k-3\choose k-2}, {n\choose k}=0 n<k","['combinatorics', 'discrete-mathematics', 'contest-math', 'recreational-mathematics', 'dynamic-programming']"
78,Combinatorics graphs for $2k+1$ representatives from $k $ different countries.,Combinatorics graphs for  representatives from  different countries.,2k+1 k ,"I'm having trouble with the following question : Representatives from $1+2k$ countries come to an international conference, $k$ representatives from each country. Is it possible to seat the $k(2k+1)$ representatives around a round table so that each pair of countries has Representatives sitting side by side?"" At first I thought of making a graph with $2k+1$ vertices, every edge will represent two representatives from $2$ different countries. Then prove that an Eulerian cycle exists. I'm not sure if that's the right way to approach this question, I would appreciate advices for this problem.","I'm having trouble with the following question : Representatives from countries come to an international conference, representatives from each country. Is it possible to seat the representatives around a round table so that each pair of countries has Representatives sitting side by side?"" At first I thought of making a graph with vertices, every edge will represent two representatives from different countries. Then prove that an Eulerian cycle exists. I'm not sure if that's the right way to approach this question, I would appreciate advices for this problem.",1+2k k k(2k+1) 2k+1 2,"['combinatorics', 'discrete-mathematics', 'graph-theory', 'eulerian-path']"
79,"Translating ""There are two different students in your class who between them have sent an e-mail message to or telephoned everyone else in the class""","Translating ""There are two different students in your class who between them have sent an e-mail message to or telephoned everyone else in the class""",,"Let $M(x,y)$ be “ $x$ has sent $y$ an e-mail message” and $T(x,y)$ be “ $x$ has telephoned $y$ ”, where the domain consists of all students in your class. Assume that all e-mail messages that were sent are received, which is not the way things often work. Symbolise this statement in first-order logic: There are two different students in your class who between them have sent an e-mail message to or telephoned everyone else in the class. I'm not sure whether my answer is correct; if not, please tell me the reasons: $$∃x∃y(x≠y ∧ ∀z(∀s(M(z,s)∨T(z,s)) ↔ (z = x ∨ z = y))).$$","Let be “ has sent an e-mail message” and be “ has telephoned ”, where the domain consists of all students in your class. Assume that all e-mail messages that were sent are received, which is not the way things often work. Symbolise this statement in first-order logic: There are two different students in your class who between them have sent an e-mail message to or telephoned everyone else in the class. I'm not sure whether my answer is correct; if not, please tell me the reasons:","M(x,y) x y T(x,y) x y ∃x∃y(x≠y ∧ ∀z(∀s(M(z,s)∨T(z,s)) ↔ (z = x ∨ z = y))).","['discrete-mathematics', 'predicate-logic', 'quantifiers', 'logic-translation']"
80,Is this relation analysis correct?,Is this relation analysis correct?,,"In my previous assignment, I was given two sets, A and B, both containing the elements 1, 2, 3, and 4. Additionally, I was provided with a relation C, which consisted of pairs of elements: (1, 1), (3, 4), (2, 2), and (3, 3). I argued that relation C was transitive based on the definition of transitivity. I believed that by considering (3, 3) as (a, b) and (3, 4) as (b, c), I could conclude that (a, c) would be (3, 4), which already existed in the set. To my surprise, my teacher disagreed and claimed that relation C was not transitive, reflexive, or symmetric. Now, I am wondering if I can contest my grade because I strongly believe that my reasoning is correct. I even sought assistance by posting a question on the Mathematics Stack Exchange website months ago, which can be found at the provided link: Transitive relation of non function","In my previous assignment, I was given two sets, A and B, both containing the elements 1, 2, 3, and 4. Additionally, I was provided with a relation C, which consisted of pairs of elements: (1, 1), (3, 4), (2, 2), and (3, 3). I argued that relation C was transitive based on the definition of transitivity. I believed that by considering (3, 3) as (a, b) and (3, 4) as (b, c), I could conclude that (a, c) would be (3, 4), which already existed in the set. To my surprise, my teacher disagreed and claimed that relation C was not transitive, reflexive, or symmetric. Now, I am wondering if I can contest my grade because I strongly believe that my reasoning is correct. I even sought assistance by posting a question on the Mathematics Stack Exchange website months ago, which can be found at the provided link: Transitive relation of non function",,"['discrete-mathematics', 'relations']"
81,Prove a lemma about permutations,Prove a lemma about permutations,,"Let $V$ be a set of $n$ permutations of $m$ numbers. Let $m<n<<m!$ I want to prove the following lemma: Lemma: For any set of permutations $V$ there exists a pair of numbers $(a,b)$ such that $\frac{|(v\in V: a\succcurlyeq b)|}{|(v\in V: b\succcurlyeq a)|}\approx 1$ . In other words, prove that there always exists a pair of numbers such that the number of partitions where $a$ comes before $b$ is approximately equal to the number of partitions where $b$ comes before $a$ . For the sake of completeness, I want to prove this lemma in order to be able to prove the following theorem: Theorem: Let $n$ be the number of permutations of $m$ numbers. Let $m<n<<m!$ . We now construct a binomial tree where at the root of the tree there is the set of all $n$ permutations. Each node we select a couple of elements of the permutations $(a,b)$ and split the permutations into two nodes containing two subsets of permutations: one with each permutation where $a$ comes before $n$ and the other viceversa. A node is a leaf if it contains equal permutations. Prove that the optimal height of the tree is $O(\log{n})$ .","Let be a set of permutations of numbers. Let I want to prove the following lemma: Lemma: For any set of permutations there exists a pair of numbers such that . In other words, prove that there always exists a pair of numbers such that the number of partitions where comes before is approximately equal to the number of partitions where comes before . For the sake of completeness, I want to prove this lemma in order to be able to prove the following theorem: Theorem: Let be the number of permutations of numbers. Let . We now construct a binomial tree where at the root of the tree there is the set of all permutations. Each node we select a couple of elements of the permutations and split the permutations into two nodes containing two subsets of permutations: one with each permutation where comes before and the other viceversa. A node is a leaf if it contains equal permutations. Prove that the optimal height of the tree is .","V n m m<n<<m! V (a,b) \frac{|(v\in V: a\succcurlyeq b)|}{|(v\in V: b\succcurlyeq a)|}\approx 1 a b b a n m m<n<<m! n (a,b) a n O(\log{n})","['discrete-mathematics', 'permutations', 'order-theory', 'trees', 'decision-trees']"
82,Find a derivation for$\{\varphi \Rightarrow (\psi \land \phi)\} \vdash \psi \to (\varphi \Rightarrow \phi)$,Find a derivation for,\{\varphi \Rightarrow (\psi \land \phi)\} \vdash \psi \to (\varphi \Rightarrow \phi),"I was given the following problem: Find a derivation for $\{\varphi \Rightarrow (\psi \land \phi)\} \vdash \psi \Rightarrow (\varphi \Rightarrow \phi)$ The derivation is to be made using natural deduction. I came to the following derivation: However, I am unsure of the last step ( $\Rightarrow I$ ). It is the case that $\psi$ was found to be true; namely, when we arrived to $\psi \land \phi$ . So the conclusion seems correct from an intuitive point of view. But I think the formal application of the rule is incorrect. The rule for $\Rightarrow I$ states that If $[\varphi] \ldots \phi $ is a derivation, then $\varphi \Rightarrow \phi$ . In our case, I should have gotten a derivation of the form $\psi \ldots (\varphi \Rightarrow \phi)$ , but what I have is a derivation of the form $(\psi \land \phi) \ldots (\varphi \Rightarrow \phi)$ , which is not identical to what is stated in the rule. Of course, another rule is $\land E$ , by virtue of which $\psi$ follows from $\psi \land \phi$ , but I have never applied this rule explicitly for $\psi$ (only for $\phi$ ).","I was given the following problem: Find a derivation for The derivation is to be made using natural deduction. I came to the following derivation: However, I am unsure of the last step ( ). It is the case that was found to be true; namely, when we arrived to . So the conclusion seems correct from an intuitive point of view. But I think the formal application of the rule is incorrect. The rule for states that If is a derivation, then . In our case, I should have gotten a derivation of the form , but what I have is a derivation of the form , which is not identical to what is stated in the rule. Of course, another rule is , by virtue of which follows from , but I have never applied this rule explicitly for (only for ).","\{\varphi \Rightarrow (\psi \land \phi)\} \vdash \psi \Rightarrow (\varphi
\Rightarrow \phi) \Rightarrow I \psi \psi \land \phi \Rightarrow I [\varphi] \ldots \phi  \varphi \Rightarrow \phi \psi \ldots (\varphi \Rightarrow \phi) (\psi \land \phi) \ldots (\varphi \Rightarrow \phi) \land E \psi \psi \land \phi \psi \phi","['discrete-mathematics', 'logic', 'propositional-calculus', 'natural-deduction']"
83,"In a 52-card deck, 3 cards are drawn. Calculate the probability of obtaining at least 1 ace.","In a 52-card deck, 3 cards are drawn. Calculate the probability of obtaining at least 1 ace.",,"I have a problem with defining the events in probaility like for this example. In a 52-card deck, 3 cards are drawn. Calculate the probability of obtaining at least 1 ace. I dont understand How to seperate the events As for this example I multiplied the choice of an ace card among the four ace type cards I multiplied it by all the combinations of choosing 2 remaining cards among 51 cards and then I divided the whole by the choice of 3 cards among 52. I would like to understand my mistake I know the solution is to use 1-p(a)","I have a problem with defining the events in probaility like for this example. In a 52-card deck, 3 cards are drawn. Calculate the probability of obtaining at least 1 ace. I dont understand How to seperate the events As for this example I multiplied the choice of an ace card among the four ace type cards I multiplied it by all the combinations of choosing 2 remaining cards among 51 cards and then I divided the whole by the choice of 3 cards among 52. I would like to understand my mistake I know the solution is to use 1-p(a)",,"['probability', 'probability-theory', 'discrete-mathematics', 'computational-mathematics', 'card-games']"
84,"What is a function $f : 2^n \rightarrow n$ such that for each $y \in n$ and $A \in 2^n$ there is $x \in n$ such that $f(\tau(x,A)) = y$?",What is a function  such that for each  and  there is  such that ?,"f : 2^n \rightarrow n y \in n A \in 2^n x \in n f(\tau(x,A)) = y","We first set up some notations and definitions: We view each positive integer $n$ as a (particular) set of $n$ elements. We also pick some bijection $\phi_n : 2^n \xrightarrow{\approx} \mathcal{P}(n)$ , where the codomain denotes the power set of $n$ . Define the function $\tau_n : n \times 2^n \rightarrow 2^n$ given by $$ \tau(x,A) =  \left\{\begin{matrix} \phi^{-1}( \phi(A) \setminus\{x\} ) \,, & x \in \phi(A) \\  \phi^{-1}( \phi(A) \cup\{x\} ) \,, & x \notin \phi(A) \\   \end{matrix}\right. $$ where the implied subscript on each of the $\tau$ 's, $\phi$ 's in the above equation is $n$ . Then my question is: For which positive integers $n$ does there exist a function $f_n : 2^n \rightarrow n$ such that for each $A \in 2^n , y\in n$ there exists $x \in n$ such that $f_n(\tau_n(x,A)) = y$ ? And for such $n$ , how would we find such a function? For background, the above question arises in considering the following puzzle: Alice and Bob are in prison, and the warden suggests a deal to them, where they will go free if they can win the following game: 0. First Alice and Bob are allowed to devise a strategy on their own, after being told about this game. However, after they agree to start the game, Alice and Bob may have no further contact. 1. The warden shows Alice an oriented $m\times m$ grid of coins, each of which will be randomly in either the heads or tails position. 2. Next, the warden points to a (randomly chosen) particular coin position, say position $P$ , which is seen by Alice. (He doesn't change the coins in any way.) 3. Alice is then required to flip exactly one coin, of her choosing. (She may not avoid flipping any coins.) 4. Alice leaves and Bob is shown the grid of coins. The two have had no contact since Alice saw the coins and Bob has not seen the coins before this. 5. Bob must determine the position $P$ , with no further input aside from looking at the coins. If this is accomplished, then Alice and Bob go free. The question is, for which $m$ is a winning strategy possible, and what would be such a strategy? Note: with the above notation, $n=m^2$ .","We first set up some notations and definitions: We view each positive integer as a (particular) set of elements. We also pick some bijection , where the codomain denotes the power set of . Define the function given by where the implied subscript on each of the 's, 's in the above equation is . Then my question is: For which positive integers does there exist a function such that for each there exists such that ? And for such , how would we find such a function? For background, the above question arises in considering the following puzzle: Alice and Bob are in prison, and the warden suggests a deal to them, where they will go free if they can win the following game: 0. First Alice and Bob are allowed to devise a strategy on their own, after being told about this game. However, after they agree to start the game, Alice and Bob may have no further contact. 1. The warden shows Alice an oriented grid of coins, each of which will be randomly in either the heads or tails position. 2. Next, the warden points to a (randomly chosen) particular coin position, say position , which is seen by Alice. (He doesn't change the coins in any way.) 3. Alice is then required to flip exactly one coin, of her choosing. (She may not avoid flipping any coins.) 4. Alice leaves and Bob is shown the grid of coins. The two have had no contact since Alice saw the coins and Bob has not seen the coins before this. 5. Bob must determine the position , with no further input aside from looking at the coins. If this is accomplished, then Alice and Bob go free. The question is, for which is a winning strategy possible, and what would be such a strategy? Note: with the above notation, .","n n \phi_n : 2^n \xrightarrow{\approx} \mathcal{P}(n) n \tau_n : n \times 2^n \rightarrow 2^n 
\tau(x,A) = 
\left\{\begin{matrix}
\phi^{-1}( \phi(A) \setminus\{x\} ) \,, & x \in \phi(A) \\ 
\phi^{-1}( \phi(A) \cup\{x\} ) \,, & x \notin \phi(A) \\  
\end{matrix}\right.
 \tau \phi n n f_n : 2^n \rightarrow n A \in 2^n , y\in n x \in n f_n(\tau_n(x,A)) = y n m\times m P P m n=m^2",['discrete-mathematics']
85,"HMMT 2014 #9, how many times has Lucky performed the procedure when there are 20 tails-up coins?","HMMT 2014 #9, how many times has Lucky performed the procedure when there are 20 tails-up coins?",,"There is a heads up coin on every integer of the number line. Lucky is initially standing on the zero point of the number line facing in the positive direction. Lucky performs the following procedure: he looks at the coin (or lack thereof) underneath him, and then, If the coin is heads up, Lucky flips it to tails up, turns around, and steps forward a distance of one unit. If the coin is tails up, Lucky picks up the coin and steps forward a distance of one unit facing the same direction. If there is no coin, Lucky places a coin heads up underneath him and steps forward a distance of one unit facing the same direction. He repeats this procedure until there are 20 coins anywhere that are tails up. How many times has Lucky performed the procedure when the process stops? Source: HMMT 2014 Problem 9 (with an official solution) In the official solution, 4 claims are made: We keep track of the following quantities: Let $N$ be the sum of $2^k$ , where $k$ ranges over all nonnegative integers such that position $−1 − k$ on the number line contains a tails-up coin. Let $M$ be the sum of $2^k$ , where $k$ ranges over all nonnegative integers such that position $k$ contains a tails-up coin. We also make the following definitions: A ""right event"" is the event that Lucky crosses from the negative integers on the number line to the non-negative integers. A ""left event"" is the event that Lucky crosses from the non-negative integers on the number line to the negative integers. We now make the following claims: Claim (a): Every time a right event or left event occurs, every point on the number line contains a coin. Claim (b): Suppose that $n$ is a positive integer. When the $n$ th left event occurs, the value of $M$ is equal to $n$ . When the $n$ th right event occurs, the value of $N$ is equal to $n$ . Claim (c): For a nonzero integer $n$ , denote by $\nu_2(n)$ the largest integer $k$ such that $2^k$ divides $n$ . The number of steps that elapse between the $(n−1)$ st right event and the $n$ th left event is equal to $2\nu_2(n)+1$ . The number of steps that elapse between the $n$ th left event and the $n$ th right event is also equal to $2\nu_2(n)+1$ . (If $n − 1 = 0$ , then the “ $(n − 1)$ st right event” refers to the beginning of the simulation.) Claim (d): The man stops as soon as the $1023$ rd right event occurs. (Note that $1023 = 2^{10} − 1$ .) Below is my attempt of a proof of claims (a)-(d) except (b), which was proved in the official solution. I'd appreciate any simpler solutions and an answer to my question at the end. We prove claims (a)-(d) except claim (b) below. Proof of claim (a): We use induction on the total number of right and left events to prove the following stronger claim: right after each event, there exist some nonnegative integers $l$ and $m$ so that points $0$ to $l-1$ contain tails up coins, points $-m$ to $-1$ contain tails up coins, and points $l$ and $-(m+1)$ contain heads up coins and  all other points contain coins. The claim holds trivially in the base case where no events have occurred. Suppose the some (possibly zero) events have occurred. Suppose first that a right event just occurred (we consider the starting point to be the end of the 0th right event) and Lucky is currently at point $0$ and facing in the positive direction. Then Lucky picks up the coins at points $0$ to $l-1$ , turns over the coin at point $l$ , puts heads up coins at points $l-1$ down to $0$ and then moves to point $-1,$ causing a left event to occur, and the claim holds. If a left event just occurred, then Lucky is at point $-1$ . Since Lucky only performed a finite number of moves, only a finite number of tails up coins are on the number line. Lucky then proceeds to pick up all tails up coins from $-1$ down to $-m$ for some nonnegative integer m where m is maximal so that the coins at points $-1$ down to $-m$ are tails up, flips the heads up coin at $-(m+1)$ , and places heads up coins at $-m$ to $-1$ . Lucky then moves to point $0$ and a right event occurs. At this point, the claim of the inductive hypothesis still holds, since coins at $0$ to $l-1$ are unchanged. Proof of claim (c): For convenience, say a point $x$ is tails up if there is a tails up coin at it and define a heads up point similarly. Also say that for a positive integer $n$ , bit $k$ in $n$ 's binary representation is the bit with value $2^k.$ Note that since right and left events alternate, with a left event occurring first, then the $n$ th left event always precedes the $n$ th right event and the $(n+1)$ th left event follows the $n$ th right event (which follows by induction). Thus, by claim (b) and the above observation,  after the $(n-1)$ th right event, $M=n-1, N=n-1$ . In particular, the point $k\ge 0$ is tails up iff $2^k$ has a nonzero coefficient in the binary representation of $n-1$ . Now if $k=v_2(n)$ , we know that points $0,\cdots, k-1$ are all tails up, since the bits with values $2^0,\cdots, 2^{k-1}$ in the binary representation of $n-1$ must all be $1$ 's and bit $k$ is $0$ because otherwise we'd get a contradiction to the maximality of $k$ . Hence $k$ steps are taken to pick up the coins at points $0$ to $k-1,$ and k+1 more steps to place heads up coins at $k-1,\cdots, -1$ . After this, the $n$ th left event occurs. This proves the first part of the claim. Now to prove the second part, suppose the $n$ th left event has just finished, where $n\ge 1.$ Then Lucky is at point $-1$ . Let $k=v_2(n).$ Then since $N$ equals $n-1$ at this point, point $-1-k$ is tails up iff bit $k$ in the binary representation of $n-1$ is a $1$ . By the definition of $k$ , bits $0$ to $k-1$ in the binary representation of $n-1$ are $1$ while bit $k$ is a zero. Hence Lucky picks up the $k$ coins at $-1,-2,\cdots, -k$ , flips over the heads up coin at $-k-1$ , and puts heads up coins at $-k,\cdots, -1$ and then moves to point $0$ . At this point, the $n$ th right event occurs and exactly $2k+1$ steps have occurred, as required. Finally, Proof of claim (d): We just need to consider the end of a left or right event. (Why?) The man stops precisely when $N$ has $x$ ones and $M$ has $y$ ones in their binary representation, where $x+y = 20$ . If the man stopped at the nth left event, then $M=n, N =n-1$ . If the man stopped at the nth right event, then $N=n,M=n$ . Note that the number of ones in the binary representation of $n-1$ is the number of ones in the binary representation of $n$ plus $v_2(n)-1.$ So we need to find the smallest positive integer $n$ so that $2B(n) + v_2(n)-1 = 20$ or $B(n)=10,$ where $B(n)$ is the number of ones in the binary representation of $n$ . The smallest $n$ with $B(n)=10$ is $1023.$ If $B(n)<10,$ then $v_2(n) = 21 - 2B(n)\ge 3,$ so $n$ is divisible by $8$ . If $B(n)\leq 5,$ then $n$ is divisible by $2^{10}$ and thus would be larger than $1023.$ $n$ is at least $2^{v_2(n)} \cdot (2^{B(n)}-1),$ since $n/2^{v_2(n)}$ has $B(n)$ ones in its binary representation.  Thus if $B(n)= 6,7,8,9$ then $n$ is at least the minimum of $2^9\cdot 63, 2^7\cdot 127, 2^5\cdot 255, 2^3\cdot 511,$ all of which exceed $1023$ . If the man has yet to complete the nth right event, then $N$ is strictly less than $n$ and $M$ is at most $n$ (by the proof of claim (b) in the official solution, in between a left event and the subsequent right event or vice versa, $M$ or $N$ respectively decrease, and only increase by $1$ when Lucky turns over a heads up coin before turning around and placing tails up coins. But doesn't the man stop just before he completes the $n$ th right event?","There is a heads up coin on every integer of the number line. Lucky is initially standing on the zero point of the number line facing in the positive direction. Lucky performs the following procedure: he looks at the coin (or lack thereof) underneath him, and then, If the coin is heads up, Lucky flips it to tails up, turns around, and steps forward a distance of one unit. If the coin is tails up, Lucky picks up the coin and steps forward a distance of one unit facing the same direction. If there is no coin, Lucky places a coin heads up underneath him and steps forward a distance of one unit facing the same direction. He repeats this procedure until there are 20 coins anywhere that are tails up. How many times has Lucky performed the procedure when the process stops? Source: HMMT 2014 Problem 9 (with an official solution) In the official solution, 4 claims are made: We keep track of the following quantities: Let be the sum of , where ranges over all nonnegative integers such that position on the number line contains a tails-up coin. Let be the sum of , where ranges over all nonnegative integers such that position contains a tails-up coin. We also make the following definitions: A ""right event"" is the event that Lucky crosses from the negative integers on the number line to the non-negative integers. A ""left event"" is the event that Lucky crosses from the non-negative integers on the number line to the negative integers. We now make the following claims: Claim (a): Every time a right event or left event occurs, every point on the number line contains a coin. Claim (b): Suppose that is a positive integer. When the th left event occurs, the value of is equal to . When the th right event occurs, the value of is equal to . Claim (c): For a nonzero integer , denote by the largest integer such that divides . The number of steps that elapse between the st right event and the th left event is equal to . The number of steps that elapse between the th left event and the th right event is also equal to . (If , then the “ st right event” refers to the beginning of the simulation.) Claim (d): The man stops as soon as the rd right event occurs. (Note that .) Below is my attempt of a proof of claims (a)-(d) except (b), which was proved in the official solution. I'd appreciate any simpler solutions and an answer to my question at the end. We prove claims (a)-(d) except claim (b) below. Proof of claim (a): We use induction on the total number of right and left events to prove the following stronger claim: right after each event, there exist some nonnegative integers and so that points to contain tails up coins, points to contain tails up coins, and points and contain heads up coins and  all other points contain coins. The claim holds trivially in the base case where no events have occurred. Suppose the some (possibly zero) events have occurred. Suppose first that a right event just occurred (we consider the starting point to be the end of the 0th right event) and Lucky is currently at point and facing in the positive direction. Then Lucky picks up the coins at points to , turns over the coin at point , puts heads up coins at points down to and then moves to point causing a left event to occur, and the claim holds. If a left event just occurred, then Lucky is at point . Since Lucky only performed a finite number of moves, only a finite number of tails up coins are on the number line. Lucky then proceeds to pick up all tails up coins from down to for some nonnegative integer m where m is maximal so that the coins at points down to are tails up, flips the heads up coin at , and places heads up coins at to . Lucky then moves to point and a right event occurs. At this point, the claim of the inductive hypothesis still holds, since coins at to are unchanged. Proof of claim (c): For convenience, say a point is tails up if there is a tails up coin at it and define a heads up point similarly. Also say that for a positive integer , bit in 's binary representation is the bit with value Note that since right and left events alternate, with a left event occurring first, then the th left event always precedes the th right event and the th left event follows the th right event (which follows by induction). Thus, by claim (b) and the above observation,  after the th right event, . In particular, the point is tails up iff has a nonzero coefficient in the binary representation of . Now if , we know that points are all tails up, since the bits with values in the binary representation of must all be 's and bit is because otherwise we'd get a contradiction to the maximality of . Hence steps are taken to pick up the coins at points to and k+1 more steps to place heads up coins at . After this, the th left event occurs. This proves the first part of the claim. Now to prove the second part, suppose the th left event has just finished, where Then Lucky is at point . Let Then since equals at this point, point is tails up iff bit in the binary representation of is a . By the definition of , bits to in the binary representation of are while bit is a zero. Hence Lucky picks up the coins at , flips over the heads up coin at , and puts heads up coins at and then moves to point . At this point, the th right event occurs and exactly steps have occurred, as required. Finally, Proof of claim (d): We just need to consider the end of a left or right event. (Why?) The man stops precisely when has ones and has ones in their binary representation, where . If the man stopped at the nth left event, then . If the man stopped at the nth right event, then . Note that the number of ones in the binary representation of is the number of ones in the binary representation of plus So we need to find the smallest positive integer so that or where is the number of ones in the binary representation of . The smallest with is If then so is divisible by . If then is divisible by and thus would be larger than is at least since has ones in its binary representation.  Thus if then is at least the minimum of all of which exceed . If the man has yet to complete the nth right event, then is strictly less than and is at most (by the proof of claim (b) in the official solution, in between a left event and the subsequent right event or vice versa, or respectively decrease, and only increase by when Lucky turns over a heads up coin before turning around and placing tails up coins. But doesn't the man stop just before he completes the th right event?","N 2^k k −1 − k M 2^k k k n n M n n N n n \nu_2(n) k 2^k n (n−1) n 2\nu_2(n)+1 n n 2\nu_2(n)+1 n − 1 = 0 (n − 1) 1023 1023 = 2^{10} − 1 l m 0 l-1 -m -1 l -(m+1) 0 0 l-1 l l-1 0 -1, -1 -1 -m -1 -m -(m+1) -m -1 0 0 l-1 x n k n 2^k. n n (n+1) n (n-1) M=n-1, N=n-1 k\ge 0 2^k n-1 k=v_2(n) 0,\cdots, k-1 2^0,\cdots, 2^{k-1} n-1 1 k 0 k k 0 k-1, k-1,\cdots, -1 n n n\ge 1. -1 k=v_2(n). N n-1 -1-k k n-1 1 k 0 k-1 n-1 1 k k -1,-2,\cdots, -k -k-1 -k,\cdots, -1 0 n 2k+1 N x M y x+y = 20 M=n, N =n-1 N=n,M=n n-1 n v_2(n)-1. n 2B(n) + v_2(n)-1 = 20 B(n)=10, B(n) n n B(n)=10 1023. B(n)<10, v_2(n) = 21 - 2B(n)\ge 3, n 8 B(n)\leq 5, n 2^{10} 1023. n 2^{v_2(n)} \cdot (2^{B(n)}-1), n/2^{v_2(n)} B(n) B(n)= 6,7,8,9 n 2^9\cdot 63, 2^7\cdot 127, 2^5\cdot 255, 2^3\cdot 511, 1023 N n M n M N 1 n","['combinatorics', 'discrete-mathematics', 'algorithms', 'contest-math', 'binary']"
86,Are these formulas equivalent?,Are these formulas equivalent?,,"I am solving the problem from the textbook, and g) part states ""There is exactly one person whom everybody loves."" L(x, y) is ""x loves y."" (1) The first and easiest solution is: $\exists !y\forall xL\left(x,y\right)$ (2) Then I came up with the second solution: $\exists \:y\left(\forall \:x\left(L\left(x,\:y\right)\:\wedge \forall \:z\left(L\left(x,\:z\right)\rightarrow \left(z=y\right)\right)\right)\right)$ Which I think is also the correct one. (3) The third solution is: $\exists x\left(\forall yL\left(y,\:x\right)\:\wedge \forall z\left(\left(z\ne x\right)\rightarrow \exists w\neg L\left(w,z\right)\right)\right)$ (4) And the solution from the book is: $\exists x\left(\forall yL\left(y,x\right)\wedge \forall z\left(\left(\forall wL\left(w,z\right)\right)\rightarrow z=x\right)\right)$ Is the (2) second formula correct in this case? and if so, are they equivalent?","I am solving the problem from the textbook, and g) part states ""There is exactly one person whom everybody loves."" L(x, y) is ""x loves y."" (1) The first and easiest solution is: (2) Then I came up with the second solution: Which I think is also the correct one. (3) The third solution is: (4) And the solution from the book is: Is the (2) second formula correct in this case? and if so, are they equivalent?","\exists !y\forall xL\left(x,y\right) \exists \:y\left(\forall \:x\left(L\left(x,\:y\right)\:\wedge \forall \:z\left(L\left(x,\:z\right)\rightarrow \left(z=y\right)\right)\right)\right) \exists x\left(\forall yL\left(y,\:x\right)\:\wedge \forall z\left(\left(z\ne x\right)\rightarrow \exists w\neg L\left(w,z\right)\right)\right) \exists x\left(\forall yL\left(y,x\right)\wedge \forall z\left(\left(\forall wL\left(w,z\right)\right)\rightarrow z=x\right)\right)","['discrete-mathematics', 'predicate-logic', 'quantifiers']"
87,Proof Verification: $2^n+1 \leq 3^n$,Proof Verification:,2^n+1 \leq 3^n,"Claim: $$\forall n \in \mathbb{N}, 2^n+1 \leq 3^n $$ Proof (Induction): Base: Let $$n = 1, 2^1 + 1 \leq 3$$ so this is true. Inductive Step: Suppose $$n \geq 1$$ and assume inductive hypothesis holds for all values less than or equal to n. $$2^{n+1} + 1 = 2*2^n + 1$$ recall $$2^n \leq 3^n - 1$$ So, $$2(2^n) + 1 \leq 2(3^n -1) + 1$$ Now, we want to show $$\forall n \in \mathbb{N}, 2(3^n) - 1 \leq 3^{n+1}$$ This inequality becomes $$-1 \leq 3^n$$ which is obviously true $\forall n \in \mathbb{N}$ . Therefore, $$2^{n+1} + 1 \leq 2(3^n - 1) + 1 \leq 3^{n+1} \implies \forall n \in \mathbb{N}, 2^{n+1}+1 \leq 3^{n+1}$$ by induction. This is one of the first inequality induction proofs I have done, and usually in an inductive proof, you construct the right hand side using the left hand side. I did not do this here, I just pulled the $3^{n+1}$ out of nowhere and tested if the simpler inequality $2(3^n) - 1$ was always less than or equal to $3^{n+1}$ . Is this rigorous enough? Thanks.","Claim: Proof (Induction): Base: Let so this is true. Inductive Step: Suppose and assume inductive hypothesis holds for all values less than or equal to n. recall So, Now, we want to show This inequality becomes which is obviously true . Therefore, by induction. This is one of the first inequality induction proofs I have done, and usually in an inductive proof, you construct the right hand side using the left hand side. I did not do this here, I just pulled the out of nowhere and tested if the simpler inequality was always less than or equal to . Is this rigorous enough? Thanks.","\forall n \in \mathbb{N}, 2^n+1 \leq 3^n  n = 1, 2^1 + 1 \leq 3 n \geq 1 2^{n+1} + 1 = 2*2^n + 1 2^n \leq 3^n - 1 2(2^n) + 1 \leq 2(3^n -1) + 1 \forall n \in \mathbb{N}, 2(3^n) - 1 \leq 3^{n+1} -1 \leq 3^n \forall n \in \mathbb{N} 2^{n+1} + 1 \leq 2(3^n - 1) + 1 \leq 3^{n+1} \implies \forall n \in \mathbb{N}, 2^{n+1}+1 \leq 3^{n+1} 3^{n+1} 2(3^n) - 1 3^{n+1}","['discrete-mathematics', 'solution-verification', 'proof-writing', 'induction']"
88,Topology to define continuous functions to the discrete plane,Topology to define continuous functions to the discrete plane,,"If you have a function from $\mathbb R \to \mathbb R \times \mathbb R$ , you can define a continuous function as a function for which the preimage of every open subset in $\mathbb R \times \mathbb R$ is an open subset of $\mathbb R$ . In the discrete case, you can define functions that ""look continuous"" from $\mathbb N \to \mathbb N \times \mathbb N$ as functions so that for every step of 1, the image point is adjacent to the original point. Is it possible to consider topologies on $\mathbb N \to \mathbb N$ and $\mathbb N$ so that the definition of the continuity ""preimage of open is open"" in the first paragraph leads to exactly the sets of ""continuous"" functions defined in the second paragraph ?","If you have a function from , you can define a continuous function as a function for which the preimage of every open subset in is an open subset of . In the discrete case, you can define functions that ""look continuous"" from as functions so that for every step of 1, the image point is adjacent to the original point. Is it possible to consider topologies on and so that the definition of the continuity ""preimage of open is open"" in the first paragraph leads to exactly the sets of ""continuous"" functions defined in the second paragraph ?",\mathbb R \to \mathbb R \times \mathbb R \mathbb R \times \mathbb R \mathbb R \mathbb N \to \mathbb N \times \mathbb N \mathbb N \to \mathbb N \mathbb N,"['general-topology', 'discrete-mathematics']"
89,Prove that probability of winning stays the same,Prove that probability of winning stays the same,,"Players $A$ and $B$ play tennis. When $A$ draws he wins the draw with probability $p_1$ , when $B$ draws he wins the draw with probability $p_2$ . Player $A$ draws first and the game is won by a player who reaches $n$ successful draws first. There are two ways to determine who draws next: Switch after every draw (i.e. $ABABAB...$ ) Switch at the moment the current drawer loses his draw (i.e. if $A$ has 5 successful draws and then fails, then B has 3 successful draws then fails we'll get $AAAAABBBA...$ ) Prove that probability of player $A$ winning is the same no matter which rule of switching drawing players is adopted. My approach : I got that for the first scheme the probability of $A$ winning is $P(A) = \sum_{N=n}^{\infty} [p_1 \cdot \binom{N-1}{n-1} p_{1}^{n-1} q_{1}^{N-n} \sum_{k=0}^{n-1} \binom{N-1}{k} p_{2}^k q_{2}^{N-k-1} ]$ , where $N$ is all possible draws at which $A$ won and $k$ runs through amount of successful draws for $B$ . I am struggling to come up with formula for $P(A)$ for the second scheme.","Players and play tennis. When draws he wins the draw with probability , when draws he wins the draw with probability . Player draws first and the game is won by a player who reaches successful draws first. There are two ways to determine who draws next: Switch after every draw (i.e. ) Switch at the moment the current drawer loses his draw (i.e. if has 5 successful draws and then fails, then B has 3 successful draws then fails we'll get ) Prove that probability of player winning is the same no matter which rule of switching drawing players is adopted. My approach : I got that for the first scheme the probability of winning is , where is all possible draws at which won and runs through amount of successful draws for . I am struggling to come up with formula for for the second scheme.",A B A p_1 B p_2 A n ABABAB... A AAAAABBBA... A A P(A) = \sum_{N=n}^{\infty} [p_1 \cdot \binom{N-1}{n-1} p_{1}^{n-1} q_{1}^{N-n} \sum_{k=0}^{n-1} \binom{N-1}{k} p_{2}^k q_{2}^{N-k-1} ] N A k B P(A),"['probability', 'combinatorics', 'probability-theory', 'discrete-mathematics']"
90,Conducting a Proof Sequence - Discrete Mathematics,Conducting a Proof Sequence - Discrete Mathematics,,"I am having trouble conducting this proof sequence. Here are the premises: p -> (q v r) ~q ~r ~p ^ ~ r So far, I have this: p -> (q v r) - Premise ~q - Premise ~r - Premise ~(q v r) - implication, 1 ~q ^ ~r - De Morgan's Law, 4 ~r ^ ~q - commutativity, 5 ~r - simplification, 6 p -> (~r) - ??? ~p - Modus Tollens, 8, 3 ~p ^ ~r - conjunction, 9, 3 Is this sequence correct? I have a hard time understanding the use of implication and when/when not to apply it. My thoughts are using it whenever the disjunction is seen. Any help is greatly appreciated. Thank you!","I am having trouble conducting this proof sequence. Here are the premises: p -> (q v r) ~q ~r ~p ^ ~ r So far, I have this: p -> (q v r) - Premise ~q - Premise ~r - Premise ~(q v r) - implication, 1 ~q ^ ~r - De Morgan's Law, 4 ~r ^ ~q - commutativity, 5 ~r - simplification, 6 p -> (~r) - ??? ~p - Modus Tollens, 8, 3 ~p ^ ~r - conjunction, 9, 3 Is this sequence correct? I have a hard time understanding the use of implication and when/when not to apply it. My thoughts are using it whenever the disjunction is seen. Any help is greatly appreciated. Thank you!",,"['discrete-mathematics', 'logic']"
91,Transitive relation of non function,Transitive relation of non function,,"I have a doubt trying to determine wether a relation is transitive or not. Given this sets A={1,2,3,4} and B={1,2,3,4} and relation AxB = {(1,1),(3,4),(2,2),(3,3)} we can determine that is transitive given the next definition: if (a,b) in R, and (b,c) in R there must be (a,c) to be transitive. We take (3,3) as (a,b), then we take (3,4) as (b,c) so (3,4) is (a,c), which is already in the set, therefore this is a transitive relation.","I have a doubt trying to determine wether a relation is transitive or not. Given this sets A={1,2,3,4} and B={1,2,3,4} and relation AxB = {(1,1),(3,4),(2,2),(3,3)} we can determine that is transitive given the next definition: if (a,b) in R, and (b,c) in R there must be (a,c) to be transitive. We take (3,3) as (a,b), then we take (3,4) as (b,c) so (3,4) is (a,c), which is already in the set, therefore this is a transitive relation.",,"['discrete-mathematics', 'relations']"
92,"Find the minimum vertex cover for a Bipartite Graph, if we are given the maximum Bipartite Matching [duplicate]","Find the minimum vertex cover for a Bipartite Graph, if we are given the maximum Bipartite Matching [duplicate]",,"This question already has an answer here : How to find a minumum vertex cover from a maximum matching in a bipartite graph? (1 answer) Closed last year . From Konig's Theorem, the size of Maximum Matching (|M|) and minimum vertex cover is the same. Now we can include both ends of the matching in the vertex cover to find a vertex cover, but its size will be 2|M|. So I considered choosing a matching edge and then checking the degree of both ends. And then include the vertex with the higher degree. Suppose the degree of both ends is the same. We can include either. I tried this with a few examples I could think of it worked. But I am not sure of the algorithm. Is this correct? Also, if not, can anyone provide any counter example.?","This question already has an answer here : How to find a minumum vertex cover from a maximum matching in a bipartite graph? (1 answer) Closed last year . From Konig's Theorem, the size of Maximum Matching (|M|) and minimum vertex cover is the same. Now we can include both ends of the matching in the vertex cover to find a vertex cover, but its size will be 2|M|. So I considered choosing a matching edge and then checking the degree of both ends. And then include the vertex with the higher degree. Suppose the degree of both ends is the same. We can include either. I tried this with a few examples I could think of it worked. But I am not sure of the algorithm. Is this correct? Also, if not, can anyone provide any counter example.?",,"['discrete-mathematics', 'graph-theory', 'discrete-optimization', 'bipartite-graphs']"
93,Why is this almost affine code not equivalent to a linear code?,Why is this almost affine code not equivalent to a linear code?,,"I am a bachelor student who just started studying coding theory and I came across the following example in ""Generalized Hamming weights for almost affine codes"" by Johnsen and Verdure, page 4 ( https://arxiv.org/abs/1601.01504 ): We will use a running example throughout this paper. It is the almost affine code C ′ in [14, Example 5]. It is a code of length 3 and dimension 2 on the alphabet F = {0, 1, 2, 3}. Its set of codewords is $$ \begin{matrix} 000 & 011 & 022 & 033 \\ 101 & 112 & 123 & 130 \\ 202 & 213 & 220 & 231 \\ 303 & 310 & 321 & 332 \\ \end{matrix} $$ [...] This is an example of an almost affine code which is not equivalent to a linear code, and not even to a multilinear code. I understand why the code is almost affine. However, to me, it seems like this is a linear code, since all the codewords can be expressed as linear combinations of 101 and 011. What mistake am I making? Also, how would I check that it is not equivalent to a multilinear code? Thank you in advance.","I am a bachelor student who just started studying coding theory and I came across the following example in ""Generalized Hamming weights for almost affine codes"" by Johnsen and Verdure, page 4 ( https://arxiv.org/abs/1601.01504 ): We will use a running example throughout this paper. It is the almost affine code C ′ in [14, Example 5]. It is a code of length 3 and dimension 2 on the alphabet F = {0, 1, 2, 3}. Its set of codewords is [...] This is an example of an almost affine code which is not equivalent to a linear code, and not even to a multilinear code. I understand why the code is almost affine. However, to me, it seems like this is a linear code, since all the codewords can be expressed as linear combinations of 101 and 011. What mistake am I making? Also, how would I check that it is not equivalent to a multilinear code? Thank you in advance.","
\begin{matrix}
000 & 011 & 022 & 033 \\
101 & 112 & 123 & 130 \\
202 & 213 & 220 & 231 \\
303 & 310 & 321 & 332 \\
\end{matrix}
","['combinatorics', 'discrete-mathematics', 'coding-theory', 'matroids']"
94,Determining whether 2 logical statements are equivalent,Determining whether 2 logical statements are equivalent,,"I recently encountered a problem which is to determine whether the following statements are logically equivalent to each other. The statements are: $$\text{$(\exists x\in U)[P(x)\land Q(x)]$ and $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$}$$ Suppose $(\exists x\in U)[P(x)\land Q(x)]$ is true. Let $x = a \in U$ s.t. $P(a)$ and $Q(a)$ is true. So both $P(a)$ and $Q(a)$ are true. Suppose $(\exists x\in U)[P(x)\land Q(x)]$ is false. Then its negation: $(\forall x \in U)[\neg P(x) \lor\neg Q(x)]$ is true. The negation holds true whenever $P(x)$ is false or $Q(x)$ is false for any $x \in U$ . Let $x \in U$ s.t. $\neg P(x) \lor\neg Q(x)$ is true, hence, we consider 2 cases: Case 1: $P(x)$ is false Since $P(x)$ is false for any $x\in U$ , $(\exists x\in U)P(x)$ is false, hence $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ must be false. Case 2: $Q(x)$ is false Since $Q(x)$ is false for any $x\in U$ , $(\exists x\in U)Q(x)$ is false, hence, $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ must be false. Since when $(\exists x\in U)[P(x)\land Q(x)]$ is true, $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ is also true. And when $(\exists x\in U)[P(x)\land Q(x)]$ is false, $[(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]$ is also false. Therefore we can conclude that they are logically equivalent. I would like to know whether my answer is valid and whether there is bug in my answer. Thanks!!","I recently encountered a problem which is to determine whether the following statements are logically equivalent to each other. The statements are: Suppose is true. Let s.t. and is true. So both and are true. Suppose is false. Then its negation: is true. The negation holds true whenever is false or is false for any . Let s.t. is true, hence, we consider 2 cases: Case 1: is false Since is false for any , is false, hence must be false. Case 2: is false Since is false for any , is false, hence, must be false. Since when is true, is also true. And when is false, is also false. Therefore we can conclude that they are logically equivalent. I would like to know whether my answer is valid and whether there is bug in my answer. Thanks!!",\text{(\exists x\in U)[P(x)\land Q(x)] and [(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)]} (\exists x\in U)[P(x)\land Q(x)] x = a \in U P(a) Q(a) P(a) Q(a) (\exists x\in U)[P(x)\land Q(x)] (\forall x \in U)[\neg P(x) \lor\neg Q(x)] P(x) Q(x) x \in U x \in U \neg P(x) \lor\neg Q(x) P(x) P(x) x\in U (\exists x\in U)P(x) [(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)] Q(x) Q(x) x\in U (\exists x\in U)Q(x) [(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)] (\exists x\in U)[P(x)\land Q(x)] [(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)] (\exists x\in U)[P(x)\land Q(x)] [(\exists x\in U)P(x)]\land[(\exists x\in U)Q(x)],"['discrete-mathematics', 'logic']"
95,Given a walk between two vertices can you always find a trail between those two same vertices?,Given a walk between two vertices can you always find a trail between those two same vertices?,,"I want to prove this proposition that intuitively seems true. Let me first start by defining both walk and trail as I'm not studying graph theory in english and I'm not 100% sure if these are the correct terms for what I want to say. Given a graph G, A walk is a succession of vertices and and edges of the following form, $r=x_0a_1x_1\cdots x_{l-1}a_lx_l$ where $l$ (the number of edges) is the length of the walk. A trail is when a walk has no repeated edges. Given this two definitions, let $r=x_0a_1x_1\cdots x_{l-1}a_lx_l$ be a walk with length $l$ from the vertex $k$ denoted by $x_0$ to the vertex $j$ dentoted by $x_l$ . In order to find a trail from $k$ to $j$ with the elements of $r$ , I need to find a subsuccession of $r$ starting in $k$ and finishing in $j$ that has no repeating edges. To do this, as there's no restrictions over $r$ , I first take a subsuccession of the original path that only crosses the initial and final vertices once (starts in $k$ and finishes in $j$ ). I can build this new walk the following way, I define $x_f \in r$ such that $f=\max\{n \in \mathbb N : x_f \in r \textrm{ and } x_f=x_l\}$ and I build the new walk $\hat r =x_0a_1x_1\cdots x_{f-1}a_fx_f$ Now, I define $x_i \in \hat r$ such that $i=\min\{n \in \mathbb N : x_i \in \hat r \textrm{ and } x_i=x_0\}$ and build the new walk $\bar r =x_ia_{i+1}x_{i+1}\cdots x_{f-1}a_fx_f$ I'm not sure if this previous step is necesary for the rest of the proof but thinking about it i thought that having the ending and starting points appear more than once could give some problems and as I only want to prove that there's at least one path with the elements in the original walk, this doesn't restrict the hypothesis. Now that i have the shortened walk, I have to find a way to ""remove"" the extra edges. The way I thought of this by intuition is that if a walk crosses a certain edge and then it crosses it again after som extra steps, those extra steps between the first and last time it crosses the edge can be removed (its a loop, no matter how long it is you end up back going through the same edge). However, if two edges are the same, as the graph is not directional, the walk could be going in same or different directions and I have to treat both cases differently. I propose the following process to build the path from the given walk $\bar r = r_0$ . 1-Let $p_m=i+m$ with $1\leq m \leq f-i$ and let $m=1$ for the first    step 2-While $m\leq f-i$ repeat: 2.1-Given $a_p$ the p-th edge in the walk, define $a_c \in r_{m-1}$ with $c=\max\{n\in \mathbb N : a_n \in r_{m-1} \textrm{ and } a_n=a_p \}$ 2.2-If $c=p$ then do nothing and skip to 2.4 2.3-If $a_p$ appears in $r_{m-1}$ as $xa_py$ and $a_c$ appears in $r_{m-1}$ as $xa_cy$ then define the succession $r_m$ as $r_{m-1}$ with the subsuccession $a_px_{p+1}a_{p+1}\cdots x_{c-1}$ removed 2.3-If $a_p$ appears in $r_{m-1}$ as $xa_py$ and $a_c$ appears in $r_{m-1}$ as $ya_cx$ then define the succession $r_m$ as $r_{m-1}$ with the subsuccession $x_pa_px_{p+1}a_{p+1}\cdots x_{c-1}a_c$ removed 2.4-Add one to $m$ and repeat step 2 3-You are left with $r_m$ a subsuccession built with the verices and edges from $r$ where the starting point is $k$ , the ending point is $j$ and no edges are repeated Therefore the walk built with this method is a trail from the edge $k$ to the edge $j$ I'd like to know wether this constructive proof is right and any sugestions anyone might have to improve it. I apologize in advance for the notation, my discrete maths professor has given us no proves on the topics of graphs and I have no idea on what notation is formaly used. Sorry too for any grammar or spelling mistakes I might have made, english is not my first language. Thanks in advance","I want to prove this proposition that intuitively seems true. Let me first start by defining both walk and trail as I'm not studying graph theory in english and I'm not 100% sure if these are the correct terms for what I want to say. Given a graph G, A walk is a succession of vertices and and edges of the following form, where (the number of edges) is the length of the walk. A trail is when a walk has no repeated edges. Given this two definitions, let be a walk with length from the vertex denoted by to the vertex dentoted by . In order to find a trail from to with the elements of , I need to find a subsuccession of starting in and finishing in that has no repeating edges. To do this, as there's no restrictions over , I first take a subsuccession of the original path that only crosses the initial and final vertices once (starts in and finishes in ). I can build this new walk the following way, I define such that and I build the new walk Now, I define such that and build the new walk I'm not sure if this previous step is necesary for the rest of the proof but thinking about it i thought that having the ending and starting points appear more than once could give some problems and as I only want to prove that there's at least one path with the elements in the original walk, this doesn't restrict the hypothesis. Now that i have the shortened walk, I have to find a way to ""remove"" the extra edges. The way I thought of this by intuition is that if a walk crosses a certain edge and then it crosses it again after som extra steps, those extra steps between the first and last time it crosses the edge can be removed (its a loop, no matter how long it is you end up back going through the same edge). However, if two edges are the same, as the graph is not directional, the walk could be going in same or different directions and I have to treat both cases differently. I propose the following process to build the path from the given walk . 1-Let with and let for the first    step 2-While repeat: 2.1-Given the p-th edge in the walk, define with 2.2-If then do nothing and skip to 2.4 2.3-If appears in as and appears in as then define the succession as with the subsuccession removed 2.3-If appears in as and appears in as then define the succession as with the subsuccession removed 2.4-Add one to and repeat step 2 3-You are left with a subsuccession built with the verices and edges from where the starting point is , the ending point is and no edges are repeated Therefore the walk built with this method is a trail from the edge to the edge I'd like to know wether this constructive proof is right and any sugestions anyone might have to improve it. I apologize in advance for the notation, my discrete maths professor has given us no proves on the topics of graphs and I have no idea on what notation is formaly used. Sorry too for any grammar or spelling mistakes I might have made, english is not my first language. Thanks in advance",r=x_0a_1x_1\cdots x_{l-1}a_lx_l l r=x_0a_1x_1\cdots x_{l-1}a_lx_l l k x_0 j x_l k j r r k j r k j x_f \in r f=\max\{n \in \mathbb N : x_f \in r \textrm{ and } x_f=x_l\} \hat r =x_0a_1x_1\cdots x_{f-1}a_fx_f x_i \in \hat r i=\min\{n \in \mathbb N : x_i \in \hat r \textrm{ and } x_i=x_0\} \bar r =x_ia_{i+1}x_{i+1}\cdots x_{f-1}a_fx_f \bar r = r_0 p_m=i+m 1\leq m \leq f-i m=1 m\leq f-i a_p a_c \in r_{m-1} c=\max\{n\in \mathbb N : a_n \in r_{m-1} \textrm{ and } a_n=a_p \} c=p a_p r_{m-1} xa_py a_c r_{m-1} xa_cy r_m r_{m-1} a_px_{p+1}a_{p+1}\cdots x_{c-1} a_p r_{m-1} xa_py a_c r_{m-1} ya_cx r_m r_{m-1} x_pa_px_{p+1}a_{p+1}\cdots x_{c-1}a_c m r_m r k j k j,"['discrete-mathematics', 'graph-theory', 'solution-verification']"
96,Comparing two sequence via their exponential generating function,Comparing two sequence via their exponential generating function,,I am studying two sequence with their e.g.f. The first one are the Bell numbers (sequence $A000110$ on OEIS) defined as follows. $B_0=1$ and $$ B_n =\sum_{k=0}^{n-1} {n-1\choose k} B_k $$ They have a known e.g.f. (via OEIS) which is $$F_B(x)=e^{e^x-1}$$ The second one is the sequence A005046 on OEIS defined as follows $a_0=1$ and $$ a_n =\sum_{k=0}^{n-1} {2n-1\choose 2k} a_k $$ Clearly $a_n\ge B_n$ for every $n$ . However on OEIS it says that the e.g.f. of $(a_n)_{n\ge0}$ is $$ F_a(x)=e^{\cosh(x) - 1} =e^{\frac{e^x+e^{-x}}{2}-1} $$ which is less than $F_B(x)$ for $x>0$ .,I am studying two sequence with their e.g.f. The first one are the Bell numbers (sequence on OEIS) defined as follows. and They have a known e.g.f. (via OEIS) which is The second one is the sequence A005046 on OEIS defined as follows and Clearly for every . However on OEIS it says that the e.g.f. of is which is less than for .,"A000110 B_0=1 
B_n =\sum_{k=0}^{n-1} {n-1\choose k} B_k
 F_B(x)=e^{e^x-1} a_0=1 
a_n =\sum_{k=0}^{n-1} {2n-1\choose 2k} a_k
 a_n\ge B_n n (a_n)_{n\ge0}  F_a(x)=e^{\cosh(x) - 1} =e^{\frac{e^x+e^{-x}}{2}-1}  F_B(x) x>0","['sequences-and-series', 'discrete-mathematics', 'generating-functions', 'oeis', 'number-comparison']"
97,Decreasing permutation,Decreasing permutation,,"A permutation σ of the set [n] = {1, 2, ..., n} is decreasing if for every i < j, it holds that σ(i) > σ(j). How many decreasing permutations of [n] are there? My attempt: Since 1<i for all i in {2, ..., n}, we know that σ(1)=n. Otherwise we would have a j with σ(j)=n>σ(1), but 1<j. Same argument: σ(2)=n-1 . . . It follows, that there is exactly one decreasing permutation, if n is even. And there is no permutation if n is not even. I dont see what is wrong, but it also seems suspiciously easy. Can someone confirm?","A permutation σ of the set [n] = {1, 2, ..., n} is decreasing if for every i < j, it holds that σ(i) > σ(j). How many decreasing permutations of [n] are there? My attempt: Since 1<i for all i in {2, ..., n}, we know that σ(1)=n. Otherwise we would have a j with σ(j)=n>σ(1), but 1<j. Same argument: σ(2)=n-1 . . . It follows, that there is exactly one decreasing permutation, if n is even. And there is no permutation if n is not even. I dont see what is wrong, but it also seems suspiciously easy. Can someone confirm?",,"['combinatorics', 'discrete-mathematics', 'solution-verification', 'permutations']"
98,How to prove $M = N$ is equivalent to $M =_{\beta} N$ in Lambda Calculus,How to prove  is equivalent to  in Lambda Calculus,M = N M =_{\beta} N,"Lambda calculus is equipped with a primitive $=$ with the following definition: (1) For any variable $x$ and lambda term $M, N$ , $\left(\lambda x. M\right) N = M\left[x := N\right]$ ; (2) For any term $M$ , $M = M$ ; (3) For any terms $M, N$ , $M = N$ implies $N = M$ ; (4) For any terms $M, N, L$ , $M = N$ and $N = L$ implies $M = L$ . On the other hand, we have the following definition for $=_{\beta}$ ( $\beta$ -conversion ): For any terms $M, N$ , $M =_{\beta} N$ if and only if for some $n \geq 0$ , there exists some sequence $s$ of lambda terms of length $n + 1$ such that $s_{0} \equiv M$ and $s_{n} \equiv N$ and for any $0 \leq i < n$ , $s_{i} \rightarrow_{\beta} s_{i + 1}$ or $s_{i + 1} \rightarrow_{\beta} s_{i}$ , where $\rightarrow_{\beta}$ is one-step beta reduction. I would like to prove that $=$ and $=_{\beta}$ are equivalent. To prove that $M =_{\beta} N$ implies $M = N$ , we can first prove the following lemma: for any $n \geq 0$ , if there exists some sequence $s$ of lambda terms of length $n + 1$ such that $s_{0} \equiv M$ and $s_{n} \equiv N$ and for any $0 \leq i < n$ , $s_{i} \rightarrow_{\beta} s_{i + 1}$ or $s_{i + 1} \rightarrow_{\beta} s_{i}$ , then $M = N$ . This is not hard to prove from mathematical induction using properties of $\rightarrow_{\beta}$ . However, I haven't found a good way to prove the inverse direction: $M = N$ implies that for some $n \geq 0$ , there exists some sequence $s$ of lambda terms of length $n + 1$ such that $s_{0} \equiv M$ and $s_{n} \equiv N$ and for any $0 \leq i < n$ , $s_{i} \rightarrow_{\beta} s_{i + 1}$ or $s_{i + 1} \rightarrow_{\beta} s_{i}$ . It seems to me that from $M = N$ , I cannot infer anything that helps me proceed. I tried proving in the other direction: if there is no $n \geq 0$ such that there exists some sequence $s$ of lambda terms of length $n + 1$ such that $s_{0} \equiv M$ and $s_{n} \equiv N$ and for any $0 \leq i < n$ , $s_{i} \rightarrow_{\beta} s_{i + 1}$ or $s_{i + 1} \rightarrow_{\beta} s_{i}$ , then $M \neq N$ . Then the problem is, our definition defines $M = N$ , but does not indicate much about $M \neq N$ . Does anyone have any clue about this proof?","Lambda calculus is equipped with a primitive with the following definition: (1) For any variable and lambda term , ; (2) For any term , ; (3) For any terms , implies ; (4) For any terms , and implies . On the other hand, we have the following definition for ( -conversion ): For any terms , if and only if for some , there exists some sequence of lambda terms of length such that and and for any , or , where is one-step beta reduction. I would like to prove that and are equivalent. To prove that implies , we can first prove the following lemma: for any , if there exists some sequence of lambda terms of length such that and and for any , or , then . This is not hard to prove from mathematical induction using properties of . However, I haven't found a good way to prove the inverse direction: implies that for some , there exists some sequence of lambda terms of length such that and and for any , or . It seems to me that from , I cannot infer anything that helps me proceed. I tried proving in the other direction: if there is no such that there exists some sequence of lambda terms of length such that and and for any , or , then . Then the problem is, our definition defines , but does not indicate much about . Does anyone have any clue about this proof?","= x M, N \left(\lambda x. M\right) N = M\left[x := N\right] M M = M M, N M = N N = M M, N, L M = N N = L M = L =_{\beta} \beta M, N M =_{\beta} N n \geq 0 s n + 1 s_{0} \equiv M s_{n} \equiv N 0 \leq i < n s_{i} \rightarrow_{\beta} s_{i + 1} s_{i + 1} \rightarrow_{\beta} s_{i} \rightarrow_{\beta} = =_{\beta} M =_{\beta} N M = N n \geq 0 s n + 1 s_{0} \equiv M s_{n} \equiv N 0 \leq i < n s_{i} \rightarrow_{\beta} s_{i + 1} s_{i + 1} \rightarrow_{\beta} s_{i} M = N \rightarrow_{\beta} M = N n \geq 0 s n + 1 s_{0} \equiv M s_{n} \equiv N 0 \leq i < n s_{i} \rightarrow_{\beta} s_{i + 1} s_{i + 1} \rightarrow_{\beta} s_{i} M = N n \geq 0 s n + 1 s_{0} \equiv M s_{n} \equiv N 0 \leq i < n s_{i} \rightarrow_{\beta} s_{i + 1} s_{i + 1} \rightarrow_{\beta} s_{i} M \neq N M = N M \neq N","['discrete-mathematics', 'induction', 'lambda-calculus']"
99,Causal system giving a non-causal output?,Causal system giving a non-causal output?,,"I have just written a Python code ploting DFT's using the convolution product : $$y[t] = u[k] * h[k] = \sum_{k=-\infty}^{+\infty} u[k] h[t-k]$$ I'll take a high resolution so the graph is more precise. Here is a simple example,for $h(t) = \delta(t)$ and $u(t) = \sin(t)\nu(t)$ : So far, so good. The causal system gives a causal answer. Yet, for $h(t) = \nu(t) - \nu(t-6)$ , I obtain this graph: The causal signal gives a non-causal answer. Indeed, $y(t)$ is not equal to $0$ for $t<0$ How is it possible ? Maybe is it a mistake from my code ?","I have just written a Python code ploting DFT's using the convolution product : I'll take a high resolution so the graph is more precise. Here is a simple example,for and : So far, so good. The causal system gives a causal answer. Yet, for , I obtain this graph: The causal signal gives a non-causal answer. Indeed, is not equal to for How is it possible ? Maybe is it a mistake from my code ?",y[t] = u[k] * h[k] = \sum_{k=-\infty}^{+\infty} u[k] h[t-k] h(t) = \delta(t) u(t) = \sin(t)\nu(t) h(t) = \nu(t) - \nu(t-6) y(t) 0 t<0,"['discrete-mathematics', 'fourier-transform']"
