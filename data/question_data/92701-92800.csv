,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Compactness of a set in the complex plane.,Compactness of a set in the complex plane.,,"Consider $$A=\Big\{(z_1,z_2) \in \Bbb{C}^2 : z_1^2+z_2^2=1\Big\}$$ Is $A$ compact? My try:  If $A$ is compact, then it is closed and bounded But it is not bounded! Since $(n,\sqrt{1-n^2});n\in \Bbb{N}$ satisfies this and $\Bbb{N}$ is unbounded. So not compact. Am I right? If not, any help?","Consider Is compact? My try:  If is compact, then it is closed and bounded But it is not bounded! Since satisfies this and is unbounded. So not compact. Am I right? If not, any help?","A=\Big\{(z_1,z_2) \in \Bbb{C}^2 : z_1^2+z_2^2=1\Big\} A A (n,\sqrt{1-n^2});n\in \Bbb{N} \Bbb{N}",['complex-analysis']
1,Zeta function generalized to quaternions?,Zeta function generalized to quaternions?,,"Has the $\zeta(s)$ function, $\sum_n 1/n^s$, been generalized   to quaternions, so $\zeta(q)$ for $q$ a quaternion? Euler defined it for $s$ integers, Chebyshev for $s$ real, Riemann for $s$ complex. So it is natural to explore $s$ a quaternion. But perhaps this does not lead to an interesting Quaternion Hypothesis?","Has the $\zeta(s)$ function, $\sum_n 1/n^s$, been generalized   to quaternions, so $\zeta(q)$ for $q$ a quaternion? Euler defined it for $s$ integers, Chebyshev for $s$ real, Riemann for $s$ complex. So it is natural to explore $s$ a quaternion. But perhaps this does not lead to an interesting Quaternion Hypothesis?",,"['complex-analysis', 'number-theory', 'riemann-zeta', 'quaternions']"
2,Proof of fundamental theorem of algebra in Baby Rudin,Proof of fundamental theorem of algebra in Baby Rudin,,"I am reading Rudin's proof of FTA. (FTA) Suppose $a_0, \ldots, a_n$ are complex numbers, $n \geq 1$, $a_n \neq 0$, $P(z) = \sum_{k = 0}^n a_k z^k$. Then $P(z) = 0$ for some $z \in \Bbb{C}$. The first part of the proof goes like this: WLOG, suppose $a_n = 1$. Let $\mu = \inf_{z \in \Bbb{C}} |P(z)|$. $\lim_{z \to \infty} |P(z)| = \infty$ (details omitted). Hence there is $R_0 >0$ such that $|z| > R_0 \implies |P(z)| > \color{red}{\mu}$ . Since $|P|$ is continuous on the closed ball $\overline{B_{R_0}(0)}$, the extreme value theorem shows that $|P(z_0)|=\mu$ for some $z_0$. However, I don't think the statement in bold is precisely what he meant. Specifically, ""there is $R_0>0$ such that $|z|> R_0 \implies |P(z)| > \mu$"" does not imply the existence of $z_0 \in \overline{B_{R_0}(0)}$ such that $|P(z_0)|=\mu$: For example, if we consider the exponential function $f(z) = e^z$, then $\mu = 0$ and $f(z) \neq 0$ for all $z \in \Bbb{C}$. In particular, $|z| > 1 \implies |f(z)|>0$. And $|f|$ is continuous on the closed ball $\overline{B_1(0)}$. But it is not true that there is $z_0 \in \Bbb{C}$ such that $f(z_0)=0$. In this example, $\lim_{z \to \infty} |f(z)| \neq \infty$ and $\inf_{|z|\leq 1} |f(z)| = e^{-1}\neq \mu$. So I think the condition $\lim_{z \to \infty} |P(z)| = \infty$ can be better utilized to show that  $\inf_{|z|\leq R_0} |P(z)| = \mu$. Thus, I think he actually meant the following: Hence there is $R_0>0$ such that $|z|>R_0 \implies |P(z)|>\mu+1$. Let $A = \overline{B_{R_0}(0)}$ and $B = \Bbb{C} \backslash A$. Now from the contrapositive, $|P(z)|\leq \color{red}{\mu+1} \implies z \in A$. But $\mu+1>\mu:=\inf_{z \in \Bbb{C}}|P(z)|$. So that there is some $z_1 \in \Bbb{C}$ such that $|P(z_1)|<\mu +1$. Above shows that $z_1 \in A$. Now we claim that $\inf_{z \in \Bbb{C}} |P(z)| = \inf_{z \in A} |P(z)|$. Pick any $z \in \Bbb{C}$. If $z \in A$, then $|P(z)| \geq \inf_{z \in A} |P(z)|$. If $z \in B$, then  $$|P(z)| > \mu+1 > |P(z_1)| \geq \inf_{z \in A} |P(z)|$$  So that $\inf_{z \in A} |P(z)|$ is a lower bound and $\inf_{z \in A} |P(z)|\leq \inf_{z \in \Bbb{C}} |P(z)|$. For $A \subset \Bbb{C}$, $\inf_{z \in \Bbb{C}} |P(z)|\leq \inf_{z \in A} |P(z)|$ and we have  $\inf_{z \in \Bbb{C}} |P(z)|= \inf_{z \in A} |P(z)|= \mu$. Since $|P|$ is continuous on the compact set $A$, the extreme value theorem shows that $|P(z_0)|= \mu$ for some $z_0 \in A$. My questions are, (1) Have I interpreted that first part of the proof correctly? (Done) The complete proof is attached below. I have already gone through the rest of the proof and I understand the logic. Apparently he only uses the fact that $\forall \ z \in \Bbb{C}$, $z = |z|e^{i \theta}$ for some $\theta \in [0,2\pi)$. (2) But does any part of the proof involves is indirectly related to any concept/theorem from complex analysis? I know nothing about complex analysis yet so can anyone provide me some keywords?","I am reading Rudin's proof of FTA. (FTA) Suppose $a_0, \ldots, a_n$ are complex numbers, $n \geq 1$, $a_n \neq 0$, $P(z) = \sum_{k = 0}^n a_k z^k$. Then $P(z) = 0$ for some $z \in \Bbb{C}$. The first part of the proof goes like this: WLOG, suppose $a_n = 1$. Let $\mu = \inf_{z \in \Bbb{C}} |P(z)|$. $\lim_{z \to \infty} |P(z)| = \infty$ (details omitted). Hence there is $R_0 >0$ such that $|z| > R_0 \implies |P(z)| > \color{red}{\mu}$ . Since $|P|$ is continuous on the closed ball $\overline{B_{R_0}(0)}$, the extreme value theorem shows that $|P(z_0)|=\mu$ for some $z_0$. However, I don't think the statement in bold is precisely what he meant. Specifically, ""there is $R_0>0$ such that $|z|> R_0 \implies |P(z)| > \mu$"" does not imply the existence of $z_0 \in \overline{B_{R_0}(0)}$ such that $|P(z_0)|=\mu$: For example, if we consider the exponential function $f(z) = e^z$, then $\mu = 0$ and $f(z) \neq 0$ for all $z \in \Bbb{C}$. In particular, $|z| > 1 \implies |f(z)|>0$. And $|f|$ is continuous on the closed ball $\overline{B_1(0)}$. But it is not true that there is $z_0 \in \Bbb{C}$ such that $f(z_0)=0$. In this example, $\lim_{z \to \infty} |f(z)| \neq \infty$ and $\inf_{|z|\leq 1} |f(z)| = e^{-1}\neq \mu$. So I think the condition $\lim_{z \to \infty} |P(z)| = \infty$ can be better utilized to show that  $\inf_{|z|\leq R_0} |P(z)| = \mu$. Thus, I think he actually meant the following: Hence there is $R_0>0$ such that $|z|>R_0 \implies |P(z)|>\mu+1$. Let $A = \overline{B_{R_0}(0)}$ and $B = \Bbb{C} \backslash A$. Now from the contrapositive, $|P(z)|\leq \color{red}{\mu+1} \implies z \in A$. But $\mu+1>\mu:=\inf_{z \in \Bbb{C}}|P(z)|$. So that there is some $z_1 \in \Bbb{C}$ such that $|P(z_1)|<\mu +1$. Above shows that $z_1 \in A$. Now we claim that $\inf_{z \in \Bbb{C}} |P(z)| = \inf_{z \in A} |P(z)|$. Pick any $z \in \Bbb{C}$. If $z \in A$, then $|P(z)| \geq \inf_{z \in A} |P(z)|$. If $z \in B$, then  $$|P(z)| > \mu+1 > |P(z_1)| \geq \inf_{z \in A} |P(z)|$$  So that $\inf_{z \in A} |P(z)|$ is a lower bound and $\inf_{z \in A} |P(z)|\leq \inf_{z \in \Bbb{C}} |P(z)|$. For $A \subset \Bbb{C}$, $\inf_{z \in \Bbb{C}} |P(z)|\leq \inf_{z \in A} |P(z)|$ and we have  $\inf_{z \in \Bbb{C}} |P(z)|= \inf_{z \in A} |P(z)|= \mu$. Since $|P|$ is continuous on the compact set $A$, the extreme value theorem shows that $|P(z_0)|= \mu$ for some $z_0 \in A$. My questions are, (1) Have I interpreted that first part of the proof correctly? (Done) The complete proof is attached below. I have already gone through the rest of the proof and I understand the logic. Apparently he only uses the fact that $\forall \ z \in \Bbb{C}$, $z = |z|e^{i \theta}$ for some $\theta \in [0,2\pi)$. (2) But does any part of the proof involves is indirectly related to any concept/theorem from complex analysis? I know nothing about complex analysis yet so can anyone provide me some keywords?",,"['complex-analysis', 'polynomials', 'proof-verification', 'proof-explanation']"
3,"why does $\frac{df}{dz}=\frac{1}{2}\left ( \frac{\partial f}{\partial x}-i\frac{\partial f}{\partial y}\right )$, why the $\frac{1}{2}$?","why does , why the ?",\frac{df}{dz}=\frac{1}{2}\left ( \frac{\partial f}{\partial x}-i\frac{\partial f}{\partial y}\right ) \frac{1}{2},"I have trouble seeing where the $\frac{1}{2}$ comes from in $$\frac{df}{dz}=\frac{1}{2}\left ( \frac{\partial f}{\partial x}-i\frac{\partial f}{\partial y}\right )$$ For a change of variables $z=x+iy$ we have $$\frac{df}{dz}= \ \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial z}$$ and $\frac{\partial x}{\partial z}=1$ and $\frac{\partial y}{\partial z}=-i$. Therefore we have the above but without the $\frac{1}{2}$. I've seen someone derive the correct expression by including the change of variables for $\overline{z}$ however I don't see how that is necessary, it should work without, right? I don't know what I am missing?","I have trouble seeing where the $\frac{1}{2}$ comes from in $$\frac{df}{dz}=\frac{1}{2}\left ( \frac{\partial f}{\partial x}-i\frac{\partial f}{\partial y}\right )$$ For a change of variables $z=x+iy$ we have $$\frac{df}{dz}= \ \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial z}$$ and $\frac{\partial x}{\partial z}=1$ and $\frac{\partial y}{\partial z}=-i$. Therefore we have the above but without the $\frac{1}{2}$. I've seen someone derive the correct expression by including the change of variables for $\overline{z}$ however I don't see how that is necessary, it should work without, right? I don't know what I am missing?",,"['complex-analysis', 'complex-numbers']"
4,"If $f \in \operatorname{Hol}(D)$, $f(\frac{1}{2}) + f(-\frac{1}{2}) = 0$, prove that $|f(0)| \leq \frac{1}{4}$","If , , prove that",f \in \operatorname{Hol}(D) f(\frac{1}{2}) + f(-\frac{1}{2}) = 0 |f(0)| \leq \frac{1}{4},"If $f \in \operatorname{Hol}(D),f(\frac{1}{2}) + f(-\frac{1}{2}) = 0$, prove that $|f(0)| \leq \frac{1}{4}$ $D = \{ z \in \mathbb{C} : |z| < 1 \} $ My thoughts so far: Let's say $f(0) = a$. Define $g = \frac{z-a}{1-\bar{a}z}$ and $h(z) = (g(f(z))$ Now all the conditions for the Shwarz lemma are met, and I can conclude that $|h(\frac{1}{2})| \leq  \frac{1}{2}$ and $|h(-\frac{1}{2})| \leq  \frac{1}{2}$. The idea would then be to multiply the two inequalities together and try to somehow separate $a$, but the algebra gets really messy and I feel like I'm doing something wrong. Any help would be appreciated!","If $f \in \operatorname{Hol}(D),f(\frac{1}{2}) + f(-\frac{1}{2}) = 0$, prove that $|f(0)| \leq \frac{1}{4}$ $D = \{ z \in \mathbb{C} : |z| < 1 \} $ My thoughts so far: Let's say $f(0) = a$. Define $g = \frac{z-a}{1-\bar{a}z}$ and $h(z) = (g(f(z))$ Now all the conditions for the Shwarz lemma are met, and I can conclude that $|h(\frac{1}{2})| \leq  \frac{1}{2}$ and $|h(-\frac{1}{2})| \leq  \frac{1}{2}$. The idea would then be to multiply the two inequalities together and try to somehow separate $a$, but the algebra gets really messy and I feel like I'm doing something wrong. Any help would be appreciated!",,"['complex-analysis', 'complex-numbers']"
5,Derivation of formula involving Gamma function?,Derivation of formula involving Gamma function?,,I'm trying to prove that: $$\prod_{n=1}^{\infty}\frac{n(n+a+b)}{(n+a)(n+b)} = \frac{\Gamma(a+1)\Gamma(b+1)}{\Gamma(a+b+1)}$$ whenever $a$ and $b$ are positive. I know that $$\frac{\Gamma(a+1)\Gamma(b+1)}{\Gamma(a+b+1)} = \frac{\int_0^{\infty}e^{-s}s^ads \int_0^{\infty}e^{-t}t^adt}{\int_0^{\infty}e^{-n}n^{a+b}dn}$$ but am confused as to where to proceed from here... Should I use the product formula for $1/\Gamma$ instead? Any direction would be appreciated. Thanks.,I'm trying to prove that: $$\prod_{n=1}^{\infty}\frac{n(n+a+b)}{(n+a)(n+b)} = \frac{\Gamma(a+1)\Gamma(b+1)}{\Gamma(a+b+1)}$$ whenever $a$ and $b$ are positive. I know that $$\frac{\Gamma(a+1)\Gamma(b+1)}{\Gamma(a+b+1)} = \frac{\int_0^{\infty}e^{-s}s^ads \int_0^{\infty}e^{-t}t^adt}{\int_0^{\infty}e^{-n}n^{a+b}dn}$$ but am confused as to where to proceed from here... Should I use the product formula for $1/\Gamma$ instead? Any direction would be appreciated. Thanks.,,['complex-analysis']
6,"The ""$\mathbb{Z}_n$-theta function"" - what is it? Is it being studied somewhere?","The ""-theta function"" - what is it? Is it being studied somewhere?",\mathbb{Z}_n,"The Jacobi theta function is well known: $$\theta(z, \tau) = \sum_{n=-\infty}^\infty \mathrm{e}^{\pi i n^2 \tau + 2\pi i nz}$$ In Shahn Majid's ""Foundations of Quantum Group Theory"", you'll find a sort of finite theta function in example 2.1.11 on page 45, which he calls ""$\mathbb{Z}_n$-theta function"": $$\theta_d(a) = \frac{1}{d}\sum_{n=0}^d \mathrm{e}^{\frac{2\pi i}{d} (n^2 + an)} \qquad d \in \mathbb{N}$$ I had never heard of such a function before. Google doesn't give anything promising. It sort of looks like a theta function with $\tau = \frac{2}{d}$ and $z = \frac{a}{d}$, but the sum is finite (like a kind of regularisation?). Is this studied anywhere? Can it be derived from the usual theta function? Are there known identities involving this?","The Jacobi theta function is well known: $$\theta(z, \tau) = \sum_{n=-\infty}^\infty \mathrm{e}^{\pi i n^2 \tau + 2\pi i nz}$$ In Shahn Majid's ""Foundations of Quantum Group Theory"", you'll find a sort of finite theta function in example 2.1.11 on page 45, which he calls ""$\mathbb{Z}_n$-theta function"": $$\theta_d(a) = \frac{1}{d}\sum_{n=0}^d \mathrm{e}^{\frac{2\pi i}{d} (n^2 + an)} \qquad d \in \mathbb{N}$$ I had never heard of such a function before. Google doesn't give anything promising. It sort of looks like a theta function with $\tau = \frac{2}{d}$ and $z = \frac{a}{d}$, but the sum is finite (like a kind of regularisation?). Is this studied anywhere? Can it be derived from the usual theta function? Are there known identities involving this?",,"['complex-analysis', 'quantum-groups', 'theta-functions']"
7,"for two non zero complex polynomial $p(z),q(z)$ we have $p(z)\overline{q(z)}$ is analytic if and only if ?? CSIR - June $2013$",for two non zero complex polynomial  we have  is analytic if and only if ?? CSIR - June,"p(z),q(z) p(z)\overline{q(z)} 2013","Question is : for two non zero complex polynomial $p(z),q(z)$ we have $p(z)\overline{q(z)}$ is analytic if and only if $p(z)$ is Constant $p(z)q(z)$ is Constant $q(z)$ is Constant $\overline{p(z)}q(z)$ is Constant I could easily eliminate first case. Put $p(z)=1$ and $q(z)=z$ then we would have $p(z)\overline{q(z)}=\bar{z}$ which is not analytic though $p(z)$ is constant. I could see third case is almost true . Suppose $q(z)$ is constant then I will be left with only polynomial case so $p(z)\overline{q(z)}$ is analytic. Now, suppose $q(z)$ is not constant then I would have a contradiction which is already considered $q(z)=z$ I could not go any further on second and fourth cases. Please help me to see this in more detail. Thank you.","Question is : for two non zero complex polynomial $p(z),q(z)$ we have $p(z)\overline{q(z)}$ is analytic if and only if $p(z)$ is Constant $p(z)q(z)$ is Constant $q(z)$ is Constant $\overline{p(z)}q(z)$ is Constant I could easily eliminate first case. Put $p(z)=1$ and $q(z)=z$ then we would have $p(z)\overline{q(z)}=\bar{z}$ which is not analytic though $p(z)$ is constant. I could see third case is almost true . Suppose $q(z)$ is constant then I will be left with only polynomial case so $p(z)\overline{q(z)}$ is analytic. Now, suppose $q(z)$ is not constant then I would have a contradiction which is already considered $q(z)=z$ I could not go any further on second and fourth cases. Please help me to see this in more detail. Thank you.",,['complex-analysis']
8,Convergence of $\sum_\lambda \frac{1}{1-\lambda x}$ where $p(\lambda)=0$ for a certain polynomial $p$,Convergence of  where  for a certain polynomial,\sum_\lambda \frac{1}{1-\lambda x} p(\lambda)=0 p,"The powers of the roots $\lambda$ of these polynomials $$p_n(x):=\sum_{k=1}^{n-1}\frac{n!}{(n-k)!}x^{k-1}$$ (compare with the $p_n$ here ) sum to these values $$\sum_\lambda \lambda^k=-(-1)^k\frac{B_k}{k!} \textrm{for } k=1..n-2$$ The $B_k$ are the $k$th Bernoulli numbers $-\frac{1}{2}, \frac{1}{6}, 0, -\frac{1}{30}...$  Since $|\lambda|<1$ (fine to just assume) we have the geometric series $$\sum_{k=0}^\infty(\lambda x)^k=\frac{1}{1-\lambda x}$$ at least for $|x|\leq1$ but most of the $\lambda$ go to zero as $n$ increasesso the radius of convergence also may increase. By summing over all $n-2$ roots $\lambda$ we get for the first $n-2$ terms of the left hand side. $$\sum_{k=1}^{n-2}(\lambda_1 x)^k+\sum_{k=1}^{n-2}(\lambda_2 x)^k+...=-\sum_{k=1}^{n-2}(-1)^kB_k\frac{x}{k!}^k$$ Which if you start at $k=0$ and go to $\infty$ converges to $-x/(1-\exp(-x))$ see here . Question: Is $$-x/(1-\exp(-x))=\lim_{n\rightarrow \infty} \left (\sum_{p_n(\lambda)=0}\frac{1}{1-\lambda x}-n+1 \right)$$ at least for $|x|<1$? Here is a plot for $-x/(1-\exp(-x))$ (green) and $\sum_\lambda \frac{1}{1-\lambda x}-n+1$ (blue) for $n=16$ and the octave code to generate it n = 16;  lambda = roots(factorial(n)./factorial(n - [n-1:-1:1]));  x = -10:1/10:20;  y = zeros(1,length(x)); for i = 1:length(x)   y(i) = sum(1./(1-lambda*x(i))); end  plot(x, y-n+1, 'b-', x, -x./(1-exp(-x)), 'g-')  axis([-10 +20 -20 +5])","The powers of the roots $\lambda$ of these polynomials $$p_n(x):=\sum_{k=1}^{n-1}\frac{n!}{(n-k)!}x^{k-1}$$ (compare with the $p_n$ here ) sum to these values $$\sum_\lambda \lambda^k=-(-1)^k\frac{B_k}{k!} \textrm{for } k=1..n-2$$ The $B_k$ are the $k$th Bernoulli numbers $-\frac{1}{2}, \frac{1}{6}, 0, -\frac{1}{30}...$  Since $|\lambda|<1$ (fine to just assume) we have the geometric series $$\sum_{k=0}^\infty(\lambda x)^k=\frac{1}{1-\lambda x}$$ at least for $|x|\leq1$ but most of the $\lambda$ go to zero as $n$ increasesso the radius of convergence also may increase. By summing over all $n-2$ roots $\lambda$ we get for the first $n-2$ terms of the left hand side. $$\sum_{k=1}^{n-2}(\lambda_1 x)^k+\sum_{k=1}^{n-2}(\lambda_2 x)^k+...=-\sum_{k=1}^{n-2}(-1)^kB_k\frac{x}{k!}^k$$ Which if you start at $k=0$ and go to $\infty$ converges to $-x/(1-\exp(-x))$ see here . Question: Is $$-x/(1-\exp(-x))=\lim_{n\rightarrow \infty} \left (\sum_{p_n(\lambda)=0}\frac{1}{1-\lambda x}-n+1 \right)$$ at least for $|x|<1$? Here is a plot for $-x/(1-\exp(-x))$ (green) and $\sum_\lambda \frac{1}{1-\lambda x}-n+1$ (blue) for $n=16$ and the octave code to generate it n = 16;  lambda = roots(factorial(n)./factorial(n - [n-1:-1:1]));  x = -10:1/10:20;  y = zeros(1,length(x)); for i = 1:length(x)   y(i) = sum(1./(1-lambda*x(i))); end  plot(x, y-n+1, 'b-', x, -x./(1-exp(-x)), 'g-')  axis([-10 +20 -20 +5])",,"['complex-analysis', 'analysis']"
9,Prove that a holomorphic function with postive real part is constant,Prove that a holomorphic function with postive real part is constant,,"Suppose that $f$ is holomorphic on $\mathbb C$ and that $\Re(f(z))\ge 0$ for all $z$ . Show that $f$ is constant. [Hint: consider $e^{−f(z)}$ .] My thoughts: If $\Re(f(z))\ge 0 $ holds, then $e^{−f(z)}$ is a bounded holomorphic function (do I need to prove this or is it obvious?) So then by Liouville's Theorem $e^{−f(z)}$ is constant. But then I'm not sure how to rigorously go from this $\exp(−f(z))$ back to $f(z)$ . Could anyone help me piece this together please? Thanks","Suppose that is holomorphic on and that for all . Show that is constant. [Hint: consider .] My thoughts: If holds, then is a bounded holomorphic function (do I need to prove this or is it obvious?) So then by Liouville's Theorem is constant. But then I'm not sure how to rigorously go from this back to . Could anyone help me piece this together please? Thanks",f \mathbb C \Re(f(z))\ge 0 z f e^{−f(z)} \Re(f(z))\ge 0  e^{−f(z)} e^{−f(z)} \exp(−f(z)) f(z),['complex-analysis']
10,Why do the Wirtinger derivatives behave like actual partial derivative operators?,Why do the Wirtinger derivatives behave like actual partial derivative operators?,,"Despite the fact that they're not partial derivative operators, the Wirtinger derivatives obey things like the chain rule.  Of course I can prove such things by manipulating formulas, but this gives no intuition for what's really happening.  Is there a deep reason that everything just seems to work out with these things?","Despite the fact that they're not partial derivative operators, the Wirtinger derivatives obey things like the chain rule.  Of course I can prove such things by manipulating formulas, but this gives no intuition for what's really happening.  Is there a deep reason that everything just seems to work out with these things?",,"['complex-analysis', 'several-complex-variables']"
11,Entire + periodic in imaginary direction + bounded on the real line implies constant?,Entire + periodic in imaginary direction + bounded on the real line implies constant?,,"I was reading some slides from a lecture. In a proof, there arose the need to show a certain function $f : \mathbb{C} \to \mathbb{C}$ was constant. The argument proceeded by checking that $f$ was entire $f(z+i) = f(z)$ for all $z$ $f$ was bounded on $\mathbb{R}$ and then concluding that $f$ must be constant. I followed the proofs of the three claims no problem, but my complex analysis is weak enough that I'm unsure how one is supposed to conclude that $f$ is constant. Clearly Liouville's theorem does not apply directly. My guess is that some kind of boundary principle is being applied to the ""rectangle"" $R = \{ z \in \mathbb{C} : 0 \leq \Im(z) \leq 1 \}$. For instance, if the maximum of $|f|$ on $R$ must occur on the boundary, then the result follows. My complex analysis is patchy enough, though, that I'm unaware if such a result. Added: Relevant: Lindelof's theorem The above article contains an enlightening example. If we take $f(z) = \exp(\exp(2 \pi z))$,  then (1) and (2) are satisfied. (3) is ""half satisfied"" in the sense that $\lim_{t \to -\infty} f(z) = 1$ here.","I was reading some slides from a lecture. In a proof, there arose the need to show a certain function $f : \mathbb{C} \to \mathbb{C}$ was constant. The argument proceeded by checking that $f$ was entire $f(z+i) = f(z)$ for all $z$ $f$ was bounded on $\mathbb{R}$ and then concluding that $f$ must be constant. I followed the proofs of the three claims no problem, but my complex analysis is weak enough that I'm unsure how one is supposed to conclude that $f$ is constant. Clearly Liouville's theorem does not apply directly. My guess is that some kind of boundary principle is being applied to the ""rectangle"" $R = \{ z \in \mathbb{C} : 0 \leq \Im(z) \leq 1 \}$. For instance, if the maximum of $|f|$ on $R$ must occur on the boundary, then the result follows. My complex analysis is patchy enough, though, that I'm unaware if such a result. Added: Relevant: Lindelof's theorem The above article contains an enlightening example. If we take $f(z) = \exp(\exp(2 \pi z))$,  then (1) and (2) are satisfied. (3) is ""half satisfied"" in the sense that $\lim_{t \to -\infty} f(z) = 1$ here.",,"['complex-analysis', 'maximum-principle']"
12,Branch cut for $\log (-z)$,Branch cut for,\log (-z),"I'm trying to understand the location of the branch cut for 2 particular branches of $\log (-z)$. Supposedly if we restrict $\arg (-z)$ to $0 \le \arg(-z) < 2 \pi $, we need to omit the half-line $(-\infty,0]$. And if we restrict $\arg(-z)$ to  $-\pi \le \arg(-z) < \pi$, we need to omit the half-line $[0,\infty)$. That seems backwards to me. EDIT : In the first case, the branch cut is along the negative real axis because that is where $-z$ is positive and real. And in the second case, the branch cut is along the positive real axis because that is where $-z$ is negative and real.","I'm trying to understand the location of the branch cut for 2 particular branches of $\log (-z)$. Supposedly if we restrict $\arg (-z)$ to $0 \le \arg(-z) < 2 \pi $, we need to omit the half-line $(-\infty,0]$. And if we restrict $\arg(-z)$ to  $-\pi \le \arg(-z) < \pi$, we need to omit the half-line $[0,\infty)$. That seems backwards to me. EDIT : In the first case, the branch cut is along the negative real axis because that is where $-z$ is positive and real. And in the second case, the branch cut is along the positive real axis because that is where $-z$ is negative and real.",,['complex-analysis']
13,Find a branch for $(4+z^2)^{1/2}$ such that it is analytic in the complex plane slit along the imaginary axis from $-2i$ to $2i$,Find a branch for  such that it is analytic in the complex plane slit along the imaginary axis from  to,(4+z^2)^{1/2} -2i 2i,"Find a branch for the multiple-valued function $(4+z^2)^{1/2}$ such that it is analytic in the complex plane slit along the imaginary axis from $-2i$ to $2i$ Also, isn't this function already analytic on the slit from $-2i$ to $2i$ without being modified?","Find a branch for the multiple-valued function $(4+z^2)^{1/2}$ such that it is analytic in the complex plane slit along the imaginary axis from $-2i$ to $2i$ Also, isn't this function already analytic on the slit from $-2i$ to $2i$ without being modified?",,['complex-analysis']
14,Finding the Range of a Complex Function,Finding the Range of a Complex Function,,"I am taking Complex Analysis right now and having difficulty understanding how to find the range of complex functions, it seems that there is no standard way to do it and that each problem is different depending on how the function is presented to you and what you know about the domain. In particular, for a function like, say, $$f(z) = \frac{\overline{z}}{4-3z}$$ how would I be able to find the range? My attempts have been to let $a + bi = \frac{x - iy}{4 - 3(x + iy)}$ and then attempt to solve for $x$ and $y$ in terms of $a$ and $b$ in order to see what values of $x$ and $y$ give you something in the range, but I just end up with a non-intuitive answer with messy algebra that doesn't actually give me a nice closed form solution for the range such as ""all complex numbers with real part less than a half"" or something.","I am taking Complex Analysis right now and having difficulty understanding how to find the range of complex functions, it seems that there is no standard way to do it and that each problem is different depending on how the function is presented to you and what you know about the domain. In particular, for a function like, say, $$f(z) = \frac{\overline{z}}{4-3z}$$ how would I be able to find the range? My attempts have been to let $a + bi = \frac{x - iy}{4 - 3(x + iy)}$ and then attempt to solve for $x$ and $y$ in terms of $a$ and $b$ in order to see what values of $x$ and $y$ give you something in the range, but I just end up with a non-intuitive answer with messy algebra that doesn't actually give me a nice closed form solution for the range such as ""all complex numbers with real part less than a half"" or something.",,"['complex-analysis', 'functions']"
15,True/False Questions for Complex Analysis,True/False Questions for Complex Analysis,,"I am studying for my (introductory) complex analysis final exam tomorrow. I am practicing an old final exam, which unfortunately has no answer key. Here is a link: http://www.math.ubc.ca/Ugrad/pastExams/Math_300_December_2008.pdf I just want to know if I am on the right track for Problem 1, which is collection of 10 (kind of tricky!) true/false questions. Here are my attempts: 1) If $f(z)$ satisfies Cauchy-Riemann equations at $z_0$, then $f(z)$ is differentiable at $z_0$. False. For differentiability, one also needs continuity of partial derivatives. 2) If $f(z)$ has a pole at $z_0$, then $\lim_{z\to z_0}|f(z)|=\infty$. True. Though I am not sure if I know how to prove it rigorously. 3) If $f(z)$ is analytic in a domain $D$ containing a simple closed contour $\Gamma$, then $\int f(z)dz=0$. False. For conclusion to be true in general, one needs simply-connected domain. 4) If the two power series $\sum_{k=0}^\infty a_k (z-z_0)^k$ and  $\sum_{k=0}^\infty b_k (z-z_0)^k$ converge to the same function in the disk $\{|z-z_0|\}$, then $a_k=b_k$ for all $k$. I think the answer is True for this one. I believe this follows from Taylor theorem. The coefficients $a_k$ and $b_k$ are determined from derivatives of $f$, so they must be equal. Is this correct? 5) There does not exist any function $f(z)$ which is analytic at the point $0$ and nonanalytic everywhere else. I think the answer is False. I can't think of a counterexample. Maybe the function $|z|^2$ ? 6) The function $\text{Log}(z^2)$ is analytic for all values of $z$ except those on the negative real axis. False. The function $\text{Log}(z^2)$ is analytic for all values of $z$ except those on upper half of imaginary axis. 7) Any entire function is the complex derivative of another entire function True. This follows from Cauchy Integral Formula. 8) If $f(z)$ has an essential singularity at $z_0$, then Res$((z-z_0)f(z); z_0)=0$. I am pretty sure this is false. For example, $f(z)=e^{1/z}$ would be a counter-example. 9) If $f(z)$ and $g(z)$ have a simple poles at $0$, then $(fg)(z)$ has a simple pole at $0$. I think it is true. By the way, I am not sure if the notation above stands for product, or composition. The question doesn't indicate the usage. But I think in either case, the statement would be true. Any comments on this one? 10) If the disk of convergence of the Taylor series of a function $f(z)$ is $\{|z|=2\}$, then the disk of convergence for the Taylor series of $f(z^2)$ is $\{|z|=4\}$. Frankly, I am completely struck at this one. I have not the slightest idea of relating radii of convergence for the functions $f(z)$ and $f(z^2)$. Any help and feedback on any of the questions is much appreciated. I suspect I have made couple mistakes above, apart from the ones I am stuck on. Confirming one of the my answers as correct would be just as awesome! :) Thanks.","I am studying for my (introductory) complex analysis final exam tomorrow. I am practicing an old final exam, which unfortunately has no answer key. Here is a link: http://www.math.ubc.ca/Ugrad/pastExams/Math_300_December_2008.pdf I just want to know if I am on the right track for Problem 1, which is collection of 10 (kind of tricky!) true/false questions. Here are my attempts: 1) If $f(z)$ satisfies Cauchy-Riemann equations at $z_0$, then $f(z)$ is differentiable at $z_0$. False. For differentiability, one also needs continuity of partial derivatives. 2) If $f(z)$ has a pole at $z_0$, then $\lim_{z\to z_0}|f(z)|=\infty$. True. Though I am not sure if I know how to prove it rigorously. 3) If $f(z)$ is analytic in a domain $D$ containing a simple closed contour $\Gamma$, then $\int f(z)dz=0$. False. For conclusion to be true in general, one needs simply-connected domain. 4) If the two power series $\sum_{k=0}^\infty a_k (z-z_0)^k$ and  $\sum_{k=0}^\infty b_k (z-z_0)^k$ converge to the same function in the disk $\{|z-z_0|\}$, then $a_k=b_k$ for all $k$. I think the answer is True for this one. I believe this follows from Taylor theorem. The coefficients $a_k$ and $b_k$ are determined from derivatives of $f$, so they must be equal. Is this correct? 5) There does not exist any function $f(z)$ which is analytic at the point $0$ and nonanalytic everywhere else. I think the answer is False. I can't think of a counterexample. Maybe the function $|z|^2$ ? 6) The function $\text{Log}(z^2)$ is analytic for all values of $z$ except those on the negative real axis. False. The function $\text{Log}(z^2)$ is analytic for all values of $z$ except those on upper half of imaginary axis. 7) Any entire function is the complex derivative of another entire function True. This follows from Cauchy Integral Formula. 8) If $f(z)$ has an essential singularity at $z_0$, then Res$((z-z_0)f(z); z_0)=0$. I am pretty sure this is false. For example, $f(z)=e^{1/z}$ would be a counter-example. 9) If $f(z)$ and $g(z)$ have a simple poles at $0$, then $(fg)(z)$ has a simple pole at $0$. I think it is true. By the way, I am not sure if the notation above stands for product, or composition. The question doesn't indicate the usage. But I think in either case, the statement would be true. Any comments on this one? 10) If the disk of convergence of the Taylor series of a function $f(z)$ is $\{|z|=2\}$, then the disk of convergence for the Taylor series of $f(z^2)$ is $\{|z|=4\}$. Frankly, I am completely struck at this one. I have not the slightest idea of relating radii of convergence for the functions $f(z)$ and $f(z^2)$. Any help and feedback on any of the questions is much appreciated. I suspect I have made couple mistakes above, apart from the ones I am stuck on. Confirming one of the my answers as correct would be just as awesome! :) Thanks.",,"['complex-analysis', 'examples-counterexamples', 'analyticity']"
16,Let $f$ be a non-constant entire function such that $\left \lvert f(z) \right\lvert=1$ for every $z$ with $\left \lvert z \right\lvert=1$.,Let  be a non-constant entire function such that  for every  with .,f \left \lvert f(z) \right\lvert=1 z \left \lvert z \right\lvert=1,"I was thinking about the problem that says: Let $f$ be a non-constant entire function such that $\left | f(z) \right |=1$  for every $z$ with $\left \lvert z \right \lvert =1$. Then which of the following option(s) is/are correct? (a) $f$ has a zero in the open unit disc, (b) $f$ always has a zero outside the closed unit disc, (c) $f$ need not have any zero, (d) any such $f$ has exactly one zero in the open unit disc. If we take $f(z)=z^n$, then the given condition is satisfied and I think option (a) is correct. But I can not predict anything about the other options. Please help. Thanks in advance for your time.","I was thinking about the problem that says: Let $f$ be a non-constant entire function such that $\left | f(z) \right |=1$  for every $z$ with $\left \lvert z \right \lvert =1$. Then which of the following option(s) is/are correct? (a) $f$ has a zero in the open unit disc, (b) $f$ always has a zero outside the closed unit disc, (c) $f$ need not have any zero, (d) any such $f$ has exactly one zero in the open unit disc. If we take $f(z)=z^n$, then the given condition is satisfied and I think option (a) is correct. But I can not predict anything about the other options. Please help. Thanks in advance for your time.",,['complex-analysis']
17,Connectedness of $\lbrace z\in\mathbb{C} : |z^2+az+b|<r\rbrace$,Connectedness of,\lbrace z\in\mathbb{C} : |z^2+az+b|<r\rbrace,"What are the values of $r$ for which the set $$\lbrace z\in\mathbb{C} : |z^2+az+b|<r\rbrace$$ is connected ? Here $a,b\in\mathbb{C}$ and $r\in\mathbb{R}$.","What are the values of $r$ for which the set $$\lbrace z\in\mathbb{C} : |z^2+az+b|<r\rbrace$$ is connected ? Here $a,b\in\mathbb{C}$ and $r\in\mathbb{R}$.",,"['complex-analysis', 'complex-numbers']"
18,Coefficient growth in the power series $\sum u_n z^n = e^{1/(1-z)}$?,Coefficient growth in the power series ?,\sum u_n z^n = e^{1/(1-z)},"Let $\sum u_n z^n$ denote the power series of $e^{1/(1-z)}$.  As our radius of convergence is $1$, it follows that $u_n$ exhibits sub-exponential growth.  On the other hand, $\{u_n\}$ must grow supra-polynomially, else transfer theorems like those found in Singularity Analysis of Generating Functions would then imply that the singularity at $z=1$ is regular.  Heuristically, it would appear that $$u_n \sim \alpha n^{-3/4} e^{2\sqrt{n}},$$ for some $\alpha \approx .162982$.  This opinion is echoed, without support, as a comment on the OEIS page for A000262 . Note: The sequence considered therein is the generating function of $e^{z/(1-z)}$, which has $\mathbb{Z}$ coefficients after scaling $u_n$ by $n!$ How would one derive asymptotic results such as these? ( Edited for spelling. ) Note: I've posted my own solution in the answers below.  In short, the saddle-point method applies.","Let $\sum u_n z^n$ denote the power series of $e^{1/(1-z)}$.  As our radius of convergence is $1$, it follows that $u_n$ exhibits sub-exponential growth.  On the other hand, $\{u_n\}$ must grow supra-polynomially, else transfer theorems like those found in Singularity Analysis of Generating Functions would then imply that the singularity at $z=1$ is regular.  Heuristically, it would appear that $$u_n \sim \alpha n^{-3/4} e^{2\sqrt{n}},$$ for some $\alpha \approx .162982$.  This opinion is echoed, without support, as a comment on the OEIS page for A000262 . Note: The sequence considered therein is the generating function of $e^{z/(1-z)}$, which has $\mathbb{Z}$ coefficients after scaling $u_n$ by $n!$ How would one derive asymptotic results such as these? ( Edited for spelling. ) Note: I've posted my own solution in the answers below.  In short, the saddle-point method applies.",,"['complex-analysis', 'asymptotics', 'generating-functions']"
19,How does the radius of convergence depend on the point about which the series is expanded?,How does the radius of convergence depend on the point about which the series is expanded?,,"For a given analytic germ $f(z)=\sum_{n=0}^{\infty} a_n (z-z_0)^n$, and a simple curve $\gamma: [0,1]\to \mathbb{C}$ such that $\gamma(0)=z_0$, suppose one may analytically continue $f(z)$ along $\gamma$. So for each point $\tilde{z} =\gamma(t)$ there is a corresponding power series $f(z;\tilde{z})=\sum_{n=0}^{\infty} \tilde{a}_n (z-\tilde{z})^n$ with its own radius of convergence $r(\tilde{z})$. My question is, what can be said about this function $r$? How regular is it? Is it continuous? What about for more than one variable?","For a given analytic germ $f(z)=\sum_{n=0}^{\infty} a_n (z-z_0)^n$, and a simple curve $\gamma: [0,1]\to \mathbb{C}$ such that $\gamma(0)=z_0$, suppose one may analytically continue $f(z)$ along $\gamma$. So for each point $\tilde{z} =\gamma(t)$ there is a corresponding power series $f(z;\tilde{z})=\sum_{n=0}^{\infty} \tilde{a}_n (z-\tilde{z})^n$ with its own radius of convergence $r(\tilde{z})$. My question is, what can be said about this function $r$? How regular is it? Is it continuous? What about for more than one variable?",,['complex-analysis']
20,"Weierstrass Factorization Theorem, infinite polynomial/infinite power series","Weierstrass Factorization Theorem, infinite polynomial/infinite power series",,"As we know from basic complex analysis, any finite polynomial (infinite power series) $P(z)$ can be represented as a product of its zeroes. $P(z)=\Pi_n(z-z_n)$ (when $z_n $ are the zeros). And as we know, the ""Weierstrass Factorization Theorem"" is a super inclusion of the theorem that I mentioned before, and it is pretty hard to prove the Weierstrass Factorization Theorem. I tried to prove the Weierstrass Factorization Theorem when the function is an infinite power series, but  it seems more complicated than I thought. Does anyone know if there is a nice (or not) proof to Weierstrass Factorization Theorem when the function is an infinite power series?","As we know from basic complex analysis, any finite polynomial (infinite power series) can be represented as a product of its zeroes. (when are the zeros). And as we know, the ""Weierstrass Factorization Theorem"" is a super inclusion of the theorem that I mentioned before, and it is pretty hard to prove the Weierstrass Factorization Theorem. I tried to prove the Weierstrass Factorization Theorem when the function is an infinite power series, but  it seems more complicated than I thought. Does anyone know if there is a nice (or not) proof to Weierstrass Factorization Theorem when the function is an infinite power series?",P(z) P(z)=\Pi_n(z-z_n) z_n ,['complex-analysis']
21,Logic behind Möbius transformation,Logic behind Möbius transformation,,"So I am attempting to get a grasp on Möbius transformations. Specifically, I'm trying to understand the logic and reasoning behind using them to map certain subsets of the complex plane into others. The following problem is from Lars Ahlfors, ""Complex analysis"", 1966.(p.83). Find the Mobius transformation which carries the circle $|z|=2$ into $|z+1|=1$ , the point $-2$ into the origin, and the origin into $i$ . Graphically: Since i know where the two specific points $z_1=-2$ and $z_2=0$ are being mapped, I can set up the equation: $$ \frac{f(z)-f(z_1)}{f(z)-f(z_2)}=K\frac{z-z_1}{z-z_2} $$ Which yields: $\frac{f(z)}{f(z)-i}=K\frac{z+2}{z}$ , or equivalently: $$[\ast] \quad \quad f(z)=\frac{(-iK)z+(-2iK)}{(1-K)z+(-2K)}$$ Now, If I knew where one more point was mapped, I would be able to determine the coefficient $K$ , and thus $f$ . This is the point where I do not know how to reason to get past. My thought was ""try $f(2)=-2$ "", since this would preserve the diametrically opposite points. The resulting transformation does however not map the circle to the circle. Therefore, to figure out the answer, I put a complex number $K$ in geogebra, defined the function $f$ as in $[\ast]$ , put a bunch of points $A,B,C,D,E$ evenly on the circle $|z|=2$ , and varied the parameter $K$ until $f(A),f(B),f(C),f(D),f(E)$ all ligned up on the circle $|z+1|=1$ . This gave the result $K=-i$ , which means that the answer to the problem is $$f(z)=\frac{iz+2i}{2z+2}$$ I do not understand how I would have figured this out by calculation, since I seem to miss some crucial information... I did however figure out that if i choose $f(-2i)=-1+i$ for my third point, I get the correct transformation, but I do not know why as I found this by trial and error.... Thanx, Robin","So I am attempting to get a grasp on Möbius transformations. Specifically, I'm trying to understand the logic and reasoning behind using them to map certain subsets of the complex plane into others. The following problem is from Lars Ahlfors, ""Complex analysis"", 1966.(p.83). Find the Mobius transformation which carries the circle into , the point into the origin, and the origin into . Graphically: Since i know where the two specific points and are being mapped, I can set up the equation: Which yields: , or equivalently: Now, If I knew where one more point was mapped, I would be able to determine the coefficient , and thus . This is the point where I do not know how to reason to get past. My thought was ""try "", since this would preserve the diametrically opposite points. The resulting transformation does however not map the circle to the circle. Therefore, to figure out the answer, I put a complex number in geogebra, defined the function as in , put a bunch of points evenly on the circle , and varied the parameter until all ligned up on the circle . This gave the result , which means that the answer to the problem is I do not understand how I would have figured this out by calculation, since I seem to miss some crucial information... I did however figure out that if i choose for my third point, I get the correct transformation, but I do not know why as I found this by trial and error.... Thanx, Robin","|z|=2 |z+1|=1 -2 i z_1=-2 z_2=0  \frac{f(z)-f(z_1)}{f(z)-f(z_2)}=K\frac{z-z_1}{z-z_2}  \frac{f(z)}{f(z)-i}=K\frac{z+2}{z} [\ast] \quad \quad f(z)=\frac{(-iK)z+(-2iK)}{(1-K)z+(-2K)} K f f(2)=-2 K f [\ast] A,B,C,D,E |z|=2 K f(A),f(B),f(C),f(D),f(E) |z+1|=1 K=-i f(z)=\frac{iz+2i}{2z+2} f(-2i)=-1+i","['complex-analysis', 'complex-numbers', 'mobius-transformation']"
22,Lower bound for $\Gamma(x+i y)$ where $x>0$ involving only the real part,Lower bound for  where  involving only the real part,\Gamma(x+i y) x>0,"I am trying to have some inequalities involving the special Gamma function. I am able to get an upper bound for $\Gamma(x+i y)$ , for $x>0$ , $$ \begin{align} |\Gamma(x+iy)| &=\left|\int_0^\infty e^{-t}\,t^{x+iy-1}\;\mathrm{d}t\right|\\ &=\left|\int_0^\infty e^{-t}\,t^{x-1}\,e^{iy\log(t)}\;\mathrm{d}t\right|\\ &\le\int_0^\infty\left|e^{-t}\,t^{x-1}\,e^{iy\log(t)}\right|\;\mathrm{d}t\\ &=\int_0^\infty e^{-t}\,t^{x-1}\;\mathrm{d}t\\ &=\Gamma(x)\\ &=|\Gamma(x)|\tag{1}. \end{align} $$ However, I did not succeed to get a lower bound for $\Gamma(x+i y)$ such that I get rid of the imaginary part. Any help in this direction? Using the suggestion of @reuns and the Euler's reflection formula, one can shows that \begin{align} \left|\Gamma(x+i y)\right| &= \frac{\pi}{\left|\Gamma(1-(x+i y)\right| \left|\sin(\pi (x+i y))\right|} \\ &\ge \frac{\pi}{\left|\Gamma(1-x)\right| \left|\sin(\pi (x+i y))\right|}  \end{align} But I can not still get a lower bound for the complex sine term such that I get rid of the imaginary part! Any suggestion?","I am trying to have some inequalities involving the special Gamma function. I am able to get an upper bound for , for , However, I did not succeed to get a lower bound for such that I get rid of the imaginary part. Any help in this direction? Using the suggestion of @reuns and the Euler's reflection formula, one can shows that But I can not still get a lower bound for the complex sine term such that I get rid of the imaginary part! Any suggestion?","\Gamma(x+i y) x>0 
\begin{align}
|\Gamma(x+iy)|
&=\left|\int_0^\infty e^{-t}\,t^{x+iy-1}\;\mathrm{d}t\right|\\
&=\left|\int_0^\infty e^{-t}\,t^{x-1}\,e^{iy\log(t)}\;\mathrm{d}t\right|\\
&\le\int_0^\infty\left|e^{-t}\,t^{x-1}\,e^{iy\log(t)}\right|\;\mathrm{d}t\\
&=\int_0^\infty e^{-t}\,t^{x-1}\;\mathrm{d}t\\
&=\Gamma(x)\\
&=|\Gamma(x)|\tag{1}.
\end{align}
 \Gamma(x+i y) \begin{align} \left|\Gamma(x+i y)\right| &= \frac{\pi}{\left|\Gamma(1-(x+i y)\right| \left|\sin(\pi (x+i y))\right|} \\
&\ge \frac{\pi}{\left|\Gamma(1-x)\right| \left|\sin(\pi (x+i y))\right|}
 \end{align}","['complex-analysis', 'inequality', 'special-functions', 'gamma-function']"
23,"If $f(z)=z+a_2z^2+...+a_nz^n$ is injective on the unit disk, then $|a_2|≤\frac12(n-1)$","If  is injective on the unit disk, then",f(z)=z+a_2z^2+...+a_nz^n |a_2|≤\frac12(n-1),"Suppose $f(z)=z+a_2z^2+...+a_nz^n$ is injective in $D:=\{z:|z|<1\}$ .  Show that $|a_2|≤(n-1)/2$ and $|a_n|≤1/n$ . Partial Solution Assume without loss of generality that $a_n\ne0$ . If $f$ is injective, then $f'(z)≠0$ in $D$ . Now, $$f'(z)=1+2a_2z+...+na_nz^{n-1}$$ By the fundamental theorem of algebra, $$f'(z)=na_n(z-r_1)...(z-r_{n-1})$$ where $r_1,...,r_{n-1}$ are the roots of $f'(z)$ , and $$f'(0)=1=na_n(-1)^nr_1r_2...r_{n-1}$$ Note that $|r_i|\geq1$ for each $i=1,...,n-1$ , hence $$|r_1r_2...r_{n-1}|\geq1$$ and, finally, $$|a_n|=\frac1{n\,|r_1r_2...r_{n-1}|}\leq\frac{1}{n}$$ What I cannot figure out, though, is how to prove that $|a_2|≤(n-1)/2$ .  I have tried similar arguments, but cannot seem to get it.  Any hints would be greatly appreciated.","Suppose is injective in .  Show that and . Partial Solution Assume without loss of generality that . If is injective, then in . Now, By the fundamental theorem of algebra, where are the roots of , and Note that for each , hence and, finally, What I cannot figure out, though, is how to prove that .  I have tried similar arguments, but cannot seem to get it.  Any hints would be greatly appreciated.","f(z)=z+a_2z^2+...+a_nz^n D:=\{z:|z|<1\} |a_2|≤(n-1)/2 |a_n|≤1/n a_n\ne0 f f'(z)≠0 D f'(z)=1+2a_2z+...+na_nz^{n-1} f'(z)=na_n(z-r_1)...(z-r_{n-1}) r_1,...,r_{n-1} f'(z) f'(0)=1=na_n(-1)^nr_1r_2...r_{n-1} |r_i|\geq1 i=1,...,n-1 |r_1r_2...r_{n-1}|\geq1 |a_n|=\frac1{n\,|r_1r_2...r_{n-1}|}\leq\frac{1}{n} |a_2|≤(n-1)/2","['complex-analysis', 'polynomials']"
24,Evaluation of $\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds$,Evaluation of,\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds,"I am having trouble trying to evaluate the integral : $$\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds$$ Where $0<c<1$ and $n,m$ are positive integers. The integrand has two branch cuts : $(-\infty,0]$ and $[1,\infty)$ , so shifting the line of integration doesn't work. I tried bending the line of integration so it lies just above and just below one of the branch cuts, but that didn't work either, or i have made a mistake. any insight is appreciated. EDIT : After a couple of transformations, i obtained : $$\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds=$$ $$\frac{1}{2\pi i }\int_{-\infty}^{\infty}\frac{\log(is)^{n}\log(1-is)^{m}}{s(1-is)}ds=-\Re\left[\frac{1}{\pi i }\int_{0}^{\infty}\frac{y ^{n}\log(1-e^{y})^{m}}{1-e^{y}}dy \right ]$$ Still, i have no idea on how to evaluate the integral !!","I am having trouble trying to evaluate the integral : Where and are positive integers. The integrand has two branch cuts : and , so shifting the line of integration doesn't work. I tried bending the line of integration so it lies just above and just below one of the branch cuts, but that didn't work either, or i have made a mistake. any insight is appreciated. EDIT : After a couple of transformations, i obtained : Still, i have no idea on how to evaluate the integral !!","\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds 0<c<1 n,m (-\infty,0] [1,\infty) \frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}\frac{\log(s)^{n}\log(1-s)^{m}}{s(1-s)}ds= \frac{1}{2\pi i }\int_{-\infty}^{\infty}\frac{\log(is)^{n}\log(1-is)^{m}}{s(1-is)}ds=-\Re\left[\frac{1}{\pi i }\int_{0}^{\infty}\frac{y ^{n}\log(1-e^{y})^{m}}{1-e^{y}}dy \right ]","['complex-analysis', 'contour-integration']"
25,Milne Thomson method for determining an analytic function from its real part,Milne Thomson method for determining an analytic function from its real part,,"What is the logic behind taking  $z = {\bar {z}}$ while finding analytic function in Milne-Thomson Method ? I mean we write  $ { f(z)=u(x,y)+iv(x,y)} $ as  $  {\displaystyle f(z)=u\left({\frac {z+{\bar {z}}}{2}}\ ,{\frac {z-{\bar {z}}}{2i}}\right)+iv\left({\frac {z+{\bar {z}}}{2}}\ ,{\frac {z-{\bar {z}}}{2i}}\right)} {\displaystyle } $ Its fine uptil now but then we say $f(z)$ can be regarded as an identity in two independent variables $z$ and $ {\bar {z}}$ so we take $z = {\bar {z}}$, this gives us $ { f(z)=u(z,0)+iv(z,0)} $ Source I am not getting the the part $z = {\bar {z}}$ . How do we regard it an identity of 2 independent variable? Please guide me with an intuitive explanation. ( Please use example if you can ) . I went through this Link but could not understand how $w$ is independent of $z$. I mean whatever value of $x$ and $y$ we take $z$ and $w$ are obtained from the same x and y, so how can we say both are independent! Thanks in advance !","What is the logic behind taking  $z = {\bar {z}}$ while finding analytic function in Milne-Thomson Method ? I mean we write  $ { f(z)=u(x,y)+iv(x,y)} $ as  $  {\displaystyle f(z)=u\left({\frac {z+{\bar {z}}}{2}}\ ,{\frac {z-{\bar {z}}}{2i}}\right)+iv\left({\frac {z+{\bar {z}}}{2}}\ ,{\frac {z-{\bar {z}}}{2i}}\right)} {\displaystyle } $ Its fine uptil now but then we say $f(z)$ can be regarded as an identity in two independent variables $z$ and $ {\bar {z}}$ so we take $z = {\bar {z}}$, this gives us $ { f(z)=u(z,0)+iv(z,0)} $ Source I am not getting the the part $z = {\bar {z}}$ . How do we regard it an identity of 2 independent variable? Please guide me with an intuitive explanation. ( Please use example if you can ) . I went through this Link but could not understand how $w$ is independent of $z$. I mean whatever value of $x$ and $y$ we take $z$ and $w$ are obtained from the same x and y, so how can we say both are independent! Thanks in advance !",,"['complex-analysis', 'holomorphic-functions', 'analytic-functions']"
26,"Find $\int_{|z|=5} \frac{zf'(z)}{f(z)}dz$ when $24\le |f'''(z)|\le 30$, $f(0)=f(1)=f(2)=3$","Find  when ,",\int_{|z|=5} \frac{zf'(z)}{f(z)}dz 24\le |f'''(z)|\le 30 f(0)=f(1)=f(2)=3,"Let $f$ be an entire function such that $24\le |f'''(z)|\le 30$, $f(0)=f(1)=f(2)=3$. I want to find $$\int_{|z|=5} \frac{zf'(z)}{f(z)}dz.$$ My attempt: Since $f$ is entire, $f'''$ is also entire. $f'''$ is also bounded. Thus, by Liouville's theorem, $f'''$ is constant and $f$ is a cubic function. Since $f(0)=f(1)=f(2)=3$, $f(z)=az(z-1)(z-2)+3$ and $4\le|a|\le 5$. To use the residue theorem, we should know the zeros of $f(z)=0$, but I don't know how to find them. Where is the way I have to go?","Let $f$ be an entire function such that $24\le |f'''(z)|\le 30$, $f(0)=f(1)=f(2)=3$. I want to find $$\int_{|z|=5} \frac{zf'(z)}{f(z)}dz.$$ My attempt: Since $f$ is entire, $f'''$ is also entire. $f'''$ is also bounded. Thus, by Liouville's theorem, $f'''$ is constant and $f$ is a cubic function. Since $f(0)=f(1)=f(2)=3$, $f(z)=az(z-1)(z-2)+3$ and $4\le|a|\le 5$. To use the residue theorem, we should know the zeros of $f(z)=0$, but I don't know how to find them. Where is the way I have to go?",,"['complex-analysis', 'complex-integration']"
27,"Eisenstein Series, discriminant and cusp forms","Eisenstein Series, discriminant and cusp forms",,"I'm working on the following exercise: Let $E_k=\frac{G_k(z)}{2\zeta(k)}$ be the normalized Eisenstein series of weight $k$. Calculate a)$E_4=1+240\sum_{n=1}\sigma_3(n)q^n$ and b)$E_6=1-504\sum_{n=1}\sigma_5(n)q^n$, where $q=\exp(2\pi i z)$ c) Show that $\sigma_3(n)=\sigma_5(n)\,\text{mod}(12)$, where $\sigma_k(n)=\sum_{d|n}d^k$ d) Finally show that $\Delta=\frac{1}{1728}(E^3_4-E^2_6)$ is a non-zero cusp form of weight $k=12$ and integer fourier coefficients. My solution attempt: a&b)The Fourier transform for $G_k$ is $G_k(z)=2\zeta(k)+\frac{2(2\pi i)^k}{(k-1)!}\sum_{n=1}^{\infty}\sigma_{k-1}(n)q^{n}$, where $q=\exp(2\pi i z)$. Further $\zeta(2k)=\sum_{n=1}n^{-2k}=\frac{(-1)^{k+1}(2\pi)^{2k}}{2(2k)!}B_{2k}$ from the Euler formula, which gives $\zeta(4)=\frac{\pi^4}{90}$ and $\zeta(6)=\frac{\pi^6}{945}$. Hence $$E_4=\frac{G_4}{2\zeta(4)}=\left(\frac{\pi^4}{45}+\frac{2(2\pi i)^4}{3!}\sum_{n=1}^{\infty}\sigma_3(n)q^n\right)\frac{\pi^4}{45}=1+240\sum_{n=1}\sigma_3(n)q^n$$ Similarly for $E_6$. c) is where I'm starting to have problems, I have honestly no idea how to approach this part. d) First we have that for $G_{k}(\frac{az+b}{cz+d})=(cz+d)^{k}G_k(z)$ and further that $G_k$ is analytic and possesses a Fourier transform, as such it is a modular form of weight $k$. By definition of $E_k$ this property is ""inherited"" obviously and we also immediately get that $E_k^j$ is a modular form of weight $kj$.  As such $\Delta'=E^3_4-E^2_6$ is the difference of two modular forms of weight $kj=12$ and hence a modular form of weight $12$ itself. Thus $\Delta$ is one as well. To verify that $\Delta$ is indeed a cusp form we have to examine the behavior at $\infty$. We have that $\lim_{z\to\infty}G_k(z)=2\zeta(k)$ and hence that $\Delta=\frac{1}{1728}(E^3_4-E^2_6)=\frac{1}{1728}\left(\left(\frac{G_4(z)}{2\zeta(4)}\right)^3-\left(\frac{G_6(z)}{2\zeta(6)}\right)^2\right)$ tends to $0$ as $z\to\infty$, as such $\Delta$ is a cusp form of weight $12$. For the fourier coefficients I'm having problems again. Calculating some of the coefficients, it's somewhat obvious that they have to be whole numbers, but I'm unsure how to prove this. As such I guess I'm hoping for some help with c) and the second part of d). Thanks in advance! Edit: And if someone could confirm that my reasoning at all is sound would be amazing as well! I'm not entirely sure with my arguments in d). Edit2: I think I've solved it: \begin{align*} E_4^3-E_6^2&=(1+240\sum_{n=1}\sigma_3(n)q^n)^3-(1-504\sum_{n=1}\sigma_5(n) q^n)^2\\ &=12^2\left(5\sum_{n=1}\sigma_3(n)q^n+7\sum_{n=1}\sigma_5(n)q^n\right)+12^3\left(100(\sum_{n=1}\sigma_3(n)q^n)^2-147(\sum_{n=1}\sigma_5(n) q^n)^2+8000(\sum_{n=1}\sigma_3(n) q^n)^3\right) \\ &=12^2\left(\left(5\sum_{n=1}\sigma_3(n)q^n+7\sum_{n=1}\sigma_5(n)q^n\right)\right)+\left(12\left(100(\sum_{n=1}\sigma_3(n)q^n)^2-147(\sum_{n=1}\sigma_5(n) q^n)^2+8000(\sum_{n=1}\sigma_3(n) q^n)^3\right)\right) \end{align*} With $\Delta=\frac{1}{1728}(E^3_4-E^2_6)=\frac{1}{2^63^3}(E^3_4-E^2_6)$ and the above it remains to show that $5\sum_{n=1}\sigma_3(n)q^n-7\sum_{n=1}\sigma_5(n) q^n$ is divisible by 12. We have $$5\sum_{n=1}\sigma_3(n)q^n-7\sum_{n=1}\sigma_5(n) q^n=\sum_{n=1}(5\sigma_3(n) +7\sigma_5(n))q^n=\sum_{n=1}\sum_{d|n}(5d^3+7d^5)q^n$$ for $d\in\mathbb{N}$. This leaves to prove $5d^3+7d^5$ is divisible by 12. We have $$5d^3+7d^5=d^3(5+7d^2)= \begin{cases} d^3(1-d^2)&=0 (\text{ mod }4)\\ d^3(-1+d^2)&=0 (\text{ mod }3) \end{cases}$$ This proves c) and what was left of d)","I'm working on the following exercise: Let $E_k=\frac{G_k(z)}{2\zeta(k)}$ be the normalized Eisenstein series of weight $k$. Calculate a)$E_4=1+240\sum_{n=1}\sigma_3(n)q^n$ and b)$E_6=1-504\sum_{n=1}\sigma_5(n)q^n$, where $q=\exp(2\pi i z)$ c) Show that $\sigma_3(n)=\sigma_5(n)\,\text{mod}(12)$, where $\sigma_k(n)=\sum_{d|n}d^k$ d) Finally show that $\Delta=\frac{1}{1728}(E^3_4-E^2_6)$ is a non-zero cusp form of weight $k=12$ and integer fourier coefficients. My solution attempt: a&b)The Fourier transform for $G_k$ is $G_k(z)=2\zeta(k)+\frac{2(2\pi i)^k}{(k-1)!}\sum_{n=1}^{\infty}\sigma_{k-1}(n)q^{n}$, where $q=\exp(2\pi i z)$. Further $\zeta(2k)=\sum_{n=1}n^{-2k}=\frac{(-1)^{k+1}(2\pi)^{2k}}{2(2k)!}B_{2k}$ from the Euler formula, which gives $\zeta(4)=\frac{\pi^4}{90}$ and $\zeta(6)=\frac{\pi^6}{945}$. Hence $$E_4=\frac{G_4}{2\zeta(4)}=\left(\frac{\pi^4}{45}+\frac{2(2\pi i)^4}{3!}\sum_{n=1}^{\infty}\sigma_3(n)q^n\right)\frac{\pi^4}{45}=1+240\sum_{n=1}\sigma_3(n)q^n$$ Similarly for $E_6$. c) is where I'm starting to have problems, I have honestly no idea how to approach this part. d) First we have that for $G_{k}(\frac{az+b}{cz+d})=(cz+d)^{k}G_k(z)$ and further that $G_k$ is analytic and possesses a Fourier transform, as such it is a modular form of weight $k$. By definition of $E_k$ this property is ""inherited"" obviously and we also immediately get that $E_k^j$ is a modular form of weight $kj$.  As such $\Delta'=E^3_4-E^2_6$ is the difference of two modular forms of weight $kj=12$ and hence a modular form of weight $12$ itself. Thus $\Delta$ is one as well. To verify that $\Delta$ is indeed a cusp form we have to examine the behavior at $\infty$. We have that $\lim_{z\to\infty}G_k(z)=2\zeta(k)$ and hence that $\Delta=\frac{1}{1728}(E^3_4-E^2_6)=\frac{1}{1728}\left(\left(\frac{G_4(z)}{2\zeta(4)}\right)^3-\left(\frac{G_6(z)}{2\zeta(6)}\right)^2\right)$ tends to $0$ as $z\to\infty$, as such $\Delta$ is a cusp form of weight $12$. For the fourier coefficients I'm having problems again. Calculating some of the coefficients, it's somewhat obvious that they have to be whole numbers, but I'm unsure how to prove this. As such I guess I'm hoping for some help with c) and the second part of d). Thanks in advance! Edit: And if someone could confirm that my reasoning at all is sound would be amazing as well! I'm not entirely sure with my arguments in d). Edit2: I think I've solved it: \begin{align*} E_4^3-E_6^2&=(1+240\sum_{n=1}\sigma_3(n)q^n)^3-(1-504\sum_{n=1}\sigma_5(n) q^n)^2\\ &=12^2\left(5\sum_{n=1}\sigma_3(n)q^n+7\sum_{n=1}\sigma_5(n)q^n\right)+12^3\left(100(\sum_{n=1}\sigma_3(n)q^n)^2-147(\sum_{n=1}\sigma_5(n) q^n)^2+8000(\sum_{n=1}\sigma_3(n) q^n)^3\right) \\ &=12^2\left(\left(5\sum_{n=1}\sigma_3(n)q^n+7\sum_{n=1}\sigma_5(n)q^n\right)\right)+\left(12\left(100(\sum_{n=1}\sigma_3(n)q^n)^2-147(\sum_{n=1}\sigma_5(n) q^n)^2+8000(\sum_{n=1}\sigma_3(n) q^n)^3\right)\right) \end{align*} With $\Delta=\frac{1}{1728}(E^3_4-E^2_6)=\frac{1}{2^63^3}(E^3_4-E^2_6)$ and the above it remains to show that $5\sum_{n=1}\sigma_3(n)q^n-7\sum_{n=1}\sigma_5(n) q^n$ is divisible by 12. We have $$5\sum_{n=1}\sigma_3(n)q^n-7\sum_{n=1}\sigma_5(n) q^n=\sum_{n=1}(5\sigma_3(n) +7\sigma_5(n))q^n=\sum_{n=1}\sum_{d|n}(5d^3+7d^5)q^n$$ for $d\in\mathbb{N}$. This leaves to prove $5d^3+7d^5$ is divisible by 12. We have $$5d^3+7d^5=d^3(5+7d^2)= \begin{cases} d^3(1-d^2)&=0 (\text{ mod }4)\\ d^3(-1+d^2)&=0 (\text{ mod }3) \end{cases}$$ This proves c) and what was left of d)",,"['complex-analysis', 'analytic-number-theory', 'modular-forms']"
28,Is there a non periodic sequence of 1 and 0 such that its power series can be analytically continued outside of the unit circle,Is there a non periodic sequence of 1 and 0 such that its power series can be analytically continued outside of the unit circle,,"This is something i came across during my own research, i went around and asked quite a few people ( most of them teaching math at college ) and none did manage do give me a definite answer. Disclaimer: i post this from phone, so don't mind me writing formulas using only standard phone keyboard i currently work with, i will try my best to make it readable, + gonna be a bit longer post. The question is following: Is there a function f: $\mathbb{N} \to \{0, 1\}$ that satisfies the following: there is no ordered pair $(n, t)$ such that for each natural number $a$, $$a>n \implies f(a)=f(a+t)$$ aka the tail of $f$ is not periodic. Let $g(z)=\sum_{k=1}^{k=\infty} f(k) z^k$, where $|z|<1$ aka $g$ is defined inside the unit circle of the complex plane excluding the circle boundary. $g(z)$ can be analytically continued to outside the unit circle. What i know so far is that there are examples of functions that satisfy the first property and doesn't satisfy the second ; the ones i know of are $f(x)=1$ if $x=2^k, k$ natural, and $0$ otherwise, and one more with $k!$ instead of $2^k$. Of course, it is easily shown that if the function doesn't satisfy the first property, it must satisfy the other one. This is a simplified version of the problem where instead of $\{0, 1\}$, the codomain of $f$ is $\{0, 1, ... n\}$ for some fixed $n$. This more general problem has came from an attempt to identify ( as many as possible ) the members of p-adic number system, where $p = n$ with complex values such that the set of numbers that can be identified in this way together with p-adic operations on them is isomorphic with the subfield of $\mathbb{C}$ that is made from elements they are identified with. So that was a little bit of background. The main purpose of it was to suggest a possible candidate for $f$ in a more general version of the problem. Let $n=7$, and $x$ be one of the solutions of the equation $x^2=2$ in $\mathbb{Q}_7$, obviously there are 2 solutions opposite to each other ( $x_1+x_2 = 0$ ), $f(k)$ is then the $k$-th digit in the representation of x in $\mathbb{Q}_7$. What i believe is that both solutions generate us a function that would satisfy both properties and that the values of analytic continuations of respective $g_1(z)$ and $g_2(z)$ at $z=7$ will be equal to $\sqrt{2}$ and $- \sqrt{2}$ respectively. Ty for reading until the end and thank you for any help on the topic, i am looking forward to read the answers","This is something i came across during my own research, i went around and asked quite a few people ( most of them teaching math at college ) and none did manage do give me a definite answer. Disclaimer: i post this from phone, so don't mind me writing formulas using only standard phone keyboard i currently work with, i will try my best to make it readable, + gonna be a bit longer post. The question is following: Is there a function f: $\mathbb{N} \to \{0, 1\}$ that satisfies the following: there is no ordered pair $(n, t)$ such that for each natural number $a$, $$a>n \implies f(a)=f(a+t)$$ aka the tail of $f$ is not periodic. Let $g(z)=\sum_{k=1}^{k=\infty} f(k) z^k$, where $|z|<1$ aka $g$ is defined inside the unit circle of the complex plane excluding the circle boundary. $g(z)$ can be analytically continued to outside the unit circle. What i know so far is that there are examples of functions that satisfy the first property and doesn't satisfy the second ; the ones i know of are $f(x)=1$ if $x=2^k, k$ natural, and $0$ otherwise, and one more with $k!$ instead of $2^k$. Of course, it is easily shown that if the function doesn't satisfy the first property, it must satisfy the other one. This is a simplified version of the problem where instead of $\{0, 1\}$, the codomain of $f$ is $\{0, 1, ... n\}$ for some fixed $n$. This more general problem has came from an attempt to identify ( as many as possible ) the members of p-adic number system, where $p = n$ with complex values such that the set of numbers that can be identified in this way together with p-adic operations on them is isomorphic with the subfield of $\mathbb{C}$ that is made from elements they are identified with. So that was a little bit of background. The main purpose of it was to suggest a possible candidate for $f$ in a more general version of the problem. Let $n=7$, and $x$ be one of the solutions of the equation $x^2=2$ in $\mathbb{Q}_7$, obviously there are 2 solutions opposite to each other ( $x_1+x_2 = 0$ ), $f(k)$ is then the $k$-th digit in the representation of x in $\mathbb{Q}_7$. What i believe is that both solutions generate us a function that would satisfy both properties and that the values of analytic continuations of respective $g_1(z)$ and $g_2(z)$ at $z=7$ will be equal to $\sqrt{2}$ and $- \sqrt{2}$ respectively. Ty for reading until the end and thank you for any help on the topic, i am looking forward to read the answers",,"['complex-analysis', 'p-adic-number-theory']"
29,Is the notion of 'divergence to infinity in a direction' used?,Is the notion of 'divergence to infinity in a direction' used?,,"In $\mathbb R$ a sequence can diverge to infinity in two directions: $+\infty$ and $-\infty$. These two cases of divergence are quite different from a sequence that diverges to ""nowhere"", like $\{(-1)^n\}$. One can be interested, for example, in the behavior of a function in one of these two directions of infinity. Is there a similar notion for sequences in the complex plane? (Or other spaces) Does it arise naturally in some field of study? What are possible uses for it? I imagine, for example, that the sequence $\{ni\}$ could be said to diverge to infinity in the direction $i$, whereas the sequence $\{ne^{in\sqrt2}\}$ could be said to diverge to infinity in ""every direction"", or in a ""divergent direction"", or in a ""set of directions"". Edit : Added two geometry tags, following the comment of Moishe Cohen","In $\mathbb R$ a sequence can diverge to infinity in two directions: $+\infty$ and $-\infty$. These two cases of divergence are quite different from a sequence that diverges to ""nowhere"", like $\{(-1)^n\}$. One can be interested, for example, in the behavior of a function in one of these two directions of infinity. Is there a similar notion for sequences in the complex plane? (Or other spaces) Does it arise naturally in some field of study? What are possible uses for it? I imagine, for example, that the sequence $\{ni\}$ could be said to diverge to infinity in the direction $i$, whereas the sequence $\{ne^{in\sqrt2}\}$ could be said to diverge to infinity in ""every direction"", or in a ""divergent direction"", or in a ""set of directions"". Edit : Added two geometry tags, following the comment of Moishe Cohen",,"['complex-analysis', 'analysis', 'riemannian-geometry', 'divergence-operator', 'metric-geometry']"
30,Show that the equation $\lambda - z - e^{-z} = 0$ has exactly one solution in the half plane.,Show that the equation  has exactly one solution in the half plane.,\lambda - z - e^{-z} = 0,"I know that this question has been asked before, but I'm not satisfied with the answers provided. I will post here my complete solution to this question, but I'm not very sure about my (a) and (c) parts. Let $\lambda > 1$ and show that (a) the equation $\lambda - z - e^{-z} = 0$ has exactly one solution in the half plane $\{z: \Re(z) > 0\}$. (b) Show that this solution must be real. (c) What happens to the solution as $\lambda \to 1$? Let f(z) = $\lambda - z - e^{-z}$ (a) The equation $f(z) = 0$ has exactly one solution in the half plane $\{z: \Re(z) > 0\}$. Assume that $\exists z_0 \in G = \{z:\Re(z) > 0 \}$ such that $f(z_0) = 0$, we will show that this is the only solution in $G$. $$f(z_0) = 0 \Rightarrow \lambda - z_0 = e^{-z_0} \Rightarrow |z_0 - \lambda| = e^{-\Re(z_0)}$$ But $Re(z_0) > 0$, thus $$|z_0 - \lambda| < 1$$ Consider $h(z) = -e^{-z}, g(z) = \lambda - z$, $$|h(z) + g(z)| = | \lambda - z - e^{-z} | \leq |e^{-z}| + |\lambda - z| = |h(z)| + |g(z)|$$ Hence, by Rouche's Theorem $$Z_h + P_h = Z_g + P_g$$ But $P_h = P_g = 0$. Since $g$ has only one zero in $|z - \lambda| < 1$, $h + g = f(z)$ has only one zero also. $\square$ (b) Show that the solution is real Consider the real function $$f(x) = \lambda - x - e^{-x}$$ Then $f(0) = \lambda - 1 > 0$ and $f(\lambda) = -e^{-\lambda} < 0$, thus by the Intermediate value theorem, $$\exists z_0 \in (0,\lambda), \mbox{ such that } f(z_0) = 0.$$ But this solution is unique by part (a), hence $f$ has a unique real solution in $G$.$\square$ (c) What happen to the solution $\lambda \to 1$? $$ \begin{align*} \lim_{\lambda \to 1}f(z_0) & = \lim_{\lambda \to 1}0 \\ 1 - z_0 - e^{-z_0} & = 0 \\ z_0 + e^{-z_0} = 1 \end{align*} $$ Hence, $z_0 \to 0$ as $\lambda \to 1$. $\square$ My problem is that I can not see how we apply here the rouche theorem for make the claim about the roots of $f$ when we only consider $h$ and $g$ and not $f$. That point is not very clear to me.","I know that this question has been asked before, but I'm not satisfied with the answers provided. I will post here my complete solution to this question, but I'm not very sure about my (a) and (c) parts. Let $\lambda > 1$ and show that (a) the equation $\lambda - z - e^{-z} = 0$ has exactly one solution in the half plane $\{z: \Re(z) > 0\}$. (b) Show that this solution must be real. (c) What happens to the solution as $\lambda \to 1$? Let f(z) = $\lambda - z - e^{-z}$ (a) The equation $f(z) = 0$ has exactly one solution in the half plane $\{z: \Re(z) > 0\}$. Assume that $\exists z_0 \in G = \{z:\Re(z) > 0 \}$ such that $f(z_0) = 0$, we will show that this is the only solution in $G$. $$f(z_0) = 0 \Rightarrow \lambda - z_0 = e^{-z_0} \Rightarrow |z_0 - \lambda| = e^{-\Re(z_0)}$$ But $Re(z_0) > 0$, thus $$|z_0 - \lambda| < 1$$ Consider $h(z) = -e^{-z}, g(z) = \lambda - z$, $$|h(z) + g(z)| = | \lambda - z - e^{-z} | \leq |e^{-z}| + |\lambda - z| = |h(z)| + |g(z)|$$ Hence, by Rouche's Theorem $$Z_h + P_h = Z_g + P_g$$ But $P_h = P_g = 0$. Since $g$ has only one zero in $|z - \lambda| < 1$, $h + g = f(z)$ has only one zero also. $\square$ (b) Show that the solution is real Consider the real function $$f(x) = \lambda - x - e^{-x}$$ Then $f(0) = \lambda - 1 > 0$ and $f(\lambda) = -e^{-\lambda} < 0$, thus by the Intermediate value theorem, $$\exists z_0 \in (0,\lambda), \mbox{ such that } f(z_0) = 0.$$ But this solution is unique by part (a), hence $f$ has a unique real solution in $G$.$\square$ (c) What happen to the solution $\lambda \to 1$? $$ \begin{align*} \lim_{\lambda \to 1}f(z_0) & = \lim_{\lambda \to 1}0 \\ 1 - z_0 - e^{-z_0} & = 0 \\ z_0 + e^{-z_0} = 1 \end{align*} $$ Hence, $z_0 \to 0$ as $\lambda \to 1$. $\square$ My problem is that I can not see how we apply here the rouche theorem for make the claim about the roots of $f$ when we only consider $h$ and $g$ and not $f$. That point is not very clear to me.",,"['complex-analysis', 'proof-verification', 'proof-explanation', 'rouches-theorem']"
31,Prove: $z^{12}+3z^8+101z^4+1$ has a root on the unit circle,Prove:  has a root on the unit circle,z^{12}+3z^8+101z^4+1,$\newcommand{\cis}{\operatorname{cis}}$>Prove that $$f(z)=z^{12}+3z^8+101z^4+1$$ has a root on the unit circle or $|z|\leq 1$ So started with looking at $$z^{12}+3z^8+101z^4+1=0$$ Therefore $$z^{12}+3z^8+101z^4=-1$$ looking at $z=r\cis\theta$ we get $$r^{12}\cis(12\cdot\theta)+3r^8\cis(8\cdot \theta)+101r^4\cis(4\cdot \theta)=-1$$ And I can see that if $x=r^4\cis(4\theta)$ we get $$x^3+3x^2+101x+1=0$$ I also know that if $z$ is a solution so is  $\overline{z}$ How should I continue? Moreover: Can we say that $12$ degree polynomial as $12$ complex roots ($z$ and $\overline{z}$) but because we have $z^8$ and $z^4$ so there will be less than $12$ solutions?,$\newcommand{\cis}{\operatorname{cis}}$>Prove that $$f(z)=z^{12}+3z^8+101z^4+1$$ has a root on the unit circle or $|z|\leq 1$ So started with looking at $$z^{12}+3z^8+101z^4+1=0$$ Therefore $$z^{12}+3z^8+101z^4=-1$$ looking at $z=r\cis\theta$ we get $$r^{12}\cis(12\cdot\theta)+3r^8\cis(8\cdot \theta)+101r^4\cis(4\cdot \theta)=-1$$ And I can see that if $x=r^4\cis(4\theta)$ we get $$x^3+3x^2+101x+1=0$$ I also know that if $z$ is a solution so is  $\overline{z}$ How should I continue? Moreover: Can we say that $12$ degree polynomial as $12$ complex roots ($z$ and $\overline{z}$) but because we have $z^8$ and $z^4$ so there will be less than $12$ solutions?,,['complex-analysis']
32,Keyhole Contour with Square Root Branch Cut on Imaginary Axis,Keyhole Contour with Square Root Branch Cut on Imaginary Axis,,"Consider integrating the following function of a complex variable, $z$ , $$ f(z)=\frac{z e^{irz}}{\sqrt{z^2+m^2}}, $$ around the contour It seems straightforward to show that the infinite radius arc segments, $C_1$ and $C_2$ , vanish and we are left with $$ 0=I_1+I_2+I_3, $$ via the residue theorem.  Now, I expect that the integrals along each side of the branch cut which runs from $im$ to $i\infty$ will differ ""by a phase"" so that they will add together rather than cancel.  However, I don't see how to show this explicitly: \begin{align} I_2 & = \int^m_\infty \frac{Re^{i\pi/2}}{\sqrt{R^2e^{i\pi}+m^2}}e^{irRe^{i\pi/2}}e^{i\pi/2}dR \\     & = \int^\infty_m \frac{R}{\sqrt{-R^2+m^2}}e^{-rR}dR \\ \end{align} But \begin{align} I_3 &= \int^\infty_m \frac{Re^{i3\pi/2}}{\sqrt{R^2e^{i3\pi}+m^2}}e^{irRe^{i3\pi/2}}e^{i3\pi/2}\\ &= -\int^\infty_m \frac{R}{\sqrt{-R^2+m^2}}e^{rR}dR, \end{align} so it appears $I_2\ne I_3$ which I believe to be wrong.","Consider integrating the following function of a complex variable, , around the contour It seems straightforward to show that the infinite radius arc segments, and , vanish and we are left with via the residue theorem.  Now, I expect that the integrals along each side of the branch cut which runs from to will differ ""by a phase"" so that they will add together rather than cancel.  However, I don't see how to show this explicitly: But so it appears which I believe to be wrong.","z 
f(z)=\frac{z e^{irz}}{\sqrt{z^2+m^2}},
 C_1 C_2 
0=I_1+I_2+I_3,
 im i\infty \begin{align}
I_2 & = \int^m_\infty \frac{Re^{i\pi/2}}{\sqrt{R^2e^{i\pi}+m^2}}e^{irRe^{i\pi/2}}e^{i\pi/2}dR \\
    & = \int^\infty_m \frac{R}{\sqrt{-R^2+m^2}}e^{-rR}dR \\
\end{align} \begin{align}
I_3 &= \int^\infty_m \frac{Re^{i3\pi/2}}{\sqrt{R^2e^{i3\pi}+m^2}}e^{irRe^{i3\pi/2}}e^{i3\pi/2}\\
&= -\int^\infty_m \frac{R}{\sqrt{-R^2+m^2}}e^{rR}dR,
\end{align} I_2\ne I_3","['complex-analysis', 'mathematical-physics', 'contour-integration', 'branch-cuts', 'branch-points']"
33,Evaluate complex integral $\int_0^{\pi}\frac{1}{\ln{(e^{ix}\sin{x})}}dx$,Evaluate complex integral,\int_0^{\pi}\frac{1}{\ln{(e^{ix}\sin{x})}}dx,"I want to find the integral: $$\int_0^{\pi}\frac{1}{\ln{(e^{ix}\sin{x})}}dx$$ From $\frac{1}{\ln{(e^{ix}\sin{x})}} = \frac{\ln(\sin{x})}{x^2+\ln^2(\sin{x})}-\frac{x}{x^2+\ln^2(\sin{x})}i$, therefore  $$\int_0^{\pi}\frac{1}{\ln{(e^{ix}\sin{x})}}dx= \int_0^{\pi}\frac{\ln(\sin{x})}{x^2+\ln^2(\sin{x})}dx-i\int_0^{\pi}\frac{x}{x^2+\ln^2(\sin{x})}dx$$. But it is hard to evaluate these integral. Are there another method? Thank you.","I want to find the integral: $$\int_0^{\pi}\frac{1}{\ln{(e^{ix}\sin{x})}}dx$$ From $\frac{1}{\ln{(e^{ix}\sin{x})}} = \frac{\ln(\sin{x})}{x^2+\ln^2(\sin{x})}-\frac{x}{x^2+\ln^2(\sin{x})}i$, therefore  $$\int_0^{\pi}\frac{1}{\ln{(e^{ix}\sin{x})}}dx= \int_0^{\pi}\frac{\ln(\sin{x})}{x^2+\ln^2(\sin{x})}dx-i\int_0^{\pi}\frac{x}{x^2+\ln^2(\sin{x})}dx$$. But it is hard to evaluate these integral. Are there another method? Thank you.",,"['complex-analysis', 'complex-integration']"
34,Analytical continuation of complete elliptic integral of the first kind,Analytical continuation of complete elliptic integral of the first kind,,"I am dealing with a problem involving the complete elliptical function of the first kind, which is defined as: $K(k)=\int_0^{\pi/2} d\theta \frac{1}{\sqrt{1-k^2\sin^2(\theta)}}=\int_0^1 dt \frac{1}{\sqrt{1-t^2}\sqrt{1-k^2 t^2}} $ for $k^2<1$. I am trying to find however how to analytically continue the function for cases where $k^2>1$, and especially when $k^2$ is complex and classify it depending on $\mathrm{Im}(k^2)$ is complex or not. This looks like a very trivial question that must be written somewhere, but i couldn't find it explicitely not in several references or here in the forum. The closest solution i found has been in these notes: http://www.damtp.cam.ac.uk/user/md327/fcm_2.pdf Where they say in a last remark that the analytically continuation should be written in terms of $K(k^2) n +iK'(k')m$, where $k'$ is just the complimentary modulus  and $n,m$ integers, however, right now i don't know how to prove it, and what are the $n,m$ depending on $\mathrm{Re,Im}(k^2)$ Someone can help?","I am dealing with a problem involving the complete elliptical function of the first kind, which is defined as: $K(k)=\int_0^{\pi/2} d\theta \frac{1}{\sqrt{1-k^2\sin^2(\theta)}}=\int_0^1 dt \frac{1}{\sqrt{1-t^2}\sqrt{1-k^2 t^2}} $ for $k^2<1$. I am trying to find however how to analytically continue the function for cases where $k^2>1$, and especially when $k^2$ is complex and classify it depending on $\mathrm{Im}(k^2)$ is complex or not. This looks like a very trivial question that must be written somewhere, but i couldn't find it explicitely not in several references or here in the forum. The closest solution i found has been in these notes: http://www.damtp.cam.ac.uk/user/md327/fcm_2.pdf Where they say in a last remark that the analytically continuation should be written in terms of $K(k^2) n +iK'(k')m$, where $k'$ is just the complimentary modulus  and $n,m$ integers, however, right now i don't know how to prove it, and what are the $n,m$ depending on $\mathrm{Re,Im}(k^2)$ Someone can help?",,"['complex-analysis', 'elliptic-integrals', 'analytic-continuation']"
35,Prove that $\int_1^{\infty}\frac{dx}{x\sqrt{x^2-1}}=\frac{\pi}{2}$ using complex analysis,Prove that  using complex analysis,\int_1^{\infty}\frac{dx}{x\sqrt{x^2-1}}=\frac{\pi}{2},"I'm trying to show that $\int_1^{\infty}\frac{dx}{x\sqrt{x^2-1}}=\frac{\pi}{2}$ by letting $f(z)=\frac{1}{z\sqrt{z^2-1}}=\frac{1}{z}e^{-\log(z^2-1)^{\frac{1}{2}}}$. and I need to show that, on the 4 straight lines, $$L_1^+=\{z|z:R+\epsilon i \rightarrow \rho+1+\epsilon i\}, L_1^-=\{z|z:\rho+1-\epsilon i \rightarrow R-\epsilon i\}, $$$$L_2^+=\{z|z:-\rho-1+\epsilon i \rightarrow -R+\epsilon i\}, L_2^-=\{z|z:-R+\epsilon i \rightarrow -\rho-1+\epsilon i\}$$, which are the parts of a simple closed contour which is surrounding the simple pole $z=0$ of $f$ and excluding $\{x\in R | x$ is less than or equal to $-1$ or $x$ is greater than or equal to $1 \}$, $$\lim_{\rho\rightarrow 0,R\rightarrow \infty, \epsilon\rightarrow 0 }\int_{L_{1,2}^{+,-}}f(z)dz=-\frac{\pi}{2}.$$ it is negative since I chose the contour negatively oriented at the first. I was able to show that the other parts go to $0$, but somehow those four line integrals cancel out each other and make me crazy. specifically, I got the following results: $L_1^+ \rightarrow -\frac{\pi}{2}$ $L_1^- \rightarrow \frac{\pi}{2}$ $L_2^+ \rightarrow \frac{\pi}{2}$ $L_2^- \rightarrow -\frac{\pi}{2}$ I think the problem is to choose new branch cut when I make $\epsilon$ go to $0$. if $z=\sigma e^{i \phi}$ and $(z^2-1)^\frac{1}{2}=r e^{i\theta}$, then $2\theta=Arg(\sigma^2 e^{2i \phi}-1)$, so $\theta$ behaves similarly with $\phi$, and from here the above results come out and I don't know where I did wrong. I know the other methods like letting $u=\sqrt{x^2-1}$, but I just want to do it this way to get used to it. any helps or hints? thanks in advance.","I'm trying to show that $\int_1^{\infty}\frac{dx}{x\sqrt{x^2-1}}=\frac{\pi}{2}$ by letting $f(z)=\frac{1}{z\sqrt{z^2-1}}=\frac{1}{z}e^{-\log(z^2-1)^{\frac{1}{2}}}$. and I need to show that, on the 4 straight lines, $$L_1^+=\{z|z:R+\epsilon i \rightarrow \rho+1+\epsilon i\}, L_1^-=\{z|z:\rho+1-\epsilon i \rightarrow R-\epsilon i\}, $$$$L_2^+=\{z|z:-\rho-1+\epsilon i \rightarrow -R+\epsilon i\}, L_2^-=\{z|z:-R+\epsilon i \rightarrow -\rho-1+\epsilon i\}$$, which are the parts of a simple closed contour which is surrounding the simple pole $z=0$ of $f$ and excluding $\{x\in R | x$ is less than or equal to $-1$ or $x$ is greater than or equal to $1 \}$, $$\lim_{\rho\rightarrow 0,R\rightarrow \infty, \epsilon\rightarrow 0 }\int_{L_{1,2}^{+,-}}f(z)dz=-\frac{\pi}{2}.$$ it is negative since I chose the contour negatively oriented at the first. I was able to show that the other parts go to $0$, but somehow those four line integrals cancel out each other and make me crazy. specifically, I got the following results: $L_1^+ \rightarrow -\frac{\pi}{2}$ $L_1^- \rightarrow \frac{\pi}{2}$ $L_2^+ \rightarrow \frac{\pi}{2}$ $L_2^- \rightarrow -\frac{\pi}{2}$ I think the problem is to choose new branch cut when I make $\epsilon$ go to $0$. if $z=\sigma e^{i \phi}$ and $(z^2-1)^\frac{1}{2}=r e^{i\theta}$, then $2\theta=Arg(\sigma^2 e^{2i \phi}-1)$, so $\theta$ behaves similarly with $\phi$, and from here the above results come out and I don't know where I did wrong. I know the other methods like letting $u=\sqrt{x^2-1}$, but I just want to do it this way to get used to it. any helps or hints? thanks in advance.",,"['complex-analysis', 'improper-integrals']"
36,Complex Analysis: Zeros of an analytic function,Complex Analysis: Zeros of an analytic function,,"What approach should I take to solve the attached problem. I was looking along the lines of 'Great Picard Theorem', which states that 'If an analytic function f has an essential singularity at a point w, then on any punctured neighborhood of w, f(z) takes on all possible complex values, with at most a single exception, infinitely often.' Any help is much appreciated.","What approach should I take to solve the attached problem. I was looking along the lines of 'Great Picard Theorem', which states that 'If an analytic function f has an essential singularity at a point w, then on any punctured neighborhood of w, f(z) takes on all possible complex values, with at most a single exception, infinitely often.' Any help is much appreciated.",,[]
37,Is a map that preserves the hyperbolic distance biholomorphic?,Is a map that preserves the hyperbolic distance biholomorphic?,,"Let $\lVert z \rVert_w = \frac{|z|}{1 - |w|^2}$  be the hyperbolic distance in $\mathbb{D}$, and let the hyperbolic metric be $d(z, w) = \inf_\gamma \int_0^1 \lVert \gamma'(t) \rVert_{\gamma(t)} \, dt$. Automorphisms of $\mathbb{D}$ preserve this metric. I'm looking to prove the converse, that is, if $f \colon \mathbb{D} \to \mathbb{D}$ preserves $d$ then it is a biholomorphism from $\mathbb{D}$ to itself, or $\overline{f}$ is. If $f$ is assumed $C^1$ it is mostly not so hard - you can get that at every point either $f$ is holomorphic or its conjugate is by considering $\psi_{f(0)} \circ f$, which preserves the origin and must also preserve the ordinary absolute value, hence is isotropic hence either $f$ or $\overline{f}$ is holomorphic at the origin, and since $f$ was arbitrary this is true of all points. (And hopefully this gives that one of them is globally holomorphic! But I haven't figured out that part yet.) If nothing is assumed of $f$, is the result even true? I see why $f$ must be continuous, but does preservation of the hyperbolic metric imply $C^1$-ness?","Let $\lVert z \rVert_w = \frac{|z|}{1 - |w|^2}$  be the hyperbolic distance in $\mathbb{D}$, and let the hyperbolic metric be $d(z, w) = \inf_\gamma \int_0^1 \lVert \gamma'(t) \rVert_{\gamma(t)} \, dt$. Automorphisms of $\mathbb{D}$ preserve this metric. I'm looking to prove the converse, that is, if $f \colon \mathbb{D} \to \mathbb{D}$ preserves $d$ then it is a biholomorphism from $\mathbb{D}$ to itself, or $\overline{f}$ is. If $f$ is assumed $C^1$ it is mostly not so hard - you can get that at every point either $f$ is holomorphic or its conjugate is by considering $\psi_{f(0)} \circ f$, which preserves the origin and must also preserve the ordinary absolute value, hence is isotropic hence either $f$ or $\overline{f}$ is holomorphic at the origin, and since $f$ was arbitrary this is true of all points. (And hopefully this gives that one of them is globally holomorphic! But I haven't figured out that part yet.) If nothing is assumed of $f$, is the result even true? I see why $f$ must be continuous, but does preservation of the hyperbolic metric imply $C^1$-ness?",,"['complex-analysis', 'hyperbolic-geometry', 'conformal-geometry']"
38,Integration of $\ln $ around a keyhole contour,Integration of  around a keyhole contour,\ln ,"I want to evaluate the following integral: $$\int_{0}^{\infty}\frac{\ln^2 x}{x^2-x+1}{\rm d}x$$ I use the following contour in order to integrate. I considered the function $\displaystyle f(z)=\frac{\ln^3 z}{z^2-z+1}$. The poles of the function are $\displaystyle z_1=\frac{1+i\sqrt{3}}{2}, \; z_2=\frac{1-i\sqrt{3}}{2}$ and these are simple poles. I evaluated the residues $\displaystyle \mathfrak{Res}(z_1)=\mathfrak{Res}(z_2)=-\frac{i\pi^2}{9\sqrt{3}}$. If we declare $\gamma$ the entire contour , we have that: $$\oint_{\gamma}f(z)\,dz=2\pi i \sum res=2\pi i \left ( -\frac{2i\pi^2}{9\sqrt{3}} \right )=\frac{4\pi^3}{9\sqrt{3}}$$ I splitted the contour apart and I got: $$\oint_{\gamma}f(z)\,dz=\int_{C_r}+\int_{S_1}+\int_{C_\epsilon }+\int_{S_2}$$ where $S_1$ is the segment from $R$ to $\epsilon$ and $S_2$ is the segment from $\epsilon$ to $R$. I proved that the other two line integrals vanish when $R\rightarrow +\infty, \epsilon \rightarrow 0$ respectively. And this is where I get stuck. Well, letting $R \rightarrow +\infty$ this gives me that: $$\int_{\gamma}f(z)\,dz=\int_{\infty}^{0}f(z)\,dz+\int_{0}^{\infty}f(z)\,dz=\int_{0}^{\infty}-\int_{0}^{\infty}$$ I set $z=-x-i\epsilon$ at the second one and at the first one $z=-x+i\epsilon$ but I cannot seem to finish up the problem and get the correct result.","I want to evaluate the following integral: $$\int_{0}^{\infty}\frac{\ln^2 x}{x^2-x+1}{\rm d}x$$ I use the following contour in order to integrate. I considered the function $\displaystyle f(z)=\frac{\ln^3 z}{z^2-z+1}$. The poles of the function are $\displaystyle z_1=\frac{1+i\sqrt{3}}{2}, \; z_2=\frac{1-i\sqrt{3}}{2}$ and these are simple poles. I evaluated the residues $\displaystyle \mathfrak{Res}(z_1)=\mathfrak{Res}(z_2)=-\frac{i\pi^2}{9\sqrt{3}}$. If we declare $\gamma$ the entire contour , we have that: $$\oint_{\gamma}f(z)\,dz=2\pi i \sum res=2\pi i \left ( -\frac{2i\pi^2}{9\sqrt{3}} \right )=\frac{4\pi^3}{9\sqrt{3}}$$ I splitted the contour apart and I got: $$\oint_{\gamma}f(z)\,dz=\int_{C_r}+\int_{S_1}+\int_{C_\epsilon }+\int_{S_2}$$ where $S_1$ is the segment from $R$ to $\epsilon$ and $S_2$ is the segment from $\epsilon$ to $R$. I proved that the other two line integrals vanish when $R\rightarrow +\infty, \epsilon \rightarrow 0$ respectively. And this is where I get stuck. Well, letting $R \rightarrow +\infty$ this gives me that: $$\int_{\gamma}f(z)\,dz=\int_{\infty}^{0}f(z)\,dz+\int_{0}^{\infty}f(z)\,dz=\int_{0}^{\infty}-\int_{0}^{\infty}$$ I set $z=-x-i\epsilon$ at the second one and at the first one $z=-x+i\epsilon$ but I cannot seem to finish up the problem and get the correct result.",,"['complex-analysis', 'analysis', 'contour-integration']"
39,Showing an open connected subset of $\mathbb{R}^n$ is path-connected,Showing an open connected subset of  is path-connected,\mathbb{R}^n,In the above proof the following equivalence is used at the last step: A space $M$ is connected if and only if the only open and closed subsets of $M$ are $\emptyset$ and $M$ (ie. there are no proper open and closed subsets). However I do not understand the claim that $X$ is the completment of the open union and feel like it is non-trivial. Can someone please elaborate?,In the above proof the following equivalence is used at the last step: A space $M$ is connected if and only if the only open and closed subsets of $M$ are $\emptyset$ and $M$ (ie. there are no proper open and closed subsets). However I do not understand the claim that $X$ is the completment of the open union and feel like it is non-trivial. Can someone please elaborate?,,['complex-analysis']
40,Transformation of contour integral $\int \frac{z^2}{e^{2\pi i z^3}-1} \operatorname dz$ over the circle $|z|=\sqrt[3]{n+\frac{1}{2}}$,Transformation of contour integral  over the circle,\int \frac{z^2}{e^{2\pi i z^3}-1} \operatorname dz |z|=\sqrt[3]{n+\frac{1}{2}},"I would like to solve the following: $$\int\limits_{|z|=\sqrt[3]{n+\frac{1}{2}}} \frac{z^2}{e^{2\pi i z^3}-1}\operatorname dz$$ I'm given an hint: ""use a transformation $w=z^3$"" I would make use of the following theorem: If $w$ holomorphic on $\Gamma$ and $f$ continous on $w(\Gamma)$ then    $$\int\limits_{w(\Gamma)} f(w) \operatorname dw = \int\limits_\Gamma f(w(z)) w'(z) \operatorname dz$$ But I'm a bit confused as to the contour itself. Is the following right? ($\Gamma_1$ is the circle with radius $\sqrt[3]{n+\frac{1}{2}}$ and center $O$, while $\Gamma_2$ had a radius of $n+\frac{1}{2}$) $$\begin{align} \int_{\Gamma_1} \frac{z^2}{e^{2\pi i z^3}-1}\operatorname dz &= \int_{\Gamma_2} \frac{w^{\frac{2}{3}}}{e^{2\pi i w}-1} \cdot \frac{1}{3}\cdot w^{-\frac{2}{3}}\operatorname dw\\ &=  \frac{1}{3} \int_{\Gamma_2} \frac{\operatorname dw}{e^{2\pi i w}-1}\\ \end{align}$$ Using the residue theorem ($\operatorname*{res}_{w=k} f(w) = \frac{-i}{2\pi}$) $$\int_{\Gamma_1} \frac{z^2}{e^{2\pi i z^3}-1}\operatorname dz = 1$$ Question This looks to good to be true ;) Could someone verify? Have I applied the theorem right?","I would like to solve the following: $$\int\limits_{|z|=\sqrt[3]{n+\frac{1}{2}}} \frac{z^2}{e^{2\pi i z^3}-1}\operatorname dz$$ I'm given an hint: ""use a transformation $w=z^3$"" I would make use of the following theorem: If $w$ holomorphic on $\Gamma$ and $f$ continous on $w(\Gamma)$ then    $$\int\limits_{w(\Gamma)} f(w) \operatorname dw = \int\limits_\Gamma f(w(z)) w'(z) \operatorname dz$$ But I'm a bit confused as to the contour itself. Is the following right? ($\Gamma_1$ is the circle with radius $\sqrt[3]{n+\frac{1}{2}}$ and center $O$, while $\Gamma_2$ had a radius of $n+\frac{1}{2}$) $$\begin{align} \int_{\Gamma_1} \frac{z^2}{e^{2\pi i z^3}-1}\operatorname dz &= \int_{\Gamma_2} \frac{w^{\frac{2}{3}}}{e^{2\pi i w}-1} \cdot \frac{1}{3}\cdot w^{-\frac{2}{3}}\operatorname dw\\ &=  \frac{1}{3} \int_{\Gamma_2} \frac{\operatorname dw}{e^{2\pi i w}-1}\\ \end{align}$$ Using the residue theorem ($\operatorname*{res}_{w=k} f(w) = \frac{-i}{2\pi}$) $$\int_{\Gamma_1} \frac{z^2}{e^{2\pi i z^3}-1}\operatorname dz = 1$$ Question This looks to good to be true ;) Could someone verify? Have I applied the theorem right?",,"['complex-analysis', 'contour-integration', 'solution-verification']"
41,$L^{\infty}$ norm is bounded by $L^2$ norm for holomorphic functions,norm is bounded by  norm for holomorphic functions,L^{\infty} L^2,"I want to prove that, given $f$ holomorphic in a disc $D_r(z)$ and $0<s<r$, we have $$\sup_{D_s(z)}|f| \leq \|f\|_{L^2(D_r(z))}$$ where the $L^2$ norm is defined on an open set $U \subset \mathbb{C}$ as $$\|f\|_{L^2(U)} = \Bigl(\int_U |f(z)|^2\,\mathrm dx\,\mathrm dy\Bigr)^{1/2}$$ I know I should use the mean value principle somehow, but I'm not sure how we can pull out the $L^2$ norm from it.  I can see that by the max modulus principle, we have that $$\sup_{D_s(z)} |f| \leq \sup_{C_s(z)}|f| \leq \sup_{C_r(z)}|f|$$ where $C_k(z)$ is the circle of radius $k$ centered on $z$. After a while of trying to figure out how to apply the mean value principle, I tried working backwards from the $L^2$ norm via polar coordinates to get $$\frac{r}{\sqrt 2} \Bigl(\int_{0}^{2\pi} |f(z+r\mathrm e^{\mathrm i\theta})|\,\mathrm d\theta\Bigr)^{1/2}.$$ Can we say that the integral is the mean value principle applied to $|f^2|$? I wanted to use max modulus and the fact that $D_s(z_0) \subset D_r(z_0)$ to conclude $\sup_{D_s}|f| \leq |f(z)|_{z \in D_r}$, but this inequality may not be true - it only applies if we consider $z \in D_r \setminus D_s$, correct? I'd appreciate it if anyone could lead me into the right direction with this. It seems like the related questions on here have answers beyond the scope of this course.","I want to prove that, given $f$ holomorphic in a disc $D_r(z)$ and $0<s<r$, we have $$\sup_{D_s(z)}|f| \leq \|f\|_{L^2(D_r(z))}$$ where the $L^2$ norm is defined on an open set $U \subset \mathbb{C}$ as $$\|f\|_{L^2(U)} = \Bigl(\int_U |f(z)|^2\,\mathrm dx\,\mathrm dy\Bigr)^{1/2}$$ I know I should use the mean value principle somehow, but I'm not sure how we can pull out the $L^2$ norm from it.  I can see that by the max modulus principle, we have that $$\sup_{D_s(z)} |f| \leq \sup_{C_s(z)}|f| \leq \sup_{C_r(z)}|f|$$ where $C_k(z)$ is the circle of radius $k$ centered on $z$. After a while of trying to figure out how to apply the mean value principle, I tried working backwards from the $L^2$ norm via polar coordinates to get $$\frac{r}{\sqrt 2} \Bigl(\int_{0}^{2\pi} |f(z+r\mathrm e^{\mathrm i\theta})|\,\mathrm d\theta\Bigr)^{1/2}.$$ Can we say that the integral is the mean value principle applied to $|f^2|$? I wanted to use max modulus and the fact that $D_s(z_0) \subset D_r(z_0)$ to conclude $\sup_{D_s}|f| \leq |f(z)|_{z \in D_r}$, but this inequality may not be true - it only applies if we consider $z \in D_r \setminus D_s$, correct? I'd appreciate it if anyone could lead me into the right direction with this. It seems like the related questions on here have answers beyond the scope of this course.",,['complex-analysis']
42,Proving that $\{ f_a \}_{a \in A}$ satisfying $\int \limits_{0}^{2\pi} |f_a(e^{i \phi})|^{1/2} d\phi \leq 1$ is a normal family in $\mathbb{D}$,Proving that  satisfying  is a normal family in,\{ f_a \}_{a \in A} \int \limits_{0}^{2\pi} |f_a(e^{i \phi})|^{1/2} d\phi \leq 1 \mathbb{D},"This is another problem from a complex analysis qualifying exam from last year for the preparation course that I'm teaching right now. The question is the following. Let $F = \{ f_a \}_{a \in A}$ be a family of holomorphic functions on a neighborhood of the closed unit disk $\overline{\mathbb{D}} = \{ z \in \mathbb{C}  \mid |z| \leq 1 \}$. Suppose also that $$ \int \limits_{0}^{2\pi} |f_a(e^{i \phi})|^{1/2} d\phi \leq 1 $$ for every $a \in A$. Prove that $F = \{ f_a \}_{a \in A}$ is a normal family in the unit disk $\mathbb{D} = \{ z \in \mathbb{C}  \mid |z| < 1 \}$. My Attempt My idea is to use Montel's theorem , so I want to show that the family $F$ is uniformly bounded on compact subsets of $\mathbb{D}$. Thus letting $K \subset \mathbb{D}$ be compact, then there's a positive constant $0 < M_K < 1$, such that for every $\xi \in K$ we have $|\xi| \leq M_K$. Then using Cauchy's integral formula we obtain, for any $a \in A$ and $\xi \in K$ \begin{align} f_a(\xi) = \frac{1}{2\pi i} \int \limits_{\partial \mathbb{D}} \frac{f_a(z)}{z - \xi} \, dz = \frac{1}{2\pi i} \int \limits_{0}^{2\pi} \frac{f_a(e^{i \phi})}{e^{i\phi} - \xi} \cdot ie^{i\phi} \, d\phi \end{align} Then taking absolute values we get \begin{align} |f_a(\xi)| &\leq \frac{1}{2\pi} \int \limits_{0}^{2\pi} \frac{|f_a(e^{i \phi})|}{|e^{i\phi} - \xi|} \cdot |ie^{i\phi}| \, d\phi \\ &\leq  \frac{1}{2\pi} \int \limits_{0}^{2\pi} \frac{|f_a(e^{i \phi})|}{ 1 - |\xi|}  \, d\phi\\ &\leq \frac{1}{2\pi(1 - M_K)}  \int \limits_{0}^{2\pi} |f_a(e^{i \phi})| \, d\phi\\ &= C_K \int \limits_{0}^{2\pi} |f_a(e^{i \phi})| \, d\phi \end{align} where we put $C_K := \dfrac{1}{2\pi(1 - M_K)}$, and the reverse triangle inequality was used to bound $\dfrac{1}{|e^{i\phi} - \xi|} \leq \dfrac{1}{1 - |\xi|}$. The constant $C_K$ is independent of $a$ and $\xi$. Hence if I can somehow use the hypothesis that $\int \limits_{0}^{2\pi} |f_a(e^{i \phi})|^{1/2} \, d\phi \leq 1$ to bound the last integral then the problem would be solved because Montel's theorem would apply. But unfortunately I am stuck at this point. Question How can I finish the argument? (assuming that what I did is the right way to proceed) Thanks a lot for any help.","This is another problem from a complex analysis qualifying exam from last year for the preparation course that I'm teaching right now. The question is the following. Let $F = \{ f_a \}_{a \in A}$ be a family of holomorphic functions on a neighborhood of the closed unit disk $\overline{\mathbb{D}} = \{ z \in \mathbb{C}  \mid |z| \leq 1 \}$. Suppose also that $$ \int \limits_{0}^{2\pi} |f_a(e^{i \phi})|^{1/2} d\phi \leq 1 $$ for every $a \in A$. Prove that $F = \{ f_a \}_{a \in A}$ is a normal family in the unit disk $\mathbb{D} = \{ z \in \mathbb{C}  \mid |z| < 1 \}$. My Attempt My idea is to use Montel's theorem , so I want to show that the family $F$ is uniformly bounded on compact subsets of $\mathbb{D}$. Thus letting $K \subset \mathbb{D}$ be compact, then there's a positive constant $0 < M_K < 1$, such that for every $\xi \in K$ we have $|\xi| \leq M_K$. Then using Cauchy's integral formula we obtain, for any $a \in A$ and $\xi \in K$ \begin{align} f_a(\xi) = \frac{1}{2\pi i} \int \limits_{\partial \mathbb{D}} \frac{f_a(z)}{z - \xi} \, dz = \frac{1}{2\pi i} \int \limits_{0}^{2\pi} \frac{f_a(e^{i \phi})}{e^{i\phi} - \xi} \cdot ie^{i\phi} \, d\phi \end{align} Then taking absolute values we get \begin{align} |f_a(\xi)| &\leq \frac{1}{2\pi} \int \limits_{0}^{2\pi} \frac{|f_a(e^{i \phi})|}{|e^{i\phi} - \xi|} \cdot |ie^{i\phi}| \, d\phi \\ &\leq  \frac{1}{2\pi} \int \limits_{0}^{2\pi} \frac{|f_a(e^{i \phi})|}{ 1 - |\xi|}  \, d\phi\\ &\leq \frac{1}{2\pi(1 - M_K)}  \int \limits_{0}^{2\pi} |f_a(e^{i \phi})| \, d\phi\\ &= C_K \int \limits_{0}^{2\pi} |f_a(e^{i \phi})| \, d\phi \end{align} where we put $C_K := \dfrac{1}{2\pi(1 - M_K)}$, and the reverse triangle inequality was used to bound $\dfrac{1}{|e^{i\phi} - \xi|} \leq \dfrac{1}{1 - |\xi|}$. The constant $C_K$ is independent of $a$ and $\xi$. Hence if I can somehow use the hypothesis that $\int \limits_{0}^{2\pi} |f_a(e^{i \phi})|^{1/2} \, d\phi \leq 1$ to bound the last integral then the problem would be solved because Montel's theorem would apply. But unfortunately I am stuck at this point. Question How can I finish the argument? (assuming that what I did is the right way to proceed) Thanks a lot for any help.",,"['complex-analysis', 'analysis']"
43,Having trouble understand the proof of Rouché's Theorem,Having trouble understand the proof of Rouché's Theorem,,"I am trying to understand this proof of Rouché's theorem, but I am missing the logic of the last and most crucial step. Here are the assumptions: Suppose that $ f $ and $ g $ are analytic inside and on a regular   closed curve $ \gamma $ and that $ |f(z)| \gt |g(z)| $ for all $ z > \in \gamma $. Then $$ \mathcal{Z}(f + g) = \mathcal{Z}(f) \text{ inside > } \gamma $$ The proof goes as follows: First note that $ f \neq 0$ on $ \gamma $ since otherwise $ |g| \lt 0 $ which doesn't make any sense. So, we can write the following: $$ \mathcal{Z}(f + g) = \frac{1}{2\pi i} \int_{\gamma}\frac{(f+g)'}{(f+g)} = \frac{1}{2\pi i} \int_{\gamma} \frac{(f(1 + \frac{g}{f}))'}{f(1 + \frac{g}{f})} = \frac{1}{2\pi i} \int_{\gamma} \frac{f'}{f} + \frac{1}{2\pi i} \int_{\gamma} \frac{(1 + \frac{g}{f})'}{(1 + \frac{g}{f})} $$ We know $ f $ is analytic, so $ \frac{1}{2\pi i} \int_{\gamma} \frac{f'}{f}  = \mathcal{Z}(f) $ by the argument principle. What I don't know is, why is $ \frac{1}{2\pi i} \int_{\gamma} \frac{(1 + \frac{g}{f})'}{(1 + \frac{g}{f})} = 0$?","I am trying to understand this proof of Rouché's theorem, but I am missing the logic of the last and most crucial step. Here are the assumptions: Suppose that $ f $ and $ g $ are analytic inside and on a regular   closed curve $ \gamma $ and that $ |f(z)| \gt |g(z)| $ for all $ z > \in \gamma $. Then $$ \mathcal{Z}(f + g) = \mathcal{Z}(f) \text{ inside > } \gamma $$ The proof goes as follows: First note that $ f \neq 0$ on $ \gamma $ since otherwise $ |g| \lt 0 $ which doesn't make any sense. So, we can write the following: $$ \mathcal{Z}(f + g) = \frac{1}{2\pi i} \int_{\gamma}\frac{(f+g)'}{(f+g)} = \frac{1}{2\pi i} \int_{\gamma} \frac{(f(1 + \frac{g}{f}))'}{f(1 + \frac{g}{f})} = \frac{1}{2\pi i} \int_{\gamma} \frac{f'}{f} + \frac{1}{2\pi i} \int_{\gamma} \frac{(1 + \frac{g}{f})'}{(1 + \frac{g}{f})} $$ We know $ f $ is analytic, so $ \frac{1}{2\pi i} \int_{\gamma} \frac{f'}{f}  = \mathcal{Z}(f) $ by the argument principle. What I don't know is, why is $ \frac{1}{2\pi i} \int_{\gamma} \frac{(1 + \frac{g}{f})'}{(1 + \frac{g}{f})} = 0$?",,['complex-analysis']
44,How to prove this identity for ${}_3F_2$ (Generalized Hypergeometric Function)?,How to prove this identity for  (Generalized Hypergeometric Function)?,{}_3F_2,"This may look like homework, but it is not. I've found this identity (using Mathematica): $$ {}_3F_2 \left( \matrix{1,1,1 \\ 2, e} ; 1 \right) = (e-1) \psi^{\prime}(e-1), $$ valid for $e$ with $\mathcal{R}(e)>0$, where ${}_3F_2$ is the Generalized Hypergeometric Function (as in here ) and $\psi^{\prime}$ is the trigamma function (definition here ). It's also in Wolfram's site: http://functions.wolfram.com/07.27.03.0083.01 The problem is... I've no idea how to prove it. I've tried using the definition of the Pochhammer symbol and some simplifications to get this: $$ {}_3F_2 \left( \matrix{1,1,1 \\ 2, e} ; 1 \right) = \sum_{k=0}^{\infty} \frac{\Gamma(k+1)\Gamma(e)}{(k+1)\Gamma(e+k)}, $$ but it's not even close to the series for trigamma function: $$ (e-1) \psi^{\prime}(e-1) = (e-1) \sum_{n=0}^{\infty} \frac{1}{(e-1+n)^2}. $$ Any help/tips/references are appreciated.","This may look like homework, but it is not. I've found this identity (using Mathematica): $$ {}_3F_2 \left( \matrix{1,1,1 \\ 2, e} ; 1 \right) = (e-1) \psi^{\prime}(e-1), $$ valid for $e$ with $\mathcal{R}(e)>0$, where ${}_3F_2$ is the Generalized Hypergeometric Function (as in here ) and $\psi^{\prime}$ is the trigamma function (definition here ). It's also in Wolfram's site: http://functions.wolfram.com/07.27.03.0083.01 The problem is... I've no idea how to prove it. I've tried using the definition of the Pochhammer symbol and some simplifications to get this: $$ {}_3F_2 \left( \matrix{1,1,1 \\ 2, e} ; 1 \right) = \sum_{k=0}^{\infty} \frac{\Gamma(k+1)\Gamma(e)}{(k+1)\Gamma(e+k)}, $$ but it's not even close to the series for trigamma function: $$ (e-1) \psi^{\prime}(e-1) = (e-1) \sum_{n=0}^{\infty} \frac{1}{(e-1+n)^2}. $$ Any help/tips/references are appreciated.",,"['complex-analysis', 'special-functions', 'hypergeometric-function']"
45,Analytically continue a function with Euler product,Analytically continue a function with Euler product,,"I would like to estimate the main term of the integral $$\frac{1}{2\pi i} \int_{(c)} L(s) \frac{x^s}{s} ds$$ where $c > 0$, $\displaystyle L(s) = \prod_p \left(1 + \frac{2}{p(p^s-1)}\right)$. Question: How to estimate the integral? In other words, is there any way to analytic continue this function? The function as stated converges for $\Re s > 0$, but I'm not sure how to extend it past $y$-axis. Thanks!","I would like to estimate the main term of the integral $$\frac{1}{2\pi i} \int_{(c)} L(s) \frac{x^s}{s} ds$$ where $c > 0$, $\displaystyle L(s) = \prod_p \left(1 + \frac{2}{p(p^s-1)}\right)$. Question: How to estimate the integral? In other words, is there any way to analytic continue this function? The function as stated converges for $\Re s > 0$, but I'm not sure how to extend it past $y$-axis. Thanks!",,['complex-analysis']
46,"$f$ continuous, $f^N$ analytic on a domain D implies $f$ analytic on D","continuous,  analytic on a domain D implies  analytic on D",f f^N f,"Working on a problem in Gamelin's book. ""Show that if $f(z)$ is a continuous function on a domain $D$ such that $f(z)^N$ is analytic on $D$ for some integer $N$, then $f(z)$ is analytic on $D$."" He starts a hint with the statement ""Show that the zeros of $f(z)$ are isolated."" This makes me think. I know that if $f$ is analytic and nonconstant, then the zeros are isolated. Is there some sort of converse to this theorem? I.e., for example, if continuous and zeros are isolated then analytic? His next hint is: ""At a zero of $f(z)$, write $f(z)^N=(z-z_0)^mh(z)$ where $h(z_0)\ne 0$ and show that $N$ divides $m$."" However, the book has covered nothing on winding numbers thus far. Also, how will the fact that $N$ divides $m$ help to show that $f(z)$ is analytic?","Working on a problem in Gamelin's book. ""Show that if $f(z)$ is a continuous function on a domain $D$ such that $f(z)^N$ is analytic on $D$ for some integer $N$, then $f(z)$ is analytic on $D$."" He starts a hint with the statement ""Show that the zeros of $f(z)$ are isolated."" This makes me think. I know that if $f$ is analytic and nonconstant, then the zeros are isolated. Is there some sort of converse to this theorem? I.e., for example, if continuous and zeros are isolated then analytic? His next hint is: ""At a zero of $f(z)$, write $f(z)^N=(z-z_0)^mh(z)$ where $h(z_0)\ne 0$ and show that $N$ divides $m$."" However, the book has covered nothing on winding numbers thus far. Also, how will the fact that $N$ divides $m$ help to show that $f(z)$ is analytic?",,['complex-analysis']
47,Proof using Cauchy–Schwarz Inequality.,Proof using Cauchy–Schwarz Inequality.,,"This is a problem I am trying to solve for a couple of months without any success. I found it in a paper and according to the authors can be proved using Cauchy–Schwarz inequality. Let $f(x)$ be a polynomial in $\mathbb{C}[x]$. Denote by $L(f)$ the length of the polynomial and by $||.||_\infty$ the sup norm on $\{|z|\leq 1\}$. So for $f(x)=a_0+a_1x+\ldots +a_nx^n , L(f)=|a_0|+|a_1|+\ldots+|a_n|$ and $||f||_\infty=\sup{\{|f(z)|:|z|\leq 1\}}.$ The problem is: If $f(x)\in \mathbb{C}[x]$ is a polynomial of degree $n$ then $$L(f)\leq \sqrt{1+n} ||f||_\infty.$$","This is a problem I am trying to solve for a couple of months without any success. I found it in a paper and according to the authors can be proved using Cauchy–Schwarz inequality. Let $f(x)$ be a polynomial in $\mathbb{C}[x]$. Denote by $L(f)$ the length of the polynomial and by $||.||_\infty$ the sup norm on $\{|z|\leq 1\}$. So for $f(x)=a_0+a_1x+\ldots +a_nx^n , L(f)=|a_0|+|a_1|+\ldots+|a_n|$ and $||f||_\infty=\sup{\{|f(z)|:|z|\leq 1\}}.$ The problem is: If $f(x)\in \mathbb{C}[x]$ is a polynomial of degree $n$ then $$L(f)\leq \sqrt{1+n} ||f||_\infty.$$",,"['complex-analysis', 'inequality']"
48,Prove that $\frac{1}{\sin^2 z } = \sum\limits_{n= -\infty} ^ {+\infty} \frac{1}{(z-\pi n)^2} $,Prove that,\frac{1}{\sin^2 z } = \sum\limits_{n= -\infty} ^ {+\infty} \frac{1}{(z-\pi n)^2} ,"I have the following problem: Find the constants $c_n$ so that  $$ \frac{1}{\sin^2 z } = \sum_{n= -\infty} ^ {+\infty} \frac{c_n}{(z-\pi n)^2} $$ and the series converges uniformly on every bounded set after dropping finitely many terms. Justify all your claims. Hint: Use Liouville's theorem to prove the equality. Let $c_n = 1 $ for all $n$. Let $\displaystyle f(z) := \frac{1}{\sin^2 z}$ and $\displaystyle g(z) := \sum_{n= -\infty} ^ {+\infty} \frac{1}{(z-\pi n)^2} $. Begin by showing that $h$ is an analytic function which converges uniformly on compact subsets of $\mathbb{C} \backslash \mathbb{Z}$. Suppose $K$ is a compact set which contains no integers. Define  $$ \delta_n = \inf_{z \in K} |\pi-z/n| =\frac{1}{n} \inf_{z \in K} |\pi n-z|, $$ where the infimum exists because $K$ is compact. Also, compactness implies boundedness. Thus as $n \to \pm \infty$, we have $\delta_n \to \pi$. Therefore, for sufficiently large $n$, we have $\delta_n > 2$, and  $$ \frac{1}{|z \pm n | ^2} \leq \frac{1}{\delta_n ^2 n^2} < \frac{1}{4n^2}. $$ By the Weierstrass M-test, $g$ converges absolutely uniformly on $K$. Since each term is analytic on $K$, we conclude that the series converges to an analytic function on $\mathbb{C} \backslash \mathbb{Z}$. Clearly the only poles of $g(z)$ are at $\pi n$ for each integer $n$, with corresponding principal part $\frac{1}{(z-\pi n)^2}$. For each integer $n$, we have $\sin^2 (\pi n) = \frac{d}{dz} \sin^2(\pi n) = 0$ and $\frac{d^2}{dz^z} \sin^2 (\pi n) \neq 0$, so $f(z) = 1/ \sin^2 (z)$ also has a pole of order two at each integer multiple of $\pi$, and no other poles. Furthermore, the principal part of $f(z)$ is, using the Laurent formulas and contour integration, equal to $\displaystyle \frac{1}{(z-n\pi)^2}$. Thus $h(z) := f(z)-g(z)$ has removable singularities at the points $n\pi$. Note that both $f$ and $g$ are periodic with period $\pi$. That is,  $$ f(z) = f(z +\pi) \quad \text{ and } \quad g(z) = g(z+\pi) \quad \text{ for all } z \in \mathbb{C}\backslash\mathbb{Z}. $$ Thus, since $h$ is bounded on the square $\{ z: |\operatorname{Re} z| < \pi, |\operatorname{Im} z |< \pi \}$ and periodic, we may conclude that $h$ is bounded on the set $\{ z: |\operatorname{Im} z |< \pi \}$. To show boundedness on the entire plane, we show that it holds on the vertical strip (with center removed)  $$ S = \{ z: 0 \leq \operatorname{Re} z \leq \pi, | \operatorname{Im} z | \geq \pi \}. $$  For $z$ in $S$, \begin{align*}  \sum_{n= -\infty} ^ {+ \infty} |z-\pi n | ^{-2}  &= \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(x-\pi n)^2 + y^2}   &\leq \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(\pi (n-1))^2 +y^2}   \end{align*} \begin{align*} & = \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(\pi n)^2 +y^2}   &< 2\sum_{n=0} ^ {+ \infty} \frac{1}{(\pi n)^2 +y^2}   &\leq 2\sum_{n=0} ^ {+ \infty} \frac{1}{(\pi n)^2 +\pi ^2}.  \end{align*}  Thus $g$ is bounded on the set. It is easy to show that $f$ is also bounded on $S$. Thus the difference $f-g$ is also bounded. By the periodicity of $h$, the function is bounded on the entire plane, and is constant by Liouville's theorem. I'm wondering if my reasoning so far is valid; and if so, how to show that the relevant constant is in fact zero. Thanks.","I have the following problem: Find the constants $c_n$ so that  $$ \frac{1}{\sin^2 z } = \sum_{n= -\infty} ^ {+\infty} \frac{c_n}{(z-\pi n)^2} $$ and the series converges uniformly on every bounded set after dropping finitely many terms. Justify all your claims. Hint: Use Liouville's theorem to prove the equality. Let $c_n = 1 $ for all $n$. Let $\displaystyle f(z) := \frac{1}{\sin^2 z}$ and $\displaystyle g(z) := \sum_{n= -\infty} ^ {+\infty} \frac{1}{(z-\pi n)^2} $. Begin by showing that $h$ is an analytic function which converges uniformly on compact subsets of $\mathbb{C} \backslash \mathbb{Z}$. Suppose $K$ is a compact set which contains no integers. Define  $$ \delta_n = \inf_{z \in K} |\pi-z/n| =\frac{1}{n} \inf_{z \in K} |\pi n-z|, $$ where the infimum exists because $K$ is compact. Also, compactness implies boundedness. Thus as $n \to \pm \infty$, we have $\delta_n \to \pi$. Therefore, for sufficiently large $n$, we have $\delta_n > 2$, and  $$ \frac{1}{|z \pm n | ^2} \leq \frac{1}{\delta_n ^2 n^2} < \frac{1}{4n^2}. $$ By the Weierstrass M-test, $g$ converges absolutely uniformly on $K$. Since each term is analytic on $K$, we conclude that the series converges to an analytic function on $\mathbb{C} \backslash \mathbb{Z}$. Clearly the only poles of $g(z)$ are at $\pi n$ for each integer $n$, with corresponding principal part $\frac{1}{(z-\pi n)^2}$. For each integer $n$, we have $\sin^2 (\pi n) = \frac{d}{dz} \sin^2(\pi n) = 0$ and $\frac{d^2}{dz^z} \sin^2 (\pi n) \neq 0$, so $f(z) = 1/ \sin^2 (z)$ also has a pole of order two at each integer multiple of $\pi$, and no other poles. Furthermore, the principal part of $f(z)$ is, using the Laurent formulas and contour integration, equal to $\displaystyle \frac{1}{(z-n\pi)^2}$. Thus $h(z) := f(z)-g(z)$ has removable singularities at the points $n\pi$. Note that both $f$ and $g$ are periodic with period $\pi$. That is,  $$ f(z) = f(z +\pi) \quad \text{ and } \quad g(z) = g(z+\pi) \quad \text{ for all } z \in \mathbb{C}\backslash\mathbb{Z}. $$ Thus, since $h$ is bounded on the square $\{ z: |\operatorname{Re} z| < \pi, |\operatorname{Im} z |< \pi \}$ and periodic, we may conclude that $h$ is bounded on the set $\{ z: |\operatorname{Im} z |< \pi \}$. To show boundedness on the entire plane, we show that it holds on the vertical strip (with center removed)  $$ S = \{ z: 0 \leq \operatorname{Re} z \leq \pi, | \operatorname{Im} z | \geq \pi \}. $$  For $z$ in $S$, \begin{align*}  \sum_{n= -\infty} ^ {+ \infty} |z-\pi n | ^{-2}  &= \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(x-\pi n)^2 + y^2}   &\leq \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(\pi (n-1))^2 +y^2}   \end{align*} \begin{align*} & = \sum_{n= -\infty} ^ {+ \infty} \frac{1}{(\pi n)^2 +y^2}   &< 2\sum_{n=0} ^ {+ \infty} \frac{1}{(\pi n)^2 +y^2}   &\leq 2\sum_{n=0} ^ {+ \infty} \frac{1}{(\pi n)^2 +\pi ^2}.  \end{align*}  Thus $g$ is bounded on the set. It is easy to show that $f$ is also bounded on $S$. Thus the difference $f-g$ is also bounded. By the periodicity of $h$, the function is bounded on the entire plane, and is constant by Liouville's theorem. I'm wondering if my reasoning so far is valid; and if so, how to show that the relevant constant is in fact zero. Thanks.",,['complex-analysis']
49,Why is this function odd?,Why is this function odd?,,"Suppose a complex valued function $f$ is entire, maps $\mathbb{R}$ to $\mathbb{R}$, and maps the imaginary axis into the imaginary axis. I see that $f(x)=\overline{f(\bar{x})}$ on the whole real axis, and thus the identity theorem implies that $f(z)=\overline{f(\bar{z})}$ for all $z\in\mathbb{C}$. Then for $ai$ on the imaginary axis, it follows that $$ f(ai)=\overline{f(\overline{ai})}=\overline{f(-ai)}=-f(-ai). $$ Does this relation somehow extend to arbitrary $z$ so that $f$ is odd on the whole complex plane?","Suppose a complex valued function $f$ is entire, maps $\mathbb{R}$ to $\mathbb{R}$, and maps the imaginary axis into the imaginary axis. I see that $f(x)=\overline{f(\bar{x})}$ on the whole real axis, and thus the identity theorem implies that $f(z)=\overline{f(\bar{z})}$ for all $z\in\mathbb{C}$. Then for $ai$ on the imaginary axis, it follows that $$ f(ai)=\overline{f(\overline{ai})}=\overline{f(-ai)}=-f(-ai). $$ Does this relation somehow extend to arbitrary $z$ so that $f$ is odd on the whole complex plane?",,"['complex-analysis', 'parity']"
50,Area integral near essential singularity,Area integral near essential singularity,,"I'm studying for an exam and am stuck on the following. If $f$ is holomorphic on the punctured unit disk $D- \{0\}$, and $0$ is an essential singularity does it follow that $\displaystyle\int_{D -\{0\}} |f(z)|^{2} dA = \infty$","I'm studying for an exam and am stuck on the following. If $f$ is holomorphic on the punctured unit disk $D- \{0\}$, and $0$ is an essential singularity does it follow that $\displaystyle\int_{D -\{0\}} |f(z)|^{2} dA = \infty$",,['complex-analysis']
51,Entire function taking all complex values?,Entire function taking all complex values?,,"I am struggling with one exercise here. It says: Let $f(z)$ be an entire function, and the set of zeros of $f$ is finite, but nonempty. Show that $f$ takes all complex values. My idea is: Assuming there is some $b$ s.th. there is no $a$ with $f(a)=b$, then define the function $g:=f-b$, so then $g$ will be entire (since it's an entire function just shifted), and $g$ will never be zero. But that is a contradiction since an entire function can be written by definition as a polynomial, and any polynomial has a root somewhere, so $g=0$ somewhere, so $f=b$ somewhere, contradiction. But there is little Picard's theorem that tells us an entire function omits at most one value. Now suddenly I seem to show that it omits no value. And the fact that the set of zeros is finite but nonempty is only used, basically, to say that $f$ is not constant in the first place. So where is the mistake? Best regards,","I am struggling with one exercise here. It says: Let $f(z)$ be an entire function, and the set of zeros of $f$ is finite, but nonempty. Show that $f$ takes all complex values. My idea is: Assuming there is some $b$ s.th. there is no $a$ with $f(a)=b$, then define the function $g:=f-b$, so then $g$ will be entire (since it's an entire function just shifted), and $g$ will never be zero. But that is a contradiction since an entire function can be written by definition as a polynomial, and any polynomial has a root somewhere, so $g=0$ somewhere, so $f=b$ somewhere, contradiction. But there is little Picard's theorem that tells us an entire function omits at most one value. Now suddenly I seem to show that it omits no value. And the fact that the set of zeros is finite but nonempty is only used, basically, to say that $f$ is not constant in the first place. So where is the mistake? Best regards,",,['complex-analysis']
52,Preimage of discs under a complex polynomial,Preimage of discs under a complex polynomial,,"Let $a_0, \ldots, a_n \in \mathbb{C}$, with $a_n \neq 0$. Consider set $$U_R = \{~z \in \mathbb{C} ~:~ |a_nz^n + \dots + a_1z + a_0| < R~\}$$ for each $R > 0$. How do I prove that $U_R$ is homeomorphic to a disk, if $R$ is large enough? It's easy to see that for some small values of $R$, this isn't even connected, unless all roots of $P(z) = a_nz^n + \dots + a_0$ coincide. Is there a way to give a lower bound (depending on $a_n, \ldots, a_0$, of course) on the set of those $R$ for which $U_R$ is connected? Thanks in advance.","Let $a_0, \ldots, a_n \in \mathbb{C}$, with $a_n \neq 0$. Consider set $$U_R = \{~z \in \mathbb{C} ~:~ |a_nz^n + \dots + a_1z + a_0| < R~\}$$ for each $R > 0$. How do I prove that $U_R$ is homeomorphic to a disk, if $R$ is large enough? It's easy to see that for some small values of $R$, this isn't even connected, unless all roots of $P(z) = a_nz^n + \dots + a_0$ coincide. Is there a way to give a lower bound (depending on $a_n, \ldots, a_0$, of course) on the set of those $R$ for which $U_R$ is connected? Thanks in advance.",,['complex-analysis']
53,Möbius transformations,Möbius transformations,,"Let $A=\{0,1,\infty,a_1,\ldots,a_n\}$ and $B=\{0,1,\infty,b_1,\ldots,b_n\}$ be subsets of the Riemann sphere. Let $\sigma$ be an automorphism of the Riemann sphere, i.e., a Möbius transformation, such that $\sigma(A) = B$. What can one say about $\sigma$? Example. Suppose that $n=0$. Then $\sigma$ is an automorphism sending $\{0,1,\infty\}$ to $\{0,1,\infty\}$. So $\sigma$ is either the identity map or $z\mapsto \frac{1}{z}$. Example. Suppose that $n=1$. Under the hypothesis, we have that $b_1 = a_1$. (The cross ratio of $A$ and $B$ should be equal.) So there should be four possibilities for $\sigma$; one of them being the identity map.","Let $A=\{0,1,\infty,a_1,\ldots,a_n\}$ and $B=\{0,1,\infty,b_1,\ldots,b_n\}$ be subsets of the Riemann sphere. Let $\sigma$ be an automorphism of the Riemann sphere, i.e., a Möbius transformation, such that $\sigma(A) = B$. What can one say about $\sigma$? Example. Suppose that $n=0$. Then $\sigma$ is an automorphism sending $\{0,1,\infty\}$ to $\{0,1,\infty\}$. So $\sigma$ is either the identity map or $z\mapsto \frac{1}{z}$. Example. Suppose that $n=1$. Under the hypothesis, we have that $b_1 = a_1$. (The cross ratio of $A$ and $B$ should be equal.) So there should be four possibilities for $\sigma$; one of them being the identity map.",,"['complex-analysis', 'riemann-surfaces']"
54,Ahlfors' proof of Cauchy's theorem in a disk,Ahlfors' proof of Cauchy's theorem in a disk,,"I'm stuck in two parts of Ahlfors' proof of Cauchy's theorem in a disk (page 113), that is, if $f$ is holomorphic in an open disc $D$ then $\int_\gamma f(z)dz=0$ over every closed curve $\gamma$ in $D$. First part: Fix $z_0\in D$. We define $F(z)=\int_\sigma f(\zeta)d\zeta$ where $\sigma$ is the path joining $z_0$ with $z$ by taking an horizontal line from $z_0$ and getting to $z$ with a vertical line (hope it is clear). ""It is immediately seen that $\frac{\partial F}{\partial y}(z)=if(z)$"". Not for me. I mean, I'm geometrically and intuitively inclined to understand that when we derive vertically, since it is a constant path what we should get is the value of $f$. I don't see how the $i$ appears, though, and I formally don't understand what's going on. First of all, what does $\frac{\partial F}{\partial y}$ mean? This is what I understand by that: if $F=u+iv$ then $\frac{\partial F}{\partial y}=\frac{\partial u}{\partial y} + i \frac{\partial v}{\partial y}$. Right? I also found the following formula scribbled on my notebook: $\int_\gamma f(z)dz = \int_\gamma f(z) dx + i \int_\gamma f(z) dy$. Is this correct? I don't see how it makes sense to integrate with respect to $x$ a complex-valued function: what am I supposed to do with the $y$'s in the integrand? I'm guessing some abuse of notation is going on here. Anyway, I'm guessing this is something easy and I'm just confused by notation. Second part: we get that $\frac{\partial F}{\partial y}(z)=if(z)$ and $\frac{\partial F}{\partial x}(z)=f(z)$. ""Hence $F$ is holomorphic with derivative $f$"". How is that? I mean, we have $\frac{\partial F}{\partial x}= -i \frac{\partial F}{\partial y}$, which does not seem like Cauchy-Riemann to me. I'm guessing this is the same confusion as above. Hope I was not overly verbose.","I'm stuck in two parts of Ahlfors' proof of Cauchy's theorem in a disk (page 113), that is, if $f$ is holomorphic in an open disc $D$ then $\int_\gamma f(z)dz=0$ over every closed curve $\gamma$ in $D$. First part: Fix $z_0\in D$. We define $F(z)=\int_\sigma f(\zeta)d\zeta$ where $\sigma$ is the path joining $z_0$ with $z$ by taking an horizontal line from $z_0$ and getting to $z$ with a vertical line (hope it is clear). ""It is immediately seen that $\frac{\partial F}{\partial y}(z)=if(z)$"". Not for me. I mean, I'm geometrically and intuitively inclined to understand that when we derive vertically, since it is a constant path what we should get is the value of $f$. I don't see how the $i$ appears, though, and I formally don't understand what's going on. First of all, what does $\frac{\partial F}{\partial y}$ mean? This is what I understand by that: if $F=u+iv$ then $\frac{\partial F}{\partial y}=\frac{\partial u}{\partial y} + i \frac{\partial v}{\partial y}$. Right? I also found the following formula scribbled on my notebook: $\int_\gamma f(z)dz = \int_\gamma f(z) dx + i \int_\gamma f(z) dy$. Is this correct? I don't see how it makes sense to integrate with respect to $x$ a complex-valued function: what am I supposed to do with the $y$'s in the integrand? I'm guessing some abuse of notation is going on here. Anyway, I'm guessing this is something easy and I'm just confused by notation. Second part: we get that $\frac{\partial F}{\partial y}(z)=if(z)$ and $\frac{\partial F}{\partial x}(z)=f(z)$. ""Hence $F$ is holomorphic with derivative $f$"". How is that? I mean, we have $\frac{\partial F}{\partial x}= -i \frac{\partial F}{\partial y}$, which does not seem like Cauchy-Riemann to me. I'm guessing this is the same confusion as above. Hope I was not overly verbose.",,['complex-analysis']
55,Best quantitative version of open mapping theorem in complex analysis,Best quantitative version of open mapping theorem in complex analysis,,"There is a ""quantitative"" version of the Open Mapping Theorem in complex analysis , saying: Let $f$ be holomorphic on the closure of a disc $V$ around $c$ , and assume $m := \min_{z\in \delta V} |f(z)-f(c)|$ is not $0$ . Then $f(V)$ contains the open disc $B_{m/2}(f(c))$ . This is e.g. proved in section 8.5 of Remmert's textbook , and the proof is essentially reproduced in the accepted answer to this question , where, possibly for pedagogical reasons, the weaker $m/3$ instead of $m/2$ is used. Remmert says (p. 258) this proof goes back to Carathéodory's Theory of Functions of a Complex Variable , pp. 139/140. I see that in this proof , the radius of the disc around $f(c)$ cannot be made bigger than $m/2$ . However, if I draw (quite possibly too simple) sketches of the geometric situation, it looks as if the image should actually always contain $B_m(f(c))$ . Question : Is there an example of a function $f$ , analytic on the closure of some disc $V$ around $c$ , with $m := \min_{z\in \delta V} |f(z)-f(c)| > 0$ but $f(V)$ does not contain $B_m(f(c))$ ? If so, is $m/2$ indeed the best upper bound for the radius of an open disc around $f(c)$ guaranteed to be in $f(V)$ ?","There is a ""quantitative"" version of the Open Mapping Theorem in complex analysis , saying: Let be holomorphic on the closure of a disc around , and assume is not . Then contains the open disc . This is e.g. proved in section 8.5 of Remmert's textbook , and the proof is essentially reproduced in the accepted answer to this question , where, possibly for pedagogical reasons, the weaker instead of is used. Remmert says (p. 258) this proof goes back to Carathéodory's Theory of Functions of a Complex Variable , pp. 139/140. I see that in this proof , the radius of the disc around cannot be made bigger than . However, if I draw (quite possibly too simple) sketches of the geometric situation, it looks as if the image should actually always contain . Question : Is there an example of a function , analytic on the closure of some disc around , with but does not contain ? If so, is indeed the best upper bound for the radius of an open disc around guaranteed to be in ?",f V c m := \min_{z\in \delta V} |f(z)-f(c)| 0 f(V) B_{m/2}(f(c)) m/3 m/2 f(c) m/2 B_m(f(c)) f V c m := \min_{z\in \delta V} |f(z)-f(c)| > 0 f(V) B_m(f(c)) m/2 f(c) f(V),"['complex-analysis', 'open-map']"
56,Great difficulty in finding the residues of $\frac{\mathrm{Log}\Gamma\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}$,Great difficulty in finding the residues of,\frac{\mathrm{Log}\Gamma\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1},"$\newcommand{\log}{\operatorname{Log}}\newcommand{\res}{\operatorname{Res}}\newcommand{\d}{\mathrm{d}}$ Let $\Lambda(z)=\log\Gamma(z)$ , $a\gt0$ , let $\psi$ denote digamma. It is written here , Page 49, equation 47: $$\pi\cdot\Im\left[\res_{z=\pi i}\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}\right]=\psi\left(\frac{1}{2}+\frac{a}{2\pi}\right)$$ To motivate the calculation of this hard residue, it is shown in that paper that knowledge of this residue indirectly solves the integral: $$\int_1^\infty\frac{\ln\ln x}{(x+1)^2}\,\d x=\frac{1}{2}\int_0^\infty\frac{\ln x}{\cosh x +1}\,\d x$$ And finds it to be equal to: $$\frac{1}{2}\left\{\ln2\pi+\lim_{a\to0+}\pi\cdot\Im\left[\res_{z=\pi i}\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}\right]\right\}=\frac{1}{2}\left(-\gamma+\ln\frac{\pi}{2}\right)$$ Which is equivalently the limit of Malmsten’s integral as $\varphi\to0$ . Formally, I can attempt to find, as the singularity is an order two pole (the reader should note that the following working is mistaken): $$\begin{align}\lim_{z\to\pi i}\frac{\d}{\d z}(z-\pi i)^2\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}&=\lim_{z\to\pi i}\frac{2(z-\pi i)\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{2\pi i}(z-\pi i)^2\psi\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}-\frac{\sinh(z)(z-\pi i)^2\Lambda\left(\frac{z+ai}{2\pi i}\right)}{(\cosh(z)+1)^2}\\&=\lim_{z\to\pi i}\frac{2\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{2}{\pi i}(z-\pi i)\psi\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{4\pi^2}(z-\pi i)^2\psi'\left(\frac{z+ai}{2\pi i}\right)}{\sinh(z)}\\&-\frac{\cosh(z)(z-\pi i)^2\Lambda\left(\frac{z+ai}{2\pi i}\right)+2\sinh(z)(z-\pi i)\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{2\pi i}\sinh(z)(z-\pi i)^2\psi\left(\frac{z+ai}{2\pi i}\right)}{2\sinh(z)(\cosh(z)+1)}\\&=\lim_{z\to\pi i}\frac{\frac{2}{\pi i}\psi\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{\pi^2}(z-\pi i)\psi'\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{4\pi^2}(z-\pi i)^2\psi''\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)}\\&-\frac{\sinh(z)(z-\pi i)^2\Lambda\left(\frac{z+ai}{2\pi i}\right)+2\cosh(z)(z-\pi i)\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{2\pi i}\cosh(z)(z-\pi i)^2\psi\left(\frac{z+ai}{2\pi i}\right)}{2\cosh(z)(\cosh(z)+1)+2\sinh^2(z)}\\&-\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{\pi i}(z-\pi i)\psi\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{8\pi^2}(z-\pi i)^2\psi'\left(\frac{z+ai}{2\pi i}\right)}{\sinh(z)}\\&=-\frac{2}{\pi i}\psi\left(\frac{1}{2}+\frac{a}{2\pi}\right)-\lim_{z\to\pi i}[\cdots]\end{align}$$ But now there is a problem. The latter "" $\cdots$ "" contains a ratio which cannot be resolved by L'Hopital (dominator $\sinh$ , numerator non-zero). This is also a horribly complicated expression, and I am assuming that the author would have mentioned it if it is was this difficult. There must surely be some more straightforward way... Any advice? I've never done residue calculations this difficult before. I have found other residues from integral earlier in the paper by using small epsilon and Taylor series arguments, but they avail me nought here. Edit: I see I have misused L'Hopital again, on the third line! The numerator goes not to zero.","Let , , let denote digamma. It is written here , Page 49, equation 47: To motivate the calculation of this hard residue, it is shown in that paper that knowledge of this residue indirectly solves the integral: And finds it to be equal to: Which is equivalently the limit of Malmsten’s integral as . Formally, I can attempt to find, as the singularity is an order two pole (the reader should note that the following working is mistaken): But now there is a problem. The latter "" "" contains a ratio which cannot be resolved by L'Hopital (dominator , numerator non-zero). This is also a horribly complicated expression, and I am assuming that the author would have mentioned it if it is was this difficult. There must surely be some more straightforward way... Any advice? I've never done residue calculations this difficult before. I have found other residues from integral earlier in the paper by using small epsilon and Taylor series arguments, but they avail me nought here. Edit: I see I have misused L'Hopital again, on the third line! The numerator goes not to zero.","\newcommand{\log}{\operatorname{Log}}\newcommand{\res}{\operatorname{Res}}\newcommand{\d}{\mathrm{d}} \Lambda(z)=\log\Gamma(z) a\gt0 \psi \pi\cdot\Im\left[\res_{z=\pi i}\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}\right]=\psi\left(\frac{1}{2}+\frac{a}{2\pi}\right) \int_1^\infty\frac{\ln\ln x}{(x+1)^2}\,\d x=\frac{1}{2}\int_0^\infty\frac{\ln x}{\cosh x +1}\,\d x \frac{1}{2}\left\{\ln2\pi+\lim_{a\to0+}\pi\cdot\Im\left[\res_{z=\pi i}\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}\right]\right\}=\frac{1}{2}\left(-\gamma+\ln\frac{\pi}{2}\right) \varphi\to0 \begin{align}\lim_{z\to\pi i}\frac{\d}{\d z}(z-\pi i)^2\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}&=\lim_{z\to\pi i}\frac{2(z-\pi i)\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{2\pi i}(z-\pi i)^2\psi\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)+1}-\frac{\sinh(z)(z-\pi i)^2\Lambda\left(\frac{z+ai}{2\pi i}\right)}{(\cosh(z)+1)^2}\\&=\lim_{z\to\pi i}\frac{2\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{2}{\pi i}(z-\pi i)\psi\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{4\pi^2}(z-\pi i)^2\psi'\left(\frac{z+ai}{2\pi i}\right)}{\sinh(z)}\\&-\frac{\cosh(z)(z-\pi i)^2\Lambda\left(\frac{z+ai}{2\pi i}\right)+2\sinh(z)(z-\pi i)\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{2\pi i}\sinh(z)(z-\pi i)^2\psi\left(\frac{z+ai}{2\pi i}\right)}{2\sinh(z)(\cosh(z)+1)}\\&=\lim_{z\to\pi i}\frac{\frac{2}{\pi i}\psi\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{\pi^2}(z-\pi i)\psi'\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{4\pi^2}(z-\pi i)^2\psi''\left(\frac{z+ai}{2\pi i}\right)}{\cosh(z)}\\&-\frac{\sinh(z)(z-\pi i)^2\Lambda\left(\frac{z+ai}{2\pi i}\right)+2\cosh(z)(z-\pi i)\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{2\pi i}\cosh(z)(z-\pi i)^2\psi\left(\frac{z+ai}{2\pi i}\right)}{2\cosh(z)(\cosh(z)+1)+2\sinh^2(z)}\\&-\frac{\Lambda\left(\frac{z+ai}{2\pi i}\right)+\frac{1}{\pi i}(z-\pi i)\psi\left(\frac{z+ai}{2\pi i}\right)-\frac{1}{8\pi^2}(z-\pi i)^2\psi'\left(\frac{z+ai}{2\pi i}\right)}{\sinh(z)}\\&=-\frac{2}{\pi i}\psi\left(\frac{1}{2}+\frac{a}{2\pi}\right)-\lim_{z\to\pi i}[\cdots]\end{align} \cdots \sinh","['complex-analysis', 'limits', 'gamma-function', 'residue-calculus', 'polygamma']"
57,Sequence of polynomials $g_n$ converging pontwise with $g(\mathbb{C})=\mathbb{Z}$.,Sequence of polynomials  converging pontwise with .,g_n g(\mathbb{C})=\mathbb{Z},"Prove that there exists a sequence of polynomials $g_n(z)$ that converges for all $z\in \mathbb{C}$ to a limit function $g(z)$ with $g(\mathbb{C})=\mathbb{Z}$ . This question was on my complex analysis prelim last August. I have given it a go at various points throughout the time since, but I seriously have no idea where I could concretely start. Clearly the limit function can not be analytic, because this violates the open mapping theorem. Any hints would be excellent!","Prove that there exists a sequence of polynomials that converges for all to a limit function with . This question was on my complex analysis prelim last August. I have given it a go at various points throughout the time since, but I seriously have no idea where I could concretely start. Clearly the limit function can not be analytic, because this violates the open mapping theorem. Any hints would be excellent!",g_n(z) z\in \mathbb{C} g(z) g(\mathbb{C})=\mathbb{Z},['complex-analysis']
58,Find all entire functions $f$ such that $|f|$ is harmonic.,Find all entire functions  such that  is harmonic.,f |f|,"I'm trying to find all entire functions $f$ such that $|f|$ is harmonic. My attempt is as follows. Because $f$ is entire, we may write $f(z) = f(x + iy) = u(x,y) + iv(x,y)$ where $u$ and $v$ have continuous first-order partial derivatives and satisfy the Cauchy-Riemann equations. Furthermore, $u$ and $v$ are harmonic. Now $|f| = \sqrt{u^2 + v^2}$ so I thought maybe to look at $|f|^2$ first. Then, $$(|f|^2)_{xx} = 2(u_x)^2 + 2(v_x)^2 + 2(u\cdot u_{xx} + v \cdot v_{xx})$$ and $$(|f|^2)_{yy} = 2(u_y)^2 + 2(v_y)^2 + 2(u\cdot u_{yy} + v \cdot v_{yy}).$$ I need $(|f|^2)_{xx} + (|f|^2)_{yy} = 0$ in order for $|f|^2$ to be harmonic. So adding these equations and using that $u$ and $v$ are harmonic, I obtain $$(u_x)^2 + (u_y)^2 + (v_x)^2 + (v_y)^2 = 0.$$ By the Cauchy-Riemann equations, I can simplify this to $$(u_x)^2 + (v_x)^2 = 0.$$ I'm a little stuck on how to proceed from here. I want to somehow conclude $|f|^2$ is constant but I'm not sure how.","I'm trying to find all entire functions such that is harmonic. My attempt is as follows. Because is entire, we may write where and have continuous first-order partial derivatives and satisfy the Cauchy-Riemann equations. Furthermore, and are harmonic. Now so I thought maybe to look at first. Then, and I need in order for to be harmonic. So adding these equations and using that and are harmonic, I obtain By the Cauchy-Riemann equations, I can simplify this to I'm a little stuck on how to proceed from here. I want to somehow conclude is constant but I'm not sure how.","f |f| f f(z) = f(x + iy) = u(x,y) + iv(x,y) u v u v |f| = \sqrt{u^2 + v^2} |f|^2 (|f|^2)_{xx} = 2(u_x)^2 + 2(v_x)^2 + 2(u\cdot u_{xx} + v \cdot v_{xx}) (|f|^2)_{yy} = 2(u_y)^2 + 2(v_y)^2 + 2(u\cdot u_{yy} + v \cdot v_{yy}). (|f|^2)_{xx} + (|f|^2)_{yy} = 0 |f|^2 u v (u_x)^2 + (u_y)^2 + (v_x)^2 + (v_y)^2 = 0. (u_x)^2 + (v_x)^2 = 0. |f|^2","['complex-analysis', 'harmonic-functions']"
59,Is there a solution to the functional equation $f(x)=2\log(x)^2f\left(x^\frac{3}{8}\right)^2f\left(x^\frac{1}{4}\right)^2$?,Is there a solution to the functional equation ?,f(x)=2\log(x)^2f\left(x^\frac{3}{8}\right)^2f\left(x^\frac{1}{4}\right)^2,"I was going through my old notebooks and I found a sheet of paper with this problem on it. I thought it would be a shame to let such an unreasonably difficult question go to waste, so I decided I would share it. The problem simply states: Solve for $f$ : $$f(x)=2\log(x)^2f\left(x^\frac{3}{8}\right)^2f\left(x^\frac{1}{4}\right)^2$$ No other information or context is given, but I'm assuming that $f$ is a complex valued function of a single real or complex variable (since evaluating the function for negative $x$ would require $f(x)$ to be complex), and that $\log$ is the natural logarithm (since no one would use it for log base-10 if they were talking about complex functions). For curiosity's sake, I present it as a challenge to either solve for $f$ or prove that a solution does not exist there is one and only one solution (at least one solution exists, courtesy of Chrystomath). My own attempts at solving have been... unsuccessful. Edit: In their answer, Chrystomath provides a solution: $$f(x)=a\log(x)^{-\frac{2}{3}}\quad:\quad a\in\left\{z\in\mathbb{C}\Bigg| z^9=\frac{6^4}{8^9}\right\}$$ Which is quite possibly the most multivalued multivalued function I've ever seen. I don't know whether or not the solution is unique, and I would still be interested in any other solutions.","I was going through my old notebooks and I found a sheet of paper with this problem on it. I thought it would be a shame to let such an unreasonably difficult question go to waste, so I decided I would share it. The problem simply states: Solve for : No other information or context is given, but I'm assuming that is a complex valued function of a single real or complex variable (since evaluating the function for negative would require to be complex), and that is the natural logarithm (since no one would use it for log base-10 if they were talking about complex functions). For curiosity's sake, I present it as a challenge to either solve for or prove that a solution does not exist there is one and only one solution (at least one solution exists, courtesy of Chrystomath). My own attempts at solving have been... unsuccessful. Edit: In their answer, Chrystomath provides a solution: Which is quite possibly the most multivalued multivalued function I've ever seen. I don't know whether or not the solution is unique, and I would still be interested in any other solutions.",f f(x)=2\log(x)^2f\left(x^\frac{3}{8}\right)^2f\left(x^\frac{1}{4}\right)^2 f x f(x) \log f f(x)=a\log(x)^{-\frac{2}{3}}\quad:\quad a\in\left\{z\in\mathbb{C}\Bigg| z^9=\frac{6^4}{8^9}\right\},"['complex-analysis', 'recreational-mathematics', 'functional-equations']"
60,A modern Introduction to Complex Analysis,A modern Introduction to Complex Analysis,,"Is the book Complex variables by  Carlos A Berenstein and Roger Gay a good book for a  second, more rigorous, course in complex analysis? My first course, while I loved the applications to analytic number theory, felt dry and bland in its analysis as they just gave definitions. This book seems to be one of its kind as it talks about algebraic topology, homological algebra, and sheaf theory while developing complex analysis from the definition of a holomorphic funtion (It gives a really good reason from linear algebra why we have the definition of a holomorphic function the way we do). I can't find any reviews or really anything about this book except for one reply on the page . Is this a good book to read or is there a similar one that covers a modern approach like it? (By the way my first course text was Complex analysis by Elias M. Stein which I read up to chapter 7).","Is the book Complex variables by  Carlos A Berenstein and Roger Gay a good book for a  second, more rigorous, course in complex analysis? My first course, while I loved the applications to analytic number theory, felt dry and bland in its analysis as they just gave definitions. This book seems to be one of its kind as it talks about algebraic topology, homological algebra, and sheaf theory while developing complex analysis from the definition of a holomorphic funtion (It gives a really good reason from linear algebra why we have the definition of a holomorphic function the way we do). I can't find any reviews or really anything about this book except for one reply on the page . Is this a good book to read or is there a similar one that covers a modern approach like it? (By the way my first course text was Complex analysis by Elias M. Stein which I read up to chapter 7).",,"['complex-analysis', 'reference-request']"
61,Julia Sets of $z^k$.,Julia Sets of .,z^k,"I'm trying to figure out a way to show that the Julia sets of $z^k$ with $k\geq 2$ are the unit circle.  I had a question posted before, but I wanted to add more details and how I'm thinking about it differently. Intuitively, I get why it must be the unit circle based on the discussion below.  Let $R(z)=z^k$.  Then $R^n(z)=z^{k^n}$.  As $n \to \infty$ when $|z|>1$ we have that $R^n(z) \to \infty$.    However, if $|z|<1$, we have that $R^n(z)\to 0$ as $n \to \infty$.  So the place I have to consider are the points $|z|=1$.  In my mind, it's clear that any open set contain a point on the unit circle will contain points that will both go to $0$ or $\infty$. Theorem:  Let $F$ be any family of maps, each mapping $(X,d)$ into $(X_1,d_1)$.  Then there is a maximal open subset of $X$ on which $F$ is equicontinuous.  In particular, if $f$ maps a metric space $(X,d)$ into itself, then there is a maximal open subset of $X$ on which the family of iterates $\{f^n\}$ is equicontinuous. I'm not sure if this is the correct way of applying the above theorem, but $R^n(z)$ maps points outside of the unit circle to points still outside the unit circle and similarly to those within the unit circle.  But I'm still not sure how to make the connection to the points on the unit circle.","I'm trying to figure out a way to show that the Julia sets of $z^k$ with $k\geq 2$ are the unit circle.  I had a question posted before, but I wanted to add more details and how I'm thinking about it differently. Intuitively, I get why it must be the unit circle based on the discussion below.  Let $R(z)=z^k$.  Then $R^n(z)=z^{k^n}$.  As $n \to \infty$ when $|z|>1$ we have that $R^n(z) \to \infty$.    However, if $|z|<1$, we have that $R^n(z)\to 0$ as $n \to \infty$.  So the place I have to consider are the points $|z|=1$.  In my mind, it's clear that any open set contain a point on the unit circle will contain points that will both go to $0$ or $\infty$. Theorem:  Let $F$ be any family of maps, each mapping $(X,d)$ into $(X_1,d_1)$.  Then there is a maximal open subset of $X$ on which $F$ is equicontinuous.  In particular, if $f$ maps a metric space $(X,d)$ into itself, then there is a maximal open subset of $X$ on which the family of iterates $\{f^n\}$ is equicontinuous. I'm not sure if this is the correct way of applying the above theorem, but $R^n(z)$ maps points outside of the unit circle to points still outside the unit circle and similarly to those within the unit circle.  But I'm still not sure how to make the connection to the points on the unit circle.",,"['complex-analysis', 'complex-dynamics']"
62,"Factoring real polynomials with no real zeros, and other polys whose zeros come in pairs","Factoring real polynomials with no real zeros, and other polys whose zeros come in pairs",,"Of course a polynomial of degree at most $4$ may ""easily"" be factored .  And for a polynomial of degree $5$ or greater, no algebraic formula for the roots need exist.  What about when the zeros of the polynomial are known to come in conjugate pairs:  Suppose that $p(z)$ is a real polynomial (ie $p(t)\in\mathbb{R}$ for all $t\in\mathbb{R}$), but $p$ is non-zero on $\mathbb{R}$ (so that the zeros of $p$ come in conjugate pairs).  If $\deg(p)=8$ (or $6$), can the quartic (or cubic) formulas be used to find the zeros of $p$? Second and related question: suppose that $q$ has no zeros on the unit circle $\mathbb{T}$, and it is known that the zeros of $q$ are conjugate symmetric across the unit circle.  (Note, this is the case for the numerator of the derivative of a finite Blaschke product, and this is in fact the motivation for the first question as well.)  If $\deg(q)\leq8$, can $q$ be factored somehow using the quartic formula?","Of course a polynomial of degree at most $4$ may ""easily"" be factored .  And for a polynomial of degree $5$ or greater, no algebraic formula for the roots need exist.  What about when the zeros of the polynomial are known to come in conjugate pairs:  Suppose that $p(z)$ is a real polynomial (ie $p(t)\in\mathbb{R}$ for all $t\in\mathbb{R}$), but $p$ is non-zero on $\mathbb{R}$ (so that the zeros of $p$ come in conjugate pairs).  If $\deg(p)=8$ (or $6$), can the quartic (or cubic) formulas be used to find the zeros of $p$? Second and related question: suppose that $q$ has no zeros on the unit circle $\mathbb{T}$, and it is known that the zeros of $q$ are conjugate symmetric across the unit circle.  (Note, this is the case for the numerator of the derivative of a finite Blaschke product, and this is in fact the motivation for the first question as well.)  If $\deg(q)\leq8$, can $q$ be factored somehow using the quartic formula?",,"['complex-analysis', 'polynomials', 'roots', 'factoring']"
63,If $z\mapsto f(z)^n$ is analytic then $f$ is analytic,If  is analytic then  is analytic,z\mapsto f(z)^n f,"Let $U$ be an open connected set in $\Bbb C$ and $f:U\to \Bbb C$ be a continuous map such that $z\mapsto f(z)^n$ is analytic for some positive integer $n$. Prove that $f$ is analytic. I think the statement is FALSE. Consider the function $f(z)=\sqrt z$ in any open connected set $U\subset \mathbb C$ containing $0$. Then $f$ is continuous and $f(z)^2$ is analytic , but $f$ is not analytic. Is my argument correct or there are some misunderstanding ? If the statement is TRUE then how I can proceed to prove it ?","Let $U$ be an open connected set in $\Bbb C$ and $f:U\to \Bbb C$ be a continuous map such that $z\mapsto f(z)^n$ is analytic for some positive integer $n$. Prove that $f$ is analytic. I think the statement is FALSE. Consider the function $f(z)=\sqrt z$ in any open connected set $U\subset \mathbb C$ containing $0$. Then $f$ is continuous and $f(z)^2$ is analytic , but $f$ is not analytic. Is my argument correct or there are some misunderstanding ? If the statement is TRUE then how I can proceed to prove it ?",,"['complex-analysis', 'complex-numbers', 'analyticity', 'analytic-functions']"
64,Inequality for incomplete Gamma Function,Inequality for incomplete Gamma Function,,"I am trying to find if the following inequality is correct or not \begin{align} f_a(x) \le f_b(x), \forall x\in \mathbb{R} \end{align} for $0<a\le b$, where \begin{align} f_a(x)= \frac{\gamma \left( \frac{1}{a}, \frac{|x|^a}{2} \right)}{\Gamma \left( \frac{1}{a} \right)}, \end{align} and where the gamma functions are defined as follows \begin{align} \Gamma\left(x \right)= \int_0^\infty t^{x-1} e^{-t} dt, \\  \gamma(x,s) = \int_0^s t^{x-1}\,e^{-t}\,dt. \end{align} I tried some simulation and this inequality seems to hold.  However, I can not show it. This inequality can also be seen as a monotonicity result in terms of a variable $a$ for $f_a(x)$. Simulation, results seem to suggest the inequality is true, see the figure below (on the figure x-axis is $x$). Thanks.","I am trying to find if the following inequality is correct or not \begin{align} f_a(x) \le f_b(x), \forall x\in \mathbb{R} \end{align} for $0<a\le b$, where \begin{align} f_a(x)= \frac{\gamma \left( \frac{1}{a}, \frac{|x|^a}{2} \right)}{\Gamma \left( \frac{1}{a} \right)}, \end{align} and where the gamma functions are defined as follows \begin{align} \Gamma\left(x \right)= \int_0^\infty t^{x-1} e^{-t} dt, \\  \gamma(x,s) = \int_0^s t^{x-1}\,e^{-t}\,dt. \end{align} I tried some simulation and this inequality seems to hold.  However, I can not show it. This inequality can also be seen as a monotonicity result in terms of a variable $a$ for $f_a(x)$. Simulation, results seem to suggest the inequality is true, see the figure below (on the figure x-axis is $x$). Thanks.",,"['complex-analysis', 'inequality', 'special-functions', 'gamma-function']"
65,Holomorphic function with constant modulus in the boundary of an annulus can be written as $f(z)=cz^n$ for $c\in \mathbb{C}$ and $n\in \mathbb{Z}$,Holomorphic function with constant modulus in the boundary of an annulus can be written as  for  and,f(z)=cz^n c\in \mathbb{C} n\in \mathbb{Z},"I'm preparing myself to take a qualifying exam for my math PHD. I was trying to solve the previous exams and I found a complex analysis problem I couldn't solve: Let $0<r<R$ and $A=\{z\in\mathbb{C}|r<|z|<R\}$. Suppose that $f:A\rightarrow \mathbb{C}$ is an holomorphic function, with a continuous extension to the boundary of $A$ and such that $f(z)\ne0$ for all $z\in A$.  Also, suppose that for every $\theta\in [0,2\pi]$ we have $|f(re^{i\theta})|=\alpha$ and $|f(Re^{i\theta})|=\beta$, where $\alpha$ and $\beta$ don't depend on $\theta$. Prove that for some $n\in\mathbb{Z}$ and $c\in\mathbb{C}$ we have $f(z)=cz^n$ for all $z\in A$. So far, I tried to define a function that scaled the range and domain to fit into the unitary disc and then apply Schwarz's Lemma, but when I tried to prove the differentiability at 0 I noticed it depended on the derivative of $f$ in $re^{i\theta}$, and I can't define $f'$ in the boundary of the annulus, so I gave up on that idea. Also, the problem has a hint that states: ""consider $\log|f(z)|-\gamma\log|z|$ for a convenient $\gamma$"". I tried to approach defining a logarithm function, but the domain isn't simply connected so I don't know how to proceed. Any help is appreciated. Thanks P.S.:This is my first time asking a question on mathstack. If I'm breaking any rule please point it out so I can stop doing it in the future.","I'm preparing myself to take a qualifying exam for my math PHD. I was trying to solve the previous exams and I found a complex analysis problem I couldn't solve: Let $0<r<R$ and $A=\{z\in\mathbb{C}|r<|z|<R\}$. Suppose that $f:A\rightarrow \mathbb{C}$ is an holomorphic function, with a continuous extension to the boundary of $A$ and such that $f(z)\ne0$ for all $z\in A$.  Also, suppose that for every $\theta\in [0,2\pi]$ we have $|f(re^{i\theta})|=\alpha$ and $|f(Re^{i\theta})|=\beta$, where $\alpha$ and $\beta$ don't depend on $\theta$. Prove that for some $n\in\mathbb{Z}$ and $c\in\mathbb{C}$ we have $f(z)=cz^n$ for all $z\in A$. So far, I tried to define a function that scaled the range and domain to fit into the unitary disc and then apply Schwarz's Lemma, but when I tried to prove the differentiability at 0 I noticed it depended on the derivative of $f$ in $re^{i\theta}$, and I can't define $f'$ in the boundary of the annulus, so I gave up on that idea. Also, the problem has a hint that states: ""consider $\log|f(z)|-\gamma\log|z|$ for a convenient $\gamma$"". I tried to approach defining a logarithm function, but the domain isn't simply connected so I don't know how to proceed. Any help is appreciated. Thanks P.S.:This is my first time asking a question on mathstack. If I'm breaking any rule please point it out so I can stop doing it in the future.",,"['complex-analysis', 'holomorphic-functions']"
66,Cauchy's Theorem - Prove that $\sum_{n=1}^\infty \frac{1}{\lambda_{n}^2} $ = $\frac{1}{10}$,Cauchy's Theorem - Prove that  =,\sum_{n=1}^\infty \frac{1}{\lambda_{n}^2}  \frac{1}{10},"I seek to prove that $$\sum_{n=1}^\infty \frac{1}{\lambda_{n}^2}   = \frac{1} {10},$$ by applying Cauchy Theorem to $$ f(z) =  \left(\frac{z\tan(z)}{z-\tan(z)}+\frac{3}{z}\right) \frac{1}{z^2},$$ where $\lambda_n$ are positive solutions to $\tan(x) = x$. How can I solve this?","I seek to prove that $$\sum_{n=1}^\infty \frac{1}{\lambda_{n}^2}   = \frac{1} {10},$$ by applying Cauchy Theorem to $$ f(z) =  \left(\frac{z\tan(z)}{z-\tan(z)}+\frac{3}{z}\right) \frac{1}{z^2},$$ where $\lambda_n$ are positive solutions to $\tan(x) = x$. How can I solve this?",,"['complex-analysis', 'complex-numbers', 'complex-integration']"
67,Find all entire function $f$ such that $\lim_{z\to \infty}\left|\frac{f(z)}{z}\right|=0$,Find all entire function  such that,f \lim_{z\to \infty}\left|\frac{f(z)}{z}\right|=0,"If $f$ is an entire function such that $\lim_{z\to \infty}\left|\frac{f(z)}{z}\right|=0$ then find the function $f$. Replacing $z$ by $\frac{1}{z}$, we get $$\lim_{z\to 0}|zf(1/z)|=0$$This shows that $f(1/z)$ has removable singularity at $z=0$ , so $f(z)$ has removable singularity at $z=\infty$. As $f$ is entire so , $f$ must be constant . Is it correct?","If $f$ is an entire function such that $\lim_{z\to \infty}\left|\frac{f(z)}{z}\right|=0$ then find the function $f$. Replacing $z$ by $\frac{1}{z}$, we get $$\lim_{z\to 0}|zf(1/z)|=0$$This shows that $f(1/z)$ has removable singularity at $z=0$ , so $f(z)$ has removable singularity at $z=\infty$. As $f$ is entire so , $f$ must be constant . Is it correct?",,['complex-analysis']
68,Is an analytic function determined by its values on a lattice?,Is an analytic function determined by its values on a lattice?,,"Suppose we know the values of a complex analytic function $f$ at all $x+iy$, for $x,y\in\mathbb{Z}$.  Can we uniquely determine $f$? More generally, are there examples of nowhere-dense sets $E$ s.t. $f\mid_E$ determines $f$?","Suppose we know the values of a complex analytic function $f$ at all $x+iy$, for $x,y\in\mathbb{Z}$.  Can we uniquely determine $f$? More generally, are there examples of nowhere-dense sets $E$ s.t. $f\mid_E$ determines $f$?",,['complex-analysis']
69,Proof or Counterexample:Is every open connected set $D \subset \mathbb C$ is a domain of holomorphy?,Proof or Counterexample:Is every open connected set  is a domain of holomorphy?,D \subset \mathbb C,Def: An open set  $D \subset \mathbb C^n$  is called a domain of Holomorphy if there exists a holomorphic function $f$ on $D$ such that $f$ cannot be extended to a bigger set. Is every non empty open set $D \subset \mathbb C$ is a domain of holomorphy? I personally believe that this result is true but I'm unable to find a proof.Any ideas?,Def: An open set  $D \subset \mathbb C^n$  is called a domain of Holomorphy if there exists a holomorphic function $f$ on $D$ such that $f$ cannot be extended to a bigger set. Is every non empty open set $D \subset \mathbb C$ is a domain of holomorphy? I personally believe that this result is true but I'm unable to find a proof.Any ideas?,,"['complex-analysis', 'several-complex-variables']"
70,Inverse Laplace transform of $\exp(-1/\sqrt{s})$,Inverse Laplace transform of,\exp(-1/\sqrt{s}),I'm looking for the inverse Laplace transform of: $$F(s) = \exp(-1/\sqrt{s}).$$ Does the inverse Laplace transform exist? Do you have a reference in which this transform is given?,I'm looking for the inverse Laplace transform of: $$F(s) = \exp(-1/\sqrt{s}).$$ Does the inverse Laplace transform exist? Do you have a reference in which this transform is given?,,"['complex-analysis', 'laplace-transform']"
71,finding certain sequences that satisfy a requirement,finding certain sequences that satisfy a requirement,,"I need to find sequence $(z_n) $ and $(w_n)$ such that $|z_n| \to 1 $ and $|w_n | \to 1 $ but $$ \Big| \frac{ w_n - z_n }{1- \overline{w}_n z_n } \Big | \; \; \text{doesn't converge to} \; \;  1 $$ My try Put $z_n = 1 + \frac{1}{n}$ and $w_n = 1 - \frac{1}{n} $ , then $|z_n| = | 1 + \frac{1}{n} | \to 1 $ and $|w_n| \to 1 $ , but $$ \Big| \frac{ w_n - z_n }{1- \overline{w}_n z_n } \Big | = \Big| \frac{ - \frac{2}{n}}{1 - (1^2 - \frac{1}{n^2})} \Big| = \Big| \frac{ - \frac{2}{n} }{\frac{1}{n^2}} \Big| = 2n$$ which does not converge to $1$ as required. My question is, is this a correct solution? What are all possible limits of such sequences?","I need to find sequence and such that and but My try Put and , then and , but which does not converge to as required. My question is, is this a correct solution? What are all possible limits of such sequences?",(z_n)  (w_n) |z_n| \to 1  |w_n | \to 1   \Big| \frac{ w_n - z_n }{1- \overline{w}_n z_n } \Big | \; \; \text{doesn't converge to} \; \;  1  z_n = 1 + \frac{1}{n} w_n = 1 - \frac{1}{n}  |z_n| = | 1 + \frac{1}{n} | \to 1  |w_n| \to 1   \Big| \frac{ w_n - z_n }{1- \overline{w}_n z_n } \Big | = \Big| \frac{ - \frac{2}{n}}{1 - (1^2 - \frac{1}{n^2})} \Big| = \Big| \frac{ - \frac{2}{n} }{\frac{1}{n^2}} \Big| = 2n 1,[]
72,maximum modulus principle implies Liouville's Theorem,maximum modulus principle implies Liouville's Theorem,,"Today during the qualifying exam I met this question: Show that the maximum modulus principle implies the Liouville Theorem. Well, this is my attempt: It suffices to show that a bounded entire function can achieve its maximum modulus in complex plane. But I got messed up here. Can anyone give me some ideas?","Today during the qualifying exam I met this question: Show that the maximum modulus principle implies the Liouville Theorem. Well, this is my attempt: It suffices to show that a bounded entire function can achieve its maximum modulus in complex plane. But I got messed up here. Can anyone give me some ideas?",,[]
73,Given two holomorphic functions on a region find two other such that...,Given two holomorphic functions on a region find two other such that...,,"Let $\Omega$ be a region in the complex plane and let $f_1$ and $f_2$ be holomorphic functions on $\Omega$ having no common zero. Show that there exist holomorphic functions $g_1$ and $g_2$ on $\Omega$ such that, $f_1g_1+f_2g_2$ is identically equal to one on $\Omega$.","Let $\Omega$ be a region in the complex plane and let $f_1$ and $f_2$ be holomorphic functions on $\Omega$ having no common zero. Show that there exist holomorphic functions $g_1$ and $g_2$ on $\Omega$ such that, $f_1g_1+f_2g_2$ is identically equal to one on $\Omega$.",,['complex-analysis']
74,Real integral using complex methods,Real integral using complex methods,,"Evaluate $\displaystyle\int_0^\infty \frac {x^\frac{1}{2}}{1+x^4}dx$ using complex methods. I'm totally locked up on this one and have thrown in the towel. My strategy was to integrate around a ""keyhole"" in the complex plane, branching the $x^{1/2}$ across the positive real line, then to take limits. The solution I keep getting for the sum of the residues for $R$ (the radius of my ""keyhole contour"") sufficiently large is $$\frac{1}{4} (e^{\pi i/8}+e^{5\pi i/8}-e^{3\pi i/8}-e^{7\pi i/8})=2\int_0^\infty \frac {x^\frac{1}{2}}{1+x^4}dx$$ which yields that $$\displaystyle\int_0^\infty \frac {x^\frac{1}{2}}{1+x^4}dx=\frac{1}{8}\left(\sqrt{\sqrt{2}+2}-\sqrt{2-\sqrt{2}}\right).$$ A quick look-see on Wolfram, however, yields $\frac{\pi}{4\cos{\frac{\pi}{8}}}=\frac{\pi}{2\sqrt{\sqrt{2}+2}}$ as the solution. So it seems like I've missed something trivial, but I'm not sure what.","Evaluate $\displaystyle\int_0^\infty \frac {x^\frac{1}{2}}{1+x^4}dx$ using complex methods. I'm totally locked up on this one and have thrown in the towel. My strategy was to integrate around a ""keyhole"" in the complex plane, branching the $x^{1/2}$ across the positive real line, then to take limits. The solution I keep getting for the sum of the residues for $R$ (the radius of my ""keyhole contour"") sufficiently large is $$\frac{1}{4} (e^{\pi i/8}+e^{5\pi i/8}-e^{3\pi i/8}-e^{7\pi i/8})=2\int_0^\infty \frac {x^\frac{1}{2}}{1+x^4}dx$$ which yields that $$\displaystyle\int_0^\infty \frac {x^\frac{1}{2}}{1+x^4}dx=\frac{1}{8}\left(\sqrt{\sqrt{2}+2}-\sqrt{2-\sqrt{2}}\right).$$ A quick look-see on Wolfram, however, yields $\frac{\pi}{4\cos{\frac{\pi}{8}}}=\frac{\pi}{2\sqrt{\sqrt{2}+2}}$ as the solution. So it seems like I've missed something trivial, but I'm not sure what.",,"['complex-analysis', 'contour-integration']"
75,Finding the order of an entire function defined from an integral,Finding the order of an entire function defined from an integral,,"The following problem is posed in Greene and Krantz, page 297, Problem 11. Let $g: \mathbb{R} \to \mathbb{C}$ be a continuous function, $\alpha \in \mathbb{R}$, and define $f: \mathbb{C} \to \mathbb{C}$ s.t.  $$f(z) = \int^b_a e^{\alpha z t} g(t) dt .$$ Show that $f$ is entire and is of finite order. Determine whether or not the order of $f$ depends on $g$. I am able to show that $f$ is entire and of finite order. Intuitively, it seems to me that assuming $\alpha \neq 0$ and $g$ not identically $0$, $f$ should always be of order 1, but I can't show this nor find a counterexample. Insights would be appreciated.","The following problem is posed in Greene and Krantz, page 297, Problem 11. Let $g: \mathbb{R} \to \mathbb{C}$ be a continuous function, $\alpha \in \mathbb{R}$, and define $f: \mathbb{C} \to \mathbb{C}$ s.t.  $$f(z) = \int^b_a e^{\alpha z t} g(t) dt .$$ Show that $f$ is entire and is of finite order. Determine whether or not the order of $f$ depends on $g$. I am able to show that $f$ is entire and of finite order. Intuitively, it seems to me that assuming $\alpha \neq 0$ and $g$ not identically $0$, $f$ should always be of order 1, but I can't show this nor find a counterexample. Insights would be appreciated.",,['complex-analysis']
76,Is there any relationship between Cauchy-Riemann equations and vector fields on manifolds?,Is there any relationship between Cauchy-Riemann equations and vector fields on manifolds?,,"Well, suppose we have $f : \mathbb{C} \to \mathbb{C}$ analytic, then if $f = u + iv$ the functions $u,v : \mathbb{C} \to \mathbb{R}$ satisfy the Cauchy-Riemann equations: $D_1u=D_2v$ and $D_2u=-D_1v$. Now, suppose we pick $(x,\mathbb{C})$ the cartesian coordinates in $\mathbb{C}$. Then we have: $$\begin{cases}\dfrac{\partial u}{\partial x^1}&=\phantom{-}\dfrac{\partial v}{\partial x^2} \\ \\ \dfrac{\partial u}{\partial x^2} &= -\dfrac{\partial v}{\partial x^1}\end{cases}$$ This can also be written as simply: $$i\dfrac{\partial f}{\partial x^1}=\dfrac{\partial f}{\partial x^2}$$ But now here is the interesting thing I've noticed. When we work with arbitrary smooth manifolds, the partials operators relative to some coordinate system are tangent vectors to the coordinate lines. So that $\partial /\partial x ^1$ and $\partial/\partial x^2$ are tangent vectors to the coordinate lines. When we work with points of $\mathbb{C}$ and we understand then as vectors (identifying the tangent space at the origin with the space $\mathbb{C}$ itself), multiplying by $i$ is the same as rotating a vector by $\pi/2$. In the standard cartesian coordinates, $\partial/\partial x^1$ is pointing in the direction of the $x$ axis and $\partial/\partial x^2$ is pointing in the direction of the $y$ axis. In that case, $\partial /\partial x^2$ is simply $\partial /\partial x^1$ rotated $\pi/2$ in the counterclockwise direction. And using $i$ to express rotations, this is exactly what is written up there. I'm not sure if I've made myself clear, but the question is: ""is there any relationship between the Cauchy-Riemann equations and the vector fields defined in $\mathbb{C}$ as a smooth manifold that gives us deeper understanding of what analytic functions do when transforming $\mathbb{C}$ into another $\mathbb{C}$?"" Thanks very much in advance!","Well, suppose we have $f : \mathbb{C} \to \mathbb{C}$ analytic, then if $f = u + iv$ the functions $u,v : \mathbb{C} \to \mathbb{R}$ satisfy the Cauchy-Riemann equations: $D_1u=D_2v$ and $D_2u=-D_1v$. Now, suppose we pick $(x,\mathbb{C})$ the cartesian coordinates in $\mathbb{C}$. Then we have: $$\begin{cases}\dfrac{\partial u}{\partial x^1}&=\phantom{-}\dfrac{\partial v}{\partial x^2} \\ \\ \dfrac{\partial u}{\partial x^2} &= -\dfrac{\partial v}{\partial x^1}\end{cases}$$ This can also be written as simply: $$i\dfrac{\partial f}{\partial x^1}=\dfrac{\partial f}{\partial x^2}$$ But now here is the interesting thing I've noticed. When we work with arbitrary smooth manifolds, the partials operators relative to some coordinate system are tangent vectors to the coordinate lines. So that $\partial /\partial x ^1$ and $\partial/\partial x^2$ are tangent vectors to the coordinate lines. When we work with points of $\mathbb{C}$ and we understand then as vectors (identifying the tangent space at the origin with the space $\mathbb{C}$ itself), multiplying by $i$ is the same as rotating a vector by $\pi/2$. In the standard cartesian coordinates, $\partial/\partial x^1$ is pointing in the direction of the $x$ axis and $\partial/\partial x^2$ is pointing in the direction of the $y$ axis. In that case, $\partial /\partial x^2$ is simply $\partial /\partial x^1$ rotated $\pi/2$ in the counterclockwise direction. And using $i$ to express rotations, this is exactly what is written up there. I'm not sure if I've made myself clear, but the question is: ""is there any relationship between the Cauchy-Riemann equations and the vector fields defined in $\mathbb{C}$ as a smooth manifold that gives us deeper understanding of what analytic functions do when transforming $\mathbb{C}$ into another $\mathbb{C}$?"" Thanks very much in advance!",,"['complex-analysis', 'multivariable-calculus', 'manifolds']"
77,"Radius of convergence of $\sum_{n = 0}^{\infty} (a_1^n + \dots + a_k^n)z^n$, where $|a_1| = |a_2| = \dots = |a_k| = 1$","Radius of convergence of , where",\sum_{n = 0}^{\infty} (a_1^n + \dots + a_k^n)z^n |a_1| = |a_2| = \dots = |a_k| = 1,"Here's the problem: Find the radius of convergence of $f(z) = \sum_{n = 0}^{\infty} (a_1^n + \dots + a_k^n)z^n$, where $|a_1| = |a_2| = \dots = |a_k| = 1$, and $a_i \in \mathbb{C}$. Since the series in question is the sum of as $j$ ranges from $1$ to $k$ of the series $f_j(z) = \sum_{n = 0}^{\infty} a_j^n z^n$ you see right away that the radius of convergence $R$ of $f(z)$ is at least $\displaystyle 1$. I'm guessing that maybe the radius of convergence $R$ is exactly $\displaystyle 1$.  I think you might be able to get the answer if you can show that the set $\{a_1^n + \dots + a_k^n : n \ge 0\}$ either has a non-zero limit point inside $\{ z : |z| \le k \}$, or else attains the same non-zero value infinitely many times, because then in either case you can find a subsequence $\{n_j\}$ with $|a_1^{n_j} + \dots + a_k^{n_j}|$ bounded away from $0$, and so $|a_1^{n_j} + \dots + a_k^{n_j}|^{1/n_j} \to 1$ as $n_j \to \infty$. Any thoughts about how to proceed with this idea? Or, is there a far better way to look at this? Edit (*) For $a_j$ and any $N > 0$, you can find a $n > N$ such that $a_j^n$ is arbitrarily close to $1$. You can do this by writing $a_j^n = e^{i n \theta_j}$ and looking at $n \theta _j$ modulo $2 \pi$. Let $b_i = a_i / a_1$. It is not true that we have any of the limits $\lim \limits_{n \to \infty}a_1^n + a_2^n = 0, -1, -2, \dots$. This is because we can find a subsequence $\{n_k\}$ such that $\lim \limits_{n \to \infty}a_1^{n_k} = 1$. Assuming to the contrary for a contradiction, for this subsequence one would have to have $\lim \limits_{n \to \infty} a_1^{n_k}(1 + b_2^{n_k}) = 0, -1, -2, \dots$ so that $\lim \limits_{n \to \infty} (1 + b_2^{n_k}) = 0, -1, -2, \dots$ and therefore $\lim \limits_{n \to \infty} b_2^{n_k} = -1, -2, -3, \dots$ which is impossible by (*). Similarly, it is not true that we have any of the limits $\lim \limits_{n \to \infty}a_1^n + a_2^n + a_3^n= 0, -1, -2, \dots$. Because otherwise, we can find a subsequence $\{n_k\}$ such that $\lim \limits_{n \to \infty}a_1^{n_k} = 1$, and then $\lim \limits_{n \to \infty} (1 + b_2^{n_k} + b_3^{n_k}) = 0, -1, -2, \dots$, and in this case $\lim \limits_{n \to \infty} b_2^{n_k} + b_3^{n_k}= -1, -2, -3, \dots$ which is impossible. Continuing like this, we see that it is not true that we have any of the limits $\lim \limits_{n \to \infty}a_1^n + a_2^n + \dots + a_k^n= 0, -1, -2, \dots$. In particular we either have a non-zero limit point, or a non-zero value is attained infinitely many times. Does this appear to be correct?","Here's the problem: Find the radius of convergence of $f(z) = \sum_{n = 0}^{\infty} (a_1^n + \dots + a_k^n)z^n$, where $|a_1| = |a_2| = \dots = |a_k| = 1$, and $a_i \in \mathbb{C}$. Since the series in question is the sum of as $j$ ranges from $1$ to $k$ of the series $f_j(z) = \sum_{n = 0}^{\infty} a_j^n z^n$ you see right away that the radius of convergence $R$ of $f(z)$ is at least $\displaystyle 1$. I'm guessing that maybe the radius of convergence $R$ is exactly $\displaystyle 1$.  I think you might be able to get the answer if you can show that the set $\{a_1^n + \dots + a_k^n : n \ge 0\}$ either has a non-zero limit point inside $\{ z : |z| \le k \}$, or else attains the same non-zero value infinitely many times, because then in either case you can find a subsequence $\{n_j\}$ with $|a_1^{n_j} + \dots + a_k^{n_j}|$ bounded away from $0$, and so $|a_1^{n_j} + \dots + a_k^{n_j}|^{1/n_j} \to 1$ as $n_j \to \infty$. Any thoughts about how to proceed with this idea? Or, is there a far better way to look at this? Edit (*) For $a_j$ and any $N > 0$, you can find a $n > N$ such that $a_j^n$ is arbitrarily close to $1$. You can do this by writing $a_j^n = e^{i n \theta_j}$ and looking at $n \theta _j$ modulo $2 \pi$. Let $b_i = a_i / a_1$. It is not true that we have any of the limits $\lim \limits_{n \to \infty}a_1^n + a_2^n = 0, -1, -2, \dots$. This is because we can find a subsequence $\{n_k\}$ such that $\lim \limits_{n \to \infty}a_1^{n_k} = 1$. Assuming to the contrary for a contradiction, for this subsequence one would have to have $\lim \limits_{n \to \infty} a_1^{n_k}(1 + b_2^{n_k}) = 0, -1, -2, \dots$ so that $\lim \limits_{n \to \infty} (1 + b_2^{n_k}) = 0, -1, -2, \dots$ and therefore $\lim \limits_{n \to \infty} b_2^{n_k} = -1, -2, -3, \dots$ which is impossible by (*). Similarly, it is not true that we have any of the limits $\lim \limits_{n \to \infty}a_1^n + a_2^n + a_3^n= 0, -1, -2, \dots$. Because otherwise, we can find a subsequence $\{n_k\}$ such that $\lim \limits_{n \to \infty}a_1^{n_k} = 1$, and then $\lim \limits_{n \to \infty} (1 + b_2^{n_k} + b_3^{n_k}) = 0, -1, -2, \dots$, and in this case $\lim \limits_{n \to \infty} b_2^{n_k} + b_3^{n_k}= -1, -2, -3, \dots$ which is impossible. Continuing like this, we see that it is not true that we have any of the limits $\lim \limits_{n \to \infty}a_1^n + a_2^n + \dots + a_k^n= 0, -1, -2, \dots$. In particular we either have a non-zero limit point, or a non-zero value is attained infinitely many times. Does this appear to be correct?",,"['complex-analysis', 'power-series']"
78,A question related to Riemann zeta function,A question related to Riemann zeta function,,"Does anyone know why the following statement is correct? Let $f(x)$ be the function whose value on the interval $m\pi<x<(m+1)\pi, m=0,1,2,\cdots$, is $(-1)^m\frac{\pi}{4}$.  Let $0<s<1$. Then $$\int_0^\infty x^{s-1}f(x)\,dx$$ represents an analytic function for $\Re s<1$ and is equal to $$2(1-2^{s+1})\zeta(1-s)$$ for $\Re s<0$. Here $\zeta(\cdot)$ is the Riemann zeta function. Edit. I think now I partially understand the first part. Let $\alpha(x)$ be the function defined by $$\int_0^x u(t)\,dt$$ where $u(t)=(-1)^m$ on $[m\pi,(m+1)\pi], m=0,1,2,\cdots.$ Then the integral $\int_0^\infty x^{s-1}f(x)\,dx$ is equal to the Riemann-Stieltjes integral $\frac{\pi}{4}\int_0^\infty x^{s-1}\,d\alpha$. For $0<s<1$, this can be written as $$\frac{\pi}{4}\left(\int_0^\pi x^{s-1}\,dx-\pi^s-(s-1)\int_{\pi}^\infty\frac{\alpha(x)}{x^{2-s}}\,dx\right),$$ which is analytic in $s$ for $0<\Re s<1$. Now I need to know how to do it for $\Re s\le 0$ and how to make it equal to $2(1-2^{s+1})\zeta(1-s)$ for $\Re s<0$.","Does anyone know why the following statement is correct? Let $f(x)$ be the function whose value on the interval $m\pi<x<(m+1)\pi, m=0,1,2,\cdots$, is $(-1)^m\frac{\pi}{4}$.  Let $0<s<1$. Then $$\int_0^\infty x^{s-1}f(x)\,dx$$ represents an analytic function for $\Re s<1$ and is equal to $$2(1-2^{s+1})\zeta(1-s)$$ for $\Re s<0$. Here $\zeta(\cdot)$ is the Riemann zeta function. Edit. I think now I partially understand the first part. Let $\alpha(x)$ be the function defined by $$\int_0^x u(t)\,dt$$ where $u(t)=(-1)^m$ on $[m\pi,(m+1)\pi], m=0,1,2,\cdots.$ Then the integral $\int_0^\infty x^{s-1}f(x)\,dx$ is equal to the Riemann-Stieltjes integral $\frac{\pi}{4}\int_0^\infty x^{s-1}\,d\alpha$. For $0<s<1$, this can be written as $$\frac{\pi}{4}\left(\int_0^\pi x^{s-1}\,dx-\pi^s-(s-1)\int_{\pi}^\infty\frac{\alpha(x)}{x^{2-s}}\,dx\right),$$ which is analytic in $s$ for $0<\Re s<1$. Now I need to know how to do it for $\Re s\le 0$ and how to make it equal to $2(1-2^{s+1})\zeta(1-s)$ for $\Re s<0$.",,"['complex-analysis', 'special-functions', 'riemann-zeta']"
79,singularity of analytic continuation of $f(z) = \sum_{n=1}^\infty \frac{z^n}{n^2}$,singularity of analytic continuation of,f(z) = \sum_{n=1}^\infty \frac{z^n}{n^2},How to show that all possible collection of analytic continuations of $\displaystyle f(z) = \sum_{n=1}^\infty \frac{z^n}{n^2} $ has singular point at $z = 1$. I know that $f(z)$ converges for $|z| \le 1$. Also is there a theorem that relates the singularity of analytic continuation with circle of convergence?,How to show that all possible collection of analytic continuations of $\displaystyle f(z) = \sum_{n=1}^\infty \frac{z^n}{n^2} $ has singular point at $z = 1$. I know that $f(z)$ converges for $|z| \le 1$. Also is there a theorem that relates the singularity of analytic continuation with circle of convergence?,,['complex-analysis']
80,The continuity assumption in Schwarz's reflection principle,The continuity assumption in Schwarz's reflection principle,,"The Schwarz reflection principle says (Serge Lang, Complex Analysis, 1993): Let $U^+$ be a connected open set in the upper half plane, and suppose that the boundary of $U^+$ contains an open interval $I$ of real numbers. Let $U^-$ be the reflection of $U^+$ across the real axis. If $f$ is a function on $U^+\cup I$, analytic on $U^+$ and continuous on I, and f is real valued on $I$, then $f$ has a unique analytic continuation on $U^+\cup I\cup U^-$. I wonder if the assumption ""$f$ is continuous on $I$"" could be replaced by the weaker assumption that ""$\text{Im}(f)$ is continuous on $I$"", since the analogue reflection theorem for harmonic functions only needs such a weaker assumption. Or is there a counter-example?","The Schwarz reflection principle says (Serge Lang, Complex Analysis, 1993): Let $U^+$ be a connected open set in the upper half plane, and suppose that the boundary of $U^+$ contains an open interval $I$ of real numbers. Let $U^-$ be the reflection of $U^+$ across the real axis. If $f$ is a function on $U^+\cup I$, analytic on $U^+$ and continuous on I, and f is real valued on $I$, then $f$ has a unique analytic continuation on $U^+\cup I\cup U^-$. I wonder if the assumption ""$f$ is continuous on $I$"" could be replaced by the weaker assumption that ""$\text{Im}(f)$ is continuous on $I$"", since the analogue reflection theorem for harmonic functions only needs such a weaker assumption. Or is there a counter-example?",,['complex-analysis']
81,Hausdorff Dimension of Arbitrary Julia Set,Hausdorff Dimension of Arbitrary Julia Set,,"I am looking to find an exact solution to the Hausdorff dimension of a Julia set $J(f)$ for a polynomial $f: z \mapsto z^2 +c$ given an arbitrary $c$. I know this question is known for a number of special cases. For example, if the $c$ is on the boundary of the Mandelbrot set, it has dimension 2. The dimension for $c=0$ is obvious as well. Are there any other cases known exactly? If so, how are they found? I'd imagine there are a number of measurements using box-counting methods to approximate the dimension for various cases. Also, have there been efforts to calculate the dimension of a Julia set for any polynomial or rational function $p : \Bbb{C} \to \Bbb{C}$? Any knowledge of work done in this area or a place to start would be awesome. EDIT: Googling the question led to a number of papers. These are the results I have found: This paper gives the dimension of some set of points, although googling the word ""biaccesible"" only brings up that paper and references to it. This one shows that Julia sets for $c$ arbitrarily close to the boundary of the Mandelbrot set have dimensions arbitrarily close to 2. This one [pdf] gives a number of results: The dimension of $J(f)$ is less than 2 if $f$ has no non-periodic recurrent critical points The Julia set of rational $f$ is hyperbolic $\implies$ The Hausdorff dimension as a function of $c$ is continuous Some other results that seem to require another paper The introduction of this paper Says that for a rational $f$ we have yet to find a Julia set with positive area and doesn't contain the whole Riemann sphere. (Doesn't $z \mapsto z^2$ provide a counterexample? I'm not sure I understand this one) I also proves a result about the Julia set of a $\sin $ function. A paper from Harvard [pdf] gives ways of calculating the dimension numerically, and proves that the Hausdorff dimension is continuous from the Feigenbaum point (is this the same one from bifurcation diagrams?) to 1/4. I'm going to read through more and these ones more carefully. In the meantime any guidance would help.","I am looking to find an exact solution to the Hausdorff dimension of a Julia set $J(f)$ for a polynomial $f: z \mapsto z^2 +c$ given an arbitrary $c$. I know this question is known for a number of special cases. For example, if the $c$ is on the boundary of the Mandelbrot set, it has dimension 2. The dimension for $c=0$ is obvious as well. Are there any other cases known exactly? If so, how are they found? I'd imagine there are a number of measurements using box-counting methods to approximate the dimension for various cases. Also, have there been efforts to calculate the dimension of a Julia set for any polynomial or rational function $p : \Bbb{C} \to \Bbb{C}$? Any knowledge of work done in this area or a place to start would be awesome. EDIT: Googling the question led to a number of papers. These are the results I have found: This paper gives the dimension of some set of points, although googling the word ""biaccesible"" only brings up that paper and references to it. This one shows that Julia sets for $c$ arbitrarily close to the boundary of the Mandelbrot set have dimensions arbitrarily close to 2. This one [pdf] gives a number of results: The dimension of $J(f)$ is less than 2 if $f$ has no non-periodic recurrent critical points The Julia set of rational $f$ is hyperbolic $\implies$ The Hausdorff dimension as a function of $c$ is continuous Some other results that seem to require another paper The introduction of this paper Says that for a rational $f$ we have yet to find a Julia set with positive area and doesn't contain the whole Riemann sphere. (Doesn't $z \mapsto z^2$ provide a counterexample? I'm not sure I understand this one) I also proves a result about the Julia set of a $\sin $ function. A paper from Harvard [pdf] gives ways of calculating the dimension numerically, and proves that the Hausdorff dimension is continuous from the Feigenbaum point (is this the same one from bifurcation diagrams?) to 1/4. I'm going to read through more and these ones more carefully. In the meantime any guidance would help.",,"['complex-analysis', 'reference-request', 'fractals', 'geometric-measure-theory', 'open-problem']"
82,Dirichlet Problem on an annulus.,Dirichlet Problem on an annulus.,,"Having found the solution for the Dirichlet problem in the region $A=\{x+iy: 0\leq y\leq 1\}$ such that $u(x,0)=0$ and $u(x,1)=1$ to be $u(x,y)=y$, I am asked to find, using conformal maps, the solution in $B=\{z:r_1\leq|z| \leq r_2 \}$ such that $u(z)=0$ on the internal disc and $u(z)=1$ on the external one. Now, I could find a conformal map from $A$ onto $B$ to be $z \rightarrow e^{i((z-i)\log r_1- z\log r_2)}$ But I think I need a map from $B$ onto $A$ instead and this one is obviously not invertible.. Once I find this conformal map I would be done as the solution wound simply be the composition of the solution in the strip and the conformal map. EDIT1: I can find a solution quite easily which is $u(x,y)= \frac{1}{\log\frac{r_2}{r1}}\log(\frac{\sqrt{x^2+y^2}}{r_1})$ but I would like to use the conformal map method! EDIT2: continuing on mrs's hint: having found the solution, we have that if there is a conformal map $f$ from $B$ onto $A$ then $f(x+iy)=u_1(x,y)+i\ u_2(x,y)$ where $u_2=u$ the solution we found, then we use C-R equations to work out the harmonic conjugate of $u$ and we find that $f(x,y)=\frac{1}{\log\frac{r_2}{r1}}(\frac{r_2}{r_1}\tan^{-1}\frac{x}{y}+ i\log\frac{\sqrt{x^2+y^2}}{r_1})$ EDIT3: the $f$ I found, sadly, has two problems: it is possibly not holomorphic when $y=0$ and the image of the annulus under it is only a rectangle...","Having found the solution for the Dirichlet problem in the region $A=\{x+iy: 0\leq y\leq 1\}$ such that $u(x,0)=0$ and $u(x,1)=1$ to be $u(x,y)=y$, I am asked to find, using conformal maps, the solution in $B=\{z:r_1\leq|z| \leq r_2 \}$ such that $u(z)=0$ on the internal disc and $u(z)=1$ on the external one. Now, I could find a conformal map from $A$ onto $B$ to be $z \rightarrow e^{i((z-i)\log r_1- z\log r_2)}$ But I think I need a map from $B$ onto $A$ instead and this one is obviously not invertible.. Once I find this conformal map I would be done as the solution wound simply be the composition of the solution in the strip and the conformal map. EDIT1: I can find a solution quite easily which is $u(x,y)= \frac{1}{\log\frac{r_2}{r1}}\log(\frac{\sqrt{x^2+y^2}}{r_1})$ but I would like to use the conformal map method! EDIT2: continuing on mrs's hint: having found the solution, we have that if there is a conformal map $f$ from $B$ onto $A$ then $f(x+iy)=u_1(x,y)+i\ u_2(x,y)$ where $u_2=u$ the solution we found, then we use C-R equations to work out the harmonic conjugate of $u$ and we find that $f(x,y)=\frac{1}{\log\frac{r_2}{r1}}(\frac{r_2}{r_1}\tan^{-1}\frac{x}{y}+ i\log\frac{\sqrt{x^2+y^2}}{r_1})$ EDIT3: the $f$ I found, sadly, has two problems: it is possibly not holomorphic when $y=0$ and the image of the annulus under it is only a rectangle...",,['complex-analysis']
83,How to find the number of roots using Rouche theorem?,How to find the number of roots using Rouche theorem?,,"Find the number of roots $f(z)=z^{10}+10z+9$ in $D(0,1)$. I want to find $g(z)$ s.t. $|f(z)-g(z)|<|g(z)|$, but I cannot. Any hint is appreciated.","Find the number of roots $f(z)=z^{10}+10z+9$ in $D(0,1)$. I want to find $g(z)$ s.t. $|f(z)-g(z)|<|g(z)|$, but I cannot. Any hint is appreciated.",,['complex-analysis']
84,Zeros of a complex polynomial,Zeros of a complex polynomial,,"The question is: Show that $$ P(z) = z^4 + 2z^3 + 3z^2 + z +2$$ has exactly one root in each quadrant of the complex plane. My initial thought was to use Rouche's Theorem (since that's generally what I use to find how many roots a complex polynomial has), but the more I think about it, the more I'm not sure how to make it work. Here is my attempt: First, pick a radius for a circle that can encompass all four roots of the polynomial. For simplicity sake (in my opinion), I went with |z| = 5. Setting $$f(z) = z^4$$ and $$g(z) = 2z^3 + 3z^2 + z + 2$$ I get |f(z)| = 625 and |g(z)| = 332, so by Rouche's Theorem we have four roots in the disc. Now, my thought was that I could somehow seperate the quadrants by breaking up my circle into quarter-circles (like four slices of pie) and applying Rouche's Theorem again on each of these new domains. However, finding the place on the boundary where the value hits its max for some f(z) or g(z) would be messy (at best), since if I juse use |z| = 5, I'm right back where I started. There's also the issue that these zeroes may occur on the boundary, so in the real/imaginary axis, which wouldn't be what I'm trying to show. So now, I'm just stuck, so if anyone can see how to tackle this, it would be greatly appreciated.","The question is: Show that $$ P(z) = z^4 + 2z^3 + 3z^2 + z +2$$ has exactly one root in each quadrant of the complex plane. My initial thought was to use Rouche's Theorem (since that's generally what I use to find how many roots a complex polynomial has), but the more I think about it, the more I'm not sure how to make it work. Here is my attempt: First, pick a radius for a circle that can encompass all four roots of the polynomial. For simplicity sake (in my opinion), I went with |z| = 5. Setting $$f(z) = z^4$$ and $$g(z) = 2z^3 + 3z^2 + z + 2$$ I get |f(z)| = 625 and |g(z)| = 332, so by Rouche's Theorem we have four roots in the disc. Now, my thought was that I could somehow seperate the quadrants by breaking up my circle into quarter-circles (like four slices of pie) and applying Rouche's Theorem again on each of these new domains. However, finding the place on the boundary where the value hits its max for some f(z) or g(z) would be messy (at best), since if I juse use |z| = 5, I'm right back where I started. There's also the issue that these zeroes may occur on the boundary, so in the real/imaginary axis, which wouldn't be what I'm trying to show. So now, I'm just stuck, so if anyone can see how to tackle this, it would be greatly appreciated.",,"['complex-analysis', 'polynomials']"
85,"a) Prove that $f$ has a removable singularity if $f'$ does; b) Evaluate $\int_0^\infty\frac{\log x}{(1+x)^3}\,dx$",a) Prove that  has a removable singularity if  does; b) Evaluate,"f f' \int_0^\infty\frac{\log x}{(1+x)^3}\,dx","a) Let $\,f\,$ be an analytic function in the punctured disk $\,\{z\;\;;\;\;0<|z-a|<r\,\,,\,r\in\mathbb R^+\}\,$ . Prove that if the limit $\displaystyle{\lim_{z\to a}f'(z)}\,$ exists finitely, then $\,a\,$ is a removable singularity of $\,f\,$ My solution and doubt: If we develop $\,f\,$ is a Laurent series around $\,a\,$ we get $$f(z)=\frac{a_{-k}}{(z-a)^k}+\frac{a_{-k+1}}{(z-a)^{k-1}}+\ldots +\frac{a_{-1}}{z-a}+a_0+a_1(z-a)+\ldots \Longrightarrow$$ $$\Longrightarrow f'(z)=-\frac{ka_{-k}}{(z-a)^{k+1}}-\ldots -\frac{a_{-1}}{(z-a)^2}+a_1+...$$ and since $\,\displaystyle{\lim_{z\to a}f'(z)}\,$ exists finitely then it must be that $$a_{-k}=a_{-k+1}=...=a_{-1}=0$$ getting that the above series for $\,f\,$ is, in fact, a Taylor one and thus $\,f\,$ has a removable singularity at $\,a\,$ . My doubt: is there any other ""more obvious"" or more elementary way to solve the above without having to resource to term-term differentiating that Laurent series? b) Evaluate, using some complex contour, the integral  $$\int_0^\infty\frac{\log x}{(1+x)^3}\,dx$$ First doubt: it is given in this exercise the hint(?) to use the function $$\frac{\log^2z}{(1+z)^3}$$Please do note the square in the logarithm! Now, is this some typo or perhaps it really helps to do it this way? After checking with WA, the original real integral equals $\,-1/2\,$ and, in fact, it is doable without need to use complex functions, and though the result is rather ugly it nevertheless is an elementary function (rational with logarithms, no hypergeometric or Li or stuff). The real integral with the logarithm squared gives the beautiful result of $\,\pi^2/6\,$ but, again, I'm not sure whether ""the hint"" is a typo. Second doubt: In either case (logarithm squared or not), what would be the best contour to choose? I though using one quarter of the circle $\,\{z\;\;;\;\;|z|=R>1\}\,$ minus one quarter of the circle $\,\{z\;\;;\;\;|z|=\epsilon\,\,,0<\epsilon<<R\}\,$,  in the first quadrant both, because $(i)\,$ to get the correct limits on the $\,x\,$-axis when passing to the limits $\,R\to\infty\,\,,\,\epsilon\to 0\,$ $(ii)\,$ To avoid the singularity $\,z=0\,$ of the logarithm (not to mention going around it and changing logarithmic branch and horrible things like this!). Well, I'm pretty stuck here with the evaluations on the different segments of the path, besides being baffled by ""the hint"",  and I definitely need some help here. As before: these exercises are supposed to be for a first course in complex variable and, thus, I think they should be more or less ""elementary"", though this integral looks really evil. For the time you've taken already to read this long post I already thank you, and any help, hint or ideas will be very much appreciated.","a) Let $\,f\,$ be an analytic function in the punctured disk $\,\{z\;\;;\;\;0<|z-a|<r\,\,,\,r\in\mathbb R^+\}\,$ . Prove that if the limit $\displaystyle{\lim_{z\to a}f'(z)}\,$ exists finitely, then $\,a\,$ is a removable singularity of $\,f\,$ My solution and doubt: If we develop $\,f\,$ is a Laurent series around $\,a\,$ we get $$f(z)=\frac{a_{-k}}{(z-a)^k}+\frac{a_{-k+1}}{(z-a)^{k-1}}+\ldots +\frac{a_{-1}}{z-a}+a_0+a_1(z-a)+\ldots \Longrightarrow$$ $$\Longrightarrow f'(z)=-\frac{ka_{-k}}{(z-a)^{k+1}}-\ldots -\frac{a_{-1}}{(z-a)^2}+a_1+...$$ and since $\,\displaystyle{\lim_{z\to a}f'(z)}\,$ exists finitely then it must be that $$a_{-k}=a_{-k+1}=...=a_{-1}=0$$ getting that the above series for $\,f\,$ is, in fact, a Taylor one and thus $\,f\,$ has a removable singularity at $\,a\,$ . My doubt: is there any other ""more obvious"" or more elementary way to solve the above without having to resource to term-term differentiating that Laurent series? b) Evaluate, using some complex contour, the integral  $$\int_0^\infty\frac{\log x}{(1+x)^3}\,dx$$ First doubt: it is given in this exercise the hint(?) to use the function $$\frac{\log^2z}{(1+z)^3}$$Please do note the square in the logarithm! Now, is this some typo or perhaps it really helps to do it this way? After checking with WA, the original real integral equals $\,-1/2\,$ and, in fact, it is doable without need to use complex functions, and though the result is rather ugly it nevertheless is an elementary function (rational with logarithms, no hypergeometric or Li or stuff). The real integral with the logarithm squared gives the beautiful result of $\,\pi^2/6\,$ but, again, I'm not sure whether ""the hint"" is a typo. Second doubt: In either case (logarithm squared or not), what would be the best contour to choose? I though using one quarter of the circle $\,\{z\;\;;\;\;|z|=R>1\}\,$ minus one quarter of the circle $\,\{z\;\;;\;\;|z|=\epsilon\,\,,0<\epsilon<<R\}\,$,  in the first quadrant both, because $(i)\,$ to get the correct limits on the $\,x\,$-axis when passing to the limits $\,R\to\infty\,\,,\,\epsilon\to 0\,$ $(ii)\,$ To avoid the singularity $\,z=0\,$ of the logarithm (not to mention going around it and changing logarithmic branch and horrible things like this!). Well, I'm pretty stuck here with the evaluations on the different segments of the path, besides being baffled by ""the hint"",  and I definitely need some help here. As before: these exercises are supposed to be for a first course in complex variable and, thus, I think they should be more or less ""elementary"", though this integral looks really evil. For the time you've taken already to read this long post I already thank you, and any help, hint or ideas will be very much appreciated.",,['complex-analysis']
86,Using conjugate differential to determine existence of a harmonic conjugate?,Using conjugate differential to determine existence of a harmonic conjugate?,,"Consider $u(z)=\ln(|z|^2)=\ln(x^2+y^2)$. I know that $u$ does not have a harmonic conjugate from $\mathbb{C}\setminus\{0\}\to\mathbb{R}$ but playing around with partial derivatives and integrating around the unit circle. However, I know that a function $u$ has a harmonic conjugate if and only if its conjugate differential $*du$ is exact. This is defined as $*du=-\frac{\partial u}{\partial y}dx+\frac{\partial u}{\partial x}dy$. I calculate this to be $$ *du=\frac{-2y}{x^2+y^2}dx+\frac{2x}{x^2+y^2}dy $$ so I would assume this is not exact. Is there a way to see that easily? Is this how the criterion for existence or nonexistence of a harmonic conjugate is usually applied in terms of the conjugate differential? Thanks.","Consider $u(z)=\ln(|z|^2)=\ln(x^2+y^2)$. I know that $u$ does not have a harmonic conjugate from $\mathbb{C}\setminus\{0\}\to\mathbb{R}$ but playing around with partial derivatives and integrating around the unit circle. However, I know that a function $u$ has a harmonic conjugate if and only if its conjugate differential $*du$ is exact. This is defined as $*du=-\frac{\partial u}{\partial y}dx+\frac{\partial u}{\partial x}dy$. I calculate this to be $$ *du=\frac{-2y}{x^2+y^2}dx+\frac{2x}{x^2+y^2}dy $$ so I would assume this is not exact. Is there a way to see that easily? Is this how the criterion for existence or nonexistence of a harmonic conjugate is usually applied in terms of the conjugate differential? Thanks.",,['complex-analysis']
87,Is it Possible to have Two Distinct Analytic Functions with the Same Real Part?,Is it Possible to have Two Distinct Analytic Functions with the Same Real Part?,,"My professor says given the real part $u$ of an analytic function $f$ defined on a domain $D\subset \mathbb{C}$, that we can't rule out the possibility that there could exist some other analytic function $g$, distinct from $f$ beyond just the addition of a constant, defined on a domain $E\subset \mathbb{C}$ either disjoint from, or not homeomorphic to, $D$, provided that $f$ is not analytic on $E$. Since differentiating $u$ with respect to one variable and then integrating it with respect to the other completely determines the imaginary part, what this says to me is that $u$ would have to either produce different partial derivatives on $D$ and $E$ respectively, or $\frac{\partial u}{\partial x}$ different primitives. The case of D and E being disjoint is trivial, but can anyone give me an example for D and E overlapping but non-homeomorphic?","My professor says given the real part $u$ of an analytic function $f$ defined on a domain $D\subset \mathbb{C}$, that we can't rule out the possibility that there could exist some other analytic function $g$, distinct from $f$ beyond just the addition of a constant, defined on a domain $E\subset \mathbb{C}$ either disjoint from, or not homeomorphic to, $D$, provided that $f$ is not analytic on $E$. Since differentiating $u$ with respect to one variable and then integrating it with respect to the other completely determines the imaginary part, what this says to me is that $u$ would have to either produce different partial derivatives on $D$ and $E$ respectively, or $\frac{\partial u}{\partial x}$ different primitives. The case of D and E being disjoint is trivial, but can anyone give me an example for D and E overlapping but non-homeomorphic?",,['complex-analysis']
88,Complex integral with essential singularity at 0,Complex integral with essential singularity at 0,,"I need help in solving the following problem in complex calculus. I need to calculate this real integral: $$ \int_0^{2\pi} e^{\cos{\theta}}\cos(\sin\theta) \,\,\, d\theta $$ I think that the best method is to do the substitution $z=re^{i\theta}$, from which we have $d\theta = \frac{dz}{iz}$, $\cos\theta=\frac{1}{2}(z+\frac{1}{z})$ and so on. The integral then becomes (without constants) $$ \oint_{|z|=r} e^{\frac{z}{2}}e^{\frac{1}{2z}}\frac{z^4-6z^2+1}{z(z^2-1)} \,\,\,dz $$ At this point I am unable to calculate the residue at the essential singularity in 0, because the manipulation of Laurent series rapidly becomes utterly complicated and I don't see any simple way to find the final coefficient of $1/z$. So, which is the way to handle this integral? Another substitution?","I need help in solving the following problem in complex calculus. I need to calculate this real integral: $$ \int_0^{2\pi} e^{\cos{\theta}}\cos(\sin\theta) \,\,\, d\theta $$ I think that the best method is to do the substitution $z=re^{i\theta}$, from which we have $d\theta = \frac{dz}{iz}$, $\cos\theta=\frac{1}{2}(z+\frac{1}{z})$ and so on. The integral then becomes (without constants) $$ \oint_{|z|=r} e^{\frac{z}{2}}e^{\frac{1}{2z}}\frac{z^4-6z^2+1}{z(z^2-1)} \,\,\,dz $$ At this point I am unable to calculate the residue at the essential singularity in 0, because the manipulation of Laurent series rapidly becomes utterly complicated and I don't see any simple way to find the final coefficient of $1/z$. So, which is the way to handle this integral? Another substitution?",,"['complex-analysis', 'definite-integrals']"
89,"Prove that if $ f : D(0,1) \to D(0,1) $ is analytic with $ f(0) = 0 $, then $\frac{f(z)}{z} $ has a removable singularity at 0","Prove that if  is analytic with , then  has a removable singularity at 0"," f : D(0,1) \to D(0,1)   f(0) = 0  \frac{f(z)}{z} ","Prove that if $ f : D(0,1) \to D(0,1) $ is analytic with $ f(0) = 0 $, then $ g(z) = \frac{f(z)}{z} $ has a removable singularity at 0. My thoughts so far: Is this even a question? If $f$ is analytic, then we can write $ f(z) = \sum_{n=0}^\infty a_n z^n $ valid for all $ z \in D(0,1) $. Then $ f(0) = 0 $ gives that $ a_0 = 0 $. Then we can write a Laurent series $ g(z) = \frac{a_0}{z} + \sum_{n = 0}^\infty a_{n+1} z^n $, and as $ a_0 = 0 $, the point 0 is necessarily a removable singularity (and it's already been removed by setting $ f(0) = 0 $!) Am I missing something? Thanks","Prove that if $ f : D(0,1) \to D(0,1) $ is analytic with $ f(0) = 0 $, then $ g(z) = \frac{f(z)}{z} $ has a removable singularity at 0. My thoughts so far: Is this even a question? If $f$ is analytic, then we can write $ f(z) = \sum_{n=0}^\infty a_n z^n $ valid for all $ z \in D(0,1) $. Then $ f(0) = 0 $ gives that $ a_0 = 0 $. Then we can write a Laurent series $ g(z) = \frac{a_0}{z} + \sum_{n = 0}^\infty a_{n+1} z^n $, and as $ a_0 = 0 $, the point 0 is necessarily a removable singularity (and it's already been removed by setting $ f(0) = 0 $!) Am I missing something? Thanks",,['complex-analysis']
90,"If the roots of $z^4+az^3+bz^2+z$ are distinct and concyclic in the complex plane, does $ab\in\mathbb R$ imply $1<ab<9$?","If the roots of  are distinct and concyclic in the complex plane, does  imply ?",z^4+az^3+bz^2+z ab\in\mathbb R 1<ab<9,"HMMT February 2022, Team Round, Problem 6 (proposed by Akash Das ) is: Let $\operatorname{\it P\!}{\left(x\right)}=x^4+ax^3+bx^2+x$ be a polynomial with four distinct roots that lie on a circle in the complex plane. Prove that $ab\neq9$ . Its solution may be found here . Recently, certain netizens claim ed that there exists a stronger result when $ab$ is real: Let $P(z)=z^4+az^3+bz^2+z$ be a polynomial with four distinct roots that are concyclic in the complex plane; then $ab\in\mathbb R\implies1<ab<9$ . Nevertheless, I could find neither any proof nor any counterexample of it. Does the above proposition hold?  (And what if $ab\in{\mathbb C\setminus\mathbb R}$ ?) Edit. It appears that when $ab\in{\mathbb C\setminus\mathbb R}$ , $ab$ can take any values in the complex plane other than the real axis. Here is a simulation:","HMMT February 2022, Team Round, Problem 6 (proposed by Akash Das ) is: Let be a polynomial with four distinct roots that lie on a circle in the complex plane. Prove that . Its solution may be found here . Recently, certain netizens claim ed that there exists a stronger result when is real: Let be a polynomial with four distinct roots that are concyclic in the complex plane; then . Nevertheless, I could find neither any proof nor any counterexample of it. Does the above proposition hold?  (And what if ?) Edit. It appears that when , can take any values in the complex plane other than the real axis. Here is a simulation:",\operatorname{\it P\!}{\left(x\right)}=x^4+ax^3+bx^2+x ab\neq9 ab P(z)=z^4+az^3+bz^2+z ab\in\mathbb R\implies1<ab<9 ab\in{\mathbb C\setminus\mathbb R} ab\in{\mathbb C\setminus\mathbb R} ab,"['complex-analysis', 'inequality', 'polynomials', 'contest-math', 'plane-geometry']"
91,Doubly periodic solutions to $\frac{|\partial w|^2}{(1+|w|^2)^2} = C^2$?,Doubly periodic solutions to ?,\frac{|\partial w|^2}{(1+|w|^2)^2} = C^2,"I am interested in solutions to $$\frac{|\partial_z w|^2}{(1+|w|^2)^2} = C^2$$ for $C>0$ a constant and $w = w(z,\bar z)$ is allowed to have poles. For example $\tan(|z|)$ is a solution. But I am interested in solutions that are doubly periodic in the complex plane, $w(z+\lambda) = w(z)$ for $\lambda \in \Lambda$ , a lattice. Note $w$ need not be holomorphic. I am interested in this in the physics context of 2D skyrmion crystals, which are naturally a doubly periodic map from the plane to a sphere. In the natural $\Bbb{CP}^1$ parameterization of the sphere equations like this pop up all the time for interesting physics. I think it describes a function $w$ which maps the torus to the sphere in some ""constant"" way, since the natural Riemannian metric on the sphere is $\frac{|dz|^2}{(1+|z|^2)^2}$ -- in fact any more insight into this equation would be helpful.","I am interested in solutions to for a constant and is allowed to have poles. For example is a solution. But I am interested in solutions that are doubly periodic in the complex plane, for , a lattice. Note need not be holomorphic. I am interested in this in the physics context of 2D skyrmion crystals, which are naturally a doubly periodic map from the plane to a sphere. In the natural parameterization of the sphere equations like this pop up all the time for interesting physics. I think it describes a function which maps the torus to the sphere in some ""constant"" way, since the natural Riemannian metric on the sphere is -- in fact any more insight into this equation would be helpful.","\frac{|\partial_z w|^2}{(1+|w|^2)^2} = C^2 C>0 w = w(z,\bar z) \tan(|z|) w(z+\lambda) = w(z) \lambda \in \Lambda w \Bbb{CP}^1 w \frac{|dz|^2}{(1+|z|^2)^2}","['complex-analysis', 'differential-geometry', 'partial-differential-equations']"
92,My contour integrations seem to contradict the residue theorem.,My contour integrations seem to contradict the residue theorem.,,"I have been studying complex integration and I have been calculating some simple contour integrals. By integrating the function $f(z) = \frac{1}{z}$ around the unit circle centered on the origin I get $\int_{C} = 2\pi i$ as expected by the residue theorem. I then repeated using a different countour, a circle of radius 1 centered on $z=3$ , $g(t) = 3 + e^{it}$ where $0 < t < 2\pi$ where I get an integral of zero, again as predicted by the residue theorem. (The singularity at $z=0$ is not inside this contour integral). I then tried to integrate around the circle with center $z=0$ and radius 4. I was expecting/hoping to get the value $2\pi i$ since the function $f(z) = \frac{1}{z}$ has a single singularity included inside it's contour. Although this is probably the most simple application of the residue theorem that anyone applies when first studying the topic, however, I get an integral of zero. Surely the residue theorem would dictate a value of $2\pi i$ around this countour as it includes the one and only singularity at $z = 0$ ? I expect that I am misunderstanding some subtlety of the logarithm function. I have included my working below: $$f(z) = \frac{1}{z}$$ $$g(t) = 3 + 4e^{it} \quad 0 < t < 2\pi$$ $$\int_{g}f(g(t))g'(t)dt = \int_{0}^{2\pi}\dfrac{4ie^{it}}{3+4e^{it}}dt = \ln(3+4e^{2\pi i}) - \ln(3 + 4e^{0}) = \ln(7) - \ln(7) = 0$$","I have been studying complex integration and I have been calculating some simple contour integrals. By integrating the function around the unit circle centered on the origin I get as expected by the residue theorem. I then repeated using a different countour, a circle of radius 1 centered on , where where I get an integral of zero, again as predicted by the residue theorem. (The singularity at is not inside this contour integral). I then tried to integrate around the circle with center and radius 4. I was expecting/hoping to get the value since the function has a single singularity included inside it's contour. Although this is probably the most simple application of the residue theorem that anyone applies when first studying the topic, however, I get an integral of zero. Surely the residue theorem would dictate a value of around this countour as it includes the one and only singularity at ? I expect that I am misunderstanding some subtlety of the logarithm function. I have included my working below:",f(z) = \frac{1}{z} \int_{C} = 2\pi i z=3 g(t) = 3 + e^{it} 0 < t < 2\pi z=0 z=0 2\pi i f(z) = \frac{1}{z} 2\pi i z = 0 f(z) = \frac{1}{z} g(t) = 3 + 4e^{it} \quad 0 < t < 2\pi \int_{g}f(g(t))g'(t)dt = \int_{0}^{2\pi}\dfrac{4ie^{it}}{3+4e^{it}}dt = \ln(3+4e^{2\pi i}) - \ln(3 + 4e^{0}) = \ln(7) - \ln(7) = 0,"['complex-analysis', 'logarithms', 'complex-integration', 'residue-calculus']"
93,What is the value of $\ln(e^{2i\pi})$?,What is the value of ?,\ln(e^{2i\pi}),"According to Euler's formula, $e^{i\theta} = \cos\theta + i\sin\theta;$ so, $e^{2\pi i} = 1.$ And $\ln(1) = 0.$ On the other hand, $\ln(e^{i\theta}) = i\theta,$ so $\ln(e^{2\pi i}) = 2\pi i$ . Is $\ln(e^{2i\pi})$ equal to $0$ or $2\pi i$ ?","According to Euler's formula, so, And On the other hand, so . Is equal to or ?","e^{i\theta} = \cos\theta + i\sin\theta; e^{2\pi i} = 1. \ln(1) = 0. \ln(e^{i\theta}) = i\theta, \ln(e^{2\pi i}) = 2\pi i \ln(e^{2i\pi}) 0 2\pi i","['complex-analysis', 'logarithms']"
94,Asymptotic expansion of q-Pochhammer symbol near q = 1,Asymptotic expansion of q-Pochhammer symbol near q = 1,,"I'd like to understand the asymptotics of the q-Pochhammer symbol $(a;q)_\infty$ as $q \to 1^-$ with $a$ complex, where $$(a;q)_\infty = \prod_{n = 0}^\infty (1- aq^n).$$ More specifically, I'm actually just interested in the limiting behavior as $a$ approaches an arbitrary point on the unit circle in the complex plane: $(q^x e^{i \theta}; q)_\infty$ as $q \to 1^-$ , with $x$ and $\theta$ real.  I managed to find a partial answer in this paper , which in theorem 3.2 gives the asymptotic expansion $$(q^x; q)_\infty = \frac{\sqrt{2\pi}}{\Gamma(x)}\left(\ln\frac{1}{q}\right)^{\frac{1}{2}-x} \prod_{k = 0, k \neq 1}^\infty \exp\left[\frac{\zeta(2-k)}{k!} B_k(x) (\ln q)^{k-1}\right]$$ for $x > 0$ , where $\zeta(2-k)$ is the Riemann zeta function and $B_k(x)$ are Bernoulli polynomials.  This is just the $\theta = 0$ , $x > 0$ version of what I'm looking for.  Doing some numerical checks, it seems that this expansion is still valid when extended to complex $x$ (at least in some neighborhood of $x = 0$ , which is all I've checked), but this generalization isn't sufficient to get the expansion I want: in the expansion above, the argument $a = q^x$ always approaches 1 as $q \to 1$ even for complex $x$ , whereas I want $a = q^x e^{i\theta}$ to approach an arbitrary point on the unit circle. Is there some other expansion that applies in the regime I'm interested in?  Or perhaps is there a way to modify the above expansion to work for general $\theta$ ?","I'd like to understand the asymptotics of the q-Pochhammer symbol as with complex, where More specifically, I'm actually just interested in the limiting behavior as approaches an arbitrary point on the unit circle in the complex plane: as , with and real.  I managed to find a partial answer in this paper , which in theorem 3.2 gives the asymptotic expansion for , where is the Riemann zeta function and are Bernoulli polynomials.  This is just the , version of what I'm looking for.  Doing some numerical checks, it seems that this expansion is still valid when extended to complex (at least in some neighborhood of , which is all I've checked), but this generalization isn't sufficient to get the expansion I want: in the expansion above, the argument always approaches 1 as even for complex , whereas I want to approach an arbitrary point on the unit circle. Is there some other expansion that applies in the regime I'm interested in?  Or perhaps is there a way to modify the above expansion to work for general ?","(a;q)_\infty q \to 1^- a (a;q)_\infty = \prod_{n = 0}^\infty (1- aq^n). a (q^x e^{i \theta}; q)_\infty q \to 1^- x \theta (q^x; q)_\infty = \frac{\sqrt{2\pi}}{\Gamma(x)}\left(\ln\frac{1}{q}\right)^{\frac{1}{2}-x} \prod_{k = 0, k \neq 1}^\infty \exp\left[\frac{\zeta(2-k)}{k!} B_k(x) (\ln q)^{k-1}\right] x > 0 \zeta(2-k) B_k(x) \theta = 0 x > 0 x x = 0 a = q^x q \to 1 x a = q^x e^{i\theta} \theta","['complex-analysis', 'asymptotics', 'special-functions', 'infinite-product', 'pochhammer-symbol']"
95,Residue Theorem Integral,Residue Theorem Integral,,"Studying for qualifying exams, I came across the following problem: using complex analysis, compute $$\int_{-\infty}^{\infty}\frac{x^2\sin(\pi x)}{x^3-1}dx $$ I decided to use the integrand $f(z)=\frac{z^2e^{i\pi z}}{z^3-1}$ (the goal is to take the imaginary part in the end), and I found that $f$ has a removable singularity at $1$ . Now, it seems to me that $|f(Re^{i\theta})|=O(e^R/R)$ , so a semicircle countour won't work. I also tried to use a rectangular contour (with height $2\pi$ ) and the sides do vanish as $R\to\infty$ , but since there are quadratic terms in the integrand, I am not able to get a simple result and conclude via the residue theorem. Any ideas? Edit: With help from the comment, I think I have a solution. Taking $f(z)$ as before, we see that $f(z)=e^{i\pi z}\cdot g(z)$ , where $g(z)=\frac{z^2}{z^3-1}$ , and since $|g(Re^{i\theta})|\leq \frac{C}{R}$ , we invoke Jordan's lemma to say that $\lim_{R\to\infty}\int_{\Gamma_R}f(z)=0$ , where $\Gamma_R$ is the upper semi-circle of radius $R$ centered at $0$ . Therefore, we get: $$\int_{-\infty}^{\infty}\frac{xe^{i\pi x}}{x^3-1}=2\pi i Res_{e^{2\pi i/3}}f $$ Now, $$Res_{e^{2\pi i/3}}f=\lim_{z\to e^{2\pi i/3}}\frac{ze^{i\pi z}}{(z-1)(z-e^{4i\pi /3})}=\frac{e^{2\pi i/3}exp\{i\pi e^{2\pi i/3}\}}{(e^{2\pi i/3}-1)(e^{2\pi i/3}-e^{4\pi i/3})} $$ This will simplify (using the fact that the roots of unity sum to $0$ ) to $exp\{i\pi( e^{2\pi i/3}-2/3)\}$ Now, $Im\{2\pi i \exp\{i\pi( e^{2\pi i/3}-2/3)\}\}=2\pi e^{-\pi \sin(2\pi/3)}\cos[\cos(2\pi/3)-2/3]$ . I don't think this should be the answer, but I am unable to figure out where I went wrong.","Studying for qualifying exams, I came across the following problem: using complex analysis, compute I decided to use the integrand (the goal is to take the imaginary part in the end), and I found that has a removable singularity at . Now, it seems to me that , so a semicircle countour won't work. I also tried to use a rectangular contour (with height ) and the sides do vanish as , but since there are quadratic terms in the integrand, I am not able to get a simple result and conclude via the residue theorem. Any ideas? Edit: With help from the comment, I think I have a solution. Taking as before, we see that , where , and since , we invoke Jordan's lemma to say that , where is the upper semi-circle of radius centered at . Therefore, we get: Now, This will simplify (using the fact that the roots of unity sum to ) to Now, . I don't think this should be the answer, but I am unable to figure out where I went wrong.","\int_{-\infty}^{\infty}\frac{x^2\sin(\pi x)}{x^3-1}dx
 f(z)=\frac{z^2e^{i\pi z}}{z^3-1} f 1 |f(Re^{i\theta})|=O(e^R/R) 2\pi R\to\infty f(z) f(z)=e^{i\pi z}\cdot g(z) g(z)=\frac{z^2}{z^3-1} |g(Re^{i\theta})|\leq \frac{C}{R} \lim_{R\to\infty}\int_{\Gamma_R}f(z)=0 \Gamma_R R 0 \int_{-\infty}^{\infty}\frac{xe^{i\pi x}}{x^3-1}=2\pi i Res_{e^{2\pi i/3}}f
 Res_{e^{2\pi i/3}}f=\lim_{z\to e^{2\pi i/3}}\frac{ze^{i\pi z}}{(z-1)(z-e^{4i\pi /3})}=\frac{e^{2\pi i/3}exp\{i\pi e^{2\pi i/3}\}}{(e^{2\pi i/3}-1)(e^{2\pi i/3}-e^{4\pi i/3})}
 0 exp\{i\pi( e^{2\pi i/3}-2/3)\} Im\{2\pi i \exp\{i\pi( e^{2\pi i/3}-2/3)\}\}=2\pi e^{-\pi \sin(2\pi/3)}\cos[\cos(2\pi/3)-2/3]","['complex-analysis', 'residue-calculus']"
96,Understanding the global residue theorem,Understanding the global residue theorem,,"I am studying the global residue theorem which applies for multivariate residues. The theorem is reported in the following references e.g. ( 1 ) (Eq.87) , ( 2 ) (Eq. 109) in different formulations, that now I would try to understand.  It is unnecessary to reveal that my education is not from math studies, so I am sorry if I won't be precise. First of all, let us focus on the following definition ( 1 ) (see Eq.87). Theorem 2. (Global residue theorem). Let $\omega$ denote a   meromorphic $n$ -form defined on a compact manifold $M$ . Given an open   covering $\{U_i\}$ , let $\omega$ take the local form $$ \omega=\frac{h(z)dz_1 ∧ · · · ∧ dz_n}{f_1(z)· · · f_n(z)} $$ where $f(z) = (f_1(z), . . . , f_n(z)):\mathbb{C}^n \rightarrow \mathbb{C}^n$ and $h(z): \mathbb{C}^n \rightarrow C$ are holomorphic functions. Let $D_j= \{z ∈ M : f_j (z) = 0\}$ with $j = 1, . . . , n$ denote the divisors of $\omega$ , and assume that $V = D_1 ∩· · ·∩ D_n$ is a finite set.   Then $$ \sum_{p∈V} Res_p\omega = 0$$ where each $Res_p\omega$ is   evaluated locally on a patch $U_i$ which contains $p$ . Strictly speaking, if we have a form which is defined on $\mathbb{C}^n$ , the theorem does not apply. This is why in ( 1 ) is suggested to compactify $\mathbb{C}^n$ into $\mathbb{CP}^n$ and then apply the theorem. This is done through the change of coordinate $$ z_1 = \frac{w_1}{w_0}\,,\,. . . \,,\,z_n = \frac{w_n}{w_0} $$ and the open covering $\{U_k\}$ is defined as $$ U_k = \{(w_0,w_1,...w_n): w_k=1\}\,, \text{for } k=0,1,...n $$ The form $\omega$ on the patch $U_k$ then takes the expression (see Eq. 92 in ( 1 )) $$ \omega|_{U_k} = \frac{(-1)^k\, h(w/w_0)\, dw_0\,\wedge\,...\wedge dw_n}{w_0^{n+1}f_1(w/w_0)...f_n(w/w_0)} $$ Question: Is there a sufficient condition on the polynomials $h(z),f_i(z)$ such that the zeros of $f(z) = (f_1(z),...,f_n(z))$ are all the points contained in the set $V$ in the open covering $U_0$ ? According to ( 2 ) the theorem can also be stated in the following way Let $\omega = h\,dz/f_1 ...f_n$ be defined by polynomials $h$ and $f_i$ . Let $F_i = \{z ∈ \mathbb{C}^n : f_i(z) = 0\}$ be the hypersurface (i.e. $n − 1$ dimensional subspace) associated with $f_i$ and $Z = F_1 ∩F_2 ∩...∩F_n$ be the set of zeroes of $f$ . Here we assume that $Z$ is a discrete set of points. Then one defines the Global residue of $h$ with respect to the map $f$ as $$ Res_f (h) = \sum_{a∈Z} res(ω)_a. $$ Now, the Global Residue Theorem (GRT) states that if $deg(h) < deg(f_1) + . . . + deg(f_n) − n$ then $Res_f (h) = 0$ . This formulation seems to give an answer to my question about the sufficient condition, i.e. provided $deg(h) < deg(f_1) + . . . + deg(f_n) − n$ . However, I don't understand it. For example, this formulation does not talk about compact manifolds and seems to be very general. However, it does not seem quite exact (maybe I am misunderstanding). Consider for example the form $$ \omega = \frac{z_2^2 z_1 dz_1\wedge dz_2}{(1-z_2 -z_1 +2z_1 z_2)z_1(z_2-z_1)z_2(z_1-1)} $$ with the map $f(z) =\left((1-z_2 -z_1 +2z_1 z_2)z_1(z_2-z_1),z_2(z_1-1)\right) $ . The set $Z$ is given by discrete points $Z=\{(0,0),(1,0),(1,1)\} $ . Moreover, $\text{deg}(h) = 3$ and $\text{deg}(f_1)+\text{deg}(f_2) = 5 + 1 = 6 $ , then the condition $3 < 6 - 2 = 4$ is satisfied and I would expect the theorem holds. Instead, by direct computation (by hand) I get a non-zero global residue. If you don't want to do computations by hand, you can use the Mathematica package MultivariateResidues , the code is shown below. Where am I wrong? Is the definition of $\text{deg}(...)$ more complicated? You can copy and past the following Mathematica Code to reproduce my result Get[""MultivariateResidues.m""]; sols = {(1 - w2 + w1 (-1 + 2 w2)) w1 (w2 - w1) == 0, w2 (w1 - 1) == 0} // Solve; listResidues = {}; Print[Dynamic[ii], ""/"", Length[sols]] For[ii = 1, ii <= Length[sols], ii++, AppendTo[listResidues, (MultivariateResidue[w2^2 w1, {(1 - 1 w2 + w1 (-1 + 2 w2)) w1 (w2 - w1), w2 (w1 - 1)},sols[[ii]]] // Simplify)]] listResidues2 /. List -> Plus // Simplify (* Output: -1 *)","I am studying the global residue theorem which applies for multivariate residues. The theorem is reported in the following references e.g. ( 1 ) (Eq.87) , ( 2 ) (Eq. 109) in different formulations, that now I would try to understand.  It is unnecessary to reveal that my education is not from math studies, so I am sorry if I won't be precise. First of all, let us focus on the following definition ( 1 ) (see Eq.87). Theorem 2. (Global residue theorem). Let denote a   meromorphic -form defined on a compact manifold . Given an open   covering , let take the local form where and are holomorphic functions. Let with denote the divisors of , and assume that is a finite set.   Then where each is   evaluated locally on a patch which contains . Strictly speaking, if we have a form which is defined on , the theorem does not apply. This is why in ( 1 ) is suggested to compactify into and then apply the theorem. This is done through the change of coordinate and the open covering is defined as The form on the patch then takes the expression (see Eq. 92 in ( 1 )) Question: Is there a sufficient condition on the polynomials such that the zeros of are all the points contained in the set in the open covering ? According to ( 2 ) the theorem can also be stated in the following way Let be defined by polynomials and . Let be the hypersurface (i.e. dimensional subspace) associated with and be the set of zeroes of . Here we assume that is a discrete set of points. Then one defines the Global residue of with respect to the map as Now, the Global Residue Theorem (GRT) states that if then . This formulation seems to give an answer to my question about the sufficient condition, i.e. provided . However, I don't understand it. For example, this formulation does not talk about compact manifolds and seems to be very general. However, it does not seem quite exact (maybe I am misunderstanding). Consider for example the form with the map . The set is given by discrete points . Moreover, and , then the condition is satisfied and I would expect the theorem holds. Instead, by direct computation (by hand) I get a non-zero global residue. If you don't want to do computations by hand, you can use the Mathematica package MultivariateResidues , the code is shown below. Where am I wrong? Is the definition of more complicated? You can copy and past the following Mathematica Code to reproduce my result Get[""MultivariateResidues.m""]; sols = {(1 - w2 + w1 (-1 + 2 w2)) w1 (w2 - w1) == 0, w2 (w1 - 1) == 0} // Solve; listResidues = {}; Print[Dynamic[ii], ""/"", Length[sols]] For[ii = 1, ii <= Length[sols], ii++, AppendTo[listResidues, (MultivariateResidue[w2^2 w1, {(1 - 1 w2 + w1 (-1 + 2 w2)) w1 (w2 - w1), w2 (w1 - 1)},sols[[ii]]] // Simplify)]] listResidues2 /. List -> Plus // Simplify (* Output: -1 *)","\omega n M \{U_i\} \omega  \omega=\frac{h(z)dz_1 ∧ · · · ∧ dz_n}{f_1(z)· · · f_n(z)}  f(z) = (f_1(z), . . . , f_n(z)):\mathbb{C}^n \rightarrow \mathbb{C}^n h(z): \mathbb{C}^n \rightarrow C D_j= \{z ∈ M : f_j (z) = 0\} j = 1, . . . , n \omega V = D_1 ∩· · ·∩ D_n  \sum_{p∈V} Res_p\omega = 0 Res_p\omega U_i p \mathbb{C}^n \mathbb{C}^n \mathbb{CP}^n 
z_1 = \frac{w_1}{w_0}\,,\,. . . \,,\,z_n = \frac{w_n}{w_0}
 \{U_k\} 
U_k = \{(w_0,w_1,...w_n): w_k=1\}\,, \text{for } k=0,1,...n
 \omega U_k 
\omega|_{U_k} = \frac{(-1)^k\, h(w/w_0)\, dw_0\,\wedge\,...\wedge dw_n}{w_0^{n+1}f_1(w/w_0)...f_n(w/w_0)}
 h(z),f_i(z) f(z) = (f_1(z),...,f_n(z)) V U_0 \omega = h\,dz/f_1 ...f_n h f_i F_i = \{z ∈ \mathbb{C}^n : f_i(z) = 0\} n − 1 f_i Z = F_1 ∩F_2 ∩...∩F_n f Z h f 
Res_f (h) = \sum_{a∈Z} res(ω)_a.
 deg(h) < deg(f_1) + . . . + deg(f_n) − n Res_f (h) = 0 deg(h) < deg(f_1) + . . . + deg(f_n) − n 
\omega = \frac{z_2^2 z_1 dz_1\wedge dz_2}{(1-z_2 -z_1 +2z_1 z_2)z_1(z_2-z_1)z_2(z_1-1)}
 f(z) =\left((1-z_2 -z_1 +2z_1 z_2)z_1(z_2-z_1),z_2(z_1-1)\right)  Z Z=\{(0,0),(1,0),(1,1)\}  \text{deg}(h) = 3 \text{deg}(f_1)+\text{deg}(f_2) = 5 + 1 = 6  3 < 6 - 2 = 4 \text{deg}(...)","['complex-analysis', 'multivariable-calculus', 'residue-calculus', 'complex-integration']"
97,How is complex analysis relevant to other areas of mathematics?,How is complex analysis relevant to other areas of mathematics?,,"I'm going to do a math PhD next year. My main interests in mathematics are composition algebra, algebraic topology, and group theory. Now I have the opportunity to take a one-semester course in complex analysis, but I am not sure if it is relevant to my research interests. My understanding of complex analysis is that it is mostly about Laurent series, Cauchy's integral theorem, residue theorem, and evaluating weird-looking real integrals using these techniques. But I fail to see its connection to algebra. I am sure that it is a beautiful theory and that it is also an important set of tools for applied mathematicians and engineers, but is there anything useful I can take from complex analysis as an algebraist?","I'm going to do a math PhD next year. My main interests in mathematics are composition algebra, algebraic topology, and group theory. Now I have the opportunity to take a one-semester course in complex analysis, but I am not sure if it is relevant to my research interests. My understanding of complex analysis is that it is mostly about Laurent series, Cauchy's integral theorem, residue theorem, and evaluating weird-looking real integrals using these techniques. But I fail to see its connection to algebra. I am sure that it is a beautiful theory and that it is also an important set of tools for applied mathematicians and engineers, but is there anything useful I can take from complex analysis as an algebraist?",,"['complex-analysis', 'soft-question']"
98,Probably incorrect method of integration gives the correct result. Why?,Probably incorrect method of integration gives the correct result. Why?,,"I have just learned about the residue theorem so when I encountered the integral $$   I = \int_{0}^{+\infty} \frac{x^3}{e^x-1}dx $$ I tried to evaluate it with this method, which failed but produced something interesting. Define the complex logarithm on $\mathbb C \setminus [0,+\infty)$ and consider the function $$   f(z) = \frac{z^3 \log z}{e^z-1} $$ with the path $\gamma$ given by this drawing Provided that both $\oint_{C_\epsilon} fdz$ and $ \oint_{C_R}fdz$ goes to zero as $R\to\infty$ and  $\epsilon \to 0$ the value of the original integral is given by the residue theorem $$  I = -\frac{1}{2\pi i}\oint_\gamma fdz =       -\sum_{k} \text{Res}(f, z_k) $$ $f$ has simple poles for $e^z=1$, $z=2k\pi i$ where $k \in \mathbb Z$ so the residues are \begin{align*} 	\text{Res}(f, z_k) &= 0 && k=0  \\ 	\text{Res}(f, z_k) &= z^3 \log{z} \big|_{z=2k\pi i} 	                   = (2k\pi)^3 \log (2k\pi i) && k\neq 0 \end{align*} The sum of the residue can be written as $$   \sum_{k=1}^{+\infty} (a_k + a_{(-k)}) $$ where \begin{align*}   a_k     &= i(2k\pi)^3\left(\log(2k\pi) + i\frac{\pi}{2}\right) \\  a_{(-k)} &= i(2k\pi)^3\left(-\log(2k\pi) - i\frac{3\pi}{2}\right) \end{align*} Cancelling the terms out $$   I = \sum_{k=1}^{+\infty} i(2\pi k)^3(-i\pi)     = 8\pi^4 \sum_{k=1}^{+\infty} k^3 $$ which diverges. Clearly something is wrong: maybe the integral on the circumference is not zero? I'm not sure. However if I replace the infinite sum with $\zeta(-3)=\frac{1}{120}$ I actually get the correct result  $I = \frac{\pi^4}{15}$. Why does this work? P.S. I managed to evaluate it in a more familiar way without involving complex analysis.","I have just learned about the residue theorem so when I encountered the integral $$   I = \int_{0}^{+\infty} \frac{x^3}{e^x-1}dx $$ I tried to evaluate it with this method, which failed but produced something interesting. Define the complex logarithm on $\mathbb C \setminus [0,+\infty)$ and consider the function $$   f(z) = \frac{z^3 \log z}{e^z-1} $$ with the path $\gamma$ given by this drawing Provided that both $\oint_{C_\epsilon} fdz$ and $ \oint_{C_R}fdz$ goes to zero as $R\to\infty$ and  $\epsilon \to 0$ the value of the original integral is given by the residue theorem $$  I = -\frac{1}{2\pi i}\oint_\gamma fdz =       -\sum_{k} \text{Res}(f, z_k) $$ $f$ has simple poles for $e^z=1$, $z=2k\pi i$ where $k \in \mathbb Z$ so the residues are \begin{align*} 	\text{Res}(f, z_k) &= 0 && k=0  \\ 	\text{Res}(f, z_k) &= z^3 \log{z} \big|_{z=2k\pi i} 	                   = (2k\pi)^3 \log (2k\pi i) && k\neq 0 \end{align*} The sum of the residue can be written as $$   \sum_{k=1}^{+\infty} (a_k + a_{(-k)}) $$ where \begin{align*}   a_k     &= i(2k\pi)^3\left(\log(2k\pi) + i\frac{\pi}{2}\right) \\  a_{(-k)} &= i(2k\pi)^3\left(-\log(2k\pi) - i\frac{3\pi}{2}\right) \end{align*} Cancelling the terms out $$   I = \sum_{k=1}^{+\infty} i(2\pi k)^3(-i\pi)     = 8\pi^4 \sum_{k=1}^{+\infty} k^3 $$ which diverges. Clearly something is wrong: maybe the integral on the circumference is not zero? I'm not sure. However if I replace the infinite sum with $\zeta(-3)=\frac{1}{120}$ I actually get the correct result  $I = \frac{\pi^4}{15}$. Why does this work? P.S. I managed to evaluate it in a more familiar way without involving complex analysis.",,"['complex-analysis', 'improper-integrals', 'residue-calculus', 'riemann-zeta']"
99,"If $|f(z)| < \sqrt{\left| z\right|}$, then $\lim_{z\to\infty} f(z)$ exists?","If , then  exists?",|f(z)| < \sqrt{\left| z\right|} \lim_{z\to\infty} f(z),"Let $f(z)$ be a holomorphic function defined on $D=\{ z\in\mathbb{C} | \left| z \right| > 1\}$. For all $z\in D$, we have $\left| f(z) \right| \le \sqrt{\left| z \right|}$. Show that $\lim_{z\to\infty} f(z)$ exists. How should I show this? I was thinking could I show that $f(z)$ is actually constant, but that doesn't seem to be the case. I think I can find $f(z)$ that is not constant but has limit at infinity. What is the right ""picture"" to think about here? Hint is greatly appreciated. Update : So I considered $g(z) = f(\frac{1}{z})$. Take $C_R$ be circle of radius $R$. Then I got something like $$\int_{C_R} \left| g(z) \right| dz=\int_{C_R} \left| f(\frac{1}{z})\right| dz\le \int_{C_R} \frac{1}{\sqrt{R}} dz = 2\pi \sqrt{R}$$ Then by Residue Theorem, $$2\pi i \text{Res}_{z= 0} g(z) = 2\pi \sqrt{R}$$ Since this is true for all $R$, $\text{Res}_{z=0} f(z) = 0$ Update 2 : I actually considered $\lim_{z\to 0} zg(z)$. Since $$ \left| z f\left(\frac{1}{z}\right)\right|<\left| \frac{z}{\sqrt{\left| z\right|}}\right| \to 0 \text{ as } z \to 0$$ $g(z)$ should have a removable singularity at $z=0$. So $f(z)$ should have a removable singularity at infinity?","Let $f(z)$ be a holomorphic function defined on $D=\{ z\in\mathbb{C} | \left| z \right| > 1\}$. For all $z\in D$, we have $\left| f(z) \right| \le \sqrt{\left| z \right|}$. Show that $\lim_{z\to\infty} f(z)$ exists. How should I show this? I was thinking could I show that $f(z)$ is actually constant, but that doesn't seem to be the case. I think I can find $f(z)$ that is not constant but has limit at infinity. What is the right ""picture"" to think about here? Hint is greatly appreciated. Update : So I considered $g(z) = f(\frac{1}{z})$. Take $C_R$ be circle of radius $R$. Then I got something like $$\int_{C_R} \left| g(z) \right| dz=\int_{C_R} \left| f(\frac{1}{z})\right| dz\le \int_{C_R} \frac{1}{\sqrt{R}} dz = 2\pi \sqrt{R}$$ Then by Residue Theorem, $$2\pi i \text{Res}_{z= 0} g(z) = 2\pi \sqrt{R}$$ Since this is true for all $R$, $\text{Res}_{z=0} f(z) = 0$ Update 2 : I actually considered $\lim_{z\to 0} zg(z)$. Since $$ \left| z f\left(\frac{1}{z}\right)\right|<\left| \frac{z}{\sqrt{\left| z\right|}}\right| \to 0 \text{ as } z \to 0$$ $g(z)$ should have a removable singularity at $z=0$. So $f(z)$ should have a removable singularity at infinity?",,['complex-analysis']
