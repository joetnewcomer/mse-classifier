,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Passage in the proof of Chern-Weil method in John Roe's Elliptic operators book,Passage in the proof of Chern-Weil method in John Roe's Elliptic operators book,,"I've problem understanding some passages in the proof of the Chern-Weil homomorphism: After defining what is an invariant polynomial $P$ on $\mathfrak{gl}_n(\Bbb C)$ we want to prove that given $K$ the curvature of a complex vector bundle $V$ over $M$ then $P(K)$ is a closed form, whose cohomology class is independent from the choice of the connection $\nabla$ on $V$. The author says that it's equivalent to prove closeness and well-definedness for the form $$\log \det(1+q\Omega)$$ where $q$ is just a parameter and $\Omega$ is the curvature $2$-form associated to the frame bundle associated to $V$. ($\Omega=d\omega+\omega^2$, where $\omega$ is the connection $1$-form). He then assume that $\omega$ depends on another parameter $t$ (I guess in order to prove well-definedness since the space of connections is affine) and after some algebra he gets $$(*) \ \ \ \ \ \ \ \ \frac{d}{dt}\log \det(1+q\Omega)= d\sum_{l=0}^{\infty}(-1)^lq^{l+1}\text{tr}\{\Omega^l \omega'\}$$ where $\omega'$ is the derivative w.r.t. $t$ of $\omega$. He then push everything to $M$ (we were working on $E$ now) and it concludes by saying: Now the result follows; for since any connection can be deformed locally to flatness, we see that $\log \det(1+q\Omega)$ is locally exact; that is closed; and since any two connections can be linked by a differentiable path, the cohomology class of $\log \det(1+q\Omega)$ is independent of the choice of connection The independence I think is obtained by integrating w.r.t. the parameter $t$ equation (*) and then switch the integral sign with the exterior derivative on RHS (can we do it?) Why do we have that the form is closed? where does flatness come into play?","I've problem understanding some passages in the proof of the Chern-Weil homomorphism: After defining what is an invariant polynomial $P$ on $\mathfrak{gl}_n(\Bbb C)$ we want to prove that given $K$ the curvature of a complex vector bundle $V$ over $M$ then $P(K)$ is a closed form, whose cohomology class is independent from the choice of the connection $\nabla$ on $V$. The author says that it's equivalent to prove closeness and well-definedness for the form $$\log \det(1+q\Omega)$$ where $q$ is just a parameter and $\Omega$ is the curvature $2$-form associated to the frame bundle associated to $V$. ($\Omega=d\omega+\omega^2$, where $\omega$ is the connection $1$-form). He then assume that $\omega$ depends on another parameter $t$ (I guess in order to prove well-definedness since the space of connections is affine) and after some algebra he gets $$(*) \ \ \ \ \ \ \ \ \frac{d}{dt}\log \det(1+q\Omega)= d\sum_{l=0}^{\infty}(-1)^lq^{l+1}\text{tr}\{\Omega^l \omega'\}$$ where $\omega'$ is the derivative w.r.t. $t$ of $\omega$. He then push everything to $M$ (we were working on $E$ now) and it concludes by saying: Now the result follows; for since any connection can be deformed locally to flatness, we see that $\log \det(1+q\Omega)$ is locally exact; that is closed; and since any two connections can be linked by a differentiable path, the cohomology class of $\log \det(1+q\Omega)$ is independent of the choice of connection The independence I think is obtained by integrating w.r.t. the parameter $t$ equation (*) and then switch the integral sign with the exterior derivative on RHS (can we do it?) Why do we have that the form is closed? where does flatness come into play?",,"['differential-geometry', 'connections', 'characteristic-classes']"
1,What kind of curvature does a cylinder have? [closed],What kind of curvature does a cylinder have? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Gaussian curvature is a kind of like an infinitesimal curvature. For example, all points of a sphere has positive Gaussian curvature. Angular defect is kind of like a ""point charge"" of curvature. For example a cube has positive angular defect at its 6 corners. So what do you call the curvature on the two circles of a cylinder? It has positive infinite gaussian curvature, but 0 angular defect. Note: The cylinder is closed, i.e. has a top and bottom (like this ).","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Gaussian curvature is a kind of like an infinitesimal curvature. For example, all points of a sphere has positive Gaussian curvature. Angular defect is kind of like a ""point charge"" of curvature. For example a cube has positive angular defect at its 6 corners. So what do you call the curvature on the two circles of a cylinder? It has positive infinite gaussian curvature, but 0 angular defect. Note: The cylinder is closed, i.e. has a top and bottom (like this ).",,"['differential-geometry', 'curvature']"
2,Why is this vector field well-defined?,Why is this vector field well-defined?,,"$\newcommand{\IP}[2]{\left\langle #1,#2 \right\rangle}$ $\newcommand{\de}{\delta}$ Let $M$ be a Riemannian manifold, and let $e_i$ be a local frame for $TM$. We also choose some fixed differential forms $\omega \in \Omega^k(M),\eta \in \Omega^{k+1}(M)$. Consider the following vector field: $$ X=\IP{e^i \wedge \omega }{\eta}e_i \tag{1} $$ (The inner product on forms is the one induced by the metric on $M$). I claim $X$ is well-defined, i.e does not depend on the chosen frame $e_i$. Is there a ""conceptual proof"" for that? I have a proof which is nothing but a routine calculation (see below), but I wonder if there is a nicer explanation for why this ""magic"" happens. (BTW, this vector field, or more precisely its divergence, arises naturally when trying to compute a formula for the coderivative ). For completeness, here is my proof: Let $f_i$ be a different frame for $TM$, and let $f^j,e^i$ be the dual bases of $f_j,e_i$ respectively. Write  $$ f_i=A_i^{j}e_j,f^i=B_j^i e^j. $$ We claim $A=B^{-1}$. Indeed, $$ \de^i_k= f^i(f_k)=B_j^ie^j(A_k^se_s)=B_j^iA_k^s\de^j_s=\sum_j B_j^iA_k^j=(BA)_{ik}. $$ So, $$ \begin{split} \IP{f^i \wedge \omega }{\eta}f_i &=\IP{   B_j^i e^j \wedge \omega }{\eta}A_i^{k}e_k=A_i^{k}B_j^i\IP{    e^j \wedge \omega }{\eta}e_k=(AB)^k_j\IP{    e^j \wedge \omega }{\eta}e_k \\ &=\de^k_j\IP{    e^j \wedge \omega }{\eta}e_k= \IP{e^i \wedge \omega }{\eta}e_i. \end{split} $$ Edit: Here is summary of Andreas and levap's suggestions: Let $V$ be a real vector space. Fix $\omega \in  \Lambda^{k}  V^*,\eta \in  \Lambda^{k+1}  V^*$. Look at the bilinear map: $V^* \times V \to \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \otimes V$ defined by $$(\hat{\omega}, v) \to \eta \otimes (\hat{\omega} \wedge \omega) \otimes v.$$ This map induces a linear map $\Phi:V^* \otimes V \to \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \otimes V$, $$\Phi(\hat{\omega}\otimes v) := \eta \otimes (\hat{\omega} \wedge \omega) \otimes v.$$ Now, put an inner product on $\Lambda^{k+1}  V^*$ (which can be induced by a product on $V$ in a natural way, or not, it does not matter). This product, which by definition is a bilinear map $\Lambda^{k+1}  V^* \times \Lambda^{k+1}  V^* \to \mathbb{R}$ induces a linear map $ \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \to \mathbb{R}$. By tensoring it with the identity map $\text{Id}_V$ we get $$ \Psi: \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \otimes V \to \mathbb{R} \otimes V \cong V , \tag{2}$$ given by $$ \Psi (\eta_1 \otimes \eta_2 \otimes v)=\IP{\eta_1}{\eta_2}v. \tag{3}$$ Now, note that for any basis $e_i$ for $V$, $$e^i \otimes e_i = \text{Id}_V, \tag{4}$$ where $e^i$ is the dual basis for $e_i$, and we have used the canonical identification $V^* \otimes V \cong \text{Hom}(V,V)$. It is this fact that, which holds for any frame $e_i$, which lies in the heart of the ""basis-independence"" of the vector field defined in $(1)$. Indeed, $$ \Phi(\text{Id}_V)=\Phi(e^i \otimes e_i) = \eta \otimes (e^i \wedge \omega) \otimes e_i,$$ and $$ \Psi \circ \Phi:\text{Hom}(V,V) \to V.$$ Finally, definition $(1)$ is nothing but setting $$ X:=\Psi \circ \Phi (\text{Id}_V)=\Psi\big(\eta \otimes (e^i \wedge \omega) \otimes e_i\big)=\IP{\eta }{e^i \wedge \omega }e_i.$$","$\newcommand{\IP}[2]{\left\langle #1,#2 \right\rangle}$ $\newcommand{\de}{\delta}$ Let $M$ be a Riemannian manifold, and let $e_i$ be a local frame for $TM$. We also choose some fixed differential forms $\omega \in \Omega^k(M),\eta \in \Omega^{k+1}(M)$. Consider the following vector field: $$ X=\IP{e^i \wedge \omega }{\eta}e_i \tag{1} $$ (The inner product on forms is the one induced by the metric on $M$). I claim $X$ is well-defined, i.e does not depend on the chosen frame $e_i$. Is there a ""conceptual proof"" for that? I have a proof which is nothing but a routine calculation (see below), but I wonder if there is a nicer explanation for why this ""magic"" happens. (BTW, this vector field, or more precisely its divergence, arises naturally when trying to compute a formula for the coderivative ). For completeness, here is my proof: Let $f_i$ be a different frame for $TM$, and let $f^j,e^i$ be the dual bases of $f_j,e_i$ respectively. Write  $$ f_i=A_i^{j}e_j,f^i=B_j^i e^j. $$ We claim $A=B^{-1}$. Indeed, $$ \de^i_k= f^i(f_k)=B_j^ie^j(A_k^se_s)=B_j^iA_k^s\de^j_s=\sum_j B_j^iA_k^j=(BA)_{ik}. $$ So, $$ \begin{split} \IP{f^i \wedge \omega }{\eta}f_i &=\IP{   B_j^i e^j \wedge \omega }{\eta}A_i^{k}e_k=A_i^{k}B_j^i\IP{    e^j \wedge \omega }{\eta}e_k=(AB)^k_j\IP{    e^j \wedge \omega }{\eta}e_k \\ &=\de^k_j\IP{    e^j \wedge \omega }{\eta}e_k= \IP{e^i \wedge \omega }{\eta}e_i. \end{split} $$ Edit: Here is summary of Andreas and levap's suggestions: Let $V$ be a real vector space. Fix $\omega \in  \Lambda^{k}  V^*,\eta \in  \Lambda^{k+1}  V^*$. Look at the bilinear map: $V^* \times V \to \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \otimes V$ defined by $$(\hat{\omega}, v) \to \eta \otimes (\hat{\omega} \wedge \omega) \otimes v.$$ This map induces a linear map $\Phi:V^* \otimes V \to \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \otimes V$, $$\Phi(\hat{\omega}\otimes v) := \eta \otimes (\hat{\omega} \wedge \omega) \otimes v.$$ Now, put an inner product on $\Lambda^{k+1}  V^*$ (which can be induced by a product on $V$ in a natural way, or not, it does not matter). This product, which by definition is a bilinear map $\Lambda^{k+1}  V^* \times \Lambda^{k+1}  V^* \to \mathbb{R}$ induces a linear map $ \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \to \mathbb{R}$. By tensoring it with the identity map $\text{Id}_V$ we get $$ \Psi: \Lambda^{k+1}  V^* \otimes \Lambda^{k+1}  V^* \otimes V \to \mathbb{R} \otimes V \cong V , \tag{2}$$ given by $$ \Psi (\eta_1 \otimes \eta_2 \otimes v)=\IP{\eta_1}{\eta_2}v. \tag{3}$$ Now, note that for any basis $e_i$ for $V$, $$e^i \otimes e_i = \text{Id}_V, \tag{4}$$ where $e^i$ is the dual basis for $e_i$, and we have used the canonical identification $V^* \otimes V \cong \text{Hom}(V,V)$. It is this fact that, which holds for any frame $e_i$, which lies in the heart of the ""basis-independence"" of the vector field defined in $(1)$. Indeed, $$ \Phi(\text{Id}_V)=\Phi(e^i \otimes e_i) = \eta \otimes (e^i \wedge \omega) \otimes e_i,$$ and $$ \Psi \circ \Phi:\text{Hom}(V,V) \to V.$$ Finally, definition $(1)$ is nothing but setting $$ X:=\Psi \circ \Phi (\text{Id}_V)=\Psi\big(\eta \otimes (e^i \wedge \omega) \otimes e_i\big)=\IP{\eta }{e^i \wedge \omega }e_i.$$",,"['linear-algebra', 'differential-geometry', 'riemannian-geometry', 'differential-forms', 'change-of-basis']"
3,Definition of smooth manifolds: What is the difference between differentiable structures and smooth structures?,Definition of smooth manifolds: What is the difference between differentiable structures and smooth structures?,,We call an atlas smooth if each of its transition maps (or change of charts) is smooth (or $C^\infty$). A differential structure is a maximal smooth atlas. A smooth manifold is a topological manifold together with a smooth structure. These are the definitions of my lecture notes. I am also wondering now why we have not defined what a smooth structure is and if one has to replace smooth structure with differentiable structure instead. In Loring Tu's An Introduction to Manifolds it is also mentioned that it has to be a differentiable structure. But I tried to compare both definitions on Wikipedia and I can not really tell the crucial difference between these both terms. Both are somehow dealing with maximal atlases. Could you give me an explanation about the right definition about smooth manifolds? Thank you.,We call an atlas smooth if each of its transition maps (or change of charts) is smooth (or $C^\infty$). A differential structure is a maximal smooth atlas. A smooth manifold is a topological manifold together with a smooth structure. These are the definitions of my lecture notes. I am also wondering now why we have not defined what a smooth structure is and if one has to replace smooth structure with differentiable structure instead. In Loring Tu's An Introduction to Manifolds it is also mentioned that it has to be a differentiable structure. But I tried to compare both definitions on Wikipedia and I can not really tell the crucial difference between these both terms. Both are somehow dealing with maximal atlases. Could you give me an explanation about the right definition about smooth manifolds? Thank you.,,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
4,Tangent space to fixed point manifold and fixed point set of tangent space,Tangent space to fixed point manifold and fixed point set of tangent space,,Assume a finite group $G$ acts smoothly on a smooth manifold $M$. Let $p\in M^G$. Then there is the action of $G$ on $T_pM$ given by differentials of diffeomorphisms being the actions of group elements. Is it true that $$ T_p(M^G)=(T_pM)^G? $$,Assume a finite group $G$ acts smoothly on a smooth manifold $M$. Let $p\in M^G$. Then there is the action of $G$ on $T_pM$ given by differentials of diffeomorphisms being the actions of group elements. Is it true that $$ T_p(M^G)=(T_pM)^G? $$,,"['differential-geometry', 'differential-topology', 'group-actions']"
5,Is the tangent space to a critical submanifold a subspace of the kernel of the Hessian?,Is the tangent space to a critical submanifold a subspace of the kernel of the Hessian?,,"Trying to solve a question I have been faced with another question. Let $f:M\to\mathbb{R}$ be a smooth function and $b\in \mathbb{R}$ a critical value of it. Now the following relation is true?  $$T_qf^{-1}(b)\subset \operatorname{Ker}\operatorname{Hess}_qf=E_0,$$ where $E_0$ is the eigenspace associated to the eigenvalue $0$. FYI: The Hessian of $f$ at a critical point $q$ is a symmetric bilinear form $\operatorname{Hess} f_q$ s.t. $\forall v,w\in T_qM$,      $$\operatorname{Hess} f_q(v,w)=V_q(W(f)),$$     where $V,W$ are the extensions of $v$ and $w$ to vector fields such that $V_q=v$ and $W_q=w$. I would appreciate any comment","Trying to solve a question I have been faced with another question. Let $f:M\to\mathbb{R}$ be a smooth function and $b\in \mathbb{R}$ a critical value of it. Now the following relation is true?  $$T_qf^{-1}(b)\subset \operatorname{Ker}\operatorname{Hess}_qf=E_0,$$ where $E_0$ is the eigenspace associated to the eigenvalue $0$. FYI: The Hessian of $f$ at a critical point $q$ is a symmetric bilinear form $\operatorname{Hess} f_q$ s.t. $\forall v,w\in T_qM$,      $$\operatorname{Hess} f_q(v,w)=V_q(W(f)),$$     where $V,W$ are the extensions of $v$ and $w$ to vector fields such that $V_q=v$ and $W_q=w$. I would appreciate any comment",,"['differential-geometry', 'riemannian-geometry', 'morse-theory', 'hessian-matrix']"
6,Pre-image of a submanifold by a submersion,Pre-image of a submanifold by a submersion,,"Let $f: M \to N$ a submersion between two manifolds, and let $S\subset N$ a subset of N. Proof that $S$ is a  regular submanifold of $N$ if and only if $f^{-1}(S)$ is a regular submanifold of M. So far I have half of the problem. Using the transversality theorem, we see that if $S$ is a submanifold, then using that $f$ is a submersion, we see that $S$ is transverse to $f$, so the preimage of $S$ is a submanifold of M. Now, for the second part I tried to use coordinate charts and the constant rank theorem, but nothing seems to work. Any help will be appreciated.","Let $f: M \to N$ a submersion between two manifolds, and let $S\subset N$ a subset of N. Proof that $S$ is a  regular submanifold of $N$ if and only if $f^{-1}(S)$ is a regular submanifold of M. So far I have half of the problem. Using the transversality theorem, we see that if $S$ is a submanifold, then using that $f$ is a submersion, we see that $S$ is transverse to $f$, so the preimage of $S$ is a submanifold of M. Now, for the second part I tried to use coordinate charts and the constant rank theorem, but nothing seems to work. Any help will be appreciated.",,['differential-geometry']
7,Pull-back of a differential : I get confused with the variables,Pull-back of a differential : I get confused with the variables,,"I edited again my message with the remarks done in the comments. I have a 2-form : $$\alpha=\alpha_{\mu \nu} dx^\mu \wedge dx^\nu$$ I want to compute the pull back $F^{*}(d \alpha)$ to show that : $F^{*}(d \alpha)=dF^{*}( \alpha)$ But I make a mistake somewhere because I can't prove the equality. $$ F : y \mapsto x $$ So when I write $x^\mu$ I have in fact a dependance $x^\mu(y^\nu)$. $$d \alpha=d \alpha_{\mu \nu} \wedge dx^\mu \wedge dx^\nu  \\= \frac{\partial \alpha_{\mu \nu}}{\partial x^\epsilon} dx^\epsilon \wedge dx^\mu \wedge dx^\nu$$ $$F^{*}(d \alpha)=F^{*}(\frac{\partial \alpha_{\mu \nu}}{\partial x^\epsilon}) F^{*}(dx^\epsilon) \wedge F^{*}(dx^\mu)  \wedge F^{*}(dx^\nu)$$ I have : $$ F^{*}(dx^\mu) = \frac{\partial x^\mu}{\partial y^i} dy^i$$ and $$F^{*}(\frac{\partial \alpha_{\mu \nu}(x)}{\partial x^\epsilon})=\frac{\partial \alpha_{\mu \nu}(x(y))}{\partial x^\epsilon(y)}$$ And finally, I get : $$F^{*}(d \alpha)=\frac{\partial \alpha_{\mu \nu}(x(y))}{\partial x^\epsilon(y)} \frac{\partial x^\epsilon}{\partial y^i}\frac{\partial x^\mu}{\partial y^j}\frac{\partial x^\nu}{\partial y^k} dy^i \wedge dy^j \wedge dy^k$$ On the other hand, I have : $$F^{*}(\alpha)=F^{*}(\alpha_{\mu \nu}(x)) F^{*}(dx^\mu)  \wedge F^{*}(dx^\nu)\\ =\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i} \frac{\partial x^\nu}{\partial y^j} dy^i \wedge dy^j$$ But here there is a problem when I differentiate : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i} \frac{\partial x^\nu}{\partial y^j}) \wedge dy^i \wedge dy^j$$ Indeed I will have extra derivative term in $\frac{\partial^2 x^\mu}{\partial y^i \partial y^l} $ when I differentiate. And I don't have these terms in $F^{*}(d \alpha)$. So where is my mistake ?? [edit] According to the answer below, I see that my misunderstanding is in the fact that : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y))) \wedge (\frac{\partial x^\mu}{\partial y^i}) dy^i \wedge ( \frac{\partial x^\nu}{\partial y^j} ) dy^j$$ We don't differentiate the terms $\frac{\partial x^\nu}{\partial y^j}$. But I don't understand why as the definition of the exterior derivative is the following : With : $$\alpha=\alpha_\mu dx^{\mu}$$ We have by definition : $$ d\alpha=d\alpha_\mu \wedge dx^{\mu}$$ Thus in my example it should be : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i}  \frac{\partial x^\nu}{\partial y^j} ) \wedge  dy^i \wedge  dy^j$$ And not : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)))  \frac{\partial x^\mu}{\partial y^i}  \frac{\partial x^\nu}{\partial y^j}  \wedge  dy^i \wedge  dy^j$$ ie the differential applies to all the terms including the chain derivative and not only on $\alpha_\mu$. Could someone clarify this for me (or at least give me an exact definition of the exterior derivative ?)","I edited again my message with the remarks done in the comments. I have a 2-form : $$\alpha=\alpha_{\mu \nu} dx^\mu \wedge dx^\nu$$ I want to compute the pull back $F^{*}(d \alpha)$ to show that : $F^{*}(d \alpha)=dF^{*}( \alpha)$ But I make a mistake somewhere because I can't prove the equality. $$ F : y \mapsto x $$ So when I write $x^\mu$ I have in fact a dependance $x^\mu(y^\nu)$. $$d \alpha=d \alpha_{\mu \nu} \wedge dx^\mu \wedge dx^\nu  \\= \frac{\partial \alpha_{\mu \nu}}{\partial x^\epsilon} dx^\epsilon \wedge dx^\mu \wedge dx^\nu$$ $$F^{*}(d \alpha)=F^{*}(\frac{\partial \alpha_{\mu \nu}}{\partial x^\epsilon}) F^{*}(dx^\epsilon) \wedge F^{*}(dx^\mu)  \wedge F^{*}(dx^\nu)$$ I have : $$ F^{*}(dx^\mu) = \frac{\partial x^\mu}{\partial y^i} dy^i$$ and $$F^{*}(\frac{\partial \alpha_{\mu \nu}(x)}{\partial x^\epsilon})=\frac{\partial \alpha_{\mu \nu}(x(y))}{\partial x^\epsilon(y)}$$ And finally, I get : $$F^{*}(d \alpha)=\frac{\partial \alpha_{\mu \nu}(x(y))}{\partial x^\epsilon(y)} \frac{\partial x^\epsilon}{\partial y^i}\frac{\partial x^\mu}{\partial y^j}\frac{\partial x^\nu}{\partial y^k} dy^i \wedge dy^j \wedge dy^k$$ On the other hand, I have : $$F^{*}(\alpha)=F^{*}(\alpha_{\mu \nu}(x)) F^{*}(dx^\mu)  \wedge F^{*}(dx^\nu)\\ =\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i} \frac{\partial x^\nu}{\partial y^j} dy^i \wedge dy^j$$ But here there is a problem when I differentiate : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i} \frac{\partial x^\nu}{\partial y^j}) \wedge dy^i \wedge dy^j$$ Indeed I will have extra derivative term in $\frac{\partial^2 x^\mu}{\partial y^i \partial y^l} $ when I differentiate. And I don't have these terms in $F^{*}(d \alpha)$. So where is my mistake ?? [edit] According to the answer below, I see that my misunderstanding is in the fact that : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y))) \wedge (\frac{\partial x^\mu}{\partial y^i}) dy^i \wedge ( \frac{\partial x^\nu}{\partial y^j} ) dy^j$$ We don't differentiate the terms $\frac{\partial x^\nu}{\partial y^j}$. But I don't understand why as the definition of the exterior derivative is the following : With : $$\alpha=\alpha_\mu dx^{\mu}$$ We have by definition : $$ d\alpha=d\alpha_\mu \wedge dx^{\mu}$$ Thus in my example it should be : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)) \frac{\partial x^\mu}{\partial y^i}  \frac{\partial x^\nu}{\partial y^j} ) \wedge  dy^i \wedge  dy^j$$ And not : $$dF^{*}(\alpha)=d(\alpha_{\mu \nu}(x(y)))  \frac{\partial x^\mu}{\partial y^i}  \frac{\partial x^\nu}{\partial y^j}  \wedge  dy^i \wedge  dy^j$$ ie the differential applies to all the terms including the chain derivative and not only on $\alpha_\mu$. Could someone clarify this for me (or at least give me an exact definition of the exterior derivative ?)",,['differential-geometry']
8,Is there any surface (or general manifold) on which the value of $\pi$ is rational?,Is there any surface (or general manifold) on which the value of  is rational?,\pi,"Let $X(u,v)=(x(u,v),y(u,v),z(u,v))$ be some map $X:U\to S$ Let $\pi(u,v,d):=C(u,v,d)/d$, with the following definitions: A ""circle""  is the set of all points $p\in S$ of distance $d/2$ to some fixed point $q=X(u,v)$ (where distance is measured using the metric $G=dX^TdX$), And $C(u,v,d)$ is the arclength of the curve (parameterized in local coordinates by $\gamma(u,v,d)$) defined by this set. (Feel free to suggest other more general definitions if you think they might be helpful) First off: Is there any surface other than the plane for which $\pi(u,v,d)=const$? Is there any other surface on which $\pi(u,v,d)=\pi(u,v)$ (i.e. its constant per point) I'm essentially asking if the fact that $\pi$ is irrational is somehow ""built-in"" to reality, or are there some more ""rational"" realities where, say, $\pi==22/7$. ~ Appendix: I'm reminded vaguely of the mean value theorem for harmonic functions (and solutions of the heat equation), which states that the mean value of any harmonic function $f$ over any set of concentric circles is constant. Assuming this even applies in the case of a harmonic function over some general metric space (does it?), can we somehow interpret $C/d$ as the (reciprocal?) mean value over circles of a harmonic function, and thereby at least prove (2)? The mean around some point $(u,v)$ would be calculated as: $\mu(u,v,d)=\frac{\int_\gamma f(\gamma(u,v,d)) ds}{C(u,v,d)}$ Perhaps the above question can then be rephrased as follows: Is there any surface on which we can define some harmonic function for which $\mu(u,v,d)=d/C(u,v,d)$, in which case we get by the mean value theorem that $\pi$ is constant per point, and further is there any such surface+harmonic function combination for which $\mu(u,v,d)=d/C=const.$ ?","Let $X(u,v)=(x(u,v),y(u,v),z(u,v))$ be some map $X:U\to S$ Let $\pi(u,v,d):=C(u,v,d)/d$, with the following definitions: A ""circle""  is the set of all points $p\in S$ of distance $d/2$ to some fixed point $q=X(u,v)$ (where distance is measured using the metric $G=dX^TdX$), And $C(u,v,d)$ is the arclength of the curve (parameterized in local coordinates by $\gamma(u,v,d)$) defined by this set. (Feel free to suggest other more general definitions if you think they might be helpful) First off: Is there any surface other than the plane for which $\pi(u,v,d)=const$? Is there any other surface on which $\pi(u,v,d)=\pi(u,v)$ (i.e. its constant per point) I'm essentially asking if the fact that $\pi$ is irrational is somehow ""built-in"" to reality, or are there some more ""rational"" realities where, say, $\pi==22/7$. ~ Appendix: I'm reminded vaguely of the mean value theorem for harmonic functions (and solutions of the heat equation), which states that the mean value of any harmonic function $f$ over any set of concentric circles is constant. Assuming this even applies in the case of a harmonic function over some general metric space (does it?), can we somehow interpret $C/d$ as the (reciprocal?) mean value over circles of a harmonic function, and thereby at least prove (2)? The mean around some point $(u,v)$ would be calculated as: $\mu(u,v,d)=\frac{\int_\gamma f(\gamma(u,v,d)) ds}{C(u,v,d)}$ Perhaps the above question can then be rephrased as follows: Is there any surface on which we can define some harmonic function for which $\mu(u,v,d)=d/C(u,v,d)$, in which case we get by the mean value theorem that $\pi$ is constant per point, and further is there any such surface+harmonic function combination for which $\mu(u,v,d)=d/C=const.$ ?",,"['differential-geometry', 'metric-spaces', 'harmonic-functions', 'pi']"
9,Trivial connections on trivial bundles,Trivial connections on trivial bundles,,"In Cliff Taubes' book ""Differential geometry"", he explains how to define the trivial connection on the product principal bundle $U \times G,$ where $G$ is a Lie group.  Namely, the trivial connection $A_0$ is a Lie(G)-valued 1-form which is defined at the point $(p, g) \in U \times G$ by $g^{-1}dg.$ I am confused about what $dg$ is supposed to mean. Possible interpretation: we could view $g$ as the identity function on the underlying Lie group.  Then $dg$ is just the differential, which takes a tangent vector $X \in T_gG$ to itself. We view $g^{-1}$ as the differential of the group multiplication map $h \mapsto g^{-1}\cdot h.$  Then $g^{-1} dg$ maps $T_gG \to T_eG$ and hence is indeed a Lie algebra value 1-form. However, this interpretation seems strange because it treats both $dg$ and $g^{-1}$ as differentials, even though the $d$ is missing from the second symbol. Is my interpretation wrong? If so, could someone provide a correct interpretation?","In Cliff Taubes' book ""Differential geometry"", he explains how to define the trivial connection on the product principal bundle $U \times G,$ where $G$ is a Lie group.  Namely, the trivial connection $A_0$ is a Lie(G)-valued 1-form which is defined at the point $(p, g) \in U \times G$ by $g^{-1}dg.$ I am confused about what $dg$ is supposed to mean. Possible interpretation: we could view $g$ as the identity function on the underlying Lie group.  Then $dg$ is just the differential, which takes a tangent vector $X \in T_gG$ to itself. We view $g^{-1}$ as the differential of the group multiplication map $h \mapsto g^{-1}\cdot h.$  Then $g^{-1} dg$ maps $T_gG \to T_eG$ and hence is indeed a Lie algebra value 1-form. However, this interpretation seems strange because it treats both $dg$ and $g^{-1}$ as differentials, even though the $d$ is missing from the second symbol. Is my interpretation wrong? If so, could someone provide a correct interpretation?",,"['differential-geometry', 'differential-topology', 'fiber-bundles', 'connections', 'gauge-theory']"
10,Are smooth functions generically immersions?,Are smooth functions generically immersions?,,"Let $T^2$ be the torus and let $\mathcal{C}^{\infty}(T^2, \mathbb{R}^3)$ be the space of smooth functions from $T^2$ to $\mathbb{R}^3$ endowed with the norm $\|f\| = \sup_x |f(x)| + \sup_x \|df_x\|$. Is a generic function $f \in \mathcal{C}^{\infty}(T^2, \mathbb{R}^3)$ an immersion? That is, is the set  $$     \{f \in \mathcal{C}^{\infty}(T^2, \mathbb{R}^3) \,|\, \forall x,\, \text{rank}\,df_x = 2 \} $$ open and dense in $\mathcal{C}^\infty(T^2, \mathbb{R}^3)$? Openess is clear. What I'm not sure about is if any smooth function can be well approximated by an immersion. This seems to be true for embeddings in $\mathcal{C}^\infty(M, R^N)$ where $N > 2 \dim M$, as a corollary of Whitney's embedding theorem proof.","Let $T^2$ be the torus and let $\mathcal{C}^{\infty}(T^2, \mathbb{R}^3)$ be the space of smooth functions from $T^2$ to $\mathbb{R}^3$ endowed with the norm $\|f\| = \sup_x |f(x)| + \sup_x \|df_x\|$. Is a generic function $f \in \mathcal{C}^{\infty}(T^2, \mathbb{R}^3)$ an immersion? That is, is the set  $$     \{f \in \mathcal{C}^{\infty}(T^2, \mathbb{R}^3) \,|\, \forall x,\, \text{rank}\,df_x = 2 \} $$ open and dense in $\mathcal{C}^\infty(T^2, \mathbb{R}^3)$? Openess is clear. What I'm not sure about is if any smooth function can be well approximated by an immersion. This seems to be true for embeddings in $\mathcal{C}^\infty(M, R^N)$ where $N > 2 \dim M$, as a corollary of Whitney's embedding theorem proof.",,"['differential-geometry', 'reference-request', 'differential-topology']"
11,Are small balls in a metric space quasi-symmetric to a compact ball connected?,Are small balls in a metric space quasi-symmetric to a compact ball connected?,,"I'm trying to solve a problem but I'm stuck. Maybe someone can help me. I will denote every metric on every metric space by $d$ and I will use closed balls, denoting them with the letter $B$, so for $x\in X$ and $r>0$ $$B(x,r)\colon=\lbrace y\in X\:\colon \: d(x,y)\leq r\rbrace.$$ To the problem: let $X$ be a metric space and let $V$ be a compact ball inside a Carnot group $G$, endowed with the usual CC metric. Assume that there exists a quasi-symmetric homeomorphism $f\colon V\longrightarrow X$. Question: Are small enough balls in $X$ connected? That is, does there exists a constant $K>0$ such that all balls of radius $\leq K$ in $X$ are connected? Intuitively I think that the answer should be yes: $V$ is a closed ball inside a Carnot group and therefore is compact, connected, simply connected i.e. very nice. $X$ not only is homeomorphic to $V$ but it's also quasi-symmetrically equivalent to it. It cannot be that ugly, right? All the ""bad cases"" I can think of do not have compact boundary. I tried using that quasi-symmetric maps on uniformly perfect spaces are $\alpha$-Hölder continuous for some $\alpha\in (0,1]$: $\textbf{Lemma:}$ Suppose that $X$ is a bounded and uniformly perfect metric space. Let $f\colon X\longrightarrow Y$ be a quasisymmetric homeomorphism. Then there are constants $A,B\geq 1$ and $\alpha\in (0,1]$ such that  $$ \frac{1}{A}d(x,y)^{1/\alpha}\leq d(f(x), f(y))\leq Bd(x,y)^\alpha.$$ Since connected spaces are uniformly perfect we can apply this to our situation to obtain that for every closed ball $B(x,r)$ there is a connected set $U$ and a constant $D$ such that $$ B(x,\frac{1}{D}r^{1/\alpha^2}) \subset U\subset B(x,r).$$  I'm not sure this is the right approach as I can't make any progress from here. I'm aware that since the metric space is compact, it would be enough to show that the closure of each open ball is the closed ball with the same radius, in order to say that balls are connected. But I couldn't show this and I don't even expect every ball to be connected.. Does anyone have other ideas that I can try? Thank you very much!","I'm trying to solve a problem but I'm stuck. Maybe someone can help me. I will denote every metric on every metric space by $d$ and I will use closed balls, denoting them with the letter $B$, so for $x\in X$ and $r>0$ $$B(x,r)\colon=\lbrace y\in X\:\colon \: d(x,y)\leq r\rbrace.$$ To the problem: let $X$ be a metric space and let $V$ be a compact ball inside a Carnot group $G$, endowed with the usual CC metric. Assume that there exists a quasi-symmetric homeomorphism $f\colon V\longrightarrow X$. Question: Are small enough balls in $X$ connected? That is, does there exists a constant $K>0$ such that all balls of radius $\leq K$ in $X$ are connected? Intuitively I think that the answer should be yes: $V$ is a closed ball inside a Carnot group and therefore is compact, connected, simply connected i.e. very nice. $X$ not only is homeomorphic to $V$ but it's also quasi-symmetrically equivalent to it. It cannot be that ugly, right? All the ""bad cases"" I can think of do not have compact boundary. I tried using that quasi-symmetric maps on uniformly perfect spaces are $\alpha$-Hölder continuous for some $\alpha\in (0,1]$: $\textbf{Lemma:}$ Suppose that $X$ is a bounded and uniformly perfect metric space. Let $f\colon X\longrightarrow Y$ be a quasisymmetric homeomorphism. Then there are constants $A,B\geq 1$ and $\alpha\in (0,1]$ such that  $$ \frac{1}{A}d(x,y)^{1/\alpha}\leq d(f(x), f(y))\leq Bd(x,y)^\alpha.$$ Since connected spaces are uniformly perfect we can apply this to our situation to obtain that for every closed ball $B(x,r)$ there is a connected set $U$ and a constant $D$ such that $$ B(x,\frac{1}{D}r^{1/\alpha^2}) \subset U\subset B(x,r).$$  I'm not sure this is the right approach as I can't make any progress from here. I'm aware that since the metric space is compact, it would be enough to show that the closure of each open ball is the closed ball with the same radius, in order to say that balls are connected. But I couldn't show this and I don't even expect every ball to be connected.. Does anyone have other ideas that I can try? Thank you very much!",,"['differential-geometry', 'metric-spaces', 'metric-geometry']"
12,Question about volume preserving transformations,Question about volume preserving transformations,,"I will denote by $d$-vol the $d$ dimensional volume in $\mathbb{R}^D$, where $D \geq d$. For example, if $A=\{(x,y,0)\in\mathbb{R}^3:\text{max}(|x|,|y|)\leq 1\}$, then $3\mbox{-}\text{vol}(A)=0$ but $2\mbox{-}\text{vol}(A)=4$. I know that if $f:\mathbb{R}^D \rightarrow \mathbb{R}^D$ is a differentiable and invertible function, the change of $D$-volume induced by $f$ is $|\text{det}(J)|$, where $J$ is the Jacobian of $f$. Thus, for $f$ to be a $D$-volume preserving transformation we need to ensure that $|\text{det}(J)|=1$. However, if $f$ is $D$-volume preserving it need not be $d$-volume preserving for $d<D$. I was wondering what the equivalent condition is for $f:\mathbb{R}^D \rightarrow \mathbb{R}^D$ to be $d$-volume preserving. Thank you very much!","I will denote by $d$-vol the $d$ dimensional volume in $\mathbb{R}^D$, where $D \geq d$. For example, if $A=\{(x,y,0)\in\mathbb{R}^3:\text{max}(|x|,|y|)\leq 1\}$, then $3\mbox{-}\text{vol}(A)=0$ but $2\mbox{-}\text{vol}(A)=4$. I know that if $f:\mathbb{R}^D \rightarrow \mathbb{R}^D$ is a differentiable and invertible function, the change of $D$-volume induced by $f$ is $|\text{det}(J)|$, where $J$ is the Jacobian of $f$. Thus, for $f$ to be a $D$-volume preserving transformation we need to ensure that $|\text{det}(J)|=1$. However, if $f$ is $D$-volume preserving it need not be $d$-volume preserving for $d<D$. I was wondering what the equivalent condition is for $f:\mathbb{R}^D \rightarrow \mathbb{R}^D$ to be $d$-volume preserving. Thank you very much!",,"['differential-geometry', 'volume']"
13,Tensor characterization,Tensor characterization,,"I want to show that $T^{1}_{1}(V)$ is isomorphic to $End(V)$. I know how to produce a linear map from $h:End(V)$ to $T^{1}_{1}(V)$, i.e. send $f \in End(V)$ to $hf(w,v) = w(f(v))$, but how to write down its inverse explicitly since I want to calculate the trace of its inverse?","I want to show that $T^{1}_{1}(V)$ is isomorphic to $End(V)$. I know how to produce a linear map from $h:End(V)$ to $T^{1}_{1}(V)$, i.e. send $f \in End(V)$ to $hf(w,v) = w(f(v))$, but how to write down its inverse explicitly since I want to calculate the trace of its inverse?",,"['linear-algebra', 'differential-geometry', 'differential-topology', 'tensors']"
14,Osculating circle,Osculating circle,,"Compute the radius of osculating circle of the hyperbola $$\frac{x^2}{a^2}-\frac{y^2}{b^2}=1$$ at one of its vertices and give a geometrical method for the construction of this osculating circle. Consider the particular case of equilateral hyperbola $x^2-y^2=a^2$ I computed the radius on the vertex $(a,0)$ by finding the reciprocal of the curvature of hyperbola. Which is $r=\frac{1}{|\kappa|}=\frac {b^2}{a}. \ $ Now how can I solve the next part? ""give a geometrical method for the construction of this osculating circle""","Compute the radius of osculating circle of the hyperbola $$\frac{x^2}{a^2}-\frac{y^2}{b^2}=1$$ at one of its vertices and give a geometrical method for the construction of this osculating circle. Consider the particular case of equilateral hyperbola $x^2-y^2=a^2$ I computed the radius on the vertex $(a,0)$ by finding the reciprocal of the curvature of hyperbola. Which is $r=\frac{1}{|\kappa|}=\frac {b^2}{a}. \ $ Now how can I solve the next part? ""give a geometrical method for the construction of this osculating circle""",,"['calculus', 'differential-geometry', 'conic-sections']"
15,Ricci Flow on a Sphere of radius r,Ricci Flow on a Sphere of radius r,,"Let $(M, g)$ be an $n$-sphere of radius $r$ with metric $g$ where $g = r^{2}g_{\mathbb{S}^{n}}$, $g_{\mathbb{S}^{n}}$ being the standard metric on the unit $n$-sphere. It is well known that $Ric_{g}=(n-1)g_{\mathbb{S}^{n}}$. If we apply Ricci flow on $M$ does the shape of the sphere change? The evolution equation is $\cfrac{\partial}{\partial t}g =\cfrac{\partial}{\partial t} (r^{2}g_{\mathbb{S}^{n}}) = -2Ric_{g}$. Now the left-hand side should give us $2r\dot{r} g_{\mathbb{S}^{n}}+\cfrac{\partial}{\partial t}g_{\mathbb{S}^{n}} $. However, most books and notes on Ricci flow say: $\cfrac{\partial}{\partial t} (r^{2}g_{\mathbb{S}^{n}}) = -2Ric_{g}$  $ \implies 2r\dot{r}g_{\mathbb{S}^{n}}= -2(n-1)g_{\mathbb{S}^{n}}$ $\implies r\dot{r}=-(n-1)$. My question is what happens to the term $\cfrac{\partial}{\partial t}g_{\mathbb{S}^{n}}$? Does the metric $g_{\mathbb{S}^{n}}$ not change under the flow? Why? Am I missing something? Thanks in advance.","Let $(M, g)$ be an $n$-sphere of radius $r$ with metric $g$ where $g = r^{2}g_{\mathbb{S}^{n}}$, $g_{\mathbb{S}^{n}}$ being the standard metric on the unit $n$-sphere. It is well known that $Ric_{g}=(n-1)g_{\mathbb{S}^{n}}$. If we apply Ricci flow on $M$ does the shape of the sphere change? The evolution equation is $\cfrac{\partial}{\partial t}g =\cfrac{\partial}{\partial t} (r^{2}g_{\mathbb{S}^{n}}) = -2Ric_{g}$. Now the left-hand side should give us $2r\dot{r} g_{\mathbb{S}^{n}}+\cfrac{\partial}{\partial t}g_{\mathbb{S}^{n}} $. However, most books and notes on Ricci flow say: $\cfrac{\partial}{\partial t} (r^{2}g_{\mathbb{S}^{n}}) = -2Ric_{g}$  $ \implies 2r\dot{r}g_{\mathbb{S}^{n}}= -2(n-1)g_{\mathbb{S}^{n}}$ $\implies r\dot{r}=-(n-1)$. My question is what happens to the term $\cfrac{\partial}{\partial t}g_{\mathbb{S}^{n}}$? Does the metric $g_{\mathbb{S}^{n}}$ not change under the flow? Why? Am I missing something? Thanks in advance.",,"['differential-geometry', 'ricci-flow']"
16,Identify the kernel of an induced Lie algebra homomorphism with a Lie subalgebra,Identify the kernel of an induced Lie algebra homomorphism with a Lie subalgebra,,"Suppose $G,H$ are Lie groups and $F:G\to H$ is a Lie group homomorphism. Suppose $\mathfrak f: \mathfrak g\to\mathfrak h$ is the induced Lie algebra homomorphism, show that we can identify $\DeclareMathOperator{\ker}{ker}\ker\mathfrak f$ with $\DeclareMathOperator{\Lie}{Lie}\Lie(\ker F)$ in the sense that   $$\ker\mathfrak f=\{X\in \mathfrak g\mid X_e\in d(\iota)_e(T_e(\ker F))\}\cong \Lie(\ker F).$$   in which $\iota : \ker F\to G$ is the inclusion map. I'm aware that $\mathfrak f(X)=0\iff \mathfrak f(X)_e = d(F)_e(X_e)=0$. If $X\in \Lie(\ker F)$ then it is equal to saying $\exists v\in T_e(\ker F)$ such that  $X_e=d(\iota)_e(v)$ and  $$d(F)_e(X_e)=d(F)_e(d(\iota)_e(v))=d(F\circ\iota)_e(v)=d(F|_{\ker F})_e(v)$$ where $F|_{\ker F}\equiv e\in G$ is a constant map, hence its differential vanishes and $d(F|_{\ker F})_e(v)=0$. And therefore we have proved $\Lie(\ker F)\subset \ker\mathfrak f$ under our identification. What about the other direction? Given only $d(F)_e(X_e)=0$ there seems to be no easy way to extract more information from it. Any help? Thanks in advance.","Suppose $G,H$ are Lie groups and $F:G\to H$ is a Lie group homomorphism. Suppose $\mathfrak f: \mathfrak g\to\mathfrak h$ is the induced Lie algebra homomorphism, show that we can identify $\DeclareMathOperator{\ker}{ker}\ker\mathfrak f$ with $\DeclareMathOperator{\Lie}{Lie}\Lie(\ker F)$ in the sense that   $$\ker\mathfrak f=\{X\in \mathfrak g\mid X_e\in d(\iota)_e(T_e(\ker F))\}\cong \Lie(\ker F).$$   in which $\iota : \ker F\to G$ is the inclusion map. I'm aware that $\mathfrak f(X)=0\iff \mathfrak f(X)_e = d(F)_e(X_e)=0$. If $X\in \Lie(\ker F)$ then it is equal to saying $\exists v\in T_e(\ker F)$ such that  $X_e=d(\iota)_e(v)$ and  $$d(F)_e(X_e)=d(F)_e(d(\iota)_e(v))=d(F\circ\iota)_e(v)=d(F|_{\ker F})_e(v)$$ where $F|_{\ker F}\equiv e\in G$ is a constant map, hence its differential vanishes and $d(F|_{\ker F})_e(v)=0$. And therefore we have proved $\Lie(\ker F)\subset \ker\mathfrak f$ under our identification. What about the other direction? Given only $d(F)_e(X_e)=0$ there seems to be no easy way to extract more information from it. Any help? Thanks in advance.",,"['differential-geometry', 'differential-topology', 'lie-groups', 'lie-algebras']"
17,Explicit computation moment map complex projective space,Explicit computation moment map complex projective space,,"Consider the hamiltonian action of $T^2$ on $\mathbb{CP}^2$ : $$ \varphi: ((e^{i\theta_1},e^{i\theta_2}),[z_0:z_1:z_2]) \longmapsto [z_0:e^{i\theta_1}z_1,e^{i\theta_2}z_2].$$ I've read that its moment map is $$ \mu (z_0,z_1,z_2) = -\tfrac{1}{2} (\tfrac{|z_1|^2}{|z_0|^2+|z_1|^2+|z_2|^2},\tfrac{|z_2|^2}{|z_0|^2+|z_1|^2+|z_2|^2}).$$ How can I show this with a explicit calculation of $d\mu^X$ and $i_{X^\#}\omega $   to show they are equal? I could do this with the same action but on $\mathbb{C}^2$, with polar coordinates. Would this work in this case, if yes what would be the equivalent of polar coordinates for projective space?","Consider the hamiltonian action of $T^2$ on $\mathbb{CP}^2$ : $$ \varphi: ((e^{i\theta_1},e^{i\theta_2}),[z_0:z_1:z_2]) \longmapsto [z_0:e^{i\theta_1}z_1,e^{i\theta_2}z_2].$$ I've read that its moment map is $$ \mu (z_0,z_1,z_2) = -\tfrac{1}{2} (\tfrac{|z_1|^2}{|z_0|^2+|z_1|^2+|z_2|^2},\tfrac{|z_2|^2}{|z_0|^2+|z_1|^2+|z_2|^2}).$$ How can I show this with a explicit calculation of $d\mu^X$ and $i_{X^\#}\omega $   to show they are equal? I could do this with the same action but on $\mathbb{C}^2$, with polar coordinates. Would this work in this case, if yes what would be the equivalent of polar coordinates for projective space?",,"['differential-geometry', 'complex-geometry', 'projective-geometry', 'symplectic-geometry', 'moment-map']"
18,Surface gradient and curvature,Surface gradient and curvature,,"I am trying to get familiar with the surface gradient operator, i.e. $\nabla_S = (I-\mathbf{n}\mathbf{n})\cdot \nabla$, where $\mathbf{n}$ is the unit normal to the surface and $I$ the identity tensor. I have seen in a paper that, for an axysimmetric surface, the mean curvature is $\kappa = \nabla \cdot\mathbf{n} = \nabla_S \cdot \mathbf{n}$, however I cannot get the latter. We can define the surface as $f = r - a(z)$, thus $\mathbf{n} = \nabla \, f / ||\nabla \,f|| = 1/\sqrt{1+(a')^2} \, \mathbf{e_r} -a'/\sqrt{1+(a')^2} \, \mathbf{e_z} = (1/\sqrt{1+(a')^2},0,-a'/\sqrt{1+(a')^2})$, and: $\kappa = \nabla \cdot \mathbf{n} = \dfrac{1}{a\sqrt{1+(a')^2}} - \dfrac{a''}{[1+(a')^2]^{3/2}}$ However I do not obtain the same result with the surface operator, $\nabla_S = (I-\mathbf{n}\mathbf{n})\cdot \nabla = \left(\frac{(a')^2}{1+(a')^2}\frac{\partial}{\partial r} + \frac{a'}{1+(a')^2}\frac{\partial }{\partial z},0,\frac{a'}{1+(a')^2} \frac{\partial}{\partial r} + \frac{1}{1+(a')^2} \frac{\partial}{\partial z}\right)$, $\nabla_S \cdot \mathbf{n} = - \dfrac{a''}{[1+(a')^2]^{3/2}}$, which is just the axial contirbution of the mean curvature. Is this correct and the paper is wrong? Or am I making a mistake in the procedure?","I am trying to get familiar with the surface gradient operator, i.e. $\nabla_S = (I-\mathbf{n}\mathbf{n})\cdot \nabla$, where $\mathbf{n}$ is the unit normal to the surface and $I$ the identity tensor. I have seen in a paper that, for an axysimmetric surface, the mean curvature is $\kappa = \nabla \cdot\mathbf{n} = \nabla_S \cdot \mathbf{n}$, however I cannot get the latter. We can define the surface as $f = r - a(z)$, thus $\mathbf{n} = \nabla \, f / ||\nabla \,f|| = 1/\sqrt{1+(a')^2} \, \mathbf{e_r} -a'/\sqrt{1+(a')^2} \, \mathbf{e_z} = (1/\sqrt{1+(a')^2},0,-a'/\sqrt{1+(a')^2})$, and: $\kappa = \nabla \cdot \mathbf{n} = \dfrac{1}{a\sqrt{1+(a')^2}} - \dfrac{a''}{[1+(a')^2]^{3/2}}$ However I do not obtain the same result with the surface operator, $\nabla_S = (I-\mathbf{n}\mathbf{n})\cdot \nabla = \left(\frac{(a')^2}{1+(a')^2}\frac{\partial}{\partial r} + \frac{a'}{1+(a')^2}\frac{\partial }{\partial z},0,\frac{a'}{1+(a')^2} \frac{\partial}{\partial r} + \frac{1}{1+(a')^2} \frac{\partial}{\partial z}\right)$, $\nabla_S \cdot \mathbf{n} = - \dfrac{a''}{[1+(a')^2]^{3/2}}$, which is just the axial contirbution of the mean curvature. Is this correct and the paper is wrong? Or am I making a mistake in the procedure?",,"['differential-geometry', 'surfaces', 'curvature']"
19,Example of a symplectic manifold with given properties,Example of a symplectic manifold with given properties,,"Is there an example of a simply-connected, compact, symplectic manifold $(M,\omega)$ such that $\omega|_{\pi_2(M)}=0$ (in the sense that $\int_{S^2} \sigma^* \omega=0$ for any smooth map $\sigma: S^2 \to M$)? Preferably with $\pi_2(M)$ being free. This question is motivated due to the usual hypotheses made on $(M,\omega)$ in order for the related action functional to be well-defined.","Is there an example of a simply-connected, compact, symplectic manifold $(M,\omega)$ such that $\omega|_{\pi_2(M)}=0$ (in the sense that $\int_{S^2} \sigma^* \omega=0$ for any smooth map $\sigma: S^2 \to M$)? Preferably with $\pi_2(M)$ being free. This question is motivated due to the usual hypotheses made on $(M,\omega)$ in order for the related action functional to be well-defined.",,"['differential-geometry', 'differential-topology', 'symplectic-geometry']"
20,Expression of $R_{ijk}^s$ in terms of coefficients $\Gamma_{ij}^k$ of the Riemannian connection,Expression of  in terms of coefficients  of the Riemannian connection,R_{ijk}^s \Gamma_{ij}^k,"Let $R$ be the curvature of a Riemannian manifold $M$ defined by    $$ R(X,Y)Z=\nabla_Y \nabla_X Z - \nabla_X \nabla_Y Z + \nabla_{[X,Y]}Z, $$   where $X,Y,Z$ are vector fields and $\nabla$ is the Riemannian connection of $M$. Let us indicate as usual $\frac{\partial}{\partial x_i}=X_i$. We put   $$ R(X_i,X_j)X_k = \sum_\ell R_{ijk}^\ell X_\ell. $$   Thus, $R_{ijk}^\ell$ are the components of the curvature $R$ in $(U,\mathbf x)$. If   $$ X=\sum_i u^i X_i, \qquad Y=\sum_j v^j X_j, \qquad Z=\sum_k w^k X_k, $$   we obtain, from the linearity of $R$,   $$ R(X,Y)Z=\sum_{i,j,k,\ell} R_{ijk}^\ell u^i v^j w^k X_\ell. $$   To express $R_{ijk}^\ell$ in terms of the coefficients $\Gamma_{ij}^k$ of the Riemannian connection, we write   \begin{align} R(X_i,X_j)X_k &= \nabla_{X_j} \nabla_{X_i} X_k -  \nabla_{X_i} \nabla_{X_j} X_k \\ &= \nabla_{X_j} \left(\sum_{\ell} \Gamma_{ik}^\ell X_\ell \right) -  \nabla_{X_i} \left(\sum_{\ell} \Gamma_{jk}^\ell X_\ell \right), \end{align}   which by a direct calculation yields   $$ R_{ijk}^s = \sum_\ell \Gamma_{ik}^\ell \Gamma_{j\ell}^s - \sum_\ell \Gamma_{jk}^\ell \Gamma_{i\ell}^s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s. $$ This is taken from Riemannian Geometry by Manfredo do Carmo, pp. 93–94. My question is how do we justify this direction calculation? There are two expressions of $R(X_i,X_j)X_k$. Equating those two expressions and taking the $s$-th index of the summation $\ell=1,\ldots,n$,  $$ R_{ijk}^s X_s = \nabla_{X_j} \Gamma_{ik}^s X_s -  \nabla_{X_i} \Gamma_{jk}^s X_s. $$ Using product rule, I think we obtain that \begin{align} R_{ijk}^s X_s &= \left(\frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s + \Gamma_{ik}^s \nabla_{X_j} X_s \right)- \left(\frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s + \Gamma_{jk}^s \nabla_{X_i} X_s \right) \\  &= \Gamma_{ik}^s \nabla_{X_j} X_s - \Gamma_{jk}^s \nabla_{X_i} X_s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s. \end{align} Recalling the definition $\nabla_{X_i} X_k = \sum_\ell \Gamma_{ik}^\ell X_\ell$,  \begin{align} R_{ijk}^s X_s &= \sum_\ell \Gamma_{ik}^s \Gamma_{js}^\ell X_\ell - \sum_\ell \Gamma_{jk}^s \Gamma_{is}^\ell X_\ell + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s \\  &= \sum_s \Gamma_{ik}^\ell \Gamma_{j\ell}^s X_s - \sum_s \Gamma_{jk}^\ell \Gamma_{i\ell}^s X_s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s. \end{align} (I achieved the last step by switching the dummy indices: interchanging the roles of $\ell$ and $s$.) Then I would cancel $X_s$ from both sides to obtain: $$ R_{ijk}^s = \sum_s \Gamma_{ik}^\ell \Gamma_{j\ell}^s - \sum_s \Gamma_{jk}^\ell \Gamma_{i\ell}^s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s. $$ However, the summations in my ""equality"" are over $s$, not over $\ell$ which is what the textbook printed. I would like to know where I went wrong in my alleged justification above.","Let $R$ be the curvature of a Riemannian manifold $M$ defined by    $$ R(X,Y)Z=\nabla_Y \nabla_X Z - \nabla_X \nabla_Y Z + \nabla_{[X,Y]}Z, $$   where $X,Y,Z$ are vector fields and $\nabla$ is the Riemannian connection of $M$. Let us indicate as usual $\frac{\partial}{\partial x_i}=X_i$. We put   $$ R(X_i,X_j)X_k = \sum_\ell R_{ijk}^\ell X_\ell. $$   Thus, $R_{ijk}^\ell$ are the components of the curvature $R$ in $(U,\mathbf x)$. If   $$ X=\sum_i u^i X_i, \qquad Y=\sum_j v^j X_j, \qquad Z=\sum_k w^k X_k, $$   we obtain, from the linearity of $R$,   $$ R(X,Y)Z=\sum_{i,j,k,\ell} R_{ijk}^\ell u^i v^j w^k X_\ell. $$   To express $R_{ijk}^\ell$ in terms of the coefficients $\Gamma_{ij}^k$ of the Riemannian connection, we write   \begin{align} R(X_i,X_j)X_k &= \nabla_{X_j} \nabla_{X_i} X_k -  \nabla_{X_i} \nabla_{X_j} X_k \\ &= \nabla_{X_j} \left(\sum_{\ell} \Gamma_{ik}^\ell X_\ell \right) -  \nabla_{X_i} \left(\sum_{\ell} \Gamma_{jk}^\ell X_\ell \right), \end{align}   which by a direct calculation yields   $$ R_{ijk}^s = \sum_\ell \Gamma_{ik}^\ell \Gamma_{j\ell}^s - \sum_\ell \Gamma_{jk}^\ell \Gamma_{i\ell}^s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s. $$ This is taken from Riemannian Geometry by Manfredo do Carmo, pp. 93–94. My question is how do we justify this direction calculation? There are two expressions of $R(X_i,X_j)X_k$. Equating those two expressions and taking the $s$-th index of the summation $\ell=1,\ldots,n$,  $$ R_{ijk}^s X_s = \nabla_{X_j} \Gamma_{ik}^s X_s -  \nabla_{X_i} \Gamma_{jk}^s X_s. $$ Using product rule, I think we obtain that \begin{align} R_{ijk}^s X_s &= \left(\frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s + \Gamma_{ik}^s \nabla_{X_j} X_s \right)- \left(\frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s + \Gamma_{jk}^s \nabla_{X_i} X_s \right) \\  &= \Gamma_{ik}^s \nabla_{X_j} X_s - \Gamma_{jk}^s \nabla_{X_i} X_s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s. \end{align} Recalling the definition $\nabla_{X_i} X_k = \sum_\ell \Gamma_{ik}^\ell X_\ell$,  \begin{align} R_{ijk}^s X_s &= \sum_\ell \Gamma_{ik}^s \Gamma_{js}^\ell X_\ell - \sum_\ell \Gamma_{jk}^s \Gamma_{is}^\ell X_\ell + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s \\  &= \sum_s \Gamma_{ik}^\ell \Gamma_{j\ell}^s X_s - \sum_s \Gamma_{jk}^\ell \Gamma_{i\ell}^s X_s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s X_s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s X_s. \end{align} (I achieved the last step by switching the dummy indices: interchanging the roles of $\ell$ and $s$.) Then I would cancel $X_s$ from both sides to obtain: $$ R_{ijk}^s = \sum_s \Gamma_{ik}^\ell \Gamma_{j\ell}^s - \sum_s \Gamma_{jk}^\ell \Gamma_{i\ell}^s + \frac{\partial}{\partial x_j} \Gamma_{ik}^s - \frac{\partial}{\partial x_i} \Gamma_{jk}^s. $$ However, the summations in my ""equality"" are over $s$, not over $\ell$ which is what the textbook printed. I would like to know where I went wrong in my alleged justification above.",,"['differential-geometry', 'riemannian-geometry', 'curvature', 'connections']"
21,Rudin's PMA Chapter 10,Rudin's PMA Chapter 10,,I am having a hard time trying to learn Rudin's Principles of Mathematica Analysis chapter 10 on differential forms. Please suggest a book for reference on this chapter. I would most prefer a book where there is a lot of geometric intuition. Also I don't know Vector calculus. Let me know if I need to learn that before learning this chapter. In that case suggest a book for that as well. Please take note that this is for self study. Thanks.,I am having a hard time trying to learn Rudin's Principles of Mathematica Analysis chapter 10 on differential forms. Please suggest a book for reference on this chapter. I would most prefer a book where there is a lot of geometric intuition. Also I don't know Vector calculus. Let me know if I need to learn that before learning this chapter. In that case suggest a book for that as well. Please take note that this is for self study. Thanks.,,"['real-analysis', 'differential-geometry', 'reference-request', 'self-learning', 'differential-forms']"
22,not surjective implies degree 0,not surjective implies degree 0,,"This seems like an easy question, but I can't get my head around it. Consider manifolds $M$, $N$, $F \in C^\infty(M,N)$, $\dim(M) = \dim(N)$, $M$ compact, $N$ connected.    The degree of $F$ is defined as the number of points in the preimage of some regular value $q$ of $F$ in $N$, that is $$\deg_2(F) := \operatorname{card}(F^{-1}(\{q\})) \mod 2.$$ (This is well defined by homotopy invariance.) Why is $\deg_2(F)=0$ if $F$ is not surjective?","This seems like an easy question, but I can't get my head around it. Consider manifolds $M$, $N$, $F \in C^\infty(M,N)$, $\dim(M) = \dim(N)$, $M$ compact, $N$ connected.    The degree of $F$ is defined as the number of points in the preimage of some regular value $q$ of $F$ in $N$, that is $$\deg_2(F) := \operatorname{card}(F^{-1}(\{q\})) \mod 2.$$ (This is well defined by homotopy invariance.) Why is $\deg_2(F)=0$ if $F$ is not surjective?",,"['differential-geometry', 'differential-topology']"
23,About the proof of the Four Vertex Theorem of Do Carmo.,About the proof of the Four Vertex Theorem of Do Carmo.,,"I have problems understanding this part of the proof given by Manfredo Do Carmo in Differential Geometry of Curves for the theorem of The Four-Vertex Theorem . I understand that in the first part he considers that exists a maximum and a minimum just because the parametrization of the curve is a mapping from $\mathbb{R}$ to $\mathbb{R}^2$. The next part is the one that I don't understand; he considers a line $L$ through those vertices where are the max and min of the curve, then he says this: Let $Ax + By + C = 0$ be the equation of $L$. If there are no further   vertices, $k'(s)$ keeps a constant sign on each of the arcs $\beta$ and $\gamma$ (until here, I understand it). We can then arrange the sign of all the coefficients $A, B, C$ so that the integral in Eq. (5)   is positive. This contradiction shows that there is a third vertex and that   $k'(s)$ changes sign on $\beta$ or $\gamma$, say, on $\beta$. Since $p$ and $q$ are points of maximum and minimum, $k'(s)$ changes sign twice on $p$. Thus, there is a fourth vertex. The integral he refferes as Eq.(5) is: $$\int_0^l (Ax+By+C)\frac{dk}{ds}ds=0$$ So I don't know how It would become a positive integral if it's zero.","I have problems understanding this part of the proof given by Manfredo Do Carmo in Differential Geometry of Curves for the theorem of The Four-Vertex Theorem . I understand that in the first part he considers that exists a maximum and a minimum just because the parametrization of the curve is a mapping from $\mathbb{R}$ to $\mathbb{R}^2$. The next part is the one that I don't understand; he considers a line $L$ through those vertices where are the max and min of the curve, then he says this: Let $Ax + By + C = 0$ be the equation of $L$. If there are no further   vertices, $k'(s)$ keeps a constant sign on each of the arcs $\beta$ and $\gamma$ (until here, I understand it). We can then arrange the sign of all the coefficients $A, B, C$ so that the integral in Eq. (5)   is positive. This contradiction shows that there is a third vertex and that   $k'(s)$ changes sign on $\beta$ or $\gamma$, say, on $\beta$. Since $p$ and $q$ are points of maximum and minimum, $k'(s)$ changes sign twice on $p$. Thus, there is a fourth vertex. The integral he refferes as Eq.(5) is: $$\int_0^l (Ax+By+C)\frac{dk}{ds}ds=0$$ So I don't know how It would become a positive integral if it's zero.",,"['differential-geometry', 'proof-explanation']"
24,Rate of change of direction of vector-valued function,Rate of change of direction of vector-valued function,,"This should be easy, but I cannot figure out what I'm doing wrong, and it's killing me. Let $\mathbf{f}(t)$ be a function from $\mathbb{R}$ to $\mathbb{R}^3$. I want to find the ""rate of change of the angle between $\mathbf{f}(t)$ and nearby vectors (from $\mathbf{f}$)"". I'm going to assume $|\mathbf{f}(t)|=1$, because it makes the writing easier, and doesn't change the answer I get. So we want to look at nearby vectors $\mathbf{f}(t+h)$, and the angle between that and $\mathbf{f}(t)$ is just $\mathbf{f}(t+h)\cdot\mathbf{f}(t)$. The rate of change is then $$ \lim_{h\to0}\dfrac{\mathbf{f}(t+h)\cdot\mathbf{f}(t)-1}{h} $$ And this is just $\mathbf{f}'(t)\cdot\mathbf{f}(t)$, which is $0$ (because of the assumption above about the norm of $\mathbf{f}$). But the right answer is (I think) $|\mathbf{f}'(t)|$. What am I doing wrong? For context, this comes up in do Carmo's book on Differential Geometry, where it is claimed that for an arc-length parameterized curve, $|\mathbf{\alpha}''(t)|$ measures the rate of change of direction for the tangent curves. Think of $\mathbf{f}$ above as $\mathbf{\alpha}'$.","This should be easy, but I cannot figure out what I'm doing wrong, and it's killing me. Let $\mathbf{f}(t)$ be a function from $\mathbb{R}$ to $\mathbb{R}^3$. I want to find the ""rate of change of the angle between $\mathbf{f}(t)$ and nearby vectors (from $\mathbf{f}$)"". I'm going to assume $|\mathbf{f}(t)|=1$, because it makes the writing easier, and doesn't change the answer I get. So we want to look at nearby vectors $\mathbf{f}(t+h)$, and the angle between that and $\mathbf{f}(t)$ is just $\mathbf{f}(t+h)\cdot\mathbf{f}(t)$. The rate of change is then $$ \lim_{h\to0}\dfrac{\mathbf{f}(t+h)\cdot\mathbf{f}(t)-1}{h} $$ And this is just $\mathbf{f}'(t)\cdot\mathbf{f}(t)$, which is $0$ (because of the assumption above about the norm of $\mathbf{f}$). But the right answer is (I think) $|\mathbf{f}'(t)|$. What am I doing wrong? For context, this comes up in do Carmo's book on Differential Geometry, where it is claimed that for an arc-length parameterized curve, $|\mathbf{\alpha}''(t)|$ measures the rate of change of direction for the tangent curves. Think of $\mathbf{f}$ above as $\mathbf{\alpha}'$.",,"['differential-geometry', 'vector-analysis', 'plane-curves']"
25,$n$-transitivity of $\operatorname{Diff}(M)$ acting on a smooth manifold $M$,-transitivity of  acting on a smooth manifold,n \operatorname{Diff}(M) M,"Let $M$ be a smooth connected manifold and $\operatorname{Diff}(M)$ the set of diffeomorphisms from $M$ to $M$. I would like to show that this group acts $n$-transitively on $M$. I started by showing transitivity. I looked at the orbit of one point and showed that is must be both open and closed (relying on the homogeneity of Euclidean space to whom $M$ is locally diffeomorphic and ""globalising"" via partitions of unity).The result thus follows from connectedness. Is there some nice way to adapt this argument to obtain $n$-transitivity? Maybe an induction? Thanks","Let $M$ be a smooth connected manifold and $\operatorname{Diff}(M)$ the set of diffeomorphisms from $M$ to $M$. I would like to show that this group acts $n$-transitively on $M$. I started by showing transitivity. I looked at the orbit of one point and showed that is must be both open and closed (relying on the homogeneity of Euclidean space to whom $M$ is locally diffeomorphic and ""globalising"" via partitions of unity).The result thus follows from connectedness. Is there some nice way to adapt this argument to obtain $n$-transitivity? Maybe an induction? Thanks",,"['differential-geometry', 'smooth-manifolds', 'group-actions']"
26,What is the Lie algebra of the Euclidean group?,What is the Lie algebra of the Euclidean group?,,"I am trying to find the Lie algebra for $E(n) = \left\{\begin{bmatrix}1 & 0^t \\ \mathbf{x} & A \end{bmatrix}: A \in SO(n), \mathbf{x} \in \mathbb{E}^n \right\}$. In particular, I would like to show that $\mathfrak{e}(n) = \left\{\begin{bmatrix}0 & 0^t \\ \mathbf{b} & B \end{bmatrix}:B \in \mathfrak{so}(n),\mathbf{b} \in  \mathbb{E}^n \right\}$ using only the definition that a Lie algebra is the tangent space at the identity of the Lie group. I've managed to show that $\mathfrak{so}(n)$ is the set of skew-symmetric matrices but I'm not sure how to proceed from there. Thank you in advance.","I am trying to find the Lie algebra for $E(n) = \left\{\begin{bmatrix}1 & 0^t \\ \mathbf{x} & A \end{bmatrix}: A \in SO(n), \mathbf{x} \in \mathbb{E}^n \right\}$. In particular, I would like to show that $\mathfrak{e}(n) = \left\{\begin{bmatrix}0 & 0^t \\ \mathbf{b} & B \end{bmatrix}:B \in \mathfrak{so}(n),\mathbf{b} \in  \mathbb{E}^n \right\}$ using only the definition that a Lie algebra is the tangent space at the identity of the Lie group. I've managed to show that $\mathfrak{so}(n)$ is the set of skew-symmetric matrices but I'm not sure how to proceed from there. Thank you in advance.",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
27,"Compute the Riemannian metric induced on $\mathbb{T^2}$ from $\mathbb{R}^3$ in the local coordinates $(θ, ϕ)$.",Compute the Riemannian metric induced on  from  in the local coordinates .,"\mathbb{T^2} \mathbb{R}^3 (θ, ϕ)","Let $a > b > 0$. Consider the torus $\mathbb{T}^2$ obtained by rotating the   circle of radius $b$ centered at $(a, 0, 0)$ (lying in the $xz$ plane) around the $z$ axis. It can be parametrized by local charts involving the restriction   of the map $(θ, ϕ) → ((a + b \cos ϕ) \cos θ,(a + b \cos ϕ) \sin θ, b \sin ϕ)$   to squares $I × J$ with $|I|, |J| < 2π$. This is same as $z^2 = 4b^2 − (\sqrt{x^2 + y^2}−(a − b))^2$ Compute the Riemannian metric induced on $\mathbb{T^2}$ from $\mathbb{R}^3$ in the local   coordinates $(θ, ϕ)$. The only thing that I know is Riemannian metric on a manifold $M$ is an inner product on $T_pM$ such that for each chart $(U,x)$ on $M$ the functions $g_{ij}=\langle\frac{\partial}{\partial x_i},\frac{\partial}{\partial x_j}\rangle$ are differentiable on $U$. This definition is really abstract and it does make any sense to me to apply it here. Could somebody please tell me how to find that inner product here?","Let $a > b > 0$. Consider the torus $\mathbb{T}^2$ obtained by rotating the   circle of radius $b$ centered at $(a, 0, 0)$ (lying in the $xz$ plane) around the $z$ axis. It can be parametrized by local charts involving the restriction   of the map $(θ, ϕ) → ((a + b \cos ϕ) \cos θ,(a + b \cos ϕ) \sin θ, b \sin ϕ)$   to squares $I × J$ with $|I|, |J| < 2π$. This is same as $z^2 = 4b^2 − (\sqrt{x^2 + y^2}−(a − b))^2$ Compute the Riemannian metric induced on $\mathbb{T^2}$ from $\mathbb{R}^3$ in the local   coordinates $(θ, ϕ)$. The only thing that I know is Riemannian metric on a manifold $M$ is an inner product on $T_pM$ such that for each chart $(U,x)$ on $M$ the functions $g_{ij}=\langle\frac{\partial}{\partial x_i},\frac{\partial}{\partial x_j}\rangle$ are differentiable on $U$. This definition is really abstract and it does make any sense to me to apply it here. Could somebody please tell me how to find that inner product here?",,"['differential-geometry', 'riemannian-geometry']"
28,Poincaré conjecture for positively curved Thurston geometries,Poincaré conjecture for positively curved Thurston geometries,,"The passages below are from Terence Tao's blog . I don't know how to get Corollary 1 from Exercises 2 and 3. I understand that the spherical space form (as the metric) is invariant under $SO(n)$, where $n$ is one plus the dimension of the manifold. Exercise 2 . Let $M$, $M'$ be connected manifolds of the same dimension. Show that $M\#M'$ is compact if and only if $M$ and $M'$ are both compact. Show that $M\#M'$ is orientable if and only if $M$ and $M'$ are both orientable. Show that $M\#M'$ is simply connected if and only if $M$ and $M'$ are both simply connected. The sphere also plays a special role, as the identity for the connected sum operation: Exercise 3 . Let $M$ be a connected manifold, and let $S$ be a sphere of the same dimension. Show that $M\#S$ (or $S\#M$) is homeomorphic to $M$. $\lozenge$ Recall that of the spherical space forms and $S^2$-bundles over $S^1$ mentioned above, the sphere $S^3$ was the only one which was simply connected. From Exercises 2 and 3 we thus have Corollary 1 . (Poincaré conjecture for positively curved Thurston geometries) Let $M$ be a simply connected 3-manifold which is the connected sum of finitely many spherical space forms and $S^2$-bundles over $S^1$. Then $M$ is homeomorphic to the sphere $S^3$. ( pic 1 , pic 2 )","The passages below are from Terence Tao's blog . I don't know how to get Corollary 1 from Exercises 2 and 3. I understand that the spherical space form (as the metric) is invariant under $SO(n)$, where $n$ is one plus the dimension of the manifold. Exercise 2 . Let $M$, $M'$ be connected manifolds of the same dimension. Show that $M\#M'$ is compact if and only if $M$ and $M'$ are both compact. Show that $M\#M'$ is orientable if and only if $M$ and $M'$ are both orientable. Show that $M\#M'$ is simply connected if and only if $M$ and $M'$ are both simply connected. The sphere also plays a special role, as the identity for the connected sum operation: Exercise 3 . Let $M$ be a connected manifold, and let $S$ be a sphere of the same dimension. Show that $M\#S$ (or $S\#M$) is homeomorphic to $M$. $\lozenge$ Recall that of the spherical space forms and $S^2$-bundles over $S^1$ mentioned above, the sphere $S^3$ was the only one which was simply connected. From Exercises 2 and 3 we thus have Corollary 1 . (Poincaré conjecture for positively curved Thurston geometries) Let $M$ be a simply connected 3-manifold which is the connected sum of finitely many spherical space forms and $S^2$-bundles over $S^1$. Then $M$ is homeomorphic to the sphere $S^3$. ( pic 1 , pic 2 )",,"['differential-geometry', 'riemannian-geometry', 'geometric-topology', 'curvature']"
29,Geodesics with respect to time-dependent Riemannian Metric,Geodesics with respect to time-dependent Riemannian Metric,,"I'm not sure where to look to solve a problem of this variety.  Does it potentially have to do with Ricci flow? Suppose we consider Euclidean space $\mathbb{R}^n$ and append to it a time-dependent metric of $A(t)$ where $A: \mathbb{R} \to SPD(n)$ is a smooth curve in the manifold of symmetric positive definite matrices $SPD(n)$.  Define the metric on $\mathbb{R}^n$ as $\langle u, v\rangle_t = u^TA(t)v$, in other words a time-dependent metric.  I'm trying to figure out how to find geodesics in $\mathbb{R}^n$ with respect to the same parameter $t$ that the metric is parameterized by.  I know the geodesic equations for an ordinary Riemmanian manfiold are given by $$ \frac{d^2\gamma^k}{dt^2} + \Gamma_{ij}^k \frac{d\gamma^i}{dt} \frac{d\gamma^j}{dt} \;\; =\;\; 0 $$ with $$ \Gamma_{ij}^k \;\; =\;\; \frac{1}{2} g^{km} \left ( \frac{\partial g_{im}}{\partial x_j} + \frac{\partial g_{jm}}{\partial x_i} - \frac{\partial g_{ij}}{\partial x_m} \right ). $$ It's not clear to me how to approach this problem or if it is even well-posed.  Another way I suppose I can phrase this is: how does a curve $\gamma$ naturally ""flow"" with respect to this metric given the initial conditions $\gamma(0)$ and $\gamma'(0)$?  Can anyone offer any insights or references?  I would appreciate it if I knew a general approach to this problem, or if the problem needs to be posed differently.","I'm not sure where to look to solve a problem of this variety.  Does it potentially have to do with Ricci flow? Suppose we consider Euclidean space $\mathbb{R}^n$ and append to it a time-dependent metric of $A(t)$ where $A: \mathbb{R} \to SPD(n)$ is a smooth curve in the manifold of symmetric positive definite matrices $SPD(n)$.  Define the metric on $\mathbb{R}^n$ as $\langle u, v\rangle_t = u^TA(t)v$, in other words a time-dependent metric.  I'm trying to figure out how to find geodesics in $\mathbb{R}^n$ with respect to the same parameter $t$ that the metric is parameterized by.  I know the geodesic equations for an ordinary Riemmanian manfiold are given by $$ \frac{d^2\gamma^k}{dt^2} + \Gamma_{ij}^k \frac{d\gamma^i}{dt} \frac{d\gamma^j}{dt} \;\; =\;\; 0 $$ with $$ \Gamma_{ij}^k \;\; =\;\; \frac{1}{2} g^{km} \left ( \frac{\partial g_{im}}{\partial x_j} + \frac{\partial g_{jm}}{\partial x_i} - \frac{\partial g_{ij}}{\partial x_m} \right ). $$ It's not clear to me how to approach this problem or if it is even well-posed.  Another way I suppose I can phrase this is: how does a curve $\gamma$ naturally ""flow"" with respect to this metric given the initial conditions $\gamma(0)$ and $\gamma'(0)$?  Can anyone offer any insights or references?  I would appreciate it if I knew a general approach to this problem, or if the problem needs to be posed differently.",,"['differential-geometry', 'riemannian-geometry']"
30,Is the normal bundle of an orientable submanifold of an orientable manifold always trivial?,Is the normal bundle of an orientable submanifold of an orientable manifold always trivial?,,"There is another question on this site which confirms that for an orientable hypersurface of an orientable manifold, the normal bundle is trivial. However, I was wondering if this result generalises to arbitrary orientable submanifolds.","There is another question on this site which confirms that for an orientable hypersurface of an orientable manifold, the normal bundle is trivial. However, I was wondering if this result generalises to arbitrary orientable submanifolds.",,"['differential-geometry', 'vector-bundles']"
31,How to integrate surface area of the Mobius strip using 'density'?,How to integrate surface area of the Mobius strip using 'density'?,,"https://www.quora.com/Can-you-do-a-surface-integral-on-a-mobius-strip According to this link, it is possible to integrate surface area of the non-orientable Mobius strip by using density. However, I'm trying to understand explanations in the Wikipedia, I don't know from which equation I should start to calculate it. Please help me.","https://www.quora.com/Can-you-do-a-surface-integral-on-a-mobius-strip According to this link, it is possible to integrate surface area of the non-orientable Mobius strip by using density. However, I'm trying to understand explanations in the Wikipedia, I don't know from which equation I should start to calculate it. Please help me.",,"['differential-geometry', 'manifolds', 'differential-topology', 'mobius-band']"
32,Group of deck transformations acts properly discontinuously,Group of deck transformations acts properly discontinuously,,"Let $M$ be a connected (smooth Riemannian) manifold which admits a universal cover $\tilde{M}$. Let $\Gamma$ be the group of deck transformations on $\tilde{M}$. I want to show that $\Gamma$ acts properly discontinuously on $\tilde{M}$. The definition for properly discontinuous that I'm using is as follows: Definition 1: A group $G$ acts properly discontinously on a (smooth) manifold $N$ (it is already enough to require $N$ being a locally compact Hausdorff space) if $G$ acts by homeomorphisms and for any compact set $K \subset N$ the set  $\{ \gamma \in \Gamma \mid \gamma(K) \cap K \neq \emptyset \}$ is finite. In literature however, one sometimes finds the following definition, which for the sake of distinction, I will call properly discontinuous$^{TypeB}$ (compare Munkres' book on Topology): Definition 2: A group $G$ acts properly discontinuously$^{TypeB}$ on a (smooth) manifold $N$ if it acts by homeomorphisms and for every $x \in N$ there is an open neighborhood $U$ of $x$ in $N$ such that $g(U) \cap U = \emptyset$ for all $g \in G \setminus\{id\}$. It is easy enough to show that the group of deck transformations $\Gamma$ acts properly discontinuously$^{TypeB}$ on $\tilde{M}$ (i.e. using Definition 2). I was unable to prove however, that properly discontinuous$^{TypeB}$ implies properly discontinuous (i.e. Definition 2 implies Definition 1). The proofs I've found are all either rather indirect (i.e. with many intermediate steps) or use methods that I don't understand. Compare for example the treatment here: https://mathoverflow.net/questions/55726/properly-discontinuous-action So, I'm looking for either an immediate proof that properly discontinuous$^{TypeB}$ implies properly discontinuous or a direct proof that $\Gamma$ acts properly discontinuously on $\tilde{M}$ (using Definition 1). Thanks in advance for any help!","Let $M$ be a connected (smooth Riemannian) manifold which admits a universal cover $\tilde{M}$. Let $\Gamma$ be the group of deck transformations on $\tilde{M}$. I want to show that $\Gamma$ acts properly discontinuously on $\tilde{M}$. The definition for properly discontinuous that I'm using is as follows: Definition 1: A group $G$ acts properly discontinously on a (smooth) manifold $N$ (it is already enough to require $N$ being a locally compact Hausdorff space) if $G$ acts by homeomorphisms and for any compact set $K \subset N$ the set  $\{ \gamma \in \Gamma \mid \gamma(K) \cap K \neq \emptyset \}$ is finite. In literature however, one sometimes finds the following definition, which for the sake of distinction, I will call properly discontinuous$^{TypeB}$ (compare Munkres' book on Topology): Definition 2: A group $G$ acts properly discontinuously$^{TypeB}$ on a (smooth) manifold $N$ if it acts by homeomorphisms and for every $x \in N$ there is an open neighborhood $U$ of $x$ in $N$ such that $g(U) \cap U = \emptyset$ for all $g \in G \setminus\{id\}$. It is easy enough to show that the group of deck transformations $\Gamma$ acts properly discontinuously$^{TypeB}$ on $\tilde{M}$ (i.e. using Definition 2). I was unable to prove however, that properly discontinuous$^{TypeB}$ implies properly discontinuous (i.e. Definition 2 implies Definition 1). The proofs I've found are all either rather indirect (i.e. with many intermediate steps) or use methods that I don't understand. Compare for example the treatment here: https://mathoverflow.net/questions/55726/properly-discontinuous-action So, I'm looking for either an immediate proof that properly discontinuous$^{TypeB}$ implies properly discontinuous or a direct proof that $\Gamma$ acts properly discontinuously on $\tilde{M}$ (using Definition 1). Thanks in advance for any help!",,"['differential-geometry', 'smooth-manifolds', 'group-actions', 'covering-spaces']"
33,Reductive homogeneous spaces,Reductive homogeneous spaces,,"If $G$ is a connected Lie group and $K$ is a closed subgroup of $G$ then $G/K$ is a homogeneous space. If $\frak g,k$ are the lie subalgebras of $G,K$ resp. Then under the projection $\pi:G\rightarrow G/K$ we get $\mathfrak g/\mathfrak k\cong T_o(G/K)$ . A homogeneous space is called reductive if there exists a subspace $\frak m$ of $\frak g$ such that $\frak g= k\oplus m$ and $Ad(k)\frak m\subset m$ for all $k\in K$ . That is, $\frak  m$ is $Ad(K)$ -invariant. My question is: How would the condition $Ad(k)\frak m\subset m$ imply that $\frak [k,m]\subset m$ ? And why the converse is true in case $K$ is connected? My Attempt: Let $X\in \frak k$ and $Y\in \frak m$ . Assume $[X,Y]\in \frak k$ , then $exp\ t[X,Y]\subset K$ . Hence, $exp\ t(ad_XY)=exp\ t(\frac d {ds}\{Ad(exp\ sX)Y\}|_{s=0})$ . Since $Ad(exp\ sX)Y\in \frak m$ for all $s\in \mathbb R$ then, $\frac d {ds}\{Ad(exp\ sX)Y\}|_{s=0}\in \frak m$ since it is a subspace. Therefore, $exp\ t(ad_XY)=exp\ t Y'\subset K$ for some $Y'\in \frak m$ . But this is a contradiction since there is a one-to-one correspondence between the elements in $\frak k$ and the one parameter subgroups in $K$ . Is my proof okay? Any comments would be appreciated!","If is a connected Lie group and is a closed subgroup of then is a homogeneous space. If are the lie subalgebras of resp. Then under the projection we get . A homogeneous space is called reductive if there exists a subspace of such that and for all . That is, is -invariant. My question is: How would the condition imply that ? And why the converse is true in case is connected? My Attempt: Let and . Assume , then . Hence, . Since for all then, since it is a subspace. Therefore, for some . But this is a contradiction since there is a one-to-one correspondence between the elements in and the one parameter subgroups in . Is my proof okay? Any comments would be appreciated!","G K G G/K \frak g,k G,K \pi:G\rightarrow G/K \mathfrak g/\mathfrak k\cong T_o(G/K) \frak m \frak g \frak g= k\oplus m Ad(k)\frak m\subset m k\in K \frak  m Ad(K) Ad(k)\frak m\subset m \frak [k,m]\subset m K X\in \frak k Y\in \frak m [X,Y]\in \frak k exp\ t[X,Y]\subset K exp\ t(ad_XY)=exp\ t(\frac d {ds}\{Ad(exp\ sX)Y\}|_{s=0}) Ad(exp\ sX)Y\in \frak m s\in \mathbb R \frac d {ds}\{Ad(exp\ sX)Y\}|_{s=0}\in \frak m exp\ t(ad_XY)=exp\ t Y'\subset K Y'\in \frak m \frak k K","['differential-geometry', 'lie-groups', 'homogeneous-spaces']"
34,How can I prove that interior product obeys a graded Leibniz rule?,How can I prove that interior product obeys a graded Leibniz rule?,,I want to prove that $i_{X}(\omega\wedge\phi)=i_{X}\omega\wedge\phi+(-1)^{k}\omega\wedge i_{X}\phi.$ I was thinking I many be able to adapt the proof that the exterior derivative obeys the graded Leibniz rule. Failing that I have no idea how to prove this.,I want to prove that $i_{X}(\omega\wedge\phi)=i_{X}\omega\wedge\phi+(-1)^{k}\omega\wedge i_{X}\phi.$ I was thinking I many be able to adapt the proof that the exterior derivative obeys the graded Leibniz rule. Failing that I have no idea how to prove this.,,"['differential-geometry', 'manifolds']"
35,A necessary and sufficient condition for the admittance of integrating factor,A necessary and sufficient condition for the admittance of integrating factor,,"Let $\omega$ be a smooth 1-form on a smooth manifold $M$. A smooth positive function $\mu$ on some open subset $U\subset M$ is called an integrating factor for $\omega$ if $\mu\omega$ is exact on U. In Lee's ISM, there is a necessary and sufficient condition for a nonvanishing 1-form to admit integrating factor. If $\omega$ is nowhere-vanishing, then $\omega$ admits an integrating factor in a   neighborhood of each point if and only if $d\omega \wedge \omega \equiv 0$. I have no idea how to prove the ""if"" part. Assume $d\omega \wedge \omega \equiv 0$ and that $\omega$ is nowhere-vanishing. What does these conditions tell us about $\omega$ and how can we construct a smooth positive function $\mu$ on some open neighborhood $U$ of any point $p$? Partial solution: Ted indicates that I need to use the Frobenius theorem for the proof. I assume the version of Frobenius theorem is the following one in Warner's book: Let $\mathcal I \subset E^*(M)$ be a differential ideal locally generated by $d-p$ independent 1-forms. Let $m\in M$. Then there exists a unique maximal, connected, integral manifold of $\mathcal I$ through $m$, and this integral manifold has dimension $p$. For any $m\in M$, we want to prove that there exists a smooth positive function $\mu$ on some open subset $m\in U\subset M$ such that $\mu\omega$ is exact on U. To use the Frobenius theorem, we need a involutive distribution $\mathcal D$ and let $\mathcal I:=\mathcal {I(D)}$(annihilator of $\mathcal D$). But what is our $\mathbb D$? What good can the existence of a unique maximal, connected, integral manifold of $\mathcal I$ through $m$ do to us in order to find $\mu$? Thanks in advance.","Let $\omega$ be a smooth 1-form on a smooth manifold $M$. A smooth positive function $\mu$ on some open subset $U\subset M$ is called an integrating factor for $\omega$ if $\mu\omega$ is exact on U. In Lee's ISM, there is a necessary and sufficient condition for a nonvanishing 1-form to admit integrating factor. If $\omega$ is nowhere-vanishing, then $\omega$ admits an integrating factor in a   neighborhood of each point if and only if $d\omega \wedge \omega \equiv 0$. I have no idea how to prove the ""if"" part. Assume $d\omega \wedge \omega \equiv 0$ and that $\omega$ is nowhere-vanishing. What does these conditions tell us about $\omega$ and how can we construct a smooth positive function $\mu$ on some open neighborhood $U$ of any point $p$? Partial solution: Ted indicates that I need to use the Frobenius theorem for the proof. I assume the version of Frobenius theorem is the following one in Warner's book: Let $\mathcal I \subset E^*(M)$ be a differential ideal locally generated by $d-p$ independent 1-forms. Let $m\in M$. Then there exists a unique maximal, connected, integral manifold of $\mathcal I$ through $m$, and this integral manifold has dimension $p$. For any $m\in M$, we want to prove that there exists a smooth positive function $\mu$ on some open subset $m\in U\subset M$ such that $\mu\omega$ is exact on U. To use the Frobenius theorem, we need a involutive distribution $\mathcal D$ and let $\mathcal I:=\mathcal {I(D)}$(annihilator of $\mathcal D$). But what is our $\mathbb D$? What good can the existence of a unique maximal, connected, integral manifold of $\mathcal I$ through $m$ do to us in order to find $\mu$? Thanks in advance.",,"['differential-geometry', 'differential-forms']"
36,Ricci flow on compact surfaces flows the metric conformally,Ricci flow on compact surfaces flows the metric conformally,,"The (normalized) Ricci flow on compact surfaces is given by  $$\frac{\partial}{\partial t}g_{ij}=(r-R)g_{ij}\text{ ,}$$ and in the beginning of Hamilton's paper on the topic he points out that since the rate of change of the metric is, pointwise, a multiple of the metric, the metric is flowed within its conformal class. That is, if the initial metric is $g_0$, the metric at later times would be something like $$g(t)=\varphi g_0$$ where $\varphi$ is some scalar function. Intuitively, this explanation makes sense, but is there a rigorous way of showing this? For an ODE of the form $f'(x)=h(x)f(x)$ we would expect the answer to be $f_0$ scaled by some exponential. Is the reasoning similar in this case? Since the scalar curvature $R$ depends implicitly on the changing metric $g(t)$, I expect this would complicate things.","The (normalized) Ricci flow on compact surfaces is given by  $$\frac{\partial}{\partial t}g_{ij}=(r-R)g_{ij}\text{ ,}$$ and in the beginning of Hamilton's paper on the topic he points out that since the rate of change of the metric is, pointwise, a multiple of the metric, the metric is flowed within its conformal class. That is, if the initial metric is $g_0$, the metric at later times would be something like $$g(t)=\varphi g_0$$ where $\varphi$ is some scalar function. Intuitively, this explanation makes sense, but is there a rigorous way of showing this? For an ODE of the form $f'(x)=h(x)f(x)$ we would expect the answer to be $f_0$ scaled by some exponential. Is the reasoning similar in this case? Since the scalar curvature $R$ depends implicitly on the changing metric $g(t)$, I expect this would complicate things.",,"['differential-geometry', 'ricci-flow']"
37,Deriving the round metric,Deriving the round metric,,"I want to derive the round metric $g=d\theta^{\,2}+\sin\left(\theta\right)^2d\phi^{\,2}$ but I cannot get the correct answer. I know that the metric in cartesian coordinates is $g=dx^2+dy^2$. I've used the formula $dx=\frac{dx}{d\theta}d\theta+\frac{dx}{d\phi}d\phi$ and $dy=\frac{dy}{d\theta}d\theta+\frac{dy}{d\phi}d\phi$. From $x=\sin\left(\theta\right)\cos\left(\phi\right)$ and $y=\sin\left(\theta\right)\sin\left(\phi\right)$, I find that $\frac{dx}{d\theta}=\cos\left(\theta\right)\cos\left(\phi\right)$, $\frac{dx}{d\phi}=-\sin\left(\theta\right)\sin\left(\phi\right)$, $\frac{dy}{d\theta}=\cos\left(\theta\right)\sin\left(\phi\right)$, $\frac{dy}{d\phi}=\sin\left(\theta\right)\cos\left(\phi\right)$. This leads to $g=dx^2+dy^2=\cos\left(\theta\right)^2d\theta^{\,2}+\sin\left(\theta\right)^2d\phi^{\,2}$ which is not correct. edit: metric was typed incorrectly","I want to derive the round metric $g=d\theta^{\,2}+\sin\left(\theta\right)^2d\phi^{\,2}$ but I cannot get the correct answer. I know that the metric in cartesian coordinates is $g=dx^2+dy^2$. I've used the formula $dx=\frac{dx}{d\theta}d\theta+\frac{dx}{d\phi}d\phi$ and $dy=\frac{dy}{d\theta}d\theta+\frac{dy}{d\phi}d\phi$. From $x=\sin\left(\theta\right)\cos\left(\phi\right)$ and $y=\sin\left(\theta\right)\sin\left(\phi\right)$, I find that $\frac{dx}{d\theta}=\cos\left(\theta\right)\cos\left(\phi\right)$, $\frac{dx}{d\phi}=-\sin\left(\theta\right)\sin\left(\phi\right)$, $\frac{dy}{d\theta}=\cos\left(\theta\right)\sin\left(\phi\right)$, $\frac{dy}{d\phi}=\sin\left(\theta\right)\cos\left(\phi\right)$. This leads to $g=dx^2+dy^2=\cos\left(\theta\right)^2d\theta^{\,2}+\sin\left(\theta\right)^2d\phi^{\,2}$ which is not correct. edit: metric was typed incorrectly",,['differential-geometry']
38,Does a tensor field acting on vector fields and covector fields give a function?,Does a tensor field acting on vector fields and covector fields give a function?,,"If I have a $(p,q)$ tensor field that acts on $p$ covector fields and $q$ vector fields then does $T\left(X_1,\dots,X_p,Y_1,\dots,Y_q\right)$ return a function $f$ defined on the manifold by $$f\left(x\right)=T_x\left(X_1\left(x\right),\dots,X_p\left(x\right),Y_1\left(x\right),\dots,Y_q\left(x\right)\right)?$$ $T_x$ is now a $\left(p,q\right)$ tensor and $X_i\left(x\right)$ and $Y_j\left(x\right)$ are now covectors and tangent vectors respectively so this seems to make sense.","If I have a $(p,q)$ tensor field that acts on $p$ covector fields and $q$ vector fields then does $T\left(X_1,\dots,X_p,Y_1,\dots,Y_q\right)$ return a function $f$ defined on the manifold by $$f\left(x\right)=T_x\left(X_1\left(x\right),\dots,X_p\left(x\right),Y_1\left(x\right),\dots,Y_q\left(x\right)\right)?$$ $T_x$ is now a $\left(p,q\right)$ tensor and $X_i\left(x\right)$ and $Y_j\left(x\right)$ are now covectors and tangent vectors respectively so this seems to make sense.",,"['differential-geometry', 'manifolds', 'tensors']"
39,Computing Sectional Curvature on Hyperbolic Plane,Computing Sectional Curvature on Hyperbolic Plane,,"For a pair of $(X,Y)$ of linearly independent vectors in $T_pM$, $p\in M$, the sectional curvature is defined as $$K_p(X,Y)=\frac{<R(X,Y)Y,X>}{|X|^2 |Y|^2 - <X,Y>^2}$$ The problem I'm looking at now asks us to compute the same on the half-plane $\mathbb{H} = \{(x,y) \in \mathbb{R}|y>0\}$ with the metric $g= 1/y^2(dx^2 + dy^2)$ (and hence show that it is the constant $-1$). The provided solution has an equality that I don't understand: $$K(\partial_1, \partial_2) = \frac{<R(\partial_1,\partial_2)\partial_2,\partial_1>}{(1/y^2)(1/y^2) - 0} = y^4\frac{1}{y^2}R^2_{112}$$ How is this last equality justified? Namely, I want to understand how the author arrived at this particular set of indices for $R$. I see that the metric is involved because of the inner product, but the details escape me. A breakdown of the steps would be much appreciated!","For a pair of $(X,Y)$ of linearly independent vectors in $T_pM$, $p\in M$, the sectional curvature is defined as $$K_p(X,Y)=\frac{<R(X,Y)Y,X>}{|X|^2 |Y|^2 - <X,Y>^2}$$ The problem I'm looking at now asks us to compute the same on the half-plane $\mathbb{H} = \{(x,y) \in \mathbb{R}|y>0\}$ with the metric $g= 1/y^2(dx^2 + dy^2)$ (and hence show that it is the constant $-1$). The provided solution has an equality that I don't understand: $$K(\partial_1, \partial_2) = \frac{<R(\partial_1,\partial_2)\partial_2,\partial_1>}{(1/y^2)(1/y^2) - 0} = y^4\frac{1}{y^2}R^2_{112}$$ How is this last equality justified? Namely, I want to understand how the author arrived at this particular set of indices for $R$. I see that the metric is involved because of the inner product, but the details escape me. A breakdown of the steps would be much appreciated!",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'curvature']"
40,"Mathematical definition of the word ""generic"" as in ""generic"" singularity or ""generic"" map?","Mathematical definition of the word ""generic"" as in ""generic"" singularity or ""generic"" map?",,"I've been trying to work out what generic means but I'm not making much progress. You can find an example of the usage of the word generic for example here : ""School on Generic Singularities in Geometry"" or here :  ""Rigidity of generic singularities of mean curvature flow"" Here is what I have so far: I found this article by Thom which mentions ""... ""generic"" singularities, i.e., singularities that appear for almost all maps ..."" Just after that he mentions ""generic maps"" but does not elaborate on what it means. He mentions it later (kind of) by saying ""...The precise definition of a generic map is very delicate; for the moment, we say only that any map may be approached by a generic map (up to an approximation on the derivatives of order r), and that any map that is sufficiently close to a generic map, in the preceding sense, is itself generic. ..."" and later  on he gives a definition of ""generic singularity of a singular set"": ""... A critical point $x$ of $S_r$ will be called transversally critical , or, furthermore, generic , if the tangent planes to $ \overline{f}(\mathbb R^n) $ and $F_r$ are in general position at the point $\overline{f} (x)$ of the Grassmannian, which is assumed to be ordinary on $F_r$ . ..."" Does this mean that generic and transversally critical are synonyms? I feel I still don't understand what generic means even after reading this definition and part of the article. Please could someone help me understand what generic means?","I've been trying to work out what generic means but I'm not making much progress. You can find an example of the usage of the word generic for example here : ""School on Generic Singularities in Geometry"" or here :  ""Rigidity of generic singularities of mean curvature flow"" Here is what I have so far: I found this article by Thom which mentions ""... ""generic"" singularities, i.e., singularities that appear for almost all maps ..."" Just after that he mentions ""generic maps"" but does not elaborate on what it means. He mentions it later (kind of) by saying ""...The precise definition of a generic map is very delicate; for the moment, we say only that any map may be approached by a generic map (up to an approximation on the derivatives of order r), and that any map that is sufficiently close to a generic map, in the preceding sense, is itself generic. ..."" and later  on he gives a definition of ""generic singularity of a singular set"": ""... A critical point $x$ of $S_r$ will be called transversally critical , or, furthermore, generic , if the tangent planes to $ \overline{f}(\mathbb R^n) $ and $F_r$ are in general position at the point $\overline{f} (x)$ of the Grassmannian, which is assumed to be ordinary on $F_r$ . ..."" Does this mean that generic and transversally critical are synonyms? I feel I still don't understand what generic means even after reading this definition and part of the article. Please could someone help me understand what generic means?",,"['differential-geometry', 'differential-topology', 'definition', 'singularity-theory']"
41,How many complex structures are on $\mathbb{R}^{2n}$,How many complex structures are on,\mathbb{R}^{2n},"By a complex structure on $\mathbb{R}^{2n} $ I mean $\mathbb{R}$ -linear $J:\mathbb{R}^{2n} \rightarrow \mathbb{R}^{2n}$ such that $JJ=-I$ . I asked myself how many nonisomorphic such structures are on $\mathbb{R}^{2n}$ , where by isomorphic I mean that $\mathbb{R}^{2n}$ 's treated as complex spaces with complex vector space structures given from $J$ 's are isomorphic as complex spaces. If I would ask only for $J$ 's we would seek for matrices, such that: $$A^2=-I$$ and would get infinitely many of them since there are infinitely many for the case when $n=1$ namely $$\left[\begin{matrix} a & b\\ c & -a\end{matrix}\right]$$ with $a^2+bc=-1$ . But now we treat $A_1$ , $A_2$ as the same structure iff there exists $B$ such that $$A_1 B=B A_2.$$","By a complex structure on I mean -linear such that . I asked myself how many nonisomorphic such structures are on , where by isomorphic I mean that 's treated as complex spaces with complex vector space structures given from 's are isomorphic as complex spaces. If I would ask only for 's we would seek for matrices, such that: and would get infinitely many of them since there are infinitely many for the case when namely with . But now we treat , as the same structure iff there exists such that","\mathbb{R}^{2n}  \mathbb{R} J:\mathbb{R}^{2n} \rightarrow \mathbb{R}^{2n} JJ=-I \mathbb{R}^{2n} \mathbb{R}^{2n} J J A^2=-I n=1 \left[\begin{matrix} a & b\\
c & -a\end{matrix}\right] a^2+bc=-1 A_1 A_2 B A_1 B=B A_2.","['linear-algebra', 'differential-geometry', 'complex-geometry']"
42,finding the laplacian beltrami operator?,finding the laplacian beltrami operator?,,the matrix $ \begin{bmatrix} g_{11} & g_{12} \\ g_{21} & g_{22}  \end{bmatrix} $ =      $ \begin{bmatrix} 1&0 \\ 0&r{(\gamma )^2}\end{bmatrix}$ what i did is $$\nabla^2f=\frac{1}{r(\gamma)} [\partial _\gamma((r(\gamma ) \partial_{\gamma})+\partial_{\theta}(r(\gamma)^3\partial_{\theta})])$$ $$=\frac{1}{r(\gamma)}[\dot{r}{(\gamma)\frac {\partial}{\partial \gamma} +r(\gamma) \frac{\partial^2}{\partial \gamma^2}+r(\gamma)^3 \frac {\partial ^2}{\partial \theta^2}}] $$ but in the book it is $$ =\frac{1}{r(\gamma)}[\dot{r}{(\gamma)\frac {\partial}{\partial \gamma} +r(\gamma) \frac{\partial^2}{\partial \gamma^2}+1/r(\gamma)\frac {\partial ^2}{\partial \theta^2}}]$$. please tell where i am wrong,the matrix $ \begin{bmatrix} g_{11} & g_{12} \\ g_{21} & g_{22}  \end{bmatrix} $ =      $ \begin{bmatrix} 1&0 \\ 0&r{(\gamma )^2}\end{bmatrix}$ what i did is $$\nabla^2f=\frac{1}{r(\gamma)} [\partial _\gamma((r(\gamma ) \partial_{\gamma})+\partial_{\theta}(r(\gamma)^3\partial_{\theta})])$$ $$=\frac{1}{r(\gamma)}[\dot{r}{(\gamma)\frac {\partial}{\partial \gamma} +r(\gamma) \frac{\partial^2}{\partial \gamma^2}+r(\gamma)^3 \frac {\partial ^2}{\partial \theta^2}}] $$ but in the book it is $$ =\frac{1}{r(\gamma)}[\dot{r}{(\gamma)\frac {\partial}{\partial \gamma} +r(\gamma) \frac{\partial^2}{\partial \gamma^2}+1/r(\gamma)\frac {\partial ^2}{\partial \theta^2}}]$$. please tell where i am wrong,,"['differential-geometry', 'laplacian']"
43,Determining if there can be smooth closed geodesic given its curvature,Determining if there can be smooth closed geodesic given its curvature,,In my class on differential geometry I have been given the following question on which I am stuck: Let S be a regular orientable surface in $ R^3 $ with Gaussian curvature $K$ (not necessarily constant) and we are to check if there can be a smooth closed geodesic on S in the following case: $ K>0 $ $ K=0 $ $ K<0 $ and we are to give an example when it is possible that the closed geodesic bounds a simply connected region I know for starters about the first one with positive curvature I may take the sphere and a great circle which is a geodesic and obviously bounds a simply connected subset of the sphere. But with the zero and negative curvatures I have no idea how to tell if a closed geodesic exists I think the Gauss Bonnet theorem has something to do with this but I cannot really proceed from there and I am posting here in the hope of getting help ******* Progress: I can work out what happens with Gauss Bonnet if I have the constraint that the geodesic bounds a simply connected region as this is simple but the fact of the matter is where I am stuck is the general existence or non existence if no constraint is given on the region bounded,In my class on differential geometry I have been given the following question on which I am stuck: Let S be a regular orientable surface in with Gaussian curvature (not necessarily constant) and we are to check if there can be a smooth closed geodesic on S in the following case: and we are to give an example when it is possible that the closed geodesic bounds a simply connected region I know for starters about the first one with positive curvature I may take the sphere and a great circle which is a geodesic and obviously bounds a simply connected subset of the sphere. But with the zero and negative curvatures I have no idea how to tell if a closed geodesic exists I think the Gauss Bonnet theorem has something to do with this but I cannot really proceed from there and I am posting here in the hope of getting help ******* Progress: I can work out what happens with Gauss Bonnet if I have the constraint that the geodesic bounds a simply connected region as this is simple but the fact of the matter is where I am stuck is the general existence or non existence if no constraint is given on the region bounded, R^3  K  K>0   K=0   K<0 ,"['differential-geometry', 'surfaces', 'curvature']"
44,The Levi-Civita Connection on the Hyperbolic Plane,The Levi-Civita Connection on the Hyperbolic Plane,,"In this question here, I asked about computing the Levi-Civita connection matrix on the Hyperbolic Plane, defined as $\mathbb{H}^2=\{x+iy\in\mathbb{C}\ \vert\ y>0\}$ equipped with the metric $g = \frac{1}{y^2}(dx^2+dy^2)$. The answer (which I believe is correct) was given as: $$\omega^i_j(X)=\begin{bmatrix} -\frac{X^2}{y} & -\frac{X^1}{y} \\ \frac{X^1}{y} & -\frac{X^2}{y} \end{bmatrix}\ .$$ But I have a proposition in my notes which reads: Let $\xi$ be a smooth vector bundle equipped with an inner product $<\cdot ,\cdot>$ and a connection $\nabla$. Then $\nabla$ is compatible with the inner product if and only if in any local orthonormal frame $(s_i)$ the connection matrix $\omega$ is skew-symmetric. The matrix $\omega$ above is clearly not skew-symmetric, and I'm not quite sure what to make of this apparent contradiction. It is certainly not true that there exists no Levi-Civita connection on the hyperbolic plane, so where am I going wrong?","In this question here, I asked about computing the Levi-Civita connection matrix on the Hyperbolic Plane, defined as $\mathbb{H}^2=\{x+iy\in\mathbb{C}\ \vert\ y>0\}$ equipped with the metric $g = \frac{1}{y^2}(dx^2+dy^2)$. The answer (which I believe is correct) was given as: $$\omega^i_j(X)=\begin{bmatrix} -\frac{X^2}{y} & -\frac{X^1}{y} \\ \frac{X^1}{y} & -\frac{X^2}{y} \end{bmatrix}\ .$$ But I have a proposition in my notes which reads: Let $\xi$ be a smooth vector bundle equipped with an inner product $<\cdot ,\cdot>$ and a connection $\nabla$. Then $\nabla$ is compatible with the inner product if and only if in any local orthonormal frame $(s_i)$ the connection matrix $\omega$ is skew-symmetric. The matrix $\omega$ above is clearly not skew-symmetric, and I'm not quite sure what to make of this apparent contradiction. It is certainly not true that there exists no Levi-Civita connection on the hyperbolic plane, so where am I going wrong?",,"['differential-geometry', 'riemannian-geometry', 'connections']"
45,Is parallelizability equivalent to the set of vector fields being free?,Is parallelizability equivalent to the set of vector fields being free?,,"We have the $C^{\infty}(M)$-module $\mathcal{D}^1(M)$ of vector fields over a $C^{\infty}$ manifold $M$. Is being parallelizable equivalent to this module being free, of dimension $n$? I have the impression it is, since we can take as a basis the $n$ vector fields given by the assumption that $M$ is parallelizable and decompose every vector field in their components in each tangent space, and reciprocally the basis of the module would give the vector fields needed to parallelizability. Am I overlooking something? If this is true, is it ever possible for $\mathcal{D}^1(M)$ to be a free module of a different dimension, other than $n$?","We have the $C^{\infty}(M)$-module $\mathcal{D}^1(M)$ of vector fields over a $C^{\infty}$ manifold $M$. Is being parallelizable equivalent to this module being free, of dimension $n$? I have the impression it is, since we can take as a basis the $n$ vector fields given by the assumption that $M$ is parallelizable and decompose every vector field in their components in each tangent space, and reciprocally the basis of the module would give the vector fields needed to parallelizability. Am I overlooking something? If this is true, is it ever possible for $\mathcal{D}^1(M)$ to be a free module of a different dimension, other than $n$?",,"['differential-geometry', 'differential-topology']"
46,Area of a spherical polygon [closed],Area of a spherical polygon [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question A spherical polygon on $S^2$ is the region formed by the intersection of $n$ hemispheres of $S^2$, where $n$ is an integer $\geq 3$. Show that, if $\alpha_1,\cdots,\alpha_n$ are the interior angles of such a polygon, its area is equal to $$\sum_{i=1}^n \alpha_i − (n − 2)\pi$$ Could you give me some hints how we can show this?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question A spherical polygon on $S^2$ is the region formed by the intersection of $n$ hemispheres of $S^2$, where $n$ is an integer $\geq 3$. Show that, if $\alpha_1,\cdots,\alpha_n$ are the interior angles of such a polygon, its area is equal to $$\sum_{i=1}^n \alpha_i − (n − 2)\pi$$ Could you give me some hints how we can show this?",,"['differential-geometry', 'area']"
47,Christoffel symbols for the Poincaré ball model,Christoffel symbols for the Poincaré ball model,,The metric tensor $g_{ij}$ of the Poincaré ball model is $$ g_{ij} = \frac{\delta_{ij}}{(1 - x_k x^k)^2} $$ where $\delta_{ij}$ is the Kronecker delta and $x^k$ are the ambient Cartesian coordinates. Hence the partial derivative of the metric tensor with respect to a coordinate $x^l$ is $$ \partial_l g_{ij} = \partial_l \frac{\delta_{ij}}{(1 - x_k x^k)^2} = \delta_{ij} \partial_l (1 - x_k x^k)^{-2} = -2 \delta_{ij} (1 - x_k x^k)^{-3} \partial_l (1 - x_k x^k) = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \partial_l x^k + x^k \partial_l x_k) = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \delta_l^k + x^k \delta_{lk}) $$ In summary $$ \partial_l g_{ij} = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \delta_l^k + x^k \delta_{lk}) = 4 \delta_{ij} (1 - x_k x^k)^{-3} x_l $$ The Christoffel symbols are defined in terms of the partial derivatives of the metric tensor as $$ \Gamma^i_{jk} = \frac{1}{2} g^{il} (\partial_j g_{lk} + \partial_k g_{lj} - \partial_l g_{jk}) $$ Hence we substitute our expression for $ \partial_l g_{ij} $ with the right indices. Is this correct? I have not been able to find an online source to verify that these are the correct Christoffel symbols for the Poincaré ball model.,The metric tensor $g_{ij}$ of the Poincaré ball model is $$ g_{ij} = \frac{\delta_{ij}}{(1 - x_k x^k)^2} $$ where $\delta_{ij}$ is the Kronecker delta and $x^k$ are the ambient Cartesian coordinates. Hence the partial derivative of the metric tensor with respect to a coordinate $x^l$ is $$ \partial_l g_{ij} = \partial_l \frac{\delta_{ij}}{(1 - x_k x^k)^2} = \delta_{ij} \partial_l (1 - x_k x^k)^{-2} = -2 \delta_{ij} (1 - x_k x^k)^{-3} \partial_l (1 - x_k x^k) = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \partial_l x^k + x^k \partial_l x_k) = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \delta_l^k + x^k \delta_{lk}) $$ In summary $$ \partial_l g_{ij} = 2 \delta_{ij} (1 - x_k x^k)^{-3} (x_k \delta_l^k + x^k \delta_{lk}) = 4 \delta_{ij} (1 - x_k x^k)^{-3} x_l $$ The Christoffel symbols are defined in terms of the partial derivatives of the metric tensor as $$ \Gamma^i_{jk} = \frac{1}{2} g^{il} (\partial_j g_{lk} + \partial_k g_{lj} - \partial_l g_{jk}) $$ Hence we substitute our expression for $ \partial_l g_{ij} $ with the right indices. Is this correct? I have not been able to find an online source to verify that these are the correct Christoffel symbols for the Poincaré ball model.,,"['differential-geometry', 'riemannian-geometry', 'tensors', 'hyperbolic-geometry', 'connections']"
48,Lie Bracket is not a tensor,Lie Bracket is not a tensor,,"Suppose that we have two vector fields $V,W \in TM$ with $M$ a differentiable manifold. We define the Lie Bracket as $[V,W](f)=V(W(f))-W(V(f))$ and it's easy to show that this bracket is indeed a vector field. I feel like I'm missing something but then why is not possible to define the Lie Bracket as a tensor taking two vector fields and a covector? In that case how should I prove this?","Suppose that we have two vector fields $V,W \in TM$ with $M$ a differentiable manifold. We define the Lie Bracket as $[V,W](f)=V(W(f))-W(V(f))$ and it's easy to show that this bracket is indeed a vector field. I feel like I'm missing something but then why is not possible to define the Lie Bracket as a tensor taking two vector fields and a covector? In that case how should I prove this?",,['differential-geometry']
49,Einstein manifolds and topology,Einstein manifolds and topology,,"Given a Riemannian manifold $(M,g)$ with Ricci tensor $ R_{mn} = k g_{mn} $. Suppose the Ricci scalar you get is $$ R > 0 $$ What can you tell about the manifold $globally$ ? In particular, can you say anything about the topology of this manifold (e.g is this compact?) ? This question arise in a Physics situation: in 11-dimensional supergravity, one can find solutions to equations with a factorised metric describing $M_4 \times M_7$, where the Riemannian manifold $M_7$ has the geometry described above (Einstein manifold with positive Ricci curvature). These solutions are said to furnish a spontaneous conpactification because $M_7$ is ""automatically"" compact. But I don't really understand why this is the case. PS: Useful references where to study these topics in differential geometry? I just know basics (in order to understand General Relativity and String Theory)","Given a Riemannian manifold $(M,g)$ with Ricci tensor $ R_{mn} = k g_{mn} $. Suppose the Ricci scalar you get is $$ R > 0 $$ What can you tell about the manifold $globally$ ? In particular, can you say anything about the topology of this manifold (e.g is this compact?) ? This question arise in a Physics situation: in 11-dimensional supergravity, one can find solutions to equations with a factorised metric describing $M_4 \times M_7$, where the Riemannian manifold $M_7$ has the geometry described above (Einstein manifold with positive Ricci curvature). These solutions are said to furnish a spontaneous conpactification because $M_7$ is ""automatically"" compact. But I don't really understand why this is the case. PS: Useful references where to study these topics in differential geometry? I just know basics (in order to understand General Relativity and String Theory)",,"['differential-geometry', 'manifolds', 'differential-topology', 'riemannian-geometry', 'compact-manifolds']"
50,Faulty Argument: Chern number of U(1)-bundle over $T^2$ is zero?,Faulty Argument: Chern number of U(1)-bundle over  is zero?,T^2,"Consider a $U(1)$-bundle $P$ over the two-dimensional torus $T^2$. Given a local curvature $F$, We can compute the first Chern number $c_1(P)$ by considering a rectangle $R_{\epsilon}$ in the center of the torus whose edges are a distance $2\epsilon$ from touching each other: Then we may also define a restricted bundle $P|_{R_{\epsilon}}:=\pi^{-1}(R_{\epsilon})$. Note that this is a principal $U(1)$-bundle in its own right, over a manifold with non-trivial boundary. The Calculation : Since the first chern-form is non-singular (by virtue of being a characteristic class), its integral over the complement of $R_{\epsilon}$ vanishes as $\epsilon$ goes to zero and we can write the first chern number of $P$ as the limit $$c_1(P)=\int_{T^2}C_1(F)=\lim_{\epsilon\to 0}\int_{R_{\epsilon}}C_1(F)=\lim_{\epsilon\to 0}c_1(P|_{R_{\epsilon}})$$ However, since $R_{\epsilon}$ is contractible, $P|_{R_{\epsilon}}$ is a trivial bundle, and so $c_1(P|_{R_{\epsilon}})=0$ for all values of $\epsilon$ greater than zero. So  $$c_1(P)=\lim_{\epsilon\to 0}c_1(P|_{R_{\epsilon}})=\lim_{\epsilon\to 0}0=0.$$ So the first chern number of any $U(1)$ bundle over the two-torus must vanish. What am I misunderstanding?","Consider a $U(1)$-bundle $P$ over the two-dimensional torus $T^2$. Given a local curvature $F$, We can compute the first Chern number $c_1(P)$ by considering a rectangle $R_{\epsilon}$ in the center of the torus whose edges are a distance $2\epsilon$ from touching each other: Then we may also define a restricted bundle $P|_{R_{\epsilon}}:=\pi^{-1}(R_{\epsilon})$. Note that this is a principal $U(1)$-bundle in its own right, over a manifold with non-trivial boundary. The Calculation : Since the first chern-form is non-singular (by virtue of being a characteristic class), its integral over the complement of $R_{\epsilon}$ vanishes as $\epsilon$ goes to zero and we can write the first chern number of $P$ as the limit $$c_1(P)=\int_{T^2}C_1(F)=\lim_{\epsilon\to 0}\int_{R_{\epsilon}}C_1(F)=\lim_{\epsilon\to 0}c_1(P|_{R_{\epsilon}})$$ However, since $R_{\epsilon}$ is contractible, $P|_{R_{\epsilon}}$ is a trivial bundle, and so $c_1(P|_{R_{\epsilon}})=0$ for all values of $\epsilon$ greater than zero. So  $$c_1(P)=\lim_{\epsilon\to 0}c_1(P|_{R_{\epsilon}})=\lim_{\epsilon\to 0}0=0.$$ So the first chern number of any $U(1)$ bundle over the two-torus must vanish. What am I misunderstanding?",,"['differential-geometry', 'differential-topology', 'homology-cohomology', 'characteristic-classes']"
51,Repeated application of the gradient on a Riemannian manifold,Repeated application of the gradient on a Riemannian manifold,,"While reading about Sobolev spaces on manifolds, I encountered the following notation regarding the norm in $H^k$: $\| \nabla ^k f \|_{L^2}$. There are two questions here: 1) What kind of object id $\nabla ^k f$? Is it a $k$-vector? How is it defined? 2) How is the metric $g$ extended to the space of these objects? I suspect a strong similarity to differential forms and their norms as defined in Hodge theory, yet there must also be some differences, since forms are a purely differential object, whereas the gradient is a Riemannian one.","While reading about Sobolev spaces on manifolds, I encountered the following notation regarding the norm in $H^k$: $\| \nabla ^k f \|_{L^2}$. There are two questions here: 1) What kind of object id $\nabla ^k f$? Is it a $k$-vector? How is it defined? 2) How is the metric $g$ extended to the space of these objects? I suspect a strong similarity to differential forms and their norms as defined in Hodge theory, yet there must also be some differences, since forms are a purely differential object, whereas the gradient is a Riemannian one.",,"['differential-geometry', 'riemannian-geometry', 'sobolev-spaces', 'tensors', 'hodge-theory']"
52,Divergence as trace of Levi-Civita connection,Divergence as trace of Levi-Civita connection,,"In ""Problems and Solution in Mathematics"" by Ta-Tsien, 2nd Edition, exercice 3314, question b Exercise question For a vector field $X$ define the divergence of $X$, $\text{div}(X)$ as the trace of the operator $Y \rightarrow D_Y X$ where $D$ is the Levi-Civita connection. Find the expression for the divergence of $X$ in a local coordinate system $(x^1,...,x^n)$. Exercise answer Denote: \begin{equation} X = \sum_i X^i \frac{\partial}{\partial x^i} \end{equation} Then, by the definition of divergence, we have: \begin{equation} \text{div}(X) = \sum_{k,l} \left<D_{\frac{\partial}{\partial x^k}} X, \frac{\partial}{\partial x^l} \right> g^{kl} = \sum_i \left(\frac{\partial X^i}{\partial x^i} + \sum_k \Gamma^i_{ki}X^k \right) \end{equation} My question I see $Y \rightarrow D_Y X$ as a ""differential"" operator in which for example the derivatives of the components $X^i$ and $Y^i$ of the vectors fields will appear. On the contrary, a tensor is a ""local"" operator which only permits algebraic operations between those components. My question thus is: What is the coordinate expression of the tensor which trace is the divergence of $X$ ?","In ""Problems and Solution in Mathematics"" by Ta-Tsien, 2nd Edition, exercice 3314, question b Exercise question For a vector field $X$ define the divergence of $X$, $\text{div}(X)$ as the trace of the operator $Y \rightarrow D_Y X$ where $D$ is the Levi-Civita connection. Find the expression for the divergence of $X$ in a local coordinate system $(x^1,...,x^n)$. Exercise answer Denote: \begin{equation} X = \sum_i X^i \frac{\partial}{\partial x^i} \end{equation} Then, by the definition of divergence, we have: \begin{equation} \text{div}(X) = \sum_{k,l} \left<D_{\frac{\partial}{\partial x^k}} X, \frac{\partial}{\partial x^l} \right> g^{kl} = \sum_i \left(\frac{\partial X^i}{\partial x^i} + \sum_k \Gamma^i_{ki}X^k \right) \end{equation} My question I see $Y \rightarrow D_Y X$ as a ""differential"" operator in which for example the derivatives of the components $X^i$ and $Y^i$ of the vectors fields will appear. On the contrary, a tensor is a ""local"" operator which only permits algebraic operations between those components. My question thus is: What is the coordinate expression of the tensor which trace is the divergence of $X$ ?",,"['differential-geometry', 'connections']"
53,Second fundamental form for surfaces (extrinsic curvature),Second fundamental form for surfaces (extrinsic curvature),,"I'm trying to understand the Gibbons–Hawking term . There appears $K$- a trace of the second fundamental form, as they say. As far as I know, the second fundamental form is the following thing: Suppose we have two manifolds $M$ and $N$, and $M$ is a surface in $N$ ($M \hookrightarrow N$). $g$ is a metrics on $N$, so $f^{*}g$ (pullback) is a metrics on $M$. Let $\rho$ to be a projection $T_{x}N \rightarrow T_{x}M$. Then $\nabla^M_{y}X=\rho(\nabla^N_{y}X)$ is a Levi-Civita connection on $M$ . Superscripts $M$ and $N$ are correspond to manifolds and $X$,$Y$ $\in \Gamma(TM)$. Then we have  $\nabla^N_{y}X - \nabla^M_{y}X=(id-\rho)\nabla^N_{y}X=B(X,Y)$. $B(X,Y)$ is called a second fundamental form. But all physicists I know write $K=h^{ab}K_{ab}=h^{ab}\nabla_{a}n_{b}$, where $h$ is induced metrics, and $n$ is a normal vector . (for example, check this link , slide number $5$, page $14$, where he introduced GH term for action. Or you can find other examples with ease by yourself). So I don't understand how $n$ have appeared in definition of $K$. Can you explain it to me? Maybe I'm mistaken in my definition of second fundamental form?","I'm trying to understand the Gibbons–Hawking term . There appears $K$- a trace of the second fundamental form, as they say. As far as I know, the second fundamental form is the following thing: Suppose we have two manifolds $M$ and $N$, and $M$ is a surface in $N$ ($M \hookrightarrow N$). $g$ is a metrics on $N$, so $f^{*}g$ (pullback) is a metrics on $M$. Let $\rho$ to be a projection $T_{x}N \rightarrow T_{x}M$. Then $\nabla^M_{y}X=\rho(\nabla^N_{y}X)$ is a Levi-Civita connection on $M$ . Superscripts $M$ and $N$ are correspond to manifolds and $X$,$Y$ $\in \Gamma(TM)$. Then we have  $\nabla^N_{y}X - \nabla^M_{y}X=(id-\rho)\nabla^N_{y}X=B(X,Y)$. $B(X,Y)$ is called a second fundamental form. But all physicists I know write $K=h^{ab}K_{ab}=h^{ab}\nabla_{a}n_{b}$, where $h$ is induced metrics, and $n$ is a normal vector . (for example, check this link , slide number $5$, page $14$, where he introduced GH term for action. Or you can find other examples with ease by yourself). So I don't understand how $n$ have appeared in definition of $K$. Can you explain it to me? Maybe I'm mistaken in my definition of second fundamental form?",,"['differential-geometry', 'mathematical-physics', 'general-relativity']"
54,"Why is the action of $SL(2, R)$ on holomorphic quadratic forms involve a square root?",Why is the action of  on holomorphic quadratic forms involve a square root?,"SL(2, R)","Following this , given a quadratic differential $q$, it can be identified with the pair of real 1-forms $(\Im(q^{1/2}), \Re(q^{1/2}))$. Given a matrix $A \in SL(2, R)$, it acts on this pair by left multiplication, and we define $A \cdot q$ to be the quadratic differential identified with this pair. My question is: Where does the $1/2$ power of $q$ in the aforementioned pair of 1-forms come from?","Following this , given a quadratic differential $q$, it can be identified with the pair of real 1-forms $(\Im(q^{1/2}), \Re(q^{1/2}))$. Given a matrix $A \in SL(2, R)$, it acts on this pair by left multiplication, and we define $A \cdot q$ to be the quadratic differential identified with this pair. My question is: Where does the $1/2$ power of $q$ in the aforementioned pair of 1-forms come from?",,"['differential-geometry', 'differential-forms', 'differential', 'teichmueller-theory']"
55,Show the first Chern class of a $U(1)$ bundle is integral.,Show the first Chern class of a  bundle is integral.,U(1),"I am working from John Baez's book: ""Gauge Fields, Knots and Gravity"". So I will stick to the notation used in that book. I am stuck at exercise 122 of part II (page 283), it reads: Show that if $E$ is a $U(1)$-bundle over $M$ with standard fiber given by the fundamental representation $U(1)$, the first Chern class of $E$ is integral. So I need to show that $i/(2\pi) \int_{M} \text{tr}F$, where $F$ is the ($\text{End}(E)$-valued) curvature two-form, is an integer. Now just before the exercise he says that one can turn the argument for charge quantization in Chapter 6 of part I (at the very end) into a proof of the integrality of the first Chern class for a $U(1)$-connection. This is the argument (paraphrased): The space we consider is $\mathbb{R}^{3}\setminus \{0 \}$. If we drag a particle with electric charge $q$ around a loop $\gamma$ that bounds a $2$-disk $D$ embedded in space, its wavefunction is multiplied by a phase \begin{equation} e^{-iq/\hbar\int_{D} B}, \end{equation} where $B$ is the magnetic field two-form, given by \begin{equation} B = (m/4\pi) \sin \phi \text{d}\theta \wedge \text{d}\phi. \end{equation} Suppose that the loop $\gamma$ is the equator of a sphere centered on the origin. Let $D_{1}$ be the northern half of this sphere and $D_{2}$ the southern half. We compute \begin{equation} \int_{D_{1}} B = \frac{m}{4\pi} \int_{0}^{\pi/2} \int_{0}^{2\pi} \sin \phi \text{d}\theta \wedge \text{d}\phi = \frac{m}{2}, \end{equation} and \begin{equation} \int_{D_{2}} B = -\frac{m}{4\pi} \int_{\pi/2}^{\pi} \int_{0}^{2\pi} \sin \phi \text{d}\theta \wedge \text{d}\phi = -\frac{m}{2}. \end{equation} We should be able to compute the phase using either of these results, thus we are led to conclude \begin{equation} e^{-\frac{iqm}{2\hbar}} = e^{\frac{iqm}{2\hbar}}, \end{equation} or \begin{equation} e^{\frac{iqm}{\pi}} = 1, \end{equation} thus $q$ must be an integer multiple of $2\pi \hbar/m$, that is, charge is quantized. Furthermore, right before the exercise, there is an argument that shows that the fact that the first Chern class is integral implies that the magnetic charge is quantized. It goes as follows (also paraphrased): Let $E$ be a (the?) $U(1)$-bundle over $\mathbb{R}^{3} \setminus \{0 \}$. Let $D$ be a $U(1)$-connection on $E$ and let $A$ be the corresponding vector potential, (that is, $D = D^{0} + A$, where $D^{0}$ is a flat connection). Let $F$ be the curvature of $D$ (equivalently of $A$). Define $\text{tr}(F)=:i B$, such that $B$ is a real-valued $2$-form on $\mathbb{R}^{3} \setminus \{0 \}$. By the integrality of the first Chern class we have \begin{equation} \int_{S^{2}} B = 2 \pi N, \end{equation} thus the magnetic charge is quantized. So here is my attempt at a solution to the problem. Let $E$ be a $U(1)$-bundle over $M$ as in the problem. Let $D$ be a connection on $E$ with corresponding vector potential $A$ and let $F$ be the curvature of $D$. We define the real valued two-form $B$ by $B:= -i \text{tr}(F)$. Now I suppose one would like to mimic the earlier proof and say that if one carries a particle with charge $q$ around a loop $\gamma$ in $M$ its wave function would be multiplied by a factor \begin{equation} e^{-\frac{i}{\hbar}\int_{D} B}, \end{equation} where $D$ is a disk enclosed by the loop $\gamma$, but here I have some doubts, since it might not be possible to make such a disk if $M$ is not simply connected, and even worse I am not sure this needs to be true. And even if there is a way around these objections, I would not know how to continue since in the argument I am trying to mimic one explicitly computes $\int_{D} B$, but I am not sure how to do this without explicit knowledge of the manifold $M$. Any help would be greatly appreciated!","I am working from John Baez's book: ""Gauge Fields, Knots and Gravity"". So I will stick to the notation used in that book. I am stuck at exercise 122 of part II (page 283), it reads: Show that if $E$ is a $U(1)$-bundle over $M$ with standard fiber given by the fundamental representation $U(1)$, the first Chern class of $E$ is integral. So I need to show that $i/(2\pi) \int_{M} \text{tr}F$, where $F$ is the ($\text{End}(E)$-valued) curvature two-form, is an integer. Now just before the exercise he says that one can turn the argument for charge quantization in Chapter 6 of part I (at the very end) into a proof of the integrality of the first Chern class for a $U(1)$-connection. This is the argument (paraphrased): The space we consider is $\mathbb{R}^{3}\setminus \{0 \}$. If we drag a particle with electric charge $q$ around a loop $\gamma$ that bounds a $2$-disk $D$ embedded in space, its wavefunction is multiplied by a phase \begin{equation} e^{-iq/\hbar\int_{D} B}, \end{equation} where $B$ is the magnetic field two-form, given by \begin{equation} B = (m/4\pi) \sin \phi \text{d}\theta \wedge \text{d}\phi. \end{equation} Suppose that the loop $\gamma$ is the equator of a sphere centered on the origin. Let $D_{1}$ be the northern half of this sphere and $D_{2}$ the southern half. We compute \begin{equation} \int_{D_{1}} B = \frac{m}{4\pi} \int_{0}^{\pi/2} \int_{0}^{2\pi} \sin \phi \text{d}\theta \wedge \text{d}\phi = \frac{m}{2}, \end{equation} and \begin{equation} \int_{D_{2}} B = -\frac{m}{4\pi} \int_{\pi/2}^{\pi} \int_{0}^{2\pi} \sin \phi \text{d}\theta \wedge \text{d}\phi = -\frac{m}{2}. \end{equation} We should be able to compute the phase using either of these results, thus we are led to conclude \begin{equation} e^{-\frac{iqm}{2\hbar}} = e^{\frac{iqm}{2\hbar}}, \end{equation} or \begin{equation} e^{\frac{iqm}{\pi}} = 1, \end{equation} thus $q$ must be an integer multiple of $2\pi \hbar/m$, that is, charge is quantized. Furthermore, right before the exercise, there is an argument that shows that the fact that the first Chern class is integral implies that the magnetic charge is quantized. It goes as follows (also paraphrased): Let $E$ be a (the?) $U(1)$-bundle over $\mathbb{R}^{3} \setminus \{0 \}$. Let $D$ be a $U(1)$-connection on $E$ and let $A$ be the corresponding vector potential, (that is, $D = D^{0} + A$, where $D^{0}$ is a flat connection). Let $F$ be the curvature of $D$ (equivalently of $A$). Define $\text{tr}(F)=:i B$, such that $B$ is a real-valued $2$-form on $\mathbb{R}^{3} \setminus \{0 \}$. By the integrality of the first Chern class we have \begin{equation} \int_{S^{2}} B = 2 \pi N, \end{equation} thus the magnetic charge is quantized. So here is my attempt at a solution to the problem. Let $E$ be a $U(1)$-bundle over $M$ as in the problem. Let $D$ be a connection on $E$ with corresponding vector potential $A$ and let $F$ be the curvature of $D$. We define the real valued two-form $B$ by $B:= -i \text{tr}(F)$. Now I suppose one would like to mimic the earlier proof and say that if one carries a particle with charge $q$ around a loop $\gamma$ in $M$ its wave function would be multiplied by a factor \begin{equation} e^{-\frac{i}{\hbar}\int_{D} B}, \end{equation} where $D$ is a disk enclosed by the loop $\gamma$, but here I have some doubts, since it might not be possible to make such a disk if $M$ is not simply connected, and even worse I am not sure this needs to be true. And even if there is a way around these objections, I would not know how to continue since in the argument I am trying to mimic one explicitly computes $\int_{D} B$, but I am not sure how to do this without explicit knowledge of the manifold $M$. Any help would be greatly appreciated!",,"['differential-geometry', 'algebraic-topology', 'quantum-mechanics']"
56,Definition of Cech-De Rham complex. Can't understand its definition!!!!,Definition of Cech-De Rham complex. Can't understand its definition!!!!,,"Let $M$ be a manifold and let $\mathcal{U}:=\{U_\alpha\}_{\alpha\in I}$ be an open covering, $I$ be a totally ordered set. For every $p$ and for every $\alpha_0<\dots<\alpha_p$, $$ U_{\alpha_0\dots\alpha_p}:=U_{\alpha_0}\cap\dots\cap U_{\alpha_p} $$ and, for every $0\le i\le p$, consider the inclusion maps $$ \partial_i:U_{\alpha_0\dots\alpha_{i-1}\alpha_i\alpha_{i+1}\dots\alpha_p}\to U_{\alpha_0\dots\alpha_{i-1}\alpha_{i+1}\dots\alpha_p} $$ and the induced (via pull-back) restriction maps $$ \delta_i:\Omega^q(U_{\alpha_0\dots\alpha_{i-1}\alpha_{i+1}\dots\alpha_p})\to\Omega^q(U_{\alpha_0\dots\alpha_{i-1}\alpha_i\alpha_{i+1}\dots\alpha_p}) $$ Hence, we can map a form $\omega\in\Omega^q(U_{\alpha_0\dots\alpha_p-1})$ to $\Omega^q(U_{\alpha_0\dots\alpha_p-1\beta})$ for all $U_\beta$ by considering a suitable $\delta_i$ (depending on the position of $\beta$ w.r.t. $\alpha_j$ in $I$). Consider the expression $$ \delta_0-\delta_1+\dots+(-1)^p\delta_p $$ For every $p,q$ and $\alpha_0<\dots <\alpha_{p-1}$ $$ \delta_0-\delta_1+\dots+(-1)^p\delta_p:\Omega^q(U_{\alpha_0\dots\alpha_p-1})\to\prod_{\beta_0<\dots<\beta_k}\Omega^q(U_{\beta_0\dots\beta_p}) $$ is defined setting zero the component of the image if $\{\alpha_i\}\nsubseteq\{\beta_j\}$ and using $(-1)^i\delta_i$ for the appropriate $i$ for the other components. Gluing these maps together and defining $$ C^p (\mathcal{U},\Omega^q):=\prod_{\alpha_0 < \dots < \alpha_p}\Omega^q(U_{\alpha_0 \dots \alpha_p}) $$ we get, for every $p,q$, $$ \delta:C^{p-1}(\mathcal{U},\Omega^q)\to C^p(\mathcal{U},\Omega^q) $$ I have to prove that $\delta\circ\delta=0$. I don't know how to proceed, since the definition of $\delta_0-\delta_1+\dots+(-1)^p\delta_p$ is not clear at all to me. Is anyone able to explain me that definition? Maybe in a simple case. For example, if I consider  $$ \delta:C^0(\mathcal{U},\Omega^q)\to C^1(\mathcal{U},\Omega^q) $$ then I can rewrite $$ \delta: \Omega^q (U_{\alpha_0})\to\prod_{\alpha_0 < \alpha_1}\Omega^q(U_{\alpha_0\alpha_1}) $$ i.e. it is the map which sends the $q$-forms on $U_{\alpha_0}$ on the direct product/direct sum (since it is finite) of the restriction of the form on the all possible intersection $U_{\alpha_0}\cap U_{\alpha_1}$, for every $\alpha_1\in I$ such that $\alpha_0<\alpha_1$. Right?","Let $M$ be a manifold and let $\mathcal{U}:=\{U_\alpha\}_{\alpha\in I}$ be an open covering, $I$ be a totally ordered set. For every $p$ and for every $\alpha_0<\dots<\alpha_p$, $$ U_{\alpha_0\dots\alpha_p}:=U_{\alpha_0}\cap\dots\cap U_{\alpha_p} $$ and, for every $0\le i\le p$, consider the inclusion maps $$ \partial_i:U_{\alpha_0\dots\alpha_{i-1}\alpha_i\alpha_{i+1}\dots\alpha_p}\to U_{\alpha_0\dots\alpha_{i-1}\alpha_{i+1}\dots\alpha_p} $$ and the induced (via pull-back) restriction maps $$ \delta_i:\Omega^q(U_{\alpha_0\dots\alpha_{i-1}\alpha_{i+1}\dots\alpha_p})\to\Omega^q(U_{\alpha_0\dots\alpha_{i-1}\alpha_i\alpha_{i+1}\dots\alpha_p}) $$ Hence, we can map a form $\omega\in\Omega^q(U_{\alpha_0\dots\alpha_p-1})$ to $\Omega^q(U_{\alpha_0\dots\alpha_p-1\beta})$ for all $U_\beta$ by considering a suitable $\delta_i$ (depending on the position of $\beta$ w.r.t. $\alpha_j$ in $I$). Consider the expression $$ \delta_0-\delta_1+\dots+(-1)^p\delta_p $$ For every $p,q$ and $\alpha_0<\dots <\alpha_{p-1}$ $$ \delta_0-\delta_1+\dots+(-1)^p\delta_p:\Omega^q(U_{\alpha_0\dots\alpha_p-1})\to\prod_{\beta_0<\dots<\beta_k}\Omega^q(U_{\beta_0\dots\beta_p}) $$ is defined setting zero the component of the image if $\{\alpha_i\}\nsubseteq\{\beta_j\}$ and using $(-1)^i\delta_i$ for the appropriate $i$ for the other components. Gluing these maps together and defining $$ C^p (\mathcal{U},\Omega^q):=\prod_{\alpha_0 < \dots < \alpha_p}\Omega^q(U_{\alpha_0 \dots \alpha_p}) $$ we get, for every $p,q$, $$ \delta:C^{p-1}(\mathcal{U},\Omega^q)\to C^p(\mathcal{U},\Omega^q) $$ I have to prove that $\delta\circ\delta=0$. I don't know how to proceed, since the definition of $\delta_0-\delta_1+\dots+(-1)^p\delta_p$ is not clear at all to me. Is anyone able to explain me that definition? Maybe in a simple case. For example, if I consider  $$ \delta:C^0(\mathcal{U},\Omega^q)\to C^1(\mathcal{U},\Omega^q) $$ then I can rewrite $$ \delta: \Omega^q (U_{\alpha_0})\to\prod_{\alpha_0 < \alpha_1}\Omega^q(U_{\alpha_0\alpha_1}) $$ i.e. it is the map which sends the $q$-forms on $U_{\alpha_0}$ on the direct product/direct sum (since it is finite) of the restriction of the form on the all possible intersection $U_{\alpha_0}\cap U_{\alpha_1}$, for every $\alpha_1\in I$ such that $\alpha_0<\alpha_1$. Right?",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'homology-cohomology', 'differential-forms']"
57,Equivalent conditions for a linear connection $\nabla$ to be compatible with Riemannian metric $g$,Equivalent conditions for a linear connection  to be compatible with Riemannian metric,\nabla g,"I am reading John M. Lee 's Riemannian Manifolds: An Introduction to Curvature. In Lemma $5.2$, it is said that the following conditions are equivalent for a linear connection $\nabla$ on a Riemannian manifold: (a) $\nabla$ is compatible with $g$.     i.e., for any vector fields $X,Y,Z$,   $$ \nabla_X g(Y,Z) = g(\nabla_X Y,Z) + g(Y,\nabla_X Z) $$   (b) $\nabla g\equiv 0.$ How do we go from (a) to (b) (and (b) to (a))?","I am reading John M. Lee 's Riemannian Manifolds: An Introduction to Curvature. In Lemma $5.2$, it is said that the following conditions are equivalent for a linear connection $\nabla$ on a Riemannian manifold: (a) $\nabla$ is compatible with $g$.     i.e., for any vector fields $X,Y,Z$,   $$ \nabla_X g(Y,Z) = g(\nabla_X Y,Z) + g(Y,\nabla_X Z) $$   (b) $\nabla g\equiv 0.$ How do we go from (a) to (b) (and (b) to (a))?",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'connections']"
58,Is Hilbert's theorem generalizable to $H^3$ immersion in $\mathbb{R}^4$?,Is Hilbert's theorem generalizable to  immersion in ?,H^3 \mathbb{R}^4,"The Hilbert theorem in differential geometry concerns the immersion of the hyperbolic plane in $\mathbb{R}^3$. Is it valid for $H^3$  in $\mathbb{R}^4$?, and for all $H^n$ in $\mathbb{R}^{n+1}$?","The Hilbert theorem in differential geometry concerns the immersion of the hyperbolic plane in $\mathbb{R}^3$. Is it valid for $H^3$  in $\mathbb{R}^4$?, and for all $H^n$ in $\mathbb{R}^{n+1}$?",,"['differential-geometry', 'riemannian-geometry']"
59,Proving that the coordinate basis is a basis of a tangent space,Proving that the coordinate basis is a basis of a tangent space,,"Given a differentiable manifold $M$ and some chart $(U, \psi)$ near $p$, we can consider the curve $\tilde{\beta}_i: t \mapsto \psi(p)+t e_i$, where $e_i$ denoted the standard basis in $\mathbb{R}^n$, $i \in \{1, \dots, n\}$. Now we can set $\beta_i := \psi^{-1} \circ \tilde{\beta}_i$ to get the corresponding curve on $M$ and we can define the corresponding tangent vector by $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} u := \left.\frac{d}{dt}\right|_{t=0} u(\beta_i(t))$$ for all $u \in C^{\infty}(M)$. We can quickly verify that this is indeed well-defined. A quick computation also shows that any linear combination of these vectors still lies in $T_pM$ and that they span $T_pM$. To show that they form a basis, it is left to show that they are linearly independent. We have done a proof in class where at some point I must have made a typo or I simply fail to understand what is happening. There exists a cutoff function $\rho: \mathbb{R}\to\mathbb{R}$ that is smooth and satisfies   $$\rho(x) = \begin{cases}1 & x \in (-\frac{1}{2},\frac{1}{2})\\ 0 & x \in (-\infty, -\frac{3}{4}] \cup [\frac{3}{4},\infty)\end{cases}.$$   For $j \in \{1,\dots,n\}$ define $\varphi_j: M \to \mathbb{R}$ by   $$\varphi_j(q) := \begin{cases} 0 & q \notin U\\ \left(\prod_{i=1}^n \rho \left(\frac{\psi^i(q)-\psi^i(p)}{\varepsilon}\right)\right)\psi^j(q) & q \in U \end{cases}.$$   Then, $\varphi_j \in C^{\infty}(M)$ and $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} \varphi_j = \delta_{ij},$$   which implies that they are linearly independent. Question 1: What is $\varepsilon$? In an earlier class we defined tangent vectors as linear maps arising as a directional derivative along some smooth curve $\gamma: (-\varepsilon,\varepsilon)\to M$ with $\gamma(0)=p$. This doesn't make any sense in the proof because we can choose $\varepsilon$ rather freely. I am pretty sure this must be a typo, so the real question is: What should the definition of $\varphi_j$ actually be? Question 2: What does the function $\varphi_j$ do? Question 3: Why does $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} \varphi_j = \delta_{ij}$$ imply that the coordinate basis vectors are linearly independent?","Given a differentiable manifold $M$ and some chart $(U, \psi)$ near $p$, we can consider the curve $\tilde{\beta}_i: t \mapsto \psi(p)+t e_i$, where $e_i$ denoted the standard basis in $\mathbb{R}^n$, $i \in \{1, \dots, n\}$. Now we can set $\beta_i := \psi^{-1} \circ \tilde{\beta}_i$ to get the corresponding curve on $M$ and we can define the corresponding tangent vector by $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} u := \left.\frac{d}{dt}\right|_{t=0} u(\beta_i(t))$$ for all $u \in C^{\infty}(M)$. We can quickly verify that this is indeed well-defined. A quick computation also shows that any linear combination of these vectors still lies in $T_pM$ and that they span $T_pM$. To show that they form a basis, it is left to show that they are linearly independent. We have done a proof in class where at some point I must have made a typo or I simply fail to understand what is happening. There exists a cutoff function $\rho: \mathbb{R}\to\mathbb{R}$ that is smooth and satisfies   $$\rho(x) = \begin{cases}1 & x \in (-\frac{1}{2},\frac{1}{2})\\ 0 & x \in (-\infty, -\frac{3}{4}] \cup [\frac{3}{4},\infty)\end{cases}.$$   For $j \in \{1,\dots,n\}$ define $\varphi_j: M \to \mathbb{R}$ by   $$\varphi_j(q) := \begin{cases} 0 & q \notin U\\ \left(\prod_{i=1}^n \rho \left(\frac{\psi^i(q)-\psi^i(p)}{\varepsilon}\right)\right)\psi^j(q) & q \in U \end{cases}.$$   Then, $\varphi_j \in C^{\infty}(M)$ and $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} \varphi_j = \delta_{ij},$$   which implies that they are linearly independent. Question 1: What is $\varepsilon$? In an earlier class we defined tangent vectors as linear maps arising as a directional derivative along some smooth curve $\gamma: (-\varepsilon,\varepsilon)\to M$ with $\gamma(0)=p$. This doesn't make any sense in the proof because we can choose $\varepsilon$ rather freely. I am pretty sure this must be a typo, so the real question is: What should the definition of $\varphi_j$ actually be? Question 2: What does the function $\varphi_j$ do? Question 3: Why does $$\left(\frac{\partial}{\partial x^i}\right)_{p,\psi} \varphi_j = \delta_{ij}$$ imply that the coordinate basis vectors are linearly independent?",,['differential-geometry']
60,$G$-structure defined by a tensor,-structure defined by a tensor,G,"Let $M$ be an $n$ dimensional manifold with its bundle of linear frames $\pi:L(M)\to M$. Suppose $T_0$ is a tensor on $\mathbb R^n$ and $u\in L(M)$. We may view $u$ as a linear map $u:\mathbb R^n\to T_{\pi(u)}M$. Obtain the induced morphism of tensor algebras $u_*:\mathfrak T(\mathbb R^n)\to\mathfrak T(T_{\pi(u)}M)$. How may we view $T=u_*T_0$ as a section of $\mathfrak T(M)$, when $T$ is only a tensor above $\pi(u)$? Now let $G<GL(n,\mathbb R)$ be the largest Lie subgroup that leaves $T_0$ invariant. How can we use invariance of $T_0$ to define a section of the associated bundle $L(M)/G$?","Let $M$ be an $n$ dimensional manifold with its bundle of linear frames $\pi:L(M)\to M$. Suppose $T_0$ is a tensor on $\mathbb R^n$ and $u\in L(M)$. We may view $u$ as a linear map $u:\mathbb R^n\to T_{\pi(u)}M$. Obtain the induced morphism of tensor algebras $u_*:\mathfrak T(\mathbb R^n)\to\mathfrak T(T_{\pi(u)}M)$. How may we view $T=u_*T_0$ as a section of $\mathfrak T(M)$, when $T$ is only a tensor above $\pi(u)$? Now let $G<GL(n,\mathbb R)$ be the largest Lie subgroup that leaves $T_0$ invariant. How can we use invariance of $T_0$ to define a section of the associated bundle $L(M)/G$?",,"['differential-geometry', 'differential-topology', 'tensors', 'fiber-bundles', 'principal-bundles']"
61,Definition of submanifolds by regular values,Definition of submanifolds by regular values,,"Let $f: M \rightarrow N$ and $q \in N$ be a regular value, then $f^{-1}(q)$ is a submanifold of $M$. Now assume that $q \in N$ is not a regular value, but you pick $K:=f^{-1}(q) \cap \{p \in M; Df|_p \text{ is surjective.}\}.$ Does this mean that $K$ is a manifold? Or more generally, is there a way out to define a manifold if our $q$ is not a regular value?","Let $f: M \rightarrow N$ and $q \in N$ be a regular value, then $f^{-1}(q)$ is a submanifold of $M$. Now assume that $q \in N$ is not a regular value, but you pick $K:=f^{-1}(q) \cap \{p \in M; Df|_p \text{ is surjective.}\}.$ Does this mean that $K$ is a manifold? Or more generally, is there a way out to define a manifold if our $q$ is not a regular value?",,"['real-analysis', 'differential-geometry', 'manifolds']"
62,Condition equivalent to a moduli space being a manifold,Condition equivalent to a moduli space being a manifold,,"Let $M$ be an $n$-manifold, and assume that it is foliated by a regular $p$-foliation. I know the following implication to be true: If for every point $m\in M$ there exists a submanifold $m\in S\subset M$ which intersects every leaf at most once and which is such that for every $x\in S$ we have $T_xM = T_xS\oplus T_xF$ (where $F$ denotes the leaf through $x$), then the moduli space of leaves is a manifold in a natural way. By the moduli space of leaves I mean $M/\sim$, where $x\sim y$ whenever $x$ and $y$ are on the same leaf. The proof goes by using the local slices $S$ as charts for the moduli space. My question is: is the converse also true? I believe it is not, but I have not been able to find a counterexample as of yet. Any help would be greatly appreciated.","Let $M$ be an $n$-manifold, and assume that it is foliated by a regular $p$-foliation. I know the following implication to be true: If for every point $m\in M$ there exists a submanifold $m\in S\subset M$ which intersects every leaf at most once and which is such that for every $x\in S$ we have $T_xM = T_xS\oplus T_xF$ (where $F$ denotes the leaf through $x$), then the moduli space of leaves is a manifold in a natural way. By the moduli space of leaves I mean $M/\sim$, where $x\sim y$ whenever $x$ and $y$ are on the same leaf. The proof goes by using the local slices $S$ as charts for the moduli space. My question is: is the converse also true? I believe it is not, but I have not been able to find a counterexample as of yet. Any help would be greatly appreciated.",,"['differential-geometry', 'foliations']"
63,About separation property of hypersurface,About separation property of hypersurface,,Let N be a complete Riemannian manifold and M be a complete hypersurface in N. M is said to have separation property if N\M is disjoint union of 2 connected open sets in N. Under what reasonable assumptions on N (like simply connected or vanishing homology or cohomology)can ensure that M must have separation property? Thank you.,Let N be a complete Riemannian manifold and M be a complete hypersurface in N. M is said to have separation property if N\M is disjoint union of 2 connected open sets in N. Under what reasonable assumptions on N (like simply connected or vanishing homology or cohomology)can ensure that M must have separation property? Thank you.,,"['differential-geometry', 'differential-topology']"
64,Mean Curvature Flow,Mean Curvature Flow,,"Recently I am reading the mean curvature flow from the lecture notes of Carlo Mantegazza where I found that Under mean curvature flow given by$$\begin{cases}{\partial\over \partial t}\varphi(p,t)=H(p,t)\nu (p,t),\\\varphi(p,0)=\varphi_0(p)\end{cases}$$  among all the velocity functions with fixed $L^2(\mu)$ norm equal to $(\int _MH^2d\mu)^{1/2}$,the one such that the Area of hypersurface decreases most rapidly. Actually I can not understand the argument that why it decreases the area most rapidly and also why we must select the $L^2$ norm?","Recently I am reading the mean curvature flow from the lecture notes of Carlo Mantegazza where I found that Under mean curvature flow given by$$\begin{cases}{\partial\over \partial t}\varphi(p,t)=H(p,t)\nu (p,t),\\\varphi(p,0)=\varphi_0(p)\end{cases}$$  among all the velocity functions with fixed $L^2(\mu)$ norm equal to $(\int _MH^2d\mu)^{1/2}$,the one such that the Area of hypersurface decreases most rapidly. Actually I can not understand the argument that why it decreases the area most rapidly and also why we must select the $L^2$ norm?",,"['differential-geometry', 'riemannian-geometry', 'mean-curvature-flows']"
65,"If a mapping is bijective and regular, then the mapping is a diffeomorphism?","If a mapping is bijective and regular, then the mapping is a diffeomorphism?",,"Let me ask a question which appears in the book 'Elementary Differential Geometry' written by O'Neil. The questions is: prove that if a one-to-one and onto mapping $f:\Bbb R ^n \to \Bbb R ^n$ is regular, then it is diffeomorphism. In the book, ""$f$ is regular"" means that the tangent map of $f$ is one to one. I think certainly I need to use the inverse function thorem. $f$ is a mapping so $f$ is in the class $\mathcal C ^1$. Since $f$ is regular and in the class $\mathcal C^1$, its Jacobian is invertible, so the derivative of $f$ is invertible. Therefore, I might apply the inverse function theorem to $f$: there exists an open set in $\Bbb R ^n$ in which the inverse of $f$ exists and the inverse belongs to the class $\mathcal C ^1$ so $f$ is a diffeomorphism. But to prove $f$ is a diffeomorphism, shouldn't I show the inverse of $f$ is in the class $\mathcal C ^1$ for every point in $\Bbb R ^n$? I would really appreciate any help. Thank you for reading.","Let me ask a question which appears in the book 'Elementary Differential Geometry' written by O'Neil. The questions is: prove that if a one-to-one and onto mapping $f:\Bbb R ^n \to \Bbb R ^n$ is regular, then it is diffeomorphism. In the book, ""$f$ is regular"" means that the tangent map of $f$ is one to one. I think certainly I need to use the inverse function thorem. $f$ is a mapping so $f$ is in the class $\mathcal C ^1$. Since $f$ is regular and in the class $\mathcal C^1$, its Jacobian is invertible, so the derivative of $f$ is invertible. Therefore, I might apply the inverse function theorem to $f$: there exists an open set in $\Bbb R ^n$ in which the inverse of $f$ exists and the inverse belongs to the class $\mathcal C ^1$ so $f$ is a diffeomorphism. But to prove $f$ is a diffeomorphism, shouldn't I show the inverse of $f$ is in the class $\mathcal C ^1$ for every point in $\Bbb R ^n$? I would really appreciate any help. Thank you for reading.",,['differential-geometry']
66,Naturality of the Exterior Derivative,Naturality of the Exterior Derivative,,"On page 8 of Kobayashi & Nomizu, Volume I, it is stated that $d(f^{*} \omega) = f^{*}(d \omega)$, that is, the exterior derivative on forms is a natural operation. Of course, one can show this simply by writing out the definition in terms of coordinates and simply computing the pullback etc.  (see the question here ). My question is: is there a more conceptual way to see this from the characterization of the exterior derivative given in K&N? I feel I am missing something here. More generally, the same applies for the Lie derivative, Lie bracket etc.  - is there a more conceptual way of seeing that such operations are natural?","On page 8 of Kobayashi & Nomizu, Volume I, it is stated that $d(f^{*} \omega) = f^{*}(d \omega)$, that is, the exterior derivative on forms is a natural operation. Of course, one can show this simply by writing out the definition in terms of coordinates and simply computing the pullback etc.  (see the question here ). My question is: is there a more conceptual way to see this from the characterization of the exterior derivative given in K&N? I feel I am missing something here. More generally, the same applies for the Lie derivative, Lie bracket etc.  - is there a more conceptual way of seeing that such operations are natural?",,"['differential-geometry', 'smooth-manifolds']"
67,Are $\mathbb{CP}^{n}$ and $\mathbb{RP}^{2n}$ diffeomorphic?,Are  and  diffeomorphic?,\mathbb{CP}^{n} \mathbb{RP}^{2n},"I understand that they are homeomorphic but couldn't find a proof that they are diffeomorphic. If they are diffeomorphic and if the proof is simple enough, I would imagine it would look like the following: $$\mathbb{CP}^{n}=(\mathbb{C}^{n+1}/\{0\})/{\sim}_{\mathbb{C}}\simeq(\mathbb{R}^{2(n+1)}/\{0\})/{\sim}_{\mathbb{R}^2}\simeq(\mathbb{R}^{2n}/\{0\})/{\sim}_{\mathbb{R}}=\mathbb{RP}^{2n} $$ where the equalities hold by definition, equivalence is diffeomorphism, and $\sim_k$ denotes the equivalence class under the multiplication by nonzero $m\in k$. The first equivalence is by the fact that $\mathbb{R}^2\simeq\mathbb{C}$, but I don't know how to prove the second equivalence. Could anybody help me?","I understand that they are homeomorphic but couldn't find a proof that they are diffeomorphic. If they are diffeomorphic and if the proof is simple enough, I would imagine it would look like the following: $$\mathbb{CP}^{n}=(\mathbb{C}^{n+1}/\{0\})/{\sim}_{\mathbb{C}}\simeq(\mathbb{R}^{2(n+1)}/\{0\})/{\sim}_{\mathbb{R}^2}\simeq(\mathbb{R}^{2n}/\{0\})/{\sim}_{\mathbb{R}}=\mathbb{RP}^{2n} $$ where the equalities hold by definition, equivalence is diffeomorphism, and $\sim_k$ denotes the equivalence class under the multiplication by nonzero $m\in k$. The first equivalence is by the fact that $\mathbb{R}^2\simeq\mathbb{C}$, but I don't know how to prove the second equivalence. Could anybody help me?",,"['differential-geometry', 'smooth-manifolds']"
68,differentiable structure on mobius strip,differentiable structure on mobius strip,,"Define $M= \mathbb{R}^2/\sim$ where $(x,y)\sim(x',y')$ if $x-x'=2n$ for some integer $n$ and $y = (-1)^n y'$. Then how can I give a differentiable sturucture on $M$? Is there a general technique for this? (Currently I'm reading Lee's SM. I hope you give me some ref. pages too.)","Define $M= \mathbb{R}^2/\sim$ where $(x,y)\sim(x',y')$ if $x-x'=2n$ for some integer $n$ and $y = (-1)^n y'$. Then how can I give a differentiable sturucture on $M$? Is there a general technique for this? (Currently I'm reading Lee's SM. I hope you give me some ref. pages too.)",,['differential-geometry']
69,Difference of two connections is a tensor,Difference of two connections is a tensor,,"I am currently reading through Jost's Riemannian Geometry and Geometric Analysis and am seeking clarification of the statement in the title. Jost abstractly defines a connection on a vector bundle $D:\Gamma(E)\rightarrow \Gamma(E\otimes T^*M)$ as $D=d+A$ where $d$ is the exterior derivative and $A=(A^k_j)$ and $A^k_j=\Gamma^k_{ij}dx^i$. He derives the transformation law for the matrix $A$ as $A_{\alpha}=\varphi_{\beta\alpha}^{-1}d\varphi_{\beta\alpha}+\varphi_{\beta\alpha}^{-1}A_{\beta}\varphi_{\beta\alpha}$ Where $\varphi_{\beta\alpha}$ are the transition maps associated with the trivialisations of the vector bundle. Jost then goes on to say 'Thus, $A$ does not transform like a tensor (because of the $\varphi_{\beta\alpha}^{-1}d\varphi_{\beta\alpha}$ term) but the difference of two connection transforms as a tensor'. I want to get a better understanding of this statement. I understand how covariant and contravariant tensors transform under a change of coordinates. However, I am struggling to see why the presence of the $\varphi_{\beta\alpha}^{-1}d\varphi_{\beta\alpha}$ term means $A$ does not transform like a tensor. Finally, in this context of connections on vector bundles, why is it that the difference of two connections transforms as a tensor?","I am currently reading through Jost's Riemannian Geometry and Geometric Analysis and am seeking clarification of the statement in the title. Jost abstractly defines a connection on a vector bundle $D:\Gamma(E)\rightarrow \Gamma(E\otimes T^*M)$ as $D=d+A$ where $d$ is the exterior derivative and $A=(A^k_j)$ and $A^k_j=\Gamma^k_{ij}dx^i$. He derives the transformation law for the matrix $A$ as $A_{\alpha}=\varphi_{\beta\alpha}^{-1}d\varphi_{\beta\alpha}+\varphi_{\beta\alpha}^{-1}A_{\beta}\varphi_{\beta\alpha}$ Where $\varphi_{\beta\alpha}$ are the transition maps associated with the trivialisations of the vector bundle. Jost then goes on to say 'Thus, $A$ does not transform like a tensor (because of the $\varphi_{\beta\alpha}^{-1}d\varphi_{\beta\alpha}$ term) but the difference of two connection transforms as a tensor'. I want to get a better understanding of this statement. I understand how covariant and contravariant tensors transform under a change of coordinates. However, I am struggling to see why the presence of the $\varphi_{\beta\alpha}^{-1}d\varphi_{\beta\alpha}$ term means $A$ does not transform like a tensor. Finally, in this context of connections on vector bundles, why is it that the difference of two connections transforms as a tensor?",,"['differential-geometry', 'manifolds', 'tensors', 'vector-bundles', 'connections']"
70,Try to show $X$ is a smooth manifold,Try to show  is a smooth manifold,X,"Let $u = (u_1,u_2,u_3)$, $v = (v_1,v_2,v_3)$ and $$X = \{(u,v) \in \mathbb{R^3} \times \mathbb{R^3} \mid u_1^2+u_2^2+u_3^3=1, v_1^2+v_2^2-v_3^2=1, u \cdot v=0 \}$$ Then, is $X$ a smooth manifold? What I have in mind is try to apply regular value theorem. So, let $F:\mathbb{R^6} \rightarrow \mathbb{R^3}$ define by $$F(u,v) = (u_1^2+u_2^2+u_3^3,v_1^2+v_2^2-v_3^2,u_1v_1+u_2v_2+u_3v_3)$$ $$DF =  \left( \begin{array}{ccc} 2u_1 & 2u_2 & 2u_3 & 0 & 0 & 0 \\ 0 & 0 & 0 & 2v_1 & 2v_2 & -2v_3 \\ v_1&v_2&v_3&u_1&u_2&u_3 \end{array} \right) $$ I know that $F(u',v')$ will be a regular value when $DF|_{(u',v')}$ has full rank (i.e. $\text{rank}(DF) = 3$). But I don't know how to show that. Isn't as long as none of the row has all zero entries, the matrix will have full rank? (Which mean as long as $u \neq 0$ or $v \neq 0$)","Let $u = (u_1,u_2,u_3)$, $v = (v_1,v_2,v_3)$ and $$X = \{(u,v) \in \mathbb{R^3} \times \mathbb{R^3} \mid u_1^2+u_2^2+u_3^3=1, v_1^2+v_2^2-v_3^2=1, u \cdot v=0 \}$$ Then, is $X$ a smooth manifold? What I have in mind is try to apply regular value theorem. So, let $F:\mathbb{R^6} \rightarrow \mathbb{R^3}$ define by $$F(u,v) = (u_1^2+u_2^2+u_3^3,v_1^2+v_2^2-v_3^2,u_1v_1+u_2v_2+u_3v_3)$$ $$DF =  \left( \begin{array}{ccc} 2u_1 & 2u_2 & 2u_3 & 0 & 0 & 0 \\ 0 & 0 & 0 & 2v_1 & 2v_2 & -2v_3 \\ v_1&v_2&v_3&u_1&u_2&u_3 \end{array} \right) $$ I know that $F(u',v')$ will be a regular value when $DF|_{(u',v')}$ has full rank (i.e. $\text{rank}(DF) = 3$). But I don't know how to show that. Isn't as long as none of the row has all zero entries, the matrix will have full rank? (Which mean as long as $u \neq 0$ or $v \neq 0$)",,['differential-geometry']
71,Fibered product of Hopf Fibrations,Fibered product of Hopf Fibrations,,I am wondering: what is the vector bundle associated to the Hopf-fibration $S^{3}\to S^{2}$? What is the fibered product of two Hopf-fibrations? Thanks.,I am wondering: what is the vector bundle associated to the Hopf-fibration $S^{3}\to S^{2}$? What is the fibered product of two Hopf-fibrations? Thanks.,,"['differential-geometry', 'algebraic-topology', 'fiber-bundles', 'fibration']"
72,Deriving Ricci identity for co-vector fields,Deriving Ricci identity for co-vector fields,,"Let $\nabla$ be the covariant derivative associated with a torsionless connection.  Prove the Ricci identity for covectors: $$\nabla_a \nabla_b \lambda_c - \nabla_b \nabla_a \lambda_c = -R^d_{\,\,cab}\lambda_d$$ Attempt: Consider the object $\nabla_a \nabla_b (X^c \lambda_c)$. Then by distributing using the Leibniz rule, we obtain $$\nabla_a (\nabla_b (X^c) \lambda_c + X^c \nabla_b (\lambda_c))$$ and again, this time operating with $\nabla_a$ gives $$(\nabla_a \nabla_b X^c)\lambda_c + \nabla_b(X^c) \nabla_a (\lambda_a) + \nabla_a(X^c)\nabla_b (\lambda_c) + X^c \nabla_a \nabla_b \lambda_c$$ I can then use the Ricci identity for vector fields on the first term and simplify the middle terms to give $$(R^c_{\,\,dab}X^d + \nabla_b \nabla_a X^c)\lambda_c + e_b(X^c) e_a(\lambda_c) + e_a(X^c) e_b(\lambda_c) + X^c\nabla_a \nabla_b \lambda_c$$ using the fact that for a function, $\nabla_X f = X(f)$ where $X$ is a vector field. $\lambda_c$ and $X^c$ are the components of the covector and vector respectively. I am just not quite sure how to progress. I think I am going to need to symmetrise over the $a$ and $b$ indices to extract another term so I can obtain the required terms in the identity but at the moment I am unsure.  Thanks for any help!","Let $\nabla$ be the covariant derivative associated with a torsionless connection.  Prove the Ricci identity for covectors: $$\nabla_a \nabla_b \lambda_c - \nabla_b \nabla_a \lambda_c = -R^d_{\,\,cab}\lambda_d$$ Attempt: Consider the object $\nabla_a \nabla_b (X^c \lambda_c)$. Then by distributing using the Leibniz rule, we obtain $$\nabla_a (\nabla_b (X^c) \lambda_c + X^c \nabla_b (\lambda_c))$$ and again, this time operating with $\nabla_a$ gives $$(\nabla_a \nabla_b X^c)\lambda_c + \nabla_b(X^c) \nabla_a (\lambda_a) + \nabla_a(X^c)\nabla_b (\lambda_c) + X^c \nabla_a \nabla_b \lambda_c$$ I can then use the Ricci identity for vector fields on the first term and simplify the middle terms to give $$(R^c_{\,\,dab}X^d + \nabla_b \nabla_a X^c)\lambda_c + e_b(X^c) e_a(\lambda_c) + e_a(X^c) e_b(\lambda_c) + X^c\nabla_a \nabla_b \lambda_c$$ using the fact that for a function, $\nabla_X f = X(f)$ where $X$ is a vector field. $\lambda_c$ and $X^c$ are the components of the covector and vector respectively. I am just not quite sure how to progress. I think I am going to need to symmetrise over the $a$ and $b$ indices to extract another term so I can obtain the required terms in the identity but at the moment I am unsure.  Thanks for any help!",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'connections']"
73,Show that a helicoid is a regular surface.,Show that a helicoid is a regular surface.,,"Let $S = \{(u\cos v, u\sin v, v): 0<v<2\pi, -\infty<u<+\infty\}.$ Show that S is a regular surface. $\newcommand{\D}{\mathrm{d}}$ I'm using DoCarmo's book, Differential Geometry of Curves and Surfaces . For $S \subset \mathbb{R}^3$ to be a regular surface, we would need for each $p \in S$, there exists a neighborhood $V$ in $\mathbb{R}^3$ and a map $\mathbb{x}: \to V \cap S$ of an open set $U \subset \mathbb{R}^2$ onto $V \cap S \subset \mathbb{R}^3$ such that $\mathbb{x}$ is differentiable (i.e., its component functions have continuous partial derivatives of all orders in $U$), $\mathbb{x}$ is a homeomorphism (i.e., it has a continuous inverse), and for each $q \in U$, the differential $\mathrm{d}\mathbb{x}_q: \mathbb{R}^2 \to \mathbb{R}^3$ is one-to-one. Is this definition equivalent to showing that the vectors $\mathbb{x}_u$ and $\mathbb{x}_v$, where $\mathbb{x}(u,v) = (u\cos v, u \sin v, v)$ are linearly independent? If so, isn't that quite trivial? If not, can someone show me why not, and explain what we can do?","Let $S = \{(u\cos v, u\sin v, v): 0<v<2\pi, -\infty<u<+\infty\}.$ Show that S is a regular surface. $\newcommand{\D}{\mathrm{d}}$ I'm using DoCarmo's book, Differential Geometry of Curves and Surfaces . For $S \subset \mathbb{R}^3$ to be a regular surface, we would need for each $p \in S$, there exists a neighborhood $V$ in $\mathbb{R}^3$ and a map $\mathbb{x}: \to V \cap S$ of an open set $U \subset \mathbb{R}^2$ onto $V \cap S \subset \mathbb{R}^3$ such that $\mathbb{x}$ is differentiable (i.e., its component functions have continuous partial derivatives of all orders in $U$), $\mathbb{x}$ is a homeomorphism (i.e., it has a continuous inverse), and for each $q \in U$, the differential $\mathrm{d}\mathbb{x}_q: \mathbb{R}^2 \to \mathbb{R}^3$ is one-to-one. Is this definition equivalent to showing that the vectors $\mathbb{x}_u$ and $\mathbb{x}_v$, where $\mathbb{x}(u,v) = (u\cos v, u \sin v, v)$ are linearly independent? If so, isn't that quite trivial? If not, can someone show me why not, and explain what we can do?",,['differential-geometry']
74,Identity used to prove the Chern-Weil theorem,Identity used to prove the Chern-Weil theorem,,"I'm reading the proof of Chern-Weil theorem found in Nakahara's second edition book (page 422) but I got stucked at the very beginning of the proof. It says that from the identity  $$\tilde{P}(Ad_{g_t}X_1,\ldots, Ad_{g_t}X_r)= \tilde{P}(X_1,\ldots,X_r)$$ where $g_t=\exp{tX}$, $\tilde{P}$ is an invariant polynomial, and $X, X_i\in\mathfrak{g}$, one can recover the identity $$\sum_{i=1}^r\tilde{P}(X_1,\ldots,[X_i,X],\ldots,X_r)=0$$ by differentiation at $t=0$. I understand that $${\frac{d}{dt}Ad_{g_t}X_i}\vert_{t=0}=[X_i,X]$$ but I still feel there is a chain rule missing when doing the differentiation of the first identity. Can someone please explain me with some degree of detail how is this differentiation done?","I'm reading the proof of Chern-Weil theorem found in Nakahara's second edition book (page 422) but I got stucked at the very beginning of the proof. It says that from the identity  $$\tilde{P}(Ad_{g_t}X_1,\ldots, Ad_{g_t}X_r)= \tilde{P}(X_1,\ldots,X_r)$$ where $g_t=\exp{tX}$, $\tilde{P}$ is an invariant polynomial, and $X, X_i\in\mathfrak{g}$, one can recover the identity $$\sum_{i=1}^r\tilde{P}(X_1,\ldots,[X_i,X],\ldots,X_r)=0$$ by differentiation at $t=0$. I understand that $${\frac{d}{dt}Ad_{g_t}X_i}\vert_{t=0}=[X_i,X]$$ but I still feel there is a chain rule missing when doing the differentiation of the first identity. Can someone please explain me with some degree of detail how is this differentiation done?",,"['differential-geometry', 'characteristic-classes']"
75,Map between Tangent Manifolds Well-Defined?,Map between Tangent Manifolds Well-Defined?,,"Let $f: \mathcal{M} \to \mathcal{N}$ be a $\mathscr{C}^{r+1}$ map. We define a map $\mathscr{T}f: \mathscr{T}\mathcal{M} \to \mathscr{T}\mathcal{N}$ as follows: A local representation of the map $\mathscr{T}f$ in the charts on $\mathscr{T}\mathcal{M}$ and $\mathscr{T}\mathcal{N}$ is simply the derivative of the local representation of $f$ in the charts $\{\psi_i,U_i\}_{i \in \Lambda_1}$ and $\{\theta_i, V_i\}_{i \in \Lambda_2}$ on $\mathcal{M}$ and $\mathcal{N}$, respectively. We have the requirement that $f(U_i) \subset V_i$. Thus we have a $\mathscr{C}^r$ map  $$ (\mathscr{T}f)_{ij}: \mathscr{T}U_i \to \mathscr{T}V_i$$ $$ [x,i,a] \mapsto [f(x),j,\partial(\theta_jf\psi^{-1}_i)(\psi_i(x))a] $$ Since this is independent of $i,j$, there is a well-defined map $\mathscr{T}f: \mathscr{T}\mathcal{M} \to \mathscr{T}\mathcal{N}$, so that if $f(x) = y$, $\mathscr{T}_xf: \mathscr{T}_x\mathcal{M} \to \mathscr{T}_y\mathcal{N}$. Now my two questions are, why must we require that $f(U_i) \subset V_j$ for our open coverings? Also, why is the map $(\mathscr{T}f)_{ij}$ independent of $i,j$? I'm told that this is an application of the chain rule, but I don't quite see it.","Let $f: \mathcal{M} \to \mathcal{N}$ be a $\mathscr{C}^{r+1}$ map. We define a map $\mathscr{T}f: \mathscr{T}\mathcal{M} \to \mathscr{T}\mathcal{N}$ as follows: A local representation of the map $\mathscr{T}f$ in the charts on $\mathscr{T}\mathcal{M}$ and $\mathscr{T}\mathcal{N}$ is simply the derivative of the local representation of $f$ in the charts $\{\psi_i,U_i\}_{i \in \Lambda_1}$ and $\{\theta_i, V_i\}_{i \in \Lambda_2}$ on $\mathcal{M}$ and $\mathcal{N}$, respectively. We have the requirement that $f(U_i) \subset V_i$. Thus we have a $\mathscr{C}^r$ map  $$ (\mathscr{T}f)_{ij}: \mathscr{T}U_i \to \mathscr{T}V_i$$ $$ [x,i,a] \mapsto [f(x),j,\partial(\theta_jf\psi^{-1}_i)(\psi_i(x))a] $$ Since this is independent of $i,j$, there is a well-defined map $\mathscr{T}f: \mathscr{T}\mathcal{M} \to \mathscr{T}\mathcal{N}$, so that if $f(x) = y$, $\mathscr{T}_xf: \mathscr{T}_x\mathcal{M} \to \mathscr{T}_y\mathcal{N}$. Now my two questions are, why must we require that $f(U_i) \subset V_j$ for our open coverings? Also, why is the map $(\mathscr{T}f)_{ij}$ independent of $i,j$? I'm told that this is an application of the chain rule, but I don't quite see it.",,"['real-analysis', 'differential-geometry', 'differential-topology']"
76,Sufficient condition for $M$ to have constant curvature,Sufficient condition for  to have constant curvature,M,"I decided to keep my original question. However, I'm having trouble only in a part of it (check NOTE ) Let's consider a Riemannian manifold $(M,g)$, with the Levi-Civita connection $\nabla$. I would like to know why is it that if $M$ has constant sectional curvature, then $\nabla R=0$, where $R$ is the curvature tensor. Moreover, I read that $\nabla R=0$ does not imply that necessarily that $M$ has constant curvature. However, if $\dim(M)=2$, that holds. ( I read in an online set of exercises ) Can anyone give solution/hints/references for this questions ? Thanks in advance... NOTE : Meanwhile, I figured it out how to prove that if $M$ has constant sectional curvature, then$\nabla R=0$. However, it is not clear to me the second question : If $\dim(M)=2$ and $M$ is such that $\nabla R=0$, then $M$ has constant curvature. How ?","I decided to keep my original question. However, I'm having trouble only in a part of it (check NOTE ) Let's consider a Riemannian manifold $(M,g)$, with the Levi-Civita connection $\nabla$. I would like to know why is it that if $M$ has constant sectional curvature, then $\nabla R=0$, where $R$ is the curvature tensor. Moreover, I read that $\nabla R=0$ does not imply that necessarily that $M$ has constant curvature. However, if $\dim(M)=2$, that holds. ( I read in an online set of exercises ) Can anyone give solution/hints/references for this questions ? Thanks in advance... NOTE : Meanwhile, I figured it out how to prove that if $M$ has constant sectional curvature, then$\nabla R=0$. However, it is not clear to me the second question : If $\dim(M)=2$ and $M$ is such that $\nabla R=0$, then $M$ has constant curvature. How ?",,"['differential-geometry', 'riemannian-geometry']"
77,Differentiate Archimedes's spiral,Differentiate Archimedes's spiral,,"I read that the only problem of differential calculus Archimedes solved was constructing the tangent to his spiral, $$r = a + b\theta$$ I would like to differentiate it but I don't know much about differentiating polar functions and can't find this particular problem online. Without giving me a full course in differential geometry, how does one calculate the tangent to the curve at $\theta$?","I read that the only problem of differential calculus Archimedes solved was constructing the tangent to his spiral, $$r = a + b\theta$$ I would like to differentiate it but I don't know much about differentiating polar functions and can't find this particular problem online. Without giving me a full course in differential geometry, how does one calculate the tangent to the curve at $\theta$?",,"['calculus', 'differential-geometry']"
78,Some questions on applying Stokes' theorem,Some questions on applying Stokes' theorem,,Let $\omega$ be a differential form. Stokes' theorem states that for any manifold $\Omega$: $$ \int_{\partial \Omega}\omega = \int_\Omega d\omega$$ where $d$ is the exterior derivative. I would like to use Stokes' theorem to prove that a given differential $1$-form $\varphi$ is exact whenever its integral over a closed curve is zero. My idea is to let $\Omega$ be a closed curve. Then $\partial \Omega = \varnothing$ and therefore $\int_{\partial \Omega}\omega =0$. By Stokes' theorem then $ \int_\Omega d\omega=0$. The problem I have now is that this shows that the integral over a closed curve of $d \omega$ is zero but this doesn't seem to help. Hence: How can I use Stokes' theorem to find a differential $0$-form $\psi$   with $d \psi = \varphi$?,Let $\omega$ be a differential form. Stokes' theorem states that for any manifold $\Omega$: $$ \int_{\partial \Omega}\omega = \int_\Omega d\omega$$ where $d$ is the exterior derivative. I would like to use Stokes' theorem to prove that a given differential $1$-form $\varphi$ is exact whenever its integral over a closed curve is zero. My idea is to let $\Omega$ be a closed curve. Then $\partial \Omega = \varnothing$ and therefore $\int_{\partial \Omega}\omega =0$. By Stokes' theorem then $ \int_\Omega d\omega=0$. The problem I have now is that this shows that the integral over a closed curve of $d \omega$ is zero but this doesn't seem to help. Hence: How can I use Stokes' theorem to find a differential $0$-form $\psi$   with $d \psi = \varphi$?,,"['differential-geometry', 'differential-forms']"
79,Relation between $\operatorname{Aut}(G)$ and $\operatorname{Aut}(\mathfrak g)$,Relation between  and,\operatorname{Aut}(G) \operatorname{Aut}(\mathfrak g),"Let $G$ be a connected Lie group with Lie algebra $\mathfrak{g}$ . We know that when $G$ is simply connected, $\operatorname{Aut}(G)=\operatorname{Aut}(\mathfrak{g})$ (this should follow from the fact that we can lift a Lie algebra homomorphism to a Lie group homomorphism whose differential at $1$ is the Lie algebra homomorphism). Now remove the simple connectedness hypothesis and replace it with semi-simplicity , does it hold that $\operatorname{Aut}(G)^{\circ}=\operatorname{Aut}(\mathfrak{g})^{\circ}$ ?","Let be a connected Lie group with Lie algebra . We know that when is simply connected, (this should follow from the fact that we can lift a Lie algebra homomorphism to a Lie group homomorphism whose differential at is the Lie algebra homomorphism). Now remove the simple connectedness hypothesis and replace it with semi-simplicity , does it hold that ?",G \mathfrak{g} G \operatorname{Aut}(G)=\operatorname{Aut}(\mathfrak{g}) 1 \operatorname{Aut}(G)^{\circ}=\operatorname{Aut}(\mathfrak{g})^{\circ},"['differential-geometry', 'lie-groups', 'lie-algebras']"
80,Find $T_\mathrm{id}\left(\mathrm{Diff}(S^1)\right)$,Find,T_\mathrm{id}\left(\mathrm{Diff}(S^1)\right),We established on last tutorial that $T_\mathrm{id}(\mathrm{Diff}(S^1))$ are vector fields on $S^1$. I'd be grateful for any explanation (formal or intuitive) standing behind this answer.,We established on last tutorial that $T_\mathrm{id}(\mathrm{Diff}(S^1))$ are vector fields on $S^1$. I'd be grateful for any explanation (formal or intuitive) standing behind this answer.,,"['differential-geometry', 'intuition']"
81,The relation between geodesics and distances on a Riemannian manifold,The relation between geodesics and distances on a Riemannian manifold,,"My question is about computing the distance between two points in a Riemannian manifold. Suppose that $(M,g)$ is compact so that it is geodesically complete and geodesically convex. Let $X\in\Gamma(TM)$ be a vector field. Fix a point $p\in M$. Let $\gamma:\mathbb{R}\to M$ denote the unique geodesic with initial velocity $X_p$. That is, $$(\exp)_p(X)=\gamma(1) \ \ \text{ and } \ \ (\exp)_p(tX)=\gamma(t).$$ My question is, why does $$d\left((\exp)_p(X),(\exp)_p(tX)\right)=|1-t||X_p| \ ?$$ Here $d:M\times M\to \mathbb{R}$ denotes the Riemann distance function. That is $$d(p,q)=\inf\left\{\int|\rho^\prime(t)|dt \ ; \rho \text{ is an admissible curve between $p$ and $q$}\right\}$$ Since geodesics are length minimizing wouldn't $\gamma$ be the unique curve between $(\exp)_p(X)$ and $(\exp)_p(tX)$ which minimizes the distance function? But the integral of $|\gamma^\prime(t)|$ isn't $|1-t||X_p|$ ? Any help is very much appreciated.","My question is about computing the distance between two points in a Riemannian manifold. Suppose that $(M,g)$ is compact so that it is geodesically complete and geodesically convex. Let $X\in\Gamma(TM)$ be a vector field. Fix a point $p\in M$. Let $\gamma:\mathbb{R}\to M$ denote the unique geodesic with initial velocity $X_p$. That is, $$(\exp)_p(X)=\gamma(1) \ \ \text{ and } \ \ (\exp)_p(tX)=\gamma(t).$$ My question is, why does $$d\left((\exp)_p(X),(\exp)_p(tX)\right)=|1-t||X_p| \ ?$$ Here $d:M\times M\to \mathbb{R}$ denotes the Riemann distance function. That is $$d(p,q)=\inf\left\{\int|\rho^\prime(t)|dt \ ; \rho \text{ is an admissible curve between $p$ and $q$}\right\}$$ Since geodesics are length minimizing wouldn't $\gamma$ be the unique curve between $(\exp)_p(X)$ and $(\exp)_p(tX)$ which minimizes the distance function? But the integral of $|\gamma^\prime(t)|$ isn't $|1-t||X_p|$ ? Any help is very much appreciated.",,"['calculus', 'differential-geometry', 'riemannian-geometry']"
82,How to prove that all smooth vector bundles on a given vector bundle are the pull back of a vector bundle on the base,How to prove that all smooth vector bundles on a given vector bundle are the pull back of a vector bundle on the base,,"Recently, during a conversation, I heard about the result (previously mentioned also here on MO), whose statement is reported below. Not having the specific background necessary to reconstruct a proof of such a (probably standard) result by myself, I would like to have some hints, or, at least, know references containing its proof. Notations All the considered objects and maps are smooth. Let $E\longrightarrow B$ and $F\longrightarrow E$ be vector bundles. Embedd $B$ into $E$ through the zero section of $E\longrightarrow B$, and let $F_B\longrightarrow B$ be the vector bundle obtained by restriction of $F\longrightarrow E$ to $B$. Statement There exists $\rho:F\longrightarrow E\times_B F_B$, a non-canonical vector bundle isomorphism over $\operatorname{id}_E$, such that $\rho|_{F_B}=\operatorname{id}_{F_B}$.","Recently, during a conversation, I heard about the result (previously mentioned also here on MO), whose statement is reported below. Not having the specific background necessary to reconstruct a proof of such a (probably standard) result by myself, I would like to have some hints, or, at least, know references containing its proof. Notations All the considered objects and maps are smooth. Let $E\longrightarrow B$ and $F\longrightarrow E$ be vector bundles. Embedd $B$ into $E$ through the zero section of $E\longrightarrow B$, and let $F_B\longrightarrow B$ be the vector bundle obtained by restriction of $F\longrightarrow E$ to $B$. Statement There exists $\rho:F\longrightarrow E\times_B F_B$, a non-canonical vector bundle isomorphism over $\operatorname{id}_E$, such that $\rho|_{F_B}=\operatorname{id}_{F_B}$.",,"['reference-request', 'differential-geometry', 'differential-topology', 'vector-bundles']"
83,Hodge star operator,Hodge star operator,,"Again I have issues with notations. The hodge star operator is defined as : (m is the dimension of the manifold) $$\star: \Omega^{r}(M) \rightarrow \Omega^{m-r}(M)$$ $$\star(dx^{\mu_{1}} \wedge dx^{\mu_{2}} \wedge ...\wedge dx^{\mu_{r}}) = \frac{\sqrt{|g|}}{(m-r)!}\epsilon^{\mu_{1}\mu_{2}...\mu_{r}}_{\nu_{r+1}...\nu_{m}}dx^{\nu_{r+1}}\wedge...\wedge dx^{v_m}$$ Where $$\epsilon^{\mu_{1}\mu_{2}...\mu_{m}}= g^{\mu_{1}\nu_{1}}g^{\mu_{2}\nu_{2}}...g^{\mu_{m}\nu_{m}}\epsilon_{\nu_{1}\nu_{2}...\nu_{m}}=g^{-1}\epsilon_{\mu_{1}\mu_{2}...\mu_{m}}$$ With an r-form $$\omega = \frac{1}{r!}\omega_{\mu_{1}\mu_{2}...\mu_{r}}dx^{\mu_{1}} \wedge dx^{\mu_{2}} \wedge...\wedge dx^{\mu_{r}} \in \Omega^{r}(M)$$ Gives $$\star\omega = \frac{\sqrt{|g|}}{r!(m-r)} \omega_{\mu_{1}\mu_{2}...\mu_{r}}\epsilon^{\mu_{1}\mu_{2}...\mu_{r}}_{\nu_{r+1}...\nu_{m}}dx^{\nu_{r+1}}\wedge...\wedge dx^{\nu_m}$$ Now I would like to derive these results (orthogonal metric and doesn't matter if forms or vectors) $$\star(e_{2} \wedge e_{3})=e_{1}$$ $$\star(e_{1} \wedge e_{3})=-e_{2}$$ $$\star(e_{1} \wedge e_{2})=e_{3}$$ Another example, let me calculate $r=2$, $m=3$ $$\star(dx \wedge dy)=\sqrt{|g|}\epsilon^{xy}_{\nu_{2}\nu_{3}}dx^{\nu_{3}} \wedge dx^{\nu_3}$$ I have no clue what's going on, is $\nu$ different from $\mu$ ? How does this machinery work? I know the formula is long and annoying, but can someone give a clear example of how this works?","Again I have issues with notations. The hodge star operator is defined as : (m is the dimension of the manifold) $$\star: \Omega^{r}(M) \rightarrow \Omega^{m-r}(M)$$ $$\star(dx^{\mu_{1}} \wedge dx^{\mu_{2}} \wedge ...\wedge dx^{\mu_{r}}) = \frac{\sqrt{|g|}}{(m-r)!}\epsilon^{\mu_{1}\mu_{2}...\mu_{r}}_{\nu_{r+1}...\nu_{m}}dx^{\nu_{r+1}}\wedge...\wedge dx^{v_m}$$ Where $$\epsilon^{\mu_{1}\mu_{2}...\mu_{m}}= g^{\mu_{1}\nu_{1}}g^{\mu_{2}\nu_{2}}...g^{\mu_{m}\nu_{m}}\epsilon_{\nu_{1}\nu_{2}...\nu_{m}}=g^{-1}\epsilon_{\mu_{1}\mu_{2}...\mu_{m}}$$ With an r-form $$\omega = \frac{1}{r!}\omega_{\mu_{1}\mu_{2}...\mu_{r}}dx^{\mu_{1}} \wedge dx^{\mu_{2}} \wedge...\wedge dx^{\mu_{r}} \in \Omega^{r}(M)$$ Gives $$\star\omega = \frac{\sqrt{|g|}}{r!(m-r)} \omega_{\mu_{1}\mu_{2}...\mu_{r}}\epsilon^{\mu_{1}\mu_{2}...\mu_{r}}_{\nu_{r+1}...\nu_{m}}dx^{\nu_{r+1}}\wedge...\wedge dx^{\nu_m}$$ Now I would like to derive these results (orthogonal metric and doesn't matter if forms or vectors) $$\star(e_{2} \wedge e_{3})=e_{1}$$ $$\star(e_{1} \wedge e_{3})=-e_{2}$$ $$\star(e_{1} \wedge e_{2})=e_{3}$$ Another example, let me calculate $r=2$, $m=3$ $$\star(dx \wedge dy)=\sqrt{|g|}\epsilon^{xy}_{\nu_{2}\nu_{3}}dx^{\nu_{3}} \wedge dx^{\nu_3}$$ I have no clue what's going on, is $\nu$ different from $\mu$ ? How does this machinery work? I know the formula is long and annoying, but can someone give a clear example of how this works?",,"['general-relativity', 'differential-geometry']"
84,Linear dual of vector fields,Linear dual of vector fields,,"Suppose that $M$ is a smooth manifold and $\mathfrak{X}(M)$ is the set of smooth vector fields on $M$. There are basically two different linear structures on $\mathfrak{X}(M)$: 1.) $\mathfrak{X}(M)$ is a (infinite dimensional) $\mathbb{R}$-vector space. 2.) $\mathfrak{X}(M)$ is an $C^\infty(M)$-module, where $C^\infty(M)$ means the algebra of smooth real valued functions on $M$. (These structures are related by a so called Lie-Rinehart pair, but that's irrelevant for the question) Now, the $C^\infty(M)$-dual of $\mathfrak{X}(M)$ is well known and precisely  the $C^\infty(M)$-module of differential one-forms , that is $$\Omega^1(M)=Hom_{C^\infty}(\mathfrak{X}(M),C^\infty(M))$$ The question is: Is there moreover a common description of the $\mathbb{R}$-dual of $\mathfrak{X}(M)$? I mean, how can we think about the elements of $$ Hom_\mathbb{R}(\mathfrak{X}(M),\mathbb{R}) $$ and are there places in mathematics where they appear? I know this is pretty vague, but I'm just trying to 'get a hand' on this kind of dual. Edit: From some of the comments/answers, it became clear to me, that there are better understood restrictions of $Hom_\mathbb{R}(\mathfrak{X}(M),\mathbb{R})$, so the question is generalized to Is there a common description of (some meaningful vector subspace of)  the $\mathbb{R}$-dual of $\mathfrak{X}(M)$?","Suppose that $M$ is a smooth manifold and $\mathfrak{X}(M)$ is the set of smooth vector fields on $M$. There are basically two different linear structures on $\mathfrak{X}(M)$: 1.) $\mathfrak{X}(M)$ is a (infinite dimensional) $\mathbb{R}$-vector space. 2.) $\mathfrak{X}(M)$ is an $C^\infty(M)$-module, where $C^\infty(M)$ means the algebra of smooth real valued functions on $M$. (These structures are related by a so called Lie-Rinehart pair, but that's irrelevant for the question) Now, the $C^\infty(M)$-dual of $\mathfrak{X}(M)$ is well known and precisely  the $C^\infty(M)$-module of differential one-forms , that is $$\Omega^1(M)=Hom_{C^\infty}(\mathfrak{X}(M),C^\infty(M))$$ The question is: Is there moreover a common description of the $\mathbb{R}$-dual of $\mathfrak{X}(M)$? I mean, how can we think about the elements of $$ Hom_\mathbb{R}(\mathfrak{X}(M),\mathbb{R}) $$ and are there places in mathematics where they appear? I know this is pretty vague, but I'm just trying to 'get a hand' on this kind of dual. Edit: From some of the comments/answers, it became clear to me, that there are better understood restrictions of $Hom_\mathbb{R}(\mathfrak{X}(M),\mathbb{R})$, so the question is generalized to Is there a common description of (some meaningful vector subspace of)  the $\mathbb{R}$-dual of $\mathfrak{X}(M)$?",,"['linear-algebra', 'differential-geometry', 'modules']"
85,Coincidence about nabla?,Coincidence about nabla?,,"I was surprised to notice that gradient of function and Levi-Civita connection have the same notation, i.e. nabla sign $\nabla$. Moreover, extending any connection on tensors, one let it be differential (or, equally in presence of Riemann metric, gradient) on functions. Is it just a strange coincidence?","I was surprised to notice that gradient of function and Levi-Civita connection have the same notation, i.e. nabla sign $\nabla$. Moreover, extending any connection on tensors, one let it be differential (or, equally in presence of Riemann metric, gradient) on functions. Is it just a strange coincidence?",,"['differential-geometry', 'notation', 'math-history']"
86,Question about line of curvature,Question about line of curvature,,"If $\alpha$ is a planar geodesic on surface $M$, show that $\alpha$ is a line of curvature. My try: $\alpha$ planar imply torsion=0, and binomial vector is constant. Since $0=\kappa_g=\kappa_\alpha B\cdot U$, ($U$ is normal vector of $M$), so B perpendicular to $U$.  Here's where I stuck. Please help","If $\alpha$ is a planar geodesic on surface $M$, show that $\alpha$ is a line of curvature. My try: $\alpha$ planar imply torsion=0, and binomial vector is constant. Since $0=\kappa_g=\kappa_\alpha B\cdot U$, ($U$ is normal vector of $M$), so B perpendicular to $U$.  Here's where I stuck. Please help",,['differential-geometry']
87,Intuition/visualization for a non-flat connection,Intuition/visualization for a non-flat connection,,"I'd just like to check whether my visualization for a way to get a non-flat connection is correct.  The definition I am using for a connection is, for a fiber bundle $\rho:E \to B$, a smooth assignment to each $e \in E$ a subspace of $T_eE$ transverse to the fiber containing $e$. For simplicity in visualization, I'll choose $\mathbb{R} \times \mathbb{R}$ as the connection, as a fiber bundle over the first factor.  The flat connection would then just be the assignment of the tangent space parallel to the first factor, so $(x,y)$ gets associated the tangent space that looks like $\mathbb{R} \times y$. So my idea for creating a non-flat connection is to take some diffeomorphism $\phi$ of $\mathbb{R} \times \mathbb{R}$ that always fixes the horizontal subspaces, but maps fibers that used to be straight lines into wavy lines (that are still never horizontal) Here's a picture in paint, where the black curves are fibers and the red lines are a few 1-dim subspaces of the tangent spaces at points in the fibers So then if we straighten the fibers by the diffiomorphism $\phi^{-1}$, and similarly push forward the tangent spaces in the picture by $d\phi^{-1}$, it seems like this would be non-flat connection. Is this correct?  Is this a good way to visualize what a non-flat connection looks like - that is, can we usually (in a local product neighbohood) view the connection as some horizontal foliation, through which the fibers move transversely, but not necessarily orthogonally? I have other related questions, but I suppose it's better to just to clarify this and then ask those as separate questions afterwards.","I'd just like to check whether my visualization for a way to get a non-flat connection is correct.  The definition I am using for a connection is, for a fiber bundle $\rho:E \to B$, a smooth assignment to each $e \in E$ a subspace of $T_eE$ transverse to the fiber containing $e$. For simplicity in visualization, I'll choose $\mathbb{R} \times \mathbb{R}$ as the connection, as a fiber bundle over the first factor.  The flat connection would then just be the assignment of the tangent space parallel to the first factor, so $(x,y)$ gets associated the tangent space that looks like $\mathbb{R} \times y$. So my idea for creating a non-flat connection is to take some diffeomorphism $\phi$ of $\mathbb{R} \times \mathbb{R}$ that always fixes the horizontal subspaces, but maps fibers that used to be straight lines into wavy lines (that are still never horizontal) Here's a picture in paint, where the black curves are fibers and the red lines are a few 1-dim subspaces of the tangent spaces at points in the fibers So then if we straighten the fibers by the diffiomorphism $\phi^{-1}$, and similarly push forward the tangent spaces in the picture by $d\phi^{-1}$, it seems like this would be non-flat connection. Is this correct?  Is this a good way to visualize what a non-flat connection looks like - that is, can we usually (in a local product neighbohood) view the connection as some horizontal foliation, through which the fibers move transversely, but not necessarily orthogonally? I have other related questions, but I suppose it's better to just to clarify this and then ask those as separate questions afterwards.",,"['differential-geometry', 'riemannian-geometry']"
88,Gauss curvature of C^2 surfaces,Gauss curvature of C^2 surfaces,,"In do Carmo's book on Differential Geometry of Curves and Surfaces, the proof of theorema egregium , that the Gauss curvature of a surface immersed in $\mathbb{R}^3$ is invariant under local isometries, requires the surface to be of class at least $C^3$. What happens if the surface is of class $C^2$ only ? The Gauss curvature can still be defined but is it invariant under local isometries ? Best, Ryan","In do Carmo's book on Differential Geometry of Curves and Surfaces, the proof of theorema egregium , that the Gauss curvature of a surface immersed in $\mathbb{R}^3$ is invariant under local isometries, requires the surface to be of class at least $C^3$. What happens if the surface is of class $C^2$ only ? The Gauss curvature can still be defined but is it invariant under local isometries ? Best, Ryan",,"['differential-geometry', 'riemannian-geometry']"
89,Why is the set of positive definite matrices in $\mathbb R^{n\times n}$ a positive cone,Why is the set of positive definite matrices in  a positive cone,\mathbb R^{n\times n},"The set of positive definite matrices in $\mathbb R^{n\times n}$ is geometrically a positive cone. This statement appears in almost every article on real positive definite matrices I read but without a proof. Where can I find a general proof, please? In addition, if I assume this statement is true, does it imply that the set of positive definite matrices is a manifold or a sub-manifold of $\mathbb R^n$ for some $n$?","The set of positive definite matrices in $\mathbb R^{n\times n}$ is geometrically a positive cone. This statement appears in almost every article on real positive definite matrices I read but without a proof. Where can I find a general proof, please? In addition, if I assume this statement is true, does it imply that the set of positive definite matrices is a manifold or a sub-manifold of $\mathbb R^n$ for some $n$?",,"['differential-geometry', 'self-learning']"
90,"Why is $[\widetilde{v},\widetilde{w}]_p(f)=0$ when $f$ has a critical point at $p$?",Why is  when  has a critical point at ?,"[\widetilde{v},\widetilde{w}]_p(f)=0 f p","Let $M$ be a smooth manifold and $f$ a smooth function $M\to\mathbb{R}$.  Let $p$ be a critical point of $f$.  We define the Hessian of $f$ at $p$ to be the symmetric bilinear functional $f_{**}$ on $T_p M$ given by $f_{**}(v,w)=\widetilde{v}_p(\widetilde{w}(f))$ where $\widetilde{v}$ and $\widetilde{w}$ are extensions of $v$ and $w$ to vector fields on $M$.  It must be checked that $f_{**}$ is symmetric and well defined. Milnor states that $f_{**}$ is symmetric because $\widetilde{v}_p(\widetilde{w}(f)) - \widetilde{w}_p(\widetilde{v}(f)) = [\widetilde{v},\widetilde{w}]_p(f)$ where $[\widetilde{v},\widetilde{w}]$ denotes the Poisson bracket, which he says satisfies $[\widetilde{v},\widetilde{w}]_p(f)=0$ because $f$ has a critical point at $p$.  Thus since $\widetilde{v}_p(\widetilde{w}(f))$ is independent of the extension of $v$ and $\widetilde{w}_p(\widetilde{v}(f))$ is independent of the extension of $w$ we have that $f_{**}$ is well defined and symmetric by the preceding. My confusion is why $[\widetilde{v},\widetilde{w}]_p(f)=0$.  I'm not familiar with Poisson bracket but this looks like the Lie bracket to me, not the Poisson bracket.  I'm also not sure why it is zero when evaluated at $p,f$. Also one more (non essential) question out of curiosity, can we only define the Hessian in a coordinate free way at points where a function has a critical point?  This would seem strange to me.","Let $M$ be a smooth manifold and $f$ a smooth function $M\to\mathbb{R}$.  Let $p$ be a critical point of $f$.  We define the Hessian of $f$ at $p$ to be the symmetric bilinear functional $f_{**}$ on $T_p M$ given by $f_{**}(v,w)=\widetilde{v}_p(\widetilde{w}(f))$ where $\widetilde{v}$ and $\widetilde{w}$ are extensions of $v$ and $w$ to vector fields on $M$.  It must be checked that $f_{**}$ is symmetric and well defined. Milnor states that $f_{**}$ is symmetric because $\widetilde{v}_p(\widetilde{w}(f)) - \widetilde{w}_p(\widetilde{v}(f)) = [\widetilde{v},\widetilde{w}]_p(f)$ where $[\widetilde{v},\widetilde{w}]$ denotes the Poisson bracket, which he says satisfies $[\widetilde{v},\widetilde{w}]_p(f)=0$ because $f$ has a critical point at $p$.  Thus since $\widetilde{v}_p(\widetilde{w}(f))$ is independent of the extension of $v$ and $\widetilde{w}_p(\widetilde{v}(f))$ is independent of the extension of $w$ we have that $f_{**}$ is well defined and symmetric by the preceding. My confusion is why $[\widetilde{v},\widetilde{w}]_p(f)=0$.  I'm not familiar with Poisson bracket but this looks like the Lie bracket to me, not the Poisson bracket.  I'm also not sure why it is zero when evaluated at $p,f$. Also one more (non essential) question out of curiosity, can we only define the Hessian in a coordinate free way at points where a function has a critical point?  This would seem strange to me.",,"['differential-geometry', 'morse-theory']"
91,Find the integral curves of the given vector field.,Find the integral curves of the given vector field.,,"The vector field is as follows: $X_{(x,y)} = x \dfrac{\partial}{\partial x} - y \dfrac{\partial}{\partial y} = \begin{bmatrix} x \\y \end{bmatrix}$. I know that to find integral curves, you need to solve a differential equation. So here, I would take a derivative of $X$, but I am not completely sure of what to do. With other integral curve computations, I'm usually given some initial conditions. Tips on how to get started would be very helpful. That's really all I'm asking for here. I can do the rest of the math myself. I'm just struggling setting it up.","The vector field is as follows: $X_{(x,y)} = x \dfrac{\partial}{\partial x} - y \dfrac{\partial}{\partial y} = \begin{bmatrix} x \\y \end{bmatrix}$. I know that to find integral curves, you need to solve a differential equation. So here, I would take a derivative of $X$, but I am not completely sure of what to do. With other integral curve computations, I'm usually given some initial conditions. Tips on how to get started would be very helpful. That's really all I'm asking for here. I can do the rest of the math myself. I'm just struggling setting it up.",,"['differential-geometry', 'manifolds']"
92,Is there a shorter path to these results?,Is there a shorter path to these results?,,"I'm a student of Physics, however I usually study mathematics on texts aimed at mathematicians to gain a deeper understanding. Currently I'm studying differential geometry on Spivak's book and one of the main results I need is the relationship between vector fields and infinitesimal transformations, i.e.: the idea of infinitesimal generators. The only problem is that Spivak's way to get into this is a little more complex than what I need. Indeed he spends time with differential equations and topological properties of manifolds that are related to differential equations. These are interesting topics, but for now what I was really needing was this relationship of vectors and infinitesimal transformations and the understanding of where Lie Groups come into play. Is there a shorter path into these results without needing to go through all of that stuff on differential equations? Is there a more direct way to get into these topics? I ask that because perhaps Spivak just presented that way because he wanted to show how vector fields relates to differential equations in a more concrete way. Thanks very much in advance.","I'm a student of Physics, however I usually study mathematics on texts aimed at mathematicians to gain a deeper understanding. Currently I'm studying differential geometry on Spivak's book and one of the main results I need is the relationship between vector fields and infinitesimal transformations, i.e.: the idea of infinitesimal generators. The only problem is that Spivak's way to get into this is a little more complex than what I need. Indeed he spends time with differential equations and topological properties of manifolds that are related to differential equations. These are interesting topics, but for now what I was really needing was this relationship of vectors and infinitesimal transformations and the understanding of where Lie Groups come into play. Is there a shorter path into these results without needing to go through all of that stuff on differential equations? Is there a more direct way to get into these topics? I ask that because perhaps Spivak just presented that way because he wanted to show how vector fields relates to differential equations in a more concrete way. Thanks very much in advance.",,"['reference-request', 'differential-geometry', 'soft-question']"
93,Calculus on Manifolds - operational point of view,Calculus on Manifolds - operational point of view,,"I'm a student of Physics and I've been studying manifolds and calculus on such objects for a time. Usually when we deal with vector calculus there are books that bring one operational point of view. For example: the book Mathematical Methods for Physicists by George Arfken. This book brings interpretations of all the objects, like the vectors themselves, the integrals, the operations and so on and in the same time shows how one operates with them in practice. How to manipulate those objects and even carry down computations with them. Calculus on manifolds, on the other hand, is being a little more complicated. The reason is that all books I've found until now focus just on theorems and their proofs. There's nothing wrong with it, of course this is interesting as well, but what I really need is that operational view with interpretations and so on. For what I've seem until now, when doing calculus on manifolds one gets one incredible amount of work just to do some computations: work out charts, prove they are bijections and homeomorphism, prove they are $C^k$ related and so on. This also confuses me, because it seems much more complicated than vector calculus even to get started, while many people say it's not. So, where can I learn this operational point of view of calculus on manifolds? Meaning, learn to interpret objects like exterior derivatives, differential forms and their integrals, and in the same time learn how to in practice carry out operations with those objects? Thanks very much in advance.","I'm a student of Physics and I've been studying manifolds and calculus on such objects for a time. Usually when we deal with vector calculus there are books that bring one operational point of view. For example: the book Mathematical Methods for Physicists by George Arfken. This book brings interpretations of all the objects, like the vectors themselves, the integrals, the operations and so on and in the same time shows how one operates with them in practice. How to manipulate those objects and even carry down computations with them. Calculus on manifolds, on the other hand, is being a little more complicated. The reason is that all books I've found until now focus just on theorems and their proofs. There's nothing wrong with it, of course this is interesting as well, but what I really need is that operational view with interpretations and so on. For what I've seem until now, when doing calculus on manifolds one gets one incredible amount of work just to do some computations: work out charts, prove they are bijections and homeomorphism, prove they are $C^k$ related and so on. This also confuses me, because it seems much more complicated than vector calculus even to get started, while many people say it's not. So, where can I learn this operational point of view of calculus on manifolds? Meaning, learn to interpret objects like exterior derivatives, differential forms and their integrals, and in the same time learn how to in practice carry out operations with those objects? Thanks very much in advance.",,"['reference-request', 'differential-geometry']"
94,The set of smooth maps from exotic smooth manifolds to the reals,The set of smooth maps from exotic smooth manifolds to the reals,,"Here a $M,N$ are topological manifolds and $\mathcal{A}$ and $\mathcal{B}$ are atlases. The brackets $[]$ denote the formation of the equivalence class of atlases. Let $(M,[\mathcal{A}])$ and $(N,[\mathcal{B}])$ smooth manifolds exotic to each other ($M$ and $N$ homeomorphic, lets say $h(M)=N$, but not diffeomorphic with the smooth structures). I wondered if the following statements are true. $f\in C^\infty (M,[\mathcal{A}])$ is not equivalent to  $f\circ h \in C^\infty (N,[\mathcal{B}])$ There exists an $f\in C^\infty (M,[\mathcal{A}])$ such that there is no $g\in C^\infty (N,[\mathcal{B}])$ such that $f=g\circ h$ and the other way around: There exists an $g\in C^\infty (N,[\mathcal{B}])$ such that there is no $f\in C^\infty (M,[\mathcal{A}])$ such that $g=f\circ h^{-1}$. For all $f\in C^\infty (M,[\mathcal{A}])$ there is no $g\in C^\infty (N,[\mathcal{B}])$ such that $f=g\circ h$. Or in more transparent version with atlases dropped from notation and $M=N$ as topological spaces, but still not diffeomorphic. $C^\infty M\neq C^\infty N$ $C^\infty M\not\subset C^\infty N$ and $C^\infty N\not\subset C^\infty M$ $C^\infty M\cap C^\infty N=\emptyset$ Thanks in advance and maybe the diffoelogy characterization of smoothness is helpful. Kind regards Mar (corrected the error)","Here a $M,N$ are topological manifolds and $\mathcal{A}$ and $\mathcal{B}$ are atlases. The brackets $[]$ denote the formation of the equivalence class of atlases. Let $(M,[\mathcal{A}])$ and $(N,[\mathcal{B}])$ smooth manifolds exotic to each other ($M$ and $N$ homeomorphic, lets say $h(M)=N$, but not diffeomorphic with the smooth structures). I wondered if the following statements are true. $f\in C^\infty (M,[\mathcal{A}])$ is not equivalent to  $f\circ h \in C^\infty (N,[\mathcal{B}])$ There exists an $f\in C^\infty (M,[\mathcal{A}])$ such that there is no $g\in C^\infty (N,[\mathcal{B}])$ such that $f=g\circ h$ and the other way around: There exists an $g\in C^\infty (N,[\mathcal{B}])$ such that there is no $f\in C^\infty (M,[\mathcal{A}])$ such that $g=f\circ h^{-1}$. For all $f\in C^\infty (M,[\mathcal{A}])$ there is no $g\in C^\infty (N,[\mathcal{B}])$ such that $f=g\circ h$. Or in more transparent version with atlases dropped from notation and $M=N$ as topological spaces, but still not diffeomorphic. $C^\infty M\neq C^\infty N$ $C^\infty M\not\subset C^\infty N$ and $C^\infty N\not\subset C^\infty M$ $C^\infty M\cap C^\infty N=\emptyset$ Thanks in advance and maybe the diffoelogy characterization of smoothness is helpful. Kind regards Mar (corrected the error)",,['differential-geometry']
95,prove that a function is an immersion,prove that a function is an immersion,,"How I can show that $F \colon \mathbb{R} \to \mathbb{R}^2$ defined by $F(t)= (\cos (t), \sin(t))$ is an immersion? In my definition $F$ is an immersion if $\forall p$,$dF_p$ is injective. I have compute $dF_p=(-\sin (t), \cos(t))$. But now?","How I can show that $F \colon \mathbb{R} \to \mathbb{R}^2$ defined by $F(t)= (\cos (t), \sin(t))$ is an immersion? In my definition $F$ is an immersion if $\forall p$,$dF_p$ is injective. I have compute $dF_p=(-\sin (t), \cos(t))$. But now?",,"['differential-geometry', 'differential-topology']"
96,Is there a name for this family of curves?,Is there a name for this family of curves?,,"I saw a space curve defined as the following before (but I don't remember the reference): $$ \alpha_{p,q}(t)=\{\left((2+\cos pt)\cos qt,(2+\cos pt)\sin qt,\sin pt\right)|t\in{\Bbb R}\} $$ where $p$ and $q$ are relatively prime. For example, $\alpha_{5,3}$ is something like Is there a name for this family of curves? Would any one come up with a reference?","I saw a space curve defined as the following before (but I don't remember the reference): $$ \alpha_{p,q}(t)=\{\left((2+\cos pt)\cos qt,(2+\cos pt)\sin qt,\sin pt\right)|t\in{\Bbb R}\} $$ where $p$ and $q$ are relatively prime. For example, $\alpha_{5,3}$ is something like Is there a name for this family of curves? Would any one come up with a reference?",,['reference-request']
97,Is this an abuse of notation?,Is this an abuse of notation?,,"Here is a proof says that the differential of Gauss map is self-adjoint. But I seems there is an abuse of notation at (1) in it. Since $dN_p$ is linear, it suffices to verify that $\langle dN_p(w_1), w_2 \rangle = \langle w_1, dN_p(w_2)\rangle$ for a basis ${w_1, w_2}$ of $T_p(S)$. Let $x(u, v)$ be a parametrization of $S$ at $p$ and ${x_u, x_v}$ the associated basis of $T_p(S)$. If $\alpha(t) = x(u(t), v(t))$ is a parametrized curve in $S$, with $\alpha(0) = p$, we have    $$\begin{align} dN_p(\alpha'(0)) &= dN_p(x_uu'(0) + x_vv'(0)) \\ &= \frac d{dt}N(u(t),v(t))\mid_{t=0} & (1)\\ &= N_uu'(0) + N_vv'(0) \end{align}$$ I think it should rewrite as: $$\begin{align} dN_p(\alpha'(0)) &= dN_p(x_uu'(0) + x_vv'(0)) \\ &= dN_p(u(t),v(t))\mid_{t=0} & (2)\\ &= \frac d{dt} N(x(u(t),v(t)))\mid_{t=0} &(3)\\ &= N_uu'(0) + N_vv'(0) \end{align}$$ Reference : Differential Geometry of Curves and Surfaces Manfredo P. do carmo Proposition 1. I care this insomuch we have: $N:S\to S^2$ and $dN_p:T_p(S)\to T_p(S)$","Here is a proof says that the differential of Gauss map is self-adjoint. But I seems there is an abuse of notation at (1) in it. Since $dN_p$ is linear, it suffices to verify that $\langle dN_p(w_1), w_2 \rangle = \langle w_1, dN_p(w_2)\rangle$ for a basis ${w_1, w_2}$ of $T_p(S)$. Let $x(u, v)$ be a parametrization of $S$ at $p$ and ${x_u, x_v}$ the associated basis of $T_p(S)$. If $\alpha(t) = x(u(t), v(t))$ is a parametrized curve in $S$, with $\alpha(0) = p$, we have    $$\begin{align} dN_p(\alpha'(0)) &= dN_p(x_uu'(0) + x_vv'(0)) \\ &= \frac d{dt}N(u(t),v(t))\mid_{t=0} & (1)\\ &= N_uu'(0) + N_vv'(0) \end{align}$$ I think it should rewrite as: $$\begin{align} dN_p(\alpha'(0)) &= dN_p(x_uu'(0) + x_vv'(0)) \\ &= dN_p(u(t),v(t))\mid_{t=0} & (2)\\ &= \frac d{dt} N(x(u(t),v(t)))\mid_{t=0} &(3)\\ &= N_uu'(0) + N_vv'(0) \end{align}$$ Reference : Differential Geometry of Curves and Surfaces Manfredo P. do carmo Proposition 1. I care this insomuch we have: $N:S\to S^2$ and $dN_p:T_p(S)\to T_p(S)$",,"['differential-geometry', 'manifolds', 'self-learning', 'proof-explanation']"
98,Examples of ergodic geodesic flow,Examples of ergodic geodesic flow,,"Are there any good examples of a geodesic flow that is ergodic? I know the result that states that the geodesic flow for manifolds with negative curvature are ergodic, but I'm fishing for some insightful examples.","Are there any good examples of a geodesic flow that is ergodic? I know the result that states that the geodesic flow for manifolds with negative curvature are ergodic, but I'm fishing for some insightful examples.",,"['differential-geometry', 'examples-counterexamples', 'ergodic-theory']"
99,An isometrie $\varphi: S_1\to S_2$ which cannot be extended into distance-preserving map,An isometrie  which cannot be extended into distance-preserving map,\varphi: S_1\to S_2,I'm searching for an example isometrie $\varphi: S_1\to S_2$($S_i$ are regular surfaces) which cannot be extended into distance-preserving maps $F: \Bbb R^3 \to \Bbb R^3$. A reference or hint will help too. \color{gray}{No need the proof of isometrie or disability for extending.},I'm searching for an example isometrie $\varphi: S_1\to S_2$($S_i$ are regular surfaces) which cannot be extended into distance-preserving maps $F: \Bbb R^3 \to \Bbb R^3$. A reference or hint will help too. \color{gray}{No need the proof of isometrie or disability for extending.},,"['reference-request', 'differential-geometry', 'examples-counterexamples']"
