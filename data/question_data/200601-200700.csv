,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Property of normal coordinates,Property of normal coordinates,,"Let $M$ be a Riemannian manifold and $\nabla$ the Levi-Civita conection. I need to prove the following. Let $B$ be an open ball of radius $r$ in $T_pM$ such that $\left.exp_p\right|_B$ be a diffeomorphism over an open $U\subset M$ and let $\{u_1,...,u_n\}$ be an orthonormal basis of $T_pM$. Let $F:T_pM\supset B\rightarrow U\subset M$ given by $F(x_1,...,x_n)=exp_p(x_1u_1+\cdots+x_nu_n)$. Clearly, $(U,F^{-1})$ is a chart. Show that $$\left(\nabla_{X_j}X_i\right)_p=0$$ where $X_i:=\dfrac{\partial }{\partial x_i}$.","Let $M$ be a Riemannian manifold and $\nabla$ the Levi-Civita conection. I need to prove the following. Let $B$ be an open ball of radius $r$ in $T_pM$ such that $\left.exp_p\right|_B$ be a diffeomorphism over an open $U\subset M$ and let $\{u_1,...,u_n\}$ be an orthonormal basis of $T_pM$. Let $F:T_pM\supset B\rightarrow U\subset M$ given by $F(x_1,...,x_n)=exp_p(x_1u_1+\cdots+x_nu_n)$. Clearly, $(U,F^{-1})$ is a chart. Show that $$\left(\nabla_{X_j}X_i\right)_p=0$$ where $X_i:=\dfrac{\partial }{\partial x_i}$.",,"['differential-geometry', 'manifolds', 'riemannian-geometry']"
1,Prove that there are no convex functions on compact manifolds,Prove that there are no convex functions on compact manifolds,,"This one seems intuitively obvious to me but I don't know how to prove it.  Suppose you have a compact manifold $M$ with a function $f$ defined on it.  Given two points $x$ and $y$ on the manifold, let $\gamma_{xy}: [0,1]\rightarrow M$ be the geodesic between $x$ and $y$.  Then we say a function is convex if, $\forall x, y\in M, \lambda \in [0,1],\,\,\,\, f(\gamma_{xy}(\lambda)) \le (1-\lambda)f(x) + \lambda f(y)$ I can't think of any function on a compact manifold for which this is actually true, and I suspect that there are no convex functions on compact manifolds.  Can anyone point me to the relevant proof?","This one seems intuitively obvious to me but I don't know how to prove it.  Suppose you have a compact manifold $M$ with a function $f$ defined on it.  Given two points $x$ and $y$ on the manifold, let $\gamma_{xy}: [0,1]\rightarrow M$ be the geodesic between $x$ and $y$.  Then we say a function is convex if, $\forall x, y\in M, \lambda \in [0,1],\,\,\,\, f(\gamma_{xy}(\lambda)) \le (1-\lambda)f(x) + \lambda f(y)$ I can't think of any function on a compact manifold for which this is actually true, and I suspect that there are no convex functions on compact manifolds.  Can anyone point me to the relevant proof?",,"['differential-geometry', 'convex-analysis', 'compact-manifolds']"
2,Length of a curve is independent of parameterization,Length of a curve is independent of parameterization,,"Suppose that $P:[a,b]\to \mathbb{R}^n$ and $Q:[c,d]\to \mathbb{R}^n$ be two parameterizations of the same continuously differentiable curve $\Gamma$. Can some one give a hint on how to prove that the length of the curve $\Gamma$ is independent of both $P$ or $Q$? If you can also point out the important intrinsic things one should remember when dealing with curves, it would be great. Thanks.","Suppose that $P:[a,b]\to \mathbb{R}^n$ and $Q:[c,d]\to \mathbb{R}^n$ be two parameterizations of the same continuously differentiable curve $\Gamma$. Can some one give a hint on how to prove that the length of the curve $\Gamma$ is independent of both $P$ or $Q$? If you can also point out the important intrinsic things one should remember when dealing with curves, it would be great. Thanks.",,['differential-geometry']
3,"a doubt on manifold with boundary, critical point, space of jets etc","a doubt on manifold with boundary, critical point, space of jets etc",,"could any one explain me the following paragraph by a simple example? ""a manifold with boundary is understood to be a smooth (real or complex) manifold with a fixed smooth hypersurface. Two functions on a manifold with boundary are called equivalent if one goes over into the other under a diffeomorphism of the manifold that takes the boundary into itself. On the boundary we consider a distinguished point O. The group of germs of diffeomorphisms of a manifold with boundary at a distinguished point that keep the boundary fixed acts on the spaces of germs and jets of functions at the distinguished point for which this is a critical point with critical value zero"" I know what is manifold with boundary but never saw such a definition or remark as the author said in 1st line, so I am not feeling anything of the first paragrgaph, but I am confident that if any one give example and tell me I can understand. I know what is critical points like say $f:N\rightarrow M$ be a smoothh map, a point $p\in N$ is said to be a critical point of $f$ if the differential $$f_{*,p}:T_p\rightarrow T_{f(p)}M$$ fails to be surjective and I also know one result for a real valued funtion $f:M\rightarrow \mathbb{R}$, a pt. $p\in M$ is critical iff relative to some chart $(U,x_1,\dots,x_n)$ containing $p$ all the partial derivatives $$\frac{\partial f}{\partial x_i}(p)=0$$ there is also some special kind of group and its action is mentioned here, I could not understand that also. Thank you for help.","could any one explain me the following paragraph by a simple example? ""a manifold with boundary is understood to be a smooth (real or complex) manifold with a fixed smooth hypersurface. Two functions on a manifold with boundary are called equivalent if one goes over into the other under a diffeomorphism of the manifold that takes the boundary into itself. On the boundary we consider a distinguished point O. The group of germs of diffeomorphisms of a manifold with boundary at a distinguished point that keep the boundary fixed acts on the spaces of germs and jets of functions at the distinguished point for which this is a critical point with critical value zero"" I know what is manifold with boundary but never saw such a definition or remark as the author said in 1st line, so I am not feeling anything of the first paragrgaph, but I am confident that if any one give example and tell me I can understand. I know what is critical points like say $f:N\rightarrow M$ be a smoothh map, a point $p\in N$ is said to be a critical point of $f$ if the differential $$f_{*,p}:T_p\rightarrow T_{f(p)}M$$ fails to be surjective and I also know one result for a real valued funtion $f:M\rightarrow \mathbb{R}$, a pt. $p\in M$ is critical iff relative to some chart $(U,x_1,\dots,x_n)$ containing $p$ all the partial derivatives $$\frac{\partial f}{\partial x_i}(p)=0$$ there is also some special kind of group and its action is mentioned here, I could not understand that also. Thank you for help.",,['differential-geometry']
4,When and *why* should one view the space of forms as one big space?,When and *why* should one view the space of forms as one big space?,,"I wonder why in books about differential geometry there seem to be no relevant results about properties of mixed differential forms like $$\omega_{12}\ \mathbb{d}x^1\land\mathbb{d}x^2+\lambda_{123}\ \mathbb{d}x^1\land\mathbb{d}x^2\land\mathbb{d}x^3,$$ where the ""+"" is understood from the ""$\oplus$""-construction of vector spaces. Given the second point I make below, the perspective seems to be a little inconsistent. Firstly, sure, you can't just integrate over these kind of forms in a direct way, but it's still a reasonable vector of the exteriour algebra. Is it that you can, maybe by means of linear algebra, just a priori say that all results you might have about these objects decompose into the direct sum of the seperate results? But moreover, general cohomology theory theory is concerned with different operators $\mathbb{d}_i$ from space to space. In deRham cohomology, which is I think the primary motivation, one doesn't really seperate the different $\mathbb{d}_i$'s going from 1-forms to 2-forms and 2-formsto 3-forms, notationally. And well, in fact even if you formally introduce different $\mathbb{d}_i$'s, you could then just use them to define the action of one big $\mathbb{d}_i$ in the direct sum space, via the action of the small $\mathbb{d}_i$'s. Is it more than a notational decission that, in general cohomolgy theory, you don't just look at a direct sum space?","I wonder why in books about differential geometry there seem to be no relevant results about properties of mixed differential forms like $$\omega_{12}\ \mathbb{d}x^1\land\mathbb{d}x^2+\lambda_{123}\ \mathbb{d}x^1\land\mathbb{d}x^2\land\mathbb{d}x^3,$$ where the ""+"" is understood from the ""$\oplus$""-construction of vector spaces. Given the second point I make below, the perspective seems to be a little inconsistent. Firstly, sure, you can't just integrate over these kind of forms in a direct way, but it's still a reasonable vector of the exteriour algebra. Is it that you can, maybe by means of linear algebra, just a priori say that all results you might have about these objects decompose into the direct sum of the seperate results? But moreover, general cohomology theory theory is concerned with different operators $\mathbb{d}_i$ from space to space. In deRham cohomology, which is I think the primary motivation, one doesn't really seperate the different $\mathbb{d}_i$'s going from 1-forms to 2-forms and 2-formsto 3-forms, notationally. And well, in fact even if you formally introduce different $\mathbb{d}_i$'s, you could then just use them to define the action of one big $\mathbb{d}_i$ in the direct sum space, via the action of the small $\mathbb{d}_i$'s. Is it more than a notational decission that, in general cohomolgy theory, you don't just look at a direct sum space?",,"['differential-geometry', 'homology-cohomology']"
5,Riemann manifold,Riemann manifold,,Let's suppose we have $N$ a compact Riemann manifold and a smooth function f on N. Prove that $\nabla f= 0$ at 2 or more points. I am not very sure that this question is correct because I don't see how the fact that N is Riemannian fits.,Let's suppose we have $N$ a compact Riemann manifold and a smooth function f on N. Prove that $\nabla f= 0$ at 2 or more points. I am not very sure that this question is correct because I don't see how the fact that N is Riemannian fits.,,['differential-geometry']
6,"coordinate system, nonzero vector field","coordinate system, nonzero vector field",,"I'm interested in the following result (chapter 5, theorem 7 in volume 1 of Spivak's Differential Geometry ): Let $X$ be a smooth vector field on an $n$-dimensional manifold M with $X(p)\neq0$ for some point $p\in M$.  Then there exists a coordinate system $x^1,\ldots,x^n$ for $U$ (an open subset of $M$ containing $p$) in which $X=\frac{\partial}{\partial x^1}$. Could someone please explain, in words, how to prove this (or, if you have the book, how Spivak proves this)? I've read Spivak's proof, and have a few questions about it: 1) How is he using the assumption $X(p)\neq0$? 2) Why can we assume $X(0)=\frac{\partial}{\partial t^1}|_0$ (where $t^1,\ldots,t^n$ is the standard coordinate system for $\mathbb{R}^n$ and WLOG $p=0\in\mathbb{R}^n$)? 3) How do we know that in a neighborhood of the origin in $\mathbb{R}^n$, there's a unique integral curve through each point $(0,a^2,\ldots,a^n)$?","I'm interested in the following result (chapter 5, theorem 7 in volume 1 of Spivak's Differential Geometry ): Let $X$ be a smooth vector field on an $n$-dimensional manifold M with $X(p)\neq0$ for some point $p\in M$.  Then there exists a coordinate system $x^1,\ldots,x^n$ for $U$ (an open subset of $M$ containing $p$) in which $X=\frac{\partial}{\partial x^1}$. Could someone please explain, in words, how to prove this (or, if you have the book, how Spivak proves this)? I've read Spivak's proof, and have a few questions about it: 1) How is he using the assumption $X(p)\neq0$? 2) Why can we assume $X(0)=\frac{\partial}{\partial t^1}|_0$ (where $t^1,\ldots,t^n$ is the standard coordinate system for $\mathbb{R}^n$ and WLOG $p=0\in\mathbb{R}^n$)? 3) How do we know that in a neighborhood of the origin in $\mathbb{R}^n$, there's a unique integral curve through each point $(0,a^2,\ldots,a^n)$?",,['differential-geometry']
7,Defining an f-invariant measure,Defining an f-invariant measure,,"Suppose I have a compact oriented manifold $M$ with an orientation preserving self-diffeomorphism $f$. I wish to define a volume form on $M$ which is invariant under $f$. Certainly, it is necessary that for any open $U\subset M$, its image $f(U)$ is not a proper subset of $U$. Is this sufficient? If not, what would be sufficient? A natural thing to try is to start with a volume form on $M$ and then try to even it out by repeatedly averaging the form with its pullback by $f$. However, I don't know how to force convergence.","Suppose I have a compact oriented manifold $M$ with an orientation preserving self-diffeomorphism $f$. I wish to define a volume form on $M$ which is invariant under $f$. Certainly, it is necessary that for any open $U\subset M$, its image $f(U)$ is not a proper subset of $U$. Is this sufficient? If not, what would be sufficient? A natural thing to try is to start with a volume form on $M$ and then try to even it out by repeatedly averaging the form with its pullback by $f$. However, I don't know how to force convergence.",,"['differential-geometry', 'dynamical-systems', 'ergodic-theory']"
8,Is the Empty set an orientable manifold?,Is the Empty set an orientable manifold?,,"The empty set can be regarded as an object in the category of smooth manifolds, at least for technical considerations. Is the empty set an orientable manifold?","The empty set can be regarded as an object in the category of smooth manifolds, at least for technical considerations. Is the empty set an orientable manifold?",,"['differential-geometry', 'differential-topology']"
9,Tangent space to a manifold - First Order Approximation to the Manifold,Tangent space to a manifold - First Order Approximation to the Manifold,,"I've a doubt about the tangent space to a manifold. Let $M$ be a $n$-manifold and let $p\in M$, I've heard that the tangent space $T_pM$ at $p$ is the first order approximation of $M$ near $p$ in the same way that the tangent hyperplane to the graph of a function $f : \mathbb{R}^n \to \mathbb{R}$ is the first order approximation to the graph of $f$. This is really intuitive, but how do I show that ? I mean, I'm using the definition of tangent space with derivations, how do I show that that abstract set associated with each point of the manifold gives the first order approximation to the manifold ? Is this fact already built in into the definition somehow or we should prove it ? If we should prove it, can someone give a hint ? I don't want the full proof, just a hint to begin the proof. Thanks in advance for your aid, and sorry if this question is too trivial.","I've a doubt about the tangent space to a manifold. Let $M$ be a $n$-manifold and let $p\in M$, I've heard that the tangent space $T_pM$ at $p$ is the first order approximation of $M$ near $p$ in the same way that the tangent hyperplane to the graph of a function $f : \mathbb{R}^n \to \mathbb{R}$ is the first order approximation to the graph of $f$. This is really intuitive, but how do I show that ? I mean, I'm using the definition of tangent space with derivations, how do I show that that abstract set associated with each point of the manifold gives the first order approximation to the manifold ? Is this fact already built in into the definition somehow or we should prove it ? If we should prove it, can someone give a hint ? I don't want the full proof, just a hint to begin the proof. Thanks in advance for your aid, and sorry if this question is too trivial.",,"['differential-geometry', 'manifolds']"
10,Check that a curve is a geodesic.,Check that a curve is a geodesic.,,Suppose $M$ is a two-dimensional manifold. Let $\sigma:M \rightarrow M$ be an isometry such that $\sigma^2=1$. Suppose that the fixed point set $\gamma=\{x \in M| \sigma(x)=x\}$ is a connected one-dimensional submanifold of $M$. The question asks to show that $\gamma$ is the image of a geodesic.,Suppose $M$ is a two-dimensional manifold. Let $\sigma:M \rightarrow M$ be an isometry such that $\sigma^2=1$. Suppose that the fixed point set $\gamma=\{x \in M| \sigma(x)=x\}$ is a connected one-dimensional submanifold of $M$. The question asks to show that $\gamma$ is the image of a geodesic.,,['differential-geometry']
11,What is the geodesic equation on $\mathbb{S}^{n}$?,What is the geodesic equation on ?,\mathbb{S}^{n},"Suppose $\gamma: \mathbb{R}\rightarrow \mathbb{S}^{n}$ is a smooth curve. Let $\gamma(t)=(x^{1}(t)...x^{n+1}(t))$. Let $\mathbb{D}^{n}$ be embedded into $\mathbb{R}^{n+1}$ by viewing $\mathbb{R}^{n+1}$ as $\mathbb{R}^{n}\times \mathbb{R}$ and introduce coordinate embedding $$f: y\rightarrow \langle y, (1-|y^{2}|)^{1/2}\rangle$$ of the ball of radius 1 in $\mathbb{R}^{n}$ into $\mathbb{S}^{n}$. The round metric on $T\mathbb{S}^{n}$ identify $$\langle (x,v), (x,w)\rangle=\langle v, w\rangle$$ with $x\in \mathbb{S}^{n},v,w\in T\mathbb{S}_{x}$. Now in order to find a geodesic on $\mathbb{S}^{n}$ I need to find the Christoffel symbols $\Gamma^{i}_{jk}$. And to find Christoffel symbols I need to find the pull-back metric (from $\mathbb{D}^{n}\rightarrow \mathbb{S}^{n}$). Taubes now assert that we have $$g_{ij}=\delta_{ij}+y_{i}y_{j}(1-|y|^{2})^{1/2}$$ I am wondering why this is true. The pull-back metric for map between manifolds $\psi:M\rightarrow N$ and vector bundle $E\rightarrow N$ with a given fibre-wise metric is defined by $\langle (p,v), (p,w)\rangle=v\cdot w,p\in M, v,w\in E$. So in our case we are working with $\mathbb{D}^{n}\rightarrow \mathbb{S}^{n}$, with the bundle $T\mathbb{S}^{n}\rightarrow \mathbb{S}^{n}$ (endowed with round metric) pulled back. By definition of metric we would be expecting $g_{ij}(x)=\langle \partial y_{i},\partial y_{j}\rangle, \partial y_{i},\partial y_{j}\in T\mathbb{S}^{n}_{x}$. Now since $x=(y,(1-y^{2})^{1/2})$, by definition above we can pull it back to $f^{*}T\mathbb{S}^{n}_{x}$. But the evaluation seems to be the same and I could not understand how he get his formula. Since the sphere case is the simplest possible, I feel I need to ask for help. I also thought about differentiating directly. Then we would have $g_{ij}=\delta_{ij}+y_{i}y_{j}(1-|y|^{2})^{-1}$. This still does not match Taube's formula and I do not know what is wrong.","Suppose $\gamma: \mathbb{R}\rightarrow \mathbb{S}^{n}$ is a smooth curve. Let $\gamma(t)=(x^{1}(t)...x^{n+1}(t))$. Let $\mathbb{D}^{n}$ be embedded into $\mathbb{R}^{n+1}$ by viewing $\mathbb{R}^{n+1}$ as $\mathbb{R}^{n}\times \mathbb{R}$ and introduce coordinate embedding $$f: y\rightarrow \langle y, (1-|y^{2}|)^{1/2}\rangle$$ of the ball of radius 1 in $\mathbb{R}^{n}$ into $\mathbb{S}^{n}$. The round metric on $T\mathbb{S}^{n}$ identify $$\langle (x,v), (x,w)\rangle=\langle v, w\rangle$$ with $x\in \mathbb{S}^{n},v,w\in T\mathbb{S}_{x}$. Now in order to find a geodesic on $\mathbb{S}^{n}$ I need to find the Christoffel symbols $\Gamma^{i}_{jk}$. And to find Christoffel symbols I need to find the pull-back metric (from $\mathbb{D}^{n}\rightarrow \mathbb{S}^{n}$). Taubes now assert that we have $$g_{ij}=\delta_{ij}+y_{i}y_{j}(1-|y|^{2})^{1/2}$$ I am wondering why this is true. The pull-back metric for map between manifolds $\psi:M\rightarrow N$ and vector bundle $E\rightarrow N$ with a given fibre-wise metric is defined by $\langle (p,v), (p,w)\rangle=v\cdot w,p\in M, v,w\in E$. So in our case we are working with $\mathbb{D}^{n}\rightarrow \mathbb{S}^{n}$, with the bundle $T\mathbb{S}^{n}\rightarrow \mathbb{S}^{n}$ (endowed with round metric) pulled back. By definition of metric we would be expecting $g_{ij}(x)=\langle \partial y_{i},\partial y_{j}\rangle, \partial y_{i},\partial y_{j}\in T\mathbb{S}^{n}_{x}$. Now since $x=(y,(1-y^{2})^{1/2})$, by definition above we can pull it back to $f^{*}T\mathbb{S}^{n}_{x}$. But the evaluation seems to be the same and I could not understand how he get his formula. Since the sphere case is the simplest possible, I feel I need to ask for help. I also thought about differentiating directly. Then we would have $g_{ij}=\delta_{ij}+y_{i}y_{j}(1-|y|^{2})^{-1}$. This still does not match Taube's formula and I do not know what is wrong.",,['differential-geometry']
12,Symplectic Chart,Symplectic Chart,,"I was reading the article "" Symplectic structures on Banach manifolds "" by Alan Weinstein. In this article there is one theorem, which is as following: If $B$ is a zero neighborhood in Banach space. Let $\Omega$ be a symplectic form on this banach space.  Let $\Omega_1$ be the symplectic structure on $B$ which is constant with respect to the natural parallelism on $B$ and equal to $\Omega$, at $0$ then... I want to understand the meaning of natural parallelism here.","I was reading the article "" Symplectic structures on Banach manifolds "" by Alan Weinstein. In this article there is one theorem, which is as following: If $B$ is a zero neighborhood in Banach space. Let $\Omega$ be a symplectic form on this banach space.  Let $\Omega_1$ be the symplectic structure on $B$ which is constant with respect to the natural parallelism on $B$ and equal to $\Omega$, at $0$ then... I want to understand the meaning of natural parallelism here.",,"['differential-geometry', 'banach-spaces', 'symplectic-geometry']"
13,Moving to a conformal metric,Moving to a conformal metric,,"Given a generic 2-dimensional metric $$    ds^2=E(x,y)dx^2+2F(x,y)dxdy+G(x,y)dy^2 $$ what is the change of coordinates that move it into the conformal form $$    ds^2=e^{\phi(\xi,\zeta)}(d\xi^2+d\zeta^2) $$ being $\xi=\xi(x,y)$ and $\zeta=\zeta(x,y)$? Is it generally known? Also a good reference will fit the bill. Thanks beforehand.","Given a generic 2-dimensional metric $$    ds^2=E(x,y)dx^2+2F(x,y)dxdy+G(x,y)dy^2 $$ what is the change of coordinates that move it into the conformal form $$    ds^2=e^{\phi(\xi,\zeta)}(d\xi^2+d\zeta^2) $$ being $\xi=\xi(x,y)$ and $\zeta=\zeta(x,y)$? Is it generally known? Also a good reference will fit the bill. Thanks beforehand.",,"['reference-request', 'differential-geometry', 'riemannian-geometry', 'conformal-geometry']"
14,The number of geodesics of a complete Riemann manifold with non-positive sectional curvature,The number of geodesics of a complete Riemann manifold with non-positive sectional curvature,,"There is a theorem of Cartan which states that if $M$ is a simply connected, complete Riemann manifold, and that the sectional curvature is everywhere $\leq 0$ , then any two points of M are joined by a unique geodesic. So if we consider a Riemann manifold $M$ which is not simply connected, but is complete and has sectional curvature $\leq 0$ , we could use the above theorem of Cartan to the universal covering space $\widetilde{M}$ of $M$ . It says in the book: For it is clear that $\widetilde{M}$ inherits a Riemannian metric from $M$ which is geodesically complete, and has sectioanl curvature $\leq 0$ . Given two points $p,q \in M$ , it follows that each homotopy class of paths from p to q contains precisely one geodesic. My question is: How does the second sectence deduced from the sentence above? I know that any two points of $\widetilde{M}$ are joined by only one geodesic, but for any two points $p,q \in M$ , there are many lifted points of $p,q$ in $\widetilde{M}$ . Thank you!","There is a theorem of Cartan which states that if is a simply connected, complete Riemann manifold, and that the sectional curvature is everywhere , then any two points of M are joined by a unique geodesic. So if we consider a Riemann manifold which is not simply connected, but is complete and has sectional curvature , we could use the above theorem of Cartan to the universal covering space of . It says in the book: For it is clear that inherits a Riemannian metric from which is geodesically complete, and has sectioanl curvature . Given two points , it follows that each homotopy class of paths from p to q contains precisely one geodesic. My question is: How does the second sectence deduced from the sentence above? I know that any two points of are joined by only one geodesic, but for any two points , there are many lifted points of in . Thank you!","M \leq 0 M \leq 0 \widetilde{M} M \widetilde{M} M \leq 0 p,q \in M \widetilde{M} p,q \in M p,q \widetilde{M}","['differential-geometry', 'riemannian-geometry']"
15,"How to show that ""spheres"" are diffeomorphic?","How to show that ""spheres"" are diffeomorphic?",,"Can anyone provide a diffeomorphism between these ""spheres"": $\mathbb{S}^2$ and $\{(x,y,z)\in \mathbb{R}^3: x^4+y^2+z^2=1\}$? PS: If you know a result that can solve this problem, I would be glad to know.","Can anyone provide a diffeomorphism between these ""spheres"": $\mathbb{S}^2$ and $\{(x,y,z)\in \mathbb{R}^3: x^4+y^2+z^2=1\}$? PS: If you know a result that can solve this problem, I would be glad to know.",,"['differential-geometry', 'manifolds']"
16,An Exercise in Peter Petersen,An Exercise in Peter Petersen,,"My question is an exercise in Peter Petersen ""Riemannian Geometry"" Chapter 5 #10 Let $N \subset M$ be a submanifold of Riemannian manifold $(M,g)$. (a) The distance from N to $x \in M$ is defined as $d(x,N) = \inf\{ d(x,y)\  |\ p \in N\}$.     A unit speed curve $\sigma : [a,b] \to M$ with $\sigma(a) \in N,\sigma(a)$ and $l(\sigma) = d(x,N)$ is called a segment from $x$ to $N$. Show that $\sigma$ is also a segment from $N$ to any $\sigma(t),t<b$. Show that $\sigma'(a)$ is perpendicular to $N$. (b) Show that if $N$ is a closed subspace of $M$ and $(M,g)$ is complete, then any point in $M$ can be joined to $N$ by segments. (d) Show that $d(\dot \ ,N)$ is smooth on a neighborhood of $N$ and that the integral curves for its gradient are the geodesics that perpendicular to $N$. Please give me a answer as complete as possible,. Thank you very much!","My question is an exercise in Peter Petersen ""Riemannian Geometry"" Chapter 5 #10 Let $N \subset M$ be a submanifold of Riemannian manifold $(M,g)$. (a) The distance from N to $x \in M$ is defined as $d(x,N) = \inf\{ d(x,y)\  |\ p \in N\}$.     A unit speed curve $\sigma : [a,b] \to M$ with $\sigma(a) \in N,\sigma(a)$ and $l(\sigma) = d(x,N)$ is called a segment from $x$ to $N$. Show that $\sigma$ is also a segment from $N$ to any $\sigma(t),t<b$. Show that $\sigma'(a)$ is perpendicular to $N$. (b) Show that if $N$ is a closed subspace of $M$ and $(M,g)$ is complete, then any point in $M$ can be joined to $N$ by segments. (d) Show that $d(\dot \ ,N)$ is smooth on a neighborhood of $N$ and that the integral curves for its gradient are the geodesics that perpendicular to $N$. Please give me a answer as complete as possible,. Thank you very much!",,"['differential-geometry', 'riemannian-geometry']"
17,Second variational formula for lengh of geodesic and Frankel's Theorem,Second variational formula for lengh of geodesic and Frankel's Theorem,,"In Frankel's paper: ""Manifolds with positive curvature"", he proved the following theorem: If $M^n$ is complete Riemannian manifold with positive sectional curvature, and $V^r$, $W^s$ are two compact totally geodesic submanifolds. If $r+s\ge n$ then $V$ and $W$ have a non-empty intersection. The proof is by contradiction. If there is no intersection, then chose $\gamma$ connecting $V$ to $W$ and realized the distance between $V$ and $W$. Due to the dimension reason, he find a parallel vector fileld $X$ along $\gamma$, then apply the second variational formula. For the boundary term $g(\nabla_X X, \dot{\gamma})$. He claimed this is zero due to the totally geodesic property. My question is: In order to take covariant derivative $\nabla_v Y$, the vector field $Y$ has to be defined at least along one curve $\sigma$ with $\dot{\sigma}=v$, right? But for $\nabla_X X$ in the proof, the vector filed $X$ is only defined along $\gamma$ not along the tangent direction $X$. (My guess is it does not depend on the extension of $X$, but I can't see why, or it's too trivial so Frankel didn't write it down?) edit: I found that probably, we can just extend $X$ at $\gamma(0)$ and $\gamma(\ell)$ as the tengent vector of geodesic along direction $X$, and extend $X$ at $\gamma(t)$ arbitrary. So this will give the desired boundary condition. Is my claim correct?","In Frankel's paper: ""Manifolds with positive curvature"", he proved the following theorem: If $M^n$ is complete Riemannian manifold with positive sectional curvature, and $V^r$, $W^s$ are two compact totally geodesic submanifolds. If $r+s\ge n$ then $V$ and $W$ have a non-empty intersection. The proof is by contradiction. If there is no intersection, then chose $\gamma$ connecting $V$ to $W$ and realized the distance between $V$ and $W$. Due to the dimension reason, he find a parallel vector fileld $X$ along $\gamma$, then apply the second variational formula. For the boundary term $g(\nabla_X X, \dot{\gamma})$. He claimed this is zero due to the totally geodesic property. My question is: In order to take covariant derivative $\nabla_v Y$, the vector field $Y$ has to be defined at least along one curve $\sigma$ with $\dot{\sigma}=v$, right? But for $\nabla_X X$ in the proof, the vector filed $X$ is only defined along $\gamma$ not along the tangent direction $X$. (My guess is it does not depend on the extension of $X$, but I can't see why, or it's too trivial so Frankel didn't write it down?) edit: I found that probably, we can just extend $X$ at $\gamma(0)$ and $\gamma(\ell)$ as the tengent vector of geodesic along direction $X$, and extend $X$ at $\gamma(t)$ arbitrary. So this will give the desired boundary condition. Is my claim correct?",,"['differential-geometry', 'riemannian-geometry']"
18,Orientability of the sphere,Orientability of the sphere,,"how does one explain the following: ""The sphere can be covered by 2 open sets using stereographic projection in such a way that the intersection of these 2 sets is a connected set $W$.Let $p \in W$, if the jacobian of transitions maps is negative then intechange the parameters, so the jacobian will be positive.Since $W$ is connected, the jacobian is positive for every $p \in W$ "" thanks.","how does one explain the following: ""The sphere can be covered by 2 open sets using stereographic projection in such a way that the intersection of these 2 sets is a connected set $W$.Let $p \in W$, if the jacobian of transitions maps is negative then intechange the parameters, so the jacobian will be positive.Since $W$ is connected, the jacobian is positive for every $p \in W$ "" thanks.",,['differential-geometry']
19,When a ruled surface can be regular,When a ruled surface can be regular,,"I know that a ruled surface is a surface with parametrization $x(u,v)$ = $c(u)$ + $vf(u)$  where if $I$ $\subset$ $R$ is an interval, $c$: $I$ $\mapsto$ $R^3$ and $f$ : $I$ $\mapsto$ $R^3$ are smooth curves with $f$ $\neq$ $0$ on $I$. The curve $c$ is called the directrix and the $f(u)$ are called the rulings. If I'm not mistaken, is a ruled surface regular at a point $p$ = $x(u,v)$ provided that $f(u)$ $\bigwedge$ $c'(u)$ = $vf(u)$ $\bigwedge$ $f'(u)$ and $x_u$ $\bigwedge$ $x_v$ $\neq$ $0$? I actually think that only the second condition is really required, or are both of them required? Are the two conditions equivalent, and is there any other extra requirement? I'd really appreciate some input on this, thanks.","I know that a ruled surface is a surface with parametrization $x(u,v)$ = $c(u)$ + $vf(u)$  where if $I$ $\subset$ $R$ is an interval, $c$: $I$ $\mapsto$ $R^3$ and $f$ : $I$ $\mapsto$ $R^3$ are smooth curves with $f$ $\neq$ $0$ on $I$. The curve $c$ is called the directrix and the $f(u)$ are called the rulings. If I'm not mistaken, is a ruled surface regular at a point $p$ = $x(u,v)$ provided that $f(u)$ $\bigwedge$ $c'(u)$ = $vf(u)$ $\bigwedge$ $f'(u)$ and $x_u$ $\bigwedge$ $x_v$ $\neq$ $0$? I actually think that only the second condition is really required, or are both of them required? Are the two conditions equivalent, and is there any other extra requirement? I'd really appreciate some input on this, thanks.",,"['differential-geometry', 'surfaces']"
20,The inclusion map from a manifold to a product manifold is $C^{\infty}$,The inclusion map from a manifold to a product manifold is,C^{\infty},"Let $i_{q0} : M\rightarrow M\times N$, $i_{q0}(p) = (p, q0)$ be a mapping between smooth manifolds.  I need some hints to show that it is $C^{\infty}$. I have so far... Let $(U,\phi)$ and $(V,\psi)$ be charts about $p$ and $i_{q0}$, and let $r^{i}$ be the $ith$ coordinate function on Euclidean space.  Then we need to show that  $\frac{\partial (r^{i}\circ \psi \circ i_{q0} \circ \phi^{-1})}{\partial r^{j}}$ exists and is continuous at $\phi(p)$ and that we can keep taking partial derivatives.","Let $i_{q0} : M\rightarrow M\times N$, $i_{q0}(p) = (p, q0)$ be a mapping between smooth manifolds.  I need some hints to show that it is $C^{\infty}$. I have so far... Let $(U,\phi)$ and $(V,\psi)$ be charts about $p$ and $i_{q0}$, and let $r^{i}$ be the $ith$ coordinate function on Euclidean space.  Then we need to show that  $\frac{\partial (r^{i}\circ \psi \circ i_{q0} \circ \phi^{-1})}{\partial r^{j}}$ exists and is continuous at $\phi(p)$ and that we can keep taking partial derivatives.",,"['differential-geometry', 'manifolds']"
21,Maurer-Cartan 1- form as a connection 1-form,Maurer-Cartan 1- form as a connection 1-form,,"I'm trying to decipher a differential geometric comment on page 23-24 of Berline, Getzler, and Vergne's ""Heat Kernels and Dirac Operators"". Take a trivial vector bundle $E \times M$ in a manifold $M$ with connection $\nabla = d + \omega$ where $\omega$ is an $End(E)$-valued 1 form.  Let $g: GL(E) \to End(E)$ be the tautological map sending a linear map in $GL(E)$ to itself as an element of $End(E)$.  The claim is that the connection 1-form on the (trivial) frame bundle for $E \times M$ is given by $g^{-1} \pi^* \omega g + g^{-1} d g$.  In particular, if $\omega = 0$ then we get that the trivial connection on the trivial bundle is the Maurer-Cartan 1-form.  Unfortunately, I don't see how to give a convincing proof of this - can someone help?","I'm trying to decipher a differential geometric comment on page 23-24 of Berline, Getzler, and Vergne's ""Heat Kernels and Dirac Operators"". Take a trivial vector bundle $E \times M$ in a manifold $M$ with connection $\nabla = d + \omega$ where $\omega$ is an $End(E)$-valued 1 form.  Let $g: GL(E) \to End(E)$ be the tautological map sending a linear map in $GL(E)$ to itself as an element of $End(E)$.  The claim is that the connection 1-form on the (trivial) frame bundle for $E \times M$ is given by $g^{-1} \pi^* \omega g + g^{-1} d g$.  In particular, if $\omega = 0$ then we get that the trivial connection on the trivial bundle is the Maurer-Cartan 1-form.  Unfortunately, I don't see how to give a convincing proof of this - can someone help?",,['differential-geometry']
22,What is the name of the matrix used to weight an inner product?,What is the name of the matrix used to weight an inner product?,,"In Linear Algebra, when computing an inner product $<x,y> = y^*Wx$, what is the name of the matrix W? If it doesn't have a name, where can I find a practical explanation of how to construct it for a particular problem or space? Is there a text on the subject that explains this simply? A note on my background, I am approaching this from the perspective of an engineering student and not that of a mathematician; I don't have an understanding of the finer points of topology or differential geometry (not yet at least :) ). I believe that this is the same matrix used in vector calculus to perform a change of variables. As in, we perform our change of variables, then multiply the new expression by $\frac{det(J(W))}{det(J(V))}$ where $W$ is this magic matrix in the new space, $V$ is this magic matrix the old space, and J(X) is the Jacobian operator.  Am I correct? Also, is this related to one of the the matrices that comes up in Singular Value Decomposition (namely the diagonal matrix containing the singular values)?","In Linear Algebra, when computing an inner product $<x,y> = y^*Wx$, what is the name of the matrix W? If it doesn't have a name, where can I find a practical explanation of how to construct it for a particular problem or space? Is there a text on the subject that explains this simply? A note on my background, I am approaching this from the perspective of an engineering student and not that of a mathematician; I don't have an understanding of the finer points of topology or differential geometry (not yet at least :) ). I believe that this is the same matrix used in vector calculus to perform a change of variables. As in, we perform our change of variables, then multiply the new expression by $\frac{det(J(W))}{det(J(V))}$ where $W$ is this magic matrix in the new space, $V$ is this magic matrix the old space, and J(X) is the Jacobian operator.  Am I correct? Also, is this related to one of the the matrices that comes up in Singular Value Decomposition (namely the diagonal matrix containing the singular values)?",,"['linear-algebra', 'differential-geometry', 'terminology', 'inner-products']"
23,How to compute curvature tensors for general n-dimensions?,How to compute curvature tensors for general n-dimensions?,,"I keep coming across calculations like this, Consider a metric on an $n+2$ dimensional manifold given as, $ds^2 = 2dudr + 2L(u,r)du^2 -r^2d\Omega_n^2$ Then apparently once can write down the Ricci and Einstein and other tensors as a function of n. Like for the above the Einstein tensor apparently has the following non-zero components, $G_{01} = \frac{n}{r}L_r+\frac{n(n-1)(2L-1)}{2r^2}$ $G_{22} = (n-1)[(2L-1)(\frac{2-n}{2})-2rL_r]-r^2L_{rr}$ $G_{00} = -\frac{nL_u}{r} + \frac{2nLL_r}{r} + \frac{n(n-1)L(2L-1)}{r^2}$ and $G^2_2 = G^3_3 = ... = G^{n+1}_{n+1}$ (where the subscripts of L denote partial derivatives with respect to those variables) For a fixed given n I can imagine doing the calculation either by hand or some software but I would like to know who these expressions are derived for a general n.","I keep coming across calculations like this, Consider a metric on an $n+2$ dimensional manifold given as, $ds^2 = 2dudr + 2L(u,r)du^2 -r^2d\Omega_n^2$ Then apparently once can write down the Ricci and Einstein and other tensors as a function of n. Like for the above the Einstein tensor apparently has the following non-zero components, $G_{01} = \frac{n}{r}L_r+\frac{n(n-1)(2L-1)}{2r^2}$ $G_{22} = (n-1)[(2L-1)(\frac{2-n}{2})-2rL_r]-r^2L_{rr}$ $G_{00} = -\frac{nL_u}{r} + \frac{2nLL_r}{r} + \frac{n(n-1)L(2L-1)}{r^2}$ and $G^2_2 = G^3_3 = ... = G^{n+1}_{n+1}$ (where the subscripts of L denote partial derivatives with respect to those variables) For a fixed given n I can imagine doing the calculation either by hand or some software but I would like to know who these expressions are derived for a general n.",,['differential-geometry']
24,Definition of Ricci flow,Definition of Ricci flow,,"My undergraduate thesis is related to the Ricci flow, and I have a number of basic questions. Let $M$ be a smooth manifold. At the start of Chapter 2.3 of Peter Topping's Lectures on the Ricci flow , he supposes that $g$ is a smooth family of Riemannian metrics on $M$ defined on an open interval. Question 1. Does Peter mean that $g$ is a map of the form $g:I \times M \rightarrow T^{(0,2)}TM$ , where $I\subseteq \mathbb R$ is an open interval? Does smoothness here mean that $g$ is smooth as a map between the smooth manifolds $I \times M$ and $T^{(0,2)}TM$ ? I'm trying to write the definition of the Ricci flow in my own words. This is what I have: Let $I$ be an open interval, and let $g:I \times M \rightarrow T^{(0,2)}TM$ be a smooth (in the sense of Question 1) family of metrics. For each $p \in M$ , we have a smooth curve $g(\cdot,p):I \rightarrow T^{(0,2)}T_p M$ given by $t \mapsto g(t,p)$ . For each $t \in I$ , define $(\partial_t g)(t,p) := g(\cdot,p)'(t)$ . Since $T^{(0,2)}T_p M$ is a vector space, we can view $g(\cdot,p)'(t)$ as an element of $T^{(0,2)}T_p M$ . We say that $g$ is a solution to the Ricci flow if $$(\partial_t g)(t,p) = -2 \text{Ric}(g(t,p)) \qquad \forall (t,p) \in I \times M.$$ Question 2. Is my definition correct? Does the solution of the Ricci flow need to be smooth in the sense of Question 1? Theorem A.15 of The Ricci Flow: Techniques and Applications Part I states the following: Theorem 1. If $(M,g_0)$ is a closed Riemannian manifold, then there exists a unique solution $g(t)$ to the Ricci flow defined on some positive time interval $[0, \varepsilon)$ such that $g (0) = g_0$ . Question 3. In the theorem above, what does it mean for the solution $g:[0,\varepsilon) \times M \rightarrow T^{(0,2)}TM$ to be smooth? Does it mean that $g$ is smooth as a map between smooth manifolds, where $[0,\varepsilon) \times M$ is considered as a manifold with boundary? Or does it mean that $g$ is continuous, and smooth on $(0,\varepsilon) \times M$ ? Or does it mean something else? On the other hand, the wikipedia page on the Ricci flow states that Hamilton proved the following theorem: Theorem 2. If $(M,g_0)$ is a closed Riemannian manifold, then there exists a positive number $T$ and a Ricci flow $g_t$ parameterised by $t \in (0,T)$ such that $g_t$ converges to $g_0$ in the $C^\infty$ topology as $t \rightarrow 0$ . Question 4. What is the relationship between Theorem 1 and Theorem 2? Does one follow from the other? I tried looking at the original paper by Hamilton , but I wasn't able to understand it.","My undergraduate thesis is related to the Ricci flow, and I have a number of basic questions. Let be a smooth manifold. At the start of Chapter 2.3 of Peter Topping's Lectures on the Ricci flow , he supposes that is a smooth family of Riemannian metrics on defined on an open interval. Question 1. Does Peter mean that is a map of the form , where is an open interval? Does smoothness here mean that is smooth as a map between the smooth manifolds and ? I'm trying to write the definition of the Ricci flow in my own words. This is what I have: Let be an open interval, and let be a smooth (in the sense of Question 1) family of metrics. For each , we have a smooth curve given by . For each , define . Since is a vector space, we can view as an element of . We say that is a solution to the Ricci flow if Question 2. Is my definition correct? Does the solution of the Ricci flow need to be smooth in the sense of Question 1? Theorem A.15 of The Ricci Flow: Techniques and Applications Part I states the following: Theorem 1. If is a closed Riemannian manifold, then there exists a unique solution to the Ricci flow defined on some positive time interval such that . Question 3. In the theorem above, what does it mean for the solution to be smooth? Does it mean that is smooth as a map between smooth manifolds, where is considered as a manifold with boundary? Or does it mean that is continuous, and smooth on ? Or does it mean something else? On the other hand, the wikipedia page on the Ricci flow states that Hamilton proved the following theorem: Theorem 2. If is a closed Riemannian manifold, then there exists a positive number and a Ricci flow parameterised by such that converges to in the topology as . Question 4. What is the relationship between Theorem 1 and Theorem 2? Does one follow from the other? I tried looking at the original paper by Hamilton , but I wasn't able to understand it.","M g M g g:I \times M \rightarrow T^{(0,2)}TM I\subseteq \mathbb R g I \times M T^{(0,2)}TM I g:I \times M \rightarrow T^{(0,2)}TM p \in M g(\cdot,p):I \rightarrow T^{(0,2)}T_p M t \mapsto g(t,p) t \in I (\partial_t g)(t,p) := g(\cdot,p)'(t) T^{(0,2)}T_p M g(\cdot,p)'(t) T^{(0,2)}T_p M g (\partial_t g)(t,p) = -2 \text{Ric}(g(t,p)) \qquad \forall (t,p) \in I \times M. (M,g_0) g(t) [0, \varepsilon) g (0) = g_0 g:[0,\varepsilon) \times M \rightarrow T^{(0,2)}TM g [0,\varepsilon) \times M g (0,\varepsilon) \times M (M,g_0) T g_t t \in (0,T) g_t g_0 C^\infty t \rightarrow 0","['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'ricci-flow']"
25,Does anybody know this integral expression?,Does anybody know this integral expression?,,"This question was migrated from Physics Stack Exchange because it can be answered on Mathematics Stack Exchange. Migrated last month . I stumbled upon the following integral, which is a low dimensional case of a minimization problem I currently investigate. $$F(V) = \int_{\mathbb{R}^3}|W+\nabla\times V)|^2+|\nabla\times(W+\nabla\times V))|^2dx$$ where $W$ is a fixed vector field that is divergence free and $V$ is another vector field, both compactly supported on $\mathbb{R}^3$ or periodic in all components in which case we would just integrate over the smallest period rectangle (I do not know if there is a term describing what I mean here, but it should be clear). Of course by Poincares lemma one has that in the non-periodic case a minimizer $V$ is the negative vector potential of $W$ , since then $F(V)=0$ . It would be really helpful, if somebody could give an interpretation of this integral or point to some physical object this integral corresponds to.","This question was migrated from Physics Stack Exchange because it can be answered on Mathematics Stack Exchange. Migrated last month . I stumbled upon the following integral, which is a low dimensional case of a minimization problem I currently investigate. where is a fixed vector field that is divergence free and is another vector field, both compactly supported on or periodic in all components in which case we would just integrate over the smallest period rectangle (I do not know if there is a term describing what I mean here, but it should be clear). Of course by Poincares lemma one has that in the non-periodic case a minimizer is the negative vector potential of , since then . It would be really helpful, if somebody could give an interpretation of this integral or point to some physical object this integral corresponds to.",F(V) = \int_{\mathbb{R}^3}|W+\nabla\times V)|^2+|\nabla\times(W+\nabla\times V))|^2dx W V \mathbb{R}^3 V W F(V)=0,"['differential-geometry', 'field-theory', 'vector-fields']"
26,Clarification on Sign in Mean Curvatures of Parallel Surfaces,Clarification on Sign in Mean Curvatures of Parallel Surfaces,,"For my Differential Geometry class, I've encountered an issue with a problem from do Carmo. Although I'm aware that similar questions have been previously addressed, my issue differs. I understand how to solve the problem but am encountering a specific challenge. Firstly, let me outline the problem: Let $\mathbf{x} = \mathbf{x}(u,v)$ be a regular parametrized surface. A parallel surface to $\mathbf{x}$ is a parametrized surface $$\overline{\mathbf{y}}(u,v) = \mathbf{x}(u,v) + a \mathbf{N}(u,v),$$ where $a$ is a real constant and $\mathbf{N}$ denotes the unit normal to $\mathbf{x}$ . (b) Show that the Gaussian and mean curvatures $\overline{K}$ and $\overline{H}$ of $\mathbf{y}$ are respectively given by $$\overline{K} = \frac{K}{1 - 2Ha + Ka^2},$$ and $$\overline{H} = \frac{H - Ka}{1 - 2Ha + Ka^2}.$$ From question (a), we derived: $$\overline{\mathbf{y}}_u \times \overline{\mathbf{y}}_v = (1 - 2 H a + K a^2) (\mathbf{x}_u \times \mathbf{x}_v).$$ This implies that the unit normal $\overline{\mathbf{N}}$ to $\overline{\mathbf{y}}$ is given by $$\overline{\mathbf{N}} = \frac{\overline{\mathbf{y}}_u \times \overline{\mathbf{y}}_v}{||\overline{\mathbf{y}}_u \times \overline{\mathbf{y}}_v||} = \frac{1 - 2 H a + K a^2}{|1 - 2 H a + K a^2|} \frac{\mathbf{x}_u \times \mathbf{x}_v}{||\mathbf{x}_u \times \mathbf{x}_v||} = \text{sgn}(1 - 2 H a + K a^2) \mathbf{N}.$$ Thus, $\overline{\mathbf{N}}$ and $\mathbf{N}$ are parallel as expected. However, the term $\text{sgn}(1 - 2 H a + K a^2)$ suggests they may not always point in the same direction. My confusion arises from this sign, as other solutions I've reviewed do not include the sign function, which doesn't make sense to me. When I account for this term throughout my proof, I arrive at the given formula for $\overline{K}$ , which makes sense since Gaussian curvature is independent of orientation. However, for the mean curvature $\overline{H}$ , I derive: $$\overline{H} = \text{sgn}(1 - 2 H a + K a^2) \frac{H - Ka}{1 - 2Ha + Ka^2} = \frac{H - Ka}{|1 - 2Ha + Ka^2|}.$$ I am wondering if I've made an error in my reasoning. Note that in class we are using the convention where the ordering of the pair $(u,v)$ matters in defining the normal unit vector. If I don't use this convention, I can get the right result by choosing the orientation that suits me, but it will depend on $u$ and $v$ , which would be a bit like cheating.","For my Differential Geometry class, I've encountered an issue with a problem from do Carmo. Although I'm aware that similar questions have been previously addressed, my issue differs. I understand how to solve the problem but am encountering a specific challenge. Firstly, let me outline the problem: Let be a regular parametrized surface. A parallel surface to is a parametrized surface where is a real constant and denotes the unit normal to . (b) Show that the Gaussian and mean curvatures and of are respectively given by and From question (a), we derived: This implies that the unit normal to is given by Thus, and are parallel as expected. However, the term suggests they may not always point in the same direction. My confusion arises from this sign, as other solutions I've reviewed do not include the sign function, which doesn't make sense to me. When I account for this term throughout my proof, I arrive at the given formula for , which makes sense since Gaussian curvature is independent of orientation. However, for the mean curvature , I derive: I am wondering if I've made an error in my reasoning. Note that in class we are using the convention where the ordering of the pair matters in defining the normal unit vector. If I don't use this convention, I can get the right result by choosing the orientation that suits me, but it will depend on and , which would be a bit like cheating.","\mathbf{x} = \mathbf{x}(u,v) \mathbf{x} \overline{\mathbf{y}}(u,v) = \mathbf{x}(u,v) + a \mathbf{N}(u,v), a \mathbf{N} \mathbf{x} \overline{K} \overline{H} \mathbf{y} \overline{K} = \frac{K}{1 - 2Ha + Ka^2}, \overline{H} = \frac{H - Ka}{1 - 2Ha + Ka^2}. \overline{\mathbf{y}}_u \times \overline{\mathbf{y}}_v = (1 - 2 H a + K a^2) (\mathbf{x}_u \times \mathbf{x}_v). \overline{\mathbf{N}} \overline{\mathbf{y}} \overline{\mathbf{N}} = \frac{\overline{\mathbf{y}}_u \times \overline{\mathbf{y}}_v}{||\overline{\mathbf{y}}_u \times \overline{\mathbf{y}}_v||} = \frac{1 - 2 H a + K a^2}{|1 - 2 H a + K a^2|} \frac{\mathbf{x}_u \times \mathbf{x}_v}{||\mathbf{x}_u \times \mathbf{x}_v||} = \text{sgn}(1 - 2 H a + K a^2) \mathbf{N}. \overline{\mathbf{N}} \mathbf{N} \text{sgn}(1 - 2 H a + K a^2) \overline{K} \overline{H} \overline{H} = \text{sgn}(1 - 2 H a + K a^2) \frac{H - Ka}{1 - 2Ha + Ka^2} = \frac{H - Ka}{|1 - 2Ha + Ka^2|}. (u,v) u v","['differential-geometry', 'surfaces', 'curvature']"
27,What is the volume of the largest surface of revolution with constant Gaussian curvature that can be placed inside the unit cube?,What is the volume of the largest surface of revolution with constant Gaussian curvature that can be placed inside the unit cube?,,"Consider a surface of revolution $S$ and an embedding $e:S \hookrightarrow X^3$ for $X^3=[0,1]^3$ with points $p,q$ elements of $\partial X^3$ where $\partial X^3=X^3-(0,1)^3$ for $\mathrm {sup}~ \mathrm{dist}(p,q)=\sqrt{3}$ . What is $\rho_{\mathrm{max}}=\mathrm{max} \lbrace \mathrm{vol}(S) \rbrace_{p,q}$ assuming $S$ must remain a surface of revolution and have constant positive Gaussian curvature? In other words, what is the volume of the largest surface of revolution with constant Gaussian curvature that can be embedded in $X^3$ with a pair of antipodal corners as cone points?","Consider a surface of revolution and an embedding for with points elements of where for . What is assuming must remain a surface of revolution and have constant positive Gaussian curvature? In other words, what is the volume of the largest surface of revolution with constant Gaussian curvature that can be embedded in with a pair of antipodal corners as cone points?","S e:S \hookrightarrow X^3 X^3=[0,1]^3 p,q \partial X^3 \partial X^3=X^3-(0,1)^3 \mathrm {sup}~ \mathrm{dist}(p,q)=\sqrt{3} \rho_{\mathrm{max}}=\mathrm{max} \lbrace \mathrm{vol}(S) \rbrace_{p,q} S X^3","['differential-geometry', 'optimization', 'riemannian-geometry', 'differential-topology', 'geometric-topology']"
28,Vertical bundle and tangent bundle of the fiber,Vertical bundle and tangent bundle of the fiber,,"For a fiber bundle $\pi: E\rightarrow B$ with typical fiber a manifold $F$ , we define the vertical subbundle $V$ by the exact sequence of verctor bundles over $E$ : $$0\rightarrow V\rightarrow TE \rightarrow \pi^*TB\rightarrow0.$$ In the case when $F$ has a Lie group structure and $E$ is a principal bundle, we know that $V$ is the trivial bundle with fiber $T_eF$ , the Lie algebra of $F$ . In general, can we say anything about $V$ and $TF$ ?","For a fiber bundle with typical fiber a manifold , we define the vertical subbundle by the exact sequence of verctor bundles over : In the case when has a Lie group structure and is a principal bundle, we know that is the trivial bundle with fiber , the Lie algebra of . In general, can we say anything about and ?",\pi: E\rightarrow B F V E 0\rightarrow V\rightarrow TE \rightarrow \pi^*TB\rightarrow0. F E V T_eF F V TF,"['differential-geometry', 'manifolds', 'differential-topology', 'vector-bundles', 'fiber-bundles']"
29,Pullback of $2$-sphere volume form via Gauss map,Pullback of -sphere volume form via Gauss map,2,"This is problem 17.3 from Tu's Differential Geometry text. This post appears to answer my question, but I don't follow many of the explanations, including the construction and usage of $det$ . Problem Let $M$ be a smooth, compact, oriented surface in $\mathbb{R^3}$ with $K$ the Gaussian curvature on $M$ . If $v : M \to S^2 $ is the Gauss map, prove that $$ v^* (vol_{S^2}) = K vol_M $$ Corrected Proof Lemma 1 . If $N$ is an $n$ -dimensional smooth, oriented manifold, $(U, x^1, \ldots, x^n)$ a chart a $p \in N$ with onb $\{e_1, \ldots e_n \} =: e $ , then $$ vol_N = det_e $$ Proof . If $\theta^1, \ldots \theta^n$ is dual to $e_1, \ldots e_n$ , then for any $X_1, \ldots X_n$ in $T_p N$ with $X_j = \sum a^i_j e^i$ \begin{align} vol_N (X_1, \ldots X_n) &= \theta^n \wedge \cdots \wedge \theta^n (X_1, \ldots X_n) \\ &= \sum_{\sigma \in S_n} sgn(\sigma) a^i_{\sigma(1)} \cdots a^i_{\sigma(n)} \\ &= det_e [ a^i_j ] \end{align} $\square$ Lemma 2 . There exists $\{ e_1, e_2 \} =: e$ principal vectors at $p$ in $M$ such that $e$ is an onb for $M$ , and $ \{ \kappa_1 e_1, \kappa_2 e_2 \} = \{ dv_p(e_1), dv_p(e_2) \} =: e'$ is an orthogonal basis for $S^2$ . We will use these facts: $dv_p = -L$ (the shape operator at $p$ ) (Problem 5.3), the $L$ has the principal vectors as eigenvectors and principal curvatures as eigenvalues (Prop 5.6), and $L$ is self-adjoint. Note that if $\kappa_1 = \kappa_2$ , all vectors in $T_p M$ are principal, so we can freely choose an onb. So assume they're unequal. Then \begin{align} \kappa_1^2 \langle e_1, e_2 \rangle &= \langle -L (e_1), -L (e_2) \rangle \\ &=  \langle dv_p (e_1), dv_p (e_2) \rangle \\ &= \kappa_2^2 \langle e_1, e_2 \rangle \end{align} Because the principal curvatures are not equal, we must have $$\langle e_1, e_2 \rangle = 0 = \langle dv_p (e_1), dv_p (e_2) \rangle = \langle \kappa_1 e_1, \kappa_2 e_2 \rangle.$$ $\square$ Note that Lemma 2 implies that $e$ is an onb for both $T_p M$ and $T_p S^2$ . Now if $K(p) = det(J_v(p)) = 0$ then the claim obviously holds because $v^* vol_{S^2} = 0 = K(p) vol_M$ . So assume $K(p) = det(J_V(p)) \neq 0$ . Applying Lemma 2, Choose onb $e$ for $M$ (which is also onb for $S^2$ ). Let $\Theta^1 \wedge \Theta^2$ be the volume form for $S^2$ (with $\Theta^i$ dual to $e_i$ ). Then for any $X_1, X_2$ vectors in $S^2$ with $X_j = \sum x^{i}_j e_i$ . \begin{align} v^* (vol_{S^2})(X_1, X_2) &= \Theta^1 \wedge \Theta^2 (dv_p X_1, dv_p X_2) \\ &= \Theta^1(dv_p X_1) \Theta^2(dv_p X_2) - \Theta^1(dv_p X_2) \Theta^2(dv_p X_1) \\ \text{(Lemma 2)} &= (\kappa_1 x^1_1) (\kappa_2 x^2_2) - (\kappa_1 x^1_2) (\kappa_2 x^2_1) \\ &= K det_e(X_1, X_2) \\ \text{(Lemma 1)} &= K vol_M \end{align} $\square$ Update Special thanks to @cbishop for providing the key insight (Prop 8.2.1) that helped me solve the problem!","This is problem 17.3 from Tu's Differential Geometry text. This post appears to answer my question, but I don't follow many of the explanations, including the construction and usage of . Problem Let be a smooth, compact, oriented surface in with the Gaussian curvature on . If is the Gauss map, prove that Corrected Proof Lemma 1 . If is an -dimensional smooth, oriented manifold, a chart a with onb , then Proof . If is dual to , then for any in with Lemma 2 . There exists principal vectors at in such that is an onb for , and is an orthogonal basis for . We will use these facts: (the shape operator at ) (Problem 5.3), the has the principal vectors as eigenvectors and principal curvatures as eigenvalues (Prop 5.6), and is self-adjoint. Note that if , all vectors in are principal, so we can freely choose an onb. So assume they're unequal. Then Because the principal curvatures are not equal, we must have Note that Lemma 2 implies that is an onb for both and . Now if then the claim obviously holds because . So assume . Applying Lemma 2, Choose onb for (which is also onb for ). Let be the volume form for (with dual to ). Then for any vectors in with . Update Special thanks to @cbishop for providing the key insight (Prop 8.2.1) that helped me solve the problem!","det M \mathbb{R^3} K M v : M \to S^2   v^* (vol_{S^2}) = K vol_M  N n (U, x^1, \ldots, x^n) p \in N \{e_1, \ldots e_n \} =: e   vol_N = det_e  \theta^1, \ldots \theta^n e_1, \ldots e_n X_1, \ldots X_n T_p N X_j = \sum a^i_j e^i \begin{align}
vol_N (X_1, \ldots X_n) &= \theta^n \wedge \cdots \wedge \theta^n (X_1, \ldots X_n) \\
&= \sum_{\sigma \in S_n} sgn(\sigma) a^i_{\sigma(1)} \cdots a^i_{\sigma(n)} \\
&= det_e [ a^i_j ]
\end{align} \square \{ e_1, e_2 \} =: e p M e M  \{ \kappa_1 e_1, \kappa_2 e_2 \} = \{ dv_p(e_1), dv_p(e_2) \} =: e' S^2 dv_p = -L p L L \kappa_1 = \kappa_2 T_p M \begin{align}
\kappa_1^2 \langle e_1, e_2 \rangle &= \langle -L (e_1), -L (e_2) \rangle \\
&=  \langle dv_p (e_1), dv_p (e_2) \rangle \\
&= \kappa_2^2 \langle e_1, e_2 \rangle
\end{align} \langle e_1, e_2 \rangle = 0 = \langle dv_p (e_1), dv_p (e_2) \rangle = \langle \kappa_1 e_1, \kappa_2 e_2 \rangle. \square e T_p M T_p S^2 K(p) = det(J_v(p)) = 0 v^* vol_{S^2} = 0 = K(p) vol_M K(p) = det(J_V(p)) \neq 0 e M S^2 \Theta^1 \wedge \Theta^2 S^2 \Theta^i e_i X_1, X_2 S^2 X_j = \sum x^{i}_j e_i \begin{align}
v^* (vol_{S^2})(X_1, X_2) &= \Theta^1 \wedge \Theta^2 (dv_p X_1, dv_p X_2) \\
&= \Theta^1(dv_p X_1) \Theta^2(dv_p X_2) - \Theta^1(dv_p X_2) \Theta^2(dv_p X_1) \\
\text{(Lemma 2)} &= (\kappa_1 x^1_1) (\kappa_2 x^2_2) - (\kappa_1 x^1_2) (\kappa_2 x^2_1) \\
&= K det_e(X_1, X_2) \\
\text{(Lemma 1)} &= K vol_M
\end{align} \square","['differential-geometry', 'riemannian-geometry', 'curvature']"
30,Covariant derivative of orthonormal frames,Covariant derivative of orthonormal frames,,"Given a $2$ dimensional riemannian manifold with a local orthonormal frame $e_1,e_2$ I want to evaluate the covariant derivatives $\nabla_{e_1}e_1$ , $\nabla_{e_2}e_1$ , $\nabla_{e_1}e_2$ and $\nabla_{e_2}e_2$ , assuming the Levi-Civita connection. I am using two methods and finding different results, so I would like to understand where I am wrong. If I express the covariant derivative with the connection form $\omega^i_j$ associated to the frame, defined by $\nabla_{X}e_j= \Sigma \omega^i_j (X)e_i$ I get the following equations $$\nabla_{e_1}e_1 = \omega_1^1(e_1)e_1+\omega_1^2(e_1)e_2$$ $$\nabla_{e_2}e_1 = \omega_1^1(e_2)e_1+\omega_1^2(e_2)e_2$$ $$\nabla_{e_1}e_2 = \omega_2^1(e_1)e_1+\omega_2^2(e_1)e_2$$ $$\nabla_{e_2}e_2 = \omega_2^1(e_2)e_1+\omega_2^2(e_2)e_2$$ as the connection matrix $\omega_i^j$ with respect to an orthonormal frame is skew symmetric, the previous equations further simplify as $$\nabla_{e_1}e_1 = -\omega^1_2(e_1)e_2$$ $$\nabla_{e_2}e_1 = -\omega^1_2(e_2)e_2$$ $$\nabla_{e_1}e_2 = \omega^1_2(e_1)e_1$$ $$\nabla_{e_2}e_2 = \omega^1_2(e_2)e_1$$ However, I am not fully conviced because if I instead use the formula for the covariant derivative in local coordinates I get a seemingly different result. Assuming two general vector fields $v=v^je_j$ and $u=u^ie_j$ the formula says: $$\nabla_v u= (v^ju^i\Gamma^k_{ij}+v^j\frac{\partial u^k}{\partial x^j})\frac{\partial}{\partial x^k}$$ To find a local expression for an orthonormal frame, I assume that in the coordinates $x^1,x^2$ the metric is expressed by the first fundamental form $[\begin{smallmatrix} E & F \\ F & G \end{smallmatrix}]$ . Then an orthonormal frame is given by (D is the determinant of the matrix): $$(\frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1}, \frac{-F}{\sqrt{ED}}\frac{\partial}{\partial x^1}+\sqrt{\frac{E}{D}}\frac{\partial}{\partial x^2})$$ . In particular, $\frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1}$ has norm $1$ for the metric in question. My problem is that if now calculate $\nabla_{e_1}e_1$ I don't get an expression only in $\frac{\partial}{\partial x^2}$ as I would have expected, as I get $$\nabla_{\frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1}}(\frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1})=\frac{1}{E}\Gamma^1_{11}\frac{\partial}{\partial x^1}+\frac{1}{E}\Gamma^2_{11}\frac{\partial}{\partial x^2}-\frac{1}{2}\frac{E_1}{E^2}\frac{\partial}{\partial x^1}$$ Further expanding the coefficient for $\frac{\partial}{\partial x^1}$ and using the expressions for the Christoffel symbols in coefficients of the first fundamental form I get $$\frac{GE_1-2FF_1+FE_2}{2E(EG-F^2)}\frac{\partial}{\partial x^1}-\frac{1}{2}\frac{E_1}{E^2}\frac{\partial}{\partial x^1}$$ Which does not seem to vanish to me, unless I am mistaken. Where am I wrong? applying the connection form and then assuming that $\nabla_{e_1}e_1$ is a multiple of $e_2$ only assuming that the vector fields above are an orthonormal frame applying the formula for the covariant derivative in local coordinates thanks!","Given a dimensional riemannian manifold with a local orthonormal frame I want to evaluate the covariant derivatives , , and , assuming the Levi-Civita connection. I am using two methods and finding different results, so I would like to understand where I am wrong. If I express the covariant derivative with the connection form associated to the frame, defined by I get the following equations as the connection matrix with respect to an orthonormal frame is skew symmetric, the previous equations further simplify as However, I am not fully conviced because if I instead use the formula for the covariant derivative in local coordinates I get a seemingly different result. Assuming two general vector fields and the formula says: To find a local expression for an orthonormal frame, I assume that in the coordinates the metric is expressed by the first fundamental form . Then an orthonormal frame is given by (D is the determinant of the matrix): . In particular, has norm for the metric in question. My problem is that if now calculate I don't get an expression only in as I would have expected, as I get Further expanding the coefficient for and using the expressions for the Christoffel symbols in coefficients of the first fundamental form I get Which does not seem to vanish to me, unless I am mistaken. Where am I wrong? applying the connection form and then assuming that is a multiple of only assuming that the vector fields above are an orthonormal frame applying the formula for the covariant derivative in local coordinates thanks!","2 e_1,e_2 \nabla_{e_1}e_1 \nabla_{e_2}e_1 \nabla_{e_1}e_2 \nabla_{e_2}e_2 \omega^i_j \nabla_{X}e_j= \Sigma \omega^i_j (X)e_i \nabla_{e_1}e_1 = \omega_1^1(e_1)e_1+\omega_1^2(e_1)e_2 \nabla_{e_2}e_1 = \omega_1^1(e_2)e_1+\omega_1^2(e_2)e_2 \nabla_{e_1}e_2 = \omega_2^1(e_1)e_1+\omega_2^2(e_1)e_2 \nabla_{e_2}e_2 = \omega_2^1(e_2)e_1+\omega_2^2(e_2)e_2 \omega_i^j \nabla_{e_1}e_1 = -\omega^1_2(e_1)e_2 \nabla_{e_2}e_1 = -\omega^1_2(e_2)e_2 \nabla_{e_1}e_2 = \omega^1_2(e_1)e_1 \nabla_{e_2}e_2 = \omega^1_2(e_2)e_1 v=v^je_j u=u^ie_j \nabla_v u= (v^ju^i\Gamma^k_{ij}+v^j\frac{\partial u^k}{\partial x^j})\frac{\partial}{\partial x^k} x^1,x^2 [\begin{smallmatrix} E & F \\ F & G \end{smallmatrix}] (\frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1}, \frac{-F}{\sqrt{ED}}\frac{\partial}{\partial x^1}+\sqrt{\frac{E}{D}}\frac{\partial}{\partial x^2}) \frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1} 1 \nabla_{e_1}e_1 \frac{\partial}{\partial x^2} \nabla_{\frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1}}(\frac{1}{\sqrt{E}}\frac{\partial}{\partial x^1})=\frac{1}{E}\Gamma^1_{11}\frac{\partial}{\partial x^1}+\frac{1}{E}\Gamma^2_{11}\frac{\partial}{\partial x^2}-\frac{1}{2}\frac{E_1}{E^2}\frac{\partial}{\partial x^1} \frac{\partial}{\partial x^1} \frac{GE_1-2FF_1+FE_2}{2E(EG-F^2)}\frac{\partial}{\partial x^1}-\frac{1}{2}\frac{E_1}{E^2}\frac{\partial}{\partial x^1} \nabla_{e_1}e_1 e_2","['differential-geometry', 'connections']"
31,Tangent Space under (linear) Transformation,Tangent Space under (linear) Transformation,,"i am looking for a confirmation of the following Lemma as well as a reference: Let $M \subset \mathbb{R}^m $ be a smooth-manifold and $A \in \mathbb{R}^{n\times m}$ be a full rank matrix with $n\geq m$ . Define $$ N = \{ Ax \, |\, x \in M\}. $$ Then N is also a smooth manifold and $$ A\mathcal{T}_x M := \{Av \, | \, v \in \mathcal{T}_x M\} = T_{Ax} N. $$ Is this correct? I would be very glad if someone could point me to a reference since unfortunatly i could not find anything that seems to be directly related. Thanks in advance.",i am looking for a confirmation of the following Lemma as well as a reference: Let be a smooth-manifold and be a full rank matrix with . Define Then N is also a smooth manifold and Is this correct? I would be very glad if someone could point me to a reference since unfortunatly i could not find anything that seems to be directly related. Thanks in advance.,"M \subset \mathbb{R}^m  A \in \mathbb{R}^{n\times m} n\geq m  N = \{ Ax \, |\, x \in M\}.   A\mathcal{T}_x M := \{Av \, | \, v \in \mathcal{T}_x M\} = T_{Ax} N. ","['differential-geometry', 'manifolds', 'smooth-manifolds', 'tangent-bundle', 'pushforward']"
32,Pullback and wedge product,Pullback and wedge product,,"I am essentially asking the same question as this one . My goal is to prove $$f^*(\omega\wedge\theta)=f^*\omega\wedge f^*\theta.$$ The step I'm missing is precisely the one in the linked question, that is, why is $$(\omega\wedge \theta)(f_*(v_1),\cdots ,f_*(v_p),f_*(w_1),\cdots ,f_*(w_q))$$ the same as $$\omega(f_(v_1),,f_(v_p))\wedge \theta(f_*(w_1),,f_(w_q))?$$ The problem is already that I do not really know how to evaluate something of the form $$(\omega\wedge\theta)(v_1,\dots,v_p,\,w_1,\dots,w_q)$$ in general. I assume that, what I need for that, is the ""summation formula for wedge products"", as mentioned in the linked question. What formula is this? Or maybe, to get started, how would you even compute $$(\mathrm dx\wedge \mathrm d y)(\partial/\partial y,\partial/\partial x),$$ as is mentioned in the linked post's comments?","I am essentially asking the same question as this one . My goal is to prove The step I'm missing is precisely the one in the linked question, that is, why is the same as The problem is already that I do not really know how to evaluate something of the form in general. I assume that, what I need for that, is the ""summation formula for wedge products"", as mentioned in the linked question. What formula is this? Or maybe, to get started, how would you even compute as is mentioned in the linked post's comments?","f^*(\omega\wedge\theta)=f^*\omega\wedge f^*\theta. (\omega\wedge \theta)(f_*(v_1),\cdots ,f_*(v_p),f_*(w_1),\cdots ,f_*(w_q)) \omega(f_(v_1),,f_(v_p))\wedge \theta(f_*(w_1),,f_(w_q))? (\omega\wedge\theta)(v_1,\dots,v_p,\,w_1,\dots,w_q) (\mathrm dx\wedge \mathrm d y)(\partial/\partial y,\partial/\partial x),","['differential-geometry', 'differential-forms', 'exterior-algebra']"
33,The space of direct decompositions,The space of direct decompositions,,"The Grassmannian $\mathrm{Gr}(k, n) = O(n) / O(k)\times O(n-k)$ describes all $k$ -dimensional subspaces of $\mathbb R^n$ . The product space $S=\mathrm{Gr}(k, n)\times \mathrm{Gr}(n-k, n)$ represents pairs of subspaces $(U, V)$ . Some of these pairs form a direct sum decomposition $U\oplus V=\mathbb R^n$ , forming a subspace $$S' := \{(U, V) \in S\mid U\oplus V=\mathbb R^n \}.$$ I am quite sure that $S'$ is a known mathematical object, but I can't find any references on it. I checked N. Steenrod's Fiber Bundles , S. Watanabe's Algebraic Geometry and Statistical Learning Theory , T. tom Dieck's Representation theory and Googled ""Grassmannian of pairs"", ""flag Grassmanian"", ""summand Grassmannian"", but I haven't found anything. Could you recommend me some references on this object?","The Grassmannian describes all -dimensional subspaces of . The product space represents pairs of subspaces . Some of these pairs form a direct sum decomposition , forming a subspace I am quite sure that is a known mathematical object, but I can't find any references on it. I checked N. Steenrod's Fiber Bundles , S. Watanabe's Algebraic Geometry and Statistical Learning Theory , T. tom Dieck's Representation theory and Googled ""Grassmannian of pairs"", ""flag Grassmanian"", ""summand Grassmannian"", but I haven't found anything. Could you recommend me some references on this object?","\mathrm{Gr}(k, n) = O(n) / O(k)\times O(n-k) k \mathbb R^n S=\mathrm{Gr}(k, n)\times \mathrm{Gr}(n-k, n) (U, V) U\oplus V=\mathbb R^n S' := \{(U, V) \in S\mid U\oplus V=\mathbb R^n \}. S'","['differential-geometry', 'reference-request', 'representation-theory', 'grassmannian']"
34,How many corners does an otherwise intrinsically flat surface need in order to be homeomorphic to a sphere?,How many corners does an otherwise intrinsically flat surface need in order to be homeomorphic to a sphere?,,"I want to build a virtual world that feels like an unbounded flat plane but actually ""connects back to itself"" with the topology of a sphere. To do this, we can build the world out of polygonal sectors corresponding to the faces of a polyhedron (bordering each other in the same configuration). This works nicely except that each vertex of the polyhedron becomes a weird point, around which a small loop has a total turning angle less than 360. (For example, if the polyhedron is a cube, each vertex is the meeting point of three square sectors, so you can walk all the way around it while making just three quarter-turns.) We can still render these locations using a portal technique and put something like a tall tree at each one to obscure the visual discontinuity. To make these ""corners"" less conspicuous, I'll use a polyhedron with a large number of vertices. But if we didn't care about that, how few corners could we theoretically get away with? I think the smallest polyhedron that makes sense with my construction is a double-sided triangle, which has 3 corners. But what about a space like a cylinder with each end pinched together (2 corners), or the one-point compactification of a flat open disk (1 corner)? I can't visualize 3D embeddings of these that preserve flatness, but could there still be a corresponding ""flat world"" with just one or two singular points? In order to answer this, I think I need to clarify the idea of a ""manifold with corners"", and that's where I'm having trouble. I've thought about cutting the corners off (leaving a small boundary loop) or rounding them off (leaving a small region with nonzero curvature) to obtain an actual manifold (on which the Gauss-Bonnet theorem might be helpful), but I'm not sure how to express the requirement that the resulting defect is still ""point-sized"", which seems important. Inside the flatworld, I want the singularity to appear as a ""pole"" standing on a point of the plane (as opposed to some larger object), and I think this is what could rule out the one- or two-corner possibilities.","I want to build a virtual world that feels like an unbounded flat plane but actually ""connects back to itself"" with the topology of a sphere. To do this, we can build the world out of polygonal sectors corresponding to the faces of a polyhedron (bordering each other in the same configuration). This works nicely except that each vertex of the polyhedron becomes a weird point, around which a small loop has a total turning angle less than 360. (For example, if the polyhedron is a cube, each vertex is the meeting point of three square sectors, so you can walk all the way around it while making just three quarter-turns.) We can still render these locations using a portal technique and put something like a tall tree at each one to obscure the visual discontinuity. To make these ""corners"" less conspicuous, I'll use a polyhedron with a large number of vertices. But if we didn't care about that, how few corners could we theoretically get away with? I think the smallest polyhedron that makes sense with my construction is a double-sided triangle, which has 3 corners. But what about a space like a cylinder with each end pinched together (2 corners), or the one-point compactification of a flat open disk (1 corner)? I can't visualize 3D embeddings of these that preserve flatness, but could there still be a corresponding ""flat world"" with just one or two singular points? In order to answer this, I think I need to clarify the idea of a ""manifold with corners"", and that's where I'm having trouble. I've thought about cutting the corners off (leaving a small boundary loop) or rounding them off (leaving a small region with nonzero curvature) to obtain an actual manifold (on which the Gauss-Bonnet theorem might be helpful), but I'm not sure how to express the requirement that the resulting defect is still ""point-sized"", which seems important. Inside the flatworld, I want the singularity to appear as a ""pole"" standing on a point of the plane (as opposed to some larger object), and I think this is what could rule out the one- or two-corner possibilities.",,"['differential-geometry', 'geometric-topology']"
35,Vector fields on a sphere: equivalence of two definitions,Vector fields on a sphere: equivalence of two definitions,,"I'm trying to solve this differential geometry exercise: Show that a vector field on a $n$ -sphere and a smooth map $\Phi: S^n\to \mathbb{R}^{n+1}$ such that $\Phi(x)$ is always orthogonal to $x$ are essentially the same object. (The $n$ -sphere is taken with its standard differentiable structure, given by the two stereographic charts $U,V$ ) I think that this exercise requires us to find a bijection between the set of vector fields on $S^n$ : $$\text{Der}(C^\infty (S^n))$$ and the set of smooth maps that satisfy that orthogonality property. I read a solution that went like this. On a stereographic chart, a vector field $X$ looks like this: $$X|_U=\sum_i \varphi_i \frac{\partial}{\partial x_i}$$ Evaluating this vector field on the function $\sum_{i=1}^n x_i^2$ , we get: $$\sum_{i=1}^n \varphi_i(x_1,...,x_n)x_i=0$$ So we just need to take $\Phi=(\varphi_1,...,\varphi_n)$ . But this doesn't seem rigorous. The functions $\varphi_i$ are defined only on $U$ and not on the whole sphere, so we need to account in someway for the missing point.","I'm trying to solve this differential geometry exercise: Show that a vector field on a -sphere and a smooth map such that is always orthogonal to are essentially the same object. (The -sphere is taken with its standard differentiable structure, given by the two stereographic charts ) I think that this exercise requires us to find a bijection between the set of vector fields on : and the set of smooth maps that satisfy that orthogonality property. I read a solution that went like this. On a stereographic chart, a vector field looks like this: Evaluating this vector field on the function , we get: So we just need to take . But this doesn't seem rigorous. The functions are defined only on and not on the whole sphere, so we need to account in someway for the missing point.","n \Phi: S^n\to \mathbb{R}^{n+1} \Phi(x) x n U,V S^n \text{Der}(C^\infty (S^n)) X X|_U=\sum_i \varphi_i \frac{\partial}{\partial x_i} \sum_{i=1}^n x_i^2 \sum_{i=1}^n \varphi_i(x_1,...,x_n)x_i=0 \Phi=(\varphi_1,...,\varphi_n) \varphi_i U","['differential-geometry', 'vector-fields']"
36,Transformation of Curvature 2-Form Under Global Bundle Autormphism,Transformation of Curvature 2-Form Under Global Bundle Autormphism,,"Let $F^A$ be a curvature two form on a principal bundle $P$ corresponding to the connection one form $A$ . Let $f:P\rightarrow P$ be a global bundle automorphism; there then exists a map $\sigma_f:P\rightarrow G$ such that: $$f(p)=p\cdot \sigma_f(p)$$ Finally let $\mu_G$ be the maurer cartan form, given by: $$\mu_G(X_g)=L_{g^{-1}*}X_g$$ where $X_g$ is a vector field on some Lie group $G$ . Under the pullback of $A$ by $f$ we have:"" $$f^*A=\text{Ad}_{\sigma_{f^{-1}} } \circ A+\sigma_f^*\mu_G$$ I am trying to show that: $$F^{f^*A}=\text{Ad}_{\sigma_{f^{-1}}}\circ F^A$$ where: $$F^A=dA+\frac{1}{2}[A,A]$$ and for two Lie algebra valued one forms $\eta,\omega$ : $$[\eta,\omega](X,Y)=[\eta(X),\omega(Y)]-[\eta(Y),\omega(X)]$$ which comes from the definition of the wedge product for Lie algebra valued $k$ and $l$ forms. When replacing $A$ with $f^*A$ , we see that: $$F^{f^*A}=d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)+\sigma_f^*d\mu_G+\frac{1}{2}\text{Ad}_{\sigma_{f^{-1}}}\circ [A,A]+\frac{1}{2}\sigma_f^*[\mu_G,\mu_G]+\frac{1}{2}[\text{Ad}_{\sigma_{f^{-1}}}\circ A,\sigma_f^*\mu_G]+\frac{1}{2}[\sigma_f^*\mu_G,\text{Ad}_{\sigma_{f^{-1}}}\circ A]$$ By the Maurer-Cartan equation we have that: $$\sigma_f^*d\mu_G=-\frac{1}{2}\sigma^*_f[\mu_G,\mu_G]$$ hence: $$F^{f^*A}=d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)+\frac{1}{2}\text{Ad}_{\sigma_{f^{-1}}}\circ [A,A]+\frac{1}{2}[\text{Ad}_{\sigma_{f^{-1}}}\circ A,\sigma_f^*\mu_G]+\frac{1}{2}[\sigma_f^*\mu_G,\text{Ad}_{\sigma_{f^{-1}}}\circ A]$$ My problem is now that I am unsure of how to calculate the exterior derivative of $\text{Ad}_{\sigma_{f^{-1}}}\circ A$ . By our previous formula for two Lie algebra valued one forms we have that for $\eta=\text{Ad}_{\sigma_{f^{-1}}}\circ A$ , and $\omega=\sigma_f^*\mu_G$ : $$\frac{1}{2}\left([\eta,\omega]+[\omega,\eta]\right)(X,Y)=\frac{1}{2}\left([\eta(X),\omega(Y)]-[\eta(Y),\omega(X)]+[\omega(X),\eta(Y)]-[\omega(Y),\eta(X)]\right)$$ $$=[\eta(X),\omega(Y)]-[\eta(Y),\omega(X]$$ $$=[\eta,\omega](X,Y)$$ So I feel that: $$d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)=\text{Ad}_{\sigma_{f^{-1}}}\circ dA-[\eta,\omega]$$ but I don't see why this should be true. In fact, since $\text{Ad}$ is a representation of $G$ on $\mathfrak{g}$ I would think that: $$d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)=\text{Ad}_{\sigma_{f^{-1}}}\circ dA$$ but then I have this extra factor of $[\eta,\omega]$ , so I am at a loss. Any hints on how to calculate this exterior derivative, or on how that wedge product may actually be zero would be greatly beneficial. Edit: Employing Professor Shifrin's notation, I write that: $$f^*A=\sigma_{f^{-1}}A\sigma_f+\sigma_{f^{-1}}d\sigma_f$$ I have already calculated the exterior derivative of the second term, albeit in a different notation, so I move to the first term: $$d(\sigma_{f^{-1}}A\sigma_f)=d(\sigma_{f^{-1}})\wedge A\sigma_f+ \text{Ad}_{\sigma_f^{-1}}\circ dA+\sigma_{f^{-1}}A\wedge d(\sigma_f) $$ Note that: $$\sigma_{f^{-1}}\sigma_f=e$$ hence: $$d(\sigma_{f^{-1}})\sigma_f=-\sigma_{f^{-1}}d\sigma_f\Rightarrow d\sigma_{f^{-1}}=-\sigma_f^{-1}d\sigma_f\sigma_{f^{-1}}$$ Therefore we obtain: $$d(\sigma_{f^{-1}}A\sigma_f)=-\sigma_{f^{-1}}d\sigma_f\wedge \text{Ad}_{\sigma_f^{-1}}A+ \text{Ad}_{\sigma_f^{-1}}\circ dA-\text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge d(\sigma_{f^{-1}})\sigma_f$$ The final term in this sum can be rewritten as: $$\text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge d(\sigma_{f^{-1}})\sigma_f=-\text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge \sigma_f^{-1}d\sigma_{f}$$ Thus: $$d(\sigma_{f^{-1}}A\sigma_f)=-\sigma_{f^{-1}}d\sigma_f\wedge \text{Ad}_{\sigma_f^{-1}}A+ \text{Ad}_{\sigma_f^{-1}}\circ dA+\text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge \sigma_f^{-1}d\sigma_{f}$$ From here, I can kind of see how the pieces should move, but I am unsure why. Reconciling the two notations is proving troublesome to me. To be clearer, it seems that from the definition for the wedge product of twisted forms, this product is actually symmetric for one forms, so I feel like the first term and the last term would cancel, which doesn't make sense. I am then left to conclude that there is something different about the wedge product I have used in this edit, and the wedge product I used in the original post, but I am unsure what that difference actually is, or how to make it precise. Edit 2: The definition of wedge product for Lie algebra valued one forms is as follows: Given a $\omega\in \Omega^k(P,\mathfrak{g})$ and $\eta\in \Omega^k(P,\mathfrak{g})$ , then their wedge product is given by: $$[\omega,\eta](X_1,\dots,X_{k+l})=\frac{1}{k!l!}\sum_{\sigma\in S}\text{sign}(\sigma)\left[\omega(X_{\sigma(1)},\dots,X_{\sigma(k)}), \eta(X_{\sigma(k+1)},\dots,X_{\sigma(k+l)} ) \right]$$ When choosing a basis $\{T_i\}$ for the Lie algebra $\mathfrak{g}$ , we have that $\eta$ and $\omega$ can be written as: $$\eta=\sum_{i=1}^n \eta^i\otimes T_i$$ $$\omega=\sum_{i=1}^n \omega^i\otimes T_i$$ where each $\omega^i$ and $\eta^i$ are $k$ and $l$ forms on $P$ respectively. Then the wedge product can be written as $$\omega \wedge \eta =\sum_{i,j=1}^n \omega^i\wedge\eta^j\otimes[T_i, T_J]  $$ Hence: $$[\eta,\omega] =\sum_{i,j=1}^n \eta^j\wedge\omega^i\otimes[T_j,T_i] $$ $$=(-1)^{lk}\sum_{i,j=1}^n\eta^i \wedge\omega^j\otimes[T_j,T_i]$$ $$=(-1)^{lk+1}\sum_{i,j=1}^n\eta^i \wedge\omega^j\otimes[T_i,T_j]$$ $$=(-1)^{lk+1}[\omega,\eta]$$ So for two one forms, $\eta$ and $\omega$ : $$[\eta,\omega]=(-1)^2[\omega,\eta]=[\omega,\eta]$$ Hence the wedge product of Lie algebra valued forms is symmetric for one forms.","Let be a curvature two form on a principal bundle corresponding to the connection one form . Let be a global bundle automorphism; there then exists a map such that: Finally let be the maurer cartan form, given by: where is a vector field on some Lie group . Under the pullback of by we have:"" I am trying to show that: where: and for two Lie algebra valued one forms : which comes from the definition of the wedge product for Lie algebra valued and forms. When replacing with , we see that: By the Maurer-Cartan equation we have that: hence: My problem is now that I am unsure of how to calculate the exterior derivative of . By our previous formula for two Lie algebra valued one forms we have that for , and : So I feel that: but I don't see why this should be true. In fact, since is a representation of on I would think that: but then I have this extra factor of , so I am at a loss. Any hints on how to calculate this exterior derivative, or on how that wedge product may actually be zero would be greatly beneficial. Edit: Employing Professor Shifrin's notation, I write that: I have already calculated the exterior derivative of the second term, albeit in a different notation, so I move to the first term: Note that: hence: Therefore we obtain: The final term in this sum can be rewritten as: Thus: From here, I can kind of see how the pieces should move, but I am unsure why. Reconciling the two notations is proving troublesome to me. To be clearer, it seems that from the definition for the wedge product of twisted forms, this product is actually symmetric for one forms, so I feel like the first term and the last term would cancel, which doesn't make sense. I am then left to conclude that there is something different about the wedge product I have used in this edit, and the wedge product I used in the original post, but I am unsure what that difference actually is, or how to make it precise. Edit 2: The definition of wedge product for Lie algebra valued one forms is as follows: Given a and , then their wedge product is given by: When choosing a basis for the Lie algebra , we have that and can be written as: where each and are and forms on respectively. Then the wedge product can be written as Hence: So for two one forms, and : Hence the wedge product of Lie algebra valued forms is symmetric for one forms.","F^A P A f:P\rightarrow P \sigma_f:P\rightarrow G f(p)=p\cdot \sigma_f(p) \mu_G \mu_G(X_g)=L_{g^{-1}*}X_g X_g G A f f^*A=\text{Ad}_{\sigma_{f^{-1}} } \circ A+\sigma_f^*\mu_G F^{f^*A}=\text{Ad}_{\sigma_{f^{-1}}}\circ F^A F^A=dA+\frac{1}{2}[A,A] \eta,\omega [\eta,\omega](X,Y)=[\eta(X),\omega(Y)]-[\eta(Y),\omega(X)] k l A f^*A F^{f^*A}=d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)+\sigma_f^*d\mu_G+\frac{1}{2}\text{Ad}_{\sigma_{f^{-1}}}\circ [A,A]+\frac{1}{2}\sigma_f^*[\mu_G,\mu_G]+\frac{1}{2}[\text{Ad}_{\sigma_{f^{-1}}}\circ A,\sigma_f^*\mu_G]+\frac{1}{2}[\sigma_f^*\mu_G,\text{Ad}_{\sigma_{f^{-1}}}\circ A] \sigma_f^*d\mu_G=-\frac{1}{2}\sigma^*_f[\mu_G,\mu_G] F^{f^*A}=d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)+\frac{1}{2}\text{Ad}_{\sigma_{f^{-1}}}\circ [A,A]+\frac{1}{2}[\text{Ad}_{\sigma_{f^{-1}}}\circ A,\sigma_f^*\mu_G]+\frac{1}{2}[\sigma_f^*\mu_G,\text{Ad}_{\sigma_{f^{-1}}}\circ A] \text{Ad}_{\sigma_{f^{-1}}}\circ A \eta=\text{Ad}_{\sigma_{f^{-1}}}\circ A \omega=\sigma_f^*\mu_G \frac{1}{2}\left([\eta,\omega]+[\omega,\eta]\right)(X,Y)=\frac{1}{2}\left([\eta(X),\omega(Y)]-[\eta(Y),\omega(X)]+[\omega(X),\eta(Y)]-[\omega(Y),\eta(X)]\right) =[\eta(X),\omega(Y)]-[\eta(Y),\omega(X] =[\eta,\omega](X,Y) d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)=\text{Ad}_{\sigma_{f^{-1}}}\circ dA-[\eta,\omega] \text{Ad} G \mathfrak{g} d(\text{Ad}_{\sigma_{f^{-1}}}\circ A)=\text{Ad}_{\sigma_{f^{-1}}}\circ dA [\eta,\omega] f^*A=\sigma_{f^{-1}}A\sigma_f+\sigma_{f^{-1}}d\sigma_f d(\sigma_{f^{-1}}A\sigma_f)=d(\sigma_{f^{-1}})\wedge A\sigma_f+
\text{Ad}_{\sigma_f^{-1}}\circ dA+\sigma_{f^{-1}}A\wedge d(\sigma_f)  \sigma_{f^{-1}}\sigma_f=e d(\sigma_{f^{-1}})\sigma_f=-\sigma_{f^{-1}}d\sigma_f\Rightarrow d\sigma_{f^{-1}}=-\sigma_f^{-1}d\sigma_f\sigma_{f^{-1}} d(\sigma_{f^{-1}}A\sigma_f)=-\sigma_{f^{-1}}d\sigma_f\wedge \text{Ad}_{\sigma_f^{-1}}A+
\text{Ad}_{\sigma_f^{-1}}\circ dA-\text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge d(\sigma_{f^{-1}})\sigma_f \text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge d(\sigma_{f^{-1}})\sigma_f=-\text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge \sigma_f^{-1}d\sigma_{f} d(\sigma_{f^{-1}}A\sigma_f)=-\sigma_{f^{-1}}d\sigma_f\wedge \text{Ad}_{\sigma_f^{-1}}A+
\text{Ad}_{\sigma_f^{-1}}\circ dA+\text{Ad}_{\sigma_{f^{-1}}}\circ A \wedge \sigma_f^{-1}d\sigma_{f} \omega\in \Omega^k(P,\mathfrak{g}) \eta\in \Omega^k(P,\mathfrak{g}) [\omega,\eta](X_1,\dots,X_{k+l})=\frac{1}{k!l!}\sum_{\sigma\in S}\text{sign}(\sigma)\left[\omega(X_{\sigma(1)},\dots,X_{\sigma(k)}), \eta(X_{\sigma(k+1)},\dots,X_{\sigma(k+l)} ) \right] \{T_i\} \mathfrak{g} \eta \omega \eta=\sum_{i=1}^n \eta^i\otimes T_i \omega=\sum_{i=1}^n \omega^i\otimes T_i \omega^i \eta^i k l P \omega \wedge \eta =\sum_{i,j=1}^n \omega^i\wedge\eta^j\otimes[T_i, T_J]   [\eta,\omega] =\sum_{i,j=1}^n \eta^j\wedge\omega^i\otimes[T_j,T_i]  =(-1)^{lk}\sum_{i,j=1}^n\eta^i \wedge\omega^j\otimes[T_j,T_i] =(-1)^{lk+1}\sum_{i,j=1}^n\eta^i \wedge\omega^j\otimes[T_i,T_j] =(-1)^{lk+1}[\omega,\eta] \eta \omega [\eta,\omega]=(-1)^2[\omega,\eta]=[\omega,\eta]","['differential-geometry', 'differential-topology', 'curvature', 'connections', 'gauge-theory']"
37,"If two points can be joined by a causal curve that is not a null geodesic, can they be joined by a timelike curve?","If two points can be joined by a causal curve that is not a null geodesic, can they be joined by a timelike curve?",,"Suppose $p$ and $q$ are connected by a causal (i.e. its tangent vectors have non-positive norm) curve $\gamma$ . If $\gamma$ is not a null geodesic, can it be deformed into a smooth, timelike curve still connecting $p$ and $q$ ? This is in Hawking and Ellis The large scale structure of space-time , Proposition 4.5.10. I write the proof below with as many details as I could fill in. Denote by $D_t$ the covariant derivative along $\gamma$ induced by the Levi-Civita connection $\nabla$ . We know $\gamma$ is a null geodesic if the acceleration vector $D_t \gamma '(t) = 0$ and $\langle \gamma'(t), \gamma'(t)\rangle = 0$ everywhere. Thus, if $\gamma$ is not a null geodesic, there must exist a point $t_0$ where $D_t\gamma'(t_0) \neq 0$ or where $\langle \gamma'(t_0), \gamma'(t_0) \rangle < 0$ . By continuity, if either of these cases hold, then they hold on an open interval $I = (t_1, t_2)$ . However, if $\langle \gamma'(t), \gamma'(t) \rangle < 0$ on $I$ then $\gamma$ is already timelike, so there is nothing to prove. Consequently, we assume that $D_t \gamma' \neq 0$ on $I$ . Here it is claimed in the book that $$ \langle D_t \gamma'(t), \gamma'(t) \rangle = \frac 12 \partial_t \langle \gamma'(t), \gamma'(t) \rangle = 0, $$ but I cannot see why this is so. Can we reparametrize any causal curve so its velocity has constant norm even it at some points the curve becomes null? Taking this for granted, we deduce that $D_t \gamma'$ is spacelike and thus $a(t) ^2 := \langle D_t \gamma'(t), D_t \gamma'(t)\rangle > 0$ on $I$ . We can Fermi transport a vector with positive inner product against $\gamma'$ to obtain a vector field $W$ along $\gamma|_I$ s.t. $c(t) := -\langle W, \gamma'(t)\rangle > 0$ on $I$ and generate the variation $$ \Gamma(s, t) = \exp_{\gamma(t)}(s (x W + y D_t \gamma'(t))), \quad S = \partial_s \Gamma(s, t), \quad T = \partial_t \Gamma(s, t) $$ where $x$ and $y$ are functions to be chosen momentarily but keeping in mind the requirement that $x(t_1) = x(t_2) = y(t_1) = y(t_2) = 0$ to ensure $\Gamma_s(t_1) = \gamma(t_1)$ and $\Gamma_s(t_2) = \gamma(t_2)$ . Then, $\Gamma_s(t)$ will be timelike if $\langle T, T \rangle < 0$ everywhere, which would hold if the the derivative with respect to $s$ at $s = 0$ were negative: \begin{align}   - 1 &= \frac{1}{2} \partial_s|_0 \langle T, T \rangle = \langle D_s T, T \rangle   \\       &= \langle D_t S, T \rangle & \nabla \text{ is torsion free,}   \\       &= \partial_t \langle S, T \rangle - \langle S, D_t T\rangle & \text{metric compatibility,}   \\   &= \partial_t (x \langle W, \gamma' \rangle) - x \langle W, D_t \gamma'\rangle - y \langle D_t \gamma', D_t \gamma'     \rangle & T|_{s = 0} = \gamma',   \\   &= u' + \langle W, D_t \gamma'\rangle c ^{-1} u - y a(t) ^2 & \text{Letting } u = - x c. \end{align} With the integrating factor $b(t) = -\int_{t_1} ^t \langle W, D_t \gamma'(s) \rangle c(s) ^{-1} \mathrm{d} s$ we have \begin{align} (u e ^{-b})' e ^{b} = y a(t) ^2 - 1 &\Rightarrow u = e ^b \int_{t_1} ^t e ^{-b(s)} (y(s) a(s) ^2 - 1)                       \mathrm{d} s   \\   &\Rightarrow x = c(t) ^{-1}e ^{b(t)} \int_{t_1} ^t e ^{-b(s)} (1 - y(s) a(s) ^2)                       \mathrm{d} s. \end{align} To satisfy our earlier constraints, we could let $y$ be a parabola with roots ata $t_1$ and $t_2$ . By scaling and applying the intermediate value theorem, we could find an appropriate factor s.t. $$ \int_{t_1} ^{t_2} e ^{-b(s)}(1 - y(s) a(s) ^2) \mathrm{d} s = 0$$ because $a(s)$ does not vanish. However, in the book, they instead define $$ x = c^{-1} e ^b \int_{t_1}^t e^{-b}(1 - a^2 y/2) \text d s $$ and I do not understand where this extra factor of a half is coming from. I think I may be misunderstanding the proof. Could someone point me in the right direction?","Suppose and are connected by a causal (i.e. its tangent vectors have non-positive norm) curve . If is not a null geodesic, can it be deformed into a smooth, timelike curve still connecting and ? This is in Hawking and Ellis The large scale structure of space-time , Proposition 4.5.10. I write the proof below with as many details as I could fill in. Denote by the covariant derivative along induced by the Levi-Civita connection . We know is a null geodesic if the acceleration vector and everywhere. Thus, if is not a null geodesic, there must exist a point where or where . By continuity, if either of these cases hold, then they hold on an open interval . However, if on then is already timelike, so there is nothing to prove. Consequently, we assume that on . Here it is claimed in the book that but I cannot see why this is so. Can we reparametrize any causal curve so its velocity has constant norm even it at some points the curve becomes null? Taking this for granted, we deduce that is spacelike and thus on . We can Fermi transport a vector with positive inner product against to obtain a vector field along s.t. on and generate the variation where and are functions to be chosen momentarily but keeping in mind the requirement that to ensure and . Then, will be timelike if everywhere, which would hold if the the derivative with respect to at were negative: With the integrating factor we have To satisfy our earlier constraints, we could let be a parabola with roots ata and . By scaling and applying the intermediate value theorem, we could find an appropriate factor s.t. because does not vanish. However, in the book, they instead define and I do not understand where this extra factor of a half is coming from. I think I may be misunderstanding the proof. Could someone point me in the right direction?","p q \gamma \gamma p q D_t \gamma \nabla \gamma D_t \gamma '(t) = 0 \langle \gamma'(t), \gamma'(t)\rangle = 0 \gamma t_0 D_t\gamma'(t_0) \neq 0 \langle \gamma'(t_0), \gamma'(t_0) \rangle < 0 I = (t_1, t_2) \langle \gamma'(t), \gamma'(t) \rangle < 0 I \gamma D_t
\gamma' \neq 0 I 
\langle D_t \gamma'(t), \gamma'(t) \rangle = \frac 12 \partial_t \langle \gamma'(t), \gamma'(t) \rangle = 0,
 D_t \gamma' a(t) ^2 := \langle D_t \gamma'(t), D_t \gamma'(t)\rangle > 0 I \gamma' W \gamma|_I c(t) := -\langle W, \gamma'(t)\rangle > 0 I  \Gamma(s, t) = \exp_{\gamma(t)}(s (x W + y D_t \gamma'(t))), \quad S = \partial_s \Gamma(s, t),
\quad T = \partial_t \Gamma(s, t)
 x y x(t_1) =
x(t_2) = y(t_1) = y(t_2) = 0 \Gamma_s(t_1) = \gamma(t_1) \Gamma_s(t_2)
= \gamma(t_2) \Gamma_s(t) \langle T, T \rangle < 0 s s = 0 \begin{align}
  - 1 &= \frac{1}{2} \partial_s|_0 \langle T, T \rangle = \langle D_s T, T \rangle
  \\
      &= \langle D_t S, T \rangle & \nabla \text{ is torsion free,}
  \\
      &= \partial_t \langle S, T \rangle - \langle S, D_t T\rangle & \text{metric compatibility,}
  \\
  &= \partial_t (x \langle W, \gamma' \rangle) - x \langle W, D_t \gamma'\rangle - y \langle D_t \gamma', D_t \gamma'
    \rangle & T|_{s = 0} = \gamma',
  \\
  &= u' + \langle W, D_t \gamma'\rangle c ^{-1} u - y a(t) ^2 & \text{Letting } u = - x c.
\end{align} b(t) = -\int_{t_1} ^t \langle W, D_t \gamma'(s) \rangle c(s) ^{-1}
\mathrm{d} s \begin{align}
(u e ^{-b})' e ^{b} = y a(t) ^2 - 1 &\Rightarrow u = e ^b \int_{t_1} ^t e ^{-b(s)} (y(s) a(s) ^2 - 1)
                      \mathrm{d} s
  \\
  &\Rightarrow x = c(t) ^{-1}e ^{b(t)} \int_{t_1} ^t e ^{-b(s)} (1 - y(s) a(s) ^2)
                      \mathrm{d} s.
\end{align} y t_1 t_2  \int_{t_1} ^{t_2} e ^{-b(s)}(1 - y(s) a(s) ^2) \mathrm{d} s = 0 a(s) 
x = c^{-1} e ^b \int_{t_1}^t e^{-b}(1 - a^2 y/2) \text d s
","['differential-geometry', 'riemannian-geometry', 'geodesic']"
38,What is largest possible sum of all interoir angles of a triangle on a torus?,What is largest possible sum of all interoir angles of a triangle on a torus?,,"As discussed in the question Triangles on a Torus , the outside of a torus has positive Gaussian curvature. A triangle inscribed on the outer surface will have interior angles which add to be greater than 180 degrees. By adjusting the geometry of the Torus, and the points which define the triangle, what is the maximum possible sum of interior angles of the triangle? I suspect the fringe case occurs with a horn torus with vertices that lie on the axis between positive and negative curvature. Edit: Inside of the Torus refers to the side of the torus facing inward toward the donut hole. Alternatively, it is simply the surface of the torus with negative Gaussian curvature. Edit 2: Im referring to one single triangle drawn anywhere on the surface of the torus, not breaking the surface into a number of smaller triangles","As discussed in the question Triangles on a Torus , the outside of a torus has positive Gaussian curvature. A triangle inscribed on the outer surface will have interior angles which add to be greater than 180 degrees. By adjusting the geometry of the Torus, and the points which define the triangle, what is the maximum possible sum of interior angles of the triangle? I suspect the fringe case occurs with a horn torus with vertices that lie on the axis between positive and negative curvature. Edit: Inside of the Torus refers to the side of the torus facing inward toward the donut hole. Alternatively, it is simply the surface of the torus with negative Gaussian curvature. Edit 2: Im referring to one single triangle drawn anywhere on the surface of the torus, not breaking the surface into a number of smaller triangles",,"['differential-geometry', 'surfaces', 'curvature']"
39,In the proof of showing $\operatorname{Ad}_{*} =\operatorname{ad} $ (adjoint representations of Lie Group(Algebra).,In the proof of showing  (adjoint representations of Lie Group(Algebra).,\operatorname{Ad}_{*} =\operatorname{ad} ,"I'am reading the Lee's Introduction to smooth manifolds, 2nd edition, p.534, Theorem 20.27 and stuck at understanding some equality : Why the underlined equality is true? Here, $\operatorname{ad} : \mathfrak{g} \to \mathfrak{gl(g)}$ is the adjoint representation of $\mathfrak{g}$ and $\operatorname{Ad}_{*} :\mathfrak{g} \to \mathfrak{gl(g)}$ is the induced Lie algebra representation which is defined as follows (His book p.195) : Here, the 'L' in the above underlined definition of $Y$ is defined as follows (His book, p.191) : Let $G$ be a Lie group. Let $v\in T_{e}G$ be arbitrary. Then define a (left invariant) vector field $v^{L}$ on $G$ by $$ v^{L}|_g = d(L_g)_{e}(v)$$ . Note that by the proof of his book, Theorem 8.37 (p.191), the correspondence $L$ is an isomorphism $T_eG \to \operatorname{Lie}(G) =: \mathfrak{g}$ with inverse $\epsilon : \operatorname{Lie}(G) \to T_eG$ , given by $\epsilon(X) := X_e$ . It seems that our question is somewhat basic but I don't know how to establish the equality rigorously. What should I notice? First attempt : Let $H:=GL(\mathfrak{g})$ and let $\mathfrak{h}:=\mathfrak{gl(g)}$ be its Lie algebra. Let $\gamma : t \mapsto \operatorname{exp}tX$ . Then $$\frac{d} {dt} |_{t=0} (\operatorname{Ad}(\operatorname{exp}tX))  = (\operatorname{Ad} \circ \gamma)^{'}(0) = d(\operatorname{Ad})_{\gamma(0)}(\gamma^{'}(0)) = d(\operatorname{Ad})_{e}(X_e) \in T_eH$$ . And, $$\operatorname{Ad}_{*}(X) = (d(\operatorname{Ad})_{e}(X_e))^{L} \in \operatorname{Lie}H =: \mathfrak{h} = \mathfrak{gl(g)} $$ And why the difference appear? I think that for the first equality, more correct form is, $$(\operatorname{Ad}_{*}X)Y = (\frac{d} {dt} |_{t=0} (\operatorname{Ad}(\operatorname{exp}tX)))^{L}(Y) $$ Did I make point out well? If so, it remains(the second equality) to show that $$(\frac{d} {dt} |_{t=0} (\operatorname{Ad}(\operatorname{exp}tX)))^{L}(Y) = \frac{d} {dt} |_{t=0}(\operatorname{Ad}(\operatorname{exp}tX)Y) $$ How can we show this? How the passage of $Y$ into the derivative $\frac{d}{dt}|_{t=0}$ ( ; i.e., the second equality) possible? If we can use the Chain rule, how can we apply the chain rule more rigorously? Can anyone helps?","I'am reading the Lee's Introduction to smooth manifolds, 2nd edition, p.534, Theorem 20.27 and stuck at understanding some equality : Why the underlined equality is true? Here, is the adjoint representation of and is the induced Lie algebra representation which is defined as follows (His book p.195) : Here, the 'L' in the above underlined definition of is defined as follows (His book, p.191) : Let be a Lie group. Let be arbitrary. Then define a (left invariant) vector field on by . Note that by the proof of his book, Theorem 8.37 (p.191), the correspondence is an isomorphism with inverse , given by . It seems that our question is somewhat basic but I don't know how to establish the equality rigorously. What should I notice? First attempt : Let and let be its Lie algebra. Let . Then . And, And why the difference appear? I think that for the first equality, more correct form is, Did I make point out well? If so, it remains(the second equality) to show that How can we show this? How the passage of into the derivative ( ; i.e., the second equality) possible? If we can use the Chain rule, how can we apply the chain rule more rigorously? Can anyone helps?","\operatorname{ad} : \mathfrak{g} \to \mathfrak{gl(g)} \mathfrak{g} \operatorname{Ad}_{*} :\mathfrak{g} \to \mathfrak{gl(g)} Y G v\in T_{e}G v^{L} G  v^{L}|_g = d(L_g)_{e}(v) L T_eG \to \operatorname{Lie}(G) =: \mathfrak{g} \epsilon : \operatorname{Lie}(G) \to T_eG \epsilon(X) := X_e H:=GL(\mathfrak{g}) \mathfrak{h}:=\mathfrak{gl(g)} \gamma : t \mapsto \operatorname{exp}tX \frac{d} {dt} |_{t=0} (\operatorname{Ad}(\operatorname{exp}tX)) 
= (\operatorname{Ad} \circ \gamma)^{'}(0) = d(\operatorname{Ad})_{\gamma(0)}(\gamma^{'}(0)) = d(\operatorname{Ad})_{e}(X_e) \in T_eH \operatorname{Ad}_{*}(X) = (d(\operatorname{Ad})_{e}(X_e))^{L} \in \operatorname{Lie}H =: \mathfrak{h} = \mathfrak{gl(g)}  (\operatorname{Ad}_{*}X)Y = (\frac{d} {dt} |_{t=0} (\operatorname{Ad}(\operatorname{exp}tX)))^{L}(Y)  (\frac{d} {dt} |_{t=0} (\operatorname{Ad}(\operatorname{exp}tX)))^{L}(Y) = \frac{d} {dt} |_{t=0}(\operatorname{Ad}(\operatorname{exp}tX)Y)  Y \frac{d}{dt}|_{t=0}","['differential-geometry', 'lie-groups', 'lie-algebras']"
40,"Differential fails to exist in a certain point in a surface, does this means the surface is not regular?","Differential fails to exist in a certain point in a surface, does this means the surface is not regular?",,"I am trying to answer the following problem: Show that the two-sheeted cone, with its vertex at the origin, that is, the set $\{(x,y,z)R^3 :x^2+y^2z^2=0\},$ is not a regular surface. I am trying the following: I rewrite it as $(x,y,\pm \sqrt{x^2+y^2})$ and then compute the differential: $$\begin{pmatrix} {1}&{0}\\  {0}&{1}\\  {\frac{x}{\sqrt{x^2+y^2}}}&{\frac{y}{\sqrt{x^2+y^2}}} \end{pmatrix}$$ In the definition of regular surface, we ask that: For each $q$ , the differential $d\textbf{x}_q$ is one to one. I think I can use that. The trouble for me is: The differential does not exist at $(0,0,0)$ , does this also means that the surface is non regular?","I am trying to answer the following problem: Show that the two-sheeted cone, with its vertex at the origin, that is, the set is not a regular surface. I am trying the following: I rewrite it as and then compute the differential: In the definition of regular surface, we ask that: For each , the differential is one to one. I think I can use that. The trouble for me is: The differential does not exist at , does this also means that the surface is non regular?","\{(x,y,z)R^3 :x^2+y^2z^2=0\}, (x,y,\pm \sqrt{x^2+y^2}) \begin{pmatrix}
{1}&{0}\\ 
{0}&{1}\\ 
{\frac{x}{\sqrt{x^2+y^2}}}&{\frac{y}{\sqrt{x^2+y^2}}}
\end{pmatrix} q d\textbf{x}_q (0,0,0)",['differential-geometry']
41,Applying the Ricci identity on the Cotton tensor,Applying the Ricci identity on the Cotton tensor,,"The Schouten tensor is given by $$ P_{i j}=\frac{1}{n-2}\left(R_{i j}-\frac{1}{2(n-2)} R g_{i j}\right).$$ I want to compute the divergence of the Bach tensor in dimension $4$ . From this post, we know that the Bach tensor is divergence-free in dimension $4.$ I want to show it explicitly. The divergence of the back tensor $$ \begin{aligned} \nabla^{j} B_{i j} &=\nabla^{j} ( \nabla^{k} \nabla_{k} P_{i j}-\nabla^{j} \nabla^{k} \nabla_{j} P_{i k})+\nabla^{j}\left(P^{k l} W_{i k j l}\right)  \\ &= (\nabla^{j} \nabla^{k} \nabla_{k} P_{i j}-\nabla^{k} \nabla^{j} \nabla_{k} P_{i j})+\nabla^{j}\left(P^{k l} W_{i k j l}\right) \end{aligned} .$$ The second term requires the divergence of the Weyl tensor, and I have a nice formula for the divergence of the Weyl tensor. I'm struggling to compute the following portion: $$ \begin{aligned} (\nabla^{j} \nabla^{k} \nabla_{k} P_{i j}-\nabla^{k} \nabla^{j} \nabla_{k} P_{i j}) \end{aligned} .$$ On page 126 of Jiaqi Chen's Doctoral thesis , he says the Ricci identity gives us $$ \begin{aligned} (\nabla^{j} \nabla^{k} \nabla_{k} P_{i j}-\nabla^{k} \nabla^{j} \nabla_{k} P_{i j}) \end{aligned} $$ equals to $$(\nabla^{j} P^{k l}) R_{i k j l}.$$ I could not derive this equality by the Ricci Identity . Could you help me establish the equality that Jiaqi Chen claimed? Thanks so much. Note that here our connection $\nabla$ is torsion-free and metric compatible. Update: Finally, I did the calculation and it was nasty. I'm still wondering how Dr. Chen did this in just two lines. I'm still looking for a better/short calculation.","The Schouten tensor is given by I want to compute the divergence of the Bach tensor in dimension . From this post, we know that the Bach tensor is divergence-free in dimension I want to show it explicitly. The divergence of the back tensor The second term requires the divergence of the Weyl tensor, and I have a nice formula for the divergence of the Weyl tensor. I'm struggling to compute the following portion: On page 126 of Jiaqi Chen's Doctoral thesis , he says the Ricci identity gives us equals to I could not derive this equality by the Ricci Identity . Could you help me establish the equality that Jiaqi Chen claimed? Thanks so much. Note that here our connection is torsion-free and metric compatible. Update: Finally, I did the calculation and it was nasty. I'm still wondering how Dr. Chen did this in just two lines. I'm still looking for a better/short calculation.","
P_{i j}=\frac{1}{n-2}\left(R_{i j}-\frac{1}{2(n-2)} R g_{i j}\right). 4 4. 
\begin{aligned}
\nabla^{j} B_{i j} &=\nabla^{j} ( \nabla^{k} \nabla_{k} P_{i j}-\nabla^{j} \nabla^{k} \nabla_{j} P_{i k})+\nabla^{j}\left(P^{k l} W_{i k j l}\right)  \\
&= (\nabla^{j} \nabla^{k} \nabla_{k} P_{i j}-\nabla^{k} \nabla^{j} \nabla_{k} P_{i j})+\nabla^{j}\left(P^{k l} W_{i k j l}\right) \end{aligned} . 
\begin{aligned}
(\nabla^{j} \nabla^{k} \nabla_{k} P_{i j}-\nabla^{k} \nabla^{j} \nabla_{k} P_{i j}) \end{aligned} . 
\begin{aligned}
(\nabla^{j} \nabla^{k} \nabla_{k} P_{i j}-\nabla^{k} \nabla^{j} \nabla_{k} P_{i j}) \end{aligned}  (\nabla^{j} P^{k l}) R_{i k j l}. \nabla","['differential-geometry', 'partial-differential-equations', 'conformal-geometry']"
42,"If every orthogonal projection of a manifold $M \subset \mathbb R^3$ on a plane is a disk, then $M$ is a sphere?","If every orthogonal projection of a manifold  on a plane is a disk, then  is a sphere?",M \subset \mathbb R^3 M,"Given  a 2-d manifold $M$ in $\mathbb R^3$ and a plane $\alpha$ in $\mathbb R^3$ . Assume that $M$ is smooth and has convex, simply-connected inner part. If we project $M$ orthogonally onto $\alpha$ we always get a round disk (maybe in different diameter as $\alpha$ changes), can we prove or disprove that $M$ is a sphere?","Given  a 2-d manifold in and a plane in . Assume that is smooth and has convex, simply-connected inner part. If we project orthogonally onto we always get a round disk (maybe in different diameter as changes), can we prove or disprove that is a sphere?",M \mathbb R^3 \alpha \mathbb R^3 M M \alpha \alpha M,"['differential-geometry', 'spheres', 'submanifold']"
43,Calculating the intersection of $u^2 - v^3$ with a 3-sphere,Calculating the intersection of  with a 3-sphere,u^2 - v^3,"For context, I'm coding a 3D visualisation of the Milnor fibration of a Trefoil knot. I've found some code https://www.unf.edu/~ddreibel/research/milnor/milnor-fibers.nb that calculates the intersection of the real and imaginary parts of $u^m - v^n$ with a 3-sphere radius $\sqrt2$ , and stereographically projects this to $\mathbb{R}^3$ . I don't understand the following substitution into $(x + iy)^m - (z + iw)^n$ (presumably to calculate the intersection): $$x \rightarrow \frac{\sqrt2 (-2+x^2+y^2+z^2)}{2+x^2 + y^2 + z^2}, y \rightarrow \frac{4x}{2+x^2 + y^2 + z^2},z \rightarrow \frac{4y}{2+x^2 + y^2 + z^2},w \rightarrow \frac{4z}{2+x^2 + y^2 + z^2}$$ after which the expression is multiplied by $(2+x^2+y^2+z^2)^{Max(m,n)}$ Any insights on how this works, or are there any alternative methods?","For context, I'm coding a 3D visualisation of the Milnor fibration of a Trefoil knot. I've found some code https://www.unf.edu/~ddreibel/research/milnor/milnor-fibers.nb that calculates the intersection of the real and imaginary parts of with a 3-sphere radius , and stereographically projects this to . I don't understand the following substitution into (presumably to calculate the intersection): after which the expression is multiplied by Any insights on how this works, or are there any alternative methods?","u^m - v^n \sqrt2 \mathbb{R}^3 (x + iy)^m - (z + iw)^n x \rightarrow \frac{\sqrt2 (-2+x^2+y^2+z^2)}{2+x^2 + y^2 + z^2}, y \rightarrow \frac{4x}{2+x^2 + y^2 + z^2},z \rightarrow \frac{4y}{2+x^2 + y^2 + z^2},w \rightarrow \frac{4z}{2+x^2 + y^2 + z^2} (2+x^2+y^2+z^2)^{Max(m,n)}","['differential-geometry', 'algebraic-geometry', 'mathematica', 'fibration', 'stereographic-projections']"
44,Higher order expansion of hypersurface about a point (beyond second fundamental form/extrinsic curvature),Higher order expansion of hypersurface about a point (beyond second fundamental form/extrinsic curvature),,"Consider a smooth, compact $(d-1)$ -dimensional hypersurface $S$ without boundary embedded in $\mathbb{R}^d$ . The surface $S$ can be described as the graph of a function $f(x_1,x_2,\cdots,x_{d-1})$ . Using the tangent plane to $S$ at some point $\mathbf{x}$ , endowed with an orthonormal basis $\{{\bf e}_1,\cdots,{\bf e}_{d-1}\}$ , one can Taylor expand the function $f$ around ${\bf x} = 0$ as \begin{aligned}\label{graph} f({\bf x })  =  \frac{1}{2} K_{ij} x^{i} x^{j} + \frac{1}{3!} A_{ijk}x^{i} x^{j} x^k +  \frac{1}{4!} B_{ijkl}x^{i} x^{j} x^k x^l+ O \left(| {\bf x} |^5 \right). \end{aligned} The quadratic term is the extrinsic curvature of $S$ as embedded in $\mathbb{R}^d$ , also called the second fundamental form. However, the higher order terms in the expansion are less known and I was wondering what the tensors $A$ and $B$ correspond to? I would guess they depend also on the extrinsic curvature (and its derivatives), but what is their exact form? I cannot find anything beyond second order. Disclaimer: physicist notations","Consider a smooth, compact -dimensional hypersurface without boundary embedded in . The surface can be described as the graph of a function . Using the tangent plane to at some point , endowed with an orthonormal basis , one can Taylor expand the function around as The quadratic term is the extrinsic curvature of as embedded in , also called the second fundamental form. However, the higher order terms in the expansion are less known and I was wondering what the tensors and correspond to? I would guess they depend also on the extrinsic curvature (and its derivatives), but what is their exact form? I cannot find anything beyond second order. Disclaimer: physicist notations","(d-1) S \mathbb{R}^d S f(x_1,x_2,\cdots,x_{d-1}) S \mathbf{x} \{{\bf e}_1,\cdots,{\bf e}_{d-1}\} f {\bf x} = 0 \begin{aligned}\label{graph}
f({\bf x })  =  \frac{1}{2} K_{ij} x^{i} x^{j} + \frac{1}{3!} A_{ijk}x^{i} x^{j} x^k +  \frac{1}{4!} B_{ijkl}x^{i} x^{j} x^k x^l+ O \left(| {\bf x} |^5 \right).
\end{aligned} S \mathbb{R}^d A B","['differential-geometry', 'submanifold']"
45,Bundle over $\mathbb CP^\infty$,Bundle over,\mathbb CP^\infty,"Good time of day. I have the following question Let $\eta$ -tautological bundle over $\mathbb CP^\infty$ . I don't understand why there is no such complex vector bundle $\xi$ over $\mathbb CP^\infty$ that bundle $\eta \bigoplus  \xi$ is trivial. I'm not sure about my attempt. I try to use Pontryagin classes for solving this task. If these classes are non-vanishing then this bundle will be non-trivial. We know that $2p(E \bigoplus F)=2p(E)\smile p(F)$ and it's famous fact that if $\theta$ is oriented real bundle of rank $2k$ then $p_k(\theta)=e(\theta)^2$ , where $e(\theta)^2$ is the square of Euler class. I don't know how to continue and compute this Thank you for your help","Good time of day. I have the following question Let -tautological bundle over . I don't understand why there is no such complex vector bundle over that bundle is trivial. I'm not sure about my attempt. I try to use Pontryagin classes for solving this task. If these classes are non-vanishing then this bundle will be non-trivial. We know that and it's famous fact that if is oriented real bundle of rank then , where is the square of Euler class. I don't know how to continue and compute this Thank you for your help",\eta \mathbb CP^\infty \xi \mathbb CP^\infty \eta \bigoplus  \xi 2p(E \bigoplus F)=2p(E)\smile p(F) \theta 2k p_k(\theta)=e(\theta)^2 e(\theta)^2,"['differential-geometry', 'algebraic-topology', 'complex-geometry', 'vector-bundles']"
46,Transitive Lie group action on the Hantzsche-Wendt Manifold,Transitive Lie group action on the Hantzsche-Wendt Manifold,,"Does there exists a smooth transitive action of a (finite dimensional) Lie group $ G $ on the Hantzsche-Wendt manifold? In other words, does there exists a Lie group $ G $ and a closed subgroup $ H $ such that $ G/H $ is diffeomorphic to the Hantzsche-Wendt manifold? If such a transitive actions exists my guess is that the group $ G $ is the Euclidean group $ E_3 $ or some subgroup of $ E_3 $ . Note that $ G $ must be noncompact as all three manifolds with transitive action by a compact group are already given here https://math.stackexchange.com/a/4364430/758507 Also the group must be at least dimension 4 since all manifolds which are the quotient of a three dimensional Lie group by a cocompact lattice are given here https://www.sciencedirect.com/science/article/pii/0166864181900183 Some background: The Hantzsche-Wendt manifold is a compact connected flat orientable 3 manifold. Like all compact flat manifolds it is normally covered by a torus, in this case $ T^3 $ . And  moreover (like all flat manifolds) it is aspherical. So it is determined by its fundamental group which is presented in https://arxiv.org/abs/math/0311476 as $$ \pi_1(M) \cong <X,Y:X=Y^2XY^2,Y=X^2YX^2> $$ where $ X,Y,Z=(XY)^{-1} $ are the generating screw motions which square to the translations $ t_1= X^2, t_2=Y^2,t_3=Z^2 $ given in Wolf theorem 3.5.5. Since $ M $ is compact and flat $ \pi_1 $ is a Bieberbach group, indeed it fits into the short exact sequence $$ 1 \to \mathbb{Z}^3 \to \pi_1(M) \to C_2 \times C_2 \to 1 $$ so $ M $ has holonomy $ C_2 \times C_2 $ . Abelianizing $ \pi_1 $ we can see that the first homology is $$ H_1(M,\mathbb{Z})\cong C_4 \times C_4  $$ From the short exact sequence above we can see that $ \pi_1 $ is virtually abelian and solvable.","Does there exists a smooth transitive action of a (finite dimensional) Lie group on the Hantzsche-Wendt manifold? In other words, does there exists a Lie group and a closed subgroup such that is diffeomorphic to the Hantzsche-Wendt manifold? If such a transitive actions exists my guess is that the group is the Euclidean group or some subgroup of . Note that must be noncompact as all three manifolds with transitive action by a compact group are already given here https://math.stackexchange.com/a/4364430/758507 Also the group must be at least dimension 4 since all manifolds which are the quotient of a three dimensional Lie group by a cocompact lattice are given here https://www.sciencedirect.com/science/article/pii/0166864181900183 Some background: The Hantzsche-Wendt manifold is a compact connected flat orientable 3 manifold. Like all compact flat manifolds it is normally covered by a torus, in this case . And  moreover (like all flat manifolds) it is aspherical. So it is determined by its fundamental group which is presented in https://arxiv.org/abs/math/0311476 as where are the generating screw motions which square to the translations given in Wolf theorem 3.5.5. Since is compact and flat is a Bieberbach group, indeed it fits into the short exact sequence so has holonomy . Abelianizing we can see that the first homology is From the short exact sequence above we can see that is virtually abelian and solvable."," G   G   H   G/H   G   E_3   E_3   G   T^3  
\pi_1(M) \cong <X,Y:X=Y^2XY^2,Y=X^2YX^2>
  X,Y,Z=(XY)^{-1}   t_1= X^2, t_2=Y^2,t_3=Z^2   M   \pi_1  
1 \to \mathbb{Z}^3 \to \pi_1(M) \to C_2 \times C_2 \to 1
  M   C_2 \times C_2   \pi_1  
H_1(M,\mathbb{Z})\cong C_4 \times C_4 
  \pi_1 ","['differential-geometry', 'riemannian-geometry', 'lie-groups', 'differential-topology', 'homogeneous-spaces']"
47,Restriction of vector bundle to norm 1 is a covering map,Restriction of vector bundle to norm 1 is a covering map,,"Given a mainfold $M$ , the vector bundle \begin{equation*} \pi:\wedge^k T^*M = \sqcup_{p \in M} \wedge^k T_p^*M \rightarrow M \end{equation*} has the property that its section are exactly the $k$ -forms on $M$ . We assume that $M$ is connected and has dimension $m$ . I have already proven that the vector bundle $\wedge^m T^*M$ has rank 1. Then we endow every fiber of the total space $\wedge^m T^*M$ with an inner product varying smoothly (i.e. for any two smooth sections, their inner product is a smooth function on $M$ ). Then $M'$ is the submanifold of $\wedge^m T^*M$ consisting of the vectors with norm 1. I need to show that \begin{equation*} \pi|_{M'}:M' \rightarrow M \end{equation*} is a smooth covering map. I have already proven that this map is both smooth and surjective. This means that I only need to prove that each point of $M$ has a neighborhood $U$ such that $\pi|_{M'}$ maps each connected component of $\pi|_{M'}^{-1}(U)$ diffeomorphically onto U. Can anyone tell me how to do this or where to start?","Given a mainfold , the vector bundle has the property that its section are exactly the -forms on . We assume that is connected and has dimension . I have already proven that the vector bundle has rank 1. Then we endow every fiber of the total space with an inner product varying smoothly (i.e. for any two smooth sections, their inner product is a smooth function on ). Then is the submanifold of consisting of the vectors with norm 1. I need to show that is a smooth covering map. I have already proven that this map is both smooth and surjective. This means that I only need to prove that each point of has a neighborhood such that maps each connected component of diffeomorphically onto U. Can anyone tell me how to do this or where to start?","M \begin{equation*}
\pi:\wedge^k T^*M = \sqcup_{p \in M} \wedge^k T_p^*M \rightarrow M
\end{equation*} k M M m \wedge^m T^*M \wedge^m T^*M M M' \wedge^m T^*M \begin{equation*}
\pi|_{M'}:M' \rightarrow M
\end{equation*} M U \pi|_{M'} \pi|_{M'}^{-1}(U)","['differential-geometry', 'manifolds', 'vector-bundles', 'covering-spaces', 'diffeomorphism']"
48,Area of minimal submanifold in $S^3$,Area of minimal submanifold in,S^3,"I am asked to prove that lower bound of area of compact minimal submanifold with no boundary in $S^3$ is $4\pi$ . Only idea i have is Gauss equation using orthonormal frame $e_1,e_2$ . We have $$1=K+|B_{12}|^2-\langle B_{11},B_{22}\rangle,$$ where $K$ is the Gauss curvature of $M$ and $B_{ij}=B(e_i,e_j)$ is the second fundamental form. Since $M$ is minimal, $B_{11}=-B_{22}$ . We get: $1=K+||B||^2/2$ . Thus by Gauss-Bonnet, $$\mathrm{Vol}(M)=2\pi \chi(M) + \frac{1}{2}\int_{M}^{} \|B\|^2 \,d\mathrm{Vol}.$$ But I can not estimate the second fundamental form.","I am asked to prove that lower bound of area of compact minimal submanifold with no boundary in is . Only idea i have is Gauss equation using orthonormal frame . We have where is the Gauss curvature of and is the second fundamental form. Since is minimal, . We get: . Thus by Gauss-Bonnet, But I can not estimate the second fundamental form.","S^3 4\pi e_1,e_2 1=K+|B_{12}|^2-\langle B_{11},B_{22}\rangle, K M B_{ij}=B(e_i,e_j) M B_{11}=-B_{22} 1=K+||B||^2/2 \mathrm{Vol}(M)=2\pi \chi(M) + \frac{1}{2}\int_{M}^{} \|B\|^2 \,d\mathrm{Vol}.","['differential-geometry', 'riemannian-geometry', 'minimal-surfaces']"
49,Do carmo: theorem of turning tangents --- notational confusion,Do carmo: theorem of turning tangents --- notational confusion,,"Theorem statement Let $\mathbf x: U \subseteq \mathbb R^2 \to S \subseteq \mathbb R^3$ be a parametrization compatible with the orientation of $S$ . Assume further that $U$ is homeomorphic to the open disk in the plane. Let $\alpha: [0, l] \to \mathbf x(U) \subseteq S$ be a simple, closed, piecewise regular parametried curve with vertices $\alpha(t_i)$ and external angles $\theta_i, i = 0,\dots,k$ . Let $\phi: [t_i, t_{i+1}] \to R$ be differentiable functions which measure at each $t \in [t_i, t_{i+}]$ the positive angle from $\mathbf x_u$ to $\alpha'(t)$ . Theorem of turning tangents : With the above notation: $$ \sum_{i=0}^k (\phi_i(t_{i+1}) - \phi_i(t_i)) + \sum_{i=0}^k \theta_i = \pm 2 \pi $$ Questions What is the quantity $\phi_i$ ? I don't follow from the definition what $\mathbf x_u$ , and what is it trying to capture by considering the angle between this $\mathbf x_u$ and $\alpha'(t)$ ? Where can I find a proof of this exact theorem? Do Carmo states this without proof. I would like to find a proof of this exact statement of the theorem --- I have found other proofs that invoke the gaussian curvature. Picture for reference","Theorem statement Let be a parametrization compatible with the orientation of . Assume further that is homeomorphic to the open disk in the plane. Let be a simple, closed, piecewise regular parametried curve with vertices and external angles . Let be differentiable functions which measure at each the positive angle from to . Theorem of turning tangents : With the above notation: Questions What is the quantity ? I don't follow from the definition what , and what is it trying to capture by considering the angle between this and ? Where can I find a proof of this exact theorem? Do Carmo states this without proof. I would like to find a proof of this exact statement of the theorem --- I have found other proofs that invoke the gaussian curvature. Picture for reference","\mathbf x: U \subseteq \mathbb R^2 \to S \subseteq \mathbb R^3 S U \alpha: [0, l] \to \mathbf x(U) \subseteq S \alpha(t_i) \theta_i, i = 0,\dots,k \phi: [t_i, t_{i+1}] \to R t \in [t_i, t_{i+}] \mathbf x_u \alpha'(t) 
\sum_{i=0}^k (\phi_i(t_{i+1}) - \phi_i(t_i)) + \sum_{i=0}^k \theta_i = \pm 2 \pi
 \phi_i \mathbf x_u \mathbf x_u \alpha'(t)","['differential-geometry', 'differential-topology', 'surfaces']"
50,What's so hyperbolic about hyperbolic sets?,What's so hyperbolic about hyperbolic sets?,,"In dynamics, we have the notion of a ""hyperbolic set"" for a diffeomorphism $f:M\to M$ of a Riemannian manifold. I am trying to connect this to my existing ideas surrounding the term ""hyperbolic"". To my understanding, $M$ itself need not be a hyperbolic manifold $^*$ , but maybe there is some more distant connection $^{**}$ at work? $^*$ Consider the action of $\begin{pmatrix}2&1\\1&1\end{pmatrix}$ on the torus. $^{**}$ Heh [EDIT] Someone wanted to know what a hyperbolic set was so I'm adding the definition here. Let $M$ be a Riemannian manifold and let $f:M\to M$ be a diffeomorphism. Then $\Lambda \subset M$ is hyperbolic if there are constants $C> 0$ and $\lambda \in (0,1)$ such that for every $x\in \Lambda$ , we can write $T_xM = E^u(x) \oplus E^s(x)$ . We require that $\|df^n_x v\| \le C\lambda^n \|v\|$ for $v\in E^s(x)$ and $n\ge 0$ , $\|df^{-n}_x v\| \le C\lambda^n \|v\|$ for $v\in E^u(x)$ and $n\ge 0$ , $df_x(E^u(x)) = E^u(f(x))$ , and $df_x(E^s(x)) = E^s(f(x))$ . In English, we have expanding and contracting directions. Standard example is, give me some $A\in GL_n(\mathbb{Z})$ with no eigenvalues on the unit circle. It'll induce an automorphism of the torus $\mathbb{R}^n/\mathbb{Z}^n$ . Then $\mathbb{T}^n$ is a hyperbolic set with respect to this automorphism, with the expanding directions being the sum of eigenspaces with eigenvalue $> 1$ , and the contracting directions being the sum of eigenspaces with eigenvalue $< 1$ .","In dynamics, we have the notion of a ""hyperbolic set"" for a diffeomorphism of a Riemannian manifold. I am trying to connect this to my existing ideas surrounding the term ""hyperbolic"". To my understanding, itself need not be a hyperbolic manifold , but maybe there is some more distant connection at work? Consider the action of on the torus. Heh [EDIT] Someone wanted to know what a hyperbolic set was so I'm adding the definition here. Let be a Riemannian manifold and let be a diffeomorphism. Then is hyperbolic if there are constants and such that for every , we can write . We require that for and , for and , , and . In English, we have expanding and contracting directions. Standard example is, give me some with no eigenvalues on the unit circle. It'll induce an automorphism of the torus . Then is a hyperbolic set with respect to this automorphism, with the expanding directions being the sum of eigenspaces with eigenvalue , and the contracting directions being the sum of eigenspaces with eigenvalue .","f:M\to M M ^* ^{**} ^* \begin{pmatrix}2&1\\1&1\end{pmatrix} ^{**} M f:M\to M \Lambda \subset M C> 0 \lambda \in (0,1) x\in \Lambda T_xM = E^u(x) \oplus E^s(x) \|df^n_x v\| \le C\lambda^n \|v\| v\in E^s(x) n\ge 0 \|df^{-n}_x v\| \le C\lambda^n \|v\| v\in E^u(x) n\ge 0 df_x(E^u(x)) = E^u(f(x)) df_x(E^s(x)) = E^s(f(x)) A\in GL_n(\mathbb{Z}) \mathbb{R}^n/\mathbb{Z}^n \mathbb{T}^n > 1 < 1","['differential-geometry', 'definition', 'dynamical-systems']"
51,Prove that $M=\{ x\in S^{n-1} \ | \ f(x)=0\}$ is an embedded submanifold of $S^{n-1}$.,Prove that  is an embedded submanifold of .,M=\{ x\in S^{n-1} \ | \ f(x)=0\} S^{n-1},"Let $n>1$ . Define $f:\mathbb{R}^n \to \mathbb{R}$ by $$f(x_1,,x_n)=x_1^3++x_n^3$$ Prove that $$M=\{ x\in S^{n-1} \ | \ f(x)=0\}$$ is an embedded submanifold of $S^{n-1}$ . What is its dimension? $S^{n-1}$ is the unit sphere in $\mathbb{R^n}$ . My attempt: We have $M=f^{-1}(0)$ . The Jacobian matrix $[df_*]=\begin{pmatrix}  3x_1^2 &  & 3x_n^2  \end{pmatrix}$ Since $x\in S^{n-1}$ , we have $x_1^2++x_n^2=1$ , hence $x_1,, x_n$ cannot be all zeros and then $[df_*]$ has a full rank. As a result, $M=f^{-1}(0)$ is an embedded submanifold of dim $1$ . Is it correct? Thank you!","Let . Define by Prove that is an embedded submanifold of . What is its dimension? is the unit sphere in . My attempt: We have . The Jacobian matrix Since , we have , hence cannot be all zeros and then has a full rank. As a result, is an embedded submanifold of dim . Is it correct? Thank you!","n>1 f:\mathbb{R}^n \to \mathbb{R} f(x_1,,x_n)=x_1^3++x_n^3 M=\{ x\in S^{n-1} \ | \ f(x)=0\} S^{n-1} S^{n-1} \mathbb{R^n} M=f^{-1}(0) [df_*]=\begin{pmatrix} 
3x_1^2 &  & 3x_n^2 
\end{pmatrix} x\in S^{n-1} x_1^2++x_n^2=1 x_1,, x_n [df_*] M=f^{-1}(0) 1","['differential-geometry', 'smooth-manifolds', 'submanifold']"
52,Why is the Kaluza-Klein ansatz the natural choice?,Why is the Kaluza-Klein ansatz the natural choice?,,"In Kaluza-Klein theory we can choose a parametrisation for the 5-dimensional metric: $$d\hat{s}^2 \equiv \hat{g}_{ab} dx^a dx^b = g_{\mu\nu}dx^\mu dx^\nu + \phi^2(dz + A_\mu dx^\mu)^2 $$ where $g_{\mu\nu}$ is the metric for the 4 ""large"" dimensions (the base manifold) and $z$ is the coordinate running along the fifth dimension (the fiber). Greek indices run from 0 to 3 while latin indices run from 0 to 4 ( $z\equiv x^4$ ). The scalar $\phi$ parametrises the size of the extra dimension. I have heard that this choice of metric is ""natural"" from the fiber bundle perspective, within which the 5D spacetime is considered as a $U(1)$ -principle bundle and $A_\mu$ are the components of a connection 1-form defined on that bundle. For example, here the author says that this choice of metric: Preserves the split between vertical and horizontal vectors Has metric on the horizontal subspace isomorphic to the metric on the base space Has metric on the vertical subspace isomorphic to some metric on the Lie algebra of the structure group ( $U(1)$ in this case) First question: I am not sure I understand these conditions properly so would appreciate any further explanation. I believe that the connection $A$ is defined to vanish on horizontal vectors so my best guess for the first point is that $\hat{g}_{a\nu} V^a = g_{\mu\nu}V^\mu$ and $\hat{g}_{a4} V^a = 0$ for a horizontal vector $V$ . And $\hat{g}_{ab}V^a = \hat{g}_{4b}V^4$ for a vertical vector $V$ . For the second and third points I don't know what the definition of an isomorphism between metrics is. I would guess $\phi^2 dz^2$ is the metric on the vertical subspace and $g_{\mu\nu}$ is the metric on the horizontal subspace, so can see that these are equivalent in some sense to what they're supposed to be equivalent to, though I am shaky on the formalities. Second question: My understanding is that there is a difference between a connection defined on the whole bundle, and the ""local connection"" defined on the base manifold (see e.g. ""Pull back via trivializing section"" here ). Which one of these is $A$ technically? Third question: The term $dz + A$ in the metric looks very similar to a gauge covariant derivative (but with $dz$ replacing a partial derivative). What's the explicit connection between the two? Final question: What are the differences between Kaluza-Klein theory and regular electromagnetism, considered from the fiber bundle perspective? (Have reposted from the physics stack exchange as the question could be more relevant here)","In Kaluza-Klein theory we can choose a parametrisation for the 5-dimensional metric: where is the metric for the 4 ""large"" dimensions (the base manifold) and is the coordinate running along the fifth dimension (the fiber). Greek indices run from 0 to 3 while latin indices run from 0 to 4 ( ). The scalar parametrises the size of the extra dimension. I have heard that this choice of metric is ""natural"" from the fiber bundle perspective, within which the 5D spacetime is considered as a -principle bundle and are the components of a connection 1-form defined on that bundle. For example, here the author says that this choice of metric: Preserves the split between vertical and horizontal vectors Has metric on the horizontal subspace isomorphic to the metric on the base space Has metric on the vertical subspace isomorphic to some metric on the Lie algebra of the structure group ( in this case) First question: I am not sure I understand these conditions properly so would appreciate any further explanation. I believe that the connection is defined to vanish on horizontal vectors so my best guess for the first point is that and for a horizontal vector . And for a vertical vector . For the second and third points I don't know what the definition of an isomorphism between metrics is. I would guess is the metric on the vertical subspace and is the metric on the horizontal subspace, so can see that these are equivalent in some sense to what they're supposed to be equivalent to, though I am shaky on the formalities. Second question: My understanding is that there is a difference between a connection defined on the whole bundle, and the ""local connection"" defined on the base manifold (see e.g. ""Pull back via trivializing section"" here ). Which one of these is technically? Third question: The term in the metric looks very similar to a gauge covariant derivative (but with replacing a partial derivative). What's the explicit connection between the two? Final question: What are the differences between Kaluza-Klein theory and regular electromagnetism, considered from the fiber bundle perspective? (Have reposted from the physics stack exchange as the question could be more relevant here)",d\hat{s}^2 \equiv \hat{g}_{ab} dx^a dx^b = g_{\mu\nu}dx^\mu dx^\nu + \phi^2(dz + A_\mu dx^\mu)^2  g_{\mu\nu} z z\equiv x^4 \phi U(1) A_\mu U(1) A \hat{g}_{a\nu} V^a = g_{\mu\nu}V^\mu \hat{g}_{a4} V^a = 0 V \hat{g}_{ab}V^a = \hat{g}_{4b}V^4 V \phi^2 dz^2 g_{\mu\nu} A dz + A dz,"['differential-geometry', 'fiber-bundles', 'general-relativity', 'electromagnetism']"
53,$g^{ij} \nabla_{\partial_j} \nabla_{\partial_i} V$?,?,g^{ij} \nabla_{\partial_j} \nabla_{\partial_i} V,"Question: How to simplify the following local expression: \begin{equation}\tag{*}   g^{ij} \Big( \partial_j (\partial_i V^k + \Gamma_{im}^k V^m) - \Gamma_{ij}^l (\partial_l V^k + \Gamma_{lm}^k V^m) \Big), \end{equation} where $V$ is a vector field on a Riemannian manifold $(M,g)$ , $\Gamma$ is the Christoffel symbols. Motivation: I am trying to get through the old paper of Dohrn and Guerra , which has the following quantity in its eqaution (12): \begin{equation}\tag{**}   g^{ij} \nabla_{\partial_j} \nabla_{\partial_i} V, \end{equation} where $\nabla$ is the Riemannian covariant derivative. According to my derivation from the preceding text of the paper, the quantity $(**)$ should coorespond to the local expression $(*)$ . However, a simple application of definitions gives the local expression of $(**)$ as follows, \begin{equation}   g^{ij} \nabla_{\partial_j} \nabla_{\partial_i} V = g^{ij} \Big( \partial_j (\partial_i V^k + \Gamma_{im}^k V^m) + \Gamma_{jm}^k (\partial_i V^m + \Gamma_{il}^m V^l) \Big) \partial_k, \end{equation} which does not coincide with (*). So I strongly suspect that the expression (**) in the paper is not correct. But I still want to know if it is possible to simplify the local expression (*) to a quantity with a global expression, which may be similar to (**) ? TIA...","Question: How to simplify the following local expression: where is a vector field on a Riemannian manifold , is the Christoffel symbols. Motivation: I am trying to get through the old paper of Dohrn and Guerra , which has the following quantity in its eqaution (12): where is the Riemannian covariant derivative. According to my derivation from the preceding text of the paper, the quantity should coorespond to the local expression . However, a simple application of definitions gives the local expression of as follows, which does not coincide with (*). So I strongly suspect that the expression (**) in the paper is not correct. But I still want to know if it is possible to simplify the local expression (*) to a quantity with a global expression, which may be similar to (**) ? TIA...","\begin{equation}\tag{*}
  g^{ij} \Big( \partial_j (\partial_i V^k + \Gamma_{im}^k V^m) - \Gamma_{ij}^l (\partial_l V^k + \Gamma_{lm}^k V^m) \Big),
\end{equation} V (M,g) \Gamma \begin{equation}\tag{**}
  g^{ij} \nabla_{\partial_j} \nabla_{\partial_i} V,
\end{equation} \nabla (**) (*) (**) \begin{equation}
  g^{ij} \nabla_{\partial_j} \nabla_{\partial_i} V = g^{ij} \Big( \partial_j (\partial_i V^k + \Gamma_{im}^k V^m) + \Gamma_{jm}^k (\partial_i V^m + \Gamma_{il}^m V^l) \Big) \partial_k,
\end{equation}","['differential-geometry', 'riemannian-geometry', 'connections']"
54,Do a negative Gaussian curvature help with the stability of a surface?,Do a negative Gaussian curvature help with the stability of a surface?,,"I found in this magazine the statement ""[...] ruled surfaces are statically efficient, especially in the case of skewed ruled surfaces, which are very stable due to a generally negative Gaussian curvature"". Why would a negative Gaussian curvature imply (or help with) the stability of a surface? I did not find a mathematical argument for the claim in the magazine, nor any mention of the same fact elsewhere. Is it really true? I'm interested in this question because I'm studying ruled surfaces (which have non-positive Gaussian curvature) and their applications in architecture and product design in general, and if such surfaces have strength or stability advantages, I'd be very interested to know.","I found in this magazine the statement ""[...] ruled surfaces are statically efficient, especially in the case of skewed ruled surfaces, which are very stable due to a generally negative Gaussian curvature"". Why would a negative Gaussian curvature imply (or help with) the stability of a surface? I did not find a mathematical argument for the claim in the magazine, nor any mention of the same fact elsewhere. Is it really true? I'm interested in this question because I'm studying ruled surfaces (which have non-positive Gaussian curvature) and their applications in architecture and product design in general, and if such surfaces have strength or stability advantages, I'd be very interested to know.",,"['differential-geometry', 'physics']"
55,What is the relationship between these two definitions of generating functions?,What is the relationship between these two definitions of generating functions?,,"I'm doing my bachelor's thesis on Integrable Hamiltonian Systems, and one important part of the thesis will be proving the Liouville theorem. For this theorem I'm using the book by Arnold ""Mathematical Methods of Classical Mechanics"", but up to this point I've used the book by Ana Cannas ""Lectures on symplectic geometry"". The problem is: in the book by Ana Cannas, the equations that describe the symplectomorphism $\varphi: T^*X:=M=(x,p)\rightarrow T^*Y:=N=(y,q)$ that a generating function $f$ generates are the following (lecture 4). \begin{align*}     p_i= &\frac{\partial f}{\partial x_i}(x,y) \\     q_i=-&\frac{\partial f}{\partial y_i}(x,y)   \end{align*} We have to solve this system of equations for the coordinates $y_i$ and $q_i$ . But according to Arnold's book (page 284, section 50 C), the equations that describe the symplectomorphism would be (using the aforementioned notation, not the one that Arnold uses) \begin{align*}   x_i=&\frac{\partial f}{\partial p_i} \\   q_i=&\frac{\partial f}{\partial y_i} \end{align*} In the book by Ana Cannas, the generating function is defined as a function $f \in C^\infty(X\times Y)$ and that generates a closed form $df$ , whose image is a lagrangian submanifold of $T^*(X\times Y)$ then we make the 'twist' of the submanifold, which must be a graph of a symplectomorphism... . If anyone can help me to understand how this relates to the view that Arnold has on generating functions it would be of great help, since I need this to understand the construction of action-angle variables. Thanks in advance for the answers.","I'm doing my bachelor's thesis on Integrable Hamiltonian Systems, and one important part of the thesis will be proving the Liouville theorem. For this theorem I'm using the book by Arnold ""Mathematical Methods of Classical Mechanics"", but up to this point I've used the book by Ana Cannas ""Lectures on symplectic geometry"". The problem is: in the book by Ana Cannas, the equations that describe the symplectomorphism that a generating function generates are the following (lecture 4). We have to solve this system of equations for the coordinates and . But according to Arnold's book (page 284, section 50 C), the equations that describe the symplectomorphism would be (using the aforementioned notation, not the one that Arnold uses) In the book by Ana Cannas, the generating function is defined as a function and that generates a closed form , whose image is a lagrangian submanifold of then we make the 'twist' of the submanifold, which must be a graph of a symplectomorphism... . If anyone can help me to understand how this relates to the view that Arnold has on generating functions it would be of great help, since I need this to understand the construction of action-angle variables. Thanks in advance for the answers.","\varphi: T^*X:=M=(x,p)\rightarrow T^*Y:=N=(y,q) f \begin{align*}
    p_i= &\frac{\partial f}{\partial x_i}(x,y) \\
    q_i=-&\frac{\partial f}{\partial y_i}(x,y)  
\end{align*} y_i q_i \begin{align*}
  x_i=&\frac{\partial f}{\partial p_i} \\
  q_i=&\frac{\partial f}{\partial y_i}
\end{align*} f \in C^\infty(X\times Y) df T^*(X\times Y)","['differential-geometry', 'dynamical-systems', 'classical-mechanics', 'symplectic-geometry', 'integrable-systems']"
56,Volume form on compact Lie group,Volume form on compact Lie group,,"Suppose $G$ is a compact Lie group, $\omega \in \Omega^n(G)$ is a left-invariant volume form and let $i:G \rightarrow G$ be the inversion $i(g)=g^{-1}$ . I have previously shown that $r^*_g \omega$ is left-invariant as well, where $r_g$ is multiplication on the right and so $r^*_g \omega=f(g)\omega$ . Moreover, since this $f$ is a homomorphism, by compactness, it follows that $f(g)=1$ . I also need to prove that $i^* \omega = \omega$ or $-\omega$ . I think I need to use the fact that $i^* \omega$ is also left-invariant. I can see this, because $$r^*_h i^* \omega=(i \circ r_h)^* \omega=(l_{h^{-1}}\circ i)^* \omega=i^* l_{h^{-1}}^* \omega=i^* \omega$$ since $\omega$ is left-invariant. How can I use this to show $i^* \omega = \omega$ or $-\omega$ ?","Suppose is a compact Lie group, is a left-invariant volume form and let be the inversion . I have previously shown that is left-invariant as well, where is multiplication on the right and so . Moreover, since this is a homomorphism, by compactness, it follows that . I also need to prove that or . I think I need to use the fact that is also left-invariant. I can see this, because since is left-invariant. How can I use this to show or ?",G \omega \in \Omega^n(G) i:G \rightarrow G i(g)=g^{-1} r^*_g \omega r_g r^*_g \omega=f(g)\omega f f(g)=1 i^* \omega = \omega -\omega i^* \omega r^*_h i^* \omega=(i \circ r_h)^* \omega=(l_{h^{-1}}\circ i)^* \omega=i^* l_{h^{-1}}^* \omega=i^* \omega \omega i^* \omega = \omega -\omega,"['differential-geometry', 'lie-groups', 'smooth-manifolds', 'differential-forms', 'pullback']"
57,A polygon with constant angular momentum bounds a circle,A polygon with constant angular momentum bounds a circle,,"Let $\alpha:[0,L] \to \mathbb{R}^2$ be a piecewise affine map satisfying $\alpha(0)= \alpha(L)$ and $|\dot \alpha|=1$ . Supopse that $\alpha(t) \times \dot \alpha(t)$ is constant. How to prove that $\operatorname{Image}(\alpha)$ is a tangential polygon, i.e. a polygon whose edges are all tangent to a fixed circle, centered at the origin? It suffices to prove that for each subinterval $[a,b] \subseteq [0,L]$ where $\alpha|_{[a,b]}$ is affine, there exists a $t_0 \in (a,b)$ such that $\dot \alpha(t_0) \perp \alpha(t_0)$ . Indeed, if this is the case, then $|\alpha(t_0)|=|\alpha(t) \times \dot \alpha(t)|=C$ is independent of the segment $[a,b]$ chosen. Thus, every ""edge"" $\alpha([a,b])$ , contains a point $P_{a,b}=\alpha(t_0)$ on the circle with radius $C$ , and the edge is perpendicular to radius at $P_{a,b}$ , i.e. it is tangent to the circle at $P_{a,b}$ . I am not sure how to prove the bold statement. I think we need to use somehow the fact that the polygon ""closes"". The converse implication is easy: If there exists such a circle with radius $R$ , then $|\alpha(t) \times \dot \alpha(t)|=R$ is constant: Indeed, suppose that $\alpha(t_0)$ lies on the circle -- so it is a tangency point. Then $\dot \alpha(t_0) \perp \alpha(t_0)$ , and $|\alpha(t_0)|=R$ . Let $t$ satisfies $\dot \alpha(t)=\dot \alpha(t_0)$ , i.e. $\alpha(t)$ belongs to the same edge as $\alpha(t_0)$ . Then $\alpha(t)=\alpha(t_0)+\beta(t)$ , where $\beta(t) || \dot \alpha(t_0)$ , so $$ \alpha(t) \times \dot \alpha(t)=\big( \alpha(t_0)+\beta(t) \big) \times \dot \alpha(t_0)=\alpha(t_0) \times \dot \alpha(t_0), $$ which implies $|\alpha(t) \times \dot \alpha(t)|=R$ .","Let be a piecewise affine map satisfying and . Supopse that is constant. How to prove that is a tangential polygon, i.e. a polygon whose edges are all tangent to a fixed circle, centered at the origin? It suffices to prove that for each subinterval where is affine, there exists a such that . Indeed, if this is the case, then is independent of the segment chosen. Thus, every ""edge"" , contains a point on the circle with radius , and the edge is perpendicular to radius at , i.e. it is tangent to the circle at . I am not sure how to prove the bold statement. I think we need to use somehow the fact that the polygon ""closes"". The converse implication is easy: If there exists such a circle with radius , then is constant: Indeed, suppose that lies on the circle -- so it is a tangency point. Then , and . Let satisfies , i.e. belongs to the same edge as . Then , where , so which implies .","\alpha:[0,L] \to \mathbb{R}^2 \alpha(0)= \alpha(L) |\dot \alpha|=1 \alpha(t) \times \dot \alpha(t) \operatorname{Image}(\alpha) [a,b] \subseteq [0,L] \alpha|_{[a,b]} t_0 \in (a,b) \dot \alpha(t_0) \perp \alpha(t_0) |\alpha(t_0)|=|\alpha(t) \times \dot \alpha(t)|=C [a,b] \alpha([a,b]) P_{a,b}=\alpha(t_0) C P_{a,b} P_{a,b} R |\alpha(t) \times \dot \alpha(t)|=R \alpha(t_0) \dot \alpha(t_0) \perp \alpha(t_0) |\alpha(t_0)|=R t \dot \alpha(t)=\dot \alpha(t_0) \alpha(t) \alpha(t_0) \alpha(t)=\alpha(t_0)+\beta(t) \beta(t) || \dot \alpha(t_0) 
\alpha(t) \times \dot \alpha(t)=\big( \alpha(t_0)+\beta(t) \big) \times \dot \alpha(t_0)=\alpha(t_0) \times \dot \alpha(t_0),
 |\alpha(t) \times \dot \alpha(t)|=R","['differential-geometry', 'euclidean-geometry', 'circles', 'symmetry', 'polygons']"
58,Is the definition of angular momentum $\vec{L} = \vec{r} \times \vec{p}$ rigorous?,Is the definition of angular momentum  rigorous?,\vec{L} = \vec{r} \times \vec{p},"Let $\vec{r}$ be the position vector in $3\mathrm{D}$ Euclidean space $\mathbb{R}^3$ , and $\vec{p}$ the linear momentum of point mass at $P\in\mathbb{R}^3$ . The angular momentum $\vec{L}$ of that point mass with respect to the origin is defined to be $$\vec{L} = \vec{r}\times\vec{p} = m\vec{r}\times\vec{v}.$$ This feels weird to me, as $\vec{r}$ is a vector in $\mathbb{R}^3$ and $\vec{v}$ is a vector in $T_P\mathbb{R}^3$ ... aren't they? If so, we shouldn't be able to take their cross product, so how can this definition be fixed for the operations to make sense?","Let be the position vector in Euclidean space , and the linear momentum of point mass at . The angular momentum of that point mass with respect to the origin is defined to be This feels weird to me, as is a vector in and is a vector in ... aren't they? If so, we shouldn't be able to take their cross product, so how can this definition be fixed for the operations to make sense?",\vec{r} 3\mathrm{D} \mathbb{R}^3 \vec{p} P\in\mathbb{R}^3 \vec{L} \vec{L} = \vec{r}\times\vec{p} = m\vec{r}\times\vec{v}. \vec{r} \mathbb{R}^3 \vec{v} T_P\mathbb{R}^3,"['differential-geometry', 'physics']"
59,Issues with the $\overline{ \partial}$-operator and the almost complex structure of a hermitian manifold,Issues with the -operator and the almost complex structure of a hermitian manifold,\overline{ \partial},"I'm working through ""Lecture on Kahler Geometry"" by Andrei Moroianu, and am stuck on Lemma 11.7 (p. 85). The lemma says: For every section $Y$ of the complex vector bundle $(TM, J)$ the $\overline{\partial}$ -operator, as a $TM$ -valued $(0,1)$ -form is given by $$\overline{\partial}^\nabla Y (X) := \frac{1}{2} (\nabla_X Y + J \nabla_{JX}Y + J(\nabla_YJ)X)$$ where $\nabla$ denotes the Levi-Civita connection of any Hermitian metric $h$ on $M$ . The proof starts by proving the Leibniz rule, recalling that $(\overline{\partial} f) (X) = \frac{1}{2} \partial_{(X+iJX)} f$ , then $$(\overline{\partial}^\nabla f Y)(X)  =   f \frac{1}{2} (\nabla_X Y + J \nabla_{JX}Y + J(\nabla_YJ)X) + \frac{1}{2} ((\partial_Xf)Y + (\partial_{JX}f)JY) = f \overline{\partial}^\nabla Y(X) + \overline{\partial}f (X)Y$$ My question is how $\overline{\partial}f (X)Y = (\frac{1}{2} ((\partial_Xf)Y + (\partial_{JX}f)JY))$ when we're given $(\overline{\partial} f) (X) = \frac{1}{2} \partial_{(X+iJX)} f$ ? Any help would be greatly apperiated.","I'm working through ""Lecture on Kahler Geometry"" by Andrei Moroianu, and am stuck on Lemma 11.7 (p. 85). The lemma says: For every section of the complex vector bundle the -operator, as a -valued -form is given by where denotes the Levi-Civita connection of any Hermitian metric on . The proof starts by proving the Leibniz rule, recalling that , then My question is how when we're given ? Any help would be greatly apperiated.","Y (TM, J) \overline{\partial} TM (0,1) \overline{\partial}^\nabla Y (X) := \frac{1}{2} (\nabla_X Y + J \nabla_{JX}Y + J(\nabla_YJ)X) \nabla h M (\overline{\partial} f) (X) = \frac{1}{2} \partial_{(X+iJX)} f (\overline{\partial}^\nabla f Y)(X)  = 
 f \frac{1}{2} (\nabla_X Y + J \nabla_{JX}Y + J(\nabla_YJ)X) + \frac{1}{2} ((\partial_Xf)Y + (\partial_{JX}f)JY) = f \overline{\partial}^\nabla Y(X) + \overline{\partial}f (X)Y \overline{\partial}f (X)Y = (\frac{1}{2} ((\partial_Xf)Y + (\partial_{JX}f)JY)) (\overline{\partial} f) (X) = \frac{1}{2} \partial_{(X+iJX)} f","['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
60,Is there a smooth homotopy lifting theorem?,Is there a smooth homotopy lifting theorem?,,"Given a smooth map $p\colon E \to B$ of smooth manifolds with the continuous homotopy lifting property, does $p$ satisfy the smooth homotopy lifting property?","Given a smooth map of smooth manifolds with the continuous homotopy lifting property, does satisfy the smooth homotopy lifting property?",p\colon E \to B p,"['differential-geometry', 'homotopy-theory', 'fibration']"
61,Mean curvature flow vs. diffusion,Mean curvature flow vs. diffusion,,"Mean curvature flow (MCF) and diffusion-type flows both have smoothing effects on a curve. I can tell there is a deep connection between the two, as seen in the Merriman-Bence-Osher (MBO) numerical scheme, which uses diffusion to approximate MCF: it takes a characteristic function of a region $\Omega$ and iterates the following apply the heat kernel (i.e. allow the boundary to diffuse), and threshold (to recreate a sharp boundary). What is the relationship between MCF and diffusive flows and how can one explain this geometrically? Honestly I'm not even sure whether ""diffusive flow"" is a term, but by that I mean evolution of a curve as described by the heat equation/heat kernel. Edit: I also read somewhere that Ricci flow on a surface effectively evolves the curvature of the surface with a heat equation. Now, how does Ricci flow come into the picture?","Mean curvature flow (MCF) and diffusion-type flows both have smoothing effects on a curve. I can tell there is a deep connection between the two, as seen in the Merriman-Bence-Osher (MBO) numerical scheme, which uses diffusion to approximate MCF: it takes a characteristic function of a region and iterates the following apply the heat kernel (i.e. allow the boundary to diffuse), and threshold (to recreate a sharp boundary). What is the relationship between MCF and diffusive flows and how can one explain this geometrically? Honestly I'm not even sure whether ""diffusive flow"" is a term, but by that I mean evolution of a curve as described by the heat equation/heat kernel. Edit: I also read somewhere that Ricci flow on a surface effectively evolves the curvature of the surface with a heat equation. Now, how does Ricci flow come into the picture?",\Omega,"['differential-geometry', 'curves', 'heat-equation', 'ricci-flow', 'mean-curvature-flows']"
62,Lift of a shortest loop is length minimizing,Lift of a shortest loop is length minimizing,,"Let $(M,g)$ be a $2$ -dimensional oriented complete Riemannian manifold without boundary. Let $f:\big(\Bbb S^1,1\big)\to (M,x_0)$ be a smooth loop such that $f$ has minimum length among all admissible loops in the given free homotopy class of loops. That is, if $f':\big(\Bbb S^1,1\big)\to (M,x_0')$ is another admissible loop such that there is a continuous map $H:\Bbb S^1\times [0,1]\to M$ with $H(-,0)=f, H(-,1)=f'$ , then length of $f$ is no more than length of $f'$ . Consider the following commutative diagram obtained from a smooth lifting. $\require{AMScd}$ \begin{CD}  (\Bbb R,0) @>\displaystyle\ell>> (\widetilde M,\widetilde {x_0})\\ @V\text{Universal Cover}  V V @VV  \text{Universal Cover}V\\ (\Bbb S^1,1) @>>\displaystyle f> (M,x_0)\\ \end{CD} Let $p:=\ell(t_0)$ and $q:=\ell(t_1)$ be two distinct points, and $\lambda:=\ell\big|[t_0,t_1]$ . Is it true that $\text{Length}_{\widetilde g}(\lambda)\leq \text{Length}_{\widetilde g}(\lambda')$ for all admissible curves $\lambda'$ with the same endpoints $p$ and $q$ ? $\bullet$ Always consider the pull-back metric on every covering. $\bullet$ In a Riemannian manifold, every minimizing curve is a geodesic when it is given a unit-speed parameterization, i.e. $\text{im}(\lambda)$ is the image of some geodesic. $\bullet$ If needed, one may assume $f$ is not null-homotopic. $\textbf{Definition:}$ On a smooth manifold $M$ a curve $\gamma:[a,b]\to M$ is said to be admissible if there is a partition $a=a_0<a_1<...<a_{n-1}<a_n=b$ of $[a,b]$ such that $\gamma\big|[a_{k-1},a_k]$ is smooth with non-vanishing velocity for each $k=1,...,n$ .","Let be a -dimensional oriented complete Riemannian manifold without boundary. Let be a smooth loop such that has minimum length among all admissible loops in the given free homotopy class of loops. That is, if is another admissible loop such that there is a continuous map with , then length of is no more than length of . Consider the following commutative diagram obtained from a smooth lifting. Let and be two distinct points, and . Is it true that for all admissible curves with the same endpoints and ? Always consider the pull-back metric on every covering. In a Riemannian manifold, every minimizing curve is a geodesic when it is given a unit-speed parameterization, i.e. is the image of some geodesic. If needed, one may assume is not null-homotopic. On a smooth manifold a curve is said to be admissible if there is a partition of such that is smooth with non-vanishing velocity for each .","(M,g) 2 f:\big(\Bbb S^1,1\big)\to (M,x_0) f f':\big(\Bbb S^1,1\big)\to (M,x_0') H:\Bbb S^1\times [0,1]\to M H(-,0)=f, H(-,1)=f' f f' \require{AMScd} \begin{CD}
 (\Bbb R,0) @>\displaystyle\ell>> (\widetilde M,\widetilde {x_0})\\
@V\text{Universal Cover}  V V @VV  \text{Universal Cover}V\\
(\Bbb S^1,1) @>>\displaystyle f> (M,x_0)\\
\end{CD} p:=\ell(t_0) q:=\ell(t_1) \lambda:=\ell\big|[t_0,t_1] \text{Length}_{\widetilde g}(\lambda)\leq \text{Length}_{\widetilde g}(\lambda') \lambda' p q \bullet \bullet \text{im}(\lambda) \bullet f \textbf{Definition:} M \gamma:[a,b]\to M a=a_0<a_1<...<a_{n-1}<a_n=b [a,b] \gamma\big|[a_{k-1},a_k] k=1,...,n","['differential-geometry', 'differential-topology', 'riemannian-geometry', 'geometric-topology', 'covering-spaces']"
63,Volumes of submanifolds with respect to two different riemannian metrics,Volumes of submanifolds with respect to two different riemannian metrics,,"Suppose we have a compact manifold $M$ and two riemannian metrics $g_1,g_2$ . For each riemannian metric we can define the riemannian measure and for each compact submanifold $Y\subset X$ we have the induced metrics on $Y$ and we can compute the volume of $Y$ with respect to this metric. Now I know that for each $x\in M$ and $v\in T_x M$ we have that there exist constants $a,b>0$ such that $ag_x^1(v,v)\leq g_x^2(v,v)\leq bg_x^1(v,v)$ , using the fact that $SM$ is compact since $M$ is compact. Now I would like to see that for the volume of a submanifold with respect to each metric we get a similar inequality, i.e, that $aVol_1(Y)\leq Vol_2(Y)\leq bVol_1(Y) $ , and for that I belive it suffices to get such an equality for $\sqrt{G^{\alpha}}$ , where this denotes the determinant of the matrix $g_{ij}^{\alpha}=g(\frac{\partial}{\partial x_i^{\alpha}},\frac{\partial}{\partial x_j^{\alpha}})$ , for each one of the metrics. Does anyone know if this is possible and if so if how can one prove it ? (My interest in this comes from the Yomdin's Theorem for the topological entropy of the geodesic flow)","Suppose we have a compact manifold and two riemannian metrics . For each riemannian metric we can define the riemannian measure and for each compact submanifold we have the induced metrics on and we can compute the volume of with respect to this metric. Now I know that for each and we have that there exist constants such that , using the fact that is compact since is compact. Now I would like to see that for the volume of a submanifold with respect to each metric we get a similar inequality, i.e, that , and for that I belive it suffices to get such an equality for , where this denotes the determinant of the matrix , for each one of the metrics. Does anyone know if this is possible and if so if how can one prove it ? (My interest in this comes from the Yomdin's Theorem for the topological entropy of the geodesic flow)","M g_1,g_2 Y\subset X Y Y x\in M v\in T_x M a,b>0 ag_x^1(v,v)\leq g_x^2(v,v)\leq bg_x^1(v,v) SM M aVol_1(Y)\leq Vol_2(Y)\leq bVol_1(Y)  \sqrt{G^{\alpha}} g_{ij}^{\alpha}=g(\frac{\partial}{\partial x_i^{\alpha}},\frac{\partial}{\partial x_j^{\alpha}})","['differential-geometry', 'smooth-manifolds']"
64,Integration along fibers,Integration along fibers,,"The following statements are  from the book heat kernel and dirac operator chapter 1. "" Let $\pi : M \rightarrow B $ be a fiber bundle with n-dimensional fiber, such that both M and B are oriented. If $\alpha \in {A}_c^k(M)$ is a compactly-supported differential form on M, its integral over the fibers of $ M \rightarrow B $ is the differential form $\int\limits_{M/B} \alpha \in A^{k-n}(B)$ such that \begin{equation}  \int\limits_B (\int\limits_{M/B} \alpha) \wedge \beta = \int\limits_M \alpha \wedge \pi^* \beta \quad  ... (1.15) \end{equation} for all differential forms $\beta$ on the base B. We sometimes write $ \pi_* \alpha $ instead of $ \int\limits_{M/B} $ . It follows easily from the (1.15) that \begin{equation}  \pi_*(\alpha \wedge \pi^* \beta ) = \pi_* \alpha \wedge \beta \quad ...(1.16) \end{equation} for all $\alpha \in A_c(M) $ and $\beta \in A(\beta).$ "" My questions are the following: what is the intuition behind defining the integral of $\alpha$ over the fibers by the equation (1.15), and why the notion of integration along fiber  is important ? how to prove that equation 1.15 implies equation 1.16 ?","The following statements are  from the book heat kernel and dirac operator chapter 1. "" Let be a fiber bundle with n-dimensional fiber, such that both M and B are oriented. If is a compactly-supported differential form on M, its integral over the fibers of is the differential form such that for all differential forms on the base B. We sometimes write instead of . It follows easily from the (1.15) that for all and "" My questions are the following: what is the intuition behind defining the integral of over the fibers by the equation (1.15), and why the notion of integration along fiber  is important ? how to prove that equation 1.15 implies equation 1.16 ?","\pi : M \rightarrow B  \alpha \in {A}_c^k(M)  M \rightarrow B  \int\limits_{M/B} \alpha \in A^{k-n}(B) \begin{equation} 
\int\limits_B (\int\limits_{M/B} \alpha) \wedge \beta = \int\limits_M \alpha \wedge \pi^* \beta \quad  ... (1.15)
\end{equation} \beta  \pi_* \alpha   \int\limits_{M/B}  \begin{equation} 
\pi_*(\alpha \wedge \pi^* \beta ) = \pi_* \alpha \wedge \beta \quad ...(1.16)
\end{equation} \alpha \in A_c(M)  \beta \in A(\beta). \alpha","['integration', 'differential-geometry', 'differential-forms', 'fiber-bundles']"
65,Example of quasi Yamabe gradient soliton,Example of quasi Yamabe gradient soliton,,"A $(M,g)$ Riemannian manifold is called quasi Yamabe gradient soliton if there exists a smooth function $f\in C^\infty(M)$ such that the following condition holds $$Hess(f)=(R-\lambda)g+\mu df\otimes df,$$ where $R$ is the scalar curvature of $g$ and $\lambda,\mu$ are constants. The concept of quasi Yamabe soliton was first introduced by Huang, Guangyue; Li, Haizhong , On a classification of the quasi Yamabe gradient solitons , Methods Appl. Anal. 21, No. 3, 379-390 (2014). ZBL1304.53033 . But I am not able to find any nontrivial example of quasi Yamabe gradient soliton in Euclidean manifold with some proper metric. In the paper, Wang, Lin Feng , On noncompact quasi Yamabe gradient solitons , Differ. Geom. Appl. 31, No. 3, 337-348 (2013). ZBL1279.53039 , there is an example in warped product manifold but I need in Euclidean space. Please help me to find an example of that. Thank you","A Riemannian manifold is called quasi Yamabe gradient soliton if there exists a smooth function such that the following condition holds where is the scalar curvature of and are constants. The concept of quasi Yamabe soliton was first introduced by Huang, Guangyue; Li, Haizhong , On a classification of the quasi Yamabe gradient solitons , Methods Appl. Anal. 21, No. 3, 379-390 (2014). ZBL1304.53033 . But I am not able to find any nontrivial example of quasi Yamabe gradient soliton in Euclidean manifold with some proper metric. In the paper, Wang, Lin Feng , On noncompact quasi Yamabe gradient solitons , Differ. Geom. Appl. 31, No. 3, 337-348 (2013). ZBL1279.53039 , there is an example in warped product manifold but I need in Euclidean space. Please help me to find an example of that. Thank you","(M,g) f\in C^\infty(M) Hess(f)=(R-\lambda)g+\mu df\otimes df, R g \lambda,\mu","['differential-geometry', 'riemannian-geometry']"
66,Motivation behind the sheaf of relative Khler differentials,Motivation behind the sheaf of relative Khler differentials,,"I'm interested in the geometric motivation behind the bundle (or in more general framework the sheaf) of relative differentials $\Omega_{X/Y}$ of a morphism $f: X \to Y$ smooth $k$ -varieties. Differential geometry provides following picture of relative differentials: Let $f: X \to Y$ a equidimensional surjective map between connected manifolds $Y, X$ and moreover assume that every fiber $F:= f^{-1}(y) \subset X$ for $y \in Y$ is also a connected submanifold of same dimension. We obtain an exact sequence of tangent spaces $$  0 \to T_{X/Y} \to T_X \to f^*T_Y \to 0  $$ where $T_{X/Y}$ is the kernel of induced map of tangent bundles. intuitively what is really going on there is that for every $x \in f^{-1}(y)$ , the $(T_{X/Y})_x$ is the tangent space of the fiber at $x$ . The relative space of Khler differentials $\Omega_{X/Y}$ defined as the dual of $T_{X/Y}$ and sits in the sequence which we will obtain if we dualize the sequence above of tangent spaces: $$ 0 \to f^*\Omega_Y \to \Omega_X \to \Omega_{X/Y} \to 0  $$ Another definition of relative Khler differentials which is more common to use in modern algebraic geometry works as follows: Let us embedd $X$ as the image of the diagonal $\Delta: X \to X \times_Y X$ and assume that the ideal sheaf $I \subset O_{X \times_Y X}$ defines the closed image $\Delta(X) \subset X \times_Y X$ . This gives us another sequence of tagent spaces $$ 0  \to T_{\Delta(X)} \to T_{X \times_Y X} \to N_{X \times_Y X/X} \to 0 $$ with normal bundle $N_{X \times_Y X/X}$ . It's a basic fact that the dual of $N_{X \times_Y X/X}$ is $I/I^2$ and most books on algebraic geometry define the sheaf relative Khler differentials by $$\Omega_{X/Y} := I/I^2$$ Since this definition not uses that $f$ is a map of smooth maps this is a far generalization of the old fashion setting from differential geometry. Now, if there is any justice n this world then these two definitions of relative differentials should coinside if we deal with $X, Y$ and $fY$ nice enough. Therefore, if $f$ a surjective map between conneted manifolds such that every fiber is a connected submanifold, why the tangent bundle $T_{X/Y}$ and the pullback of normal bundle $\Delta^* N_{X \times_Y X/X}$ of $\Delta(X) \subset X \times_Y X$ are canonically isomorphic? Can we write down an explicit isomorphism and understand what is geometrically going on there?","I'm interested in the geometric motivation behind the bundle (or in more general framework the sheaf) of relative differentials of a morphism smooth -varieties. Differential geometry provides following picture of relative differentials: Let a equidimensional surjective map between connected manifolds and moreover assume that every fiber for is also a connected submanifold of same dimension. We obtain an exact sequence of tangent spaces where is the kernel of induced map of tangent bundles. intuitively what is really going on there is that for every , the is the tangent space of the fiber at . The relative space of Khler differentials defined as the dual of and sits in the sequence which we will obtain if we dualize the sequence above of tangent spaces: Another definition of relative Khler differentials which is more common to use in modern algebraic geometry works as follows: Let us embedd as the image of the diagonal and assume that the ideal sheaf defines the closed image . This gives us another sequence of tagent spaces with normal bundle . It's a basic fact that the dual of is and most books on algebraic geometry define the sheaf relative Khler differentials by Since this definition not uses that is a map of smooth maps this is a far generalization of the old fashion setting from differential geometry. Now, if there is any justice n this world then these two definitions of relative differentials should coinside if we deal with and nice enough. Therefore, if a surjective map between conneted manifolds such that every fiber is a connected submanifold, why the tangent bundle and the pullback of normal bundle of are canonically isomorphic? Can we write down an explicit isomorphism and understand what is geometrically going on there?","\Omega_{X/Y} f: X \to Y k f: X \to Y Y, X F:= f^{-1}(y) \subset X y \in Y   0 \to T_{X/Y} \to T_X \to f^*T_Y \to 0   T_{X/Y} x \in f^{-1}(y) (T_{X/Y})_x x \Omega_{X/Y} T_{X/Y}  0 \to f^*\Omega_Y \to \Omega_X \to \Omega_{X/Y} \to 0   X \Delta: X \to X \times_Y X I \subset O_{X \times_Y X} \Delta(X) \subset X \times_Y X  0  \to T_{\Delta(X)} \to T_{X \times_Y X} \to N_{X \times_Y X/X} \to 0  N_{X \times_Y X/X} N_{X \times_Y X/X} I/I^2 \Omega_{X/Y} := I/I^2 f X, Y fY f T_{X/Y} \Delta^* N_{X \times_Y X/X} \Delta(X) \subset X \times_Y X","['differential-geometry', 'algebraic-geometry', 'vector-bundles', 'coherent-sheaves']"
67,Diffeomorphism from $n$-cone to $\mathbb{R}^{n+1}$ -- parametric equation of geodesic?,Diffeomorphism from -cone to  -- parametric equation of geodesic?,n \mathbb{R}^{n+1},"Let $\mathbb{S}^n=\{\mathbf{x}\in\mathbb{R}^{n+1}\colon\lVert\mathbf{x}\rVert^2=1\}$ be the $n$ -sphere. We know that a bijection from $\mathbb{S}^n\backslash \{N\}$ to $\mathbb{R}^n\times\{0\}\subset\mathbb{R}^{n+1}$ , where $N$ is, for instance, the north pole of $\mathbb{S}^n$ , is given by stereographic projection. Moreover, we know that a great circle on $\mathbb{S}^n$ can be given analytically, parametrized for instance by an angle $\theta$ and with respect to some basis where this geodesic belongs. I am trying to figure out if any of the following can be defined in a similar manner: Can an $n$ -dimensional cone be defined similarly to the $n$ -sphere, i.e., as a subset of $n+1$ -dimensional Euclidean space, given a formula? If so, is there any injection (more specifically a diffeomorphism) from the $n$ -cone manifold to the Euclidean $\mathbb{R}^{n+1}$ ? Can a geodesic on $n$ -cone be parametrized in a similar way? For instance, if we define a $2$ -plane using a set of $n+1$ -dimensional vectors, can we parametrized the conic section in the general case?","Let be the -sphere. We know that a bijection from to , where is, for instance, the north pole of , is given by stereographic projection. Moreover, we know that a great circle on can be given analytically, parametrized for instance by an angle and with respect to some basis where this geodesic belongs. I am trying to figure out if any of the following can be defined in a similar manner: Can an -dimensional cone be defined similarly to the -sphere, i.e., as a subset of -dimensional Euclidean space, given a formula? If so, is there any injection (more specifically a diffeomorphism) from the -cone manifold to the Euclidean ? Can a geodesic on -cone be parametrized in a similar way? For instance, if we define a -plane using a set of -dimensional vectors, can we parametrized the conic section in the general case?",\mathbb{S}^n=\{\mathbf{x}\in\mathbb{R}^{n+1}\colon\lVert\mathbf{x}\rVert^2=1\} n \mathbb{S}^n\backslash \{N\} \mathbb{R}^n\times\{0\}\subset\mathbb{R}^{n+1} N \mathbb{S}^n \mathbb{S}^n \theta n n n+1 n \mathbb{R}^{n+1} n 2 n+1,"['differential-geometry', 'geodesic', 'diffeomorphism']"
68,How to prove $ L_X(\omega(Y)) = (L_X\omega)Y + \omega(L_XY)$ starting from the fundamental definition of Lie derivative?,How to prove  starting from the fundamental definition of Lie derivative?, L_X(\omega(Y)) = (L_X\omega)Y + \omega(L_XY),"The Lie derivative of a smooth real valued function $f$ along a vector field $X$ , on a point $p$ in some smooth manifold is given as $$ L_X f(p) :=  \lim_{h\to 0} \frac{1}{h}\left[ f(\phi(p)) - f(p) \right]\label{Lief}\tag{1} $$ The Lie derivative of a vector field $Y$ along another vector field $X$ , on a point $p$ in some smooth manifold is given as $$ L_X Y(p) =\frac{d}{dt}\left[\phi_{-t*}Y(p)\right] :=  \lim_{h\to 0} \frac{1}{h}\left[ (\phi_{-h*}Y)_p - Y_p \right]\label{Liev}\tag{2} $$ $\phi_t$ is the integral curve of the vector field $X$ , with the push-forward map defined by $$(\phi_{-h*}Y)_p  = \phi_{-h*}Y_{\phi_h(p)}$$ Similarly, the Lie derivative of a one-form $\omega$ along a vector field $X$ , is given by $$ L_X \omega(p) =\frac{d}{dt}\left[\phi_{t}^*\omega\right](p) :=  \lim_{h\to 0} \frac{1}{h}\left[ (\phi_{h}^*\omega)_p - \omega_p \right]\label{Lieo}\tag{3} $$ $$ (\phi_h^* \omega)(p)(X_p) = \omega(\phi_h(p)) (\phi_{h*}X_p) $$ Now, I want to prove that the Lie derivative $$ L_X(\omega(Y)) = (L_X\omega)Y + \omega(L_XY) $$ The function $\omega(Y)(p) = \omega_p (Y_p)$ , as $\omega(Y)(p)$ is a function it's transformation rule should be something like \begin{align} L_X(\omega(Y)) &=  \lim_{h\to 0} \frac{1}{h}\left[ (\phi_{h}^*(\omega(Y)))_p - (\omega(Y))_p \right] \label{LiewY}\tag{4} \end{align} Is the equation \eqref{LiewY} the right way to begin?, or the expression be more like \eqref{Lief} as $\omega(Y)$ is a real valued function over the manifold, I am not sure how $(\phi_{h}^*(\omega(Y)))_p$ in \eqref{LiewY} will look when simplified. This question has an answer here but in terms of Cartan's formula. I'd like to know how to start from the very basic definition of Lie derivative","The Lie derivative of a smooth real valued function along a vector field , on a point in some smooth manifold is given as The Lie derivative of a vector field along another vector field , on a point in some smooth manifold is given as is the integral curve of the vector field , with the push-forward map defined by Similarly, the Lie derivative of a one-form along a vector field , is given by Now, I want to prove that the Lie derivative The function , as is a function it's transformation rule should be something like Is the equation \eqref{LiewY} the right way to begin?, or the expression be more like \eqref{Lief} as is a real valued function over the manifold, I am not sure how in \eqref{LiewY} will look when simplified. This question has an answer here but in terms of Cartan's formula. I'd like to know how to start from the very basic definition of Lie derivative","f X p 
L_X f(p) :=  \lim_{h\to 0} \frac{1}{h}\left[ f(\phi(p)) - f(p) \right]\label{Lief}\tag{1}
 Y X p 
L_X Y(p) =\frac{d}{dt}\left[\phi_{-t*}Y(p)\right] :=  \lim_{h\to 0} \frac{1}{h}\left[ (\phi_{-h*}Y)_p - Y_p \right]\label{Liev}\tag{2}
 \phi_t X (\phi_{-h*}Y)_p  = \phi_{-h*}Y_{\phi_h(p)} \omega X 
L_X \omega(p) =\frac{d}{dt}\left[\phi_{t}^*\omega\right](p) :=  \lim_{h\to 0} \frac{1}{h}\left[ (\phi_{h}^*\omega)_p - \omega_p \right]\label{Lieo}\tag{3}
 
(\phi_h^* \omega)(p)(X_p) = \omega(\phi_h(p)) (\phi_{h*}X_p)
 
L_X(\omega(Y)) = (L_X\omega)Y + \omega(L_XY)
 \omega(Y)(p) = \omega_p (Y_p) \omega(Y)(p) \begin{align}
L_X(\omega(Y)) &=  \lim_{h\to 0} \frac{1}{h}\left[ (\phi_{h}^*(\omega(Y)))_p - (\omega(Y))_p \right] \label{LiewY}\tag{4}
\end{align} \omega(Y) (\phi_{h}^*(\omega(Y)))_p","['differential-geometry', 'smooth-manifolds', 'lie-derivative']"
69,"Find $F$-related vector fields on $M\times N$, where $F(x)=(x, f(x))$","Find -related vector fields on , where","F M\times N F(x)=(x, f(x))","I am reading Lee's book on Differential geometry. In Chapter 4, Lee has this exercise. Let $M$ , $N$ be smooth manifolds, and let $f:M\to N$ be a smooth map. Define $F : M\to M \times N$ by $F(x) = (x, f(x) )$ . Show that for every smooth vector field $V$ of $M$ , there is a smooth vector field on $W$ on $M \times N$ that is $F$ -related to $V$ . I can understand that we must have $W_{(x,f(x))}=V_x\oplus Df(x)V_p$ for all $x\in M.$ The set $\{(x,f(x)):x\in M\}$ is a closed set in $M\times N.$ Therefore, if we can show that for all $(p,f(p))\in M\times N$ there is a neighbourhood $U_p$ and a smooth vector field on $U_p$ extending $V_x\oplus Df(x)V_x$ we are done by partition of unity. But I cannot show that. Can someone help me out?","I am reading Lee's book on Differential geometry. In Chapter 4, Lee has this exercise. Let , be smooth manifolds, and let be a smooth map. Define by . Show that for every smooth vector field of , there is a smooth vector field on on that is -related to . I can understand that we must have for all The set is a closed set in Therefore, if we can show that for all there is a neighbourhood and a smooth vector field on extending we are done by partition of unity. But I cannot show that. Can someone help me out?","M N f:M\to N F : M\to M \times N F(x) = (x, f(x) ) V M W M \times N F V W_{(x,f(x))}=V_x\oplus Df(x)V_p x\in M. \{(x,f(x)):x\in M\} M\times N. (p,f(p))\in M\times N U_p U_p V_x\oplus Df(x)V_x","['differential-geometry', 'smooth-manifolds', 'vector-fields']"
70,relation of supp of form $\omega$ and $d\omega$,relation of supp of form  and,\omega d\omega,"Given $n$ dimension smooth manifold,and smooth $k$ (where $k\le n-1$ ) form $\omega$ . Assume we know $\text{supp}\ \omega \subset U$ where $U$ is open subset of $M$ Can we say anything about support for $\omega$ and $d\omega$ ,for example the proporsitions below is true or false: $\text{supp} (d\omega) = \text{supp}(\omega)$ $\text{supp}(d\omega) \subset \text{supp}(\omega)$ (I try to show for example when $\omega$ is 0-form,and $\text{supp}(d\omega)\subset \text{supp}\omega\ $ i.e. denote $Z(\omega) = \{p:\omega_p \ne 0\}$ it's sufficient to show $Z(d\omega) \subset Z(\omega)$ but we can't say if $\omega_p =0$ then $(d\omega)_p = 0$ ?since $(d\omega)_p(X_p)$ is determined by the neighborhood value of $\omega$ around $p$ not only a single point?","Given dimension smooth manifold,and smooth (where ) form . Assume we know where is open subset of Can we say anything about support for and ,for example the proporsitions below is true or false: (I try to show for example when is 0-form,and i.e. denote it's sufficient to show but we can't say if then ?since is determined by the neighborhood value of around not only a single point?",n k k\le n-1 \omega \text{supp}\ \omega \subset U U M \omega d\omega \text{supp} (d\omega) = \text{supp}(\omega) \text{supp}(d\omega) \subset \text{supp}(\omega) \omega \text{supp}(d\omega)\subset \text{supp}\omega\  Z(\omega) = \{p:\omega_p \ne 0\} Z(d\omega) \subset Z(\omega) \omega_p =0 (d\omega)_p = 0 (d\omega)_p(X_p) \omega p,"['differential-geometry', 'differential-forms']"
71,$f^{-1}f(\Sigma)$ has measure zero for analytic map from manifolds $M$ to $N$,has measure zero for analytic map from manifolds  to,f^{-1}f(\Sigma) M N,"Differential Topology Hirsch Chapter 3 Section 1 Problem 4: (a) Let $M$ be a connected manifold and $f: M \rightarrow N$ an analytic map. Let $\Sigma \subset M$ be the set of critical points. If $\Sigma \neq M$ then $f^{-1}f(\Sigma)$ has measure zero. (b) If $f$ is merely $C^{\infty}$ The conclusion (a) can be false. For part (a) A function is analytic iff its Taylor series about $x_0$ converges to the function in some neighborhood for every $x_0$ in the domain. The definition of analytic function is the same as $C^{\infty}$ function except for the notion of convergence in a neighborhood of nonzero radius in the former. Therefore, we can apply the Morse-Sard Theorem and conclude that the set of regular values is dense. A critical point cannot be a regular value so $f^{-1}f(\Sigma)$ , which is the set of critical points must have measure 0. For part (b) I didn't use anything about the function being analytic in part (a) so I'm not sure how I would approach this part. Thank you!","Differential Topology Hirsch Chapter 3 Section 1 Problem 4: (a) Let be a connected manifold and an analytic map. Let be the set of critical points. If then has measure zero. (b) If is merely The conclusion (a) can be false. For part (a) A function is analytic iff its Taylor series about converges to the function in some neighborhood for every in the domain. The definition of analytic function is the same as function except for the notion of convergence in a neighborhood of nonzero radius in the former. Therefore, we can apply the Morse-Sard Theorem and conclude that the set of regular values is dense. A critical point cannot be a regular value so , which is the set of critical points must have measure 0. For part (b) I didn't use anything about the function being analytic in part (a) so I'm not sure how I would approach this part. Thank you!",M f: M \rightarrow N \Sigma \subset M \Sigma \neq M f^{-1}f(\Sigma) f C^{\infty} x_0 x_0 C^{\infty} f^{-1}f(\Sigma),"['differential-geometry', 'differential-topology']"
72,Differential in terms of $T_pX \simeq \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast$,Differential in terms of,T_pX \simeq \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast,"I am studying different definitions of the tangent space to a manifold $X$ in a point. When we identify $T_pX \simeq \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast$ , how can we express the differential $dF_p$ of a differentiable map $F:(X, p) \to (Y, q)$ ? The ""standard"" definition, seeing $T_pX$ as a space of derivations of $\mathcal{C}^\infty_X(p)$ , would be $dF_p(\delta)=\delta F^\ast_p$ for every $\delta \in T_pX$ . My idea is that if we call $\alpha_q=\alpha: T_qY \to  \left(\mathfrak{m}_q/ \mathfrak{m}_q^2\right)^\ast$ and $\beta_p=\beta: \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast \to T_pX$ the two isomorphism defined by $$\alpha(\delta)(f+ \mathfrak{m}_q^2)=\delta(f), \quad \beta(\omega)(g)=\omega(g-g(p)+\mathfrak{m}_p^2) \quad \forall \delta \in T_qY, f \in \mathfrak {m}_q, g \in \mathcal{C}^\infty_X(p),\omega \in \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast, $$ then the differential $ \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast \to \left(\mathfrak{m}_q/ \mathfrak{m}_q^2\right)^\ast$ should be $\alpha \circ dF_p \circ \beta$ , that is, the bottom row of the following diagram: $\require{AMScd}$ \begin{CD} {T_pX} @>{dF_p}>> T_qY\\ @A{\beta_p}AA @VV{\alpha_q}V\\ \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast @>{??}>> \left(\mathfrak{m}_q/ \mathfrak{m}_q^2\right)^\ast \end{CD} However I find difficulties finding an explicit expression.","I am studying different definitions of the tangent space to a manifold in a point. When we identify , how can we express the differential of a differentiable map ? The ""standard"" definition, seeing as a space of derivations of , would be for every . My idea is that if we call and the two isomorphism defined by then the differential should be , that is, the bottom row of the following diagram: However I find difficulties finding an explicit expression.","X T_pX \simeq \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast dF_p F:(X, p) \to (Y, q) T_pX \mathcal{C}^\infty_X(p) dF_p(\delta)=\delta F^\ast_p \delta \in T_pX \alpha_q=\alpha: T_qY \to  \left(\mathfrak{m}_q/ \mathfrak{m}_q^2\right)^\ast \beta_p=\beta: \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast \to T_pX \alpha(\delta)(f+ \mathfrak{m}_q^2)=\delta(f), \quad \beta(\omega)(g)=\omega(g-g(p)+\mathfrak{m}_p^2) \quad \forall \delta \in T_qY, f \in \mathfrak {m}_q, g \in \mathcal{C}^\infty_X(p),\omega \in \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast,   \left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast \to \left(\mathfrak{m}_q/ \mathfrak{m}_q^2\right)^\ast \alpha \circ dF_p \circ \beta \require{AMScd} \begin{CD}
{T_pX} @>{dF_p}>> T_qY\\
@A{\beta_p}AA @VV{\alpha_q}V\\
\left(\mathfrak{m}_p/ \mathfrak{m}_p^2\right)^\ast @>{??}>> \left(\mathfrak{m}_q/ \mathfrak{m}_q^2\right)^\ast
\end{CD}","['differential-geometry', 'tangent-spaces']"
73,"Minimal Manifold, $\mathbb{R}^4$","Minimal Manifold,",\mathbb{R}^4,We know that all the minimal surfaces of revolution in $\mathbb{R}^3$ are the Catenoid and the euclidean plane $\mathbb{R}^2$ in $\mathbb{R}^3$ . Do we know what are the minimal surfaces of revolution in $\mathbb{R}^4$ ?,We know that all the minimal surfaces of revolution in are the Catenoid and the euclidean plane in . Do we know what are the minimal surfaces of revolution in ?,\mathbb{R}^3 \mathbb{R}^2 \mathbb{R}^3 \mathbb{R}^4,"['differential-geometry', 'riemannian-geometry', 'minimal-surfaces']"
74,"What does ""antisymmetric"" mean for the adjoint map of a Lie algebra?","What does ""antisymmetric"" mean for the adjoint map of a Lie algebra?",,"A theorem about Lie algebras says that: Fix a Lie group $G$ , endowed with a left invariant riemannian metric $g$ , let $\nabla$ be the Levi Civita connection. Let the Lie algebra of $G$ be $\mathfrak{g}$ then the following are equivalent: The adjoint map of $\mathfrak{g}$ is such that $ad(X)$ is antisymmetric $\forall X\in\mathfrak{g}$ The one parameter subgroups of $G$ are precisely the (Levi-Civita) geodetics of $G$ Now my question is not about the theorem, but about the meaniing of the first condition. To my understanding $ad$ is a linear map $X\in\mathfrak{g}\mapsto ad(\mathfrak{g})\in \mathfrak{gl}(\mathfrak{g})\cong Hom(\mathfrak{g},\mathfrak{g})$ where $ad(X): Y\in\mathfrak{g}\mapsto [X,Y]\in \mathfrak{g}$ . So it is a linear map, and not multinear map: how can it be antisymmetric? Wat do we mean by this term here? What am I missing? Thanks in advance","A theorem about Lie algebras says that: Fix a Lie group , endowed with a left invariant riemannian metric , let be the Levi Civita connection. Let the Lie algebra of be then the following are equivalent: The adjoint map of is such that is antisymmetric The one parameter subgroups of are precisely the (Levi-Civita) geodetics of Now my question is not about the theorem, but about the meaniing of the first condition. To my understanding is a linear map where . So it is a linear map, and not multinear map: how can it be antisymmetric? Wat do we mean by this term here? What am I missing? Thanks in advance","G g \nabla G \mathfrak{g} \mathfrak{g} ad(X) \forall X\in\mathfrak{g} G G ad X\in\mathfrak{g}\mapsto ad(\mathfrak{g})\in \mathfrak{gl}(\mathfrak{g})\cong Hom(\mathfrak{g},\mathfrak{g}) ad(X): Y\in\mathfrak{g}\mapsto [X,Y]\in \mathfrak{g}","['differential-geometry', 'lie-groups', 'riemannian-geometry', 'lie-algebras', 'geodesic']"
75,Tangent bundle $TM\to M$ is an orientable bundle iff $M$ is orientable,Tangent bundle  is an orientable bundle iff  is orientable,TM\to M M,"This is Example 6.3 in Bott-Tu, which asserts a smooth manifold $M$ is orientable iff the tangent bundle $TM\to M$ is an orientable bundle. If $A=\{(U_\alpha,\psi_\alpha)\}$ is an atlas for $M$ , then for each $\alpha$ , there is a local trivialization $\phi_\alpha:TU_\alpha\to U_\alpha \times \Bbb R^n$ (where $n=\dim M$ ) given by $\sum_{i=1}^n a^i \dfrac{\partial }{\partial x^i}|_p$ where $\psi_\alpha=(x^1,\dots,x^n)$ . Clearly the transition function $g_{\alpha \beta}:U_\alpha\cap U_\beta \to GL_n(\Bbb R)$ equals the Jacobian $U_\alpha\cap U_\beta \to GL_n(\Bbb R)$ , $p\mapsto J(\psi_\alpha \circ \psi_\beta^{-1})(p)$ . Thus if $A$ is an oriented atlas, then the trivialization $\{(U_\alpha, \phi_\alpha)\}$ is oriented, and this proves one direction. But how does the opposite direction hold? (There is no explanation in the book)","This is Example 6.3 in Bott-Tu, which asserts a smooth manifold is orientable iff the tangent bundle is an orientable bundle. If is an atlas for , then for each , there is a local trivialization (where ) given by where . Clearly the transition function equals the Jacobian , . Thus if is an oriented atlas, then the trivialization is oriented, and this proves one direction. But how does the opposite direction hold? (There is no explanation in the book)","M TM\to M A=\{(U_\alpha,\psi_\alpha)\} M \alpha \phi_\alpha:TU_\alpha\to U_\alpha \times \Bbb R^n n=\dim M \sum_{i=1}^n a^i \dfrac{\partial }{\partial x^i}|_p \psi_\alpha=(x^1,\dots,x^n) g_{\alpha \beta}:U_\alpha\cap U_\beta \to GL_n(\Bbb R) U_\alpha\cap U_\beta \to GL_n(\Bbb R) p\mapsto J(\psi_\alpha \circ \psi_\beta^{-1})(p) A \{(U_\alpha, \phi_\alpha)\}","['differential-geometry', 'smooth-manifolds', 'orientation', 'tangent-bundle']"
76,Standard version of covariant derivative properties,Standard version of covariant derivative properties,,"[Throughout we're considering the intrinsic version of the covariant derivative. The extrinsic version isn't of any concern.] I'm having trouble reconciling different versions of the properties to be satisfied by the covariant derivative. Essentially $\nabla$ sends $(p,q)$ -tensors to $(p,q+1)$ -tensors. I'll write down the required properties for $\nabla$ from the two sources. This lecture (relevant timestamp linked) If $X$ is a vector field, $\nabla_Xf=Xf$ , for a scalar field $f$ $\nabla_X(T+S)=\nabla_XT+\nabla_XS$ $\nabla_X(T(\omega,Y))=(\nabla_XT)(\omega,Y)+T(\nabla_X\omega,Y)+T(\omega,\nabla_XY)$ $\nabla_{fX+Z}\ T=f\nabla_XT+\nabla_ZT$ Core principles of special and general relativity (Luscombe): $\nabla_if=\partial_if$ $\nabla(aT+bS)=a\nabla T+b\nabla S$ for real $a,b$ $\nabla(S\otimes T)=(\nabla S)\otimes T+S\otimes (\nabla T)$ $\nabla$ commutes with contractions, $\nabla_i(T^j_{\ \ jk})=(\nabla T)^j_{\ \ ijk}$ At least the second property is consistent. The first property from the book is a more restrictive version of the first property from the lecture. In fact, $\nabla_i$ means $\nabla_{\partial_i}$ and $\partial_i$ isn't even a vector field! As for the last two properties from the two sources, I have no idea on how to relate them. Are these requirements incomplete for either of the sources? If not, how can these two sets of requirements be shown to be equivalent?","[Throughout we're considering the intrinsic version of the covariant derivative. The extrinsic version isn't of any concern.] I'm having trouble reconciling different versions of the properties to be satisfied by the covariant derivative. Essentially sends -tensors to -tensors. I'll write down the required properties for from the two sources. This lecture (relevant timestamp linked) If is a vector field, , for a scalar field Core principles of special and general relativity (Luscombe): for real commutes with contractions, At least the second property is consistent. The first property from the book is a more restrictive version of the first property from the lecture. In fact, means and isn't even a vector field! As for the last two properties from the two sources, I have no idea on how to relate them. Are these requirements incomplete for either of the sources? If not, how can these two sets of requirements be shown to be equivalent?","\nabla (p,q) (p,q+1) \nabla X \nabla_Xf=Xf f \nabla_X(T+S)=\nabla_XT+\nabla_XS \nabla_X(T(\omega,Y))=(\nabla_XT)(\omega,Y)+T(\nabla_X\omega,Y)+T(\omega,\nabla_XY) \nabla_{fX+Z}\ T=f\nabla_XT+\nabla_ZT \nabla_if=\partial_if \nabla(aT+bS)=a\nabla T+b\nabla S a,b \nabla(S\otimes T)=(\nabla S)\otimes T+S\otimes (\nabla T) \nabla \nabla_i(T^j_{\ \ jk})=(\nabla T)^j_{\ \ ijk} \nabla_i \nabla_{\partial_i} \partial_i","['differential-geometry', 'tensors']"
77,Perelman's entropy functional computation problem.,Perelman's entropy functional computation problem.,,"I was reading Hopper and Andrews's book on Ricci flow in Riemannian Geometry. I came across the following proposition on the monotonicity of Perelman's $\mathcal{W}$ -functional. Let $(g(t),f(t), \tau(t))$ evolve by \begin{align*} \frac{\partial g}{\partial t} &= -2\text{Ric} \\ \frac{\partial f}{\partial t} &= -|\nabla f|^{2} + \Delta f - \text{Scal} + \frac{n}{2\tau} \\ \frac{d \tau}{d t} &= -1.  \end{align*} Consider the function $$ w = (\tau(\text{Scal} + 2\Delta f - |\nabla f|^{2}) + f - n)u, $$ where $u = (4\pi \tau)^{-n/2}e^{-f}$ . Also, consider the operator $$ \Box^{*} = -\frac{\partial}{\partial t} - \Delta + \text{Scal}.  $$ We have to show that $$ \Box^{*}w = -2\tau \left | \text{Ric} + \text{Hess}{f} - \frac{g}{2\tau} \right|^{2} u.  $$ I'm having trouble proving this. The book refers to Peter Topping's lecture notes on Ricci flow where the computation is done. In the first line of their proof, I found the following which I find problematic. They write $$ \Box^{*}w = \Box^{*}(u) \frac{w}{u} - \left(\frac{\partial}{\partial t} + \Delta \right) \left(\frac{w}{u}\right) - 2 \left \langle \nabla \left( \frac{w}{u} \right) , \nabla u \right \rangle.  $$ I believe that the term comes from the following intermediate step, $$ \Box^{*}w = \Box^{*}(u) \left( \frac{w}{u} \right) + u \Box^{*}\left( \frac{w}{u} \right). $$ The last term in the above expression troubles me. What should have been simply $$  u \text{Scal} \frac{w}{u} $$ is written as $$ -2\left \langle \nabla \frac{w}{u}, \nabla u \right \rangle.  $$ I don't understand how are these equal. When I tried to solve the derivative myself I found exactly these terms which I couldn't wish away. I found the same problem as an exercise in Chow, Lu, and Ni's book on Hamilton's Ricci flow as well. I would be happy to provide more details if needed.","I was reading Hopper and Andrews's book on Ricci flow in Riemannian Geometry. I came across the following proposition on the monotonicity of Perelman's -functional. Let evolve by Consider the function where . Also, consider the operator We have to show that I'm having trouble proving this. The book refers to Peter Topping's lecture notes on Ricci flow where the computation is done. In the first line of their proof, I found the following which I find problematic. They write I believe that the term comes from the following intermediate step, The last term in the above expression troubles me. What should have been simply is written as I don't understand how are these equal. When I tried to solve the derivative myself I found exactly these terms which I couldn't wish away. I found the same problem as an exercise in Chow, Lu, and Ni's book on Hamilton's Ricci flow as well. I would be happy to provide more details if needed.","\mathcal{W} (g(t),f(t), \tau(t)) \begin{align*}
\frac{\partial g}{\partial t} &= -2\text{Ric} \\
\frac{\partial f}{\partial t} &= -|\nabla f|^{2} + \Delta f - \text{Scal} + \frac{n}{2\tau} \\
\frac{d \tau}{d t} &= -1. 
\end{align*} 
w = (\tau(\text{Scal} + 2\Delta f - |\nabla f|^{2}) + f - n)u,
 u = (4\pi \tau)^{-n/2}e^{-f} 
\Box^{*} = -\frac{\partial}{\partial t} - \Delta + \text{Scal}. 
 
\Box^{*}w = -2\tau \left | \text{Ric} + \text{Hess}{f} - \frac{g}{2\tau} \right|^{2} u. 
 
\Box^{*}w = \Box^{*}(u) \frac{w}{u} - \left(\frac{\partial}{\partial t} + \Delta \right) \left(\frac{w}{u}\right) - 2 \left \langle \nabla \left( \frac{w}{u} \right) , \nabla u \right \rangle. 
 
\Box^{*}w = \Box^{*}(u) \left( \frac{w}{u} \right) + u \Box^{*}\left( \frac{w}{u} \right).
 
 u \text{Scal} \frac{w}{u}
 
-2\left \langle \nabla \frac{w}{u}, \nabla u \right \rangle. 
","['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
78,Definition of geodesic not as critical point of length $L_\gamma$ [*] [duplicate],Definition of geodesic not as critical point of length  [*] [duplicate],L_\gamma,"This question already has answers here : geodesic computation: ""energy"" minimization versus arc length minimization (2 answers) Closed 3 years ago . Context of this question: This question follows from a post Decomposition of a function and chain rule. and discusses on something different. Using calculation of variation we can find critical points of a function of a vaiable curve $\gamma$ with its end points fixed at $a,b$ and therefore defining geodesic on a manifold. (The rest of the paragraph is unnecessary reading for the question; it's mainly for the purpose of arranging my several posts on a topic.) Along the geodesic, exponential maps on a manifold project a tangent vector at a point $p$ (locally approximately linearly) to another point, as discussed here What is exponential map in differential geometry (a related but different concept of exponential maps of Lie group is discussed here Relations between two definitions of Lie algebra ). Geodesics have as such properties like the 'closed curve' { $\exp_p(v),\forall v$ of the same norm and belonging to $T_pM$ } is perpendicular to all the geodesics passing through $p$ , and is the shortest curve connecting $a,b$ (i.e. it's also a critical point for length). So we can say the 'closed curve' is very much resembles a circle, and a geodesic a radius or a straight line (We can perhaps even say that with geodesic and exponential maps we 'maps' projective geometry on to a manifold, similar to what we do when, with homeomorphism in definition of a manifold, we 'map' Euclidean space to a manifold). With the fact that geodesics is the shortest curve, we can define a metric (a measure of distance, NOT Riemannian metric which is an inner product and 2-tensor, as discussed here: Calculation of inner product for Riemannian metrics. ) on a manifold. The metric is homeomorphic to the original metric of the manifold, as discussed here Comparison of metrics on a manifold. . My question is as follows: A critical point of 'energy' (as Spivak calls it) $E(\gamma)=\int_a^b \langle \frac{d\gamma}{dt},\frac{d\gamma}{dt}\rangle dt$ --where $\frac{d\gamma}{dt}$ is tangent vector along $\gamma$ at the point of $\gamma(t)$ --is called geodesic. (I guess he uses the name 'energy' for in physics square of velocity is proportional to energy.) Why we define critical point for energy, instead of critical point for length $L(\gamma)=\int_a^b\sqrt{\langle \frac{d\gamma}{dt},\frac{d\gamma}{dt}\rangle} dt$ , to be geodesic?","This question already has answers here : geodesic computation: ""energy"" minimization versus arc length minimization (2 answers) Closed 3 years ago . Context of this question: This question follows from a post Decomposition of a function and chain rule. and discusses on something different. Using calculation of variation we can find critical points of a function of a vaiable curve with its end points fixed at and therefore defining geodesic on a manifold. (The rest of the paragraph is unnecessary reading for the question; it's mainly for the purpose of arranging my several posts on a topic.) Along the geodesic, exponential maps on a manifold project a tangent vector at a point (locally approximately linearly) to another point, as discussed here What is exponential map in differential geometry (a related but different concept of exponential maps of Lie group is discussed here Relations between two definitions of Lie algebra ). Geodesics have as such properties like the 'closed curve' { of the same norm and belonging to } is perpendicular to all the geodesics passing through , and is the shortest curve connecting (i.e. it's also a critical point for length). So we can say the 'closed curve' is very much resembles a circle, and a geodesic a radius or a straight line (We can perhaps even say that with geodesic and exponential maps we 'maps' projective geometry on to a manifold, similar to what we do when, with homeomorphism in definition of a manifold, we 'map' Euclidean space to a manifold). With the fact that geodesics is the shortest curve, we can define a metric (a measure of distance, NOT Riemannian metric which is an inner product and 2-tensor, as discussed here: Calculation of inner product for Riemannian metrics. ) on a manifold. The metric is homeomorphic to the original metric of the manifold, as discussed here Comparison of metrics on a manifold. . My question is as follows: A critical point of 'energy' (as Spivak calls it) --where is tangent vector along at the point of --is called geodesic. (I guess he uses the name 'energy' for in physics square of velocity is proportional to energy.) Why we define critical point for energy, instead of critical point for length , to be geodesic?","\gamma a,b p \exp_p(v),\forall v T_pM p a,b E(\gamma)=\int_a^b \langle \frac{d\gamma}{dt},\frac{d\gamma}{dt}\rangle dt \frac{d\gamma}{dt} \gamma \gamma(t) L(\gamma)=\int_a^b\sqrt{\langle \frac{d\gamma}{dt},\frac{d\gamma}{dt}\rangle} dt",['differential-geometry']
79,"If $M$ is a domain of class $\mathcal C$, is $\partial M$ a $(d-1)$-dimensional $\mathcal C$-submanifold?","If  is a domain of class , is  a -dimensional -submanifold?",M \mathcal C \partial M (d-1) \mathcal C,"Let $\mathcal C$ be a class of functions between Banach spaces, $d\in\mathbb N$ and $k\in\{1,\ldots,d\}$ . We say that $M\subseteq\mathbb R^d$ is a $k$ -dimensional embedded $\mathcal C$ -submanifold of $\mathbb R^d$ if $M$ is locally $\mathcal C$ -homeomorphic $^1$ to $\mathbb R^k$ . On the other hand, we say $^2$ that $\partial M$ is of class $\mathcal C$ if for each $x\in M$ , there is an open neighborhood $\Omega$ of $x$ and a function $g:\mathbb R^{d-1}\to\mathbb R$ of class $\mathcal C$ with $$\Omega\cap M=\{x\in\Omega:x_d>g(x_1,\ldots,x_{d-1})\}.\tag1$$ And lastly, if $M$ is compact, I've seen that people say that $\partial M$ is of class $C^1$ if for each $x\in M$ , there is an open neighborhood $\Omega$ of $x$ and a $\psi\in C^1(U)$ with $\psi'(x)\ne0$ for all $x\in\Omega$ and $$\Omega\cap M=\{\psi\le0\}\tag2.$$ How do all these three (the first applied for $\partial M$ instead of $M$ ) come together? Can we given an equivalent characterization of the second, which does not rely on an appropriate coordinate transformation? And how can we show that if $\partial M$ is of class $\mathcal C$ , then $\partial M$ is a $(d-1)$ -dimensional embedded $\mathcal C$ -submanifold? (I'm willing to assume that $M$ is bounded and open for this implication to hold.) It is clear that if $\partial M$ is of class $C^1$ (in the sense of the third definition), then $\partial M$ is a $(d-1)$ -dimensional embedded $C^1$ -submanifold $^1$ i.e. for each $x\in M$ , there is an open neighborhood $\Omega$ of $x$ and a homeomorphism $\varphi$ from $\Omega$ onto an open subset of $\mathbb R^k$ so that $\varphi$ and $\varphi^{-1}$ are of class $\mathcal C$ . $^2$ see Definition 7.2.1 here . I'm not happy with this definition, since it implicitly assumes an appropriate coordinate transformation.","Let be a class of functions between Banach spaces, and . We say that is a -dimensional embedded -submanifold of if is locally -homeomorphic to . On the other hand, we say that is of class if for each , there is an open neighborhood of and a function of class with And lastly, if is compact, I've seen that people say that is of class if for each , there is an open neighborhood of and a with for all and How do all these three (the first applied for instead of ) come together? Can we given an equivalent characterization of the second, which does not rely on an appropriate coordinate transformation? And how can we show that if is of class , then is a -dimensional embedded -submanifold? (I'm willing to assume that is bounded and open for this implication to hold.) It is clear that if is of class (in the sense of the third definition), then is a -dimensional embedded -submanifold i.e. for each , there is an open neighborhood of and a homeomorphism from onto an open subset of so that and are of class . see Definition 7.2.1 here . I'm not happy with this definition, since it implicitly assumes an appropriate coordinate transformation.","\mathcal C d\in\mathbb N k\in\{1,\ldots,d\} M\subseteq\mathbb R^d k \mathcal C \mathbb R^d M \mathcal C ^1 \mathbb R^k ^2 \partial M \mathcal C x\in M \Omega x g:\mathbb R^{d-1}\to\mathbb R \mathcal C \Omega\cap M=\{x\in\Omega:x_d>g(x_1,\ldots,x_{d-1})\}.\tag1 M \partial M C^1 x\in M \Omega x \psi\in C^1(U) \psi'(x)\ne0 x\in\Omega \Omega\cap M=\{\psi\le0\}\tag2. \partial M M \partial M \mathcal C \partial M (d-1) \mathcal C M \partial M C^1 \partial M (d-1) C^1 ^1 x\in M \Omega x \varphi \Omega \mathbb R^k \varphi \varphi^{-1} \mathcal C ^2","['differential-geometry', 'manifolds', 'smooth-manifolds', 'submanifold']"
80,Proof of Hadamard's theorem in book of Do Carmo,Proof of Hadamard's theorem in book of Do Carmo,,"I'm currently reading the book of Do Carmo but I don't understand something in the proof of Hadamard's theorem. He first proves two lemmas which I understand completely but in the actual proof of the theorem, he states that $\exp_p : T_pM \to M$ is a local isometry because it is a local diffeomorphism. However, he then says that the induced metric on $T_pM$ is complete because the geodesics that pass through the origin are straight lines. I don't really see how this follows and I was wondering if someone could help me understand.","I'm currently reading the book of Do Carmo but I don't understand something in the proof of Hadamard's theorem. He first proves two lemmas which I understand completely but in the actual proof of the theorem, he states that is a local isometry because it is a local diffeomorphism. However, he then says that the induced metric on is complete because the geodesics that pass through the origin are straight lines. I don't really see how this follows and I was wondering if someone could help me understand.",\exp_p : T_pM \to M T_pM,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
81,Modification of Law of Cosines,Modification of Law of Cosines,,"How should the Law of Cosines $$\cos c = \cos a \cos b + \sin a \sin b \cos C$$ be modified  if sides $(a,b,c) $ are not geodesics but are small circles with geodesic curvatures $k_a,k_b,k_c?$ It may be useful for navigation on the globe as airplanes and ships  do not always take the shortest path. EDIT1: Parallelly could we consider using radii ( of curvatures instead of curvatures directly? ... like $(R_a,R_b,R_c) $ along with triangle sides because there seems to be a possible advantage for direct spherical trigonometric calculations and simplifications on each triangle side. A schematic with a rough hand sketch of small circles:",How should the Law of Cosines be modified  if sides are not geodesics but are small circles with geodesic curvatures It may be useful for navigation on the globe as airplanes and ships  do not always take the shortest path. EDIT1: Parallelly could we consider using radii ( of curvatures instead of curvatures directly? ... like along with triangle sides because there seems to be a possible advantage for direct spherical trigonometric calculations and simplifications on each triangle side. A schematic with a rough hand sketch of small circles:,"\cos c = \cos a \cos b + \sin a \sin b \cos C (a,b,c)  k_a,k_b,k_c? (R_a,R_b,R_c) ","['differential-geometry', 'spherical-geometry']"
82,What exactly is a tangent space?,What exactly is a tangent space?,,"I'm self learning differential geometry and got confused by the definition of tangent space. The note I'm using defines tangent space of a smooth manifold $X\subset R^N$ with parametrization $f:U\rightarrow X$ as follow: $$T_xX=df_0(R^N) $$ where $$df_x=lim\frac{f(x+th)-f(x)}{t}$$ and $f(0)=x$ . So I suppose that if $f:R^N\rightarrow R$ , the tangent space would consist of real numbers. However, when I was reading the example on page 4 of this note ( https://folk.ntnu.no/gereonq/TMA4190V2018/TMA4190_Lecture12.pdf ), it states that the tangent space of a $f:R^3 \rightarrow R$ is $span\{(-z,0,x),(0,-z,y)\}$ which is not an output of the $df_x$ defined previously. Can someone please explain what exactly a tangent space is? Any help would be appreciated. I realized that I mistook the direction of the map in the example mentioned above.","I'm self learning differential geometry and got confused by the definition of tangent space. The note I'm using defines tangent space of a smooth manifold with parametrization as follow: where and . So I suppose that if , the tangent space would consist of real numbers. However, when I was reading the example on page 4 of this note ( https://folk.ntnu.no/gereonq/TMA4190V2018/TMA4190_Lecture12.pdf ), it states that the tangent space of a is which is not an output of the defined previously. Can someone please explain what exactly a tangent space is? Any help would be appreciated. I realized that I mistook the direction of the map in the example mentioned above.","X\subset R^N f:U\rightarrow X T_xX=df_0(R^N)  df_x=lim\frac{f(x+th)-f(x)}{t} f(0)=x f:R^N\rightarrow R f:R^3 \rightarrow R span\{(-z,0,x),(0,-z,y)\} df_x","['differential-geometry', 'manifolds', 'differential-topology']"
83,From Riemann tensor to Ricci tensor and vice versa,From Riemann tensor to Ricci tensor and vice versa,,"Is it possible to find the Riemann tensor using the Ricci tensor and also to switch from Riemann $(0,4)$ to Riemann $(1,3)$ ? I am not clear if these operations can only be carried out in one sense, I will explain better with these two questions. 1) $g^{bd}R_{abcd}=R_{ac}$ , where $R_{abcd}$ it is Riemann $(0,4)$ and $R_{ac}$ it is the Ricci tensor, is it now possible to get the Riemann tensor $(0,4)$ again this way: $R_{ac} g_{bd}=R_{abcd}$ ? 2) $g_{ae}R^a_{bcd}=R_{ebcd}$ , where $R^a_{bcd}$ it ise the Riemann $(1,3)$ and $R_{ebcd}$ it is the Riemann $(0,4)$ , is it now possible to get the Riemann tensor $(1,3)$ again this way: $g^{ae}R_{ebcd}=R^a_{bcd}$ ?","Is it possible to find the Riemann tensor using the Ricci tensor and also to switch from Riemann to Riemann ? I am not clear if these operations can only be carried out in one sense, I will explain better with these two questions. 1) , where it is Riemann and it is the Ricci tensor, is it now possible to get the Riemann tensor again this way: ? 2) , where it ise the Riemann and it is the Riemann , is it now possible to get the Riemann tensor again this way: ?","(0,4) (1,3) g^{bd}R_{abcd}=R_{ac} R_{abcd} (0,4) R_{ac} (0,4) R_{ac} g_{bd}=R_{abcd} g_{ae}R^a_{bcd}=R_{ebcd} R^a_{bcd} (1,3) R_{ebcd} (0,4) (1,3) g^{ae}R_{ebcd}=R^a_{bcd}","['differential-geometry', 'riemannian-geometry']"
84,Intuition behind tangent space to a point on a manifold,Intuition behind tangent space to a point on a manifold,,"Let $M$ be a smooth manifold and let $p \in M$ . We have a notion of a ""tangent space"" of $p$ , i.e. a vector space structure around $p$ to give us the idea, roughly, or ""directions we can travel in"" from $p$ , which an abstract manifold need not have inherently. I want to get a sense of the intuition behind what exactly a tangent vector is and how it's defined, and I break this up into four questions. 1) What is the purpose behind defining a tangent space? As I will write below, tangent vectors are defined in terms of directional derivative operators evaluated at $p$ . Is the only use behind tangent vectors to be able to take directional derivative? We might define a ""direction"" in our tangent space to be an operator that produces the directional derivative of a $C^{\infty}$ function in that ""direction"". Intuitively, this notion of direction doesn't look useful for doing anything other than taking directional derivatives; is that indeed the case? 2) Geometric Interpretation How would one visualize a tangent space? Say, for simplicity of picturing, that our manifold is actually a $k$ -submanifold in Euclidean space. In this case, isn't the tangent space every single vector in $\mathbb{R}^{k}$ ? How does this compare with visualizing the tangent space as a parallelepiped? 3) Definition 1: Smooth Curves We might define the tangent space as the equivalence class of all smooth curves $\gamma: \mathbb{R} \to M$ with $\gamma(0) = p$ , where two smooth curves $\gamma_{1}, \gamma_{2}$ are equivalent if $(\varphi \circ \gamma_{1})'(0) = (\varphi \circ \gamma_{2})'(0)$ . In this sense, each equivalence class defines a ""direction"" about $p$ , which helps us take directional derivatives. If $f: M \to \mathbb{R}$ is a smooth function, then $(f \circ \gamma)'(0)$ (differentiated in the ordinary sense, which makes sense here) is the directional derivative of $f$ in direction $\gamma$ . I again come back to my question of what use direction $\gamma$ is serving other than giving us directional derivatives. Now, I give the other definition, and want to know why these two definitions are exactly the same: 4) Definition 2: Directional Derivative Operator Note - This is often given in terms of ""derivations"" (linear maps that satisfy a generalized product rule, or Liebniz's rule): But a (non-trivial) result tells us that derivations are nothing but directional derivatives, so I stick to talking about directional derivatives here. Let $\mathcal{C}$ denote $C^{\infty}(M, \mathbb{R}$ ), i.e. smooth functions $M \to \mathbb{R}$ . Let $D_{\gamma}: \mathcal{C} \to \mathbb{R}$ be the operator s.t. $D_{\gamma}(f) = (f \circ \gamma)'(0)$ , where $\gamma: \mathbb{R} \to M$ is a smooth curve with $\gamma(0) = p$ , as above .We can define an equivalence relation (similar to what we did above) and define our tangent space to be all these ""directional derivative operators"" (that take a function and spit out its derivative in the direction of a smooth curve). In this sense, each ""direction"" in our tangent space is basically one of these operators. How is our notion of direction here same as the notion of direction we obtained in 3)? In one case, a curve (under equivalence relation) is our direction, while in this case, an operator (defined using a curve, but nevertheless different) is our direction. Further, this again brings me back to my question on whether direction and directional derivative can be used synonymously in this context. Thank you!","Let be a smooth manifold and let . We have a notion of a ""tangent space"" of , i.e. a vector space structure around to give us the idea, roughly, or ""directions we can travel in"" from , which an abstract manifold need not have inherently. I want to get a sense of the intuition behind what exactly a tangent vector is and how it's defined, and I break this up into four questions. 1) What is the purpose behind defining a tangent space? As I will write below, tangent vectors are defined in terms of directional derivative operators evaluated at . Is the only use behind tangent vectors to be able to take directional derivative? We might define a ""direction"" in our tangent space to be an operator that produces the directional derivative of a function in that ""direction"". Intuitively, this notion of direction doesn't look useful for doing anything other than taking directional derivatives; is that indeed the case? 2) Geometric Interpretation How would one visualize a tangent space? Say, for simplicity of picturing, that our manifold is actually a -submanifold in Euclidean space. In this case, isn't the tangent space every single vector in ? How does this compare with visualizing the tangent space as a parallelepiped? 3) Definition 1: Smooth Curves We might define the tangent space as the equivalence class of all smooth curves with , where two smooth curves are equivalent if . In this sense, each equivalence class defines a ""direction"" about , which helps us take directional derivatives. If is a smooth function, then (differentiated in the ordinary sense, which makes sense here) is the directional derivative of in direction . I again come back to my question of what use direction is serving other than giving us directional derivatives. Now, I give the other definition, and want to know why these two definitions are exactly the same: 4) Definition 2: Directional Derivative Operator Note - This is often given in terms of ""derivations"" (linear maps that satisfy a generalized product rule, or Liebniz's rule): But a (non-trivial) result tells us that derivations are nothing but directional derivatives, so I stick to talking about directional derivatives here. Let denote ), i.e. smooth functions . Let be the operator s.t. , where is a smooth curve with , as above .We can define an equivalence relation (similar to what we did above) and define our tangent space to be all these ""directional derivative operators"" (that take a function and spit out its derivative in the direction of a smooth curve). In this sense, each ""direction"" in our tangent space is basically one of these operators. How is our notion of direction here same as the notion of direction we obtained in 3)? In one case, a curve (under equivalence relation) is our direction, while in this case, an operator (defined using a curve, but nevertheless different) is our direction. Further, this again brings me back to my question on whether direction and directional derivative can be used synonymously in this context. Thank you!","M p \in M p p p p C^{\infty} k \mathbb{R}^{k} \gamma: \mathbb{R} \to M \gamma(0) = p \gamma_{1}, \gamma_{2} (\varphi \circ \gamma_{1})'(0) = (\varphi \circ \gamma_{2})'(0) p f: M \to \mathbb{R} (f \circ \gamma)'(0) f \gamma \gamma \mathcal{C} C^{\infty}(M, \mathbb{R} M \to \mathbb{R} D_{\gamma}: \mathcal{C} \to \mathbb{R} D_{\gamma}(f) = (f \circ \gamma)'(0) \gamma: \mathbb{R} \to M \gamma(0) = p","['real-analysis', 'differential-geometry', 'smooth-manifolds', 'tangent-spaces']"
85,Foliations and Geodesic Congruences,Foliations and Geodesic Congruences,,"I have a very basic question on the definition of foliations and geodesic congruences. My understanding is that: Geodesic congruences are families of geodesics such that locally, every point belongs to exactly one geodesic. Foliations an equivalence relation on an n-manifold, the equivalence classes being connected, injectively immersed submanifolds, all of the same dimension $p$ . One important distinction seems to be that foliations are defined on the entire manifold whereas geodesic congruences can be on any open subregion. For instance, a trivial example when the two coincide is when we have a family of parellel lines in $\mathbb{R}^2$ . We can also have the collection of axial circles on the torus. Unless I am mistaken, the collection of curves in both of these examples satisfy the definitions of geodesic congruences and foliations. My question: if given a foliation of a manifold by geodesics, do we have a geodesic congruence? The answer seems to be in the affirmative, and (at least in terms of the picture I have in my head) the two notions seem very closely related, however I have not found any resources that talk about both of them.","I have a very basic question on the definition of foliations and geodesic congruences. My understanding is that: Geodesic congruences are families of geodesics such that locally, every point belongs to exactly one geodesic. Foliations an equivalence relation on an n-manifold, the equivalence classes being connected, injectively immersed submanifolds, all of the same dimension . One important distinction seems to be that foliations are defined on the entire manifold whereas geodesic congruences can be on any open subregion. For instance, a trivial example when the two coincide is when we have a family of parellel lines in . We can also have the collection of axial circles on the torus. Unless I am mistaken, the collection of curves in both of these examples satisfy the definitions of geodesic congruences and foliations. My question: if given a foliation of a manifold by geodesics, do we have a geodesic congruence? The answer seems to be in the affirmative, and (at least in terms of the picture I have in my head) the two notions seem very closely related, however I have not found any resources that talk about both of them.",p \mathbb{R}^2,"['general-relativity', 'differential-geometry']"
86,Why are these two definitions of a connection equivalent?,Why are these two definitions of a connection equivalent?,,"I'm working through Kai Khler's ""Differentialgeometrie und homogene Rume"" (Differential geometry and homogenous spaces) and struggle to understand the notion of a connection on a vector bundle. In particular, I do not completely understand why two definitions are equivalent. The main definition that the author gives is the following: Let $ E \to M$ be a vector bundle. A (covariant) connection $\nabla$ on $E$ is a $\mathbb{R}$ -linear map $\nabla:\Gamma(M,E)\to \Gamma(M,T^*M \otimes E)$ , that satisfies Leibniz's rule: $\forall f\in C^\infty(M),s\in \Gamma(M,E): \nabla(f\cdot s) = df \otimes s + f\nabla s$ . Apparently, it is equivalent to ask for $\nabla$ to be a map $\nabla:\Gamma(M,TM) \times \Gamma(M,E) \to \Gamma(M,E)$ , that is $C^{\infty}$ -linear in the first and satisfies the Leibniz rule in the second argument. Why does this hold? Also, what is a good intuition to think about $df \otimes s$ ?","I'm working through Kai Khler's ""Differentialgeometrie und homogene Rume"" (Differential geometry and homogenous spaces) and struggle to understand the notion of a connection on a vector bundle. In particular, I do not completely understand why two definitions are equivalent. The main definition that the author gives is the following: Let be a vector bundle. A (covariant) connection on is a -linear map , that satisfies Leibniz's rule: . Apparently, it is equivalent to ask for to be a map , that is -linear in the first and satisfies the Leibniz rule in the second argument. Why does this hold? Also, what is a good intuition to think about ?"," E \to M \nabla E \mathbb{R} \nabla:\Gamma(M,E)\to \Gamma(M,T^*M \otimes E) \forall f\in C^\infty(M),s\in \Gamma(M,E): \nabla(f\cdot s) = df \otimes s + f\nabla s \nabla \nabla:\Gamma(M,TM) \times \Gamma(M,E) \to \Gamma(M,E) C^{\infty} df \otimes s","['differential-geometry', 'vector-bundles', 'connections']"
87,Constructing a normal variation using a given smooth function with zero mean,Constructing a normal variation using a given smooth function with zero mean,,"Let $x_0:\Sigma^n\to\mathbb{R}^{n+1}$ be an immersion of an orientable compact $n$ -dimensional smooth manifold into the Euclidean space. It is well-known that given a smooth function $\varphi:\Sigma\to\mathbb{R}$ satisfying the zero-mean condition: \begin{align} \int_{\Sigma}\varphi d\mu=0 \end{align} (where $d\mu$ is the area element in the induced metric), there always exist a volume-preserving normal variation $X:\Sigma\times(-\epsilon,\epsilon)\to\mathbb{R}^{n+1}$ whose variation vector field is \begin{align} Y:=\frac{\partial X}{\partial t}\bigg|_{t=0}=\varphi\nu \end{align} where $\nu$ is the unit normal. In Barbosa-do Carmo , the proof begins by considering a two-parameter family of immersion \begin{align} x(t,u)=x_0+(t\varphi+ug)\nu & & (1) \end{align} (where $g:\Sigma\to\mathbb{R}$ is any smooth function with $g\equiv 0$ on the boundary $\partial\Sigma$ and $\int_{\Sigma}gd\mu\neq 0$ ), then considers the equation \begin{align} V(t,u)=const \end{align} (where $V(t,u)$ is the volume of $x(t,u)$ ) and use the implicit function theorem to deduce that $u$ can be expressed as a function of $t$ in a small open neighbourhood of $0\in\mathbb{R}$ . Finally, one checks that $X(p,t)=x(t,u(t))(p)$ is the desired volume-preserving normal variation of $x_0$ . My question is the following: Instead of considering (1), why not the   proof considers the one-parameter family \begin{align} x(t)=x_0+t\varphi\nu & & (2)  \end{align} of immersions? This seems to directly give the desired variation (by setting $X(p,t)=x(t)(p)$ ) and it looks simpler than (1). For one thing, a big theorem like implicit function theorem will not be needed. Is there any reason that I've failed to observe which makes it necessary to consider (2) instead of (1)? Any comment or answer is welcomed and greatly appreciated.","Let be an immersion of an orientable compact -dimensional smooth manifold into the Euclidean space. It is well-known that given a smooth function satisfying the zero-mean condition: (where is the area element in the induced metric), there always exist a volume-preserving normal variation whose variation vector field is where is the unit normal. In Barbosa-do Carmo , the proof begins by considering a two-parameter family of immersion (where is any smooth function with on the boundary and ), then considers the equation (where is the volume of ) and use the implicit function theorem to deduce that can be expressed as a function of in a small open neighbourhood of . Finally, one checks that is the desired volume-preserving normal variation of . My question is the following: Instead of considering (1), why not the   proof considers the one-parameter family of immersions? This seems to directly give the desired variation (by setting ) and it looks simpler than (1). For one thing, a big theorem like implicit function theorem will not be needed. Is there any reason that I've failed to observe which makes it necessary to consider (2) instead of (1)? Any comment or answer is welcomed and greatly appreciated.","x_0:\Sigma^n\to\mathbb{R}^{n+1} n \varphi:\Sigma\to\mathbb{R} \begin{align}
\int_{\Sigma}\varphi d\mu=0
\end{align} d\mu X:\Sigma\times(-\epsilon,\epsilon)\to\mathbb{R}^{n+1} \begin{align}
Y:=\frac{\partial X}{\partial t}\bigg|_{t=0}=\varphi\nu
\end{align} \nu \begin{align}
x(t,u)=x_0+(t\varphi+ug)\nu & & (1)
\end{align} g:\Sigma\to\mathbb{R} g\equiv 0 \partial\Sigma \int_{\Sigma}gd\mu\neq 0 \begin{align}
V(t,u)=const
\end{align} V(t,u) x(t,u) u t 0\in\mathbb{R} X(p,t)=x(t,u(t))(p) x_0 \begin{align}
x(t)=x_0+t\varphi\nu & & (2) 
\end{align} X(p,t)=x(t)(p)","['differential-geometry', 'riemannian-geometry', 'calculus-of-variations']"
88,Length of a planar curve,Length of a planar curve,,"Let $\gamma:[0,L]\rightarrow \mathbb{R}^2$ be a $C^\infty$ curve parameterized by arc length. We suppose that $\gamma$ is a simple closed curve that bounds a bounded domain in $\mathbb{R}^2$ . We denote by $\nu(t)$ the inward unit normal at $\gamma(t)$ . For any $\epsilon>0$ sufficiently small, $t\in[0,L]\mapsto \gamma_\epsilon(t)=\gamma(t)+\epsilon \nu(t)$ is a still a smooth curve. Question. Is it true that the length of the curve $\gamma_\epsilon$ is less than or equal to the length of $\gamma$ ? ","Let be a curve parameterized by arc length. We suppose that is a simple closed curve that bounds a bounded domain in . We denote by the inward unit normal at . For any sufficiently small, is a still a smooth curve. Question. Is it true that the length of the curve is less than or equal to the length of ? ","\gamma:[0,L]\rightarrow \mathbb{R}^2 C^\infty \gamma \mathbb{R}^2 \nu(t) \gamma(t) \epsilon>0 t\in[0,L]\mapsto \gamma_\epsilon(t)=\gamma(t)+\epsilon \nu(t) \gamma_\epsilon \gamma",['differential-geometry']
89,What kind of object is the jacobian in differential geometry?,What kind of object is the jacobian in differential geometry?,,"I know the jacobian from multivariate calculus, i.e. not in the context of differential geometry. Differential geometry gives a nice abstract language for differentiation. I find the concept of a ""tangent space"" particularly clarifying. I don't know how the jacobian fits in this picture. Is there a differential geometry version of the jacobian?","I know the jacobian from multivariate calculus, i.e. not in the context of differential geometry. Differential geometry gives a nice abstract language for differentiation. I find the concept of a ""tangent space"" particularly clarifying. I don't know how the jacobian fits in this picture. Is there a differential geometry version of the jacobian?",,"['differential-geometry', 'jacobian']"
90,The existence of a square!,The existence of a square!,,"My question is the following: There exists an homeomorphism from a Moebius band to a subset of $\mathbb{R}^3$ such that $\partial M$ is mapped in a continuous closed simple curve of $\mathbb{R}^3$ contained in a plane? I've done this question because I would to prove the following interesting property: I think that this problem is well known, but I don't understand how to prove it. Let $\gamma=(\gamma_1,\gamma_2)$ be a continuous closed simple curve of $\mathbb{R}^2$ , so $\gamma:[0,1]\to \mathbb{R}^2$ is injective in $(0,1)$ , $\gamma(0)=\gamma(1)$ and it's a continuous function. The question is if there exists $4$ points $A,B,C,D$ on this curve for which the polygon $ABCD$ results to be a square. I guess is possible to prove a weaker thesis in a simple way, substituting the existence of a square with the existence of a rectangle. We know that $ABCD$ would be a rectangle if and only if $AB\cap CD=\{M\}$ where $M$ is the middle point of $AB$ and $CD$ , and $AB\cong CD$ .  Now we can interpret this property in this way: We define the following map $F:[0,1]\times [0,1]\to \mathbb{R}^3$ that maps each couple $(a,b)$ to $F(a,b):=\left(\frac{\gamma_1(a)+\gamma_1(b)}{2},\frac{\gamma_2(a)+\gamma_2(b)}{2}, ||\gamma(a)\gamma(b)||\right)$ This map associate to each couple of points $A$ and $B$ on the curve $\gamma$ , their middle point $M$ and the distance between them. We can observe that this map is continuous and it holds the following property: $F(0,b)=F(1,b)$ ; $F(a,0)=F(a,1)$ ; $F(a,b)=F(b,a)$ ; $F(a,a)=(\gamma(a),0)$ ; We define the following equivalence relation $\sim$ on $[0,1]\times [0,1]$ : for each $(a,b), (a',b')$ we say $a\sim b \iff (a,b)=(a',b')$ or $b=b'$ , $a=0,a'=1$ or $a=a'$ , $b=0,b'=1$ or $a=b'$ , $b=a'$ It's easy to check that $[0,1]\times[0,1]/\sim$ is the Moebius band $M$ and it's boundary is the image with respect the projection map of the diagonal $\Delta:=\{(a,a): a\in [0,1]\}$ . Now we observe that the map $F$ with that $4$ property induces a natural map $F^\sim : M\to \mathbb{R}^3$ defined in the following way: $F^\sim([(a,b)]):=F(a,b)$ Is clear that $F^\sim$ is a continuous map. Moreover we have $F^\sim([(a,a)])=(\gamma(a),0)\in \gamma([0,1])\times \{0\}$ , thus the boundary of the Moebius band $M$ is mapped by $F^\sim$ in a simple closed continuous curve of $\mathbb{R}^3$ contained in the plane $\{z=0\}$ . We observe that the existence of the rectangle $ABCD$ on the curve $\gamma$ is equivalent to say that the map $F^\sim$ is not injective. Arguing by contradiction, if $F^\sim$ would be injective, then $F^\sim: M\to F^\sim(M)\subseteq \mathbb{R}^3$ would be an homeomorphism because $M$ is compact and $\mathbb{R}^3$ is Housdorff, that means $F^\sim$ is also a closed map. Now the question is: There exists an homeomorphism from $M$ to a subset of $\mathbb{R}^3$ such that $\partial M$ is mapped in a continuous closed simple curve of $\mathbb{R}^3$ contained in a plane? I think that the answer is no, but I don't understand how to prove it.","My question is the following: There exists an homeomorphism from a Moebius band to a subset of such that is mapped in a continuous closed simple curve of contained in a plane? I've done this question because I would to prove the following interesting property: I think that this problem is well known, but I don't understand how to prove it. Let be a continuous closed simple curve of , so is injective in , and it's a continuous function. The question is if there exists points on this curve for which the polygon results to be a square. I guess is possible to prove a weaker thesis in a simple way, substituting the existence of a square with the existence of a rectangle. We know that would be a rectangle if and only if where is the middle point of and , and .  Now we can interpret this property in this way: We define the following map that maps each couple to This map associate to each couple of points and on the curve , their middle point and the distance between them. We can observe that this map is continuous and it holds the following property: ; ; ; ; We define the following equivalence relation on : for each we say or , or , or , It's easy to check that is the Moebius band and it's boundary is the image with respect the projection map of the diagonal . Now we observe that the map with that property induces a natural map defined in the following way: Is clear that is a continuous map. Moreover we have , thus the boundary of the Moebius band is mapped by in a simple closed continuous curve of contained in the plane . We observe that the existence of the rectangle on the curve is equivalent to say that the map is not injective. Arguing by contradiction, if would be injective, then would be an homeomorphism because is compact and is Housdorff, that means is also a closed map. Now the question is: There exists an homeomorphism from to a subset of such that is mapped in a continuous closed simple curve of contained in a plane? I think that the answer is no, but I don't understand how to prove it.","\mathbb{R}^3 \partial M \mathbb{R}^3 \gamma=(\gamma_1,\gamma_2) \mathbb{R}^2 \gamma:[0,1]\to \mathbb{R}^2 (0,1) \gamma(0)=\gamma(1) 4 A,B,C,D ABCD ABCD AB\cap CD=\{M\} M AB CD AB\cong CD F:[0,1]\times [0,1]\to \mathbb{R}^3 (a,b) F(a,b):=\left(\frac{\gamma_1(a)+\gamma_1(b)}{2},\frac{\gamma_2(a)+\gamma_2(b)}{2}, ||\gamma(a)\gamma(b)||\right) A B \gamma M F(0,b)=F(1,b) F(a,0)=F(a,1) F(a,b)=F(b,a) F(a,a)=(\gamma(a),0) \sim [0,1]\times [0,1] (a,b), (a',b') a\sim b \iff (a,b)=(a',b') b=b' a=0,a'=1 a=a' b=0,b'=1 a=b' b=a' [0,1]\times[0,1]/\sim M \Delta:=\{(a,a): a\in [0,1]\} F 4 F^\sim : M\to \mathbb{R}^3 F^\sim([(a,b)]):=F(a,b) F^\sim F^\sim([(a,a)])=(\gamma(a),0)\in \gamma([0,1])\times \{0\} M F^\sim \mathbb{R}^3 \{z=0\} ABCD \gamma F^\sim F^\sim F^\sim: M\to F^\sim(M)\subseteq \mathbb{R}^3 M \mathbb{R}^3 F^\sim M \mathbb{R}^3 \partial M \mathbb{R}^3","['differential-geometry', 'algebraic-topology', 'knot-theory']"
91,What does it mean with real manifold with complex structure?,What does it mean with real manifold with complex structure?,,"For example on wikipedia I found that one can also define a Hermitian manifold as a real manifold with a Riemannian metric that preserves a complex structure. For real manifold it should be understood a manifold with real charts, i.e., diffeomorphisms from an open subsets of M and open subsets of $\mathbb{R}^n$ , then what does it mean with complex structure? is only the complexification of its tangent space?","For example on wikipedia I found that one can also define a Hermitian manifold as a real manifold with a Riemannian metric that preserves a complex structure. For real manifold it should be understood a manifold with real charts, i.e., diffeomorphisms from an open subsets of M and open subsets of , then what does it mean with complex structure? is only the complexification of its tangent space?",\mathbb{R}^n,['differential-geometry']
92,Algebraic (?) proof that Ricci form is closed,Algebraic (?) proof that Ricci form is closed,,"Let $(M,\omega, J, g)$ be a Khler manifold. The Ricci form of $M$ is defined as $\rho(X,Y)={\rm Ric}(JX,Y)$ . I wanted to give a possibly coordinate-free proof that ${\rm d}\rho=0$ . From the condition $\nabla J=0$ we have that $${\rm d}\rho(X,Y,Z) = (\nabla_X{\rm Ric})(JY,Z) +(\nabla_Y{\rm Ric})(JZ,X)+(\nabla_Z{\rm Ric})(JX,Y).$$ I'm guessing that there is a smart way of using the second Bianchi identity to get the result from the above, but I can't see how to deal with terms of the form $\nabla_{JX}$ . Also the fact that the second Bianchi identity is true for all connections makes me think that it might not be powerful enough. Help?","Let be a Khler manifold. The Ricci form of is defined as . I wanted to give a possibly coordinate-free proof that . From the condition we have that I'm guessing that there is a smart way of using the second Bianchi identity to get the result from the above, but I can't see how to deal with terms of the form . Also the fact that the second Bianchi identity is true for all connections makes me think that it might not be powerful enough. Help?","(M,\omega, J, g) M \rho(X,Y)={\rm Ric}(JX,Y) {\rm d}\rho=0 \nabla J=0 {\rm d}\rho(X,Y,Z) = (\nabla_X{\rm Ric})(JY,Z) +(\nabla_Y{\rm Ric})(JZ,X)+(\nabla_Z{\rm Ric})(JX,Y). \nabla_{JX}","['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
93,Equivalent definitions of foliation,Equivalent definitions of foliation,,"I am having trouble proving the equivalence of two different definitions of foliation. The first one is the one where you define a k-foliation on a smooth manifold $M$ with k-dimensional leaves such that every point has a local chart that sends all these submanifolds in ""horizontal subspaces"" of $\mathbb{R}^n$ . The second definition is the one where you require an atlas with transition functions like $\phi_{ij}(x,y)=(\phi^1 _{ij}(x,y), \phi^2 _{ij}(y))$ . I am not being formal because I think these are quite common definitions, and you know what I am talking about. The problem is proving that the second definition implies the first. The teacher suggests taking different topologies on $\mathbb{R}^k$ and $\mathbb{R}^{n-k}$ and then the product topology, but it is a quite short hint and I really don't understand what to do. Also, it is pointed out that the biggest problem here would be the second countability, but I can't understand the reasoning I should do. This equivalence is stated right after the two definitions are given, so there shouldn't be any need of particular results concerning foliations.","I am having trouble proving the equivalence of two different definitions of foliation. The first one is the one where you define a k-foliation on a smooth manifold with k-dimensional leaves such that every point has a local chart that sends all these submanifolds in ""horizontal subspaces"" of . The second definition is the one where you require an atlas with transition functions like . I am not being formal because I think these are quite common definitions, and you know what I am talking about. The problem is proving that the second definition implies the first. The teacher suggests taking different topologies on and and then the product topology, but it is a quite short hint and I really don't understand what to do. Also, it is pointed out that the biggest problem here would be the second countability, but I can't understand the reasoning I should do. This equivalence is stated right after the two definitions are given, so there shouldn't be any need of particular results concerning foliations.","M \mathbb{R}^n \phi_{ij}(x,y)=(\phi^1 _{ij}(x,y), \phi^2 _{ij}(y)) \mathbb{R}^k \mathbb{R}^{n-k}","['differential-geometry', 'manifolds', 'smooth-manifolds', 'foliations']"
94,Existence of only finitely many geodesics,Existence of only finitely many geodesics,,"The following question arose from Theorem 16.3 (p.90) in the book Morse theory from John Milnor. We are dealing with a complete Riemannian manifold $M$ , an $a \in \mathbb{R_{>0}}$ and two points $p,q \in M$ which are not conjugate along any geodesic from $p$ to $q$ of length $\le \sqrt{a}$ . Then the question is: Why are there only finitely many geodesics from $p$ to $q$ of length $\le \sqrt{a}$ . I have already tried arguing this way: Assume that there are infinitely many geodesics $(\gamma_n)_{n \in \mathbb{N}}$ of the kind spoken of. Since the closed ball $B:=\{ v \in T_pM : \Vert v \Vert \le \sqrt{a}\}$ is compact (by Heine-Borel), there exists a subsequence of the vectors $(\gamma_n(0))_{n \in \mathbb{N}} \in B$ which converges against an $v_\infty \in B$ . The fact that solutions of DGLs depend continuously on the initial value provides that the curve $\gamma_{v_\infty} = exp(t \cdot v_\infty)$ also ends in $q$ . Now the idea is, that this sequence yields a proper, geodesic variation $\alpha:(-\varepsilon, \varepsilon) \times [0,1] \to M$ of $\gamma_{v_\infty}=\alpha(0,-)$ . This would yield a Jacobifield $J=\frac{D}{ds}\alpha(0,t)$ along $\gamma_{v_\infty}$ , which vanishes at $p$ and $q$ , so we get a contradiction to the premise that $p$ and $q$ are not conjugate along any geodesic. Solution : I don't think there is a way to extract uncountably many geodesics of length $\le \sqrt{a}$ , all of which connect $p$ and $q$ . So first of all, to get a variation $\alpha:(-1,1) \times [0,1] \to M$ we may do the following: Let $(v_n)_{n \in \mathbb{N}}$ be the (sub)sequence converging to $v_\infty$ . Set $v:(-1,1) \to B; v\left(\frac{1}{n}\right) := v_n$ for $n \ge 2$ . Then extend $v$ differentiably (i.e. by connecting the $v_n$ through lines and then smoothing the edges out). Finally, set $\alpha(s,t) := exp(t \cdot v(s))$ . As $M$ is complete, this makes sense and is well defined. This certainly is a geodesic variation of $\gamma_{v_\infty}$ . What remains to show is that the vector field $\frac{D}{ds}\alpha(0,t)$ vanishes at $q$ (to get the contradiction from above). Notice, that the $\alpha(s,-)$ mustn't connect $p$ and $q$ for all $s$ , but for $s=\frac{1}{n}$ . Since $\alpha$ is differentiable, we can compute $\frac{D}{ds}\alpha(0,1)$ by choosing the sequence $(s_n=\frac{1}{n})_{n \in \mathbb{N}}$ which yields $\frac{D}{ds}\alpha(0,1) = 0$ since the difference quotient is 0 for all $s_n$ because the $\alpha(s_n,-)$ connect $p$ and $q$ by our assumption.","The following question arose from Theorem 16.3 (p.90) in the book Morse theory from John Milnor. We are dealing with a complete Riemannian manifold , an and two points which are not conjugate along any geodesic from to of length . Then the question is: Why are there only finitely many geodesics from to of length . I have already tried arguing this way: Assume that there are infinitely many geodesics of the kind spoken of. Since the closed ball is compact (by Heine-Borel), there exists a subsequence of the vectors which converges against an . The fact that solutions of DGLs depend continuously on the initial value provides that the curve also ends in . Now the idea is, that this sequence yields a proper, geodesic variation of . This would yield a Jacobifield along , which vanishes at and , so we get a contradiction to the premise that and are not conjugate along any geodesic. Solution : I don't think there is a way to extract uncountably many geodesics of length , all of which connect and . So first of all, to get a variation we may do the following: Let be the (sub)sequence converging to . Set for . Then extend differentiably (i.e. by connecting the through lines and then smoothing the edges out). Finally, set . As is complete, this makes sense and is well defined. This certainly is a geodesic variation of . What remains to show is that the vector field vanishes at (to get the contradiction from above). Notice, that the mustn't connect and for all , but for . Since is differentiable, we can compute by choosing the sequence which yields since the difference quotient is 0 for all because the connect and by our assumption.","M a \in \mathbb{R_{>0}} p,q \in M p q \le \sqrt{a} p q \le \sqrt{a} (\gamma_n)_{n \in \mathbb{N}} B:=\{ v \in T_pM : \Vert v \Vert \le \sqrt{a}\} (\gamma_n(0))_{n \in \mathbb{N}} \in B v_\infty \in B \gamma_{v_\infty} = exp(t \cdot v_\infty) q \alpha:(-\varepsilon, \varepsilon) \times [0,1] \to M \gamma_{v_\infty}=\alpha(0,-) J=\frac{D}{ds}\alpha(0,t) \gamma_{v_\infty} p q p q \le \sqrt{a} p q \alpha:(-1,1) \times [0,1] \to M (v_n)_{n \in \mathbb{N}} v_\infty v:(-1,1) \to B; v\left(\frac{1}{n}\right) := v_n n \ge 2 v v_n \alpha(s,t) := exp(t \cdot v(s)) M \gamma_{v_\infty} \frac{D}{ds}\alpha(0,t) q \alpha(s,-) p q s s=\frac{1}{n} \alpha \frac{D}{ds}\alpha(0,1) (s_n=\frac{1}{n})_{n \in \mathbb{N}} \frac{D}{ds}\alpha(0,1) = 0 s_n \alpha(s_n,-) p q","['differential-geometry', 'geodesic', 'morse-theory']"
95,Understand the need of affine connection,Understand the need of affine connection,,"I can't understand why textbook says that directional derivative cannot be defined for general manifold, and a separate affine connection is needed. Assume there are two vector fields $X$ and $Y$ . In particular, you have a tangent vector at point $p$ called $X_p$ . To find the derivative of $Y$ at $p$ in the direction of $X_p$ , why can't you just operate $X_p = a^i\partial_i$ on $Y_p = b^j \partial_j$ component-wise? By component-wise, I meant differentiate the component smooth function $b^j$ with respect to $X_p$ . It seems that a smooth real valued function can still be differentiated by a vector field without connection?","I can't understand why textbook says that directional derivative cannot be defined for general manifold, and a separate affine connection is needed. Assume there are two vector fields and . In particular, you have a tangent vector at point called . To find the derivative of at in the direction of , why can't you just operate on component-wise? By component-wise, I meant differentiate the component smooth function with respect to . It seems that a smooth real valued function can still be differentiated by a vector field without connection?",X Y p X_p Y p X_p X_p = a^i\partial_i Y_p = b^j \partial_j b^j X_p,['differential-geometry']
96,"Vector fields - Chapter 0, Do Carmo's Riemannian Geometry","Vector fields - Chapter 0, Do Carmo's Riemannian Geometry",,"There's the following observation with a very short proof: Observe that if $\varphi : M \to M$ is a diffeomorphism, $v \in T_p M$ and $f$ is a differentiable function in a neighborhood of $\varphi(p)$ , we have $$ (d\varphi(p) f) \varphi (p) = v(f \circ \varphi)(p) $$ Indeed, let $\alpha : (-\epsilon, \epsilon) \to M$ be a differentiable curve with $\alpha'(0) = v$ and $\alpha(0) = p$ . Then $$ (d \varphi (v) f) \varphi (p) = \left. \frac{d}{dt} (f \circ \varphi \circ \alpha) \right|_{t=0} = v(f \circ \varphi)(p) $$ I don't get the very last line, I suppose it follows from the definition given of tangent vector, but I really can't work out the details. Could you explain more in detail that line? Thank you (P.S. here $M$ is a differentiable manifold). Update : In the statement of this theorem $\beta$ is defined as $\beta = \varphi \circ \alpha$ . Given a curve $\alpha : (-\epsilon,\epsilon) \to M$ (differentiable manifold) a tangent vector is defined as $$ \alpha'(0) f = \frac{d}{dt} (f \circ \alpha). $$ Using $\beta$ instead of $\alpha$ we have $$ \beta'(0)f = \frac{d}{dt}(f \circ \beta) = \frac{d}{dt}(f \circ \varphi \circ \alpha) $$ but $\beta'(0) = d \varphi_p(v)$ therefore $\beta'(0) f = d \varphi_p(v) f$ and therefore we have $$ d \varphi_p(v) f = \frac{d}{dt}(f \circ \varphi \circ \alpha) $$ Therefore what I think I'm actually missing is the meaning of the notation $ \left( d \varphi_p(v) f \right) \varphi(p)$ More details Just to clarify, my previous update is my interpretation of the notation used, I've noticed there's some inconsistencies (I think) in the notation used throughout the book (at least for chapter 0). 1) In definition 2.6. The author defines a tangent vector to a differentiable manifold $M$ as an operator $\alpha'(0) : \cal{D} \to \mathbb{R}$ , where $\cal{D}$ is the set of differentiable functions defined on $M$ . Such description makes very clear to me the meaning of the notation $\alpha'(0)f$ , If I view it as an operator. Moreover we have the expression given $$ \alpha'(0) f = \frac{d}{dt}(f \circ \alpha) $$ The right handside of the expression in terms of computation is clear to me, because of the parameterization. 2) In proposition 2.7, given a differentiable map $\varphi$ between two differentiable manifolds $M_1^n, M_2^m$ and the differential $d \varphi_p(v)$ is defined. To define this differential we need a $p \in M_1^n$ and a tangent vector $v \in T_p M_1^n$ . The differential is a map from $T_p M_1^n$ to $T_{\varphi(p)} M_2^m$ , and therefore it acts as an operator from the set of differentiable functions on $M_2^m$ to $\mathbb{R}$ . Thefore the meaning of the notation $ d \varphi_p(v) f $ is still clear to me. 3) My original question concern page 26 of the book, where the notation $(d \varphi(v) f)\varphi(p)$ is introduced. The reason I get confused is in the first place I think there's a mistake in the notation used because if you compare $d \varphi_p(v) f$ against $(d \varphi (v) f) \varphi(p)$ there's some difference. I don't know for example what $d \varphi(v)$ means, but I do know what $d \varphi_p(v)$ means. Also $d \varphi_p(v) f$ returns a real value by definition and this doesn't not seem evident to me from $(d \varphi(v) f) \varphi(p)$ . I hope I clarified what my issue is.","There's the following observation with a very short proof: Observe that if is a diffeomorphism, and is a differentiable function in a neighborhood of , we have Indeed, let be a differentiable curve with and . Then I don't get the very last line, I suppose it follows from the definition given of tangent vector, but I really can't work out the details. Could you explain more in detail that line? Thank you (P.S. here is a differentiable manifold). Update : In the statement of this theorem is defined as . Given a curve (differentiable manifold) a tangent vector is defined as Using instead of we have but therefore and therefore we have Therefore what I think I'm actually missing is the meaning of the notation More details Just to clarify, my previous update is my interpretation of the notation used, I've noticed there's some inconsistencies (I think) in the notation used throughout the book (at least for chapter 0). 1) In definition 2.6. The author defines a tangent vector to a differentiable manifold as an operator , where is the set of differentiable functions defined on . Such description makes very clear to me the meaning of the notation , If I view it as an operator. Moreover we have the expression given The right handside of the expression in terms of computation is clear to me, because of the parameterization. 2) In proposition 2.7, given a differentiable map between two differentiable manifolds and the differential is defined. To define this differential we need a and a tangent vector . The differential is a map from to , and therefore it acts as an operator from the set of differentiable functions on to . Thefore the meaning of the notation is still clear to me. 3) My original question concern page 26 of the book, where the notation is introduced. The reason I get confused is in the first place I think there's a mistake in the notation used because if you compare against there's some difference. I don't know for example what means, but I do know what means. Also returns a real value by definition and this doesn't not seem evident to me from . I hope I clarified what my issue is.","\varphi : M \to M v \in T_p M f \varphi(p) 
(d\varphi(p) f) \varphi (p) = v(f \circ \varphi)(p)
 \alpha : (-\epsilon, \epsilon) \to M \alpha'(0) = v \alpha(0) = p 
(d \varphi (v) f) \varphi (p) = \left. \frac{d}{dt} (f \circ \varphi \circ \alpha) \right|_{t=0} = v(f \circ \varphi)(p)
 M \beta \beta = \varphi \circ \alpha \alpha : (-\epsilon,\epsilon) \to M 
\alpha'(0) f = \frac{d}{dt} (f \circ \alpha).
 \beta \alpha 
\beta'(0)f = \frac{d}{dt}(f \circ \beta) = \frac{d}{dt}(f \circ \varphi \circ \alpha)
 \beta'(0) = d \varphi_p(v) \beta'(0) f = d \varphi_p(v) f 
d \varphi_p(v) f = \frac{d}{dt}(f \circ \varphi \circ \alpha)
  \left( d \varphi_p(v) f \right) \varphi(p) M \alpha'(0) : \cal{D} \to \mathbb{R} \cal{D} M \alpha'(0)f 
\alpha'(0) f = \frac{d}{dt}(f \circ \alpha)
 \varphi M_1^n, M_2^m d \varphi_p(v) p \in M_1^n v \in T_p M_1^n T_p M_1^n T_{\varphi(p)} M_2^m M_2^m \mathbb{R}  d \varphi_p(v) f  (d \varphi(v) f)\varphi(p) d \varphi_p(v) f (d \varphi (v) f) \varphi(p) d \varphi(v) d \varphi_p(v) d \varphi_p(v) f (d \varphi(v) f) \varphi(p)","['differential-geometry', 'proof-explanation']"
97,Can an injective smooth map from a smooth manifold into another smooth manifold have a discontinuous inverse?,Can an injective smooth map from a smooth manifold into another smooth manifold have a discontinuous inverse?,,"I think the answer is yes. See the example below: we consider the open interval $(-1,\infty)$ as an open submanifold of the smooth manifold $(i,\mathbb{R})$ with $i:\mathbb{R}\rightarrow \mathbb{R},i(x)=x$ being the chart. Similarly, $(i,\mathbb{R^2})$ is a smooth manifold with $i:\mathbb{R}^2\rightarrow\mathbb{R}^2,i(\textbf{x})=\textbf{x}$ being the chart. Let $\varphi:(-1,\infty)\rightarrow\mathbb{R}^2$ by $\varphi(t)=\left(\frac{3t}{1+t^3},\frac{3t^2}{1+t^3} \right)$ . The trace of $\varphi$ (with subspace topology) is the portion of the ""folium of Descartes"" lying in the first and second quadrants together with the origin. Observe that $\varphi$ is injective but near the origin, $\varphi^{-1}$ is not continuous (since $\varphi(0)=\textbf{0}$ but $\varphi(t)\rightarrow\textbf{0}$ as $t\rightarrow \infty$ ). Hence, an injective smooth map between smooth manifolds can have a discontinuous inverse. $\varphi$ "">","I think the answer is yes. See the example below: we consider the open interval as an open submanifold of the smooth manifold with being the chart. Similarly, is a smooth manifold with being the chart. Let by . The trace of (with subspace topology) is the portion of the ""folium of Descartes"" lying in the first and second quadrants together with the origin. Observe that is injective but near the origin, is not continuous (since but as ). Hence, an injective smooth map between smooth manifolds can have a discontinuous inverse. $\varphi$ "">","(-1,\infty) (i,\mathbb{R}) i:\mathbb{R}\rightarrow \mathbb{R},i(x)=x (i,\mathbb{R^2}) i:\mathbb{R}^2\rightarrow\mathbb{R}^2,i(\textbf{x})=\textbf{x} \varphi:(-1,\infty)\rightarrow\mathbb{R}^2 \varphi(t)=\left(\frac{3t}{1+t^3},\frac{3t^2}{1+t^3} \right) \varphi \varphi \varphi^{-1} \varphi(0)=\textbf{0} \varphi(t)\rightarrow\textbf{0} t\rightarrow \infty","['differential-geometry', 'manifolds', 'smooth-manifolds']"
98,Nonvanishing vector field on an odd sphere,Nonvanishing vector field on an odd sphere,,"This is an exercise I am somewhat confused about. Here $X$ looks like a vector field on $\mathbb{R}^{2n}$ , not $S^{2n-1}$ . Then how should I interpret $X$ to make it a vector field on the sphere? Could anyone please explain?","This is an exercise I am somewhat confused about. Here looks like a vector field on , not . Then how should I interpret to make it a vector field on the sphere? Could anyone please explain?",X \mathbb{R}^{2n} S^{2n-1} X,"['differential-geometry', 'manifolds', 'vector-fields']"
99,Why is a differential a dual basis vector (i.e. why $dx^i \frac{\partial}{\partial x^j} =\delta^i_j$)?,Why is a differential a dual basis vector (i.e. why )?,dx^i \frac{\partial}{\partial x^j} =\delta^i_j,"I have been learning about differential forms, but do not understand exactly why a differential $dx$ forms a dual basis to the basis $\frac{\partial}{\partial x}$ . For example, expand a vector $\vec{w}$ as $\vec{w}=w^je_j$ , $i=1,2,\ldots, n$ on an $n$ -dimensional manifold $M$ with coordinates $x^i$ . Why is it that $$dx^i\vec{w}=dx^iw^je_j=w^i$$ In other words, why is is true that $$dx^ie_j=\delta^i_j$$ I am used to thinking of the differential $dx$ as a differential displacement in the $x$ direction, and not as a dual basis. Is it possible to reconcile the two notions?","I have been learning about differential forms, but do not understand exactly why a differential forms a dual basis to the basis . For example, expand a vector as , on an -dimensional manifold with coordinates . Why is it that In other words, why is is true that I am used to thinking of the differential as a differential displacement in the direction, and not as a dual basis. Is it possible to reconcile the two notions?","dx \frac{\partial}{\partial x} \vec{w} \vec{w}=w^je_j i=1,2,\ldots, n n M x^i dx^i\vec{w}=dx^iw^je_j=w^i dx^ie_j=\delta^i_j dx x","['differential-geometry', 'differential-forms']"
