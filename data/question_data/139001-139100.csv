,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Bifurcation diagrams,value and classification","Bifurcation diagrams,value and classification",,"I got the following dynamical system in 1-d, $$\dot x = (x+\mu)(\mu+2x-x^2)$$ Im asked to find dependence of the the stationary points of the system and its stability with respect the $\mu$ parameter. Then draw the bifurcation diagram and find at which $\mu$ the bifurcation occurs. Before showing my attempt of solution I have to say sorry, but Im really lost and I havent found any reference to study this properly. Here we go, Attempt of partial solution For the stationary(fixed points), we have that $x=-\mu$ or $x=1\pm 1\sqrt{1+\mu}$ . So, now we have to analyze stability for the cases $\mu >-1$ and $\mu <-1$ . We will check the sign of $\frac{d((x+\mu)(\mu+2x-x^2))}{dx} = 3\mu + 4x - 2 \mu x - 3 x^2$ . Case 0: $\mu = -1$ theres only one stationary point which is x=1. Case 1: $\mu >-1$ , 1.1)For $x=-\mu$ , $\frac{d((x+\mu)(\mu+2x-x^2))}{dx} = 3\mu-4\mu+2\mu^{2}-3\mu^{2}<0$ . So, $x=-\mu$ is stable. 1.2)For $x= 1+1\sqrt{1+\mu}$ , $\frac{d((x+\mu)(\mu+2x-x^2))}{dx}=-2 (\mu + 1)( \sqrt{\mu+ 1} + 1)<0$ 1.3) For $x = 1-1\sqrt{1+\mu}$ , $\frac{d((x+\mu)(\mu+2x-x^2))}{dx}=2 (1 + \mu) (-1 + \sqrt{1 + \mu})>0$ which implies it is unstable. Case 2: $\mu <-1$ The way to work it is analogous to what we did in C.1. Now, I have no idea how to draw the bifurcation diagram. Its only one diagram or its 1 for each case?, what exactly means that 'a bifurcation occurs' and how do I classify these points into pitchfork, saddle node and transcritical? Thanks so much for your help, I really appreciate it. <3","I got the following dynamical system in 1-d, Im asked to find dependence of the the stationary points of the system and its stability with respect the parameter. Then draw the bifurcation diagram and find at which the bifurcation occurs. Before showing my attempt of solution I have to say sorry, but Im really lost and I havent found any reference to study this properly. Here we go, Attempt of partial solution For the stationary(fixed points), we have that or . So, now we have to analyze stability for the cases and . We will check the sign of . Case 0: theres only one stationary point which is x=1. Case 1: , 1.1)For , . So, is stable. 1.2)For , 1.3) For , which implies it is unstable. Case 2: The way to work it is analogous to what we did in C.1. Now, I have no idea how to draw the bifurcation diagram. Its only one diagram or its 1 for each case?, what exactly means that 'a bifurcation occurs' and how do I classify these points into pitchfork, saddle node and transcritical? Thanks so much for your help, I really appreciate it. <3",\dot x = (x+\mu)(\mu+2x-x^2) \mu \mu x=-\mu x=1\pm 1\sqrt{1+\mu} \mu >-1 \mu <-1 \frac{d((x+\mu)(\mu+2x-x^2))}{dx} = 3\mu + 4x - 2 \mu x - 3 x^2 \mu = -1 \mu >-1 x=-\mu \frac{d((x+\mu)(\mu+2x-x^2))}{dx} = 3\mu-4\mu+2\mu^{2}-3\mu^{2}<0 x=-\mu x= 1+1\sqrt{1+\mu} \frac{d((x+\mu)(\mu+2x-x^2))}{dx}=-2 (\mu + 1)( \sqrt{\mu+ 1} + 1)<0 x = 1-1\sqrt{1+\mu} \frac{d((x+\mu)(\mu+2x-x^2))}{dx}=2 (1 + \mu) (-1 + \sqrt{1 + \mu})>0 \mu <-1,"['ordinary-differential-equations', 'dynamical-systems', 'stability-in-odes', 'stability-theory', 'bifurcation']"
1,Differential Equations by Complex Substitution,Differential Equations by Complex Substitution,,"Suppose I have to solve $y'' + 9y = \sin(3t) + 2\sin(4t)$ where $y$ is real. Since $\sin(3t) = Im(e^{3it})$ and $\sin(4t) = Im(e^{4it})$ . Can I instead solve for complex $z$ such that $z'' + 9z = e^{i3t} + 2e^{i4t}$ and say $x = Im(z)$ ? Could you please help me find the error in the below solution: Setting $z = e^{\lambda i}$ gives $\lambda^2 + 9 = 0$ giving $\lambda = \pm 3i$ . So complementary function is $z = Ae^{3it} + Be^{-3it}$ . Complementary function for $x$ is $Im(Ae^{3it} + Be^{-3it}) = A\sin(3t) - B\sin(3t)$ . But since $A,B$ are constants, let $C = A-B$ . Complementary function is $C\sin(3t)$ . But shouldn't the complementary function be of form $D\cos(3t) + E\sin(3t)$ ?","Suppose I have to solve where is real. Since and . Can I instead solve for complex such that and say ? Could you please help me find the error in the below solution: Setting gives giving . So complementary function is . Complementary function for is . But since are constants, let . Complementary function is . But shouldn't the complementary function be of form ?","y'' + 9y = \sin(3t) + 2\sin(4t) y \sin(3t) = Im(e^{3it}) \sin(4t) = Im(e^{4it}) z z'' + 9z = e^{i3t} + 2e^{i4t} x = Im(z) z = e^{\lambda i} \lambda^2 + 9 = 0 \lambda = \pm 3i z = Ae^{3it} + Be^{-3it} x Im(Ae^{3it} + Be^{-3it}) = A\sin(3t) - B\sin(3t) A,B C = A-B C\sin(3t) D\cos(3t) + E\sin(3t)","['real-analysis', 'calculus', 'ordinary-differential-equations']"
2,How to make the function of the planes from the lorenz attractor,How to make the function of the planes from the lorenz attractor,,"How can I make the equation for the planes of the wings of the lorenzattractor,  I know that the critical point should be used. But I don't know how I should make this plane, the figure shows in yellow which plane I want.","How can I make the equation for the planes of the wings of the lorenzattractor,  I know that the critical point should be used. But I don't know how I should make this plane, the figure shows in yellow which plane I want.",,"['ordinary-differential-equations', 'plane-geometry', 'chaos-theory']"
3,initial value problem with differential,initial value problem with differential,,"Does this initial value problem have a solution which is valid on the domain $\mathbb{R}$ ? $$y'=\sqrt{x^2-y^2}\\ y(1) = 1$$ If not, does it have a solution which is valid on the domain $(1-\epsilon, 1+\epsilon)$ ? I can't use the Picard Lindelöf theorem here since $\sqrt{x^2-y^2}$ is not Lipschitz continuous with respect to $y$ when $x=y=1$ .","Does this initial value problem have a solution which is valid on the domain ? If not, does it have a solution which is valid on the domain ? I can't use the Picard Lindelöf theorem here since is not Lipschitz continuous with respect to when .","\mathbb{R} y'=\sqrt{x^2-y^2}\\ y(1) = 1 (1-\epsilon, 1+\epsilon) \sqrt{x^2-y^2} y x=y=1","['ordinary-differential-equations', 'initial-value-problems']"
4,Where is the flaw in my stability analysis of this ODE?,Where is the flaw in my stability analysis of this ODE?,,"The ODE $${d^2x\over dt^2}=-kx$$ can be converted in the system of linear equations as $$\begin{align} {dx\over dt} & =v\\ {dv\over dt} &= -kx\\ \end{align}$$ Using Euler’s method, given $x_n$ and $y_n$ and for the time step $\Delta t$ , the next values can be determined as $$\left[ \begin{matrix} x_{n+1}\\ v_{n+1}\\ \end{matrix}\right] =  \left[\begin{matrix} 1&\Delta t\\ -k\Delta t&1 \end{matrix}\right] \left[\begin{matrix} x_n\\ v_n\\ \end{matrix}\right].$$ Now the absolute value of the (possibly complex) eigenvalues should be less than $1$ for this algorithm to be stable. But the eigenvalues turn out to be $1\pm i\sqrt{k}\Delta t$ whose absolute values are strictly greater than $1$ for any nonzero time-step $\Delta t$ . So the algorithm should not work for any value of $\Delta t$ , however small. But clearly, this is not the case as my programs do come up with (an approximate) solution though. So where is the flaw in my reasoning?","The ODE can be converted in the system of linear equations as Using Euler’s method, given and and for the time step , the next values can be determined as Now the absolute value of the (possibly complex) eigenvalues should be less than for this algorithm to be stable. But the eigenvalues turn out to be whose absolute values are strictly greater than for any nonzero time-step . So the algorithm should not work for any value of , however small. But clearly, this is not the case as my programs do come up with (an approximate) solution though. So where is the flaw in my reasoning?","{d^2x\over dt^2}=-kx \begin{align}
{dx\over dt} & =v\\
{dv\over dt} &= -kx\\
\end{align} x_n y_n \Delta t \left[ \begin{matrix}
x_{n+1}\\
v_{n+1}\\
\end{matrix}\right] = 
\left[\begin{matrix}
1&\Delta t\\
-k\Delta t&1
\end{matrix}\right]
\left[\begin{matrix}
x_n\\
v_n\\
\end{matrix}\right]. 1 1\pm i\sqrt{k}\Delta t 1 \Delta t \Delta t","['ordinary-differential-equations', 'numerical-methods', 'numerical-linear-algebra']"
5,Does $\lim_{s\to \infty}F(s)=0$ for all Laplace transforms?,Does  for all Laplace transforms?,\lim_{s\to \infty}F(s)=0,"Let $f(t)$ be a piece-wise continous function of exponential order $\alpha$ . Then $F(s)$ exists. I must prove then that $\lim_{s\to\infty} F(s)=0$ but i have no idea on how to do it. I tried to prove it by the $\varepsilon,\delta$ definition of limits, using the piece-wise continous and exponential order properties of $f(t)$ , but didn't reach the result. Perhaps I'm doing something wrong? My definition of  the limit would be that for every $\varepsilon>0\ \exists\ \delta>0$ such that $|F(s)|<\varepsilon$ for every $s\geq\delta$ .","Let be a piece-wise continous function of exponential order . Then exists. I must prove then that but i have no idea on how to do it. I tried to prove it by the definition of limits, using the piece-wise continous and exponential order properties of , but didn't reach the result. Perhaps I'm doing something wrong? My definition of  the limit would be that for every such that for every .","f(t) \alpha F(s) \lim_{s\to\infty} F(s)=0 \varepsilon,\delta f(t) \varepsilon>0\ \exists\ \delta>0 |F(s)|<\varepsilon s\geq\delta","['ordinary-differential-equations', 'laplace-transform']"
6,"Function as a ""constant of integration""","Function as a ""constant of integration""",,"I'm reading a book Differential Equations with Applications and Historical Notes , 3rd edition, specifically section 8 about exact equations. The author is trying to prove that iff $\partial M/\partial y = \partial N/\partial x$ then equation \begin{equation} M(x,y)dx + N(x,y)dy = 0 \end{equation} is exact differential equation. At some point we integrate equation \begin{equation} \frac{\partial f(x,y)}{\partial x} = M(x,y) \end{equation} to get \begin{equation} f(x, y) = \int M(x,y)dx + g(y) \end{equation} The author states that function $g(y)$ appears as a constant of integration because if we take derivative of both sides with respect to $x$ , $g(y)$ would disappear because it doesn't depend on $x$ . That's the part that I have trouble with, $y$ is a dependent variable and $x$ is independent variable so wouldn't derivative of $g(y)$ with respect to $x$ be \begin{equation} \frac{d\,g(y)}{dy} \frac{dy}{dx} \end{equation} and not $0$ ?","I'm reading a book Differential Equations with Applications and Historical Notes , 3rd edition, specifically section 8 about exact equations. The author is trying to prove that iff then equation is exact differential equation. At some point we integrate equation to get The author states that function appears as a constant of integration because if we take derivative of both sides with respect to , would disappear because it doesn't depend on . That's the part that I have trouble with, is a dependent variable and is independent variable so wouldn't derivative of with respect to be and not ?","\partial M/\partial y = \partial N/\partial x \begin{equation}
M(x,y)dx + N(x,y)dy = 0
\end{equation} \begin{equation}
\frac{\partial f(x,y)}{\partial x} = M(x,y)
\end{equation} \begin{equation}
f(x, y) = \int M(x,y)dx + g(y)
\end{equation} g(y) x g(y) x y x g(y) x \begin{equation}
\frac{d\,g(y)}{dy} \frac{dy}{dx}
\end{equation} 0","['calculus', 'ordinary-differential-equations']"
7,Some kind of perturbed system of ODEs,Some kind of perturbed system of ODEs,,"Problem $\dot x = Ax + h(t)$ , where $h(t)\in \mathbb{R}^{n}$ is continuous and bounded over $\mathbb{R}$ and $A\in M_{n\times n}$ a constant matrix with all its eigenvalues having negative real part . I have to prove that there's only one bounded solution over $(-\infty, \infty)$ and in case that $|h(t)| \to 0$ when $t \to \infty$ , then all solutions tends to $0$ . My thoughts Since A is constant with all its eigenvalues having negative real part then we can ensure that $ | \Pi_{A}(t,s) | \leq Ce^{-\alpha(t-s)}$ , i.e all solutions for the homogeneous system $\dot x=Ax$ are bounded. Now, since $\dot x= Ax+h(t)$ is an inhomogeneous system, we can find the solutions by using Duhamel's formula, $x(t)=| \Pi_{A}(t,s) |x_{0} + \int | \Pi_{A}(t,r)|h(r)dr$ and after this im lost, I mean, I could bound it by $|x(t)| \leq Ce^{-\alpha(t-s)}x_{0}+\int Ce^{-\alpha(t-r)}C_{1}dr$ but I can't see where to be able to prove uniqueness of a bounded solutions. Im pretty sure that this must be some kind of theorem but I couldn't be able to find it. So, any help would be really appreciated. Thanks so much for your help.","Problem , where is continuous and bounded over and a constant matrix with all its eigenvalues having negative real part . I have to prove that there's only one bounded solution over and in case that when , then all solutions tends to . My thoughts Since A is constant with all its eigenvalues having negative real part then we can ensure that , i.e all solutions for the homogeneous system are bounded. Now, since is an inhomogeneous system, we can find the solutions by using Duhamel's formula, and after this im lost, I mean, I could bound it by but I can't see where to be able to prove uniqueness of a bounded solutions. Im pretty sure that this must be some kind of theorem but I couldn't be able to find it. So, any help would be really appreciated. Thanks so much for your help.","\dot x = Ax + h(t) h(t)\in \mathbb{R}^{n} \mathbb{R} A\in M_{n\times n} (-\infty, \infty) |h(t)| \to 0 t \to \infty 0  | \Pi_{A}(t,s) | \leq Ce^{-\alpha(t-s)} \dot x=Ax \dot x= Ax+h(t) x(t)=| \Pi_{A}(t,s) |x_{0} + \int | \Pi_{A}(t,r)|h(r)dr |x(t)| \leq Ce^{-\alpha(t-s)}x_{0}+\int Ce^{-\alpha(t-r)}C_{1}dr","['real-analysis', 'calculus', 'linear-algebra', 'ordinary-differential-equations', 'stability-in-odes']"
8,Proof Lyapunov function for a given system,Proof Lyapunov function for a given system,,"I have the following exercise: Let $V : \Re^{L} \rightarrow \Re$ be twice continuously differentiable. Let $x^{*}$ be an isolated minimum of $V$ . Show that $V$ is a strict Lyapunov function for the system $$ \dot{x} = -\nabla V(x) = (-\frac{\partial{V}}{\partial{x_{1}}}, ...,-\frac{\partial{V}}{\partial{x_{L}}}) $$ and deduce that $x^{*}$ is asymptotically stable. I understand that I need to show that $V(x^{*})= 0$ , $V(x)>0 \; \text{if} \; x \in \Re^{L}  \text{ \ {$x^{*}$}}$ , and $\dot{V} < 0 $ in $\Re^{L}$ . I am able to get the following: $$ \dot{V} = <\nabla V, \dot{x}> = \frac{\partial{V}}{\partial{x_{1}}}(-\frac{\partial{V}}{\partial{x_{1}}}) + ... + \frac{\partial{V}}{\partial{x_{L}}}(-\frac{\partial{V}}{\partial{x_{L}}}) = \sum_{i = 1}^{L}-(\frac{\partial{V}}{\partial{x_{i}}})^{2}$$ $$ \Rightarrow \dot{V} < 0 $$ . I am unable to show that $V(x^{*}) = 0 $ and that $V(x)>0 \; \text{if} \; x \in \Re^{L}  \text{ \ {$x^{*}$}}$ . I understand the argument going from Lyapunov function to these facts but not the other way around or how to show this here. Any help/tips are welcome. Thanks in advance!","I have the following exercise: Let be twice continuously differentiable. Let be an isolated minimum of . Show that is a strict Lyapunov function for the system and deduce that is asymptotically stable. I understand that I need to show that , , and in . I am able to get the following: . I am unable to show that and that . I understand the argument going from Lyapunov function to these facts but not the other way around or how to show this here. Any help/tips are welcome. Thanks in advance!","V : \Re^{L} \rightarrow \Re x^{*} V V  \dot{x} = -\nabla V(x) = (-\frac{\partial{V}}{\partial{x_{1}}}, ...,-\frac{\partial{V}}{\partial{x_{L}}})  x^{*} V(x^{*})= 0 V(x)>0 \; \text{if} \; x \in \Re^{L}  \text{ \ {x^{*}}} \dot{V} < 0  \Re^{L}  \dot{V} = <\nabla V, \dot{x}> = \frac{\partial{V}}{\partial{x_{1}}}(-\frac{\partial{V}}{\partial{x_{1}}}) + ... + \frac{\partial{V}}{\partial{x_{L}}}(-\frac{\partial{V}}{\partial{x_{L}}}) = \sum_{i = 1}^{L}-(\frac{\partial{V}}{\partial{x_{i}}})^{2}  \Rightarrow \dot{V} < 0  V(x^{*}) = 0  V(x)>0 \; \text{if} \; x \in \Re^{L}  \text{ \ {x^{*}}}","['ordinary-differential-equations', 'stability-in-odes', 'lyapunov-functions']"
9,What is integration of $\csc (\pi \sqrt y )$,What is integration of,\csc (\pi \sqrt y ),"I have given an O.D.E $$\frac{dy}{dt}=\sin(\pi\sqrt y)$$ We can solve this by doing $$\frac{1}{\sin(\pi\sqrt y) }\;dy=dt$$ and then integrating each side $$\int\frac{1}{\sin(\pi\sqrt y) }\;dy=\int dt$$ $$\int \csc(\pi\sqrt y)\;dy= \int dt$$ after that i put $\pi\sqrt y=z$ , $\;$ I am getting eqaution like $$\frac{2}{\pi^{2}}\int {\csc(z).z}=\int dt$$ further this i am not able to solve I applied the method of integration by parts but not getting anywhere Please help Thnkyou","I have given an O.D.E We can solve this by doing and then integrating each side after that i put , I am getting eqaution like further this i am not able to solve I applied the method of integration by parts but not getting anywhere Please help Thnkyou",\frac{dy}{dt}=\sin(\pi\sqrt y) \frac{1}{\sin(\pi\sqrt y) }\;dy=dt \int\frac{1}{\sin(\pi\sqrt y) }\;dy=\int dt \int \csc(\pi\sqrt y)\;dy= \int dt \pi\sqrt y=z \; \frac{2}{\pi^{2}}\int {\csc(z).z}=\int dt,"['real-analysis', 'integration', 'ordinary-differential-equations']"
10,Solve 2nd order Ordinary differential equation $y d^2y/dx^2 -2 (dy/dx)^2 = y^2$,Solve 2nd order Ordinary differential equation,y d^2y/dx^2 -2 (dy/dx)^2 = y^2,"$$y \dfrac{d^2y}{dx^2} -2\left( \dfrac{dy}{dx} \right)^2 =y^2$$ let $y \dfrac{dy}{dx} = t$ $$\left( \dfrac{dy}{dx}) \right)^2 +y\dfrac{d^2y}{dx^2}=\dfrac{dt}{dx}$$ put in equation after this i am stuck I don't how to proceed because I got differential in $x ,y$ , and $t$ please help","let put in equation after this i am stuck I don't how to proceed because I got differential in , and please help","y \dfrac{d^2y}{dx^2} -2\left( \dfrac{dy}{dx} \right)^2 =y^2 y \dfrac{dy}{dx} = t \left( \dfrac{dy}{dx}) \right)^2 +y\dfrac{d^2y}{dx^2}=\dfrac{dt}{dx} x ,y t",['ordinary-differential-equations']
11,Alternative Proof of Liouville's Theorem of Linear Flow,Alternative Proof of Liouville's Theorem of Linear Flow,,"I am working on this problem: (a) Consider a time dependent ODE $\dot{x}=A(t)x$ . Let $\Psi_{t}$ by the time dependent linear flow with $\Psi_{0}=Id$ . Prove by writing down the determinant directly that $$\dfrac{d}{dt}\Big|_{t=0}\det(\Psi_{t})=Tr(A(0)).$$ (b)Use part $(a)$ to generate an alternative proof of the following: Let $\varphi_{t}$ be a flow generated by a vector field $X$ . Then $\varphi_{t}$ is volume preserving if and only if $div(X)=0$ everywhere on $\mathbb{R}^{n}.$ I have shown part $(a)$ as following: Recall that $\Psi_{t}$ is the solution of the ODE $\dot{x}=A(t)x,$ and thus it satisfies $$\dfrac{d}{dt}\Psi_{t}=A(t)\Psi_{t}.$$ Now, by Jacobi's Formula, we have \begin{align*} \dfrac{d}{dt}\det(\Psi_{t})&=Tr\Big(adj(\Psi_{t})\cdot\dfrac{d\Psi_{t}}{dt}\Big)\\ &=Tr\Big(adj(\Psi_{t})\cdot A(t)\cdot\Psi_{t}\Big)\ \text{by above recall}. \end{align*} Then, at $t=0$ , we have \begin{align*} \dfrac{d}{dt}\Big|_{t=0}\det(\Psi_{t})&=Tr\Big(adj(\Psi_{0})\cdot\Psi_{0}\cdot A(0)\Big)\\ &=Tr\Big(adj(Id)\cdot Id\cdot A(0)\Big)\\ &=Tr\Big(Id\cdot Id\cdot A(0)\Big)\\ &=Tr\Big(A(0)\Big), \ \text{as desried}. \end{align*} However, I don't see the connection between $(a)$ and Liouville's Theorem. The proof of Liouville's Theorem I learnt can be sketched as following: (1) Let $m_{0}$ denote the Lebesgue measure on $\mathbb{R}^{n}$ , and let $m_{t}$ denote $m_{0}$ transported forward by $\varphi_{t}$ , i.e. $$m_{t}(V)=m_{0}(\varphi_{-t}(V)).$$ Then, we show that $m_{t}=m_{0}$ if and only if $\dfrac{d}{dt}\Big|_{t=0}m_{t}(V)=0$ for all Borel $V.$ (2) The rate of flow of measure across a cross-section $\Sigma$ to the flow is given by $$\int_{\Sigma}X\cdot \textbf{n}ds,$$ where $\textbf{n}$ is the unit normal vector to $\Sigma$ in the direction of the flow, and $ds$ is surface area on $\Sigma$ . (3) Let $V\subset\mathbb{R}^{n}$ be a bounded region with smooth $\partial V$ . Then by Gauss-Green Theorem, we have $$\dfrac{d}{dt}\Big|_{t=0}m_{t}(V)=\int_{\partial V}X\cdot\textbf{n}ds=\int_{V}div(X),$$ which concludes the proof. However, I did not see how to apply $(a)$ to this proof since we never used $\det(\Psi_{t})$ in the original proof.","I am working on this problem: (a) Consider a time dependent ODE . Let by the time dependent linear flow with . Prove by writing down the determinant directly that (b)Use part to generate an alternative proof of the following: Let be a flow generated by a vector field . Then is volume preserving if and only if everywhere on I have shown part as following: Recall that is the solution of the ODE and thus it satisfies Now, by Jacobi's Formula, we have Then, at , we have However, I don't see the connection between and Liouville's Theorem. The proof of Liouville's Theorem I learnt can be sketched as following: (1) Let denote the Lebesgue measure on , and let denote transported forward by , i.e. Then, we show that if and only if for all Borel (2) The rate of flow of measure across a cross-section to the flow is given by where is the unit normal vector to in the direction of the flow, and is surface area on . (3) Let be a bounded region with smooth . Then by Gauss-Green Theorem, we have which concludes the proof. However, I did not see how to apply to this proof since we never used in the original proof.","\dot{x}=A(t)x \Psi_{t} \Psi_{0}=Id \dfrac{d}{dt}\Big|_{t=0}\det(\Psi_{t})=Tr(A(0)). (a) \varphi_{t} X \varphi_{t} div(X)=0 \mathbb{R}^{n}. (a) \Psi_{t} \dot{x}=A(t)x, \dfrac{d}{dt}\Psi_{t}=A(t)\Psi_{t}. \begin{align*}
\dfrac{d}{dt}\det(\Psi_{t})&=Tr\Big(adj(\Psi_{t})\cdot\dfrac{d\Psi_{t}}{dt}\Big)\\
&=Tr\Big(adj(\Psi_{t})\cdot A(t)\cdot\Psi_{t}\Big)\ \text{by above recall}.
\end{align*} t=0 \begin{align*}
\dfrac{d}{dt}\Big|_{t=0}\det(\Psi_{t})&=Tr\Big(adj(\Psi_{0})\cdot\Psi_{0}\cdot A(0)\Big)\\
&=Tr\Big(adj(Id)\cdot Id\cdot A(0)\Big)\\
&=Tr\Big(Id\cdot Id\cdot A(0)\Big)\\
&=Tr\Big(A(0)\Big), \ \text{as desried}.
\end{align*} (a) m_{0} \mathbb{R}^{n} m_{t} m_{0} \varphi_{t} m_{t}(V)=m_{0}(\varphi_{-t}(V)). m_{t}=m_{0} \dfrac{d}{dt}\Big|_{t=0}m_{t}(V)=0 V. \Sigma \int_{\Sigma}X\cdot \textbf{n}ds, \textbf{n} \Sigma ds \Sigma V\subset\mathbb{R}^{n} \partial V \dfrac{d}{dt}\Big|_{t=0}m_{t}(V)=\int_{\partial V}X\cdot\textbf{n}ds=\int_{V}div(X), (a) \det(\Psi_{t})","['ordinary-differential-equations', 'dynamical-systems', 'alternative-proof', 'ergodic-theory']"
12,General solution for 1st order differential equation $(1-\sqrt{3})\frac{dy}{dx} + y\sec x = y^{\sqrt3}\sec x$,General solution for 1st order differential equation,(1-\sqrt{3})\frac{dy}{dx} + y\sec x = y^{\sqrt3}\sec x,"How do I find general solution for $$(1-\sqrt{3})\frac{dy}{dx} + y\sec x = y^{\sqrt3}\sec x$$ What I tried $$y^{-\sqrt3}(1-\sqrt{3})\frac{dy}{dx} + y^{1-\sqrt3}\sec x = \sec x$$ Then, $u=y^{1-\sqrt3}  \Rightarrow \frac{du}{dy}=(1-\sqrt3)y^{-\sqrt3}$ $\frac{du}{dx}+u\sec x=\sec x$ $$e^{\int \sec x \,dx}=e^{\ln |\sec x+\tan x|}=\sec x+\tan x$$ $$(\sec x+\tan x)\frac{du}{dx}+u(\sec^2x+\tan x\sec x)=sec^2x+\tan x\sec x$$ $$\frac{d{\bigl((\sec x+\tan x)u\bigr)}}{dx}=\sec^2x+\tan x\sec x$$ After integrating both sides - $\int dx$ , $$(\sec x+\tan x)u=\sec x+\tan x\\ u=1=y^{1-\sqrt3}\\ y=1$$ Where am I doing the mistake ?","How do I find general solution for What I tried Then, After integrating both sides - , Where am I doing the mistake ?","(1-\sqrt{3})\frac{dy}{dx} + y\sec x = y^{\sqrt3}\sec x y^{-\sqrt3}(1-\sqrt{3})\frac{dy}{dx} + y^{1-\sqrt3}\sec x = \sec x u=y^{1-\sqrt3}  \Rightarrow \frac{du}{dy}=(1-\sqrt3)y^{-\sqrt3} \frac{du}{dx}+u\sec x=\sec x e^{\int \sec x \,dx}=e^{\ln |\sec x+\tan x|}=\sec x+\tan x (\sec x+\tan x)\frac{du}{dx}+u(\sec^2x+\tan x\sec x)=sec^2x+\tan x\sec x \frac{d{\bigl((\sec x+\tan x)u\bigr)}}{dx}=\sec^2x+\tan x\sec x \int dx (\sec x+\tan x)u=\sec x+\tan x\\
u=1=y^{1-\sqrt3}\\
y=1",['ordinary-differential-equations']
13,Autonomous equilibrium points,Autonomous equilibrium points,,"Given $$\frac{dx}{dt}= 3x-x^2$$ I don't understand how $$x=0$$ is not semistable. I get the following 0 points: $$x = 0, x = 3$$ Here are the values of $\frac{dx}{dt}$ I get when plugging in and my reasoning: $-3 \to -18$ $-2 \to -10$ $-1 \to -4$ It would seem to me that clearly the slope gets closer to zero as we go up and would have the curve going up and arcing to the right and then flattening out but no the book has the curve going the opposite direction.....doesnt make any sense at all $1 \to 2$ $1.5 \to 2.25$ $2 \to 2$ The slope increases then levels out and then goes down somehow giving an S shape between $x = 0$ and $x = 3$ Now for $6 \to -18$ $5 \to -10$ $4 \to  -4$ The slope gets nearer to zero as we near 3 so we get a kind of semi c shape going down and leveling out at $x = 3$ This turned out to be right. So I don't understand how my reasoning worked out in one instance but the same exact approach didn't work in the first part.",Given I don't understand how is not semistable. I get the following 0 points: Here are the values of I get when plugging in and my reasoning: It would seem to me that clearly the slope gets closer to zero as we go up and would have the curve going up and arcing to the right and then flattening out but no the book has the curve going the opposite direction.....doesnt make any sense at all The slope increases then levels out and then goes down somehow giving an S shape between and Now for The slope gets nearer to zero as we near 3 so we get a kind of semi c shape going down and leveling out at This turned out to be right. So I don't understand how my reasoning worked out in one instance but the same exact approach didn't work in the first part.,"\frac{dx}{dt}= 3x-x^2 x=0 x = 0, x = 3 \frac{dx}{dt} -3 \to -18 -2 \to -10 -1 \to -4 1 \to 2 1.5 \to 2.25 2 \to 2 x = 0 x = 3 6 \to -18 5 \to -10 4 \to  -4 x = 3",['ordinary-differential-equations']
14,second derivative of a function equals the function squared,second derivative of a function equals the function squared,,Can someone solve the following differential equation for me please? The second derivative of a function equals the function squared. Find $y(x)$ if $$ \frac{d^2 y}{dx^2} = y^2 $$,Can someone solve the following differential equation for me please? The second derivative of a function equals the function squared. Find if,"y(x) 
\frac{d^2 y}{dx^2} = y^2
","['ordinary-differential-equations', 'differential']"
15,"Among midpoint method, Heun's method and Ralston method, which method of solving ODE performs better in which case and why?","Among midpoint method, Heun's method and Ralston method, which method of solving ODE performs better in which case and why?",,"Midpoint method, Heun's method and Ralston method- all are 2nd order Runge-Kutta methods. I know how these methods work. Are there some specific functions for which one of these methods performs better than the other two? If yes, what are those functions? And why do we see the difference in performance?","Midpoint method, Heun's method and Ralston method- all are 2nd order Runge-Kutta methods. I know how these methods work. Are there some specific functions for which one of these methods performs better than the other two? If yes, what are those functions? And why do we see the difference in performance?",,"['ordinary-differential-equations', 'numerical-methods']"
16,Theoretical link between Two Solutions and the Existence and Uniqueness Theorem,Theoretical link between Two Solutions and the Existence and Uniqueness Theorem,,"I am new to Differential Equations, and am one step away from the solution to what was a very challenging exercise. Any help would be amazing. Find two different solutions to the initial value problem $$xy'-2x^2 \sqrt{|y|}=4y~,~~~~~~~~~~~~~~y(1)=0$$ and explain how the existence of two different solutions to this problem abides by the Existence and Uniqueness Theorem. After a lot of work I found the solutions to this problem, namely $|y|^{\frac{1}{2}}=x^2\ln|x|$ , which renders two $x$ solutions for each $y$ . However, I am not sure how to link this back theoretically to the Existence and Uniqueness Theorem. I have two theories, but I am not sure regarding either of them: ${}$ $1.~$ the derivative of $xy'-2x^2 \sqrt{|y|}=4y$ , that is to say $y'=2x \sqrt{|y|}+4\frac{y}{x}$ , is $~\frac{xy}{|y|\sqrt{|y|}}+\frac{4}{x}$ , and this is not defined at (1,0). I am not sure if that is a valid way of justifying why the Existence and Uniqueness Theorem does not apply. ${}$ $2.~$ To show that there is no $L$ , such that $f(x,y)-f(x,0) \leq L(y-0)$ . This leads me to $2x \sqrt{|y|}+4\frac{y}{x}\leq L(y)$ . Again, I am not sure if this is valid, and - if so - how to take it to the next step. Any insight would be immensely appreciated. Thank you! ${}$ PS:","I am new to Differential Equations, and am one step away from the solution to what was a very challenging exercise. Any help would be amazing. Find two different solutions to the initial value problem and explain how the existence of two different solutions to this problem abides by the Existence and Uniqueness Theorem. After a lot of work I found the solutions to this problem, namely , which renders two solutions for each . However, I am not sure how to link this back theoretically to the Existence and Uniqueness Theorem. I have two theories, but I am not sure regarding either of them: the derivative of , that is to say , is , and this is not defined at (1,0). I am not sure if that is a valid way of justifying why the Existence and Uniqueness Theorem does not apply. To show that there is no , such that . This leads me to . Again, I am not sure if this is valid, and - if so - how to take it to the next step. Any insight would be immensely appreciated. Thank you! PS:","xy'-2x^2 \sqrt{|y|}=4y~,~~~~~~~~~~~~~~y(1)=0 |y|^{\frac{1}{2}}=x^2\ln|x| x y {} 1.~ xy'-2x^2 \sqrt{|y|}=4y y'=2x \sqrt{|y|}+4\frac{y}{x} ~\frac{xy}{|y|\sqrt{|y|}}+\frac{4}{x} {} 2.~ L f(x,y)-f(x,0) \leq L(y-0) 2x \sqrt{|y|}+4\frac{y}{x}\leq L(y) {}",['ordinary-differential-equations']
17,Find the time it takes for a particle to reach the source of the attractive force acting on it,Find the time it takes for a particle to reach the source of the attractive force acting on it,,"A particle of mass m is released from rest a distance b from a fixed origin of force that attracts the particle according to the inverse square law: $$F(x)=-kx^{-2}$$ Show that the time required for the particle to reach the origin is $$t=\pi\sqrt{\frac{mb^3}{8k}}$$ My solution is as follows: $$F(x)=-kx^{-2}\tag1$$ $$m\frac{d\dot x}{dt}=-kx^{-2}$$ By chain rule, $\frac{d\dot x}{dt}=\frac{dx}{dt}\frac{d\dot x}{dx}=\dot x\frac{d\dot x}{dx}$ $$m\dot{x}\frac{d\dot{x}}{dx}=-kx^{-2}\tag2$$ When the particle is at a distance $x$ from the source, wherein $x\leq b$ , the speed of the particle is $\dot{x}$ . Therefore, $$\int_0^{\dot{x}}\dot{x}d\dot{x}=-\frac km\int_b^x\frac{dx}{x^2}$$ $$\frac12\dot{x}^2=\frac km\left(\frac1x-\frac1b\right)$$ Solving for $\dot x$ , I get $$\dot{x}=\sqrt{\frac{2k}{mb}\left(\frac{b-x}{x}\right)}\tag3$$ $$\frac{dx}{dt}=\sqrt{\frac{2k}{mb}\left(\frac{b-x}{x}\right)}$$ $$dt=\sqrt{\frac{mb}{2k}\left(\frac{x}{b-x}\right)}dx$$ When the particle has reached the source at time $t$ , the distance to the source is $0$ . Thus, $$\int_0^tdt=\sqrt{\frac{mb}{2k}}\int_b^0\left(\frac{x}{b-x}\right)^\frac12dx\tag4$$ Applying partial fraction decomposition, I get $$t=\sqrt{\frac{mb}{2k}}\left(b\int_b^0\frac{dx}{b-x}-\int_b^0dx\right)$$ Intergrating $\int_b^0\frac{dx}{b-x}$ , I get $-\infty$ . I don't know where to go from there. From the solution given to us, Eq. (4) was rewritten as $$\int_0^tdt=\sqrt{\frac{mb^3}{2k}}\int_b^0\left(\frac{\frac xb}{1-\frac xb}\right)^\frac12d\left(\frac xb\right)\tag5$$ Since $x\leq b$ , say $\frac xb=\sin^2\theta$ $$t=\sqrt{\frac{mb^3}{2k}}\int_{-\pi/2}^0\frac{\sin\theta\left(2\sin\theta\cos\theta\right)}{\cos\theta}d\theta\tag6$$ $$t=\sqrt{\frac{2mb^3}{k}}\int_{-\pi/2}^0\sin^2\theta d\theta$$ $$t=\pi\sqrt{\frac{mb^3}{8k}}$$ What I don't understand from the given solution is how could $dx$ be rewritten as $d\left(\frac xb\right)$ and how the limits for Eq. (6) were obtained. I'm also confused as to why trigonometric functions were used and by what reason was $\frac xb=\sin^2\theta$ . From my solution, I know I'm wrong, but I'd like to know if there are other integration methods that could be used for Eq. (6) without using trigonometric functions.","A particle of mass m is released from rest a distance b from a fixed origin of force that attracts the particle according to the inverse square law: Show that the time required for the particle to reach the origin is My solution is as follows: By chain rule, When the particle is at a distance from the source, wherein , the speed of the particle is . Therefore, Solving for , I get When the particle has reached the source at time , the distance to the source is . Thus, Applying partial fraction decomposition, I get Intergrating , I get . I don't know where to go from there. From the solution given to us, Eq. (4) was rewritten as Since , say What I don't understand from the given solution is how could be rewritten as and how the limits for Eq. (6) were obtained. I'm also confused as to why trigonometric functions were used and by what reason was . From my solution, I know I'm wrong, but I'd like to know if there are other integration methods that could be used for Eq. (6) without using trigonometric functions.",F(x)=-kx^{-2} t=\pi\sqrt{\frac{mb^3}{8k}} F(x)=-kx^{-2}\tag1 m\frac{d\dot x}{dt}=-kx^{-2} \frac{d\dot x}{dt}=\frac{dx}{dt}\frac{d\dot x}{dx}=\dot x\frac{d\dot x}{dx} m\dot{x}\frac{d\dot{x}}{dx}=-kx^{-2}\tag2 x x\leq b \dot{x} \int_0^{\dot{x}}\dot{x}d\dot{x}=-\frac km\int_b^x\frac{dx}{x^2} \frac12\dot{x}^2=\frac km\left(\frac1x-\frac1b\right) \dot x \dot{x}=\sqrt{\frac{2k}{mb}\left(\frac{b-x}{x}\right)}\tag3 \frac{dx}{dt}=\sqrt{\frac{2k}{mb}\left(\frac{b-x}{x}\right)} dt=\sqrt{\frac{mb}{2k}\left(\frac{x}{b-x}\right)}dx t 0 \int_0^tdt=\sqrt{\frac{mb}{2k}}\int_b^0\left(\frac{x}{b-x}\right)^\frac12dx\tag4 t=\sqrt{\frac{mb}{2k}}\left(b\int_b^0\frac{dx}{b-x}-\int_b^0dx\right) \int_b^0\frac{dx}{b-x} -\infty \int_0^tdt=\sqrt{\frac{mb^3}{2k}}\int_b^0\left(\frac{\frac xb}{1-\frac xb}\right)^\frac12d\left(\frac xb\right)\tag5 x\leq b \frac xb=\sin^2\theta t=\sqrt{\frac{mb^3}{2k}}\int_{-\pi/2}^0\frac{\sin\theta\left(2\sin\theta\cos\theta\right)}{\cos\theta}d\theta\tag6 t=\sqrt{\frac{2mb^3}{k}}\int_{-\pi/2}^0\sin^2\theta d\theta t=\pi\sqrt{\frac{mb^3}{8k}} dx d\left(\frac xb\right) \frac xb=\sin^2\theta,"['ordinary-differential-equations', 'classical-mechanics']"
18,Solve the initial value problem $xyy' + xy' = 1$ and $y(1) = 0$,Solve the initial value problem  and,xyy' + xy' = 1 y(1) = 0,"I can solve the differential equation, which is $y + y^{2}/2 = \ln(x) + C$ . But I cannot solve the IVP because I can't isolate for $y$ and find the value of $C.$","I can solve the differential equation, which is . But I cannot solve the IVP because I can't isolate for and find the value of",y + y^{2}/2 = \ln(x) + C y C.,"['ordinary-differential-equations', 'initial-value-problems']"
19,Is there a closed form solution to the matrix differential equation $\dot X=AX+XA^T - K$?,Is there a closed form solution to the matrix differential equation ?,\dot X=AX+XA^T - K,"Is there a closed form solution the matrix differential equation $\dot X = AX + XA^T - K $ for example when $A = \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix}$ and $K = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix}$ In general $A$ is square and $K$ is positive semi-definite. As far as I understand the equation: $\dot X = AX + XA^T$ has the closed form solution $X(t) = e^{At}Ce^{tA^T}$ Can this be extended to $\dot X = AX + XA^T - K $ ? These are similar questions, but do not answer the closed form solution question: On the solution of one matrix differential equation Solution of differential lyapunov equation","Is there a closed form solution the matrix differential equation for example when and In general is square and is positive semi-definite. As far as I understand the equation: has the closed form solution Can this be extended to ? These are similar questions, but do not answer the closed form solution question: On the solution of one matrix differential equation Solution of differential lyapunov equation",\dot X = AX + XA^T - K  A = \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix} K = \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix} A K \dot X = AX + XA^T X(t) = e^{At}Ce^{tA^T} \dot X = AX + XA^T - K ,"['matrices', 'ordinary-differential-equations', 'dynamical-systems', 'matrix-equations']"
20,General ODE and rewriting solution,General ODE and rewriting solution,,When considering the general form (which is an initial value problem) $$\frac{{dy}}{{dt}} = ay - b % MathType!MTEF!2!1!+- % feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn % hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr % 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9 % vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x % fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaWaaSaaaeaaca % WGKbGaamyEaaqaaiaadsgacaWG0baaaiabg2da9iaadggacaWG5bGa % eyOeI0IaamOyaaaa!3E8D! $$ with initial condition y(0)=y0 (Where y0 is an arbitrary initial value) If $$\begin{array}{l}a \ne 0\\y \ne \frac{b}{a}\end{array} % MathType!MTEF!2!1!+- % feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn % hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr % 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9 % vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x % fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGceaqabeaacaWGHb % GaeyiyIKRaaGimaaqaaiaadMhacqGHGjsUdaWcaaqaaiaadkgaaeaa % caWGHbaaaaaaaa!3E06! $$ The testbook I have rewrites the general form as: $$\frac{{\frac{{dy}}{{dt}}}}{{y - (\frac{b}{a})}} = a % MathType!MTEF!2!1!+- % feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn % hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr % 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9 % vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x % fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaWaaSaaaeaada % WcaaqaaiaadsgacaWG5baabaGaamizaiaadshaaaaabaGaamyEaiab % gkHiTiaacIcadaWcaaqaaiaadkgaaeaacaWGHbaaaiaacMcaaaGaey % ypa0Jaamyyaaaa!40EC! $$ I don't understand why they would rewrite in this way. The only connection I can make in my mind that the derivative is related to the limit which 1/0 would be undefined or a condition associated with a limit. Any insight that some one can provide for this rewrite would really clear up a lot for me. This leads to a solution of the initial value problem of $$y = (\frac{b}{a}) + [y0 - (\frac{b}{a})]{e^{at}} % MathType!MTEF!2!1!+- % feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn % hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr % 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9 % vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x % fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaamyEaiabg2 % da9iaacIcadaWcaaqaaiaadkgaaeaacaWGHbaaaiaacMcacqGHRaWk % caGGBbGaamyEaiaaicdacqGHsislcaGGOaWaaSaaaeaacaWGIbaaba % GaamyyaaaacaGGPaGaaiyxaiaadwgadaahaaWcbeqaaiaadggacaWG % 0baaaaaa!46A3! $$ Thanks in advance.,When considering the general form (which is an initial value problem) with initial condition y(0)=y0 (Where y0 is an arbitrary initial value) If The testbook I have rewrites the general form as: I don't understand why they would rewrite in this way. The only connection I can make in my mind that the derivative is related to the limit which 1/0 would be undefined or a condition associated with a limit. Any insight that some one can provide for this rewrite would really clear up a lot for me. This leads to a solution of the initial value problem of Thanks in advance.,"\frac{{dy}}{{dt}} = ay - b
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaWaaSaaaeaaca
% WGKbGaamyEaaqaaiaadsgacaWG0baaaiabg2da9iaadggacaWG5bGa
% eyOeI0IaamOyaaaa!3E8D!
 \begin{array}{l}a \ne 0\\y \ne \frac{b}{a}\end{array}
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGceaqabeaacaWGHb
% GaeyiyIKRaaGimaaqaaiaadMhacqGHGjsUdaWcaaqaaiaadkgaaeaa
% caWGHbaaaaaaaa!3E06!
 \frac{{\frac{{dy}}{{dt}}}}{{y - (\frac{b}{a})}} = a
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaWaaSaaaeaada
% WcaaqaaiaadsgacaWG5baabaGaamizaiaadshaaaaabaGaamyEaiab
% gkHiTiaacIcadaWcaaqaaiaadkgaaeaacaWGHbaaaiaacMcaaaGaey
% ypa0Jaamyyaaaa!40EC!
 y = (\frac{b}{a}) + [y0 - (\frac{b}{a})]{e^{at}}
% MathType!MTEF!2!1!+-
% feaagKart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn
% hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr
% 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9
% vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x
% fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaamyEaiabg2
% da9iaacIcadaWcaaqaaiaadkgaaeaacaWGHbaaaiaacMcacqGHRaWk
% caGGBbGaamyEaiaaicdacqGHsislcaGGOaWaaSaaaeaacaWGIbaaba
% GaamyyaaaacaGGPaGaaiyxaiaadwgadaahaaWcbeqaaiaadggacaWG
% 0baaaaaa!46A3!
","['ordinary-differential-equations', 'multivariable-calculus', 'mathematical-modeling']"
21,How should I approach the differential equation.,How should I approach the differential equation.,,"I am working through the following paper: https://www.researchgate.net/publication/222417459_Mathematical_models_for_motion_of_the_rear_ends_of_vehicles On Page 4, equation 8 models the position of the back wheel when given the position of the front wheels during a turn. I wanted to model the path of the front and rear wheels when a car turns in a circle, which yielded the following differential equation: $$\frac{d\psi}{dt}=\frac{\sin{\psi}\cos{t}-\cos{\psi}\sin{t}}{2.5}$$ How would I approach solving this equation. I have considered the following: separating the variables is impossible it isn't a linear first order differential equation so Euler's method of using an integrating factor will not work I cannot see how to get $\frac{y}{x}$ used to solve a homogeneous differential equation. Any help would be appreciated.","I am working through the following paper: https://www.researchgate.net/publication/222417459_Mathematical_models_for_motion_of_the_rear_ends_of_vehicles On Page 4, equation 8 models the position of the back wheel when given the position of the front wheels during a turn. I wanted to model the path of the front and rear wheels when a car turns in a circle, which yielded the following differential equation: How would I approach solving this equation. I have considered the following: separating the variables is impossible it isn't a linear first order differential equation so Euler's method of using an integrating factor will not work I cannot see how to get used to solve a homogeneous differential equation. Any help would be appreciated.",\frac{d\psi}{dt}=\frac{\sin{\psi}\cos{t}-\cos{\psi}\sin{t}}{2.5} \frac{y}{x},"['calculus', 'ordinary-differential-equations']"
22,Solution to Differential Equation $\sum_{i = 0}^n a_i f^{(i)} (x) = 0$,Solution to Differential Equation,\sum_{i = 0}^n a_i f^{(i)} (x) = 0,"Let $p(x) = \sum_{i =0}^n a_i x^i$ be a polynomial over $\mathbb{C}$ . I am interested in solutions to the differential equation $a_0 y + a_1 y' + a_2 y'' + ... + a_n y^{(n)} = 0$ , where $y : \mathbb{C} \rightarrow \mathbb{C}$ is holomorphic. I realize this is a common one but I don't know the name of it. It seems we can do this: say $D : H \rightarrow H$ from holomorphic functions on $\mathbb{C}$ to holomorphic functions on $\mathbb{C}$ is the differentiation operator, and $I$ is the identity. Factor the polynomial $\sum_{i =0}^n a_i x^i$ as $\prod_{i = 1}^n (z - b_i)$ (without loss of generality, we can take this to be monic). Then $(D - b_n I) \circ (D - b_{n-1} I) \circ \cdots \circ (D - b_0 I) (y) = 0$ . Perhaps $y$ is then a $\mathbb{C}$ -linear sum of elements $y_i$ such that $D(y_i) = b_i I (y_i)$ , i.e. elements of the form $e^{b_i z}$ .","Let be a polynomial over . I am interested in solutions to the differential equation , where is holomorphic. I realize this is a common one but I don't know the name of it. It seems we can do this: say from holomorphic functions on to holomorphic functions on is the differentiation operator, and is the identity. Factor the polynomial as (without loss of generality, we can take this to be monic). Then . Perhaps is then a -linear sum of elements such that , i.e. elements of the form .",p(x) = \sum_{i =0}^n a_i x^i \mathbb{C} a_0 y + a_1 y' + a_2 y'' + ... + a_n y^{(n)} = 0 y : \mathbb{C} \rightarrow \mathbb{C} D : H \rightarrow H \mathbb{C} \mathbb{C} I \sum_{i =0}^n a_i x^i \prod_{i = 1}^n (z - b_i) (D - b_n I) \circ (D - b_{n-1} I) \circ \cdots \circ (D - b_0 I) (y) = 0 y \mathbb{C} y_i D(y_i) = b_i I (y_i) e^{b_i z},[]
23,Mistake in reasoning regarding initial value problem,Mistake in reasoning regarding initial value problem,,"Let $y(x)$ be the solution to the initial value problem: $y''y=(y')^2$ $y(0)=1, y'(0)=2$ I am very close to the right answer, but there is a mistake in my reasoning, and I would like to know where: Let's define $z=y'$ . $y''=z \frac{dz}{dy}$ . Therefore z $\frac {dz}{dy}y=z^2$ $z dz=\frac{z^2}{y}dy$ $\frac{dz}{z}=\frac{1}{y}dy$ Therefore $lnz=lny$ , meaning the derivative is identical to the original function. And therefore $y = e^x$ . I know that the right answer is $y=e^{2x}$ , so I am close, but there is a mistake somewhere. I suspect it is in the very last step, but I am not sure what the right alternative should be… Thank you!","Let be the solution to the initial value problem: I am very close to the right answer, but there is a mistake in my reasoning, and I would like to know where: Let's define . . Therefore z Therefore , meaning the derivative is identical to the original function. And therefore . I know that the right answer is , so I am close, but there is a mistake somewhere. I suspect it is in the very last step, but I am not sure what the right alternative should be… Thank you!","y(x) y''y=(y')^2 y(0)=1, y'(0)=2 z=y' y''=z \frac{dz}{dy} \frac {dz}{dy}y=z^2 z dz=\frac{z^2}{y}dy \frac{dz}{z}=\frac{1}{y}dy lnz=lny y = e^x y=e^{2x}",['ordinary-differential-equations']
24,Existence of global attractor in duffing equation,Existence of global attractor in duffing equation,,"How to prove the existence and identify global attractor in Duffing equation $$\ddot{x}+\epsilon \dot{x}+x^3-ax=0$$ where $\epsilon >0$ and $a>0$ ? I found a definition: A bounded closed set $A_1 \subset X$ is called a global attractor for a dynamical system $(X, S_t)$ , if $A_1$ is an invariant set the set $A_1$ uniformly attracts all trajectories starting in bounded sets, i.e. for any bounded set $B$ from $X$ $$\lim_{t\to \infty} \sup \lbrace \operatorname{dist}(S_t y, A_1): y\in B \rbrace=0$$ where $\operatorname{dist}(z,A)=\inf\lbrace\operatorname{d}(z,y): y\in A\rbrace$ where $\operatorname{d}(z,y)$ is the distance between the elements $z$ and $y$ in $X$ . I finished only ODE course and I don't know a lot about dynamical systems.","How to prove the existence and identify global attractor in Duffing equation where and ? I found a definition: A bounded closed set is called a global attractor for a dynamical system , if is an invariant set the set uniformly attracts all trajectories starting in bounded sets, i.e. for any bounded set from where where is the distance between the elements and in . I finished only ODE course and I don't know a lot about dynamical systems.","\ddot{x}+\epsilon \dot{x}+x^3-ax=0 \epsilon >0 a>0 A_1 \subset X (X, S_t) A_1 A_1 B X \lim_{t\to \infty} \sup \lbrace \operatorname{dist}(S_t y, A_1): y\in B \rbrace=0 \operatorname{dist}(z,A)=\inf\lbrace\operatorname{d}(z,y): y\in A\rbrace \operatorname{d}(z,y) z y X","['ordinary-differential-equations', 'dynamical-systems', 'nonlinear-system']"
25,Repeated roots in differential equations: The need to find further roots?,Repeated roots in differential equations: The need to find further roots?,,"Given a differential equation with $n$ roots, suppose there exists a 2-fold repeated root $y_1 = Ae^{\lambda_1 x}$ In this case, we are often told that for a $k$ -fold repeated root, we need to find an additional $k-1$ roots, by multiplying integer powers of $x$ as such the additional root required for our DE is $y=Axe^{\lambda_1 x}$ such that the $n$ roots are: $y_1 = Ae^{\lambda_1 x}, \ y_2=Axe^{\lambda_1 x}, \ y_3 = Axe^{\lambda_3 x}, \ \cdots \ y_n=Axe^{\lambda_n x}$$ Intuitively, why do we need to find the additional roots? For example in a quadratic equation $x^2 +2x +1 $ , if there are repeated roots. We would just ""accept"" that there is only one root $(x=1)$ . Why can't we do the same for a DE and just ""accept"" the existence of a repeated root instead of going further to find new ones?","Given a differential equation with roots, suppose there exists a 2-fold repeated root In this case, we are often told that for a -fold repeated root, we need to find an additional roots, by multiplying integer powers of as such the additional root required for our DE is such that the roots are: $y_1 = Ae^{\lambda_1 x}, \ y_2=Axe^{\lambda_1 x}, \ y_3 = Axe^{\lambda_3 x}, \ \cdots \ y_n=Axe^{\lambda_n x}$$ Intuitively, why do we need to find the additional roots? For example in a quadratic equation , if there are repeated roots. We would just ""accept"" that there is only one root . Why can't we do the same for a DE and just ""accept"" the existence of a repeated root instead of going further to find new ones?",n y_1 = Ae^{\lambda_1 x} k k-1 x y=Axe^{\lambda_1 x} n x^2 +2x +1  (x=1),['ordinary-differential-equations']
26,What is the soln to the differential equation : $x'''+x''+xx' = 0$?,What is the soln to the differential equation : ?,x'''+x''+xx' = 0,"$$x'''+x''+xx' = 0, \quad x' = \frac{\mathrm{d}x}{\mathrm{d}t}.$$ Is there an analytic soln for this? I am very new to numerical methods also, how do I solve this in python, if a numerical method is the only possibility?","Is there an analytic soln for this? I am very new to numerical methods also, how do I solve this in python, if a numerical method is the only possibility?","x'''+x''+xx' = 0, \quad x' = \frac{\mathrm{d}x}{\mathrm{d}t}.",['ordinary-differential-equations']
27,Why the existence and uniqueness of solution of ODE implies existence of $n$ independent solution of $\dot x=A(t)x$ where $A$ is periodic?,Why the existence and uniqueness of solution of ODE implies existence of  independent solution of  where  is periodic?,n \dot x=A(t)x A,"Let $A(t)\in \mathcal M_{n\times n}(\mathbb R)$ periodic, i.e. $$\exists \quad T>0:\forall t\in \mathbb R, A(t+T)=A(t).$$ Consider the system $$ \dot x(t)=A(t)x(t),\quad x(t)\in \mathbb R^n.$$ It's written in my course that if $t\mapsto A(t)$ is continuous, the existence and uniqueness theorem for ODE implies the existence of $n$ linearly independents solutions. I don't understand in what this ""existence and uniqueness theorem for ODE"" implies existence of $n$ linearly independents solution. Could someone explain why ? This theorem says (more or less) : If $F:\mathbb R\times \mathbb R^n\to \mathbb R^n$ is locally Lipschitz w.r.t. the second variable, then the Cauchy problem $$\begin{cases}\dot x(t)=F(t,x(t))\\ x(0)=x_0\end{cases}$$ has a unique (local) solution. So indeed, we take $F(t,x)=A(t)x$ which is obviously globally Lipschitz. But in one case we have a Cauchy problem, and in the other case we have an ODE without initial condition.","Let periodic, i.e. Consider the system It's written in my course that if is continuous, the existence and uniqueness theorem for ODE implies the existence of linearly independents solutions. I don't understand in what this ""existence and uniqueness theorem for ODE"" implies existence of linearly independents solution. Could someone explain why ? This theorem says (more or less) : If is locally Lipschitz w.r.t. the second variable, then the Cauchy problem has a unique (local) solution. So indeed, we take which is obviously globally Lipschitz. But in one case we have a Cauchy problem, and in the other case we have an ODE without initial condition.","A(t)\in \mathcal M_{n\times n}(\mathbb R) \exists \quad T>0:\forall t\in \mathbb R, A(t+T)=A(t).  \dot x(t)=A(t)x(t),\quad x(t)\in \mathbb R^n. t\mapsto A(t) n n F:\mathbb R\times \mathbb R^n\to \mathbb R^n \begin{cases}\dot x(t)=F(t,x(t))\\ x(0)=x_0\end{cases} F(t,x)=A(t)x","['real-analysis', 'linear-algebra', 'ordinary-differential-equations']"
28,"First order differential equation with $y,y',$ and $\sqrt y$",First order differential equation with  and,"y,y', \sqrt y","I have been struggling with this equation: $(x^2+1)y'-2xy=4\sqrt{(x^2+1)y}\arctan x$ I have tried with $y=z^m$ to make homogeneous equation, but I didn't get anything anything useful. Left side also looks a lot like quotient rule, so I tried solving in that direction, but again it didn't work. Whatever I do I can't seem to get it to any standard form. Thanks for help.","I have been struggling with this equation: I have tried with to make homogeneous equation, but I didn't get anything anything useful. Left side also looks a lot like quotient rule, so I tried solving in that direction, but again it didn't work. Whatever I do I can't seem to get it to any standard form. Thanks for help.",(x^2+1)y'-2xy=4\sqrt{(x^2+1)y}\arctan x y=z^m,['ordinary-differential-equations']
29,derivation of order 3 method for differential equations,derivation of order 3 method for differential equations,,"I am stuck with a big problem. Trying to understand the proof that the numerical method of solving differential equation $x_{i+1} = x_i + \tau_iF(t_i+\frac{\tau_i}{2}, x_{i+\frac{1}{2}})$ $x_{i+\frac{1}{2}} = x_i + \frac{\tau}{2}F(t_i,x_i)$ which seems to be the Cauchy-Euler's method. I am stuck with the Taylor approximation of $x(t+\tau) = x(t)+\tau x'(t) + \frac{1}{2} x''(t) + O(\tau^3)$ . Here it is OK for me. I also understand, why $x'(t)=F(t,x(t))$ . But why $x''(t) = \frac{d}{dt}F(t,x(t)) = \partial_tF(t,x(t)) + D_xF(t,x(t))F(t,x(t))$ ??? I am a little frustrated about this. Normally I am more into computer science and some mathematical concepts can be missing, so sorry for possible trivial or illposed question, thanks for patience :)","I am stuck with a big problem. Trying to understand the proof that the numerical method of solving differential equation which seems to be the Cauchy-Euler's method. I am stuck with the Taylor approximation of . Here it is OK for me. I also understand, why . But why ??? I am a little frustrated about this. Normally I am more into computer science and some mathematical concepts can be missing, so sorry for possible trivial or illposed question, thanks for patience :)","x_{i+1} = x_i + \tau_iF(t_i+\frac{\tau_i}{2}, x_{i+\frac{1}{2}}) x_{i+\frac{1}{2}} = x_i + \frac{\tau}{2}F(t_i,x_i) x(t+\tau) = x(t)+\tau x'(t) + \frac{1}{2} x''(t) + O(\tau^3) x'(t)=F(t,x(t)) x''(t) = \frac{d}{dt}F(t,x(t)) = \partial_tF(t,x(t)) + D_xF(t,x(t))F(t,x(t))","['ordinary-differential-equations', 'numerical-methods']"
30,Analytical function of this landscape,Analytical function of this landscape,,"Hey I'm looking for an analytical (or at least with an analytical inverse) continuous function that has this ""landscape"" please, and I welcome even differential equations that this function would respect : Meaning : $$\lim_{r\rightarrow \pm\infty} f(r)=0$$ , $$\lim_{r\rightarrow \pm\infty} f'(r)=0$$ and $f(0)=0$ and $f(\pm a)=b$ with $a>0$ and $b>0$ , if we make it simple : $$f(\pm 1)=\pm 1$$ . Thank you in advance","Hey I'm looking for an analytical (or at least with an analytical inverse) continuous function that has this ""landscape"" please, and I welcome even differential equations that this function would respect : Meaning : , and and with and , if we make it simple : . Thank you in advance",\lim_{r\rightarrow \pm\infty} f(r)=0 \lim_{r\rightarrow \pm\infty} f'(r)=0 f(0)=0 f(\pm a)=b a>0 b>0 f(\pm 1)=\pm 1,"['ordinary-differential-equations', 'functions', 'continuity']"
31,"ODE: $\dot{x}=f(t)x^2,x(0)=1$ solution on $\mathbb{R}\Leftrightarrow\int_{0}^{t}f(s)ds<1\forall t\in\mathbb{R}$",ODE:  solution on,"\dot{x}=f(t)x^2,x(0)=1 \mathbb{R}\Leftrightarrow\int_{0}^{t}f(s)ds<1\forall t\in\mathbb{R}","Let $f:\mathbb{R}\rightarrow\mathbb{R}$ a continuous function and $\phi$ a solution on its maximal interval of existence for the initial value problem $$ \dot{x}=f(t)x^2\hspace{0.3cm},\hspace{0.3cm}x(0)=1 $$ Show that the solution exists on $\mathbb{R}$ iff $$ \int_{0}^{t}f(s)ds<1\hspace{0.3cm}\forall t\in\mathbb{R} $$ So what I think would be the right way to start is to note that $\dfrac{\dot{x}}{x^2}=-\dfrac{d}{dt}\dfrac{1}{x}$ however that only works when $x\neq 0$ so I'm not quite sure about how to proceed.",Let a continuous function and a solution on its maximal interval of existence for the initial value problem Show that the solution exists on iff So what I think would be the right way to start is to note that however that only works when so I'm not quite sure about how to proceed.,"f:\mathbb{R}\rightarrow\mathbb{R} \phi 
\dot{x}=f(t)x^2\hspace{0.3cm},\hspace{0.3cm}x(0)=1
 \mathbb{R} 
\int_{0}^{t}f(s)ds<1\hspace{0.3cm}\forall t\in\mathbb{R}
 \dfrac{\dot{x}}{x^2}=-\dfrac{d}{dt}\dfrac{1}{x} x\neq 0","['real-analysis', 'ordinary-differential-equations', 'proof-writing']"
32,How to calculate the shape of a curve given y coordinates and slope?,How to calculate the shape of a curve given y coordinates and slope?,,"I apologise in advance if my description of the problem does not use the correct terminology but I'm still learning! Let me know if something is ambiguous or not clear and I'll try to rephrase it. The Problem: I would like to draw a curve/figure out the shape of a curve given the information in the following graph: On the y axis, I'm showing the slope of my curve, and on the x axis I'm showing the height/y-coordinate of each point in my curve. I am missing information about the x-coordinates of my curve. In this case, because the graph I have shown above is quite simple (a straight line indicating ever increasing slope), I can intuitively understand that my curve will have a shape similar to this: However, I don't know exactly how to go about deducing this shape in the case of more complex curves, or even how to go about figuring out the shape of the curve I just showed you in a principled manner. Importantly, I am also happy to make the assumption that a slope of 1 equals a change of one unit in the x axis of the graph where I'll draw my curve (I'm more interested in the shape of the curve, and it's shape relative to other curves deduced using the same method, than in the absolute value of the x axis coordinates). It just seems like this is the kind of problem that might have already been solved by someone, but I don't really know how to search for the answer since I don't know what keywords to use. In the example above, the graph telling me information about the curve showed a line y = 2x. However, I might have a graph whose information is not given by a simple mathematical equation (imagine a local regression curve, or a complicated spline). Many thanks in advance.","I apologise in advance if my description of the problem does not use the correct terminology but I'm still learning! Let me know if something is ambiguous or not clear and I'll try to rephrase it. The Problem: I would like to draw a curve/figure out the shape of a curve given the information in the following graph: On the y axis, I'm showing the slope of my curve, and on the x axis I'm showing the height/y-coordinate of each point in my curve. I am missing information about the x-coordinates of my curve. In this case, because the graph I have shown above is quite simple (a straight line indicating ever increasing slope), I can intuitively understand that my curve will have a shape similar to this: However, I don't know exactly how to go about deducing this shape in the case of more complex curves, or even how to go about figuring out the shape of the curve I just showed you in a principled manner. Importantly, I am also happy to make the assumption that a slope of 1 equals a change of one unit in the x axis of the graph where I'll draw my curve (I'm more interested in the shape of the curve, and it's shape relative to other curves deduced using the same method, than in the absolute value of the x axis coordinates). It just seems like this is the kind of problem that might have already been solved by someone, but I don't really know how to search for the answer since I don't know what keywords to use. In the example above, the graph telling me information about the curve showed a line y = 2x. However, I might have a graph whose information is not given by a simple mathematical equation (imagine a local regression curve, or a complicated spline). Many thanks in advance.",,"['ordinary-differential-equations', 'curves']"
33,"Finding Particular Intergrals for ODE's, Is it okay if particular integral varies?","Finding Particular Intergrals for ODE's, Is it okay if particular integral varies?",,"The equation to solve : $y''-6y'+9y=e^{3x}$ This is the general solution from wolframalpha : $y(x) = c_2 e^{3 x} x + c_1 e^{3 x} + 1/2 e^{3x} x^{2}$ This is the solution I calculated from the method of undetermined coefficients : $y(x) = c_2 e^{3 x} x + c_1 e^{3 x} + Ax^2 e^{3x}$ This is the solution I calculated using the 'D' operator and shortcut method : $y(x) = c_2 e^{3 x} x + c_1 e^{3 x} + e^{3x}/18$ I think I'm getting different particular integrals while using different methods because this differential equation has a family of solutions ? But the fact that the last solution's P.I doesn't even have an 'x' term concerns me. All of them are correct, am I right ?","The equation to solve : This is the general solution from wolframalpha : This is the solution I calculated from the method of undetermined coefficients : This is the solution I calculated using the 'D' operator and shortcut method : I think I'm getting different particular integrals while using different methods because this differential equation has a family of solutions ? But the fact that the last solution's P.I doesn't even have an 'x' term concerns me. All of them are correct, am I right ?",y''-6y'+9y=e^{3x} y(x) = c_2 e^{3 x} x + c_1 e^{3 x} + 1/2 e^{3x} x^{2} y(x) = c_2 e^{3 x} x + c_1 e^{3 x} + Ax^2 e^{3x} y(x) = c_2 e^{3 x} x + c_1 e^{3 x} + e^{3x}/18,"['calculus', 'ordinary-differential-equations', 'proof-verification']"
34,"fixpoint iteration to solve $y'(t)=y(t), y(0)=1$",fixpoint iteration to solve,"y'(t)=y(t), y(0)=1","Solve the initial value problem $y'(t)=y(t)$ , $y(0)=1$ on the interval $[0,1]$ with a fixpoint iteration of the operator $T: Y\to Y, (Ty)(t):=y_0+\int_0^t f(s,y(s))\, ds$ . Begin with $y_0(t)=0$ and give the function series $(y_k)$ . The operator $T$ is supposed to be taken from the proof of the theorem of Picard-Lindelöf. But how do I do the fixpoint iteration here?  What is $f(s,y(s))$ ? In the proof of Picard-Lindelöf it is $y'(t)=f(t,y(t))$ .  Since we want to solve $y'(t)=y(t)$ can we set $f(t,y(t))=y(t)$ ? So, I set that all together and start the iteration: We have $y(0)=1$ and $y_0(t)=0$ . $y_1(t)=y(0)+\int_0^t y_0(s)\, ds=1$ $y_2(t)=y(0)+\int_0^t y_1(s)\, ds=t+1$ $y_3(t)=y(0)+\int_0^t y_2(s)\, ds=\frac{1}{2}t^2+t+1$ $y_4(t)=y(0)+\int_0^t y_3(s)\, ds=\frac{1}{6}t^3+\frac12t^2+t+1$ And so on. We see, that this indeed gives the sum: $y_n(t)=\sum_{k=0}^n \frac{t^k}{k!}$ Which would give $e^t$ eventually. Is this done correctly? How comes the interval $[0,1]$ into account here? Thanks in advance.","Solve the initial value problem , on the interval with a fixpoint iteration of the operator . Begin with and give the function series . The operator is supposed to be taken from the proof of the theorem of Picard-Lindelöf. But how do I do the fixpoint iteration here?  What is ? In the proof of Picard-Lindelöf it is .  Since we want to solve can we set ? So, I set that all together and start the iteration: We have and . And so on. We see, that this indeed gives the sum: Which would give eventually. Is this done correctly? How comes the interval into account here? Thanks in advance.","y'(t)=y(t) y(0)=1 [0,1] T: Y\to Y, (Ty)(t):=y_0+\int_0^t f(s,y(s))\, ds y_0(t)=0 (y_k) T f(s,y(s)) y'(t)=f(t,y(t)) y'(t)=y(t) f(t,y(t))=y(t) y(0)=1 y_0(t)=0 y_1(t)=y(0)+\int_0^t y_0(s)\, ds=1 y_2(t)=y(0)+\int_0^t y_1(s)\, ds=t+1 y_3(t)=y(0)+\int_0^t y_2(s)\, ds=\frac{1}{2}t^2+t+1 y_4(t)=y(0)+\int_0^t y_3(s)\, ds=\frac{1}{6}t^3+\frac12t^2+t+1 y_n(t)=\sum_{k=0}^n \frac{t^k}{k!} e^t [0,1]","['ordinary-differential-equations', 'numerical-methods', 'fixed-point-theorems']"
35,"Solve ODE initial value problem: $\dot{u}=(2t+u-3)^2-2 , u(1)=0$ Separation of variables fails",Solve ODE initial value problem:  Separation of variables fails,"\dot{u}=(2t+u-3)^2-2 , u(1)=0",So I have this ODE initial value problem $\dot{u}=(2t+u-3)^2-2 \hspace{2cm}u(1)=0$ So I tried seperating the variables somehow but to no avail. How else could I tackle this problem ?,So I have this ODE initial value problem So I tried seperating the variables somehow but to no avail. How else could I tackle this problem ?,\dot{u}=(2t+u-3)^2-2 \hspace{2cm}u(1)=0,"['calculus', 'ordinary-differential-equations']"
36,An optimal control problem with fixed final time and free final state,An optimal control problem with fixed final time and free final state,,"I am attempting to solve an optimal control problem, but I am not really sure what it is asking. Given the control system $$\dfrac{d}{dt}\begin{bmatrix} x_1(t) \\ x_2(t) \end{bmatrix} = \begin{bmatrix} -x_1(t) \\ x_2(t) \end{bmatrix}u(t)$$ where $u(t) \in [-1,1]$ and $\mathbf{x} (t) \in \mathbb R^2$ for all $t \in [0,1]$ , and $\mathbf{x}(0) =[x_1(0),x_2(0)]^T =: \mathbf{x}^0$ . Prove there is an optimal controller for every $\mathbf{x}^0$ and there exists $$\min_{u:[0,1] \to [-1,1]} \|\mathbf{x}(1)\|_2^2$$ For every $\mathbf x^0 \in \mathbb R^2$ , find an optimal controller $u:[0,1] \to [-1,1] $ . I have never taken an optimization course and only had basic education on control theory, but it all involved actual numbers and coding. The main thing I am confused on is the mathematical notation — what is the problem asking? Any advice on what the best way to approach this problem is?","I am attempting to solve an optimal control problem, but I am not really sure what it is asking. Given the control system where and for all , and . Prove there is an optimal controller for every and there exists For every , find an optimal controller . I have never taken an optimization course and only had basic education on control theory, but it all involved actual numbers and coding. The main thing I am confused on is the mathematical notation — what is the problem asking? Any advice on what the best way to approach this problem is?","\dfrac{d}{dt}\begin{bmatrix} x_1(t) \\ x_2(t) \end{bmatrix} = \begin{bmatrix} -x_1(t) \\ x_2(t) \end{bmatrix}u(t) u(t) \in [-1,1] \mathbf{x} (t) \in \mathbb R^2 t \in [0,1] \mathbf{x}(0) =[x_1(0),x_2(0)]^T =: \mathbf{x}^0 \mathbf{x}^0 \min_{u:[0,1] \to [-1,1]} \|\mathbf{x}(1)\|_2^2 \mathbf x^0 \in \mathbb R^2 u:[0,1] \to [-1,1] ","['ordinary-differential-equations', 'optimization', 'control-theory', 'optimal-control']"
37,Bessel differential equation from integral,Bessel differential equation from integral,,"It is a relatively well-known fact that $$\int_{0}^{2\pi}e^{-ikr\cos\theta}d\theta=2\pi J_{0}(kr),$$ where $J_{0}$ is the Bessel function of the first kind and order zero. I'm trying to show that this is the case not from the definition itself, but from the differential equation it should verify, namely the Bessel differential equation of order zero, $$q^{2}\frac{ d^{2}J_{0}}{dq^{2}}+q\frac{dJ_{0}}{dq}+q^{2}J_{0}=0,$$ where now $q\equiv kr$ is the argument of the Bessel function in order to simplify the notation. However, when I apply differentiation with respect to $q$ two times to the above integral, this yields $$\int_{0}^{2\pi}(-q^{2}\cos^{2}\theta-iq\cos\theta+q^{2})e^{-iq\cos\theta}d\theta,$$ and it is not obvious to me why this should be 0. Any help is appreciated!","It is a relatively well-known fact that where is the Bessel function of the first kind and order zero. I'm trying to show that this is the case not from the definition itself, but from the differential equation it should verify, namely the Bessel differential equation of order zero, where now is the argument of the Bessel function in order to simplify the notation. However, when I apply differentiation with respect to two times to the above integral, this yields and it is not obvious to me why this should be 0. Any help is appreciated!","\int_{0}^{2\pi}e^{-ikr\cos\theta}d\theta=2\pi J_{0}(kr), J_{0} q^{2}\frac{ d^{2}J_{0}}{dq^{2}}+q\frac{dJ_{0}}{dq}+q^{2}J_{0}=0, q\equiv kr q \int_{0}^{2\pi}(-q^{2}\cos^{2}\theta-iq\cos\theta+q^{2})e^{-iq\cos\theta}d\theta,","['integration', 'ordinary-differential-equations', 'special-functions', 'bessel-functions']"
38,Finding particular solutions of $y^{(4)} + 2y'' + y = x \sin x$,Finding particular solutions of,y^{(4)} + 2y'' + y = x \sin x,"We have a non homogeneous ODE $$y^{(4)} + 2y'' + y = x \sin x$$ with characteristic equation I get $(l^2+1)^2 = 0$ so $l = -i ,i$ and so the answer of homogeneous ODE is a linear combination of $\sin x , \cos x , x \sin x , x\cos x$ . For finding the Particular solution first I assumed $y_p = (Ax+B)(C\sin x + D \cos x)$ and it didn't work. Then $y_p = x(Ax+B)(C\sin x + D \cos x)$ and it didn't work. At last, $y_p = x^2(Ax+B)(C\sin x + D \cos x)$ worked and the answer was $-1/24 x^3 \sin x -1/8 x^2 \cos x$ worked but it took a lot of time to find that the other two don't work. I want to know is there any way to guess the leading $x^n$ term and not testing different situations? (In this case $n=2$ ) I know it can be solved with a way involving Wronskian and Cramer's rule (but that way needs a 4x4 determinant which takes time to calculate) but I want to solve with undetermined coefficients rule so I want to find a better way for guessing the answer format.","We have a non homogeneous ODE with characteristic equation I get so and so the answer of homogeneous ODE is a linear combination of . For finding the Particular solution first I assumed and it didn't work. Then and it didn't work. At last, worked and the answer was worked but it took a lot of time to find that the other two don't work. I want to know is there any way to guess the leading term and not testing different situations? (In this case ) I know it can be solved with a way involving Wronskian and Cramer's rule (but that way needs a 4x4 determinant which takes time to calculate) but I want to solve with undetermined coefficients rule so I want to find a better way for guessing the answer format.","y^{(4)} + 2y'' + y = x \sin x (l^2+1)^2 = 0 l = -i ,i \sin x , \cos x , x \sin x , x\cos x y_p = (Ax+B)(C\sin x + D \cos x) y_p = x(Ax+B)(C\sin x + D \cos x) y_p = x^2(Ax+B)(C\sin x + D \cos x) -1/24 x^3 \sin x -1/8 x^2 \cos x x^n n=2","['ordinary-differential-equations', 'derivatives']"
39,Find a composite solution to the following problem,Find a composite solution to the following problem,,"I'm trying to solve the following exercise: Find a composite solution to the following problem: $$ \epsilon y'' + y(y' + 3) = 0 \text{ for }0<x<1, \text{ where }y(0) = 1, \,y(1) = 1 $$ where $\epsilon <<1.$ What I've tried: I've just learned about matched asymptotic expansions and I'm pretty sure that my teacher wants me to use those to solve this exercise. The procedure works as follows: Find the outer solution . This solution is often found by assuming that the solution can be expanded in powers of $\epsilon$ . Because this solution often has only one arbitrary constant it will not be able to satisfy both the boundary value conditions. Find the inner solution . Assume that there exists a boundary layer at one of the boundaries. Introduce a boundary-layer coordinate and use an expansion for the boundary-layer solution . Matching. Since the inner (corresponding to the boundary-layer) and outer expansions are approximations of the same function we expect them to be the same in the region between the inner and outer layers. Composite expansion. Use the inner and outer solution to find a solution that will work over the entire interval. This can be done by adding the two solutions and subtracting corresponding to the region where they are equal. I found the outer solution by assuming that the solution $y$ can expanded in powers of $\epsilon$ as follows: $$ y \sim y_0(x) + \epsilon y_1(x) + \ldots \tag{1} $$ If we substitute $(1)$ into the problem equation we get $$ \epsilon(y''_0 + \epsilon y''_1 + \ldots) + (y_0 + \epsilon y_1 + \ldots)(y'_0 + y'_1 + \ldots + 3) = 0 $$ We can find $y_0$ by looking at the order one terms: $\mathcal{O}(1):$ $$ y_0(y'_0 + 3) = 0 $$ so that $y_0$ or $y_0 = c_1 - 3x$ . This is the first moment where I don't exactly know how to proceed: I would have expected one solution. To find the inner solution or boundary-layer solution we assume that there is a boundary layer at $x = 0$ and introduce a boundary layer coordinate: $$ \bar{x} = \dfrac{x}{\epsilon^\alpha} $$ From this change of variables and the chain rule, we have that $$ \dfrac{d}{dx} = \dfrac{d\bar{x}}{dx}\dfrac{d}{d\bar{x}} = \dfrac{1}{\epsilon^\alpha}\dfrac{d}{d\bar{x}} $$ If we now let $Y(\bar{x})$ denote the solution when using this boundary-layer coordinate, the problem equation transforms to $$ \epsilon^{1 - 2\alpha}\dfrac{d^2}{d\bar{x}^2}(Y_0 + \epsilon Y_1 + \ldots) + (Y_0 + \epsilon Y_1 + \ldots)\dfrac{1}{\epsilon^\alpha}\dfrac{d}{d\bar{x}}(Y_0 + \epsilon Y_1 + \ldots) + 3(Y_0 + \epsilon Y_1 + \ldots) $$ In order to determine $Y_0$ , I want to balance the terms in this equation. I tried balancing the first and second term so that the third term becomes higher order. To balance the first and second term we need $1 - 2\alpha = -\alpha$ so that $\alpha = 1$ . In this case the first to terms are $\mathcal{O}(\frac{1}{\epsilon})$ and the third term is $\mathcal{O}(1)$ so that the requirement that the third term is higher order is satisfied. If $\alpha = 1$ we find: $\mathcal{O}(\frac{1}{\epsilon})$ : \begin{align} Y''_0 + Y_0Y'_0 = 0\\ Y_0(0) = 1 \end{align} If I enter this equation in wolfram I get a pretty long solution and I don't think it's supposed to be like that. It feels as if I'm doing something wrong. Question: I am doing this correctly? What should I be doing differently? I don't know how to proceed from here since I can't find a reasonable solution for $Y_0$ .","I'm trying to solve the following exercise: Find a composite solution to the following problem: where What I've tried: I've just learned about matched asymptotic expansions and I'm pretty sure that my teacher wants me to use those to solve this exercise. The procedure works as follows: Find the outer solution . This solution is often found by assuming that the solution can be expanded in powers of . Because this solution often has only one arbitrary constant it will not be able to satisfy both the boundary value conditions. Find the inner solution . Assume that there exists a boundary layer at one of the boundaries. Introduce a boundary-layer coordinate and use an expansion for the boundary-layer solution . Matching. Since the inner (corresponding to the boundary-layer) and outer expansions are approximations of the same function we expect them to be the same in the region between the inner and outer layers. Composite expansion. Use the inner and outer solution to find a solution that will work over the entire interval. This can be done by adding the two solutions and subtracting corresponding to the region where they are equal. I found the outer solution by assuming that the solution can expanded in powers of as follows: If we substitute into the problem equation we get We can find by looking at the order one terms: so that or . This is the first moment where I don't exactly know how to proceed: I would have expected one solution. To find the inner solution or boundary-layer solution we assume that there is a boundary layer at and introduce a boundary layer coordinate: From this change of variables and the chain rule, we have that If we now let denote the solution when using this boundary-layer coordinate, the problem equation transforms to In order to determine , I want to balance the terms in this equation. I tried balancing the first and second term so that the third term becomes higher order. To balance the first and second term we need so that . In this case the first to terms are and the third term is so that the requirement that the third term is higher order is satisfied. If we find: : If I enter this equation in wolfram I get a pretty long solution and I don't think it's supposed to be like that. It feels as if I'm doing something wrong. Question: I am doing this correctly? What should I be doing differently? I don't know how to proceed from here since I can't find a reasonable solution for .","
\epsilon y'' + y(y' + 3) = 0 \text{ for }0<x<1, \text{ where }y(0) = 1, \,y(1) = 1
 \epsilon <<1. \epsilon y \epsilon 
y \sim y_0(x) + \epsilon y_1(x) + \ldots \tag{1}
 (1) 
\epsilon(y''_0 + \epsilon y''_1 + \ldots) + (y_0 + \epsilon y_1 + \ldots)(y'_0 + y'_1 + \ldots + 3) = 0
 y_0 \mathcal{O}(1): 
y_0(y'_0 + 3) = 0
 y_0 y_0 = c_1 - 3x x = 0 
\bar{x} = \dfrac{x}{\epsilon^\alpha}
 
\dfrac{d}{dx} = \dfrac{d\bar{x}}{dx}\dfrac{d}{d\bar{x}} = \dfrac{1}{\epsilon^\alpha}\dfrac{d}{d\bar{x}}
 Y(\bar{x}) 
\epsilon^{1 - 2\alpha}\dfrac{d^2}{d\bar{x}^2}(Y_0 + \epsilon Y_1 + \ldots) + (Y_0 + \epsilon Y_1 + \ldots)\dfrac{1}{\epsilon^\alpha}\dfrac{d}{d\bar{x}}(Y_0 + \epsilon Y_1 + \ldots) + 3(Y_0 + \epsilon Y_1 + \ldots)
 Y_0 1 - 2\alpha = -\alpha \alpha = 1 \mathcal{O}(\frac{1}{\epsilon}) \mathcal{O}(1) \alpha = 1 \mathcal{O}(\frac{1}{\epsilon}) \begin{align}
Y''_0 + Y_0Y'_0 = 0\\
Y_0(0) = 1
\end{align} Y_0","['ordinary-differential-equations', 'power-series', 'approximation']"
40,How to numerically set up to solve this differential equation?,How to numerically set up to solve this differential equation?,,"I have a 1-d differential equation: $$\frac{\mathrm{d}f}{\mathrm{d}\theta} = c(\mathrm{max}(\sin\theta,0)-f^4)~.$$ I am given periodic boundary condition, i.e. $f(\theta) = f(2\pi+\theta)$ . How would I set up a discretised form of this equation to solve for $f(\theta)$ ?","I have a 1-d differential equation: I am given periodic boundary condition, i.e. . How would I set up a discretised form of this equation to solve for ?","\frac{\mathrm{d}f}{\mathrm{d}\theta} = c(\mathrm{max}(\sin\theta,0)-f^4)~. f(\theta) = f(2\pi+\theta) f(\theta)","['ordinary-differential-equations', 'numerical-methods']"
41,How is $\frac{dx }{z(x+y) } = \frac{dy}{z(x-y) } = \frac{dz }{x^2 + y^2 } $ equivalent to $\frac{ y dx + xdy - zdz}{0}=\frac{ xdx - ydy -zdz}{0}$?,How is  equivalent to ?,\frac{dx }{z(x+y) } = \frac{dy}{z(x-y) } = \frac{dz }{x^2 + y^2 }  \frac{ y dx + xdy - zdz}{0}=\frac{ xdx - ydy -zdz}{0},"In the book of PDE by Kumar, it is given that However, I couldn't figure out how is $$\frac{dx }{z(x+y) } = \frac{dy}{z(x-y) } = \frac{dz }{x^2 + y^2 }  $$ is equivalent to $$\frac{ y dx + xdy - zdz}{0 } = \frac{ x dx - y dy -z dz}{ 0}  .$$","In the book of PDE by Kumar, it is given that However, I couldn't figure out how is is equivalent to",\frac{dx }{z(x+y) } = \frac{dy}{z(x-y) } = \frac{dz }{x^2 + y^2 }   \frac{ y dx + xdy - zdz}{0 } = \frac{ x dx - y dy -z dz}{ 0}  .,"['ordinary-differential-equations', 'partial-differential-equations']"
42,Is this system of differential equations coupled or not?,Is this system of differential equations coupled or not?,,$$\begin{aligned} \dot{x_{1}} &= a\\ \dot{x_{2}} &= b \sin\Bigl(\omega(t-x_{1})\Bigr) \end{aligned}$$ Does it follow from here that $ x_{1} = at+c $ ? Or do I have to turn it into a single higher-order differential equation and then solve it? How to spot the difference easily?,Does it follow from here that ? Or do I have to turn it into a single higher-order differential equation and then solve it? How to spot the difference easily?,\begin{aligned} \dot{x_{1}} &= a\\ \dot{x_{2}} &= b \sin\Bigl(\omega(t-x_{1})\Bigr) \end{aligned}  x_{1} = at+c ,['ordinary-differential-equations']
43,"Why does the ""solution"" not satisfy the PDE?","Why does the ""solution"" not satisfy the PDE?",,"I'm trying to solve the following PDE: $$x z_x -xyz_y = z \quad with\quad z(x,x) =x^2 e^x \quad (x,y) \in \mathbb{R}^2.$$ I've proceeded as, $$\frac{dx}{ x} = \frac{dy }{-xy }  \Rightarrow y = C e^{-x}, $$ so $$\frac{dz}{ dx}  = z \Rightarrow z = G(C) e^x .$$ Using the given curve, $$ \begin{split} z(x,x) &= G\left(\frac{ x}{ e^{-x}}\right) e^x = x^2 e^x\\ \\ & \Rightarrow G(t) = t^2 e^{2x} (\text{ I am not sure this is the only possible form of }G). \end{split} $$ Hence, $$z(x,y) = y^2 e^x,$$ but the thing is, this does not satisfy the given PDE: $$ x (y^2 e^x) - xy (2y e^x) = -xy^2e^x \not = z. $$ I'm assuming that there is a problem while finding the characteristic curve since I cancelled $x$ s there, but not sure why would that cause a problem, so I'm looking for both a solution and an explanation what is wrong in my wrong solution.","I'm trying to solve the following PDE: I've proceeded as, so Using the given curve, Hence, but the thing is, this does not satisfy the given PDE: I'm assuming that there is a problem while finding the characteristic curve since I cancelled s there, but not sure why would that cause a problem, so I'm looking for both a solution and an explanation what is wrong in my wrong solution.","x z_x -xyz_y = z \quad with\quad z(x,x) =x^2 e^x \quad (x,y) \in \mathbb{R}^2. \frac{dx}{ x} = \frac{dy }{-xy }  \Rightarrow y = C e^{-x},  \frac{dz}{ dx}  = z \Rightarrow z = G(C) e^x . 
\begin{split}
z(x,x) &= G\left(\frac{ x}{ e^{-x}}\right) e^x = x^2 e^x\\
\\
& \Rightarrow G(t) = t^2 e^{2x} (\text{ I am not sure this is the only possible form of }G).
\end{split}
 z(x,y) = y^2 e^x, 
x (y^2 e^x) - xy (2y e^x) = -xy^2e^x \not = z.
 x","['ordinary-differential-equations', 'partial-differential-equations']"
44,How do I prove/disprove this formula of infinite sums of derivatives.,How do I prove/disprove this formula of infinite sums of derivatives.,,"I am a first year student who wants to learn more about math, specifically how to think like a mathematicians. For that, I came up with a simple exercise to find functions f(x) that satisfy $$f(x) = \sum_{i=1}^\infty \frac{d^i}{dx^i}f(x)$$ or show that the trivial solution f(x) = 0 is the only function that satisfies the infinite sum. I have no idea or pointers on how to solve this. I don't necessarily want a solution to this, I would love to get some hints because appart from basic induction (which I learned from my first year at college) I can't come up with a tool or method that might help me to solve this puzzle (I tried Taylor expansion but it led to nothing usefull). I specifically want to grasp how mathematicians approach such questions. Where do I start, what should I apply to solve this sum, what is the standart tool to approach this, etc? Trial and error did work for f(x) = 0, but I wan't to be able to solve such tasks in a more academic sense.","I am a first year student who wants to learn more about math, specifically how to think like a mathematicians. For that, I came up with a simple exercise to find functions f(x) that satisfy or show that the trivial solution f(x) = 0 is the only function that satisfies the infinite sum. I have no idea or pointers on how to solve this. I don't necessarily want a solution to this, I would love to get some hints because appart from basic induction (which I learned from my first year at college) I can't come up with a tool or method that might help me to solve this puzzle (I tried Taylor expansion but it led to nothing usefull). I specifically want to grasp how mathematicians approach such questions. Where do I start, what should I apply to solve this sum, what is the standart tool to approach this, etc? Trial and error did work for f(x) = 0, but I wan't to be able to solve such tasks in a more academic sense.",f(x) = \sum_{i=1}^\infty \frac{d^i}{dx^i}f(x),"['sequences-and-series', 'ordinary-differential-equations']"
45,Some phase plane analysis for $u_t=u_{xx}+f(u)$ with assumptions on $f$,Some phase plane analysis for  with assumptions on,u_t=u_{xx}+f(u) f,"Consider the semilinear diffusion equation $$ u_t=u_{xx}+f(u) $$ with the following assumptions on $f$ for some $\alpha\in (0,1)$ : $f\in C^1[0,1]$ $f(0)=f(1)=0$ $f'(0) < 0$ $f(u)<0$ in $(0,\alpha)$ $f(u)>0$ in $(\alpha,1)$ $\int_0^1 f(u)\, du>0$ Introduce the moving coordinates $\xi=x-ct$ . Plugging this into the equation gives $$ -cU_\xi=U_{\xi\xi}+f(U) $$ which as a system is $$ \begin{align*} U_\xi&=V\\ V_\xi&=-cV-f(U) \end{align*} $$ For $c=0$ , we have the ""Energy"" $$ E(U,U_\xi)=\frac{1}{2}(U_\xi)^2+F(U),\qquad F(U):=\int_0^U f(y)\, dy $$ and, in particular, each trajectory satisfies an equation $$ E(U,U_\xi)=\textrm{const}. $$ Now, there is the following part in a paper which I do not understand: Under our hypotheses on $f(u)$ [which I listed above], there is an $\eta\in (0,1)$ such that $F(\eta)>0$ . For any $0 < \nu < (2F(\eta))^{1/2}$ the trajectory through $(0,-\nu)$ lies in the strip $U\in [0,1)$ and contains a point of the positive $V$ -axis. 1.) Why is there an $\eta\in (0,1)$ with $F(\eta)>0$ ? Am I right that $F(0)=0$ and $F(1)>0$ ; if yes then this implies the existence of such an $\eta$ (Intermediate value theorem?) 2.) Where does the condition $0<\nu<(2 F(\eta))^{1/2}$ come from? From the energy picture, it is clear to me that by assumption $\int_0^1 f(u)\, du=F(1)-F(0)>0$ , we have that there are to hill tops positioned at $U=0, F(0)$ and $U=1, F(1)$ and that the second hill top is higher than the first one. Hence, from the phase plane it is clear to me that there are trajectories through $(u,0)$ and $(0,-v)$ for $u\approx 1$ and some $v>0$ . I think the condition $0<\nu <(2 F(\eta))^{1/2}$ has something to do with this energy picture. Edit. My idea would be to use $$ E(U,V)=C \Leftrightarrow V=\pm\sqrt{2C-2F(U)} $$ which makes sense iff $F(U)\leqslant C$ . If we choose $C=F(\eta)$ then for $0<F(U)<F(\eta)$ we have $$ 0<\lvert V\rvert<\sqrt{2F(\eta)} $$ and the trajectories containing $(0,-V)$ are of the described type?","Consider the semilinear diffusion equation with the following assumptions on for some : in in Introduce the moving coordinates . Plugging this into the equation gives which as a system is For , we have the ""Energy"" and, in particular, each trajectory satisfies an equation Now, there is the following part in a paper which I do not understand: Under our hypotheses on [which I listed above], there is an such that . For any the trajectory through lies in the strip and contains a point of the positive -axis. 1.) Why is there an with ? Am I right that and ; if yes then this implies the existence of such an (Intermediate value theorem?) 2.) Where does the condition come from? From the energy picture, it is clear to me that by assumption , we have that there are to hill tops positioned at and and that the second hill top is higher than the first one. Hence, from the phase plane it is clear to me that there are trajectories through and for and some . I think the condition has something to do with this energy picture. Edit. My idea would be to use which makes sense iff . If we choose then for we have and the trajectories containing are of the described type?","
u_t=u_{xx}+f(u)
 f \alpha\in (0,1) f\in C^1[0,1] f(0)=f(1)=0 f'(0) < 0 f(u)<0 (0,\alpha) f(u)>0 (\alpha,1) \int_0^1 f(u)\, du>0 \xi=x-ct 
-cU_\xi=U_{\xi\xi}+f(U)
 
\begin{align*}
U_\xi&=V\\
V_\xi&=-cV-f(U)
\end{align*}
 c=0 
E(U,U_\xi)=\frac{1}{2}(U_\xi)^2+F(U),\qquad F(U):=\int_0^U f(y)\, dy
 
E(U,U_\xi)=\textrm{const}.
 f(u) \eta\in (0,1) F(\eta)>0 0 < \nu < (2F(\eta))^{1/2} (0,-\nu) U\in [0,1) V \eta\in (0,1) F(\eta)>0 F(0)=0 F(1)>0 \eta 0<\nu<(2 F(\eta))^{1/2} \int_0^1 f(u)\, du=F(1)-F(0)>0 U=0, F(0) U=1, F(1) (u,0) (0,-v) u\approx 1 v>0 0<\nu <(2 F(\eta))^{1/2} 
E(U,V)=C \Leftrightarrow V=\pm\sqrt{2C-2F(U)}
 F(U)\leqslant C C=F(\eta) 0<F(U)<F(\eta) 
0<\lvert V\rvert<\sqrt{2F(\eta)}
 (0,-V)","['ordinary-differential-equations', 'partial-differential-equations']"
46,Visualise the bifurcation diagram,Visualise the bifurcation diagram,,Can anyone help me visualise the bifurcation diagram that would be produced by $\dot x = (x−μ)(1+μ−x^2)$ and $\dot x = (μ^2−1)(μ−2)−x$ I know for 2. there is only one equilibrium point so should this give me a wave like graph? I know for 1. I have 3 solutions so is this a pitchfork bifurcation plot?,Can anyone help me visualise the bifurcation diagram that would be produced by and I know for 2. there is only one equilibrium point so should this give me a wave like graph? I know for 1. I have 3 solutions so is this a pitchfork bifurcation plot?,\dot x = (x−μ)(1+μ−x^2) \dot x = (μ^2−1)(μ−2)−x,"['linear-algebra', 'ordinary-differential-equations', 'nonlinear-system', 'bifurcation']"
47,Vector differential equation,Vector differential equation,,"In electromagnetism we often have a perpendicular constant magnetic field causing a charge to move in a circle. My question is, how do we formally solve this differential equation which involves a cross product? $\frac{\mathrm{d} \mathbf{v}}{\mathrm{d}t} = \frac{qB_0}{m}\mathbf{v}\times{{\hat{\mathbf{k}}}}$ So I think I have made progress by splitting into 3 equations. Using that cartesian unit vectors are linearly independent and don't change with time. $\frac{\mathrm{d} v_x}{\mathrm{d}t} = \frac{qB_0}{m}v_y$ and $\frac{\mathrm{d} v_y}{\mathrm{d}t} = -\frac{qB_0}{m}v_x$ and $\frac{\mathrm{d} v_z}{\mathrm{d}t} = 0$ $v_z = v_z(0)$ , which is trivial. But what about the others? Also I can see that the derivative is a linear transformation of the vector $v_x,v_y$ and have found the matrix. What now?","In electromagnetism we often have a perpendicular constant magnetic field causing a charge to move in a circle. My question is, how do we formally solve this differential equation which involves a cross product? So I think I have made progress by splitting into 3 equations. Using that cartesian unit vectors are linearly independent and don't change with time. and and , which is trivial. But what about the others? Also I can see that the derivative is a linear transformation of the vector and have found the matrix. What now?","\frac{\mathrm{d} \mathbf{v}}{\mathrm{d}t} = \frac{qB_0}{m}\mathbf{v}\times{{\hat{\mathbf{k}}}} \frac{\mathrm{d} v_x}{\mathrm{d}t} = \frac{qB_0}{m}v_y \frac{\mathrm{d} v_y}{\mathrm{d}t} = -\frac{qB_0}{m}v_x \frac{\mathrm{d} v_z}{\mathrm{d}t} = 0 v_z = v_z(0) v_x,v_y","['ordinary-differential-equations', 'multivariable-calculus', 'vector-analysis', 'electromagnetism']"
48,Proving uniqueness of ODE solution,Proving uniqueness of ODE solution,,"The ODE is the following: $\begin{cases} u''(x) = 0,\\[6pt] u(0) = a, u'(0) = b \end{cases} $ I need to prove that ODE is well-posed and so far I have proven both the existence of the solution and the stability, but I am not sure how to approach the uniqueness problem, assuming I don't know any particular theorems regarding the uniqueness proof. My apologies if this is really trivial. I am not looking for an answer for this problem, but simply for a hint. Thanks.","The ODE is the following: I need to prove that ODE is well-posed and so far I have proven both the existence of the solution and the stability, but I am not sure how to approach the uniqueness problem, assuming I don't know any particular theorems regarding the uniqueness proof. My apologies if this is really trivial. I am not looking for an answer for this problem, but simply for a hint. Thanks.","\begin{cases}
u''(x) = 0,\\[6pt]
u(0) = a, u'(0) = b
\end{cases}
",['ordinary-differential-equations']
49,Solving $v-\eta v' = vv''+v'^2$,Solving,v-\eta v' = vv''+v'^2,"Question: How to solve the differential equation $$v - \eta \frac{dv}{d\eta} = v\frac{d^2v}{d\eta^2} + \bigg(\frac{dv}{d\eta}\bigg)^2$$ Attempt: This equation looks quite disgusting to me. I tried writing it in the form $$-\eta^2 \frac{d}{d\eta}\bigg(\frac{v}{\eta}\bigg) = \frac{d}{d\eta}\bigg( v\frac{dv}{d\eta}\bigg)$$ but that doesn't seem to help. Honestly, I am at a loss at how to tackle this equation (not even sure if there is an easy solution for this). Note: This differential equation actually arose as part of my attempt to find a similarity solution for the PDE $$\frac{\partial u}{\partial t} = \frac{\partial}{\partial x}\bigg(u\frac{\partial u}{\partial x}\bigg)$$ Letting $u(x,t) = t^a v(\eta)$ where $\eta = x/t^b$ and $a,b$ are constants to be specified later on, we get \begin{align} & \frac{\partial u}{\partial t} = \frac{\partial}{\partial x}\bigg(u\frac{\partial u}{\partial x}\bigg)\\ \implies & \frac{\partial u}{\partial t} = u\frac{\partial ^2u}{\partial x^2} + \bigg(\frac{\partial u}{\partial x}\bigg)^2 \\ \implies & at^{a - 1}v - bxt^{a-b-1}v' = t^{2a-2b}vv'' + t^{2a-2b} v'^2 \\ \implies & at^{a - 1}v - b\eta t^{a-1}v' = t^{2a-2b}vv'' + t^{2a-2b} v'^2 \end{align} So we need $a=b=1$ in order for this to be a similarity solution. The equation thus becomes $$v - \eta \frac{dv}{d\eta} = v\frac{d^2v}{d\eta^2} + \bigg(\frac{dv}{d\eta}\bigg)^2$$ which I am unable to solve.","Question: How to solve the differential equation Attempt: This equation looks quite disgusting to me. I tried writing it in the form but that doesn't seem to help. Honestly, I am at a loss at how to tackle this equation (not even sure if there is an easy solution for this). Note: This differential equation actually arose as part of my attempt to find a similarity solution for the PDE Letting where and are constants to be specified later on, we get So we need in order for this to be a similarity solution. The equation thus becomes which I am unable to solve.","v - \eta \frac{dv}{d\eta} = v\frac{d^2v}{d\eta^2} + \bigg(\frac{dv}{d\eta}\bigg)^2 -\eta^2 \frac{d}{d\eta}\bigg(\frac{v}{\eta}\bigg) = \frac{d}{d\eta}\bigg( v\frac{dv}{d\eta}\bigg) \frac{\partial u}{\partial t} = \frac{\partial}{\partial x}\bigg(u\frac{\partial u}{\partial x}\bigg) u(x,t) = t^a v(\eta) \eta = x/t^b a,b \begin{align}
& \frac{\partial u}{\partial t} = \frac{\partial}{\partial x}\bigg(u\frac{\partial u}{\partial x}\bigg)\\
\implies & \frac{\partial u}{\partial t} = u\frac{\partial ^2u}{\partial x^2} + \bigg(\frac{\partial u}{\partial x}\bigg)^2 \\
\implies & at^{a - 1}v - bxt^{a-b-1}v' = t^{2a-2b}vv'' + t^{2a-2b} v'^2 \\
\implies & at^{a - 1}v - b\eta t^{a-1}v' = t^{2a-2b}vv'' + t^{2a-2b} v'^2
\end{align} a=b=1 v - \eta \frac{dv}{d\eta} = v\frac{d^2v}{d\eta^2} + \bigg(\frac{dv}{d\eta}\bigg)^2","['ordinary-differential-equations', 'partial-differential-equations']"
50,Discretization of second order nonlinear ODE using finite difference approximation not correct,Discretization of second order nonlinear ODE using finite difference approximation not correct,,"I have the differential equation $$y'' + x(y^2)' - 2y^2 = g(x) \Longleftrightarrow y'' + x2yy'-2y^2 = g(x).$$ Using finite-difference approximations $$y''(x_m) \approx \frac{Y_{m-1} - 2Y_m + Y_{m+1}}{\Delta x^2},$$ $$y'(x_m) \approx \frac{Y_{m+1} - Y_{m-1}}{2\Delta x},$$ $$y(x_m) \approx Y_m,$$ I get $$\frac{Y_{m-1} - 2Y_m + Y_{m+1}}{\Delta x^2} + \frac{x_m}{\Delta x}Y_m(Y_{m+1}-Y_{m-1}) - 2Y_m^2 = g(x_m).$$ However, the answer is supposed to be Why is the second term in my answer wrong?","I have the differential equation Using finite-difference approximations I get However, the answer is supposed to be Why is the second term in my answer wrong?","y'' + x(y^2)' - 2y^2 = g(x) \Longleftrightarrow y'' + x2yy'-2y^2 = g(x). y''(x_m) \approx \frac{Y_{m-1} - 2Y_m + Y_{m+1}}{\Delta x^2}, y'(x_m) \approx \frac{Y_{m+1} - Y_{m-1}}{2\Delta x}, y(x_m) \approx Y_m, \frac{Y_{m-1} - 2Y_m + Y_{m+1}}{\Delta x^2} + \frac{x_m}{\Delta x}Y_m(Y_{m+1}-Y_{m-1}) - 2Y_m^2 = g(x_m).","['ordinary-differential-equations', 'numerical-methods', 'nonlinear-system', 'finite-differences', 'finite-difference-methods']"
51,using Poincaré-Bendixon to prove periodic solution existence,using Poincaré-Bendixon to prove periodic solution existence,,I got the system: $$\dot{x} = x-y-y^3-2x(x^2+y^2)$$ $$\dot{y}= x+y-2y(x^2+y^2)$$ And it's given that the origin is the only fixed point.  I've converted it to Polar using $\dot{r}r=\dot{x}x+\dot{y}y$ and ended up with: $$r\dot{r}=r^2-2r^3-r^4\cos\theta \sin^3\theta $$ Which I have simplified to the following but I do not trust my trig within this. $$\dot{r}=r-2r^2-\frac{r^3}{4}(\sin2\theta-\frac{1}{2}\sin4\theta)$$ I'm not very sure if this was the right way to go because when it comes to classifying $\dot{r}$ now I have to deal with $\sin2\theta$ and $\sin4\theta$ . So I guess my question right now is did I end up with the correct $\dot{r}$ ? If yes how do I end up trapping the region in this situation? I know that I have to check for when $\dot{r}>0$ for the outward flow and $\dot{r}<0$ for the inward flow. But I do not know how to inspect that with both $\sin{2\theta}$ and $\sin{4\theta}$ present at the same time. My brain right now is a scattered mess and I do not trust anything that comes out of it so I have resorted to share this with you and hopefully someone can put my mind to rest and let me know where I am going wrong because I have tried to solve this question 4 times now and every time I get a different $\dot{r}$ .,I got the system: And it's given that the origin is the only fixed point.  I've converted it to Polar using and ended up with: Which I have simplified to the following but I do not trust my trig within this. I'm not very sure if this was the right way to go because when it comes to classifying now I have to deal with and . So I guess my question right now is did I end up with the correct ? If yes how do I end up trapping the region in this situation? I know that I have to check for when for the outward flow and for the inward flow. But I do not know how to inspect that with both and present at the same time. My brain right now is a scattered mess and I do not trust anything that comes out of it so I have resorted to share this with you and hopefully someone can put my mind to rest and let me know where I am going wrong because I have tried to solve this question 4 times now and every time I get a different .,\dot{x} = x-y-y^3-2x(x^2+y^2) \dot{y}= x+y-2y(x^2+y^2) \dot{r}r=\dot{x}x+\dot{y}y r\dot{r}=r^2-2r^3-r^4\cos\theta \sin^3\theta  \dot{r}=r-2r^2-\frac{r^3}{4}(\sin2\theta-\frac{1}{2}\sin4\theta) \dot{r} \sin2\theta \sin4\theta \dot{r} \dot{r}>0 \dot{r}<0 \sin{2\theta} \sin{4\theta} \dot{r},"['ordinary-differential-equations', 'systems-of-equations']"
52,Does this velocity field have a potential?,Does this velocity field have a potential?,,"Let $\Psi=x-\frac{x^3y}{2}$ be the stream function . Then, by definition: $$ v_x=-\frac{\partial \Psi}{\partial y}, \, v_y=-\frac{\partial \Psi}{\partial x} $$ To determine whether this field have a velocity potential : $$ -\frac{\partial \Phi}{\partial x}=v_x, \, -\frac{\partial \Phi}{\partial y}=v_y $$ Solution: \begin{align*} &\Phi (x,y)= -\frac{x^4}{8}+f(y) \\  &\Phi (x,y)=\frac{3x^2y^2}{4}-y+g(x) \end{align*} Does the fact that $x,y$ are not separated ensures that $\Phi(x,y)$ does not exist and the fluid is viscid ?","Let be the stream function . Then, by definition: To determine whether this field have a velocity potential : Solution: Does the fact that are not separated ensures that does not exist and the fluid is viscid ?","\Psi=x-\frac{x^3y}{2} 
v_x=-\frac{\partial \Psi}{\partial y}, \, v_y=-\frac{\partial \Psi}{\partial x}
 
-\frac{\partial \Phi}{\partial x}=v_x, \, -\frac{\partial \Phi}{\partial y}=v_y
 \begin{align*}
&\Phi (x,y)= -\frac{x^4}{8}+f(y) \\
 &\Phi (x,y)=\frac{3x^2y^2}{4}-y+g(x)
\end{align*} x,y \Phi(x,y)","['ordinary-differential-equations', 'fluid-dynamics']"
53,Finding general solution to DE subject to initial condition,Finding general solution to DE subject to initial condition,,How do we solve the following Differential Equation? $$2 x''' + xx'' =0$$ Subject to conditions: $$ x(0)=0$$ $$ x'(0)=0$$ $$ x'(\infty)=1$$ Is there any numerical method to solve it or some general method??,How do we solve the following Differential Equation? Subject to conditions: Is there any numerical method to solve it or some general method??,2 x''' + xx'' =0  x(0)=0  x'(0)=0  x'(\infty)=1,"['ordinary-differential-equations', 'numerical-methods', 'numerical-calculus']"
54,Find the integrating factor and solve,Find the integrating factor and solve,,"Find an integrating factor and solve $(2x^2y + x)\,dy + (xy^2 + y)\,dx = 0$ I checked if it was exact, which it wasn't. Then I found $M/Y$ to be $xy + 1$ $N/Y$ to be $2xy + 1,$ but when I tried to put it in the form of $n N/X - mM/Y$ I got $-2xy,$ which didn't really tell me much about the value of $n$ and $m.$ So I tried over by multiplying the original equation by $x^ny^m$ and didn't get two linear equations at the end but two equations, which still had $xy$ terms and am stuck now. Any help would be appreciated.","Find an integrating factor and solve I checked if it was exact, which it wasn't. Then I found to be to be but when I tried to put it in the form of I got which didn't really tell me much about the value of and So I tried over by multiplying the original equation by and didn't get two linear equations at the end but two equations, which still had terms and am stuck now. Any help would be appreciated.","(2x^2y + x)\,dy + (xy^2 + y)\,dx = 0 M/Y xy + 1 N/Y 2xy + 1, n N/X - mM/Y -2xy, n m. x^ny^m xy",['ordinary-differential-equations']
55,Second order ODE problem with a series solution,Second order ODE problem with a series solution,,"I'm trying to obtain an analytical solution to the following ODE: $$-\epsilon x y+\left(\epsilon R-x-\epsilon x^2\right)y'+\left(R-x^2\right)y''=0$$ The only method that would make sense for me is the series method where I define $$y=\sum_{n=0}^\infty a_n x^n$$ and try to obtain a recurrence relation. If each part of the ODE is written separately we obtain: $$-\epsilon xy = \epsilon \sum_{n=0}^{\infty}a_nx^{n+1}$$ $$\left(\epsilon R-x-\epsilon x^2\right)y'=\sum_{n=1}^{\infty}n a_n x^{n-1}-\sum_{n=1}^{\infty}na_nx^n-\epsilon \sum_{n=1}^{\infty}na_nx^{n+1}$$ $$\left(R-x^2\right)y''=R\sum_{n=2}^{\infty}n(n-1)a_nx^{n-2}-\sum_{n=2}^{\infty}n(n-1)a_nx^n$$ Each time I'm trying to work out the equation I reach a dead end in terms of the indexes. Is it possible to reduce this problem to a recurrence relation problem? If not, is this equation solvable analytically?","I'm trying to obtain an analytical solution to the following ODE: The only method that would make sense for me is the series method where I define and try to obtain a recurrence relation. If each part of the ODE is written separately we obtain: Each time I'm trying to work out the equation I reach a dead end in terms of the indexes. Is it possible to reduce this problem to a recurrence relation problem? If not, is this equation solvable analytically?",-\epsilon x y+\left(\epsilon R-x-\epsilon x^2\right)y'+\left(R-x^2\right)y''=0 y=\sum_{n=0}^\infty a_n x^n -\epsilon xy = \epsilon \sum_{n=0}^{\infty}a_nx^{n+1} \left(\epsilon R-x-\epsilon x^2\right)y'=\sum_{n=1}^{\infty}n a_n x^{n-1}-\sum_{n=1}^{\infty}na_nx^n-\epsilon \sum_{n=1}^{\infty}na_nx^{n+1} \left(R-x^2\right)y''=R\sum_{n=2}^{\infty}n(n-1)a_nx^{n-2}-\sum_{n=2}^{\infty}n(n-1)a_nx^n,"['ordinary-differential-equations', 'recurrence-relations']"
56,Solving the nonlinear differential equation $ m \ddot x +\alpha x + \beta x^3 = 0$,Solving the nonlinear differential equation, m \ddot x +\alpha x + \beta x^3 = 0,"As the header says: I want to solve the differential equation $ m \ddot x +\alpha x + \beta x^3 = 0$ , with initial conditions $x(0) = -x_0$ , $\dot x(0)=0$ . It comes up in the solution to the equations of motion of the so-called undamped duffing oscillator, an undamped oscillator driven by nonlinear force $-\alpha x - \beta x^3$ . My research has shown that the solution involves elliptic integrals, which I have never seen before. Here is my approach so far: I use conservation of energy. The total Energy should be $E_{tot} = T + V = \frac{1}{2}m \dot x^2 +\alpha \frac{x^2}{2}+ \beta \frac{x^4}{4} = E_{t= 0} = \alpha \frac{x_0^2}{2}+ \beta \frac{x_0^4}{4}  $ . Now I would transfrom this equation into $\dot x = \sqrt{\frac{2}{m}(\alpha \frac{x^2-x_0^2}{2}+ \beta \frac{x_0^4-x^4}{4})}$ and then obtain by seperation of variables $dt = \frac{dx}{\sqrt{\frac{2}{m}(\alpha \frac{x^2-x_0^2}{2}+ \beta \frac{x_0^4-x^4}{4})}}$ . By integrating both sides, I'm guessing the integral on the right $$\int \frac{dx}{\sqrt{\frac{2}{m}(\alpha \frac{x^2-x_0^2}{2}+ \beta \frac{x_0^4-x^4}{4})}}$$ is the elliptic integral. Is my reasoning correct so far? And if yes, how do you solve (analytically) the integral?","As the header says: I want to solve the differential equation , with initial conditions , . It comes up in the solution to the equations of motion of the so-called undamped duffing oscillator, an undamped oscillator driven by nonlinear force . My research has shown that the solution involves elliptic integrals, which I have never seen before. Here is my approach so far: I use conservation of energy. The total Energy should be . Now I would transfrom this equation into and then obtain by seperation of variables . By integrating both sides, I'm guessing the integral on the right is the elliptic integral. Is my reasoning correct so far? And if yes, how do you solve (analytically) the integral?", m \ddot x +\alpha x + \beta x^3 = 0 x(0) = -x_0 \dot x(0)=0 -\alpha x - \beta x^3 E_{tot} = T + V = \frac{1}{2}m \dot x^2 +\alpha \frac{x^2}{2}+ \beta \frac{x^4}{4} = E_{t= 0} = \alpha \frac{x_0^2}{2}+ \beta \frac{x_0^4}{4}   \dot x = \sqrt{\frac{2}{m}(\alpha \frac{x^2-x_0^2}{2}+ \beta \frac{x_0^4-x^4}{4})} dt = \frac{dx}{\sqrt{\frac{2}{m}(\alpha \frac{x^2-x_0^2}{2}+ \beta \frac{x_0^4-x^4}{4})}} \int \frac{dx}{\sqrt{\frac{2}{m}(\alpha \frac{x^2-x_0^2}{2}+ \beta \frac{x_0^4-x^4}{4})}},"['ordinary-differential-equations', 'physics', 'nonlinear-system', 'elliptic-integrals']"
57,"Differential equation with ""backwards product rule"".","Differential equation with ""backwards product rule"".",,"If we have the following differential equation, ( $h,f$ known, $y$ unknown): $$f'(x)y(x) + f(x)y'(x) = h(x)$$ it would be easy, since we could spot the derivative for a product: $$(f(x)y(x))' = h(x)$$ and conclude $$y(x) = \frac{1}{f(x)}\left(C + \int h(x) dx\right)$$ But what if we have it the ""other way around"", like this? $$f(x)y(x) + f'(x)y'(x) = h(x)$$","If we have the following differential equation, ( known, unknown): it would be easy, since we could spot the derivative for a product: and conclude But what if we have it the ""other way around"", like this?","h,f y f'(x)y(x) + f(x)y'(x) = h(x) (f(x)y(x))' = h(x) y(x) = \frac{1}{f(x)}\left(C + \int h(x) dx\right) f(x)y(x) + f'(x)y'(x) = h(x)","['real-analysis', 'calculus', 'ordinary-differential-equations', 'reference-request', 'soft-question']"
58,Does $y'=|y|^a$ have any global solutions?,Does  have any global solutions?,y'=|y|^a,"Assume the differential equation $$ y'=|y|^a $$ My intuition tells me that since it involves an absolute value, there might not be any solutions defined everywhere, except for the case $a=0$ , where $y(x)=x+c$ . To show this, let $$ f(y)=|y|^a$$ $\bullet\,$ For $a<0$ : $f$ is not defined for $y=0$ plus it's not bounded $\bullet\,$ For $a=0$ : $$y'=1 \iff y(x)=x+c, \quad x \in \mathbb{R}$$ $\bullet\,$ For $a>0$ : $f$ is defined $\forall y \in \mathbb{R}$ , but it's not bounded Can we thus conclude that the only global solution of $y'=|y|^a$ is $y(x)=x+c$ ?","Assume the differential equation My intuition tells me that since it involves an absolute value, there might not be any solutions defined everywhere, except for the case , where . To show this, let For : is not defined for plus it's not bounded For : For : is defined , but it's not bounded Can we thus conclude that the only global solution of is ?","
y'=|y|^a
 a=0 y(x)=x+c 
f(y)=|y|^a \bullet\, a<0 f y=0 \bullet\, a=0 y'=1 \iff y(x)=x+c, \quad x \in \mathbb{R} \bullet\, a>0 f \forall y \in \mathbb{R} y'=|y|^a y(x)=x+c","['ordinary-differential-equations', 'dynamical-systems', 'stability-in-odes', 'initial-value-problems']"
59,Finding the roots of a characteristic polynomial,Finding the roots of a characteristic polynomial,,"Main aim is to find the lowest order equation with the solution: $$y(x)= 2 \cosh(x) + 3 e^{-2x} \sin(x)$$ Now, I am trying to find the roots to form the characteristic polynomial from which I get the lowest order equation. However, am stuck with the second expression as the first can be easily expressed as $e^x - e^{-x}$ so I deduce $\lambda_{1}=1,\lambda_{1} = -1   $ but the other expression I am not quite sure whether it is $-2\pm i  $ or something else as there is an exponential and a trigonometric function at the same time ? Any advice greatly appreciated!","Main aim is to find the lowest order equation with the solution: Now, I am trying to find the roots to form the characteristic polynomial from which I get the lowest order equation. However, am stuck with the second expression as the first can be easily expressed as so I deduce but the other expression I am not quite sure whether it is or something else as there is an exponential and a trigonometric function at the same time ? Any advice greatly appreciated!","y(x)= 2 \cosh(x) + 3 e^{-2x} \sin(x) e^x - e^{-x} \lambda_{1}=1,\lambda_{1} = -1    -2\pm i  ","['ordinary-differential-equations', 'reduction-of-order-ode']"
60,"differential Eq, how do I make it Exact? (using an integrating factor?)","differential Eq, how do I make it Exact? (using an integrating factor?)",,"$$ye^xdx-(4y+3e^x)dy=0$$ $$(\frac{\partial M}{\partial y} - \frac{\partial N}{\partial x}) * \frac{1}{M}$$ $$e^{\int(4/y)}=y^4 $$ when multiplying $$y^4$$ though the problem still does not become exact? attempt (cant find my error) , this will not make it exact...? what am I doing wrong?","when multiplying though the problem still does not become exact? attempt (cant find my error) , this will not make it exact...? what am I doing wrong?",ye^xdx-(4y+3e^x)dy=0 (\frac{\partial M}{\partial y} - \frac{\partial N}{\partial x}) * \frac{1}{M} e^{\int(4/y)}=y^4  y^4,"['ordinary-differential-equations', 'integrating-factor']"
61,Does the formula $\frac{1}{D + a} f = \frac{1}{a}\left(f - \frac{1}{D + a} f'\right)$ have a name?,Does the formula  have a name?,\frac{1}{D + a} f = \frac{1}{a}\left(f - \frac{1}{D + a} f'\right),"Using integration by parts, we can show that: $$\frac{1}{D + a} f = \frac{1}{a}\left(f - \frac{1}{D + a} f'\right)$$ where $a$ is a real number, $D$ is differentiation, and $D+a$ is the corresponding linear differential operator. This formula is very helpful for computing $\frac{1}{D+a}$ applied to a polynomial, exponential, trigonometric or hyperbolic function. For example, to solve $$y' - 5y = x^7$$ rewrite it as $$(D-5)y = x^7$$ which is equivalent to $$y \in \frac{1}{D-5} x^7$$ which an be solved relatively painlessly using the above formula, which essentially manages your integration by parts for you and allows you to just focus on the algebra. Question. Is there a name for this formula?","Using integration by parts, we can show that: where is a real number, is differentiation, and is the corresponding linear differential operator. This formula is very helpful for computing applied to a polynomial, exponential, trigonometric or hyperbolic function. For example, to solve rewrite it as which is equivalent to which an be solved relatively painlessly using the above formula, which essentially manages your integration by parts for you and allows you to just focus on the algebra. Question. Is there a name for this formula?",\frac{1}{D + a} f = \frac{1}{a}\left(f - \frac{1}{D + a} f'\right) a D D+a \frac{1}{D+a} y' - 5y = x^7 (D-5)y = x^7 y \in \frac{1}{D-5} x^7,"['calculus', 'ordinary-differential-equations', 'power-series', 'differential-operators']"
62,Breakdown of Analytical Solution to 4th order ODE,Breakdown of Analytical Solution to 4th order ODE,,"The Problem: I have the 4th order Ordinary Differential Equation $$ \frac{\text{d}^4\theta}{\text{d}\eta^4} +R(\theta-\theta_*)=0 $$ in the interval $0\le\eta\le1$ , subject to the boundary conditions $$ \eta=0: \frac{\text{d}\theta}{\text{d}\eta}=-1 ;         \frac{\text{d}^2\theta}{\text{d}\eta^2}=0 $$ $$ \eta=1: \frac{\text{d}\theta}{\text{d}\eta}=0 ;         \frac{\text{d}^2\theta}{\text{d}\eta^2}=0 $$ and where $\theta_*$ is to be determined such that the clamping constraint $$\theta(\eta=0)=0$$ is satisfied. Skipping details, it can be shown that the solution to the differential equation is $$ \theta=\theta_* + e^{P(\eta-1)}(A\cos P\eta+B\sin P\eta) +e^{-P\eta}(C\cos P\eta+D\sin P\eta) $$ where $P=\frac{R^\frac{1}{4}}{\sqrt{2}}$ and (skipping details again) the constants $A,B,C,D$ and $\theta_*$ can be determined from the boundary conditions and constraint. So far, so good. The issue: The solution works beautifully, until $R$ approaches $10^7$ whereupon it breaks down due to what I believe is the stiffness of the differential equation - the difference between the largest and smallest roots of the characteristic equation is of the order of $2P$ ~ $R^\frac{1}{4}$ . This is also apparent from the original differential equation itself, where as $R$ becomes very large $\theta \rightarrow \theta_*$ which tends to violate the Neumann boundary condition $\frac{\text{d}\theta}{\text{d}\eta}(\eta=0)=-1$ . What I find very odd however, is that the breakdown in the analytical solution is manifested not at $\eta=0$ , where the Neumann BC is actually satisfied very well, but by blowing up in the vicinity of $\eta=1$ . This is evident in the graphic below: My Question Given that the analytical solution tends to break down at large $R$ , how much confidence can I place in the computed values in the vicinity of $\eta=0$ . The Neumann condition at $\eta=0$ certainly seems to be honoured for $R=10^7$ , but I'm a bit circumspect about the correctness of the peak value in the second derivative (right plot in the graphic above). Any advice? Thanks in advance. Note that in practice, I clamp the value of $\eta$ used to compute $\theta$ and its derivatives at $\eta=1.1-0.1\log_{10}R$ , for $R\ge 10^6$","The Problem: I have the 4th order Ordinary Differential Equation in the interval , subject to the boundary conditions and where is to be determined such that the clamping constraint is satisfied. Skipping details, it can be shown that the solution to the differential equation is where and (skipping details again) the constants and can be determined from the boundary conditions and constraint. So far, so good. The issue: The solution works beautifully, until approaches whereupon it breaks down due to what I believe is the stiffness of the differential equation - the difference between the largest and smallest roots of the characteristic equation is of the order of ~ . This is also apparent from the original differential equation itself, where as becomes very large which tends to violate the Neumann boundary condition . What I find very odd however, is that the breakdown in the analytical solution is manifested not at , where the Neumann BC is actually satisfied very well, but by blowing up in the vicinity of . This is evident in the graphic below: My Question Given that the analytical solution tends to break down at large , how much confidence can I place in the computed values in the vicinity of . The Neumann condition at certainly seems to be honoured for , but I'm a bit circumspect about the correctness of the peak value in the second derivative (right plot in the graphic above). Any advice? Thanks in advance. Note that in practice, I clamp the value of used to compute and its derivatives at , for","
\frac{\text{d}^4\theta}{\text{d}\eta^4}
+R(\theta-\theta_*)=0
 0\le\eta\le1 
\eta=0: \frac{\text{d}\theta}{\text{d}\eta}=-1 ;
        \frac{\text{d}^2\theta}{\text{d}\eta^2}=0
 
\eta=1: \frac{\text{d}\theta}{\text{d}\eta}=0 ;
        \frac{\text{d}^2\theta}{\text{d}\eta^2}=0
 \theta_* \theta(\eta=0)=0 
\theta=\theta_* + e^{P(\eta-1)}(A\cos P\eta+B\sin P\eta)
+e^{-P\eta}(C\cos P\eta+D\sin P\eta)
 P=\frac{R^\frac{1}{4}}{\sqrt{2}} A,B,C,D \theta_* R 10^7 2P R^\frac{1}{4} R \theta \rightarrow \theta_* \frac{\text{d}\theta}{\text{d}\eta}(\eta=0)=-1 \eta=0 \eta=1 R \eta=0 \eta=0 R=10^7 \eta \theta \eta=1.1-0.1\log_{10}R R\ge 10^6",['ordinary-differential-equations']
63,Using variation of parameters to solve $y''-25y=x$,Using variation of parameters to solve,y''-25y=x,"I keep trying to solve this but I end up needing to do integration by parts like 3 or 4 times. My only question is, is that going to be the only way to do this? If so it will literally take me hours. I don't need a solution, just a confirmation that if the requirement is to use variation of parameters, then will I need to take integrals that need to be done by IBP? Thank you and sorry if this is not a good question.","I keep trying to solve this but I end up needing to do integration by parts like 3 or 4 times. My only question is, is that going to be the only way to do this? If so it will literally take me hours. I don't need a solution, just a confirmation that if the requirement is to use variation of parameters, then will I need to take integrals that need to be done by IBP? Thank you and sorry if this is not a good question.",,['ordinary-differential-equations']
64,Dynamical systems and equilibrium points,Dynamical systems and equilibrium points,,"Recently I have been trying to understand dynamical systems and I came up with   the following question: Consider the system $y' =f(y)$ , $t\ge0$ with only two equilibrium points $0, 1$ and $f(y)\le0$ in $[0,1]$ , $f'(0)\lt0$ , $f'(1)\gt0$ . Is there any solution $y$ with $y(0)\in(0,1)$ such that $lim_{t\to \infty}y$ is not $0$ ? Remark:    As $y$ is decreasing, it will have an infimum $s$ , $s\ge0$ . If $s\ne0$ then it cannot be an equilibrium point.... Thanks in advance.","Recently I have been trying to understand dynamical systems and I came up with   the following question: Consider the system , with only two equilibrium points and in , , . Is there any solution with such that is not ? Remark:    As is decreasing, it will have an infimum , . If then it cannot be an equilibrium point.... Thanks in advance.","y' =f(y) t\ge0 0, 1 f(y)\le0 [0,1] f'(0)\lt0 f'(1)\gt0 y y(0)\in(0,1) lim_{t\to \infty}y 0 y s s\ge0 s\ne0","['ordinary-differential-equations', 'dynamical-systems']"
65,State-space representation of a nonlinear MIMO system,State-space representation of a nonlinear MIMO system,,"Question: Obtain a state-space representation of nonlinear multiple-input multiple-output (MIMO) system: $$\dddot{y}_1 + 2\dot{y_1} + 3y_2 + 2 = u_1 y_2 \tag{1}$$ $$\ddot{y}_2 - 2 \dot{y}_2 + \dot{y}_1^3 + y_2 + y_1 = (u_2 - u_3)y_1 \tag{2}$$ I find it difficult solving the above equations. I have the following queries: What do I do with $(dy_1/dt)^3$ ? How do I represent it in state space model? Are $u_1, u_2$ and $u_3$ control inputs or just constants (coefficients of $y_1$ and $y_2$ )? Does the constant $2$ in equation come in $\mathbf B$ (i.e., $\mathbf A x + \mathbf B u)$ ? Do I have to convert these equations into linear equations?","Question: Obtain a state-space representation of nonlinear multiple-input multiple-output (MIMO) system: I find it difficult solving the above equations. I have the following queries: What do I do with ? How do I represent it in state space model? Are and control inputs or just constants (coefficients of and )? Does the constant in equation come in (i.e., ? Do I have to convert these equations into linear equations?","\dddot{y}_1 + 2\dot{y_1} + 3y_2 + 2 = u_1 y_2 \tag{1} \ddot{y}_2 - 2 \dot{y}_2 + \dot{y}_1^3 + y_2 + y_1 = (u_2 - u_3)y_1 \tag{2} (dy_1/dt)^3 u_1, u_2 u_3 y_1 y_2 2 \mathbf B \mathbf A x + \mathbf B u)","['ordinary-differential-equations', 'control-theory', 'nonlinear-system']"
66,Finding the geodesic equations on $S^2$,Finding the geodesic equations on,S^2,"The metric on $S^2$ is given as $\bar{g} = ds^2 = d\theta^2 + \sin^2\theta d\phi^2$ where $x^1 = \theta$ and $x^2 = \phi$ . The only non-zero components of the Christoffel symbols are $\Gamma^{\ 1}_{ \ 2 \ 2}$ and $$\Gamma^{\ 2}_{ \ 2 \ 1} =  \Gamma^{\ 2}_{ \ 1 \ 2} =  \cot\theta$$ Write down the geodesic equations for the co-ordinates $\theta(t)$ and $\phi(t$ ) I know that in local co-ordinates on any smooth manifold $M$ the geodesic equation is given by $$\frac{d^2x^a}{dt^2} +  \Gamma^{\ a}_{ \ b \ c}\frac{dx^b}{dt}\frac{dx^c}{dt} = 0$$ on $S^2$ then substituting for $x^1$ and $x^2$ in local co-ordinates we get $$\frac{d^2\theta}{dt^2} -\sin\theta\cos\theta \left(\frac{d\phi}{dt}\right) + \frac{d^2\phi}{dt^2} + 2\cot\theta \frac{d\theta}{dt}\frac{d\phi}{dt} = 0$$ rearranging for $\frac{d^2\theta}{dt}$ we get $$\frac{d^2\theta}{dt^2} =\sin\theta\cos\theta \left(\frac{d\phi}{dt}\right) - \frac{d^2\phi}{dt^2} - 2\cot\theta \frac{d\theta}{dt}\frac{d\phi}{dt} $$ and similarly we can rearrange and solve for $\frac{d^2\phi}{dt}$ . My question is, what exactly do the authors mean by ""write down the geodesic equations for the co-ordinates $\theta(t)$ and $\phi(t)$ , do I need to solve the above differential equation and then obtain $\theta(t)$ ? If so how can I go about doing that, what's the best approach?","The metric on is given as where and . The only non-zero components of the Christoffel symbols are and Write down the geodesic equations for the co-ordinates and ) I know that in local co-ordinates on any smooth manifold the geodesic equation is given by on then substituting for and in local co-ordinates we get rearranging for we get and similarly we can rearrange and solve for . My question is, what exactly do the authors mean by ""write down the geodesic equations for the co-ordinates and , do I need to solve the above differential equation and then obtain ? If so how can I go about doing that, what's the best approach?",S^2 \bar{g} = ds^2 = d\theta^2 + \sin^2\theta d\phi^2 x^1 = \theta x^2 = \phi \Gamma^{\ 1}_{ \ 2 \ 2} \Gamma^{\ 2}_{ \ 2 \ 1} =  \Gamma^{\ 2}_{ \ 1 \ 2} =  \cot\theta \theta(t) \phi(t M \frac{d^2x^a}{dt^2} +  \Gamma^{\ a}_{ \ b \ c}\frac{dx^b}{dt}\frac{dx^c}{dt} = 0 S^2 x^1 x^2 \frac{d^2\theta}{dt^2} -\sin\theta\cos\theta \left(\frac{d\phi}{dt}\right) + \frac{d^2\phi}{dt^2} + 2\cot\theta \frac{d\theta}{dt}\frac{d\phi}{dt} = 0 \frac{d^2\theta}{dt} \frac{d^2\theta}{dt^2} =\sin\theta\cos\theta \left(\frac{d\phi}{dt}\right) - \frac{d^2\phi}{dt^2} - 2\cot\theta \frac{d\theta}{dt}\frac{d\phi}{dt}  \frac{d^2\phi}{dt} \theta(t) \phi(t) \theta(t),"['ordinary-differential-equations', 'differential-geometry', 'riemannian-geometry']"
67,Motion of an object that always has an acceleration perpendicular to its velocity,Motion of an object that always has an acceleration perpendicular to its velocity,,Consider an object whose position vector $x$ (changes with time) satisfies the condition $$ \dot{x}\cdot\ddot{x}=0 $$ i.e. the object is always accelerating in the direction perpendicular to its direction of motion. How can I solve the DE and find an equation relating $x$ and $t$ (the time)? Is it wrong to say that the speed should be constant?,Consider an object whose position vector (changes with time) satisfies the condition i.e. the object is always accelerating in the direction perpendicular to its direction of motion. How can I solve the DE and find an equation relating and (the time)? Is it wrong to say that the speed should be constant?,"x 
\dot{x}\cdot\ddot{x}=0
 x t","['ordinary-differential-equations', 'vector-analysis', 'physics']"
68,solve this 1st order linear equation,solve this 1st order linear equation,,$$(x+3)^2\frac{dy}{dx}=6-12y-4xy=6-y(12+4x)$$ a. Write it in standard form. $$\frac{dy}{dx}+\frac{12+4x}{(x+3)^2}y=\frac6{(x+3)^2}$$ b. What is the integrating factor? $$\frac{12+4x}{(x+3)^2} = \frac14x+\frac34 \implies$$ $$IF=e^{\int{\frac14x+\frac34}}=e^{\frac18x^2+\frac34x}$$ c. Integrate the DE subject to $y(0)=1$ . $$e^{\frac18x^2+\frac34x}\frac{dy}{dx}+ye^{\frac18x^2+\frac34x}(\frac14x+\frac34)=\frac{6e^{\frac18x^2+\frac34x}}{(x+3)^2} \implies$$ $$ye^{\frac18x^2+\frac34x}=\int{\frac{6e^{\frac18x^2+\frac34x}}{(x+3)^2}}+c$$ I have done this problem a few times and now getting kind of stuck. Please check my standard form and integrating factor. Right now if everything else is correct I cannot solve the integral. Any help appreciated.,a. Write it in standard form. b. What is the integrating factor? c. Integrate the DE subject to . I have done this problem a few times and now getting kind of stuck. Please check my standard form and integrating factor. Right now if everything else is correct I cannot solve the integral. Any help appreciated.,(x+3)^2\frac{dy}{dx}=6-12y-4xy=6-y(12+4x) \frac{dy}{dx}+\frac{12+4x}{(x+3)^2}y=\frac6{(x+3)^2} \frac{12+4x}{(x+3)^2} = \frac14x+\frac34 \implies IF=e^{\int{\frac14x+\frac34}}=e^{\frac18x^2+\frac34x} y(0)=1 e^{\frac18x^2+\frac34x}\frac{dy}{dx}+ye^{\frac18x^2+\frac34x}(\frac14x+\frac34)=\frac{6e^{\frac18x^2+\frac34x}}{(x+3)^2} \implies ye^{\frac18x^2+\frac34x}=\int{\frac{6e^{\frac18x^2+\frac34x}}{(x+3)^2}}+c,"['integration', 'ordinary-differential-equations']"
69,Second order non-linear ode - am I on the right path?,Second order non-linear ode - am I on the right path?,,"I've found this to be difficult to solve: $$ \frac{d^2 x }{dt^2} + (a x + b) \frac{dx}{dt} = 0 $$ I've done some reading, and I guess I could write this as: $$ \frac{d^2 x }{dt^2} +  b \frac{dx}{dt} + ax \frac{dx}{dt} = 0 $$ If I then treat $v(x) = \frac{dx}{dt}$ as an independent variable, I would get: $$ \frac{dv}{dt} + bv +  axv = 0 $$ This is sort of like a nonhomogenous equation. If I take the homogenous solution, I would get: $$ v(t) = A e^{-bt}$$ I think.... I'm not sure where to go from here though.","I've found this to be difficult to solve: $$ \frac{d^2 x }{dt^2} + (a x + b) \frac{dx}{dt} = 0 $$ I've done some reading, and I guess I could write this as: $$ \frac{d^2 x }{dt^2} +  b \frac{dx}{dt} + ax \frac{dx}{dt} = 0 $$ If I then treat $v(x) = \frac{dx}{dt}$ as an independent variable, I would get: $$ \frac{dv}{dt} + bv +  axv = 0 $$ This is sort of like a nonhomogenous equation. If I take the homogenous solution, I would get: $$ v(t) = A e^{-bt}$$ I think.... I'm not sure where to go from here though.",,['ordinary-differential-equations']
70,Equilibrium Solution in Solving a Linear ODE using an Integrating Factor,Equilibrium Solution in Solving a Linear ODE using an Integrating Factor,,"Problem I've stumbled upon this differential equation during the second week of my ODE class in university: $$ y' - \frac{2}{t+1}y = (t+1)^2$$ And I solved it using the exact procedure in the ""Attempt"" section below. I checked my work and indeed got the right answer, but as I was solving the problem, I was having difficulty discerning the domain of the function and the equilibrium solutions that arise in the midst of solving such a problem. I believe there are no equilibrium solutions to take into account in this case, but my main goal of asking this question is for the answerer to outline when to check for equilibrium solutions , how to go about doing it , and providing best practices for constraining both the dependent and independent variables, as well as constants found along the way. Attempt Here is my attempt at the solution: $$ y' - \frac{2}{t+1}y = (t+1)^2 $$ $ t \neq -1 $ is implicitly assumed. $$ \mu(t) = e^{\int p(t)dt} $$ $$ p(t) = -\frac{2}{t+1} $$ $$ \int p(t)dt = \int -\frac{2}{t+1}dt = -2ln|t+1|+C_1 $$ for $ C_1 \in \mathbb R $. $$ \mu(t) = e^{-2ln|t+1| + C_1} = e^{C_1}e^{ln|t+1|^{-2}} $$ Let $ C_2 = e^{C_1}$ for $ C_2 \in \mathbb R $, $ C_2 \gt 0 $. $$ \mu(t) = C_2 e^{ln(\frac{1}{(t+1)^2})} $$ $$ \mu(t) = C_2 \frac{1}{(t+1)^2} $$ Multiplying both sides by the integrating factor $ \mu(t) $, $$ C_2 \frac{1}{(t+1)^2} y' - C_2 \frac{1}{(t+1)^2} \frac{2}{(t+1)}y = C_2 \frac{1}{(t+1)^2} (t+1)^2 $$ $$ (t + 1)^{-2} y' - 2(t+1)^{-3}y = 1 $$ $$ ((t+1)^{-2}y)' = 1 $$ $$ (t+1)^{-2}y = \int 1 dt $$ $$ (t+1)^{-2}y = t + C_3 $$ for $ C_3 \in \mathbb R $. Dividing both sides by $ \mu(t) $ we get, $$ \frac{(t+1)^2}{C_2 (t+1)^2} y = \frac{(t+1)^2(t+C_3)}{C_2} $$ $$ y = (t+1)^2(t+C_3) $$ Notes I'd love the answerer to identify where to check for equilibrium cases in this situation, as well as answer the above bolded questions. I understand equilibrium solutions are to be checked when variables may be separated to solve a differential equation, but I'd love to know all the other cases and have that part be elaborated to me. Here's the direction field for $ y' = f(t,y) $: Thanks in advance!","Problem I've stumbled upon this differential equation during the second week of my ODE class in university: $$ y' - \frac{2}{t+1}y = (t+1)^2$$ And I solved it using the exact procedure in the ""Attempt"" section below. I checked my work and indeed got the right answer, but as I was solving the problem, I was having difficulty discerning the domain of the function and the equilibrium solutions that arise in the midst of solving such a problem. I believe there are no equilibrium solutions to take into account in this case, but my main goal of asking this question is for the answerer to outline when to check for equilibrium solutions , how to go about doing it , and providing best practices for constraining both the dependent and independent variables, as well as constants found along the way. Attempt Here is my attempt at the solution: $$ y' - \frac{2}{t+1}y = (t+1)^2 $$ $ t \neq -1 $ is implicitly assumed. $$ \mu(t) = e^{\int p(t)dt} $$ $$ p(t) = -\frac{2}{t+1} $$ $$ \int p(t)dt = \int -\frac{2}{t+1}dt = -2ln|t+1|+C_1 $$ for $ C_1 \in \mathbb R $. $$ \mu(t) = e^{-2ln|t+1| + C_1} = e^{C_1}e^{ln|t+1|^{-2}} $$ Let $ C_2 = e^{C_1}$ for $ C_2 \in \mathbb R $, $ C_2 \gt 0 $. $$ \mu(t) = C_2 e^{ln(\frac{1}{(t+1)^2})} $$ $$ \mu(t) = C_2 \frac{1}{(t+1)^2} $$ Multiplying both sides by the integrating factor $ \mu(t) $, $$ C_2 \frac{1}{(t+1)^2} y' - C_2 \frac{1}{(t+1)^2} \frac{2}{(t+1)}y = C_2 \frac{1}{(t+1)^2} (t+1)^2 $$ $$ (t + 1)^{-2} y' - 2(t+1)^{-3}y = 1 $$ $$ ((t+1)^{-2}y)' = 1 $$ $$ (t+1)^{-2}y = \int 1 dt $$ $$ (t+1)^{-2}y = t + C_3 $$ for $ C_3 \in \mathbb R $. Dividing both sides by $ \mu(t) $ we get, $$ \frac{(t+1)^2}{C_2 (t+1)^2} y = \frac{(t+1)^2(t+C_3)}{C_2} $$ $$ y = (t+1)^2(t+C_3) $$ Notes I'd love the answerer to identify where to check for equilibrium cases in this situation, as well as answer the above bolded questions. I understand equilibrium solutions are to be checked when variables may be separated to solve a differential equation, but I'd love to know all the other cases and have that part be elaborated to me. Here's the direction field for $ y' = f(t,y) $: Thanks in advance!",,"['integration', 'ordinary-differential-equations']"
71,Substituting $y^2$ in a differential equation,Substituting  in a differential equation,y^2,"I have the IVP: $$2yy'+5 = y^2 + 5x; y(0)=6.$$ In order to solve this, I have attempted to make the substitution $u = y^2 \implies \sqrt{u} = y$. However, I am not sure how to solve for $u'$, so I don't know how to proceed in the problem. I know that $\frac{du}{dx} = \frac{d(y^2)}{dx}$ but I'm not really sure what that means or how to deal with it.","I have the IVP: $$2yy'+5 = y^2 + 5x; y(0)=6.$$ In order to solve this, I have attempted to make the substitution $u = y^2 \implies \sqrt{u} = y$. However, I am not sure how to solve for $u'$, so I don't know how to proceed in the problem. I know that $\frac{du}{dx} = \frac{d(y^2)}{dx}$ but I'm not really sure what that means or how to deal with it.",,"['ordinary-differential-equations', 'derivatives']"
72,How can I solve $y'+\sin y'=x$?,How can I solve ?,y'+\sin y'=x,I have no idea how to start with this. I tried taking the derivative and making use of $\cos{y'}^2+\sin{y'}^2=1$ but it seems to get even more confusing. Of course we can replace $y'$ with $f$ since $y$ does not appear but that's as far as I can get.,I have no idea how to start with this. I tried taking the derivative and making use of $\cos{y'}^2+\sin{y'}^2=1$ but it seems to get even more confusing. Of course we can replace $y'$ with $f$ since $y$ does not appear but that's as far as I can get.,,['ordinary-differential-equations']
73,Differential Equation with Integration,Differential Equation with Integration,,"Function $f(x)$ is differentiable. Given further that \begin{eqnarray*} f’(x)+xf’(x-1) &=& 4 \\ \int_0^1 f(xt) dt + \int_0^x f(t-1)dt &=& x^3 +x^2 +2x \end{eqnarray*} Determine the function $f(x)$. $\textbf{Attempt}$ I know $\frac{d}{dx} \int_0^x f(t-1)dt = f(x-1)$, but I am confused about what’s $\frac{d}{dx} \int_0^1 f(xt) dt $ . Maybe I can do $ - \frac{d}{dx} \int_1^x f(xt) dt - \frac{d}{dx} \int_0^x f(xt) dt $ ?","Function $f(x)$ is differentiable. Given further that \begin{eqnarray*} f’(x)+xf’(x-1) &=& 4 \\ \int_0^1 f(xt) dt + \int_0^x f(t-1)dt &=& x^3 +x^2 +2x \end{eqnarray*} Determine the function $f(x)$. $\textbf{Attempt}$ I know $\frac{d}{dx} \int_0^x f(t-1)dt = f(x-1)$, but I am confused about what’s $\frac{d}{dx} \int_0^1 f(xt) dt $ . Maybe I can do $ - \frac{d}{dx} \int_1^x f(xt) dt - \frac{d}{dx} \int_0^x f(xt) dt $ ?",,"['calculus', 'ordinary-differential-equations']"
74,Is this differential equation solvable in MATLAB?,Is this differential equation solvable in MATLAB?,,"\begin{align}     r'' - r θ'^2 &= g \sinθ - (M/m)(g - y'') \\         r' + Rθ' + y' &= 0   \\       rθ'' + 2r'θ' + g \cosθ &= 0 \end{align} Sorry may I know how I can solve this with ode45? I am attempting to convert all three equations into 1st Order Coupled equations, but I can't seem to get the second equation into the correct substitution. Is it possible? Or do I have to use another ODE solver (which?) Edit: I attempted rob's solution, and have gotten the following code Taking M=3m, g=9.81, R=4 function dydt = odefun(t,y) dydt = zeros(9,1) dydt(1) = y(7) dydt(2) = y(8) dydt(3) = y(9) dydt(4) = sqrt((y(8)-9.81*sin(y(4))-3*9.81+3*y(9))/(2*y(1))) dydt(5) = -(9.81*cos(y(4))+y(5)*y(7))/(2*y(1)) dydt(6) = -y(2)-y(1)*4 end but received the following error message Not enough input arguments. Error in <filename> (line 3) dydt(1) = y(7) It seems matlab does not accept the code if I do not define (θ'')' = ___. Sorry if this is a dumb misunderstanding, I am still trying to figure out how MATLAB works (any resources to recommend?) I have also attempted function dydt = odefun(t,y) dydt = zeros(9,1) dydt(1) = y(7) dydt(2) = y(8) dydt(3) = y(9) dydt(4) = sqrt((y(8)-9.81*sin(y(4))-3*9.81+3*y(9))/(2*y(1))) dydt(5) = -(9.81*cos(y(4))+y(5)*y(7))/(2*y(1)) dydt(6) = -y(2)-y(1)*4 % radius here! dydt(4) = y(1) % are these 3 more lines correct logically, they seem to  dydt(5) = y(2) % let matlab run, but for now I am just getting constants dydt(6) = y(3) % for all solutions end is this the right code?","\begin{align}     r'' - r θ'^2 &= g \sinθ - (M/m)(g - y'') \\         r' + Rθ' + y' &= 0   \\       rθ'' + 2r'θ' + g \cosθ &= 0 \end{align} Sorry may I know how I can solve this with ode45? I am attempting to convert all three equations into 1st Order Coupled equations, but I can't seem to get the second equation into the correct substitution. Is it possible? Or do I have to use another ODE solver (which?) Edit: I attempted rob's solution, and have gotten the following code Taking M=3m, g=9.81, R=4 function dydt = odefun(t,y) dydt = zeros(9,1) dydt(1) = y(7) dydt(2) = y(8) dydt(3) = y(9) dydt(4) = sqrt((y(8)-9.81*sin(y(4))-3*9.81+3*y(9))/(2*y(1))) dydt(5) = -(9.81*cos(y(4))+y(5)*y(7))/(2*y(1)) dydt(6) = -y(2)-y(1)*4 end but received the following error message Not enough input arguments. Error in <filename> (line 3) dydt(1) = y(7) It seems matlab does not accept the code if I do not define (θ'')' = ___. Sorry if this is a dumb misunderstanding, I am still trying to figure out how MATLAB works (any resources to recommend?) I have also attempted function dydt = odefun(t,y) dydt = zeros(9,1) dydt(1) = y(7) dydt(2) = y(8) dydt(3) = y(9) dydt(4) = sqrt((y(8)-9.81*sin(y(4))-3*9.81+3*y(9))/(2*y(1))) dydt(5) = -(9.81*cos(y(4))+y(5)*y(7))/(2*y(1)) dydt(6) = -y(2)-y(1)*4 % radius here! dydt(4) = y(1) % are these 3 more lines correct logically, they seem to  dydt(5) = y(2) % let matlab run, but for now I am just getting constants dydt(6) = y(3) % for all solutions end is this the right code?",,['ordinary-differential-equations']
75,Solve $\frac{a^2}{x^2 f'(x)}-\log{{(1-f(x))}}=S^2 +1$,Solve,\frac{a^2}{x^2 f'(x)}-\log{{(1-f(x))}}=S^2 +1,"Solve   $$  \frac{a^2}{x^2 f'(x)}-\log{{(1-f(x))}}=S^2 +1,  $$ for $x\geq 1$, $f(x)<1$   where $a,S\in \mathbb{R}$ and $f'(x)=\frac{d f(x)}{dx}$. My effort: It is equivalent to  $$  {a^2}-(x^2 f'(x))\log{{(1-f(x))}}-(S^2 +1)(x^2 f'(x))=0,  $$ or $$  {a^2}- f'(x)x^2(\log{{(1-f(x))}}-S^2 +1)=0,  $$ I am not sure what to do with the $\log(1-f(x))$. Any idea?","Solve   $$  \frac{a^2}{x^2 f'(x)}-\log{{(1-f(x))}}=S^2 +1,  $$ for $x\geq 1$, $f(x)<1$   where $a,S\in \mathbb{R}$ and $f'(x)=\frac{d f(x)}{dx}$. My effort: It is equivalent to  $$  {a^2}-(x^2 f'(x))\log{{(1-f(x))}}-(S^2 +1)(x^2 f'(x))=0,  $$ or $$  {a^2}- f'(x)x^2(\log{{(1-f(x))}}-S^2 +1)=0,  $$ I am not sure what to do with the $\log(1-f(x))$. Any idea?",,"['ordinary-differential-equations', 'derivatives']"
76,Differential equation for logistic population growth with harvesting,Differential equation for logistic population growth with harvesting,,"When both parameters are set to $1$, the differential equation for logistic population growth is $$x'=x(1-x)$$ Suppose the population is also harvested at the constant rate $h$. The differential equation then apparently becomes $$x'=x(1-x)-h$$ Here's what I don't understand: If the population is harvested at the constant rate $h$, it means that $x$ is reduced by $h$ periodically. Why would this also mean that $x'$ is reduced by $h$?","When both parameters are set to $1$, the differential equation for logistic population growth is $$x'=x(1-x)$$ Suppose the population is also harvested at the constant rate $h$. The differential equation then apparently becomes $$x'=x(1-x)-h$$ Here's what I don't understand: If the population is harvested at the constant rate $h$, it means that $x$ is reduced by $h$ periodically. Why would this also mean that $x'$ is reduced by $h$?",,['ordinary-differential-equations']
77,Exists an exponential matrix,Exists an exponential matrix,,"I'm struggling with this proof: Let $\phi(t)$ a square matrix of size $n$ with $C^1$ functions such that $$\phi(0)=I_n \qquad \text{and} \qquad \phi(s+t)=\phi(s)\phi(t)$$   $\forall s,t\in\mathbb{R}$.    Prove that there exists a square matrix $A\in M_n(\mathbb{R})$ such that $\phi(t)=e^{tA}$, for all $t$. I'm almost sure that the matrix $\phi$ is kind of solution of an linear ODE. But I don't realize how i'm supposed to construct the matrix A","I'm struggling with this proof: Let $\phi(t)$ a square matrix of size $n$ with $C^1$ functions such that $$\phi(0)=I_n \qquad \text{and} \qquad \phi(s+t)=\phi(s)\phi(t)$$   $\forall s,t\in\mathbb{R}$.    Prove that there exists a square matrix $A\in M_n(\mathbb{R})$ such that $\phi(t)=e^{tA}$, for all $t$. I'm almost sure that the matrix $\phi$ is kind of solution of an linear ODE. But I don't realize how i'm supposed to construct the matrix A",,"['linear-algebra', 'ordinary-differential-equations', 'matrix-exponential']"
78,Why I can't divide $\frac{d^3}{dx^3}$ and $\frac{d^2}{dx^2}$,Why I can't divide  and,\frac{d^3}{dx^3} \frac{d^2}{dx^2},"I had an differential equation exam last semester. There was a question I never found out how I could answer. At a part of the question I faced: $\frac{u'''}{u''} = \cot(x)u+x$ And it was asked to make it first-order Linear and then solve it. I simply wrote $\frac{u'''}{u''}= u'$. Then wrote it like $u' - \cot(x)u = x$,  but I know the first part is not correct at all. I never had the chance to ask the teacher or anyone what should one do in this situation? I think I had a confusion and it's root is the notation when you could write $\frac{dy}{dx}$ as $(D)y$ so $\frac{d^3y}{d^3x}$ could be $(D^3)y$. Is there a way to lower this equations order?","I had an differential equation exam last semester. There was a question I never found out how I could answer. At a part of the question I faced: $\frac{u'''}{u''} = \cot(x)u+x$ And it was asked to make it first-order Linear and then solve it. I simply wrote $\frac{u'''}{u''}= u'$. Then wrote it like $u' - \cot(x)u = x$,  but I know the first part is not correct at all. I never had the chance to ask the teacher or anyone what should one do in this situation? I think I had a confusion and it's root is the notation when you could write $\frac{dy}{dx}$ as $(D)y$ so $\frac{d^3y}{d^3x}$ could be $(D^3)y$. Is there a way to lower this equations order?",,['ordinary-differential-equations']
79,solving the Thomas-Fermi-Dirac equation for planetary interior structure modeling,solving the Thomas-Fermi-Dirac equation for planetary interior structure modeling,,"I am currently working on implementing high pressure equations of state to model interiors of planets and exoplanets. To this end, what I need to do is to numerically solve the Thomas-Fermi-Dirac equation for a given material. The problem I have is purely mathematical, i.e. I am having trouble solving the differential equation. For the simpler case of the Thomas-Fermi equation I successfully proceeded in analogy to S. Esposito 2001 (link 1). After lengthy research I found in F. Ren 2014 (link 2) that they transformed the TFD equation and applied a 4th order Runge-Kutta scheme to solve it. I am, however, struggling to practically apply this idea my self. The equation I seek to solve is: $$ {d^2 \phi}/{d x^2} = x(\epsilon + (\phi/x)^{1/2} )^3$$ With the initial conditions: $$ d^2\phi/dx^2|_{x_0} = \phi(x_0)/x_0, \ \ \ \phi(0) = 1 $$ The first problem I have is, that the rhs depends on x and $\phi$ itself rather than on x and the first derivative, which would probably be easier. The second thing is that the initial conditions are given for the second derivative and the function itself at two different points. Of course, transforming the equation into a first order one would considerably simplify things. The simplest substitution $ f (\phi,x) = d \phi /dx$ would yield an integral term on the rhs so another approach seems to be required. Since I have no experience with 2nd order nonlinear differential equations I would appreciate it if some one could guide me through this one. 1: https://core.ac.uk/download/pdf/25325537.pdf 2: https://pdfs.semanticscholar.org/f0b8/0210ae2c2da807cd874c5e8c4c37091a4a46.pdf","I am currently working on implementing high pressure equations of state to model interiors of planets and exoplanets. To this end, what I need to do is to numerically solve the Thomas-Fermi-Dirac equation for a given material. The problem I have is purely mathematical, i.e. I am having trouble solving the differential equation. For the simpler case of the Thomas-Fermi equation I successfully proceeded in analogy to S. Esposito 2001 (link 1). After lengthy research I found in F. Ren 2014 (link 2) that they transformed the TFD equation and applied a 4th order Runge-Kutta scheme to solve it. I am, however, struggling to practically apply this idea my self. The equation I seek to solve is: $$ {d^2 \phi}/{d x^2} = x(\epsilon + (\phi/x)^{1/2} )^3$$ With the initial conditions: $$ d^2\phi/dx^2|_{x_0} = \phi(x_0)/x_0, \ \ \ \phi(0) = 1 $$ The first problem I have is, that the rhs depends on x and $\phi$ itself rather than on x and the first derivative, which would probably be easier. The second thing is that the initial conditions are given for the second derivative and the function itself at two different points. Of course, transforming the equation into a first order one would considerably simplify things. The simplest substitution $ f (\phi,x) = d \phi /dx$ would yield an integral term on the rhs so another approach seems to be required. Since I have no experience with 2nd order nonlinear differential equations I would appreciate it if some one could guide me through this one. 1: https://core.ac.uk/download/pdf/25325537.pdf 2: https://pdfs.semanticscholar.org/f0b8/0210ae2c2da807cd874c5e8c4c37091a4a46.pdf",,"['ordinary-differential-equations', 'numerical-methods']"
80,show that the function $f(x)=\frac{e^{-x}}{1+t^2}$ satisfies Lipschitz condition,show that the function  satisfies Lipschitz condition,f(x)=\frac{e^{-x}}{1+t^2},"show that  $$f(x)=\frac{e^{-x}}{1+t^2}$$  is defined $0<x<p, 0<t<N$ ( where N is positive integer ) Lipschitz condition with Lipschitz constant $N$ Attempt consider $|f(t,x_1)-f(t,x_2)=|\frac{e^{-x_1}}{1+t^2}-\frac{e^{-x_2}}{1+t^2}|\\=|\frac{1}{1+t^2}(e^{-x_1}-e^{-x_2})|$ from here how to we procesed","show that  $$f(x)=\frac{e^{-x}}{1+t^2}$$  is defined $0<x<p, 0<t<N$ ( where N is positive integer ) Lipschitz condition with Lipschitz constant $N$ Attempt consider $|f(t,x_1)-f(t,x_2)=|\frac{e^{-x_1}}{1+t^2}-\frac{e^{-x_2}}{1+t^2}|\\=|\frac{1}{1+t^2}(e^{-x_1}-e^{-x_2})|$ from here how to we procesed",,"['ordinary-differential-equations', 'initial-value-problems']"
81,Series solution to $y''+(\cos t) y=0$,Series solution to,y''+(\cos t) y=0,"Series solution to $\mathbf{y''+(cost)y=0}\;$ is$$\sum_{n=0}^{\infty}a_nt^n$$Find $a_2/a_4$ choices are -6, -4, 4, 6 I found $a_{k+2}=-\frac{\cos t}{(k+1)(k+2)}a_k$ So, $a_4=-\frac{\cos t}{3\cdot4}a_2 \;\to\;a2/a4=\frac{-12}{\cos t}$ I'm not sure how to pick answer from this. Is information given in this problem enough to solve it?","Series solution to $\mathbf{y''+(cost)y=0}\;$ is$$\sum_{n=0}^{\infty}a_nt^n$$Find $a_2/a_4$ choices are -6, -4, 4, 6 I found $a_{k+2}=-\frac{\cos t}{(k+1)(k+2)}a_k$ So, $a_4=-\frac{\cos t}{3\cdot4}a_2 \;\to\;a2/a4=\frac{-12}{\cos t}$ I'm not sure how to pick answer from this. Is information given in this problem enough to solve it?",,['ordinary-differential-equations']
82,Finding change of variables to give linear homogeneous system,Finding change of variables to give linear homogeneous system,,"I have worked out $a = -5$ and $b = -5/2$ which I'm confident is correct.  However, what I'm struggling with is understanding what matrix $B$ is meant to become. Any help will be appreciated. Thanks","I have worked out $a = -5$ and $b = -5/2$ which I'm confident is correct.  However, what I'm struggling with is understanding what matrix $B$ is meant to become. Any help will be appreciated. Thanks",,"['matrices', 'ordinary-differential-equations', 'homogeneous-equation', 'change-of-variable']"
83,Differential Polynomials(?),Differential Polynomials(?),,"Consider an equation of the form: cy""+cy'+cy Or something of the form. Essentially, it's a polynomial but instead of powers, there are derivatives. Do these kind of things have a name? Or are they completely useless? Note: I KNOW what Taylor Polynomials and the like are, but I mean something in the form of what I have shown.","Consider an equation of the form: cy""+cy'+cy Or something of the form. Essentially, it's a polynomial but instead of powers, there are derivatives. Do these kind of things have a name? Or are they completely useless? Note: I KNOW what Taylor Polynomials and the like are, but I mean something in the form of what I have shown.",,"['calculus', 'ordinary-differential-equations', 'polynomials', 'taylor-expansion']"
84,Why is u'(t)/u(t) = (ln(u(t)))'?,Why is u'(t)/u(t) = (ln(u(t)))'?,,I saw this from these online notes about differential equations. $\frac{\mu'(t)}{\mu(t)} = p(t)$ Hopefully you will recognize the left side of this from your Calculus I class as the following derivative. ($\ln\mu(t))' = p(t)$ I don't think I understand why $\frac{\mu'(t)}{\mu(t)} = (\ln\mu(t))'$ is true. Why is this the case? Thank you very much!,I saw this from these online notes about differential equations. $\frac{\mu'(t)}{\mu(t)} = p(t)$ Hopefully you will recognize the left side of this from your Calculus I class as the following derivative. ($\ln\mu(t))' = p(t)$ I don't think I understand why $\frac{\mu'(t)}{\mu(t)} = (\ln\mu(t))'$ is true. Why is this the case? Thank you very much!,,"['calculus', 'ordinary-differential-equations']"
85,Unique solution to homogenous second order differential equation,Unique solution to homogenous second order differential equation,,"I have a problem which gives me the homogenous second order differential equation $$y''-6y'+9y=0 \tag{1}\label{D.E.}$$ and had me find the expression which describes the solution to the differential equation (\ref{D.E.}). I found the solution to be: $$y(t)=c_1 e^{3t}+c_2 te^{3t} \tag{2}\label{solution}$$ The problem continues by stating: The differential equation has a unique solution $y(t)$ with initial conditions $y(1)=3e^3, y'(1)=10e^3$. Mark the value $y(0)$ of that solution at $t=0$ . With the possible multiple choice answers: a) 6, b) 2, c) $0$ , and d) None of these. I know how to solve for the IVP, but it throws me off that I have to solve for a unique solution (especially when the class and I haven't recieved any litterature on how to solve for a unique solution). CALCULATIONS BELOW HAVE BEEN EDITED: (to correct $y'(t)$ this time) I have tried solving for the IVP for $y(1)$ and $y'(1)$ where: $$y'(t)=3c_1e^{3t}+c_2\left(e^{3t}+3e^{3t}t\right) \tag{3}\label{y'solution}$$ And if I plug in $y(1)=3e^3$ in equation (\ref{solution}), and $y'(1)=10e^3$ in equation (\ref{y'solution}) then: $$y(1)=c_1 e^{3\cdot1}+c_2\cdot1\cdot e^{3\cdot1}= 3e^3 \Rightarrow  c_1 e^{3}+c_2e^{3}= 3e^3 \tag{4}\label{y(1)solution}$$ $$y'(1)=c_1e^{3\cdot1}\cdot 3+c_2\left(e^{3\cdot1}+3e^{3\cdot1}\cdot1\right) = 10e^3 \Rightarrow  3c_1e^{3}+c_2\left(e^{3}+3e^{3}\right) = 10e^3 \tag{5}\label{y'(1)solution}$$ If we continue, and divide both sides of $y(1)$ with $e^3$ we get: $$y(1)=\frac{(c_1 e^3+c_2e^3)}{e^3}=\frac{3e^3}{e^3} \Rightarrow c_1+c_2=3 $$ We then multiply the $c_2(e^{3}+3e^{3})$ part out and do the same: $$y'(1)=\frac{(3c_1e^{3}+c_2e^{3}+3c_2e^{3})}{e^3} = \frac{10e^3}{e^3} \Rightarrow 3c_1+4c_2=10$$ and get: $$  \begin{cases}  c_1 + c_2 = 3 \\  3c_1 + 4c_2 = 10 \end{cases} $$ which yields: $y(t) = 2e^{3t} + te^{3t}\tag{6}\label{y(t)}$ as @pointguardo answered. Finishing it of with $y(0)$ at $t=0$ we get: $$y(0) = 2e^{3\cdot0} + 0\cdot e^{3\cdot0} = 2$$ Thank you for the help guys =)","I have a problem which gives me the homogenous second order differential equation $$y''-6y'+9y=0 \tag{1}\label{D.E.}$$ and had me find the expression which describes the solution to the differential equation (\ref{D.E.}). I found the solution to be: $$y(t)=c_1 e^{3t}+c_2 te^{3t} \tag{2}\label{solution}$$ The problem continues by stating: The differential equation has a unique solution $y(t)$ with initial conditions $y(1)=3e^3, y'(1)=10e^3$. Mark the value $y(0)$ of that solution at $t=0$ . With the possible multiple choice answers: a) 6, b) 2, c) $0$ , and d) None of these. I know how to solve for the IVP, but it throws me off that I have to solve for a unique solution (especially when the class and I haven't recieved any litterature on how to solve for a unique solution). CALCULATIONS BELOW HAVE BEEN EDITED: (to correct $y'(t)$ this time) I have tried solving for the IVP for $y(1)$ and $y'(1)$ where: $$y'(t)=3c_1e^{3t}+c_2\left(e^{3t}+3e^{3t}t\right) \tag{3}\label{y'solution}$$ And if I plug in $y(1)=3e^3$ in equation (\ref{solution}), and $y'(1)=10e^3$ in equation (\ref{y'solution}) then: $$y(1)=c_1 e^{3\cdot1}+c_2\cdot1\cdot e^{3\cdot1}= 3e^3 \Rightarrow  c_1 e^{3}+c_2e^{3}= 3e^3 \tag{4}\label{y(1)solution}$$ $$y'(1)=c_1e^{3\cdot1}\cdot 3+c_2\left(e^{3\cdot1}+3e^{3\cdot1}\cdot1\right) = 10e^3 \Rightarrow  3c_1e^{3}+c_2\left(e^{3}+3e^{3}\right) = 10e^3 \tag{5}\label{y'(1)solution}$$ If we continue, and divide both sides of $y(1)$ with $e^3$ we get: $$y(1)=\frac{(c_1 e^3+c_2e^3)}{e^3}=\frac{3e^3}{e^3} \Rightarrow c_1+c_2=3 $$ We then multiply the $c_2(e^{3}+3e^{3})$ part out and do the same: $$y'(1)=\frac{(3c_1e^{3}+c_2e^{3}+3c_2e^{3})}{e^3} = \frac{10e^3}{e^3} \Rightarrow 3c_1+4c_2=10$$ and get: $$  \begin{cases}  c_1 + c_2 = 3 \\  3c_1 + 4c_2 = 10 \end{cases} $$ which yields: $y(t) = 2e^{3t} + te^{3t}\tag{6}\label{y(t)}$ as @pointguardo answered. Finishing it of with $y(0)$ at $t=0$ we get: $$y(0) = 2e^{3\cdot0} + 0\cdot e^{3\cdot0} = 2$$ Thank you for the help guys =)",,"['calculus', 'ordinary-differential-equations']"
86,Mean value theorem for a derivative being equal to the function,Mean value theorem for a derivative being equal to the function,,"I have the following task in my homework: Let $a,b \in \mathbb{R}, a < b $ and $f:[a,b] \to \mathbb{R} $ be a continuous function that is differentiable on $(a,b)$. Show that if $f'(x)=f(x)$ for all $x \in (a,b)$, then there is a $c \in \mathbb{R}$ with $f(x)=ce^x$ for all $x \in [a,b]$. Hint: Consider the function $x\mapsto f(x)e^{-x} $ I know that the two solutions here would be $c=1$ and $c=0$, but apparently, that has to be shown with the mean value theorem, and that hint just confuses me more. Any help would be appreciated!","I have the following task in my homework: Let $a,b \in \mathbb{R}, a < b $ and $f:[a,b] \to \mathbb{R} $ be a continuous function that is differentiable on $(a,b)$. Show that if $f'(x)=f(x)$ for all $x \in (a,b)$, then there is a $c \in \mathbb{R}$ with $f(x)=ce^x$ for all $x \in [a,b]$. Hint: Consider the function $x\mapsto f(x)e^{-x} $ I know that the two solutions here would be $c=1$ and $c=0$, but apparently, that has to be shown with the mean value theorem, and that hint just confuses me more. Any help would be appreciated!",,"['real-analysis', 'ordinary-differential-equations', 'derivatives']"
87,"If $\int^{x}_{0}2x(f(t))^2dt = \bigg(\int^{x}_{0}2f(x-t)dt\bigg)^2$ and $f(1) = 1,$ Then $f(x)$ is",If  and  Then  is,"\int^{x}_{0}2x(f(t))^2dt = \bigg(\int^{x}_{0}2f(x-t)dt\bigg)^2 f(1) = 1, f(x)","If  $\displaystyle \int^{x}_{0}2x(f(t))^2dt = \bigg(\int^{x}_{0}2f(x-t)dt\bigg)^2$ and $f(1) = 1,$ Then $f(x)$ is Try: Using $\displaystyle  \int^{a}_{0}f(x)dx = \int^{a}_{0}f(a-x)dx$ We can write it as $$\displaystyle x\int^{x}_{0}f^2(t)dt = \bigg(\int^{x}_{0}2f(t)dt\bigg)^2 = 4 \bigg(\int^{x}_{0}f(t)dt\bigg)^2\;\;\;(*)$$ Using Leibnitz Rule of Differentiation $$xf^2(x)+\int^{x}_{0}f^2(t)dt = 8\int^{x}_{0}f(t)dt\cdot f(x)$$ Again Differentiate w r to $x$ $$x\cdot 2f(x)\cdot f'(x)+f^2(x)+f^2(x)=8f^2(x)+8\int^{x}_{0}f(t)dt$$ Could some help me how to solve it, Thanks","If  $\displaystyle \int^{x}_{0}2x(f(t))^2dt = \bigg(\int^{x}_{0}2f(x-t)dt\bigg)^2$ and $f(1) = 1,$ Then $f(x)$ is Try: Using $\displaystyle  \int^{a}_{0}f(x)dx = \int^{a}_{0}f(a-x)dx$ We can write it as $$\displaystyle x\int^{x}_{0}f^2(t)dt = \bigg(\int^{x}_{0}2f(t)dt\bigg)^2 = 4 \bigg(\int^{x}_{0}f(t)dt\bigg)^2\;\;\;(*)$$ Using Leibnitz Rule of Differentiation $$xf^2(x)+\int^{x}_{0}f^2(t)dt = 8\int^{x}_{0}f(t)dt\cdot f(x)$$ Again Differentiate w r to $x$ $$x\cdot 2f(x)\cdot f'(x)+f^2(x)+f^2(x)=8f^2(x)+8\int^{x}_{0}f(t)dt$$ Could some help me how to solve it, Thanks",,"['calculus', 'real-analysis', 'ordinary-differential-equations', 'derivatives', 'functional-equations']"
88,Justify why there are no non-constant periodic solutions,Justify why there are no non-constant periodic solutions,,"I'm probably missing something stupid here, regarding periodic solutions to ODE's. The ode is $$\dot{x}=-\nabla f$$ I can see that a solution will require $\frac{df}{dt}=-\|\nabla f\|^2$. Buy why does this prevent existence of such solutions? More generally, why are we interested in the behavior of $f$ rather than $x$?","I'm probably missing something stupid here, regarding periodic solutions to ODE's. The ode is $$\dot{x}=-\nabla f$$ I can see that a solution will require $\frac{df}{dt}=-\|\nabla f\|^2$. Buy why does this prevent existence of such solutions? More generally, why are we interested in the behavior of $f$ rather than $x$?",,['ordinary-differential-equations']
89,Are omega limit points always in the domain of definition of the flow?,Are omega limit points always in the domain of definition of the flow?,,"Definition of an $\omega$-limit point: Let $\phi_t(p)$ be the orbit of the solution of the ODE $\dot{x}=f(x)$ which passes through the point $p$. We know that a point $x$ in $\mathbb{ R}^n$ is called an $\omega$-limit point of the orbit through the point $p$ if there is a sequence of numbers $t_1 \le t_2 \le t_3 \le · · ·$ such that $\lim_{i \to \infty } t_i = \infty $ and $\lim_{i\to \infty} \phi_{t_i}(p) = x$. From this definition, first and foremost, we understand that an $\omega$-limit point is ""the limit point of a subsequence"" constructed on the orbit. Obviously, this limit point may not be on the same orbit. I appreciate it if someone can answer the following questions: Q1- Is that possible that an $\omega$-limit point is not on any orbit (i.e., it is not in the domain of definition of the solution (flow))? I guess that if the solution is forward complete (i.e., defined for all time $t\in(0,+\infty)$), then all the omega limit points are always in the domain of definition of the solution. Q2- How should we define the $\omega$-limit point for the case when $t$ cannot go to $\infty$, i.e., the maximal interval of existence of the solution (i.e., domain of $t$) is $(-\infty, a)$ where $a<\infty$?","Definition of an $\omega$-limit point: Let $\phi_t(p)$ be the orbit of the solution of the ODE $\dot{x}=f(x)$ which passes through the point $p$. We know that a point $x$ in $\mathbb{ R}^n$ is called an $\omega$-limit point of the orbit through the point $p$ if there is a sequence of numbers $t_1 \le t_2 \le t_3 \le · · ·$ such that $\lim_{i \to \infty } t_i = \infty $ and $\lim_{i\to \infty} \phi_{t_i}(p) = x$. From this definition, first and foremost, we understand that an $\omega$-limit point is ""the limit point of a subsequence"" constructed on the orbit. Obviously, this limit point may not be on the same orbit. I appreciate it if someone can answer the following questions: Q1- Is that possible that an $\omega$-limit point is not on any orbit (i.e., it is not in the domain of definition of the solution (flow))? I guess that if the solution is forward complete (i.e., defined for all time $t\in(0,+\infty)$), then all the omega limit points are always in the domain of definition of the solution. Q2- How should we define the $\omega$-limit point for the case when $t$ cannot go to $\infty$, i.e., the maximal interval of existence of the solution (i.e., domain of $t$) is $(-\infty, a)$ where $a<\infty$?",,"['ordinary-differential-equations', 'analysis', 'differential-geometry', 'manifolds', 'control-theory']"
90,"A curve $C$ in the $x$-$y$ plane is such that the line joining the origin to any point $P(x,y)$ on the curve and the line parallel to?",A curve  in the - plane is such that the line joining the origin to any point  on the curve and the line parallel to?,"C x y P(x,y)","A curve $C$ in the $x-y$ plane is such that the line joining the origin to any point $P(x,y)$ on the curve and the line parallel to the $y$ axis through P are equally inclined to the tangent to the curve at P. Find the differential equation of the curve $C$. Slope of the line from origin to $P(x,y)$ will be $\frac{y}x = m1$ Slope of the line from $P$ parallel to y axis = $\tan(90) = m2$ I am having trouble proceeding from here.","A curve $C$ in the $x-y$ plane is such that the line joining the origin to any point $P(x,y)$ on the curve and the line parallel to the $y$ axis through P are equally inclined to the tangent to the curve at P. Find the differential equation of the curve $C$. Slope of the line from origin to $P(x,y)$ will be $\frac{y}x = m1$ Slope of the line from $P$ parallel to y axis = $\tan(90) = m2$ I am having trouble proceeding from here.",,"['calculus', 'ordinary-differential-equations', 'differential-geometry']"
91,Area preservation when transverse intersection,Area preservation when transverse intersection,,"This might be something way too trivial but I'm not seeing it yet so if you could explain to me the following I'd be thankful. On this page http://mathworld.wolfram.com/HomoclinicTangle.html the property ""area preservation"" is used, but I don't see where this comes from. Thanks in advance","This might be something way too trivial but I'm not seeing it yet so if you could explain to me the following I'd be thankful. On this page http://mathworld.wolfram.com/HomoclinicTangle.html the property ""area preservation"" is used, but I don't see where this comes from. Thanks in advance",,"['ordinary-differential-equations', 'analysis', 'dynamical-systems']"
92,How to solve this second order ODE question?,How to solve this second order ODE question?,,"I have this second-order ode equation: $y''-4y'+13y=0$ I've identified it as a x missing case as $y''=f(y',y)=4y'-13y$, so I'm substituting with: $y'=P, y''=P\frac{dy^2}{d^2x}=f(P,y)=4P-13y$. At this point I have $P\frac{dP}{dy}=4P-13y$, which seems a non-linear first-order ODE. This is currently beyond the scope of my course, so I'm unsure if I should continue and search online for solving techniques, or did I already do something wrong?","I have this second-order ode equation: $y''-4y'+13y=0$ I've identified it as a x missing case as $y''=f(y',y)=4y'-13y$, so I'm substituting with: $y'=P, y''=P\frac{dy^2}{d^2x}=f(P,y)=4P-13y$. At this point I have $P\frac{dP}{dy}=4P-13y$, which seems a non-linear first-order ODE. This is currently beyond the scope of my course, so I'm unsure if I should continue and search online for solving techniques, or did I already do something wrong?",,['ordinary-differential-equations']
93,Why should I take the time order to solve this differential equation?,Why should I take the time order to solve this differential equation?,,In a textbook on quantum field theory I come across the following differential equation. $$ i \partial_t U(t) = H(t) U(t) $$ I would say that the solution to this equation would be $$U(t) = e^{-i \int_0^t dt H(t) }$$ Since $$ \partial_t e^{-i \int_0^t dt H(t) } =  \partial_t ( -i\int_0^t dt H(t))e^{-i\int_0^t dt H(t) } =  -i H(t) e^{-i\int_0^t dt H(t) } = -i H(t) U(t)$$ exactly as desired. However the solution in the textbook states: $$ T(e^{-i\int_0^t dt H(t) })$$ where T stands for the time order parameter. In other words the solution should be $$ U(t) = 1 -i  \int_0^t dt_1 H(t_1)  + \frac{1}{2}(-i)^2  \int_0^{t} \int_0^{t} dt_t dt_2 T(H(t_1)H(t_2)) + \cdots $$ where $T(H(t_1)H(t_2))$ equals $H(t_1)H(t_2)$ if $t_1<t_2$ and $H(t_2)H(t_1)$ otherwise. So why is this the correct solution? What goes wrong in the reasoning above?,In a textbook on quantum field theory I come across the following differential equation. $$ i \partial_t U(t) = H(t) U(t) $$ I would say that the solution to this equation would be $$U(t) = e^{-i \int_0^t dt H(t) }$$ Since $$ \partial_t e^{-i \int_0^t dt H(t) } =  \partial_t ( -i\int_0^t dt H(t))e^{-i\int_0^t dt H(t) } =  -i H(t) e^{-i\int_0^t dt H(t) } = -i H(t) U(t)$$ exactly as desired. However the solution in the textbook states: $$ T(e^{-i\int_0^t dt H(t) })$$ where T stands for the time order parameter. In other words the solution should be $$ U(t) = 1 -i  \int_0^t dt_1 H(t_1)  + \frac{1}{2}(-i)^2  \int_0^{t} \int_0^{t} dt_t dt_2 T(H(t_1)H(t_2)) + \cdots $$ where $T(H(t_1)H(t_2))$ equals $H(t_1)H(t_2)$ if $t_1<t_2$ and $H(t_2)H(t_1)$ otherwise. So why is this the correct solution? What goes wrong in the reasoning above?,,['ordinary-differential-equations']
94,"For which values of $\alpha$ is the disk $B = \{(x, y) \mid x^2+y^2 \leq 1\}$ positively invariant?",For which values of  is the disk  positively invariant?,"\alpha B = \{(x, y) \mid x^2+y^2 \leq 1\}","Given the following dynamical system $$\begin{aligned} \dot x &= f(x,y) = -x + \alpha y \\ \dot y &= g(x,y) = -y\end{aligned}$$ for which values of $\alpha$ is the disk $B = \{(x, y)\mid x^2+y^2 \leq 1\}$ positively invariant? Now what I have done is that I have taken the orbital derivative of $x^2 + y^2$ . This gives $$\frac{dV}{dt} = 2x\dot x + 2y \dot y = 2x(-x+\alpha y) - 2y^2$$ Now I say at the edge of this disk we have $x^2 + y^2 = 1$ so I now get $$\frac{dV}{dt}= -2 +2x\alpha y$$ and I want $\frac{dV}{dt} < 0$ so from this I conclude that $\alpha < \frac{1}{xy}$ . Now here I am just looking for some clarification. If I have done this wrong can someone please point me in the correct direction. I am not very confident in my answer due to the fact I have not got a actual numerate answer.",Given the following dynamical system for which values of is the disk positively invariant? Now what I have done is that I have taken the orbital derivative of . This gives Now I say at the edge of this disk we have so I now get and I want so from this I conclude that . Now here I am just looking for some clarification. If I have done this wrong can someone please point me in the correct direction. I am not very confident in my answer due to the fact I have not got a actual numerate answer.,"\begin{aligned} \dot x &= f(x,y) = -x + \alpha y \\ \dot y &= g(x,y) = -y\end{aligned} \alpha B = \{(x, y)\mid x^2+y^2 \leq 1\} x^2 + y^2 \frac{dV}{dt} = 2x\dot x + 2y \dot y = 2x(-x+\alpha y) - 2y^2 x^2 + y^2 = 1 \frac{dV}{dt}= -2 +2x\alpha y \frac{dV}{dt} < 0 \alpha < \frac{1}{xy}","['ordinary-differential-equations', 'derivatives', 'dynamical-systems', 'set-invariance']"
95,How to solve this differential equation numerically in Python?,How to solve this differential equation numerically in Python?,,I am trying to solve a differential equation in Python:     $$y'' + 2\frac{y'}{x} + (1 - \frac{e^{-x}}{x} - \frac{l(l+1)}{x^2})y = 0$$ I have initial conditions at $x=0$ as:     $$y(0) = a$$     $$y'(0) = b$$ $a$ and $b$ are some known constants and they will be constrained by $l$. I tried using Euler forward method but solution was unstable. I tried Runge-Kutta 2nd order method but again the solution was unstable. What method should I use so that I will get a stable solution?,I am trying to solve a differential equation in Python:     $$y'' + 2\frac{y'}{x} + (1 - \frac{e^{-x}}{x} - \frac{l(l+1)}{x^2})y = 0$$ I have initial conditions at $x=0$ as:     $$y(0) = a$$     $$y'(0) = b$$ $a$ and $b$ are some known constants and they will be constrained by $l$. I tried using Euler forward method but solution was unstable. I tried Runge-Kutta 2nd order method but again the solution was unstable. What method should I use so that I will get a stable solution?,,"['ordinary-differential-equations', 'numerical-methods', 'python']"
96,What numerical approach should I take with solving this system of 2nd order coupled ODEs?,What numerical approach should I take with solving this system of 2nd order coupled ODEs?,,"I want to solve this system numerically, but I am stuck as to how to proceed.  Do I need to transform this into a set of four 1st order equations before discretizing?  Which numerical method would be recommended here? $ \frac{d^2x}{dt^2} = \omega^2 x + 2\omega\frac{dy}{dt} $ $ \frac{d^2y}{dt^2} = \omega^2 y - 2\omega\frac{dx}{dt} $ Thanks!","I want to solve this system numerically, but I am stuck as to how to proceed.  Do I need to transform this into a set of four 1st order equations before discretizing?  Which numerical method would be recommended here? $ \frac{d^2x}{dt^2} = \omega^2 x + 2\omega\frac{dy}{dt} $ $ \frac{d^2y}{dt^2} = \omega^2 y - 2\omega\frac{dx}{dt} $ Thanks!",,"['ordinary-differential-equations', 'numerical-methods']"
97,ODE power series solution $y'+xy=1+x$,ODE power series solution,y'+xy=1+x,"So i have been told to find the power series solution to the following ode $$y'+yx=1-x$$ Using the substitution $y=\sum_{n=0}^{\infty}a_nx^n$, i can rewrite the equation as the following; $$\sum_{n=1}^{\infty}na_nx^{n-1}+\sum_{n=0}^{\infty}a_nx^{n+1}=1+x$$ That is $$\sum_{n=0}^{\infty}(n+1)a_{n+1}x^{n}+\sum_{n=1}^{\infty}a_{n-1}x^{n}=1+x$$ I then combined the series and the non homogeneous terms to obtain $$(a_1-1)+x(2a_2+a_0-1)+\sum_{n=2}^{\infty}[(n+1)a_{n+1}+a_{n-1}]x^n=0$$ Setting $a_1=1$ and $2a_2+a_0-1=0$, I can say that $(n+1)a_{n+1}+a_{n-1}=0$, meaning i can say $a_n=\frac{-a_{n-2}}{n}$ for $n=3,4,5...$ I began subbing in the values for n to try and get a relation, i got $a_3=-\frac{1}{3}$, $a_4=\frac{a_0-1}{4\cdot2}$, $a_5=\frac{1}{5\cdot3}$, $a_6=-\frac{a_0-1}{6\cdot4\cdot2}$... This is where I am stumped, I said that $$a_{2k}=\frac{(-1)^k(a_0-1)}{2k!!}, k=2,3,4...$$ And $$a_{2k+1}=\frac{(-1)^n}{(2k-1)!!},k=1,2,3..$$ Am i correct in saying this? And if so how to i get to an answer from these statements? Any help would be greatly appriciated.","So i have been told to find the power series solution to the following ode $$y'+yx=1-x$$ Using the substitution $y=\sum_{n=0}^{\infty}a_nx^n$, i can rewrite the equation as the following; $$\sum_{n=1}^{\infty}na_nx^{n-1}+\sum_{n=0}^{\infty}a_nx^{n+1}=1+x$$ That is $$\sum_{n=0}^{\infty}(n+1)a_{n+1}x^{n}+\sum_{n=1}^{\infty}a_{n-1}x^{n}=1+x$$ I then combined the series and the non homogeneous terms to obtain $$(a_1-1)+x(2a_2+a_0-1)+\sum_{n=2}^{\infty}[(n+1)a_{n+1}+a_{n-1}]x^n=0$$ Setting $a_1=1$ and $2a_2+a_0-1=0$, I can say that $(n+1)a_{n+1}+a_{n-1}=0$, meaning i can say $a_n=\frac{-a_{n-2}}{n}$ for $n=3,4,5...$ I began subbing in the values for n to try and get a relation, i got $a_3=-\frac{1}{3}$, $a_4=\frac{a_0-1}{4\cdot2}$, $a_5=\frac{1}{5\cdot3}$, $a_6=-\frac{a_0-1}{6\cdot4\cdot2}$... This is where I am stumped, I said that $$a_{2k}=\frac{(-1)^k(a_0-1)}{2k!!}, k=2,3,4...$$ And $$a_{2k+1}=\frac{(-1)^n}{(2k-1)!!},k=1,2,3..$$ Am i correct in saying this? And if so how to i get to an answer from these statements? Any help would be greatly appriciated.",,"['ordinary-differential-equations', 'power-series']"
98,Solution of the second order differential equation,Solution of the second order differential equation,,"Consider the differential equation $$\frac{d^2y}{dx^2}-2\tan x \frac{dy}{dx}-y=0$$ defined on $\big(-\frac{\pi}{2}, \frac{\pi}{2}\big)$. Which among the following are true? there is exactly one solution $y=y(x)$ with $y(0) = y'(0) = 0$ and $y\big(\frac{\pi}{3}\big) = 2\big(1+\frac{\pi}{3}\big)$ there is exactly one solution $y=y(x)$ with $y(0) =1, \  y'(0) = -1$ and $y\big(-\frac{\pi}{3}\big) = 2\big(1+\frac{\pi}{3}\big)$ any solution $y=y(x)$ satisfies $y''(0) = y(0)$. if $y_1$ and $y_2$ are any two solutions then $(ax+b)y_1 = (cx+d)y_2$ for some $a, b, c, d \in \mathbb{R}$. How to solve the above problem?","Consider the differential equation $$\frac{d^2y}{dx^2}-2\tan x \frac{dy}{dx}-y=0$$ defined on $\big(-\frac{\pi}{2}, \frac{\pi}{2}\big)$. Which among the following are true? there is exactly one solution $y=y(x)$ with $y(0) = y'(0) = 0$ and $y\big(\frac{\pi}{3}\big) = 2\big(1+\frac{\pi}{3}\big)$ there is exactly one solution $y=y(x)$ with $y(0) =1, \  y'(0) = -1$ and $y\big(-\frac{\pi}{3}\big) = 2\big(1+\frac{\pi}{3}\big)$ any solution $y=y(x)$ satisfies $y''(0) = y(0)$. if $y_1$ and $y_2$ are any two solutions then $(ax+b)y_1 = (cx+d)y_2$ for some $a, b, c, d \in \mathbb{R}$. How to solve the above problem?",,['ordinary-differential-equations']
99,Integro-Differential Equations,Integro-Differential Equations,,I was attempting to solve the following integro-differential equation using convolutions. My answer also had a convolution which did not seem right and was wondering if someone would check my process. Problem with initial work My final solution,I was attempting to solve the following integro-differential equation using convolutions. My answer also had a convolution which did not seem right and was wondering if someone would check my process. Problem with initial work My final solution,,"['ordinary-differential-equations', 'convolution', 'integro-differential-equations']"
