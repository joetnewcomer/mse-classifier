,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Cauchys integral formula with an exponential,Cauchys integral formula with an exponential,,"The question is to evaluate the integral : $$ \oint\limits_{|z-1|=2}\frac{\mathrm{d}z}{z^2(z^2-4)e^z} $$ by using Cauchy's integral formula. I have this so far: We have a circle with radius 2 centered at 1, and we have 3 singularities, $z=2, z=-2, z=0$ . However, $z=-2$ is not included within our circle, so we don't need to worry about it. Now we can rewrite what we have as $$ \oint\limits_{|z-1|=2}\frac{dz}{z^2(z^2-4)e^z} = \oint\limits_{|z|=\epsilon} \frac{\frac{e^{-z}}{z^2-4}}{z^2} \mathrm{d}z+  \oint\limits_{|z-2|=\epsilon}\frac{\frac{e^{-z}}{z^2(z+2)}}{z-2} \mathrm{d}z. $$ My solution ends up as $\frac{i\pi}{2} $ + $\frac{i\pi}{8e^2}$ . I think this is correct, but when I do my calculations I end up with the wrong solution (the solution is in the back of the book). Can anyone guide me in the right direction, or tell me if what I'm doing is wrong? The answer given in the back of the book is given as $\frac{-i\pi}{2} +\frac{i\pi}{4e^2}.$","The question is to evaluate the integral : by using Cauchy's integral formula. I have this so far: We have a circle with radius 2 centered at 1, and we have 3 singularities, . However, is not included within our circle, so we don't need to worry about it. Now we can rewrite what we have as My solution ends up as + . I think this is correct, but when I do my calculations I end up with the wrong solution (the solution is in the back of the book). Can anyone guide me in the right direction, or tell me if what I'm doing is wrong? The answer given in the back of the book is given as","
\oint\limits_{|z-1|=2}\frac{\mathrm{d}z}{z^2(z^2-4)e^z}
 z=2, z=-2, z=0 z=-2 
\oint\limits_{|z-1|=2}\frac{dz}{z^2(z^2-4)e^z} = \oint\limits_{|z|=\epsilon} \frac{\frac{e^{-z}}{z^2-4}}{z^2} \mathrm{d}z+ 
\oint\limits_{|z-2|=\epsilon}\frac{\frac{e^{-z}}{z^2(z+2)}}{z-2} \mathrm{d}z.
 \frac{i\pi}{2}  \frac{i\pi}{8e^2} \frac{-i\pi}{2} +\frac{i\pi}{4e^2}.","['complex-analysis', 'cauchy-integral-formula']"
1,Functional Derivative with Discrete Variable,Functional Derivative with Discrete Variable,,"Problem $$\text{Find}\quad\frac{\delta F_k}{\delta G} \quad \text{given} \quad F_k=\left(\sum_{r=0}^{N-1} e^{ikr}\int_{-\infty}^{\infty} dt \ e^{i\omega t} G(r,t)\right)^{-1}$$ noting that $k$ and $r$ are discrete while $\omega$ and $t$ are continuous. Background I am trying to show that $F_k[G(r,t)]$ is very sensitive to perturbations in $G(r,t)$ . By numerical work I know this is (often) the case. Ultimately I'd like to argue that constructing $F_k$ by measuring $G(r,t)$ won't work well when the measurement is noisy. I figured a good way to show that was to compute the functional derivative and show it gets large (or perhaps diverges) in some places. However, I am doing something wrong. Attempt By the definition here : $$\frac{\delta F_k}{\delta G}:\int dt \frac{\delta F_k}{\delta G}\eta(t)=\left[\frac{d}{d\epsilon}\left(\sum_{r=0}^{N-1} e^{ikr}\int dt \ e^{i\omega t} G(r,t)+\epsilon\eta(t)\right)^{-1}\right]_{\epsilon=0}$$ Using the chain rule, $\sum_{r=0}^{N-1} e^{ikr}=N\delta_{k,0}$ i.e. the Kronecker delta, and the definition $G(k,\omega)\equiv\sum_{r=0}^{N-1} e^{ikr}\int dt \ e^{i\omega t} G(r,t)$ transforms the above to $$\frac{-\int dt\sum_{r=0}^{N-1} e^{i(kr+\omega t)}\eta(t)}{\left(\sum_{r=0}^{N-1} e^{ikr}\int dt \ e^{i\omega t} G(r,t)\right)^{2}}=\int dt\frac{-\delta_{k,0} \ e^{i\omega t}}{G(k,\omega)^2}\eta(t)\to \frac{\delta F_k}{\delta G(r,t)}=\frac{-\delta_{k,0} \ e^{i\omega t}}{G(k,\omega)^2}$$ I know this is wrong because this numerics show this isn't $0$ for all $k\neq 0$ . I suspect the problem has something to do with $\eta$ only depending on $t$ and not $r$ , but I'm not sure how to account for a discrete variable like $r$ . Resolution? I think my understanding of the definition above is likely wrong, and probably needs a test function that depends on both $r$ and $t$ ? I'd be pretty jazzed if the right way to do it looked something like $$\frac{\delta F_k}{\delta G}:\sum_{r=0}^{N-1}\int dt \frac{\delta F_k}{\delta G}\eta(r,t)=\left[\frac{d}{d\epsilon}F_k\left[G(r,t)+\epsilon\eta(r,t)\right]\right]_{\epsilon=0}$$ but my math is too weak to assert this is the right way, even though it looks like it makes some sense (to me). I really have no idea how to handle the fact that $r$ is discrete. If the above is correct, this would give $$ \frac{\delta F_k}{\delta G(r,t)}=\frac{-e^{i(\omega t+kr)}}{G(k,\omega)^2} $$ which is what I was hoping to show since $G(k,\omega)=0$ for at least one $\omega$ at every $k$ . Seeking Any of the following $\dfrac{\delta F_k}{\delta G}$ How to approach such functional derivatives? What's wrong with my attempt? Confirm/deny the correctness of my ""resolution"". Thanks in advance!","Problem noting that and are discrete while and are continuous. Background I am trying to show that is very sensitive to perturbations in . By numerical work I know this is (often) the case. Ultimately I'd like to argue that constructing by measuring won't work well when the measurement is noisy. I figured a good way to show that was to compute the functional derivative and show it gets large (or perhaps diverges) in some places. However, I am doing something wrong. Attempt By the definition here : Using the chain rule, i.e. the Kronecker delta, and the definition transforms the above to I know this is wrong because this numerics show this isn't for all . I suspect the problem has something to do with only depending on and not , but I'm not sure how to account for a discrete variable like . Resolution? I think my understanding of the definition above is likely wrong, and probably needs a test function that depends on both and ? I'd be pretty jazzed if the right way to do it looked something like but my math is too weak to assert this is the right way, even though it looks like it makes some sense (to me). I really have no idea how to handle the fact that is discrete. If the above is correct, this would give which is what I was hoping to show since for at least one at every . Seeking Any of the following How to approach such functional derivatives? What's wrong with my attempt? Confirm/deny the correctness of my ""resolution"". Thanks in advance!","\text{Find}\quad\frac{\delta F_k}{\delta G} \quad \text{given} \quad F_k=\left(\sum_{r=0}^{N-1} e^{ikr}\int_{-\infty}^{\infty} dt \ e^{i\omega t} G(r,t)\right)^{-1} k r \omega t F_k[G(r,t)] G(r,t) F_k G(r,t) \frac{\delta F_k}{\delta G}:\int dt \frac{\delta F_k}{\delta G}\eta(t)=\left[\frac{d}{d\epsilon}\left(\sum_{r=0}^{N-1} e^{ikr}\int dt \ e^{i\omega t} G(r,t)+\epsilon\eta(t)\right)^{-1}\right]_{\epsilon=0} \sum_{r=0}^{N-1} e^{ikr}=N\delta_{k,0} G(k,\omega)\equiv\sum_{r=0}^{N-1} e^{ikr}\int dt \ e^{i\omega t} G(r,t) \frac{-\int dt\sum_{r=0}^{N-1} e^{i(kr+\omega t)}\eta(t)}{\left(\sum_{r=0}^{N-1} e^{ikr}\int dt \ e^{i\omega t} G(r,t)\right)^{2}}=\int dt\frac{-\delta_{k,0} \ e^{i\omega t}}{G(k,\omega)^2}\eta(t)\to \frac{\delta F_k}{\delta G(r,t)}=\frac{-\delta_{k,0} \ e^{i\omega t}}{G(k,\omega)^2} 0 k\neq 0 \eta t r r r t \frac{\delta F_k}{\delta G}:\sum_{r=0}^{N-1}\int dt \frac{\delta F_k}{\delta G}\eta(r,t)=\left[\frac{d}{d\epsilon}F_k\left[G(r,t)+\epsilon\eta(r,t)\right]\right]_{\epsilon=0} r 
\frac{\delta F_k}{\delta G(r,t)}=\frac{-e^{i(\omega t+kr)}}{G(k,\omega)^2}
 G(k,\omega)=0 \omega k \dfrac{\delta F_k}{\delta G}","['calculus', 'complex-analysis', 'functional-analysis', 'derivatives', 'functional-calculus']"
2,Taylor expansion of a function defined by a sum.,Taylor expansion of a function defined by a sum.,,"I'm looking at a complex function defined as $$f(z) = \sum\limits_{r=1}^\infty (-1)^{r+1}\sin\left(\frac{pz}{r}\right)$$ and am looking to find its Taylor expansion about $z=0$ . Presumably $p$ is some real number. My instinct is to Taylor expand $\sin$ about $z=0$ , then combine the sums. The only issue is that I have no idea how to combine sums nicely. Is this a decent approach, or is there a better way?","I'm looking at a complex function defined as and am looking to find its Taylor expansion about . Presumably is some real number. My instinct is to Taylor expand about , then combine the sums. The only issue is that I have no idea how to combine sums nicely. Is this a decent approach, or is there a better way?",f(z) = \sum\limits_{r=1}^\infty (-1)^{r+1}\sin\left(\frac{pz}{r}\right) z=0 p \sin z=0,"['real-analysis', 'complex-analysis', 'taylor-expansion', 'laurent-series']"
3,"Find $f(t,w)$ such that $\int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = \ln|w - \delta(\theta)|$",Find  such that,"f(t,w) \int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = \ln|w - \delta(\theta)|","Problem As part of a 2d Stokes flow fluid simulation I'm working on I'm trying to find a $f(t, w)$ such that $$\int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = \ln|w - \delta(\theta)|, \forall \theta \in [0, 2\pi)$$ where $w \in \mathbb{C}, |w| < 1$ and $\delta(t)$ is just a complex finite fourier series: $$\delta(t) = \sum_{n=-N}^N c_n e^{int}, c_n \in \mathbb{C}$$ Partial solutution If $\delta(t) = e^{it}$ I have that $$f(t, w) = \frac{1}{\pi} Re\Big(\frac{1}{1 - w e^{-it}}\Big)$$ to give some flavor of what $f(t,w)$ might look like (this value for $f(t,w)$ is not unique).  I'm trying to generalize this result to a wider class of $\delta(t)$ , ideally all finite Fourier series but maybe it's only possible for a certain class, I'm not sure. Possible approach? I thought maybe I could factor $\delta(t) - \delta(\theta)$ as $a e^{-iNt} \prod_{n=-N}^N (e^{it} - \alpha_n)$ .  Then the log term is linearly seperable: $$ \ln|a e^{iNt} \prod_{n=-N}^N (e^{it} - \alpha_n) | = \ln|a| + \sum_{n=-N}^N \ln|e^{it} - \alpha_n| $$ I can then split the integral into smaller, solvable pieces: $$\int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = $$ $$\ln|a| \int_0^{2 \pi} f(t, w) dt + \sum_{n=-N}^N \int_0^{2 \pi} f(t, w) \ln|e^{it} - \alpha_n| dt$$ Assuming $|\alpha_n| = 1$ , (which is a big assumption!), I think I can use my solution for $\delta(t) = e^{it}$ and a little bit of linear algebra to build up a more complex solution.  But the $\theta$ term disappears in the factorization (I have to pick some arbitrary value of $\theta$ to even do the factorization).  Maybe that's okay?  My solution when $\delta(t) = e^{it}$ should hold for all $\theta$ so maybe picking a value for $\theta$ arbitrarily is okay?  It's unclear to me and I'm not sure how to justify or refute the idea. Any help would be appreciated.  Mostly I'm out of tools in my toolbox and I'm not sure if I'm on the right track or if this is even possible in principle.","Problem As part of a 2d Stokes flow fluid simulation I'm working on I'm trying to find a such that where and is just a complex finite fourier series: Partial solutution If I have that to give some flavor of what might look like (this value for is not unique).  I'm trying to generalize this result to a wider class of , ideally all finite Fourier series but maybe it's only possible for a certain class, I'm not sure. Possible approach? I thought maybe I could factor as .  Then the log term is linearly seperable: I can then split the integral into smaller, solvable pieces: Assuming , (which is a big assumption!), I think I can use my solution for and a little bit of linear algebra to build up a more complex solution.  But the term disappears in the factorization (I have to pick some arbitrary value of to even do the factorization).  Maybe that's okay?  My solution when should hold for all so maybe picking a value for arbitrarily is okay?  It's unclear to me and I'm not sure how to justify or refute the idea. Any help would be appreciated.  Mostly I'm out of tools in my toolbox and I'm not sure if I'm on the right track or if this is even possible in principle.","f(t, w) \int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt = \ln|w - \delta(\theta)|, \forall \theta \in [0, 2\pi) w \in \mathbb{C}, |w| < 1 \delta(t) \delta(t) = \sum_{n=-N}^N c_n e^{int}, c_n \in \mathbb{C} \delta(t) = e^{it} f(t, w) = \frac{1}{\pi} Re\Big(\frac{1}{1 - w e^{-it}}\Big) f(t,w) f(t,w) \delta(t) \delta(t) - \delta(\theta) a e^{-iNt} \prod_{n=-N}^N (e^{it} - \alpha_n)  \ln|a e^{iNt} \prod_{n=-N}^N (e^{it} - \alpha_n) | = \ln|a| + \sum_{n=-N}^N \ln|e^{it} - \alpha_n|  \int_0^{2 \pi} f(t, w) \ln|\delta(t) - \delta(\theta)| dt =  \ln|a| \int_0^{2 \pi} f(t, w) dt + \sum_{n=-N}^N \int_0^{2 \pi} f(t, w) \ln|e^{it} - \alpha_n| dt |\alpha_n| = 1 \delta(t) = e^{it} \theta \theta \delta(t) = e^{it} \theta \theta","['integration', 'complex-analysis', 'contour-integration', 'fluid-dynamics']"
4,Coloring Julia Sets using Distance Estimation Relative to Zoom Depth,Coloring Julia Sets using Distance Estimation Relative to Zoom Depth,,"Using the distance estimation coloring algorithm learned from here , I was able to color Julia Sets projected on a Riemann sphere, as with this video. However, once I started displaying polynomial matings of Julia Sets , using this coloring algorithm provided inconsistent results, as shown in the first image below. Certain parts are clearer than others, and this is because the polynomial mating brings out deeper parts of the fractal without zooming in , and so using the same distance adjustment makes those zoomed in parts more ""blurry"" than the rest. As such, what I think I need is some sort of algorithm to detect how ""zoomed in"" I am in the Julia set, so I can adjust the distance accordingly. I tried basing it off of how many iterations it takes for the orbit to escape (as the deeper you get, the more iterations it takes for the orbit to escape) but that didn't quite get the intended effect (second image below - certain parts are barely visible). Here is my code for the coloring: for (iter = currentMatingIteration + 1; iter < maxIterations && (w.x * w.x + w.y * w.y < bailout*bailout); iter++) {     d2 *= 4.0 * w2;          // Julia Set algorithm     w = c_2(w) + c;      w2 = w.x * w.x + w.y * w.y;      // Distance checker     if(w2 > maxDist)         break; }  float fineness = 7;     // the higher, the less ""blurry"" //float fineness = 15;  // this is used for the second picture below  float d = sqrt(w2 / d2) * log(w2);  // this is the distance estimation float dist = clamp(sqrt(d * pow(fineness, 2)), 0, 1);   // this is the adjustments I make for coloring  //float dist = clamp(sqrt(d * pow(fineness * (float(iter) / maxIterations), 2)), 0, 1);     // This is my attempt to solve this problem, used in the second picture below My project is here for testing. Edit: While this probably isn't a general solution to figuring out how deeply zoomed one is, what worked for this issue is calculating the derivative during the pull-back part of the mating algorithm, and using that as the initial value for calculating the distance estimation for each Julia Set (thanks to Claude in the comments). The successful result is below: Riemann Sphere Adjustment Without adjustment: With adjustment:","Using the distance estimation coloring algorithm learned from here , I was able to color Julia Sets projected on a Riemann sphere, as with this video. However, once I started displaying polynomial matings of Julia Sets , using this coloring algorithm provided inconsistent results, as shown in the first image below. Certain parts are clearer than others, and this is because the polynomial mating brings out deeper parts of the fractal without zooming in , and so using the same distance adjustment makes those zoomed in parts more ""blurry"" than the rest. As such, what I think I need is some sort of algorithm to detect how ""zoomed in"" I am in the Julia set, so I can adjust the distance accordingly. I tried basing it off of how many iterations it takes for the orbit to escape (as the deeper you get, the more iterations it takes for the orbit to escape) but that didn't quite get the intended effect (second image below - certain parts are barely visible). Here is my code for the coloring: for (iter = currentMatingIteration + 1; iter < maxIterations && (w.x * w.x + w.y * w.y < bailout*bailout); iter++) {     d2 *= 4.0 * w2;          // Julia Set algorithm     w = c_2(w) + c;      w2 = w.x * w.x + w.y * w.y;      // Distance checker     if(w2 > maxDist)         break; }  float fineness = 7;     // the higher, the less ""blurry"" //float fineness = 15;  // this is used for the second picture below  float d = sqrt(w2 / d2) * log(w2);  // this is the distance estimation float dist = clamp(sqrt(d * pow(fineness, 2)), 0, 1);   // this is the adjustments I make for coloring  //float dist = clamp(sqrt(d * pow(fineness * (float(iter) / maxIterations), 2)), 0, 1);     // This is my attempt to solve this problem, used in the second picture below My project is here for testing. Edit: While this probably isn't a general solution to figuring out how deeply zoomed one is, what worked for this issue is calculating the derivative during the pull-back part of the mating algorithm, and using that as the initial value for calculating the distance estimation for each Julia Set (thanks to Claude in the comments). The successful result is below: Riemann Sphere Adjustment Without adjustment: With adjustment:",,"['complex-analysis', 'derivatives', 'coloring', 'fractals']"
5,$\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial u}{\partial y}\right)^2=\left|2\frac{\partial u}{\partial z}\right|^2$,,\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial u}{\partial y}\right)^2=\left|2\frac{\partial u}{\partial z}\right|^2,"I'm reading Complex Analysis by Stein and Shakarchi (page 13). The goal is to prove that $\partial f/\partial z=2\, \partial u/\partial z$ where $f=u+iv$ and $z=x+iy$ . The proof in the book states that $$\begin{align}\det J_F (x_0,y_0)&=\frac{\partial u}{\partial x}\frac{\partial v}{\partial y}-\frac{\partial v}{\partial x}\frac{\partial u}{\partial y}\\&=\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial u}{\partial y}\right)^2\\&\overset{?}{=}\left|2\frac{\partial u}{\partial z}\right|^2.\end{align}$$ I understand everything except for the last step marked with ""?"". What I get instead is $$\begin{align}\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial u}{\partial y}\right)^2&=\frac{\partial u^2}{\partial x^2}+\frac{\partial u^2}{\partial y^2}\\&=\frac{\partial u^2\partial y^2+\partial u^2\partial x^2}{\partial x^2\partial y^2}\\&=\frac{\partial u^2(\partial x^2+\partial y^2)}{\partial x^2\partial y^2}\\&=\frac{\partial u^2\partial z^2}{\partial x^2\partial y^2}\end{align}$$ but I don't understand why should that equal $\left|2\frac{\partial u}{\partial z}\right|^2$ .","I'm reading Complex Analysis by Stein and Shakarchi (page 13). The goal is to prove that where and . The proof in the book states that I understand everything except for the last step marked with ""?"". What I get instead is but I don't understand why should that equal .","\partial f/\partial z=2\, \partial u/\partial z f=u+iv z=x+iy \begin{align}\det J_F (x_0,y_0)&=\frac{\partial u}{\partial x}\frac{\partial v}{\partial y}-\frac{\partial v}{\partial x}\frac{\partial u}{\partial y}\\&=\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial u}{\partial y}\right)^2\\&\overset{?}{=}\left|2\frac{\partial u}{\partial z}\right|^2.\end{align} \begin{align}\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial u}{\partial y}\right)^2&=\frac{\partial u^2}{\partial x^2}+\frac{\partial u^2}{\partial y^2}\\&=\frac{\partial u^2\partial y^2+\partial u^2\partial x^2}{\partial x^2\partial y^2}\\&=\frac{\partial u^2(\partial x^2+\partial y^2)}{\partial x^2\partial y^2}\\&=\frac{\partial u^2\partial z^2}{\partial x^2\partial y^2}\end{align} \left|2\frac{\partial u}{\partial z}\right|^2","['complex-analysis', 'cauchy-riemann-equations']"
6,Show that $\sum\frac{(-1)^{n+1}} {{n}^r} \sum\frac{(-1)^{n+1}} {{n}^s} $ by Abel's rule forms a series that doesn't converge when r+s=1.,Show that  by Abel's rule forms a series that doesn't converge when r+s=1.,\sum\frac{(-1)^{n+1}} {{n}^r} \sum\frac{(-1)^{n+1}} {{n}^s} ,"It is a similar problem to that in Show that the series $\frac{1} {\sqrt{1}} -\frac{1} {\sqrt{2}} +\frac{1} {\sqrt{3}} +\dots$ converges, and its square (formed by Abel's rule) doesn't. . It may provide some hint to the latter. Show that $\frac{1} {{1}^r} -\frac{1} {{2}^r} +\frac{1} {{3}^r} +\dots$ and $\frac{1} {{1}^s} -\frac{1} {{2}^s} +\frac{1} {{3}^s} +\dots$ , where 0 < r < 1, being multiplied by Abel's rule, forms a series (say $\sum \nu_n$ ) that doesn't converge, when r+s=1. Abel's rule: given $\sum a_n, \sum b_n$ , $\sum_{n=0} ^\infty c_n=\sum_{n=0} ^\infty [\sum_{i=0} ^n a_{n-i}b_i]$ is the infinite series gotten from multiplication of two series. Initial steps are similar to those in the post, $(\frac{1} {{1}^r} -\frac{1} {{2}^r} +\frac{1} {{3}^r} +\dots)(\frac{1} {{1}^s} -\frac{1} {{2}^s} +\frac{1} {{3}^s} +\dots)\\ =\frac{1} {{1}^r}\frac{1} {{1}^s}+\dots +[(-\frac{1} {{1}^r} \frac{1} {{(2k)}^s}+\frac{1} {{1}^r} \frac{1} {{(2k+1)}^s} -\frac{1} {{2}^r} \frac{1} {{(2k-1)}^s}+\frac{1} {{2}^r} \frac{1} {{(2k)}^s}+\dots -\frac{1} {{k}^r}\frac{1} {{(k+1)}^s}+\frac{1} {{k}^r}\frac{1} {{(k+2)}^s} -\frac{1} {{(k+1)}^r}\frac{1} {{k}^s}+\frac{1} {{(k+2)}^r}\frac{1} {{k}^s} \dots-\frac{1} {{(2k)}^r}\frac{1} {{1}^s}+ \frac{1} {{(2k+1)}^r}\frac{1} {{1}^s})  +\frac{1} {{(k+1)}^{r+s}}]+\dots,$ where $\sum_{m=1}^{2k}|(-\frac{1} {m^r} \frac{1} {(2k+1-m)^s}+\frac{1} {m^r} \frac{1} {(2k+2-m)^s})| =\sum_{m=1}^{2k}\frac{1} {m^r} \frac{1} {(2k+1-m)^s}(1-\frac{1} {(1+\frac{1}{2k+1-m})^s})\\ =\sum_{m=1}^{2k}\frac{1} {m^r} \frac{1} {(2k+1-m)^s}(s\frac{1}{2k+1-m}+O(\frac{1}{(2k+1-m)^2})) =\sum_{m=1}^{2k}\frac{1} {m^r} \frac{s} {(2k+1-m)^{s+1}},$ for $1-(1+x)^{-s}=-\frac{(-s)}{1!}x-\frac{(-s)(-s-1)}{2!}x^2+\dots.$ We can not easily use $\frac{1}{\sqrt{ab}}>\frac{1}{a+b}$ here, instead we use Taylor expansion. It seems the above sum approximates $\sum_{m=1}^{2k}\frac{1} {k^r} \frac{1} {(k)^{s+1}}\approx \frac{k}{k^{r+s+1}}=\frac{1}{k},$ and so the series (say $\sum \psi_n$ ) it forms diverges as well. But here we are gonna show that the serives diverges more than $\sum \frac{1}{k+1}$ , which we can't yet show in the above post. Let s go near 1-0 (i.e. r+s-0), then $\sum \psi_n$ goes near $\sum_{m=1}^{2k}\frac{1} {m^0} \frac{r+s} {(2k+1-m)^{r+s+1}} =\sum_{m=1}^{2k}\frac{1} {(2k+1-m)^{2}}=\frac{1}{(2k)^2}+\frac{1}{(2k-1)^2}+\dots+\frac{1}{1^2}>\frac{2}{k+1}$ ( A note for myself: for calculation of this sum and the sum in the above post, see Formula for $\frac{1}{(n)^2}+\frac{1}{(n-1)^2}+\dots+\frac{1}{1^2}$. . According to results there, the left side tends to $\frac{\pi^2}{6}$ which is obviously larger than the right side that tends to 0. So $\sum \nu_n\approx \sum_{k=0}^\infty \frac{\pi^2}{6}$ , it doesn't oscillates between two values but oscillates to infinity.) when k $\geq$ 3 (i.e. $\frac{2}{k+1}\leq \frac{1}{2^2}$ ). Therefore when s is near 0, $|\sum \nu_n|>\sum\frac{2}{k+1}-\sum\frac{1}{k+1}$ , which diverges. My question is how to, in general, prove that it the series $\sum \nu_n$ diverges?","It is a similar problem to that in Show that the series $\frac{1} {\sqrt{1}} -\frac{1} {\sqrt{2}} +\frac{1} {\sqrt{3}} +\dots$ converges, and its square (formed by Abel's rule) doesn't. . It may provide some hint to the latter. Show that and , where 0 < r < 1, being multiplied by Abel's rule, forms a series (say ) that doesn't converge, when r+s=1. Abel's rule: given , is the infinite series gotten from multiplication of two series. Initial steps are similar to those in the post, where for We can not easily use here, instead we use Taylor expansion. It seems the above sum approximates and so the series (say ) it forms diverges as well. But here we are gonna show that the serives diverges more than , which we can't yet show in the above post. Let s go near 1-0 (i.e. r+s-0), then goes near ( A note for myself: for calculation of this sum and the sum in the above post, see Formula for $\frac{1}{(n)^2}+\frac{1}{(n-1)^2}+\dots+\frac{1}{1^2}$. . According to results there, the left side tends to which is obviously larger than the right side that tends to 0. So , it doesn't oscillates between two values but oscillates to infinity.) when k 3 (i.e. ). Therefore when s is near 0, , which diverges. My question is how to, in general, prove that it the series diverges?","\frac{1} {{1}^r} -\frac{1} {{2}^r} +\frac{1} {{3}^r} +\dots \frac{1} {{1}^s} -\frac{1} {{2}^s} +\frac{1} {{3}^s} +\dots \sum \nu_n \sum a_n, \sum b_n \sum_{n=0} ^\infty c_n=\sum_{n=0} ^\infty [\sum_{i=0} ^n a_{n-i}b_i] (\frac{1} {{1}^r} -\frac{1} {{2}^r} +\frac{1} {{3}^r} +\dots)(\frac{1} {{1}^s} -\frac{1} {{2}^s} +\frac{1} {{3}^s} +\dots)\\
=\frac{1} {{1}^r}\frac{1} {{1}^s}+\dots
+[(-\frac{1} {{1}^r} \frac{1} {{(2k)}^s}+\frac{1} {{1}^r} \frac{1} {{(2k+1)}^s}
-\frac{1} {{2}^r} \frac{1} {{(2k-1)}^s}+\frac{1} {{2}^r} \frac{1} {{(2k)}^s}+\dots
-\frac{1} {{k}^r}\frac{1} {{(k+1)}^s}+\frac{1} {{k}^r}\frac{1} {{(k+2)}^s}
-\frac{1} {{(k+1)}^r}\frac{1} {{k}^s}+\frac{1} {{(k+2)}^r}\frac{1} {{k}^s}
\dots-\frac{1} {{(2k)}^r}\frac{1} {{1}^s}+ \frac{1} {{(2k+1)}^r}\frac{1} {{1}^s})
 +\frac{1} {{(k+1)}^{r+s}}]+\dots, \sum_{m=1}^{2k}|(-\frac{1} {m^r} \frac{1} {(2k+1-m)^s}+\frac{1} {m^r} \frac{1} {(2k+2-m)^s})|
=\sum_{m=1}^{2k}\frac{1} {m^r} \frac{1} {(2k+1-m)^s}(1-\frac{1} {(1+\frac{1}{2k+1-m})^s})\\
=\sum_{m=1}^{2k}\frac{1} {m^r} \frac{1} {(2k+1-m)^s}(s\frac{1}{2k+1-m}+O(\frac{1}{(2k+1-m)^2}))
=\sum_{m=1}^{2k}\frac{1} {m^r} \frac{s} {(2k+1-m)^{s+1}}, 1-(1+x)^{-s}=-\frac{(-s)}{1!}x-\frac{(-s)(-s-1)}{2!}x^2+\dots. \frac{1}{\sqrt{ab}}>\frac{1}{a+b} \sum_{m=1}^{2k}\frac{1} {k^r} \frac{1} {(k)^{s+1}}\approx \frac{k}{k^{r+s+1}}=\frac{1}{k}, \sum \psi_n \sum \frac{1}{k+1} \sum \psi_n \sum_{m=1}^{2k}\frac{1} {m^0} \frac{r+s} {(2k+1-m)^{r+s+1}}
=\sum_{m=1}^{2k}\frac{1} {(2k+1-m)^{2}}=\frac{1}{(2k)^2}+\frac{1}{(2k-1)^2}+\dots+\frac{1}{1^2}>\frac{2}{k+1} \frac{\pi^2}{6} \sum \nu_n\approx \sum_{k=0}^\infty \frac{\pi^2}{6} \geq \frac{2}{k+1}\leq \frac{1}{2^2} |\sum \nu_n|>\sum\frac{2}{k+1}-\sum\frac{1}{k+1} \sum \nu_n","['complex-analysis', 'absolute-convergence']"
7,Convergence of $\sum_{n=1}^\infty 2^n\sin\frac{1}{3^nz}$,Convergence of,\sum_{n=1}^\infty 2^n\sin\frac{1}{3^nz},"The problem is: prove $\sum_{n=1}^\infty 2^n\sin\frac{1}{3^nz}$ converges absolutely for all $z\neq 0$ , but does not converge uniformly near $z=0$ . Proof : for all $z\neq 0$ $$\left|2^n\sin\frac{1}{3^nz}-2^n\frac{1}{3^nz}\right| = \left| 2^n\left(     -\frac{(\frac{1}{3^nz})^3}{3!}+\frac{(\frac{1}{3^nz})^5}{5!}\dots \right) \right|, \ \ \ \ (1)$$ $\exists~ N$ such that when n>N, $\frac{1/z}{3^n}<1$ , so that (1) is less than $$\left| 2^n\left(     \frac{|\frac{1}{3^nz}|^3}{3!}+\frac{|\frac{1}{3^nz}|^5}{5!}\dots \right) \right| <\left| \frac{2^n}{3^nz}\left(     \frac{|\frac{1}{3^nz}|^2}{1-|\frac{1}{3^nz}|^2} \right) \right| <\frac{2^n}{3^n}\left| \frac{1}{z}\left(     \frac{|\frac{1}{3^nz}|^2}{1-|\frac{1}{3^nz}|^2} \right) \right|, $$ $\forall~ \epsilon, \exists~ N_1>-\log(\epsilon^{1/2} z^{3/2})$ , such that when $n>N_2=\max\{N, N_1\}$ , $|\frac{1}{z}||\frac{1}{3^nz}|^2<\epsilon$ , and so (1) is less $\frac{2^n}{3^n}\epsilon$ . Therefore, we have $N_2(\epsilon)$ satisfying that $\forall~ p,$ $$\left|\sum_{n=N_2}^{N_2+p} 2^n\sin\frac{1}{3^nz}-\sum_{n=N_2}^{N_2+p} 2^n\frac{1}{3^nz}\right| <\sum_{n=N_2}^{N_2+p} \left|2^n\sin\frac{1}{3^nz}-2^n\frac{1}{3^nz}\right|\ \ \ \ (2)\\ <\sum_{n=N_2}^{N_2+p}\frac{2^n}{3^n}\epsilon \leq 2\epsilon, $$ and so $\sum_{n=1}^\infty 2^n\sin\frac{1}{3^nz}$ converges absolutely. (A step seems to be missing. One should, instead of $\sum_{n=N_2}^{N_2+p}\frac{2^n}{3^n}$ , use something like 2/z (plus a constant), which is the limit of the former.) $\blacksquare$ A possibly trivial question is whether it is proper to prove this way: given n sufficiently large, $u_n<f(n)\epsilon$ (different from that $u_n<\epsilon$ , or that $u_n/f(n)<\epsilon$ and so $u_n<f(n)\epsilon$ ). There are other questions that I may post somewhere else. The following is a proof that the series doesn't converge uniformly. It's unnecessarily for answering my questions , but I put it here for completeness of proof. Proof : However large $N_2$ , we can find $n_0$ > $N_2$ and $z=\frac{2}{\pi 3^{n_0}}$ such that $2^{n_0}\sin\frac{1}{3^{n_0}z}=2^{n_0}$ , and so (say the limit function is $f(z)=\frac{2}{z}+C$ , where $C$ is a constant; I suddenly realize C seems also to be a function of z, that could cause some issues), $$\left|\sum_{n=1}^{\infty} 2^n\sin\frac{1}{3^nz}-f(z)\right| >\left|\sum_{n=N_2}^{N_2+p} 2^n\sin\frac{1}{3^nz}-\sum_{n=N_2}^{N_2+p} 2^n\frac{1}{3^nz}-C\right|>|2^{n_0}-\frac{2}{z}-C|>\epsilon.$$","The problem is: prove converges absolutely for all , but does not converge uniformly near . Proof : for all such that when n>N, , so that (1) is less than , such that when , , and so (1) is less . Therefore, we have satisfying that and so converges absolutely. (A step seems to be missing. One should, instead of , use something like 2/z (plus a constant), which is the limit of the former.) A possibly trivial question is whether it is proper to prove this way: given n sufficiently large, (different from that , or that and so ). There are other questions that I may post somewhere else. The following is a proof that the series doesn't converge uniformly. It's unnecessarily for answering my questions , but I put it here for completeness of proof. Proof : However large , we can find > and such that , and so (say the limit function is , where is a constant; I suddenly realize C seems also to be a function of z, that could cause some issues),","\sum_{n=1}^\infty 2^n\sin\frac{1}{3^nz} z\neq 0 z=0 z\neq 0 \left|2^n\sin\frac{1}{3^nz}-2^n\frac{1}{3^nz}\right|
= \left|
2^n\left(
    -\frac{(\frac{1}{3^nz})^3}{3!}+\frac{(\frac{1}{3^nz})^5}{5!}\dots
\right)
\right|, \ \ \ \ (1) \exists~ N \frac{1/z}{3^n}<1 \left|
2^n\left(
    \frac{|\frac{1}{3^nz}|^3}{3!}+\frac{|\frac{1}{3^nz}|^5}{5!}\dots
\right)
\right|
<\left|
\frac{2^n}{3^nz}\left(
    \frac{|\frac{1}{3^nz}|^2}{1-|\frac{1}{3^nz}|^2}
\right)
\right|
<\frac{2^n}{3^n}\left|
\frac{1}{z}\left(
    \frac{|\frac{1}{3^nz}|^2}{1-|\frac{1}{3^nz}|^2}
\right)
\right|,
 \forall~ \epsilon, \exists~ N_1>-\log(\epsilon^{1/2} z^{3/2}) n>N_2=\max\{N, N_1\} |\frac{1}{z}||\frac{1}{3^nz}|^2<\epsilon \frac{2^n}{3^n}\epsilon N_2(\epsilon) \forall~ p, \left|\sum_{n=N_2}^{N_2+p} 2^n\sin\frac{1}{3^nz}-\sum_{n=N_2}^{N_2+p} 2^n\frac{1}{3^nz}\right|
<\sum_{n=N_2}^{N_2+p} \left|2^n\sin\frac{1}{3^nz}-2^n\frac{1}{3^nz}\right|\ \ \ \ (2)\\
<\sum_{n=N_2}^{N_2+p}\frac{2^n}{3^n}\epsilon
\leq 2\epsilon,
 \sum_{n=1}^\infty 2^n\sin\frac{1}{3^nz} \sum_{n=N_2}^{N_2+p}\frac{2^n}{3^n} \blacksquare u_n<f(n)\epsilon u_n<\epsilon u_n/f(n)<\epsilon u_n<f(n)\epsilon N_2 n_0 N_2 z=\frac{2}{\pi 3^{n_0}} 2^{n_0}\sin\frac{1}{3^{n_0}z}=2^{n_0} f(z)=\frac{2}{z}+C C \left|\sum_{n=1}^{\infty} 2^n\sin\frac{1}{3^nz}-f(z)\right|
>\left|\sum_{n=N_2}^{N_2+p} 2^n\sin\frac{1}{3^nz}-\sum_{n=N_2}^{N_2+p} 2^n\frac{1}{3^nz}-C\right|>|2^{n_0}-\frac{2}{z}-C|>\epsilon.","['complex-analysis', 'absolute-convergence']"
8,Trouble on Factorizing,Trouble on Factorizing,,"I have trouble factoring $ a^2+ab+b^2 $ . It can be done easily using $\omega$ , which is a complex cube root of unity with non-zero imaginary part- $$ a^2+ab+b^2 = a^2 - \omega ab - {\omega}^2ab+{\omega}^3b^2 = a(a-\omega b) -\omega ^2b(a-\omega b) = (a-\omega ^2b)(a-\omega b) $$ But the following is also a way to factor- $$ a^2+ab+b^2 = (a+b)^2-ab = (a+b-\sqrt {ab})(a+b+\sqrt {ab}) $$ But why is it that this factorization not so much popular while the one with complex factors is more popular? Can anybody explain me with an example? What I think is it is probably because $\sqrt{ab}$ can't be real all the time. Thanks!","I have trouble factoring . It can be done easily using , which is a complex cube root of unity with non-zero imaginary part- But the following is also a way to factor- But why is it that this factorization not so much popular while the one with complex factors is more popular? Can anybody explain me with an example? What I think is it is probably because can't be real all the time. Thanks!", a^2+ab+b^2  \omega  a^2+ab+b^2 = a^2 - \omega ab - {\omega}^2ab+{\omega}^3b^2 = a(a-\omega b) -\omega ^2b(a-\omega b) = (a-\omega ^2b)(a-\omega b)   a^2+ab+b^2 = (a+b)^2-ab = (a+b-\sqrt {ab})(a+b+\sqrt {ab})  \sqrt{ab},"['complex-analysis', 'factoring']"
9,What is the value of $1 -\omega^h + \omega^{2h} -...+(-1)^{n-1} \omega^{(n-1)h}$ when $\omega$ is a root of unity?,What is the value of  when  is a root of unity?,1 -\omega^h + \omega^{2h} -...+(-1)^{n-1} \omega^{(n-1)h} \omega,"I'm reading Ahlfors' complex analysis book. One of the problems in the book says as follows What is the value of $1 -\omega^h + \omega^{2h} -...+(-1)^{n-1} \omega^{(n-1)h}$ ? where $h$ is some integer and $ \omega = \cos\left(\frac{2\pi}{n}\right) + i \sin \left(\frac{2 \pi}{n}\right)$ , for some fixed $n \in \mathbb{N}$ , is one of the $n$ -th roots of unity. The first thing I noticed is that I could write the series in terms of $-\omega^h$ as $$ 1 +\left(-\omega^h\right) + \left(-\omega^h\right)^2 +...+\left(-\omega^h\right)^{n-1} $$ Inspired by this, I separated the problem into 2 cases If $h$ is an integer of the form $ h = \frac{n(2k+1)}{2}$ for some $k \in \mathbb{Z}$ , then I get the following $$ -\omega^h = -\cos\left(\frac{2\pi}{n}h\right) - i \sin \left(\frac{2 \pi}{n}h\right)= -\cos\left(\pi + 2\pi k\right) - i \sin \left(\pi + 2\pi k\right) = 1 $$ which means the sum evaluates to $\sum_{j=0}^{n-1} 1 = n$ . If $-\omega^h \neq 1$ , then using the fact that the sum in question is a sum of the first $n$ terms in a geometric series, I can write $$ 1 -\omega^h + \omega^{2h} -...+(-1)^n \omega^{(n-1)h} = \frac{1 - \left(-\omega^h\right)^n}{1 - \left(-\omega^h\right)} = \frac{1 - (-1)^n\omega^{nh}}{1 +\omega^h}  $$ and since $h$ is an integer, I see that $$ \omega^{nh} = \cos\left(\frac{2\pi}{n}nh\right) + i \sin \left(\frac{2 \pi}{n}nh\right) = \cos\left(2\pi h\right) + i \sin \left(2\pi h\right) = 1 $$ which means the sum simplifies to $\frac{1 - (-1)^n}{1 +\omega^h}$ . From here I see that if $n$ is odd the sum will become $0$ because of the numerator, but for the case of $n$ being an even number, I don't see a way to simplify $\frac{2}{1 +\omega^h}$ more than it already is. Is my solution correct? And if so, is this as simplified as I can write the solution, or can it still be simplified further? Thank you very much!","I'm reading Ahlfors' complex analysis book. One of the problems in the book says as follows What is the value of ? where is some integer and , for some fixed , is one of the -th roots of unity. The first thing I noticed is that I could write the series in terms of as Inspired by this, I separated the problem into 2 cases If is an integer of the form for some , then I get the following which means the sum evaluates to . If , then using the fact that the sum in question is a sum of the first terms in a geometric series, I can write and since is an integer, I see that which means the sum simplifies to . From here I see that if is odd the sum will become because of the numerator, but for the case of being an even number, I don't see a way to simplify more than it already is. Is my solution correct? And if so, is this as simplified as I can write the solution, or can it still be simplified further? Thank you very much!","1 -\omega^h + \omega^{2h} -...+(-1)^{n-1} \omega^{(n-1)h} h  \omega = \cos\left(\frac{2\pi}{n}\right) + i \sin \left(\frac{2 \pi}{n}\right) n \in \mathbb{N} n -\omega^h 
1 +\left(-\omega^h\right) + \left(-\omega^h\right)^2 +...+\left(-\omega^h\right)^{n-1}
 h  h = \frac{n(2k+1)}{2} k \in \mathbb{Z} 
-\omega^h = -\cos\left(\frac{2\pi}{n}h\right) - i \sin \left(\frac{2 \pi}{n}h\right)= -\cos\left(\pi + 2\pi k\right) - i \sin \left(\pi + 2\pi k\right) = 1
 \sum_{j=0}^{n-1} 1 = n -\omega^h \neq 1 n 
1 -\omega^h + \omega^{2h} -...+(-1)^n \omega^{(n-1)h} = \frac{1 - \left(-\omega^h\right)^n}{1 - \left(-\omega^h\right)} = \frac{1 - (-1)^n\omega^{nh}}{1 +\omega^h} 
 h 
\omega^{nh} = \cos\left(\frac{2\pi}{n}nh\right) + i \sin \left(\frac{2 \pi}{n}nh\right) = \cos\left(2\pi h\right) + i \sin \left(2\pi h\right) = 1
 \frac{1 - (-1)^n}{1 +\omega^h} n 0 n \frac{2}{1 +\omega^h}","['complex-analysis', 'complex-numbers', 'solution-verification', 'roots-of-unity']"
10,Moduli Space of Tori,Moduli Space of Tori,,"I'm looking at an exercise that reads: Problem. Let $A = \begin{bmatrix}a & b\\c & d\end{bmatrix} \in GL(2, \mathbb{C})$ and $\Lambda = \langle z \mapsto z + \omega_1, z \mapsto z + \omega_2\rangle$ with $\omega_1, \omega_2$ linearly independent over $\mathbb{R}$ . Prove that if $\Lambda = \langle z \mapsto z + \omega_1', z \mapsto z + \omega_2'\rangle$ where $$ \begin{bmatrix}\omega_1'\\\omega_2'\end{bmatrix} = A\begin{bmatrix}\omega_1\\\omega_2\end{bmatrix} $$ then $A \in GL(2, \mathbb{Z})$ with $\det(A) = \pm1$ . Now show that the moduli space of tori, defined to be the space of all conformal equivalence classes of tori, is $\mathbb{H}/PSL(2, \mathbb{Z})$ . I've done the first bit, but not sure how to proceed with the second. In particular, I'm not sure how to visualise $\mathbb{H}/PSL(2, \mathbb{Z})$ and hence find a bijection between that and the equivalence classes.","I'm looking at an exercise that reads: Problem. Let and with linearly independent over . Prove that if where then with . Now show that the moduli space of tori, defined to be the space of all conformal equivalence classes of tori, is . I've done the first bit, but not sure how to proceed with the second. In particular, I'm not sure how to visualise and hence find a bijection between that and the equivalence classes.","A = \begin{bmatrix}a & b\\c & d\end{bmatrix} \in GL(2, \mathbb{C}) \Lambda = \langle z \mapsto z + \omega_1, z \mapsto z + \omega_2\rangle \omega_1, \omega_2 \mathbb{R} \Lambda = \langle z \mapsto z + \omega_1', z \mapsto z + \omega_2'\rangle 
\begin{bmatrix}\omega_1'\\\omega_2'\end{bmatrix} = A\begin{bmatrix}\omega_1\\\omega_2\end{bmatrix}
 A \in GL(2, \mathbb{Z}) \det(A) = \pm1 \mathbb{H}/PSL(2, \mathbb{Z}) \mathbb{H}/PSL(2, \mathbb{Z})","['complex-analysis', 'moduli-space']"
11,Showing that a given covering is not normal,Showing that a given covering is not normal,,"This is a question regarding exercise 5.6 of Forster's Lectures on Riemann surfaces. We have $X=\mathbb{C}\setminus\{0,1\}$ , $Y=\mathbb{C}\setminus\{0,\pm i,\pm i\sqrt{2}\}$ , $p\colon Y\to X$ given by $p(z)=(z^2+1)^2$ . It is easy to see that this defines an (unbranched) 4-sheeted covering map, and that $\varphi\colon z\mapsto -z$ is a deck transformation. (1) I want to proof that apart from $\varphi$ and the identity, there are no other deck transformations for $p$ . One way to see this is as follows: We can extend $p$ to a branched holomorphic covering map $\overline{p}\colon \hat{\mathbb{C}}=\mathbb{C}\cup\{\infty\}\to\hat{\mathbb{C}}$ , since $p$ is a meromorphic function. Then one can show that any deck transformation of $p$ extends to a deck transformation of $\overline{p}$ by Riemann's theorem on removable singularities. Now one notes that a deck transformation of a branched covering map must preserve the ramification index to see that our list of deck transformations was exhaustive. My question is: Is there a way to prove statement (1) without going to the extension of $p$ to an unbranched covering map?**","This is a question regarding exercise 5.6 of Forster's Lectures on Riemann surfaces. We have , , given by . It is easy to see that this defines an (unbranched) 4-sheeted covering map, and that is a deck transformation. (1) I want to proof that apart from and the identity, there are no other deck transformations for . One way to see this is as follows: We can extend to a branched holomorphic covering map , since is a meromorphic function. Then one can show that any deck transformation of extends to a deck transformation of by Riemann's theorem on removable singularities. Now one notes that a deck transformation of a branched covering map must preserve the ramification index to see that our list of deck transformations was exhaustive. My question is: Is there a way to prove statement (1) without going to the extension of to an unbranched covering map?**","X=\mathbb{C}\setminus\{0,1\} Y=\mathbb{C}\setminus\{0,\pm i,\pm i\sqrt{2}\} p\colon Y\to X p(z)=(z^2+1)^2 \varphi\colon z\mapsto -z \varphi p p \overline{p}\colon \hat{\mathbb{C}}=\mathbb{C}\cup\{\infty\}\to\hat{\mathbb{C}} p p \overline{p} p","['complex-analysis', 'riemann-surfaces', 'covering-spaces']"
12,Let $f$ be an entire function such that $|f'(z)|\leq |f(z)|$ for all $z$. Show that $f(z)=ae^{cz}$,Let  be an entire function such that  for all . Show that,f |f'(z)|\leq |f(z)| z f(z)=ae^{cz},"LEt $f$ be an entire function such that $|f'(z)|\leq |f(z)|$ for all $z$ . Show that $f(z)=ae^{cz}$ My proof: Consider $g(z)=\frac{f'(z)}{f(z)}$ This function is bounded by 1 per our inequality. It is holomorphic everywhere except at zeroes of $f(z)$ however, these must be removable singularities as $g(z)$ is bounded around them. Thus $g(z)$ is entire and bounded (or can be extended to be such). Thus by louvile theorem it is a constant funciton. Hence $f'(z)=af(z)$ for all $z$ that are not zeroes of $f$ , but it also works for zeroes as our inequality implies that $f(z)=0 \implies f'(z)=0$ . Thus we get that $f^{(n)}(z)=a^nf(z)$ Hence looking the the taylors series we find that it is of the form $\Sigma \frac{f(0)((\frac{z}{a})^n}{n!}=f(0)e^{z/a}$ and this conclued our proofs.","LEt be an entire function such that for all . Show that My proof: Consider This function is bounded by 1 per our inequality. It is holomorphic everywhere except at zeroes of however, these must be removable singularities as is bounded around them. Thus is entire and bounded (or can be extended to be such). Thus by louvile theorem it is a constant funciton. Hence for all that are not zeroes of , but it also works for zeroes as our inequality implies that . Thus we get that Hence looking the the taylors series we find that it is of the form and this conclued our proofs.",f |f'(z)|\leq |f(z)| z f(z)=ae^{cz} g(z)=\frac{f'(z)}{f(z)} f(z) g(z) g(z) f'(z)=af(z) z f f(z)=0 \implies f'(z)=0 f^{(n)}(z)=a^nf(z) \Sigma \frac{f(0)((\frac{z}{a})^n}{n!}=f(0)e^{z/a},"['complex-analysis', 'solution-verification']"
13,"Maximize $u_x(0)$ for a harmonic function $u:D\rightarrow [0,1]$",Maximize  for a harmonic function,"u_x(0) u:D\rightarrow [0,1]","If $u$ is a harmonic function from $D$ to $[0,1]$ , where $D\subset\mathbb{R}^2$ is the open unit disk centered at $0$ .  What is the maximum of $u_x(0)$ ? My solution: first we assume that $U\supset\overline{D}$ is an open ball and $u:U\rightarrow[0,1]$ is harmonic on $U$ , then there exists an analytic function $f:U\rightarrow\mathbb{C}$ such that $\text{Re }f=u$ on $U$ . The Schwartz integral formula says $$f(z)=\int_0^{2\pi}u(\xi)\frac{\xi+z}{\xi-z}\frac{d\theta}{2\pi}+iK$$ if $z\in D$ , where $\xi=e^{i\theta}$ and $K\in\mathbb{R}$ is a constant. We differentiate this with respect to $z$ , $$f'(z)=\int_0^{2\pi}u(\xi)\frac{2\xi}{(\xi-z)^2}\frac{d\theta}{2\pi}.$$ Take $z=0$ , we have $$f'(0)=\int_0^{2\pi}u(\xi)\frac{2}{\xi}\frac{d\theta}{2\pi}.$$ Hence $$u_x(0)=\int_0^{2\pi}u(e^{i\theta})\cos\theta\,\frac{d\theta}{\pi}.$$ Since $u(e^{i\theta})\in[0,1]$ , the maximum of this integral is $\frac{2}{\pi}$ . If instead $u$ is a harmonic function from $D$ to $[0,1]$ , then what we have shown implies that for any $r\in(0,1),$ we have $ru_x(0)\leq\frac{2}{\pi}$ , therefore, $u_x(0)\leq\frac{2}{\pi}$ . This maximum can be attained: simply stipulate that $u(e^{i\theta})=1$ if $\theta\in[-\pi/2,\pi/2]$ and $u(e^{i\theta})=0$ if $\theta\in(\pi/2,3\pi/2)$ , then use the Poisson's formula with this boundary condition to find such $u$ . Therefore, the maximum is $\frac{2}{\pi}$ . My question: is my solution correct and is there some way to do this without complex analysis? For example if we would like to generalize to $n$ -dimensions. Thanks!","If is a harmonic function from to , where is the open unit disk centered at .  What is the maximum of ? My solution: first we assume that is an open ball and is harmonic on , then there exists an analytic function such that on . The Schwartz integral formula says if , where and is a constant. We differentiate this with respect to , Take , we have Hence Since , the maximum of this integral is . If instead is a harmonic function from to , then what we have shown implies that for any we have , therefore, . This maximum can be attained: simply stipulate that if and if , then use the Poisson's formula with this boundary condition to find such . Therefore, the maximum is . My question: is my solution correct and is there some way to do this without complex analysis? For example if we would like to generalize to -dimensions. Thanks!","u D [0,1] D\subset\mathbb{R}^2 0 u_x(0) U\supset\overline{D} u:U\rightarrow[0,1] U f:U\rightarrow\mathbb{C} \text{Re }f=u U f(z)=\int_0^{2\pi}u(\xi)\frac{\xi+z}{\xi-z}\frac{d\theta}{2\pi}+iK z\in D \xi=e^{i\theta} K\in\mathbb{R} z f'(z)=\int_0^{2\pi}u(\xi)\frac{2\xi}{(\xi-z)^2}\frac{d\theta}{2\pi}. z=0 f'(0)=\int_0^{2\pi}u(\xi)\frac{2}{\xi}\frac{d\theta}{2\pi}. u_x(0)=\int_0^{2\pi}u(e^{i\theta})\cos\theta\,\frac{d\theta}{\pi}. u(e^{i\theta})\in[0,1] \frac{2}{\pi} u D [0,1] r\in(0,1), ru_x(0)\leq\frac{2}{\pi} u_x(0)\leq\frac{2}{\pi} u(e^{i\theta})=1 \theta\in[-\pi/2,\pi/2] u(e^{i\theta})=0 \theta\in(\pi/2,3\pi/2) u \frac{2}{\pi} n","['complex-analysis', 'harmonic-functions']"
14,Why is this map between Riemann surfaces a covering map?,Why is this map between Riemann surfaces a covering map?,,"In Donaldson's book http://wwwf.imperial.ac.uk/~skdona/RSPREF.PDF Theorem 3 of Chapter 6 asserts that, given a compact Riemann surface $X$ with a holomorphic 1-form with no zeros $\omega$ , there is a lattice $\Lambda \subset \mathbb{C}$ and isomorphism $\mathbb{C}/\Lambda \cong X$ identifying $\omega$ with $dz$ . The proof starts by considering the universal covering space $p:\tilde{X} \to X$ . We then note that there exists a holomorphic function $F: \tilde{X} \to \mathbb{C}$ such that $dF = p^*\omega$ . This last equation implies in particular that $F$ is a local homeomorphism. The next claim is that $F$ is actually a covering map. I am confused because the proof given in the book doesn't seem to show that $F$ is surjective. Is there a simple way of seeing that?","In Donaldson's book http://wwwf.imperial.ac.uk/~skdona/RSPREF.PDF Theorem 3 of Chapter 6 asserts that, given a compact Riemann surface with a holomorphic 1-form with no zeros , there is a lattice and isomorphism identifying with . The proof starts by considering the universal covering space . We then note that there exists a holomorphic function such that . This last equation implies in particular that is a local homeomorphism. The next claim is that is actually a covering map. I am confused because the proof given in the book doesn't seem to show that is surjective. Is there a simple way of seeing that?",X \omega \Lambda \subset \mathbb{C} \mathbb{C}/\Lambda \cong X \omega dz p:\tilde{X} \to X F: \tilde{X} \to \mathbb{C} dF = p^*\omega F F F,['general-topology']
15,An exercise from Ahlfors' book Complex Analysis,An exercise from Ahlfors' book Complex Analysis,,"this is Exercise 4, Section 3.2 (page 26) from Ahlfors book (First Edition): Show that any four distinct points can be carried by a linear transformation (i.e. Mobius transformation) to positions $1,-1,k,-k$ , where the value of $k$ depends on the points? How many solutions are there, and how they related? My attempt: If the points are $z_1,z_2,z_3,z_4$ , then it suffices to find a linear transformation $T$ such that $$ \begin{cases} T(z_1)+T(z_2)=0\\ T(z_3)+T(z_4)=0 \end{cases} $$ Once we find such transformation, we can rotate and change proportion of its image to obtain the desired result. How to prove the existence of such transformation? and what is the answer of the rest of the question? Thanks.","this is Exercise 4, Section 3.2 (page 26) from Ahlfors book (First Edition): Show that any four distinct points can be carried by a linear transformation (i.e. Mobius transformation) to positions , where the value of depends on the points? How many solutions are there, and how they related? My attempt: If the points are , then it suffices to find a linear transformation such that Once we find such transformation, we can rotate and change proportion of its image to obtain the desired result. How to prove the existence of such transformation? and what is the answer of the rest of the question? Thanks.","1,-1,k,-k k z_1,z_2,z_3,z_4 T 
\begin{cases}
T(z_1)+T(z_2)=0\\
T(z_3)+T(z_4)=0
\end{cases}
",['complex-analysis']
16,Find unknown factor in series so it converges to a given value,Find unknown factor in series so it converges to a given value,,"I'm trying to find $F(z)$ such that: $$\lim_{N \to\infty} \sum_{n=1}^N F\left(\exp\bigg(\frac{2 \pi i n}{N}\bigg)\right) \cdot \log\left|\exp\bigg(\frac{2 \pi i n}{N}\bigg) - \exp(i \theta)\right| = \\\log|a \exp(i \phi) - \exp(i \theta)| $$ where $a \in (0, 1)$ is fixed. I thought I could express this as an integral: $$\begin{matrix}\displaystyle \int_0^{2\pi} F\big(\exp(it)\big) \log|\exp(it) - \exp(i \theta)| dt &= \log|a \exp(i \phi) - \exp(i \theta)| \\ \displaystyle\oint F(z) \log|z - \exp(i \theta)| \frac{dz}{iz} &= \log|a \exp(i \phi) - \exp(i \theta)| \\ \end{matrix}$$ in which case $$F(z) = \frac{1}{2 \pi} \frac{z}{(z - a \exp(i \phi))}$$ However when I plug in this $F(z)$ and do some example partial sums I get values which are not close to the expected values and are not even off by a constant factor, which makes me think I've screwed something up.","I'm trying to find such that: where is fixed. I thought I could express this as an integral: in which case However when I plug in this and do some example partial sums I get values which are not close to the expected values and are not even off by a constant factor, which makes me think I've screwed something up.","F(z) \lim_{N \to\infty} \sum_{n=1}^N F\left(\exp\bigg(\frac{2 \pi i n}{N}\bigg)\right) \cdot \log\left|\exp\bigg(\frac{2 \pi i n}{N}\bigg) - \exp(i \theta)\right| = \\\log|a \exp(i \phi) - \exp(i \theta)|  a \in (0, 1) \begin{matrix}\displaystyle
\int_0^{2\pi} F\big(\exp(it)\big) \log|\exp(it) - \exp(i \theta)| dt &= \log|a \exp(i \phi) - \exp(i \theta)| \\
\displaystyle\oint F(z) \log|z - \exp(i \theta)| \frac{dz}{iz} &= \log|a \exp(i \phi) - \exp(i \theta)| \\
\end{matrix} F(z) = \frac{1}{2 \pi} \frac{z}{(z - a \exp(i \phi))} F(z)","['integration', 'sequences-and-series', 'complex-analysis']"
17,Converges uniformly on an arbitrary closed disc implies on every compact subsets,Converges uniformly on an arbitrary closed disc implies on every compact subsets,,"Suppose that we have a given sequence of functions $(f_n)_{n\geq 0}$ . The goal is to show that it converges uniformly on every compact subsets of $\mathbb{C}$ . Let $R>0$ be arbitrary, and define, say, $C_R=\{z\in \mathbb{C}\mid |z-1|\leq R\}$ . If one has shown that $(f_n)_{n\geq 0}$ converges uniformly on $C_R$ , how do you conclude mathematically that it then converges uniformly on every compact subsets of $\mathbb{C}$ ? I can't find a correct way to conclude: obviously, I would just say that $R$ could be taken arbitrarily large, but in this case, what's been shown, is that it actually converges on every compact subsets containing $1$ . See the definition of $C_R$ , which is a closed disc around $1$ with centre $R$ .","Suppose that we have a given sequence of functions . The goal is to show that it converges uniformly on every compact subsets of . Let be arbitrary, and define, say, . If one has shown that converges uniformly on , how do you conclude mathematically that it then converges uniformly on every compact subsets of ? I can't find a correct way to conclude: obviously, I would just say that could be taken arbitrarily large, but in this case, what's been shown, is that it actually converges on every compact subsets containing . See the definition of , which is a closed disc around with centre .",(f_n)_{n\geq 0} \mathbb{C} R>0 C_R=\{z\in \mathbb{C}\mid |z-1|\leq R\} (f_n)_{n\geq 0} C_R \mathbb{C} R 1 C_R 1 R,"['complex-analysis', 'proof-writing', 'solution-verification', 'uniform-convergence', 'alternative-proof']"
18,Extension of a map holomorphic on the unit disk to map holomorphic on the complex plane,Extension of a map holomorphic on the unit disk to map holomorphic on the complex plane,,"I want to prove a statement regarding the holomorphic extension of a function holomorphic on the unit disk. Let $D \subset \mathbb{C}$ be the (open) unit disk and $f: \bar{D} \to > \mathbb{C}$ be a continous map, such that $f$ restricted to $D$ is   holomorphic and $|f(z)|=1$ for all $z \in \partial D$ . Show that $f$ can be extended to a function holomorphic on $\mathbb{C}$ up to   finitely many isolated singularities, i.e. there are finitely many   points $z_1,..., z_n \in \mathbb{C}$ and a holomorphic function $g:  \mathbb{C} \setminus \{z_1,...,z_n \} \to \mathbb{C}$ such that $f=g$ on $D$ . Let $C_0=\partial D$ . Then $C_0$ is the unit circle. Consider $f|_D: D \to \mathbb{C}$ . Then $f|_D$ is holomorphic because $f$ is holomorphic. Let $K \subset C_0$ be a circular arc. Because $|f(z)|=1 $ for all $z \in \partial D$ it follows $f(K) \subset C_0$ . Let $\sigma_0$ be the inversion with respect to $C_0$ . Consider \begin{align*} g: D \cup K \cup \sigma_0(D),  \ F(z)=\begin{cases} f(z)                       & , \ z \in D          \\ \sigma_0(f(\sigma_0(z)))   & , \ z \in \sigma_0(G) \\ \sigma_0(f(\sigma_0(z)))   & , \ z \in K     \end{cases} \end{align*} Then $f(z)=\sigma_0(f(\sigma_0(z)))$ for all $z \in K$ . Because $f|_D$ can be extended to a function that is conitnous on $\bar{D}$ it follows from the Schwarz reflection principle that the function $g$ is holomorphic. The function $g$ has a singularity at $a \in \mathbb{C}$ if and only if $a\in \sigma_0(G)$ and $f(\sigma_0(a))=0$ . Define $S:=\{z \in \sigma_0(D) \ | \ f(\sigma_0(z))=0 \}$ . Then $S$ is the set of singularities of $g$ . Suppose that $S$ contains infinitely many elements. Because $\sigma_0$ is bijective it follows that there are infinitely many elements $z \in D$ such that $f(z)=0$ . Thus $f$ has infinitely many zeros. For every zero of order $m \geq 1$ there is a neighborhood and a holomorphic function $h$ such that $f(z)=(h(z))^m$ in that neighborhood. But I do not see how to proceed.","I want to prove a statement regarding the holomorphic extension of a function holomorphic on the unit disk. Let be the (open) unit disk and be a continous map, such that restricted to is   holomorphic and for all . Show that can be extended to a function holomorphic on up to   finitely many isolated singularities, i.e. there are finitely many   points and a holomorphic function such that on . Let . Then is the unit circle. Consider . Then is holomorphic because is holomorphic. Let be a circular arc. Because for all it follows . Let be the inversion with respect to . Consider Then for all . Because can be extended to a function that is conitnous on it follows from the Schwarz reflection principle that the function is holomorphic. The function has a singularity at if and only if and . Define . Then is the set of singularities of . Suppose that contains infinitely many elements. Because is bijective it follows that there are infinitely many elements such that . Thus has infinitely many zeros. For every zero of order there is a neighborhood and a holomorphic function such that in that neighborhood. But I do not see how to proceed.","D \subset \mathbb{C} f: \bar{D} \to
> \mathbb{C} f D |f(z)|=1 z \in \partial D f \mathbb{C} z_1,..., z_n \in \mathbb{C} g:
 \mathbb{C} \setminus \{z_1,...,z_n \} \to \mathbb{C} f=g D C_0=\partial D C_0 f|_D: D \to \mathbb{C} f|_D f K \subset C_0 |f(z)|=1  z \in \partial D f(K) \subset C_0 \sigma_0 C_0 \begin{align*}
g: D \cup K \cup \sigma_0(D),  \ F(z)=\begin{cases}
f(z)                       & , \ z \in D          \\
\sigma_0(f(\sigma_0(z)))   & , \ z \in \sigma_0(G) \\
\sigma_0(f(\sigma_0(z)))   & , \ z \in K    
\end{cases}
\end{align*} f(z)=\sigma_0(f(\sigma_0(z))) z \in K f|_D \bar{D} g g a \in \mathbb{C} a\in \sigma_0(G) f(\sigma_0(a))=0 S:=\{z \in \sigma_0(D) \ | \ f(\sigma_0(z))=0 \} S g S \sigma_0 z \in D f(z)=0 f m \geq 1 h f(z)=(h(z))^m",['complex-analysis']
19,Need a book on Graduate Complex Analysis.,Need a book on Graduate Complex Analysis.,,"Is there a book on complex analysis that deals with the same topic as the 3rd chapter of Nevanlinna Paatero's  ""Introduction to Complex Analysis"" but more rigorously?","Is there a book on complex analysis that deals with the same topic as the 3rd chapter of Nevanlinna Paatero's  ""Introduction to Complex Analysis"" but more rigorously?",,"['complex-analysis', 'reference-request']"
20,Elementary proof that $\pi$ is transcendental,Elementary proof that  is transcendental,\pi,"A popular (and maybe the only) approach to showing that $\pi$ is transcendental is to first prove that for every non-zero algebraic number $a$ , the number $e^a$ is transcendental. That requires tools from complex analysis. But is there a known elementary proof that $\pi$ is transcendental? By an elementary proof I mean proof that does not use complex analysis. For example, there are known proofs that $e$ is transcendental which do not use complex analysis. Also, can it be proved that complex analysis must be used to prove some given theorem?","A popular (and maybe the only) approach to showing that is transcendental is to first prove that for every non-zero algebraic number , the number is transcendental. That requires tools from complex analysis. But is there a known elementary proof that is transcendental? By an elementary proof I mean proof that does not use complex analysis. For example, there are known proofs that is transcendental which do not use complex analysis. Also, can it be proved that complex analysis must be used to prove some given theorem?",\pi a e^a \pi e,"['complex-analysis', 'pi', 'transcendental-numbers']"
21,"How do I show that if $f$ and $g$ are entire and $|f|\ge |g|$, then there is some $\beta$ such that $f(z) = \beta g(z)$ for all $z$? [duplicate]","How do I show that if  and  are entire and , then there is some  such that  for all ? [duplicate]",f g |f|\ge |g| \beta f(z) = \beta g(z) z,"This question already has answers here : Suppose $f$ and $g$ are entire functions, and $|f(z)| \leq |g(z)|$ for all $z \in \mathbb{C}$, Prove that $f(z)=cg(z)$. (4 answers) Closed 4 years ago . I was wondering if you could help me with a question: Suppose that $ f $ and $ g $ are entire functions, and that $ |f(z)| \leq |g(z)| ,\forall z \in C $ . Prove that there $ \exists \beta \in C $ such that $f(z) = \beta g(z), \forall z  C$ . I tried to show $f(z)/g(z) $ was constant by Liouville theorem however we don't know if $ f(z)/g(z)$ is entire as $g(z)$ might be equal to $0$ . So I couldn't use the fact that it is entire and bounded to use Liouville theorem. Do you have an idea?  thank you in advance","This question already has answers here : Suppose $f$ and $g$ are entire functions, and $|f(z)| \leq |g(z)|$ for all $z \in \mathbb{C}$, Prove that $f(z)=cg(z)$. (4 answers) Closed 4 years ago . I was wondering if you could help me with a question: Suppose that and are entire functions, and that . Prove that there such that . I tried to show was constant by Liouville theorem however we don't know if is entire as might be equal to . So I couldn't use the fact that it is entire and bounded to use Liouville theorem. Do you have an idea?  thank you in advance"," f   g   |f(z)| \leq |g(z)| ,\forall z \in C   \exists \beta \in C  f(z) = \beta g(z), \forall z  C f(z)/g(z)   f(z)/g(z) g(z) 0",[]
22,Radius of convergence of all taylor series of f are uniformly bounded then analytic,Radius of convergence of all taylor series of f are uniformly bounded then analytic,,"Let $f \in C^{\infty}( \mathbb{R},\mathbb{R})$ such that the radius of convergence of all taylor series of $f$ are uniformly bounded . Then $f$ is analytic. I don't know if this result is true or not , i was working on analytic functions and i asked myself this question . I searched to find something similar , i am not able to prove it or find an example ...","Let such that the radius of convergence of all taylor series of are uniformly bounded . Then is analytic. I don't know if this result is true or not , i was working on analytic functions and i asked myself this question . I searched to find something similar , i am not able to prove it or find an example ...","f \in C^{\infty}( \mathbb{R},\mathbb{R}) f f","['real-analysis', 'complex-analysis']"
23,Equivalent definitions of total variation of a complex measure,Equivalent definitions of total variation of a complex measure,,"Let $(X,M,\mu)$ be a complex measure space. Then for $E \in M$ we have $|\mu|(E)=sup\{\Sigma_k| \mu(E_k)|: E = \sqcup_{k=1}^\infty E_k $ where $ E_k \in M\}$ Prove that for each $E\in M$ $$\begin{align*}  |\mu|(E)&=\sup\left\{\sum_{k=1}^N |\mu(E_k)| : \{E_k\}_{k=1}^N \ \text{is a finite partition of} \ E\right\}\\ &=\sup\left\{\Big|\int_E f\,d\mu\Big| : f \ \text{is measurable and} \ |f|\leq 1\right\}\end{align*}$$ I've been having a real rough time trying to show these inequalities... I feel like I'm running into some sort of tunnel vision, I've been stuck on this for awhile now, I'd really appreciate it if someone could walk me through this one.. Thanks","Let be a complex measure space. Then for we have where Prove that for each I've been having a real rough time trying to show these inequalities... I feel like I'm running into some sort of tunnel vision, I've been stuck on this for awhile now, I'd really appreciate it if someone could walk me through this one.. Thanks","(X,M,\mu) E \in M |\mu|(E)=sup\{\Sigma_k| \mu(E_k)|: E = \sqcup_{k=1}^\infty E_k   E_k \in M\} E\in M \begin{align*} 
|\mu|(E)&=\sup\left\{\sum_{k=1}^N |\mu(E_k)| : \{E_k\}_{k=1}^N \ \text{is a finite partition of} \ E\right\}\\
&=\sup\left\{\Big|\int_E f\,d\mu\Big| : f \ \text{is measurable and} \ |f|\leq 1\right\}\end{align*}","['real-analysis', 'complex-analysis']"
24,Pointwise convergence of holomorphic functions on a dense set,Pointwise convergence of holomorphic functions on a dense set,,"Let $G$ be an open connected set and let $D \subset G$ be a dense set. Let $(f_n)$ be a sequence of holomorphic functions in $G$ and assume $f_n \rightarrow 0$ pointwisely on $D$ . Can we deduce that $f_n$ converges pointwisely to a function $f$ ? If this is true, by Osgood theorem ( Convergence of a sequence holomorphic functions ) $f_n$ converges uniformly in a dense open set $D'$ of $G$ , so we deduce $f$ is holomorphic in $D'$ . Since $f\mid_D = 0$ it will follow that $f\mid_{D'} = 0.$ Now, assume we do not know that $f_n$ converges pointwisely but instead $f_n$ is locally bounded. By Vitali-Porter theorem ( https://mathoverflow.net/questions/82787/vitalis-theorem-on-convergence-of-holomorphic-functions ) $f_n$ converges uniformly on compacts subsets of $G$ to an analytic function, but it only 'needs' $D$ to have an accumulation point. My question is the following: could we deduce something like Vitali or Osgood theorem using only pointwise convergence on a dense set $D$ ? Thank you very much!","Let be an open connected set and let be a dense set. Let be a sequence of holomorphic functions in and assume pointwisely on . Can we deduce that converges pointwisely to a function ? If this is true, by Osgood theorem ( Convergence of a sequence holomorphic functions ) converges uniformly in a dense open set of , so we deduce is holomorphic in . Since it will follow that Now, assume we do not know that converges pointwisely but instead is locally bounded. By Vitali-Porter theorem ( https://mathoverflow.net/questions/82787/vitalis-theorem-on-convergence-of-holomorphic-functions ) converges uniformly on compacts subsets of to an analytic function, but it only 'needs' to have an accumulation point. My question is the following: could we deduce something like Vitali or Osgood theorem using only pointwise convergence on a dense set ? Thank you very much!",G D \subset G (f_n) G f_n \rightarrow 0 D f_n f f_n D' G f D' f\mid_D = 0 f\mid_{D'} = 0. f_n f_n f_n G D D,"['complex-analysis', 'analytic-functions', 'pointwise-convergence']"
25,Find Mobius transformations $\varphi$ satisfying $\sum (1-|\varphi_n(z)|)<\infty$ in the unit disc.,Find Mobius transformations  satisfying  in the unit disc.,\varphi \sum (1-|\varphi_n(z)|)<\infty,"Suppose that $\varphi$ is a Mobius transformation which maps the unit disc onto itself. Let $\varphi_n(z)=\varphi(\varphi_{n-1}(z))$ , where $n=1,2,\ldots$ and $\varphi_0(z)=z$ . Find all $\varphi$ satisfying the condition $\sum (1-|\varphi_n(z)|)<\infty$ in the unit disc if $\varphi$ has a unique fixed point on the unit circle. My thought: Suppose $\varphi(z)=\frac{az+b}{cz+d}$ with $ad-bc=1$ . From the hypotheses, we know that $c \neq 0$ , $a+d=\pm 2$ and the fixed point will be $\frac{\pm 1-d}{c}$ . Then I don't know how to use these to determine $\varphi$ . Any help?","Suppose that is a Mobius transformation which maps the unit disc onto itself. Let , where and . Find all satisfying the condition in the unit disc if has a unique fixed point on the unit circle. My thought: Suppose with . From the hypotheses, we know that , and the fixed point will be . Then I don't know how to use these to determine . Any help?","\varphi \varphi_n(z)=\varphi(\varphi_{n-1}(z)) n=1,2,\ldots \varphi_0(z)=z \varphi \sum (1-|\varphi_n(z)|)<\infty \varphi \varphi(z)=\frac{az+b}{cz+d} ad-bc=1 c \neq 0 a+d=\pm 2 \frac{\pm 1-d}{c} \varphi","['complex-analysis', 'mobius-transformation']"
26,Ahlfors' lemma of winding number,Ahlfors' lemma of winding number,,"On page 115 of Ahlfors Complex Analysis, he defines $$h(t) = \int_\alpha^t \frac{z'(t)}{z(t)-a} dt$$ Later on the page he states that $e^{h(t)} = \frac{z(t) - a}{z(\alpha)-a}$ , but I don't see how to arrive at that. Is there a result outside of complex analysis this relies on or am I just not seeing the algebra of it?","On page 115 of Ahlfors Complex Analysis, he defines Later on the page he states that , but I don't see how to arrive at that. Is there a result outside of complex analysis this relies on or am I just not seeing the algebra of it?",h(t) = \int_\alpha^t \frac{z'(t)}{z(t)-a} dt e^{h(t)} = \frac{z(t) - a}{z(\alpha)-a},['complex-analysis']
27,Asymptotics of the quantum dilogarithm,Asymptotics of the quantum dilogarithm,,"Fadeev and Kashaev define the quantum dilogarithm by $$ \Psi(x) = \prod_{n=1}^\infty (1 - x q^n) $$ for $|q| < 1$ . For $q = \exp(\epsilon)$ , $\Re \epsilon < 0$ , they say the asymptotic expansion $$   \Psi(x) = \frac{1}{\sqrt{1 - x}} \exp( \operatorname{Li}_2(x) / \epsilon)(1 + O(\epsilon)) $$ as $\epsilon \to 0$ is ""easy to see,"" but I'm having trouble deriving it. Here $\operatorname{Li}_2$ is the dilogarithm $$   \operatorname{Li}_2(x) = - \int_0^x \frac{\log( 1-t )}{t} \, dt = \sum_{n=1}^\infty \frac{x^n}{n^2}. $$ I've tried expanding $$     \log \left( \Psi(x) \sqrt{1-x} \exp(- \epsilon^{-1} \operatorname{Li}_2(x)) \right) = \log \Psi(x) + \frac{1}{2} \log(1 - x) - \frac{1}{\epsilon} \operatorname{Li}_2(x). $$ but this doesn't seem like it can work: if you expand $\log \Psi(x)$ in $\epsilon$ there's only positive powers, so I don't see how you can get a cancellation with the $\epsilon^{-1} \operatorname{Li}_2(x)$ .","Fadeev and Kashaev define the quantum dilogarithm by for . For , , they say the asymptotic expansion as is ""easy to see,"" but I'm having trouble deriving it. Here is the dilogarithm I've tried expanding but this doesn't seem like it can work: if you expand in there's only positive powers, so I don't see how you can get a cancellation with the .","
\Psi(x) = \prod_{n=1}^\infty (1 - x q^n)
 |q| < 1 q = \exp(\epsilon) \Re \epsilon < 0 
  \Psi(x) = \frac{1}{\sqrt{1 - x}} \exp( \operatorname{Li}_2(x) / \epsilon)(1 + O(\epsilon))
 \epsilon \to 0 \operatorname{Li}_2 
  \operatorname{Li}_2(x) = - \int_0^x \frac{\log( 1-t )}{t} \, dt = \sum_{n=1}^\infty \frac{x^n}{n^2}.
 
    \log \left( \Psi(x) \sqrt{1-x} \exp(- \epsilon^{-1} \operatorname{Li}_2(x)) \right) = \log \Psi(x) + \frac{1}{2} \log(1 - x) - \frac{1}{\epsilon} \operatorname{Li}_2(x).
 \log \Psi(x) \epsilon \epsilon^{-1} \operatorname{Li}_2(x)","['complex-analysis', 'asymptotics', 'q-series']"
28,What's known about $\sum_{n=1}^\infty\frac{1}{\sigma_s(n)}$?,What's known about ?,\sum_{n=1}^\infty\frac{1}{\sigma_s(n)},"Let $$\sigma_s(n)=\sum_{d|n} d^s$$ $$f(s)=\sum_{n=1}^\infty\frac{1}{\sigma_s(n)}$$ (1) Is it possible to prove that $f$ converges for $s>1$ ? (2) Is there anything that can be said about an analytic continuation of $f$ ? Namely, is there a unique analytic continuation to $\mathbb{C} \setminus\{1\}$ ? Here's what's clear to me: $f$ diverges at $s=1$ . Let $\mathbb{P}$ denote the prime numbers. $$f(s)> \sum_{p\in\mathbb{P} } \frac{1}{\sigma_s(p)}=\sum_{p\in\mathbb{P}}\frac{1}{1+p^s}$$ And this last expression converges iff $P(s)$ the prime zeta function converges. So in particular $f(s)$ is divergent at $s=1$ .","Let (1) Is it possible to prove that converges for ? (2) Is there anything that can be said about an analytic continuation of ? Namely, is there a unique analytic continuation to ? Here's what's clear to me: diverges at . Let denote the prime numbers. And this last expression converges iff the prime zeta function converges. So in particular is divergent at .",\sigma_s(n)=\sum_{d|n} d^s f(s)=\sum_{n=1}^\infty\frac{1}{\sigma_s(n)} f s>1 f \mathbb{C} \setminus\{1\} f s=1 \mathbb{P} f(s)> \sum_{p\in\mathbb{P} } \frac{1}{\sigma_s(p)}=\sum_{p\in\mathbb{P}}\frac{1}{1+p^s} P(s) f(s) s=1,"['complex-analysis', 'convergence-divergence', 'zeta-functions']"
29,Laurent series of exp(az+b/z),Laurent series of exp(az+b/z),,"I need to show that \begin{align} 		\exp \left(a z+b z^{-1}\right)&=\sum_{n=-\infty}^{\infty} a_{n} z^{n} \;\;\; a, b \in \mathbb{C} \\\ 		a_{n}&=\frac{1}{2 \pi} \int_{0}^{2 \pi} e^{(a+b) \cos \theta} \cos \Big[(a-b) \sin \theta-n \theta\Big] d \theta \end{align} I am stuck at one of my arguments, which I find shaky. What I have so far is: I note that f(z) is a composition of a polynomial, with the exponential function, it is holomorphic on the punctured disk K'(a,r) centered at the point a = 0 which is a singularity. This is analogous to the annulus $$A(a, R_1, R_2) , R_1 \rightarrow 0, R_1 \rightarrow \infty$$ There exists a Laurent series for the function at a. The general term a_n is given by \begin{align} 		a_n &= \frac{1}{2\pi i} \int_{\partial K(a,r)}\frac{f(z)}{(z-a)^{n+1}}dz \\\ 			&= \frac{1}{2\pi i} \int_{\partial K(0,r)}\frac{\exp \left(a z+b z^{-1}\right)}{z^{n+1}}dz\\\ 		&= \frac{1}{2\pi i} \int_{0}^{2\pi}\frac{\exp \left(a r e^{i\theta}+b (re^{i\theta})^{-1}\right)}{(re^{i\theta})^{n+1}}r i e^{i\theta}d\theta \\\ 			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\left(a r e^{i\theta}+b (re^{i\theta})^{-1}\right)}(re^{i\theta})^{-n}d\theta \\\ 			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\big( a r [cos(\theta)+i\sin(\theta)]+b [cos(\theta)-i\sin(\theta)]r^{-1} \big)} (re^{i\theta})^{-n} d\theta \\\ 			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\big( (a r+b r^{-1})cos(\theta)+i(a r-b r^{-1})\sin(\theta)\big)} (re^{i\theta})^{-n} d\theta \\\ 			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta}e^{i(a r-b r^{-1})\sin\theta}e^{-i\theta n} r^{-n} d\theta \\\ 			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta}e^{i\big[(a r-b r^{-1})\sin\theta -\theta n\big]} r^{-n} d\theta \\\ 			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta} \Big(\cos\left[(a r-b r^{-1})\sin\theta-\theta n\right] + i\sin\left[(a r-b r^{-1})\sin\theta - \theta n\right] \Big) r^{-n} d\theta 	\end{align} $f(z)$ has a primitive (as it is the composition of the exponential with polynomials),so the last term of the integral is zero, since it is the evaluation of its primitives at the upper and lower boundaries of the integral. The primitive of $i\sin z$ is $i \cos z$ , so evaluating the last term at $F(0)$ and $F(2\pi)$ yields $F(2\pi) - F(0) = i\cos(2\pi n)-i\cos(0) = i - i = 0$ , and thus \begin{align} 	a_n &=  \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta} \cos\left[(a r-b r^{-1})\sin\theta-\theta n\right]  r^{-n} d\theta 	\end{align} Now i need to get rid of the r's... I somehow want to just say they are equal to one, since the closed path integral is independent of the path. We are integrating around the boundary of the disc, a closed circle, and the integral must be independent of r. This means it must hold for any r. Is this reasoning correct?","I need to show that I am stuck at one of my arguments, which I find shaky. What I have so far is: I note that f(z) is a composition of a polynomial, with the exponential function, it is holomorphic on the punctured disk K'(a,r) centered at the point a = 0 which is a singularity. This is analogous to the annulus There exists a Laurent series for the function at a. The general term a_n is given by has a primitive (as it is the composition of the exponential with polynomials),so the last term of the integral is zero, since it is the evaluation of its primitives at the upper and lower boundaries of the integral. The primitive of is , so evaluating the last term at and yields , and thus Now i need to get rid of the r's... I somehow want to just say they are equal to one, since the closed path integral is independent of the path. We are integrating around the boundary of the disc, a closed circle, and the integral must be independent of r. This means it must hold for any r. Is this reasoning correct?","\begin{align}
		\exp \left(a z+b z^{-1}\right)&=\sum_{n=-\infty}^{\infty} a_{n} z^{n} \;\;\; a, b \in \mathbb{C} \\\
		a_{n}&=\frac{1}{2 \pi} \int_{0}^{2 \pi} e^{(a+b) \cos \theta} \cos \Big[(a-b) \sin \theta-n \theta\Big] d \theta
\end{align} A(a, R_1, R_2) , R_1 \rightarrow 0, R_1 \rightarrow \infty \begin{align}
		a_n &= \frac{1}{2\pi i} \int_{\partial K(a,r)}\frac{f(z)}{(z-a)^{n+1}}dz \\\
			&= \frac{1}{2\pi i} \int_{\partial K(0,r)}\frac{\exp \left(a z+b z^{-1}\right)}{z^{n+1}}dz\\\
		&= \frac{1}{2\pi i} \int_{0}^{2\pi}\frac{\exp \left(a r e^{i\theta}+b (re^{i\theta})^{-1}\right)}{(re^{i\theta})^{n+1}}r i e^{i\theta}d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\left(a r e^{i\theta}+b (re^{i\theta})^{-1}\right)}(re^{i\theta})^{-n}d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\big( a r [cos(\theta)+i\sin(\theta)]+b [cos(\theta)-i\sin(\theta)]r^{-1} \big)} (re^{i\theta})^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{\big( (a r+b r^{-1})cos(\theta)+i(a r-b r^{-1})\sin(\theta)\big)} (re^{i\theta})^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta}e^{i(a r-b r^{-1})\sin\theta}e^{-i\theta n} r^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta}e^{i\big[(a r-b r^{-1})\sin\theta -\theta n\big]} r^{-n} d\theta \\\
			&= \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta} \Big(\cos\left[(a r-b r^{-1})\sin\theta-\theta n\right] + i\sin\left[(a r-b r^{-1})\sin\theta - \theta n\right] \Big) r^{-n} d\theta
	\end{align} f(z) i\sin z i \cos z F(0) F(2\pi) F(2\pi) - F(0) = i\cos(2\pi n)-i\cos(0) = i - i = 0 \begin{align}
	a_n &=  \frac{1}{2\pi} \int_{0}^{2\pi} e^{(a r+b r^{-1})\cos\theta} \cos\left[(a r-b r^{-1})\sin\theta-\theta n\right]  r^{-n} d\theta
	\end{align}","['sequences-and-series', 'complex-analysis', 'analysis', 'laurent-series']"
30,In how many ways can I express a positive integer as a sum of elements in a subset of $\mathbb Z^+$?,In how many ways can I express a positive integer as a sum of elements in a subset of ?,\mathbb Z^+,"Let $S\subseteq \mathbb Z^+$ be set of positive integers. Given $n\in\mathbb Z^+$ , how can I find the number of ways in which we can express $n$ as a sum of elements in $S$ ? ( $S$ can be infinite.) $$ n=\sum_{k\in A} k,A\subseteq S. $$ This does not seem very difficult, but I am not familiar with this type of problem. I tried to use the generating function $$ G(x)=\prod_{k\in S} (1+x^k) $$ but obtained little results. In fact, I am aiming to find all sets $S$ such that the representation $n=\sum_{k\in A} k$ is unique for all $n$ . That means the coefficients of $G(x)$ are $1$ for all $x$ , i.e., $G(x)=1+x+x^2+\ldots=\frac{1}{1-x}$ . Now, it appears that I am running into a serious piece of analysis/algebra. $\frac{1}{1-z}$ does not have any zeros on $\mathbb C$ . Its only zero is $\infty$ . But $\prod_{k\in S} (1+z^k)$ does have a lot of zeros, and all of them lie on the unit circle $\{z:|z|=1\}$ . It therefore seems that such a set $S$ is not possible. EDIT: The above argument seems wrong. Indeed, we have $$ \prod_{k=0}^\infty (1+x^{2^k})=1+x+x^2+x^3+\ldots. $$ It is apparent that I am not tackling a lot of technical subtlety in this factorization. (I have not considered the domains of functions here; however, I think such discussion of ""zeros"" outside the domain might make sense after something like analytic continuation.) I studied the Weierstrass factorization theorem, but it only applies to entire functions; I am not sure what to do with the pole at $z=1$ . Can I evaluate the coefficients of $G(x)$ and what's wrong with my argument in the second part of my question?","Let be set of positive integers. Given , how can I find the number of ways in which we can express as a sum of elements in ? ( can be infinite.) This does not seem very difficult, but I am not familiar with this type of problem. I tried to use the generating function but obtained little results. In fact, I am aiming to find all sets such that the representation is unique for all . That means the coefficients of are for all , i.e., . Now, it appears that I am running into a serious piece of analysis/algebra. does not have any zeros on . Its only zero is . But does have a lot of zeros, and all of them lie on the unit circle . It therefore seems that such a set is not possible. EDIT: The above argument seems wrong. Indeed, we have It is apparent that I am not tackling a lot of technical subtlety in this factorization. (I have not considered the domains of functions here; however, I think such discussion of ""zeros"" outside the domain might make sense after something like analytic continuation.) I studied the Weierstrass factorization theorem, but it only applies to entire functions; I am not sure what to do with the pole at . Can I evaluate the coefficients of and what's wrong with my argument in the second part of my question?","S\subseteq \mathbb Z^+ n\in\mathbb Z^+ n S S 
n=\sum_{k\in A} k,A\subseteq S.
 
G(x)=\prod_{k\in S} (1+x^k)
 S n=\sum_{k\in A} k n G(x) 1 x G(x)=1+x+x^2+\ldots=\frac{1}{1-x} \frac{1}{1-z} \mathbb C \infty \prod_{k\in S} (1+z^k) \{z:|z|=1\} S 
\prod_{k=0}^\infty (1+x^{2^k})=1+x+x^2+x^3+\ldots.
 z=1 G(x)","['combinatorics', 'complex-analysis', 'number-theory', 'analytic-number-theory', 'integer-partitions']"
31,Trouble understanding definition of complex logarithm of Dirichlet L function.,Trouble understanding definition of complex logarithm of Dirichlet L function.,,"I know that for $\chi\not =1$ (i.e. Dirichlet character of modulo $m$ ) $L(1,\chi)\not= 0$ . In Serre's book (A Course in Arithmetic page 74) he gives 2 definitions of the complex logarithm of $Log(L(1,\chi))$ : For the second definition, I believe he is using the fact that $L(1,\chi)$ is analytic and non-zero in a region around 1 so it has a an analytic function $g$ s.t $e^g=f$ in this small region. But how do I use this g to get a series definition of $Log(L(s,\chi))$ ? I don't quite understand the first definition. Is he composing $L(s,\chi)$ with some branch of the complex logarithm? If so, how can we confirm that the image of $L(s,\chi)$ falls with the domain of that branch? Can someone care to explain how what Serre means by $Log(L(s,\chi))$ ?","I know that for (i.e. Dirichlet character of modulo ) . In Serre's book (A Course in Arithmetic page 74) he gives 2 definitions of the complex logarithm of : For the second definition, I believe he is using the fact that is analytic and non-zero in a region around 1 so it has a an analytic function s.t in this small region. But how do I use this g to get a series definition of ? I don't quite understand the first definition. Is he composing with some branch of the complex logarithm? If so, how can we confirm that the image of falls with the domain of that branch? Can someone care to explain how what Serre means by ?","\chi\not =1 m L(1,\chi)\not= 0 Log(L(1,\chi)) L(1,\chi) g e^g=f Log(L(s,\chi)) L(s,\chi) L(s,\chi) Log(L(s,\chi))","['complex-analysis', 'logarithms', 'analytic-number-theory']"
32,$z^\alpha$ is defined and holomorphic on $\mathbb{C}^{\times}$ only for $\alpha$ an integer.,is defined and holomorphic on  only for  an integer.,z^\alpha \mathbb{C}^{\times} \alpha,"I think I found a solution for this for all $\alpha$ : for $\alpha$ rational and not an integer one gets an impossible endomorphism of $\pi_1(\mathbb{C}^{\times})=\mathbb{Z}$ , and for $\alpha$ irrational one can show that $z^\alpha$ basically induces the same impossible map as a $z^\frac{p}{q}$ when $\frac{p}{q}$ is a sufficiently good rational approximation of $\alpha$ . However I'm afraid I'm missing something because I find the the irrational case to be a bit too complicated for the exercise sheet I was given. Is there a better, simpler solution ? Thanks","I think I found a solution for this for all : for rational and not an integer one gets an impossible endomorphism of , and for irrational one can show that basically induces the same impossible map as a when is a sufficiently good rational approximation of . However I'm afraid I'm missing something because I find the the irrational case to be a bit too complicated for the exercise sheet I was given. Is there a better, simpler solution ? Thanks",\alpha \alpha \pi_1(\mathbb{C}^{\times})=\mathbb{Z} \alpha z^\alpha z^\frac{p}{q} \frac{p}{q} \alpha,['complex-analysis']
33,"Cauchy's integral formula, application","Cauchy's integral formula, application",,"Let $f: U \to \mathbb{C}$ be a holomorphic function and let $z_0 \in U$ . How can I use Cauchy's integral formula to express the third derivative of $f$ in $z_0$ . I do not see how to show this, but I need to use the statements in (1) and (2). I appreciate any help! (1) Cauchy's integral formula: Let $f$ be a holomorphic function on the open disc centered in in $z_0$ with radius $\rho$ . Then the number $a_n = \frac{1}{2 \pi r^n} \int_{0}^{2 \pi} f(r e^{it} + z_0) e^{-int} dt$ doesn't depend on the choice of $r < \rho$ the power series $\sum a_n z^n$ has a convergence radius of at least $\rho$ We have equality: $f(z) = \sum_{n \geq 0} a_n (z-z_0)^n$ for $ |z-z_0| < \rho$ (2) Uniqueness of developement of Taylor series: Every analytic function $f: U \to \mathbb{C}$ has an unique developement in a power series in an environment of its points $z_0 \in U$ .","Let be a holomorphic function and let . How can I use Cauchy's integral formula to express the third derivative of in . I do not see how to show this, but I need to use the statements in (1) and (2). I appreciate any help! (1) Cauchy's integral formula: Let be a holomorphic function on the open disc centered in in with radius . Then the number doesn't depend on the choice of the power series has a convergence radius of at least We have equality: for (2) Uniqueness of developement of Taylor series: Every analytic function has an unique developement in a power series in an environment of its points .",f: U \to \mathbb{C} z_0 \in U f z_0 f z_0 \rho a_n = \frac{1}{2 \pi r^n} \int_{0}^{2 \pi} f(r e^{it} + z_0) e^{-int} dt r < \rho \sum a_n z^n \rho f(z) = \sum_{n \geq 0} a_n (z-z_0)^n  |z-z_0| < \rho f: U \to \mathbb{C} z_0 \in U,"['complex-analysis', 'complex-numbers', 'complex-integration']"
34,Method of steepest descent: why can we relate these two contours?,Method of steepest descent: why can we relate these two contours?,,"Let $f,g:\mathbb{C}\to \mathbb{C}$ be two functions which are holomorphic in $\Omega\subset \mathbb{C}$ . Consider the integral $$I(\lambda)=\int_{\Gamma}g(z)e^{\lambda f(z)}dz,\quad \lambda \in (0,+\infty)$$ where $\Gamma$ is a contour in $\Omega$ . I want to understand the method of steepest descend which allows to approximate $I(\lambda)$ as $\lambda \to +\infty$ . Now, if I understand, the rough idea is to deform the contour into another contour $\Gamma'$ passing through a saddle point of $f(z)$ in the direction of steepest descent of its real part. To do so we look for a saddle point $f'(z_0)=0$ , expand $f(z)$ up to second order around it $$f(z)=f(z_0)+\frac{1}{2}(z-z_0)f''(z_0)+\cdots$$ and we parameterize $z - z_0 = r_1e^{i\theta_1}$ . Also letting $\frac{1}{2}f''(z_0)=r_2 e^{i\theta_2}$ we have the changes in the real and imaginary parts of $f$ : $$\operatorname{Re}[f(z)-f(z_0)]=r_1^2r_2\cos(2\theta_1+\theta_2),\quad \operatorname{Im}[f(z)-f(z_0)]=r_1^2r_2\sin(2\theta_1+\theta_2).$$ The direction of steepest descent has vanishing change in the imaginary part and negative change in the real part. These two conditions give $2\theta_1+\theta_2$ either $\pi$ or $3\pi$ . Therefore the desired contour $\Gamma'$ can be parameterized as $$z(t)=z_0+\frac{t}{\sqrt{r_2}}e^{i\theta_1}$$ Question: why can we deform $\Gamma$ into $\Gamma'$ and not change $I(\lambda)$ ? I mean, I do know that from Cauchy's theorem if $\Gamma$ and $\Gamma'$ have the same endpoints then the integral is the same along both. But in this whole derivation I see no reason why $\Gamma'$ would share endpoints with $\Gamma$ .","Let be two functions which are holomorphic in . Consider the integral where is a contour in . I want to understand the method of steepest descend which allows to approximate as . Now, if I understand, the rough idea is to deform the contour into another contour passing through a saddle point of in the direction of steepest descent of its real part. To do so we look for a saddle point , expand up to second order around it and we parameterize . Also letting we have the changes in the real and imaginary parts of : The direction of steepest descent has vanishing change in the imaginary part and negative change in the real part. These two conditions give either or . Therefore the desired contour can be parameterized as Question: why can we deform into and not change ? I mean, I do know that from Cauchy's theorem if and have the same endpoints then the integral is the same along both. But in this whole derivation I see no reason why would share endpoints with .","f,g:\mathbb{C}\to \mathbb{C} \Omega\subset \mathbb{C} I(\lambda)=\int_{\Gamma}g(z)e^{\lambda f(z)}dz,\quad \lambda \in (0,+\infty) \Gamma \Omega I(\lambda) \lambda \to +\infty \Gamma' f(z) f'(z_0)=0 f(z) f(z)=f(z_0)+\frac{1}{2}(z-z_0)f''(z_0)+\cdots z - z_0 = r_1e^{i\theta_1} \frac{1}{2}f''(z_0)=r_2 e^{i\theta_2} f \operatorname{Re}[f(z)-f(z_0)]=r_1^2r_2\cos(2\theta_1+\theta_2),\quad \operatorname{Im}[f(z)-f(z_0)]=r_1^2r_2\sin(2\theta_1+\theta_2). 2\theta_1+\theta_2 \pi 3\pi \Gamma' z(t)=z_0+\frac{t}{\sqrt{r_2}}e^{i\theta_1} \Gamma \Gamma' I(\lambda) \Gamma \Gamma' \Gamma' \Gamma","['calculus', 'integration', 'complex-analysis', 'asymptotics']"
35,Does this set of functions separate points of $\Omega$?,Does this set of functions separate points of ?,\Omega,"Let $\Omega$$\subset\mathbb{C}$ be a open connected set (domain). Let $z\in\Omega$ I want to show that if all bounded holomorphic functions on $\Omega$ are not just the constant functions (denoted by $H^\infty(\Omega)\not\equiv\mathbb{C}$ ), then, for every $0\neq\xi\in\mathbb{C}$ , there exists a bounded holomorphic function $f$ on $\Omega$ such that $f(z)\xi\neq 0$ The proof goes like this (see proof of Proposition 2.5.1 in this book ). Suppose $H^\infty(\Omega)\not\equiv\mathbb{C}$ and let $f_0\in H^\infty(\Omega), a_1,a_2\in\Omega$ , such that $f_0(a_1)\neq f_0(a_2)$ . Define for $j=1,2$ , $f_j$ as \begin{equation*}     f_j(z) = \begin{cases}               \frac{f_0(z)-f_0(a_j)}{z-a_j}& \text{if } z\neq a_j,\\                f_0(a_j) & \text{if } z= a_j.           \end{cases} \end{equation*} Then it is said that $f_0,f_1,f_2$ separates points of $\Omega$ . And $rank(f_0,f_1,f_2)=1$ on $\Omega$ and hence proved. I do not understand how $f_0,f_1,f_2$ separates points of $\Omega$ ? And what is the meaning of $rank(f_0,f_1,f_2)=1$ ?","Let be a open connected set (domain). Let I want to show that if all bounded holomorphic functions on are not just the constant functions (denoted by ), then, for every , there exists a bounded holomorphic function on such that The proof goes like this (see proof of Proposition 2.5.1 in this book ). Suppose and let , such that . Define for , as Then it is said that separates points of . And on and hence proved. I do not understand how separates points of ? And what is the meaning of ?","\Omega\subset\mathbb{C} z\in\Omega \Omega H^\infty(\Omega)\not\equiv\mathbb{C} 0\neq\xi\in\mathbb{C} f \Omega f(z)\xi\neq 0 H^\infty(\Omega)\not\equiv\mathbb{C} f_0\in H^\infty(\Omega), a_1,a_2\in\Omega f_0(a_1)\neq f_0(a_2) j=1,2 f_j \begin{equation*}
    f_j(z) = \begin{cases}
              \frac{f_0(z)-f_0(a_j)}{z-a_j}& \text{if } z\neq a_j,\\
               f_0(a_j) & \text{if } z= a_j.
          \end{cases}
\end{equation*} f_0,f_1,f_2 \Omega rank(f_0,f_1,f_2)=1 \Omega f_0,f_1,f_2 \Omega rank(f_0,f_1,f_2)=1","['complex-analysis', 'functional-analysis']"
36,I have a question about homotopy of the unit circumference with a point,I have a question about homotopy of the unit circumference with a point,,"Definition: Let $\gamma_0,\gamma_1:[0,1]\to G$ two rectifiable curves and $G\subseteq\mathbb{C}$ an open connected set. We say $\gamma_0$ and $\gamma_1$ are homotopic in $G$ if there exists $\Gamma:[0,1]\times[0,1]\to G$ continuous such that: \begin{cases}        \Gamma(s,0)=\gamma_0(s), \Gamma(s,1)=\gamma_1(s) & 0\le s\le 1 \\       \Gamma(0,t)=\Gamma(1,t) & 0\le t\le 1 \\    \end{cases} The question is: Show that if we remove the condition "" $\Gamma(0,t)=\Gamma(1,t)$ "" in the above definition, then the curves $\gamma_0(s)=e^{2\pi i s}$ and $\gamma_1(s)=1$ if $0\le s\le 1$ would be homotopic in $\mathbb{C}\setminus\{0\}$ . I defined by $\Gamma(s,t) = t + (1-t)e^{2\pi is}$ . This function satisfies the definition, but I saw in a topology article that the unit circumference is not homotopic with point 1. So where is my error?","Definition: Let two rectifiable curves and an open connected set. We say and are homotopic in if there exists continuous such that: The question is: Show that if we remove the condition "" "" in the above definition, then the curves and if would be homotopic in . I defined by . This function satisfies the definition, but I saw in a topology article that the unit circumference is not homotopic with point 1. So where is my error?","\gamma_0,\gamma_1:[0,1]\to G G\subseteq\mathbb{C} \gamma_0 \gamma_1 G \Gamma:[0,1]\times[0,1]\to G \begin{cases} 
      \Gamma(s,0)=\gamma_0(s), \Gamma(s,1)=\gamma_1(s) & 0\le s\le 1 \\
      \Gamma(0,t)=\Gamma(1,t) & 0\le t\le 1 \\
   \end{cases} \Gamma(0,t)=\Gamma(1,t) \gamma_0(s)=e^{2\pi i s} \gamma_1(s)=1 0\le s\le 1 \mathbb{C}\setminus\{0\} \Gamma(s,t) = t + (1-t)e^{2\pi is}","['general-topology', 'complex-analysis']"
37,Inverse Laplace Transform of $\frac{1}{s+1}$ using Mellin's Inverse Formula,Inverse Laplace Transform of  using Mellin's Inverse Formula,\frac{1}{s+1},"I am trying to compute the inverse Laplace Transform of $F(s)=\frac{1}{s+1}.$ I know that it is supposed to be $f(t)=e^{-t}$ , but I am specifically trying to get that result using Mellin's Inverse Formula, according to which: $$f(t)=\mathcal{L}^{-1}[F(s)](t)=\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty}\frac{e^{st}}{s+1}\ ds$$ According to the formula, I need to choose $\sigma>-1$ (since $s_0=-1$ is the singularity of $F(s)$ and $\Re{\{s_0\}=-1}$ ) and to integrate on the line $\Re{\{s\}}=\sigma$ . I chose $\sigma=0$ , thus a proper parametrization would be $s=ix$ when $x\in\mathbb{R}$ : $$f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{e^{ixt}}{1+ix}\ dx$$ (I also checked that $F(s)$ is bounded on the line, and it is indeed). I have no idea how to compute this integral. If I were to use the Residue Theorem, I would have ended up with a complex integral again. Another problem that I have: It doesn't even seem like the integral is convergent. Plugging $t=0$ , the result of the integral should be $1$ , but the integral I got doesn't seem convergent at all: $$f(0)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{1}{1+ix}\ dx=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{1-ix}{1+x^2}\ dx=\frac{1}{2\pi}\left[\left.\arctan(x)\right|_{-\infty}^{\infty}-\frac{i}{2}\left.\ln(1+x^2)\right|_{-\infty}^{\infty}\right]$$ The integral does not converge because of the imaginary part (the logarithm). But, even if for some reason I should take only the real part, it wouldn't correlate with the desired answer, since I would get $\frac 12$ instead of $1$ . I must be missing something here.","I am trying to compute the inverse Laplace Transform of I know that it is supposed to be , but I am specifically trying to get that result using Mellin's Inverse Formula, according to which: According to the formula, I need to choose (since is the singularity of and ) and to integrate on the line . I chose , thus a proper parametrization would be when : (I also checked that is bounded on the line, and it is indeed). I have no idea how to compute this integral. If I were to use the Residue Theorem, I would have ended up with a complex integral again. Another problem that I have: It doesn't even seem like the integral is convergent. Plugging , the result of the integral should be , but the integral I got doesn't seem convergent at all: The integral does not converge because of the imaginary part (the logarithm). But, even if for some reason I should take only the real part, it wouldn't correlate with the desired answer, since I would get instead of . I must be missing something here.",F(s)=\frac{1}{s+1}. f(t)=e^{-t} f(t)=\mathcal{L}^{-1}[F(s)](t)=\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty}\frac{e^{st}}{s+1}\ ds \sigma>-1 s_0=-1 F(s) \Re{\{s_0\}=-1} \Re{\{s\}}=\sigma \sigma=0 s=ix x\in\mathbb{R} f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{e^{ixt}}{1+ix}\ dx F(s) t=0 1 f(0)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{1}{1+ix}\ dx=\frac{1}{2\pi}\int_{-\infty}^{\infty}\frac{1-ix}{1+x^2}\ dx=\frac{1}{2\pi}\left[\left.\arctan(x)\right|_{-\infty}^{\infty}-\frac{i}{2}\left.\ln(1+x^2)\right|_{-\infty}^{\infty}\right] \frac 12 1,"['integration', 'complex-analysis', 'definite-integrals', 'laplace-transform', 'integral-transforms']"
38,Prove that the set of accumulation points is circle. Find it center and radius [closed],Prove that the set of accumulation points is circle. Find it center and radius [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I have the following sequence $a_n= \prod_{k=1}^n (1+\frac{i}{k})$ I need to prove that the set of accumulation points is circle. Also I need to find it center and radius. I dont know how to attempt, could someone give any hints ? So first I was trying to understand what is the center and radius of circle. Also I think , that I need to somehow rewrite $a_n$ s","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question I have the following sequence I need to prove that the set of accumulation points is circle. Also I need to find it center and radius. I dont know how to attempt, could someone give any hints ? So first I was trying to understand what is the center and radius of circle. Also I think , that I need to somehow rewrite s",a_n= \prod_{k=1}^n (1+\frac{i}{k}) a_n,['complex-analysis']
39,How to calculate principal value of this complex integral?,How to calculate principal value of this complex integral?,,"$$I = \text{p. v.}\int_{-\infty}^{\infty}\frac{e^{\alpha x}}{e^{2x} - 1}dx$$ $$ 0<\Re(\alpha)<2$$ Use this contour (see image) $$\lim_{\epsilon\rightarrow 0, \\ R\rightarrow\infty}{\int_{-R+i\pi}^{-R} + \int_{-R}^{-\epsilon} + \int_{C_{\epsilon^{+}}} + \int_{\epsilon}^{R} + \int_{R}^{R+i\pi} +\int_{R+i\pi}^{\epsilon+i\pi} + \int_{C_{\epsilon^{-}}} + \int_{-\epsilon+i\pi}^{-R+i\pi}}$$ Am I do right? $$\int_{-R+i\pi}^{-R} = 0,$$ $$\int_{R}^{R+i\pi} = 0,$$ and $$\int_{C_{\epsilon^{-}}},\int_{C_{\epsilon^{+}}} = -i\pi \ \underset{z=0}{\text{Res}}\left(\frac{e^{\alpha z}}{e^{2z} - 1}\right)$$ How to do next?",Use this contour (see image) Am I do right? and How to do next?,"I = \text{p. v.}\int_{-\infty}^{\infty}\frac{e^{\alpha x}}{e^{2x} - 1}dx  0<\Re(\alpha)<2 \lim_{\epsilon\rightarrow 0, \\ R\rightarrow\infty}{\int_{-R+i\pi}^{-R} + \int_{-R}^{-\epsilon} + \int_{C_{\epsilon^{+}}} + \int_{\epsilon}^{R} + \int_{R}^{R+i\pi} +\int_{R+i\pi}^{\epsilon+i\pi} + \int_{C_{\epsilon^{-}}} + \int_{-\epsilon+i\pi}^{-R+i\pi}} \int_{-R+i\pi}^{-R} = 0, \int_{R}^{R+i\pi} = 0, \int_{C_{\epsilon^{-}}},\int_{C_{\epsilon^{+}}} = -i\pi \ \underset{z=0}{\text{Res}}\left(\frac{e^{\alpha z}}{e^{2z} - 1}\right)","['complex-analysis', 'complex-integration', 'cauchy-principal-value']"
40,Finding a 2D Fourier transform with a Contour Integral,Finding a 2D Fourier transform with a Contour Integral,,"I am reading a paper which has a number of two-dimensional Fourier transforms in the appendix.  For example, $$F\left(\frac{x^2}{r^3}\right)=\frac{k_2^2-k_1^2 z k}{k^3}e^{-kz},$$ where $r^2 = x^2 + y^2 + z^2$ , $k^2 = k_1^2 + k_2^2$ and the 2D Fourier transform is defined as $$\hat{f}(k_1, k_2, z)=F(f)=\frac{1}{2 \pi} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x,y,z) e^{ik_1x +ik_2 y} \: dx \: dy.$$ I suspect that these were obtained by treating the Fourier transform as a contour integral in the upper half-plane and was wondering if someone could carry out the integral and show how to do this to get the above result as an example of the method. Edit: I see how an integral from $-\infty$ to $\infty$ of a function of $x$ with respect to $x$ can be written as a contour integral along the real axis and a semicircle in the upper half plane if we assume $f$ to be analytic in the upper half-plane except for a finite number of poles. Here we have a 2D Fourier transform which is defined to be an integral of a function of $3$ variables where the integral is with respect to the first $2$ variables, so how do you write this as a contour integral in the upper half-plane?","I am reading a paper which has a number of two-dimensional Fourier transforms in the appendix.  For example, where , and the 2D Fourier transform is defined as I suspect that these were obtained by treating the Fourier transform as a contour integral in the upper half-plane and was wondering if someone could carry out the integral and show how to do this to get the above result as an example of the method. Edit: I see how an integral from to of a function of with respect to can be written as a contour integral along the real axis and a semicircle in the upper half plane if we assume to be analytic in the upper half-plane except for a finite number of poles. Here we have a 2D Fourier transform which is defined to be an integral of a function of variables where the integral is with respect to the first variables, so how do you write this as a contour integral in the upper half-plane?","F\left(\frac{x^2}{r^3}\right)=\frac{k_2^2-k_1^2 z k}{k^3}e^{-kz}, r^2 = x^2 + y^2 + z^2 k^2 = k_1^2 + k_2^2 \hat{f}(k_1, k_2, z)=F(f)=\frac{1}{2 \pi} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x,y,z) e^{ik_1x +ik_2 y} \: dx \: dy. -\infty \infty x x f 3 2","['complex-analysis', 'fourier-analysis', 'contour-integration', 'fourier-transform']"
41,complex polynomials problem with a weird inequality,complex polynomials problem with a weird inequality,,Show that if $P(z) = a_nz^n+a_{n-1}z^{n-1}+...+a_1z + a_0$ is a polynomial of degree n then there is $R_0>0$ such that for $|z| > R_0$ the polynomial can be bound from below as $|P(z)| > \frac{1}{2}|a_n||z|^n$ but what if you have the polynomial $P(z) = a_1z+a_0$ where $a_1 = -100$ and $a_0 = 100$ and we fill in $z = 1$ then we have the left side equal to $0$ and the right side equal to 50 so it does not hold. How does that work? I also do not understand what the $R_0$ adds to the problem. Do i use it somewhere in the proof because i do not see its relevance otherwise than stating that absolute value is bigger than 0 also.,Show that if is a polynomial of degree n then there is such that for the polynomial can be bound from below as but what if you have the polynomial where and and we fill in then we have the left side equal to and the right side equal to 50 so it does not hold. How does that work? I also do not understand what the adds to the problem. Do i use it somewhere in the proof because i do not see its relevance otherwise than stating that absolute value is bigger than 0 also.,P(z) = a_nz^n+a_{n-1}z^{n-1}+...+a_1z + a_0 R_0>0 |z| > R_0 |P(z)| > \frac{1}{2}|a_n||z|^n P(z) = a_1z+a_0 a_1 = -100 a_0 = 100 z = 1 0 R_0,['complex-analysis']
42,Derivative of Contour Integral Representation of Step Function,Derivative of Contour Integral Representation of Step Function,,"The following is Problem 11.9 in ""Mathematical Physics: A Modern Introduction to Its Foundations, Second Edition"" by Sadri Hassani. Given the following representation of the step function: $$\theta(x) = \lim_{\epsilon\to 0}\frac{1}{2\pi i} \int_{-\infty}^\infty \frac{e^{i t x}}{t-i\epsilon} \, dt, $$ show that $\theta'(x) = \delta(x)$ . This was a homework problem for an undergraduate physics class, but I (the grad student TA) am having trouble solving it rigorously. The derivative is clearly $$\theta'(x) = \frac{1}{2\pi} \int_{-\infty}^\infty \frac{t e^{itx}}{t-i\epsilon} \, dt,$$ which is essentially the usual Fourier representation of the Dirac delta function $$\delta(x) = \frac{1}{2\pi} \int_{-\infty}^\infty e^{itx} \, dt.$$ However, the textbook has not introduced the Fourier transform yet, so this problem should be doable without using this representation. It is easy to show that $\theta'(x) = 0$ for $x>0$ and $x<0$ by coverting the integral over $t$ into a contour integral with a semicircular portion in the UHP for $x>0$ and LHP in the $x<0$ . One can also see that $\theta'(0)$ is infinite. Lastly, one can show that $\theta'(x)$ integrates to 1 over any region containing the origin. This is the answer that I will accept from the students. However, I would like to have a more rigorous derivation involving a test function. Here is my attempt. Let $$\theta_\epsilon(x) = \frac{1}{2\pi i} \int_{-\infty}^\infty \frac{e^{i t x}}{t-i\epsilon} \, dt $$ We wish to show $\displaystyle{\lim_{\epsilon\to 0} \theta_{\epsilon}'(x) = \delta(x)}$ . The derivative is: $$\theta_\epsilon'(x) = \frac{1}{2\pi i} \int_{-\infty}^\infty \frac{it e^{itx}}{t-i\epsilon} \, dt $$ Let $g(x) \in \mathcal{S}(\mathbb{R})$ be a smooth test function (Schwartz function). We wish to show that $$\lim_{\epsilon \to 0} A_\epsilon = g(0),$$ where $$ A_\epsilon \equiv \int_{-\infty}^\infty \theta_\epsilon'(x) g(x) \, dx.$$ We integrate and convert one of the integrals into a contour integral: \begin{align*} A_\epsilon &= \frac{1}{2\pi} \int_{-\infty}^\infty \int_{-\infty}^\infty \frac{g(x) t e^{itx}}{t-i\epsilon} \, dt \, dx \\ & = \frac{1}{2\pi} \int_{-\infty}^\infty \underbrace{\int_{R} \frac{g(x)z e^{ixz}}{z-i\epsilon} \ dz}_{I_R} \, dx \end{align*} where $R$ is the contour of real numbers in $\mathbb{C}$ . By Jordan's lemma, the contour integral $I_R$ is: $$I_R = \left\{\begin{matrix} g(x) \cdot 2\pi i \cdot  i\epsilon e^{-\epsilon x} & x>0 \\ 0 & x<0 \end{matrix}\right.,$$ where we have closed the contour in the UHP or LHP for $x>0$ and $x<0$ , respectively. Thus: $$A_\epsilon = -\epsilon \int_0^\infty g(x) e^{-\epsilon x} \ dx $$ Integrating by parts: \begin{align*} A_\epsilon  &= -\epsilon \left[ -\frac{1}{\epsilon} e^{-\epsilon x} g(x)\Big|_0^\infty  + \frac{1}{\epsilon} \int_{0}^\infty e^{-\epsilon x} g'(x) dx \right] \\ & = -g(0) - \int_0^\infty e^{-\epsilon x} g'(x) \ dx \\ \end{align*} where we used the fact that $g\to 0$ as $x \to\infty$ . Examining the second term, we see that since $e^{-\epsilon x} g'(x)$ is dominated by $g'(x)$ on $[0,\infty)$ , we can use the Dominated Convergence Theorem to bring the $\epsilon \to 0$ limit inside the integral and find $$\lim_{\epsilon \to 0} A_\epsilon = -g(0) - \int_0^\infty g'(x) \, dx = -g(0) - g(x)\Big\vert_0^\infty = g(0) - g(0) = 0.$$ This is clearly not the desired result. I don't see anything wrong with the manipulations after the contour integral, so that step must be wrong. I guess splitting up the integral for $x>0$ and $x<0$ somehow misses the $x=0$ piece, which at the end of the day is the only piece that matters? Any ideas would be appreciated.","The following is Problem 11.9 in ""Mathematical Physics: A Modern Introduction to Its Foundations, Second Edition"" by Sadri Hassani. Given the following representation of the step function: show that . This was a homework problem for an undergraduate physics class, but I (the grad student TA) am having trouble solving it rigorously. The derivative is clearly which is essentially the usual Fourier representation of the Dirac delta function However, the textbook has not introduced the Fourier transform yet, so this problem should be doable without using this representation. It is easy to show that for and by coverting the integral over into a contour integral with a semicircular portion in the UHP for and LHP in the . One can also see that is infinite. Lastly, one can show that integrates to 1 over any region containing the origin. This is the answer that I will accept from the students. However, I would like to have a more rigorous derivation involving a test function. Here is my attempt. Let We wish to show . The derivative is: Let be a smooth test function (Schwartz function). We wish to show that where We integrate and convert one of the integrals into a contour integral: where is the contour of real numbers in . By Jordan's lemma, the contour integral is: where we have closed the contour in the UHP or LHP for and , respectively. Thus: Integrating by parts: where we used the fact that as . Examining the second term, we see that since is dominated by on , we can use the Dominated Convergence Theorem to bring the limit inside the integral and find This is clearly not the desired result. I don't see anything wrong with the manipulations after the contour integral, so that step must be wrong. I guess splitting up the integral for and somehow misses the piece, which at the end of the day is the only piece that matters? Any ideas would be appreciated.","\theta(x) = \lim_{\epsilon\to 0}\frac{1}{2\pi i} \int_{-\infty}^\infty \frac{e^{i t x}}{t-i\epsilon} \, dt,  \theta'(x) = \delta(x) \theta'(x) = \frac{1}{2\pi} \int_{-\infty}^\infty \frac{t e^{itx}}{t-i\epsilon} \, dt, \delta(x) = \frac{1}{2\pi} \int_{-\infty}^\infty e^{itx} \, dt. \theta'(x) = 0 x>0 x<0 t x>0 x<0 \theta'(0) \theta'(x) \theta_\epsilon(x) = \frac{1}{2\pi i} \int_{-\infty}^\infty \frac{e^{i t x}}{t-i\epsilon} \, dt  \displaystyle{\lim_{\epsilon\to 0} \theta_{\epsilon}'(x) = \delta(x)} \theta_\epsilon'(x) = \frac{1}{2\pi i} \int_{-\infty}^\infty \frac{it e^{itx}}{t-i\epsilon} \, dt  g(x) \in \mathcal{S}(\mathbb{R}) \lim_{\epsilon \to 0} A_\epsilon = g(0),  A_\epsilon \equiv \int_{-\infty}^\infty \theta_\epsilon'(x) g(x) \, dx. \begin{align*}
A_\epsilon &= \frac{1}{2\pi} \int_{-\infty}^\infty \int_{-\infty}^\infty \frac{g(x) t e^{itx}}{t-i\epsilon} \, dt \, dx \\
& = \frac{1}{2\pi} \int_{-\infty}^\infty \underbrace{\int_{R} \frac{g(x)z e^{ixz}}{z-i\epsilon} \ dz}_{I_R} \, dx
\end{align*} R \mathbb{C} I_R I_R = \left\{\begin{matrix} g(x) \cdot 2\pi i \cdot  i\epsilon e^{-\epsilon x} & x>0 \\ 0 & x<0 \end{matrix}\right., x>0 x<0 A_\epsilon = -\epsilon \int_0^\infty g(x) e^{-\epsilon x} \ dx  \begin{align*}
A_\epsilon 
&= -\epsilon \left[ -\frac{1}{\epsilon} e^{-\epsilon x} g(x)\Big|_0^\infty 
+ \frac{1}{\epsilon} \int_{0}^\infty e^{-\epsilon x} g'(x) dx \right] \\
& = -g(0) - \int_0^\infty e^{-\epsilon x} g'(x) \ dx \\
\end{align*} g\to 0 x \to\infty e^{-\epsilon x} g'(x) g'(x) [0,\infty) \epsilon \to 0 \lim_{\epsilon \to 0} A_\epsilon
= -g(0) - \int_0^\infty g'(x) \, dx
= -g(0) - g(x)\Big\vert_0^\infty = g(0) - g(0) = 0. x>0 x<0 x=0","['complex-analysis', 'complex-integration', 'dirac-delta', 'step-function']"
43,How to Show $\int_n^{n+1}(\frac{1}{n^s}-\frac{1}{x^s})dx$ is Analytic,How to Show  is Analytic,\int_n^{n+1}(\frac{1}{n^s}-\frac{1}{x^s})dx,"I found in a note that $F_n(s)=\int_n^{n+1}(\frac{1}{n^s}-\frac{1}{x^s})dx$ ,  then $F_n(s)$ is analytic in $\mathbb{C}$ for every $n \in \mathbb{N}$ . Now, from the definition of analytic function found in Wikipedia (click here) , I am having trouble to see how $F_n(s)$ is analytic, specially, the integral is defined by the variable $x$ , but we are dealing with complex plan and complex number $s= \sigma +it.$ I request to explain and show  elaborately why $F_n(s)$ is analytic. Thanks.","I found in a note that ,  then is analytic in for every . Now, from the definition of analytic function found in Wikipedia (click here) , I am having trouble to see how is analytic, specially, the integral is defined by the variable , but we are dealing with complex plan and complex number I request to explain and show  elaborately why is analytic. Thanks.",F_n(s)=\int_n^{n+1}(\frac{1}{n^s}-\frac{1}{x^s})dx F_n(s) \mathbb{C} n \in \mathbb{N} F_n(s) x s= \sigma +it. F_n(s),"['real-analysis', 'complex-analysis', 'number-theory', 'analysis', 'analytic-number-theory']"
44,Properties of $\lim \sup$,Properties of,\lim \sup,"Suppose { $a_n$ } and { $b_n$ } are bounded sequences and that lim $b_n =b$ . Prove   that $$\lim \sup (a_n + b_n) = \lim \sup a_n + b. $$ Here is what I  tried: Consider $$\sup (a_k) + b$$ Since $b$ is a fixed number, and $\sup (a_k) = \sup \{ a_n : n\geq k \} $ , then it follows that $$\sup (a_k) + b  = \sup (a_k + b)$$ (is this correct?) Then since $b_k \rightarrow b $ , for $k \geq N$ for some $N \in \mathbb{N}$ large enough, $ b_k - \epsilon \leq b \leq b_k + \epsilon$ . So $$ \sup (a_k + b_k - \epsilon) \leq   \sup (a_k + b) \leq \sup (a_k + b_k + \epsilon)$$ Since this holds for all $k \geq N$ , we can take the limit as $k$ approaches $\infty$ , $$\lim \sup (a_k + b_k - \epsilon) \leq \lim  \sup (a_k + b) \leq \lim \sup (a_k + b_k + \epsilon)$$ Since $\epsilon$ was arbitrary, we can conclude that $$\lim \sup (a_n + b_n) = \lim \sup a_n + b. $$","Suppose { } and { } are bounded sequences and that lim . Prove   that Here is what I  tried: Consider Since is a fixed number, and , then it follows that (is this correct?) Then since , for for some large enough, . So Since this holds for all , we can take the limit as approaches , Since was arbitrary, we can conclude that",a_n b_n b_n =b \lim \sup (a_n + b_n) = \lim \sup a_n + b.  \sup (a_k) + b b \sup (a_k) = \sup \{ a_n : n\geq k \}  \sup (a_k) + b  = \sup (a_k + b) b_k \rightarrow b  k \geq N N \in \mathbb{N}  b_k - \epsilon \leq b \leq b_k + \epsilon  \sup (a_k + b_k - \epsilon) \leq   \sup (a_k + b) \leq \sup (a_k + b_k + \epsilon) k \geq N k \infty \lim \sup (a_k + b_k - \epsilon) \leq \lim  \sup (a_k + b) \leq \lim \sup (a_k + b_k + \epsilon) \epsilon \lim \sup (a_n + b_n) = \lim \sup a_n + b. ,"['real-analysis', 'complex-analysis', 'limits', 'proof-verification', 'limsup-and-liminf']"
45,Proof of the Kramers-Kronig relation for amplitude and phase,Proof of the Kramers-Kronig relation for amplitude and phase,,"I learned that the the amplitude and phase of a transfer function of a minimum phase system are related by the Hilbert transform, specifically, $$\arg(H(\Omega))=-\frac{1}{\pi} \mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln|H(\omega)|}{\Omega-\omega}d\omega  $$ where $\mathrm{PV}$ denotes principal value. A proof I found will be provided at the end of this post. My question concerns the other direction: We can also obtain the amplitude from the phase by Hilbert transform, up to a constant multiplicative factor $c$ , i.e., $$ \mathcal{H} \{\arg(H(\omega))\}=\ln{|cH(\omega)|} $$ However, I am unable to find a rigorous proof. Does anyone know how to prove this? Thanks. Appendix: Proof of the forward direction (amp-to-phase). Referring to the contour below. By minimum phase, the transfer function $H$ has no zero at the lower half $\omega$ -plane, and thus $\ln{H(\omega)}$ is analytic there. Then by Cauchy integral theorem, we have $$\int_{C_P+C_R+C_0}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega=0$$ Integration along $C_0$ vanishes as the radius goes to infinity, because the denominator is second order. (It is not the case if the denominator is only first order, as in the standard proof of the real-imag form of KK relation, because the log function goes to $\infty$ in the lower half $\omega$ -plane.) Hence we have $$\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega=-\int_{C_R}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega\\=-i\pi\{\mathrm{res}_{\Omega}[\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}]+\mathrm{res}_{-\Omega}[\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}]\}\\=-i\pi\{\frac{\ln{H(\Omega)}}{2\Omega}+\frac{\ln{H(-\Omega)}}{-2\Omega}\}=\frac{\pi}{\Omega}\arg(H(\Omega))$$ Since the RHS is real, we only have to consider the real part of the LHS. By writing $\frac{1}{\omega^2-\Omega^2}=\frac{1}{2\Omega}[\frac{1}{\omega-\Omega}-\frac{1}{\omega+\Omega}]$ , and noting that $|H(\omega)|$ is an even function of $\omega$ , we have $$\frac{\pi}{\Omega}\arg(H(\Omega))=\frac{1}{2\Omega}\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{|H(\omega)|}}{\omega-\Omega}-\frac{\ln{|H(\omega)|}}{\omega+\Omega}d\omega\\ =-\frac{1}{\Omega}\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{|H(\omega)|}}{\Omega-\omega}d\omega$$ as was to be shown.","I learned that the the amplitude and phase of a transfer function of a minimum phase system are related by the Hilbert transform, specifically, where denotes principal value. A proof I found will be provided at the end of this post. My question concerns the other direction: We can also obtain the amplitude from the phase by Hilbert transform, up to a constant multiplicative factor , i.e., However, I am unable to find a rigorous proof. Does anyone know how to prove this? Thanks. Appendix: Proof of the forward direction (amp-to-phase). Referring to the contour below. By minimum phase, the transfer function has no zero at the lower half -plane, and thus is analytic there. Then by Cauchy integral theorem, we have Integration along vanishes as the radius goes to infinity, because the denominator is second order. (It is not the case if the denominator is only first order, as in the standard proof of the real-imag form of KK relation, because the log function goes to in the lower half -plane.) Hence we have Since the RHS is real, we only have to consider the real part of the LHS. By writing , and noting that is an even function of , we have as was to be shown.","\arg(H(\Omega))=-\frac{1}{\pi} \mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln|H(\omega)|}{\Omega-\omega}d\omega   \mathrm{PV} c  \mathcal{H} \{\arg(H(\omega))\}=\ln{|cH(\omega)|}  H \omega \ln{H(\omega)} \int_{C_P+C_R+C_0}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega=0 C_0 \infty \omega \mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega=-\int_{C_R}\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}d\omega\\=-i\pi\{\mathrm{res}_{\Omega}[\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}]+\mathrm{res}_{-\Omega}[\frac{\ln{H(\omega)}}{\omega^2-\Omega^2}]\}\\=-i\pi\{\frac{\ln{H(\Omega)}}{2\Omega}+\frac{\ln{H(-\Omega)}}{-2\Omega}\}=\frac{\pi}{\Omega}\arg(H(\Omega)) \frac{1}{\omega^2-\Omega^2}=\frac{1}{2\Omega}[\frac{1}{\omega-\Omega}-\frac{1}{\omega+\Omega}] |H(\omega)| \omega \frac{\pi}{\Omega}\arg(H(\Omega))=\frac{1}{2\Omega}\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{|H(\omega)|}}{\omega-\Omega}-\frac{\ln{|H(\omega)|}}{\omega+\Omega}d\omega\\
=-\frac{1}{\Omega}\mathrm{PV}\int_{-\infty}^{\infty}\frac{\ln{|H(\omega)|}}{\Omega-\omega}d\omega",['complex-analysis']
46,Generators of conformal isometries on two-dimensional manifolds,Generators of conformal isometries on two-dimensional manifolds,,"I'm studying Conformal Field Theory via Paul Ginsparg's lecture notes and have a doubt regarding the Witt algebra. Let $(M,g)$ be a smooth manifold with a metric tensor $g$ which we shall assume to have Euclidean signature for simplicity. A conformal isometry is a diffeomorphism $\phi :M\to M$ such that $\phi_\ast g = \Omega^2 g$ for some conformal factor. We wish to understand the generators of such transformations, i.e., vector fields $X\in \Gamma(TM)$ whose flow are conformal isometries. This demands that the Lie derivative of $g$ be $$\mathfrak{L}_Xg=\alpha g.$$ Now, in components this is $$\nabla_\mu X_\nu+\nabla_\nu X_\mu=\alpha g_{\mu\nu}.$$ Now suppose that $D = 2$ and $g_{\mu\nu}=\delta_{\mu\nu}$ . The resulting equations are the Cauchy-Riemann equations: $$\partial_1 X_2 = -\partial_2 X_1,\quad \partial_1 X_1 = \partial_2 X_2. \tag{1}$$ This I can understand. The problem is that one usually takes a big leap from here and says: That $\phi : M\to M$ must be a holomorphic or anti-holomorphic function; If we introduce complex coordinates on $M$ , $(z,\bar{z}) : U\subset M\to \mathbb{C}^2$ this means $\phi$ is either a function only of $z$ or only of $\bar{z}$ . That the algebra of the generators of conformal isometries is generated by $$\ell_n=-z^{n-1}\partial_z,\quad \bar{\ell}_n=-\bar{z}^{n-1}\partial_\bar{z}.$$ Now I fail to see how do we get from Eq. (1) to the two conclusions. All I know is that if the function $f : \mathbb{C}\to \mathbb{C}$ written $f(x,y) = u(x,y)+i v(x,y)$ has $u,v$ satisfying the Cauchy-Riemann equations, then $f$ is holomorphic . It is not the case here. What satisfies the Cauchy Riemann equations are the components of vector fields generators of conformal isometries , not the maps $\phi : M\to M$ themselves. Also, I fail to see why $\ell_n,\bar{\ell}_n$ are the generators. So how do we get from the vector fields satisfying the Cauchy Riemann equations to the conclusion that the finite diffeomorphisms are holomorphic/anti-holomorphic and that such vector fields are spanned by the $\ell_n,\bar{\ell}_n$ ?","I'm studying Conformal Field Theory via Paul Ginsparg's lecture notes and have a doubt regarding the Witt algebra. Let be a smooth manifold with a metric tensor which we shall assume to have Euclidean signature for simplicity. A conformal isometry is a diffeomorphism such that for some conformal factor. We wish to understand the generators of such transformations, i.e., vector fields whose flow are conformal isometries. This demands that the Lie derivative of be Now, in components this is Now suppose that and . The resulting equations are the Cauchy-Riemann equations: This I can understand. The problem is that one usually takes a big leap from here and says: That must be a holomorphic or anti-holomorphic function; If we introduce complex coordinates on , this means is either a function only of or only of . That the algebra of the generators of conformal isometries is generated by Now I fail to see how do we get from Eq. (1) to the two conclusions. All I know is that if the function written has satisfying the Cauchy-Riemann equations, then is holomorphic . It is not the case here. What satisfies the Cauchy Riemann equations are the components of vector fields generators of conformal isometries , not the maps themselves. Also, I fail to see why are the generators. So how do we get from the vector fields satisfying the Cauchy Riemann equations to the conclusion that the finite diffeomorphisms are holomorphic/anti-holomorphic and that such vector fields are spanned by the ?","(M,g) g \phi :M\to M \phi_\ast g = \Omega^2 g X\in \Gamma(TM) g \mathfrak{L}_Xg=\alpha g. \nabla_\mu X_\nu+\nabla_\nu X_\mu=\alpha g_{\mu\nu}. D = 2 g_{\mu\nu}=\delta_{\mu\nu} \partial_1 X_2 = -\partial_2 X_1,\quad \partial_1 X_1 = \partial_2 X_2. \tag{1} \phi : M\to M M (z,\bar{z}) : U\subset M\to \mathbb{C}^2 \phi z \bar{z} \ell_n=-z^{n-1}\partial_z,\quad \bar{\ell}_n=-\bar{z}^{n-1}\partial_\bar{z}. f : \mathbb{C}\to \mathbb{C} f(x,y) = u(x,y)+i v(x,y) u,v f \phi : M\to M \ell_n,\bar{\ell}_n \ell_n,\bar{\ell}_n","['complex-analysis', 'differential-geometry', 'manifolds', 'mathematical-physics', 'conformal-geometry']"
47,Calculate the integral value using residues,Calculate the integral value using residues,,"Hello I'm trying to solve this integral : $\\$ $$\int_{0}^{2\pi} \frac {\cos^2(x)}{4+3\cos(x)} dx.$$ I want to solve this integral using the theorem: $$\int_{0}^{2\pi} R\bigl(\cos(\alpha),\sin(\alpha)\bigr) d\alpha =2\pi i \sum_{|z_{k}|<1} \operatorname*{Res}_{z=z_k}f(z)$$ where $\displaystyle\;f(z)=\frac {1}{iz}R\biggl(\frac{1}{2}\Bigl(z+\frac {1}{z}\Bigr),\frac {1}{2i}\Bigl(z-\frac {1}{z}\Bigr)\biggr).$ Let $R(x,y)=\frac {x^2}{4+3x}$ , then i used the theorem to find $f(z)$ . So $f(z)=\frac{1}{i} \frac {(z+\frac {1}{z})^2}{16z+6z^{2}+6}$ then i find the zeros of ${16z+6z^{2}+6}$ which is $z_{1}=\frac{-8+\sqrt{28}}{6}$ and $z_{2}=\frac{-8-\sqrt{28}}{6}$ . Then i don't know but i should use only $z_{1}$ to answer the question? $$I=\int_{0}^{2\pi} \frac {\cos^2(x)}{4+3\cos(x)} dx=2\pi i {Res}_{z=z_1}f(z)$$ I found ${Res}_{z=z_1}f(z)=\frac{64-8\sqrt{28}}{i(-8\sqrt{28}+28)}$ Using the theorem I mentioned, I found the singular points ( $z_1=0$ essential point, $z_2=\frac{8+sqrt(28)}{6}$ and $z_3=\frac{8-sqrt(28)}{6}$ such as simple poles). But $z_3$ isn't in the disk $D(0,1)$ . So the integral $=2\pi i(Res_{z=z1}f(z)+Res_{z=z2}f(z))$ . I found the $Res_{z=z2} f(z)$ but i can't find $Res_{z=z1}f(z)$ . Can someone help me with that? Thank you :)","Hello I'm trying to solve this integral : I want to solve this integral using the theorem: where Let , then i used the theorem to find . So then i find the zeros of which is and . Then i don't know but i should use only to answer the question? I found Using the theorem I mentioned, I found the singular points ( essential point, and such as simple poles). But isn't in the disk . So the integral . I found the but i can't find . Can someone help me with that? Thank you :)","\\ \int_{0}^{2\pi} \frac {\cos^2(x)}{4+3\cos(x)} dx. \int_{0}^{2\pi} R\bigl(\cos(\alpha),\sin(\alpha)\bigr) d\alpha =2\pi i \sum_{|z_{k}|<1} \operatorname*{Res}_{z=z_k}f(z) \displaystyle\;f(z)=\frac {1}{iz}R\biggl(\frac{1}{2}\Bigl(z+\frac {1}{z}\Bigr),\frac {1}{2i}\Bigl(z-\frac {1}{z}\Bigr)\biggr). R(x,y)=\frac {x^2}{4+3x} f(z) f(z)=\frac{1}{i} \frac {(z+\frac {1}{z})^2}{16z+6z^{2}+6} {16z+6z^{2}+6} z_{1}=\frac{-8+\sqrt{28}}{6} z_{2}=\frac{-8-\sqrt{28}}{6} z_{1} I=\int_{0}^{2\pi} \frac {\cos^2(x)}{4+3\cos(x)} dx=2\pi i {Res}_{z=z_1}f(z) {Res}_{z=z_1}f(z)=\frac{64-8\sqrt{28}}{i(-8\sqrt{28}+28)} z_1=0 z_2=\frac{8+sqrt(28)}{6} z_3=\frac{8-sqrt(28)}{6} z_3 D(0,1) =2\pi i(Res_{z=z1}f(z)+Res_{z=z2}f(z)) Res_{z=z2} f(z) Res_{z=z1}f(z)",['complex-analysis']
48,Show that a conformal equivalence of two tori lifts to an automorphism of $\mathbb C$,Show that a conformal equivalence of two tori lifts to an automorphism of,\mathbb C,"Let $L_1,L_2$ be two lattices of rank 2 in $\mathbb C$ . Then $\mathbb C/L_1$ and $\mathbb C/L_2$ are two tori. Let $$f:\mathbb C/L_1\to\mathbb C/L_2$$ be a conformal equivalence. Show that the lift $\tilde f:\mathbb C\to\mathbb C$ of $f$ is an automorphism (conformal equivalence to itself) of $\mathbb C$ . My attempt: Donote the natural projections by $$\pi_1:\mathbb C\to\mathbb C/L_1$$ $$\pi_2:\mathbb C\to\mathbb C/L_2$$ Then the lift $\tilde f$ satisfies $$f\circ\pi_1=\pi_2\circ\tilde f$$ and is holomorphic. The same applies to $f^{-1}$ . $$f^{-1}\circ\pi_2=\pi_1\circ\widetilde{f^{-1}}$$ $$\implies \pi_2=(ff^{-1})\pi_2=f\pi_1\widetilde{f^{-1}}=\pi_2\tilde f\widetilde{f^{-1}}$$ But I can't cancel $\pi_2$ as it is not injective. What am I missing?",Let be two lattices of rank 2 in . Then and are two tori. Let be a conformal equivalence. Show that the lift of is an automorphism (conformal equivalence to itself) of . My attempt: Donote the natural projections by Then the lift satisfies and is holomorphic. The same applies to . But I can't cancel as it is not injective. What am I missing?,"L_1,L_2 \mathbb C \mathbb C/L_1 \mathbb C/L_2 f:\mathbb C/L_1\to\mathbb C/L_2 \tilde f:\mathbb C\to\mathbb C f \mathbb C \pi_1:\mathbb C\to\mathbb C/L_1 \pi_2:\mathbb C\to\mathbb C/L_2 \tilde f f\circ\pi_1=\pi_2\circ\tilde f f^{-1} f^{-1}\circ\pi_2=\pi_1\circ\widetilde{f^{-1}} \implies \pi_2=(ff^{-1})\pi_2=f\pi_1\widetilde{f^{-1}}=\pi_2\tilde f\widetilde{f^{-1}} \pi_2","['general-topology', 'complex-analysis', 'algebraic-topology', 'covering-spaces']"
49,Quotient by finite subgroups are biholomorphic.,Quotient by finite subgroups are biholomorphic.,,Let $X$ be a complex manifold and let $G$ and $H$ be two finite subgroups of its automorphism group $Aut(X)$ . Suppose we are given that $X/G$ and $X/H$ are bi-holomorphic complex manifolds. What can we say about $G$ and $H$ ? Is it the case that $G$ and $H$ have to be isomorphic as subgroups?,Let be a complex manifold and let and be two finite subgroups of its automorphism group . Suppose we are given that and are bi-holomorphic complex manifolds. What can we say about and ? Is it the case that and have to be isomorphic as subgroups?,X G H Aut(X) X/G X/H G H G H,"['complex-analysis', 'algebraic-topology', 'differential-topology', 'complex-geometry', 'topological-groups']"
50,analytic function that maps the entire complex plane into the real axis,analytic function that maps the entire complex plane into the real axis,,An analytic function that maps the entire complex plane into the real axis must map the imaginary axis onto: A) the entire real axis B) a point C) a ray D) an open finite interval E) the empty set I was thinking that it might be a constant function.  Any help would be appreciated!,An analytic function that maps the entire complex plane into the real axis must map the imaginary axis onto: A) the entire real axis B) a point C) a ray D) an open finite interval E) the empty set I was thinking that it might be a constant function.  Any help would be appreciated!,,['complex-analysis']
51,"Is there a Mellin transform or an analogue on $L^2([0,2\pi])$ or $\ell^2(\mathbb{Z})$?",Is there a Mellin transform or an analogue on  or ?,"L^2([0,2\pi]) \ell^2(\mathbb{Z})","From Wikipedia, the Mellin transform is an isometry $M : L^2(\mathbb{R}^+) \mapsto L^2(\mathbb{R})$ , $$\{M f\} (s) := \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}^+} x^{-1/2 + \mathrm{i} s} f(x) dx.$$ https://en.wikipedia.org/wiki/Mellin_transform Does anyone know if there is an analogue of this transformation on $L^2([0,2\pi])$ or $\ell^2(\mathbb{Z})$ ? Thanks !","From Wikipedia, the Mellin transform is an isometry , https://en.wikipedia.org/wiki/Mellin_transform Does anyone know if there is an analogue of this transformation on or ? Thanks !","M : L^2(\mathbb{R}^+) \mapsto L^2(\mathbb{R}) \{M f\} (s) := \frac{1}{\sqrt{2\pi}} \int_{\mathbb{R}^+} x^{-1/2 + \mathrm{i} s} f(x) dx. L^2([0,2\pi]) \ell^2(\mathbb{Z})","['complex-analysis', 'analysis', 'fourier-analysis', 'integral-transforms', 'mellin-transform']"
52,Find all entire functions $f$ satisfying $\Re(f(z))\leq\frac{2}{|z|}$ whenever $|z|>1\iff \frac{1}{|z|}< 1$,Find all entire functions  satisfying  whenever,f \Re(f(z))\leq\frac{2}{|z|} |z|>1\iff \frac{1}{|z|}< 1,"I've been working in the following: Find all the entire function $f$ satisfying $$\Re (f(z))\leq \frac{2}{|z|}\quad\textrm{  whenever } \quad|z|>1\iff \frac{1}{|z|}< 1$$ Solution: Suppose that $f$ is entire with under these conditions. First, $\Re f\leq 2$ . Second, consider $g(z)=\exp(f(z))$ , then $g$ is entire too and $$ |g(z)|=|\exp(f(z))|=\exp(\Re(f(z)))\leq e^2. $$ Hence, by  Liouvilles theorem, $g(z)=C$ .  Finally, we observe $$g(z)=\exp(f(z))\Longrightarrow g'(z)=f'(z)\exp(f(z))\Longrightarrow 0=f'(z)$$ meaning that $f(z)$ must be a constant. I just wonder if I miss steps or I'm wrong. Thanks","I've been working in the following: Find all the entire function satisfying Solution: Suppose that is entire with under these conditions. First, . Second, consider , then is entire too and Hence, by  Liouvilles theorem, .  Finally, we observe meaning that must be a constant. I just wonder if I miss steps or I'm wrong. Thanks","f \Re (f(z))\leq \frac{2}{|z|}\quad\textrm{  whenever } \quad|z|>1\iff \frac{1}{|z|}< 1 f \Re f\leq 2 g(z)=\exp(f(z)) g 
|g(z)|=|\exp(f(z))|=\exp(\Re(f(z)))\leq e^2.
 g(z)=C g(z)=\exp(f(z))\Longrightarrow g'(z)=f'(z)\exp(f(z))\Longrightarrow 0=f'(z) f(z)",['complex-analysis']
53,Differential in Complex Analysis,Differential in Complex Analysis,,"If we define the operator $$\partial_{\bar{z}} = \frac{\partial_x + i \partial_y}{2}$$ then it is claimed that for $\lambda \in \mathbb{R}$ we have the following series of equalities: $$ \frac{1}{\pi} \int_{\mathbb{R}^2} \frac{\partial_{\bar{z}} f(x+ i y) }{\lambda - x- y} dx dy = \frac{1}{2 \pi i} \int_{\mathbb{R}^2} \partial_{\bar{z}} \left( \frac{f(x + i y)}{\lambda - x- iy} \right) dz d\bar{z} = \frac{1}{2 \pi i} \int_{\mathbb{R}^2} d \left( \frac{f(x + i y)}{\lambda - x- iy} dz \right) $$ where the operator $d$ is the differential in the sense of a $~1$ -form. I'm having trouble proving both equalities and do not have any idea what the statement ""is the differential in the sense of a $~1$ -form"" means in this context. The first equality they claim follows from the observation $\partial_{\bar{z}} (\lambda - z)^{-1}= 0$ which I can prove.","If we define the operator then it is claimed that for we have the following series of equalities: where the operator is the differential in the sense of a -form. I'm having trouble proving both equalities and do not have any idea what the statement ""is the differential in the sense of a -form"" means in this context. The first equality they claim follows from the observation which I can prove.","\partial_{\bar{z}} = \frac{\partial_x + i \partial_y}{2} \lambda \in \mathbb{R} 
\frac{1}{\pi} \int_{\mathbb{R}^2} \frac{\partial_{\bar{z}} f(x+ i y) }{\lambda - x- y} dx dy = \frac{1}{2 \pi i} \int_{\mathbb{R}^2} \partial_{\bar{z}} \left( \frac{f(x + i y)}{\lambda - x- iy} \right) dz d\bar{z} = \frac{1}{2 \pi i} \int_{\mathbb{R}^2} d \left( \frac{f(x + i y)}{\lambda - x- iy} dz \right)
 d ~1 ~1 \partial_{\bar{z}} (\lambda - z)^{-1}= 0","['complex-analysis', 'differential-forms']"
54,Prove a tough limit involving the digamma function,Prove a tough limit involving the digamma function,,"Here I have a limit to which I arrived while working on a seperate integral through  Mellin Transforms. $$\lim\limits_{s\to -1^{-}}\Big[\psi_{(0)}(s)-\frac{\pi}{2}\tan\left(\frac{\pi s}{2}\right)\Big]$$ Here, we have $\psi_{(0)}(s)$ which represents the digamma function. I graphed the whole thing on Desmos to see what it looked like approaching $-1$ , and it seems very likely that the limit approaches $$1-\gamma$$ Here, $\gamma$ is the Euler-Mascheroni constant. I would like to know if there is a concrete way of evaluating this limit. I tried doing some work with it: $$=\lim\limits_{x\to 0}\Big[\psi_{(0)}(x-1)-\frac{\pi}{2}\tan\left(\frac{\pi}{2}(x-1)\right)\Big]$$ $$=\lim\limits_{x\to 0}\Big[\frac{1}{1-x}+\psi_{(0)}(x)-\frac{\pi}{2}\tan\left(\frac{\pi}{2}(x-1)\right)\Big]$$ I don't really know where to go from here. I figure maybe a Taylor expansion could do the trick. However, the expansions for both the digamma and tangent functions are largely unrelated, it seems. I'm curious to see a solution to this problem, and wish you all good luck! A natural extension of this question would be to find: $$\lim\limits_{s\to (-1-2k)^{-}}\Big[\psi_{(0)}(s)-\frac{\pi}{2}\tan\left(\frac{\pi s}{2}\right)\Big]\,\,\forall\,\,k\in Z^{+}$$ This generalized limit might be the bane of my existance.","Here I have a limit to which I arrived while working on a seperate integral through  Mellin Transforms. Here, we have which represents the digamma function. I graphed the whole thing on Desmos to see what it looked like approaching , and it seems very likely that the limit approaches Here, is the Euler-Mascheroni constant. I would like to know if there is a concrete way of evaluating this limit. I tried doing some work with it: I don't really know where to go from here. I figure maybe a Taylor expansion could do the trick. However, the expansions for both the digamma and tangent functions are largely unrelated, it seems. I'm curious to see a solution to this problem, and wish you all good luck! A natural extension of this question would be to find: This generalized limit might be the bane of my existance.","\lim\limits_{s\to -1^{-}}\Big[\psi_{(0)}(s)-\frac{\pi}{2}\tan\left(\frac{\pi s}{2}\right)\Big] \psi_{(0)}(s) -1 1-\gamma \gamma =\lim\limits_{x\to 0}\Big[\psi_{(0)}(x-1)-\frac{\pi}{2}\tan\left(\frac{\pi}{2}(x-1)\right)\Big] =\lim\limits_{x\to 0}\Big[\frac{1}{1-x}+\psi_{(0)}(x)-\frac{\pi}{2}\tan\left(\frac{\pi}{2}(x-1)\right)\Big] \lim\limits_{s\to (-1-2k)^{-}}\Big[\psi_{(0)}(s)-\frac{\pi}{2}\tan\left(\frac{\pi s}{2}\right)\Big]\,\,\forall\,\,k\in Z^{+}","['real-analysis', 'calculus', 'complex-analysis', 'limits', 'digamma-function']"
55,Question regarding the Taub-NUT metric on $\mathbb{S}^3 \times \mathbb{R}^+$.,Question regarding the Taub-NUT metric on .,\mathbb{S}^3 \times \mathbb{R}^+,"I have a question regarding Claude Lebrun's paper Complete Ricci-flat Khler metrics on $\mathbb{C}^n$ need not be flat. In the introduction of the paper, he writes that the Taub-NUT metric is given explicitly by $$g = \frac{\rho +1}{4 \rho} d\rho^2 + \rho(1+\rho) \left[ \sigma_1^2 + \sigma_2^2 \right] + \frac{\rho}{\rho+1}\sigma_3^2,$$ where $\sigma_1, \sigma_2, \sigma_3$ is a left-invariant coframe for $\mathbb{S}^3$ and where $\rho \in \mathbb{R}^+$ . He continues to mention that there is a common erroneous assertion which maintains that this metric is not Khler -- the reasoning being that with respect to the most obvious integrable almost complex structure $(\sigma_1 \mapsto \sigma_2, \sigma_3 \mapsto -(1+\rho)d\rho/2\rho)$ , the metric is Hermitian but not Khler. However, the metric has self-dual curvature tensor, and so has holonomy $SU(2)$ . Q: I want to verify that the above almost complex structure is integrable. It seems that the most straightforward way of doing this is by showing that the Nijenhuis tensor vanishes identically. We can write vector fields $X$ and $Y$ on $\mathbb{S}^3 \times \mathbb{R}^+$ as $X = \alpha_1 \sigma_1 + \alpha_2 \sigma_2 + \alpha_3 \sigma_3 + \alpha_4 d\rho$ and $Y = \beta_1 \sigma_1 + \beta_2 \sigma_2 + \beta_3 \sigma_3 + \beta_4 d\rho$ . Then \begin{eqnarray*} JX &=& \alpha_1 \sigma_2 - \alpha_2 \sigma_1 - \alpha_3 \frac{1+\rho}{2\rho} d\rho - \alpha_4 \frac{2\rho}{1+\rho} \sigma_3, \\ JY &=& \beta_1 \sigma_2 - \beta_2 \sigma_1 - \beta_3 \frac{1+\rho}{2\rho} d\rho - \beta_4 \frac{2\rho}{1+\rho} \sigma_3.  \end{eqnarray*} The result Lie bracket computations become very cumbersome to treat. Is there an easier way of showing that the above almost complex structure is integrable?","I have a question regarding Claude Lebrun's paper Complete Ricci-flat Khler metrics on need not be flat. In the introduction of the paper, he writes that the Taub-NUT metric is given explicitly by where is a left-invariant coframe for and where . He continues to mention that there is a common erroneous assertion which maintains that this metric is not Khler -- the reasoning being that with respect to the most obvious integrable almost complex structure , the metric is Hermitian but not Khler. However, the metric has self-dual curvature tensor, and so has holonomy . Q: I want to verify that the above almost complex structure is integrable. It seems that the most straightforward way of doing this is by showing that the Nijenhuis tensor vanishes identically. We can write vector fields and on as and . Then The result Lie bracket computations become very cumbersome to treat. Is there an easier way of showing that the above almost complex structure is integrable?","\mathbb{C}^n g = \frac{\rho +1}{4 \rho} d\rho^2 + \rho(1+\rho) \left[ \sigma_1^2 + \sigma_2^2 \right] + \frac{\rho}{\rho+1}\sigma_3^2, \sigma_1, \sigma_2, \sigma_3 \mathbb{S}^3 \rho \in \mathbb{R}^+ (\sigma_1 \mapsto \sigma_2, \sigma_3 \mapsto -(1+\rho)d\rho/2\rho) SU(2) X Y \mathbb{S}^3 \times \mathbb{R}^+ X = \alpha_1 \sigma_1 + \alpha_2 \sigma_2 + \alpha_3 \sigma_3 + \alpha_4 d\rho Y = \beta_1 \sigma_1 + \beta_2 \sigma_2 + \beta_3 \sigma_3 + \beta_4 d\rho \begin{eqnarray*}
JX &=& \alpha_1 \sigma_2 - \alpha_2 \sigma_1 - \alpha_3 \frac{1+\rho}{2\rho} d\rho - \alpha_4 \frac{2\rho}{1+\rho} \sigma_3, \\
JY &=& \beta_1 \sigma_2 - \beta_2 \sigma_1 - \beta_3 \frac{1+\rho}{2\rho} d\rho - \beta_4 \frac{2\rho}{1+\rho} \sigma_3. 
\end{eqnarray*}","['complex-analysis', 'differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
56,If $\Omega$ is convex and $|f'(z)-1|<1$ then $f$ is injective,If  is convex and  then  is injective,\Omega |f'(z)-1|<1 f,"The statement is: Let $\Omega$ be an open convex subset of $\mathbb{C}$ , and $f\in\mathcal{H}(\Omega)$ with $|f'(z)-1|<1$ , for all $z\in\Omega$ . Prove that $f$ is injective. I want to know if my proof is correct. Suppose there exist $\alpha,\beta\in\Omega$ with $\alpha\ne\beta$ and $f(\alpha)=f(\beta)$ . Because $\Omega$ is convex, we can integrate over the segment $\alpha\beta$ , which is in $\Omega$ . Then we have $$ \left|\int_{\alpha}^{\beta} (f'(z)-1) \,dz\right| = \left|\left. f(z)-z\right]_{\alpha}^{\beta}\right|=  |f(\alpha)-\alpha - f(\beta)+\beta| = |\beta -\alpha|. $$ By the other hand we have $$ \left|\int_{\alpha}^{\beta}( f'(z)-1) \,dz\right|\leq \int_{\alpha}^{\beta}|f'(z)-1||dz| < \int_{\alpha}^{\beta}  |dz| = |\beta - \alpha| $$ but this is not possible. Is this correct? Thanks","The statement is: Let be an open convex subset of , and with , for all . Prove that is injective. I want to know if my proof is correct. Suppose there exist with and . Because is convex, we can integrate over the segment , which is in . Then we have By the other hand we have but this is not possible. Is this correct? Thanks","\Omega \mathbb{C} f\in\mathcal{H}(\Omega) |f'(z)-1|<1 z\in\Omega f \alpha,\beta\in\Omega \alpha\ne\beta f(\alpha)=f(\beta) \Omega \alpha\beta \Omega 
\left|\int_{\alpha}^{\beta} (f'(z)-1) \,dz\right| = \left|\left. f(z)-z\right]_{\alpha}^{\beta}\right|= 
|f(\alpha)-\alpha - f(\beta)+\beta| = |\beta -\alpha|.
 
\left|\int_{\alpha}^{\beta}( f'(z)-1) \,dz\right|\leq \int_{\alpha}^{\beta}|f'(z)-1||dz| < \int_{\alpha}^{\beta} 
|dz| = |\beta - \alpha|
","['complex-analysis', 'proof-verification']"
57,Uniform convergence of sequence of analytic functions,Uniform convergence of sequence of analytic functions,,"I am having trouble with the following question: Let $\Omega$ be a non-empty open subset of $\mathbb{C}$ , and let $f$ be a continuous function on $\Omega$ . Suppose that $f_1, f_2,f_3,...$ are analytic on $\Omega$ , and that $$\lim_{n\rightarrow \infty} \int_{D} \vert f_n (x+ iy) - f(x + iy)  \vert dxdy = 0, $$ for every closed disk $D \subset \Omega$ . Show that $f$ is analytic, and that $f_n \rightarrow f$ uniformly on compact subsets of $\Omega$ . $\textbf{Thoughts}:$ $\textbf{1.}$ I am aware that Cauchy's Theorem will ensure that $f$ analytic provided $f_n \rightarrow f$ uniformly. $\textbf{2.}$ The limit of the integral is zero namely for $\sup_{z \in D} \vert f_n(x+iy) - f(x+iy) \vert$ . $\textbf{3.}$ Triangle Inequality. I've pushed some things around, but I don't think I am properly timing $\vert \int \vert \leq \int \vert \vert$ to see what next steps should be. $\textbf{4.}$ Montel's Theorem and Normal families smell like they could be related. One concern is using some circular logic that is wrapped up in the relationship of Dominated Convergence and Uniform Continuity. Clarification, tips, resources, etc., will all be greatly appreciated.","I am having trouble with the following question: Let be a non-empty open subset of , and let be a continuous function on . Suppose that are analytic on , and that for every closed disk . Show that is analytic, and that uniformly on compact subsets of . I am aware that Cauchy's Theorem will ensure that analytic provided uniformly. The limit of the integral is zero namely for . Triangle Inequality. I've pushed some things around, but I don't think I am properly timing to see what next steps should be. Montel's Theorem and Normal families smell like they could be related. One concern is using some circular logic that is wrapped up in the relationship of Dominated Convergence and Uniform Continuity. Clarification, tips, resources, etc., will all be greatly appreciated.","\Omega \mathbb{C} f \Omega f_1, f_2,f_3,... \Omega \lim_{n\rightarrow \infty} \int_{D} \vert f_n (x+ iy) - f(x + iy)  \vert dxdy = 0,  D \subset \Omega f f_n \rightarrow f \Omega \textbf{Thoughts}: \textbf{1.} f f_n \rightarrow f \textbf{2.} \sup_{z \in D} \vert f_n(x+iy) - f(x+iy) \vert \textbf{3.} \vert \int \vert \leq \int \vert \vert \textbf{4.}","['complex-analysis', 'uniform-convergence']"
58,Are the Euclidean plane and the Minkowski plane conformally equivalent?,Are the Euclidean plane and the Minkowski plane conformally equivalent?,,"Are the Euclidean plane $R^{2,0}$ and the Minkowski plane $R^{1,1}$ conformally equivalent?",Are the Euclidean plane and the Minkowski plane conformally equivalent?,"R^{2,0} R^{1,1}","['complex-analysis', 'analysis', 'differential-geometry', 'conformal-geometry']"
59,Laurent Series $f(z)=\frac{1}{(z+1)(z-2)}$ with conditions,Laurent Series  with conditions,f(z)=\frac{1}{(z+1)(z-2)},"I want to find the laurent series of the function $$f(z)=\frac{1}{(z+1)(z-2)}$$ for the following conditions: $|z|<1$ $2<|z|<\infty$ I have found the series for first condition, by partial fractions as $$f(z)=\frac13(\frac{1}{z-2}-\frac{1}{z+1})=-\frac12+\frac z4-\frac{3z^8}{8}+\cdots$$ But how to find the series for the second condition $2<|z|<\infty$ , as in the second condition function is holomorphic everywhere? We can use also use the long general procedure using contour integration, but that I know to be used when laurent series is to be found out at a particular point $z=z_0$ , but how to perform  it for intervals ? Another doubt And sometimes I get confused when we can say taylor's series will be same as laurent series?","I want to find the laurent series of the function for the following conditions: I have found the series for first condition, by partial fractions as But how to find the series for the second condition , as in the second condition function is holomorphic everywhere? We can use also use the long general procedure using contour integration, but that I know to be used when laurent series is to be found out at a particular point , but how to perform  it for intervals ? Another doubt And sometimes I get confused when we can say taylor's series will be same as laurent series?",f(z)=\frac{1}{(z+1)(z-2)} |z|<1 2<|z|<\infty f(z)=\frac13(\frac{1}{z-2}-\frac{1}{z+1})=-\frac12+\frac z4-\frac{3z^8}{8}+\cdots 2<|z|<\infty z=z_0,"['complex-analysis', 'complex-numbers', 'power-series', 'taylor-expansion', 'laurent-series']"
60,Invertibility of weighted shift operator.,Invertibility of weighted shift operator.,,"A linear operator $T$ on a (complex) separable Hilbert space $H$ is said to be a weighted shift operator if there is some orthogonal basis $\{e_n\}_n$ and weight sequence $\{w_n\}_n$ such that $$Te_n=w_n e_{n+1}, \forall n$$ $T$ is unilateral if $n$ runs over $\mathbb{N}$ and bilateral if $\mathbb{Z}$ . The adjoint is given by $$T^* e_n=\overline{w}_{n-1}e_{n-1} \text{ for all } n $$ if $T$ is bilateral and \begin{align*} 		T^* e_n&= \overline{w}_{n-1} e_{n-1} \text{	for all } n\geq 1\\ 		T^* e_0&=0 		\end{align*} if $T$ is unilateral I saw in a paper that the unilateral shift is never invertible with the reason that $T^*$ is not invertible but the bilateral shift can be invertible given some conditions . Do we have that an operator is invertible iff its adjoint is invertible? I can't see the reason behind the conclusion. Please I need hints. Thanks",A linear operator on a (complex) separable Hilbert space is said to be a weighted shift operator if there is some orthogonal basis and weight sequence such that is unilateral if runs over and bilateral if . The adjoint is given by if is bilateral and if is unilateral I saw in a paper that the unilateral shift is never invertible with the reason that is not invertible but the bilateral shift can be invertible given some conditions . Do we have that an operator is invertible iff its adjoint is invertible? I can't see the reason behind the conclusion. Please I need hints. Thanks,"T H \{e_n\}_n \{w_n\}_n Te_n=w_n e_{n+1}, \forall n T n \mathbb{N} \mathbb{Z} T^* e_n=\overline{w}_{n-1}e_{n-1} \text{ for all } n  T \begin{align*}
		T^* e_n&= \overline{w}_{n-1} e_{n-1} \text{	for all } n\geq 1\\
		T^* e_0&=0
		\end{align*} T T^*","['complex-analysis', 'functional-analysis', 'operator-theory']"
61,Can we let $n$ go to $\infty$ after applying the fundamental theorem of algebra to a polynomial of degree $n$?,Can we let  go to  after applying the fundamental theorem of algebra to a polynomial of degree ?,n \infty n,"Recently I came across a proof of the infinite product for $\sin z$ ( https://www.sciencedirect.com/science/article/pii/0022247X77902347 ). It applies the fundamental theorem of algebra to $$p_{n}(z)=\dfrac{1}{2}\left(\left(1+\frac{z}{n}\right)^{n}-\left(1-\frac{z}{n}\right)^{n}\right),$$ which it factors to a product. But it also states that $n=2m+1$ and lets $n$ and $m$ go to infinity. Then how is the factorization to a product, by applying the fundamental theorem of algebra, possible? I'm confused because the fundamental theorem of algebra holds only for finite polynomials , but $p_{n}(z)$ is not a finite polynomial if we let $n$ go to $\infty$ .","Recently I came across a proof of the infinite product for ( https://www.sciencedirect.com/science/article/pii/0022247X77902347 ). It applies the fundamental theorem of algebra to which it factors to a product. But it also states that and lets and go to infinity. Then how is the factorization to a product, by applying the fundamental theorem of algebra, possible? I'm confused because the fundamental theorem of algebra holds only for finite polynomials , but is not a finite polynomial if we let go to .","\sin z p_{n}(z)=\dfrac{1}{2}\left(\left(1+\frac{z}{n}\right)^{n}-\left(1-\frac{z}{n}\right)^{n}\right), n=2m+1 n m p_{n}(z) n \infty","['calculus', 'abstract-algebra', 'complex-analysis', 'trigonometry', 'polynomials']"
62,What is the most commonly used metric in $\mathbb{C} \times \mathbb{C}$?,What is the most commonly used metric in ?,\mathbb{C} \times \mathbb{C},"I am reading Conway's Functions of One Complex Variable , and many times it makes reference to a function from $\mathbb{C} \times \mathbb{C}$ being continuous. I would like to rigorously prove such assertions, so I have to know which metric he is referring to. I haven't taken topology, so I'm not sure what the most natural or nice metric would be. The one I've come up with is $d[(z_1, w_1), (z_2, w_2)] = |z_1-z_2| + |w_1 - w_2|$ . Is there a ""natural"" metric that is most often used on $\mathbb{C} \times \mathbb{C}?$","I am reading Conway's Functions of One Complex Variable , and many times it makes reference to a function from being continuous. I would like to rigorously prove such assertions, so I have to know which metric he is referring to. I haven't taken topology, so I'm not sure what the most natural or nice metric would be. The one I've come up with is . Is there a ""natural"" metric that is most often used on","\mathbb{C} \times \mathbb{C} d[(z_1, w_1), (z_2, w_2)] = |z_1-z_2| + |w_1 - w_2| \mathbb{C} \times \mathbb{C}?","['real-analysis', 'general-topology', 'complex-analysis', 'analysis']"
63,Proof of $\Gamma(1-z) \Gamma (z) = \frac{\pi}{\sin \pi z}$,Proof of,\Gamma(1-z) \Gamma (z) = \frac{\pi}{\sin \pi z},"In the proof of the above result from the book by Stein and Shakarchi, they have used the substitution $vt = u$ where $t>0$ to get $$\Gamma (1-z) = \int_{0}^{\infty} e^{-u} u^{-z} du = t\int_{0}^{\infty} e^{-vt} (vt)^{-z} dv.$$ Well, up to this part it was okay. But I am not understanding the following mixing of integrals: $$ \begin{align} \Gamma (1-z) \Gamma (z) & = \int_{0}^{\infty} e^{-t} t^{z-1} \Gamma (1-z) dt \\ &= \int_{0}^{\infty} e^{-t} t^{z-1} \left(t \int_{0}^{\infty} e^{-vt}(vt)^{-z}dv \right) dt  \\ &=\int_{0}^{\infty} \int_{0}^{\infty} e^{-t(1+v)}v^{-z} dvdt. \end{align}$$ I want to understand how the introduced variable $t$ is taken to be the same with the dummy variable $t$ while mixing the integrals.","In the proof of the above result from the book by Stein and Shakarchi, they have used the substitution where to get Well, up to this part it was okay. But I am not understanding the following mixing of integrals: I want to understand how the introduced variable is taken to be the same with the dummy variable while mixing the integrals.","vt = u t>0 \Gamma (1-z) = \int_{0}^{\infty} e^{-u} u^{-z} du = t\int_{0}^{\infty} e^{-vt} (vt)^{-z} dv.  \begin{align} \Gamma (1-z) \Gamma (z) & = \int_{0}^{\infty} e^{-t} t^{z-1} \Gamma (1-z) dt \\
&= \int_{0}^{\infty} e^{-t} t^{z-1} \left(t \int_{0}^{\infty} e^{-vt}(vt)^{-z}dv \right) dt  \\ &=\int_{0}^{\infty} \int_{0}^{\infty} e^{-t(1+v)}v^{-z} dvdt. \end{align} t t","['complex-analysis', 'proof-verification', 'gamma-function']"
64,Inverse Laplace transform of $F(s)=\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}}$ using complex integration,Inverse Laplace transform of  using complex integration,F(s)=\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}},"I want to find the inverse Laplace transform of $$F(s)=\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}}$$ I tried to use the Bromwich integral $$f(t)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}}e^{st}\,ds$$ My progress so far has been stunted by the fact that we have a branch point at s=0. The contour may be like this. But I don't know how to perform the integration. Any help is appreciated.",I want to find the inverse Laplace transform of I tried to use the Bromwich integral My progress so far has been stunted by the fact that we have a branch point at s=0. The contour may be like this. But I don't know how to perform the integration. Any help is appreciated.,"F(s)=\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}} f(t)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}}e^{st}\,ds","['complex-analysis', 'laplace-transform', 'contour-integration']"
65,Differentiability of $G_k(w)$,Differentiability of,G_k(w),"Suppose that $f$ is holomorphic in a neighborhood of $z_0$ , and that all complex derivatives of $f$ up to order $m-1$ at $z_0$ vanish, namely, $f^{(j)}(z_0)=0$ for all $j=0,...,m-1$ , but that $f^{(m)}(z_0)\ne 0$ . (a)Prove that there exist $\epsilon>0$ and $\delta>0$ such that, for every $k\in\mathbb N$ , the equation $$ G_k(w)=\frac{1}{2\pi i}\int_{|\zeta-z_0|=\epsilon}\frac{\zeta^k f'(\zeta)}{f(\zeta)-w}d\zeta $$ defines a holomorphic function of $w$ in the set $$ D_\delta(f(z_0))=\{  w\in\mathbb C:|w-f(z_0)|<\delta \}.$$ (b) Prove that, in the context of (a), if $w\in D_\delta(f(z_0))$ then the equation $f(z)-w=0$ has $m$ roots (counted with multiplicity), $z_1,...,z_m,$ inside $|z-z_0|<\epsilon$ , and that $$G_k(w)=\sum_{j=1}^m z_j^k.$$ My attempt: (a) Suppose $w\in D_\delta(f(z_0))$ , then \begin{align} \frac{G_k(w+\Delta w)-G_k(w)}{\Delta w}&=\frac{1}{2\pi i}\int_{|\zeta-z_0|=\epsilon}\frac{\zeta^k f'(\zeta)}{(f(\zeta)-w-\Delta w)(f(\zeta)-w)}d\zeta \end{align} I was about to show that the modulus of integrand is bounded by an integrable function so that I can apply the dominated convergence theorem. However, I cannot find such a function... Edit: We know that if $\gamma$ is a Jordan curve, $\varphi(\zeta)$ is continuous on $\gamma$ , then the function $$ F(z)=\frac{1}{2\pi i}\int_\gamma\frac{\varphi (\zeta)}{\zeta-z}d\zeta $$ is analytic on each region of $\overline{\mathbb C}\setminus\gamma$ . The proof of differentiability of $F(z)$ depends on the non-vanishment of $\zeta-z$ on $\overline{\mathbb C}\setminus\gamma$ which clearly is not the case in this problem. So we have to use different techniques.","Suppose that is holomorphic in a neighborhood of , and that all complex derivatives of up to order at vanish, namely, for all , but that . (a)Prove that there exist and such that, for every , the equation defines a holomorphic function of in the set (b) Prove that, in the context of (a), if then the equation has roots (counted with multiplicity), inside , and that My attempt: (a) Suppose , then I was about to show that the modulus of integrand is bounded by an integrable function so that I can apply the dominated convergence theorem. However, I cannot find such a function... Edit: We know that if is a Jordan curve, is continuous on , then the function is analytic on each region of . The proof of differentiability of depends on the non-vanishment of on which clearly is not the case in this problem. So we have to use different techniques.","f z_0 f m-1 z_0 f^{(j)}(z_0)=0 j=0,...,m-1 f^{(m)}(z_0)\ne 0 \epsilon>0 \delta>0 k\in\mathbb N  G_k(w)=\frac{1}{2\pi i}\int_{|\zeta-z_0|=\epsilon}\frac{\zeta^k f'(\zeta)}{f(\zeta)-w}d\zeta  w  D_\delta(f(z_0))=\{ 
w\in\mathbb C:|w-f(z_0)|<\delta \}. w\in D_\delta(f(z_0)) f(z)-w=0 m z_1,...,z_m, |z-z_0|<\epsilon G_k(w)=\sum_{j=1}^m z_j^k. w\in D_\delta(f(z_0)) \begin{align}
\frac{G_k(w+\Delta w)-G_k(w)}{\Delta w}&=\frac{1}{2\pi i}\int_{|\zeta-z_0|=\epsilon}\frac{\zeta^k f'(\zeta)}{(f(\zeta)-w-\Delta w)(f(\zeta)-w)}d\zeta
\end{align} \gamma \varphi(\zeta) \gamma  F(z)=\frac{1}{2\pi i}\int_\gamma\frac{\varphi (\zeta)}{\zeta-z}d\zeta  \overline{\mathbb C}\setminus\gamma F(z) \zeta-z \overline{\mathbb C}\setminus\gamma",['complex-analysis']
66,$f$ is non-vanishing holomorphic function on open unit disc such that $|f(z)|\to1$ as $|z|\to1$. Is $f$ constant?,is non-vanishing holomorphic function on open unit disc such that  as . Is  constant?,f |f(z)|\to1 |z|\to1 f,"The whole question looks like- $f$ is a holomorphic function on the interior of the open unit disc   (say $D$ ) around $0$ and $f(z)\ne0\ \forall z\in D$ . Suppose, $|f(z)|\to1$ as $|z|\to1$ . Is f a constant function? Now, if we remove   the non-vanishing condition then is $f$ constant? The 2nd part is easy if we take $f(z)=z$ , then $|f(z)|\to1$ as $|z|\to1$ but $f(0)=0$ . For the first part, I tried to show $f'(z)=0\ \forall z\in D$ From application of Cauchy intrgral formula, we know that $f'(z)={1\over 2\pi i}\int_{C} \frac{f(\zeta)}{(\zeta-z)^2}d\zeta$ where $z\in D$ and $C$ is a circle around $z$ inside $D$ . So, $|f'(z)|\le\sup\{\frac{f(\zeta)}{(\zeta-z)^2}|\zeta\in C\}\operatorname{Radius}(C)$ Can use these concepts and the condition $|f(z)|\to1$ as $|z|\to1$ to show $f$ is constant? I even don't know the answer, so may be the $f$ is non-constant. But I think it will be constant. Can anybody solve the problem? Thanks for assistance in advance.","The whole question looks like- is a holomorphic function on the interior of the open unit disc   (say ) around and . Suppose, as . Is f a constant function? Now, if we remove   the non-vanishing condition then is constant? The 2nd part is easy if we take , then as but . For the first part, I tried to show From application of Cauchy intrgral formula, we know that where and is a circle around inside . So, Can use these concepts and the condition as to show is constant? I even don't know the answer, so may be the is non-constant. But I think it will be constant. Can anybody solve the problem? Thanks for assistance in advance.",f D 0 f(z)\ne0\ \forall z\in D |f(z)|\to1 |z|\to1 f f(z)=z |f(z)|\to1 |z|\to1 f(0)=0 f'(z)=0\ \forall z\in D f'(z)={1\over 2\pi i}\int_{C} \frac{f(\zeta)}{(\zeta-z)^2}d\zeta z\in D C z D |f'(z)|\le\sup\{\frac{f(\zeta)}{(\zeta-z)^2}|\zeta\in C\}\operatorname{Radius}(C) |f(z)|\to1 |z|\to1 f f,"['complex-analysis', 'cauchy-integral-formula']"
67,Check my proof for equality in general triangle equality,Check my proof for equality in general triangle equality,,"Consider the generalized triangle equality in $\mathbb C$ : $$|z_1+\dots+z_n|\le |z_1|+\dots+|z_n|\tag 1$$ The theorem in question is the following: Equality occurs in (1) if and only if $z_k/z_l\ge 0$ for any integers $k,l$ where $1\le k,l\le n$ for which $z_l\ne 0$ . My proof is as follows: The result is easy to verify for $n=2$ . (This part is solved in the textbook). We proceed by induction and assume the result for $n-1$ . If $z_n=0$ we are done anyway so we suppose $z_n\ne 0$ . Let $z_{i_1},\dots,z_{i_k}$ be all the nonzero complex numbers amongst $z_1,\dots,z_{n-1}$ . There must be at least one such nonzero number for otherwise the proof is trivial. Further let $z^*=z_{i_1}+\dots+z_{i_k}$ . Now suppose equality prevails in (1). Then, $$|z_{i_1}|+\dots+|z_{i_k}|+|z_n|=|z^*+z_n|\le |z^*|+|z_n|$$ following which $|z^*|\ge |z_{i_1}|+\dots+|z_{i_k}|.\tag 2$ Also by the triangle inequality we have $|z^*|\le |z_{i_1}|+\dots+|z_{i_k}|.\tag 3$ From (2),(3) we see that $$|z^*|=|z_{i_1}|+\dots+|z_{i_k}|.$$ This shows that $z_k/z_l\ge 0$ for any integers $k,l$ where $1\le k,l\le n-1$ for which $z_l\ne 0$ . Note that $z^*\ne 0$ for otherwise $z_{i_1}=\dots=z_{i_k}=0$ . Fix any $j$ , $1\le j\le k$ . By the induction hypothesis we now have $c_m=z_{i_m}/z_{i_j}>0$ where $1\le m\le k$ . Since $|z^*+z_n|=|z^*|+|z_n|$ so, by the case $n=2$ of the result we have $z_n=tz^*$ for some $t>0$ . Dividing both sides by $z_{i_j}$ we see that $$z_n/z_{i_j}=t(c_1+\dots+c_{j-1}+1+c_{j+1}+\dots+c_k)>0$$ following which $z_{i_j}/z_n>0$ . This completes one direction of the proof. Now suppose that for any $1\le p,q\le k$ we have $z_{i_p}/z_{i_q},z_{i_p}/z_n>0$ . Then $\frac{z_{i_1}+\dots+z_{i_k}}{z_n}>0$ and so both $z^*/z_n,z+n/z^*>0$ . Again, by the case $n=2$ this implies that $|z_n+z^*|=|z_n|+|z^*|$ . Hence, \begin{align*} |z_1+\dots+z_n|&=|z_{i_1}+\dots+z_{i_k}|+|z_n|\\ &=|z_{i_1}|+\dots+|z_{i_k}|+|z_n|\mbox{ (by the induction hypothesis)}\\ &=|z_1|+\dots+|z_n| \end{align*} which completes the proof. Is this proof correct? Can it be improved?","Consider the generalized triangle equality in : The theorem in question is the following: Equality occurs in (1) if and only if for any integers where for which . My proof is as follows: The result is easy to verify for . (This part is solved in the textbook). We proceed by induction and assume the result for . If we are done anyway so we suppose . Let be all the nonzero complex numbers amongst . There must be at least one such nonzero number for otherwise the proof is trivial. Further let . Now suppose equality prevails in (1). Then, following which Also by the triangle inequality we have From (2),(3) we see that This shows that for any integers where for which . Note that for otherwise . Fix any , . By the induction hypothesis we now have where . Since so, by the case of the result we have for some . Dividing both sides by we see that following which . This completes one direction of the proof. Now suppose that for any we have . Then and so both . Again, by the case this implies that . Hence, which completes the proof. Is this proof correct? Can it be improved?","\mathbb C |z_1+\dots+z_n|\le |z_1|+\dots+|z_n|\tag 1 z_k/z_l\ge 0 k,l 1\le k,l\le n z_l\ne 0 n=2 n-1 z_n=0 z_n\ne 0 z_{i_1},\dots,z_{i_k} z_1,\dots,z_{n-1} z^*=z_{i_1}+\dots+z_{i_k} |z_{i_1}|+\dots+|z_{i_k}|+|z_n|=|z^*+z_n|\le |z^*|+|z_n| |z^*|\ge |z_{i_1}|+\dots+|z_{i_k}|.\tag 2 |z^*|\le |z_{i_1}|+\dots+|z_{i_k}|.\tag 3 |z^*|=|z_{i_1}|+\dots+|z_{i_k}|. z_k/z_l\ge 0 k,l 1\le k,l\le n-1 z_l\ne 0 z^*\ne 0 z_{i_1}=\dots=z_{i_k}=0 j 1\le j\le k c_m=z_{i_m}/z_{i_j}>0 1\le m\le k |z^*+z_n|=|z^*|+|z_n| n=2 z_n=tz^* t>0 z_{i_j} z_n/z_{i_j}=t(c_1+\dots+c_{j-1}+1+c_{j+1}+\dots+c_k)>0 z_{i_j}/z_n>0 1\le p,q\le k z_{i_p}/z_{i_q},z_{i_p}/z_n>0 \frac{z_{i_1}+\dots+z_{i_k}}{z_n}>0 z^*/z_n,z+n/z^*>0 n=2 |z_n+z^*|=|z_n|+|z^*| \begin{align*}
|z_1+\dots+z_n|&=|z_{i_1}+\dots+z_{i_k}|+|z_n|\\
&=|z_{i_1}|+\dots+|z_{i_k}|+|z_n|\mbox{ (by the induction hypothesis)}\\
&=|z_1|+\dots+|z_n|
\end{align*}","['complex-analysis', 'proof-verification']"
68,Almost complex structure question,Almost complex structure question,,"I know that if $M$ admits an almost complex structure $J$ , then $\text{dim}_{\mathbb{R}}(M)=2k$ , thus every odd-dimensional manifold doesn't admit an almost complex structure. My question is, are there even-dimensional, orientable manifolds that don't admit an almost complex structure?","I know that if admits an almost complex structure , then , thus every odd-dimensional manifold doesn't admit an almost complex structure. My question is, are there even-dimensional, orientable manifolds that don't admit an almost complex structure?",M J \text{dim}_{\mathbb{R}}(M)=2k,"['complex-analysis', 'differential-geometry', 'complex-geometry', 'several-complex-variables']"
69,$f$ is $\mathbb{R}$ - differentiable iff $Re(f)$ and $Im(f)$ are $\mathbb{R}$ - differentiable,is  - differentiable iff  and  are  - differentiable,f \mathbb{R} Re(f) Im(f) \mathbb{R},"I just read that a sufficient condition for a function $f:A \rightarrow \mathbb{C},f(z) = u(z)+ i v(z)$ to be holomorphic is: $A$ open. f is $\mathbb{R}$ - differentiable in $A$ . The Cauchy Riemann equations hold in $A$ . In the book i' m reading $\mathbb{R}$ - differentiability is defined as: $f: D \rightarrow \mathbb{C}$ is $\mathbb{R}$ - differentiable in $z_0$ if there exists an $\mathbb{R}$ - linear map $T$ such that $$\lim_{z \rightarrow z_0}\frac{f(z)-f(z_0)-T(z-z_0)}{| z-z_0 |}=0$$ Is this equivalent to saying that $Re(z)$ and $Im(z)$ (which are real valued) are differentiable in $A$ ?",I just read that a sufficient condition for a function to be holomorphic is: open. f is - differentiable in . The Cauchy Riemann equations hold in . In the book i' m reading - differentiability is defined as: is - differentiable in if there exists an - linear map such that Is this equivalent to saying that and (which are real valued) are differentiable in ?,"f:A \rightarrow \mathbb{C},f(z) = u(z)+ i v(z) A \mathbb{R} A A \mathbb{R} f: D \rightarrow \mathbb{C} \mathbb{R} z_0 \mathbb{R} T \lim_{z \rightarrow z_0}\frac{f(z)-f(z_0)-T(z-z_0)}{| z-z_0 |}=0 Re(z) Im(z) A","['complex-analysis', 'cauchy-riemann-equations']"
70,"$f$ is analytic on $D$ except an essential singularity $z_0$. Can one deduce that
$\int\int_D|f(z)|^p d x d y=\infty$
For all $p>0$?","is analytic on  except an essential singularity . Can one deduce that

For all ?",f D z_0 \int\int_D|f(z)|^p d x d y=\infty p>0,"$z_0$ is an essential singularity of $f$ , $D$ is a disc centered at the origion and contains $z_0$ . $f$ is analytic on $D$ except $z_0$ . Can one deduce that $$\int\int_D|f(z)|^p d x d y=\infty$$ For all $p>0$ ?","is an essential singularity of , is a disc centered at the origion and contains . is analytic on except . Can one deduce that For all ?",z_0 f D z_0 f D z_0 \int\int_D|f(z)|^p d x d y=\infty p>0,['complex-analysis']
71,"Complex: If $|f|<\varepsilon$, then $\frac{1}{\pi}\int_E \frac{|f|}{|z-w|}<\varepsilon$?","Complex: If , then ?",|f|<\varepsilon \frac{1}{\pi}\int_E \frac{|f|}{|z-w|}<\varepsilon,"Is this true? Let $f:E\xrightarrow{}\mathbb{C}$ be holomorphic on the interior of a compact set $E$ , and let $\varepsilon>0.$ If $|f|<\varepsilon$ on $E$ , then $$\frac{1}{\pi}\int_E \frac{|f(w)|}{|z-w|} dm(w)<\varepsilon$$ for $z\in E$ , where $m$ is the two-dimensional Lebesgue measure. Important edit: $E$ is COMPACT.","Is this true? Let be holomorphic on the interior of a compact set , and let If on , then for , where is the two-dimensional Lebesgue measure. Important edit: is COMPACT.",f:E\xrightarrow{}\mathbb{C} E \varepsilon>0. |f|<\varepsilon E \frac{1}{\pi}\int_E \frac{|f(w)|}{|z-w|} dm(w)<\varepsilon z\in E m E,"['complex-analysis', 'complex-integration']"
72,Bound on gradient of Harmonic functions,Bound on gradient of Harmonic functions,,"Let $G\subseteq\mathbb{C}$ be a domain and assume $u:G\to\mathbb{R}$ is a harmonic function such that $|u(z)|\leq M$ for all $z\in G$ . Show that $|\nabla u(z)|\leq\frac{2M}{r}$ for $0<r<dist(z,\partial G$ ) and for all $z\in G$ . ( $\nabla u$ is the gradient of $u$ ). Attempt: As we know, there is some harmonic function $v:G\to\mathbb{R}$ such that $f=u+iv$ is holomorphic. I thought it might help to use Cauchy integral formula. For a given $z_0\in G$ and $0<r<dist(z_0,\partial G$ ) we have: $f'(z_0)=\frac{1}{2\pi i}\int_{B_r(z_0)}\frac{f(\xi)}{(\xi-z_0)^2} d\xi=\frac{1}{2\pi}\int_0^{2\pi}\frac{f(z_0+re^{it})}{re^{it}}dt=\frac{1}{2\pi r}\int_0^{2\pi}f(z_0+re^{it})(cost-isint)dt$ Alright, now using the fact that $f'(z_0)=u_x(z_0)+iv_x(z_0)$ I tried to compare real parts. What I got is the following: $u_x(z_0)=\frac{1}{2\pi r}\int_ 0^{2\pi} u(z_0+re^{it})cost+v(z_0+re^{it})sint dt$ I hoped I can get a bound on both $u_x$ and $u_y$ and from there get the required bound on the gradient. However as you can see I got that $u_x$ is dependent on the values of $v$ and this is a function I cannot bound since I don't know anything about it. So I'm stuck. Any ideas?","Let be a domain and assume is a harmonic function such that for all . Show that for ) and for all . ( is the gradient of ). Attempt: As we know, there is some harmonic function such that is holomorphic. I thought it might help to use Cauchy integral formula. For a given and ) we have: Alright, now using the fact that I tried to compare real parts. What I got is the following: I hoped I can get a bound on both and and from there get the required bound on the gradient. However as you can see I got that is dependent on the values of and this is a function I cannot bound since I don't know anything about it. So I'm stuck. Any ideas?","G\subseteq\mathbb{C} u:G\to\mathbb{R} |u(z)|\leq M z\in G |\nabla u(z)|\leq\frac{2M}{r} 0<r<dist(z,\partial G z\in G \nabla u u v:G\to\mathbb{R} f=u+iv z_0\in G 0<r<dist(z_0,\partial G f'(z_0)=\frac{1}{2\pi i}\int_{B_r(z_0)}\frac{f(\xi)}{(\xi-z_0)^2} d\xi=\frac{1}{2\pi}\int_0^{2\pi}\frac{f(z_0+re^{it})}{re^{it}}dt=\frac{1}{2\pi r}\int_0^{2\pi}f(z_0+re^{it})(cost-isint)dt f'(z_0)=u_x(z_0)+iv_x(z_0) u_x(z_0)=\frac{1}{2\pi r}\int_ 0^{2\pi} u(z_0+re^{it})cost+v(z_0+re^{it})sint dt u_x u_y u_x v","['complex-analysis', 'harmonic-functions']"
73,Mapping of Complex function,Mapping of Complex function,,"Let $w = f(w)=(3+4i)z- 2 +i$ Find the images of the disk $|z-1|<1$ and the half-plane $Im(z)>1$ For the first mapping of the disk I attempted the following : $$z = \frac{w+2-i}{3+4i}$$ which then gives us $$|\frac{w+2-i}{3+4i} - 1| < 1$$ $$|w-(1+5i)| < |3+4i|$$ $$|w-(1+5i)| < 5$$ And this is just a circle with origin (1,5) with a radius of 5 For the second image I did the following : Let $z=x+iy$ thus $$w =(3+4i)(x+iy)-2+i=(3x-4y-2)+i(3y+4x+1)$$ Then $y=1$ gives $u=3x-2$ and $v=4+4x$ which leads to the line $u=\frac{3}{4}v-5$ Are these mappings correct ?","Let Find the images of the disk and the half-plane For the first mapping of the disk I attempted the following : which then gives us And this is just a circle with origin (1,5) with a radius of 5 For the second image I did the following : Let thus Then gives and which leads to the line Are these mappings correct ?",w = f(w)=(3+4i)z- 2 +i |z-1|<1 Im(z)>1 z = \frac{w+2-i}{3+4i} |\frac{w+2-i}{3+4i} - 1| < 1 |w-(1+5i)| < |3+4i| |w-(1+5i)| < 5 z=x+iy w =(3+4i)(x+iy)-2+i=(3x-4y-2)+i(3y+4x+1) y=1 u=3x-2 v=4+4x u=\frac{3}{4}v-5,['complex-analysis']
74,finite number of zeros of a complex function,finite number of zeros of a complex function,,"Suppose that $f$ is analytic on a region $D = \{|z|>R\}$ , and the limit of $\vert f \vert$ at infinity exists. Show that $f$ is either the constant function $0$ , or has only finitely many zeros. I thought since the limit at infinity exists then Laurent seires of $f$ only contains the principal part plus a constant, but how do I proceed to show that this will only have finite zeros ?","Suppose that is analytic on a region , and the limit of at infinity exists. Show that is either the constant function , or has only finitely many zeros. I thought since the limit at infinity exists then Laurent seires of only contains the principal part plus a constant, but how do I proceed to show that this will only have finite zeros ?",f D = \{|z|>R\} \vert f \vert f 0 f,['complex-analysis']
75,Understanding better the topology of the circle and the representation of periodic function using function defined on the circle.,Understanding better the topology of the circle and the representation of periodic function using function defined on the circle.,,"I'm a bit in truble with the circle. Question 1 I want to use $\mathcal C=\{e^{it}\mid t\in [0,2\pi]\}$ . Since it's the image of $[0,2\pi]$ under the coninuous function $t\mapsto e^{it}$ , the set $\mathcal C$ is compact. But is it a metric space ? I know that I can put the euclienne metric, but I would like to use the metric $$d(e^{it},e^{is})=|t-s|.$$ I proved it was a metric but $t,s\in [0,2\pi)$ only because otherwise, we have $d(e^0,e^{2i\pi})=|2\pi|>0$ . So, to use this metric, I have to consider $\mathcal C=\{e^{it}\mid t\in[0,2\pi)\}$ , no ? And with this definition, it's not compact anymore, right ? Question 2 Now if I want to stud periodic function, I know that any $2\pi-$ periodic function can be seen as a function on the unit circle, i.e. $f:\mathbb R\to \mathbb R$ is a $2\pi-$ periodic function $\iff$ there is a function $F:\mathcal C\to \mathbb R$ s.t. $f(\theta )=F(e^{i\theta })$ . So, for example, $f$ is continuous $\iff$ $F$ is continuous or $f$ is derivable $\iff$ $F$ is derivable. But which topology I have to use on $\mathcal C$ to talk about continuity ? And for the derivability, I don't really understand how can such a function $F$ be derivable on the Circle... What would be the sense of $F'$ ?","I'm a bit in truble with the circle. Question 1 I want to use . Since it's the image of under the coninuous function , the set is compact. But is it a metric space ? I know that I can put the euclienne metric, but I would like to use the metric I proved it was a metric but only because otherwise, we have . So, to use this metric, I have to consider , no ? And with this definition, it's not compact anymore, right ? Question 2 Now if I want to stud periodic function, I know that any periodic function can be seen as a function on the unit circle, i.e. is a periodic function there is a function s.t. . So, for example, is continuous is continuous or is derivable is derivable. But which topology I have to use on to talk about continuity ? And for the derivability, I don't really understand how can such a function be derivable on the Circle... What would be the sense of ?","\mathcal C=\{e^{it}\mid t\in [0,2\pi]\} [0,2\pi] t\mapsto e^{it} \mathcal C d(e^{it},e^{is})=|t-s|. t,s\in [0,2\pi) d(e^0,e^{2i\pi})=|2\pi|>0 \mathcal C=\{e^{it}\mid t\in[0,2\pi)\} 2\pi- f:\mathbb R\to \mathbb R 2\pi- \iff F:\mathcal C\to \mathbb R f(\theta )=F(e^{i\theta }) f \iff F f \iff F \mathcal C F F'","['real-analysis', 'general-topology', 'complex-analysis']"
76,Recursive formula for Bernoulli numbers from power series,Recursive formula for Bernoulli numbers from power series,,"This is Ch 7, Exercise 62 in Palka's Complex Function Theory . Define $$ f:B(0,2 \pi) \to \mathbb{C},z \mapsto \frac{z}{e^z-1}\text{ if }z \neq 0, \; f(0):=1$$ Let $f$ have Taylor series $$f(z)= \sum_{n=0}^\infty \frac{B_n}{n!}z^n$$ where the $B_n$ are Bernoulli numbers (Here I use Wikipedia's notation, not Palka's). The question is to show $$\sum_{k=1}^{n}\binom{2n+1}{2k}B_{2k}= \frac{2n-1}{2}\tag{1}$$ I am stuck on showing this, but have some initial leads (from earlier in the problem). We have $B_0=f(0)=1$ , and from Palka's hint, $z \mapsto z/2+f(z)$ is even: $$\begin{split} \frac{z}{2}+f(z)=& \frac{z(e^z-1)+2z}{2(e^z-1)}= \frac{ze^z+z}{2(e^z-1)}\\ \frac{-z}{2}+f(-z)=& \frac{-z}{2}- \frac{ze^z}{1-e^z}= \frac{-z(e^z-1)+2ze^z}{2(e^z-1)}= \frac{ze^z+z}{2(e^z-1)} \end{split}$$ which reveals $B_1=-1/2$ and $B_n=0$ for $n>2$ odd. I have also tried manipulating $(1)$ : since $B_1$ is the only nonzero odd Bernoulli number: $$\sum_{k=1}^{2n}\binom{2n+1}{k}B_k= \frac{2n-1}{2}+ \binom{2n+1}{1}B_1=-1$$ or starting the sum at $0$ : $$\sum_{k=0}^{2n}\binom{2n+1}{k}B_k=-1+ \binom{2n+1}{0}B_0=0$$ but I didn't get any additional insight on how to show $(1)$ . Any help is greatly appreciated.","This is Ch 7, Exercise 62 in Palka's Complex Function Theory . Define Let have Taylor series where the are Bernoulli numbers (Here I use Wikipedia's notation, not Palka's). The question is to show I am stuck on showing this, but have some initial leads (from earlier in the problem). We have , and from Palka's hint, is even: which reveals and for odd. I have also tried manipulating : since is the only nonzero odd Bernoulli number: or starting the sum at : but I didn't get any additional insight on how to show . Any help is greatly appreciated."," f:B(0,2 \pi) \to \mathbb{C},z \mapsto \frac{z}{e^z-1}\text{ if }z \neq 0, \; f(0):=1 f f(z)= \sum_{n=0}^\infty \frac{B_n}{n!}z^n B_n \sum_{k=1}^{n}\binom{2n+1}{2k}B_{2k}= \frac{2n-1}{2}\tag{1} B_0=f(0)=1 z \mapsto z/2+f(z) \begin{split}
\frac{z}{2}+f(z)=& \frac{z(e^z-1)+2z}{2(e^z-1)}= \frac{ze^z+z}{2(e^z-1)}\\
\frac{-z}{2}+f(-z)=& \frac{-z}{2}- \frac{ze^z}{1-e^z}= \frac{-z(e^z-1)+2ze^z}{2(e^z-1)}= \frac{ze^z+z}{2(e^z-1)}
\end{split} B_1=-1/2 B_n=0 n>2 (1) B_1 \sum_{k=1}^{2n}\binom{2n+1}{k}B_k= \frac{2n-1}{2}+ \binom{2n+1}{1}B_1=-1 0 \sum_{k=0}^{2n}\binom{2n+1}{k}B_k=-1+ \binom{2n+1}{0}B_0=0 (1)","['sequences-and-series', 'complex-analysis', 'power-series', 'bernoulli-numbers']"
77,How many roots does an exponential polynomial have?,How many roots does an exponential polynomial have?,,"Let $s$ be a complex variable and consider two polynomials with real coefficients: $$A(s) = s^n + a_{n-1}s^{n-1}+\ldots+a_1s+a_0,$$ $$B(s) = s^m + b_{m-1}s^{m-1}+\ldots+b_1s+b_0,$$ where $n \ge m$ . Let $k$ be a real constant. I am looking for roots of the function $$A(s)+e^{sk}B(s)=0.$$ Obviously, when $k=0$ I have just a polynomial of degree $n$ and I have $n$ roots. Then I have two questions: Is it true that this function always has $n$ roots for any fixed $k$ ? (Negative, see UPD2). Do these roots depend continuously on $k$ ? UPD: We also assume that $n\ge 1$ . UPD2: Let us take $A(s)=s$ and $B(s)=1$ . Then we have $$s+e^{ks} = 0.$$ For $k=0$ the only roots is $s_1=-1$ . However, for $k=-1$ we have $$se^{s}=-1$$ and we have multiple solutions. So the answer to the first question is negative. However, I do not know if the roots are continuous with respect to $k$ .","Let be a complex variable and consider two polynomials with real coefficients: where . Let be a real constant. I am looking for roots of the function Obviously, when I have just a polynomial of degree and I have roots. Then I have two questions: Is it true that this function always has roots for any fixed ? (Negative, see UPD2). Do these roots depend continuously on ? UPD: We also assume that . UPD2: Let us take and . Then we have For the only roots is . However, for we have and we have multiple solutions. So the answer to the first question is negative. However, I do not know if the roots are continuous with respect to .","s A(s) = s^n + a_{n-1}s^{n-1}+\ldots+a_1s+a_0, B(s) = s^m + b_{m-1}s^{m-1}+\ldots+b_1s+b_0, n \ge m k A(s)+e^{sk}B(s)=0. k=0 n n n k k n\ge 1 A(s)=s B(s)=1 s+e^{ks} = 0. k=0 s_1=-1 k=-1 se^{s}=-1 k","['complex-analysis', 'polynomials', 'exponential-function', 'roots']"
78,The inverse of a Dirichlet product is the Dirichlet product of the inverses of each function,The inverse of a Dirichlet product is the Dirichlet product of the inverses of each function,,"Let $f,g$ be arithmetic functions. According to Wikipedia , $(f*g)^{-1} = f^{-1} * g^{-1}$ if $f(1) \neq 0$ and $g(1) \neq 0$ . However, it is not clear to me why this is true, and the statement does not provide a reference text for a proof. Would anyone be able to provide a link to one and/or prove it?","Let be arithmetic functions. According to Wikipedia , if and . However, it is not clear to me why this is true, and the statement does not provide a reference text for a proof. Would anyone be able to provide a link to one and/or prove it?","f,g (f*g)^{-1} = f^{-1} * g^{-1} f(1) \neq 0 g(1) \neq 0","['complex-analysis', 'number-theory', 'analytic-number-theory']"
79,Area of Mandelbrot set: Uniform convergence in Laurent series method,Area of Mandelbrot set: Uniform convergence in Laurent series method,,"I am reading Ewing and Schober's paper on analytically computing the area of the Mandelbrot set and I hope, in a shred of such, that someone might have an idea why swapping an integral and sum is justified. The paper can be foud on https://link.springer.com/article/10.1007%2FBF01385497 , p.69. A diffeomorphism $$\phi(z)=\sum_{m=-1}^{\infty} b_mz^{-m}$$ maps the exterior of the unit disk to the exterior of the Mandelbrot set.  The image $\phi(C_r)$ of a circle of radius $r>1$ forms a region $M( R)$ and we wish to find the area of $M(1)$ . Using Green's Theorem, they give the following expression for the area $$ -\frac12 \int \sum_{n,m\geq -1} m\overline{b_n}b_m(1/r)^{n+m}e^{(m-n)i\theta} d\theta. $$ I am trying to understand: Why does the sum $$\sum_{n,m\geq -1} m\overline{b_n}b_m(1/r)^{n+m}e^{(m-n)i\theta}$$ converges uniformly so that swapping the integral and the sum is justified? I tried to bound it by a geometric series but the trouble is that the coefficients are not constant and also $r>1$ . The first coeffients are $b_0=-1/2,b_2=-1/4,b_3=15/128,b4=0,b_5=-47/1024$ but computing these coefficients seems to be a delicate matter. Does the sum converge because these coefficients converge very quickly to zero?","I am reading Ewing and Schober's paper on analytically computing the area of the Mandelbrot set and I hope, in a shred of such, that someone might have an idea why swapping an integral and sum is justified. The paper can be foud on https://link.springer.com/article/10.1007%2FBF01385497 , p.69. A diffeomorphism maps the exterior of the unit disk to the exterior of the Mandelbrot set.  The image of a circle of radius forms a region and we wish to find the area of . Using Green's Theorem, they give the following expression for the area I am trying to understand: Why does the sum converges uniformly so that swapping the integral and the sum is justified? I tried to bound it by a geometric series but the trouble is that the coefficients are not constant and also . The first coeffients are but computing these coefficients seems to be a delicate matter. Does the sum converge because these coefficients converge very quickly to zero?","\phi(z)=\sum_{m=-1}^{\infty} b_mz^{-m} \phi(C_r) r>1 M( R) M(1)  -\frac12 \int \sum_{n,m\geq -1} m\overline{b_n}b_m(1/r)^{n+m}e^{(m-n)i\theta} d\theta.  \sum_{n,m\geq -1} m\overline{b_n}b_m(1/r)^{n+m}e^{(m-n)i\theta} r>1 b_0=-1/2,b_2=-1/4,b_3=15/128,b4=0,b_5=-47/1024","['complex-analysis', 'complex-dynamics']"
80,Nested sequence of compact subsets covering an open set in $\mathbb{C}$,Nested sequence of compact subsets covering an open set in,\mathbb{C},"Let $U$ be an open set in $\mathbb{C}$ . I would like to prove the following result: There exists a sequence of compact sets $\{K_n\}$ with the following properties: Each $K_n$ is a subset of $U$ . $K_n \subset \mathrm{int}(K_{n+1}) \ \forall n$ , where $\mathrm{int}()$ denotes interior. $\bigcup_{n} K_n = U$ . each bounded component of the complement of $K_n$ meets the complement of $U$ (This result is used without proof in Theorem 1.4.3 of ""Several Complex Variables with Connections to Algebraic Geometry and Lie Groups"" by Joseph L. Taylor.) Construction of  a sequence with the first 3 properties has already been answered here . How do I ensure that the fourth property is also satisfied?","Let be an open set in . I would like to prove the following result: There exists a sequence of compact sets with the following properties: Each is a subset of . , where denotes interior. . each bounded component of the complement of meets the complement of (This result is used without proof in Theorem 1.4.3 of ""Several Complex Variables with Connections to Algebraic Geometry and Lie Groups"" by Joseph L. Taylor.) Construction of  a sequence with the first 3 properties has already been answered here . How do I ensure that the fourth property is also satisfied?",U \mathbb{C} \{K_n\} K_n U K_n \subset \mathrm{int}(K_{n+1}) \ \forall n \mathrm{int}() \bigcup_{n} K_n = U K_n U,"['general-topology', 'complex-analysis', 'metric-spaces', 'compactness']"
81,Proving the injectivity of an entire function,Proving the injectivity of an entire function,,"This is an exercise from a book I was reading: Suppose that an entire function $f:\mathbb{C} \to \mathbb {C}$ satisfies $$f(z)\in \mathbb{R} \iff z\in \mathbb{R} .$$ Prove that $f'$ does not vanish on $\mathbb{R}$ . The author gave a hint; he told us to use the following theorem: Theorem: Suppose that a function $f$ is holomorphic in an open set $U$ , that $z_0$ is a point of $U$ , and that $f$ takes the value $w_0$ with multiplicity $m$ at $z_0$ . Then there exist $s>0$ and a domain $D$ that is contained in $U$ with the properties that $D$ is contained in a closed disk centered at $z_0$ that is contained in $U$ , $f(D)=\Delta(w_0,s),$ $f(z)\neq w_0,\ f'(z)\neq 0$ for all $z\in D-\{z_0\}$ , for each $w$ in $\Delta ^{\ast}(w_0,s)$ , there are exactly $m$ points in $D$ that are mapped to $w$ by $f$ . (Here the symbol $\Delta(w_0,s)$ denotes the open disk of radius $s$ centered at $w_0$ , and $\Delta^{\ast}(w_0,s)=\Delta(w_0,s)-\{w_0\}$ .   ) $\blacksquare$ Here's what I have tried. My attempt: Following the author's direction, I try to use the apply   the following theorem to prove the problem by contradiction. Suppose that $f'(z_0)=0$ for some $z_0$ in $\mathbb{R}$ . Choose $D$ and $s$ as in the above theorem. Fix a point $w_1$ in $\Delta(w_0,s)\cap \mathbb{R}$ . According to the theorem, there are at   least $2$ points in $D$ that are mapped to $w_1$ by $f$ . Now since $f$ is real on $\mathbb{R}$ , so is $f'$ . By choice of $D$ , $f'(z)\neq 0$ for $z\in D^{\ast}:=D-\{z_0\}$ . So $f'$ is either   always positive or always negative on the set $A:=\{x\in\mathbb{R}\cap > D|\ x< z_0\}$ . The same thing can be said about $f'$ on the set $B:=\{x\in\mathbb{R}\cap D|\ x> z_0\}$ . If $f'$ happened to be   positive on both of these sets, then $f$ would be strictly increasing   on $A\cup \{z_0\}\cup B$ , contrary to the result in the previous   paragraph and our hypothesis that $f(z)$ is real iff $z$ is real.   Hence $f'>0$ on $A$ and $f'<0$ on $B$ , or $f'<0$ on $A$ and $f'>0$ on $B$ . I feel like I am going in the wrong direction. But I cannot find any other direction. Can anyone help me? Thanks in advance!","This is an exercise from a book I was reading: Suppose that an entire function satisfies Prove that does not vanish on . The author gave a hint; he told us to use the following theorem: Theorem: Suppose that a function is holomorphic in an open set , that is a point of , and that takes the value with multiplicity at . Then there exist and a domain that is contained in with the properties that is contained in a closed disk centered at that is contained in , for all , for each in , there are exactly points in that are mapped to by . (Here the symbol denotes the open disk of radius centered at , and .   ) Here's what I have tried. My attempt: Following the author's direction, I try to use the apply   the following theorem to prove the problem by contradiction. Suppose that for some in . Choose and as in the above theorem. Fix a point in . According to the theorem, there are at   least points in that are mapped to by . Now since is real on , so is . By choice of , for . So is either   always positive or always negative on the set . The same thing can be said about on the set . If happened to be   positive on both of these sets, then would be strictly increasing   on , contrary to the result in the previous   paragraph and our hypothesis that is real iff is real.   Hence on and on , or on and on . I feel like I am going in the wrong direction. But I cannot find any other direction. Can anyone help me? Thanks in advance!","f:\mathbb{C} \to \mathbb {C} f(z)\in \mathbb{R} \iff z\in \mathbb{R} . f' \mathbb{R} f U z_0 U f w_0 m z_0 s>0 D U D z_0 U f(D)=\Delta(w_0,s), f(z)\neq w_0,\ f'(z)\neq 0 z\in D-\{z_0\} w \Delta ^{\ast}(w_0,s) m D w f \Delta(w_0,s) s w_0 \Delta^{\ast}(w_0,s)=\Delta(w_0,s)-\{w_0\} \blacksquare f'(z_0)=0 z_0 \mathbb{R} D s w_1 \Delta(w_0,s)\cap \mathbb{R} 2 D w_1 f f \mathbb{R} f' D f'(z)\neq 0 z\in D^{\ast}:=D-\{z_0\} f' A:=\{x\in\mathbb{R}\cap
> D|\ x< z_0\} f' B:=\{x\in\mathbb{R}\cap D|\ x> z_0\} f' f A\cup \{z_0\}\cup B f(z) z f'>0 A f'<0 B f'<0 A f'>0 B","['complex-analysis', 'entire-functions']"
82,Finding the argument of a complex function,Finding the argument of a complex function,,"I've the following transfer function: $$H(s)=\frac{1}{as^3+bs^2+cs+1}$$ Where $a,b,c$ are all real and positive. How can I find $\arg(H(i\omega))$ ? And I know that $\omega\ge0$ What I did: $$H(i\omega)=\frac{1}{a(i\omega)^3+b(i\omega)^2+c(i\omega)+1}=\frac{1}{-a\omega^3i-b\omega^2+c\omega i+1}=$$ $$\frac{1}{1-b\omega^2+(c\omega-a\omega^3)i}$$ Now finding the argument I can write: $$\arg(H(i\omega))=\arg(1)-\arg(1-b\omega^2+(c\omega-a\omega^3)i)=$$ $$0-\arg(1-b\omega^2+(c\omega-a\omega^3)i)=-\arg(1-b\omega^2+(c\omega-a\omega^3)i)$$ Now, how can I setup a function that depends on the value of $a,b,c,\omega$ ?","I've the following transfer function: Where are all real and positive. How can I find ? And I know that What I did: Now finding the argument I can write: Now, how can I setup a function that depends on the value of ?","H(s)=\frac{1}{as^3+bs^2+cs+1} a,b,c \arg(H(i\omega)) \omega\ge0 H(i\omega)=\frac{1}{a(i\omega)^3+b(i\omega)^2+c(i\omega)+1}=\frac{1}{-a\omega^3i-b\omega^2+c\omega i+1}= \frac{1}{1-b\omega^2+(c\omega-a\omega^3)i} \arg(H(i\omega))=\arg(1)-\arg(1-b\omega^2+(c\omega-a\omega^3)i)= 0-\arg(1-b\omega^2+(c\omega-a\omega^3)i)=-\arg(1-b\omega^2+(c\omega-a\omega^3)i) a,b,c,\omega","['complex-analysis', 'complex-numbers', 'triangles', 'laplace-transform', 'transfer-theory']"
83,"What's going on when we compute $d(\gamma(z)) = \frac{1}{|cz+d|^2}dz$, where $\gamma \in \operatorname{SL}_2(\mathbb Z)$","What's going on when we compute , where",d(\gamma(z)) = \frac{1}{|cz+d|^2}dz \gamma \in \operatorname{SL}_2(\mathbb Z),"Let $\gamma = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \operatorname{SL}_2(\mathbb Z)$ .  Consider the space $\Omega^1(\mathbb H)$ of smooth complex $1$ -forms on $\mathbb H$ .  These consist of all smooth sections of $\mathbb H$ into the complexified tangent bundle of $\mathbb H$ , written formally as $$\omega = f(x,y)dx + g(x,y)dy$$ for $f, g$ smooth complex valued functions on $\mathbb H$ .  In particular, we have the holomorphic differential forms, given by $h(x,y)dz$ , where $dz = dx + i dy$ , and $h$ holomorphic on $\mathbb H$ . Since $\gamma$ induces a diffeomorphism of $\mathbb H$ to itself, it induces a diffeomorphism on the tangent bundle of $\mathbb H$ to itself, and therefore an automorphism of $\Omega^1(\mathbb H)$ . We can compute the effect of $\gamma$ on the form $dz$ .  I have seen the following done: $$\gamma.(dz) = d(\gamma(z)) = d( \frac{az+b}{cz+d}) = (\frac{az+b}{cz+d})'  = \frac{1}{(cz+d)^2}dz \tag{1}$$ I don't really understand what is going on here formally with differential forms.  How do we formally justify what is happening in (1)?  I did compute the action of $\gamma$ on $dz$ and got the same answer in another way: Another way : Let's consider the map $d \gamma$ on the tangent bundle.  With our chart, we can do this by computing the Jacobian of $\gamma$ .  Writing $\gamma(x,y) = u + iv$ , and using the fact that $\gamma$ is holomorphic and $v(z) = v(x+iy) = \frac{y}{|cz+d|^2}$ , we have by the Cauchy-Riemann equations that $$d \gamma = \begin{pmatrix} \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix} = \begin{pmatrix} \frac{\partial v}{\partial y} & -\frac{\partial v}{\partial x} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix}  $$ The dual map on the contangent bundle is then given by the tranpose: $$\begin{pmatrix} \frac{\partial v}{\partial y} & \frac{\partial v}{\partial x} \\ -\frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix}   \tag{2} $$ with $$\frac{\partial v}{\partial x} = |cz+d|^{-3}(-4c^2x-4ycd)$$ $$\frac{\partial v}{\partial y} = \frac{|cz+d|^2-2y^2c^2}{|cz+d|^4} $$ Now by (2), $d \gamma$ sends $dx$ to $\frac{\partial v}{\partial y} dx - \frac{\partial v}{\partial x}dy$ , and it sends $dy$ to $\frac{\partial v}{\partial x}dx + \frac{\partial v}{\partial y} dy$ .  Therefore, $d \gamma$ sends $dz = dx + i dy$ to $$(\frac{\partial v}{\partial y} dx - \frac{\partial v}{\partial x}dy) + i(-\frac{\partial v}{\partial x}dx + \frac{\partial v}{\partial y} dy) = (\frac{\partial v}{\partial y} + i \frac{\partial v}{\partial x})dz $$ This last expression, $\frac{\partial v}{\partial y} + i \frac{\partial v}{\partial x}$ , is equal to $\frac{\partial v}{\partial x} + i \frac{\partial v}{\partial x} = \frac{\partial}{\partial x}(u+iv) = \frac{\partial}{\partial x}(\gamma(z)) = \gamma'(z)$ . This shows that $\gamma$ induces an automorphism on holomorphic $1$ -forms which sends $dz$ to $$dz \mapsto \gamma'(z)dz = \frac{1}{(cz+d)^2}dz$$ exactly as in (1).  But how can we justify this without going into the Cauchy-Riemann equations and Jacobian calculation?","Let .  Consider the space of smooth complex -forms on .  These consist of all smooth sections of into the complexified tangent bundle of , written formally as for smooth complex valued functions on .  In particular, we have the holomorphic differential forms, given by , where , and holomorphic on . Since induces a diffeomorphism of to itself, it induces a diffeomorphism on the tangent bundle of to itself, and therefore an automorphism of . We can compute the effect of on the form .  I have seen the following done: I don't really understand what is going on here formally with differential forms.  How do we formally justify what is happening in (1)?  I did compute the action of on and got the same answer in another way: Another way : Let's consider the map on the tangent bundle.  With our chart, we can do this by computing the Jacobian of .  Writing , and using the fact that is holomorphic and , we have by the Cauchy-Riemann equations that The dual map on the contangent bundle is then given by the tranpose: with Now by (2), sends to , and it sends to .  Therefore, sends to This last expression, , is equal to . This shows that induces an automorphism on holomorphic -forms which sends to exactly as in (1).  But how can we justify this without going into the Cauchy-Riemann equations and Jacobian calculation?","\gamma = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \operatorname{SL}_2(\mathbb Z) \Omega^1(\mathbb H) 1 \mathbb H \mathbb H \mathbb H \omega = f(x,y)dx + g(x,y)dy f, g \mathbb H h(x,y)dz dz = dx + i dy h \mathbb H \gamma \mathbb H \mathbb H \Omega^1(\mathbb H) \gamma dz \gamma.(dz) = d(\gamma(z)) = d( \frac{az+b}{cz+d}) = (\frac{az+b}{cz+d})'  = \frac{1}{(cz+d)^2}dz \tag{1} \gamma dz d \gamma \gamma \gamma(x,y) = u + iv \gamma v(z) = v(x+iy) = \frac{y}{|cz+d|^2} d \gamma = \begin{pmatrix} \frac{\partial u}{\partial x} & \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix} = \begin{pmatrix} \frac{\partial v}{\partial y} & -\frac{\partial v}{\partial x} \\ \frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix}   \begin{pmatrix} \frac{\partial v}{\partial y} & \frac{\partial v}{\partial x} \\ -\frac{\partial v}{\partial x} & \frac{\partial v}{\partial y} \end{pmatrix} 
 \tag{2}  \frac{\partial v}{\partial x} = |cz+d|^{-3}(-4c^2x-4ycd) \frac{\partial v}{\partial y} = \frac{|cz+d|^2-2y^2c^2}{|cz+d|^4}  d \gamma dx \frac{\partial v}{\partial y} dx - \frac{\partial v}{\partial x}dy dy \frac{\partial v}{\partial x}dx + \frac{\partial v}{\partial y} dy d \gamma dz = dx + i dy (\frac{\partial v}{\partial y} dx - \frac{\partial v}{\partial x}dy) + i(-\frac{\partial v}{\partial x}dx + \frac{\partial v}{\partial y} dy) = (\frac{\partial v}{\partial y} + i \frac{\partial v}{\partial x})dz  \frac{\partial v}{\partial y} + i \frac{\partial v}{\partial x} \frac{\partial v}{\partial x} + i \frac{\partial v}{\partial x} = \frac{\partial}{\partial x}(u+iv) = \frac{\partial}{\partial x}(\gamma(z)) = \gamma'(z) \gamma 1 dz dz \mapsto \gamma'(z)dz = \frac{1}{(cz+d)^2}dz","['complex-analysis', 'differential-geometry', 'differential-forms', 'riemann-surfaces', 'complex-manifolds']"
84,Differentiability of simple zero of a polynomial curve,Differentiability of simple zero of a polynomial curve,,"Suppose $f(x, t) = x^n + a_{n-1}(t) x^{n-1} + \dots + a_0(t) \in \mathbb R[x]$ where each $a_j(t) \in C^{\infty}(\mathbb R)$ . If $x_0 \in \mathbb C$ is a simple zero of $f(x, t_0)$ , I want to know if there is a $C^{\infty}$ function $\eta: I \to \mathbb C$ such that $\eta(t_0) = x_0$ and $\eta(t)$ is a zero for $f(x, t)$ for every $t \in I$ and $I$ is some interval with $t_0 \in I$ . Clearly, a zero should be a function over the coefficients and thus a function over $t$ . By chain rule, we can formally differentiate with respect to $t$ and get $f(x(t))' = f'(x(t)) x'(t)$ here $x$ can be equivalently viewed as $\eta$ . At $t_0$ , $f'(x(t_0)) = f'(x_0) \neq 0$ . I want to say by inverse function theorem, $\eta$ is defined for some $I$ . But I got suspicious over the first step. I am not convinced why I can do that?","Suppose where each . If is a simple zero of , I want to know if there is a function such that and is a zero for for every and is some interval with . Clearly, a zero should be a function over the coefficients and thus a function over . By chain rule, we can formally differentiate with respect to and get here can be equivalently viewed as . At , . I want to say by inverse function theorem, is defined for some . But I got suspicious over the first step. I am not convinced why I can do that?","f(x, t) = x^n + a_{n-1}(t) x^{n-1} + \dots + a_0(t) \in \mathbb R[x] a_j(t) \in C^{\infty}(\mathbb R) x_0 \in \mathbb C f(x, t_0) C^{\infty} \eta: I \to \mathbb C \eta(t_0) = x_0 \eta(t) f(x, t) t \in I I t_0 \in I t t f(x(t))' = f'(x(t)) x'(t) x \eta t_0 f'(x(t_0)) = f'(x_0) \neq 0 \eta I","['abstract-algebra', 'complex-analysis', 'polynomials']"
85,Can I take a derivative of any complex function so long as I treat the complex numbers as matrices?,Can I take a derivative of any complex function so long as I treat the complex numbers as matrices?,,"Complex numbers can be represented as matrices, for example $$ a+bi \leftrightarrow \pmatrix{a &b\\-b&a} $$ Only some functions of a complex variable have a derivative that is a complex number (those which are holomorphic). However, I can take derivatives of all smooth maps from matrices to matrices, even those that correspond to functions that are not holomorphic. What gives?","Complex numbers can be represented as matrices, for example Only some functions of a complex variable have a derivative that is a complex number (those which are holomorphic). However, I can take derivatives of all smooth maps from matrices to matrices, even those that correspond to functions that are not holomorphic. What gives?","
a+bi \leftrightarrow \pmatrix{a &b\\-b&a}
","['matrices', 'complex-analysis']"
86,What does an entire function whose images are normal matrices look like?,What does an entire function whose images are normal matrices look like?,,"I'd like to ask about the properties of a matrix-valued function $A:\mathbb C\to M_n(\mathbb C)$ where each entry of $A$ is an entire function and $A(z)$ is invertible and normal for every $z\in\mathbb C$ . I have difficultly to even come up with an interesting example of such a matrix-valued function. If $A$ is always Hermitian or always unitary, $A$ must be constant. Every non-constant example that I could find turned out to be uninteresting: it could be written in the form of $$ A(z)=UD(z)U^\ast,\tag{1} $$ where $U$ is some constant unitary matrix and $D(z)$ is some diagonal matrix function. This includes the cases where $A=f(z)M$ or $A=e^{f(z)K}$ , in which $f$ is an entire scalar function, $M$ is a constant normal matrix and $K$ is a constant skew-Hermitian matrix. Must $A$ be in the form of $(1)$ ? If not, is there any complete characterisation of $A$ ? Answers with the invertibility requirement removed are also welcomed.","I'd like to ask about the properties of a matrix-valued function where each entry of is an entire function and is invertible and normal for every . I have difficultly to even come up with an interesting example of such a matrix-valued function. If is always Hermitian or always unitary, must be constant. Every non-constant example that I could find turned out to be uninteresting: it could be written in the form of where is some constant unitary matrix and is some diagonal matrix function. This includes the cases where or , in which is an entire scalar function, is a constant normal matrix and is a constant skew-Hermitian matrix. Must be in the form of ? If not, is there any complete characterisation of ? Answers with the invertibility requirement removed are also welcomed.","A:\mathbb C\to M_n(\mathbb C) A A(z) z\in\mathbb C A A 
A(z)=UD(z)U^\ast,\tag{1}
 U D(z) A=f(z)M A=e^{f(z)K} f M K A (1) A","['linear-algebra', 'matrices', 'complex-analysis']"
87,Does the Polygonal Confinement Theorem hold on the set of entire functions?,Does the Polygonal Confinement Theorem hold on the set of entire functions?,,"The Polygonal Confinement Theorem can be found in Section 2 of this paper by Rosenthal. I am interested in a generalization of Lemma 3.1 in the paper, which states: $\textbf{Lemma 3.1:} $ If $v_1,\ldots,v_m \in \mathbb{R}^n$ , and $\left\|\displaystyle \sum_{i=1}^m v_i\right\|<\epsilon$ , $\|v_j\|<\epsilon$ for all $j$ , then there is a constant $C$ which does not depend on $m$ and a permutation $\sigma$ of $\{1,\ldots,m\}$ such that for each $1\leq j\leq m$ , $$ \left\|\sum_{i=1}^j v_i\right\| \leq C\epsilon.$$ I am wondering whether the following analogue for entire functions holds. In the question below, $\|f\|_R$ denotes the supremum of $f$ on the disk $|z|\leq R$ . $\textbf{Question:}$ Suppose $R>0$ and $f_i$ are entire functions on $\mathbb{C}$ . Let $\epsilon>0$ .  If $\displaystyle \left\| \sum_{i=1}^m f_i \right\|_R< \epsilon$ and $\displaystyle \|f_j\|_R < \epsilon$ for each $j$ , does there exist a constant $C$ independent of $m$ and a permutation $\sigma$ of $\{1,\ldots,m\}$ such that whenever $1\leq j\leq m$ , $$ \left\| \sum_{i=1}^j f_{\sigma(i)} \right\|_R< C\epsilon?$$ Lemma 3.1, called the rearrangement theorem by Rosenthal and the Steinitz lemma by others, was the crucial element for proving the Levy-Steinitz theorem (found in the Rosenthal paper).  The Levy-Stenitz theorem was generalized to metrizable nuclear topological vector spaces by Banaszczyk in this paper .  Since the space of entire functions is a Frechet space, and hence a nuclear space, I am hoping that the analgoue of Lemma 3.1 holds.  In fact, it looks like the Corollary in the Banaszczyk paper on page 196 may be what I'm looking for.  But the generality and technicality of the paper is well beyond my expertise. Any insight or references would be most appreciated.","The Polygonal Confinement Theorem can be found in Section 2 of this paper by Rosenthal. I am interested in a generalization of Lemma 3.1 in the paper, which states: If , and , for all , then there is a constant which does not depend on and a permutation of such that for each , I am wondering whether the following analogue for entire functions holds. In the question below, denotes the supremum of on the disk . Suppose and are entire functions on . Let .  If and for each , does there exist a constant independent of and a permutation of such that whenever , Lemma 3.1, called the rearrangement theorem by Rosenthal and the Steinitz lemma by others, was the crucial element for proving the Levy-Steinitz theorem (found in the Rosenthal paper).  The Levy-Stenitz theorem was generalized to metrizable nuclear topological vector spaces by Banaszczyk in this paper .  Since the space of entire functions is a Frechet space, and hence a nuclear space, I am hoping that the analgoue of Lemma 3.1 holds.  In fact, it looks like the Corollary in the Banaszczyk paper on page 196 may be what I'm looking for.  But the generality and technicality of the paper is well beyond my expertise. Any insight or references would be most appreciated.","\textbf{Lemma 3.1:}  v_1,\ldots,v_m \in \mathbb{R}^n \left\|\displaystyle \sum_{i=1}^m v_i\right\|<\epsilon \|v_j\|<\epsilon j C m \sigma \{1,\ldots,m\} 1\leq j\leq m  \left\|\sum_{i=1}^j v_i\right\| \leq C\epsilon. \|f\|_R f |z|\leq R \textbf{Question:} R>0 f_i \mathbb{C} \epsilon>0 \displaystyle \left\| \sum_{i=1}^m f_i \right\|_R< \epsilon \displaystyle \|f_j\|_R < \epsilon j C m \sigma \{1,\ldots,m\} 1\leq j\leq m  \left\| \sum_{i=1}^j f_{\sigma(i)} \right\|_R< C\epsilon?","['complex-analysis', 'topological-vector-spaces']"
88,Subgroup of Mbius transformations which are isometries with respect to the standard metric on the Riemann sphere,Subgroup of Mbius transformations which are isometries with respect to the standard metric on the Riemann sphere,,"I'm trying to find which subgroup of Mobius transformations are isometries with respect to the standard metric on the Riemann sphere (the one induced from the Euclidean metric on $\mathbb{R}^3$ ). The question hints that the distance on the Riemann sphere corresponds to the distance function on $\mathbb{P}^1$ given by $$d(L_1,L_2) = 2\sqrt{1 - \frac{|\langle v,w \rangle|^2}{||v||^2||w||^2}}$$ where $ v \in L_1\backslash\{0\}$ and $w \in L_2\backslash\{0\}$ , and that a Mobius map corresponds to the action of a matrix $A \in GL_2(\mathbb{C})$ on lines in $\mathbb{C}^2$ , and asks me to consider which $2x2$ matrices automatically preserve this expression for $d$ . I honestly have no idea where to start with this question, so I'd really appreciate whatever help you might be able to give.","I'm trying to find which subgroup of Mobius transformations are isometries with respect to the standard metric on the Riemann sphere (the one induced from the Euclidean metric on ). The question hints that the distance on the Riemann sphere corresponds to the distance function on given by where and , and that a Mobius map corresponds to the action of a matrix on lines in , and asks me to consider which matrices automatically preserve this expression for . I honestly have no idea where to start with this question, so I'd really appreciate whatever help you might be able to give.","\mathbb{R}^3 \mathbb{P}^1 d(L_1,L_2) = 2\sqrt{1 - \frac{|\langle v,w \rangle|^2}{||v||^2||w||^2}}  v \in L_1\backslash\{0\} w \in L_2\backslash\{0\} A \in GL_2(\mathbb{C}) \mathbb{C}^2 2x2 d","['complex-analysis', 'metric-spaces', 'isometry', 'mobius-transformation', 'stereographic-projections']"
89,I cannot calculate $\tan^{-1}(1+i)$,I cannot calculate,\tan^{-1}(1+i),"I use the formula below for inverse tangent function: $$\tan^{-1}(z)= \frac {i} 2 \log \biggr( \frac {i+z}{i-z} \biggr)$$ I have written $$\tan^{-1}(1+i)= \frac {i} 2 \log \biggr( \frac {i+1+i}{i-1-i} \biggr)=  \frac {i} 2 \log (-2i-1)$$ The answer is $n\pi i , n\in \mathbb Z$ but I dont know or I cannot see what is the argument of $-2i-1$ I know it is basic question but I couldnt see how can I do Thanks for helps",I use the formula below for inverse tangent function: I have written The answer is but I dont know or I cannot see what is the argument of I know it is basic question but I couldnt see how can I do Thanks for helps,"\tan^{-1}(z)= \frac {i} 2 \log \biggr( \frac {i+z}{i-z} \biggr) \tan^{-1}(1+i)= \frac {i} 2 \log \biggr( \frac {i+1+i}{i-1-i} \biggr)=  \frac {i} 2 \log (-2i-1) n\pi i , n\in \mathbb Z -2i-1","['complex-analysis', 'trigonometry', 'complex-numbers']"
90,"Prove that there exists $h\in V$, such that $|f'(\frac{1}{2})|\leq|h'(\frac{1}{2})|$ for all $f\in V$.","Prove that there exists , such that  for all .",h\in V |f'(\frac{1}{2})|\leq|h'(\frac{1}{2})| f\in V,"Let $V=\{f\in\mathcal{O}(\mathbb{D}):f(z)=\sum_{n=0}^{\infty}a_{n}z^{n}\text{ with }|a_{n}|\leq n^{2}\text{ for all }n\}$ . Prove that there exists $h\in V$ , such that $|f'(\frac{1}{2})|\leq|h'(\frac{1}{2})|$ for all $f\in V$ . I want to use Montel's Theorem: Let $\mathcal{F}$ be a family of holomorphic functions on . If $\mathcal{F}$ is uniformly bounded on every compact subset of , then $\mathcal{F}$ is equicontinuous on every compact subset of , and hence $\mathcal{F}$ is a normal family. My initial thought is to first prove that the set $V$ is uniformly bounded on every compact subset, but I'm not quite sure how to show that. Also, How do I use the Montel's theorem to prove above? I guess my question is how is showing the existence of $h$ relate to $V$ is a normal family?","Let . Prove that there exists , such that for all . I want to use Montel's Theorem: Let be a family of holomorphic functions on . If is uniformly bounded on every compact subset of , then is equicontinuous on every compact subset of , and hence is a normal family. My initial thought is to first prove that the set is uniformly bounded on every compact subset, but I'm not quite sure how to show that. Also, How do I use the Montel's theorem to prove above? I guess my question is how is showing the existence of relate to is a normal family?",V=\{f\in\mathcal{O}(\mathbb{D}):f(z)=\sum_{n=0}^{\infty}a_{n}z^{n}\text{ with }|a_{n}|\leq n^{2}\text{ for all }n\} h\in V |f'(\frac{1}{2})|\leq|h'(\frac{1}{2})| f\in V \mathcal{F} \mathcal{F} \mathcal{F} \mathcal{F} V h V,['complex-analysis']
91,Cauchy Integral Theorem with $f(z)=e^{z^2}$,Cauchy Integral Theorem with,f(z)=e^{z^2},"I have $z(t)=t(1-t)e^t + \cos(2 \pi \cdot t^3)i$ with $0 \le  t  \le 1$ and need to evaluate the line integral of $e^{z^2}$ . I know that the endpoints are $z(0)=z(1)=0+i$ , so the line is a closed curve. I also know that $e^{z^2}$ is an analytic function, so we can use Cauchy's integral formula here. I have a decent understanding of Cauchy's, but still kind of confused. Doesn't it make us ""pick"" a point that lies inside the curve (since the denominator is $(z-a)$ ). How am I supposed to pick a point within this curve for this problem? It feels fairly arbitrary. Thanks!","I have with and need to evaluate the line integral of . I know that the endpoints are , so the line is a closed curve. I also know that is an analytic function, so we can use Cauchy's integral formula here. I have a decent understanding of Cauchy's, but still kind of confused. Doesn't it make us ""pick"" a point that lies inside the curve (since the denominator is ). How am I supposed to pick a point within this curve for this problem? It feels fairly arbitrary. Thanks!",z(t)=t(1-t)e^t + \cos(2 \pi \cdot t^3)i 0 \le  t  \le 1 e^{z^2} z(0)=z(1)=0+i e^{z^2} (z-a),"['complex-analysis', 'parametrization', 'line-integrals', 'cauchy-integral-formula']"
92,Algebraic dependence of any 3 integral weighted modular forms,Algebraic dependence of any 3 integral weighted modular forms,,"Let $M_k(\Gamma)$ be the integral weight $k$ modular forms defined over discrete subgroup $\Gamma\leq SL_2(R)$ .  One is given $dim_C M_k(\Gamma)\leq \frac{kV}{4\pi}+1$ with $V$ some constant number. Book says the following. ""If $f,g,h$ were algebraically independent modular forms, then for large $k$ , dimension $M_k(\Gamma)$ would be at least the number of monomials in $f,g,h$ of total weight $k$ , which is bigger than some positive multiple of $k^2$ . This contradicts dimension of $M_k(\Gamma)$ growth in $k$ by above."" $\textbf{Q:}$ Suppose $f,g,h$ are weighted $l_1,l_2,l_3$ modular forms. I need to look for number of solutions asymptotic solution $(a_1,a_2,a_3)\in Z_{\geq 0}^3$ $a_1l_1+a_2l_2+a_3l_3=k$ . It is clear that in general the defining equation cuts off a hyperplane in $R^3$ with a surface area asymptotic $k^2$ . If I further assume the points are evenly distributed(very wrong hypothesis), then indeed I expect number of points lying on that hypersurface should be asymptotic to $k^2$ for large $k$ . How do I argue that statement rigorously? Ref. Zagier 1-2-3 Modular Forms pg 12. Proposition 3","Let be the integral weight modular forms defined over discrete subgroup .  One is given with some constant number. Book says the following. ""If were algebraically independent modular forms, then for large , dimension would be at least the number of monomials in of total weight , which is bigger than some positive multiple of . This contradicts dimension of growth in by above."" Suppose are weighted modular forms. I need to look for number of solutions asymptotic solution . It is clear that in general the defining equation cuts off a hyperplane in with a surface area asymptotic . If I further assume the points are evenly distributed(very wrong hypothesis), then indeed I expect number of points lying on that hypersurface should be asymptotic to for large . How do I argue that statement rigorously? Ref. Zagier 1-2-3 Modular Forms pg 12. Proposition 3","M_k(\Gamma) k \Gamma\leq SL_2(R) dim_C M_k(\Gamma)\leq \frac{kV}{4\pi}+1 V f,g,h k M_k(\Gamma) f,g,h k k^2 M_k(\Gamma) k \textbf{Q:} f,g,h l_1,l_2,l_3 (a_1,a_2,a_3)\in Z_{\geq 0}^3 a_1l_1+a_2l_2+a_3l_3=k R^3 k^2 k^2 k","['abstract-algebra', 'complex-analysis', 'number-theory']"
93,Cauchy principle value-improper integral,Cauchy principle value-improper integral,,"I'd like to calculate $\int_0^\infty \frac{\ln(1+x)}{x^{1+a}}dx$ for $a \in (0,1).$ I don't know how to start. Would you give me any hint for this problem? Thanks in advance!",I'd like to calculate for I don't know how to start. Would you give me any hint for this problem? Thanks in advance!,"\int_0^\infty \frac{\ln(1+x)}{x^{1+a}}dx a \in (0,1).","['calculus', 'complex-analysis', 'multivariable-calculus']"
94,What is the angle and the length of the sum of two complex numbers?,What is the angle and the length of the sum of two complex numbers?,,"Let $z = a+bi$ , $w = c+di$ and $s = z+w$ . It is very easy and straightforward to calculate $s$ , $\arg(s)$ and $|s|$ , but what I want to know, is how $\arg(s)$ and $|s|$ are related to $z$ and $w$ . What is $\arg(s)$ in terms of $\arg(z)$ and $\arg(w)$ ? And likewise, what is $|s|$ in terms of $|z|$ and $|w|$ ? Funny enough, complex addition seems to be more difficult than multiplication, when we think about $\arg(z)$ and $|z|$ . Even complex multiplication is easier, a simple formula for that using only $|x|$ , $Arg(x)$ and other basic operations, can be written like this: $$zw = |z||w|e^{(Arg(z)+Arg(w))i}$$ And for complex exponentiation it's a bit more complicated and complex (literally): $$z^w = \frac{|z|^{Re(w)}}{e^{Arg(z)Im(w)}}e^{(Arg(z)Re(w)+ln(|z|)Im(w))i}$$","Let , and . It is very easy and straightforward to calculate , and , but what I want to know, is how and are related to and . What is in terms of and ? And likewise, what is in terms of and ? Funny enough, complex addition seems to be more difficult than multiplication, when we think about and . Even complex multiplication is easier, a simple formula for that using only , and other basic operations, can be written like this: And for complex exponentiation it's a bit more complicated and complex (literally):",z = a+bi w = c+di s = z+w s \arg(s) |s| \arg(s) |s| z w \arg(s) \arg(z) \arg(w) |s| |z| |w| \arg(z) |z| |x| Arg(x) zw = |z||w|e^{(Arg(z)+Arg(w))i} z^w = \frac{|z|^{Re(w)}}{e^{Arg(z)Im(w)}}e^{(Arg(z)Re(w)+ln(|z|)Im(w))i},[]
95,Where is $k(z)=PV(z-1)^{\frac{1}{2}}PV(z+1)^{\frac{1}{2}}$ Continuous and Differentiable,Where is  Continuous and Differentiable,k(z)=PV(z-1)^{\frac{1}{2}}PV(z+1)^{\frac{1}{2}},"Consider the function ( $PV$ denotes the principal value ) $$PV(z-1)^{\frac{1}{2}}PV(z+1)^{\frac{1}{2}},  \ \ \forall z\in\mathbb{C}.$$ Find where $k$ is continuous and differentiable, giving reasons. We first recall that $f(w)=w^{\frac{1}{2}}$ is not continuous when $w<0$ . Using this, we can conclude that $PV(z-1)^{\frac{1}{2}}$ is not continuous when $z<1$ and $PV(z+1)^{\frac{1}{2}}$ is not continuous when $z<-1$ . Hence, $k(z)$ is not continuous when $z<1$ . Is this sufficient to determine that $k(z)$ is not differentiable on the interval $(-\infty, 1)$ , as $k(z)$ is not continuous for $z<1$ and not differentiable at $z=1$ (by inspection)?","Consider the function ( denotes the principal value ) Find where is continuous and differentiable, giving reasons. We first recall that is not continuous when . Using this, we can conclude that is not continuous when and is not continuous when . Hence, is not continuous when . Is this sufficient to determine that is not differentiable on the interval , as is not continuous for and not differentiable at (by inspection)?","PV PV(z-1)^{\frac{1}{2}}PV(z+1)^{\frac{1}{2}},  \ \ \forall z\in\mathbb{C}. k f(w)=w^{\frac{1}{2}} w<0 PV(z-1)^{\frac{1}{2}} z<1 PV(z+1)^{\frac{1}{2}} z<-1 k(z) z<1 k(z) (-\infty, 1) k(z) z<1 z=1","['complex-analysis', 'derivatives', 'proof-verification', 'continuity']"
96,"Clarification over Ahlfors page 116, 2.1 about winding numbers","Clarification over Ahlfors page 116, 2.1 about winding numbers",,"Everything on this question is in complex plane. As the book describes a property of a winding number, it says that: Outside of the [line segment from $a$ to $b$ ] the function $(z-a) / (z-b)$ is never real and $\leq 0$ . Here, the above statement should be interpreted as ""never (real and $\leq 0$ )"". If anyone could explain why this is true that would be great. I do get why any point on the line segment (other than $b$ , in which case the denominator is $0$ ) has to satisfy the condition that $(z-a) / (z-b)$ is real and $\leq 0$ , but I am not sure how to prove why any point not on the line has to satisfy the condition also. Here, $a$ and $b$ are arbitrary complex number in a region determined by a closed curve in the complex plane; both points lie on the same region.","Everything on this question is in complex plane. As the book describes a property of a winding number, it says that: Outside of the [line segment from to ] the function is never real and . Here, the above statement should be interpreted as ""never (real and )"". If anyone could explain why this is true that would be great. I do get why any point on the line segment (other than , in which case the denominator is ) has to satisfy the condition that is real and , but I am not sure how to prove why any point not on the line has to satisfy the condition also. Here, and are arbitrary complex number in a region determined by a closed curve in the complex plane; both points lie on the same region.",a b (z-a) / (z-b) \leq 0 \leq 0 b 0 (z-a) / (z-b) \leq 0 a b,"['complex-analysis', 'winding-number']"
97,"Calculating the residue of $\frac{10z^4-10\sin(z)}{z^3}, z(0) = 0$",Calculating the residue of,"\frac{10z^4-10\sin(z)}{z^3}, z(0) = 0","$$\frac{10z^4-10\sin(z)}{z^3}, \quad z(0) = 0.$$ I've gotten that $$\operatorname{Res} = 0$$ but I'm not quite  sure if that is correct, or if I have even used a correct pathway towards it. How should one work around sine (or cosine, for that matter) during residue calculations?","I've gotten that but I'm not quite  sure if that is correct, or if I have even used a correct pathway towards it. How should one work around sine (or cosine, for that matter) during residue calculations?","\frac{10z^4-10\sin(z)}{z^3}, \quad z(0) = 0. \operatorname{Res} = 0","['complex-analysis', 'residue-calculus']"
98,Use of Mergelyan's theorem to approximate a function that is nearly vanishing on unit circle,Use of Mergelyan's theorem to approximate a function that is nearly vanishing on unit circle,,"Let $K$ be a proper compact subset of the unit circle in $\mathbb{C}$ . Prove that for any $\epsilon > 0$ , there exists a polynomial $p(z)$ such that $$|p(z)| \leq \epsilon$$ for $z \in K$ and $p(0)=1$ . My thoughts: Mergelyan's Theorem came to mind, but I could not maintain the condition $p(0)=1$ . That is, even if I could construct a function $f(z)$ continuous on $K$ such that $|f(z)|<\epsilon/2$ (for instance) whenever $z \in K$ , there is no guarantee that the polynomial approximation $p(z)$ to $f(z)$ has to satisfy $p(0)=1$ . How to maintain this condition when Mergelyan is invoked?","Let be a proper compact subset of the unit circle in . Prove that for any , there exists a polynomial such that for and . My thoughts: Mergelyan's Theorem came to mind, but I could not maintain the condition . That is, even if I could construct a function continuous on such that (for instance) whenever , there is no guarantee that the polynomial approximation to has to satisfy . How to maintain this condition when Mergelyan is invoked?",K \mathbb{C} \epsilon > 0 p(z) |p(z)| \leq \epsilon z \in K p(0)=1 p(0)=1 f(z) K |f(z)|<\epsilon/2 z \in K p(z) f(z) p(0)=1,['complex-analysis']
99,"If $f(z)$ is continuous and nonzero at a point $z=z_0$, then there is a neighbourhood of $z=z_0$ in which $f(z)$ is nonzero.","If  is continuous and nonzero at a point , then there is a neighbourhood of  in which  is nonzero.",f(z) z=z_0 z=z_0 f(z),"Here is my proof. (Note that $z$ refers to complex number.) Since $f(z)$ is continuous at $z=z_0$ , by definition, for any $\epsilon > 0$ , there exists $\delta > 0$ such that $|f(z)-f(z_0)| <\epsilon$ whenever $|z-z_0|<\delta$ . (or equivalently, there exists a neighbourhood $N(z_0;\delta)$ .) Then for $\epsilon=|f(z_0)|>0$ ( $|f(z_0)|\neq 0$ as $f(z_0)\neq 0$ ), there exists $N(z_0;\delta)$ such that $$\big||f(z)|-|f(z_0)|\big|\leq |f(z)-f(z_0)|<\epsilon$$ $$\Rightarrow\big||f(z)|-|f(z_0)|\big|<\epsilon$$ $$\Rightarrow -\epsilon+|f(z_0)|<|f(z)|<\epsilon+|f(z_0)|$$ $$\Rightarrow 0<|f(z)|<2|f(z_0)|$$ $$\Rightarrow |f(z)|>0$$ $$\Rightarrow f(z)\neq 0$$ as required. Is my proof correct?","Here is my proof. (Note that refers to complex number.) Since is continuous at , by definition, for any , there exists such that whenever . (or equivalently, there exists a neighbourhood .) Then for ( as ), there exists such that as required. Is my proof correct?",z f(z) z=z_0 \epsilon > 0 \delta > 0 |f(z)-f(z_0)| <\epsilon |z-z_0|<\delta N(z_0;\delta) \epsilon=|f(z_0)|>0 |f(z_0)|\neq 0 f(z_0)\neq 0 N(z_0;\delta) \big||f(z)|-|f(z_0)|\big|\leq |f(z)-f(z_0)|<\epsilon \Rightarrow\big||f(z)|-|f(z_0)|\big|<\epsilon \Rightarrow -\epsilon+|f(z_0)|<|f(z)|<\epsilon+|f(z_0)| \Rightarrow 0<|f(z)|<2|f(z_0)| \Rightarrow |f(z)|>0 \Rightarrow f(z)\neq 0,"['complex-analysis', 'proof-verification']"
