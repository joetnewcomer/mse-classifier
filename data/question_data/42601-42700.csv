,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Describe the groups of homomorphisms of the given abelian groups,Describe the groups of homomorphisms of the given abelian groups,,"In algebra we have the following problem to solve: Describe the groups of homomorphisms of abelian groups. (a) $\textrm{Hom}(\mathbb{Q} / \mathbb{Z}, \mathbb{Q})$ (b) $\textrm{Hom}(\mathbb{Q}, \mathbb{Q} / \mathbb{Z})$ So first of all, I'm not sure, if I really understand what to do. I assume that I just have to describe the group $\textrm{Hom}(\mathbb{Q/Z,Q})$, This means that I have to define a group operation and then prove that it satisfies the group axioms, like closedness, associativity, existence of inverses element, existence of an identity element, etc. Is this idea correct? If so, I would define the operation like this: let $f,g \in \textrm{Hom}(\mathbb{Q/Z,Q})$ then: $$(f\odot g)(x):=f(x)+g(x), \qquad \forall x\in \mathbb{Q}.$$ to check that this operation is closed, we have to show that $$f\odot g \in \textrm{Hom}(\mathbb{Q/Z,Q}), \qquad \forall f,g \in \textrm{Hom}(\mathbb{Q/Z,Q})$$ Proof: Let $f,g \in \forall f,g \in \textrm{Hom}(\mathbb{Q/Z,Q})$. Then, $$\begin{array}{rclcl} (f\odot g)(x+y)     &=& f(x+y)+g(x+y) & \qquad & \text{(by def of $\odot$)} \\     &=& f(x)+f(y)+g(x)+g(y) & & \\     &=& f(x)+g(x)+f(y)+g(y) & & \\     &=& (f\odot g)(x)+(f\odot g)(y). & & \text{($\forall x,y \in \mathbb{Q/Z}$)}  \end{array}$$ This follows only if $\mathbb{Q}$ is abelian, which is obviously true. Also from this fact follows that: $$(f\odot g)(x)=f(x)+g(x)=g(x)+f(x)=(g\odot f)(x), \qquad \forall x \in \mathbb{Q/Z},$$ and hence $\textrm{Hom}(\mathbb{Q/Z,Q})$ is abelian. It remains only to show that there exist inverses and an identity element. As identity element we could take the embedding  $e: \mathbb{Q/Z} \hookrightarrow \mathbb{Q}.$ For the inverse I did this: $(f\odot g)(x)=e(x)=x$, $\forall x \in \mathbb{Q/Z}$ , so $$(f\odot g)(x)=f(x)+g(x)=x$$ and so $f(x)^{-1}:=g(x)=x-f(x)$ should be the inverse. Is this correct, or am I completely on the wrong trail?","In algebra we have the following problem to solve: Describe the groups of homomorphisms of abelian groups. (a) $\textrm{Hom}(\mathbb{Q} / \mathbb{Z}, \mathbb{Q})$ (b) $\textrm{Hom}(\mathbb{Q}, \mathbb{Q} / \mathbb{Z})$ So first of all, I'm not sure, if I really understand what to do. I assume that I just have to describe the group $\textrm{Hom}(\mathbb{Q/Z,Q})$, This means that I have to define a group operation and then prove that it satisfies the group axioms, like closedness, associativity, existence of inverses element, existence of an identity element, etc. Is this idea correct? If so, I would define the operation like this: let $f,g \in \textrm{Hom}(\mathbb{Q/Z,Q})$ then: $$(f\odot g)(x):=f(x)+g(x), \qquad \forall x\in \mathbb{Q}.$$ to check that this operation is closed, we have to show that $$f\odot g \in \textrm{Hom}(\mathbb{Q/Z,Q}), \qquad \forall f,g \in \textrm{Hom}(\mathbb{Q/Z,Q})$$ Proof: Let $f,g \in \forall f,g \in \textrm{Hom}(\mathbb{Q/Z,Q})$. Then, $$\begin{array}{rclcl} (f\odot g)(x+y)     &=& f(x+y)+g(x+y) & \qquad & \text{(by def of $\odot$)} \\     &=& f(x)+f(y)+g(x)+g(y) & & \\     &=& f(x)+g(x)+f(y)+g(y) & & \\     &=& (f\odot g)(x)+(f\odot g)(y). & & \text{($\forall x,y \in \mathbb{Q/Z}$)}  \end{array}$$ This follows only if $\mathbb{Q}$ is abelian, which is obviously true. Also from this fact follows that: $$(f\odot g)(x)=f(x)+g(x)=g(x)+f(x)=(g\odot f)(x), \qquad \forall x \in \mathbb{Q/Z},$$ and hence $\textrm{Hom}(\mathbb{Q/Z,Q})$ is abelian. It remains only to show that there exist inverses and an identity element. As identity element we could take the embedding  $e: \mathbb{Q/Z} \hookrightarrow \mathbb{Q}.$ For the inverse I did this: $(f\odot g)(x)=e(x)=x$, $\forall x \in \mathbb{Q/Z}$ , so $$(f\odot g)(x)=f(x)+g(x)=x$$ and so $f(x)^{-1}:=g(x)=x-f(x)$ should be the inverse. Is this correct, or am I completely on the wrong trail?",,"['abstract-algebra', 'group-theory']"
1,On a Proof that the Splitting Field of a Separable Polynomial is Galois,On a Proof that the Splitting Field of a Separable Polynomial is Galois,,"Prop.: If $f \in F[x]$ is separable, then the splitting field of $f$ over $F$ is a Galois extension of $F$. Proof: By induction over $[E:F]$, where $E$ is the splitting field. By previous results concerning finite extensions, we know it suffices to show that $[E:F] = |\text{Aut}(E/F)|$. If $[E:F]=1$ there is nothing to do. If $[E:F]>1$, then we can write $f=pq$ where $p,q \in F[x]$, $p$ irreducible and $\deg p>1$. Since $f$ is separable, $p$ is separable. Write $$ p(x) := \prod_{i=1}^n (X-\alpha_i), $$ where $\alpha_i \in E$ are different. Let $E_i := F(\alpha_i)$. Then $E$ is the splitting field of $f/(x-\alpha_1) \in E_1[x]$. Since $m := [E:E_1]<[E:F]$, the induction hypothesis tells us there are $m$ elements in $\text{Aut}(E/E_1)$, let's say $\text{Aut}(E/E_1) = \{\tau_1, \ldots, \tau_m\}$. There are also $n$ isomorphisms \begin{align} \sigma_i : E_1 &\to E_i \\ \alpha_1 &\mapsto \alpha_i. \end{align} Each combination $(\tau_j, \sigma_i)$ gives an element in $\text{Aut}(E/F)$. Hence there are $mn$ elements in $\text{Aut}(E/F)$. But $mn=[E:E_1][E_1:F]=[E:F]$. $\blacksquare$ Questions: Does $\alpha_i \in E\backslash F$ for all $i$? In fact, this is used to deduce $[E:E_1]<[E:F]$? I think the answer to both is yes and that $\alpha_i \not\in F$ follows from the irreducibility of $p$ over $F$ and from the fact that $e \in E\backslash F$ & $f\in F$ $\implies$ $ef \in E\backslash F$. To apply the induction hypothesis, we note that $E$ is the splitting field of $f/(x-\alpha_1) \in E_1[x]$. But is it not true that we have more simply that $E$ is the splitting field of $f \in E_1[x]$? When we say that each combination $(\tau_j, \sigma_i)$ gives an element in $\text{Aut}(E/F)$, what are those elements? I think it must be some compositions, but the domains and codomains of $\tau_j$ and $\sigma_i$ don't quite match...? Also why are those $mn$ elements different?","Prop.: If $f \in F[x]$ is separable, then the splitting field of $f$ over $F$ is a Galois extension of $F$. Proof: By induction over $[E:F]$, where $E$ is the splitting field. By previous results concerning finite extensions, we know it suffices to show that $[E:F] = |\text{Aut}(E/F)|$. If $[E:F]=1$ there is nothing to do. If $[E:F]>1$, then we can write $f=pq$ where $p,q \in F[x]$, $p$ irreducible and $\deg p>1$. Since $f$ is separable, $p$ is separable. Write $$ p(x) := \prod_{i=1}^n (X-\alpha_i), $$ where $\alpha_i \in E$ are different. Let $E_i := F(\alpha_i)$. Then $E$ is the splitting field of $f/(x-\alpha_1) \in E_1[x]$. Since $m := [E:E_1]<[E:F]$, the induction hypothesis tells us there are $m$ elements in $\text{Aut}(E/E_1)$, let's say $\text{Aut}(E/E_1) = \{\tau_1, \ldots, \tau_m\}$. There are also $n$ isomorphisms \begin{align} \sigma_i : E_1 &\to E_i \\ \alpha_1 &\mapsto \alpha_i. \end{align} Each combination $(\tau_j, \sigma_i)$ gives an element in $\text{Aut}(E/F)$. Hence there are $mn$ elements in $\text{Aut}(E/F)$. But $mn=[E:E_1][E_1:F]=[E:F]$. $\blacksquare$ Questions: Does $\alpha_i \in E\backslash F$ for all $i$? In fact, this is used to deduce $[E:E_1]<[E:F]$? I think the answer to both is yes and that $\alpha_i \not\in F$ follows from the irreducibility of $p$ over $F$ and from the fact that $e \in E\backslash F$ & $f\in F$ $\implies$ $ef \in E\backslash F$. To apply the induction hypothesis, we note that $E$ is the splitting field of $f/(x-\alpha_1) \in E_1[x]$. But is it not true that we have more simply that $E$ is the splitting field of $f \in E_1[x]$? When we say that each combination $(\tau_j, \sigma_i)$ gives an element in $\text{Aut}(E/F)$, what are those elements? I think it must be some compositions, but the domains and codomains of $\tau_j$ and $\sigma_i$ don't quite match...? Also why are those $mn$ elements different?",,"['abstract-algebra', 'field-theory', 'galois-theory', 'splitting-field']"
2,Is there a name for those commutative monoids in which the divisibility order is antisymmetric?,Is there a name for those commutative monoids in which the divisibility order is antisymmetric?,,"Every commutative monoid $M$ is naturally equipped with its divisibility preorder, defined as follows. $$x \mid y \leftrightarrow \exists a(ax=y)$$ Is there a name for those commutative monoids such that the above preorder is antisymmetric? In other words, I'm interested in those commutative monoids satisfying the following quasi-identity : $$\frac{ax=y\quad by=x}{x=y}$$ Motivation. The category of all such structures is probably a reflective subcategory of the category of all commutative monoids, with the left-adjoint to the inclusion functor being the functor $F$ such that $F(M)$ is the commutative monoid obtained by identifying elements $x,y \in M$ satisfying $x \mid y$ and $y \mid x$. Now given a commutative monoid $M$, we are often interested in meets and joins with respect to the divisibility order, but uniqueness issues rear their annoying heads. They can be remedied by working not in $M$, but in $F(M).$","Every commutative monoid $M$ is naturally equipped with its divisibility preorder, defined as follows. $$x \mid y \leftrightarrow \exists a(ax=y)$$ Is there a name for those commutative monoids such that the above preorder is antisymmetric? In other words, I'm interested in those commutative monoids satisfying the following quasi-identity : $$\frac{ax=y\quad by=x}{x=y}$$ Motivation. The category of all such structures is probably a reflective subcategory of the category of all commutative monoids, with the left-adjoint to the inclusion functor being the functor $F$ such that $F(M)$ is the commutative monoid obtained by identifying elements $x,y \in M$ satisfying $x \mid y$ and $y \mid x$. Now given a commutative monoid $M$, we are often interested in meets and joins with respect to the divisibility order, but uniqueness issues rear their annoying heads. They can be remedied by working not in $M$, but in $F(M).$",,"['abstract-algebra', 'category-theory', 'terminology', 'monoid']"
3,Automorphisms of a field extension permute roots of irreducible factors.,Automorphisms of a field extension permute roots of irreducible factors.,,Would someone mind confirming (or refuting) the following... Proposition. Let $K$ be a field and let $f \in K[X]$. Suppose $g \in K[X]$ is an irreducible factor of $f$. Let $L$ be a splitting field for $f$ over $K$. Then Aut$(L/K)$ permutes the roots of $g$. Proof. Let $x \in L$ be a root of $g$ and let $\sigma \in$ Aut$(L/K)$. As $g \in K[X]$ we have $\sigma g = g$. Clearly $\sigma(x)$ is a root of $\sigma g$ and so the result follows. // Many thanks :),Would someone mind confirming (or refuting) the following... Proposition. Let $K$ be a field and let $f \in K[X]$. Suppose $g \in K[X]$ is an irreducible factor of $f$. Let $L$ be a splitting field for $f$ over $K$. Then Aut$(L/K)$ permutes the roots of $g$. Proof. Let $x \in L$ be a root of $g$ and let $\sigma \in$ Aut$(L/K)$. As $g \in K[X]$ we have $\sigma g = g$. Clearly $\sigma(x)$ is a root of $\sigma g$ and so the result follows. // Many thanks :),,"['abstract-algebra', 'galois-theory']"
4,intersection of all subgroups of order 9 in a group of order 36 is non trivial,intersection of all subgroups of order 9 in a group of order 36 is non trivial,,"Let $G$ be a group of order 36, prove that all its subgroups of order 9 intersect in a non-trivial subgroup. I have proven that they intersect in a subgroup, but i cant prove that it contains an element $a \not= e$, can anyone give me a proof for the fact that it is non-trivial?","Let $G$ be a group of order 36, prove that all its subgroups of order 9 intersect in a non-trivial subgroup. I have proven that they intersect in a subgroup, but i cant prove that it contains an element $a \not= e$, can anyone give me a proof for the fact that it is non-trivial?",,"['abstract-algebra', 'group-theory']"
5,exact sequence and modules proposition.,exact sequence and modules proposition.,,"I have problems to prove the following proposition: Let's consider $$0 \rightarrow L \stackrel{\alpha}{\rightarrow} M \stackrel{\beta}{\rightarrow} N \rightarrow 0$$ an exact sequence of modules   and $M_1$, $M_2$ are submodules of $M$. Prove the following statement in case it's true or give a counterexample if not:   $$\beta(M_1)=\beta(M_2) \mbox{ and } \alpha^{-1}(M_1)=\alpha^{-1}(M_2) \Rightarrow M_1=M_2.$$ My attemp: I've been trying to prove it's true, because I haven't found a counterexample. In the given conditions, for submodules $M_a \subset M_b \subset M$, I've proved that: $$[\beta(M_a)=\beta(M_b) \mbox{ and } L \cap M_a=L \cap M_b] \Rightarrow M_a=M_b$$ and I've been trying to use that by doing $M_a=M_1$ and $M_b=M_1 \cup M_2$ and applying this but I don't get what I want. Any help would be appreciate. Thanks in advance.","I have problems to prove the following proposition: Let's consider $$0 \rightarrow L \stackrel{\alpha}{\rightarrow} M \stackrel{\beta}{\rightarrow} N \rightarrow 0$$ an exact sequence of modules   and $M_1$, $M_2$ are submodules of $M$. Prove the following statement in case it's true or give a counterexample if not:   $$\beta(M_1)=\beta(M_2) \mbox{ and } \alpha^{-1}(M_1)=\alpha^{-1}(M_2) \Rightarrow M_1=M_2.$$ My attemp: I've been trying to prove it's true, because I haven't found a counterexample. In the given conditions, for submodules $M_a \subset M_b \subset M$, I've proved that: $$[\beta(M_a)=\beta(M_b) \mbox{ and } L \cap M_a=L \cap M_b] \Rightarrow M_a=M_b$$ and I've been trying to use that by doing $M_a=M_1$ and $M_b=M_1 \cup M_2$ and applying this but I don't get what I want. Any help would be appreciate. Thanks in advance.",,"['abstract-algebra', 'modules', 'exact-sequence']"
6,Why $\mathbb{Q}$ is not a projective $\mathbb{Z}$-module? [duplicate],Why  is not a projective -module? [duplicate],\mathbb{Q} \mathbb{Z},"This question already has answers here : Prove that $\operatorname{Hom}_{\Bbb{Z}}(\Bbb{Q},\Bbb{Z}) = 0$ and show that $\Bbb{Q}$ is not a projective $\Bbb{Z}$-module. (2 answers) Closed 6 years ago . From the fact that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q},\mathbb{Z})=0$, how do we conclude that $\mathbb{Q}$ is not a projective $\mathbb{Z}$-module?","This question already has answers here : Prove that $\operatorname{Hom}_{\Bbb{Z}}(\Bbb{Q},\Bbb{Z}) = 0$ and show that $\Bbb{Q}$ is not a projective $\Bbb{Z}$-module. (2 answers) Closed 6 years ago . From the fact that $\operatorname{Hom}_{\mathbb{Z}}(\mathbb{Q},\mathbb{Z})=0$, how do we conclude that $\mathbb{Q}$ is not a projective $\mathbb{Z}$-module?",,['abstract-algebra']
7,Is an abelian group characterized by its localizations?,Is an abelian group characterized by its localizations?,,Let $G$ and $H$ be countable abelian groups. Assume that for every prime number $p$ there is an isomorphism $G\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]\cong H\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]$. Does it follow that $G$ and $H$ are isomorphic as abelian groups? (Note that this is certainly true for finitely generated groups. Moreover it also holds if all isomorphisms $G\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]\cong H\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]$ are induced by one fixed group homomorphism $G\to H$. In both cases it is enough to consider two different prime numbers.),Let $G$ and $H$ be countable abelian groups. Assume that for every prime number $p$ there is an isomorphism $G\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]\cong H\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]$. Does it follow that $G$ and $H$ are isomorphic as abelian groups? (Note that this is certainly true for finitely generated groups. Moreover it also holds if all isomorphisms $G\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]\cong H\otimes_{\mathbb Z} \mathbb Z[\frac{1}{p}]$ are induced by one fixed group homomorphism $G\to H$. In both cases it is enough to consider two different prime numbers.),,"['abstract-algebra', 'commutative-algebra']"
8,"Prove that if both $N$ and $G/N'$ are nilpotent, then $G$ is nilpotent.","Prove that if both  and  are nilpotent, then  is nilpotent.",N G/N' G,"Let $G$ be a group, and let $N$ be a normal subgroup of $G$. Let $N'$ be the derived group of $N$. Prove that if both $N$ and $G/N'$ are nilpotent, then $G$ is nilpotent. Furthermore, assume that $G$ is arbitrary, not necessarily finite. Prove that if $N$ is nilpotent and $G/N'$ is abelian, thn $G$ is nilpotent and $C_{i}(G)=C_{i}(N)$ for $2 \leq i $ Recall that $C_{i}(G)$ is the higher commutator subgroup of a group $G$ I think the lemma maybe usefull: If the factor group $G/ \Phi G$ is nilpotent for a finite group $G$, then $G$ itself is nilpotent. So I think we should prove that if $G/N'$ is nilpotent then $G/ \Phi G$ is nilpotent. How do I prove it? P/s: There is a details proof on the book The Theory of Infinite Soluble Groups, JOHN C. LENNOX and DEREK J. S. ROBINSON, $(1.2.17)$ page $12$, but it looks complicated because they use stronger tools","Let $G$ be a group, and let $N$ be a normal subgroup of $G$. Let $N'$ be the derived group of $N$. Prove that if both $N$ and $G/N'$ are nilpotent, then $G$ is nilpotent. Furthermore, assume that $G$ is arbitrary, not necessarily finite. Prove that if $N$ is nilpotent and $G/N'$ is abelian, thn $G$ is nilpotent and $C_{i}(G)=C_{i}(N)$ for $2 \leq i $ Recall that $C_{i}(G)$ is the higher commutator subgroup of a group $G$ I think the lemma maybe usefull: If the factor group $G/ \Phi G$ is nilpotent for a finite group $G$, then $G$ itself is nilpotent. So I think we should prove that if $G/N'$ is nilpotent then $G/ \Phi G$ is nilpotent. How do I prove it? P/s: There is a details proof on the book The Theory of Infinite Soluble Groups, JOHN C. LENNOX and DEREK J. S. ROBINSON, $(1.2.17)$ page $12$, but it looks complicated because they use stronger tools",,"['abstract-algebra', 'group-theory']"
9,Corestriction map in lie algebra cohomology,Corestriction map in lie algebra cohomology,,"Given a lie algebra $\mathfrak{g}$ over a field $k$, we can define the cohomology groups of $\mathfrak{g}$ as follows: $$H^n(\mathfrak{g},k):=\mathrm{Ext}_{U(\mathfrak{g})}^n(k,k)$$ where $U(\mathfrak{g})$ is the universal enveloping algebra of $\mathfrak{g}$, and $k$ is the trivial $U(\mathfrak{g})$-module.  There is a cup product on $H^*(\mathfrak{g})=\oplus H^n(\mathfrak{g},k)$ which gives it the structure of a graded commutative ring.  By functoriality, a map of lie algebras $\mathfrak{h}\hookrightarrow\mathfrak{g}$ induces a ring map on cohomology $H^*(\mathfrak{g})\to H^*(\mathfrak{h})$, which we call the restriction map. For a group $G$, we may replace $U(\mathfrak{g})$ with $kG$, the group algebra, to obtain group cohomology, and again, a map of groups $H\hookrightarrow G$ induces a ring map on cohomology $H^*(G)\to H^*(H)$.  However, in the case that $(G:H)<\infty$, we also obtain a corestriction map $H^*(H)\to H^*(G)$.  Corestriction is the composition $$H^n(H,k)\to H^n(G,kG\otimes_{kH}k)\to H^n(G,k)$$ where the first map is from Shapiro's lemma (this is where we use the finite index condition, so that the induced and coinduced modules are isomorphic), and the second map is induced by the $kG$-module map $g\otimes a\mapsto ga=a$. I've heard that there is no corestriction map in the lie algebra setting.  Is this true?  If so, what is the obstruction in trying to define such a map?","Given a lie algebra $\mathfrak{g}$ over a field $k$, we can define the cohomology groups of $\mathfrak{g}$ as follows: $$H^n(\mathfrak{g},k):=\mathrm{Ext}_{U(\mathfrak{g})}^n(k,k)$$ where $U(\mathfrak{g})$ is the universal enveloping algebra of $\mathfrak{g}$, and $k$ is the trivial $U(\mathfrak{g})$-module.  There is a cup product on $H^*(\mathfrak{g})=\oplus H^n(\mathfrak{g},k)$ which gives it the structure of a graded commutative ring.  By functoriality, a map of lie algebras $\mathfrak{h}\hookrightarrow\mathfrak{g}$ induces a ring map on cohomology $H^*(\mathfrak{g})\to H^*(\mathfrak{h})$, which we call the restriction map. For a group $G$, we may replace $U(\mathfrak{g})$ with $kG$, the group algebra, to obtain group cohomology, and again, a map of groups $H\hookrightarrow G$ induces a ring map on cohomology $H^*(G)\to H^*(H)$.  However, in the case that $(G:H)<\infty$, we also obtain a corestriction map $H^*(H)\to H^*(G)$.  Corestriction is the composition $$H^n(H,k)\to H^n(G,kG\otimes_{kH}k)\to H^n(G,k)$$ where the first map is from Shapiro's lemma (this is where we use the finite index condition, so that the induced and coinduced modules are isomorphic), and the second map is induced by the $kG$-module map $g\otimes a\mapsto ga=a$. I've heard that there is no corestriction map in the lie algebra setting.  Is this true?  If so, what is the obstruction in trying to define such a map?",,"['abstract-algebra', 'lie-algebras', 'homology-cohomology', 'group-cohomology', 'lie-algebra-cohomology']"
10,Ring of formal Laurent series over an Euclidean domain.,Ring of formal Laurent series over an Euclidean domain.,,"If $R$ is a commutative Euclidean domain, then the ring $R((x))$ of formal Laurent series will also be an Euclidean domain. (Here we can assume that $R((x))$ is a commutative integral domain.) Additional information, I have: Let $F$ be a field and define the ring $F((x))$ of formal Laurent series with coefficients in $F$ as the set of all formal series of the form $\sum_{n \geq N} a_nx^n$ where $a_n \in F$ and $N \in \mathbb{Z}.$ Then $F((x))$ is a field. We can think of the elements of $F((x))$ as functions $\alpha : \mathbb{Z} \rightarrow F$ with the property that there exists a minimal element $k \in \mathbb{Z}$ such that $\alpha(k) \neq 0$, together with the zero function. With this interpretation in mind, the notation $ \alpha = \sum_{n \geq N} a_n x^n $ means that $ a_n = 0 $ for all $n < N$; note that N is not necessarily maximal with this property. That is, if $a_n = 0$ for all $N \leq n < M$, then we also say $\alpha = \sum_{n \geq M} a_n x^n$. With this in mind, we define addition and multiplication on $F((x))$ as follows $$\left( \displaystyle\sum_{n \geq N} a_n x^n \right) + \left( \displaystyle\sum_{n \geq M} b_n x^n \right) 	 =  	\displaystyle\sum_{n \geq \min(N,M)} (a_n+b_n)x^n$$ $$\left( \displaystyle\sum_{n \geq N} a_n x^n \right) \cdot \left( \displaystyle\sum_{n \geq M} b_n x^n \right) 	 =  	\displaystyle\sum_{n \geq N+M} \left( \displaystyle\sum_{i+j=n} a_ib_j \right) x^n$$ For the definition of multiplication, note that for n an integer there are only finitely many pairs $(i,j)$ such that $i+j = 0, i \geq N$, and $j \geq M.$ Then we can check all the properties.","If $R$ is a commutative Euclidean domain, then the ring $R((x))$ of formal Laurent series will also be an Euclidean domain. (Here we can assume that $R((x))$ is a commutative integral domain.) Additional information, I have: Let $F$ be a field and define the ring $F((x))$ of formal Laurent series with coefficients in $F$ as the set of all formal series of the form $\sum_{n \geq N} a_nx^n$ where $a_n \in F$ and $N \in \mathbb{Z}.$ Then $F((x))$ is a field. We can think of the elements of $F((x))$ as functions $\alpha : \mathbb{Z} \rightarrow F$ with the property that there exists a minimal element $k \in \mathbb{Z}$ such that $\alpha(k) \neq 0$, together with the zero function. With this interpretation in mind, the notation $ \alpha = \sum_{n \geq N} a_n x^n $ means that $ a_n = 0 $ for all $n < N$; note that N is not necessarily maximal with this property. That is, if $a_n = 0$ for all $N \leq n < M$, then we also say $\alpha = \sum_{n \geq M} a_n x^n$. With this in mind, we define addition and multiplication on $F((x))$ as follows $$\left( \displaystyle\sum_{n \geq N} a_n x^n \right) + \left( \displaystyle\sum_{n \geq M} b_n x^n \right) 	 =  	\displaystyle\sum_{n \geq \min(N,M)} (a_n+b_n)x^n$$ $$\left( \displaystyle\sum_{n \geq N} a_n x^n \right) \cdot \left( \displaystyle\sum_{n \geq M} b_n x^n \right) 	 =  	\displaystyle\sum_{n \geq N+M} \left( \displaystyle\sum_{i+j=n} a_ib_j \right) x^n$$ For the definition of multiplication, note that for n an integer there are only finitely many pairs $(i,j)$ such that $i+j = 0, i \geq N$, and $j \geq M.$ Then we can check all the properties.",,"['abstract-algebra', 'commutative-algebra']"
11,Galois group of irreducible polynomial in a field of characteristic zero in which every element is a perfect square,Galois group of irreducible polynomial in a field of characteristic zero in which every element is a perfect square,,"This is one of the exercises during my reading of Ian Stewart's Galois Theory . Whether the following statement is true: If $K$ is a field of characteristic zero in which every element is a perfect square, then the Galois group of any irreducible $n$-th degree polynomial over $K$ is isomorphic to $A_n$. I think it might not be true but the examples of such fields in my knowledge are very few. Any thoughts? Thanks!","This is one of the exercises during my reading of Ian Stewart's Galois Theory . Whether the following statement is true: If $K$ is a field of characteristic zero in which every element is a perfect square, then the Galois group of any irreducible $n$-th degree polynomial over $K$ is isomorphic to $A_n$. I think it might not be true but the examples of such fields in my knowledge are very few. Any thoughts? Thanks!",,"['abstract-algebra', 'galois-theory']"
12,"If two submodules are isomorphic, so is their quotient… conditions on the ring!","If two submodules are isomorphic, so is their quotient… conditions on the ring!",,"In this question Isomorphic quotients by isomorphic normal subgroups it is shown that if we have isomorphic normal subgroups, their quotients need not be isomorphic. Now, what if we take finite dimensional vector spaces, instead of groups, we do have that if two subspaces are isomorphic, then their quotients are isomorphic (simply these quotients have the same dimension, so their are isomorphic). Now considering an arbitrary module $M$ over some ring $R$, what conditions do we have to impose on $R$ and $M$ for the above statement to be true? Do modules with this property have a name? Thanks","In this question Isomorphic quotients by isomorphic normal subgroups it is shown that if we have isomorphic normal subgroups, their quotients need not be isomorphic. Now, what if we take finite dimensional vector spaces, instead of groups, we do have that if two subspaces are isomorphic, then their quotients are isomorphic (simply these quotients have the same dimension, so their are isomorphic). Now considering an arbitrary module $M$ over some ring $R$, what conditions do we have to impose on $R$ and $M$ for the above statement to be true? Do modules with this property have a name? Thanks",,['abstract-algebra']
13,"If $H$ is a subgroup of $G$ of prime index $p$, $\exists g\in G$ such that $G/H=\{H,gH,\ldots,g^{p-1}H\}$.","If  is a subgroup of  of prime index ,  such that .","H G p \exists g\in G G/H=\{H,gH,\ldots,g^{p-1}H\}","Suppose $G$ is a group and $H$ a subgroup of prime index $p$. I am trying to show that there exists an element $g\in G$ such that $$G/H=\{H,gH,g^2H,\ldots,g^{p-1}H\}$$ My attempt: By considering the (transitive) action of $G$ on $G/H$, we have a homomorphism $$\psi:G\longrightarrow S_p$$ and thus $\psi(G)$ is a transitive subgroup of $S_p$. It follows that $p$ divides $\psi(G)$ and thus, by Cauchy's theorem, there is an element $\psi(g)\in\psi(G)$ of order $p$. Then, $\psi(g^p)=\psi(g)^p=1$, so $g^p \in\ker\psi\subseteq H$, whence $g^pH=H$. The result would then follow if we can show that $g^k\notin H$ for $1\leq k\leq p-1$, but I didn't find a way to show that.","Suppose $G$ is a group and $H$ a subgroup of prime index $p$. I am trying to show that there exists an element $g\in G$ such that $$G/H=\{H,gH,g^2H,\ldots,g^{p-1}H\}$$ My attempt: By considering the (transitive) action of $G$ on $G/H$, we have a homomorphism $$\psi:G\longrightarrow S_p$$ and thus $\psi(G)$ is a transitive subgroup of $S_p$. It follows that $p$ divides $\psi(G)$ and thus, by Cauchy's theorem, there is an element $\psi(g)\in\psi(G)$ of order $p$. Then, $\psi(g^p)=\psi(g)^p=1$, so $g^p \in\ker\psi\subseteq H$, whence $g^pH=H$. The result would then follow if we can show that $g^k\notin H$ for $1\leq k\leq p-1$, but I didn't find a way to show that.",,"['abstract-algebra', 'group-theory']"
14,A valuation-like function $w: \mathbb{N}^{+} \rightarrow \mathbb{N}$ is a $p$-adic valuation?,A valuation-like function  is a -adic valuation?,w: \mathbb{N}^{+} \rightarrow \mathbb{N} p,"This question is a variant of problem 4, pg. 21, from Birkhoff and Maclane, A Survey of Modern Algebra . Given a function $w: \mathbb{N}^+ \rightarrow \mathbb{N}$  that behaves like a valuation function, i.e., (1) $ w(ab) = w(a) + w(b) $ (2) $ w(a+b) \geq \min(w(a), w(b)).$ Show that it is either constant $0$ function, $w(a) = 0$   or a multiple of a $p$-adic valuation, in other words $\forall a \in \mathbb{N}^+, w(a) = k v_p(a)$ for some $p, k$ with $v_p(p^\alpha d) = \alpha $ when $(p, d) = 1 $. Note that this problem is relatively simple if $w$ is defined over $\mathbb{Z}\backslash \{0\}$ instead of $\mathbb{N}^+$ which is the problem listed in the book. My question is whether the stronger statement above is also true. My current proof attempt is incomplete. If $\forall a,\ w(a) = 0$ we are done. Otherwise let $n$ be the least number s.t. $w(n) \neq 0$. Easy to show from (1) that $n \neq 1$ since $w(1) = 0$ and that $n$ is prime. By unique factorisation theorem and (1) to get the result I need only prove that for all primes $p$, $p\neq n \implies w(p) = 0$. I tried to proceed using well founded induction. If $p \lt n$ done. Otherwise $p \gt n$. If $n \gt 2$ then $n, p$ are odd and $n+p$ is even hence $n+p=2q$. Now $n \nmid p$ so $n \nmid n + p$. If $n \gt 2$ we have $n \nmid q$. Since $q \lt p$ the induction hypothesis gives us $w(q) = 0$ and since $n \gt 2$, $w(2) = 0$. Thus $w(n+p) = w(2q) = w(2) + w(q) = 0 \ge \min(w(n), w(p))$. This gives us that $w(p) = 0$. I can't see how to solve the $n=2$ case. Is the case where $n=2$ solvable or is there a counterexample? Some perhaps useful facts. If $w(2) \neq 0$ and any other $w(p')=0$ for $p'$ prime, $p'\neq 2$ then $w(p) =0$ for all primes $p\neq2$. Easy to prove since every prime $p$ is an even multiple less than some power $r$ of $p'$ and by (1) $w(p^r) = 0$ and then by (2) $w(p) = 0$. It can't be the case that $w$ behaves identically on all primes, i.e. $w(p) = k$ for all primes $p$ since it is easy to compute counterexamples, e.g. $2^2*5^2 + 3^5 = 7^3$ that will contradict (2). Thus it must be distinct at some two primes $p_1, p_2$. This gives two distinct relatively prime numbers where w is equal, $ p_1^{w(p_2)} $ and $p_2^{w(p_1)}$. I hoped that this would lead to a contradiction but haven't found a way forward yet.","This question is a variant of problem 4, pg. 21, from Birkhoff and Maclane, A Survey of Modern Algebra . Given a function $w: \mathbb{N}^+ \rightarrow \mathbb{N}$  that behaves like a valuation function, i.e., (1) $ w(ab) = w(a) + w(b) $ (2) $ w(a+b) \geq \min(w(a), w(b)).$ Show that it is either constant $0$ function, $w(a) = 0$   or a multiple of a $p$-adic valuation, in other words $\forall a \in \mathbb{N}^+, w(a) = k v_p(a)$ for some $p, k$ with $v_p(p^\alpha d) = \alpha $ when $(p, d) = 1 $. Note that this problem is relatively simple if $w$ is defined over $\mathbb{Z}\backslash \{0\}$ instead of $\mathbb{N}^+$ which is the problem listed in the book. My question is whether the stronger statement above is also true. My current proof attempt is incomplete. If $\forall a,\ w(a) = 0$ we are done. Otherwise let $n$ be the least number s.t. $w(n) \neq 0$. Easy to show from (1) that $n \neq 1$ since $w(1) = 0$ and that $n$ is prime. By unique factorisation theorem and (1) to get the result I need only prove that for all primes $p$, $p\neq n \implies w(p) = 0$. I tried to proceed using well founded induction. If $p \lt n$ done. Otherwise $p \gt n$. If $n \gt 2$ then $n, p$ are odd and $n+p$ is even hence $n+p=2q$. Now $n \nmid p$ so $n \nmid n + p$. If $n \gt 2$ we have $n \nmid q$. Since $q \lt p$ the induction hypothesis gives us $w(q) = 0$ and since $n \gt 2$, $w(2) = 0$. Thus $w(n+p) = w(2q) = w(2) + w(q) = 0 \ge \min(w(n), w(p))$. This gives us that $w(p) = 0$. I can't see how to solve the $n=2$ case. Is the case where $n=2$ solvable or is there a counterexample? Some perhaps useful facts. If $w(2) \neq 0$ and any other $w(p')=0$ for $p'$ prime, $p'\neq 2$ then $w(p) =0$ for all primes $p\neq2$. Easy to prove since every prime $p$ is an even multiple less than some power $r$ of $p'$ and by (1) $w(p^r) = 0$ and then by (2) $w(p) = 0$. It can't be the case that $w$ behaves identically on all primes, i.e. $w(p) = k$ for all primes $p$ since it is easy to compute counterexamples, e.g. $2^2*5^2 + 3^5 = 7^3$ that will contradict (2). Thus it must be distinct at some two primes $p_1, p_2$. This gives two distinct relatively prime numbers where w is equal, $ p_1^{w(p_2)} $ and $p_2^{w(p_1)}$. I hoped that this would lead to a contradiction but haven't found a way forward yet.",,"['abstract-algebra', 'number-theory', 'p-adic-number-theory', 'monoid', 'valuation-theory']"
15,character degree and solvability,character degree and solvability,,"There is an unsolved problem in Berkovich's book ""Characters of Finite Groups Part 2"" I state here: Is $G$ solvable if $\chi(1)^2$ divides $|G|$ for all $\chi \in \operatorname{Irr}{(G)}$? Can any one tell me some latest progresses for this? Maybe you can tell me some latest research papers. Thank you.","There is an unsolved problem in Berkovich's book ""Characters of Finite Groups Part 2"" I state here: Is $G$ solvable if $\chi(1)^2$ divides $|G|$ for all $\chi \in \operatorname{Irr}{(G)}$? Can any one tell me some latest progresses for this? Maybe you can tell me some latest research papers. Thank you.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'characters']"
16,A set of basic abstract algebra exercises,A set of basic abstract algebra exercises,,"I wanted to review some basic abstract algebra. Here's a few problems for which I am seeking solution verification. Thank you very much in advance! $\textbf{Problem:}$ Let $H$ be a subgroup of $G$, and let $X$ denote the set of all the left cosets of $H$ in $G$. For each element $a \in G$, define $\rho_{a}: X \rightarrow X$ as follows: $$\rho_{a} (xH) = (ax) H.$$ Prove that $\rho_{a}$ is a permutation of $X$ for each $a \in G$. Prove that $h: G \rightarrow S_{X}$ defined by $h(a)=\rho_{a}$ is a homomorphism. Prove that the set $\{a \in H : xax^{-1} \in H \> \forall x \in G\}$ is the kernel of $h$. $\textbf{Solution:}$ Choose any $a \in G$. We first show that $\rho_{a}$ is injective. So, assume $\rho_{a}(xH) = \rho_{a}(x'H).$ Hence, $(ax)H = (ax')H$; we need to show $ xH = x'H$. Let $g \in xH$. Then, $g = xh_0$ and $ag = (ax)h_0 = (ax')h_1$ by our assumption. Multiplying $ag = (ax')h_1$ on the left by $a^{-1}$ gives us that $g= x'h_1$. Thus, $g \in x'H$. A similar argument gives us the reverse inclusion. To prove the surjectivity of $\rho_{a}$, let $xH \in X$. Since $a^{-1}x \in G$, we have $\rho_{a} (a^{-1}x H) = (aa^{-1}x)H = xH$. Indeed, $\rho_{a}$ is surjective. First, we show $\rho_{ab} = \rho_{a} \circ \rho_{b}$. Let $xH$ be an arbitrary element belonging to $X$. Observe that $$\rho_{a} \circ \rho_{b} (xH) = \rho_{a}((bx)H) = (abx)H = \rho_{ab}(xH).$$ Thus, $$h(ab)=\rho_{ab}=\rho_{a} \circ \rho_{b} = h(a)h(b),$$ and we conclude that $h$ is a homomorphism. Let $K$ denote the kernel of $h$. We show $\{a \in H : xax^{-1} \in H \> \forall x \in G\} = K$. To start, let $k \in K$. Then, $h(k)=\rho_{k}=\rho_{e}$, where $e$ is the identity element of $G$. Since $\rho_{k}=\rho_{e}$, for each $xH \in X$ we have $(kx)H=xH.$ Hence, $kxh_0 = xh_1$ for some $h_0,h_1 \in H$ and $x^{-1}kx=h_{1}h^{-1}_{0}.$ This implies $x^{-1}kx \in H$. For clarity, put $x_0 = x^{-1}$. So, $x^{-1}kx = x_{0}kx^{-1}_0 \in H$. Indeed, $k \in\{a \in H : xax^{-1} \in H \> \forall x \in G\}$. To prove the reverse inclusion, this time let $k \in \{a \in H : xax^{-1} \in H \> \forall x \in G\}.$ Then, we must show $(kx)H=xH$. Let $g\in (kx)H$. Suppose $g = kxh_0$ for $h_0 \in H$. Multiplying on the right by $x^{-1}$, we obtain $x^{-1}g = x^{-1}kxh_0 = h_1$ for some $h_1 \in H$. Multiplying on the right by $x$, we indeed get $g=xh_1 \in xH$. For the reverse inclusion, we let $g \in xH$ so that $g=xh_0$ for some $h_0$. Then, $$kg=kxh_0$$ $$g^{-1}kg=g^{-1}kxh_{0}$$  $$ h_{1}=g^{-1}kxh_0$$ $$g=kxh_0h^{-1}_{1}.$$ The last line gives us that $g \in (kx)H$ as desired.  $\blacksquare$","I wanted to review some basic abstract algebra. Here's a few problems for which I am seeking solution verification. Thank you very much in advance! $\textbf{Problem:}$ Let $H$ be a subgroup of $G$, and let $X$ denote the set of all the left cosets of $H$ in $G$. For each element $a \in G$, define $\rho_{a}: X \rightarrow X$ as follows: $$\rho_{a} (xH) = (ax) H.$$ Prove that $\rho_{a}$ is a permutation of $X$ for each $a \in G$. Prove that $h: G \rightarrow S_{X}$ defined by $h(a)=\rho_{a}$ is a homomorphism. Prove that the set $\{a \in H : xax^{-1} \in H \> \forall x \in G\}$ is the kernel of $h$. $\textbf{Solution:}$ Choose any $a \in G$. We first show that $\rho_{a}$ is injective. So, assume $\rho_{a}(xH) = \rho_{a}(x'H).$ Hence, $(ax)H = (ax')H$; we need to show $ xH = x'H$. Let $g \in xH$. Then, $g = xh_0$ and $ag = (ax)h_0 = (ax')h_1$ by our assumption. Multiplying $ag = (ax')h_1$ on the left by $a^{-1}$ gives us that $g= x'h_1$. Thus, $g \in x'H$. A similar argument gives us the reverse inclusion. To prove the surjectivity of $\rho_{a}$, let $xH \in X$. Since $a^{-1}x \in G$, we have $\rho_{a} (a^{-1}x H) = (aa^{-1}x)H = xH$. Indeed, $\rho_{a}$ is surjective. First, we show $\rho_{ab} = \rho_{a} \circ \rho_{b}$. Let $xH$ be an arbitrary element belonging to $X$. Observe that $$\rho_{a} \circ \rho_{b} (xH) = \rho_{a}((bx)H) = (abx)H = \rho_{ab}(xH).$$ Thus, $$h(ab)=\rho_{ab}=\rho_{a} \circ \rho_{b} = h(a)h(b),$$ and we conclude that $h$ is a homomorphism. Let $K$ denote the kernel of $h$. We show $\{a \in H : xax^{-1} \in H \> \forall x \in G\} = K$. To start, let $k \in K$. Then, $h(k)=\rho_{k}=\rho_{e}$, where $e$ is the identity element of $G$. Since $\rho_{k}=\rho_{e}$, for each $xH \in X$ we have $(kx)H=xH.$ Hence, $kxh_0 = xh_1$ for some $h_0,h_1 \in H$ and $x^{-1}kx=h_{1}h^{-1}_{0}.$ This implies $x^{-1}kx \in H$. For clarity, put $x_0 = x^{-1}$. So, $x^{-1}kx = x_{0}kx^{-1}_0 \in H$. Indeed, $k \in\{a \in H : xax^{-1} \in H \> \forall x \in G\}$. To prove the reverse inclusion, this time let $k \in \{a \in H : xax^{-1} \in H \> \forall x \in G\}.$ Then, we must show $(kx)H=xH$. Let $g\in (kx)H$. Suppose $g = kxh_0$ for $h_0 \in H$. Multiplying on the right by $x^{-1}$, we obtain $x^{-1}g = x^{-1}kxh_0 = h_1$ for some $h_1 \in H$. Multiplying on the right by $x$, we indeed get $g=xh_1 \in xH$. For the reverse inclusion, we let $g \in xH$ so that $g=xh_0$ for some $h_0$. Then, $$kg=kxh_0$$ $$g^{-1}kg=g^{-1}kxh_{0}$$  $$ h_{1}=g^{-1}kxh_0$$ $$g=kxh_0h^{-1}_{1}.$$ The last line gives us that $g \in (kx)H$ as desired.  $\blacksquare$",,"['abstract-algebra', 'solution-verification']"
17,Valuations on a field and ramification,Valuations on a field and ramification,,"For $K\subseteq L$, where $L$ is a finite number field extension of $K$, we consider $p\subset R_K$ and $p'\subset R_L$ where $p'$ lies over $p$, where $R_K$ is the ring of integers of $K$ and $R_L$ defined likewise. Then valuations on $K$ and $L$ are associated with the primes of the fields, so there is a valuation associated with $p$ and $p'$. My question is how would the way $p$ behave in $L$ (i.e. whether it is inert, split or ramified) affect the relation between $v_{p}(x)$ in $K$ and $v_{p'}(x)$ in $L$? For example, if $L$ is a quadratic extension of $K$, I think that if: $p$ is inert in $L$, then $v_p(x)=v_{p'}(x)$ (Note that this means $v_{p}(x)$ in $K$ is equal to $v_{p'}(x)$ in $L$). $p$ splits in $L$, so that $pR_L=p'p''$, then $v_p(x)=v_{p'}(x)+v_{p''}(x)$. $p$ ramifies in $L$, so that $pR_L=p'p'$, then $v_p(x)=2v_{p'}(x)$. I'm would like to know how this is generalised to general finite extensions $L$ of $K$ using inertia degree and a proof or a reference to something containing a proof would be much appreciated. Thank you!","For $K\subseteq L$, where $L$ is a finite number field extension of $K$, we consider $p\subset R_K$ and $p'\subset R_L$ where $p'$ lies over $p$, where $R_K$ is the ring of integers of $K$ and $R_L$ defined likewise. Then valuations on $K$ and $L$ are associated with the primes of the fields, so there is a valuation associated with $p$ and $p'$. My question is how would the way $p$ behave in $L$ (i.e. whether it is inert, split or ramified) affect the relation between $v_{p}(x)$ in $K$ and $v_{p'}(x)$ in $L$? For example, if $L$ is a quadratic extension of $K$, I think that if: $p$ is inert in $L$, then $v_p(x)=v_{p'}(x)$ (Note that this means $v_{p}(x)$ in $K$ is equal to $v_{p'}(x)$ in $L$). $p$ splits in $L$, so that $pR_L=p'p''$, then $v_p(x)=v_{p'}(x)+v_{p''}(x)$. $p$ ramifies in $L$, so that $pR_L=p'p'$, then $v_p(x)=2v_{p'}(x)$. I'm would like to know how this is generalised to general finite extensions $L$ of $K$ using inertia degree and a proof or a reference to something containing a proof would be much appreciated. Thank you!",,"['abstract-algebra', 'algebraic-number-theory', 'extension-field', 'valuation-theory']"
18,Equivalence between Ext and Hom,Equivalence between Ext and Hom,,"This is a question from Homology by Saunders Mac Lane. This is problem 5 page 76. I've been struggling to solve this problem for like more than a day, but still nothing valuable comes across my mind yet. Problem For $p$ prime, and $C$ an Abelian group such that $pC = 0$ , prove that: $$\mbox{Ext}_\mathbb{Z}(C; G) \cong \mbox{Hom}(C; G/pG)$$ I've made a couple of attempts, but all of them fail. Firstly, I try to find some connections between the elements in $\mbox{Ext}_\mathbb{Z}(C; G)$ , and the elements in $\mbox{Hom}(C; G/pG)$ . The elements of $\mbox{Ext}_\mathbb{Z}(C; G)$ is a short exact sequence of Abelian groups $0 \to G \to W \to C \to 0$ , with $W$ varies. So given this exact sequence, how can I manage to find a homomorphism from $C$ to $G/pG$ ? And vice versa, given a homomorphism, how can I deduce a short exact sequence? Secondly, I try to make use of the fact that $pC = 0$ . Although I know that $C$ can only be some group of orders $p^k$ , can I deduce that $C = \bigoplus\mathbb{Z}_p$ , or is it $C = \prod\mathbb{Z}_p$ ? That's all I have in mind till now. :( Is there some other way that to look at this problem? Thanks very much, And have a good day, :* Edit (July, 03) I've managed to prove the problem for the simpliest case, i.e, for $C = \mathbb{Z}_p$ , i.e, to prove: $$\mbox{Ext}_\mathbb{Z}(\mathbb{Z}_p; G) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG)$$ I hope someone can have a quick look over the proof. Consider the short exact sequence: $$0 \to p\mathbb{Z} \to \mathbb{Z} \to \mathbb{Z}_p \to 0$$ Apply $\mbox{Ext}^n(-; G)$ to the above ses (? is this the right way to say it) , gives the long one: $$0 \to \mbox{Hom}(\mathbb{Z}_p; G) \to \mbox{Hom}(\mathbb{Z}; G) \xrightarrow{\chi} \mbox{Hom}(p\mathbb{Z}; G) \xrightarrow{\sigma} \mbox{Ext}(\mathbb{Z}_p; G) \to \mbox{Ext}(\mathbb{Z}; G) = 0$$ Hence $\sigma$ is epic, we'll have: $\mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im} \chi \cong \mbox{Ext}(\mathbb{Z}_p; G)$ . Notice that a group homomorphism $f$ from $\mathbb{Z}$ to $G$ is completely determined if we know $f(1)$ , similarly any $g: p\mathbb{Z} \to G$ will be determined by $g(p)$ . So, in fact, we'll have $\mbox{Im}(\chi) = \left\{ f: p\mathbb{Z} \to G \middle| f(p) \in pG\right \}$ . And hence, 2 classes of $f$ , and $g$ in $\mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im}$ will be congruent iff $f - g \in \mbox{Hom}(p\mathbb{Z}, pG)$ . So: $\mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im} \chi \cong \mbox{Hom}(p\mathbb{Z}; G/pG) \cong \mbox{Hom}(\mathbb{Z}; G/pG)$ , since $\mathbb{Z} \cong p\mathbb{Z}$ as Abelian groups. And moreover, one should notice that, for every $f \in \mbox{Hom}(\mathbb{Z}; G/pG)$ , and for every $m, n \in \mathbb{Z}$ , such that $(m - n) \vdots p$ , then $f(m) = f(n)$ . Which, in turns means that, $\mbox{Hom}(\mathbb{Z}; G/pG) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG)$ . Hence, it's done. And I've found this pdf http://www.math.wichita.edu/~pparker/classes/handout/torext.pdf , which says that: $$\mbox{Ext}\left( \bigoplus A_i; B\right) \cong \prod \mbox{Ext}\left( A_i; B\right)$$ So if it's true that $pC = 0 \Leftrightarrow C = \bigoplus \mathbb{Z}_p$ , if so, then everything should be pretty clear. Questions So some of my concerns left are: ""Apply $\mbox{Ext}^n (-; G)$ to..."" is this the right way to say it? Does the proof I gave for $\mbox{Ext}_\mathbb{Z}(\mathbb{Z}_p; G) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG)$ look correct? Can it be shortened? I know that $\mbox{Ext}\left( \bigoplus A_i; B\right) \cong \prod \mbox{Ext}\left( A_i; B\right)$ , but is it also true that $\mbox{Ext}\left( \prod A_i; B\right) \cong \bigoplus \mbox{Ext}\left( A_i; B\right)$ ? Can you guys guide me to some article, or some book, or website that have a proof to that? Or, can you guys just give me some hints on proving them? Is it true that $pC = 0 \Leftrightarrow \left[ \begin{array}{l} C = \oplus\mathbb{Z}_p \\ C = \prod \mathbb{Z}_p \end{array} \right.$ ? Thank you very much,","This is a question from Homology by Saunders Mac Lane. This is problem 5 page 76. I've been struggling to solve this problem for like more than a day, but still nothing valuable comes across my mind yet. Problem For prime, and an Abelian group such that , prove that: I've made a couple of attempts, but all of them fail. Firstly, I try to find some connections between the elements in , and the elements in . The elements of is a short exact sequence of Abelian groups , with varies. So given this exact sequence, how can I manage to find a homomorphism from to ? And vice versa, given a homomorphism, how can I deduce a short exact sequence? Secondly, I try to make use of the fact that . Although I know that can only be some group of orders , can I deduce that , or is it ? That's all I have in mind till now. :( Is there some other way that to look at this problem? Thanks very much, And have a good day, :* Edit (July, 03) I've managed to prove the problem for the simpliest case, i.e, for , i.e, to prove: I hope someone can have a quick look over the proof. Consider the short exact sequence: Apply to the above ses (? is this the right way to say it) , gives the long one: Hence is epic, we'll have: . Notice that a group homomorphism from to is completely determined if we know , similarly any will be determined by . So, in fact, we'll have . And hence, 2 classes of , and in will be congruent iff . So: , since as Abelian groups. And moreover, one should notice that, for every , and for every , such that , then . Which, in turns means that, . Hence, it's done. And I've found this pdf http://www.math.wichita.edu/~pparker/classes/handout/torext.pdf , which says that: So if it's true that , if so, then everything should be pretty clear. Questions So some of my concerns left are: ""Apply to..."" is this the right way to say it? Does the proof I gave for look correct? Can it be shortened? I know that , but is it also true that ? Can you guys guide me to some article, or some book, or website that have a proof to that? Or, can you guys just give me some hints on proving them? Is it true that ? Thank you very much,","p C pC = 0 \mbox{Ext}_\mathbb{Z}(C; G) \cong \mbox{Hom}(C; G/pG) \mbox{Ext}_\mathbb{Z}(C; G) \mbox{Hom}(C; G/pG) \mbox{Ext}_\mathbb{Z}(C; G) 0 \to G \to W \to C \to 0 W C G/pG pC = 0 C p^k C = \bigoplus\mathbb{Z}_p C = \prod\mathbb{Z}_p C = \mathbb{Z}_p \mbox{Ext}_\mathbb{Z}(\mathbb{Z}_p; G) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG) 0 \to p\mathbb{Z} \to \mathbb{Z} \to \mathbb{Z}_p \to 0 \mbox{Ext}^n(-; G) 0 \to \mbox{Hom}(\mathbb{Z}_p; G) \to \mbox{Hom}(\mathbb{Z}; G) \xrightarrow{\chi} \mbox{Hom}(p\mathbb{Z}; G) \xrightarrow{\sigma} \mbox{Ext}(\mathbb{Z}_p; G) \to \mbox{Ext}(\mathbb{Z}; G) = 0 \sigma \mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im} \chi \cong \mbox{Ext}(\mathbb{Z}_p; G) f \mathbb{Z} G f(1) g: p\mathbb{Z} \to G g(p) \mbox{Im}(\chi) = \left\{ f: p\mathbb{Z} \to G \middle| f(p) \in pG\right \} f g \mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im} f - g \in \mbox{Hom}(p\mathbb{Z}, pG) \mbox{Hom}(p\mathbb{Z}; G)/\mbox{Im} \chi \cong \mbox{Hom}(p\mathbb{Z}; G/pG) \cong \mbox{Hom}(\mathbb{Z}; G/pG) \mathbb{Z} \cong p\mathbb{Z} f \in \mbox{Hom}(\mathbb{Z}; G/pG) m, n \in \mathbb{Z} (m - n) \vdots p f(m) = f(n) \mbox{Hom}(\mathbb{Z}; G/pG) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG) \mbox{Ext}\left( \bigoplus A_i; B\right) \cong \prod \mbox{Ext}\left( A_i; B\right) pC = 0 \Leftrightarrow C = \bigoplus \mathbb{Z}_p \mbox{Ext}^n (-; G) \mbox{Ext}_\mathbb{Z}(\mathbb{Z}_p; G) \cong \mbox{Hom}(\mathbb{Z}_p; G/pG) \mbox{Ext}\left( \bigoplus A_i; B\right) \cong \prod \mbox{Ext}\left( A_i; B\right) \mbox{Ext}\left( \prod A_i; B\right) \cong \bigoplus \mbox{Ext}\left( A_i; B\right) pC = 0 \Leftrightarrow \left[ \begin{array}{l} C = \oplus\mathbb{Z}_p \\ C = \prod \mathbb{Z}_p \end{array} \right.","['abstract-algebra', 'modules', 'homological-algebra', 'derived-functors', 'exact-sequence']"
19,How to teach a High school student that complex numbers cannot be totally ordered?,How to teach a High school student that complex numbers cannot be totally ordered?,,I once again need your precious knowledge! I am not sure which is the best pedagogic way to teach a High school student about why complex numbers cannot be totally ordered. When I was in High school we were simply told that we cannot order complex numbers. When we asked why the answer was because there is no total order in $\mathbb C$. But we weren't taught a thing about order in general. Is there a crystal clear way to do this in High school? I am thanking you all in advance!,I once again need your precious knowledge! I am not sure which is the best pedagogic way to teach a High school student about why complex numbers cannot be totally ordered. When I was in High school we were simply told that we cannot order complex numbers. When we asked why the answer was because there is no total order in $\mathbb C$. But we weren't taught a thing about order in general. Is there a crystal clear way to do this in High school? I am thanking you all in advance!,,"['abstract-algebra', 'complex-numbers', 'education', 'ordered-fields']"
20,"References about $PGL(2,q^2)/PGL(2,q)$",References about,"PGL(2,q^2)/PGL(2,q)","My question about $PGL(2,q^2)$ has 2 related parts: 1) I am interested in learning about the structure of the group $G:=PGL(2,q^2)$, where $q$ is a prime power. Particularly in the cosets of $PGL(2,q)$ in $PGL(2,q^2)$. I would like it if you could recommend some introductory references to start learning about this group and these cosets. 2) I would like to be able to enumerate all $\Theta(q^3)$ distinct elements in the coset $PGL(2,q)$ in $PGL(2,q^2)$, without repetition. I have seen that there are $\Theta(q^3)$ distinct representatives (1 for each coset). My problem is that so far I haven't been able to enumerate them without repetition, so I end up doing more work by enumerating $\Theta(q^4)$ elements instead. So far my enumeration strategy goes like this: -Given an element $m_1:=\begin{pmatrix} a & b \\ c & d\end{pmatrix} \in G$, with $a,d \neq 0$, I can perform elementary row operations and transform it into the element: $m_2:=\begin{pmatrix} 1 & \bar{b} \\ \bar{c} & 1\end{pmatrix} \in G$, such that $m_1$ and $m_2$ are equivalent in G. -Under the assumption that $a,d\neq 0$ I try every possible $\bar{b},\bar{c} \in F_{q^2}$, so I list $\Theta(q^4)$ elements. Then I handle the cases where $a$ or $d$ are $0$. I have tried other row operations, but still can't enumerate the elements of $G$ without repetitions.","My question about $PGL(2,q^2)$ has 2 related parts: 1) I am interested in learning about the structure of the group $G:=PGL(2,q^2)$, where $q$ is a prime power. Particularly in the cosets of $PGL(2,q)$ in $PGL(2,q^2)$. I would like it if you could recommend some introductory references to start learning about this group and these cosets. 2) I would like to be able to enumerate all $\Theta(q^3)$ distinct elements in the coset $PGL(2,q)$ in $PGL(2,q^2)$, without repetition. I have seen that there are $\Theta(q^3)$ distinct representatives (1 for each coset). My problem is that so far I haven't been able to enumerate them without repetition, so I end up doing more work by enumerating $\Theta(q^4)$ elements instead. So far my enumeration strategy goes like this: -Given an element $m_1:=\begin{pmatrix} a & b \\ c & d\end{pmatrix} \in G$, with $a,d \neq 0$, I can perform elementary row operations and transform it into the element: $m_2:=\begin{pmatrix} 1 & \bar{b} \\ \bar{c} & 1\end{pmatrix} \in G$, such that $m_1$ and $m_2$ are equivalent in G. -Under the assumption that $a,d\neq 0$ I try every possible $\bar{b},\bar{c} \in F_{q^2}$, so I list $\Theta(q^4)$ elements. Then I handle the cases where $a$ or $d$ are $0$. I have tried other row operations, but still can't enumerate the elements of $G$ without repetitions.",,"['abstract-algebra', 'group-theory', 'linear-groups']"
21,Subgroup of elements of order at most $2^{m}$,Subgroup of elements of order at most,2^{m},"The problem A5 in Putnam 2009 reads as follows: Is there a finite abelian group $G$ such that the product of the   orders of all its elements is $2^{2009}$? The answer is No . I am reading the official solution here . The solution starts by observing that if such group existed, it would be a 2-group. By structure theorem for finitely generated abelian groups, we may write $$G\cong\prod_{i=1}^{\infty} (\mathbb{Z}/2^{i}\mathbb{Z})^{e_i}$$ for some nonnegative integers $e_1, e_2, ...$ all but finitely many of which are $0$. I am having trouble understanding the step that immediately follows: For any nonnegative integer $m$, the elements of $G$ of order at most   $2^m$ form a subgroup isomorphic to  $$\prod_{i=1}^{\infty}  (\mathbb{Z}/2^{\min(i, m)}\mathbb{Z})$$ I can see that the elements of order at most $2^{m}$ forms a subgroup. But I don't see why this subgroup must be isomorphic to the group $\prod_{i=1}^{\infty}  (\mathbb{Z}/2^{\min(i, m)}\mathbb{Z})$. Can someone shed light on this matter? Perhaps even show an explicit isomorphism if possible? I appreciate any input.","The problem A5 in Putnam 2009 reads as follows: Is there a finite abelian group $G$ such that the product of the   orders of all its elements is $2^{2009}$? The answer is No . I am reading the official solution here . The solution starts by observing that if such group existed, it would be a 2-group. By structure theorem for finitely generated abelian groups, we may write $$G\cong\prod_{i=1}^{\infty} (\mathbb{Z}/2^{i}\mathbb{Z})^{e_i}$$ for some nonnegative integers $e_1, e_2, ...$ all but finitely many of which are $0$. I am having trouble understanding the step that immediately follows: For any nonnegative integer $m$, the elements of $G$ of order at most   $2^m$ form a subgroup isomorphic to  $$\prod_{i=1}^{\infty}  (\mathbb{Z}/2^{\min(i, m)}\mathbb{Z})$$ I can see that the elements of order at most $2^{m}$ forms a subgroup. But I don't see why this subgroup must be isomorphic to the group $\prod_{i=1}^{\infty}  (\mathbb{Z}/2^{\min(i, m)}\mathbb{Z})$. Can someone shed light on this matter? Perhaps even show an explicit isomorphism if possible? I appreciate any input.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'contest-math']"
22,Hilbert's 17th Problem - Artin's proof,Hilbert's 17th Problem - Artin's proof,,"In this expository article, it is mentioned that Emil Artin proved Hilbert's 17th problem in his paper: E. Artin, Uber die Zerlegung definiter Funktionen in Quadrate, Abh.   math. Sem. Hamburg 5(1927), 110–115. Not being able to speak German, my question is Does anyone know if English translation of this paper exists somewhere? Or perhaps some link to a book (or article, blog post, etc.) where this proof is given in English? My google searches have been in vain. Note that I am only interested in Artin's proof. (There is a algorithmic proof due to Dellzel, which is in English). Thanks! P.S. I have previously asked for English translation of another paper by E. Artin.","In this expository article, it is mentioned that Emil Artin proved Hilbert's 17th problem in his paper: E. Artin, Uber die Zerlegung definiter Funktionen in Quadrate, Abh.   math. Sem. Hamburg 5(1927), 110–115. Not being able to speak German, my question is Does anyone know if English translation of this paper exists somewhere? Or perhaps some link to a book (or article, blog post, etc.) where this proof is given in English? My google searches have been in vain. Note that I am only interested in Artin's proof. (There is a algorithmic proof due to Dellzel, which is in English). Thanks! P.S. I have previously asked for English translation of another paper by E. Artin.",,"['abstract-algebra', 'reference-request', 'rational-functions']"
23,"Given $G$, when can we find a division ring $R$ with $R^*=G$?","Given , when can we find a division ring  with ?",G R R^*=G,"This is motivated by a characterization of finite cyclic groups , in which one proves Let $G$ be a finite group. If $\#\{g\in G\colon g^d=e\}$ is at most $d$, then $G$ is cyclic. The proof is not actually difficult, but a unnecessarily complicated idea occurred to me (maybe because the first time I saw such a result, it was used to prove that finite subgroups of the multiplicative group of a field are cyclic). If we can construct this $G$ as the multiplicative group of a certain division ring, that is, $R^*\colon=\{r\in R\colon r\neq 1\}$. Then we know $G$ is abelian since finite division rings are commutative , and the abelian case follows from a direct use of the structure theorem of finite abelian groups . Of course such a proof is unnecessarily complicated and very likely results in some cyclic arguments since it uses two very big structure theorems. But I guess it would still be nice to know what kind of groups are multiplicative groups of division rings. Thanks very much!","This is motivated by a characterization of finite cyclic groups , in which one proves Let $G$ be a finite group. If $\#\{g\in G\colon g^d=e\}$ is at most $d$, then $G$ is cyclic. The proof is not actually difficult, but a unnecessarily complicated idea occurred to me (maybe because the first time I saw such a result, it was used to prove that finite subgroups of the multiplicative group of a field are cyclic). If we can construct this $G$ as the multiplicative group of a certain division ring, that is, $R^*\colon=\{r\in R\colon r\neq 1\}$. Then we know $G$ is abelian since finite division rings are commutative , and the abelian case follows from a direct use of the structure theorem of finite abelian groups . Of course such a proof is unnecessarily complicated and very likely results in some cyclic arguments since it uses two very big structure theorems. But I guess it would still be nice to know what kind of groups are multiplicative groups of division rings. Thanks very much!",,"['abstract-algebra', 'group-theory', 'ring-theory', 'field-theory']"
24,Calculate a galois group,Calculate a galois group,,"I am trying to calculate the galois group $\operatorname{Gal}( \mathbb{Z}_q (\vartheta_p) : \mathbb{Z}_q) $, where $p$ and $q$ are different primes, $\mathbb{Z}_q$ $q$-adic ring, $\vartheta_p$ a primitive $p$-th root of unity, but I just get, that it is embedded in $\mathbb{Z}/(p)$ and no equality. How could one solve this?","I am trying to calculate the galois group $\operatorname{Gal}( \mathbb{Z}_q (\vartheta_p) : \mathbb{Z}_q) $, where $p$ and $q$ are different primes, $\mathbb{Z}_q$ $q$-adic ring, $\vartheta_p$ a primitive $p$-th root of unity, but I just get, that it is embedded in $\mathbb{Z}/(p)$ and no equality. How could one solve this?",,"['abstract-algebra', 'galois-theory']"
25,Irreducibility over $\mathbb F_p$ - A useless hint?,Irreducibility over  - A useless hint?,\mathbb F_p,"Dummit and Foote, 13.5.5: For any prime $p$ and nonzero $a \in \mathbb F_p$ prove that $x^p-x+a$ is irreducible and separable over $\mathbb F_p$ The question goes on to suggest two approaches to proving the irreducibility (separability follows): 1. Prove first that if $\alpha$ is a root then $\alpha + 1$ is also a root. 2. Suppose it's reducible and compute the derivatives. Now I've solved the problem using the first hint, but only after trying for hours to find the contradiction given by the second approach (I'm stubborn). I'd really like to see if it is possible to get the irreducibility by that approach. Note that the derivative here is the algebraic definition rather than the analytic notion. Right away we see from the second approach, that assuming $f(x)=x^p-x+a = g(x)h(x)$ and taking the derivatives on each side $D_xf(x)= g(x)D_xh(x)+(D_xg(x))h(x)=px^{p-1} -1=-1$ I've tried comparing the coefficients of each side to no avail.","Dummit and Foote, 13.5.5: For any prime $p$ and nonzero $a \in \mathbb F_p$ prove that $x^p-x+a$ is irreducible and separable over $\mathbb F_p$ The question goes on to suggest two approaches to proving the irreducibility (separability follows): 1. Prove first that if $\alpha$ is a root then $\alpha + 1$ is also a root. 2. Suppose it's reducible and compute the derivatives. Now I've solved the problem using the first hint, but only after trying for hours to find the contradiction given by the second approach (I'm stubborn). I'd really like to see if it is possible to get the irreducibility by that approach. Note that the derivative here is the algebraic definition rather than the analytic notion. Right away we see from the second approach, that assuming $f(x)=x^p-x+a = g(x)h(x)$ and taking the derivatives on each side $D_xf(x)= g(x)D_xh(x)+(D_xg(x))h(x)=px^{p-1} -1=-1$ I've tried comparing the coefficients of each side to no avail.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
26,For which $d<0$ is $\mathbb Z[\sqrt{d}]$ an Euclidean Domain? [duplicate],For which  is  an Euclidean Domain? [duplicate],d<0 \mathbb Z[\sqrt{d}],"This question already has answers here : Why is $\mathbb{Z}[\sqrt{-n}], n\ge 3$ not a UFD? (2 answers) Closed 11 years ago . I know that for $d=-1, -2$ the ring $\mathbb Z[\sqrt{d}]$ is an Euclidean Domain. I believe that it is not an Euclidean Domain for and $d \leq-3$. I have been able to prove it for a handful of examples (like $d=-3$), showing that the resulting ring is not a UFD, but am not sure how to prove the claim in general. (And whether the resulting rings are not UFDs in the general case or merely not Euclidean.)","This question already has answers here : Why is $\mathbb{Z}[\sqrt{-n}], n\ge 3$ not a UFD? (2 answers) Closed 11 years ago . I know that for $d=-1, -2$ the ring $\mathbb Z[\sqrt{d}]$ is an Euclidean Domain. I believe that it is not an Euclidean Domain for and $d \leq-3$. I have been able to prove it for a handful of examples (like $d=-3$), showing that the resulting ring is not a UFD, but am not sure how to prove the claim in general. (And whether the resulting rings are not UFDs in the general case or merely not Euclidean.)",,"['abstract-algebra', 'ring-theory']"
27,When is intersection of infinitely many maximal ideals zero?,When is intersection of infinitely many maximal ideals zero?,,"I've been trying without success to figure out what are the rings $R$ such that whenever $M_n, n \in \omega$ is a countably infinite collection of pairwise distinct maximal ideals then $\bigcap_{n \in \omega}M_n=0$. If $R$ is a Dedekind domain then this obviously holds, and if $R$ has this property and has infinitely many maximal ideals then it has to have zero radical. Thanks for any input or hint.","I've been trying without success to figure out what are the rings $R$ such that whenever $M_n, n \in \omega$ is a countably infinite collection of pairwise distinct maximal ideals then $\bigcap_{n \in \omega}M_n=0$. If $R$ is a Dedekind domain then this obviously holds, and if $R$ has this property and has infinitely many maximal ideals then it has to have zero radical. Thanks for any input or hint.",,"['abstract-algebra', 'ring-theory', 'ideals']"
28,"Automorphisms of $k[x_1,x_2,\dots,x_n]$ that fix $k$",Automorphisms of  that fix,"k[x_1,x_2,\dots,x_n] k","Given a field $k$, consider the polynomial ring $k[x_1,x_2,\dots,x_n]$. Is it possible to find all the automorphisms of this ring that fix the field $k$?","Given a field $k$, consider the polynomial ring $k[x_1,x_2,\dots,x_n]$. Is it possible to find all the automorphisms of this ring that fix the field $k$?",,"['abstract-algebra', 'commutative-algebra', 'polynomials']"
29,Dedekind modular law,Dedekind modular law,,"Dedekind modular law. If $A,B,C$ are subgroups of a group $G$ with $A \subseteq B$ then $A(B \cap C) = B \cap AC$. Below is what I want to prove. Let K be a finite group with $K = LH$, where $L,H$ are subgroups of $K$ with relatively prime orders. If $U$ is a maximal subgroup of $L$ then $UH = HU$. Proof: $HU = HU \cap LH = (HU \cap L)H = (H \cap L)UH = UH$ Is my proof true?","Dedekind modular law. If $A,B,C$ are subgroups of a group $G$ with $A \subseteq B$ then $A(B \cap C) = B \cap AC$. Below is what I want to prove. Let K be a finite group with $K = LH$, where $L,H$ are subgroups of $K$ with relatively prime orders. If $U$ is a maximal subgroup of $L$ then $UH = HU$. Proof: $HU = HU \cap LH = (HU \cap L)H = (H \cap L)UH = UH$ Is my proof true?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
30,Derivations and separability of field extensions,Derivations and separability of field extensions,,"This is written on page 4 of James E. Humphreys' Linear Algebraic Groups : A derivation $\delta: E \rightarrow L$ ($E$ a field, $L$ an extension field of $E$), is a map which satisfies $\delta(x+y) = \delta(x)+\delta(y)$ and $\delta(xy)=x \delta(y)+ \delta(x)y$. If $F$ is a subfield of $E$, $\delta$ is called an $F$-derivation if in addition $\delta(x)=0$ for all $x \in F$ (so $\delta$ is $F$-linear). Then the author said: The space $\operatorname{Der}_F(E,L)$ of all $F$-derivations $E \rightarrow L$ is a vector space over $L$, whose dimension equals the transcendence degree of $E$ over $F$ if $E/F$ is separably generated. $E/F$ is separable if and only if all derivations $F \rightarrow L$ extend to derivations $E \rightarrow L$ ($L$ an extension field of $E$). I am confused by the last statement. Let $F = F_5 = \{0,1,2,3,4 \} $, the field of $5$ elements, and $E$ the splitting field of $x^5 -2$ over $F$. For any extension field $L$ of $E$, any derivation $\delta: F \rightarrow L$ must be the zero map (because of the two conditions). So the zero map from $E$ to $L$ is the extension of $\delta$ to $E$. But, $E/F$ is obviously inseparable. Where am I wrong? Are there any references or hints as to the proof of the statement? Sincere thanks. I was wrong because $F$ is perfect and the extension is trivial. Now, please allow me to ask for some references or hints as to the proof of: $E/F$ is separable if and only if all derivations $F\rightarrow L$ extend to derivations $E\rightarrow L$, where $L$ is an extension field of $E$.","This is written on page 4 of James E. Humphreys' Linear Algebraic Groups : A derivation $\delta: E \rightarrow L$ ($E$ a field, $L$ an extension field of $E$), is a map which satisfies $\delta(x+y) = \delta(x)+\delta(y)$ and $\delta(xy)=x \delta(y)+ \delta(x)y$. If $F$ is a subfield of $E$, $\delta$ is called an $F$-derivation if in addition $\delta(x)=0$ for all $x \in F$ (so $\delta$ is $F$-linear). Then the author said: The space $\operatorname{Der}_F(E,L)$ of all $F$-derivations $E \rightarrow L$ is a vector space over $L$, whose dimension equals the transcendence degree of $E$ over $F$ if $E/F$ is separably generated. $E/F$ is separable if and only if all derivations $F \rightarrow L$ extend to derivations $E \rightarrow L$ ($L$ an extension field of $E$). I am confused by the last statement. Let $F = F_5 = \{0,1,2,3,4 \} $, the field of $5$ elements, and $E$ the splitting field of $x^5 -2$ over $F$. For any extension field $L$ of $E$, any derivation $\delta: F \rightarrow L$ must be the zero map (because of the two conditions). So the zero map from $E$ to $L$ is the extension of $\delta$ to $E$. But, $E/F$ is obviously inseparable. Where am I wrong? Are there any references or hints as to the proof of the statement? Sincere thanks. I was wrong because $F$ is perfect and the extension is trivial. Now, please allow me to ask for some references or hints as to the proof of: $E/F$ is separable if and only if all derivations $F\rightarrow L$ extend to derivations $E\rightarrow L$, where $L$ is an extension field of $E$.",,"['abstract-algebra', 'galois-theory']"
31,An application of Eisenstein's criterion,An application of Eisenstein's criterion,,"So, this is Hungerford problem 9 on page 166. Here's the problem in full: Let $f(x) = \sum_{i=0}^n a_i x^i \in \mathbb{Z}[x]$. Suppose that for some $k$, $0 < k < n$, and some prime $p$ such that $p \nmid a_n$, $p \nmid a_k$, and $p \mid a_i$ for all $i = 0, \dots, k-1$, but $p^2 \nmid a_0$. Show that $f$ has a factor of degree at least $k$ that is irreducible in $\mathbb{Z}[x]$. Here's my progress: If we construct a new polynomial $g$ where $g$ is $\sum_{i=0}^k a_i x^i$ , we know by Eisenstein's criterion that $g$ is irreducible in $\mathbb{Q}[x]$. If we somehow knew that $g$ was irreducible in $\mathbb{Z}[x]$ too (that would follow if $g$ were primitive), then we could say that the smallest thing we could possibly factor out of $f$ that isn't a unit has to be of degree $k$ and that $g$ must be a factor of it. I tried writing $f$ as $C(f) \cdot f_1$ where $C(f)$ is the content of $f$, so that we'd be dealing with a primitive $f_1$ (and of course, the nice things about $g$ don't go away since $p$ doesn't divide every term), but this doesn't necessarily result in $g$ being primitive (right?)! So, here's where I'm stuck: how can I show I can even factor $f$? How can I show that $g$ is irreducible in $\mathbb{Z}[x]$, whether by showing it's primitive or by some other means? Thanks so much, everyone!","So, this is Hungerford problem 9 on page 166. Here's the problem in full: Let $f(x) = \sum_{i=0}^n a_i x^i \in \mathbb{Z}[x]$. Suppose that for some $k$, $0 < k < n$, and some prime $p$ such that $p \nmid a_n$, $p \nmid a_k$, and $p \mid a_i$ for all $i = 0, \dots, k-1$, but $p^2 \nmid a_0$. Show that $f$ has a factor of degree at least $k$ that is irreducible in $\mathbb{Z}[x]$. Here's my progress: If we construct a new polynomial $g$ where $g$ is $\sum_{i=0}^k a_i x^i$ , we know by Eisenstein's criterion that $g$ is irreducible in $\mathbb{Q}[x]$. If we somehow knew that $g$ was irreducible in $\mathbb{Z}[x]$ too (that would follow if $g$ were primitive), then we could say that the smallest thing we could possibly factor out of $f$ that isn't a unit has to be of degree $k$ and that $g$ must be a factor of it. I tried writing $f$ as $C(f) \cdot f_1$ where $C(f)$ is the content of $f$, so that we'd be dealing with a primitive $f_1$ (and of course, the nice things about $g$ don't go away since $p$ doesn't divide every term), but this doesn't necessarily result in $g$ being primitive (right?)! So, here's where I'm stuck: how can I show I can even factor $f$? How can I show that $g$ is irreducible in $\mathbb{Z}[x]$, whether by showing it's primitive or by some other means? Thanks so much, everyone!",,"['abstract-algebra', 'polynomials']"
32,A question concerning polynomial solvable by radicals,A question concerning polynomial solvable by radicals,,"We know from Galois Theory that a polynomial is solvable by radicals if and only if its Galois group is solvable. On the other hand solvable by radicals for example means that the equation $X^n-1=0$ is always solvable by radicals (its Galois group is abelian), but this only means that we can find a solution by saying it is $1^{1/n}$, which is a radical. As for $n\le 6$ we can find its solution in the form $a+ib$ where $a,b$ are representable by real radicals. I guess this is not always possible for larger $n$. (I can see how it could be up to $n\le10$, but any higher?) Is there a theory concerning this kind of problem (whether a polynomial can be solved by ""real radicals"")?","We know from Galois Theory that a polynomial is solvable by radicals if and only if its Galois group is solvable. On the other hand solvable by radicals for example means that the equation $X^n-1=0$ is always solvable by radicals (its Galois group is abelian), but this only means that we can find a solution by saying it is $1^{1/n}$, which is a radical. As for $n\le 6$ we can find its solution in the form $a+ib$ where $a,b$ are representable by real radicals. I guess this is not always possible for larger $n$. (I can see how it could be up to $n\le10$, but any higher?) Is there a theory concerning this kind of problem (whether a polynomial can be solved by ""real radicals"")?",,"['abstract-algebra', 'galois-theory']"
33,"Are algebroids ""just matrices?""","Are algebroids ""just matrices?""",,"Algebroids are particularly interesting structures: they are basically categories enriched over $K$ -Vect for some field $K$ . This means the hom-sets are all vector spaces, and composition is ""bilinear"" in a certain sense. (Let's just focus on when $K$ is a field for now rather than an arbitrary ring.) Most examples I can think of are equivalent to some subset of matrices with the usual addition and multiplication rules, as long as we are willing to be creative and allow ""infinite matrices"" to exist. In general, for any $n$ and $m$ , the set of $n \times m$ matrices forms an algebroid. The union of any such sets also forms an algebroid, as long as matrix compositions exist when expected (meaning if we have $5 \times 4$ and $4 \times 3$ matrices, we must also have $5 \times 3$ matrices). This is also true if $n$ and $m$ are arbitrary infinite cardinals, with the caveat that only finitely many elements of each column of the matrix can be nonzero. So, we can ask if this is basically ""what algebroids are,"" in the following sense: Let's say that the category $\text{Mat}^+_K$ is basically an extension of the usual $\text{Mat}_K$ , but with the objects as all possible cardinals rather than only natural numbers. For objects $\kappa, \lambda$ , the morphisms from $\kappa \to \lambda$ are (possibly infinite) matrices of size $\kappa \times \lambda$ (treating these cardinals as initial ordinals), with finitely many nonzero coefficients in each column, taking values in $K$ . Naive Pre-Question : is every possible $K$ -algebroid equivalent to a subcategory of $\text{Mat}_K^+$ ? Now, the answer to this first question is ""no,"" because we can have, for instance, a disjoint union of $\text{Mat}_K^+$ with itself, which is a $K$ -algebroid but not equivalent to $\text{Mat}_K^+$ . This would be like having, for instance, ""red"" and ""blue"" matrices, where the product of red and blue matrices is undefined. So, to salvage the spirit of this question, we can note that $\text{Mat}_K^+$ is a skeleton category of $K$ -Vect, which has infinitely many copies of $\text{Mat}_K^+$ with all possible linear transformations (and thus isomorphisms, when they exist). So, we can get to the better question: Real Question : is every possible $K$ -algebroid equivalent to a subcategory of $\text{Vect}_K$ ?","Algebroids are particularly interesting structures: they are basically categories enriched over -Vect for some field . This means the hom-sets are all vector spaces, and composition is ""bilinear"" in a certain sense. (Let's just focus on when is a field for now rather than an arbitrary ring.) Most examples I can think of are equivalent to some subset of matrices with the usual addition and multiplication rules, as long as we are willing to be creative and allow ""infinite matrices"" to exist. In general, for any and , the set of matrices forms an algebroid. The union of any such sets also forms an algebroid, as long as matrix compositions exist when expected (meaning if we have and matrices, we must also have matrices). This is also true if and are arbitrary infinite cardinals, with the caveat that only finitely many elements of each column of the matrix can be nonzero. So, we can ask if this is basically ""what algebroids are,"" in the following sense: Let's say that the category is basically an extension of the usual , but with the objects as all possible cardinals rather than only natural numbers. For objects , the morphisms from are (possibly infinite) matrices of size (treating these cardinals as initial ordinals), with finitely many nonzero coefficients in each column, taking values in . Naive Pre-Question : is every possible -algebroid equivalent to a subcategory of ? Now, the answer to this first question is ""no,"" because we can have, for instance, a disjoint union of with itself, which is a -algebroid but not equivalent to . This would be like having, for instance, ""red"" and ""blue"" matrices, where the product of red and blue matrices is undefined. So, to salvage the spirit of this question, we can note that is a skeleton category of -Vect, which has infinitely many copies of with all possible linear transformations (and thus isomorphisms, when they exist). So, we can get to the better question: Real Question : is every possible -algebroid equivalent to a subcategory of ?","K K K n m n \times m 5 \times 4 4 \times 3 5 \times 3 n m \text{Mat}^+_K \text{Mat}_K \kappa, \lambda \kappa \to \lambda \kappa \times \lambda K K \text{Mat}_K^+ \text{Mat}_K^+ K \text{Mat}_K^+ \text{Mat}_K^+ K \text{Mat}_K^+ K \text{Vect}_K","['abstract-algebra', 'category-theory', 'enriched-category-theory']"
34,Tensor product $L \otimes_K L$ has no nilpotent elements iff $I/I^2=0$,Tensor product  has no nilpotent elements iff,L \otimes_K L I/I^2=0,"Let $L \supset K$ be  a finite extension of fields. The diagonal $L \otimes_K L$ we can endow with structure of $L$ algebra via $L \to L \otimes_K L,\ l \mapsto l \otimes 1_L$ . Especially $L \otimes_K L$ carries structure of a $L$ -module via $L$ -multiplication in first factor $l \cdot (a \otimes b) := la \otimes b$ . Let $d: L \otimes_K L \to L, a \otimes b \mapsto ab $ be the diagonal map and $I$ its kernel. I want to show that $L \otimes_K L$ is reduced (has no nilpotent elements) iff $I = I^2$ , i.e. $I/I^2=0$ . Ideas: We can simplify the problem if we choose an more accessible system of generators for $L$ -module $I/I^2$ . I claim that $a \otimes 1_L -1_L \otimes a$ for $a \in L$ generate $I/I^2$ as $L$ -module. That's because $a \otimes b = ab \otimes 1 - a \cdot (b \otimes 1 - 1 \otimes b)$ (recall $I$ carries $L$ -module structure by multiplication in first factor) and therefore for $\sum a_i \otimes b_i \in I$ we obtain by linearity $$\sum a_i \otimes b_i = (\sum a_i b_i) \otimes 1  - \sum a_i \cdot  (b_i \otimes 1 - 1 \otimes b_i)= \sum a_i \cdot  (b_i \otimes 1 - 1 \otimes b_i)$$ Therefore it suffice to show that $L \otimes_K L$ is reduced iff every $a \otimes 1 - 1 \otimes a, a \in L$ is modulo $I^2$ a product of two other such $x \otimes 1 - 1 \otimes x, y \otimes 1 - 1 \otimes y, x, y \in L$ . How can I do it? Note: If we realize that $I/I^2$ can be interpreted as module of Kahler differentials $\Omega_L$ and we use another more usual construction of $\Omega_L$ as certain quotient of some free $\bigoplus_iK[x_1,..., x_n] dx_i$ use some standard exact sequences between Kahler differentials then the claim follows immediately. But I want to know if it possible to show the claim directly(!) working only with definition of $I/I^2$ instead of making a detour over quoting results known for Kahler differntials.","Let be  a finite extension of fields. The diagonal we can endow with structure of algebra via . Especially carries structure of a -module via -multiplication in first factor . Let be the diagonal map and its kernel. I want to show that is reduced (has no nilpotent elements) iff , i.e. . Ideas: We can simplify the problem if we choose an more accessible system of generators for -module . I claim that for generate as -module. That's because (recall carries -module structure by multiplication in first factor) and therefore for we obtain by linearity Therefore it suffice to show that is reduced iff every is modulo a product of two other such . How can I do it? Note: If we realize that can be interpreted as module of Kahler differentials and we use another more usual construction of as certain quotient of some free use some standard exact sequences between Kahler differentials then the claim follows immediately. But I want to know if it possible to show the claim directly(!) working only with definition of instead of making a detour over quoting results known for Kahler differntials.","L \supset K L \otimes_K L L L \to L \otimes_K L,\ l \mapsto l \otimes 1_L L \otimes_K L L L l \cdot (a \otimes b) :=
la \otimes b d: L \otimes_K L \to L, a \otimes b \mapsto ab  I L \otimes_K L I = I^2 I/I^2=0 L I/I^2 a \otimes 1_L -1_L \otimes a a \in L I/I^2 L a \otimes b =
ab \otimes 1 - a \cdot (b \otimes 1 - 1 \otimes b) I L \sum a_i \otimes b_i \in I \sum a_i \otimes b_i =
(\sum a_i b_i) \otimes 1  - \sum a_i \cdot
 (b_i \otimes 1 - 1 \otimes b_i)= \sum a_i \cdot
 (b_i \otimes 1 - 1 \otimes b_i) L \otimes_K L a \otimes 1 - 1 \otimes a, a \in L I^2 x \otimes 1 - 1 \otimes x, y \otimes 1 - 1 \otimes y,
x, y \in L I/I^2 \Omega_L \Omega_L \bigoplus_iK[x_1,..., x_n] dx_i I/I^2","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'field-theory', 'chinese-remainder-theorem']"
35,Conjugacy classes of finite group G having size at most 4 implies G is solvable.,Conjugacy classes of finite group G having size at most 4 implies G is solvable.,,"I am stuck on the following question and am looking for help/ hints: Question: Show that if the conjugacy classes of a finite group $G$ have size at most 4, then $G$ is solvable. (I have not been able to find anything on stackexchange that is the same or a similar question). Context : This is a past paper question for an algebra preliminary exam I am studying for, not a homework question. Apologies if this is still against the rules. The sequence associated with the exam uses Dummit-Foote as the main textbook to give some idea of the level the questions are aimed at: I have not taken the sequence and did not learn solvable groups (or composition/ normal series) in undergrad, but have read the relevant parts of Dummit-Foote and Aluffi's Chapter 0 and tried some problems from there (I much prefer the style of exposition in the latter). So I'm quite new to the topic of solvable groups and not at all comfortable/ proficient with it yet. My thoughts/ attempt : I have mostly been trying to work with the derived series definition, as I didn't get very far with trying to come up with an abelian/ cyclic series for $G$ . I've showed that conjugacy classes are identified in the abelianization, but this just gives me that $|G/[G,G]| \leq$ (number of conjugacy classes of $G$ ), but the hypothesis of the question just implies that the number of conjucagy classes is at least $|G|/4$ , which is unhelpful. Abelian groups are solvable but they are their abelianization, so the only a priori bound on the number of conjugacy classes is $|G|$ , so I don't think this approach has gotten me anywhere. I am mainly stuck on firstly which characterisation of solvable groups to use, and secondly how to use the bound given in the hypothesis of the question.  I also noted that the hypothesis can be restated as: $ [ G \colon C_{G}(g) ] \leq 4 $ for any $ g \in G $ . But $C_{G}(g)$ is not a normal subgroup a priori so I can't quotient by it (it would be if its index were bounded by 2, however). Apologies for the length, this is my first post and I wanted to provide context for my level and the level the question is aimed at, as well as showing that I've thought and attempted the question (but am quite lost at the moment). I tried to follow the guidelines for asking questions as much as possible. For questions on solvable groups I am feeling a bit overwhelmed by all the different approaches one can take: derived series terminating in the identity, showing $G$ has a cyclic (or merely abelian) series, finding a solvable normal subgroup $N$ such that $G/N$ is solvable... and I always find it hard to see which approach will be most viable when starting out on a problem. At this stage I would appreciate hints etc. to point me in the right direction and get me unstuck, and not a full answer, as working out some of it on my own would be more beneficial to me. EDIT : Thanks to the helpful hint from @DerekHolt I've managed to work out the solution so will now accept answers (if none come I will type one up when I have time) so that this can be marked as answered.","I am stuck on the following question and am looking for help/ hints: Question: Show that if the conjugacy classes of a finite group have size at most 4, then is solvable. (I have not been able to find anything on stackexchange that is the same or a similar question). Context : This is a past paper question for an algebra preliminary exam I am studying for, not a homework question. Apologies if this is still against the rules. The sequence associated with the exam uses Dummit-Foote as the main textbook to give some idea of the level the questions are aimed at: I have not taken the sequence and did not learn solvable groups (or composition/ normal series) in undergrad, but have read the relevant parts of Dummit-Foote and Aluffi's Chapter 0 and tried some problems from there (I much prefer the style of exposition in the latter). So I'm quite new to the topic of solvable groups and not at all comfortable/ proficient with it yet. My thoughts/ attempt : I have mostly been trying to work with the derived series definition, as I didn't get very far with trying to come up with an abelian/ cyclic series for . I've showed that conjugacy classes are identified in the abelianization, but this just gives me that (number of conjugacy classes of ), but the hypothesis of the question just implies that the number of conjucagy classes is at least , which is unhelpful. Abelian groups are solvable but they are their abelianization, so the only a priori bound on the number of conjugacy classes is , so I don't think this approach has gotten me anywhere. I am mainly stuck on firstly which characterisation of solvable groups to use, and secondly how to use the bound given in the hypothesis of the question.  I also noted that the hypothesis can be restated as: for any . But is not a normal subgroup a priori so I can't quotient by it (it would be if its index were bounded by 2, however). Apologies for the length, this is my first post and I wanted to provide context for my level and the level the question is aimed at, as well as showing that I've thought and attempted the question (but am quite lost at the moment). I tried to follow the guidelines for asking questions as much as possible. For questions on solvable groups I am feeling a bit overwhelmed by all the different approaches one can take: derived series terminating in the identity, showing has a cyclic (or merely abelian) series, finding a solvable normal subgroup such that is solvable... and I always find it hard to see which approach will be most viable when starting out on a problem. At this stage I would appreciate hints etc. to point me in the right direction and get me unstuck, and not a full answer, as working out some of it on my own would be more beneficial to me. EDIT : Thanks to the helpful hint from @DerekHolt I've managed to work out the solution so will now accept answers (if none come I will type one up when I have time) so that this can be marked as answered.","G G G |G/[G,G]| \leq G |G|/4 |G|  [ G \colon C_{G}(g) ] \leq 4   g \in G  C_{G}(g) G N G/N","['abstract-algebra', 'group-theory', 'finite-groups', 'solvable-groups']"
36,Find the minimal polynomial of $\alpha=\sqrt{3+2\sqrt{2}}$ over $\mathbb{Q}$,Find the minimal polynomial of  over,\alpha=\sqrt{3+2\sqrt{2}} \mathbb{Q},"Question: Find the minimal polynomial of $\alpha=\sqrt{3+2\sqrt{2}}$ over $\mathbb{Q}$ Thoughts: the ""standard"" method of starting by squaring (twice) to get rid of the square roots, because I don't have a nice way of showing the resulting polynomial is irreducible.  So.. Attempt: It would be great if I could get our $\alpha$ in the form $$(a+b)^2=a^2+2ab+b^2=\sqrt{3+2\sqrt{2}}.$$ So, $$3+2\sqrt{2}=(\sqrt{2})^2+2\sqrt{2}+1=(\sqrt{2}+1)^2.$$ So, $$\alpha=\sqrt{3+2\sqrt{2}}=\sqrt{2}+1.$$ So, $$(\alpha-1)^2=2\\  \alpha^2-2\alpha+1=2\\ \alpha^2-2\alpha-1=0.$$ So let $f(x)=x^2-2x-1$ .  Since $f(x)$ is irreducible over $\mathbb{Q}$ by the Rational Roots Test (since it has degree $2$ ), $f(x)$ is monic, and $f(\alpha)=0$ , we conclude that $f(x)$ is the minimal polynomial of $\alpha$ over $\mathbb{Q}$ . Does this look okay?","Question: Find the minimal polynomial of over Thoughts: the ""standard"" method of starting by squaring (twice) to get rid of the square roots, because I don't have a nice way of showing the resulting polynomial is irreducible.  So.. Attempt: It would be great if I could get our in the form So, So, So, So let .  Since is irreducible over by the Rational Roots Test (since it has degree ), is monic, and , we conclude that is the minimal polynomial of over . Does this look okay?","\alpha=\sqrt{3+2\sqrt{2}} \mathbb{Q} \alpha (a+b)^2=a^2+2ab+b^2=\sqrt{3+2\sqrt{2}}. 3+2\sqrt{2}=(\sqrt{2})^2+2\sqrt{2}+1=(\sqrt{2}+1)^2. \alpha=\sqrt{3+2\sqrt{2}}=\sqrt{2}+1. (\alpha-1)^2=2\\
 \alpha^2-2\alpha+1=2\\
\alpha^2-2\alpha-1=0. f(x)=x^2-2x-1 f(x) \mathbb{Q} 2 f(x) f(\alpha)=0 f(x) \alpha \mathbb{Q}","['abstract-algebra', 'solution-verification', 'field-theory', 'minimal-polynomials']"
37,Two seemingly non-isomorphic elliptic curves over a finite field which have the same cardinality,Two seemingly non-isomorphic elliptic curves over a finite field which have the same cardinality,,"Let $p$ be a prime number such that $p \equiv 3 \bmod 4$ . Now consider the elliptic curves $$ E/\mathbb{F}_{p^2}: \quad y^2 = x^3 - ax \quad \text{and} \quad E'/\mathbb{F}_{p^2}: \quad y^2 = x^3 - a^{-1}x $$ where $a$ is an element generating $\mathbb{F}_{p^2}^*$ . The curve itself depends on the choice of $a$ : the curves $E$ and $E'$ are not isomorphic in general, see MAGMA code below (for my computed cases, they are all not isomorphic to each other). But what I noticed is that in every case I computed, it is $|E(\mathbb{F}_{p^2})| = |E'(\mathbb{F}_{p^2})|$ . Question : Is this a general observation or is it just mere coincidence? Below is the MAGMA code I used: for p in [ x : x in [3 .. 100] | IsPrime(x) and x mod 4 eq 3 ] do     print """";     K := GF(p^2);     a := PrimitiveElement(K);     R<x> := PolynomialRing(K);     f := x^3 - a*x;     g := x^3 - 1/a*x;     E := EllipticCurve(f);     Eprime := EllipticCurve(g);     print ""Are both curves isomorphic?"";     IsIsomorphic(E,Eprime);     print ""Do both curves have the same cardinality?"";     #E eq #Eprime; end for;","Let be a prime number such that . Now consider the elliptic curves where is an element generating . The curve itself depends on the choice of : the curves and are not isomorphic in general, see MAGMA code below (for my computed cases, they are all not isomorphic to each other). But what I noticed is that in every case I computed, it is . Question : Is this a general observation or is it just mere coincidence? Below is the MAGMA code I used: for p in [ x : x in [3 .. 100] | IsPrime(x) and x mod 4 eq 3 ] do     print """";     K := GF(p^2);     a := PrimitiveElement(K);     R<x> := PolynomialRing(K);     f := x^3 - a*x;     g := x^3 - 1/a*x;     E := EllipticCurve(f);     Eprime := EllipticCurve(g);     print ""Are both curves isomorphic?"";     IsIsomorphic(E,Eprime);     print ""Do both curves have the same cardinality?"";     #E eq #Eprime; end for;","p p \equiv 3 \bmod 4 
E/\mathbb{F}_{p^2}: \quad y^2 = x^3 - ax \quad \text{and} \quad E'/\mathbb{F}_{p^2}: \quad y^2 = x^3 - a^{-1}x
 a \mathbb{F}_{p^2}^* a E E' |E(\mathbb{F}_{p^2})| = |E'(\mathbb{F}_{p^2})|","['abstract-algebra', 'algebraic-geometry', 'algebraic-number-theory', 'finite-fields', 'elliptic-curves']"
38,$\operatorname{Spec} A$ as a colimit,as a colimit,\operatorname{Spec} A,"I was reading the lecture notes on algebraic geometry and came across with the following definition: Let $A$ be a commutative ring with unit, then $\operatorname{Spec} A$ is defined as the collection of all ring homomorphism $A\rightarrow K$ , where $K$ is some field, and where we identify two maps $f:A\rightarrow K$ and $f':A\rightarrow K'$ if there exists a field homomorphism $\alpha:K\rightarrow K'$ such that $f'=\alpha \circ f$ . And then the author went on: this is a rather categorical definition, and in fact we could rephrase it as $$\operatorname{Spec} A=\operatorname*{colim}_{K\in \mathfrak{Field}} \operatorname{Hom}_{\mathfrak{Ring}}(A,K).$$ where $\mathfrak{Field}$ is the category of fields and $\mathfrak{Ring}$ is the category of rings. I am trying to prove this but not sure if I am on the right track: Let $\mathfrak{C}$ be the subcategory of the coslice category of $\mathfrak{Ring}$ over $A$ where the objects are $f:A\rightarrow K$ and the morphisms are $\alpha: f\rightarrow f'$ such that $f'=\alpha \circ f$ . But then I don't see how to proceed from there. Is there any literature about this definition of spectrum of a ring rather than the usual definition as the set of all prime ideals of $A$ ? Thank you.","I was reading the lecture notes on algebraic geometry and came across with the following definition: Let be a commutative ring with unit, then is defined as the collection of all ring homomorphism , where is some field, and where we identify two maps and if there exists a field homomorphism such that . And then the author went on: this is a rather categorical definition, and in fact we could rephrase it as where is the category of fields and is the category of rings. I am trying to prove this but not sure if I am on the right track: Let be the subcategory of the coslice category of over where the objects are and the morphisms are such that . But then I don't see how to proceed from there. Is there any literature about this definition of spectrum of a ring rather than the usual definition as the set of all prime ideals of ? Thank you.","A \operatorname{Spec} A A\rightarrow K K f:A\rightarrow K f':A\rightarrow K' \alpha:K\rightarrow K' f'=\alpha \circ f \operatorname{Spec} A=\operatorname*{colim}_{K\in \mathfrak{Field}} \operatorname{Hom}_{\mathfrak{Ring}}(A,K). \mathfrak{Field} \mathfrak{Ring} \mathfrak{C} \mathfrak{Ring} A f:A\rightarrow K \alpha: f\rightarrow f' f'=\alpha \circ f A","['abstract-algebra', 'algebraic-geometry', 'category-theory']"
39,Mistake in paper? Subgroup of order $4$ in group of order $16$.,Mistake in paper? Subgroup of order  in group of order .,4 16,"I'm reading this proof from this article and I don't see why one argument works. In the Lemma, $n_4(G)$ is the number of elements of order $4$ in $G$ . In the first step of the induction we have a group $G$ with $|G|=16$ and $exp(G)=4$ , three maximal subgroups $A,B,C \leq G$ , s.t. $A \cap B \cap C =H$ with $|H|=4$ . Now the author says, that if $C_G(H)=G$ , then $G$ is abelian. I don't see, why this is true and I think I found a counterexample: I looked up $SmallGroup(16,3)=C_2^2 \rtimes C_4$ in which exist three maximal subgroups with intersection $H=Z(G) \cong C_2^2$ . Clearly $C_G(H)=G$ , but $G$ is not abelian. What am I missing? SmallGroup(16,3) Edit: I think the next argument is wrong aswell. If $C_G(H)\not = G$ , then $C_G(H)=A$ is indeed abelian, but its not true, that $B\cong C$ . See $SmallGroup(16,13)$ and chose $Q_8$ as a maximal subgroup. It will always lead to $(A,B,C)=(C_4 \times C_2,Q_8,D_8)$ (up to ordering). Is there any quick way to see that all groups of order $16$ contain a number of elements of order 4, that is divisible by $4$ ?","I'm reading this proof from this article and I don't see why one argument works. In the Lemma, is the number of elements of order in . In the first step of the induction we have a group with and , three maximal subgroups , s.t. with . Now the author says, that if , then is abelian. I don't see, why this is true and I think I found a counterexample: I looked up in which exist three maximal subgroups with intersection . Clearly , but is not abelian. What am I missing? SmallGroup(16,3) Edit: I think the next argument is wrong aswell. If , then is indeed abelian, but its not true, that . See and chose as a maximal subgroup. It will always lead to (up to ordering). Is there any quick way to see that all groups of order contain a number of elements of order 4, that is divisible by ?","n_4(G) 4 G G |G|=16 exp(G)=4 A,B,C \leq G A \cap B \cap C =H |H|=4 C_G(H)=G G SmallGroup(16,3)=C_2^2 \rtimes C_4 H=Z(G) \cong C_2^2 C_G(H)=G G C_G(H)\not = G C_G(H)=A B\cong C SmallGroup(16,13) Q_8 (A,B,C)=(C_4 \times C_2,Q_8,D_8) 16 4","['abstract-algebra', 'group-theory', 'finite-groups']"
40,Converse to a proposition on homogeneous polynomials,Converse to a proposition on homogeneous polynomials,,"I know that for a homogeneous polynomial $P$ , if $P(x_1, ... , x_n) = 0$ , then $P(ax_1, ..., ax_n) = 0$ for every $a$ in the field of $P$ . Is the converse of this proposition true? That is, if $P(x_1, ... , x_n) =0$ implies $P(ax_1, ..., ax_n) = 0$ for every $a$ in the field of $P$ , is $P$ homogeneous?","I know that for a homogeneous polynomial , if , then for every in the field of . Is the converse of this proposition true? That is, if implies for every in the field of , is homogeneous?","P P(x_1, ... , x_n) = 0 P(ax_1, ..., ax_n) = 0 a P P(x_1, ... , x_n) =0 P(ax_1, ..., ax_n) = 0 a P P","['abstract-algebra', 'polynomials']"
41,"Szamuely's ""Galois groups and fundamental groups"" exercise I.7","Szamuely's ""Galois groups and fundamental groups"" exercise I.7",,"I am working through the exercises in Tamás Szamuely's book ""Galois group and fundamental groups"". Exercise 7 from the first chapter is the following. Let $k$ be a field and $\bar{k}$ be a fixed algebraic closure of $k$ . Given a finite etale $k$ -algebra $A$ with a finite group $G$ acting via $k$ -algebra automorphisms on it, say it is ""Galois"" if $A^G = k$ , and $\mathrm{dim}_k(A) = |G|$ . Show that such an algebra $A$ is Galois if and only if $A \otimes_k \bar{k} \simeq \bar{k}[G]$ as a $G$ -module. I'm currently stuck at showing that if $A$ is Galois, then $A \otimes_k \bar{k} \simeq \bar{k}[G]$ as a $G$ -module. I get that they both have dimension $|G|$ as $\bar{k}$ -algebra, that the $G$ -invariants are $\bar{k}$ in both case, and that this boils down to finding a basis of the form $(x, g_1.x,\ldots,g_{n-1}.x)$ of $A \otimes_k \bar{k}$ . I know that in the case that $A$ is a finite separable extension of $k$ , then being Galois and being a normal extension is the same, and $G$ is then the Galois group of $A$ . In this case the normal basis theorem gives a slightly stronger result, i.e $A \simeq k[G]$ as a $G$ -module. I tried using this to get the general case where $A$ is a product of finite separable extensions of $k$ , but this is getting nowhere. I also tried to see if I could adapt the proof of the normal basis theorem to get this, but I couldn't as well. Any hint would be appreciated.","I am working through the exercises in Tamás Szamuely's book ""Galois group and fundamental groups"". Exercise 7 from the first chapter is the following. Let be a field and be a fixed algebraic closure of . Given a finite etale -algebra with a finite group acting via -algebra automorphisms on it, say it is ""Galois"" if , and . Show that such an algebra is Galois if and only if as a -module. I'm currently stuck at showing that if is Galois, then as a -module. I get that they both have dimension as -algebra, that the -invariants are in both case, and that this boils down to finding a basis of the form of . I know that in the case that is a finite separable extension of , then being Galois and being a normal extension is the same, and is then the Galois group of . In this case the normal basis theorem gives a slightly stronger result, i.e as a -module. I tried using this to get the general case where is a product of finite separable extensions of , but this is getting nowhere. I also tried to see if I could adapt the proof of the normal basis theorem to get this, but I couldn't as well. Any hint would be appreciated.","k \bar{k} k k A G k A^G = k \mathrm{dim}_k(A) = |G| A A \otimes_k \bar{k} \simeq \bar{k}[G] G A A \otimes_k \bar{k} \simeq \bar{k}[G] G |G| \bar{k} G \bar{k} (x, g_1.x,\ldots,g_{n-1}.x) A \otimes_k \bar{k} A k G A A \simeq k[G] G A k","['abstract-algebra', 'commutative-algebra']"
42,Algebraic closure of $k((t))$,Algebraic closure of,k((t)),"Let $k$ be an algebraic closed field of characteristic $0$ . I want to understand why the algebraic closure of the field $k((t))$ is $\underset{n\geq 1}{\bigcup k((t^{1/n}))}$ . Obviously, $\underset{n\geq 1}{\bigcup k((t^{1/n}))} \subset \overline{k((t))}$ as $x^n-t$ are irreducible over $k((t))$ . Question 1: Why for every element $\alpha \in \overline{k((t))}$ there exist a $n = n(\alpha) \in \mathbb{N}$ (<- ""the common denominator"") such that $\alpha = \sum_{r \in \mathbb{Z}} f_{r} t^{r/n}$ ? Question 2: How are the algebraic closures of $k(t)$ and $k((t))$ related?","Let be an algebraic closed field of characteristic . I want to understand why the algebraic closure of the field is . Obviously, as are irreducible over . Question 1: Why for every element there exist a (<- ""the common denominator"") such that ? Question 2: How are the algebraic closures of and related?",k 0 k((t)) \underset{n\geq 1}{\bigcup k((t^{1/n}))} \underset{n\geq 1}{\bigcup k((t^{1/n}))} \subset \overline{k((t))} x^n-t k((t)) \alpha \in \overline{k((t))} n = n(\alpha) \in \mathbb{N} \alpha = \sum_{r \in \mathbb{Z}} f_{r} t^{r/n} k(t) k((t)),['abstract-algebra']
43,Can we find a simple basis for the cokernel of this derivation?,Can we find a simple basis for the cokernel of this derivation?,,"Let $K$ be a field of characteristic zero. Let $R$ be the $K$ -algebra $K[x_0,x_1,\ldots]$ of polynomials in countably infinitely many variables. Consider the $K$ -linear derivation $\delta:R\to R$ following the Leibniz rule $\delta(ab)=\delta(a)\cdot b+a\cdot \delta(b)$ for all $a,b\in R$ as well as the rules $\delta(x_i)=x_{i+1}$ for all $i=0,1,2,\ldots$ . Can we find a nice basis (= a basis consisting of cosets of some monomials) for the cokernel $R/\delta(R)$ ? A physicist friend asked me this question. I thought about it for a while, and made the following observation. Consider a monomial $M=\prod_{j=0}^n x_j^{a_j}$ with $a_n>0$ . Then (w.r.t. the ordering where the highest appearing index dominates) the leading term of $\delta(M)$ has the form $a_n(M/x_n)x_{n+1}$ . Observe that the exponent of $x_{n+1}$ is necessarily $1$ . This lead us to make a conjecture: Let $S$ be the set of monomials $M=\prod_{j=0}^n x_j^{a_j}, a_j\in\Bbb{N}$ for all $j$ , $n=0,1,2,\ldots$ , $a_n>1$ together with all the monomials $x_0^i, i=0,1,\ldots$ . Then the cosets $p+\delta(R)$ , $p\in S$ , form a $K$ -basis of the cokernel $R/\delta(R)$ . The intuition is, of course, that the monomials with highest index exponent $a_n=1$ can be reduced modulo $\delta(K[x_0,x_1,\ldots,x_{n-1}])$ in view of the first observation. Questions. Is this conjecture true? Or (well) known in an appropriate context? Failing that, is there another easy to describe basis for the cokernel? What buzzwords should we use when searching for more information on this theme? Asking before I commence an effort to check whether the intuition holds water, and leads to a proof. The problem feels very natural, and I suspect the answer is known already.","Let be a field of characteristic zero. Let be the -algebra of polynomials in countably infinitely many variables. Consider the -linear derivation following the Leibniz rule for all as well as the rules for all . Can we find a nice basis (= a basis consisting of cosets of some monomials) for the cokernel ? A physicist friend asked me this question. I thought about it for a while, and made the following observation. Consider a monomial with . Then (w.r.t. the ordering where the highest appearing index dominates) the leading term of has the form . Observe that the exponent of is necessarily . This lead us to make a conjecture: Let be the set of monomials for all , , together with all the monomials . Then the cosets , , form a -basis of the cokernel . The intuition is, of course, that the monomials with highest index exponent can be reduced modulo in view of the first observation. Questions. Is this conjecture true? Or (well) known in an appropriate context? Failing that, is there another easy to describe basis for the cokernel? What buzzwords should we use when searching for more information on this theme? Asking before I commence an effort to check whether the intuition holds water, and leads to a proof. The problem feels very natural, and I suspect the answer is known already.","K R K K[x_0,x_1,\ldots] K \delta:R\to R \delta(ab)=\delta(a)\cdot b+a\cdot \delta(b) a,b\in R \delta(x_i)=x_{i+1} i=0,1,2,\ldots R/\delta(R) M=\prod_{j=0}^n x_j^{a_j} a_n>0 \delta(M) a_n(M/x_n)x_{n+1} x_{n+1} 1 S M=\prod_{j=0}^n x_j^{a_j}, a_j\in\Bbb{N} j n=0,1,2,\ldots a_n>1 x_0^i, i=0,1,\ldots p+\delta(R) p\in S K R/\delta(R) a_n=1 \delta(K[x_0,x_1,\ldots,x_{n-1}])","['abstract-algebra', 'differential-algebra']"
44,"Nonabelian finite $G$ such that $O(g) \subseteq Z(G)g, \forall g \in G$",Nonabelian finite  such that,"G O(g) \subseteq Z(G)g, \forall g \in G","Is there any nonabelian finite group $G$ such that: $$O(g) \subseteq Z(G)g, \forall g \in G \tag 1$$ where $O(g)$ is the orbit ""by $g$ "" of the natural action of $\operatorname{Aut}(G)$ on $G$ , namely $\sigma \cdot g := \sigma(g)$ ?","Is there any nonabelian finite group such that: where is the orbit ""by "" of the natural action of on , namely ?","G O(g) \subseteq Z(G)g, \forall g \in G \tag 1 O(g) g \operatorname{Aut}(G) G \sigma \cdot g := \sigma(g)","['abstract-algebra', 'group-theory']"
45,What familiar group is G isomorphic to?,What familiar group is G isomorphic to?,,"Let $G$ be the quotient $F_2/\langle a^4,b^4,aba^{-1}b^{-1} \rangle.$ a) What is a simplified form of $ab^8a^5b^{10}$ ? b) What is a normal form for the elements of $G$ ? c) What familiar group is G isomorphic to? My attempt: The quotient is formed by the equivalence relations: $a^4 \equiv e, b^4 \equiv e,ab \equiv ba$ a) $ab^8a^5b^{10}=ab^4b^4aa^4b^4b^4b^2=a^2b^2.$ b) the normal form of elements is $a^ib^j$ , where $0 \leq i,j\leq 3$ , since if we have degree higher than 3, we can simplify it using the relations $a^4 \equiv e, b^4 \equiv e,ab \equiv ba.$ c) since there are 4 possible choices for $i$ and $j$ , I suppose it's isomorphic to $\mathbb Z_4 \times \mathbb Z_4.$ But I don't know how to formally prove that... How to define an mapping $\phi:G\rightarrow \mathbb Z_4 \times \mathbb Z_4$ and prove that it is actually isomorphism Can somebody check my attempt and help me out with part c)? Thanks in advance.","Let be the quotient a) What is a simplified form of ? b) What is a normal form for the elements of ? c) What familiar group is G isomorphic to? My attempt: The quotient is formed by the equivalence relations: a) b) the normal form of elements is , where , since if we have degree higher than 3, we can simplify it using the relations c) since there are 4 possible choices for and , I suppose it's isomorphic to But I don't know how to formally prove that... How to define an mapping and prove that it is actually isomorphism Can somebody check my attempt and help me out with part c)? Thanks in advance.","G F_2/\langle a^4,b^4,aba^{-1}b^{-1} \rangle. ab^8a^5b^{10} G a^4 \equiv e, b^4 \equiv e,ab \equiv ba ab^8a^5b^{10}=ab^4b^4aa^4b^4b^4b^2=a^2b^2. a^ib^j 0 \leq i,j\leq 3 a^4 \equiv e, b^4 \equiv e,ab \equiv ba. i j \mathbb Z_4 \times \mathbb Z_4. \phi:G\rightarrow \mathbb Z_4 \times \mathbb Z_4",['abstract-algebra']
46,Group where for each $d \ \big|\ |G|$ there is unique subgroup of order $d$,Group where for each  there is unique subgroup of order,d \ \big|\ |G| d,"Let $(G,\cdot)$ be a finite group with $\Bbb N \ni n\ge 2$ elements. Prove that if for every divisor $d$ of $n$ there is a unique subgroup of $G$ which has $d$ elements, then $(G,\cdot)$ is a cyclic group. Solution : Consider the sets $M_d=\{a\in G| \operatorname{ord} a=d\}$ . Any two of these sets are disjoint and they form a partition of $G$ . We have $M_d \neq \emptyset \iff \exists$ a cyclic subgroup of $G$ of order $d$ . Let's denote this subgroup by $H_d$ . According to the hypothesis, $H_d$ is the unique subgroup of order $d$ of $G$ . $\implies M_d=\{a \in G \mid \langle a\rangle=H_d\}$ , so $|M_d|=\phi(d)$ . We have that $n=\sum\limits_{d|n}|M_d|=\sum\limits_{d|n}\phi(d)$ , which is true, so there will exist a cyclic subgroup of $G$ of order $n$ . Hence, $(G,\cdot)$ is cyclic. I came up with this solution after I read the solution of a similar problem and I tried to use the same reasoning to solve this problem. I think that the reasoning itself is sound, but I feel that there may be a few issues with my solution. I am basically assuming that none of the sets $M_d$ is empty and I don't think that is correct. Intuitively, it is , because the sets $M_d$ form a partition of $G$ and if one of them is empty, then they no longer form a partition. But I don't think that it is necessary for them to form a partition, so one of them may as well be empty and, as a result, my reasoning is flawed. A friend suggested that I should just change $|M_d|=\phi(d)$ to $|M_d|\le \phi(d)$ (which is obviously true) and then I would have that $n=\sum\limits_{d|n}|M_d| \le \sum\limits_{d|n}\phi(d)=n$ , which would imply that every set $M_d$ is not empty, so $H_d$ exists and the desired conclusion is reached. To me, this seems true, but I would like to know if it really is and if there are any other better ways to repair the flaw in my solution. Edit: Is it possible that I may not actually be assuming that $M_d$ is non-empty? What I mean is : it is true that $M_d=\{a \in G \mid \langle a\rangle=H_d\}$ (it is true because if there are to be elements of order $d$ , then they will be a generator of that cyclic subgroup of order $d$ ).From here I get that $|M_d|=\phi(d)$ , so since the sets $M_d$ form a partition I reach the equality $n=\sum\limits_{d|n}|M_d|=\sum\limits_{d|n}\phi(d)$ , which is true, so from here I would get that every $M_d$ is non-empty and the conclusion would follow. Does this work?","Let be a finite group with elements. Prove that if for every divisor of there is a unique subgroup of which has elements, then is a cyclic group. Solution : Consider the sets . Any two of these sets are disjoint and they form a partition of . We have a cyclic subgroup of of order . Let's denote this subgroup by . According to the hypothesis, is the unique subgroup of order of . , so . We have that , which is true, so there will exist a cyclic subgroup of of order . Hence, is cyclic. I came up with this solution after I read the solution of a similar problem and I tried to use the same reasoning to solve this problem. I think that the reasoning itself is sound, but I feel that there may be a few issues with my solution. I am basically assuming that none of the sets is empty and I don't think that is correct. Intuitively, it is , because the sets form a partition of and if one of them is empty, then they no longer form a partition. But I don't think that it is necessary for them to form a partition, so one of them may as well be empty and, as a result, my reasoning is flawed. A friend suggested that I should just change to (which is obviously true) and then I would have that , which would imply that every set is not empty, so exists and the desired conclusion is reached. To me, this seems true, but I would like to know if it really is and if there are any other better ways to repair the flaw in my solution. Edit: Is it possible that I may not actually be assuming that is non-empty? What I mean is : it is true that (it is true because if there are to be elements of order , then they will be a generator of that cyclic subgroup of order ).From here I get that , so since the sets form a partition I reach the equality , which is true, so from here I would get that every is non-empty and the conclusion would follow. Does this work?","(G,\cdot) \Bbb N \ni n\ge 2 d n G d (G,\cdot) M_d=\{a\in G| \operatorname{ord} a=d\} G M_d \neq \emptyset \iff \exists G d H_d H_d d G \implies M_d=\{a \in G \mid \langle a\rangle=H_d\} |M_d|=\phi(d) n=\sum\limits_{d|n}|M_d|=\sum\limits_{d|n}\phi(d) G n (G,\cdot) M_d M_d G |M_d|=\phi(d) |M_d|\le \phi(d) n=\sum\limits_{d|n}|M_d| \le \sum\limits_{d|n}\phi(d)=n M_d H_d M_d M_d=\{a \in G \mid \langle a\rangle=H_d\} d d |M_d|=\phi(d) M_d n=\sum\limits_{d|n}|M_d|=\sum\limits_{d|n}\phi(d) M_d","['abstract-algebra', 'group-theory', 'proof-verification', 'finite-groups']"
47,A question about groups of order $504=2^3\cdot 3^2 \cdot 7$,A question about groups of order,504=2^3\cdot 3^2 \cdot 7,"I was looking at past qualifying exams in algebra and came across the following problem which I can't solve. The problem asks to show that if a group $G$ of order $504=2^3\cdot 3^2 \cdot 7$ has a normal subgroup of order $2^3$ , then it has at most $8$ Sylow $7$ -subgroups. Applying the Sylow theorems gives that the number of Sylow $7$ -subgroups is either $1$ , $8$ , or $36$ . So we only need to exclude the last possibility. If $P$ is a  Sylow $7$ -subgroup of $G$ and if $G$ has $36$ Sylow $7$ -subgroups, then $N_G(P)$ has order $14$ . I don't see what to do with that information though. Any help would be appreciated.","I was looking at past qualifying exams in algebra and came across the following problem which I can't solve. The problem asks to show that if a group of order has a normal subgroup of order , then it has at most Sylow -subgroups. Applying the Sylow theorems gives that the number of Sylow -subgroups is either , , or . So we only need to exclude the last possibility. If is a  Sylow -subgroup of and if has Sylow -subgroups, then has order . I don't see what to do with that information though. Any help would be appreciated.",G 504=2^3\cdot 3^2 \cdot 7 2^3 8 7 7 1 8 36 P 7 G G 36 7 N_G(P) 14,"['abstract-algebra', 'group-theory']"
48,Inverse image ideal sheaf and pullback of ideal sheaf,Inverse image ideal sheaf and pullback of ideal sheaf,,"Assume that we are given a morphism $m: X\to Y$ of varieties and that $I\subset O_Y$ is an ideal sheaf defining some subscheme $T\subset Y$ . Then we have two objects on $X$ associated to $I$ . The one is $m^{-1}I\cdot O_X$ , the other is $m^*I=m^{-1}I\otimes O_X$ . From the inclusion $i: I\to O_Y$ we get $m^*i: m^*I\to m^*O_Y=O_X$ and I found the statement that $m^{-1}I\cdot O_X=(m^*i)(m^*I)$ . Now there are some questions occurring to me. Relation between the subscheme defined by $T$ and those defined by $m^{-1}I\cdot O_X.$ Let me denote the subscheme of $X$ defined by $m^{-1}I\cdot O_X$ by $S$ . Now, if $I_T=\langle f_1,\dots,f_n\rangle$ , is $I_S=\langle m^*f_1,\dots, m^*f_n\rangle$ ? It seems that this should rather be $m^*I_T$ but how does $m^{-1}I\cdot O_X$ then look like? Why is $m^*I$ not necessarily a subsheaf of $O_X$ ? I know the short answer is that it is because of non-exactness of the tensor product but its hard for me to find an explicit example. This maybe has to do with me not understanding the previous question to well, i.e. not understanding how $m^{-1}I\cdot O_X$ looks like. If $m^{-1}T=S$ , does $m^{-1}I_T\cdot O_X=I_S$ follow? By $I_S$ I mean the ideal sheaf defining $S$ and by $I_T$ I mean the ideal sheaf defining $T=m^{-1}S$ . Since it is an ideal sheaf, the preimage of the ideal defining $T$ would then be the ideal defining $T$ and it looks like this should then give the statement on the ideal sheaves but I am unable to write down a proof.","Assume that we are given a morphism of varieties and that is an ideal sheaf defining some subscheme . Then we have two objects on associated to . The one is , the other is . From the inclusion we get and I found the statement that . Now there are some questions occurring to me. Relation between the subscheme defined by and those defined by Let me denote the subscheme of defined by by . Now, if , is ? It seems that this should rather be but how does then look like? Why is not necessarily a subsheaf of ? I know the short answer is that it is because of non-exactness of the tensor product but its hard for me to find an explicit example. This maybe has to do with me not understanding the previous question to well, i.e. not understanding how looks like. If , does follow? By I mean the ideal sheaf defining and by I mean the ideal sheaf defining . Since it is an ideal sheaf, the preimage of the ideal defining would then be the ideal defining and it looks like this should then give the statement on the ideal sheaves but I am unable to write down a proof.","m: X\to Y I\subset O_Y T\subset Y X I m^{-1}I\cdot O_X m^*I=m^{-1}I\otimes O_X i: I\to O_Y m^*i: m^*I\to m^*O_Y=O_X m^{-1}I\cdot O_X=(m^*i)(m^*I) T m^{-1}I\cdot O_X. X m^{-1}I\cdot O_X S I_T=\langle f_1,\dots,f_n\rangle I_S=\langle m^*f_1,\dots, m^*f_n\rangle m^*I_T m^{-1}I\cdot O_X m^*I O_X m^{-1}I\cdot O_X m^{-1}T=S m^{-1}I_T\cdot O_X=I_S I_S S I_T T=m^{-1}S T T","['abstract-algebra', 'algebraic-geometry', 'sheaf-theory']"
49,Error in Algebraic Curves by Fulton?,Error in Algebraic Curves by Fulton?,,"The following lemma is from section 3.3 of Fulton's algebraic curves. Notation: $\psi$ is a map from $k[X,Y]/I^n×k[X,Y]/I^m$ to $k[X,Y]/I^{m+n}$ I'm having some difficulty understanding the paragraph marked in yellow. Should it be $r<n$ or $s<m$ instead? Otherwise, how does it follow that $r+m=s+n$ and $A_rF_m=-B_sG_n$ ? I realize that this must have something to do with the degree of $A_rF_m$ or $B_sG_n$ being less than $m+n$ , but it seems to me as though this doesn't follow from the premise $r<m$ or $s<n$ (although replacing or with and seems to suffice ).","The following lemma is from section 3.3 of Fulton's algebraic curves. Notation: is a map from to I'm having some difficulty understanding the paragraph marked in yellow. Should it be or instead? Otherwise, how does it follow that and ? I realize that this must have something to do with the degree of or being less than , but it seems to me as though this doesn't follow from the premise or (although replacing or with and seems to suffice ).","\psi k[X,Y]/I^n×k[X,Y]/I^m k[X,Y]/I^{m+n} r<n s<m r+m=s+n A_rF_m=-B_sG_n A_rF_m B_sG_n m+n r<m s<n","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'algebraic-curves']"
50,Proof of $G$ is solvable implies $G/N$ is solvable.,Proof of  is solvable implies  is solvable.,G G/N,"I want to show that if $N$ is normal in $G$ then $G$ is solvable implies $G/N$ is solvable. Now, $G$ is solvable implies there exists a chain $\{e\}=G_0 \trianglelefteq G_1 \trianglelefteq G_2 \trianglelefteq G_3 \cdots \trianglelefteq G_s=G $ , such that $G_i\trianglelefteq G_{i+1}$ and $G_{i+1}/G_i$ is abelian. We can consider the chain $\overline{N} =G_0N/N \trianglelefteq G_1N/N \trianglelefteq G_2/N \trianglelefteq G_3N/N \cdots \trianglelefteq G_sN/N=G/N $ I want to show that 1. $G_iN/N \trianglelefteq G_{i+1}N/N $ which is equivalent to showing $G_iN\trianglelefteq G_{i+1}N$ 2. and $\frac{G_{i+1}N/N} { G_{i}N/N }$ which is isomorphic to $\frac{G_{i+1}N}{G_iN}$ is abelian . With a lot of brut force somehow I can prove the first part. But I am unable to prove the second part. Can someone suggest me an elegant proof of (1) and any proof of (2)? I am including a proof of (1) which I have done","I want to show that if is normal in then is solvable implies is solvable. Now, is solvable implies there exists a chain , such that and is abelian. We can consider the chain I want to show that 1. which is equivalent to showing 2. and which is isomorphic to is abelian . With a lot of brut force somehow I can prove the first part. But I am unable to prove the second part. Can someone suggest me an elegant proof of (1) and any proof of (2)? I am including a proof of (1) which I have done",N G G G/N G \{e\}=G_0 \trianglelefteq G_1 \trianglelefteq G_2 \trianglelefteq G_3 \cdots \trianglelefteq G_s=G  G_i\trianglelefteq G_{i+1} G_{i+1}/G_i \overline{N} =G_0N/N \trianglelefteq G_1N/N \trianglelefteq G_2/N \trianglelefteq G_3N/N \cdots \trianglelefteq G_sN/N=G/N  G_iN/N \trianglelefteq G_{i+1}N/N  G_iN\trianglelefteq G_{i+1}N \frac{G_{i+1}N/N} { G_{i}N/N } \frac{G_{i+1}N}{G_iN},"['abstract-algebra', 'group-theory', 'solvable-groups', 'quotient-group']"
51,Iterated function 'periodicity',Iterated function 'periodicity',,"Note: $f^n$ denotes the iteration of composition, e.g. $f^3(x)=(f\circ f\circ f)(x)$ I've noticed that particular functions have a certain property where for some number $n$ the iterations of the function cycle through a set of values so that $f^{m+n}(x)=f^m(x)$ for all $m\in\mathbb{N}$ . For example, if $f(x)=1-\frac{1}{x}$ : $$f^1(x)=1-\frac{1}{x}$$ $$f^2(x)=1-\frac{1}{1-\frac{1}{x}}=\frac{1}{1-x}$$ $$f^3(x)=1-\frac{1}{1-\frac{1}{1-\frac{1}{x}}}=x$$ $$f^4(x)=1-\frac{1}{x}$$ So the cycle has a  period of $n=3$ . Is there a name for this property, and where can I find more information? Also, are there any cases where the 'period' $n$ varies as a function of the iterate $m$ ? Edit: As others have pointed to in the comments, the property I am describing can be stated succinctly by $F^n(X)=X$ * for some $n$ , and can apply to functions as well as operators on functions. Since this extends rather naturally to integer $n$ , idempotence and involution would be examples with periods $1$ and $2$ , respectively. If matrix multiplication is used to represent the composition of functions, then the property in question applies to any $M$ such that $M^n=\pm I$ for some $n$ . As Will Jagy pointed out, in the example $f(x)=1-\frac{1}{x}$ , $M^3=-I$ is given by the Moebius transformation $f(x)=\frac{x-1}{x+0}$ . Given how incredibly general this property is and the number of things to which it applies there is absolutely no way that I am the first person to notice it. There has to be a book or a paper somewhere, right? *In retrospect, this should have been apparent given that $f^{m+n}=f^m\implies f^n=f^0$ ""Corollary""? If $$\frac{d^nf(x)}{dx^n}=f(x)$$ for some $n\in\mathbb{Z},n\neq0$ , then $$\frac{d^{mn}f(x)}{dx^{mn}}=f(x)$$ and $$\int^{m(n-1)}f(x)\ dx^{m(n-1)}=f(x)$$ for all $m\in\mathbb{Z}$","Note: denotes the iteration of composition, e.g. I've noticed that particular functions have a certain property where for some number the iterations of the function cycle through a set of values so that for all . For example, if : So the cycle has a  period of . Is there a name for this property, and where can I find more information? Also, are there any cases where the 'period' varies as a function of the iterate ? Edit: As others have pointed to in the comments, the property I am describing can be stated succinctly by * for some , and can apply to functions as well as operators on functions. Since this extends rather naturally to integer , idempotence and involution would be examples with periods and , respectively. If matrix multiplication is used to represent the composition of functions, then the property in question applies to any such that for some . As Will Jagy pointed out, in the example , is given by the Moebius transformation . Given how incredibly general this property is and the number of things to which it applies there is absolutely no way that I am the first person to notice it. There has to be a book or a paper somewhere, right? *In retrospect, this should have been apparent given that ""Corollary""? If for some , then and for all","f^n f^3(x)=(f\circ f\circ f)(x) n f^{m+n}(x)=f^m(x) m\in\mathbb{N} f(x)=1-\frac{1}{x} f^1(x)=1-\frac{1}{x} f^2(x)=1-\frac{1}{1-\frac{1}{x}}=\frac{1}{1-x} f^3(x)=1-\frac{1}{1-\frac{1}{1-\frac{1}{x}}}=x f^4(x)=1-\frac{1}{x} n=3 n m F^n(X)=X n n 1 2 M M^n=\pm I n f(x)=1-\frac{1}{x} M^3=-I f(x)=\frac{x-1}{x+0} f^{m+n}=f^m\implies f^n=f^0 \frac{d^nf(x)}{dx^n}=f(x) n\in\mathbb{Z},n\neq0 \frac{d^{mn}f(x)}{dx^{mn}}=f(x) \int^{m(n-1)}f(x)\ dx^{m(n-1)}=f(x) m\in\mathbb{Z}","['abstract-algebra', 'polynomials', 'function-and-relation-composition']"
52,Fitting subgroup of wreath product of $\Bbb Z_p$ with an infinite abelian $p$-group.,Fitting subgroup of wreath product of  with an infinite abelian -group.,\Bbb Z_p p,"Let say I have an infinite elementary abelian $p$-group $E$ (i.e. with presentation $E= \langle x_1,x_2,x_3,... \mid x_i^p=1, \  x_i x_j = x_j x_i \rangle$). How do I find the Fitting subgroup of the wreath product $G := \mathbb{Z}_p \wr E$, or more precisely, how could I prove that $\operatorname{Fitt}(G) = G$? What my thinking is, find a series of normal subgroups with increasing nilpotency class, so something like $\mathbb{Z}_p \times E$, $(\mathbb{Z}_p  \oplus \mathbb{Z}_p) \times E, \ldots$ but these don't seem to be normal in $G$ and I can't think of any better ones. Any ideas?","Let say I have an infinite elementary abelian $p$-group $E$ (i.e. with presentation $E= \langle x_1,x_2,x_3,... \mid x_i^p=1, \  x_i x_j = x_j x_i \rangle$). How do I find the Fitting subgroup of the wreath product $G := \mathbb{Z}_p \wr E$, or more precisely, how could I prove that $\operatorname{Fitt}(G) = G$? What my thinking is, find a series of normal subgroups with increasing nilpotency class, so something like $\mathbb{Z}_p \times E$, $(\mathbb{Z}_p  \oplus \mathbb{Z}_p) \times E, \ldots$ but these don't seem to be normal in $G$ and I can't think of any better ones. Any ideas?",,"['abstract-algebra', 'group-theory']"
53,Proving the number of real roots of a cubic polynomial corresponds to the discriminant using Galois Theory,Proving the number of real roots of a cubic polynomial corresponds to the discriminant using Galois Theory,,"I want to prove that a cubic polynomial $f$ with real coefficients has 3 real roots iff  $\Delta(f) > 0$ and $f$ has 1 real root iff $\Delta(f) <0$. I was able to do this by just multiplying out the discriminant, but my professor says there is also a way to do this using $\operatorname{Gal}_\mathbb{R}(f)$.  How would that work?","I want to prove that a cubic polynomial $f$ with real coefficients has 3 real roots iff  $\Delta(f) > 0$ and $f$ has 1 real root iff $\Delta(f) <0$. I was able to do this by just multiplying out the discriminant, but my professor says there is also a way to do this using $\operatorname{Gal}_\mathbb{R}(f)$.  How would that work?",,"['abstract-algebra', 'galois-theory']"
54,Why is the commutator subgroup of the group associated to a finite quandle finitely generated?,Why is the commutator subgroup of the group associated to a finite quandle finitely generated?,,"A quandle $Q$ is a set with one binary operation $(x, y) \mapsto  x ∗ y$ which satisfies the following three axioms: i) $\forall x \in Q: x ∗ x=x$ ii) the map $S_{x}: y \mapsto y ∗ x$ is a bijection on $Q$ for all $x \in Q$ iii)$(x∗ y)∗ z=(x∗ z)∗ (y∗ z)$ for all $x,y,z \in Q$ Given a quandle $(Q,∗)$, denote by $G_{Q}$ the group generated by all the elements of $Q$ and the set of relations $x ∗ y = y^{−1}xy$  for all $x, y \in Q$. I came across a theorem that said: let $(Q, ∗)$ be a finite quandle , then the commutator subgroup $G^{'}_{Q }$ of $G_{Q }$ is finitely generated. But why is that? I mean $G^{'}_{Q }= \langle g^{-1}h^{-1}gh|g,h \in G_Q \rangle$, but you still can generate infinitely many elements of $G_Q$ by using finitely many elements of $Q$. Can someone help me out?","A quandle $Q$ is a set with one binary operation $(x, y) \mapsto  x ∗ y$ which satisfies the following three axioms: i) $\forall x \in Q: x ∗ x=x$ ii) the map $S_{x}: y \mapsto y ∗ x$ is a bijection on $Q$ for all $x \in Q$ iii)$(x∗ y)∗ z=(x∗ z)∗ (y∗ z)$ for all $x,y,z \in Q$ Given a quandle $(Q,∗)$, denote by $G_{Q}$ the group generated by all the elements of $Q$ and the set of relations $x ∗ y = y^{−1}xy$  for all $x, y \in Q$. I came across a theorem that said: let $(Q, ∗)$ be a finite quandle , then the commutator subgroup $G^{'}_{Q }$ of $G_{Q }$ is finitely generated. But why is that? I mean $G^{'}_{Q }= \langle g^{-1}h^{-1}gh|g,h \in G_Q \rangle$, but you still can generate infinitely many elements of $G_Q$ by using finitely many elements of $Q$. Can someone help me out?",,['abstract-algebra']
55,Prove the existence of $\frac{1}{2}$ from the following axioms,Prove the existence of  from the following axioms,\frac{1}{2},"The question is how to prove that there exists an element $z$ such that $z+z = 1$ from the following axioms (assume we are talking about set $R$): A1: $x≠y$ implies $x < y$ or $x > y$; A2: $x < y$ implies not $y < x$ A3: $x < y$ implies there exists $t$ such that $x < t < y$ A4: For any two sets $S$ and $T$ which is a subset of $R$, if (any $x$ from $S$ and $y$ from $T$ implies $x < y$) then (there exists a $z$ such that for all $m$ from $S$ and $n$ from $T$, $m≠z$ and $n≠z$ implies $m < z < n$) A5: $x+(y+z)=(x+z)+y$ A6: For all $x$ and $y$, there exists $z$ such that $x = y+z$ A7: $x+z < y+t$ implies $x < y$ or $z < t$ A8: $1$ is an element of $R$ A9: $1 < 1+1$ So far following the textbook, I construct set $K$ containing all $x$ such that $x+x < 1$, and set $L$ containing all $y$ such that $1 < y+y$. Now by A4, there exists an element $z$ such that any $x$ from $K$ is smaller than or equal to $z$, and any $y$ from $L$ is larger than or equal to $z$. It is all good up to this point. Now I try to prove that z cannot belong to K nor L. Assume $z$ is an element of $K$. Then $z+z < 1$ and there exists an element $t$ such that $z+z < t < 1$ by A3. Define set $N$ containing all $p$ such that $p+p < t$. Then by A4, there exists $q$ such that any $p$ from $N$ is smaller than or equal to $q$, and any $y$ from $L$ is larger than or equal to $q$. But now I have trouble proving that $q ≠ z$. If $q ≠ z$ then the contradiction is immediate. For anyone wondering, the textbook is ""Introduction to Logic and the Methodology of the Deductive Sciences,"" by none other than A. Tarski himself. Chapter 10, exercise 5.","The question is how to prove that there exists an element $z$ such that $z+z = 1$ from the following axioms (assume we are talking about set $R$): A1: $x≠y$ implies $x < y$ or $x > y$; A2: $x < y$ implies not $y < x$ A3: $x < y$ implies there exists $t$ such that $x < t < y$ A4: For any two sets $S$ and $T$ which is a subset of $R$, if (any $x$ from $S$ and $y$ from $T$ implies $x < y$) then (there exists a $z$ such that for all $m$ from $S$ and $n$ from $T$, $m≠z$ and $n≠z$ implies $m < z < n$) A5: $x+(y+z)=(x+z)+y$ A6: For all $x$ and $y$, there exists $z$ such that $x = y+z$ A7: $x+z < y+t$ implies $x < y$ or $z < t$ A8: $1$ is an element of $R$ A9: $1 < 1+1$ So far following the textbook, I construct set $K$ containing all $x$ such that $x+x < 1$, and set $L$ containing all $y$ such that $1 < y+y$. Now by A4, there exists an element $z$ such that any $x$ from $K$ is smaller than or equal to $z$, and any $y$ from $L$ is larger than or equal to $z$. It is all good up to this point. Now I try to prove that z cannot belong to K nor L. Assume $z$ is an element of $K$. Then $z+z < 1$ and there exists an element $t$ such that $z+z < t < 1$ by A3. Define set $N$ containing all $p$ such that $p+p < t$. Then by A4, there exists $q$ such that any $p$ from $N$ is smaller than or equal to $q$, and any $y$ from $L$ is larger than or equal to $q$. But now I have trouble proving that $q ≠ z$. If $q ≠ z$ then the contradiction is immediate. For anyone wondering, the textbook is ""Introduction to Logic and the Methodology of the Deductive Sciences,"" by none other than A. Tarski himself. Chapter 10, exercise 5.",,"['abstract-algebra', 'logic', 'proof-writing']"
56,Does $a\otimes b=0$ in $M\otimes_R N$ imply $ar=0$ or $rb=0$ for some non-zero $r\in R$?,Does  in  imply  or  for some non-zero ?,a\otimes b=0 M\otimes_R N ar=0 rb=0 r\in R,"Let $R$ be a ring and let $M$ be a right $R$-module and $N$ be a left $R$-module. Then $M\otimes_R N$ is the tensor product over $R$. Consider $a\in M$ and $b\in N$ such that the pure tensor $a\otimes b=0$. Then I understand that this does not imply that $a=0$ or $b=0$. My question is: is there $r\in R$, $r\ne0$ such that $ar=0$ or $rb=0$? If the question is true, I want to know the proof. If not, could you give me some counterexample?","Let $R$ be a ring and let $M$ be a right $R$-module and $N$ be a left $R$-module. Then $M\otimes_R N$ is the tensor product over $R$. Consider $a\in M$ and $b\in N$ such that the pure tensor $a\otimes b=0$. Then I understand that this does not imply that $a=0$ or $b=0$. My question is: is there $r\in R$, $r\ne0$ such that $ar=0$ or $rb=0$? If the question is true, I want to know the proof. If not, could you give me some counterexample?",,['abstract-algebra']
57,infinite product of $Z$ hasn't a basis,infinite product of  hasn't a basis,Z,"I was reading this brief article (I don't know if I am allowed to post links, if don't I apologize) concerning the fact that $\prod_{i=1}^{\infty} \mathbb{Z}$ has no basis and is not a free group. The problem is just before the end of the article. When he says that the last equation has solutions for $n=n_1,n_2, \dots$, shouldn't he stop at $n_i$? Then how can he conclude using the final lemma, if we have only a finite number of integers that allow a solution? (that is exacly what the lemma is saying, and so I shouldn't get an absurd). Probably I am getting something wrong, but I can't figure out where my mistake is. Thanks for the help.","I was reading this brief article (I don't know if I am allowed to post links, if don't I apologize) concerning the fact that $\prod_{i=1}^{\infty} \mathbb{Z}$ has no basis and is not a free group. The problem is just before the end of the article. When he says that the last equation has solutions for $n=n_1,n_2, \dots$, shouldn't he stop at $n_i$? Then how can he conclude using the final lemma, if we have only a finite number of integers that allow a solution? (that is exacly what the lemma is saying, and so I shouldn't get an absurd). Probably I am getting something wrong, but I can't figure out where my mistake is. Thanks for the help.",,"['abstract-algebra', 'group-theory', 'free-groups']"
58,"Proving $x\in\text{SL}(n,\mathbb Q)$ given finite indices of $x^{-1}Gx$ in $G$ and $x^{-1}Gx$",Proving  given finite indices of  in  and,"x\in\text{SL}(n,\mathbb Q) x^{-1}Gx G x^{-1}Gx","Denote $G=\text{SL}(n,\mathbb Z)$ and let $x\in \text{SL}(n,\mathbb R)$ such that $$[G:x^{-1}Gx\cap G],[x^{-1}Gx:x^{-1}Gx\cap G]<\infty.$$   Prove that $x\in\text{SL}(n,\mathbb Q)$. I know that $\text{SL}(n,\mathbb Z)$ is finitely generated but somehow I can't find how to use that to show that the entries of $x$ are all rational. The best I got is that for $n=2$, by some calculation, $x=\sqrt q M$ where $q\in\mathbb Q,M\in\text{GL}(2,\mathbb Q)$. From there I couldn't prove that $\sqrt q\in\mathbb Q$. Can I get a hint how to proceed? even for the case of $SL(2,\mathbb Z$)?","Denote $G=\text{SL}(n,\mathbb Z)$ and let $x\in \text{SL}(n,\mathbb R)$ such that $$[G:x^{-1}Gx\cap G],[x^{-1}Gx:x^{-1}Gx\cap G]<\infty.$$   Prove that $x\in\text{SL}(n,\mathbb Q)$. I know that $\text{SL}(n,\mathbb Z)$ is finitely generated but somehow I can't find how to use that to show that the entries of $x$ are all rational. The best I got is that for $n=2$, by some calculation, $x=\sqrt q M$ where $q\in\mathbb Q,M\in\text{GL}(2,\mathbb Q)$. From there I couldn't prove that $\sqrt q\in\mathbb Q$. Can I get a hint how to proceed? even for the case of $SL(2,\mathbb Z$)?",,"['abstract-algebra', 'matrices', 'group-theory', 'linear-groups']"
59,Describe all ring homomorphisms from $\mathbb{R}[T] \rightarrow \mathbb{R}[T]$,Describe all ring homomorphisms from,\mathbb{R}[T] \rightarrow \mathbb{R}[T],"One of the problems in a problem set I was given as homework in my Algebra course proposes the next problem: Describe all ring homomorphisms $\mathbb{R}[T] \rightarrow \mathbb{R}[T]$. Which of them are isomorphisms? I would like some suggestions towards the right direction, not the answer to the problem. This is what I've got so far: Given a ring homomorphism $f:\mathbb{R}[T] \rightarrow \mathbb{R}[T]$: Given an arbitrary polinomial $p(T) = a_{0} + a_{1}T + \ldots + a_nT^n$ we have that $f(p) = f(a_0) + f(a_1)f(T) + \ldots + f(a_n)f(T)^n$. So we get that $f$ is completely determined by the values it assumes on $\mathbb{R}$ and $f(T)$. So this problem may now be separated in two: Classifying all homomorphisms of the form $f:\mathbb{R} \rightarrow \mathbb{R}[T]$ Classifying all possible values $f(T)$ With respect to (1): Conjecture The only ring homomorphism is $f(x)=x$ (we put as a condition that f(1) = 1, on the definition the professor gave us, so that discards $f(x)=0$) I've shown by induction that $f(n) = n, ~\forall n\in\mathbb{N}$, then $f(m) = m, ~\forall m\in \mathbb{Z}$, then $f(q) = q, ~\forall q\in \mathbb{Q}$ but I am having problems showing that $f(\alpha) = \alpha, ~\forall \alpha \in \mathbb{Q}'$ because I don't really know if $f(\alpha) \in \mathbb{R}$. If I knew that $f(\mathbb{R}) \subset \mathbb{R}$ then I could do something like $f(\alpha) = f(\sqrt{\alpha})^2 > 0$ if $\alpha > 0$. And this would help me prove that $f(\beta) = \beta$ for all irrationals too. The only problem is that, what happens if say, $f(\alpha) = T$. Then $>$ would make no sense. I think I solved this problem but I am not sure, maybe here is where you guys can help me a little. If we suppose that $f(\alpha)$ is a polynomial with degree $n$, we can then compute $f(\alpha^\frac{1}{n+1}) = f(\alpha)^\frac{1}{n+1}$ and that would be in $\mathbb{R}[T]$ only if the degree, $n$, of $f(\alpha)$ were $0$ thus proving that indeed $f(\alpha) \in \mathbb{R}$. Is there any mistake or an easier way? Or is there any usefull comment anyone wants to make that could help me out. Thanks in advance :)","One of the problems in a problem set I was given as homework in my Algebra course proposes the next problem: Describe all ring homomorphisms $\mathbb{R}[T] \rightarrow \mathbb{R}[T]$. Which of them are isomorphisms? I would like some suggestions towards the right direction, not the answer to the problem. This is what I've got so far: Given a ring homomorphism $f:\mathbb{R}[T] \rightarrow \mathbb{R}[T]$: Given an arbitrary polinomial $p(T) = a_{0} + a_{1}T + \ldots + a_nT^n$ we have that $f(p) = f(a_0) + f(a_1)f(T) + \ldots + f(a_n)f(T)^n$. So we get that $f$ is completely determined by the values it assumes on $\mathbb{R}$ and $f(T)$. So this problem may now be separated in two: Classifying all homomorphisms of the form $f:\mathbb{R} \rightarrow \mathbb{R}[T]$ Classifying all possible values $f(T)$ With respect to (1): Conjecture The only ring homomorphism is $f(x)=x$ (we put as a condition that f(1) = 1, on the definition the professor gave us, so that discards $f(x)=0$) I've shown by induction that $f(n) = n, ~\forall n\in\mathbb{N}$, then $f(m) = m, ~\forall m\in \mathbb{Z}$, then $f(q) = q, ~\forall q\in \mathbb{Q}$ but I am having problems showing that $f(\alpha) = \alpha, ~\forall \alpha \in \mathbb{Q}'$ because I don't really know if $f(\alpha) \in \mathbb{R}$. If I knew that $f(\mathbb{R}) \subset \mathbb{R}$ then I could do something like $f(\alpha) = f(\sqrt{\alpha})^2 > 0$ if $\alpha > 0$. And this would help me prove that $f(\beta) = \beta$ for all irrationals too. The only problem is that, what happens if say, $f(\alpha) = T$. Then $>$ would make no sense. I think I solved this problem but I am not sure, maybe here is where you guys can help me a little. If we suppose that $f(\alpha)$ is a polynomial with degree $n$, we can then compute $f(\alpha^\frac{1}{n+1}) = f(\alpha)^\frac{1}{n+1}$ and that would be in $\mathbb{R}[T]$ only if the degree, $n$, of $f(\alpha)$ were $0$ thus proving that indeed $f(\alpha) \in \mathbb{R}$. Is there any mistake or an easier way? Or is there any usefull comment anyone wants to make that could help me out. Thanks in advance :)",,"['abstract-algebra', 'polynomials', 'ring-theory']"
60,"If the tensor product of algebras $A \otimes B$ is unital, both $A$ and $B$ must be unital","If the tensor product of algebras  is unital, both  and  must be unital",A \otimes B A B,"It is clear that if $A$ and $B$ are unital algebras (over a field), then the tensor product $A \otimes B$ is also unital, with the unit being $1_A \otimes 1_B$. I came across an exercise that questions about the converse statement. That is, if $A \otimes B$ is a unital non-zero algebra then $A$ and $B$ must also be unital . I started by denoting $e$ the unit of $A \otimes B$. We can write $e = \sum_{i=1}^{n} a_i \otimes b_i$, with $n$ being minimal. This minimality implies that $a_1, \cdots, a_n$ and $b_1, \cdots, b_n$ are linearly independent. If we can prove that $n = 1$, then $e = a \otimes b$ is a pure tensor. These elements $a \in A$ and $b \in B$ are the ideal candidates for units in $A$ and $B$, respectively. However, I have not been able to arrive to a contradiction if $n > 1$ using only the basic tools and computations of tensors. Since no properties from $A$ or $B$ are assumed, I do not know what other tools can be used in this generality. Note : Said exercise can be found in Introduction to Noncommutative Algebra by M. Bresar, chapter 4, page 104.","It is clear that if $A$ and $B$ are unital algebras (over a field), then the tensor product $A \otimes B$ is also unital, with the unit being $1_A \otimes 1_B$. I came across an exercise that questions about the converse statement. That is, if $A \otimes B$ is a unital non-zero algebra then $A$ and $B$ must also be unital . I started by denoting $e$ the unit of $A \otimes B$. We can write $e = \sum_{i=1}^{n} a_i \otimes b_i$, with $n$ being minimal. This minimality implies that $a_1, \cdots, a_n$ and $b_1, \cdots, b_n$ are linearly independent. If we can prove that $n = 1$, then $e = a \otimes b$ is a pure tensor. These elements $a \in A$ and $b \in B$ are the ideal candidates for units in $A$ and $B$, respectively. However, I have not been able to arrive to a contradiction if $n > 1$ using only the basic tools and computations of tensors. Since no properties from $A$ or $B$ are assumed, I do not know what other tools can be used in this generality. Note : Said exercise can be found in Introduction to Noncommutative Algebra by M. Bresar, chapter 4, page 104.",,"['abstract-algebra', 'tensor-products', 'algebras']"
61,Classify all groups of order $p^2q^2$ up to isomorphism,Classify all groups of order  up to isomorphism,p^2q^2,"Let $p,q \in \mathbb{N}$ be prime numbers with the properties $2 < p < q$  and $q - 1 , q + 1 \notin \left\langle p \right\rangle$ Classify all groups of the order $p^2q^2$ up to isomorphism. This was a question given by my algebra professor and quite frankly I am stumped. My initial thought was that this question is referring to p-Sylow subgroups and one would need to apply the Sylow-theorems. If this is true, how would you apply them? Then what does ""up to isomorphism"" exactly mean? I also thought to try and break it down and look at different possible cases. For example something like this: Since  $$q - 1 \notin \left\langle p \right\rangle \Rightarrow p \nmid q - 1 $$ $\Rightarrow \exists! $ subgroup of order $p$  $\Rightarrow \exists p - 1 $elements of order $p$ and $q-1$ elements of order $q$. But honestly I am not sure how to answer this question. I would really appreciate if someone could try and explain this to me. Thank you in advance!","Let $p,q \in \mathbb{N}$ be prime numbers with the properties $2 < p < q$  and $q - 1 , q + 1 \notin \left\langle p \right\rangle$ Classify all groups of the order $p^2q^2$ up to isomorphism. This was a question given by my algebra professor and quite frankly I am stumped. My initial thought was that this question is referring to p-Sylow subgroups and one would need to apply the Sylow-theorems. If this is true, how would you apply them? Then what does ""up to isomorphism"" exactly mean? I also thought to try and break it down and look at different possible cases. For example something like this: Since  $$q - 1 \notin \left\langle p \right\rangle \Rightarrow p \nmid q - 1 $$ $\Rightarrow \exists! $ subgroup of order $p$  $\Rightarrow \exists p - 1 $elements of order $p$ and $q-1$ elements of order $q$. But honestly I am not sure how to answer this question. I would really appreciate if someone could try and explain this to me. Thank you in advance!",,"['abstract-algebra', 'group-theory', 'sylow-theory', 'p-groups']"
62,"How to generalize ""Seven trees in one"" to labelled/colored trees?","How to generalize ""Seven trees in one"" to labelled/colored trees?",,"In the famous paper Seven trees in one , Andreas Blass showed that there is ""a particularly elementary bijection between the set $T$ of finite binary trees and the set $T^7$ of seven-tuples of such trees"". For the Haskellers, if we define data Tree = Leaf | Node Tree Tree this leads to a bijection of types iso :: Tree -> (Tree, Tree, Tree, Tree, Tree, Tree, Tree) The justification, which this paper elaborates on, stems from the fact that for the set $T$ of trees, the recursive definitions yields an isomorphism $$T \cong T^2 + 1.$$ Treating this as an equation of complex numbers , we'd get $$T = \frac 1 2 \pm \frac 1 2 i \sqrt 3$$ which is a primitive sixth root of unity, thus yielding $T^7 = T$. This fascinating isomorphism just works for trees with no information attached to the nodes, as it just operates on the structure of the tree. I would love to see how we could incorporate actual, labelled nodes though (or better: colored nodes, see comments below). What do we get if we introduced labels on the nodes (with one of $n$ possibilities)? Say data Label = A1 | ... | An data Tree = Leaf | Node Label Tree Tree Now we have an isomorphism $$T \cong 1 + nT^2$$ with complex solution $$T = \frac 1{2n}(1+i\sqrt{4n-1}).$$ E.g. for $n=2$ we had $$T = \frac 1 4 (1 \pm i\sqrt 7).$$ None of these solutions can be roots of unity for $k>1$ because of their absolute values, so some nontrivial isomorphism $T^k \cong T^\ell$ won't arise. Are there other results one can achieve? I know that this question basically amounts to asking if there is nice integral polynomial equation satisfied by the complex value for $T$ above, which means nice polynomial multiples of $nT^2-T+1$. Has there been any work done on these? Thank you for your comments I know this question , though it's way broader (and hasn't received an answer anyway).","In the famous paper Seven trees in one , Andreas Blass showed that there is ""a particularly elementary bijection between the set $T$ of finite binary trees and the set $T^7$ of seven-tuples of such trees"". For the Haskellers, if we define data Tree = Leaf | Node Tree Tree this leads to a bijection of types iso :: Tree -> (Tree, Tree, Tree, Tree, Tree, Tree, Tree) The justification, which this paper elaborates on, stems from the fact that for the set $T$ of trees, the recursive definitions yields an isomorphism $$T \cong T^2 + 1.$$ Treating this as an equation of complex numbers , we'd get $$T = \frac 1 2 \pm \frac 1 2 i \sqrt 3$$ which is a primitive sixth root of unity, thus yielding $T^7 = T$. This fascinating isomorphism just works for trees with no information attached to the nodes, as it just operates on the structure of the tree. I would love to see how we could incorporate actual, labelled nodes though (or better: colored nodes, see comments below). What do we get if we introduced labels on the nodes (with one of $n$ possibilities)? Say data Label = A1 | ... | An data Tree = Leaf | Node Label Tree Tree Now we have an isomorphism $$T \cong 1 + nT^2$$ with complex solution $$T = \frac 1{2n}(1+i\sqrt{4n-1}).$$ E.g. for $n=2$ we had $$T = \frac 1 4 (1 \pm i\sqrt 7).$$ None of these solutions can be roots of unity for $k>1$ because of their absolute values, so some nontrivial isomorphism $T^k \cong T^\ell$ won't arise. Are there other results one can achieve? I know that this question basically amounts to asking if there is nice integral polynomial equation satisfied by the complex value for $T$ above, which means nice polynomial multiples of $nT^2-T+1$. Has there been any work done on these? Thank you for your comments I know this question , though it's way broader (and hasn't received an answer anyway).",,"['abstract-algebra', 'combinatorics', 'category-theory', 'computer-science']"
63,Reference Request for Topics in Group Theory,Reference Request for Topics in Group Theory,,"I'm taking an honors-level algebra class and we're getting into group actions, Sylow subgroups and semidirect products. These topics are fairly intimidating, but the lengthier discussions in the book (Dummit and Foote) have been very helpful in bringing these topics down to earth - for example, investigating the structure of groups of order $pq$, $p^2q$, classifying all groups of order 30, etc. Seeing these ideas put to use ""in the wild"" makes them a lot more tractable. Therefore I'm looking for further reading material in this vein, i.e. substantial discussions that use many of the techniques and ideas that one would find in a solid undergraduate group theory course. Ideas I had: research papers in group theory which would be accessible to someone at my level, materials used in graduate courses, miscellaneous articles and expository writings. D&F has plenty of exercises but even more couldn't hurt. And I'm open to sources that go a little beyond what might be expected of an undergraduate.","I'm taking an honors-level algebra class and we're getting into group actions, Sylow subgroups and semidirect products. These topics are fairly intimidating, but the lengthier discussions in the book (Dummit and Foote) have been very helpful in bringing these topics down to earth - for example, investigating the structure of groups of order $pq$, $p^2q$, classifying all groups of order 30, etc. Seeing these ideas put to use ""in the wild"" makes them a lot more tractable. Therefore I'm looking for further reading material in this vein, i.e. substantial discussions that use many of the techniques and ideas that one would find in a solid undergraduate group theory course. Ideas I had: research papers in group theory which would be accessible to someone at my level, materials used in graduate courses, miscellaneous articles and expository writings. D&F has plenty of exercises but even more couldn't hurt. And I'm open to sources that go a little beyond what might be expected of an undergraduate.",,"['abstract-algebra', 'group-theory', 'reference-request', 'soft-question']"
64,"express prime as sum of squares, $p = a^2 + b^2$","express prime as sum of squares,",p = a^2 + b^2,"Espress $2017$ as sum of two squares. attempt: by Fermat's Theorem on sums of squares, the prime $p = 2017$ is the sum of two squares $2017 = a^2 + b^2$ , $a,b \in \mathbb{Z}$, if and only if $p \equiv 1 mod 4$. And The irreducible elements in the Gaussian integers $\mathbb{Z[i]}$ are as follows $(a + bi)(a - bi) $ for primes $p\in \mathbb{Z}$ with $p \equiv 1 mod 4$ (both of which have norm $p$). Then since $2017 \equiv 1 (mod 4)$ Then $2017 = a^2 + b^2$ . Notice that $\sqrt2017 $ is approximately $44.91$. So $a^2, b^2 $ will be between values $1,2^2,....,44^2$ . Then plugging different values from the above squares in  $2017 - a^2 = b^2$ we find $2017 - 44^2 = 81 = 9^2$ So $2017 = 44^2 + 9^2$. However, I found them using that approach.  But is there a way to find them without doing this approach? I dont' know how to use $p = a^2 + b^2 = (a + bi)(a - bi) $ for primes $p\in \mathbb{Z}$ with $p \equiv 1 mod 4$ (both of which have norm $p$). So $2017 = a^2 + b^2 = (a+ bi)(a - bi) $. I don't' know how I would proceed assuming I would not have found the values . Any feedback or better approach would be appreciated it.  Thank you!","Espress $2017$ as sum of two squares. attempt: by Fermat's Theorem on sums of squares, the prime $p = 2017$ is the sum of two squares $2017 = a^2 + b^2$ , $a,b \in \mathbb{Z}$, if and only if $p \equiv 1 mod 4$. And The irreducible elements in the Gaussian integers $\mathbb{Z[i]}$ are as follows $(a + bi)(a - bi) $ for primes $p\in \mathbb{Z}$ with $p \equiv 1 mod 4$ (both of which have norm $p$). Then since $2017 \equiv 1 (mod 4)$ Then $2017 = a^2 + b^2$ . Notice that $\sqrt2017 $ is approximately $44.91$. So $a^2, b^2 $ will be between values $1,2^2,....,44^2$ . Then plugging different values from the above squares in  $2017 - a^2 = b^2$ we find $2017 - 44^2 = 81 = 9^2$ So $2017 = 44^2 + 9^2$. However, I found them using that approach.  But is there a way to find them without doing this approach? I dont' know how to use $p = a^2 + b^2 = (a + bi)(a - bi) $ for primes $p\in \mathbb{Z}$ with $p \equiv 1 mod 4$ (both of which have norm $p$). So $2017 = a^2 + b^2 = (a+ bi)(a - bi) $. I don't' know how I would proceed assuming I would not have found the values . Any feedback or better approach would be appreciated it.  Thank you!",,"['abstract-algebra', 'number-theory', 'ring-theory', 'sums-of-squares']"
65,How to show that the group is abelian?,How to show that the group is abelian?,,"I have this exercise: a. Let $\sigma \in S_{15}$ be an element of order 5. What type of   cycles can occur in the decomposition of $\sigma$ in disjoint cycles? b. Let $S \subseteq S_{15}$ be one of the Sylow 5-group in $S_{15}$.   What is the order of S? Show that S is abelian and that all nontrivial   elements are of order 5. c. Let p be a prime number and let $0<k<p$ be a natural number. Show   that the Sylow p-subgroups of the symmetric group $S_{kp}$ is abelian. my attempt and questions: a.In this part I think we only can get 5 cycles, because the order of a product of disjoint cycles is the least common multiple of the orders of all, and 5 is a prime number. b. Since the order of $S_{15}$ is 15!. We must have that the order of the Sylow 5-subgroup is $5^3=125$, since 5 occurs 3 times in the product of the order. But I am not sure how to show that S is abelian and that all nontrivial elements are of order 5. For all I know there might be elements of order 25 and 125. 15! is so big that there should be no problem for this to fit, so there must be another argument for this? And how do I show that S is abelian? c. Here I have no idea. But I guess it is a generalisation of b. So if I knew b, maybe it would be easier.","I have this exercise: a. Let $\sigma \in S_{15}$ be an element of order 5. What type of   cycles can occur in the decomposition of $\sigma$ in disjoint cycles? b. Let $S \subseteq S_{15}$ be one of the Sylow 5-group in $S_{15}$.   What is the order of S? Show that S is abelian and that all nontrivial   elements are of order 5. c. Let p be a prime number and let $0<k<p$ be a natural number. Show   that the Sylow p-subgroups of the symmetric group $S_{kp}$ is abelian. my attempt and questions: a.In this part I think we only can get 5 cycles, because the order of a product of disjoint cycles is the least common multiple of the orders of all, and 5 is a prime number. b. Since the order of $S_{15}$ is 15!. We must have that the order of the Sylow 5-subgroup is $5^3=125$, since 5 occurs 3 times in the product of the order. But I am not sure how to show that S is abelian and that all nontrivial elements are of order 5. For all I know there might be elements of order 25 and 125. 15! is so big that there should be no problem for this to fit, so there must be another argument for this? And how do I show that S is abelian? c. Here I have no idea. But I guess it is a generalisation of b. So if I knew b, maybe it would be easier.",,"['abstract-algebra', 'group-theory', 'sylow-theory']"
66,Gauss's lemma: More than a stepping stone on the way to proving $R[x]$ is a UFD when $R$ is?,Gauss's lemma: More than a stepping stone on the way to proving  is a UFD when  is?,R[x] R,"I'm reviewing my abstract algebra a bit. Currently looking at UFDs. In this context, Gauss's lemma (or part of it, at least) says that the product of two primitive polynomials over a UFD is primitive. It seems to me that Gauss's lemma follows pretty easily from the Theorem  that $R[x]$ is a UFD when $R$ is. However, this is a bit logically backwards, since I think Gauss's lemma is a sort of a preliminary step towards proving exactly that theorem? Argument: Let $R$ be a UFD. Suppose that $p(x)q(x)$ is not primitve, where $p(x),q(x) \in R[x]$. Thus, there must be some nonunit element of $R$ dividing $p(x)q(x)$. It follows that there is an irreducible $r$ of $R$ which divides $p(x)q(x)$. Now it is easy to see that an irreducible element of $R$ is still an irreducible element of $R[x]$ (degrees add, so you can't factor a constant into anything but constants). Since $R[x]$ is a UFD, its irreducibles are also prime, so $r$ is a prime element of $R[x]$. Then, from $r|p(x)q(x)$, we get that $r|p(x)$ or $r|q(x)$, so one of $p(x)$ or $q(x)$ is not primitive. My question is sort of a philisophical one: Question: Is it correct to think of Gauss's lemma as just a partial result which is then superseded by the Theorem: ""$R$ a UFD implies $R[x]$ a UFD"", or am I somehow missing out on something here? In other words, is this roughly how you think of Gauss's Lemma, or do you view it as a useful result in its own right?","I'm reviewing my abstract algebra a bit. Currently looking at UFDs. In this context, Gauss's lemma (or part of it, at least) says that the product of two primitive polynomials over a UFD is primitive. It seems to me that Gauss's lemma follows pretty easily from the Theorem  that $R[x]$ is a UFD when $R$ is. However, this is a bit logically backwards, since I think Gauss's lemma is a sort of a preliminary step towards proving exactly that theorem? Argument: Let $R$ be a UFD. Suppose that $p(x)q(x)$ is not primitve, where $p(x),q(x) \in R[x]$. Thus, there must be some nonunit element of $R$ dividing $p(x)q(x)$. It follows that there is an irreducible $r$ of $R$ which divides $p(x)q(x)$. Now it is easy to see that an irreducible element of $R$ is still an irreducible element of $R[x]$ (degrees add, so you can't factor a constant into anything but constants). Since $R[x]$ is a UFD, its irreducibles are also prime, so $r$ is a prime element of $R[x]$. Then, from $r|p(x)q(x)$, we get that $r|p(x)$ or $r|q(x)$, so one of $p(x)$ or $q(x)$ is not primitive. My question is sort of a philisophical one: Question: Is it correct to think of Gauss's lemma as just a partial result which is then superseded by the Theorem: ""$R$ a UFD implies $R[x]$ a UFD"", or am I somehow missing out on something here? In other words, is this roughly how you think of Gauss's Lemma, or do you view it as a useful result in its own right?",,"['abstract-algebra', 'polynomials', 'factoring', 'irreducible-polynomials', 'unique-factorization-domains']"
67,Calculate the ring of integers of quadratic number field $\mathbb{Q}(\sqrt{d})$ [duplicate],Calculate the ring of integers of quadratic number field  [duplicate],\mathbb{Q}(\sqrt{d}),"This question already has answers here : Why is quadratic integer ring defined in that way? (6 answers) Closed 9 years ago . Calculate the ring of integers of quadratic number field $\mathbb{Q}(\sqrt{d})$ Solution: Let $F$ be an algebraic number field. Then an element $b\in F$ is integral iff its monic irreducible polynomial has integer coefficients. For example, $\sqrt{d}$ for integer $d$ is integral. If $d\equiv 1 \bmod 4$ , then the monic irreducible polynomial of $(1+\sqrt{d})/2$ over $\mathbb{Q}$ is $x^2 -x + (1-d)/4 \in \mathbb{Z}[x]$ , so $(1+\sqrt{d})/2$ is integral. Thus the integral closure of $\mathbb{Z}$ in $\mathbb{Q}(\sqrt{d})$ contains the subring $\mathbb{Z}[\sqrt{d}]$ , and the subring $\mathbb{Z}[(1+\sqrt{d})/2]$ if $d\equiv 1 \bmod 4$ . We show that there are no other integral elements. An element $a+b\sqrt{d}$ with rational $a$ and $b\neq0$ is integral iff its monic irreducible polynomial $x^2 -2ax +(a^2 -db^2)$ belongs to $\mathbb{Z}[x]$ . Therefore, $2a$ , $2b$ are integers. If $a=(2k+1)/2$ , for $k\in\mathbb{Z}$ , then it is easy to see that $a^2 - db^2 \in \mathbb{Z}$ iff $b=(2l+1)/2$ for some $l\in\mathbb{Z}$ , and $(2k+1)^2 - d(2l+1)^2$ is divisible by $4$ . The latter implies that $d$ is a quadratic residue modulo $4$ , i.e. $d\equiv 1 \bmod 4$ . In turn, if $d\equiv 1 \bmod 4$ then every element $(2k+1)/2 +(2l+1)\sqrt{d}/2$ is integral. Thus, integral elements of $\mathbb{Q}(\sqrt{d})$ are equal to $\mathbb{Z}[\sqrt{d}]$ if $d\not \equiv 1 \bmod 4$ , and $\mathbb{Z}[(1+\sqrt{d})/2]$ if $d\equiv 1 \bmod 4$ . Can someone explain why $\sqrt{d}$ for integer $d$ is integral, and why the monic irreducible polynomial of an integral element $a+b\sqrt{d}$ is of the form $x^2 -2ax +(a^2 -db^2)$ ?","This question already has answers here : Why is quadratic integer ring defined in that way? (6 answers) Closed 9 years ago . Calculate the ring of integers of quadratic number field Solution: Let be an algebraic number field. Then an element is integral iff its monic irreducible polynomial has integer coefficients. For example, for integer is integral. If , then the monic irreducible polynomial of over is , so is integral. Thus the integral closure of in contains the subring , and the subring if . We show that there are no other integral elements. An element with rational and is integral iff its monic irreducible polynomial belongs to . Therefore, , are integers. If , for , then it is easy to see that iff for some , and is divisible by . The latter implies that is a quadratic residue modulo , i.e. . In turn, if then every element is integral. Thus, integral elements of are equal to if , and if . Can someone explain why for integer is integral, and why the monic irreducible polynomial of an integral element is of the form ?",\mathbb{Q}(\sqrt{d}) F b\in F \sqrt{d} d d\equiv 1 \bmod 4 (1+\sqrt{d})/2 \mathbb{Q} x^2 -x + (1-d)/4 \in \mathbb{Z}[x] (1+\sqrt{d})/2 \mathbb{Z} \mathbb{Q}(\sqrt{d}) \mathbb{Z}[\sqrt{d}] \mathbb{Z}[(1+\sqrt{d})/2] d\equiv 1 \bmod 4 a+b\sqrt{d} a b\neq0 x^2 -2ax +(a^2 -db^2) \mathbb{Z}[x] 2a 2b a=(2k+1)/2 k\in\mathbb{Z} a^2 - db^2 \in \mathbb{Z} b=(2l+1)/2 l\in\mathbb{Z} (2k+1)^2 - d(2l+1)^2 4 d 4 d\equiv 1 \bmod 4 d\equiv 1 \bmod 4 (2k+1)/2 +(2l+1)\sqrt{d}/2 \mathbb{Q}(\sqrt{d}) \mathbb{Z}[\sqrt{d}] d\not \equiv 1 \bmod 4 \mathbb{Z}[(1+\sqrt{d})/2] d\equiv 1 \bmod 4 \sqrt{d} d a+b\sqrt{d} x^2 -2ax +(a^2 -db^2),"['abstract-algebra', 'algebraic-number-theory']"
68,Frobenius kernel is regular normal elementary abelian p-subgroup?,Frobenius kernel is regular normal elementary abelian p-subgroup?,,"I'm attempting Exercise 3.4.6 in Dixon & Mortimer's book on Permutation Groups: Let $G$ be a finite primitive permutation group with abelian point stabilisers. Show that $G$ has a regular normal elementary abelian $p$-subgroup for some prime $p$. I know that if $G$ is a primitive permutation group with abelian point stabilisers and $G$ does not have prime order, then it is a Frobenius Group. Is it also a Frobenius group if $G$ has finite order? If so, I know that the Frobenius kernel $K$ is a normal regular subgroup from the Structure Theorem for Finite Frobenius Groups. I'm not sure how to go about proving that $K$ is also an elementary abelian $p$-subgroup though. From the Frattini Argument I know that if $P$ is a Sylow $p$-subgroup of $K$ then the direct product of $K$ and the normaliser of $P$ is equal to $G$. But if $G$ is Frobenius it is also equal to the semi-direct product of the Frobenius kernel and complement - perhaps I can use this to show that $K$ itself is a $p$-subgroup? And therefore an elementary group since a direct product of a $p$-subgroup and the identity (which is finite and cyclic or order $1$). I'm a bit stuck as to where to start on proving that $K$ is abelian, and this is all assuming that $G$ is a Frobenius group and $K$ is the subgroup in question! Any help would be much appreciated. Thanks!","I'm attempting Exercise 3.4.6 in Dixon & Mortimer's book on Permutation Groups: Let $G$ be a finite primitive permutation group with abelian point stabilisers. Show that $G$ has a regular normal elementary abelian $p$-subgroup for some prime $p$. I know that if $G$ is a primitive permutation group with abelian point stabilisers and $G$ does not have prime order, then it is a Frobenius Group. Is it also a Frobenius group if $G$ has finite order? If so, I know that the Frobenius kernel $K$ is a normal regular subgroup from the Structure Theorem for Finite Frobenius Groups. I'm not sure how to go about proving that $K$ is also an elementary abelian $p$-subgroup though. From the Frattini Argument I know that if $P$ is a Sylow $p$-subgroup of $K$ then the direct product of $K$ and the normaliser of $P$ is equal to $G$. But if $G$ is Frobenius it is also equal to the semi-direct product of the Frobenius kernel and complement - perhaps I can use this to show that $K$ itself is a $p$-subgroup? And therefore an elementary group since a direct product of a $p$-subgroup and the identity (which is finite and cyclic or order $1$). I'm a bit stuck as to where to start on proving that $K$ is abelian, and this is all assuming that $G$ is a Frobenius group and $K$ is the subgroup in question! Any help would be much appreciated. Thanks!",,"['abstract-algebra', 'group-theory', 'finite-groups', 'p-groups', 'frobenius-groups']"
69,Stuggling to understand ideal powers,Stuggling to understand ideal powers,,"In my current algebraic number theory course we have defined the multiplication of 2 ideals as the smallest ideal containing all products of elements of both, [i.e: let I and J be ideals of a ring R, then IJ:={$\sum_1^k a_ib_i : a_i\in I , b_i\in J$} where k depends on R ] we haven't however, formally defined ideal powers, by which I mean ideals of the form $I^x$ where x is an integer. However, using the first, informal definition, it seems to me that all products of elements from I will just again form I i.e. using the formal definition, and taking x = 2 I find that $I^2$ = II = {$\sum_i^k a_ib_i : a_i\in I , b_i\in I$} = {$\sum_1^k c_i : c_i\in I$} = {$d : d\in I$} = I and clearly extending this definition to higher powers results in the same thing? Thanks for any clarification!","In my current algebraic number theory course we have defined the multiplication of 2 ideals as the smallest ideal containing all products of elements of both, [i.e: let I and J be ideals of a ring R, then IJ:={$\sum_1^k a_ib_i : a_i\in I , b_i\in J$} where k depends on R ] we haven't however, formally defined ideal powers, by which I mean ideals of the form $I^x$ where x is an integer. However, using the first, informal definition, it seems to me that all products of elements from I will just again form I i.e. using the formal definition, and taking x = 2 I find that $I^2$ = II = {$\sum_i^k a_ib_i : a_i\in I , b_i\in I$} = {$\sum_1^k c_i : c_i\in I$} = {$d : d\in I$} = I and clearly extending this definition to higher powers results in the same thing? Thanks for any clarification!",,"['abstract-algebra', 'algebraic-number-theory', 'ideals']"
70,On semisimple rings,On semisimple rings,,"Let $R$ denote a ring with unity. I know that, if $R$ is semisimple, then every $R$-module is semisimple. In particular the class of indecomposable $R$-modules coincides with the class of simple $R$-modules (If $N$ is indecomposable and semisimple, then it is simple). I was wondering if the converse holds. Precisely: if all indecomposable $R$-modules are simple, can we deduce that $R$ is a semisimple ring? In particular this is equivalent on trying to prove that $R$ is completely decomposable, i.e. a direct sum of indecomposable (hence simple) $R$-modules.","Let $R$ denote a ring with unity. I know that, if $R$ is semisimple, then every $R$-module is semisimple. In particular the class of indecomposable $R$-modules coincides with the class of simple $R$-modules (If $N$ is indecomposable and semisimple, then it is simple). I was wondering if the converse holds. Precisely: if all indecomposable $R$-modules are simple, can we deduce that $R$ is a semisimple ring? In particular this is equivalent on trying to prove that $R$ is completely decomposable, i.e. a direct sum of indecomposable (hence simple) $R$-modules.",,"['abstract-algebra', 'modules', 'semi-simple-rings']"
71,Proof Verification: Let S be a non-empty subset of a ring R. Then S is a subring of R if and only if S is closed under $-$ and $\times$.,Proof Verification: Let S be a non-empty subset of a ring R. Then S is a subring of R if and only if S is closed under  and .,- \times,"Let S be a non-empty subset of a ring R. Then S is a subring of R if and only if S is closed under $-$ and $\times$. Proof:  First, prove that S is a subgroup of R. Pick an arbitrary element $x$ from S. Since S is closed under subtraction, $x - x = 0 \in S$ and $0 - x = -x \in S$. Therefore, for all $x, y \in S, -x, -y \in S$ and hence $x-(-y) = x+y$ also belongs to $S$. Hence S is a subgroup. Since R is a ring, distributive laws hold in R and hence also in S. Abelian property is also inherited from R. S is closed under multiplication. Hence, S is a subring. Is my proof OK?","Let S be a non-empty subset of a ring R. Then S is a subring of R if and only if S is closed under $-$ and $\times$. Proof:  First, prove that S is a subgroup of R. Pick an arbitrary element $x$ from S. Since S is closed under subtraction, $x - x = 0 \in S$ and $0 - x = -x \in S$. Therefore, for all $x, y \in S, -x, -y \in S$ and hence $x-(-y) = x+y$ also belongs to $S$. Hence S is a subgroup. Since R is a ring, distributive laws hold in R and hence also in S. Abelian property is also inherited from R. S is closed under multiplication. Hence, S is a subring. Is my proof OK?",,"['abstract-algebra', 'proof-verification']"
72,Multiplication Operation,Multiplication Operation,,"I am a father of two young boys and I looks forward to exploring mathematics with them for as long as they will let me :-). I would really like for them to have a deeper understanding of mathematics than what I had when I was a young student. As I think about how I might approach some of the topics, there is one that remains particularly unclear to me to this day - the multiplication operation. Now I do not have a strong background in mathematics (e.g. never had a course in abstract algebra), so please forgive me if some things that I say are off - maybe  even way off. I have seen that there have been debates online as to what multiplication is, and how to teach it to students.  Often the discussion turns into interpretations of multiplication (e.g. repeated addition, scaling, etc.) but the discussions/debate from this approach seem to be fruitless. Other times properties of multiplication are discussed, but often the properties are the same as those found under different types of operations. Integer multiplication may be associative, but so is integer addition - leaving me no more informed about the unique and universal thread for the concept of multiplication. From my perspective, I am most confused by the many definitions for the multiplication operation depending on the type of objects of interest (real numbers, complex numbers, matrices, etc). I always think to myself, ""why would mathematics allow the same name to be associated with multiple definitions?"". It seems like there must be something that all the definitions must have in common. Surely, not just any binary operation on a set of objects can be labeled multiplication on a whim...or can it? So this is my question, is there a characterization of the multiplication operation that holds true for all operations labeled multiplication, that it is agreed on within the academic community, and is unique enough to be able to distinguish it from other operations (namely addition)? If so, please do share. And if not, how would you explain why the same term has various definitions in mathematics to students learning about operations like multiplication? From my limited mathematical knowledge, it appears that the only thing in common with different definitions of multiplication on different objects is that that they all rely on the use of the addition operation in their construction. So perhaps the term addition is used to reference an operation for a set of objects that is considered to be the simplest method for combining/connecting two objects in a set, and multiplication is a more complex method for  doing so (perhaps based on the use of simpler operations, like addition, already defined for the set). But, I would prefer that my discussion with my sons not rely on my experience. Hence, the reason for the post. Many thanks for taking the time to review my write up and I look forward to any insight that may be offered.","I am a father of two young boys and I looks forward to exploring mathematics with them for as long as they will let me :-). I would really like for them to have a deeper understanding of mathematics than what I had when I was a young student. As I think about how I might approach some of the topics, there is one that remains particularly unclear to me to this day - the multiplication operation. Now I do not have a strong background in mathematics (e.g. never had a course in abstract algebra), so please forgive me if some things that I say are off - maybe  even way off. I have seen that there have been debates online as to what multiplication is, and how to teach it to students.  Often the discussion turns into interpretations of multiplication (e.g. repeated addition, scaling, etc.) but the discussions/debate from this approach seem to be fruitless. Other times properties of multiplication are discussed, but often the properties are the same as those found under different types of operations. Integer multiplication may be associative, but so is integer addition - leaving me no more informed about the unique and universal thread for the concept of multiplication. From my perspective, I am most confused by the many definitions for the multiplication operation depending on the type of objects of interest (real numbers, complex numbers, matrices, etc). I always think to myself, ""why would mathematics allow the same name to be associated with multiple definitions?"". It seems like there must be something that all the definitions must have in common. Surely, not just any binary operation on a set of objects can be labeled multiplication on a whim...or can it? So this is my question, is there a characterization of the multiplication operation that holds true for all operations labeled multiplication, that it is agreed on within the academic community, and is unique enough to be able to distinguish it from other operations (namely addition)? If so, please do share. And if not, how would you explain why the same term has various definitions in mathematics to students learning about operations like multiplication? From my limited mathematical knowledge, it appears that the only thing in common with different definitions of multiplication on different objects is that that they all rely on the use of the addition operation in their construction. So perhaps the term addition is used to reference an operation for a set of objects that is considered to be the simplest method for combining/connecting two objects in a set, and multiplication is a more complex method for  doing so (perhaps based on the use of simpler operations, like addition, already defined for the set). But, I would prefer that my discussion with my sons not rely on my experience. Hence, the reason for the post. Many thanks for taking the time to review my write up and I look forward to any insight that may be offered.",,"['abstract-algebra', 'soft-question', 'definition']"
73,A question about the automorphism group of $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$,A question about the automorphism group of,\mathbb{Z}_{2} \times \mathbb{Z}_{4},"I wanted to clarify some confusion I was having on the automorphism group of $\mathbb{Z}_{2} \times \mathbb{Z}_{4}$ , which I call $\mathrm{Aut}(\mathbb{Z}_{2} \times \mathbb{Z}_{4})$ . I considered the following as a presentation of this group $\mathbb{Z}_{2} \times \mathbb{Z}_{4} = \langle r,s : r^{2}=1=s^{4}, sr=rs \rangle$ . Looking at this presentation, an element $\alpha \in \mathrm{Aut}(\mathbb{Z}_{2} \times \mathbb{Z}_{4})$ will send $r$ to $r$ or $s^{2}r$ and will send $s$ to $s, s^{3}, sr$ , or $s^{3}r$ . Using this, I was able to list $8$ possible automorphisms. I did not check this carefully, but the autmorphisms that I listed each had order $2$ and I may not be remembering this correctly but a group of order $8$ where all the non-identity  elements are of order $2$ is abelian. I turned to looking at $\mathrm{Aut}(\mathbb{Z}_{5} \times \mathbb{Z}_{25})$ where I found this question: Properties of automorphism group of $G={Z_5}\times Z_{25}$ The answer uses the following proposition the result of which is found in the paper below(which I haven't finished reading yet to verify): Christopher J. Hillar, Darren Rhea, Automorphisms of finite Abelian groups , arXiv For example, if $p$ is a prime, then $$\mathrm{End}(\mathbb{Z}/p \times \mathbb{Z}/p^2) \cong \begin{pmatrix} \hom(\mathbb{Z}/p,\mathbb{Z}/p) & \hom(\mathbb{Z}/p^2,\mathbb{Z}/p) \\ \hom(\mathbb{Z}/p,\mathbb{Z}/p^2) & \hom(\mathbb{Z}/p^2,\mathbb{Z}/p^2) \end{pmatrix} \cong \begin{pmatrix} \mathbb{Z}/p & \mathbb{Z}/p \\ \mathbb{Z}/p & \mathbb{Z}/p^2 \end{pmatrix}$$ But I think based on that result, my conclusion that $\mathrm{Aut}(\mathbb{Z}_{2} \times \mathbb{Z}_{4})$ is abelian looks to be false. I am essentially wondering if I did something wrong","I wanted to clarify some confusion I was having on the automorphism group of , which I call . I considered the following as a presentation of this group . Looking at this presentation, an element will send to or and will send to , or . Using this, I was able to list possible automorphisms. I did not check this carefully, but the autmorphisms that I listed each had order and I may not be remembering this correctly but a group of order where all the non-identity  elements are of order is abelian. I turned to looking at where I found this question: Properties of automorphism group of $G={Z_5}\times Z_{25}$ The answer uses the following proposition the result of which is found in the paper below(which I haven't finished reading yet to verify): Christopher J. Hillar, Darren Rhea, Automorphisms of finite Abelian groups , arXiv For example, if is a prime, then But I think based on that result, my conclusion that is abelian looks to be false. I am essentially wondering if I did something wrong","\mathbb{Z}_{2} \times \mathbb{Z}_{4} \mathrm{Aut}(\mathbb{Z}_{2} \times \mathbb{Z}_{4}) \mathbb{Z}_{2} \times \mathbb{Z}_{4} = \langle r,s : r^{2}=1=s^{4}, sr=rs \rangle \alpha \in \mathrm{Aut}(\mathbb{Z}_{2} \times \mathbb{Z}_{4}) r r s^{2}r s s, s^{3}, sr s^{3}r 8 2 8 2 \mathrm{Aut}(\mathbb{Z}_{5} \times \mathbb{Z}_{25}) p \mathrm{End}(\mathbb{Z}/p \times \mathbb{Z}/p^2) \cong \begin{pmatrix} \hom(\mathbb{Z}/p,\mathbb{Z}/p) & \hom(\mathbb{Z}/p^2,\mathbb{Z}/p) \\ \hom(\mathbb{Z}/p,\mathbb{Z}/p^2) & \hom(\mathbb{Z}/p^2,\mathbb{Z}/p^2) \end{pmatrix} \cong \begin{pmatrix} \mathbb{Z}/p & \mathbb{Z}/p \\ \mathbb{Z}/p & \mathbb{Z}/p^2 \end{pmatrix} \mathrm{Aut}(\mathbb{Z}_{2} \times \mathbb{Z}_{4})","['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
74,Subfield Criteria - Proof or Counterexample,Subfield Criteria - Proof or Counterexample,,"I am interested in whether the following claim is true for all fields $F$: Conjecture : A subset $X\subset F$ is a subfield if and only if (1) $1\in X$, (2) $x,y\in X\Rightarrow x-y\in X$; and (3) $x\in X\setminus\{0\}\Rightarrow x^{-1}\in X$. It isn't too hard to prove true if char$F\neq2$, and I can also show it holds if $F$ is finite. The case of an infinite field of characteristic $2$ remains elusive, though. I can neither prove it nor find a counterexample. Can anyone else give it a go? Some notes: conditions (1), (2) and (3) are certainly independent, hence my interest in the problem. The following are consequences of the conditions: If $x,y\in X$ then $(xy)^2,xy^2\in X$ If $x\in X$ then $x^n\in X$ for all $n\in\mathbb{Z}$ In case you were after the work so far: Clearly conditions (1) and (2) imply $X$ is a subgroup. Suppose $x\in X$. If $x\in\{0,1\}$ then $x^2=x\in X$. If not, $x^{-1},(1-x)^{-1}\in X$, so $x^2=x-[x^{-1}+(1-x)^{-1}]^{-1}\in X$. Hence $X$ is closed under squares. Assume char$F\neq2$. Then if $x,y\in X$, $2xy=(x+y)^2-x^2-y^2\in X$, so either $xy=0\in X$ or $(2xy)^{-1}\in X$, in which case $xy=[(2xy)^{-1}+(2xy)^{-1}]^{-1}\in X$. This proves the conjecture if char$F\neq2$. Assume char$F=2$. Then if $x,y,z\in X$ with $x\notin\{y^{-1},z^{-1}\}$ and $y,z,0$ all distinct, we have $\omega:=(x+y^{-1})^{-1}+(x+z^{-1})^{-1}\in X$. Simplifying gives $\omega=[y(1+xz)+z(1+xy)][(1+xy)(1+xz)]^{-1}=(y+z)[1+x(y+z)+x^2yz]^{-1}$, and so $$f(x,y,z):=x^2yz(y+z)^{-1}=\omega^{-1}-x-(y+z)^{-1}\in X$$ for all $x,y,z\in X$. Thus if $x,y\in X$, we have $$x^2y(y+1)=f(x,y,y+1)\in X,\quad y(x^2+y)=f(x,y,x^2+y)\in X\Rightarrow x^2y\in X\Rightarrow x^2y^2\in X.$$ If $|F|<\infty$, then $|F|=2^n$ for some $n$ and $F\setminus\{0\}$ is a multiplicative group of order $2^n-1$. Since $X$ is closed under squares, induction gives us $$xy=(xy)^{2^n}\in X.$$ If $|F|=\infty$, I'm stuck. Since $x\in X$, $x^3=x^2x\in X$, and if $x^{n-2}\in X$ then $x^n=x^{n-2}x^2\in X$. Hence by induction $x^n\in X$ for all $n\in\mathbb{N}$ (since $X$ is closed under squares and cubes), and so by taking inverses $x^n\in X$ for all $n\in\mathbb{Z}$.","I am interested in whether the following claim is true for all fields $F$: Conjecture : A subset $X\subset F$ is a subfield if and only if (1) $1\in X$, (2) $x,y\in X\Rightarrow x-y\in X$; and (3) $x\in X\setminus\{0\}\Rightarrow x^{-1}\in X$. It isn't too hard to prove true if char$F\neq2$, and I can also show it holds if $F$ is finite. The case of an infinite field of characteristic $2$ remains elusive, though. I can neither prove it nor find a counterexample. Can anyone else give it a go? Some notes: conditions (1), (2) and (3) are certainly independent, hence my interest in the problem. The following are consequences of the conditions: If $x,y\in X$ then $(xy)^2,xy^2\in X$ If $x\in X$ then $x^n\in X$ for all $n\in\mathbb{Z}$ In case you were after the work so far: Clearly conditions (1) and (2) imply $X$ is a subgroup. Suppose $x\in X$. If $x\in\{0,1\}$ then $x^2=x\in X$. If not, $x^{-1},(1-x)^{-1}\in X$, so $x^2=x-[x^{-1}+(1-x)^{-1}]^{-1}\in X$. Hence $X$ is closed under squares. Assume char$F\neq2$. Then if $x,y\in X$, $2xy=(x+y)^2-x^2-y^2\in X$, so either $xy=0\in X$ or $(2xy)^{-1}\in X$, in which case $xy=[(2xy)^{-1}+(2xy)^{-1}]^{-1}\in X$. This proves the conjecture if char$F\neq2$. Assume char$F=2$. Then if $x,y,z\in X$ with $x\notin\{y^{-1},z^{-1}\}$ and $y,z,0$ all distinct, we have $\omega:=(x+y^{-1})^{-1}+(x+z^{-1})^{-1}\in X$. Simplifying gives $\omega=[y(1+xz)+z(1+xy)][(1+xy)(1+xz)]^{-1}=(y+z)[1+x(y+z)+x^2yz]^{-1}$, and so $$f(x,y,z):=x^2yz(y+z)^{-1}=\omega^{-1}-x-(y+z)^{-1}\in X$$ for all $x,y,z\in X$. Thus if $x,y\in X$, we have $$x^2y(y+1)=f(x,y,y+1)\in X,\quad y(x^2+y)=f(x,y,x^2+y)\in X\Rightarrow x^2y\in X\Rightarrow x^2y^2\in X.$$ If $|F|<\infty$, then $|F|=2^n$ for some $n$ and $F\setminus\{0\}$ is a multiplicative group of order $2^n-1$. Since $X$ is closed under squares, induction gives us $$xy=(xy)^{2^n}\in X.$$ If $|F|=\infty$, I'm stuck. Since $x\in X$, $x^3=x^2x\in X$, and if $x^{n-2}\in X$ then $x^n=x^{n-2}x^2\in X$. Hence by induction $x^n\in X$ for all $n\in\mathbb{N}$ (since $X$ is closed under squares and cubes), and so by taking inverses $x^n\in X$ for all $n\in\mathbb{Z}$.",,"['abstract-algebra', 'field-theory']"
75,"Tensor Product, Exterior Power and Splitting","Tensor Product, Exterior Power and Splitting",,Let $M$ be a $\mathbb{Z}$-module and consider the submodule $K=\langle m\otimes m\mid m\in M\rangle$ of $M\otimes M$. Under what conditions does the SES $$0\to K\to M\otimes M\to M\wedge M\to 0$$ split? In other words when can we write $M\otimes M\cong K \times (M\wedge M)$. Thanks.,Let $M$ be a $\mathbb{Z}$-module and consider the submodule $K=\langle m\otimes m\mid m\in M\rangle$ of $M\otimes M$. Under what conditions does the SES $$0\to K\to M\otimes M\to M\wedge M\to 0$$ split? In other words when can we write $M\otimes M\cong K \times (M\wedge M)$. Thanks.,,"['abstract-algebra', 'commutative-algebra']"
76,Showing that group of orientation preserving isometries of Icosahedron is a simple group,Showing that group of orientation preserving isometries of Icosahedron is a simple group,,"Let $G$ denote the group of orientation preserving isometries of Icosahedron. To prove the claim, I have shown that $\nexists \  N \ \triangleleft \ G$ such that $|N|=5.$ $\nexists \  N \ \triangleleft \ G$ such that $|N|=3.$ $\nexists \  N \ \triangleleft \ G$ such that $|N|=2.$ I know the following: Rotation around a vertex gives a subgroup of order 5. Rotation around the center of a face gives a subgroup of order 3. Rotation around the midpoint of an edge gives a subgroup of order 2. We have $|G|=60=2^2\times 3\times 5.$ What more do I need to show to conclude that $G$ is simple? Is it that I have to show there are no normal subgroup of order $4,6,10,12,15,20,30$? Is there a general theorem that can be useful in my case? I would be glad to know in that case.","Let $G$ denote the group of orientation preserving isometries of Icosahedron. To prove the claim, I have shown that $\nexists \  N \ \triangleleft \ G$ such that $|N|=5.$ $\nexists \  N \ \triangleleft \ G$ such that $|N|=3.$ $\nexists \  N \ \triangleleft \ G$ such that $|N|=2.$ I know the following: Rotation around a vertex gives a subgroup of order 5. Rotation around the center of a face gives a subgroup of order 3. Rotation around the midpoint of an edge gives a subgroup of order 2. We have $|G|=60=2^2\times 3\times 5.$ What more do I need to show to conclude that $G$ is simple? Is it that I have to show there are no normal subgroup of order $4,6,10,12,15,20,30$? Is there a general theorem that can be useful in my case? I would be glad to know in that case.",,"['abstract-algebra', 'group-theory']"
77,Efficient algorithm for calculating the tetration of two numbers mod n?,Efficient algorithm for calculating the tetration of two numbers mod n?,,"I'm trying to study the algebraic properties of the magma created by defining the binary operation $x*y$ to be: $ x*y = (x \uparrow y) \bmod n $ where $ \uparrow $ is the symbol for tetration. Doing so, the hardest commutation necessary for this kind of magma of order n is: $ (n-1) \uparrow (n-1) \bmod n $. Using the standard algorithms for tetration and the modulus, this computation was instantaneous up to the magma of order 4. For the magma of order 5 however, with the computation $ 4 \uparrow 4 \bmod 5 $, I could not compute it after 2+ hours. Is this computation even tractable for a core i7 laptop? (I'm using a library that allows for arbitrarily large integers) Is there a better way to do this computation than with a standard (brute force) calculation?","I'm trying to study the algebraic properties of the magma created by defining the binary operation $x*y$ to be: $ x*y = (x \uparrow y) \bmod n $ where $ \uparrow $ is the symbol for tetration. Doing so, the hardest commutation necessary for this kind of magma of order n is: $ (n-1) \uparrow (n-1) \bmod n $. Using the standard algorithms for tetration and the modulus, this computation was instantaneous up to the magma of order 4. For the magma of order 5 however, with the computation $ 4 \uparrow 4 \bmod 5 $, I could not compute it after 2+ hours. Is this computation even tractable for a core i7 laptop? (I'm using a library that allows for arbitrarily large integers) Is there a better way to do this computation than with a standard (brute force) calculation?",,"['abstract-algebra', 'algorithms', 'computability', 'tetration', 'magma']"
78,Which mathematical structures are particular cases of small categories?,Which mathematical structures are particular cases of small categories?,,"In what follows, all categories are assumed to be small (classes of objects and morphisms are sets). Which mathematical structures $X$ can be seen as particular cases of small categories $\underline{X}$ , so that the morphisms $X\to Y$ of those structures coincide with functors $\underline{X}\to \underline{Y}$ ? So far, I have: set $S$ (objects are elements of $S$ , there are no morphisms except identities); a set is precisely a category without non-identity morphisms; semigroup $S$ (one object, morphisms are elements of $S$ , composition is multiplication in $S$ ); a unital semigroup is precisely a category with just one object; a group is precisely a category with one object and all morphisms invertible; multidigraph $\Gamma$ (objects are vertices of $\Gamma$ , morphisms are directed paths, composition is concatenation); a multidigraph is precisely a free category; posets $P$ (objects are elements of $P$ , morphisms are elements of $\leq$ ); posets are precisely categories with at most one arrow between any two objects). Basically I'm asking is What known (popular) categories are full subcategories of $\textsf{Cat}$ , the category of all small categories and functors? How about topological spaces? Rings? Modules? Lattices? Simplicial complexes? Is the category algebra studied for such cases? I'm beginning to realize that associative algebras seem to be the central concept through which all others are studied, such as groups (group algebras), rings ( $\mathbb{Z}$ -algebras), ideals (associated graded algebras), modules (tensor, symmetric, exterior algebras), Lie algebras (universal enveloping algebras), simplicial complexes (Stanley-Reisner algebras), small categories (categorical algebras such as semigroup, incidence, quiver algebras), topological spaces (algebra of continuous functions to $\mathbb{R}$ ), affine and projective algebraic sets (coordinate algebras). Thus I'm wondering how much the category algebras really cover.","In what follows, all categories are assumed to be small (classes of objects and morphisms are sets). Which mathematical structures can be seen as particular cases of small categories , so that the morphisms of those structures coincide with functors ? So far, I have: set (objects are elements of , there are no morphisms except identities); a set is precisely a category without non-identity morphisms; semigroup (one object, morphisms are elements of , composition is multiplication in ); a unital semigroup is precisely a category with just one object; a group is precisely a category with one object and all morphisms invertible; multidigraph (objects are vertices of , morphisms are directed paths, composition is concatenation); a multidigraph is precisely a free category; posets (objects are elements of , morphisms are elements of ); posets are precisely categories with at most one arrow between any two objects). Basically I'm asking is What known (popular) categories are full subcategories of , the category of all small categories and functors? How about topological spaces? Rings? Modules? Lattices? Simplicial complexes? Is the category algebra studied for such cases? I'm beginning to realize that associative algebras seem to be the central concept through which all others are studied, such as groups (group algebras), rings ( -algebras), ideals (associated graded algebras), modules (tensor, symmetric, exterior algebras), Lie algebras (universal enveloping algebras), simplicial complexes (Stanley-Reisner algebras), small categories (categorical algebras such as semigroup, incidence, quiver algebras), topological spaces (algebra of continuous functions to ), affine and projective algebraic sets (coordinate algebras). Thus I'm wondering how much the category algebras really cover.",X \underline{X} X\to Y \underline{X}\to \underline{Y} S S S S S \Gamma \Gamma P P \leq \textsf{Cat} \mathbb{Z} \mathbb{R},"['abstract-algebra', 'category-theory', 'noncommutative-algebra']"
79,"Two ideals both alike in dignity, in fair Paris where we lay our scene. (proving ideals are isomorphic)","Two ideals both alike in dignity, in fair Paris where we lay our scene. (proving ideals are isomorphic)",,"Let $A$ be an integral domain. I have to show that two ideals $\mathfrak a$ and $\mathfrak b$ are isomorphic as $A$-modules if and only if there exist $a$ and $b$ such that $a\mathfrak b=b\mathfrak a$. I gather that for ""$\Leftarrow$"" the isomorphism is $x\rightarrow a^{-1}bx$ or something, but I can't prove that $a$ and $b$ have inverses. My question is: why are $a$ and $b$ invertible?","Let $A$ be an integral domain. I have to show that two ideals $\mathfrak a$ and $\mathfrak b$ are isomorphic as $A$-modules if and only if there exist $a$ and $b$ such that $a\mathfrak b=b\mathfrak a$. I gather that for ""$\Leftarrow$"" the isomorphism is $x\rightarrow a^{-1}bx$ or something, but I can't prove that $a$ and $b$ have inverses. My question is: why are $a$ and $b$ invertible?",,"['abstract-algebra', 'modules', 'ideals', 'integral-domain']"
80,"Space of morhisms of representations, its dimension in special case","Space of morhisms of representations, its dimension in special case",,"The symmetric group $S_n$ acts linearly on $\mathbb{C}^n$, hence it brings up to the representation in $\Lambda^m\mathbb{C}^n$. The goal is to evaluate the dimension of morphisms $\mathrm{Hom}_{S_n}(\Lambda^k\mathbb{C}^n,\Lambda^m\mathbb{C}^n)$. There is a general way to do it: given two representations $\rho_1$ and $\rho_2$ in $V_1$ and $V_2$ respectively of some group $G$ we can build a representation $T$ in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$ by $$T_g(\phi)=\rho_1(g)\circ\phi\circ\rho_2(g^{-1})$$ So, morphisms of $\rho_1$ and $\rho_2$ are exactly $G$-invariants in this representation of $G$ in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$. But the dimension of the space of $G$-invariants is the trace of $\frac{1}{|G|}\sum T_g$, i.e. the sum of traces $\frac{1}{|G|}\sum \operatorname{tr}(T_g)$. So, I do not believe we should evaluate each trace in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$... Could you help? Perhaps, there is another way?","The symmetric group $S_n$ acts linearly on $\mathbb{C}^n$, hence it brings up to the representation in $\Lambda^m\mathbb{C}^n$. The goal is to evaluate the dimension of morphisms $\mathrm{Hom}_{S_n}(\Lambda^k\mathbb{C}^n,\Lambda^m\mathbb{C}^n)$. There is a general way to do it: given two representations $\rho_1$ and $\rho_2$ in $V_1$ and $V_2$ respectively of some group $G$ we can build a representation $T$ in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$ by $$T_g(\phi)=\rho_1(g)\circ\phi\circ\rho_2(g^{-1})$$ So, morphisms of $\rho_1$ and $\rho_2$ are exactly $G$-invariants in this representation of $G$ in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$. But the dimension of the space of $G$-invariants is the trace of $\frac{1}{|G|}\sum T_g$, i.e. the sum of traces $\frac{1}{|G|}\sum \operatorname{tr}(T_g)$. So, I do not believe we should evaluate each trace in $\mathrm{Hom}_{\mathbb{C}}(V_1,V_2)$... Could you help? Perhaps, there is another way?",,['representation-theory']
81,Prove that a finite abelian group is simple if and only if its order is prime. [duplicate],Prove that a finite abelian group is simple if and only if its order is prime. [duplicate],,"This question already has answers here : Proof that all abelian simple groups are cyclic groups of prime order (5 answers) Closed 8 years ago . So I'm having trouble with this problem. I know that the definition of a simple group means that the group has no nontrivial subgroups. I know that this can be proven somehow with the help of the converse of Lagrange's Theorem for Abelian groups: If G is abelian of order n, and d is a divisor of n, then G has a subgroup of order d. My attempt: (=>)Assume that G is a finite abelian group and is simple, then G has no nontrivial normal  subgroups.  (Now I don't know how to show that this implies that G has order p, where p is prime. (<=)Assume that G is a finite abelian group with order p, where p is a prime. (Since the order of p is prime then what does this mean?) Edit: Can someone check my new attempt at the proof? (=>) Suppose G is a simple finite abelian group. Suppose for the sake of contradiction that G does not have prime order, then |G|=p*k where p is a prime number and k is an integer such that k>1. Then G has an element of order p. Let the element of order p be called x. Then , the subgroup generated by x, is of order p and  is not all of G. Since G is abelian, this subgroup is normal, which leads us to a contradiction. Therefore, G must have prime order. (<=) Suppose that G is a finite abelian group and it’s order is p, a prime. Since G has prime order, then the only two subgroups of G are the trivial subgroup and the group G. Then, by definition the group G is simple since there are no nontrivial proper subgroups, and thus no nontrivial normal subgroups.","This question already has answers here : Proof that all abelian simple groups are cyclic groups of prime order (5 answers) Closed 8 years ago . So I'm having trouble with this problem. I know that the definition of a simple group means that the group has no nontrivial subgroups. I know that this can be proven somehow with the help of the converse of Lagrange's Theorem for Abelian groups: If G is abelian of order n, and d is a divisor of n, then G has a subgroup of order d. My attempt: (=>)Assume that G is a finite abelian group and is simple, then G has no nontrivial normal  subgroups.  (Now I don't know how to show that this implies that G has order p, where p is prime. (<=)Assume that G is a finite abelian group with order p, where p is a prime. (Since the order of p is prime then what does this mean?) Edit: Can someone check my new attempt at the proof? (=>) Suppose G is a simple finite abelian group. Suppose for the sake of contradiction that G does not have prime order, then |G|=p*k where p is a prime number and k is an integer such that k>1. Then G has an element of order p. Let the element of order p be called x. Then , the subgroup generated by x, is of order p and  is not all of G. Since G is abelian, this subgroup is normal, which leads us to a contradiction. Therefore, G must have prime order. (<=) Suppose that G is a finite abelian group and it’s order is p, a prime. Since G has prime order, then the only two subgroups of G are the trivial subgroup and the group G. Then, by definition the group G is simple since there are no nontrivial proper subgroups, and thus no nontrivial normal subgroups.",,"['abstract-algebra', 'group-theory', 'proof-verification', 'finite-groups', 'abelian-groups']"
82,"Have mathematical structures equipped with ""generalized relations"" been considered in a systematic way?","Have mathematical structures equipped with ""generalized relations"" been considered in a systematic way?",,"A binary relation on $X$ is basically just a function $X^2 \rightarrow \mathbb{B}$, where $\mathbb{B}$ is the prototypical Boolean algebra $\{0,1\}.$ We can generalize by replacing $\mathbb{B}$ with a more complicated partially ordered structure. Thus, we have: Heuristic idea. A generalized relation on $X$ is a function $X^n \rightarrow P$, where $P$ is a partially ordered set possibly having additional structure. For example, a metric space can be viewed as set $X$ equipped with a generalized relation $d : X^2 \rightarrow [0,\infty)$ satisfying the usual axioms. Question. Have mathematical structures equipped with generalized relations been considered in a systematic way? A reference would be nice. Discussion . Here's the example I am most interested in. Suppose $X$ and $Y$ are sets, and that $R$ is a binary relation on $Y$. That is, $R$ is a function $Y \times Y \rightarrow \mathbb{B}$. Then the family $Y^X$ can naturally be equipped with a generalized binary relation $R' : Y^X \times Y^X \rightarrow \mathbb{B}^X$ defined by asserting that $R'(f,g)$ equals the characteristic function of $$\{x \in X \mid R(f(x),g(x))\}.$$ Anyway, the point is that if $\mathcal{Y} = (Y,R)$ is a relational structure, then really $\mathcal{Y}^X$ is most naturally viewed as equipped not with a relation $R'$ having codomain $\mathbb{B}$, but rather a generalized relation having codomain $\mathbb{B}^X.$ We might call such a beast a ""generalized relational structure."" Metric spaces presumably undergo a similar generalization, although I'm still trying to work out the details.","A binary relation on $X$ is basically just a function $X^2 \rightarrow \mathbb{B}$, where $\mathbb{B}$ is the prototypical Boolean algebra $\{0,1\}.$ We can generalize by replacing $\mathbb{B}$ with a more complicated partially ordered structure. Thus, we have: Heuristic idea. A generalized relation on $X$ is a function $X^n \rightarrow P$, where $P$ is a partially ordered set possibly having additional structure. For example, a metric space can be viewed as set $X$ equipped with a generalized relation $d : X^2 \rightarrow [0,\infty)$ satisfying the usual axioms. Question. Have mathematical structures equipped with generalized relations been considered in a systematic way? A reference would be nice. Discussion . Here's the example I am most interested in. Suppose $X$ and $Y$ are sets, and that $R$ is a binary relation on $Y$. That is, $R$ is a function $Y \times Y \rightarrow \mathbb{B}$. Then the family $Y^X$ can naturally be equipped with a generalized binary relation $R' : Y^X \times Y^X \rightarrow \mathbb{B}^X$ defined by asserting that $R'(f,g)$ equals the characteristic function of $$\{x \in X \mid R(f(x),g(x))\}.$$ Anyway, the point is that if $\mathcal{Y} = (Y,R)$ is a relational structure, then really $\mathcal{Y}^X$ is most naturally viewed as equipped not with a relation $R'$ having codomain $\mathbb{B}$, but rather a generalized relation having codomain $\mathbb{B}^X.$ We might call such a beast a ""generalized relational structure."" Metric spaces presumably undergo a similar generalization, although I'm still trying to work out the details.",,"['abstract-algebra', 'reference-request', 'logic']"
83,"Smallest normal subgroup making quotient abelian, nilpotent, solvable","Smallest normal subgroup making quotient abelian, nilpotent, solvable",,"Given a finite group $G$ that is not abelian, nilpotent, or solvable, what is the smallest normal subgroup $H$ in each case such that $G/H$ is abelian, nilpotent, or solvable (respectively)? In the abelian case it seems clear that the correct subgroup is the commutator subgroup. But what of the other two? Perhaps I'm just shaky with the concepts (of nilpotency and solvability) but I'm having trouble finding the right way to tackle this problem. Edit: Well I've tried the most obvious thing and it worked out. For the nilpotent case I took the intersection of all the subgroups in the lower central series, and for the solvable case I took the intersection of all subgroups in the derived/commutator series.","Given a finite group $G$ that is not abelian, nilpotent, or solvable, what is the smallest normal subgroup $H$ in each case such that $G/H$ is abelian, nilpotent, or solvable (respectively)? In the abelian case it seems clear that the correct subgroup is the commutator subgroup. But what of the other two? Perhaps I'm just shaky with the concepts (of nilpotency and solvability) but I'm having trouble finding the right way to tackle this problem. Edit: Well I've tried the most obvious thing and it worked out. For the nilpotent case I took the intersection of all the subgroups in the lower central series, and for the solvable case I took the intersection of all subgroups in the derived/commutator series.",,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
84,How to use flatness here?,How to use flatness here?,,"Let $X\to S$ be a scheme. Definition: A relative effective Cartier divisor on $X/S$ is a closed subscheme $D\subset X$ such that the ideal sheaf $I$ of $D$ is invertible and $D\to S$ is flat. Let now $T\to S$ be another scheme over $S$ and denote by $X_T$ the fibered product $X\times_S T$. I read on a paper the following: Claim: Let $D$ be a relative effective Cartier divisor on $X_T/T$ and $p:T'\to T$ be an arbitrary $S$-map of schemes. Then the pullback $p^*_{X_T}(I)$ is the ideal sheaf of the $T'$-flat closed subscheme $D_{T'}\subset X_{T'}$. Hence $D_{T'}$ is a relative effective Cartier divisor on $X_{T'}/T'$. Can you please help me proving the claim? In particular, the author says: Since $D$ is $T$-flat, $p^*_{X_T} (I)$ is equal to the ideal of $D_{T'}$ And I don't understand why.","Let $X\to S$ be a scheme. Definition: A relative effective Cartier divisor on $X/S$ is a closed subscheme $D\subset X$ such that the ideal sheaf $I$ of $D$ is invertible and $D\to S$ is flat. Let now $T\to S$ be another scheme over $S$ and denote by $X_T$ the fibered product $X\times_S T$. I read on a paper the following: Claim: Let $D$ be a relative effective Cartier divisor on $X_T/T$ and $p:T'\to T$ be an arbitrary $S$-map of schemes. Then the pullback $p^*_{X_T}(I)$ is the ideal sheaf of the $T'$-flat closed subscheme $D_{T'}\subset X_{T'}$. Hence $D_{T'}$ is a relative effective Cartier divisor on $X_{T'}/T'$. Can you please help me proving the claim? In particular, the author says: Since $D$ is $T$-flat, $p^*_{X_T} (I)$ is equal to the ideal of $D_{T'}$ And I don't understand why.",,"['algebraic-geometry', 'schemes', 'abstract-algebra']"
85,Principal ideal of an integrally closed domain,Principal ideal of an integrally closed domain,,Let $R$ be an integrally closed domain and $S$ be an integral domain that contains $R$. Assume that $a\in S$ is integral over $R$. Prove that $I=\left\{ f\left(x\right)\in R\left[x\right]\mid f\left(a\right)=0\right\} $ is a principal ideal of $R[x].$ I only know that $R[x]$ is also an integrally closed integral domain and $a$ is a root of a monic polynomial of $R[x]$. So if $g(x)$ is a monic polynomial of $R[x]$ then $g(a)=0$. Help me a hint. Thank for any insight.,Let $R$ be an integrally closed domain and $S$ be an integral domain that contains $R$. Assume that $a\in S$ is integral over $R$. Prove that $I=\left\{ f\left(x\right)\in R\left[x\right]\mid f\left(a\right)=0\right\} $ is a principal ideal of $R[x].$ I only know that $R[x]$ is also an integrally closed integral domain and $a$ is a root of a monic polynomial of $R[x]$. So if $g(x)$ is a monic polynomial of $R[x]$ then $g(a)=0$. Help me a hint. Thank for any insight.,,"['abstract-algebra', 'commutative-algebra', 'integral-domain']"
86,Number of elements of group with specific order,Number of elements of group with specific order,,"Consider the group $(G,\cdot)$ where $$G=\left\{\left(\begin{matrix}1&a\\0&b\end{matrix}\right):a,b\in\mathbb{R}, b\neq0\right\}.$$ How many members of $G$ have order 2? My Attemt A member $M$ of $G$ will have order two iff $M^2=I$. I.e. $$\left(\begin{matrix}1&a\\0&b\end{matrix}\right)^2=\left(\begin{matrix}1&a+ab\\0&b^2\end{matrix}\right)=I.$$This is true for $b=1$ and $a=0$ in which case $M=I$ or in the case $b=-1$ and $a$ is any real. Hence, there is an infinite number of elements with order 2 in $G$. Can somebody please verify that this is true?","Consider the group $(G,\cdot)$ where $$G=\left\{\left(\begin{matrix}1&a\\0&b\end{matrix}\right):a,b\in\mathbb{R}, b\neq0\right\}.$$ How many members of $G$ have order 2? My Attemt A member $M$ of $G$ will have order two iff $M^2=I$. I.e. $$\left(\begin{matrix}1&a\\0&b\end{matrix}\right)^2=\left(\begin{matrix}1&a+ab\\0&b^2\end{matrix}\right)=I.$$This is true for $b=1$ and $a=0$ in which case $M=I$ or in the case $b=-1$ and $a$ is any real. Hence, there is an infinite number of elements with order 2 in $G$. Can somebody please verify that this is true?",,['abstract-algebra']
87,Examples of a non-commutative division ring,Examples of a non-commutative division ring,,What are some examples of a non-commutative division ring other than quaternions?,What are some examples of a non-commutative division ring other than quaternions?,,"['abstract-algebra', 'ring-theory', 'quaternions']"
88,The Zig Zag Lemma in Cohomology,The Zig Zag Lemma in Cohomology,,"I´m reading the Zig Zag lemma in Cohomology and i want to prove the exactness of cohomology sequence at $ H^k(A)$ and $H^k(B)$ : A short exact sequence of cochain complexes $ 0 \to A \ \xrightarrow{i} \ B \ \xrightarrow{j} \ C \to 0$ gives rise to a long exact sequence in cohomology: $ ... \ \xrightarrow{j^*} \ H^{k-1}(C) \ \xrightarrow{d^*} \ H^k(A) \ \xrightarrow{i^*} H^k(B) \ \xrightarrow{j^*} H^k(C) \ \xrightarrow{d^*} H^{k+1}(A) \ \xrightarrow{i^*} ...$ where $i^∗$ and $j^∗$ are the maps in cohomology induced from the cochain maps i and j,and $d^∗$ is the connecting homomorphism. I think first i need to prove that $im(d^∗) = ker(i^∗)$ for exactness in $H^k(A)$ . Help please….. I prove the exactness of $H^k(C)$: First I prove that $im( j^*)\subseteq ker (d^*)$.  Let $[b]\in H^k(B) $ then $d^* j^* [b] = d^*[j(b)]$.  In the recipe above for $d^*$ , we can choose the element in $B^k$ that maps to $j(b)$ to be b. Then $db \in B^{k+1}$. Because b is a cocycle, $db=0$. Following the Zig-Zag diagram we see that since $i(0) = 0 = db$, we must have  $d^*[j(b)] = [0]$, so $j^*[b]\in ker(d^*)$. The other way, i.e., $ker(d^*) \subseteq im(j^*)$:  suppose $d^*[c] = [a]=0$, where  $[c] \in H^k(C) $, this means that $a=da´$ for some $ a´ \in A^k$.i calculate the $d^*$ again by the diagram and take an element $ b \in B^k$with $j(b) = c$ and $i(a) = db$. Then $b - i(a´)$ is a cocycle in $B^k$ that maps to c under j: $d(b - i(a´)) = db-di(a´) = db - id(a´) = db - ia = 0$, $j(b - i(a´)) = db-ji(a´) = j(b) = c$ Therefore, $ j^*[b - i(a´)]= [c]$.","I´m reading the Zig Zag lemma in Cohomology and i want to prove the exactness of cohomology sequence at $ H^k(A)$ and $H^k(B)$ : A short exact sequence of cochain complexes $ 0 \to A \ \xrightarrow{i} \ B \ \xrightarrow{j} \ C \to 0$ gives rise to a long exact sequence in cohomology: $ ... \ \xrightarrow{j^*} \ H^{k-1}(C) \ \xrightarrow{d^*} \ H^k(A) \ \xrightarrow{i^*} H^k(B) \ \xrightarrow{j^*} H^k(C) \ \xrightarrow{d^*} H^{k+1}(A) \ \xrightarrow{i^*} ...$ where $i^∗$ and $j^∗$ are the maps in cohomology induced from the cochain maps i and j,and $d^∗$ is the connecting homomorphism. I think first i need to prove that $im(d^∗) = ker(i^∗)$ for exactness in $H^k(A)$ . Help please….. I prove the exactness of $H^k(C)$: First I prove that $im( j^*)\subseteq ker (d^*)$.  Let $[b]\in H^k(B) $ then $d^* j^* [b] = d^*[j(b)]$.  In the recipe above for $d^*$ , we can choose the element in $B^k$ that maps to $j(b)$ to be b. Then $db \in B^{k+1}$. Because b is a cocycle, $db=0$. Following the Zig-Zag diagram we see that since $i(0) = 0 = db$, we must have  $d^*[j(b)] = [0]$, so $j^*[b]\in ker(d^*)$. The other way, i.e., $ker(d^*) \subseteq im(j^*)$:  suppose $d^*[c] = [a]=0$, where  $[c] \in H^k(C) $, this means that $a=da´$ for some $ a´ \in A^k$.i calculate the $d^*$ again by the diagram and take an element $ b \in B^k$with $j(b) = c$ and $i(a) = db$. Then $b - i(a´)$ is a cocycle in $B^k$ that maps to c under j: $d(b - i(a´)) = db-di(a´) = db - id(a´) = db - ia = 0$, $j(b - i(a´)) = db-ji(a´) = j(b) = c$ Therefore, $ j^*[b - i(a´)]= [c]$.",,"['abstract-algebra', 'homological-algebra', 'group-cohomology', 'exact-sequence']"
89,"$H\leq Z(G)$ for a normal Subgroup $H\leq G$ Dummit Foote 4.4.12,13,14","for a normal Subgroup  Dummit Foote 4.4.12,13,14",H\leq Z(G) H\leq G,"Title is More General (which may not be true) But the Question is : Let $G$ be a Group of order $3825$. Prove that if $H\unlhd G$with $|H|=17$ then $H\leq Z(G)$. what i have done so far is $3825=17\times 3^2\times 5^2$. As $H\unlhd G$ we see that $N_G(H)=G$ and by a result stating $N_G(H)/C_G(H)\text {is isomorphic to a subgroup of }Aut(H)$ we see that $G/C_G(H)$ is isomorphic to subgroup of $Aut(H)$. As $H$ is of prime order it is cyclic, So, $|Aut(H)|=16$ As $C_G(H)$ is a subgroup of $G$, $|C_G(H)|$ divides $|G|$ and with the condition $|G/C_G(H)|$ divides $16$, i.e., some factor of $16$ divides $|G/C_G(H)|$ and $(16,3825)=1$ Thus $C_G(H)=G$ and so i conclude $H\leq Z(G)$ Please let me know if my approach can be reduced to a simpler approach. and I would like to look for a generalization of this : If $G$ has a Normal Group of prime order $p$ and no factor of $|G|$ divides $p-1$ then $H\leq Z(G)$. I would like to see if this is correct? I feel it is correct But Just for a clarification. please help me with this. Thank You","Title is More General (which may not be true) But the Question is : Let $G$ be a Group of order $3825$. Prove that if $H\unlhd G$with $|H|=17$ then $H\leq Z(G)$. what i have done so far is $3825=17\times 3^2\times 5^2$. As $H\unlhd G$ we see that $N_G(H)=G$ and by a result stating $N_G(H)/C_G(H)\text {is isomorphic to a subgroup of }Aut(H)$ we see that $G/C_G(H)$ is isomorphic to subgroup of $Aut(H)$. As $H$ is of prime order it is cyclic, So, $|Aut(H)|=16$ As $C_G(H)$ is a subgroup of $G$, $|C_G(H)|$ divides $|G|$ and with the condition $|G/C_G(H)|$ divides $16$, i.e., some factor of $16$ divides $|G/C_G(H)|$ and $(16,3825)=1$ Thus $C_G(H)=G$ and so i conclude $H\leq Z(G)$ Please let me know if my approach can be reduced to a simpler approach. and I would like to look for a generalization of this : If $G$ has a Normal Group of prime order $p$ and no factor of $|G|$ divides $p-1$ then $H\leq Z(G)$. I would like to see if this is correct? I feel it is correct But Just for a clarification. please help me with this. Thank You",,['abstract-algebra']
90,Every principal ideal domain satisfies ACCP.,Every principal ideal domain satisfies ACCP.,,"Every principal ideal domain $D$ satisfies ACCP (ascending chain condition on principal ideals) Proof. Let $(a_1) ⊆ (a_2) ⊆ (a_3) ⊆ · · ·$ be a chain of principal ideals in $D$ . It can be easily verified that $I = \displaystyle{∪_{i∈N} (a_i)}$ is an ideal of $D$ . Since $D$ is a PID, there exists an element $a ∈ D$ such that $ I = (a)$ . Hence, $a ∈ (a_n)$ for some positive integer $n$ . Then $I ⊆ (a_n) ⊆ I$ . Therefore, $I = a_n$ . For $t ≥ n$ , $(a_t) ⊆ I = (a_n) ⊆ (a_t)$ . Thus, $(a_n) = (a_t)$ for all $t ≥ n$ . I have prove $I$ is an ideal in the following way:- Let $ x,y\in I$ . Then there exist $i,j \in \mathbb{N}$ s.t. $x \in (a_i)$ & $y \in (a_j)$ . Let $k \in \mathbb{N}$ s.t $k>i,j$ . Then $x \in (a_k)$ & $y \in (a_k)$ . as $(a_k)$ is an ideal $x-y \in (a_k)\subset I$ and $rx,xr \in (a_k)\subset I$ . So $I$ is an ideal. Is it correct?","Every principal ideal domain satisfies ACCP (ascending chain condition on principal ideals) Proof. Let be a chain of principal ideals in . It can be easily verified that is an ideal of . Since is a PID, there exists an element such that . Hence, for some positive integer . Then . Therefore, . For , . Thus, for all . I have prove is an ideal in the following way:- Let . Then there exist s.t. & . Let s.t . Then & . as is an ideal and . So is an ideal. Is it correct?","D (a_1) ⊆ (a_2) ⊆ (a_3) ⊆ · · · D I = \displaystyle{∪_{i∈N} (a_i)} D D a ∈ D  I = (a) a ∈ (a_n) n I ⊆ (a_n) ⊆ I I = a_n t ≥ n (a_t) ⊆ I = (a_n) ⊆ (a_t) (a_n) = (a_t) t ≥ n I  x,y\in I i,j \in \mathbb{N} x \in (a_i) y \in (a_j) k \in \mathbb{N} k>i,j x \in (a_k) y \in (a_k) (a_k) x-y \in (a_k)\subset I rx,xr \in (a_k)\subset I I","['abstract-algebra', 'ring-theory', 'principal-ideal-domains']"
91,Abstract algebra T/F questions.,Abstract algebra T/F questions.,,"This is from our review and my study group is wondering if we can get some feedback on our progress: $1$. The symmetric group $S_3$ only has two proper normal subgroups. True, because $e \subset A_3 \subset S_3$. $2$. Every abelian group is cyclic. False, every cyclic group is abelian but the converse is not true OR a counter example is a Klein-4 group. $3$. The ideal generated by $x^2+1$ in $\mathbb{R}[x]$ is maximal. True. Every ideal generated by irreducible element in principal domain is maximal. $4$. The order of the cycle $(a_1, \cdots, a_k) \in S_n$ is $k$. False. The order should be $k-1$. $5$. Let $f: R \to S$ be a ring homomorphism, and $I \subset S$ a maximal ideal. Then $f^{-1}(I)$ is maximal. True. Because isomorphism preserves ring properties (honestly no idea how to do this one).","This is from our review and my study group is wondering if we can get some feedback on our progress: $1$. The symmetric group $S_3$ only has two proper normal subgroups. True, because $e \subset A_3 \subset S_3$. $2$. Every abelian group is cyclic. False, every cyclic group is abelian but the converse is not true OR a counter example is a Klein-4 group. $3$. The ideal generated by $x^2+1$ in $\mathbb{R}[x]$ is maximal. True. Every ideal generated by irreducible element in principal domain is maximal. $4$. The order of the cycle $(a_1, \cdots, a_k) \in S_n$ is $k$. False. The order should be $k-1$. $5$. Let $f: R \to S$ be a ring homomorphism, and $I \subset S$ a maximal ideal. Then $f^{-1}(I)$ is maximal. True. Because isomorphism preserves ring properties (honestly no idea how to do this one).",,"['abstract-algebra', 'group-theory', 'ring-theory']"
92,Recovering Hopf Algebra from Group-Like Elements,Recovering Hopf Algebra from Group-Like Elements,,"Given the natural coalgebra structure on a group algebra $kG$, one can recover the group by taking the set of group-like elements of the coalgebra $kG$. When can you go the other way? In particular, given a Hopf algebra $H$, under what conditions can one recover the structure of $H$ from it's group of group-like elements? I'm also curious as to how the answer differs if $H$ is finitely generated versus finite dimensional. Thanks!","Given the natural coalgebra structure on a group algebra $kG$, one can recover the group by taking the set of group-like elements of the coalgebra $kG$. When can you go the other way? In particular, given a Hopf algebra $H$, under what conditions can one recover the structure of $H$ from it's group of group-like elements? I'm also curious as to how the answer differs if $H$ is finitely generated versus finite dimensional. Thanks!",,"['abstract-algebra', 'group-theory', 'hopf-algebras', 'coalgebras']"
93,Isomorphism of Direct Product of Groups,Isomorphism of Direct Product of Groups,,"I have $H_1,H_2,\dots, H_n$ groups with the property $H_i\cong G_i$, where $G_1,\dots,G_n$ are also groups. It should be somehow easily followed that $G_1\times \dots\times G_n\cong H_1\times \dots\times H_n$. I would define a function $\phi:G_1\times\dots\times G_n\to H_1\times \dots\times H_n$ where $\phi(g)_i=h_i$ and prove that it is an bijective homomorphism which should be clear for that function, but is this enough?","I have $H_1,H_2,\dots, H_n$ groups with the property $H_i\cong G_i$, where $G_1,\dots,G_n$ are also groups. It should be somehow easily followed that $G_1\times \dots\times G_n\cong H_1\times \dots\times H_n$. I would define a function $\phi:G_1\times\dots\times G_n\to H_1\times \dots\times H_n$ where $\phi(g)_i=h_i$ and prove that it is an bijective homomorphism which should be clear for that function, but is this enough?",,['abstract-algebra']
94,Computable Criteria to check whether a given basis is a Gröbner Basis,Computable Criteria to check whether a given basis is a Gröbner Basis,,"In an upcoming exam we have to do Gröbnber-Basis computation with Buchberger's algorithm. A typical example looks like this: $$ \langle f_1,f_2 \rangle $$ Then I compute the S-Polynomial $S(f_1,f_2)$. Most of the time $S(f_1,f_2)$ is an ugly expression so I use linear combinations of $\langle f_1, f_2, S(f_1,f_2)\rangle$ and obtain a new representation of the ideal with nice polynomials $\langle f_1',f_2',f_3' \rangle$. Now, I have to restart Buchberger's algorithm because I have changed the ideal representation and compute $S(f_1',f_2'), S(f_1',f_3') \dots$. Usually $\langle f_1',f_2',f_3' \rangle$ is a valid Gröber basis already. But to compute the three (or more) S-Polynomials takes a lot of time. Is there are a  (fast computable) criteria to check whether a given basis is already a Gröbner-Basis and to abort the computation?","In an upcoming exam we have to do Gröbnber-Basis computation with Buchberger's algorithm. A typical example looks like this: $$ \langle f_1,f_2 \rangle $$ Then I compute the S-Polynomial $S(f_1,f_2)$. Most of the time $S(f_1,f_2)$ is an ugly expression so I use linear combinations of $\langle f_1, f_2, S(f_1,f_2)\rangle$ and obtain a new representation of the ideal with nice polynomials $\langle f_1',f_2',f_3' \rangle$. Now, I have to restart Buchberger's algorithm because I have changed the ideal representation and compute $S(f_1',f_2'), S(f_1',f_3') \dots$. Usually $\langle f_1',f_2',f_3' \rangle$ is a valid Gröber basis already. But to compute the three (or more) S-Polynomials takes a lot of time. Is there are a  (fast computable) criteria to check whether a given basis is already a Gröbner-Basis and to abort the computation?",,"['abstract-algebra', 'polynomials', 'groebner-basis']"
95,How to prove that a mapping is homomorphic,How to prove that a mapping is homomorphic,,"Let $ f:(A, \cdot) \to (B, \ast) $ and $g:(B,\ast) \to (C,\times)$ be Operation preserving maps. Then I must prove that $ g \circ f$ is an operation preserving map too.  This is what I have so far: Since $f$ is a homomorphism $(A, \cdot)$ and $(B, \ast)$ are groups and $ f(x \cdot y)=f(x)\ast f(y)$ Since $(C,\times)$ is a group so $g(f(x)\ast (f(y))=g(f(x)) \times g(f(y))$. Hence $ g\circ f$ is homomorphic.","Let $ f:(A, \cdot) \to (B, \ast) $ and $g:(B,\ast) \to (C,\times)$ be Operation preserving maps. Then I must prove that $ g \circ f$ is an operation preserving map too.  This is what I have so far: Since $f$ is a homomorphism $(A, \cdot)$ and $(B, \ast)$ are groups and $ f(x \cdot y)=f(x)\ast f(y)$ Since $(C,\times)$ is a group so $g(f(x)\ast (f(y))=g(f(x)) \times g(f(y))$. Hence $ g\circ f$ is homomorphic.",,['abstract-algebra']
96,Showing an ideal is prime in polynomial ring,Showing an ideal is prime in polynomial ring,,"Let $k=\mathbb{C}$ and let $J$ the ideal $(xw-yz,y^{3}-x^{2}z,z^{3}-yw^{2},y^{2}w-xz^{2})$. I want to see why $J$ is a prime ideal in $k[x,y,z,w]$. I know that $Z(J)$ (the zero set of $J$) is exactly the image of the $4$-fold Veronese embedding from $\mathbb{P}^{1}$ to $\mathbb{P}^{3}$, i.e., the map given by $[s : t] \mapsto [s^{4}: s^{3}t : st^{3}: t^{4}]$. What I tried: if we consider the following ring homomomorphism: $k[x,y,z,w] \rightarrow k[s,t]$ given by $x \mapsto s^{4}$, $y \mapsto s^{3}t$, $z \mapsto st^{3}$ and $w \mapsto t^{4}$, then one can check that $J$ is contained in the kernel of this ring homomorphism. Now if we can show the the other inclusion we are done because then $k[x,y,z,w]/J$ embeds a subring of $k[s,t]$ and hence $J$ is prime. However I don't see the other inclusion, can you please help? Perhaps there's an easier way.","Let $k=\mathbb{C}$ and let $J$ the ideal $(xw-yz,y^{3}-x^{2}z,z^{3}-yw^{2},y^{2}w-xz^{2})$. I want to see why $J$ is a prime ideal in $k[x,y,z,w]$. I know that $Z(J)$ (the zero set of $J$) is exactly the image of the $4$-fold Veronese embedding from $\mathbb{P}^{1}$ to $\mathbb{P}^{3}$, i.e., the map given by $[s : t] \mapsto [s^{4}: s^{3}t : st^{3}: t^{4}]$. What I tried: if we consider the following ring homomomorphism: $k[x,y,z,w] \rightarrow k[s,t]$ given by $x \mapsto s^{4}$, $y \mapsto s^{3}t$, $z \mapsto st^{3}$ and $w \mapsto t^{4}$, then one can check that $J$ is contained in the kernel of this ring homomorphism. Now if we can show the the other inclusion we are done because then $k[x,y,z,w]/J$ embeds a subring of $k[s,t]$ and hence $J$ is prime. However I don't see the other inclusion, can you please help? Perhaps there's an easier way.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'ideals']"
97,"If $\varphi: F_n\to F_n/[F_n,F_n]$ is onto, then there exists  $\Phi:\mathrm{Aut}(F_n)\to \mathrm{Aut} (F_n/[F_n,F_n])$. Why?","If  is onto, then there exists  . Why?","\varphi: F_n\to F_n/[F_n,F_n] \Phi:\mathrm{Aut}(F_n)\to \mathrm{Aut} (F_n/[F_n,F_n])","My question is the following: Let $G:=F_n$ If we look at the commutator subgroup $[G,G]$ of $G$, we get the canonical epimorphism $\varphi: G\to G/[G,G]$ Since $[G,G]$ is characteristic in $G$, we know that $Aut(G)$ acts in a natural way on the factor group $G/[G,G]$ and we get a map: $\Phi:\mathrm{Aut}(G)\to \mathrm{Aut} (G/[G,G]);\alpha(g) \mapsto \bar{\alpha}(g*[G,G]):=\alpha(g)*[G,G]$ But how can I show that $\Phi$ is an epimorphism ? Added. When I was asking the question we were in the general case, where $G$ is an arbitrary group. Because of some answers, I edited the question into the case, where $G=F_n$, the free group of rank $n$. Thanks to the last comment, I now know that there is a solution in the book ""Combinatorial Group Theory"" from Magnus. I don't have the book beside me. So does someone knows a proof for the existence of the epimorphism $\Phi$.  I think, if we assume that $Aut(F_n)$ is generated by the right nielsen transformations, we only have to show that $Aut(F_n/[F_n,F_n])$ is generated by these trasnformations, since we know that every $\alpha\in Aut(F_n)$ induces an $\bar{\alpha}\in Aut(F_n/[F_n,F_n])$. Is this true? And how can we get this?","My question is the following: Let $G:=F_n$ If we look at the commutator subgroup $[G,G]$ of $G$, we get the canonical epimorphism $\varphi: G\to G/[G,G]$ Since $[G,G]$ is characteristic in $G$, we know that $Aut(G)$ acts in a natural way on the factor group $G/[G,G]$ and we get a map: $\Phi:\mathrm{Aut}(G)\to \mathrm{Aut} (G/[G,G]);\alpha(g) \mapsto \bar{\alpha}(g*[G,G]):=\alpha(g)*[G,G]$ But how can I show that $\Phi$ is an epimorphism ? Added. When I was asking the question we were in the general case, where $G$ is an arbitrary group. Because of some answers, I edited the question into the case, where $G=F_n$, the free group of rank $n$. Thanks to the last comment, I now know that there is a solution in the book ""Combinatorial Group Theory"" from Magnus. I don't have the book beside me. So does someone knows a proof for the existence of the epimorphism $\Phi$.  I think, if we assume that $Aut(F_n)$ is generated by the right nielsen transformations, we only have to show that $Aut(F_n/[F_n,F_n])$ is generated by these trasnformations, since we know that every $\alpha\in Aut(F_n)$ induces an $\bar{\alpha}\in Aut(F_n/[F_n,F_n])$. Is this true? And how can we get this?",,"['abstract-algebra', 'group-theory', 'geometric-group-theory']"
98,Inverse of the Grothendieck group construction?,Inverse of the Grothendieck group construction?,,"Is there an ""inverse"" of the Grothendieck group construction that would generate a (somehow ""simplest"") Abelian semigroup given some (suitably qualified, if necessary) Abelian group?  (I realize that any Abelian group is already an Abelian semigroup, but this is not very satisfying...  I'm trying to get at the ""simplest"" semigroup that will generate a given Abelian group when one applies the Grothendieck construction to it.  So this ""reverse construction"" should, e.g., yield $\mathbf{N}^+$ (i.e. the positive integers) when applied to $\mathbf{Z}$, not simply produce $\mathbf{Z}$  back.) Thx EDIT2: Please read the comments on this post by Theo and Arturo before spending any time on it; it looks like the wording of my question is not right, but I'll need to do some more research to fix it... EDIT: As I wrote in a comment below, this question was motivated by a passing remark I came across about a ""well-known"" one-to-one correspondence between cancellative Abelian semigroups and ordered Abelian groups.  Judging from the brief, informal account I read of this correspondence, it looked to me like the semigroup $\to$ group half was just the construction of the Grothendieck group from the semigroup, although it was not explicitly named as such.  And since this correspondence was described as being bijective, I figured that there may be an inverse construction, which, at least in this special case (partially ordered Abelian group $\to$ cancellative Abelian semigroup), could be construed as a sort of inverse of the Grothendieck group construction.  The citation given for all this is a 1940 paper by Clifford, which I don't have access to (beyond the first page), and even if I did, it may not be of much help to me, since its abstract states that the paper gives no proofs, and instead refers the reader to another paper (which I think is this one ), even further out of my reach, and in German, a language I can read only with a lot of help from the dictionary...","Is there an ""inverse"" of the Grothendieck group construction that would generate a (somehow ""simplest"") Abelian semigroup given some (suitably qualified, if necessary) Abelian group?  (I realize that any Abelian group is already an Abelian semigroup, but this is not very satisfying...  I'm trying to get at the ""simplest"" semigroup that will generate a given Abelian group when one applies the Grothendieck construction to it.  So this ""reverse construction"" should, e.g., yield $\mathbf{N}^+$ (i.e. the positive integers) when applied to $\mathbf{Z}$, not simply produce $\mathbf{Z}$  back.) Thx EDIT2: Please read the comments on this post by Theo and Arturo before spending any time on it; it looks like the wording of my question is not right, but I'll need to do some more research to fix it... EDIT: As I wrote in a comment below, this question was motivated by a passing remark I came across about a ""well-known"" one-to-one correspondence between cancellative Abelian semigroups and ordered Abelian groups.  Judging from the brief, informal account I read of this correspondence, it looked to me like the semigroup $\to$ group half was just the construction of the Grothendieck group from the semigroup, although it was not explicitly named as such.  And since this correspondence was described as being bijective, I figured that there may be an inverse construction, which, at least in this special case (partially ordered Abelian group $\to$ cancellative Abelian semigroup), could be construed as a sort of inverse of the Grothendieck group construction.  The citation given for all this is a 1940 paper by Clifford, which I don't have access to (beyond the first page), and even if I did, it may not be of much help to me, since its abstract states that the paper gives no proofs, and instead refers the reader to another paper (which I think is this one ), even further out of my reach, and in German, a language I can read only with a lot of help from the dictionary...",,"['abstract-algebra', 'group-theory', 'semigroups', 'grothendieck-construction']"
99,"Best approximation of an irrational number by primes $2,3,5,7$",Best approximation of an irrational number by primes,"2,3,5,7","Let $G$ be the multiplicative group $(\mathbb{R}_+,\cdot)$ , which is the positive real numbers equipped with the usual distance. Let $P$ be the subgroup of $G$ generated by $2,3,5,7$ , i.e. $$P = \bigcup\limits_{n=1}^\infty\{2,3,5,7,\frac12,\frac13,\frac15\frac17\}^n$$ I have a few questions. Is the subgroup $P$ dense in $(\mathbb{R}_+,\cdot)$ ? What is the best approximation of $\sqrt2$ or $\pi$ in $P$ given the constraint that, for example, the total number of primes used is less than $1000$ ? I'm allowed only to use $2,3,5,7$ and no more. I know that a nontrivial additive subgroup of $(\mathbb R,+)$ is either dense or discrete, so we can transform $2,3,5,7$ into $\log 2,\log3,\log5,\log7$ and consider the subgroup of $(\mathbb R,+)$ generated by $\log 2,\log3,\log5,\log7$ , which I believe is dense. Then we can approximate $\log \sqrt2=\frac12\log2$ by an integer combination of these elements. However, I've done some simulations and the best approximation I can find is $\frac{7^3}{3^5}\approx 1.411522633744856$ , which makes me suspect it is not dense. Where did I go wrong? Does there exist an algorithm for finding such combinations? Edit: I just found out that $\sqrt2$ is a very special case because $\log\sqrt2=\frac12\log2$ . What if I want to approximate $\pi$ ? I used @lulu's method and got $$3^a=2^b\pi\implies a\log3=b\log2+\log\pi\implies \frac{a}{b+\frac{\log\pi}{\log2}}=\frac{\log2}{\log3}$$ Or I want to use all of $2,3,5,7$ . $$2^a3^b5^c7^d=\sqrt2$$ $$a\log2+b\log3+c\log5+d\log7=\frac12\log2$$ $$2b\log3+2c\log5+2d\log7=(1-2a)\log2$$ $$\frac{2b+2\frac{\log5}{\log3}c+2\frac{\log7}{\log3}d}{1-2a}=\frac{\log2}{\log3}$$ but I couldn't proceed.","Let be the multiplicative group , which is the positive real numbers equipped with the usual distance. Let be the subgroup of generated by , i.e. I have a few questions. Is the subgroup dense in ? What is the best approximation of or in given the constraint that, for example, the total number of primes used is less than ? I'm allowed only to use and no more. I know that a nontrivial additive subgroup of is either dense or discrete, so we can transform into and consider the subgroup of generated by , which I believe is dense. Then we can approximate by an integer combination of these elements. However, I've done some simulations and the best approximation I can find is , which makes me suspect it is not dense. Where did I go wrong? Does there exist an algorithm for finding such combinations? Edit: I just found out that is a very special case because . What if I want to approximate ? I used @lulu's method and got Or I want to use all of . but I couldn't proceed.","G (\mathbb{R}_+,\cdot) P G 2,3,5,7 P = \bigcup\limits_{n=1}^\infty\{2,3,5,7,\frac12,\frac13,\frac15\frac17\}^n P (\mathbb{R}_+,\cdot) \sqrt2 \pi P 1000 2,3,5,7 (\mathbb R,+) 2,3,5,7 \log 2,\log3,\log5,\log7 (\mathbb R,+) \log 2,\log3,\log5,\log7 \log \sqrt2=\frac12\log2 \frac{7^3}{3^5}\approx 1.411522633744856 \sqrt2 \log\sqrt2=\frac12\log2 \pi 3^a=2^b\pi\implies a\log3=b\log2+\log\pi\implies \frac{a}{b+\frac{\log\pi}{\log2}}=\frac{\log2}{\log3} 2,3,5,7 2^a3^b5^c7^d=\sqrt2 a\log2+b\log3+c\log5+d\log7=\frac12\log2 2b\log3+2c\log5+2d\log7=(1-2a)\log2 \frac{2b+2\frac{\log5}{\log3}c+2\frac{\log7}{\log3}d}{1-2a}=\frac{\log2}{\log3}","['abstract-algebra', 'group-theory', 'number-theory', 'approximation']"
