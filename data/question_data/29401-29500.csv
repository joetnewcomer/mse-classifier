,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Solitaire probability,Solitaire probability,,"I would like to know the exact probability of the following game. I start counting from one to 13 and do this totally four times. On each turn I say a number and turn a card from a deck. Ace is considered to be as 1. If on one turn I say the same number as it is on the card, I lose. What is my winning probability?","I would like to know the exact probability of the following game. I start counting from one to 13 and do this totally four times. On each turn I say a number and turn a card from a deck. Ace is considered to be as 1. If on one turn I say the same number as it is on the card, I lose. What is my winning probability?",,['probability']
1,Conditional probability that a rotated inner product is zero,Conditional probability that a rotated inner product is zero,,"Consider a two random vectors $v=v_1,\dots, v_n$ and $w=w_1,\dots, w_n$, each of $n$ elements, each of which is independently $\pm1$ with prob $1/2$ .  Let $n$ be even and let $X$ be the inner product of $v$ and $w$. We know: $$P(X = 0) =  {n \choose n/2} \frac{1}{2^n}.$$ Now let $Y$ be the inner product of $v$ and the vector $z=w_2,\dots,w_n, w_1$. What is $P(Y=0|X=0)$?","Consider a two random vectors $v=v_1,\dots, v_n$ and $w=w_1,\dots, w_n$, each of $n$ elements, each of which is independently $\pm1$ with prob $1/2$ .  Let $n$ be even and let $X$ be the inner product of $v$ and $w$. We know: $$P(X = 0) =  {n \choose n/2} \frac{1}{2^n}.$$ Now let $Y$ be the inner product of $v$ and the vector $z=w_2,\dots,w_n, w_1$. What is $P(Y=0|X=0)$?",,[]
2,Why do knowers of Bayes's Theorem still commit the Base Rate Fallacy?,Why do knowers of Bayes's Theorem still commit the Base Rate Fallacy?,,"Source: 6 July 2014, ""Do doctors understand test results?"" by William Kremer, BBC World Service. A 50-year-old woman, with no prior symptoms of breast cancer, participates in routine mammography screening. She tests positive, is alarmed, and wants to know from the physician whether she has breast cancer  or what the chances are. Apart from the screening results, the physician knows nothing else about this woman. How many women who test positive actually have breast cancer? a. nine in 10        b. eight in 10        c. one in 10        d. one in 100 Additional (needed) information: The probability that a woman has breast cancer is 1% (""prevalence"" or base rate probability). If a woman has breast cancer, the probability that she tests positive is 90% (""sensitivity"" or reliability rating). If a woman does not have breast cancer, the probability that she nevertheless tests positive is 9% (""false alarm rate"" or false-positive rate). I have used a similar example when teaching introductory  probability and statistics for about 30 years now, and feel most  instructors use some variation of this problem (if for no reason other than) as an example of Bayes's Theorem. What amazes me is that only 21% of gynaecologists responded (as reported by the author) with the correct answer (let us please leave the solution of this problem for a student). My more cosmic questions: 1. Why do our students not understand this basic application of Bayes's Theorem? 2. What can we as instructors do to explain this prior and posterior probability concept more clearly? 3. Why do the trained experts (gynaecologists) get this question wrong?","Source: 6 July 2014, ""Do doctors understand test results?"" by William Kremer, BBC World Service. A 50-year-old woman, with no prior symptoms of breast cancer, participates in routine mammography screening. She tests positive, is alarmed, and wants to know from the physician whether she has breast cancer  or what the chances are. Apart from the screening results, the physician knows nothing else about this woman. How many women who test positive actually have breast cancer? a. nine in 10        b. eight in 10        c. one in 10        d. one in 100 Additional (needed) information: The probability that a woman has breast cancer is 1% (""prevalence"" or base rate probability). If a woman has breast cancer, the probability that she tests positive is 90% (""sensitivity"" or reliability rating). If a woman does not have breast cancer, the probability that she nevertheless tests positive is 9% (""false alarm rate"" or false-positive rate). I have used a similar example when teaching introductory  probability and statistics for about 30 years now, and feel most  instructors use some variation of this problem (if for no reason other than) as an example of Bayes's Theorem. What amazes me is that only 21% of gynaecologists responded (as reported by the author) with the correct answer (let us please leave the solution of this problem for a student). My more cosmic questions: 1. Why do our students not understand this basic application of Bayes's Theorem? 2. What can we as instructors do to explain this prior and posterior probability concept more clearly? 3. Why do the trained experts (gynaecologists) get this question wrong?",,"['probability', 'education', 'bayes-theorem']"
3,"Asymptotically, how many random students do I have to mark before I've marked two consecutive students","Asymptotically, how many random students do I have to mark before I've marked two consecutive students",,"Background The motivtion for this question comes from observations made by a colleague while he was marking homework and recording the marks this year. His procedure for recording the marks is as follows.  The homework is placed into his folder by students before the deadline, (presumably) in a 'random' order.  Once the deadline passes, he collects the folder, and starts marking.  He takes the first script from the folder, marks it and records the mark on the mark-sheet.  Then he takes the next script, marks it and records it.  And so on... Whilst doing this, he noticed that one would surprisingly quickly have entered marks for two consecutive students on the list.  For example, in a class of 20 students, it only took 4 or 5 scripts on average. This prompted some questions from him on the distribution of this number: What is the expectation and standard deviation? Is there an explicit formula for any class size? (Or a recurrence relation, or any other good way to compute it?) How does it behave asymptotically for large classes? Setup of Problem Let's phrase the problem a bit more precisely, so I can explain what we've succeeded in doing. Suppose you have a line of $ N $ boxes, all initially unfilled.  Select uniformly at random an unfilled box, and fill it in.  Repeat this until two consecutive boxes have been filled in, then stop.  (The boxes form a line, and do not wrap around, so the two end boxes are not considered consecutive.)  The value of the discrete random variable $ X_N $ is then the number of filled in boxes. In particular we are now looking for Explicit formulae for $ E(X_N) $ and $ \operatorname{Var}(X_N) $, (or recurrence relations, or whatever), and the asymptotic behaviour of these Example: When $ N = 3 $, there possible ways to terminate with two consecutive boxes are End, then middle with probability $ \frac{2}{3} \frac{1}{2} = \frac{1}{3} $ and $ X_3 = 2 $ Middle, then end with probability $ \frac{1}{3} 1 = \frac{1}{3} $ and $ X_3 = 2 $, or End, other end and finally middle with probability $ \frac{2}{3} \frac{1}{2} 1 = \frac{1}{3} $ and $ X_3 = 3 $. So, we've got the full distribution of $ X_3 $, and we can compute that $ E(X_3) = 2 \frac{2}{3} + 3 \frac{1}{3} = \frac{7}{3} = 2.\overline{3} $, et cetera. Current Work I have managed to give an explicit (though unpleasant) formula for $ E(X_N) $.  Roughly this is by analysing how the process can terminate with $ n+1 $ boxes filled, looking at the configuration one step before the end, and breaking this up into various types.  (No ends filled, one end filled, both ends filled and various numbers, $ k $, of 'triples' like $ \blacksquare \square \blacksquare $.)  I can then count the number of each type of configuration using standard combinatorial techniques, and then work out the probability of ending with $ n+1 $ boxes filled.  I get: \begin{align} E(X_N) &= \sum_{n=1}^{\left\lfloor \frac{N+1}{2} \right\rfloor} \sum_{k=0}^{n-1} (n+1) \binom{n-1}{k} \Bigg[ (2n-k) \binom{N-2n}{n-k} + 2(2n-k-1) \binom{N-2n}{n-k-1} \\ & {} \quad + (2n-k-2) \binom{N-2n}{n-k-2} \Bigg] \left( n! \frac{(N-n)!}{N!} \frac{1}{N-n} \right) \, , \end{align} and similarly I can get the variance.  (You can still see something of my approach reflected in the structure of the formula.) Using this, we can compute $$ E(X_{20}) = 153641/33592 \approx 4.5737377947 \, , $$ with standard deviation $ \approx 1.6291544998 $, corroborating his initial observations. From here, we can compute the first thousand or so values of $ E(X_N) $, to get a feeling for the behaivour at large $ N $.  The result is as follows: So, at the first glance, is looks like maybe $ E(X_N) \sim N^{1/2} $ (plus or minus a small power).  But it's at this point I'm stuck. Questions My specific questions about this problem are: Is there a neater/more compact/more elegant formula to explicitly compute $ E(X_N) $? Can it be done via a recurrence relation? What sort of techniques are well suited to this type of computation? How accurate is my guess that $ E(X_N) \sim \sqrt{N} $? Can I determine the asymptotic behaviour from the explicit formula? If not, how can I go about finding the asymptotic behaviour? Lastly, (though I'm not expecting anywhere near a complete answer) how does all of this generalise to more complicated arrangements of boxes? Say we do this on an $ N\times M $ grid, and we stop when we fill in two adjacent boxes (including diagonally, or not including diagonally). Or more generally, randomly filling in the vertices of a graph, with the edges determining adjacency. What if some boxes have multiple parts, so can be filled in a number of times?","Background The motivtion for this question comes from observations made by a colleague while he was marking homework and recording the marks this year. His procedure for recording the marks is as follows.  The homework is placed into his folder by students before the deadline, (presumably) in a 'random' order.  Once the deadline passes, he collects the folder, and starts marking.  He takes the first script from the folder, marks it and records the mark on the mark-sheet.  Then he takes the next script, marks it and records it.  And so on... Whilst doing this, he noticed that one would surprisingly quickly have entered marks for two consecutive students on the list.  For example, in a class of 20 students, it only took 4 or 5 scripts on average. This prompted some questions from him on the distribution of this number: What is the expectation and standard deviation? Is there an explicit formula for any class size? (Or a recurrence relation, or any other good way to compute it?) How does it behave asymptotically for large classes? Setup of Problem Let's phrase the problem a bit more precisely, so I can explain what we've succeeded in doing. Suppose you have a line of $ N $ boxes, all initially unfilled.  Select uniformly at random an unfilled box, and fill it in.  Repeat this until two consecutive boxes have been filled in, then stop.  (The boxes form a line, and do not wrap around, so the two end boxes are not considered consecutive.)  The value of the discrete random variable $ X_N $ is then the number of filled in boxes. In particular we are now looking for Explicit formulae for $ E(X_N) $ and $ \operatorname{Var}(X_N) $, (or recurrence relations, or whatever), and the asymptotic behaviour of these Example: When $ N = 3 $, there possible ways to terminate with two consecutive boxes are End, then middle with probability $ \frac{2}{3} \frac{1}{2} = \frac{1}{3} $ and $ X_3 = 2 $ Middle, then end with probability $ \frac{1}{3} 1 = \frac{1}{3} $ and $ X_3 = 2 $, or End, other end and finally middle with probability $ \frac{2}{3} \frac{1}{2} 1 = \frac{1}{3} $ and $ X_3 = 3 $. So, we've got the full distribution of $ X_3 $, and we can compute that $ E(X_3) = 2 \frac{2}{3} + 3 \frac{1}{3} = \frac{7}{3} = 2.\overline{3} $, et cetera. Current Work I have managed to give an explicit (though unpleasant) formula for $ E(X_N) $.  Roughly this is by analysing how the process can terminate with $ n+1 $ boxes filled, looking at the configuration one step before the end, and breaking this up into various types.  (No ends filled, one end filled, both ends filled and various numbers, $ k $, of 'triples' like $ \blacksquare \square \blacksquare $.)  I can then count the number of each type of configuration using standard combinatorial techniques, and then work out the probability of ending with $ n+1 $ boxes filled.  I get: \begin{align} E(X_N) &= \sum_{n=1}^{\left\lfloor \frac{N+1}{2} \right\rfloor} \sum_{k=0}^{n-1} (n+1) \binom{n-1}{k} \Bigg[ (2n-k) \binom{N-2n}{n-k} + 2(2n-k-1) \binom{N-2n}{n-k-1} \\ & {} \quad + (2n-k-2) \binom{N-2n}{n-k-2} \Bigg] \left( n! \frac{(N-n)!}{N!} \frac{1}{N-n} \right) \, , \end{align} and similarly I can get the variance.  (You can still see something of my approach reflected in the structure of the formula.) Using this, we can compute $$ E(X_{20}) = 153641/33592 \approx 4.5737377947 \, , $$ with standard deviation $ \approx 1.6291544998 $, corroborating his initial observations. From here, we can compute the first thousand or so values of $ E(X_N) $, to get a feeling for the behaivour at large $ N $.  The result is as follows: So, at the first glance, is looks like maybe $ E(X_N) \sim N^{1/2} $ (plus or minus a small power).  But it's at this point I'm stuck. Questions My specific questions about this problem are: Is there a neater/more compact/more elegant formula to explicitly compute $ E(X_N) $? Can it be done via a recurrence relation? What sort of techniques are well suited to this type of computation? How accurate is my guess that $ E(X_N) \sim \sqrt{N} $? Can I determine the asymptotic behaviour from the explicit formula? If not, how can I go about finding the asymptotic behaviour? Lastly, (though I'm not expecting anywhere near a complete answer) how does all of this generalise to more complicated arrangements of boxes? Say we do this on an $ N\times M $ grid, and we stop when we fill in two adjacent boxes (including diagonally, or not including diagonally). Or more generally, randomly filling in the vertices of a graph, with the edges determining adjacency. What if some boxes have multiple parts, so can be filled in a number of times?",,"['probability', 'asymptotics']"
4,"Secretary Problem - What is the solution for $n=3,4,5$?",Secretary Problem - What is the solution for ?,"n=3,4,5","I have been reading this page for a few days and still cannot understand the solution to the Secretary Problem. In particular, I cannot understand parts 2 and 4 It goes like this. Given the assumptions of the Secretary Problem, let $n$ be the number of candidates and let the ""let $k$ go by"" strategy be as follows: We let $k-1$ candidates go by, and then select the first candidate who is better than all previous candidates. If the candidate exists, select her. Else, select the last candidate.  $k$ can take the value of $\{ 1, 2, ... n\}$. Given this strategy, we compute the probability of success $p_n(k)$, using ""let $k$ go by"" with $n$ candidates. Here is where my question comes in: When $n=3$, we permuate $\{x_1,x_2,x_3\}$ (the smaller the number, the better the candidate) I understand why $p_3(1)=\frac 26$ and $p_3(3)=\frac 26$ because of the $6$ permutations, $x_1$ could come into the interview first in $2$ permutations. Similarly, $x_1$ could come into the interview last in $2$ permutations. However, why is it that $p_3(2)=\frac 36$? In fact, there is another confusing point. Formally, my questions are: Is it true that by counting the permutations, we find out the numerator of $p_i(k)$ for $i=1, \cdots, n$? If so, then why is it that $\sum_i^n p_i(k) \neq 1$? Also, how did the author arrive at the $\frac 36$ for $p_2(k)$? This question, of course extends to the case where $n=4$ and $n=5$. Maybe consider $n=4$ and $n=5$ and someone could derive the expressions for $p_i(k)$: $n=4$ \begin{matrix} k & 1 & 2 & 3 & 4 \\ p_4(k) & \frac {6}{24} & \frac {11}{24} & \frac {10}{24} & \frac {6}{24} \end{matrix} $n=5$ \begin{matrix} k & 1 & 2 & 3 & 4 & 5\\ p_5(k) & \frac {24}{120} & \frac {50}{120} & \frac {52}{120} & \frac {42}{120} & \frac {24}{120} \end{matrix}","I have been reading this page for a few days and still cannot understand the solution to the Secretary Problem. In particular, I cannot understand parts 2 and 4 It goes like this. Given the assumptions of the Secretary Problem, let $n$ be the number of candidates and let the ""let $k$ go by"" strategy be as follows: We let $k-1$ candidates go by, and then select the first candidate who is better than all previous candidates. If the candidate exists, select her. Else, select the last candidate.  $k$ can take the value of $\{ 1, 2, ... n\}$. Given this strategy, we compute the probability of success $p_n(k)$, using ""let $k$ go by"" with $n$ candidates. Here is where my question comes in: When $n=3$, we permuate $\{x_1,x_2,x_3\}$ (the smaller the number, the better the candidate) I understand why $p_3(1)=\frac 26$ and $p_3(3)=\frac 26$ because of the $6$ permutations, $x_1$ could come into the interview first in $2$ permutations. Similarly, $x_1$ could come into the interview last in $2$ permutations. However, why is it that $p_3(2)=\frac 36$? In fact, there is another confusing point. Formally, my questions are: Is it true that by counting the permutations, we find out the numerator of $p_i(k)$ for $i=1, \cdots, n$? If so, then why is it that $\sum_i^n p_i(k) \neq 1$? Also, how did the author arrive at the $\frac 36$ for $p_2(k)$? This question, of course extends to the case where $n=4$ and $n=5$. Maybe consider $n=4$ and $n=5$ and someone could derive the expressions for $p_i(k)$: $n=4$ \begin{matrix} k & 1 & 2 & 3 & 4 \\ p_4(k) & \frac {6}{24} & \frac {11}{24} & \frac {10}{24} & \frac {6}{24} \end{matrix} $n=5$ \begin{matrix} k & 1 & 2 & 3 & 4 & 5\\ p_5(k) & \frac {24}{120} & \frac {50}{120} & \frac {52}{120} & \frac {42}{120} & \frac {24}{120} \end{matrix}",,"['probability', 'probability-theory']"
5,Tossing a coin until you have more heads than tails,Tossing a coin until you have more heads than tails,,"I toss a coin a many times, each time noting down the result of the toss. If at any time I have tossed more heads than tails I stop.  I.e. if I get heads on the first toss I stop. Or if toss T-T-H-H-T-H-H I will stop. If I decide to only toss the coin at most 2n+1 times, what is the probability that I will get more heads than tails before I have to give up?","I toss a coin a many times, each time noting down the result of the toss. If at any time I have tossed more heads than tails I stop.  I.e. if I get heads on the first toss I stop. Or if toss T-T-H-H-T-H-H I will stop. If I decide to only toss the coin at most 2n+1 times, what is the probability that I will get more heads than tails before I have to give up?",,['probability']
6,Probability in Minesweeper,Probability in Minesweeper,,"Suppose I click a random tile during a Minesweeper game. It is a 1. During each time I click an adjacent square, what are the chances of hitting a mine? How would this change if it were a 2 or another number?","Suppose I click a random tile during a Minesweeper game. It is a 1. During each time I click an adjacent square, what are the chances of hitting a mine? How would this change if it were a 2 or another number?",,"['probability', 'puzzle']"
7,An extension of the birthday problem,An extension of the birthday problem,,"Th birthday problem (or paradox) has been done in many way, with around a dozen thread only on math.stackexchange. The way it is expressed is usually the following: ""Let us take $n$ people ""independently"" (no twins, etc.). What is the probability that no two people share the same birthday?"" It is abstracted in the following way: ""Let $X_1$, $\cdots$, $X_n$ be $n$ i.i.d. random variables taken uniformly in $[[1, 365]]$. What is the probability that all the $X_i$'s are distinct?"" There are many generalizations, for instance: ""Let $n$, $d$ be two positive integers, $n \leq d$. Let $X_1$, $\cdots$, $X_n$ be $n$ i.i.d. random variables taken uniformly in $[[1, d]]$. What is the probability $p(n,d)$ that all the $X_i$'s are distinct?"" One can show that in the regimen $1 \ll n \ll d$, the probability $p(n,d)$ is logarithmically equivalent to something like $e^{-\frac{n^2}{2d}}$ (Wikipedia) or $e^{-\frac{n^2}{d}}$ (my computations)*. This problem can be reduced to simple combinatorics, and Stirling's formula (for instance) gives the solution. However, in the real world, the birthdays are not distributed that way . One might also want to estimate the probability that two peoples are born the same half-day, the same hour, etc. The following generalization seems natural: ""Let $\mu$ be a probability measure on $[0,1]$ absolutely continuous with respect to the Lebesgue measure. Let $n$, $d$ be two positive integers. For $k \in [[0,d-1]]$, let $a_k := [k/d, (k+1)/d]$. Let $X_1$, $\cdots$, $X_n$ be $n$ i.i.d. random variables in $[0,1]$ with distribution $\mu$. What is the probability $p(n,d)$ that all the $X_i$'s lie in different elements of the partition?"" I would expect the solution to be something like $e^{-C(\mu) \frac{n^2}{d}}$, with perhaps some explicit expression of $C(\mu)$. But the combinatorial solutions do not work as well in this setting, and all I can get are very crude bounds when the density of $\mu$ is bounded. In addition, I would expect $C(\mu)$ to be minimal when $\mu$ is the Lebesgue measure, but I don't know how to prove it. One might wonder what happens when $\mu$ is no longer absolutely continuous, but this might be a bit too broad of a generalization. I am sure this problem has been done to death, but I don't have any access to the literature right now, and quick search didn't yield anything (the generalizations of the birthday problem I found are quite different). Any result/proof/reference related to the problems above would be nice. .* By the way, any rigorous proof of either of the two facts (or of any similar-sounding result) is appreciated. I don't know which I can trust more, between my computations and Wikipedia.","Th birthday problem (or paradox) has been done in many way, with around a dozen thread only on math.stackexchange. The way it is expressed is usually the following: ""Let us take $n$ people ""independently"" (no twins, etc.). What is the probability that no two people share the same birthday?"" It is abstracted in the following way: ""Let $X_1$, $\cdots$, $X_n$ be $n$ i.i.d. random variables taken uniformly in $[[1, 365]]$. What is the probability that all the $X_i$'s are distinct?"" There are many generalizations, for instance: ""Let $n$, $d$ be two positive integers, $n \leq d$. Let $X_1$, $\cdots$, $X_n$ be $n$ i.i.d. random variables taken uniformly in $[[1, d]]$. What is the probability $p(n,d)$ that all the $X_i$'s are distinct?"" One can show that in the regimen $1 \ll n \ll d$, the probability $p(n,d)$ is logarithmically equivalent to something like $e^{-\frac{n^2}{2d}}$ (Wikipedia) or $e^{-\frac{n^2}{d}}$ (my computations)*. This problem can be reduced to simple combinatorics, and Stirling's formula (for instance) gives the solution. However, in the real world, the birthdays are not distributed that way . One might also want to estimate the probability that two peoples are born the same half-day, the same hour, etc. The following generalization seems natural: ""Let $\mu$ be a probability measure on $[0,1]$ absolutely continuous with respect to the Lebesgue measure. Let $n$, $d$ be two positive integers. For $k \in [[0,d-1]]$, let $a_k := [k/d, (k+1)/d]$. Let $X_1$, $\cdots$, $X_n$ be $n$ i.i.d. random variables in $[0,1]$ with distribution $\mu$. What is the probability $p(n,d)$ that all the $X_i$'s lie in different elements of the partition?"" I would expect the solution to be something like $e^{-C(\mu) \frac{n^2}{d}}$, with perhaps some explicit expression of $C(\mu)$. But the combinatorial solutions do not work as well in this setting, and all I can get are very crude bounds when the density of $\mu$ is bounded. In addition, I would expect $C(\mu)$ to be minimal when $\mu$ is the Lebesgue measure, but I don't know how to prove it. One might wonder what happens when $\mu$ is no longer absolutely continuous, but this might be a bit too broad of a generalization. I am sure this problem has been done to death, but I don't have any access to the literature right now, and quick search didn't yield anything (the generalizations of the birthday problem I found are quite different). Any result/proof/reference related to the problems above would be nice. .* By the way, any rigorous proof of either of the two facts (or of any similar-sounding result) is appreciated. I don't know which I can trust more, between my computations and Wikipedia.",,"['probability', 'reference-request', 'birthday']"
8,The law of large numbers: How does the convergence take place? How does the “remainder” look like?,The law of large numbers: How does the convergence take place? How does the “remainder” look like?,,"I have the independent and identically distributed random variables $X_1,X_2,\ldots$ with a finite expectation $\mu$. I also have defined $S_n = X_1 + \cdots + X_n$. According to the law of large numbers, I already know that $S_n/n \to \mu$ almost surely as $n\to\infty$. However, my question is: How does the convergence take place? What is the “shape” of this convergence? For example, for a given $N>0$, how close is $S_N/N$ to $\mu$? How does the difference, or remainder/residual, look like? Are there any results, or theorems, available that tell me these kinds of things?","I have the independent and identically distributed random variables $X_1,X_2,\ldots$ with a finite expectation $\mu$. I also have defined $S_n = X_1 + \cdots + X_n$. According to the law of large numbers, I already know that $S_n/n \to \mu$ almost surely as $n\to\infty$. However, my question is: How does the convergence take place? What is the “shape” of this convergence? For example, for a given $N>0$, how close is $S_N/N$ to $\mu$? How does the difference, or remainder/residual, look like? Are there any results, or theorems, available that tell me these kinds of things?",,['probability']
9,"What is the probability of randomly selecting $ n $ natural numbers, all pairwise coprime?","What is the probability of randomly selecting  natural numbers, all pairwise coprime?", n ,"It's known that the probability of selecting $ n $ natural numbers randomly and ending up with a greatest common divisor equal to one is $ \prod (1-p^{-n}) = 1/\zeta(n) $. However, a total GCD of 1 does not rule out any of the pairs among the set of $ n $ numbers sharing a common factor. What's the probability none of them share a common factor? (Since there's a possibility of ""random selection"" being ambiguous, let's take it to mean chosen with uniform probability from {$ 1,2,3,\dots, N$} as $N \to \infty $.)","It's known that the probability of selecting $ n $ natural numbers randomly and ending up with a greatest common divisor equal to one is $ \prod (1-p^{-n}) = 1/\zeta(n) $. However, a total GCD of 1 does not rule out any of the pairs among the set of $ n $ numbers sharing a common factor. What's the probability none of them share a common factor? (Since there's a possibility of ""random selection"" being ambiguous, let's take it to mean chosen with uniform probability from {$ 1,2,3,\dots, N$} as $N \to \infty $.)",,"['probability', 'number-theory']"
10,Probability of spelling IDAHO correctly,Probability of spelling IDAHO correctly,,"I'm working with a problem stated as follows: A sign reads IDAHO. Two letters are removed and put back at random, each equally likely to be put upside down as in the correct orientation. What is the probability that the sign still reads IDAHO? So, we form our events as: $A = \{$ IDAHO is spelt correctly $\}$ $B = \{$ 2 ""symmetric"" characters are chosen $\}$ $C = \{$ 1 ""symmetric"" and 1 ""unsymmetric"" character is chosen $\}$ $D = \{$ 2 ""unsymmetric"" characters are chosen $\}$ Where symmetric means that no matter of orientation, the character looks just like it used to before. Notice, $B,C,D$ form a partition of our sample space. Hence, the the total law of probability gives us: $$P(A) = P(A|B)P(B) + P(A|C)P(C) + P(A|D)P(D) $$ We trivially know that $P(A|B) = 1/2$ , since in choosing two symmetric letters. Furthermore, $P(B) = \frac{\begin{pmatrix} 3 \\2 \end{pmatrix}}{\begin{pmatrix} 5 \\2 \end{pmatrix}} = 3/10$ Then, we have $P(A|C) = 2/4$ , since in choosing 1 symmetric letter and 1 unsymmetric, we have to get the correct position on the unsymmetric letter, whereas the symmetric letter can be switched in orientation without changing the word. Meaning we have 2 out of a total 4 possible scenarios. 4 comes from the fact that we can choose to place the symmetric letter in 2 positions, and orient it in 2 ways, however, these are equivalent. Then, the latter unsymmetric letter has already been given a position, but can be oriented in 2 distinct ways. Furthermore, $P(C) = \frac{\begin{pmatrix} 3 \\2  \end{pmatrix}\begin{pmatrix} 2 \\1  \end{pmatrix}}{\begin{pmatrix} 5 \\2 \end{pmatrix}} = 3/5$ Lastly, $P(A|D) = 1/6$ , since we only have one scenario in which it can become the same word, and the total scenarios are given as we choose a position for the first letter (2), then we choose orientation (2), the latter letter has already been given a position and orientation can be choosen (2). Also $P(D) = \frac{\begin{pmatrix} 2 \\ 2\end{pmatrix}}{\begin{pmatrix} 5 \\2 \end{pmatrix}} = 1/10$ Finally, we have $P(A) = 1/2 \cdot 3/10 + 1/2 \cdot 3/5 + 1/6 \cdot 1/10 = 7/15$ , which according to the answer sheet is wrong ( $5/16$ ). Does anyone of you guys see the mistake. I've tried to find it and gone through my argumentation but can't find the mistake. Thanks.","I'm working with a problem stated as follows: A sign reads IDAHO. Two letters are removed and put back at random, each equally likely to be put upside down as in the correct orientation. What is the probability that the sign still reads IDAHO? So, we form our events as: IDAHO is spelt correctly 2 ""symmetric"" characters are chosen 1 ""symmetric"" and 1 ""unsymmetric"" character is chosen 2 ""unsymmetric"" characters are chosen Where symmetric means that no matter of orientation, the character looks just like it used to before. Notice, form a partition of our sample space. Hence, the the total law of probability gives us: We trivially know that , since in choosing two symmetric letters. Furthermore, Then, we have , since in choosing 1 symmetric letter and 1 unsymmetric, we have to get the correct position on the unsymmetric letter, whereas the symmetric letter can be switched in orientation without changing the word. Meaning we have 2 out of a total 4 possible scenarios. 4 comes from the fact that we can choose to place the symmetric letter in 2 positions, and orient it in 2 ways, however, these are equivalent. Then, the latter unsymmetric letter has already been given a position, but can be oriented in 2 distinct ways. Furthermore, Lastly, , since we only have one scenario in which it can become the same word, and the total scenarios are given as we choose a position for the first letter (2), then we choose orientation (2), the latter letter has already been given a position and orientation can be choosen (2). Also Finally, we have , which according to the answer sheet is wrong ( ). Does anyone of you guys see the mistake. I've tried to find it and gone through my argumentation but can't find the mistake. Thanks.","A = \{ \} B = \{ \} C = \{ \} D = \{ \} B,C,D P(A) = P(A|B)P(B) + P(A|C)P(C) + P(A|D)P(D)  P(A|B) = 1/2 P(B) = \frac{\begin{pmatrix}
3 \\2
\end{pmatrix}}{\begin{pmatrix}
5 \\2
\end{pmatrix}} = 3/10 P(A|C) = 2/4 P(C) = \frac{\begin{pmatrix}
3 \\2 
\end{pmatrix}\begin{pmatrix}
2 \\1 
\end{pmatrix}}{\begin{pmatrix}
5 \\2
\end{pmatrix}} = 3/5 P(A|D) = 1/6 P(D) = \frac{\begin{pmatrix}
2 \\
2\end{pmatrix}}{\begin{pmatrix}
5 \\2
\end{pmatrix}} = 1/10 P(A) = 1/2 \cdot 3/10 + 1/2 \cdot 3/5 + 1/6 \cdot 1/10 = 7/15 5/16",['probability']
11,"Did Kolmogorov's probability ""experiments"" survive in the modern theory?","Did Kolmogorov's probability ""experiments"" survive in the modern theory?",,"In Kolmogorov's probability book, he defines the independence of multiple ""experiments"" before using that to define the independence of events. Here is an excerpt from Section 5, Chapter 1 (note that Kolmogorov uses $E$ to refer to the sample space, while I will use $\Omega$ in what follows): Let us turn to the definition of independence. Given $n$ experiments $\mathfrak{A}^{(1)}, \mathfrak{A}^{(2)}, \ldots, \mathfrak{A}^{(n)}$ , that is, $n$ decompositions $$E = A_1^{(i)} + A_2^{(i)} + \cdots + A_{r_i}^{(i)} \quad \quad i = 1,2, \ldots, n$$ of the basic set $E$ . It is then possible to assign $r = r_1 r_2 \ldots r_n$ probabilities (in the general case) $$p_{q_1 q_2 \ldots q_n} = \mathsf{P} \left ( A_{q_1}^{(1)} A_{q_2}^{(2)} \ldots A_{q_n}^{(n)} \right ) \geq 0$$ which are entirely arbitrary except for the single condition that $$\sum_{q_1, q_2, \ldots, q_n} p_{q_1 q_2 \ldots q_n} = 1$$ DEFINITION I. $n$ experiments $\mathfrak{A}^{(1)}, \mathfrak{A}^{(2)}, \ldots, \mathfrak{A}^{(n)}$ are called mutually independent , if for any $q_1, q_2, \ldots, q_n$ the following equation holds true: $$\mathsf{P} \left ( A_{q_1}^{(1)} A_{q_2}^{(2)} \ldots A_{q_n}^{(n)} \right ) = \mathsf{P} \left ( A_{q_1}^{(1)} \right ) \mathsf{P} \left ( A_{q_2}^{(2)} \right ) \ldots \mathsf{P} \left ( A_{q_n}^{(n)} \right )$$ In modern language, an ""experiment"" is represented by the sample space, $\Omega$ , of a probability space $\left(\Omega, \mathfrak{F}, P\right)$ , with the elements of $\Omega$ being the elementary outcomes of that ""experiment,"" and elements of $\mathfrak{F}$ being all possible events associated to the ""experiment."" But here Kolmogorov is describing something else: an experiment is a partition of the sample space into a set of disjoint events.  In my understanding, this could be thought of as a specific question about the system, with the disjoint events being the set of all possible answers to that question.  For example, when flipping two coins, you could ask (i) ""Was the first coin heads?"" with experiment $\left\{A, A^c \right\}$ , where $A$ is the event that the first coin was heads, or (ii) ""How many heads appeared?"", where the experiment would be $\left\{A_0, A_1, A_2 \right\}$ with $A_i$ being the event of seeing $i$ heads. To define the independence of events, Kolmogorov states that two events, $A$ and $B$ , are independent if their associated experiments, $\left\{A, A^c \right\}$ and $\left\{B, B^c \right\}$ , are independent. The (four) resulting equations from the final equation in the above excerpt reduce to a single independent equation, which can be taken to be $P\left(A\cap B\right) = P(A)P(B)$ . He then defines the conditional probability of an event, B, with respect to an experiment, $\mathfrak{A}=\left\{A_1, A_2, \ldots \right\}$ , as a random variable that takes the (already defined, standard) value $P(B | A_i)$ when acting on the element of the partition of $\Omega$ defined by $\mathfrak{A}$ .  This definition generalizes nicely in later sections (Chapter 5) to define conditional probability with respect to a random variable, which can be thought of as itself defining a partition of $\Omega$ , and thus an ""experiment."" My question is: what is the purpose of these definitions (Kolmogorov's ""experiments"", and the associated definitions of independence and conditional probabilities) in probability theory?  I ask because I cannot find very much discussion of them in probability textbooks or on the internet.  It seems that either they have been discarded as not vital to the theory, or have been replaced and renamed, so that I cannot find them.","In Kolmogorov's probability book, he defines the independence of multiple ""experiments"" before using that to define the independence of events. Here is an excerpt from Section 5, Chapter 1 (note that Kolmogorov uses to refer to the sample space, while I will use in what follows): Let us turn to the definition of independence. Given experiments , that is, decompositions of the basic set . It is then possible to assign probabilities (in the general case) which are entirely arbitrary except for the single condition that DEFINITION I. experiments are called mutually independent , if for any the following equation holds true: In modern language, an ""experiment"" is represented by the sample space, , of a probability space , with the elements of being the elementary outcomes of that ""experiment,"" and elements of being all possible events associated to the ""experiment."" But here Kolmogorov is describing something else: an experiment is a partition of the sample space into a set of disjoint events.  In my understanding, this could be thought of as a specific question about the system, with the disjoint events being the set of all possible answers to that question.  For example, when flipping two coins, you could ask (i) ""Was the first coin heads?"" with experiment , where is the event that the first coin was heads, or (ii) ""How many heads appeared?"", where the experiment would be with being the event of seeing heads. To define the independence of events, Kolmogorov states that two events, and , are independent if their associated experiments, and , are independent. The (four) resulting equations from the final equation in the above excerpt reduce to a single independent equation, which can be taken to be . He then defines the conditional probability of an event, B, with respect to an experiment, , as a random variable that takes the (already defined, standard) value when acting on the element of the partition of defined by .  This definition generalizes nicely in later sections (Chapter 5) to define conditional probability with respect to a random variable, which can be thought of as itself defining a partition of , and thus an ""experiment."" My question is: what is the purpose of these definitions (Kolmogorov's ""experiments"", and the associated definitions of independence and conditional probabilities) in probability theory?  I ask because I cannot find very much discussion of them in probability textbooks or on the internet.  It seems that either they have been discarded as not vital to the theory, or have been replaced and renamed, so that I cannot find them.","E \Omega n \mathfrak{A}^{(1)}, \mathfrak{A}^{(2)}, \ldots, \mathfrak{A}^{(n)} n E = A_1^{(i)} + A_2^{(i)} + \cdots + A_{r_i}^{(i)} \quad \quad i = 1,2, \ldots, n E r = r_1 r_2 \ldots r_n p_{q_1 q_2 \ldots q_n} = \mathsf{P} \left ( A_{q_1}^{(1)} A_{q_2}^{(2)} \ldots A_{q_n}^{(n)} \right ) \geq 0 \sum_{q_1, q_2, \ldots, q_n} p_{q_1 q_2 \ldots q_n} = 1 n \mathfrak{A}^{(1)}, \mathfrak{A}^{(2)}, \ldots, \mathfrak{A}^{(n)} q_1, q_2, \ldots, q_n \mathsf{P} \left ( A_{q_1}^{(1)} A_{q_2}^{(2)} \ldots A_{q_n}^{(n)} \right ) = \mathsf{P} \left ( A_{q_1}^{(1)} \right ) \mathsf{P} \left ( A_{q_2}^{(2)} \right ) \ldots \mathsf{P} \left ( A_{q_n}^{(n)} \right ) \Omega \left(\Omega, \mathfrak{F}, P\right) \Omega \mathfrak{F} \left\{A, A^c \right\} A \left\{A_0, A_1, A_2 \right\} A_i i A B \left\{A, A^c \right\} \left\{B, B^c \right\} P\left(A\cap B\right) = P(A)P(B) \mathfrak{A}=\left\{A_1, A_2, \ldots \right\} P(B | A_i) \Omega \mathfrak{A} \Omega","['probability', 'probability-theory', 'conditional-probability', 'independence']"
12,Dudley's Inequality can be Loose (Vershynin 8.1.12),Dudley's Inequality can be Loose (Vershynin 8.1.12),,"Let $e_1,...,e_n$ denote the canonical basis vectors in $\mathbb{R}^n$ . Consider the set $$T = \left \{ \frac{e_k}{\sqrt{1 + \log k}}, k =1,...,n\right \}$$ Show that $$\int_{0}^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)} d\epsilon \rightarrow\infty$$ as $n \rightarrow \infty$ . Here $\mathcal{N}(T,d,\epsilon)$ is the size of the smallest $\epsilon$ -net of $T$ with respect to the metric $d$ . An $\epsilon$ -net in this context is a set $N \subset T$ such that for all $t \in T$ there is an $s \in N$ such that $d(s,t) \leq \epsilon$ . I assume that $d(x,y) = ||x-y||_2$ , although this isn't explicitly stated. Also note,that $\epsilon$ -nets must be  subsets of $T$ I also write $\log$ when really I mean $\ln$ . I've spent quite a bit of time working on this exercise and from what I can tell, unless I've missed the trick completely, is that this example actually does not work. Here is my argument. For convenience, let $v_k = \frac{e_k}{\sqrt{1+\log k}}$ . Let $f_n(k):\{1,...,n-1\} \rightarrow \mathbb{R}_+$ be defined as $$f_n(k) = \sqrt{\frac{1}{1+\log k} + \frac{1}{1+\log n}}$$ It is easy to see that for $1 \leq j < k \leq n$ we have $$||v_j -v_k||_2 = \sqrt{\frac{1}{1+\log j}+\frac{1}{1+\log k}} \geq \sqrt{\frac{1}{1+\log j}+\frac{1}{1+\log n}} = ||v_j - v_n||_2 =f_n(j)$$ Now let $1 \leq k \leq n-2$ and let $\epsilon \in [f_n(k+1),f_n(k))$ . Let $N$ be an $\epsilon$ -net of $T$ . It must be that for all $j \leq k$ that $v_j \in N$ since the nearest point $$\min_{i \neq j} ||v_j - v_i||_2 = ||v_j - v_n|| = f_n(j) \geq f_n(k) > \epsilon.$$ Therefore $|N| \geq k+1$ since $\{v_1,...,v_k\} \subset N$ and we need at least one more point for $v_n$ . Also note that $N = \{v_1,...,v_k,v_n\}$ is an $\epsilon$ -net since for all $j \geq k+1$ we have $$||v_j - v_n||_2 = f_n(j) \leq f_n(k+1) \leq \epsilon.$$ This and the lower bound shows that $N$ is best possible and therefore that $\mathcal{N}(T,d,\epsilon) = k+1$ . Also note that for $\epsilon < f_n(n-1)$ the only possible $\epsilon$ -net is $T$ and therefore $\mathcal{N}(T,d,\epsilon) = |T| = n$ for $\epsilon < f_n(n-1)$ . Similarly for $\epsilon \geq f_n(1)$ the set $N = v_n$ is an $\epsilon$ -net. We next put these bounds on $\mathcal{N}(T,d,\epsilon)$ together. First we can use what happens when $\epsilon \geq f_n(1)$ . \begin{align} \int_0^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon &= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \int_{f_n(1)}^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon \\ &= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \int_{f_n(1)}^\infty \sqrt{\log 1}d\epsilon \\ &= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon \end{align} Next we split the integral up \begin{align} \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon &= \int_0^{f_n(n-1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \sum_{i=1}^{n-2} \int_{f_n(i+1)}^{f_n(i)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon \\ &= \int_0^{f_n(n-1)} \sqrt{\log(n)}d\epsilon + \sum_{i=1}^{n-2} \int_{f_n(i+1)}^{f_n(i)} \sqrt{\log(i+1)}d\epsilon \\ &= f_n(n-1)\sqrt{\log n} + \sum_{i=1}^{n-2} [f_n(i) - f_n(i+1)]\sqrt{\log(i+1)} \end{align} So far this is all an exact equality. If we substitute in the definition of $f_n$ into this expression we get $$\sqrt{\frac{\log n}{1+\log (n-1)} + \frac{\log n}{1+\log n}} + \sum_{i=1}^{n-2}\sqrt{\frac{\log(i+1)}{1+\log i } + \frac{\log(i+1)}{1+\log n}}-\sqrt{\frac{\log(i+1)}{1+\log(i+1)} + \frac{\log(i+1)}{1+\log n}}$$ Numerically however this seems to converge to less than 3. So either the series grows incredibly slowly or it is failing to grow to infinity. Any help would be greatly appreciated! Also, if you try replacing $||\cdot||_2$ with $||\cdot||_1$ it doesn't appear to help","Let denote the canonical basis vectors in . Consider the set Show that as . Here is the size of the smallest -net of with respect to the metric . An -net in this context is a set such that for all there is an such that . I assume that , although this isn't explicitly stated. Also note,that -nets must be  subsets of I also write when really I mean . I've spent quite a bit of time working on this exercise and from what I can tell, unless I've missed the trick completely, is that this example actually does not work. Here is my argument. For convenience, let . Let be defined as It is easy to see that for we have Now let and let . Let be an -net of . It must be that for all that since the nearest point Therefore since and we need at least one more point for . Also note that is an -net since for all we have This and the lower bound shows that is best possible and therefore that . Also note that for the only possible -net is and therefore for . Similarly for the set is an -net. We next put these bounds on together. First we can use what happens when . Next we split the integral up So far this is all an exact equality. If we substitute in the definition of into this expression we get Numerically however this seems to converge to less than 3. So either the series grows incredibly slowly or it is failing to grow to infinity. Any help would be greatly appreciated! Also, if you try replacing with it doesn't appear to help","e_1,...,e_n \mathbb{R}^n T = \left \{ \frac{e_k}{\sqrt{1 + \log k}}, k =1,...,n\right \} \int_{0}^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)} d\epsilon \rightarrow\infty n \rightarrow \infty \mathcal{N}(T,d,\epsilon) \epsilon T d \epsilon N \subset T t \in T s \in N d(s,t) \leq \epsilon d(x,y) = ||x-y||_2 \epsilon T \log \ln v_k = \frac{e_k}{\sqrt{1+\log k}} f_n(k):\{1,...,n-1\} \rightarrow \mathbb{R}_+ f_n(k) = \sqrt{\frac{1}{1+\log k} + \frac{1}{1+\log n}} 1 \leq j < k \leq n ||v_j -v_k||_2 = \sqrt{\frac{1}{1+\log j}+\frac{1}{1+\log k}} \geq \sqrt{\frac{1}{1+\log j}+\frac{1}{1+\log n}} = ||v_j - v_n||_2 =f_n(j) 1 \leq k \leq n-2 \epsilon \in [f_n(k+1),f_n(k)) N \epsilon T j \leq k v_j \in N \min_{i \neq j} ||v_j - v_i||_2 = ||v_j - v_n|| = f_n(j) \geq f_n(k) > \epsilon. |N| \geq k+1 \{v_1,...,v_k\} \subset N v_n N = \{v_1,...,v_k,v_n\} \epsilon j \geq k+1 ||v_j - v_n||_2 = f_n(j) \leq f_n(k+1) \leq \epsilon. N \mathcal{N}(T,d,\epsilon) = k+1 \epsilon < f_n(n-1) \epsilon T \mathcal{N}(T,d,\epsilon) = |T| = n \epsilon < f_n(n-1) \epsilon \geq f_n(1) N = v_n \epsilon \mathcal{N}(T,d,\epsilon) \epsilon \geq f_n(1) \begin{align}
\int_0^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon &= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \int_{f_n(1)}^\infty \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon \\
&= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \int_{f_n(1)}^\infty \sqrt{\log 1}d\epsilon \\
&= \int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon
\end{align} \begin{align}
\int_0^{f_n(1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon &= \int_0^{f_n(n-1)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon + \sum_{i=1}^{n-2} \int_{f_n(i+1)}^{f_n(i)} \sqrt{\log \mathcal{N}(T,d,\epsilon)}d\epsilon \\
&= \int_0^{f_n(n-1)} \sqrt{\log(n)}d\epsilon + \sum_{i=1}^{n-2} \int_{f_n(i+1)}^{f_n(i)} \sqrt{\log(i+1)}d\epsilon \\
&= f_n(n-1)\sqrt{\log n} + \sum_{i=1}^{n-2} [f_n(i) - f_n(i+1)]\sqrt{\log(i+1)}
\end{align} f_n \sqrt{\frac{\log n}{1+\log (n-1)} + \frac{\log n}{1+\log n}} + \sum_{i=1}^{n-2}\sqrt{\frac{\log(i+1)}{1+\log i } + \frac{\log(i+1)}{1+\log n}}-\sqrt{\frac{\log(i+1)}{1+\log(i+1)} + \frac{\log(i+1)}{1+\log n}} ||\cdot||_2 ||\cdot||_1","['probability', 'probability-theory', 'inequality', 'concentration-of-measure']"
13,Exponentially weighted infinite sum of Bernoulli variables,Exponentially weighted infinite sum of Bernoulli variables,,"Consider the following process.  For each integer $i \geq 0$ , independently sample a Bernoulli distribution with probability $p = 1/2$ , obtaining sample $x_i$ .  Then calculate $x = \sum_{i=0}^\infty x_i \theta^i,$ where $(\theta < 1)$ .  What is the distribution over $x$ ? I see that if θ = 0.5 then this is a uniformly generated binary number between 0 and 2. This post is closely related, but I don't see how the method given there (with θ = 0.5) generalizes to arbitrary $\theta$ .  I am interested in values of $\theta$ close to 1, such as $\theta = 0.95$ . I am ultimately interested in a hypothesis test: $H_0=$ "" $p = 0.5$ "" against the alternative $H_A=$ "" $p \neq 0.5$ "".  The motivation is, I am receiving an infinite sequence of 0s and 1s for which I only retain an exponentially weighted average (not recording the whole sequence).  And based on this weighted average I want to decide whether the 0s and 1s were generated with equal probability or not. Edit: based on an empirical test it appears to be roughly normally distributed.  The following was generated by performing a 100,000 sample run with $\theta = 0.95$ .  It has mean 10 and variance 2.5. 5.9   6.0   6.1 *  6.2 *  6.3 *  6.4 *  6.5 **  6.6 **  6.7 **  6.8 ***  6.9 ***  7.0 ****  7.1 *****  7.2 *****  7.3 ******  7.4 ******  7.5 ********  7.6 ********  7.7 *********  7.8 *********  7.9 **********  8.0 ************  8.1 ************  8.2 *************  8.3 **************  8.4 ***************  8.5 ****************  8.6 *****************  8.7 ******************  8.8 *******************  8.9 *******************  9.0 ********************  9.1 *********************  9.2 **********************  9.3 ***********************  9.4 **********************  9.5 ***********************  9.6 ***********************  9.7 *************************  9.8 ************************  9.9 ************************ 10.0 ************************ 10.1 ************************ 10.2 ************************* 10.3 ************************ 10.4 *********************** 10.5 *********************** 10.6 ********************** 10.7 *********************** 10.8 ********************** 10.9 ********************* 11.0 ******************* 11.1 ******************* 11.2 ****************** 11.3 ****************** 11.4 **************** 11.5 *************** 11.6 *************** 11.7 ************* 11.8 ************ 11.9 ************ 12.0 *********** 12.1 ********** 12.2 ********* 12.3 ******** 12.4 ******** 12.5 ******* 12.6 ****** 12.7 ***** 12.8 ***** 12.9 ***** 13.0 **** 13.1 *** 13.2 *** 13.3 ** 13.4 ** 13.5 ** 13.6 * 13.7 * 13.8 * 13.9 * 14.0  14.1 Normal quantile plot for $\theta=0.90$ : Normal quantile plot for $\theta=0.95$ : Looks like it has thin tails.","Consider the following process.  For each integer , independently sample a Bernoulli distribution with probability , obtaining sample .  Then calculate where .  What is the distribution over ? I see that if θ = 0.5 then this is a uniformly generated binary number between 0 and 2. This post is closely related, but I don't see how the method given there (with θ = 0.5) generalizes to arbitrary .  I am interested in values of close to 1, such as . I am ultimately interested in a hypothesis test: "" "" against the alternative "" "".  The motivation is, I am receiving an infinite sequence of 0s and 1s for which I only retain an exponentially weighted average (not recording the whole sequence).  And based on this weighted average I want to decide whether the 0s and 1s were generated with equal probability or not. Edit: based on an empirical test it appears to be roughly normally distributed.  The following was generated by performing a 100,000 sample run with .  It has mean 10 and variance 2.5. 5.9   6.0   6.1 *  6.2 *  6.3 *  6.4 *  6.5 **  6.6 **  6.7 **  6.8 ***  6.9 ***  7.0 ****  7.1 *****  7.2 *****  7.3 ******  7.4 ******  7.5 ********  7.6 ********  7.7 *********  7.8 *********  7.9 **********  8.0 ************  8.1 ************  8.2 *************  8.3 **************  8.4 ***************  8.5 ****************  8.6 *****************  8.7 ******************  8.8 *******************  8.9 *******************  9.0 ********************  9.1 *********************  9.2 **********************  9.3 ***********************  9.4 **********************  9.5 ***********************  9.6 ***********************  9.7 *************************  9.8 ************************  9.9 ************************ 10.0 ************************ 10.1 ************************ 10.2 ************************* 10.3 ************************ 10.4 *********************** 10.5 *********************** 10.6 ********************** 10.7 *********************** 10.8 ********************** 10.9 ********************* 11.0 ******************* 11.1 ******************* 11.2 ****************** 11.3 ****************** 11.4 **************** 11.5 *************** 11.6 *************** 11.7 ************* 11.8 ************ 11.9 ************ 12.0 *********** 12.1 ********** 12.2 ********* 12.3 ******** 12.4 ******** 12.5 ******* 12.6 ****** 12.7 ***** 12.8 ***** 12.9 ***** 13.0 **** 13.1 *** 13.2 *** 13.3 ** 13.4 ** 13.5 ** 13.6 * 13.7 * 13.8 * 13.9 * 14.0  14.1 Normal quantile plot for : Normal quantile plot for : Looks like it has thin tails.","i \geq 0 p = 1/2 x_i x = \sum_{i=0}^\infty x_i \theta^i, (\theta < 1) x \theta \theta \theta = 0.95 H_0= p = 0.5 H_A= p \neq 0.5 \theta = 0.95 \theta=0.90 \theta=0.95","['probability', 'hypothesis-testing']"
14,Probability and expected steps for two ants to meet on cube,Probability and expected steps for two ants to meet on cube,,"Here I present an extension to the famous ant on a cube question: Two ants, A and B, are placed on diametrically opposite corners of a   cube. With every step, each ants move from one vertex to an adjacent vertex (with 1/3 probability of moving along each of the joining edges). What is i) the probability that A and B collide before either   ant reaches the diametrically opposite corner; and ii) the expected   number of steps before they collide? I fully understand how the law of iterated expectations work for a single ant reaching the diametrically opposite corner, however I am unsure of how to extend it for this case. I read in a separate question (lost the link sadly, please edit if you find it) about two players meeting on a random walk, and how characteristic functions were involved, but I did not really understand it. Could someone provide some insight? Cheers! Edit: second part makes more sense after drawing the Markov chain, could someone prod me in the right direction for constructing the Markov chain for the first part?","Here I present an extension to the famous ant on a cube question: Two ants, A and B, are placed on diametrically opposite corners of a   cube. With every step, each ants move from one vertex to an adjacent vertex (with 1/3 probability of moving along each of the joining edges). What is i) the probability that A and B collide before either   ant reaches the diametrically opposite corner; and ii) the expected   number of steps before they collide? I fully understand how the law of iterated expectations work for a single ant reaching the diametrically opposite corner, however I am unsure of how to extend it for this case. I read in a separate question (lost the link sadly, please edit if you find it) about two players meeting on a random walk, and how characteristic functions were involved, but I did not really understand it. Could someone provide some insight? Cheers! Edit: second part makes more sense after drawing the Markov chain, could someone prod me in the right direction for constructing the Markov chain for the first part?",,"['probability', 'conditional-expectation', 'expected-value']"
15,Calculating odds of Minesweeper is this correct?,Calculating odds of Minesweeper is this correct?,,"EDIT Please see new question: Calculating Minesweeper Odds Is this calculation correct? The answers here helped me create the new question (The post below has some errors which makes it harder to review) The below question is only kept for historical purposes. So I originally asked this question here , given that the number of mines was unknown. However user2661923 pointed out that the 104 different possibilities do not have an equal weight . For example, having 4 mines in total is more likely than having 5 mines in total. We know this without knowing the total mines because in Minesweeper there are always a greater number of unmined cells than mined cells. See this question & answer for a detailed explanation as to why the 104 combinations are not all equal weight Problem I want to calculate the odds of hitting a mine in any of the spaces. I will apply my original calculation & the new information to this board where the number of mines is known ( 25 ): N = number of mines = 25. T = number of unidentified squares = 124 ABFI,B,C..NOP,RSTUVWXY (All labeled squares minus M & Q) I'll refer to as Section1 The grey squares (including M & Q) I'll refer to as Section2 I've broken up the board into colour groups based on the probabilities. Every square in the green group will have the same probability. Every square in the grey group will have the same probability and so on. We know this based on the numbered squares the square is touching. For example, 'A' & 'B' both touch a '3'. There is no reason 'B' would have different odds than 'A'. I've labeled the board for my own sake, to be able to refer to the squares of interest ( M & Q are not interesting, they are part of section2 I just wanted a square of marked squares ) Based on this we know: Section1 can have 4, or 5 or 6 mines. Section2 can have 21, 20, or 19 mines. (Remember section2 is 'the rest' aka gray squares) I'll refer to what we know as 'Rules'. We know the total number of mines surrounding a '1' must equal '1'. Rules: ColorGroups                          # of bombs in ColorGroups -----------                          ---------------------------- (A+B+F+I) + (C) + (G) + (J) =        3 (D+E+H+L) (C) + (G) + (K)   =        1 (N+O+P) + (J) + (K) + (G)   =        1 (R+S+T+U+V+W+X+Y)           =        1 Before collecting every possible combination, Let's look at the formula for assigning weights (Found in the 'question & answer' linked at the top, Credit to user Joriki in the linked answer): m = remaining mines (25) t = remaining unidentified squares (124) n = mines assigned s = assigned squares Let's assume Section1 has 4 mines (Section2 must have the remaining 21): m = 25 t = 124 n = 4 s = 23 (Remember M & Q are not part of this section).  124 - 23 = 101 25 - 4 = 21 101 ncr 21 = 2577824781465941808570 Assuming Section1 has 5 mines: m = 25 t = 124 n = 5 s = 23  124 - 23 = 101 25 - 5 = 20 101 ncr 20 = 668324943343021950370 Finally, assuming Section1 has 6 mines: m = 25 t = 124 n = 6 s = 23  124 - 23 = 101 25 - 6 = 19 101 ncr 19 = 163006083742200475700 Calculating all of the possibilities (I refer to these as 'Scenarios') the same way we've done in the original post tells us there are 6 different possibilities for Section1: #:      A1  A12 A21 A22 A23 A24 GREEN:  1   2   2   2   3   3 PINK:   1   1   0   0   0   0    ORANGE: 0   0   0   1   0   1 BROWN:  0   0   1   0   0   0 YELLOW: 1   0   0   1   0   0 PURPLE: 0   0   0   0   1   0 BLUE:   0   1   0   0   0   1 RED:    1   1   1   1   1   1 Total:  4   5   4   5   5   6 Note: I described & listed all scenerios in the original post. As done in the original post, taking the NCR for all combinations (Adding Red here, gives us the same result since Red is always 1): #:      A1  A12 A21 A22 A23 A24 GREEN:  4   6   6   6   4   4 PINK:   1   1   1   1   1   1    ORANGE: 1   1   1   4   1   4 BROWN:  1   1   1   1   1   1 YELLOW: 1   1   1   1   1   1 PURPLE: 1   1   1   1   1   1 BLUE:   1   3   1   1   1   3 RED:    1   1   1   1   1   1 TOTALS: 4   18  6   24  4   48  Total combinations = 104 Note: In the above table, to get 'TOTALS' we multiply all combinations to get the total combinations for that solution. Tallying up the number of mines for the known sections we see there are 1 scenerios where the sections contains 6 mines, 2 scenarios which have 4 mines and 3 that have 5 mines. To normalize the weights: 3 * 2577824781465941808570 = 7.7334743e+21 2 * 668324943343021950370 = 1.3366499e+21 1 * 163006083742200475700 = 163006083742200475700   7.7334743e+21 + 1.3366499e+21 + 163006083742200475700  = 9.2331303e+21  2577824781465941808570 / 9.2331303e+21 = 0.279% 668324943343021950370 / 9.2331303e+21 = 0.072% 163006083742200475700 / 9.2331303e+21 = 0.018% So, for each 'scenario' for section1, we can assign the weights: 4 mine scenarios weight = 0.279% 5 mine scenarios weight = 0.072% 6 mine scenarios weight = 0.018% Since 'Section1' is nearly identical to the scenario in my last question I can take the results but apply the weights: m (number of mines), divide by t (squares) times c (total combinations for the solution) multiplied by the weight (based on total mines for the solution. 4 is 0.279, 5 is 0.072, 6 is 0.018) A11 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (1/4 * 4) *  0.279    =  0.279 Pink   = (1/1 * 4) *  0.279    =  1.116 Orange = (0/4 * 4) *  0.279    =  0.00 Brown  = (0/1 * 4) *  0.279    =  0.00 Yellow = (1/1 * 4) *  0.279    =  1.116 Purple = (0/1 * 4) *  0.279    =  0.00 Blue   = (0/1 * 4) *  0.279    =  0.00 Red    = (1/8 * 4) *  0.279    =  0.14 A12 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (2/4 * 18) * 0.072    =  0.648 Pink   = (1/1 * 18) * 0.072    =  1.296 Orange = (0/4 * 18) * 0.072    =  0.00 Brown  = (0/1 * 18) * 0.072    =  0.00 Yellow = (0/1 * 18) * 0.072    =  0.00 Purple = (0/1 * 18) * 0.072    =  0.00 Blue   = (1/1 * 18) * 0.072    =  1.296 Red    = (1/8 * 18) * 0.072    =  0.162 A21 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (2/4 * 6)  * 0.279    =  0.837 Pink   = (0/1 * 6)  * 0.279    =  0.00 Orange = (0/4 * 6)  * 0.279    =  0.00 Brown  = (1/1 * 6)  * 0.279    =  1.674 Yellow = (0/1 * 6)  * 0.279    =  0.00 Purple = (0/1 * 6)  * 0.279    =  0.00 Blue   = (0/1 * 6)  * 0.279    =  0.00 Red    = (1/8 * 6)  * 0.279    =  0.2093 A22 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (2/4 * 24) * 0.279    =  3.348 Pink   = (0/1 * 24) * 0.279    =  0.00 Orange = (1/4 * 24) * 0.279    =  1.674 Brown  = (0/1 * 24) * 0.279    =  0.00 Yellow = (1/1 * 24) * 0.279    =  6.696 Purple = (0/1 * 24) * 0.279    =  0.00 Blue   = (0/1 * 24) * 0.279    =  0.00 Red    = (1/8 * 24) * 0.279    =  0.837 A23 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (3/4 * 4)  * 0.072     = 0.216 Pink   = (0/1 * 4)  * 0.072     = 0.00 Orange = (0/4 * 4)  * 0.072     = 0.00 Brown  = (0/1 * 4)  * 0.072     = 0.00 Yellow = (0/1 * 4)  * 0.072     = 0.00 Purple = (1/1 * 4)  * 0.072     = 0.288 Blue   = (0/1 * 4)  * 0.072     = 0.00 Red    = (1/8 * 4)  * 0.072     = 0.036 A24 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (3/4 * 48)  * 0.018    = 0.648 Pink   = (0/1 * 48)  * 0.018    = 0.00 Orange = (1/4 * 48)  * 0.018    = 0.216 Brown  = (0/1 * 48)  * 0.018    = 0.00 Yellow = (0/1 * 48)  * 0.018    = 0.00 Purple = (0/1 * 48)  * 0.018    = 0.00 Blue   = (1/1 * 48)  * 0.018    = 0.864 Red    = (1/8 * 48)  * 0.018    = 0.108 Adding up all the results, then divding by 104 (total combinations) we get the result. Then divide by the number of squares in the section to get the probability per square: Green:    5.976 / 104 = 0.057 / 4 = %0.0144 Pink:     2.412 / 104 = 0.023 / 1 = %0.023 Orange:   1.89  / 104 = 0.018 / 4 = %0.0045 Brown:    1.674 / 104 = 0.016 / 1 = %0.016 Yellow:   7.812 / 104 = 0.075 / 1 = %0.075 Purple:   0.288 / 104 = 0.003 / 1 = %0.003 Blue:     2.16  / 104 = 0.208 / 3 = %0.0069 Red:      1.4923/ 104 = 0.014 / 8 = %0.0018 This means brown has the best odds. In a real game, the player should click one of the squares surrounding the '1'. Is this logic right?","EDIT Please see new question: Calculating Minesweeper Odds Is this calculation correct? The answers here helped me create the new question (The post below has some errors which makes it harder to review) The below question is only kept for historical purposes. So I originally asked this question here , given that the number of mines was unknown. However user2661923 pointed out that the 104 different possibilities do not have an equal weight . For example, having 4 mines in total is more likely than having 5 mines in total. We know this without knowing the total mines because in Minesweeper there are always a greater number of unmined cells than mined cells. See this question & answer for a detailed explanation as to why the 104 combinations are not all equal weight Problem I want to calculate the odds of hitting a mine in any of the spaces. I will apply my original calculation & the new information to this board where the number of mines is known ( 25 ): N = number of mines = 25. T = number of unidentified squares = 124 ABFI,B,C..NOP,RSTUVWXY (All labeled squares minus M & Q) I'll refer to as Section1 The grey squares (including M & Q) I'll refer to as Section2 I've broken up the board into colour groups based on the probabilities. Every square in the green group will have the same probability. Every square in the grey group will have the same probability and so on. We know this based on the numbered squares the square is touching. For example, 'A' & 'B' both touch a '3'. There is no reason 'B' would have different odds than 'A'. I've labeled the board for my own sake, to be able to refer to the squares of interest ( M & Q are not interesting, they are part of section2 I just wanted a square of marked squares ) Based on this we know: Section1 can have 4, or 5 or 6 mines. Section2 can have 21, 20, or 19 mines. (Remember section2 is 'the rest' aka gray squares) I'll refer to what we know as 'Rules'. We know the total number of mines surrounding a '1' must equal '1'. Rules: ColorGroups                          # of bombs in ColorGroups -----------                          ---------------------------- (A+B+F+I) + (C) + (G) + (J) =        3 (D+E+H+L) (C) + (G) + (K)   =        1 (N+O+P) + (J) + (K) + (G)   =        1 (R+S+T+U+V+W+X+Y)           =        1 Before collecting every possible combination, Let's look at the formula for assigning weights (Found in the 'question & answer' linked at the top, Credit to user Joriki in the linked answer): m = remaining mines (25) t = remaining unidentified squares (124) n = mines assigned s = assigned squares Let's assume Section1 has 4 mines (Section2 must have the remaining 21): m = 25 t = 124 n = 4 s = 23 (Remember M & Q are not part of this section).  124 - 23 = 101 25 - 4 = 21 101 ncr 21 = 2577824781465941808570 Assuming Section1 has 5 mines: m = 25 t = 124 n = 5 s = 23  124 - 23 = 101 25 - 5 = 20 101 ncr 20 = 668324943343021950370 Finally, assuming Section1 has 6 mines: m = 25 t = 124 n = 6 s = 23  124 - 23 = 101 25 - 6 = 19 101 ncr 19 = 163006083742200475700 Calculating all of the possibilities (I refer to these as 'Scenarios') the same way we've done in the original post tells us there are 6 different possibilities for Section1: #:      A1  A12 A21 A22 A23 A24 GREEN:  1   2   2   2   3   3 PINK:   1   1   0   0   0   0    ORANGE: 0   0   0   1   0   1 BROWN:  0   0   1   0   0   0 YELLOW: 1   0   0   1   0   0 PURPLE: 0   0   0   0   1   0 BLUE:   0   1   0   0   0   1 RED:    1   1   1   1   1   1 Total:  4   5   4   5   5   6 Note: I described & listed all scenerios in the original post. As done in the original post, taking the NCR for all combinations (Adding Red here, gives us the same result since Red is always 1): #:      A1  A12 A21 A22 A23 A24 GREEN:  4   6   6   6   4   4 PINK:   1   1   1   1   1   1    ORANGE: 1   1   1   4   1   4 BROWN:  1   1   1   1   1   1 YELLOW: 1   1   1   1   1   1 PURPLE: 1   1   1   1   1   1 BLUE:   1   3   1   1   1   3 RED:    1   1   1   1   1   1 TOTALS: 4   18  6   24  4   48  Total combinations = 104 Note: In the above table, to get 'TOTALS' we multiply all combinations to get the total combinations for that solution. Tallying up the number of mines for the known sections we see there are 1 scenerios where the sections contains 6 mines, 2 scenarios which have 4 mines and 3 that have 5 mines. To normalize the weights: 3 * 2577824781465941808570 = 7.7334743e+21 2 * 668324943343021950370 = 1.3366499e+21 1 * 163006083742200475700 = 163006083742200475700   7.7334743e+21 + 1.3366499e+21 + 163006083742200475700  = 9.2331303e+21  2577824781465941808570 / 9.2331303e+21 = 0.279% 668324943343021950370 / 9.2331303e+21 = 0.072% 163006083742200475700 / 9.2331303e+21 = 0.018% So, for each 'scenario' for section1, we can assign the weights: 4 mine scenarios weight = 0.279% 5 mine scenarios weight = 0.072% 6 mine scenarios weight = 0.018% Since 'Section1' is nearly identical to the scenario in my last question I can take the results but apply the weights: m (number of mines), divide by t (squares) times c (total combinations for the solution) multiplied by the weight (based on total mines for the solution. 4 is 0.279, 5 is 0.072, 6 is 0.018) A11 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (1/4 * 4) *  0.279    =  0.279 Pink   = (1/1 * 4) *  0.279    =  1.116 Orange = (0/4 * 4) *  0.279    =  0.00 Brown  = (0/1 * 4) *  0.279    =  0.00 Yellow = (1/1 * 4) *  0.279    =  1.116 Purple = (0/1 * 4) *  0.279    =  0.00 Blue   = (0/1 * 4) *  0.279    =  0.00 Red    = (1/8 * 4) *  0.279    =  0.14 A12 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (2/4 * 18) * 0.072    =  0.648 Pink   = (1/1 * 18) * 0.072    =  1.296 Orange = (0/4 * 18) * 0.072    =  0.00 Brown  = (0/1 * 18) * 0.072    =  0.00 Yellow = (0/1 * 18) * 0.072    =  0.00 Purple = (0/1 * 18) * 0.072    =  0.00 Blue   = (1/1 * 18) * 0.072    =  1.296 Red    = (1/8 * 18) * 0.072    =  0.162 A21 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (2/4 * 6)  * 0.279    =  0.837 Pink   = (0/1 * 6)  * 0.279    =  0.00 Orange = (0/4 * 6)  * 0.279    =  0.00 Brown  = (1/1 * 6)  * 0.279    =  1.674 Yellow = (0/1 * 6)  * 0.279    =  0.00 Purple = (0/1 * 6)  * 0.279    =  0.00 Blue   = (0/1 * 6)  * 0.279    =  0.00 Red    = (1/8 * 6)  * 0.279    =  0.2093 A22 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (2/4 * 24) * 0.279    =  3.348 Pink   = (0/1 * 24) * 0.279    =  0.00 Orange = (1/4 * 24) * 0.279    =  1.674 Brown  = (0/1 * 24) * 0.279    =  0.00 Yellow = (1/1 * 24) * 0.279    =  6.696 Purple = (0/1 * 24) * 0.279    =  0.00 Blue   = (0/1 * 24) * 0.279    =  0.00 Red    = (1/8 * 24) * 0.279    =  0.837 A23 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (3/4 * 4)  * 0.072     = 0.216 Pink   = (0/1 * 4)  * 0.072     = 0.00 Orange = (0/4 * 4)  * 0.072     = 0.00 Brown  = (0/1 * 4)  * 0.072     = 0.00 Yellow = (0/1 * 4)  * 0.072     = 0.00 Purple = (1/1 * 4)  * 0.072     = 0.288 Blue   = (0/1 * 4)  * 0.072     = 0.00 Red    = (1/8 * 4)  * 0.072     = 0.036 A24 Colour   m/t * c      Weight      Result ------   ----------   ------      ------ Green  = (3/4 * 48)  * 0.018    = 0.648 Pink   = (0/1 * 48)  * 0.018    = 0.00 Orange = (1/4 * 48)  * 0.018    = 0.216 Brown  = (0/1 * 48)  * 0.018    = 0.00 Yellow = (0/1 * 48)  * 0.018    = 0.00 Purple = (0/1 * 48)  * 0.018    = 0.00 Blue   = (1/1 * 48)  * 0.018    = 0.864 Red    = (1/8 * 48)  * 0.018    = 0.108 Adding up all the results, then divding by 104 (total combinations) we get the result. Then divide by the number of squares in the section to get the probability per square: Green:    5.976 / 104 = 0.057 / 4 = %0.0144 Pink:     2.412 / 104 = 0.023 / 1 = %0.023 Orange:   1.89  / 104 = 0.018 / 4 = %0.0045 Brown:    1.674 / 104 = 0.016 / 1 = %0.016 Yellow:   7.812 / 104 = 0.075 / 1 = %0.075 Purple:   0.288 / 104 = 0.003 / 1 = %0.003 Blue:     2.16  / 104 = 0.208 / 3 = %0.0069 Red:      1.4923/ 104 = 0.014 / 8 = %0.0018 This means brown has the best odds. In a real game, the player should click one of the squares surrounding the '1'. Is this logic right?",,"['probability', 'combinatorics', 'combinations']"
16,Books similar to Fifty Challenging Problems in Probability with Solutions by Frederick Mosteller,Books similar to Fifty Challenging Problems in Probability with Solutions by Frederick Mosteller,,I find the book Fifty Challenging Problems in Probability with Solutions by Frederick Mosteller . I would like to solve more probability problems whose levels are similar to book above.  Does anyone have good suggestions?,I find the book Fifty Challenging Problems in Probability with Solutions by Frederick Mosteller . I would like to solve more probability problems whose levels are similar to book above.  Does anyone have good suggestions?,,"['probability', 'reference-request', 'book-recommendation']"
17,Disease spread through checkerboard,Disease spread through checkerboard,,"Suppose we have an infinite checkerboard (square grid) with a single “infected” square at time $t=0$ . After each discrete time step, each square that is adjacent (sharing an edge) to one or more infected squares becomes infected with probability $p$ . Infected squares stay infected forever. Let $X_t$ be the number of squares infected at time $t$ . It is probably far too complicated and difficult to explicitly calculate $\mathbb E[X_t]$ . However, we can anticipate that $X_t\sim c\cdot t^2$ for some constant $c$ that depends on $p$ . Does anyone know how to make this asymptotic estimate sharper by calculating the explicit value of $c$ in terms of $p$ ? In other words, can we find $$\lim_{t\to\infty}\frac{\mathbb E[X_t]}{t^2}=c=\space ?$$ I do know that $c=2$ when $p=1$ and $c=0$ when $p=0$ , so I would expect something like $c=2p$ or $c=2p^2$ . However, I have no idea how to go about finding $c$ . Can somebody please help?","Suppose we have an infinite checkerboard (square grid) with a single “infected” square at time . After each discrete time step, each square that is adjacent (sharing an edge) to one or more infected squares becomes infected with probability . Infected squares stay infected forever. Let be the number of squares infected at time . It is probably far too complicated and difficult to explicitly calculate . However, we can anticipate that for some constant that depends on . Does anyone know how to make this asymptotic estimate sharper by calculating the explicit value of in terms of ? In other words, can we find I do know that when and when , so I would expect something like or . However, I have no idea how to go about finding . Can somebody please help?",t=0 p X_t t \mathbb E[X_t] X_t\sim c\cdot t^2 c p c p \lim_{t\to\infty}\frac{\mathbb E[X_t]}{t^2}=c=\space ? c=2 p=1 c=0 p=0 c=2p c=2p^2 c,"['probability', 'limits', 'asymptotics', 'markov-chains', 'markov-process']"
18,Why is the maximum of i.i.d. Gaussians asymptotically $\sqrt{2 \log n}$?,Why is the maximum of i.i.d. Gaussians asymptotically ?,\sqrt{2 \log n},"Assuming that $\xi$ is bounded (as a function of $x$ ?), the claim is that given the equation: $$\xi \frac{\sqrt{2\pi}}{n} = \frac{1}{x} e^{-\frac{x^2}{2}} \left( 1 + O\left(\frac{1}{x^2} \right) \right)  $$ one can solve (""after some calculation"") for $x$ to get: $$x = \sqrt{2 \log n} - \frac{\log \log n + \log 4 \pi}{2 \sqrt{2 \log n}} - \frac{\log \xi}{\sqrt{2 \log n}} + O\left( \frac{1}{\log n} \right) \,. $$ Question: Would it be possible to get some hints about how to solve for $x$ in this situation? There are several issues about this which I don't understand: How is the assumption that $\xi$ is bounded used or otherwise relevant? Why is the ""imprecise knowledge of $x$ transferred to $n$ "" when solving for $x$ , and not ""transferred"" to some other variable? If we require an assumption on $\xi$ , then why isn't the ""imprecise knowledge transferred"" to $\xi$ ? (Why don't we get an $O(f(\xi))$ term for some $f$ ? Do we have to use/calculate some inverse function to $g(x) := \frac{1}{x} e^{-\frac{x^2}{2}}$ ? This function isn't even defined, strictly speaking, at $x=0$ , but perhaps it has a continuous extension over the entire real line? If it does have a continuous extension over $\mathbb{R}$ , is that continuous extension even an invertible function, such that talking about $g^{-1}(x)$ even makes sense? If we do calculate such an inverse function, do we then basically proceed by applying that function to both sides of the equation and ignoring the $O(x^{-2})$ term, with the understanding that the ""uncertainty"" contained within it now needs to be transferred somewhere else? If so, this leads back to the above question about where the $O((\log n)^{-1})$ term could come from. Context: I don't think the context is actually relevant to solving this problem, but for the record this comes up on p. 374 of Cramer's 1946 Mathematical Methods of Statistics where an asymptotic form for the maximum of i.i.d. Gaussian random variables is sought.","Assuming that is bounded (as a function of ?), the claim is that given the equation: one can solve (""after some calculation"") for to get: Question: Would it be possible to get some hints about how to solve for in this situation? There are several issues about this which I don't understand: How is the assumption that is bounded used or otherwise relevant? Why is the ""imprecise knowledge of transferred to "" when solving for , and not ""transferred"" to some other variable? If we require an assumption on , then why isn't the ""imprecise knowledge transferred"" to ? (Why don't we get an term for some ? Do we have to use/calculate some inverse function to ? This function isn't even defined, strictly speaking, at , but perhaps it has a continuous extension over the entire real line? If it does have a continuous extension over , is that continuous extension even an invertible function, such that talking about even makes sense? If we do calculate such an inverse function, do we then basically proceed by applying that function to both sides of the equation and ignoring the term, with the understanding that the ""uncertainty"" contained within it now needs to be transferred somewhere else? If so, this leads back to the above question about where the term could come from. Context: I don't think the context is actually relevant to solving this problem, but for the record this comes up on p. 374 of Cramer's 1946 Mathematical Methods of Statistics where an asymptotic form for the maximum of i.i.d. Gaussian random variables is sought.","\xi x \xi \frac{\sqrt{2\pi}}{n} = \frac{1}{x} e^{-\frac{x^2}{2}} \left( 1 + O\left(\frac{1}{x^2} \right) \right)   x x = \sqrt{2 \log n} - \frac{\log \log n + \log 4 \pi}{2 \sqrt{2 \log n}} - \frac{\log \xi}{\sqrt{2 \log n}} + O\left( \frac{1}{\log n} \right) \,.  x \xi x n x \xi \xi O(f(\xi)) f g(x) := \frac{1}{x} e^{-\frac{x^2}{2}} x=0 \mathbb{R} g^{-1}(x) O(x^{-2}) O((\log n)^{-1})","['probability', 'statistics', 'asymptotics', 'problem-solving', 'order-statistics']"
19,Probability of remaining a whole pancake rather than two halves.,Probability of remaining a whole pancake rather than two halves.,,"A very interesting question. It is trivial for small number of pancakes but for 100 I was not able to find an analytical or manual way to figure out the probability. Thanks a lot in advance if you can share your ideas! Suppose you have 100 pancakes to eat. Everyday you eat a half of a pancake. In this way after one day there will remain 99 whole pancakes and a half pancake. Suppose your choice of the pancake is random. That is, you are equally likely to pick any remaining pancake, no matter it is a whole pancake or a half pancake, to eat everyday. Formally, if there are $X$ whole pancakes and $Y$ half pancakes at the beginning of some day, then the probability of each piece of pancake to be picked is $\frac{1}{X+Y}$. Then what's the probability of the event that after $99\times 2 = 198$ days of eating, there will remain a whole pancake rather than 2 halves of pancakes? Notice that the question might be interpreted in another way, as @Acccumulation noted in his answer. So please be careful about the interpretation. For example, denote the index of the day by $k$, and the number of whole pancakes at (the end of) day $k$ as $X_k$ (i.e., after you eat the pancake), then $P(X_0 = 100) = 1$, $P(X_1 = 99) = 1$, $P(X_2 = 99) =1/100, P(X_2 = 98) = 99/100 $. If we denote the number of half pancakes at (the end of) day $k$ as $Y_k$, then it's easy to see that $2X_k + Y_k + k = 200$ and  $$P(X_{k+1} = X_k - 1) = \frac{X_k}{X_k+Y_k}, P(X_{k+1} = X_k) = \frac{Y_k}{X_k+Y_k}.$$ Or equivalently, $$P(X_{k+1} = X_k - 1) = \frac{X_k}{200-k-X_k}, P(X_{k+1} = X_k) = \frac{200-k-2X_k}{200-k-X_k}.$$ However, this relationship depends on both the values of $X_k$ and $k$, which is hard to use for recursion by hand. Does anyone have some ideas to do recursion or go in some other directions? Thanks a lot!","A very interesting question. It is trivial for small number of pancakes but for 100 I was not able to find an analytical or manual way to figure out the probability. Thanks a lot in advance if you can share your ideas! Suppose you have 100 pancakes to eat. Everyday you eat a half of a pancake. In this way after one day there will remain 99 whole pancakes and a half pancake. Suppose your choice of the pancake is random. That is, you are equally likely to pick any remaining pancake, no matter it is a whole pancake or a half pancake, to eat everyday. Formally, if there are $X$ whole pancakes and $Y$ half pancakes at the beginning of some day, then the probability of each piece of pancake to be picked is $\frac{1}{X+Y}$. Then what's the probability of the event that after $99\times 2 = 198$ days of eating, there will remain a whole pancake rather than 2 halves of pancakes? Notice that the question might be interpreted in another way, as @Acccumulation noted in his answer. So please be careful about the interpretation. For example, denote the index of the day by $k$, and the number of whole pancakes at (the end of) day $k$ as $X_k$ (i.e., after you eat the pancake), then $P(X_0 = 100) = 1$, $P(X_1 = 99) = 1$, $P(X_2 = 99) =1/100, P(X_2 = 98) = 99/100 $. If we denote the number of half pancakes at (the end of) day $k$ as $Y_k$, then it's easy to see that $2X_k + Y_k + k = 200$ and  $$P(X_{k+1} = X_k - 1) = \frac{X_k}{X_k+Y_k}, P(X_{k+1} = X_k) = \frac{Y_k}{X_k+Y_k}.$$ Or equivalently, $$P(X_{k+1} = X_k - 1) = \frac{X_k}{200-k-X_k}, P(X_{k+1} = X_k) = \frac{200-k-2X_k}{200-k-X_k}.$$ However, this relationship depends on both the values of $X_k$ and $k$, which is hard to use for recursion by hand. Does anyone have some ideas to do recursion or go in some other directions? Thanks a lot!",,"['probability', 'combinatorics']"
20,"An urn has 4 balls of 4 different colours Red,Blue,Green,Yellow.","An urn has 4 balls of 4 different colours Red,Blue,Green,Yellow.",,"An urn has $4$ balls of $4$ different colours; red, blue, green, and   yellow. I pick one ball at random at first and if it is red, I paint   it blue and return it to the urn. If it is blue, I paint it green. If   it is green, I paint it yellow. If it is yellow, I paint it red. What   is the expected number of trials to get all $4$ balls of the same   colour? Reminder: $$\color{red}{red}\to \color{blue}{blue}$$ $$\color{blue}{blue}\to \color{green}{green}$$ $$\color{green}{green}\to \color{yellow}{yellow}$$ $$\color{yellow}{yellow}\to \color{red}{red}$$ I am really stuck with this problem. Help!","An urn has $4$ balls of $4$ different colours; red, blue, green, and   yellow. I pick one ball at random at first and if it is red, I paint   it blue and return it to the urn. If it is blue, I paint it green. If   it is green, I paint it yellow. If it is yellow, I paint it red. What   is the expected number of trials to get all $4$ balls of the same   colour? Reminder: $$\color{red}{red}\to \color{blue}{blue}$$ $$\color{blue}{blue}\to \color{green}{green}$$ $$\color{green}{green}\to \color{yellow}{yellow}$$ $$\color{yellow}{yellow}\to \color{red}{red}$$ I am really stuck with this problem. Help!",,['probability']
21,Question about proof of Stein's Lemma by Casella and Berger,Question about proof of Stein's Lemma by Casella and Berger,,"I am looking at the following proof from Casella and Berger's Statistical Inference. However, I don't understand the final statement. The only condition on $g'$ here is that $E|g'(X)|<\infty$. But how does this ensure that $g(x)e^{-(x-\theta)^2/(2\sigma^2)} \to 0$ as $x \to \pm \infty$?","I am looking at the following proof from Casella and Berger's Statistical Inference. However, I don't understand the final statement. The only condition on $g'$ here is that $E|g'(X)|<\infty$. But how does this ensure that $g(x)e^{-(x-\theta)^2/(2\sigma^2)} \to 0$ as $x \to \pm \infty$?",,"['probability', 'statistics']"
22,Advanced airplane problem,Advanced airplane problem,,"I recently came across a quite interesting problem:  ""One hundred passengers are lined up to board a full flight. The first passenger lost his boarding pass and decides to choose a seat randomly. Each subsequent passenger (responsible enough to not lose their boarding pass) will sit in his or her assigned seat if it is free and, otherwise, randomly choose a seat from those remaining. What is the probability that the last passenger will get to sit in his assigned seat?"" I figured out that the probability would be 0.5. If you would like to know why I would link you to another topic on this site where this problem was discussed. Taking Seats on a Plane However, I kept thinking about what the probability would be if there were multiple people who lost their boarding pass. So for example, the first 5 people out of the 100 passengers lost their boarding pass so they take a random seat. Every person that boards the plane after him will either take their ""proper"" seat, or if that seat is taken, a random seat instead. Then what is the probability that the last passenger will get to sit in his assigned seat? I have trouble figuring it out and I hope that some of you could help me. Thanks in advance!","I recently came across a quite interesting problem:  ""One hundred passengers are lined up to board a full flight. The first passenger lost his boarding pass and decides to choose a seat randomly. Each subsequent passenger (responsible enough to not lose their boarding pass) will sit in his or her assigned seat if it is free and, otherwise, randomly choose a seat from those remaining. What is the probability that the last passenger will get to sit in his assigned seat?"" I figured out that the probability would be 0.5. If you would like to know why I would link you to another topic on this site where this problem was discussed. Taking Seats on a Plane However, I kept thinking about what the probability would be if there were multiple people who lost their boarding pass. So for example, the first 5 people out of the 100 passengers lost their boarding pass so they take a random seat. Every person that boards the plane after him will either take their ""proper"" seat, or if that seat is taken, a random seat instead. Then what is the probability that the last passenger will get to sit in his assigned seat? I have trouble figuring it out and I hope that some of you could help me. Thanks in advance!",,['probability']
23,Equality in Conditional Jensen's Inequality,Equality in Conditional Jensen's Inequality,,"Conditonal Jensen's Inequality says that for a convex function $\varphi$, a random variable $X$, and a sub-sigma-field $\mathcal{F}$, $E[\varphi(X)\mid \mathcal{F}] \geq \varphi(E[X\mid \mathcal{F}])$. In ordinary Jensen's Inequality, $E[\varphi(X)]\geq \varphi(E[X])$, and we have equality if and only if $X$ is degenerate (i.e., almost surely a constant) or $\varphi$ is linear. I'm wondering if an analogous result holds for the conditional version. Is it the case that $E[\varphi(X)\mid\mathcal{F}]=\varphi(E[X\mid\mathcal{F}])$ if and only if $X \in \mathcal{F}$ or $\varphi$ is linear? (Certainly the ""if"" is true, but I'm wondering about the ""only if."")","Conditonal Jensen's Inequality says that for a convex function $\varphi$, a random variable $X$, and a sub-sigma-field $\mathcal{F}$, $E[\varphi(X)\mid \mathcal{F}] \geq \varphi(E[X\mid \mathcal{F}])$. In ordinary Jensen's Inequality, $E[\varphi(X)]\geq \varphi(E[X])$, and we have equality if and only if $X$ is degenerate (i.e., almost surely a constant) or $\varphi$ is linear. I'm wondering if an analogous result holds for the conditional version. Is it the case that $E[\varphi(X)\mid\mathcal{F}]=\varphi(E[X\mid\mathcal{F}])$ if and only if $X \in \mathcal{F}$ or $\varphi$ is linear? (Certainly the ""if"" is true, but I'm wondering about the ""only if."")",,"['probability', 'measure-theory', 'conditional-expectation']"
24,Convolution - Difference of two random variables with different distributions,Convolution - Difference of two random variables with different distributions,,"This is a homework problem, but it isn't me looking for an easy way out. I've been thinking about this problem for a while now and even went to my professor's office hours and still don't quite understand it. Question: Let $X \sim Exp(1)$ and $Y \sim Unif[0,1]$ be two independent random variables. Find the PDF of $|X-Y|$ by using convolution. So, the very first thing I did was define $Z = |X-Y|$. Usually, when I deal with problems like this and want to find the PDF of a sum (difference), I find the CDF of $Z$ and then differentiate to get the PDF of $Z$.  \begin{align*} F_Z(z) &= P(Z \leq z) = P(|X-Y| \leq z)\\ &= P(-z \leq |X-Y| \leq z)\\&= P(X-Y \leq z) - P(X-Y \leq -z)\\ &=F_{X-Y}(z) - F_{X-Y}(-z) \end{align*} So, this is the CDF of $Z=|X-Y|$. If i differentiate it, then the F's (CDF's) simply spit out f's (PDF's) and by the chain rule the second CDF would produce a negative. Altogether, this means: \begin{align*} f_Z(z) = f_{X-Y}(z) + f_{X-Y}(-z) \end{align*} Okay, now that's all fine and dandy, but now I want to explicitly write out the distribution functions in terms of how they are defined over particular intervals. I think this is where convolution comes into play. My game plan was to solve for the two separate pdf's by computing two convolutions. Because $X$ is distributed exponentially, I know it must take on a positive value. Because $Y$ is uniform on $[0,1]$ I know we are only considering the values $[0,1]$ and not all positive values. So, this is where I start getting a little ""bewildered"", haha. I have this written down so far: \begin{align*} &f_{X-Y}(z) &= \int_{-\infty}^{\infty}{f_X(x)f_Y(x-z)dx}\\ &f_{X-Y}(-z) &= \int_{-\infty}^{\infty}{f_X(x)f_Y(x+z)dx} \end{align*} Does this set-up make sense? I obviously have to change the limits of integration but that is the part that confuses me the most. How can I derive the limits of integration on my own? Thank you!","This is a homework problem, but it isn't me looking for an easy way out. I've been thinking about this problem for a while now and even went to my professor's office hours and still don't quite understand it. Question: Let $X \sim Exp(1)$ and $Y \sim Unif[0,1]$ be two independent random variables. Find the PDF of $|X-Y|$ by using convolution. So, the very first thing I did was define $Z = |X-Y|$. Usually, when I deal with problems like this and want to find the PDF of a sum (difference), I find the CDF of $Z$ and then differentiate to get the PDF of $Z$.  \begin{align*} F_Z(z) &= P(Z \leq z) = P(|X-Y| \leq z)\\ &= P(-z \leq |X-Y| \leq z)\\&= P(X-Y \leq z) - P(X-Y \leq -z)\\ &=F_{X-Y}(z) - F_{X-Y}(-z) \end{align*} So, this is the CDF of $Z=|X-Y|$. If i differentiate it, then the F's (CDF's) simply spit out f's (PDF's) and by the chain rule the second CDF would produce a negative. Altogether, this means: \begin{align*} f_Z(z) = f_{X-Y}(z) + f_{X-Y}(-z) \end{align*} Okay, now that's all fine and dandy, but now I want to explicitly write out the distribution functions in terms of how they are defined over particular intervals. I think this is where convolution comes into play. My game plan was to solve for the two separate pdf's by computing two convolutions. Because $X$ is distributed exponentially, I know it must take on a positive value. Because $Y$ is uniform on $[0,1]$ I know we are only considering the values $[0,1]$ and not all positive values. So, this is where I start getting a little ""bewildered"", haha. I have this written down so far: \begin{align*} &f_{X-Y}(z) &= \int_{-\infty}^{\infty}{f_X(x)f_Y(x-z)dx}\\ &f_{X-Y}(-z) &= \int_{-\infty}^{\infty}{f_X(x)f_Y(x+z)dx} \end{align*} Does this set-up make sense? I obviously have to change the limits of integration but that is the part that confuses me the most. How can I derive the limits of integration on my own? Thank you!",,"['probability', 'probability-theory', 'random-variables', 'convolution']"
25,Fair 5-sided die,Fair 5-sided die,,"Commonly used polyhedral dice all have sides of the same shape. However: is this strictly required? Take a triangular prism. A triangular prism with small height compared to the base edge would almost always fall on one of its bases when thrown. A triangular prism with large height would fall like a ""three-sided cylinder"", almost always on one of the flat sides. How would a fair triangular prism that falls on any of its sides with equal probability look?","Commonly used polyhedral dice all have sides of the same shape. However: is this strictly required? Take a triangular prism. A triangular prism with small height compared to the base edge would almost always fall on one of its bases when thrown. A triangular prism with large height would fall like a ""three-sided cylinder"", almost always on one of the flat sides. How would a fair triangular prism that falls on any of its sides with equal probability look?",,"['probability', 'geometry']"
26,The density of the square of the exponentially distributed random variable,The density of the square of the exponentially distributed random variable,,"Let $\xi$ - a random variable with an exponential distribution $p_{\xi} (x) = \lambda e^{-\lambda x}$ $$ p_{\xi} (x) =  \begin{cases}  0, & x < 0, \\ \lambda e^{-\lambda x}, & x \ge 0. \end{cases} $$ I want to find the density of a square $\xi^2$. Can I say that $p_{\xi^2} (x) = p_{\xi}^2 (x)$ or should I look for density according to the definition $p_{\xi^2} (x)  = \big ( F_{\xi^2} (x) \big )' = (\mathbb{P} \big ( \xi^2 < x) \big )'$ ?","Let $\xi$ - a random variable with an exponential distribution $p_{\xi} (x) = \lambda e^{-\lambda x}$ $$ p_{\xi} (x) =  \begin{cases}  0, & x < 0, \\ \lambda e^{-\lambda x}, & x \ge 0. \end{cases} $$ I want to find the density of a square $\xi^2$. Can I say that $p_{\xi^2} (x) = p_{\xi}^2 (x)$ or should I look for density according to the definition $p_{\xi^2} (x)  = \big ( F_{\xi^2} (x) \big )' = (\mathbb{P} \big ( \xi^2 < x) \big )'$ ?",,"['probability', 'probability-theory']"
27,How probable is that a randomly typed 47 digit odd integer is a prime?,How probable is that a randomly typed 47 digit odd integer is a prime?,,"So, I have been playing around with prime numbers, I have installed gmp and gmpy2 gmpy2 has a function gmpy2.is_prime for primality testing (non deterministic) which uses the Miller-Rabin primality test. Now to test the speed of gmpy2.is_prime I typed some random digits '1245268798719487981976914598618498569816481948' and added a '3' to the end so that the number is not even . It took it milliseconds to get the result and to my surprise, In [18]: gmpy2.is_prime(12452687987194879819769145986184985698164819483) Out[18]: True What? really? the number I randomly typed is a prime? To make sure is_prime wasn't returning true for every other number I added a few digits and expectedly In [25]: gmpy2.is_prime(124526879871948798197691459861849856981648139483) Out[25]: False  In [26]: gmpy2.is_prime(12452687987194879819769145986555184985698164819483) Out[26]: False I was blown away, but now, I am curious. What is the probability of this happening? More specifically, What is the probability that a randomly selected odd 47 digit number passes Miller-Rabin primality test? Did I just get really really lucky?","So, I have been playing around with prime numbers, I have installed gmp and gmpy2 gmpy2 has a function gmpy2.is_prime for primality testing (non deterministic) which uses the Miller-Rabin primality test. Now to test the speed of gmpy2.is_prime I typed some random digits '1245268798719487981976914598618498569816481948' and added a '3' to the end so that the number is not even . It took it milliseconds to get the result and to my surprise, In [18]: gmpy2.is_prime(12452687987194879819769145986184985698164819483) Out[18]: True What? really? the number I randomly typed is a prime? To make sure is_prime wasn't returning true for every other number I added a few digits and expectedly In [25]: gmpy2.is_prime(124526879871948798197691459861849856981648139483) Out[25]: False  In [26]: gmpy2.is_prime(12452687987194879819769145986555184985698164819483) Out[26]: False I was blown away, but now, I am curious. What is the probability of this happening? More specifically, What is the probability that a randomly selected odd 47 digit number passes Miller-Rabin primality test? Did I just get really really lucky?",,"['probability', 'prime-numbers', 'primality-test']"
28,Can conditional distributions determine the joint distribution?,Can conditional distributions determine the joint distribution?,,"Can conditional distributions determine the joint distribution? For example, let $X_1, \dots, X_n$ be random variables. Can their joint distribution be determined from the conditional distribution of $X_i$ given others, $i=1, \dots, n$? Can their joint distribution be determined from other types of conditional distributions, such as the type of $P(X_i|X_j)$, and/or the type of $P(X_i, X_j | \text{others})$, and/or other types? Thanks!","Can conditional distributions determine the joint distribution? For example, let $X_1, \dots, X_n$ be random variables. Can their joint distribution be determined from the conditional distribution of $X_i$ given others, $i=1, \dots, n$? Can their joint distribution be determined from other types of conditional distributions, such as the type of $P(X_i|X_j)$, and/or the type of $P(X_i, X_j | \text{others})$, and/or other types? Thanks!",,['probability']
29,Showing probability no husband next to wife converges to $e^{-1}$,Showing probability no husband next to wife converges to,e^{-1},"Inspired by these questions: Probability of Couples sitting next to each other (Sitting in a Row) Probability question about married couples Four married couples, eight seats. Probability that husband sits next to his wife? In how many ways can n couples (husband and wife) be arranged on a bench so no wife would sit next to her husband? No husband can sit next to his wife in this probability question the more general question of the probability that seating $n$ couples (i.e. $2n$ individuals) in a row at random means that no couples are sat together can be expressed using inclusion-exclusion as $$\displaystyle\sum_{i=0}^n (-2)^i {n \choose i}\frac{(2n-i)!}{(2n)!}$$ which for small $n$ takes the values: n   Probability of no couple together            1   0           0    2   1/3         0.3333333 3   1/3         0.3333333 4   12/35       0.3481481 5   47/135      0.3428571    6   3655/10395  0.3516114 7   1772/5005   0.3540460 8   20609/57915 0.3558491 This made me wonder whether it converges to $e^{-1} \approx  0.3678794$ as $n$ increases, like other cases such as the secretary/dating problem and $\left(1-\frac1n\right)^n$ do.  So I tried the following R code (using logarithms to avoid overflows) couples  <- 1000000 together <- 0:couples sum( (-1)^together * exp( log(2)*together + lchoose(couples,together) +       lfactorial(2*couples - together) - lfactorial(2*couples) ) ) which indeed gave a figure of $0.3678794$. How might one try to prove this limit?","Inspired by these questions: Probability of Couples sitting next to each other (Sitting in a Row) Probability question about married couples Four married couples, eight seats. Probability that husband sits next to his wife? In how many ways can n couples (husband and wife) be arranged on a bench so no wife would sit next to her husband? No husband can sit next to his wife in this probability question the more general question of the probability that seating $n$ couples (i.e. $2n$ individuals) in a row at random means that no couples are sat together can be expressed using inclusion-exclusion as $$\displaystyle\sum_{i=0}^n (-2)^i {n \choose i}\frac{(2n-i)!}{(2n)!}$$ which for small $n$ takes the values: n   Probability of no couple together            1   0           0    2   1/3         0.3333333 3   1/3         0.3333333 4   12/35       0.3481481 5   47/135      0.3428571    6   3655/10395  0.3516114 7   1772/5005   0.3540460 8   20609/57915 0.3558491 This made me wonder whether it converges to $e^{-1} \approx  0.3678794$ as $n$ increases, like other cases such as the secretary/dating problem and $\left(1-\frac1n\right)^n$ do.  So I tried the following R code (using logarithms to avoid overflows) couples  <- 1000000 together <- 0:couples sum( (-1)^together * exp( log(2)*together + lchoose(couples,together) +       lfactorial(2*couples - together) - lfactorial(2*couples) ) ) which indeed gave a figure of $0.3678794$. How might one try to prove this limit?",,"['probability', 'combinatorics', 'limits']"
30,How many expected people needed until 3 share a birthday?,How many expected people needed until 3 share a birthday?,,"I asked a somewhat related question recently and then became interested in this one: how many people are required, on average, until 3 share a birthday?  More generally, if we have $M$ bins, what is the expected number of balls we must toss before some bin contains exactly 3 balls? The straightforward techniques used in the question cited above seem hard-to-apply here because the number of ways to obtain configurations with 2-balls-or-fewer is quite a bit messier now. Question: what is the expected number of balls needed to obtain a bin with 3 balls in it? To expand a bit on the ""messy"" comment above: the EGF for the number of ways to toss $n$ balls into $M$ bins with no bin containing more than 2 balls is $$(1+z+z^2/2)^M$$ So, for example, if we have $M=3$ bins, the number of ways for $n$ balls to be arranged (with no bin having more than 2 balls) is found by taking the $n$-th coefficient of  $$(1+z+z^2/2)^3 = 1/0! + 3 z/1! + 9z^2/2! + 24z^3/3! + 54z^4/4! + 90z^5/5! + 90z^6/6!$$ So if I want the number of 4-letter words from the alphabet $\{a,b,c\}$ where no letter occurs more than twice, it's the coefficient of ${z^4/4!}$ or  54 according to this formula.  We can verify this directly by noticing there are three 4-letter words with all characters the same (aaaa, bbbb, and cccc).  For the words with 3 letters the same and one different, there are 4 ways to choose the position of the different letter, then 3 choices of what that letter is, then 2 choices for the three letters that match.  The total number of 4-letter words is therefore $3^4=81$, so we have $81-3-4\cdot 3\cdot 2 = 54$.  Of course this gets complicated as $M$ increases. How you get from this EGF to an asymptotic estimate of the expectation is beyond me. Note: Byron's answer below settles this.  For anyone interested, this fully generalizes to ""k-wise collisions"" using $$E(M,k) \approx \sqrt[k]{k!}\ \Gamma(1 + 1/k)\ M^{1-1/k}$$ where setting $k=3$ yields the result in Byron's answer below.  Of course this is an asymptotic result and gets better as $M$ increases.  For $M$=365 this formula yields about 82.87, whereas the correct answer is about 88.73891.","I asked a somewhat related question recently and then became interested in this one: how many people are required, on average, until 3 share a birthday?  More generally, if we have $M$ bins, what is the expected number of balls we must toss before some bin contains exactly 3 balls? The straightforward techniques used in the question cited above seem hard-to-apply here because the number of ways to obtain configurations with 2-balls-or-fewer is quite a bit messier now. Question: what is the expected number of balls needed to obtain a bin with 3 balls in it? To expand a bit on the ""messy"" comment above: the EGF for the number of ways to toss $n$ balls into $M$ bins with no bin containing more than 2 balls is $$(1+z+z^2/2)^M$$ So, for example, if we have $M=3$ bins, the number of ways for $n$ balls to be arranged (with no bin having more than 2 balls) is found by taking the $n$-th coefficient of  $$(1+z+z^2/2)^3 = 1/0! + 3 z/1! + 9z^2/2! + 24z^3/3! + 54z^4/4! + 90z^5/5! + 90z^6/6!$$ So if I want the number of 4-letter words from the alphabet $\{a,b,c\}$ where no letter occurs more than twice, it's the coefficient of ${z^4/4!}$ or  54 according to this formula.  We can verify this directly by noticing there are three 4-letter words with all characters the same (aaaa, bbbb, and cccc).  For the words with 3 letters the same and one different, there are 4 ways to choose the position of the different letter, then 3 choices of what that letter is, then 2 choices for the three letters that match.  The total number of 4-letter words is therefore $3^4=81$, so we have $81-3-4\cdot 3\cdot 2 = 54$.  Of course this gets complicated as $M$ increases. How you get from this EGF to an asymptotic estimate of the expectation is beyond me. Note: Byron's answer below settles this.  For anyone interested, this fully generalizes to ""k-wise collisions"" using $$E(M,k) \approx \sqrt[k]{k!}\ \Gamma(1 + 1/k)\ M^{1-1/k}$$ where setting $k=3$ yields the result in Byron's answer below.  Of course this is an asymptotic result and gets better as $M$ increases.  For $M$=365 this formula yields about 82.87, whereas the correct answer is about 88.73891.",,"['probability', 'balls-in-bins', 'birthday']"
31,Strictly positive martingales,Strictly positive martingales,,"Does the following property for martingales hold? Given a continuous martingale $(X_t)_{t\leq T}$ that is almost surely strictly positive at time T, i.e. $\mathbb{P}(X_T >0)=1$, we have $P(X_t > 0 \,\, \text{for all} \,\, t \in [0,T])=1$. I tried fiddling around with the optional stopping theorem and different stopping times like $\inf\{t\leq T\, |\, X_t = 0\} \wedge T$, but have gotten nowhere yet.","Does the following property for martingales hold? Given a continuous martingale $(X_t)_{t\leq T}$ that is almost surely strictly positive at time T, i.e. $\mathbb{P}(X_T >0)=1$, we have $P(X_t > 0 \,\, \text{for all} \,\, t \in [0,T])=1$. I tried fiddling around with the optional stopping theorem and different stopping times like $\inf\{t\leq T\, |\, X_t = 0\} \wedge T$, but have gotten nowhere yet.",,"['probability', 'stochastic-processes', 'stochastic-calculus']"
32,Inter-causal reasoning: How to solve probability with two conditions?,Inter-causal reasoning: How to solve probability with two conditions?,,"Below is the scheme of conditional dependence and the probabilities of events: P(A=1) = 0.01 P(A=0) = 0.99 P(B=1) = 0.1 P(B=0) = 0.9 P(C=1|A=0,B=0) = 0.1 P(C=1|A=0,B=1) = 0.5 P(C=1|A=1,B=0) = 0.6 P(C=1|A=1,B=1) = 0.9 Given the probabilities above I wanted to calculate P(B=1|C=1) and P(B=1|C=1,A=1) but didn't get the correct result. I wrote the probabilistic function the following way: P(A, B, C) = P(A)P(B)P(C|A, B) and then set the variables P(B=1, C=1) = P(A=0, B=1, C=1) + P(A=1, B=1, C=1)= =P(A=0)P(B=1)P(C=1|A=0, B=1) + P(A=1)P(B=1)P(C=1|A=1, B=1)= =0.99*0.1*0.5 + 0.01*0.1*0.9 = 0.0495 The result however is not correct and don't know where is the error. I would be very thankful if anyone could correct/explain what's wrong.","Below is the scheme of conditional dependence and the probabilities of events: P(A=1) = 0.01 P(A=0) = 0.99 P(B=1) = 0.1 P(B=0) = 0.9 P(C=1|A=0,B=0) = 0.1 P(C=1|A=0,B=1) = 0.5 P(C=1|A=1,B=0) = 0.6 P(C=1|A=1,B=1) = 0.9 Given the probabilities above I wanted to calculate P(B=1|C=1) and P(B=1|C=1,A=1) but didn't get the correct result. I wrote the probabilistic function the following way: P(A, B, C) = P(A)P(B)P(C|A, B) and then set the variables P(B=1, C=1) = P(A=0, B=1, C=1) + P(A=1, B=1, C=1)= =P(A=0)P(B=1)P(C=1|A=0, B=1) + P(A=1)P(B=1)P(C=1|A=1, B=1)= =0.99*0.1*0.5 + 0.01*0.1*0.9 = 0.0495 The result however is not correct and don't know where is the error. I would be very thankful if anyone could correct/explain what's wrong.",,['probability']
33,"Keys inside closed boxes, a question on probability","Keys inside closed boxes, a question on probability",,"The keys to $n$ boxes are placed randomly in the boxes, one per box, The boxes are closed, which locks them. I would like to know the probability that breaking open $k$ random boxes will allow all the remaining boxes to be unlocked. Could you help me please?","The keys to $n$ boxes are placed randomly in the boxes, one per box, The boxes are closed, which locks them. I would like to know the probability that breaking open $k$ random boxes will allow all the remaining boxes to be unlocked. Could you help me please?",,"['probability', 'permutations']"
34,Optimal Strategy for Deal or No Deal,Optimal Strategy for Deal or No Deal,,"When I have watched Deal or No Deal (I try not to make a habit of it) I always do little sums in my head to work out if the banker is offering a good deal. Where odds drop below ""evens"" it's easy to see it's a bad deal, but what would be the correct mathematical way to decide if you're getting a good deal?","When I have watched Deal or No Deal (I try not to make a habit of it) I always do little sums in my head to work out if the banker is offering a good deal. Where odds drop below ""evens"" it's easy to see it's a bad deal, but what would be the correct mathematical way to decide if you're getting a good deal?",,"['probability', 'recreational-mathematics']"
35,Simple random walk on cycle graph (Ending on specific vertex after cover time),Simple random walk on cycle graph (Ending on specific vertex after cover time),,"I'm considering a simple random walk on a cycle graph comprising a number of vertices, labelled $1$ to $5$ consecutively. Suppose I start at vertex 1 and can traverse to either side ( $2$ or $5$ ). I continue this random walk until I have covered all vertices. What is the probability that I finish on node $3$ , and the expected number of steps to get there? How do I calculate the same quantities if I finish on the other vertices? How do I generalise to say $n$ vertices? I have seen multiple resources discussing the cover time on a cycle graph, but in this context, I guess I have to include a discussion on either stopping time after visiting all vertices (which I don't really know how to include here, perhaps via a conditional probability) or transforming the end state as an absorbing state (which I guess won't make it a Markov chain anymore). I also suspect that for the first part (ending on node 3) we can exploit symmetry, but I'm not sure how. What should I do here? Thanks! Edit: after simulating this, I've noticed that the probabilities of ending at any node is $1/4$ . The expected number of steps terminating at $3$ (or $4$ ) should be $11$ , and the expected number of steps terminating at $2$ (or $5$ ) should be $9$ .","I'm considering a simple random walk on a cycle graph comprising a number of vertices, labelled to consecutively. Suppose I start at vertex 1 and can traverse to either side ( or ). I continue this random walk until I have covered all vertices. What is the probability that I finish on node , and the expected number of steps to get there? How do I calculate the same quantities if I finish on the other vertices? How do I generalise to say vertices? I have seen multiple resources discussing the cover time on a cycle graph, but in this context, I guess I have to include a discussion on either stopping time after visiting all vertices (which I don't really know how to include here, perhaps via a conditional probability) or transforming the end state as an absorbing state (which I guess won't make it a Markov chain anymore). I also suspect that for the first part (ending on node 3) we can exploit symmetry, but I'm not sure how. What should I do here? Thanks! Edit: after simulating this, I've noticed that the probabilities of ending at any node is . The expected number of steps terminating at (or ) should be , and the expected number of steps terminating at (or ) should be .",1 5 2 5 3 n 1/4 3 4 11 2 5 9,"['probability', 'markov-chains', 'expected-value', 'conditional-probability', 'conditional-expectation']"
36,Suppose we have $N$ people. A random selection of $k$ of these people meet each day. What is the expected number of days until everyone has met?,Suppose we have  people. A random selection of  of these people meet each day. What is the expected number of days until everyone has met?,N k,"I thought of this problem today and I'm not quite sure how it's solved. My idea is simply to use the definition of expectation: $$E[\text{# of days until everyone has met}] = \sum_{x=1} x \cdot p(x)$$ Where $p(x)$ is the probability that everyone has met in $x$ days. After that, I'm not quite sure how to compute $p(x)$ . Is this the correct approach? If so, any ideas for how to compute $p(x)$ ? Also, does anyone have ideas for how to solve the case for the expected number of days until $X \%$ of people have met?","I thought of this problem today and I'm not quite sure how it's solved. My idea is simply to use the definition of expectation: Where is the probability that everyone has met in days. After that, I'm not quite sure how to compute . Is this the correct approach? If so, any ideas for how to compute ? Also, does anyone have ideas for how to solve the case for the expected number of days until of people have met?",E[\text{# of days until everyone has met}] = \sum_{x=1} x \cdot p(x) p(x) x p(x) p(x) X \%,"['probability', 'combinatorics', 'graph-theory', 'expected-value', 'coupon-collector']"
37,"Let $\{X_n\}$ be i.i.d $N(0,1)$ random variables. Show that $\limsup_{n\rightarrow\infty} \frac{|X_n|}{\sqrt{\log n}}=\sqrt2$ a.s.",Let  be i.i.d  random variables. Show that  a.s.,"\{X_n\} N(0,1) \limsup_{n\rightarrow\infty} \frac{|X_n|}{\sqrt{\log n}}=\sqrt2","Let $\{X_n\}_{n\ge1}$ be independent $N(0,1)$ random variables. Show that $$\limsup\limits_{n\to\infty} \frac{\left|X_n\right|}{\sqrt{\log(n)}}=\sqrt{2} \qquad \text{a.s.}$$ I aim to prove this using the fact that $$\limsup\limits_{n\to\infty} X_n = b \quad \iff \quad \text{for all } \varepsilon>0 \ : \ \Biggl\{ \begin{array}{l} \mathbb{P}(X_n \le b+\varepsilon \text{ eventually})=1, \text{ and} \\ \mathbb{P}(X_n > b-\varepsilon\text{ i.o.})=1. \end{array}$$ I show the first of these two conditions as follows: \begin{align*} &\hspace{-2em}\mathbb{P}\left(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\right)\\ &= \mathbb{P}\bigl(|X_1|>(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}\bigr) & \text{as $X_n$'s are identically distributed}\\ &=\int_{(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}}^{\infty} |x|\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \, dx\\ &=\int_{(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}}^{\infty} x\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \, dx\\ &=\frac{1}{\sqrt{2\pi}}\int_{(\sqrt{2}+\varepsilon)^2\log(n)}^{\infty} e^{-u}du & \text{by making the substitution $u=\frac{x^2}{2}$}\\ &=-\frac{1}{\sqrt{2\pi}}\bigl[e^{-\infty}-e^{-\log(n)(\sqrt{2}+\varepsilon)^2}\bigr]\\ &=\frac{1}{\sqrt{2\pi}}n^{-(\sqrt{2}+\varepsilon)^2} \end{align*} Thus, we have: \begin{align*} \sum_{n=1}^\infty \mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\Biggr)&=\sum_{n=1}^{\infty}\frac{1}{\sqrt{2\pi}}n^{-(\sqrt{2} + \varepsilon)^2}\\ &<\infty \qquad \text{ since $\sqrt{2}+\varepsilon>1$} \end{align*} So, by the Borel–Cantelli Lemmas: \begin{align} &\mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\text{ i.o.}\Biggr)=0\\ &\implies \mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} \le \sqrt{2} + \varepsilon\text{ eventually}\Biggr)=1 \end{align} It remains then to show that $$\mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} - \varepsilon \text{ i.o.}\Biggr)=1.$$ To do this, I would like to run a symmetric argument to the one above but here we need the final series to diverge which will happen if and only if $\sqrt{2}-\varepsilon \le1$ , which happens if and only if $\varepsilon\ge \sqrt{2}-1=0.414\ldots$ and so $\varepsilon$ is getting away from zero, which we can't have. Unless I am making a stupid mistake or missing something obvious, I don't see a way around this issue. Is this approach doomed to fail or is there a way to fix it up? Or is there just a better approach in general for such a problem. Thanks in advance. The problem is #1 (a) from this exam","Let be independent random variables. Show that I aim to prove this using the fact that I show the first of these two conditions as follows: Thus, we have: So, by the Borel–Cantelli Lemmas: It remains then to show that To do this, I would like to run a symmetric argument to the one above but here we need the final series to diverge which will happen if and only if , which happens if and only if and so is getting away from zero, which we can't have. Unless I am making a stupid mistake or missing something obvious, I don't see a way around this issue. Is this approach doomed to fail or is there a way to fix it up? Or is there just a better approach in general for such a problem. Thanks in advance. The problem is #1 (a) from this exam","\{X_n\}_{n\ge1} N(0,1) \limsup\limits_{n\to\infty} \frac{\left|X_n\right|}{\sqrt{\log(n)}}=\sqrt{2} \qquad \text{a.s.} \limsup\limits_{n\to\infty} X_n = b \quad \iff \quad \text{for all } \varepsilon>0 \ : \ \Biggl\{ \begin{array}{l}
\mathbb{P}(X_n \le b+\varepsilon \text{ eventually})=1, \text{ and} \\
\mathbb{P}(X_n > b-\varepsilon\text{ i.o.})=1.
\end{array} \begin{align*}
&\hspace{-2em}\mathbb{P}\left(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\right)\\
&= \mathbb{P}\bigl(|X_1|>(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}\bigr) & \text{as X_n's are identically distributed}\\
&=\int_{(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}}^{\infty} |x|\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \, dx\\
&=\int_{(\sqrt{2}+\varepsilon)\sqrt{\smash[b]{\log(n)}}}^{\infty} x\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}} \, dx\\
&=\frac{1}{\sqrt{2\pi}}\int_{(\sqrt{2}+\varepsilon)^2\log(n)}^{\infty} e^{-u}du & \text{by making the substitution u=\frac{x^2}{2}}\\
&=-\frac{1}{\sqrt{2\pi}}\bigl[e^{-\infty}-e^{-\log(n)(\sqrt{2}+\varepsilon)^2}\bigr]\\
&=\frac{1}{\sqrt{2\pi}}n^{-(\sqrt{2}+\varepsilon)^2}
\end{align*} \begin{align*}
\sum_{n=1}^\infty \mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\Biggr)&=\sum_{n=1}^{\infty}\frac{1}{\sqrt{2\pi}}n^{-(\sqrt{2} + \varepsilon)^2}\\
&<\infty \qquad \text{ since \sqrt{2}+\varepsilon>1}
\end{align*} \begin{align}
&\mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} + \varepsilon\text{ i.o.}\Biggr)=0\\
&\implies \mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} \le \sqrt{2} + \varepsilon\text{ eventually}\Biggr)=1
\end{align} \mathbb{P}\Biggl(\frac{\left|X_n\right|}{\sqrt{\log(n)}} > \sqrt{2} - \varepsilon \text{ i.o.}\Biggr)=1. \sqrt{2}-\varepsilon \le1 \varepsilon\ge \sqrt{2}-1=0.414\ldots \varepsilon","['probability', 'probability-theory', 'self-learning', 'probability-limit-theorems']"
38,"Given a knight on an infinite chess board that moves randomly, what's the expected number of distinct squares it reaches in 50 moves?","Given a knight on an infinite chess board that moves randomly, what's the expected number of distinct squares it reaches in 50 moves?",,"I was asked this in an interview and wasn't sure how to frame the answer. Basically as in the question you have a knight on an infinite chess board and it chooses one of its valid 8 moves uniformly at each move. After 50 moves, the question was to give (as tight as possible) a lower and upper bound on the expected number of distinct squares it reached. I got as far as realizing that the knight must live in a 200x200 square, and that it can only reach half of the squares (since it must end at the same colour as it started). However this doesn't really address the randomness aspect of the question.","I was asked this in an interview and wasn't sure how to frame the answer. Basically as in the question you have a knight on an infinite chess board and it chooses one of its valid 8 moves uniformly at each move. After 50 moves, the question was to give (as tight as possible) a lower and upper bound on the expected number of distinct squares it reached. I got as far as realizing that the knight must live in a 200x200 square, and that it can only reach half of the squares (since it must end at the same colour as it started). However this doesn't really address the randomness aspect of the question.",,"['probability', 'probability-theory', 'stochastic-processes', 'geometric-probability']"
39,Probability of ordered dice,Probability of ordered dice,,"Suppose you throw five dice, order them from lowest to highest number, then select the third die. What is the probability that the third die was number 2? Or, in general, when throwing $n$ dice and selecting the $i$th die (sorted from low to high), what is the probability that the number of that die is $k_i$? So the above example was $n=5,i=3,k_i=2$. How do you determine a general formula for finding the probability?","Suppose you throw five dice, order them from lowest to highest number, then select the third die. What is the probability that the third die was number 2? Or, in general, when throwing $n$ dice and selecting the $i$th die (sorted from low to high), what is the probability that the number of that die is $k_i$? So the above example was $n=5,i=3,k_i=2$. How do you determine a general formula for finding the probability?",,"['probability', 'combinatorics']"
40,What are some interesting un-intuitive problems in probability aside from Monty Hall?,What are some interesting un-intuitive problems in probability aside from Monty Hall?,,Does anyone know of some interesting and almost strange problems in probability? I know that probability is sometimes notorious for being mind-bending and un-intuitive! (Monty Hall is already an obvious one),Does anyone know of some interesting and almost strange problems in probability? I know that probability is sometimes notorious for being mind-bending and un-intuitive! (Monty Hall is already an obvious one),,"['probability', 'probability-theory', 'soft-question', 'intuition', 'independence']"
41,How to generate correlated random numbers with specific distributions?,How to generate correlated random numbers with specific distributions?,,"After read the answers of some similar questions on this site, e.g., Generate Correlated Normal Random Variables Generate correlated random numbers precisely I wonder whether such approaches can assure the specific distributions of random variables generated. In order to make it easier to present my question, let us consider a simple case of creating correlated two uniform continuous random variables on $[0,1]$ with correlation coefficient $\dfrac{1}{2}=\rho$. The methods by Cholesky decomposition (or spectral decomposition, similarly) first generates $X_1$ and $X_2$ which are independent pseudo random numbers uniformly distributed on $[0,1]$, and then creates $X_3=\rho X_1+\sqrt{1-\rho^2} X_2$. The $X_1$ and $X_3$ thus created are random variables  with correlation coefficient $\rho$. But the problem is, $X_3$ 's probability density fuction is triangle /trapezoid distribution which can be deducted by the convolution of the density functions of $X_1$ and $X_2$. The probability density functions of $\rho X_1$ and $\sqrt{1-\rho^2} X_2$ are: The convolution (sum) of them $X_3$ has density function: This means, the distribution of $X_3$ is not the desired uniform one on $[0,1]$. What should I do in order to create  random variables uniformly distributed on $[0,1]$ with correlation coefficient $\rho$ ? The similar issue persists when I want to create multiple correlated random variables with predefined correlation matrix. Considering the pseudo random variables usually are not really independent with a correlation coefficient between -1 and 1, it seems that: it is difficult to generate numerically independent $[0,1]$ uniform random variables since the uncorrelation transformation seems to always change the distribution profile. PS: Before asking this question, I had read the following questions and links but didnot find an answer : http://www.sitmo.com/article/generating-correlated-random-numbers/ http://numericalexpert.com/blog/correlated_random_variables/ https://en.wikipedia.org/wiki/Whitening_transformation","After read the answers of some similar questions on this site, e.g., Generate Correlated Normal Random Variables Generate correlated random numbers precisely I wonder whether such approaches can assure the specific distributions of random variables generated. In order to make it easier to present my question, let us consider a simple case of creating correlated two uniform continuous random variables on $[0,1]$ with correlation coefficient $\dfrac{1}{2}=\rho$. The methods by Cholesky decomposition (or spectral decomposition, similarly) first generates $X_1$ and $X_2$ which are independent pseudo random numbers uniformly distributed on $[0,1]$, and then creates $X_3=\rho X_1+\sqrt{1-\rho^2} X_2$. The $X_1$ and $X_3$ thus created are random variables  with correlation coefficient $\rho$. But the problem is, $X_3$ 's probability density fuction is triangle /trapezoid distribution which can be deducted by the convolution of the density functions of $X_1$ and $X_2$. The probability density functions of $\rho X_1$ and $\sqrt{1-\rho^2} X_2$ are: The convolution (sum) of them $X_3$ has density function: This means, the distribution of $X_3$ is not the desired uniform one on $[0,1]$. What should I do in order to create  random variables uniformly distributed on $[0,1]$ with correlation coefficient $\rho$ ? The similar issue persists when I want to create multiple correlated random variables with predefined correlation matrix. Considering the pseudo random variables usually are not really independent with a correlation coefficient between -1 and 1, it seems that: it is difficult to generate numerically independent $[0,1]$ uniform random variables since the uncorrelation transformation seems to always change the distribution profile. PS: Before asking this question, I had read the following questions and links but didnot find an answer : http://www.sitmo.com/article/generating-correlated-random-numbers/ http://numericalexpert.com/blog/correlated_random_variables/ https://en.wikipedia.org/wiki/Whitening_transformation",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'correlation']"
42,Complexity of Gaussian Process algorithms is $\mathcal{O}(n^3)$,Complexity of Gaussian Process algorithms is,\mathcal{O}(n^3),"It is often quoted that the complexity of Gaussian Process algorithms is $\mathcal{O}(n^3)$ due to the need to invert an $n \times n$ matrix, where $n$ is the number of data points. But as far as I can find online, matrix multiplication is also $\mathcal{O}(n^3)$. So would the complexity of GP algorithms still be $\mathcal{O}(n^3)$ if we no longer needed to invert matrices? Or have I missed something.","It is often quoted that the complexity of Gaussian Process algorithms is $\mathcal{O}(n^3)$ due to the need to invert an $n \times n$ matrix, where $n$ is the number of data points. But as far as I can find online, matrix multiplication is also $\mathcal{O}(n^3)$. So would the complexity of GP algorithms still be $\mathcal{O}(n^3)$ if we no longer needed to invert matrices? Or have I missed something.",,"['probability', 'algorithms', 'regression', 'machine-learning', 'neural-networks']"
43,"From a pack of 52 playing cards, three are drawn at random. Find the probability of drawing a king, a queen and jack.","From a pack of 52 playing cards, three are drawn at random. Find the probability of drawing a king, a queen and jack.",,"A simple question but the solution is confusing me. The answer I obtained was  $$p = 3! \times 4/52 \times 4/51 \times 4/50$$ The first 3! is for the order of king, queen, jack. $4/52$ is the probability of drawing a king, $4/51$ is the probability of drawing a queen after a king is drawn and $4/50$ is the probability of drawing a jack once both king and queen are drawn. But the book takes the solution as $$p = 3!  \times  4/52 \times 3/51 \times 2/50$$ Can anyone please explain how this comes? Thanks in advance.","A simple question but the solution is confusing me. The answer I obtained was  $$p = 3! \times 4/52 \times 4/51 \times 4/50$$ The first 3! is for the order of king, queen, jack. $4/52$ is the probability of drawing a king, $4/51$ is the probability of drawing a queen after a king is drawn and $4/50$ is the probability of drawing a jack once both king and queen are drawn. But the book takes the solution as $$p = 3!  \times  4/52 \times 3/51 \times 2/50$$ Can anyone please explain how this comes? Thanks in advance.",,"['probability', 'permutations', 'combinations', 'card-games']"
44,"Joint distribution of $\min(X_1,\ldots,X_n)$ and $\max(X_1,\ldots,X_n)$.",Joint distribution of  and .,"\min(X_1,\ldots,X_n) \max(X_1,\ldots,X_n)","Let $X_1,\ldots,X_n$ be independent random variables with common cumulative distribution function $F$. I am trying to find the joint cumulative distribution function of $$U=\min(X_1,\ldots,X_n)\quad\text{and}\quad V=\max(X_1,\ldots,X_n).$$ The result that I get is $$F_{U,V}(u,v)=F(v)^n-(F(v)-F(u))^n,$$ but this seems wrong because letting $u\to\infty$ gives the marginal CDF $$F_V(v)=F(v)^n-(F(v)-1)^n,$$ while it should be $F_V(v)=F(v)^n$. I obtained the result as follows $$\begin{align} F_{U,V}(u,v) &= P(U\leq u,V\leq v) \\ &= P(V\leq v)-P(U>u,V\leq v) \\ &= P(X_1\leq v,\ldots,X_n\leq v)-P(u<X_1\leq v,\ldots,u<X_n\leq v) \\ &= F(v)^n-(F(v)-F(u))^n. \end{align} $$ But $$F_V(v)=P(V\leq v)=P(X_1\leq v,\ldots,X_n\leq v)=P(X_1\leq v)\cdots P(X_n\leq v)=F(v)^n.$$ What is wrong with these computations?","Let $X_1,\ldots,X_n$ be independent random variables with common cumulative distribution function $F$. I am trying to find the joint cumulative distribution function of $$U=\min(X_1,\ldots,X_n)\quad\text{and}\quad V=\max(X_1,\ldots,X_n).$$ The result that I get is $$F_{U,V}(u,v)=F(v)^n-(F(v)-F(u))^n,$$ but this seems wrong because letting $u\to\infty$ gives the marginal CDF $$F_V(v)=F(v)^n-(F(v)-1)^n,$$ while it should be $F_V(v)=F(v)^n$. I obtained the result as follows $$\begin{align} F_{U,V}(u,v) &= P(U\leq u,V\leq v) \\ &= P(V\leq v)-P(U>u,V\leq v) \\ &= P(X_1\leq v,\ldots,X_n\leq v)-P(u<X_1\leq v,\ldots,u<X_n\leq v) \\ &= F(v)^n-(F(v)-F(u))^n. \end{align} $$ But $$F_V(v)=P(V\leq v)=P(X_1\leq v,\ldots,X_n\leq v)=P(X_1\leq v)\cdots P(X_n\leq v)=F(v)^n.$$ What is wrong with these computations?",,['probability']
45,A maximal Hoeffding's inequality?,A maximal Hoeffding's inequality?,,"Let $X_1, \cdots, X_n$ be real-valued independent random variables satisfying $|X_k|\le 1$ and $\mathbb EX_k=0$. Hoeffding's inequality tells us that for any $k=1,\cdots, n$ and $t>0$, $$\mathbb P\Big( \Big | \frac{X_1+\cdots+ X_k}{\sqrt{k}} \Big | \ge t \Big) \le 2 e^{-t^2/2}.$$ My question is whether there exists a similar bound for the maximum over $k$. More precisely: Question: Do there exist absolute constants $C>0$ and $A>0$ so that   $$\mathbb P\Big( \max_{1\le k\le n} \Big | \frac{X_1+\cdots+ X_k}{\sqrt{k}} \Big | \ge t \Big) \le C e^{-t^2/A}$$   holds for all $t>0$? If not what can we say about the left hand side?","Let $X_1, \cdots, X_n$ be real-valued independent random variables satisfying $|X_k|\le 1$ and $\mathbb EX_k=0$. Hoeffding's inequality tells us that for any $k=1,\cdots, n$ and $t>0$, $$\mathbb P\Big( \Big | \frac{X_1+\cdots+ X_k}{\sqrt{k}} \Big | \ge t \Big) \le 2 e^{-t^2/2}.$$ My question is whether there exists a similar bound for the maximum over $k$. More precisely: Question: Do there exist absolute constants $C>0$ and $A>0$ so that   $$\mathbb P\Big( \max_{1\le k\le n} \Big | \frac{X_1+\cdots+ X_k}{\sqrt{k}} \Big | \ge t \Big) \le C e^{-t^2/A}$$   holds for all $t>0$? If not what can we say about the left hand side?",,"['probability', 'statistics', 'probability-theory']"
46,Find: The expected number of urns that are empty,Find: The expected number of urns that are empty,,"A total of $n$ balls, numbered $1$ through $n$, are put into $n$ urns, also numbered $1$ through $n$ in such a way that ball $i$ is equally likely to go into any of the urns $1, 2, . . . , i$. Find the expected number of urns that are empty. Can somebody help me? I don´t understand. Thanks very much.","A total of $n$ balls, numbered $1$ through $n$, are put into $n$ urns, also numbered $1$ through $n$ in such a way that ball $i$ is equally likely to go into any of the urns $1, 2, . . . , i$. Find the expected number of urns that are empty. Can somebody help me? I don´t understand. Thanks very much.",,"['probability', 'balls-in-bins']"
47,Deriving the 37-percent rule for dating,Deriving the 37-percent rule for dating,,"I am trying to prove the theoretical ""37-percent rule"" for dating.  The setup, if I remember correctly, is this.  Suppose that you will meet exactly $N$ potential mates in your life, and you will meet them one at a time, in a perfectly random order.  The potential mates rank from best to worst (in a total ordering), and you want to maximize the probability that you end up with the best one.  However, you can only tell how good the mates are relative to each other , so while you can fully rank the people you've already met, you can't say anything about the ones you have yet to meet.  Also, for each potential mate, you can either stay with them forever or leave forever, i.e. there is no divorce or post-breakup dating. The result I have heard, and which I am trying to prove, is that your best strategy is to wait and reject the first 37% of them ($1/e$, to be precise), and then marry the next one that is better than all you have previously met .  The $1/e$ number presumably arises as the limit as $N \to \infty$. Obviously, you should never marry someone who isn't strictly better than all the previous ones, because then your chances of picking the right one are $0$.  Also, given a strategy that you wait through the first $K$ partners and then marry the next one that is the best so far, I calculate your expected chances of succeeding as \begin{equation} \frac{\displaystyle \sum_{M = K}^{N-1} \frac{M - 1 \choose K-1}{N - M}}{N \choose K} \end{equation} (Let $M$ be the maximum value among the first $K$ people you meet, where $1$ is the value of the worst person, $2$ is the next, and so on, with your desired mate having value $N$.  Given $M$, your chances of winning are $\frac{1}{N - M}$, because the value $N$ must be the first to appear out of the highest $N - M$ values.  The chances of the maximum being exactly $M$ are ${M - 1\choose K - 1}/{N \choose K}$.) (The above formula doesn't technically work for $K = 0$, but the reasonable convention ${-1 \choose -1} = 1$ gives the desired value $\frac1N$.) The two things I am unable to prove, and which I would like to see ideas for, are: Given that you never pick someone unless they are the best so far, how do you prove further that the best strategy must involve waiting for some $K$ people and then going for anyone else after that $K$? Why is the formula above optomized at $K = N / e$, and how could one show this?","I am trying to prove the theoretical ""37-percent rule"" for dating.  The setup, if I remember correctly, is this.  Suppose that you will meet exactly $N$ potential mates in your life, and you will meet them one at a time, in a perfectly random order.  The potential mates rank from best to worst (in a total ordering), and you want to maximize the probability that you end up with the best one.  However, you can only tell how good the mates are relative to each other , so while you can fully rank the people you've already met, you can't say anything about the ones you have yet to meet.  Also, for each potential mate, you can either stay with them forever or leave forever, i.e. there is no divorce or post-breakup dating. The result I have heard, and which I am trying to prove, is that your best strategy is to wait and reject the first 37% of them ($1/e$, to be precise), and then marry the next one that is better than all you have previously met .  The $1/e$ number presumably arises as the limit as $N \to \infty$. Obviously, you should never marry someone who isn't strictly better than all the previous ones, because then your chances of picking the right one are $0$.  Also, given a strategy that you wait through the first $K$ partners and then marry the next one that is the best so far, I calculate your expected chances of succeeding as \begin{equation} \frac{\displaystyle \sum_{M = K}^{N-1} \frac{M - 1 \choose K-1}{N - M}}{N \choose K} \end{equation} (Let $M$ be the maximum value among the first $K$ people you meet, where $1$ is the value of the worst person, $2$ is the next, and so on, with your desired mate having value $N$.  Given $M$, your chances of winning are $\frac{1}{N - M}$, because the value $N$ must be the first to appear out of the highest $N - M$ values.  The chances of the maximum being exactly $M$ are ${M - 1\choose K - 1}/{N \choose K}$.) (The above formula doesn't technically work for $K = 0$, but the reasonable convention ${-1 \choose -1} = 1$ gives the desired value $\frac1N$.) The two things I am unable to prove, and which I would like to see ideas for, are: Given that you never pick someone unless they are the best so far, how do you prove further that the best strategy must involve waiting for some $K$ people and then going for anyone else after that $K$? Why is the formula above optomized at $K = N / e$, and how could one show this?",,['probability']
48,Convex Combinations of Low Probability Bernoulli Variables,Convex Combinations of Low Probability Bernoulli Variables,,"Let $X_1,\dots,X_n$ be independent Bernoulli variables with probability $p<\frac{1}{2}$ (even $p\le\frac{1}{3}$ if needed). Let $\alpha_1,\ldots,\alpha_n$ be non-negative real numbers such that $\sum\limits_{i=1}^n \alpha_i = 1$, and let $Y = \sum\limits_{i=1}^n \alpha_i X_i$. Prove (or disprove): $\Pr(Y\ge p)\ge p$. I can prove this for all $p=\frac{1}{k}$, $k\ge3$, but intuitively it seems to me that it should be true for all $p<\frac{1}{2}$, and I could not find a proof for that. EDIT: my (or rather, a friend's) proof for $p = \frac{1}{k}$: For each Bernoulli variable define a random variable $Z_i$ that takes values from a set of formal objects $\{b_1,\ldots b_k\}$ uniformly, and define a function $f$ on these formal objects as $f(b_1) = 1$, $\forall_{i>1}f(b_i)=0$. Clearly, $f(Z_i)$ is a Bernoulli variable with probability $p$, but the sample space for a convex combination of $f(Z_1),\ldots f(Z_n)$ can be now viewed as consisting of $k^n$ states of the form $(b_{i_1},\ldots,b_{i_n})$ from which one is selected uniformly. Group these states into sets of $k$ states of cyclic shifts of the indices (that is, $(b_{i_1},\ldots,b_{i_n})$ and $(b_{j_1},\ldots,b_{j_n})$ are in the same set iff for all for all $1\le s \le n$, $b_{j_s} = b_{i_s} + c (\mod k)$ for some $s$-independent integer $c$). The sum of the values of a convex combination of such sets under $f$ is exactly $1$, since each component is $b_0$ in exactly one member of the set, so in each set there exists at least one state whose value is greater than or equal to $\frac{1}{k}$. To sum up, I have proven that the new sample space can be divided into sets of $k$ points such that in each set there exists at least one point valued above (or at) $\frac{1}{k}$, and the probability of choosing such a point is at least $\frac{1}{k}$.","Let $X_1,\dots,X_n$ be independent Bernoulli variables with probability $p<\frac{1}{2}$ (even $p\le\frac{1}{3}$ if needed). Let $\alpha_1,\ldots,\alpha_n$ be non-negative real numbers such that $\sum\limits_{i=1}^n \alpha_i = 1$, and let $Y = \sum\limits_{i=1}^n \alpha_i X_i$. Prove (or disprove): $\Pr(Y\ge p)\ge p$. I can prove this for all $p=\frac{1}{k}$, $k\ge3$, but intuitively it seems to me that it should be true for all $p<\frac{1}{2}$, and I could not find a proof for that. EDIT: my (or rather, a friend's) proof for $p = \frac{1}{k}$: For each Bernoulli variable define a random variable $Z_i$ that takes values from a set of formal objects $\{b_1,\ldots b_k\}$ uniformly, and define a function $f$ on these formal objects as $f(b_1) = 1$, $\forall_{i>1}f(b_i)=0$. Clearly, $f(Z_i)$ is a Bernoulli variable with probability $p$, but the sample space for a convex combination of $f(Z_1),\ldots f(Z_n)$ can be now viewed as consisting of $k^n$ states of the form $(b_{i_1},\ldots,b_{i_n})$ from which one is selected uniformly. Group these states into sets of $k$ states of cyclic shifts of the indices (that is, $(b_{i_1},\ldots,b_{i_n})$ and $(b_{j_1},\ldots,b_{j_n})$ are in the same set iff for all for all $1\le s \le n$, $b_{j_s} = b_{i_s} + c (\mod k)$ for some $s$-independent integer $c$). The sum of the values of a convex combination of such sets under $f$ is exactly $1$, since each component is $b_0$ in exactly one member of the set, so in each set there exists at least one state whose value is greater than or equal to $\frac{1}{k}$. To sum up, I have proven that the new sample space can be divided into sets of $k$ points such that in each set there exists at least one point valued above (or at) $\frac{1}{k}$, and the probability of choosing such a point is at least $\frac{1}{k}$.",,"['probability', 'random-variables']"
49,Probability that all bins contain strictly more than one ball?,Probability that all bins contain strictly more than one ball?,,"Here's the problem I'm working on: Given that I'm distributing $N$ balls into $K$ bins, what is the probability that all bins contain at least two (strictly more than 1) balls? This seems like a very similar question to asking what the probability that all bins contain strictly more than zero (e.g., all are occupied), but for whatever reason it's a lot harder! Although the problem is similar to this related question addressed by Henry , Joe , David Mitra , and MJD regarding the expected number of bins containing >1 balls , it doesn't seem like I can apply the same method since different occupancy sets occur with different probabilities. For example, distributing $N=4$ balls into $K=2$ bins, there are $K^N=16$ total distributions, six of which have two balls in each bin, giving me a probability of $6/16$. Is there a general solution?","Here's the problem I'm working on: Given that I'm distributing $N$ balls into $K$ bins, what is the probability that all bins contain at least two (strictly more than 1) balls? This seems like a very similar question to asking what the probability that all bins contain strictly more than zero (e.g., all are occupied), but for whatever reason it's a lot harder! Although the problem is similar to this related question addressed by Henry , Joe , David Mitra , and MJD regarding the expected number of bins containing >1 balls , it doesn't seem like I can apply the same method since different occupancy sets occur with different probabilities. For example, distributing $N=4$ balls into $K=2$ bins, there are $K^N=16$ total distributions, six of which have two balls in each bin, giving me a probability of $6/16$. Is there a general solution?",,"['probability', 'combinatorics', 'balls-in-bins']"
50,Estimating maximum value of random variable,Estimating maximum value of random variable,,"Suppose I have some random variable $X$ which only takes on values over some finite region of the real line, and I want to estimate the maximum value of this random variable. Obviously one crude method is to take many measurements, lets say $X_1$, $X_2$, $\ldots, X_n$ (which we'll say are all iid) and to use  $$X_{max} = \text{max}(X_1, \ldots X_n)$$ as my guess, and as long as $n$ is large enough this should be good enough. However, $X_{max}$ is always less than the actual maximum, and I'm wondering if there's any way to modify $X_{max}$ so it gives a guess (still with some uncertainty) which is centred around the actual maximum value, rather than always a little less than it. Thanks","Suppose I have some random variable $X$ which only takes on values over some finite region of the real line, and I want to estimate the maximum value of this random variable. Obviously one crude method is to take many measurements, lets say $X_1$, $X_2$, $\ldots, X_n$ (which we'll say are all iid) and to use  $$X_{max} = \text{max}(X_1, \ldots X_n)$$ as my guess, and as long as $n$ is large enough this should be good enough. However, $X_{max}$ is always less than the actual maximum, and I'm wondering if there's any way to modify $X_{max}$ so it gives a guess (still with some uncertainty) which is centred around the actual maximum value, rather than always a little less than it. Thanks",,['probability']
51,"Calculating the ""Spreads"" for Different Outcomes in Dice Rolls?","Calculating the ""Spreads"" for Different Outcomes in Dice Rolls?",,"Suppose I roll a 6-sided die 100 times and observe the following data - let's say that I don't know the probability of getting any specific number (but I am assured that each ""trial"" is independent from the previous ""trial""). Below, here is some R code to simulate this experiment: # Set the probabilities for each number (pretend this is unknown in real life) probs <- c(0.1, 0.2, 0.3, 0.2, 0.1, 0.1)  # Generate 100 random observations observations <- sample(1:6, size = 100, replace = TRUE, prob = probs)  # Print the observations print(observations)    [1] 2 4 2 2 4 6 2 2 6 6 3 4 6 4 2 1 3 6 3 1 2 5 3 6 4 6 1 3 4 2 6 2 4 1 3 3 3 5 2 5 2 3 5 1 4 6 1 6 4 2  [51] 2 3 2 3 3 5 6 5 4 3 2 3 2 1 2 3 2 2 5 3 2 1 1 1 3 3 2 4 4 3 1 4 4 6 3 3 5 5 2 2 1 3 2 1 6 3 4 3 3 3 As we know, the above experiment corresponds to the Multinomial Probability Distribution Function ( https://en.wikipedia.org/wiki/Multinomial_distribution ): $$ P(X_1 = x_1, X_2 = x_2, \dots, X_k = x_k) = \frac{n!}{x_1!x_2!\dots x_k!}p_1^{x_1}p_2^{x_2} \dots p_k^{x_k} $$ Using Maximum Likelihood Estimation ( https://en.wikipedia.org/wiki/Maximum_likelihood_estimation MLE), the estimate for the probability for getting any number on this die is given by (e.g. what is the probability that this above die gives you a ""3""?): $$ \hat{p}_{i,\text{MLE}} = \frac{x_i}{n} $$ Next, the Variance for each of these parameters can be written as follows : $$ \text{Var}(\hat{p}_{i,\text{MLE}}) = \frac{p_i(1 - p_i)}{n} $$ From here, I am interested in estimating the ""spreads"" of these probabilities - for example, there might be a 0.2 probability of getting a ""6"" - but we can then ""bound"" this estimate and say there is a 0.2 ± 0.05 probability of rolling a 6. Effectively, this ""bounding"" corresponds to a Confidence Interval ( https://en.wikipedia.org/wiki/Confidence_interval ). Recently, I learned that when writing Confidence Intervals for ""proportions and probabilities"", we might not be able to use the ""classic"" notion of the Confidence Interval (i.e. parameter ± z-alpha/2*sqrt(var(parameter))), because this could result in these bounds going over ""1"" and below ""0"", thus violating the fundamental definitions of probability. Doing some reading online, I found different methods that might be applicable for writing the Confidence Intervals for the parameters of a Multinomial Distribution. Bootstrapping ( https://en.wikipedia.org/wiki/Bootstrapping_(statistics) ): By virtue of the Large Law of Large Numbers ( https://en.wikipedia.org/wiki/Law_of_large_numbers ), Bootstrapping works by repeatedly resampling your observed data and using this MLE formulas to calculate the parameters of interest on each of these re-samples. Then, you would sort the parameter in estimates in ascending order and take the estimates corresponding to the 5th and 95th percentiles. These estimates from the 5th and 95th percentiles would now correspond to the desired Confidence Interval. As I understand, this is an approximate method , but I have heard that the Law of Large Numbers argues that for an infinite sized population and an infinite number of resamples, the bootstrap estimates will converge to the actual values. It is important to note that in this case, the ""Sequential Bootstrap"" approach needs to be used such that the chronological order of the observed data is not interrupted. Delta Method ( https://en.wikipedia.org/wiki/Delta_method ): The Delta Method uses a Taylor Approximation ( https://en.wikipedia.org/wiki/Taylor%27s_theorem ) for the function of interest (i.e. MLE variance estimate). Even though this is also said to be an approximate method (i.e. the Delta Method relies on the Taylor APPROXIMATION), there supposedly exists mathematical theory (e.g. https://en.wikipedia.org/wiki/Continuous_mapping_theorem ) which can demonstrate that estimates from the Delta Method ""converge in probability"" to the actual values. This being said, I am not sure how the Delta method can directly be used to calculate Confidence Intervals. Finally, very recently I learned about the Wilson Interval ( https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval ), which is said to be more suitable for writing Confidence Intervals in the case of proportions and probabilities. In the case of the Multinomial Probability Distribution, I think the Wilson Interval for 95% Confidence Intervals on parameter estimates can be written as follows: $$ \left( \hat{\theta} - \frac{z_{\alpha/2} \sqrt{\hat{\theta}(1-\hat{\theta})/n}}{1+z_{\alpha/2}^2/n}, \hat{\theta} + \frac{z_{\alpha/2} \sqrt{\hat{\theta}(1-\hat{\theta})/n}}{1+z_{\alpha/2}^2/n} \right) $$ However, I am still learning about the details of this. This brings me to my question: What are the advantages and disadvantages of using any of these approaches for calculating the Confidence Interval for parameter estimates in the Multinomial Distribution? It seems like many of these methods are approximations - but I am willing to guess that perhaps some of these approximate methods might have better properties than others. As an example: Perhaps some of these methods might take longer to calculate in terms of computational power for more complex functions and larger sample sizes? Perhaps some of these methods  might be less suitable for smaller sample sizes? Perhaps some of these methods are known to ""chronically"" overestimate or underestimate the confidence intervals? Perhaps some of these methods are simply ""weaker"" - i.e. the guarantee of the true parameter estimate lying between predicted ranges is not ""as strong a guarantee""? In any case, I would be interested in hearing about opinions on this matter - and in general, learning about which approaches might be generally more suitable for evaluating the Confidence Intervals on parameter estimates for the Multinomial Distribution. Thanks! Note: Or perhaps all these differences in real life applications might be negligible and they are all equally suitable?","Suppose I roll a 6-sided die 100 times and observe the following data - let's say that I don't know the probability of getting any specific number (but I am assured that each ""trial"" is independent from the previous ""trial""). Below, here is some R code to simulate this experiment: # Set the probabilities for each number (pretend this is unknown in real life) probs <- c(0.1, 0.2, 0.3, 0.2, 0.1, 0.1)  # Generate 100 random observations observations <- sample(1:6, size = 100, replace = TRUE, prob = probs)  # Print the observations print(observations)    [1] 2 4 2 2 4 6 2 2 6 6 3 4 6 4 2 1 3 6 3 1 2 5 3 6 4 6 1 3 4 2 6 2 4 1 3 3 3 5 2 5 2 3 5 1 4 6 1 6 4 2  [51] 2 3 2 3 3 5 6 5 4 3 2 3 2 1 2 3 2 2 5 3 2 1 1 1 3 3 2 4 4 3 1 4 4 6 3 3 5 5 2 2 1 3 2 1 6 3 4 3 3 3 As we know, the above experiment corresponds to the Multinomial Probability Distribution Function ( https://en.wikipedia.org/wiki/Multinomial_distribution ): Using Maximum Likelihood Estimation ( https://en.wikipedia.org/wiki/Maximum_likelihood_estimation MLE), the estimate for the probability for getting any number on this die is given by (e.g. what is the probability that this above die gives you a ""3""?): Next, the Variance for each of these parameters can be written as follows : From here, I am interested in estimating the ""spreads"" of these probabilities - for example, there might be a 0.2 probability of getting a ""6"" - but we can then ""bound"" this estimate and say there is a 0.2 ± 0.05 probability of rolling a 6. Effectively, this ""bounding"" corresponds to a Confidence Interval ( https://en.wikipedia.org/wiki/Confidence_interval ). Recently, I learned that when writing Confidence Intervals for ""proportions and probabilities"", we might not be able to use the ""classic"" notion of the Confidence Interval (i.e. parameter ± z-alpha/2*sqrt(var(parameter))), because this could result in these bounds going over ""1"" and below ""0"", thus violating the fundamental definitions of probability. Doing some reading online, I found different methods that might be applicable for writing the Confidence Intervals for the parameters of a Multinomial Distribution. Bootstrapping ( https://en.wikipedia.org/wiki/Bootstrapping_(statistics) ): By virtue of the Large Law of Large Numbers ( https://en.wikipedia.org/wiki/Law_of_large_numbers ), Bootstrapping works by repeatedly resampling your observed data and using this MLE formulas to calculate the parameters of interest on each of these re-samples. Then, you would sort the parameter in estimates in ascending order and take the estimates corresponding to the 5th and 95th percentiles. These estimates from the 5th and 95th percentiles would now correspond to the desired Confidence Interval. As I understand, this is an approximate method , but I have heard that the Law of Large Numbers argues that for an infinite sized population and an infinite number of resamples, the bootstrap estimates will converge to the actual values. It is important to note that in this case, the ""Sequential Bootstrap"" approach needs to be used such that the chronological order of the observed data is not interrupted. Delta Method ( https://en.wikipedia.org/wiki/Delta_method ): The Delta Method uses a Taylor Approximation ( https://en.wikipedia.org/wiki/Taylor%27s_theorem ) for the function of interest (i.e. MLE variance estimate). Even though this is also said to be an approximate method (i.e. the Delta Method relies on the Taylor APPROXIMATION), there supposedly exists mathematical theory (e.g. https://en.wikipedia.org/wiki/Continuous_mapping_theorem ) which can demonstrate that estimates from the Delta Method ""converge in probability"" to the actual values. This being said, I am not sure how the Delta method can directly be used to calculate Confidence Intervals. Finally, very recently I learned about the Wilson Interval ( https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval ), which is said to be more suitable for writing Confidence Intervals in the case of proportions and probabilities. In the case of the Multinomial Probability Distribution, I think the Wilson Interval for 95% Confidence Intervals on parameter estimates can be written as follows: However, I am still learning about the details of this. This brings me to my question: What are the advantages and disadvantages of using any of these approaches for calculating the Confidence Interval for parameter estimates in the Multinomial Distribution? It seems like many of these methods are approximations - but I am willing to guess that perhaps some of these approximate methods might have better properties than others. As an example: Perhaps some of these methods might take longer to calculate in terms of computational power for more complex functions and larger sample sizes? Perhaps some of these methods  might be less suitable for smaller sample sizes? Perhaps some of these methods are known to ""chronically"" overestimate or underestimate the confidence intervals? Perhaps some of these methods are simply ""weaker"" - i.e. the guarantee of the true parameter estimate lying between predicted ranges is not ""as strong a guarantee""? In any case, I would be interested in hearing about opinions on this matter - and in general, learning about which approaches might be generally more suitable for evaluating the Confidence Intervals on parameter estimates for the Multinomial Distribution. Thanks! Note: Or perhaps all these differences in real life applications might be negligible and they are all equally suitable?","
P(X_1 = x_1, X_2 = x_2, \dots, X_k = x_k) = \frac{n!}{x_1!x_2!\dots x_k!}p_1^{x_1}p_2^{x_2} \dots p_k^{x_k}
 
\hat{p}_{i,\text{MLE}} = \frac{x_i}{n}
 
\text{Var}(\hat{p}_{i,\text{MLE}}) = \frac{p_i(1 - p_i)}{n}
 
\left( \hat{\theta} - \frac{z_{\alpha/2} \sqrt{\hat{\theta}(1-\hat{\theta})/n}}{1+z_{\alpha/2}^2/n}, \hat{\theta} + \frac{z_{\alpha/2} \sqrt{\hat{\theta}(1-\hat{\theta})/n}}{1+z_{\alpha/2}^2/n} \right)
","['probability', 'statistics', 'confidence-interval']"
52,Uniformly integrability of inverse of sample moments,Uniformly integrability of inverse of sample moments,,"I am interested in the uniform integrability of the set $\{Y_n\}_{n\ge 3}$ where $$ Y_n = \bigg(\frac{1}{n} \sum_{i=1}^n X_i^k\bigg)^{-1}, $$ where the $X_i$ 's are i.i.d observations of a continuous random variable $X$ , $k\ge 1$ , and $E[X] < \infty$ . Is $\{Y_n\}_{n\ge 3}$ uniformly integrable for $k = 1$ which corresponds to the inverse of the sample mean? What about $k > 1$ ? In particular, the inverse of the second sample momemt, i.e. , $k=2$ , is what I am most interested in. If it is not uniformly integrable in general, is it uniformly integrable if we restrict the allowable $X$ ?","I am interested in the uniform integrability of the set where where the 's are i.i.d observations of a continuous random variable , , and . Is uniformly integrable for which corresponds to the inverse of the sample mean? What about ? In particular, the inverse of the second sample momemt, i.e. , , is what I am most interested in. If it is not uniformly integrable in general, is it uniformly integrable if we restrict the allowable ?","\{Y_n\}_{n\ge 3} 
Y_n = \bigg(\frac{1}{n} \sum_{i=1}^n X_i^k\bigg)^{-1},
 X_i X k\ge 1 E[X] < \infty \{Y_n\}_{n\ge 3} k = 1 k > 1 k=2 X","['probability', 'measure-theory', 'statistics', 'random-variables', 'uniform-integrability']"
53,probability of guessing a k-digit number sequentially from n trials,probability of guessing a k-digit number sequentially from n trials,,"I recently encountered the following problem. Assume that we need to guess a $k$ -digit number. We guess it digit by digit and there are $n$ guesses in total. What is the probability of success? Say, $k=5$ , and $n=25$ . We can spend, e.g., 9 trials guessing the first digit, then guess the second digit from the 3rd trial etc. But we cannot make more than 25 guesses in total. I believe we should proceed as follows: guessed from 5 trials: $p=1/10^5$ ; -- we cannot make less than 5 trials when guessing step by step guessed from 6 trials: $p=1/10^4\cdot(1-1/10)\cdot 1/9\cdot 5$ guessed from 7 trials: $p=1/10^3\cdot(1-1/10)^2\cdot 1/9^2\cdot \binom{5}{2}+1/10^4\cdot(1-1/10)\cdot(1-1/9)\cdot 1/8\cdot 5$ , etc. but I'm failing to generalize this scheme. And there is an additional problem that we have to set an upper bound to the number of trials at some point... UPDATE (09.02): As @JMoravitz suggested, one can write an iterative scheme for computing the probability of guessing exactly $\kappa$ digits from $\eta$ trials, $f(\kappa,\eta)$ . I believe that this scheme can be written as $$f(\kappa,\eta)=\frac{1}{10}\sum_{i=1}^{10}f(\kappa−1,\eta−i),$$ where we use the fact that the probability of guessing the digit from $1\le \kappa\le 10$ guesses is always the same: $$p(i=1)=\frac1{10},\quad p(i=2)=\frac{9}{10}\frac{1}{9}=\frac{1}{10},...$$ We also need to add boundary conditions $$\begin{cases}f(\kappa,\eta)=0,&\eta<\kappa\mbox{ (we cannot guess $\kappa$ digits from less than $\eta$ trials)},\\ f(1,\eta)=\frac{1}{10},&0<\eta\le 10\mbox{ (probabilities of guessing the first digit from $\eta$ trials)},\\ f(1,\eta)=0,&\eta=0\mbox{ or }\eta>10.\end{cases}$$ The final probability is to be found as the sum $$p^*=\sum_{i=k}^n f(k,i)=\sum_{i=5}^{25} f(5,i).$$ This scheme looks pretty neat and can be easily computed numerically. However, I wonder if there is any chance to solve this problem analytically? Perhaps there exists a different approach?...","I recently encountered the following problem. Assume that we need to guess a -digit number. We guess it digit by digit and there are guesses in total. What is the probability of success? Say, , and . We can spend, e.g., 9 trials guessing the first digit, then guess the second digit from the 3rd trial etc. But we cannot make more than 25 guesses in total. I believe we should proceed as follows: guessed from 5 trials: ; -- we cannot make less than 5 trials when guessing step by step guessed from 6 trials: guessed from 7 trials: , etc. but I'm failing to generalize this scheme. And there is an additional problem that we have to set an upper bound to the number of trials at some point... UPDATE (09.02): As @JMoravitz suggested, one can write an iterative scheme for computing the probability of guessing exactly digits from trials, . I believe that this scheme can be written as where we use the fact that the probability of guessing the digit from guesses is always the same: We also need to add boundary conditions The final probability is to be found as the sum This scheme looks pretty neat and can be easily computed numerically. However, I wonder if there is any chance to solve this problem analytically? Perhaps there exists a different approach?...","k n k=5 n=25 p=1/10^5 p=1/10^4\cdot(1-1/10)\cdot 1/9\cdot 5 p=1/10^3\cdot(1-1/10)^2\cdot 1/9^2\cdot \binom{5}{2}+1/10^4\cdot(1-1/10)\cdot(1-1/9)\cdot 1/8\cdot 5 \kappa \eta f(\kappa,\eta) f(\kappa,\eta)=\frac{1}{10}\sum_{i=1}^{10}f(\kappa−1,\eta−i), 1\le \kappa\le 10 p(i=1)=\frac1{10},\quad p(i=2)=\frac{9}{10}\frac{1}{9}=\frac{1}{10},... \begin{cases}f(\kappa,\eta)=0,&\eta<\kappa\mbox{ (we cannot guess \kappa digits from less than \eta trials)},\\
f(1,\eta)=\frac{1}{10},&0<\eta\le 10\mbox{ (probabilities of guessing the first digit from \eta trials)},\\
f(1,\eta)=0,&\eta=0\mbox{ or }\eta>10.\end{cases} p^*=\sum_{i=k}^n f(k,i)=\sum_{i=5}^{25} f(5,i).","['probability', 'problem-solving']"
54,Are primes (ignoring $2$) equally likely to be $1~\text{or}~3\pmod 4$?,Are primes (ignoring ) equally likely to be ?,2 1~\text{or}~3\pmod 4,"For all primes $p\neq 2$ , it's easy to see that $$p\equiv 1~\text{or}~3\pmod 4$$ I was wondering if it's equally likely ( $50\%-50\%$ ) that prime modulo $4$ is $1$ or $3$ . And if so, is there a simple proof?","For all primes , it's easy to see that I was wondering if it's equally likely ( ) that prime modulo is or . And if so, is there a simple proof?",p\neq 2 p\equiv 1~\text{or}~3\pmod 4 50\%-50\% 4 1 3,"['probability', 'number-theory', 'prime-numbers', 'modular-arithmetic']"
55,Polynomials with minimal variation and a fixed root---looking for a variant of Chebyshev polynomials (motivated by probability),Polynomials with minimal variation and a fixed root---looking for a variant of Chebyshev polynomials (motivated by probability),,"Recall that the Chebyshev polynomial $T_n(x)$ for a positive integer $n$ is, in a formal sense, the polynomial of degree $n$ that ""varies the least"" over an interval. Specifically, (a suitable scaling of) $T_n(x)$ is the monic polynomial $p$ of degree $n$ that minimizes $$\sup_{x \in [-1,1]} |p(x)| \; .$$ I am interested in finding a polynomial of degree $n$ that varies the least over an interval, subject to the constraint that the polynomial must have a root at some fixed point. I.e., I would like to find a polynomial $p$ of degree $n$ such that $$p(0) = 0$$ and satisfying $$1 \leq p(x) \leq \alpha_p$$ for all $x \in [1,N]$ with $\alpha_p$ as small as possible. (I'm not sure how important the parameter $N$ is.) So, that's the question. For those who are interesting, I'll write down my motivation below. Motivation My motivation comes from another very natural question. Suppose that I have some random variable $X$ over, say, the integers $0,\ldots, N$ , and suppose I know the first $n$ moments of $X$ , $M_1,\ldots, M_n$ with $N \gg n$ . Given this information, how accurately can we estimate $\Pr[X \neq 0]$ (in the worst case)? The first observation to make here is that knowing $M_1,\ldots, M_n$ is equivalent to knowing the expectation $\mathbb{E}[p(X)]$ for any polynomial $p$ whose degree is at most $n$ . Suppose for simplicity that we just want to use one such expectation to answer this question. What polynomial $p$ do we pick, and how well can we do? It's clear that $p$ is useless for this purpose if there exist non-zero $k_1,k_2$ with $p(k_1) \leq p(0) \leq p(k_2)$ , since then there exist values of $\mathbb{E}[p(X)]$ that do not constrain $p(0)$ at all. So, after shifting and rescaling, we may assume that $p(0) = 0$ and $1 \leq p(k) \leq \alpha_p$ for $k \in \{1,\ldots, N\}$ . Such a polynomial yields a multiplicative approximation factor of $\alpha_p$ , so our goal is to find the polynomial minimizing $\alpha_p$ . The above question is identical, except that I removed the restriction that $k$ must be an integer (which seems reasonable for large $N$ ).","Recall that the Chebyshev polynomial for a positive integer is, in a formal sense, the polynomial of degree that ""varies the least"" over an interval. Specifically, (a suitable scaling of) is the monic polynomial of degree that minimizes I am interested in finding a polynomial of degree that varies the least over an interval, subject to the constraint that the polynomial must have a root at some fixed point. I.e., I would like to find a polynomial of degree such that and satisfying for all with as small as possible. (I'm not sure how important the parameter is.) So, that's the question. For those who are interesting, I'll write down my motivation below. Motivation My motivation comes from another very natural question. Suppose that I have some random variable over, say, the integers , and suppose I know the first moments of , with . Given this information, how accurately can we estimate (in the worst case)? The first observation to make here is that knowing is equivalent to knowing the expectation for any polynomial whose degree is at most . Suppose for simplicity that we just want to use one such expectation to answer this question. What polynomial do we pick, and how well can we do? It's clear that is useless for this purpose if there exist non-zero with , since then there exist values of that do not constrain at all. So, after shifting and rescaling, we may assume that and for . Such a polynomial yields a multiplicative approximation factor of , so our goal is to find the polynomial minimizing . The above question is identical, except that I removed the restriction that must be an integer (which seems reasonable for large ).","T_n(x) n n T_n(x) p n \sup_{x \in [-1,1]} |p(x)|
\; . n p n p(0) = 0 1 \leq p(x) \leq \alpha_p x \in [1,N] \alpha_p N X 0,\ldots, N n X M_1,\ldots, M_n N \gg n \Pr[X \neq 0] M_1,\ldots, M_n \mathbb{E}[p(X)] p n p p k_1,k_2 p(k_1) \leq p(0) \leq p(k_2) \mathbb{E}[p(X)] p(0) p(0) = 0 1 \leq p(k) \leq \alpha_p k \in \{1,\ldots, N\} \alpha_p \alpha_p k N","['probability', 'polynomials', 'chebyshev-polynomials']"
56,If $X\sim \mathrm{lognormal}$ then $Y:=(X-d|x\geq d)$ has approximately a Generalized Pareto distribution.,If  then  has approximately a Generalized Pareto distribution.,X\sim \mathrm{lognormal} Y:=(X-d|x\geq d),"Let $X$ be a random variable with lognormal distribution. Show that when sufficiently large then $Y:=(X-d|x\geq d)$ is approximately a random variable with generalized Pareto distribution. Hint: Use the fact that $\mathrm{erf}(x)\approx 1-\frac{1}{\sqrt{x}}e^{-\frac{x^2}{2}}$ for large values of $x$ . My attempt: We recall that the density function for the lognormal distribution is given by $$ f(x)=\frac{1}{x\sigma\sqrt{2\pi}}e^{\frac{-(\log x-\mu)^2}{\sigma}}\:\:\mbox{ for }x>0. $$ The comulative distribution function for a generalized Pareto random variable is given by $$ G(x)=1-\left(1+\frac{\gamma x}{\theta}\right)^{\frac{-1}{\gamma}}. $$ The objective is to find parameters $\gamma$ and $\theta$ such that $\mathbb{P}(Y\leq y)\approx G(y)$ , it is clear that $\gamma$ and $\theta$ will be expressed in terms of $\sigma$ , $\mu$ and $d$ . My attempt is: \begin{align} \mathbb{P}(Y\leq y) & =1- \frac{1-\int_{0}^{d+y}\frac{1}{x\sigma\sqrt{2\pi}}e^{\frac{-(\log x-\mu)^2}{\sigma}} dx}{1-\int_{0}^{d}\frac{1}{x\sigma\sqrt{2\pi}}e^{\frac{-(\log x-\mu)^2}{\sigma}} dx}   \end{align} We consider the changge of variable given by $t=\frac{\log x -\mu}{\sqrt{2}\sigma}$ , then $dt=\frac{1}{\sqrt{2}\sigma x}dx$ , so, $dx=\sqrt{2}\sigma x dt$ . Therefores, we have \begin{align} \mathbb{P}(Y\leq y) & =1- \frac{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt }{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt} \\ &= 1- \frac{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{0}e^{-t^{2}} dy- \frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt }{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{0}e^{-t^{2}} dy-\frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt} \\ &= 1- \frac{1-\frac{1}{2}- \frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt }{1-\frac{1}{2}-\frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt} \\ &= 1- \frac{\frac{1}{2}- \frac{1}{2}\mathrm{erf}\left(\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}\right) }{\frac{1}{2}- \frac{1}{2}\mathrm{erf}\left(\frac{\log(d) -\mu}{\sqrt{2}\sigma}\right) } \\ &= 1- \frac{1- \mathrm{erf}\left(\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}\right) }{1- \mathrm{erf}\left(\frac{\log(d) -\mu}{\sqrt{2}\sigma}\right) } \\ &\approx 1- \frac{\frac{1}{\sqrt{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}}e^{-\frac{(\log(d+y)-\mu)^2}{4\sigma^2}} }{\frac{1}{\sqrt{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}}e^{-\frac{(\log(d)-\mu)^2}{4\sigma^2}}  } \leftarrow \mbox{by hint.}\\ &= 1- \sqrt{\frac{\log(d)-\mu}{\log(d+y)-\mu}}e^{-\frac{(\log(d+y)-\mu)^2}{4\sigma^2}+\frac{(\log(d)-\mu)^2}{4\sigma^2}}\\ &=1- \sqrt{\frac{\log(d)-\mu}{\log(d+y)-\mu}}e^{\frac{1}{4\sigma^2}(\log(d)-\log(d+y))(\log(y+d)+\log(d)-2\mu) }\\ &=1- \sqrt{\frac{\log(d)-\mu}{\log(d+y)-\mu}}e^{\frac{1}{4\sigma^2}\log\left(\frac{d+y}{d}\right)\left(2\mu-\log(dy+d^2)\right) }\\  \end{align} I do not know how to continue, algebraically I have not been able calibrate the parameters to get what I need. I ask for your help with this problem, any solution or suggestion will be well received.","Let be a random variable with lognormal distribution. Show that when sufficiently large then is approximately a random variable with generalized Pareto distribution. Hint: Use the fact that for large values of . My attempt: We recall that the density function for the lognormal distribution is given by The comulative distribution function for a generalized Pareto random variable is given by The objective is to find parameters and such that , it is clear that and will be expressed in terms of , and . My attempt is: We consider the changge of variable given by , then , so, . Therefores, we have I do not know how to continue, algebraically I have not been able calibrate the parameters to get what I need. I ask for your help with this problem, any solution or suggestion will be well received.","X Y:=(X-d|x\geq d) \mathrm{erf}(x)\approx 1-\frac{1}{\sqrt{x}}e^{-\frac{x^2}{2}} x 
f(x)=\frac{1}{x\sigma\sqrt{2\pi}}e^{\frac{-(\log x-\mu)^2}{\sigma}}\:\:\mbox{ for }x>0.
 
G(x)=1-\left(1+\frac{\gamma x}{\theta}\right)^{\frac{-1}{\gamma}}.
 \gamma \theta \mathbb{P}(Y\leq y)\approx G(y) \gamma \theta \sigma \mu d \begin{align}
\mathbb{P}(Y\leq y) & =1- \frac{1-\int_{0}^{d+y}\frac{1}{x\sigma\sqrt{2\pi}}e^{\frac{-(\log x-\mu)^2}{\sigma}} dx}{1-\int_{0}^{d}\frac{1}{x\sigma\sqrt{2\pi}}e^{\frac{-(\log x-\mu)^2}{\sigma}} dx} 
 \end{align} t=\frac{\log x -\mu}{\sqrt{2}\sigma} dt=\frac{1}{\sqrt{2}\sigma x}dx dx=\sqrt{2}\sigma x dt \begin{align}
\mathbb{P}(Y\leq y) & =1- \frac{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt }{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt} \\
&= 1- \frac{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{0}e^{-t^{2}} dy- \frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt }{1-\frac{1}{\sqrt{\pi}}\int_{-\infty}^{0}e^{-t^{2}} dy-\frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt} \\
&= 1- \frac{1-\frac{1}{2}- \frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt }{1-\frac{1}{2}-\frac{1}{\sqrt{\pi}}\int_{0}^{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}e^{-t^{2}} dt} \\
&= 1- \frac{\frac{1}{2}- \frac{1}{2}\mathrm{erf}\left(\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}\right) }{\frac{1}{2}- \frac{1}{2}\mathrm{erf}\left(\frac{\log(d) -\mu}{\sqrt{2}\sigma}\right) } \\
&= 1- \frac{1- \mathrm{erf}\left(\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}\right) }{1- \mathrm{erf}\left(\frac{\log(d) -\mu}{\sqrt{2}\sigma}\right) } \\
&\approx 1- \frac{\frac{1}{\sqrt{\frac{\log(d+y) -\mu}{\sqrt{2}\sigma}}}e^{-\frac{(\log(d+y)-\mu)^2}{4\sigma^2}} }{\frac{1}{\sqrt{\frac{\log(d) -\mu}{\sqrt{2}\sigma}}}e^{-\frac{(\log(d)-\mu)^2}{4\sigma^2}}  } \leftarrow \mbox{by hint.}\\
&= 1- \sqrt{\frac{\log(d)-\mu}{\log(d+y)-\mu}}e^{-\frac{(\log(d+y)-\mu)^2}{4\sigma^2}+\frac{(\log(d)-\mu)^2}{4\sigma^2}}\\
&=1- \sqrt{\frac{\log(d)-\mu}{\log(d+y)-\mu}}e^{\frac{1}{4\sigma^2}(\log(d)-\log(d+y))(\log(y+d)+\log(d)-2\mu) }\\
&=1- \sqrt{\frac{\log(d)-\mu}{\log(d+y)-\mu}}e^{\frac{1}{4\sigma^2}\log\left(\frac{d+y}{d}\right)\left(2\mu-\log(dy+d^2)\right) }\\
 \end{align}","['probability', 'probability-theory', 'probability-distributions', 'conditional-probability']"
57,Variational distance of product of distributions,Variational distance of product of distributions,,"Let $F(\bar{x})=\prod_{i=1}^{n}f(x_i)$ and $G(\bar{x})=\prod_{i=1}^{n}g(x_i)$, where $f(x)$ and $g(x)$ are probability density functions, and $\bar{x}=(x_1,\ldots,x_n)$. The variational distance between $F$ and $G$ is:   $$V(F,G)=\int |F(\bar{x})-G(\bar{x})|d\bar{x}$$   Can we write it in terms of the variational distance between $f$ and $g$? I know we could do such if it was KL divergence: $$D_{KL}(F,G)=n D_{KL}(f,g).$$ Do we have such a simplification for variational distance as well?","Let $F(\bar{x})=\prod_{i=1}^{n}f(x_i)$ and $G(\bar{x})=\prod_{i=1}^{n}g(x_i)$, where $f(x)$ and $g(x)$ are probability density functions, and $\bar{x}=(x_1,\ldots,x_n)$. The variational distance between $F$ and $G$ is:   $$V(F,G)=\int |F(\bar{x})-G(\bar{x})|d\bar{x}$$   Can we write it in terms of the variational distance between $f$ and $g$? I know we could do such if it was KL divergence: $$D_{KL}(F,G)=n D_{KL}(f,g).$$ Do we have such a simplification for variational distance as well?",,"['probability', 'probability-theory', 'statistics', 'information-theory', 'total-variation']"
58,Finding expected value of remaining piece,Finding expected value of remaining piece,,"A father has a pie made for his two sons. Eating more than half of the pie will give indigestion to anyone. While he is away, the older son helps himself to a piece of the pie. The younger son then comes and has a piece of what is left by the brother. Assume that the size of each of the two pieces eaten by the sons is random and uniformly distributed over what is currently available. What is the expected size of the remaining piece give that no son has indigestion? After a while of thinking this is what I did.  Let $\theta_1$ be the total angle corresponding to the amount of pie that son $1$ eats. Similarly, let $\theta_2$ be the total angle corresponding to the amount of pie for son $2$. Let $X$ be the remaining piece. So,  $$ X = 2\pi - \theta_1 - \theta_2 \\ \mathbb{E}(X) = 2\pi - \mathbb{E}(\theta_1) - \mathbb{E}(\theta_2).   $$ So after a while of thinking, given that no son has indigestion, it feels as if son 1 and son 2 are independent, since they eat less than $\pi$... So $\theta_1 \sim \operatorname{Unif}(0,\pi)$ and also $\theta_2\sim \operatorname{Unif}(0,\pi)$. Then $\mathbb{E}(X) = \pi$. Is this correct?","A father has a pie made for his two sons. Eating more than half of the pie will give indigestion to anyone. While he is away, the older son helps himself to a piece of the pie. The younger son then comes and has a piece of what is left by the brother. Assume that the size of each of the two pieces eaten by the sons is random and uniformly distributed over what is currently available. What is the expected size of the remaining piece give that no son has indigestion? After a while of thinking this is what I did.  Let $\theta_1$ be the total angle corresponding to the amount of pie that son $1$ eats. Similarly, let $\theta_2$ be the total angle corresponding to the amount of pie for son $2$. Let $X$ be the remaining piece. So,  $$ X = 2\pi - \theta_1 - \theta_2 \\ \mathbb{E}(X) = 2\pi - \mathbb{E}(\theta_1) - \mathbb{E}(\theta_2).   $$ So after a while of thinking, given that no son has indigestion, it feels as if son 1 and son 2 are independent, since they eat less than $\pi$... So $\theta_1 \sim \operatorname{Unif}(0,\pi)$ and also $\theta_2\sim \operatorname{Unif}(0,\pi)$. Then $\mathbb{E}(X) = \pi$. Is this correct?",,"['probability', 'probability-distributions', 'conditional-expectation']"
59,Investigating a coupon collector statistic.,Investigating a coupon collector statistic.,,"We   present  a   problem  inspired   by   the  work   at  this MSE link .             In particular, we  consider a coupon collector scenario  with $n$ coupons where an  integer $1\le  j\le n-1$ is  given. We introduce  two random variables, namely $T$ and $Q$ where $T$ represents the number of draws until all coupons have been  collected and $Q$ the number of different coupons that appeared in the first $j$ draws. The following conjecture is submitted for your consideration. $$\mathrm{E}\left[{T\choose Q}\right] = \sum_{k=1}^j \frac{n!}{n^{n-k-1+j}} \times {j\brace k}   \sum_{r=0}^k {n+j-k\choose k-r} \\ \times \sum_{p=0}^{n-k-1} \frac{(-1)^{n-k-1-p}}{p! (n-k-1-p)!} \frac{(k+p)^{n-k-1+r}}{(n-k-p)^{r+1}}.$$ I have  what I  believe to  be a proof  but it  is quite  involved. We propose the following list of questions concerning the above identity: does it indeed hold and does it perhaps have a straightforward proof using probabilistic methods and is there structural simplification what  are the  asymptotics, are there  effective estimates  of these terms that  match the  numeric exact values  from the  formula without having recurse to a triple sum. The reader  is invited to compare  potentially relevant asymptotics to the data from the identity. There is  the following extremely basic (no pun intended) C program which  I  include  here  to help clarify  what   interpretation of the problem is being used.  Compiled with GCC 4.3.2 and  the std=gnu99 option. #include <stdlib.h> #include <stdio.h> #include <assert.h> #include <time.h> #include <string.h>  long choose(long n, long k) {   long num = 1, denom = 1;    while(k > 0){     num *= n;     denom *= k;      n--; k--;   }    return num/denom; }   int main(int argc, char **argv) {   int n = 6 , j = 3, trials = 1000;     if(argc >= 2){     n = atoi(argv[1]);   }    if(argc >= 3){     j = atoi(argv[2]);   }    if(argc >= 4){     trials = atoi(argv[3]);   }    assert(1 <= n);   assert(1 <= j && j < n);   assert(1 <= trials);    srand48(time(NULL));   long long data = 0;    long genstats[n];   memset(genstats, 0, n*sizeof(long));    for(int tind = 0; tind < trials; tind++){     int seen = 0; int steps = 0;      int dist[n], startseg[n];      for(int cind = 0; cind < n; cind++){       dist[cind] = 0; startseg[cind] = 0;     }      while(seen < n){       int coupon = drand48() * (double)n;       genstats[coupon]++;        steps++;        if(steps <= j)         startseg[coupon]++;        if(dist[coupon] == 0)         seen++;       dist[coupon]++;     }      int stseen = 0;     for(int stcoup = 0; stcoup < n; stcoup++)       if(startseg[stcoup] > 0)         stseen++;      data += choose(steps, stseen);   }    long double expt = (long double)data/(long double)trials;   printf(""[n = %d, j = %d, trials = %d]: %Le\n"",           n, j, trials, expt);     long long gentotal = 0;   for(int cind = 0; cind < n; cind++){     gentotal += genstats[cind];   }    for(int cind = 0; cind < n; cind++){     printf(""%02d: %.8Le\n"", cind,            (long double)genstats[cind]            /(long double)gentotal);   }   exit(0); } Addendum. As a sanity check  when $j=1$ the formula should produce $n H_n$ for $n\ge 2.$ In fact we obtain $$\frac{n!}{n^{n-1}} \left(n\times   \sum_{p=0}^{n-2} \frac{(-1)^{n-2-p}}{p! (n-2-p)!} \frac{(1+p)^{n-2}}{n-1-p} + \sum_{p=0}^{n-2} \frac{(-1)^{n-2-p}}{p! (n-2-p)!} \frac{(1+p)^{n-1}}{(n-1-p)^2}\right).$$ For the first sum we introduce $$f(z) = \frac{(1+z)^{n-2}}{n-1-z}  \prod_{q=0}^{n-2} \frac{1}{z-q}$$ so that the sum is given by (residues sum to zero) $$\sum_{q=0}^{n-2} \mathrm{Res}_{z=q} f(z) = -\mathrm{Res}_{z=n-1} f(z) - \mathrm{Res}_{z=\infty} f(z).$$ The contribution from the first term is $$\frac{n^{n-2}}{(n-1)!}$$ and from the second $$\mathrm{Res}_{z=0} \frac{1}{z^2} \frac{(1+1/z)^{n-2}}{n-1-1/z}  \prod_{q=0}^{n-2} \frac{1}{1/z-q} = \mathrm{Res}_{z=0} \frac{1}{z^n} \frac{(1+z)^{n-2}}{n-1-1/z}  \prod_{q=0}^{n-2} \frac{z}{1-qz} \\ = \mathrm{Res}_{z=0} \frac{1}{z} \frac{(1+z)^{n-2}}{n-1-1/z}  \prod_{q=0}^{n-2} \frac{1}{1-qz} = \mathrm{Res}_{z=0} \frac{(1+z)^{n-2}}{z(n-1)-1}  \prod_{q=0}^{n-2} \frac{1}{1-qz} = 0.$$ Hence the first sum contributes $$\frac{n!}{n^{n-1}} \times n \frac{n^{n-2}}{(n-1)!} = n.$$ For the second sum we use $$g(z) = \frac{(1+z)^{n-1}}{(n-1-z)^2}  \prod_{q=0}^{n-2} \frac{1}{z-q} = \frac{(1+z)^{n-1}}{(z-(n-1))^2}  \prod_{q=0}^{n-2} \frac{1}{z-q}.$$ We get for the negative of the residue at $n-1$ the value $$-\left((1+z)^{n-1} \prod_{q=0}^{n-2} \frac{1}{z-q} \right)' _{z=n-1} \\ = -\left((n-1)(1+z)^{n-2} \prod_{q=0}^{n-2} \frac{1}{z-q}  - (1+z)^{n-1} \prod_{q=0}^{n-2} \frac{1}{z-q} \sum_{q=0}^{n-2} \frac{1}{z-q}\right)_{z=n-1} \\ = - \left((n-1)n^{n-2} \frac{1}{(n-1)!} - n^{n-1} \frac{1}{(n-1)!} H_{n-1}\right).$$ Multiply by $n!/n^{n-1}$ to get $$n H_{n-1} - (n-1)n^{n-2} \frac{1}{(n-1)!} \frac{n!}{n^{n-1}} \\ = n H_{n-1} - (n-1)\frac{n}{n} = n H_{n-1} - (n-1).$$ For the negative of the residue at infinity we obtain $$\mathrm{Res}_{z=0} \frac{1}{z^2} \frac{(1+1/z)^{n-1}}{(n-1-1/z)^2}  \prod_{q=0}^{n-2} \frac{1}{1/z-q} = \mathrm{Res}_{z=0} \frac{1}{z^{n+1}} \frac{(1+z)^{n-1}}{(n-1-1/z)^2}  \prod_{q=0}^{n-2} \frac{z}{1-qz} \\ = \mathrm{Res}_{z=0} \frac{1}{z^2} \frac{(1+z)^{n-1}}{(n-1-1/z)^2}  \prod_{q=0}^{n-2} \frac{1}{1-qz} \\ = \mathrm{Res}_{z=0} \frac{(1+z)^{n-1}}{(z(n-1)-1)^2}  \prod_{q=0}^{n-2} \frac{1}{1-qz} = 0.$$ Collecting everything we get $$n H_{n-1} - (n-1) + n = n H_{n-1} + n \frac{1}{n}$$ or alternatively $$\bbox[5px,border:2px solid #00A000]{n H_n}$$ and  the sanity check goes through. Observe that we  evidently require something more  sophisticated to  prove the conjectured  identity e.g. when $j=n-1.$  (Remark.  We don't  need to actually apply  the formula for  the residues  at infinity,  it  is sufficient  when working  with rational functions  to observe  that both $f(z)$  and $g(z)$  have the difference between the degree of  the denominator and of the numerator equal to two.)","We   present  a   problem  inspired   by   the  work   at  this MSE link .             In particular, we  consider a coupon collector scenario  with $n$ coupons where an  integer $1\le  j\le n-1$ is  given. We introduce  two random variables, namely $T$ and $Q$ where $T$ represents the number of draws until all coupons have been  collected and $Q$ the number of different coupons that appeared in the first $j$ draws. The following conjecture is submitted for your consideration. $$\mathrm{E}\left[{T\choose Q}\right] = \sum_{k=1}^j \frac{n!}{n^{n-k-1+j}} \times {j\brace k}   \sum_{r=0}^k {n+j-k\choose k-r} \\ \times \sum_{p=0}^{n-k-1} \frac{(-1)^{n-k-1-p}}{p! (n-k-1-p)!} \frac{(k+p)^{n-k-1+r}}{(n-k-p)^{r+1}}.$$ I have  what I  believe to  be a proof  but it  is quite  involved. We propose the following list of questions concerning the above identity: does it indeed hold and does it perhaps have a straightforward proof using probabilistic methods and is there structural simplification what  are the  asymptotics, are there  effective estimates  of these terms that  match the  numeric exact values  from the  formula without having recurse to a triple sum. The reader  is invited to compare  potentially relevant asymptotics to the data from the identity. There is  the following extremely basic (no pun intended) C program which  I  include  here  to help clarify  what   interpretation of the problem is being used.  Compiled with GCC 4.3.2 and  the std=gnu99 option. #include <stdlib.h> #include <stdio.h> #include <assert.h> #include <time.h> #include <string.h>  long choose(long n, long k) {   long num = 1, denom = 1;    while(k > 0){     num *= n;     denom *= k;      n--; k--;   }    return num/denom; }   int main(int argc, char **argv) {   int n = 6 , j = 3, trials = 1000;     if(argc >= 2){     n = atoi(argv[1]);   }    if(argc >= 3){     j = atoi(argv[2]);   }    if(argc >= 4){     trials = atoi(argv[3]);   }    assert(1 <= n);   assert(1 <= j && j < n);   assert(1 <= trials);    srand48(time(NULL));   long long data = 0;    long genstats[n];   memset(genstats, 0, n*sizeof(long));    for(int tind = 0; tind < trials; tind++){     int seen = 0; int steps = 0;      int dist[n], startseg[n];      for(int cind = 0; cind < n; cind++){       dist[cind] = 0; startseg[cind] = 0;     }      while(seen < n){       int coupon = drand48() * (double)n;       genstats[coupon]++;        steps++;        if(steps <= j)         startseg[coupon]++;        if(dist[coupon] == 0)         seen++;       dist[coupon]++;     }      int stseen = 0;     for(int stcoup = 0; stcoup < n; stcoup++)       if(startseg[stcoup] > 0)         stseen++;      data += choose(steps, stseen);   }    long double expt = (long double)data/(long double)trials;   printf(""[n = %d, j = %d, trials = %d]: %Le\n"",           n, j, trials, expt);     long long gentotal = 0;   for(int cind = 0; cind < n; cind++){     gentotal += genstats[cind];   }    for(int cind = 0; cind < n; cind++){     printf(""%02d: %.8Le\n"", cind,            (long double)genstats[cind]            /(long double)gentotal);   }   exit(0); } Addendum. As a sanity check  when $j=1$ the formula should produce $n H_n$ for $n\ge 2.$ In fact we obtain $$\frac{n!}{n^{n-1}} \left(n\times   \sum_{p=0}^{n-2} \frac{(-1)^{n-2-p}}{p! (n-2-p)!} \frac{(1+p)^{n-2}}{n-1-p} + \sum_{p=0}^{n-2} \frac{(-1)^{n-2-p}}{p! (n-2-p)!} \frac{(1+p)^{n-1}}{(n-1-p)^2}\right).$$ For the first sum we introduce $$f(z) = \frac{(1+z)^{n-2}}{n-1-z}  \prod_{q=0}^{n-2} \frac{1}{z-q}$$ so that the sum is given by (residues sum to zero) $$\sum_{q=0}^{n-2} \mathrm{Res}_{z=q} f(z) = -\mathrm{Res}_{z=n-1} f(z) - \mathrm{Res}_{z=\infty} f(z).$$ The contribution from the first term is $$\frac{n^{n-2}}{(n-1)!}$$ and from the second $$\mathrm{Res}_{z=0} \frac{1}{z^2} \frac{(1+1/z)^{n-2}}{n-1-1/z}  \prod_{q=0}^{n-2} \frac{1}{1/z-q} = \mathrm{Res}_{z=0} \frac{1}{z^n} \frac{(1+z)^{n-2}}{n-1-1/z}  \prod_{q=0}^{n-2} \frac{z}{1-qz} \\ = \mathrm{Res}_{z=0} \frac{1}{z} \frac{(1+z)^{n-2}}{n-1-1/z}  \prod_{q=0}^{n-2} \frac{1}{1-qz} = \mathrm{Res}_{z=0} \frac{(1+z)^{n-2}}{z(n-1)-1}  \prod_{q=0}^{n-2} \frac{1}{1-qz} = 0.$$ Hence the first sum contributes $$\frac{n!}{n^{n-1}} \times n \frac{n^{n-2}}{(n-1)!} = n.$$ For the second sum we use $$g(z) = \frac{(1+z)^{n-1}}{(n-1-z)^2}  \prod_{q=0}^{n-2} \frac{1}{z-q} = \frac{(1+z)^{n-1}}{(z-(n-1))^2}  \prod_{q=0}^{n-2} \frac{1}{z-q}.$$ We get for the negative of the residue at $n-1$ the value $$-\left((1+z)^{n-1} \prod_{q=0}^{n-2} \frac{1}{z-q} \right)' _{z=n-1} \\ = -\left((n-1)(1+z)^{n-2} \prod_{q=0}^{n-2} \frac{1}{z-q}  - (1+z)^{n-1} \prod_{q=0}^{n-2} \frac{1}{z-q} \sum_{q=0}^{n-2} \frac{1}{z-q}\right)_{z=n-1} \\ = - \left((n-1)n^{n-2} \frac{1}{(n-1)!} - n^{n-1} \frac{1}{(n-1)!} H_{n-1}\right).$$ Multiply by $n!/n^{n-1}$ to get $$n H_{n-1} - (n-1)n^{n-2} \frac{1}{(n-1)!} \frac{n!}{n^{n-1}} \\ = n H_{n-1} - (n-1)\frac{n}{n} = n H_{n-1} - (n-1).$$ For the negative of the residue at infinity we obtain $$\mathrm{Res}_{z=0} \frac{1}{z^2} \frac{(1+1/z)^{n-1}}{(n-1-1/z)^2}  \prod_{q=0}^{n-2} \frac{1}{1/z-q} = \mathrm{Res}_{z=0} \frac{1}{z^{n+1}} \frac{(1+z)^{n-1}}{(n-1-1/z)^2}  \prod_{q=0}^{n-2} \frac{z}{1-qz} \\ = \mathrm{Res}_{z=0} \frac{1}{z^2} \frac{(1+z)^{n-1}}{(n-1-1/z)^2}  \prod_{q=0}^{n-2} \frac{1}{1-qz} \\ = \mathrm{Res}_{z=0} \frac{(1+z)^{n-1}}{(z(n-1)-1)^2}  \prod_{q=0}^{n-2} \frac{1}{1-qz} = 0.$$ Collecting everything we get $$n H_{n-1} - (n-1) + n = n H_{n-1} + n \frac{1}{n}$$ or alternatively $$\bbox[5px,border:2px solid #00A000]{n H_n}$$ and  the sanity check goes through. Observe that we  evidently require something more  sophisticated to  prove the conjectured  identity e.g. when $j=n-1.$  (Remark.  We don't  need to actually apply  the formula for  the residues  at infinity,  it  is sufficient  when working  with rational functions  to observe  that both $f(z)$  and $g(z)$  have the difference between the degree of  the denominator and of the numerator equal to two.)",,"['probability', 'stirling-numbers', 'coupon-collector']"
60,Probability that a clumsy boy eats $k$ out of 20 candies,Probability that a clumsy boy eats  out of 20 candies,k,"A week or two (or maybe more) ago, the following question was posted and then deleted just as I was getting to the end of my solution. Unfortunately I have now forgotten what my solution was going to be. I don't think the OP reposted it, so here is a slight variant of it. A boy has 20 candies in his hand. He eats them one at a time, but each   time he puts one in his mouth there is a chance he drops one of those   remaining in his hand. That chance is $0.04n$ where $n$ is the number   remaining (and independent of everything else). So after eating the   first candy there is a 0.76 chance that he is left with only 18   candies in his hand. He never picks up dropped candies. Find the   probability that he ends up eating $k$ of the candies. Part of the fun is the elegance or otherwise of the solution. The series one needs to sum with a plodding approach is not difficult, there is just a (fairly obvious) trap for the overhasty. But it would be good to think of a more elegant approach. I am snowed under with work today, but will try to reconstruct my solution and post it as an answer tomorrow (I am on GMT+1, ie 5 hours ahead of EDT. I hope that is the correct jargon for time in NY.). Oh, I nice plot always helps. A solution for the general case (replacing 0.04 by a constant $p=\frac{1}{M}$, where $M\ge N$, and 20 by $N$) and any resulting rules of thumb for what was needed for him to eat at least half or whatever would be good too. The more sophisticated could rattle off the related inference problem: assuming your prior belief is that $p$ is uniformly distributed over (1) $[0,1]$, (2) $[0,0.1]$, (3) $[0.9,1]$ (three separate cases) and you observe that he drops $k$, then what is the posterior distribution for $p$? BTW, aged 66, I don't tend to get given homework. :) And I don't mind solutions with a software element, provided there is an adequate explanation. Also I have put together three questions of varying difficulty because they are so closely related. So to be clear, I would welcome solutions covering just one of (1) the basic problem (first yellow background above) with 20 candies and $p=0.04$, (2) the more general case with $N$ candies and $p=\frac{1}{M}$, and (3) the inference question (the second yellow background).","A week or two (or maybe more) ago, the following question was posted and then deleted just as I was getting to the end of my solution. Unfortunately I have now forgotten what my solution was going to be. I don't think the OP reposted it, so here is a slight variant of it. A boy has 20 candies in his hand. He eats them one at a time, but each   time he puts one in his mouth there is a chance he drops one of those   remaining in his hand. That chance is $0.04n$ where $n$ is the number   remaining (and independent of everything else). So after eating the   first candy there is a 0.76 chance that he is left with only 18   candies in his hand. He never picks up dropped candies. Find the   probability that he ends up eating $k$ of the candies. Part of the fun is the elegance or otherwise of the solution. The series one needs to sum with a plodding approach is not difficult, there is just a (fairly obvious) trap for the overhasty. But it would be good to think of a more elegant approach. I am snowed under with work today, but will try to reconstruct my solution and post it as an answer tomorrow (I am on GMT+1, ie 5 hours ahead of EDT. I hope that is the correct jargon for time in NY.). Oh, I nice plot always helps. A solution for the general case (replacing 0.04 by a constant $p=\frac{1}{M}$, where $M\ge N$, and 20 by $N$) and any resulting rules of thumb for what was needed for him to eat at least half or whatever would be good too. The more sophisticated could rattle off the related inference problem: assuming your prior belief is that $p$ is uniformly distributed over (1) $[0,1]$, (2) $[0,0.1]$, (3) $[0.9,1]$ (three separate cases) and you observe that he drops $k$, then what is the posterior distribution for $p$? BTW, aged 66, I don't tend to get given homework. :) And I don't mind solutions with a software element, provided there is an adequate explanation. Also I have put together three questions of varying difficulty because they are so closely related. So to be clear, I would welcome solutions covering just one of (1) the basic problem (first yellow background above) with 20 candies and $p=0.04$, (2) the more general case with $N$ candies and $p=\frac{1}{M}$, and (3) the inference question (the second yellow background).",,"['probability', 'discrete-mathematics', 'statistical-inference', 'bayesian']"
61,Hillary Clinton's Iowa Caucus Coin Toss Wins and Bayesian Inference,Hillary Clinton's Iowa Caucus Coin Toss Wins and Bayesian Inference,,"In yesterday's Iowa Caucus, Hillary Clinton beat Bernie Sanders in six out of six tied counties by a coin-toss *. I believe we would have heard the uproar about it by now if this was somehow rigged in her favor, but I wanted to calculate the odds of this happening, assuming she really was that lucky, and assuming she rigged various numbers of the tosses. * As many people have pointed out already, this turned out to be a selective data set - Sander's won just about as many coin tosses as Mrs. Clinton did. Read on if you still care about the problem. At first I calculated the odds using simple rules for the probabilities of independent events: $$ P(6\text{H})=6*P(\text{H})=\left( \frac{1}{2} \right)^{6}= \frac{1}{64} \approx 1.56\% $$ i.e. naively, there was a 1.56% chance it was fair . But I vaguely remembered from reading about Bayesian inference that we can make a more educated statement about whether or not this was fair using Bayes' Theorem, and assuming various numbers of the coin tosses were rigged. I tried it out myself, and here's what I came up with, but I'm fairly positive I worked this out incorrectly, so here's hoping you wonderful people can help. Here's my shot at it: Example assuming it was fair (0% chance it was rigged): $$ P(6\text{H}) = \underbrace{P(6\text{H}|\text{fair})}_{1/64}\underbrace{P(\text{fair})}_{1} + \underbrace{P(6\text{H}|\text{not fair})}_{1}\underbrace{P(\text{not fair})}_{0} = \frac{1}{64} $$ and by Bayes Theorem: $$ P(\text{fair}|6\text{H}) = \frac{P(6\text{H}|\text{fair})P(\text{fair})}{P(6\text{H})} = \frac{(1/64)(1)}{(1/64)}=1 $$ (obviously). Assuming $n$ of the tosses were rigged: $$ P(6\text{H}) = \underbrace{P(6\text{H}|\text{fair})}_{\left(\frac{1}{2}\right)^{6}}\underbrace{P(\text{fair})}_{1-\frac{n}{6}} + \underbrace{P(6\text{H}|\text{not fair})}_{1}\underbrace{P(\text{not fair})}_{\frac{n}{6}} = \frac{6-n}{384} + \frac{n}{6} = \frac{63n+6}{384} $$ and by Bayes' Theorem: $$ P(\text{fair}|6\text{H}) = \frac{P(6\text{H}|\text{fair})P(\text{fair})}{P(6\text{H})} = \frac{\left(\frac{1}{64}\right)\left(\frac{6-n}{6}\right)}{\left(\frac{63n+6}{384}\right)}=\frac{6-n}{63n+6} $$ Here's a plot of the probabilities that the coin tosses were fair given an assumption of $n$ unfair coins: Questions: I'm pretty sure some of my assumptions for probabilities were off in various parts of this - if so, where did I go wrong? On the off chance I carried this out correctly, what can be made of these results? For example, is it most probable that there were 0, 1, or 2 coin tosses that were unfair, as making the assumption that there were $n<3$ unfair coins gives a probability $P(\text{fair}|6\text{H})$ greater than the $1/64$ chance it was fair? EDIT: @Eric Wofsey Informed me that I was calculating the wrong probability. What I really wanted to calculate was $P(0|6H)$, the probability of 0 coins being rigged, considering an outcome of 6 heads. What I learned (I'm new to Bayesian inference) is that it all depends upon your prior guess as to the probability that n of the coins were rigged. As he pointed out: $$ P(0|6H) = \frac{P(0)}{\sum_{i=0}^{6}2^iP(i)} $$ where $$ P(n) = {6 \choose n}p^n(1-p)^{6-n} $$ and $p$ is the prior probability that each coin toss was rigged. Here's what $P(0|6H)$ looks like fully expanded (assuming the prior $p$ is the same for each $P(n)$): As I learned, the prior probability is arbitrarily chosen, and represents your belief/guess as to the likelihood that the coins were rigged. I was interested in looking at what the distribution of $P(0|6H)$ looked like for values of $p$ from 0 to 1 (0 meaning you believe there's no possibility the coins were rigged, 1 meaning you're certain the coins were rigged). Here's the plot: I may be going way off the reservation here, but if this graph represents values of $P(0|6H)$ for prior probabilities of having rigged coins, wouldn't the integral of this from $p=0$ to $1$ represent the total probability of 0 rigged coins, considering an outcome of 6 heads, with each prior $p$ weighted equally? Whether or not I'm abusing the maths, the integral evaluates to: $$ \int_{0}^{1} P(0|6H)(p) \ dp = 0.0822\dots $$ Note: I'm thinking in retrospect that the prior $p$ should probably be different for every $P(n)$ and assuming they're the same for each $P(n)$ is likely problematic, but I thought I'd share my process anyway. EDIT 2 : On further thought, it seems like what I really want to compute is the integral: $$\int{\int{\int{\int{\int{\int{\int P(0|6H) \ d p_0 \ d p_1 \ d p_2 \ d p_3 \ d p_4 \ d p_5 \ d p_6}}}}}}$$ where $$ P(0|6H) = \dfrac{(1-p_0)^6}{(1-p_0)^6 + 12p_1(1-p_1)^5 + 60p_2^2(1-p_2)^4 + 160p_3^3(1-p_3)^3 + 240p_4^4(1-p_4)^2 + 192p_5^5(1-p_5) + 64p_6^6} $$ and $$ p_0 + p_1 + p_2 + p_3 + p_4 + p_5 + p_6 = 1 $$ and $p_n$ is the prior probability that $n$ coins are rigged. I have absolutely no idea how one would go about even thinking about evaluating this integral - it seems as though there are a range of values for the integral anyway, depending on the choices of $p_n$. It seems it is definitely possible given specific choices for $p_n$ and maybe even a distribution for the $p_n$s, dependent on n, such that the distribution is still normalized, like a weighted decaying distribution or something (gets less likely as n increases that that number of coins was rigged). Happy Tuesday","In yesterday's Iowa Caucus, Hillary Clinton beat Bernie Sanders in six out of six tied counties by a coin-toss *. I believe we would have heard the uproar about it by now if this was somehow rigged in her favor, but I wanted to calculate the odds of this happening, assuming she really was that lucky, and assuming she rigged various numbers of the tosses. * As many people have pointed out already, this turned out to be a selective data set - Sander's won just about as many coin tosses as Mrs. Clinton did. Read on if you still care about the problem. At first I calculated the odds using simple rules for the probabilities of independent events: $$ P(6\text{H})=6*P(\text{H})=\left( \frac{1}{2} \right)^{6}= \frac{1}{64} \approx 1.56\% $$ i.e. naively, there was a 1.56% chance it was fair . But I vaguely remembered from reading about Bayesian inference that we can make a more educated statement about whether or not this was fair using Bayes' Theorem, and assuming various numbers of the coin tosses were rigged. I tried it out myself, and here's what I came up with, but I'm fairly positive I worked this out incorrectly, so here's hoping you wonderful people can help. Here's my shot at it: Example assuming it was fair (0% chance it was rigged): $$ P(6\text{H}) = \underbrace{P(6\text{H}|\text{fair})}_{1/64}\underbrace{P(\text{fair})}_{1} + \underbrace{P(6\text{H}|\text{not fair})}_{1}\underbrace{P(\text{not fair})}_{0} = \frac{1}{64} $$ and by Bayes Theorem: $$ P(\text{fair}|6\text{H}) = \frac{P(6\text{H}|\text{fair})P(\text{fair})}{P(6\text{H})} = \frac{(1/64)(1)}{(1/64)}=1 $$ (obviously). Assuming $n$ of the tosses were rigged: $$ P(6\text{H}) = \underbrace{P(6\text{H}|\text{fair})}_{\left(\frac{1}{2}\right)^{6}}\underbrace{P(\text{fair})}_{1-\frac{n}{6}} + \underbrace{P(6\text{H}|\text{not fair})}_{1}\underbrace{P(\text{not fair})}_{\frac{n}{6}} = \frac{6-n}{384} + \frac{n}{6} = \frac{63n+6}{384} $$ and by Bayes' Theorem: $$ P(\text{fair}|6\text{H}) = \frac{P(6\text{H}|\text{fair})P(\text{fair})}{P(6\text{H})} = \frac{\left(\frac{1}{64}\right)\left(\frac{6-n}{6}\right)}{\left(\frac{63n+6}{384}\right)}=\frac{6-n}{63n+6} $$ Here's a plot of the probabilities that the coin tosses were fair given an assumption of $n$ unfair coins: Questions: I'm pretty sure some of my assumptions for probabilities were off in various parts of this - if so, where did I go wrong? On the off chance I carried this out correctly, what can be made of these results? For example, is it most probable that there were 0, 1, or 2 coin tosses that were unfair, as making the assumption that there were $n<3$ unfair coins gives a probability $P(\text{fair}|6\text{H})$ greater than the $1/64$ chance it was fair? EDIT: @Eric Wofsey Informed me that I was calculating the wrong probability. What I really wanted to calculate was $P(0|6H)$, the probability of 0 coins being rigged, considering an outcome of 6 heads. What I learned (I'm new to Bayesian inference) is that it all depends upon your prior guess as to the probability that n of the coins were rigged. As he pointed out: $$ P(0|6H) = \frac{P(0)}{\sum_{i=0}^{6}2^iP(i)} $$ where $$ P(n) = {6 \choose n}p^n(1-p)^{6-n} $$ and $p$ is the prior probability that each coin toss was rigged. Here's what $P(0|6H)$ looks like fully expanded (assuming the prior $p$ is the same for each $P(n)$): As I learned, the prior probability is arbitrarily chosen, and represents your belief/guess as to the likelihood that the coins were rigged. I was interested in looking at what the distribution of $P(0|6H)$ looked like for values of $p$ from 0 to 1 (0 meaning you believe there's no possibility the coins were rigged, 1 meaning you're certain the coins were rigged). Here's the plot: I may be going way off the reservation here, but if this graph represents values of $P(0|6H)$ for prior probabilities of having rigged coins, wouldn't the integral of this from $p=0$ to $1$ represent the total probability of 0 rigged coins, considering an outcome of 6 heads, with each prior $p$ weighted equally? Whether or not I'm abusing the maths, the integral evaluates to: $$ \int_{0}^{1} P(0|6H)(p) \ dp = 0.0822\dots $$ Note: I'm thinking in retrospect that the prior $p$ should probably be different for every $P(n)$ and assuming they're the same for each $P(n)$ is likely problematic, but I thought I'd share my process anyway. EDIT 2 : On further thought, it seems like what I really want to compute is the integral: $$\int{\int{\int{\int{\int{\int{\int P(0|6H) \ d p_0 \ d p_1 \ d p_2 \ d p_3 \ d p_4 \ d p_5 \ d p_6}}}}}}$$ where $$ P(0|6H) = \dfrac{(1-p_0)^6}{(1-p_0)^6 + 12p_1(1-p_1)^5 + 60p_2^2(1-p_2)^4 + 160p_3^3(1-p_3)^3 + 240p_4^4(1-p_4)^2 + 192p_5^5(1-p_5) + 64p_6^6} $$ and $$ p_0 + p_1 + p_2 + p_3 + p_4 + p_5 + p_6 = 1 $$ and $p_n$ is the prior probability that $n$ coins are rigged. I have absolutely no idea how one would go about even thinking about evaluating this integral - it seems as though there are a range of values for the integral anyway, depending on the choices of $p_n$. It seems it is definitely possible given specific choices for $p_n$ and maybe even a distribution for the $p_n$s, dependent on n, such that the distribution is still normalized, like a weighted decaying distribution or something (gets less likely as n increases that that number of coins was rigged). Happy Tuesday",,"['probability', 'soft-question', 'recreational-mathematics', 'bayesian']"
62,"Techniques for determining how ""random"" a sample is?","Techniques for determining how ""random"" a sample is?",,"What techniques exist to determine the ""randomness"" of a sample? For instance, say I have data from a series of $1200$ six-sided dice rolls. If the results were 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, ... Or: 1, 1, 1, ..., 2, 2, 2, ..., 3, 3, 3, ... The confidence of randomness would be quite low. Is there a formula where I can input the sequence of outcomes and get back a number that corresponds to the likelihood of randomness? Thanks UPDATE: awkward's answer was the most helpful. Some Googling turned up these two helpful resources: Statistical analysis of Random.org - an overview of the statistical analyses used to evaluate the random numbers generated by the website, www.random.org Random Number Generation Software - a NIST-funded project that provides a discussion on tests that can be used against random number generators, as well as a free software package for running said tests.","What techniques exist to determine the ""randomness"" of a sample? For instance, say I have data from a series of $1200$ six-sided dice rolls. If the results were 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, ... Or: 1, 1, 1, ..., 2, 2, 2, ..., 3, 3, 3, ... The confidence of randomness would be quite low. Is there a formula where I can input the sequence of outcomes and get back a number that corresponds to the likelihood of randomness? Thanks UPDATE: awkward's answer was the most helpful. Some Googling turned up these two helpful resources: Statistical analysis of Random.org - an overview of the statistical analyses used to evaluate the random numbers generated by the website, www.random.org Random Number Generation Software - a NIST-funded project that provides a discussion on tests that can be used against random number generators, as well as a free software package for running said tests.",,['probability']
63,"$P(x,n) = \frac{x(n-1)!}{n^{x}(n-x)! }$ -- What is the name of this probability distribution?",-- What is the name of this probability distribution?,"P(x,n) = \frac{x(n-1)!}{n^{x}(n-x)! }","$$ P(x,n) = \frac{x(n-1)!}{n^{x}(n-x)! } $$ I'm having a really tough time describing what this distribution does, but it's simple in code.  So if you know code, then read on: // example with n = 10 // keep incrementing x until it is greater than random number between 0 and 10 // note that the random number is generated after each iteration var i = 0; while (i++ < Math.random() * 10){}; i = i - 1; // P(3, 10) = the odds that i will end up being 3 What is the name of this distribution?","$$ P(x,n) = \frac{x(n-1)!}{n^{x}(n-x)! } $$ I'm having a really tough time describing what this distribution does, but it's simple in code.  So if you know code, then read on: // example with n = 10 // keep incrementing x until it is greater than random number between 0 and 10 // note that the random number is generated after each iteration var i = 0; while (i++ < Math.random() * 10){}; i = i - 1; // P(3, 10) = the odds that i will end up being 3 What is the name of this distribution?",,"['probability', 'probability-distributions']"
64,What is the probability of an independent event occurring after repeated attempts?,What is the probability of an independent event occurring after repeated attempts?,,"Let's suppose that I have an event whose probability of occurring is $\frac{44}{1000}$. Let's also assume that I can make multiple independent attempts at observing the event. I want to know what the compounded probability is that the event would occur after a certain number of tries.  My intuition is that each event has the same chance of occurring as each attempt is completely independent. Since I couldn't reason my way out of it, I thought instead about the probability of the event NOT occurring.  I asked myself ""What is the probability of the event NOT occurring x times in a row?"" Since these attempts are independent and the probability of 2 independent events occurring in sequence is $P=P(A)*P(B)$, I computed $P=(1-\frac{44}{1000})^x$ With $x=100$, $P\approx 1.1\%$.  Applying the same logic again this means that the probability of not not seeing the event in 100 attempts is $1-P(100)=98.9\%$  Following this reasoning, at x=323 Excel returns 0, meaning near $100\%$ probability (this is of course an artifact of finite precision, it approaches but not reaches 0). This seems to contradict the earlier statement that each event had an independent probability of $\frac{44}{1000}$. What is the correct way of reasoning about this that resolves the seeming contradiction between the odds of the event occurring and the odds of it not occurring after x attempts?","Let's suppose that I have an event whose probability of occurring is $\frac{44}{1000}$. Let's also assume that I can make multiple independent attempts at observing the event. I want to know what the compounded probability is that the event would occur after a certain number of tries.  My intuition is that each event has the same chance of occurring as each attempt is completely independent. Since I couldn't reason my way out of it, I thought instead about the probability of the event NOT occurring.  I asked myself ""What is the probability of the event NOT occurring x times in a row?"" Since these attempts are independent and the probability of 2 independent events occurring in sequence is $P=P(A)*P(B)$, I computed $P=(1-\frac{44}{1000})^x$ With $x=100$, $P\approx 1.1\%$.  Applying the same logic again this means that the probability of not not seeing the event in 100 attempts is $1-P(100)=98.9\%$  Following this reasoning, at x=323 Excel returns 0, meaning near $100\%$ probability (this is of course an artifact of finite precision, it approaches but not reaches 0). This seems to contradict the earlier statement that each event had an independent probability of $\frac{44}{1000}$. What is the correct way of reasoning about this that resolves the seeming contradiction between the odds of the event occurring and the odds of it not occurring after x attempts?",,['probability']
65,Probability question (Birthday problem),Probability question (Birthday problem),,"I was wondering if someone could critique my argument here. The problem is to find the probability where exactly 2 people in a room full of 23 people share the same birthday. My argument is that there are 23 choose 2 ways times $\displaystyle \frac{1}{365^{2}}$ for 2 people to share the same birthday. But, we also have to consider the case involving 21 people who don't share the same birthday. This is just 365 permute 21 times $\displaystyle \frac{1}{365^{21}}$. To summarize: $$\binom{23}{2} \frac{1}{365^2} \frac{1}{365^{21}} P\binom{365}{21}$$","I was wondering if someone could critique my argument here. The problem is to find the probability where exactly 2 people in a room full of 23 people share the same birthday. My argument is that there are 23 choose 2 ways times $\displaystyle \frac{1}{365^{2}}$ for 2 people to share the same birthday. But, we also have to consider the case involving 21 people who don't share the same birthday. This is just 365 permute 21 times $\displaystyle \frac{1}{365^{21}}$. To summarize: $$\binom{23}{2} \frac{1}{365^2} \frac{1}{365^{21}} P\binom{365}{21}$$",,"['probability', 'birthday']"
66,Prove ranks are uniformly distributed,Prove ranks are uniformly distributed,,"We have n IID random variables $X_1, X_2, \ldots, X_n$.  Let $R_i$ be $X_i$'s rank in the set $\{X_1, X_2, \ldots, X_3 \}$ when we order from large to small.  How to prove $R_i, \forall i \in \{1, 2, \ldots, n\}$, is uniformly distributed on $\{1, 2, \ldots, n\}$? My first guess is that, for any position $j$ in ordered sequence of $X$s, as $X_1, X_2, \ldots, X_n$ are equally likely to be the $j$th largest, $$\Pr \{ R_i = j \} = \frac 1 n.$$ So $R_i$ is uniformly distributed on $\{1, 2, \ldots, n\}$. Another way to think about it, is to count how many possible cases are there when $R_i = j$.  As $X_i$'s position in ordered sequence is fixed at $j$, then we can just permute the rest of $X$s to get all possible ordered sequence.  Since there are $n-1$ variables left, there are $(n-1)!$ situations.  As for any $R_i = j, 1 \le j \le n$, there are always $(n-1)!$ possible ordered sequences, we can say $R_i$ is uniformly distributed on $\{1, 2, \ldots, n\}$. Are these 2 proof rigorous? Edit: As cardinal pointed out, an additional condition is needed for the proof, and a sufficient such condition is that $X_i$ to be a continuous random variable.","We have n IID random variables $X_1, X_2, \ldots, X_n$.  Let $R_i$ be $X_i$'s rank in the set $\{X_1, X_2, \ldots, X_3 \}$ when we order from large to small.  How to prove $R_i, \forall i \in \{1, 2, \ldots, n\}$, is uniformly distributed on $\{1, 2, \ldots, n\}$? My first guess is that, for any position $j$ in ordered sequence of $X$s, as $X_1, X_2, \ldots, X_n$ are equally likely to be the $j$th largest, $$\Pr \{ R_i = j \} = \frac 1 n.$$ So $R_i$ is uniformly distributed on $\{1, 2, \ldots, n\}$. Another way to think about it, is to count how many possible cases are there when $R_i = j$.  As $X_i$'s position in ordered sequence is fixed at $j$, then we can just permute the rest of $X$s to get all possible ordered sequence.  Since there are $n-1$ variables left, there are $(n-1)!$ situations.  As for any $R_i = j, 1 \le j \le n$, there are always $(n-1)!$ possible ordered sequences, we can say $R_i$ is uniformly distributed on $\{1, 2, \ldots, n\}$. Are these 2 proof rigorous? Edit: As cardinal pointed out, an additional condition is needed for the proof, and a sufficient such condition is that $X_i$ to be a continuous random variable.",,['probability']
67,Miklos Schweitzer 1968 P11 by Renyi,Miklos Schweitzer 1968 P11 by Renyi,,"Source : Miklos Schweitzer 1968, Problem 11 Let $ A_1,...,A_n$ be arbitrary events in a probability field. Denote by $ C_k$ the event that at least $ k$ of $ A_1,...,A_n$ occur. Prove that $$\prod_{k=1}^n P(C_k) \leq  \prod_{k=1}^n P(A_k).$$ Attempt : I believe the first step to tackle this would be to employ Bayes rule: $$P(C_n)=P(A_1\cap\cdots\cap A_n)=P(A_2\cap\cdots\cap A_n|A_1)P(A_1)$$ as here we accrue a $P(A_1)$ term times something less than or equal to one which is promising for the inequality to show. Then my guess would be to continue to establish similar correspondences with the other $P(A_i)$ terms. I try that by further employing Bayes to get $$P(C_n)=P(A_1)P(A_2|A_1\cap A_3\cap\cdots\cap A_n)P(A_3\cap\cdots\cap A_n|A_1).$$ However this seems to lead to a dead end (at least with $C_n$ ) because I'm conditioning the other $A_k$ terms on some measurable subset of the sample space, so I can't obtain the other $P(A_k)$ terms unconditioned without magic. Another approach or follow-up that seems messy is to use sub-additivity of $P$ to look at the $C_k$ terms for $k<n$ : $$P(C_k)=P\left(\bigcup\limits_{i_1\neq i_2\neq\cdots\neq i_k} A_{i_1}\cap\cdots\cap A_{i_k}\right)\leq \sum\limits_{i_1\neq i_2\neq\cdots\neq i_k} P\left(A_{i_1}\cap\cdots\cap A_{i_k}\right)$$ but um, aside from applying Bayes here to get $P(A_k)$ times some constant $\leq 1$ , this doesn't help as we are adding these factors, not multiplying. Question : I would appreciate tactics/hints here (preferably related to my line of reasoning if possible), not full blown solutions - thanks!","Source : Miklos Schweitzer 1968, Problem 11 Let be arbitrary events in a probability field. Denote by the event that at least of occur. Prove that Attempt : I believe the first step to tackle this would be to employ Bayes rule: as here we accrue a term times something less than or equal to one which is promising for the inequality to show. Then my guess would be to continue to establish similar correspondences with the other terms. I try that by further employing Bayes to get However this seems to lead to a dead end (at least with ) because I'm conditioning the other terms on some measurable subset of the sample space, so I can't obtain the other terms unconditioned without magic. Another approach or follow-up that seems messy is to use sub-additivity of to look at the terms for : but um, aside from applying Bayes here to get times some constant , this doesn't help as we are adding these factors, not multiplying. Question : I would appreciate tactics/hints here (preferably related to my line of reasoning if possible), not full blown solutions - thanks!"," A_1,...,A_n  C_k  k  A_1,...,A_n \prod_{k=1}^n P(C_k) \leq  \prod_{k=1}^n P(A_k). P(C_n)=P(A_1\cap\cdots\cap A_n)=P(A_2\cap\cdots\cap A_n|A_1)P(A_1) P(A_1) P(A_i) P(C_n)=P(A_1)P(A_2|A_1\cap A_3\cap\cdots\cap A_n)P(A_3\cap\cdots\cap A_n|A_1). C_n A_k P(A_k) P C_k k<n P(C_k)=P\left(\bigcup\limits_{i_1\neq i_2\neq\cdots\neq i_k} A_{i_1}\cap\cdots\cap A_{i_k}\right)\leq \sum\limits_{i_1\neq i_2\neq\cdots\neq i_k} P\left(A_{i_1}\cap\cdots\cap A_{i_k}\right) P(A_k) \leq 1",['probability']
68,Probability of choosing integers that sum to zero,Probability of choosing integers that sum to zero,,"This is just a little problem that occurred to me. I don't know how to go about solving it and thought it would be fun to post here. Let $N \geq 3$ be a natural number, and let $n \leq N$ . What is the probability that $n$ numbers randomly selected without repetition from $\{1,...,N\}$ have the property that their signs may be chosen so that they sum to $0$ ? For example, if $N=n=3$ , then the selection $1,2,3$ has the desired property because $3 +(-2) + (-1)=0$ . In this case, $1,2,3$ is the only possible selection and so the probability of obtaining the desired property is $1$ . On the other hand, if $N=3$ and $n=2$ , then no selection has the desired property and the probability is therefore $0$ .","This is just a little problem that occurred to me. I don't know how to go about solving it and thought it would be fun to post here. Let be a natural number, and let . What is the probability that numbers randomly selected without repetition from have the property that their signs may be chosen so that they sum to ? For example, if , then the selection has the desired property because . In this case, is the only possible selection and so the probability of obtaining the desired property is . On the other hand, if and , then no selection has the desired property and the probability is therefore .","N \geq 3 n \leq N n \{1,...,N\} 0 N=n=3 1,2,3 3 +(-2) + (-1)=0 1,2,3 1 N=3 n=2 0","['probability', 'number-theory']"
69,Can sum of pairwise independent random variables be constant?,Can sum of pairwise independent random variables be constant?,,"If we consider a set of random variables $X_1$ up to $X_n$ that are independent, then their sum cannot be a constant (given that at least one of them is non-constant). That is not too hard to prove. Does this assertion still hold, if the random variables are just pairwise independent? The answer is yes, if the variances exist. Then the variance of the sum exists and is the sum of the individual variances, hence larger than zero and the sum cannot be constant. However, is it possible to construct a counterexample if we do not require finite variance (or even expectation) and only pairwise independence?","If we consider a set of random variables up to that are independent, then their sum cannot be a constant (given that at least one of them is non-constant). That is not too hard to prove. Does this assertion still hold, if the random variables are just pairwise independent? The answer is yes, if the variances exist. Then the variance of the sum exists and is the sum of the individual variances, hence larger than zero and the sum cannot be constant. However, is it possible to construct a counterexample if we do not require finite variance (or even expectation) and only pairwise independence?",X_1 X_n,"['probability', 'probability-theory', 'random-variables', 'independence']"
70,How easy is it to create false evidence for a biased coin?,How easy is it to create false evidence for a biased coin?,,"I have a biased coin which comes up heads with probability $p$ . I know the value of $p$ , but I want to falsely claim that the coin has a different probability of heads, $q$ , where $q > p$ . To support my claim I decide to produce some false evidence: I flip the coin repeatedly and record the fraction of flips that were heads, and keep flipping until the fraction is at least $q$ . I also make sure I flip the coin at least $100$ times before stopping (so I flip $100$ times initially, then I keep flipping until the fraction of heads so far is at least $q$ ). I report the total number of flips, and the fraction of heads, as evidence that the coin has probability of heads (approximately) $q$ . In terms of $p$ and $q$ , what is the probability that I can successfully produce evidence for my false claim? (I.e. what is the probability that after $100$ initial flips, my repeated flipping will eventually terminate with a fraction above $q$ in a finite amount of time?) Given that I do successfully produce the false evidence, what is the expected number of flips required? I thought of this question out of curiosity, when pondering about how we can soundly use data to infer unknown probabilities. For Question 1, the probability is positive: in fact, it's at least $p^{100}$ since the first $100$ flips could all be heads. It's less clear if the probability is $< 1$ , but I think it is. The question can be phrased as a random walk in two dimensions, where the false evidence is produced if the random walk enters into the region of points $(x,y)$ where $y > q \cdot (x + y) \text{ and } x + y \ge 100$ . For Question 2, probably thinking about it as a random walk is also the first step. For either question, I would be happy with upper/lower bounds or approximations, if an exact answer is not easy.","I have a biased coin which comes up heads with probability . I know the value of , but I want to falsely claim that the coin has a different probability of heads, , where . To support my claim I decide to produce some false evidence: I flip the coin repeatedly and record the fraction of flips that were heads, and keep flipping until the fraction is at least . I also make sure I flip the coin at least times before stopping (so I flip times initially, then I keep flipping until the fraction of heads so far is at least ). I report the total number of flips, and the fraction of heads, as evidence that the coin has probability of heads (approximately) . In terms of and , what is the probability that I can successfully produce evidence for my false claim? (I.e. what is the probability that after initial flips, my repeated flipping will eventually terminate with a fraction above in a finite amount of time?) Given that I do successfully produce the false evidence, what is the expected number of flips required? I thought of this question out of curiosity, when pondering about how we can soundly use data to infer unknown probabilities. For Question 1, the probability is positive: in fact, it's at least since the first flips could all be heads. It's less clear if the probability is , but I think it is. The question can be phrased as a random walk in two dimensions, where the false evidence is produced if the random walk enters into the region of points where . For Question 2, probably thinking about it as a random walk is also the first step. For either question, I would be happy with upper/lower bounds or approximations, if an exact answer is not easy.","p p q q > p q 100 100 q q p q 100 q p^{100} 100 < 1 (x,y) y > q \cdot (x + y) \text{ and } x + y \ge 100","['probability', 'statistics', 'statistical-inference', 'random-walk']"
71,Random Game Using Real Numbers,Random Game Using Real Numbers,,"The original question: Alice and Bob play a game. To win the game, Alice needs $a$ points, and Bob needs $1$ point ( $a$ is fixed for each game). In each round of the game, Alice picks a real number $x$ . Then a coin is flipped, and Alice is awarded $x$ points if the coin comes up heads, and Bob is awarded $x$ points if the coin comes up tails. Assume Alice always plays optimally. Your task is to find the probability that Alice wins given she is using the best strategy. This problem is a little difficult to formalize, so I will offer the following formalization. First, note that at the beginning of any round, we can normalize the game so that Bob needs exactly $1$ more point. We will define a strategy $s:\mathbb{R^+}\to\mathbb{R^+}$ as a function that takes as an input the number of points Alice needs, and outputs her choice $x$ . Define $p_s(a)$ to be the probability that Alice wins the game needing $a$ points and playing strategy $s$ . Let $S$ be the set of all strategies. Find $$p, p(a)=\sup_{s \in S}p_s(a).$$ First, we note that $p(a) = 1$ if $a = 1 - \epsilon < 1$ , as Alice can choose a sufficiently small $x$ and play it repeatedly until she wins. I have included a formal proof below. Second, we note that $p(1)$ still equals $1$ . Pick $\epsilon, 2\epsilon, 4\epsilon, 8\epsilon, \dots$ until she has won one of these. For sufficiently small $\epsilon$ , this will always happen before she is defeated by Bob. At this point, she is ahead of Bob by $\epsilon$ , and the argument for $a < 1$ applies. Again, I have included a formal proof below Clearly this also imples that $\lim_{a \to 1^+}p(a)=1$ . These are the easy cases. Now intuition suggests that $\lim_{a \to \infty}p(a)=\frac 12$ (she is forced to choose $x=a$ when $a$ is sufficiently large). I have not tried to prove this, but it does not seem too difficult. Finally, I can show that $p(2) \geq \frac 34$ . This is easily done by first having Alice choose $x=1-\epsilon$ for sufficiently small $\epsilon$ . If she wins the points, invoke the $\lim_{a \to 1^+}$ case to win with probability $1$ , and if not then choose $x=2$ to win with probability $\frac 12$ . This strategy can be expanded to any $n \in \mathbb{N}$ by simply picking $1-\epsilon$ repeatedly, $n-1$ times. This shows that $p(n) \geq \frac 12 + 2^{-n+1}$ for natural numbers $n$ . Question: Can this bound be improved, shown to be tight, or extended to all real numbers? Proof for a < 1: Consider the game in which Bob needs $1$ point and Alice needs $1-\epsilon, \epsilon > 0$ points. We will show that for every $\delta > 0$ , there exists a strategy that allows Alice to win with probability at least $1-\delta$ . The strategy is simple: Alice will repeatedly choose $x=k$ , where $k=\frac{\epsilon^2}{8(2-\epsilon)\log \delta}$ . We note that once $2-\epsilon$ points have been awarded, one of the two players must have won. As a result, one of the two players will always have won after $\frac{2-\epsilon}{k}$ rounds have been played. Let $X_i, 1 \leq i \leq \frac{2-\epsilon}{k}$ be the indicator random variable that is $1$ if Bob wins round $i$ and $0$ otherwise, and let $X=\sum X_i$ . Then clearly Bob is awarded a total of $Xk$ points, and so he wins only if $X \geq \frac 1k.$ Then, $$\begin{aligned} \Pr [\text{Bob wins}] =& \text{Pr }\left[X \geq \frac 1k\right] \\ =& \Pr \left[X \geq \frac 1k - \frac \epsilon {2k} + \frac \epsilon {2k}\right] \\ =& \Pr \left[X \geq \mathbb{E} [X] + \frac{\epsilon}{2k}\right] \\ =& \Pr \left[X \geq \mathbb{E} [X] \left(1+ \frac{\epsilon}{2-\epsilon}\right)\right] \\ \leq & \text{exp }\left(-\frac{2-\epsilon}{8k}\left(\frac{\epsilon}{2-\epsilon}\right)^2\right) \hspace{20 px} (*)\\ = & \delta \end{aligned}$$ where $(*)$ is due to Chernoff Bounds. Proof for a=1: We will describe a set of strategies that allow Alice to win the game in which both she and Bob need $1$ point with probability $\geq 1-\delta$ for any $\delta > 0$ . Let $\delta ' = \frac \delta 2$ , and $r=\frac{\delta '}2$ . Alice will begin by choosing $x=r, 2r, 4r, 8r, \dots$ until either Bob wins the game, or until Alice wins any of these coin flips. It is easy to verify algebraically that the probability that Bob wins in this stage is $\leq \delta '$ . Once Alice wins any coin flip, she is ahead of Bob by exactly $r$ points. At this point, she can abandon her current betting scheme, normalize Bob's points and play a strategy for $a<1$ that gives her a win chance of $1-\delta '$ . By union bound, the probability of Bob winning is then $\leq 2\delta ' = \delta$ , as desired.","The original question: Alice and Bob play a game. To win the game, Alice needs points, and Bob needs point ( is fixed for each game). In each round of the game, Alice picks a real number . Then a coin is flipped, and Alice is awarded points if the coin comes up heads, and Bob is awarded points if the coin comes up tails. Assume Alice always plays optimally. Your task is to find the probability that Alice wins given she is using the best strategy. This problem is a little difficult to formalize, so I will offer the following formalization. First, note that at the beginning of any round, we can normalize the game so that Bob needs exactly more point. We will define a strategy as a function that takes as an input the number of points Alice needs, and outputs her choice . Define to be the probability that Alice wins the game needing points and playing strategy . Let be the set of all strategies. Find First, we note that if , as Alice can choose a sufficiently small and play it repeatedly until she wins. I have included a formal proof below. Second, we note that still equals . Pick until she has won one of these. For sufficiently small , this will always happen before she is defeated by Bob. At this point, she is ahead of Bob by , and the argument for applies. Again, I have included a formal proof below Clearly this also imples that . These are the easy cases. Now intuition suggests that (she is forced to choose when is sufficiently large). I have not tried to prove this, but it does not seem too difficult. Finally, I can show that . This is easily done by first having Alice choose for sufficiently small . If she wins the points, invoke the case to win with probability , and if not then choose to win with probability . This strategy can be expanded to any by simply picking repeatedly, times. This shows that for natural numbers . Question: Can this bound be improved, shown to be tight, or extended to all real numbers? Proof for a < 1: Consider the game in which Bob needs point and Alice needs points. We will show that for every , there exists a strategy that allows Alice to win with probability at least . The strategy is simple: Alice will repeatedly choose , where . We note that once points have been awarded, one of the two players must have won. As a result, one of the two players will always have won after rounds have been played. Let be the indicator random variable that is if Bob wins round and otherwise, and let . Then clearly Bob is awarded a total of points, and so he wins only if Then, where is due to Chernoff Bounds. Proof for a=1: We will describe a set of strategies that allow Alice to win the game in which both she and Bob need point with probability for any . Let , and . Alice will begin by choosing until either Bob wins the game, or until Alice wins any of these coin flips. It is easy to verify algebraically that the probability that Bob wins in this stage is . Once Alice wins any coin flip, she is ahead of Bob by exactly points. At this point, she can abandon her current betting scheme, normalize Bob's points and play a strategy for that gives her a win chance of . By union bound, the probability of Bob winning is then , as desired.","a 1 a x x x 1 s:\mathbb{R^+}\to\mathbb{R^+} x p_s(a) a s S p, p(a)=\sup_{s \in S}p_s(a). p(a) = 1 a = 1 - \epsilon < 1 x p(1) 1 \epsilon, 2\epsilon, 4\epsilon, 8\epsilon, \dots \epsilon \epsilon a < 1 \lim_{a \to 1^+}p(a)=1 \lim_{a \to \infty}p(a)=\frac 12 x=a a p(2) \geq \frac 34 x=1-\epsilon \epsilon \lim_{a \to 1^+} 1 x=2 \frac 12 n \in \mathbb{N} 1-\epsilon n-1 p(n) \geq \frac 12 + 2^{-n+1} n 1 1-\epsilon, \epsilon > 0 \delta > 0 1-\delta x=k k=\frac{\epsilon^2}{8(2-\epsilon)\log \delta} 2-\epsilon \frac{2-\epsilon}{k} X_i, 1 \leq i \leq \frac{2-\epsilon}{k} 1 i 0 X=\sum X_i Xk X \geq \frac 1k. \begin{aligned}
\Pr [\text{Bob wins}] =& \text{Pr }\left[X \geq \frac 1k\right] \\
=& \Pr \left[X \geq \frac 1k - \frac \epsilon {2k} + \frac \epsilon {2k}\right] \\
=& \Pr \left[X \geq \mathbb{E} [X] + \frac{\epsilon}{2k}\right] \\
=& \Pr \left[X \geq \mathbb{E} [X] \left(1+ \frac{\epsilon}{2-\epsilon}\right)\right] \\
\leq & \text{exp }\left(-\frac{2-\epsilon}{8k}\left(\frac{\epsilon}{2-\epsilon}\right)^2\right) \hspace{20 px} (*)\\
= & \delta
\end{aligned} (*) 1 \geq 1-\delta \delta > 0 \delta ' = \frac \delta 2 r=\frac{\delta '}2 x=r, 2r, 4r, 8r, \dots \leq \delta ' r a<1 1-\delta ' \leq 2\delta ' = \delta","['probability', 'statistics', 'game-theory']"
72,Prisoners wearing infinite stack of hats,Prisoners wearing infinite stack of hats,,"There are N prisoners, each wearing an infinite stack of hats. Each hat was chosen at random to be black or white. Each prisoner can see all the others but not her own stack. Each prisoner must independently write down the index of a black hat in her own stack. The warden checks all the guesses, and if one or more are wrong the prisoners are killed. The day before, the prisoners were told the rules and allowed to agree on a strategy they would follow for guessing. What strategy should they adopt and what is the probability that they will survive? I have an ad hoc strategy that promises survival with probability 1/( N +1). Can one do better or prove that this is optimal?","There are N prisoners, each wearing an infinite stack of hats. Each hat was chosen at random to be black or white. Each prisoner can see all the others but not her own stack. Each prisoner must independently write down the index of a black hat in her own stack. The warden checks all the guesses, and if one or more are wrong the prisoners are killed. The day before, the prisoners were told the rules and allowed to agree on a strategy they would follow for guessing. What strategy should they adopt and what is the probability that they will survive? I have an ad hoc strategy that promises survival with probability 1/( N +1). Can one do better or prove that this is optimal?",,"['probability', 'combinatorics', 'recreational-mathematics', 'puzzle']"
73,Probability a tree has $n$ nodes,Probability a tree has  nodes,n,"Consider each node on a graph has a $p$ probability of creating a new child node every step $c$. For this example $p = \frac{1}{2^{l+1}}$, where $l$ is the distance away from the origin node. See the chart at bottom (sorry for paint). Question: For a step $c$, if $n \in [1, 2^c]$, what is the probability the graph has $n$ nodes? Is there a closed form expression? My thoughts are that you'd have to ""add down the tree"" to get the probability for a specific branch. However, there are multiple ways of having $n$ nodes, which I assume you'd account for by multiplying the probabilities of having each possibility together, i.e. $P(x_j + \dots + x_k) \cdots P(x_m + \dots + x_n)$, where $x_m \dots x_n$ are probabilities in a combination of nodes that gives $n$ nodes overall. For $c=2$ there's $1$ way for it to have $1$ node ($20\%$), $1$ way it could have $2$ ($20\%$), $2$ ways it could have $3$ ($40\%$), and $1$ way it could have $4$ ($20\%$). Clearly this is the result if each outcome is equally likely, which is not the case. Is there an easy, closed form way to weight each outcome? I'm not sure where to go from there or really how to approach this problem at all. Edit: I've been messing around with Mathematica and I've been able to simulate up to $10^7$ and generate some plots of the distributions (seen below). The width is slightly skew due to each step $c$ having a different max number of nodes, however we can still see the shape of the plot well. where the solid lines are approximations using the Gaussian curve, $$ \frac{A}{\sqrt{2\pi}\sigma} e^{\frac{-(x-x_0)^2}{2\sigma^2}} ,$$ $c=11 \to (A=1.00334,\, x_0=15.5507, \, \sigma=6.37225)$, $c=10 \to (A=1.00428,\, x_0=13.0468, \, \sigma=5.50204)$, $c=9 \to (A=1.0053,\, x_0=10.8424, \, \sigma=4.68556)$, $c=7 \to (A=1.01089,\, x_0=7.25233, \, \sigma=3.33195)$, $c=5 \to (A=1.02033,\, x_0=4.58044, \, \sigma=2.22072)$. It's interesting that it's close to a Gaussian distribution, however I'm not sure if this helps in finding a closed form. Maybe one could define $f : \mathbb N \to \mathbb R^3$, which maps $c$ to $A$, $x_0$, and $\sigma$. How one would go about this? My only idea is to calculate $A$, $x_0$, and $\sigma$ a considerable number more times and try to fit the data with Mathematica. I've shown the general trend of the data here .","Consider each node on a graph has a $p$ probability of creating a new child node every step $c$. For this example $p = \frac{1}{2^{l+1}}$, where $l$ is the distance away from the origin node. See the chart at bottom (sorry for paint). Question: For a step $c$, if $n \in [1, 2^c]$, what is the probability the graph has $n$ nodes? Is there a closed form expression? My thoughts are that you'd have to ""add down the tree"" to get the probability for a specific branch. However, there are multiple ways of having $n$ nodes, which I assume you'd account for by multiplying the probabilities of having each possibility together, i.e. $P(x_j + \dots + x_k) \cdots P(x_m + \dots + x_n)$, where $x_m \dots x_n$ are probabilities in a combination of nodes that gives $n$ nodes overall. For $c=2$ there's $1$ way for it to have $1$ node ($20\%$), $1$ way it could have $2$ ($20\%$), $2$ ways it could have $3$ ($40\%$), and $1$ way it could have $4$ ($20\%$). Clearly this is the result if each outcome is equally likely, which is not the case. Is there an easy, closed form way to weight each outcome? I'm not sure where to go from there or really how to approach this problem at all. Edit: I've been messing around with Mathematica and I've been able to simulate up to $10^7$ and generate some plots of the distributions (seen below). The width is slightly skew due to each step $c$ having a different max number of nodes, however we can still see the shape of the plot well. where the solid lines are approximations using the Gaussian curve, $$ \frac{A}{\sqrt{2\pi}\sigma} e^{\frac{-(x-x_0)^2}{2\sigma^2}} ,$$ $c=11 \to (A=1.00334,\, x_0=15.5507, \, \sigma=6.37225)$, $c=10 \to (A=1.00428,\, x_0=13.0468, \, \sigma=5.50204)$, $c=9 \to (A=1.0053,\, x_0=10.8424, \, \sigma=4.68556)$, $c=7 \to (A=1.01089,\, x_0=7.25233, \, \sigma=3.33195)$, $c=5 \to (A=1.02033,\, x_0=4.58044, \, \sigma=2.22072)$. It's interesting that it's close to a Gaussian distribution, however I'm not sure if this helps in finding a closed form. Maybe one could define $f : \mathbb N \to \mathbb R^3$, which maps $c$ to $A$, $x_0$, and $\sigma$. How one would go about this? My only idea is to calculate $A$, $x_0$, and $\sigma$ a considerable number more times and try to fit the data with Mathematica. I've shown the general trend of the data here .",,"['probability', 'graph-theory', 'trees']"
74,Monty hall problem with 4 doors and PLAYER choosing 2 initially,Monty hall problem with 4 doors and PLAYER choosing 2 initially,,"Question: In a variation of the Monty Hall game show, you now have 4 doors and only one has a car behind it. The other 3 doors have goats. This time you choose (without opening them) 2 doors. Monty Hall opens one of the remaining doors and shows that it has a goat. He then asks you “If you keep your two choices and the car is behind one of the two doors you chose, you win. But you can give up your two choices and open the remaining door and win the car if it is there.” In order to maximize your chance of winning the car, should you take Monty’s offer or not? My Attempt: Initially we have ${{4}\choose{2}} = 6$ ways of choosing 2 doors.  1) We have 3 ways of choosing two doors so that we are on door with car.  If we switch, we lose. 2) We have 3 ways of choosing two doors so that both of the doors have goats.  If we switch we win. Since we are equally likely if we switch or do not (in light of the equal number of ways we can choose doors so that we have the car or do not have the car), it does not make any difference, probability-wise to make the switch.","Question: In a variation of the Monty Hall game show, you now have 4 doors and only one has a car behind it. The other 3 doors have goats. This time you choose (without opening them) 2 doors. Monty Hall opens one of the remaining doors and shows that it has a goat. He then asks you “If you keep your two choices and the car is behind one of the two doors you chose, you win. But you can give up your two choices and open the remaining door and win the car if it is there.” In order to maximize your chance of winning the car, should you take Monty’s offer or not? My Attempt: Initially we have ${{4}\choose{2}} = 6$ ways of choosing 2 doors.  1) We have 3 ways of choosing two doors so that we are on door with car.  If we switch, we lose. 2) We have 3 ways of choosing two doors so that both of the doors have goats.  If we switch we win. Since we are equally likely if we switch or do not (in light of the equal number of ways we can choose doors so that we have the car or do not have the car), it does not make any difference, probability-wise to make the switch.",,"['probability', 'proof-verification', 'monty-hall']"
75,"""Mastermind""-esque safe opening problem.","""Mastermind""-esque safe opening problem.",,"I read this interview question for a trading job and it seems quite difficult. What is the technique to solving it? You have a safe with six digits and a light. You can input a code, if   you have between 0 and 3 of the 6 digits correct, the light will turn   red. If you have between 4 and 5 of the 6 digits correct, it will turn   yellow and if you have all 6 digits correct, it will open. There is   $10, 000 inside the safe, you can guess the code as many times as you   want, but need to pay each time you guess, how much would you be   willing to pay for each guess? Thanks","I read this interview question for a trading job and it seems quite difficult. What is the technique to solving it? You have a safe with six digits and a light. You can input a code, if   you have between 0 and 3 of the 6 digits correct, the light will turn   red. If you have between 4 and 5 of the 6 digits correct, it will turn   yellow and if you have all 6 digits correct, it will open. There is   $10, 000 inside the safe, you can guess the code as many times as you   want, but need to pay each time you guess, how much would you be   willing to pay for each guess? Thanks",,"['probability', 'combinatorics', 'statistics']"
76,Difference between conditional and intersection in probability.,Difference between conditional and intersection in probability.,,"I am having hard time figuring out if it is a conditional probability or an ""and"" probability under the following types of problems. When a student is absent, the probability of the student being sick is .6 In such a sentence, I am not quite sure if the probability is conditional or the probability when the student is sick and absent. Which one would it be? As a matter of fact, is there a rule of thumb to be able to tell if it is conditional or not? I feel as though every time I deal with these kind of problems I get stuck.","I am having hard time figuring out if it is a conditional probability or an ""and"" probability under the following types of problems. When a student is absent, the probability of the student being sick is .6 In such a sentence, I am not quite sure if the probability is conditional or the probability when the student is sick and absent. Which one would it be? As a matter of fact, is there a rule of thumb to be able to tell if it is conditional or not? I feel as though every time I deal with these kind of problems I get stuck.",,"['probability', 'actuarial-science']"
77,A plan to defeat a betting game where the odds of winning are 50/50. Help me understand why it's flawed. [duplicate],A plan to defeat a betting game where the odds of winning are 50/50. Help me understand why it's flawed. [duplicate],,"This question already has answers here : Why did my friend lose all his money? (4 answers) Closed 9 years ago . My friend has this plan where he implies that it's impossible to lose, as long as the odds of winning are 50/50 on each bet. His idea is that basically you keep doubling your bet until you win and then start over again. So for example, you bet 1 dollar and you lose, your net profit is now -1 dollar. Now you double your bet to 2 dollars and you lose again so your net profit is -3 dollars. Now you double your bet to 4 dollars and you win. This means you gain 4 dollars and now your net profit is 1 dollar. So you've made a profit. Now you start again. The reasoning here being that it is highly unlikely for you to lose a 50/50 toss x number of times in a row. My counter-argument here is that basically if you go in with 50 dollars with the aim of doubling up to 100 dollars, you have the same odds of winning if you do one bet of 50 dollars or the technique outlined above. I cannot wrap my head around explaining this issue in a clear manner though, so maybe you wonderful folk at Mathematics can help! Oh and I've pointed out that he uses gamblers fallacy in very obscure way, as he insists you need to go back to betting 1 dollar once you've won. This appears to be an obscure case of gamblers fallacy to me as it implies there is some hidden force which are changing the odds on each individual coin toss.","This question already has answers here : Why did my friend lose all his money? (4 answers) Closed 9 years ago . My friend has this plan where he implies that it's impossible to lose, as long as the odds of winning are 50/50 on each bet. His idea is that basically you keep doubling your bet until you win and then start over again. So for example, you bet 1 dollar and you lose, your net profit is now -1 dollar. Now you double your bet to 2 dollars and you lose again so your net profit is -3 dollars. Now you double your bet to 4 dollars and you win. This means you gain 4 dollars and now your net profit is 1 dollar. So you've made a profit. Now you start again. The reasoning here being that it is highly unlikely for you to lose a 50/50 toss x number of times in a row. My counter-argument here is that basically if you go in with 50 dollars with the aim of doubling up to 100 dollars, you have the same odds of winning if you do one bet of 50 dollars or the technique outlined above. I cannot wrap my head around explaining this issue in a clear manner though, so maybe you wonderful folk at Mathematics can help! Oh and I've pointed out that he uses gamblers fallacy in very obscure way, as he insists you need to go back to betting 1 dollar once you've won. This appears to be an obscure case of gamblers fallacy to me as it implies there is some hidden force which are changing the odds on each individual coin toss.",,"['probability', 'gambling']"
78,Coupon Collector's problem with unequal probabilities,Coupon Collector's problem with unequal probabilities,,"Given 4 different items, each with different chance of being selected, select an item, replace it and select another. What is the expected mean number of selections that is required to select at least one of each item. Through some research, this appears to be a variation of the coupon collector's problem where each of my ""coupons"" doesn't have the same probability. From the final formula this post , I deduced that the average number of draws is given by: $$ n\sum\limits_{j=1}^n {1\over j} $$ How can I amend this for items of unequal probability of selection please? From the partial answer from @John: $p_1 = 1$ $p_2 = p_a (p_b + p_c + p_d) + p_b (p_c + p_d + p_a) + p_c (p_d + p_a + p_b) + p_d (p_a + p_b + p_c)$ Am I then right in thinking $p_3$ would be  $ p_ap_b(p_c + p_d) +  p_ap_c(p_b + p_d) +  p_ap_d(p_b + p_c) +  p_bp_c(p_a + p_d) +  p_bp_d(p_a + p_c) +  p_cp_d(p_a + p_b) $ and $p_4$ would be $ p_ap_bp_c(p_d) +  p_ap_bp_d(p_c) +  p_ap_cp_d(p_b) +  p_bp_cp_d(p_c) $ simplified to $4(p_ap_bp_cp_d)$ I put these values into a spreadsheet, but there's something I've done wrong. For the purpose of testing, I gave my coupons equal probability where I know the result should be 8.33. However, I'm getting the result 71.67 and can't see what is wrong. Any suggestions please?","Given 4 different items, each with different chance of being selected, select an item, replace it and select another. What is the expected mean number of selections that is required to select at least one of each item. Through some research, this appears to be a variation of the coupon collector's problem where each of my ""coupons"" doesn't have the same probability. From the final formula this post , I deduced that the average number of draws is given by: $$ n\sum\limits_{j=1}^n {1\over j} $$ How can I amend this for items of unequal probability of selection please? From the partial answer from @John: $p_1 = 1$ $p_2 = p_a (p_b + p_c + p_d) + p_b (p_c + p_d + p_a) + p_c (p_d + p_a + p_b) + p_d (p_a + p_b + p_c)$ Am I then right in thinking $p_3$ would be  $ p_ap_b(p_c + p_d) +  p_ap_c(p_b + p_d) +  p_ap_d(p_b + p_c) +  p_bp_c(p_a + p_d) +  p_bp_d(p_a + p_c) +  p_cp_d(p_a + p_b) $ and $p_4$ would be $ p_ap_bp_c(p_d) +  p_ap_bp_d(p_c) +  p_ap_cp_d(p_b) +  p_bp_cp_d(p_c) $ simplified to $4(p_ap_bp_cp_d)$ I put these values into a spreadsheet, but there's something I've done wrong. For the purpose of testing, I gave my coupons equal probability where I know the result should be 8.33. However, I'm getting the result 71.67 and can't see what is wrong. Any suggestions please?",,"['probability', 'coupon-collector']"
79,How does the answer to Feynman's Restaurant Problem change if $M$ is not restricted to a single value?,How does the answer to Feynman's Restaurant Problem change if  is not restricted to a single value?,M,"First, the background: Feynman's restaurant problem asks how we can maximise the total rating of the meals we eat at a restaurant with $N$ items on the menu, given that we know up-front that we are going to eat $M$ meals there . I have transcribed the problem and answer: Assume that a restaurant has $N$ dishes on its menu that are rated   from worst to best, $1$ to $N$ (according to your personal   preferences). You, however, don't know the ratings of the dishes, and   when you try a new dish, all you learn is whether it is the best   (highest rated) dish you have tried so far, or not. Each time you eat   a meal at the restaurant you either order a new dish or you order the   best dish you have tried so far. Your goal is to maximize the average   total ratings of the dishes you eat in $M$ meals (where $M \leq N$). The average total ratings in a sequence of meals that includes $n$   ""new"" dishes and $b$ ""best so far"" dishes can be no higher than the   average total ratings in the sequence having all $n$ ""new"" dishes   followed by all $b$ ""best so far"" dishes. Thus a successful strategy   requires you to order some number of new dishes and thereafter only   order the best dish so far. The problem then reduces to the following: Given $N$ (dishes on the menu) and $M\leq N$ (meals to be eaten at   the restaurant), how many new dishes $D$ should you try before   switching to ordering the best of them for all the remaining $(M–D)$   meals, in order to maximize the average total ratings of the dishes   consumed? Answer : $D = \sqrt{2(M+1)} - 1$ So if we are visiting a restaurant with $20$ dishes $7$ times, we should pick different dishes for the first $3$ trips, then have the best of those the next $4$ times. However, as far as practical application goes, this answer is the answer to a question that doesn't match reality - rarely do we know exactly how many times we're going to eat at a restaurant! Suppose instead of having $M$ equal some fixed value, we instead have $M$ distributed according to some probability distribution $P$. For example, suppose we know we are going to visit a restaurant with $20$ dishes on some number of occasions uniformly distributed over $5..10$. What now should be our value for $D$? What about if $P$ is a less simple distribution? * edit to add * Is it as simple as $\sum_m{P(m) D(m)}$ (which is I think $E(D)$?) where $D(m) = \sqrt{2(m+1)} - 1$ as above? Assuming that $P$ can't change over the course of the exercise, which as mjqxxxx points out would be quite possible in reality...","First, the background: Feynman's restaurant problem asks how we can maximise the total rating of the meals we eat at a restaurant with $N$ items on the menu, given that we know up-front that we are going to eat $M$ meals there . I have transcribed the problem and answer: Assume that a restaurant has $N$ dishes on its menu that are rated   from worst to best, $1$ to $N$ (according to your personal   preferences). You, however, don't know the ratings of the dishes, and   when you try a new dish, all you learn is whether it is the best   (highest rated) dish you have tried so far, or not. Each time you eat   a meal at the restaurant you either order a new dish or you order the   best dish you have tried so far. Your goal is to maximize the average   total ratings of the dishes you eat in $M$ meals (where $M \leq N$). The average total ratings in a sequence of meals that includes $n$   ""new"" dishes and $b$ ""best so far"" dishes can be no higher than the   average total ratings in the sequence having all $n$ ""new"" dishes   followed by all $b$ ""best so far"" dishes. Thus a successful strategy   requires you to order some number of new dishes and thereafter only   order the best dish so far. The problem then reduces to the following: Given $N$ (dishes on the menu) and $M\leq N$ (meals to be eaten at   the restaurant), how many new dishes $D$ should you try before   switching to ordering the best of them for all the remaining $(M–D)$   meals, in order to maximize the average total ratings of the dishes   consumed? Answer : $D = \sqrt{2(M+1)} - 1$ So if we are visiting a restaurant with $20$ dishes $7$ times, we should pick different dishes for the first $3$ trips, then have the best of those the next $4$ times. However, as far as practical application goes, this answer is the answer to a question that doesn't match reality - rarely do we know exactly how many times we're going to eat at a restaurant! Suppose instead of having $M$ equal some fixed value, we instead have $M$ distributed according to some probability distribution $P$. For example, suppose we know we are going to visit a restaurant with $20$ dishes on some number of occasions uniformly distributed over $5..10$. What now should be our value for $D$? What about if $P$ is a less simple distribution? * edit to add * Is it as simple as $\sum_m{P(m) D(m)}$ (which is I think $E(D)$?) where $D(m) = \sqrt{2(m+1)} - 1$ as above? Assuming that $P$ can't change over the course of the exercise, which as mjqxxxx points out would be quite possible in reality...",,['probability']
80,Laplace transform of integrated geometric Brownian motion,Laplace transform of integrated geometric Brownian motion,,"Is there any closed form of the Laplace transform of an integrated geometric Brownian motion ? A geometric Brownian motion $X=(X_t)_{t \geq 0}$ satisifies $dX_t = \sigma X_t \, dW_t$ where $W=(W_t)_{t \geq 0}$ denotes a Brownian motion and the associated integrated Brownian motion is $\int_0^t X_s \, ds$. The Laplace transform of an integrated gometric Brownian motion is thus $$ \mathcal{L}(\lambda) = \mathbb{E}\left[e^{-\lambda \int_0^t X_s ds } \right]$$","Is there any closed form of the Laplace transform of an integrated geometric Brownian motion ? A geometric Brownian motion $X=(X_t)_{t \geq 0}$ satisifies $dX_t = \sigma X_t \, dW_t$ where $W=(W_t)_{t \geq 0}$ denotes a Brownian motion and the associated integrated Brownian motion is $\int_0^t X_s \, ds$. The Laplace transform of an integrated gometric Brownian motion is thus $$ \mathcal{L}(\lambda) = \mathbb{E}\left[e^{-\lambda \int_0^t X_s ds } \right]$$",,"['probability', 'stochastic-processes', 'laplace-transform', 'brownian-motion']"
81,Expectation of a Random Subset of the Roots of Unity.,Expectation of a Random Subset of the Roots of Unity.,,"Let $p$ be a prime.  If $1_A(x)$ denotes the indicator function of the set $A\subset\mathbb{Z}/p\mathbb{Z}$ and $$\hat{1}_A(t):=\frac{1}{p}\sum_{n=1}^p 1_A(n)e^{2\pi i \frac{nt}{p}}$$ denotes the Fourier transform of $1_A$, then what can be said about $$\mathbb{E}\left( \sup_{t\neq 0} |\hat{1}_A(t)|\right)?$$  Do we have an upper bound of the form $O\left(\frac{\log p}{\sqrt{p}}\right)$ as $p$ goes to infinity? Alternate wording: For each subset $A$ of the $p$ roots, let $Sum(A)$ to denote the sum of the elements in $A$, and look at $A^t:=\{a^t:\ a\in A\}$ for integers $0<t<p$.  Then, what is the expectation of the maximum of the sum over $t$?  How well can we bound $$\mathbb{E}_A\left(\sup_{t} \ \left|Sum\left(A^t\right)\right|\right).$$ Remarks: This question originated from an optional homework problem in my Arithmetic Combinatorics class.  I tried some fairly long and drawn out things that did not work.  Also, note that since $p$ is prime, taking the power for $0<t<p$ corresponds exactly to the automorphisms.","Let $p$ be a prime.  If $1_A(x)$ denotes the indicator function of the set $A\subset\mathbb{Z}/p\mathbb{Z}$ and $$\hat{1}_A(t):=\frac{1}{p}\sum_{n=1}^p 1_A(n)e^{2\pi i \frac{nt}{p}}$$ denotes the Fourier transform of $1_A$, then what can be said about $$\mathbb{E}\left( \sup_{t\neq 0} |\hat{1}_A(t)|\right)?$$  Do we have an upper bound of the form $O\left(\frac{\log p}{\sqrt{p}}\right)$ as $p$ goes to infinity? Alternate wording: For each subset $A$ of the $p$ roots, let $Sum(A)$ to denote the sum of the elements in $A$, and look at $A^t:=\{a^t:\ a\in A\}$ for integers $0<t<p$.  Then, what is the expectation of the maximum of the sum over $t$?  How well can we bound $$\mathbb{E}_A\left(\sup_{t} \ \left|Sum\left(A^t\right)\right|\right).$$ Remarks: This question originated from an optional homework problem in my Arithmetic Combinatorics class.  I tried some fairly long and drawn out things that did not work.  Also, note that since $p$ is prime, taking the power for $0<t<p$ corresponds exactly to the automorphisms.",,"['probability', 'combinatorics', 'fourier-analysis', 'roots-of-unity', 'arithmetic-combinatorics']"
82,An Inverse Jensen Inequality,An Inverse Jensen Inequality,,"Given $\sigma>0$ , let $X\sim N(0,\sigma^2I_d)$ be a normal random variable in $\mathbb R^d$ . Prove or disprove: there exists a constant $C$ such that for any 1-Lipschitz function $f:\mathbb R^d\rightarrow\mathbb R$ , $$ \log\big(\mathbb E[e^{f(X)}]\big) - \mathbb E[f(X)] \leqslant C\sigma^2. $$ Here, $f$ is 1-Lipschitz means that $f$ is continuous in $\mathbb R^d$ and $|f(x)-f(y)|\leqslant |x-y|$ for any $x,y\in\mathbb R^d$ . This problem comes from the proof of Proposition 3 in this paper , where the authors claimed that the log-Sobolev inequality can be used to prove eq. 25. The problem above can be viewed as a simplified version of eq. 25 of the paper. However, I found it non-trivial to obtain eq. 25 using the log-Sobolev inequality, the log-Harnack inequality, or other functional inequalities I know. It looks more like an inverse type of the Jensen's inequality, which is the reason this problem is so named. Here are some direct observations of this problem. First of all, by Jensen's inequality, one has $$ \log\big(\mathbb E[e^{f(X)}]\big) - \mathbb E[f(X)] \geqslant 0, $$ which seems no help. Another idea is to consider the random variable $Y = f(X)$ rather than $X$ itself. Then it may be reasonable to consider $$ \log\big( \mathbb E[e^Y]\big) - \mathbb E[Y] \leqslant \mathrm{Var}(Y). $$ Unfortunately, this inequality does not hold for arbitrary $Y$ . Also, the Lipschitz property of $f$ becomes implicit here. In the case $d=1$ , if one chooses $f(x) = x$ directly, it can be verified that $$ \log\big(\mathbb E[e^{X}]\big) - \mathbb E[X] = \frac{\sigma^2}2. $$ This is why the RHS has a square term of $\sigma$ . Any suggestions are appreciated. Even the solution in the case $d=1$ is fine.","Given , let be a normal random variable in . Prove or disprove: there exists a constant such that for any 1-Lipschitz function , Here, is 1-Lipschitz means that is continuous in and for any . This problem comes from the proof of Proposition 3 in this paper , where the authors claimed that the log-Sobolev inequality can be used to prove eq. 25. The problem above can be viewed as a simplified version of eq. 25 of the paper. However, I found it non-trivial to obtain eq. 25 using the log-Sobolev inequality, the log-Harnack inequality, or other functional inequalities I know. It looks more like an inverse type of the Jensen's inequality, which is the reason this problem is so named. Here are some direct observations of this problem. First of all, by Jensen's inequality, one has which seems no help. Another idea is to consider the random variable rather than itself. Then it may be reasonable to consider Unfortunately, this inequality does not hold for arbitrary . Also, the Lipschitz property of becomes implicit here. In the case , if one chooses directly, it can be verified that This is why the RHS has a square term of . Any suggestions are appreciated. Even the solution in the case is fine.","\sigma>0 X\sim N(0,\sigma^2I_d) \mathbb R^d C f:\mathbb R^d\rightarrow\mathbb R 
\log\big(\mathbb E[e^{f(X)}]\big) - \mathbb E[f(X)] \leqslant C\sigma^2.
 f f \mathbb R^d |f(x)-f(y)|\leqslant |x-y| x,y\in\mathbb R^d 
\log\big(\mathbb E[e^{f(X)}]\big) - \mathbb E[f(X)] \geqslant 0,
 Y = f(X) X 
\log\big(
\mathbb E[e^Y]\big) - \mathbb E[Y] \leqslant \mathrm{Var}(Y).
 Y f d=1 f(x) = x 
\log\big(\mathbb E[e^{X}]\big) - \mathbb E[X] = \frac{\sigma^2}2.
 \sigma d=1","['probability', 'inequality', 'jensen-inequality']"
83,Yankee swap without stealing: Prob of last player ending with his/her own gift,Yankee swap without stealing: Prob of last player ending with his/her own gift,,"Our group did a yankee swap yesterday, which got me thinking about a probability question, re: a simplified version without actual ""stealing"". Players numbered $1, 2, ..., N$ each brings a wrapped gift. Then in order, player $1, 2, ..., N-1$ each uniformly-randomly picks a wrapped gift which is NOT the one he/she brought, and unwraps it.  (By unwrapping it, this gift cannot be picked by any subsequent player.) Question: What is the probability $p$ that the last wrapped gift was brought by the last player, i.e. $N$ ?  (Or in yankee swap terminology, the last player would be forced to unwrap the gift he/she brought.) Further thoughts: Clearly $1/N$ is not the answer since $N=2 \implies p=0$ (player $1$ is forced to pick the gift brought by player $2$ ). A bit of calculation shows $N = 3 \implies p=1/4$ : Player $1$ can pick $2$ or $3$ , with prob $1/2$ each. If player $1$ picked $3$ , then player $2$ must pick $1$ and player $3$ will pick $2$ . If player $1$ picked $2$ , then player $2$ can pick $1$ or $3$ , with conditional probability $1/2$ each. Therefore, the only case of gift $3$ being the last wrapped gift is $1$ picks $2$ and $2$ picks $1$ , which happens with probability $1/2 \times 1/2 = 1/4$ . I would think for large $N$ the probability approaches $1/N$ , but stays slightly below.  I.e. I imagine $p = 1/N - \epsilon(N)$ where the error term $\epsilon(N) > 0$ and approaches $0$ very very fast (much faster than $1/N$ ). For any $N$ , we can solve this exactly using a system of recurrences (involving $3N$ variables, I think...), but I'm wondering if there is a smarter way.  E.g. if my second bullet above is correct, is there a good way to calculate or bound the error term?","Our group did a yankee swap yesterday, which got me thinking about a probability question, re: a simplified version without actual ""stealing"". Players numbered each brings a wrapped gift. Then in order, player each uniformly-randomly picks a wrapped gift which is NOT the one he/she brought, and unwraps it.  (By unwrapping it, this gift cannot be picked by any subsequent player.) Question: What is the probability that the last wrapped gift was brought by the last player, i.e. ?  (Or in yankee swap terminology, the last player would be forced to unwrap the gift he/she brought.) Further thoughts: Clearly is not the answer since (player is forced to pick the gift brought by player ). A bit of calculation shows : Player can pick or , with prob each. If player picked , then player must pick and player will pick . If player picked , then player can pick or , with conditional probability each. Therefore, the only case of gift being the last wrapped gift is picks and picks , which happens with probability . I would think for large the probability approaches , but stays slightly below.  I.e. I imagine where the error term and approaches very very fast (much faster than ). For any , we can solve this exactly using a system of recurrences (involving variables, I think...), but I'm wondering if there is a smarter way.  E.g. if my second bullet above is correct, is there a good way to calculate or bound the error term?","1, 2, ..., N 1, 2, ..., N-1 p N 1/N N=2 \implies p=0 1 2 N = 3 \implies p=1/4 1 2 3 1/2 1 3 2 1 3 2 1 2 2 1 3 1/2 3 1 2 2 1 1/2 \times 1/2 = 1/4 N 1/N p = 1/N - \epsilon(N) \epsilon(N) > 0 0 1/N N 3N","['probability', 'recreational-mathematics']"
84,How can I prove these two questions without using the following theorem?,How can I prove these two questions without using the following theorem?,,"Question 1: Let $X_1, X_2, \cdots$ be independent random variables such that $$P(X_n=-n^{\theta})=P(X_n=n^{\theta})=\frac{1}{2}.$$ If $\theta > -\frac{1}{2}$ prove that the Lyapunov condition works and the sequence satisfies the central limit theorem. Question 2: Let $X_1, X_2, \cdots$ be independent random variables such that $$P(X_n=-n^{\theta})=P(X_n=n^{\theta})=\frac{1}{6n^{2(\theta -1)}}\quad \text{and} \quad P(X_n=0)=1-\frac{1}{3n^{2(\theta -1)}}.$$ If $1< \theta < \frac{3}{2}$ prove that the Lindeberg condition works works and the sequence satisfies the central limit theorem. THEOREM: Let be $\lambda >0$ , then $$\frac{1}{n^{\lambda +1}}\displaystyle\sum_{k=1}^{n} k^{\lambda}\underset{n\to +\infty}{\longrightarrow} \frac{1}{\lambda+1},$$ in such a way that $\displaystyle\sum_{k=1}^{n} k^{\lambda}$ has the order $\mathcal{O}= n^{\lambda + 1}$ . Solution of the question 1: $EX_n=0\; \forall n\in \mathbb{N}$ , $Var(X_n)=EX_n^2=n^{2\theta}$ and $\displaystyle\sum_{k=1}^{n} Var X_k = \displaystyle\sum_{k=1}^{n}k^{2\theta}$ is (by the theorem above) $\mathcal{O}(n^{2\theta +1})$ . Also $S_n=\left(\sum_{k=1}^{n}Var(X_k)\right)^{\frac{1}{2}}$ is (using the theorem above) $\mathcal{O}=\left(n^{(2\theta+1)/2}\right)$ . By the Lyapunov condition there exists $\delta >0$ , such that \begin{align*} \lim_{n\to +\infty} \frac{1}{s_n^{2+\delta}} \displaystyle\sum_{k=1}^{n} E|X_k|^{2+\delta} &=lim_{n\to +\infty} \frac{1}{2^{2+\delta}}\displaystyle\sum_{k=1}^{n} K^{(2+\delta)\theta}\\ 	&=\lim_{n\to +\infty} \frac{\mathcal{O}\left(n^{(2+\delta)\theta+1}\right)}{\mathcal{O}\left(n^{(2+\delta)(2\theta +1)/2}\right)}\\ 	&=\lim_{n\to +\infty} \frac{\mathcal{O}(n)}{\mathcal{O}(n^{(2+\delta)/2})}\\ 	&=0\quad \text{for}\; \delta=2 \end{align*} Thus, the Lyapunov condition is satisfied $\forall \alpha \in \mathbb{R}$ and $\delta =2$ . Therefore, $$\frac{\displaystyle\sum_{k=1}^{n} X_k - E\sum_{k=1}^{n} X_k}{\sqrt{\displaystyle\sum_{k=1}^{n}Var(X_k)}}\overset{D}{\longrightarrow} \mathcal{N}(0,1).$$ The convergence above means that converge in distribution to standard normal distribution $\mathcal{N}(0,1)$ . REMARK: Notice that the question 1 is already answered, however I'm strying to prove again without use the theorem above. Can you help me with this?","Question 1: Let be independent random variables such that If prove that the Lyapunov condition works and the sequence satisfies the central limit theorem. Question 2: Let be independent random variables such that If prove that the Lindeberg condition works works and the sequence satisfies the central limit theorem. THEOREM: Let be , then in such a way that has the order . Solution of the question 1: , and is (by the theorem above) . Also is (using the theorem above) . By the Lyapunov condition there exists , such that Thus, the Lyapunov condition is satisfied and . Therefore, The convergence above means that converge in distribution to standard normal distribution . REMARK: Notice that the question 1 is already answered, however I'm strying to prove again without use the theorem above. Can you help me with this?","X_1, X_2, \cdots P(X_n=-n^{\theta})=P(X_n=n^{\theta})=\frac{1}{2}. \theta > -\frac{1}{2} X_1, X_2, \cdots P(X_n=-n^{\theta})=P(X_n=n^{\theta})=\frac{1}{6n^{2(\theta -1)}}\quad \text{and} \quad P(X_n=0)=1-\frac{1}{3n^{2(\theta -1)}}. 1< \theta < \frac{3}{2} \lambda >0 \frac{1}{n^{\lambda +1}}\displaystyle\sum_{k=1}^{n} k^{\lambda}\underset{n\to +\infty}{\longrightarrow} \frac{1}{\lambda+1}, \displaystyle\sum_{k=1}^{n} k^{\lambda} \mathcal{O}= n^{\lambda + 1} EX_n=0\; \forall n\in \mathbb{N} Var(X_n)=EX_n^2=n^{2\theta} \displaystyle\sum_{k=1}^{n} Var X_k = \displaystyle\sum_{k=1}^{n}k^{2\theta} \mathcal{O}(n^{2\theta +1}) S_n=\left(\sum_{k=1}^{n}Var(X_k)\right)^{\frac{1}{2}} \mathcal{O}=\left(n^{(2\theta+1)/2}\right) \delta >0 \begin{align*}
\lim_{n\to +\infty} \frac{1}{s_n^{2+\delta}} \displaystyle\sum_{k=1}^{n} E|X_k|^{2+\delta} &=lim_{n\to +\infty} \frac{1}{2^{2+\delta}}\displaystyle\sum_{k=1}^{n} K^{(2+\delta)\theta}\\
	&=\lim_{n\to +\infty} \frac{\mathcal{O}\left(n^{(2+\delta)\theta+1}\right)}{\mathcal{O}\left(n^{(2+\delta)(2\theta +1)/2}\right)}\\
	&=\lim_{n\to +\infty} \frac{\mathcal{O}(n)}{\mathcal{O}(n^{(2+\delta)/2})}\\
	&=0\quad \text{for}\; \delta=2
\end{align*} \forall \alpha \in \mathbb{R} \delta =2 \frac{\displaystyle\sum_{k=1}^{n} X_k - E\sum_{k=1}^{n} X_k}{\sqrt{\displaystyle\sum_{k=1}^{n}Var(X_k)}}\overset{D}{\longrightarrow} \mathcal{N}(0,1). \mathcal{N}(0,1)","['probability', 'probability-theory']"
85,Finding best players in a tournament with a probabilistic comparison function,Finding best players in a tournament with a probabilistic comparison function,,"I am currently facing the following problem in my research and I have no clue how to tackle this kind of question. The problem Imagine you have a tournament with $n$ players $P=\{p_1,...,p_n\}$ . My goal is to determine one of the best players in my tournament. I do have a comparison function $f: P x P\to \{0,1\}$ that can tell me which of two given players is better, i.e. $f(p_1,p_2)=1$ iff player two is better than player one and $f(p_1,p_2)=0$ iff player one is better than player two. You can think of $f$ as the $<$ relation. The kicker is that my comparison function $f$ has an error, meaning that it will give me the correct result of my comparison with a probability $p>0.5$ . Calculating $f$ will take some time and thus I want to find a good player for my tournament with the least amount of queries. My current approach is to compare all players with each other which gives me a total amount of $b \in O(n^2)$ comparison calls. I then chose the player $p_i$ , which ""won"" the most comparisons. Edit: Please be aware that my comparison function will give me the same result for a call $f(p_i,p_j)$ no matter how often I call it. So the probability that the result is correct is $p$ , but the function itself is deterministic. My example below is a bit misleading. However, each comparison call is only done once so this won't be a problem. Key questions What is the probability that the chosen player is the best player? What is the probability that the chosen player is in the top k percent? My thoughts I think that question one might be easier to calculate as my best player will win all comparisons if $p=1$ and I can deduce the probability that $k$ comparisons were correct. However, I am stuck at the point at which I have to calculate the probability that it in fact is the player that ""won"" the most comparisons as others might be evaluated incorrectly. My dream is to get a formula that allows me to calculate the desired probabilities for different $p,n$ , and budget $b$ . Simulation I wrote a small simulation in Python which revealed some interesting facts about the influence of $p$ . In my example, the tournament players are represented as numbers $0,...,63$ . The function $f$ is the standard $<$ relation with a given probability. In the plot below I have plotted the mean position (y-axis) that was selected as the best individual for different $p$ (x-axis). You can find the source code below. import random import numpy as np from itertools import combinations from tqdm import tqdm import matplotlib.pyplot as plt  x, y = [], []  n = 64 # How many players nums = np.arange(n).tolist() # Player strengths count = 1000 # The amount of tests (O(n^2)) combinations that should be made  for p in tqdm(np.arange(0, 1, 0.01)):     x.append(p)      def compare(a, b):         r = random.random()         if r <= p:             return a < b         else:             return a >= b      def tournament():         scores = [0] * n         for a, b in combinations(nums, 2):             result = compare(a, b)             if result:                 scores[b] += 1             else:                 scores[a] += 1          best = max(nums, key=lambda x: scores[x])         return best      vals = []      for _ in range(count):         vals.append(tournament())      y.append(np.mean(vals))  plt.plot(x, y)  plt.show()","I am currently facing the following problem in my research and I have no clue how to tackle this kind of question. The problem Imagine you have a tournament with players . My goal is to determine one of the best players in my tournament. I do have a comparison function that can tell me which of two given players is better, i.e. iff player two is better than player one and iff player one is better than player two. You can think of as the relation. The kicker is that my comparison function has an error, meaning that it will give me the correct result of my comparison with a probability . Calculating will take some time and thus I want to find a good player for my tournament with the least amount of queries. My current approach is to compare all players with each other which gives me a total amount of comparison calls. I then chose the player , which ""won"" the most comparisons. Edit: Please be aware that my comparison function will give me the same result for a call no matter how often I call it. So the probability that the result is correct is , but the function itself is deterministic. My example below is a bit misleading. However, each comparison call is only done once so this won't be a problem. Key questions What is the probability that the chosen player is the best player? What is the probability that the chosen player is in the top k percent? My thoughts I think that question one might be easier to calculate as my best player will win all comparisons if and I can deduce the probability that comparisons were correct. However, I am stuck at the point at which I have to calculate the probability that it in fact is the player that ""won"" the most comparisons as others might be evaluated incorrectly. My dream is to get a formula that allows me to calculate the desired probabilities for different , and budget . Simulation I wrote a small simulation in Python which revealed some interesting facts about the influence of . In my example, the tournament players are represented as numbers . The function is the standard relation with a given probability. In the plot below I have plotted the mean position (y-axis) that was selected as the best individual for different (x-axis). You can find the source code below. import random import numpy as np from itertools import combinations from tqdm import tqdm import matplotlib.pyplot as plt  x, y = [], []  n = 64 # How many players nums = np.arange(n).tolist() # Player strengths count = 1000 # The amount of tests (O(n^2)) combinations that should be made  for p in tqdm(np.arange(0, 1, 0.01)):     x.append(p)      def compare(a, b):         r = random.random()         if r <= p:             return a < b         else:             return a >= b      def tournament():         scores = [0] * n         for a, b in combinations(nums, 2):             result = compare(a, b)             if result:                 scores[b] += 1             else:                 scores[a] += 1          best = max(nums, key=lambda x: scores[x])         return best      vals = []      for _ in range(count):         vals.append(tournament())      y.append(np.mean(vals))  plt.plot(x, y)  plt.show()","n P=\{p_1,...,p_n\} f: P x P\to \{0,1\} f(p_1,p_2)=1 f(p_1,p_2)=0 f < f p>0.5 f b \in O(n^2) p_i f(p_i,p_j) p p=1 k p,n b p 0,...,63 f < p","['probability', 'combinatorics', 'discrete-mathematics', 'stochastic-processes']"
86,$N$ kids with $k$ balls. Reshuffle. Find distribution of number of balls brought back by same kids when $N \rightarrow \infty$,kids with  balls. Reshuffle. Find distribution of number of balls brought back by same kids when,N k N \rightarrow \infty,"$N$ kids each brought $k$ balls to a party. When they leave each kid brings back $k$ balls randomly. Let $X$ be the total number of balls brought back by their original owners. We fix $k$ . Find the distribution of $X$ when $N \rightarrow \infty$ [EDIT, removed my earlier incorrect attempt] As the comment pointed out when $k=1$ it's a rather simple Poisson distribution. But how do we prove this case for arbitrary $k$ ?","kids each brought balls to a party. When they leave each kid brings back balls randomly. Let be the total number of balls brought back by their original owners. We fix . Find the distribution of when [EDIT, removed my earlier incorrect attempt] As the comment pointed out when it's a rather simple Poisson distribution. But how do we prove this case for arbitrary ?",N k k X k X N \rightarrow \infty k=1 k,"['probability', 'probability-theory', 'probability-distributions']"
87,Cans on a shelf,Cans on a shelf,,"6 cans are placed on a shelf in a circular arrangement. After tidying and cleaning the kitchen, the cans are placed again in new, random positions around a circle. What is the probability that none of the cans are in their initial positions or their adjacent? Isn't it $(\frac{3}{6})^6$ ?","6 cans are placed on a shelf in a circular arrangement. After tidying and cleaning the kitchen, the cans are placed again in new, random positions around a circle. What is the probability that none of the cans are in their initial positions or their adjacent? Isn't it ?",(\frac{3}{6})^6,['probability']
88,"If $X$ and $Y$ are independent random variables, with $Z = \min(X,Y),$ prove that $Z^2\sim\chi^2(1),$","If  and  are independent random variables, with  prove that","X Y Z = \min(X,Y), Z^2\sim\chi^2(1),","Let $X \sim N (0, 1)$ and $Y ∼ N (0, 1)$ be two independent random variables, and define $Z = \min(X, Y )$ . Prove that $Z^2\sim\chi^2(1),$ i.e. Chi-Squared with degree of freedom $1.$ I found the density functions of $X$ and $Y,$ as they are normally distributed. How would one use the fact that $Z = \min(X,Y)$ to answer the question? Thanks!","Let and be two independent random variables, and define . Prove that i.e. Chi-Squared with degree of freedom I found the density functions of and as they are normally distributed. How would one use the fact that to answer the question? Thanks!","X \sim N (0, 1) Y ∼ N (0, 1) Z = \min(X, Y ) Z^2\sim\chi^2(1), 1. X Y, Z = \min(X,Y)","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
89,Probability that the difference of the max and min of three random numbers between 0 and 2 is less than 1/4?,Probability that the difference of the max and min of three random numbers between 0 and 2 is less than 1/4?,,Three numbers are chosen at random between 0 and 2. What is the probability that the difference between the largest number and the least number is less than 1/4? This is a problem from JHMT Calculus 2011. I'm trying to see if there are any better solutions than the one provided. Here is the solution provided:,Three numbers are chosen at random between 0 and 2. What is the probability that the difference between the largest number and the least number is less than 1/4? This is a problem from JHMT Calculus 2011. I'm trying to see if there are any better solutions than the one provided. Here is the solution provided:,,[]
90,The probability of an ant rarely visiting the points with both coordinates even,The probability of an ant rarely visiting the points with both coordinates even,,"A point of the lattice $\mathbb{Z}^3$ in $\mathbb{R}^3$ is painted white if at least one of its coordinates is odd. An ant is moving in $\mathbb{R}^3$. At each integer time $t$ the ant is at a point in $\mathbb{Z}^3$ and it chooses one of points in $\mathbb{Z}^3$ at distance $1$ with uniform probability, and it moves there before time $t + 1$. For an integer $n$, denote by $P_n$ the probability that among the previous $n$ integer times the ant was at least $90\%$ of the time at a white point. Prove that $P_n$ decreases exponentially with $n$. Can you compute the rate?","A point of the lattice $\mathbb{Z}^3$ in $\mathbb{R}^3$ is painted white if at least one of its coordinates is odd. An ant is moving in $\mathbb{R}^3$. At each integer time $t$ the ant is at a point in $\mathbb{Z}^3$ and it chooses one of points in $\mathbb{Z}^3$ at distance $1$ with uniform probability, and it moves there before time $t + 1$. For an integer $n$, denote by $P_n$ the probability that among the previous $n$ integer times the ant was at least $90\%$ of the time at a white point. Prove that $P_n$ decreases exponentially with $n$. Can you compute the rate?",,"['probability', 'stochastic-processes', 'markov-chains', 'random-walk']"
91,Dynamic voting quorum,Dynamic voting quorum,,"Problem: Suppose that a committee with $n$ members needs to vote on whether to accept a proposition. Each member in the committee can cast a yes/no vote ($q_i\in\{1,0\}$ for $i\in \{1,2,...,n \}$), and each member's vote has a  different weight ($w_i\in[0,1]$ for $i\in \{1,2,...,n \}$). The committee rules stipulate that the proposition is to be accepted if the weighted average of votes is more than 50%, namely, if $$\bar{q}(n)=\sum_{i=1}^{n} w_i q_i>0.5$$ Suppose that (i) voting is sequential, (ii) each vote is a random draw from a Bernoulli distribution with unknown mean $p$, and (iii) the order of voting is independent of voting weights. I would like to define a 'dynamic quorum rule', such that a decision (accept vs reject) is made with only a subset of the committee's votes (e.g. the first $k$ votes),  and yet be statistically confident that the decision made is the same as the one that would have been made if all members had voted. What I currently have: This problem is very similar to one that I posted earlier . The only difference is that I am now interested in a weighted solution. That means that for $w_i=w$, the bayesian solution proposed in the related question also applies here.","Problem: Suppose that a committee with $n$ members needs to vote on whether to accept a proposition. Each member in the committee can cast a yes/no vote ($q_i\in\{1,0\}$ for $i\in \{1,2,...,n \}$), and each member's vote has a  different weight ($w_i\in[0,1]$ for $i\in \{1,2,...,n \}$). The committee rules stipulate that the proposition is to be accepted if the weighted average of votes is more than 50%, namely, if $$\bar{q}(n)=\sum_{i=1}^{n} w_i q_i>0.5$$ Suppose that (i) voting is sequential, (ii) each vote is a random draw from a Bernoulli distribution with unknown mean $p$, and (iii) the order of voting is independent of voting weights. I would like to define a 'dynamic quorum rule', such that a decision (accept vs reject) is made with only a subset of the committee's votes (e.g. the first $k$ votes),  and yet be statistically confident that the decision made is the same as the one that would have been made if all members had voted. What I currently have: This problem is very similar to one that I posted earlier . The only difference is that I am now interested in a weighted solution. That means that for $w_i=w$, the bayesian solution proposed in the related question also applies here.",,"['probability', 'statistics', 'stochastic-processes', 'bayesian']"
92,Interesting shapes using probability and discrete view of a problem,Interesting shapes using probability and discrete view of a problem,,"Suppose we have a circle of radius $r$, we show the distance between a point and the center of the circle by $d$. We then choose each point inside the circle with probability $\frac{d}{r}$ , and turn it black (note that $\frac{d}{r}<1$). With these rules we get shapes like this: (With help of Java) The shapes made were pretty interesting to me. I decided to add a few lines of code to my program to keep count of the drawn points, and then divide them by the area of the circle, to see what percentage of the circle is full. All I got for multiple number of tests was a number getting close to $2/3$ as the circle got bigger. Problem A : Almost what percentage of the circle is black? I found an answer as following: As all the points with distance $l$ from the center lie on a circle of radius $l$ and the same center, to find the ""probable"" number of black points, we shall consider all circles with radius $l$ ($0<l<r$). Consider one of these circles with radius $l$. the circumference of that circle is $2\pi l$ and by how we choose black points, almost $\frac{l}{r}*2\pi l=\frac{2\pi l^2}{r}$ of that circle is black. Taking the sum of all these circles means integrating the circumferences of these circles from $l=0$ to $r$. So: $$\int_0^r{\frac{2\pi l^2}{r}dl}=\frac{2\pi r^2}{3}$$ and so the percentage of all black points shall be $$\frac{\frac{2\pi r^2}{3}}{\pi r^2}=\frac{2}{3}$$. The other question that came up in my mind is: Problem B : For given number $x\geq 1$, what is the probability $P$ that $1/x$ of the circle is black? I think the answer is $P=0$ for any given $x$. We can say if there exists an area $A>0$ full of black points, there exists an infinite number of points so that their distance to the center of the circle is equal, and the probability of all of them being black is $0$ (because there is an infinite number of them, $d$ and $r$ are constant, $\frac{d}{r}<1$ and $\lim_{n\to\infty}{(\frac{d}{r})}^n=0$). It gets more interesting with a discrete view of the problem. Suppose we have a grid full of $1*1$ squares with the size $(2r+1)*(2r+1)$.We define the reference square with length $2l+1$ (we call $l$ it's radius ) as the set of squares ""around"" the reference square with length $2l-1$, and the reference square with length $1$ is the set of $8$ squares around the central square. We define the distance $d$ of a square from the central square by the radius of it's reference square. Now we are ready to propose a problem similar to problem A: Problem C : Suppose each square with distance $d$ to the central square turns black with a probability $\frac{d}{r}$. Prove that Almost $2/3$ of the squares turn black, as $r\to \infty$ We begin our proof by proving a reference square of radius $l$ contains exactly $8l$ squares. This is easy because there are $(2l+1)^2-(2l-1)^2=8l$ squares in a reference square with radius $l$. Now, each square in the reference square is black with probability $\frac{l}{r}$, so almost $\frac{l}{r}*8l=\frac{8l^2}{r}$ of the reference square is black (Similar to the proof of Problem A). By summing up all the reference squares with radius $l=1$ to $r$ we get: $$\sum_{l=1}^{r} \frac{8l^2}{r} = \frac{8}{r}*\frac{(r)(r+1)(2r+1)}{6}=\frac{4(r+1)(2r+1)}{3}$$ and so the percentage of the whole square that is black (as $r$ tends to infinity) is:$$\lim_{r\to\infty} \frac{\frac{4(r+1)(2r+1)}{3}}{(2r+1)^2}=\frac{4(r+1)}{3(2r+1)}=\frac{2}{3}$$ as expected. Some problems, though, still remain. First , I would appreciate the verification of my solutions to problems A, B and C. The program I wrote in java only fills out a finite number of ""pixels"", does this represent Problem A or Problem C? would there be a difference if we draw the circle for infinite number of ""points""? Second ,The result of Problem B seems a little strange because as $X$ tends to $\frac{3}{2}$, $P$ should go to $1$ because $\frac{2}{3}$ of the circle is black (as proved in Problem A).  Then Why do we get $P=0$ for all values of $X$? How can we explain this? Third, What is the connection between the discrete view of the problem and the main problem? Can someone generalize the proof of Problem C to prove Problem A? I think one can easily generalize Problem C to ""circles"" full of tiny squares and prove the fact similarly, but going to an infinite number of points instead of ""pixels"" (which are equivalent to tiny squares in problem C) is still another matter. I would appreciate any help.","Suppose we have a circle of radius $r$, we show the distance between a point and the center of the circle by $d$. We then choose each point inside the circle with probability $\frac{d}{r}$ , and turn it black (note that $\frac{d}{r}<1$). With these rules we get shapes like this: (With help of Java) The shapes made were pretty interesting to me. I decided to add a few lines of code to my program to keep count of the drawn points, and then divide them by the area of the circle, to see what percentage of the circle is full. All I got for multiple number of tests was a number getting close to $2/3$ as the circle got bigger. Problem A : Almost what percentage of the circle is black? I found an answer as following: As all the points with distance $l$ from the center lie on a circle of radius $l$ and the same center, to find the ""probable"" number of black points, we shall consider all circles with radius $l$ ($0<l<r$). Consider one of these circles with radius $l$. the circumference of that circle is $2\pi l$ and by how we choose black points, almost $\frac{l}{r}*2\pi l=\frac{2\pi l^2}{r}$ of that circle is black. Taking the sum of all these circles means integrating the circumferences of these circles from $l=0$ to $r$. So: $$\int_0^r{\frac{2\pi l^2}{r}dl}=\frac{2\pi r^2}{3}$$ and so the percentage of all black points shall be $$\frac{\frac{2\pi r^2}{3}}{\pi r^2}=\frac{2}{3}$$. The other question that came up in my mind is: Problem B : For given number $x\geq 1$, what is the probability $P$ that $1/x$ of the circle is black? I think the answer is $P=0$ for any given $x$. We can say if there exists an area $A>0$ full of black points, there exists an infinite number of points so that their distance to the center of the circle is equal, and the probability of all of them being black is $0$ (because there is an infinite number of them, $d$ and $r$ are constant, $\frac{d}{r}<1$ and $\lim_{n\to\infty}{(\frac{d}{r})}^n=0$). It gets more interesting with a discrete view of the problem. Suppose we have a grid full of $1*1$ squares with the size $(2r+1)*(2r+1)$.We define the reference square with length $2l+1$ (we call $l$ it's radius ) as the set of squares ""around"" the reference square with length $2l-1$, and the reference square with length $1$ is the set of $8$ squares around the central square. We define the distance $d$ of a square from the central square by the radius of it's reference square. Now we are ready to propose a problem similar to problem A: Problem C : Suppose each square with distance $d$ to the central square turns black with a probability $\frac{d}{r}$. Prove that Almost $2/3$ of the squares turn black, as $r\to \infty$ We begin our proof by proving a reference square of radius $l$ contains exactly $8l$ squares. This is easy because there are $(2l+1)^2-(2l-1)^2=8l$ squares in a reference square with radius $l$. Now, each square in the reference square is black with probability $\frac{l}{r}$, so almost $\frac{l}{r}*8l=\frac{8l^2}{r}$ of the reference square is black (Similar to the proof of Problem A). By summing up all the reference squares with radius $l=1$ to $r$ we get: $$\sum_{l=1}^{r} \frac{8l^2}{r} = \frac{8}{r}*\frac{(r)(r+1)(2r+1)}{6}=\frac{4(r+1)(2r+1)}{3}$$ and so the percentage of the whole square that is black (as $r$ tends to infinity) is:$$\lim_{r\to\infty} \frac{\frac{4(r+1)(2r+1)}{3}}{(2r+1)^2}=\frac{4(r+1)}{3(2r+1)}=\frac{2}{3}$$ as expected. Some problems, though, still remain. First , I would appreciate the verification of my solutions to problems A, B and C. The program I wrote in java only fills out a finite number of ""pixels"", does this represent Problem A or Problem C? would there be a difference if we draw the circle for infinite number of ""points""? Second ,The result of Problem B seems a little strange because as $X$ tends to $\frac{3}{2}$, $P$ should go to $1$ because $\frac{2}{3}$ of the circle is black (as proved in Problem A).  Then Why do we get $P=0$ for all values of $X$? How can we explain this? Third, What is the connection between the discrete view of the problem and the main problem? Can someone generalize the proof of Problem C to prove Problem A? I think one can easily generalize Problem C to ""circles"" full of tiny squares and prove the fact similarly, but going to an infinite number of points instead of ""pixels"" (which are equivalent to tiny squares in problem C) is still another matter. I would appreciate any help.",,"['probability', 'discrete-mathematics', 'differential-geometry', 'definite-integrals', 'recreational-mathematics']"
93,Expected Value of the Maximum Number of Heads in n Flips,Expected Value of the Maximum Number of Heads in n Flips,,"How would one go about finding the expected value of the maximum number of consecutive heads when flipping a coin $n$ times? For small $n$, it seems easy to brute-force it (i.e. when $n = 3$, the sample space is $\{HHH, HHT, HTH, HTT, TTT, TTH,THT,THH\}$ and so the maximum number of consecutive heads is $\{3,2,1,1,0,1,1,2\}$ so the expected value of the number of maximum consecutive heads should be $11/8$). However, for $n>5$, it becomes pretty hard to brute force this. For a research project, I am really wondering how the solution to this problem behaves for $ 50 \leq n \leq 100 $. In other words, if I flip $50$ coins, what is the maximum run length of heads that should be expected? Any advice on how to solve this problem for either the $n$ in the above bound, or for $n$ in general?","How would one go about finding the expected value of the maximum number of consecutive heads when flipping a coin $n$ times? For small $n$, it seems easy to brute-force it (i.e. when $n = 3$, the sample space is $\{HHH, HHT, HTH, HTT, TTT, TTH,THT,THH\}$ and so the maximum number of consecutive heads is $\{3,2,1,1,0,1,1,2\}$ so the expected value of the number of maximum consecutive heads should be $11/8$). However, for $n>5$, it becomes pretty hard to brute force this. For a research project, I am really wondering how the solution to this problem behaves for $ 50 \leq n \leq 100 $. In other words, if I flip $50$ coins, what is the maximum run length of heads that should be expected? Any advice on how to solve this problem for either the $n$ in the above bound, or for $n$ in general?",,"['probability', 'combinatorics', 'expectation']"
94,How far do I need to drive to find an empty parking spot?,How far do I need to drive to find an empty parking spot?,,"A parking lot consists of an infinite row of bays.  Cars arrive at random intervals (mean interval $T_a$) and stay for a random time (mean stay $T_s$).  The time intervals are memoryless (negative exponential distribution).  An arriving car parks in bay $n$, which is the first available bay.  What is the distribution of $n$? The question is motivated by the following annoyance: why is it that, when I meet someone at the airport, I always end up driving to the far end of the lot? Here is a bit more information, based on simulation.  The ratio of the times, rather than their actual values, determines the behaviour.  Thus we can write $k=T_s/T_a$ and use $k$ as the single parameter.  If $k=1$, the parking lot can be small (two bays are usually enough), and the distribution is interesting only for large values of $k$.  E.g., cars arrive every $2$ minutes and stay for $2$ hours. The first bay is the one most likely to be free (!).  However, for large $k$, the distribution is almost flat, falling off rapidly after $k$ bays and therefore having a mean of $k/2$.  In fact, I conjecture that $\mu \rightarrow k/2$ as $k \rightarrow \infty$. Thanks, Peter.","A parking lot consists of an infinite row of bays.  Cars arrive at random intervals (mean interval $T_a$) and stay for a random time (mean stay $T_s$).  The time intervals are memoryless (negative exponential distribution).  An arriving car parks in bay $n$, which is the first available bay.  What is the distribution of $n$? The question is motivated by the following annoyance: why is it that, when I meet someone at the airport, I always end up driving to the far end of the lot? Here is a bit more information, based on simulation.  The ratio of the times, rather than their actual values, determines the behaviour.  Thus we can write $k=T_s/T_a$ and use $k$ as the single parameter.  If $k=1$, the parking lot can be small (two bays are usually enough), and the distribution is interesting only for large values of $k$.  E.g., cars arrive every $2$ minutes and stay for $2$ hours. The first bay is the one most likely to be free (!).  However, for large $k$, the distribution is almost flat, falling off rapidly after $k$ bays and therefore having a mean of $k/2$.  In fact, I conjecture that $\mu \rightarrow k/2$ as $k \rightarrow \infty$. Thanks, Peter.",,"['probability', 'statistics']"
95,Probability to starve,Probability to starve,,"First of all, I'm sorry if I'll use some game related terms, but that's where the question that bugged me for the last week came from. Let's say, we have a mana pool of size $M$, and we can cast a spell that costs $n$, with $n < M$. The spell has a  probability $p$ to give us $kM$ mana, where both $p$ and $k$ are fixed constants in the interval $[0,1]$. What is the probability to get mana starved, that means, to end up without enough mana to cast any more instances of our spell after $t$ casts? edit : as a first ( and simpler ) case, we can assume $M = qn$ with $q \in N , q > 1$ and $kM = pn , p < q$ .","First of all, I'm sorry if I'll use some game related terms, but that's where the question that bugged me for the last week came from. Let's say, we have a mana pool of size $M$, and we can cast a spell that costs $n$, with $n < M$. The spell has a  probability $p$ to give us $kM$ mana, where both $p$ and $k$ are fixed constants in the interval $[0,1]$. What is the probability to get mana starved, that means, to end up without enough mana to cast any more instances of our spell after $t$ casts? edit : as a first ( and simpler ) case, we can assume $M = qn$ with $q \in N , q > 1$ and $kM = pn , p < q$ .",,['probability']
96,Conditional probability is undefined even though it seems defined intuitively,Conditional probability is undefined even though it seems defined intuitively,,"We know that conditional probability $P(A | B)$ is undefined when $P(B) = 0$. But this doesn't seem to be true to me always. Consider the probability of chosing a real number between $r$ such that $0 \leq r \lt 1$ where any real number in $[0, 1)$ is equally likely to be chosen. Thus, the sample space $S = [0, 1)$. Let $A = \{0.1\}$ and $B = \{0.1, 0.2\}$. Therefore, $P(A) = P(B) = 0$. Now, speaking from intuition, if we are given that $r$ is either $0.1$ or $0.2$, one might conclude that the probability that $r = 0.1$ is $0.5$. Therefore, it seems like $P(A | B) = 0.5$. But this contradicts the fact that since $P(B) = 0$, $P(A|B)$ is undefined. Where am I making a mistake?","We know that conditional probability $P(A | B)$ is undefined when $P(B) = 0$. But this doesn't seem to be true to me always. Consider the probability of chosing a real number between $r$ such that $0 \leq r \lt 1$ where any real number in $[0, 1)$ is equally likely to be chosen. Thus, the sample space $S = [0, 1)$. Let $A = \{0.1\}$ and $B = \{0.1, 0.2\}$. Therefore, $P(A) = P(B) = 0$. Now, speaking from intuition, if we are given that $r$ is either $0.1$ or $0.2$, one might conclude that the probability that $r = 0.1$ is $0.5$. Therefore, it seems like $P(A | B) = 0.5$. But this contradicts the fact that since $P(B) = 0$, $P(A|B)$ is undefined. Where am I making a mistake?",,['probability']
97,"First player to win k matches of series of n, win probability p = 0.5","First player to win k matches of series of n, win probability p = 0.5",,"A series of matches are held between n identical competitors. Each is won by one of the n with equal probability (no ties). I'm looking for a probabilistic description of the outcome when looking at the first player to win 1, 2, ... matches. For example, if player #3 is the first player to win 400 matches, she has a better than 1/n chance to be the first player to win 401 matches. In particular: how many matches need to be played before some player wins k ? (The dominant term is of course kn but what is the next (negative) term?) How often does the lead change places? (I expect infinitely often, but with decreasing frequency... maybe sqrt-ly many times?) I have a decent math background but have not studied any probability since a basic undergrad class. Related question: How long until everyone is in the lead?","A series of matches are held between n identical competitors. Each is won by one of the n with equal probability (no ties). I'm looking for a probabilistic description of the outcome when looking at the first player to win 1, 2, ... matches. For example, if player #3 is the first player to win 400 matches, she has a better than 1/n chance to be the first player to win 401 matches. In particular: how many matches need to be played before some player wins k ? (The dominant term is of course kn but what is the next (negative) term?) How often does the lead change places? (I expect infinitely often, but with decreasing frequency... maybe sqrt-ly many times?) I have a decent math background but have not studied any probability since a basic undergrad class. Related question: How long until everyone is in the lead?",,"['probability', 'random-walk']"
98,Tail bound on the sum of independent (non-identical) geometric random variables,Tail bound on the sum of independent (non-identical) geometric random variables,,"Suppose $X_1, \ldots , X_k$ are $k$ independent geometric random variables with success probability $p_1, \ldots, p_k$ and let $X = X_1 + \cdots + X_k$. The expected number of trials needed is  $$ \mathbb E[X] = \frac{1}{p_1} + \cdots + \frac{1}{p_k} \> . $$ Claim :  It should be true that there is a constant $c>0$ (independent of $k$ and the success probabilities $p_i$) such that for any $t>0$ we have  $$ \mathbb P[X > c (\mathbb E[X] + t)] < (1 - p_\min)^t \>, $$ where $p_\min = \min_i p_i$. I would be very thankful for any help in proving this. Note that if $p_1 = \cdots = p_k = p$ then $X$ is a negative binomial random variable. In this case, one can prove the claim with $c=16$ via a standard Chernoff bound: The expected number of successes after $16(\frac{k}{p}+t)$ trials is $16(k+tp)$ and, by the Chernoff bound, the probability that there are less than $k<\frac{1}{2}E[X]$ successes is at most $e^{-16(k+tp)/8}$ which is less than $e^{-2tp} < (1 - p)^t$.","Suppose $X_1, \ldots , X_k$ are $k$ independent geometric random variables with success probability $p_1, \ldots, p_k$ and let $X = X_1 + \cdots + X_k$. The expected number of trials needed is  $$ \mathbb E[X] = \frac{1}{p_1} + \cdots + \frac{1}{p_k} \> . $$ Claim :  It should be true that there is a constant $c>0$ (independent of $k$ and the success probabilities $p_i$) such that for any $t>0$ we have  $$ \mathbb P[X > c (\mathbb E[X] + t)] < (1 - p_\min)^t \>, $$ where $p_\min = \min_i p_i$. I would be very thankful for any help in proving this. Note that if $p_1 = \cdots = p_k = p$ then $X$ is a negative binomial random variable. In this case, one can prove the claim with $c=16$ via a standard Chernoff bound: The expected number of successes after $16(\frac{k}{p}+t)$ trials is $16(k+tp)$ and, by the Chernoff bound, the probability that there are less than $k<\frac{1}{2}E[X]$ successes is at most $e^{-16(k+tp)/8}$ which is less than $e^{-2tp} < (1 - p)^t$.",,"['probability', 'stochastic-processes', 'probability-distributions']"
99,"A fair 6-sided die is thrown 10 times. What is the probability of rolling a six three times in a row, and the other rolls not being a 6?","A fair 6-sided die is thrown 10 times. What is the probability of rolling a six three times in a row, and the other rolls not being a 6?",,"In 10 rolls, there are 8 positions where the chain of three can start, so there are 8 permutations since dice rolls are interchangeable (their order doesn't matter). Therefore, I believe that the answer should be $8\times \left(\frac 16\right)^3\times \left(\frac 56\right)^7$ . However, I am not $100\%$ sure. Any confirmation is appreciated.","In 10 rolls, there are 8 positions where the chain of three can start, so there are 8 permutations since dice rolls are interchangeable (their order doesn't matter). Therefore, I believe that the answer should be . However, I am not sure. Any confirmation is appreciated.",8\times \left(\frac 16\right)^3\times \left(\frac 56\right)^7 100\%,"['probability', 'binomial-theorem']"
