,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is there a notion of a continuous basis of a Banach space?,Is there a notion of a continuous basis of a Banach space?,,"If $X$ is a Banach space, then a Hamel basis of $X$ is a subset $B$ of $X$ such that every element of $X$ can be written uniquely as a linear combination of elements of $B$ .  And a Schauder basis of $X$ is a subset $B$ of $X$ such that every element of $X$ can be written uniquely as an infinite linear combination of elements of $B$ . But my question is, is there a notion of a “continuous basis” of a Banach space?  That is, a subset $B$ of $X$ such that every element of $X$ can be written uniquely in terms of some kind of integral involving elements of $B$ . I’m not sure what the integral should look like, but one possibility is this.  We define some function $f:\mathbb{R}\rightarrow X$ , and we let $B$ be the range of $f$ . And then for any $x\in X$ , there exists a unique function $g:\mathbb{R}\rightarrow\mathbb{R}$ such that $x = \int_{-\infty}^\infty g(t)f(t)dt$ , where this is a Bochner integral .  And if that’s the case we say that $B$ is a continuous basis for $X$ .  Does any of this make sense? EDIT:  I've realized that my question is related to a whole bunch of other topics, including Fourier transforms , Rigged Hilbert Spaces , and Spectral Theory .  See this answer , this answer , this question , this question , and this question .","If is a Banach space, then a Hamel basis of is a subset of such that every element of can be written uniquely as a linear combination of elements of .  And a Schauder basis of is a subset of such that every element of can be written uniquely as an infinite linear combination of elements of . But my question is, is there a notion of a “continuous basis” of a Banach space?  That is, a subset of such that every element of can be written uniquely in terms of some kind of integral involving elements of . I’m not sure what the integral should look like, but one possibility is this.  We define some function , and we let be the range of . And then for any , there exists a unique function such that , where this is a Bochner integral .  And if that’s the case we say that is a continuous basis for .  Does any of this make sense? EDIT:  I've realized that my question is related to a whole bunch of other topics, including Fourier transforms , Rigged Hilbert Spaces , and Spectral Theory .  See this answer , this answer , this question , this question , and this question .",X X B X X B X B X X B B X X B f:\mathbb{R}\rightarrow X B f x\in X g:\mathbb{R}\rightarrow\mathbb{R} x = \int_{-\infty}^\infty g(t)f(t)dt B X,"['functional-analysis', 'banach-spaces', 'distribution-theory', 'bochner-spaces', 'schauder-basis']"
1,Simple proof that Fourier transform is an isomorphism between $L^p$ spaces for $p \neq 2$?,Simple proof that Fourier transform is an isomorphism between  spaces for ?,L^p p \neq 2,"It is known that the Fourier transform $\mathcal F$ maps $L^2 \to L^2$ as an (isometric) isomorphism and $L^1 \to L^\infty$ as bounded operator. Via Riesz-Thorin this result can be extended to give that $\mathcal F$ also maps $L^p \to L^{p'}$ where $1 = \frac{1}{p} + \frac{1}{p'}$ as a bounded operator, i.e. the Hausdorff-Young equality holds: $$ \|\mathcal F(u) \|_{p'} \leq \|u\|_p $$ for all $u \in L^p(\mathbb{R}^n)$, $p \in (1,2)$. How do we know that the Fourier transform is only an isomorphism from $L^2 \to L^2$? One could argue that no $L^p$ space is isomorphic to an $L^q$ space for $p \neq q$ using the invariants type and cotype as suggested here but, considering that I only want to show that $\mathcal F$ is not an isomorphism from $L^p \to L^{p'}$, I suppose there is a more simple approach directly related to the Fourier transform . I am thinking of showing the fourier transform from $L^p \to L^{p'}$ is simply not surjective. Can you think of an easier approach to this problem?","It is known that the Fourier transform $\mathcal F$ maps $L^2 \to L^2$ as an (isometric) isomorphism and $L^1 \to L^\infty$ as bounded operator. Via Riesz-Thorin this result can be extended to give that $\mathcal F$ also maps $L^p \to L^{p'}$ where $1 = \frac{1}{p} + \frac{1}{p'}$ as a bounded operator, i.e. the Hausdorff-Young equality holds: $$ \|\mathcal F(u) \|_{p'} \leq \|u\|_p $$ for all $u \in L^p(\mathbb{R}^n)$, $p \in (1,2)$. How do we know that the Fourier transform is only an isomorphism from $L^2 \to L^2$? One could argue that no $L^p$ space is isomorphic to an $L^q$ space for $p \neq q$ using the invariants type and cotype as suggested here but, considering that I only want to show that $\mathcal F$ is not an isomorphism from $L^p \to L^{p'}$, I suppose there is a more simple approach directly related to the Fourier transform . I am thinking of showing the fourier transform from $L^p \to L^{p'}$ is simply not surjective. Can you think of an easier approach to this problem?",,"['functional-analysis', 'fourier-analysis', 'fourier-transform', 'harmonic-analysis', 'vector-space-isomorphism']"
2,Extension of PDE's to critical strip,Extension of PDE's to critical strip,,"Introduction: In statistics, distributions in the exponential family are very natural to consider. One famous example is the Gaussian. It shows up in the heat equation, in probability theory, and in many other fields. While the Gaussian may be most important due to the central limit theorem, distributions in the exponential family have properties that may be connected to the properties of the Gaussian itself.  So, consider the exponential family, the close cousin of the Gaussian, $f_s(x)=e^{sT(x)}$ for parameter $s$ and sufficient statistic $T(x)=\frac{1}{\log x}.$ Relating $f_s(x)$ to the Riemann zeta function: Viewing $f_s(x)$ geometrically: The function $f_s(x)$ is a particular solution to a linear parabolic diffusion equation (use an exponential ansatz): $$s \frac{\partial ^2f(s,x)}{\partial s^2}=-x \frac{\partial f(s,x)}{\partial x} \tag{2}$$ and the Mellin transform can be used to transform that equation to (transform the solution $f_s(x)$ and use a CAS to verify): $$r^2 \frac{\partial ^3\Psi(r,s)}{\partial r^3}=s^2 \frac{\partial \Psi(r,s)}{\partial s} \tag{3}$$ where a particular solution Bessel function, $K_1$ appears: $$\Psi(r,s)=2 \sqrt{\frac{r}{s}}K_1(2\sqrt{r s})$$ We recover a connection with the Riemann zeta function and the Gamma function: $$\frac{1}{\Gamma(w-1)\Gamma(w)}\int_0^\infty \sum_{r \in \Bbb N} \Psi(r,s) s^{w-1}~ds=\zeta(w-1) \tag{1}$$ convergent for $\Re(w)>2.$ We can recover the symmetric functional equation about the critical strip $\xi(s)=\xi(1-s)$ through this integral relationship and analytic continuation, although it is calculation intensive. A more fundamental approach: Another, perhaps more fundamental, way to obtain the symmetric functional equation is to start with any Schwartz function. Usually the self dual Gaussian is used to obtain the Gamma factor $\Gamma(s/2)\pi^{-s/2}.$ Here I ask for a closed form for the Gamma factor associated to the Schwartz class $f_s(x):$ Obtaining the correct Gamma factor for this Schwartz function . We are looking for a functional equation of this form: $$\Gamma(f,r,s)\cdot \zeta(s) \;=\; \Gamma(\hat{f},r,1-s)\cdot \zeta(1-s)\tag{4}$$ Here, $\Gamma$ is the Gamma factor and $\hat f$ denotes the Fourier transform. Note however, that the fundamental domain of $f$ is $(0,1)$ so the Fourier transform will act on this bounded domain. Here I will show the calculation of $\Gamma(f,r,s):$ $$\Gamma(f,r,s)=\int_{\mathbb R^\times \cap ~(0,1)} |x|^r~f_s(x)~{dx\over |x|}=2 \sqrt{\frac{r}{s}}K_1(2\sqrt{r s})$$ for modified Bessel function of the second kind $K_1.$ Informal discussion and remarks: In terms of geometric analysis $\Psi(r,s)$ has an interpretation as a $1$ -parameter family of Riemannian metrics which can be shown using the Fisher methodology and information geometry, and this is how I initially started thinking about $\Psi(r,s)$ . I initially thought of it as a Fisher metric. With this linear geometric flow we have essentially summed discrete pieces of the metric, over a spectrum, in this case the natural numbers, and then taken the Mellin transform to recover the zeta function. That is to say, $f_s(x)$ seems to be ""weakly"" tied to the Riemann zeta function. If you start with $f_s(x)$ and pretend that you can take two Mellin transforms in a row and sum over the natural numbers you recover the Riemann zeta i.e. formula $(1).$ Of course it doesn't make sense to take iterative Mellin transforms like this. But already, you can see that $f_s(x)$ is deeply linked to $\zeta(s)$ . And this really isn't that surprising, given the modern viewpoint of things as in Iwasawa-Tate theory. Now I claimed above, that $f_s(x)$ was Schwartz $\forall s >0.$ You may be very skeptical about this and rightfully so. This is a delicate situation and I'll explain why. The Schwartz space is classically defined for functions on the real line and so there must be some functional analysis work done to show that $f_s(x)$ can legitimately be thought of as a kind of Schwartz function. I believe things will work out just fine, under the appropriate modifications, but I personally do not know enough functional analysis to tie everything up neatly here. Question: At this point I'd like to state my question. As the title says I am looking to extend the two PDE's $(2)$ and $(3)$ to the critical strip as defined through $(4).$ How do you extend $(2)$ and $(3)$ to the critical strip as defined by $(4)?$ Explorations of the literature: Here are some other attempts of mine to educate myself on the approaches that have already been developed. Most relevant I think is the de Bruijn constant: I've read Tao's article about freezing and vaporizing the Riemann zeta function. Also see de Bruijn constant . Here is Tao's presentation: https://terrytao.files.wordpress.com/2018/08/webinar.pdf . This seems related since $f_s(x)$ obeys a strange kind of ""backwards heat equation"" $$s \frac{\partial ^2f(s,x)}{\partial s^2}=-x \frac{\partial f(s,x)}{\partial x}$$ I do know that the Mellin transform by definition maps some function $\psi : (0,\infty) \to \mathbb{C}$ with $\mathcal{M}(\psi)(s) = \int_{0}^{\infty} \psi(x) x^s  \frac{dx}{x}$ that's absolutely convergent on the vertical strip $\lbrace s \in \mathbb{C} : a < \Re(s) < b \rbrace$ . So it seems to me that this sum of the metric over a particular spectrum of the naturals, is being converted from a real $s$ to a complex $w$ through the Mellin transform. So, I guess that's where I'm stuck. I don't know how to connect that complex object to the $1$ -parameter family of real metrics. It seems closely related to this too: https://mathoverflow.net/q/139863/123449 , but I don't know if the argument applies since the operator of my PDE is not a second order p.d.o. (it's third order) among other things. I mean I guess it could be reduced to second order through a Fourier transform but I don't know how to proceed exactly. Final remarks: $(A).~f_s(x)$ is a $1$ -parameter class, and therefore we should have a varying, or $1$ -parameter class of functional equations. $(B).~$ The Gamma factor is also a $1$ -parameter class. $(C).~$ I think there is a way to unify $(A)$ and $(B)$ on the critical strip, using existing mathematical methods. $(D).~$ Any argument showing that $f_s(x)$ cannot be used to obtain $(4)$ would also answer this question, essentially providing a counterexample.","Introduction: In statistics, distributions in the exponential family are very natural to consider. One famous example is the Gaussian. It shows up in the heat equation, in probability theory, and in many other fields. While the Gaussian may be most important due to the central limit theorem, distributions in the exponential family have properties that may be connected to the properties of the Gaussian itself.  So, consider the exponential family, the close cousin of the Gaussian, for parameter and sufficient statistic Relating to the Riemann zeta function: Viewing geometrically: The function is a particular solution to a linear parabolic diffusion equation (use an exponential ansatz): and the Mellin transform can be used to transform that equation to (transform the solution and use a CAS to verify): where a particular solution Bessel function, appears: We recover a connection with the Riemann zeta function and the Gamma function: convergent for We can recover the symmetric functional equation about the critical strip through this integral relationship and analytic continuation, although it is calculation intensive. A more fundamental approach: Another, perhaps more fundamental, way to obtain the symmetric functional equation is to start with any Schwartz function. Usually the self dual Gaussian is used to obtain the Gamma factor Here I ask for a closed form for the Gamma factor associated to the Schwartz class Obtaining the correct Gamma factor for this Schwartz function . We are looking for a functional equation of this form: Here, is the Gamma factor and denotes the Fourier transform. Note however, that the fundamental domain of is so the Fourier transform will act on this bounded domain. Here I will show the calculation of for modified Bessel function of the second kind Informal discussion and remarks: In terms of geometric analysis has an interpretation as a -parameter family of Riemannian metrics which can be shown using the Fisher methodology and information geometry, and this is how I initially started thinking about . I initially thought of it as a Fisher metric. With this linear geometric flow we have essentially summed discrete pieces of the metric, over a spectrum, in this case the natural numbers, and then taken the Mellin transform to recover the zeta function. That is to say, seems to be ""weakly"" tied to the Riemann zeta function. If you start with and pretend that you can take two Mellin transforms in a row and sum over the natural numbers you recover the Riemann zeta i.e. formula Of course it doesn't make sense to take iterative Mellin transforms like this. But already, you can see that is deeply linked to . And this really isn't that surprising, given the modern viewpoint of things as in Iwasawa-Tate theory. Now I claimed above, that was Schwartz You may be very skeptical about this and rightfully so. This is a delicate situation and I'll explain why. The Schwartz space is classically defined for functions on the real line and so there must be some functional analysis work done to show that can legitimately be thought of as a kind of Schwartz function. I believe things will work out just fine, under the appropriate modifications, but I personally do not know enough functional analysis to tie everything up neatly here. Question: At this point I'd like to state my question. As the title says I am looking to extend the two PDE's and to the critical strip as defined through How do you extend and to the critical strip as defined by Explorations of the literature: Here are some other attempts of mine to educate myself on the approaches that have already been developed. Most relevant I think is the de Bruijn constant: I've read Tao's article about freezing and vaporizing the Riemann zeta function. Also see de Bruijn constant . Here is Tao's presentation: https://terrytao.files.wordpress.com/2018/08/webinar.pdf . This seems related since obeys a strange kind of ""backwards heat equation"" I do know that the Mellin transform by definition maps some function with that's absolutely convergent on the vertical strip . So it seems to me that this sum of the metric over a particular spectrum of the naturals, is being converted from a real to a complex through the Mellin transform. So, I guess that's where I'm stuck. I don't know how to connect that complex object to the -parameter family of real metrics. It seems closely related to this too: https://mathoverflow.net/q/139863/123449 , but I don't know if the argument applies since the operator of my PDE is not a second order p.d.o. (it's third order) among other things. I mean I guess it could be reduced to second order through a Fourier transform but I don't know how to proceed exactly. Final remarks: is a -parameter class, and therefore we should have a varying, or -parameter class of functional equations. The Gamma factor is also a -parameter class. I think there is a way to unify and on the critical strip, using existing mathematical methods. Any argument showing that cannot be used to obtain would also answer this question, essentially providing a counterexample.","f_s(x)=e^{sT(x)} s T(x)=\frac{1}{\log x}. f_s(x) f_s(x) f_s(x) s \frac{\partial ^2f(s,x)}{\partial s^2}=-x \frac{\partial f(s,x)}{\partial x} \tag{2} f_s(x) r^2 \frac{\partial ^3\Psi(r,s)}{\partial r^3}=s^2 \frac{\partial \Psi(r,s)}{\partial s} \tag{3} K_1 \Psi(r,s)=2 \sqrt{\frac{r}{s}}K_1(2\sqrt{r s}) \frac{1}{\Gamma(w-1)\Gamma(w)}\int_0^\infty \sum_{r \in \Bbb N} \Psi(r,s) s^{w-1}~ds=\zeta(w-1) \tag{1} \Re(w)>2. \xi(s)=\xi(1-s) \Gamma(s/2)\pi^{-s/2}. f_s(x): \Gamma(f,r,s)\cdot \zeta(s) \;=\; \Gamma(\hat{f},r,1-s)\cdot \zeta(1-s)\tag{4} \Gamma \hat f f (0,1) \Gamma(f,r,s): \Gamma(f,r,s)=\int_{\mathbb R^\times \cap ~(0,1)} |x|^r~f_s(x)~{dx\over |x|}=2 \sqrt{\frac{r}{s}}K_1(2\sqrt{r s}) K_1. \Psi(r,s) 1 \Psi(r,s) f_s(x) f_s(x) (1). f_s(x) \zeta(s) f_s(x) \forall s >0. f_s(x) (2) (3) (4). (2) (3) (4)? f_s(x) s \frac{\partial ^2f(s,x)}{\partial s^2}=-x \frac{\partial f(s,x)}{\partial x} \psi : (0,\infty) \to \mathbb{C} \mathcal{M}(\psi)(s) = \int_{0}^{\infty} \psi(x) x^s  \frac{dx}{x} \lbrace s \in \mathbb{C} : a < \Re(s) < b \rbrace s w 1 (A).~f_s(x) 1 1 (B).~ 1 (C).~ (A) (B) (D).~ f_s(x) (4)","['functional-analysis', 'partial-differential-equations', 'analytic-number-theory', 'harmonic-analysis', 'riemann-zeta']"
3,No bounded surjective linear map $L^{\infty} \to L^1$,No bounded surjective linear map,L^{\infty} \to L^1,"Let $L^p([0,1])$ denote the $L^p$ space with respect to Lebesgue measure on the unit interval. I want to show there is no bounded surjective linear operator $T \colon L^{\infty}([0,1]) \to L^1([0,1])$ . The open mapping theorem says $T$ is maps open sets to open sets, but I'm not sure how that helps. I know how to prove this if $L^{\infty}$ is replaced by $L^p$ for $1 < p < \infty$ by looking at the adjoint map, but that doesn't work here since $(L^{\infty})^{\ast}$ is not separable","Let denote the space with respect to Lebesgue measure on the unit interval. I want to show there is no bounded surjective linear operator . The open mapping theorem says is maps open sets to open sets, but I'm not sure how that helps. I know how to prove this if is replaced by for by looking at the adjoint map, but that doesn't work here since is not separable","L^p([0,1]) L^p T \colon L^{\infty}([0,1]) \to L^1([0,1]) T L^{\infty} L^p 1 < p < \infty (L^{\infty})^{\ast}","['functional-analysis', 'lp-spaces']"
4,Are continuous functions strongly measurable?,Are continuous functions strongly measurable?,,"Measure theory is still quite new to me, and I'm a bit confused about the following. Suppose we have a continuous function $f: I \rightarrow X$, where $I \subset \mathbb{R}$ is a closed interval and $X$ is a Banach space. I can show that $f$ is weakly measurable: for each $v \in X^*$, we have that the mapping $x \mapsto v(f(x))$ is continuous since it is a composition of continuous mappings $v$ and $f$ (is this correct?). I also know that a continuous function is measurable. In this case, does measurable mean the same as strongly measurable? If it does, how can you show this using Pettis' theorem (i.e. why is there a null set $N\subset I$ such that the set $\{f(x) | x\in I\backslash N\}$ is separable)? Or is it easier to prove it without Pettis' theorem? For continuous $f$, does strong convergence then also imply that it is summable / Bochner integrable, since the mapping $x \mapsto ||f(x)||$ is the composition of continuous maps ($f$ and $||.||$)? EDIT: This last sentence is nonsense of course, $x \mapsto ||f(x)||$ must be summable, not continuous.","Measure theory is still quite new to me, and I'm a bit confused about the following. Suppose we have a continuous function $f: I \rightarrow X$, where $I \subset \mathbb{R}$ is a closed interval and $X$ is a Banach space. I can show that $f$ is weakly measurable: for each $v \in X^*$, we have that the mapping $x \mapsto v(f(x))$ is continuous since it is a composition of continuous mappings $v$ and $f$ (is this correct?). I also know that a continuous function is measurable. In this case, does measurable mean the same as strongly measurable? If it does, how can you show this using Pettis' theorem (i.e. why is there a null set $N\subset I$ such that the set $\{f(x) | x\in I\backslash N\}$ is separable)? Or is it easier to prove it without Pettis' theorem? For continuous $f$, does strong convergence then also imply that it is summable / Bochner integrable, since the mapping $x \mapsto ||f(x)||$ is the composition of continuous maps ($f$ and $||.||$)? EDIT: This last sentence is nonsense of course, $x \mapsto ||f(x)||$ must be summable, not continuous.",,"['functional-analysis', 'measure-theory', 'lebesgue-integral']"
5,"Are the unconditionally convergent series, with terms in a Banach algebra, closed under the Cauchy product?","Are the unconditionally convergent series, with terms in a Banach algebra, closed under the Cauchy product?",,"We have a Banach algebra $\mathbb L$ , and two sequences $(A_0,A_1,A_2,\cdots),\;(B_0,B_1,B_2,\cdots)\in\mathbb L^{\mathbb N}$ , for which the sums $\sum_{n\in\mathbb N}A_n,\;\sum_{n\in\mathbb N}B_n$ are unconditionally convergent . Is $$\sum_{n\in\mathbb N}\left(\sum_{l+m=n}A_lB_m\right)$$ also unconditionally convergent? If it helps, you may assume commutativity ( $A_lB_m=B_mA_l$ ), or that they're power series with scalar coefficients ( $A_n=a_nX^n,\;B_n=b_nX^n,\;X\in\mathbb L$ ). The case with absolute convergence is easy . (There, we just need to replace $|a_nb_k|=|a_n||b_k|$ with $|a_nb_k|\leq|a_n||b_k|$ .) Possibly related: Is the sequence space $\ell^p$ closed under the Cauchy product?","We have a Banach algebra , and two sequences , for which the sums are unconditionally convergent . Is also unconditionally convergent? If it helps, you may assume commutativity ( ), or that they're power series with scalar coefficients ( ). The case with absolute convergence is easy . (There, we just need to replace with .) Possibly related: Is the sequence space $\ell^p$ closed under the Cauchy product?","\mathbb L (A_0,A_1,A_2,\cdots),\;(B_0,B_1,B_2,\cdots)\in\mathbb L^{\mathbb N} \sum_{n\in\mathbb N}A_n,\;\sum_{n\in\mathbb N}B_n \sum_{n\in\mathbb N}\left(\sum_{l+m=n}A_lB_m\right) A_lB_m=B_mA_l A_n=a_nX^n,\;B_n=b_nX^n,\;X\in\mathbb L |a_nb_k|=|a_n||b_k| |a_nb_k|\leq|a_n||b_k|","['functional-analysis', 'convergence-divergence', 'reference-request', 'banach-algebras', 'cauchy-product']"
6,Is every Hilbert space separable?,Is every Hilbert space separable?,,"A Hilbert space is a complete inner product space; that is any Cauchy sequence is convergent using the metric induced by the inner product. From Wikipedia: A Hilbert space is separable if and only if it has a countable orthonormal basis. What are the examples of non-separable Hilbert spaces? From an applied point of view, are all interesting (finite or infinite) Hilbert spaces separable?","A Hilbert space is a complete inner product space; that is any Cauchy sequence is convergent using the metric induced by the inner product. From Wikipedia: A Hilbert space is separable if and only if it has a countable orthonormal basis. What are the examples of non-separable Hilbert spaces? From an applied point of view, are all interesting (finite or infinite) Hilbert spaces separable?",,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
7,Significance of Sobolev spaces for numerical analysis & PDEs?,Significance of Sobolev spaces for numerical analysis & PDEs?,,"I never had an option to take a Functional Analysis module. I am tied up with other work for the next two months so I won't get a chance to self-study it until September. So one thing I was wondering about is the significance of Sobolev spaces for the fields of numerical analysis and PDEs. I have been told on more than one occasion that they are very important in these fields. Having not taken Functional Analysis, I've never encountered Sobolev spaces before. Would someone be able to give me an overview of what is so significant about these spaces and why are they are so relevant to the above fields?","I never had an option to take a Functional Analysis module. I am tied up with other work for the next two months so I won't get a chance to self-study it until September. So one thing I was wondering about is the significance of Sobolev spaces for the fields of numerical analysis and PDEs. I have been told on more than one occasion that they are very important in these fields. Having not taken Functional Analysis, I've never encountered Sobolev spaces before. Would someone be able to give me an overview of what is so significant about these spaces and why are they are so relevant to the above fields?",,"['functional-analysis', 'partial-differential-equations', 'numerical-methods', 'sobolev-spaces']"
8,what is the relation of smooth compact supported funtions and real analytic function?,what is the relation of smooth compact supported funtions and real analytic function?,,What is the major difference between real analytic and test function (smooth compact supported functions). Can we find a real analytic function $f$ on $\mathbb R^n$ which is also smooth compact supported? If not then need a proof.,What is the major difference between real analytic and test function (smooth compact supported functions). Can we find a real analytic function on which is also smooth compact supported? If not then need a proof.,f \mathbb R^n,"['complex-analysis', 'functional-analysis', 'functions', 'analyticity']"
9,Example of nested closed balls with empty intersection?,Example of nested closed balls with empty intersection?,,"Can anybody give an example of a complete metric space and a sequence of nested closed balls , which has empty intersection. (Exercise from Kolmogorov, Fomin: Elements of the Theory of Functions and Functional Analysis) What is the answer to a similar question, where just the complete metric space is changed by the complete normed space?","Can anybody give an example of a complete metric space and a sequence of nested closed balls , which has empty intersection. (Exercise from Kolmogorov, Fomin: Elements of the Theory of Functions and Functional Analysis) What is the answer to a similar question, where just the complete metric space is changed by the complete normed space?",,"['functional-analysis', 'metric-spaces', 'examples-counterexamples']"
10,"Vector, Hilbert, Banach, Sobolev spaces","Vector, Hilbert, Banach, Sobolev spaces",,Trying to wrap my head around all these different spaces. Which one is the most general? Can you summarize the differences between them? Is there a notable space that I missed?,Trying to wrap my head around all these different spaces. Which one is the most general? Can you summarize the differences between them? Is there a notable space that I missed?,,"['functional-analysis', 'vector-spaces', 'banach-spaces', 'hilbert-spaces', 'sobolev-spaces']"
11,Norm of self-adjoint operator,Norm of self-adjoint operator,,"I am trying to prove that $\|A\|=\sup_{\|x\|=1}|\langle x,Ax\rangle|$ for some self-adjoint bounded operator $A$ on a Hilbert space. Can anyone give me a hint how to prove it.",I am trying to prove that for some self-adjoint bounded operator on a Hilbert space. Can anyone give me a hint how to prove it.,"\|A\|=\sup_{\|x\|=1}|\langle x,Ax\rangle| A","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'self-adjoint-operators']"
12,Closed unbounded operator with domain not closed,Closed unbounded operator with domain not closed,,"I am looking for an example for further understanding of the Closed Graph Theorem : Let $X,Y$ be Banach spaces and $T:X\to Y$ closed (i.e. the graph of $T$ is closed in $X\times Y$). Then if $\mathcal{D}(T)$ is closed in $X$, $T$ is bounded. I am looking for an unbounded operator whose graph $\mathcal{G}(T)$ is closed in $X\times Y$ and whose domain $\mathcal{D}(T)$ is not closed in $X$, to clearify the necessity of $\mathcal{D}(T)$ being closed. This question arose due to the definition of the norm of a graph $\lVert (x,Tx)\rVert:=\lVert x\rVert+\lVert Tx\rVert$, where I thought the following statement would be true:  [$\mathcal{G}(T)$ closed $\Rightarrow\mathcal{D}(T)$ closed] which in general is false.","I am looking for an example for further understanding of the Closed Graph Theorem : Let $X,Y$ be Banach spaces and $T:X\to Y$ closed (i.e. the graph of $T$ is closed in $X\times Y$). Then if $\mathcal{D}(T)$ is closed in $X$, $T$ is bounded. I am looking for an unbounded operator whose graph $\mathcal{G}(T)$ is closed in $X\times Y$ and whose domain $\mathcal{D}(T)$ is not closed in $X$, to clearify the necessity of $\mathcal{D}(T)$ being closed. This question arose due to the definition of the norm of a graph $\lVert (x,Tx)\rVert:=\lVert x\rVert+\lVert Tx\rVert$, where I thought the following statement would be true:  [$\mathcal{G}(T)$ closed $\Rightarrow\mathcal{D}(T)$ closed] which in general is false.",,"['functional-analysis', 'operator-theory', 'unbounded-operators']"
13,Weak Convergence implies boundedness and componentwise convergence,Weak Convergence implies boundedness and componentwise convergence,,"Let $\ell^2$ be the set of real number sequences $a=(a(i))_i$ such that $\sum_i a(i)^2 <\infty$ . Suppose $\{a_n\}$ is a sequence in $\ell^2$ and $a\in\ell^2$ such that $\langle a_n,y\rangle \rightarrow \langle a,y\rangle$ for all $y\in \ell^2$ . Would you help me prove that $\{\|  a_n\|\}$ is bounded and for each fixed $i$ , $a_n(i) \to a(i)$ where $x(i)$ denote the $i$ -component of $x$ .","Let be the set of real number sequences such that . Suppose is a sequence in and such that for all . Would you help me prove that is bounded and for each fixed , where denote the -component of .","\ell^2 a=(a(i))_i \sum_i a(i)^2 <\infty \{a_n\} \ell^2 a\in\ell^2 \langle a_n,y\rangle \rightarrow \langle a,y\rangle y\in \ell^2 \{\|  a_n\|\} i a_n(i) \to a(i) x(i) i x","['functional-analysis', 'convergence-divergence', 'hilbert-spaces']"
14,Weak convergence $\iff$ strong convergence in finite dimensional space,Weak convergence  strong convergence in finite dimensional space,\iff,I am seeking a proof of the following claim. Weak convergence $\implies$ strong convergence in a finite-dimensional normed linear space. Thank you.,I am seeking a proof of the following claim. Weak convergence $\implies$ strong convergence in a finite-dimensional normed linear space. Thank you.,,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'weak-convergence']"
15,Weighted Poincare Inequality,Weighted Poincare Inequality,,"I'm trying to prove a result I found in a paper, and I think I'm being a bit silly. The paper claims the following: By the Poincare inequality on the unit square $\Omega \subset \mathbb{R}^2$ we have that $$\int_{\Omega} f(x)^2 dx \leq C \int_{\Omega}|\nabla f|^2 dx + \left(\int_{\Omega}f(x)dx\right)^2.$$ Thus,  if $w(x)$ is a weight satisfying $\int_\Omega w(x)\,dx =1$ and $0 < W_{-} \leq w(x)$ one can prove the Poincare inequality with respect to the measure $w(x)dx$. I'm assuming that the author means the following result $$\int_{\Omega} f(x)^2 w(x)dx \leq C' \int_{\Omega}|\nabla f|^2 w(x)dx + \left(\int_{\Omega}f(x)w(x)dx\right)^2.$$ Does anybody have any idea how to prove this?   I'm particularly interested in the relationship between the Poincare constant $C$ and $C'$.","I'm trying to prove a result I found in a paper, and I think I'm being a bit silly. The paper claims the following: By the Poincare inequality on the unit square $\Omega \subset \mathbb{R}^2$ we have that $$\int_{\Omega} f(x)^2 dx \leq C \int_{\Omega}|\nabla f|^2 dx + \left(\int_{\Omega}f(x)dx\right)^2.$$ Thus,  if $w(x)$ is a weight satisfying $\int_\Omega w(x)\,dx =1$ and $0 < W_{-} \leq w(x)$ one can prove the Poincare inequality with respect to the measure $w(x)dx$. I'm assuming that the author means the following result $$\int_{\Omega} f(x)^2 w(x)dx \leq C' \int_{\Omega}|\nabla f|^2 w(x)dx + \left(\int_{\Omega}f(x)w(x)dx\right)^2.$$ Does anybody have any idea how to prove this?   I'm particularly interested in the relationship between the Poincare constant $C$ and $C'$.",,"['functional-analysis', 'partial-differential-equations', 'functional-inequalities']"
16,Tensor product of operators,Tensor product of operators,,"We know that if $T_1$ is a linear bounded operator on a Hilbert space $H_1$ and $T_2$ is a linear bounded operator on a Hilbert space $H_2$ there exists a unique linear bounded operator $T$ on $H_1 \otimes H_2$ such that $$ T (x_1 \otimes x_2) = T_1x_1 \otimes T_2x_2$$ for all $x_1$ in $H_1$ and $x_2$ in $H_2$. This operator is called a tensor product of operators $T_1$ and $T_2$ and denoted by $T_1 \otimes T_2$. We can extend this to the arbitrary finite tensor product of Hilbert spaces and even infinite one which works with respect to some stabilising sequence. How about the converse? Is it true that if $T$ is a linear bounded operator on a Hilbert space $H_1 \otimes H_2$ (here of course $H_1$, $H_2$ also Hilbert spaces) then we can find operators (unique?) $T_1$ and $T_2$ on $H_1$, $H_2$ respectively, such that $Tu= (T_1 \otimes T_2)u$ for every $u \in H_1 \otimes H_2$. If not I would be grateful for any counterexamples. If it is true, how about the arbitrary tensor product and what about inifinite one? Thank you for the help. Any suggestions for good books are welcome.","We know that if $T_1$ is a linear bounded operator on a Hilbert space $H_1$ and $T_2$ is a linear bounded operator on a Hilbert space $H_2$ there exists a unique linear bounded operator $T$ on $H_1 \otimes H_2$ such that $$ T (x_1 \otimes x_2) = T_1x_1 \otimes T_2x_2$$ for all $x_1$ in $H_1$ and $x_2$ in $H_2$. This operator is called a tensor product of operators $T_1$ and $T_2$ and denoted by $T_1 \otimes T_2$. We can extend this to the arbitrary finite tensor product of Hilbert spaces and even infinite one which works with respect to some stabilising sequence. How about the converse? Is it true that if $T$ is a linear bounded operator on a Hilbert space $H_1 \otimes H_2$ (here of course $H_1$, $H_2$ also Hilbert spaces) then we can find operators (unique?) $T_1$ and $T_2$ on $H_1$, $H_2$ respectively, such that $Tu= (T_1 \otimes T_2)u$ for every $u \in H_1 \otimes H_2$. If not I would be grateful for any counterexamples. If it is true, how about the arbitrary tensor product and what about inifinite one? Thank you for the help. Any suggestions for good books are welcome.",,"['functional-analysis', 'hilbert-spaces', 'tensor-products']"
17,Exercise books on functional analysis,Exercise books on functional analysis,,"I have known a lot of excellent textbooks on functional analysis: Functional Analysis (Walter Rudin) Functional Analysis, Sobolev Spaces and Partial Differential Equations (Haim Brezis) +.... I could not find some good exercise books on functional analysis. Please help me to find some good books on exercise of functional analysis. Thank you for all helping and comments.","I have known a lot of excellent textbooks on functional analysis: Functional Analysis (Walter Rudin) Functional Analysis, Sobolev Spaces and Partial Differential Equations (Haim Brezis) +.... I could not find some good exercise books on functional analysis. Please help me to find some good books on exercise of functional analysis. Thank you for all helping and comments.",,"['functional-analysis', 'reference-request', 'book-recommendation']"
18,Motivation behind the definition of Banach-Mazur Distance,Motivation behind the definition of Banach-Mazur Distance,,"We know that any two n-dimensional normed vector spaces $X,Y$ are isomorphic, and we define the Banach-Mazur distance between $X,Y$ as $$ d(X,Y)=\inf \{ \|T\|\|T^{-1}\|:T\in GL(X,Y) \} ,$$ where $GL(X,Y)$ is the space of all linear isomorphisms. What is the motivation behind this definition? Are there other kind of metric that we can define similarly  between finite dimensional normed spaces? And finally, whether there is a  similar notion for infinite dimensional version? As for the context, I am reading about $\mathcal{L}_p$-spaces which utilizes this the Banach-Mazur distance.","We know that any two n-dimensional normed vector spaces $X,Y$ are isomorphic, and we define the Banach-Mazur distance between $X,Y$ as $$ d(X,Y)=\inf \{ \|T\|\|T^{-1}\|:T\in GL(X,Y) \} ,$$ where $GL(X,Y)$ is the space of all linear isomorphisms. What is the motivation behind this definition? Are there other kind of metric that we can define similarly  between finite dimensional normed spaces? And finally, whether there is a  similar notion for infinite dimensional version? As for the context, I am reading about $\mathcal{L}_p$-spaces which utilizes this the Banach-Mazur distance.",,['functional-analysis']
19,Weak-* sequential compactness and separability,Weak-* sequential compactness and separability,,"Let $X$ be a Banach space, and let $B$ be the closed unit ball of $X^*$, equipped with the weak-* topology.  Alaoglu's theorem says that $B$ is compact.  If $X$ is separable, then $B$ is metrizable, and in particular it is sequentially compact. What about the converse?  If $B$ is sequentially compact, must $X$ be separable? This question was inspired by this one .","Let $X$ be a Banach space, and let $B$ be the closed unit ball of $X^*$, equipped with the weak-* topology.  Alaoglu's theorem says that $B$ is compact.  If $X$ is separable, then $B$ is metrizable, and in particular it is sequentially compact. What about the converse?  If $B$ is sequentially compact, must $X$ be separable? This question was inspired by this one .",,"['functional-analysis', 'banach-spaces']"
20,$f$ is discontinuous $\iff$ kernel($f$) is dense in X,is discontinuous  kernel() is dense in X,f \iff f,"Problem: Let $X$ be a normed space and $f$ be a non-zero linear functional on $X$. Then prove that $f$ is discontinuous $\iff$   kernel($f$) is dense in $X$. I have proved that if $f$ is discontinuous, then kernel($f$) is dense in $X$. How to prove the other way?","Problem: Let $X$ be a normed space and $f$ be a non-zero linear functional on $X$. Then prove that $f$ is discontinuous $\iff$   kernel($f$) is dense in $X$. I have proved that if $f$ is discontinuous, then kernel($f$) is dense in $X$. How to prove the other way?",,[]
21,Do eigenvectors of Hermitian operators span the space in infinite dimensions?,Do eigenvectors of Hermitian operators span the space in infinite dimensions?,,"I was reading Introduction to quantum mechanics by David J. Griffiths and came across following paragraph: $3$ . The eigenvectors of a hermitian transformation span the space. As we have seen, this is equivalent to the statement that any hermitian matrix can be diagonalized. This rather technical fact is , in a sense, the mathematical support on which much of a quantum mechanics leans . It turns out to be a thinner reed then one might have hoped, because the proof does not carry over to infinite-dimensional spaces. "" My thoughts: If much of a quantum mechanics leans on it, but the proof does not carry over to infinite-dimensional spaces, then hermitian transformations with infinite dimensionality are spurious. But there is infinite set of separable solutions for e.g. particle in a box. So Hamiltionan for that system has spectrum with infinite number of eigenvectors and is of infinite dimensionality. If we can't prove that this infinite set of eigenvectors span the space then how can we use completness all the time? Am I missing something here? Any missconceptions? I'd appriciate any help.","I was reading Introduction to quantum mechanics by David J. Griffiths and came across following paragraph: . The eigenvectors of a hermitian transformation span the space. As we have seen, this is equivalent to the statement that any hermitian matrix can be diagonalized. This rather technical fact is , in a sense, the mathematical support on which much of a quantum mechanics leans . It turns out to be a thinner reed then one might have hoped, because the proof does not carry over to infinite-dimensional spaces. "" My thoughts: If much of a quantum mechanics leans on it, but the proof does not carry over to infinite-dimensional spaces, then hermitian transformations with infinite dimensionality are spurious. But there is infinite set of separable solutions for e.g. particle in a box. So Hamiltionan for that system has spectrum with infinite number of eigenvectors and is of infinite dimensionality. If we can't prove that this infinite set of eigenvectors span the space then how can we use completness all the time? Am I missing something here? Any missconceptions? I'd appriciate any help.",3,"['functional-analysis', 'mathematical-physics', 'spectral-theory', 'quantum-mechanics', 'unbounded-operators']"
22,Finite-dimensional subspaces of normed vector spaces are direct summands,Finite-dimensional subspaces of normed vector spaces are direct summands,,"Here is a problem in functional analysis from Folland's book: If $\mathcal{M}$ is a finite-dimensional subspace of a normed vector space $\mathcal{X}$, then there is a closed subspace $\mathcal{N}$ such that $\mathcal{M}\cap \mathcal{N} = 0$ and $\mathcal{M}+\mathcal{N} = \mathcal{X}$. I tried the following approach: I am trying to define a projection map $\pi_{\mathcal{M}}$ from $\mathcal{X}$ to $\mathcal{M}$, which would be continuous and hence taking the inverse of any closed set would give a closed set in $\mathcal{X}$. I am confused about what the projection map would be. Please suggest some approach.","Here is a problem in functional analysis from Folland's book: If $\mathcal{M}$ is a finite-dimensional subspace of a normed vector space $\mathcal{X}$, then there is a closed subspace $\mathcal{N}$ such that $\mathcal{M}\cap \mathcal{N} = 0$ and $\mathcal{M}+\mathcal{N} = \mathcal{X}$. I tried the following approach: I am trying to define a projection map $\pi_{\mathcal{M}}$ from $\mathcal{X}$ to $\mathcal{M}$, which would be continuous and hence taking the inverse of any closed set would give a closed set in $\mathcal{X}$. I am confused about what the projection map would be. Please suggest some approach.",,['functional-analysis']
23,Closed subspace of $l^\infty$,Closed subspace of,l^\infty,"I've got here this exercise that says: ""Show that $c$ is a closed subspace of $l^{\infty}$"" (with $c$ I mean the sequences of $l^{\infty}$ that converge in $l^{\infty}$, with respect to the norm of $l^{\infty}$). I've done it, but I cannot say if it is correct. In order to show that $c$ is a closed subspace of $l^{\infty}$, I have to prove that any convergent sequence $\{c_n\}_n$ of elements of $c$ converges to $x\in c$. I know that, since $l^{\infty}$ is complete, $\{c_n\}$ converges to $x\in l^{\infty}$, so it is enough prove that $x\in c$. Since $\{c_n\}$ converges to $x\in l^{\infty}$, we have that $||c_n-x||_\infty\to 0$ for $n\to \infty$, i.e. $\sup_{j\in \mathbb{N}}|c_n-x|\to 0$ (here $j$ runs over the elements of the sequence $c_n-x$), i.e. for every $\epsilon>0$ there exists $N>0$ such that $\sup_{j\in \mathbb{N}}|c_n-x|<\epsilon$ for $n>N$. Now, since $c_n\in c$, we have that $c_n\to \xi\in l^{\infty}$ for $n\to \infty$, and so for every $\epsilon>0$ \begin{equation*} \sup_{j\in \mathbb{N}}|\lim_{n\to \infty}(c_n-x)|=\sup_{j\in \mathbb{N}}|\xi-x|<\epsilon,  \end{equation*} which means that $x\in c$. What do you think? Is there anybody that could suggest me a different argument?","I've got here this exercise that says: ""Show that $c$ is a closed subspace of $l^{\infty}$"" (with $c$ I mean the sequences of $l^{\infty}$ that converge in $l^{\infty}$, with respect to the norm of $l^{\infty}$). I've done it, but I cannot say if it is correct. In order to show that $c$ is a closed subspace of $l^{\infty}$, I have to prove that any convergent sequence $\{c_n\}_n$ of elements of $c$ converges to $x\in c$. I know that, since $l^{\infty}$ is complete, $\{c_n\}$ converges to $x\in l^{\infty}$, so it is enough prove that $x\in c$. Since $\{c_n\}$ converges to $x\in l^{\infty}$, we have that $||c_n-x||_\infty\to 0$ for $n\to \infty$, i.e. $\sup_{j\in \mathbb{N}}|c_n-x|\to 0$ (here $j$ runs over the elements of the sequence $c_n-x$), i.e. for every $\epsilon>0$ there exists $N>0$ such that $\sup_{j\in \mathbb{N}}|c_n-x|<\epsilon$ for $n>N$. Now, since $c_n\in c$, we have that $c_n\to \xi\in l^{\infty}$ for $n\to \infty$, and so for every $\epsilon>0$ \begin{equation*} \sup_{j\in \mathbb{N}}|\lim_{n\to \infty}(c_n-x)|=\sup_{j\in \mathbb{N}}|\xi-x|<\epsilon,  \end{equation*} which means that $x\in c$. What do you think? Is there anybody that could suggest me a different argument?",,['functional-analysis']
24,A Continuous Function with a Divergent Fourier Series,A Continuous Function with a Divergent Fourier Series,,"This is a Q&A I hope simply posting a question and then answering it is the right protocol. This is stuff I thought everybody knew, but in at least two recent threads it's turned out to be somewhat mysterious. So: Q: How do you show that there exists a continuous function on the circle whose Fourier series diverges at the origin? Edit @TrialAndError points out that Stackexchange officially encourages asking and answering your own question .","This is a Q&A I hope simply posting a question and then answering it is the right protocol. This is stuff I thought everybody knew, but in at least two recent threads it's turned out to be somewhat mysterious. So: Q: How do you show that there exists a continuous function on the circle whose Fourier series diverges at the origin? Edit @TrialAndError points out that Stackexchange officially encourages asking and answering your own question .",,"['functional-analysis', 'fourier-series']"
25,What is the difference between weak and strong convergence?,What is the difference between weak and strong convergence?,,"What is the difference between strong and weak convergence? I am reading ""Introductory functional analysis"" by Kreyszig and I dont appreciate the differences between the two. Definition of strong convergence: A sequence $(x_n)$ in a normed space $X$ is said to be strongly convergent if there is an $x \in X$ such that $$\lim_{n \to \infty}||x_n-x||=0$$ Definition of weak convergence: A sequence $(x_n)$ in a normed space $X$ is said to be weakly  convergent if there is an $x \in X$ such that $$\lim_{n \to \infty}f(x_n)=f(x)$$ I do not appreciate the differences between the two, does anyone have an example to highlight the differences? How does the proof differ in showing if a sequences converges weakly   or strongly?","What is the difference between strong and weak convergence? I am reading ""Introductory functional analysis"" by Kreyszig and I dont appreciate the differences between the two. Definition of strong convergence: A sequence $(x_n)$ in a normed space $X$ is said to be strongly convergent if there is an $x \in X$ such that $$\lim_{n \to \infty}||x_n-x||=0$$ Definition of weak convergence: A sequence $(x_n)$ in a normed space $X$ is said to be weakly  convergent if there is an $x \in X$ such that $$\lim_{n \to \infty}f(x_n)=f(x)$$ I do not appreciate the differences between the two, does anyone have an example to highlight the differences? How does the proof differ in showing if a sequences converges weakly   or strongly?",,['functional-analysis']
26,uniqueness of Hahn-Banach extension for convex dual spaces,uniqueness of Hahn-Banach extension for convex dual spaces,,"Let $X'$ be strict convex, i.e. for all $x_1',x_2'\in X'$ with $\|x_1'\|_{X'}=\|x_2'\|_{X'}=1$ the implication $$\left\|\frac{x_1'+x_2'}{2}\right\|=1\Rightarrow x_1'=x_2'$$ holds. In this case the Hahn-Banach-extension is unique. I am trying to figure out how I can show this. The Hahn-Banach theorem says that for a subspace $U\subset X$ of a normed space $X$, there exists an extension $x'\in X'$ with $x'|_U=u'$ for every map $u':U\to \mathbb C$. I've already gone through the proof of the Hahn-Banach theorem, but I don't see where I have to use the convexity of $X'$ to show that the extension is unique. Can anyone help me here? Thanks.","Let $X'$ be strict convex, i.e. for all $x_1',x_2'\in X'$ with $\|x_1'\|_{X'}=\|x_2'\|_{X'}=1$ the implication $$\left\|\frac{x_1'+x_2'}{2}\right\|=1\Rightarrow x_1'=x_2'$$ holds. In this case the Hahn-Banach-extension is unique. I am trying to figure out how I can show this. The Hahn-Banach theorem says that for a subspace $U\subset X$ of a normed space $X$, there exists an extension $x'\in X'$ with $x'|_U=u'$ for every map $u':U\to \mathbb C$. I've already gone through the proof of the Hahn-Banach theorem, but I don't see where I have to use the convexity of $X'$ to show that the extension is unique. Can anyone help me here? Thanks.",,"['functional-analysis', 'convex-analysis']"
27,Linear operators with no adjoint,Linear operators with no adjoint,,"Here is a standard theorem about bounded operators: Let $H$ be a Hilbert space. For any bounded linear operator $A:H\to H$ there is a unique bounded operator $A^*$ s.t $\langle Au,v\rangle=\langle u,A^*v\rangle$ for all $u,v\in H$. The proof that I know of uses Riesz Representation Theorem, which states that a continuous linear functional $T:H\to \mathbb{C}$ on a Hilbert space is of the form $T(u)=\langle u,w\rangle$ for a unique $w\in H$. I have two questions: 1) It's natural to expect that there are linear operators on a pre-Hilbert space that are bounded but have no adjoint. What is an example? 2) When does an unbounded operator on a Hilbert space have an adjoint? I know there are self-adjoint unbounded operators. so I am thinking if there is a characterization for when the adjoint exists? the first question is more important for me right now. I'm not sure if the second question has a good answer.","Here is a standard theorem about bounded operators: Let $H$ be a Hilbert space. For any bounded linear operator $A:H\to H$ there is a unique bounded operator $A^*$ s.t $\langle Au,v\rangle=\langle u,A^*v\rangle$ for all $u,v\in H$. The proof that I know of uses Riesz Representation Theorem, which states that a continuous linear functional $T:H\to \mathbb{C}$ on a Hilbert space is of the form $T(u)=\langle u,w\rangle$ for a unique $w\in H$. I have two questions: 1) It's natural to expect that there are linear operators on a pre-Hilbert space that are bounded but have no adjoint. What is an example? 2) When does an unbounded operator on a Hilbert space have an adjoint? I know there are self-adjoint unbounded operators. so I am thinking if there is a characterization for when the adjoint exists? the first question is more important for me right now. I'm not sure if the second question has a good answer.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
28,Example of a Bounded Linear Operator with Unbounded Spectrum.,Example of a Bounded Linear Operator with Unbounded Spectrum.,,"I was looking at this superb question posted on MSE Spectrum can be an arbitrary subset. . And this question raised the following more elementary question Find an example of bounded linear operator $T: X\to X$ , defined in a normed vector space $X$ , such that, $\sigma(T)$ is unbounded ( $\sigma(T)$ is the spectrum of $T$ ). I have tried to construct an example but I  have failed miserably. Moreover, I searched online but I was not able to find anything related to the question. Does anyone know an example? Just a comment. By Banach Completion we can always consider $X$ as a dense subspace of the Banach space $\widetilde X$ . Using the following question extending a bounded linear operator there exists a unique bounded linear operator $S:\widetilde X\to \widetilde X$ such that $\|T\|=\|S\|$ and $\left.S\right|_{X}=T$ . It really seems like that $\sigma(T)\subset\sigma(S)$ . If $\lambda \in \rho(S)$ (resolvent of $S$ ), then $(\lambda I-S)^{-1}$ is bounded. Therefore $$(\lambda I-S)^{-1}(\lambda I-S)=\text{Id}_{\widetilde X}, $$ if we restric the above equation to the subspace $X$ we conclude that $$(\lambda I-S)^{-1}(\lambda I-T)=\text{Id}_{X}. $$ Since $(\lambda I-S)^{-1}$ is bounded then $(\lambda I-T)^{-1}$ is bounded as well, therefore $\rho(S)\subset \rho(T)$ , then $\sigma(T)\subset \sigma(S)$ . Since $S$ is a bounded linear operator in a Banach space $\sigma(S)$ is bounded $\Rightarrow$ $\sigma(T)$ is bounded. Is this correct? (Maybe $(\lambda I-S)$ surjective  will not imply $(\lambda I-T)$ surjective).","I was looking at this superb question posted on MSE Spectrum can be an arbitrary subset. . And this question raised the following more elementary question Find an example of bounded linear operator , defined in a normed vector space , such that, is unbounded ( is the spectrum of ). I have tried to construct an example but I  have failed miserably. Moreover, I searched online but I was not able to find anything related to the question. Does anyone know an example? Just a comment. By Banach Completion we can always consider as a dense subspace of the Banach space . Using the following question extending a bounded linear operator there exists a unique bounded linear operator such that and . It really seems like that . If (resolvent of ), then is bounded. Therefore if we restric the above equation to the subspace we conclude that Since is bounded then is bounded as well, therefore , then . Since is a bounded linear operator in a Banach space is bounded is bounded. Is this correct? (Maybe surjective  will not imply surjective).","T: X\to X X \sigma(T) \sigma(T) T X \widetilde X S:\widetilde X\to \widetilde X \|T\|=\|S\| \left.S\right|_{X}=T \sigma(T)\subset\sigma(S) \lambda \in \rho(S) S (\lambda I-S)^{-1} (\lambda I-S)^{-1}(\lambda I-S)=\text{Id}_{\widetilde X},  X (\lambda I-S)^{-1}(\lambda I-T)=\text{Id}_{X}.  (\lambda I-S)^{-1} (\lambda I-T)^{-1} \rho(S)\subset \rho(T) \sigma(T)\subset \sigma(S) S \sigma(S) \Rightarrow \sigma(T) (\lambda I-S) (\lambda I-T)","['functional-analysis', 'operator-theory', 'examples-counterexamples', 'normed-spaces', 'spectral-theory']"
29,Example of a self-adjoint bounded operator on a Hilbert space with empty point spectrum,Example of a self-adjoint bounded operator on a Hilbert space with empty point spectrum,,"I want to find a self-adjoint bounded operator on a Hilbert space with empty point spectrum i.e. $$ T = T^* ~\text{but}~ \sigma_p(T)= \emptyset $$ Some definitions and results of the lecture: (On a Hilbert space $X$ and let $T \in \mathscr{L}(X)$ i.e. a bounded linear operator on $X$ ) $T=T^* \Leftrightarrow \sigma(T) \subset \mathbb{R} $ $TT^* = T^* T \Rightarrow \sigma_r(T)=\emptyset$ i.e. the residual spectrum is empty $\sigma(T)=\sigma_r(T) \cup \sigma_p \cup \sigma_c(T)$ disjoint unions If the space is finite then $\sigma_p(T)=\sigma(T)$ $\sigma(T)$ is non-empty So, I have a self-adjoint operator i.e the residual spectrum is empty and I also want the point spectrum to be empty i.e. I want to achieve $\sigma(T)=\sigma_c(T)$ i.e $$ \{\lambda \in \mathbb{C} ~|~ (\lambda I - T) ~\text{not invertible} \}=$$ $$\{\lambda \in \mathbb{C} ~|~ \ker(\lambda I - T)=\emptyset ~\text{ and }~ \text{ran}(\lambda I - T) \neq \overline{\text{ran}(\lambda I - T)}=X \}$$ Additionally the space has to be infinite since otherwise $\sigma(T)=\sigma_p(T)$ . Does someone have such an example for me? And please explain why this example works in this way. This spectral theory is new for me.","I want to find a self-adjoint bounded operator on a Hilbert space with empty point spectrum i.e. Some definitions and results of the lecture: (On a Hilbert space and let i.e. a bounded linear operator on ) i.e. the residual spectrum is empty disjoint unions If the space is finite then is non-empty So, I have a self-adjoint operator i.e the residual spectrum is empty and I also want the point spectrum to be empty i.e. I want to achieve i.e Additionally the space has to be infinite since otherwise . Does someone have such an example for me? And please explain why this example works in this way. This spectral theory is new for me.", T = T^* ~\text{but}~ \sigma_p(T)= \emptyset  X T \in \mathscr{L}(X) X T=T^* \Leftrightarrow \sigma(T) \subset \mathbb{R}  TT^* = T^* T \Rightarrow \sigma_r(T)=\emptyset \sigma(T)=\sigma_r(T) \cup \sigma_p \cup \sigma_c(T) \sigma_p(T)=\sigma(T) \sigma(T) \sigma(T)=\sigma_c(T)  \{\lambda \in \mathbb{C} ~|~ (\lambda I - T) ~\text{not invertible} \}= \{\lambda \in \mathbb{C} ~|~ \ker(\lambda I - T)=\emptyset ~\text{ and }~ \text{ran}(\lambda I - T) \neq \overline{\text{ran}(\lambda I - T)}=X \} \sigma(T)=\sigma_p(T),"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
30,Smoothness and decay property of Fourier transformation,Smoothness and decay property of Fourier transformation,,"If my memory serves I have heard something like ""the less smooth your function $f$ is, the worse its Fourier transform $\hat{f}$ decay because its Fourier transform $\hat{f}$ needs more waves of high frequency"". I now would like to formulate the claim above properly. I am interested in relation of smoothness and decay property of Fourier transformation. I think this can be rigorously shown by the fundamental properties of Fourier transformation: $\widehat{\partial_{x}^n f}(\xi)=(i\xi)^n\hat{f}(\xi)$ and    $\widehat{(i\xi)^n f}(\xi)=\partial_{x}^n\hat{f}(\xi)$ From these equalities how can one conclude smoothness and decay property of Fourier transformation?","If my memory serves I have heard something like ""the less smooth your function $f$ is, the worse its Fourier transform $\hat{f}$ decay because its Fourier transform $\hat{f}$ needs more waves of high frequency"". I now would like to formulate the claim above properly. I am interested in relation of smoothness and decay property of Fourier transformation. I think this can be rigorously shown by the fundamental properties of Fourier transformation: $\widehat{\partial_{x}^n f}(\xi)=(i\xi)^n\hat{f}(\xi)$ and    $\widehat{(i\xi)^n f}(\xi)=\partial_{x}^n\hat{f}(\xi)$ From these equalities how can one conclude smoothness and decay property of Fourier transformation?",,"['functional-analysis', 'fourier-analysis']"
31,What's the connection between the Laplace transform and the Fourier transform?,What's the connection between the Laplace transform and the Fourier transform?,,"Both the Laplace transform and the Fourier transform in some sense decode the ""spectrum"" of a function. The Laplace transform gives a power-series decomposition whereas the Fourier transform gives a harmonic (or loop-based) decomposition. Are there deep connections between these two transforms? The formulaic connection is clear, but is there something deeper? (Maybe the answer will involve spectral theory?)","Both the Laplace transform and the Fourier transform in some sense decode the ""spectrum"" of a function. The Laplace transform gives a power-series decomposition whereas the Fourier transform gives a harmonic (or loop-based) decomposition. Are there deep connections between these two transforms? The formulaic connection is clear, but is there something deeper? (Maybe the answer will involve spectral theory?)",,"['functional-analysis', 'fourier-analysis', 'integral-transforms', 'spectral-theory']"
32,Leray-Schauder fixed point theorem,Leray-Schauder fixed point theorem,,"I know the proof of the Schauder fixed point theorem which states Schauder fixed point theorem :   If $D$ is a non-empty , convex and compact subset of Banach space $B$ and $T:D \to D$ a continuous function then $T$ has a fixed point in $D$. Now my question is how I can prove the Leray-Schauder fixed point theorem, which states Leray-Schauder fixed point theorem :   If $D$ is a non-empty , convex , bounded and closed subset of Banach space $B$ and $T:D \to D$ a compact and continuous map , then $T$ has a fixed point in $D$. Can we prove the Leray-Schauder fixed point theorem with the Schauder fixed point theorem or are the proofs technically different?","I know the proof of the Schauder fixed point theorem which states Schauder fixed point theorem :   If $D$ is a non-empty , convex and compact subset of Banach space $B$ and $T:D \to D$ a continuous function then $T$ has a fixed point in $D$. Now my question is how I can prove the Leray-Schauder fixed point theorem, which states Leray-Schauder fixed point theorem :   If $D$ is a non-empty , convex , bounded and closed subset of Banach space $B$ and $T:D \to D$ a compact and continuous map , then $T$ has a fixed point in $D$. Can we prove the Leray-Schauder fixed point theorem with the Schauder fixed point theorem or are the proofs technically different?",,"['functional-analysis', 'ordinary-differential-equations', 'partial-differential-equations', 'fixed-point-theorems']"
33,"When two projections in a C*-algebra are ""almost"" Murray-von Neumann equivalent, they are equivalent","When two projections in a C*-algebra are ""almost"" Murray-von Neumann equivalent, they are equivalent",,"Let $A$ be a C*-algebra and $p,q \in A$ be projections. Assume there is an element $a\in A$ such that $\|aa^*-p\|<\frac{1}{4}$ and $\|a^*a-q\|<\frac{1}{4}$. Then there is a partial isometry $v$ with $vv^*=p$ and $v^*v=q$. This is considered obvious in the paper I'm reading. I've tried to mimic the proof of the following proposition. Let $p$, $q$ be projections in a C*-algebra A. If $\|p-q\|<1$ then p and q are unitarily    equivalent. Which involves using a suitable expression ($1-p-q+2pq$) and polar decomposition. But it's not going anywhere.","Let $A$ be a C*-algebra and $p,q \in A$ be projections. Assume there is an element $a\in A$ such that $\|aa^*-p\|<\frac{1}{4}$ and $\|a^*a-q\|<\frac{1}{4}$. Then there is a partial isometry $v$ with $vv^*=p$ and $v^*v=q$. This is considered obvious in the paper I'm reading. I've tried to mimic the proof of the following proposition. Let $p$, $q$ be projections in a C*-algebra A. If $\|p-q\|<1$ then p and q are unitarily    equivalent. Which involves using a suitable expression ($1-p-q+2pq$) and polar decomposition. But it's not going anywhere.",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
34,Elliptic Regularity Theorem,Elliptic Regularity Theorem,,"I want to collect some results on elliptic regularity. The problem I consider is \begin{align}                      Lu&=f,&in \quad U,\\              u&=g,&on \quad  \partial U.\tag{1} \end{align} where $Lu:=a_{ij}(x)u_{x_ix_j}+b_i(x)u_{x_i}+c(x)u.$ is a strictly elliptic operator. I have known that the $C^{2,\alpha}$-regularity from Gilbarg&Trudinger's book and the $H^2$-regularity from Evans'book. Now I wonder that can the $C^2$-regularity is also available？Namely，can we take $\alpha=0$ in the $C^{2,\alpha}$-regularity. More precisely，I want to make clear that is the following theorem valid？ THEOREM ($C^2$-elliptic regularity ) Let $U$ is $C^2$ bounded domain, $g\in C^2(\bar U)$,$u\in C(\bar U)\cap C^2(U)$ is a classical solution of the Dirichlet problem $(1)$, where $a_{ij},b_i,c,f\in C(\bar U)$. Then $u\in C^2(\bar U)$. In addition, I also wonder the solvability of $(1)$ in function space $C^2(\bar U)$.Namely,is the following existence theorem valid？ THEOREM ($C^2$-existence) Let $U$ is $C^2$ bounded domain, $g\in C^2(\bar U)$, $c\leq 0$,$a_{ij},b_i,c,f\in C(\bar U)$. Then the Dirichlet problem $(1)$ has a unique solution $u\in C^2(\bar U)$. Any answer or reference is appreciated! :)","I want to collect some results on elliptic regularity. The problem I consider is \begin{align}                      Lu&=f,&in \quad U,\\              u&=g,&on \quad  \partial U.\tag{1} \end{align} where $Lu:=a_{ij}(x)u_{x_ix_j}+b_i(x)u_{x_i}+c(x)u.$ is a strictly elliptic operator. I have known that the $C^{2,\alpha}$-regularity from Gilbarg&Trudinger's book and the $H^2$-regularity from Evans'book. Now I wonder that can the $C^2$-regularity is also available？Namely，can we take $\alpha=0$ in the $C^{2,\alpha}$-regularity. More precisely，I want to make clear that is the following theorem valid？ THEOREM ($C^2$-elliptic regularity ) Let $U$ is $C^2$ bounded domain, $g\in C^2(\bar U)$,$u\in C(\bar U)\cap C^2(U)$ is a classical solution of the Dirichlet problem $(1)$, where $a_{ij},b_i,c,f\in C(\bar U)$. Then $u\in C^2(\bar U)$. In addition, I also wonder the solvability of $(1)$ in function space $C^2(\bar U)$.Namely,is the following existence theorem valid？ THEOREM ($C^2$-existence) Let $U$ is $C^2$ bounded domain, $g\in C^2(\bar U)$, $c\leq 0$,$a_{ij},b_i,c,f\in C(\bar U)$. Then the Dirichlet problem $(1)$ has a unique solution $u\in C^2(\bar U)$. Any answer or reference is appreciated! :)",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'holder-spaces']"
35,How does $\sigma(T)$ change with respect to $T$?,How does  change with respect to ?,\sigma(T) T,"Consider $\sigma$ as a mapping which maps $T\in\mathcal{L}(X)$ to $\sigma(T)$, the spectrum of $T$, a compact set in the complex plane. I wonder whether there is some result concerning how $\sigma(T)$ changes when $T$ changes. For instance,  how is the Hausdorff distance between $\sigma(T)$ and $\sigma(S)$ related to $\|T-S\|$? Or something like this. Thanks!","Consider $\sigma$ as a mapping which maps $T\in\mathcal{L}(X)$ to $\sigma(T)$, the spectrum of $T$, a compact set in the complex plane. I wonder whether there is some result concerning how $\sigma(T)$ changes when $T$ changes. For instance,  how is the Hausdorff distance between $\sigma(T)$ and $\sigma(S)$ related to $\|T-S\|$? Or something like this. Thanks!",,"['reference-request', 'functional-analysis', 'banach-spaces', 'operator-theory', 'operator-algebras']"
36,Properties of dual spaces of sequence spaces,Properties of dual spaces of sequence spaces,,"Can you tell me if I got the following homework right? Nitpicking is welcome. a) Recall that $$ c_0 (\mathbb{N}) = \{ f: \mathbb{N} \rightarrow \mathbb{C} \mid \lim_{n \rightarrow \infty } f(n) = 0\} \subset l^\infty ( \mathbb{N}) $$ is a Banach space with respect to the supremum norm $\| . \|_\infty $. Show that  $(c_0(\mathbb{N}))^\ast \cong l^1(\mathbb{N})$ where the dual pairing is given by $$ \langle f, g \rangle = \sum_{n = 0}^\infty f(n) g(n)$$ for $f \in c_0(\mathbb{N})$ and $g \in l^1(\mathbb{N})$. b) Show that $(l^1(\mathbb{N}))^\ast \cong l^\infty(\mathbb{N})$ c) Compute the dual of $c(\mathbb{N}) = \{ f: \mathbb{N} \rightarrow \mathbb{C} | \lim_{n \rightarrow \infty} f(n) $ exists $\}$ d) Show that $l^1$ is not reflexive by showing that a Banach limit does not come from a pairing as above with an element of $l^1$ My answers: a) We want to show that $\varphi : l^1(\mathbb{N}) \rightarrow (c_0 (\mathbb{N}))^\ast$ defined by $g \mapsto \langle ., g\rangle$ is an isomorphism. First, I think, we need to verify that it maps into $(c_0 (\mathbb{N}))^\ast$. So let $f \in c_0(\mathbb{N})$. Then $$ | \langle f,g \rangle | = \Big | \sum_{n=0}^\infty f(n) g(n) \Big | \leq \sum_{n=0}^\infty |f(n)| |g(n)| \leq \| f \|_\infty \sum_{n=0}^\infty | g(n)| < \infty$$ Next we need to verify that it's a vector space homomorphism, that is, it's linear. For this, let $\alpha \in \mathbb{C}, g \in l^1(\mathbb{N})$ and $f_1 , f_2 \in c_0(\mathbb{N})$. Then $$ \langle \alpha (f_1 + f_2), g \rangle = \sum_{n=0}^\infty \alpha (f_1 + f_2)(n) g(n) = \alpha \sum_{n=0}^\infty f_1(n)g(n) + \alpha \sum_{n=0}^\infty f_2(n)g(n) = \alpha \langle f_1 , g \rangle + \alpha \langle f_2 , g \rangle$$ Next we need to show that $\varphi$ is injective. For this let $g \in l^1(\mathbb{N})$ such that $\langle f,g \rangle = 0$ for all $f$ in $c_0(\mathbb{N})$. Then in particular, $\langle f_N,g \rangle = 0$ for  $$ f_N (n) := \begin{cases} 1 & n = N \\ 0 & otherwise \end{cases}$$ So $g(n) = 0$ for all $n$ and so $\ker \varphi = \{ 0 \}$. The last thing to verify is that $\varphi$ is surjective. Consider any $\lambda \in c_0(\mathbb{N})^\ast$. For the next step $\mathbb{N}$ should be locally compact and Hausdorff. This would be the case if $\mathbb{N}$ had the discrete topology but the topology is not specified in the homework so I'm not so sure about the following: By Riesz-Markov there exists a unique regular countably additive complex Borel measure $\mu$ on $\mathbb{N}$ such that $\varphi(f) = \int_X f(x) d \mu$. Set $g(n) := \mu(n)$ then $\varphi(f) = \int_X f(x) d \mu = \sum_{n=0}^\infty f(n) g(n)$. $g(n) \in l^1$ because $\mu$ is regular and therefore has finite measure on each compact set, in particular $\{ n \}$. b) Here we need to verify that $\varphi^\prime: g \mapsto \langle ., g \rangle$ is an isomorphism where $g \in l^\infty(\mathbb{N})$. By the same arguments as in a) I showed that it maps into $(l^1 (\mathbb{N}))^\ast$, that it's a homomorphism and that it's injective. To verify that it's surjective, consider any $\lambda : l^1(\mathbb{N}) \rightarrow \mathbb{C}$. Then $\lambda$ can be split into positive real functions as follows: $\lambda = \Re (\lambda) + i \Im(\lambda) = \Re (\lambda)^+ - \Re (\lambda)^- + i \Im(\lambda)^+ - i \Im(\lambda)^-$. Then for each part separately, there exists a unique regular measure by the same argument as in a), so $\varphi^\prime$ is surjective. c) To compute $(c(\mathbb{N}))^\ast$ consider an $s \in c(\mathbb{N})$. Then $\lim_{n \rightarrow \infty} s_n = k$ for some $k \in \mathbb{C}$ and $\lim_{n \rightarrow \infty}(s_n - k) = 0$ so $(s_n - k)$ is an element of $c_0(\mathbb{N})$. Now I'm not sure about my next step. I suspected that if $V, V^\prime$ are isomorphic vector spaces then their duals $V^\ast$ and $(V^\prime)^\ast$ are isomorphic. So I constructed a bijective linear function from $c(\mathbb{N})$ into $c_0(\mathbb{N}) \times \mathbb{C}$ as follows: $s_n \mapsto (s_n - k, k)$ and verified that it's bijective and linear. d) To show that $l^1$ is not reflexive I used Kakutani's theorem which says that $l^1$ is reflexive if and only if the closed unit ball is weakly compact. To find an open cover of the unit ball that doesn't contain a finite subcover pick $B_1 (f) $, the ball of radius $1$ around $f$ for all $f$ with $\| f \| = 1$. Then any two such $f$ have distance $2$ and therefore no $f$ is in any $B_1 (f^\prime) $ for any $f^\prime$ with $\| f^\prime \| = 1$. There is an infinite number of $f$'s with $\| f \| = 1$ so any finite collection of balls $B_1 (f) $ leave an infinite number of $f$'s uncovered. So $l^1$ is not reflexive. Thanks for your help!","Can you tell me if I got the following homework right? Nitpicking is welcome. a) Recall that $$ c_0 (\mathbb{N}) = \{ f: \mathbb{N} \rightarrow \mathbb{C} \mid \lim_{n \rightarrow \infty } f(n) = 0\} \subset l^\infty ( \mathbb{N}) $$ is a Banach space with respect to the supremum norm $\| . \|_\infty $. Show that  $(c_0(\mathbb{N}))^\ast \cong l^1(\mathbb{N})$ where the dual pairing is given by $$ \langle f, g \rangle = \sum_{n = 0}^\infty f(n) g(n)$$ for $f \in c_0(\mathbb{N})$ and $g \in l^1(\mathbb{N})$. b) Show that $(l^1(\mathbb{N}))^\ast \cong l^\infty(\mathbb{N})$ c) Compute the dual of $c(\mathbb{N}) = \{ f: \mathbb{N} \rightarrow \mathbb{C} | \lim_{n \rightarrow \infty} f(n) $ exists $\}$ d) Show that $l^1$ is not reflexive by showing that a Banach limit does not come from a pairing as above with an element of $l^1$ My answers: a) We want to show that $\varphi : l^1(\mathbb{N}) \rightarrow (c_0 (\mathbb{N}))^\ast$ defined by $g \mapsto \langle ., g\rangle$ is an isomorphism. First, I think, we need to verify that it maps into $(c_0 (\mathbb{N}))^\ast$. So let $f \in c_0(\mathbb{N})$. Then $$ | \langle f,g \rangle | = \Big | \sum_{n=0}^\infty f(n) g(n) \Big | \leq \sum_{n=0}^\infty |f(n)| |g(n)| \leq \| f \|_\infty \sum_{n=0}^\infty | g(n)| < \infty$$ Next we need to verify that it's a vector space homomorphism, that is, it's linear. For this, let $\alpha \in \mathbb{C}, g \in l^1(\mathbb{N})$ and $f_1 , f_2 \in c_0(\mathbb{N})$. Then $$ \langle \alpha (f_1 + f_2), g \rangle = \sum_{n=0}^\infty \alpha (f_1 + f_2)(n) g(n) = \alpha \sum_{n=0}^\infty f_1(n)g(n) + \alpha \sum_{n=0}^\infty f_2(n)g(n) = \alpha \langle f_1 , g \rangle + \alpha \langle f_2 , g \rangle$$ Next we need to show that $\varphi$ is injective. For this let $g \in l^1(\mathbb{N})$ such that $\langle f,g \rangle = 0$ for all $f$ in $c_0(\mathbb{N})$. Then in particular, $\langle f_N,g \rangle = 0$ for  $$ f_N (n) := \begin{cases} 1 & n = N \\ 0 & otherwise \end{cases}$$ So $g(n) = 0$ for all $n$ and so $\ker \varphi = \{ 0 \}$. The last thing to verify is that $\varphi$ is surjective. Consider any $\lambda \in c_0(\mathbb{N})^\ast$. For the next step $\mathbb{N}$ should be locally compact and Hausdorff. This would be the case if $\mathbb{N}$ had the discrete topology but the topology is not specified in the homework so I'm not so sure about the following: By Riesz-Markov there exists a unique regular countably additive complex Borel measure $\mu$ on $\mathbb{N}$ such that $\varphi(f) = \int_X f(x) d \mu$. Set $g(n) := \mu(n)$ then $\varphi(f) = \int_X f(x) d \mu = \sum_{n=0}^\infty f(n) g(n)$. $g(n) \in l^1$ because $\mu$ is regular and therefore has finite measure on each compact set, in particular $\{ n \}$. b) Here we need to verify that $\varphi^\prime: g \mapsto \langle ., g \rangle$ is an isomorphism where $g \in l^\infty(\mathbb{N})$. By the same arguments as in a) I showed that it maps into $(l^1 (\mathbb{N}))^\ast$, that it's a homomorphism and that it's injective. To verify that it's surjective, consider any $\lambda : l^1(\mathbb{N}) \rightarrow \mathbb{C}$. Then $\lambda$ can be split into positive real functions as follows: $\lambda = \Re (\lambda) + i \Im(\lambda) = \Re (\lambda)^+ - \Re (\lambda)^- + i \Im(\lambda)^+ - i \Im(\lambda)^-$. Then for each part separately, there exists a unique regular measure by the same argument as in a), so $\varphi^\prime$ is surjective. c) To compute $(c(\mathbb{N}))^\ast$ consider an $s \in c(\mathbb{N})$. Then $\lim_{n \rightarrow \infty} s_n = k$ for some $k \in \mathbb{C}$ and $\lim_{n \rightarrow \infty}(s_n - k) = 0$ so $(s_n - k)$ is an element of $c_0(\mathbb{N})$. Now I'm not sure about my next step. I suspected that if $V, V^\prime$ are isomorphic vector spaces then their duals $V^\ast$ and $(V^\prime)^\ast$ are isomorphic. So I constructed a bijective linear function from $c(\mathbb{N})$ into $c_0(\mathbb{N}) \times \mathbb{C}$ as follows: $s_n \mapsto (s_n - k, k)$ and verified that it's bijective and linear. d) To show that $l^1$ is not reflexive I used Kakutani's theorem which says that $l^1$ is reflexive if and only if the closed unit ball is weakly compact. To find an open cover of the unit ball that doesn't contain a finite subcover pick $B_1 (f) $, the ball of radius $1$ around $f$ for all $f$ with $\| f \| = 1$. Then any two such $f$ have distance $2$ and therefore no $f$ is in any $B_1 (f^\prime) $ for any $f^\prime$ with $\| f^\prime \| = 1$. There is an infinite number of $f$'s with $\| f \| = 1$ so any finite collection of balls $B_1 (f) $ leave an infinite number of $f$'s uncovered. So $l^1$ is not reflexive. Thanks for your help!",,"['functional-analysis', 'banach-spaces']"
37,The dual of a Fréchet space.,The dual of a Fréchet space.,,"Let $\mathcal{F}$ be a Fréchet space (locally convex, Hausdorff, metrizable, with a family of seminorms $\{\|~\|_n\}$). I've read that the dual $\mathcal{F}^*$ is never a Fréchet space, unless $\mathcal{F}$ is actually a Banach space. I'd like to know in which ways the dual can fail to be Fréchet in general; for example, is it always incomplete as a metric space? Or is it always non-metrizable? What are the real issues here? If there's a relatively easy proof of this fact (that $\mathcal{F}^*$ is not Fréchet unless $\mathcal{F}$ is Banach), I would appreciate it as well. Thanks. [EDIT: The reference cited by Dirk contains a Theorem whose proof is inaccessible to me, so I'd upvote/accept an answer that at least sketches such a proof, or provides another way of settling the question. I'd also be interested in any further explanations regarding the statement that "" (...) a LCTVS cannot be a (non-trivial) projective limit and an inductive limit of countably infinite families of Banach spaces at the same time. "", made by Andrew Stacey in that link, which is related to my question.]","Let $\mathcal{F}$ be a Fréchet space (locally convex, Hausdorff, metrizable, with a family of seminorms $\{\|~\|_n\}$). I've read that the dual $\mathcal{F}^*$ is never a Fréchet space, unless $\mathcal{F}$ is actually a Banach space. I'd like to know in which ways the dual can fail to be Fréchet in general; for example, is it always incomplete as a metric space? Or is it always non-metrizable? What are the real issues here? If there's a relatively easy proof of this fact (that $\mathcal{F}^*$ is not Fréchet unless $\mathcal{F}$ is Banach), I would appreciate it as well. Thanks. [EDIT: The reference cited by Dirk contains a Theorem whose proof is inaccessible to me, so I'd upvote/accept an answer that at least sketches such a proof, or provides another way of settling the question. I'd also be interested in any further explanations regarding the statement that "" (...) a LCTVS cannot be a (non-trivial) projective limit and an inductive limit of countably infinite families of Banach spaces at the same time. "", made by Andrew Stacey in that link, which is related to my question.]",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
38,Eigenfunctions of the Helmholtz equation in Toroidal geometry,Eigenfunctions of the Helmholtz equation in Toroidal geometry,,"the Helmholtz equation $$\Delta \psi + k^2 \psi = 0$$ has a lot of fundamental applications in physics since it is a form of the wave equation $\Delta\phi - c^{-2}\partial_{tt}\phi = 0$ with an assumed harmonic time dependence $e^{\pm\mathrm{i}\omega t}$. $k$ can be seen as some kind of potential - the equation is analogue to the stationary Schrödinger equation . The existance of solutions is to my knowledge linked to the separability of the Laplacian $\Delta$ in certain coordinate systems. Examples are cartesian, elliptical and cylindrical ones. For now I am interested in a toroidal geometry,  $$k(\mathbf{r}) = \begin{cases} k_{to} & \mathbf{r}\in T^2 \\ k_{out} & \text{else}\end{cases}$$ where $T^2 = \left\{ (x,y,z):\, r^2 \geq \left(  \sqrt{x^2 + y^2} - R\right)^2 + z^2  \right\}$ Hence the question: Are there known solutions (in terms of eigenfunctions) of the Helmholtz equation for the given geometry? Thank you in advance Sincerely Robert Edit: As Hans pointed out, there might not be any solution according to a corresponding Wikipedia article . Unfortunately, there is no reference given - does anyone know where I could find the proof?","the Helmholtz equation $$\Delta \psi + k^2 \psi = 0$$ has a lot of fundamental applications in physics since it is a form of the wave equation $\Delta\phi - c^{-2}\partial_{tt}\phi = 0$ with an assumed harmonic time dependence $e^{\pm\mathrm{i}\omega t}$. $k$ can be seen as some kind of potential - the equation is analogue to the stationary Schrödinger equation . The existance of solutions is to my knowledge linked to the separability of the Laplacian $\Delta$ in certain coordinate systems. Examples are cartesian, elliptical and cylindrical ones. For now I am interested in a toroidal geometry,  $$k(\mathbf{r}) = \begin{cases} k_{to} & \mathbf{r}\in T^2 \\ k_{out} & \text{else}\end{cases}$$ where $T^2 = \left\{ (x,y,z):\, r^2 \geq \left(  \sqrt{x^2 + y^2} - R\right)^2 + z^2  \right\}$ Hence the question: Are there known solutions (in terms of eigenfunctions) of the Helmholtz equation for the given geometry? Thank you in advance Sincerely Robert Edit: As Hans pointed out, there might not be any solution according to a corresponding Wikipedia article . Unfortunately, there is no reference given - does anyone know where I could find the proof?",,"['functional-analysis', 'partial-differential-equations', 'physics']"
39,Weak derivative zero implies constant function,Weak derivative zero implies constant function,,"Let $u\in W^{1,p}(U)$ such that $Du=0$ a.e. on $U$. I have to prove that $u$ is constant a.e. on $U$. Take $(\rho_{\varepsilon})_{\varepsilon>0}$ mollifiers. I know that $D(u\ast\rho_{\varepsilon})=Du\ast\rho_{\varepsilon}$, so $u\ast\rho_{\varepsilon}(x)=c $ for every $x\in U$, since it is a smooth function. How can I conclude?","Let $u\in W^{1,p}(U)$ such that $Du=0$ a.e. on $U$. I have to prove that $u$ is constant a.e. on $U$. Take $(\rho_{\varepsilon})_{\varepsilon>0}$ mollifiers. I know that $D(u\ast\rho_{\varepsilon})=Du\ast\rho_{\varepsilon}$, so $u\ast\rho_{\varepsilon}(x)=c $ for every $x\in U$, since it is a smooth function. How can I conclude?",,"['functional-analysis', 'partial-differential-equations', 'weak-derivatives']"
40,"When viewing Sobolev spaces as completions, how does the notion of weak derivative arise?","When viewing Sobolev spaces as completions, how does the notion of weak derivative arise?",,"Suppose instead of defining the Sobolev spaces $W^{k,p}(\Omega), \Omega\subset\Bbb R^n$ as the space of functions whose Sobolev norm (with weak derivatives) is finite, we define it as the completion of the subset of $C^\infty(\Omega)$ functions whose Sobolev norm is finite (call it $C^{k,p}(\Omega)$). By a theorem of topology, these spaces are homeomorphic, since $C^{k,p}(\Omega)$ is dense in both $W^{k,p}(\Omega)$ and $\text{comp}(C^{k,p}(\Omega))$. So while these constructions are equivalent...that's not very clear. For instance, it is not clear what $Df$ is supposed to mean, when $f$ is an equivalence class of Cauchy sequences in $C^{k,p}(\Omega)$. (I also don't know how to interpret the equivalent class as a function $f:\Omega\to\Bbb R$ in the first place. I imagine it is an equivalence class of functions that agree a.e. somehow.) In the ""standard"" viewpoint, we have that $Df$ is just the weak derivative. So how does one interpret what $Df$ means in the completion viewpoint, and can one show that $\int Df\varphi=-\int fD\varphi$, $\forall \varphi\in C^1_0(\Omega)$, just like for weak derivatives? If this makes sense for $\Bbb R^n$, then I would like to understand it on manifolds. The completion viewpoint seems to be dominant in the geometric analysis literature, but no one explains what $\nabla f$ is actually supposed to be. In Chavel ( Eigenvales in Riem. Geo. ), we find: Given a function $f\in L^2(M)$, we say that $Y\in\mathscr L^2(M)$ is a weak derivative of $f$ if    $$\int_M\langle Y,X\rangle=-\int_M f\operatorname{div}(X)$$   for all compactly supported $C^1$ vector fields $X$. (Here $\mathscr L^2(M)$ are the square integrable vector fields.) Now, this viewpoint is somewhat different from the usual PDE one since we use compactly supported vector fields...but I suppose this is just a reflection of the fact that $\partial f/\partial x^i$ has no intrinsic meaning on a manifold. I am either looking for someone to clear up my questions here, or give a good reference on this subject.","Suppose instead of defining the Sobolev spaces $W^{k,p}(\Omega), \Omega\subset\Bbb R^n$ as the space of functions whose Sobolev norm (with weak derivatives) is finite, we define it as the completion of the subset of $C^\infty(\Omega)$ functions whose Sobolev norm is finite (call it $C^{k,p}(\Omega)$). By a theorem of topology, these spaces are homeomorphic, since $C^{k,p}(\Omega)$ is dense in both $W^{k,p}(\Omega)$ and $\text{comp}(C^{k,p}(\Omega))$. So while these constructions are equivalent...that's not very clear. For instance, it is not clear what $Df$ is supposed to mean, when $f$ is an equivalence class of Cauchy sequences in $C^{k,p}(\Omega)$. (I also don't know how to interpret the equivalent class as a function $f:\Omega\to\Bbb R$ in the first place. I imagine it is an equivalence class of functions that agree a.e. somehow.) In the ""standard"" viewpoint, we have that $Df$ is just the weak derivative. So how does one interpret what $Df$ means in the completion viewpoint, and can one show that $\int Df\varphi=-\int fD\varphi$, $\forall \varphi\in C^1_0(\Omega)$, just like for weak derivatives? If this makes sense for $\Bbb R^n$, then I would like to understand it on manifolds. The completion viewpoint seems to be dominant in the geometric analysis literature, but no one explains what $\nabla f$ is actually supposed to be. In Chavel ( Eigenvales in Riem. Geo. ), we find: Given a function $f\in L^2(M)$, we say that $Y\in\mathscr L^2(M)$ is a weak derivative of $f$ if    $$\int_M\langle Y,X\rangle=-\int_M f\operatorname{div}(X)$$   for all compactly supported $C^1$ vector fields $X$. (Here $\mathscr L^2(M)$ are the square integrable vector fields.) Now, this viewpoint is somewhat different from the usual PDE one since we use compactly supported vector fields...but I suppose this is just a reflection of the fact that $\partial f/\partial x^i$ has no intrinsic meaning on a manifold. I am either looking for someone to clear up my questions here, or give a good reference on this subject.",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'riemannian-geometry', 'sobolev-spaces']"
41,"Are Sobolev spaces $W^{k,1}(\mathbb R^d)$ and $H^{k,1}(\mathbb R^d)$ the same?",Are Sobolev spaces  and  the same?,"W^{k,1}(\mathbb R^d) H^{k,1}(\mathbb R^d)","We consider the following spaces $H^{k,p}(\mathbb R^d)$, $k \geq 1$ is integer, $p \geq 1$ (Bessel potential spaces): $$    H^{k,p}(\mathbb R^d) = \bigl\{ f \in L^p(\mathbb R^d) \colon \mathcal F^{-1}[(1+|\xi|^2)^{\frac k 2} \mathcal F f] \in L^p(\mathbb R^d) \bigr\}, $$ where $\mathcal F$ is the Fourier transform. We also consider the classical Sobolev spaces $$    W^{k,p}(\mathbb R^d) = \bigl\{ f \in L^p(\mathbb R^d) \colon D^\alpha f \in L^p(\mathbb R^d), \; |\alpha| \leq k \bigr\}, $$ where $D^\alpha$ is the derivative of multi-order $\alpha$. It is written in Wikipedia that for $p>1$ we have $H^{k,p}(\mathbb R^d) = W^{k,p}(\mathbb R^d)$. My question is what is the relation between the spaces $H^{k,1}(\mathbb R^d)$ and $W^{k,1}(\mathbb R^d)$? Are they still equal? For example, if $f \in W^{k,1}(\mathbb R^d)$, then all derivatives of $f$ up to order $k$ are in $L^1(\mathbb R^d)$ and hence $(1+|\xi|^2)^{\frac k 2}\mathcal F f \in L^\infty(\mathbb R^d)$. But it is not clear that the latter function is the Fourier transform of some function from $L^1(\mathbb R^d)$ (if it the case, we have $W^{k,1}(\mathbb R^d) \subseteq H^{k,1}(\mathbb R^d)$). On the other hand, if $f \in H^{k,1}(\mathbb R^d)$ then $f \in L^1(\mathbb R^d)$ and $(1+|\xi|^2)^{\frac k 2}\mathcal F f \in L^\infty(\mathbb R^d)$. I am not sure that it implies that $f$ has distributional derivatives in $L^1(\mathbb R^d)$ up to order $k$ (it would imply $H^{k,1}(\mathbb R^d) \subseteq W^{k,1}(\mathbb R^d)$).","We consider the following spaces $H^{k,p}(\mathbb R^d)$, $k \geq 1$ is integer, $p \geq 1$ (Bessel potential spaces): $$    H^{k,p}(\mathbb R^d) = \bigl\{ f \in L^p(\mathbb R^d) \colon \mathcal F^{-1}[(1+|\xi|^2)^{\frac k 2} \mathcal F f] \in L^p(\mathbb R^d) \bigr\}, $$ where $\mathcal F$ is the Fourier transform. We also consider the classical Sobolev spaces $$    W^{k,p}(\mathbb R^d) = \bigl\{ f \in L^p(\mathbb R^d) \colon D^\alpha f \in L^p(\mathbb R^d), \; |\alpha| \leq k \bigr\}, $$ where $D^\alpha$ is the derivative of multi-order $\alpha$. It is written in Wikipedia that for $p>1$ we have $H^{k,p}(\mathbb R^d) = W^{k,p}(\mathbb R^d)$. My question is what is the relation between the spaces $H^{k,1}(\mathbb R^d)$ and $W^{k,1}(\mathbb R^d)$? Are they still equal? For example, if $f \in W^{k,1}(\mathbb R^d)$, then all derivatives of $f$ up to order $k$ are in $L^1(\mathbb R^d)$ and hence $(1+|\xi|^2)^{\frac k 2}\mathcal F f \in L^\infty(\mathbb R^d)$. But it is not clear that the latter function is the Fourier transform of some function from $L^1(\mathbb R^d)$ (if it the case, we have $W^{k,1}(\mathbb R^d) \subseteq H^{k,1}(\mathbb R^d)$). On the other hand, if $f \in H^{k,1}(\mathbb R^d)$ then $f \in L^1(\mathbb R^d)$ and $(1+|\xi|^2)^{\frac k 2}\mathcal F f \in L^\infty(\mathbb R^d)$. I am not sure that it implies that $f$ has distributional derivatives in $L^1(\mathbb R^d)$ up to order $k$ (it would imply $H^{k,1}(\mathbb R^d) \subseteq W^{k,1}(\mathbb R^d)$).",,"['functional-analysis', 'sobolev-spaces', 'harmonic-analysis']"
42,Motivation of Feynman-Kac formula and its relation to Kolmogorov backward/forward equations?,Motivation of Feynman-Kac formula and its relation to Kolmogorov backward/forward equations?,,"Kolmogorov backward/forward equations are pdes, derived for the semigroups constructed from the Markov transition kernels. Feynman-Kac formula is also a pde corresponding to a stochastic process defined by a SDE.  But I was wondering if the stochastic process is also Markovian? I.e., does Feynman-Kac formula apply only to Markov process? Does the semigroups from the Markov transition kernels also lead to Feynman-kac pde? If not, what leads to Feynman-Kac pde? If yes, Is Feynman-Kac pde also some kind of Kolmogorov backward/forward equation? if not, how is Feynman-Kac pde related to Kolmogorov backward/forward equations? Thanks and regards!","Kolmogorov backward/forward equations are pdes, derived for the semigroups constructed from the Markov transition kernels. Feynman-Kac formula is also a pde corresponding to a stochastic process defined by a SDE.  But I was wondering if the stochastic process is also Markovian? I.e., does Feynman-Kac formula apply only to Markov process? Does the semigroups from the Markov transition kernels also lead to Feynman-kac pde? If not, what leads to Feynman-Kac pde? If yes, Is Feynman-Kac pde also some kind of Kolmogorov backward/forward equation? if not, how is Feynman-Kac pde related to Kolmogorov backward/forward equations? Thanks and regards!",,"['functional-analysis', 'partial-differential-equations', 'stochastic-processes', 'stochastic-calculus', 'markov-process']"
43,$(n^2 \alpha \bmod 1)$ is equidistributed in $\mathbb{T}^2$ if $\alpha \in \mathbb{R} \setminus \mathbb{Q}$,is equidistributed in  if,(n^2 \alpha \bmod 1) \mathbb{T}^2 \alpha \in \mathbb{R} \setminus \mathbb{Q},"I did the following homework question, can you tell me if I have it right? We want to show that the sequence $(n^2 \alpha \bmod 1)$ is equidistributed if $\alpha \in \mathbb{R} \setminus \mathbb{Q}$. To that end we consider the transformation $T: (x,y) \mapsto (x + \alpha, y + 2x + \alpha)$ on the $2$-dimensional torus $\mathbb{T}^2$ endowed with the Lebesgue measure $\lambda \times \lambda$. a) Show that the action of $T$ on the torus is ergodic, i.e., if a measurable set $A \subset \mathbb{T}^2$ is invariant under $T$, then $(\lambda \times \lambda)(A) \in \{0, 1\}$. Show this by checking the following equivalent definition of ergodicity: $\forall f \in L^2( \mathbb{T}^2)$, we have: if $f$ is $T$-invariant, then $f$ has to be constant almost everywhere. Hint: Use Fourier series. My answer: $$  \begin{align} f(x,y) &= \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ijx} e^{iky} \\ &\stackrel{f = f\circ T}{=} \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ij(x + \alpha)} e^{ik(y + 2x + \alpha)}  \\ &= \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ij\alpha + ik\alpha} e^{ijx + ik2x}e^{iky} \\ &\stackrel{j \rightarrow j-2k}{=} \sum_{j,k \in \mathbb{Z}} c_{(j-2k)k} e^{i(j-k)\alpha} e^{ijx}e^{iky} . \end{align}$$ Now we want $c_{jk} = c_{(j-2k)k} e^{i(j-k)\alpha}$, and we have $|c_{jk}| = |c_{(j-2k)k}| = |c_{(j-4k)k}| = \cdots$, and so on. The series only converges if $|c_{(j-4k)k}| \; \xrightarrow{k \rightarrow \infty} \; 0$ and so $c_{jk}$ has to be $0$, too. b) For $x \in \mathbb{T}$ show that $$ \frac{1}{m} \sum_{n=1}^m T^n_\ast (\delta_x \times \lambda) \rightarrow \lambda \times \lambda$$ using the equidistribution of $(n \alpha \bmod 1)$. My answer: $$  \begin{align} \frac{1}{m} \sum_{n=1}^m T_\ast^n(\delta_x \times \lambda (A \times B))  &=  \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda ((T^{-1})^n(A \times B))  \\ &=  \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda (T^n(A \times B)) , \end{align} $$ where I have the last equality because it doesn't matter which way the points are shifted. Then writing out what $T^n$ does I get: $$  \begin{align} \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda (T^n(A \times B))  &=  \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda ( (A + \alpha n) \times (B + \alpha n) ) \\ &= \frac{1}{m} \sum_{n=1}^m \delta_x (A + \alpha n) \lambda(B + \alpha n) \\ &= \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B + \alpha n) . \end{align} $$ And then using that the Lebesgue measure $\lambda$ is translation invariant I get: $$ \begin{align} \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B + \alpha n) =  \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B) . \end{align} $$ And finally, by using the ergodic theorem: $$ \begin{align} \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B)= \lambda(B) \int_{\mathbb{T}} \chi_{A + \alpha n} (x) d \lambda(x) = \lambda(B)\lambda(A) = \lambda \times \lambda (A \times B) . \end{align} $$ c) For $\eta \in (0,1)$ and $x,y \in \mathbb{T}$ define the two sequences $$  \begin{align*} \mu_m &=  \frac{1}{m} \sum_{n=1}^m T^n_\ast \left(\delta_x \times \left(\frac{1}{2 \eta} \left. \lambda \right \vert_{[y-\eta, y + \eta]} \right) \right) \\ \nu_m &=  \frac{1}{m} \sum_{n=1}^m T^n_\ast \left(\delta_x \times \left( \frac{1}{1 - 2 \eta} \left. \lambda \right\vert_{\mathbb{T} \smallsetminus [y-\eta, y + \eta]} \right) \right) \end{align*} $$ Using exercise 3 of assignment 10 and weak$^\ast$-compactness of the unit ball we know that there exists a subsequence in $\mathbb{N}$ such that both sequences converge along these subsequences. Call the limit points $\mu$ and $\nu$ respectively. Show that $2 \eta \mu + (1 - 2 \eta) \nu = \lambda \times \lambda$. My answer: Exercies 3 of assignment 10 was to show that any weak$^\ast$ limit point $\mu$ of the sequence $\mu_n = \frac{1}{n}\sum_{j=0}^{n-1} T_\ast^j \nu_n$ is a Borel probability measure with $\mu = T_\ast \mu$. $$ 2 \eta \lim_{m \to \infty} \frac{1}{m} \sum_{n=1}^m T_\ast^n \left(\delta_x \times \left( \frac{1}{2 \eta} \left. \lambda \right\vert_{[y- \eta, y + \eta]} \right) \right) +  (1 - 2 \eta) \lim_{m \to \infty} \frac{1}{m} \sum_{n=1}^m T_\ast^n \left( \delta_x \times \left( \frac{1}{1- 2 \eta} \left.  \lambda \right\vert_{\mathbb{T} \smallsetminus [y- \eta, y + \eta]} \right) \right) , $$ which, by part (b), is equal to  $$ \left. \lambda \times \lambda \right\vert_{[y - \eta , y + \eta]} +  \left. \lambda \times \lambda \right \vert_{\mathbb{T} \smallsetminus [y - \eta , y + \eta]} = \lambda \times \lambda. $$ d) Using the following proposition, show that $\mu = \lambda \times \lambda$. Proposition: A $T$-invariant probability measure is extremal if and only if its action is ergodic. My answer: Distinguish the cases $\eta \geq \frac{1}{2}$ and $\eta < \frac{1}{2}$. If  $\eta < \frac{1}{2}$ then by c) $\lambda \times \lambda = 2 \eta \mu + (1 - 2 \eta) \nu$ and since $2 \eta < 1$, by extremality, $\lambda \times \lambda = \mu = \nu$. If $\eta \geq \frac{1}{2}$ then $[y - \eta , y + \eta] = \mathbb{T}$ and so $$ \begin{align} \mu(A \times B) &= \lim_{m \to \infty} \mu_m (A \times B)  \\ &= \lim_{m \to \infty} \frac{1}{m} \frac{1}{2 \eta} \sum_{n=1}^m \chi_A(x + \alpha n) \lambda \mid_{[y - \eta , y + \eta]} (B) \\ &\stackrel{b)}{=} \frac{1}{ 2 \eta} \lambda \times \lambda \end{align}$$ So I think I got the sums wrong here. e) Show that $\mu_m \to \lambda \times \lambda$. To that end prove and apply the following: Lemma: Let $X$ be a metric space and $x \in X$, $x_n$ a sequence in $X$. Assume that each subsequence of $x_n$ has a subsequence converging to $x$. Then $x_n$ itself converges to $x$. My answer: Assume that $x_n$ converges to $y \neq x$. Then there is a (sub)sequence (the sequence itself is a subsequence) not converging to $x$. Contradiction. Same argument for $x_n$ diverges. Now with c) and d), $\mu_m \to \mu = \lambda \times \lambda$. I'm stuck on: f) Show that for all $f \in C(\mathbb{T}^2)$ and for all $\varepsilon > 0$, there exists $\eta > 0$ such that we have $$  \left\vert \int f d \mu_m - \int f d \omega_m  \right\vert < \varepsilon ,$$ where $$ \omega_m = \frac{1}{m} \sum_{n=1}^m T^n_\ast (\delta_x \times \delta_y) .$$ Thanks for your help!","I did the following homework question, can you tell me if I have it right? We want to show that the sequence $(n^2 \alpha \bmod 1)$ is equidistributed if $\alpha \in \mathbb{R} \setminus \mathbb{Q}$. To that end we consider the transformation $T: (x,y) \mapsto (x + \alpha, y + 2x + \alpha)$ on the $2$-dimensional torus $\mathbb{T}^2$ endowed with the Lebesgue measure $\lambda \times \lambda$. a) Show that the action of $T$ on the torus is ergodic, i.e., if a measurable set $A \subset \mathbb{T}^2$ is invariant under $T$, then $(\lambda \times \lambda)(A) \in \{0, 1\}$. Show this by checking the following equivalent definition of ergodicity: $\forall f \in L^2( \mathbb{T}^2)$, we have: if $f$ is $T$-invariant, then $f$ has to be constant almost everywhere. Hint: Use Fourier series. My answer: $$  \begin{align} f(x,y) &= \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ijx} e^{iky} \\ &\stackrel{f = f\circ T}{=} \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ij(x + \alpha)} e^{ik(y + 2x + \alpha)}  \\ &= \sum_{j,k \in \mathbb{Z}} c_{jk} e^{ij\alpha + ik\alpha} e^{ijx + ik2x}e^{iky} \\ &\stackrel{j \rightarrow j-2k}{=} \sum_{j,k \in \mathbb{Z}} c_{(j-2k)k} e^{i(j-k)\alpha} e^{ijx}e^{iky} . \end{align}$$ Now we want $c_{jk} = c_{(j-2k)k} e^{i(j-k)\alpha}$, and we have $|c_{jk}| = |c_{(j-2k)k}| = |c_{(j-4k)k}| = \cdots$, and so on. The series only converges if $|c_{(j-4k)k}| \; \xrightarrow{k \rightarrow \infty} \; 0$ and so $c_{jk}$ has to be $0$, too. b) For $x \in \mathbb{T}$ show that $$ \frac{1}{m} \sum_{n=1}^m T^n_\ast (\delta_x \times \lambda) \rightarrow \lambda \times \lambda$$ using the equidistribution of $(n \alpha \bmod 1)$. My answer: $$  \begin{align} \frac{1}{m} \sum_{n=1}^m T_\ast^n(\delta_x \times \lambda (A \times B))  &=  \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda ((T^{-1})^n(A \times B))  \\ &=  \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda (T^n(A \times B)) , \end{align} $$ where I have the last equality because it doesn't matter which way the points are shifted. Then writing out what $T^n$ does I get: $$  \begin{align} \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda (T^n(A \times B))  &=  \frac{1}{m} \sum_{n=1}^m \delta_x \times \lambda ( (A + \alpha n) \times (B + \alpha n) ) \\ &= \frac{1}{m} \sum_{n=1}^m \delta_x (A + \alpha n) \lambda(B + \alpha n) \\ &= \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B + \alpha n) . \end{align} $$ And then using that the Lebesgue measure $\lambda$ is translation invariant I get: $$ \begin{align} \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B + \alpha n) =  \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B) . \end{align} $$ And finally, by using the ergodic theorem: $$ \begin{align} \frac{1}{m} \sum_{n=1}^m \chi_{A + \alpha n}(x) \lambda(B)= \lambda(B) \int_{\mathbb{T}} \chi_{A + \alpha n} (x) d \lambda(x) = \lambda(B)\lambda(A) = \lambda \times \lambda (A \times B) . \end{align} $$ c) For $\eta \in (0,1)$ and $x,y \in \mathbb{T}$ define the two sequences $$  \begin{align*} \mu_m &=  \frac{1}{m} \sum_{n=1}^m T^n_\ast \left(\delta_x \times \left(\frac{1}{2 \eta} \left. \lambda \right \vert_{[y-\eta, y + \eta]} \right) \right) \\ \nu_m &=  \frac{1}{m} \sum_{n=1}^m T^n_\ast \left(\delta_x \times \left( \frac{1}{1 - 2 \eta} \left. \lambda \right\vert_{\mathbb{T} \smallsetminus [y-\eta, y + \eta]} \right) \right) \end{align*} $$ Using exercise 3 of assignment 10 and weak$^\ast$-compactness of the unit ball we know that there exists a subsequence in $\mathbb{N}$ such that both sequences converge along these subsequences. Call the limit points $\mu$ and $\nu$ respectively. Show that $2 \eta \mu + (1 - 2 \eta) \nu = \lambda \times \lambda$. My answer: Exercies 3 of assignment 10 was to show that any weak$^\ast$ limit point $\mu$ of the sequence $\mu_n = \frac{1}{n}\sum_{j=0}^{n-1} T_\ast^j \nu_n$ is a Borel probability measure with $\mu = T_\ast \mu$. $$ 2 \eta \lim_{m \to \infty} \frac{1}{m} \sum_{n=1}^m T_\ast^n \left(\delta_x \times \left( \frac{1}{2 \eta} \left. \lambda \right\vert_{[y- \eta, y + \eta]} \right) \right) +  (1 - 2 \eta) \lim_{m \to \infty} \frac{1}{m} \sum_{n=1}^m T_\ast^n \left( \delta_x \times \left( \frac{1}{1- 2 \eta} \left.  \lambda \right\vert_{\mathbb{T} \smallsetminus [y- \eta, y + \eta]} \right) \right) , $$ which, by part (b), is equal to  $$ \left. \lambda \times \lambda \right\vert_{[y - \eta , y + \eta]} +  \left. \lambda \times \lambda \right \vert_{\mathbb{T} \smallsetminus [y - \eta , y + \eta]} = \lambda \times \lambda. $$ d) Using the following proposition, show that $\mu = \lambda \times \lambda$. Proposition: A $T$-invariant probability measure is extremal if and only if its action is ergodic. My answer: Distinguish the cases $\eta \geq \frac{1}{2}$ and $\eta < \frac{1}{2}$. If  $\eta < \frac{1}{2}$ then by c) $\lambda \times \lambda = 2 \eta \mu + (1 - 2 \eta) \nu$ and since $2 \eta < 1$, by extremality, $\lambda \times \lambda = \mu = \nu$. If $\eta \geq \frac{1}{2}$ then $[y - \eta , y + \eta] = \mathbb{T}$ and so $$ \begin{align} \mu(A \times B) &= \lim_{m \to \infty} \mu_m (A \times B)  \\ &= \lim_{m \to \infty} \frac{1}{m} \frac{1}{2 \eta} \sum_{n=1}^m \chi_A(x + \alpha n) \lambda \mid_{[y - \eta , y + \eta]} (B) \\ &\stackrel{b)}{=} \frac{1}{ 2 \eta} \lambda \times \lambda \end{align}$$ So I think I got the sums wrong here. e) Show that $\mu_m \to \lambda \times \lambda$. To that end prove and apply the following: Lemma: Let $X$ be a metric space and $x \in X$, $x_n$ a sequence in $X$. Assume that each subsequence of $x_n$ has a subsequence converging to $x$. Then $x_n$ itself converges to $x$. My answer: Assume that $x_n$ converges to $y \neq x$. Then there is a (sub)sequence (the sequence itself is a subsequence) not converging to $x$. Contradiction. Same argument for $x_n$ diverges. Now with c) and d), $\mu_m \to \mu = \lambda \times \lambda$. I'm stuck on: f) Show that for all $f \in C(\mathbb{T}^2)$ and for all $\varepsilon > 0$, there exists $\eta > 0$ such that we have $$  \left\vert \int f d \mu_m - \int f d \omega_m  \right\vert < \varepsilon ,$$ where $$ \omega_m = \frac{1}{m} \sum_{n=1}^m T^n_\ast (\delta_x \times \delta_y) .$$ Thanks for your help!",,"['functional-analysis', 'ergodic-theory', 'equidistribution']"
44,Can all continuous linear operators on a function space be represented using integrals?,Can all continuous linear operators on a function space be represented using integrals?,,"A linear functional $\omega:v\mapsto\omega(v)$ on a finite dimensional vector space $X$ of dimension $N$ with an inner product $(·\ ,·)$  is an element of the dual vector space $X'$, and a couple of isomorphisms later I'll find  $$\omega(v)=(\omega,v).$$ Now the Riesz representation theorem for $L^p(\Omega)$, $1\le p<\infty$, says that for some $\omega\in L^p(\Omega)'$, there is an $u\in L^q(\Omega)$ with $$\omega(v)=\int_\Omega u(x)v(x) \mathbb{d}x.$$ Secondly, a continuous endomorphism $A: v\mapsto A(v)$ of a finite dimensional vector space can naturally be represented by a matrix with $N^2$ coefficients $A_n^{p}$, which acts on the vectors as $$(A(v))_n=\sum_{p=1}^NA_n^{p}v_p.$$ My question now is if every linear map $A: f\mapsto A(f)$ on function spaces can represented similar to the matrixes operation, i.e. as $$(A(f))(x) = \int_\Omega A(x,p)f(p) \mathbb{d}p,$$ even if this might only be true in a distributional sense. Clearly $f(x) \mapsto \int A(x,p)f(p) \mathbb{d}p$ is a linear map and besides the regular examples where $A(x,p)$ is really just a nice function itself (like for the Fourier transformation with $A(x,p)=e^{\mathbb{i}xp}$), I am aware of distributions like the Dirac delta $``A(x,p)=\delta(x-p)´´$, which for example represents the identity $f(x) \mapsto \int \delta(x-p)f(p) \mathbb{d}p = f(x)$. But do i get everything this way? Can I write all operators using an integral which a priori gathers information of the function $f(x)$ on its whole domain? The question arose when I ask for an ``matrix-like´´ representation of common linear operators like  $$D\equiv\frac{\partial}{\partial x}: f(x)\mapsto f'(x).$$  I guess $``D=-\delta'\ ´´$ works since $$f(x)\mapsto(D(f))(x)=\int (-\delta'(x-p))f(p) \mathbb{d}p=\int \delta(x-p)f'(p) \mathbb{d}p=f'(x).$$ But are there even integral representations for, say, $\Delta=\sum_i\frac{\partial^i}{\partial x^i}$ or even the Laplace–Beltrami operator? Maybe using nesting of delta-distributions and metric-coefficient functions? Is this possible, is it useful in any sense, and are there more difficult linear operators than that? And if not, why? Is it advantageous to view the linear operators on function spaces like that?","A linear functional $\omega:v\mapsto\omega(v)$ on a finite dimensional vector space $X$ of dimension $N$ with an inner product $(·\ ,·)$  is an element of the dual vector space $X'$, and a couple of isomorphisms later I'll find  $$\omega(v)=(\omega,v).$$ Now the Riesz representation theorem for $L^p(\Omega)$, $1\le p<\infty$, says that for some $\omega\in L^p(\Omega)'$, there is an $u\in L^q(\Omega)$ with $$\omega(v)=\int_\Omega u(x)v(x) \mathbb{d}x.$$ Secondly, a continuous endomorphism $A: v\mapsto A(v)$ of a finite dimensional vector space can naturally be represented by a matrix with $N^2$ coefficients $A_n^{p}$, which acts on the vectors as $$(A(v))_n=\sum_{p=1}^NA_n^{p}v_p.$$ My question now is if every linear map $A: f\mapsto A(f)$ on function spaces can represented similar to the matrixes operation, i.e. as $$(A(f))(x) = \int_\Omega A(x,p)f(p) \mathbb{d}p,$$ even if this might only be true in a distributional sense. Clearly $f(x) \mapsto \int A(x,p)f(p) \mathbb{d}p$ is a linear map and besides the regular examples where $A(x,p)$ is really just a nice function itself (like for the Fourier transformation with $A(x,p)=e^{\mathbb{i}xp}$), I am aware of distributions like the Dirac delta $``A(x,p)=\delta(x-p)´´$, which for example represents the identity $f(x) \mapsto \int \delta(x-p)f(p) \mathbb{d}p = f(x)$. But do i get everything this way? Can I write all operators using an integral which a priori gathers information of the function $f(x)$ on its whole domain? The question arose when I ask for an ``matrix-like´´ representation of common linear operators like  $$D\equiv\frac{\partial}{\partial x}: f(x)\mapsto f'(x).$$  I guess $``D=-\delta'\ ´´$ works since $$f(x)\mapsto(D(f))(x)=\int (-\delta'(x-p))f(p) \mathbb{d}p=\int \delta(x-p)f'(p) \mathbb{d}p=f'(x).$$ But are there even integral representations for, say, $\Delta=\sum_i\frac{\partial^i}{\partial x^i}$ or even the Laplace–Beltrami operator? Maybe using nesting of delta-distributions and metric-coefficient functions? Is this possible, is it useful in any sense, and are there more difficult linear operators than that? And if not, why? Is it advantageous to view the linear operators on function spaces like that?",,['functional-analysis']
45,Definition of resolvent set,Definition of resolvent set,,"I'm having trouble understanding some subtlety of definition of resolvent set for given bounded operator A everywhere defined on some Hilbert space. Book I use (and many other sources) give the following:  $\lambda \in \mathbb C $ is in resolvent set if $ R_{ \lambda} = ( \lambda \mathbb I - A ) ^ {-1} $ exists, is bounded and range of $\lambda \mathbb I -A$ is dense. Now my reasoning begins. This range is also domain of resolvent. Since it is bounded operator on dense domain it can be extended to whole Hilbert space by continuity. $ ( \lambda \mathbb I - A ) R_{\lambda}$ is equal to identity on dense subset so its extension is identity on whole Hilbert space. Similarly $R_{\lambda} (\lambda \mathbb I - A ) $ is identity on whole Hilbert space by definition of resolvent. But this means that $A - \lambda \mathbb I$ is bijection because it has left and right inverse. Therefore its range is actually whole Hilbert space. But if that is the case, why everyone demands it to be merely a dense subset?","I'm having trouble understanding some subtlety of definition of resolvent set for given bounded operator A everywhere defined on some Hilbert space. Book I use (and many other sources) give the following:  $\lambda \in \mathbb C $ is in resolvent set if $ R_{ \lambda} = ( \lambda \mathbb I - A ) ^ {-1} $ exists, is bounded and range of $\lambda \mathbb I -A$ is dense. Now my reasoning begins. This range is also domain of resolvent. Since it is bounded operator on dense domain it can be extended to whole Hilbert space by continuity. $ ( \lambda \mathbb I - A ) R_{\lambda}$ is equal to identity on dense subset so its extension is identity on whole Hilbert space. Similarly $R_{\lambda} (\lambda \mathbb I - A ) $ is identity on whole Hilbert space by definition of resolvent. But this means that $A - \lambda \mathbb I$ is bijection because it has left and right inverse. Therefore its range is actually whole Hilbert space. But if that is the case, why everyone demands it to be merely a dense subset?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
46,"Prove that $C^1[0,1]$ is not complete with norms [duplicate]",Prove that  is not complete with norms [duplicate],"C^1[0,1]","This question already has answers here : Example to prove that $ C^1[0,1] $ is not a Banach space for the uniform norm? (2 answers) $C([0, 1])$ is not complete with respect to the norm $\lVert f\rVert _1 = \int_0^1 \lvert f (x) \rvert \,dx$ (2 answers) Closed 8 years ago . I have to show that the $C^1[0,1]$ is not complete with any of these norms: $\|f\|_{\infty}=\sup_{x\in[0,1]}|f(x)|$ $\|f\|_{*}=|f(0)|+\int_0^1|f'(x)|dx$ My attempt The right sequence for the first norm is $f_n=\sqrt{x+\frac{1}{n}}$. Notice that $\forall n\in\mathbb{N} : f_n\in C^1[0,1]$ Let $f=\sqrt{x}$ We see that $(f_n)$ converges to $f$ in sup norm in $C[0,1]$, thus it is Cauchy. $C^1[0,1]$ is a subspace of $C[0,1]$ and all terms of $(f_n)$ are in $C^1[0,1]$, so $(f_n)$ is Cauchy in $C^1[0,1]$ But $f$ is not in $C^1[0,1]$. So $C^1[0,1]$ with sup norm is not complete. When it comes to the second norm, I think the same sequence will be also okay. Am I right?","This question already has answers here : Example to prove that $ C^1[0,1] $ is not a Banach space for the uniform norm? (2 answers) $C([0, 1])$ is not complete with respect to the norm $\lVert f\rVert _1 = \int_0^1 \lvert f (x) \rvert \,dx$ (2 answers) Closed 8 years ago . I have to show that the $C^1[0,1]$ is not complete with any of these norms: $\|f\|_{\infty}=\sup_{x\in[0,1]}|f(x)|$ $\|f\|_{*}=|f(0)|+\int_0^1|f'(x)|dx$ My attempt The right sequence for the first norm is $f_n=\sqrt{x+\frac{1}{n}}$. Notice that $\forall n\in\mathbb{N} : f_n\in C^1[0,1]$ Let $f=\sqrt{x}$ We see that $(f_n)$ converges to $f$ in sup norm in $C[0,1]$, thus it is Cauchy. $C^1[0,1]$ is a subspace of $C[0,1]$ and all terms of $(f_n)$ are in $C^1[0,1]$, so $(f_n)$ is Cauchy in $C^1[0,1]$ But $f$ is not in $C^1[0,1]$. So $C^1[0,1]$ with sup norm is not complete. When it comes to the second norm, I think the same sequence will be also okay. Am I right?",,['functional-analysis']
47,Inequalities on kernels of compact operators,Inequalities on kernels of compact operators,,"Suppose we have a $\sigma$-finite positive measure $\mu(v)$ on $\Bbb R^d$ and we have two positive kernels on $\Bbb R^d\times \Bbb R^d$ $k_1(v,u)>0$, $k_2(v,u)>0$. We define integral operators $$K_i[f](v) =\int_{\Bbb R^d}k_i(v,u)f(u)d\mu(u).$$ We know by some external argument that $K_2:L^2(d\mu)\to L^2(d\mu)$ is a compact operator; furthermore, we know that there exist two strictly positive constants $C_+$ and $C_-$ such that $$C_-k_2\le k_1\le C_+k_2.$$ I want to deduce from these conditions that $K_1$ is a compact operator, but I can't see an evident path to prove it. It's possible to show that $K_1$ is bounded by examining negative and positive parts of $f$. It's important to say that neither $k_1$ nor $k_2$ satisfies the Hilbert-Schmidt criterion (i.e. they are not $L^2(d\mu(v)d \mu(u))$). We can additionally suppose that $K_i$ are symmetric. So, is there a way to prove that $K_1$ is compact (or to prove that it can be non-compact)?  Any help will be appreciated.","Suppose we have a $\sigma$-finite positive measure $\mu(v)$ on $\Bbb R^d$ and we have two positive kernels on $\Bbb R^d\times \Bbb R^d$ $k_1(v,u)>0$, $k_2(v,u)>0$. We define integral operators $$K_i[f](v) =\int_{\Bbb R^d}k_i(v,u)f(u)d\mu(u).$$ We know by some external argument that $K_2:L^2(d\mu)\to L^2(d\mu)$ is a compact operator; furthermore, we know that there exist two strictly positive constants $C_+$ and $C_-$ such that $$C_-k_2\le k_1\le C_+k_2.$$ I want to deduce from these conditions that $K_1$ is a compact operator, but I can't see an evident path to prove it. It's possible to show that $K_1$ is bounded by examining negative and positive parts of $f$. It's important to say that neither $k_1$ nor $k_2$ satisfies the Hilbert-Schmidt criterion (i.e. they are not $L^2(d\mu(v)d \mu(u))$). We can additionally suppose that $K_i$ are symmetric. So, is there a way to prove that $K_1$ is compact (or to prove that it can be non-compact)?  Any help will be appreciated.",,"['functional-analysis', 'operator-theory', 'compact-operators', 'integral-operators']"
48,Why is the Fourier transform self-inverse?,Why is the Fourier transform self-inverse?,,"I've seen the standard proof that the Fourier transform is self-inverse (up to an overall factor determined by conventions), which is essentially equivalent to  $\int_{-\infty}^\infty e^{2 \pi i \omega x} dx = \delta(\omega)$. That isn't too hard to see from definitions. But intuitively, the Fourier transform of a function gives the amplitude of each component frequency in an obvious sense.  Is it intuitively obvious that this operation is self-inverse or is there a deep reason why it must be so?","I've seen the standard proof that the Fourier transform is self-inverse (up to an overall factor determined by conventions), which is essentially equivalent to  $\int_{-\infty}^\infty e^{2 \pi i \omega x} dx = \delta(\omega)$. That isn't too hard to see from definitions. But intuitively, the Fourier transform of a function gives the amplitude of each component frequency in an obvious sense.  Is it intuitively obvious that this operation is self-inverse or is there a deep reason why it must be so?",,"['complex-analysis', 'functional-analysis', 'fourier-analysis']"
49,The spectrum of a product of operators,The spectrum of a product of operators,,"Suppose $A,B\in\mathcal{B}(\mathcal{H})$, where $\mathcal{H}$ is an infinite dimensional Hilbert space. In general, we know that there is no relationship between $\sigma(AB)$ and $\sigma(A)$ and $\sigma(B)$ without assuming that perhaps $A$ and $B$ commute. What I've been wondering about is if we can say anything if $A$ and $B$ have finite spectrum - can we conclude that $AB$ has finite spectrum? Or are there examples of bounded operators $A$ and $B$ with finite spectrum but $\sigma(AB)$ is infinite? If nothing can be said in general for this problem, what if $A$ and $B$ are self-adjoint involutions (i.e. $A^* = A$, $B^*=B$ and $A^2 = B^2 = I$)? I haven't been able to make any serious headway on this due to the complicated nature of a spectrum of a product of operators. I've had a string of if and only ifs for when $AB-\lambda I$ is invertible but nothing enlightening came of it. In the self-adjoint involution case, I would think that the spectral theorem could play a big role but I don't see how to invoke it here in a meaningful way. After some scouring of the internet, I haven't really found any result or even any mention of such a problem.","Suppose $A,B\in\mathcal{B}(\mathcal{H})$, where $\mathcal{H}$ is an infinite dimensional Hilbert space. In general, we know that there is no relationship between $\sigma(AB)$ and $\sigma(A)$ and $\sigma(B)$ without assuming that perhaps $A$ and $B$ commute. What I've been wondering about is if we can say anything if $A$ and $B$ have finite spectrum - can we conclude that $AB$ has finite spectrum? Or are there examples of bounded operators $A$ and $B$ with finite spectrum but $\sigma(AB)$ is infinite? If nothing can be said in general for this problem, what if $A$ and $B$ are self-adjoint involutions (i.e. $A^* = A$, $B^*=B$ and $A^2 = B^2 = I$)? I haven't been able to make any serious headway on this due to the complicated nature of a spectrum of a product of operators. I've had a string of if and only ifs for when $AB-\lambda I$ is invertible but nothing enlightening came of it. In the self-adjoint involution case, I would think that the spectral theorem could play a big role but I don't see how to invoke it here in a meaningful way. After some scouring of the internet, I haven't really found any result or even any mention of such a problem.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
50,Increasing orthogonal functions,Increasing orthogonal functions,,"What is the maximal $n$ such that there exist functions $f_1, \dots, f_n:[0,1] \to \mathbb{R}$ that are all bounded, non-decreasing, and mutually orthogonal in $L^2([0,1])$?","What is the maximal $n$ such that there exist functions $f_1, \dots, f_n:[0,1] \to \mathbb{R}$ that are all bounded, non-decreasing, and mutually orthogonal in $L^2([0,1])$?",,"['functional-analysis', 'functions']"
51,Hahn-Banach extensions from $E$ to $E^{**}$.,Hahn-Banach extensions from  to .,E E^{**},"I was thinking the following problem while reading some functional analysis notes. Is it possible to characterize the Hahn-Banach extensions (meaning, extensions with the same norm) of a functional in a Banach space $E$ to the double continuous dual $E^{**}$ ? My intuition tells me that there aren't many. This is due to two facts: Theorem 1 (Goldstine) The unit ball $B_E$ of $E$ is $w^*$ -dense in the unit ball of $E^{**}$ , $B_{E^{**}}$ Theorem 2 There is a canonical (H-B) extension of a functional $\varphi \in E^*$ given by the natural map $E^* \to E^{***}$ . Even more so, this map splits. Are there examples of spaces and functionals that admit many H-B extensions to its double dual? Just for reference, the first example one would think is $c_0$ which has $c_0^{**}=\ell^\infty$ . But in this case, it is well known that the H-B extension is always unique. Edit : I'll extend the results I know a little in order to attain a possible answer. Theorem 3 (Phelps) Given a closed subspace $Y$ of a Banach space $X$ , every functional on $Y$ has a unique norm-preserving extension if and only if the distance from a functional $f \in X^*$ to $Y^\perp$ is attained uniquely, in the sense that there exists a unique $g \in Y^\perp$ such that $$ d(f,Y^\perp) = \|f-g\|$$ Form this is an easy exercise that the Hahn-Banach extension is always unique if and only if the dual space is strictly convex. Using theorem 3 and theorem 2, it is also possible to observe the following: The triple dual, $E^{***}$ splits $$ E^{***} = E^* \oplus E^\perp$$ Then every functional on $E$ admits unique H-B extension to $E^{**}$ if and only if the norm on $E^{***}$ satisfies $$\|f\|_{E^{***}} = \|f|_E\|_{E^*} + \| f - f_E \|_{E^\perp} $$ Is this always the case? Thanks in advance.","I was thinking the following problem while reading some functional analysis notes. Is it possible to characterize the Hahn-Banach extensions (meaning, extensions with the same norm) of a functional in a Banach space to the double continuous dual ? My intuition tells me that there aren't many. This is due to two facts: Theorem 1 (Goldstine) The unit ball of is -dense in the unit ball of , Theorem 2 There is a canonical (H-B) extension of a functional given by the natural map . Even more so, this map splits. Are there examples of spaces and functionals that admit many H-B extensions to its double dual? Just for reference, the first example one would think is which has . But in this case, it is well known that the H-B extension is always unique. Edit : I'll extend the results I know a little in order to attain a possible answer. Theorem 3 (Phelps) Given a closed subspace of a Banach space , every functional on has a unique norm-preserving extension if and only if the distance from a functional to is attained uniquely, in the sense that there exists a unique such that Form this is an easy exercise that the Hahn-Banach extension is always unique if and only if the dual space is strictly convex. Using theorem 3 and theorem 2, it is also possible to observe the following: The triple dual, splits Then every functional on admits unique H-B extension to if and only if the norm on satisfies Is this always the case? Thanks in advance.","E E^{**} B_E E w^* E^{**} B_{E^{**}} \varphi \in E^* E^* \to E^{***} c_0 c_0^{**}=\ell^\infty Y X Y f \in X^* Y^\perp g \in Y^\perp  d(f,Y^\perp) = \|f-g\| E^{***}  E^{***} = E^* \oplus E^\perp E E^{**} E^{***} \|f\|_{E^{***}} = \|f|_E\|_{E^*} + \| f - f_E \|_{E^\perp} ","['functional-analysis', 'banach-spaces', 'dual-spaces']"
52,Frechet derivative of square root on positive elements in some $C^*$-algebra,Frechet derivative of square root on positive elements in some -algebra,C^*,"Let $A$ - is some unital $C^*$ algebra, and $P$ is set of all strictly positive elements in $A$. We can define map $\sqrt{?} : P \to A$ which takes positive element and returns its (unique) strictly positive square root. How to evaluate its Frechet derivative?","Let $A$ - is some unital $C^*$ algebra, and $P$ is set of all strictly positive elements in $A$. We can define map $\sqrt{?} : P \to A$ which takes positive element and returns its (unique) strictly positive square root. How to evaluate its Frechet derivative?",,"['functional-analysis', 'c-star-algebras', 'frechet-derivative']"
53,Intuition behind the direct integral of a family of Hilbert spaces,Intuition behind the direct integral of a family of Hilbert spaces,,"In order to understand better the mathematically rigorous version of Dirac's formalism in Quantum Mechanics I've been reading about direct integrals of Hilbert spaces, projector-valued measures and so on. Although the definition of the direct integrals of Hilbert spaces I've seem is quite clear, I simply couldn't get the idea behind it. The definition I have is the following: Definition 1 : Let $\mu$ be a Radon measure on the $\sigma$ -compact locally compact Hausdorff space $X$ . A measurable field of Hilbert spaces is a collection $\{H_x : x \in X\}$ of Hilbert spaces together with a linear subspace $\mathcal{S}$ of $\prod_{x\in X}H_x$ , whose elements are called measurable sections satisfying the following axioms: If $\eta\in \prod_{x\in X}H_x$ , then $\eta\in \mathcal{S}$ if and only if $x\mapsto \langle \xi(x),\eta(x)\rangle$ is measurable for all $\xi \in \mathcal{S}$ . There is a sequence $(\xi_n)$ in $\mathcal{S}$ such that for almost every $x\in X$ , the closed linear span of $\xi_n(x)$ is $H_x$ . Definition 2 : Let $\mu$ be a Radon measure on the $\sigma$ -compact locally compact Hausdorff space $X$ , and $\{H_x: x\in X\}$ a measurable field of Hilbert spaces over $X$ . We define the direct integral of the $H_x$ to be the set of all $\xi \in \mathcal{S}$ (modulo agreeing on measure zero sets) such that $\int_X |\xi(x)|^2d\mu(x) < \infty$ and we denote this direct integral by $$\int_X^{\oplus}H_x d\mu(x).$$ On the direct integral we have the inner product $$\langle \xi,\eta\rangle = \int_X \langle \xi(x),\eta(x)\rangle_{H_x}d\mu(x),$$ which turns the direct integral into a Hilbert space. Now, although the definition by itself is clear, I can't get the intuition behind it. We have a collection of Hilbert spaces indexed by one topological space with a Radon measure. We then consider a linear subspace of the product, satisfing two properties. This is my first question: what is the intuition behind the defining properties of a measurable section? What we are really defining there? After that, one simply picks all the measurable sections with the property that the integral of the square of the norm of the vectors at each point converge. This is my second question: what is the intuition behind this definition? What we are really trying to define with this construction of the direct integral? The direct sum, for example, can be understood in a intuitive way as the space of sums of elements of each space alone. In the case of the direct integral I'm not seeing one simple inution like that.","In order to understand better the mathematically rigorous version of Dirac's formalism in Quantum Mechanics I've been reading about direct integrals of Hilbert spaces, projector-valued measures and so on. Although the definition of the direct integrals of Hilbert spaces I've seem is quite clear, I simply couldn't get the idea behind it. The definition I have is the following: Definition 1 : Let be a Radon measure on the -compact locally compact Hausdorff space . A measurable field of Hilbert spaces is a collection of Hilbert spaces together with a linear subspace of , whose elements are called measurable sections satisfying the following axioms: If , then if and only if is measurable for all . There is a sequence in such that for almost every , the closed linear span of is . Definition 2 : Let be a Radon measure on the -compact locally compact Hausdorff space , and a measurable field of Hilbert spaces over . We define the direct integral of the to be the set of all (modulo agreeing on measure zero sets) such that and we denote this direct integral by On the direct integral we have the inner product which turns the direct integral into a Hilbert space. Now, although the definition by itself is clear, I can't get the intuition behind it. We have a collection of Hilbert spaces indexed by one topological space with a Radon measure. We then consider a linear subspace of the product, satisfing two properties. This is my first question: what is the intuition behind the defining properties of a measurable section? What we are really defining there? After that, one simply picks all the measurable sections with the property that the integral of the square of the norm of the vectors at each point converge. This is my second question: what is the intuition behind this definition? What we are really trying to define with this construction of the direct integral? The direct sum, for example, can be understood in a intuitive way as the space of sums of elements of each space alone. In the case of the direct integral I'm not seeing one simple inution like that.","\mu \sigma X \{H_x : x \in X\} \mathcal{S} \prod_{x\in X}H_x \eta\in \prod_{x\in X}H_x \eta\in \mathcal{S} x\mapsto \langle \xi(x),\eta(x)\rangle \xi \in \mathcal{S} (\xi_n) \mathcal{S} x\in X \xi_n(x) H_x \mu \sigma X \{H_x: x\in X\} X H_x \xi \in \mathcal{S} \int_X |\xi(x)|^2d\mu(x) < \infty \int_X^{\oplus}H_x d\mu(x). \langle \xi,\eta\rangle = \int_X \langle \xi(x),\eta(x)\rangle_{H_x}d\mu(x),","['functional-analysis', 'measure-theory', 'hilbert-spaces', 'definition', 'intuition']"
54,Spectrum of composition of convolution and multiplication,Spectrum of composition of convolution and multiplication,,"Let $T$ be the operator from $L^2(\mathbb R^n)$ to $L^2(\mathbb R^n)$ defined as composition of convolution and multiplication,  $Tf := (af) * g$ where $g$ is in $L^2$ and $a$ is a bounded function. Can we find the spectrum of $T$?  For $a$ identically equal 1, the spectrum is the essential range of the  Fourier transform of $g$.  I am interested in the more general case. If both $a$ and the Fourier transform of $g$ are positive functions, I assume that the spectrum of $T$ will also be positive but don't have a proof.","Let $T$ be the operator from $L^2(\mathbb R^n)$ to $L^2(\mathbb R^n)$ defined as composition of convolution and multiplication,  $Tf := (af) * g$ where $g$ is in $L^2$ and $a$ is a bounded function. Can we find the spectrum of $T$?  For $a$ identically equal 1, the spectrum is the essential range of the  Fourier transform of $g$.  I am interested in the more general case. If both $a$ and the Fourier transform of $g$ are positive functions, I assume that the spectrum of $T$ will also be positive but don't have a proof.",,['analysis']
55,Looking for an easy lightning introduction to Hilbert spaces and Banach spaces,Looking for an easy lightning introduction to Hilbert spaces and Banach spaces,,"I'm co-organizing a reading seminar on Higson and Roe's Analytic K-homology . Most participants are graduate students and faculty, but there are a number of undergraduates who might like to participate, and who have never taken a course in functional analysis. They are strong students though, and they do have decent analysis, linear algebra, point-set topology, algebraic topology... Question: Could anyone here recommend a very soft, easy, hand-wavy reference I could recommend to these undergraduates, which covers and motivates basic definitions and results of Hilbert spaces, Banach spaces, Banach algebras, Gelfand transform,  and functional calculus? It doesn't need to be rigourous at all- it just needs to introduce and to motivate the main definitions and results so that they can ""black box"" the prerequisites and get something out of the reading seminar. They can do back and do things properly when they take a functional analysis course next year or so.","I'm co-organizing a reading seminar on Higson and Roe's Analytic K-homology . Most participants are graduate students and faculty, but there are a number of undergraduates who might like to participate, and who have never taken a course in functional analysis. They are strong students though, and they do have decent analysis, linear algebra, point-set topology, algebraic topology... Question: Could anyone here recommend a very soft, easy, hand-wavy reference I could recommend to these undergraduates, which covers and motivates basic definitions and results of Hilbert spaces, Banach spaces, Banach algebras, Gelfand transform,  and functional calculus? It doesn't need to be rigourous at all- it just needs to introduce and to motivate the main definitions and results so that they can ""black box"" the prerequisites and get something out of the reading seminar. They can do back and do things properly when they take a functional analysis course next year or so.",,"['functional-analysis', 'reference-request', 'operator-theory', 'self-learning', 'banach-algebras']"
56,Computing the total variation for a multivariable function,Computing the total variation for a multivariable function,,"I am trying to write an example computation with multivariable total variation to include in my functional analysis notes using the following definition from Wikipedia : Let $\Omega$ be an open subset of $\mathbb{R}^n$ . Given a function $f$ belonging to $L^1(\Omega)$ , the total variation of $f$ in $\Omega$ is defined as $$V(f,\Omega):=\sup \left \{ \int_\Omega f(x) \text{div} \phi(x) dx : \phi \in C_c^1(\Omega, \mathbb{R}^n), \|\phi\|_{L^\infty(\Omega)} \leq 1\right\}$$ $C_c^1(\Omega, \mathbb{R}^n)$ is the set of continuously differentiable vector functions of compact support contained in $\Omega$ , $\|\cdot\|_{L^\infty(\Omega)}$ is the essential supremum norm, and $\text{div}$ is the divergence operator. I would like to use this formula directly and demonstrate the process of taking the supremum. I understand that if $f$ is $C^1$ on $\overline \Omega$ , then the formula for total variation is simplified to the computation of $$ V(f, \Omega) = \int_\Omega |\nabla f(x)| dx, $$ which I am not trying to use here. So, the problem is computing the total variation of $f: \mathbb{R}^2 \to \mathbb{R}$ , $$ f(x,y) =\frac{xy}{x^2 + y^2} $$ on $\Omega$ , where $\Omega$ is the open unit disk in $\mathbb{R}^2$ . So, $\Omega = \{x : x \in \mathbb{R}^2 \text{ and }\|x\| < 1\}.$ Here is a visual of this situation: My Attempted Solution . $f$ is a classic example of a function discontinuous at 0, so $f \notin C^1(\overline \Omega)$ . We first show that $f \in L^1(\Omega)$ . Recall $f \in L^1(\Omega) \iff \int_\Omega |f| < \infty$ . So, $$\begin{align} \int_{\Omega} |f| &= \iint_D |f(x,y)| dA \\ &= \int_{-1}^1 \int_{-\sqrt{1 - x^2}}^{\sqrt{1 - x^2}} \left \lvert \frac{xy}{x^2 + y^2}\right \rvert dy dx \\ &= 1 < \infty \qquad \text{(C.A.S)}\end{align}.$$ Hence, $f \in L^1(\Omega)$ . It remains to compute $$V(f,\Omega):=\sup \left \{ \int_\Omega f(x,y) \text{div} \phi(x,y) dx : \phi \in C_c^1(\Omega, \mathbb{R}^2), \|\phi\|_{L^\infty(\Omega)} \leq 1\right\}$$ Before taking the supremum over $\phi \in C_c^1(\Omega, \mathbb{R}^2)$ , we attempt the following simplification, $$\begin{align*} 				\int_\Omega f(x,y) \text{div} \phi(x,y) dx &= \iint_D f(x,y) \left(\nabla \cdot \left(\phi_x, \phi_y\right)\right) dA \\ 				&= \iint_D f(x,y) \left(\frac{\partial \phi_x}{\partial x} + \frac{\partial \phi_y}{\partial y}\right) dA \\ 				&= \iint_D f(x,y) \frac{\partial \phi_x}{\partial x} dA + \iint_D f(x,y) \frac{\partial \phi_y}{\partial y} dA 			\end{align*} $$ This is where I am stuck in terms of working with $\phi(x,y)$ . It boils down to two main questions: Given what we know about $\phi$ , can the above be simplified any further to an expression that does not depend on $\phi$ ? (So that we don't have to take a supremum) Otherwise, If we do have to take a supremum over the vector fields $\phi$ , how would one go about this? I understand in the single variable case of total variation, one is simply constructing a family of partitions on an interval that enable you to take the supremum over all partitions. But here, how would I go about constructing a family of vector fields that enable me to take the supremum required?","I am trying to write an example computation with multivariable total variation to include in my functional analysis notes using the following definition from Wikipedia : Let be an open subset of . Given a function belonging to , the total variation of in is defined as is the set of continuously differentiable vector functions of compact support contained in , is the essential supremum norm, and is the divergence operator. I would like to use this formula directly and demonstrate the process of taking the supremum. I understand that if is on , then the formula for total variation is simplified to the computation of which I am not trying to use here. So, the problem is computing the total variation of , on , where is the open unit disk in . So, Here is a visual of this situation: My Attempted Solution . is a classic example of a function discontinuous at 0, so . We first show that . Recall . So, Hence, . It remains to compute Before taking the supremum over , we attempt the following simplification, This is where I am stuck in terms of working with . It boils down to two main questions: Given what we know about , can the above be simplified any further to an expression that does not depend on ? (So that we don't have to take a supremum) Otherwise, If we do have to take a supremum over the vector fields , how would one go about this? I understand in the single variable case of total variation, one is simply constructing a family of partitions on an interval that enable you to take the supremum over all partitions. But here, how would I go about constructing a family of vector fields that enable me to take the supremum required?","\Omega \mathbb{R}^n f L^1(\Omega) f \Omega V(f,\Omega):=\sup \left \{ \int_\Omega f(x) \text{div} \phi(x) dx : \phi \in C_c^1(\Omega, \mathbb{R}^n), \|\phi\|_{L^\infty(\Omega)} \leq 1\right\} C_c^1(\Omega, \mathbb{R}^n) \Omega \|\cdot\|_{L^\infty(\Omega)} \text{div} f C^1 \overline \Omega 
V(f, \Omega) = \int_\Omega |\nabla f(x)| dx,
 f: \mathbb{R}^2 \to \mathbb{R} 
f(x,y) =\frac{xy}{x^2 + y^2}
 \Omega \Omega \mathbb{R}^2 \Omega = \{x : x \in \mathbb{R}^2 \text{ and }\|x\| < 1\}. f f \notin C^1(\overline \Omega) f \in L^1(\Omega) f \in L^1(\Omega) \iff \int_\Omega |f| < \infty \begin{align} \int_{\Omega} |f| &= \iint_D |f(x,y)| dA \\ &= \int_{-1}^1 \int_{-\sqrt{1 - x^2}}^{\sqrt{1 - x^2}} \left \lvert \frac{xy}{x^2 + y^2}\right \rvert dy dx \\ &= 1 < \infty \qquad \text{(C.A.S)}\end{align}. f \in L^1(\Omega) V(f,\Omega):=\sup \left \{ \int_\Omega f(x,y) \text{div} \phi(x,y) dx : \phi \in C_c^1(\Omega, \mathbb{R}^2), \|\phi\|_{L^\infty(\Omega)} \leq 1\right\} \phi \in C_c^1(\Omega, \mathbb{R}^2) \begin{align*}
				\int_\Omega f(x,y) \text{div} \phi(x,y) dx &= \iint_D f(x,y) \left(\nabla \cdot \left(\phi_x, \phi_y\right)\right) dA \\
				&= \iint_D f(x,y) \left(\frac{\partial \phi_x}{\partial x} + \frac{\partial \phi_y}{\partial y}\right) dA \\
				&= \iint_D f(x,y) \frac{\partial \phi_x}{\partial x} dA + \iint_D f(x,y) \frac{\partial \phi_y}{\partial y} dA
			\end{align*}  \phi(x,y) \phi \phi \phi","['functional-analysis', 'total-variation']"
57,Examples of bounded linear operators with range not closed,Examples of bounded linear operators with range not closed,,I've been trying to get some intuition on what it means for a bounded linear operator to have closed range. Can anyone give some simple examples of such an operator that does not have closed range? Thanks!,I've been trying to get some intuition on what it means for a bounded linear operator to have closed range. Can anyone give some simple examples of such an operator that does not have closed range? Thanks!,,"['functional-analysis', 'operator-theory', 'examples-counterexamples']"
58,Why is the space of surjective operators open?,Why is the space of surjective operators open?,,"Suppose $E$ and $F$ are given Banach spaces. Let $A$ be a continuous surjective map. Why is there a small ball around $A$ in the operator topology, such that all elements in this ball are surjective?","Suppose $E$ and $F$ are given Banach spaces. Let $A$ be a continuous surjective map. Why is there a small ball around $A$ in the operator topology, such that all elements in this ball are surjective?",,"['functional-analysis', 'banach-spaces']"
59,Why do we consider Lebesgue spaces for $p$ greater than and equal to $1$ only?,Why do we consider Lebesgue spaces for  greater than and equal to  only?,p 1,Why do we consider Lebesgue spaces for $p$ greater than and equal to $1$ only and not for $p$ any real number?,Why do we consider Lebesgue spaces for $p$ greater than and equal to $1$ only and not for $p$ any real number?,,"['analysis', 'functional-analysis', 'measure-theory']"
60,An idempotent operator is compact if and only if it is of finite rank,An idempotent operator is compact if and only if it is of finite rank,,Would you help me to solve this problem. Show that an idempotent operator on hilbert space is compact if and only if it has finite rank.,Would you help me to solve this problem. Show that an idempotent operator on hilbert space is compact if and only if it has finite rank.,,"['functional-analysis', 'hilbert-spaces']"
61,Do weak convergence and convergence of norms imply convergence in $L^2$?,Do weak convergence and convergence of norms imply convergence in ?,L^2,"Let $(f_n)_n\subseteq L^2(0,1)$ s.t.    $$ f_n \rightharpoonup f, \qquad\qquad \Vert f_n\Vert_2 \to \Vert f\Vert_2 $$   where $\rightharpoonup$ means weak convergence . Is it true that $f_n \to f$ strongly , i.e. in $L^2$? I don't know how to start and I really would like some hints on how to solve it. Actually, I do not know: is it true? I don't manage to find any counterexample... Is this somehow related to the well-known fact that a.e. convergence + convergence of norms in $L^p$ do imply convergence in $L^p$ ( Rudin , R&CA, ex. 17 pag. 73)? Thanks.","Let $(f_n)_n\subseteq L^2(0,1)$ s.t.    $$ f_n \rightharpoonup f, \qquad\qquad \Vert f_n\Vert_2 \to \Vert f\Vert_2 $$   where $\rightharpoonup$ means weak convergence . Is it true that $f_n \to f$ strongly , i.e. in $L^2$? I don't know how to start and I really would like some hints on how to solve it. Actually, I do not know: is it true? I don't manage to find any counterexample... Is this somehow related to the well-known fact that a.e. convergence + convergence of norms in $L^p$ do imply convergence in $L^p$ ( Rudin , R&CA, ex. 17 pag. 73)? Thanks.",,"['functional-analysis', 'convergence-divergence']"
62,Spectrum of a product of operators on a Banach space,Spectrum of a product of operators on a Banach space,,"Let $A$ and $B$ be two operators on a Banach space X. I am interested in the relationship between the spectra of $A$, $B$ and $AB$. In particular, are there any set theoretic inclusions or everything can happen in general like: $\sigma(A) \subset \sigma(AB)$, and conversely, $\sigma(B) \subset \sigma(AB)$, and conversely? If we know the spectra $\sigma(A)$, $\sigma(B)$ of $A$ and $B$, can we determine the spectrum of $AB$? I would appreciate any comment or reference.","Let $A$ and $B$ be two operators on a Banach space X. I am interested in the relationship between the spectra of $A$, $B$ and $AB$. In particular, are there any set theoretic inclusions or everything can happen in general like: $\sigma(A) \subset \sigma(AB)$, and conversely, $\sigma(B) \subset \sigma(AB)$, and conversely? If we know the spectra $\sigma(A)$, $\sigma(B)$ of $A$ and $B$, can we determine the spectrum of $AB$? I would appreciate any comment or reference.",,['functional-analysis']
63,Why is $L^{1} \cap L^{\infty}$ dense is in $L^{p}$?,Why is  dense is in ?,L^{1} \cap L^{\infty} L^{p},It is mentioned that using the interpolation inequality $$\Vert f \Vert_{p} \leq \Vert f \Vert^{1/p}_{1} \Vert f \Vert_{\infty}^{1-1/p}$$ one can deduce that the space $L^{1} \cap L^{\infty}$ is dense in $L^{p}$ . Does anybody knows the trick behind this? Thanks !,It is mentioned that using the interpolation inequality one can deduce that the space is dense in . Does anybody knows the trick behind this? Thanks !,\Vert f \Vert_{p} \leq \Vert f \Vert^{1/p}_{1} \Vert f \Vert_{\infty}^{1-1/p} L^{1} \cap L^{\infty} L^{p},"['functional-analysis', 'analysis', 'lp-spaces', 'interpolation']"
64,A Question on Compact Operators,A Question on Compact Operators,,"Let $ \mathcal{H} $ and $ \mathcal{K} $ be Hilbert spaces, and let $ T: \mathcal{H} \to \mathcal{K} $ be a bounded linear operator. Show that if $ T $ is a compact operator, then $$ \lim_{n \to \infty} \| T(e_{n}) \|_{\mathcal{K}} = 0 $$ for every orthonormal sequence $ (e_{n})_{n \in \mathbb{N}} $ in $ \mathcal{H} $. Is the converse of this statement true? Thanks.","Let $ \mathcal{H} $ and $ \mathcal{K} $ be Hilbert spaces, and let $ T: \mathcal{H} \to \mathcal{K} $ be a bounded linear operator. Show that if $ T $ is a compact operator, then $$ \lim_{n \to \infty} \| T(e_{n}) \|_{\mathcal{K}} = 0 $$ for every orthonormal sequence $ (e_{n})_{n \in \mathbb{N}} $ in $ \mathcal{H} $. Is the converse of this statement true? Thanks.",,"['functional-analysis', 'hilbert-spaces', 'compact-operators']"
65,extending a bounded linear operator,extending a bounded linear operator,,So I have a homework question which I have no idea how to start. Let $E_0$ be a dense subspace of the normed space $E$. Let $T_0:E_0 \rightarrow F$ be a bounded linear operator into the Banach space $F$. (i) Show that $T_0$ can be uniquely extended to a bounded linear operator $T:E \rightarrow F$. (ii) Prove that $\|T\| = \|T_0\|$. Any hints would be much appreciated!,So I have a homework question which I have no idea how to start. Let $E_0$ be a dense subspace of the normed space $E$. Let $T_0:E_0 \rightarrow F$ be a bounded linear operator into the Banach space $F$. (i) Show that $T_0$ can be uniquely extended to a bounded linear operator $T:E \rightarrow F$. (ii) Prove that $\|T\| = \|T_0\|$. Any hints would be much appreciated!,,"['functional-analysis', 'operator-theory']"
66,Why isn't every element of the spectrum an eigenvalue? (Where is the error in my proof?),Why isn't every element of the spectrum an eigenvalue? (Where is the error in my proof?),,"My book defines the spectrum like this: Let $H$ be a complex Hilbert space, let $I \in B(H)$ be the identity   operator and let $T \in B(H)$. The spectrum of $T$, denoted $\sigma(T)$,   is defined to be: $$\sigma(T)=\{\lambda \in \mathbb{C}: T-\lambda I\text{ is not invertible}\}$$ Later there is a lemma that says that all eigenvalues are in the spectrum: Let $H$ be a complex Hilbert space and let $T \in B(H)$. If $\lambda$ is   an eigenvalue of T then $\lambda \in \sigma(T)$. But why does the converse not hold? I mean, if $\lambda \in \sigma(T)$, why is not $\lambda$ and eigenvalue? What is wrong with this proof?: Let $\lambda \in \sigma(T)$, then $T-\lambda I$ is not invertible. Then there is an $x \in H, x \ne0$ such that $T(x)-\lambda x=0$, if not, only 0 will be sent to 0, and then the operator is invertible. But then we have that $T(x)=\lambda x$, and hence $\lambda$ is an eigenvalue. Do you see where the error is?","My book defines the spectrum like this: Let $H$ be a complex Hilbert space, let $I \in B(H)$ be the identity   operator and let $T \in B(H)$. The spectrum of $T$, denoted $\sigma(T)$,   is defined to be: $$\sigma(T)=\{\lambda \in \mathbb{C}: T-\lambda I\text{ is not invertible}\}$$ Later there is a lemma that says that all eigenvalues are in the spectrum: Let $H$ be a complex Hilbert space and let $T \in B(H)$. If $\lambda$ is   an eigenvalue of T then $\lambda \in \sigma(T)$. But why does the converse not hold? I mean, if $\lambda \in \sigma(T)$, why is not $\lambda$ and eigenvalue? What is wrong with this proof?: Let $\lambda \in \sigma(T)$, then $T-\lambda I$ is not invertible. Then there is an $x \in H, x \ne0$ such that $T(x)-\lambda x=0$, if not, only 0 will be sent to 0, and then the operator is invertible. But then we have that $T(x)=\lambda x$, and hence $\lambda$ is an eigenvalue. Do you see where the error is?",,"['functional-analysis', 'eigenvalues-eigenvectors', 'hilbert-spaces', 'spectral-theory']"
67,What will be the support of the convolution of two test functions.,What will be the support of the convolution of two test functions.,,"If $g\in C^{\infty}_c$ defined on $\Bbb R^n$ and K is the support of function $g$. I want to find the support of $g_\epsilon$. Where $g_\epsilon$ is regularization of $g$. Regularization of $g$ is defined as: $g_\epsilon$:=  $g*\omega_\epsilon$ (convolution of g and a test function) i.e. $g_\epsilon(x )$=$\int_{\Bbb R^n}g(x-y).\omega_\epsilon(y)dy $ I think, this process is also known as mollification. Here  $ \omega_\epsilon (x)=  \begin{cases} \frac{C^{-1}}{\epsilon^n} e^{{\frac{-\epsilon^2}{{\epsilon^2}-|x|^2}}},  &\text{for |x|< $\epsilon$ } \\ 0, & \text{otherwise}  \\ \end{cases} $ I only know that support of convolution of two compactly supported functions is again a compact set. And, as support of $\omega_\epsilon $ is a ball $B(0,\epsilon)$ and support of g is a compact set K(given) then support of their convolution should be the intersection of the support of $g(x-y)$ and $\omega_\epsilon(y)$.  Because for non zero function integration remains non zero...","If $g\in C^{\infty}_c$ defined on $\Bbb R^n$ and K is the support of function $g$. I want to find the support of $g_\epsilon$. Where $g_\epsilon$ is regularization of $g$. Regularization of $g$ is defined as: $g_\epsilon$:=  $g*\omega_\epsilon$ (convolution of g and a test function) i.e. $g_\epsilon(x )$=$\int_{\Bbb R^n}g(x-y).\omega_\epsilon(y)dy $ I think, this process is also known as mollification. Here  $ \omega_\epsilon (x)=  \begin{cases} \frac{C^{-1}}{\epsilon^n} e^{{\frac{-\epsilon^2}{{\epsilon^2}-|x|^2}}},  &\text{for |x|< $\epsilon$ } \\ 0, & \text{otherwise}  \\ \end{cases} $ I only know that support of convolution of two compactly supported functions is again a compact set. And, as support of $\omega_\epsilon $ is a ball $B(0,\epsilon)$ and support of g is a compact set K(given) then support of their convolution should be the intersection of the support of $g(x-y)$ and $\omega_\epsilon(y)$.  Because for non zero function integration remains non zero...",,"['functional-analysis', 'fourier-analysis', 'convolution', 'lp-spaces']"
68,Prove that $\sigma(AB) \backslash \{0\} = \sigma(BA)\backslash \{0\} $,Prove that,\sigma(AB) \backslash \{0\} = \sigma(BA)\backslash \{0\} ,"Prove that $\sigma(AB) \backslash \{0\} = \sigma(BA)\backslash \{0\} $. Where $A,\ B$ are bounded operators in Banach space and $\sigma$ denotes spectrum.","Prove that $\sigma(AB) \backslash \{0\} = \sigma(BA)\backslash \{0\} $. Where $A,\ B$ are bounded operators in Banach space and $\sigma$ denotes spectrum.",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'banach-algebras']"
69,Hilbert Space is reflexive,Hilbert Space is reflexive,,"A normed space $X$ is reflexive iff $X^{**}=\{g_x:x\in X\}$ where $g_x$ is bounded linear functional on $X^*$ defined by $g_x(f)=f(x)$ for any $f\in X^*$. Let $X$ be a Hilbert space, would you help me to show that $X$ is reflexive. One of the example is $L^2[a,b]$, the reason is its dual is $L^2$ and the second dual is $L^2$ again.","A normed space $X$ is reflexive iff $X^{**}=\{g_x:x\in X\}$ where $g_x$ is bounded linear functional on $X^*$ defined by $g_x(f)=f(x)$ for any $f\in X^*$. Let $X$ be a Hilbert space, would you help me to show that $X$ is reflexive. One of the example is $L^2[a,b]$, the reason is its dual is $L^2$ and the second dual is $L^2$ again.",,"['functional-analysis', 'banach-spaces', 'hilbert-spaces']"
70,equivalent norms in Banach spaces of infinite dimension,equivalent norms in Banach spaces of infinite dimension,,"Suppose $ X $ is a Banach space with respect to two different norms, $ \|\cdot\|_1 \mathrm{ e } \|\cdot\|_2 $. Suppose there is a constant $ K > 0 $  such that $$ \forall  x \in X, \|x\|_1 \leq K\|x\|_2 .$$ show then that these two norms are equivalent","Suppose $ X $ is a Banach space with respect to two different norms, $ \|\cdot\|_1 \mathrm{ e } \|\cdot\|_2 $. Suppose there is a constant $ K > 0 $  such that $$ \forall  x \in X, \|x\|_1 \leq K\|x\|_2 .$$ show then that these two norms are equivalent",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
71,Example of an algebra that is a Banach space but not a Banach algebra,Example of an algebra that is a Banach space but not a Banach algebra,,"I'm looking for an example of a space $\mathbb{A} $ such, $\mathbb{A} $ is an algebra; $\mathbb{A}$ is equipped with a norm that makes it a Banach space; $\mathbb{A}$ is not a Banach algebra, i.e., the norm is not submultiplicative. I have not been able to think of any examples for this case, but I believe there must be a space satisfying this. And if I assume that $\mathbb{A}$ has unity, is it still possible to find any examples? Edit: The example given by José made me question whether it is possible to construct an example in which the norm is not equivalent to another norm that turns the space into a Banach algebra.","I'm looking for an example of a space such, is an algebra; is equipped with a norm that makes it a Banach space; is not a Banach algebra, i.e., the norm is not submultiplicative. I have not been able to think of any examples for this case, but I believe there must be a space satisfying this. And if I assume that has unity, is it still possible to find any examples? Edit: The example given by José made me question whether it is possible to construct an example in which the norm is not equivalent to another norm that turns the space into a Banach algebra.",\mathbb{A}  \mathbb{A}  \mathbb{A} \mathbb{A} \mathbb{A},"['functional-analysis', 'normed-spaces', 'banach-spaces', 'examples-counterexamples', 'banach-algebras']"
72,Kernel of $T$ is closed iff $T$ is continuous,Kernel of  is closed iff  is continuous,T T,"I know that for a Banach space $X$ and a linear functional $T:X\rightarrow\mathbb{R}$ in its dual $X'$ the following holds: \begin{align}T \text{ is continuous } \iff \text{Ker }T \text{ is closed}\end{align} which probably holds for general operators $T:X\rightarrow Y$ with finite-dimensional Banach space $Y$. I think the argument doesn't work for infinite-dimensional Banach spaces $Y$. Is the statement still correct? I.e. continuity of course still implies the closedness of the kernel for general Banach spaces $X,Y$ but is the converse still true?","I know that for a Banach space $X$ and a linear functional $T:X\rightarrow\mathbb{R}$ in its dual $X'$ the following holds: \begin{align}T \text{ is continuous } \iff \text{Ker }T \text{ is closed}\end{align} which probably holds for general operators $T:X\rightarrow Y$ with finite-dimensional Banach space $Y$. I think the argument doesn't work for infinite-dimensional Banach spaces $Y$. Is the statement still correct? I.e. continuity of course still implies the closedness of the kernel for general Banach spaces $X,Y$ but is the converse still true?",,"['functional-analysis', 'banach-spaces']"
73,A counterexample to theorem about orthogonal projection,A counterexample to theorem about orthogonal projection,,"Can someone give me an example of noncomplete inner product space $H$, its closed linear subspace of $H_0$ and element $x\in H$ such that there is no orthogonal projection of $x$ on $H_0$. In other words I need to construct a counterexample to theorem about orthogonal projection when inner product space is not complete.","Can someone give me an example of noncomplete inner product space $H$, its closed linear subspace of $H_0$ and element $x\in H$ such that there is no orthogonal projection of $x$ on $H_0$. In other words I need to construct a counterexample to theorem about orthogonal projection when inner product space is not complete.",,"['functional-analysis', 'hilbert-spaces', 'examples-counterexamples', 'inner-products', 'projection']"
74,"Prove that if $\langle Tx,x\rangle =0$ for all $x \in X$, then $T = 0$","Prove that if  for all , then","\langle Tx,x\rangle =0 x \in X T = 0","This is exercise 10 in section 3.2 of Kreyszig's Introductory Functional Analysis with Applications: (Zero Operator): Let $T:X \to X$ be a bounded linear operator on complex inner product space $X$. If $\langle Tx,x\rangle =0$ for all $x \in X$, show that $T=0$. I had solved little kindly guide me further Solution: Let $\langle Tx,x\rangle =0$ for all $x \in X$. Let $x=u+av$ where $v,u$ belong to $X$ and $a$ be the scalar then  $$ \langle Tx,x\rangle =\langle T(u+av), u+av\rangle $$ since $T$ is linear then  \begin{align} \langle Tx,x\rangle &=\langle Tu+aTv, u+av\rangle \\     & =\langle Tu,u\rangle +\overline{a}\langle Tu,v\rangle +a\langle Tv,u\rangle +a\overline{a}\langle Tv,v\rangle \\     & =\overline{a} \langle Tu,v\rangle +a\langle Tv,u\rangle  \end{align}","This is exercise 10 in section 3.2 of Kreyszig's Introductory Functional Analysis with Applications: (Zero Operator): Let $T:X \to X$ be a bounded linear operator on complex inner product space $X$. If $\langle Tx,x\rangle =0$ for all $x \in X$, show that $T=0$. I had solved little kindly guide me further Solution: Let $\langle Tx,x\rangle =0$ for all $x \in X$. Let $x=u+av$ where $v,u$ belong to $X$ and $a$ be the scalar then  $$ \langle Tx,x\rangle =\langle T(u+av), u+av\rangle $$ since $T$ is linear then  \begin{align} \langle Tx,x\rangle &=\langle Tu+aTv, u+av\rangle \\     & =\langle Tu,u\rangle +\overline{a}\langle Tu,v\rangle +a\langle Tv,u\rangle +a\overline{a}\langle Tv,v\rangle \\     & =\overline{a} \langle Tu,v\rangle +a\langle Tv,u\rangle  \end{align}",,"['analysis', 'functional-analysis']"
75,Norm of adjoint operator in Hilbert space,Norm of adjoint operator in Hilbert space,,"Suppose $H$ is a Hilbert space and let $T \in B(H,H)$ where in our notation $B(H,H)$ denotes the set of all linear continuous operators $H \rightarrow H$. We defined the adjoint of $T$ as the unique $T^* \in B(H,H)$ such that $\langle Tx,y \rangle = \langle x, T^*y\rangle$ for all $x,y$ in $H$. I proved its existence as follows: Fix $y \in H$. Put $\Phi_y: H \rightarrow \mathbb{C}, x \mapsto \langle Tx,y \rangle$. This functional is continuous since $|\langle Tx, y\rangle | \leq ||Tx||\; ||y|| \leq ||T||\; ||x||\; ||y||$. Therefore we can apply the Riesz-Fréchet theorem which gives us the existence of a vector $T^*y \in H$ such that for all $x \in H$ we have $\langle Tx, y\rangle = \langle x, T^* y\rangle$. I now have to prove that $||T^*|| = ||T||$. I can show $||T^*|| \leq ||T||$: Since the Riesz theorem gives us an isometry we have $||T^*y|| = ||\Phi_y||_{H*} = \sup_{||x||\leq 1} |\langle Tx, y\rangle| \leq ||T||\;||y||$ and thus $||T^*|| \leq ||T||$. However, I do not see how to prove the other inequality without using consequences of Hahn-Banach or similar results. It seems like I am missing some quite simple point. Any help is very much appreciated! Regards, Carlo","Suppose $H$ is a Hilbert space and let $T \in B(H,H)$ where in our notation $B(H,H)$ denotes the set of all linear continuous operators $H \rightarrow H$. We defined the adjoint of $T$ as the unique $T^* \in B(H,H)$ such that $\langle Tx,y \rangle = \langle x, T^*y\rangle$ for all $x,y$ in $H$. I proved its existence as follows: Fix $y \in H$. Put $\Phi_y: H \rightarrow \mathbb{C}, x \mapsto \langle Tx,y \rangle$. This functional is continuous since $|\langle Tx, y\rangle | \leq ||Tx||\; ||y|| \leq ||T||\; ||x||\; ||y||$. Therefore we can apply the Riesz-Fréchet theorem which gives us the existence of a vector $T^*y \in H$ such that for all $x \in H$ we have $\langle Tx, y\rangle = \langle x, T^* y\rangle$. I now have to prove that $||T^*|| = ||T||$. I can show $||T^*|| \leq ||T||$: Since the Riesz theorem gives us an isometry we have $||T^*y|| = ||\Phi_y||_{H*} = \sup_{||x||\leq 1} |\langle Tx, y\rangle| \leq ||T||\;||y||$ and thus $||T^*|| \leq ||T||$. However, I do not see how to prove the other inequality without using consequences of Hahn-Banach or similar results. It seems like I am missing some quite simple point. Any help is very much appreciated! Regards, Carlo",,['functional-analysis']
76,"Space Sobolev $W^{m,p}$ complete",Space Sobolev  complete,"W^{m,p}",Show that Sobolev space is complete. I am trying Than $L^p(\Omega)$ is complete then If $f_n \in L^p(\Omega)$ then $f_n \to f \in L^p(\Omega)$. But rest show that $D^{\alpha}f \in L^p(\Omega)$. How I will be able to show this?,Show that Sobolev space is complete. I am trying Than $L^p(\Omega)$ is complete then If $f_n \in L^p(\Omega)$ then $f_n \to f \in L^p(\Omega)$. But rest show that $D^{\alpha}f \in L^p(\Omega)$. How I will be able to show this?,,"['functional-analysis', 'convergence-divergence']"
77,Why are weak topologies useful in functional analysis?,Why are weak topologies useful in functional analysis?,,"I've been reading through chapter 3, Rudin's Functional Analysis, and an important point is the one of weak topology. From the theorems it seems to me weak topologies are somehow the result of introducing a topology of a vector space by using the dual space, however I believe there must be some special and useful property of such topologies that I might be missing. Can anyone explain why weak and weak* topologies are actually useful?","I've been reading through chapter 3, Rudin's Functional Analysis, and an important point is the one of weak topology. From the theorems it seems to me weak topologies are somehow the result of introducing a topology of a vector space by using the dual space, however I believe there must be some special and useful property of such topologies that I might be missing. Can anyone explain why weak and weak* topologies are actually useful?",,"['functional-analysis', 'topological-vector-spaces', 'weak-topology']"
78,How do you prove translation invariance of Fourier transform?,How do you prove translation invariance of Fourier transform?,,"Let $f$ be a rapidly decreasing function in the sense that it lies in the Schwartz space $\mathcal{S}(\Bbb{R})$ . Then $\widehat{f(x+h)} = \hat{f}(\omega) e^{i 2 \pi h \omega}$, where $\hat{f}(\omega)$ is the Fourier transform of $f(x)$. How do I prove that?  This might not depend on the rapidly decreasing part.","Let $f$ be a rapidly decreasing function in the sense that it lies in the Schwartz space $\mathcal{S}(\Bbb{R})$ . Then $\widehat{f(x+h)} = \hat{f}(\omega) e^{i 2 \pi h \omega}$, where $\hat{f}(\omega)$ is the Fourier transform of $f(x)$. How do I prove that?  This might not depend on the rapidly decreasing part.",,"['functional-analysis', 'fourier-analysis']"
79,Nonnegative linear functionals over $l^\infty$,Nonnegative linear functionals over,l^\infty,"My purpose is a clarification of the role of the axiom of choice in constructing limits for bounded sequences. Namely, we want a linear functional of norm 1 defined on the space of all bounded complex sequences that takes nonnegative sequences to nonnegative numbers. We also want that it annihilate all sequences with finite number of nonzero elements, and that it take constant sequences to the same constant. It is well known that such functionals can be realized as limits along free ultrafilters, thus the axiom of choice is needed. I would like to understand if the construction can be simplified if, instead of the ultrafilters, we allow functionals with properties as described above. Here are my questions: Does there exist an explicit construction of such a functional? If not, does this mean that there are formal reasons why the explicit construction cannot exist? Is it possible to establish the fact that the functional exists without using the axiom of choice? Update after discussion: It is important that there are different ""levels"" of the axiom of choice. If I felt this better when I wrote this posting, I would also add the following question answered below in the affirmative: Is it possible to construct the functional as desired without ultrafilters, but with using only the Hahn-Banach theorem for the space $l^\infty$? This question looks more natural and elementary than the list of my questions, but the path sometimes gives you more than the goal. Many thanks to you all for the very helphul and interesting discussion!","My purpose is a clarification of the role of the axiom of choice in constructing limits for bounded sequences. Namely, we want a linear functional of norm 1 defined on the space of all bounded complex sequences that takes nonnegative sequences to nonnegative numbers. We also want that it annihilate all sequences with finite number of nonzero elements, and that it take constant sequences to the same constant. It is well known that such functionals can be realized as limits along free ultrafilters, thus the axiom of choice is needed. I would like to understand if the construction can be simplified if, instead of the ultrafilters, we allow functionals with properties as described above. Here are my questions: Does there exist an explicit construction of such a functional? If not, does this mean that there are formal reasons why the explicit construction cannot exist? Is it possible to establish the fact that the functional exists without using the axiom of choice? Update after discussion: It is important that there are different ""levels"" of the axiom of choice. If I felt this better when I wrote this posting, I would also add the following question answered below in the affirmative: Is it possible to construct the functional as desired without ultrafilters, but with using only the Hahn-Banach theorem for the space $l^\infty$? This question looks more natural and elementary than the list of my questions, but the path sometimes gives you more than the goal. Many thanks to you all for the very helphul and interesting discussion!",,"['functional-analysis', 'set-theory', 'banach-spaces', 'axiom-of-choice', 'constructive-mathematics']"
80,Sobolev spaces with negative exponent,Sobolev spaces with negative exponent,,"For $k\in \mathbb{N}$ and $p \geq 1,$ what is the motivation behind defining the Sobolev spaces with negative exponent $W^{-k,p}$ as the dual of $W_0^{k,p}$ and not as the dual of $W^{k,p}.$",For and what is the motivation behind defining the Sobolev spaces with negative exponent as the dual of and not as the dual of,"k\in \mathbb{N} p \geq 1, W^{-k,p} W_0^{k,p} W^{k,p}.","['functional-analysis', 'analysis', 'sobolev-spaces']"
81,Ideal in $C(X)$,Ideal in,C(X),"Let $X$ be a compact Hausdorff space, and $C(X)$ the space of complex-valued continuous functions with maximum-norm. The following problem is driving me little nuts. I want to show that every closed Ideal $J\subset C(X)$ is of the form $J_Y = \{f\in C(X)| Y\subset f^{-1}(0)\}$ where $Y\subset X$ is some closed set. It seems that $Y=\bigcap_{f\in J}f^{-1}(0)$ is the only logical choice. Then $J\subset J_Y$ is obvious, but $J_Y\subset J$ is not so obvious. It seemed logical to me that if $f\in J$ then $J_{f^{-1}(0)} \subset J$, but I can't prove it. If this would be true I thought of finding a $g\in J$ such that $g^{-1}(0)=Y $ would then be sufficient. Maybe constructing a sequence of functions $g_n\in J_n\subset J$ that is 0 on some $Y_n\supset Y$ and using the fact that $J$ is closed to show $g_n\to g\in J$. Does someone have any suggestions? I'm little stuck.","Let $X$ be a compact Hausdorff space, and $C(X)$ the space of complex-valued continuous functions with maximum-norm. The following problem is driving me little nuts. I want to show that every closed Ideal $J\subset C(X)$ is of the form $J_Y = \{f\in C(X)| Y\subset f^{-1}(0)\}$ where $Y\subset X$ is some closed set. It seems that $Y=\bigcap_{f\in J}f^{-1}(0)$ is the only logical choice. Then $J\subset J_Y$ is obvious, but $J_Y\subset J$ is not so obvious. It seemed logical to me that if $f\in J$ then $J_{f^{-1}(0)} \subset J$, but I can't prove it. If this would be true I thought of finding a $g\in J$ such that $g^{-1}(0)=Y $ would then be sufficient. Maybe constructing a sequence of functions $g_n\in J_n\subset J$ that is 0 on some $Y_n\supset Y$ and using the fact that $J$ is closed to show $g_n\to g\in J$. Does someone have any suggestions? I'm little stuck.",,"['functional-analysis', 'c-star-algebras']"
82,Do there exist some relations between Functional Analysis and Algebraic Topology?,Do there exist some relations between Functional Analysis and Algebraic Topology?,,"As the title: does there exist some relations between Functional Analysis and Algebraic Topology. As we have known, the tools developed in Algebraic Topology are used to classify spaces, especially the geometrical structures in finite dimensional Euclidean space. But when we come across some infinite dimensional spaces, such as Banach spaces, do the tools in Algebraic Topology also take effect? Moreover, are there some books discussing such relation? My learning background is listed following:basic algebra(group, ring, field, polynomial); Rudin's real & complex analysis and functional analysis; general topology(Munkres level). Any viewpoint will be appreciated.","As the title: does there exist some relations between Functional Analysis and Algebraic Topology. As we have known, the tools developed in Algebraic Topology are used to classify spaces, especially the geometrical structures in finite dimensional Euclidean space. But when we come across some infinite dimensional spaces, such as Banach spaces, do the tools in Algebraic Topology also take effect? Moreover, are there some books discussing such relation? My learning background is listed following:basic algebra(group, ring, field, polynomial); Rudin's real & complex analysis and functional analysis; general topology(Munkres level). Any viewpoint will be appreciated.",,"['functional-analysis', 'algebraic-topology']"
83,A linear operator between Banach spaces is weakly continuous iff norm continuous?,A linear operator between Banach spaces is weakly continuous iff norm continuous?,,"Claim : a linear function $T$ between Banach spaces is weakly continuous iff norm continuous? Okay, So I think I have realised weakly continuous implies norm continuous. As weakly continuous implies weakly sequentially continuous. Now suppose that $T$ is unbounded. But we also know that 'weakly convergent implies weakly bounded', which implies norm bounded. But this would then imply that '$T(x_{n})$ converges weakly implies that $\|T(x_{n})\|$ is bounded'. Hence $T(x_{n})$ is not weakly convergent, so $T$ cannot be weakly continuous. Contradiction! Hence T is bounded. Any ideas on the converse? I.e How do I show norm continuous is weakly continuous?","Claim : a linear function $T$ between Banach spaces is weakly continuous iff norm continuous? Okay, So I think I have realised weakly continuous implies norm continuous. As weakly continuous implies weakly sequentially continuous. Now suppose that $T$ is unbounded. But we also know that 'weakly convergent implies weakly bounded', which implies norm bounded. But this would then imply that '$T(x_{n})$ converges weakly implies that $\|T(x_{n})\|$ is bounded'. Hence $T(x_{n})$ is not weakly convergent, so $T$ cannot be weakly continuous. Contradiction! Hence T is bounded. Any ideas on the converse? I.e How do I show norm continuous is weakly continuous?",,['functional-analysis']
84,"relations between distance-preserving, norm-preserving, and inner product-preserving maps","relations between distance-preserving, norm-preserving, and inner product-preserving maps",,"An inner product can induce a norm by defining $\|x\| = \sqrt{\langle x,x \rangle}$, the a norm can induce a metric by setting $d(x,y) = \|x - y\|$. But not every norm (metric) is induced from inner product (norm), unless the parallelogram law (homogeneity and translation invariance conditions) is (are) satisfied. Suppose an inner product induces a norm, which then induces a metric, using these defined inner product, norm and metric, can we tell what are the relations between distance-preserving, norm-preserving, and inner product-preserving maps? I just know one: if an isometry (distance-preserving), which is injective, is also surjective, then it's unitary (bijective), which means the isometry is also inner product-preserving. For example,  distance-preserving maps on a compact metric space are  also inner product-preserving. Are there any other relations?","An inner product can induce a norm by defining $\|x\| = \sqrt{\langle x,x \rangle}$, the a norm can induce a metric by setting $d(x,y) = \|x - y\|$. But not every norm (metric) is induced from inner product (norm), unless the parallelogram law (homogeneity and translation invariance conditions) is (are) satisfied. Suppose an inner product induces a norm, which then induces a metric, using these defined inner product, norm and metric, can we tell what are the relations between distance-preserving, norm-preserving, and inner product-preserving maps? I just know one: if an isometry (distance-preserving), which is injective, is also surjective, then it's unitary (bijective), which means the isometry is also inner product-preserving. For example,  distance-preserving maps on a compact metric space are  also inner product-preserving. Are there any other relations?",,"['functional-analysis', 'normed-spaces']"
85,Can the phase of a function be extracted from only its absolute value and its Fourier transform's absolute value?,Can the phase of a function be extracted from only its absolute value and its Fourier transform's absolute value?,,"If for a function $f(x)$ only its absolute value $|f(x)|$ and the absolute value $|\tilde f(k)|$ of its Fourier transform $\tilde f(k)=N\int f(x)e^{-ikx} dx$ is known, can $f(x) = |f(x)|e^{i\phi(x)}$ and thus the phase function $\phi(x)$ be extracted? (with e.g. $N=1/(2\pi)$) As Marek already stated , this is even not uniquely possible for $f(x)=c\in\mathbb C$, since the global phase cannot be re-determined. So please let me extend the question to Under what circumstances is the phase-retrieval (up to a global phase) uniquely possible, and what ambiguities could arise otherwise?","If for a function $f(x)$ only its absolute value $|f(x)|$ and the absolute value $|\tilde f(k)|$ of its Fourier transform $\tilde f(k)=N\int f(x)e^{-ikx} dx$ is known, can $f(x) = |f(x)|e^{i\phi(x)}$ and thus the phase function $\phi(x)$ be extracted? (with e.g. $N=1/(2\pi)$) As Marek already stated , this is even not uniquely possible for $f(x)=c\in\mathbb C$, since the global phase cannot be re-determined. So please let me extend the question to Under what circumstances is the phase-retrieval (up to a global phase) uniquely possible, and what ambiguities could arise otherwise?",,"['analysis', 'functional-analysis', 'fourier-analysis']"
86,"Example to prove that $ C^1[0,1] $ is not a Banach space for the uniform norm?",Example to prove that  is not a Banach space for the uniform norm?," C^1[0,1] ","The space $ C^1[0,1] $- the space of all continuously differentiable functions on $ [0,1]$ is not a Banach space with respect to the sup norm,$ \|.\|_{\infty} $ since the uniform limit of a continuously differentiable function need not be differentiable. How can I illustate this statement using a counter example? Can I use $ f_{n}=\frac1 n \sin nx $ as a counter example? Also, is $ C^1[0,1] $ is same as the space given by $ X=\{f\in C^1[0,1]:f(0)=0 \}$. Can I use the same example to show that this is not a Banach space? More help is appreciated! Thanks!","The space $ C^1[0,1] $- the space of all continuously differentiable functions on $ [0,1]$ is not a Banach space with respect to the sup norm,$ \|.\|_{\infty} $ since the uniform limit of a continuously differentiable function need not be differentiable. How can I illustate this statement using a counter example? Can I use $ f_{n}=\frac1 n \sin nx $ as a counter example? Also, is $ C^1[0,1] $ is same as the space given by $ X=\{f\in C^1[0,1]:f(0)=0 \}$. Can I use the same example to show that this is not a Banach space? More help is appreciated! Thanks!",,['functional-analysis']
87,Is every probability measure in the line induced by a random variable?,Is every probability measure in the line induced by a random variable?,,"It is a basic fact in probability theory that, for every random variable $$ X: (\Omega, \mathcal{F}, \mathbb{P}) \to (\mathbb{R}, \mathcal{B}), $$ we have an associated measure $\mathbb{P}_X$ on the borelians of $\mathbb{R}$ given by $$ \mathbb{P}_X(B) := \mathbb{P}(X \in B) = \mathbb{P}(X^{-1}(B)), \forall B \in \mathbb{B}.    $$ $\mathbb{P}_X$ is called the measure induced by $X$ . My question: is the opposite also true? That is, given a probability measure on the borelians of $\mathbb{R}$ , is it induced by a random variable? More precisely: Is there a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ such that, given a probability measure $\mu$ in $(\mathbb{R}, \mathcal{B})$ , one can find a random variable $X: (\Omega, \mathcal{F}, \mathbb{P}) \to (\mathbb{R}, \mathcal{B})$ such that $\mu$ is induced by $X$ ? I aprreciate your concern! [Edit] What I really want is a probability space that can be used for global representation of probability measures as measures induced by random variables. I have a guess that the space $\Omega = \{f: \mathbb{R} \to \mathbb{R} | f \:\text{is Borel measurable}\}$ with the $\sigma$ -algebra of cilinders and some appropriate measure is the space desired, but I'm not pretty sure on how to prove it.","It is a basic fact in probability theory that, for every random variable we have an associated measure on the borelians of given by is called the measure induced by . My question: is the opposite also true? That is, given a probability measure on the borelians of , is it induced by a random variable? More precisely: Is there a probability space such that, given a probability measure in , one can find a random variable such that is induced by ? I aprreciate your concern! [Edit] What I really want is a probability space that can be used for global representation of probability measures as measures induced by random variables. I have a guess that the space with the -algebra of cilinders and some appropriate measure is the space desired, but I'm not pretty sure on how to prove it.","
X: (\Omega, \mathcal{F}, \mathbb{P}) \to (\mathbb{R}, \mathcal{B}),
 \mathbb{P}_X \mathbb{R} 
\mathbb{P}_X(B) := \mathbb{P}(X \in B) = \mathbb{P}(X^{-1}(B)), \forall B \in \mathbb{B}.   
 \mathbb{P}_X X \mathbb{R} (\Omega, \mathcal{F}, \mathbb{P}) \mu (\mathbb{R}, \mathcal{B}) X: (\Omega, \mathcal{F}, \mathbb{P}) \to (\mathbb{R}, \mathcal{B}) \mu X \Omega = \{f: \mathbb{R} \to \mathbb{R} | f \:\text{is Borel measurable}\} \sigma","['functional-analysis', 'probability-theory', 'measure-theory']"
88,C$^*$-algebras: When is there equality in the triangle inequality?,C-algebras: When is there equality in the triangle inequality?,^*,"(I had never thought about this question before, and I want to record the basic answer here for future reference) Let $A$ be a C$^*$-algebra, and $x,y\in A$. When do we have equality in the triangle inequality? $$\|x+y\|=\|x\|+\|y\|$$","(I had never thought about this question before, and I want to record the basic answer here for future reference) Let $A$ be a C$^*$-algebra, and $x,y\in A$. When do we have equality in the triangle inequality? $$\|x+y\|=\|x\|+\|y\|$$",,"['functional-analysis', 'normed-spaces', 'operator-algebras', 'c-star-algebras']"
89,Why no trace operator in $L^2(\Omega)$?,Why no trace operator in ?,L^2(\Omega),"We have trace operator which allows us to define boundary values of an $H^1$ function. This is because of the fact that $C^\infty$ is dense in $H^1$ under the $H^1$ norm, I believe. I'm sure either $C^0$ or $C^\infty$ is also dense in $L^2$ in the $L^2$ norm, so why no trace operator in this case? Or am I wrong?","We have trace operator which allows us to define boundary values of an $H^1$ function. This is because of the fact that $C^\infty$ is dense in $H^1$ under the $H^1$ norm, I believe. I'm sure either $C^0$ or $C^\infty$ is also dense in $L^2$ in the $L^2$ norm, so why no trace operator in this case? Or am I wrong?",,"['functional-analysis', 'partial-differential-equations', 'operator-theory', 'sobolev-spaces']"
90,"Showing $(C[0,1], d_1)$ is not a complete metric space",Showing  is not a complete metric space,"(C[0,1], d_1)","I am completely stuck on this problem: $C[0,1] = \{f: f\text{ is continuous function on } [0,1] \}$ with metric $d_1$ defined as follows: $d_1(f,g) = \int_{0}^{1} |f(x) - g(x)|dx $. Let the sequence $\{f_n\}_{n =1}^{\infty}\subseteq C[0,1]$ be defined as follows: $    f_n(x) = \left\{    \begin{array}{l l}      -1 & \quad \text{ $x\in [0, 1/2 - 1/n]$}\\      n(x - 1/2) & \quad \text{$x\in [1/2 - 1/n, 1/2 +1/n]$}\\   1 & \quad \text{ $x\in [1/2 +1/n, 1]$}\\    \end{array} \right.  $ Then $f_{n}$ is cauchy in $(C[0,1], d_1)$ but not convergent in $d_1$. I have proved that $f_{n}$ is not convergent in $(C[0,1])$ since it is converging to discontinuous function given as follows: $    f_n(x) = \left\{    \begin{array}{l l}      -1 & \quad \text{ $x\in [0, 1/2 )$}\\      0 & \quad \text{$x = 1/2$}\\   1 & \quad \text{ $x\in (1/2 , 1]$}\\    \end{array} \right.  $ I am finding it difficult to prove that $f_{n}$ is Cauchy in $(C[0,1], d_1)$.  I need help to solve this problem. Edit: I am sorry i have to show $f_n$ is cauchy Thanks for helping me.","I am completely stuck on this problem: $C[0,1] = \{f: f\text{ is continuous function on } [0,1] \}$ with metric $d_1$ defined as follows: $d_1(f,g) = \int_{0}^{1} |f(x) - g(x)|dx $. Let the sequence $\{f_n\}_{n =1}^{\infty}\subseteq C[0,1]$ be defined as follows: $    f_n(x) = \left\{    \begin{array}{l l}      -1 & \quad \text{ $x\in [0, 1/2 - 1/n]$}\\      n(x - 1/2) & \quad \text{$x\in [1/2 - 1/n, 1/2 +1/n]$}\\   1 & \quad \text{ $x\in [1/2 +1/n, 1]$}\\    \end{array} \right.  $ Then $f_{n}$ is cauchy in $(C[0,1], d_1)$ but not convergent in $d_1$. I have proved that $f_{n}$ is not convergent in $(C[0,1])$ since it is converging to discontinuous function given as follows: $    f_n(x) = \left\{    \begin{array}{l l}      -1 & \quad \text{ $x\in [0, 1/2 )$}\\      0 & \quad \text{$x = 1/2$}\\   1 & \quad \text{ $x\in (1/2 , 1]$}\\    \end{array} \right.  $ I am finding it difficult to prove that $f_{n}$ is Cauchy in $(C[0,1], d_1)$.  I need help to solve this problem. Edit: I am sorry i have to show $f_n$ is cauchy Thanks for helping me.",,"['functional-analysis', 'metric-spaces']"
91,A vector without minimum norm in a Banach space,A vector without minimum norm in a Banach space,,"Question : Let $E = C[0, 1]$, with sup norm. Let $K$ consist of all $f$ in $E$ such that $$\int_{0}^{\frac{1}{2}}f(s)ds-\int_{\frac{1}{2}}^{1}f(s)ds=1$$ Prove that $K$ is a closed convex subset of $E$ which contains no element of minimum norm. My proof: For convexity of $K$ : Let $f, g \in K$ and $\alpha\in [0,1]$ Then  $\begin{align}\int_{0}^{\frac{1}{2}}&((1-\alpha)f(s)+\alpha g(s))ds-\int_{\frac{1}{2}}^{1}((1-\alpha)f(s)+\alpha g(s))ds& \\ &=(1-\alpha)\left(\int_{0}^{\frac{1}{2}}f(s)ds-\int_{\frac{1}{2}}^{1}f(s)ds\right)+\alpha\left(\int_{0}^{\frac{1}{2}}g(s)ds-\int_{\frac{1}{2}}^{1}g(s)ds\right)&\\ &=(1-\alpha)+\alpha=1 \end{align}$ For closure: Let $f_{n}$ be a sequence in $K$ such that $f_{n}\to f$ as $n\to \infty$. We need to show that $f\in K$ $\int_{0}^{\frac{1}{2}}f_{n}(s)ds-\int_{\frac{1}{2}}^{1}f_{n}(s)ds=1$ because $f_{n}$ is in $K$. Taking limit as $n\to \infty$ we have $f\in K$. Next, is to show $K$ contains no element of minimum norm, but I stuck here, can I go by contradiction? That is supposing K contains at least 1 element of minimum norm, say $f_{0}$ i.e $\|f_{0}\|=\inf_{f\in K}\|f\|$, then what? Please I need the help of professionals. Thanks","Question : Let $E = C[0, 1]$, with sup norm. Let $K$ consist of all $f$ in $E$ such that $$\int_{0}^{\frac{1}{2}}f(s)ds-\int_{\frac{1}{2}}^{1}f(s)ds=1$$ Prove that $K$ is a closed convex subset of $E$ which contains no element of minimum norm. My proof: For convexity of $K$ : Let $f, g \in K$ and $\alpha\in [0,1]$ Then  $\begin{align}\int_{0}^{\frac{1}{2}}&((1-\alpha)f(s)+\alpha g(s))ds-\int_{\frac{1}{2}}^{1}((1-\alpha)f(s)+\alpha g(s))ds& \\ &=(1-\alpha)\left(\int_{0}^{\frac{1}{2}}f(s)ds-\int_{\frac{1}{2}}^{1}f(s)ds\right)+\alpha\left(\int_{0}^{\frac{1}{2}}g(s)ds-\int_{\frac{1}{2}}^{1}g(s)ds\right)&\\ &=(1-\alpha)+\alpha=1 \end{align}$ For closure: Let $f_{n}$ be a sequence in $K$ such that $f_{n}\to f$ as $n\to \infty$. We need to show that $f\in K$ $\int_{0}^{\frac{1}{2}}f_{n}(s)ds-\int_{\frac{1}{2}}^{1}f_{n}(s)ds=1$ because $f_{n}$ is in $K$. Taking limit as $n\to \infty$ we have $f\in K$. Next, is to show $K$ contains no element of minimum norm, but I stuck here, can I go by contradiction? That is supposing K contains at least 1 element of minimum norm, say $f_{0}$ i.e $\|f_{0}\|=\inf_{f\in K}\|f\|$, then what? Please I need the help of professionals. Thanks",,"['functional-analysis', 'banach-spaces']"
92,Category of Banach spaces,Category of Banach spaces,,"I know that Banach spaces forms a category $\bf Ban_1$ with morphisms as contracting linear maps. This is not an abelian category since $cokernels$ are not there in it. Q.1 Can we talk about the direct limits of a directed system of Banach spaces? Do they exists? Q.2 Does the ""category of short exact sequences"" of Banach spaces makes sense? if no, does some modification in morphisms between Banach spaces make it work? Q.3 With all the above settings assumed to be working,does direct limit preserve the exactness in the sense that if $(X_i)$ , $(Y_i)$ and $(Z_i)$ are directed systems of Banach spaces on directed set $I$ such  that for each $i\in I$ , the sequence $$0\to X_i\to Y_i\to Z_i\to 0$$ is exact , then $$0\to\lim_{\longrightarrow}X_i\to\lim_{\longrightarrow}Y_i\to \lim_{\longrightarrow}Z_i\to 0$$ is exact? Apologies for asking multiple questions at once. I am new to category theory and trying to learn it from functional analysis point of view. Any reference related to above questions will be helpful.","I know that Banach spaces forms a category with morphisms as contracting linear maps. This is not an abelian category since are not there in it. Q.1 Can we talk about the direct limits of a directed system of Banach spaces? Do they exists? Q.2 Does the ""category of short exact sequences"" of Banach spaces makes sense? if no, does some modification in morphisms between Banach spaces make it work? Q.3 With all the above settings assumed to be working,does direct limit preserve the exactness in the sense that if , and are directed systems of Banach spaces on directed set such  that for each , the sequence is exact , then is exact? Apologies for asking multiple questions at once. I am new to category theory and trying to learn it from functional analysis point of view. Any reference related to above questions will be helpful.",\bf Ban_1 cokernels (X_i) (Y_i) (Z_i) I i\in I 0\to X_i\to Y_i\to Z_i\to 0 0\to\lim_{\longrightarrow}X_i\to\lim_{\longrightarrow}Y_i\to \lim_{\longrightarrow}Z_i\to 0,"['functional-analysis', 'category-theory', 'banach-spaces']"
93,Meaning of the continuous spectrum and the residual spectrum,Meaning of the continuous spectrum and the residual spectrum,,"Let's consider an infinite dimensional space $X$ and a linear operator $T$. The resolvent operator of $T$ is $R_\lambda (T) = (T-\lambda I)^{-1}$. A regular value $\lambda$ of $T$ is a complex number such that: (R1) $R_\lambda(T)$ exists (R2) $R_\lambda(T)$ is bounded (R3) $R_\lambda(T)$ defined on a set which is dense in $X$ The resolvent set $\rho(T)$ consists of all regular values $\lambda$ of $T$. The complement $\sigma(T)=C-\rho(T)$ is the spectrum of $T$ and we may distinguish parts of the spectrum: point spectrum (eigenvalues) $\sigma_p(T)$: (R1) isn't satisfied continuous spectrum $\sigma_c(T)$: (R2) isn't satisfied, but (R1) and (R3) are satisfied residual spectrum $\sigma_r(T)$: (R3) isn't satisfied, (R1) is satisfied, (R2) - doesn't matter Please, help me to clarify a couple of points: Question 1: The point spectrum consists of eigenvalues and exists in finite dimensional case. So its meaning seems to be the same as in a finite dimensional case (scaling of eigenvectors that roughly represent orientation of the distortion by $T$). What is the meaning of the continuous and the residual spectrum? Question 2: Why do we care about dense in the definitions? I have found a related question but didn't get the exact answer from it.","Let's consider an infinite dimensional space $X$ and a linear operator $T$. The resolvent operator of $T$ is $R_\lambda (T) = (T-\lambda I)^{-1}$. A regular value $\lambda$ of $T$ is a complex number such that: (R1) $R_\lambda(T)$ exists (R2) $R_\lambda(T)$ is bounded (R3) $R_\lambda(T)$ defined on a set which is dense in $X$ The resolvent set $\rho(T)$ consists of all regular values $\lambda$ of $T$. The complement $\sigma(T)=C-\rho(T)$ is the spectrum of $T$ and we may distinguish parts of the spectrum: point spectrum (eigenvalues) $\sigma_p(T)$: (R1) isn't satisfied continuous spectrum $\sigma_c(T)$: (R2) isn't satisfied, but (R1) and (R3) are satisfied residual spectrum $\sigma_r(T)$: (R3) isn't satisfied, (R1) is satisfied, (R2) - doesn't matter Please, help me to clarify a couple of points: Question 1: The point spectrum consists of eigenvalues and exists in finite dimensional case. So its meaning seems to be the same as in a finite dimensional case (scaling of eigenvectors that roughly represent orientation of the distortion by $T$). What is the meaning of the continuous and the residual spectrum? Question 2: Why do we care about dense in the definitions? I have found a related question but didn't get the exact answer from it.",,"['functional-analysis', 'spectral-theory']"
94,Proof of Gelfand formula for spectral radius,Proof of Gelfand formula for spectral radius,,"STATEMENT: Let $A$ be a Banach algebra, then for every $x\in A$ we have $$\lim_{n\rightarrow\infty}\|x^n\|^{1/n}=r(x)$$ Proof: We know that $r(x)\leq \lim \inf_n\|x^n\|^{1/n}$ , so it suffices to prove that $$\limsup_{n\rightarrow \infty}\|x^n\|^{1/n}\leq r(x)$$ We need only consider the case $x\neq 0$ . To prove our formula choose $\lambda \in \mathbb{C}$ satisfying $|\lambda|<1/r(x)$ . We claim that the sequence $\left\{(\lambda x)^n:n-1,2,...\right\}$ is bounded. Indeed, by the Banach-Steinhaus theorem it suffices to show thatfor every bounded linear function $\rho$ on $A$ we have the following $$|\rho(x^n)\lambda^n|=|\rho((x\lambda)^n)|\leq M_p<\infty$$ Question: I don't see why Banach-Steinhaus theorem would be sufficient to show that the sequence is bounded. This proof is from A Short Course in Spectral Theory by William Arveson.","STATEMENT: Let be a Banach algebra, then for every we have Proof: We know that , so it suffices to prove that We need only consider the case . To prove our formula choose satisfying . We claim that the sequence is bounded. Indeed, by the Banach-Steinhaus theorem it suffices to show thatfor every bounded linear function on we have the following Question: I don't see why Banach-Steinhaus theorem would be sufficient to show that the sequence is bounded. This proof is from A Short Course in Spectral Theory by William Arveson.","A x\in A \lim_{n\rightarrow\infty}\|x^n\|^{1/n}=r(x) r(x)\leq \lim \inf_n\|x^n\|^{1/n} \limsup_{n\rightarrow \infty}\|x^n\|^{1/n}\leq r(x) x\neq 0 \lambda \in \mathbb{C} |\lambda|<1/r(x) \left\{(\lambda x)^n:n-1,2,...\right\} \rho A |\rho(x^n)\lambda^n|=|\rho((x\lambda)^n)|\leq M_p<\infty","['functional-analysis', 'spectral-theory', 'banach-algebras']"
95,Hardy–Littlewood-Sobolev inequality without Marcinkiewicz interpolation?,Hardy–Littlewood-Sobolev inequality without Marcinkiewicz interpolation?,,"Here is the statement of the Hardy–Littlewood–Sobolev theorem. Let $0< \alpha< n$, $1 < p < q < \infty$ and $\frac{1}{q}=\frac{1}{p}-\frac{\alpha}{n}$. Then: $$ \left \| \int_{\mathbb{R}^n} \frac{f(y)dy}{|x-y|^{n-\alpha} } \right\|_{L^q(\mathbb{R}^n)}\leq C\left\| f\right\| _{L^p(\mathbb{R^n})}.$$ I know two proofs of this theorem. The first one (I think the standard one) uses the Marcinckiewicz interpolation theorem . The second one uses the Hardy–Littlewood maximal function and its boundedness from $L^p(\mathbb{R}^n)$ to $L^p(\mathbb{R}^n)$. To prove this boundedness I need the Marcinkiewicz interpolation theorem again. (Even if it's enough the ""diagonal"" version.) My question is: is there a proof of the above theorem that doesn't use Marcinkiewicz? Is this interpolation theorem necessary in order to prove HLS?","Here is the statement of the Hardy–Littlewood–Sobolev theorem. Let $0< \alpha< n$, $1 < p < q < \infty$ and $\frac{1}{q}=\frac{1}{p}-\frac{\alpha}{n}$. Then: $$ \left \| \int_{\mathbb{R}^n} \frac{f(y)dy}{|x-y|^{n-\alpha} } \right\|_{L^q(\mathbb{R}^n)}\leq C\left\| f\right\| _{L^p(\mathbb{R^n})}.$$ I know two proofs of this theorem. The first one (I think the standard one) uses the Marcinckiewicz interpolation theorem . The second one uses the Hardy–Littlewood maximal function and its boundedness from $L^p(\mathbb{R}^n)$ to $L^p(\mathbb{R}^n)$. To prove this boundedness I need the Marcinkiewicz interpolation theorem again. (Even if it's enough the ""diagonal"" version.) My question is: is there a proof of the above theorem that doesn't use Marcinkiewicz? Is this interpolation theorem necessary in order to prove HLS?",,"['functional-analysis', 'reference-request', 'fourier-analysis', 'interpolation', 'harmonic-analysis']"
96,Distance between a point and closed set in finite dimensional space,Distance between a point and closed set in finite dimensional space,,"Let $X$ be a linear normed space. I need to prove that $X$ is  finite dimensional normed space if and only if for every non empty closed set $C$ contained  in $X$ and for every $x$ in $X$ the distance $d(x,C)$ is achieved in specific $c$. I know how to prove the direction which assumes $X$ is finite dimensional (use Riesz lemma) but I dont know what to do in the other direction.  thanks","Let $X$ be a linear normed space. I need to prove that $X$ is  finite dimensional normed space if and only if for every non empty closed set $C$ contained  in $X$ and for every $x$ in $X$ the distance $d(x,C)$ is achieved in specific $c$. I know how to prove the direction which assumes $X$ is finite dimensional (use Riesz lemma) but I dont know what to do in the other direction.  thanks",,"['functional-analysis', 'normed-spaces']"
97,Two-valued measure is a Dirac measure,Two-valued measure is a Dirac measure,,"Let $(X,\mathfrak B)$ be a measurable space such that $\{x\}\in \mathfrak B$ for all $x\in X$, and let $\mu$ be a positive measure on this space such that $$   \mu(B) \in\{0,1\} \quad\text{for all }B\in \mathfrak B. $$ What are the mildest conditions on $(X,\mathfrak B)$ that imply that $\mu =\delta_x$ for some $x\in X$? It is known to hold for $\Bbb R$ with a Borel $\sigma$-algebra, and I believe it fairly easy extends to $\Bbb R^n$. I wonder, though, whether it holds at least for locally compact Polish spaces, or perhaps for more general case. I am also interested in examples of spaces where such statement does not hold.","Let $(X,\mathfrak B)$ be a measurable space such that $\{x\}\in \mathfrak B$ for all $x\in X$, and let $\mu$ be a positive measure on this space such that $$   \mu(B) \in\{0,1\} \quad\text{for all }B\in \mathfrak B. $$ What are the mildest conditions on $(X,\mathfrak B)$ that imply that $\mu =\delta_x$ for some $x\in X$? It is known to hold for $\Bbb R$ with a Borel $\sigma$-algebra, and I believe it fairly easy extends to $\Bbb R^n$. I wonder, though, whether it holds at least for locally compact Polish spaces, or perhaps for more general case. I am also interested in examples of spaces where such statement does not hold.",,"['functional-analysis', 'measure-theory', 'probability-theory']"
98,Does separability follow from weak-* sequential separability of dual space?,Does separability follow from weak-* sequential separability of dual space?,,"Let $E$ be a Banach space. Suppose that $E'$ is weakly-* sequentially separable, that is, that there exists a countable $D \subset E'$ s.t. every $x' \in E'$ is a limit point of a sequence in $D$. Does it follow that $E$ is separable? This question arises from a conversation with a friend of mine. He thinks this is true and plans to use it to prove separability of $C(K)$ for a metrizable and compact Hausdorff $K$. I'm not so sure this can work, though. Of course, if $E'$ is norm separable then $E$ is separable, but we are talking about a much weaker topology here.","Let $E$ be a Banach space. Suppose that $E'$ is weakly-* sequentially separable, that is, that there exists a countable $D \subset E'$ s.t. every $x' \in E'$ is a limit point of a sequence in $D$. Does it follow that $E$ is separable? This question arises from a conversation with a friend of mine. He thinks this is true and plans to use it to prove separability of $C(K)$ for a metrizable and compact Hausdorff $K$. I'm not so sure this can work, though. Of course, if $E'$ is norm separable then $E$ is separable, but we are talking about a much weaker topology here.",,"['functional-analysis', 'banach-spaces', 'examples-counterexamples']"
99,Does the identity $\cos^2(x)+\sin^2(x)=1$ hold in a unital Banach algebra where $1$ is the unit?,Does the identity  hold in a unital Banach algebra where  is the unit?,\cos^2(x)+\sin^2(x)=1 1,Let's assume that we have an unital Banach algebra $T$ and we define sine and cosine using the normal power series definition as for $\mathbb{R}$. Let $x \in T$ and let $1$ be the unit of $T$. Does the Pythagorean trigonometric identity $\cos^2(x)+\sin^2(x)=1$ still hold?,Let's assume that we have an unital Banach algebra $T$ and we define sine and cosine using the normal power series definition as for $\mathbb{R}$. Let $x \in T$ and let $1$ be the unit of $T$. Does the Pythagorean trigonometric identity $\cos^2(x)+\sin^2(x)=1$ still hold?,,"['functional-analysis', 'analysis', 'trigonometry', 'operator-theory']"
