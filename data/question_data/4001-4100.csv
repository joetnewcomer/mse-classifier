,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,The closed form of $\int_0^{\infty} \frac{\log(\cosh(x))}{x} e^{-x} \ dx$,The closed form of,\int_0^{\infty} \frac{\log(\cosh(x))}{x} e^{-x} \ dx,"An integral I discussed last days in a chat, and it looks like a hard nut since  after some manipulations of the initial form we reach an integral where the integrand is expressed in terms of  digamma function  that can be further reduced to some very resistent series. I conjecture that the integral has  a  closed  form expressed in terms of G-Barnes function (and newer constants?) Well, I might be wrong, but here we have many integration gurus that could probably  answer that. $$\int_0^{\infty} \frac{\log(\cosh(x))}{x} e^{-x} \ dx$$","An integral I discussed last days in a chat, and it looks like a hard nut since  after some manipulations of the initial form we reach an integral where the integrand is expressed in terms of  digamma function  that can be further reduced to some very resistent series. I conjecture that the integral has  a  closed  form expressed in terms of G-Barnes function (and newer constants?) Well, I might be wrong, but here we have many integration gurus that could probably  answer that. $$\int_0^{\infty} \frac{\log(\cosh(x))}{x} e^{-x} \ dx$$",,"['calculus', 'real-analysis', 'integration', 'complex-analysis', 'improper-integrals']"
1,Closed form of $ \int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx$,Closed form of, \int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx,"Hello I am trying to solve an incredible integral given by $$ \int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx=\pi \ln\bigg[\frac{1}{2}\left(\cos^2\alpha +\sqrt{\cos^4 \alpha +\cos^2\frac{\beta}{2} \sin^2 \frac{\beta}{2}}\right)\bigg],\qquad \alpha > \beta >0. $$ I defined $$ I\equiv  \int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx $$ and using $\cos^2 x=1-\sin^2 x$ but obtained a more complicated expression. Usually it is easier to work with a closed form of Log Sine so I was trying this.  I am not really sure how else to approach this at all. The result looks like very nice and similar to something we all know :) I am looking for real or complex methods to solve this problem.  I am not sure of what substitutions to make but maybe we could work in hyperbolic space","Hello I am trying to solve an incredible integral given by $$ \int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx=\pi \ln\bigg[\frac{1}{2}\left(\cos^2\alpha +\sqrt{\cos^4 \alpha +\cos^2\frac{\beta}{2} \sin^2 \frac{\beta}{2}}\right)\bigg],\qquad \alpha > \beta >0. $$ I defined $$ I\equiv  \int_0^{\pi/2}\ln\big[1-\cos^2 x(\sin^2\alpha-\sin^2\beta \sin^2 x)\big]dx $$ and using $\cos^2 x=1-\sin^2 x$ but obtained a more complicated expression. Usually it is easier to work with a closed form of Log Sine so I was trying this.  I am not really sure how else to approach this at all. The result looks like very nice and similar to something we all know :) I am looking for real or complex methods to solve this problem.  I am not sure of what substitutions to make but maybe we could work in hyperbolic space",,"['real-analysis', 'calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
2,"Improper Integral $\int\limits_0^\frac{1}{2}x^n\cot(\pi x)\,dx$",Improper Integral,"\int\limits_0^\frac{1}{2}x^n\cot(\pi x)\,dx","What is the closed form of the following integral for every $n\in\mathbb{N}$? $$\int_0^\frac{1}{2}x^n\cot(\pi x)\,dx$$ By Mathematica we see that $$\int_0^\frac{1}{2}x\cot(\pi x)\,dx=\frac{\log(2)}{2\pi}$$ $$\int_0^\frac{1}{2}x^2\cot(\pi x)\,dx=\frac{\pi^2\log(4)-7\zeta(3)}{8\pi^3}.$$ If there not exist a closed form, how one can prove these two formulas?","What is the closed form of the following integral for every $n\in\mathbb{N}$? $$\int_0^\frac{1}{2}x^n\cot(\pi x)\,dx$$ By Mathematica we see that $$\int_0^\frac{1}{2}x\cot(\pi x)\,dx=\frac{\log(2)}{2\pi}$$ $$\int_0^\frac{1}{2}x^2\cot(\pi x)\,dx=\frac{\pi^2\log(4)-7\zeta(3)}{8\pi^3}.$$ If there not exist a closed form, how one can prove these two formulas?",,"['real-analysis', 'integration', 'complex-analysis', 'improper-integrals', 'closed-form']"
3,Functions satisfying $(b-a)f'(\tfrac{a+b}{2}) = f(b)- f(a)$,Functions satisfying,(b-a)f'(\tfrac{a+b}{2}) = f(b)- f(a),"Let $f$ be a differientable real function such that $$(b-a)f'(\tfrac{a+b}{2}) = f(b)- f(a)$$ for all reals $a,b$. Is $f$ polynomial of degree $\leq 2$ ?","Let $f$ be a differientable real function such that $$(b-a)f'(\tfrac{a+b}{2}) = f(b)- f(a)$$ for all reals $a,b$. Is $f$ polynomial of degree $\leq 2$ ?",,"['real-analysis', 'functions']"
4,I need to prove the continuity of $f(x)=\log x$ using a $\epsilon-\delta$ proof,I need to prove the continuity of  using a  proof,f(x)=\log x \epsilon-\delta,I need to prove the  continuity of $f(x)=\log x$ using a $\epsilon-\delta$ proof These is what I have so far but am not sure how to continue $|\log x-\log a| < \epsilon$ $\log a- \epsilon < \log x < \log a+ \epsilon$ $\frac{a}{e^\epsilon} < x < {a}e^\epsilon$ Any help is appreciated,I need to prove the  continuity of $f(x)=\log x$ using a $\epsilon-\delta$ proof These is what I have so far but am not sure how to continue $|\log x-\log a| < \epsilon$ $\log a- \epsilon < \log x < \log a+ \epsilon$ $\frac{a}{e^\epsilon} < x < {a}e^\epsilon$ Any help is appreciated,,"['calculus', 'real-analysis', 'limits', 'continuity']"
5,Differential equation $xy^3y'=2y^4+x^4$,Differential equation,xy^3y'=2y^4+x^4,Solve the differential equation $$xy^3y'=2y^4+x^4$$,Solve the differential equation $$xy^3y'=2y^4+x^4$$,,"['calculus', 'real-analysis', 'ordinary-differential-equations']"
6,abel summable implies convergence,abel summable implies convergence,,"Prove that: If $\sum c_n$ is Abel summable to $s$ and $c_n=O(\frac{1}{n})$ , then $\sum c_n $ converges to $s$. ""A series of complex number $\sum_{n=0}^{\infty} c_n $ is said to be Abel summable to $s$ if for every $0 \le r <1$ ,the series $A(r)=\sum_{k=0}^{\infty} c_kr^k$ converges ,and  $\lim_{r\rightarrow 1^-} A(r)=s$.""","Prove that: If $\sum c_n$ is Abel summable to $s$ and $c_n=O(\frac{1}{n})$ , then $\sum c_n $ converges to $s$. ""A series of complex number $\sum_{n=0}^{\infty} c_n $ is said to be Abel summable to $s$ if for every $0 \le r <1$ ,the series $A(r)=\sum_{k=0}^{\infty} c_kr^k$ converges ,and  $\lim_{r\rightarrow 1^-} A(r)=s$.""",,"['real-analysis', 'sequences-and-series', 'divergent-series']"
7,Fréchet differentiability from Gâteaux differentiability,Fréchet differentiability from Gâteaux differentiability,,"Let $X$ be a Banach space and $\Omega \subset X$ be open. The functional $f$ has a Gâteaux derivative $g \in X'$ at $u \in \Omega$ if, $\forall h\in X,$ $$\lim_{t \rightarrow 0}[f(u+th)-f(u)- \langle g,th \rangle]=0$$ How can I prove the following: If $f$ has a continuous Gâteaux derivative on $\Omega$, then $f \in C^1(\Omega,\mathbb R)$.","Let $X$ be a Banach space and $\Omega \subset X$ be open. The functional $f$ has a Gâteaux derivative $g \in X'$ at $u \in \Omega$ if, $\forall h\in X,$ $$\lim_{t \rightarrow 0}[f(u+th)-f(u)- \langle g,th \rangle]=0$$ How can I prove the following: If $f$ has a continuous Gâteaux derivative on $\Omega$, then $f \in C^1(\Omega,\mathbb R)$.",,"['real-analysis', 'banach-spaces']"
8,"Function whose integral over $[0, \infty)$ is finite, but the limit of the function is $>0$","Function whose integral over  is finite, but the limit of the function is","[0, \infty) >0","Let $t \in \mathbb{R},f:\mathbb{R} \rightarrow \mathbb{R}:t \mapsto f(t)$. $f$ is required to have: $\displaystyle\lim_{t \rightarrow \infty} f(t) = L$, where $L>0$ (could be $\infty$, so the limit exists, only it could be $\infty$) $\displaystyle\int_{0}^{\infty} f(t) dt < \infty$ Is that possible to construct such $f$? Note: $f$ can be any function continuous or discontinuous. I found the discussion here which is involving ""tent"" function but in that example, the limit does not exist. Note 2: I have edited the title. Thank you for your fedback !!! Thank you for any answers or comments.","Let $t \in \mathbb{R},f:\mathbb{R} \rightarrow \mathbb{R}:t \mapsto f(t)$. $f$ is required to have: $\displaystyle\lim_{t \rightarrow \infty} f(t) = L$, where $L>0$ (could be $\infty$, so the limit exists, only it could be $\infty$) $\displaystyle\int_{0}^{\infty} f(t) dt < \infty$ Is that possible to construct such $f$? Note: $f$ can be any function continuous or discontinuous. I found the discussion here which is involving ""tent"" function but in that example, the limit does not exist. Note 2: I have edited the title. Thank you for your fedback !!! Thank you for any answers or comments.",,"['calculus', 'real-analysis', 'functions']"
9,Nowhere continuous real valued function which has an antiderivative,Nowhere continuous real valued function which has an antiderivative,,"My question: Is there a function $f: \mathbb{R} \rightarrow \mathbb{R}$ that nowhere continuous on its domain, but has an antiderivative? If there is no such a function,  is it true to conclude that: to have an antiderivative, $f$ is necessary to be continuous at least at one point on its domain? Any comments/ inputs are highly appreciated. Thanks in advance.","My question: Is there a function $f: \mathbb{R} \rightarrow \mathbb{R}$ that nowhere continuous on its domain, but has an antiderivative? If there is no such a function,  is it true to conclude that: to have an antiderivative, $f$ is necessary to be continuous at least at one point on its domain? Any comments/ inputs are highly appreciated. Thanks in advance.",,['real-analysis']
10,Equivalent Topologies,Equivalent Topologies,,"In a text I am reading, the author defines two norms on a vector space $X$ to be equivalent if they induce the same topology on $X$. The text does not define what it means however for two topologies to be equivalent. The only definition I can think of that seems reasonable is that two topologies $T_1$ and $T_2$ are equivalent if an open set in $T_1$ is an open set in $T_2$ and conversely. Since open sets in a normed space are determined by the norm-relative open balls, this would mean that any open ball about a point $x$ with respect to one norm not only contains an open ball about $x$ with respect to the other norm but is also contained within an open ball relative to that other norm. Is this the right way to look at the situation? Is my definition of ""equivalent toplogies"" appropriate in this context?","In a text I am reading, the author defines two norms on a vector space $X$ to be equivalent if they induce the same topology on $X$. The text does not define what it means however for two topologies to be equivalent. The only definition I can think of that seems reasonable is that two topologies $T_1$ and $T_2$ are equivalent if an open set in $T_1$ is an open set in $T_2$ and conversely. Since open sets in a normed space are determined by the norm-relative open balls, this would mean that any open ball about a point $x$ with respect to one norm not only contains an open ball about $x$ with respect to the other norm but is also contained within an open ball relative to that other norm. Is this the right way to look at the situation? Is my definition of ""equivalent toplogies"" appropriate in this context?",,"['real-analysis', 'general-topology']"
11,Limit of a function. Integration problem,Limit of a function. Integration problem,,"I have this problem: Let $c\in \mathbb{R}$. If $\int_c^\infty f(x)dx$ converges, then $$\lim_{x\to \infty} f(x)$$ exist and is $0$. Moreover, if $f$ is monotonic, $\lim_{x\to \infty} xf(x)$ exist and is equal to $0$. Although I can't assume that $f$ is continuous, I have tihis question: If $F$ is a function with continuous first derivative, such that $$\lim_{x\to \infty}F(x)=L,$$ for some $L\in\mathbb{R}$. Is it true that $$\lim_{x\to \infty} F'(x)=0\;?$$","I have this problem: Let $c\in \mathbb{R}$. If $\int_c^\infty f(x)dx$ converges, then $$\lim_{x\to \infty} f(x)$$ exist and is $0$. Moreover, if $f$ is monotonic, $\lim_{x\to \infty} xf(x)$ exist and is equal to $0$. Although I can't assume that $f$ is continuous, I have tihis question: If $F$ is a function with continuous first derivative, such that $$\lim_{x\to \infty}F(x)=L,$$ for some $L\in\mathbb{R}$. Is it true that $$\lim_{x\to \infty} F'(x)=0\;?$$",,"['real-analysis', 'analysis', 'integration']"
12,Is expectation Riemann-/Lebesgue–Stieltjes integral?,Is expectation Riemann-/Lebesgue–Stieltjes integral?,,"In probability theory,  when having $    E(f(X))=\int_{-\infty}^\infty f(x)\, dg(x) $, an expectation of a measurable function $f$ of a random variable $X$ with respect to its cumulative distribution function $g$, is it true that it is always a Lebesgue–Stieltjes integral ? Furthermore, is it always a Riemann–Stieltjes integral ? Thanks and regards!","In probability theory,  when having $    E(f(X))=\int_{-\infty}^\infty f(x)\, dg(x) $, an expectation of a measurable function $f$ of a random variable $X$ with respect to its cumulative distribution function $g$, is it true that it is always a Lebesgue–Stieltjes integral ? Furthermore, is it always a Riemann–Stieltjes integral ? Thanks and regards!",,"['real-analysis', 'integration', 'probability-theory', 'measure-theory', 'functional-analysis']"
13,"Small parameter expansion of the definite integral, divergence of coefficients","Small parameter expansion of the definite integral, divergence of coefficients",,"I’m considering the following integral with one parameter $\omega$ $$I(\omega):=\int_0^{\infty}(1+x)^2\Bigg(\sqrt{x^2+\frac{\omega^2}{(1+x)^\delta}}-x\Bigg)dx,$$ where $\delta>2$ and $\omega $ is small parameter. I want to know the expansion of $I(\omega)$ around $\omega=0$ . Naively, it is accomplished by the standard Taylor expansion, but the problem is its coefficient has a divergence, for example, $$\frac{d^2I(0)}{d\omega^2}= \int_0^{\infty}\frac{1}{(1+x)^{\delta-2}}\frac{1}{x}dx\sim\infty.$$ Does anyone know how to fix this problem?","I’m considering the following integral with one parameter where and is small parameter. I want to know the expansion of around . Naively, it is accomplished by the standard Taylor expansion, but the problem is its coefficient has a divergence, for example, Does anyone know how to fix this problem?","\omega I(\omega):=\int_0^{\infty}(1+x)^2\Bigg(\sqrt{x^2+\frac{\omega^2}{(1+x)^\delta}}-x\Bigg)dx, \delta>2 \omega  I(\omega) \omega=0 \frac{d^2I(0)}{d\omega^2}= \int_0^{\infty}\frac{1}{(1+x)^{\delta-2}}\frac{1}{x}dx\sim\infty.","['real-analysis', 'definite-integrals', 'taylor-expansion', 'divergent-integrals']"
14,When does this series $\sum_{n=0}^{\infty}\sin(n!\pi x)$ converge?,When does this series  converge?,\sum_{n=0}^{\infty}\sin(n!\pi x),"My book says that the following series $$\sum_{n=0}^{\infty}\sin(n!\pi x)$$ converges for all rational values of $x$ (which is correct since then all the terms are $0$ after some definite index) and also for $x = e$ , $=(2k+1)e$ , $=2k/e$ , $=\sin1$ , $=\cos1$ . I don't understand why, since it seems that the general term doesn't go to zero, or am I mistaken? Also is it probably a typo? For $x = e$ , according to Wolfram Alpha, the sum does not converge.","My book says that the following series converges for all rational values of (which is correct since then all the terms are after some definite index) and also for , , , , . I don't understand why, since it seems that the general term doesn't go to zero, or am I mistaken? Also is it probably a typo? For , according to Wolfram Alpha, the sum does not converge.",\sum_{n=0}^{\infty}\sin(n!\pi x) x 0 x = e =(2k+1)e =2k/e =\sin1 =\cos1 x = e,"['real-analysis', 'calculus', 'sequences-and-series']"
15,Show that $f(x)=\cos(x)$ is Lipschitz continuous function.,Show that  is Lipschitz continuous function.,f(x)=\cos(x),I am not sure how to proceed. Should I rewrite $|\cos(x)-\cos(y)|=|2\cos\frac{x+y}{2}\cos\frac{x-y}{2}|$ ?,I am not sure how to proceed. Should I rewrite ?,|\cos(x)-\cos(y)|=|2\cos\frac{x+y}{2}\cos\frac{x-y}{2}|,"['real-analysis', 'calculus']"
16,$x^n+nx-1$ has a unique solution,has a unique solution,x^n+nx-1,"Show that for any integer $n\geq1,$ the equation $$x^n+nx-1=0$$ has a unique positive solution $x_n$ . Furthermore, show that $x_n$ is such that for any $p>1$ the series $\sum_{n=1}^{\infty}x_n^p$ is convergent . For the first part of the question I can prove the solution by the intermediate value theorem (by considering $x=0$ and $x=1$ ). And also uniqueness is achieved because the function is increasing (since the first derivative is always positive.) But how about the convergence of the series?","Show that for any integer the equation has a unique positive solution . Furthermore, show that is such that for any the series is convergent . For the first part of the question I can prove the solution by the intermediate value theorem (by considering and ). And also uniqueness is achieved because the function is increasing (since the first derivative is always positive.) But how about the convergence of the series?","n\geq1, x^n+nx-1=0 x_n x_n p>1 \sum_{n=1}^{\infty}x_n^p x=0 x=1","['real-analysis', 'calculus']"
17,Polynomials- Prove that function can be only polynomial,Polynomials- Prove that function can be only polynomial,,"Suppose there exist a function $f : \mathbb R \to \mathbb R$ such that $f(x)\cdot f'(x)$ is polynomial It. is trivial that if $f(x)$ is polynomial, then $f(x)\cdot f'(x)$ is polynomial. My question is: how would one prove that $f(x)$ can be only polynomial?","Suppose there exist a function $f : \mathbb R \to \mathbb R$ such that $f(x)\cdot f'(x)$ is polynomial It. is trivial that if $f(x)$ is polynomial, then $f(x)\cdot f'(x)$ is polynomial. My question is: how would one prove that $f(x)$ can be only polynomial?",,"['real-analysis', 'polynomials']"
18,Rotation invariance of the Lebesgue measure,Rotation invariance of the Lebesgue measure,,"Denote the Borel sets in $\mathbb R^d$ as $\mathcal B^d$. Is there a proof for the rotation invariance of the Lebesgue measure that doesn't use already that one has  $$ \lambda(A^{-1}(B)) = \vert \operatorname{det} A \vert ^{-1} \lambda (B) \qquad \text{for all } A \in \operatorname{GL}(\mathbb R^d), \ B \in \mathcal B^d?$$ For example one can show easily that $\lambda$ is invariant under translation just using that intervals are invariant under translation and a $\cap$-closed generator of the Borel sets. This the first step in the proof of the above statement. Hence I am interested to see a proof for the rotation invariance likewise without the above statement.","Denote the Borel sets in $\mathbb R^d$ as $\mathcal B^d$. Is there a proof for the rotation invariance of the Lebesgue measure that doesn't use already that one has  $$ \lambda(A^{-1}(B)) = \vert \operatorname{det} A \vert ^{-1} \lambda (B) \qquad \text{for all } A \in \operatorname{GL}(\mathbb R^d), \ B \in \mathcal B^d?$$ For example one can show easily that $\lambda$ is invariant under translation just using that intervals are invariant under translation and a $\cap$-closed generator of the Borel sets. This the first step in the proof of the above statement. Hence I am interested to see a proof for the rotation invariance likewise without the above statement.",,"['real-analysis', 'measure-theory', 'reference-request', 'lebesgue-measure', 'rotations']"
19,Limit of a monotonically increasing sequence and decreasing sequence,Limit of a monotonically increasing sequence and decreasing sequence,,"If a sequence ($a_n$) is monotonically increasing, and ($b_n$) is a decreasing sequence, with $\lim_{n\to\infty}\,(b_n-a_n)=0$, show that $\lim a_n$ and $\lim b_n$ both exist, and that $\lim a_n=\lim b_n$. My attempt: To show that the limits of both sequences exist, I think I should be using the Monotone Convergence Theorem (MCT). For that I would need to show that the sequences are bounded. ($a_n$) is increasing, and so it should be bounded below. ($b_n$) is decreasing, so it should be bounded above. The challenge here is to show that ($a_n$) can be bounded above and ($b_n$) can be bounded below. This should utilise the third condition, from which I get: $$\begin{align*}  & \lim_{n\to\infty}\,(b_n-a_n)=0 \\[3pt] \iff & \forall\varepsilon>0,\ \exists N\in \mathbb{N} \text{ s.t. } \forall n\geq N,\ |{b_n-a_n}|<\varepsilon  \end{align*}$$ I then tried using the triangle inequality: $$ |b_n|-|a_n|\leq|b_n-a_n|<\varepsilon$$ but I'm not sure where to go from here.","If a sequence ($a_n$) is monotonically increasing, and ($b_n$) is a decreasing sequence, with $\lim_{n\to\infty}\,(b_n-a_n)=0$, show that $\lim a_n$ and $\lim b_n$ both exist, and that $\lim a_n=\lim b_n$. My attempt: To show that the limits of both sequences exist, I think I should be using the Monotone Convergence Theorem (MCT). For that I would need to show that the sequences are bounded. ($a_n$) is increasing, and so it should be bounded below. ($b_n$) is decreasing, so it should be bounded above. The challenge here is to show that ($a_n$) can be bounded above and ($b_n$) can be bounded below. This should utilise the third condition, from which I get: $$\begin{align*}  & \lim_{n\to\infty}\,(b_n-a_n)=0 \\[3pt] \iff & \forall\varepsilon>0,\ \exists N\in \mathbb{N} \text{ s.t. } \forall n\geq N,\ |{b_n-a_n}|<\varepsilon  \end{align*}$$ I then tried using the triangle inequality: $$ |b_n|-|a_n|\leq|b_n-a_n|<\varepsilon$$ but I'm not sure where to go from here.",,"['real-analysis', 'sequences-and-series']"
20,Why does existence of directional derivatives not imply differentiability?,Why does existence of directional derivatives not imply differentiability?,,"In my notes I have: $$Df\big|_{\mathbf{a}}(\mathbf{h})=\lim_{t\to 0}\frac{f(\mathbf{a}+t\mathbf{h})-f(\mathbf{a})}{t}$$ It says that even if this limit exists for all $\mathbf{h}$, we do not necessarily have differentiability. Is this because the $Df\big|_{\mathbf{a}}$ we get from this is not necessarily linear, or even continuous, in $\mathbf{h}?$ Can I say that if the result map is linear & continuous then we have differentiability? I ask because I am doing a problem which asks to check differentiability of some functions $f:\mathbb{R}^2\to\mathbb{R}$. One of them is: $$f(x,y)=xy\left(\frac{x^4-y^4}{x^4+y^4}\right)\qquad f(0,0)=0$$ which I thought was differentiable at $\mathbf{0}$ since $Df\big|_{\mathbf{0}}(\mathbf{h})=0$ for all $\mathbf{h}$, but I am not sure this is enough.","In my notes I have: $$Df\big|_{\mathbf{a}}(\mathbf{h})=\lim_{t\to 0}\frac{f(\mathbf{a}+t\mathbf{h})-f(\mathbf{a})}{t}$$ It says that even if this limit exists for all $\mathbf{h}$, we do not necessarily have differentiability. Is this because the $Df\big|_{\mathbf{a}}$ we get from this is not necessarily linear, or even continuous, in $\mathbf{h}?$ Can I say that if the result map is linear & continuous then we have differentiability? I ask because I am doing a problem which asks to check differentiability of some functions $f:\mathbb{R}^2\to\mathbb{R}$. One of them is: $$f(x,y)=xy\left(\frac{x^4-y^4}{x^4+y^4}\right)\qquad f(0,0)=0$$ which I thought was differentiable at $\mathbf{0}$ since $Df\big|_{\mathbf{0}}(\mathbf{h})=0$ for all $\mathbf{h}$, but I am not sure this is enough.",,"['real-analysis', 'limits', 'multivariable-calculus', 'derivatives', 'proof-verification']"
21,Any convex set is connected,Any convex set is connected,,"I'm stuck in a proof: given that $E\subset \mathbb{R}^n$ is convex, prove that it is connected. I know that this can be proved easier using the concept of path-connectedness, but that's not I'm ""allowed"" to do. I need to use another definition: $E$ is connected if and only if it cannot be separatedby a pair of two relatively open sets. My attempt: Pick any $x, y\in E$. Since $E$ is convex, $tx+(1-t)y \subset E$ for $t\in [0,1]$. Suppose that $E$ is not connected. Then there exist non-empty sets $U$ and $V$, such that $U\cap V =\emptyset$, $U\cup V=E$, and $U$ and $V$ are relatively open in $E$, which implies that there exist open sets $A$ and $B$ such that $U=A\cap E$ and $V=B\cap E$. Let $x \in U$ and $y \in V$. (i) $U$ and $V$ are clearly not empty. (ii) $U\cup V$... Intuitively I understand that what needs to be shown is that $U \cup V \ne E$, but I'm stuck in trying to show it. Would appreciate some help.","I'm stuck in a proof: given that $E\subset \mathbb{R}^n$ is convex, prove that it is connected. I know that this can be proved easier using the concept of path-connectedness, but that's not I'm ""allowed"" to do. I need to use another definition: $E$ is connected if and only if it cannot be separatedby a pair of two relatively open sets. My attempt: Pick any $x, y\in E$. Since $E$ is convex, $tx+(1-t)y \subset E$ for $t\in [0,1]$. Suppose that $E$ is not connected. Then there exist non-empty sets $U$ and $V$, such that $U\cap V =\emptyset$, $U\cup V=E$, and $U$ and $V$ are relatively open in $E$, which implies that there exist open sets $A$ and $B$ such that $U=A\cap E$ and $V=B\cap E$. Let $x \in U$ and $y \in V$. (i) $U$ and $V$ are clearly not empty. (ii) $U\cup V$... Intuitively I understand that what needs to be shown is that $U \cup V \ne E$, but I'm stuck in trying to show it. Would appreciate some help.",,"['real-analysis', 'general-topology', 'analysis']"
22,"Are the unit partial quotients of $\pi, \log(2), \zeta(3) $ and other constants $all$ governed by $H=0.415\dots$?",Are the unit partial quotients of  and other constants  governed by ?,"\pi, \log(2), \zeta(3)  all H=0.415\dots","Khinchin showed that given the simple continued fraction of a real number, $$r = a_0+\cfrac{1}{a_1+\cfrac{1}{a_2+\cfrac{1} {\ddots}}}$$ then it is almost always true that the partial quotients $a_i$ satisfy, $$K = \lim_{n \rightarrow \infty } \left( a_1 a_2 ... a_n \right) ^{1/n} =2.685452\dots$$ where $K$ is Khinchin's constant . (Some exceptional $r$ are the rationals, roots of quadratic equations, and rational powers of $e$.) Q1: Given $n$, let $T_n$ be the total number of partial quotients $a_i = 1$. Is it almost always true that,   $$H=\lim_{n \rightarrow \infty } \frac{T_n}{n} = 0.415\dots$$   exists and converges? If it does, can $H$ be expressed in terms of $K$ and other constants? Numerical evidence for various transcendental and algebraic constants are given below with $n=10^k$ and entries as $T_n$: $$\begin{array}{|c|c|c|c|c|} \hline \text{constant}&10^3&10^4&10^5&10^6&10^7\\ \hline \pi&412& 4206& 41494& 414526& 4148280\\ \Gamma\big(\tfrac{1}{2}\big)&417& 4178& 41620& 415352& 4151849\\ \log(2)&433& 4148& 41430& 415443&-\\ \log(3)&429& 4170& 41458& 414919&-\\ T&396& 4084& 41172& 414458&-\\ P&410& 4087& 41364& 415180&-\\ K&418& 4111& 41379&-&-\\ C&412& 4147& 41543&-&-\\ \zeta(3)&418& 4223&-&-&-\\ \hline \end{array}$$ where $T, P, K, C$ are the tribonacci , plastic , Khinchin , and Catalan constants. Q2 : Anybody able to fill in the blanks? Or extend it to $n>10^{7}$ so we can have more decimal digits of $H$? (I know the continued fraction for $\pi$ has been computed to more than $n>10^{10}$ terms.)","Khinchin showed that given the simple continued fraction of a real number, $$r = a_0+\cfrac{1}{a_1+\cfrac{1}{a_2+\cfrac{1} {\ddots}}}$$ then it is almost always true that the partial quotients $a_i$ satisfy, $$K = \lim_{n \rightarrow \infty } \left( a_1 a_2 ... a_n \right) ^{1/n} =2.685452\dots$$ where $K$ is Khinchin's constant . (Some exceptional $r$ are the rationals, roots of quadratic equations, and rational powers of $e$.) Q1: Given $n$, let $T_n$ be the total number of partial quotients $a_i = 1$. Is it almost always true that,   $$H=\lim_{n \rightarrow \infty } \frac{T_n}{n} = 0.415\dots$$   exists and converges? If it does, can $H$ be expressed in terms of $K$ and other constants? Numerical evidence for various transcendental and algebraic constants are given below with $n=10^k$ and entries as $T_n$: $$\begin{array}{|c|c|c|c|c|} \hline \text{constant}&10^3&10^4&10^5&10^6&10^7\\ \hline \pi&412& 4206& 41494& 414526& 4148280\\ \Gamma\big(\tfrac{1}{2}\big)&417& 4178& 41620& 415352& 4151849\\ \log(2)&433& 4148& 41430& 415443&-\\ \log(3)&429& 4170& 41458& 414919&-\\ T&396& 4084& 41172& 414458&-\\ P&410& 4087& 41364& 415180&-\\ K&418& 4111& 41379&-&-\\ C&412& 4147& 41543&-&-\\ \zeta(3)&418& 4223&-&-&-\\ \hline \end{array}$$ where $T, P, K, C$ are the tribonacci , plastic , Khinchin , and Catalan constants. Q2 : Anybody able to fill in the blanks? Or extend it to $n>10^{7}$ so we can have more decimal digits of $H$? (I know the continued fraction for $\pi$ has been computed to more than $n>10^{10}$ terms.)",,"['real-analysis', 'analytic-number-theory', 'computational-mathematics', 'continued-fractions', 'constants']"
23,Evaluating $ \int_{-\pi /2014}^{\pi /2014}\frac{1}{2014^{x}+1}\left( \frac{\sin ^{2014}x}{\sin ^{2014}x+\cos ^{2014}x}\right) dx $,Evaluating, \int_{-\pi /2014}^{\pi /2014}\frac{1}{2014^{x}+1}\left( \frac{\sin ^{2014}x}{\sin ^{2014}x+\cos ^{2014}x}\right) dx ,The following integration problem appears in our calculus assignment: $$ \int \limits_{-\pi /2014}^{\pi /2014}\dfrac{1}{2014^{x}+1}\left(\dfrac{\sin ^{2014}x}{\sin ^{2014}x+\cos ^{2014}x}\right) dx .$$ But the problem is I have no idea how to begin this problem. Could anyone give me some help ? Any hints/ideas are much appreciated.,The following integration problem appears in our calculus assignment: But the problem is I have no idea how to begin this problem. Could anyone give me some help ? Any hints/ideas are much appreciated., \int \limits_{-\pi /2014}^{\pi /2014}\dfrac{1}{2014^{x}+1}\left(\dfrac{\sin ^{2014}x}{\sin ^{2014}x+\cos ^{2014}x}\right) dx .,"['calculus', 'real-analysis', 'integration', 'analysis', 'definite-integrals']"
24,Prove that limit inferior is same as limit superior for a convergent sequence,Prove that limit inferior is same as limit superior for a convergent sequence,,"I was reading the book ""Understanding Analysis"" by Stephen Abbott on my own. I came across the following problem. Let $(a_n)$ be a convergent sequence. Let $y_n$=sup{$a_k:k\geq n$}. Then lim sup $a_n$ = lim $y_n$. Similarly define lim inf $a_n$. Prove that lim inf $a_n$ = lim sup $a_n$ if and only if $(a_n$) converges and in that case all three share the same value. I don't know how to prove it. I know that there are alternate definitions of lim sup and lim inf . So if anyone uses those definitions in their proof, please mention those clearly and if possible, also state how that definition is equivalent to the above definition . A proof which doesn't use metric spaces etc is preferred since I have not studied it yet.","I was reading the book ""Understanding Analysis"" by Stephen Abbott on my own. I came across the following problem. Let $(a_n)$ be a convergent sequence. Let $y_n$=sup{$a_k:k\geq n$}. Then lim sup $a_n$ = lim $y_n$. Similarly define lim inf $a_n$. Prove that lim inf $a_n$ = lim sup $a_n$ if and only if $(a_n$) converges and in that case all three share the same value. I don't know how to prove it. I know that there are alternate definitions of lim sup and lim inf . So if anyone uses those definitions in their proof, please mention those clearly and if possible, also state how that definition is equivalent to the above definition . A proof which doesn't use metric spaces etc is preferred since I have not studied it yet.",,"['real-analysis', 'sequences-and-series']"
25,"Limit of the geometric sequence $\{r^n\}$, with $|r| < 1$, is $0$?","Limit of the geometric sequence , with , is ?",\{r^n\} |r| < 1 0,"Prove that the $\lim_{n\to \infty} r^n = 0$ for $|r|\lt 1$ . I can't think of a sequence to compare this to that'll work.  L'Hopital's rule doesn't apply.  I know there's some simple way of doing this, but it just isn't coming to me. :(","Prove that the for . I can't think of a sequence to compare this to that'll work.  L'Hopital's rule doesn't apply.  I know there's some simple way of doing this, but it just isn't coming to me. :(",\lim_{n\to \infty} r^n = 0 |r|\lt 1,"['real-analysis', 'calculus', 'sequences-and-series', 'limits']"
26,Integrate: $\int_0^1 \mathrm{d}x_1 \int_0^1 \mathrm{d}x_2 \ldots \int_0^1 \mathrm{d}x_n \delta\left( \sum_{i=1}^n k_i x_i \right)$,Integrate:,\int_0^1 \mathrm{d}x_1 \int_0^1 \mathrm{d}x_2 \ldots \int_0^1 \mathrm{d}x_n \delta\left( \sum_{i=1}^n k_i x_i \right),"Is there a closed form formula for this integral: $$\int_0^1 \mathrm{d}x_1 \int_0^1 \mathrm{d}x_2  \ldots \int_0^1 \mathrm{d}x_n \delta\left( \sum_{i=1}^n k_i x_i \right)$$ where $\delta(x)$ is the Dirac delta function, and the $k_i$ are real numbers. Here's how far I've got. Doing the integral on $x_n$ gives: $$\frac{1}{|k_n|}\int_0^1 \mathrm{d}x_1 \int_0^1 \mathrm{d}x_2  \ldots \int_0^1 \mathrm{d}x_{n-1} \left[0\leq -\frac{1}{k_n}\sum_{i=1}^{n-1} k_i x_i \leq 1 \right]$$ where the brackets are Iverson brackets : $$\left[P\right]= \begin{cases} 1 & \text{if }P\text{ is true }\\ 0 & \text{otherwise} \end{cases}$$ From here, I could calculate the appropriate limits of integration of $x_{n-1}$ . But that seems like too much work, and I am not sure that I will get a closed form formula eventually as I keep going to $x_{n-2}$ and so on. I wonder if there is a simpler approach...","Is there a closed form formula for this integral: where is the Dirac delta function, and the are real numbers. Here's how far I've got. Doing the integral on gives: where the brackets are Iverson brackets : From here, I could calculate the appropriate limits of integration of . But that seems like too much work, and I am not sure that I will get a closed form formula eventually as I keep going to and so on. I wonder if there is a simpler approach...","\int_0^1 \mathrm{d}x_1 \int_0^1 \mathrm{d}x_2  \ldots \int_0^1 \mathrm{d}x_n \delta\left( \sum_{i=1}^n k_i x_i \right) \delta(x) k_i x_n \frac{1}{|k_n|}\int_0^1 \mathrm{d}x_1 \int_0^1 \mathrm{d}x_2  \ldots \int_0^1 \mathrm{d}x_{n-1} \left[0\leq -\frac{1}{k_n}\sum_{i=1}^{n-1} k_i x_i \leq 1 \right] \left[P\right]=
\begin{cases}
1 & \text{if }P\text{ is true }\\
0 & \text{otherwise}
\end{cases} x_{n-1} x_{n-2}","['real-analysis', 'integration', 'multivariable-calculus', 'definite-integrals']"
27,Proving that the union of the limit points of sets is equal to the limit points of the union of the sets,Proving that the union of the limit points of sets is equal to the limit points of the union of the sets,,"My instructor gave us an exercise to do, to show that this equality holds: $$\bigcup_{k=1}^m A_k'=\left(\bigcup_{k=1}^m A_k\right)^{\!\prime}.$$ My thoughts on approaching this question is by contradiction, suppose that there is an element that satisfies the left side of the equality and not the right side. Then there is a deleted ball with radius $r$ such that $B(x,r)$ intersect the left side of the equality is non empty while there is a deleted ball with radius $r$ such that $B(x,r)$ intersect the right side of the equality is empty. Is this the right approach in proving this? This is as far as I can go. Thanks for the help in advance.","My instructor gave us an exercise to do, to show that this equality holds: $$\bigcup_{k=1}^m A_k'=\left(\bigcup_{k=1}^m A_k\right)^{\!\prime}.$$ My thoughts on approaching this question is by contradiction, suppose that there is an element that satisfies the left side of the equality and not the right side. Then there is a deleted ball with radius $r$ such that $B(x,r)$ intersect the left side of the equality is non empty while there is a deleted ball with radius $r$ such that $B(x,r)$ intersect the right side of the equality is empty. Is this the right approach in proving this? This is as far as I can go. Thanks for the help in advance.",,"['real-analysis', 'general-topology']"
28,"Show that $f(x)=||x||^p, p\ge 1$ is convex function on $\mathbb{R}^n$",Show that  is convex function on,"f(x)=||x||^p, p\ge 1 \mathbb{R}^n","Show that $f(x)=||x||^p, p\ge 1$  is convex function on $\mathbb{R}^n$. I have tried to use Holder's inequality, but I still cannot solve this problem. Could you help me with this problem? Thank you so much.","Show that $f(x)=||x||^p, p\ge 1$  is convex function on $\mathbb{R}^n$. I have tried to use Holder's inequality, but I still cannot solve this problem. Could you help me with this problem? Thank you so much.",,"['real-analysis', 'convex-analysis', 'normed-spaces']"
29,Properties of $\bigcap_{p > 1} \ell_p$,Properties of,\bigcap_{p > 1} \ell_p,"Consider the following space of sequences $$\left\{a=(a_n)_{n\in\mathbb{N}}:a\in\bigcap_{p>1}\ell_p, a_n\in\mathbb{R}\right\}$$ What are some of its properties? What is its relation to $\ell_1$ and $\ell_\infty$?","Consider the following space of sequences $$\left\{a=(a_n)_{n\in\mathbb{N}}:a\in\bigcap_{p>1}\ell_p, a_n\in\mathbb{R}\right\}$$ What are some of its properties? What is its relation to $\ell_1$ and $\ell_\infty$?",,"['real-analysis', 'sequences-and-series', 'lp-spaces']"
30,Countable sets in $\mathbb R$ are Borel sets,Countable sets in  are Borel sets,\mathbb R,"I am aware that this is a very general question, but why is every countable set in the real numbers a Borel set?","I am aware that this is a very general question, but why is every countable set in the real numbers a Borel set?",,"['real-analysis', 'measure-theory']"
31,Compute $\sum_{m>n=1}^{\infty} \frac{1}{m!n!}$,Compute,\sum_{m>n=1}^{\infty} \frac{1}{m!n!},Compute the series $$\sum_{m>n=1}^{\infty} \frac{1}{m!n!}$$,Compute the series $$\sum_{m>n=1}^{\infty} \frac{1}{m!n!}$$,,"['calculus', 'real-analysis', 'sequences-and-series', 'special-functions']"
32,Equivalence of a Lebesgue Integrable function,Equivalence of a Lebesgue Integrable function,,"I have the following question: Let $X$: $\mu(X)<\infty$, and let $f \geq 0$ on $X$.  Prove that $f$ is Lebesgue integrable on $X$ if and only if $\sum_{n=0}^{\infty}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) < \infty $. I have the following ideas, but am a little unsure. For the forward direction: By our hypothesis, we are taking $f$ to be Lebesgue integrable.  Assume $\sum_{n=0}^{\infty}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) = \infty $.  Then for any n, no matter how large, $\mu(\lbrace x \in X : f(x) \geq 2^n \rbrace)$ has positive measure.  Otherwise, the sum will terminate for a certain $N$, giving us $\sum_{n=0}^{N}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) < \infty $.  Thus we have $f$ unbounded on a set of positive measure, which in combination with $f(x) \geq 0$, gives us that $\int_E f(x) d\mu=\infty$.  This is a contradiction to $f$ being Lebesgue integrable.  So our summation must be finite. For the reverse direction: We have that $\sum_{n=0}^{N}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) < \infty \\$.  Assume that $f$ is not Lebesgue integrable, then we have $\int_E f(x) d\mu=\infty$.  Since we are integrating over a finite set $X$, then this means that $f(x)$ must be unbounded on a set of positive measure, which makes our summation infinite, a contradiction. Any thoughts as to the validity of my proof?  I feel as if there is an easier, direct way to do it.","I have the following question: Let $X$: $\mu(X)<\infty$, and let $f \geq 0$ on $X$.  Prove that $f$ is Lebesgue integrable on $X$ if and only if $\sum_{n=0}^{\infty}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) < \infty $. I have the following ideas, but am a little unsure. For the forward direction: By our hypothesis, we are taking $f$ to be Lebesgue integrable.  Assume $\sum_{n=0}^{\infty}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) = \infty $.  Then for any n, no matter how large, $\mu(\lbrace x \in X : f(x) \geq 2^n \rbrace)$ has positive measure.  Otherwise, the sum will terminate for a certain $N$, giving us $\sum_{n=0}^{N}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) < \infty $.  Thus we have $f$ unbounded on a set of positive measure, which in combination with $f(x) \geq 0$, gives us that $\int_E f(x) d\mu=\infty$.  This is a contradiction to $f$ being Lebesgue integrable.  So our summation must be finite. For the reverse direction: We have that $\sum_{n=0}^{N}2^n \mu(\lbrace x \in X : f(x) \geq 2^n \rbrace) < \infty \\$.  Assume that $f$ is not Lebesgue integrable, then we have $\int_E f(x) d\mu=\infty$.  Since we are integrating over a finite set $X$, then this means that $f(x)$ must be unbounded on a set of positive measure, which makes our summation infinite, a contradiction. Any thoughts as to the validity of my proof?  I feel as if there is an easier, direct way to do it.",,['real-analysis']
33,A limit involving polynomials,A limit involving polynomials,,"Let be the polynomial: $$P_n (x)=x^{n+1} - (x^{n-1}+x^{n-2}+\cdots+x+1)$$ I want to prove that it has a single positive real root we'll denote by $x_n$, and then to compute: $$\lim_{n\to\infty} x_{n}$$","Let be the polynomial: $$P_n (x)=x^{n+1} - (x^{n-1}+x^{n-2}+\cdots+x+1)$$ I want to prove that it has a single positive real root we'll denote by $x_n$, and then to compute: $$\lim_{n\to\infty} x_{n}$$",,"['real-analysis', 'polynomials', 'limits']"
34,A uniform continuous function which is not Hölder continuous,A uniform continuous function which is not Hölder continuous,,"Can someone give me an example of a function $f: I\to \mathbb R$ which is uniform continuous but not Hölder continuous (for any $\alpha$)? Here $I$ is an interval. If $I$ is closed and bounded then we are essentially assuming that $f$ is merely continuous. By saying that $f$ is not Hölder continuous for any $\alpha$, I mean for all $\alpha >0$, $$\sup_{x,y\in I, x\neq y} \frac{|f(x) - f(y)|}{|x-y|^\alpha} = \infty.$$ That is, I need to find a function $f$ so that for all $\alpha$ and $M>0$, there are $x, y\in I$ so that $$ \frac{|f(x) - f(y)|}{|x-y|^\alpha} \ge M.$$ I know that $f(x) = x^\alpha$ are $\alpha$-Hölder continuous. Thus, in some sense, I am looking for $f$ which are worst than the functions $x^\alpha$ for all $\alpha >0$.","Can someone give me an example of a function $f: I\to \mathbb R$ which is uniform continuous but not Hölder continuous (for any $\alpha$)? Here $I$ is an interval. If $I$ is closed and bounded then we are essentially assuming that $f$ is merely continuous. By saying that $f$ is not Hölder continuous for any $\alpha$, I mean for all $\alpha >0$, $$\sup_{x,y\in I, x\neq y} \frac{|f(x) - f(y)|}{|x-y|^\alpha} = \infty.$$ That is, I need to find a function $f$ so that for all $\alpha$ and $M>0$, there are $x, y\in I$ so that $$ \frac{|f(x) - f(y)|}{|x-y|^\alpha} \ge M.$$ I know that $f(x) = x^\alpha$ are $\alpha$-Hölder continuous. Thus, in some sense, I am looking for $f$ which are worst than the functions $x^\alpha$ for all $\alpha >0$.",,"['real-analysis', 'continuity', 'holder-spaces']"
35,Local definition of Hölder continuity,Local definition of Hölder continuity,,"What does it mean for a continuous function $ f $ on $ \mathbb{R} $ to be Hölder continuous with exponent $ \alpha $ at a point $ x_0 $ ? I only now the global definition: A function $ f $ on $ \mathbb{R} $ is (globally) Hölder continuous with exponent $ \alpha $ if $$ \sup_{x \neq y} \frac{| f(x) - f(y) |}{ |x - y|^\alpha} < + \infty $$ Thanks for the clarification! Regards, Si","What does it mean for a continuous function on to be Hölder continuous with exponent at a point ? I only now the global definition: A function on is (globally) Hölder continuous with exponent if Thanks for the clarification! Regards, Si", f   \mathbb{R}   \alpha   x_0   f   \mathbb{R}   \alpha   \sup_{x \neq y} \frac{| f(x) - f(y) |}{ |x - y|^\alpha} < + \infty ,"['real-analysis', 'definition', 'holder-spaces']"
36,"In this case, does $\{x_n\}$ converge given that $\{x_{2m}\}$ and $\{x_{2m+1}\}$ converge?","In this case, does  converge given that  and  converge?",\{x_n\} \{x_{2m}\} \{x_{2m+1}\},"I'm playing around with a sequence $\{x_n\}$ defined by $$ x_{n+1}=\frac{\alpha+x_n}{1+x_n}=x_n+\frac{\alpha-x_n^2}{1+x_n}. $$ Here $\alpha\gt 1$, and $x_1\gt\sqrt{\alpha}$. I'm trying to compute $\lim\ x_n$. If it converges, it's easy to compute it as $\sqrt{\alpha}$ from the above equalities, but I don't know if it does or not. Does it? I made a few observations from the relations (I can included proofs, which are mostly playing with inequalies): $x_n\gt\sqrt{\alpha}\implies x_{n+1}<\sqrt{\alpha}$ $x_n\lt\sqrt{\alpha}\implies x_{n+1}>\sqrt{\alpha}$ $x_n>\sqrt{\alpha}\implies x_{n+2}<x_n$ $x_n<\sqrt{\alpha}\implies x_{n+2}>x_n$ From these I deduced that $x_1>x_3>x_5>\cdots$ and is bounded below by $\sqrt{\alpha}$. Also, $x_2<x_4<x_6<\cdots$ and is bounded above by $\sqrt{\alpha}$. So I know $\{x_{2m}\}$ and $\{x_{2m+1}\}$ both converge. I figure if $\{x_n\}$ does not converge, then for some $\epsilon>0$, and for any $N$, there exist some $n,m>N$ such that $|x_n-x_m|>\epsilon$, and $n$ and $m$ can be of different parity. Is there some way to get a contradiction? Thanks.","I'm playing around with a sequence $\{x_n\}$ defined by $$ x_{n+1}=\frac{\alpha+x_n}{1+x_n}=x_n+\frac{\alpha-x_n^2}{1+x_n}. $$ Here $\alpha\gt 1$, and $x_1\gt\sqrt{\alpha}$. I'm trying to compute $\lim\ x_n$. If it converges, it's easy to compute it as $\sqrt{\alpha}$ from the above equalities, but I don't know if it does or not. Does it? I made a few observations from the relations (I can included proofs, which are mostly playing with inequalies): $x_n\gt\sqrt{\alpha}\implies x_{n+1}<\sqrt{\alpha}$ $x_n\lt\sqrt{\alpha}\implies x_{n+1}>\sqrt{\alpha}$ $x_n>\sqrt{\alpha}\implies x_{n+2}<x_n$ $x_n<\sqrt{\alpha}\implies x_{n+2}>x_n$ From these I deduced that $x_1>x_3>x_5>\cdots$ and is bounded below by $\sqrt{\alpha}$. Also, $x_2<x_4<x_6<\cdots$ and is bounded above by $\sqrt{\alpha}$. So I know $\{x_{2m}\}$ and $\{x_{2m+1}\}$ both converge. I figure if $\{x_n\}$ does not converge, then for some $\epsilon>0$, and for any $N$, there exist some $n,m>N$ such that $|x_n-x_m|>\epsilon$, and $n$ and $m$ can be of different parity. Is there some way to get a contradiction? Thanks.",,"['real-analysis', 'sequences-and-series', 'fixed-point-theorems']"
37,Does the exponential of a function converge? What can we do with it?,Does the exponential of a function converge? What can we do with it?,,"I’m in middle school (6th grade) and I have a question related to the exponential function (the teacher couldn’t help me): We define the exponential as follows: $$ \exp(t) = \sum_{n = 0}^{\infty} \frac{t^n}{n!}$$ For whole number inputs of $t$ , this corresponds to raising $e$ to that power. I think $\exp(t)$ converges for every possible input of $t$ , but I haven’t found a proof yet. If anyone can provide a proof or disproof then that would be helpful. I would also like to know if for some $\exp(t)$ where $t \in U$ , $\exp(t)$ will also be $\in U$ . However, these are secondary questions and you can ignore them (but do answer if you want). We also define $\exp(t)$ for complex numbers , and matrices . Today I thought about the exponential of a function: $\exp(f(t))$ . For example, let’s take $\exp(t^2)$ . This would result in something like: $\exp(t^2) = \sum_{n = 0}^{\infty} \frac{(t^2)^n}{n!} = 1 + t^2 + \frac{t^4}{2!} + \frac{t^6}{3!} + \cdots$ Which we could write as a regular polynomial as $1 + t^2 + \frac{1}{2}t^4 + \frac{1}{6}t^6 + \frac{1}{24}t^8 + \cdots$ Another example: $\exp\left(\sin(t)\right)$ : $1 + \sin(t) + \frac{1}{2}\sin^2 (t) + \frac{1}{6}\sin^3 (t) + \cdots$ Actually, this is the same thing as raising $e$ to the power of a function. If we took $\exp(e^x)$ it would be the same as $e^{(e^x)}$ : $1 + \frac{1}{2}e^x + \frac{1}{6}e^{2x} + \cdots$ Question : Does the exponential “converge” for function inputs? Also, is there anything useful you can take away from taking the exponential of a function?","I’m in middle school (6th grade) and I have a question related to the exponential function (the teacher couldn’t help me): We define the exponential as follows: For whole number inputs of , this corresponds to raising to that power. I think converges for every possible input of , but I haven’t found a proof yet. If anyone can provide a proof or disproof then that would be helpful. I would also like to know if for some where , will also be . However, these are secondary questions and you can ignore them (but do answer if you want). We also define for complex numbers , and matrices . Today I thought about the exponential of a function: . For example, let’s take . This would result in something like: Which we could write as a regular polynomial as Another example: : Actually, this is the same thing as raising to the power of a function. If we took it would be the same as : Question : Does the exponential “converge” for function inputs? Also, is there anything useful you can take away from taking the exponential of a function?", \exp(t) = \sum_{n = 0}^{\infty} \frac{t^n}{n!} t e \exp(t) t \exp(t) t \in U \exp(t) \in U \exp(t) \exp(f(t)) \exp(t^2) \exp(t^2) = \sum_{n = 0}^{\infty} \frac{(t^2)^n}{n!} = 1 + t^2 + \frac{t^4}{2!} + \frac{t^6}{3!} + \cdots 1 + t^2 + \frac{1}{2}t^4 + \frac{1}{6}t^6 + \frac{1}{24}t^8 + \cdots \exp\left(\sin(t)\right) 1 + \sin(t) + \frac{1}{2}\sin^2 (t) + \frac{1}{6}\sin^3 (t) + \cdots e \exp(e^x) e^{(e^x)} 1 + \frac{1}{2}e^x + \frac{1}{6}e^{2x} + \cdots,"['real-analysis', 'functions']"
38,Evaluating $\int_0^\infty \frac{\arctan (x^2) \ln(1+x^4)}{x(x^8+x^4+1)} \mathrm dx$,Evaluating,\int_0^\infty \frac{\arctan (x^2) \ln(1+x^4)}{x(x^8+x^4+1)} \mathrm dx,"So, my friend has challenged me to solve the following integral $\displaystyle \tag*{} I=\int_0^\infty  \frac{\arctan (x^2) \ln(1+x^4)}{x(x^8+x^4+1)} \mathrm dx$ I started by doing $x^2=t$ , so $\displaystyle \tag{1} I=\frac 12 \int_0^\infty  \frac{\arctan (x) \ln(1+x^2)}{x(x^4+x^2+1)} \mathrm dx$ Now, I first tried to solve this generalized integral: $\displaystyle \tag*{} \mathcal L(m,n,a) = \int_0^\infty \frac{\arctan(mx)\ln(1+n^2x^2)}{x(a^2+x^2)} \ \mathrm dx$ We have $\mathcal L(0,1,a)=0$ and $\mathcal L(1,0,a)=0$ . We now differentiate $\mathcal L(m,n,a)$ w.r.t $m$ first and then w.r.t $n$ . We get: $\displaystyle \tag{2} \begin{align} \partial m \ \partial n  \ \mathcal L(m,n,a) &= \int_0^\infty \frac{2nx^2}{(a^2+x^2)(1+m^2x^2)(1+n^2x^2)} \ \mathrm dx \\\\  &= \frac{\pi n}{(m+n)(am+1)(an+1)} \\\\  &= \frac{\pi}{2(am+1)(an+1)} , \ \ \text{via symmetry} \end{align}$ And now taking the double integeral gives $\displaystyle \tag{3} \mathcal L(1,1,a) = \int_0^1\int_0^1 \frac{\pi}{2(am+1)(an+1)} \ \mathrm dm \ \mathrm dn$ Using the elementary result: $\displaystyle \tag*{} \int_0^1 \frac{1}{ay+1} \ \mathrm dy = \frac{\log(a+1)}{a}$ We find the value of $(3)$ as $\displaystyle \tag*{} \mathcal L(1,1,a) = \frac{\pi \log^2(a+1)}{2a^2}$ Finally, we conclude that $\displaystyle \tag*{}\int_0^\infty \frac{\arctan(x)\ln(1+x^2)}{x(a^2+x^2)} \ \mathrm dx={\color{Red} { \frac{\pi \log^2(a+1)}{2a^2}}}:= {\color{Blue}{ f(a)}}$ Now by completing square and performing, we have: $\displaystyle \tag*{} \begin{align}\frac{1}{x^4+x^2+1} &=\frac{1}{\left(x^2+\frac 12\right)^2+\frac 34 }\\ &= \frac{1}{\left(x^2+\frac 12 - \frac{i \sqrt 3}{2}\right)\left(x^2+\frac 12 + \frac{i \sqrt 3}{2}\right)} \\ &= \frac{2}{i \sqrt 3} \left(\frac{1}{\left(x^2+\frac 12 - \frac{i \sqrt 3}{2}\right)}-\frac{1}{\left(x^2+\frac 12 + \frac{i \sqrt 3}{2}\right)}\right)\end{align} $ Adding all the pieces together, we get $\displaystyle \tag{4} I=\frac{1}{i \sqrt 3} \left(f\left(\sqrt{\frac{1-i\sqrt3}{2}}\right) - f\left(\sqrt{\frac{1+i\sqrt3}{2}}\right)\right)$ My question is to simplify $(4)$ (if all my steps are correct) and also is there any short ways (methods others than contour integration) to destroy this integral? Thanks :).","So, my friend has challenged me to solve the following integral I started by doing , so Now, I first tried to solve this generalized integral: We have and . We now differentiate w.r.t first and then w.r.t . We get: And now taking the double integeral gives Using the elementary result: We find the value of as Finally, we conclude that Now by completing square and performing, we have: Adding all the pieces together, we get My question is to simplify (if all my steps are correct) and also is there any short ways (methods others than contour integration) to destroy this integral? Thanks :).","\displaystyle \tag*{} I=\int_0^\infty  \frac{\arctan (x^2) \ln(1+x^4)}{x(x^8+x^4+1)} \mathrm dx x^2=t \displaystyle \tag{1} I=\frac 12 \int_0^\infty  \frac{\arctan (x) \ln(1+x^2)}{x(x^4+x^2+1)} \mathrm dx \displaystyle \tag*{} \mathcal L(m,n,a) = \int_0^\infty \frac{\arctan(mx)\ln(1+n^2x^2)}{x(a^2+x^2)} \ \mathrm dx \mathcal L(0,1,a)=0 \mathcal L(1,0,a)=0 \mathcal L(m,n,a) m n \displaystyle \tag{2} \begin{align} \partial m \ \partial n  \ \mathcal L(m,n,a) &= \int_0^\infty \frac{2nx^2}{(a^2+x^2)(1+m^2x^2)(1+n^2x^2)} \ \mathrm dx \\\\
 &= \frac{\pi n}{(m+n)(am+1)(an+1)} \\\\
 &= \frac{\pi}{2(am+1)(an+1)} , \ \ \text{via symmetry} \end{align} \displaystyle \tag{3} \mathcal L(1,1,a) = \int_0^1\int_0^1 \frac{\pi}{2(am+1)(an+1)} \ \mathrm dm \ \mathrm dn \displaystyle \tag*{} \int_0^1 \frac{1}{ay+1} \ \mathrm dy = \frac{\log(a+1)}{a} (3) \displaystyle \tag*{} \mathcal L(1,1,a) = \frac{\pi \log^2(a+1)}{2a^2} \displaystyle \tag*{}\int_0^\infty \frac{\arctan(x)\ln(1+x^2)}{x(a^2+x^2)} \ \mathrm dx={\color{Red} { \frac{\pi \log^2(a+1)}{2a^2}}}:= {\color{Blue}{ f(a)}} \displaystyle \tag*{} \begin{align}\frac{1}{x^4+x^2+1} &=\frac{1}{\left(x^2+\frac 12\right)^2+\frac 34 }\\ &= \frac{1}{\left(x^2+\frac 12 - \frac{i \sqrt 3}{2}\right)\left(x^2+\frac 12 + \frac{i \sqrt 3}{2}\right)} \\ &= \frac{2}{i \sqrt 3} \left(\frac{1}{\left(x^2+\frac 12 - \frac{i \sqrt 3}{2}\right)}-\frac{1}{\left(x^2+\frac 12 + \frac{i \sqrt 3}{2}\right)}\right)\end{align}  \displaystyle \tag{4} I=\frac{1}{i \sqrt 3} \left(f\left(\sqrt{\frac{1-i\sqrt3}{2}}\right) - f\left(\sqrt{\frac{1+i\sqrt3}{2}}\right)\right) (4)","['real-analysis', 'calculus', 'integration', 'definite-integrals', 'solution-verification']"
39,Understanding Layer Cake Representation,Understanding Layer Cake Representation,,"It is a common exercise to show that if $f\in L^1 $ then $$\int_R |f(x)|d\mu(x) =\int_0^\infty \mu(\{|f|\geq t\})dt $$ In showing this, it is common to make the observation that $$ \mathbb{1}_{[0,|f(x)|]}(t) = \mathbb{1}_{\{|f|\geq t\}}(x) $$ I can't seem to figure out how these are equal and what the notation means. I am familiar with the indicator function, but not of an indicator function being a function of $ t$ or $x$ here, so perhaps this is part of my misunderstanding. Why are these two indicator functions equal?","It is a common exercise to show that if then In showing this, it is common to make the observation that I can't seem to figure out how these are equal and what the notation means. I am familiar with the indicator function, but not of an indicator function being a function of or here, so perhaps this is part of my misunderstanding. Why are these two indicator functions equal?","f\in L^1  \int_R |f(x)|d\mu(x) =\int_0^\infty \mu(\{|f|\geq t\})dt   \mathbb{1}_{[0,|f(x)|]}(t) = \mathbb{1}_{\{|f|\geq t\}}(x)   t x","['real-analysis', 'lebesgue-integral', 'lebesgue-measure']"
40,"If $\{x_n\}$ is an increasing sequence and $\lim_{n\to\infty}x_n=L$, then $L$ is an upper bound of $\{x_n\}$","If  is an increasing sequence and , then  is an upper bound of",\{x_n\} \lim_{n\to\infty}x_n=L L \{x_n\},"I was wondering if somebody could critique my proof -- I feel I have the general idea but my solution lacks elegance. I appreciate your help! Proposition: An increasing sequence $\{x_n\}$ has a limit $L$ . Then $L$ is an upper bound for $\{x_n\}$ . Indirect Proof: Assume that $L$ is not an upper bound. Then for some value $n=N$ , we have: $$x_{N}>L.$$ Since $ x_n $ is increasing, we have: $$x_{n}> L\text{ for all }n \geq N.$$ However, because $L$ is the limit of $x_n$ , we also have, given $\epsilon>0$ ,: $$L-\epsilon<x_n<L+\epsilon,$$ for sufficiently large $n$ . Because the above equation must hold for all $\epsilon >0$ , I can select a value of $\epsilon$ such that: $$ 0<\epsilon<x_N-L.$$ It follows that: $$L+\epsilon<x_N.$$ And since $x_n$ is an increasing sequence, I can extend the above equation to: $$L+\epsilon<x_n$$ for sufficiently large $n$ . This contradicts our earlier definition of $L$ as the limit of $x_n$ , which required $x_n<L+\epsilon$ for sufficiently large $n$ . Therefore, our original assumption is false, and we conclude that $L$ is an upper bound.","I was wondering if somebody could critique my proof -- I feel I have the general idea but my solution lacks elegance. I appreciate your help! Proposition: An increasing sequence has a limit . Then is an upper bound for . Indirect Proof: Assume that is not an upper bound. Then for some value , we have: Since is increasing, we have: However, because is the limit of , we also have, given ,: for sufficiently large . Because the above equation must hold for all , I can select a value of such that: It follows that: And since is an increasing sequence, I can extend the above equation to: for sufficiently large . This contradicts our earlier definition of as the limit of , which required for sufficiently large . Therefore, our original assumption is false, and we conclude that is an upper bound.","\{x_n\} L L \{x_n\} L n=N x_{N}>L.  x_n  x_{n}> L\text{ for all }n \geq N. L x_n \epsilon>0 L-\epsilon<x_n<L+\epsilon, n \epsilon >0 \epsilon  0<\epsilon<x_N-L. L+\epsilon<x_N. x_n L+\epsilon<x_n n L x_n x_n<L+\epsilon n L","['real-analysis', 'proof-verification']"
41,How to find $\lim\limits_{n \to \infty}n\int_{0}^{1}(\cos x-\sin x)^ndx$?,How to find ?,\lim\limits_{n \to \infty}n\int_{0}^{1}(\cos x-\sin x)^ndx,"I want to compute $$\lim\limits_{n \to \infty}n\int_{0}^{1}(\cos x-\sin x)^ndx$$ Someone helped me find the limit of the integral , which is $0$ , but now I can't figure out this one. Also tried squeeze theorem but I only get only one side of it to converge to $1$ . Moreover, I'm bound to using elementary calculus.","I want to compute Someone helped me find the limit of the integral , which is , but now I can't figure out this one. Also tried squeeze theorem but I only get only one side of it to converge to . Moreover, I'm bound to using elementary calculus.",\lim\limits_{n \to \infty}n\int_{0}^{1}(\cos x-\sin x)^ndx 0 1,"['real-analysis', 'calculus', 'limits', 'trigonometric-integrals']"
42,"If $g$ is 2 times differentiable in $[a,b]$ and $g''+g'\,g=g$ and $g(a)=g(b)=0$, prove that $g=0$.","If  is 2 times differentiable in  and  and , prove that .","g [a,b] g''+g'\,g=g g(a)=g(b)=0 g=0","Let $g:[a,b]\rightarrow \mathbb{R}$ two times differentiable such that $$g''(x)+g'(x)\,g(x)=g(x),~x\in [a,b]$$   and $g(a)=g(b)=0$. Prove that $g(x)=0$ for all $x\in [a,b].$ Attempt . It seemed like one of those exercises where multiplying be a suitable factor  we get a derivative. I started by multiplying with $g$, after with $e^g$ but I dind't get what I expected. Am I on the wrong path? Thanks in advance for the help!","Let $g:[a,b]\rightarrow \mathbb{R}$ two times differentiable such that $$g''(x)+g'(x)\,g(x)=g(x),~x\in [a,b]$$   and $g(a)=g(b)=0$. Prove that $g(x)=0$ for all $x\in [a,b].$ Attempt . It seemed like one of those exercises where multiplying be a suitable factor  we get a derivative. I started by multiplying with $g$, after with $e^g$ but I dind't get what I expected. Am I on the wrong path? Thanks in advance for the help!",,"['calculus', 'real-analysis', 'derivatives']"
43,Composition of absolutely continuous function on $\mathbb{R}$ [duplicate],Composition of absolutely continuous function on  [duplicate],\mathbb{R},"This question already has an answer here : Composition of Absolutely Continuous Functions (1 answer) Closed 6 years ago . Is it true that the composition of two absolutely continuous functions on the real line is absolutely continuous? I feel like this should be a resounding no, however, I'm unsure of any quick counterexamples to this claim.  Can anyone think of one?","This question already has an answer here : Composition of Absolutely Continuous Functions (1 answer) Closed 6 years ago . Is it true that the composition of two absolutely continuous functions on the real line is absolutely continuous? I feel like this should be a resounding no, however, I'm unsure of any quick counterexamples to this claim.  Can anyone think of one?",,"['real-analysis', 'measure-theory', 'examples-counterexamples', 'function-and-relation-composition', 'absolute-continuity']"
44,In search of nontrivial solutions to $f'(t)=f(t/2)$,In search of nontrivial solutions to,f'(t)=f(t/2),"Just then my friend gave me a kinda interesting problem: find all non-trivial solutions to the DE $$f'(t)=f(\frac t2),\quad f:\Bbb R\to\Bbb R.$$ Regularity concerns are temporarily ignored. You may just assume sufficient smoothness if needed. (Note also that this is NOT an ODE!) So far the only solution I can find is $f\equiv 0$, the trivial one. And surprisingly, I can't find any useful results of this problem, simple as it looks. Any full or non full answer or just attempt is welcome!","Just then my friend gave me a kinda interesting problem: find all non-trivial solutions to the DE $$f'(t)=f(\frac t2),\quad f:\Bbb R\to\Bbb R.$$ Regularity concerns are temporarily ignored. You may just assume sufficient smoothness if needed. (Note also that this is NOT an ODE!) So far the only solution I can find is $f\equiv 0$, the trivial one. And surprisingly, I can't find any useful results of this problem, simple as it looks. Any full or non full answer or just attempt is welcome!",,"['real-analysis', 'ordinary-differential-equations', 'recreational-mathematics', 'functional-equations']"
45,Function analytic in each variable does not imply jointly analytic,Function analytic in each variable does not imply jointly analytic,,"I have heard that a function $f: \mathbb R^2 \to \mathbb R$ can be analytic in each variable (i.e. $f(x,y_0) = \sum_{n=0}^{\infty} a_n x^n, \forall x \in \mathbb R$, and the same for $y$) without being jointly analytic (i.e. $f(x,y) = \sum_{i,j=0}^{\infty} a_i b_j x^i y^j, \forall x,y \in \mathbb R$). Is there some standard example of such a function?","I have heard that a function $f: \mathbb R^2 \to \mathbb R$ can be analytic in each variable (i.e. $f(x,y_0) = \sum_{n=0}^{\infty} a_n x^n, \forall x \in \mathbb R$, and the same for $y$) without being jointly analytic (i.e. $f(x,y) = \sum_{i,j=0}^{\infty} a_i b_j x^i y^j, \forall x,y \in \mathbb R$). Is there some standard example of such a function?",,"['real-analysis', 'analyticity']"
46,Continuous functions that attain local extrema at every point,Continuous functions that attain local extrema at every point,,"Let $f:[0,1]\to\mathbb R$ is a continuous function, and for all $x\in [0,1]$, $f(x)$ is either a local maximum or a local minimum. Then prove that $f$ is a constant. Here is what I have tried, I don't know whether it is correct: Assume $f$ is not a constant, by continuity, there exist $x_1$, $x_2$ such that $f(x_1)=m$ is a global minimum and $f(x_2)=M$ is a global maximum. Now if $m\ne M$, choose any $c\in(m,M)$ and define $$x_0=\sup (x\in[x_1,x_2]:f(x)<c)$$ Then we have $f(x_0)$ NOT a local minimum nor a local maximum (since according to the definition of $x_0$, there are always some points $<c$ in the left neighborhood of $x_0$ and the points in right neighborhood are always $>c$). Contradiction arises and so $f$ must be a constant.","Let $f:[0,1]\to\mathbb R$ is a continuous function, and for all $x\in [0,1]$, $f(x)$ is either a local maximum or a local minimum. Then prove that $f$ is a constant. Here is what I have tried, I don't know whether it is correct: Assume $f$ is not a constant, by continuity, there exist $x_1$, $x_2$ such that $f(x_1)=m$ is a global minimum and $f(x_2)=M$ is a global maximum. Now if $m\ne M$, choose any $c\in(m,M)$ and define $$x_0=\sup (x\in[x_1,x_2]:f(x)<c)$$ Then we have $f(x_0)$ NOT a local minimum nor a local maximum (since according to the definition of $x_0$, there are always some points $<c$ in the left neighborhood of $x_0$ and the points in right neighborhood are always $>c$). Contradiction arises and so $f$ must be a constant.",,"['real-analysis', 'analysis']"
47,Proving that I can interchange limit and infinite sum,Proving that I can interchange limit and infinite sum,,"So I want to prove that  $$\lim_{x \to a} \sum_{n=0}^{\infty} f_n(x) = \sum_{n=0}^{\infty} \lim_{x \to a} f_n(x)$$ is true if $\displaystyle \sum_{n=0}^\infty f_n(x)$ converges uniformly. I'd like to avoid advanced theorems, like Dominated Convergence etc which is all I find on similar questions. Can this be proven in an elementary way?","So I want to prove that  $$\lim_{x \to a} \sum_{n=0}^{\infty} f_n(x) = \sum_{n=0}^{\infty} \lim_{x \to a} f_n(x)$$ is true if $\displaystyle \sum_{n=0}^\infty f_n(x)$ converges uniformly. I'd like to avoid advanced theorems, like Dominated Convergence etc which is all I find on similar questions. Can this be proven in an elementary way?",,"['real-analysis', 'sequences-and-series', 'limits', 'uniform-convergence']"
48,Another integral related to Fresnel integrals,Another integral related to Fresnel integrals,,"How would we prove this result by real methods ? $$\int_0^{\infty } \frac{\sin \left(\pi  x^2\right)}{x+2} \, dx=\frac{1}{4} \left(\pi-2 \pi  C\left(2 \sqrt{2}\right)-2 \pi  S\left(2 \sqrt{2}\right)+2 \text{Si}(4 \pi ) \right)$$ As you can easily see, Fresnel integrals are involved. What are your ideas on it?","How would we prove this result by real methods ? $$\int_0^{\infty } \frac{\sin \left(\pi  x^2\right)}{x+2} \, dx=\frac{1}{4} \left(\pi-2 \pi  C\left(2 \sqrt{2}\right)-2 \pi  S\left(2 \sqrt{2}\right)+2 \text{Si}(4 \pi ) \right)$$ As you can easily see, Fresnel integrals are involved. What are your ideas on it?",,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'special-functions']"
49,Find a closed form of the power series,Find a closed form of the power series,,"Let a power series $$S(x)=\sum_{n=1}^{\infty}\frac{x^{n}}{4n+1},$$ then  $1$ is the radius of convergence of $S$ .In fact $S(x)$ convergens for each $x\in[-1,1).$ My work is to find a closed form of this power series. The following is my solution: $$S(x)=\sum_{n=1}^{\infty}\frac{(4n+1)x^{n}-4nx^{n}}{4n+1}=\sum_{n=1}^{\infty}x^{n}-4x\sum_{n=1}^{\infty}(\frac{x^{n}}{4n+1})^{'}.$$then we have $$S(x)+4x S^{'}(x)=\frac{x}{1-x}.(\text{a first-order linear differential equation })\Rightarrow $$  $$\mathbf{A.}\quad  S(x)=\frac{1}{x^{\frac{1}{4}}}[C_{1}+\frac{\ln(1+x^{\frac{1}{4}})+2\arctan(x^{\frac{1}{4}})-\ln(1-x^{\frac{1}{4}})-4x^{\frac{1}{4}}}{4}](1>x>0);$$$$\mathbf{B.}\quad  S(x)=-\frac{1}{8(-x)^{\frac{1}{4}}}\begin{Bmatrix} C_{2}+8(-x)^{\frac{1}{4}}\\+2\sqrt{2}\arctan[1-\sqrt{2}(-x)^{\frac{1}{4}}]-2\sqrt{2}\arctan[1+\sqrt{2}(-x)^{\frac{1}{4}}]\\+ \sqrt{2}\ln[1-\sqrt{2}(-x)^{\frac{1}{4}}+\sqrt{-x}]-\sqrt{2}\ln[1+\sqrt{2}(-x)^{\frac{1}{4}}+\sqrt{-x}] \end{Bmatrix}\quad(-1\leq x<0).$$ Since $S(0)=0$ and $S(x)$ is continuous at $x=0$ , I conclude that $C_{1}=C_{2}=0.$ I am not sure my solution is right .I need someone to check my answer,or If you   have some good ideas about how to solve this question ,please give me some hints.Any help is going to be appreciated!","Let a power series $$S(x)=\sum_{n=1}^{\infty}\frac{x^{n}}{4n+1},$$ then  $1$ is the radius of convergence of $S$ .In fact $S(x)$ convergens for each $x\in[-1,1).$ My work is to find a closed form of this power series. The following is my solution: $$S(x)=\sum_{n=1}^{\infty}\frac{(4n+1)x^{n}-4nx^{n}}{4n+1}=\sum_{n=1}^{\infty}x^{n}-4x\sum_{n=1}^{\infty}(\frac{x^{n}}{4n+1})^{'}.$$then we have $$S(x)+4x S^{'}(x)=\frac{x}{1-x}.(\text{a first-order linear differential equation })\Rightarrow $$  $$\mathbf{A.}\quad  S(x)=\frac{1}{x^{\frac{1}{4}}}[C_{1}+\frac{\ln(1+x^{\frac{1}{4}})+2\arctan(x^{\frac{1}{4}})-\ln(1-x^{\frac{1}{4}})-4x^{\frac{1}{4}}}{4}](1>x>0);$$$$\mathbf{B.}\quad  S(x)=-\frac{1}{8(-x)^{\frac{1}{4}}}\begin{Bmatrix} C_{2}+8(-x)^{\frac{1}{4}}\\+2\sqrt{2}\arctan[1-\sqrt{2}(-x)^{\frac{1}{4}}]-2\sqrt{2}\arctan[1+\sqrt{2}(-x)^{\frac{1}{4}}]\\+ \sqrt{2}\ln[1-\sqrt{2}(-x)^{\frac{1}{4}}+\sqrt{-x}]-\sqrt{2}\ln[1+\sqrt{2}(-x)^{\frac{1}{4}}+\sqrt{-x}] \end{Bmatrix}\quad(-1\leq x<0).$$ Since $S(0)=0$ and $S(x)$ is continuous at $x=0$ , I conclude that $C_{1}=C_{2}=0.$ I am not sure my solution is right .I need someone to check my answer,or If you   have some good ideas about how to solve this question ,please give me some hints.Any help is going to be appreciated!",,"['calculus', 'real-analysis']"
50,What is the difference between a ring and a $\sigma$-ring?,What is the difference between a ring and a -ring?,\sigma,"I started reading Rudin's Principles of Mathematical Analysis for some Lebesgue Theory. Rudin introduces both rings and $\sigma$-rings, but I don't see the difference between them. Assuming I'm not misunderstanding the definition, a ring is a family $\mathscr{R}$ of sets that is closed under set difference and unions. On the other hand, a $\sigma$- ring is a ring with the property that $\bigcup_{n=1}^{\infty}A_n\in\mathscr{R}$, where $A_i\in\mathscr{R}$. But isn't this just saying that a $\sigma$-ring is a ring that is closed under union, which we already know from the definition of a ring? If someone could help clear this doubt, it would be appreciated. Thanks.","I started reading Rudin's Principles of Mathematical Analysis for some Lebesgue Theory. Rudin introduces both rings and $\sigma$-rings, but I don't see the difference between them. Assuming I'm not misunderstanding the definition, a ring is a family $\mathscr{R}$ of sets that is closed under set difference and unions. On the other hand, a $\sigma$- ring is a ring with the property that $\bigcup_{n=1}^{\infty}A_n\in\mathscr{R}$, where $A_i\in\mathscr{R}$. But isn't this just saying that a $\sigma$-ring is a ring that is closed under union, which we already know from the definition of a ring? If someone could help clear this doubt, it would be appreciated. Thanks.",,['real-analysis']
51,The closed form of $\sum_{n=1}^{\infty} \left(\frac{1}{\lfloor\sqrt{3n}\rfloor^2}-\frac{1}{3n}\right)$,The closed form of,\sum_{n=1}^{\infty} \left(\frac{1}{\lfloor\sqrt{3n}\rfloor^2}-\frac{1}{3n}\right),I need some ideas to exploit for finding the closed form of  $$\sum_{n=1}^{\infty} \left(\frac{1}{\lfloor\sqrt{3n}\rfloor^2}-\frac{1}{3n}\right)$$,I need some ideas to exploit for finding the closed form of  $$\sum_{n=1}^{\infty} \left(\frac{1}{\lfloor\sqrt{3n}\rfloor^2}-\frac{1}{3n}\right)$$,,"['calculus', 'real-analysis', 'sequences-and-series', 'number-theory']"
52,Mean Value Theorem: $\frac{2}{\pi}<\frac{\sin x}{x}<1$,Mean Value Theorem:,\frac{2}{\pi}<\frac{\sin x}{x}<1,"I need to show that $\dfrac{2}{\pi}<\dfrac{\sin(x)}{x}<1$ for $0<x<\dfrac{\pi}{2}$. I know I need to use the mean value theorem, would I just say that since $f$ is continuous in the interval (call it I). We know $\exists c\in I$ such that $f'(c) = \dfrac{f\left(\dfrac{\pi}{2}\right)-f(0)}{\dfrac{\pi}{2}}$. I don't know where this is going though. Also, would I need to show $\lim_{x \to 0}\dfrac{\sin(x)}{x} = 1$? Is there a way to do this without L'H Rule?","I need to show that $\dfrac{2}{\pi}<\dfrac{\sin(x)}{x}<1$ for $0<x<\dfrac{\pi}{2}$. I know I need to use the mean value theorem, would I just say that since $f$ is continuous in the interval (call it I). We know $\exists c\in I$ such that $f'(c) = \dfrac{f\left(\dfrac{\pi}{2}\right)-f(0)}{\dfrac{\pi}{2}}$. I don't know where this is going though. Also, would I need to show $\lim_{x \to 0}\dfrac{\sin(x)}{x} = 1$? Is there a way to do this without L'H Rule?",,"['calculus', 'real-analysis']"
53,"A sequence of measurable functions and the sup, lim sup of them","A sequence of measurable functions and the sup, lim sup of them",,"So I have stumbled upon the following theorem: Let $\left\{f_n\right\}$ be a sequence of measurable functions. For $x \in X$, put   $$ g(x) = \sup \left\{ f_n (x) \mid n \in \mathbb{N} \right\} \\ h(x) = \limsup_{n \to \infty} f_n (x) $$   Then $g$ and $h$ are measurable The proof is as follows: $$ \left\{ x \mid g(x) > a \right\} = \bigcup_{n=1}^{\infty} \left\{ x \mid f_n (x) > a \right\} $$ At least to me, this seems to not be true, so I was wondering if someone could help me understand where I go awry. It seems to me that you could have a sequence of functions $f_n (x) = x + \frac{x}{n} : n \neq 3 , f_3 (x) = 1000$. From the proof  $$ g(x) = \sup \left\{ x + \frac{x}{n} \mid n \in \mathbb{N} \right\} = \left\{ \begin{array}{rr} 2x & : x \ge 0 \\ x & : x < 0 \end{array} \right. $$ Now it seems to me that each $f_n (x)$ is measurable in $\mathbb{R}$ however the statement in the proof isn't true here. Put $a = 3$ then $\left\{ x \mid g(x) > 3 \right\} = \left( \frac{3}{2}, \infty \right)$ however $\bigcup_{n=1}^{\infty} \left\{ x \mid f_n (x) > 3 \right\} = (- \infty , \infty )$ because $f_3 (x) > 3 \; \forall \; x \in \mathbb{R}$, so wouldn't this be a counter example to the proof given? Thanks in advance!","So I have stumbled upon the following theorem: Let $\left\{f_n\right\}$ be a sequence of measurable functions. For $x \in X$, put   $$ g(x) = \sup \left\{ f_n (x) \mid n \in \mathbb{N} \right\} \\ h(x) = \limsup_{n \to \infty} f_n (x) $$   Then $g$ and $h$ are measurable The proof is as follows: $$ \left\{ x \mid g(x) > a \right\} = \bigcup_{n=1}^{\infty} \left\{ x \mid f_n (x) > a \right\} $$ At least to me, this seems to not be true, so I was wondering if someone could help me understand where I go awry. It seems to me that you could have a sequence of functions $f_n (x) = x + \frac{x}{n} : n \neq 3 , f_3 (x) = 1000$. From the proof  $$ g(x) = \sup \left\{ x + \frac{x}{n} \mid n \in \mathbb{N} \right\} = \left\{ \begin{array}{rr} 2x & : x \ge 0 \\ x & : x < 0 \end{array} \right. $$ Now it seems to me that each $f_n (x)$ is measurable in $\mathbb{R}$ however the statement in the proof isn't true here. Put $a = 3$ then $\left\{ x \mid g(x) > 3 \right\} = \left( \frac{3}{2}, \infty \right)$ however $\bigcup_{n=1}^{\infty} \left\{ x \mid f_n (x) > 3 \right\} = (- \infty , \infty )$ because $f_3 (x) > 3 \; \forall \; x \in \mathbb{R}$, so wouldn't this be a counter example to the proof given? Thanks in advance!",,"['real-analysis', 'analysis', 'measure-theory']"
54,What type of discontinuity is $\sin(1/x)$?,What type of discontinuity is ?,\sin(1/x),"For those of you familiar with the graph of $\sin\left(\dfrac{1}{x}\right)$ , things get quite 'intense' as $x \to 0$ . Is this a removable discontinuity or an infinite discontinuity or even discontinuous at all? Lastly, is it differentiable at $x = 0$ ?","For those of you familiar with the graph of , things get quite 'intense' as . Is this a removable discontinuity or an infinite discontinuity or even discontinuous at all? Lastly, is it differentiable at ?",\sin\left(\dfrac{1}{x}\right) x \to 0 x = 0,"['real-analysis', 'calculus', 'continuity']"
55,non-continuous function satisfies $f(x+y)=f(x)+f(y)$,non-continuous function satisfies,f(x+y)=f(x)+f(y),"As mentioned in this link , it shows that For any $f$ on the real line $\mathbb{R}^1$, $f(x+y)=f(x)+f(y)$  implies $f$ continuous $\Leftrightarrow$ $f$  measurable. But how to show there exists such an non-measurable function satisfying $f(x+y)=f(x)+f(y)$? I guess we may use the uniform bounded principal and the fact that $f$ is continuous iff it is continuous at zero under the above assumption. Thanks in advance!","As mentioned in this link , it shows that For any $f$ on the real line $\mathbb{R}^1$, $f(x+y)=f(x)+f(y)$  implies $f$ continuous $\Leftrightarrow$ $f$  measurable. But how to show there exists such an non-measurable function satisfying $f(x+y)=f(x)+f(y)$? I guess we may use the uniform bounded principal and the fact that $f$ is continuous iff it is continuous at zero under the above assumption. Thanks in advance!",,"['real-analysis', 'analysis', 'functional-analysis', 'functional-equations']"
56,Function $f$ which isn't smooth but $f^3$ is smooth,Function  which isn't smooth but  is smooth,f f^3,"In Pugh's Real Mathematical Analysis there is an exercise, marked with three stars (which denotes that the author doesn't know the answer), whether there exist a nonsmooth function $f : \mathbb{R} \to \mathbb{R}$ such that $f^2$ and $f^3$ are both smooth. My question is not strictly about this exercise, but rather about cases when we weaken the hypotheses when only one of $f^2$ and $f^3$ are smooth. The fact that the exercise comes with this hypotheses suggest we should be able to find those functions. For the case when $f^2$ need to be smooth we have a function $f(x) = x$ if $x$ is rational and $-x$ if $x$ is irrational, but what about the case when $f^3$ needs to be smooth?","In Pugh's Real Mathematical Analysis there is an exercise, marked with three stars (which denotes that the author doesn't know the answer), whether there exist a nonsmooth function $f : \mathbb{R} \to \mathbb{R}$ such that $f^2$ and $f^3$ are both smooth. My question is not strictly about this exercise, but rather about cases when we weaken the hypotheses when only one of $f^2$ and $f^3$ are smooth. The fact that the exercise comes with this hypotheses suggest we should be able to find those functions. For the case when $f^2$ need to be smooth we have a function $f(x) = x$ if $x$ is rational and $-x$ if $x$ is irrational, but what about the case when $f^3$ needs to be smooth?",,['real-analysis']
57,A series with infinitely many logarithms: $\lim_{n\to\infty} \left(\frac{\ln 2}2+\frac{\ln 3}3+\cdots + \frac{\ln n}n \right)^{\frac1n}$,A series with infinitely many logarithms:,\lim_{n\to\infty} \left(\frac{\ln 2}2+\frac{\ln 3}3+\cdots + \frac{\ln n}n \right)^{\frac1n},I have to solve the following limit: $$\lim_{n\rightarrow\infty} \left(\frac{\ln 2}{2}+\frac{\ln 3}{3}+\cdots + \frac{\ln n}{n} \right)^{\frac{1}{n}}$$ I'm just curious if there is a simple way to solve it. I think I solved it by using some pretty unusual trick: I just considered the sum approximation under the radical by using an integral and got $\approx \frac{\ln^{2}n}{2}$. Then I simply applied Cauchy D'Alembert and got 1. Still thinking of a simple way.,I have to solve the following limit: $$\lim_{n\rightarrow\infty} \left(\frac{\ln 2}{2}+\frac{\ln 3}{3}+\cdots + \frac{\ln n}{n} \right)^{\frac{1}{n}}$$ I'm just curious if there is a simple way to solve it. I think I solved it by using some pretty unusual trick: I just considered the sum approximation under the radical by using an integral and got $\approx \frac{\ln^{2}n}{2}$. Then I simply applied Cauchy D'Alembert and got 1. Still thinking of a simple way.,,"['real-analysis', 'sequences-and-series', 'limits', 'logarithms']"
58,Questions about derivative and differentiation,Questions about derivative and differentiation,,"For a real-valued function $f$ defined on $\mathbb{R}$ or its subset, is it possible that it is differentiable at one point and not in one of its neighbourhoods except the point itself? is it possible that it is differentiable over an interval, but its derivative over the interval is not continuous? I found on this link that for $f(x) = x^2 \sin(1/x)$, when $x$ is not 0, the derivative is $2x \sin(1/x) -     \cos(1/x)$ which does not have a limit as x approaches 0, but the derivative of $f$ does exist at 0: $$\lim_{h \rightarrow 0} ( h^2     \sin(1/h) - 0)/(h-0) = 0.$$ I was wondering how $f$ is differentiable at 0? Doesn't it require $f$ to be defined on 0? Thanks and regards!","For a real-valued function $f$ defined on $\mathbb{R}$ or its subset, is it possible that it is differentiable at one point and not in one of its neighbourhoods except the point itself? is it possible that it is differentiable over an interval, but its derivative over the interval is not continuous? I found on this link that for $f(x) = x^2 \sin(1/x)$, when $x$ is not 0, the derivative is $2x \sin(1/x) -     \cos(1/x)$ which does not have a limit as x approaches 0, but the derivative of $f$ does exist at 0: $$\lim_{h \rightarrow 0} ( h^2     \sin(1/h) - 0)/(h-0) = 0.$$ I was wondering how $f$ is differentiable at 0? Doesn't it require $f$ to be defined on 0? Thanks and regards!",,['real-analysis']
59,$\sum_{n=1}^\infty\ln(1+u_n)$ converges but $\sum_{n=1}^\infty u_n$ diverges,converges but  diverges,\sum_{n=1}^\infty\ln(1+u_n) \sum_{n=1}^\infty u_n,"We know that if $\sum\limits_{n=1}^\infty u_n^2<+\infty$ is convergent, then both $\sum\limits_{n=1}^\infty u_n$ and $\sum\limits_{n=1}^\infty \ln(1+u_n)$ converge or diverge simultaneously. If $\sum\limits_{n=1}^\infty u_n$ converges and $\sum\limits_{n=1}^\infty u^2_n=+\infty$ , then $\sum\limits_{n=1}^\infty \ln(1+u_n)=-\infty$ ；If $\sum\limits_{n=1}^\infty \ln(1+u_n)$ converges and $\sum\limits_{n=1}^\infty u^2_n=+\infty$ , then $\sum\limits_{n=1}^\infty u_n=+\infty$ . My question is that: can we construct a sequence $\{u_n\}$ such that $\sum\limits_{n=1}^\infty\ln(1+u_n)$ is convergent but $\sum\limits_{n=1}^\infty u_n$ is divergent? In fact, it is suffices to construct $\{u_n\}$ such that $$\sum_{n=1}^\infty u_n=+\infty,\quad \sum_{n=1}^\infty \frac{u^2_n}{2}=+\infty,\quad \sum_{n=1}^\infty|u_n|^3<+\infty$$ and $$\sum\limits_{n=1}^\infty\left(u_n-\frac{u^2_n}{2}\right) \text{is convergent.}$$ Does such a sequence exist？","We know that if is convergent, then both and converge or diverge simultaneously. If converges and , then ；If converges and , then . My question is that: can we construct a sequence such that is convergent but is divergent? In fact, it is suffices to construct such that and Does such a sequence exist？","\sum\limits_{n=1}^\infty u_n^2<+\infty \sum\limits_{n=1}^\infty u_n \sum\limits_{n=1}^\infty \ln(1+u_n) \sum\limits_{n=1}^\infty u_n \sum\limits_{n=1}^\infty u^2_n=+\infty \sum\limits_{n=1}^\infty \ln(1+u_n)=-\infty \sum\limits_{n=1}^\infty \ln(1+u_n) \sum\limits_{n=1}^\infty u^2_n=+\infty \sum\limits_{n=1}^\infty u_n=+\infty \{u_n\} \sum\limits_{n=1}^\infty\ln(1+u_n) \sum\limits_{n=1}^\infty u_n \{u_n\} \sum_{n=1}^\infty u_n=+\infty,\quad \sum_{n=1}^\infty \frac{u^2_n}{2}=+\infty,\quad
\sum_{n=1}^\infty|u_n|^3<+\infty \sum\limits_{n=1}^\infty\left(u_n-\frac{u^2_n}{2}\right) \text{is convergent.}","['real-analysis', 'analysis']"
60,"Find $\lim\limits_{n\to\infty}\left(\frac{(2n+1)!}{(n!)^2}\right)^2\int_0^1 \int_0^1 (xy(1-x)(1-y))^n f(x,y)dxdy$",Find,"\lim\limits_{n\to\infty}\left(\frac{(2n+1)!}{(n!)^2}\right)^2\int_0^1 \int_0^1 (xy(1-x)(1-y))^n f(x,y)dxdy","Note: even though this is technically a duplicate of this post , I'd like further justification on what exactly the claim about ""convergence in distribution"" in @JackD'Aurizio's answer means, and, if possible, a proof as to why that claim holds. Let $f\colon [0,1]^2\to\mathbb{R}$ be a continuous function. Find $$\lim\limits_{n\to\infty} \left(\dfrac{(2n+1)!}{(n!)^2}\right)^2\int_0^1 \int_0^1 (xy(1-x)(1-y))^n f(x,y)\ \mathrm dx\mathrm dy.$$ I think it might be useful to first consider the case where $f$ is a polynomial. By the linearity of integrals, it suffices to consider the case where $f(x,y)=x^ky^l$ for all x,y. Also, Stirling's formula might be useful. There's probably a general formula for evaluating the double integral $I(n,k,l) := \int_0^1 \int_0^1 x^{n+k} y^{n+l} (1-x)^n (1-y)^n dxdy.$ It seems possible but tedious to evaluate the latter integral using the Binomial theorem. Alternatively it might be possible to use induction if one can guess the general formula for the integral. For instance in the specific case that $n=0,$ we have the integral $\int_0^1 \int_0^1 x^k y^l dxdy = \dfrac{1}{(k+1)(l+1)}$ . By the linearity of the integral we also have $I(n,k,l) = I(n-1,k+1,l+1) -I(n-1,k+2,l+1)-I(n-1,k+1,l+2)+I(n-1,k+2,l+2).$ Also a special case of the Stone-Weierstrass theorem says that every continuous function $f:[0,1]^2\to\mathbb{R}$ can be uniformly approximated by polynomials. But I'm not sure if one can reduce to the case of polynomials.","Note: even though this is technically a duplicate of this post , I'd like further justification on what exactly the claim about ""convergence in distribution"" in @JackD'Aurizio's answer means, and, if possible, a proof as to why that claim holds. Let be a continuous function. Find I think it might be useful to first consider the case where is a polynomial. By the linearity of integrals, it suffices to consider the case where for all x,y. Also, Stirling's formula might be useful. There's probably a general formula for evaluating the double integral It seems possible but tedious to evaluate the latter integral using the Binomial theorem. Alternatively it might be possible to use induction if one can guess the general formula for the integral. For instance in the specific case that we have the integral . By the linearity of the integral we also have Also a special case of the Stone-Weierstrass theorem says that every continuous function can be uniformly approximated by polynomials. But I'm not sure if one can reduce to the case of polynomials.","f\colon [0,1]^2\to\mathbb{R} \lim\limits_{n\to\infty} \left(\dfrac{(2n+1)!}{(n!)^2}\right)^2\int_0^1 \int_0^1 (xy(1-x)(1-y))^n f(x,y)\ \mathrm dx\mathrm dy. f f(x,y)=x^ky^l I(n,k,l) := \int_0^1 \int_0^1 x^{n+k} y^{n+l} (1-x)^n (1-y)^n dxdy. n=0, \int_0^1 \int_0^1 x^k y^l dxdy = \dfrac{1}{(k+1)(l+1)} I(n,k,l) = I(n-1,k+1,l+1) -I(n-1,k+2,l+1)-I(n-1,k+1,l+2)+I(n-1,k+2,l+2). f:[0,1]^2\to\mathbb{R}","['real-analysis', 'integration', 'limits', 'continuity', 'binomial-coefficients']"
61,Is it possible to compute $\int_{0}^{\infty} \frac{1}{x^a + 1} dx$ without the residue theorem or Euler's reflection formula.,Is it possible to compute  without the residue theorem or Euler's reflection formula.,\int_{0}^{\infty} \frac{1}{x^a + 1} dx,"I've been trying to find a way to compute the integral $$\int_{0}^{\infty}\frac{1}{x^a + 1} dx, \quad a > 1$$ without having to resort to the heavy machinery of complex analysis. I've found two methods to compute this integral but they both use complex. One way is just to use contour integration on the slice of pie with angle $2\pi/a$ and apply the residue theorem, the other method uses u-substitution to turn this integral into the beta function $$\frac{1}{a}B\left(1/a,1-1/a\right) = \frac{1}{a}\Gamma(1/a)\Gamma(1-1/a)$$ and from here you can use Euler's reflection formula to get the solution. Is there any way to analyze this integral without referencing either the residue theorem or Euler's reflection formula?","I've been trying to find a way to compute the integral without having to resort to the heavy machinery of complex analysis. I've found two methods to compute this integral but they both use complex. One way is just to use contour integration on the slice of pie with angle and apply the residue theorem, the other method uses u-substitution to turn this integral into the beta function and from here you can use Euler's reflection formula to get the solution. Is there any way to analyze this integral without referencing either the residue theorem or Euler's reflection formula?","\int_{0}^{\infty}\frac{1}{x^a + 1} dx, \quad a > 1 2\pi/a \frac{1}{a}B\left(1/a,1-1/a\right) = \frac{1}{a}\Gamma(1/a)\Gamma(1-1/a)","['real-analysis', 'integration', 'complex-analysis']"
62,A sum of series with the inverse squared central binomial coefficient,A sum of series with the inverse squared central binomial coefficient,,"A nice challenge by Cornel Valean: Show that $$2\sum _{n=1}^{\infty }\frac{2^{4 n}}{\displaystyle n^3 \binom{2 n}{n}^2}-\sum _{n=1}^{\infty }\frac{2^{4 n}}{\displaystyle n^4 \binom{2 n}{n}^2}+\sum _{n=1}^{\infty }\frac{2^{4 n} H_n^{(2)}}{\displaystyle n^2 (2 n+1) \binom{2 n}{n}^2}=\frac{\pi^3}{3}.$$ I have to say that I am not experienced in series involving squared central binomial coefficient, so I leave it for people who are experts in such series. All approaches are appreciated. Thank you.","A nice challenge by Cornel Valean: Show that I have to say that I am not experienced in series involving squared central binomial coefficient, so I leave it for people who are experts in such series. All approaches are appreciated. Thank you.",2\sum _{n=1}^{\infty }\frac{2^{4 n}}{\displaystyle n^3 \binom{2 n}{n}^2}-\sum _{n=1}^{\infty }\frac{2^{4 n}}{\displaystyle n^4 \binom{2 n}{n}^2}+\sum _{n=1}^{\infty }\frac{2^{4 n} H_n^{(2)}}{\displaystyle n^2 (2 n+1) \binom{2 n}{n}^2}=\frac{\pi^3}{3}.,"['real-analysis', 'integration', 'sequences-and-series', 'binomial-coefficients', 'harmonic-numbers']"
63,Evaluating $\int_0^1\frac{\arctan x\ln\left(\frac{2x^2}{1+x^2}\right)}{1-x}dx$,Evaluating,\int_0^1\frac{\arctan x\ln\left(\frac{2x^2}{1+x^2}\right)}{1-x}dx,"Here is a nice problem proposed by Cornel Valean $$ I=\int_0^1\frac{\arctan\left(x\right)}{1-x}\, \ln\left(\frac{2x^2}{1+x^2}\right)\,\mathrm{d}x = -\frac{\pi}{16}\ln^{2}\left(2\right) - \frac{11}{192}\,\pi^{3} + 2\Im\left\{% \text{Li}_{3}\left(\frac{1 + \mathrm{i}}{2}\right)\right\} $$ My Trial: By subbing $x=\frac{1-t}{1+t}$ we have $$I=\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln\left(\frac{(1-x)^2}{1+x^2}\right)}{x(1+x)}dx$$ $$=2\underbrace{\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln(1-x)}{x(1+x)}dx}_{x\to (1-x)/(1+x)}-\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln(1+x^2)}{x(1+x)}dx$$ $$=2\int_0^1\frac{\arctan x\ln(\frac{2x}{1+x})}{1-x}dx-\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln(1+x^2)}{x(1+x)}dx$$ and got stuck here. Any idea? thanks.",Here is a nice problem proposed by Cornel Valean My Trial: By subbing we have and got stuck here. Any idea? thanks.,"
I=\int_0^1\frac{\arctan\left(x\right)}{1-x}\,
\ln\left(\frac{2x^2}{1+x^2}\right)\,\mathrm{d}x =
-\frac{\pi}{16}\ln^{2}\left(2\right) -
\frac{11}{192}\,\pi^{3} +
2\Im\left\{%
\text{Li}_{3}\left(\frac{1 + \mathrm{i}}{2}\right)\right\}
 x=\frac{1-t}{1+t} I=\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln\left(\frac{(1-x)^2}{1+x^2}\right)}{x(1+x)}dx =2\underbrace{\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln(1-x)}{x(1+x)}dx}_{x\to (1-x)/(1+x)}-\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln(1+x^2)}{x(1+x)}dx =2\int_0^1\frac{\arctan x\ln(\frac{2x}{1+x})}{1-x}dx-\int_0^1\frac{\left(\frac{\pi}{4}-\arctan x\right)\ln(1+x^2)}{x(1+x)}dx","['real-analysis', 'integration', 'closed-form', 'harmonic-numbers', 'polylogarithm']"
64,Most gentle introduction to undergraduate analysis,Most gentle introduction to undergraduate analysis,,"I will be teaching a course which expects to have the following topics pulled from a now out-of-print book: Fundamental ideas of analysis, by Michael C. Reed, John Wiley&Sons,1998 As we can't use this book, I need something comparable. The expected topics include (again these are presumably pulled from the book mentioned above, and I'm supposed to teach these): Set of Natural Numbers Set of Rational Numbers Set of Real Numbers Completeness Axiom Sequences Limit Theorems for Sequences Monotone Sequences and Cauchy Sequences Series Alternating Series and Integral Tests Continuity Properties of Continuous Functions Sequences and Series Functions Uniform Convergence Differentiation and Integration of Power Series Mean Value Theorem L’Hopital Rule Taylor Theorem Part one of Integration Part two of Integration So can someone tell me the most gentle undergraduate analysis book which would deal with these (as gently as possible)?","I will be teaching a course which expects to have the following topics pulled from a now out-of-print book: Fundamental ideas of analysis, by Michael C. Reed, John Wiley&Sons,1998 As we can't use this book, I need something comparable. The expected topics include (again these are presumably pulled from the book mentioned above, and I'm supposed to teach these): Set of Natural Numbers Set of Rational Numbers Set of Real Numbers Completeness Axiom Sequences Limit Theorems for Sequences Monotone Sequences and Cauchy Sequences Series Alternating Series and Integral Tests Continuity Properties of Continuous Functions Sequences and Series Functions Uniform Convergence Differentiation and Integration of Power Series Mean Value Theorem L’Hopital Rule Taylor Theorem Part one of Integration Part two of Integration So can someone tell me the most gentle undergraduate analysis book which would deal with these (as gently as possible)?",,"['real-analysis', 'analysis', 'book-recommendation']"
65,"$f(x)=\frac{\sin x}{x}$, prove that $|f^{(n)}(x)|\le \frac{1}{n+1}$ [duplicate]",", prove that  [duplicate]",f(x)=\frac{\sin x}{x} |f^{(n)}(x)|\le \frac{1}{n+1},"This question already has answers here : Proving that: $\forall n \in \mathbb{N} :|f^{(n)}(x)|\leq \frac{1}{n+1}$ (3 answers) Closed 4 years ago . This is a homework question. Let $f: (0, \infty) \to \mathbb{R}$ with $f(x)=\dfrac{\sin x}{x}$ . I   have to prove that $$|f^{(n)}(x)|\le \frac{1}{n+1}$$ where $f^{(n)}$ is the nth derivative of $f$ . I started to do a few derivatives: $f^{(1)}(x)=\dfrac{1}{x^2}(x \cos x-\sin x)$ $f^{(2)}(x)=\dfrac{1}{x^3}((2-x^2) \sin x-2x\cos x)$ $f^{(3)}(x)=\dfrac{1}{x^4}(3(x^2-2) \sin x-x(x^2-6)\cos x)$ $f^{(4)}(x)=\dfrac{1}{x^5}(4x(x^2-6)\cos x + (x^4-12x^2+24)\cos x)$ I noticed that in denominator, there is always $x^{n+1}$ (because there is $x$ in denominator of $f$ ), but I couldn't spot a pattern for the numerator that would help me prove the inequality. Can I get a hint or a clue, please?","This question already has answers here : Proving that: $\forall n \in \mathbb{N} :|f^{(n)}(x)|\leq \frac{1}{n+1}$ (3 answers) Closed 4 years ago . This is a homework question. Let with . I   have to prove that where is the nth derivative of . I started to do a few derivatives: I noticed that in denominator, there is always (because there is in denominator of ), but I couldn't spot a pattern for the numerator that would help me prove the inequality. Can I get a hint or a clue, please?","f: (0, \infty) \to \mathbb{R} f(x)=\dfrac{\sin x}{x} |f^{(n)}(x)|\le \frac{1}{n+1} f^{(n)} f f^{(1)}(x)=\dfrac{1}{x^2}(x \cos x-\sin x) f^{(2)}(x)=\dfrac{1}{x^3}((2-x^2) \sin x-2x\cos x) f^{(3)}(x)=\dfrac{1}{x^4}(3(x^2-2) \sin x-x(x^2-6)\cos x) f^{(4)}(x)=\dfrac{1}{x^5}(4x(x^2-6)\cos x + (x^4-12x^2+24)\cos x) x^{n+1} x f","['real-analysis', 'calculus']"
66,For a continuous function $f$ satisfying $f(f(x))=x$ has exactly one fixed point,For a continuous function  satisfying  has exactly one fixed point,f f(f(x))=x,"Let $f \colon [ 0, 1] \to [0, 1]$ be a continuous map such that    $$ f\big( f(x) \big) = x \ \mbox{ for each } x \in [0, 1], $$   and    $$ f(x) \neq x \ \mbox{ for at least one } x \in [0, 1], $$   then how to show that $f$ has exactly one fixed point in $[0, 1]$? I know (how to show) that $f$ does have at least one fixed point in $[0, 1]$. Suppose that $u \in [0, 1]$ is such that $f(u) \neq u$. Suppose further that $p, q \in [0, 1]$ satisfy $f(p) = p$ and $f(q) = q$. What next? Can we arrive at a contradiction? Of course,  $$ f\big( f(u) \big) = u, $$ so that  $$ f \big( f(u) \big) \neq f(u). $$ Context: This is Prob. 1.2 in the book An Introduction To Metric Spaces And Fixed Point Theory by Mohamed A. Khamsi and William A. Kirk.","Let $f \colon [ 0, 1] \to [0, 1]$ be a continuous map such that    $$ f\big( f(x) \big) = x \ \mbox{ for each } x \in [0, 1], $$   and    $$ f(x) \neq x \ \mbox{ for at least one } x \in [0, 1], $$   then how to show that $f$ has exactly one fixed point in $[0, 1]$? I know (how to show) that $f$ does have at least one fixed point in $[0, 1]$. Suppose that $u \in [0, 1]$ is such that $f(u) \neq u$. Suppose further that $p, q \in [0, 1]$ satisfy $f(p) = p$ and $f(q) = q$. What next? Can we arrive at a contradiction? Of course,  $$ f\big( f(u) \big) = u, $$ so that  $$ f \big( f(u) \big) \neq f(u). $$ Context: This is Prob. 1.2 in the book An Introduction To Metric Spaces And Fixed Point Theory by Mohamed A. Khamsi and William A. Kirk.",,"['real-analysis', 'analysis', 'continuity', 'fixed-point-theorems', 'fixed-points']"
67,Version of identity theorem for functions in $\mathbb{R}^n$,Version of identity theorem for functions in,\mathbb{R}^n,"How to show the following version of the identity theorem for real-analytic function in $\mathbb{R}^n$ Let $g,f: \mathbb{R}^n \to \mathbb{R}$ be two real-analytic functions.   Suppose, that $g(x)=f(x)$ on a set $E$ of positive Lebesgue measure.   Then, $f(x)=g(x)$ for all $x \in \mathbb{R}^n$. Also, providing a reference for this would great. The question was first raised here and motivated by identity theorem on open sets. Where the case of $n=1$ was also solved. It was suggested that the case of $n>1$ can be solved by using induction. However, I was not able to follow the proof. Since one can come up with a number of identity theorems for analytic function in $\mathbb{R}^n$, I was wondering if there is a good source that summarizes these result. I found one for complex analytic functions here , but I don't think it is very complete.","How to show the following version of the identity theorem for real-analytic function in $\mathbb{R}^n$ Let $g,f: \mathbb{R}^n \to \mathbb{R}$ be two real-analytic functions.   Suppose, that $g(x)=f(x)$ on a set $E$ of positive Lebesgue measure.   Then, $f(x)=g(x)$ for all $x \in \mathbb{R}^n$. Also, providing a reference for this would great. The question was first raised here and motivated by identity theorem on open sets. Where the case of $n=1$ was also solved. It was suggested that the case of $n>1$ can be solved by using induction. However, I was not able to follow the proof. Since one can come up with a number of identity theorems for analytic function in $\mathbb{R}^n$, I was wondering if there is a good source that summarizes these result. I found one for complex analytic functions here , but I don't think it is very complete.",,"['real-analysis', 'complex-analysis', 'functional-analysis']"
68,"Let $f: [0 ,1] \to \mathbb{R} $ be continuous, prove $\lim_{n\to \infty} \int_0^1 f(x^n)dx = f(0)$","Let  be continuous, prove","f: [0 ,1] \to \mathbb{R}  \lim_{n\to \infty} \int_0^1 f(x^n)dx = f(0)","Let $f: [0,1] \to \mathbb{R}$ be continuous, prove $\lim_{n\to \infty} \int_0^1 f(x^n)dx = f(0)$ This makes some sense looking at it. I have only the Regulated Integral definition of integration to work with : https://en.wikipedia.org/wiki/Regulated_integral It uses sequences of step functions with a partition over a closed interval. So I need to solve the integral prior to taking the limit but not sure how to really get what I need. Since $f $ is continuous function there exists a sequence $(\varphi_n)_{n \in \mathbb{N}}$ of step functions such that $\lim_{n \to \infty} \sup_{x \in [0,1]} \mid f(x) - \varphi_n(x)\mid \,= 0$. Moreover, $\int_0^1 f(x)dx := \lim_{m \to \infty} \int_0^1 \varphi_m(x)dx $ so it should be the case that $\int_0^1 f(x^n)dx := \lim_{m \to \infty} \int_0^1 \varphi_m(x^n)dx $ so I assume that it would be that $\lim_{n \to \infty } \int_0^1 f(x^n)dx := \lim_{n \to\infty} (\lim_{n \to \infty} \int_0^1 \varphi_m(x^n)dx )$ Now, $ \int_a^b \varphi(\eta)d\eta := \sum_{j=0}^{N}\varphi(\eta_j)(\sigma_{j+1}-\sigma_j)$ where $(\sigma_j)_{j=0}^{N+1})$ is a partition of $[a,b]$ and $\eta_{j} \in (\sigma_j,\sigma_{j+1})$ such that each block of the partition is constant so choice of $\eta_j$ is not particularly important. So should have $ lim_{n \to \infty}(lim_{m \to \infty}\int_a^b \varphi_m(\eta^n)d\eta := lim_{n \to \infty}(\lim_{m \to \infty}\sum_{j=0}^{N}\varphi_m(\eta_j^n)(\sigma_{j+1}-\sigma_j))$. This is where I get stuck.","Let $f: [0,1] \to \mathbb{R}$ be continuous, prove $\lim_{n\to \infty} \int_0^1 f(x^n)dx = f(0)$ This makes some sense looking at it. I have only the Regulated Integral definition of integration to work with : https://en.wikipedia.org/wiki/Regulated_integral It uses sequences of step functions with a partition over a closed interval. So I need to solve the integral prior to taking the limit but not sure how to really get what I need. Since $f $ is continuous function there exists a sequence $(\varphi_n)_{n \in \mathbb{N}}$ of step functions such that $\lim_{n \to \infty} \sup_{x \in [0,1]} \mid f(x) - \varphi_n(x)\mid \,= 0$. Moreover, $\int_0^1 f(x)dx := \lim_{m \to \infty} \int_0^1 \varphi_m(x)dx $ so it should be the case that $\int_0^1 f(x^n)dx := \lim_{m \to \infty} \int_0^1 \varphi_m(x^n)dx $ so I assume that it would be that $\lim_{n \to \infty } \int_0^1 f(x^n)dx := \lim_{n \to\infty} (\lim_{n \to \infty} \int_0^1 \varphi_m(x^n)dx )$ Now, $ \int_a^b \varphi(\eta)d\eta := \sum_{j=0}^{N}\varphi(\eta_j)(\sigma_{j+1}-\sigma_j)$ where $(\sigma_j)_{j=0}^{N+1})$ is a partition of $[a,b]$ and $\eta_{j} \in (\sigma_j,\sigma_{j+1})$ such that each block of the partition is constant so choice of $\eta_j$ is not particularly important. So should have $ lim_{n \to \infty}(lim_{m \to \infty}\int_a^b \varphi_m(\eta^n)d\eta := lim_{n \to \infty}(\lim_{m \to \infty}\sum_{j=0}^{N}\varphi_m(\eta_j^n)(\sigma_{j+1}-\sigma_j))$. This is where I get stuck.",,"['real-analysis', 'integration', 'analysis']"
69,Does $\sum\limits_{i=1}^{\infty}|a_i||x_i| < \infty$ whenever $\sum\limits_{i=1}^{\infty} |x_i| < \infty $ imply $(a_i)$ is bounded?,Does  whenever  imply  is bounded?,\sum\limits_{i=1}^{\infty}|a_i||x_i| < \infty \sum\limits_{i=1}^{\infty} |x_i| < \infty  (a_i),"Written with StackEdit . Suppose $(a_i)$ is a sequence in $\Bbb R$ such that $\sum\limits_{i=1}^{ \infty} |a_i||x_i| < \infty$ whenever $\sum\limits_{i=1}^{\infty} |x_i| < \infty$. Then  is $(a_i)$ a bounded sequence? Look at the end of the question for the right answer. If the statement '$(a_i)$ is a properly divergent sequence implies that there exists some $k \in \Bbb N$ such that $\sum\limits_{i=1}^{\infty} {1/{a_i}}^k$ is convergent' was true, we could have easily proven $(a_i)$ is bounded by using sub-sequences but since that is dis-proven by $ln(n)$, can we use something around it? Like can all the functions which do not satisfy the 'statement' I mentioned be considered as a special case of functions? Correct Answer - Yes, $(a_i)$ is bounded. Source - Tata Institute of Fundamental Research Graduate Studies 2013","Written with StackEdit . Suppose $(a_i)$ is a sequence in $\Bbb R$ such that $\sum\limits_{i=1}^{ \infty} |a_i||x_i| < \infty$ whenever $\sum\limits_{i=1}^{\infty} |x_i| < \infty$. Then  is $(a_i)$ a bounded sequence? Look at the end of the question for the right answer. If the statement '$(a_i)$ is a properly divergent sequence implies that there exists some $k \in \Bbb N$ such that $\sum\limits_{i=1}^{\infty} {1/{a_i}}^k$ is convergent' was true, we could have easily proven $(a_i)$ is bounded by using sub-sequences but since that is dis-proven by $ln(n)$, can we use something around it? Like can all the functions which do not satisfy the 'statement' I mentioned be considered as a special case of functions? Correct Answer - Yes, $(a_i)$ is bounded. Source - Tata Institute of Fundamental Research Graduate Studies 2013",,"['real-analysis', 'sequences-and-series', 'inequality']"
70,"Prove or disprove the existence of a measurable set 'equally' distributed in [0,1].","Prove or disprove the existence of a measurable set 'equally' distributed in [0,1].",,"Is there a measurable set E in $[0,1]$ such that for every open interval $I$ in $[0,1]$, we have $m(E\cap I)=m(I)/2$ where $m$ denotes the Lebesgue measure? Intuitively I think such a set exists and is 'equally' distributed in $[0,1]$, but I don't know how to describe more precisely this set.","Is there a measurable set E in $[0,1]$ such that for every open interval $I$ in $[0,1]$, we have $m(E\cap I)=m(I)/2$ where $m$ denotes the Lebesgue measure? Intuitively I think such a set exists and is 'equally' distributed in $[0,1]$, but I don't know how to describe more precisely this set.",,"['real-analysis', 'lebesgue-measure']"
71,Is the derivative of differentiable function $f:\mathbb{R}\to\mathbb{R}$ measurable on $\mathbb{R}$?,Is the derivative of differentiable function  measurable on ?,f:\mathbb{R}\to\mathbb{R} \mathbb{R},"Suppose we have a bounded differentiable function $f:\mathbb{R}\to[a,b]\subset\mathbb{R}$. Hence $f$ is continuous and measurable (in terms of standart Lebesgue measure) on $\mathbb{R}$. I want $f$ to have bounded measurable derivative $f'$. Derivative $f'$ doesn't have to be bounded by default, so I add additional constrain on $f$, saying that $f$ is bounded differentiable function with bounded derivative. Now do I have to explicitly postulate that $f'$ is measurable, or do I have it automatically from already mentioned conditions?","Suppose we have a bounded differentiable function $f:\mathbb{R}\to[a,b]\subset\mathbb{R}$. Hence $f$ is continuous and measurable (in terms of standart Lebesgue measure) on $\mathbb{R}$. I want $f$ to have bounded measurable derivative $f'$. Derivative $f'$ doesn't have to be bounded by default, so I add additional constrain on $f$, saying that $f$ is bounded differentiable function with bounded derivative. Now do I have to explicitly postulate that $f'$ is measurable, or do I have it automatically from already mentioned conditions?",,"['real-analysis', 'functional-analysis', 'lebesgue-measure']"
72,"How to prove that if $f$ is continuous a.e., then it is measurable.","How to prove that if  is continuous a.e., then it is measurable.",f,"Definition of simple function $f$ is said to be a simple function if $f$ can be written as $$f(\mathbf{x}) = \sum_{k=1}^{N} a_{_k} \chi_{_{E_k}}(\mathbf{x})$$ where $\{a_{_k}\}$ are distinct values for $k=1, 2, \cdots, N$ and $\chi_{_{E_k}}(\mathbf{x})=\cases{1&if $\mathbf{x}\in E_k$\\0&if $\mathbf{x}\notin E_k$}$. Theorem $(4.12)$ If $\{f_k\}$, is a sequence of measurable functions, then $\displaystyle\limsup_{k\to\infty}f_k$ and $\displaystyle\liminf_{k\to\infty}f_k$ are measurable. In particular if $\displaystyle\lim_{k\to\infty}f_k$ exists a.e., it is measurable. Theorem $(4.13)$ Every function $f$ can be written as the limit of a sequence $\{f_k\}$ of simple functions. Problem If $f(x)$, $x\in\mathbb{R}^1$, is continuous at almost every point of an interval $[a, b]$, show that $f$ is measurable on $[a, b]$. Generalize this to functions defined in $\mathbb{R}^n$. [For a constructive proof, use the subintervals of a sequence of partitions to define a sequence of simple measurable functions converging to $f$ a.e. in $[a, b]$. Use $(4.12)$.] By the theorem $(4.13)$, we can choose $\{f_k\}$, which are simple functions defined on $[a, b]$ and approaching to $f$. That is, choose $\{f_k\}$ such that, for $k=1, 2, \cdots$,  $$f_k=\sum_{i=1}^{N} a_{_i}^{(k)} \chi^{(k)}_{_{E_i}} \quad \text{and} \quad \displaystyle\lim_{k\to\infty}f_k=f$$ Since $f$ is continuous a.e., $f_k$ are measurable for all $k\in\mathbb{N}$. Then, by the theorem $(4.12)$, $f$ is measurable. Q1) Why are $f_1, f_2, \cdots, f_N$ all measurable? Q2) Morever, if $f_k$ are all measurable, then how can I ensure that $\displaystyle \lim_{k\to\infty}f_k$ exists? Is it ensured by theorem $(4.13)$? If there is any advice or other proofs, please let me know them. Thank you.","Definition of simple function $f$ is said to be a simple function if $f$ can be written as $$f(\mathbf{x}) = \sum_{k=1}^{N} a_{_k} \chi_{_{E_k}}(\mathbf{x})$$ where $\{a_{_k}\}$ are distinct values for $k=1, 2, \cdots, N$ and $\chi_{_{E_k}}(\mathbf{x})=\cases{1&if $\mathbf{x}\in E_k$\\0&if $\mathbf{x}\notin E_k$}$. Theorem $(4.12)$ If $\{f_k\}$, is a sequence of measurable functions, then $\displaystyle\limsup_{k\to\infty}f_k$ and $\displaystyle\liminf_{k\to\infty}f_k$ are measurable. In particular if $\displaystyle\lim_{k\to\infty}f_k$ exists a.e., it is measurable. Theorem $(4.13)$ Every function $f$ can be written as the limit of a sequence $\{f_k\}$ of simple functions. Problem If $f(x)$, $x\in\mathbb{R}^1$, is continuous at almost every point of an interval $[a, b]$, show that $f$ is measurable on $[a, b]$. Generalize this to functions defined in $\mathbb{R}^n$. [For a constructive proof, use the subintervals of a sequence of partitions to define a sequence of simple measurable functions converging to $f$ a.e. in $[a, b]$. Use $(4.12)$.] By the theorem $(4.13)$, we can choose $\{f_k\}$, which are simple functions defined on $[a, b]$ and approaching to $f$. That is, choose $\{f_k\}$ such that, for $k=1, 2, \cdots$,  $$f_k=\sum_{i=1}^{N} a_{_i}^{(k)} \chi^{(k)}_{_{E_i}} \quad \text{and} \quad \displaystyle\lim_{k\to\infty}f_k=f$$ Since $f$ is continuous a.e., $f_k$ are measurable for all $k\in\mathbb{N}$. Then, by the theorem $(4.12)$, $f$ is measurable. Q1) Why are $f_1, f_2, \cdots, f_N$ all measurable? Q2) Morever, if $f_k$ are all measurable, then how can I ensure that $\displaystyle \lim_{k\to\infty}f_k$ exists? Is it ensured by theorem $(4.13)$? If there is any advice or other proofs, please let me know them. Thank you.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'simple-functions']"
73,Countability of set of positive reals with bounded sum for all finite subsets,Countability of set of positive reals with bounded sum for all finite subsets,,"Consider a set $B$ of positive real numbers such that the sum of elements in any finite subset of $B$ is always less than or equal to $2$. Show that $B$ is countable. I'm trying to find a bijection between $\mathbb{N}$ and $B$ but it's not clear how I would do this. I have a feeling I should be using the fact that if you have finite subsets $S$ and $T$, the sum of elements in $S \cup T$ is also $ \leq 2$... but I don't see that going anywhere. I'd appreciate a hint, with a full solution in spoiler markdown if you can manage it.","Consider a set $B$ of positive real numbers such that the sum of elements in any finite subset of $B$ is always less than or equal to $2$. Show that $B$ is countable. I'm trying to find a bijection between $\mathbb{N}$ and $B$ but it's not clear how I would do this. I have a feeling I should be using the fact that if you have finite subsets $S$ and $T$, the sum of elements in $S \cup T$ is also $ \leq 2$... but I don't see that going anywhere. I'd appreciate a hint, with a full solution in spoiler markdown if you can manage it.",,['real-analysis']
74,Prove continuity/discontinuity of the Popcorn Function (Thomae's Function).,Prove continuity/discontinuity of the Popcorn Function (Thomae's Function).,,"I have to prove that a function $f:]0,1] \rightarrow \Bbb R$ : $$ f(x) = \begin{cases} \frac1q,  & \text{if $x \in \Bbb Q$  with $ x=\frac{p}q$ for $p,q \in \Bbb N$ coprime} \\ 0, & \text{if $x \notin \Bbb Q $} \end{cases} $$ is discontinuous in every point $x \in \ ]0,1] \cap\Bbb Q$. And then to consider $x \in \ ]0,1] \backslash \Bbb Q$ and prove that it is continuous. For now I learned different ways to prove continuity (epsilon-delta, sequences), but I'm never sure what would be better to use in each different case. I wanted to prove the discontinuity by using sequences: $$\forall x_n \quad x_n\rightarrow a \quad \Rightarrow \quad f(x_n) \rightarrow f(a)$$ I tried creating a sequence $ x_n=\frac1n + a$, we know it converges to $a$ but $f(x_n)\ $ doesn't  converges to $\ f(a)$ because there would still be some points not in our set (irrational numbers that creates gaps). But I don't think it works, so I'm asking you if you could help me solving the two questions.","I have to prove that a function $f:]0,1] \rightarrow \Bbb R$ : $$ f(x) = \begin{cases} \frac1q,  & \text{if $x \in \Bbb Q$  with $ x=\frac{p}q$ for $p,q \in \Bbb N$ coprime} \\ 0, & \text{if $x \notin \Bbb Q $} \end{cases} $$ is discontinuous in every point $x \in \ ]0,1] \cap\Bbb Q$. And then to consider $x \in \ ]0,1] \backslash \Bbb Q$ and prove that it is continuous. For now I learned different ways to prove continuity (epsilon-delta, sequences), but I'm never sure what would be better to use in each different case. I wanted to prove the discontinuity by using sequences: $$\forall x_n \quad x_n\rightarrow a \quad \Rightarrow \quad f(x_n) \rightarrow f(a)$$ I tried creating a sequence $ x_n=\frac1n + a$, we know it converges to $a$ but $f(x_n)\ $ doesn't  converges to $\ f(a)$ because there would still be some points not in our set (irrational numbers that creates gaps). But I don't think it works, so I'm asking you if you could help me solving the two questions.",,"['real-analysis', 'sequences-and-series', 'continuity']"
75,Lebesgue integration of simple functions,Lebesgue integration of simple functions,,"Define $f : [0,1] \to \Bbb R$ by $f(x) := 0$ if $x$ is rational, and   $f(x) := d^2$ if $x$ is irrational, where $d$ is the first nonzero   digit in the decimal expansion of $x$. Show that $\int_{[0,1]} f d m   = 95/3$. Here $m$ is the Lebesgue measure I know that $f$ is simple, but can someone please suggest on how to proceed with this?","Define $f : [0,1] \to \Bbb R$ by $f(x) := 0$ if $x$ is rational, and   $f(x) := d^2$ if $x$ is irrational, where $d$ is the first nonzero   digit in the decimal expansion of $x$. Show that $\int_{[0,1]} f d m   = 95/3$. Here $m$ is the Lebesgue measure I know that $f$ is simple, but can someone please suggest on how to proceed with this?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
76,does derivative of convergent function go to 0? [duplicate],does derivative of convergent function go to 0? [duplicate],,"This question already has answers here : Does the derivative of a continuous function goes to zero if the function converges to it? (2 answers) Closed 9 years ago . My question: if $f$ is differentiable and $\lim_{x \to \infty} f(x) = M$, does this imply that $\lim_{x \to \infty} f'(x) = 0$? My thinking: there exists $X$ such that $\forall x,y>X$, $|f(x)-f(y)|<\epsilon$ by the Cauchy criterion. Thus $\frac{|f(x)-f(y)|}{x-y} = f'(d)< \epsilon$ for $d$ between $x$ and $y$. I worry this won't hold if $x$ is extremely close to $y$ though.","This question already has answers here : Does the derivative of a continuous function goes to zero if the function converges to it? (2 answers) Closed 9 years ago . My question: if $f$ is differentiable and $\lim_{x \to \infty} f(x) = M$, does this imply that $\lim_{x \to \infty} f'(x) = 0$? My thinking: there exists $X$ such that $\forall x,y>X$, $|f(x)-f(y)|<\epsilon$ by the Cauchy criterion. Thus $\frac{|f(x)-f(y)|}{x-y} = f'(d)< \epsilon$ for $d$ between $x$ and $y$. I worry this won't hold if $x$ is extremely close to $y$ though.",,"['real-analysis', 'limits', 'derivatives']"
77,Test for convergence $\int_0^{\infty} \frac{\sin(x)}{x+\log(x)} \ dx$,Test for convergence,\int_0^{\infty} \frac{\sin(x)}{x+\log(x)} \ dx,What is the easiest way to test the convergence of $$\int_0^{\infty} \frac{\sin(x)}{x+\log(x)} \ dx$$ Is it possible to only use the high school tools for that?,What is the easiest way to test the convergence of $$\int_0^{\infty} \frac{\sin(x)}{x+\log(x)} \ dx$$ Is it possible to only use the high school tools for that?,,"['calculus', 'real-analysis', 'integration', 'improper-integrals']"
78,Why do the real numbers have the least upper bound property while the rationals do not?,Why do the real numbers have the least upper bound property while the rationals do not?,,"I'm fairly new to formal proof, so when I started learning about real analysis it has been a huge source of confusion to me. Not too long ago I was introduced to the least-upper-bound property, or, what my teacher calls it, the axioma de completez , meaning ""axiom of completeness"", which states ""any non-empty set of real numbers that has an upper bound must have a least upper bound in real numbers."" I know that this property somehow sets the rational numbers and the real numbers apart by making the real numbers complete, meaning there are no gaps whatsoever between any element of the set, whereas the rational numbers have gaps (which correspond to irrational numbers); but I don't understand why. To me, it just states that if there's any number that's bigger than all of those in a set (called a bound), then there must be one bound that's smaller than any of the others, called the least upper bound or supremum. Could anybody explain this to a newbie to real analysis and formal proof?","I'm fairly new to formal proof, so when I started learning about real analysis it has been a huge source of confusion to me. Not too long ago I was introduced to the least-upper-bound property, or, what my teacher calls it, the axioma de completez , meaning ""axiom of completeness"", which states ""any non-empty set of real numbers that has an upper bound must have a least upper bound in real numbers."" I know that this property somehow sets the rational numbers and the real numbers apart by making the real numbers complete, meaning there are no gaps whatsoever between any element of the set, whereas the rational numbers have gaps (which correspond to irrational numbers); but I don't understand why. To me, it just states that if there's any number that's bigger than all of those in a set (called a bound), then there must be one bound that's smaller than any of the others, called the least upper bound or supremum. Could anybody explain this to a newbie to real analysis and formal proof?",,"['real-analysis', 'algebra-precalculus']"
79,"Show that function $f$ has a continuous extension to $[a,b]$ iff $f$ is uniformly continuous on $(a,b)$",Show that function  has a continuous extension to  iff  is uniformly continuous on,"f [a,b] f (a,b)","Let $E \subset F \subset X$ and $f:E\rightarrow Y$. We say that the function $g:F\rightarrow Y$ is an extension of $f$ if $g(x) = f(x)$ for all $x \in E$. Let $f: (a, b) \rightarrow \mathbb{R}$. Show that $f$ has a continuous extension to $[a, b]$ if and only if $f$ is uniformly continuous on $(a, b)$. $(X,d)$ is a metric space. Hint: To prove $\Leftarrow$ start by showing that $f$ maps Cauchy sequences to Cauchy sequences. Then how should you define $g(a)$ and $g(b)$? The $\Rightarrow$ part of the proof was quite simple, but even with the hint, the other way seems a bit difficult. Doesn't the first part of the ""hint"" follow from the way we defined $f$? If so, how do I prove this? Help/Hints appreciated!","Let $E \subset F \subset X$ and $f:E\rightarrow Y$. We say that the function $g:F\rightarrow Y$ is an extension of $f$ if $g(x) = f(x)$ for all $x \in E$. Let $f: (a, b) \rightarrow \mathbb{R}$. Show that $f$ has a continuous extension to $[a, b]$ if and only if $f$ is uniformly continuous on $(a, b)$. $(X,d)$ is a metric space. Hint: To prove $\Leftarrow$ start by showing that $f$ maps Cauchy sequences to Cauchy sequences. Then how should you define $g(a)$ and $g(b)$? The $\Rightarrow$ part of the proof was quite simple, but even with the hint, the other way seems a bit difficult. Doesn't the first part of the ""hint"" follow from the way we defined $f$? If so, how do I prove this? Help/Hints appreciated!",,"['real-analysis', 'continuity', 'uniform-continuity', 'cauchy-sequences']"
80,Singular values of square orthogonal matrix?,Singular values of square orthogonal matrix?,,What are the singular values of an $n \times n$ square orthogonal matrix?  How do we know that the set of all orthogonal matrices is convex? Is there an example?,What are the singular values of an $n \times n$ square orthogonal matrix?  How do we know that the set of all orthogonal matrices is convex? Is there an example?,,"['real-analysis', 'matrices']"
81,Uniform continuity of $\ln(x)$,Uniform continuity of,\ln(x),"Is $f(x)=\ln(x)$ uniformly continuous on $(1,+\infty)$? If so, how to show it? I know how to show that it is not uniformly continuous on $(0,1)$, by taking $x=\frac{1}{\exp(n)}$ and $y = \frac{1}{\exp(n+1)}$. Also, on which interval does $\ln(x)$ satisfy the Lipschitz condition?","Is $f(x)=\ln(x)$ uniformly continuous on $(1,+\infty)$? If so, how to show it? I know how to show that it is not uniformly continuous on $(0,1)$, by taking $x=\frac{1}{\exp(n)}$ and $y = \frac{1}{\exp(n+1)}$. Also, on which interval does $\ln(x)$ satisfy the Lipschitz condition?",,"['real-analysis', 'continuity']"
82,limit of an integral of a sequence of functions,limit of an integral of a sequence of functions,,"Suppose that $f$ is continuous on $[0,1]$. ($f'(x)$ may or may not exist). How can I show that $$\lim_{n\rightarrow\infty} \int\limits_0^1 \frac{nf(x)}{1+n^2x^2} dx = \frac{\pi}{2}f(0)\;?$$ My attempt was to recognize that $\int_0^1\frac{n}{1+n^2x^2}dx=\tan^{-1}(nx)$. But I can't simply use integration by parts on the original integral as $f'(x)$ might not exist. Any hints on how to solve this? Help much appreciated...","Suppose that $f$ is continuous on $[0,1]$. ($f'(x)$ may or may not exist). How can I show that $$\lim_{n\rightarrow\infty} \int\limits_0^1 \frac{nf(x)}{1+n^2x^2} dx = \frac{\pi}{2}f(0)\;?$$ My attempt was to recognize that $\int_0^1\frac{n}{1+n^2x^2}dx=\tan^{-1}(nx)$. But I can't simply use integration by parts on the original integral as $f'(x)$ might not exist. Any hints on how to solve this? Help much appreciated...",,"['real-analysis', 'sequences-and-series', 'analysis', 'integration']"
83,"Good metric on $C^k(0,1)$ and $C^\infty(0,1)$",Good metric on  and,"C^k(0,1) C^\infty(0,1)","What would be a good metric on $C^k(0,1)$, space of $k$ times continuously differentiable real valued functions on $(0,1)$ and $C^\infty(0,1)$, space of infinitely differentiable real valued functions on $(0,1)$? It is of course open to interpretation what good would mean, I want it to bring a good notion of convergence and unitize the openness of the interval as well as the $k$ times/infinite continuously differentiable property. This is a question that I want to think more about to understand metric spaces better. Thank you. EDIT: And what changes if it is on $[0,1]$?","What would be a good metric on $C^k(0,1)$, space of $k$ times continuously differentiable real valued functions on $(0,1)$ and $C^\infty(0,1)$, space of infinitely differentiable real valued functions on $(0,1)$? It is of course open to interpretation what good would mean, I want it to bring a good notion of convergence and unitize the openness of the interval as well as the $k$ times/infinite continuously differentiable property. This is a question that I want to think more about to understand metric spaces better. Thank you. EDIT: And what changes if it is on $[0,1]$?",,"['real-analysis', 'general-topology', 'metric-spaces']"
84,Compute the limit of $\sum\limits_{k=1}^{n} \left(\frac{k}{n^2}\right)^{1+k/n^2}$ when $n\to\infty$,Compute the limit of  when,\sum\limits_{k=1}^{n} \left(\frac{k}{n^2}\right)^{1+k/n^2} n\to\infty,"Compute the limit   $$\lim_{n\to\infty} \sum_{k=1}^{n} \left(\frac{k}{n^2}\right)^{\frac{k}{n^2} + 1}$$ At a first look, I only thought of Riemann sums, but I don't see how I may apply it. What else could I do? I need some hints, suggestions.","Compute the limit   $$\lim_{n\to\infty} \sum_{k=1}^{n} \left(\frac{k}{n^2}\right)^{\frac{k}{n^2} + 1}$$ At a first look, I only thought of Riemann sums, but I don't see how I may apply it. What else could I do? I need some hints, suggestions.",,"['real-analysis', 'sequences-and-series', 'limits']"
85,Convergence of $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$?,Convergence of ?,\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}},"I need to prove the convergence/divergence of the series $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$ based on the convergence/divergence of the series $\sum_{n=1}^{\infty }a_{n}$. It is given that $a_{n}> 0$, $\forall n\in \mathbb{N}$ If the series $\sum_{n=1}^{\infty }a_{n}$ is convergent, then from $\frac{a_{n}}{1+na_{n}}< a_{n}$ and the comparison test, we conclude that $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$ is convergent. However, if the series $\sum_{n=1}^{\infty }a_{n}$ is divergent, I have no idea how to prove the convergence/divergence of $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$. It is definitely divergent (just take $a_{n}=\frac{1}{n}$), but I have no clue how to prove it.","I need to prove the convergence/divergence of the series $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$ based on the convergence/divergence of the series $\sum_{n=1}^{\infty }a_{n}$. It is given that $a_{n}> 0$, $\forall n\in \mathbb{N}$ If the series $\sum_{n=1}^{\infty }a_{n}$ is convergent, then from $\frac{a_{n}}{1+na_{n}}< a_{n}$ and the comparison test, we conclude that $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$ is convergent. However, if the series $\sum_{n=1}^{\infty }a_{n}$ is divergent, I have no idea how to prove the convergence/divergence of $\sum_{n=1}^{\infty }\frac{a_{n}}{1+na_{n}}$. It is definitely divergent (just take $a_{n}=\frac{1}{n}$), but I have no clue how to prove it.",,"['calculus', 'real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence']"
86,"Show that $\int f=0$ implies $f=0$ a.e, given that $f$ is a nonnegative measurable function.","Show that  implies  a.e, given that  is a nonnegative measurable function.",\int f=0 f=0 f,"I am trying to show that $\int f=0$ implies $f=0$ a.e, given that $f$ is a nonnegative measurable function. But I search my head from what I have learn I have no any clue of solving the problem. That is why I brought it to this room with the hope that somebody will give me a hint. Thanks","I am trying to show that $\int f=0$ implies $f=0$ a.e, given that $f$ is a nonnegative measurable function. But I search my head from what I have learn I have no any clue of solving the problem. That is why I brought it to this room with the hope that somebody will give me a hint. Thanks",,"['real-analysis', 'measure-theory']"
87,The Class of Non-empty Compact Subsets of a Compact Metric Space is Compact,The Class of Non-empty Compact Subsets of a Compact Metric Space is Compact,,"This is a question from my homework for a real analysis course. Please hint only. Let $M$ be a compact metric space. Let $\mathbb{K}$ be the class of non-empty compact subsets of $M$. The $r$-neighbourhood of $A \in \mathbb{K}$ is $$ M_r A = \lbrace x \in M : \exists a \in A \text{ and } d(x,a) < r \rbrace = \bigcup_{a \in A} M_r a. $$ For $A$, $B \in \mathbb{K}$ define $$D(A,B) = \inf \lbrace r > 0 : A \subset M_r B \text{ and } B \subset M_r A \rbrace. $$ Show that $\mathbb{K}$ is compact. (Another part of the question is that if $M$ is connected, then so is $\mathbb{K}$, but this is not assigned). Many thanks.","This is a question from my homework for a real analysis course. Please hint only. Let $M$ be a compact metric space. Let $\mathbb{K}$ be the class of non-empty compact subsets of $M$. The $r$-neighbourhood of $A \in \mathbb{K}$ is $$ M_r A = \lbrace x \in M : \exists a \in A \text{ and } d(x,a) < r \rbrace = \bigcup_{a \in A} M_r a. $$ For $A$, $B \in \mathbb{K}$ define $$D(A,B) = \inf \lbrace r > 0 : A \subset M_r B \text{ and } B \subset M_r A \rbrace. $$ Show that $\mathbb{K}$ is compact. (Another part of the question is that if $M$ is connected, then so is $\mathbb{K}$, but this is not assigned). Many thanks.",,"['real-analysis', 'metric-spaces']"
88,Calculating pretty difficult limit that invloves Riemann sums,Calculating pretty difficult limit that invloves Riemann sums,,"Let $S_n = \sum_{k=1}^n\frac{1}{\sqrt{n^2+k^2}}$ . Calculate the following limit $$\lim_{n \to \infty} n\left(n\Big(\ln(1+\sqrt{2})-S_n\Big)-\frac{1}{2\sqrt{2}\,(1+\sqrt{2})}\right).$$ My intuition says that every from of $n$ times a parentheses in a form of $0 \cdot \infty$ otherwise the problem would be trivial. So let's first calculate the inner most bracket, $\ln(1+\sqrt{2})-S_n$ . Firstly, we notice that $S_n$ is a Riemann sum. Take $f(x)=\frac{1}{\sqrt{1+x^2}}$ . Now $S_n = \sum_{k=0}^n\frac{1}{\sqrt{n^2+k^2}}=\sum_{k=0}^n\frac{1}{n}f(\frac{k}{n})$ which is the Riemann sum for $\int_0^1f(x)dx=\text{arcsinh}(x) \vert_0^1=\ln(1+\sqrt{2})$ . Now $\ln(1+\sqrt{2})-S_n$ is the difference between the area under the curve and the riemann sum. Now trying to calculate $n(\ln(1+\sqrt{2})-S_n)=\frac{\ln(1+\sqrt{2})-S_n}{\frac{1}{n}}=^{\text{Stolz-Cesaro}}=n(n+1)(S_n-S_{n+1})$ . But I am stuck here. How should I continue? $S_n-S_{n+1}$ does not look like a nice Riemann sum, and I have no idea how to actually compute it. Any tips would be gladly appreciated.","Let . Calculate the following limit My intuition says that every from of times a parentheses in a form of otherwise the problem would be trivial. So let's first calculate the inner most bracket, . Firstly, we notice that is a Riemann sum. Take . Now which is the Riemann sum for . Now is the difference between the area under the curve and the riemann sum. Now trying to calculate . But I am stuck here. How should I continue? does not look like a nice Riemann sum, and I have no idea how to actually compute it. Any tips would be gladly appreciated.","S_n = \sum_{k=1}^n\frac{1}{\sqrt{n^2+k^2}} \lim_{n \to \infty} n\left(n\Big(\ln(1+\sqrt{2})-S_n\Big)-\frac{1}{2\sqrt{2}\,(1+\sqrt{2})}\right). n 0 \cdot \infty \ln(1+\sqrt{2})-S_n S_n f(x)=\frac{1}{\sqrt{1+x^2}} S_n = \sum_{k=0}^n\frac{1}{\sqrt{n^2+k^2}}=\sum_{k=0}^n\frac{1}{n}f(\frac{k}{n}) \int_0^1f(x)dx=\text{arcsinh}(x) \vert_0^1=\ln(1+\sqrt{2}) \ln(1+\sqrt{2})-S_n n(\ln(1+\sqrt{2})-S_n)=\frac{\ln(1+\sqrt{2})-S_n}{\frac{1}{n}}=^{\text{Stolz-Cesaro}}=n(n+1)(S_n-S_{n+1}) S_n-S_{n+1}","['real-analysis', 'integration', 'limits', 'analysis', 'riemann-sum']"
89,Find $f(x)$ such that it maximizes $\int_0^1 \left(f(f(x))-f(x)\right) dx$,Find  such that it maximizes,f(x) \int_0^1 \left(f(f(x))-f(x)\right) dx,"Inspired by this post Find the maximun of the sum $\sum_{k=1}^{n}(f(f(k))-f(k))$ , I came to the below question. Find the $f(x)$ that satisfies: $1.$ $0\le f(x)\le 1$ $2.$ Increasing for $\left(0,1\right)$ $3.$ Maximizes $\quad\int_0^1 \left(f(f(x))-f(x)\right) dx$ After I tried a few elementary functions, now I am feeling that there might not be an analytic solution for the $f(x)$ (but I'm not sure). If that's the case, can we at least know the maximum of the integral? I posted this question because the original discrete version of the question didn't seem to have a clear solution I was wondering if this continuous version of the question has any analytic solution. The accepted answer suggests that the solution could be the piecewise linear function. However, there's no clear proof or reasoning why that should be the optimal case. What I've tried was: $1$ . I started from $f(x)=\frac{x+1}2$ as it was assumed in the original question I likned above. $2$ . I tried a few elementary functions such as $f(x)=x^p$ , and then $f(x)=m\ln\left(\frac{x+a}{1+a}\right)+1$ , and two terms, etc. (assumed $f(1)$ should be $1$ to maximize the integral) and could see that the integral kept increasing for more variables, so I thought there must be an optimum (but differentiable) $f(x)$ and that it might not be an analytically obtained due to $f(f(x))$ . At that time I didn't know that I was only approaching to the step function. Thanks for all the comments and the answers. Now I can see that the solution is probably the piecewise step function in the answer, so this question may not be as interesting as I thought. However, I think that we are still missing the proof that it is the optimal $f(x)$ .","Inspired by this post Find the maximun of the sum , I came to the below question. Find the that satisfies: Increasing for Maximizes After I tried a few elementary functions, now I am feeling that there might not be an analytic solution for the (but I'm not sure). If that's the case, can we at least know the maximum of the integral? I posted this question because the original discrete version of the question didn't seem to have a clear solution I was wondering if this continuous version of the question has any analytic solution. The accepted answer suggests that the solution could be the piecewise linear function. However, there's no clear proof or reasoning why that should be the optimal case. What I've tried was: . I started from as it was assumed in the original question I likned above. . I tried a few elementary functions such as , and then , and two terms, etc. (assumed should be to maximize the integral) and could see that the integral kept increasing for more variables, so I thought there must be an optimum (but differentiable) and that it might not be an analytically obtained due to . At that time I didn't know that I was only approaching to the step function. Thanks for all the comments and the answers. Now I can see that the solution is probably the piecewise step function in the answer, so this question may not be as interesting as I thought. However, I think that we are still missing the proof that it is the optimal .","\sum_{k=1}^{n}(f(f(k))-f(k)) f(x) 1. 0\le f(x)\le 1 2. \left(0,1\right) 3. \quad\int_0^1 \left(f(f(x))-f(x)\right) dx f(x) 1 f(x)=\frac{x+1}2 2 f(x)=x^p f(x)=m\ln\left(\frac{x+a}{1+a}\right)+1 f(1) 1 f(x) f(f(x)) f(x)","['real-analysis', 'optimization', 'definite-integrals']"
90,Can we find $ \lim_{n \to \infty } n\left ( \frac{1}{n} - \frac{1}{n+1} + \frac{1}{n+2} - \frac{1}{n+3} + ... \right ) $?,Can we find ?, \lim_{n \to \infty } n\left ( \frac{1}{n} - \frac{1}{n+1} + \frac{1}{n+2} - \frac{1}{n+3} + ... \right ) ,"I have got one method, If we consider $ a_{n} = \int_{0}^{1} \frac{nx^{n-1}}{1+x} \ dx $ Then, $ \lim_{n \to \infty } n\left ( \frac{1}{n} - \frac{1}{n+1} + \frac{1}{n+2} - \frac{1}{n+3} + ... \right ) = \lim_{n \to \infty }a_{n} = \frac{1}{2} $ But can anyone attack this problem in a different & more standard way?","I have got one method, If we consider Then, But can anyone attack this problem in a different & more standard way?", a_{n} = \int_{0}^{1} \frac{nx^{n-1}}{1+x} \ dx   \lim_{n \to \infty } n\left ( \frac{1}{n} - \frac{1}{n+1} + \frac{1}{n+2} - \frac{1}{n+3} + ... \right ) = \lim_{n \to \infty }a_{n} = \frac{1}{2} ,"['real-analysis', 'sequences-and-series']"
91,"Show that there exists $c\in[a,b]$ such that $f(c)=0$.",Show that there exists  such that .,"c\in[a,b] f(c)=0","Question: Let $f:[a,b]\to\mathbb{R}$ be a continuous function with the property that for every $x\in[a,b]$ , there exists $y\in[a,b]$ such that $|f(y)|\le\frac{1}{2}|f(x)|$ . Show that there exists $c\in[a,b]$ such that $f(c)=0$ . Solution: Select any $x\in [a,b].$ Let $x=x_1$ . Now by our hypothesis there exists $x_2\in [a,b]$ such that $|f(x_2)|\le \frac{1}{2}|f(x_1)|.$ Again by our hypothesis there exists $x_3\in[a,b]$ such that $|f(x_3)|\le \frac{1}{2}|f(x_2)|\le \frac{1}{4}|f(x_1)|.$ Continuing like this we will end up having a sequence $(x_n)_{n\ge 1}$ such that $$|f(x_n)|\le \frac{1}{2^{n-1}}|f(x_1)|, \forall n\in\mathbb{N}.$$ Notice that this implies that $$-\frac{1}{2^{n-1}}|f(x_1)|\le f(x_n)\le \frac{1}{2^{n-1}}|f(x_1)|, \forall n\in\mathbb{N}.$$ Thus by Sandwich theorem we can conclude that the sequence $f(x_n)$ is convergent and it converges to $0$ . Next notice that the sequence $(x_n)_{n\ge 1}$ is bounded. Thus, by Bolzano-Weierstrass theorem we can conclude that $(x_n)_{n\ge 1}$ has a convergent subsequence $(x_{n_k})_{k\ge 1}$ . Let us assume that $(x_{n_k})_{k\ge 1}$ converges to $c$ . Note that $a\le c\le b$ . Now since $f$ is continuous on $[a,b]$ , implies that $f$ is continuous at $c$ . Thus by the sequential definition of limit we can conclude that $f(x_{n_k})$ converges to $f(c)$ . Now note that we have already shown that the sequence $f(x_n)$ converges to $0$ , which implies that the subsequence $f(x_{n_k})$ also converges to $0$ . This implies that $f(c)=0.$ This completes the proof. It is also easy to see that if the inequality $|f(y)|\le \frac{1}{2}|f(x)|$ was replaced by the inequality $|f(y)|\le \lambda |f(x)|$ where $|\lambda|<1$ is arbitrary then also the statement in the question holds true. Is this solution correct and rigorous enough and is there any other way to solve this problem?","Question: Let be a continuous function with the property that for every , there exists such that . Show that there exists such that . Solution: Select any Let . Now by our hypothesis there exists such that Again by our hypothesis there exists such that Continuing like this we will end up having a sequence such that Notice that this implies that Thus by Sandwich theorem we can conclude that the sequence is convergent and it converges to . Next notice that the sequence is bounded. Thus, by Bolzano-Weierstrass theorem we can conclude that has a convergent subsequence . Let us assume that converges to . Note that . Now since is continuous on , implies that is continuous at . Thus by the sequential definition of limit we can conclude that converges to . Now note that we have already shown that the sequence converges to , which implies that the subsequence also converges to . This implies that This completes the proof. It is also easy to see that if the inequality was replaced by the inequality where is arbitrary then also the statement in the question holds true. Is this solution correct and rigorous enough and is there any other way to solve this problem?","f:[a,b]\to\mathbb{R} x\in[a,b] y\in[a,b] |f(y)|\le\frac{1}{2}|f(x)| c\in[a,b] f(c)=0 x\in [a,b]. x=x_1 x_2\in [a,b] |f(x_2)|\le \frac{1}{2}|f(x_1)|. x_3\in[a,b] |f(x_3)|\le \frac{1}{2}|f(x_2)|\le \frac{1}{4}|f(x_1)|. (x_n)_{n\ge 1} |f(x_n)|\le \frac{1}{2^{n-1}}|f(x_1)|, \forall n\in\mathbb{N}. -\frac{1}{2^{n-1}}|f(x_1)|\le f(x_n)\le \frac{1}{2^{n-1}}|f(x_1)|, \forall n\in\mathbb{N}. f(x_n) 0 (x_n)_{n\ge 1} (x_n)_{n\ge 1} (x_{n_k})_{k\ge 1} (x_{n_k})_{k\ge 1} c a\le c\le b f [a,b] f c f(x_{n_k}) f(c) f(x_n) 0 f(x_{n_k}) 0 f(c)=0. |f(y)|\le \frac{1}{2}|f(x)| |f(y)|\le \lambda |f(x)| |\lambda|<1","['real-analysis', 'sequences-and-series', 'solution-verification']"
92,Series that evaluates to different values,Series that evaluates to different values,,"I am trying to find a sequence $x_{pq}$ such that $\sum_{p=1}^\infty\sum_{q=1}^\infty x_{pq}$ and $\sum_{q=1}^\infty\sum_{p=1}^\infty x_{pq}$ both exist and evaluate to different values. I am thinking of this as a matrix, but I can't seem to see how adding all the elements of it column wise vs row-wise would change the total sum? Any hints/examples would be helpful.","I am trying to find a sequence such that and both exist and evaluate to different values. I am thinking of this as a matrix, but I can't seem to see how adding all the elements of it column wise vs row-wise would change the total sum? Any hints/examples would be helpful.",x_{pq} \sum_{p=1}^\infty\sum_{q=1}^\infty x_{pq} \sum_{q=1}^\infty\sum_{p=1}^\infty x_{pq},['real-analysis']
93,$\mu$ is $\sigma$-finite $\iff \exists$ function $f \in \mathcal{L}^{1}(\mu)$ with $f(x)>0$ for all $x \in X$,is -finite  function  with  for all,\mu \sigma \iff \exists f \in \mathcal{L}^{1}(\mu) f(x)>0 x \in X,"Let $(X,\mathcal{A}, \mu)$ be a measure space. Prove: $\mu$ is $\sigma$ -finite $\iff \exists$ function $f \in \mathcal{L}^{1}(\mu)$ with $f(x)>0$ for all $x \in X$ My ideas $""\Leftarrow""$ Let $f \in \mathcal{L}^{1}(\mu)$ with $f(x)>0$ , $\forall x \in X$ . So, $f$ is measurable. This implies that for a $B_{n}$ defined as $B_{n}:=\{f>\frac{1}{n}\}$ which is measurable, so $\in \mathcal{A}$ . By definition, $\{f>0\}=\bigcup_{n\in \mathbb N}B_{n}\in \mathcal{A}$ , but since $f > 0, \forall x \in X$ then $X\subseteq\bigcup_{n\in \mathbb N}B_{n}$ and $\mu(B_{n})<\infty, \forall n \in \mathbb N$ , since $\int_{X}fd\mu < \infty$$\Rightarrow \mu$ is $\sigma-$ finite. $""\Rightarrow""$ I have no idea how to define this function, particularly as $f>0$ , $\forall x \in X$","Let be a measure space. Prove: is -finite function with for all My ideas Let with , . So, is measurable. This implies that for a defined as which is measurable, so . By definition, , but since then and , since is finite. I have no idea how to define this function, particularly as ,","(X,\mathcal{A}, \mu) \mu \sigma \iff \exists f \in \mathcal{L}^{1}(\mu) f(x)>0 x \in X ""\Leftarrow"" f \in \mathcal{L}^{1}(\mu) f(x)>0 \forall x \in X f B_{n} B_{n}:=\{f>\frac{1}{n}\} \in \mathcal{A} \{f>0\}=\bigcup_{n\in \mathbb N}B_{n}\in \mathcal{A} f > 0, \forall x \in X X\subseteq\bigcup_{n\in \mathbb N}B_{n} \mu(B_{n})<\infty, \forall n \in \mathbb N \int_{X}fd\mu < \infty\Rightarrow \mu \sigma- ""\Rightarrow"" f>0 \forall x \in X","['real-analysis', 'integration', 'measure-theory']"
94,"Prove that $(C^1[0,1], \|\cdot\|)$ is not a Banach space",Prove that  is not a Banach space,"(C^1[0,1], \|\cdot\|)","Given the normed space $C^1[0,1]$ of differentiable functions with continuous derivatives on $[0,1]$ . The norm is defined as $$\|x\| = \max_{[0,1]} |x(t)|$$ I'd like to prove that the given normed space is not a Banach space. In the attempt of solving this problem, I have thought about the possibility to construct a Cauchy sequence in the space which doesn't converge in the space. However until now I haven't got any idea. Then I proceeded to think about constructing an equivalent norm to the given one where the space can be easily proven to be not a Banach space. However, I have got nothing either. Now I'm stuck without a clue. Please give me a hint to a correct direction. Any help is greatly appreciated.","Given the normed space of differentiable functions with continuous derivatives on . The norm is defined as I'd like to prove that the given normed space is not a Banach space. In the attempt of solving this problem, I have thought about the possibility to construct a Cauchy sequence in the space which doesn't converge in the space. However until now I haven't got any idea. Then I proceeded to think about constructing an equivalent norm to the given one where the space can be easily proven to be not a Banach space. However, I have got nothing either. Now I'm stuck without a clue. Please give me a hint to a correct direction. Any help is greatly appreciated.","C^1[0,1] [0,1] \|x\| = \max_{[0,1]} |x(t)|","['real-analysis', 'functional-analysis', 'banach-spaces', 'normed-spaces']"
95,What's the derivative of: $ \sqrt{x+\sqrt{{x}+\sqrt{x+\cdots}}}$?,What's the derivative of: ?, \sqrt{x+\sqrt{{x}+\sqrt{x+\cdots}}},"let $ y=\displaystyle \sqrt{x+\sqrt{{x}+\sqrt{x+\cdots}}}$, i'm really interesting to know how do I find : $\displaystyle \frac{dy}{dx}$ ?. Note: I have used the definition of derivative of the square root function but i don't succed . Thank you for any help","let $ y=\displaystyle \sqrt{x+\sqrt{{x}+\sqrt{x+\cdots}}}$, i'm really interesting to know how do I find : $\displaystyle \frac{dy}{dx}$ ?. Note: I have used the definition of derivative of the square root function but i don't succed . Thank you for any help",,"['real-analysis', 'functions', 'derivatives', 'nested-radicals']"
96,What does $dx$ mean in a Lebesgue integral?,What does  mean in a Lebesgue integral?,dx,"This is an introduction for Lebesgue integral of simple function in Carothers' Real Analysis . We say that a simple function $\phi$ is Lebesgue integrable if the set { $\phi$ $\ne$ 0} has finite measure. In this case, we may write the standard representation for $\phi$ as $\phi = \sum_{i=0}^{n} a_i \chi_{A_i}$ , where $a_0 = 0, a_1, .., a_n$ are distinct real numbers, where $A_0 = \{\phi = 0\}, A_1, ..., A_n$ are pairwise disjoint and measurable, and where only $A_0$ has infinite measure, Once $\phi$ is so written, there is an obvious definition for $\int \phi$ , namely, $$\int \phi = \int_{\mathbb R} \phi = \int_{-\infty}^{+\infty} \phi(x) dx = \sum_{i=1}^{n} a_i m(A_i)$$ . I've noticed that wikipedia's definition of Lebesgue integral(see here https://en.wikipedia.org/wiki/Lebesgue_integration ) uses $d\mu$ . So What does $dx$ or $d\mu$ mean in Lebesgue integral? Update: I don't think it is a exactly duplicate one coz I didn't mean using $d\mu$ instead of $dx$ . Before my typing this question, I have read Rodyen's Real Analysis, 3rd and he also uses $dx$ in Lebesgue integral as well. $d\mu$ is just from wikipedia. I have this question in this May when I was reading Caorthers' book and during that time, I treated it as a whole of symbols and being equal to a fixed formula -- $\sum_{i=1}^{n}a_i m(A_i)$ . And then when I was trying to solve some problems with this symbol in Lebesgue integral, I felt weird for quite a while, recalling the Riemann's definition and then realized ""ohhh, man, it is not Riemann integral"".","This is an introduction for Lebesgue integral of simple function in Carothers' Real Analysis . We say that a simple function is Lebesgue integrable if the set { 0} has finite measure. In this case, we may write the standard representation for as , where are distinct real numbers, where are pairwise disjoint and measurable, and where only has infinite measure, Once is so written, there is an obvious definition for , namely, . I've noticed that wikipedia's definition of Lebesgue integral(see here https://en.wikipedia.org/wiki/Lebesgue_integration ) uses . So What does or mean in Lebesgue integral? Update: I don't think it is a exactly duplicate one coz I didn't mean using instead of . Before my typing this question, I have read Rodyen's Real Analysis, 3rd and he also uses in Lebesgue integral as well. is just from wikipedia. I have this question in this May when I was reading Caorthers' book and during that time, I treated it as a whole of symbols and being equal to a fixed formula -- . And then when I was trying to solve some problems with this symbol in Lebesgue integral, I felt weird for quite a while, recalling the Riemann's definition and then realized ""ohhh, man, it is not Riemann integral"".","\phi \phi \ne \phi \phi = \sum_{i=0}^{n} a_i \chi_{A_i} a_0 = 0, a_1, .., a_n A_0 = \{\phi = 0\}, A_1, ..., A_n A_0 \phi \int \phi \int \phi = \int_{\mathbb R} \phi = \int_{-\infty}^{+\infty} \phi(x) dx = \sum_{i=1}^{n} a_i m(A_i) d\mu dx d\mu d\mu dx dx d\mu \sum_{i=1}^{n}a_i m(A_i)","['real-analysis', 'lebesgue-integral']"
97,Does positive definite Hessian imply the Jacobian is injective?,Does positive definite Hessian imply the Jacobian is injective?,,"Suppose $f(x):\mathbb{R}^n \mapsto \mathbb{R}$ is an infinitely differentiable function. If $\nabla^2 f(x)$, the hessian of $f$ is positive definite everywhere, does this imply that the gradient(first order derivative) $\nabla f:x\mapsto \nabla f(x)$ from $\mathbb{R}^n$ to $\mathbb{R}^n$ is injective? It is the case for $n=1$ but not sure if it is the case for general $n$. I have tried to prove thinking along the inverse function theorem. But that one is local while I need a global property. Maybe there is a simple counter example I have not seen.","Suppose $f(x):\mathbb{R}^n \mapsto \mathbb{R}$ is an infinitely differentiable function. If $\nabla^2 f(x)$, the hessian of $f$ is positive definite everywhere, does this imply that the gradient(first order derivative) $\nabla f:x\mapsto \nabla f(x)$ from $\mathbb{R}^n$ to $\mathbb{R}^n$ is injective? It is the case for $n=1$ but not sure if it is the case for general $n$. I have tried to prove thinking along the inverse function theorem. But that one is local while I need a global property. Maybe there is a simple counter example I have not seen.",,"['real-analysis', 'multivariable-calculus', 'differential-geometry']"
98,What are functions in the Sobolev space $H_0^m(\Omega)$?,What are functions in the Sobolev space ?,H_0^m(\Omega),"Let $\Omega \subset \mathbb{R}^n$ be open, then $H_0^m(\Omega) := \overline{C^{\infty}_c(\Omega)}$ with respect to the Sobolev norm $\|\|_{H^m(\Omega)}$. The problem is that I don't really see what kind of functions are in this space. Apparently for $m=0$ we just have $H_0^0 (\Omega)=L^2(\Omega).$ Despite, from the definition I don't see a defining property for all the functions in $H_0^m$?- I mean it is intuitively clear to me what $H^m$ is (weakly differentiable functions that are square integrable in every derivative) , but this closure definition is pretty unclear to me in the sense that I don't understand what these functions have in common. What is so special about this space? In particular, what is the difference between $H^m(\Omega)$ and $H_0^m(\Omega)$? It looks to me as if they are quite often the same, as $C_c^{\infty}$ should be dense in $H^m$","Let $\Omega \subset \mathbb{R}^n$ be open, then $H_0^m(\Omega) := \overline{C^{\infty}_c(\Omega)}$ with respect to the Sobolev norm $\|\|_{H^m(\Omega)}$. The problem is that I don't really see what kind of functions are in this space. Apparently for $m=0$ we just have $H_0^0 (\Omega)=L^2(\Omega).$ Despite, from the definition I don't see a defining property for all the functions in $H_0^m$?- I mean it is intuitively clear to me what $H^m$ is (weakly differentiable functions that are square integrable in every derivative) , but this closure definition is pretty unclear to me in the sense that I don't understand what these functions have in common. What is so special about this space? In particular, what is the difference between $H^m(\Omega)$ and $H_0^m(\Omega)$? It looks to me as if they are quite often the same, as $C_c^{\infty}$ should be dense in $H^m$",,"['real-analysis', 'functional-analysis', 'partial-differential-equations']"
99,Prove that an infinite sigma algebra contains an infinite sequence of disjoint sets and is uncountable,Prove that an infinite sigma algebra contains an infinite sequence of disjoint sets and is uncountable,,"The following question is from Folland Real Analysis, chapter 1 problem 3. Let $\mathcal{M}$ be an infinite $\sigma$ -algebra.  Prove that a. $\mathcal{M}$ contains an infinite sequence of disjoint sets. b. $\text{card}(\mathcal{M}) \ge \mathfrak{c}$ . This is the problem I'm totally stuck at. First, I think there is a missing condition in (a). For (a) to be meaningful, (a) should be corrected : ""M contains an infinite collection of disjoint and nonempty sets."" But I can't find a way to construct such a collection of sets. Could anyone show me how to solve it?","The following question is from Folland Real Analysis, chapter 1 problem 3. Let be an infinite -algebra.  Prove that a. contains an infinite sequence of disjoint sets. b. . This is the problem I'm totally stuck at. First, I think there is a missing condition in (a). For (a) to be meaningful, (a) should be corrected : ""M contains an infinite collection of disjoint and nonempty sets."" But I can't find a way to construct such a collection of sets. Could anyone show me how to solve it?",\mathcal{M} \sigma \mathcal{M} \text{card}(\mathcal{M}) \ge \mathfrak{c},"['real-analysis', 'measure-theory']"
