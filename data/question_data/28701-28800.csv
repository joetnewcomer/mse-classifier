,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Smallest constant $C$ to bound $\mathbb{E}[\tfrac{1}{\overline{X}_n + 1}] \leq C~\tfrac{1}{\mathbb{E}[X] + 1}$?,Smallest constant  to bound ?,C \mathbb{E}[\tfrac{1}{\overline{X}_n + 1}] \leq C~\tfrac{1}{\mathbb{E}[X] + 1},"Let $X_1, \dots, X_n$ be random real-valued random variables in the interval $[0, a]$ . Assume they are independently and identically distributed. Let $\mu = \mathbb{E}[X_i]$ denote their common mean. Define their average $\overline{X}_{n} = n^{-1} S_n$ where $S_n = \sum_{i=1}^n X_i$ . Let $f(t) := (t + 1)^{-1}$ . Question: What is the smallest constant $C = C(a, n) \geq 1$ such that we have $$ \mathbb{E}[f(\overline{X}_n)] \leq C~f(\mu)? $$ It should be emphasized that the constant $C$ is universal: it is valid for any law of $X_i$ , supported on $[0, a]$ . It should be dependent only on $a, n$ . Comments: Necessarily $C \geq 1$ . Note that by Jensen's inequality, we have the following inequality, $ \mathbb{E}[f(\overline{X}_n)] \geq f(\mu),  $ since $f$ is a convex function on the nonnegative reals. Additionally, I claim that $C \leq 1 + \tfrac{a}{n}$ . I have a proof of this below. (I would also be interested if there is a simpler way to establish this. I tried, thinking I could possibly improve the constant, to obtain it by Taylor expansion of the function $f$ around $t = \mu$ , but failed to recover it.) Let $X_{n+1}$ be independent of $\{X_i\}_{i=1}^n$ , but identically distributed. Then \begin{multline*} \mathbb{E} [f(\overline{X}_n)] = \frac{n}{\mu}  \mathbb{E} \Big[\frac{X_{n+1}}{S_n + n}\Big] = \frac{n}{\mu}  \mathbb{E} \Big[\frac{X_{n+1}}{S_{n+1} + n} \frac{S_{n} + n + X_{n+1}}{S_{n} + n}\Big] \\\leq \Big(1 + \frac{a}{n}\Big) \frac{n}{\mu}  \mathbb{E} \Big[\frac{X_{n+1}}{S_{n+1} + n} \Big].\qquad \mbox{(1)} \end{multline*} Since $X_{j}$ , $j \leq n + 1$ are exchangeable, we also have $$ \mathbb{E} \Big[\frac{X_{n+1}}{S_{n+1} + n} \Big] = \frac{1}{n+1}  \mathbb{E} \Big[\frac{\overline{X}_{n+1}}{\overline{X}_{n+1} + n/(n+1)} \Big] \stackrel{{\rm (*)}}{\leq}  \frac{\mu}{(n+1)\mu + n} \leq \frac{\mu}{n} \frac{1}{\mu + 1}. \quad \mbox{(2)} $$ Above, we have used Jensen's inequality in (*) with mapping $z \mapsto z/(z + n/(n+1))$ which is concave on the nonnegative reals. Combining bounds (1) and (2), we get a bound $C(a, n) \leq 1 + a/n$ .","Let be random real-valued random variables in the interval . Assume they are independently and identically distributed. Let denote their common mean. Define their average where . Let . Question: What is the smallest constant such that we have It should be emphasized that the constant is universal: it is valid for any law of , supported on . It should be dependent only on . Comments: Necessarily . Note that by Jensen's inequality, we have the following inequality, since is a convex function on the nonnegative reals. Additionally, I claim that . I have a proof of this below. (I would also be interested if there is a simpler way to establish this. I tried, thinking I could possibly improve the constant, to obtain it by Taylor expansion of the function around , but failed to recover it.) Let be independent of , but identically distributed. Then Since , are exchangeable, we also have Above, we have used Jensen's inequality in (*) with mapping which is concave on the nonnegative reals. Combining bounds (1) and (2), we get a bound .","X_1, \dots, X_n [0, a] \mu = \mathbb{E}[X_i] \overline{X}_{n} = n^{-1} S_n S_n = \sum_{i=1}^n X_i f(t) := (t + 1)^{-1} C = C(a, n) \geq 1 
\mathbb{E}[f(\overline{X}_n)] \leq C~f(\mu)?
 C X_i [0, a] a, n C \geq 1 
\mathbb{E}[f(\overline{X}_n)] \geq f(\mu), 
 f C \leq 1 + \tfrac{a}{n} f t = \mu X_{n+1} \{X_i\}_{i=1}^n \begin{multline*}
\mathbb{E} [f(\overline{X}_n)] = \frac{n}{\mu} 
\mathbb{E} \Big[\frac{X_{n+1}}{S_n + n}\Big] =
\frac{n}{\mu} 
\mathbb{E} \Big[\frac{X_{n+1}}{S_{n+1} + n} \frac{S_{n} + n + X_{n+1}}{S_{n} + n}\Big]
\\\leq \Big(1 + \frac{a}{n}\Big) \frac{n}{\mu} 
\mathbb{E} \Big[\frac{X_{n+1}}{S_{n+1} + n} \Big].\qquad \mbox{(1)}
\end{multline*} X_{j} j \leq n + 1 
\mathbb{E} \Big[\frac{X_{n+1}}{S_{n+1} + n} \Big]
= \frac{1}{n+1} 
\mathbb{E} \Big[\frac{\overline{X}_{n+1}}{\overline{X}_{n+1} + n/(n+1)} \Big]
\stackrel{{\rm (*)}}{\leq}  \frac{\mu}{(n+1)\mu + n} \leq \frac{\mu}{n} \frac{1}{\mu + 1}. \quad \mbox{(2)}
 z \mapsto z/(z + n/(n+1)) C(a, n) \leq 1 + a/n","['probability', 'inequality', 'expected-value']"
1,Toss 100 fair coins and take away the tails; toss the remaining coins and take away the tails. Continue until no coins remain. [duplicate],Toss 100 fair coins and take away the tails; toss the remaining coins and take away the tails. Continue until no coins remain. [duplicate],,"This question already has answers here : Expectation of the maximum of i.i.d. geometric random variables (3 answers) Closed 3 years ago . 100 participants have a fair coin each, on a given round, the not already discarded participants flip their coins, those who flip a tail are discarded from the game, the remaining ones continue to play until nobody is left (everyone has been discarded). What would be the average number of trials (where each trial consists of a tossing and removing the tails) one would expect from doing this experiment? Does conditional expectation work for something like this? I know that each individual coin follows a Geometric distribution, but I am trying to figure out the sum of them to determine the average number of trials for a game like this. My Logic/Thought Process: I started out trying to think of the probability that a particular coin makes it to round $r$ which is $\frac{1}{2^m}$ . I then realized that each coin outcome can be modeled by a Geometric random variables with $p = 0.5$ . I am just now unsure how to take the leap from this single case to a case with 100 coins. I presume it has to do with summing the geometric random variables, but I am not sure.","This question already has answers here : Expectation of the maximum of i.i.d. geometric random variables (3 answers) Closed 3 years ago . 100 participants have a fair coin each, on a given round, the not already discarded participants flip their coins, those who flip a tail are discarded from the game, the remaining ones continue to play until nobody is left (everyone has been discarded). What would be the average number of trials (where each trial consists of a tossing and removing the tails) one would expect from doing this experiment? Does conditional expectation work for something like this? I know that each individual coin follows a Geometric distribution, but I am trying to figure out the sum of them to determine the average number of trials for a game like this. My Logic/Thought Process: I started out trying to think of the probability that a particular coin makes it to round which is . I then realized that each coin outcome can be modeled by a Geometric random variables with . I am just now unsure how to take the leap from this single case to a case with 100 coins. I presume it has to do with summing the geometric random variables, but I am not sure.",r \frac{1}{2^m} p = 0.5,"['probability', 'combinatorics']"
2,"100 blank cards, minimize the EV","100 blank cards, minimize the EV",,"I give you a hundred blank cards, and you can write a single positive integer on each card. I look at the cards when you are done, then I shuffle the deck. I guess the top card of the deck, and if I am right, I make the dollar which is written on the card. What numbers should you write on the cards to minimize the expected return of mine? Attempt: So this problem seems to me quite difficult. If I put a 1 on a cards, then the Expected value is 1. if I put two 2s, and the rest 1-99, the Expected value is 99/100. I feel  the minimum occurs when i is an integer on at least one of the cards, where $ip_{i} = jp_{j}$ for every i,j is nearly satisfied, otherwise you could minimize it further. So p1=2p2 = 3p3 =...=npn So if you used only 1 and 2, then could get EV close to 2/3. So to solve this I feel I need to work out the minimum G such that, p1 ≈ p2 ≈  p3 ≈ .. ≈  pn ≈  G where you cannot reorganise the cards, to make a closer approximation.","I give you a hundred blank cards, and you can write a single positive integer on each card. I look at the cards when you are done, then I shuffle the deck. I guess the top card of the deck, and if I am right, I make the dollar which is written on the card. What numbers should you write on the cards to minimize the expected return of mine? Attempt: So this problem seems to me quite difficult. If I put a 1 on a cards, then the Expected value is 1. if I put two 2s, and the rest 1-99, the Expected value is 99/100. I feel  the minimum occurs when i is an integer on at least one of the cards, where $ip_{i} = jp_{j}$ for every i,j is nearly satisfied, otherwise you could minimize it further. So p1=2p2 = 3p3 =...=npn So if you used only 1 and 2, then could get EV close to 2/3. So to solve this I feel I need to work out the minimum G such that, p1 ≈ p2 ≈  p3 ≈ .. ≈  pn ≈  G where you cannot reorganise the cards, to make a closer approximation.",,"['probability', 'algebra-precalculus']"
3,Expected number of times Random Walk crosses 0 line.,Expected number of times Random Walk crosses 0 line.,,"Suppose we have a simple random walk: $$ x_t = x_{t-1} + \epsilon_{t} $$ Where $$ \epsilon_{t} =  iid\  \mathcal{N} (0,1) $$ Assume that x starts at 0 what is the expected number of times x will cross the 0 point for N number of periods? I am more interested in the method of obtaining the answer than the answer  itself. What I have so far: I was looking at simple case where N = 2, and in this case expected number of crosses seems to be 0.25 . Intuitively, this makes sense, in the first period we moved somewhere, and on the second the probability that we move in the right direction is 0.5, and of that 0.5, the probability (on average) that we move back far enough to cross is 0.5, so 0.5 * 0.5 => 0.25. I validated this with simulation: import numpy as np  def simulations(n, n_iterations):     return sum(my_one_run(n) for _ in xrange(n_iterations)) / float(n_iterations)  def my_one_run(n):     path = [0]     n_crosses = 0     for i in xrange(n):         prev = path[-1]         new_x = prev + np.random.normal(0,1)         path.append(new_x)         if prev * new_x < 0:             n_crosses += 1     return n_crosses And my results have been confirmed: In [66]: simulations(2, 1000000) Out[66]: 0.250249 However, I don't see how to proceed for a more complicated case, even more general case. (This is not a homework question, if this matters. I am just trying to explore something in this area and wanted to start with a basic case.).","Suppose we have a simple random walk: $$ x_t = x_{t-1} + \epsilon_{t} $$ Where $$ \epsilon_{t} =  iid\  \mathcal{N} (0,1) $$ Assume that x starts at 0 what is the expected number of times x will cross the 0 point for N number of periods? I am more interested in the method of obtaining the answer than the answer  itself. What I have so far: I was looking at simple case where N = 2, and in this case expected number of crosses seems to be 0.25 . Intuitively, this makes sense, in the first period we moved somewhere, and on the second the probability that we move in the right direction is 0.5, and of that 0.5, the probability (on average) that we move back far enough to cross is 0.5, so 0.5 * 0.5 => 0.25. I validated this with simulation: import numpy as np  def simulations(n, n_iterations):     return sum(my_one_run(n) for _ in xrange(n_iterations)) / float(n_iterations)  def my_one_run(n):     path = [0]     n_crosses = 0     for i in xrange(n):         prev = path[-1]         new_x = prev + np.random.normal(0,1)         path.append(new_x)         if prev * new_x < 0:             n_crosses += 1     return n_crosses And my results have been confirmed: In [66]: simulations(2, 1000000) Out[66]: 0.250249 However, I don't see how to proceed for a more complicated case, even more general case. (This is not a homework question, if this matters. I am just trying to explore something in this area and wanted to start with a basic case.).",,"['probability', 'random-walk']"
4,p chance of winning tennis point -> what f(p) chance of winning game?,p chance of winning tennis point -> what f(p) chance of winning game?,,"In Wii Tennis, I have fixed $\,\,p\,\,$ chance of winning a given point. What is my chance $f(p)$ of winning the entire game? If $p=0.5, f(p)=0.5$ by symmetry, but I believe $f(0.51) > 0.51 $ EDIT: to clarify, the rules of Wii Tennis are the same as regular tennis. EDIT: would a Markov Chain be useful here?","In Wii Tennis, I have fixed $\,\,p\,\,$ chance of winning a given point. What is my chance $f(p)$ of winning the entire game? If $p=0.5, f(p)=0.5$ by symmetry, but I believe $f(0.51) > 0.51 $ EDIT: to clarify, the rules of Wii Tennis are the same as regular tennis. EDIT: would a Markov Chain be useful here?",,[]
5,Probability of the outcome of this simple card game,Probability of the outcome of this simple card game,,"I have a deck of $N$ cards. $n$ of the cards are red circles and $N-n$ cards are blue circles. I also have an unlimited supply of red square and blue square cards. I play the following game and want to know the probability distribution of the outcome: Repeat the following process until no circle card left: Pick one of the circle cards from the deck at random and replace it with a square card of the same color (let's call this color $c$ ). Then pick another card from the deck (it could be a circle or square card of any color) at random and replace it with another square card of color $c$ . Note that in each repeated step of the above process, the second replaced card could possibly be the same as the first square card of that step. Every time you repeat this process, you replace one or two of the circle cards with square cards. In the end, we will have $N$ square cards. I want to know the probability $P(n'|n)$ of having $n'$ red squares and $N-n'$ blue squares at the end, given $n$ initial red circles. What do I want: Ideally $P(n'|n)$ . If that's not easy, a large $N$ approximation could be equally helpful. Alternatively, finding the mean and the variance of $n'$ would be equally helpful. I'm guessing the mean of $n'$ is $n$ . The mean and variance of $n'$ for large $N$ would also be good enough if nothing else works. Update 1 : Numerically, it looks like $\left\langle n'\right\rangle = n$ , and for large $N$ , $\text{var}(n') \approx\frac{3n(N-n)}{4N}$ . Update 2 : antkam's answer gives a beautiful symmetry proof for $\left\langle n'\right\rangle = n$ . Now, all I need is: Prove $\text{var}(n') \approx\frac{3n(N-n)}{4N}$ for large N. Update 3 : Some more numerical results that may help to find a proof: as in antkam's answer , we can define the variable $X_i\in\{0,1,2\}$ to be the number of square cards resulted from the $i$ 'th circle card. $n'$ can be written as $$n'=\sum_{i=1}^n X_i.$$ We can write the Var( $n'$ ) as $$ \begin{align} \text{Var}(n') &= \left\langle\left(\sum_{i=1}^n X_i\right)^2\right\rangle - \left\langle\sum_{i=1}^n X_i\right\rangle^2\\ &=n\left(\text{Var}(X_1)+(n-1)\text{Cov}(X_1,X_2)\right) \end{align} $$ Numerically, I have found ( Edit : Now both of these partial results are proven in joriki's answer below): $\text{Var}(X_1) = 3/4$ Probabilities are $P(X=0) = P(X=2) = 3/8$ and $P(X=1)=1/4$ . Observations: The equality of $P(X=0) = P(X=2)$ can be justfied through the following observation: For $\sum_{i=1}^N X_i = N$ to be satisfied, the number of $X_i=0$ should be exactly the same as the number of $X_j=2$ . For $\text{Var}(n')$ to be $\frac{3n(N-n)}{4N}$ , the value of $\text{Cov}(X_1,X_2)$ should be $-\frac{3}{4N}$ to first order in $1/N$ .","I have a deck of cards. of the cards are red circles and cards are blue circles. I also have an unlimited supply of red square and blue square cards. I play the following game and want to know the probability distribution of the outcome: Repeat the following process until no circle card left: Pick one of the circle cards from the deck at random and replace it with a square card of the same color (let's call this color ). Then pick another card from the deck (it could be a circle or square card of any color) at random and replace it with another square card of color . Note that in each repeated step of the above process, the second replaced card could possibly be the same as the first square card of that step. Every time you repeat this process, you replace one or two of the circle cards with square cards. In the end, we will have square cards. I want to know the probability of having red squares and blue squares at the end, given initial red circles. What do I want: Ideally . If that's not easy, a large approximation could be equally helpful. Alternatively, finding the mean and the variance of would be equally helpful. I'm guessing the mean of is . The mean and variance of for large would also be good enough if nothing else works. Update 1 : Numerically, it looks like , and for large , . Update 2 : antkam's answer gives a beautiful symmetry proof for . Now, all I need is: Prove for large N. Update 3 : Some more numerical results that may help to find a proof: as in antkam's answer , we can define the variable to be the number of square cards resulted from the 'th circle card. can be written as We can write the Var( ) as Numerically, I have found ( Edit : Now both of these partial results are proven in joriki's answer below): Probabilities are and . Observations: The equality of can be justfied through the following observation: For to be satisfied, the number of should be exactly the same as the number of . For to be , the value of should be to first order in .","N n N-n c c N P(n'|n) n' N-n' n P(n'|n) N n' n' n n' N \left\langle n'\right\rangle = n N \text{var}(n') \approx\frac{3n(N-n)}{4N} \left\langle n'\right\rangle = n \text{var}(n') \approx\frac{3n(N-n)}{4N} X_i\in\{0,1,2\} i n' n'=\sum_{i=1}^n X_i. n' 
\begin{align}
\text{Var}(n') &= \left\langle\left(\sum_{i=1}^n X_i\right)^2\right\rangle - \left\langle\sum_{i=1}^n X_i\right\rangle^2\\
&=n\left(\text{Var}(X_1)+(n-1)\text{Cov}(X_1,X_2)\right)
\end{align}
 \text{Var}(X_1) = 3/4 P(X=0) = P(X=2) = 3/8 P(X=1)=1/4 P(X=0) = P(X=2) \sum_{i=1}^N X_i = N X_i=0 X_j=2 \text{Var}(n') \frac{3n(N-n)}{4N} \text{Cov}(X_1,X_2) -\frac{3}{4N} 1/N","['probability', 'combinatorics', 'probability-distributions', 'card-games']"
6,Expected max load with $n$ balls in $n$ bins?,Expected max load with  balls in  bins?,n n,"If you throw $n$ balls into $n$ bins uniformly and independently at random, let $X$ be the number of balls in the bin with the largest number of balls in it. Is there an elementary way to compute $\mathbb{E}(X)$? This problem comes up when considering hashing in computer science, for example, or randomized load balancing. EDIT.  Having seen the current answer, if there is a simpler way to prove that $\mathbb{E}(X) =\Theta(\log{n}/\log{\log{n}})$ instead of an exact formula I would be happy with that.","If you throw $n$ balls into $n$ bins uniformly and independently at random, let $X$ be the number of balls in the bin with the largest number of balls in it. Is there an elementary way to compute $\mathbb{E}(X)$? This problem comes up when considering hashing in computer science, for example, or randomized load balancing. EDIT.  Having seen the current answer, if there is a simpler way to prove that $\mathbb{E}(X) =\Theta(\log{n}/\log{\log{n}})$ instead of an exact formula I would be happy with that.",,['probability']
7,Probability that the sum of 'n' positive numbers less than 2 is less than 2,Probability that the sum of 'n' positive numbers less than 2 is less than 2,,"I'm a high school student, And I stumbled across this problem Q) if you arbitrarily choose 3 real positive numbers less than or equal to 2 What is the probability that their sum is less than or equal to 2? In my course I have learnt to solve 2 number based probability problems by using the ratio of the areas plotted by their graphs. This was an application question that required me to plot it in 3 dimensions and find the ratio of their volumes to get the required probability, and so I managed to pull it off and got the required answer. My question then arose... How do I deal with N dimensions? As I only have the knowledge to visualize 3 dimensions at my level of Math, Can anyone help me out? I am really curious to see 1) the actual function and how it's growth is 2) the way you solve such kind of problems! (some kind of multivariable calculus??) Thanks!","I'm a high school student, And I stumbled across this problem Q) if you arbitrarily choose 3 real positive numbers less than or equal to 2 What is the probability that their sum is less than or equal to 2? In my course I have learnt to solve 2 number based probability problems by using the ratio of the areas plotted by their graphs. This was an application question that required me to plot it in 3 dimensions and find the ratio of their volumes to get the required probability, and so I managed to pull it off and got the required answer. My question then arose... How do I deal with N dimensions? As I only have the knowledge to visualize 3 dimensions at my level of Math, Can anyone help me out? I am really curious to see 1) the actual function and how it's growth is 2) the way you solve such kind of problems! (some kind of multivariable calculus??) Thanks!",,['probability']
8,Why would I use Bayes' Theorem if I can directly compute the posterior probability?,Why would I use Bayes' Theorem if I can directly compute the posterior probability?,,"I fully understand the mechanics of Bayes' Theorem. However, I am wondering when do I need to use it? If I am able to compute the posterior probability directly from measured data, why would I need to use Bayes' Theorem? For example, consider NBA basketball games. Let $A = team\ wins$ and let $B = team\ scores\ 100\ points$. I want to compute the posterior probability $P(A|B)$, or $P(team\ wins | team\ scores\ 100\ points)$. If I expand this out using Bayes, I would get: $$P(team\ wins | team\ scores\ 100) = \frac{P(team\ scores\ 100 | team\ wins) \cdot P(team\ wins)}{P(team\ scores\ 100)}$$ Suppose I have the entire log of my team's results. I can compute the posterior (left-hand-side) directly from the logs by simply building a contingency table and doing the appropriate calculations, just as I would to compute the likelihood probability $P(B|A)$. Why would I need to compute the posterior through Bayes' Theorem? Would I use it when I have sparse data (e.g. A and B seldom co-occur)?","I fully understand the mechanics of Bayes' Theorem. However, I am wondering when do I need to use it? If I am able to compute the posterior probability directly from measured data, why would I need to use Bayes' Theorem? For example, consider NBA basketball games. Let $A = team\ wins$ and let $B = team\ scores\ 100\ points$. I want to compute the posterior probability $P(A|B)$, or $P(team\ wins | team\ scores\ 100\ points)$. If I expand this out using Bayes, I would get: $$P(team\ wins | team\ scores\ 100) = \frac{P(team\ scores\ 100 | team\ wins) \cdot P(team\ wins)}{P(team\ scores\ 100)}$$ Suppose I have the entire log of my team's results. I can compute the posterior (left-hand-side) directly from the logs by simply building a contingency table and doing the appropriate calculations, just as I would to compute the likelihood probability $P(B|A)$. Why would I need to compute the posterior through Bayes' Theorem? Would I use it when I have sparse data (e.g. A and B seldom co-occur)?",,"['probability', 'bayesian']"
9,The minimum of two independent geometric random variables,The minimum of two independent geometric random variables,,"here's a question I got for homework (sorry if my translation is a bit unclear): Let $X\sim‬G(p_1)$ , $Y\sim ‬G(p_2)$ , $X$ and $Y$ are independent. Prove that the minimum is also geometric, meaning: $\min(X,Y)\sim G(1-(1-p_1)(1-p_2))$ . Instructions: first calculate the probability $P(\min(X,Y) > k)$ and compare it to the parallel probability in (of?) a geometric random variable. I have no idea where to start, even with the great clue that they've supplied. Any hints?","here's a question I got for homework (sorry if my translation is a bit unclear): Let , , and are independent. Prove that the minimum is also geometric, meaning: . Instructions: first calculate the probability and compare it to the parallel probability in (of?) a geometric random variable. I have no idea where to start, even with the great clue that they've supplied. Any hints?","X\sim‬G(p_1) Y\sim ‬G(p_2) X Y \min(X,Y)\sim G(1-(1-p_1)(1-p_2)) P(\min(X,Y) > k)",['probability']
10,"Ulam spiral: Is there an ""unusual amount of clumping"" in prime-rich quadratic polynomials?","Ulam spiral: Is there an ""unusual amount of clumping"" in prime-rich quadratic polynomials?",,"I was reading Martin Gardner's Mathematical Games column on the Ulam spiral which appeared in the March 1964 issue of Scientific American .  (The spiral actually featured on the cover of that issue.)  Gardner makes the following statement: The grid on the cover suggests that throughout the entire number series expressions of this form are likely to vary markedly from those ""poor"" in primes to those that are ""rich,"" and that on the rich lines an unusual amount of clumping occurs. By ""this form"" Gardner means the form $4x^2+bx+c$.  I'm curious - and a little bit skeptical - about his last statement concerning clumping.  I know that the existence of prime-rich and prime-poor polynomials is a longstanding conjecture, going back to Euler's discovery that polynomials such as $x^2-x+41$ generate unusually many primes, and that Hardy and Littlewood and also Bateman and Horn made concrete proposals as to what the density of primes in such polynomials ought to be. My question is whether there is any evidence, either numerical or heuristic, that there should be a large amount of clumping in the primes of the form $x^2-x+41$.  Famously, the first 40 values of $x$ all give primes, but if one goes to higher values of $x$ are there more long clusters of primes than one would expect if the primes were randomly distributed? Rephrasing the question: I am aware of the conjecture that $x^2-x+41$ has more primes than other, similar lines.  The question is whether there is a conjecture saying that $x^2-x+41$ has more dense clusters of primes than expected.","I was reading Martin Gardner's Mathematical Games column on the Ulam spiral which appeared in the March 1964 issue of Scientific American .  (The spiral actually featured on the cover of that issue.)  Gardner makes the following statement: The grid on the cover suggests that throughout the entire number series expressions of this form are likely to vary markedly from those ""poor"" in primes to those that are ""rich,"" and that on the rich lines an unusual amount of clumping occurs. By ""this form"" Gardner means the form $4x^2+bx+c$.  I'm curious - and a little bit skeptical - about his last statement concerning clumping.  I know that the existence of prime-rich and prime-poor polynomials is a longstanding conjecture, going back to Euler's discovery that polynomials such as $x^2-x+41$ generate unusually many primes, and that Hardy and Littlewood and also Bateman and Horn made concrete proposals as to what the density of primes in such polynomials ought to be. My question is whether there is any evidence, either numerical or heuristic, that there should be a large amount of clumping in the primes of the form $x^2-x+41$.  Famously, the first 40 values of $x$ all give primes, but if one goes to higher values of $x$ are there more long clusters of primes than one would expect if the primes were randomly distributed? Rephrasing the question: I am aware of the conjecture that $x^2-x+41$ has more primes than other, similar lines.  The question is whether there is a conjecture saying that $x^2-x+41$ has more dense clusters of primes than expected.",,"['number-theory', 'probability', 'prime-numbers']"
11,Upper bound in information theory puzzle,Upper bound in information theory puzzle,,"Consider the following puzzle: I have just flipped $n$ fair coins. Before I start revealing them to you, you can ask me one yes/no question. Then, you can make $n$ Head/Tail guesses. What's your question and strategy for maximizing the number of correct guesses? The baseline (no question asked a priori) is to guess only H (or T). This will give you $\dfrac{n}{2}$ correct guesses (in expectation). A first question would be: ""Is the first coin H?"" . If yes, guess only H, otherwise guess only T. So you now get $1 + \dfrac{n-1}{2} = \dfrac{n}{2} + \dfrac12$ correct guesses. Another question: ""Are there more H than T?"" -- and just answer H or T depending on the answer. This strategy yields $n\cdot \Pr(H \geq T) = n\cdot\sum_{k=n/2}^{n} \binom{n}{k} \cdot \dfrac{1}{2^n}$ correct guesses (from Binomial PMF), which is the best so far. My questions are the following: How much more can we maximize the number of correct guesses? Is there a (tractable) way to quantify this (an upper bound)? One yes/no question means one bit of entropy. Can we derive some sort of relationship between this quantity and the max correct guesses? For example, if one asks two questions (2 bits of entropy), how much better off are we? Clearly, if we're allowed $n$ bits of entropy, then we can guess the entire sequence.","Consider the following puzzle: I have just flipped fair coins. Before I start revealing them to you, you can ask me one yes/no question. Then, you can make Head/Tail guesses. What's your question and strategy for maximizing the number of correct guesses? The baseline (no question asked a priori) is to guess only H (or T). This will give you correct guesses (in expectation). A first question would be: ""Is the first coin H?"" . If yes, guess only H, otherwise guess only T. So you now get correct guesses. Another question: ""Are there more H than T?"" -- and just answer H or T depending on the answer. This strategy yields correct guesses (from Binomial PMF), which is the best so far. My questions are the following: How much more can we maximize the number of correct guesses? Is there a (tractable) way to quantify this (an upper bound)? One yes/no question means one bit of entropy. Can we derive some sort of relationship between this quantity and the max correct guesses? For example, if one asks two questions (2 bits of entropy), how much better off are we? Clearly, if we're allowed bits of entropy, then we can guess the entire sequence.",n n \dfrac{n}{2} 1 + \dfrac{n-1}{2} = \dfrac{n}{2} + \dfrac12 n\cdot \Pr(H \geq T) = n\cdot\sum_{k=n/2}^{n} \binom{n}{k} \cdot \dfrac{1}{2^n} n,"['probability', 'puzzle', 'information-theory']"
12,The case of the missing ninth of a $2$€ coin,The case of the missing ninth of a € coin,2,"In answering Expected value of the number of bills , I came across a phenomenon the likes of which I don't think I've encountered before, and I'd like to know more about it. You draw coins, each coin independently being a $1$ € coin or a $2$ € coin with equal probability. Obviously you'd expect to draw as many $2$ € coins as $1$ € coins. In particular, the expectation of $A-B$ , where $A$ is the number of $1$ € coins drawn and $B$ is the number of $2$ € coins drawn, is $0$ after any given number of draws. However, conditional on reaching a total value of $n$ euros, the expectation of $A-B$ tends to $\frac13$ for $n\to\infty$ (in fact, it's positive for all $n\gt2$ ): The probability to reach $n$ euros with $k$ $2$ € coins and $n-2k$ $1$ € coins is $\binom{n-k}k2^{k-n}$ , so the expectation of $B$ is \begin{eqnarray*} &&\frac{\sum_{k=0}^n\binom{n-k}k2^{k-n}k}{\sum_{k=0}^n\binom{n-k}k2^{k-n}}=\frac{\frac2{27}(3n-1)+O\left(2^{-n}\right)}{\frac23+O\left(2^{-n}\right)}=\frac n3-\frac19+O\left(2^{-n}\right)\;,\\ \end{eqnarray*} the expectation of $A=n-2B$ is $\frac n3+\frac29+O\left(2^{-n}\right)$ , and  the expectation of $A-B$ is $\frac13+O\left(2^{-n}\right)$ . This is rather counterintuitive (to me): For any given number of coins the expectation is $0$ , but for any given value of the coins it's positive. This is the stuff that paradoxes are made of if you're not careful how you talk about it, e.g.: “Someone is playing this game. What value do you expect for $A-B$ ?” – “ $0$ .” – “So far they drew $137$ €. Now what do you expect?” – “ $\frac13$ .” The resolution here is (as it often is) that the conditions aren't properly defined – we don't know why and when the person is telling us this amount. If they fixed a number of draws to wait for and then told us the total value at that point, the correct answer would still be $0$ ; if they fixed a total value to wait for and then told us when it was reached, the correct answer would be $\frac13$ , but then the paradox of changing our mind just because we were told some number, no matter which one, wouldn't arise, because it's the stopping protocol that makes the difference. Still, a certain uneasy sense of paradox remains, even if it temporarily retreats under the glare of careful analysis. I don't have any concrete questions about this, but I'd be interested to hear about any other cases where such a phenomenon occurs, or names by which it's known, or approaches to deal with it, and perhaps also to ease that lingering sense of paradox.","In answering Expected value of the number of bills , I came across a phenomenon the likes of which I don't think I've encountered before, and I'd like to know more about it. You draw coins, each coin independently being a € coin or a € coin with equal probability. Obviously you'd expect to draw as many € coins as € coins. In particular, the expectation of , where is the number of € coins drawn and is the number of € coins drawn, is after any given number of draws. However, conditional on reaching a total value of euros, the expectation of tends to for (in fact, it's positive for all ): The probability to reach euros with € coins and € coins is , so the expectation of is the expectation of is , and  the expectation of is . This is rather counterintuitive (to me): For any given number of coins the expectation is , but for any given value of the coins it's positive. This is the stuff that paradoxes are made of if you're not careful how you talk about it, e.g.: “Someone is playing this game. What value do you expect for ?” – “ .” – “So far they drew €. Now what do you expect?” – “ .” The resolution here is (as it often is) that the conditions aren't properly defined – we don't know why and when the person is telling us this amount. If they fixed a number of draws to wait for and then told us the total value at that point, the correct answer would still be ; if they fixed a total value to wait for and then told us when it was reached, the correct answer would be , but then the paradox of changing our mind just because we were told some number, no matter which one, wouldn't arise, because it's the stopping protocol that makes the difference. Still, a certain uneasy sense of paradox remains, even if it temporarily retreats under the glare of careful analysis. I don't have any concrete questions about this, but I'd be interested to hear about any other cases where such a phenomenon occurs, or names by which it's known, or approaches to deal with it, and perhaps also to ease that lingering sense of paradox.","1 2 2 1 A-B A 1 B 2 0 n A-B \frac13 n\to\infty n\gt2 n k 2 n-2k 1 \binom{n-k}k2^{k-n} B \begin{eqnarray*}
&&\frac{\sum_{k=0}^n\binom{n-k}k2^{k-n}k}{\sum_{k=0}^n\binom{n-k}k2^{k-n}}=\frac{\frac2{27}(3n-1)+O\left(2^{-n}\right)}{\frac23+O\left(2^{-n}\right)}=\frac n3-\frac19+O\left(2^{-n}\right)\;,\\
\end{eqnarray*} A=n-2B \frac n3+\frac29+O\left(2^{-n}\right) A-B \frac13+O\left(2^{-n}\right) 0 A-B 0 137 \frac13 0 \frac13","['probability', 'soft-question', 'expected-value', 'paradoxes']"
13,Stochastic domination and sum of random variables,Stochastic domination and sum of random variables,,"I'm dealing with a statement that seems trivial but I couldn't prove it rigorously. Suppose that I have two i.i.d. random variables $X_1$ and $X_2$ and another couple of i.i.d. variables $Y_1$ and $Y_2$ ( $X$ and $Y$ are independent on each other and do not need to have the same law). Suppose that $X$ dominates $Y$ in the sense that $$\mathbb{P}(X \ge t) \ge \mathbb{P}(Y \ge t), \quad \forall \: t \in \mathbb{R}  $$ How can I show that $$\mathbb{P}(X_1+X_2 \ge t) \ge \mathbb{P}(Y_1+Y_2 \ge t), \quad \forall \: t \in \mathbb{R}  $$ This seems pretty intuitive to me but I didn't get far.",I'm dealing with a statement that seems trivial but I couldn't prove it rigorously. Suppose that I have two i.i.d. random variables and and another couple of i.i.d. variables and ( and are independent on each other and do not need to have the same law). Suppose that dominates in the sense that How can I show that This seems pretty intuitive to me but I didn't get far.,"X_1 X_2 Y_1 Y_2 X Y X Y \mathbb{P}(X \ge t) \ge \mathbb{P}(Y \ge t), \quad \forall \: t \in \mathbb{R}   \mathbb{P}(X_1+X_2 \ge t) \ge \mathbb{P}(Y_1+Y_2 \ge t), \quad \forall \: t \in \mathbb{R}  ","['probability', 'measure-theory', 'summation', 'random-variables']"
14,Probability that $\displaystyle \vert x\vert +\vert y\vert +\vert z\vert +\vert x+y+z\vert=\vert x+y\vert +\vert x+z\vert +\vert y+z\vert$,Probability that,\displaystyle \vert x\vert +\vert y\vert +\vert z\vert +\vert x+y+z\vert=\vert x+y\vert +\vert x+z\vert +\vert y+z\vert,"Real numbers $x, y$ , and $z$ are chosen from the interval $[−1, 1]$ independently and uniformly at random.   What is the probability that $$\vert x\vert +\vert y\vert +\vert z\vert +\vert x+y+z\vert=\vert x+y\vert +\vert x+z\vert +\vert y+z\vert$$ Now if all of $x, y, z$ are positive or all negative then the equation is of course satisfied.  Hence if we consider a 3D space , it denotes two unit cubes, one in the first octant centred at $\left( \frac 12,\frac 12,\frac 12\right)$ and the other in seventh octant centred at $\left( -\frac 12,-\frac 12,-\frac 12\right)$ . The total measure of universal set is the cube with edge length $2$ centred at origin. But now I have a problem about what if any two of $x, y, z$ are positive while the other remaining be negative or the other way around.  Even if I try to make cases it seems to be quite a cumbersome task to approach since we will also need to check signs of $\vert x+y\vert$ and similarly others as well as that of $\vert x+y+z\vert $ I also thought to give a shot using vectors but didn't reach any specific result. Any help would be quite beneficial. Edit: I would also be happy to see a geometrical intuitive way to attack the problem.","Real numbers , and are chosen from the interval independently and uniformly at random.   What is the probability that Now if all of are positive or all negative then the equation is of course satisfied.  Hence if we consider a 3D space , it denotes two unit cubes, one in the first octant centred at and the other in seventh octant centred at . The total measure of universal set is the cube with edge length centred at origin. But now I have a problem about what if any two of are positive while the other remaining be negative or the other way around.  Even if I try to make cases it seems to be quite a cumbersome task to approach since we will also need to check signs of and similarly others as well as that of I also thought to give a shot using vectors but didn't reach any specific result. Any help would be quite beneficial. Edit: I would also be happy to see a geometrical intuitive way to attack the problem.","x, y z [−1, 1] \vert x\vert +\vert y\vert +\vert z\vert +\vert x+y+z\vert=\vert x+y\vert +\vert x+z\vert +\vert y+z\vert x, y, z \left( \frac 12,\frac 12,\frac 12\right) \left( -\frac 12,-\frac 12,-\frac 12\right) 2 x, y, z \vert x+y\vert \vert x+y+z\vert ","['probability', 'probability-theory', 'coordinate-systems', '3d']"
15,Joint density of order statistics,Joint density of order statistics,,"I need some help to understand the following proposition (mainly to understand how it is proven): Let $Y_1,Y_2...,Y_n$ be $n$ random variables which are independent, identically distributed random variables with probability density function $f$. The joint density of the order statistics $Y_{(1)},Y_{(2)},..,Y_{(n)}$ is given by: $\textbf{(1)}\quad$$f(y_1,y_2,...,y_n)= n!\prod\limits_{i=1}^{n}f(y_1) \qquad y_1 <y_2...<y_n$ $\textbf{(i)} \quad$the preceding follows since: ($Y_{(1)},Y_{(2)},..,Y_{(n)})$ will equal $(y_1,y_2...,y_n)$ if $(Y_1,Y_2,...Y_n)$ is equal to any of the $n!$ permutations of  $(y_1,y_2...,y_n)$ ** this part i get; they are saying that the ordered statistics is equal to the tuple $(y_1,y_2...,y_n)$ only if the unordered  $(Y_1,Y_2,...Y_n)$ is equal to a permutation of $(y_1,y_2...,y_n)$. But what does have for consequence in $\textbf{(1)} ??$ ** $\textbf{(ii)}\quad$ the probability density that $(Y_1,Y_2,...,Y_n)$ is equal to $y_{i_{1}},...,y_{i_{n}}$  is $\prod_{j=1}^{n}f(y_{i_{j}}) = \prod_{j=1}^{n}f(y_j)$ when $i_1,...i_n$ is a permutation of $1,2...,n$ ** here Iam completely lost;  the probability density that $(Y_1,Y_2,...,Y_n)$ is equal to $y_{i_{1}},...,y_{i_{n}}$ what do they mean? probability density (function)? I don't know what they mean at all with this statement","I need some help to understand the following proposition (mainly to understand how it is proven): Let $Y_1,Y_2...,Y_n$ be $n$ random variables which are independent, identically distributed random variables with probability density function $f$. The joint density of the order statistics $Y_{(1)},Y_{(2)},..,Y_{(n)}$ is given by: $\textbf{(1)}\quad$$f(y_1,y_2,...,y_n)= n!\prod\limits_{i=1}^{n}f(y_1) \qquad y_1 <y_2...<y_n$ $\textbf{(i)} \quad$the preceding follows since: ($Y_{(1)},Y_{(2)},..,Y_{(n)})$ will equal $(y_1,y_2...,y_n)$ if $(Y_1,Y_2,...Y_n)$ is equal to any of the $n!$ permutations of  $(y_1,y_2...,y_n)$ ** this part i get; they are saying that the ordered statistics is equal to the tuple $(y_1,y_2...,y_n)$ only if the unordered  $(Y_1,Y_2,...Y_n)$ is equal to a permutation of $(y_1,y_2...,y_n)$. But what does have for consequence in $\textbf{(1)} ??$ ** $\textbf{(ii)}\quad$ the probability density that $(Y_1,Y_2,...,Y_n)$ is equal to $y_{i_{1}},...,y_{i_{n}}$  is $\prod_{j=1}^{n}f(y_{i_{j}}) = \prod_{j=1}^{n}f(y_j)$ when $i_1,...i_n$ is a permutation of $1,2...,n$ ** here Iam completely lost;  the probability density that $(Y_1,Y_2,...,Y_n)$ is equal to $y_{i_{1}},...,y_{i_{n}}$ what do they mean? probability density (function)? I don't know what they mean at all with this statement",,"['probability', 'statistics', 'stochastic-processes']"
16,"Expectation number of cycles in a Erdős–Rényi random directed graph $G(n,p)$",Expectation number of cycles in a Erdős–Rényi random directed graph,"G(n,p)","Let $G \sim G(n,p)$ be a directed Erdős–Rényi random graph with $n$ vertices and the probability $p$ that  there is a directed edge between any two ordered pairs of vertices. What is the expected number of cycles in $G$? Is there an exact formula or an upper bound and lower bound on the expected number of simple cycles in $G$?","Let $G \sim G(n,p)$ be a directed Erdős–Rényi random graph with $n$ vertices and the probability $p$ that  there is a directed edge between any two ordered pairs of vertices. What is the expected number of cycles in $G$? Is there an exact formula or an upper bound and lower bound on the expected number of simple cycles in $G$?",,"['probability', 'graph-theory', 'expectation', 'random', 'random-graphs']"
17,Intuition behind Variance formula [duplicate],Intuition behind Variance formula [duplicate],,This question already has answers here : What's so special about standard deviation? (11 answers) Closed 5 years ago . Variance is given as: $\operatorname{Var}(X) = \mathbb{E}[(X-\mathbb{E}(X))^2]$. Is there an intuition behind this and can you find this formula starting from the second generating moment ?,This question already has answers here : What's so special about standard deviation? (11 answers) Closed 5 years ago . Variance is given as: $\operatorname{Var}(X) = \mathbb{E}[(X-\mathbb{E}(X))^2]$. Is there an intuition behind this and can you find this formula starting from the second generating moment ?,,"['probability', 'probability-distributions', 'intuition']"
18,Distribution of time spent above $0$ by a Brownian Bridge.,Distribution of time spent above  by a Brownian Bridge.,0,"Let's say I have a Brownian motion, such that I know its value at time 0 (0) and time T (also 0). I am trying to evaluate the time spent above 0 between time 0 and T. Obviously I know that the average of this value is 1/2, but is there a way to know the full law of that duration? Or are there other known theoretical results for this? I am guessing this is a fairly common problem but I am unable to find references for this. Thanks!","Let's say I have a Brownian motion, such that I know its value at time 0 (0) and time T (also 0). I am trying to evaluate the time spent above 0 between time 0 and T. Obviously I know that the average of this value is 1/2, but is there a way to know the full law of that duration? Or are there other known theoretical results for this? I am guessing this is a fairly common problem but I am unable to find references for this. Thanks!",,"['probability', 'stochastic-processes', 'simulation']"
19,Conditional Probability: Sheldon Ross Example 2h,Conditional Probability: Sheldon Ross Example 2h,,"The following question comes from Example 2h, in Sheldon Ross's textbook A First Course in Probability on page 64. I got the same answer as the author through a different line of reasoning (given at the end of the solution). However, I would really like to understand the reasoning given in this solution, if someone could elaborate that would be great! The question: An ordinary deck of 52 playing cards is randomly divided in 4 piles 13 cards in each pile. Compute the probability that each pile has an ace. The solution: We want to define four events for this problem : \begin{align*} E_{1}	&=	\{\text{The ace of spades in any one of the piles}\}\\ E_{2}	&=	\{\text{The ace of spades and the ace of hearts are in different piles}\}\\ E_{3}	&=	\{\text{The aces of spades, hearts, and diamonds are all in different piles}\}\\ E_{4}	&=	\{\text{All four of the aces are in different piles}\} \end{align*} The desired probability is $P(E_{1}E_{2}E_{3}E_{4})$ and by applying the multiplication rule, $$P(E_{1}E_{2}E_{3}E_{4})=P(E_{1})P(E_{2}|E_{1})\cdots P(E_{4}|E_{1}E_{2}E_{3})$$ Now, $$P(E_{1})=1$$ Since $E_1$ is in the sample space $S$. Also,  $$P(E_{2}|E_{1})=\frac{39}{51}$$ Since the pile containing the pile contain the ace of spades will contain 12 of the remaining 51 card, and  $$P(E_3 | E_1 E_2)=\frac{26}{50}$$ Since the piles containing the aces of spades and hearts will receive 24 of the remaining 50 cards. Finally, and finally,  $$P(E_4 | E_1 E_2 E_3)=\frac{13}{49}$$ Multiplying them all together we get  $$P( E_1 E_2 E_3 E_4) \approx 0.105$$ My Confusion: I don't quite understand the reasoning; it is clear that $P(E_1)$ is 1, because the ace of spades has to end up some where. But the the conditional probability has me confused; given the the ace of spades is in one pile I have 51 cards to choose from to put in any of the piles. There are $\binom{51}{39}$  ways that I can choose the 39 cards for the piles that don't contain the ace of spades. If I want to assure that I get the ace of hearts in one of the 3 piles that doesn't contain the ace of spades, I can set it aside. Then I am left to choose 38 from 50, there are  $\binom{50}{38}$ ways to do this. Then I have  $$\frac{\binom{50}{38}}{\binom{51}{39}}=\frac{39}{51}$$ And this same reasoning will lead to the same answer. I see benefit from not having to use the binomial coefficient, but I don't understand the soundness of the authors reasoning could someone elaborate on why his method works?","The following question comes from Example 2h, in Sheldon Ross's textbook A First Course in Probability on page 64. I got the same answer as the author through a different line of reasoning (given at the end of the solution). However, I would really like to understand the reasoning given in this solution, if someone could elaborate that would be great! The question: An ordinary deck of 52 playing cards is randomly divided in 4 piles 13 cards in each pile. Compute the probability that each pile has an ace. The solution: We want to define four events for this problem : \begin{align*} E_{1}	&=	\{\text{The ace of spades in any one of the piles}\}\\ E_{2}	&=	\{\text{The ace of spades and the ace of hearts are in different piles}\}\\ E_{3}	&=	\{\text{The aces of spades, hearts, and diamonds are all in different piles}\}\\ E_{4}	&=	\{\text{All four of the aces are in different piles}\} \end{align*} The desired probability is $P(E_{1}E_{2}E_{3}E_{4})$ and by applying the multiplication rule, $$P(E_{1}E_{2}E_{3}E_{4})=P(E_{1})P(E_{2}|E_{1})\cdots P(E_{4}|E_{1}E_{2}E_{3})$$ Now, $$P(E_{1})=1$$ Since $E_1$ is in the sample space $S$. Also,  $$P(E_{2}|E_{1})=\frac{39}{51}$$ Since the pile containing the pile contain the ace of spades will contain 12 of the remaining 51 card, and  $$P(E_3 | E_1 E_2)=\frac{26}{50}$$ Since the piles containing the aces of spades and hearts will receive 24 of the remaining 50 cards. Finally, and finally,  $$P(E_4 | E_1 E_2 E_3)=\frac{13}{49}$$ Multiplying them all together we get  $$P( E_1 E_2 E_3 E_4) \approx 0.105$$ My Confusion: I don't quite understand the reasoning; it is clear that $P(E_1)$ is 1, because the ace of spades has to end up some where. But the the conditional probability has me confused; given the the ace of spades is in one pile I have 51 cards to choose from to put in any of the piles. There are $\binom{51}{39}$  ways that I can choose the 39 cards for the piles that don't contain the ace of spades. If I want to assure that I get the ace of hearts in one of the 3 piles that doesn't contain the ace of spades, I can set it aside. Then I am left to choose 38 from 50, there are  $\binom{50}{38}$ ways to do this. Then I have  $$\frac{\binom{50}{38}}{\binom{51}{39}}=\frac{39}{51}$$ And this same reasoning will lead to the same answer. I see benefit from not having to use the binomial coefficient, but I don't understand the soundness of the authors reasoning could someone elaborate on why his method works?",,"['probability', 'combinatorics']"
20,Expected time for winning in biased Gambler's Ruin,Expected time for winning in biased Gambler's Ruin,,"Consider the random walk $X_0, X_1, X_2, \ldots$ on state space $S=\{0,1,\ldots,n\}$ with absorbing states $A=\{0,n\}$, and with $P(i,i+1)=p$ and $P(i,i-1)=q$ for all $i \in S \setminus A$, where $p+q=1$ and $p,q>0$. Let $T$ denote the number of steps until the walk is absorbed in either $0$ or $n$. Let $\mathbb{E}_k(\cdot) := \mathbb\{\cdot | X_0 = k\}$ denote the expectation conditioned on starting in state $k \in S \setminus A$. How to compute $\mathbb{E}_k(T|X_T = n)$?","Consider the random walk $X_0, X_1, X_2, \ldots$ on state space $S=\{0,1,\ldots,n\}$ with absorbing states $A=\{0,n\}$, and with $P(i,i+1)=p$ and $P(i,i-1)=q$ for all $i \in S \setminus A$, where $p+q=1$ and $p,q>0$. Let $T$ denote the number of steps until the walk is absorbed in either $0$ or $n$. Let $\mathbb{E}_k(\cdot) := \mathbb\{\cdot | X_0 = k\}$ denote the expectation conditioned on starting in state $k \in S \setminus A$. How to compute $\mathbb{E}_k(T|X_T = n)$?",,"['probability', 'markov-chains', 'random-walk']"
21,What is meant by closed under complementation?,What is meant by closed under complementation?,,"I was going through the probability and measure chapter of testing of hypothesis book by L.H. Lehman, where I found this ""A class of sets that contains Z and is closed under complementation and countable unions is a σ-field"". I was not able to understand closed under complementation in this matter. Any help would be appreciated.","I was going through the probability and measure chapter of testing of hypothesis book by L.H. Lehman, where I found this ""A class of sets that contains Z and is closed under complementation and countable unions is a σ-field"". I was not able to understand closed under complementation in this matter. Any help would be appreciated.",,"['probability', 'measure-theory']"
22,A number of die rolls to see every number at least once,A number of die rolls to see every number at least once,,"We have a fair die that can produce $n$ different numbers. How many times should we roll the die to see every number at least once with probability $p$ ? Not a homework, just interesting. Tried to solve myself but with no luck. I think it could be sort of coupon collector problem, but I can't get exact formula.","We have a fair die that can produce different numbers. How many times should we roll the die to see every number at least once with probability ? Not a homework, just interesting. Tried to solve myself but with no luck. I think it could be sort of coupon collector problem, but I can't get exact formula.",n p,"['probability', 'dice', 'coupon-collector']"
23,Gambling game: What is the probability of eventually going broke,Gambling game: What is the probability of eventually going broke,,"You find 2  dollars in your pocket and decide to go gambling. Fortunately, the game you're playing has very favourable odds: each time you play, you gain 1 dollar with probability 3/4 and lose $1 with probability 1/4. Suppose you continue playing so long as you have money in your pocket. If you lose your first two bets, you go broke and go home after only two rounds; but if you win forever, you'll play forever. What's the probability you'll eventually go broke? I think I am overthinking this: To go broke, you have to end on two Losses, which have p(L) = 1/4 Before the two losses there has to have been an even number of losses and win to have a balance of 2 dollars before the final two losses. $P(Broke)=\left( \dfrac {1}{4}\right) ^{2}\sum ^{\infty }_{i=0}\left( \dfrac {1}{4}\right) ^{i}\left( \dfrac {3}{4}\right) ^{i}N_{i}$ But then for each summand I need to multiply by the number of ways it is possible to get to an equal number of losses is without going broke beforehand. so for i = 1 LW and WL, are allowed, for i = 2 WLLW , WLWL, LWWL, LWLW, LLWW are allowed. So my final calculatin is $P(Broke) = \left( \dfrac {1}{4}\right) ^{2}\sum ^{\infty }_{i=0}\left( \dfrac {1}{4}\right) ^{i}\left( \dfrac {3}{4}\right) ^{i}\left( \begin{pmatrix} 2i \\ i \end{pmatrix}-\sum ^{i-1}_{k=1}\begin{pmatrix} 2k \\ n-1 \end{pmatrix}\right) $ But this doesn't equal anything and seems rather complicated.","You find 2  dollars in your pocket and decide to go gambling. Fortunately, the game you're playing has very favourable odds: each time you play, you gain 1 dollar with probability 3/4 and lose $1 with probability 1/4. Suppose you continue playing so long as you have money in your pocket. If you lose your first two bets, you go broke and go home after only two rounds; but if you win forever, you'll play forever. What's the probability you'll eventually go broke? I think I am overthinking this: To go broke, you have to end on two Losses, which have p(L) = 1/4 Before the two losses there has to have been an even number of losses and win to have a balance of 2 dollars before the final two losses. $P(Broke)=\left( \dfrac {1}{4}\right) ^{2}\sum ^{\infty }_{i=0}\left( \dfrac {1}{4}\right) ^{i}\left( \dfrac {3}{4}\right) ^{i}N_{i}$ But then for each summand I need to multiply by the number of ways it is possible to get to an equal number of losses is without going broke beforehand. so for i = 1 LW and WL, are allowed, for i = 2 WLLW , WLWL, LWWL, LWLW, LLWW are allowed. So my final calculatin is $P(Broke) = \left( \dfrac {1}{4}\right) ^{2}\sum ^{\infty }_{i=0}\left( \dfrac {1}{4}\right) ^{i}\left( \dfrac {3}{4}\right) ^{i}\left( \begin{pmatrix} 2i \\ i \end{pmatrix}-\sum ^{i-1}_{k=1}\begin{pmatrix} 2k \\ n-1 \end{pmatrix}\right) $ But this doesn't equal anything and seems rather complicated.",,"['probability', 'algebra-precalculus']"
24,Expected Value of Square Root of Poisson Random Variable,Expected Value of Square Root of Poisson Random Variable,,Find the expected value of $\sqrt{K}$ where $K$ is a random variable according to Poisson distribution with parameter $\lambda$. I don't know how to calculate the following sum: $E[\sqrt{K}]= e^{-\lambda} \sum_{k=0}^{\infty} \sqrt{k} \frac{\lambda^k}{k!} $ Based on Wiki ( https://en.wikipedia.org/wiki/Poisson_distribution ) I know that should be approximately $\sqrt{\lambda}$.,Find the expected value of $\sqrt{K}$ where $K$ is a random variable according to Poisson distribution with parameter $\lambda$. I don't know how to calculate the following sum: $E[\sqrt{K}]= e^{-\lambda} \sum_{k=0}^{\infty} \sqrt{k} \frac{\lambda^k}{k!} $ Based on Wiki ( https://en.wikipedia.org/wiki/Poisson_distribution ) I know that should be approximately $\sqrt{\lambda}$.,,"['probability', 'probability-theory', 'probability-distributions', 'expectation', 'poisson-distribution']"
25,Expected Value of Local Maxima and Local Minima,Expected Value of Local Maxima and Local Minima,,"Recently I came across this question: Given a random permutation of integers 1, 2, 3, …, n with a discrete, uniform distribution, find the expected number of local maxima. (A number is a local maxima if it is greater than the number before and after it.) For example, if n=4 and our permutation was 1, 4, 2, 3, then the # of local maxima would be 2 (both 4 and 3 are maxima). I know the answer will be (n+1)/3 .I wanted to know what will be the answer when we have to consider the local maxima as well as the local minima i.e Finding out the expected number of local maxima and local minima.","Recently I came across this question: Given a random permutation of integers 1, 2, 3, …, n with a discrete, uniform distribution, find the expected number of local maxima. (A number is a local maxima if it is greater than the number before and after it.) For example, if n=4 and our permutation was 1, 4, 2, 3, then the # of local maxima would be 2 (both 4 and 3 are maxima). I know the answer will be (n+1)/3 .I wanted to know what will be the answer when we have to consider the local maxima as well as the local minima i.e Finding out the expected number of local maxima and local minima.",,"['probability', 'probability-theory', 'discrete-mathematics', 'permutations', 'random-variables']"
26,Probability of duplicate GUID,Probability of duplicate GUID,,"A GUID (globally unique identifier) is a 32 character hexadecimal string: http://en.wikipedia.org/wiki/Globally_Unique_Identifier If you randomly generate 2, the chance of them being the same is incredibly small. But what if you generate 1,000,000, what are the chances there is 1 or more duplicates in those 1,000,000? What about 10,000,000, or 100,000,000 or even 1 billion?  Each new GUID has a chance to match all those previously inserted into the set. Graphs! Thanks to Rawlings answer we have the following graphs:","A GUID (globally unique identifier) is a 32 character hexadecimal string: http://en.wikipedia.org/wiki/Globally_Unique_Identifier If you randomly generate 2, the chance of them being the same is incredibly small. But what if you generate 1,000,000, what are the chances there is 1 or more duplicates in those 1,000,000? What about 10,000,000, or 100,000,000 or even 1 billion?  Each new GUID has a chance to match all those previously inserted into the set. Graphs! Thanks to Rawlings answer we have the following graphs:",,"['probability', 'statistics']"
27,"Bounding ""Jensen's Gap"": Elementary Approaches","Bounding ""Jensen's Gap"": Elementary Approaches",,"The point of this post is to explore some ""elementary"" but general ways one can quantify the ""gap"" in Jensen's inequality. Specifically, let $h:\mathbb R\rightarrow\mathbb R$ be a convex function and let $X$ be a real-valued random variable, then how can we bound $$?\leq \mathbb E\big[h(X)\big]-h\big(\mathbb EX\big)\leq ? $$ There does exist a good amount of research on this question, which i will detail in Section 2 of this post, but first i want to give a simple example to explain what i mean by (a) elementary and (b) a ""non-trivial bound"" on Jensen's gap: Section 1: Bounded Second Derivatives Suppose $h$ is twice differentiable and there exists a $\lambda>0$ such that $h''>\lambda$ . Then it is easily seen by computing second derivatives that the function $g(x)=h(x)-\frac12 \lambda x^2$ is convex. Thus, applying Jensen's inequality to $g$ yields $$\mathbb E\bigg[h(X)-\frac12\lambda X^2\bigg]\geq h\big(\mathbb EX\big)-\frac12 \lambda (\mathbb E X)^2$$ and rearranging gives $$\mathbb E\big[ h(X)\big]-h\big(\mathbb E X\big)\geq \frac12\lambda\bigg[\mathbb EX^2-(\mathbb EX)^2\bigg]=\frac12 \lambda \text{Var}(X).$$ Thus we have achieved a lower bound on Jensen's gap. Similarly, if we assume $h''<\Lambda$ then the same argument shows the upper bound $$\mathbb E\big[ h(X)\big]-h\big(\mathbb E X\big)\leq \frac12\Lambda \text{Var}(X).$$ (As a small remark, we technically have only used the assumption that $h-\frac12\lambda x^2$ is convex. This can be true even if $h$ is not twice differentiable) I hope you would agree that such a result is ""elementary"" in the sense that the condition on $h$ is both intuitive and likely easy to verify. The proof also is easily understood. The bound this achieves is meaningful in the sense that it uses some score of ""how strictly convex"" the function $h$ is (quantified by $\lambda$ ) and uses a simple property of the distribution of $X$ . Clearly these two types of information are the least we will need to obtain an interesting bound. I am essentially looking for arguments and results of similar simplicity that give you a bound on Jensen's gap. Section 2: Some existing Research Before i present some research papers, let me first refer to a few existing StackExchange posts about Jensen's gap: First, there is a question about the gap for $h(x)=\frac{1}{1+x}$ and $X\geq 0$ , which again finds a meaningful upper bound on the gap based on the first two moments of $X$ . There's a post about the minimal Eigenvalue of a Random Matrix , which again represents a concave function, where no good bound on the gap was found. Also worth noting is this post about $h(x)=|x|$ . Now to the interesting part: Here are two research papers i have found on this question: First, there is ""Bound on the Jensen Gap, and Implications for Mean-Concentrated Distributions"" . Among other things, it first mentions very elementary upper and lower bound the gap for $\alpha$ -Hölder-continuous functions $h$ based on the $\alpha$ -th moment $\mathbb E|X-\mathbb EX|^\alpha$ . Some nice examples where e.g. $h(x)=\log x$ or $h(x)=\sqrt x$ are also presented. Their main results (Theorem 2.1 and Theorem 3.1) seem to generalize the bound based on Hölder-continuity to some functions ""locally Hölder-continuous around the mean of $X$ "" As another example, there is ""Some new estimates of the ‘Jensen gap’"" . Their main results seem to be based on a condition on the Taylor series of the convex function $h$ . Though the result they obtain in Theorem 1 seems to be of a similar type to the result obtained in Section 1. Final Remarks: I want to reiterate that i am looking for elementary appraoches to this question, i.e. results where the conditions on $h$ and $X$ are easy to verify and ideally results with a concise proof. Section 2 was only there to have a ""reference post"" here on StackExchange for results on Jensen's gap.","The point of this post is to explore some ""elementary"" but general ways one can quantify the ""gap"" in Jensen's inequality. Specifically, let be a convex function and let be a real-valued random variable, then how can we bound There does exist a good amount of research on this question, which i will detail in Section 2 of this post, but first i want to give a simple example to explain what i mean by (a) elementary and (b) a ""non-trivial bound"" on Jensen's gap: Section 1: Bounded Second Derivatives Suppose is twice differentiable and there exists a such that . Then it is easily seen by computing second derivatives that the function is convex. Thus, applying Jensen's inequality to yields and rearranging gives Thus we have achieved a lower bound on Jensen's gap. Similarly, if we assume then the same argument shows the upper bound (As a small remark, we technically have only used the assumption that is convex. This can be true even if is not twice differentiable) I hope you would agree that such a result is ""elementary"" in the sense that the condition on is both intuitive and likely easy to verify. The proof also is easily understood. The bound this achieves is meaningful in the sense that it uses some score of ""how strictly convex"" the function is (quantified by ) and uses a simple property of the distribution of . Clearly these two types of information are the least we will need to obtain an interesting bound. I am essentially looking for arguments and results of similar simplicity that give you a bound on Jensen's gap. Section 2: Some existing Research Before i present some research papers, let me first refer to a few existing StackExchange posts about Jensen's gap: First, there is a question about the gap for and , which again finds a meaningful upper bound on the gap based on the first two moments of . There's a post about the minimal Eigenvalue of a Random Matrix , which again represents a concave function, where no good bound on the gap was found. Also worth noting is this post about . Now to the interesting part: Here are two research papers i have found on this question: First, there is ""Bound on the Jensen Gap, and Implications for Mean-Concentrated Distributions"" . Among other things, it first mentions very elementary upper and lower bound the gap for -Hölder-continuous functions based on the -th moment . Some nice examples where e.g. or are also presented. Their main results (Theorem 2.1 and Theorem 3.1) seem to generalize the bound based on Hölder-continuity to some functions ""locally Hölder-continuous around the mean of "" As another example, there is ""Some new estimates of the ‘Jensen gap’"" . Their main results seem to be based on a condition on the Taylor series of the convex function . Though the result they obtain in Theorem 1 seems to be of a similar type to the result obtained in Section 1. Final Remarks: I want to reiterate that i am looking for elementary appraoches to this question, i.e. results where the conditions on and are easy to verify and ideally results with a concise proof. Section 2 was only there to have a ""reference post"" here on StackExchange for results on Jensen's gap.",h:\mathbb R\rightarrow\mathbb R X ?\leq \mathbb E\big[h(X)\big]-h\big(\mathbb EX\big)\leq ?  h \lambda>0 h''>\lambda g(x)=h(x)-\frac12 \lambda x^2 g \mathbb E\bigg[h(X)-\frac12\lambda X^2\bigg]\geq h\big(\mathbb EX\big)-\frac12 \lambda (\mathbb E X)^2 \mathbb E\big[ h(X)\big]-h\big(\mathbb E X\big)\geq \frac12\lambda\bigg[\mathbb EX^2-(\mathbb EX)^2\bigg]=\frac12 \lambda \text{Var}(X). h''<\Lambda \mathbb E\big[ h(X)\big]-h\big(\mathbb E X\big)\leq \frac12\Lambda \text{Var}(X). h-\frac12\lambda x^2 h h h \lambda X h(x)=\frac{1}{1+x} X\geq 0 X h(x)=|x| \alpha h \alpha \mathbb E|X-\mathbb EX|^\alpha h(x)=\log x h(x)=\sqrt x X h h X,"['probability', 'measure-theory', 'inequality', 'convex-analysis', 'jensen-inequality']"
28,"Probability density function of $max(X,Y)$",Probability density function of,"max(X,Y)","Assume that we have a random variable $W = \max({X,Y})$ and that we would like to find the pdf of $W$ . This is what I have done. $$ F_W(w)= \mathbb{P}[ W\leq w]=\mathbb{P}[ \max({X,Y})\leq w]=\mathbb{P}[ X\leq w]\mathbb{P}[Y\leq w]= F_X(w)F_y(w) $$ then the pdf is $$f_W(w) = \frac{dF_W(w)}{dw}=\frac{d (F_X(w)F_y(w))}{dw}= f_x(w)F_y(w)+ f_y(w)F_x(w)$$ Is my reasoning correct? What if one want to find the distribution of $W = \min({X,Y})$ ?",Assume that we have a random variable and that we would like to find the pdf of . This is what I have done. then the pdf is Is my reasoning correct? What if one want to find the distribution of ?,"W = \max({X,Y}) W  F_W(w)= \mathbb{P}[ W\leq w]=\mathbb{P}[ \max({X,Y})\leq w]=\mathbb{P}[ X\leq w]\mathbb{P}[Y\leq w]= F_X(w)F_y(w)  f_W(w) = \frac{dF_W(w)}{dw}=\frac{d (F_X(w)F_y(w))}{dw}= f_x(w)F_y(w)+ f_y(w)F_x(w) W = \min({X,Y})","['probability', 'proof-verification', 'probability-distributions']"
29,What is the expected number of infected people?,What is the expected number of infected people?,,"I was recently in an interview and got asked an interesting problem which I want to know the answer to. Suppose we're in a party with $n$ people. At minute $t=0$ , there is $1$ person who has a contagious disease that is transferable by shaking hands. Every minute, every person in the party shakes hands with someone they haven't shook hands with yet randomly (i.e. if there are $k$ people he/she hasn't shaken hands with, then probability of shaking hands with any of them is $\frac{1}{k}$ ). Let $S(t)$ be the random variables of the number of people who have disease at minute $t$ . What is $S(t), \mathbb{E}(S)$ ? A followup question was if you could choose who shakes hands with who, how can you maximize $t^*$ , the minute where everyone is infected. In the interview, it was $n=1000$ , and I did some approximations manually and reached $664$ for the first problem until minute $t=10$ . Couldn't really answer the followup question that well. I am not even sure if this is a known probability distribution or not. Would appreciate an answer, thanks!","I was recently in an interview and got asked an interesting problem which I want to know the answer to. Suppose we're in a party with people. At minute , there is person who has a contagious disease that is transferable by shaking hands. Every minute, every person in the party shakes hands with someone they haven't shook hands with yet randomly (i.e. if there are people he/she hasn't shaken hands with, then probability of shaking hands with any of them is ). Let be the random variables of the number of people who have disease at minute . What is ? A followup question was if you could choose who shakes hands with who, how can you maximize , the minute where everyone is infected. In the interview, it was , and I did some approximations manually and reached for the first problem until minute . Couldn't really answer the followup question that well. I am not even sure if this is a known probability distribution or not. Would appreciate an answer, thanks!","n t=0 1 k \frac{1}{k} S(t) t S(t), \mathbb{E}(S) t^* n=1000 664 t=10","['probability', 'probability-distributions', 'stochastic-processes', 'reliability']"
30,Covariance of increasing functions of random variables,Covariance of increasing functions of random variables,,"Let $X$ be a random variable and $f, g: \mathbb{R} \rightarrow  \mathbb{R}$ be increasing functions. Show that $cov(f(X), g(X)) \ge  0$. The following hint was also provided: Assume $X$, $Y$ are independent and identically distributed, then show $E[(f(X)-f(Y))(g(X)-g(Y))] \ge 0$. My attempt: Since $f$ and $g$ are increasing, then $(f(x) - f(y))(g(x) - g(y)) \ge 0$ for all $x, y \in \mathbb{R}$. Thus, $E[(f(X) - f(Y))(g(X) - g(Y))] \ge 0$ by the monotonicity of expectations. Expanding, we get $E[f(X)g(X)]-E[f(X)g(Y)]-E[f(Y)g(X)]+E[f(Y)g(Y)] \ge 0$. Now due to independence, the LHS becomes $E[f(X)g(X)]-E[f(X)]E[g(Y)]-E[f(Y)]E[g(X)]+E[f(Y)g(Y)]$. Then due to identically distributed, the LHS further becomes $2E[f(X)g(X)]-2E[f(X)]E[g(X)]$. So together we have $2cov(f(X), g(X)) \ge 0$ and we are done. My main query: This whole proof relies on the fact that $X$ and $Y$ are i.i.d. How can we just simply assume this? If we didn't make this assumption, then we would never have been able to break up the expectations and collect like terms. Is this proof correct or do I need a proof that does not rely on the iid of $X$ and $Y$?","Let $X$ be a random variable and $f, g: \mathbb{R} \rightarrow  \mathbb{R}$ be increasing functions. Show that $cov(f(X), g(X)) \ge  0$. The following hint was also provided: Assume $X$, $Y$ are independent and identically distributed, then show $E[(f(X)-f(Y))(g(X)-g(Y))] \ge 0$. My attempt: Since $f$ and $g$ are increasing, then $(f(x) - f(y))(g(x) - g(y)) \ge 0$ for all $x, y \in \mathbb{R}$. Thus, $E[(f(X) - f(Y))(g(X) - g(Y))] \ge 0$ by the monotonicity of expectations. Expanding, we get $E[f(X)g(X)]-E[f(X)g(Y)]-E[f(Y)g(X)]+E[f(Y)g(Y)] \ge 0$. Now due to independence, the LHS becomes $E[f(X)g(X)]-E[f(X)]E[g(Y)]-E[f(Y)]E[g(X)]+E[f(Y)g(Y)]$. Then due to identically distributed, the LHS further becomes $2E[f(X)g(X)]-2E[f(X)]E[g(X)]$. So together we have $2cov(f(X), g(X)) \ge 0$ and we are done. My main query: This whole proof relies on the fact that $X$ and $Y$ are i.i.d. How can we just simply assume this? If we didn't make this assumption, then we would never have been able to break up the expectations and collect like terms. Is this proof correct or do I need a proof that does not rely on the iid of $X$ and $Y$?",,"['probability', 'expectation', 'covariance']"
31,Do the Kolmogorov's axioms permit speaking of frequencies of occurence in any meaningful sense?,Do the Kolmogorov's axioms permit speaking of frequencies of occurence in any meaningful sense?,,"It is frequently stated (in textbooks, on Wikipedia) that the ""Law of large numbers"" in mathematical probability theory is a statement about relative frequencies of occurrence of an event in a finite number of trials or that it ""relates the axiomatic concept of probability to the statistical concept of frequency"". Isn't this is a methodological mistake of ascribing an interpretation to a mathematical term, perhaps relying too much on the colorful language, that does not at all follow from how this term is mathematically defined? Recall the typical derivation of the WLLN: Let $X_1, X_2, ..., X_n$ be a sequence of n independent and identically distributed random variables with the same finite mean $\mu$, and with variance $\sigma^2$ and let: $\overline{X}=\tfrac1n(X_1+\cdots+X_n)$ We have: $E[\overline{X}] = \frac{E[X_1+...+X_n]}{n} = \frac{E[X_1]+...+E[X_n]}{n} =  \frac{n\mu}{n} = \mu$ $Var[\overline{X}] = \frac{Var[X_1+...+X_n]}{n^2} = \frac{Var[X_1]+...+Var[X_n]}{n^2} = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n}$ And from Chebyshev's inequality: $P(|\overline{X}-\mu|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ And so X is said to converge in probability to $\mu$. Now consider what is strictly speaking the meaning of this expression in the axiomatic framework it is derived in: $P(|\overline{X}-\mu|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ $P()$, everywhere it occurs in the derivation, is known only to be a number satisfying Kolmogorov's axioms, so a number between 0 and 1, and so forth, but none of the axioms introduce any theoretical equivalent of the intuitive notion of frequency. If additional assumptions about $P()$ are not made, the sentence can obviously not be interpreted at all, but what is also important the theoretical mean $\mu$ is not necessarily the mean value in an infinite number of trials, $\overline{X}$ is not necessarily the mean value from n trials, and so forth. Consider an experiment of tossing a fair coin repeatedly - quite obviously, nothing in Kolmogorov's axioms enforces using 1/2 for the probability of heads, you could just as well use $1/\sqrt{\pi}$, yet the derivation continues to ""work"", except the meaning of the various variables is not in agreement with their intuitive interpretations. The $P()$ might still mean something, it might be a quantification of an absurd belief of mine, the mathematical derivation continues be true regardless, in the sense that as long as the initial $P()'s$ satisfy axioms, theorems about other $P()'s$ follow, and with Kolmogorov's axioms providing only weak constraints on and not a definition of $P()$, it's basically only symbol manipulation. This ""relative frequency"" interpretation frequently given seems to rest on an additional assumption, and this assumption seems to be a form of the law of large numbers itself. Consider this fragment from Kolmogorov's Grundbegriffe on applying the results of probability theory to the real world: We apply the theory of probability to the actual world of experiment   in the following manner: ... 4) Under certain conditions, which we shall not discuss here, we may   assume that the event A which may or may not occur under conditions S,   is assigned a real number P(A) which has the following   characteristics: a) One can be practically certain that if the complex of conditions S   is repeated a large number of times, n, then if m be the number of   occurrences of event A, the ratio m/n will differ very slightly from   P(A). Which seems equivalent to introducing the weak law of large numbers in a particular, slightly different form, as an additional axiom. Meanwhile, many reputable sources contain statements that seem completely in opposition to the above reasoning, for example Wikipedia: It follows from the law of large numbers that the empirical   probability of success in a series of Bernoulli trials will converge   to the theoretical probability. For a Bernoulli random variable, the   expected value is the theoretical probability of success, and the   average of n such variables (assuming they are independent and   identically distributed (i.i.d.)) is precisely the relative frequency. This seem to be mistaken already in claiming that from a mathematical theorem anything can follow about empirical probability (the page on which defines it as the relative frequency in actual experiment), but there are many more subtle claims that technically also seem erroneous from the above considerations: The LLN is important because it ""guarantees"" stable long-term results for the averages of random events. Note that the Wikipedia article about LLN claims to be about the mathematical theorem, not about the empirical observation, which was also historically sometimes been called the LLN. It seems to me that LLN does nothing to ""guarantee stable long-term results"", for as stated above those stable long-term results have to be assumed in the first place for the terms occuring in the derivation to have the intuitive meaning we typically ascribe to them, not to mention something has to be done to at all interpret $P()$ in the first place. Another instance from Wikipedia: According to the law of large numbers, if a large number of six-sided die are rolled, the average of their values (sometimes called the sample mean) is likely to be close to 3.5, with the precision increasing as more dice are rolled. Does this really follow from the mathematical theorem? In my opinion, the interpretation of the theorem that is used here, rests on assuming this fact. There is a particularly vivid example in the ""Treatise on probability"" by Keynes of what happens when one follows the WLLN with even a slight deviation from this initial assumptions of p's being the relative frequencies in the limit of an infinite number of trials: The following example from Czuber will be   sufficient for the purpose of illustration. Czuber’s argument is as   follows: In the period 1866–1877 there were registered in Austria m = 4,311,076 male births n = 4,052,193 female births s = 8,363,269 for the succeeding period, 1877–1899, we are given only m' = 6,533,961 male births; what conclusion can we draw as to the number n of female births? We   can conclude, according to Czuber, that the most probable value n' = nm'/m = 6,141,587 and that there is a probability P = .9999779 that n will lie between   the limits 6,118,361 and 6,164,813. It seems in plain opposition to   good sense that on such evidence we should be able with practical   certainty P = .9999779 = 1 − 1/45250 to estimate the number of female   births within such narrow limits. And we see that the conditions laid   down in § 11 have been flagrantly neglected. The number of cases, over   which the prediction based on Bernoulli’s Theorem is to extend,   actually exceeds the number of cases upon which the à priori   probability has been based. It may be added that for the period,   1877–1894, the actual value of n did lie between the estimated limits,   but that for the period, 1895–1905, it lay outside limits to which the   same method had attributed practical certainty. Am I mistaken in my reasoning above, or are all those really mistakes in the Wikipedia? I have seen similar statements all over the place in textbooks, and I am honestly wondering what I am missing.","It is frequently stated (in textbooks, on Wikipedia) that the ""Law of large numbers"" in mathematical probability theory is a statement about relative frequencies of occurrence of an event in a finite number of trials or that it ""relates the axiomatic concept of probability to the statistical concept of frequency"". Isn't this is a methodological mistake of ascribing an interpretation to a mathematical term, perhaps relying too much on the colorful language, that does not at all follow from how this term is mathematically defined? Recall the typical derivation of the WLLN: Let $X_1, X_2, ..., X_n$ be a sequence of n independent and identically distributed random variables with the same finite mean $\mu$, and with variance $\sigma^2$ and let: $\overline{X}=\tfrac1n(X_1+\cdots+X_n)$ We have: $E[\overline{X}] = \frac{E[X_1+...+X_n]}{n} = \frac{E[X_1]+...+E[X_n]}{n} =  \frac{n\mu}{n} = \mu$ $Var[\overline{X}] = \frac{Var[X_1+...+X_n]}{n^2} = \frac{Var[X_1]+...+Var[X_n]}{n^2} = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n}$ And from Chebyshev's inequality: $P(|\overline{X}-\mu|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ And so X is said to converge in probability to $\mu$. Now consider what is strictly speaking the meaning of this expression in the axiomatic framework it is derived in: $P(|\overline{X}-\mu|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ $P()$, everywhere it occurs in the derivation, is known only to be a number satisfying Kolmogorov's axioms, so a number between 0 and 1, and so forth, but none of the axioms introduce any theoretical equivalent of the intuitive notion of frequency. If additional assumptions about $P()$ are not made, the sentence can obviously not be interpreted at all, but what is also important the theoretical mean $\mu$ is not necessarily the mean value in an infinite number of trials, $\overline{X}$ is not necessarily the mean value from n trials, and so forth. Consider an experiment of tossing a fair coin repeatedly - quite obviously, nothing in Kolmogorov's axioms enforces using 1/2 for the probability of heads, you could just as well use $1/\sqrt{\pi}$, yet the derivation continues to ""work"", except the meaning of the various variables is not in agreement with their intuitive interpretations. The $P()$ might still mean something, it might be a quantification of an absurd belief of mine, the mathematical derivation continues be true regardless, in the sense that as long as the initial $P()'s$ satisfy axioms, theorems about other $P()'s$ follow, and with Kolmogorov's axioms providing only weak constraints on and not a definition of $P()$, it's basically only symbol manipulation. This ""relative frequency"" interpretation frequently given seems to rest on an additional assumption, and this assumption seems to be a form of the law of large numbers itself. Consider this fragment from Kolmogorov's Grundbegriffe on applying the results of probability theory to the real world: We apply the theory of probability to the actual world of experiment   in the following manner: ... 4) Under certain conditions, which we shall not discuss here, we may   assume that the event A which may or may not occur under conditions S,   is assigned a real number P(A) which has the following   characteristics: a) One can be practically certain that if the complex of conditions S   is repeated a large number of times, n, then if m be the number of   occurrences of event A, the ratio m/n will differ very slightly from   P(A). Which seems equivalent to introducing the weak law of large numbers in a particular, slightly different form, as an additional axiom. Meanwhile, many reputable sources contain statements that seem completely in opposition to the above reasoning, for example Wikipedia: It follows from the law of large numbers that the empirical   probability of success in a series of Bernoulli trials will converge   to the theoretical probability. For a Bernoulli random variable, the   expected value is the theoretical probability of success, and the   average of n such variables (assuming they are independent and   identically distributed (i.i.d.)) is precisely the relative frequency. This seem to be mistaken already in claiming that from a mathematical theorem anything can follow about empirical probability (the page on which defines it as the relative frequency in actual experiment), but there are many more subtle claims that technically also seem erroneous from the above considerations: The LLN is important because it ""guarantees"" stable long-term results for the averages of random events. Note that the Wikipedia article about LLN claims to be about the mathematical theorem, not about the empirical observation, which was also historically sometimes been called the LLN. It seems to me that LLN does nothing to ""guarantee stable long-term results"", for as stated above those stable long-term results have to be assumed in the first place for the terms occuring in the derivation to have the intuitive meaning we typically ascribe to them, not to mention something has to be done to at all interpret $P()$ in the first place. Another instance from Wikipedia: According to the law of large numbers, if a large number of six-sided die are rolled, the average of their values (sometimes called the sample mean) is likely to be close to 3.5, with the precision increasing as more dice are rolled. Does this really follow from the mathematical theorem? In my opinion, the interpretation of the theorem that is used here, rests on assuming this fact. There is a particularly vivid example in the ""Treatise on probability"" by Keynes of what happens when one follows the WLLN with even a slight deviation from this initial assumptions of p's being the relative frequencies in the limit of an infinite number of trials: The following example from Czuber will be   sufficient for the purpose of illustration. Czuber’s argument is as   follows: In the period 1866–1877 there were registered in Austria m = 4,311,076 male births n = 4,052,193 female births s = 8,363,269 for the succeeding period, 1877–1899, we are given only m' = 6,533,961 male births; what conclusion can we draw as to the number n of female births? We   can conclude, according to Czuber, that the most probable value n' = nm'/m = 6,141,587 and that there is a probability P = .9999779 that n will lie between   the limits 6,118,361 and 6,164,813. It seems in plain opposition to   good sense that on such evidence we should be able with practical   certainty P = .9999779 = 1 − 1/45250 to estimate the number of female   births within such narrow limits. And we see that the conditions laid   down in § 11 have been flagrantly neglected. The number of cases, over   which the prediction based on Bernoulli’s Theorem is to extend,   actually exceeds the number of cases upon which the à priori   probability has been based. It may be added that for the period,   1877–1894, the actual value of n did lie between the estimated limits,   but that for the period, 1895–1905, it lay outside limits to which the   same method had attributed practical certainty. Am I mistaken in my reasoning above, or are all those really mistakes in the Wikipedia? I have seen similar statements all over the place in textbooks, and I am honestly wondering what I am missing.",,"['probability', 'probability-theory', 'logic', 'philosophy', 'foundations']"
32,Select a new value from last $N$ values; how long until the last $N$ are all the same?,Select a new value from last  values; how long until the last  are all the same?,N N,"Say first we have N distinct numbers in a line, like 1,2,3,...,N , in each round, we choose a random one from the last N numbers , and put it in the end. Asking the expected number of rounds to make the last N numbers the same. e.g. for N = 2, first we have 1, 2 and if we chose 1, we got 1, 2, 1 and the status stays the same, since the last N numbers still all distinct. and if we chose 2, we got 1, 2, 2 and the game ends. Suppose the expected number is S , we can write S = 1/2 * (S + 1) + 1/2 * (1) and we get S = 2 Things become very complicated when N > 2 , so I turn for help. UPDATE: this occurs to me when doing a project, see this if you are interested in. and i just wanna know whether it can be solved in a graceful way, or in a hard way but get the answer finally, so i don't need a numeric answer.","Say first we have N distinct numbers in a line, like 1,2,3,...,N , in each round, we choose a random one from the last N numbers , and put it in the end. Asking the expected number of rounds to make the last N numbers the same. e.g. for N = 2, first we have 1, 2 and if we chose 1, we got 1, 2, 1 and the status stays the same, since the last N numbers still all distinct. and if we chose 2, we got 1, 2, 2 and the game ends. Suppose the expected number is S , we can write S = 1/2 * (S + 1) + 1/2 * (1) and we get S = 2 Things become very complicated when N > 2 , so I turn for help. UPDATE: this occurs to me when doing a project, see this if you are interested in. and i just wanna know whether it can be solved in a graceful way, or in a hard way but get the answer finally, so i don't need a numeric answer.",,"['probability', 'combinatorics', 'random-walk', 'markov-process']"
33,Expected smallest prime factor,Expected smallest prime factor,,"For a random integer $x$ chosen uniformly between 2 and $n$, what is the expected value of the smallest prime factor of $x$ as a function of $n$? What is the behavior of the function as $n$ tends to infinity?","For a random integer $x$ chosen uniformly between 2 and $n$, what is the expected value of the smallest prime factor of $x$ as a function of $n$? What is the behavior of the function as $n$ tends to infinity?",,"['probability', 'prime-numbers', 'limits']"
34,I wrote a probability question I can't solve,I wrote a probability question I can't solve,,"$\newcommand{\nCk}[2]{{}^{#1}C_{#2}}$ I wrote this question to prep my students for their midterm, and I realized when I sat down to solve it that I can't figure out the right way to think about it. A costume shop has $7$ costumes available to rent, $4$ of each. You and $9$ friends go to the costume shop independently and each pick a costume. What is the probability you arrive at the party and there are exactly $5$ distinct costumes? (You are the only 10 guests) I know from simulation that the solution should be something like $0.232402$ , perhaps it is $\nCk{7}{5}\cdot 48\cdot\frac{\nCk{15}{5}}{\nCk{28}{10}}$ . I can justify the $\nCk{7}{5}$ and the $\nCk{15}{5}$ in the numerator, but not the $48$ . $\nCk{7}{5}$ because of the $7$ costumes $5$ are chosen. We need to ensure that $1$ of each are worn by $5$ guests, but the other $5$ are free to choose from the $15$ (hence $\nCk{15}{5}$ ). But I'm sure I'm thinking about this not quite right. I'd love any explanations. Thanks!","I wrote this question to prep my students for their midterm, and I realized when I sat down to solve it that I can't figure out the right way to think about it. A costume shop has costumes available to rent, of each. You and friends go to the costume shop independently and each pick a costume. What is the probability you arrive at the party and there are exactly distinct costumes? (You are the only 10 guests) I know from simulation that the solution should be something like , perhaps it is . I can justify the and the in the numerator, but not the . because of the costumes are chosen. We need to ensure that of each are worn by guests, but the other are free to choose from the (hence ). But I'm sure I'm thinking about this not quite right. I'd love any explanations. Thanks!",\newcommand{\nCk}[2]{{}^{#1}C_{#2}} 7 4 9 5 0.232402 \nCk{7}{5}\cdot 48\cdot\frac{\nCk{15}{5}}{\nCk{28}{10}} \nCk{7}{5} \nCk{15}{5} 48 \nCk{7}{5} 7 5 1 5 5 15 \nCk{15}{5},"['probability', 'combinations']"
35,The coupon collector's most collected coupon,The coupon collector's most collected coupon,,"Suppose a coupon collector is collecting a set of $n$ coupons that he receives one-by-one uniformly at random. If the collector stops exactly when the collection is complete, we know the expected number of coupons in his collection is $n*H[n]$ . What is the expected number of copies, $M$ , of his most collected coupon? When $n = 2$ , then $M = 2$ because after the first coupon he will collect the other coupon with probability p ~ Geom(1/2). So he will collect the same coupon one additional time on average, and that coupon is certain to be his most collected coupon. I don't know the exact value for any $n$ larger than 2, but found some approximate values by simulation: n M 3 2.8415 4 3.4992 5 4.0259 6 4.4633 7 4.8377 8 5.1649 9 5.4560 EDIT 1: For small n enumerating the small possibilities converges faster than simulation, and from this approach I hypothesize that $M[3] = (15 + 6 \sqrt{5})/10$ but don't have any real argument to support that claim. EDIT 2: With some more thought, I find that M has an explicit sum formula. The probability the collection terminates with a given distribution of coupons $v = \{c_1, ..., c_{n-1}\}$ other than the final collected coupon is just the multinomial coefficient $(c_1; ...; c_{n-1})$ over $n^\text{total # of coupons in the collection}$ . This is an infinite sum over n-1 variables. Here is Mathematica code the computes the sum for terms where the collection has no more than k copies of any coupon: M[n_, k_] := Sum[Max[v]*(Multinomial @@ v)/n^Total[v], {v, Tuples[Range[1, k], n-1]}] Mathematica can't actually evaluate this though for $k \rightarrow \infty$ though.","Suppose a coupon collector is collecting a set of coupons that he receives one-by-one uniformly at random. If the collector stops exactly when the collection is complete, we know the expected number of coupons in his collection is . What is the expected number of copies, , of his most collected coupon? When , then because after the first coupon he will collect the other coupon with probability p ~ Geom(1/2). So he will collect the same coupon one additional time on average, and that coupon is certain to be his most collected coupon. I don't know the exact value for any larger than 2, but found some approximate values by simulation: n M 3 2.8415 4 3.4992 5 4.0259 6 4.4633 7 4.8377 8 5.1649 9 5.4560 EDIT 1: For small n enumerating the small possibilities converges faster than simulation, and from this approach I hypothesize that but don't have any real argument to support that claim. EDIT 2: With some more thought, I find that M has an explicit sum formula. The probability the collection terminates with a given distribution of coupons other than the final collected coupon is just the multinomial coefficient over . This is an infinite sum over n-1 variables. Here is Mathematica code the computes the sum for terms where the collection has no more than k copies of any coupon: M[n_, k_] := Sum[Max[v]*(Multinomial @@ v)/n^Total[v], {v, Tuples[Range[1, k], n-1]}] Mathematica can't actually evaluate this though for though.","n n*H[n] M n = 2 M = 2 n M[3] = (15 + 6 \sqrt{5})/10 v = \{c_1, ..., c_{n-1}\} (c_1; ...; c_{n-1}) n^\text{total # of coupons in the collection} k \rightarrow \infty","['probability', 'combinatorics', 'expected-value', 'coupon-collector']"
36,Distribution of Dot-Product of Two Independent Multivariate Gaussian Vectors,Distribution of Dot-Product of Two Independent Multivariate Gaussian Vectors,,"Let $X,Y\stackrel{\text{i.i.d.}}{\sim}\mathcal{N}(0,I_d)$ , where $I_d$ is the $d$ -dimensional identity matrix. What is the distribution of $\langle X,Y\rangle=X^TY$ ? Approach 1: So far I know that for any $i\in\{1,...,d\}$ the MGF of $X_iY_i$ is: $$ M_{X_iY_i}(t)=\frac{1}{\sqrt{1-t^2}}. \qquad\left(=\arcsin'(t)\right) $$ The derivation of this can be found here . I've verified it - it's correct. Now, using the product-rule the MGF of $\langle X,Y\rangle$ is: $$ \begin{align*} M_{\langle X,Y\rangle}(t) &=\left(\frac{1}{\sqrt{1-t^2}}\right)^d \\ &=(1-t^2)^{-\frac{d}{2}} \\ &=(1-t^2)^{-\frac{d}{2}} \\ &=(1-t)^{-\frac{d}{2}}(1+t)^{-\frac{d}{2}} \end{align*} $$ Now I don't know how to continue from here. Maybe this product might as the product of two typical MGFs. In that case we could express it as the sum of two typical random variables... I don't know how to continue from here. Approach 2: Let $\theta$ denote the angle between the two random vectors $X$ , $Y$ . Then $$ \begin{align*} \langle X,Y\rangle &= \|X\|\|Y\|\cos(\theta) \\ &= \sqrt{\langle X,X \rangle}\sqrt{\langle Y,Y\rangle}\cos(\theta) \end{align*} $$ Now, $U:=\langle X,X\rangle\sim \chi^2(d)$ and $V:=\langle Y,Y\rangle\sim\chi^2(d)$ as one can easily verify. $$ \begin{align*} &= \sqrt{U\cdot V}\cos(\theta) \end{align*} $$ Now, $\cos(\theta)$ is distributed as the dot-product divided by the norms of the two random vectors $X,Y$ . So $\cos(\theta)$ is distributed as the dot-product of the corresponding random unit vectors of $X,Y$ . By rotational invariance of the dot-product, we may rotate both random unit vectors (corresponding to $X,Y$ ), such that one of the unit vectors has only the first coefficient being one. Hence, $\cos(\theta)$ is also distributed as the first-coefficient of a random unit vector. Since the angle between $X$ and $Y$ doesn't affect the outcome of $U$ and $V$ (since they're just the norms of the random vectors; so $\cos(\theta)$ is independent of $U$ and also $V$ ), we can model the randomness of $\cos(\theta)$ independently (as we've said through the first coefficient of a random unit vector). We model this random unit vector through sampling a random multivariate gaussian vector $Z\sim\mathcal{N}(0,I_d)$ that we then normalize. Then we just take its first coefficient. Now, w.l.o.g. we may also use Z:=X. So, $$ W:= \cos(\theta)\sim\frac{X_1}{\sqrt{\sum_{i=1}^d X_i^2}}. $$ And finally we have $$ \begin{align*} \langle X, Y\rangle &=\sqrt{U\cdot V}\cdot W \\ &=\sqrt{\langle X,X\rangle}\sqrt{V}\frac{X_1}{\sqrt{\langle X,X \rangle}} \\ &=\sqrt{V}X_1 \end{align*} $$ Now, we have the product of the square root of a chi-squared distributed variable and a standard normal random variable. Do you know if that gives any familiar distribution? Right now I'm building the product distribution - let's see what comes out. Approach 3: It's known that the dot product of two random unit vectors in $\mathbb{R^d}$ follows a $Beta((d-1)/2,(d-1)/2)$ distribution (see this post ). So, let $$ Z\sim Beta((d-1)/2,(d-1)/2) $$ Then we have that $$ \langle X,Y \rangle = Z*\|X\|\|Y\| $$ Where $\|X\|,\|Y\|\stackrel{\text{i.i.d.}}{\sim}\chi^2(d)$ . So we have that the dot-product is a product of a Beta-, and two Chi^2-distributed variables. That might help us to continue from here by building the product distribution. Sidenote: In the limit $d\to\infty$ we have that it approaches the normal distribution (see here , or Feller II (1971, p. 516, Theorem 2).","Let , where is the -dimensional identity matrix. What is the distribution of ? Approach 1: So far I know that for any the MGF of is: The derivation of this can be found here . I've verified it - it's correct. Now, using the product-rule the MGF of is: Now I don't know how to continue from here. Maybe this product might as the product of two typical MGFs. In that case we could express it as the sum of two typical random variables... I don't know how to continue from here. Approach 2: Let denote the angle between the two random vectors , . Then Now, and as one can easily verify. Now, is distributed as the dot-product divided by the norms of the two random vectors . So is distributed as the dot-product of the corresponding random unit vectors of . By rotational invariance of the dot-product, we may rotate both random unit vectors (corresponding to ), such that one of the unit vectors has only the first coefficient being one. Hence, is also distributed as the first-coefficient of a random unit vector. Since the angle between and doesn't affect the outcome of and (since they're just the norms of the random vectors; so is independent of and also ), we can model the randomness of independently (as we've said through the first coefficient of a random unit vector). We model this random unit vector through sampling a random multivariate gaussian vector that we then normalize. Then we just take its first coefficient. Now, w.l.o.g. we may also use Z:=X. So, And finally we have Now, we have the product of the square root of a chi-squared distributed variable and a standard normal random variable. Do you know if that gives any familiar distribution? Right now I'm building the product distribution - let's see what comes out. Approach 3: It's known that the dot product of two random unit vectors in follows a distribution (see this post ). So, let Then we have that Where . So we have that the dot-product is a product of a Beta-, and two Chi^2-distributed variables. That might help us to continue from here by building the product distribution. Sidenote: In the limit we have that it approaches the normal distribution (see here , or Feller II (1971, p. 516, Theorem 2).","X,Y\stackrel{\text{i.i.d.}}{\sim}\mathcal{N}(0,I_d) I_d d \langle X,Y\rangle=X^TY i\in\{1,...,d\} X_iY_i 
M_{X_iY_i}(t)=\frac{1}{\sqrt{1-t^2}}.
\qquad\left(=\arcsin'(t)\right)
 \langle X,Y\rangle 
\begin{align*}
M_{\langle X,Y\rangle}(t)
&=\left(\frac{1}{\sqrt{1-t^2}}\right)^d
\\
&=(1-t^2)^{-\frac{d}{2}}
\\
&=(1-t^2)^{-\frac{d}{2}}
\\
&=(1-t)^{-\frac{d}{2}}(1+t)^{-\frac{d}{2}}
\end{align*}
 \theta X Y 
\begin{align*}
\langle X,Y\rangle
&=
\|X\|\|Y\|\cos(\theta)
\\
&=
\sqrt{\langle X,X \rangle}\sqrt{\langle Y,Y\rangle}\cos(\theta)
\end{align*}
 U:=\langle X,X\rangle\sim \chi^2(d) V:=\langle Y,Y\rangle\sim\chi^2(d) 
\begin{align*}
&=
\sqrt{U\cdot V}\cos(\theta)
\end{align*}
 \cos(\theta) X,Y \cos(\theta) X,Y X,Y \cos(\theta) X Y U V \cos(\theta) U V \cos(\theta) Z\sim\mathcal{N}(0,I_d) 
W:=
\cos(\theta)\sim\frac{X_1}{\sqrt{\sum_{i=1}^d X_i^2}}.
 
\begin{align*}
\langle X, Y\rangle
&=\sqrt{U\cdot V}\cdot W
\\
&=\sqrt{\langle X,X\rangle}\sqrt{V}\frac{X_1}{\sqrt{\langle X,X \rangle}}
\\
&=\sqrt{V}X_1
\end{align*}
 \mathbb{R^d} Beta((d-1)/2,(d-1)/2) 
Z\sim Beta((d-1)/2,(d-1)/2)
 
\langle X,Y \rangle = Z*\|X\|\|Y\|
 \|X\|,\|Y\|\stackrel{\text{i.i.d.}}{\sim}\chi^2(d) d\to\infty","['probability', 'probability-distributions', 'moment-generating-functions']"
37,Is the zero set of Brownian motion homeomorphic to Cantor space?,Is the zero set of Brownian motion homeomorphic to Cantor space?,,"Let $(B_t)_{t\in[0,1]}$ be a standard Brownian motion and let $Z=\{t\in [0,1]\colon B_t=0\}$ denote its zero set. $Z$ is a topological space when given the induced topology from $[0,1]$. Let $C=\{0,1\}^{\mathbb N}$ denote the space of infinite binary sequences, equipped with the product topology. Does there exist a homeomorphism from $Z$ to $C$ with probability $1$? By considering ternary expansions of real numbers, it is easy to show that $C$ is homeomorphic to the standard ternary Cantor set. Also, $Z$ can be constructed in a manner roughly similar to the ternary Cantor set, by successively removing open intervals from $[0,1]$ with an increasing level of precision. On the other hand, $Z$ has Hausdorff dimension $1/2$ while the ternary Cantor set has Hausdorff dimension $\log_3 2$.","Let $(B_t)_{t\in[0,1]}$ be a standard Brownian motion and let $Z=\{t\in [0,1]\colon B_t=0\}$ denote its zero set. $Z$ is a topological space when given the induced topology from $[0,1]$. Let $C=\{0,1\}^{\mathbb N}$ denote the space of infinite binary sequences, equipped with the product topology. Does there exist a homeomorphism from $Z$ to $C$ with probability $1$? By considering ternary expansions of real numbers, it is easy to show that $C$ is homeomorphic to the standard ternary Cantor set. Also, $Z$ can be constructed in a manner roughly similar to the ternary Cantor set, by successively removing open intervals from $[0,1]$ with an increasing level of precision. On the other hand, $Z$ has Hausdorff dimension $1/2$ while the ternary Cantor set has Hausdorff dimension $\log_3 2$.",,"['probability', 'general-topology', 'brownian-motion', 'cantor-set', 'hausdorff-measure']"
38,What is the intuitive difference between almost sure convergence and convergence in probability? [duplicate],What is the intuitive difference between almost sure convergence and convergence in probability? [duplicate],,"This question already has an answer here : How to show a sequence of independent random variables do not almost surely converge by definition? (1 answer) Closed 8 years ago . It is a standard fact in probability that almost sure convergence is stronger than convergence in probability. I can only see the differences in the proof. However, is there a way to view it intuitively? Is it true that almost sure convergence has a tighter hold on the tails of a sequence of random variables than convergence in probability does? The definition of convergence in probability I am using is that given $\epsilon >0$: $$ \lim_{n \to \infty} P(|X_n-X|> \epsilon) = 0 $$ and the definition of almost sure convergence I am using is: $$ P(\lim_{n \to \infty}X_n = X) = P\left(\omega \in \Omega: \lim_{n \to \infty}X_n(\omega) = X(\omega)\right) = 1 $$ The two above appear almost exactly the same to me, except that the limit on $n$ is outside of convergence in probability and within the probability measure for almost sure convergence. Is there an easy to understand intuitive difference here? Thanks!","This question already has an answer here : How to show a sequence of independent random variables do not almost surely converge by definition? (1 answer) Closed 8 years ago . It is a standard fact in probability that almost sure convergence is stronger than convergence in probability. I can only see the differences in the proof. However, is there a way to view it intuitively? Is it true that almost sure convergence has a tighter hold on the tails of a sequence of random variables than convergence in probability does? The definition of convergence in probability I am using is that given $\epsilon >0$: $$ \lim_{n \to \infty} P(|X_n-X|> \epsilon) = 0 $$ and the definition of almost sure convergence I am using is: $$ P(\lim_{n \to \infty}X_n = X) = P\left(\omega \in \Omega: \lim_{n \to \infty}X_n(\omega) = X(\omega)\right) = 1 $$ The two above appear almost exactly the same to me, except that the limit on $n$ is outside of convergence in probability and within the probability measure for almost sure convergence. Is there an easy to understand intuitive difference here? Thanks!",,"['probability', 'probability-theory']"
39,How to tell is a matrix is a covariance matrix?,How to tell is a matrix is a covariance matrix?,,"How can we know that these matrices are valid covariance matrices? $$        C= \begin{pmatrix}              1 & -1 & 2 \\         -1 & 2 & -1 \\         2 & -1 &  1 \\         \end{pmatrix} \\        C= \begin{pmatrix}              4 & -1 & 1 \\         -1 & 4 & -1 \\         1 & -1 &  4 \\         \end{pmatrix} $$ I know that $C_{xy}=C_{yx}$ (is symmetric) $C_{xx}= \mathrm{Var}[x] \ge 0$ (the diagonal entries are all positive) But I want to know, are there any other properties?","How can we know that these matrices are valid covariance matrices? $$        C= \begin{pmatrix}              1 & -1 & 2 \\         -1 & 2 & -1 \\         2 & -1 &  1 \\         \end{pmatrix} \\        C= \begin{pmatrix}              4 & -1 & 1 \\         -1 & 4 & -1 \\         1 & -1 &  4 \\         \end{pmatrix} $$ I know that $C_{xy}=C_{yx}$ (is symmetric) $C_{xx}= \mathrm{Var}[x] \ge 0$ (the diagonal entries are all positive) But I want to know, are there any other properties?",,"['probability', 'matrices', 'covariance']"
40,Combinatorial Analysis: Fermat's Combinatorial Identity,Combinatorial Analysis: Fermat's Combinatorial Identity,,"I was looking through practice questions and need some guidance/assistance in Fermat's combinatorial identity. I read through this on the stack exchange, but the question was modified in the latest edition of my book. The book asks for a combinatorial argument (no computations needed) to establish the identity: $${n \choose k} = \sum_{i=k}^n {i-1 \choose k-1}   \text{ where }n\ge k$$ Hint given: Consider set of numbers $1$ through $n$, and how many subsets of size $k$ have $i$ as their highest numbered member? I'm still getting a grasp on the way these arguments work, so any help is greatly appreciated.","I was looking through practice questions and need some guidance/assistance in Fermat's combinatorial identity. I read through this on the stack exchange, but the question was modified in the latest edition of my book. The book asks for a combinatorial argument (no computations needed) to establish the identity: $${n \choose k} = \sum_{i=k}^n {i-1 \choose k-1}   \text{ where }n\ge k$$ Hint given: Consider set of numbers $1$ through $n$, and how many subsets of size $k$ have $i$ as their highest numbered member? I'm still getting a grasp on the way these arguments work, so any help is greatly appreciated.",,"['probability', 'combinatorics', 'binomial-coefficients']"
41,The vertices of a pentagram are five random points on a circle. Conjecture: The probability that the pentagram contains the circle's centre is $3/8$.,The vertices of a pentagram are five random points on a circle. Conjecture: The probability that the pentagram contains the circle's centre is .,3/8,"The vertices of a pentagram are five uniformly random points on a circle. Is the following conjecture true: The probability that the pentagram contains the circle's centre is $\frac38$ . (The pentagram is said to contain the circle's centre if the central pentagon, or any of the five triangles adjecent to the central pentagon, contains the circle's centre.) A simulation with $10^7$ such random pentagrams yielded a proportion of $0.3750079\approx1.00002\times\frac38$ containing the circle's centre. Thus, my conjecture. How to set up a simulation Let the circle be $x^2+y^2=1$ with centre $O\space(0,0)$ . Assume the first random point is $(1,0)$ and let the other four random points be, going anticlockwise from $(1,0)$ : $(\cos\theta_1,\sin\theta_1)$ , $(\cos\theta_2,\sin\theta_2)$ , $(\cos\theta_3,\sin\theta_3)$ , $(\cos\theta_4,\sin\theta_4)$ . Let $A,B,C,D,E$ be the five regions in the circle and outside the pentagram, going anticlockwise starting with the region between $(1,0)$ and $(\cos\theta_1,\sin\theta_1)$ . $O$ lies in $A$ if and only if $\theta_2>\pi,$ and $\theta_4-\theta_1<\pi$ . $O$ lies in $B$ if and only if $\theta_2>\pi,$ and $\theta_3-\theta_1>\pi$ . $O$ lies in $C$ if and only if $\theta_3-\theta_1>\pi$ , and $\theta_4-\theta_2>\pi$ . $O$ lies in $D$ if and only if $\theta_3<\pi,$ and $\theta_4-\theta_2>\pi$ . $O$ lies in $E$ if and only if $\theta_3<\pi,$ and $\theta_4-\theta_1<\pi$ . The pentagram contains $O$ just if $O$ lies in none of $A,B,C,D,E$ . If my conjecture is true, then, given the simplicity of the probability, there might be a proof based on some kind of symmetry.","The vertices of a pentagram are five uniformly random points on a circle. Is the following conjecture true: The probability that the pentagram contains the circle's centre is . (The pentagram is said to contain the circle's centre if the central pentagon, or any of the five triangles adjecent to the central pentagon, contains the circle's centre.) A simulation with such random pentagrams yielded a proportion of containing the circle's centre. Thus, my conjecture. How to set up a simulation Let the circle be with centre . Assume the first random point is and let the other four random points be, going anticlockwise from : , , , . Let be the five regions in the circle and outside the pentagram, going anticlockwise starting with the region between and . lies in if and only if and . lies in if and only if and . lies in if and only if , and . lies in if and only if and . lies in if and only if and . The pentagram contains just if lies in none of . If my conjecture is true, then, given the simplicity of the probability, there might be a proof based on some kind of symmetry.","\frac38 10^7 0.3750079\approx1.00002\times\frac38 x^2+y^2=1 O\space(0,0) (1,0) (1,0) (\cos\theta_1,\sin\theta_1) (\cos\theta_2,\sin\theta_2) (\cos\theta_3,\sin\theta_3) (\cos\theta_4,\sin\theta_4) A,B,C,D,E (1,0) (\cos\theta_1,\sin\theta_1) O A \theta_2>\pi, \theta_4-\theta_1<\pi O B \theta_2>\pi, \theta_3-\theta_1>\pi O C \theta_3-\theta_1>\pi \theta_4-\theta_2>\pi O D \theta_3<\pi, \theta_4-\theta_2>\pi O E \theta_3<\pi, \theta_4-\theta_1<\pi O O A,B,C,D,E","['probability', 'geometry', 'circles', 'conjectures', 'geometric-probability']"
42,Combinatorial reasoning in an expected value problem,Combinatorial reasoning in an expected value problem,,I saw this problem: There is an urn with $a$ red and $a$ blue balls. We are drawing from it without replacement until we have drawn all the blue balls (we know there are $a$ of them). What is the expected value of the number of balls remaining in the urn? This can be solved by taking $a+ (a-1) {a \choose 1} +  (a-2) {a+1 \choose 2}+\dotsb+1 {2a-2 \choose a-1 } $ and applying the identity $\sum_{i=0}^{k} {n+i \choose i}= {n+k+1 \choose k} $ multiple times. It gives $\frac {2a \choose a+1} {2a \choose a}$ which simplifies to $\frac {a}{a+1}$. Is there a reasoning that produces this result directly?,I saw this problem: There is an urn with $a$ red and $a$ blue balls. We are drawing from it without replacement until we have drawn all the blue balls (we know there are $a$ of them). What is the expected value of the number of balls remaining in the urn? This can be solved by taking $a+ (a-1) {a \choose 1} +  (a-2) {a+1 \choose 2}+\dotsb+1 {2a-2 \choose a-1 } $ and applying the identity $\sum_{i=0}^{k} {n+i \choose i}= {n+k+1 \choose k} $ multiple times. It gives $\frac {2a \choose a+1} {2a \choose a}$ which simplifies to $\frac {a}{a+1}$. Is there a reasoning that produces this result directly?,,"['probability', 'combinatorics', 'expectation']"
43,reference request for a book on high dimensional probability and data analysis written for mathematicians,reference request for a book on high dimensional probability and data analysis written for mathematicians,,"I hope someone can help with this. I am a statistician looking for a good book on high dimensional probability and data analysis. Basically I am looking for the equivalent of Terry Tao's 2 volume set on Analysis, but for high dimensional probability. Let me qualify what I am looking for. Now there are a bunch of books out there with these very words in the title. I will list some below. But most of these are geared towards just pure machine learning folks or computer science. So often books on high dimensional data focus on techniques like Principle Components Analysis or Lasso, etc., to analyze high dimensional data. In developing these models, the authors start off with strong parametric assumptions about exponential family distributions or independence, etc. These book lack any sort of organic development of a theory behind adding dimensions to a data set or changes in the patterns of symmetry as a data set grows larger--both in dimensions and in the number of observations. A basic probability text book will begin with a definition of random variables and work its way towards the Central Limit Theorem. While that is good for an intro stats course, there are a lot of problems with assuming normality even in high dimensional situations.  An example of such a book is: Geometric Structure of High-Dimensional Data and Dimensionality Reduction Statistics for High-Dimensional Data: Methods, Theory and Applications (Please note that I am not critizing any of the books mentioned. I am just saying that these books don't fit my particular need.) So what I am looking for is a more analytic look at how probability varies as dimensions get rather high. I use Terry Tao's book as an example of a wonderful development of analysis from basic foundations. I am looking for the same treatment for high dimensional data. I am not sure if I should be looking at a book on measure theory, or calculus on manifolds, or where? Any suggestions would really be appreciated.","I hope someone can help with this. I am a statistician looking for a good book on high dimensional probability and data analysis. Basically I am looking for the equivalent of Terry Tao's 2 volume set on Analysis, but for high dimensional probability. Let me qualify what I am looking for. Now there are a bunch of books out there with these very words in the title. I will list some below. But most of these are geared towards just pure machine learning folks or computer science. So often books on high dimensional data focus on techniques like Principle Components Analysis or Lasso, etc., to analyze high dimensional data. In developing these models, the authors start off with strong parametric assumptions about exponential family distributions or independence, etc. These book lack any sort of organic development of a theory behind adding dimensions to a data set or changes in the patterns of symmetry as a data set grows larger--both in dimensions and in the number of observations. A basic probability text book will begin with a definition of random variables and work its way towards the Central Limit Theorem. While that is good for an intro stats course, there are a lot of problems with assuming normality even in high dimensional situations.  An example of such a book is: Geometric Structure of High-Dimensional Data and Dimensionality Reduction Statistics for High-Dimensional Data: Methods, Theory and Applications (Please note that I am not critizing any of the books mentioned. I am just saying that these books don't fit my particular need.) So what I am looking for is a more analytic look at how probability varies as dimensions get rather high. I use Terry Tao's book as an example of a wonderful development of analysis from basic foundations. I am looking for the same treatment for high dimensional data. I am not sure if I should be looking at a book on measure theory, or calculus on manifolds, or where? Any suggestions would really be appreciated.",,"['probability', 'reference-request', 'soft-question', 'information-geometry']"
44,Reconciling two intuitions about convolution,Reconciling two intuitions about convolution,,"There are two intuitive things convolution does. In the time domain, it represents the distribution of the sum of two independent random variables. In the frequency domain, it's just multiplication. These seem sort of related but I can't make the connection. Is there a way to see one of these properties from the other?","There are two intuitive things convolution does. In the time domain, it represents the distribution of the sum of two independent random variables. In the frequency domain, it's just multiplication. These seem sort of related but I can't make the connection. Is there a way to see one of these properties from the other?",,"['probability', 'fourier-analysis', 'convolution']"
45,Monotone class theorem vs Dynkin $\pi-\lambda$ theorem,Monotone class theorem vs Dynkin  theorem,\pi-\lambda,"Monotone class theorem : Let $\mathcal C$ be a class of subset closed under finite   intersections and containing $\Omega$ (that is, $\mathcal C$ is a   $\pi$-system). Let $\mathcal B$ be the smallest class containing   $\mathcal C$ which is closed under increasing limits and by difference   (that is, $\mathcal B$ is the smallest $\lambda$ system containing $\mathcal C$). Then $\mathcal B =  \sigma(\mathcal C)$ Dynkin $\pi-\lambda$ theorem If $P$ is a $\pi$ system and $D$ is a $\lambda$ system with $P  \subseteq D$, then $\sigma(P) \subseteq D$ (Also, I believe that it can concluded that $D$ is a $\sigma$ algebra) It seems to me that they are basically the same thing. Dynking statement is slightly more general but more or less the same. Is it it true or am I misunderstanding something?","Monotone class theorem : Let $\mathcal C$ be a class of subset closed under finite   intersections and containing $\Omega$ (that is, $\mathcal C$ is a   $\pi$-system). Let $\mathcal B$ be the smallest class containing   $\mathcal C$ which is closed under increasing limits and by difference   (that is, $\mathcal B$ is the smallest $\lambda$ system containing $\mathcal C$). Then $\mathcal B =  \sigma(\mathcal C)$ Dynkin $\pi-\lambda$ theorem If $P$ is a $\pi$ system and $D$ is a $\lambda$ system with $P  \subseteq D$, then $\sigma(P) \subseteq D$ (Also, I believe that it can concluded that $D$ is a $\sigma$ algebra) It seems to me that they are basically the same thing. Dynking statement is slightly more general but more or less the same. Is it it true or am I misunderstanding something?",,"['probability', 'measure-theory', 'probability-theory', 'monotone-class-theorem']"
46,Is there a probabilistic proof of the inequality $4p(1-p) \leq 1$ for a probability $p$?,Is there a probabilistic proof of the inequality  for a probability ?,4p(1-p) \leq 1 p,"Let $p\in(0,1)$. The inequality $4p(1-p)\leq 1$ is very easy and elementary, but I wonder if there is a probabilistic proof of it. By that, I mean constructing a “natural” probability space and an event in it with probability $4p(1-p)$. This is easy to do if $4p(1-p)$ is replaced by $3p(1-p)$ : consider three i.i.d. variables $(X_1,X_2,X_3)$ with Bernoulli distribution ${\cal B}(p)$, and consider the event “The $X_i$ are not all equal”. Update : One thing that makes this problem hard is that there is no “discrete,finite” solution, involving only a set of $n$ i.i.d. variables $X_1,X_2,X_3,\ldots,X_n$ with Bernoulli distribution ${\cal B}(p)$ (this is because the inequality becomes an equality exactly when $p=\frac{1}{2}$).","Let $p\in(0,1)$. The inequality $4p(1-p)\leq 1$ is very easy and elementary, but I wonder if there is a probabilistic proof of it. By that, I mean constructing a “natural” probability space and an event in it with probability $4p(1-p)$. This is easy to do if $4p(1-p)$ is replaced by $3p(1-p)$ : consider three i.i.d. variables $(X_1,X_2,X_3)$ with Bernoulli distribution ${\cal B}(p)$, and consider the event “The $X_i$ are not all equal”. Update : One thing that makes this problem hard is that there is no “discrete,finite” solution, involving only a set of $n$ i.i.d. variables $X_1,X_2,X_3,\ldots,X_n$ with Bernoulli distribution ${\cal B}(p)$ (this is because the inequality becomes an equality exactly when $p=\frac{1}{2}$).",,"['probability', 'inequality']"
47,A man is known to speak truth 3 out of 4 times. He throws a die and reports that it is a six. Find the probability that it is actually a six.,A man is known to speak truth 3 out of 4 times. He throws a die and reports that it is a six. Find the probability that it is actually a six.,,"I have this question as an example in my maths school book. The solution given there is:- E = the man reports six P(S1)= Probability that six actually occurs = $\frac{1}{6}$ P(S2)= Probability that six doesn't occur= $\frac{5}{6}$ P(E|S1)= Probability that the man reports six when six has actually occurred = $\frac{3}{4}$ P(E|S2)= Probability that the man reports six when six has not occurred = $1-\frac 3 4=\frac 1 4$ Therefore, by Bayes' Theorem, $P(S1|E)=\frac{(\frac{1}{6}\cdot\frac{3}{4})}{(\frac{1}{6}\cdot \frac{3}{4})+(\frac{5}{6}\cdot \frac{1}{4})} =\frac{3}{8}  $ I have its solution but my teacher said that the solution given is incorrect and told that the actual solution would be something else:- $P(S1|E)=\frac{\frac 1 6\cdot\frac3 4}{(\frac 1 6\cdot \frac 3 4)+(\frac 5 6\cdot \frac1 4\cdot\frac1 5)} = \frac 3 4$ So, I want to ask which one is correct. Thank you.","I have this question as an example in my maths school book. The solution given there is:- E = the man reports six P(S1)= Probability that six actually occurs = P(S2)= Probability that six doesn't occur= P(E|S1)= Probability that the man reports six when six has actually occurred = P(E|S2)= Probability that the man reports six when six has not occurred = Therefore, by Bayes' Theorem, I have its solution but my teacher said that the solution given is incorrect and told that the actual solution would be something else:- So, I want to ask which one is correct. Thank you.",\frac{1}{6} \frac{5}{6} \frac{3}{4} 1-\frac 3 4=\frac 1 4 P(S1|E)=\frac{(\frac{1}{6}\cdot\frac{3}{4})}{(\frac{1}{6}\cdot \frac{3}{4})+(\frac{5}{6}\cdot \frac{1}{4})} =\frac{3}{8}   P(S1|E)=\frac{\frac 1 6\cdot\frac3 4}{(\frac 1 6\cdot \frac 3 4)+(\frac 5 6\cdot \frac1 4\cdot\frac1 5)} = \frac 3 4,"['probability', 'bayes-theorem']"
48,Derive Student T distribution using transformation theorem,Derive Student T distribution using transformation theorem,,"I am trying working on an exercise that asks me to show that If $ X_1 \in N(0,1) $ and $ X_2 \in \chi^2(n) $ are independent random variables, then $ X_1 / \sqrt{X_2/n} \in t(n) \, $ where $ \,t(n) $ is the student T distribution. This section of the book deals with functions of random variables and the transformation theorem (multivariate analogue of distribution function method) which is why I want to solve it specifically using that technique. I started by putting $$ Y_1 = g_1(X_1,X_2)=X_1/\sqrt{X_2/n} $$ $$ Y_2 = g_2(X_1,X_2)=X_2 $$ and making inverses $$ X_1=h_1(Y_1,Y_2)=Y_1\sqrt{Y_2/n} $$ $$ X_2=h_2(Y_1,Y_2)=Y_2. $$ From which I get the Jacobian $$ \begin{vmatrix}\sqrt{Y_2/n} & \frac{Y_1}{2n\sqrt{Y_2/n}}\\0 & 1\end{vmatrix}. $$ From there I want to use independence and calculate my density function as $$ f_{y_1y_2}(y_1,y_2)=f_{x_1}(\frac{Y_1}{\sqrt{Y_2/n}})*f_{x_2}(Y_2)*\sqrt{Y_2/n} $$ I think that this should then equal the $ t(n) $ density. But the result I'm getting appears to be incorrect. I would appreciate if someone could tell me if my way of thinking about this is just completely wrong or if I'm on the right track and might have made a calculation error or something else. Thank you.","I am trying working on an exercise that asks me to show that If $ X_1 \in N(0,1) $ and $ X_2 \in \chi^2(n) $ are independent random variables, then $ X_1 / \sqrt{X_2/n} \in t(n) \, $ where $ \,t(n) $ is the student T distribution. This section of the book deals with functions of random variables and the transformation theorem (multivariate analogue of distribution function method) which is why I want to solve it specifically using that technique. I started by putting $$ Y_1 = g_1(X_1,X_2)=X_1/\sqrt{X_2/n} $$ $$ Y_2 = g_2(X_1,X_2)=X_2 $$ and making inverses $$ X_1=h_1(Y_1,Y_2)=Y_1\sqrt{Y_2/n} $$ $$ X_2=h_2(Y_1,Y_2)=Y_2. $$ From which I get the Jacobian $$ \begin{vmatrix}\sqrt{Y_2/n} & \frac{Y_1}{2n\sqrt{Y_2/n}}\\0 & 1\end{vmatrix}. $$ From there I want to use independence and calculate my density function as $$ f_{y_1y_2}(y_1,y_2)=f_{x_1}(\frac{Y_1}{\sqrt{Y_2/n}})*f_{x_2}(Y_2)*\sqrt{Y_2/n} $$ I think that this should then equal the $ t(n) $ density. But the result I'm getting appears to be incorrect. I would appreciate if someone could tell me if my way of thinking about this is just completely wrong or if I'm on the right track and might have made a calculation error or something else. Thank you.",,"['probability', 'probability-distributions', 'random-variables', 'transformation']"
49,are elementary symmetric polynomials concave on probability distributions?,are elementary symmetric polynomials concave on probability distributions?,,"Let $S_{n,k}=\sum_{S\subset[n],|S|=k}\prod_{i\in S} x_i$ be the elementary symmetric polynomial of degree $k$ on $n$ variables.  Consider this polynomial as a function, in particular a function on probability distributions on $n$ items. It is not hard to see that this function is maximized at the uniform distribution.  I am wondering if there is a ""convexity""-based approach to show this.  Specifically, is $S_{n,k}$ concave on probability distributions on $n$ items?","Let $S_{n,k}=\sum_{S\subset[n],|S|=k}\prod_{i\in S} x_i$ be the elementary symmetric polynomial of degree $k$ on $n$ variables.  Consider this polynomial as a function, in particular a function on probability distributions on $n$ items. It is not hard to see that this function is maximized at the uniform distribution.  I am wondering if there is a ""convexity""-based approach to show this.  Specifically, is $S_{n,k}$ concave on probability distributions on $n$ items?",,"['probability', 'convex-optimization', 'lagrange-multiplier', 'symmetric-polynomials']"
50,Edge percolation on $\mathbb{Z}^2$: probability that two neighbouring vertices are connected?,Edge percolation on : probability that two neighbouring vertices are connected?,\mathbb{Z}^2,"I'm considering edge percolation on $\mathbb{Z}^2$ with parameter $p$, so that edges are present with probability $p$. Is it known how to express the probability $P(p)$ that $(0,0)$ is in the same connected component as $(1,0)$ as an explicit function of $p$? A very crude bound is $$ p \leqslant P(p) \leqslant 1-(1-p)^4, $$ but I'm sure people have derived better bounds, or even an exact expression. Simulations suggest that $P(1/2)$ is close to $3/4$. Thanks. Edit: The following is an approximation of the graph of the function $p\mapsto P(p)$ for $p=0,.01,\ldots,.82$.","I'm considering edge percolation on $\mathbb{Z}^2$ with parameter $p$, so that edges are present with probability $p$. Is it known how to express the probability $P(p)$ that $(0,0)$ is in the same connected component as $(1,0)$ as an explicit function of $p$? A very crude bound is $$ p \leqslant P(p) \leqslant 1-(1-p)^4, $$ but I'm sure people have derived better bounds, or even an exact expression. Simulations suggest that $P(1/2)$ is close to $3/4$. Thanks. Edit: The following is an approximation of the graph of the function $p\mapsto P(p)$ for $p=0,.01,\ldots,.82$.",,"['probability', 'connectedness', 'inclusion-exclusion', 'percolation']"
51,Counting certain paths,Counting certain paths,,"Suppose we wish to count the number (say $P(n)$ ) of lattice paths from $(0,0)$ to $(n,n)$ where at each step  one can make a move $1$ unit to the right or up, with the condition that every point $(k_1,k_2)$ obeys $k_2\geq\left\lceil\dfrac{k_1^2}{n}\right\rceil$ , that is, lies inside the parabola passing through $(0,0)$ , $(n,n)$ and $(-n,n)$ . How does one enumerate these, other than of course bashing with brute force code? Also, is there a good way (other than simulation) to estimate $\dfrac{P(n)}{\binom{2n}{n}}$ , or maybe $\displaystyle\lim_{n\to\infty}\dfrac{P(n)}{\binom{2n}{n}}$ ? IE the probability that a lattice path from $(0,0)$ to $(n,n)$ lies in the parabola. Is there a nice way to estimate this? Any help is appreciated!","Suppose we wish to count the number (say ) of lattice paths from to where at each step  one can make a move unit to the right or up, with the condition that every point obeys , that is, lies inside the parabola passing through , and . How does one enumerate these, other than of course bashing with brute force code? Also, is there a good way (other than simulation) to estimate , or maybe ? IE the probability that a lattice path from to lies in the parabola. Is there a nice way to estimate this? Any help is appreciated!","P(n) (0,0) (n,n) 1 (k_1,k_2) k_2\geq\left\lceil\dfrac{k_1^2}{n}\right\rceil (0,0) (n,n) (-n,n) \dfrac{P(n)}{\binom{2n}{n}} \displaystyle\lim_{n\to\infty}\dfrac{P(n)}{\binom{2n}{n}} (0,0) (n,n)","['probability', 'combinatorics']"
52,Convergence of probabilistic power tower $e^{\pm e^{\pm e^{...}}}$,Convergence of probabilistic power tower,e^{\pm e^{\pm e^{...}}},"While pondering over this question , I came across another interesting one. I am familiar with infinite tetration and its convergence over the reals. Nevertheless, when I saw this power tower, I couldn't help but wonder which distributions of $\pm$ signs make this converge or diverge. For instance: $$e^{-e^{-e^{...}}}={}^\infty(e^{-1})< \infty \\ e^{e^{e^{...}}}={}^\infty e \to \infty$$ Let's define $\forall n\geq 1,\epsilon_n \in {\pm 1}$ as the n th sign of the power tower $$P_\epsilon=e^{\epsilon_1e^{\epsilon_2e^{...}}}$$ defined recursively as $$ [P_\epsilon]_1(x) =e^{\epsilon_1 x}\\ [P_\epsilon]_{n+1}(x) = [P_\epsilon]_{n}(e^{\epsilon_{n+1} x})\\ [P_\epsilon]_n(e) = [P_\epsilon]_n\\ $$ Then, evidently, the first terms of $\epsilon_n$ are irrelevant, only the assymptotic behaviour is important. If we take $$\epsilon_n=\begin{cases}1&\text{for } n\equiv 0 \mod k \\-1 &\text{else }\end{cases}$$ would this converge for some $k$ ? Lastly, one can conjure of all sorts of patterns for these $(\epsilon_n)_{n\in \mathbb{N}}:$ what if the $(-1)$ s are only for prime indexes? What if $\epsilon$ is $−1$ with probability $(1−p)$ and $1$ with probability $p$ ? I think this last question is very interesting, but probably hard to solve. It would seem an important threshold occurs if the expected value $\mathbb{E}(\epsilon)=0$ , or $p=\frac{1}{2}$ , as the limit case for convergence is $${}^\infty(e^{e^{-1}})<\infty$$ My guess is, for $\epsilon$ with $\mathbb{E}(\epsilon)>0$ it will diverge a.s. and for $\mathbb{E}(\epsilon)<0$ it will converge a.s., but I have no idea on how to prove it. This reminds me a lot of Kolmogorov's three series theorem, although I doubt it can be solved in a similar manner. I hope I haven't missed something that would make this problem trivial, that would be very disappointing. Thanks! (feel free to edit to make it look better, or to add more appropriate tags) EDIT :This question has been edited to account for the non-associativity of exponentiation, a fact I, somehow, seemed to have momentarily forgotten.","While pondering over this question , I came across another interesting one. I am familiar with infinite tetration and its convergence over the reals. Nevertheless, when I saw this power tower, I couldn't help but wonder which distributions of signs make this converge or diverge. For instance: Let's define as the n th sign of the power tower defined recursively as Then, evidently, the first terms of are irrelevant, only the assymptotic behaviour is important. If we take would this converge for some ? Lastly, one can conjure of all sorts of patterns for these what if the s are only for prime indexes? What if is with probability and with probability ? I think this last question is very interesting, but probably hard to solve. It would seem an important threshold occurs if the expected value , or , as the limit case for convergence is My guess is, for with it will diverge a.s. and for it will converge a.s., but I have no idea on how to prove it. This reminds me a lot of Kolmogorov's three series theorem, although I doubt it can be solved in a similar manner. I hope I haven't missed something that would make this problem trivial, that would be very disappointing. Thanks! (feel free to edit to make it look better, or to add more appropriate tags) EDIT :This question has been edited to account for the non-associativity of exponentiation, a fact I, somehow, seemed to have momentarily forgotten.","\pm e^{-e^{-e^{...}}}={}^\infty(e^{-1})< \infty \\ e^{e^{e^{...}}}={}^\infty e \to \infty \forall n\geq 1,\epsilon_n \in {\pm 1} P_\epsilon=e^{\epsilon_1e^{\epsilon_2e^{...}}} 
[P_\epsilon]_1(x) =e^{\epsilon_1 x}\\ [P_\epsilon]_{n+1}(x) = [P_\epsilon]_{n}(e^{\epsilon_{n+1} x})\\ [P_\epsilon]_n(e) = [P_\epsilon]_n\\
 \epsilon_n \epsilon_n=\begin{cases}1&\text{for } n\equiv 0 \mod k \\-1 &\text{else }\end{cases} k (\epsilon_n)_{n\in \mathbb{N}}: (-1) \epsilon −1 (1−p) 1 p \mathbb{E}(\epsilon)=0 p=\frac{1}{2} {}^\infty(e^{e^{-1}})<\infty \epsilon \mathbb{E}(\epsilon)>0 \mathbb{E}(\epsilon)<0","['probability', 'convergence-divergence', 'power-towers']"
53,"Urn with an infinite number of balls of finite, uniformly distributed colours [duplicate]","Urn with an infinite number of balls of finite, uniformly distributed colours [duplicate]",,"This question already has an answer here : Magic 8 Ball Problem (1 answer) Closed 4 years ago . There's an urn with an infinite number of balls, from which one can draw as many times as one wants. The balls have $n$ different colours, and the probability a ball has a certain colour is $1/n$. For instance, if there are two colours, red and green, there's a 50% chance of a ball being red, but problem is that the number of colours is unknown. Given that a person has made $m$ draws, of which there are $m_1$ occurences of the colour $c_1$, $m_2$ occurences of the colour $c_2$ $\ldots$ $m_n$ occurences of colour $c_n$ (so that $m = m_1+m_2+\cdots+m_n$, not all necessarily non-zero), how can one estimate the total number of colours $n$? If there's only one colour ($n=1$), one would expect to draw $c_1c_1c_1c_1\cdots$, but after a finite number of draws, one would still only have a probability that there's only one colour, and never be certain. But intuitively, one should be able to exclude large $n$s with a high probability, so how would $\mathbb{P}(n\,|\,\underbrace{c_1,c_1,c_1,\ldots,c_1}_{m})$ be distributed, and how would the general case look like? $$ \mathbb{P}(n\,|\,\underbrace{c_1,\ldots,c_1}_{m_1},\underbrace{c_2,\ldots,c_2}_{m_2},\underbrace{c_n,\ldots,c_n}_{m_n})\quad\sim\quad? $$ There's a similar question here , however, this question doesn't assume that each colour is of equal probability.","This question already has an answer here : Magic 8 Ball Problem (1 answer) Closed 4 years ago . There's an urn with an infinite number of balls, from which one can draw as many times as one wants. The balls have $n$ different colours, and the probability a ball has a certain colour is $1/n$. For instance, if there are two colours, red and green, there's a 50% chance of a ball being red, but problem is that the number of colours is unknown. Given that a person has made $m$ draws, of which there are $m_1$ occurences of the colour $c_1$, $m_2$ occurences of the colour $c_2$ $\ldots$ $m_n$ occurences of colour $c_n$ (so that $m = m_1+m_2+\cdots+m_n$, not all necessarily non-zero), how can one estimate the total number of colours $n$? If there's only one colour ($n=1$), one would expect to draw $c_1c_1c_1c_1\cdots$, but after a finite number of draws, one would still only have a probability that there's only one colour, and never be certain. But intuitively, one should be able to exclude large $n$s with a high probability, so how would $\mathbb{P}(n\,|\,\underbrace{c_1,c_1,c_1,\ldots,c_1}_{m})$ be distributed, and how would the general case look like? $$ \mathbb{P}(n\,|\,\underbrace{c_1,\ldots,c_1}_{m_1},\underbrace{c_2,\ldots,c_2}_{m_2},\underbrace{c_n,\ldots,c_n}_{m_n})\quad\sim\quad? $$ There's a similar question here , however, this question doesn't assume that each colour is of equal probability.",,"['probability', 'statistics']"
54,Algorithm to compute the area of a convex set in 2 dimensions,Algorithm to compute the area of a convex set in 2 dimensions,,"I am interested in an algorithm to compute the area of a compact, convex body $K \subset \mathbb{R}^2$, up to an error $\epsilon > 0$. I am curious about the optimal running time of such an algorithm, but I would be happy with a simple algorithm that is provably close to the optimum. Specifically, you get the set $K$ in the form of a 'membership oracle,' which, for any $x \in \mathbb{R}^2$, tells you whether or not $x \in K$ for a cost $c$. Also, assume for simplicity that $K$ is contained in a fixed compact set, say the unit disk. Now fix an error $\epsilon > 0$: what is the running time (in terms of $\epsilon$ and $c$) to find an approximate answer $A$, i.e. $|A - area(K)| < \epsilon$? Here are some simple ideas, ranked according to how fast I believe them to be: 1) generate a lattice with sufficiently small mesh size, and count how many points belong to $K$. 2) Approximate the set by a convex polygon, and compute its area. I think the last step is (in theory) reasonably quick, via triangulating the polygon and summing the area of the triangles. 3) Determine an approximate boundary of $K$, then numerically integrate over the boundary and use Green's theorem to get the area. Also, I am OK with probabilistic algorithms: for example, one can run a Monte-Carlo simulation, i.e. sample points randomly according to area measure on the unit disk, and record how many land inside $K$. This should (I think) take time $O(c/\epsilon)$ with probability at least $1-\epsilon$. (This is essentially parameter estimation for a Bernoulli r.v.) I suspect this is actually optimal. I have found papers on this topic in arbitrary dimension, and some ideas/results for 2-D, but I have been unable to find the state of the art for 2-D. I would also be interested in a proof of any lower bound on the running time. Edit 1: I have done the analysis for method 2 above, namely approximating with a convex polygon and finding the area. The running time comes out to $O(\frac{c}{\epsilon} \log \frac{1}{\epsilon})$, which is pretty close to (what I expect to be) the optimum of $O(c/\epsilon)$. Edit 2: I have also done the analysis for method 1, i.e. just using a square mesh. I believe the running time comes out to $O(c \epsilon^{-2})$, which is worse than the convex polygon method. Basically this is because one has to check every square in the mesh (of which there are $\epsilon^{-2}$), while the other method 'finds' the boundary of $K$ in $-\log(\epsilon)$ time and does the area calculation on that set, which is length $\epsilon^{-1}$.","I am interested in an algorithm to compute the area of a compact, convex body $K \subset \mathbb{R}^2$, up to an error $\epsilon > 0$. I am curious about the optimal running time of such an algorithm, but I would be happy with a simple algorithm that is provably close to the optimum. Specifically, you get the set $K$ in the form of a 'membership oracle,' which, for any $x \in \mathbb{R}^2$, tells you whether or not $x \in K$ for a cost $c$. Also, assume for simplicity that $K$ is contained in a fixed compact set, say the unit disk. Now fix an error $\epsilon > 0$: what is the running time (in terms of $\epsilon$ and $c$) to find an approximate answer $A$, i.e. $|A - area(K)| < \epsilon$? Here are some simple ideas, ranked according to how fast I believe them to be: 1) generate a lattice with sufficiently small mesh size, and count how many points belong to $K$. 2) Approximate the set by a convex polygon, and compute its area. I think the last step is (in theory) reasonably quick, via triangulating the polygon and summing the area of the triangles. 3) Determine an approximate boundary of $K$, then numerically integrate over the boundary and use Green's theorem to get the area. Also, I am OK with probabilistic algorithms: for example, one can run a Monte-Carlo simulation, i.e. sample points randomly according to area measure on the unit disk, and record how many land inside $K$. This should (I think) take time $O(c/\epsilon)$ with probability at least $1-\epsilon$. (This is essentially parameter estimation for a Bernoulli r.v.) I suspect this is actually optimal. I have found papers on this topic in arbitrary dimension, and some ideas/results for 2-D, but I have been unable to find the state of the art for 2-D. I would also be interested in a proof of any lower bound on the running time. Edit 1: I have done the analysis for method 2 above, namely approximating with a convex polygon and finding the area. The running time comes out to $O(\frac{c}{\epsilon} \log \frac{1}{\epsilon})$, which is pretty close to (what I expect to be) the optimum of $O(c/\epsilon)$. Edit 2: I have also done the analysis for method 1, i.e. just using a square mesh. I believe the running time comes out to $O(c \epsilon^{-2})$, which is worse than the convex polygon method. Basically this is because one has to check every square in the mesh (of which there are $\epsilon^{-2}$), while the other method 'finds' the boundary of $K$ in $-\log(\epsilon)$ time and does the area calculation on that set, which is length $\epsilon^{-1}$.",,"['probability', 'computational-complexity', 'computational-mathematics', 'computational-geometry']"
55,Expectation of Last Remaining Container,Expectation of Last Remaining Container,,"You decide to play a holiday drinking game. You start with 100 containers of eggnog in a row. The 1st container contains 1 liter of eggnog, the 2nd contains 2 liters, all the way until the 100th, which contains 100 liters. You select a container uniformly at random and take a one liter sip from it. If the container is empty after taking this sip, you remove it from the row and select only from the remaining bottles. You continue this process until there is only 1 bottle remaining. What is the expected number of liters of eggnog in this last bottle? What is this as this as a function of n, the number of starting bottles? I came up with this problem myself recently, and I'm not really sure how to approach it. I can find the conditional expectation of a bottle given that it is the last one remaining using linearity of expectations, but it's not clear to me how to use this to get the overall expectation.","You decide to play a holiday drinking game. You start with 100 containers of eggnog in a row. The 1st container contains 1 liter of eggnog, the 2nd contains 2 liters, all the way until the 100th, which contains 100 liters. You select a container uniformly at random and take a one liter sip from it. If the container is empty after taking this sip, you remove it from the row and select only from the remaining bottles. You continue this process until there is only 1 bottle remaining. What is the expected number of liters of eggnog in this last bottle? What is this as this as a function of n, the number of starting bottles? I came up with this problem myself recently, and I'm not really sure how to approach it. I can find the conditional expectation of a bottle given that it is the last one remaining using linearity of expectations, but it's not clear to me how to use this to get the overall expectation.",,"['probability', 'expectation']"
56,$1/2$ or $1$? probability that all bacteria will die,or ? probability that all bacteria will die,1/2 1,"Suppose there is a bacterium in a bottle, it has $\frac{1}{3}$ chance to die and it has $\frac{2}{3}$ chance to split into 2 individuals, and the new individuals will follow this rule and so on. So here is the question, what is the probability that all bacteria are dead in the bottle? Denote by p the probability that all the bacteria are dead. $$ p =\frac{1}{3}+\frac{2}{3}p^2$$ and it gives that  $p = 0.5$ or $1$, so what is the next step? Which one is the answer? thanks.","Suppose there is a bacterium in a bottle, it has $\frac{1}{3}$ chance to die and it has $\frac{2}{3}$ chance to split into 2 individuals, and the new individuals will follow this rule and so on. So here is the question, what is the probability that all bacteria are dead in the bottle? Denote by p the probability that all the bacteria are dead. $$ p =\frac{1}{3}+\frac{2}{3}p^2$$ and it gives that  $p = 0.5$ or $1$, so what is the next step? Which one is the answer? thanks.",,['probability']
57,A samurai cuts a piece of bamboo,A samurai cuts a piece of bamboo,,"Suppose a samurai wants to try out his new sword and cuts a piece of bamboo twice, randomly, so now there are $3$ lenghts of bamboo. What is the probability of these 3 pieces being able to form a triangle? I have never came across a continuous probability problem before, but I tried doing it anyway and got a result of 0.25 probability. My solution: Let $L$ be the original lenght of the bamboo, $x$ be the place of the first cut and $y$ be the place of the second cut. Writing out all the 3 triangle inequalities, we come to the conclusion that no piece of bamboo can have more than $L/2$ lenght, then the probability we're looking for is: $$ \frac{\int_{x=0}^{L/2}(\int_{y=L/2}^{x+L/2}(1)dy)dx}{\int_{x=0}^{L}(\int_{y=x}^L(1)dy)dx}=0.25 $$","Suppose a samurai wants to try out his new sword and cuts a piece of bamboo twice, randomly, so now there are $3$ lenghts of bamboo. What is the probability of these 3 pieces being able to form a triangle? I have never came across a continuous probability problem before, but I tried doing it anyway and got a result of 0.25 probability. My solution: Let $L$ be the original lenght of the bamboo, $x$ be the place of the first cut and $y$ be the place of the second cut. Writing out all the 3 triangle inequalities, we come to the conclusion that no piece of bamboo can have more than $L/2$ lenght, then the probability we're looking for is: $$ \frac{\int_{x=0}^{L/2}(\int_{y=L/2}^{x+L/2}(1)dy)dx}{\int_{x=0}^{L}(\int_{y=x}^L(1)dy)dx}=0.25 $$",,['probability']
58,Number of cards to be pulled,Number of cards to be pulled,,"There is a game with $10$ cards(cards are number $1$ to $10$ ). They are distributed to $2$ players randomly. Player who has the highest sum of card values wins the game. Now, before the cards are dealt, player A will say a number. This number is the number of cards he will RANDOMLY pull from player B, and then return the cards of his choice to player B.(The cards returned cannot be the cards he has taken from player B). So, what is the number of cards player A should pull from player B to maximize his chances of winning the game? If Player A says $0$ , his winning probability remains at $0.5$ If Player A says $5$ , he takes all of B's card, and give all of his cards to B. His winning probability remains at $0.5$ again I assume that there is a unimodal winning probability with the peak at the centre. However, I am facing difficulty in which one of these $2$ will be larger and by how much? Part $2$ - Can this be generalised to ' $n$ ' cards?","There is a game with cards(cards are number to ). They are distributed to players randomly. Player who has the highest sum of card values wins the game. Now, before the cards are dealt, player A will say a number. This number is the number of cards he will RANDOMLY pull from player B, and then return the cards of his choice to player B.(The cards returned cannot be the cards he has taken from player B). So, what is the number of cards player A should pull from player B to maximize his chances of winning the game? If Player A says , his winning probability remains at If Player A says , he takes all of B's card, and give all of his cards to B. His winning probability remains at again I assume that there is a unimodal winning probability with the peak at the centre. However, I am facing difficulty in which one of these will be larger and by how much? Part - Can this be generalised to ' ' cards?",10 1 10 2 0 0.5 5 0.5 2 2 n,"['probability', 'combinatorics', 'permutations', 'card-games']"
59,Extinction probability in a population with competition,Extinction probability in a population with competition,,"Suppose we have a colony of bacteria. At the end of each day, each bacterium produces an exact copy of itself with probability $p$ and then dies with probability $q$ . However, $q$ is not constant, but a function of $N$ , the total number of bacteria: $$q=p\bigg(1-\frac{1}{N}\bigg)$$ So in larger populations of bacteria, each bacterium is more likely to die (because of competition, say). To clarify, $N$ counts the number of bacteria before new ones were born. For instance, if there are $2$ bacteria on one day and they both reproduce to form $4$ bacteria, both of them still have exactly $p/2$ chance of dying (not $3p/4$ ). And the babies that have just been born cannot die immediately. Let $P_N$ be the probability that a bacteria colony consisting of $N$ bacteria initially eventually goes extinct. Can we find an asymptotic formula for $P_N$ ? I suspect that we will have $$P_N\sim \alpha^N$$ for some $\alpha$ , but I don’t know how to calculate this constant. I did manage to figure out that if we keep $q$ constant, then the probability of eventual extinction starting with $N$ bacteria is exactly equal to $$\bigg(1-\frac{p-q}{p(1-q)}\bigg)^N$$ for $p>q$ , and equal to $1$ for $p\le q$ . But that problem was much easier because “newborn” bacteria were independent from their parents, whereas in this problem the chance of each bacterium’s survival is dependent on the overall population size. So, really my question is: what is the value of $$\lim_{N\to\infty}P_N^{1/N}=\space ?$$","Suppose we have a colony of bacteria. At the end of each day, each bacterium produces an exact copy of itself with probability and then dies with probability . However, is not constant, but a function of , the total number of bacteria: So in larger populations of bacteria, each bacterium is more likely to die (because of competition, say). To clarify, counts the number of bacteria before new ones were born. For instance, if there are bacteria on one day and they both reproduce to form bacteria, both of them still have exactly chance of dying (not ). And the babies that have just been born cannot die immediately. Let be the probability that a bacteria colony consisting of bacteria initially eventually goes extinct. Can we find an asymptotic formula for ? I suspect that we will have for some , but I don’t know how to calculate this constant. I did manage to figure out that if we keep constant, then the probability of eventual extinction starting with bacteria is exactly equal to for , and equal to for . But that problem was much easier because “newborn” bacteria were independent from their parents, whereas in this problem the chance of each bacterium’s survival is dependent on the overall population size. So, really my question is: what is the value of",p q q N q=p\bigg(1-\frac{1}{N}\bigg) N 2 4 p/2 3p/4 P_N N P_N P_N\sim \alpha^N \alpha q N \bigg(1-\frac{p-q}{p(1-q)}\bigg)^N p>q 1 p\le q \lim_{N\to\infty}P_N^{1/N}=\space ?,"['probability', 'limits', 'stochastic-processes', 'asymptotics']"
60,Showing $E(S^2\mid \bar X)=\bar X$ for i.i.d Poisson random variables $X_i$,Showing  for i.i.d Poisson random variables,E(S^2\mid \bar X)=\bar X X_i,"Let $X_1,X_2,\ldots,X_n$ be i.i.d $\text{P}(\lambda)$ random variables where $\lambda(>0)$ is unknown. Define $$\bar X=\frac{1}{n}\sum_{i=1}^n X_i\qquad,\qquad S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar X)^2$$ as the sample mean and sample variance respectively. Since $\sum_{i=1}^n X_i$ and hence $\bar X$ is a complete sufficient statistic for $\lambda$ such that $E(\bar X)=\lambda$, $\bar X$ is the uniformly minimum variance unbiased estimator (UMVUE) of $\lambda$ by the Lehmann-Scheffe theorem. Again, $E(S^2)=\lambda$, so that $E(S^2\mid \bar X)$ is also the UMVUE of $\lambda$. As UMVUE is unique whenever it exists, it must be that $$E(S^2\mid \bar X)=\bar X$$ The question is: How can I directly show that $E(S^2\mid \bar X)=\bar X$ ? I don't see how to proceed from \begin{align} E(S^2\mid \bar X=t)&=E\left[\frac{1}{n-1}\sum_{i=1}^n(X_i-t)^2\mid \bar X=t\right] \\&=E\left[\frac{1}{n-1}\left(\sum_{i=1}^nX_i^2-nt^2\right)\mid \bar X=t\right] \\&=E\left[\frac{1}{n-1}\sum_{i=1}^nX_i^2\mid \bar X=t\right]-E\left[\frac{nt^2}{n-1}\mid \bar X=t\right] \\&=\frac{1}{n-1}\sum_{i=1}^nE\left(X_i^2\mid \bar X=t\right)-\frac{n}{n-1}E(\bar X^2\mid \bar X=t)\tag{1} \end{align} Any hint would be great. As correctly pointed out by Mike Earnest, the conditional distribution of $(X_1,X_2,\cdots,X_n)\mid \bar X$ is multinomial. That is, for a natural number $k$, $$P\left(X_1=x_1,\cdots,X_n=x_n\mid \bar X=\frac{k}{n}\right)=\frac{k!}{x_1!\,x_2!\cdots x_n!}\left(\frac{1}{n}\right)^{x_1}\left(\frac{1}{n}\right)^{x_2}\cdots\left(\frac{1}{n}\right)^{x_n}\mathbf1_{x_i\in A}$$ , where $$A=\left\{(x_1,\cdots,x_n)\in\{0,1,\cdots,k\}: \sum_{i=1}^nx_i=k\right\}$$ From this , we have for each $i$, $$V\left(X_i\mid \bar X=t\right)=t\left(1-\frac{1}{n}\right)\qquad,\qquad E\left(X_i\mid \bar X=t\right)=t$$ And for all $i\ne j$, $$E\left(X_iX_j\mid \bar X=t\right)=t\left(t-\frac{1}{n}\right)$$ So, \begin{align} E\left(X_i^2\mid \bar X=t\right)&=V\left(X_i\mid \bar X=t\right)+\left[E\left(X_i\mid \bar X=t\right)\right]^2 \\&=\frac{t}{n}(n+nt-1) \end{align} Also, as expected, \begin{align} E\left(\bar X^2\mid \bar X=t\right)&=E\left[\frac{1}{n^2}\sum_{i=1}^n\sum_{j=1}^nX_iX_j\mid \bar X=t\right] \\&=\frac{1}{n}E\left(X_1^2\mid \bar X=t\right)+\frac{1}{n^2}\sum_{i\ne j}E\left[X_iX_j\mid \bar X=t\right] \\&=\frac{1}{n}\cdot\frac{t}{n}(n-1+nt)+\frac{2}{n^2}\binom{n}{2}t\left(t-\frac{1}{n}\right) \\&=t^2 \end{align} So from $(1)$ I finally get, \begin{align} E(S^2\mid \bar X=t)&=\frac{n}{n-1}\cdot\frac{t}{n}(n+nt-1)-\frac{n}{n-1}\cdot t^2 \\&=t \end{align} Hence proved. (Thanks to Mike Earnest in particular.)","Let $X_1,X_2,\ldots,X_n$ be i.i.d $\text{P}(\lambda)$ random variables where $\lambda(>0)$ is unknown. Define $$\bar X=\frac{1}{n}\sum_{i=1}^n X_i\qquad,\qquad S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar X)^2$$ as the sample mean and sample variance respectively. Since $\sum_{i=1}^n X_i$ and hence $\bar X$ is a complete sufficient statistic for $\lambda$ such that $E(\bar X)=\lambda$, $\bar X$ is the uniformly minimum variance unbiased estimator (UMVUE) of $\lambda$ by the Lehmann-Scheffe theorem. Again, $E(S^2)=\lambda$, so that $E(S^2\mid \bar X)$ is also the UMVUE of $\lambda$. As UMVUE is unique whenever it exists, it must be that $$E(S^2\mid \bar X)=\bar X$$ The question is: How can I directly show that $E(S^2\mid \bar X)=\bar X$ ? I don't see how to proceed from \begin{align} E(S^2\mid \bar X=t)&=E\left[\frac{1}{n-1}\sum_{i=1}^n(X_i-t)^2\mid \bar X=t\right] \\&=E\left[\frac{1}{n-1}\left(\sum_{i=1}^nX_i^2-nt^2\right)\mid \bar X=t\right] \\&=E\left[\frac{1}{n-1}\sum_{i=1}^nX_i^2\mid \bar X=t\right]-E\left[\frac{nt^2}{n-1}\mid \bar X=t\right] \\&=\frac{1}{n-1}\sum_{i=1}^nE\left(X_i^2\mid \bar X=t\right)-\frac{n}{n-1}E(\bar X^2\mid \bar X=t)\tag{1} \end{align} Any hint would be great. As correctly pointed out by Mike Earnest, the conditional distribution of $(X_1,X_2,\cdots,X_n)\mid \bar X$ is multinomial. That is, for a natural number $k$, $$P\left(X_1=x_1,\cdots,X_n=x_n\mid \bar X=\frac{k}{n}\right)=\frac{k!}{x_1!\,x_2!\cdots x_n!}\left(\frac{1}{n}\right)^{x_1}\left(\frac{1}{n}\right)^{x_2}\cdots\left(\frac{1}{n}\right)^{x_n}\mathbf1_{x_i\in A}$$ , where $$A=\left\{(x_1,\cdots,x_n)\in\{0,1,\cdots,k\}: \sum_{i=1}^nx_i=k\right\}$$ From this , we have for each $i$, $$V\left(X_i\mid \bar X=t\right)=t\left(1-\frac{1}{n}\right)\qquad,\qquad E\left(X_i\mid \bar X=t\right)=t$$ And for all $i\ne j$, $$E\left(X_iX_j\mid \bar X=t\right)=t\left(t-\frac{1}{n}\right)$$ So, \begin{align} E\left(X_i^2\mid \bar X=t\right)&=V\left(X_i\mid \bar X=t\right)+\left[E\left(X_i\mid \bar X=t\right)\right]^2 \\&=\frac{t}{n}(n+nt-1) \end{align} Also, as expected, \begin{align} E\left(\bar X^2\mid \bar X=t\right)&=E\left[\frac{1}{n^2}\sum_{i=1}^n\sum_{j=1}^nX_iX_j\mid \bar X=t\right] \\&=\frac{1}{n}E\left(X_1^2\mid \bar X=t\right)+\frac{1}{n^2}\sum_{i\ne j}E\left[X_iX_j\mid \bar X=t\right] \\&=\frac{1}{n}\cdot\frac{t}{n}(n-1+nt)+\frac{2}{n^2}\binom{n}{2}t\left(t-\frac{1}{n}\right) \\&=t^2 \end{align} So from $(1)$ I finally get, \begin{align} E(S^2\mid \bar X=t)&=\frac{n}{n-1}\cdot\frac{t}{n}(n+nt-1)-\frac{n}{n-1}\cdot t^2 \\&=t \end{align} Hence proved. (Thanks to Mike Earnest in particular.)",,"['probability', 'statistics', 'probability-distributions', 'conditional-expectation', 'poisson-distribution']"
61,"PDF of $X = \max\{X_1,X_2\}$, being $X_1$ and $X_2$ independent Normal distributed random variables","PDF of , being  and  independent Normal distributed random variables","X = \max\{X_1,X_2\} X_1 X_2","Let $X_1 \sim \mathcal{N}(\mu_1,\sigma_1^2)$ and $X_2 \sim \mathcal{N}(\mu_2,\sigma_2^2)$, what's the CDF of $X = \max\{X_1,X_2\}$? Both variables are assumed to be independent. I tried the following: \begin{equation} F_X(x) = \text{Prob}\{X<x\} = \text{Prob}\{X_1<x, X_2<x\} = \text{Prob}\{X_1<x\}\cdot \text{Prob}\{X_2<x\} = F_{X_1}(x)\cdot F_{X_2}(x) \end{equation} Since $X_1$ and $X_2$ are normal distributed variables, their CDFs are well known: \begin{equation} \tag{1} F_X(x) = F_{X_1}(x)\cdot F_{X_2}(x) = \bigg(1-\mathcal{Q}\Big(\frac{x-\mu_1}{\sigma_1}\Big)\bigg)\cdot \bigg(1-\mathcal{Q}\Big(\frac{x-\mu_2}{\sigma_2}\Big)\bigg) \end{equation} where $\mathcal{Q}\big(\frac{x-\mu}{\sigma}\big) = \int_x^{\infty} \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx$. However, MATLAB simulation shows that this is not correct. The MATLAB code and the plot result comparing simulation and theoretical is shown below. S=1e6;  % Define Normal Distributed RV #1 mu_1 = 1; sigma_1 = 1; X_1 = sigma_1/sqrt(2)*(randn(1,S))+mu_1;  % Define Normal Distributed RV #1 mu_2 = 1; sigma_2 = 1; X_2 = sigma_2/sqrt(2)*(randn(1,S))+mu_2;  % Define variable X = max{X_1,X_2} X = max(X_1,X_2); [X_pdf, X_var] = ecdf(X); % Obtain empirical CDF (similar to function hist)  X_pdf_th = (1-qfunc((X_var-mu_1)/sigma_1)).*(1-qfunc((X_var-mu_2)/sigma_2));  plot(X_var,X_pdf); hold on;grid on; plot(X_var,X_pdf_th,'r');  legend('Simulation CDF', 'Theory CDF'); hold off;","Let $X_1 \sim \mathcal{N}(\mu_1,\sigma_1^2)$ and $X_2 \sim \mathcal{N}(\mu_2,\sigma_2^2)$, what's the CDF of $X = \max\{X_1,X_2\}$? Both variables are assumed to be independent. I tried the following: \begin{equation} F_X(x) = \text{Prob}\{X<x\} = \text{Prob}\{X_1<x, X_2<x\} = \text{Prob}\{X_1<x\}\cdot \text{Prob}\{X_2<x\} = F_{X_1}(x)\cdot F_{X_2}(x) \end{equation} Since $X_1$ and $X_2$ are normal distributed variables, their CDFs are well known: \begin{equation} \tag{1} F_X(x) = F_{X_1}(x)\cdot F_{X_2}(x) = \bigg(1-\mathcal{Q}\Big(\frac{x-\mu_1}{\sigma_1}\Big)\bigg)\cdot \bigg(1-\mathcal{Q}\Big(\frac{x-\mu_2}{\sigma_2}\Big)\bigg) \end{equation} where $\mathcal{Q}\big(\frac{x-\mu}{\sigma}\big) = \int_x^{\infty} \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}} dx$. However, MATLAB simulation shows that this is not correct. The MATLAB code and the plot result comparing simulation and theoretical is shown below. S=1e6;  % Define Normal Distributed RV #1 mu_1 = 1; sigma_1 = 1; X_1 = sigma_1/sqrt(2)*(randn(1,S))+mu_1;  % Define Normal Distributed RV #1 mu_2 = 1; sigma_2 = 1; X_2 = sigma_2/sqrt(2)*(randn(1,S))+mu_2;  % Define variable X = max{X_1,X_2} X = max(X_1,X_2); [X_pdf, X_var] = ecdf(X); % Obtain empirical CDF (similar to function hist)  X_pdf_th = (1-qfunc((X_var-mu_1)/sigma_1)).*(1-qfunc((X_var-mu_2)/sigma_2));  plot(X_var,X_pdf); hold on;grid on; plot(X_var,X_pdf_th,'r');  legend('Simulation CDF', 'Theory CDF'); hold off;",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution']"
62,How long does it take for a given number of Minecraft sugar cane plants to grow to full size?,How long does it take for a given number of Minecraft sugar cane plants to grow to full size?,,"In Minecraft , the growth of sugar cane plants is governed by random events.  On each game tick (1/20th of a second), each sugar cane plant has a certain probability of advancing to the next stage of growth. The random event must occur 30 times for the plant to grow from 1-block tall to 3-blocks tall. My goal is to calculate the average amount of time required for a given number of sugar cane plants to all grow completely, if all of the plants are in the same field and planted simultaneously. Since many users at Math.SE might not know much about Minecraft sugar cane, I'm going to reformulate the problem in a more general way: We have a given number $N$ of weighted coins, each with the same probability $P$ of landing on heads.  Each coin is flipped until it lands on heads a given minimum $M$ number of times, and we count the number of flips required by each coin.  The time T is given by the number of flips required by the coin that took the most flips (it is the maximum out of the data set). What is the average value of $T$? When $N = 1$, it is clear that $T \approx M/P$.  When $P = 0.5$ (a fair coin) and $M = 3$, it will take an average of six flips for the coin to land on heads three times. In the case of sugar cane, my internet research tells me that $P = 3/4096$ and $M = 30$. This means that it takes an average of $40960$ game ticks for a single plant to grow completely. When $N > 1$, I don't know exactly how to approach the problem.  I've done some computer simulations, and by trying to fit curves to the data I found that it seems to follow this pattern:  $$T \approx f(M,P) \times \log(N) + M/P$$ The formula for $f(M,P)$ is unknown. Edit: For clarification, $N$ represents the number of sugar cane plants in the field.","In Minecraft , the growth of sugar cane plants is governed by random events.  On each game tick (1/20th of a second), each sugar cane plant has a certain probability of advancing to the next stage of growth. The random event must occur 30 times for the plant to grow from 1-block tall to 3-blocks tall. My goal is to calculate the average amount of time required for a given number of sugar cane plants to all grow completely, if all of the plants are in the same field and planted simultaneously. Since many users at Math.SE might not know much about Minecraft sugar cane, I'm going to reformulate the problem in a more general way: We have a given number $N$ of weighted coins, each with the same probability $P$ of landing on heads.  Each coin is flipped until it lands on heads a given minimum $M$ number of times, and we count the number of flips required by each coin.  The time T is given by the number of flips required by the coin that took the most flips (it is the maximum out of the data set). What is the average value of $T$? When $N = 1$, it is clear that $T \approx M/P$.  When $P = 0.5$ (a fair coin) and $M = 3$, it will take an average of six flips for the coin to land on heads three times. In the case of sugar cane, my internet research tells me that $P = 3/4096$ and $M = 30$. This means that it takes an average of $40960$ game ticks for a single plant to grow completely. When $N > 1$, I don't know exactly how to approach the problem.  I've done some computer simulations, and by trying to fit curves to the data I found that it seems to follow this pattern:  $$T \approx f(M,P) \times \log(N) + M/P$$ The formula for $f(M,P)$ is unknown. Edit: For clarification, $N$ represents the number of sugar cane plants in the field.",,['probability']
63,Two players roll the dice until the first repetition. Who is more likely to win?,Two players roll the dice until the first repetition. Who is more likely to win?,,"To give more details about the title question, assume that we have a collection of $n$ distinct elements. On each step, numbering from zero, we choose one of them uniformly at random (with replacement). I am interested in the distribution of the random variable $X_n$ indicating the moment when any element is selected a second time, i.e. the first collision . Specifically, I am interested in whether $X_n$ is more likely to be even or odd. It is easy to see that $$p_k(n) := \mbox{P}(X_n=k) = \Big(1-\frac{1}{n}\Big)\Big(1-\frac{2}{n}\Big) \dots \Big(1-\frac{k-1}{n}\Big)\cdot\frac{k}{n} = \binom{n-1}{k-1} \cdot \frac{k!}{n^k}$$ for all $1\le k \le n$ . I do not know if this distribution has a common name, but it is closely related to the birthday problem . In particular, it is known that the expected value $\mbox{E}(X_n)$ is asymptotically equal to $\sqrt{\frac{\pi}{2}n}$ for large $n$ , see e.g. this Math.SE post , Wikipedia , or the paper ' Bounds on Birthday Attack Times ' by Michael J. Wiener. Let $P_0(n)$ and $P_1(n)$ be the probabilities that $X_n$ is even and odd, respectively. Namely, we have $$ P_0(n) = \sum_{\substack{k=1 \\ k \scriptsize\mbox{ is even}}}^{n} p_k(n), \ \  \ P_1(n) = \sum_{\substack{k=1 \\ k \scriptsize\mbox{ is odd}}}^{n} p_k(n).$$ For $1 \le n \le 6$ , the values of $P_1(n)$ are equal to $1, \frac{1}{2}, \frac{5}{9}, \frac{17}{32}, \frac{329}{625}, \frac{169}{324}$ , respectively. This (and some more numerical experiments that I better not to show explicitly) suggest the following problem. Question Is it true, that for all $n>2$ , we have $P_1(n)>P_0(n)$ , i.e that $X_n$ is more likely to be odd than even? I think that numerical data supports an even stronger statement that $P_1(n) = \frac{1}{2}+\frac{1+o(1)}{8n}$ as $n \to \infty$ , but I don't know how to estimate this sum with such an accuracy. Finally, what happens if there are more than two 'players', i.e. if we look at $X_n \bmod m$ for some fixed $m>2$ (for instance, modulo 3)? Which residue would have an advantage in this case for large values of $n$ ?","To give more details about the title question, assume that we have a collection of distinct elements. On each step, numbering from zero, we choose one of them uniformly at random (with replacement). I am interested in the distribution of the random variable indicating the moment when any element is selected a second time, i.e. the first collision . Specifically, I am interested in whether is more likely to be even or odd. It is easy to see that for all . I do not know if this distribution has a common name, but it is closely related to the birthday problem . In particular, it is known that the expected value is asymptotically equal to for large , see e.g. this Math.SE post , Wikipedia , or the paper ' Bounds on Birthday Attack Times ' by Michael J. Wiener. Let and be the probabilities that is even and odd, respectively. Namely, we have For , the values of are equal to , respectively. This (and some more numerical experiments that I better not to show explicitly) suggest the following problem. Question Is it true, that for all , we have , i.e that is more likely to be odd than even? I think that numerical data supports an even stronger statement that as , but I don't know how to estimate this sum with such an accuracy. Finally, what happens if there are more than two 'players', i.e. if we look at for some fixed (for instance, modulo 3)? Which residue would have an advantage in this case for large values of ?","n X_n X_n p_k(n) := \mbox{P}(X_n=k) = \Big(1-\frac{1}{n}\Big)\Big(1-\frac{2}{n}\Big) \dots \Big(1-\frac{k-1}{n}\Big)\cdot\frac{k}{n} = \binom{n-1}{k-1} \cdot \frac{k!}{n^k} 1\le k \le n \mbox{E}(X_n) \sqrt{\frac{\pi}{2}n} n P_0(n) P_1(n) X_n  P_0(n) = \sum_{\substack{k=1 \\ k \scriptsize\mbox{ is even}}}^{n} p_k(n), \ \  \ P_1(n) = \sum_{\substack{k=1 \\ k \scriptsize\mbox{ is odd}}}^{n} p_k(n). 1 \le n \le 6 P_1(n) 1, \frac{1}{2}, \frac{5}{9}, \frac{17}{32}, \frac{329}{625}, \frac{169}{324} n>2 P_1(n)>P_0(n) X_n P_1(n) = \frac{1}{2}+\frac{1+o(1)}{8n} n \to \infty X_n \bmod m m>2 n","['probability', 'combinatorics', 'discrete-mathematics', 'summation', 'binomial-coefficients']"
64,Estimating the Number of Pokemon Without Knowing How Many There Are,Estimating the Number of Pokemon Without Knowing How Many There Are,,"I was imagining the following scenario: Suppose you are playing a Pokemon game for the first time and you don't know how many Pokemon are there. You spend some time playing today, encounter some random Pokemon, and record how many unique Pokemon you came across (e.g. you saw 15 total Pokemon, but only 8 of them were unique). Tomorrow, you spend some time playing and you encounter some Pokemon (e.g. 25, but only 7 were unique ) - now you record how many unique Pokemon you saw today and add these to the number of unique Pokemon you saw yesterday. You repeat this process a few times, and after collecting ""n"" number of samples, you have observed ""m"" number of unique samples. Using this information, are there any mathematical formulas that you can use to estimate the total number of Pokemon that might exist in the game? I am thinking that there might already exist some statistical/probability formulas that can be used for estimating the population size based on some finite samples, but so far I have not found any such formulas that can be directly used for this problem. I came across two somewhat related concepts in math ( https://en.wikipedia.org/wiki/German_tank_problem , https://en.wikipedia.org/wiki/Coupon_collector%27s_problem ), but I am not sure how to apply these concepts to this problem of estimating the number of Pokemon. To make things a little more concrete, I wrote some computer code (R programming language) that attempts to simulate this problem. Suppose we are playing the original Pokemon game and there are 150 Pokemon : library(dplyr) library(ggplot2)  pokemon_id = 1:150  pokemon_names = names = c(""Bulbasaur"",""Ivysaur"",""Venusaur"",""Charmander"",""Charmeleon"",""Charizard"",""Squirtle"",""Wartortle"",""Blastoise"",""Caterpie"",""Metapod"",""Butterfree"",""Weedle"",""Kakuna"",""Beedrill"",           ""Pidgey"",""Pidgeotto"",""Pidgeot"",""Rattata"",""Raticate"",""Spearow"",""Fearow"",""Ekans"",""Arbok"",""Pikachu"",""Raichu"",""Sandshrew"",""Sandslash"",""Nidoran"",""Nidorina"",""Nidoqueen"",""Nidorino"",""Nidoking"",           ""Clefairy"",""Clefable"",""Vulpix"",""Ninetales"",""Jigglypuff"",""Wigglytuff"",""Zubat"",""Golbat"",""Oddish"",""Gloom"",""Vileplume"",""Paras"",""Parasect"",""Venonat"",""Venomoth"",""Diglett"",""Dugtrio"",""Meowth"",""Persian"",           ""Psyduck"",""Golduck"",""Mankey"",""Primeape"",""Growlithe"",""Arcanine"",""Poliwag"",""Poliwhirl"",""Poliwrath"",""Abra"",""Kadabra"",""Alakazam"",""Machop"",""Machoke"",""Machamp"",""Bellsprout"",""Weepinbell"",""Victreebel"",""Tentacool"",           ""Tentacruel"",""Geodude"",""Graveler"",""Golem"",""Ponyta"",""Rapidash"",""Slowpoke"",""Slowbro"",""Magnemite"",""Magneton"",""Farfetch’d"",""Doduo"",""Dodrio"",""Seel"",""Dewgong"",""Grimer"",""Muk"",""Shellder"",""Cloyster"",""Gastly"",""Haunter"",           ""Gengar"",""Onix"",""Drowzee"",""Hypno"",""Krabby"",""Kingler"",""Voltorb"",""Electrode"",""Exeggcute"",""Exeggutor"",""Cubone"",""Marowak"",""Hitmonlee"",""Hitmonchan"",""Lickitung"",""Koffing"",""Weezing"",""Rhyhorn"",""Rhydon"",""Chansey"",""Tangela"",           ""Kangaskhan"",""Horsea"",""Seadra"",""Goldeen"",""Seaking"",""Staryu"",""Starmie"",""Mr.Mime"",""Scyther"",""Jynx"",""Electabuzz"",""Magmar"",""Pinsir"",""Tauros"",""Magikarp"",""Gyarados"",""Lapras"",""Ditto""           ,""Eevee"",""Vaporeon"",""Jolteon"",""Flareon"",""Porygon"",""Omanyte"",""Omastar"",""Kabuto"",""Kabutops"",""Aerodactyl"",""Snorlax"",""Articuno"",""Zapdos"",""Moltres"",""Dratini"",""Dragonair"",""Dragonite"",""Mewtwo"",""Mew"")  pokemon_data = data.frame(pokemon_id, pokemon_names) Now, suppose you have 20 days to play this game - each day, you encounter a random number of Pokemon and keep track which of these Pokemon were unique (note: In the real example, we don't know there are 150 Pokemon, but I have included this number to facilitate some of the calculations) : pokemon_function <- function() {    pokemon_results <- list()    for (i in 1:20) {      run_i <- i      pokemon_caught_i <- abs(sample.int(10, 1))     sample_i <- pokemon_data[sample(nrow(pokemon_data), pokemon_caught_i), ]     pokemon_tmp <- data.frame(run_i, sample_i)       pokemon_results[[i]] <- pokemon_tmp   }   results_df <- do.call(rbind.data.frame,   pokemon_results)    pokemon_int <- data.frame(results_df %>%                          group_by(pokemon_id) %>%                          filter(run_i == min(run_i)) %>%                          distinct)    pokemon_caught <- data.frame(pokemon_int %>%                                group_by(run_i) %>%                                summarise(Count=n()))    cumulative <- cumsum(pokemon_caught $Count)   pokemon_caught$ Cumulative <- cumulative   pokemon_caught$unseen <- 150 - cumulative   return(pokemon_caught) } We can now see how many (cumulative) unique Pokemon we encountered each day for 20 days (note: I am assuming that there is an equal probability of encountering any given Pokemon) : [1]  1 11 15 24 27 28 34 35 36 38 45 53 56 59 62 64 68 71 In theory, we could repeat this simulation experiment many times (e.g. 50 times) and visualize the results: #Repeat Simulation 50 Times:  final <- list() for (i in 1:50) {   round_i <- i   s_i <- pokemon_function()   final_tmp <- data.frame(round_i, s_i)   final[[i]] <- final_tmp }  visualization_file <- do.call(rbind.data.frame, final)  visualization_file $round_i = as.factor(visualization_file$ round_i)   g1 = ggplot(data=visualization_file, aes(x=run_i, y=Cumulative, group = round_i, colour = round_i)) + geom_line() +labs(y= ""Total Pokemon Seen"", x = ""Iterations"") +geom_point() + ggtitle(""Pokemon Simulation: Number of Unique Pokemon Seen in Different Simulations"")  g2 = ggplot(data=visualization_file, aes(x=run_i, y=unseen, group = round_i, colour = round_i)) + geom_line() +labs(y= ""Total Pokemon Not Seen"", x = ""Iterations"") +geom_point() + ggtitle(""Pokemon Simulation: Number of Unique Pokemon Not Seen in Different Simulations"") Obviously, with enough time, we would surely encounter every single unique Pokemon in this game.  But is there some mathematical formula that can be used to estimate the total number of Pokemon based on a single random sample? If I have the following measurements ( 1, 11 ,15 ,24 ,27 ,28 ,34 ,35, 36, 38, 45, 53, 56, 59, 62, 64, 68, 71) - is there some mathematical formula that can be used to estimate the total population size? Thank You!","I was imagining the following scenario: Suppose you are playing a Pokemon game for the first time and you don't know how many Pokemon are there. You spend some time playing today, encounter some random Pokemon, and record how many unique Pokemon you came across (e.g. you saw 15 total Pokemon, but only 8 of them were unique). Tomorrow, you spend some time playing and you encounter some Pokemon (e.g. 25, but only 7 were unique ) - now you record how many unique Pokemon you saw today and add these to the number of unique Pokemon you saw yesterday. You repeat this process a few times, and after collecting ""n"" number of samples, you have observed ""m"" number of unique samples. Using this information, are there any mathematical formulas that you can use to estimate the total number of Pokemon that might exist in the game? I am thinking that there might already exist some statistical/probability formulas that can be used for estimating the population size based on some finite samples, but so far I have not found any such formulas that can be directly used for this problem. I came across two somewhat related concepts in math ( https://en.wikipedia.org/wiki/German_tank_problem , https://en.wikipedia.org/wiki/Coupon_collector%27s_problem ), but I am not sure how to apply these concepts to this problem of estimating the number of Pokemon. To make things a little more concrete, I wrote some computer code (R programming language) that attempts to simulate this problem. Suppose we are playing the original Pokemon game and there are 150 Pokemon : library(dplyr) library(ggplot2)  pokemon_id = 1:150  pokemon_names = names = c(""Bulbasaur"",""Ivysaur"",""Venusaur"",""Charmander"",""Charmeleon"",""Charizard"",""Squirtle"",""Wartortle"",""Blastoise"",""Caterpie"",""Metapod"",""Butterfree"",""Weedle"",""Kakuna"",""Beedrill"",           ""Pidgey"",""Pidgeotto"",""Pidgeot"",""Rattata"",""Raticate"",""Spearow"",""Fearow"",""Ekans"",""Arbok"",""Pikachu"",""Raichu"",""Sandshrew"",""Sandslash"",""Nidoran"",""Nidorina"",""Nidoqueen"",""Nidorino"",""Nidoking"",           ""Clefairy"",""Clefable"",""Vulpix"",""Ninetales"",""Jigglypuff"",""Wigglytuff"",""Zubat"",""Golbat"",""Oddish"",""Gloom"",""Vileplume"",""Paras"",""Parasect"",""Venonat"",""Venomoth"",""Diglett"",""Dugtrio"",""Meowth"",""Persian"",           ""Psyduck"",""Golduck"",""Mankey"",""Primeape"",""Growlithe"",""Arcanine"",""Poliwag"",""Poliwhirl"",""Poliwrath"",""Abra"",""Kadabra"",""Alakazam"",""Machop"",""Machoke"",""Machamp"",""Bellsprout"",""Weepinbell"",""Victreebel"",""Tentacool"",           ""Tentacruel"",""Geodude"",""Graveler"",""Golem"",""Ponyta"",""Rapidash"",""Slowpoke"",""Slowbro"",""Magnemite"",""Magneton"",""Farfetch’d"",""Doduo"",""Dodrio"",""Seel"",""Dewgong"",""Grimer"",""Muk"",""Shellder"",""Cloyster"",""Gastly"",""Haunter"",           ""Gengar"",""Onix"",""Drowzee"",""Hypno"",""Krabby"",""Kingler"",""Voltorb"",""Electrode"",""Exeggcute"",""Exeggutor"",""Cubone"",""Marowak"",""Hitmonlee"",""Hitmonchan"",""Lickitung"",""Koffing"",""Weezing"",""Rhyhorn"",""Rhydon"",""Chansey"",""Tangela"",           ""Kangaskhan"",""Horsea"",""Seadra"",""Goldeen"",""Seaking"",""Staryu"",""Starmie"",""Mr.Mime"",""Scyther"",""Jynx"",""Electabuzz"",""Magmar"",""Pinsir"",""Tauros"",""Magikarp"",""Gyarados"",""Lapras"",""Ditto""           ,""Eevee"",""Vaporeon"",""Jolteon"",""Flareon"",""Porygon"",""Omanyte"",""Omastar"",""Kabuto"",""Kabutops"",""Aerodactyl"",""Snorlax"",""Articuno"",""Zapdos"",""Moltres"",""Dratini"",""Dragonair"",""Dragonite"",""Mewtwo"",""Mew"")  pokemon_data = data.frame(pokemon_id, pokemon_names) Now, suppose you have 20 days to play this game - each day, you encounter a random number of Pokemon and keep track which of these Pokemon were unique (note: In the real example, we don't know there are 150 Pokemon, but I have included this number to facilitate some of the calculations) : pokemon_function <- function() {    pokemon_results <- list()    for (i in 1:20) {      run_i <- i      pokemon_caught_i <- abs(sample.int(10, 1))     sample_i <- pokemon_data[sample(nrow(pokemon_data), pokemon_caught_i), ]     pokemon_tmp <- data.frame(run_i, sample_i)       pokemon_results[[i]] <- pokemon_tmp   }   results_df <- do.call(rbind.data.frame,   pokemon_results)    pokemon_int <- data.frame(results_df %>%                          group_by(pokemon_id) %>%                          filter(run_i == min(run_i)) %>%                          distinct)    pokemon_caught <- data.frame(pokemon_int %>%                                group_by(run_i) %>%                                summarise(Count=n()))    cumulative <- cumsum(pokemon_caught Cumulative <- cumulative   pokemon_caught$unseen <- 150 - cumulative   return(pokemon_caught) } We can now see how many (cumulative) unique Pokemon we encountered each day for 20 days (note: I am assuming that there is an equal probability of encountering any given Pokemon) : [1]  1 11 15 24 27 28 34 35 36 38 45 53 56 59 62 64 68 71 In theory, we could repeat this simulation experiment many times (e.g. 50 times) and visualize the results: #Repeat Simulation 50 Times:  final <- list() for (i in 1:50) {   round_i <- i   s_i <- pokemon_function()   final_tmp <- data.frame(round_i, s_i)   final[[i]] <- final_tmp }  visualization_file <- do.call(rbind.data.frame, final)  visualization_file round_i)   g1 = ggplot(data=visualization_file, aes(x=run_i, y=Cumulative, group = round_i, colour = round_i)) + geom_line() +labs(y= ""Total Pokemon Seen"", x = ""Iterations"") +geom_point() + ggtitle(""Pokemon Simulation: Number of Unique Pokemon Seen in Different Simulations"")  g2 = ggplot(data=visualization_file, aes(x=run_i, y=unseen, group = round_i, colour = round_i)) + geom_line() +labs(y= ""Total Pokemon Not Seen"", x = ""Iterations"") +geom_point() + ggtitle(""Pokemon Simulation: Number of Unique Pokemon Not Seen in Different Simulations"") Obviously, with enough time, we would surely encounter every single unique Pokemon in this game.  But is there some mathematical formula that can be used to estimate the total number of Pokemon based on a single random sample? If I have the following measurements ( 1, 11 ,15 ,24 ,27 ,28 ,34 ,35, 36, 38, 45, 53, 56, 59, 62, 64, 68, 71) - is there some mathematical formula that can be used to estimate the total population size? Thank You!","Count)
  pokemon_caught round_i = as.factor(visualization_file","['probability', 'statistics']"
65,"Two random variables $X,Y$ such that $X+Y$ has the same distribution as $X$",Two random variables  such that  has the same distribution as,"X,Y X+Y X","Let $X$ and $Y$ be two almost surely finite real-valued random variables which are not necessarily independent. Assume that $X$ is non-negative and $Y$ has a finite, positive mean. Is it possible that $X+Y$ has the same distribution as $X$ ? Note that this is trivial if $\mathbb E(X) < \infty$ , so we can restrict attention to the case when $\mathbb E(X) = \infty$ . It is also easy to prove using characteristic functions if $X$ and $Y$ are independent, but I am interested in the case when they are not independent.","Let and be two almost surely finite real-valued random variables which are not necessarily independent. Assume that is non-negative and has a finite, positive mean. Is it possible that has the same distribution as ? Note that this is trivial if , so we can restrict attention to the case when . It is also easy to prove using characteristic functions if and are independent, but I am interested in the case when they are not independent.",X Y X Y X+Y X \mathbb E(X) < \infty \mathbb E(X) = \infty X Y,"['probability', 'probability-theory']"
66,Are all almost virtually free groups word hyperbolic?,Are all almost virtually free groups word hyperbolic?,,"Suppose $G$ is a finitely generated group with a finite symmetric generating set $A$ . Lets define Cayley ball $B_A^n := (A \cup \{e\})^n$ as the set of all elements with Cayley length (in respect to $A$ ) $n$ or less. Suppose $R_1, … , R_k$ are $k$ random elements chosen uniformly from $B_A^n$ . Then we can define a random $k$ -generated subgroup of $G$ as $H(G, A, k, n) = \langle \{R_1, … , R_k\} \rangle$ . Now, suppose, $\mathfrak{X}$ is some group property closed under finitely-generated subgroups. We say, that  a finitely generated group $G := \langle A \rangle$ is almost $\mathfrak{X}$ iff $\forall k \in \mathbb{N} \lim_{n \to \infty} P(H(G, A, k, n)) = 1$ . The following facts are not hard to see: The definition does not depend on the choice of $A$ The property of being almost $\mathfrak{X}$ is closed under finitely-generated subgroups A group is almost almost $\mathfrak{X}$ iff it is almost $\mathfrak{X}$ Moreover, a following fact was proved by Gilman, Miasnikov and Osin in «Exponentially generic subsets of groups»: Any word hyperbolic group is either almost free or virtually cyclic An easy corollary of this statement is: All word hyperbolic groups are almost virtually free My question is whether the converse is also true: Are all almost virtually free groups word hyperbolic?","Suppose is a finitely generated group with a finite symmetric generating set . Lets define Cayley ball as the set of all elements with Cayley length (in respect to ) or less. Suppose are random elements chosen uniformly from . Then we can define a random -generated subgroup of as . Now, suppose, is some group property closed under finitely-generated subgroups. We say, that  a finitely generated group is almost iff . The following facts are not hard to see: The definition does not depend on the choice of The property of being almost is closed under finitely-generated subgroups A group is almost almost iff it is almost Moreover, a following fact was proved by Gilman, Miasnikov and Osin in «Exponentially generic subsets of groups»: Any word hyperbolic group is either almost free or virtually cyclic An easy corollary of this statement is: All word hyperbolic groups are almost virtually free My question is whether the converse is also true: Are all almost virtually free groups word hyperbolic?","G A B_A^n := (A \cup \{e\})^n A n R_1, … , R_k k B_A^n k G H(G, A, k, n) = \langle \{R_1, … , R_k\} \rangle \mathfrak{X} G := \langle A \rangle \mathfrak{X} \forall k \in \mathbb{N} \lim_{n \to \infty} P(H(G, A, k, n)) = 1 A \mathfrak{X} \mathfrak{X} \mathfrak{X}","['probability', 'group-theory', 'geometric-group-theory', 'combinatorial-group-theory', 'gromov-hyperbolic-spaces']"
67,Is finding martingales black magic?,Is finding martingales black magic?,,"I've recently been learning about the power of martingales for calculating various stochastic quantities. This is a bit of a meta question: is coming up with the right martingale for the quantity you want just complete black magic? As an example, consider an unbiased random walk, where we start at position $x$ and want the probability we either hit $0$ or $L$ . In this case (after shifting the start to $0$ and left/right limits to $-x$ and $L-x$ ) a good martingale to use for the calculation is $$S_n=\sum_{i=1}^n X_i$$ where $X_i$ is the random variable of the steps ( $X_i=\pm 1$ with equal probability). However, this is not a martingale when the walk is biased, i.e. $X_n=+1$ with probability $p$ and $X_n=-1$ with probability $q=1-p$ . Then it turns out that we should use a different martingale for the calculation, namely $$Y_n=\left(\frac{q}{p}\right)^{\sum_{i=1}^n X_i}.$$ How does one come up with the appropriate martingale to calculate a given quantity in general? Edit: fixed definition of appropriate martingale for unbiased case above, thank you commenters...","I've recently been learning about the power of martingales for calculating various stochastic quantities. This is a bit of a meta question: is coming up with the right martingale for the quantity you want just complete black magic? As an example, consider an unbiased random walk, where we start at position and want the probability we either hit or . In this case (after shifting the start to and left/right limits to and ) a good martingale to use for the calculation is where is the random variable of the steps ( with equal probability). However, this is not a martingale when the walk is biased, i.e. with probability and with probability . Then it turns out that we should use a different martingale for the calculation, namely How does one come up with the appropriate martingale to calculate a given quantity in general? Edit: fixed definition of appropriate martingale for unbiased case above, thank you commenters...",x 0 L 0 -x L-x S_n=\sum_{i=1}^n X_i X_i X_i=\pm 1 X_n=+1 p X_n=-1 q=1-p Y_n=\left(\frac{q}{p}\right)^{\sum_{i=1}^n X_i}.,"['probability', 'martingales']"
68,Computing an Ito Integral using the Definition,Computing an Ito Integral using the Definition,,"Let $B_t$ be a brownian motion adapted to $\mathcal F_t$. For general $\mathcal F_t$-adapted processes $X_t$ the Ito-integral could be defined as $$  \int_0^t X_s dB_s = \lim_{n\to \infty} \int_0^t X_s^{(n)} dB_s $$ where the $X_t^{(n)}$ are simple processes approximating $X_t$ such that for each $0 = t_0 < t_1 < \ldots < t_k = t$ as the constant value on the interval $[t_i, t_{i+1})$ the left end point is choosen, i.e. $X_t^{(n)}(t) = X_{t_i}$ for $t_i \le t < t_{i+1}$ and such that $$  \lim_{n\to \infty} E\int_0^T | X_t^{(n)} - X_t |^2 dt = 0. $$ Now I am looking for examples where this definition is used to compute the integral (and not Ito's Lemma). The only one I find in the literature are $$  \int_0^t B_s dB_s \quad \mbox{ and } \quad \int_0^t B_s^s dB_s $$ For example, for the first we can choose $$  \int_0^1 B_s dB_s = \lim_n \sum_{i=0}^{n-1} B_{i/n} (B_{(i+1)/n} - B_{i/n}) $$ and by $\sum_{i=0}^{n-1} B_{i/n} (B_{(i+1)/n} - B_{i/n}) = \frac{1}{2} B_1^2 - \frac{1}{2} \sum_{i=0}^{n-1} (B_{(i+1)/n} - B_{i/n})^2$ we have $$   \int_0^t B_s dB_s. = \frac{1}{2} B_1^2 - \frac{1}{2} $$ where the last term approaches $1$ as this is the quadratic variation of the Brownian motion. Another computation using the definition with the law of large numbers could be found on the german wikipedia . Now I am looking for other examples where the definition is used, do you know any? For example for $\exp(B_t)$, by using Ito's Lemme we find $$  \int_0^t \exp(B_s) dB_s = \exp(B_t) - \frac{1}{2}\int_0^t B_s ds $$ but I do not know how to derive this result using just the definition (i.e. finding an approximating series of simple processes).","Let $B_t$ be a brownian motion adapted to $\mathcal F_t$. For general $\mathcal F_t$-adapted processes $X_t$ the Ito-integral could be defined as $$  \int_0^t X_s dB_s = \lim_{n\to \infty} \int_0^t X_s^{(n)} dB_s $$ where the $X_t^{(n)}$ are simple processes approximating $X_t$ such that for each $0 = t_0 < t_1 < \ldots < t_k = t$ as the constant value on the interval $[t_i, t_{i+1})$ the left end point is choosen, i.e. $X_t^{(n)}(t) = X_{t_i}$ for $t_i \le t < t_{i+1}$ and such that $$  \lim_{n\to \infty} E\int_0^T | X_t^{(n)} - X_t |^2 dt = 0. $$ Now I am looking for examples where this definition is used to compute the integral (and not Ito's Lemma). The only one I find in the literature are $$  \int_0^t B_s dB_s \quad \mbox{ and } \quad \int_0^t B_s^s dB_s $$ For example, for the first we can choose $$  \int_0^1 B_s dB_s = \lim_n \sum_{i=0}^{n-1} B_{i/n} (B_{(i+1)/n} - B_{i/n}) $$ and by $\sum_{i=0}^{n-1} B_{i/n} (B_{(i+1)/n} - B_{i/n}) = \frac{1}{2} B_1^2 - \frac{1}{2} \sum_{i=0}^{n-1} (B_{(i+1)/n} - B_{i/n})^2$ we have $$   \int_0^t B_s dB_s. = \frac{1}{2} B_1^2 - \frac{1}{2} $$ where the last term approaches $1$ as this is the quadratic variation of the Brownian motion. Another computation using the definition with the law of large numbers could be found on the german wikipedia . Now I am looking for other examples where the definition is used, do you know any? For example for $\exp(B_t)$, by using Ito's Lemme we find $$  \int_0^t \exp(B_s) dB_s = \exp(B_t) - \frac{1}{2}\int_0^t B_s ds $$ but I do not know how to derive this result using just the definition (i.e. finding an approximating series of simple processes).",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals']"
69,Probability distribution for distances between randomly selected integers within an interval,Probability distribution for distances between randomly selected integers within an interval,,"Suppose I pick 'N' integers over an interval [A, B] without replacement.  As a function of 'N' and the interval length, what distribution / average values should I expect for the distances between nearest-neighbors in a sorted array of the selected integers? Edit: I apologize, an important note is that the distances between the endpoints and the nearest integers to the endpoints should also be included.  This is a bit like dividing a piece of rope into (B - A + 1) segments, cutting at the locations representing the 'N' selected integers, and looking at the distribution of cut rope lengths. Edit 2:  Apparently this question is in desperate need of clarification.  Extending the rope example I provided, here's exactly what I'm looking for: Upon cutting the rope into 'N' pieces, and placing these pieces in a bag, I would very much like the probability, P(k), of randomly selecting a fragment of rope of length 'k' from this bag.  Here, the probability of selecting a particular fragment of the rope is independent of its length.  The function for P(k) provides what I'd like to know about the distribution of rope lengths after 'N' cuts.","Suppose I pick 'N' integers over an interval [A, B] without replacement.  As a function of 'N' and the interval length, what distribution / average values should I expect for the distances between nearest-neighbors in a sorted array of the selected integers? Edit: I apologize, an important note is that the distances between the endpoints and the nearest integers to the endpoints should also be included.  This is a bit like dividing a piece of rope into (B - A + 1) segments, cutting at the locations representing the 'N' selected integers, and looking at the distribution of cut rope lengths. Edit 2:  Apparently this question is in desperate need of clarification.  Extending the rope example I provided, here's exactly what I'm looking for: Upon cutting the rope into 'N' pieces, and placing these pieces in a bag, I would very much like the probability, P(k), of randomly selecting a fragment of rope of length 'k' from this bag.  Here, the probability of selecting a particular fragment of the rope is independent of its length.  The function for P(k) provides what I'd like to know about the distribution of rope lengths after 'N' cuts.",,"['probability', 'probability-distributions']"
70,Probability that product of means is larger than product of maximum and minimum,Probability that product of means is larger than product of maximum and minimum,,"Given $X_1,...,X_n \stackrel{iid}{\sim} \text{Unif}(a,b)$, what is $$\mathbb{P}\left[\frac{\sum x_i}{\sum \frac{1}{x_i}} \geq \max(x_i) \cdot \min(x_i)\right].$$ I don't need a closed-form formula, just a description of the asymptotic behavior would be nice. Numerical experiments seem to show that the probability tends to 1. Here $a,b$ are arbitrary. As wolfies pointed out in the comments, when $a=0$, the result is immediate since $\min(x_i)\to 0$. So we can assume $a>0$. The inequality is invariant by scaling, so we can assume w.l.o.g. that $a=1$ and $b$ is arbitrary. A little background : I am studying an algorithm which has parameters $x_i \in \Bbb R_+, i =1,...,n$. The algorithm has provably good performances when  $$\frac{\sum x_i}{\sum \frac{1}{x_i}} \geq \max(x_i) \cdot \min(x_i).$$ The left-hand side can be written as $AM(x_i) \cdot HM(x_i)$ where $AM$ and $HM$ are the arithmetic and harmonic means. Both quantities are between $\min(x_i)$ and $\max(x_i)$, so nothing can be said about their product in general. However, numerical evidences seem to indicate that the event occurs with probability one as $n\to \infty$ if the $x_i$'s are sampled uniformly. But I am unable to come up with a proof of this fact.","Given $X_1,...,X_n \stackrel{iid}{\sim} \text{Unif}(a,b)$, what is $$\mathbb{P}\left[\frac{\sum x_i}{\sum \frac{1}{x_i}} \geq \max(x_i) \cdot \min(x_i)\right].$$ I don't need a closed-form formula, just a description of the asymptotic behavior would be nice. Numerical experiments seem to show that the probability tends to 1. Here $a,b$ are arbitrary. As wolfies pointed out in the comments, when $a=0$, the result is immediate since $\min(x_i)\to 0$. So we can assume $a>0$. The inequality is invariant by scaling, so we can assume w.l.o.g. that $a=1$ and $b$ is arbitrary. A little background : I am studying an algorithm which has parameters $x_i \in \Bbb R_+, i =1,...,n$. The algorithm has provably good performances when  $$\frac{\sum x_i}{\sum \frac{1}{x_i}} \geq \max(x_i) \cdot \min(x_i).$$ The left-hand side can be written as $AM(x_i) \cdot HM(x_i)$ where $AM$ and $HM$ are the arithmetic and harmonic means. Both quantities are between $\min(x_i)$ and $\max(x_i)$, so nothing can be said about their product in general. However, numerical evidences seem to indicate that the event occurs with probability one as $n\to \infty$ if the $x_i$'s are sampled uniformly. But I am unable to come up with a proof of this fact.",,"['probability', 'inequality']"
71,Random graph probability lemma,Random graph probability lemma,,"I'm trying to prove a fiddly lemma for homework, but getting absolutely nowhere with it. Here, $G_{n,p}$ and $G_{n,m}$ represent, respectively, random graphs on $n$ vertices where the number of edges is binomially distributed with probability $p$ (i.e. any edge in the graph is present with probability $p$ and $N = {n \choose 2}$ possible edges, mean $Np$), and random graphs on $n$ vertices uniformly distributed across all possible such graphs with $m$ edges. We say $G_{n,p}$ has a property $Q = (Q_n)$ 'WHP' (with high probability) if $\mathbb{P}_{n,p}(Q_n) \to 1$ as $n \to \infty$ (similarly for $G_{n,m}$) - for example, this might be that the graph is connected, or is a forest. Now, the lemma I want to prove is as follows: Let $(Q_n)$ be a property of graphs. Then $G_{n,p}$ has $Q$ WHP iff for every $x > 0$ and $\epsilon > 0$ we have (as $n \to \infty$): $$\#\{m: |m-pN| \leq xn\sqrt{pq} \text{ and } \mathbb{P}_{n, m}(Q_n) < 1 - \epsilon\} < \epsilon n \sqrt{pq}$$ Now I've spent a very long time trying to chisel away at thie ""lemma"" but sadly I'm having no luck. In the $\Rightarrow$ direction, we have to translate from some condition in $G_{n,p}$ to one in $G_{n,m}$; the latter condition is, conceptually, on showing that the number of $m$ ""close to the mean"" which have a low $\mathbb{P}(Q_n)$ is small. One thought I had was to try and convert from our binomial distribution to its normal approximation and then use that (since of course $n\sqrt{pq}$ is a close approximation to the standard deviation), but again no progress. It was suggested that it might help to observe that if $\omega (n) \to \infty$ as $n \to \infty$ then WHP, $$|e(G_{n,p}) - pN| \leq \omega(n)n\sqrt{pq}\;,$$ but I couldn't complete the proof - nothing has worked so far. Could anyone help please? I've spent ages on this and not managed either direction, so the more detailed assistance you could provide the better. Many thanks for the help.","I'm trying to prove a fiddly lemma for homework, but getting absolutely nowhere with it. Here, $G_{n,p}$ and $G_{n,m}$ represent, respectively, random graphs on $n$ vertices where the number of edges is binomially distributed with probability $p$ (i.e. any edge in the graph is present with probability $p$ and $N = {n \choose 2}$ possible edges, mean $Np$), and random graphs on $n$ vertices uniformly distributed across all possible such graphs with $m$ edges. We say $G_{n,p}$ has a property $Q = (Q_n)$ 'WHP' (with high probability) if $\mathbb{P}_{n,p}(Q_n) \to 1$ as $n \to \infty$ (similarly for $G_{n,m}$) - for example, this might be that the graph is connected, or is a forest. Now, the lemma I want to prove is as follows: Let $(Q_n)$ be a property of graphs. Then $G_{n,p}$ has $Q$ WHP iff for every $x > 0$ and $\epsilon > 0$ we have (as $n \to \infty$): $$\#\{m: |m-pN| \leq xn\sqrt{pq} \text{ and } \mathbb{P}_{n, m}(Q_n) < 1 - \epsilon\} < \epsilon n \sqrt{pq}$$ Now I've spent a very long time trying to chisel away at thie ""lemma"" but sadly I'm having no luck. In the $\Rightarrow$ direction, we have to translate from some condition in $G_{n,p}$ to one in $G_{n,m}$; the latter condition is, conceptually, on showing that the number of $m$ ""close to the mean"" which have a low $\mathbb{P}(Q_n)$ is small. One thought I had was to try and convert from our binomial distribution to its normal approximation and then use that (since of course $n\sqrt{pq}$ is a close approximation to the standard deviation), but again no progress. It was suggested that it might help to observe that if $\omega (n) \to \infty$ as $n \to \infty$ then WHP, $$|e(G_{n,p}) - pN| \leq \omega(n)n\sqrt{pq}\;,$$ but I couldn't complete the proof - nothing has worked so far. Could anyone help please? I've spent ages on this and not managed either direction, so the more detailed assistance you could provide the better. Many thanks for the help.",,"['probability', 'graph-theory', 'random-graphs']"
72,A rigorous proof of an obvious fact about a Markov chain,A rigorous proof of an obvious fact about a Markov chain,,"So I'm having trouble writing down a rigorous proof of something that seems very clear. Consider the following Markov chain on a ring: with probability $1/2$, it stays where it is, with probability $1/2-1/n$ it moves counterclockwise, and with probability $1/n$ it jumps to a random node. When the latter has happened, we'll say a jump has occurred. Let $A$ be the event that by time $10n$, exactly one jump has occurred.  Let $B$ be the event that the random walk has never taken the self loop at node $1$. I want to prove that $P(B|A)$ is lower bounded by some constant independent of $n$. I'm actually guessing that $P(B|A) \geq 1/2^{11}$. This seems obvious to me: conditional on $A$, the number of times the chain transitions into node $1$  by time $10n$ is at most $11$, and the probability of not taking the self-loop is $1/2$ each time. But how to say this formally? Edit: Actually the above sketch is somewhat problematic: as Craig points out in the comments, taking exactly one jump changes the probabilities of taking the self loop whenever the chain is at node $1$. But, presumably, the chance of taking the counterclockwise transition should only increase, since the number of jumps is below what you'd expect in $10n$ transitions. So I'd be perfectly satisfied with the bound $(1/2-1/n)^{11}$ instead.","So I'm having trouble writing down a rigorous proof of something that seems very clear. Consider the following Markov chain on a ring: with probability $1/2$, it stays where it is, with probability $1/2-1/n$ it moves counterclockwise, and with probability $1/n$ it jumps to a random node. When the latter has happened, we'll say a jump has occurred. Let $A$ be the event that by time $10n$, exactly one jump has occurred.  Let $B$ be the event that the random walk has never taken the self loop at node $1$. I want to prove that $P(B|A)$ is lower bounded by some constant independent of $n$. I'm actually guessing that $P(B|A) \geq 1/2^{11}$. This seems obvious to me: conditional on $A$, the number of times the chain transitions into node $1$  by time $10n$ is at most $11$, and the probability of not taking the self-loop is $1/2$ each time. But how to say this formally? Edit: Actually the above sketch is somewhat problematic: as Craig points out in the comments, taking exactly one jump changes the probabilities of taking the self loop whenever the chain is at node $1$. But, presumably, the chance of taking the counterclockwise transition should only increase, since the number of jumps is below what you'd expect in $10n$ transitions. So I'd be perfectly satisfied with the bound $(1/2-1/n)^{11}$ instead.",,"['probability', 'markov-chains']"
73,Probability Based on a Grid of Lights,Probability Based on a Grid of Lights,,"The question is as follows : A grid of $n\times n$ ( $n\ge 3$ ) lights is connected to a switch in such a way that each light has a $50\%$ chance of lighting up when switched on. What is the probability that we see a closed curve after turning on the switch? A closed curve is basically a set of any number of lines that enclose an area (containing at least one light). The lines could be vertical, horizontal, or diagonal only (that is, making angles $0°, 90°$ or $45°$ with the horizontal), otherwise the curve would not be closed. A line is a line segment joining two illuminated lights. We only say a closed curve is formed, when all the lights except the ones that make up the boundary of the shape are switched off . To check if any configuration satisfies these conditions, connect all the lights (that you claim to be part of the boundary of a shape) through lines . If there’s any other illuminated light left out, then this configuration is invalid. Every illuminated light must be immediately next to at least one of the grid points that the curve encloses. As an example for what ‘immediately next to’ means, consider the $5\times5$ grid: $$\begin{matrix} 1&2&3&4&5 \\ 6& \color{blue}7 & \color{blue}8 &\color{blue}9 &10 \\ 11&\color{blue}{12} &\color{red}{13} & \color{blue}{14} & 15   \\16 & \color{blue}{17}&\color{blue}{18}&\color{blue}{19} &20 \\ 21&22&23&24&25 \end{matrix} $$ Here, the blue lights are immediately next to $13$ . This problem essentially comes down to counting the total number of such closed curves in an $n\times n$ grid. So I figured I might as well start off with the easy part. Now, every single configuration of the grid occurs with an equal probability of $P=\frac{1}{2^{n^2}}$ (as there are a total of $2^{n^2}$ cases possible). So, the required probability will be the number of possible closed curves $\space \times P$ . How can I determine all the closed curves?","The question is as follows : A grid of ( ) lights is connected to a switch in such a way that each light has a chance of lighting up when switched on. What is the probability that we see a closed curve after turning on the switch? A closed curve is basically a set of any number of lines that enclose an area (containing at least one light). The lines could be vertical, horizontal, or diagonal only (that is, making angles or with the horizontal), otherwise the curve would not be closed. A line is a line segment joining two illuminated lights. We only say a closed curve is formed, when all the lights except the ones that make up the boundary of the shape are switched off . To check if any configuration satisfies these conditions, connect all the lights (that you claim to be part of the boundary of a shape) through lines . If there’s any other illuminated light left out, then this configuration is invalid. Every illuminated light must be immediately next to at least one of the grid points that the curve encloses. As an example for what ‘immediately next to’ means, consider the grid: Here, the blue lights are immediately next to . This problem essentially comes down to counting the total number of such closed curves in an grid. So I figured I might as well start off with the easy part. Now, every single configuration of the grid occurs with an equal probability of (as there are a total of cases possible). So, the required probability will be the number of possible closed curves . How can I determine all the closed curves?","n\times n n\ge 3 50\% 0°, 90° 45° 5\times5 \begin{matrix} 1&2&3&4&5 \\ 6& \color{blue}7 & \color{blue}8 &\color{blue}9 &10 \\ 11&\color{blue}{12} &\color{red}{13} & \color{blue}{14} & 15   \\16 & \color{blue}{17}&\color{blue}{18}&\color{blue}{19} &20 \\ 21&22&23&24&25 \end{matrix}  13 n\times n P=\frac{1}{2^{n^2}} 2^{n^2} \space \times P","['probability', 'combinatorics', 'combinatorial-geometry', 'geometric-probability']"
74,What is $E|\langle A\rangle|$?,What is ?,E|\langle A\rangle|,"Suppose $A$ is a random subset of $S_n$, such that each element of $S_n$ independently belongs to $A$ with probability p. What is the expectation of $|\langle A\rangle|$? The case with $p = 1$ ($E|\langle A\rangle| = n!$) is quite obvious, however, I do not know, how to deal with the situation when $0 < p < 1$. Any help will be appreciated.","Suppose $A$ is a random subset of $S_n$, such that each element of $S_n$ independently belongs to $A$ with probability p. What is the expectation of $|\langle A\rangle|$? The case with $p = 1$ ($E|\langle A\rangle| = n!$) is quite obvious, however, I do not know, how to deal with the situation when $0 < p < 1$. Any help will be appreciated.",,"['probability', 'abstract-algebra', 'group-theory', 'permutations', 'expectation']"
75,Probability that an exam will have a perfect predictor,Probability that an exam will have a perfect predictor,,"Here is a just-for-fun question, inspired by this answer of Noam Elkies : Suppose an exam with $q$ questions is taken by $s$ students. Each student independently has probability $1/2$ of getting each question right or wrong, a passing grade is getting the majority of the questions right. (Let's take $q$ odd, for simplicity.) What is the asymtotic probability that there will be at least one question which is gotten right precisely by the students who pass? Of course, there are a variety of ways in which $q$ and $s$ can go to $\infty$, so the question is which relative growth rates make this situation likely or unlikely.","Here is a just-for-fun question, inspired by this answer of Noam Elkies : Suppose an exam with $q$ questions is taken by $s$ students. Each student independently has probability $1/2$ of getting each question right or wrong, a passing grade is getting the majority of the questions right. (Let's take $q$ odd, for simplicity.) What is the asymtotic probability that there will be at least one question which is gotten right precisely by the students who pass? Of course, there are a variety of ways in which $q$ and $s$ can go to $\infty$, so the question is which relative growth rates make this situation likely or unlikely.",,"['probability', 'combinatorics']"
76,Strategy for a game of breaking sticks,Strategy for a game of breaking sticks,,"Two persons have 2 uniform sticks with equal length which can be cut at any point. Each person will cut the stick into $n$ parts ($n$ is an odd number). And each person's $n$ parts will be permuted randomly, and be compared with the other person's sticks one by one. When one's stick is longer than the other person's, he will get one point. The person with more points will win the game. How to maximize the probability of winning the game for one of the person. What is the best strategy to cut the stick.","Two persons have 2 uniform sticks with equal length which can be cut at any point. Each person will cut the stick into $n$ parts ($n$ is an odd number). And each person's $n$ parts will be permuted randomly, and be compared with the other person's sticks one by one. When one's stick is longer than the other person's, he will get one point. The person with more points will win the game. How to maximize the probability of winning the game for one of the person. What is the best strategy to cut the stick.",,"['probability', 'game-theory']"
77,Simplifying an expression involving $x^x$,Simplifying an expression involving,x^x,"Is it possible to simplify the following function: $$p(n, k) = \sum_{\substack{x_1 + x_2 + \cdots + x_k = n \\\ x_i \in \mathbb{N}}} x_1^{x_1} x_2^{x_2} \cdots x_k^{x_k},$$ or, at least, find a good (easy to compute) approximation of $\log{(p(n, k))}$? Here is my motivation. Consider a probabilistic node $A$ with $k$ output arrows $a_1, \cdots, a_k$, and let us assume that the probability of passing the $k$-th arrow is $p_k$. Then the probability of consecutively moving through arrows $x = \langle a_{i_1}, \cdots, a_{i_n} \rangle$ is  $$ p^A(x) = \prod_{i = 1}^n p_{k_i} = \prod_{i = 1}^k p_i^{s_i}, $$ where $s_i$ is the number of occurences of $a_i$ in $x$. So given a sample $x$ and a probabilistic node $A$ the optimal length of a code describing $x$ is about $\log(\frac{1}{p^A(x)})$, and the shortest code is achieved for $A$ having probabilities $p_1 = \frac{s_1}{n}, \cdots, p_k = \frac{s_k}{n}$. Now, let us assume that we do not know probabilities at $A$. Then any code describing $x$ via $A$ has to contain some information about these probabilities. A ``uniform approach'' would look like follows: for a given sample $x$ chose the optimal probability node $A_x$, then $u(x) = p^{A_x}(x)$ is not a probability on $k^n$ as it does not sum up to $1$ (it does not contain information about choosing appropriate $A_x$); however $p(x)$ is, where $$ p(x) = \frac{u(x)}{\sum_{y \in k^n} u(y)} = \frac{\prod_{i = 1}^k s_i^{s_i}}{\sum_{t_1 + \cdots + t_k = n} \prod_{i = 1}^k t_i^{t_i}}. $$ One may take another approach based on Bayesian interpretation. Let us fix a meta-distribution $q$ on all probabilistic nodes $A$ having the same output arrows. This distribution chooses probabilities $p_1, \cdots, p_k$, that is --- non-negative real numbers such that $p_1 + \cdots + p_k = 1$ --- then for a given sample $x$ chose a node $A_{p_1, \cdots, p_k}$ with probability $q(A_{p_1, \cdots, p_k})$ and describe $x$ according to that node:  $$ b(x) = \int_{p_1 + \cdots + p_n = 1, p_i \geq 0} p^{A_{p_1, \cdots, p_k}}(x) q(A_{p_1, \cdots, p_k}). $$ If $q$ is a uniform distribution (and I have not made any mistake during calculations), then  $$ b(x) = \frac{\int_{p_1 + \cdots + p_k = 1, p_i \geq 0} \prod_{i = 1}^k p_i^{s_i}}{\mathit{Vol}(\Delta_k)} = \frac{\Gamma(k) \prod_{i = 1}^k\Gamma(s_i + 1)}{\Gamma(\sum_{i = 1}^k (s_i + 1))}. $$ So $$p(x) = p \prod_{i = 1}^k s_i^{s_i}$$ is proportional to the probability corresponding to the Kolmogorov complexity of $x$ seen from the perspective of a ""stateless"" random source, and $$q(x) = q \prod_{i = 1}^k s_i^{\underline{s_i}}$$ is inversly proportional to the number of sequences containing exactly $s_i$ of $a_i$ (if there are a lot of such sequences, then from the perspective of a ""stateless"" random source they are ""more"" random, so less interesting). Here $p, q$ are some constants. In fact, these distributions are really close --- by using Striling's formula $n^{\underline{n}} \approx \sqrt{2\pi n}(\frac{n}{e})^n$ we have $$q(x) \approx q' \prod_{i=1}^k s_i^{s_i+\frac{1}{2}}$$ where $q' = q\;e^{-n} (2\pi)^{k/2}$ is just another constant. I would like to compare $p(x)$ with $b(x)$.","Is it possible to simplify the following function: $$p(n, k) = \sum_{\substack{x_1 + x_2 + \cdots + x_k = n \\\ x_i \in \mathbb{N}}} x_1^{x_1} x_2^{x_2} \cdots x_k^{x_k},$$ or, at least, find a good (easy to compute) approximation of $\log{(p(n, k))}$? Here is my motivation. Consider a probabilistic node $A$ with $k$ output arrows $a_1, \cdots, a_k$, and let us assume that the probability of passing the $k$-th arrow is $p_k$. Then the probability of consecutively moving through arrows $x = \langle a_{i_1}, \cdots, a_{i_n} \rangle$ is  $$ p^A(x) = \prod_{i = 1}^n p_{k_i} = \prod_{i = 1}^k p_i^{s_i}, $$ where $s_i$ is the number of occurences of $a_i$ in $x$. So given a sample $x$ and a probabilistic node $A$ the optimal length of a code describing $x$ is about $\log(\frac{1}{p^A(x)})$, and the shortest code is achieved for $A$ having probabilities $p_1 = \frac{s_1}{n}, \cdots, p_k = \frac{s_k}{n}$. Now, let us assume that we do not know probabilities at $A$. Then any code describing $x$ via $A$ has to contain some information about these probabilities. A ``uniform approach'' would look like follows: for a given sample $x$ chose the optimal probability node $A_x$, then $u(x) = p^{A_x}(x)$ is not a probability on $k^n$ as it does not sum up to $1$ (it does not contain information about choosing appropriate $A_x$); however $p(x)$ is, where $$ p(x) = \frac{u(x)}{\sum_{y \in k^n} u(y)} = \frac{\prod_{i = 1}^k s_i^{s_i}}{\sum_{t_1 + \cdots + t_k = n} \prod_{i = 1}^k t_i^{t_i}}. $$ One may take another approach based on Bayesian interpretation. Let us fix a meta-distribution $q$ on all probabilistic nodes $A$ having the same output arrows. This distribution chooses probabilities $p_1, \cdots, p_k$, that is --- non-negative real numbers such that $p_1 + \cdots + p_k = 1$ --- then for a given sample $x$ chose a node $A_{p_1, \cdots, p_k}$ with probability $q(A_{p_1, \cdots, p_k})$ and describe $x$ according to that node:  $$ b(x) = \int_{p_1 + \cdots + p_n = 1, p_i \geq 0} p^{A_{p_1, \cdots, p_k}}(x) q(A_{p_1, \cdots, p_k}). $$ If $q$ is a uniform distribution (and I have not made any mistake during calculations), then  $$ b(x) = \frac{\int_{p_1 + \cdots + p_k = 1, p_i \geq 0} \prod_{i = 1}^k p_i^{s_i}}{\mathit{Vol}(\Delta_k)} = \frac{\Gamma(k) \prod_{i = 1}^k\Gamma(s_i + 1)}{\Gamma(\sum_{i = 1}^k (s_i + 1))}. $$ So $$p(x) = p \prod_{i = 1}^k s_i^{s_i}$$ is proportional to the probability corresponding to the Kolmogorov complexity of $x$ seen from the perspective of a ""stateless"" random source, and $$q(x) = q \prod_{i = 1}^k s_i^{\underline{s_i}}$$ is inversly proportional to the number of sequences containing exactly $s_i$ of $a_i$ (if there are a lot of such sequences, then from the perspective of a ""stateless"" random source they are ""more"" random, so less interesting). Here $p, q$ are some constants. In fact, these distributions are really close --- by using Striling's formula $n^{\underline{n}} \approx \sqrt{2\pi n}(\frac{n}{e})^n$ we have $$q(x) \approx q' \prod_{i=1}^k s_i^{s_i+\frac{1}{2}}$$ where $q' = q\;e^{-n} (2\pi)^{k/2}$ is just another constant. I would like to compare $p(x)$ with $b(x)$.",,"['probability', 'combinatorics']"
78,"Given particle undergoing Geometric Brownian Motion, want to find formula for probability that max-min > z after n days","Given particle undergoing Geometric Brownian Motion, want to find formula for probability that max-min > z after n days",,"Consider a particle undergoing geometric brownian motion with drift $\mu$ and volatility $\sigma$ e.g. as in here . Let $W_t$ denote this geometric brownian motion with drift at time $t$. I am looking for a formula to calculate: $$ \mathbb{P}\big(\max_{0 \leq t \leq n} W_t - \min_{0\leq t \leq n} W_t > z\big)   $$ The inputs to the formula will be $\mu$, $\sigma$, $z$, and $n$.","Consider a particle undergoing geometric brownian motion with drift $\mu$ and volatility $\sigma$ e.g. as in here . Let $W_t$ denote this geometric brownian motion with drift at time $t$. I am looking for a formula to calculate: $$ \mathbb{P}\big(\max_{0 \leq t \leq n} W_t - \min_{0\leq t \leq n} W_t > z\big)   $$ The inputs to the formula will be $\mu$, $\sigma$, $z$, and $n$.",,"['probability', 'stochastic-processes']"
79,How much are you willing to pay for this treasure chest game?,How much are you willing to pay for this treasure chest game?,,"I was given an interesting problem that comes in two parts. In front of you is a treasure chest containing \$1000 with a 6-digit   combination lock. You have to pay a constant amount for each time you   change a digit. What is the maximum amount you are willing to pay per turn? Not sure if my approach here is correct: if the expected value of the game is $E$ and the amount I pay per turn is $x$ , then $$E=\frac{1}{10^6}(1000-x)+\frac{10^6-1}{10^6}(E-x)$$ $$=E\left(1-\frac{1}{10^6}\right)+\frac{1000}{10^6}-x.$$ $$\Rightarrow E=1000-10^6x.$$ For positive payoff, we require $x<1000/10^6$ , i.e. we want to pay less than \$0.001. My main issue is with the next subproblem. When two or less digits are correct, an LED on the chest glows red.   When three or more (but not six) digits are correct, the LED glows   yellow. When all digits are correct, the LED glows green and the chest   opens. Is there an optimal strategy? How much are you willing to pay   per turn now? How exactly do we form a strategy? I’m unsure of the most efficient way to keep track of the correct digits, and how to get back on track if a yellow LED switches to red. I am also unsure of how this affects the equation for the expectation. Could someone guide me on this please? Thank you!","I was given an interesting problem that comes in two parts. In front of you is a treasure chest containing \$1000 with a 6-digit   combination lock. You have to pay a constant amount for each time you   change a digit. What is the maximum amount you are willing to pay per turn? Not sure if my approach here is correct: if the expected value of the game is and the amount I pay per turn is , then For positive payoff, we require , i.e. we want to pay less than \$0.001. My main issue is with the next subproblem. When two or less digits are correct, an LED on the chest glows red.   When three or more (but not six) digits are correct, the LED glows   yellow. When all digits are correct, the LED glows green and the chest   opens. Is there an optimal strategy? How much are you willing to pay   per turn now? How exactly do we form a strategy? I’m unsure of the most efficient way to keep track of the correct digits, and how to get back on track if a yellow LED switches to red. I am also unsure of how this affects the equation for the expectation. Could someone guide me on this please? Thank you!",E x E=\frac{1}{10^6}(1000-x)+\frac{10^6-1}{10^6}(E-x) =E\left(1-\frac{1}{10^6}\right)+\frac{1000}{10^6}-x. \Rightarrow E=1000-10^6x. x<1000/10^6,"['probability', 'conditional-expectation', 'expected-value']"
80,"Particle moves in square, what is the expected distance before first return to edge?","Particle moves in square, what is the expected distance before first return to edge?",,"There is a unit square with a particle moving in it. After the particle collides with an edge, the angle of reflection is random and is drawn from the uniform distribution on $[-\frac{\pi}{2}, \frac{\pi}{2}].$ The question is to find the average distance the particle covers before it returns to the same edge next time (I guess that after a large number of collusions the starting point is not important). To me, this sounds like a question about the stationary distribution of a Markov chain with a continuum of states. However, the problem actually is taken from a physics olympiad for high school students. It is claimed that the answer is $2\sqrt{2}$. If it is not a mistake, there probably is an intuitive non-rigorous argument why the answer is $2\sqrt{2}$. Update 1: I was asked to post the original text of the problem here. It is somewhat different from what I wrote above, but I believe that this is basically the same question: Problem: In a computer model, movement of a particle inside of a square is   simulated. Square has sides of length L, the speed of the point is V.   After a collusion with an edge point bounces at a random angle   (equiprobable from -90 to 90 degrees) with the same speed. Estimate the   number of collusions with one of the sides after a large period of   time T. Answer: $\frac{TV}{2\sqrt{2}L}$. Update 2: There were attempts to do a simulation (see comments below), and the results tend to be somewhat smaller than $2\sqrt{2}$. Also, in my simulation the distribution of collision points is not uniform (points close to angles are more frequent) and distribution of distance from bounce to bounce is asymmetric and bimodal.","There is a unit square with a particle moving in it. After the particle collides with an edge, the angle of reflection is random and is drawn from the uniform distribution on $[-\frac{\pi}{2}, \frac{\pi}{2}].$ The question is to find the average distance the particle covers before it returns to the same edge next time (I guess that after a large number of collusions the starting point is not important). To me, this sounds like a question about the stationary distribution of a Markov chain with a continuum of states. However, the problem actually is taken from a physics olympiad for high school students. It is claimed that the answer is $2\sqrt{2}$. If it is not a mistake, there probably is an intuitive non-rigorous argument why the answer is $2\sqrt{2}$. Update 1: I was asked to post the original text of the problem here. It is somewhat different from what I wrote above, but I believe that this is basically the same question: Problem: In a computer model, movement of a particle inside of a square is   simulated. Square has sides of length L, the speed of the point is V.   After a collusion with an edge point bounces at a random angle   (equiprobable from -90 to 90 degrees) with the same speed. Estimate the   number of collusions with one of the sides after a large period of   time T. Answer: $\frac{TV}{2\sqrt{2}L}$. Update 2: There were attempts to do a simulation (see comments below), and the results tend to be somewhat smaller than $2\sqrt{2}$. Also, in my simulation the distribution of collision points is not uniform (points close to angles are more frequent) and distribution of distance from bounce to bounce is asymmetric and bimodal.",,"['probability', 'markov-chains']"
81,Limit theorems in measure theory,Limit theorems in measure theory,,"From probability theory/measure theory we know set of theorems such as Monotone convergence, dominated convergence or conditions like uniform integrability which deals with the general question of interchanging limits and integration. In these cases we have either measurable functions $f_n$ converging to $f$ or  measures $\pi_k$ converging to $\pi$ and we see under what condition for instance $\int f_n\rm d \pi \to \int f\rm d \pi$ or $\int f\rm d \pi_k\to \int f\rm d \pi$. My question is what happens if those two are mixed. Namely if we have measurable functions $f_n$ converging to $f$ and  measures $\pi_k$ converging to $\pi$ then what we can say about limits of $\int f_n\rm d \pi_n$. A particularly interesting case is when $f_n$ is implicitly a functional of $\pi_n$, which means that by changing the measure $f_n$ will change too. I have looked into many classical books on measure theory and probability theory (Rudin, Billingsley, Feller, Durrett, Halmos, etc), but could not find an answer to this. Any help is appreciated.","From probability theory/measure theory we know set of theorems such as Monotone convergence, dominated convergence or conditions like uniform integrability which deals with the general question of interchanging limits and integration. In these cases we have either measurable functions $f_n$ converging to $f$ or  measures $\pi_k$ converging to $\pi$ and we see under what condition for instance $\int f_n\rm d \pi \to \int f\rm d \pi$ or $\int f\rm d \pi_k\to \int f\rm d \pi$. My question is what happens if those two are mixed. Namely if we have measurable functions $f_n$ converging to $f$ and  measures $\pi_k$ converging to $\pi$ then what we can say about limits of $\int f_n\rm d \pi_n$. A particularly interesting case is when $f_n$ is implicitly a functional of $\pi_n$, which means that by changing the measure $f_n$ will change too. I have looked into many classical books on measure theory and probability theory (Rudin, Billingsley, Feller, Durrett, Halmos, etc), but could not find an answer to this. Any help is appreciated.",,"['probability', 'measure-theory', 'probability-limit-theorems']"
82,Random walks and diffusion limits,Random walks and diffusion limits,,"Imagine a long and narrow cylinder of radius r and a point particle that moves in the region bounded by the cylinder. The motion is specified as follows: starting at a point on the inner wall of the cylinder, choose at random a direction and let the particle move with constant speed until it hits another  point of the cylinder. Once there, choose a new direction at random  and repeat the process.  The problem is to determine the probability that the particle will be given distance away from the initial point at a given time in the future. I realized that t is hard to find such a probability explicitly, but if the cylinder is very narrow and the particle moves very fast (with speed proportional to the reciprocal of the radius) you can use the central limit theorem to obtain an explicit (Gaussian) approximation. What is the variance of the resulting normal law? How does the variance change if the cross section of the tube is, say a square, instead of a circle? Can Anyone help me here?","Imagine a long and narrow cylinder of radius r and a point particle that moves in the region bounded by the cylinder. The motion is specified as follows: starting at a point on the inner wall of the cylinder, choose at random a direction and let the particle move with constant speed until it hits another  point of the cylinder. Once there, choose a new direction at random  and repeat the process.  The problem is to determine the probability that the particle will be given distance away from the initial point at a given time in the future. I realized that t is hard to find such a probability explicitly, but if the cylinder is very narrow and the particle moves very fast (with speed proportional to the reciprocal of the radius) you can use the central limit theorem to obtain an explicit (Gaussian) approximation. What is the variance of the resulting normal law? How does the variance change if the cross section of the tube is, say a square, instead of a circle? Can Anyone help me here?",,"['probability', 'geometry', 'random-walk']"
83,Infinite sum of Gamma random variables with same shape parameter but different rate parameter,Infinite sum of Gamma random variables with same shape parameter but different rate parameter,,"Question Let $Z_i\sim\chi_{(1)}^2\sim\Gamma(\frac{1}{2},\frac{1}{2})$ be i.i.d. chi-square random variables. We define: $$ W_n =\Bigl[\sum_{i = 1}^{n-1}\frac{Z_i}{2^{i}}\Bigr] + \frac{Z_n}{2^{n-1}} \mbox{ $\forall n\geq 2$} $$ For example: $W_2 = \frac{1}{2}Z_1+\frac{1}{2}Z_2$ , $W_3 = \frac{1}{2}Z_1+\frac{1}{4}Z_2+\frac{1}{4}Z_3$ and so on. I would like to determine the distribution of $W_{\infty}$ defined as: $$ W_{\infty} = \lim_{n\to\infty}W_n = \sum_{k = 1}^{\infty} \frac{Z_k}{2^{k}} \mbox{ where $Z_k\sim \Gamma\Bigl(\frac{1}{2},\frac{1}{2}\Bigr)$ are i.i.d.} $$ More specifically I have interest in computing the probability $P(W_{\infty} > 1$ ). References Note that this problem has references, in particular in this paper by Mathai: https://www.ism.ac.jp/editsec/aism/pdf/034_3_0591.pdf Reference [4]: In my case, following its notations $\alpha = \frac{1}{2}$ , $X_i\sim\Gamma(\frac{1}{2},\frac{1}{2})$ are i.i.d. and $n\to\infty$ . The main problem is that I didn't manage to find Prabhu's work about this fact, and in general I didn't manage to find any other references to this problem. My attempt I was trying to approach this problem using the Levy-criteria for the convergence in distribution.. in particular I was trying to calculate (since they are indipendent random variables) the infinite product of their characteristic functions, which is the characteristic function of $W_{\infty}$ .. but I wasn't able to determine a closed form for it. In particular if $H_k \sim \Gamma(1/2,2^k)$ then $\phi_{H_k}(t) = \Bigl(1-\frac{t}{2^k}\Bigr)^{-\frac{1}{2}}$ and so: $$ \phi_{W_{\infty}}(t) = \prod_{k = 0}^{\infty}\frac{1}{\sqrt{1-\frac{it}{2^k}}} $$ Code and simulation I'm sure that $W_n$ converges in distribution by simulating it using R, in particular the following code: it = 10000 n = 300 mat = matrix(rep(0,n*it),n,it) w = vector() for(i in 1:n) {   mat[i,] = rchisq(it,1) } for(i in 1:n) {   mat[i,] = mat[i,]/2^i } for(j in 1:it) {   w[j] = sum(mat[,j]) } hist(w,freq = F,breaks = seq(0,10,0.1)) produces the following output: $W_{300}$ "" /> which is the distribution of $W_{300}$ . I don't really know if this is a well known distribution, and I don't really know if its density function has a closed form. I don't know how to proceed. Thank you in advance for your help! New approximation of $P(W_{\infty} > 1)$ Using the software R and the library ""CompQuadForm"": https://cran.r-project.org/web/packages/CompQuadForm/CompQuadForm.pdf I manage to approximate the value of $P(W_{\infty} > 1)$ with the code: library(CompQuadForm) n = 10000 q = 1 lambda = vector() for(i in 1:n) {   lambda[i] = 2^(-i) } acc1 = 10^(-15) approx = davies(q, lambda, h = rep(1, length(lambda)), delta = rep(0,length(lambda)), sigma = 0, lim = 500000, acc = acc1)$Qq sprintf(""%.30f"",approx) which gives: $$ P(W_{\infty} > 1) \approx 0.371741079532780016592141691945 $$ which I think are the real first 30 digits. (I'm sure for the first 15 since I set an accuracy of $10^{-15}$ ). Of course I would prefer an ""analytic"" form of this number..","Question Let be i.i.d. chi-square random variables. We define: For example: , and so on. I would like to determine the distribution of defined as: More specifically I have interest in computing the probability ). References Note that this problem has references, in particular in this paper by Mathai: https://www.ism.ac.jp/editsec/aism/pdf/034_3_0591.pdf Reference [4]: In my case, following its notations , are i.i.d. and . The main problem is that I didn't manage to find Prabhu's work about this fact, and in general I didn't manage to find any other references to this problem. My attempt I was trying to approach this problem using the Levy-criteria for the convergence in distribution.. in particular I was trying to calculate (since they are indipendent random variables) the infinite product of their characteristic functions, which is the characteristic function of .. but I wasn't able to determine a closed form for it. In particular if then and so: Code and simulation I'm sure that converges in distribution by simulating it using R, in particular the following code: it = 10000 n = 300 mat = matrix(rep(0,n*it),n,it) w = vector() for(i in 1:n) {   mat[i,] = rchisq(it,1) } for(i in 1:n) {   mat[i,] = mat[i,]/2^i } for(j in 1:it) {   w[j] = sum(mat[,j]) } hist(w,freq = F,breaks = seq(0,10,0.1)) produces the following output: $W_{300}$ "" /> which is the distribution of . I don't really know if this is a well known distribution, and I don't really know if its density function has a closed form. I don't know how to proceed. Thank you in advance for your help! New approximation of Using the software R and the library ""CompQuadForm"": https://cran.r-project.org/web/packages/CompQuadForm/CompQuadForm.pdf I manage to approximate the value of with the code: library(CompQuadForm) n = 10000 q = 1 lambda = vector() for(i in 1:n) {   lambda[i] = 2^(-i) } acc1 = 10^(-15) approx = davies(q, lambda, h = rep(1, length(lambda)), delta = rep(0,length(lambda)), sigma = 0, lim = 500000, acc = acc1)$Qq sprintf(""%.30f"",approx) which gives: which I think are the real first 30 digits. (I'm sure for the first 15 since I set an accuracy of ). Of course I would prefer an ""analytic"" form of this number..","Z_i\sim\chi_{(1)}^2\sim\Gamma(\frac{1}{2},\frac{1}{2}) 
W_n =\Bigl[\sum_{i = 1}^{n-1}\frac{Z_i}{2^{i}}\Bigr] + \frac{Z_n}{2^{n-1}} \mbox{ \forall n\geq 2}
 W_2 = \frac{1}{2}Z_1+\frac{1}{2}Z_2 W_3 = \frac{1}{2}Z_1+\frac{1}{4}Z_2+\frac{1}{4}Z_3 W_{\infty} 
W_{\infty} = \lim_{n\to\infty}W_n = \sum_{k = 1}^{\infty} \frac{Z_k}{2^{k}} \mbox{ where Z_k\sim \Gamma\Bigl(\frac{1}{2},\frac{1}{2}\Bigr) are i.i.d.}
 P(W_{\infty} > 1 \alpha = \frac{1}{2} X_i\sim\Gamma(\frac{1}{2},\frac{1}{2}) n\to\infty W_{\infty} H_k \sim \Gamma(1/2,2^k) \phi_{H_k}(t) = \Bigl(1-\frac{t}{2^k}\Bigr)^{-\frac{1}{2}} 
\phi_{W_{\infty}}(t) = \prod_{k = 0}^{\infty}\frac{1}{\sqrt{1-\frac{it}{2^k}}}
 W_n W_{300} P(W_{\infty} > 1) P(W_{\infty} > 1) 
P(W_{\infty} > 1) \approx 0.371741079532780016592141691945
 10^{-15}","['probability', 'probability-theory', 'probability-distributions', 'probability-limit-theorems', 'infinite-product']"
84,Expected area of an inscribed triangle in a sphere,Expected area of an inscribed triangle in a sphere,,"On the surface of a unit sphere, three points $A$, $B$ and $C$ are   chosen in the following way: Points $A$ and $B$ are chosen randomly and independently on the whole surface After $A$ and $B$ are fixed, $C$ is a point on sphere that maximises the area of $\triangle ABC$. Find the expected area of $\triangle ABC$. (which I assume to be the triangle cutting through the sphere, not on the spherical surface) I am looking for a solution for this question from a test, hopefully a ""smart"" one that uses a quick approach. This was my approach: I quickly chose $C$ to be the mid-point of the major arc of the great circle through $A$ and $B$. To find the area, first I attempted to find the distribution of the angle between two random points, $\angle AOB$ with $O$ being the centre of sphere. I tried to use the fact that bands of equal width on sphere have the same area, and hope that it would link area with the angle $\angle AOB$, but I failed to find the distribution. Lastly I planned to take the expectation of $$\frac12\sin\angle AOB+\sin\frac{2\pi-\angle AOB}2$$ Yet this approach appears to be too lengthy for my test. Edit: I seem to find the distribution of $\Theta=\angle AOB$ as  $$f_\Theta(\theta) = \begin{cases}\frac12\sin\theta&0\le\theta\le\pi\\ 0&\text{otherwise}\end{cases}$$ And the expected value to be $$\int_0^\pi\left(\frac12\sin\theta+\sin\frac{2\pi-\theta}2\right)\frac12\sin\theta\,d\theta = \frac\pi8+\frac23$$","On the surface of a unit sphere, three points $A$, $B$ and $C$ are   chosen in the following way: Points $A$ and $B$ are chosen randomly and independently on the whole surface After $A$ and $B$ are fixed, $C$ is a point on sphere that maximises the area of $\triangle ABC$. Find the expected area of $\triangle ABC$. (which I assume to be the triangle cutting through the sphere, not on the spherical surface) I am looking for a solution for this question from a test, hopefully a ""smart"" one that uses a quick approach. This was my approach: I quickly chose $C$ to be the mid-point of the major arc of the great circle through $A$ and $B$. To find the area, first I attempted to find the distribution of the angle between two random points, $\angle AOB$ with $O$ being the centre of sphere. I tried to use the fact that bands of equal width on sphere have the same area, and hope that it would link area with the angle $\angle AOB$, but I failed to find the distribution. Lastly I planned to take the expectation of $$\frac12\sin\angle AOB+\sin\frac{2\pi-\angle AOB}2$$ Yet this approach appears to be too lengthy for my test. Edit: I seem to find the distribution of $\Theta=\angle AOB$ as  $$f_\Theta(\theta) = \begin{cases}\frac12\sin\theta&0\le\theta\le\pi\\ 0&\text{otherwise}\end{cases}$$ And the expected value to be $$\int_0^\pi\left(\frac12\sin\theta+\sin\frac{2\pi-\theta}2\right)\frac12\sin\theta\,d\theta = \frac\pi8+\frac23$$",,"['probability', 'probability-distributions', 'euclidean-geometry', 'geometric-probability']"
85,Crisis in my understanding of probability [duplicate],Crisis in my understanding of probability [duplicate],,"This question already has answers here : Why is not the answer to all probability questions 1/2. (6 answers) Closed 6 years ago . If I were to roll a die, what would ​be the probability of getting $2$? Certainly it would be $\dfrac 16$ (because there are $6$ numbers and sample space contains 6 numbers)  But I think we can look at it another way.  We need $2$ right? and from $1-6$ there is only one number which is $2$ i.e. $2$. If I were to roll there would essentially be two types of numbers ie. one which is $2$ and one which is not ie $1,3,4,5,6$. So there are two basic outcomes. P(E) = number $2$÷total outcomes ie $2$. P(E)= $\dfrac 12$ So why is the probability $\dfrac 16$(when it is clear that the outcome we desire, can either happen or not happen.) Shouldn't the probability be $\dfrac 12$ instead, why not?","This question already has answers here : Why is not the answer to all probability questions 1/2. (6 answers) Closed 6 years ago . If I were to roll a die, what would ​be the probability of getting $2$? Certainly it would be $\dfrac 16$ (because there are $6$ numbers and sample space contains 6 numbers)  But I think we can look at it another way.  We need $2$ right? and from $1-6$ there is only one number which is $2$ i.e. $2$. If I were to roll there would essentially be two types of numbers ie. one which is $2$ and one which is not ie $1,3,4,5,6$. So there are two basic outcomes. P(E) = number $2$÷total outcomes ie $2$. P(E)= $\dfrac 12$ So why is the probability $\dfrac 16$(when it is clear that the outcome we desire, can either happen or not happen.) Shouldn't the probability be $\dfrac 12$ instead, why not?",,"['probability', 'probability-theory', 'terminology', 'paradoxes']"
86,Variant of boy or girl paradox,Variant of boy or girl paradox,,"Here is an interesting question my friend brought up: You are invited to a family party. A Boy opens the door for you. There   are two children there. What is the probability that a boy opens door for   you next time? This is my solution: $$P(\text{boy second time | boy first time}) = \frac{P(\text{boy both time)}}{P(\text{boy first time)}}$$ $$=\frac{1/3+1/3*1/2*1/2+1/3*1/2*1/2}{1/3+1/3*1/2+1/3*1/2}=3/4$$ The $1/3$ comes from the fact that given we have one boy already so the combination can only be {boy, girl}, {girl, boy}, {boy, boy}. The 1/2 comes from for each time there is a 1/2 probability that a boy will open the door if there is one boy one girl. Is my calculation correct? I feel not confident about the 1/3 argument. Edited: @Rolf proposed another point that actually the probability of two boys and one boy/one girl should be 1/2, not 1/3 each. Edited again: Actually there are two approaches, as shown below. The key is to whether to assume the prior or not in the calculation.","Here is an interesting question my friend brought up: You are invited to a family party. A Boy opens the door for you. There   are two children there. What is the probability that a boy opens door for   you next time? This is my solution: $$P(\text{boy second time | boy first time}) = \frac{P(\text{boy both time)}}{P(\text{boy first time)}}$$ $$=\frac{1/3+1/3*1/2*1/2+1/3*1/2*1/2}{1/3+1/3*1/2+1/3*1/2}=3/4$$ The $1/3$ comes from the fact that given we have one boy already so the combination can only be {boy, girl}, {girl, boy}, {boy, boy}. The 1/2 comes from for each time there is a 1/2 probability that a boy will open the door if there is one boy one girl. Is my calculation correct? I feel not confident about the 1/3 argument. Edited: @Rolf proposed another point that actually the probability of two boys and one boy/one girl should be 1/2, not 1/3 each. Edited again: Actually there are two approaches, as shown below. The key is to whether to assume the prior or not in the calculation.",,"['probability', 'paradoxes']"
87,Probability of drawing all 4 balls,Probability of drawing all 4 balls,,"A Greek urn contains a red, blue, yellow, and orange ball. A ball is drawn from the urn at random and then replaced. If one does this $4$ times, what is the probability that all $4$ colors were selected? I approached this questions by doing $(1/4)^4$ because there's always a $1/4$ chance of selected a specific color ball if it's replaced. I also tried doing if not the correct ball was selected; so I did $(3/4)^4$ but that didn't work either. What am I doing wrong?","A Greek urn contains a red, blue, yellow, and orange ball. A ball is drawn from the urn at random and then replaced. If one does this $4$ times, what is the probability that all $4$ colors were selected? I approached this questions by doing $(1/4)^4$ because there's always a $1/4$ chance of selected a specific color ball if it's replaced. I also tried doing if not the correct ball was selected; so I did $(3/4)^4$ but that didn't work either. What am I doing wrong?",,['probability']
88,Probability of winning a game by rolling the die first,Probability of winning a game by rolling the die first,,"Two persons are playing a game where they take turns rolling a die (so A rolls first, then B, then A again and so on). The first person to roll a $6$ wins the game. What is the probability that the person who started the game (rolled the die first) wins? This was the question that I was given, but I feel like the probability depends on the number of turns played? My approach was that the probability of rolling a 6 at any particular turn will be $\frac{1}{6}$ . So, the probability of winning in $n$ turns will be the probability of not rolling a $6$ on the first $n-1$ turns (since if a $6$ had been rolled, that would have been the last, i.e. the $nth$ turn) and then rolling a $6$ on the $nth$ turn. The required probability would then be $$\frac{5}{6}\cdot\frac{5}{6}\cdot\frac{5}{6}\cdot...(n-1\text{ times})\cdot\frac{1}{6} = \frac{5^{n-1}}{6^n}$$ Is this train of thought correct? Or have I misunderstood something?","Two persons are playing a game where they take turns rolling a die (so A rolls first, then B, then A again and so on). The first person to roll a wins the game. What is the probability that the person who started the game (rolled the die first) wins? This was the question that I was given, but I feel like the probability depends on the number of turns played? My approach was that the probability of rolling a 6 at any particular turn will be . So, the probability of winning in turns will be the probability of not rolling a on the first turns (since if a had been rolled, that would have been the last, i.e. the turn) and then rolling a on the turn. The required probability would then be Is this train of thought correct? Or have I misunderstood something?",6 \frac{1}{6} n 6 n-1 6 nth 6 nth \frac{5}{6}\cdot\frac{5}{6}\cdot\frac{5}{6}\cdot...(n-1\text{ times})\cdot\frac{1}{6} = \frac{5^{n-1}}{6^n},"['probability', 'dice']"
89,Probability that last child is a boy,Probability that last child is a boy,,"Johnny has 4 children. It is known that he has more daughters than sons. Find the probability that the last child is a boy. I let A be the event that the last child is a boy, P(A) = $\frac{1}{2}$. and B be the event that he as more daughters than sons. But im not sure how to calculate P(B) and what are the subsequent steps to take after. Appreciate any help. Thanks","Johnny has 4 children. It is known that he has more daughters than sons. Find the probability that the last child is a boy. I let A be the event that the last child is a boy, P(A) = $\frac{1}{2}$. and B be the event that he as more daughters than sons. But im not sure how to calculate P(B) and what are the subsequent steps to take after. Appreciate any help. Thanks",,['probability']
90,"If a deck of 54 cards (including 2 jokers) is evenly split into 3 groups of 18, what is the probability that any one group contains both jokers?","If a deck of 54 cards (including 2 jokers) is evenly split into 3 groups of 18, what is the probability that any one group contains both jokers?",,"I was just asked this interview question on combinatorics: A deck of 54 cards (includes 2 jokers) are split into 3 equal groups of 18. What is the probability of any single group having both jokers? I only had time to think of a solution post-interview, but please check whether my answer is correct: $$ P = \frac{\text{Ways to form group with 2 jokers} \times \text{Ways to form 1st non-joker group} \times \text{Ways to form 2nd non-joker group}}{\text{Ways to form 3 equal groups}} $$ $$ P = \frac{{2 \choose 2}{52 \choose 16} \times {36 \choose 18} \times {18 \choose 18}}{{54 \choose 18}{36 \choose 18}{18 \choose 18} / 3!} $$ I'm not sure whether I need to divide by $3!$ in the denominator, since it seems the numerator will also have this and it cancels out?","I was just asked this interview question on combinatorics: A deck of 54 cards (includes 2 jokers) are split into 3 equal groups of 18. What is the probability of any single group having both jokers? I only had time to think of a solution post-interview, but please check whether my answer is correct: I'm not sure whether I need to divide by in the denominator, since it seems the numerator will also have this and it cancels out?","
P = \frac{\text{Ways to form group with 2 jokers} \times \text{Ways to form 1st non-joker group} \times \text{Ways to form 2nd non-joker group}}{\text{Ways to form 3 equal groups}}
 
P = \frac{{2 \choose 2}{52 \choose 16} \times {36 \choose 18} \times {18 \choose 18}}{{54 \choose 18}{36 \choose 18}{18 \choose 18} / 3!}
 3!","['probability', 'combinatorics', 'card-games']"
91,Probability of a random graph being triangle-free,Probability of a random graph being triangle-free,,"Let $S$ be the set of all graphs with vertex set $\{1,2,\ldots,n\}$. A random graph $G\in S$ has probability $2^{-{n \choose 2}}$. Show that a random graph almost surely contains a triangle. My attempt so far: we want to show that as $n$ goes to infinity, the probability of a triangle-free graph goes to zero. I tried to find a general formula for the probability of a triangle-free graph with $n$ vertices, but it seems impossible. I know that for any three vertices, the probability of not being a triangle is $\frac{7}{8}$, but I can't calculate the probability of the union of all such three vertices. Is there any other way to approach this problem?","Let $S$ be the set of all graphs with vertex set $\{1,2,\ldots,n\}$. A random graph $G\in S$ has probability $2^{-{n \choose 2}}$. Show that a random graph almost surely contains a triangle. My attempt so far: we want to show that as $n$ goes to infinity, the probability of a triangle-free graph goes to zero. I tried to find a general formula for the probability of a triangle-free graph with $n$ vertices, but it seems impossible. I know that for any three vertices, the probability of not being a triangle is $\frac{7}{8}$, but I can't calculate the probability of the union of all such three vertices. Is there any other way to approach this problem?",,"['probability', 'discrete-mathematics']"
92,Expected number of cards in original position in a shuffled deck of $52$ cards?,Expected number of cards in original position in a shuffled deck of  cards?,52,Assume is shuffle is quite good that it randomizes the card order. We know that E = $ \sum_{X=1}^n X*P(X) $ We are already know that n=52 and that there are 52! ways to arrange the cards. So probability that exactly 1 card is in correct position is $\frac{1}{52!} {52 \choose 1}*$ (derangements of remaining cards) This will be summed over all the 52 cases. This seems a bit complicated. Is there a simpler way?,Assume is shuffle is quite good that it randomizes the card order. We know that E = We are already know that n=52 and that there are 52! ways to arrange the cards. So probability that exactly 1 card is in correct position is (derangements of remaining cards) This will be summed over all the 52 cases. This seems a bit complicated. Is there a simpler way?, \sum_{X=1}^n X*P(X)  \frac{1}{52!} {52 \choose 1}*,"['probability', 'combinatorics', 'permutations', 'expected-value']"
93,"If you toss $1000$ fair coins $10$ times each, what is the probability the *some* coin will get $10$ heads?","If you toss  fair coins  times each, what is the probability the *some* coin will get  heads?",1000 10 10,"The answer to this is supposedly close to $0.63$. However, I get approximately $0.9765625$ for the following reason: The probability of a fair coin flipped $N$ times resulting in all heads is $1/2^N$. In this case, $1/2^{10}=1/1024$. If I flip $M$ coins, $N$ times each, there are $M$ ways for some coin to result in all heads (from the binomial coefficient ""$M$ choose $1$""), so the probability of some coin resulting in all heads is $M(1/2^N)$. In this case, $1000\times 1/1024 \approx 0.9765625$. Can someone please explain the flaw in my reasoning?","The answer to this is supposedly close to $0.63$. However, I get approximately $0.9765625$ for the following reason: The probability of a fair coin flipped $N$ times resulting in all heads is $1/2^N$. In this case, $1/2^{10}=1/1024$. If I flip $M$ coins, $N$ times each, there are $M$ ways for some coin to result in all heads (from the binomial coefficient ""$M$ choose $1$""), so the probability of some coin resulting in all heads is $M(1/2^N)$. In this case, $1000\times 1/1024 \approx 0.9765625$. Can someone please explain the flaw in my reasoning?",,"['probability', 'probability-theory']"
94,A question of random points in a square and probability of intersection of their line segments,A question of random points in a square and probability of intersection of their line segments,,"The following is a problem from PUMaC 2007: Take the square with vertices $(0,0)$ , $(1,0)$ , $(0,1)$ , and $(1,1)$ . Choose a random point in this square and draw the line segment from it to $(0,0)$ . Choose a second random point in this square and draw the line segment from it to $(1,0)$ . What is the probability that the two line segments intersect? I tried to find the probability by taking the general point $(x,y)$ and finding the region in which the second point should lie so that the line segments intersect, however, I am stuck in this step. My idea was to find the area of the region, divide by area of the square to get probability and then double integrate wrt y and x to get probability.  I have failed at this after multiple attempts, If the region is a triangle (which is erroneous) I got the answer as $3/8$ , and if I try to do the general case, I find that the integral does not converge. (Do note, over here vertices are adjacent, not opposite)","The following is a problem from PUMaC 2007: Take the square with vertices , , , and . Choose a random point in this square and draw the line segment from it to . Choose a second random point in this square and draw the line segment from it to . What is the probability that the two line segments intersect? I tried to find the probability by taking the general point and finding the region in which the second point should lie so that the line segments intersect, however, I am stuck in this step. My idea was to find the area of the region, divide by area of the square to get probability and then double integrate wrt y and x to get probability.  I have failed at this after multiple attempts, If the region is a triangle (which is erroneous) I got the answer as , and if I try to do the general case, I find that the integral does not converge. (Do note, over here vertices are adjacent, not opposite)","(0,0) (1,0) (0,1) (1,1) (0,0) (1,0) (x,y) 3/8","['probability', 'probability-theory', 'geometric-probability']"
95,Methods for Finding Raw Moments of the Normal Distribution,Methods for Finding Raw Moments of the Normal Distribution,,"I'm having some trouble with finding raw moments for the normal distribution. Right now I am trying to find the 4th raw moment on my own. So far, I know of two methods: I can take the 4th derivative of the moment generating function for the normal distribution and evaluate it at 0. I can use the fact that $E(x^4)$ is an expectation of a function of x to write  $$E({X}^{4})=\int_{Sx}^{} {x}^{4} f(x) dx=\int_{-\infty}^{\infty} {x}^{4}\frac{{e}^{\frac{{(x-\mu )}^{2}}{2{\sigma }^{2}}}}{\sqrt{2\pi }\sigma } dx$$ I'm wondering if there's a 3rd method. We haven't covered integrating the normal pdf in class, and taking the 4th derivative of ${e}^{\frac{{t}^{2}{\sigma }^{2}}{2}+t\mu }$ seems really messy/inelegant, so I'm wondering if there is some conceptual piece about moment generating functions I am missing. Thanks in advance!","I'm having some trouble with finding raw moments for the normal distribution. Right now I am trying to find the 4th raw moment on my own. So far, I know of two methods: I can take the 4th derivative of the moment generating function for the normal distribution and evaluate it at 0. I can use the fact that $E(x^4)$ is an expectation of a function of x to write  $$E({X}^{4})=\int_{Sx}^{} {x}^{4} f(x) dx=\int_{-\infty}^{\infty} {x}^{4}\frac{{e}^{\frac{{(x-\mu )}^{2}}{2{\sigma }^{2}}}}{\sqrt{2\pi }\sigma } dx$$ I'm wondering if there's a 3rd method. We haven't covered integrating the normal pdf in class, and taking the 4th derivative of ${e}^{\frac{{t}^{2}{\sigma }^{2}}{2}+t\mu }$ seems really messy/inelegant, so I'm wondering if there is some conceptual piece about moment generating functions I am missing. Thanks in advance!",,"['probability', 'normal-distribution', 'moment-generating-functions']"
96,"If n people randomly pick one hat out of $n$ hats, why is the probability of a match $1/n$? What about order of previous hats?","If n people randomly pick one hat out of  hats, why is the probability of a match ? What about order of previous hats?",n 1/n,"For a standard matching problem There are $n$ people with hats at a party. Each person randomly grabs a hat. A match occurs if a person gets his own hat. Define the number of matches $N$ as $$ N=\sum_{k=1}^n X_k, $$ where $X_k$ is the indicator function $$ X_k= I\{\text{person } k\text{ grabs his own hat}\}. $$ Why is $$ P(X_k=1)=\frac{1}{n}? $$ I expect $P(X_k=1)$ to depend on the order, so I don't see why $P(X_k=1)$ simplifies to $1/n$.","For a standard matching problem There are $n$ people with hats at a party. Each person randomly grabs a hat. A match occurs if a person gets his own hat. Define the number of matches $N$ as $$ N=\sum_{k=1}^n X_k, $$ where $X_k$ is the indicator function $$ X_k= I\{\text{person } k\text{ grabs his own hat}\}. $$ Why is $$ P(X_k=1)=\frac{1}{n}? $$ I expect $P(X_k=1)$ to depend on the order, so I don't see why $P(X_k=1)$ simplifies to $1/n$.",,[]
97,Probability of getting a second $6$,Probability of getting a second,6,"A sister has two fair six sided dice, one red one blue, the dice are rolled together. The sister announces to her brother who is sat in another room and unable to see the dice, that there is at least one six in the outcome. Then asks him what are the odds that the other die is a six. He replies $1/6$, she says no it has to be $1/11$. Who is right or most likely to be right? Please help settle this family feud!","A sister has two fair six sided dice, one red one blue, the dice are rolled together. The sister announces to her brother who is sat in another room and unable to see the dice, that there is at least one six in the outcome. Then asks him what are the odds that the other die is a six. He replies $1/6$, she says no it has to be $1/11$. Who is right or most likely to be right? Please help settle this family feud!",,"['probability', 'dice']"
98,A question about Poker (and probability in general),A question about Poker (and probability in general),,"Okay, so I've been thinking about this question for a long time, and I'm starting to think that there isn't an answer. So please read the question, and if there is an answer, tell how you came to it, and if there isn't, tell me why. There are a certain number of hands that can be dealt from a deck of 52 cards. Playing five card hands of poker, there are 52*51*50*49*48 possible hands, if I'm not mistaken. The question is, how many hands would you have to deal in order to have dealt every hand at least once? Assume that five cards are dealt, then those cards are shuffled into the deck and another five random cards are dealt. How many times would you have to deal, on average, before having dealt every hamd?","Okay, so I've been thinking about this question for a long time, and I'm starting to think that there isn't an answer. So please read the question, and if there is an answer, tell how you came to it, and if there isn't, tell me why. There are a certain number of hands that can be dealt from a deck of 52 cards. Playing five card hands of poker, there are 52*51*50*49*48 possible hands, if I'm not mistaken. The question is, how many hands would you have to deal in order to have dealt every hand at least once? Assume that five cards are dealt, then those cards are shuffled into the deck and another five random cards are dealt. How many times would you have to deal, on average, before having dealt every hamd?",,"['probability', 'card-games']"
99,Calculating the probability of seeing a shooting star within half an hour if we know it for one hour,Calculating the probability of seeing a shooting star within half an hour if we know it for one hour,,The probability to see a falling star in the sky over the course of one hour is 0.64. What is the probability to see it over the course of half an hour?,The probability to see a falling star in the sky over the course of one hour is 0.64. What is the probability to see it over the course of half an hour?,,['probability']
