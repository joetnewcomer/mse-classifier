,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Density of $X-Y$ where $X,Y$ are independent random variables with common PDF $f(x) = e^{-x}$?",Density of  where  are independent random variables with common PDF ?,"X-Y X,Y f(x) = e^{-x}","$X,Y$ are independent random variables with common PDF $f(x) = e^{-x}$ then density of $X-Y = \text{?}$ I thought of this let $ Y_1 = X + Y$, $Y_2 = \frac{X-Y}{X+Y}$, solving which gives me $X = \frac{Y_1(1 + Y_2)}{2}$, $Y = \frac{Y_1-Y_2}{2}$ then I calculated the Jacobian $J = \begin{bmatrix} \frac{1+y_2}{2} & \frac{y_1}{2} \\ \frac{1}{2} & -\frac{1}{2} \end{bmatrix}$ so that $\left|\det(J)\right| = \frac{1+y_1+y_2}{4}$ and the joint density of $Y_1,Y_2$ is the following $W(Y_1,Y_2) = \left|\det(J)\right| e^{-(y_1+y_2)}$ when $y_1,y_2> 0$ and $0$ otherwise. Next I thought of recovering $X-Y$ as the marginal but I got stuck. I think i messed up in the variables. Any help is great!.","$X,Y$ are independent random variables with common PDF $f(x) = e^{-x}$ then density of $X-Y = \text{?}$ I thought of this let $ Y_1 = X + Y$, $Y_2 = \frac{X-Y}{X+Y}$, solving which gives me $X = \frac{Y_1(1 + Y_2)}{2}$, $Y = \frac{Y_1-Y_2}{2}$ then I calculated the Jacobian $J = \begin{bmatrix} \frac{1+y_2}{2} & \frac{y_1}{2} \\ \frac{1}{2} & -\frac{1}{2} \end{bmatrix}$ so that $\left|\det(J)\right| = \frac{1+y_1+y_2}{4}$ and the joint density of $Y_1,Y_2$ is the following $W(Y_1,Y_2) = \left|\det(J)\right| e^{-(y_1+y_2)}$ when $y_1,y_2> 0$ and $0$ otherwise. Next I thought of recovering $X-Y$ as the marginal but I got stuck. I think i messed up in the variables. Any help is great!.",,"['probability', 'probability-distributions', 'density-function', 'exponential-distribution']"
1,Probability from randomized dice,Probability from randomized dice,,"Suppose you have a pair of dice that have removable stickers for numbers on each of their 6 sides. Suppose that you unstick all 12 of the stickers from the dice and reapply them randomly to the 2 dice. You will still have 2 occurrences of each number 1 through 6. However, they may both occur on the same die. (For instance: after rearranging the stickers, you may have dice $d_1$ and $d_2$ with sides  $d_1 = [1,2,2,4,4,6]$ and $d_2 = [1,3,3,5,5,6]$.) Suppose now that you roll this randomized pair of dice. Is there a concise way to calculate the probability of each outcome? What is the probability of each possible outcome? Just by working out some of the possible arrangements, it seems like $p(2)$ should be $\frac{1}{72}$ (which might not be correct), but the other probabilities are more difficult to compute this way.","Suppose you have a pair of dice that have removable stickers for numbers on each of their 6 sides. Suppose that you unstick all 12 of the stickers from the dice and reapply them randomly to the 2 dice. You will still have 2 occurrences of each number 1 through 6. However, they may both occur on the same die. (For instance: after rearranging the stickers, you may have dice $d_1$ and $d_2$ with sides  $d_1 = [1,2,2,4,4,6]$ and $d_2 = [1,3,3,5,5,6]$.) Suppose now that you roll this randomized pair of dice. Is there a concise way to calculate the probability of each outcome? What is the probability of each possible outcome? Just by working out some of the possible arrangements, it seems like $p(2)$ should be $\frac{1}{72}$ (which might not be correct), but the other probabilities are more difficult to compute this way.",,"['probability', 'dice']"
2,Simple calculation in imprecise probability urn example,Simple calculation in imprecise probability urn example,,"In Miranda and de Cooman's chapter 3, ""Structural judgements"" , in Augustin et al.'s Introduction to Imprecise Probability , example 3.4 on p. 65 shows that independence in the selection (type-2 independence) does not imply strong independence (type-3 independence) for lower previsions.  One of the numerical values in the example seems incorrect to me.  I'm not sure whether there is a typo (there is an obvious trivial typo at the top of the same page, so this seems possible), or whether I don't fully understand the example (quite plausible). There are two possible configurations, or compositions, for a pair of urns containing red ( $R$ ) and green ( $G$ ) balls, but we don't know which configuration is actual.  Given a configuration, draws from each urn are random, i.e. independent. Configuration 1:    Urn 1: $\{R, R, G\}$ Urn 2: $\{R,R,G\}$ Configuration 2:    Urn 1: $\{R, G, G\}$ Urn 2: $\{R,G,G\}$ Let $X_k$ be the r.v. representing the outcome of the draw from the $k$ th urn.  The text claims that given this setup, the lower prevision $\underline P$ of $X_1=R$ & $X_2=G$ is \begin{equation} \underline P(X_1 = R, X_2=G) = \frac{4}{9} . \end{equation} It seems to me that this value should be 2/9.  Since the draws are independent within each configuration, the probability (linear prevision) corresponding to configuration 1 is \begin{equation} P(X_1 = R, X_2=G) = P(X_1=R) \times P(X_2=G) = \frac{2}{3} \times \frac{1}{3} = \frac{2}{9} . \end{equation} Similarly, the probability corresponding to configuration 2 is \begin{equation} \frac{1}{3} \times \frac{2}{3} = \frac{2}{9} . \end{equation} Since the lower prevision is the lower envelope of the probabilities in this example, it seems to follow that $\underline P(X_1 = R, X_2=G) = 2/9$ .  However, I suspect that I've interpreted the example incorrectly in some respect or have some more basic misunderstanding. (I believe that if 2/9 were the correct value here, the example would still illustrate the point that independence in the selection doesn't imply strong independence.  For that point all that's needed is that $\underline P(X_1 = R, X_2=G) > 1/9$ .)","In Miranda and de Cooman's chapter 3, ""Structural judgements"" , in Augustin et al.'s Introduction to Imprecise Probability , example 3.4 on p. 65 shows that independence in the selection (type-2 independence) does not imply strong independence (type-3 independence) for lower previsions.  One of the numerical values in the example seems incorrect to me.  I'm not sure whether there is a typo (there is an obvious trivial typo at the top of the same page, so this seems possible), or whether I don't fully understand the example (quite plausible). There are two possible configurations, or compositions, for a pair of urns containing red ( ) and green ( ) balls, but we don't know which configuration is actual.  Given a configuration, draws from each urn are random, i.e. independent. Configuration 1:    Urn 1: Urn 2: Configuration 2:    Urn 1: Urn 2: Let be the r.v. representing the outcome of the draw from the th urn.  The text claims that given this setup, the lower prevision of & is It seems to me that this value should be 2/9.  Since the draws are independent within each configuration, the probability (linear prevision) corresponding to configuration 1 is Similarly, the probability corresponding to configuration 2 is Since the lower prevision is the lower envelope of the probabilities in this example, it seems to follow that .  However, I suspect that I've interpreted the example incorrectly in some respect or have some more basic misunderstanding. (I believe that if 2/9 were the correct value here, the example would still illustrate the point that independence in the selection doesn't imply strong independence.  For that point all that's needed is that .)","R G \{R, R, G\} \{R,R,G\} \{R, G, G\} \{R,G,G\} X_k k \underline P X_1=R X_2=G \begin{equation}
\underline P(X_1 = R, X_2=G) = \frac{4}{9} .
\end{equation} \begin{equation}
P(X_1 = R, X_2=G) = P(X_1=R) \times P(X_2=G) = \frac{2}{3} \times \frac{1}{3} = \frac{2}{9} .
\end{equation} \begin{equation}
\frac{1}{3} \times \frac{2}{3} = \frac{2}{9} .
\end{equation} \underline P(X_1 = R, X_2=G) = 2/9 \underline P(X_1 = R, X_2=G) > 1/9","['probability', 'bayesian', 'imprecise-probability']"
3,Random Variable Distribution problem,Random Variable Distribution problem,,"You just rented a large house and the realtor gave you five keys, one for the front door and the other four for each of the four side and back doors of the house. Unfortunately, all keys look identical, so to open the front door, you are forced to try them at random.   Find the distribution and the expectation of the number of trials you will need to open the front door. (Assume that you can mark a key after you’ve tried opening the front door with it and it doesn’t work.) I started doing this problem by setting r.v. $X$ to be the number of trials (keys) you have to try in order to unlock the front door. Then in order to find the distribution, I know I have to find the probability of success for each number of trials. This is what I came up with X Pr[X] 1 1/5 2 1/4 3 1/3 4 1/2 5 1/1 I thought this was true because for example The probability of 1 key opening the front door is 1/5 The probability of 2 keys opening the door is 1/4 because one of the keys have already been marked as incorrect (sampling without replacement) However, the answer turned out to be this: I'm confused as to why $Pr[K=2] = \frac{4}{5} \times \frac{1}{4}$ ... where did those values come from? I think if I understand the method used for the first one I can figure out the rest","You just rented a large house and the realtor gave you five keys, one for the front door and the other four for each of the four side and back doors of the house. Unfortunately, all keys look identical, so to open the front door, you are forced to try them at random.   Find the distribution and the expectation of the number of trials you will need to open the front door. (Assume that you can mark a key after you’ve tried opening the front door with it and it doesn’t work.) I started doing this problem by setting r.v. $X$ to be the number of trials (keys) you have to try in order to unlock the front door. Then in order to find the distribution, I know I have to find the probability of success for each number of trials. This is what I came up with X Pr[X] 1 1/5 2 1/4 3 1/3 4 1/2 5 1/1 I thought this was true because for example The probability of 1 key opening the front door is 1/5 The probability of 2 keys opening the door is 1/4 because one of the keys have already been marked as incorrect (sampling without replacement) However, the answer turned out to be this: I'm confused as to why $Pr[K=2] = \frac{4}{5} \times \frac{1}{4}$ ... where did those values come from? I think if I understand the method used for the first one I can figure out the rest",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
4,"If $E(XY)=E(X) \cdot E(Y)$, why is not $E(X^2)=[E(X)^2]$ [duplicate]","If , why is not  [duplicate]",E(XY)=E(X) \cdot E(Y) E(X^2)=[E(X)^2],"This question already has answers here : Why is the expected value $E(X^2) \neq E(X)^2$? (10 answers) Closed 7 years ago . My book states that the expected value of the product of two independent random variables equal the product of their expected values. Why cannot one use this to give the following? $$E(X \cdot X) = E(X) \cdot E(X) = [E(X)]^2$$ Of course, this is incorrect, as if this were true the variance would always be 0.","This question already has answers here : Why is the expected value $E(X^2) \neq E(X)^2$? (10 answers) Closed 7 years ago . My book states that the expected value of the product of two independent random variables equal the product of their expected values. Why cannot one use this to give the following? $$E(X \cdot X) = E(X) \cdot E(X) = [E(X)]^2$$ Of course, this is incorrect, as if this were true the variance would always be 0.",,"['probability', 'probability-theory', 'random-variables']"
5,Probability of getting an odd number of heads if n biased coins are tossed once.,Probability of getting an odd number of heads if n biased coins are tossed once.,,"The question is basically to find out the probability of getting odd number of heads when $ n$ biased coins,with $m^{th}$ coin having probability of throwing head equal to $\frac{1}{2m+1}$ ($m=1,2,\cdots,n$) are tossed once.The results for each coin are independent. If we consider first that only one head turns up.The probability then is equal to $$\sum_{m=1}^{n} [\frac{1}{2m+1} \prod_{k=1,k \neq m}^{n} (1-\frac{1}{2k+1})]$$ which seems very difficult to evaluate.It gets more complicated if we increase the number of heads.I couldnot find out a simple way to do this.Any suggestion would be highly appreciated.Thanks.","The question is basically to find out the probability of getting odd number of heads when $ n$ biased coins,with $m^{th}$ coin having probability of throwing head equal to $\frac{1}{2m+1}$ ($m=1,2,\cdots,n$) are tossed once.The results for each coin are independent. If we consider first that only one head turns up.The probability then is equal to $$\sum_{m=1}^{n} [\frac{1}{2m+1} \prod_{k=1,k \neq m}^{n} (1-\frac{1}{2k+1})]$$ which seems very difficult to evaluate.It gets more complicated if we increase the number of heads.I couldnot find out a simple way to do this.Any suggestion would be highly appreciated.Thanks.",,['probability']
6,Expected days to finish a box of cookies,Expected days to finish a box of cookies,,Adam has a box containing 10 cookies. Each day he eats each cookie with a probability of $\frac12$. Calculate the expected number of days it takes Adam to complete the cookies. As a start we can set $X$ as the expected days it takes for Adam to finish eating the cookies. However I'm unable to progress further.,Adam has a box containing 10 cookies. Each day he eats each cookie with a probability of $\frac12$. Calculate the expected number of days it takes Adam to complete the cookies. As a start we can set $X$ as the expected days it takes for Adam to finish eating the cookies. However I'm unable to progress further.,,"['probability', 'combinatorics', 'discrete-mathematics']"
7,Expected Value Problem with a Polar Bear Using a Typewriter,Expected Value Problem with a Polar Bear Using a Typewriter,,"A polar bear starts to write an $80$ character word on a typewriter, where each letter is equally likely to occur (no other symbols or spaces can occur, just letters). I want to find out the expected number of times the phrase ""PANDA"" occurs in the sentence. I can see that ""PANDA"" can occur a maximum of  $\frac{80}{5} = 16$ times within the word. I can see generally a sketch of how to get the first term, since I originally thought that I can place ""PANDA"" in $76$ spaces, then place the rest of the possible letters $(26)^{75}$ ways. When we compare to the number of $80$-character letter strings available, on initial guess, one would think that the first term would be $$\frac{76 (26)^{75}}{(26)^{80}},$$ but obviously this also counts the instances where ""PANDA"" also shows up in the other $75$ characters in the string. Is there a reasonable way to remove those observations from this term? I would like to know this so I can also account for their removal in later terms. Otherwise, is there a more reasonable way to compute this expected value?","A polar bear starts to write an $80$ character word on a typewriter, where each letter is equally likely to occur (no other symbols or spaces can occur, just letters). I want to find out the expected number of times the phrase ""PANDA"" occurs in the sentence. I can see that ""PANDA"" can occur a maximum of  $\frac{80}{5} = 16$ times within the word. I can see generally a sketch of how to get the first term, since I originally thought that I can place ""PANDA"" in $76$ spaces, then place the rest of the possible letters $(26)^{75}$ ways. When we compare to the number of $80$-character letter strings available, on initial guess, one would think that the first term would be $$\frac{76 (26)^{75}}{(26)^{80}},$$ but obviously this also counts the instances where ""PANDA"" also shows up in the other $75$ characters in the string. Is there a reasonable way to remove those observations from this term? I would like to know this so I can also account for their removal in later terms. Otherwise, is there a more reasonable way to compute this expected value?",,"['probability', 'combinatorics']"
8,What is the smallest and largest possible values for the variance?,What is the smallest and largest possible values for the variance?,,"Suppose $P( X \in \{1,2,3\}) = 1$ and  $E(X) =2.5.$ What is the smallest and largest possible values for the variance? My understand: So what I understand is variance finds the distance between each element and the mean. So the closer 2 is to E(X) the farther 1 and 3 can be from E(X). But I have no clue how to obtain this..","Suppose $P( X \in \{1,2,3\}) = 1$ and  $E(X) =2.5.$ What is the smallest and largest possible values for the variance? My understand: So what I understand is variance finds the distance between each element and the mean. So the closer 2 is to E(X) the farther 1 and 3 can be from E(X). But I have no clue how to obtain this..",,['probability']
9,Rearrangement of Students (flaw in my solution),Rearrangement of Students (flaw in my solution),,"There are 11 students in a class including A, B and C. The 11 students have to form a straight line. Provided that A cannot be the first person in the line, what is the probability that in any random rearrangement of line, A comes before B and C. For eg, this is a valid rearrangement (1-8 are other students) 1 2 3 A 4 5 C 6 7 B 8 Here's my solution - Probability that A goes before B and C without any restrictions is $\frac13$. (Notice the symmetry. The answer will be same for B goes first and C goes first.) Probability that A goes first without any restrictions is $\frac{1}{11}$ Hence the answer is $$\frac13 - \frac{1}{11} = \frac{8}{33}$$ But the answer is $\frac{4}{15}$ according to my textbook. Please help me to find flaw in my solution.","There are 11 students in a class including A, B and C. The 11 students have to form a straight line. Provided that A cannot be the first person in the line, what is the probability that in any random rearrangement of line, A comes before B and C. For eg, this is a valid rearrangement (1-8 are other students) 1 2 3 A 4 5 C 6 7 B 8 Here's my solution - Probability that A goes before B and C without any restrictions is $\frac13$. (Notice the symmetry. The answer will be same for B goes first and C goes first.) Probability that A goes first without any restrictions is $\frac{1}{11}$ Hence the answer is $$\frac13 - \frac{1}{11} = \frac{8}{33}$$ But the answer is $\frac{4}{15}$ according to my textbook. Please help me to find flaw in my solution.",,"['probability', 'combinatorics']"
10,Independence of complementary events,Independence of complementary events,,"Suppose $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space, $I$ is an arbitrary index set and $\{A_i\}_{i \in I} \in \mathcal{F}^{I}$. For $i \in I$ we define $B_i^{(0)} := A_i$ and $B_i^{(1)} := A_i^{\mathsf{c}}$. I want to show the implication   $$ \exists \, \alpha \in \{0,1\}^{I} \colon \ \{B_i^{(\alpha_i)}\}_{i \in I} \text{ is independent } \Longrightarrow \{A_i\}_{i \in I} \text{ is independent }. $$ Let $\alpha$ be the fixed sequence and let $J \subseteq I$ with $|J|< \infty$. We have to show that $$ \mathbb{P}\left( \bigcap_{j \in J} A_j \right) = \prod_{j \in J} \mathbb{P}(A_j). $$ Let us write $J=J_0 \uplus J_1$, where $J_0 = \{ j \in J \colon \alpha_j =0\}$ and $J_1 = \{ j \in J \colon \alpha_j =1\}$. Then we have $$ \mathbb{P}\left( \bigcap_{j \in J} A_j \right) =\mathbb{P}\left( \bigcap_{j \in J_0} A_j  \cap  \bigcap_{j \in J_1} A_j \right) = \mathbb{P}\left( \bigcap_{j \in J_0} B_j^{(\alpha_j)}  \cap  \bigcap_{j \in J_1} A_j \right) $$ To apply the assumption I need something like $\bigcap_{j \in J_1} B_j^{(\alpha_j)}$. But using De Morgan's laws I only get that $$  \bigcap_{j \in J_1} A_j = \left( \left(\bigcap_{j \in J_1} A_j \right)^{\mathsf{c}} \right)^{\mathsf{c}} =  \left(\bigcup_{j \in J_1} A_j^{\mathsf{c}}  \right)^{\mathsf{c}}  = \left(\bigcup_{j \in J_1} B_j^{(\alpha_j)}  \right)^{\mathsf{c}}. $$ What is the correct way to continue the proof?","Suppose $(\Omega,\mathcal{F},\mathbb{P})$ is a probability space, $I$ is an arbitrary index set and $\{A_i\}_{i \in I} \in \mathcal{F}^{I}$. For $i \in I$ we define $B_i^{(0)} := A_i$ and $B_i^{(1)} := A_i^{\mathsf{c}}$. I want to show the implication   $$ \exists \, \alpha \in \{0,1\}^{I} \colon \ \{B_i^{(\alpha_i)}\}_{i \in I} \text{ is independent } \Longrightarrow \{A_i\}_{i \in I} \text{ is independent }. $$ Let $\alpha$ be the fixed sequence and let $J \subseteq I$ with $|J|< \infty$. We have to show that $$ \mathbb{P}\left( \bigcap_{j \in J} A_j \right) = \prod_{j \in J} \mathbb{P}(A_j). $$ Let us write $J=J_0 \uplus J_1$, where $J_0 = \{ j \in J \colon \alpha_j =0\}$ and $J_1 = \{ j \in J \colon \alpha_j =1\}$. Then we have $$ \mathbb{P}\left( \bigcap_{j \in J} A_j \right) =\mathbb{P}\left( \bigcap_{j \in J_0} A_j  \cap  \bigcap_{j \in J_1} A_j \right) = \mathbb{P}\left( \bigcap_{j \in J_0} B_j^{(\alpha_j)}  \cap  \bigcap_{j \in J_1} A_j \right) $$ To apply the assumption I need something like $\bigcap_{j \in J_1} B_j^{(\alpha_j)}$. But using De Morgan's laws I only get that $$  \bigcap_{j \in J_1} A_j = \left( \left(\bigcap_{j \in J_1} A_j \right)^{\mathsf{c}} \right)^{\mathsf{c}} =  \left(\bigcup_{j \in J_1} A_j^{\mathsf{c}}  \right)^{\mathsf{c}}  = \left(\bigcup_{j \in J_1} B_j^{(\alpha_j)}  \right)^{\mathsf{c}}. $$ What is the correct way to continue the proof?",,"['probability', 'probability-theory', 'independence']"
11,How many ways to write $2010$?,How many ways to write ?,2010,"Let $ N$ be the number of ways to write $ 2010$ in the form $ 2010 = a_3 \cdot 10^3 + a_2 \cdot 10^2 + a_1 \cdot 10 + a_0$, where the $ a_i$'s are integers, and $ 0 \le a_i \le 99$. An example of such a representation is $ 1\cdot10^3 + 3\cdot10^2 + 67\cdot10^1 + 40\cdot10^0$. Find $ N$. I picked the biggest $a_1$ so: $a_1 = 2$, there are only two ways to form $2010$. Take $a_1 = 1$ now. This opens up to a lot of possibilities. Specific Casework should work: Cases 1-1: $a_2 = 10$, then possibilities are: $a_1 = 1, a_0 = 0$ or $a_1  = 0, a_0 = 10$ Actually, I think a number-theoretic way is easier. But still. Case 1: $a_1 = 1$ then we must solve: $100x + 10y + z = 1010$. Since $0 \le x \le 10$, we can casework $x$ so that: Case 1-1:$x = 0$. So that: $10y + z = 1010 \implies z \equiv 0 \pmod{10}, z = 10k$ and $y = 101 - k$. Hence, $(0, 101 - k, 10k)$. $\min{k} = 0 $ and we need to find the max of $k$. We must have, $101 - k \le 99$ and $10k \le 99$. This suggests, $k \le 9$. Cases 1-2: $x=1$. So that: $10y + z = 910 \implies z \equiv 0 \pmod{10}$ Again, $z = 10k$ and $y = 91 - k$. Giving a set of $(1, 91 - k, 10k)$.Here again, $\min{k} = 0$ and $10k \le 99$ so $k \le 9$. I am conjecturing that since we are always increasing $x$ values, the value on the RHS will always be divisible by $10$. $x = 9$ so that: $10y + z = 110 \implies z = 10k$ and $y = 11 - k$, which again there are $9$ values. Except if $x=10$ then there is: $10y + z = 10$ then $z = 10k$ and $y = 1 - k$. Then $k$ must be $1$. So there are: $10(9) + 1 + 2 = 93$ solutions total. This is just an attempt! Bump: anybody have anything?","Let $ N$ be the number of ways to write $ 2010$ in the form $ 2010 = a_3 \cdot 10^3 + a_2 \cdot 10^2 + a_1 \cdot 10 + a_0$, where the $ a_i$'s are integers, and $ 0 \le a_i \le 99$. An example of such a representation is $ 1\cdot10^3 + 3\cdot10^2 + 67\cdot10^1 + 40\cdot10^0$. Find $ N$. I picked the biggest $a_1$ so: $a_1 = 2$, there are only two ways to form $2010$. Take $a_1 = 1$ now. This opens up to a lot of possibilities. Specific Casework should work: Cases 1-1: $a_2 = 10$, then possibilities are: $a_1 = 1, a_0 = 0$ or $a_1  = 0, a_0 = 10$ Actually, I think a number-theoretic way is easier. But still. Case 1: $a_1 = 1$ then we must solve: $100x + 10y + z = 1010$. Since $0 \le x \le 10$, we can casework $x$ so that: Case 1-1:$x = 0$. So that: $10y + z = 1010 \implies z \equiv 0 \pmod{10}, z = 10k$ and $y = 101 - k$. Hence, $(0, 101 - k, 10k)$. $\min{k} = 0 $ and we need to find the max of $k$. We must have, $101 - k \le 99$ and $10k \le 99$. This suggests, $k \le 9$. Cases 1-2: $x=1$. So that: $10y + z = 910 \implies z \equiv 0 \pmod{10}$ Again, $z = 10k$ and $y = 91 - k$. Giving a set of $(1, 91 - k, 10k)$.Here again, $\min{k} = 0$ and $10k \le 99$ so $k \le 9$. I am conjecturing that since we are always increasing $x$ values, the value on the RHS will always be divisible by $10$. $x = 9$ so that: $10y + z = 110 \implies z = 10k$ and $y = 11 - k$, which again there are $9$ values. Except if $x=10$ then there is: $10y + z = 10$ then $z = 10k$ and $y = 1 - k$. Then $k$ must be $1$. So there are: $10(9) + 1 + 2 = 93$ solutions total. This is just an attempt! Bump: anybody have anything?",,"['probability', 'combinatorics', 'algebra-precalculus', 'elementary-number-theory', 'contest-math']"
12,Limit of normal hazard rate,Limit of normal hazard rate,,"I'm trying to work out the asymptotic behavior of the normal hazard rate as $x$ gets very large.  To be clear, that's the behavior of $$ h(x) = \frac{ \phi(x)}{1-\Phi(x)} \qquad \text{ as } \qquad x \rightarrow \infty$$ Where $\phi(\cdot)$ and $\Phi(\cdot)$ are the pdf and cdf respectively of the standard normal. I don't think anyone on this site or elsewhere online has addressed this question specifically.  The closest I found was this , but that is much more general than what I want. In the limit, this looks like it is linear (picture below), but I can't quite show why or to what limit.  Both numerator and denominator go to 0 as $x$ gets very large. My best attempt at figuring this out was to apply L'Hopital's rule. \begin{align*}   \lim_{x\rightarrow\infty} h(x) &= \frac{ \lim_{x\rightarrow\infty} \phi'(x) }{ \lim_{x\rightarrow\infty} -\phi(x)} \\                                  &= \frac{ \lim_{x\rightarrow\infty} -x \phi(x) }{ \lim_{x\rightarrow\infty} -\phi(x)}  \end{align*} This still fails as both the top and bottom converge to zero.    The limits don't exist, so I'm no good here. Now I know that the next line is not ok, but I tried it anyway, because I had no better ideas.  What if I ""cancel"" the $\phi(\cdot)$ functions in the numerator and denominator?  That is, I tried the following: $$ \lim_{x\rightarrow\infty} h(x) \overset{?}{=} x$$ It turns out that this is a pretty good approximation to the limiting behavior. See the picture below ($h(x)$ solid, candidate $h'(x)$ dashed).  But I haven't proved anything, which is annoying.  It also turns out that this limit doesn't work in some other applications (not discussed here!). So, to summarize my questions: What is the asymptotic behavior of the normal hazard rate?  I couldn't find a reference. Is $h'(x)=x$ in the limit? If so, why?  My abuse of L'Hopital's rule isn't the reason.","I'm trying to work out the asymptotic behavior of the normal hazard rate as $x$ gets very large.  To be clear, that's the behavior of $$ h(x) = \frac{ \phi(x)}{1-\Phi(x)} \qquad \text{ as } \qquad x \rightarrow \infty$$ Where $\phi(\cdot)$ and $\Phi(\cdot)$ are the pdf and cdf respectively of the standard normal. I don't think anyone on this site or elsewhere online has addressed this question specifically.  The closest I found was this , but that is much more general than what I want. In the limit, this looks like it is linear (picture below), but I can't quite show why or to what limit.  Both numerator and denominator go to 0 as $x$ gets very large. My best attempt at figuring this out was to apply L'Hopital's rule. \begin{align*}   \lim_{x\rightarrow\infty} h(x) &= \frac{ \lim_{x\rightarrow\infty} \phi'(x) }{ \lim_{x\rightarrow\infty} -\phi(x)} \\                                  &= \frac{ \lim_{x\rightarrow\infty} -x \phi(x) }{ \lim_{x\rightarrow\infty} -\phi(x)}  \end{align*} This still fails as both the top and bottom converge to zero.    The limits don't exist, so I'm no good here. Now I know that the next line is not ok, but I tried it anyway, because I had no better ideas.  What if I ""cancel"" the $\phi(\cdot)$ functions in the numerator and denominator?  That is, I tried the following: $$ \lim_{x\rightarrow\infty} h(x) \overset{?}{=} x$$ It turns out that this is a pretty good approximation to the limiting behavior. See the picture below ($h(x)$ solid, candidate $h'(x)$ dashed).  But I haven't proved anything, which is annoying.  It also turns out that this limit doesn't work in some other applications (not discussed here!). So, to summarize my questions: What is the asymptotic behavior of the normal hazard rate?  I couldn't find a reference. Is $h'(x)=x$ in the limit? If so, why?  My abuse of L'Hopital's rule isn't the reason.",,"['probability', 'probability-distributions']"
13,Expectation of hitting time of a markov chain,Expectation of hitting time of a markov chain,,"Let $\{X_n\}$ be a homogenous Markov chain, taking values in N. $T_i:=\inf\{k\ge0:X_k=i\}$ is the first time when the chain arrives at i. I know that if X is irreducible positive recurrent, then $E_iT_i$ is finite. Now I want to know some results about $E_j T_i$, the expected time of first arrival at state $i$ starting from state $j$. I think that it should be finite almost surely. Is there any explicit form of $E_j T_i$, or inequality? And what about an arbitrary initial distribution?   Any help would be appreciated.","Let $\{X_n\}$ be a homogenous Markov chain, taking values in N. $T_i:=\inf\{k\ge0:X_k=i\}$ is the first time when the chain arrives at i. I know that if X is irreducible positive recurrent, then $E_iT_i$ is finite. Now I want to know some results about $E_j T_i$, the expected time of first arrival at state $i$ starting from state $j$. I think that it should be finite almost surely. Is there any explicit form of $E_j T_i$, or inequality? And what about an arbitrary initial distribution?   Any help would be appreciated.",,"['probability', 'markov-chains']"
14,If P(A) = 0 or 1 then A and B are independent,If P(A) = 0 or 1 then A and B are independent,,"The question is: Let A,B and C be events in S then prove if P(A) = 0 A and B are independent. Here's my working: For two events to be independent P(A ∩ B) needs to equal P(A)P(B). Since P(A) = 0, P(A ∩ B) = P(Ø) = 0 and P(A)P(B) = 0 therefore P(A ∩ B) = P(A)P(B) = 0 and are independent events. And for part two it asks to prove A and B are independent if P(A) = 1 My working: P(A ∩ B) = P(B) since P(A) = 1 and P(A)(B) = P(B) since P(A) = 1 therefore P(A ∩ B) = P(A)P(B). I'm skeptical about how I dealt with the intersections for example ""P(A ∩ B) = P(B) since P(A) = 1"" and ""Since P(A) = 0, P(A ∩ B) = P(Ø) = 0"". Can someone clarify if this is right or wrong and if it's wrong how can I make it correct. Thanks","The question is: Let A,B and C be events in S then prove if P(A) = 0 A and B are independent. Here's my working: For two events to be independent P(A ∩ B) needs to equal P(A)P(B). Since P(A) = 0, P(A ∩ B) = P(Ø) = 0 and P(A)P(B) = 0 therefore P(A ∩ B) = P(A)P(B) = 0 and are independent events. And for part two it asks to prove A and B are independent if P(A) = 1 My working: P(A ∩ B) = P(B) since P(A) = 1 and P(A)(B) = P(B) since P(A) = 1 therefore P(A ∩ B) = P(A)P(B). I'm skeptical about how I dealt with the intersections for example ""P(A ∩ B) = P(B) since P(A) = 1"" and ""Since P(A) = 0, P(A ∩ B) = P(Ø) = 0"". Can someone clarify if this is right or wrong and if it's wrong how can I make it correct. Thanks",,"['probability', 'probability-theory']"
15,Expected number of red balls removed from an urn before the first black ball,Expected number of red balls removed from an urn before the first black ball,,"Question: An urn contains n+m balls of which n are red and m are black. They are withdrawn from the urn one at a time and without replacement. Let $X$  be the number of red balls removed before the first black ball is chosen. We are interested in determining the $E[X]$. To obtain this quantity, number the red balls from 1 to n. Define the random variables $X_i$ $(i=1,2...,n)$ by $$X_i =   \begin{cases}      1  \quad & : \text{if red ball labeled (i) is taken before any black ball is chosen}\\     0  \quad & : \text{otherwise}  \end{cases}$$ Express $X$ in terms of $X_i$s and find $E[X]$. My Attempt: Now we can express $X$ as $X = X_1+X_2+...+X_n$ To find the $X_i's$, what I think is it not geometric, but it is more like this  $$ \begin{array}{c|c|c|c}  X   &  1  &  2 &     \ldots                              \\ \hline  P(X) & \frac{m}{n+m} & (\frac{n}{n+m})(\frac{m}{(n+m)-1})  & \ldots \end{array} $$ Now to determine the random variables, I tried to think about this step-by step. For $X_1$, it means that is the red ball labeled 1 is picked before any black ball is chosen, and so on for $ X_2, X_3,..,X_N$. What I think is to determine the random variables, it is like a permutation going on since the balls are numbered, but it's not. There is only 1 ball in the urn which is red and is labeled #1. There is only 1 ball which is red and is labeled #2, etc. The question is that am I thinking about this the right way? Again, I really apologize about the organization. It is my first time on this site and I am trying to get familiar with the programming. Thank you for all of your help!","Question: An urn contains n+m balls of which n are red and m are black. They are withdrawn from the urn one at a time and without replacement. Let $X$  be the number of red balls removed before the first black ball is chosen. We are interested in determining the $E[X]$. To obtain this quantity, number the red balls from 1 to n. Define the random variables $X_i$ $(i=1,2...,n)$ by $$X_i =   \begin{cases}      1  \quad & : \text{if red ball labeled (i) is taken before any black ball is chosen}\\     0  \quad & : \text{otherwise}  \end{cases}$$ Express $X$ in terms of $X_i$s and find $E[X]$. My Attempt: Now we can express $X$ as $X = X_1+X_2+...+X_n$ To find the $X_i's$, what I think is it not geometric, but it is more like this  $$ \begin{array}{c|c|c|c}  X   &  1  &  2 &     \ldots                              \\ \hline  P(X) & \frac{m}{n+m} & (\frac{n}{n+m})(\frac{m}{(n+m)-1})  & \ldots \end{array} $$ Now to determine the random variables, I tried to think about this step-by step. For $X_1$, it means that is the red ball labeled 1 is picked before any black ball is chosen, and so on for $ X_2, X_3,..,X_N$. What I think is to determine the random variables, it is like a permutation going on since the balls are numbered, but it's not. There is only 1 ball in the urn which is red and is labeled #1. There is only 1 ball which is red and is labeled #2, etc. The question is that am I thinking about this the right way? Again, I really apologize about the organization. It is my first time on this site and I am trying to get familiar with the programming. Thank you for all of your help!",,['probability']
16,Calculating probability of getting $m$ unique numbers when choosing $n$ times from $0\ldots k$,Calculating probability of getting  unique numbers when choosing  times from,m n 0\ldots k,"I'm trying to write a test to verify a reasonable distribution for a function that generates 4-digit pin numbers from 8 digit phone numbers.  I'm not aware of any direct method of calculating this, so my approach is to (1) generate $n$ pin numbers, (2) for each $i \in \{1,\ldots,n\}$ calculate the probability that there would be $i$ unique pin numbers among the generated, and (3) test that the actual number of unique pins in the $n$ generated fall within $\pm2$ stdev of the average of the probabilities calculated in step (2). I'm stuck on step 2. I know that the probability of choosing only 1 distinct number from $0..k$ in $n$ tries is $$\left(1 \over k \right)^{n-1}$$ and that the probability of choosing $n$ distinct numbers from $0..k$ in $n$ tries is $$\prod_{i=0}^n{1-\left(i \over k \right)}$$ How do I calculate the probability when the chosen numbers aren't all the same or all distinct?","I'm trying to write a test to verify a reasonable distribution for a function that generates 4-digit pin numbers from 8 digit phone numbers.  I'm not aware of any direct method of calculating this, so my approach is to (1) generate $n$ pin numbers, (2) for each $i \in \{1,\ldots,n\}$ calculate the probability that there would be $i$ unique pin numbers among the generated, and (3) test that the actual number of unique pins in the $n$ generated fall within $\pm2$ stdev of the average of the probabilities calculated in step (2). I'm stuck on step 2. I know that the probability of choosing only 1 distinct number from $0..k$ in $n$ tries is $$\left(1 \over k \right)^{n-1}$$ and that the probability of choosing $n$ distinct numbers from $0..k$ in $n$ tries is $$\prod_{i=0}^n{1-\left(i \over k \right)}$$ How do I calculate the probability when the chosen numbers aren't all the same or all distinct?",,['probability']
17,Proving the expected value of the square root of X is less than the square root of the expected value of X,Proving the expected value of the square root of X is less than the square root of the expected value of X,,"How do I show that $E(\sqrt{X}) \leq \sqrt{E(X)}$ for a positive random variable $X$? I may be intended to use the Cauchy-Schwarz Inequality, $[E(XY)]^2 \leq E(X^2)E(Y^2)$, but I'm not sure how.","How do I show that $E(\sqrt{X}) \leq \sqrt{E(X)}$ for a positive random variable $X$? I may be intended to use the Cauchy-Schwarz Inequality, $[E(XY)]^2 \leq E(X^2)E(Y^2)$, but I'm not sure how.",,['probability']
18,The sum of moment generating functions,The sum of moment generating functions,,"Let $X, Y$ be independent r.v with moment generating functions $M_X(t)$ and $M_Y(t)$ respectively. Is there a function of $X$ and $Y, Z$, with moment generating function $$\frac{M_x(t) + M_y(t)}2$$","Let $X, Y$ be independent r.v with moment generating functions $M_X(t)$ and $M_Y(t)$ respectively. Is there a function of $X$ and $Y, Z$, with moment generating function $$\frac{M_x(t) + M_y(t)}2$$",,"['probability', 'moment-generating-functions']"
19,How to prove that convergence in MGF implies Convergence in Distribution?,How to prove that convergence in MGF implies Convergence in Distribution?,,I know that if the moment generating function of two distribution converges to the same function then the two distribution converges in CDF. But how can we prove this thing explicitly ?,I know that if the moment generating function of two distribution converges to the same function then the two distribution converges in CDF. But how can we prove this thing explicitly ?,,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes']"
20,To sample or not to sample?,To sample or not to sample?,,"I have the following issue (I want to predict sports results). Let $X$ be a discrete RV with $m$ possible outcomes, each having probability $p_i$, for $i=1,\ldots,m$. Assume that I have a large iid sample $X_1,\ldots,X_n$, where each variable has the same distribution as $X$. Now, to make a prediction for each $X_k$ (before its actual value is drawn) I could just always predict outcome $i^*$ with largest probability $p^*_i$. Then, in expectation, I would be right on $n\cdot p^*_i$ samples. Alternatively, I could sample from the distribution of $X$, that is, for each $X_k$ predict value $i$ according to $p_i$. Then, the probability that my prediction for $X_k$ equals the actual draw of $X_k$ is $$q=P[\hat{X}_k=X_k]=\sum_{i=1}^m P[\hat{X}_k=i]P[X_k=i]=\sum_{i=1}^m p_i^2.$$ Thus, according to this approach, the probability that I am correct on $r$ predictions is $B(r;n,q)=\binom{n}{r}q^r(1-q)^{n-r}$. Now, what is the probability that this approach gives me at least $n\cdot p_i^*$ correct results (i.e., $B(n\cdot p_i^*;n,q)+\cdots+B(n;n,q)$)? Are there any known general results on this? How does the answer depend on the distribution of $X$ (e.g. uniform, skewed, ...)? In other words, should I sample (approach 2) or just predict the most probable outcome (approach 1)? (Did I make any mistakes somewhere?)","I have the following issue (I want to predict sports results). Let $X$ be a discrete RV with $m$ possible outcomes, each having probability $p_i$, for $i=1,\ldots,m$. Assume that I have a large iid sample $X_1,\ldots,X_n$, where each variable has the same distribution as $X$. Now, to make a prediction for each $X_k$ (before its actual value is drawn) I could just always predict outcome $i^*$ with largest probability $p^*_i$. Then, in expectation, I would be right on $n\cdot p^*_i$ samples. Alternatively, I could sample from the distribution of $X$, that is, for each $X_k$ predict value $i$ according to $p_i$. Then, the probability that my prediction for $X_k$ equals the actual draw of $X_k$ is $$q=P[\hat{X}_k=X_k]=\sum_{i=1}^m P[\hat{X}_k=i]P[X_k=i]=\sum_{i=1}^m p_i^2.$$ Thus, according to this approach, the probability that I am correct on $r$ predictions is $B(r;n,q)=\binom{n}{r}q^r(1-q)^{n-r}$. Now, what is the probability that this approach gives me at least $n\cdot p_i^*$ correct results (i.e., $B(n\cdot p_i^*;n,q)+\cdots+B(n;n,q)$)? Are there any known general results on this? How does the answer depend on the distribution of $X$ (e.g. uniform, skewed, ...)? In other words, should I sample (approach 2) or just predict the most probable outcome (approach 1)? (Did I make any mistakes somewhere?)",,"['probability', 'statistics', 'sampling']"
21,finding the pdf of the square of another pdf,finding the pdf of the square of another pdf,,"This might be just a silly question. If I have a distribution $Y=X^2$ where $X$ is normally distributed, how would I find the pdf of $Y$?","This might be just a silly question. If I have a distribution $Y=X^2$ where $X$ is normally distributed, how would I find the pdf of $Y$?",,"['probability', 'probability-distributions']"
22,Expected value of number of draws,Expected value of number of draws,,"We have $5$ number in a bag: $(1,3,5,7,9)$. We draw one from the bag and then put it back. We do this until the sum of the numbers can be divided by $3$. Whats the expected value of the number of draws? My idea was to solve it with Markov-chains: States: $0,1,2$. So numbers$\mod 3$. The matrix will be: $\begin{pmatrix} 2/5 & 2/5 & 1/5 \\ 1/5 & 2/5 & 2/5 \\ 2/5 & 1/5 & 2/5 \end{pmatrix}$ Then we have an equation system:  $k_1=1+2/5k_1+2/5k_2$, $\ k_2=1+1/5k_1+2/5k_2$ and $k_3=0$. Even if I solve this, I'm not sure how to continue. Thanks for help.","We have $5$ number in a bag: $(1,3,5,7,9)$. We draw one from the bag and then put it back. We do this until the sum of the numbers can be divided by $3$. Whats the expected value of the number of draws? My idea was to solve it with Markov-chains: States: $0,1,2$. So numbers$\mod 3$. The matrix will be: $\begin{pmatrix} 2/5 & 2/5 & 1/5 \\ 1/5 & 2/5 & 2/5 \\ 2/5 & 1/5 & 2/5 \end{pmatrix}$ Then we have an equation system:  $k_1=1+2/5k_1+2/5k_2$, $\ k_2=1+1/5k_1+2/5k_2$ and $k_3=0$. Even if I solve this, I'm not sure how to continue. Thanks for help.",,"['probability', 'probability-distributions', 'markov-chains', 'expectation']"
23,How do I calculate variance for sum of dice?,How do I calculate variance for sum of dice?,,"I'll post my work, but I'm not sure how to calculate variance. The question asks for the expected sum of 3 dice rolls and the variance. I think I got the expected sum. Any help would be awesome :) thanks!","I'll post my work, but I'm not sure how to calculate variance. The question asks for the expected sum of 3 dice rolls and the variance. I think I got the expected sum. Any help would be awesome :) thanks!",,"['probability', 'combinatorics', 'discrete-mathematics']"
24,Does almost sure convergence implies convergence of the mean?,Does almost sure convergence implies convergence of the mean?,,"I asked a slightly similar question here: Does Convergence in probability implies convergence of the mean? , but now I wish to examine a stricter scenario: Let $\{X_n\}_{n=1}^\infty$ be a sequence of random variables converging a.s to a const $c$. Is it required for the sequence to be uniformly integrable in order to imply  $\lim_{n\to \infty} EX_n = c$? And what about $\lim_{n\to \infty} EYh(X_n) = E[Y]h(c)$ for some random variable $Y$ and a continuous function $h$?  Under which regularity conditions does the last equality holds?","I asked a slightly similar question here: Does Convergence in probability implies convergence of the mean? , but now I wish to examine a stricter scenario: Let $\{X_n\}_{n=1}^\infty$ be a sequence of random variables converging a.s to a const $c$. Is it required for the sequence to be uniformly integrable in order to imply  $\lim_{n\to \infty} EX_n = c$? And what about $\lim_{n\to \infty} EYh(X_n) = E[Y]h(c)$ for some random variable $Y$ and a continuous function $h$?  Under which regularity conditions does the last equality holds?",,"['probability', 'probability-theory', 'convergence-divergence']"
25,"not-independent variables, but conditionally dependent","not-independent variables, but conditionally dependent",,"I am trying to understand (in)dependence and conditional (in)dependence. As far as I know conditional independence does not imply unconditional independence and vice versa. Assuming that I have three random binary variables A, B and C, I can easily find such a case when A and B are independent, but conditionally dependent given C. However I am struggling to find an example of joint distribution of this three variables A,B and C such that A and B are dependent, but given C are independent. Can someone guide me preferably by giving such an example?","I am trying to understand (in)dependence and conditional (in)dependence. As far as I know conditional independence does not imply unconditional independence and vice versa. Assuming that I have three random binary variables A, B and C, I can easily find such a case when A and B are independent, but conditionally dependent given C. However I am struggling to find an example of joint distribution of this three variables A,B and C such that A and B are dependent, but given C are independent. Can someone guide me preferably by giving such an example?",,"['probability', 'statistics', 'random-variables']"
26,Decomposition of exponential random variable,Decomposition of exponential random variable,,I know that sum of independent Exponential random variables follows Gamma distribution . But Is it possible to decompose exponential random variate into independent and identically gamma random variates?,I know that sum of independent Exponential random variables follows Gamma distribution . But Is it possible to decompose exponential random variate into independent and identically gamma random variates?,,"['probability', 'statistics', 'probability-distributions', 'deconvolution']"
27,Coin Flip Betting System,Coin Flip Betting System,,"-Read comments before posting I came up with a betting system that seems to defy logic... explain why its wrong? Here's the ""logic"" behind it Rule: If you flip a coin enough times(x) the number of heads(H) and tails(T) will be equal to each other (law of large numbers?) H + T = x  AND 1/2H = 1/2T AND 1/2H / 1/2T = 1 This could happen at after flipping HT or THTTHH or HHTHTHTT... extra And Now The System!!! The first bet(more like lack of bet) you make is for $0, you have 1/2H / (1/2H + 1/2T) chance of getting heads. The coin flips tails.  Therefor x is now x-1 and T is now T-1 and H is still the same.  So now you have 1/2H / (1/2H + 1/2T - 1) chance of flipping heads.  Because 1/2H / (1/2H + 1/2T) = 50% chance of flipping heads and 1/2H / (1/2H + 1/2T - 1) is not equal to 1/2H / (1/2H + 1/2T) then 1/2H / (1/2H + 1/2T - 1) is not equal to a 50% chance of flipping heads.  How can this be? PLEASE do not say every time the next flip will be heads or tails, therefor you have a 50% chance of flipping heads... of course I know this!!!  I want to know what is wrong with my logic not that it is wrong, I already know that it is wrong... On a side note this system would never work in a real life senario because no casino offers 1:1 odds which this system needs. The system itself is Watch first flip Bet on opposite of flip amount of money you want to profit Continue making bet until heads and tail flips are equal","-Read comments before posting I came up with a betting system that seems to defy logic... explain why its wrong? Here's the ""logic"" behind it Rule: If you flip a coin enough times(x) the number of heads(H) and tails(T) will be equal to each other (law of large numbers?) H + T = x  AND 1/2H = 1/2T AND 1/2H / 1/2T = 1 This could happen at after flipping HT or THTTHH or HHTHTHTT... extra And Now The System!!! The first bet(more like lack of bet) you make is for $0, you have 1/2H / (1/2H + 1/2T) chance of getting heads. The coin flips tails.  Therefor x is now x-1 and T is now T-1 and H is still the same.  So now you have 1/2H / (1/2H + 1/2T - 1) chance of flipping heads.  Because 1/2H / (1/2H + 1/2T) = 50% chance of flipping heads and 1/2H / (1/2H + 1/2T - 1) is not equal to 1/2H / (1/2H + 1/2T) then 1/2H / (1/2H + 1/2T - 1) is not equal to a 50% chance of flipping heads.  How can this be? PLEASE do not say every time the next flip will be heads or tails, therefor you have a 50% chance of flipping heads... of course I know this!!!  I want to know what is wrong with my logic not that it is wrong, I already know that it is wrong... On a side note this system would never work in a real life senario because no casino offers 1:1 odds which this system needs. The system itself is Watch first flip Bet on opposite of flip amount of money you want to profit Continue making bet until heads and tail flips are equal",,"['probability', 'fake-proofs']"
28,Probability of a graph having at least 1 k-clique,Probability of a graph having at least 1 k-clique,,"I need to estimate the probability $P(\text{Graph G has at least 1 k-clique})$, any precision will do. I know the edge probability, say $p$, so the average number of the edges, $EK$, is $pm(m - 1)/2$, where $m$ is a number of vertices. I tried to use the Turan theorem with the Markov inequality, but Turan condition is too strong, so I ended up with the estimation $P(\text{Graph G has at least 1 k-clique}) \ge 0$. I tried to use more precise Chebyshev inequality instead, but to calculate $E(K)^2$ is really hard in my case. Does anyone know what should I do? Is there maybe any estimates for the probability of a k-clique in a random graph, so I could use it instead of precise Turan condition?","I need to estimate the probability $P(\text{Graph G has at least 1 k-clique})$, any precision will do. I know the edge probability, say $p$, so the average number of the edges, $EK$, is $pm(m - 1)/2$, where $m$ is a number of vertices. I tried to use the Turan theorem with the Markov inequality, but Turan condition is too strong, so I ended up with the estimation $P(\text{Graph G has at least 1 k-clique}) \ge 0$. I tried to use more precise Chebyshev inequality instead, but to calculate $E(K)^2$ is really hard in my case. Does anyone know what should I do? Is there maybe any estimates for the probability of a k-clique in a random graph, so I could use it instead of precise Turan condition?",,"['probability', 'graph-theory', 'random-graphs']"
29,Lebesgue measure on $\mathbb{R}$ is not a probability measure,Lebesgue measure on  is not a probability measure,\mathbb{R},"So I'm not a math student hence the (probably rather simple) question in the title. I could not find an answer in the slides or the internet. My intuition is that the elements (ie. reals) of  $\mathbb{R}$ are not countable, hence no probability measure can be established. Am I correct and is this a sufficient explanation?","So I'm not a math student hence the (probably rather simple) question in the title. I could not find an answer in the slides or the internet. My intuition is that the elements (ie. reals) of  $\mathbb{R}$ are not countable, hence no probability measure can be established. Am I correct and is this a sufficient explanation?",,"['probability', 'elementary-set-theory']"
30,Number of possible pairs,Number of possible pairs,,"I have a problem counting all the possible way of ""pairing"" 2 people in a group of N people (let's assume N is even). Example: The professor wants the students to work in pairs (groups of two). In how many ways the students could pairs ? I have seen that the answer is $$\frac{N!}{2^{N/2}*\frac{N}{2}!} $$ So, the way i understand it: it is the way of all possible combination (N!) divided by $$2^{N/2}$$ because ... I don't know (that is the reason of the question) ... And divided by $$(N/2)!$$ because of the permutation. So, could you explain me why this division by $$2^{N/2}$$ ? Also, what are the probability for 2 people (let's say student1 and student 2), to be in the same group ?","I have a problem counting all the possible way of ""pairing"" 2 people in a group of N people (let's assume N is even). Example: The professor wants the students to work in pairs (groups of two). In how many ways the students could pairs ? I have seen that the answer is So, the way i understand it: it is the way of all possible combination (N!) divided by because ... I don't know (that is the reason of the question) ... And divided by because of the permutation. So, could you explain me why this division by ? Also, what are the probability for 2 people (let's say student1 and student 2), to be in the same group ?",\frac{N!}{2^{N/2}*\frac{N}{2}!}  2^{N/2} (N/2)! 2^{N/2},['probability']
31,Independent and mutually exclusive,Independent and mutually exclusive,,Prove or disprove via proof that events $X$ and $Y$ can be independent and mutually exclusive if both of their probabilities are greater than $0$.,Prove or disprove via proof that events $X$ and $Y$ can be independent and mutually exclusive if both of their probabilities are greater than $0$.,,"['probability', 'probability-theory']"
32,Birthday paradox: Comparing the original version with the same-birthday-as-you version,Birthday paradox: Comparing the original version with the same-birthday-as-you version,,The birthday paradox itself is well known. I am only interested in a small aspect here: The number of pairings in the original problem is $${23 \choose 2} = \frac{23 \cdot 22}{2}=253$$ Another version is the same-birthday-as-you problem . It turns out that you need also at least $253$ people  to get over $50%$ probability. $$1 - \left( \frac{364}{365} \right)^{253}=1-0.499$$ I am interesting in this double occurrence of $253$: Wikipedia states it is not a coincidence Ian Stewart states in an Scientific American article that it is a coincidence My question Who is right and why? Addendum Just for the sake of completeness after receiving the great answers below (for which I am very grateful): In the meantime I had also contacted Ian Stewart on the matter and he too acknowledges the connection. He told me that in fact one of his readers wrote in soon after the article was published to point it out.,The birthday paradox itself is well known. I am only interested in a small aspect here: The number of pairings in the original problem is $${23 \choose 2} = \frac{23 \cdot 22}{2}=253$$ Another version is the same-birthday-as-you problem . It turns out that you need also at least $253$ people  to get over $50%$ probability. $$1 - \left( \frac{364}{365} \right)^{253}=1-0.499$$ I am interesting in this double occurrence of $253$: Wikipedia states it is not a coincidence Ian Stewart states in an Scientific American article that it is a coincidence My question Who is right and why? Addendum Just for the sake of completeness after receiving the great answers below (for which I am very grateful): In the meantime I had also contacted Ian Stewart on the matter and he too acknowledges the connection. He told me that in fact one of his readers wrote in soon after the article was published to point it out.,,"['probability', 'combinatorics', 'birthday']"
33,Probability books useful for Information Theory?,Probability books useful for Information Theory?,,"Can you recommend me a list of good Probability Books for self-studying, with good explanations and introductions for Information Theory and not for the typical statistical subjects?","Can you recommend me a list of good Probability Books for self-studying, with good explanations and introductions for Information Theory and not for the typical statistical subjects?",,"['probability', 'reference-request', 'information-theory']"
34,What's the probability that the next coin flip is heads?,What's the probability that the next coin flip is heads?,,I randomly chose between 2 coins. One of the coins has a 0.8 chance of heads and a 0.2 chance of tails. The other is a fair coin that has a 0.5 chance of either heads or tails. I flip this coin twice and get 2 heads. What's the probability that my next flip is heads? I tried using Bayes' Theorem: $$ P(H|HH) = \frac{P(HH|H)P(H)}{P(HH)} $$ But then $P(HH|H)$ is not easy to solve...,I randomly chose between 2 coins. One of the coins has a 0.8 chance of heads and a 0.2 chance of tails. The other is a fair coin that has a 0.5 chance of either heads or tails. I flip this coin twice and get 2 heads. What's the probability that my next flip is heads? I tried using Bayes' Theorem: $$ P(H|HH) = \frac{P(HH|H)P(H)}{P(HH)} $$ But then $P(HH|H)$ is not easy to solve...,,['probability']
35,A binomial multiplied by a poisson,A binomial multiplied by a poisson,,"What distribution do you obtain when you multiply a poisson distribution and a binomial distribution, and why? I'm assuming you obtain a poisson distribution.","What distribution do you obtain when you multiply a poisson distribution and a binomial distribution, and why? I'm assuming you obtain a poisson distribution.",,"['probability', 'statistics']"
36,order statistics of random sample,order statistics of random sample,,"suppose $X_1,X_2,\ldots,X_n$ is a random sample of distribution with positive values where $E(X)=\text{Var}(X)=1$. We show order statistics of this random sample with $Y_1,Y_2,\ldots,Y_n$. How can show $E\left(\displaystyle\sum_{i=1}^n \frac{Y_i}{X_i}\right)\geq n$ $E\left(\displaystyle\sum_{i=1}^n Y_iX_i\right)\leq n+n^2$","suppose $X_1,X_2,\ldots,X_n$ is a random sample of distribution with positive values where $E(X)=\text{Var}(X)=1$. We show order statistics of this random sample with $Y_1,Y_2,\ldots,Y_n$. How can show $E\left(\displaystyle\sum_{i=1}^n \frac{Y_i}{X_i}\right)\geq n$ $E\left(\displaystyle\sum_{i=1}^n Y_iX_i\right)\leq n+n^2$",,"['probability', 'order-statistics']"
37,Generalizing the total probability of simultaneous occurrences for independent events,Generalizing the total probability of simultaneous occurrences for independent events,,"I want to generalize a formula and I need your help with this. This is not my homework or assignment but I need to come up with a concise formula that fits my documentation. Background for my problem: Considering all events to be independent of each other, Let the probability of $Event$ $0$ be $P_{0}$ and $Event$ $1$ be $P_{1}$ and so on ... Then the probability that two events occur simultaneously is : $P_0P_1$ . This is nothing but the area of intersection of two circles $P_0$ and $P_1$. Continuing the same way, The total probability of simultaneous occurrence in case of three events is: $P_0 P_1 + P_0P_2 + P_1P_2 - 2 P_{0}P_{1}P_{2}$. Also can be visualized by drawing three intersecting circles. One clarification here: This gives me the total probability of any two events plus  all the three occurring at the same time right? I cannot visualize the formula by drawing circles anymore. How can the above formula be generalized to get the probability of simultaneous occurrences when there are 4, 5, ... independent events. I have seen that the inclusion-exclusion principle is the answer. But I am not able to get an intuition for it. The inclusion-exclusion principle gives the probability of 2,3,4 sets intersecting but isn't my question different? I get this doubt because, probability of four independent events occurring simultaneous is: $P_0P_1P_2P_3$. But what I need is a general formula for the total probability of two or more independent events at the same time. Can anyone of you please throw some light? Yes indeed I meant that the probability of ""two or more events"". The answer you have given is very precise and the one I was looking for. Yes it is boring to try to visualize circles when the number exceeds three. Instead, in general if use 1 - ($w_0 + w_1$) then we should land up correctly given that the events are independent. Thank you so much.","I want to generalize a formula and I need your help with this. This is not my homework or assignment but I need to come up with a concise formula that fits my documentation. Background for my problem: Considering all events to be independent of each other, Let the probability of $Event$ $0$ be $P_{0}$ and $Event$ $1$ be $P_{1}$ and so on ... Then the probability that two events occur simultaneously is : $P_0P_1$ . This is nothing but the area of intersection of two circles $P_0$ and $P_1$. Continuing the same way, The total probability of simultaneous occurrence in case of three events is: $P_0 P_1 + P_0P_2 + P_1P_2 - 2 P_{0}P_{1}P_{2}$. Also can be visualized by drawing three intersecting circles. One clarification here: This gives me the total probability of any two events plus  all the three occurring at the same time right? I cannot visualize the formula by drawing circles anymore. How can the above formula be generalized to get the probability of simultaneous occurrences when there are 4, 5, ... independent events. I have seen that the inclusion-exclusion principle is the answer. But I am not able to get an intuition for it. The inclusion-exclusion principle gives the probability of 2,3,4 sets intersecting but isn't my question different? I get this doubt because, probability of four independent events occurring simultaneous is: $P_0P_1P_2P_3$. But what I need is a general formula for the total probability of two or more independent events at the same time. Can anyone of you please throw some light? Yes indeed I meant that the probability of ""two or more events"". The answer you have given is very precise and the one I was looking for. Yes it is boring to try to visualize circles when the number exceeds three. Instead, in general if use 1 - ($w_0 + w_1$) then we should land up correctly given that the events are independent. Thank you so much.",,['probability']
38,References for Kolmogorov's strong law of a large numbers,References for Kolmogorov's strong law of a large numbers,,"On the Wikipedia law of large numbers site, they mention ""Kolmogorov's strong law of large numbers"", which works even if the random variables are not identically distributed. Where can I find this theorem shown and proven? I know that a reference is provided on the Wikipedia site, but that book is out of availability. Are there any other references out there? (Interestingly, Allan Gut's book ""Probability: A Graduate Course"", has a theorem by the name of ""Kolmogorov's strong law"", but in his book, the random variables have to be identically distributed. Any ideas why this is?)","On the Wikipedia law of large numbers site, they mention ""Kolmogorov's strong law of large numbers"", which works even if the random variables are not identically distributed. Where can I find this theorem shown and proven? I know that a reference is provided on the Wikipedia site, but that book is out of availability. Are there any other references out there? (Interestingly, Allan Gut's book ""Probability: A Graduate Course"", has a theorem by the name of ""Kolmogorov's strong law"", but in his book, the random variables have to be identically distributed. Any ideas why this is?)",,"['probability', 'statistics', 'reference-request', 'law-of-large-numbers']"
39,dice problem - throws necessary for sum multiple of n,dice problem - throws necessary for sum multiple of n,,"A die (with six sides) is rolled repeatedly and summed. Show that the expected number of rolls until the sum is a multiple of $n$ is $n$. In http://www.madandmoonly.com/doctormatt/mathematics/dice1.pdf problem 12 page 15 a proof is given, assuming that the distribution for the sum of dice values for n > 6 is uniform and equals $\frac{2}{7}$ which is a false assumption that should not be used in a rigorous proof.","A die (with six sides) is rolled repeatedly and summed. Show that the expected number of rolls until the sum is a multiple of $n$ is $n$. In http://www.madandmoonly.com/doctormatt/mathematics/dice1.pdf problem 12 page 15 a proof is given, assuming that the distribution for the sum of dice values for n > 6 is uniform and equals $\frac{2}{7}$ which is a false assumption that should not be used in a rigorous proof.",,"['probability', 'dice']"
40,Probability and Entropy,Probability and Entropy,,"According to the Wikipedia article on conditional entropy , $\sum p(x,y)\log p(x)=\sum p(x)\log p(x)$. Can someone please explain how?","According to the Wikipedia article on conditional entropy , $\sum p(x,y)\log p(x)=\sum p(x)\log p(x)$. Can someone please explain how?",,['probability']
41,covariance of increasing functions,covariance of increasing functions,,"Suppose $f$ and $g$ are monotonically increasing, and bounded, and let $X$ be a random variable. I want to show $f$, $g$ have positive covariance.  I tried to compute it directly but I am not getting anything useful","Suppose $f$ and $g$ are monotonically increasing, and bounded, and let $X$ be a random variable. I want to show $f$, $g$ have positive covariance.  I tried to compute it directly but I am not getting anything useful",,['probability']
42,What is the reasoning behind a multinomial coefficient in a practical sense?,What is the reasoning behind a multinomial coefficient in a practical sense?,,"If you want to divide a team of 10 people into teams A, B, and C of sizes 3,5, and 2, how many divisions are possible? If you want to divide them into just teams of sizes 3,5, and 2, how many arrangements are possible? I know that you use multinomial coefficients such that for part 1, the number of divisions is 10!/(3!5!2!) and for part 2, the number of divisions is  10!/(3!5!2!)/2!. I don't know why this is the case intuitively. Also, I can understand the formula for combinations as (n choose k) = (n*n-1*..n-k+1)/(k!) more clearly than (n!)/(k!)(n-k)!. I can't seem to interpret the second form of of the formula for combinations(or multinomials).","If you want to divide a team of 10 people into teams A, B, and C of sizes 3,5, and 2, how many divisions are possible? If you want to divide them into just teams of sizes 3,5, and 2, how many arrangements are possible? I know that you use multinomial coefficients such that for part 1, the number of divisions is 10!/(3!5!2!) and for part 2, the number of divisions is  10!/(3!5!2!)/2!. I don't know why this is the case intuitively. Also, I can understand the formula for combinations as (n choose k) = (n*n-1*..n-k+1)/(k!) more clearly than (n!)/(k!)(n-k)!. I can't seem to interpret the second form of of the formula for combinations(or multinomials).",,"['probability', 'intuition']"
43,"Throw a die $N$ times, observe results are a monotonic sequence. What is probability that all 6 numbers occur in the sequence?","Throw a die  times, observe results are a monotonic sequence. What is probability that all 6 numbers occur in the sequence?",N,"I throw a die $N$ times and the results are observed to be a monotonic sequence. What is probability that all 6 numbers occur in the sequence? I'm having trouble with this. There are two cases: when the first number is 1, and when the first number is 6. By symmetry, we can just consider one of them and double the answer at the end. I've looked at individual cases of $N$, and have that For $ N = 6 $, the probability is $ \left(\frac{1}{6}\right)^2 \frac{1}{5!} $. For $ N = 7 $, the probability is $ \left(\frac{1}{6}\right)^2 \frac{1}{5!}\left(\frac{1}{6} + \frac{1}{5} + \frac{1}{4} + \frac{1}{3} + \frac{1}{2} + 1\right) $. I'm not sure if the above are correct. When it comes to $ N = 8 $, there are many more cases to consider. I'm worried I may be approaching this the wrong way. I've also thought about calculating the probability that a number doesn't occur in the sequence, but that doesn't look to be any easier. Any hints/corrections would be greatly appreciated. Thanks","I throw a die $N$ times and the results are observed to be a monotonic sequence. What is probability that all 6 numbers occur in the sequence? I'm having trouble with this. There are two cases: when the first number is 1, and when the first number is 6. By symmetry, we can just consider one of them and double the answer at the end. I've looked at individual cases of $N$, and have that For $ N = 6 $, the probability is $ \left(\frac{1}{6}\right)^2 \frac{1}{5!} $. For $ N = 7 $, the probability is $ \left(\frac{1}{6}\right)^2 \frac{1}{5!}\left(\frac{1}{6} + \frac{1}{5} + \frac{1}{4} + \frac{1}{3} + \frac{1}{2} + 1\right) $. I'm not sure if the above are correct. When it comes to $ N = 8 $, there are many more cases to consider. I'm worried I may be approaching this the wrong way. I've also thought about calculating the probability that a number doesn't occur in the sequence, but that doesn't look to be any easier. Any hints/corrections would be greatly appreciated. Thanks",,['probability']
44,Chance of $7$ of a kind with $10$ dice,Chance of  of a kind with  dice,7 10,How can I calculate the probability of shaking $7$ of a kind using $10$ six-sided dice?,How can I calculate the probability of shaking $7$ of a kind using $10$ six-sided dice?,,['probability']
45,Find thickness of a coin,Find thickness of a coin,,"This is one of the question asked in a written test conducted by a company. The question sounded stupid to me. May be its not. ""Given the area of the coin to be 'A'. If the probability of getting a tail, head and the edge are same, what is the thickness of the coin?","This is one of the question asked in a written test conducted by a company. The question sounded stupid to me. May be its not. ""Given the area of the coin to be 'A'. If the probability of getting a tail, head and the edge are same, what is the thickness of the coin?",,"['probability', 'geometry', '3d']"
46,Sum of iid random variables,Sum of iid random variables,,"Iid random variables $Y_1, Y_2, \dots, Y_{50}$ take only the values $0$ , $1$ and $2$ with probabilities $\mathbb{P}(Y_i = 0) = \mathbb{P}(Y_i = 1) = \frac{4}{9}, \mathbb{P}(Y_i = 2) = \frac{1}{9}$ . Find the probability that the sum of these random variables will be $45$ . Now here's my idea: let $i$ be the number of $2$ 's ( $i$ is an integer between $0$ and $22$ ), then we must have $45 - 2i$ $1$ 's. There is $C^i_{50}$ ways to choose $Y_i$ that are gonna be equal to $2$ and $C^{45 - 2i}_{50 - i}$ ways to choose $Y_i$ that are gonna be equal to $1$ . The rest are going to be $0$ . Since we will have $i$ $2$ 's, $45 - 2i$ $1$ 's there is going to be $5 + i$ $0$ 's (since we have $50$ variables in total). Hence we have: $$\sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i} \mathbb{P}(Y_i = 2)^{i} \mathbb{P}(Y_i = 1)^{45 - 2i} \mathbb{P}(Y_i = 0)^{5 + i} = $$ $$\sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i} (\frac{1}{9})^{i} (\frac{4}{9})^{45 - 2i} (\frac{4}{9})^{5 + i} = $$ $$(\frac{4}{9})^{45} (\frac{4}{9})^{5} \sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i} (\frac{1}{9})^{i} (\frac{4}{9})^{- 2i} (\frac{4}{9})^{i} = $$ $$(\frac{4}{9})^{50} \sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i}$$ Now what surprises me is that there are no probabilities left inside the sum. Am I doing everything correctly? And if so, how can I make this sum prettier (i.e. get a number instead of a sum)? Thanks!","Iid random variables take only the values , and with probabilities . Find the probability that the sum of these random variables will be . Now here's my idea: let be the number of 's ( is an integer between and ), then we must have 's. There is ways to choose that are gonna be equal to and ways to choose that are gonna be equal to . The rest are going to be . Since we will have 's, 's there is going to be 's (since we have variables in total). Hence we have: Now what surprises me is that there are no probabilities left inside the sum. Am I doing everything correctly? And if so, how can I make this sum prettier (i.e. get a number instead of a sum)? Thanks!","Y_1, Y_2, \dots, Y_{50} 0 1 2 \mathbb{P}(Y_i = 0) =
\mathbb{P}(Y_i = 1) = \frac{4}{9}, \mathbb{P}(Y_i = 2) = \frac{1}{9} 45 i 2 i 0 22 45 - 2i 1 C^i_{50} Y_i 2 C^{45 - 2i}_{50 - i} Y_i 1 0 i 2 45 - 2i 1 5 + i 0 50 \sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i} \mathbb{P}(Y_i = 2)^{i} \mathbb{P}(Y_i = 1)^{45 - 2i} \mathbb{P}(Y_i = 0)^{5 + i} =  \sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i} (\frac{1}{9})^{i} (\frac{4}{9})^{45 - 2i} (\frac{4}{9})^{5 + i} =  (\frac{4}{9})^{45} (\frac{4}{9})^{5} \sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i} (\frac{1}{9})^{i} (\frac{4}{9})^{- 2i} (\frac{4}{9})^{i} =  (\frac{4}{9})^{50} \sum \limits_{i = 0}^{22} C^i_{50} C^{45 - 2i}_{50 - i}","['probability', 'random-variables', 'binomial-coefficients']"
47,Shooter and 8 targets,Shooter and 8 targets,,"A shooter shoots at eight identical targets in a shooting gallery. The probability of hitting each target with each shot is the same. It takes the shooter 11 shots to hit all 8 targets. What is the probability that the shooter hit fewer than 4 targets with the first five shots? I did the following: $p = \frac{8}{11}$ , $q = \frac{3}{11}$ - for Bernoulli formula. Then I calculated $P(x<4) = 1 - P(x=4) - P(x=5) = 0.72$ . But my friend told me that answer is $\frac{1}{2}$ . Where is a mistake in my solution?","A shooter shoots at eight identical targets in a shooting gallery. The probability of hitting each target with each shot is the same. It takes the shooter 11 shots to hit all 8 targets. What is the probability that the shooter hit fewer than 4 targets with the first five shots? I did the following: , - for Bernoulli formula. Then I calculated . But my friend told me that answer is . Where is a mistake in my solution?",p = \frac{8}{11} q = \frac{3}{11} P(x<4) = 1 - P(x=4) - P(x=5) = 0.72 \frac{1}{2},['probability']
48,Probability of winning a circular ball game,Probability of winning a circular ball game,,"Context: You and 4 other people are sitting in a circle. You are given a ball to start the game. Every second of this game, the person with the ball has three choices they can make. They can either pass the ball to the left, pass the ball to the right, or keep the ball (all with equal probability). This game goes on till someone keeps the ball. What is the probability that you are the person to end the game and keep the ball? I am refreshing my knowledge of probability, and I am stuck on this question. For reference, it is the 'pass the Quantguide. Working: Consider the following diagram for clarity. Let's define random variable $W(S_i)$ to be the event that player $S_i$ keeps the ball, and end the games. Well, by symmetry we have that $\mathbb{P}(W(S_1)) = \mathbb{P}(W(S_2))$ , and similarly $\mathbb{P}(W(S_3)) = \mathbb{P}(W(S_4))$ . For simplicity, let use denote $W(S_1)$ and $W(S_2)$ by $N$ (neighbour), and $W(S_3), W(S_4)$ by $NN$ (next neighbour). So, we wish to find $\mathbb{P}(W(S_0))$ (presumably by also finding $\mathbb{P}(N)$ and $\mathbb{P}(NN)$ ). To proceed, we may condition on the action of $S_0$ . Thus, $$ \mathbb{P}(W(S_0)) = \frac{1}{3} + \frac{1}{3} \mathbb{P}(W(S_0) | \text{left} ) + \frac{1}{3} \mathbb{P}(W(S_0) | \text{right}) = \frac{1}{3} + \frac{2}{3} \mathbb{P}(N) $$ Now, I struggle to proceed. I think that I should try to find an expression for $\mathbb{P}(N)$ in terms of $\mathbb{P}(W(S_0))$ and $\mathbb{P}(NN)$ , and similarly an expression for $\mathbb{P}(NN)$ in terms of $\mathbb{P}(W(S_0))$ and $\mathbb{P}(N)$ , however I am unsure of how I can do this without ending up with the exact same system of equations.","Context: You and 4 other people are sitting in a circle. You are given a ball to start the game. Every second of this game, the person with the ball has three choices they can make. They can either pass the ball to the left, pass the ball to the right, or keep the ball (all with equal probability). This game goes on till someone keeps the ball. What is the probability that you are the person to end the game and keep the ball? I am refreshing my knowledge of probability, and I am stuck on this question. For reference, it is the 'pass the Quantguide. Working: Consider the following diagram for clarity. Let's define random variable to be the event that player keeps the ball, and end the games. Well, by symmetry we have that , and similarly . For simplicity, let use denote and by (neighbour), and by (next neighbour). So, we wish to find (presumably by also finding and ). To proceed, we may condition on the action of . Thus, Now, I struggle to proceed. I think that I should try to find an expression for in terms of and , and similarly an expression for in terms of and , however I am unsure of how I can do this without ending up with the exact same system of equations.","W(S_i) S_i \mathbb{P}(W(S_1)) = \mathbb{P}(W(S_2)) \mathbb{P}(W(S_3)) = \mathbb{P}(W(S_4)) W(S_1) W(S_2) N W(S_3), W(S_4) NN \mathbb{P}(W(S_0)) \mathbb{P}(N) \mathbb{P}(NN) S_0 
\mathbb{P}(W(S_0)) = \frac{1}{3} + \frac{1}{3} \mathbb{P}(W(S_0) | \text{left} ) + \frac{1}{3} \mathbb{P}(W(S_0) | \text{right}) = \frac{1}{3} + \frac{2}{3} \mathbb{P}(N)
 \mathbb{P}(N) \mathbb{P}(W(S_0)) \mathbb{P}(NN) \mathbb{P}(NN) \mathbb{P}(W(S_0)) \mathbb{P}(N)",['probability']
49,"On average, how many uniformly random real numbers from $0$ to $1$ are required for the sum of their squares to exceed $1$?","On average, how many uniformly random real numbers from  to  are required for the sum of their squares to exceed ?",0 1 1,"A well-known question is: On average, how many uniformly random real numbers are needed for their sum to exceed $1$ ? The answer is $e$ . Let's tweak the question: On average, how many uniformly random real numbers are needed for the sum of their squares to exceed $1$ ? My attempt Let $f(n)=$ probability that the sum of squares of $n$ uniformly random real numbers is less than $1$ . The probability that the sum of squares exceeds $1$ for the first time with the $n$ th random number, is $f(n-1)-f(n)$ . Then the expectation is $\sum\limits_{n=2}^\infty n(f(n-1)-f(n))$ . I have worked out that: $f(1)=1$ $f(2)=\int_0^1\sqrt{1-{x_1}^2}dx_1$ $f(3)=\int_0^1\int_0^{\sqrt{1-{x_1}^2}}\sqrt{1-{x_1}^2-{x_2}^2}d{x_2}d{x_1}$ $f(4)=\int_0^1\int_0^{\sqrt{1-{x_1}^2}}\int_0^{\sqrt{1-{x_1}^2-{x_2}^2}}\sqrt{1-{x_1}^2-{x_2}^2-{x_3}^2}d{x_3}d{x_2}d{x_1}$ And so on. With help from Wolfram, the above expressions are: $f(2)=\frac{\pi}{4}$ $f(3)=\frac{\pi}{6}$ $f(4)=\frac{\pi^2}{32}$ A087299 suggests that $f(n)$ equals the ratio of the volume of an $n$ -dimensional ball to the circumscribed $n$ -cube, but I don't understand why. Assuming this is true, the expectation is  approximately $3.9257708130843$ . I don't know if this expectation has a closed form.","A well-known question is: On average, how many uniformly random real numbers are needed for their sum to exceed ? The answer is . Let's tweak the question: On average, how many uniformly random real numbers are needed for the sum of their squares to exceed ? My attempt Let probability that the sum of squares of uniformly random real numbers is less than . The probability that the sum of squares exceeds for the first time with the th random number, is . Then the expectation is . I have worked out that: And so on. With help from Wolfram, the above expressions are: A087299 suggests that equals the ratio of the volume of an -dimensional ball to the circumscribed -cube, but I don't understand why. Assuming this is true, the expectation is  approximately . I don't know if this expectation has a closed form.",1 e 1 f(n)= n 1 1 n f(n-1)-f(n) \sum\limits_{n=2}^\infty n(f(n-1)-f(n)) f(1)=1 f(2)=\int_0^1\sqrt{1-{x_1}^2}dx_1 f(3)=\int_0^1\int_0^{\sqrt{1-{x_1}^2}}\sqrt{1-{x_1}^2-{x_2}^2}d{x_2}d{x_1} f(4)=\int_0^1\int_0^{\sqrt{1-{x_1}^2}}\int_0^{\sqrt{1-{x_1}^2-{x_2}^2}}\sqrt{1-{x_1}^2-{x_2}^2-{x_3}^2}d{x_3}d{x_2}d{x_1} f(2)=\frac{\pi}{4} f(3)=\frac{\pi}{6} f(4)=\frac{\pi^2}{32} f(n) n n 3.9257708130843,"['probability', 'integration', 'expected-value', 'closed-form', 'volume']"
50,What's the explanation for the distribution of this kind of dice roll?,What's the explanation for the distribution of this kind of dice roll?,,"Consider the following type of dice roll for the attack damage in some tabletop RPG: Roll three six-sided dice. Pick two of them that have a sum greater six. The remaining die is the attack damage. If no combination of two dice has a sum greater than six then the attack damage is zero. Naturally players want to maximize damage and thus pick the lowest possible sum of two dice that is still greater than six. I tried to simulate that roll to see the probability distribution of the attack damage and was surprised that there is a probability of ~20% to roll the maximum damage of six. Here is the full distribution after 1M rolls: dmg p 0 0.195335 1 0.153332 2 0.097448 3 0.125001 4 0.101249 5 0.115615 6 0.21202 I makes sense to me that the attack damage is biased towards higher values, because players will choose the higher one when having the choice, but I kind of expected the distribution to increase from 1 to 6 as a result of that instead of fluctuating so much. So what's happening here? Inspired by some of the comments I plotted the distribution with this roll/selection for different kind of dice: The target value is always the most probable value when rolling two dice and taking the sum (so 7 for d6, 11 for d10 and 21 for d20).","Consider the following type of dice roll for the attack damage in some tabletop RPG: Roll three six-sided dice. Pick two of them that have a sum greater six. The remaining die is the attack damage. If no combination of two dice has a sum greater than six then the attack damage is zero. Naturally players want to maximize damage and thus pick the lowest possible sum of two dice that is still greater than six. I tried to simulate that roll to see the probability distribution of the attack damage and was surprised that there is a probability of ~20% to roll the maximum damage of six. Here is the full distribution after 1M rolls: dmg p 0 0.195335 1 0.153332 2 0.097448 3 0.125001 4 0.101249 5 0.115615 6 0.21202 I makes sense to me that the attack damage is biased towards higher values, because players will choose the higher one when having the choice, but I kind of expected the distribution to increase from 1 to 6 as a result of that instead of fluctuating so much. So what's happening here? Inspired by some of the comments I plotted the distribution with this roll/selection for different kind of dice: The target value is always the most probable value when rolling two dice and taking the sum (so 7 for d6, 11 for d10 and 21 for d20).",,"['probability', 'statistics', 'probability-distributions', 'dice']"
51,Marble drawing without replacement question,Marble drawing without replacement question,,There are $7$ marbles in a bag. $4$ white and $3$ black. Marbles are removed from the bag one at a time without replacement. What is the probability that the fifth marble removed is black? My thought is $\frac37$ . The thinking is like you are trying to label $1$ to $7$ on these balls. The chance that a black marble gets the label $5$ is $\frac37$ . Is my thought correct?,There are marbles in a bag. white and black. Marbles are removed from the bag one at a time without replacement. What is the probability that the fifth marble removed is black? My thought is . The thinking is like you are trying to label to on these balls. The chance that a black marble gets the label is . Is my thought correct?,7 4 3 \frac37 1 7 5 \frac37,"['probability', 'combinatorics']"
52,"Coupon collectors problem, but kicking a ball around","Coupon collectors problem, but kicking a ball around",,"The coupon collectors problem asks about the distribution of the number of coupons you'd need to collect in order to complete a collection. The coupons can have equal probabilities or unequal probabilities (in general). This is covered extensively here: Coupon collector's problem: mean and variance in number of coupons to be collected to complete a set (unequal probabilities) . Now, imagine $n$ soccer players training. They stand equally spaced in a circle and pass the ball to each other. Each player is more likely to pass the ball to someone standing close to them and less likely to pass to someone diametrically opposite. This implies an $n \times n$ matrix of probabilities, $p_{i, j}$ , which is given (probability player $i$ will pass to player $j$ ). How many passes are needed before every player has kicked the ball? Let's call this number of passes $N$ . What is $E(N)$ ?","The coupon collectors problem asks about the distribution of the number of coupons you'd need to collect in order to complete a collection. The coupons can have equal probabilities or unequal probabilities (in general). This is covered extensively here: Coupon collector's problem: mean and variance in number of coupons to be collected to complete a set (unequal probabilities) . Now, imagine soccer players training. They stand equally spaced in a circle and pass the ball to each other. Each player is more likely to pass the ball to someone standing close to them and less likely to pass to someone diametrically opposite. This implies an matrix of probabilities, , which is given (probability player will pass to player ). How many passes are needed before every player has kicked the ball? Let's call this number of passes . What is ?","n n \times n p_{i, j} i j N E(N)","['probability', 'expected-value', 'coupon-collector']"
53,$|W_{t_n}| \to \infty$ a.s. as $n \to \infty$ for Brownian $(W_t)_{t \in \mathbb{R}_+}$ with $\sum_{n=1}^\infty t_n^{-0.5} < \infty$?,a.s. as  for Brownian  with ?,|W_{t_n}| \to \infty n \to \infty (W_t)_{t \in \mathbb{R}_+} \sum_{n=1}^\infty t_n^{-0.5} < \infty,"Let $(W_t)_{t \in \mathbb{R}_+}$ be a Brownian motion. Let $(t_n)_{n \in \mathbb{N}} \subset \mathbb{R}_+$ be a sequence of time points, such that $\sum_{n=1}^\infty t_n^{-0.5} < \infty$ (so, for example, the sequences $t_n = n$ or $t_n = n^2 $ are not increasing sufficiently fast, but the sequence $t_n = n^3$ is increasing fast enough). Prove that \begin{align*} |W_{t_n}| \to + \infty \quad \text{a.s. as } n \to +\infty  \end{align*} I stumbled across this problem in a relatively unknown stochastic process textbook and I have no idea how to solve it. Thank you in advance for your help.","Let be a Brownian motion. Let be a sequence of time points, such that (so, for example, the sequences or are not increasing sufficiently fast, but the sequence is increasing fast enough). Prove that I stumbled across this problem in a relatively unknown stochastic process textbook and I have no idea how to solve it. Thank you in advance for your help.","(W_t)_{t \in \mathbb{R}_+} (t_n)_{n \in \mathbb{N}} \subset \mathbb{R}_+ \sum_{n=1}^\infty t_n^{-0.5} < \infty t_n = n t_n = n^2  t_n = n^3 \begin{align*}
|W_{t_n}| \to + \infty \quad \text{a.s. as } n \to +\infty 
\end{align*}","['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
54,Expected number of trials until all 3 (independent?) events happened,Expected number of trials until all 3 (independent?) events happened,,"Suppose there are three boxes, each has $9$ white balls and $1$ colored ball: Box $1$ : $9$ white and $1$ red. Box $2$ : $9$ white and $1$ green. Box $3$ : $9$ white and $1$ blue. Now I am drawing balls from the boxes with replacement. In each trial, I draw $1$ ball from each of the three boxes. If any of them is red, I increase my red ball counter by $1$ , then I put all balls back to their respective boxes. Similarly, I increase the corresponding counter if I get a green ball or a blue ball. The trials end only if my counters for all red, green and blue balls are at least $1$ (i.e., I get balls of each color at least once over all the trials). The question is, how do I calculate the expected number of trials until I hit the end condition? I know, if I only have $1$ box, then it is a simple geometric distribution, with $p=\frac{1}{10}$ , and hence the expected number of trials will be $10$ . But now, although the three events (get a red ball, get a green ball and get a blue ball) are independent, the combined event is not. And also since it is possible to have more than one event happen in each trial (e.g., getting red from box $1$ and green from box $2$ in the same trial), I cannot consider the events to happen one after another. I ran a quick simulation and it seems like the expected number of trials is around $17.9$ . I would like to know if there is a mathematical way to justify this number.","Suppose there are three boxes, each has white balls and colored ball: Box : white and red. Box : white and green. Box : white and blue. Now I am drawing balls from the boxes with replacement. In each trial, I draw ball from each of the three boxes. If any of them is red, I increase my red ball counter by , then I put all balls back to their respective boxes. Similarly, I increase the corresponding counter if I get a green ball or a blue ball. The trials end only if my counters for all red, green and blue balls are at least (i.e., I get balls of each color at least once over all the trials). The question is, how do I calculate the expected number of trials until I hit the end condition? I know, if I only have box, then it is a simple geometric distribution, with , and hence the expected number of trials will be . But now, although the three events (get a red ball, get a green ball and get a blue ball) are independent, the combined event is not. And also since it is possible to have more than one event happen in each trial (e.g., getting red from box and green from box in the same trial), I cannot consider the events to happen one after another. I ran a quick simulation and it seems like the expected number of trials is around . I would like to know if there is a mathematical way to justify this number.",9 1 1 9 1 2 9 1 3 9 1 1 1 1 1 p=\frac{1}{10} 10 1 2 17.9,"['probability', 'expected-value', 'conditional-probability']"
55,Is it possible to guess a number from an infinite range with yes or no questions?,Is it possible to guess a number from an infinite range with yes or no questions?,,"(I hope this qualifies as a math question; it might just be a puzzle.) I've had a thought experiment a few days ago: Assume you have a machine that randomly picks a whole number from 1 to infinity, and you can ask that machine as many yes or no question about the number it picked as you need; can you find out what number it picked? Edit (comments): to clarify, it has to be a whole number, it cannot pick infinity itself. Examples questions could be ""is the number larger/smaller than x?"" , ""is the nth digit x?"", ""is the number prime?"" , etc. My questions are: Is it possible to find out what number it picked (at all)? Is it possible in a finite amount of time? If yes, what could be the most efficient strategy to find out? (asking for ""higher than x"" , going through every single digit one by one, or something else entirely?) My intuition tells me that it's not possible to find out what number it picked, because no matter how large I make ""x"" (to ask ""is the number larger than x?"" ), there are always infinitely many more larger numbers the machine could've picked from. So the chances of me ever finding the upper bound of that number should be basically 0, since it's infinitely more likely to have picked a larger number?","(I hope this qualifies as a math question; it might just be a puzzle.) I've had a thought experiment a few days ago: Assume you have a machine that randomly picks a whole number from 1 to infinity, and you can ask that machine as many yes or no question about the number it picked as you need; can you find out what number it picked? Edit (comments): to clarify, it has to be a whole number, it cannot pick infinity itself. Examples questions could be ""is the number larger/smaller than x?"" , ""is the nth digit x?"", ""is the number prime?"" , etc. My questions are: Is it possible to find out what number it picked (at all)? Is it possible in a finite amount of time? If yes, what could be the most efficient strategy to find out? (asking for ""higher than x"" , going through every single digit one by one, or something else entirely?) My intuition tells me that it's not possible to find out what number it picked, because no matter how large I make ""x"" (to ask ""is the number larger than x?"" ), there are always infinitely many more larger numbers the machine could've picked from. So the chances of me ever finding the upper bound of that number should be basically 0, since it's infinitely more likely to have picked a larger number?",,"['probability', 'puzzle', 'infinity']"
56,What is wrong with my two fair dice probability question reasoning?,What is wrong with my two fair dice probability question reasoning?,,"There is a game where you are asked to roll two fair six-sided dice. If the sum of the values equals 7, then win £21. However, must pay £5 to play each time both dice are rolled. Do you play this game? One way to think about this is that getting a 7 comes with 1/6 chance, and to make money we need to get 7 at a rate of 1/4, so the answer is not to play. Another way to think about it is: what is my chance of throwing a 7 at least once in every 4 throws? In which case I would calculate a probability of not throwing a 7 4 throws in a row (5/6)^4, and then subtract this from 1 to get a probability of throwing at least one 7. Which is 1 - (5/6)^4 = 0.52. By this logic I would play the game. Both of these answers cannot be correct. Could someone explain to me which one is incorrect and why? Thanks! EDIT: wow, this is the first time I asked a question on StackOverflow, did not expect to get so many responses. Thank you all, I am very grateful!","There is a game where you are asked to roll two fair six-sided dice. If the sum of the values equals 7, then win £21. However, must pay £5 to play each time both dice are rolled. Do you play this game? One way to think about this is that getting a 7 comes with 1/6 chance, and to make money we need to get 7 at a rate of 1/4, so the answer is not to play. Another way to think about it is: what is my chance of throwing a 7 at least once in every 4 throws? In which case I would calculate a probability of not throwing a 7 4 throws in a row (5/6)^4, and then subtract this from 1 to get a probability of throwing at least one 7. Which is 1 - (5/6)^4 = 0.52. By this logic I would play the game. Both of these answers cannot be correct. Could someone explain to me which one is incorrect and why? Thanks! EDIT: wow, this is the first time I asked a question on StackOverflow, did not expect to get so many responses. Thank you all, I am very grateful!",,"['probability', 'statistics', 'dice']"
57,Probability that you win in rock scissors paper with 3 players?,Probability that you win in rock scissors paper with 3 players?,,"Let's say person A, person B and person C are playing rock paper scissors. Clearly $n(S)=3\times 3\times 3=27$ . We want to find the probability that person A wins. $n(\text{only A wins})=3$ (A wins with rock/scissors/paper). $n(\text{A and one other person wins})=2\times 3=6$ ( $2$ ways to choose the other winner, $3$ ways to win (rock/scissors/paper)) $\therefore P(\text{A wins})=\frac{3+2\times3}{27}=\frac{1}{3}$ , but this is flawed but this because it doesn't account for the probability where you draw. (i.e. if the probability of each person winning is $\frac{1}{3}$ , then the total probability is already $1$ , when we haven't accounted for the probability of drawing yet.) What is the correct probability that you will win in a game of rock scissors paper with 3 players? Thanks.","Let's say person A, person B and person C are playing rock paper scissors. Clearly . We want to find the probability that person A wins. (A wins with rock/scissors/paper). ( ways to choose the other winner, ways to win (rock/scissors/paper)) , but this is flawed but this because it doesn't account for the probability where you draw. (i.e. if the probability of each person winning is , then the total probability is already , when we haven't accounted for the probability of drawing yet.) What is the correct probability that you will win in a game of rock scissors paper with 3 players? Thanks.",n(S)=3\times 3\times 3=27 n(\text{only A wins})=3 n(\text{A and one other person wins})=2\times 3=6 2 3 \therefore P(\text{A wins})=\frac{3+2\times3}{27}=\frac{1}{3} \frac{1}{3} 1,"['probability', 'permutations', 'combinations']"
58,"Probability that $Y > 3X$ where $X,Y$ are $N(0,1)$ random variables",Probability that  where  are  random variables,"Y > 3X X,Y N(0,1)","$X$ and $Y$ are i.i.d. $N(0,1)$ random  variables.   You  are  given  that $Y >0$ .   What is the probability that $Y>3X$ ? Solution. The key is that $N(0,1)^2$ is cyclically symmetric.  When plotting the distributions,the pdf will be cyclically symmetric about the origin.  Then one can perform a geometric probabiltiy calculation to obtain the answer. How is $N(0,1)$ cyclically symmetric? Im not sure what this means in this case. How does $Y>0$ change this question? When you dont have this you can just consider adding multiple of the normal distribution (ie considering $Y-3X$ )","and are i.i.d. random  variables.   You  are  given  that .   What is the probability that ? Solution. The key is that is cyclically symmetric.  When plotting the distributions,the pdf will be cyclically symmetric about the origin.  Then one can perform a geometric probabiltiy calculation to obtain the answer. How is cyclically symmetric? Im not sure what this means in this case. How does change this question? When you dont have this you can just consider adding multiple of the normal distribution (ie considering )","X Y N(0,1) Y >0 Y>3X N(0,1)^2 N(0,1) Y>0 Y-3X","['probability', 'geometry', 'probability-distributions', 'normal-distribution']"
59,"What is the probability that the larger of two independent uniform variables on $[0,1]$ is greater than $3/4$ if the smaller one is less than $1/4$?",What is the probability that the larger of two independent uniform variables on  is greater than  if the smaller one is less than ?,"[0,1] 3/4 1/4","Two independent random variables are uniformly distributed on $[0, 1]$ . The question asks if the smaller of the two numbers is strictly less than $\frac{1}{4}$ , then what is the probability that the larger one is strictly greater than $\frac{3}{4}$ . I approached the question with trying to find a suitable area within the unit square. I got two lines that cut off a smaller square of $\frac{1}{4}$ length, hence I calculated the probability as $\frac{1}{16}$ ; but the answer given is $\frac{2}{7}$ and now I can't understand where I'm wrong.","Two independent random variables are uniformly distributed on . The question asks if the smaller of the two numbers is strictly less than , then what is the probability that the larger one is strictly greater than . I approached the question with trying to find a suitable area within the unit square. I got two lines that cut off a smaller square of length, hence I calculated the probability as ; but the answer given is and now I can't understand where I'm wrong.","[0, 1] \frac{1}{4} \frac{3}{4} \frac{1}{4} \frac{1}{16} \frac{2}{7}","['probability', 'uniform-distribution', 'geometric-probability']"
60,We roll a fair die until a $5$ appears. What is the expected value of the minimum value rolled?,We roll a fair die until a  appears. What is the expected value of the minimum value rolled?,5,"Question: Given a fair dice, we roll until we get a $5.$ What is the expected value of the minimum value rolled? Answer is $\frac{137}{60}.$ There is a similar question asked in MSE but I do not understand the method used by Henry. In particular, if we let $X$ be the minimum value rolled up to and including $5$ , then $$E(X) = \sum_{x=1}^5 xP(X=x) = 1 \times \frac12 + 2 \times \frac16 + 3 \times \frac1{12}+4 \times \frac{1}{20}+5 \times \frac15 = \frac{137}{60}.$$ It seems that we are using the fact that $$P(X=x) = \frac{1}{x(x+1)}.$$ I do not understand how to obtain the equation above.","Question: Given a fair dice, we roll until we get a What is the expected value of the minimum value rolled? Answer is There is a similar question asked in MSE but I do not understand the method used by Henry. In particular, if we let be the minimum value rolled up to and including , then It seems that we are using the fact that I do not understand how to obtain the equation above.",5. \frac{137}{60}. X 5 E(X) = \sum_{x=1}^5 xP(X=x) = 1 \times \frac12 + 2 \times \frac16 + 3 \times \frac1{12}+4 \times \frac{1}{20}+5 \times \frac15 = \frac{137}{60}. P(X=x) = \frac{1}{x(x+1)}.,"['probability', 'expected-value']"
61,Coin flips and Dice rolls,Coin flips and Dice rolls,,"A die is rolled 100 times, and the sum of the numbers that are rolled is recorded as X (for example, if a 6 is rolled every time, X = 600). A coin is tossed 600 times, and the number of heads is recorded as Y.  Find P(X > Y). I know E[X] = 350 and E[Y] = 300, but I am not able to find the probability of X > Y. Any help is appreciated.","A die is rolled 100 times, and the sum of the numbers that are rolled is recorded as X (for example, if a 6 is rolled every time, X = 600). A coin is tossed 600 times, and the number of heads is recorded as Y.  Find P(X > Y). I know E[X] = 350 and E[Y] = 300, but I am not able to find the probability of X > Y. Any help is appreciated.",,['probability']
62,Probability that graph with $6$ vertices and $5$ edges has a triangle.,Probability that graph with  vertices and  edges has a triangle.,6 5,"How to calcultate a probability that a graph with $6$ vertices and $5$ edges has a triangle? So we have ${15\choose 5}=3003$ (labeled) graphs and ${6\choose 3} =20$ possible triangles. Let $m_i$ be a number of graphs with $i$ -th triangle. Then $m_i= {12\choose 2}= 66$ and $m_{i,j} = 1$ if $\Delta _i$ and $\Delta _j$ have one common side, else it is $0$ . Notice that $m_{i,j} = 1$ is $9$ times for each $i$ . So $$m= 20\cdot 66 - {20\cdot 9\over 2} = 1230$$ So $$P = {1230\over 3003} \approx 0.41 $$ Is this correct and how to calculate this probability in general if we have $n$ vertices and $\varepsilon$ edges?","How to calcultate a probability that a graph with vertices and edges has a triangle? So we have (labeled) graphs and possible triangles. Let be a number of graphs with -th triangle. Then and if and have one common side, else it is . Notice that is times for each . So So Is this correct and how to calculate this probability in general if we have vertices and edges?","6 5 {15\choose 5}=3003 {6\choose 3} =20 m_i i m_i= {12\choose 2}= 66 m_{i,j} = 1 \Delta _i \Delta _j 0 m_{i,j} = 1 9 i m= 20\cdot 66 - {20\cdot 9\over 2} = 1230 P = {1230\over 3003} \approx 0.41  n \varepsilon","['probability', 'graph-theory']"
63,Alternate way of computing the probability of being dealt a 13 card hand with 3 kings given that you have been dealt 2 kings,Alternate way of computing the probability of being dealt a 13 card hand with 3 kings given that you have been dealt 2 kings,,"We are dealt 13 cards from a standard 52 card deck.  If $A$ is the event where we are dealt at least two kings and $B$ is the event where we are dealt at least 3 kings, we want to know $P(B|A)$ .  I believe the correct way to do this is to calculate the probability of being dealt a hand with each number of kings separately as follows: $\displaystyle \frac{{4 \choose 3}{48 \choose 10} + {4 \choose 4}{48 \choose 9}}{{4 \choose 2}{48 \choose 11} + {4 \choose 3}{48 \choose 10} + {4 \choose 4}{48 \choose 9}} \approx .17$ . However, it also makes sense to me that if we know we have been dealt 2 kings, it doesn't matter where in our hand they are, the $P(B|A)$ should be the same as the probability of getting dealt either 1 or 2 kings in an 11 card hand from a 50 card deck with two kings in it as follows: $\displaystyle \frac{{2 \choose 1}{48 \choose 10} + {2 \choose 2}{48 \choose 9}}{{50 \choose 11}} \approx .4$ (Or compute $1-p$ , where $p$ is the probability of getting no kings in an 11 card hand from a deck with 50 cards and only 2 kings.) What is the issue with my logic here?","We are dealt 13 cards from a standard 52 card deck.  If is the event where we are dealt at least two kings and is the event where we are dealt at least 3 kings, we want to know .  I believe the correct way to do this is to calculate the probability of being dealt a hand with each number of kings separately as follows: . However, it also makes sense to me that if we know we have been dealt 2 kings, it doesn't matter where in our hand they are, the should be the same as the probability of getting dealt either 1 or 2 kings in an 11 card hand from a 50 card deck with two kings in it as follows: (Or compute , where is the probability of getting no kings in an 11 card hand from a deck with 50 cards and only 2 kings.) What is the issue with my logic here?",A B P(B|A) \displaystyle \frac{{4 \choose 3}{48 \choose 10} + {4 \choose 4}{48 \choose 9}}{{4 \choose 2}{48 \choose 11} + {4 \choose 3}{48 \choose 10} + {4 \choose 4}{48 \choose 9}} \approx .17 P(B|A) \displaystyle \frac{{2 \choose 1}{48 \choose 10} + {2 \choose 2}{48 \choose 9}}{{50 \choose 11}} \approx .4 1-p p,"['probability', 'conditional-probability']"
64,Use De Moivre–Laplace to approximate $1 - \sum_{k=0}^{n} {n \choose k} p^{k}(1-p)^{n-k} \log\left(1+\left(\frac{p}{1-p}\right)^{n-2k}\right)$,Use De Moivre–Laplace to approximate,1 - \sum_{k=0}^{n} {n \choose k} p^{k}(1-p)^{n-k} \log\left(1+\left(\frac{p}{1-p}\right)^{n-2k}\right),I am trying to use De Moivre–Laplace theorem to approximate  $$1 - \sum_{k=0}^{n} {n \choose k} p^{k}(1-p)^{n-k} \log\left(1+\left(\frac{p}{1-p}\right)^{n-2k}\right)$$ The idea of an approximation is that we don't have the sum term which is difficult to calculate if $n$ is high. Using the  De Moivre–Laplace theorem gets us that: $${n \choose k} p^{k}(1-p)^{n-k} \approx \frac{1}{\sqrt{2 \pi np(1-p)}}e^{-\frac{(k-np)^2}{2np(1-p)}}$$ Now we see that \begin{align} F &= 1 - \sum_{k=0}^{n} {n \choose k} p^{k}(1-p)^{n-k} \log\left(1+\left(\frac{p}{1-p}\right)^{n-2k}\right) \\&\approx 1 - \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi np(1-p)}}e^{-\frac{(x-np)^2}{2np(1-p)}}\log_2\left(1+\left(\frac{p}{1-p}\right)^{n-2x}\right) dx \end{align} my calculation is inspired by Entropy of a binomial distribution If one has an other suggestion to approximate $F$ or get a closed for i would like to hear those. So far i've tried approximating $F$ with a least squares method using a tanh function as the fit function.,I am trying to use De Moivre–Laplace theorem to approximate  $$1 - \sum_{k=0}^{n} {n \choose k} p^{k}(1-p)^{n-k} \log\left(1+\left(\frac{p}{1-p}\right)^{n-2k}\right)$$ The idea of an approximation is that we don't have the sum term which is difficult to calculate if $n$ is high. Using the  De Moivre–Laplace theorem gets us that: $${n \choose k} p^{k}(1-p)^{n-k} \approx \frac{1}{\sqrt{2 \pi np(1-p)}}e^{-\frac{(k-np)^2}{2np(1-p)}}$$ Now we see that \begin{align} F &= 1 - \sum_{k=0}^{n} {n \choose k} p^{k}(1-p)^{n-k} \log\left(1+\left(\frac{p}{1-p}\right)^{n-2k}\right) \\&\approx 1 - \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi np(1-p)}}e^{-\frac{(x-np)^2}{2np(1-p)}}\log_2\left(1+\left(\frac{p}{1-p}\right)^{n-2x}\right) dx \end{align} my calculation is inspired by Entropy of a binomial distribution If one has an other suggestion to approximate $F$ or get a closed for i would like to hear those. So far i've tried approximating $F$ with a least squares method using a tanh function as the fit function.,,"['calculus', 'probability', 'integration', 'sequences-and-series', 'central-limit-theorem']"
65,If $\left< e^{-x}\right>=1$ then $\left<x\right>\ge 0$.,If  then .,\left< e^{-x}\right>=1 \left<x\right>\ge 0,I am wanting to prove that: $$\left< e^{-x}\right>=1\Rightarrow \left<x\right>\ge 0\tag{a}$$ which comes up in nonequilbrium physics with $x$ being the difference in entropy. Intuitively it seems correct as we have: $$ \int dx\; e^{-x} P(x)=1\tag{b}$$ thus $P(x)$ will need to be larger for the $x \gt 0$ terms then for the $x\lt 0$ due to the $e^{-x}$ factor weighing down $x\gt 0$ terms. But how can I rigorously prove (a)?,I am wanting to prove that: $$\left< e^{-x}\right>=1\Rightarrow \left<x\right>\ge 0\tag{a}$$ which comes up in nonequilbrium physics with $x$ being the difference in entropy. Intuitively it seems correct as we have: $$ \int dx\; e^{-x} P(x)=1\tag{b}$$ thus $P(x)$ will need to be larger for the $x \gt 0$ terms then for the $x\lt 0$ due to the $e^{-x}$ factor weighing down $x\gt 0$ terms. But how can I rigorously prove (a)?,,"['probability', 'expectation']"
66,Probability that if three balls numbered from 1-20 are selected without replacement that at least one will be numbered at least 17,Probability that if three balls numbered from 1-20 are selected without replacement that at least one will be numbered at least 17,,"I'm a new user here. I am currently self-learning probability theory (long journey ahead). I was wondering as to why my answer is not correct. I have listed the question below. Three balls are to be randomly selected without replacement from an urn containing 20 balls numbered 1 through 20. If we bet that at least one of the balls that are drawn has a number as large as or larger than 17, what is the probability that we win the bet? My solution: $ {{ 4 \choose 1}{ 19 \choose 2} \over { 20 \choose 3}}  $ Reason: ${ 4 \choose 1}$ is of choosing either 17, 18, 19, or 20. ${ 19 \choose 2}$ once a urn is chosen which is either 17,18, 19 ,20. There are 19 balls left and the value does not matter.","I'm a new user here. I am currently self-learning probability theory (long journey ahead). I was wondering as to why my answer is not correct. I have listed the question below. Three balls are to be randomly selected without replacement from an urn containing 20 balls numbered 1 through 20. If we bet that at least one of the balls that are drawn has a number as large as or larger than 17, what is the probability that we win the bet? My solution: $ {{ 4 \choose 1}{ 19 \choose 2} \over { 20 \choose 3}}  $ Reason: ${ 4 \choose 1}$ is of choosing either 17, 18, 19, or 20. ${ 19 \choose 2}$ once a urn is chosen which is either 17,18, 19 ,20. There are 19 balls left and the value does not matter.",,"['probability', 'combinatorics']"
67,Probability of two heads given the probability of a head on a Saturday,Probability of two heads given the probability of a head on a Saturday,,"The probability that a fair-coin lands on either Heads or Tails on a certain day of the week is $1/14$. Example: (H, Monday), (H, Tuesday) $...$ (T, Monday), (T, Tuesday) $...$ Thus, $(1/2 \cdot 1/7) = 1/14$. There are $14$ such outcomes. In some arbitrary week, Tom flips two fair-coins. You don't know if they were flipped on the same day, or on different days. After this arbitrary week, Tom tells you that at least one of the flips was a Heads which he flipped on Saturday . Determine the probability that Tom flipped two heads in that week. I know that this is a conditional probability problem. The probability of getting two heads is $(1/2)^2 = 1/4$. Call this event $P$ . I am trying to figure out the probability of Tom flipping at least one head on a Saturday. To get this probability, I know that we must compute the probability of there being no (H, Saturday) which is $1 - 1/14 = 13/14$. But then to get this ""at least"", we need to do $1 - 13/14$ which gives us $1/14$ again. Call this event $Q$. So is the probability of event $Q = 1/14$? It doesn't sound right to me. Afterwards we  must do $Pr(P | Q) = \frac{P(P \cap Q)}{Pr(Q)}$. Now I'm not quite sure what $P \cap Q$ means in this context.","The probability that a fair-coin lands on either Heads or Tails on a certain day of the week is $1/14$. Example: (H, Monday), (H, Tuesday) $...$ (T, Monday), (T, Tuesday) $...$ Thus, $(1/2 \cdot 1/7) = 1/14$. There are $14$ such outcomes. In some arbitrary week, Tom flips two fair-coins. You don't know if they were flipped on the same day, or on different days. After this arbitrary week, Tom tells you that at least one of the flips was a Heads which he flipped on Saturday . Determine the probability that Tom flipped two heads in that week. I know that this is a conditional probability problem. The probability of getting two heads is $(1/2)^2 = 1/4$. Call this event $P$ . I am trying to figure out the probability of Tom flipping at least one head on a Saturday. To get this probability, I know that we must compute the probability of there being no (H, Saturday) which is $1 - 1/14 = 13/14$. But then to get this ""at least"", we need to do $1 - 13/14$ which gives us $1/14$ again. Call this event $Q$. So is the probability of event $Q = 1/14$? It doesn't sound right to me. Afterwards we  must do $Pr(P | Q) = \frac{P(P \cap Q)}{Pr(Q)}$. Now I'm not quite sure what $P \cap Q$ means in this context.",,"['probability', 'combinatorics']"
68,Probability with Custom dice,Probability with Custom dice,,"I have a question about probabilities with custom 6-sided dice (not the regular 1,2,3,4,5,6 dice we all know and love, but a dice like 0,0,1,1,2,3). Now imagine having 3 different custom dice (blue, red and green, all with different sides) and that 2 players roll 3 of those dice (Player A is rolling R+G+B, player B is rolling 2R+G). Now, I can calculate the probability of each result separately. For example, I know that Player A has a 68% to roll at least ""3"" with his chosen dice, while Player B has only 52% to roll ""3"" with his dice. Same for any other result. What I don't know is if it is possible (an algorithm or formula) to calculate the probability that Player A will win the roll regardless of the number of successes. So I am not looking for statements of the type  ""68% vs 52% to roll ""3"", 53% vs 40% to roll ""4"", etc"",  but instead I am looking for the X in the following statement: ""When you roll R+G+B and the opponent is rolling 2R+G, you have a X% to roll higher"" (which equals winning the roll). Any ideas about how/if I can come up with an answer to this question? I can code this in a small app so that it makes all the calculations by itself, but I have no idea where to start when it comes to this type of complex probability result. I assume it is a purely mathematical/probability question, so I hope I posted this in the correct forum.","I have a question about probabilities with custom 6-sided dice (not the regular 1,2,3,4,5,6 dice we all know and love, but a dice like 0,0,1,1,2,3). Now imagine having 3 different custom dice (blue, red and green, all with different sides) and that 2 players roll 3 of those dice (Player A is rolling R+G+B, player B is rolling 2R+G). Now, I can calculate the probability of each result separately. For example, I know that Player A has a 68% to roll at least ""3"" with his chosen dice, while Player B has only 52% to roll ""3"" with his dice. Same for any other result. What I don't know is if it is possible (an algorithm or formula) to calculate the probability that Player A will win the roll regardless of the number of successes. So I am not looking for statements of the type  ""68% vs 52% to roll ""3"", 53% vs 40% to roll ""4"", etc"",  but instead I am looking for the X in the following statement: ""When you roll R+G+B and the opponent is rolling 2R+G, you have a X% to roll higher"" (which equals winning the roll). Any ideas about how/if I can come up with an answer to this question? I can code this in a small app so that it makes all the calculations by itself, but I have no idea where to start when it comes to this type of complex probability result. I assume it is a purely mathematical/probability question, so I hope I posted this in the correct forum.",,"['probability', 'dice']"
69,Singletons in coupon collecting problem,Singletons in coupon collecting problem,,"There are $n$ types of coupons. All types are equally likely to turn up and each ""draw"" of a coupon is independent of others. If someone collects coupons until they have a complete set of all the $n$ types, what is the expected value of the number of coupons that only appear once in this complete set? In the book, they give this solution: Let $X$ be the number of singletons. Let $T_i$ be the $i$th type of coupon collected and $A_i$ the event that there is only one $T_i$ coupon in the set. Then $$\mathbb{E} [X]=\sum_{i=1}^n \mathbb{P}(A_i)$$ This much I understand. What I do not understand is the following: Now, at the moment when the first type $T_i$ coupon is collected, there remain $n − i$ types that need to be collected to have a complete set. Because, starting at this moment, each of these $n − i + 1$ types (the $n − i$ not yet collected and type $T_i$) is equally likely to be the last of these types to be collected, it follows that the type $T_i$ will be the last of these types (and so will be a singleton) with probability $\frac {1}{ n−i+1}$. I do not understand this derivation of the probability. If $T_i$ just got collected, how is it that it can be collected last of the $n-i$ not yet collected types?","There are $n$ types of coupons. All types are equally likely to turn up and each ""draw"" of a coupon is independent of others. If someone collects coupons until they have a complete set of all the $n$ types, what is the expected value of the number of coupons that only appear once in this complete set? In the book, they give this solution: Let $X$ be the number of singletons. Let $T_i$ be the $i$th type of coupon collected and $A_i$ the event that there is only one $T_i$ coupon in the set. Then $$\mathbb{E} [X]=\sum_{i=1}^n \mathbb{P}(A_i)$$ This much I understand. What I do not understand is the following: Now, at the moment when the first type $T_i$ coupon is collected, there remain $n − i$ types that need to be collected to have a complete set. Because, starting at this moment, each of these $n − i + 1$ types (the $n − i$ not yet collected and type $T_i$) is equally likely to be the last of these types to be collected, it follows that the type $T_i$ will be the last of these types (and so will be a singleton) with probability $\frac {1}{ n−i+1}$. I do not understand this derivation of the probability. If $T_i$ just got collected, how is it that it can be collected last of the $n-i$ not yet collected types?",,"['probability', 'coupon-collector']"
70,Maximum Likelihood Estimation with Indicator Function,Maximum Likelihood Estimation with Indicator Function,,"I need to solve this exercise from the book below. $\textbf{Mathematical Statistics, Knight (2000)}$ $\textbf{Problem 6.17}$ Suppose that $X_1,\ldots,X_n$ are i.i.d. random variables with frequency function \begin{equation}   f(x;\theta)=\begin{cases}     \theta                 & \text{for $x=-1$}.\\     (1- \theta)^2 \theta^x & \text{for $x=0,1,2,\ldots$}   \end{cases} \end{equation} (a) Find the Cramer-Rao lower bound for unbiased estimators based on $X_1,\ldots,X_n$. (b) Show that the maximum likelihood estimator of $\theta$ based on $X_1,\ldots,X_n$ is $$\hat{\theta}_n = \frac{2 \sum_{i=1}^{n} I_{(X_{i}=-1)} + \sum_{i=1}^n X_i}{2n + \sum_{i=1}^n X_i}$$ and show that $\{\hat{\theta}_n\}$ is consistent for $\theta$. (c) Show that $\sqrt{n}(\hat{\theta}_n-\theta)\to_d N(0,\sigma^2(\theta))$ and find the value of $\sigma^2(\theta)$. Compare $\sigma^2(\theta)$ to the Cramer-Rao lower bound in part (a). No clue on how to solve (a) or (c). I started to solve (b) but I can't seem to arrive at the desired solution. I'm getting this: \begin{align} \mathcal{L} &= \prod_{i=1}^n (1-\theta)^2 \theta^{x_i I_{(X_i \geq 0)} + I_{(X_{i}=-1)}} \\ \mathcal{L} &= (1-\theta)^{2 \sum_{i=1}^n I_{(X_i \geq 0)}} \theta^{\sum_{i=1}^n x_i I_{(X_i \geq 0)} + \sum_{i=1}^n I_{(X_{i}=-1)}} \\ \log \mathcal{L} &= 2 \sum_{i=1}^n I_{(X_i \geq 0)} \log(1-\theta) + \sum_{i=1}^n x_i I_{(X_i \geq 0)} \log \theta + \sum_{i=1}^n I_{(X_i=-1)} \log \theta \end{align} $\textbf{FOC}$ \begin{align} 0 &= - \frac{2 \sum_{i=1}^n I_{(X_i \geq 0)}}{1-\theta} + \frac{\sum_{i=1}^n x_i I_{(X_i \geq 0)}} \theta + \frac{\sum_{i=1}^n I_{(X_i=-1)}} \theta \\ \\ \hat{\theta}_n &= \frac{\sum_{i=1}^n I_{(X_i=-1)} + \sum_{i=1}^n x_i I_{(X_i \geq 0)}}{\sum_{i=1}^n I_{(X_i=-1)} + 2 \sum_{i=1}^n I_{(X_i \geq 0)} + \sum_{i=1}^n x_i I_{(X_i \geq 0)}} \end{align} which differs from the result I'm given... Any help would be greatly appreciated.","I need to solve this exercise from the book below. $\textbf{Mathematical Statistics, Knight (2000)}$ $\textbf{Problem 6.17}$ Suppose that $X_1,\ldots,X_n$ are i.i.d. random variables with frequency function \begin{equation}   f(x;\theta)=\begin{cases}     \theta                 & \text{for $x=-1$}.\\     (1- \theta)^2 \theta^x & \text{for $x=0,1,2,\ldots$}   \end{cases} \end{equation} (a) Find the Cramer-Rao lower bound for unbiased estimators based on $X_1,\ldots,X_n$. (b) Show that the maximum likelihood estimator of $\theta$ based on $X_1,\ldots,X_n$ is $$\hat{\theta}_n = \frac{2 \sum_{i=1}^{n} I_{(X_{i}=-1)} + \sum_{i=1}^n X_i}{2n + \sum_{i=1}^n X_i}$$ and show that $\{\hat{\theta}_n\}$ is consistent for $\theta$. (c) Show that $\sqrt{n}(\hat{\theta}_n-\theta)\to_d N(0,\sigma^2(\theta))$ and find the value of $\sigma^2(\theta)$. Compare $\sigma^2(\theta)$ to the Cramer-Rao lower bound in part (a). No clue on how to solve (a) or (c). I started to solve (b) but I can't seem to arrive at the desired solution. I'm getting this: \begin{align} \mathcal{L} &= \prod_{i=1}^n (1-\theta)^2 \theta^{x_i I_{(X_i \geq 0)} + I_{(X_{i}=-1)}} \\ \mathcal{L} &= (1-\theta)^{2 \sum_{i=1}^n I_{(X_i \geq 0)}} \theta^{\sum_{i=1}^n x_i I_{(X_i \geq 0)} + \sum_{i=1}^n I_{(X_{i}=-1)}} \\ \log \mathcal{L} &= 2 \sum_{i=1}^n I_{(X_i \geq 0)} \log(1-\theta) + \sum_{i=1}^n x_i I_{(X_i \geq 0)} \log \theta + \sum_{i=1}^n I_{(X_i=-1)} \log \theta \end{align} $\textbf{FOC}$ \begin{align} 0 &= - \frac{2 \sum_{i=1}^n I_{(X_i \geq 0)}}{1-\theta} + \frac{\sum_{i=1}^n x_i I_{(X_i \geq 0)}} \theta + \frac{\sum_{i=1}^n I_{(X_i=-1)}} \theta \\ \\ \hat{\theta}_n &= \frac{\sum_{i=1}^n I_{(X_i=-1)} + \sum_{i=1}^n x_i I_{(X_i \geq 0)}}{\sum_{i=1}^n I_{(X_i=-1)} + 2 \sum_{i=1}^n I_{(X_i \geq 0)} + \sum_{i=1}^n x_i I_{(X_i \geq 0)}} \end{align} which differs from the result I'm given... Any help would be greatly appreciated.",,"['probability', 'maximum-likelihood']"
71,"Roll 10 fair die. What is the probability that the number 1 appears exactly four times, on four consecutive rolls","Roll 10 fair die. What is the probability that the number 1 appears exactly four times, on four consecutive rolls",,"I am asked: Roll $10$ fair die. What is the probability that the number $1$ appears   exactly four times, on four consecutive rolls? The answer I was given is $$\frac{1}{6^{10}}\cdot7\cdot5^6$$ with a comment saying we multiply by 7 ""for the first roll"". However, this doesn't make sense to me since there are only $6$ possible sides to the die. So it's not counting sides of the die. The only reason I can come up with for the 7 appearing is the case when the first $6$ rolls do not produce a sequence of consecutive $1$'s, so the $7$th item must begin the sequence of consecutive $1$'s So where exactly is this $7$ coming from?","I am asked: Roll $10$ fair die. What is the probability that the number $1$ appears   exactly four times, on four consecutive rolls? The answer I was given is $$\frac{1}{6^{10}}\cdot7\cdot5^6$$ with a comment saying we multiply by 7 ""for the first roll"". However, this doesn't make sense to me since there are only $6$ possible sides to the die. So it's not counting sides of the die. The only reason I can come up with for the 7 appearing is the case when the first $6$ rolls do not produce a sequence of consecutive $1$'s, so the $7$th item must begin the sequence of consecutive $1$'s So where exactly is this $7$ coming from?",,[]
72,"Why is the unit sphere strictly convex w.r.t ""continuous"" combinations?","Why is the unit sphere strictly convex w.r.t ""continuous"" combinations?",,"Let $\mu$ be a probability measure $\mathbb{R}^n$ (on the Borel or Lebesgue $\sigma$-algebra, I do not really care) which is supported on $\mathbb{S}^{n-1}$. (You can just think on a measure on the sphere itself). Suppose that for some unit vector $v \in \mathbb{S}^{n-1}$, it holds that $$ v= \int_{\mathbb{S}^{n-1}} x \, d\mu(x)$$ (That is $v$ is a ""continuous"" convex combination of the points of the sphere). How to prove that $\mu = \delta_v$? (I know this holds for finite combinations, and I am not sure how to generalize to the continuous case)","Let $\mu$ be a probability measure $\mathbb{R}^n$ (on the Borel or Lebesgue $\sigma$-algebra, I do not really care) which is supported on $\mathbb{S}^{n-1}$. (You can just think on a measure on the sphere itself). Suppose that for some unit vector $v \in \mathbb{S}^{n-1}$, it holds that $$ v= \int_{\mathbb{S}^{n-1}} x \, d\mu(x)$$ (That is $v$ is a ""continuous"" convex combination of the points of the sphere). How to prove that $\mu = \delta_v$? (I know this holds for finite combinations, and I am not sure how to generalize to the continuous case)",,"['probability', 'measure-theory', 'convex-analysis', 'spherical-geometry', 'spheres']"
73,Show that every finite family of random variables is tight.,Show that every finite family of random variables is tight.,,"A family of random variables $(X_i)_{i \in \mathcal{I}}$ is said to be $tight$ if for every $\epsilon>0$ there exist a compact set $K_\epsilon$ such that $$\displaystyle\sup_{i \in \mathcal{I}}\mathbb{P}(X_i\notin K_{\epsilon})<\epsilon$$ Show that every finite family of random variables is tight. So I tried to star with only one random variable, say $X$. So, I have that $\mathbb{P}(X\notin K_\epsilon)=\mathbb{P}(\{\omega : X(\omega) \notin K_\epsilon \})$ And I get stuck right there. I don't know how to construct my compact set $K_\epsilon$ because I don't know how to work with the event $\{\omega : X(\omega) \notin K_\epsilon \}$. Any help?","A family of random variables $(X_i)_{i \in \mathcal{I}}$ is said to be $tight$ if for every $\epsilon>0$ there exist a compact set $K_\epsilon$ such that $$\displaystyle\sup_{i \in \mathcal{I}}\mathbb{P}(X_i\notin K_{\epsilon})<\epsilon$$ Show that every finite family of random variables is tight. So I tried to star with only one random variable, say $X$. So, I have that $\mathbb{P}(X\notin K_\epsilon)=\mathbb{P}(\{\omega : X(\omega) \notin K_\epsilon \})$ And I get stuck right there. I don't know how to construct my compact set $K_\epsilon$ because I don't know how to work with the event $\{\omega : X(\omega) \notin K_\epsilon \}$. Any help?",,"['probability', 'probability-theory']"
74,How to understand the proof of E[X+Y] = E[X] + E[Y]?,How to understand the proof of E[X+Y] = E[X] + E[Y]?,,"I am studying probability and trying to follow an example in my textbook discussing expectation of the sum of random variables. But I'm having trouble following it. $E[X+Y] = \int^∞_{-∞}\int^∞_{-∞}$(x+y)f(x,y)dxdy $ = \int^∞_{-∞}\int^∞_{-∞}xf(x,y)dydx + \int^∞_{-∞}\int^∞_{-∞}yf(x,y)dxdy$ $ = \int^∞_{-∞}xf_X(x)dx + \int^∞_{-∞}yf_Y(y)dy$ $ = E[X] + E[Y]$ I am unsure how they obtain the third line down (the second equality). I understand $\int^∞_{-∞}f(x,y)dy = f_X(x)$ and vice versa for the marginal density function of Y. However, I'm a bit lost as to how they got rid of the double integral and not have to integrate x with respect to y as part of $xf(x,y)$ and likewise for y with respect to x. Could anyone point me in the right direction?","I am studying probability and trying to follow an example in my textbook discussing expectation of the sum of random variables. But I'm having trouble following it. $E[X+Y] = \int^∞_{-∞}\int^∞_{-∞}$(x+y)f(x,y)dxdy $ = \int^∞_{-∞}\int^∞_{-∞}xf(x,y)dydx + \int^∞_{-∞}\int^∞_{-∞}yf(x,y)dxdy$ $ = \int^∞_{-∞}xf_X(x)dx + \int^∞_{-∞}yf_Y(y)dy$ $ = E[X] + E[Y]$ I am unsure how they obtain the third line down (the second equality). I understand $\int^∞_{-∞}f(x,y)dy = f_X(x)$ and vice versa for the marginal density function of Y. However, I'm a bit lost as to how they got rid of the double integral and not have to integrate x with respect to y as part of $xf(x,y)$ and likewise for y with respect to x. Could anyone point me in the right direction?",,"['probability', 'random-variables', 'expectation']"
75,"Biased coin probability, uneven probability","Biased coin probability, uneven probability",,Getting at least $2$ heads when flipping a coin $3$ times but the coin is biased so that heads are $3$ times more likely than tails. Can anyone explain how uneven probability works? Thank you,Getting at least $2$ heads when flipping a coin $3$ times but the coin is biased so that heads are $3$ times more likely than tails. Can anyone explain how uneven probability works? Thank you,,['probability']
76,How do you scale a set of number such that they sum to 0.5 after scaling,How do you scale a set of number such that they sum to 0.5 after scaling,,"Suppose I have a set of numbers of various different values (>0.0). I want to scale these numbers so that they all sum to 0.5. The scaling is required so that the relative strength of the numbers with respect to the other numbers is retained as is, and the constraint that the sum of the numbers should be 0.5 after scaling is my requirement. What is the actual mathematical way to accomplish this?","Suppose I have a set of numbers of various different values (>0.0). I want to scale these numbers so that they all sum to 0.5. The scaling is required so that the relative strength of the numbers with respect to the other numbers is retained as is, and the constraint that the sum of the numbers should be 0.5 after scaling is my requirement. What is the actual mathematical way to accomplish this?",,"['probability', 'discrete-mathematics', 'mathematical-modeling']"
77,Interesting Probability Question - Birthday Problem Variation,Interesting Probability Question - Birthday Problem Variation,,"Suppose at a hipster eatery they make craft pickles. At this eatery they have $n$ pickle makers (picklers). Every day each pickler makes $10$ jars of pickles. Whenever any pickler has a birthday, there is a holiday (the eatery is closed, they do not work at all). There are no other holidays provided even weekends. Under these conditions, how many picklers have to be employed, if they want to maximize the expected number of jars of pickles produced in a year (i.e. maximize person-hours)? Hi, this is a very interesting problem I've come across. It seems to be a variation of the birthday problem. I tried let $y$ be the number of holidays and $f(y)$ be the pdf of the number holidays with respect to $n$. This is the pdf I came up with but it does not seem to be normalized. $$f(y) = \frac{365! \cdot y^{n-y}}{(365-y)!365^n}$$ Any suggestions?","Suppose at a hipster eatery they make craft pickles. At this eatery they have $n$ pickle makers (picklers). Every day each pickler makes $10$ jars of pickles. Whenever any pickler has a birthday, there is a holiday (the eatery is closed, they do not work at all). There are no other holidays provided even weekends. Under these conditions, how many picklers have to be employed, if they want to maximize the expected number of jars of pickles produced in a year (i.e. maximize person-hours)? Hi, this is a very interesting problem I've come across. It seems to be a variation of the birthday problem. I tried let $y$ be the number of holidays and $f(y)$ be the pdf of the number holidays with respect to $n$. This is the pdf I came up with but it does not seem to be normalized. $$f(y) = \frac{365! \cdot y^{n-y}}{(365-y)!365^n}$$ Any suggestions?",,"['probability', 'probability-distributions']"
78,"The bug ""probably"" gets stuck!","The bug ""probably"" gets stuck!",,"Consider a regular tetrahedron with vertices $A,B,C,D$. A bug starts crawling from $A$. The bug moves from one vertex to the other along the edges continuously until it reaches $D$, where there is glue and hence once the bug reaches $D$, it gets stuck. The bug can move to any one vertex from any other vertex with equal probability. Then, find the probability that the bug reaches $D$ from $B$. There seems to be varying answers to this question from different people (with $1/4$ and $1/5$ being the commonest responses). What can be the possible equation to be framed? Any hint is appreciated. Thanks!!","Consider a regular tetrahedron with vertices $A,B,C,D$. A bug starts crawling from $A$. The bug moves from one vertex to the other along the edges continuously until it reaches $D$, where there is glue and hence once the bug reaches $D$, it gets stuck. The bug can move to any one vertex from any other vertex with equal probability. Then, find the probability that the bug reaches $D$ from $B$. There seems to be varying answers to this question from different people (with $1/4$ and $1/5$ being the commonest responses). What can be the possible equation to be framed? Any hint is appreciated. Thanks!!",,"['probability', 'combinatorics', 'probability-theory', 'probability-distributions']"
79,A and B play until one has 2 more points than the other...,A and B play until one has 2 more points than the other...,,"Question A and B play until one has 2 more points than the other. Assuming that each point is independently won by A with probability p , what is the probability they will play a total of 2n points? What is the probability that A will win? My attempt for the solution: what is the probability they will play a total of 2n points? For the first question, A and B will be ""exchanging wins"" until $|A-B| = 2$, if one wins twice in a row then its terminal state. Also, winning guarantees even total points, $A = B + 2\\ A+B=B+B+2=2B+2$ A win always means even points then, making the job simpler. Probability prior to double winning streak shown in the following, Let $E_{i}$ be a set of game from start till achieving $2*i$ points. $P(E_{1}, E_{2}, \cdots, E_{n-1}) = P(E_{1}) + P(E_{2}) + \cdots + P(E_{n-1})\\ P(E_{1}, E_{2}, \cdots, E_{n-1}) = 1 + p*(p-1) + \cdots + (p*(p-1))^{2i-2}\\ P(E_{1}, E_{2}, \cdots, E_{n-1}) = \frac{1}{1-(p*(p-1))^{2}} - (p*(p-1))^{2i-1} - (p*(p-1))^{2i}$ *Note that $P(E_{1}) = P(\emptyset)$ since this is not the two winning streak. The winning streaks can be a union of either $A$ wins twice in a row or $B$ wins twice in a row: Let $S$ be the probability of 2n final points. $P(S) = P(E_{1}, E_{2}, \cdots, E_{n-1})*p^{2} + P(E_{1}, E_{2}, \cdots, E_{n-1})*(p-1)^{2}$ What is the probability that A will win? I didn't really understand this question, does it mean from a tie points to a double winning streak of A? Anyway, in that case, I just use the result from first question, $P(A_{win}) = P(E_{1}, E_{2}, \cdots, E_{n-1})*p^{2}$","Question A and B play until one has 2 more points than the other. Assuming that each point is independently won by A with probability p , what is the probability they will play a total of 2n points? What is the probability that A will win? My attempt for the solution: what is the probability they will play a total of 2n points? For the first question, A and B will be ""exchanging wins"" until $|A-B| = 2$, if one wins twice in a row then its terminal state. Also, winning guarantees even total points, $A = B + 2\\ A+B=B+B+2=2B+2$ A win always means even points then, making the job simpler. Probability prior to double winning streak shown in the following, Let $E_{i}$ be a set of game from start till achieving $2*i$ points. $P(E_{1}, E_{2}, \cdots, E_{n-1}) = P(E_{1}) + P(E_{2}) + \cdots + P(E_{n-1})\\ P(E_{1}, E_{2}, \cdots, E_{n-1}) = 1 + p*(p-1) + \cdots + (p*(p-1))^{2i-2}\\ P(E_{1}, E_{2}, \cdots, E_{n-1}) = \frac{1}{1-(p*(p-1))^{2}} - (p*(p-1))^{2i-1} - (p*(p-1))^{2i}$ *Note that $P(E_{1}) = P(\emptyset)$ since this is not the two winning streak. The winning streaks can be a union of either $A$ wins twice in a row or $B$ wins twice in a row: Let $S$ be the probability of 2n final points. $P(S) = P(E_{1}, E_{2}, \cdots, E_{n-1})*p^{2} + P(E_{1}, E_{2}, \cdots, E_{n-1})*(p-1)^{2}$ What is the probability that A will win? I didn't really understand this question, does it mean from a tie points to a double winning streak of A? Anyway, in that case, I just use the result from first question, $P(A_{win}) = P(E_{1}, E_{2}, \cdots, E_{n-1})*p^{2}$",,['probability']
80,Calculating Conditional Probability for Continuous Random Variables (Density Function or PDF),Calculating Conditional Probability for Continuous Random Variables (Density Function or PDF),,"Is that possible to calculate this? $$P(Y \leq \frac{1}{2} | X = 2)?$$ $X$ and $Y$ are both continuous random variables. I am asking this question because I know that we can't calculate a density function in a point, instead we should specify an interval. So how can we calculate this: $$P(Y < \frac{1}{2}, X = 2) / P(X = 2)? \quad\text{(Bayes form of the former expression)}$$ Since $X = 2$ is a point, not an interval.","Is that possible to calculate this? $$P(Y \leq \frac{1}{2} | X = 2)?$$ $X$ and $Y$ are both continuous random variables. I am asking this question because I know that we can't calculate a density function in a point, instead we should specify an interval. So how can we calculate this: $$P(Y < \frac{1}{2}, X = 2) / P(X = 2)? \quad\text{(Bayes form of the former expression)}$$ Since $X = 2$ is a point, not an interval.",,['probability']
81,"Is it possible to be ""too good"" at Spider Solitaire?","Is it possible to be ""too good"" at Spider Solitaire?",,"There was a similar question here: Losing at Spider Solitaire However, what I'm asking is different. The game has a rule that it would not deal the next ten cards, unless there is already a card in everyone of the ten slots. What I'm asking is whether it is theoretically possible that at any time, except the last deal, there might be a situation with less then 10 cards on the table? To me it feels like it should be possible, but it never happened to me, and I couldn't find any mention of it happening to anyone else...","There was a similar question here: Losing at Spider Solitaire However, what I'm asking is different. The game has a rule that it would not deal the next ten cards, unless there is already a card in everyone of the ten slots. What I'm asking is whether it is theoretically possible that at any time, except the last deal, there might be a situation with less then 10 cards on the table? To me it feels like it should be possible, but it never happened to me, and I couldn't find any mention of it happening to anyone else...",,"['probability', 'combinatorics', 'card-games']"
82,Brownian motion is almost surely not differentiable everywhere,Brownian motion is almost surely not differentiable everywhere,,"Could anyone point out the difference between the statement of the following theorems: 1) For any $t\ge0$, Brownian motion is almost surely not differentiable at $t$. 2) Almost surely, the sample paths of Brownian motion are not Lipschitz continuous at any point. In particular, the sample of Brownian motion are almost surely not differentiable at any point. The author of the book argues that to show 2) a more refined argument is needed. I'm a bit confused about the difference between the above statements. Could someone explain this?","Could anyone point out the difference between the statement of the following theorems: 1) For any $t\ge0$, Brownian motion is almost surely not differentiable at $t$. 2) Almost surely, the sample paths of Brownian motion are not Lipschitz continuous at any point. In particular, the sample of Brownian motion are almost surely not differentiable at any point. The author of the book argues that to show 2) a more refined argument is needed. I'm a bit confused about the difference between the above statements. Could someone explain this?",,"['probability', 'brownian-motion']"
83,Probability of drawing all red balls before any green ball,Probability of drawing all red balls before any green ball,,"Question: Suppose that a box contains $r$ red balls, $g$ green balls, and $b$ blue balls. Suppose also that balls are drawn from the box one at a time, at random, without replacement. What is the probability that all $r$ red balls will be obtained before any green balls are obtained? Solution(Partial): I know this solution for $1$ red, $1$ green and $1$ blue balls: $$\begin{array}{c|l|c} \color{red}{red} & \color{green}{green} & \color{blue}{blue}  \\ \hline \\ \color{blue}{blue} & \color{red}{red} & \color{green}{green}  \\ \hline \\ \color{red}{red} & \color{green}{green} & \color{blue}{blue}   \\\hline \\ \color{green}{green} & \color{red}{red} & \color{blue}{blue}    \\\hline \\\color{green}{green} & \color{blue}{blue}  &  \color{red}{red} \\\hline \\ \color{blue}{blue}  & \color{green}{green} & \color{red}{red} \\ \end{array}$$ This means,that there are $3$ outcomes for this event with the sample space of $6$.So, probability is $\frac{1}{2}$. But I don't know how to generalize this. Please help.Thank you.","Question: Suppose that a box contains $r$ red balls, $g$ green balls, and $b$ blue balls. Suppose also that balls are drawn from the box one at a time, at random, without replacement. What is the probability that all $r$ red balls will be obtained before any green balls are obtained? Solution(Partial): I know this solution for $1$ red, $1$ green and $1$ blue balls: $$\begin{array}{c|l|c} \color{red}{red} & \color{green}{green} & \color{blue}{blue}  \\ \hline \\ \color{blue}{blue} & \color{red}{red} & \color{green}{green}  \\ \hline \\ \color{red}{red} & \color{green}{green} & \color{blue}{blue}   \\\hline \\ \color{green}{green} & \color{red}{red} & \color{blue}{blue}    \\\hline \\\color{green}{green} & \color{blue}{blue}  &  \color{red}{red} \\\hline \\ \color{blue}{blue}  & \color{green}{green} & \color{red}{red} \\ \end{array}$$ This means,that there are $3$ outcomes for this event with the sample space of $6$.So, probability is $\frac{1}{2}$. But I don't know how to generalize this. Please help.Thank you.",,['probability']
84,Birthday Problem for 3 people,Birthday Problem for 3 people,,"I know that, in a room of 23 people, there is a 50-50 chance that two people have the same birthday. However, what I want to know is: How many people do you need to have a 50-50 chance that 3 people share the same birthday? Note: Assume for this question, that birthdays are equally distributed","I know that, in a room of 23 people, there is a 50-50 chance that two people have the same birthday. However, what I want to know is: How many people do you need to have a 50-50 chance that 3 people share the same birthday? Note: Assume for this question, that birthdays are equally distributed",,"['probability', 'birthday']"
85,Are two independent events $A$ and $B$ also conditionally independent given the event $C$?,Are two independent events  and  also conditionally independent given the event ?,A B C,"If we know that two events $A$ and $B$ are independent, can we say that $A$ and $B$ are also conditionally independent given an arbitrary event $C$? $$P(A\cap B) = P(A)P(B) \overset{?}{\Rightarrow} P(A\cap B|C) = P(A|C)P(B|C)$$","If we know that two events $A$ and $B$ are independent, can we say that $A$ and $B$ are also conditionally independent given an arbitrary event $C$? $$P(A\cap B) = P(A)P(B) \overset{?}{\Rightarrow} P(A\cap B|C) = P(A|C)P(B|C)$$",,['probability']
86,Zeta function and probability,Zeta function and probability,,I know that $\zeta(n) = \displaystyle\sum_{k=1}^\infty \frac{1}{k^n}$ (Where $\zeta(n)$ is the Riemann zeta function ) But the reciprocal of $\zeta(n)$ for $n$ a positive integer is equal to the probability that $n$ numbers chossen at random are relatively prime. But why? Can you give a proof?,I know that $\zeta(n) = \displaystyle\sum_{k=1}^\infty \frac{1}{k^n}$ (Where $\zeta(n)$ is the Riemann zeta function ) But the reciprocal of $\zeta(n)$ for $n$ a positive integer is equal to the probability that $n$ numbers chossen at random are relatively prime. But why? Can you give a proof?,,"['probability', 'number-theory', 'summation', 'riemann-zeta', 'exponentiation']"
87,Probability that multi-dimensional random variable is positive?,Probability that multi-dimensional random variable is positive?,,"If we have some multi-dimensional normal probability distribution, $X \sim \mathcal{N}(0,\Sigma)$, with zero mean and a known covariance matrix  then what is the probability that every component of $X$ is greater than or equal to zero? $$\mathbb{P}(\forall i.X_i \ge 0) = \: ?$$","If we have some multi-dimensional normal probability distribution, $X \sim \mathcal{N}(0,\Sigma)$, with zero mean and a known covariance matrix  then what is the probability that every component of $X$ is greater than or equal to zero? $$\mathbb{P}(\forall i.X_i \ge 0) = \: ?$$",,"['probability', 'probability-distributions']"
88,probability density function,probability density function,,"In a book the following sentence is told about probability density function at point $a$: ""it is a measure of how likely it is that the random variable will be near $a$."" What is the meaning of this ?","In a book the following sentence is told about probability density function at point $a$: ""it is a measure of how likely it is that the random variable will be near $a$."" What is the meaning of this ?",,['probability']
89,What is Cumulative Distribution Function of this random variable?,What is Cumulative Distribution Function of this random variable?,,"Suppose that we have $n$ independent random variables, $x_1,\ldots,x_n$ such that each $x_i$ takes value $a_i$ with success probability $p_i$ and value $0$ with failure probability $1-p_i$ ,i.e., \begin{align} P(x_1=a_1) & = p_1,\  P(x_1=0)= 1-p_1 \\ P(x_2=a_2) & = p_2,\ P(x_2=0) = 1-p_2 \\                                                                                                                                                                                                                                    & \vdots \\ P(x_n=a_n) & = p_n,\ P(x_n=0)=1-p_n   \end{align} where $a_i$'s are positive Real numbers . What would be the CDF of the sum of these random variables? That  is, what would be  $P(x_1+\cdots+x_n\le k)$ ? and how can we find it in an efficient way?","Suppose that we have $n$ independent random variables, $x_1,\ldots,x_n$ such that each $x_i$ takes value $a_i$ with success probability $p_i$ and value $0$ with failure probability $1-p_i$ ,i.e., \begin{align} P(x_1=a_1) & = p_1,\  P(x_1=0)= 1-p_1 \\ P(x_2=a_2) & = p_2,\ P(x_2=0) = 1-p_2 \\                                                                                                                                                                                                                                    & \vdots \\ P(x_n=a_n) & = p_n,\ P(x_n=0)=1-p_n   \end{align} where $a_i$'s are positive Real numbers . What would be the CDF of the sum of these random variables? That  is, what would be  $P(x_1+\cdots+x_n\le k)$ ? and how can we find it in an efficient way?",,"['probability', 'combinatorics', 'statistics', 'probability-theory', 'probability-distributions']"
90,Independent increments?,Independent increments?,,The questions are simple: Does the process $ X(t) = \int_0^t B(s)ds$ have independent increments? What about $X(t) = \int_{t-r}^{t}B(s)ds$ ? Here $B$ denotes the standard Brownian motion. Thanks a lot!,The questions are simple: Does the process have independent increments? What about ? Here denotes the standard Brownian motion. Thanks a lot!, X(t) = \int_0^t B(s)ds X(t) = \int_{t-r}^{t}B(s)ds B,"['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
91,Show the limsup of $B_t/\sqrt{t}$ when $t\to\infty$ is positive,Show the limsup of  when  is positive,B_t/\sqrt{t} t\to\infty,"I am trying to prove the following statement about the standard Brownian Motion: $\varlimsup_{t\rightarrow\infty} \frac{B_t}{\sqrt{t}}>0$. I know that it is trivial to prove the above statement by using powerful theorems about the Brownian Motion. But I have found this exercise in the first section of the first chapter in Revuz Yor. At this point, there aren't very many results about BM beyond the invariance properties. So can anyone help me to prove this using only elementary results?","I am trying to prove the following statement about the standard Brownian Motion: $\varlimsup_{t\rightarrow\infty} \frac{B_t}{\sqrt{t}}>0$. I know that it is trivial to prove the above statement by using powerful theorems about the Brownian Motion. But I have found this exercise in the first section of the first chapter in Revuz Yor. At this point, there aren't very many results about BM beyond the invariance properties. So can anyone help me to prove this using only elementary results?",,"['probability', 'stochastic-processes', 'brownian-motion']"
92,"Expectation of $TS_T$ where $T$ is the absorption time at $\{a,-a\}$ of a simple symmetric random walk $\{S_n\}$",Expectation of  where  is the absorption time at  of a simple symmetric random walk,"TS_T T \{a,-a\} \{S_n\}",I was trying to calculate the expectation of $T^2$ using some martingale and got that I needed the expectation of $TS_T$. Any idea?,I was trying to calculate the expectation of $T^2$ using some martingale and got that I needed the expectation of $TS_T$. Any idea?,,"['probability', 'probability-theory', 'random-walk', 'martingales']"
93,Expected number of intersection points when $n$ random chords are drawn in a circle,Expected number of intersection points when  random chords are drawn in a circle,n,There are $n$ random chords drawn in a circle. I am trying to determine the expected number of points in which the chords intersect within the circle.,There are $n$ random chords drawn in a circle. I am trying to determine the expected number of points in which the chords intersect within the circle.,,['probability']
94,Drawing a ball question,Drawing a ball question,,"Suppose we draw 3 balls without replacement from an urn with 2 red, 2 green, and 2 blue balls. How can I find the probability of each 0 red, 1 red and 2 red? I know the number of sample space is 120 ( Since we draw 3 balls and 6 balls in total, it would be 6*5*4). But I'm not sure how to get 0 red probability and 1 red pro. and 2 red prob. Can someone please help me?","Suppose we draw 3 balls without replacement from an urn with 2 red, 2 green, and 2 blue balls. How can I find the probability of each 0 red, 1 red and 2 red? I know the number of sample space is 120 ( Since we draw 3 balls and 6 balls in total, it would be 6*5*4). But I'm not sure how to get 0 red probability and 1 red pro. and 2 red prob. Can someone please help me?",,['probability']
95,Increasing the number of repetitions decreases the error probability,Increasing the number of repetitions decreases the error probability,,In coding theory when we encode 101 with 111000111 we have certain error probability. how can one prove that increasing the number of repetitions decreases the error probability. Let the probability of flipping a bit on receiving is 1-p If it done using three bits then P[A] = If two bits are flipped. = 3C2 * p^2 * (1-p) P[B] = If three bits are flipped = 3C3 * p^3 P[E] < P[A] + P[B] Similarly one can calculate for n=4 but I am not able to generalize it.,In coding theory when we encode 101 with 111000111 we have certain error probability. how can one prove that increasing the number of repetitions decreases the error probability. Let the probability of flipping a bit on receiving is 1-p If it done using three bits then P[A] = If two bits are flipped. = 3C2 * p^2 * (1-p) P[B] = If three bits are flipped = 3C3 * p^3 P[E] < P[A] + P[B] Similarly one can calculate for n=4 but I am not able to generalize it.,,"['probability', 'information-theory', 'coding-theory']"
96,Help with understanding and studying probability,Help with understanding and studying probability,,"I'm a CS major and self studying sheldon ross's first course in probability book, before that I have taken a calculus based probability course, not a strong one, which ended with superficially covering content in ross's 6th and 7th chapter. We proved gamma(1/2) = pi, solved integrals for calculating moment generating functions of some common ditributions, joint pdfs, jacobian determinant etc. The problem is, although doing a calculus based probability course and being comfortable with linear algebra and calculus I spend a lot of time understanding example problems in this book. My intention was studying some real analysis and measure theory and continue with stochastic calculus and I was hoping that at least at the end of summer I would get my feet wet in stochastic calculus. With this speed it seems that I would only be able to complete the ross's book at the end of summer if I attempt fair amount of exercises for each chapter. As an example, I was reading sum of independent random variables and the author explains it by convolution and I lost lots of time (hours) just understanding the convolution integral and its applications to the problem but this is only a single example in the book and there are many examples of this kind. I love to learn math and doing this as an hobby, but I have started to think that I am a bit stupid for learning math. What do you suggest me for studying math books efficiently ? And for professional math major students, do you spend a lot of time on text or do you grasp it very quickly ? Can you give some strategies for learning faster ? As a note I'm a foreign student and do not have abundance of qualified instructors or tutors who would help me with points I do not understand.","I'm a CS major and self studying sheldon ross's first course in probability book, before that I have taken a calculus based probability course, not a strong one, which ended with superficially covering content in ross's 6th and 7th chapter. We proved gamma(1/2) = pi, solved integrals for calculating moment generating functions of some common ditributions, joint pdfs, jacobian determinant etc. The problem is, although doing a calculus based probability course and being comfortable with linear algebra and calculus I spend a lot of time understanding example problems in this book. My intention was studying some real analysis and measure theory and continue with stochastic calculus and I was hoping that at least at the end of summer I would get my feet wet in stochastic calculus. With this speed it seems that I would only be able to complete the ross's book at the end of summer if I attempt fair amount of exercises for each chapter. As an example, I was reading sum of independent random variables and the author explains it by convolution and I lost lots of time (hours) just understanding the convolution integral and its applications to the problem but this is only a single example in the book and there are many examples of this kind. I love to learn math and doing this as an hobby, but I have started to think that I am a bit stupid for learning math. What do you suggest me for studying math books efficiently ? And for professional math major students, do you spend a lot of time on text or do you grasp it very quickly ? Can you give some strategies for learning faster ? As a note I'm a foreign student and do not have abundance of qualified instructors or tutors who would help me with points I do not understand.",,['probability']
97,"Finding MLE given dependent observations from uniform distribution $U(0,\theta)$ [closed]",Finding MLE given dependent observations from uniform distribution  [closed],"U(0,\theta)","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 days ago . Improve this question Suppose we are given random variables $X_1,...,X_n$ that are uniformly distributed on the interval $[0,\theta]$ , with $\theta >0$ unknown.  I know that if the $X_1,...,X_n$ are furthermore independent, we can conclude that the Maximum Likelihood Estimation is given as $\hat{\theta} = \max\limits_i x_i$ . I was wondering if the same conclusion also holds if the random variables $X_1,...,X_n$ are not independent. My main problem is that I am unable to determine the Likelihood function, which I do not know if it is possible if the $X_i$ are not independent. I would appreciate any help.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 days ago . Improve this question Suppose we are given random variables that are uniformly distributed on the interval , with unknown.  I know that if the are furthermore independent, we can conclude that the Maximum Likelihood Estimation is given as . I was wondering if the same conclusion also holds if the random variables are not independent. My main problem is that I am unable to determine the Likelihood function, which I do not know if it is possible if the are not independent. I would appreciate any help.","X_1,...,X_n [0,\theta] \theta >0 X_1,...,X_n \hat{\theta} = \max\limits_i x_i X_1,...,X_n X_i","['probability', 'probability-theory', 'statistics', 'parameter-estimation', 'maximum-likelihood']"
98,"Find $P(\sum_{i=1}^{10} X_i>50)$ if $X_i\sim U\{\pm 1,\dots,\pm 6\}$.",Find  if .,"P(\sum_{i=1}^{10} X_i>50) X_i\sim U\{\pm 1,\dots,\pm 6\}","A stock is currently worth \$ $100$ . each day a coin is flipped and a dice rolled. If the coin lands heads the stock price increases by the rolled value of the dice in $. If the coin lands tails, the stock price decreases by rolled value of the dice. What is probability that after 10 days the stock is worth more than 150? What I've tried is that 50 is such a large number that if you don't roll a 6, you have to roll 5*5 for the dice every day. And then to discuss case by case of rolling one 6,two 6 and so on.But that's a lot of work and seems tedious for 10 cases. Anyone can give me some insights on this?","A stock is currently worth \$ . each day a coin is flipped and a dice rolled. If the coin lands heads the stock price increases by the rolled value of the dice in $. If the coin lands tails, the stock price decreases by rolled value of the dice. What is probability that after 10 days the stock is worth more than 150? What I've tried is that 50 is such a large number that if you don't roll a 6, you have to roll 5*5 for the dice every day. And then to discuss case by case of rolling one 6,two 6 and so on.But that's a lot of work and seems tedious for 10 cases. Anyone can give me some insights on this?",100,"['probability', 'stochastic-processes', 'random-variables', 'generating-functions', 'simulation']"
99,Find the Expected Travel Distance of the Ambulance (Where did I go wrong?),Find the Expected Travel Distance of the Ambulance (Where did I go wrong?),,"Problem: The county hospital is located at the center of a square whose sides are 3 miles wide. If an accident occurs within this square, then the hospital sends out an ambulance. The road network is rectangular, so the travel distance from the hospital, whose coordinates are (0, 0), to the point (x, y) is |x|+|y|. If an accident occurs at a point that is uniformly distributed in the square, find the expected travel distance of the ambulance. My Attempt: $E[D] = E[X] + E[Y]$ ; Where D is the travel distance, X is the travel distance on the x axis and Y is the travel distance on the y axis. Because it's uniformly distributed and its a square I can do this: $E[D] = 2E[X]$ . Then $$(1) \space E[X] = \int_{a}^{b} xf_X(x) \,dx$$ $$(2) \space f(x, y) = |x| + |y|, 0 \leq x, y \leq 3/2$$ $$(3) \space f_X(x) = \int_{0}^{3/2} |x| + |y| \,dy = \frac{3}{2}x + \frac{9}{8}$$ (Because we're only working with positive values, there's no negative, so it's similar to integrating x + y) $$(4) \space E[X] = \int_{0}^{3/2} x(\frac{3}{2}x + \frac{9}{8}) \,dx = \frac{189}{64}$$ $$(5) \space E[D] = 2E[X]; E[D] = 2(\frac{189}{64}) = \frac{378}{64}$$ So the answer obviously doesn't make sense, as it's larger than the max travel distance possible, which is 3. \ The answer is 3/2 and this doesn't make sense to me either and I'll explain why. $E[X] = \mu$ which is the average. If the average is 3/2 then on average the ambulance will drive 0.75 miles on the x axis and 0.75 miles on the y axis. If we take the hospital as the center point, then we have a square of 1.5 by 1.5 mile surrounding the hospital. The area of that square is $\frac{9}{4}$ and the area of the other square which was 3 by 3, is 9. Then we have $9 - \frac{9}{4} = \frac{27}{4}.$ Considering we took the mean and the chance is uniform, meaning that every point in the square has an equal chance of being chosen, the area within the mean and the area outside of the mean should be equal, no?","Problem: The county hospital is located at the center of a square whose sides are 3 miles wide. If an accident occurs within this square, then the hospital sends out an ambulance. The road network is rectangular, so the travel distance from the hospital, whose coordinates are (0, 0), to the point (x, y) is |x|+|y|. If an accident occurs at a point that is uniformly distributed in the square, find the expected travel distance of the ambulance. My Attempt: ; Where D is the travel distance, X is the travel distance on the x axis and Y is the travel distance on the y axis. Because it's uniformly distributed and its a square I can do this: . Then (Because we're only working with positive values, there's no negative, so it's similar to integrating x + y) So the answer obviously doesn't make sense, as it's larger than the max travel distance possible, which is 3. \ The answer is 3/2 and this doesn't make sense to me either and I'll explain why. which is the average. If the average is 3/2 then on average the ambulance will drive 0.75 miles on the x axis and 0.75 miles on the y axis. If we take the hospital as the center point, then we have a square of 1.5 by 1.5 mile surrounding the hospital. The area of that square is and the area of the other square which was 3 by 3, is 9. Then we have Considering we took the mean and the chance is uniform, meaning that every point in the square has an equal chance of being chosen, the area within the mean and the area outside of the mean should be equal, no?","E[D] = E[X] + E[Y] E[D] = 2E[X] (1) \space E[X] = \int_{a}^{b} xf_X(x) \,dx (2) \space f(x, y) = |x| + |y|, 0 \leq x, y \leq 3/2 (3) \space f_X(x) = \int_{0}^{3/2} |x| + |y| \,dy = \frac{3}{2}x + \frac{9}{8} (4) \space E[X] = \int_{0}^{3/2} x(\frac{3}{2}x + \frac{9}{8}) \,dx = \frac{189}{64} (5) \space E[D] = 2E[X]; E[D] = 2(\frac{189}{64}) = \frac{378}{64} E[X] = \mu \frac{9}{4} 9 - \frac{9}{4} = \frac{27}{4}.","['probability', 'integration', 'probability-theory', 'expected-value', 'uniform-distribution']"
