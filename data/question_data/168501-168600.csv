,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Confidence interval for generalized variance (determinant of covariance matrix),Confidence interval for generalized variance (determinant of covariance matrix),,"Let $X\sim N(\mu,\Sigma)$ be a random variable in $\mathbb{R}^d$ with multivariate normal distribution. Let $\hat\Sigma$ be the maximum likelihood estimator for $\Sigma$ , \begin{align} \hat\Sigma=\frac1n\sum_{i=1}^n(\vec{x}_i-\bar x)(\vec{x}_i-\bar x)^T, \end{align} where $\vec{x}_i\in\mathbb{R}^d$ is the $i$ th sample vector and $\bar x\in\mathbb{R}^d$ is the sample mean of $X$ . What is a 95% confidence interval for $\det(\Sigma)$ ? That is, what is a confidence interval around $\det(\hat\Sigma)$ that will contain $\det(\Sigma)$ 95% of the time a sample is taken? I was led to this question because I am trying to find confidence intervals for estimates of entropy and mutual information for multivariate normally distributed variables. Edit : According to the article ""The distribution of the determinant of a complex Wishart distributed matrix"" by N.R. Goodman (see note at the end about the distibution of the determinant of a (real) Wishart distributed matrix, which is attributed to Wilks (1934)), the ratio $n^d(\det\hat\Sigma/\det\Sigma)$ is distributed as the product of $d$ independent $\chi^2$ random variables with $n, n-1, \cdots, n-d+1$ degress of freedom: \begin{align}   \frac{\det\hat\Sigma}{\det\Sigma}\sim \prod_{k=0}^{d-1} \frac{Y_k}{n},\text{ where } Y_k\sim\chi^2_{(n-k)}. \end{align} I checked this empirically with n=100, d=20, and it worked. The image at the bottom shows that the distribution of the variables on the left and right overlap almost identically. I simulated the variable on the left by choosing a fixed positive definite 20x20 covariance matrix $\Sigma$ , and creating n=100 samples to find $\hat\Sigma$ , and repeated $10^5$ times. I simulated the distribution on the right by sampling the appropriate $\chi^2$ distributions, dividing by n and forming the product ( $10^6$ times because it was faster). In this case (n=100, d=20) the confidence interval for $\det\hat\Sigma/\det\Sigma$ is approximately $[0.0344,0.3120]$ (which is interesting since it doesn't include 1). This means that if $l(n,d)$ is the .025-quantile, and $u(n,d)$ is the .975-quantile for $\prod_{k=0}^{d-1}\frac{Y_k}{n}$ , then \begin{align}  l(n,d) &\le \frac{\det\hat\Sigma}{\det\Sigma} \le u(n,d) \\  \frac{\det\hat\Sigma}{u(n,d)} &\le \det\Sigma \le \frac{\det\hat\Sigma}{l(n,d)} \end{align} 95% of the time. So what I am hoping for is expressions for $l(n,d)$ and $u(n,d)$ . Approximations in terms of n and d would be fine. (Let's say something like second order in $1/n$ and $1/d$ or any good approximation method that converges a lot faster than sampling the $\chi^2$ distributions). Thank you! Any help would be greatly appreciated.","Let be a random variable in with multivariate normal distribution. Let be the maximum likelihood estimator for , where is the th sample vector and is the sample mean of . What is a 95% confidence interval for ? That is, what is a confidence interval around that will contain 95% of the time a sample is taken? I was led to this question because I am trying to find confidence intervals for estimates of entropy and mutual information for multivariate normally distributed variables. Edit : According to the article ""The distribution of the determinant of a complex Wishart distributed matrix"" by N.R. Goodman (see note at the end about the distibution of the determinant of a (real) Wishart distributed matrix, which is attributed to Wilks (1934)), the ratio is distributed as the product of independent random variables with degress of freedom: I checked this empirically with n=100, d=20, and it worked. The image at the bottom shows that the distribution of the variables on the left and right overlap almost identically. I simulated the variable on the left by choosing a fixed positive definite 20x20 covariance matrix , and creating n=100 samples to find , and repeated times. I simulated the distribution on the right by sampling the appropriate distributions, dividing by n and forming the product ( times because it was faster). In this case (n=100, d=20) the confidence interval for is approximately (which is interesting since it doesn't include 1). This means that if is the .025-quantile, and is the .975-quantile for , then 95% of the time. So what I am hoping for is expressions for and . Approximations in terms of n and d would be fine. (Let's say something like second order in and or any good approximation method that converges a lot faster than sampling the distributions). Thank you! Any help would be greatly appreciated.","X\sim N(\mu,\Sigma) \mathbb{R}^d \hat\Sigma \Sigma \begin{align}
\hat\Sigma=\frac1n\sum_{i=1}^n(\vec{x}_i-\bar x)(\vec{x}_i-\bar x)^T,
\end{align} \vec{x}_i\in\mathbb{R}^d i \bar x\in\mathbb{R}^d X \det(\Sigma) \det(\hat\Sigma) \det(\Sigma) n^d(\det\hat\Sigma/\det\Sigma) d \chi^2 n, n-1, \cdots, n-d+1 \begin{align}
  \frac{\det\hat\Sigma}{\det\Sigma}\sim \prod_{k=0}^{d-1} \frac{Y_k}{n},\text{ where } Y_k\sim\chi^2_{(n-k)}.
\end{align} \Sigma \hat\Sigma 10^5 \chi^2 10^6 \det\hat\Sigma/\det\Sigma [0.0344,0.3120] l(n,d) u(n,d) \prod_{k=0}^{d-1}\frac{Y_k}{n} \begin{align}
 l(n,d) &\le \frac{\det\hat\Sigma}{\det\Sigma} \le u(n,d) \\
 \frac{\det\hat\Sigma}{u(n,d)} &\le \det\Sigma \le \frac{\det\hat\Sigma}{l(n,d)}
\end{align} l(n,d) u(n,d) 1/n 1/d \chi^2","['statistics', 'statistical-inference', 'matrix-calculus', 'entropy', 'confidence-interval']"
1,Find two numbers to minimize the sum of squares,Find two numbers to minimize the sum of squares,,"Suppose we are given a sequence of positive numbers $0<a_1<a_2< \cdots < a_n$ . Step 1. Choose an integer $m$ where $m \in \{1,2,\cdots,n\}$ . After choosing $m$ , we divide our numbers into two subgroups $\{a_1,\cdots,a_m\}$ and $\{a_{m+1},\cdots,a_n\}$ . Step 2. Given two numbers $a', a'' \in \mathbb{R}$ , we can calculate the sum of squares in the two subgroups $$SS = \sum_{i=1}^{m} (a_i-a')^2+\sum_{j=m+1}^n (a_j-a'')^2.$$ My question is how to choose $m, a', a''$ to minimize the $SS$ . The $a'$ and $a''$ are easy to solve. In fact, $a'$ should be the mean of the first subgroup, i.e. $\frac{a_1+\cdots + a_m}{m}$ and $a''$ should be the mean of the second subgroup, i.e. $\frac{a_{m+1}+\cdots + a_n}{n-m}$ . To solve $m$ , I guess that we can firstly compute the mean $\bar{a}$ of the whole group, i.e. $\frac{a_1+\cdots+a_n}{n}$ and then $m$ should be the largest integer such that $a_m<\bar{a}$ . But I don't know how to prove it.","Suppose we are given a sequence of positive numbers . Step 1. Choose an integer where . After choosing , we divide our numbers into two subgroups and . Step 2. Given two numbers , we can calculate the sum of squares in the two subgroups My question is how to choose to minimize the . The and are easy to solve. In fact, should be the mean of the first subgroup, i.e. and should be the mean of the second subgroup, i.e. . To solve , I guess that we can firstly compute the mean of the whole group, i.e. and then should be the largest integer such that . But I don't know how to prove it.","0<a_1<a_2< \cdots < a_n m m \in \{1,2,\cdots,n\} m \{a_1,\cdots,a_m\} \{a_{m+1},\cdots,a_n\} a', a'' \in \mathbb{R} SS = \sum_{i=1}^{m} (a_i-a')^2+\sum_{j=m+1}^n (a_j-a'')^2. m, a', a'' SS a' a'' a' \frac{a_1+\cdots + a_m}{m} a'' \frac{a_{m+1}+\cdots + a_n}{n-m} m \bar{a} \frac{a_1+\cdots+a_n}{n} m a_m<\bar{a}","['statistics', 'optimization', 'least-squares']"
2,Why can we treat Cox's partial likelihood as a full likelihood?,Why can we treat Cox's partial likelihood as a full likelihood?,,"I am doing some self study on Cox regression, and am trying to figure out how we can derive the partial likelihood for the Cox model from the full likelihood.  Generally, I know that to get a partial likelihood, we can just use proportionality, but here, this doesn't seem as intuitive. Consider the Cox full log likelihood: $$l(\theta) = \sum_{i=1}^n \delta_i log h_i(T_i;\theta) - \int_0^{T_{i}}h_i(s;\theta)ds$$ where $h_i(T_i;\theta)$ is the hazard: $h_i(T_i;\theta) = h_0(t)exp(\gamma^Tw_i)$ . The corresponding partial log likelihood would be: $$ pl(\gamma) = \sum_{i=1}^n \delta_i \bigg[\gamma^Tw_i - log \bigg\{\sum_{T_j\geq T_i}exp(\gamma^tw_j) \bigg\} \bigg] $$ Of course, the first apparent step I see is to substitute in the hazard function into the full likelihood: $$l(\theta) = \sum_{i=1}^n \delta_i log (h_0(t)exp(\gamma^Tw_i)) - \int_0^{T_{i}}h_0(t)exp(\gamma^Tw_i)ds$$ $$ = \sum_{i=1}^n \delta_i \bigg[\gamma^Tw_i+ log (h_0(t))\bigg] - \int_0^{T_{i}}h_0(t)exp(\gamma^Tw_i)ds$$ From here, any advice in the derivation or intuition would be much appreciated!","I am doing some self study on Cox regression, and am trying to figure out how we can derive the partial likelihood for the Cox model from the full likelihood.  Generally, I know that to get a partial likelihood, we can just use proportionality, but here, this doesn't seem as intuitive. Consider the Cox full log likelihood: where is the hazard: . The corresponding partial log likelihood would be: Of course, the first apparent step I see is to substitute in the hazard function into the full likelihood: From here, any advice in the derivation or intuition would be much appreciated!",l(\theta) = \sum_{i=1}^n \delta_i log h_i(T_i;\theta) - \int_0^{T_{i}}h_i(s;\theta)ds h_i(T_i;\theta) h_i(T_i;\theta) = h_0(t)exp(\gamma^Tw_i)  pl(\gamma) = \sum_{i=1}^n \delta_i \bigg[\gamma^Tw_i - log \bigg\{\sum_{T_j\geq T_i}exp(\gamma^tw_j) \bigg\} \bigg]  l(\theta) = \sum_{i=1}^n \delta_i log (h_0(t)exp(\gamma^Tw_i)) - \int_0^{T_{i}}h_0(t)exp(\gamma^Tw_i)ds  = \sum_{i=1}^n \delta_i \bigg[\gamma^Tw_i+ log (h_0(t))\bigg] - \int_0^{T_{i}}h_0(t)exp(\gamma^Tw_i)ds,"['statistics', 'statistical-inference', 'maximum-likelihood', 'regression-analysis', 'log-likelihood']"
3,Expected maximum of beta random variables,Expected maximum of beta random variables,,"Let $Y = \max_i X_i$ where $X_i \sim \text{Beta}(\alpha_i, \beta_i)$ independently. What is $\operatorname*{E} Y$ ? Let $[\cdot]$ denote the CDF of a random variable at $x$ . Since $Y \geq 0$ , \begin{align} \operatorname*{E} Y &= \int_0^\infty (1 - [Y]) \,\mathrm{d}x \\ &= \int_0^1 (1 - [Y]) \,\mathrm{d}x \\ &= 1 - \int_0^1 [Y] \,\mathrm{d}x \\ &= 1 - \int_0^1 \left[\max_i X_i\right] \,\mathrm{d}x \\ &= 1 - \int_0^1 \prod_i [X_i] \,\mathrm{d}x \\ &= 1 - \int_0^1 \prod_i I_x(\alpha_i, \beta_i) \,\mathrm{d}x \\ \end{align} where $I_x$ is the regularized incomplete beta function . Is there a closed form for this integral, perhaps in terms of transcendental functions?","Let where independently. What is ? Let denote the CDF of a random variable at . Since , where is the regularized incomplete beta function . Is there a closed form for this integral, perhaps in terms of transcendental functions?","Y = \max_i X_i X_i \sim \text{Beta}(\alpha_i, \beta_i) \operatorname*{E} Y [\cdot] x Y \geq 0 \begin{align}
\operatorname*{E} Y
&= \int_0^\infty (1 - [Y]) \,\mathrm{d}x \\
&= \int_0^1 (1 - [Y]) \,\mathrm{d}x \\
&= 1 - \int_0^1 [Y] \,\mathrm{d}x \\
&= 1 - \int_0^1 \left[\max_i X_i\right] \,\mathrm{d}x \\
&= 1 - \int_0^1 \prod_i [X_i] \,\mathrm{d}x \\
&= 1 - \int_0^1 \prod_i I_x(\alpha_i, \beta_i) \,\mathrm{d}x \\
\end{align} I_x","['statistics', 'probability-distributions', 'definite-integrals', 'expected-value', 'beta-function']"
4,Concentration inequality for sum of iid squares of sub-Exponential variables,Concentration inequality for sum of iid squares of sub-Exponential variables,,"If $X_i$ follows sub-Exponetial distribution, can we obtain the following inequality: $$ P(X_1^2+\cdots+X_n^2>nt)\le nP(X_1^2>nt) $$ I just saw this answer from this page: Concentration inequality for sum of squares of i.i.d. sub-exponential random variables? However I still cannot figure out why it holds. Could someone give me some explanations or references? Thanks a lot!","If follows sub-Exponetial distribution, can we obtain the following inequality: I just saw this answer from this page: Concentration inequality for sum of squares of i.i.d. sub-exponential random variables? However I still cannot figure out why it holds. Could someone give me some explanations or references? Thanks a lot!","X_i 
P(X_1^2+\cdots+X_n^2>nt)\le nP(X_1^2>nt)
","['probability', 'statistics']"
5,Understanding stochastic Big-$O$ notation in a stochastic process context,Understanding stochastic Big- notation in a stochastic process context,O,"I am trying to understand an equality in this paper about locally stationary processes on page 24. The equality includes stochastic Big-O (see D5 in this paper for a definition of stochastic O-notation) and is as follows: $$ \sum_{j = 0}^T \left[\prod_{k=0}^{j-1} \alpha\left(\frac{t-k}{T}\right)\right]\varepsilon_{t-j} = \sum_{j = 0}^T \alpha\left(\frac{1}{T}\right)^j \varepsilon_{t-j} + O_p\left(\frac{1}{T}\right), $$ for $T \rightarrow \infty$ where $\varepsilon_{t-j}$ is white noise. (I have left some coefficients from the paper out and I have only considered finitely many summands here for simplicity) Here I have already proved that $$ 	\prod_{k=0}^{j-1} \alpha\left(\frac{t-k}{T}\right) = \alpha\left(\frac{1}{T}\right)^j + O\left(\frac{1}{T}\right) $$ with deterministic Big-O notation. However, if I plug this result into the equation above, I get \begin{align*} 	\sum_{j = 0}^T \left[\prod_{k=0}^{j-1} \alpha\left(\frac{t-k}{T}\right)\right]\varepsilon_{t-j}  	&= \sum_{j = 0}^T \left[\alpha\left(\frac{1}{T}\right)^j + O\left(\frac{1}{T}\right)\right]\varepsilon_{t-j} \\ 	&= \sum_{j = 0}^T \alpha\left(\frac{1}{T}\right)^j \varepsilon_{t-j} + \sum_{j = 0}^T O\left(\frac{1}{T}\right) \varepsilon_{t-j}. \end{align*} Now we would need the following: $$ \sum_{j = 0}^T O\left(\frac{1}{T}\right) \varepsilon_{t-j} = O_p\left(\frac{1}{T}\right)$$ It is easy to see that $O\left(\frac{1}{T}\right) \varepsilon_{t-j} =  O_p\left(\frac{1}{T}\right)$ , but summing up I would get $$ \sum_{j = 0}^T O\left(\frac{1}{T}\right) \varepsilon_{t-j} = \sum_{j = 0}^T O_p\left(\frac{1}{T}\right) = T  O_p\left(\frac{1}{T}\right) = O_p(1)$$ and not the result above.","I am trying to understand an equality in this paper about locally stationary processes on page 24. The equality includes stochastic Big-O (see D5 in this paper for a definition of stochastic O-notation) and is as follows: for where is white noise. (I have left some coefficients from the paper out and I have only considered finitely many summands here for simplicity) Here I have already proved that with deterministic Big-O notation. However, if I plug this result into the equation above, I get Now we would need the following: It is easy to see that , but summing up I would get and not the result above.","
\sum_{j = 0}^T \left[\prod_{k=0}^{j-1} \alpha\left(\frac{t-k}{T}\right)\right]\varepsilon_{t-j} =
\sum_{j = 0}^T \alpha\left(\frac{1}{T}\right)^j \varepsilon_{t-j} + O_p\left(\frac{1}{T}\right),
 T \rightarrow \infty \varepsilon_{t-j} 
	\prod_{k=0}^{j-1} \alpha\left(\frac{t-k}{T}\right) = \alpha\left(\frac{1}{T}\right)^j + O\left(\frac{1}{T}\right)
 \begin{align*}
	\sum_{j = 0}^T \left[\prod_{k=0}^{j-1} \alpha\left(\frac{t-k}{T}\right)\right]\varepsilon_{t-j} 
	&= \sum_{j = 0}^T \left[\alpha\left(\frac{1}{T}\right)^j + O\left(\frac{1}{T}\right)\right]\varepsilon_{t-j} \\
	&= \sum_{j = 0}^T \alpha\left(\frac{1}{T}\right)^j \varepsilon_{t-j} + \sum_{j = 0}^T O\left(\frac{1}{T}\right) \varepsilon_{t-j}.
\end{align*}  \sum_{j = 0}^T O\left(\frac{1}{T}\right) \varepsilon_{t-j} = O_p\left(\frac{1}{T}\right) O\left(\frac{1}{T}\right) \varepsilon_{t-j} =  O_p\left(\frac{1}{T}\right)  \sum_{j = 0}^T O\left(\frac{1}{T}\right) \varepsilon_{t-j} = \sum_{j = 0}^T O_p\left(\frac{1}{T}\right) = T  O_p\left(\frac{1}{T}\right) = O_p(1)","['statistics', 'stochastic-processes', 'asymptotics', 'probability-limit-theorems']"
6,Why is it nice to be able to “add in quadrature” [$f(x+y)^2 = f(x)^2 + f(y)^2$]?,Why is it nice to be able to “add in quadrature” []?,f(x+y)^2 = f(x)^2 + f(y)^2,"If $x, y$ are two mathematical objects/variables, and $f$ is some function, then by “adding in quadrature” I mean that $(f(x+y))^2 = (f(x))^2 + (f(y))^2$ . For example, we have the Pythagorean Theorem for inner product spaces: for orthogonal vectors $u, v$ , we have $$\lVert {u + v} \rVert^2 = \lVert {u} \rVert^2 + \lVert {v} \rVert^2.$$ For two independent random variables $X, Y$ , the variance of the sum is the sum of variances: $$\sigma_{X+Y}^2 = \sigma_{X}^2 + \sigma_{Y}^2.$$ Also, I believe that when errors are uncorrelated, we can add uncertainties in quadrature. My question is: In general, when might we have $$(f(x+y))^2 = (f(x))^2 + (f(y))^2?$$ Why is this important? In all the examples above, there was some notion of independence: orthogonality, independent variables, and uncorrelatedness all have some interpretation as to how things are “independent”. My attempt at answering it might be: “If the square of $f(x+y)$ can be written only in terms of the original function values $f(x)$ and $f(y)$ , this indicates some independence among the variables.” But, why might it be related to squaring? Another thing I found interesting is that, if instead of squaring we just considered powers of 1, then we get $f(x + y) = f(x) + f(y)$ , which is just additivity. Is there something about squaring that is sort of like a “second-order” condition? (Whereas additivity might be the “first-order” condition?) Perhaps analogous to something like the first-derivative test and second-derivative test? Is it an interesting question to ask more generally whether $(f(x+y))^n = (f(x))^n + (f(y))^n$ , or some other similar question?","If are two mathematical objects/variables, and is some function, then by “adding in quadrature” I mean that . For example, we have the Pythagorean Theorem for inner product spaces: for orthogonal vectors , we have For two independent random variables , the variance of the sum is the sum of variances: Also, I believe that when errors are uncorrelated, we can add uncertainties in quadrature. My question is: In general, when might we have Why is this important? In all the examples above, there was some notion of independence: orthogonality, independent variables, and uncorrelatedness all have some interpretation as to how things are “independent”. My attempt at answering it might be: “If the square of can be written only in terms of the original function values and , this indicates some independence among the variables.” But, why might it be related to squaring? Another thing I found interesting is that, if instead of squaring we just considered powers of 1, then we get , which is just additivity. Is there something about squaring that is sort of like a “second-order” condition? (Whereas additivity might be the “first-order” condition?) Perhaps analogous to something like the first-derivative test and second-derivative test? Is it an interesting question to ask more generally whether , or some other similar question?","x, y f (f(x+y))^2 = (f(x))^2 + (f(y))^2 u, v \lVert {u + v} \rVert^2 = \lVert {u} \rVert^2 + \lVert {v} \rVert^2. X, Y \sigma_{X+Y}^2 = \sigma_{X}^2 + \sigma_{Y}^2. (f(x+y))^2 = (f(x))^2 + (f(y))^2? f(x+y) f(x) f(y) f(x + y) = f(x) + f(y) (f(x+y))^n = (f(x))^n + (f(y))^n","['real-analysis', 'linear-algebra', 'statistics', 'functions', 'physics']"
7,Intuitive explanation of GP-LVM,Intuitive explanation of GP-LVM,,"I am looking for an intuitive explanation of Gaussian Process Latent Variable Models (GP-LVM). Here is what I understand: GP-LVM is a nonlinear dimensionality-reduction method. I think ""nonlinear"" means that there is no linear relationship between the reduced dimensions that we end up with. PCA is a linear dimensionality-reduction method: We end up with principal components, which are the projection of the original data onto the principal axes. There is a linear relationship between principal components of different principal axes as we can always transform one into the other through scaling and addition. Does this sound right? GP-LVM assumes there are ""latent"" variables in a high-dimensional dataset. These are the ""important"" variables of the dataset as we can obtain all the other data through a nonlinear combination of the latent variables. Neil Lawrence gives an introduction in this presentation. He is trying to make a point with these rotated digits on slide 18. Can anyone explain to me what this is about? I understand that when being given a handwritten digit, i.e. 64 x 57 pixel values that are either 0 or 1, when we take random samples, we will never end up seeing the original digit. ""Sampling"" the image translates into taking random samples and arranging them on a 64 x 57 figure, doesn't it? Now he is rotating the digits a bit and plots principal components. Does this mean he has rotated the digit X times and for each rotated image he plots PC2 and PC3 ? Why doesn't he plot PC1 ? Very confused here. Finally, and this is where an intuitive explanation may reach its limits: How are Gaussian processes involved in predicting the original data from the latent variables? Also: How do we find the latent variables ?","I am looking for an intuitive explanation of Gaussian Process Latent Variable Models (GP-LVM). Here is what I understand: GP-LVM is a nonlinear dimensionality-reduction method. I think ""nonlinear"" means that there is no linear relationship between the reduced dimensions that we end up with. PCA is a linear dimensionality-reduction method: We end up with principal components, which are the projection of the original data onto the principal axes. There is a linear relationship between principal components of different principal axes as we can always transform one into the other through scaling and addition. Does this sound right? GP-LVM assumes there are ""latent"" variables in a high-dimensional dataset. These are the ""important"" variables of the dataset as we can obtain all the other data through a nonlinear combination of the latent variables. Neil Lawrence gives an introduction in this presentation. He is trying to make a point with these rotated digits on slide 18. Can anyone explain to me what this is about? I understand that when being given a handwritten digit, i.e. 64 x 57 pixel values that are either 0 or 1, when we take random samples, we will never end up seeing the original digit. ""Sampling"" the image translates into taking random samples and arranging them on a 64 x 57 figure, doesn't it? Now he is rotating the digits a bit and plots principal components. Does this mean he has rotated the digit X times and for each rotated image he plots PC2 and PC3 ? Why doesn't he plot PC1 ? Very confused here. Finally, and this is where an intuitive explanation may reach its limits: How are Gaussian processes involved in predicting the original data from the latent variables? Also: How do we find the latent variables ?",,"['statistics', 'data-analysis']"
8,Modern definition of unimodality for multivariate distributions and characterizations thereof,Modern definition of unimodality for multivariate distributions and characterizations thereof,,"Let $X$ be a random variable on $\mathbb R^n$ with density $f$ (w.r.t Lebesgue). Question. What is a generally agreed upon definition of unimodularity (of the distribution) of $X$ ? Are there any known charaterizations of this property ? Notes In the special case $n=1$ , unimodality is agreed in the literature to mean that There is a point $c \in \mathbb R$ (called the mode of $X$ ) such that $f$ is increasing on $(-\infty, c)$ and decreasing on $(c,\infty)$ . In this case, it is well-known (Khintchine, 1938) that $X$ has unimodal distribution iff $X \overset{d}{=} UZ$ , where $U$ is the uniformly distributed r.v on $[0, 1]$ and $Z$ a r.v on $\mathbb R$ which is independent of $U$ . Update: $\alpha$ -unimodularity The following definition is an interesting candidate for the concept of multivariate modularity. Definition. Let $\alpha \in [1,n]$ . A random variable $X$ on $\mathbb R^d$ is said to $\alpha$ -unimodular about the point $c \in \mathbb R^d$ iff for every bounded measurable function $g:\mathbb R^n \rightarrow [0,\infty)$ the function $t \mapsto t^{n-\alpha}\mathbb E[g(t(X-c))]$ is non-decreasing on $[0,\infty]$ . The unimodularity index of $X$ is defined to be the smallest value of $\alpha \in [1,n]$ such that $X$ is $\alpha$ -unimodular. The following is a characterization of multivariate unimodularity which parallels the univariate case. Theorem (Dharmadhikari et Joag-Dev, 1988). $X$ is $\alpha$ -unimodular iff $X \overset{d}{=} U^{1/\alpha}Z$ , where $U$ is the uniformly distributed r.v on $[0, 1]$ and $Z$ a r.v on $\mathbb R^d$ which is independent of $U$ .","Let be a random variable on with density (w.r.t Lebesgue). Question. What is a generally agreed upon definition of unimodularity (of the distribution) of ? Are there any known charaterizations of this property ? Notes In the special case , unimodality is agreed in the literature to mean that There is a point (called the mode of ) such that is increasing on and decreasing on . In this case, it is well-known (Khintchine, 1938) that has unimodal distribution iff , where is the uniformly distributed r.v on and a r.v on which is independent of . Update: -unimodularity The following definition is an interesting candidate for the concept of multivariate modularity. Definition. Let . A random variable on is said to -unimodular about the point iff for every bounded measurable function the function is non-decreasing on . The unimodularity index of is defined to be the smallest value of such that is -unimodular. The following is a characterization of multivariate unimodularity which parallels the univariate case. Theorem (Dharmadhikari et Joag-Dev, 1988). is -unimodular iff , where is the uniformly distributed r.v on and a r.v on which is independent of .","X \mathbb R^n f X n=1 c \in \mathbb R X f (-\infty, c) (c,\infty) X X \overset{d}{=} UZ U [0, 1] Z \mathbb R U \alpha \alpha \in [1,n] X \mathbb R^d \alpha c \in \mathbb R^d g:\mathbb R^n \rightarrow [0,\infty) t \mapsto t^{n-\alpha}\mathbb E[g(t(X-c))] [0,\infty] X \alpha \in [1,n] X \alpha X \alpha X \overset{d}{=} U^{1/\alpha}Z U [0, 1] Z \mathbb R^d U","['probability', 'statistics', 'probability-distributions', 'definition']"
9,Reference Request: Good book on parameter estimation for stochastic processes,Reference Request: Good book on parameter estimation for stochastic processes,,"I have to do some work where I need to estimate the parameters for a poisson process and a Hawkes process from data. I was looking through some of my old probability and stochastic processes textbooks, but I really could not find much on the actual parameter estimation of these process. I checked Grimmett and Stirzaker and the Sheldon Ross' Probability Models book, but they don't reference much on parameter estimation, etc. The Vere-Jones book on point processes as a bit more info, but not really fully fleshed examples. It seems a bit odd that there is not more on numerical methods and estimation of parameters for stochastic processes? Since there is so much theory on the numerical issues surrounding numerical estimation of say ordinary differential equations and partial differential equations, I assume numerical estimation would be a popular topic for stochastic processes too. There are a number of books on estimating Stochastic Differential Equations, but they don't seem to cover other stochastic processes--as far as I could see. I am curious if I am just looking in the wrong places, or if there is just a lack of materials? Seems like maximum likelihood would be a simple enough method to fit parameters for some of these models, but there could be numerical computing issues that I am not thinking of. I can certainly envision numerical computing issues cropping up in the case of continuous time stochastic processes--that need to be approximated by some discrete scheme. What about having lots of zeros, or the potential for big jumps--these things might generally throw off the optimization routine for a given model. So any good reference on parameter estimation for different types of stochastic processes would really be appreciated. Thanks.","I have to do some work where I need to estimate the parameters for a poisson process and a Hawkes process from data. I was looking through some of my old probability and stochastic processes textbooks, but I really could not find much on the actual parameter estimation of these process. I checked Grimmett and Stirzaker and the Sheldon Ross' Probability Models book, but they don't reference much on parameter estimation, etc. The Vere-Jones book on point processes as a bit more info, but not really fully fleshed examples. It seems a bit odd that there is not more on numerical methods and estimation of parameters for stochastic processes? Since there is so much theory on the numerical issues surrounding numerical estimation of say ordinary differential equations and partial differential equations, I assume numerical estimation would be a popular topic for stochastic processes too. There are a number of books on estimating Stochastic Differential Equations, but they don't seem to cover other stochastic processes--as far as I could see. I am curious if I am just looking in the wrong places, or if there is just a lack of materials? Seems like maximum likelihood would be a simple enough method to fit parameters for some of these models, but there could be numerical computing issues that I am not thinking of. I can certainly envision numerical computing issues cropping up in the case of continuous time stochastic processes--that need to be approximated by some discrete scheme. What about having lots of zeros, or the potential for big jumps--these things might generally throw off the optimization routine for a given model. So any good reference on parameter estimation for different types of stochastic processes would really be appreciated. Thanks.",,"['probability', 'statistics', 'stochastic-processes', 'numerical-methods', 'poisson-distribution']"
10,Generalized Least Squares results,Generalized Least Squares results,,"So, I've got the next problem: Let $Y\sim N_n(X\beta, \sigma^2 V)$ . Prove that, if $\hat{\beta} = (X^{\prime}V^{-1}X)^{-1}X^{\prime}V^{-1}Y$ then: $SSR = (Y-X\hat{\beta})^{\prime}V^{-1}(Y-X\hat{\beta}) \sim \sigma^{2}\chi^{2}_{(n-p)}$ . $SSR/(n-p)$ is UMVUE for $\sigma^{2}$ . If $\hat{Y} = X\hat{\beta} = PY$ then $P$ is idempotent but not necessarily symmetric. $\hat{\beta}$ is BLUE for $\beta$ . To note, the exercise didn't tell anything about the matrix $V$ , I'm guessing $V$ is, at least, a semi-positive definite matrix, or even positive-definite since $\sigma^{2}V$ is a covariance matrix... My attempt: Reading Seber's Linear regression analysis I realize there's a theorem that says that if $Y\sim N_n(\mu, \Sigma)$ where $\Sigma$ is positive-definite, then $(Y-\mu)^{\prime}\Sigma^{-1}(Y-\mu)\sim \chi^{2}_{n}$ . Since $Y-X\hat{\beta}\sim N_n(0,\sigma^{2}V)$ , and $\Sigma = \sigma^2 V$ positive-definite then $SSR = (Y-X\hat{\beta})^{\prime}\Sigma^{-1}(Y-X\hat{\beta})\sim \chi^{2}_{(n)}$ , but the exercise says the distribution is $\chi^2_{(n-p)}$ , that would be, if I'm not wrong, iff $\operatorname{rank}(\Sigma)=n-p$ . If that's so, then how can I prove $\operatorname{rank}(\Sigma)=n-p$ ? For this, I think the result is trivial once I have proved 1. I'm totally lost at this, for the idempotent property, it's as simple as $$P = X\hat{\beta} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1}$$ $$P^{2} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} = P. $$ But for proving that in general, $P$ is not symmetric I'm confused, should I give a counter example or something? I've already found that $$\mathbb{E}[\hat{\beta}] = \beta \mbox{ and } Var(\hat{\beta}) = \sigma^{2}(X^\prime V^{-1}X)^{-1}$$ Is that it to conclude $\hat{\beta}$ is BLUE? Any help would be appreciated.","So, I've got the next problem: Let . Prove that, if then: . is UMVUE for . If then is idempotent but not necessarily symmetric. is BLUE for . To note, the exercise didn't tell anything about the matrix , I'm guessing is, at least, a semi-positive definite matrix, or even positive-definite since is a covariance matrix... My attempt: Reading Seber's Linear regression analysis I realize there's a theorem that says that if where is positive-definite, then . Since , and positive-definite then , but the exercise says the distribution is , that would be, if I'm not wrong, iff . If that's so, then how can I prove ? For this, I think the result is trivial once I have proved 1. I'm totally lost at this, for the idempotent property, it's as simple as But for proving that in general, is not symmetric I'm confused, should I give a counter example or something? I've already found that Is that it to conclude is BLUE? Any help would be appreciated.","Y\sim N_n(X\beta, \sigma^2 V) \hat{\beta} = (X^{\prime}V^{-1}X)^{-1}X^{\prime}V^{-1}Y SSR = (Y-X\hat{\beta})^{\prime}V^{-1}(Y-X\hat{\beta}) \sim \sigma^{2}\chi^{2}_{(n-p)} SSR/(n-p) \sigma^{2} \hat{Y} = X\hat{\beta} = PY P \hat{\beta} \beta V V \sigma^{2}V Y\sim N_n(\mu, \Sigma) \Sigma (Y-\mu)^{\prime}\Sigma^{-1}(Y-\mu)\sim \chi^{2}_{n} Y-X\hat{\beta}\sim N_n(0,\sigma^{2}V) \Sigma = \sigma^2 V SSR = (Y-X\hat{\beta})^{\prime}\Sigma^{-1}(Y-X\hat{\beta})\sim \chi^{2}_{(n)} \chi^2_{(n-p)} \operatorname{rank}(\Sigma)=n-p \operatorname{rank}(\Sigma)=n-p P = X\hat{\beta} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} P^{2} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} = X(X^\prime V^{-1}X)^{-1}X^{\prime}V^{-1} = P.  P \mathbb{E}[\hat{\beta}] = \beta \mbox{ and } Var(\hat{\beta}) = \sigma^{2}(X^\prime V^{-1}X)^{-1} \hat{\beta}","['statistics', 'statistical-inference', 'linear-regression']"
11,Does it make sense to take the standard deviation of a uniform distribution of values?,Does it make sense to take the standard deviation of a uniform distribution of values?,,"You can get the mean and standard deviation of any set of numbers and come up with a Gaussian fitting them. What does it mean if you do this with another distribution, such as a uniform distribution? For instance, if i generate 1,000,000 uniform random numbers from 0 to 100, i get a mean of about 50 and a standard deviation of about 28.8. Gaussians have the 68-95-99.7 rule ( https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule ) which say that 68% of the values are going to be +/- 1 standard deviation from the mean. Using that logic, that says that 68% of the values in the uniform distribution are going to be between 50-28.8 and 50+28.8 aka between 21.2 and 78.8.  those values have a range of 57.6 which is definitely not accurate for a uniform distribution.  68% of the samples should be +/-34 from the mean of 50. When i plot the normalized histogram (pdf) of these two distributions, this is what I get. So, does taking the standard deviation of a uniform distribution make sense?  Can it tell me anything in particular other than a very general sense of how much dispersion the values have?  It doesn't feel very useful when the standard deviation itself has to be interpreted differently based on what sort of distribution the data itself has.  This doesn't seem to let you compare two pieces of data that may have different distributions. Am i missing something? Thanks!","You can get the mean and standard deviation of any set of numbers and come up with a Gaussian fitting them. What does it mean if you do this with another distribution, such as a uniform distribution? For instance, if i generate 1,000,000 uniform random numbers from 0 to 100, i get a mean of about 50 and a standard deviation of about 28.8. Gaussians have the 68-95-99.7 rule ( https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule ) which say that 68% of the values are going to be +/- 1 standard deviation from the mean. Using that logic, that says that 68% of the values in the uniform distribution are going to be between 50-28.8 and 50+28.8 aka between 21.2 and 78.8.  those values have a range of 57.6 which is definitely not accurate for a uniform distribution.  68% of the samples should be +/-34 from the mean of 50. When i plot the normalized histogram (pdf) of these two distributions, this is what I get. So, does taking the standard deviation of a uniform distribution make sense?  Can it tell me anything in particular other than a very general sense of how much dispersion the values have?  It doesn't feel very useful when the standard deviation itself has to be interpreted differently based on what sort of distribution the data itself has.  This doesn't seem to let you compare two pieces of data that may have different distributions. Am i missing something? Thanks!",,"['statistics', 'uniform-distribution', 'gaussian']"
12,How to estimate this expectation involving two binomial random variables?,How to estimate this expectation involving two binomial random variables?,,"$X$ and $Y$ are two independent binomial random variables where $X\sim B(K_1, q), Y\sim B(K_0, p)$ , (Suppose $p>q, p+q$ is not necessarily equal to 1). I am wondering how to compute the following expectation: $$ \mathbb{E}_X[X \ \text{Pr}(Y\geq \frac{q}{p}X)] = \sum_{t=0}^{K_1} t \text{Pr}(Y\geq \frac{q}{p}t) \text{Pr}(X=t).$$ Or at least give an upper and lower bound. I am also curious in another problem $\mathbb{E}_X[X \ \text{Pr}(Y\geq \frac{p}{q}X)]$ . If we assume that $K_0=K_1$ , then $Y$ and $\frac{p}{q}X$ have the same mean. This might be a more interesting case.","and are two independent binomial random variables where , (Suppose is not necessarily equal to 1). I am wondering how to compute the following expectation: Or at least give an upper and lower bound. I am also curious in another problem . If we assume that , then and have the same mean. This might be a more interesting case.","X Y X\sim B(K_1, q), Y\sim B(K_0, p) p>q, p+q  \mathbb{E}_X[X \ \text{Pr}(Y\geq \frac{q}{p}X)] = \sum_{t=0}^{K_1} t \text{Pr}(Y\geq \frac{q}{p}t) \text{Pr}(X=t). \mathbb{E}_X[X \ \text{Pr}(Y\geq \frac{p}{q}X)] K_0=K_1 Y \frac{p}{q}X","['probability', 'statistics', 'expected-value', 'binomial-distribution']"
13,What is the UMVUE of $\exp(-2\lambda)$ for X is a random variable with poisson distribution~poisson $(\lambda)$ [duplicate],What is the UMVUE of  for X is a random variable with poisson distribution~poisson  [duplicate],\exp(-2\lambda) (\lambda),"This question already has answers here : Confusion in finding conditional expecation of indicator function (Lehmann-Scheffe) (2 answers) Closed 4 years ago . If $X_1,X_2,…,X_n\sim Pois(λ)$ , find the UMVUE of $\exp(−2λ)$ . I know based on lehmann scheffe theorem, the step is (1)find $q(x)$ an unbiased estimater of $\exp(−2λ)$ (2) $T(X)$ is sufficient and complete (3) $s(*)=\mathbb E(q(x)|t(x))$ is a UMVUE (4) var $(s(*))$ < $\infty$ , then it is the UMVUE The answer IS: y=(-1)^x, when x is even y=1,when x is odd, y=-1. But I still do not know step by step, how to make it work?","This question already has answers here : Confusion in finding conditional expecation of indicator function (Lehmann-Scheffe) (2 answers) Closed 4 years ago . If , find the UMVUE of . I know based on lehmann scheffe theorem, the step is (1)find an unbiased estimater of (2) is sufficient and complete (3) is a UMVUE (4) var < , then it is the UMVUE The answer IS: y=(-1)^x, when x is even y=1,when x is odd, y=-1. But I still do not know step by step, how to make it work?","X_1,X_2,…,X_n\sim Pois(λ) \exp(−2λ) q(x) \exp(−2λ) T(X) s(*)=\mathbb E(q(x)|t(x)) (s(*)) \infty",['statistics']
14,The product of a normal variable by the cossine of another normal variable is a Laplace distribution?,The product of a normal variable by the cossine of another normal variable is a Laplace distribution?,,"Let $Z=X \cos(Y)$ be a random variable where $X\sim\mathcal N(0,\sigma_1)$ , $Y\sim\mathcal N(0,\sigma_2)$ . $X$ and $Y$ are independent.My goal it to obtain the PDF of Z or at least prove some behaviors. My first approach was to evaluate the pdf of $\cos (Y)$ and after that, use the convolution theorem to get $Z$ . However, I think that it's not a good way because the pdf of $\cos (Y)$ is a mess] 1 . After lost time with this approach, I investigated pdf of $Z$ numerically. [ 2 ] This distribution resembles a Laplace (exponential) distribution! Because of the exponential decay behavior (figure), I tried to discover the characteristic function of $Z$ . The reason to do that, it’s because if the characteristic function of $Z$ coincides with the characteristic function of the Laplace distribution then I solve my problem. I obtained the following integral for the characteristic function of $Z$ , $$ \varphi_Z(t) =    \frac{1}{\sqrt{2\pi}\sigma_2}   \int\limits_{-\infty}^\infty     \exp\left(-\frac{(t \sigma_1 \cos(y))^2}{2}\right) \exp\left(-\frac{y^2}{2\sigma_2^2}\right)    \mathrm{d} y, $$ I tried to solve that integral expanding the first exponential. $$ \varphi_Z(t) = \sum_{n=0}^\infty\frac{(-1)^n}{n!} \left(\frac{\sigma_1 t}{\sqrt{2}}\right)^{2n} \frac{1}{\sqrt{2\pi}} \sum_{k=0}^{2n} \binom{2n}{k} \exp(-2\sigma_2^2(n-k)^2). $$ However, I don’t know if I’m doing something wrong. This equation doesn’t look useful. My questions are Is there another way to calculate the pdf of $Z$ ? How to prove the exponential decaying behavior of pdf $Z$ without knowing the pdf of $Z$ ?","Let be a random variable where , . and are independent.My goal it to obtain the PDF of Z or at least prove some behaviors. My first approach was to evaluate the pdf of and after that, use the convolution theorem to get . However, I think that it's not a good way because the pdf of is a mess] 1 . After lost time with this approach, I investigated pdf of numerically. [ 2 ] This distribution resembles a Laplace (exponential) distribution! Because of the exponential decay behavior (figure), I tried to discover the characteristic function of . The reason to do that, it’s because if the characteristic function of coincides with the characteristic function of the Laplace distribution then I solve my problem. I obtained the following integral for the characteristic function of , I tried to solve that integral expanding the first exponential. However, I don’t know if I’m doing something wrong. This equation doesn’t look useful. My questions are Is there another way to calculate the pdf of ? How to prove the exponential decaying behavior of pdf without knowing the pdf of ?","Z=X \cos(Y) X\sim\mathcal N(0,\sigma_1) Y\sim\mathcal N(0,\sigma_2) X Y \cos (Y) Z \cos (Y) Z Z Z Z 
\varphi_Z(t) = 
  \frac{1}{\sqrt{2\pi}\sigma_2}
  \int\limits_{-\infty}^\infty
    \exp\left(-\frac{(t \sigma_1 \cos(y))^2}{2}\right) \exp\left(-\frac{y^2}{2\sigma_2^2}\right) 
  \mathrm{d} y,
 
\varphi_Z(t) = \sum_{n=0}^\infty\frac{(-1)^n}{n!} \left(\frac{\sigma_1 t}{\sqrt{2}}\right)^{2n}
\frac{1}{\sqrt{2\pi}} \sum_{k=0}^{2n} \binom{2n}{k} \exp(-2\sigma_2^2(n-k)^2).
 Z Z Z","['statistics', 'probability-distributions', 'random-variables', 'characteristic-functions']"
15,Partial Sum of Random Variables - Order Statistics,Partial Sum of Random Variables - Order Statistics,,"Let $U_1, U_2,\ldots,U_n$ be iid uniform random variables on $[0,1]$ . $U_{1,n}\leq U_{2,n}\leq\cdots\leq U_{n,n}$ be the order statistics. Show that, as $\frac{k_n}{n}\to p$ and $0\leq p\leq 1$ $$\frac{\sqrt{n}(U_{k_n,n}-\frac{k_n}{n+1})}{p(1-p)^{1/2}} \to N(0,1)$$ This is what I have tried: Using Renyi Rerepresentation: $$U_{k_n,n} = \frac{S(k_n)}{S(n+1)}$$ $$U_{k_n,n}-\frac{k_n}{n+1}=\frac{S(k_n)-k_n}{S(n+1)}-\frac{(S(n+1)-(n+1))k_n}{(n+1)S(n+1)}$$ This is where I get stuck Eventually I want to get to something like $\frac{S(k_n)-k_n}{\sqrt{k_n}}$ multiply by other fractions, those fractions converge to 1 and the whole transformation converges to $N(0,1)$","Let be iid uniform random variables on . be the order statistics. Show that, as and This is what I have tried: Using Renyi Rerepresentation: This is where I get stuck Eventually I want to get to something like multiply by other fractions, those fractions converge to 1 and the whole transformation converges to","U_1, U_2,\ldots,U_n [0,1] U_{1,n}\leq U_{2,n}\leq\cdots\leq U_{n,n} \frac{k_n}{n}\to p 0\leq p\leq 1 \frac{\sqrt{n}(U_{k_n,n}-\frac{k_n}{n+1})}{p(1-p)^{1/2}} \to N(0,1) U_{k_n,n} = \frac{S(k_n)}{S(n+1)} U_{k_n,n}-\frac{k_n}{n+1}=\frac{S(k_n)-k_n}{S(n+1)}-\frac{(S(n+1)-(n+1))k_n}{(n+1)S(n+1)} \frac{S(k_n)-k_n}{\sqrt{k_n}} N(0,1)","['sequences-and-series', 'statistics', 'weak-convergence', 'central-limit-theorem', 'order-statistics']"
16,Correlated discrete random variable generated by Markov Chains,Correlated discrete random variable generated by Markov Chains,,"I am dealing with following problem. I have $n=10$ weather stations and for each station I have information about wind direction: a discrete variable with 4 states $\{s, n, w, e\}$ . If I need generate wind direction scenarios for one station I am using a first order Markov chain. But now I need to generate scenarios for all weather stations and i need to include correlation between wind directions for each stations. Any idea how to model this  situation?",I am dealing with following problem. I have weather stations and for each station I have information about wind direction: a discrete variable with 4 states . If I need generate wind direction scenarios for one station I am using a first order Markov chain. But now I need to generate scenarios for all weather stations and i need to include correlation between wind directions for each stations. Any idea how to model this  situation?,"n=10 \{s, n, w, e\}","['statistics', 'markov-chains', 'correlation']"
17,Error in calculation of expectation of function chi square random variable,Error in calculation of expectation of function chi square random variable,,"Suppose that $X$ follows a chi-square distribution $\chi_n^2$ and that $Y=\sqrt{2X}$ . Find the pdf of $Y$ and show that $\mathbb{E}(Y) = \frac{\Gamma((n+1)/2)}{\Gamma(n/2)}$ . I have calculated the pdf using the change of variable formula as $$f_Y(y) = \frac{y^{n-1} e^{-y^2/4}}{2^{n-1} \Gamma(n/2)}$$ Now $$ \begin{split} \mathbb{E}(Y)  &= \int^{\infty}_{0} y \cdot \frac{y^{n-1} e^{-y^2/4}}{2^{n-1} \Gamma(n/2)}dy \\  &= \int^{\infty}_{0} \frac{y^{n} e^{-y^2/4}}{2^{n-1} \Gamma(n/2)}dy \\  &= \int^{\infty}_{0}\frac{y^{n-1}e^{-y^2/4}}{2^{n-2}\Gamma(n/2)} \frac{y}{2}dy \\  &= \int^{\infty}_{0}\frac{2^{n-1}(y^2/4)^{(n-1)/2}e^{-y^2/4}}{2^{n-2}\Gamma(n/2)} \frac{y}{2}dy \\  &= \int^{\infty}_{0}\frac{2(y^2/4)^{(n+1)/2-1}e^{-y^2/4}}{\Gamma(n/2)} \frac{y}{2}dy. \end{split} $$ Finally using the definition that $\Gamma(\alpha) = \int^{\infty}_{0} x^{\alpha-1}e^{-t}dt$ and making the substitution $t=y^2/4 \Leftrightarrow dt = y/2\,dy$ we get $$ \mathbb{E}(Y)  = \frac{2}{\Gamma(n/2)} \int^\infty_0  t^{(n+1)/2-1}e^{-t}\,dt  = \frac{2\Gamma((n+1)/2)}{\Gamma(n/2)} $$ which is off by a factor of $2$ of what they get. Where is the mistake?",Suppose that follows a chi-square distribution and that . Find the pdf of and show that . I have calculated the pdf using the change of variable formula as Now Finally using the definition that and making the substitution we get which is off by a factor of of what they get. Where is the mistake?,"X \chi_n^2 Y=\sqrt{2X} Y \mathbb{E}(Y) = \frac{\Gamma((n+1)/2)}{\Gamma(n/2)} f_Y(y) = \frac{y^{n-1} e^{-y^2/4}}{2^{n-1} \Gamma(n/2)} 
\begin{split}
\mathbb{E}(Y)
 &= \int^{\infty}_{0} y \cdot \frac{y^{n-1} e^{-y^2/4}}{2^{n-1} \Gamma(n/2)}dy \\
 &= \int^{\infty}_{0} \frac{y^{n} e^{-y^2/4}}{2^{n-1} \Gamma(n/2)}dy \\
 &= \int^{\infty}_{0}\frac{y^{n-1}e^{-y^2/4}}{2^{n-2}\Gamma(n/2)} \frac{y}{2}dy \\
 &= \int^{\infty}_{0}\frac{2^{n-1}(y^2/4)^{(n-1)/2}e^{-y^2/4}}{2^{n-2}\Gamma(n/2)}
\frac{y}{2}dy \\
 &= \int^{\infty}_{0}\frac{2(y^2/4)^{(n+1)/2-1}e^{-y^2/4}}{\Gamma(n/2)} \frac{y}{2}dy.
\end{split}
 \Gamma(\alpha) = \int^{\infty}_{0} x^{\alpha-1}e^{-t}dt t=y^2/4 \Leftrightarrow dt = y/2\,dy 
\mathbb{E}(Y)
 = \frac{2}{\Gamma(n/2)} \int^\infty_0  t^{(n+1)/2-1}e^{-t}\,dt
 = \frac{2\Gamma((n+1)/2)}{\Gamma(n/2)}
 2","['calculus', 'probability', 'statistics', 'probability-distributions', 'substitution']"
18,Correlation of $x + E(y\mid x)$ and $y + E(x\mid y)$ is bigger than the correlation of $x$ and $y$,Correlation of  and  is bigger than the correlation of  and,x + E(y\mid x) y + E(x\mid y) x y,"Suppose $x$ and $y$ are random variables with positive variance.  Let $\rho_{x,y} \in [-1,1]$ denote their (Pearson) correlation coefficient.  Let $\mathbb{E}(x\mid y)$ denote the conditional expectation of $x$ given $y$ and similarly $\mathbb{E}(y\mid x)$ is the conditional expectation of $y$ given $x$ .  Construct two functions: $$\lambda(x) \equiv x + \mathbb{E}(y\mid x) \text{ and } \mu(y) \equiv y + \mathbb{E}(x\mid y).$$ We can thus think of $\lambda$ and $\mu$ themselves as random variables. Assume the variances of both $\lambda$ and $\mu$ are strictly positive. Let $\rho_{\lambda,\mu}$ be the correlation coefficient for these random variables. Conjecture: $\rho_{x,y} \le \rho_{\lambda,\mu}$ . I've spent some time trying to prove this.  It is easy to show when the conditional expectations are linear, e.g. when $x$ and $y$ are jointly normal.  In that case, $|\rho_{x,y}| = |\rho_{\lambda,\mu}|$ .  I've also used Monte Carlo to construct many examples where $x$ and $y$ are discrete.  I have not found a counterexample.  I feel like this must be a known result, but my google skills have failed me.  Any ideas are appreciated.","Suppose and are random variables with positive variance.  Let denote their (Pearson) correlation coefficient.  Let denote the conditional expectation of given and similarly is the conditional expectation of given .  Construct two functions: We can thus think of and themselves as random variables. Assume the variances of both and are strictly positive. Let be the correlation coefficient for these random variables. Conjecture: . I've spent some time trying to prove this.  It is easy to show when the conditional expectations are linear, e.g. when and are jointly normal.  In that case, .  I've also used Monte Carlo to construct many examples where and are discrete.  I have not found a counterexample.  I feel like this must be a known result, but my google skills have failed me.  Any ideas are appreciated.","x y \rho_{x,y} \in [-1,1] \mathbb{E}(x\mid y) x y \mathbb{E}(y\mid x) y x \lambda(x) \equiv x + \mathbb{E}(y\mid x) \text{ and } \mu(y) \equiv y + \mathbb{E}(x\mid y). \lambda \mu \lambda \mu \rho_{\lambda,\mu} \rho_{x,y} \le \rho_{\lambda,\mu} x y |\rho_{x,y}| = |\rho_{\lambda,\mu}| x y","['probability', 'statistics', 'correlation']"
19,How to find the expectation of a Poisson process related variable,How to find the expectation of a Poisson process related variable,,"Q) Let $X_k\sim \operatorname{Exp}(\lambda)$ , $X_k$ are iid which represent the interarrival times of a Poisson process of mean rate $\lambda$ . Let $Y_k$ be the arrival times of the events. Let $$Z = \sum_{k=1}^N e^{-(t-Y_k)}$$ where $Y_1<Y_2<\cdots< t$ i.e. $N(t)$ events have occurred in time $t$ . Find $EZ, \operatorname{Var}(Z)$ . I have two questions. Does the $EZ$ calculation below look right and is there a simpler way to find $\operatorname{Var}(Z)$ because the expressions I have are large? $N(t)\sim \operatorname{Pois}(\lambda t)$ and $Y_k\sim \operatorname{Erlang}(k,\lambda)$ because $Y_k$ is the sum of iid exponential r.v's. $$\begin{align} EZ &= E[E[Z\mid N(t)]] \\ &= E\left[\sum_{k=1}^{N(t)} Ee^{-(t-Y_k)}\right] \\ &= E\left[\sum_{k=1}^{N(t)}\int_0^{\infty} e^{-(t-x)}\frac{\lambda^k x^{k-1}e^{-\lambda x}}{(k-1)!}dx \right] \\ &= E\left[\sum_{k=1}^{N(t)}\frac{\lambda^k e^{-t}}{(k-1)!} \int_0^\infty e^{(1-\lambda )x}x^{k-1}dx \right] \\ \end{align} $$ In general, $$\int_0^{\infty}e^{ax}x^n = (-a)^{-k-1}\Gamma(n+1)$$ Thus: $$\begin{align} EZ &= E\left[\sum_{k=1}^{N(t)}\frac{\lambda^k e^{-t}}{(k-1)!}\int_0^{\infty} e^{(1-\lambda )x}x^{k-1}dx \right] \\ &= E\left[\sum_{k=1}^{N(t)}\frac{\lambda^k e^{-t}}{(k-1)!} (\lambda - 1)^{-k}\Gamma(k)\right] \\ &= E\left[\sum_{k=1}^{N(t)}\left( \frac{\lambda}{\lambda-1}\right)^k e^{-t} \right] \\ &= e^{-t} E\left[ \frac{1-\left(\frac{\lambda}{\lambda-1}\right)^{N(t)+1}}{1-\frac{\lambda}{\lambda-1}} - 1 \right] \tag{1}\\ \end{align} $$ Note that since $N(t)\sim \operatorname{Pois}(\lambda t)$ : $$ \begin{align} E\left[ \left(\frac{\lambda}{\lambda-1}\right)^{N(t)+1} \right] &= \frac{e^{-\lambda}}{\lambda !}\sum_{k=0}^{\infty} \left(\frac{\lambda}{\lambda-1}\right)^{k+1}\times (\lambda t)^k\\ &= \frac{1}{(\lambda-1)(\lambda-1)!}.e^{-\lambda}\sum_{k=0}^{\infty} \left(\frac{\lambda ^2 t}{\lambda-1}\right)^k \\ &= \frac{e^{-\lambda}}{(\lambda-1)(\lambda-1)!}\times \frac{1}{1-\left(\frac{\lambda ^2 t}{\lambda-1}\right)} \tag{2} \end{align} $$ Plugging $(2)$ in $(1)$ , we get $EZ$ .","Q) Let , are iid which represent the interarrival times of a Poisson process of mean rate . Let be the arrival times of the events. Let where i.e. events have occurred in time . Find . I have two questions. Does the calculation below look right and is there a simpler way to find because the expressions I have are large? and because is the sum of iid exponential r.v's. In general, Thus: Note that since : Plugging in , we get .","X_k\sim \operatorname{Exp}(\lambda) X_k \lambda Y_k Z = \sum_{k=1}^N e^{-(t-Y_k)} Y_1<Y_2<\cdots< t N(t) t EZ, \operatorname{Var}(Z) EZ \operatorname{Var}(Z) N(t)\sim \operatorname{Pois}(\lambda t) Y_k\sim \operatorname{Erlang}(k,\lambda) Y_k \begin{align}
EZ &= E[E[Z\mid N(t)]] \\
&= E\left[\sum_{k=1}^{N(t)} Ee^{-(t-Y_k)}\right] \\
&= E\left[\sum_{k=1}^{N(t)}\int_0^{\infty} e^{-(t-x)}\frac{\lambda^k x^{k-1}e^{-\lambda x}}{(k-1)!}dx \right] \\
&= E\left[\sum_{k=1}^{N(t)}\frac{\lambda^k e^{-t}}{(k-1)!} \int_0^\infty e^{(1-\lambda )x}x^{k-1}dx \right] \\
\end{align}
 \int_0^{\infty}e^{ax}x^n = (-a)^{-k-1}\Gamma(n+1) \begin{align}
EZ &= E\left[\sum_{k=1}^{N(t)}\frac{\lambda^k e^{-t}}{(k-1)!}\int_0^{\infty} e^{(1-\lambda )x}x^{k-1}dx \right] \\
&= E\left[\sum_{k=1}^{N(t)}\frac{\lambda^k e^{-t}}{(k-1)!} (\lambda - 1)^{-k}\Gamma(k)\right] \\
&= E\left[\sum_{k=1}^{N(t)}\left( \frac{\lambda}{\lambda-1}\right)^k e^{-t} \right] \\
&= e^{-t} E\left[ \frac{1-\left(\frac{\lambda}{\lambda-1}\right)^{N(t)+1}}{1-\frac{\lambda}{\lambda-1}} - 1 \right] \tag{1}\\
\end{align}
 N(t)\sim \operatorname{Pois}(\lambda t) 
\begin{align}
E\left[ \left(\frac{\lambda}{\lambda-1}\right)^{N(t)+1} \right] &= \frac{e^{-\lambda}}{\lambda !}\sum_{k=0}^{\infty} \left(\frac{\lambda}{\lambda-1}\right)^{k+1}\times (\lambda t)^k\\
&= \frac{1}{(\lambda-1)(\lambda-1)!}.e^{-\lambda}\sum_{k=0}^{\infty} \left(\frac{\lambda ^2 t}{\lambda-1}\right)^k \\
&= \frac{e^{-\lambda}}{(\lambda-1)(\lambda-1)!}\times \frac{1}{1-\left(\frac{\lambda ^2 t}{\lambda-1}\right)} \tag{2}
\end{align}
 (2) (1) EZ","['probability', 'statistics']"
20,Bayesian hypothesis testing and posterior distribution,Bayesian hypothesis testing and posterior distribution,,"Let $X$ be a random variable with a probability density $f(\cdot;\theta)$ where $\theta \in \Theta \subset \mathbb R$ is an unknown parameter. Suppose that we have a prior density $\pi(\theta)$ , with associated random variable for the parameter $\tilde\Theta$ . Suppose that we have a random sample $X_1, \dots, X_n$ from $X$ . The interest is in the hypothesis testing problem $$ H_0: \theta \in \Theta_0 \quad\text{vs.}\quad H_1: \theta \in \Theta_1,$$ where $\Theta_1 = \Theta \setminus \Theta_0$ . Now, according to my course notes, we should proceed as follows. We determine the ratio of the posterior probabilities $$ \frac{P(\tilde\Theta \in \Theta_0 \mid X_1,\dots,X_n)}{P(\tilde\Theta \in \Theta_1 \mid X_1,\dots,X_n)} = \frac{P(\tilde\Theta \in \Theta_0) \int_{\Theta_0} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}{P(\tilde\Theta \in \Theta_1) \int_{\Theta_1} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}.$$ So we have $$ \frac{P(\tilde\Theta \in \Theta_0 \mid X_1,\dots,X_n)}{P(\tilde\Theta \in \Theta_1 \mid X_1,\dots,X_n)} = \frac{ \int_{\Theta_0} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}{ \int_{\Theta_1} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta} \times \frac{\int_{\Theta_0} \pi(\theta)}{1 - \int_{\Theta_0} \pi(\theta)}.$$ However, we also have that the posterior density is given by $$f_{\tilde \Theta \mid X_1,\dots,X_n}(\theta\mid x_1,\dots,x_n) = \frac{\prod_{i=1}^n f(X_i;\theta) \pi(\theta)}{\int_{\Theta}\prod_{i=1}^n f(X_i;\theta) \pi(\theta)\,d\theta}.$$ So it seems to me that the factor $\frac{ \int_{\Theta_0} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}{ \int_{\Theta_1} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}$ is already the ratio of the posterior probabilities (since it is just the posterior distribution integrated over $\Theta_0$ and $\Theta_1$ ). Where is the mistake in my reasoning?","Let be a random variable with a probability density where is an unknown parameter. Suppose that we have a prior density , with associated random variable for the parameter . Suppose that we have a random sample from . The interest is in the hypothesis testing problem where . Now, according to my course notes, we should proceed as follows. We determine the ratio of the posterior probabilities So we have However, we also have that the posterior density is given by So it seems to me that the factor is already the ratio of the posterior probabilities (since it is just the posterior distribution integrated over and ). Where is the mistake in my reasoning?","X f(\cdot;\theta) \theta \in \Theta \subset \mathbb R \pi(\theta) \tilde\Theta X_1, \dots, X_n X  H_0: \theta \in \Theta_0 \quad\text{vs.}\quad H_1: \theta \in \Theta_1, \Theta_1 = \Theta \setminus \Theta_0  \frac{P(\tilde\Theta \in \Theta_0 \mid X_1,\dots,X_n)}{P(\tilde\Theta \in \Theta_1 \mid X_1,\dots,X_n)}
= \frac{P(\tilde\Theta \in \Theta_0) \int_{\Theta_0} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}{P(\tilde\Theta \in \Theta_1) \int_{\Theta_1} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}.  \frac{P(\tilde\Theta \in \Theta_0 \mid X_1,\dots,X_n)}{P(\tilde\Theta \in \Theta_1 \mid X_1,\dots,X_n)} = \frac{
\int_{\Theta_0} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}{ \int_{\Theta_1} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta} \times \frac{\int_{\Theta_0} \pi(\theta)}{1 - \int_{\Theta_0} \pi(\theta)}. f_{\tilde \Theta \mid X_1,\dots,X_n}(\theta\mid x_1,\dots,x_n) = \frac{\prod_{i=1}^n f(X_i;\theta) \pi(\theta)}{\int_{\Theta}\prod_{i=1}^n f(X_i;\theta) \pi(\theta)\,d\theta}. \frac{
\int_{\Theta_0} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta}{ \int_{\Theta_1} \prod_{i=1}^n f(X_i;\theta) \pi(\theta) \,d\theta} \Theta_0 \Theta_1","['statistics', 'statistical-inference', 'bayesian', 'hypothesis-testing']"
21,Why are there (r-s-1) degrees of freedom in a Chi Square GoF Test for Composite Hypotheses?,Why are there (r-s-1) degrees of freedom in a Chi Square GoF Test for Composite Hypotheses?,,"In a Chi Square GoF Test for Composite Hypotheses, we are interested in whether the distribution of the random variable $\ X$ , which can take on a discrete set of values $\ B_1 , B_2, ...B_r$ according to probabilities $\ \mathbb{P}(X= B_1)=p_1 $ , $\ \mathbb{P}(X = B_2)=p_2 $ ,  ... , $\ \mathbb{P}(X= B_r)=p_r $ , is described by a family of distributions  { $\ \mathbb{P}_{\theta}: \theta\in\Theta $ }. Using a maximum likelihood estimation of our parameter $\theta$ , denoted $\theta^{*}$ , and utilizing notation that $\ \mathbb{P}_{\theta} (X= B_j)\equiv p_j(\theta)$ , our claim is that if the $\ p_j(\theta)$ are sufficiently close to the $\ p_j$ for some $\theta\in\Theta$ , then the statistic $$T_C= \sum_{j=1}^r \frac{(\nu_j-np_j(\theta^*))^2}{np_j(\theta^*)}\longrightarrow^d \chi_{r-s-1}^2$$ converges to a Chi Square distribution with $\ (r-s-1)$ degrees of freedom, where $\ s$ refers to the dimension of the parameter set $\Theta$ . In the paper I was reading about this test, which can be accessed here , the degrees of freedom of the Chi Square distribution to which this sum converges is stated without proof. I have already grappled with and understood Pearson's Theorem , which states  that: $$T_S= \sum_{j=1}^r \frac{(\nu_j-np_j)^2}{np_j}\longrightarrow^d \chi_{r-1}^2$$ in the situation where we want to know if our counts follow a specific distribution, rather than any one of a family of distributions. My question is: Is there a simple extension of Pearson's theorem which makes it easy to understand rigorously why the degrees of freedom should be $\ (r-s-1)$ in this new composite hypothesis case? P.S. $\nu_j$ in the above statements refers to the experimentally observed counts of $\ X_i$ that take on the value $\ B_j$ . The likelihood function can therefore be written as $\ \varphi(\theta)= p_1(\theta)^{\nu_1}p_2(\theta)^{\nu_2}...p_r(\theta)^{\nu_r}$ , $\ \theta^*$ maximizing the value of this function on its domain. I have used the same notation as used in the linked paper, in case I've left anything out and also for continuity of discussion. Update: The exact proof I am searching for is mentioned here , but I cannot find the relevant document on MIT's OCW website. Any link to a valid proof would be appreciated.","In a Chi Square GoF Test for Composite Hypotheses, we are interested in whether the distribution of the random variable , which can take on a discrete set of values according to probabilities , ,  ... , , is described by a family of distributions  { }. Using a maximum likelihood estimation of our parameter , denoted , and utilizing notation that , our claim is that if the are sufficiently close to the for some , then the statistic converges to a Chi Square distribution with degrees of freedom, where refers to the dimension of the parameter set . In the paper I was reading about this test, which can be accessed here , the degrees of freedom of the Chi Square distribution to which this sum converges is stated without proof. I have already grappled with and understood Pearson's Theorem , which states  that: in the situation where we want to know if our counts follow a specific distribution, rather than any one of a family of distributions. My question is: Is there a simple extension of Pearson's theorem which makes it easy to understand rigorously why the degrees of freedom should be in this new composite hypothesis case? P.S. in the above statements refers to the experimentally observed counts of that take on the value . The likelihood function can therefore be written as , maximizing the value of this function on its domain. I have used the same notation as used in the linked paper, in case I've left anything out and also for continuity of discussion. Update: The exact proof I am searching for is mentioned here , but I cannot find the relevant document on MIT's OCW website. Any link to a valid proof would be appreciated.","\ X \ B_1 , B_2, ...B_r \ \mathbb{P}(X= B_1)=p_1  \ \mathbb{P}(X = B_2)=p_2  \ \mathbb{P}(X= B_r)=p_r  \ \mathbb{P}_{\theta}: \theta\in\Theta  \theta \theta^{*} \ \mathbb{P}_{\theta} (X= B_j)\equiv p_j(\theta) \ p_j(\theta) \ p_j \theta\in\Theta T_C= \sum_{j=1}^r \frac{(\nu_j-np_j(\theta^*))^2}{np_j(\theta^*)}\longrightarrow^d \chi_{r-s-1}^2 \ (r-s-1) \ s \Theta T_S= \sum_{j=1}^r \frac{(\nu_j-np_j)^2}{np_j}\longrightarrow^d \chi_{r-1}^2 \ (r-s-1) \nu_j \ X_i \ B_j \ \varphi(\theta)= p_1(\theta)^{\nu_1}p_2(\theta)^{\nu_2}...p_r(\theta)^{\nu_r} \ \theta^*","['statistics', 'probability-distributions', 'hypothesis-testing']"
22,Joint Probability Distribution Problem (drawing balls from an urn),Joint Probability Distribution Problem (drawing balls from an urn),,"Suppose that 3 balls are randomly selected from an urn containing 3   red, 4 white, and 5 blue balls. If we let X and Y denote,   respectively, the number of red and white balls chosen, find the joint   probability mass function and probability mass functions for X and Y ,   respectively. I have the PMF for X and Y independently, but I tried checking my joint PMF response on Wolfram and it refuses to return an answer. Can someone verify if my response for the joint PMF is on the right path, or show me a better way. $$f_X(x) = \frac{{3 \choose x}{9 \choose 3-x}}{12 \choose 3} $$ $$F_X(x) = \frac{\sum_{x=0}^n{3 \choose x}{9 \choose 3-x}}{12 \choose 3} $$ $$f_Y(y) = \frac{{4 \choose y}{8 \choose 3-y}}{12 \choose 3}$$ $$F_Y(y) = \frac{\sum_{y=0}^n{4 \choose y}{8 \choose 3-y}}{12 \choose 3} $$ $$f(x, y) = \frac{{3 \choose x}{4 \choose y}{5 \choose 3-x-y}}{12 \choose 3} $$ My general CDF solution: $ j = x + y $ $$\ F(x, y) = \frac{\sum_{j=0}^n\sum_{x=0}^j\sum_{y=0}^{j-x}{3 \choose x}{4 \choose y}{5 \choose 3-x-y}}{12 \choose 3}$$ Without modifying it significantly, I can only find the probability the draw contains n red and/or white balls. There has to be a better, more accurate way of writing this. Looking for a response that can be used to answer a question with conditions such as the following. $$ P(a_1 < X ≤ a_2, b_1 < Y ≤ b_2) $$ Thank you in advance.","Suppose that 3 balls are randomly selected from an urn containing 3   red, 4 white, and 5 blue balls. If we let X and Y denote,   respectively, the number of red and white balls chosen, find the joint   probability mass function and probability mass functions for X and Y ,   respectively. I have the PMF for X and Y independently, but I tried checking my joint PMF response on Wolfram and it refuses to return an answer. Can someone verify if my response for the joint PMF is on the right path, or show me a better way. My general CDF solution: Without modifying it significantly, I can only find the probability the draw contains n red and/or white balls. There has to be a better, more accurate way of writing this. Looking for a response that can be used to answer a question with conditions such as the following. Thank you in advance.","f_X(x) = \frac{{3 \choose x}{9 \choose 3-x}}{12 \choose 3}  F_X(x) = \frac{\sum_{x=0}^n{3 \choose x}{9 \choose 3-x}}{12 \choose 3}  f_Y(y) = \frac{{4 \choose y}{8 \choose 3-y}}{12 \choose 3} F_Y(y) = \frac{\sum_{y=0}^n{4 \choose y}{8 \choose 3-y}}{12 \choose 3}  f(x, y) = \frac{{3 \choose x}{4 \choose y}{5 \choose 3-x-y}}{12 \choose 3}   j = x + y  \ F(x, y) = \frac{\sum_{j=0}^n\sum_{x=0}^j\sum_{y=0}^{j-x}{3 \choose x}{4 \choose y}{5 \choose 3-x-y}}{12 \choose 3}  P(a_1 < X ≤ a_2, b_1 < Y ≤ b_2) ","['probability', 'statistics', 'density-function', 'cumulative-distribution-functions']"
23,"Prove that for Bernoulli distribution, the normal-based CI is shorter than the one given by Hoeffding's inequality","Prove that for Bernoulli distribution, the normal-based CI is shorter than the one given by Hoeffding's inequality",,"This is a result claimed in Example 6.17 of All of Statistics . Basically, we need to prove that: $$ z_{\alpha/2} \sqrt{\frac{\hat p_n (1- \hat p_n)}{n}} < \sqrt{\frac 1 {2n} \log(\frac 2 \alpha)} $$ We can use the inequality $p(1-p) \le \frac 1 4$ and make the substitution that $t=\alpha/2$ . We only need to prove that $$ \sqrt{-2\log t} > z_t $$ The approach I used requires quite a lot of work: Since the CDF of the standard normal distribution $\Phi$ is monotonic, it suffices to prove that (apply $\Phi$ on both sides): $$ \int_0^{\sqrt{-2\log t}} \frac 1 {2\pi}\exp(-\frac{x^2}2)\,\mathrm dx > \frac 1 2 -t $$ Then let $g(t)=\text{LHS}\, - \, \text{RHS}$ and take its derivative. We find that g(t) first increase then decrease. Thus we only need to verify the values it takes at boundary points. After some analysis, we can show that this is always positive. Is there a better way to do this? I've tried the Mill's inequality as well to get bounds of the tail of the normal distribution, but it only works in an interval and you still need to justify the inequality on the interval leftover.","This is a result claimed in Example 6.17 of All of Statistics . Basically, we need to prove that: We can use the inequality and make the substitution that . We only need to prove that The approach I used requires quite a lot of work: Since the CDF of the standard normal distribution is monotonic, it suffices to prove that (apply on both sides): Then let and take its derivative. We find that g(t) first increase then decrease. Thus we only need to verify the values it takes at boundary points. After some analysis, we can show that this is always positive. Is there a better way to do this? I've tried the Mill's inequality as well to get bounds of the tail of the normal distribution, but it only works in an interval and you still need to justify the inequality on the interval leftover.","
z_{\alpha/2} \sqrt{\frac{\hat p_n (1- \hat p_n)}{n}} < \sqrt{\frac 1 {2n} \log(\frac 2 \alpha)}
 p(1-p) \le \frac 1 4 t=\alpha/2 
\sqrt{-2\log t} > z_t
 \Phi \Phi 
\int_0^{\sqrt{-2\log t}} \frac 1 {2\pi}\exp(-\frac{x^2}2)\,\mathrm dx > \frac 1 2 -t
 g(t)=\text{LHS}\, - \, \text{RHS}","['probability', 'statistics', 'inequality', 'distribution-tails']"
24,Why is a skew symmetric matrix called thus?,Why is a skew symmetric matrix called thus?,,The symmetric matrix is a lot like the symmetric curve having skewness 0 in a statistical distribution. Can we somehow relate a skew symmetric matrix with this definition to see why it is called thus?,The symmetric matrix is a lot like the symmetric curve having skewness 0 in a statistical distribution. Can we somehow relate a skew symmetric matrix with this definition to see why it is called thus?,,"['matrices', 'statistics']"
25,Does convergence in distribution imply anything about the KL divergence?,Does convergence in distribution imply anything about the KL divergence?,,"Given that some sequence of random variables $X_n$ converge in distribution to $X$ and assuming that the distribution of all $X_n$ are absolutely continuous with respect to a Lebesgue measure, is there anything that we can say about $KL(p(X_n)|p(X))$ ?","Given that some sequence of random variables converge in distribution to and assuming that the distribution of all are absolutely continuous with respect to a Lebesgue measure, is there anything that we can say about ?",X_n X X_n KL(p(X_n)|p(X)),"['statistics', 'weak-convergence', 'probability-limit-theorems']"
26,Discriminant Analysis: the polynomial kernel of Support Vector Machine,Discriminant Analysis: the polynomial kernel of Support Vector Machine,,"The following 【Quiz】 and 【Official Answer】are the rough translation (with minor modification) of Quiz No.03-1 of the exam of the ""2018's semi-first grade of Japan Statistical Society Certificate (JSSC)"" You can   find the original of this quiz from this URL (But written in Japanese). 【My Question】 How can we derive Equation 2 from Equation 1 ?  What is the relationship between $(1 + \textbf{x}^{T} \textbf{x}')^{4}$ and $(x-3)(x-1)(x+1)(x+3)$ . As a characteristic of data on Fig.1, I recognize the following. All Data near x = -4 are  positive cases All Data near x = -2 are  negative case All Data near x = 0 are  positive cases All Data near x = 2 are  negative case Therefore, I understand that, if there is a function such that positive near x = -4, negative near x = -2 , positive near x = 0, and negative near x = 2 , it can be correctly identified.  And I can understand that the following Equation 2 satisfies the above requirement. However, I cannot imagine the relationship between $(1 + \textbf{x}^{T} \textbf{x}')^{4}$ and $(x-3)(x-1)(x+1)(x+3)$ . I feel, a formula like $ (1+(x,y)\binom{x'}{y'})^4$ will never be a formula like $(x-a)(x-b)(x-c)(x-d)$ 【Quiz】 Two types of data, positive-case (+1) and negative-case (-1), are shown in Fig.1. Fig.1 In order to determine whether each data in FIG.1 are a positive case or a negative case, Support Vector Machines using the polynomial kernel of Equation 1 is performed. Equation 1: $\ \ k(\textbf{x}, \textbf{x}') =  (1 + \textbf{x}^{T} \textbf{x}')^{p} $ Here, $\textbf{x},\textbf{x}' \in {R}^2$ , ${\textbf{x}}^{T} $ is the    transpose vector of ${\textbf{x}} $ , and p  shall be a positive integer. At this time, what is the smallest p that can correctly distinguish all data? Explain why. 【Official Answer】 By using a fourth-order polynomial kernel, the following function of Equation 2 is configured. Equation 2: $\ \ f(x) = sign\{ (x-3)(x-1)(x+1)(x+3)\} $ This function completely discriminates the data. On the other hand, in the polynomial kernel of the third-order or less, since the change of the sign are three times or less, the data in FIG.1 cannot be discriminated. P.S. I'm not very good at English, so I'm sorry if I have some impolite or unclear expressions.","The following 【Quiz】 and 【Official Answer】are the rough translation (with minor modification) of Quiz No.03-1 of the exam of the ""2018's semi-first grade of Japan Statistical Society Certificate (JSSC)"" You can   find the original of this quiz from this URL (But written in Japanese). 【My Question】 How can we derive Equation 2 from Equation 1 ?  What is the relationship between and . As a characteristic of data on Fig.1, I recognize the following. All Data near x = -4 are  positive cases All Data near x = -2 are  negative case All Data near x = 0 are  positive cases All Data near x = 2 are  negative case Therefore, I understand that, if there is a function such that positive near x = -4, negative near x = -2 , positive near x = 0, and negative near x = 2 , it can be correctly identified.  And I can understand that the following Equation 2 satisfies the above requirement. However, I cannot imagine the relationship between and . I feel, a formula like will never be a formula like 【Quiz】 Two types of data, positive-case (+1) and negative-case (-1), are shown in Fig.1. Fig.1 In order to determine whether each data in FIG.1 are a positive case or a negative case, Support Vector Machines using the polynomial kernel of Equation 1 is performed. Equation 1: Here, , is the    transpose vector of , and p  shall be a positive integer. At this time, what is the smallest p that can correctly distinguish all data? Explain why. 【Official Answer】 By using a fourth-order polynomial kernel, the following function of Equation 2 is configured. Equation 2: This function completely discriminates the data. On the other hand, in the polynomial kernel of the third-order or less, since the change of the sign are three times or less, the data in FIG.1 cannot be discriminated. P.S. I'm not very good at English, so I'm sorry if I have some impolite or unclear expressions.","(1 + \textbf{x}^{T} \textbf{x}')^{4} (x-3)(x-1)(x+1)(x+3) (1 + \textbf{x}^{T} \textbf{x}')^{4} (x-3)(x-1)(x+1)(x+3)  (1+(x,y)\binom{x'}{y'})^4 (x-a)(x-b)(x-c)(x-d) \ \ k(\textbf{x}, \textbf{x}') =  (1 + \textbf{x}^{T} \textbf{x}')^{p}  \textbf{x},\textbf{x}' \in {R}^2 {\textbf{x}}^{T}  {\textbf{x}}  \ \ f(x) = sign\{ (x-3)(x-1)(x+1)(x+3)\} ","['statistics', 'polynomials', 'machine-learning', 'discriminant']"
27,expectation of upper quantile proportion,expectation of upper quantile proportion,,"We have a collection $\boldsymbol{S}$ of $n$ discrete random variables $X_1$ , $X_2$ , $\dots$ , $X_n$ $\overset{\small \text{i.i.d.}}{\small \sim}$ $\mathcal{D}$ , where $\mathcal{D}$ is a distribution over $\{1, 2, \ldots, U\} \subset \mathbb{N}$ with cumulative distribution function $F_\mathcal{D}$ . We define the subcollection that includes only the values in $\boldsymbol{S}$ that are above $Q(p)$ , where $Q$ is the quantile function. That is: $$ \boldsymbol{S}_{\geq p} \overset{\small \text{def}}{=} \left\{X : X \in \boldsymbol{S} \text{ and } p\leq F_{\mathcal{D}}(X)\right\} $$ (below we mark $\pmb{\sum}\boldsymbol{C}$ as the sum of all elements in collection $\boldsymbol{C}$ ) We're interested in the quantity $\mathbb{E}\left[\frac{\pmb{\sum}\boldsymbol{S}_{\geq p}}{\pmb{\sum}\boldsymbol{S}}\right]$ , $n \to \infty$ (nicknamed "" upper quantile proportion "") and wish to check if the following inequality holds for some constant $A$ : $$ \tag{1} \mathbb{E}\left[\frac{\pmb{\sum}\boldsymbol{S}_{\geq p}}{\pmb{\sum}\boldsymbol{S}} \right]\overset{\small \text{?}}{\leq} A,\ n \to \infty $$ In practice, we're looking for an appropriate $n$ for a given parameters $0 \leq \delta \leq 1$ , $\frac{1}{2} < p < 1$ . For which the following is correct if $(1)$ is true: $$ P\left[\frac{\pmb{\sum}\boldsymbol{S}_{\geq p}}{\pmb{\sum}\boldsymbol{S}} \geq A\right] < \delta\:\:? $$ Can anyone point me in the right direction with this? thank you! Note (my first steps) : Considering that membership in $\boldsymbol{S}_{\geq p}$ can be viewed as a simple Bernoulli random variable with probability $1 - p$ , we can get the following bound using Hoeffding's inequality with parameter $\varepsilon > 0$ : $$ \Pr \Big(| \boldsymbol{S}_{\geq p}| \geq (1 - p + \varepsilon)n\Big) \leq \mathrm{e}^{-2 \varepsilon^2 n} $$ Therefore for any $\delta > 0$ and $n \geq \ln{\frac{1}{\delta}} / 2\varepsilon^2$ ,  we can bound $\pmb{\sum}\boldsymbol{S}_{\geq p}$ with $1-\delta$ confidence: $$\pmb{\sum}\boldsymbol{S}_{\geq p} \leq \pmb{\sum}\{x : x \in \boldsymbol{S} \land x \geq  \text{$\lfloor(p - \varepsilon)n\rfloor$-th element in $\boldsymbol{S}$}\}     $$ Additionally, it is easy to produce a lower bound on $\pmb{\sum}\boldsymbol{S}$ , so in essence we can check: $$ \frac{\mathbb{E} \pmb{\sum}\boldsymbol{S}_{\geq p}}{\mathbb{E}\pmb{\sum}\boldsymbol{S}} \overset{\small \text{?}}{\leq} A,\ n \to \infty $$ but I'm not sure what this means in relation to $(1)$","We have a collection of discrete random variables , , , , where is a distribution over with cumulative distribution function . We define the subcollection that includes only the values in that are above , where is the quantile function. That is: (below we mark as the sum of all elements in collection ) We're interested in the quantity , (nicknamed "" upper quantile proportion "") and wish to check if the following inequality holds for some constant : In practice, we're looking for an appropriate for a given parameters , . For which the following is correct if is true: Can anyone point me in the right direction with this? thank you! Note (my first steps) : Considering that membership in can be viewed as a simple Bernoulli random variable with probability , we can get the following bound using Hoeffding's inequality with parameter : Therefore for any and ,  we can bound with confidence: Additionally, it is easy to produce a lower bound on , so in essence we can check: but I'm not sure what this means in relation to","\boldsymbol{S} n X_1 X_2 \dots X_n \overset{\small \text{i.i.d.}}{\small \sim} \mathcal{D} \mathcal{D} \{1, 2, \ldots, U\} \subset \mathbb{N} F_\mathcal{D} \boldsymbol{S} Q(p) Q 
\boldsymbol{S}_{\geq p} \overset{\small \text{def}}{=} \left\{X : X \in \boldsymbol{S} \text{ and } p\leq F_{\mathcal{D}}(X)\right\}
 \pmb{\sum}\boldsymbol{C} \boldsymbol{C} \mathbb{E}\left[\frac{\pmb{\sum}\boldsymbol{S}_{\geq p}}{\pmb{\sum}\boldsymbol{S}}\right] n \to \infty A 
\tag{1}
\mathbb{E}\left[\frac{\pmb{\sum}\boldsymbol{S}_{\geq p}}{\pmb{\sum}\boldsymbol{S}} \right]\overset{\small \text{?}}{\leq} A,\ n \to \infty
 n 0 \leq \delta \leq 1 \frac{1}{2} < p < 1 (1) 
P\left[\frac{\pmb{\sum}\boldsymbol{S}_{\geq p}}{\pmb{\sum}\boldsymbol{S}} \geq A\right] < \delta\:\:?
 \boldsymbol{S}_{\geq p} 1 - p \varepsilon > 0 
\Pr \Big(| \boldsymbol{S}_{\geq p}| \geq (1 - p + \varepsilon)n\Big) \leq \mathrm{e}^{-2 \varepsilon^2 n}
 \delta > 0 n \geq \ln{\frac{1}{\delta}} / 2\varepsilon^2 \pmb{\sum}\boldsymbol{S}_{\geq p} 1-\delta \pmb{\sum}\boldsymbol{S}_{\geq p} \leq \pmb{\sum}\{x : x \in \boldsymbol{S} \land x \geq  \text{\lfloor(p - \varepsilon)n\rfloor-th element in \boldsymbol{S}}\}    
 \pmb{\sum}\boldsymbol{S} 
\frac{\mathbb{E} \pmb{\sum}\boldsymbol{S}_{\geq p}}{\mathbb{E}\pmb{\sum}\boldsymbol{S}} \overset{\small \text{?}}{\leq} A,\ n \to \infty
 (1)","['statistics', 'conditional-expectation', 'order-statistics', 'quantile']"
28,Question about confidence intervals for the ratio $\frac{\sigma^2_x}{\sigma^2_y}$,Question about confidence intervals for the ratio,\frac{\sigma^2_x}{\sigma^2_y},"Hello I have already one problem that stipulates: Consider two independent random samples $\mathsf{X_1,X_2,\ldots,X_n}$ and $\mathsf{Y_1,Y_2,\ldots,Y_m}$ from the respective normal distribution $N(\mu_x,\sigma^2_x)$ and $N(\mu_y,\sigma^2_y)$ where the four parameters are unknown. Given $0<\alpha<1$ , the problem asks to find some expressions for the random variables $L$ and $U$ such that $$P\left(L<\frac{\sigma^2_x}{\sigma^2_y}<U\right) = 1-\alpha$$ If someone might check on this my work please: I have that $$ \displaystyle\frac{\frac{\frac{(m-1)S_y^2}{\sigma^2_y}}{(m-1)}}{\frac{\frac{(n-1)S_x^2}{\sigma^2_x}}{(n-1)}}= \frac{\sigma^2_x\,S^2_y}{\sigma^2_y\,S^2_x} \sim F(m-1,n-1)$$ has Fisher distribution with $m-1 \,\text{and}\,n-1$ degrees of freedom where $S^2_x\, \text{and}\,S^2_y$ are the respective sample variances. So, $$P\left(L<\frac{\sigma^2_x}{\sigma^2_y}<U\right) = 1-\alpha$$ $$ P\left(L\frac{S^2_y}{S^2_x}<\frac{\sigma^2_x\,S^2_y}{\sigma^2_y\,S^2_x}<U\frac{S^2_y}{S^2_x}\right) = 1-\alpha$$ $$f_{1-\frac{\alpha}{2}}(m-1,n-1) = L\frac{S^2_y}{S^2_x}\quad \Longrightarrow L = \frac{S^2_x}{S^2_y}\frac{1}{f_{\frac{\alpha}{2}}(n-1,m-1)}$$ and $$f_{\frac{\alpha}{2}}(m-1,n-1) = U\frac{S^2_y}{S^2_x}\quad \Longrightarrow U = \frac{S^2_x}{S^2_y}\,{f_{\frac{\alpha}{2}}(m-1,n-1)}$$ Is this alright? or have I mistakes? please if somebody may help me thank you in advance.","Hello I have already one problem that stipulates: Consider two independent random samples and from the respective normal distribution and where the four parameters are unknown. Given , the problem asks to find some expressions for the random variables and such that If someone might check on this my work please: I have that has Fisher distribution with degrees of freedom where are the respective sample variances. So, and Is this alright? or have I mistakes? please if somebody may help me thank you in advance.","\mathsf{X_1,X_2,\ldots,X_n} \mathsf{Y_1,Y_2,\ldots,Y_m} N(\mu_x,\sigma^2_x) N(\mu_y,\sigma^2_y) 0<\alpha<1 L U P\left(L<\frac{\sigma^2_x}{\sigma^2_y}<U\right) = 1-\alpha  \displaystyle\frac{\frac{\frac{(m-1)S_y^2}{\sigma^2_y}}{(m-1)}}{\frac{\frac{(n-1)S_x^2}{\sigma^2_x}}{(n-1)}}= \frac{\sigma^2_x\,S^2_y}{\sigma^2_y\,S^2_x} \sim F(m-1,n-1) m-1 \,\text{and}\,n-1 S^2_x\, \text{and}\,S^2_y P\left(L<\frac{\sigma^2_x}{\sigma^2_y}<U\right) = 1-\alpha  P\left(L\frac{S^2_y}{S^2_x}<\frac{\sigma^2_x\,S^2_y}{\sigma^2_y\,S^2_x}<U\frac{S^2_y}{S^2_x}\right) = 1-\alpha f_{1-\frac{\alpha}{2}}(m-1,n-1) = L\frac{S^2_y}{S^2_x}\quad \Longrightarrow L = \frac{S^2_x}{S^2_y}\frac{1}{f_{\frac{\alpha}{2}}(n-1,m-1)} f_{\frac{\alpha}{2}}(m-1,n-1) = U\frac{S^2_y}{S^2_x}\quad \Longrightarrow U = \frac{S^2_x}{S^2_y}\,{f_{\frac{\alpha}{2}}(m-1,n-1)}","['statistics', 'probability-distributions', 'parameter-estimation', 'confidence-interval']"
29,Loss of a randomized decision rule,Loss of a randomized decision rule,,"I am looking into the Wikipedia article with the topic Randomised decision rule . In the ""Definition and interpretation"" section, I see the formula of randomized loss: $$L(\theta,d^*)=\int_{A\in\mathcal{A}}d^*(x,A)L(\theta,A)dA$$ where $\mathcal{A}$ is the action space. What bothers me is that the action space can be anything, not necessarily a subset of real numbers, so it does not make senseto integrate with respect to an action. Can anybody help me to make sense out of this? EDIT: After looking into several books, including Lehmann, I'm ashamed to admit that I still not understand the domain, codomain and the (joint?) measurability details of the above.","I am looking into the Wikipedia article with the topic Randomised decision rule . In the ""Definition and interpretation"" section, I see the formula of randomized loss: where is the action space. What bothers me is that the action space can be anything, not necessarily a subset of real numbers, so it does not make senseto integrate with respect to an action. Can anybody help me to make sense out of this? EDIT: After looking into several books, including Lehmann, I'm ashamed to admit that I still not understand the domain, codomain and the (joint?) measurability details of the above.","L(\theta,d^*)=\int_{A\in\mathcal{A}}d^*(x,A)L(\theta,A)dA \mathcal{A}","['probability', 'statistics', 'decision-theory']"
30,What is mathematical statistics (DeGroot vs Hogg)?,What is mathematical statistics (DeGroot vs Hogg)?,,"I’m currently self-studying Ross’ A First Course in Probability, and want to pick up a statistics text as well.  What’s the difference between a Prob/Stats book like DeGroot & Schervish vs. Mathematical Statistics by Hogg/McKean/Craig or the book by Rice? Are they intended for different audiences/courses?  I currently like the level of mathematical rigor in Ross, so I’m looking for something comparable.","I’m currently self-studying Ross’ A First Course in Probability, and want to pick up a statistics text as well.  What’s the difference between a Prob/Stats book like DeGroot & Schervish vs. Mathematical Statistics by Hogg/McKean/Craig or the book by Rice? Are they intended for different audiences/courses?  I currently like the level of mathematical rigor in Ross, so I’m looking for something comparable.",,"['probability', 'statistics', 'reference-request']"
31,Calculate theoretical quantiles with calculator (qq-plot),Calculate theoretical quantiles with calculator (qq-plot),,"Let's say we have the following data: $-1.8, -0.82, 0.3, 1.2, 1.6$ Now I want to make a qq-plot out of it by hand, just with a calculator (Casio fc 991). I start by sorting the values in ranks j and calculate how many observations are less than or equal to $x(j)$ by $j* = \frac{j-0.5}n$ . This brings us following values $j*$ : $0.1, 0.3, 0.5, 0.7, 0.9$ These are my sample quantiles, right? To get my qq-plot I now want to plot these against the theoretical quantiles. But here I stuck. The theoretical quantiles are: $-1.28, -0.52, 0.00, 0.52, 1.28$ But how do I calculate these values without R or any software but just with a calculator? I got the following formula: $(\phi^{-1})(j*)$ but I simply do not understand how I should come up with those values. Cheers and thanks for your effort!","Let's say we have the following data: Now I want to make a qq-plot out of it by hand, just with a calculator (Casio fc 991). I start by sorting the values in ranks j and calculate how many observations are less than or equal to by . This brings us following values : These are my sample quantiles, right? To get my qq-plot I now want to plot these against the theoretical quantiles. But here I stuck. The theoretical quantiles are: But how do I calculate these values without R or any software but just with a calculator? I got the following formula: but I simply do not understand how I should come up with those values. Cheers and thanks for your effort!","-1.8, -0.82, 0.3, 1.2, 1.6 x(j) j* = \frac{j-0.5}n j* 0.1, 0.3, 0.5, 0.7, 0.9 -1.28, -0.52, 0.00, 0.52, 1.28 (\phi^{-1})(j*)","['statistics', 'normal-distribution', 'quantile']"
32,Help me find my mistake for this variance,Help me find my mistake for this variance,,"Suppose X is an observation from a distribution with probability mass function $$X\sim f(x)=\left(\frac{\theta}{2}\right)^{\left | x \right |}(1-\theta)^{1-\left | x \right |} 1_{A}(x)$$ $$0<\theta<1$$ where $$A=\left \{ 1,0,-1 \right.\left.  \right \}$$ Suppose $$T(X)=2 \cdot 1_{B}(x)$$ where $$B=\left \{ 1 \right.\left.  \right \}$$ I am trying to find the variance of T and this is what i did : $$V(T)=E(4 \cdot 1_{B} ^2) - E^2(2 \cdot  1_{B})$$ where i used the fact that $$V(X)=E(X^2)-E^2(X)$$ We can show that $$E(T)=\theta$$ So the variance can now be written as $$V(T)=4[1^2 f(1,\theta) + 0^2  f(0,\theta)] - (\theta)^2$$ Can you spot my mistake?",Suppose X is an observation from a distribution with probability mass function where Suppose where I am trying to find the variance of T and this is what i did : where i used the fact that We can show that So the variance can now be written as Can you spot my mistake?,"X\sim f(x)=\left(\frac{\theta}{2}\right)^{\left | x \right |}(1-\theta)^{1-\left | x \right |} 1_{A}(x) 0<\theta<1 A=\left \{ 1,0,-1 \right.\left.  \right \} T(X)=2 \cdot 1_{B}(x) B=\left \{ 1 \right.\left.  \right \} V(T)=E(4 \cdot 1_{B} ^2) - E^2(2 \cdot  1_{B}) V(X)=E(X^2)-E^2(X) E(T)=\theta V(T)=4[1^2 f(1,\theta) + 0^2  f(0,\theta)] - (\theta)^2","['statistics', 'variance']"
33,Generalized Measure of Central Tendency,Generalized Measure of Central Tendency,,"I was wondering if there is some general notion of central tendency. I had in mind the following axiomatization: A measure of central tendency on a totally ordered set $X$ is a family of functions $\mu_n : X^n \to X$ such that If $a_i \geq b_i$ for all $i \in \{1, \ldots, n\}$ , then $\mu_n(a_1, \ldots, a_n) \geq \mu_n(b_1, \ldots, b_n)$ . If $a_{n+1} \geq \mu_n(a_1, \ldots, a_n)$ , then $\mu_{n + 1} (a_1, \ldots, a_{n + 1}) \geq \mu_n (a_1, \ldots, a_n)$ . The same statement holds with $\geq$ replaced by $\leq$ or $=$ . $\min(a_1, \ldots, a_n) \leq \mu_n(a_1, \ldots, a_n) \leq \max(a_1, \ldots, a_n)$ If $\sigma \in S_n$ , then $\mu_n(a_1, \ldots, a_n) = \mu_n(a_{\sigma(1)}, \ldots, a_{\sigma(n)})$ (the $\mu_n$ are symmetric). It seems like everything we call a measure of central tendency satisfies these axioms. For example, the arithmetic, geometric, and harmonic means; median; and mode (when it is unique) all satisfy these axioms. Based on this, these axioms seem general enough, but are they too general? Do they allow functions which we wouldn't call measures of central tendency? I'm not that invested in the axiomatization I've layed out above. I'm mostly interested in whether or not this sort of thing has been written about. How have others attempted to generalize the notion of ""central tendency?""","I was wondering if there is some general notion of central tendency. I had in mind the following axiomatization: A measure of central tendency on a totally ordered set is a family of functions such that If for all , then . If , then . The same statement holds with replaced by or . If , then (the are symmetric). It seems like everything we call a measure of central tendency satisfies these axioms. For example, the arithmetic, geometric, and harmonic means; median; and mode (when it is unique) all satisfy these axioms. Based on this, these axioms seem general enough, but are they too general? Do they allow functions which we wouldn't call measures of central tendency? I'm not that invested in the axiomatization I've layed out above. I'm mostly interested in whether or not this sort of thing has been written about. How have others attempted to generalize the notion of ""central tendency?""","X \mu_n : X^n \to X a_i \geq b_i i \in \{1, \ldots, n\} \mu_n(a_1, \ldots, a_n) \geq \mu_n(b_1, \ldots, b_n) a_{n+1} \geq \mu_n(a_1, \ldots, a_n) \mu_{n + 1} (a_1, \ldots, a_{n + 1}) \geq \mu_n (a_1, \ldots, a_n) \geq \leq = \min(a_1, \ldots, a_n) \leq \mu_n(a_1, \ldots, a_n) \leq \max(a_1, \ldots, a_n) \sigma \in S_n \mu_n(a_1, \ldots, a_n) = \mu_n(a_{\sigma(1)}, \ldots, a_{\sigma(n)}) \mu_n","['statistics', 'reference-request', 'average']"
34,N-fold sum of random variables,N-fold sum of random variables,,"the topic itself might not be something new, but I don't think this particular problem was posted before. What I am hoping for is advice from somebody who might be more experienced than me on how to tackle the problem I got on my hands. In particular I looking for a solution to the following problem: Find the probability density of $x$ , where $x$ is defined as $x=\sum_{j=1}^{N}{\frac{\cos{\phi_j}}{\sqrt{j}}}$ , when $\phi_j$ are independent uniformly distributed random variables between $0$ and $2\pi$ . I have gotten so far to say that: The probability density of $\cos{\phi_j}$ is given by $\frac{1}{\pi\sqrt{1-x^2}}$ for $-1 < x < 1$ . Then it should follow that the distribution of $\frac{\cos{\phi_j}}{\sqrt{j}}$ is given by $\cos{\phi_j}$ is given by $\frac{1}{\pi\sqrt{1-\frac{x^2}{j}}}$ for $-\frac{1}{\sqrt{j}} < x < \frac{1}{\sqrt{j}}$ . So the last step would be to do an N-fold convolution of the aforementioned distributions. As I mentioned in the beginning, I am hoping for somebody who might know of a similar problem or a trick to simplify this problem. Greets and thank you very much, FB.","the topic itself might not be something new, but I don't think this particular problem was posted before. What I am hoping for is advice from somebody who might be more experienced than me on how to tackle the problem I got on my hands. In particular I looking for a solution to the following problem: Find the probability density of , where is defined as , when are independent uniformly distributed random variables between and . I have gotten so far to say that: The probability density of is given by for . Then it should follow that the distribution of is given by is given by for . So the last step would be to do an N-fold convolution of the aforementioned distributions. As I mentioned in the beginning, I am hoping for somebody who might know of a similar problem or a trick to simplify this problem. Greets and thank you very much, FB.",x x x=\sum_{j=1}^{N}{\frac{\cos{\phi_j}}{\sqrt{j}}} \phi_j 0 2\pi \cos{\phi_j} \frac{1}{\pi\sqrt{1-x^2}} -1 < x < 1 \frac{\cos{\phi_j}}{\sqrt{j}} \cos{\phi_j} \frac{1}{\pi\sqrt{1-\frac{x^2}{j}}} -\frac{1}{\sqrt{j}} < x < \frac{1}{\sqrt{j}},"['statistics', 'probability-distributions', 'convolution']"
35,Are there generalised rules for generating heuristics from data?,Are there generalised rules for generating heuristics from data?,,"Heuristics seems to be more of an art than a science, like a gut-feel supported by data; I might be wrong. Are there algorithms for mathematically generating heuristics from data, like pruning a Bayesian network? Things like the Reichenbach Common Cause principle comes to mind. Is there a branch of mathematics that is specifically applicable here? Maybe a generalised way of expressing discrete data as a function in the way a Taylor series estimates a sine wave? I'll do the reading I just need some pointers. Any help will be appreciated.","Heuristics seems to be more of an art than a science, like a gut-feel supported by data; I might be wrong. Are there algorithms for mathematically generating heuristics from data, like pruning a Bayesian network? Things like the Reichenbach Common Cause principle comes to mind. Is there a branch of mathematics that is specifically applicable here? Maybe a generalised way of expressing discrete data as a function in the way a Taylor series estimates a sine wave? I'll do the reading I just need some pointers. Any help will be appreciated.",,"['statistics', 'probability-distributions', 'statistical-inference']"
36,Simple probability and statistics problem,Simple probability and statistics problem,,"If there are 12 football teams in a league, how many different bets can you make if you bet on 3 first teams and 2 that will get kicked out of the league? The solutions says its (12*11*10*9*8)/2. Why do you divide by two? Is it because the twos that get kicked out, their order doesnt matter so there are half of their variations? What if the bet was on 3 first and 3 that get kicked out?","If there are 12 football teams in a league, how many different bets can you make if you bet on 3 first teams and 2 that will get kicked out of the league? The solutions says its (12*11*10*9*8)/2. Why do you divide by two? Is it because the twos that get kicked out, their order doesnt matter so there are half of their variations? What if the bet was on 3 first and 3 that get kicked out?",,"['probability', 'statistics']"
37,Under what conditions does Jensen's inequality hold with equality?,Under what conditions does Jensen's inequality hold with equality?,,"From what I understand Jensen's Inequality is $$E(f(X))\leq f(E(X)) \;\text{ when $f$ is a concave function}$$ Are there any conditions on the distribution of $X$ (rather than the function f) under which this holds with equality: $E(f(X))=f(E(X))$ ? (eg. when $VAR(X)=0$ , $X$ is a constant so it should hold with equality) Also, is there any term $O$ which would make this true: $E(f(X)) = f(E(x)) + O $ (I was thinking some sort of Taylor Expansion) I am mainly interested in the case $f(x)=ln(x)$","From what I understand Jensen's Inequality is Are there any conditions on the distribution of (rather than the function f) under which this holds with equality: ? (eg. when , is a constant so it should hold with equality) Also, is there any term which would make this true: (I was thinking some sort of Taylor Expansion) I am mainly interested in the case",E(f(X))\leq f(E(X)) \;\text{ when f is a concave function} X E(f(X))=f(E(X)) VAR(X)=0 X O E(f(X)) = f(E(x)) + O  f(x)=ln(x),"['probability', 'statistics', 'inequality']"
38,"Solving $\int_{c_1}^{c_2}dF = \int_{c_1}^{c_2}dG$ for $c_1$, $c_2$","Solving  for ,",\int_{c_1}^{c_2}dF = \int_{c_1}^{c_2}dG c_1 c_2,"Following an exercise in Uniformly Most Powerful tests and the correspoding Neyman–Pearson lemma,    it is possible to show that a certain test exists, where the critical values $c_1$ and $c_2$ can be solved under a certain $\alpha$ using the following system of equations: $$\left\{    \begin{array}{rl} \mathbb{P}(c_1 < \chi^2_{2\lambda} < c_2) = 1 - \alpha \\ \mathbb{P}(c_1 < \chi^2_{2\lambda+2} < c_2) = 1 - \alpha   \end{array} \right.$$ Here $\lambda > 0$ is known. However, I'm not sure how to proceed: in one way, this corresponds to $$\left\{    \begin{array}{rl} F(c_2) - F(c_1) = 1 - \alpha \\ G(c_2) - G(c_1)  = 1 - \alpha   \end{array} \right.$$ where $F$ and $G$ are the CDF's of $\chi^{2}_{2\lambda}$ and $\chi^{2}_{2\lambda+2}$ , but I can't see a way to extract the values using only inverses. On the other hand, this then seems like an integral equation $$\left\{    \begin{array}{rl} \int_{c_1}^{c_2}dF = 1 - \alpha \\ \int_{c_1}^{c_2}dG  = 1 - \alpha   \end{array} \right.$$ but not having much experience with integration, I'm not sure how are such equations usually solved. Any tips or suggestions would be appreciated!","Following an exercise in Uniformly Most Powerful tests and the correspoding Neyman–Pearson lemma,    it is possible to show that a certain test exists, where the critical values and can be solved under a certain using the following system of equations: Here is known. However, I'm not sure how to proceed: in one way, this corresponds to where and are the CDF's of and , but I can't see a way to extract the values using only inverses. On the other hand, this then seems like an integral equation but not having much experience with integration, I'm not sure how are such equations usually solved. Any tips or suggestions would be appreciated!","c_1 c_2 \alpha \left\{  
 \begin{array}{rl}
\mathbb{P}(c_1 < \chi^2_{2\lambda} < c_2) = 1 - \alpha \\
\mathbb{P}(c_1 < \chi^2_{2\lambda+2} < c_2) = 1 - \alpha 
 \end{array} \right. \lambda > 0 \left\{  
 \begin{array}{rl}
F(c_2) - F(c_1) = 1 - \alpha \\
G(c_2) - G(c_1)  = 1 - \alpha 
 \end{array} \right. F G \chi^{2}_{2\lambda} \chi^{2}_{2\lambda+2} \left\{  
 \begin{array}{rl}
\int_{c_1}^{c_2}dF = 1 - \alpha \\
\int_{c_1}^{c_2}dG  = 1 - \alpha 
 \end{array} \right.","['real-analysis', 'calculus', 'statistics', 'systems-of-equations']"
39,Are my calculations of the pregnancy ratio of the population correct?,Are my calculations of the pregnancy ratio of the population correct?,,"So this question is a math question having to do with me calculating the rate of population growth starting from a population of 100,000. I have already gotten the first 3 steps done(sex ratio, ratio of cycle time, and pregnancy ratio after a week among those in the fertile timeframe(calculating the ratio amongst the entire female population which is what I'm after should be relatively easy afterwards). Monthly Cycle numbers Here is the cycle ratio: $2_{early}:2_{fertile}:1_{late}$ And the numbers: $20,000_{early}:20,000_{fertile}:10,000_{late}$ Now, let's divide the early into 2 groups, pre-fertile, and safe and assume there is a 50/50 split between those 2 groups. Let's also assume that all the people in the fertile group are in the late group after a week, all those that are in the late group, are in the safe group after a week and so on. This suggests a cycle length of $4$ but let me verify it. After a week: $10,000_{safe}:10,000_{pre-fertile}:10,000_{fertile}:20,000_{late}$ After 2 weeks: $20,000_{safe}:10,000_{pre-fertile}:10,000_{fertile}: 10,000_{late}$ After 3 weeks: $10,000_{safe}:20,000_{pre-fertile}:10,000_{fertile}:10,000_{late}$ Yep, cycle length of $4$ is confirmed. To get the pregnancy ratio after a month of trying for pregnancy, I need the exact division which is a tad more complicated. Figuring out pregnancy ratio The ratio amongst the people in the fertile window of people who become pregnant is $2:3$ or $40\%$ Anti-miscarriage meds only work at or after 4 weeks has passed. Their effectiveness is $60\%$ at 4 weeks and $70\%$ at 5 weeks. It is 100% effective at 6 weeks. Here are the miscarriage rates: 3 weeks: 30.9% 4 weeks: 35.4% 5 weeks: 26.9% So for the first week, $8,000$ become pregnant and the other $12,000$ in the fertile window go on to be in the late group. Ratio is $8,000_{pregnant}:42,000_{non-pregnant}$ which simplifies to $4:21$ or in terms of percents, $16\%$ of the female population. After a week, another $4,000$ become pregnant. However, 30.9% of those from the starting week have a miscarriage. That is $2472$ people who miscarried, fewer than the number that became pregnant. Now the number is at $9,528$ pregnancies. After another week, another $4,000$ become pregnant. 30.9% of those from the previous week miscarry. On top of that, 40% of the predicted 35.4% miscarry. So that is $1,236 + 783 = 2019$ miscarriages. This is fewer than those that become pregnant so there is an overall increase again. Now $11,509$ people are pregnant After a third week, another $4,000$ become pregnant. 30.9% of those from the previous week, 40% of 35.4% of those that became pregnant the week before last, and 30% of 26.9% of those that became pregnant on the starting week miscarry. This adds up to $1,236 + 566 + 346 = 2,148$ miscarriages. Now $13,361$ people are pregnant. After a fourth week, another $8,800$ become pregnant. At this point, there is no more push to become pregnant so the miscarriage calculations will get simpler from here. Here are the numbers for the miscarriages: $177 + 391 + 1236 = 1804$ miscarriages. Now, this is way less than the number that became pregnant so the total number of pregnancies now is $20,357$ Fifth week: $2,719 + 391 + 192 = 3,302$ miscarriages $17,055$ pregnancies Sixth week: $192 + 861 = 1,053$ miscarriages $16,002$ pregnancies Seventh week: $421$ miscarriages The final number of pregnancies is $15,581$ pregnancies Percentage pregnant is $31.2\%$ which is approximately a $3:10$ ratio Did I do my calculations correctly or did I make a mistake somewhere in the sea of multiplication, addition, and subtraction to calculate the miscarriage and pregnancy numbers week by week? NOTE: My calculations assume no fertility after the miscarriage for several months, no other causes of fetal death besides spontaneous abortion(otherwise known as a miscarriage), and no maternal death while pregnant so despite matching the percent of the population that become pregnant after 1 try very closely, it might not be a realistic percentage for after 2-4 tries. Also, it is only this step, calculating the number of pregnancies that I need you to verify. Caculating how many are twins, etc. I should be able to do fine on my own.","So this question is a math question having to do with me calculating the rate of population growth starting from a population of 100,000. I have already gotten the first 3 steps done(sex ratio, ratio of cycle time, and pregnancy ratio after a week among those in the fertile timeframe(calculating the ratio amongst the entire female population which is what I'm after should be relatively easy afterwards). Monthly Cycle numbers Here is the cycle ratio: And the numbers: Now, let's divide the early into 2 groups, pre-fertile, and safe and assume there is a 50/50 split between those 2 groups. Let's also assume that all the people in the fertile group are in the late group after a week, all those that are in the late group, are in the safe group after a week and so on. This suggests a cycle length of but let me verify it. After a week: After 2 weeks: After 3 weeks: Yep, cycle length of is confirmed. To get the pregnancy ratio after a month of trying for pregnancy, I need the exact division which is a tad more complicated. Figuring out pregnancy ratio The ratio amongst the people in the fertile window of people who become pregnant is or Anti-miscarriage meds only work at or after 4 weeks has passed. Their effectiveness is at 4 weeks and at 5 weeks. It is 100% effective at 6 weeks. Here are the miscarriage rates: 3 weeks: 30.9% 4 weeks: 35.4% 5 weeks: 26.9% So for the first week, become pregnant and the other in the fertile window go on to be in the late group. Ratio is which simplifies to or in terms of percents, of the female population. After a week, another become pregnant. However, 30.9% of those from the starting week have a miscarriage. That is people who miscarried, fewer than the number that became pregnant. Now the number is at pregnancies. After another week, another become pregnant. 30.9% of those from the previous week miscarry. On top of that, 40% of the predicted 35.4% miscarry. So that is miscarriages. This is fewer than those that become pregnant so there is an overall increase again. Now people are pregnant After a third week, another become pregnant. 30.9% of those from the previous week, 40% of 35.4% of those that became pregnant the week before last, and 30% of 26.9% of those that became pregnant on the starting week miscarry. This adds up to miscarriages. Now people are pregnant. After a fourth week, another become pregnant. At this point, there is no more push to become pregnant so the miscarriage calculations will get simpler from here. Here are the numbers for the miscarriages: miscarriages. Now, this is way less than the number that became pregnant so the total number of pregnancies now is Fifth week: miscarriages pregnancies Sixth week: miscarriages pregnancies Seventh week: miscarriages The final number of pregnancies is pregnancies Percentage pregnant is which is approximately a ratio Did I do my calculations correctly or did I make a mistake somewhere in the sea of multiplication, addition, and subtraction to calculate the miscarriage and pregnancy numbers week by week? NOTE: My calculations assume no fertility after the miscarriage for several months, no other causes of fetal death besides spontaneous abortion(otherwise known as a miscarriage), and no maternal death while pregnant so despite matching the percent of the population that become pregnant after 1 try very closely, it might not be a realistic percentage for after 2-4 tries. Also, it is only this step, calculating the number of pregnancies that I need you to verify. Caculating how many are twins, etc. I should be able to do fine on my own.","2_{early}:2_{fertile}:1_{late} 20,000_{early}:20,000_{fertile}:10,000_{late} 4 10,000_{safe}:10,000_{pre-fertile}:10,000_{fertile}:20,000_{late} 20,000_{safe}:10,000_{pre-fertile}:10,000_{fertile}: 10,000_{late} 10,000_{safe}:20,000_{pre-fertile}:10,000_{fertile}:10,000_{late} 4 2:3 40\% 60\% 70\% 8,000 12,000 8,000_{pregnant}:42,000_{non-pregnant} 4:21 16\% 4,000 2472 9,528 4,000 1,236 + 783 = 2019 11,509 4,000 1,236 + 566 + 346 = 2,148 13,361 8,800 177 + 391 + 1236 = 1804 20,357 2,719 + 391 + 192 = 3,302 17,055 192 + 861 = 1,053 16,002 421 15,581 31.2\% 3:10","['statistics', 'ratio']"
40,Emergence of Lognormal distribution for the concentration of chemical compounds,Emergence of Lognormal distribution for the concentration of chemical compounds,,"I'm currently reviewing the literature about lognormal distributions describing/approximating the variability of a given chemical compound across different cells/ samples etc etc. The main argument pro lognormality is the multiplicative central limit theorem, that many authors mention without providing a clear example of a reaction pathway where a targeted concentration can be approximated by the multiplication of many factors. In this article and that they make the case of autocatalytic/ catalytic processes. What would be the simplest example of a chemical reaction system where the concentration of a target chemical (not the rate) would appear Lognormal?","I'm currently reviewing the literature about lognormal distributions describing/approximating the variability of a given chemical compound across different cells/ samples etc etc. The main argument pro lognormality is the multiplicative central limit theorem, that many authors mention without providing a clear example of a reaction pathway where a targeted concentration can be approximated by the multiplication of many factors. In this article and that they make the case of autocatalytic/ catalytic processes. What would be the simplest example of a chemical reaction system where the concentration of a target chemical (not the rate) would appear Lognormal?",,"['statistics', 'probability-distributions', 'reference-request', 'central-limit-theorem']"
41,"Why is this not a valid Variance Covariance matrix, and inherently not positive semi-definite?","Why is this not a valid Variance Covariance matrix, and inherently not positive semi-definite?",,"[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [1,]  1.0 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 [2,] -0.5  1.0 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 [3,] -0.5 -0.5  1.0 -0.5 -0.5 -0.5 -0.5 -0.5 [4,] -0.5 -0.5 -0.5  1.0 -0.5 -0.5 -0.5 -0.5 [5,] -0.5 -0.5 -0.5 -0.5  1.0 -0.5 -0.5 -0.5 [6,] -0.5 -0.5 -0.5 -0.5 -0.5  1.0 -0.5 -0.5 [7,] -0.5 -0.5 -0.5 -0.5 -0.5 -0.5  1.0 -0.5 [8,] -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5  1.0 The reason I know is because this results in a negative eigenvalue, and variance-covariance matrices are positive semi-definite. My thinking here was to have the variances be one, so that the correlations were the covariances, and thus equal -0.5. Is there something with the theory I am missing?  I understand that it is not positive semi-definite and how to show as such, but I am more curious what assumptions this is violating in terms of probability/statistics. I went to generate MVN data with this variance-covariance structure and realized this wasn't positive semi-definite, and then became curious what was inherently wrong with this matrix.","[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [1,]  1.0 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 [2,] -0.5  1.0 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 [3,] -0.5 -0.5  1.0 -0.5 -0.5 -0.5 -0.5 -0.5 [4,] -0.5 -0.5 -0.5  1.0 -0.5 -0.5 -0.5 -0.5 [5,] -0.5 -0.5 -0.5 -0.5  1.0 -0.5 -0.5 -0.5 [6,] -0.5 -0.5 -0.5 -0.5 -0.5  1.0 -0.5 -0.5 [7,] -0.5 -0.5 -0.5 -0.5 -0.5 -0.5  1.0 -0.5 [8,] -0.5 -0.5 -0.5 -0.5 -0.5 -0.5 -0.5  1.0 The reason I know is because this results in a negative eigenvalue, and variance-covariance matrices are positive semi-definite. My thinking here was to have the variances be one, so that the correlations were the covariances, and thus equal -0.5. Is there something with the theory I am missing?  I understand that it is not positive semi-definite and how to show as such, but I am more curious what assumptions this is violating in terms of probability/statistics. I went to generate MVN data with this variance-covariance structure and realized this wasn't positive semi-definite, and then became curious what was inherently wrong with this matrix.",,"['linear-algebra', 'probability', 'statistics', 'normal-distribution']"
42,Average of maximum among order statistic,Average of maximum among order statistic,,"We have G groups. Each group has $M$ (i.i.d) variables $X_{g,1}$ ,..., $X_{g,M}$ following the exponential distribution exp(- $\mu$ ) ( $\mu$ is a constant). Focus on each group g (g=1,...,G), we take the $k$ th ( $k\leq M$ and fixed) order statistic $X_{g,sta}$ , i.e., $X_{g,sta}$ is the $k$ th-smallest value of each group. By taking the maximum of the G order statistics, we get a new varaible $X_{max}$ =max{ $X_{1,sta}, X_{2,sta},..., X_{G,sta}$ }. The question is: how to get the expectation E[ $X_{max}$ ] of $X_{max}$ ?","We have G groups. Each group has (i.i.d) variables ,..., following the exponential distribution exp(- ) ( is a constant). Focus on each group g (g=1,...,G), we take the th ( and fixed) order statistic , i.e., is the th-smallest value of each group. By taking the maximum of the G order statistics, we get a new varaible =max{ }. The question is: how to get the expectation E[ ] of ?","M X_{g,1} X_{g,M} \mu \mu k k\leq M X_{g,sta} X_{g,sta} k X_{max} X_{1,sta}, X_{2,sta},..., X_{G,sta} X_{max} X_{max}","['statistics', 'expected-value', 'order-statistics']"
43,What distribution has the probability generating function $\mathbb E[s^X]=\left(\frac{1-\delta P}{1-sP}\right)^{\frac{1-s}{\delta-s}}$?,What distribution has the probability generating function ?,\mathbb E[s^X]=\left(\frac{1-\delta P}{1-sP}\right)^{\frac{1-s}{\delta-s}},"Is it possible to obtain the probability mass function for the discrete random variable $X$ associated with the following probability generating function? $$ \mathbb E[s^X]=\left(\frac{1-\delta P}{1-sP}\right)^{\frac{1-s}{\delta-s}} $$ In the limit $\delta\to1$ , this is the generating function of the Geometric( $P$ ) distribution, which models the number of successes before the first failure given a success probability $P$ . It would be great to obtain the distribution of $X$ for any $0<\delta<1$ , or at least some sort of asymptotic expansion about $\delta\approx 1$ . Any ideas would be very much appreciated!","Is it possible to obtain the probability mass function for the discrete random variable associated with the following probability generating function? In the limit , this is the generating function of the Geometric( ) distribution, which models the number of successes before the first failure given a success probability . It would be great to obtain the distribution of for any , or at least some sort of asymptotic expansion about . Any ideas would be very much appreciated!","X 
\mathbb E[s^X]=\left(\frac{1-\delta P}{1-sP}\right)^{\frac{1-s}{\delta-s}}
 \delta\to1 P P X 0<\delta<1 \delta\approx 1","['probability', 'statistics', 'probability-distributions', 'generating-functions']"
44,Is it possible to parameterize the model by $\Psi = \frac{1-\theta}{\theta}$ ? Prove your answer,Is it possible to parameterize the model by  ? Prove your answer,\Psi = \frac{1-\theta}{\theta},"A random sample of $6$ observations $(X_1, X_2, \cdots, X_6)$ is generated from a Geometric( $\theta$ ), where $\theta \in (0, 1)$ unknown, but only $T = \sum_{i=1}^{6} X_i$ is observed by the statistician. (a) Describe the statistical model for the observed data ( $T$ ) (b)-(i) Is it possible to parameterize the model by $\Psi = \frac{1-\theta}{\theta}$ ? Prove your answer (b)-(ii) Is it possible to parameterize the model by $\Psi = \theta(1-\theta)$ ? Prove your answer My attempt: (a) Since geometric is iid with Negative Binomial Each $X_i$ ~ $\mathrm{Geometric}(\theta)$ therefore $T = \sum_{i=1}^{6}$ ~ $\mathrm{NegativeBinomial}(r, \theta)$ where $\theta \in (0, 1)$ unknown. The probability function for T is given by $$f_{\theta}(t) = {t +r-1\choose t}(1-\theta)^t \theta^r$$ for $t = 0,1, \cdots, 6$ parameter is $\theta$ and parameter space is $[0,1]$ (b)-(i) and (b)-(ii) I'm not sure how to do. Would I just show they are one to one by graphing each of them? Not sure","A random sample of observations is generated from a Geometric( ), where unknown, but only is observed by the statistician. (a) Describe the statistical model for the observed data ( ) (b)-(i) Is it possible to parameterize the model by ? Prove your answer (b)-(ii) Is it possible to parameterize the model by ? Prove your answer My attempt: (a) Since geometric is iid with Negative Binomial Each ~ therefore ~ where unknown. The probability function for T is given by for parameter is and parameter space is (b)-(i) and (b)-(ii) I'm not sure how to do. Would I just show they are one to one by graphing each of them? Not sure","6 (X_1, X_2, \cdots, X_6) \theta \theta \in (0, 1) T = \sum_{i=1}^{6} X_i T \Psi = \frac{1-\theta}{\theta} \Psi = \theta(1-\theta) X_i \mathrm{Geometric}(\theta) T = \sum_{i=1}^{6} \mathrm{NegativeBinomial}(r, \theta) \theta \in (0, 1) f_{\theta}(t) = {t +r-1\choose t}(1-\theta)^t \theta^r t = 0,1, \cdots, 6 \theta [0,1]","['probability', 'statistics']"
45,Show $ \sum_1^n (x_i-\bar{x})^2 = \sum_1^{n-1} (x_i -\bar{x}^*)^2+\frac n{n-1}(x_n-\bar{x})^2 $,Show, \sum_1^n (x_i-\bar{x})^2 = \sum_1^{n-1} (x_i -\bar{x}^*)^2+\frac n{n-1}(x_n-\bar{x})^2 ,"Let $x_1,...,x_n$ be a random sample from some population with $n\geq3$ and with at most $n-2$ sample points being equal. How can one show $$ \sum_1^n (x_i-\bar{x})^2 = \sum_1^{n-1} (x_i -\bar{x}^*)^2+\frac n{n-1}(x_n-\bar{x})^2, $$ where $ \bar{x}=\frac1n\sum_1^nx_i$ and $ \bar{x}^* = \frac 1{n-1} \sum_1^{n-1} x_i.$ This is a useful identity since it would allow me to have an upper bound on the deviation of $x_i$ from the mean. That is $$ \max_{1\leq i \leq n} | x_i - \bar{x}| < \frac {n-1} {\sqrt{n}} S, $$ where $ S^2 = \frac 1 {n-1} \sum_1^n (x_i - \bar{x})^2.$ Thank you very much for your help. Source of the question A Matrix Formulation on How Deviant an Observation Can Be Author: Ingram Olkin. Source: The American Statistician, Vol. 46, No. 3 (Aug., 1992), pp. 205-209 https://www.jstor.org/stable/2685215 I will add shortly what I've tried so far.","Let be a random sample from some population with and with at most sample points being equal. How can one show where and This is a useful identity since it would allow me to have an upper bound on the deviation of from the mean. That is where Thank you very much for your help. Source of the question A Matrix Formulation on How Deviant an Observation Can Be Author: Ingram Olkin. Source: The American Statistician, Vol. 46, No. 3 (Aug., 1992), pp. 205-209 https://www.jstor.org/stable/2685215 I will add shortly what I've tried so far.","x_1,...,x_n n\geq3 n-2  \sum_1^n (x_i-\bar{x})^2 = \sum_1^{n-1} (x_i -\bar{x}^*)^2+\frac n{n-1}(x_n-\bar{x})^2,   \bar{x}=\frac1n\sum_1^nx_i  \bar{x}^* = \frac 1{n-1} \sum_1^{n-1} x_i. x_i  \max_{1\leq i \leq n} | x_i - \bar{x}| < \frac {n-1} {\sqrt{n}} S,   S^2 = \frac 1 {n-1} \sum_1^n (x_i - \bar{x})^2.",['statistics']
46,How to implement an insurance risk model,How to implement an insurance risk model,,"So the problem goes as follows: ""Suppose that the different policyholders of a casualty insurance company generate claims according to independent Poisson processes with a common rate $λ$ , and that each claim amount has distribution $F$ . Suppose also that new customers sign up according to a Poisson process with rate $ν$ , and that each existing policyholder remains with the company for an exponentially distributed time with rate $μ$ . Finally, suppose that each policyholder pays the insurance firm at a fixed rate $c$ per unit time. Starting with $n_{0}$ customers and initial capital $a_{0} \geq 0$ , we are interested in using simulation to estimate the probability that the firm’s capital is always nonnegative at all times up to time T ."" Well to simulate the preceding, we define the variables and events as follows: Time Variable : $t$ System State Variable : $(n, a)$ , where $n$ is the number of policyholders and $a$ is the firm’s current capital. Events : There are three types of events: a new policyholder, a lost policyholder, and a claim. The event list consists of a single value, equal to the time at which the next event occurs. EL : $t_{E}$ We are able to have the event list consist solely of the time of the next event because of results about exponential random variables. Specifically, if $(n, a)$ is the system state at time t then, because the minimum of independent exponential random variables is also exponential, the time at which the next event occurs will equal $t + X$ , where $X$ is an exponential random variable with rate $ν +nμ+nλ$ . Moreover, no matter when this next event occurs, it will result from A new policyholder, with probability $\frac{v}{ν +nμ+nλ}$ A lost policyholder, with probability $\frac{nμ}{ν +nμ+nλ}$ A claim, with probability $\frac{nλ}{ν +nμ+nλ}$ After determining when the next event occurs, we generate a random number to determine which of the three possibilities caused the event, and then use this information to determine the new value of the system state variable. In the following, for given state variable $(n, a)$ , $X$ will be an exponential random variable with rate $ν + nμ + nλ$ ; $J$ will be a random variable equal to $1$ with probability $\frac{v}{ν +nμ+nλ}$ , to $2$ with probability $\frac{nμ}{ν +nμ+nλ}$ , or to $3$ with probability $\frac{nλ}{ν +nμ+nλ}$ ; $Y$ will be a random variable having the claim distribution F. Output Variable : $I$ , where $I=1$ , if the firm’s capital is nonnegative throughout $[0,t]$ $I=0$ , otherwise Thinking of the algorithm it will look something like this: Initialize First initialize t = 0, a = a0, n = n0 then generate X and initialize t_E = X To update the system we move along to the next event, first checking whether it takes us past time T . Update Step Case 1: t_e > T : Set I = 1 and end this run. Case 2: t_e <= T : Reset a = a + nc(t_e − t) and t = t_e Generate $J$ : If J = 1 : reset n = n + 1 then if J = 2 : reset n = n − 1 then if J = 3 : Generate $Y$ . if Y > a , set I = 0 and end this run; otherwise reset a = a − Y Generate $X$ : reset t_e = t + X The update step is then continually repeated until a run is completed. So far I think this could work, but since I'm not closely familiar with actuarial science (and insurance companies in general) my questions are: What values for $a_{0}$ and $n_{0}$ are the most suitable (realistic) for this model in actuarial science? What distributions $F$ for my $Y$ RV  are common and uncommon in this field? What range and in wich units of time $[0,t]$ are generally used to test models like this? My goal is to simulate this model on python and compare if changing the distributions or rates around could determine whether this company go bankruptcy or stays with a nonnegative capital over a defined time. PS: Please let me know what else should be taking in cosideration. Is this is just a trial and error problem (change values, variables, distribution, etc to look for a change in the end result)?.","So the problem goes as follows: ""Suppose that the different policyholders of a casualty insurance company generate claims according to independent Poisson processes with a common rate , and that each claim amount has distribution . Suppose also that new customers sign up according to a Poisson process with rate , and that each existing policyholder remains with the company for an exponentially distributed time with rate . Finally, suppose that each policyholder pays the insurance firm at a fixed rate per unit time. Starting with customers and initial capital , we are interested in using simulation to estimate the probability that the firm’s capital is always nonnegative at all times up to time T ."" Well to simulate the preceding, we define the variables and events as follows: Time Variable : System State Variable : , where is the number of policyholders and is the firm’s current capital. Events : There are three types of events: a new policyholder, a lost policyholder, and a claim. The event list consists of a single value, equal to the time at which the next event occurs. EL : We are able to have the event list consist solely of the time of the next event because of results about exponential random variables. Specifically, if is the system state at time t then, because the minimum of independent exponential random variables is also exponential, the time at which the next event occurs will equal , where is an exponential random variable with rate . Moreover, no matter when this next event occurs, it will result from A new policyholder, with probability A lost policyholder, with probability A claim, with probability After determining when the next event occurs, we generate a random number to determine which of the three possibilities caused the event, and then use this information to determine the new value of the system state variable. In the following, for given state variable , will be an exponential random variable with rate ; will be a random variable equal to with probability , to with probability , or to with probability ; will be a random variable having the claim distribution F. Output Variable : , where , if the firm’s capital is nonnegative throughout , otherwise Thinking of the algorithm it will look something like this: Initialize First initialize t = 0, a = a0, n = n0 then generate X and initialize t_E = X To update the system we move along to the next event, first checking whether it takes us past time T . Update Step Case 1: t_e > T : Set I = 1 and end this run. Case 2: t_e <= T : Reset a = a + nc(t_e − t) and t = t_e Generate : If J = 1 : reset n = n + 1 then if J = 2 : reset n = n − 1 then if J = 3 : Generate . if Y > a , set I = 0 and end this run; otherwise reset a = a − Y Generate : reset t_e = t + X The update step is then continually repeated until a run is completed. So far I think this could work, but since I'm not closely familiar with actuarial science (and insurance companies in general) my questions are: What values for and are the most suitable (realistic) for this model in actuarial science? What distributions for my RV  are common and uncommon in this field? What range and in wich units of time are generally used to test models like this? My goal is to simulate this model on python and compare if changing the distributions or rates around could determine whether this company go bankruptcy or stays with a nonnegative capital over a defined time. PS: Please let me know what else should be taking in cosideration. Is this is just a trial and error problem (change values, variables, distribution, etc to look for a change in the end result)?.","λ F ν μ c n_{0} a_{0} \geq 0 t (n, a) n a t_{E} (n, a) t + X X ν +nμ+nλ \frac{v}{ν +nμ+nλ} \frac{nμ}{ν +nμ+nλ} \frac{nλ}{ν +nμ+nλ} (n, a) X ν + nμ + nλ J 1 \frac{v}{ν +nμ+nλ} 2 \frac{nμ}{ν +nμ+nλ} 3 \frac{nλ}{ν +nμ+nλ} Y I I=1 [0,t] I=0 J Y X a_{0} n_{0} F Y [0,t]","['statistics', 'simulation', 'actuarial-science']"
47,Linear Discriminant Analysis: Meaning of Negative Eigenvalues?,Linear Discriminant Analysis: Meaning of Negative Eigenvalues?,,"In Linear Discriminant Analysis (LDA) we compute two matrices from the data: the between scatter matrix $\boldsymbol{S}_b$ and within scatter matrix $\boldsymbol{S}_w$ . A direction $\boldsymbol{w}$ is then considered more discriminative if $(\boldsymbol{w}^T \boldsymbol{S}_b \boldsymbol{w})/(\boldsymbol{w}^T \boldsymbol{S}_w \boldsymbol{w})$ is larger. Therefore, the most $k$ discriminative directions correspond to the top $k$ eigenvectors of the matrix $\boldsymbol{S}_b \boldsymbol{S}_w^{-1}$ . While the two scatter matrices $\boldsymbol{S}_b$ and $\boldsymbol{S}_w$ are positive semi-definite, the matrix $\boldsymbol{S}_b \boldsymbol{S}_w^{-1}$ does not have to be. So I wonder what is the meaning/intuition of negative eigenvalues in this case? This question arose when I wanted to choose the number $k$ based on what percentage of discriminative information is preserved by the top $k$ eigenvectors. For example, in case of PCA, I could say I want to pick the top $k$ eigenvectors that maintain $90\%$ of the variance, i.e. $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^n \lambda_j) \approx 0.9$ ( $n$ being the total number of eigenvalues). However, if negative eigenvalues can exist in LDA, how should I modify the PCA idea to achieve similar goal? Should I use $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^n \lambda_j) \approx 0.9$ , or $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^{n^+} \lambda_j) \approx 0.9$ ( $n^+$ meaning sum over nonnegative eigenvalues only), or $(\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^{n} |\lambda_j|) \approx 0.9$ , or none of these? Thanks Golabi","In Linear Discriminant Analysis (LDA) we compute two matrices from the data: the between scatter matrix and within scatter matrix . A direction is then considered more discriminative if is larger. Therefore, the most discriminative directions correspond to the top eigenvectors of the matrix . While the two scatter matrices and are positive semi-definite, the matrix does not have to be. So I wonder what is the meaning/intuition of negative eigenvalues in this case? This question arose when I wanted to choose the number based on what percentage of discriminative information is preserved by the top eigenvectors. For example, in case of PCA, I could say I want to pick the top eigenvectors that maintain of the variance, i.e. ( being the total number of eigenvalues). However, if negative eigenvalues can exist in LDA, how should I modify the PCA idea to achieve similar goal? Should I use , or ( meaning sum over nonnegative eigenvalues only), or , or none of these? Thanks Golabi",\boldsymbol{S}_b \boldsymbol{S}_w \boldsymbol{w} (\boldsymbol{w}^T \boldsymbol{S}_b \boldsymbol{w})/(\boldsymbol{w}^T \boldsymbol{S}_w \boldsymbol{w}) k k \boldsymbol{S}_b \boldsymbol{S}_w^{-1} \boldsymbol{S}_b \boldsymbol{S}_w \boldsymbol{S}_b \boldsymbol{S}_w^{-1} k k k 90\% (\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^n \lambda_j) \approx 0.9 n (\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^n \lambda_j) \approx 0.9 (\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^{n^+} \lambda_j) \approx 0.9 n^+ (\sum_{j=1}^k \lambda_j)/(\sum_{j=1}^{n} |\lambda_j|) \approx 0.9,"['statistics', 'machine-learning']"
48,"prove $\lim \limits_{n \to \infty}{\frac{W_n\sqrt{n}}{(n-1)\sqrt{2}}} \sim N_{(0,1)}$",prove,"\lim \limits_{n \to \infty}{\frac{W_n\sqrt{n}}{(n-1)\sqrt{2}}} \sim N_{(0,1)}","I searched the internet alot . The only relevant clue is in Wikipedia: F-distribution Beside that I didn't find any proof for this theory. If $Y$ has $B\left(\frac{d_1}{2}, \frac{d_2}{2}\right)$ distribution, then show that $X$ with given formula has $F\left(d_1,d_2\right)$ distribution. $$X = \frac{d_2Y}{d_1\left(1-Y\right)}$$ I tried this but I can't do anything because of $\Gamma{}$ integral: $$Y = \frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}$$ so: $$X = \frac{d_2Y}{d_1\left(1-Y\right)}$$ $$X = \frac{d_2\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\left(1-\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}\right)}$$ $$X = x^{\frac{d_1}{2} - 1}\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}\left(\frac{d_2\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right) - \Gamma\left({\frac{d_1 + d_2}{2}}\right)x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}\right)$$ compare it to $F\left(d_1,d_2\right)$ : $$F\left(d_1,d_2\right)=x^{\frac{d_1}{2} - 1}\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}\left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}-1}\frac{1}{\left(1+\frac{d_1}{d_2}x\right)^{\frac{d_1+d_2}{2}}}$$ so: $$\left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}-1}\frac{1}{\left(1+\frac{d_1}{d_2}x\right)^{\frac{d_1+d_2}{2}}} = \left(\frac{d_2\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right) - \Gamma\left({\frac{d_1 + d_2}{2}}\right)x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}\right)$$ I can't go on anymore because of $\Gamma$ integral! If possible, give me a hint to prove this. Any help will be appreciated.","I searched the internet alot . The only relevant clue is in Wikipedia: F-distribution Beside that I didn't find any proof for this theory. If has distribution, then show that with given formula has distribution. I tried this but I can't do anything because of integral: so: compare it to : so: I can't go on anymore because of integral! If possible, give me a hint to prove this. Any help will be appreciated.","Y B\left(\frac{d_1}{2}, \frac{d_2}{2}\right) X F\left(d_1,d_2\right) X = \frac{d_2Y}{d_1\left(1-Y\right)} \Gamma{} Y = \frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1} X = \frac{d_2Y}{d_1\left(1-Y\right)} X = \frac{d_2\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\left(1-\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}\right)} X = x^{\frac{d_1}{2} - 1}\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}\left(\frac{d_2\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right) - \Gamma\left({\frac{d_1 + d_2}{2}}\right)x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}\right) F\left(d_1,d_2\right) F\left(d_1,d_2\right)=x^{\frac{d_1}{2} - 1}\frac{\Gamma\left({\frac{d_1 + d_2}{2}}\right)}{\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)}\left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}-1}\frac{1}{\left(1+\frac{d_1}{d_2}x\right)^{\frac{d_1+d_2}{2}}} \left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}-1}\frac{1}{\left(1+\frac{d_1}{d_2}x\right)^{\frac{d_1+d_2}{2}}} = \left(\frac{d_2\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right)\left(1-x\right)^{\frac{d_2}{2}-1}}{d_1\Gamma\left(\frac{d_1}{2}\right)\Gamma\left(\frac{d_2}{2}\right) - \Gamma\left({\frac{d_1 + d_2}{2}}\right)x^{\frac{d_1}{2} - 1}\left(1-x\right)^{\frac{d_2}{2}-1}}\right) \Gamma",['statistics']
49,$\sum_i X_i^2$ has $\chi^2_{n}$ distribution and $X_i$ i.i.d. imply $X_i$ normal,has  distribution and  i.i.d. imply  normal,\sum_i X_i^2 \chi^2_{n} X_i X_i,"Let $X_1,\ldots,X_n$ be i.i.d. random variables with distribution $F$ . It is known that if $F$ is the standard normal distribution then $$ S:=\sum_{i=1}^n X_i^2 $$ has a chi square distribution with $n$ degrees of freedom. I remeber that the converse is an open problem: if $S$ has a chi square distribution with $n$ degrees of freedom then $F$ has to be the standard normal. Do you have some references on this problem? (I remember that some instances has been solved, but I couldn't find them anymore)","Let be i.i.d. random variables with distribution . It is known that if is the standard normal distribution then has a chi square distribution with degrees of freedom. I remeber that the converse is an open problem: if has a chi square distribution with degrees of freedom then has to be the standard normal. Do you have some references on this problem? (I remember that some instances has been solved, but I couldn't find them anymore)","X_1,\ldots,X_n F F 
S:=\sum_{i=1}^n X_i^2
 n S n F","['statistics', 'probability-distributions', 'reference-request', 'conjectures']"
50,"Compute conditional expectations of X,Y iid given the generated sigma algebra of $Z=\mathbf{1}_{\{X+Y=0\}}$","Compute conditional expectations of X,Y iid given the generated sigma algebra of",Z=\mathbf{1}_{\{X+Y=0\}},"Let X, Y be idependent, identically distributed random variables with $${P}(X=1) = {P}(Y=1) = p$$ $${P}(X=-1) = {P}(Y=-1) = 1-p$$ and set $$Z=\mathbf{1}_{\{X+Y=0\}}$$ $$\mathcal{G} = \sigma(Z)$$ Compute $\mathbb{E}[X|\mathcal{G}]$ and $\mathbb{E}[Y|\mathcal{G}]$ . Are these random variables still independent? I am confused because, I dont know on which space X and Y are on. Also because all examples I have seen just use a random variable as condition, now it is the generated sigma algebra of a RV and I dont know what $\mathbb{E}[-|\mathcal{G}]$ really means and how I can compute it.","Let X, Y be idependent, identically distributed random variables with and set Compute and . Are these random variables still independent? I am confused because, I dont know on which space X and Y are on. Also because all examples I have seen just use a random variable as condition, now it is the generated sigma algebra of a RV and I dont know what really means and how I can compute it.",{P}(X=1) = {P}(Y=1) = p {P}(X=-1) = {P}(Y=-1) = 1-p Z=\mathbf{1}_{\{X+Y=0\}} \mathcal{G} = \sigma(Z) \mathbb{E}[X|\mathcal{G}] \mathbb{E}[Y|\mathcal{G}] \mathbb{E}[-|\mathcal{G}],"['probability', 'statistics', 'conditional-expectation']"
51,Does a data-dependent sampling rule induce correlation?,Does a data-dependent sampling rule induce correlation?,,"I'm struggling to understand whether a data stream sliced up in a certain way could produce two quantities that are dependent but uncorrelated. Suppose I have two iid streams of data that are independent of each other: $X = (X_1, X_2, \ldots)$ and $Y = (Y_1, Y_2, \ldots)$ . I want to estimate the difference in means between the two groups. Between the two streams, I want to sample a total of $n$ points. For notation's sake, say I'm sampling one point per unit of time for $T$ total time units. Now consider the following sampling scheme which divides up the $T$ time period into two halves: Up until time $t = T/2$ , sample from $X$ and $Y$ with equal probability. From $t = (T/2+1)$ until $T$ , sample from $X$ with probability $p$ and from $Y$ with probability $1-p$ , where $p$ is some function of the data I observed in the first half and also $p \in (0,1)$ . Now consider $\hat{\theta}_1 := \bar{X}_1 - \bar{Y}_1$ , the difference in sample means calculated from only the data collected up until time $t=T/2$ and $\hat{\theta}_2 := \bar{X}_2 - \bar{Y}_2$ calculated from only the data collected from time $t=(T/2+1)$ to $t=T$ . Question: Without knowing more about how $p$ depends on the data in the first half, can we tell whether $\hat{\theta}_1$ and $\hat{\theta}_2$ are correlated ? Obviously, $\hat{\theta}_1$ and $\hat{\theta}_2$ are not independent, but nevertheless I thought they would be uncorrelated. My reasoning was that the dependence of $p$ only affects the allocation between $X$ and $Y$ , and doesn't introduce any bias as far as the expected value of $\bar{X} - \bar{Y}$ . I feel like I oversimplified this, but I'm a bit stuck as to how to work this out rigorously. EDIT: As an answer below pointed out, this problem may be more interesting if we restrict $p \in (0,1)$ . Or to put it another way, if we require $\bar{X}_1, \bar{X}_2, \bar{Y}_1$ and $\bar{Y}_2$ to all have nonzero probability of containing points. Edit made above.","I'm struggling to understand whether a data stream sliced up in a certain way could produce two quantities that are dependent but uncorrelated. Suppose I have two iid streams of data that are independent of each other: and . I want to estimate the difference in means between the two groups. Between the two streams, I want to sample a total of points. For notation's sake, say I'm sampling one point per unit of time for total time units. Now consider the following sampling scheme which divides up the time period into two halves: Up until time , sample from and with equal probability. From until , sample from with probability and from with probability , where is some function of the data I observed in the first half and also . Now consider , the difference in sample means calculated from only the data collected up until time and calculated from only the data collected from time to . Question: Without knowing more about how depends on the data in the first half, can we tell whether and are correlated ? Obviously, and are not independent, but nevertheless I thought they would be uncorrelated. My reasoning was that the dependence of only affects the allocation between and , and doesn't introduce any bias as far as the expected value of . I feel like I oversimplified this, but I'm a bit stuck as to how to work this out rigorously. EDIT: As an answer below pointed out, this problem may be more interesting if we restrict . Or to put it another way, if we require and to all have nonzero probability of containing points. Edit made above.","X = (X_1, X_2, \ldots) Y = (Y_1, Y_2, \ldots) n T T t = T/2 X Y t = (T/2+1) T X p Y 1-p p p \in (0,1) \hat{\theta}_1 := \bar{X}_1 - \bar{Y}_1 t=T/2 \hat{\theta}_2 := \bar{X}_2 - \bar{Y}_2 t=(T/2+1) t=T p \hat{\theta}_1 \hat{\theta}_2 \hat{\theta}_1 \hat{\theta}_2 p X Y \bar{X} - \bar{Y} p \in (0,1) \bar{X}_1, \bar{X}_2, \bar{Y}_1 \bar{Y}_2","['probability', 'statistics', 'independence', 'sampling']"
52,Method of moments exponential distribution,Method of moments exponential distribution,,"Find the method of moments estimate for $\lambda$ if a random sample of size $n$ is taken from the exponential pdf, $$f_Y(y_i;\lambda)= \lambda e^{-\lambda y} \;, \quad y \ge 0$$ $$E[Y] = \int_{0}^{\infty}y\lambda e^{-y}dy  \\ = \lambda \int_{0}^{\infty}ye^{-\lambda y} dy \\ = -y\frac{e^{-\lambda y}}{\lambda}\bigg\rvert_{0}^{\infty} - \int_{0}^{\infty}e^{-\lambda y}dy \\ =\bigg[\frac{e^{-\lambda y}}{\lambda}\bigg]\bigg\rvert_{0}^{\infty} \\ E[Y] =  \frac{1}{\lambda} \\ $$ Now solve for $\bar{y}$ $$E[Y] = \frac{1}{n}\sum_\limits{i=1}^{n} y_i \\ \bar{y} = \frac{1}{\lambda} \\ \lambda = \frac{1}{\bar{y}} $$ Implies that $\hat{\lambda}=\frac{1}{\bar{y}}$ Did I get this one? I have not got the answer for this one in the book.","Find the method of moments estimate for if a random sample of size is taken from the exponential pdf, Now solve for Implies that Did I get this one? I have not got the answer for this one in the book.","\lambda n f_Y(y_i;\lambda)= \lambda e^{-\lambda y} \;, \quad y \ge 0 E[Y] = \int_{0}^{\infty}y\lambda e^{-y}dy  \\
= \lambda \int_{0}^{\infty}ye^{-\lambda y} dy \\
= -y\frac{e^{-\lambda y}}{\lambda}\bigg\rvert_{0}^{\infty} - \int_{0}^{\infty}e^{-\lambda y}dy \\
=\bigg[\frac{e^{-\lambda y}}{\lambda}\bigg]\bigg\rvert_{0}^{\infty} \\
E[Y] =  \frac{1}{\lambda} \\
 \bar{y} E[Y] = \frac{1}{n}\sum_\limits{i=1}^{n} y_i \\
\bar{y} = \frac{1}{\lambda} \\
\lambda = \frac{1}{\bar{y}}  \hat{\lambda}=\frac{1}{\bar{y}}","['statistics', 'exponential-distribution']"
53,Convolution of independent standard normal random variables,Convolution of independent standard normal random variables,,"Let $X$ and $Y$ be two independent random variables, each with the standard   normal density. Compute $f_{X+Y} (a)$. The solution uses a convolution of the form $$f_{X+Y}(a)= {1\over 2\pi} \int_{-\infty}^{\infty} e^{-{(a-y)^2}\over2}e^{-{y^2}\over2} \ dy$$ I am wondering why the bounds are $\infty$ and not $a$ and $0$ such as I found in another problem- Let $X$ and $Y$ be two independent exponential random variables with common parameter $λ$. Compute $f_{X+Y} (a)$ , where the solution uses $f_{X+Y}(a)= \int_{0}^{a} λe^{-λ(a-y)}λe^{-λy}\ dy$ Why are the bounds $\infty$ when the sum of $X$ and $Y$ is no more than $a$? Is this something special about the standard normal variable?","Let $X$ and $Y$ be two independent random variables, each with the standard   normal density. Compute $f_{X+Y} (a)$. The solution uses a convolution of the form $$f_{X+Y}(a)= {1\over 2\pi} \int_{-\infty}^{\infty} e^{-{(a-y)^2}\over2}e^{-{y^2}\over2} \ dy$$ I am wondering why the bounds are $\infty$ and not $a$ and $0$ such as I found in another problem- Let $X$ and $Y$ be two independent exponential random variables with common parameter $λ$. Compute $f_{X+Y} (a)$ , where the solution uses $f_{X+Y}(a)= \int_{0}^{a} λe^{-λ(a-y)}λe^{-λy}\ dy$ Why are the bounds $\infty$ when the sum of $X$ and $Y$ is no more than $a$? Is this something special about the standard normal variable?",,"['probability', 'statistics', 'probability-distributions']"
54,Condition number of $AA^T$ when $A$ is polynomial Vandermonde,Condition number of  when  is polynomial Vandermonde,AA^T A,"Suppose I'm doing polynomial regression of degree $m$ $$p(x, \mathbf{w}) = w_0 + w_1x + \dotsb + w_mx^m$$ given training data $(x_1, t_1), \dotsc, (x_N, t_N)$. Suppose I'm using the loss function $$L(\mathbf{w}) = \frac12 \sum_{j=1}^N \big( p(x_j, \mathbf{w}) - t_j \big)^2$$ The Hessian of the loss function is $AA^T$, where $A_{ij} = {x_{(i)}}^{j-1}$. What can be said about the eigenvalues of the positive definite matrix $AA^T$, as we vary which $x_{i}$ we choose? Specifically its condition number?","Suppose I'm doing polynomial regression of degree $m$ $$p(x, \mathbf{w}) = w_0 + w_1x + \dotsb + w_mx^m$$ given training data $(x_1, t_1), \dotsc, (x_N, t_N)$. Suppose I'm using the loss function $$L(\mathbf{w}) = \frac12 \sum_{j=1}^N \big( p(x_j, \mathbf{w}) - t_j \big)^2$$ The Hessian of the loss function is $AA^T$, where $A_{ij} = {x_{(i)}}^{j-1}$. What can be said about the eigenvalues of the positive definite matrix $AA^T$, as we vary which $x_{i}$ we choose? Specifically its condition number?",,"['linear-algebra', 'matrices', 'statistics', 'regression', 'condition-number']"
55,$\hat{Y} = X^T\hat{\beta}$ Matrix Dimension For Linear Regression Coefficients $\beta$,Matrix Dimension For Linear Regression Coefficients,\hat{Y} = X^T\hat{\beta} \beta,"While reading about least squares implementation for machine learning I came across this passage in the following two photos: Perhaps I’m misinterpreting the meaning of $ \beta $ but if $ X^T$ has dimension $ 1 \times p $ and $\beta$ has dimension $ p \times K $, then $\hat{Y} $ would have dimension $1\times K$ and would be a row vector. According to the text, vectors are assumed column vectors unless otherwise noted. Can someone provide clarification? Edit: the matrix notation in this text is confusing me. The pages preceding the above passages state the following: Should the matrix referenced not have dimensions $ p \times N$, assuming a $p$-vector is a vector with $p$-elements? Or are the input vectors assumed to be row vectors. Note: The passage is taken from “Elements of Statistical Learning” by Hastie, Tibshirani, & Friedman.","While reading about least squares implementation for machine learning I came across this passage in the following two photos: Perhaps I’m misinterpreting the meaning of $ \beta $ but if $ X^T$ has dimension $ 1 \times p $ and $\beta$ has dimension $ p \times K $, then $\hat{Y} $ would have dimension $1\times K$ and would be a row vector. According to the text, vectors are assumed column vectors unless otherwise noted. Can someone provide clarification? Edit: the matrix notation in this text is confusing me. The pages preceding the above passages state the following: Should the matrix referenced not have dimensions $ p \times N$, assuming a $p$-vector is a vector with $p$-elements? Or are the input vectors assumed to be row vectors. Note: The passage is taken from “Elements of Statistical Learning” by Hastie, Tibshirani, & Friedman.",,"['linear-algebra', 'matrices', 'statistics', 'linear-regression']"
56,"For $Y\sim N(0,\sigma^2)$, find $\mathbb{E}(Y^n)$ for odd and even $n$ using the expectation of $G\sim \text{Gamma}(\alpha,\beta)$","For , find  for odd and even  using the expectation of","Y\sim N(0,\sigma^2) \mathbb{E}(Y^n) n G\sim \text{Gamma}(\alpha,\beta)","For $\alpha,\beta>0$, the probability density function of a Gamma$(\alpha,\beta)$ random variable is given by   $$f(x)=\frac{x^{\alpha-1}e^{\frac{-x}{\beta}}}{\Gamma(\alpha)\beta^\alpha} \ \ \ \ \ \ \ x>0$$   For $\sigma>0$, the probability density function of a $N(0,\sigma^2)$ random variable is given by   $$f(x)=\frac{e^{-\frac{x^2}{2\sigma^2}}}{\sqrt{2\pi\sigma^2}} \ \ \ \ \ \ \ x\in\mathbb{R}$$ Now for $G\sim\text{Gamma}(\alpha,\beta)$, I have shown that for $k\in\mathbb{N}^+$ $$\mathbb{E}(G^k)=\frac{\beta^k\Gamma(\alpha+k)}{\Gamma(\alpha)}  \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ (1)$$ by manipulating the integrand $g^kf(g)$ Let $Y\sim N(0,\sigma^2)$, using the result $(1)$, or otherwise, show that for $n\in\mathbb{N}^+$   $$\mathbb{E}(Y^n)=\ \begin{cases}        \frac{(2\sigma^2)^{\frac{n}{2}}\Gamma(\frac{1}{2}+\frac{n}{2})}{\Gamma(\frac{1}{2})} & \text{n is even} \\      0 &\text{n is odd}  \\     \end{cases} $$ I decide to first tackle the odd case first, as this seemed most obvious. For odd $n$ $$ \mathbb{E}(Y^n)=\int_{-\infty}^{\infty} y^n\frac{e^{-\frac{y^2}{2\sigma^2}}}{\sqrt{2\pi\sigma^2}} dy=0 $$ as the integrand is an odd function when $n$ is odd. For the even case, I have seen a solution that actually solved the expectation by definition. I wanted to use the result $(1)$, as I thought this could speed things up. But i'm unsure if my solution is valid. For even $n$ We first start with  \begin{align} &Y\sim N(0,\sigma^2) \\ &\Rightarrow \frac{Y}{\sigma}\sim N(0,1) \\ &\Rightarrow \frac{Y^2}{\sigma^2}\sim \chi^2_1 \\ &\Rightarrow \frac{Y^2}{\sigma^2}\sim \text{Gamma}\Big(\frac{1}{2},2\Big)\\ &\Rightarrow Y^2\sim\text{Gamma}\Big(\frac{1}{2},2\sigma^2\Big) \\ \end{align} Now let $$Z=Y^2\Rightarrow Y=Z^\frac{1}{2}$$ Hence $$\mathbb{E}(Y^n)=\mathbb{E}(Z^{\frac{n}{2}})=\frac{(2\sigma^2)^{\frac{n}{2}}\Gamma(\frac{1}{2}+\frac{n}{2})}{\Gamma(\frac{1}{2})}$$ I am not entirely sure that my logic for the even case, where I derived a gamma distribution from the normal distribution, is correct. Is this a sufficient answer?","For $\alpha,\beta>0$, the probability density function of a Gamma$(\alpha,\beta)$ random variable is given by   $$f(x)=\frac{x^{\alpha-1}e^{\frac{-x}{\beta}}}{\Gamma(\alpha)\beta^\alpha} \ \ \ \ \ \ \ x>0$$   For $\sigma>0$, the probability density function of a $N(0,\sigma^2)$ random variable is given by   $$f(x)=\frac{e^{-\frac{x^2}{2\sigma^2}}}{\sqrt{2\pi\sigma^2}} \ \ \ \ \ \ \ x\in\mathbb{R}$$ Now for $G\sim\text{Gamma}(\alpha,\beta)$, I have shown that for $k\in\mathbb{N}^+$ $$\mathbb{E}(G^k)=\frac{\beta^k\Gamma(\alpha+k)}{\Gamma(\alpha)}  \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ (1)$$ by manipulating the integrand $g^kf(g)$ Let $Y\sim N(0,\sigma^2)$, using the result $(1)$, or otherwise, show that for $n\in\mathbb{N}^+$   $$\mathbb{E}(Y^n)=\ \begin{cases}        \frac{(2\sigma^2)^{\frac{n}{2}}\Gamma(\frac{1}{2}+\frac{n}{2})}{\Gamma(\frac{1}{2})} & \text{n is even} \\      0 &\text{n is odd}  \\     \end{cases} $$ I decide to first tackle the odd case first, as this seemed most obvious. For odd $n$ $$ \mathbb{E}(Y^n)=\int_{-\infty}^{\infty} y^n\frac{e^{-\frac{y^2}{2\sigma^2}}}{\sqrt{2\pi\sigma^2}} dy=0 $$ as the integrand is an odd function when $n$ is odd. For the even case, I have seen a solution that actually solved the expectation by definition. I wanted to use the result $(1)$, as I thought this could speed things up. But i'm unsure if my solution is valid. For even $n$ We first start with  \begin{align} &Y\sim N(0,\sigma^2) \\ &\Rightarrow \frac{Y}{\sigma}\sim N(0,1) \\ &\Rightarrow \frac{Y^2}{\sigma^2}\sim \chi^2_1 \\ &\Rightarrow \frac{Y^2}{\sigma^2}\sim \text{Gamma}\Big(\frac{1}{2},2\Big)\\ &\Rightarrow Y^2\sim\text{Gamma}\Big(\frac{1}{2},2\sigma^2\Big) \\ \end{align} Now let $$Z=Y^2\Rightarrow Y=Z^\frac{1}{2}$$ Hence $$\mathbb{E}(Y^n)=\mathbb{E}(Z^{\frac{n}{2}})=\frac{(2\sigma^2)^{\frac{n}{2}}\Gamma(\frac{1}{2}+\frac{n}{2})}{\Gamma(\frac{1}{2})}$$ I am not entirely sure that my logic for the even case, where I derived a gamma distribution from the normal distribution, is correct. Is this a sufficient answer?",,"['probability', 'statistics']"
57,Why does sample covariance matrix inflates the larger eigenvalues and shrinks the smaller eigenvalues of the covariance matrix?,Why does sample covariance matrix inflates the larger eigenvalues and shrinks the smaller eigenvalues of the covariance matrix?,,"In classification context, using the maximum likelihood, the sample covariance matrix for each class, estimates the larger eigenvalues of the covariance matrix of each class, larger and estimates the smaller eigenvalues smaller. Why is that? I am studying Regularized Discriminant Analysis written by Friedman. From Regularized Discriminant Analysis Jerome H. Friedman, Journal of the American Statistical Association, Vol. 84, No. 405 (Mar., 1989), pp. 165-175 (original source ): It is well known that the estimates based on Equation (12) produce biased estimates of the eigenvalues; the largest ones are biased high and the smallest ones are biased toward values that are too low. This bias is most pronounced when the population eigenvalues tend toward equality, and it is correspondingly less severe when their values are highly disparate. In all cases, this phenomenon becomes more pronounced as the sample size decreases. When $N_k \le p$ the sample covariance matrix is singular with rank $\le N_k$ and the smallest $p - N_k + 1$ eigenvalues are estimated to be 0. The corresponding eigenvectors are then arbitrary, subject perhaps to orthogonality constraint","In classification context, using the maximum likelihood, the sample covariance matrix for each class, estimates the larger eigenvalues of the covariance matrix of each class, larger and estimates the smaller eigenvalues smaller. Why is that? I am studying Regularized Discriminant Analysis written by Friedman. From Regularized Discriminant Analysis Jerome H. Friedman, Journal of the American Statistical Association, Vol. 84, No. 405 (Mar., 1989), pp. 165-175 (original source ): It is well known that the estimates based on Equation (12) produce biased estimates of the eigenvalues; the largest ones are biased high and the smallest ones are biased toward values that are too low. This bias is most pronounced when the population eigenvalues tend toward equality, and it is correspondingly less severe when their values are highly disparate. In all cases, this phenomenon becomes more pronounced as the sample size decreases. When the sample covariance matrix is singular with rank and the smallest eigenvalues are estimated to be 0. The corresponding eigenvectors are then arbitrary, subject perhaps to orthogonality constraint",N_k \le p \le N_k p - N_k + 1,"['statistics', 'statistical-inference', 'machine-learning', 'estimation']"
58,Characteristic function of the sum of random variables,Characteristic function of the sum of random variables,,"The problem statement, all variables and given/known data I am trying to understand the very last equality for (let me replace the tilda with a hat) $$\widehat{P_X(K)}=\widehat{P(k_1=k_2=\cdots=k_N=k)} \tag 1$$ Relevant equations I also thought that the following imaginary exponential delta identity may be useful, due to the equality of the $k_i$, but see comments below: $$\int dk \, \exp(ikx) = \delta(x=0) $$ The attempt at a solution So it sees to me the goal is something like expressing $\widehat{P_{X}(K)}$ in terms of $P(\widehat{k}_i)$ ? So these are given by $\widehat{P(k_1)\cdots P(k_n)}= \int d^N \vec{x} \, p(\vec{x}) \exp\left( -i \sum_j x_j k_j\right) $ I thought I'd first try to look at the simplified case of independent random variables to understand $(1)$ but still can't seem to get it. So in this case $p(\vec{x}) = \prod_i p(x_i)$ And then we have (If I am correct in that the notation is that $\prod_i dx_i = d^N (\vec{x}) $) $$\widehat{P(k_1)\cdots P(k_n)}= \int \prod_i dx_i \, p(x_i)  \exp\left( -i \sum_j x_j k_j\right) $$ and then you can seperate the integrals and so we have: $$\widehat{P(k_1)\cdots P(k_n)}= \widehat{P_{x_1}(k_1)} \cdots \widehat{P_{x_n}(k_n)} \tag 2 $$ Now if I consider the independent case in $\widehat{P_{X}(K)}$ I have: \begin{align} \widehat{P_{X}(K)} & = \int \prod_i dx_i \, p(x_i) \exp\left( -i k \sum_j x_j  \right) \\[10pt] & = \int  dx_1 \, p(x_1) e^{-ix_1 k} \int dx_2 \, p(x_2) e^{-ix_2 k} \cdots \int dx_N \, p(x_N) e^{-ikx_N} = \widehat{P_{x_1}(k)} \cdots \widehat{P_{x_n}(k)} \end{align} So if I compare this to $(2),$ and can reason( I'm not sure you can) that it does matter whether you have $k_i$ or $k$, this is just the label of the fourier transform, but look at the lower notation that gives the distribution, that $\widehat{P_{x_1}(k)}= \widehat{P_{x_1}(k_1)} $ and then I have $k_1=k$ and can do the same for each $k_i$ etc. Without independence instead i have: $$\int d^N \vec{x} \, p(\vec{x}) \exp\left( -i k \sum_j x_j\right) $$ and I can't see how you can make any conclusions without knowing what $ p(\vec{x}) $ is? Many thanks","The problem statement, all variables and given/known data I am trying to understand the very last equality for (let me replace the tilda with a hat) $$\widehat{P_X(K)}=\widehat{P(k_1=k_2=\cdots=k_N=k)} \tag 1$$ Relevant equations I also thought that the following imaginary exponential delta identity may be useful, due to the equality of the $k_i$, but see comments below: $$\int dk \, \exp(ikx) = \delta(x=0) $$ The attempt at a solution So it sees to me the goal is something like expressing $\widehat{P_{X}(K)}$ in terms of $P(\widehat{k}_i)$ ? So these are given by $\widehat{P(k_1)\cdots P(k_n)}= \int d^N \vec{x} \, p(\vec{x}) \exp\left( -i \sum_j x_j k_j\right) $ I thought I'd first try to look at the simplified case of independent random variables to understand $(1)$ but still can't seem to get it. So in this case $p(\vec{x}) = \prod_i p(x_i)$ And then we have (If I am correct in that the notation is that $\prod_i dx_i = d^N (\vec{x}) $) $$\widehat{P(k_1)\cdots P(k_n)}= \int \prod_i dx_i \, p(x_i)  \exp\left( -i \sum_j x_j k_j\right) $$ and then you can seperate the integrals and so we have: $$\widehat{P(k_1)\cdots P(k_n)}= \widehat{P_{x_1}(k_1)} \cdots \widehat{P_{x_n}(k_n)} \tag 2 $$ Now if I consider the independent case in $\widehat{P_{X}(K)}$ I have: \begin{align} \widehat{P_{X}(K)} & = \int \prod_i dx_i \, p(x_i) \exp\left( -i k \sum_j x_j  \right) \\[10pt] & = \int  dx_1 \, p(x_1) e^{-ix_1 k} \int dx_2 \, p(x_2) e^{-ix_2 k} \cdots \int dx_N \, p(x_N) e^{-ikx_N} = \widehat{P_{x_1}(k)} \cdots \widehat{P_{x_n}(k)} \end{align} So if I compare this to $(2),$ and can reason( I'm not sure you can) that it does matter whether you have $k_i$ or $k$, this is just the label of the fourier transform, but look at the lower notation that gives the distribution, that $\widehat{P_{x_1}(k)}= \widehat{P_{x_1}(k_1)} $ and then I have $k_1=k$ and can do the same for each $k_i$ etc. Without independence instead i have: $$\int d^N \vec{x} \, p(\vec{x}) \exp\left( -i k \sum_j x_j\right) $$ and I can't see how you can make any conclusions without knowing what $ p(\vec{x}) $ is? Many thanks",,"['statistics', 'probability-distributions', 'random-variables', 'characteristic-functions', 'statistical-mechanics']"
59,"Estimation of an average, and speed of convergence","Estimation of an average, and speed of convergence",,"I asked myself those two questions the other day, and I have a very limited backgroud in stats, so help would be appreciated! Sometimes in the middle of my grading, I look at the average of the students I have graded. Of course, it's not the exact average of the whole group but it gives an idea of what the group has done . This is the part that I tried to quantify. If you grade the exams of a classroom made of $N$ students, and suppose the average of the whole group is $\mu$, and a standard deviation $\sigma$. Suppose also a regular bell curve (to make it easier). I have two questions (the first I think I could end up finding it by going over my old books, but the second seems more complex to me): What is the ratio $n/N$ of corrected exams over the total amount of exams that would give you a correct estimate of the average, with let say a 5% accuracy and 95% of being correct? How fast does the intermediate average (the one you can compute after each exam graded) converges towards the actual average of the whole group. In other words, if $$\mu_n=\frac{1}{n}\cdot \Sigma_{k=1}^n G_k$$ and $$f(n)=\frac{|\mu_n-\mu|}{\mu}$$ How fast would $f(n)$ approach $0$? In a exponential, log, or exponent way? I tried to do some simulations, not enough though to get something. (it's a bit late, and I did it very fast on excel, but I'll try with a quick script later). Any partial, or complete answer (or even a reference to some article) would be appreciated! Thanks!","I asked myself those two questions the other day, and I have a very limited backgroud in stats, so help would be appreciated! Sometimes in the middle of my grading, I look at the average of the students I have graded. Of course, it's not the exact average of the whole group but it gives an idea of what the group has done . This is the part that I tried to quantify. If you grade the exams of a classroom made of $N$ students, and suppose the average of the whole group is $\mu$, and a standard deviation $\sigma$. Suppose also a regular bell curve (to make it easier). I have two questions (the first I think I could end up finding it by going over my old books, but the second seems more complex to me): What is the ratio $n/N$ of corrected exams over the total amount of exams that would give you a correct estimate of the average, with let say a 5% accuracy and 95% of being correct? How fast does the intermediate average (the one you can compute after each exam graded) converges towards the actual average of the whole group. In other words, if $$\mu_n=\frac{1}{n}\cdot \Sigma_{k=1}^n G_k$$ and $$f(n)=\frac{|\mu_n-\mu|}{\mu}$$ How fast would $f(n)$ approach $0$? In a exponential, log, or exponent way? I tried to do some simulations, not enough though to get something. (it's a bit late, and I did it very fast on excel, but I'll try with a quick script later). Any partial, or complete answer (or even a reference to some article) would be appreciated! Thanks!",,"['statistics', 'convergence-divergence', 'normal-distribution', 'central-limit-theorem']"
60,Berry-Esseen Smoothing Inequality from Feller Volume 2; Lemma 2 XVI.4,Berry-Esseen Smoothing Inequality from Feller Volume 2; Lemma 2 XVI.4,,"Fellow Feller fans, I have a question concerning Fellers (An introduction to probability and its Applications, Volume 2 1971) treatment of the Berry-Esseen inequality obtained by smoothing which is Lemma 2 on page 538. Specifically it is about going from (3.11) to (3.12) on page 538. To make the question (more or less) self contained denote by $X\sim F_X$, $Y\sim F_Y$ and $Z \sim F_Z$ three absolutely continuous and independent random variables, where $Z$ has a density $f_Z(x) = \frac{1-\cos(Tx)}{\pi T x^2}$ for $T > 0$. Characteristic functions are denoted by $C_X$, $C_Y$ and $C_Z$. For example $C_X(\zeta) = \mathbb{E}[\exp(i \zeta X)]$. With the inverse transformation for densities and $C_{X+Z}(\zeta)=C_X(\zeta)C_Z(\zeta)$ we then have \begin{align}\tag{3.11} f_{X+Z}(x) - f_{Y+Z}(x) = \frac{1}{2\pi} \int_{\mathbb{R}} e^{-i \zeta x} \left[C_X(\zeta) - C_Y(\zeta)\right] C_Z(\zeta) d\zeta. \end{align} This is (3.11) in Feller on page 538 (where $C_Z(\zeta) = \omega_T(\zeta)I_{[-T,T]}(\zeta)$ in Fellers notation). The other relevant (in-) equalities are \begin{align}\tag{3.12} F_{X+Z}(y) - F_{Y+Z}(y) = \frac{1}{2\pi} \int_{\mathbb{R}} e^{-i \zeta y} \frac{C_X(\zeta) - C_Y(\zeta)}{-i\zeta} C_Z(\zeta) d\zeta. \end{align} and just for reference the final goal (in combination with Lemma 1, pager 537) \begin{align}\tag{3.13} \left\vert F_{X}(y) - F_{Y}(y) \right\vert \leq \frac{1}{\pi} \int_{-T}^T  \left\vert \frac{C_X(\zeta) - C_Y(\zeta)}{\zeta}\right\vert d\zeta + \frac{24 m}{\pi T}, \end{align} where $m$ is constant depending only on $F_Y$. Now to the question. Starting from (3.11) we are interested in going to (3.12) and hence need to integrate with respect to $x$. There are now two options: 1) What I would do: Integrate  both sides of (3.11) with respect to $x$. Then we have \begin{align} F_{X+Z}(y)-F_{X+Z}(a) - F_{Y+Z}(y)+F_{Y+Z}(a) &= \int_{a}^y f_{X+Z}(x) - f_{Y+Z}(x) dx\\ &= \frac{1}{2\pi} \int_{\mathbb{R}} \frac{ie^{-i \zeta x}}{\zeta} \Big|_{x=a}^{x=y} \left[C_X(\zeta) - C_Y(\zeta)\right] C_Z(\zeta) d\zeta. \end{align} On the right the factor $\frac{ie^{-i \zeta x}}{\zeta} \big|_{x=a}^{x=y}$ in the integral is related to $e^{-i \zeta x}$ when integrating. To deal with this factor (because there is no convergence for $a \to -\infty$) take absolute values on both sides, pull them into the integral on the right. Now we have $\left\vert \frac{ie^{-i \zeta x}}{\zeta} \big|_{x=a}^{x=y} \right\vert \leq \frac{2}{\vert \zeta \vert}$ for all $y$ and $a$. Now we can take the limit $a \to -\infty$ to get \begin{align}\tag{3.12*} \left\vert F_{X+Z}(y) - F_{Y+Z}(y) \right\vert \leq \frac{1}{2\pi} \int_{\mathbb{R}} 2 \left\vert \frac{C_X(\zeta) - C_Y(\zeta)}{\zeta}\right\vert \vert C_Z(\zeta) \vert d\zeta. \end{align} This method does not give (3.12) - the absolute values are already in play, but it is still good enough to get to something like (3.13). However, this yields an additional factor of $2$ that is not present in Fellers treatment. I have finally \begin{align}\tag{3.13*} \left\vert F_{X}(y) - F_{Y}(y) \right\vert \leq \frac{2}{\pi} \int_{-T}^T  \left\vert \frac{C_X(\zeta) - C_Y(\zeta)}{\zeta}\right\vert d\zeta + \frac{24 m}{\pi T}. \end{align} 2) What Feller does: Essentially guess the anti-derivative of (3.11) and argue that there are no integration constants. Then one gets (3.12) directly (""Integrating with respect to $x$ we obtain"" (3.12) in Fellers words) and this saves the factor $2$ that we otherwise buy in. But I don't really understand the argument: ""No integration constant appears because both sides tend to $0$ as $\vert x \vert \to \infty$, the left because $F(x) - G(x) \to 0$, the right by the Riemann-Lebesgue lemma 4 of XV, 4."" My question now is how Fellers argument can be formalized (or explained in more detailed). I would like to get (3.12) instead of (3.12*) to save the factor $2$ in (3.13) versus (3.13*).","Fellow Feller fans, I have a question concerning Fellers (An introduction to probability and its Applications, Volume 2 1971) treatment of the Berry-Esseen inequality obtained by smoothing which is Lemma 2 on page 538. Specifically it is about going from (3.11) to (3.12) on page 538. To make the question (more or less) self contained denote by $X\sim F_X$, $Y\sim F_Y$ and $Z \sim F_Z$ three absolutely continuous and independent random variables, where $Z$ has a density $f_Z(x) = \frac{1-\cos(Tx)}{\pi T x^2}$ for $T > 0$. Characteristic functions are denoted by $C_X$, $C_Y$ and $C_Z$. For example $C_X(\zeta) = \mathbb{E}[\exp(i \zeta X)]$. With the inverse transformation for densities and $C_{X+Z}(\zeta)=C_X(\zeta)C_Z(\zeta)$ we then have \begin{align}\tag{3.11} f_{X+Z}(x) - f_{Y+Z}(x) = \frac{1}{2\pi} \int_{\mathbb{R}} e^{-i \zeta x} \left[C_X(\zeta) - C_Y(\zeta)\right] C_Z(\zeta) d\zeta. \end{align} This is (3.11) in Feller on page 538 (where $C_Z(\zeta) = \omega_T(\zeta)I_{[-T,T]}(\zeta)$ in Fellers notation). The other relevant (in-) equalities are \begin{align}\tag{3.12} F_{X+Z}(y) - F_{Y+Z}(y) = \frac{1}{2\pi} \int_{\mathbb{R}} e^{-i \zeta y} \frac{C_X(\zeta) - C_Y(\zeta)}{-i\zeta} C_Z(\zeta) d\zeta. \end{align} and just for reference the final goal (in combination with Lemma 1, pager 537) \begin{align}\tag{3.13} \left\vert F_{X}(y) - F_{Y}(y) \right\vert \leq \frac{1}{\pi} \int_{-T}^T  \left\vert \frac{C_X(\zeta) - C_Y(\zeta)}{\zeta}\right\vert d\zeta + \frac{24 m}{\pi T}, \end{align} where $m$ is constant depending only on $F_Y$. Now to the question. Starting from (3.11) we are interested in going to (3.12) and hence need to integrate with respect to $x$. There are now two options: 1) What I would do: Integrate  both sides of (3.11) with respect to $x$. Then we have \begin{align} F_{X+Z}(y)-F_{X+Z}(a) - F_{Y+Z}(y)+F_{Y+Z}(a) &= \int_{a}^y f_{X+Z}(x) - f_{Y+Z}(x) dx\\ &= \frac{1}{2\pi} \int_{\mathbb{R}} \frac{ie^{-i \zeta x}}{\zeta} \Big|_{x=a}^{x=y} \left[C_X(\zeta) - C_Y(\zeta)\right] C_Z(\zeta) d\zeta. \end{align} On the right the factor $\frac{ie^{-i \zeta x}}{\zeta} \big|_{x=a}^{x=y}$ in the integral is related to $e^{-i \zeta x}$ when integrating. To deal with this factor (because there is no convergence for $a \to -\infty$) take absolute values on both sides, pull them into the integral on the right. Now we have $\left\vert \frac{ie^{-i \zeta x}}{\zeta} \big|_{x=a}^{x=y} \right\vert \leq \frac{2}{\vert \zeta \vert}$ for all $y$ and $a$. Now we can take the limit $a \to -\infty$ to get \begin{align}\tag{3.12*} \left\vert F_{X+Z}(y) - F_{Y+Z}(y) \right\vert \leq \frac{1}{2\pi} \int_{\mathbb{R}} 2 \left\vert \frac{C_X(\zeta) - C_Y(\zeta)}{\zeta}\right\vert \vert C_Z(\zeta) \vert d\zeta. \end{align} This method does not give (3.12) - the absolute values are already in play, but it is still good enough to get to something like (3.13). However, this yields an additional factor of $2$ that is not present in Fellers treatment. I have finally \begin{align}\tag{3.13*} \left\vert F_{X}(y) - F_{Y}(y) \right\vert \leq \frac{2}{\pi} \int_{-T}^T  \left\vert \frac{C_X(\zeta) - C_Y(\zeta)}{\zeta}\right\vert d\zeta + \frac{24 m}{\pi T}. \end{align} 2) What Feller does: Essentially guess the anti-derivative of (3.11) and argue that there are no integration constants. Then one gets (3.12) directly (""Integrating with respect to $x$ we obtain"" (3.12) in Fellers words) and this saves the factor $2$ that we otherwise buy in. But I don't really understand the argument: ""No integration constant appears because both sides tend to $0$ as $\vert x \vert \to \infty$, the left because $F(x) - G(x) \to 0$, the right by the Riemann-Lebesgue lemma 4 of XV, 4."" My question now is how Fellers argument can be formalized (or explained in more detailed). I would like to get (3.12) instead of (3.12*) to save the factor $2$ in (3.13) versus (3.13*).",,"['probability', 'statistics', 'inequality', 'characteristic-functions']"
61,What does a confidence interval tell you about the relationship between two things?,What does a confidence interval tell you about the relationship between two things?,,"So I have found a 95% confidence interval for the odds ratio of  developing cancer with vitamin A intake. My sample odds ratio was 1.1667 with a 95% confidence interval of (0.5394, 2.5227). I am then asked what this interval can tell me about the relationship between vitamin A intake and cancer death. But I am unsure what I could say and what it is actually telling me. Is there is a strong relationship between the two? A weak one? Nothing?","So I have found a 95% confidence interval for the odds ratio of  developing cancer with vitamin A intake. My sample odds ratio was 1.1667 with a 95% confidence interval of (0.5394, 2.5227). I am then asked what this interval can tell me about the relationship between vitamin A intake and cancer death. But I am unsure what I could say and what it is actually telling me. Is there is a strong relationship between the two? A weak one? Nothing?",,"['statistics', 'statistical-inference', 'ratio', 'confidence-interval']"
62,Log Likelihood vs Chi Squared- what's the difference?,Log Likelihood vs Chi Squared- what's the difference?,,"A program I have used for a linguistics analysis offers the option of using log likelihood or chi-squared to calculate the keyness of a word (Keyness being the actual frequency of a word in a text in comparison to the expected frequency based upon its frequency in a reference text) The program has a default setting of using log likelihood, so I happily left it at that and let it compute the statistics I needed.  I do however, need to briefly explain the difference between the two methods, and possibly why LL is suggested as the better option. I haven't studied maths in a long time. Can someone explain the difference between chi-squared and log likelihood, in simpleton terms for me?","A program I have used for a linguistics analysis offers the option of using log likelihood or chi-squared to calculate the keyness of a word (Keyness being the actual frequency of a word in a text in comparison to the expected frequency based upon its frequency in a reference text) The program has a default setting of using log likelihood, so I happily left it at that and let it compute the statistics I needed.  I do however, need to briefly explain the difference between the two methods, and possibly why LL is suggested as the better option. I haven't studied maths in a long time. Can someone explain the difference between chi-squared and log likelihood, in simpleton terms for me?",,['statistics']
63,Applied - how to represent confidence (failure probability) in geometric progression of computer upgrades,Applied - how to represent confidence (failure probability) in geometric progression of computer upgrades,,"I think there is a correct way of representing confidence in the below table, but I was never strong at statics. This is based on a practical problem. In reality, the ""upgrade"" has gone through a number of QA tests, and in fact should not cause any breakages. In practice an upgrade sometimes causes failures. What I want to do is minimise the impact of such a failure. I have 1000 computers. I want to upgrade these computers with an identical upgrade. There is an unknown chance that this upgrade will break a computer. I want to do it efficiently (in as few rounds as possible). I want to define my confidence in each round of the likelihood that a computer will break. A long time ago I was told the ""best"" way to upgrade a large number of computers was a ""doubling"" method (geometric progression). My specific question is: A) How do I measure my confidence in the upgrade (IE> I want to know (probabilistically) how many computers will break). In the below table I think the confidence level is far too low. OR How to I report probability of a failure occurring (which is probably more important, but perhaps is just the inverse of the confidence. B) Is this actually (provably) efficient? 2(n)  Num of upgrades  upgrades   Confidence level       per round        completed 1     2                2          0.2% 2     4                6          0.6% 4     8                14         1.4% 8     16               30         3.0% 16    32               62         6.2% 32    64               126        12.6% 64    128              254        25.4% 128   256              510        51.0% 256   512              1000       100.0% Further notes. The idea is that if a breakage happens, you fix the upgrade, and restart from the beginning. If I had a formula then I could re-calculate based on the reduced total population (as some would already be upgraded Not to over complicate, but what if I have, 1% VVIP and 10% VIP, I assume I just leave them until the end of the process to have lowest probability of failure. Thank you!","I think there is a correct way of representing confidence in the below table, but I was never strong at statics. This is based on a practical problem. In reality, the ""upgrade"" has gone through a number of QA tests, and in fact should not cause any breakages. In practice an upgrade sometimes causes failures. What I want to do is minimise the impact of such a failure. I have 1000 computers. I want to upgrade these computers with an identical upgrade. There is an unknown chance that this upgrade will break a computer. I want to do it efficiently (in as few rounds as possible). I want to define my confidence in each round of the likelihood that a computer will break. A long time ago I was told the ""best"" way to upgrade a large number of computers was a ""doubling"" method (geometric progression). My specific question is: A) How do I measure my confidence in the upgrade (IE> I want to know (probabilistically) how many computers will break). In the below table I think the confidence level is far too low. OR How to I report probability of a failure occurring (which is probably more important, but perhaps is just the inverse of the confidence. B) Is this actually (provably) efficient? 2(n)  Num of upgrades  upgrades   Confidence level       per round        completed 1     2                2          0.2% 2     4                6          0.6% 4     8                14         1.4% 8     16               30         3.0% 16    32               62         6.2% 32    64               126        12.6% 64    128              254        25.4% 128   256              510        51.0% 256   512              1000       100.0% Further notes. The idea is that if a breakage happens, you fix the upgrade, and restart from the beginning. If I had a formula then I could re-calculate based on the reduced total population (as some would already be upgraded Not to over complicate, but what if I have, 1% VVIP and 10% VIP, I assume I just leave them until the end of the process to have lowest probability of failure. Thank you!",,"['probability', 'statistics', 'confidence-interval']"
64,"How to convert a detailed mathematical, statistical compuational process into mathematical and statistical equation?","How to convert a detailed mathematical, statistical compuational process into mathematical and statistical equation?",,"I am working on a problem that allows haplotype phasing. I have developed this computation method (expressed in detail below) and have developed a python code (not shown here) to solve the issue. Now, I am having a hard time trying to translate this computation in mathematical and/or statistical language. I have revisited maths and I am able to comprehend the process at several places, but I cannot translate those ideas onto my computation (or algorithm). Here is my computation (step by step) with a very workable example. I have tried to make it as comprehensive as possible, let me know if there is any confustion: Fig 01: Example of the haplotype file contig   pos     ref   all-alleles   ms01e_PI   ms01e_PG_al   ms02g_PI   ms02g_PG_al   ms03g_PI   ms03g_PG_al   ms04h_PI   ms04h_PG_al   ms05h_PI   ms05h_PG_al   ms06h_PI   ms06h_PG_al 2      15881764   .      .           4           C|T           6           C|T           7           T|T           7           T|T           7           C|T           7           C|T 2      15881767   .      .           4           C|C           6           T|C           7           C|C           7           C|C           7           T|C           7           C|C 2      15881989   .      .           4           C|C           6           A|C           7           C|C           7           C|C           7           A|T           7           A|C 2      15882091   .      .           4           G|T           6           G|T           7           T|A           7           A|A           7           A|T           7           A|C 2      15882451   .      .           4           C|T           4           T|C           7           T|T           7           T|T           7           C|T           7           C|A 2      15882454   .      .           4           C|T           4           T|C           7           T|T           7           T|T           7           C|T           7           C|T 2      15882493   .      .           4           C|T           4           T|C           7           T|T           7           T|T           7           C|T           7           C|T 2      15882505   .      .           4           A|T           4           T|A           7           T|T           7           T|T           7           A|C           7           A|T This (fig 01) is my main data file. The main idea is to take a pool of several samples which have short phased haplotype blocks represented as PI (phased index) and PG_al  (phased genotype) . For any sample, the site where two consecutive haplotype blocks are not joined represents the break point (and has different PI values). In the above example only sample ms02g has break point and needs to be phased. All other samples have haplotype block that bridges these two consecutive haplotype blocks and contains the data required to extend the phase state of sample ms02g . Fig 02: Representing a break-point in the sample: ms02g contig    pos    ms02g_PI    ms02g_PG_al 2     15881764     6         C|T 2     15881767     6         T|C 2     15881989     6         A|C 2     15882091     6         G|T                    ×——————————×—————> Break Point 2     15882451     4         T|C 2     15882454     4         T|C  2     15882493     4         T|C 2     15882505     4         T|A So, in the above haplotype file there is a breakpoint in sample ms02g at the position 15882091-15882451 . For sample ms02g(PI-6) the haplotypes are C-T-A-G and T-C-C-T . Similarly, at PI-4 the haplotypes are T-T-T-T and C-C-C-A . Since the haplotype is broken in two levels, we don’t know which phase from level-6 goes with which phase of level-4. But, all other samples have full haplotype intact that bridges this position. We can therefore use this information from other samples to join the two consecutive haplotype in sample ms02g. Using markov-chain transition to extend the haplotype block: Since, all other samples are completely phased bridging that breakpoint, I can run a markov-chain transition probabilities to solve the phase state in the sample ms02g . To the human eye/mind you can clearly see and say that left part of ms02g (PI-6, i.e C-T-A-G is more likely to go with right block of PI-4 C-C-C-A), thereby creating the extended haplotype block as C-T-A-G-C-C-C-A and T-C-C-T-T-T-T-T . Below, I show how I can apply the first order markov transition matrix  to compute the likelyhood estimates, calculate the log2Odds and then assign and extend the haplotype in proper configuration. And, I feed this logic to the computer using python. Calculation of likelyhood estimates using markov transition: Step 01:   prepare required haplotype configuration The top PI-6 is Block 01 and the bottom PI-4 is Block 02 . The phased haplotype in the left within each block is Hap-A and on the right is Hap-B . Fig: representation of the haplotype breakpoint and block assignment ms02g_PI    ms02g_PG_al   6         C|T \   6         T|C | Block 1   6         A|C |   6         G|T /   ×——————————×—————> Break Point   4         T|C \   4         T|C |   4         T|C | Block 2   4         T|A /            ↓   ↓        Hap-A   Hap-B So, the two consecutive blocks can be extended in one of the two possible haplotype configurations: Parallel Configuration:  Block01-HapA with Block02-HapA, so B01-HapB with B02-HapB  Vs. Alternate Configuration:  Block01-HapA with Block02-HapB, so B01-HapB with B02-HapA Step 02: Compute transition matrix and estimate likelihood for each configuration. Fig 03: Representation of the allele transition matrix (from alleles of former block-01 to alleles of later block-02). Possible transitions     ms02g_PG_al  │              ┌┬┬┬  C|T \  │              ││││  T|C | Block 1  │              ││││  A|C |  │              ││││  G|T /  └────────────> ││││   ×—————> Break Point                 │││└> T|C \                 ││└─> T|C | Block 2                 │└──> T|C |                 └───> T|A /                      ↓   ↓                   Hap-A   Hap-B I count the number of transitions from each nucleotide of PI-6 to each nucleotide of PI-4 for each haplotype configuration across all the samples and convert them to transition probabilities. And multiply the transition probabilities from the first nucleotide in PI-6 to all nucleotides of PI-4. Then similarly multiply the transition probability from 2nd nucleotide of PI-6 to all nucleotides in PI-4, and so on. When transition probabilities are calculated for all possible combination (from each position of PI-6 to each position of PI-4), then I compute the cumulative transition probabilities for each possible haplotype configuration. Fig 04 : Representation of nucleotide counts (emission counts) at positions 15881764 and 15882451. pos\allele     A    T    G    C 15881764       0    8    0    4 15882451       1    7    0    4 Fig 05 : Representation of transition matrix counts (from pos 15881764) to (pos 15882451). This transition matrix is computed from nucleotides (A,T,G,C) at block01 to nucleotides (A,T,G,C) at block02 for all the positions. Transition counts are then converted to transition probabilities. from     to           A    T    G    C   A       0    0    0    0   T       1    6.5  0    0.5   G       0    0    0    0   C       0    0.5  0    3.5 **Note: if the PI matches between two blocks the transition are counted    as 1, else 0.5. Sample ms02g itself is also taken as an observation. Step 03: Compute the maximul likelihood for each configuration Fig 06 : Likelihood estimate for parallel configuration using transition counts (probabilities) Parallel configuration: Block-1-Hap-A (C-T-A-G) with Block-2-Hap-A (T-T-T-T)   CtT × CtT × CtT × CtT = (0.5/4)*(0.5/4)*(0.5/4)*(0.5/4) = 0.000244 + TtT × TtT × TtT × TtT = (0.5/2)*(0.5/2)*(0.5/2)*(0.5/2) = 0.003906 + AtT × AtT × AtT × AtT = (0.5/3)*(0.5/3)*(0.5/3)*(0.5/3) = 0.0007716 + GtT × GtT × GtT × GtT = (0.5/2)*(0.5/2)*(0.5/2)*(0.5/2) = 0.003906 ——————— ————————— ——————— ————————— Max Sum (likelihoods) = 0.008828                                     Average (likelihoods) = 0.002207  Block-1-Hap-B (T-C-C-T) with Block-2-Hap-B (C-C-C-A)   TtC × TtC × TtC × TtA = (0.5/8)*(0.5/8)*(0.5/8)*(0.5/8) = 0.00001526 + CtC × CtC × CtC × CtA = (2.5/10)*(2.5/10)*(2.5/10)*(2.5/10) = 0.003906 + CtC × CtC × CtC × CtA = (1.5/8)*(1.5/8)*(1.5/8)*(1.5/8) = 0.001236 + TtC × TtC × TtC × TtA = (0.5/4)*(0.5/4)*(0.5/4)*(0.5/4) = 0.000244 ——————— ————————— ——————— ————————— Max Sum (likelihoods) = 0.0054016                                      Average (likelihoods) = 0.0013504 **note:    - ""AtC"" -> represent ""A"" to ""C"" transition   - ""+"" represents the summation of the likelyhoods Fig 07 : Likelihood estimate for alternate configuration using transition counts (probabilities) Alternate configuration: Block-1-Hap-A (C-T-A-G) with Block-2-Hap-B (C-C-C-A)   CtC × CtC × CtC × CtA = (3.5/4)*(3.5/4)*(3.5/4)*(3.5/4) = 0.5861  + TtC × TtC × TtC × TtA = (1.5/2)*(1.5/2)*(1.5/2)*(1.5/2) = 0.3164 + AtC × AtC × AtC × AtA = (2.5/3)*(2.5/3)*(2.5/3)*(2.5/3) = 0.4823 + GtC × GtC × GtC × GtA = (1.5/2)*(1.5/2)*(1.5/2)*(1.5/2) = 0.3164 ——————— ————————— ——————— ————————— Max Sum (likelyhoods) = 1.7012                                      Average (likelihoods) = 0.425311  Block-1-Hap-B (T-C-C-T) with Block-2-Hap-A (T-T-T-T)    TtC × TtC × TtC × TtA = (6.5/8)*(7.5/8)*(7.5/8)*(6.5/8) = 0.5802 + CtC × CtC × CtC × CtA = (6.5/10)*(7.5/10)*(7.5/10)*(6.5/10) = 0.237 + CtC × CtC × CtC × CtA = (5.5/8)*(6.5/8)*(6.5/8)*(6.5/8) = 0.36875 + TtC × TtC × TtC × TtA = (3.5/4)*(3.5/4)*(3.5/4)*(2.5/4) = 0.4187 ——————— ————————— ——————— ————————— Max Sum (likelyhoods) = 1.60465                                     Average (likelihoods) = 0.4011625  **note:    - the sum of the likelihoods > 1, in the above example.   - So, we can rather use the product of the likelyhoods. Fig 08 : Likelhood estimate of Parallel vs. Alternate configuration. Likelihood of Parallel vs. Alternate configuration  = likelihood of Parallel config / likelihood of Alternate config  = (0.002207 + 0.0013504)/ (0.425311 + 0.4011625) = 0.0043043  (i.e 1/232) Therefore, haplotype is 232 times more likely to be phased  in ""alternate configuration"".  log2Odds = log2(0.0043043) = -7.860006 So, with our default cutoff threshold of ""|5|"", we will be extending  the haplotype in ""alternate configuration"" Final Output data: contig   pos   ref   all-alleles   ms02g_PI   ms02g_PG_al 2   15881764   .    .                  6      C|T 2   15881767   .    .                  6      T|C 2   15881989   .    .                  6      A|C 2   15882091   .    .                  6      G|T 2   15882451   .    .                  6      C|T 2   15882454   .    .                  6      C|T 2   15882493   .    .                  6      C|T 2   15882505   .    .                  6      A|T So, how do I translate my overall computation process in mathematical and statistical language. I am looking to represent computation of: emission counts (and probabilities) transition counts (and probabilities) summation of the transition counts for each configuration computation of likelihood ratio and it's conversion to log2Odds I am trying to represent my computation (algorithm) in the way it's shown in these links, but have a hard time doing it. https://www.probabilitycourse.com/chapter11/11_2_3_probability_distributions.php https://stats.stackexchange.com/questions/25540/summation-of-conditional-probability-in-bayesian-network How to write an algorithm as an equation? FYI - I am biologist but have managed to learn python and write a python program to work it out ( https://codereview.stackexchange.com/questions/186396/solve-the-phase-state-between-two-haplotype-blocks-using-markov-transition-proba ). The code isn't relevant in this question though. Now, it's my time to work out some maths and represent my algorithm. Any help, suggestion is appreciated. Thanks,","I am working on a problem that allows haplotype phasing. I have developed this computation method (expressed in detail below) and have developed a python code (not shown here) to solve the issue. Now, I am having a hard time trying to translate this computation in mathematical and/or statistical language. I have revisited maths and I am able to comprehend the process at several places, but I cannot translate those ideas onto my computation (or algorithm). Here is my computation (step by step) with a very workable example. I have tried to make it as comprehensive as possible, let me know if there is any confustion: Fig 01: Example of the haplotype file contig   pos     ref   all-alleles   ms01e_PI   ms01e_PG_al   ms02g_PI   ms02g_PG_al   ms03g_PI   ms03g_PG_al   ms04h_PI   ms04h_PG_al   ms05h_PI   ms05h_PG_al   ms06h_PI   ms06h_PG_al 2      15881764   .      .           4           C|T           6           C|T           7           T|T           7           T|T           7           C|T           7           C|T 2      15881767   .      .           4           C|C           6           T|C           7           C|C           7           C|C           7           T|C           7           C|C 2      15881989   .      .           4           C|C           6           A|C           7           C|C           7           C|C           7           A|T           7           A|C 2      15882091   .      .           4           G|T           6           G|T           7           T|A           7           A|A           7           A|T           7           A|C 2      15882451   .      .           4           C|T           4           T|C           7           T|T           7           T|T           7           C|T           7           C|A 2      15882454   .      .           4           C|T           4           T|C           7           T|T           7           T|T           7           C|T           7           C|T 2      15882493   .      .           4           C|T           4           T|C           7           T|T           7           T|T           7           C|T           7           C|T 2      15882505   .      .           4           A|T           4           T|A           7           T|T           7           T|T           7           A|C           7           A|T This (fig 01) is my main data file. The main idea is to take a pool of several samples which have short phased haplotype blocks represented as PI (phased index) and PG_al  (phased genotype) . For any sample, the site where two consecutive haplotype blocks are not joined represents the break point (and has different PI values). In the above example only sample ms02g has break point and needs to be phased. All other samples have haplotype block that bridges these two consecutive haplotype blocks and contains the data required to extend the phase state of sample ms02g . Fig 02: Representing a break-point in the sample: ms02g contig    pos    ms02g_PI    ms02g_PG_al 2     15881764     6         C|T 2     15881767     6         T|C 2     15881989     6         A|C 2     15882091     6         G|T                    ×——————————×—————> Break Point 2     15882451     4         T|C 2     15882454     4         T|C  2     15882493     4         T|C 2     15882505     4         T|A So, in the above haplotype file there is a breakpoint in sample ms02g at the position 15882091-15882451 . For sample ms02g(PI-6) the haplotypes are C-T-A-G and T-C-C-T . Similarly, at PI-4 the haplotypes are T-T-T-T and C-C-C-A . Since the haplotype is broken in two levels, we don’t know which phase from level-6 goes with which phase of level-4. But, all other samples have full haplotype intact that bridges this position. We can therefore use this information from other samples to join the two consecutive haplotype in sample ms02g. Using markov-chain transition to extend the haplotype block: Since, all other samples are completely phased bridging that breakpoint, I can run a markov-chain transition probabilities to solve the phase state in the sample ms02g . To the human eye/mind you can clearly see and say that left part of ms02g (PI-6, i.e C-T-A-G is more likely to go with right block of PI-4 C-C-C-A), thereby creating the extended haplotype block as C-T-A-G-C-C-C-A and T-C-C-T-T-T-T-T . Below, I show how I can apply the first order markov transition matrix  to compute the likelyhood estimates, calculate the log2Odds and then assign and extend the haplotype in proper configuration. And, I feed this logic to the computer using python. Calculation of likelyhood estimates using markov transition: Step 01:   prepare required haplotype configuration The top PI-6 is Block 01 and the bottom PI-4 is Block 02 . The phased haplotype in the left within each block is Hap-A and on the right is Hap-B . Fig: representation of the haplotype breakpoint and block assignment ms02g_PI    ms02g_PG_al   6         C|T \   6         T|C | Block 1   6         A|C |   6         G|T /   ×——————————×—————> Break Point   4         T|C \   4         T|C |   4         T|C | Block 2   4         T|A /            ↓   ↓        Hap-A   Hap-B So, the two consecutive blocks can be extended in one of the two possible haplotype configurations: Parallel Configuration:  Block01-HapA with Block02-HapA, so B01-HapB with B02-HapB  Vs. Alternate Configuration:  Block01-HapA with Block02-HapB, so B01-HapB with B02-HapA Step 02: Compute transition matrix and estimate likelihood for each configuration. Fig 03: Representation of the allele transition matrix (from alleles of former block-01 to alleles of later block-02). Possible transitions     ms02g_PG_al  │              ┌┬┬┬  C|T \  │              ││││  T|C | Block 1  │              ││││  A|C |  │              ││││  G|T /  └────────────> ││││   ×—————> Break Point                 │││└> T|C \                 ││└─> T|C | Block 2                 │└──> T|C |                 └───> T|A /                      ↓   ↓                   Hap-A   Hap-B I count the number of transitions from each nucleotide of PI-6 to each nucleotide of PI-4 for each haplotype configuration across all the samples and convert them to transition probabilities. And multiply the transition probabilities from the first nucleotide in PI-6 to all nucleotides of PI-4. Then similarly multiply the transition probability from 2nd nucleotide of PI-6 to all nucleotides in PI-4, and so on. When transition probabilities are calculated for all possible combination (from each position of PI-6 to each position of PI-4), then I compute the cumulative transition probabilities for each possible haplotype configuration. Fig 04 : Representation of nucleotide counts (emission counts) at positions 15881764 and 15882451. pos\allele     A    T    G    C 15881764       0    8    0    4 15882451       1    7    0    4 Fig 05 : Representation of transition matrix counts (from pos 15881764) to (pos 15882451). This transition matrix is computed from nucleotides (A,T,G,C) at block01 to nucleotides (A,T,G,C) at block02 for all the positions. Transition counts are then converted to transition probabilities. from     to           A    T    G    C   A       0    0    0    0   T       1    6.5  0    0.5   G       0    0    0    0   C       0    0.5  0    3.5 **Note: if the PI matches between two blocks the transition are counted    as 1, else 0.5. Sample ms02g itself is also taken as an observation. Step 03: Compute the maximul likelihood for each configuration Fig 06 : Likelihood estimate for parallel configuration using transition counts (probabilities) Parallel configuration: Block-1-Hap-A (C-T-A-G) with Block-2-Hap-A (T-T-T-T)   CtT × CtT × CtT × CtT = (0.5/4)*(0.5/4)*(0.5/4)*(0.5/4) = 0.000244 + TtT × TtT × TtT × TtT = (0.5/2)*(0.5/2)*(0.5/2)*(0.5/2) = 0.003906 + AtT × AtT × AtT × AtT = (0.5/3)*(0.5/3)*(0.5/3)*(0.5/3) = 0.0007716 + GtT × GtT × GtT × GtT = (0.5/2)*(0.5/2)*(0.5/2)*(0.5/2) = 0.003906 ——————— ————————— ——————— ————————— Max Sum (likelihoods) = 0.008828                                     Average (likelihoods) = 0.002207  Block-1-Hap-B (T-C-C-T) with Block-2-Hap-B (C-C-C-A)   TtC × TtC × TtC × TtA = (0.5/8)*(0.5/8)*(0.5/8)*(0.5/8) = 0.00001526 + CtC × CtC × CtC × CtA = (2.5/10)*(2.5/10)*(2.5/10)*(2.5/10) = 0.003906 + CtC × CtC × CtC × CtA = (1.5/8)*(1.5/8)*(1.5/8)*(1.5/8) = 0.001236 + TtC × TtC × TtC × TtA = (0.5/4)*(0.5/4)*(0.5/4)*(0.5/4) = 0.000244 ——————— ————————— ——————— ————————— Max Sum (likelihoods) = 0.0054016                                      Average (likelihoods) = 0.0013504 **note:    - ""AtC"" -> represent ""A"" to ""C"" transition   - ""+"" represents the summation of the likelyhoods Fig 07 : Likelihood estimate for alternate configuration using transition counts (probabilities) Alternate configuration: Block-1-Hap-A (C-T-A-G) with Block-2-Hap-B (C-C-C-A)   CtC × CtC × CtC × CtA = (3.5/4)*(3.5/4)*(3.5/4)*(3.5/4) = 0.5861  + TtC × TtC × TtC × TtA = (1.5/2)*(1.5/2)*(1.5/2)*(1.5/2) = 0.3164 + AtC × AtC × AtC × AtA = (2.5/3)*(2.5/3)*(2.5/3)*(2.5/3) = 0.4823 + GtC × GtC × GtC × GtA = (1.5/2)*(1.5/2)*(1.5/2)*(1.5/2) = 0.3164 ——————— ————————— ——————— ————————— Max Sum (likelyhoods) = 1.7012                                      Average (likelihoods) = 0.425311  Block-1-Hap-B (T-C-C-T) with Block-2-Hap-A (T-T-T-T)    TtC × TtC × TtC × TtA = (6.5/8)*(7.5/8)*(7.5/8)*(6.5/8) = 0.5802 + CtC × CtC × CtC × CtA = (6.5/10)*(7.5/10)*(7.5/10)*(6.5/10) = 0.237 + CtC × CtC × CtC × CtA = (5.5/8)*(6.5/8)*(6.5/8)*(6.5/8) = 0.36875 + TtC × TtC × TtC × TtA = (3.5/4)*(3.5/4)*(3.5/4)*(2.5/4) = 0.4187 ——————— ————————— ——————— ————————— Max Sum (likelyhoods) = 1.60465                                     Average (likelihoods) = 0.4011625  **note:    - the sum of the likelihoods > 1, in the above example.   - So, we can rather use the product of the likelyhoods. Fig 08 : Likelhood estimate of Parallel vs. Alternate configuration. Likelihood of Parallel vs. Alternate configuration  = likelihood of Parallel config / likelihood of Alternate config  = (0.002207 + 0.0013504)/ (0.425311 + 0.4011625) = 0.0043043  (i.e 1/232) Therefore, haplotype is 232 times more likely to be phased  in ""alternate configuration"".  log2Odds = log2(0.0043043) = -7.860006 So, with our default cutoff threshold of ""|5|"", we will be extending  the haplotype in ""alternate configuration"" Final Output data: contig   pos   ref   all-alleles   ms02g_PI   ms02g_PG_al 2   15881764   .    .                  6      C|T 2   15881767   .    .                  6      T|C 2   15881989   .    .                  6      A|C 2   15882091   .    .                  6      G|T 2   15882451   .    .                  6      C|T 2   15882454   .    .                  6      C|T 2   15882493   .    .                  6      C|T 2   15882505   .    .                  6      A|T So, how do I translate my overall computation process in mathematical and statistical language. I am looking to represent computation of: emission counts (and probabilities) transition counts (and probabilities) summation of the transition counts for each configuration computation of likelihood ratio and it's conversion to log2Odds I am trying to represent my computation (algorithm) in the way it's shown in these links, but have a hard time doing it. https://www.probabilitycourse.com/chapter11/11_2_3_probability_distributions.php https://stats.stackexchange.com/questions/25540/summation-of-conditional-probability-in-bayesian-network How to write an algorithm as an equation? FYI - I am biologist but have managed to learn python and write a python program to work it out ( https://codereview.stackexchange.com/questions/186396/solve-the-phase-state-between-two-haplotype-blocks-using-markov-transition-proba ). The code isn't relevant in this question though. Now, it's my time to work out some maths and represent my algorithm. Any help, suggestion is appreciated. Thanks,",,"['probability', 'statistics', 'markov-chains', 'markov-process', 'biology']"
65,Find matrix $S$ such that $diag(S)=d$ and $S^{-1}_{ij}=P_{ij}$ $\forall i \neq j$,Find matrix  such that  and,S diag(S)=d S^{-1}_{ij}=P_{ij} \forall i \neq j,"I want to find a matrix $S$ with a fixed diagonal $d$ whose inverse matches $P$ on all of its off-diagonal elements. You can assume $S$ and $P$ are positive definite, and $d>0$ (all elements of $d$ are positive). Where this problem arises is in the following optimization: $$\max_{S ~ s.t. ~ diag(S)=d} ~ -S \circ P + \ln | S |$$ where $\circ$ is a matrix dot product operator (multiply corresponding elements and add it all up). If it weren't for the condition that $diag(S)=d$, the solution to the maximization would be $S=P^{-1}$. However, because of the condition, we need $S^{-1}$ to match $P$ on all the off diagonal elements, while still keeping its diagonal equal to $d$. The only solution I can think of is to just do the optimization numerically (via gradient descent or Convex Optimization / Semidefinite Programming), which is too costly computationally.","I want to find a matrix $S$ with a fixed diagonal $d$ whose inverse matches $P$ on all of its off-diagonal elements. You can assume $S$ and $P$ are positive definite, and $d>0$ (all elements of $d$ are positive). Where this problem arises is in the following optimization: $$\max_{S ~ s.t. ~ diag(S)=d} ~ -S \circ P + \ln | S |$$ where $\circ$ is a matrix dot product operator (multiply corresponding elements and add it all up). If it weren't for the condition that $diag(S)=d$, the solution to the maximization would be $S=P^{-1}$. However, because of the condition, we need $S^{-1}$ to match $P$ on all the off diagonal elements, while still keeping its diagonal equal to $d$. The only solution I can think of is to just do the optimization numerically (via gradient descent or Convex Optimization / Semidefinite Programming), which is too costly computationally.",,"['linear-algebra', 'matrices', 'statistics', 'matrix-equations', 'matrix-calculus']"
66,The Law of Total Covariance on a Gaussian Process,The Law of Total Covariance on a Gaussian Process,,"Suppose that we have a Gaussian process with zero mean and covariance function $k$, $$   f(x) \sim \mathcal{GP}(0, K(x,x')) \tag{1} $$ It is usually assumed that there are a collection of training inputs $X = [\mathbf{x}_0, \ldots, \mathbf{x}_N]$, and training outputs $\mathbf{f} = [f_0, \ldots, f_N]$, such that, $$   \mathbf{f} \sim \mathcal{N}(0, K(X,X)) \tag{2} $$ see for example Gaussian Processes for Machine Learning by Rasmussen and Williams. My question how to, instead, deal with connected sets of known training points, i.e., $X = [X_0, \ldots, X_N] \subset \mathbb{R}^N$, with $X_i \cap X_j = \emptyset$, with constant training outputs, i.e. $f(x_i) = \kappa_i$ for every $x_i \in X_i$. Rather than viewing the sets themselves as random variables, with a specified covariance functions, I need to extend the idea of a Gaussian process defined by points over entire sets. The law of total covariance gives that, $$   \operatorname{Cov}(\kappa_i, \kappa_j) = \int_{X_i \times X_j} K(x_i, x_j)p(x_i, x_j) d(x_i,x_j) $$ for random variables $\kappa_i$. This gives a covariance between the outputs, using a covariance function which is defined in terms of points. Is there a way of using the process notation, such as in (1) or (2), to deal with this idea properly?","Suppose that we have a Gaussian process with zero mean and covariance function $k$, $$   f(x) \sim \mathcal{GP}(0, K(x,x')) \tag{1} $$ It is usually assumed that there are a collection of training inputs $X = [\mathbf{x}_0, \ldots, \mathbf{x}_N]$, and training outputs $\mathbf{f} = [f_0, \ldots, f_N]$, such that, $$   \mathbf{f} \sim \mathcal{N}(0, K(X,X)) \tag{2} $$ see for example Gaussian Processes for Machine Learning by Rasmussen and Williams. My question how to, instead, deal with connected sets of known training points, i.e., $X = [X_0, \ldots, X_N] \subset \mathbb{R}^N$, with $X_i \cap X_j = \emptyset$, with constant training outputs, i.e. $f(x_i) = \kappa_i$ for every $x_i \in X_i$. Rather than viewing the sets themselves as random variables, with a specified covariance functions, I need to extend the idea of a Gaussian process defined by points over entire sets. The law of total covariance gives that, $$   \operatorname{Cov}(\kappa_i, \kappa_j) = \int_{X_i \times X_j} K(x_i, x_j)p(x_i, x_j) d(x_i,x_j) $$ for random variables $\kappa_i$. This gives a covariance between the outputs, using a covariance function which is defined in terms of points. Is there a way of using the process notation, such as in (1) or (2), to deal with this idea properly?",,"['probability', 'statistics', 'stochastic-processes', 'statistical-inference', 'stationary-processes']"
67,Asymptotic distribution of non-linear least squares,Asymptotic distribution of non-linear least squares,,"Assume an i.i.d sample of a scalar dependent variable $y_i$ and a $k$-dimensional regressor $x_i$. Assume that $\mathbb{E}[y_i \mid x_i] = \exp\left(x_i'\beta_0\right)$ and $Var(y_i \mid x_i) = \exp\left(x_i'\gamma_0\right)$. Also assume that the non-linear least squares estimator $\widehat{\beta}$ of $\beta_0$ is $\sqrt{N}$-consistent and asymptotically normal, i.e., $$\sqrt{N}\left(\widehat{\beta} - \beta_0\right) \overset{d}{\rightarrow} N(0, H_0^{-1}V_0 H_0^{-1}) $$ Find an expression for $H_0$ and $V_0$. I know the general formulas for $H_0$ and $V_0$ for non-linear least squares, that is, for the non-linear least squares estimator $$\widehat{\theta}_N = \arg\min_{\theta} \frac{1}{N} \sum_{i=1}^{N} (y_i - g(x_i, \theta))^2 $$ where $g(x_i, \theta) = \mathbb{E}\left[y_i \mid x_i = x \right]$, we have: $$V_0 = 4\mathbb{E}\left[(y_i - g(x_i, \theta_0))^2 \frac{\partial g(x_i, \theta_0)}{\partial \theta} \frac{\partial g(x_i, \theta_0)}{\partial \theta'} \right] $$ and $$H_0 = 2\mathbb{E}\left[ \frac{\partial g(x_i, \theta_0)}{\partial \theta} \frac{\partial g(x_i, \theta_0)}{\partial \theta'}\right] $$ where $\theta_0$ denotes the true parameter. I'm unsure of how to compute the expressions using these results.","Assume an i.i.d sample of a scalar dependent variable $y_i$ and a $k$-dimensional regressor $x_i$. Assume that $\mathbb{E}[y_i \mid x_i] = \exp\left(x_i'\beta_0\right)$ and $Var(y_i \mid x_i) = \exp\left(x_i'\gamma_0\right)$. Also assume that the non-linear least squares estimator $\widehat{\beta}$ of $\beta_0$ is $\sqrt{N}$-consistent and asymptotically normal, i.e., $$\sqrt{N}\left(\widehat{\beta} - \beta_0\right) \overset{d}{\rightarrow} N(0, H_0^{-1}V_0 H_0^{-1}) $$ Find an expression for $H_0$ and $V_0$. I know the general formulas for $H_0$ and $V_0$ for non-linear least squares, that is, for the non-linear least squares estimator $$\widehat{\theta}_N = \arg\min_{\theta} \frac{1}{N} \sum_{i=1}^{N} (y_i - g(x_i, \theta))^2 $$ where $g(x_i, \theta) = \mathbb{E}\left[y_i \mid x_i = x \right]$, we have: $$V_0 = 4\mathbb{E}\left[(y_i - g(x_i, \theta_0))^2 \frac{\partial g(x_i, \theta_0)}{\partial \theta} \frac{\partial g(x_i, \theta_0)}{\partial \theta'} \right] $$ and $$H_0 = 2\mathbb{E}\left[ \frac{\partial g(x_i, \theta_0)}{\partial \theta} \frac{\partial g(x_i, \theta_0)}{\partial \theta'}\right] $$ where $\theta_0$ denotes the true parameter. I'm unsure of how to compute the expressions using these results.",,"['statistics', 'probability-distributions', 'asymptotics', 'normal-distribution', 'regression']"
68,How to find the MLE of multiple parameters [closed],How to find the MLE of multiple parameters [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Suppose $X_1,\ldots,X_n,Y_1,\ldots,Y_n$ are independent exponential r.v., where the density of $X_i$ is $f_i(x)= \lambda_i\theta \exp(-\lambda_i \theta x_i)$ for $x\geq0$, while the density of $Y_i$ is $g_i(x) = \lambda_i \exp(-\lambda_i x_i)$  for $x\geq0$. Find the MLE of theta (based on $X_1,\ldots,X_n,Y_1,\ldots,Y_n$). Find the MLEs of $\lambda_i$ for each $i$.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Suppose $X_1,\ldots,X_n,Y_1,\ldots,Y_n$ are independent exponential r.v., where the density of $X_i$ is $f_i(x)= \lambda_i\theta \exp(-\lambda_i \theta x_i)$ for $x\geq0$, while the density of $Y_i$ is $g_i(x) = \lambda_i \exp(-\lambda_i x_i)$  for $x\geq0$. Find the MLE of theta (based on $X_1,\ldots,X_n,Y_1,\ldots,Y_n$). Find the MLEs of $\lambda_i$ for each $i$.",,['statistics']
69,Unbiased estimator in Laplace distribution [closed],Unbiased estimator in Laplace distribution [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $X\sim f_X(x\mid\theta)=\frac{1}{2\theta}e^{-|x|/\theta}$, $x\in\mathbb{R}$, and $\theta>0,$ find an unbiased estimator of $(1+\theta)^{-1}$ of least variation. I have tried using the fact that $|X|\sim \exp(1/\theta)$ and so $T=\sum_{i=1}^n |X_i| \sim \operatorname{gamma}(n,1/\theta)$ . I calculate that $E[1/T]=\frac{1}{(n-1)\theta}$ but I can't calculate something like $E[1/(1+T)]$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $X\sim f_X(x\mid\theta)=\frac{1}{2\theta}e^{-|x|/\theta}$, $x\in\mathbb{R}$, and $\theta>0,$ find an unbiased estimator of $(1+\theta)^{-1}$ of least variation. I have tried using the fact that $|X|\sim \exp(1/\theta)$ and so $T=\sum_{i=1}^n |X_i| \sim \operatorname{gamma}(n,1/\theta)$ . I calculate that $E[1/T]=\frac{1}{(n-1)\theta}$ but I can't calculate something like $E[1/(1+T)]$.",,"['statistics', 'parameter-estimation']"
70,Using averages to measure the dispersion of data,Using averages to measure the dispersion of data,,"INTRODUCTION: I recently had a new idea on how to measure the dispersion of data. Since I have done my quick research and have not been able to find this method anywhere I was curious to see what somebody with greater expertise in the field of statistics would think about it and so I am sharing it here as a first step. During my engineering education I have been taught several ways to analyze the dispersion of data, the most popular being the standard deviation, where a lot of the probability and statistics theory is based on. In some other applications however, I have been exposed to methods such as the range, both of the MAD's or even the IQR. I even did my own literature study regarding the suitability of each of these methods, and it is clear to me that while the standard deviation is the most widely used method, it is not the only method nor always the most suitable one. IDEA: To my idea: The result of this method actually looks a lot like the box and whiskers plot you would get from using the IQR (Inter quartile range) method. Instead of relying though on percentiles, it relies on averages. Here the method outline: Calculate the mean: This is a very common step, since most methods out there require this value in order to be able to calculate the dispersion of the data from the expected value. Calculate the mean for left and right sides: We just calculated the mean, which for a function represents the centroid of a distribution. This center line is used usually as a reference for how far away a data point is in terms of dispersion. So why do we not split the data here, and take again the averages, but this time only for each half, left and right? That is actually what I then do. Results: We now have a mid-average (mq), a lower quarter average (lq) and a upper quarter average (uq). Obviously from this we can then also calculate the IQR as: \begin{equation} \text{IQR} = \text{uq} - \text{lq} \end{equation}  Obviously this gives a good idea on how the data is distributed. Not only can we say something about its distribution through the IQR, but we can analyze the symmetry by checking the difference between the $(\text{uq} - \text{mq})$ and $(\text{mq} - \text{lq})$. I hope I am also right in saying that the IQR (for a normal distribution) represents 50% of the data, and if we would want to use more data, we would simply have to repeat the 'split and calculate new average' method (in which the next iteration would include 75% of the data). So, what do you guys think about this method? Maybe you could also tell how one would go about testing the method? OWN THOUGHTS: As far as I can see, the method relies on averages, which is quite nice. Unlike the percentiles used for the typical IQR method, averages rely on the whole data. This might not make them very robust, but are always adjusted  fully to the data. In addition, I find this quite an intuitive method; it's simple and the dispersion measured by 50% of the data seems easy to grasp. Finally, compared to the standard deviation, the values do not need to be squared, which means that this method does not get skewed as much by outliers and may be more fitting when analyzing data with errors. (The reason the mean absolute deviation (MAD or MD) is sometimes used.) EXAMPLE: In order to give an idea how this would look like, two examples, one in which the numerical process is shown, another of a comparison between the box and whiskers (without the whiskers) results from the typical IQR method and the method I propose here. Example 1: Say we start off with the following data: 2,4,4,4,5,6,6,7,8,10 From this we can calculate the mid-average:  \begin{equation} \text{mq} = \frac{2+4+\cdots+10}{10} = 5.6  \end{equation}  All the values lower than or equal to 5.6 are taken and the lq is calculated with the same average formula: \begin{equation} \text{lq} = \frac{2+4+\cdots+5}{5} = 3.8  \end{equation}  We can repeat this method to calculate the uq, this time for all the values bigger or equal to 5.6: \begin{equation} \text{lq} = \frac{6+6+\cdots+10}{5} = 7.4  \end{equation}  We therefore can calculate the IQR using these average values: \begin{equation} \text{IQR} = \text{uq} - \text{lq} = 3.6 \end{equation} In addition, we can observe that when taking the ratio between $(\text{uq} - \text{mq})$ and $(\text{mq} - \text{lq})$, we get a value of 1.0, suggesting that the data is symmetric. Example 2: Here the figure I have obtained using a Python code (posted below) which compares the typical IQR method with the method outlined here. You can see in green the mq, lq and uq for the typical IQR method, in red the result of the method I have been proposing. The sample size is 1000, and the values for the lines are: My method: mid_avg:  -0.0905134149804 lq_avg:  -1.63815314319 uq_avg: 1.50107551444 IQRwAVG:  3.13922865764 Typical IQR method: median:  -0.116056069599 25 percentile:  -1.39684011872 50 percentile:  1.21390120378 IQR:  2.6107413225 Here the code: # -*- coding: utf-8 -*- """""" Created on Sat Jan 13 20:47:36 2018  @author: Marco DS  This script shall give an idea how well the IQR  method works if the quartiles are calculated using averages instead.  In this version we will focus on comparing the IQR with quarter averages to the typical IQR method  using percentiles. """"""  import numpy as np import matplotlib.pyplot as plt  #============================================================================== # Create random sample #============================================================================== mu, sigma = 0.0, 2.0 np.random.seed(0) sample = np.random.normal(mu, sigma, 1000)  #============================================================================== # Calculations #==============================================================================  #------------------------------------------------------------------------------ # IQR with averages #------------------------------------------------------------------------------ mid_avg = np.average(sample)  lq_avg = np.average(sample[sample<=mid_avg]) uq_avg = np.average(sample[sample>=mid_avg])  IQRwAVG = uq_avg - lq_avg  print '==========' print 'mid_avg: ', mid_avg print 'lq_avg: ', lq_avg print 'uq_avg: ', uq_avg print 'IQRwAVG: ', IQRwAVG  #------------------------------------------------------------------------------ # IQR with averages #------------------------------------------------------------------------------ p75, p50, p25 = np.percentile(sample, [75 , 50, 25]) IQR = p75 - p25  print '==========' print 'median: ', p50 print '25 percentile: ', p25 print '50 percentile: ', p75 print 'IQR: ', IQR  #============================================================================== # Show plot #============================================================================== plt.hist(sample, 10)  #plt.xlabel('Smarts') #plt.ylabel('Probability') #plt.title('Histogram of IQ') #plt.text(60, .025, r'$\mu=100,\ \sigma=15$') #plt.axis([40, 160, 0, 0.03]) #plt.grid(True)  for i in [lq_avg, mid_avg, uq_avg]:     plt.axvline(x = i, color = 'r')  for i in [p75, p50, p25]:     plt.axvline(x = i, color = 'g')  plt.show()","INTRODUCTION: I recently had a new idea on how to measure the dispersion of data. Since I have done my quick research and have not been able to find this method anywhere I was curious to see what somebody with greater expertise in the field of statistics would think about it and so I am sharing it here as a first step. During my engineering education I have been taught several ways to analyze the dispersion of data, the most popular being the standard deviation, where a lot of the probability and statistics theory is based on. In some other applications however, I have been exposed to methods such as the range, both of the MAD's or even the IQR. I even did my own literature study regarding the suitability of each of these methods, and it is clear to me that while the standard deviation is the most widely used method, it is not the only method nor always the most suitable one. IDEA: To my idea: The result of this method actually looks a lot like the box and whiskers plot you would get from using the IQR (Inter quartile range) method. Instead of relying though on percentiles, it relies on averages. Here the method outline: Calculate the mean: This is a very common step, since most methods out there require this value in order to be able to calculate the dispersion of the data from the expected value. Calculate the mean for left and right sides: We just calculated the mean, which for a function represents the centroid of a distribution. This center line is used usually as a reference for how far away a data point is in terms of dispersion. So why do we not split the data here, and take again the averages, but this time only for each half, left and right? That is actually what I then do. Results: We now have a mid-average (mq), a lower quarter average (lq) and a upper quarter average (uq). Obviously from this we can then also calculate the IQR as: \begin{equation} \text{IQR} = \text{uq} - \text{lq} \end{equation}  Obviously this gives a good idea on how the data is distributed. Not only can we say something about its distribution through the IQR, but we can analyze the symmetry by checking the difference between the $(\text{uq} - \text{mq})$ and $(\text{mq} - \text{lq})$. I hope I am also right in saying that the IQR (for a normal distribution) represents 50% of the data, and if we would want to use more data, we would simply have to repeat the 'split and calculate new average' method (in which the next iteration would include 75% of the data). So, what do you guys think about this method? Maybe you could also tell how one would go about testing the method? OWN THOUGHTS: As far as I can see, the method relies on averages, which is quite nice. Unlike the percentiles used for the typical IQR method, averages rely on the whole data. This might not make them very robust, but are always adjusted  fully to the data. In addition, I find this quite an intuitive method; it's simple and the dispersion measured by 50% of the data seems easy to grasp. Finally, compared to the standard deviation, the values do not need to be squared, which means that this method does not get skewed as much by outliers and may be more fitting when analyzing data with errors. (The reason the mean absolute deviation (MAD or MD) is sometimes used.) EXAMPLE: In order to give an idea how this would look like, two examples, one in which the numerical process is shown, another of a comparison between the box and whiskers (without the whiskers) results from the typical IQR method and the method I propose here. Example 1: Say we start off with the following data: 2,4,4,4,5,6,6,7,8,10 From this we can calculate the mid-average:  \begin{equation} \text{mq} = \frac{2+4+\cdots+10}{10} = 5.6  \end{equation}  All the values lower than or equal to 5.6 are taken and the lq is calculated with the same average formula: \begin{equation} \text{lq} = \frac{2+4+\cdots+5}{5} = 3.8  \end{equation}  We can repeat this method to calculate the uq, this time for all the values bigger or equal to 5.6: \begin{equation} \text{lq} = \frac{6+6+\cdots+10}{5} = 7.4  \end{equation}  We therefore can calculate the IQR using these average values: \begin{equation} \text{IQR} = \text{uq} - \text{lq} = 3.6 \end{equation} In addition, we can observe that when taking the ratio between $(\text{uq} - \text{mq})$ and $(\text{mq} - \text{lq})$, we get a value of 1.0, suggesting that the data is symmetric. Example 2: Here the figure I have obtained using a Python code (posted below) which compares the typical IQR method with the method outlined here. You can see in green the mq, lq and uq for the typical IQR method, in red the result of the method I have been proposing. The sample size is 1000, and the values for the lines are: My method: mid_avg:  -0.0905134149804 lq_avg:  -1.63815314319 uq_avg: 1.50107551444 IQRwAVG:  3.13922865764 Typical IQR method: median:  -0.116056069599 25 percentile:  -1.39684011872 50 percentile:  1.21390120378 IQR:  2.6107413225 Here the code: # -*- coding: utf-8 -*- """""" Created on Sat Jan 13 20:47:36 2018  @author: Marco DS  This script shall give an idea how well the IQR  method works if the quartiles are calculated using averages instead.  In this version we will focus on comparing the IQR with quarter averages to the typical IQR method  using percentiles. """"""  import numpy as np import matplotlib.pyplot as plt  #============================================================================== # Create random sample #============================================================================== mu, sigma = 0.0, 2.0 np.random.seed(0) sample = np.random.normal(mu, sigma, 1000)  #============================================================================== # Calculations #==============================================================================  #------------------------------------------------------------------------------ # IQR with averages #------------------------------------------------------------------------------ mid_avg = np.average(sample)  lq_avg = np.average(sample[sample<=mid_avg]) uq_avg = np.average(sample[sample>=mid_avg])  IQRwAVG = uq_avg - lq_avg  print '==========' print 'mid_avg: ', mid_avg print 'lq_avg: ', lq_avg print 'uq_avg: ', uq_avg print 'IQRwAVG: ', IQRwAVG  #------------------------------------------------------------------------------ # IQR with averages #------------------------------------------------------------------------------ p75, p50, p25 = np.percentile(sample, [75 , 50, 25]) IQR = p75 - p25  print '==========' print 'median: ', p50 print '25 percentile: ', p25 print '50 percentile: ', p75 print 'IQR: ', IQR  #============================================================================== # Show plot #============================================================================== plt.hist(sample, 10)  #plt.xlabel('Smarts') #plt.ylabel('Probability') #plt.title('Histogram of IQ') #plt.text(60, .025, r'$\mu=100,\ \sigma=15$') #plt.axis([40, 160, 0, 0.03]) #plt.grid(True)  for i in [lq_avg, mid_avg, uq_avg]:     plt.axvline(x = i, color = 'r')  for i in [p75, p50, p25]:     plt.axvline(x = i, color = 'g')  plt.show()",,"['statistics', 'statistical-inference']"
71,How to prove mutually independence?,How to prove mutually independence?,,"The original problem is somewhat trivial, and I have one last step to prove the mutually independence. $P(Y=k)=1/n, k=0,1,...,n-1$ $n=p_1p_2…p_k$ and $p_1,p_2,...,p_k$ are co-prime integers. Prove that $X_{p_i}=(Y\ mod\ p_i), i=1,...,k$ are mutually independent. Any help would be appreciated. (By the way, I have caculated the probability  $P(X_{p_i}=k)=1/p_i, k=1,...,p_i-1$ But no idea of what to do next.)","The original problem is somewhat trivial, and I have one last step to prove the mutually independence. $P(Y=k)=1/n, k=0,1,...,n-1$ $n=p_1p_2…p_k$ and $p_1,p_2,...,p_k$ are co-prime integers. Prove that $X_{p_i}=(Y\ mod\ p_i), i=1,...,k$ are mutually independent. Any help would be appreciated. (By the way, I have caculated the probability  $P(X_{p_i}=k)=1/p_i, k=1,...,p_i-1$ But no idea of what to do next.)",,"['probability', 'statistics', 'probability-distributions', 'independence']"
72,Joint distribution for simple mixture of discrete and continous,Joint distribution for simple mixture of discrete and continous,,"This is a problem 4.31 b) in Statistical Inference by Casella and Berger: let $X \sim Unif(0,1)$ and $Y \sim Binom(n, X)$. What is the joint distribution? The answer can be found in solutions manual but I don't know how to arrive at it. This is where I get: this is mixture of discrete and continuous RVs so there is no well defined pdf. But the distribution will be determined if we can get $P(Y=y, X \leq x) = P(Y=y|X \leq x)P(X \leq x) $. Obviously $P(X \leq x) = x$. And here I've got stuck: not sure if this is legit: $P(Y=y|X \leq x) = \binom{n}{y} \int_{0}^{x} t^{y}(1-t)^{n-y}dt $ ? And even if it is, I don't know how to compute the integral.","This is a problem 4.31 b) in Statistical Inference by Casella and Berger: let $X \sim Unif(0,1)$ and $Y \sim Binom(n, X)$. What is the joint distribution? The answer can be found in solutions manual but I don't know how to arrive at it. This is where I get: this is mixture of discrete and continuous RVs so there is no well defined pdf. But the distribution will be determined if we can get $P(Y=y, X \leq x) = P(Y=y|X \leq x)P(X \leq x) $. Obviously $P(X \leq x) = x$. And here I've got stuck: not sure if this is legit: $P(Y=y|X \leq x) = \binom{n}{y} \int_{0}^{x} t^{y}(1-t)^{n-y}dt $ ? And even if it is, I don't know how to compute the integral.",,"['probability', 'statistics']"
73,Neyman-Pearson $\alpha$-level test always exists for continuous distributions,Neyman-Pearson -level test always exists for continuous distributions,\alpha,"The Neyman-Pearson lemma as in the classical book by Casella and Berger, gives to conditions for the existence of $\alpha$-level tests: The critical region must be of the form: $\{x:f(x|\theta_1) > k f(x|\theta_0)\} \subseteq R \subseteq \{x:f(x|\theta_1) \ge k f(x|\theta_0)\}$ $\alpha = P_{\theta_0}(X \in R)$ One can see that not every $\alpha$ has a suitable critical region such that 2. holds. The problem comes with discrete distributions. Example Let $X \sim Binom(2,\theta)$ and the test $H_0: \theta = 1/2$, $H_1:\theta = 3/4$. In this situation I cannot find a critical region of the form $\{x:f(x|\theta_1)/f(x|\theta_0) \ge k\}$ such that the size of the test is $\alpha = 1/\pi$ the reason is that all computations are done with rational values. I had an argument that tried to proved that for continuous distributions the test of level $\alpha$ always exists but thanks to @Nch I found that it was wrong. How can I prove that for continuous distributions there is always an $\alpha$-level test?","The Neyman-Pearson lemma as in the classical book by Casella and Berger, gives to conditions for the existence of $\alpha$-level tests: The critical region must be of the form: $\{x:f(x|\theta_1) > k f(x|\theta_0)\} \subseteq R \subseteq \{x:f(x|\theta_1) \ge k f(x|\theta_0)\}$ $\alpha = P_{\theta_0}(X \in R)$ One can see that not every $\alpha$ has a suitable critical region such that 2. holds. The problem comes with discrete distributions. Example Let $X \sim Binom(2,\theta)$ and the test $H_0: \theta = 1/2$, $H_1:\theta = 3/4$. In this situation I cannot find a critical region of the form $\{x:f(x|\theta_1)/f(x|\theta_0) \ge k\}$ such that the size of the test is $\alpha = 1/\pi$ the reason is that all computations are done with rational values. I had an argument that tried to proved that for continuous distributions the test of level $\alpha$ always exists but thanks to @Nch I found that it was wrong. How can I prove that for continuous distributions there is always an $\alpha$-level test?",,"['probability', 'statistics', 'statistical-inference', 'hypothesis-testing']"
74,Bayes estimator for binomial sample given a beta prior,Bayes estimator for binomial sample given a beta prior,,"I'm working through some old qualifying exam problems and am wondering what I'm being asked to do in the following question: We have a random sample $\textbf{X} = (X_1, \dots, X_n)$ from a binomial$(m,\theta)$ distribution with prior distribution $\Theta \sim \text{Beta}(\alpha, \beta)$, where $m \in \mathbb{Z}^+, \alpha>0$, and $\beta>0$ are all known. Find the Bayes estimator for $\theta$ and $\theta^2$. Here is where my confusion begins. Usually I am asked to find the Bayes estimator with respect to a loss function. There is no loss function given here. Hence, I am not sure how to proceed. I have worked out that the posterior distribution is $\Theta | T \sim \text{Beta}(T + \alpha, \beta + nm - T)$ where $T$ is the sample sum.","I'm working through some old qualifying exam problems and am wondering what I'm being asked to do in the following question: We have a random sample $\textbf{X} = (X_1, \dots, X_n)$ from a binomial$(m,\theta)$ distribution with prior distribution $\Theta \sim \text{Beta}(\alpha, \beta)$, where $m \in \mathbb{Z}^+, \alpha>0$, and $\beta>0$ are all known. Find the Bayes estimator for $\theta$ and $\theta^2$. Here is where my confusion begins. Usually I am asked to find the Bayes estimator with respect to a loss function. There is no loss function given here. Hence, I am not sure how to proceed. I have worked out that the posterior distribution is $\Theta | T \sim \text{Beta}(T + \alpha, \beta + nm - T)$ where $T$ is the sample sum.",,"['statistics', 'bayesian']"
75,"$P(X_{(2)}>2)$ given $f_X(x) =\frac{2}{x^3}I_{(1,\infty)}(x)$",given,"P(X_{(2)}>2) f_X(x) =\frac{2}{x^3}I_{(1,\infty)}(x)","$X_1$, $X_2$, and $X_3$ are independent random variables having pdf $$f_X(x) =\frac{2}{x^3}I_{(1,\infty)}(x)$$ Give the value of $P(X_{(2)}>2)$ Would this just be the same as finding the probability that at least two of $X_1$, $X_2$, and $X_3$ are greater than $2$? Because if only $1$ were greater than $2$ then that would be $X_{(n)}$, the sample maximum. If that's true, then I have for an individual $X$ that $$\begin{align*} P(X>2) &= 1-\int_1^2 \frac{2}{x^3}dx\\\\ &= 1-\left({-1\over{x^2}}|_1^2\right)\\\\ &= 1-\left(\frac{-1}{4}-\frac{-1}{1}\right) \\\\ &= \frac{1}{4} \end{align*}$$ Then $$\begin{align*} P(X_{(2)}>2) &= {3\choose{2}}\cdot\frac{1}{4}^2 \cdot\frac{3}{4}+{3\choose{3}}\cdot\frac{1}{4}^3\\\\ &= \frac{5}{32}=.15625\\\\ \end{align*}$$ Is this correct?","$X_1$, $X_2$, and $X_3$ are independent random variables having pdf $$f_X(x) =\frac{2}{x^3}I_{(1,\infty)}(x)$$ Give the value of $P(X_{(2)}>2)$ Would this just be the same as finding the probability that at least two of $X_1$, $X_2$, and $X_3$ are greater than $2$? Because if only $1$ were greater than $2$ then that would be $X_{(n)}$, the sample maximum. If that's true, then I have for an individual $X$ that $$\begin{align*} P(X>2) &= 1-\int_1^2 \frac{2}{x^3}dx\\\\ &= 1-\left({-1\over{x^2}}|_1^2\right)\\\\ &= 1-\left(\frac{-1}{4}-\frac{-1}{1}\right) \\\\ &= \frac{1}{4} \end{align*}$$ Then $$\begin{align*} P(X_{(2)}>2) &= {3\choose{2}}\cdot\frac{1}{4}^2 \cdot\frac{3}{4}+{3\choose{3}}\cdot\frac{1}{4}^3\\\\ &= \frac{5}{32}=.15625\\\\ \end{align*}$$ Is this correct?",,"['probability', 'statistics', 'probability-distributions']"
76,Order Statistics w/ Max,Order Statistics w/ Max,,"Let $X_1, X_2, \ldots$ be i.i.d. r.v.s with CDF $F$, and let $M_n = \max(X_1,X_2, \ldots ,X_n)$. Find the joint distribution of $M_n$ and $M_{n+1}$, for each $n \geq 1$. So, CDF of $M_{n+1}$ is given as,  $$ \begin{align}  P(M_{n+1} \leq x) &= P(X_1 ≤ x, X_2 ≤ x, \ldots, X_n ≤ x, X_{n+1} ≤ x ) \\ &= \underbrace{F(x) \times F(x) \times \ldots}_{(n+1) \text{ times}} \\ &= F(x)^{n+1} \end{align}$$ We want to consider two cases: $P(M_n \leq a,M_{n+1} \leq b)$. However, after getting these facts, I am lost. Can someone help me in finding this joint distribution? Much thanks.","Let $X_1, X_2, \ldots$ be i.i.d. r.v.s with CDF $F$, and let $M_n = \max(X_1,X_2, \ldots ,X_n)$. Find the joint distribution of $M_n$ and $M_{n+1}$, for each $n \geq 1$. So, CDF of $M_{n+1}$ is given as,  $$ \begin{align}  P(M_{n+1} \leq x) &= P(X_1 ≤ x, X_2 ≤ x, \ldots, X_n ≤ x, X_{n+1} ≤ x ) \\ &= \underbrace{F(x) \times F(x) \times \ldots}_{(n+1) \text{ times}} \\ &= F(x)^{n+1} \end{align}$$ We want to consider two cases: $P(M_n \leq a,M_{n+1} \leq b)$. However, after getting these facts, I am lost. Can someone help me in finding this joint distribution? Much thanks.",,"['probability', 'statistics', 'probability-distributions', 'order-statistics']"
77,UMP test and MLR of a distribution,UMP test and MLR of a distribution,,"Let $Y_1, \ldots, Y_n$ be a random sample from a distribution with the density function $$f_θ(y) = \frac{3θ^3}{y^4} \text{ for } y ≥ θ > 0.$$ Is there a UMP test at level α for testing $H_0 : θ ≤ θ_0$ vs $H_1 : θ > θ_0$? I've begun this question by looking for an MLR, but I'm already stuck. I've got the likelihood ratio as just $(θ_2/θ_1)^{3n}$, which means it is non-decreasing, but it's not a function of a statistic, just the parameter. Does this mean a) there is no MLR for this distribution and hence, no UMP? b) there is no MLR for this distribution, but this doesn't necessarily mean no UMP? or c) I have misunderstood how to calculate an MLR and there is one. Thanks!","Let $Y_1, \ldots, Y_n$ be a random sample from a distribution with the density function $$f_θ(y) = \frac{3θ^3}{y^4} \text{ for } y ≥ θ > 0.$$ Is there a UMP test at level α for testing $H_0 : θ ≤ θ_0$ vs $H_1 : θ > θ_0$? I've begun this question by looking for an MLR, but I'm already stuck. I've got the likelihood ratio as just $(θ_2/θ_1)^{3n}$, which means it is non-decreasing, but it's not a function of a statistic, just the parameter. Does this mean a) there is no MLR for this distribution and hence, no UMP? b) there is no MLR for this distribution, but this doesn't necessarily mean no UMP? or c) I have misunderstood how to calculate an MLR and there is one. Thanks!",,['statistics']
78,MSEs of Estimators of Variance in Normal Distribution,MSEs of Estimators of Variance in Normal Distribution,,"$\newcommand{\MSE}{\operatorname{MSE}}$ Consider the mean squared error (MSE) of the following estimators of variance, where $X_i$ is given by the normal distribution: $$\MSE(S^2)=\MSE\left(\frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2\right) = \frac{2}{n-1} \sigma^4$$ $$\MSE(S_1^2)=\MSE\left(\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2\right) = \frac{2(n-1)}{n^2}\sigma^4$$ (first one is an unbiased estimator of variance, and second one is a biased estimator) And, in the case where $\mu$ is known: $$\MSE(S_0^2)=\MSE(\frac{1} n \sum_{i=1}^n (X_i - \mu)^2) = \frac{2}{n}\sigma^4$$ In considering the MSE of these three estimators, I have two questions: Why do we often use $S^2$ instead of $S_1^2$ as an estimator for $\sigma$ , even though the latter has a lower MSE? If it is due to the fact that $S^2$ has a lower bias, then why do we define MSE the way we do at all? If minimizing bias is more important than minimizing variance, couldn't we set the MSE to be equal to twice the bias squared plus the variance, or something like that? Intuitively, how is $\MSE(S_1^2) > \MSE(S_0^2)$ ? This doesn't really make sense to me, as in cases where we know $\mu$ our MSE should really only decrease. The only explanation I can think of is that if we were to have an entire sample that was biased, the deviations from the population mean would clearly be greater than the deviations from the sample mean. But, on average, this shouldn't be the case. Thanks in advance!","Consider the mean squared error (MSE) of the following estimators of variance, where is given by the normal distribution: (first one is an unbiased estimator of variance, and second one is a biased estimator) And, in the case where is known: In considering the MSE of these three estimators, I have two questions: Why do we often use instead of as an estimator for , even though the latter has a lower MSE? If it is due to the fact that has a lower bias, then why do we define MSE the way we do at all? If minimizing bias is more important than minimizing variance, couldn't we set the MSE to be equal to twice the bias squared plus the variance, or something like that? Intuitively, how is ? This doesn't really make sense to me, as in cases where we know our MSE should really only decrease. The only explanation I can think of is that if we were to have an entire sample that was biased, the deviations from the population mean would clearly be greater than the deviations from the sample mean. But, on average, this shouldn't be the case. Thanks in advance!",\newcommand{\MSE}{\operatorname{MSE}} X_i \MSE(S^2)=\MSE\left(\frac{1}{n-1}\sum_{i=1}^n (X_i - \bar{X})^2\right) = \frac{2}{n-1} \sigma^4 \MSE(S_1^2)=\MSE\left(\frac{1}{n}\sum_{i=1}^{n}(X_i - \bar{X})^2\right) = \frac{2(n-1)}{n^2}\sigma^4 \mu \MSE(S_0^2)=\MSE(\frac{1} n \sum_{i=1}^n (X_i - \mu)^2) = \frac{2}{n}\sigma^4 S^2 S_1^2 \sigma S^2 \MSE(S_1^2) > \MSE(S_0^2) \mu,"['probability', 'statistics', 'normal-distribution', 'chi-squared', 'mean-square-error']"
79,Understanding the use of Radial Basis Function in Linear Regression,Understanding the use of Radial Basis Function in Linear Regression,,"I am attempting to understand the use of Radial Basis Functions (RBFs) as used in linear regression. Building the problem : RBFs can be used as a means of separating data which is not linearly separable (see example scatter-plot by link containing different below) Non-linearly separable Scatter plot Positive (green) and negative (red) data-points are clustered together but no straight line can be found to separate them from each-other. We are seeking some function $f(x) = w\phi(x) + c$ which will plot a 'line' between the points. Note : $w$ represents a matrix of weights $\phi(x) = \exp(−(x−c)^⊤(x−c)/h^2)$ ( Note : Our Radial Basis function is Gaussian). $c$ is our 'y' intercept $h$ relates to how quickly $\phi(x)$ drops off towards zero My current ""understanding"" : We can use a linear combination of RBFs (a seperate RBF for each cluster, 3 in this case) to find a 'line' ( $f(x)$ ) which will separate positive data-points from negative data-points. The function will appear as follows: $f(x) = w_1\phi_1(x) + w_2\phi_2(x) + w_3\phi_3(x)$ So we choose values for centers $c_1, c_2, c_3$ to offset the respective RBFs $\phi_1(x), \phi_2(x), \phi_3(x)$ according to the distance the related scatter plot is from the origin of the 2-d plane ($x_1$,$x_2$). Appropriate values are then chosen for the $w_1, w_2, w_3$ matrix such that when multiplied by the respective $\phi$ the hope being that any new (previously unseen values) will be determined to be positive or negative depending on what side of the 'line' defined by $f(x)$ they reside on. My Questions : Am I correct, incorrect, partially correct in my current understanding? If correct are there things you feel I am leaving out? If incorrect, why? If partially correct, could you advise what is right or wrong?","I am attempting to understand the use of Radial Basis Functions (RBFs) as used in linear regression. Building the problem : RBFs can be used as a means of separating data which is not linearly separable (see example scatter-plot by link containing different below) Non-linearly separable Scatter plot Positive (green) and negative (red) data-points are clustered together but no straight line can be found to separate them from each-other. We are seeking some function $f(x) = w\phi(x) + c$ which will plot a 'line' between the points. Note : $w$ represents a matrix of weights $\phi(x) = \exp(−(x−c)^⊤(x−c)/h^2)$ ( Note : Our Radial Basis function is Gaussian). $c$ is our 'y' intercept $h$ relates to how quickly $\phi(x)$ drops off towards zero My current ""understanding"" : We can use a linear combination of RBFs (a seperate RBF for each cluster, 3 in this case) to find a 'line' ( $f(x)$ ) which will separate positive data-points from negative data-points. The function will appear as follows: $f(x) = w_1\phi_1(x) + w_2\phi_2(x) + w_3\phi_3(x)$ So we choose values for centers $c_1, c_2, c_3$ to offset the respective RBFs $\phi_1(x), \phi_2(x), \phi_3(x)$ according to the distance the related scatter plot is from the origin of the 2-d plane ($x_1$,$x_2$). Appropriate values are then chosen for the $w_1, w_2, w_3$ matrix such that when multiplied by the respective $\phi$ the hope being that any new (previously unseen values) will be determined to be positive or negative depending on what side of the 'line' defined by $f(x)$ they reside on. My Questions : Am I correct, incorrect, partially correct in my current understanding? If correct are there things you feel I am leaving out? If incorrect, why? If partially correct, could you advise what is right or wrong?",,"['statistics', 'regression', 'machine-learning', 'radial-basis-functions']"
80,How to calculate recurring probability,How to calculate recurring probability,,"I have a very basic understanding of statistics and probability. I just passed an intro college course on it. The problem is, there's one type of problem that I'd like to know how to do, and I don't have another statistics class, and it wasn't covered in this one. I think that there are other threads that answer this question, but the math is a bit over my head. So what I'm wondering is how to calculate a percentile probability based on a recurring event. Let's say event A has a 2% probability of occurring. But what if we repeat event A x number of times? I understand the (and - multiplication) and (or - addition) rules. It seems that repeating this x number of times would be an or incident, since it gives a situation multiple opportunities to occur. But the problem with that is that with enough repetitions of x, we'd eventually, and rather quickly end up with P>1, which isn't how a percentage works. For example, in our situation with a 2% likelihood, let's assume we repeat the situation 51 times. That's 51 different opportunities for the event to happen, so it falls into the or rule. If we add .02 together for all of this, we will end up with P>1. For one, this isn't how a percentile based calculation even works, since P cannot ever be greater than 1. Secondly, it seems unlikely that given 50 repetitions, something with a 2% likelihood would be certain to occur. Basically, I know I'm doing this wrong, but I don't understand what about it is wrong, and I'd like to know the right way to do it. I've done a lot of digging, but the only things that I can find that closely relate to this do not explain it without breaking down whatever formula they're using. I'd really like to know how to do it, as well as why it works the way it does. I appreciate any answers.","I have a very basic understanding of statistics and probability. I just passed an intro college course on it. The problem is, there's one type of problem that I'd like to know how to do, and I don't have another statistics class, and it wasn't covered in this one. I think that there are other threads that answer this question, but the math is a bit over my head. So what I'm wondering is how to calculate a percentile probability based on a recurring event. Let's say event A has a 2% probability of occurring. But what if we repeat event A x number of times? I understand the (and - multiplication) and (or - addition) rules. It seems that repeating this x number of times would be an or incident, since it gives a situation multiple opportunities to occur. But the problem with that is that with enough repetitions of x, we'd eventually, and rather quickly end up with P>1, which isn't how a percentage works. For example, in our situation with a 2% likelihood, let's assume we repeat the situation 51 times. That's 51 different opportunities for the event to happen, so it falls into the or rule. If we add .02 together for all of this, we will end up with P>1. For one, this isn't how a percentile based calculation even works, since P cannot ever be greater than 1. Secondly, it seems unlikely that given 50 repetitions, something with a 2% likelihood would be certain to occur. Basically, I know I'm doing this wrong, but I don't understand what about it is wrong, and I'd like to know the right way to do it. I've done a lot of digging, but the only things that I can find that closely relate to this do not explain it without breaking down whatever formula they're using. I'd really like to know how to do it, as well as why it works the way it does. I appreciate any answers.",,['statistics']
81,Bayesian statistics - finding a posterior distribution,Bayesian statistics - finding a posterior distribution,,"Suppose the number of sales, N, in a year on a sales portfolio has a   poisson distribution with parameter $\lambda$. Sales are either large   with probability $p$ or small with probability $1-p$, independently   from each other. Suppose we observer $r$ large sales. Show that the conditional   distribution of $N - r \mid r$ is poisson. I've managed to complete the question from first principles: Let $R$ be the number of large sales, we have $ R \mid N$ is binomially distributed with parameters $N$ and $p$. If we consider $P(N - r = s \mid R = r)$ and apply Bayes conditional probability formula we eventually get the result. I am wondering if there is perhaps a simplier way to do it? For instance, could we perhaps just directly use the the result that, $$ \text{ Posterior PDF } \propto \text{Prior PDF } \times \text{ Likelihood}$$ that is, $$f(\theta \mid x) \propto f(\theta) \times L(x \mid \theta)$$ Can this general formula be applied in this case as a shortcut?","Suppose the number of sales, N, in a year on a sales portfolio has a   poisson distribution with parameter $\lambda$. Sales are either large   with probability $p$ or small with probability $1-p$, independently   from each other. Suppose we observer $r$ large sales. Show that the conditional   distribution of $N - r \mid r$ is poisson. I've managed to complete the question from first principles: Let $R$ be the number of large sales, we have $ R \mid N$ is binomially distributed with parameters $N$ and $p$. If we consider $P(N - r = s \mid R = r)$ and apply Bayes conditional probability formula we eventually get the result. I am wondering if there is perhaps a simplier way to do it? For instance, could we perhaps just directly use the the result that, $$ \text{ Posterior PDF } \propto \text{Prior PDF } \times \text{ Likelihood}$$ that is, $$f(\theta \mid x) \propto f(\theta) \times L(x \mid \theta)$$ Can this general formula be applied in this case as a shortcut?",,"['probability', 'statistics', 'bayesian']"
82,combined probability of N items.,combined probability of N items.,,"I'm currently facing a situation that I need some help about. So here is the problem. Let's say we have a question bank with N questions, where in each question has a defined probability score that tells the question's capability of segregating good/bad students out of the pool of students who took that question. Essentially this is a conditional probability in form: $ P(Good\;Student/Question\;answered\;correctly) $ This probability has been calculated based on past data. Now, I want to calculate the similar probability score of a question paper that has been created by selecting N questions from Question Bank. As per my understanding, this is the case of $P(A\,and\,B\,and\,C....\,and\,N)$ wherein A is probability of question 1 answered correctly and so on. Considering questions are mutually exclusive (not sure about this though). However, the problem with this approach is that the end probability after selecting N questions would be very small and I don't think that is the appropriate probability. So what should be the suggested approach in this case. Please let me know in case any other detail is required to understand the question better. Looking forward to any help and thanks in advance! Peace.","I'm currently facing a situation that I need some help about. So here is the problem. Let's say we have a question bank with N questions, where in each question has a defined probability score that tells the question's capability of segregating good/bad students out of the pool of students who took that question. Essentially this is a conditional probability in form: $ P(Good\;Student/Question\;answered\;correctly) $ This probability has been calculated based on past data. Now, I want to calculate the similar probability score of a question paper that has been created by selecting N questions from Question Bank. As per my understanding, this is the case of $P(A\,and\,B\,and\,C....\,and\,N)$ wherein A is probability of question 1 answered correctly and so on. Considering questions are mutually exclusive (not sure about this though). However, the problem with this approach is that the end probability after selecting N questions would be very small and I don't think that is the appropriate probability. So what should be the suggested approach in this case. Please let me know in case any other detail is required to understand the question better. Looking forward to any help and thanks in advance! Peace.",,"['probability', 'statistics']"
83,"Martingale estimating, Confidence interval","Martingale estimating, Confidence interval",,"I would like to create confidence intervals for martingale estimators. For the processes $$B_{t}(a,k)=\int_0^ta_s(k)\,\mathbb 1_{\{\mathbb E[\lambda_{s}(k)]>0\}}\,\mathrm ds$$ we have estimators $$\hat{B}^n_t(a,k)=\int_0^t\big(\lambda^n_s(k)\big)^{-1}\,\mathrm dN^n_s(k).$$ These estimators are consistent and asymptotically normal with mean= $0$ . $N^n$ is a sequence of point processes with stochastic intensity $\lambda^n$ . We observe i.i.d. copies $(N_t^i,\lambda_t^i)$ , $1\le i\le n$ of pairs $(N,\lambda)$ . For the variance, we have the estimator $$\hat{C}_t(a,k)=n\int_0^t\frac1{[\lambda^n_s(k)]^{2}}\,\mathrm dN^n_s(k).$$ How do I now create a confidence interval?","I would like to create confidence intervals for martingale estimators. For the processes we have estimators These estimators are consistent and asymptotically normal with mean= . is a sequence of point processes with stochastic intensity . We observe i.i.d. copies , of pairs . For the variance, we have the estimator How do I now create a confidence interval?","B_{t}(a,k)=\int_0^ta_s(k)\,\mathbb 1_{\{\mathbb E[\lambda_{s}(k)]>0\}}\,\mathrm ds \hat{B}^n_t(a,k)=\int_0^t\big(\lambda^n_s(k)\big)^{-1}\,\mathrm dN^n_s(k). 0 N^n \lambda^n (N_t^i,\lambda_t^i) 1\le i\le n (N,\lambda) \hat{C}_t(a,k)=n\int_0^t\frac1{[\lambda^n_s(k)]^{2}}\,\mathrm dN^n_s(k).","['statistics', 'martingales', 'estimation', 'confidence-interval', 'point-processes']"
84,if $X$ and $Y$ are Normal random variables with same parameters. is $(aX+bX)=(aX+bY)$?,if  and  are Normal random variables with same parameters. is ?,X Y (aX+bX)=(aX+bY),"if $X$ and $Y$ are random variables and both are $\sim N(\mu,\sigma^2)$, ie share the same average and variance. Then we defined a new random variable as the linear combination of them as: $Z=(aX+bY)$ is that the same as saying $Z=(aX+bX)$? Is $Z=(aX+bX)$ the same as saying $Z=((a+b)X)$?","if $X$ and $Y$ are random variables and both are $\sim N(\mu,\sigma^2)$, ie share the same average and variance. Then we defined a new random variable as the linear combination of them as: $Z=(aX+bY)$ is that the same as saying $Z=(aX+bX)$? Is $Z=(aX+bX)$ the same as saying $Z=((a+b)X)$?",,"['statistics', 'normal-distribution']"
85,Help with an expectation of log beta (or Gamma) function,Help with an expectation of log beta (or Gamma) function,,"Suppose a vector ${\bf x} = (m,1-m) \times s$  where $(m,1-m)$ is distributed according to a beta distribution beta$(a,b)$ with density $f(m,1-m) = \frac{m^{a-1}(1-m)^{b-1}} {B (a,b)}$, $s$ is distributed according to a Gamma distribution gamma$(\alpha, \beta)$ with density $g(s) = {\frac {\beta ^{\alpha }}{\Gamma (\alpha )}}s^{\alpha \,-\,1}e^{-\beta s}$. All parameters $a,b,\alpha,\beta$ are known. Also note $m,s$ are independent. Then the question is: is there anyway to calculate the expectation of log beta function: $\log B ({\bf x})$, which is $\Bbb E [\log \Gamma (sm) + \log \Gamma (s(1-m)) - \log \Gamma (s) ]$ with both $m$ and $s$ as random variables? See also related question . My attempt : I am not sure, but maybe we can use Stirling's approximation That is $\ln \Gamma (x) \approx (x - \frac{1}{2})\ln x - x + \frac{1}{{12(x + 1)}} + \frac{1}{2}\ln 2\pi  + O(x)$ and my application scenario allows dropping the constant addends and the $O(x)$ term. Then, $\ln \Gamma (sm) + \ln \Gamma (s(1 - m)) - \log \Gamma (s) = sm\ln sm - \frac{1}{2}\ln sm + \frac{1}{{12(sm + 1)}} + s(1 - m)\ln s(1 - m) - \frac{1}{2}\ln s(1 - m) + \frac{1}{{12(s(1 - m) + 1)}} - s\ln s - \frac{1}{2}\ln s + \frac{1}{{12(s + 1)}}$ Note $s,m$ are independent random variables, and $\Bbb E[s]$, $\Bbb E[m]$, $\Bbb E[\ln s]$, $\Bbb E[\ln m]$ have known form. The remaining problems are to calculate $\Bbb E[\frac {1}{s+1}]$, $\Bbb E[\frac {1}{sm+1}]$, $\Bbb E[s \ln s]$ and $\Bbb E[m \ln m]$, etc. See the related question .","Suppose a vector ${\bf x} = (m,1-m) \times s$  where $(m,1-m)$ is distributed according to a beta distribution beta$(a,b)$ with density $f(m,1-m) = \frac{m^{a-1}(1-m)^{b-1}} {B (a,b)}$, $s$ is distributed according to a Gamma distribution gamma$(\alpha, \beta)$ with density $g(s) = {\frac {\beta ^{\alpha }}{\Gamma (\alpha )}}s^{\alpha \,-\,1}e^{-\beta s}$. All parameters $a,b,\alpha,\beta$ are known. Also note $m,s$ are independent. Then the question is: is there anyway to calculate the expectation of log beta function: $\log B ({\bf x})$, which is $\Bbb E [\log \Gamma (sm) + \log \Gamma (s(1-m)) - \log \Gamma (s) ]$ with both $m$ and $s$ as random variables? See also related question . My attempt : I am not sure, but maybe we can use Stirling's approximation That is $\ln \Gamma (x) \approx (x - \frac{1}{2})\ln x - x + \frac{1}{{12(x + 1)}} + \frac{1}{2}\ln 2\pi  + O(x)$ and my application scenario allows dropping the constant addends and the $O(x)$ term. Then, $\ln \Gamma (sm) + \ln \Gamma (s(1 - m)) - \log \Gamma (s) = sm\ln sm - \frac{1}{2}\ln sm + \frac{1}{{12(sm + 1)}} + s(1 - m)\ln s(1 - m) - \frac{1}{2}\ln s(1 - m) + \frac{1}{{12(s(1 - m) + 1)}} - s\ln s - \frac{1}{2}\ln s + \frac{1}{{12(s + 1)}}$ Note $s,m$ are independent random variables, and $\Bbb E[s]$, $\Bbb E[m]$, $\Bbb E[\ln s]$, $\Bbb E[\ln m]$ have known form. The remaining problems are to calculate $\Bbb E[\frac {1}{s+1}]$, $\Bbb E[\frac {1}{sm+1}]$, $\Bbb E[s \ln s]$ and $\Bbb E[m \ln m]$, etc. See the related question .",,"['probability', 'statistics', 'approximation']"
86,Boosting randomized algorithms with Hoeffding's inequality,Boosting randomized algorithms with Hoeffding's inequality,,"I am working on Ex. 2.2.8 out of Roman Vershinyn's High Dimensional Probability book: https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf The problem asks: Imagine we have an algorithm for solving a decision problem. Suppose the algorithm makes the decision at random and returns the correct answer with probability $1/2 + \delta$ for some $\delta > 0$. To improve the performance, we run the algorithm $N$ times and take the majority vote. Show that, for any $\epsilon \in (0,1)$, the answer is correct with probability $1 - \epsilon$ as long as $N \geq 2 \delta^{-2} \ln (\epsilon^{-1})$. The hint was to set $X_i$ to the indicator function on the event that the algorithm guessed incorrectly and apply Hoeffding's inequality. However, in this section he gives variations of Hoeffding's inequality, one for symmetric bernoulli random variables (along with its two sided inequality) and for general bounded random variables (which is asked to be proven in the previous exercise). Ultimately, I think I want to show that $$\mathbb{P}\left\{\text{event that the algorithm guessed incorrectly a majority of the time}\right\} \leq \epsilon$$ as long as $N \geq 2\delta^{-2}\ln(\epsilon^{-1})$ but I am not sure how to formulate this properly with the Hoeffding inequalities introduced since $X_i$ is not symmetric. Would anyone be able to provide a hint as to how to proceed?","I am working on Ex. 2.2.8 out of Roman Vershinyn's High Dimensional Probability book: https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf The problem asks: Imagine we have an algorithm for solving a decision problem. Suppose the algorithm makes the decision at random and returns the correct answer with probability $1/2 + \delta$ for some $\delta > 0$. To improve the performance, we run the algorithm $N$ times and take the majority vote. Show that, for any $\epsilon \in (0,1)$, the answer is correct with probability $1 - \epsilon$ as long as $N \geq 2 \delta^{-2} \ln (\epsilon^{-1})$. The hint was to set $X_i$ to the indicator function on the event that the algorithm guessed incorrectly and apply Hoeffding's inequality. However, in this section he gives variations of Hoeffding's inequality, one for symmetric bernoulli random variables (along with its two sided inequality) and for general bounded random variables (which is asked to be proven in the previous exercise). Ultimately, I think I want to show that $$\mathbb{P}\left\{\text{event that the algorithm guessed incorrectly a majority of the time}\right\} \leq \epsilon$$ as long as $N \geq 2\delta^{-2}\ln(\epsilon^{-1})$ but I am not sure how to formulate this properly with the Hoeffding inequalities introduced since $X_i$ is not symmetric. Would anyone be able to provide a hint as to how to proceed?",,"['probability', 'statistics']"
87,I need to solve a problem. What branches of math should I study?,I need to solve a problem. What branches of math should I study?,,"The answer seems to be 'statistics' but I assume that's about as useful as saying a person interested in gravity should study 'physics'. I anticipate a large number of data points to be delivered to me from a sensor. For purposes of discussion, say it's the temperature at the top of a tower, every second.  That is, I'll have one sensor returning values every second. I know the possible range of the values, and I'll know when they were taken. I want to know if a particular value is unusual. I want to know with some certainty that since time X, the values are trending up or down. I want to know if the sensor is misbehaving. For example, if our temperature sensor developed a bad ground and Murphy paid a visit, it could be the temperature would seem very stable. The average could be about right, and nope, not trending at all. Different analysis could point out that the nature of the data has changed, or that it is indeed just noise. So of course this is statistics but is there a specific type I should care about? EDIT - another reasonable use case is to notice cyclic behavior. It would probably be pretty normal for network traffic or memory usage to increase starting at about 8am 5 days a week. We would not be concerned by this. But what if one Monday, it didn't?  What if another cycle was noticed, say, one that peaked on the 3rd Saturday of each month? Analysis of cyclic behavior says FFT to me, but after that I am lost. (This may sound like a climate change question. It isn't. The fact is I am looking for a general solution. I am not even sure what the data will be. I'll ultimately have hundreds of sensors reporting to me... everything from memory usage on computers to the timestamps in which a security door is opened...)","The answer seems to be 'statistics' but I assume that's about as useful as saying a person interested in gravity should study 'physics'. I anticipate a large number of data points to be delivered to me from a sensor. For purposes of discussion, say it's the temperature at the top of a tower, every second.  That is, I'll have one sensor returning values every second. I know the possible range of the values, and I'll know when they were taken. I want to know if a particular value is unusual. I want to know with some certainty that since time X, the values are trending up or down. I want to know if the sensor is misbehaving. For example, if our temperature sensor developed a bad ground and Murphy paid a visit, it could be the temperature would seem very stable. The average could be about right, and nope, not trending at all. Different analysis could point out that the nature of the data has changed, or that it is indeed just noise. So of course this is statistics but is there a specific type I should care about? EDIT - another reasonable use case is to notice cyclic behavior. It would probably be pretty normal for network traffic or memory usage to increase starting at about 8am 5 days a week. We would not be concerned by this. But what if one Monday, it didn't?  What if another cycle was noticed, say, one that peaked on the 3rd Saturday of each month? Analysis of cyclic behavior says FFT to me, but after that I am lost. (This may sound like a climate change question. It isn't. The fact is I am looking for a general solution. I am not even sure what the data will be. I'll ultimately have hundreds of sensors reporting to me... everything from memory usage on computers to the timestamps in which a security door is opened...)",,['statistics']
88,What is the name of this statistical filter? [closed],What is the name of this statistical filter? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I have a piece of code that takes a noisy data set and uses some sort of statistical filter to plot a trend line over the noisy data. The original author of the code no longer works at my job, so I can't ask him what the filter is. I've included a math-ified version of his code, and I would love to know what the filter is called so I can learn more about it . Here's a code/math snippet. First, a bunch of variables are set. The first element of filtered is set to just be the average of the noisy data, just so we have a value to use in the first iteration of the loop. filtered will contain all the filtered points from the noisy dataset called noisy . $\beta = 0.00001 \\ \sigma = 0.005 \\  \overline{p}_0 = 1 \\ q = 1 \\ k = \frac{\overline{p}_0}{\overline{p}_0 + 1} \\ p = k \\  filtered[0] = avg(noisy)$ Then, we enter a loop, and forgive me if this is a little confusing. For each element $i$ in noisy , do the following things: $m_i = e^{-\beta} \\  \gamma = \sqrt{\frac{\sigma^2(1-m_i^2)}{2\beta}} \\  \phi = m_i \\ \overline{\eta} = \phi \cdot filtered(i) \\ \overline{p}_i = \phi \cdot p \cdot (\phi + \gamma) \cdot q \cdot \gamma \\ k = \frac{\overline{p}_i}{\overline{p}_i + 1} \\  filtered[i] = \overline{\eta} + k \cdot (noisy[i] - \overline\eta) \\ p = k$ Does anyone recognize anything from this math/code sample? The filter seems to work (I wrote a simple moving average filter and compared the two and it looks pretty good to me). Thanks in advance!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I have a piece of code that takes a noisy data set and uses some sort of statistical filter to plot a trend line over the noisy data. The original author of the code no longer works at my job, so I can't ask him what the filter is. I've included a math-ified version of his code, and I would love to know what the filter is called so I can learn more about it . Here's a code/math snippet. First, a bunch of variables are set. The first element of filtered is set to just be the average of the noisy data, just so we have a value to use in the first iteration of the loop. filtered will contain all the filtered points from the noisy dataset called noisy . $\beta = 0.00001 \\ \sigma = 0.005 \\  \overline{p}_0 = 1 \\ q = 1 \\ k = \frac{\overline{p}_0}{\overline{p}_0 + 1} \\ p = k \\  filtered[0] = avg(noisy)$ Then, we enter a loop, and forgive me if this is a little confusing. For each element $i$ in noisy , do the following things: $m_i = e^{-\beta} \\  \gamma = \sqrt{\frac{\sigma^2(1-m_i^2)}{2\beta}} \\  \phi = m_i \\ \overline{\eta} = \phi \cdot filtered(i) \\ \overline{p}_i = \phi \cdot p \cdot (\phi + \gamma) \cdot q \cdot \gamma \\ k = \frac{\overline{p}_i}{\overline{p}_i + 1} \\  filtered[i] = \overline{\eta} + k \cdot (noisy[i] - \overline\eta) \\ p = k$ Does anyone recognize anything from this math/code sample? The filter seems to work (I wrote a simple moving average filter and compared the two and it looks pretty good to me). Thanks in advance!",,['statistics']
89,What do the parameters of a multinomial logistic regression correspond to?,What do the parameters of a multinomial logistic regression correspond to?,,"I've recently started learning about data science/statistics and learned how to derive such models as linear regressors and logistic regressors. What I don't understand, however, is what the parameters that are calculated in a logistic regression correspond to. For instance, it's simple in linear regressors in which $X \in \mathbb{R}^{2\times n}$ with $n$ training examples and $y\in\mathbb{R}^{1\times n}$. So long as the $X_0$ (the first column of X) is all ones and the second column correspond to the X coordinates and y contains the y coordinates of the examples, the calculated parameters in linear regression are in the shape of $\theta\in\mathbb{R}^{1\times 2}$. Clearly, $\theta_0 = b, \theta_1 = m$ as the regression on a linear equation $y=mx+b$. Furthermore, the parameterization of linear regression makes clear sense to me because the calculated parameters in $\theta$ directly correspond to coefficients in the line function. However, I have a lot of trouble understanding what the parameters calculated by multinomial logistic regression correspond to. I understand that logistic regression is used for classification and that the parameters calculated must in some way distinguish between the classes based on the input data, but I don't quite understand how. A graphical explanation would be preferred if possible :) Thanks in advance!","I've recently started learning about data science/statistics and learned how to derive such models as linear regressors and logistic regressors. What I don't understand, however, is what the parameters that are calculated in a logistic regression correspond to. For instance, it's simple in linear regressors in which $X \in \mathbb{R}^{2\times n}$ with $n$ training examples and $y\in\mathbb{R}^{1\times n}$. So long as the $X_0$ (the first column of X) is all ones and the second column correspond to the X coordinates and y contains the y coordinates of the examples, the calculated parameters in linear regression are in the shape of $\theta\in\mathbb{R}^{1\times 2}$. Clearly, $\theta_0 = b, \theta_1 = m$ as the regression on a linear equation $y=mx+b$. Furthermore, the parameterization of linear regression makes clear sense to me because the calculated parameters in $\theta$ directly correspond to coefficients in the line function. However, I have a lot of trouble understanding what the parameters calculated by multinomial logistic regression correspond to. I understand that logistic regression is used for classification and that the parameters calculated must in some way distinguish between the classes based on the input data, but I don't quite understand how. A graphical explanation would be preferred if possible :) Thanks in advance!",,"['linear-algebra', 'matrices', 'statistics', 'data-analysis', 'logistic-regression']"
90,prove a continuous mapping theorem for $g_n(X_n)\stackrel{d}{\to}g(X)$?,prove a continuous mapping theorem for ?,g_n(X_n)\stackrel{d}{\to}g(X),"Suppose that $X_n\stackrel{d}{\to}X$ where $X_n,X$ take value in a metric space $(\mathbb{D},d)$. We know from continuous mapping theorem that if $g:\mathbb{D}\to\mathbb{E}$ is a fixed continuous function (independent of $n$), where $\mathbb{E}$ is another metric space, then $g(X_n)\stackrel{d}{\to} g(X)$ as $n\to\infty$. My question: Let $\{g_n\}_{n\in\mathbb{N}}$ be a sequence of continuous functions such that $g_n\to g$ ""pointwisely"" on $\mathbb{D}$. Can one conclude that  $$ g_n(X_n)\stackrel{d}{\to}g(X)? $$ If not, is there a counterexample? The proof for the classical continuous mapping theorem uses portmanteau theorem (see the proof of Theorem 1.3.6 on p.20 of van der Vaart and Wellner (1996)). For example, one can prove $g(X_n)\stackrel{d}{\to} g(X)$ by showing that for any closed $F\subset\mathbb{D}$, $$ \limsup P(g_n(X_n)\in F) = \limsup P(X_n\in g_n^{-1}(F)) \stackrel{?}{\leq} P(g(X)\in F). $$ where ""$\stackrel{?}{\leq}$"" is the inequality that I do not know how to show (perhaps not true). Another fact that might be useful is $\limsup P(X_n\in g_n^{-1}(F))\leq P(\limsup\{X_n\in g_n^{-1}(F)\})$. Thank you!","Suppose that $X_n\stackrel{d}{\to}X$ where $X_n,X$ take value in a metric space $(\mathbb{D},d)$. We know from continuous mapping theorem that if $g:\mathbb{D}\to\mathbb{E}$ is a fixed continuous function (independent of $n$), where $\mathbb{E}$ is another metric space, then $g(X_n)\stackrel{d}{\to} g(X)$ as $n\to\infty$. My question: Let $\{g_n\}_{n\in\mathbb{N}}$ be a sequence of continuous functions such that $g_n\to g$ ""pointwisely"" on $\mathbb{D}$. Can one conclude that  $$ g_n(X_n)\stackrel{d}{\to}g(X)? $$ If not, is there a counterexample? The proof for the classical continuous mapping theorem uses portmanteau theorem (see the proof of Theorem 1.3.6 on p.20 of van der Vaart and Wellner (1996)). For example, one can prove $g(X_n)\stackrel{d}{\to} g(X)$ by showing that for any closed $F\subset\mathbb{D}$, $$ \limsup P(g_n(X_n)\in F) = \limsup P(X_n\in g_n^{-1}(F)) \stackrel{?}{\leq} P(g(X)\in F). $$ where ""$\stackrel{?}{\leq}$"" is the inequality that I do not know how to show (perhaps not true). Another fact that might be useful is $\limsup P(X_n\in g_n^{-1}(F))\leq P(\limsup\{X_n\in g_n^{-1}(F)\})$. Thank you!",,"['probability', 'statistics']"
91,Sampling from the space of positive definite matrices,Sampling from the space of positive definite matrices,,"Is there a way to sample from a probability distribution on the space of positive definite $3\times3$ matrices with some constraints? I'm looking for any examples of such schemes. In particular, I'd be interested in looking at matrices with $\alpha_1 < \det(M) < \alpha_2$ and $ \beta_1 < \text{tr}(M) < \beta_2 $, where $\alpha_i,\beta_i >0$.  I am aware these may not be sufficient to bound the space. It would be nice to not only have a uniform distribution on such a space, but also have a Gaussian-like distribution (where I would have some matrix $M$ set as the mean of the distribution, such that one could sample around it). But any thoughts/literature on the topic would be nice. I suspect it might be easier if $M$ were symmetric. Initial ideas: since  $ \text{tr}(M) = \sum_i\lambda_i $ and $\det(M)= \prod_i\lambda_i$, I was thinking of drawing random eigenvalues such that the constraints are satisfied. Another constraint may need to be added (3 constraints for 3 eigenvalues). Then I would sample $P$ as an orthogonal matrix and take $P\,\text{diag}(\lambda)P^{-1}$ (not sure this is the right thing to do). However, I have no idea how ""uniform"" such a distribution would be in the space of PD matrices, nor does this seem very efficient. Further, whether it covers the whole space is not clear. Edit 1: the ""Related"" questions bar suggested this question , which is similar but restricted to symmetric matrices. It links to the Wishart distribution , which led me to the matrix Gamma distribution and inverse matrix Gamma distribution . It would be nice to find something allowing sampling from asymmetric PD matrices. On the other hand, a matrix $M$ is PD iff its symmetrized version $M+M^T$ is PD. (e.g. here ). (Maybe this can come in handy? E.g. if one specifies the eigenvalues, could one generate an SPD matrix, and then perturb it in a principled way).","Is there a way to sample from a probability distribution on the space of positive definite $3\times3$ matrices with some constraints? I'm looking for any examples of such schemes. In particular, I'd be interested in looking at matrices with $\alpha_1 < \det(M) < \alpha_2$ and $ \beta_1 < \text{tr}(M) < \beta_2 $, where $\alpha_i,\beta_i >0$.  I am aware these may not be sufficient to bound the space. It would be nice to not only have a uniform distribution on such a space, but also have a Gaussian-like distribution (where I would have some matrix $M$ set as the mean of the distribution, such that one could sample around it). But any thoughts/literature on the topic would be nice. I suspect it might be easier if $M$ were symmetric. Initial ideas: since  $ \text{tr}(M) = \sum_i\lambda_i $ and $\det(M)= \prod_i\lambda_i$, I was thinking of drawing random eigenvalues such that the constraints are satisfied. Another constraint may need to be added (3 constraints for 3 eigenvalues). Then I would sample $P$ as an orthogonal matrix and take $P\,\text{diag}(\lambda)P^{-1}$ (not sure this is the right thing to do). However, I have no idea how ""uniform"" such a distribution would be in the space of PD matrices, nor does this seem very efficient. Further, whether it covers the whole space is not clear. Edit 1: the ""Related"" questions bar suggested this question , which is similar but restricted to symmetric matrices. It links to the Wishart distribution , which led me to the matrix Gamma distribution and inverse matrix Gamma distribution . It would be nice to find something allowing sampling from asymmetric PD matrices. On the other hand, a matrix $M$ is PD iff its symmetrized version $M+M^T$ is PD. (e.g. here ). (Maybe this can come in handy? E.g. if one specifies the eigenvalues, could one generate an SPD matrix, and then perturb it in a principled way).",,"['matrices', 'statistics', 'sampling', 'positive-definite', 'random-matrices']"
92,Calculating Total variation distance between two multivariate probability density?,Calculating Total variation distance between two multivariate probability density?,,"There are several probability metrics such as KL Divergence, and Hellinger distance that can be calculated in a closed form equation when two distributions are multivariate normal. With those metrics, some useful bounds for TV distance are already known. However, I want to calculate the metric(specifically TV distance) directly in a countable space(discrete) with its definition if it is possible. First, I'm trying to think with not that complicated examples which includes two random vector have +1 and -1 in each elements with probability 1/2. If there are some empirical calculation tutorials or related references of Total variation distance or other probability metrics, please let me know.","There are several probability metrics such as KL Divergence, and Hellinger distance that can be calculated in a closed form equation when two distributions are multivariate normal. With those metrics, some useful bounds for TV distance are already known. However, I want to calculate the metric(specifically TV distance) directly in a countable space(discrete) with its definition if it is possible. First, I'm trying to think with not that complicated examples which includes two random vector have +1 and -1 in each elements with probability 1/2. If there are some empirical calculation tutorials or related references of Total variation distance or other probability metrics, please let me know.",,"['probability', 'statistics']"
93,Probability that the number of different-colored cards in two decks is equal,Probability that the number of different-colored cards in two decks is equal,,"After googling a bit and filling up a couple pieces of scratch paper, I haven't found a way to prove my intuition of the solution to this problem. Take two normal identical decks of cards (52 each), combine them, and shuffle them randomly. Then cut the combined deck of 104 cards in half, giving you new decks A & B. 1) What is the probability that the number of red cards in deck A is equal the number of black cards in deck B? 2) How many cards would one have to check to ensure that those two numbers are equal? Say we call X: the number of red cards in deck A, X': the number of black cards in deck A, Y: the number of red cards in deck B, and Y': the number of black cards in deck B. For part 1, my intuition says that P(X == Y') = 1, since X is always equal to Y': X = 0    X' = 52   Y = 52   Y' = 0, X = 1    X' = 51   Y = 51   Y' = 1, ..., X = 51   X' = 1    Y = 1    Y' = 51, X = 52   X' = 0    Y = 0    Y' = 52. And for part 2, my intuition says 52, because you couldn't know if you've seen all the cards of whichever color you're looking for in whichever deck you're looking through until you look at all the cards in that deck. So my ultimate question is twofold: is my intuition correct, and how would I prove those answers? Does proving that P(X == Y') = 1 have something with a cdf and/or stats-related calculations, or could you just use an induction-ish (sort of like the above table) proof?","After googling a bit and filling up a couple pieces of scratch paper, I haven't found a way to prove my intuition of the solution to this problem. Take two normal identical decks of cards (52 each), combine them, and shuffle them randomly. Then cut the combined deck of 104 cards in half, giving you new decks A & B. 1) What is the probability that the number of red cards in deck A is equal the number of black cards in deck B? 2) How many cards would one have to check to ensure that those two numbers are equal? Say we call X: the number of red cards in deck A, X': the number of black cards in deck A, Y: the number of red cards in deck B, and Y': the number of black cards in deck B. For part 1, my intuition says that P(X == Y') = 1, since X is always equal to Y': X = 0    X' = 52   Y = 52   Y' = 0, X = 1    X' = 51   Y = 51   Y' = 1, ..., X = 51   X' = 1    Y = 1    Y' = 51, X = 52   X' = 0    Y = 0    Y' = 52. And for part 2, my intuition says 52, because you couldn't know if you've seen all the cards of whichever color you're looking for in whichever deck you're looking through until you look at all the cards in that deck. So my ultimate question is twofold: is my intuition correct, and how would I prove those answers? Does proving that P(X == Y') = 1 have something with a cdf and/or stats-related calculations, or could you just use an induction-ish (sort of like the above table) proof?",,"['probability', 'statistics', 'proof-writing']"
94,"Pearson Correlation Coefficient for samples $X,Y$ equals $1$ iff there is $a>0, b\in \mathbb{R}$ with $x_i = ay_i + b$ for every $i=1,\dots,n$.",Pearson Correlation Coefficient for samples  equals  iff there is  with  for every .,"X,Y 1 a>0, b\in \mathbb{R} x_i = ay_i + b i=1,\dots,n","Let $X = (x_1,\dots,x_n)$ and $Y = (y_1,\dots,y_n)$ be outcome values. We have defined the variances $s^2_X = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$, $s^2_Y = \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar{y})^2$, the covariance $s_{XY} = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})$ and the correlation coefficient $r_{XY} = \dfrac{s_{XY}}{s_X s_Y}$. The if-direction was rather easy to show but I have trouble with the other direction. I do not know how to find $a>0, b \in \mathbb{R}$ or how to use my precondition $r_{XY}=1$ or how to show the equality for every sample unit. Could anyone help me with this problem? Thank you.","Let $X = (x_1,\dots,x_n)$ and $Y = (y_1,\dots,y_n)$ be outcome values. We have defined the variances $s^2_X = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2$, $s^2_Y = \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar{y})^2$, the covariance $s_{XY} = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})$ and the correlation coefficient $r_{XY} = \dfrac{s_{XY}}{s_X s_Y}$. The if-direction was rather easy to show but I have trouble with the other direction. I do not know how to find $a>0, b \in \mathbb{R}$ or how to use my precondition $r_{XY}=1$ or how to show the equality for every sample unit. Could anyone help me with this problem? Thank you.",,"['statistics', 'discrete-mathematics', 'correlation', 'descriptive-statistics']"
95,Linear transformation of a random vector with pseudo-inverse,Linear transformation of a random vector with pseudo-inverse,,"I have already asked this question in cross-validated, but nobody answered, so I thought I may have more luck here. If $$ \mathbf{X} = (X_1,\ldots,X_n)^t$$ is a random variable drawn according to a probability density function (pdf) $$ f_{X_1,\ldots,X_n}(x_1,\ldots,x_n) $$ then $$ \mathbf{Y} = A\mathbf{X} = (Y_1,\ldots,Y_n)^t$$ with $A$ a square non-singular matrix, has a pdf given by: $$ f_{Y_1,\ldots,Y_n}(y_1,\ldots,y_n)=\frac{f_\mathbf{X}(A^{-1} \mathbf{y})}{|A|} $$ I have heard that this can be generalised to the case of a non-square matrix with the Moore–Penrose pseudo-inverse concept, where now $$ \mathbf{Y} = A\mathbf{X} = (Y_1,\ldots,Y_m)^t \qquad m<n $$ and  $$ f_{Y_1,\ldots,Y_m}(y_1,\ldots,y_m)=\frac{f_\mathbf{X}(A^{+} \mathbf{y})}{|A|_{+}} $$  with $A^+$ the pseudo-inverse of $A$ and $|A|_{+}$ the pseudo-determinant. If this is right, how can it be proved? and more important, what is the intuition behind this generalisation? I've only found this related question, but I can't understand how the OP finds the general expression for $f_{Y_1,\ldots,Y_m}(y_1,\ldots,y_m)$.","I have already asked this question in cross-validated, but nobody answered, so I thought I may have more luck here. If $$ \mathbf{X} = (X_1,\ldots,X_n)^t$$ is a random variable drawn according to a probability density function (pdf) $$ f_{X_1,\ldots,X_n}(x_1,\ldots,x_n) $$ then $$ \mathbf{Y} = A\mathbf{X} = (Y_1,\ldots,Y_n)^t$$ with $A$ a square non-singular matrix, has a pdf given by: $$ f_{Y_1,\ldots,Y_n}(y_1,\ldots,y_n)=\frac{f_\mathbf{X}(A^{-1} \mathbf{y})}{|A|} $$ I have heard that this can be generalised to the case of a non-square matrix with the Moore–Penrose pseudo-inverse concept, where now $$ \mathbf{Y} = A\mathbf{X} = (Y_1,\ldots,Y_m)^t \qquad m<n $$ and  $$ f_{Y_1,\ldots,Y_m}(y_1,\ldots,y_m)=\frac{f_\mathbf{X}(A^{+} \mathbf{y})}{|A|_{+}} $$  with $A^+$ the pseudo-inverse of $A$ and $|A|_{+}$ the pseudo-determinant. If this is right, how can it be proved? and more important, what is the intuition behind this generalisation? I've only found this related question, but I can't understand how the OP finds the general expression for $f_{Y_1,\ldots,Y_m}(y_1,\ldots,y_m)$.",,"['statistics', 'probability-distributions', 'linear-transformations']"
96,"Reference request on statistical convergence, asymptotics","Reference request on statistical convergence, asymptotics",,"I'm looking for good literature on asymptotics in statistics. I've learned about alsmost sure convergence, convergence in probability, convergence in law, $O_p, o_p$, etc... Definitions, theorems and limited examples. But besides the definitions I don't feel that I get what the true meaning of these concepts implies... Can someone give me a good reference which truly explains these concepts by means of graphs , intuition and perhaps simulation .","I'm looking for good literature on asymptotics in statistics. I've learned about alsmost sure convergence, convergence in probability, convergence in law, $O_p, o_p$, etc... Definitions, theorems and limited examples. But besides the definitions I don't feel that I get what the true meaning of these concepts implies... Can someone give me a good reference which truly explains these concepts by means of graphs , intuition and perhaps simulation .",,"['statistics', 'reference-request', 'asymptotics']"
97,Find the variance of sum of indicator variables,Find the variance of sum of indicator variables,,"Compute $\operatorname{Var} (X)$ where $X = \sum_{i=1}^n x_i$ I am aware of the formula $$\operatorname{Var} (X) = \sum_{i=1}^9 \operatorname{Var} (X_i) + \sum_{i \ne j} \operatorname{Cov } (X_i, X_j)$$ But I cannot seem to apply it here Edit: We know that $\text{Var } (X_i) = 0.234$ Thus $\sum_{i=1}^{9} \text{Var} (X_i) = 9 \times 0.234 = 2.106$ $\displaystyle \sum_{i \ne j} \text{Cov} (X_i, X_j)$ , we know that if $j > i + 1$ then $\text{Cov} (X_i, X_j) = 0$ , thus $\sum = 9 \times 0.046875 = 0.4219$ Thus $\text{Var} (X) = 9 \times 0.2344 + 0.421875 = 2.53$","Compute where I am aware of the formula But I cannot seem to apply it here Edit: We know that Thus , we know that if then , thus Thus","\operatorname{Var} (X) X = \sum_{i=1}^n x_i \operatorname{Var} (X) = \sum_{i=1}^9 \operatorname{Var} (X_i) + \sum_{i \ne j} \operatorname{Cov } (X_i, X_j) \text{Var } (X_i) = 0.234 \sum_{i=1}^{9} \text{Var} (X_i) = 9 \times 0.234 = 2.106 \displaystyle \sum_{i \ne j} \text{Cov} (X_i, X_j) j > i + 1 \text{Cov} (X_i, X_j) = 0 \sum = 9 \times 0.046875 = 0.4219 \text{Var} (X) = 9 \times 0.2344 + 0.421875 = 2.53","['probability', 'statistics']"
98,Is there any quick way to derive the maximum likelihood estimator in the following example?,Is there any quick way to derive the maximum likelihood estimator in the following example?,,"Let's say we are given a sample: $Z_1,Z_2,\cdots,Z_n$. We know their joint distribution is $$ \begin{bmatrix} Z_1\\ Z_2\\ \vdots\\ Z_n \end{bmatrix} \sim N\left(0, \begin{bmatrix} \sigma^2+2\omega^2 & -\omega^2 & 0 & 0 &\cdots & 0\\ -\omega^2 & \sigma^2+2\omega^2 & -\omega^2 & 0 &\cdots & 0\\ 0 & -\omega^2 & \sigma^2+2\omega^2 & -\omega^2 & \cdots & 0\\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots\\ 0 & \cdots &\cdots &\cdots & -\omega^2 & \sigma^2 + 2\omega^2 \\ \end{bmatrix} \right) $$ and want to derive the maximum likelihood estimator for both $\sigma^2$ and $\omega^2$. If we put $\Sigma$ as the covariance matrix of the sample, we may get a closed-form solution for $|\Sigma|$ and $\Sigma^{-1}$. Since it's a tridiagonal matrix, what I usually do is to use the formulas for determinants and inverse of block matrix inductively. Then we should be able to get the first order conditions and then solve for the MLE. However, I doubt if such method is too laboursome. At the very first glance, I guess that the MLE should be the same as moment estimator. That is, $$ \begin{bmatrix} \hat{\sigma}^2_{ML}\\ \hat{\omega}^2_{ML}\\ \end{bmatrix} = \begin{bmatrix} \frac{1}{n} \sum_{j=1}^n Z_j^2 + \frac{2}{n-1} \sum_{j=2}^n Z_j Z_{j-1} \\ -\frac{2}{n-1} \sum_{j=2}^n Z_j Z_{j-1} \end{bmatrix} $$ Now my question is: if my guess is correct, is there any quick way to derive the maximum likelihood estimator than to do the tedious derivation? Or maybe I'm wrong, that is, $|\Sigma|$ and $\Sigma^{-1}$ can be easily solved? Any help will be greatly appreciated!","Let's say we are given a sample: $Z_1,Z_2,\cdots,Z_n$. We know their joint distribution is $$ \begin{bmatrix} Z_1\\ Z_2\\ \vdots\\ Z_n \end{bmatrix} \sim N\left(0, \begin{bmatrix} \sigma^2+2\omega^2 & -\omega^2 & 0 & 0 &\cdots & 0\\ -\omega^2 & \sigma^2+2\omega^2 & -\omega^2 & 0 &\cdots & 0\\ 0 & -\omega^2 & \sigma^2+2\omega^2 & -\omega^2 & \cdots & 0\\ \cdots & \cdots & \cdots & \cdots & \cdots & \cdots\\ 0 & \cdots &\cdots &\cdots & -\omega^2 & \sigma^2 + 2\omega^2 \\ \end{bmatrix} \right) $$ and want to derive the maximum likelihood estimator for both $\sigma^2$ and $\omega^2$. If we put $\Sigma$ as the covariance matrix of the sample, we may get a closed-form solution for $|\Sigma|$ and $\Sigma^{-1}$. Since it's a tridiagonal matrix, what I usually do is to use the formulas for determinants and inverse of block matrix inductively. Then we should be able to get the first order conditions and then solve for the MLE. However, I doubt if such method is too laboursome. At the very first glance, I guess that the MLE should be the same as moment estimator. That is, $$ \begin{bmatrix} \hat{\sigma}^2_{ML}\\ \hat{\omega}^2_{ML}\\ \end{bmatrix} = \begin{bmatrix} \frac{1}{n} \sum_{j=1}^n Z_j^2 + \frac{2}{n-1} \sum_{j=2}^n Z_j Z_{j-1} \\ -\frac{2}{n-1} \sum_{j=2}^n Z_j Z_{j-1} \end{bmatrix} $$ Now my question is: if my guess is correct, is there any quick way to derive the maximum likelihood estimator than to do the tedious derivation? Or maybe I'm wrong, that is, $|\Sigma|$ and $\Sigma^{-1}$ can be easily solved? Any help will be greatly appreciated!",,"['linear-algebra', 'probability', 'statistics']"
99,Ranges given instead of exact values in survey,Ranges given instead of exact values in survey,,"I gave a survey wherein one data there is stated as to how often do individuals watch tv in a day. I was hoping to get exact values from the individuals but some of them put ranges like 1-5 times in a day. Given that, how can I get the average of the data? Should I average each ranges? Thanks in advance","I gave a survey wherein one data there is stated as to how often do individuals watch tv in a day. I was hoping to get exact values from the individuals but some of them put ranges like 1-5 times in a day. Given that, how can I get the average of the data? Should I average each ranges? Thanks in advance",,"['statistics', 'statistical-inference', 'descriptive-statistics']"
