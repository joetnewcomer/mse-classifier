,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Show how the probability that an 8 character password contains exactly 1 OR 2 integers is .630,Show how the probability that an 8 character password contains exactly 1 OR 2 integers is .630,,A password is 8 characters long. Each character can contain 26 lower case or 26 uppercase letters or a integer from 0-9. What is the probability that an 8 character password contains exactly 1 OR 2 integers? Please explain as the book answer is P = .630 Assuming that I could use (52^6*10^2+52^7*10)/62^8 was incorrect. This is the sum of the product between the possibilities of having one integer in the password and having two integers in the password; 62^8 is the total possibilities given each character can be a lower/uppercase or integer.,A password is 8 characters long. Each character can contain 26 lower case or 26 uppercase letters or a integer from 0-9. What is the probability that an 8 character password contains exactly 1 OR 2 integers? Please explain as the book answer is P = .630 Assuming that I could use (52^6*10^2+52^7*10)/62^8 was incorrect. This is the sum of the product between the possibilities of having one integer in the password and having two integers in the password; 62^8 is the total possibilities given each character can be a lower/uppercase or integer.,,"['probability', 'combinatorics', 'combinations']"
1,Integrating brownian motion times exponential function,Integrating brownian motion times exponential function,,"I am trying to calculate $$\int_0^tB_se^{\lambda s}ds$$ but I am unsure of how to start the computation. The motivation behind this is that I read (and am now trying to prove) that $$\lim_{\lambda\to\infty}\sup_{t\in[0,T]}| e^{-\lambda t}\int_0^te^{\lambda s}dB_s|=0 $$ So far I have used Ito's formula to simplify the expression inside the absolute values to $$\lambda e^{-\lambda t}\int_0^t e^{\lambda s}B_sds - B_t $$ and am now trying to evaluate the expression so that I can take the supremum and then the limit. Thank you for any help!","I am trying to calculate $$\int_0^tB_se^{\lambda s}ds$$ but I am unsure of how to start the computation. The motivation behind this is that I read (and am now trying to prove) that $$\lim_{\lambda\to\infty}\sup_{t\in[0,T]}| e^{-\lambda t}\int_0^te^{\lambda s}dB_s|=0 $$ So far I have used Ito's formula to simplify the expression inside the absolute values to $$\lambda e^{-\lambda t}\int_0^t e^{\lambda s}B_sds - B_t $$ and am now trying to evaluate the expression so that I can take the supremum and then the limit. Thank you for any help!",,"['probability', 'probability-theory', 'stochastic-calculus', 'brownian-motion', 'stochastic-integrals']"
2,Proving the Kochen-Stone lemma using the Paley-Zygmund inequality,Proving the Kochen-Stone lemma using the Paley-Zygmund inequality,,"I am trying to understand a proof to a lemma by Kochen and Stone which appears here , using the Paley-Zygmund inequality . I'll repeat the proof in a detailed manner, and explain what bothers me about it. Lemma (Kochen-Stone). $\ $ Let $A_n$ be a sequence of events with $\sum\mathbb{P}(A_n)=\infty$ and \begin{equation*}   \liminf_{k\to\infty}\frac{\sum_{1\le m,n \le k}\mathbb{P}(A_m\cap   A_n)}{\left(\sum_{n=1}^k\mathbb{P}(A_n)\right)^2}<\infty \end{equation*} then, there is a positive probability that $A_n$ occur infinitely often. Proof (partial). $\ $ Fix $\ell<k$. Let $X=\sum_{n=\ell}^{k}1_{A_n}$; it follows that \begin{equation*}   \mathbb{E}(X)=\sum_{n=\ell}^{k}\mathbb(A_n) \end{equation*} and \begin{equation*}   \mathbb{E}(X^2)=\sum_{\ell\le m,n \le k}\mathbb{P}(A_n\cap A_m). \end{equation*} Using Paley-Zygmund inequality for $\theta=0$ (it's not mentioned in the wikipedia page, but the inequality holds for $\theta=0$ as well), we obtain \begin{eqnarray*}   \mathbb{P}\left(\bigcup_{n=\ell}^{k}A_n\right)   &=& \mathbb{P}(X>0)\\   &\ge& \frac{\left(\sum_{n=\ell}^{k}\mathbb{P}(A_n)\right)^2}            {\sum_{\ell\le m,n \le k}\mathbb{P}(A_n\cap A_m)}\\   &\ge& \frac{\left(\sum_{n=1}^{k}\mathbb{P}(A_n)             -\sum_{n=1}^{\ell-1}\mathbb{P}(A_n)\right)^2}            {\sum_{1\le m,n \le k}\mathbb(A_n\cap A_m)             -\sum_{1\le m,n < \ell}\mathbb(A_n\cap A_m)} \end{eqnarray*} Now, it holds that $\mathbb{P}(A_n\text{ occurs i.o.}) = \lim_{\ell\to\infty}\lim_{k\to\infty}\mathbb{P}\left(\bigcup_{n=\ell}^{k}A_n\right)$; however, I can't see how I can bound that probability away from 0. Am I missing some minor detail here?","I am trying to understand a proof to a lemma by Kochen and Stone which appears here , using the Paley-Zygmund inequality . I'll repeat the proof in a detailed manner, and explain what bothers me about it. Lemma (Kochen-Stone). $\ $ Let $A_n$ be a sequence of events with $\sum\mathbb{P}(A_n)=\infty$ and \begin{equation*}   \liminf_{k\to\infty}\frac{\sum_{1\le m,n \le k}\mathbb{P}(A_m\cap   A_n)}{\left(\sum_{n=1}^k\mathbb{P}(A_n)\right)^2}<\infty \end{equation*} then, there is a positive probability that $A_n$ occur infinitely often. Proof (partial). $\ $ Fix $\ell<k$. Let $X=\sum_{n=\ell}^{k}1_{A_n}$; it follows that \begin{equation*}   \mathbb{E}(X)=\sum_{n=\ell}^{k}\mathbb(A_n) \end{equation*} and \begin{equation*}   \mathbb{E}(X^2)=\sum_{\ell\le m,n \le k}\mathbb{P}(A_n\cap A_m). \end{equation*} Using Paley-Zygmund inequality for $\theta=0$ (it's not mentioned in the wikipedia page, but the inequality holds for $\theta=0$ as well), we obtain \begin{eqnarray*}   \mathbb{P}\left(\bigcup_{n=\ell}^{k}A_n\right)   &=& \mathbb{P}(X>0)\\   &\ge& \frac{\left(\sum_{n=\ell}^{k}\mathbb{P}(A_n)\right)^2}            {\sum_{\ell\le m,n \le k}\mathbb{P}(A_n\cap A_m)}\\   &\ge& \frac{\left(\sum_{n=1}^{k}\mathbb{P}(A_n)             -\sum_{n=1}^{\ell-1}\mathbb{P}(A_n)\right)^2}            {\sum_{1\le m,n \le k}\mathbb(A_n\cap A_m)             -\sum_{1\le m,n < \ell}\mathbb(A_n\cap A_m)} \end{eqnarray*} Now, it holds that $\mathbb{P}(A_n\text{ occurs i.o.}) = \lim_{\ell\to\infty}\lim_{k\to\infty}\mathbb{P}\left(\bigcup_{n=\ell}^{k}A_n\right)$; however, I can't see how I can bound that probability away from 0. Am I missing some minor detail here?",,"['probability', 'inequality', 'limsup-and-liminf']"
3,Probabilities for clock visits based on coin flips,Probabilities for clock visits based on coin flips,,"We have a fair coin, and start at the 12 o'clock marker on a clock. At each step, flip the coin. If heads, move clockwise, if tails move counter-clockwise. As you land on a number, mark that number as visited. Which number(s) on the clock has the highest probability of being the last one to be visited? Which one has the lowest? Alternatively, what are the probabilities of each number being the last one to be visited? I ran some simulations in python. The probabilities seem evenly distributed across 2-10 and 12, but half as big for 1 and 11. My intuition tells me that 6 might be the reasonable choice for ""most likely to be last"", but intuition isn't very good for probability.","We have a fair coin, and start at the 12 o'clock marker on a clock. At each step, flip the coin. If heads, move clockwise, if tails move counter-clockwise. As you land on a number, mark that number as visited. Which number(s) on the clock has the highest probability of being the last one to be visited? Which one has the lowest? Alternatively, what are the probabilities of each number being the last one to be visited? I ran some simulations in python. The probabilities seem evenly distributed across 2-10 and 12, but half as big for 1 and 11. My intuition tells me that 6 might be the reasonable choice for ""most likely to be last"", but intuition isn't very good for probability.",,['probability']
4,Expected number of bridges,Expected number of bridges,,There are 10 islands in a row. Each island is linked to the successive one by 2 bridges. One of these two is the correct bridge i.e. it will take you to the other side. The other is a bad bridge i.e. if you take that one you will be taken back to the first island and will have to start over again. The probability of any of the two connecting bridges being good or bad is 0.5.What is the expected number of bridges that you need to cross before reaching the last island ? Also once you have crossed a bridge you remember it to be good or bad so that you are not crossing the bad bridges more than once. Any help is appreciated. Thank you.,There are 10 islands in a row. Each island is linked to the successive one by 2 bridges. One of these two is the correct bridge i.e. it will take you to the other side. The other is a bad bridge i.e. if you take that one you will be taken back to the first island and will have to start over again. The probability of any of the two connecting bridges being good or bad is 0.5.What is the expected number of bridges that you need to cross before reaching the last island ? Also once you have crossed a bridge you remember it to be good or bad so that you are not crossing the bad bridges more than once. Any help is appreciated. Thank you.,,"['probability', 'statistics']"
5,Probability question with bounds?,Probability question with bounds?,,"If I am given that on Saturday there is 0.6 probability of raining and 0.7 probability of raining on Sunday, then there is a 0.88 chance that it will rain at least one of the days (this is using independence assumption). However, what if nothing about their probability structures were known? Ie. they could be negatively correlated. They could be correlated with $r=1$. What would be the bounds on the probability of it raining at least one day? Im thinking $0.7,0.88$?","If I am given that on Saturday there is 0.6 probability of raining and 0.7 probability of raining on Sunday, then there is a 0.88 chance that it will rain at least one of the days (this is using independence assumption). However, what if nothing about their probability structures were known? Ie. they could be negatively correlated. They could be correlated with $r=1$. What would be the bounds on the probability of it raining at least one day? Im thinking $0.7,0.88$?",,"['probability', 'probability-theory']"
6,M/M/3 queue - reducing wait time by adding servers,M/M/3 queue - reducing wait time by adding servers,,"Full question below: You are the manager of the customer support division in your company. Your division uses 3 telephone lines operated by 3 separate customer service representatives. A customer is put on hold if their call arrives while all 3 customer service representatives are busy serving other customers. You observe that customer calls arrive at a Poisson rate of 5 per hour, and that the length of the customer calls is exponentially distributed. You also observe that 75% of the time, a customer is not put on hold, while the remaining 25% of the time, a customer can expected to be put on hold for an average of 12 minutes. You wish to improve service in the division by making sure that 90% of the time, a customer is not put on hold, while 10% of the time, a customer can expect to be put on hold for an average of only 4 minutes. How many telephone lines will you add to your division to achieve your goal? So I think the biggest problem here is that I don't know $\mu$.  I do know $\rho=\frac{\lambda}{c\mu}=\frac{5}{3\mu}$ for this problem.  I understand that ""time on hold"" refers to to time waiting in the queue.  With $W$ is time waiting in the queue, I know: $$E[W]=\frac{\rho}{\lambda(1-\rho)}P(W>0)$$ With 3 operators, I used the fact that ""75% of the time, a customer is not put on hold, while the remaining 25% of the time, a customer can expected to be put on hold for an average of 12 minutes"" to calculate: $$E[W]=.75(0) + .25(12min)=3min$$ Then using $E[W]$ along with $P(W>0)=.25$, I solved the first equation to find $\mu=\frac{10}{3}$. Knowing $u$, I used ""90% of the time, a customer is not put on hold, while 10% of the time, a customer can expect to be put on hold for an average of only 4 minutes"" to find the new $E[W]=1min$ and $P(W>0)=.1$. To solve for $c$(number of servers) I again plugged these numbers into the original equation for $E[W]$ and found $c=3.3$. You can obviously only have an integer number of servers, so this would be $c=4$, and minus the original 3 would give the addition of just 1 server as the answer. Sorry for the long question, but am I doing this right?  I feel like I messed up along the way or made some wrong assumptions (mostly that $E[W] can be calculated from the information in the problem). Thanks for looking.","Full question below: You are the manager of the customer support division in your company. Your division uses 3 telephone lines operated by 3 separate customer service representatives. A customer is put on hold if their call arrives while all 3 customer service representatives are busy serving other customers. You observe that customer calls arrive at a Poisson rate of 5 per hour, and that the length of the customer calls is exponentially distributed. You also observe that 75% of the time, a customer is not put on hold, while the remaining 25% of the time, a customer can expected to be put on hold for an average of 12 minutes. You wish to improve service in the division by making sure that 90% of the time, a customer is not put on hold, while 10% of the time, a customer can expect to be put on hold for an average of only 4 minutes. How many telephone lines will you add to your division to achieve your goal? So I think the biggest problem here is that I don't know $\mu$.  I do know $\rho=\frac{\lambda}{c\mu}=\frac{5}{3\mu}$ for this problem.  I understand that ""time on hold"" refers to to time waiting in the queue.  With $W$ is time waiting in the queue, I know: $$E[W]=\frac{\rho}{\lambda(1-\rho)}P(W>0)$$ With 3 operators, I used the fact that ""75% of the time, a customer is not put on hold, while the remaining 25% of the time, a customer can expected to be put on hold for an average of 12 minutes"" to calculate: $$E[W]=.75(0) + .25(12min)=3min$$ Then using $E[W]$ along with $P(W>0)=.25$, I solved the first equation to find $\mu=\frac{10}{3}$. Knowing $u$, I used ""90% of the time, a customer is not put on hold, while 10% of the time, a customer can expect to be put on hold for an average of only 4 minutes"" to find the new $E[W]=1min$ and $P(W>0)=.1$. To solve for $c$(number of servers) I again plugged these numbers into the original equation for $E[W]$ and found $c=3.3$. You can obviously only have an integer number of servers, so this would be $c=4$, and minus the original 3 would give the addition of just 1 server as the answer. Sorry for the long question, but am I doing this right?  I feel like I messed up along the way or made some wrong assumptions (mostly that $E[W] can be calculated from the information in the problem). Thanks for looking.",,"['probability', 'queueing-theory']"
7,Probability & Statistics: Random variables,Probability & Statistics: Random variables,,"I have a problem similar to the well-known ""Coupon Collector Problem."" A box of a certain brand of cereal comes with a special toy. There are 10 different toys in all.  How many packs you will need to buy until you find the first toy already acquired in previous purchases?","I have a problem similar to the well-known ""Coupon Collector Problem."" A box of a certain brand of cereal comes with a special toy. There are 10 different toys in all.  How many packs you will need to buy until you find the first toy already acquired in previous purchases?",,"['probability', 'statistics']"
8,Asymptotic Relative Efficiency: Poisson,Asymptotic Relative Efficiency: Poisson,,"I'm trying to find the asymptotic relative efficiency of a Poisson process: $$\frac{\lambda^t \exp(-\lambda)}{t!} =  P(X=t).$$ When $X = t = 0$, the best unbiased estimator of $e^{-\lambda}$ is ((n-1)/n)$^y$, where y = $\Sigma{X_i}$, the complete sufficient statistic for $\lambda$. When $X = t = 1$, the best unbiased estimator of $\lambda e^{-\lambda}$ is $\frac{y}{n}\left(\frac{n-1}{n}\right)^{y-1}$. It is stated that the asymptotic relative efficiency for $t=0$ is: ARE $$\left(\left( \frac{n-1}{n}\right)^{n \hat{\lambda}}, \quad\frac{y}{n}\left(\frac{n-1}{n}\right)^{y-1}\right) = \left[\frac{e^{-\lambda}}{\left(\frac{n-1}{n}\right)^{n\lambda}\log\left( \frac{n-1}{n}\right)^n}\right]^2$$ I'm not able to calculate this.","I'm trying to find the asymptotic relative efficiency of a Poisson process: $$\frac{\lambda^t \exp(-\lambda)}{t!} =  P(X=t).$$ When $X = t = 0$, the best unbiased estimator of $e^{-\lambda}$ is ((n-1)/n)$^y$, where y = $\Sigma{X_i}$, the complete sufficient statistic for $\lambda$. When $X = t = 1$, the best unbiased estimator of $\lambda e^{-\lambda}$ is $\frac{y}{n}\left(\frac{n-1}{n}\right)^{y-1}$. It is stated that the asymptotic relative efficiency for $t=0$ is: ARE $$\left(\left( \frac{n-1}{n}\right)^{n \hat{\lambda}}, \quad\frac{y}{n}\left(\frac{n-1}{n}\right)^{y-1}\right) = \left[\frac{e^{-\lambda}}{\left(\frac{n-1}{n}\right)^{n\lambda}\log\left( \frac{n-1}{n}\right)^n}\right]^2$$ I'm not able to calculate this.",,"['probability', 'statistics', 'probability-theory', 'asymptotics', 'probability-limit-theorems']"
9,To maximise my chance of winning one prize should I put all my entries in a single draw?,To maximise my chance of winning one prize should I put all my entries in a single draw?,,"Every week there's a prize draw. It's free to enter using the code from a soup tin lid. You can enter as many times as you like during the week until Monday's draw and then it starts all over. The prizes are experiences and the value to me is not especially relevant. Winning more than once might be worth more in value terms, but I only want to win once. So my question is; in order to maximise my chance of winning once should I; batch up my lids and enter as many of them as I can in one go, probably during the last week of the prize draws? enter lids as I go along. It feels like (1) to me, but the maths to explain it is beyond me. To be clear, I'm not actually interested in trying to gain a winning advantage. I realise that in reality the odds are small and about even either way, but as a maths puzzle I'm interested. Say for instance that I have 10 lids. Lets assume that the number of other entries are an even number (say 5 each week), and lets say there are 10 weeks and one prize available per week. Do I have more chance of winning a prize by entering one lid over 10 weeks, or 10 lids in any other week.","Every week there's a prize draw. It's free to enter using the code from a soup tin lid. You can enter as many times as you like during the week until Monday's draw and then it starts all over. The prizes are experiences and the value to me is not especially relevant. Winning more than once might be worth more in value terms, but I only want to win once. So my question is; in order to maximise my chance of winning once should I; batch up my lids and enter as many of them as I can in one go, probably during the last week of the prize draws? enter lids as I go along. It feels like (1) to me, but the maths to explain it is beyond me. To be clear, I'm not actually interested in trying to gain a winning advantage. I realise that in reality the odds are small and about even either way, but as a maths puzzle I'm interested. Say for instance that I have 10 lids. Lets assume that the number of other entries are an even number (say 5 each week), and lets say there are 10 weeks and one prize available per week. Do I have more chance of winning a prize by entering one lid over 10 weeks, or 10 lids in any other week.",,"['probability', 'puzzle']"
10,Deciding to place a bet on outcome of a dice roll based on the probability,Deciding to place a bet on outcome of a dice roll based on the probability,,"I have encountered several question of the following format. I have no trouble answering the first half but second half I have no clue on how to proceed. a: If you roll 5 standard six-sided dice, what is the probability of getting at least three 2s? b: If the roller gives you $10 on getting at least three 2's but asks only $2 in return if you lose. Would you take the bet? Why or why not? First part is just an application of binomial theorem and you are done. The probability is 0.03549 . But how to go about second part. Does it make sense to also take into consideration that if I win only once and lose other 5 times then also I will have not lost anything in the end. It will be evened out. Answers with complete explanation would be the best. If not, then please provide pointers to relevant readings.","I have encountered several question of the following format. I have no trouble answering the first half but second half I have no clue on how to proceed. a: If you roll 5 standard six-sided dice, what is the probability of getting at least three 2s? b: If the roller gives you $10 on getting at least three 2's but asks only $2 in return if you lose. Would you take the bet? Why or why not? First part is just an application of binomial theorem and you are done. The probability is 0.03549 . But how to go about second part. Does it make sense to also take into consideration that if I win only once and lose other 5 times then also I will have not lost anything in the end. It will be evened out. Answers with complete explanation would be the best. If not, then please provide pointers to relevant readings.",,"['probability', 'dice', 'gambling']"
11,Variance of drawing coins from a bag.,Variance of drawing coins from a bag.,,"First off, disclaimer, this was a homework question, albeit one that I've already turned in. I was given the problem There is a bag containing forty coins: 5 nickels, 10 dimes, and 25 quarters. Let X be the value of drawing twenty coins out of this bag at random without replacement. Calculate the expected value and the variance of X I calculated $\mathbb{E}[X]$ by noting that we would expect to grab half of each type of coin, thus $\mathbb{E}[X]=2.5(.05)+5(.10)+12.5(.25)=3.75$. Where I got stuck was calculating the variance. I'm aware of the formula $Var[X]=\mathbb{E}[(X-\mathbb{E}[X])^2]$, which seems relevant, but I'm not sure how to apply it. Any hints/help would be appreciated!","First off, disclaimer, this was a homework question, albeit one that I've already turned in. I was given the problem There is a bag containing forty coins: 5 nickels, 10 dimes, and 25 quarters. Let X be the value of drawing twenty coins out of this bag at random without replacement. Calculate the expected value and the variance of X I calculated $\mathbb{E}[X]$ by noting that we would expect to grab half of each type of coin, thus $\mathbb{E}[X]=2.5(.05)+5(.10)+12.5(.25)=3.75$. Where I got stuck was calculating the variance. I'm aware of the formula $Var[X]=\mathbb{E}[(X-\mathbb{E}[X])^2]$, which seems relevant, but I'm not sure how to apply it. Any hints/help would be appreciated!",,"['probability', 'stochastic-processes']"
12,What is the expectation of the product of two random variables of Dirichlet distribution?,What is the expectation of the product of two random variables of Dirichlet distribution?,,"I understand that the expectation of a random variable $X_i$ a Dirichlet distribution is $E[X_i] = \frac{\alpha_i}{\sum_k \alpha_k}$ and $E[\ln(X_i)] = \psi(\alpha_i) - \psi(\sum_k \alpha_k)$ I read a great paper ""Distribution of Mutual Information from Complete and Incomplete Data"" that states that $E[X_i\ln(X_i)] = \sum_{i} \frac{\alpha_i}{\sum_k \alpha_k} \{\psi(\alpha_i) - \psi(\sum_k \alpha_k)\}$ I was wondering what is $E[X_i X_j]$? Can I use the property $\operatorname{Cov}(X_i X_j) = E[X_i X_j] - E[X_i] E[X_j]$ to get $E[X_i X_j] = \operatorname{Cov}(X_i X_j) + E[X_i] E[X_j]$? What about $E[X_i \ln(X_j)]$? Can I also use the $\operatorname{Cov}$ to derive it? Latest update: I believe that $E[X_i \ln(X_j)]$ can be derived using $\operatorname{Cov}[X_i, \ln(X_j)]$ I found that $\mathrm{Cov}[X_i,X_j] = \frac{- \alpha_i \alpha_j}{\alpha^2 (\alpha+1)} \ \ \ $ where    $\alpha = \sum_{i=1}^K\alpha_i$ and $\operatorname{Cov}[\log(X_i),\log(X_j)] = \psi'(\alpha_i) \delta_{ij} - \psi'(\alpha_0)$ where $\psi$ is the digamma function, $\psi'$ is the trigamma function, and $\delta_{ij}$ is the Kronecker delta Is there a form for $\operatorname{Cov}[X_i,\log(X_j)]$? If so, we can use it to derive $E[X_i \ln(X_j)]$.","I understand that the expectation of a random variable $X_i$ a Dirichlet distribution is $E[X_i] = \frac{\alpha_i}{\sum_k \alpha_k}$ and $E[\ln(X_i)] = \psi(\alpha_i) - \psi(\sum_k \alpha_k)$ I read a great paper ""Distribution of Mutual Information from Complete and Incomplete Data"" that states that $E[X_i\ln(X_i)] = \sum_{i} \frac{\alpha_i}{\sum_k \alpha_k} \{\psi(\alpha_i) - \psi(\sum_k \alpha_k)\}$ I was wondering what is $E[X_i X_j]$? Can I use the property $\operatorname{Cov}(X_i X_j) = E[X_i X_j] - E[X_i] E[X_j]$ to get $E[X_i X_j] = \operatorname{Cov}(X_i X_j) + E[X_i] E[X_j]$? What about $E[X_i \ln(X_j)]$? Can I also use the $\operatorname{Cov}$ to derive it? Latest update: I believe that $E[X_i \ln(X_j)]$ can be derived using $\operatorname{Cov}[X_i, \ln(X_j)]$ I found that $\mathrm{Cov}[X_i,X_j] = \frac{- \alpha_i \alpha_j}{\alpha^2 (\alpha+1)} \ \ \ $ where    $\alpha = \sum_{i=1}^K\alpha_i$ and $\operatorname{Cov}[\log(X_i),\log(X_j)] = \psi'(\alpha_i) \delta_{ij} - \psi'(\alpha_0)$ where $\psi$ is the digamma function, $\psi'$ is the trigamma function, and $\delta_{ij}$ is the Kronecker delta Is there a form for $\operatorname{Cov}[X_i,\log(X_j)]$? If so, we can use it to derive $E[X_i \ln(X_j)]$.",,"['probability', 'probability-distributions']"
13,Expected sum of all the n-sided dice rolls until we get n,Expected sum of all the n-sided dice rolls until we get n,,"So the problem is the following. We have an $n$-sided die. We throw it until we get $n$. What's n, if the expected sum of all the throws including the $n$ one is $21$. Now, I did manage to solve it by assuming we throw the dice m times, then getting the expected value of a single throw and multiplying it with m to get the expected sum of all the throws. Then I just needed to get the expected m for an n sided die. However, the solution provided with the problem seems to be much shorter and I don't really understand how it works. It goes like this: Let X be a random variable representing the sum. Let Y be a random variable representing the value of the first throw. Then we can write the expected value of X using the law of total expectation like this: $EX=E(X|Y=1)P(Y=1) + ...+E(X|Y=n)P(Y=n)$ So far so good I thought. But then they substitute $EX$ with $21$ and do this: $21 = (21+1)\frac{1}{n}+...+(21+n-1)\frac{1}{n}+1$ Solving it for $n$ does produce the correct result ($6$), but I don't understand the reasoning behind $E(X|Y=a)=(21+a)$ Surely the expected value of $X$ already takes into account that the first throw will add something into the sum, right? So how is the expected value of $X$ GREATER than $21$ if the first throw gave the lowest possible amount? Using the same logic I tried to solve it by calculating the expected value for each throw ($\frac{n+1}{2}$) and then replacing $E(X|Y=a)$ with $(21+a-\frac{n+1}{2})$ my logic being that if we get $a$ and we expect $\frac{n+1}{2}$, the sum goes up or down by the same amount that $a$ differs from the expected value. Solving it like that, however, produces a wrong result ($-41$). So, where did I make a mistake?","So the problem is the following. We have an $n$-sided die. We throw it until we get $n$. What's n, if the expected sum of all the throws including the $n$ one is $21$. Now, I did manage to solve it by assuming we throw the dice m times, then getting the expected value of a single throw and multiplying it with m to get the expected sum of all the throws. Then I just needed to get the expected m for an n sided die. However, the solution provided with the problem seems to be much shorter and I don't really understand how it works. It goes like this: Let X be a random variable representing the sum. Let Y be a random variable representing the value of the first throw. Then we can write the expected value of X using the law of total expectation like this: $EX=E(X|Y=1)P(Y=1) + ...+E(X|Y=n)P(Y=n)$ So far so good I thought. But then they substitute $EX$ with $21$ and do this: $21 = (21+1)\frac{1}{n}+...+(21+n-1)\frac{1}{n}+1$ Solving it for $n$ does produce the correct result ($6$), but I don't understand the reasoning behind $E(X|Y=a)=(21+a)$ Surely the expected value of $X$ already takes into account that the first throw will add something into the sum, right? So how is the expected value of $X$ GREATER than $21$ if the first throw gave the lowest possible amount? Using the same logic I tried to solve it by calculating the expected value for each throw ($\frac{n+1}{2}$) and then replacing $E(X|Y=a)$ with $(21+a-\frac{n+1}{2})$ my logic being that if we get $a$ and we expect $\frac{n+1}{2}$, the sum goes up or down by the same amount that $a$ differs from the expected value. Solving it like that, however, produces a wrong result ($-41$). So, where did I make a mistake?",,"['probability', 'dice', 'expectation']"
14,On Chernoff bound,On Chernoff bound,,"Suppose $X\sim \textrm{Binomal}(n,p)$, show that for $\epsilon\geq 1$ $$P\bigg\{{X/n \over p}\geq \epsilon\bigg\}\leq \exp\bigg[-np(\epsilon(\log \epsilon -1)+1)\bigg]$$ I suppose there is a way of using Chernoff Bound of some kind but I don't quite get the right procedure. Any hint or comment will be appreciated.","Suppose $X\sim \textrm{Binomal}(n,p)$, show that for $\epsilon\geq 1$ $$P\bigg\{{X/n \over p}\geq \epsilon\bigg\}\leq \exp\bigg[-np(\epsilon(\log \epsilon -1)+1)\bigg]$$ I suppose there is a way of using Chernoff Bound of some kind but I don't quite get the right procedure. Any hint or comment will be appreciated.",,['probability']
15,Azuma's inequality: Expected sum of differences,Azuma's inequality: Expected sum of differences,,"I am looking for an extension of Azuma's inequality which involves the expected sum of squared differences. In particular, recall that Azuma's inequality states \begin{align*} \Pr[X_n-X_0 \geq a] \leq \exp\big(\frac{-a^2}{\sum_{k=1}^n c_k^2}\big) \end{align*} I am looking for a similar version which involves $\mathbb{E} \sum_{i=1}^n c_i^2$, while we can still enjoy the extra assumption of $0\leq c_i\leq 1$ if it is needed. Any comments/ideas are appreciated.","I am looking for an extension of Azuma's inequality which involves the expected sum of squared differences. In particular, recall that Azuma's inequality states \begin{align*} \Pr[X_n-X_0 \geq a] \leq \exp\big(\frac{-a^2}{\sum_{k=1}^n c_k^2}\big) \end{align*} I am looking for a similar version which involves $\mathbb{E} \sum_{i=1}^n c_i^2$, while we can still enjoy the extra assumption of $0\leq c_i\leq 1$ if it is needed. Any comments/ideas are appreciated.",,"['probability', 'inequality', 'martingales', 'sums-of-squares']"
16,Find a probability integral,Find a probability integral,,"For $0 <t<1$  express the integral $$ \int_0^\pi \int_{\max\left\{-1;\cos x - \frac{t}{\sin x}\right\}}^{\cos x}  \frac{dy}{\sqrt{1-y^2}} \, dx $$ as a function of $t$ (without any  integrals). I am sorry, but actually I don't know  any attempt  to do it.","For $0 <t<1$  express the integral $$ \int_0^\pi \int_{\max\left\{-1;\cos x - \frac{t}{\sin x}\right\}}^{\cos x}  \frac{dy}{\sqrt{1-y^2}} \, dx $$ as a function of $t$ (without any  integrals). I am sorry, but actually I don't know  any attempt  to do it.",,"['calculus', 'real-analysis', 'probability', 'multivariable-calculus']"
17,"Alternative to Parthasarathy's ""Probability measures on metric spaces""","Alternative to Parthasarathy's ""Probability measures on metric spaces""",,"In the book ""Probability measures on metric spaces"" by K. R. Parthasarathy the fifth chapter is devoted to the Kolmogorov consistency theorem. Before coming to this result, however, he proves the following: Let $(X,\mathcal{B})$ be a Borel space and $\mathcal{B}_n\subseteq\mathcal{B}$ a $\sigma$-algebra such that (i) $\mathcal{B}_1\subseteq\mathcal{B}_2\subseteq ...$ and $\displaystyle\bigcup_{n}\mathcal{B}_n$ generates $\mathcal{B}$. (ii) $(X,\mathcal{B}_n)$ is a standard Borel space for each $n=1,2,...$ Then, in order that every consistent sequence of measures on $\mathcal{B_1},\mathcal{B}_2,...$ be extendable to a measure on $\mathcal{B}$ it is necessary and sufficient that $\displaystyle\bigcup_n A_n\neq\emptyset$ for each sequence $A_1,A_2,...$. If this is the case, then $(X,\mathcal{B})$ is also standard. I need this theorem in order to prove a different result, and I would like for my text to be somewhat self-contained. The problem is, however, that this would mean adding quite a large appendix if I were to follow the lines of the Parthasarathy book. Hence, my question is: Does anyone know of an alternative text containing a different proof of this (or a similar) result?","In the book ""Probability measures on metric spaces"" by K. R. Parthasarathy the fifth chapter is devoted to the Kolmogorov consistency theorem. Before coming to this result, however, he proves the following: Let $(X,\mathcal{B})$ be a Borel space and $\mathcal{B}_n\subseteq\mathcal{B}$ a $\sigma$-algebra such that (i) $\mathcal{B}_1\subseteq\mathcal{B}_2\subseteq ...$ and $\displaystyle\bigcup_{n}\mathcal{B}_n$ generates $\mathcal{B}$. (ii) $(X,\mathcal{B}_n)$ is a standard Borel space for each $n=1,2,...$ Then, in order that every consistent sequence of measures on $\mathcal{B_1},\mathcal{B}_2,...$ be extendable to a measure on $\mathcal{B}$ it is necessary and sufficient that $\displaystyle\bigcup_n A_n\neq\emptyset$ for each sequence $A_1,A_2,...$. If this is the case, then $(X,\mathcal{B})$ is also standard. I need this theorem in order to prove a different result, and I would like for my text to be somewhat self-contained. The problem is, however, that this would mean adding quite a large appendix if I were to follow the lines of the Parthasarathy book. Hence, my question is: Does anyone know of an alternative text containing a different proof of this (or a similar) result?",,"['probability', 'probability-theory']"
18,Banach space valued random variable,Banach space valued random variable,,Let $X$ be a Banach space valued random variable.  Is there a characteristic function of $X$ in this case? How it is defined if there is one?Are there any applications of this function in this high dimensional case? For example proving limit theorems? What if $X$ takes values in a (locally convex) topological vector space?,Let $X$ be a Banach space valued random variable.  Is there a characteristic function of $X$ in this case? How it is defined if there is one?Are there any applications of this function in this high dimensional case? For example proving limit theorems? What if $X$ takes values in a (locally convex) topological vector space?,,"['probability', 'functional-analysis']"
19,Variation of Coupon Collector Problem,Variation of Coupon Collector Problem,,"I buy 7 bags of candies, each guaranteed to have one of 4 celebs' picture, with probabilities of 1/12 , 1/6 , 5/12 , and 1/3 . What is the expected # of celebs whose picture I'll get ?","I buy 7 bags of candies, each guaranteed to have one of 4 celebs' picture, with probabilities of 1/12 , 1/6 , 5/12 , and 1/3 . What is the expected # of celebs whose picture I'll get ?",,"['probability', 'combinatorics']"
20,Sample space of the Monty Hall problem,Sample space of the Monty Hall problem,,"I have read two sources where the outcomes of the Monty Hall problem are triples of the form: ( initial guess , the curtain Monty opens , the curtain where the car is ) However, I think it should be: ( initial guess , the curtain Monty opens , switched curtain , the curtain where the car is ) Is the sample space consisting of these outcomes wrong? It seems that it is because I am getting that it doesn't matter if one switches curtains.","I have read two sources where the outcomes of the Monty Hall problem are triples of the form: ( initial guess , the curtain Monty opens , the curtain where the car is ) However, I think it should be: ( initial guess , the curtain Monty opens , switched curtain , the curtain where the car is ) Is the sample space consisting of these outcomes wrong? It seems that it is because I am getting that it doesn't matter if one switches curtains.",,"['probability', 'monty-hall']"
21,Choosing distribution for hypotheses testing,Choosing distribution for hypotheses testing,,"I am testing hypotheses, that there is a significant difference between skin temp in the morning and in the evening. My null hypotheses  is that $$ H_0: |t_m - t_e| = 0 $$ My alte hypotheses  is that $$ H_a: |t_m - t_e| > 0 $$ There is a hist and normplot of morning data: And there is a hist and normplot of evening data What distribution should I use for statistical testing of my hypotheses?","I am testing hypotheses, that there is a significant difference between skin temp in the morning and in the evening. My null hypotheses  is that $$ H_0: |t_m - t_e| = 0 $$ My alte hypotheses  is that $$ H_a: |t_m - t_e| > 0 $$ There is a hist and normplot of morning data: And there is a hist and normplot of evening data What distribution should I use for statistical testing of my hypotheses?",,"['probability', 'probability-distributions']"
22,Expected number of times before winning the lottery $n$ times,Expected number of times before winning the lottery  times,n,"Let $p,n$ be positive integers. Suppose that every time you buy the lottery, you have a $\dfrac1p$ chance of winning it (independently of other times). What is the expected number of times you have to buy the lottery before you win $n$ times? Intuitively, it should be $pn$, but how to prove it? Using linearity of expectations, it's easy to see that after buying $k$ times, you'll have won $\dfrac{k}{p}$ times. But that doesn't seem to help with the above question.","Let $p,n$ be positive integers. Suppose that every time you buy the lottery, you have a $\dfrac1p$ chance of winning it (independently of other times). What is the expected number of times you have to buy the lottery before you win $n$ times? Intuitively, it should be $pn$, but how to prove it? Using linearity of expectations, it's easy to see that after buying $k$ times, you'll have won $\dfrac{k}{p}$ times. But that doesn't seem to help with the above question.",,"['probability', 'combinatorics', 'expectation']"
23,show that $E(X|G)=\int_0^{\infty}P[X>t|G]dt$,show that,E(X|G)=\int_0^{\infty}P[X>t|G]dt,"For $0\le X \in L_1$,  $X$ is a random variable on $(\Omega,B,P)$, and G is a $\sigma$-algebra and $G \subset B$, show almost surely $$E(X|G)=\int_0^{\infty}P[X>t|G]dt$$ Here is my try: This is about conditional expectation. By the definition of the conditional expectation $E(X|G)$ has two requirements: $$E(X|G) \in G$$  And for all  $ A \in G$ $$\int_AE(X|G)dP=\int_AXdP $$ It's easy to get the second equation. That is  $$ \begin{align} \int_A\int_0^\infty P[X>t|G]dtdP &= \int_0^\infty \int_A P[X>t|G]dPdt \;\;(Fubini) \\  &= \int_0^\infty \int_A E(1_{[X>t]}|G)dPdt  \\&=\int_0^\infty \int_{A} 1_{[X>t]}dPdt \\&=\int_{A} \int_0^\infty  1_{[X>t]}dtdP \;\; (Fubini) \\&=\int_A X dP \end{align} $$ But I tried a lot, still cannot prove the first one, because it's contained in the integral. Anyone has any idea? Thank you!","For $0\le X \in L_1$,  $X$ is a random variable on $(\Omega,B,P)$, and G is a $\sigma$-algebra and $G \subset B$, show almost surely $$E(X|G)=\int_0^{\infty}P[X>t|G]dt$$ Here is my try: This is about conditional expectation. By the definition of the conditional expectation $E(X|G)$ has two requirements: $$E(X|G) \in G$$  And for all  $ A \in G$ $$\int_AE(X|G)dP=\int_AXdP $$ It's easy to get the second equation. That is  $$ \begin{align} \int_A\int_0^\infty P[X>t|G]dtdP &= \int_0^\infty \int_A P[X>t|G]dPdt \;\;(Fubini) \\  &= \int_0^\infty \int_A E(1_{[X>t]}|G)dPdt  \\&=\int_0^\infty \int_{A} 1_{[X>t]}dPdt \\&=\int_{A} \int_0^\infty  1_{[X>t]}dtdP \;\; (Fubini) \\&=\int_A X dP \end{align} $$ But I tried a lot, still cannot prove the first one, because it's contained in the integral. Anyone has any idea? Thank you!",,"['probability', 'measure-theory']"
24,Gaussian density function satisfies $y'=-xy$. Coincidence?,Gaussian density function satisfies . Coincidence?,y'=-xy,Is part of the rationale for the Gaussian distribution that the density function satisfies the differential equation $y' = -xy$? Or is this more or less incidental?,Is part of the rationale for the Gaussian distribution that the density function satisfies the differential equation $y' = -xy$? Or is this more or less incidental?,,"['probability', 'ordinary-differential-equations', 'soft-question']"
25,marble probabilities,marble probabilities,,"A bucket has 3 marbles numbered 1, 2, and 3. Choose one and put it back along with another marble with the same number. Now choose a second and put it back along with a marble with the sum of your first two picks. Choose one more marble. Find P(the first number was a 3 | third was a 3). So what I did was draw out the entire tree of possibilities and then used the equation P(1st =3 AND 3rd =3)/P(3rd =3) and got 4/9 as the answer. Can anyone confirm this is correct? Also, is there an easier was to do this without drawing out the whole tree? Thanks!","A bucket has 3 marbles numbered 1, 2, and 3. Choose one and put it back along with another marble with the same number. Now choose a second and put it back along with a marble with the sum of your first two picks. Choose one more marble. Find P(the first number was a 3 | third was a 3). So what I did was draw out the entire tree of possibilities and then used the equation P(1st =3 AND 3rd =3)/P(3rd =3) and got 4/9 as the answer. Can anyone confirm this is correct? Also, is there an easier was to do this without drawing out the whole tree? Thanks!",,['probability']
26,Simple probability question with cards,Simple probability question with cards,,"I have 16 cards total, 4 cards from each suit of diamonds, hearts, clubs, spades. If I draw 5 cards without replacement, what is the probability that the 5th card drawn is a club? Is there any easy short cut to do this? Or do I need to consider every scenario and sum probabilities?","I have 16 cards total, 4 cards from each suit of diamonds, hearts, clubs, spades. If I draw 5 cards without replacement, what is the probability that the 5th card drawn is a club? Is there any easy short cut to do this? Or do I need to consider every scenario and sum probabilities?",,"['probability', 'probability-theory']"
27,Probability of consecutive row of at least $m$ by $n\leq2m$ events. Is there a shorter route?,Probability of consecutive row of at least  by  events. Is there a shorter route?,m n\leq2m,"Inspired by this I started to generalize it. Go out from independent events $E_{1},E_{2},\cdots$ that succeed or fail. This with $p$ as probability of succes, and $p+q=1$ . Event $A_{m,n}$ occurs if among the first $n$ events there is a consecutive row of at least $m$ successes. Letting $K$ denote the smallest index of a failing event, we have $P\left(K=k\right)=p^{k-1}q$ . Looking at $P\left(A_{m,n}\mid K=k\right)$ it is easy to find that this probability equals $1$ if $k>m$ and equals $P\left(A_{m,n-k}\right)$ otherwise.  So for $m\leq n$ we find: $P\left(A_{m,n}\right)=\sum_{k=1}^{\infty}P\left(A_{m,n}\mid K=k\right)P\left(K=k\right)=\sum_{k=1}^{m}P\left(A_{m,n-k}\right)p^{k-1}q+p^{m}$ . Here $P\left(A_{m,n-k}\right):=0$ if $m>n-k$ . I thought that this would lead to some unfriendly polynomial in $p$ , but working this out for $n=m,m+1,m+2,m+3,...,2m$ a pattern showed up, and with induction I could prove: $P\left(A_{m,n}\right)=p^{m}\left(1+\left(n-m\right)q\right)$ if $m\leq n\leq 2m$ The fact that this is a neat formula pleases me, but also bothers me. Quite often it indicates that there is a shorter route. Do you know one?","Inspired by this I started to generalize it. Go out from independent events that succeed or fail. This with as probability of succes, and . Event occurs if among the first events there is a consecutive row of at least successes. Letting denote the smallest index of a failing event, we have . Looking at it is easy to find that this probability equals if and equals otherwise.  So for we find: . Here if . I thought that this would lead to some unfriendly polynomial in , but working this out for a pattern showed up, and with induction I could prove: if The fact that this is a neat formula pleases me, but also bothers me. Quite often it indicates that there is a shorter route. Do you know one?","E_{1},E_{2},\cdots p p+q=1 A_{m,n} n m K P\left(K=k\right)=p^{k-1}q P\left(A_{m,n}\mid K=k\right) 1 k>m P\left(A_{m,n-k}\right) m\leq n P\left(A_{m,n}\right)=\sum_{k=1}^{\infty}P\left(A_{m,n}\mid K=k\right)P\left(K=k\right)=\sum_{k=1}^{m}P\left(A_{m,n-k}\right)p^{k-1}q+p^{m} P\left(A_{m,n-k}\right):=0 m>n-k p n=m,m+1,m+2,m+3,...,2m P\left(A_{m,n}\right)=p^{m}\left(1+\left(n-m\right)q\right) m\leq n\leq 2m","['probability', 'combinatorics', 'dice']"
28,What is the right invariant $\sigma$-algebra for the Birkhoff ergodic theorem?,What is the right invariant -algebra for the Birkhoff ergodic theorem?,\sigma,"I have been reading stuff about ergodic theory, and I have encountered two versions of the involved ""invariant sigma field"". let the underlying probability space be $(\Omega,\mathcal{F},P)$, and let's consider a measure preserving transformation $T:\Omega \rightarrow \Omega$). then the two definitions of the $T$-invariant sets are: 1) $\mathcal{I}_1:=\{A \in \mathcal{F} \mid T^{-1}A=A\}$; 2) $\mathcal{I}_2:=\{A \in \mathcal{F} \mid P(T^{-1}A \Delta A) = 0\}$; obviously, $\mathcal{I}_1\subseteq\mathcal{I}_2$. but I don't think that $\mathcal{I}_2\subseteq\mathcal{I}_1$ holds as well. 2hat is the relationship between the two (is the larger one the completion of the smaller one?)? But here is the prime question: which one is the right ""conditioning"" sigma field for the limit in Birkhoff's ergodic theorem? Are the conditional expectations versions of each other? If yes, how would you show that? Many thanks for any help!","I have been reading stuff about ergodic theory, and I have encountered two versions of the involved ""invariant sigma field"". let the underlying probability space be $(\Omega,\mathcal{F},P)$, and let's consider a measure preserving transformation $T:\Omega \rightarrow \Omega$). then the two definitions of the $T$-invariant sets are: 1) $\mathcal{I}_1:=\{A \in \mathcal{F} \mid T^{-1}A=A\}$; 2) $\mathcal{I}_2:=\{A \in \mathcal{F} \mid P(T^{-1}A \Delta A) = 0\}$; obviously, $\mathcal{I}_1\subseteq\mathcal{I}_2$. but I don't think that $\mathcal{I}_2\subseteq\mathcal{I}_1$ holds as well. 2hat is the relationship between the two (is the larger one the completion of the smaller one?)? But here is the prime question: which one is the right ""conditioning"" sigma field for the limit in Birkhoff's ergodic theorem? Are the conditional expectations versions of each other? If yes, how would you show that? Many thanks for any help!",,"['probability', 'statistics', 'probability-theory', 'ergodic-theory', 'stochastic-analysis']"
29,Prove expectation inequality,Prove expectation inequality,,"Any ideas on how I could prove the veracity or falseness of the following inequality? Let $X:\Omega \to \mathbb{R}$ a random variable such that the expressions under are well-defined. Then $$E[e^X] \leq 1 + e^{E[|X|]}.$$ I have the feeling that this is true but i do not know how to show it. I was thinking Jensen's inequality but it goes the wrong way. One more question, if the above inequality is false, is there a way to upperbound $E[e^X] \leq f(E|X|)$ ? Thanks you very much for your help.","Any ideas on how I could prove the veracity or falseness of the following inequality? Let $X:\Omega \to \mathbb{R}$ a random variable such that the expressions under are well-defined. Then $$E[e^X] \leq 1 + e^{E[|X|]}.$$ I have the feeling that this is true but i do not know how to show it. I was thinking Jensen's inequality but it goes the wrong way. One more question, if the above inequality is false, is there a way to upperbound $E[e^X] \leq f(E|X|)$ ? Thanks you very much for your help.",,"['real-analysis', 'probability', 'inequality', 'probability-distributions', 'random-variables']"
30,An intuitive solution to this problem (Using probability tree),An intuitive solution to this problem (Using probability tree),,"A group of boys has been lost several days in the dessert. This group has a phone to make phone calls. After a long way walk, they believe that the current area is suitable for phone calls; even though, the battery just allow three call attempts. Due to remote conditions of the current area, the probability of a successful call is 0.2. If the call is not successful, the network would save a register of their location with a probability of 0.375. With a probability of 0.625 the attempt was in vain. If the call attempt was successful or there are 2 registers, they would be rescued within a few hours the same day. 1.) What is the probability that they are not rescued the same day if that just depends on the result of the call attempts. 2.) Which is the probability that the group is rescued with EXACTLY two call attempts 3.) What is the probability of a successful call 4.) What is the probability that the network generates register but they are not rescued I have try a solution by a tree, but i'm blocked with the fact that with 2 calls they are rescued. I really appreciate an explanation, since my self-learning resources are not extremely complete for wide understanding. If you think in a tree, how could it be. I would really appreciate a tree model of the problem","A group of boys has been lost several days in the dessert. This group has a phone to make phone calls. After a long way walk, they believe that the current area is suitable for phone calls; even though, the battery just allow three call attempts. Due to remote conditions of the current area, the probability of a successful call is 0.2. If the call is not successful, the network would save a register of their location with a probability of 0.375. With a probability of 0.625 the attempt was in vain. If the call attempt was successful or there are 2 registers, they would be rescued within a few hours the same day. 1.) What is the probability that they are not rescued the same day if that just depends on the result of the call attempts. 2.) Which is the probability that the group is rescued with EXACTLY two call attempts 3.) What is the probability of a successful call 4.) What is the probability that the network generates register but they are not rescued I have try a solution by a tree, but i'm blocked with the fact that with 2 calls they are rescued. I really appreciate an explanation, since my self-learning resources are not extremely complete for wide understanding. If you think in a tree, how could it be. I would really appreciate a tree model of the problem",,"['probability', 'probability-theory', 'discrete-mathematics']"
31,Expected value for $a^x$,Expected value for,a^x,"Assume a random variable $X$. Assume, if this simplifies the problem, that $X$ can take only non negative integer values. Does there exist any relation between $E(X)$ and $E(a^X)$, where $a$ is an arbitrary value in the interval $[0,1]$ and by $a^X$ I mean the random variable that takes value $a^x$ with the same probability $p$ such that $X$ takes probability $x$? Thanks!","Assume a random variable $X$. Assume, if this simplifies the problem, that $X$ can take only non negative integer values. Does there exist any relation between $E(X)$ and $E(a^X)$, where $a$ is an arbitrary value in the interval $[0,1]$ and by $a^X$ I mean the random variable that takes value $a^x$ with the same probability $p$ such that $X$ takes probability $x$? Thanks!",,['probability']
32,Expected value of sum of dice roll (one 6 side and one 10 side dice),Expected value of sum of dice roll (one 6 side and one 10 side dice),,"You have 2 dice, one 6-sided dice and one 10-sided dice. You get the dollar amount of the sum of the 2 dice. If unsatisfied with the current roll, you may pay 1 dollar to re-roll. How much would you pay to play the game, or what is the expected value of the game?","You have 2 dice, one 6-sided dice and one 10-sided dice. You get the dollar amount of the sum of the 2 dice. If unsatisfied with the current roll, you may pay 1 dollar to re-roll. How much would you pay to play the game, or what is the expected value of the game?",,['probability']
33,Probability to draw a white ball from the third box.,Probability to draw a white ball from the third box.,,There are $2$ boxes full of black and white balls. The first one has $a$ white and $b$ black balls ($a\geq2$ && $b\geq2$). The second one has $c$ white and $d$ black balls ($c\geq1$ && $d\geq1$). You draw $2$ balls from the first box and $1$ ball from the second box and put them into a third box. What is the probability to draw a white ball from the third box. I tried to solve it this way: $A_1$ - draw 2 white balls from first box and 1 white from second box and put them in third box. $A_2$ - draw 2 white balls from first box and 1 black from second box and put them in third box. $A_3$ - draw 1 white ball and 1 black ball from first box and 1 white from second box and put them in third box. $A_4$ - draw 1 white ball and 1 black ball from first box and 1 black from second box and put them in third box. $A_5$ - draw 2 black balls from first box and 1 white from second box and put them in third box. $A_6$ - draw 2 black balls from first box and 1 black from second box and put them in third box. $B$ - draw white ball from third box. $$P(B) = \sum_{i = 1}^{6} P(B \mid A_i)P(A_i)$$ I think $P(B\mid A_i)$ are pretty obvious so i won't write them. After long brute force i came up with this answer $$\frac{ac(5(a-1) + 6b + b(b-1))}{3(a+b)(a+b-1)(c+d)}$$ I want to know if there is a shorter answer.,There are $2$ boxes full of black and white balls. The first one has $a$ white and $b$ black balls ($a\geq2$ && $b\geq2$). The second one has $c$ white and $d$ black balls ($c\geq1$ && $d\geq1$). You draw $2$ balls from the first box and $1$ ball from the second box and put them into a third box. What is the probability to draw a white ball from the third box. I tried to solve it this way: $A_1$ - draw 2 white balls from first box and 1 white from second box and put them in third box. $A_2$ - draw 2 white balls from first box and 1 black from second box and put them in third box. $A_3$ - draw 1 white ball and 1 black ball from first box and 1 white from second box and put them in third box. $A_4$ - draw 1 white ball and 1 black ball from first box and 1 black from second box and put them in third box. $A_5$ - draw 2 black balls from first box and 1 white from second box and put them in third box. $A_6$ - draw 2 black balls from first box and 1 black from second box and put them in third box. $B$ - draw white ball from third box. $$P(B) = \sum_{i = 1}^{6} P(B \mid A_i)P(A_i)$$ I think $P(B\mid A_i)$ are pretty obvious so i won't write them. After long brute force i came up with this answer $$\frac{ac(5(a-1) + 6b + b(b-1))}{3(a+b)(a+b-1)(c+d)}$$ I want to know if there is a shorter answer.,,"['probability', 'conditional-probability']"
34,How to determine the number of trials done for a discrete uniform random distribution?,How to determine the number of trials done for a discrete uniform random distribution?,,"Say I have a discrete uniformly random die which rolls values in the range $[min,max]$.  And say I roll that die $N$ times and record the total sum $Sum$. Given $min$, $max$, and $Sum$, I'd like to determine $N$ with some amount of certainty. So for example, let's say I roll a normal 6-sided die $N$ times and get a sum of 30.  I'd like to know, with, say, 95% certainty, a range of values that $N$ is in. (This is not a homework question; I encountered the problem when writing this answer and realized I have no idea how to solve it)","Say I have a discrete uniformly random die which rolls values in the range $[min,max]$.  And say I roll that die $N$ times and record the total sum $Sum$. Given $min$, $max$, and $Sum$, I'd like to determine $N$ with some amount of certainty. So for example, let's say I roll a normal 6-sided die $N$ times and get a sum of 30.  I'd like to know, with, say, 95% certainty, a range of values that $N$ is in. (This is not a homework question; I encountered the problem when writing this answer and realized I have no idea how to solve it)",,"['probability', 'probability-theory']"
35,Average number of heads in filtered coin toss,Average number of heads in filtered coin toss,,"I have a coin that, when tossed, produces heads with probability $p \geq 0.5$ and tails with probability $1-p$. I start a coin-tossing experiment. Whenever I get more than one tail in a row, I discard the second tail and toss again, so that my results look like one long chain of heads with the occasional tail sprinkled in. In the long run, does the overall percentage of heads converge to 100%? How long does my result list have to be to guarantee at least $x$%  heads? What if I only discard the last toss if I get more than $k$ tails in a row? (This question comes from thinking about the caching function of my streaming music library. Please excuse a first-year undergrad's background knowledge; if this has been done a million times before I would appreciate a link to the general subject)","I have a coin that, when tossed, produces heads with probability $p \geq 0.5$ and tails with probability $1-p$. I start a coin-tossing experiment. Whenever I get more than one tail in a row, I discard the second tail and toss again, so that my results look like one long chain of heads with the occasional tail sprinkled in. In the long run, does the overall percentage of heads converge to 100%? How long does my result list have to be to guarantee at least $x$%  heads? What if I only discard the last toss if I get more than $k$ tails in a row? (This question comes from thinking about the caching function of my streaming music library. Please excuse a first-year undergrad's background knowledge; if this has been done a million times before I would appreciate a link to the general subject)",,['probability']
36,Number of times you can play a game in an hour?,Number of times you can play a game in an hour?,,"Suppose that you have a game you can play that takes a variable amount of time to finish - suppose it takes between $A$ seconds and $B$ seconds to complete, and is uniformly distributed between the two. Given $A$ and $B$, is there an easy way to compute the expected number of games you can play within some amount of time $T$? Thanks!","Suppose that you have a game you can play that takes a variable amount of time to finish - suppose it takes between $A$ seconds and $B$ seconds to complete, and is uniformly distributed between the two. Given $A$ and $B$, is there an easy way to compute the expected number of games you can play within some amount of time $T$? Thanks!",,['probability']
37,"$X \sim U [-0.5 , 1.5] , Y = X^2$",,"X \sim U [-0.5 , 1.5] , Y = X^2","Given $$ f(x) = \begin{cases} \frac12 &,\ -0.5 \le x\le 1.5\\0 &,\ \mbox{otherwise} \end{cases}$$ find the probability density function of $Y=X^2$. To solve this I first divided up the pdf of X into three parts: $$f(x) = \begin{cases} \frac12 &, \ -0.5 \le x\le 0\\\frac12 &, \ 0\le x\le 0.5 \\ \frac12 &,\ 0.5 \le x\le 1.5\\ 0 &, \ \mbox{otherwise} \end{cases}$$ Then applying $g^{-1}(y) = -\sqrt{y}$ for $-0.5 \le x \le 0 $ and $g^{-1}(y) = +\sqrt{y}$ for $ 0 \le x \le 0.5 $ and $ 0.5 \le x \le 1.5 $, I get: $$ g(y) = \begin{cases} \frac{1}{4\sqrt{y}} &,\ 0 \le x \le 0.25\\ \frac{1}{4\sqrt{y}} &, \ 0\le x\le 0.25 \\ \frac{1}{4\sqrt{y}} &, \ 0.25 \le x \le 2.25 \\ 0 &, \ \mbox{otherwise} \end{cases}$$ Summing up the first two cases I get: $$ g(y) = \begin{cases} \frac{1}{2\sqrt{y}} &, \ 0 \le x \le 0.25 \\ \frac{1}{4\sqrt{y}} &, \ 0.25 \le x \le 2.25\\ 0 &, \ \mbox{otherwise} \end{cases} $$ Could someone confirm whether my solution is correct or not? And whether my argumentation makes sense? Thanks!","Given $$ f(x) = \begin{cases} \frac12 &,\ -0.5 \le x\le 1.5\\0 &,\ \mbox{otherwise} \end{cases}$$ find the probability density function of $Y=X^2$. To solve this I first divided up the pdf of X into three parts: $$f(x) = \begin{cases} \frac12 &, \ -0.5 \le x\le 0\\\frac12 &, \ 0\le x\le 0.5 \\ \frac12 &,\ 0.5 \le x\le 1.5\\ 0 &, \ \mbox{otherwise} \end{cases}$$ Then applying $g^{-1}(y) = -\sqrt{y}$ for $-0.5 \le x \le 0 $ and $g^{-1}(y) = +\sqrt{y}$ for $ 0 \le x \le 0.5 $ and $ 0.5 \le x \le 1.5 $, I get: $$ g(y) = \begin{cases} \frac{1}{4\sqrt{y}} &,\ 0 \le x \le 0.25\\ \frac{1}{4\sqrt{y}} &, \ 0\le x\le 0.25 \\ \frac{1}{4\sqrt{y}} &, \ 0.25 \le x \le 2.25 \\ 0 &, \ \mbox{otherwise} \end{cases}$$ Summing up the first two cases I get: $$ g(y) = \begin{cases} \frac{1}{2\sqrt{y}} &, \ 0 \le x \le 0.25 \\ \frac{1}{4\sqrt{y}} &, \ 0.25 \le x \le 2.25\\ 0 &, \ \mbox{otherwise} \end{cases} $$ Could someone confirm whether my solution is correct or not? And whether my argumentation makes sense? Thanks!",,['probability']
38,uniform integrability of a squared sum of iid variables,uniform integrability of a squared sum of iid variables,,"I'm trying to prove that if $X_i$ are independent, identically distributed random variables such that $E X_i = 0$ and $E X_i^2 < \infty$ then the sequence $\frac{(\sum_{i=1}^{n} X_i)^2}{n}$ is uniformly integrable. Actually I've been told that even something stronger holds, namely that  $$\frac{\max_{k\leq n}(\sum_{i=1}^{k} X_i)^2}{n}$$ is uniformly integrable. Can someone please give me a hint or a reference to some proof? I've been told that the Hoffmann-Jorgensenn inequality might come in handy, but I suppose that's just for the generalization with $\max$. I know this would be trivial if we had $\frac{\sum_{i=1}^{n} X_i^2}{n}$, but the problem is that the whole sum is squared, not each variable separately. Thank you very much for your help.","I'm trying to prove that if $X_i$ are independent, identically distributed random variables such that $E X_i = 0$ and $E X_i^2 < \infty$ then the sequence $\frac{(\sum_{i=1}^{n} X_i)^2}{n}$ is uniformly integrable. Actually I've been told that even something stronger holds, namely that  $$\frac{\max_{k\leq n}(\sum_{i=1}^{k} X_i)^2}{n}$$ is uniformly integrable. Can someone please give me a hint or a reference to some proof? I've been told that the Hoffmann-Jorgensenn inequality might come in handy, but I suppose that's just for the generalization with $\max$. I know this would be trivial if we had $\frac{\sum_{i=1}^{n} X_i^2}{n}$, but the problem is that the whole sum is squared, not each variable separately. Thank you very much for your help.",,"['probability', 'reference-request', 'uniform-integrability']"
39,Weak Law of Large Numbers proof,Weak Law of Large Numbers proof,,I want to know if there is a proof of the Weak Law of Large Numbers without using the Chebyshev's Inequality? please can anyone give me some references,I want to know if there is a proof of the Weak Law of Large Numbers without using the Chebyshev's Inequality? please can anyone give me some references,,"['probability', 'probability-theory', 'reference-request']"
40,Expected Value for Powerball Lottery,Expected Value for Powerball Lottery,,"Suppose that there the grand prize in the Powerball lottery is 150 million dollars and that you purchase exactly one ticket.  Calculate your expected winnings.  Assume no taxes, no split/multiple winners, and that the grand prize is paid in cash. To play the game, we draw five balls out of a drum with 53 numbered white balls and one power ball out of a drum with 42 numbered green balls.  Anyway, I got the odds table here: My approach: $E[Winning] = 149,999,999 \cdot \cfrac{1}{120,526,770} + 99,999 \cdot \cfrac{41}{120,526,770} + \cdots + (-1) \cdot \cfrac{117,184,724}{120,526,770} = \$0.45$ But the answer they get is 42 cents.  The book gets $\cfrac{50,361,822}{120,526,770}$ but I got $\cfrac{53,703,826}{120,526,770}$. Can anyone see what I'm doing wrong if anything?  All I want to know is if my approach is correct, I don't care so much about the numerical values although I checked my calculations several times in python: 149999999 + 99999*41 + 5000*240 + 100*9840 + 100*11280 + 7*462480 + 7*172960 + 4*972900 + 3*1712304 + (-1)*117184724) Thank you in advance.","Suppose that there the grand prize in the Powerball lottery is 150 million dollars and that you purchase exactly one ticket.  Calculate your expected winnings.  Assume no taxes, no split/multiple winners, and that the grand prize is paid in cash. To play the game, we draw five balls out of a drum with 53 numbered white balls and one power ball out of a drum with 42 numbered green balls.  Anyway, I got the odds table here: My approach: $E[Winning] = 149,999,999 \cdot \cfrac{1}{120,526,770} + 99,999 \cdot \cfrac{41}{120,526,770} + \cdots + (-1) \cdot \cfrac{117,184,724}{120,526,770} = \$0.45$ But the answer they get is 42 cents.  The book gets $\cfrac{50,361,822}{120,526,770}$ but I got $\cfrac{53,703,826}{120,526,770}$. Can anyone see what I'm doing wrong if anything?  All I want to know is if my approach is correct, I don't care so much about the numerical values although I checked my calculations several times in python: 149999999 + 99999*41 + 5000*240 + 100*9840 + 100*11280 + 7*462480 + 7*172960 + 4*972900 + 3*1712304 + (-1)*117184724) Thank you in advance.",,"['probability', 'statistics']"
41,Probability of two people in a group of n people sharing the *exact* birthday?,Probability of two people in a group of n people sharing the *exact* birthday?,,"I understand the solution to the birthday paradox. But I was wondering how I would calculate the probability of two people having the same age, or the exact birthday, down to matching years. I am thoroughly confused. Please help.","I understand the solution to the birthday paradox. But I was wondering how I would calculate the probability of two people having the same age, or the exact birthday, down to matching years. I am thoroughly confused. Please help.",,['probability']
42,weak/vague convergence,weak/vague convergence,,"I am trying to understand 'vague/weak convergence' and need to decide whether or not a measure converges vaguely or weakly. Weak convergence implies vague convergences. However, I don't really understand whole thing. The measure $\delta_n$ converges vaguely but not weakly, but I cannot see how that works if I take the definition of weak/vague convergence weak convergence : $\int f(x)\, \mu_n(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \mu(dx)\, f \in C_b$ vague convergence : $\int f(x)\, \mu_n(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \mu(dx)\, f \in C_0$ If I take the $\delta_n$ from above I have $\int f(x)\, \delta_n\,(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \delta_{\infty}(dx)$ How do I take the limit ? Do I calculate the integral at every n while $n\rightarrow \infty$, say if $f(x) \in C_b$ (e.g. $f \equiv 1)$ I get always $1$ but at some $n$ I get $0$ since $f(x)$ is bounded and, hence, it does not converge weakly ? How does the vague case look like ? jed","I am trying to understand 'vague/weak convergence' and need to decide whether or not a measure converges vaguely or weakly. Weak convergence implies vague convergences. However, I don't really understand whole thing. The measure $\delta_n$ converges vaguely but not weakly, but I cannot see how that works if I take the definition of weak/vague convergence weak convergence : $\int f(x)\, \mu_n(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \mu(dx)\, f \in C_b$ vague convergence : $\int f(x)\, \mu_n(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \mu(dx)\, f \in C_0$ If I take the $\delta_n$ from above I have $\int f(x)\, \delta_n\,(dx) \stackrel{n\rightarrow\infty}{\to} \int f(x)\, \delta_{\infty}(dx)$ How do I take the limit ? Do I calculate the integral at every n while $n\rightarrow \infty$, say if $f(x) \in C_b$ (e.g. $f \equiv 1)$ I get always $1$ but at some $n$ I get $0$ since $f(x)$ is bounded and, hence, it does not converge weakly ? How does the vague case look like ? jed",,"['probability', 'probability-distributions', 'weak-convergence']"
43,Confidence interval of a random variable with infinite mean. (St. Petersburg paradox),Confidence interval of a random variable with infinite mean. (St. Petersburg paradox),,"Let $X_i$ be random (independent) discrete variables such that $$\forall k\ge 0 \quad P(X_i=2^k)=2^{-(k+1)}$$ $$\begin{array}{c||ccccccc} v & 1 & 2 & 4 & 8 & 16 & 32 & \dots \\ \hline P(X_i=v) & \frac{1}{2}& \frac{1}{4}& \frac{1}{8}& \frac{1}{16}& \frac{1}{32}& \frac{1}{64} &\dots \end{array} $$ Of course $E(X_i)=\infty$. Let $S_n$ be the mean of the first $n$ $X_i$$$S_n=\frac{1}{n}\sum_{i=1}^{n}X_i$$ Let p, a real such that $0<p<0.5$ I want to compute $a_p(n)$ and $b_p(n)$ (or, at least, an asymptotic approximation when $n\rightarrow\infty$) such that $$\forall n \quad P(S_n<a_p(n))=P(S_n>b_p(n))=p $$ How ? This question is related to the St. Petersburg paradox .","Let $X_i$ be random (independent) discrete variables such that $$\forall k\ge 0 \quad P(X_i=2^k)=2^{-(k+1)}$$ $$\begin{array}{c||ccccccc} v & 1 & 2 & 4 & 8 & 16 & 32 & \dots \\ \hline P(X_i=v) & \frac{1}{2}& \frac{1}{4}& \frac{1}{8}& \frac{1}{16}& \frac{1}{32}& \frac{1}{64} &\dots \end{array} $$ Of course $E(X_i)=\infty$. Let $S_n$ be the mean of the first $n$ $X_i$$$S_n=\frac{1}{n}\sum_{i=1}^{n}X_i$$ Let p, a real such that $0<p<0.5$ I want to compute $a_p(n)$ and $b_p(n)$ (or, at least, an asymptotic approximation when $n\rightarrow\infty$) such that $$\forall n \quad P(S_n<a_p(n))=P(S_n>b_p(n))=p $$ How ? This question is related to the St. Petersburg paradox .",,"['probability', 'random-variables']"
44,Can one sample uniformly from the surface of an $n$-sphere of non-unit radius using normal r.v.'s?,Can one sample uniformly from the surface of an -sphere of non-unit radius using normal r.v.'s?,n,"One can sample coordinates of the surface of a unit radius $n$-dimensional sphere uniformly using the following method: independently generate a vector of $n$ standard normal random variables $\mathbf{x}=[X_1,\ldots,X_n]$, compute the Euclidean norm of this vector $\|\mathbf{x}\|_2=\sqrt{X_1^2+\ldots+X_n^2}$, then vector $\mathbf{x}/\|\mathbf{x}\|_2$ will contain the uniform sample of a coordinate from the surface of a unit-radius $n$-sphere. I am wondering if that method can be extended to sampling from an $n$-sphere with arbitrary radius $r>0$.  My intuition tells me that multiplying the sample from unit-radius $n$-sphere by $r$ might work, but I haven't seen that mentioned anywhere, which makes me think that either my intuition is wrong or this may be a question with an obvious answer. So, can someone clarify: is vector $r\mathbf{x}/\|\mathbf{x}\|_2$ a uniform sample from the surface of an $n$-sphere of radius $r$?  If it is not, is there a way to use i.i.d. normal variates to obtain such a sample?","One can sample coordinates of the surface of a unit radius $n$-dimensional sphere uniformly using the following method: independently generate a vector of $n$ standard normal random variables $\mathbf{x}=[X_1,\ldots,X_n]$, compute the Euclidean norm of this vector $\|\mathbf{x}\|_2=\sqrt{X_1^2+\ldots+X_n^2}$, then vector $\mathbf{x}/\|\mathbf{x}\|_2$ will contain the uniform sample of a coordinate from the surface of a unit-radius $n$-sphere. I am wondering if that method can be extended to sampling from an $n$-sphere with arbitrary radius $r>0$.  My intuition tells me that multiplying the sample from unit-radius $n$-sphere by $r$ might work, but I haven't seen that mentioned anywhere, which makes me think that either my intuition is wrong or this may be a question with an obvious answer. So, can someone clarify: is vector $r\mathbf{x}/\|\mathbf{x}\|_2$ a uniform sample from the surface of an $n$-sphere of radius $r$?  If it is not, is there a way to use i.i.d. normal variates to obtain such a sample?",,"['probability', 'geometry', 'normal-distribution']"
45,poisson distribution jobs in printer,poisson distribution jobs in printer,,"A printer receives a number of jobs in an hour, which is poisson distributed with parameter $\lambda$. Every job is recognized with a probability $p$ such that the job is faulty and wont be printed. (1) What is the distribution of printed jobs? (2) If we assume that we printed $k$ jobs, what is the probability that $n$ jobs arrived. For (1) I did the following: Let $a$ be the number of jobs in an hour, then $\mathbb P(n=a)=\frac{\lambda^n}{n!}e^{-\lambda}$. Let $X$ be the number of printed jobs and $F$ the set of faulty jobs, then $\mathbb P(F)=p$. What we want is $\mathbb P(k=X)$, correct? I guess it is possion again, but why? For (2) I guess we need $\mathbb P(n=k | X=k )$ or something similar?","A printer receives a number of jobs in an hour, which is poisson distributed with parameter $\lambda$. Every job is recognized with a probability $p$ such that the job is faulty and wont be printed. (1) What is the distribution of printed jobs? (2) If we assume that we printed $k$ jobs, what is the probability that $n$ jobs arrived. For (1) I did the following: Let $a$ be the number of jobs in an hour, then $\mathbb P(n=a)=\frac{\lambda^n}{n!}e^{-\lambda}$. Let $X$ be the number of printed jobs and $F$ the set of faulty jobs, then $\mathbb P(F)=p$. What we want is $\mathbb P(k=X)$, correct? I guess it is possion again, but why? For (2) I guess we need $\mathbb P(n=k | X=k )$ or something similar?",,"['probability', 'probability-theory', 'probability-distributions']"
46,Cultish birthday puzzle,Cultish birthday puzzle,,I was asked the following puzzle recently which I couldn't see how to solve. A particular cult wants to find a group of people all of whom have different birthdays for some mysterious ceremony they are about to hold. However all they require in order to be quorate is to have in this group one person whose birthday is on Christmas day and one whose birthday is on the day Easter Sunday falls this year.  They invite people into a room with $10$ chairs one at a time.  If the person who comes in has the same birthday as anyone else in the room (not including the hosts) they are told to sit down. Otherwise they stay in the room standing up as part of the selected group.  What are the chances they can get their group before all the chairs are full?,I was asked the following puzzle recently which I couldn't see how to solve. A particular cult wants to find a group of people all of whom have different birthdays for some mysterious ceremony they are about to hold. However all they require in order to be quorate is to have in this group one person whose birthday is on Christmas day and one whose birthday is on the day Easter Sunday falls this year.  They invite people into a room with $10$ chairs one at a time.  If the person who comes in has the same birthday as anyone else in the room (not including the hosts) they are told to sit down. Otherwise they stay in the room standing up as part of the selected group.  What are the chances they can get their group before all the chairs are full?,,['probability']
47,Sequential allocation of $n$ balls into $n$ urns,Sequential allocation of  balls into  urns,n n,"Assume that there are $n$ balls (numbered from $1$ to $n$) and $n$ urns (numbered from $1$ to $n$). At the beginning no ball is placed in any urn. At $t=1$, each ball is randomly put into an urn (no restriction on how many balls an urn can contain, each ball can be placed into one urn for example) Check each urn and if there is more than one ball, randomly choose one of the balls and keep it in the urn and remove all the other balls. (do this for each urn) At $t=2$, take the balls removed from some urn at $t=1$ and again randomly place into an urn (except the urn that the ball was removed from at $t=1$, say ball 1 was removed from urn 1, then ball 1 can be thrown at urns 2,3,...,n; same for other balls). Again, check each urn and if there is an urn that contains more than one ball and if there was no ball placed to that urn at $t=1$ choose one of them randomly and remove others. If there was a ball placed into that urn at $t=1$ remove all the new balls placed at $t=2$ from that urn. At $t=k$, take the balls removed from some urn at $t=(k-1)$ and again randomly place into an urn ( except the urn that the ball was removed from at $t=1,...,(k-1)$). Again, check each urn and if there is an urn that contains more than one ball, choose one of them randomly if there was no ball placed to that urn at $t=1,\ldots,(k-1)$. If there was a ball placed into that urn at $t=1,\ldots,(k-1)$ remove all the new balls placed at $t=k$ from that urn. Continue in this manner and stop when each urn has only one ball. Although it should be clear, just to emphasize, if a ball is chosen to be placed into an urn at the end of $t=k$, it remains in that urn afterwards, that is, it can not be removed in the later stages. Also, a ball can not be thrown into an urn it was removed in earlier stages. What is the probability that a certain ball, say Ball 1, is placed into some urn at exactly $t=k$ for each $k=1,\ldots,n$? Any suggestions for the solution or even references on similar problems would be appreciated. The answer for $t=1$ is easy:  For example, consider Ball 1, and assume it is thrown into Urn 1 at $t=1$ and let $j$ be the number of balls that are placed into urn 1 at $t=1$ among the remaining $n-1$ balls. Then, probability that ball 1 is placed into urn 1 is: $$ \sum_{j=0}^{n-1}\binom{n-1}{j}\left( \frac{1}{n}\right) ^{j}\left( \frac{n-1}{n% }\right) ^{n-j-1}\left( \frac{1}{j+1% }\right) $$","Assume that there are $n$ balls (numbered from $1$ to $n$) and $n$ urns (numbered from $1$ to $n$). At the beginning no ball is placed in any urn. At $t=1$, each ball is randomly put into an urn (no restriction on how many balls an urn can contain, each ball can be placed into one urn for example) Check each urn and if there is more than one ball, randomly choose one of the balls and keep it in the urn and remove all the other balls. (do this for each urn) At $t=2$, take the balls removed from some urn at $t=1$ and again randomly place into an urn (except the urn that the ball was removed from at $t=1$, say ball 1 was removed from urn 1, then ball 1 can be thrown at urns 2,3,...,n; same for other balls). Again, check each urn and if there is an urn that contains more than one ball and if there was no ball placed to that urn at $t=1$ choose one of them randomly and remove others. If there was a ball placed into that urn at $t=1$ remove all the new balls placed at $t=2$ from that urn. At $t=k$, take the balls removed from some urn at $t=(k-1)$ and again randomly place into an urn ( except the urn that the ball was removed from at $t=1,...,(k-1)$). Again, check each urn and if there is an urn that contains more than one ball, choose one of them randomly if there was no ball placed to that urn at $t=1,\ldots,(k-1)$. If there was a ball placed into that urn at $t=1,\ldots,(k-1)$ remove all the new balls placed at $t=k$ from that urn. Continue in this manner and stop when each urn has only one ball. Although it should be clear, just to emphasize, if a ball is chosen to be placed into an urn at the end of $t=k$, it remains in that urn afterwards, that is, it can not be removed in the later stages. Also, a ball can not be thrown into an urn it was removed in earlier stages. What is the probability that a certain ball, say Ball 1, is placed into some urn at exactly $t=k$ for each $k=1,\ldots,n$? Any suggestions for the solution or even references on similar problems would be appreciated. The answer for $t=1$ is easy:  For example, consider Ball 1, and assume it is thrown into Urn 1 at $t=1$ and let $j$ be the number of balls that are placed into urn 1 at $t=1$ among the remaining $n-1$ balls. Then, probability that ball 1 is placed into urn 1 is: $$ \sum_{j=0}^{n-1}\binom{n-1}{j}\left( \frac{1}{n}\right) ^{j}\left( \frac{n-1}{n% }\right) ^{n-j-1}\left( \frac{1}{j+1% }\right) $$",,"['probability', 'combinatorics']"
48,Asymptotic moments of $\sqrt{n} \bar{X}$ when $X_i$'s are iid Cauchy distributed?,Asymptotic moments of  when 's are iid Cauchy distributed?,\sqrt{n} \bar{X} X_i,"For a Cauchy distribution with density $f(x) =  	\frac{1}{\pi(1 + x^2)}$ , it doesn't have well-defined moments .  Therefore both the law of large numbers and the central limit theorem can't apply to the distribution. For example, Given iid sample points $X_1, \dots, X_n$ of the distribution, as $n\to \infty$, $\bar{X}$ will not converge to a constant in probability . However a note says under the above Cauchy distribution, ""asymptotic variance of $\sqrt{n} \bar{X}$ is $\infty$"", which seems like a version of CLT? The definition of the asymptotic variance of a statistic is defined in Casella's Statistical Infernce: Definition 10.1.9 For an estimator $T_n$, suppose that $k_n(T_n - \tau(\theta)) \to n(0, \sigma^2)$ in distribution. The parameter $\sigma^2$ is called the asymptotic variance or variance of the limit distribution of $T_n$. So I wonder if the above definition applies to the case here, for example, with $\tau(\theta) =0$ and $k_n = \sqrt{n}$? If yes, the limit distribution of $\sqrt{n} \bar{X}$  is $N(0, \infty)$, the asymptotic mean of $\sqrt{n} \bar{X}$  is $0$ and its asymptotic variance is $\infty$? If no, how shall we understand ""the asymptotic variance of $\sqrt{n} \bar{X}$ is $\infty$""? Btw, for each $n$, $\sqrt{n} \bar{X}$ doesn't admit mean and variance, right? Thanks and regards!","For a Cauchy distribution with density $f(x) =  	\frac{1}{\pi(1 + x^2)}$ , it doesn't have well-defined moments .  Therefore both the law of large numbers and the central limit theorem can't apply to the distribution. For example, Given iid sample points $X_1, \dots, X_n$ of the distribution, as $n\to \infty$, $\bar{X}$ will not converge to a constant in probability . However a note says under the above Cauchy distribution, ""asymptotic variance of $\sqrt{n} \bar{X}$ is $\infty$"", which seems like a version of CLT? The definition of the asymptotic variance of a statistic is defined in Casella's Statistical Infernce: Definition 10.1.9 For an estimator $T_n$, suppose that $k_n(T_n - \tau(\theta)) \to n(0, \sigma^2)$ in distribution. The parameter $\sigma^2$ is called the asymptotic variance or variance of the limit distribution of $T_n$. So I wonder if the above definition applies to the case here, for example, with $\tau(\theta) =0$ and $k_n = \sqrt{n}$? If yes, the limit distribution of $\sqrt{n} \bar{X}$  is $N(0, \infty)$, the asymptotic mean of $\sqrt{n} \bar{X}$  is $0$ and its asymptotic variance is $\infty$? If no, how shall we understand ""the asymptotic variance of $\sqrt{n} \bar{X}$ is $\infty$""? Btw, for each $n$, $\sqrt{n} \bar{X}$ doesn't admit mean and variance, right? Thanks and regards!",,['probability']
49,Probability of losing packets,Probability of losing packets,,"I am currently enrolled in an Intro to Networking course and I have been studying for an upcoming exam by doing practice problems in the course textbook. I came across this question that stumped me. It deals with probability, which I have always had a hard time understanding and never really studied in depth. Suppose an IP packet is fragmented into 10 fragments, each with a 1%   (independent) probability of loss. To a reasonable approximation, this   means there is a 10% chance of losing the whole packet due to loss of   a fragment. What is the probability of net loss of the whole packet if   the packet is transmitted twice A) Assuming all fragments received must have been part of the same   transmission? B) Assuming any given fragment may have been part of either   transmission? I assume for part A there is a 20% chance of losing the whole packet, because since we send two transmissions the probability doubles. What I don't understand is how the probability is affected in part B. How does the probability change if the two packets are mixed within each transmission? Can someone explain this to someone who is not a math major? Thanks in advance.","I am currently enrolled in an Intro to Networking course and I have been studying for an upcoming exam by doing practice problems in the course textbook. I came across this question that stumped me. It deals with probability, which I have always had a hard time understanding and never really studied in depth. Suppose an IP packet is fragmented into 10 fragments, each with a 1%   (independent) probability of loss. To a reasonable approximation, this   means there is a 10% chance of losing the whole packet due to loss of   a fragment. What is the probability of net loss of the whole packet if   the packet is transmitted twice A) Assuming all fragments received must have been part of the same   transmission? B) Assuming any given fragment may have been part of either   transmission? I assume for part A there is a 20% chance of losing the whole packet, because since we send two transmissions the probability doubles. What I don't understand is how the probability is affected in part B. How does the probability change if the two packets are mixed within each transmission? Can someone explain this to someone who is not a math major? Thanks in advance.",,['probability']
50,How many boxes will be empty?,How many boxes will be empty?,,"$150$ balls randomly put into $100$ boxes, each ball could be put into any of these 100 boxes with same probability, after that, on average, how many boxes will be empty? No calculator. Choose one of the following: A 0-10 B 10-20 C 20-30 D 30-40 E 40-50 F 50-60 G 60-70 I 70-80 J 80-90 K 90-100","$150$ balls randomly put into $100$ boxes, each ball could be put into any of these 100 boxes with same probability, after that, on average, how many boxes will be empty? No calculator. Choose one of the following: A 0-10 B 10-20 C 20-30 D 30-40 E 40-50 F 50-60 G 60-70 I 70-80 J 80-90 K 90-100",,"['probability', 'balls-in-bins']"
51,Chance of two Gaussian distributions being observations of the same phenomenom?,Chance of two Gaussian distributions being observations of the same phenomenom?,,"For an algorithm used for generation of a road map based upon position-samples, I am looking for a method of determining the probability of a sample belonging to an already discovered element of the map. For the sake of simplicity, the element on the map is represented as one point $v$ (a node in the graph), for which the position $\mu_v$ is estimated using the average of all measurements $M_v$ matched to this position. Each measurement comes from a GPS-source, which gives an approximate position ( $\mu_m$ ) and accuracy ( $\sigma_m$ ). The accuracy follows a Gaussian distribution. The distribution $\sigma_v$ for $v$ is assumed Gaussian, for ease of computation. In the algorithm I use the chance of a measurement and the already estimated node on the map belonging together to determine if a measurement should be merged with the node, or should become a new node on the map. If the chance of belonging together is acceptable, the measurement will be added to the node. If this chance is below a certain threshold (probably 0.05), the measurement will be added to the map generating a new node in the graph. My question is therefore: Given $\mu_v$ , $\sigma_v$ , $\mu_m$ , and $\sigma_m$ : What is the chance that $m$ and $v$ are observations of the same phenomenom?","For an algorithm used for generation of a road map based upon position-samples, I am looking for a method of determining the probability of a sample belonging to an already discovered element of the map. For the sake of simplicity, the element on the map is represented as one point (a node in the graph), for which the position is estimated using the average of all measurements matched to this position. Each measurement comes from a GPS-source, which gives an approximate position ( ) and accuracy ( ). The accuracy follows a Gaussian distribution. The distribution for is assumed Gaussian, for ease of computation. In the algorithm I use the chance of a measurement and the already estimated node on the map belonging together to determine if a measurement should be merged with the node, or should become a new node on the map. If the chance of belonging together is acceptable, the measurement will be added to the node. If this chance is below a certain threshold (probably 0.05), the measurement will be added to the map generating a new node in the graph. My question is therefore: Given , , , and : What is the chance that and are observations of the same phenomenom?",v \mu_v M_v \mu_m \sigma_m \sigma_v v \mu_v \sigma_v \mu_m \sigma_m m v,"['probability', 'statistics', 'normal-distribution']"
52,"$X_n - X_{n-1}$ is i.i.d. mean 1. Is $\frac{1}{n}X_n$ ""nearly"" decreasing a.s.?","is i.i.d. mean 1. Is  ""nearly"" decreasing a.s.?",X_n - X_{n-1} \frac{1}{n}X_n,"Let $0=X_0 \leq X_1 \leq X_2 \leq \cdots $ be an increasing sequence of random variables with $X_n - X_{n-1}$ i.i.d. and $\mathbb{E}(X_n - X_{n-1}) = 1$ for all integers $n > 0$. I want to show that almost surely for each $m$, there is an $M>m$ such that $$ \frac{1}{M}X_M \leq \frac{1}{m}X_m. $$ I've computed $$ \mathbb{E}\left(\frac{T_{n}}{n} - \frac{T_{n-1}}{n-1} \right) = \frac{1}{n} - 1. $$ and  $$ \mathbb{E}\left(\frac{T_{M}}{M} - \frac{T_{m}}{m} \right) = (M-m)\sum_{n=m+1}^{M} \left(\frac{1}{n} - 1\right). $$ I feel like I should be able to use this to show that $$ \mathbb{P}\left(\text{there exists $m$ such that for all $M > m$: } \frac{1}{M}X_M > \frac{1}{m}X_m  \right) = 0 $$ by using independence and forming an infinite product. I'm not sure how to make this work. I would appreciate any help.","Let $0=X_0 \leq X_1 \leq X_2 \leq \cdots $ be an increasing sequence of random variables with $X_n - X_{n-1}$ i.i.d. and $\mathbb{E}(X_n - X_{n-1}) = 1$ for all integers $n > 0$. I want to show that almost surely for each $m$, there is an $M>m$ such that $$ \frac{1}{M}X_M \leq \frac{1}{m}X_m. $$ I've computed $$ \mathbb{E}\left(\frac{T_{n}}{n} - \frac{T_{n-1}}{n-1} \right) = \frac{1}{n} - 1. $$ and  $$ \mathbb{E}\left(\frac{T_{M}}{M} - \frac{T_{m}}{m} \right) = (M-m)\sum_{n=m+1}^{M} \left(\frac{1}{n} - 1\right). $$ I feel like I should be able to use this to show that $$ \mathbb{P}\left(\text{there exists $m$ such that for all $M > m$: } \frac{1}{M}X_M > \frac{1}{m}X_m  \right) = 0 $$ by using independence and forming an infinite product. I'm not sure how to make this work. I would appreciate any help.",,"['probability', 'probability-theory', 'random-variables']"
53,Probability distribution of tossing a coin until obtaining $k$ heads,Probability distribution of tossing a coin until obtaining  heads,k,"My question is the following. We toss a coin, for which probability of obtaining heads is $p \in (0,1]$, until we obtain $k$ heads, not necessarily in a row (generally $k$ heads). Let $X$ be a number of executed tosses. I need to find a probability distribution of $X$. So of course for $t <k$ we have $F_x(t) =0$. And for greater $t$? Firstly I thought that it would be $p\cdot \sum_{n=k}^t $${n-1}\choose {k-1} $$p^{k-1} (1-p)^{n-k-1} $, because we want to have head in the last toss and $k-1$ in all previous ones, but later I realised that things like $100 $ heads in $105$ tosses and $100$ heads in $106$ tosses are not disjoint. Then can somebody help me with finding the probability distribution for $X$? I don't know how to compute probability of tossing $k-1$ heads in $t$ tosses or LESS?","My question is the following. We toss a coin, for which probability of obtaining heads is $p \in (0,1]$, until we obtain $k$ heads, not necessarily in a row (generally $k$ heads). Let $X$ be a number of executed tosses. I need to find a probability distribution of $X$. So of course for $t <k$ we have $F_x(t) =0$. And for greater $t$? Firstly I thought that it would be $p\cdot \sum_{n=k}^t $${n-1}\choose {k-1} $$p^{k-1} (1-p)^{n-k-1} $, because we want to have head in the last toss and $k-1$ in all previous ones, but later I realised that things like $100 $ heads in $105$ tosses and $100$ heads in $106$ tosses are not disjoint. Then can somebody help me with finding the probability distribution for $X$? I don't know how to compute probability of tossing $k-1$ heads in $t$ tosses or LESS?",,"['probability', 'probability-distributions']"
54,Expected Value of a Randomly decreasing function,Expected Value of a Randomly decreasing function,,"We are asked to find the expected value of the following function RDF(N, K) for i = 1 to K     do N = random(N) return N Random(N) returns any integer in the range $[0, N)$ with equal probability and Random(0) = 0 . Let's have a case- N = 4 and K = 3 Our function will return values 4 → 0 → 0 with probability 1/4. 4 → 1 → 0 with probability 1/4. 4 → 2 → 0 with probability 1/8. 4 → 2 → 1 with probability 1/8. 4 → 3 → 0 with probability 1/12. 4 → 3 → 1 with probability 1/12. 4 → 3 → 2 with probability 1/12. Hence the expected value is 0 * 1/4 + 0 * 1/4 + 0 * 1/8 + 1 * 1/8 + 0 * 1/12 + 1 * 1/12 + 2 * 1/12 = 1/8 + 1/12 + 1/6 = 3/8 = 0.375","We are asked to find the expected value of the following function RDF(N, K) for i = 1 to K     do N = random(N) return N Random(N) returns any integer in the range $[0, N)$ with equal probability and Random(0) = 0 . Let's have a case- N = 4 and K = 3 Our function will return values 4 → 0 → 0 with probability 1/4. 4 → 1 → 0 with probability 1/4. 4 → 2 → 0 with probability 1/8. 4 → 2 → 1 with probability 1/8. 4 → 3 → 0 with probability 1/12. 4 → 3 → 1 with probability 1/12. 4 → 3 → 2 with probability 1/12. Hence the expected value is 0 * 1/4 + 0 * 1/4 + 0 * 1/8 + 1 * 1/8 + 0 * 1/12 + 1 * 1/12 + 2 * 1/12 = 1/8 + 1/12 + 1/6 = 3/8 = 0.375",,"['probability', 'random-variables', 'random-functions']"
55,Binomial-Like Distribution with Changing Probability,Binomial-Like Distribution with Changing Probability,,"The Question Assume we have $n$ multiple choice questions, the $k$-th question having $k+1$ answer choices. What is the probability that, guessing randomly, we get at least $r$ questions right? If no general case is available, I am OK with the special case $r = \left\lfloor\frac{n}{2}\right\rfloor + 1$. Example Assume we have four different multiple choice questions. Question 1 Choice A Choice B Question 2 Choice A Choice B Choice C Question 3 Choice A Choice B Choice C Choice D Question 4 Choice A Choice B Choice C Choice D Choice E If we choose the answer to each question at random, what is the probability we get at least three right? (By constructing a probability tree, I get the answer as $11/120$.)","The Question Assume we have $n$ multiple choice questions, the $k$-th question having $k+1$ answer choices. What is the probability that, guessing randomly, we get at least $r$ questions right? If no general case is available, I am OK with the special case $r = \left\lfloor\frac{n}{2}\right\rfloor + 1$. Example Assume we have four different multiple choice questions. Question 1 Choice A Choice B Question 2 Choice A Choice B Choice C Question 3 Choice A Choice B Choice C Choice D Question 4 Choice A Choice B Choice C Choice D Choice E If we choose the answer to each question at random, what is the probability we get at least three right? (By constructing a probability tree, I get the answer as $11/120$.)",,['probability']
56,Exercise 3.5 from Jaynes' Probability Theory - induction?,Exercise 3.5 from Jaynes' Probability Theory - induction?,,"N balls are tossed into M urns; there are evidently $M^N$ ways this can be done. If we consider them all equally likely, what is the probability that each urn receives at least one ball? I tried solving this by induction, or trial, and came to the following result: $$\frac{\binom{M}{N-M}}{M^N}$$ Is it correct? Is there any other way to find it? Now that I've thought about the denominator for a while, it doesn't sound quite right. Conventioning right now that 'xyz...' means 'x balls in urn 1, y balls in urn 2, z balls in urn 3 and so on,' T(M, N) = number of possible distributions of N balls into M urns, F(M,N) = number of distributions of N balls into M urns with at least one ball per urn: N balls into 1 urn: N (T(1, N) = 1 distribution, F(1,N≠0) = 1 distribution) 1 ball into 2 urns: 10 01 (T(2,1) = 2 distributions, F(2,1) = 0 distributions) 2 balls into 2 urns: 20 11 02 (T(2,2) = 3 distributions, F(2,2) = 1 distribution) 3 balls into 2 urns: 30 21 12 03 (T(2,3) = 4 distributions, F(2,3) = 2 distributions) 2 balls into 3 urns: 200 110 101 020 011 002 (T(3,2) = 6 distributions, F(3,2) = 0 distributions) 3 balls into 3 urns: 300 210 201 120 111 102 030 021 012 003 (T(3,3) = 10 distributions, F(3,3) = 1 distribution) 4 balls into 3 urns: 400 310 301 220 211 202 130 121 112 103 040 031 022 013 004 (T(3,4) = 15 distributions, F(3,4) = 3 distributions) 5 balls into 3 urns: 500 410 401 320 311 302 230 221 212 203 140 131 122 113 104 050 041 032 023 014 005 (T(3,5) = 21 distributions, F(3,5) = 6 distributions) 1 ball into 4 urns: 1000 0100 0010 0001 (T(4,1) = 4 distributions, F(4,1) = 0 distributions) 2 balls into 4 urns: 2000 1100 1010 1001 0200 0110 0101 0020 0011 0002 (T(4,2) = 10 distributions, F(4,2) = 0 distributions) 3 balls into 4 urns: 3000 2100 2010 2001 1200 1110 1101 1020 1011 1002 0300 0210 0201 0120 0111 0102 0030 0021 0012 0003 (T(4,3) = 20 distributions, F(4,3) = 0 distributions) 4 balls into 4 urns: 4000 3100 3010 3001 2200 2110 2101 2020 2011 2002 1300 1210 1201 1120 1111 1102 1030 1021 1012 1003 0400 0310 0301 0220 0211 0202 0130 0121 0112 0103 0040 0031 0022 0013 0004 (T(4,4) = 35 distributions, F(4,4) = 1 distribution) 5 balls into 4 urns: 5000 4100 4010 4001 3200 3110 3101 3020 3011 3002 2300 2210 2201 2120 2111 2102 2030 2021 2012 2003 1400 1310 1301 1220 1211 1202 1130 1121 1112 1103 1040 1031 1022 1013 1004 0500 0410 0401 0320 0311 0302 0230 0221 0212 0203 0140 0131 0122 0113 0104 0050 0041 0032 0023 0014 0005 (T(4,5) = 56 distributions, F(4,5) = 4 distributions) From those numbers, it looks like $T(M,N) = \binom{N+M-1}{M-1}$ and $F(M,N) = \binom{N-1}{M-1}$. So that would make the probability of having at least one ball in each urn, throwing N balls into M urns, go as: $$p(M,N) = \frac{F(M,N)}{T(M,N)} = \frac{\binom{N-1}{M-1}}{\binom{N+M-1}{M-1}} = \frac{N!(N-1)!}{(N-M)!(N+M-1)!}$$ That doesn't look one bit like the stirling numbers, however, or like the answer you gave me... So, where did I go wrong in my steps? Okay, I completely failed to consider this: he wants me to distinguish the ways that will lead to a certain final ball-urn state, not only the final states themselves, in which case I count 300 only once, but 210 counts 4 times and 111 counts 6 times. So much for my induction on the final sates... So, using the Stirling numbers, that would make the final answer: $$P(M,N) = \frac{\frac{1}{k!}∑_{j=0}^M(-1)^{M-j}\binom{M}{j}j^N}{M^N}$$ That being said, I wonder how I was expected to come to this conclusion, without previous knowledge of the Stirling numbers. Obviously I was supposed to reason them out, but I don't quite see how. Of course that is a fact about my ignorance and not about the problem itself. I shall work on it. Further reading on the Stirling numbers of the second kind article on Wikipedia shows that these numbers are supposed to represent ways to put the balls into unlabelled urns, which would make the following two paths equivalent: 10 -> 20 -> 21 01 -> 02 -> 12 Which they clearly are not, in the problem, because otherwise there wouldn't be $M^N$ ways to fill the urns. In that case, I will remain working on the problem, but what would such a solution look like? Alright, so, following your lead, I got to: $$p(M,N) = 1 - \frac{∑_{j=1}^{M-1}(-1)^{j+1}\binom{M}{j}(M-j)^N}{M^N}$$ And the results agree with induction. I wonder if there are any other possible ways to solve this?","N balls are tossed into M urns; there are evidently $M^N$ ways this can be done. If we consider them all equally likely, what is the probability that each urn receives at least one ball? I tried solving this by induction, or trial, and came to the following result: $$\frac{\binom{M}{N-M}}{M^N}$$ Is it correct? Is there any other way to find it? Now that I've thought about the denominator for a while, it doesn't sound quite right. Conventioning right now that 'xyz...' means 'x balls in urn 1, y balls in urn 2, z balls in urn 3 and so on,' T(M, N) = number of possible distributions of N balls into M urns, F(M,N) = number of distributions of N balls into M urns with at least one ball per urn: N balls into 1 urn: N (T(1, N) = 1 distribution, F(1,N≠0) = 1 distribution) 1 ball into 2 urns: 10 01 (T(2,1) = 2 distributions, F(2,1) = 0 distributions) 2 balls into 2 urns: 20 11 02 (T(2,2) = 3 distributions, F(2,2) = 1 distribution) 3 balls into 2 urns: 30 21 12 03 (T(2,3) = 4 distributions, F(2,3) = 2 distributions) 2 balls into 3 urns: 200 110 101 020 011 002 (T(3,2) = 6 distributions, F(3,2) = 0 distributions) 3 balls into 3 urns: 300 210 201 120 111 102 030 021 012 003 (T(3,3) = 10 distributions, F(3,3) = 1 distribution) 4 balls into 3 urns: 400 310 301 220 211 202 130 121 112 103 040 031 022 013 004 (T(3,4) = 15 distributions, F(3,4) = 3 distributions) 5 balls into 3 urns: 500 410 401 320 311 302 230 221 212 203 140 131 122 113 104 050 041 032 023 014 005 (T(3,5) = 21 distributions, F(3,5) = 6 distributions) 1 ball into 4 urns: 1000 0100 0010 0001 (T(4,1) = 4 distributions, F(4,1) = 0 distributions) 2 balls into 4 urns: 2000 1100 1010 1001 0200 0110 0101 0020 0011 0002 (T(4,2) = 10 distributions, F(4,2) = 0 distributions) 3 balls into 4 urns: 3000 2100 2010 2001 1200 1110 1101 1020 1011 1002 0300 0210 0201 0120 0111 0102 0030 0021 0012 0003 (T(4,3) = 20 distributions, F(4,3) = 0 distributions) 4 balls into 4 urns: 4000 3100 3010 3001 2200 2110 2101 2020 2011 2002 1300 1210 1201 1120 1111 1102 1030 1021 1012 1003 0400 0310 0301 0220 0211 0202 0130 0121 0112 0103 0040 0031 0022 0013 0004 (T(4,4) = 35 distributions, F(4,4) = 1 distribution) 5 balls into 4 urns: 5000 4100 4010 4001 3200 3110 3101 3020 3011 3002 2300 2210 2201 2120 2111 2102 2030 2021 2012 2003 1400 1310 1301 1220 1211 1202 1130 1121 1112 1103 1040 1031 1022 1013 1004 0500 0410 0401 0320 0311 0302 0230 0221 0212 0203 0140 0131 0122 0113 0104 0050 0041 0032 0023 0014 0005 (T(4,5) = 56 distributions, F(4,5) = 4 distributions) From those numbers, it looks like $T(M,N) = \binom{N+M-1}{M-1}$ and $F(M,N) = \binom{N-1}{M-1}$. So that would make the probability of having at least one ball in each urn, throwing N balls into M urns, go as: $$p(M,N) = \frac{F(M,N)}{T(M,N)} = \frac{\binom{N-1}{M-1}}{\binom{N+M-1}{M-1}} = \frac{N!(N-1)!}{(N-M)!(N+M-1)!}$$ That doesn't look one bit like the stirling numbers, however, or like the answer you gave me... So, where did I go wrong in my steps? Okay, I completely failed to consider this: he wants me to distinguish the ways that will lead to a certain final ball-urn state, not only the final states themselves, in which case I count 300 only once, but 210 counts 4 times and 111 counts 6 times. So much for my induction on the final sates... So, using the Stirling numbers, that would make the final answer: $$P(M,N) = \frac{\frac{1}{k!}∑_{j=0}^M(-1)^{M-j}\binom{M}{j}j^N}{M^N}$$ That being said, I wonder how I was expected to come to this conclusion, without previous knowledge of the Stirling numbers. Obviously I was supposed to reason them out, but I don't quite see how. Of course that is a fact about my ignorance and not about the problem itself. I shall work on it. Further reading on the Stirling numbers of the second kind article on Wikipedia shows that these numbers are supposed to represent ways to put the balls into unlabelled urns, which would make the following two paths equivalent: 10 -> 20 -> 21 01 -> 02 -> 12 Which they clearly are not, in the problem, because otherwise there wouldn't be $M^N$ ways to fill the urns. In that case, I will remain working on the problem, but what would such a solution look like? Alright, so, following your lead, I got to: $$p(M,N) = 1 - \frac{∑_{j=1}^{M-1}(-1)^{j+1}\binom{M}{j}(M-j)^N}{M^N}$$ And the results agree with induction. I wonder if there are any other possible ways to solve this?",,"['probability', 'probability-theory']"
57,Conditional independence property: weak union,Conditional independence property: weak union,,"Let $(X,Y,W,Z)$ be disjoint sets of random variables each with finite space. Then prove that if $\Pr(X\mid W,Y \cup Z)=\Pr(X\mid W)$ then $\Pr(X\mid Y,Z \cup W) = \Pr(X\mid Z \cup W)$. This is sometimes referred to as weak union in conditional independence. i am having hard time to prove this. Can someone help me to prove this? Thanks","Let $(X,Y,W,Z)$ be disjoint sets of random variables each with finite space. Then prove that if $\Pr(X\mid W,Y \cup Z)=\Pr(X\mid W)$ then $\Pr(X\mid Y,Z \cup W) = \Pr(X\mid Z \cup W)$. This is sometimes referred to as weak union in conditional independence. i am having hard time to prove this. Can someone help me to prove this? Thanks",,['probability']
58,"(Paul Bartha and Christopher Hitchcock, “The Shooting Room Paradox and Conditionalizing on Measurably Challenged Sets,” Synthese, March 1999)","(Paul Bartha and Christopher Hitchcock, “The Shooting Room Paradox and Conditionalizing on Measurably Challenged Sets,” Synthese, March 1999)",,"I first read this problem here . I am having trouble finding the expected value of the game.  I understand for the first round,but on the 2nd round assuming that no group is killed, does just one person role the dices and if not (6,6), then someone roles for the other 89? Or is it 10 people role the dice and if none of them die, then one role for the other 80? I am having trouble viewing a copy of the primary paper.","I first read this problem here . I am having trouble finding the expected value of the game.  I understand for the first round,but on the 2nd round assuming that no group is killed, does just one person role the dices and if not (6,6), then someone roles for the other 89? Or is it 10 people role the dice and if none of them die, then one role for the other 80? I am having trouble viewing a copy of the primary paper.",,['probability']
59,The probability for guessing a dynamic value (one that changes for each wrong guess),The probability for guessing a dynamic value (one that changes for each wrong guess),,"Please correct me if I am wrong... For a random number X between 1 and 100, the probability for guessing X correctly would be 1/100 For 2 random numbers X and Y between 1 and 100, the probability for guessing X then Y correctly would be (1/100) * (1/100) For a random number X between 1 and 100, what is the probability for guessing X, if X gets a new random value each time we guess X wrong? (Assuming we can guess 100 times, each wrong guess generates a value that is different than the previous one only.)","Please correct me if I am wrong... For a random number X between 1 and 100, the probability for guessing X correctly would be 1/100 For 2 random numbers X and Y between 1 and 100, the probability for guessing X then Y correctly would be (1/100) * (1/100) For a random number X between 1 and 100, what is the probability for guessing X, if X gets a new random value each time we guess X wrong? (Assuming we can guess 100 times, each wrong guess generates a value that is different than the previous one only.)",,"['probability', 'statistics', 'random']"
60,Confidence interval for sum of random subsequence generated by coin tossing,Confidence interval for sum of random subsequence generated by coin tossing,,"This question is related to Sum of random subsequence generated by coin tossing . Here is the corresponding problem description as given by Memming : Let $(\pi_1, \pi_2, \cdots)$ be an infinite sequence of real numbers such that $\forall i\; \pi_i > 0$ and $\sum_i \pi_i = 1$. This can be thought of as a probability over natural numbers. Let $(z_1, z_2, \ldots)$ be a sequence of independently and identically distributed Bernoulli random variables such that $P(z_i = 1) = p$ and $P(z_i = 0) = (1-p)$. What can we say about the distribution of $X = \sum_i \pi_i z_i$? $X$ is the sum of a random subsequence of $(\pi_i)$ generated by coin tossing. Since $E[X] = p$, $X$ can be used to get an estimation for $p$. Given the sequence $\pi_i$, how does the corresponding confidence interval look like? I am especially interested in the case, where $\pi_i$ is a geometric sequence $\pi_i := (1-\rho) \rho^{i-1}$. Edit: More precisely, I would like to know a method to calculate the optimal (smallest) confidence interval. The corresponding lower and upper bounds are functions of the given sequence $(\pi_1, \pi_2, \cdots)$, $L_\alpha=L_\alpha(\pi_1, \pi_2, \cdots)$ and $U_\alpha=U_\alpha(\pi_1, \pi_2, \cdots)$, respectively, which fulfill $P(X<L_\alpha)=P(X>U_\alpha)\leq\frac{\alpha}{2}$ for given confidence level $\alpha$. I would also be satisfied with an efficient numerical procedure. Edit: Changed ...how do the corresponding confidence intervals look like? to ...how does the corresponding confidence interval look like? to make this question more clearly.","This question is related to Sum of random subsequence generated by coin tossing . Here is the corresponding problem description as given by Memming : Let $(\pi_1, \pi_2, \cdots)$ be an infinite sequence of real numbers such that $\forall i\; \pi_i > 0$ and $\sum_i \pi_i = 1$. This can be thought of as a probability over natural numbers. Let $(z_1, z_2, \ldots)$ be a sequence of independently and identically distributed Bernoulli random variables such that $P(z_i = 1) = p$ and $P(z_i = 0) = (1-p)$. What can we say about the distribution of $X = \sum_i \pi_i z_i$? $X$ is the sum of a random subsequence of $(\pi_i)$ generated by coin tossing. Since $E[X] = p$, $X$ can be used to get an estimation for $p$. Given the sequence $\pi_i$, how does the corresponding confidence interval look like? I am especially interested in the case, where $\pi_i$ is a geometric sequence $\pi_i := (1-\rho) \rho^{i-1}$. Edit: More precisely, I would like to know a method to calculate the optimal (smallest) confidence interval. The corresponding lower and upper bounds are functions of the given sequence $(\pi_1, \pi_2, \cdots)$, $L_\alpha=L_\alpha(\pi_1, \pi_2, \cdots)$ and $U_\alpha=U_\alpha(\pi_1, \pi_2, \cdots)$, respectively, which fulfill $P(X<L_\alpha)=P(X>U_\alpha)\leq\frac{\alpha}{2}$ for given confidence level $\alpha$. I would also be satisfied with an efficient numerical procedure. Edit: Changed ...how do the corresponding confidence intervals look like? to ...how does the corresponding confidence interval look like? to make this question more clearly.",,"['probability', 'statistics']"
61,"Two player pool, probability of winning","Two player pool, probability of winning",,"I have what seems like a simple question, but it's been a while since I've done any P/S. So i come to SE for help! Two player pool/billiards: P1 has probability p of sinking a ball on any shot and has N balls remaining, while P2 has prob q and M balls remaining. Question: What is the probability of the first player winning? I can type out my reasoning (and will in an edit - will post before i reason it out though), but my answer has come down to: $$\sum_{j=0}^{M-1} [p^N q^j \sum_{i=0}^\infty [(1-p)^i (1-q)^i]]$$ Is this correct or close? Reasoning: not really theoretical reasoning, but extrapolating the simple cases outwards: (hit = h, miss = m, with probability p = w/p) 1 ball each: possible victory paths - P1 wins w/p, P1 m w/ (1-p), P2 m w/ (1-q), P1 wins w/ p ... etc - $p \sum_{i=0}^\infty (1-p)^i (1-q)^i$ 2 and above balls each: At some point, all the P1 hits must occur - $p^N$ All possible amounts of P2 hits must be accounted for - $\sum_{j=0}^{M-1} q^j$ Every miss variation is accounted for - * <-- This is where i think I am wrong. Is it actually a double sum in and of itself? IE $\sum_{i=0}^\infty \sum_{k=0}^\infty (1-p)^i (1-q)^k$ ? EDIT: Some wolfram alpha shows me that $\sum_{i=0}^\infty (1-p)^i = \frac 1 p$, so I guess my final final equation can be simplified to $$\sum_{j=0}^{M-1} \frac{p^N q^j}{pq} $$ ?? etc.","I have what seems like a simple question, but it's been a while since I've done any P/S. So i come to SE for help! Two player pool/billiards: P1 has probability p of sinking a ball on any shot and has N balls remaining, while P2 has prob q and M balls remaining. Question: What is the probability of the first player winning? I can type out my reasoning (and will in an edit - will post before i reason it out though), but my answer has come down to: $$\sum_{j=0}^{M-1} [p^N q^j \sum_{i=0}^\infty [(1-p)^i (1-q)^i]]$$ Is this correct or close? Reasoning: not really theoretical reasoning, but extrapolating the simple cases outwards: (hit = h, miss = m, with probability p = w/p) 1 ball each: possible victory paths - P1 wins w/p, P1 m w/ (1-p), P2 m w/ (1-q), P1 wins w/ p ... etc - $p \sum_{i=0}^\infty (1-p)^i (1-q)^i$ 2 and above balls each: At some point, all the P1 hits must occur - $p^N$ All possible amounts of P2 hits must be accounted for - $\sum_{j=0}^{M-1} q^j$ Every miss variation is accounted for - * <-- This is where i think I am wrong. Is it actually a double sum in and of itself? IE $\sum_{i=0}^\infty \sum_{k=0}^\infty (1-p)^i (1-q)^k$ ? EDIT: Some wolfram alpha shows me that $\sum_{i=0}^\infty (1-p)^i = \frac 1 p$, so I guess my final final equation can be simplified to $$\sum_{j=0}^{M-1} \frac{p^N q^j}{pq} $$ ?? etc.",,['probability']
62,Kernel density estimation for heavy-tailed distributions using the champernowne transformation,Kernel density estimation for heavy-tailed distributions using the champernowne transformation,,"I am trying to follow this paper to estimate the density for a heavy-tailed distributions using the champernowne transformation. Alternative link to the paper Another alternative link to the paper However, I do not understand the final step to transform the kernel density estimate of the transformed data back to the untransformed data set. An outline of the procedure is below: Firstly, the data, X, is transformed: Where T() is a modified Champernowne CDF. The parameter alpha, M and c have already been estimated. Then a Kernel Density Estimate, with a Gaussian kernel is done on the transformed data. However, the data must lie in the interval (0,1), so we only take the that part of the estimated density and then divide by the integral of that part of the density. The final step, which I don't understand is the formula below. What does the denominator mean? I understand that the numerator is the estimate of the transformed data set. I can also see the transformered data set in the denominator, T(), but what is T'? The authors of the paper then write the following expression for the density estimator of the untransformed dataset:","I am trying to follow this paper to estimate the density for a heavy-tailed distributions using the champernowne transformation. Alternative link to the paper Another alternative link to the paper However, I do not understand the final step to transform the kernel density estimate of the transformed data back to the untransformed data set. An outline of the procedure is below: Firstly, the data, X, is transformed: Where T() is a modified Champernowne CDF. The parameter alpha, M and c have already been estimated. Then a Kernel Density Estimate, with a Gaussian kernel is done on the transformed data. However, the data must lie in the interval (0,1), so we only take the that part of the estimated density and then divide by the integral of that part of the density. The final step, which I don't understand is the formula below. What does the denominator mean? I understand that the numerator is the estimate of the transformed data set. I can also see the transformered data set in the denominator, T(), but what is T'? The authors of the paper then write the following expression for the density estimator of the untransformed dataset:",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'transformation']"
63,What is the PDF of the Square Length of a Normally-Generated Vector?,What is the PDF of the Square Length of a Normally-Generated Vector?,,"Consider a vector $\mathbf{x}\in\mathbb{R}^n$, where each element in $\mathbf{x}$ is sampled independently from a normal distribution $\mathcal{N}(0,\sigma^2)$. What is the probability density function of $||\mathbf{x}||_2^2$?","Consider a vector $\mathbf{x}\in\mathbb{R}^n$, where each element in $\mathbf{x}$ is sampled independently from a normal distribution $\mathcal{N}(0,\sigma^2)$. What is the probability density function of $||\mathbf{x}||_2^2$?",,"['probability', 'probability-distributions', 'normal-distribution']"
64,Bounds on integral for computing expectation,Bounds on integral for computing expectation,,I have a discrete random variable $X$ with $P(X \geq x) = c^x$ and I would like to bound $E(\log{X})$. I can write this as follows I think $$E(\log{X}) = \sum_{x=1}^{\infty} c^x \log{x}.$$ We know that $0\leq c \leq 1$. I would like to bound $E(\log{X})$ above and below. One would approach would be to replace the sum by an integral but I didn't get anywhere. Can anyone see how to get good bounds? Question has been edited to make it clearer.,I have a discrete random variable $X$ with $P(X \geq x) = c^x$ and I would like to bound $E(\log{X})$. I can write this as follows I think $$E(\log{X}) = \sum_{x=1}^{\infty} c^x \log{x}.$$ We know that $0\leq c \leq 1$. I would like to bound $E(\log{X})$ above and below. One would approach would be to replace the sum by an integral but I didn't get anywhere. Can anyone see how to get good bounds? Question has been edited to make it clearer.,,"['probability', 'integration', 'asymptotics']"
65,Puzzle : Birds on a circular wire,Puzzle : Birds on a circular wire,,The problem is taken from my course on randomized algorithms : There is a circle made of wire. n birds (assume n>2) occupy uniformly random position over it (visualize each bird occupying a point on the circumference of the circle). This will lead to partitioning of circle into n segments. We follow the following rule for painting these segments. A segment is painted if it is smaller than at least one of its neighboring segments. What is the expected fraction of the circle which gets painted? I am not able to frame it mathematically. Any hints?,The problem is taken from my course on randomized algorithms : There is a circle made of wire. n birds (assume n>2) occupy uniformly random position over it (visualize each bird occupying a point on the circumference of the circle). This will lead to partitioning of circle into n segments. We follow the following rule for painting these segments. A segment is painted if it is smaller than at least one of its neighboring segments. What is the expected fraction of the circle which gets painted? I am not able to frame it mathematically. Any hints?,,"['probability', 'algorithms', 'random-variables']"
66,Marginals and compactness in the narrow topology,Marginals and compactness in the narrow topology,,"I've read in a working paper (bottom of page 9) that the following is a ""standard result"": Let $A$ be a compact metric space and $T$ be a Polish space.     Let $\rho$ be a Borel probability measure on $T$. Let   $\mathcal{M}^\rho(T\times A)$ be the set of Borel probability measures   on $T\times A$ such that the marginal on $T$ is equal to $\rho$. Then   $\mathcal{M}^\rho(T\times A)$ is a compact set in the narrow topology on the space of probability measures. Could anyone tell me how to show this or give me a reference? The narrow topology is the same as the weak* topology or the topology of weak convergence of measures.","I've read in a working paper (bottom of page 9) that the following is a ""standard result"": Let $A$ be a compact metric space and $T$ be a Polish space.     Let $\rho$ be a Borel probability measure on $T$. Let   $\mathcal{M}^\rho(T\times A)$ be the set of Borel probability measures   on $T\times A$ such that the marginal on $T$ is equal to $\rho$. Then   $\mathcal{M}^\rho(T\times A)$ is a compact set in the narrow topology on the space of probability measures. Could anyone tell me how to show this or give me a reference? The narrow topology is the same as the weak* topology or the topology of weak convergence of measures.",,"['probability', 'reference-request', 'measure-theory']"
67,Estimate confidence interval for true positive rate and false positive rate,Estimate confidence interval for true positive rate and false positive rate,,"I asked a question in the statistics stack exchange about ""Error of generalized classifier performance"" https://stats.stackexchange.com/questions/41400/error-of-generalized-classifier-performance : I am working on a problem where it is expensive to label data and I have sampled a small subset of the available data and labeled it. My classifier is a binary classifier that I use with the hope of removing samples that are ""false"" but keep samples that are ""true"". My question is: how well does the classifier performance generalize to the full population? Some numbers: I sample 500 data records and label them (uniform sample). True | False 180 | 320 If I assume a binomial distribution I can calculate (e.g. using R) a confidence interval as such: > binom.confint(180,500, conf.level = 0.95, methods=""exact"")   method   x   n mean    lower     upper  1  exact 180 500 0.36 0.317863 0.4038034 If I then use a classifier and the performance is the following: === Confusion Matrix ===   a   b   <-- classified as 150  30 |   a = related   33 287 |   b = unrelated I know how I can calculate precision and F measure from this result, but what is the error? How well does this generalize to the whole population? Can we make any error estimation with the help of the above confidence interval of the binomial distribution? I have been doing some calculations where I assume that the true-positive and false-positive rates from the classification hold in general. But I know that this is more or less a back-of the envelope type estimation. But got no answers. I can reformulate the question a bit and I hope someone can lead me in the right direction. I have a classifier (a black box) that assigns a label to each record. What can I say about the error here? In my data mining book they talk about estimating accuracy with the binomial distribution. But what I am interested in is estimating the true positive and false positive rates. \ Classifier Data     T   F      T p_tp       F p_fp I have sampled 500 records that I have annotated with class labels. I can estimate the underlying distribution using the binomial to get a confidence interval for p(d=t). Here d stands for data and t for true. But what about: p( c(d)=t | d=t ) //true positive rate  p( c(d)=t | d=f ) //false positive rate My education in statistics is regrettably limited (5 weeks course at uni). But I still want to see a solution even if I (maybe) can't understand it.","I asked a question in the statistics stack exchange about ""Error of generalized classifier performance"" https://stats.stackexchange.com/questions/41400/error-of-generalized-classifier-performance : I am working on a problem where it is expensive to label data and I have sampled a small subset of the available data and labeled it. My classifier is a binary classifier that I use with the hope of removing samples that are ""false"" but keep samples that are ""true"". My question is: how well does the classifier performance generalize to the full population? Some numbers: I sample 500 data records and label them (uniform sample). True | False 180 | 320 If I assume a binomial distribution I can calculate (e.g. using R) a confidence interval as such: > binom.confint(180,500, conf.level = 0.95, methods=""exact"")   method   x   n mean    lower     upper  1  exact 180 500 0.36 0.317863 0.4038034 If I then use a classifier and the performance is the following: === Confusion Matrix ===   a   b   <-- classified as 150  30 |   a = related   33 287 |   b = unrelated I know how I can calculate precision and F measure from this result, but what is the error? How well does this generalize to the whole population? Can we make any error estimation with the help of the above confidence interval of the binomial distribution? I have been doing some calculations where I assume that the true-positive and false-positive rates from the classification hold in general. But I know that this is more or less a back-of the envelope type estimation. But got no answers. I can reformulate the question a bit and I hope someone can lead me in the right direction. I have a classifier (a black box) that assigns a label to each record. What can I say about the error here? In my data mining book they talk about estimating accuracy with the binomial distribution. But what I am interested in is estimating the true positive and false positive rates. \ Classifier Data     T   F      T p_tp       F p_fp I have sampled 500 records that I have annotated with class labels. I can estimate the underlying distribution using the binomial to get a confidence interval for p(d=t). Here d stands for data and t for true. But what about: p( c(d)=t | d=t ) //true positive rate  p( c(d)=t | d=f ) //false positive rate My education in statistics is regrettably limited (5 weeks course at uni). But I still want to see a solution even if I (maybe) can't understand it.",,"['probability', 'statistics']"
68,Probability of one event given the probability of two other events,Probability of one event given the probability of two other events,,"Let $A$, $B$, and $C$ be events. Suppose $P(A) \ge .9$, $P(B) \ge .8$, and $P(A \cap B \cap C)=0$. Show that $P(C) \le .3$. Now, I tried using the inclusion-exclusion principle to solve this, but I'm getting nowhere. Perhaps that is the correct way of starting, but I'm looking at it the wrong way? It's been a little white since I've worked with this, so I'm not sure I'm on the right track. Also, is it correct that $P(A \cap B \cap C)=0$ means that the events $A$, $B$, and $C$ are disjoint (but not necessarily $A \cap C$, $A \cap B$, and $B \cap C$)? Any hints would be appreciated. Thanks.","Let $A$, $B$, and $C$ be events. Suppose $P(A) \ge .9$, $P(B) \ge .8$, and $P(A \cap B \cap C)=0$. Show that $P(C) \le .3$. Now, I tried using the inclusion-exclusion principle to solve this, but I'm getting nowhere. Perhaps that is the correct way of starting, but I'm looking at it the wrong way? It's been a little white since I've worked with this, so I'm not sure I'm on the right track. Also, is it correct that $P(A \cap B \cap C)=0$ means that the events $A$, $B$, and $C$ are disjoint (but not necessarily $A \cap C$, $A \cap B$, and $B \cap C$)? Any hints would be appreciated. Thanks.",,['probability']
69,"If A and C are independent, is P(A,C) = P(A)*P(C) always true?","If A and C are independent, is P(A,C) = P(A)*P(C) always true?",,"Here is the original question. Of three possible events, event A is independent of the other two, and events B and C are mutually exclusive.  The probabilities that the individual events A, B, and C will occur are 0.5, 0.3, and 0.2, respectively.  What is the probability that both event A and event C will occur? The answer to this question is: Start with the “mutually exclusive” events, as this is the most restrictive statement.  If event B happens, event C cannot happen.  Likewise, if event C happens, event B cannot happen.  It is possible that neither event B or C will happen, but they can’t both happen. Consider the possibilities, starting with whether event B happens. If event B occurs, event C cannot occur, so there is no way for both event A and event C to happen. (i.e. Probability of both A and C is zero if B occurs.)  If event B does not occur, event C might happen, as might event A. Thus, the probability that both event A and event C will occur is the probability that B will NOT happen, A will happen, and C will happen.  {NOTE:  ""and"" means multiply probabilities, ""or"" would mean add probabilities.} P(A and C) = P(not B) × P(A) × P(C)   P(A and C) = [1 – 0.3] × 0.5 × 0.2 = 0.7 × 0.5 × 0.2 = 0.07 = 7% The correct answer is 7% Source: http://www.manhattanprep.com/gre/ChallengeProblems/LastWeek/ My question is: 1) P(A,C) = 0.07 in this question. However, this is not P(A)*P(C)=0.10, despite A and C are independent. Why does the rule P(A,C) = P(A)*P(C) fail even though A and C are independent? Is there a certain restraint that applies to this rule? 2) Event B and C are not independent. However, the problem states that P(A,C,~B) = P(A)*P(C)*P(~B). I thought this was possible only if C and ~B are independent. Can you please explain if this is valid? Your help is greatly appreciated. Have a wonderful day.","Here is the original question. Of three possible events, event A is independent of the other two, and events B and C are mutually exclusive.  The probabilities that the individual events A, B, and C will occur are 0.5, 0.3, and 0.2, respectively.  What is the probability that both event A and event C will occur? The answer to this question is: Start with the “mutually exclusive” events, as this is the most restrictive statement.  If event B happens, event C cannot happen.  Likewise, if event C happens, event B cannot happen.  It is possible that neither event B or C will happen, but they can’t both happen. Consider the possibilities, starting with whether event B happens. If event B occurs, event C cannot occur, so there is no way for both event A and event C to happen. (i.e. Probability of both A and C is zero if B occurs.)  If event B does not occur, event C might happen, as might event A. Thus, the probability that both event A and event C will occur is the probability that B will NOT happen, A will happen, and C will happen.  {NOTE:  ""and"" means multiply probabilities, ""or"" would mean add probabilities.} P(A and C) = P(not B) × P(A) × P(C)   P(A and C) = [1 – 0.3] × 0.5 × 0.2 = 0.7 × 0.5 × 0.2 = 0.07 = 7% The correct answer is 7% Source: http://www.manhattanprep.com/gre/ChallengeProblems/LastWeek/ My question is: 1) P(A,C) = 0.07 in this question. However, this is not P(A)*P(C)=0.10, despite A and C are independent. Why does the rule P(A,C) = P(A)*P(C) fail even though A and C are independent? Is there a certain restraint that applies to this rule? 2) Event B and C are not independent. However, the problem states that P(A,C,~B) = P(A)*P(C)*P(~B). I thought this was possible only if C and ~B are independent. Can you please explain if this is valid? Your help is greatly appreciated. Have a wonderful day.",,['probability']
70,Does Bayesian probability have a different interpretation of a random variable?,Does Bayesian probability have a different interpretation of a random variable?,,Bayesian probability interprets the meaning of the probability of a random variable as some degree of belief.  But does this result in any difference in the interpretation of a random variable itself?,Bayesian probability interprets the meaning of the probability of a random variable as some degree of belief.  But does this result in any difference in the interpretation of a random variable itself?,,"['probability', 'bayesian']"
71,How do I calculate the aposteriori probability distribution for someone's answer to a poll being an approval?,How do I calculate the aposteriori probability distribution for someone's answer to a poll being an approval?,,"Imagine I'm polling a random sample from the population and it asks them if they approve of the President or not. I also ask them some categorical demographic questions (age-bracket, race, gender, income-bracket). Now given a new randomly-selected person from the population, I want to know the aposteriori probability distribution that he approves. I take it that if this is all I know, the answer is just $Beta[approvers+1, nonapprovers+1]$ (assuming a uniform prior). But I happen to know all the demographic information for this person too -- it's a 24-to-34-year-old white man in the lowest income bracket. Now I could just look at the 24-to-34-year-old low-income white men I polled, but I only polled one (or no) other person like that, leaving me essentially just with my prior. How do I appropriately combine all the information I have about different demographics and sub-demographics?","Imagine I'm polling a random sample from the population and it asks them if they approve of the President or not. I also ask them some categorical demographic questions (age-bracket, race, gender, income-bracket). Now given a new randomly-selected person from the population, I want to know the aposteriori probability distribution that he approves. I take it that if this is all I know, the answer is just $Beta[approvers+1, nonapprovers+1]$ (assuming a uniform prior). But I happen to know all the demographic information for this person too -- it's a 24-to-34-year-old white man in the lowest income bracket. Now I could just look at the 24-to-34-year-old low-income white men I polled, but I only polled one (or no) other person like that, leaving me essentially just with my prior. How do I appropriately combine all the information I have about different demographics and sub-demographics?",,"['probability', 'statistics', 'probability-distributions', 'bayesian']"
72,Puzzle: Guessing the bigger number!,Puzzle: Guessing the bigger number!,,"Consider the following interesting puzzle: ""Alice writes two distinct real numbers between 0 and  1 on two sheets of paper. Bob selects one of the sheets randomly to inspect it. He then  has to declare  whether the  number he sees is the  bigger or smaller of the two.  Is there any way he can expect to be correct more than half the times Alice plays this game with him?"" SPOILER ALERT: In the linked site below, the solution to this puzzle is right below the posed question. The puzzle is lifted from here . In the following questions, I have just given my hunch. My calculations could be wrong as I am not very strong at probability. Questions: 1) Is there an assumption here that Bob can play the game many times with Alice (from the last statement)? Are the real numbers assumed to be fixed? My hunch: If it is played in time, then fixed real numbers dont make sense. So perhaps we have to think over different realizations. Is this right? 2)[Variant] If Bob knows that Alice samples the two real numbers uniformly and independently from [0,1] every time she plays then can he design a strategy that works more than half of the times? My opinion: I have a strategy that works two-thirds of the time. However I am not sure if that is the best! Is there a strategy that works better? 3) Is there a distribution from which if Alice samples her numbers independently, then she can ensure that Bob can never do better than getting right half the time? My opinion: No! Although I am not sure. I guess the independence assumption is what allows Bob to get a good strategy. 4) If Alice can sample two real numbers in a correlated fashion every time she plays, can she ensure that Bob can never do better than getting right half the time? My opinion: Yes! I think I have an answer. P.S: I will post my version of the answers after a few days, if nobody comes up with the same idea. Thanks! :) P.P.S: This is not a homework problem, but just a musing :)","Consider the following interesting puzzle: ""Alice writes two distinct real numbers between 0 and  1 on two sheets of paper. Bob selects one of the sheets randomly to inspect it. He then  has to declare  whether the  number he sees is the  bigger or smaller of the two.  Is there any way he can expect to be correct more than half the times Alice plays this game with him?"" SPOILER ALERT: In the linked site below, the solution to this puzzle is right below the posed question. The puzzle is lifted from here . In the following questions, I have just given my hunch. My calculations could be wrong as I am not very strong at probability. Questions: 1) Is there an assumption here that Bob can play the game many times with Alice (from the last statement)? Are the real numbers assumed to be fixed? My hunch: If it is played in time, then fixed real numbers dont make sense. So perhaps we have to think over different realizations. Is this right? 2)[Variant] If Bob knows that Alice samples the two real numbers uniformly and independently from [0,1] every time she plays then can he design a strategy that works more than half of the times? My opinion: I have a strategy that works two-thirds of the time. However I am not sure if that is the best! Is there a strategy that works better? 3) Is there a distribution from which if Alice samples her numbers independently, then she can ensure that Bob can never do better than getting right half the time? My opinion: No! Although I am not sure. I guess the independence assumption is what allows Bob to get a good strategy. 4) If Alice can sample two real numbers in a correlated fashion every time she plays, can she ensure that Bob can never do better than getting right half the time? My opinion: Yes! I think I have an answer. P.S: I will post my version of the answers after a few days, if nobody comes up with the same idea. Thanks! :) P.P.S: This is not a homework problem, but just a musing :)",,"['probability', 'puzzle']"
73,one-dimensional random walk,one-dimensional random walk,,"Consider a one-dimensional random walk whose steps are $+2$ and $-1$ with probabilities $p$ and $1-p$ respectively, starting from $0$ and in the interval {$-n$, $n$}. The walk ends at $-n$ or $n$ or $n+1$. Let $m$ be the number of integers ""jumped"" during the walk. Is there a limit for the ratio $\frac{m}{2n+1}$ for $n \rightarrow \infty$? Three examples to clarify: 1) n=15 p= 1/2  Steps = {-1, 2, -1, 2, -1, 2, -1, 2, -1, -1, 2, 2, -1, -1, 2, 2, 2, 2, -1, \ -1, 2, -1, -1, 2, -1, 2, -1, -1, 2, 2} Positions = {0, -1, 1, 0, 2, 1, 3, 2, 4, 3, 2, 4, 6, 5, 4, 6, 8, 10, 12, 11, 10, \ 12, 11, 10, 12, 11, 13, 12, 11, 13, 15} Missed (jumped) positions =  {-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, 7, 9, 14} m = 17;  r = m/(2 n +1) = 0.548387 2) n= 15 p=1/2  Steps = {2, 2, 2, 2, -1, -1, 2, 2, 2, -1, -1, -1, -1, 2, 2, -1, -1, -1, 2, \ -1, 2, -1, -1, 2, 2, 2} Positions = {0, 2, 4, 6, 8, 7, 6, 8, 10, 12, 11, 10, 9, 8, 10, 12, 11, 10, 9, 11, \ 10, 12, 11, 10, 12, 14, 16} Missed positions =  {-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 1, 3, 5, 13, 15} m =20;  r = m/(2 n +1) = 0.645161 3) n=20 p=1/2  Steps = {-1, 2, -1, 2, 2, 2, -1, -1, -1, -1, -1, -1, 2, -1, 2, 2, 2, -1, 2, \ -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, 2, -1, 2, \ -1, 2, 2, -1, -1, -1, -1, -1, -1, -1, 2, 2, -1, -1, 2, 2, -1, 2, -1, \ 2, 2, 2, -1, 2, 2, 2, 2} Positions = {0, -1, 1, 0, 2, 4, 6, 5, 4, 3, 2, 1, 0, 2, 1, 3, 5, 7, 6, 8, 7, 9, \ 8, 7, 6, 5, 4, 6, 5, 4, 3, 5, 4, 3, 2, 4, 3, 5, 4, 6, 8, 7, 6, 5, 4, \ 3, 2, 1, 3, 5, 4, 3, 5, 7, 6, 8, 7, 9, 11, 13, 12, 14, 16, 18, 20} Missed positions =  {-20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, \ -6, -5, -4, -3, -2, 10, 15, 17, 19} m =20;  r = m/(2 n +1) = 0.560976 A simulation with the range {-2000,2000}, iterated 1000 times provides r as 0.572958. The question is: Is there a limit for n -> Infinity based on: (n, p, base steps {-1,2}) ?","Consider a one-dimensional random walk whose steps are $+2$ and $-1$ with probabilities $p$ and $1-p$ respectively, starting from $0$ and in the interval {$-n$, $n$}. The walk ends at $-n$ or $n$ or $n+1$. Let $m$ be the number of integers ""jumped"" during the walk. Is there a limit for the ratio $\frac{m}{2n+1}$ for $n \rightarrow \infty$? Three examples to clarify: 1) n=15 p= 1/2  Steps = {-1, 2, -1, 2, -1, 2, -1, 2, -1, -1, 2, 2, -1, -1, 2, 2, 2, 2, -1, \ -1, 2, -1, -1, 2, -1, 2, -1, -1, 2, 2} Positions = {0, -1, 1, 0, 2, 1, 3, 2, 4, 3, 2, 4, 6, 5, 4, 6, 8, 10, 12, 11, 10, \ 12, 11, 10, 12, 11, 13, 12, 11, 13, 15} Missed (jumped) positions =  {-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, 7, 9, 14} m = 17;  r = m/(2 n +1) = 0.548387 2) n= 15 p=1/2  Steps = {2, 2, 2, 2, -1, -1, 2, 2, 2, -1, -1, -1, -1, 2, 2, -1, -1, -1, 2, \ -1, 2, -1, -1, 2, 2, 2} Positions = {0, 2, 4, 6, 8, 7, 6, 8, 10, 12, 11, 10, 9, 8, 10, 12, 11, 10, 9, 11, \ 10, 12, 11, 10, 12, 14, 16} Missed positions =  {-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 1, 3, 5, 13, 15} m =20;  r = m/(2 n +1) = 0.645161 3) n=20 p=1/2  Steps = {-1, 2, -1, 2, 2, 2, -1, -1, -1, -1, -1, -1, 2, -1, 2, 2, 2, -1, 2, \ -1, 2, -1, -1, -1, -1, -1, 2, -1, -1, -1, 2, -1, -1, -1, 2, -1, 2, \ -1, 2, 2, -1, -1, -1, -1, -1, -1, -1, 2, 2, -1, -1, 2, 2, -1, 2, -1, \ 2, 2, 2, -1, 2, 2, 2, 2} Positions = {0, -1, 1, 0, 2, 4, 6, 5, 4, 3, 2, 1, 0, 2, 1, 3, 5, 7, 6, 8, 7, 9, \ 8, 7, 6, 5, 4, 6, 5, 4, 3, 5, 4, 3, 2, 4, 3, 5, 4, 6, 8, 7, 6, 5, 4, \ 3, 2, 1, 3, 5, 4, 3, 5, 7, 6, 8, 7, 9, 11, 13, 12, 14, 16, 18, 20} Missed positions =  {-20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, \ -6, -5, -4, -3, -2, 10, 15, 17, 19} m =20;  r = m/(2 n +1) = 0.560976 A simulation with the range {-2000,2000}, iterated 1000 times provides r as 0.572958. The question is: Is there a limit for n -> Infinity based on: (n, p, base steps {-1,2}) ?",,"['probability', 'stochastic-processes', 'random-walk']"
74,"Difference between population, sample and sample value.","Difference between population, sample and sample value.",,"I was going through a book and reached a point where the author is comparing a Population, Sample and Sample Values. I don't seem to understand the difference at all. (Caps are Random Variables, small font are values/data points) What is the role of Random Variables here? What does the numbering in X imply? ($X_i \forall i\in \{1,2,3,\cdots,n\}$) What does the vertical line from $X_1$ to $x_1$ suggest?","I was going through a book and reached a point where the author is comparing a Population, Sample and Sample Values. I don't seem to understand the difference at all. (Caps are Random Variables, small font are values/data points) What is the role of Random Variables here? What does the numbering in X imply? ($X_i \forall i\in \{1,2,3,\cdots,n\}$) What does the vertical line from $X_1$ to $x_1$ suggest?",,['probability']
75,Mlodinow. The Drunkard's Walk. An example from the book.,Mlodinow. The Drunkard's Walk. An example from the book.,,"This excerpt is from Leonard Mlodinow's book The Drunkard's Walk: And   although Fortune is fair in potentialities, she is not fair in outcomes.   That means that if each of 10 Hollywood executives tosses 10 coins,   although each has an equal chance of being the winner or the loser,   in the end there will be winners and losers. In this example, the   chances are 2 out of 3 that at least 1 of the executives will score 8 or   more heads or tails. How can it be proved with math?","This excerpt is from Leonard Mlodinow's book The Drunkard's Walk: And   although Fortune is fair in potentialities, she is not fair in outcomes.   That means that if each of 10 Hollywood executives tosses 10 coins,   although each has an equal chance of being the winner or the loser,   in the end there will be winners and losers. In this example, the   chances are 2 out of 3 that at least 1 of the executives will score 8 or   more heads or tails. How can it be proved with math?",,"['probability', 'probability-theory']"
76,Bounding $\|(X'X)^{-1}X'\mathbf{1}\|_{\infty}$ in probability,Bounding  in probability,\|(X'X)^{-1}X'\mathbf{1}\|_{\infty},"Let $X \in \mathbb{R}^{n \times d}$ be a random matrix with independent elements $N(0, 1)$ and let $\mathbf{1}$ be an n-vector of ones. Assume that $d \asymp n^\alpha$ for some $\alpha > 0$. I would like to find a bound on  $$ \|(n^{-1}X'X)^{-1}n^{-1}X'\mathbf{1}\|_{\infty} $$ that holds with probability $1-o(1)$. Simulations suggest that the bound should look like ${\cal O}(\sqrt{\frac{d}{n}})$ (modulo logarithmic factors in d and n), but I have problems proving that. Below are a few approaches that I have tried, but am not sure how to proceed with them. Question 1 : Using standard Gaussian tail bounds, we have that $\|n^{-1}X'\mathbf{1}\|_{\infty} \leq \sqrt{\frac{2\log(d\log(n))}{n}}$ with probability $1-o(n)$. Is there a way to condition on the event $\{\|n^{-1}X'X - I\|_{\rm op} \leq c_1\sqrt{\frac{d}{n}}\}$ and analyze $\|n^{-1}X'\mathbf{1}\|_{\infty}$ on it? That is, how does distribution of $\|n^{-1}X'\mathbf{1}\|_{\infty}$ change once we condition on $\{\|n^{-1}X'X - I\|_{\rm op} \leq c_1\sqrt{\frac{d}{n}}\}$? Question 2 : Let $X = USV'$ be the SVD decomposition of $X$. Then $(n^{-1}X'X)^{-1}n^{-1}X'\mathbf{1} = VS^{-1}U'\mathbf{1}$. Can I assume without loss of generality that $V = I$, that is, the matrix $V$ is identity, since the distribution of $X$ is rotationally invariant? Question 3 : This is related to previous question. How does the distribution of $X'\mathbf{1}$ change once we condition on $S$.","Let $X \in \mathbb{R}^{n \times d}$ be a random matrix with independent elements $N(0, 1)$ and let $\mathbf{1}$ be an n-vector of ones. Assume that $d \asymp n^\alpha$ for some $\alpha > 0$. I would like to find a bound on  $$ \|(n^{-1}X'X)^{-1}n^{-1}X'\mathbf{1}\|_{\infty} $$ that holds with probability $1-o(1)$. Simulations suggest that the bound should look like ${\cal O}(\sqrt{\frac{d}{n}})$ (modulo logarithmic factors in d and n), but I have problems proving that. Below are a few approaches that I have tried, but am not sure how to proceed with them. Question 1 : Using standard Gaussian tail bounds, we have that $\|n^{-1}X'\mathbf{1}\|_{\infty} \leq \sqrt{\frac{2\log(d\log(n))}{n}}$ with probability $1-o(n)$. Is there a way to condition on the event $\{\|n^{-1}X'X - I\|_{\rm op} \leq c_1\sqrt{\frac{d}{n}}\}$ and analyze $\|n^{-1}X'\mathbf{1}\|_{\infty}$ on it? That is, how does distribution of $\|n^{-1}X'\mathbf{1}\|_{\infty}$ change once we condition on $\{\|n^{-1}X'X - I\|_{\rm op} \leq c_1\sqrt{\frac{d}{n}}\}$? Question 2 : Let $X = USV'$ be the SVD decomposition of $X$. Then $(n^{-1}X'X)^{-1}n^{-1}X'\mathbf{1} = VS^{-1}U'\mathbf{1}$. Can I assume without loss of generality that $V = I$, that is, the matrix $V$ is identity, since the distribution of $X$ is rotationally invariant? Question 3 : This is related to previous question. How does the distribution of $X'\mathbf{1}$ change once we condition on $S$.",,"['probability', 'random-matrices']"
77,Compression of equations and coincidence?,Compression of equations and coincidence?,,"I stumbled across an interesting paper last night. Basically, it tries to see if mathematical equations have meaning by determining how well they ""compress"" the results.  For instance, he says the equation $e^\pi-\pi = 19.9990999...$ is compressible (the equation generates more bits of $\pi$ than it takes up itself), and thus it is likely that there is some mathematical reason for this -- it's not just a coincident.  On the other hand, $\frac{314}{100}$ gives an approximation to $\pi$ but does not compress its representation, so there is nothing intriguing about this formula. I can't find much information on the guy that wrote the paper -- it may be someone doing math in his spare time.  But I am interesting if there is something like this in ""professional"" math, where equations are analyzed this sort of way to determine if there is something meaningful about them.  Can anyone shed some light on this?","I stumbled across an interesting paper last night. Basically, it tries to see if mathematical equations have meaning by determining how well they ""compress"" the results.  For instance, he says the equation $e^\pi-\pi = 19.9990999...$ is compressible (the equation generates more bits of $\pi$ than it takes up itself), and thus it is likely that there is some mathematical reason for this -- it's not just a coincident.  On the other hand, $\frac{314}{100}$ gives an approximation to $\pi$ but does not compress its representation, so there is nothing intriguing about this formula. I can't find much information on the guy that wrote the paper -- it may be someone doing math in his spare time.  But I am interesting if there is something like this in ""professional"" math, where equations are analyzed this sort of way to determine if there is something meaningful about them.  Can anyone shed some light on this?",,['probability']
78,How to find the probability of a family having two boys out of three?,How to find the probability of a family having two boys out of three?,,How do I find the probability of a three children family having exactly two boys given that at least one of their children is a boy? Do I use the dependent formula $$P(A \text{ and } B) = P(A) \times P(B \text{ given that }A \text{ has occurred})$$ or do I use the conditional probability form of $P(B|A)$?,How do I find the probability of a three children family having exactly two boys given that at least one of their children is a boy? Do I use the dependent formula $$P(A \text{ and } B) = P(A) \times P(B \text{ given that }A \text{ has occurred})$$ or do I use the conditional probability form of $P(B|A)$?,,['probability']
79,"Notationally, what is the difference between $\Pr(X = x)$ and $P(X = x)$? When should I use each?","Notationally, what is the difference between  and ? When should I use each?",\Pr(X = x) P(X = x),"I'm talking specifically about probability theory. I was reading some stuff about probabilistic graphical models, and they kept switching the notation in this book, but I couldn't discern the difference by context. One possible hypothesis is that they are subtly different, e.g., $P$ is a probability measure, while $\Pr$ is an unnormalized probability measure (or something; I really have no idea).","I'm talking specifically about probability theory. I was reading some stuff about probabilistic graphical models, and they kept switching the notation in this book, but I couldn't discern the difference by context. One possible hypothesis is that they are subtly different, e.g., $P$ is a probability measure, while $\Pr$ is an unnormalized probability measure (or something; I really have no idea).",,"['probability', 'probability-theory', 'notation']"
80,optional sampling theorem,optional sampling theorem,,"I deal a standard deck of 52 cards to you face up, one card at a time. Before any deal of any card you can shout out ""NOW"". If you shout out ""NOW"" and the next card I deal is a queen, then the game finishes and I give you $100. If the next card isn't a queen, then the game finishes and I give you nothing. What is a fair price for you to pay me in order to play this game with me? What I think of is to use the optional sampling theorem and show it is a martingale. But I am a bit lost on the setup.","I deal a standard deck of 52 cards to you face up, one card at a time. Before any deal of any card you can shout out ""NOW"". If you shout out ""NOW"" and the next card I deal is a queen, then the game finishes and I give you $100. If the next card isn't a queen, then the game finishes and I give you nothing. What is a fair price for you to pay me in order to play this game with me? What I think of is to use the optional sampling theorem and show it is a martingale. But I am a bit lost on the setup.",,"['probability', 'stochastic-processes']"
81,Joint distribution of two functions of two random variables,Joint distribution of two functions of two random variables,,"1) Suppose I have two random variables $A > 0$ and $B > 0$ with joint p.d.f. $f_{A,B}(a,b)$, and two random variables $X = g_1(A,B)$ and $Y = g_2(A,B)$. What is the general procedure for determining the joint p.d.f. $f_{X,Y}(x,y)$ ? 2) More specifically, suppose that: $A$ and $B$ are i.i.d. with $A \sim \Gamma (k, m)$. $X = AB$ $Y = A + B$ Clearly it this case $X$ takes a K distribution and $Y$ takes a Gamma distribution.  Due to struggling with 1) above, I've unfortunately been unable to determine whether in this case a closed non-integral expression for the joint p.d.f. $f_{X,Y}(x,y|k,m)$ even exists, let alone what it is... Any assistance / suggestions would be greatly appreciated.","1) Suppose I have two random variables $A > 0$ and $B > 0$ with joint p.d.f. $f_{A,B}(a,b)$, and two random variables $X = g_1(A,B)$ and $Y = g_2(A,B)$. What is the general procedure for determining the joint p.d.f. $f_{X,Y}(x,y)$ ? 2) More specifically, suppose that: $A$ and $B$ are i.i.d. with $A \sim \Gamma (k, m)$. $X = AB$ $Y = A + B$ Clearly it this case $X$ takes a K distribution and $Y$ takes a Gamma distribution.  Due to struggling with 1) above, I've unfortunately been unable to determine whether in this case a closed non-integral expression for the joint p.d.f. $f_{X,Y}(x,y|k,m)$ even exists, let alone what it is... Any assistance / suggestions would be greatly appreciated.",,"['probability', 'reference-request', 'probability-distributions']"
82,Find the expected value of a dice sum,Find the expected value of a dice sum,,"If fair dodecahedron is rolled until at least $k$($k$ is fixed between 2 and 12) is gotten, and $X$ is the sum of all numbers appeared until the last time, what is $E(X)$?","If fair dodecahedron is rolled until at least $k$($k$ is fixed between 2 and 12) is gotten, and $X$ is the sum of all numbers appeared until the last time, what is $E(X)$?",,"['probability', 'dice']"
83,Moment generating function of two independent variables,Moment generating function of two independent variables,,"The moment generating functions of two independent variables $X$ and   $Y$ are $M_X(t)=\exp(2e^t-2)$ and   $M_Y(t)=\left(\frac34e^t+\frac14\right)^{10}$. What are (a) $P(X+Y=2)$; (b)   $P(XY=0)$; (c) $E[XY]$? For (a), I did it in two ways that yield different answers. First method : $M_{X+Y}(t)=\exp(2e^t-2)\left(\frac34e^t+\frac14\right)^{10}$, so $$P(X+Y=2)=\frac{d^2}{d(e^t)^2}M_{X+Y}(t)\big|_{e^t=0}=\frac{467}{524288e^2}.$$ Second method : $X$ is Poisson with parameter $2$ and $Y$ is Binomial with parameters $(10,\frac34)$. So $$P(X+Y=2)=\sum_{i=0}^2e^{-2}\frac{2^i}{i!}{10\choose 2-i}\left(\frac34\right)^{2-i}\left(\frac14\right)^{8+i}=\frac{467}{1048576e^2}.$$ Where did I go wrong? For (b) and (c), can you check my solutions? (b) $P(XY=0)=P(X=0)+P(Y=0)-P(X=0,Y=0)=e^{-2}+\frac1{4^{10}}-\frac{e^{-2}}{4^{10}}$ (c) $E[XY]=E[X]E[Y]=2\left(10\cdot\frac34\right)=15$ Thanks in advance.","The moment generating functions of two independent variables $X$ and   $Y$ are $M_X(t)=\exp(2e^t-2)$ and   $M_Y(t)=\left(\frac34e^t+\frac14\right)^{10}$. What are (a) $P(X+Y=2)$; (b)   $P(XY=0)$; (c) $E[XY]$? For (a), I did it in two ways that yield different answers. First method : $M_{X+Y}(t)=\exp(2e^t-2)\left(\frac34e^t+\frac14\right)^{10}$, so $$P(X+Y=2)=\frac{d^2}{d(e^t)^2}M_{X+Y}(t)\big|_{e^t=0}=\frac{467}{524288e^2}.$$ Second method : $X$ is Poisson with parameter $2$ and $Y$ is Binomial with parameters $(10,\frac34)$. So $$P(X+Y=2)=\sum_{i=0}^2e^{-2}\frac{2^i}{i!}{10\choose 2-i}\left(\frac34\right)^{2-i}\left(\frac14\right)^{8+i}=\frac{467}{1048576e^2}.$$ Where did I go wrong? For (b) and (c), can you check my solutions? (b) $P(XY=0)=P(X=0)+P(Y=0)-P(X=0,Y=0)=e^{-2}+\frac1{4^{10}}-\frac{e^{-2}}{4^{10}}$ (c) $E[XY]=E[X]E[Y]=2\left(10\cdot\frac34\right)=15$ Thanks in advance.",,['probability']
84,Conditional probability and independent events.,Conditional probability and independent events.,,"In a test, an examinee either guesses or copies or knows the answer to a multiple-choice question with four choices, only one answer being correct. The probability that he makes a guess is $\frac{1}{3}$ and the probability that he copies the answer is $\frac{1}{6}$. The probability that his answer is correct, given that he copies it, is $\frac{1}{8}$ What is the probability that he knew the answer to the question, given that he correctly answers it? From the text I identified $3$ events regard to the same experience.So the sum of the $3$ probabilities must be $1$.It's known that: $P(A)=\frac{1}{3}$ $P(B)=\frac{1}{6}$ So, $P(C)+\frac{1}{3}+\frac{1}{6}=1$ $P(C)=\frac{1}{2}$, this is the probability of knowing the answer. It's also known that $P(D|B)=\frac{1}{8}$. $P(D)$ is the probability of the question is correctly answered. The problem ask about $P(C|D)$. From the knowledge that $P(D|B)=\frac{1}{8}$, $P(B)=\frac{1}{6}$ and by the definition of conditional probability, it's known that $P(D \cap B)=\frac{1}{8} \cdot \frac{1}{6}$. This proves that $B$ and $D$ are indepentend events. And if the $P(B)$ it's known, the $P(D)$ must be $\frac{1}{8}$. Now, using the conditional probability definition, one can find $P(C|D)$.But if $D$ and $B$ were independent, and $C$ and $B$ are events of the same experience, than $C$ and $D$ must also be independents. So $P(C|D)=P(C)=\frac{1}{2}$ Is my thought right?","In a test, an examinee either guesses or copies or knows the answer to a multiple-choice question with four choices, only one answer being correct. The probability that he makes a guess is $\frac{1}{3}$ and the probability that he copies the answer is $\frac{1}{6}$. The probability that his answer is correct, given that he copies it, is $\frac{1}{8}$ What is the probability that he knew the answer to the question, given that he correctly answers it? From the text I identified $3$ events regard to the same experience.So the sum of the $3$ probabilities must be $1$.It's known that: $P(A)=\frac{1}{3}$ $P(B)=\frac{1}{6}$ So, $P(C)+\frac{1}{3}+\frac{1}{6}=1$ $P(C)=\frac{1}{2}$, this is the probability of knowing the answer. It's also known that $P(D|B)=\frac{1}{8}$. $P(D)$ is the probability of the question is correctly answered. The problem ask about $P(C|D)$. From the knowledge that $P(D|B)=\frac{1}{8}$, $P(B)=\frac{1}{6}$ and by the definition of conditional probability, it's known that $P(D \cap B)=\frac{1}{8} \cdot \frac{1}{6}$. This proves that $B$ and $D$ are indepentend events. And if the $P(B)$ it's known, the $P(D)$ must be $\frac{1}{8}$. Now, using the conditional probability definition, one can find $P(C|D)$.But if $D$ and $B$ were independent, and $C$ and $B$ are events of the same experience, than $C$ and $D$ must also be independents. So $P(C|D)=P(C)=\frac{1}{2}$ Is my thought right?",,[]
85,What is wrong with this solution to a combinatorial problem?,What is wrong with this solution to a combinatorial problem?,,"In a pool game, there are 15 numbered balls, of which one is black and the other 14 consist of 7 colored pairs. For instance, balls 1 and 9 could be yellow, 2 and 10 blue, and so on. At the beginning of a game, the balls are arranged in an equilateral triangle. Assuming the arrangement is performed at random and uniformly, what is the probability that two of the balls placed in the triangle vertices will have the same color? The answer to the problem is 1/5, and the calculation is quite simple. However, my first (dull) attempt to solve it was to condition the arrangements on the position of the black ball, like the following: Consider events S = {arrangements with two vertices with the same color} and B = {arrangements with the black ball in one of the corners}. We have: $$ P(B) = 3/15 \\ P(S|B) = \frac{3 \times 7 \times 2 \times 12!}{15!} = \frac{1}{65} $$ Explained: Ways to pick position of the black ball = 3, to pick a color = 7, to pick an ordering among the two balls with the same color = 2, to pick the other 12 balls = 12! For the event that the black ball is not in one of the corners, we have: $$ P(B^c) = 12/15 \\ P(S|B^c) = \frac{3 \times 7 \times 2 \times 12 \times 12!}{15!} = \frac{12}{65} $$ Which is similar to the calculation of P(S|B), except that we have 12 possibilities to pick a third vertex (cannot be black). By applying the formula of conditional probabilities, we should get: $$ P(S \cap B) = P(S|B) \times P(B) = \frac{3}{975} \\ P(S \cap B^c) = P(S|B^c) \times P(B^c) = \frac{144}{975} \\ P(S) = P(S \cap B) + P(S \cap B^c) = \frac{147}{975} = \frac{49}{325} $$ Which is clearly not 1/5. Why didn't this reasoning provide the correct answer? Thank you","In a pool game, there are 15 numbered balls, of which one is black and the other 14 consist of 7 colored pairs. For instance, balls 1 and 9 could be yellow, 2 and 10 blue, and so on. At the beginning of a game, the balls are arranged in an equilateral triangle. Assuming the arrangement is performed at random and uniformly, what is the probability that two of the balls placed in the triangle vertices will have the same color? The answer to the problem is 1/5, and the calculation is quite simple. However, my first (dull) attempt to solve it was to condition the arrangements on the position of the black ball, like the following: Consider events S = {arrangements with two vertices with the same color} and B = {arrangements with the black ball in one of the corners}. We have: $$ P(B) = 3/15 \\ P(S|B) = \frac{3 \times 7 \times 2 \times 12!}{15!} = \frac{1}{65} $$ Explained: Ways to pick position of the black ball = 3, to pick a color = 7, to pick an ordering among the two balls with the same color = 2, to pick the other 12 balls = 12! For the event that the black ball is not in one of the corners, we have: $$ P(B^c) = 12/15 \\ P(S|B^c) = \frac{3 \times 7 \times 2 \times 12 \times 12!}{15!} = \frac{12}{65} $$ Which is similar to the calculation of P(S|B), except that we have 12 possibilities to pick a third vertex (cannot be black). By applying the formula of conditional probabilities, we should get: $$ P(S \cap B) = P(S|B) \times P(B) = \frac{3}{975} \\ P(S \cap B^c) = P(S|B^c) \times P(B^c) = \frac{144}{975} \\ P(S) = P(S \cap B) + P(S \cap B^c) = \frac{147}{975} = \frac{49}{325} $$ Which is clearly not 1/5. Why didn't this reasoning provide the correct answer? Thank you",,"['probability', 'combinatorics']"
86,What is the difference between $\mathrm{E}[Y|X = x]$ and $\mathrm{E}[Y|X]$ and between $\mathrm{Var}(Y|X = x)$ and $\mathrm{Var}(Y|X)$?,What is the difference between  and  and between  and ?,\mathrm{E}[Y|X = x] \mathrm{E}[Y|X] \mathrm{Var}(Y|X = x) \mathrm{Var}(Y|X),"I am slightly confused about the different between $\mathrm{E}[Y|X = x]$ and $\mathrm{E}[Y|X]$ and similarly for Variance. It seems to me the first should be a scalar, because we first pick a specific $X = x$ and then get the expected value of $Y$ within that set whereas the second one is a random variable that depends on the random variable $X$. Is that correct? Any definition using the probabilities $\mathrm{P}(X)$, $\mathrm{P}(Y)$, $\mathrm{P}(Y|X)$ and $\mathrm{P}(Y, X)$ is appreciated.","I am slightly confused about the different between $\mathrm{E}[Y|X = x]$ and $\mathrm{E}[Y|X]$ and similarly for Variance. It seems to me the first should be a scalar, because we first pick a specific $X = x$ and then get the expected value of $Y$ within that set whereas the second one is a random variable that depends on the random variable $X$. Is that correct? Any definition using the probabilities $\mathrm{P}(X)$, $\mathrm{P}(Y)$, $\mathrm{P}(Y|X)$ and $\mathrm{P}(Y, X)$ is appreciated.",,"['probability', 'statistics', 'definition']"
87,"Conditions for an ""Algebra"" of probabilities","Conditions for an ""Algebra"" of probabilities",,"Suppose I have events $A,B,C,D,\ldots$ and that my probability space is discrete and finite (As nice as possible). Now, suppose I give you the values of say $P(A,B)$ , $P(A|B,C)$, $P(D, B|A)$ etc etc. When can I determine whether or not I have enough information to calculate a quantity like $P(C, D | A, B)$. In other words, I give you a bunch of single, joint and conditional probabilities. Which functions of the form $f(x1,x2,\ldots, x1',x2',\ldots):= P(x1, x2, \ldots | x1', x2',\ldots)$ are calculable? Notice that by basic conditioning rules I can reduce most statements to sums and ratios of probabilities of unions or intersections. I don't expect there to be a ""closed form"" answer to any of this but, is there at least some general overview?","Suppose I have events $A,B,C,D,\ldots$ and that my probability space is discrete and finite (As nice as possible). Now, suppose I give you the values of say $P(A,B)$ , $P(A|B,C)$, $P(D, B|A)$ etc etc. When can I determine whether or not I have enough information to calculate a quantity like $P(C, D | A, B)$. In other words, I give you a bunch of single, joint and conditional probabilities. Which functions of the form $f(x1,x2,\ldots, x1',x2',\ldots):= P(x1, x2, \ldots | x1', x2',\ldots)$ are calculable? Notice that by basic conditioning rules I can reduce most statements to sums and ratios of probabilities of unions or intersections. I don't expect there to be a ""closed form"" answer to any of this but, is there at least some general overview?",,"['probability', 'statistics', 'probability-theory']"
88,Probability and combinatorics on tetahedron faces.,Probability and combinatorics on tetahedron faces.,,"Let it be a tetrahedron with the numbers $1$,$2$,$3$ and $4$ on its faces.The tetrahedron is launch $3$ times. Each time, the number that stays face down is registered. $1$)In total how many possible ways there are to registered the $3$ launches? As there are $4$ numbers to $3$ launches(positions), the order matters and each number can repeats itself. I used a permutation with replacement: $4^3=64$ $2$)How many possible ways there are to the number $1$ never face down? In this case I reduced the sample set to $\{2,3,4 \}$, and made the same as before. But this time there are $3$ numbers to $3$ launchs: $3^3=27$ $3$)How many possible ways there are to the number $1$ appears only $1$ time face down? There are $3$ ways for number $1$ can be put on the $3$ launches. For the $2$ left there is $\{2,3,4 \}$.So I made a permutation with replacement: $3 \cdot 3^2=27$ $4$)How many possible ways there are to the number $1$ appears exactly $2$ times face down? First I made a combination: $C(3,2)$ to find the number of ways that the pair of $1$'s can be put in the $3$ launchs.Then I multiplied by $3$, that is $ \{2,3,4 \}$ : $C(3,2) \cdot 3=9$. Is this correct? Thank you very much, you(plural)have been very helpful.","Let it be a tetrahedron with the numbers $1$,$2$,$3$ and $4$ on its faces.The tetrahedron is launch $3$ times. Each time, the number that stays face down is registered. $1$)In total how many possible ways there are to registered the $3$ launches? As there are $4$ numbers to $3$ launches(positions), the order matters and each number can repeats itself. I used a permutation with replacement: $4^3=64$ $2$)How many possible ways there are to the number $1$ never face down? In this case I reduced the sample set to $\{2,3,4 \}$, and made the same as before. But this time there are $3$ numbers to $3$ launchs: $3^3=27$ $3$)How many possible ways there are to the number $1$ appears only $1$ time face down? There are $3$ ways for number $1$ can be put on the $3$ launches. For the $2$ left there is $\{2,3,4 \}$.So I made a permutation with replacement: $3 \cdot 3^2=27$ $4$)How many possible ways there are to the number $1$ appears exactly $2$ times face down? First I made a combination: $C(3,2)$ to find the number of ways that the pair of $1$'s can be put in the $3$ launchs.Then I multiplied by $3$, that is $ \{2,3,4 \}$ : $C(3,2) \cdot 3=9$. Is this correct? Thank you very much, you(plural)have been very helpful.",,"['probability', 'combinatorics']"
89,Inequality of probabilities,Inequality of probabilities,,"If $X$ and $Y$ are (not necessarily independent) random variables taking values in $\Omega=\{1,\ldots,n\}$. then: $\sum_{i=1}^nP(X=i,Y=i)\leq1-\frac12\sum_{i=1}^n\mid P(X=i)-P(Y=i)\mid$ I am only 99.9% sure this inequality is true. I hope someone can prove it. Thanks in advance!","If $X$ and $Y$ are (not necessarily independent) random variables taking values in $\Omega=\{1,\ldots,n\}$. then: $\sum_{i=1}^nP(X=i,Y=i)\leq1-\frac12\sum_{i=1}^n\mid P(X=i)-P(Y=i)\mid$ I am only 99.9% sure this inequality is true. I hope someone can prove it. Thanks in advance!",,"['probability', 'probability-theory', 'probability-distributions']"
90,Where am I doing it wrong? Trying to develop intuition for probability,Where am I doing it wrong? Trying to develop intuition for probability,,"I have two problems which I know how to solve now, but I am still not quite sure why my initial solutions are incorrect. I would really appreciate a thorough explanation of where I went wrong. Thank you. Problem #1: In a pond there are 105 fish, 40 trout, 65 carp. A fisherman catches 8 fish, what is the probability of exactly two of them being trout if at least three of them are not (so they are carp)? I approached this by reducing the sample to 102 (assuming 3 carps), and counting $$\frac{\binom{40}{2} \binom{62}{3}}{\binom{102}{5}}.$$ I thought since 3 carps are already there, we are looking for P that two of the other 5 are trout, and the other 3 are carps. But this was wrong, and the correct answer was $$\frac{\frac{\binom{40}{2} \binom{65}{6}}{\binom{105}{8}}}{\frac{\sum_{x=3}^{8} \binom{40}{8-x} \binom{65}{x}}{\binom{105}{8}}}.$$ This also makes sense, but I don't understand why my original solution was wrong (it over-counted). Problem #2: A box contains 18 tennis balls, 8 new 10 old. 3 balls are picked randomly and played with (so if any of them were new, they become 'old'), and returned to the box. If we pick 3 balls for the second time (after this condition), what is P that they are all new? I broke this down into 4 pieces: P(3 new second round|3 new first round)P(3 new first round) + P(3 new second round|2 new 1 old first round)P(2 new 1 old first round) + P(3 new second round|1 new 2 old first round)P(1 new 2 old first round) + P(3 new second round|3 old first round)(3 old first round). However, I was supposed to used binomials to count this. Instead I had a feeling that I should just multiply probabilities this way: $$\begin{align*} \frac{5\times4\times3}{18\times17\times16} &\times \frac{8\times7\times 6}{18\times 17\times 16} + \frac{6\times5\times 4}{18\times17\times16} \times \frac{8\times7\times10}{18\times17\times16}\\ &\quad + \frac{7\times6\times5}{18\times17\times16} \times \frac{8\times10\times9}{18\times17\times16} + \frac{8\times7\times6}{18\times17\times16} \times \frac{10\times9\times8}{18\times17\times16}. \end{align*}$$ I get the correct answer with binomials, but this equation that I constructed undercounts the possibilities. Could you tell me what I am missing? ty!","I have two problems which I know how to solve now, but I am still not quite sure why my initial solutions are incorrect. I would really appreciate a thorough explanation of where I went wrong. Thank you. Problem #1: In a pond there are 105 fish, 40 trout, 65 carp. A fisherman catches 8 fish, what is the probability of exactly two of them being trout if at least three of them are not (so they are carp)? I approached this by reducing the sample to 102 (assuming 3 carps), and counting $$\frac{\binom{40}{2} \binom{62}{3}}{\binom{102}{5}}.$$ I thought since 3 carps are already there, we are looking for P that two of the other 5 are trout, and the other 3 are carps. But this was wrong, and the correct answer was $$\frac{\frac{\binom{40}{2} \binom{65}{6}}{\binom{105}{8}}}{\frac{\sum_{x=3}^{8} \binom{40}{8-x} \binom{65}{x}}{\binom{105}{8}}}.$$ This also makes sense, but I don't understand why my original solution was wrong (it over-counted). Problem #2: A box contains 18 tennis balls, 8 new 10 old. 3 balls are picked randomly and played with (so if any of them were new, they become 'old'), and returned to the box. If we pick 3 balls for the second time (after this condition), what is P that they are all new? I broke this down into 4 pieces: P(3 new second round|3 new first round)P(3 new first round) + P(3 new second round|2 new 1 old first round)P(2 new 1 old first round) + P(3 new second round|1 new 2 old first round)P(1 new 2 old first round) + P(3 new second round|3 old first round)(3 old first round). However, I was supposed to used binomials to count this. Instead I had a feeling that I should just multiply probabilities this way: $$\begin{align*} \frac{5\times4\times3}{18\times17\times16} &\times \frac{8\times7\times 6}{18\times 17\times 16} + \frac{6\times5\times 4}{18\times17\times16} \times \frac{8\times7\times10}{18\times17\times16}\\ &\quad + \frac{7\times6\times5}{18\times17\times16} \times \frac{8\times10\times9}{18\times17\times16} + \frac{8\times7\times6}{18\times17\times16} \times \frac{10\times9\times8}{18\times17\times16}. \end{align*}$$ I get the correct answer with binomials, but this equation that I constructed undercounts the possibilities. Could you tell me what I am missing? ty!",,['probability']
91,Bayesian analysis of the Venice Doge elections,Bayesian analysis of the Venice Doge elections,,"Does anyone know of a Bayesian (or a classical) analysis of the Venetian Doge election system?  I am looking mainly for chances of subversion, chances for a candidate to be elected at each stage, or ideally a Bayesian game theory model of the elections. Electing the Doge of Venice: analysis of a 13th Century protocol and 64% Majority Rule in Ducal Venice: Voting for the Doge have information about the way the elections were handled.","Does anyone know of a Bayesian (or a classical) analysis of the Venetian Doge election system?  I am looking mainly for chances of subversion, chances for a candidate to be elected at each stage, or ideally a Bayesian game theory model of the elections. Electing the Doge of Venice: analysis of a 13th Century protocol and 64% Majority Rule in Ducal Venice: Voting for the Doge have information about the way the elections were handled.",,"['probability', 'statistics', 'probability-theory', 'social-choice-theory']"
92,Probability of Drawing a Card from a Deck,Probability of Drawing a Card from a Deck,,"I like to play Magic: The Gathering, and I'm interested in calculating the probability of certain things in the game. After drawing 7 cards from a 60 card deck, what is the probability that draw will contain at least one of x, where x is a card having y copies? My best effort has been with the following formula: $$ \binom{y}{1}\binom{60 - y}{6}/\binom{60}{7} $$ There are deck analyzers that will generate the answer for a simple 7-card draw (I'm wanting to get the formula though). Our answers are the same for y=1, but they start to deviate for y=2, y=3, etc. which has put some doubt in this formula. What's the proper way to solve this?","I like to play Magic: The Gathering, and I'm interested in calculating the probability of certain things in the game. After drawing 7 cards from a 60 card deck, what is the probability that draw will contain at least one of x, where x is a card having y copies? My best effort has been with the following formula: $$ \binom{y}{1}\binom{60 - y}{6}/\binom{60}{7} $$ There are deck analyzers that will generate the answer for a simple 7-card draw (I'm wanting to get the formula though). Our answers are the same for y=1, but they start to deviate for y=2, y=3, etc. which has put some doubt in this formula. What's the proper way to solve this?",,['probability']
93,considering the minimum in random walk,considering the minimum in random walk,,"Grimmett and Stirzaker's ""Probability and Random Processes"" gives a nice discussion about random walk, for example, it considers $M_n=\max\{S_i,0\le i \le n\}$ where as usual $$S_i=\sum_{k=1}^i{X_k},$$ here $S_0=0$, $\mathbb{P}(X_k=1)=p$ and $\mathbb{P}(X_k=-1)=q=1-p$. One of the results about $M_n$ is $\mathbb{P}(M_n\ge r, S_n=b)$ or even $\mathbb{P}(M_n\ge r)$. I am just wondering how to relate to the minimum $m_n=\min\{S_i,0\le i \le n\}$ given this result? Is there any simple way to do this? I just found sometimes considering the minimum is most convenient for some problems.","Grimmett and Stirzaker's ""Probability and Random Processes"" gives a nice discussion about random walk, for example, it considers $M_n=\max\{S_i,0\le i \le n\}$ where as usual $$S_i=\sum_{k=1}^i{X_k},$$ here $S_0=0$, $\mathbb{P}(X_k=1)=p$ and $\mathbb{P}(X_k=-1)=q=1-p$. One of the results about $M_n$ is $\mathbb{P}(M_n\ge r, S_n=b)$ or even $\mathbb{P}(M_n\ge r)$. I am just wondering how to relate to the minimum $m_n=\min\{S_i,0\le i \le n\}$ given this result? Is there any simple way to do this? I just found sometimes considering the minimum is most convenient for some problems.",,"['probability', 'random-walk']"
94,Probability Density Functions and Metropolis Hastings,Probability Density Functions and Metropolis Hastings,,"I have a quick question regarding implementation of Metropolis-Hastings for a particular problem I'm dealing with. Suppose that I have a probability density function $P(X)$ for a continuous random variable $X$.  In Metropolis-Hastings, I am required to compute acceptance probability $\frac{ Pr(x') Q(x_{t}|x') } {Pr(x_{t} Q(x' | x)}$.  However, the probability of any single event in a continuous space is zero.  Do  I just replace $Pr$ with $P$ and go on my merry way? My primary concern is that the $P(x)$ is not necessarily less than or equal to 1.","I have a quick question regarding implementation of Metropolis-Hastings for a particular problem I'm dealing with. Suppose that I have a probability density function $P(X)$ for a continuous random variable $X$.  In Metropolis-Hastings, I am required to compute acceptance probability $\frac{ Pr(x') Q(x_{t}|x') } {Pr(x_{t} Q(x' | x)}$.  However, the probability of any single event in a continuous space is zero.  Do  I just replace $Pr$ with $P$ and go on my merry way? My primary concern is that the $P(x)$ is not necessarily less than or equal to 1.",,['probability']
95,"Random Walk - If $m$ is odd, probability of no equalization in the last $m$ steps in path of length $2m$ is 1/2","Random Walk - If  is odd, probability of no equalization in the last  steps in path of length  is 1/2",m m 2m,"I am trying to solve the problems in the Chapter 12 Random Walks of Introduction to Probability by Grinstead and Snell. I am stuck at Problem 6(b) which I quote below ( page 482 ) Problem 6 (a) Show that the probability that a random walk of length $2m$ has a last return to the origin at time $2k$, where $0 \le k \le m$, equals $ \frac{{2k \choose k} {2m-2k \choose m-k}}{2^{2m}} = u_{2k} u_{2m-2k} $. (The case $k = 0$ consists of all paths that do not return to the origin at any positive time.) Hint: A path whose last return to the origin occurs at time $2k$ consists of two paths glued together, one path of which is of length $2k$ and which begins and ends at the origin, and the other path of which is of length $2m - 2k$ and which begins at the origin but never returns to the origin. Both types of paths can be counted using quantities which appear in this section. Solution I could solve this part. The proof follows from the hint. We know the probability of  equalization at $2k$ is $u_{2k} = {2k \choose k}$. The probability of no equalization in $2k$ steps is = $1 - \sum_{m=1}^{k} f_{2m}$ where $f_{2m}$ is the probability of first equalization happening at $2m$. From Problem 2(a), we know $f_{2m} = u_{2m-2} - u_{2m}$. Using this result we get, $1 - \sum_{m=1}^{k} f_{2m} =  1 - [(u_{0}-u_{2}) + (u_{2}-u_{4}) + \ldots + (u_{2k-2} - u_{2k})]$ which on telescoping leads to $1 - u_{0} + u_{2k}  = u_{2k}$ since $u_{0} = 1$ by definition. Thus the probability of no equalization in $2k$ steps is $u_{2k}$ which is same as the probability of equalization in $2k$ steps. Thus in $2m$ steps the probability of equalization in $2k$ and no equalization in the remaining $2m-2k$ steps is $u_{2k} u_{2m-2k}$. Problem 6(b) Using part (a), show that if $m$ is odd, the probability that a walk of length $2m$ has no equalization in the last $m$ outcomes is equal to $1/2$, regardless of the value of $m$. Hint :  The answer to part a) is symmetric in $k$ and $m-k$. I don't understand the hint in this part and I am not sure how to go about solving this problem. I tried the brute force and could not generalize it. This is what I did. I wrote down the sample paths for $2m=6$ and found that at $m=3$ the sum can either be $S_{3} = \{3,1,-1,-3\}$. There are $3$ paths whose sum is either $\{1,-1\}$ and a path each whose sum is either $\{3,-3\}$. The path whose sum is either $\{3,-3\}$ can combine with $7$ paths without equalizing and the paths whose sum is either $\{1,-1\}$ can combine with $3$ paths without equalizing. Thus total number of paths which do not equalize in the latter half ($k = 4,5,6$) of $2m=6$ is = $7 \times 1 + 3 \times 3 + 3 \times 3 + 7 \times 1 = 32$. Thus $32$ out of possible $64$ paths do not equalize the latter half  ($k = 4,5,6$) of the sample path. I tried to generalize this to get an answer of $2^{2m-1}$ but I could not make any headway. I think there must be an easier way based on the hint. Can someone give me more hints on how to solve this problem?","I am trying to solve the problems in the Chapter 12 Random Walks of Introduction to Probability by Grinstead and Snell. I am stuck at Problem 6(b) which I quote below ( page 482 ) Problem 6 (a) Show that the probability that a random walk of length $2m$ has a last return to the origin at time $2k$, where $0 \le k \le m$, equals $ \frac{{2k \choose k} {2m-2k \choose m-k}}{2^{2m}} = u_{2k} u_{2m-2k} $. (The case $k = 0$ consists of all paths that do not return to the origin at any positive time.) Hint: A path whose last return to the origin occurs at time $2k$ consists of two paths glued together, one path of which is of length $2k$ and which begins and ends at the origin, and the other path of which is of length $2m - 2k$ and which begins at the origin but never returns to the origin. Both types of paths can be counted using quantities which appear in this section. Solution I could solve this part. The proof follows from the hint. We know the probability of  equalization at $2k$ is $u_{2k} = {2k \choose k}$. The probability of no equalization in $2k$ steps is = $1 - \sum_{m=1}^{k} f_{2m}$ where $f_{2m}$ is the probability of first equalization happening at $2m$. From Problem 2(a), we know $f_{2m} = u_{2m-2} - u_{2m}$. Using this result we get, $1 - \sum_{m=1}^{k} f_{2m} =  1 - [(u_{0}-u_{2}) + (u_{2}-u_{4}) + \ldots + (u_{2k-2} - u_{2k})]$ which on telescoping leads to $1 - u_{0} + u_{2k}  = u_{2k}$ since $u_{0} = 1$ by definition. Thus the probability of no equalization in $2k$ steps is $u_{2k}$ which is same as the probability of equalization in $2k$ steps. Thus in $2m$ steps the probability of equalization in $2k$ and no equalization in the remaining $2m-2k$ steps is $u_{2k} u_{2m-2k}$. Problem 6(b) Using part (a), show that if $m$ is odd, the probability that a walk of length $2m$ has no equalization in the last $m$ outcomes is equal to $1/2$, regardless of the value of $m$. Hint :  The answer to part a) is symmetric in $k$ and $m-k$. I don't understand the hint in this part and I am not sure how to go about solving this problem. I tried the brute force and could not generalize it. This is what I did. I wrote down the sample paths for $2m=6$ and found that at $m=3$ the sum can either be $S_{3} = \{3,1,-1,-3\}$. There are $3$ paths whose sum is either $\{1,-1\}$ and a path each whose sum is either $\{3,-3\}$. The path whose sum is either $\{3,-3\}$ can combine with $7$ paths without equalizing and the paths whose sum is either $\{1,-1\}$ can combine with $3$ paths without equalizing. Thus total number of paths which do not equalize in the latter half ($k = 4,5,6$) of $2m=6$ is = $7 \times 1 + 3 \times 3 + 3 \times 3 + 7 \times 1 = 32$. Thus $32$ out of possible $64$ paths do not equalize the latter half  ($k = 4,5,6$) of the sample path. I tried to generalize this to get an answer of $2^{2m-1}$ but I could not make any headway. I think there must be an easier way based on the hint. Can someone give me more hints on how to solve this problem?",,"['probability', 'random-walk']"
96,Overtaking Probability,Overtaking Probability,,"On a uni-directional circular road where all vehicles travel in the same direction with varying speeds and overtaking is allowed on the entire road, what is the expected number of times  (a) a particular vehicle will overtake others? (b) a particular vehicle will be overtaken by others? In particular, what I want to find out: Is (a) = (b)? Thanks,","On a uni-directional circular road where all vehicles travel in the same direction with varying speeds and overtaking is allowed on the entire road, what is the expected number of times  (a) a particular vehicle will overtake others? (b) a particular vehicle will be overtaken by others? In particular, what I want to find out: Is (a) = (b)? Thanks,",,[]
97,what is a tight lower bound on the coupon collector time?,what is a tight lower bound on the coupon collector time?,,"In the classic Coupon Collector's problem , it is well known that the time $T$ necessary to complete a set of $n$ randomly-picked coupons satisfies $E[T] \sim n \ln n $,$Var(T) \sim n^2$, and $\Pr(T > n \ln n + cn) < e^{-c}$. This upper bound is better than the one given by the Chebyshev inequality, which would be roughly  $1/c^2$. My question is: is there a corresponding better-than-Chebyshev lower bound for $T$? (e.g., something like $\Pr(T < n \ln n - cn) < e^{-c}$ ) ?","In the classic Coupon Collector's problem , it is well known that the time $T$ necessary to complete a set of $n$ randomly-picked coupons satisfies $E[T] \sim n \ln n $,$Var(T) \sim n^2$, and $\Pr(T > n \ln n + cn) < e^{-c}$. This upper bound is better than the one given by the Chebyshev inequality, which would be roughly  $1/c^2$. My question is: is there a corresponding better-than-Chebyshev lower bound for $T$? (e.g., something like $\Pr(T < n \ln n - cn) < e^{-c}$ ) ?",,"['probability', 'combinatorics']"
98,Poker combinations & probability,Poker combinations & probability,,"I'm trying to figure out how I can work out the number of possible valid hand combinations of a poker game that a player (opponent) could possibly have when the flop has been dealt on the table. So I'm guessing that I have to take the probability that each hand can occur and then see which one is the highest one that could possibly be? Let's say that the opponent has bet $10 and now I have to make my next move.  Is there some math way, (with use of computer) that I can work out the number of valid combinations of hands that this opponent could still have and which he'll most likely pick? If anyone could give some pointers as to what I should look into?","I'm trying to figure out how I can work out the number of possible valid hand combinations of a poker game that a player (opponent) could possibly have when the flop has been dealt on the table. So I'm guessing that I have to take the probability that each hand can occur and then see which one is the highest one that could possibly be? Let's say that the opponent has bet $10 and now I have to make my next move.  Is there some math way, (with use of computer) that I can work out the number of valid combinations of hands that this opponent could still have and which he'll most likely pick? If anyone could give some pointers as to what I should look into?",,"['probability', 'combinatorics', 'poker']"
99,Interpretation of Markov's Inequality,Interpretation of Markov's Inequality,,"Markov's inequality states that $Pr(X \geq tE(X)) \leq 1/t$.  This is great for asking ""What is the probability that we get more than t times our expected value"".  However, if rather than more, we want to ask what is the probability that we get LESS than our expected value, how is this handled? Say our expected value is $n/4$.  If we wanted to ask what the probability is that we'd get less than $n/6$, intuitively I'd say ""It is 1 - the probability that we get   greater than or equal to n/6"" , but that doesn't seem to be working out for me.  How is this accomplished with Markov's inequality?","Markov's inequality states that $Pr(X \geq tE(X)) \leq 1/t$.  This is great for asking ""What is the probability that we get more than t times our expected value"".  However, if rather than more, we want to ask what is the probability that we get LESS than our expected value, how is this handled? Say our expected value is $n/4$.  If we wanted to ask what the probability is that we'd get less than $n/6$, intuitively I'd say ""It is 1 - the probability that we get   greater than or equal to n/6"" , but that doesn't seem to be working out for me.  How is this accomplished with Markov's inequality?",,['probability']
