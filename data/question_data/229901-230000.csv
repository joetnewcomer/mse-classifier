,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Simple algebra of sets ""proof""","Simple algebra of sets ""proof""",,I just wanted to ask about this equality $A\cap B\cap C = (A\cap B)\cap (A\cap C)$ Can this easily be proven by using the associative property of sets which states? $(A\cap B)\cap (A\cap C) = (A\cap A)\cap (B\cap C) = A\cap (B\cap C) = A\cap B\cap C$ Or is this not a valid mathematical proof,I just wanted to ask about this equality $A\cap B\cap C = (A\cap B)\cap (A\cap C)$ Can this easily be proven by using the associative property of sets which states? $(A\cap B)\cap (A\cap C) = (A\cap A)\cap (B\cap C) = A\cap (B\cap C) = A\cap B\cap C$ Or is this not a valid mathematical proof,,"['elementary-set-theory', 'proof-verification']"
1,Definition of the value of a function in Enderton's Elements of Set-Theory,Definition of the value of a function in Enderton's Elements of Set-Theory,,"In chapter 3 of his book Elements of Set Theory, Enderton defines the value of a funtion $F$ at a point $x$ in its domain $\text{dom} \, F$ to be the unique $y$ such that $\langle x,y \rangle \in F$, and denotes it by $F(x)$. Then, he explicitly resolves to use this notation only when $F$ is a function and $x \in \text{dom} \, F$. Now consider the following problem (exercise 12 of the same chapter): Assume that $f$ and $g$ are functions and show that $$ f \subseteq g \iff  \text{dom} \, f \subseteq \text{dom} \, g \ \& \ (\forall x \in \text{dom}\,f) f(x) = g(x)$$ I'm having trouble going from the right to the left-hand side. It is intuitively clear to me that the implication is true. However, when trying to formalize my intuition, I get stuck. In particular, when trying to translate the statement $$(\forall x \in \text{dom}\,f) f(x) = g(x)$$ to a well formed formula (wff) , I don't know how to handle the fact that if $x$ is not in $\text{dom}\,g$, then the expression $g(x)$ is meaningless (according to the notational convention stated above). I am aware that if the other right-hand side condition, $\text{dom} \, f \subseteq \text{dom} \, g$, is true, then $g(x)$ will always be meaningful. However, this doesn't seem to be of any help in obtaining a wff for  the previous expression, which should be meaningful independently of any conjuncts we might attach to it. I attempted a few different interpretations, which I later fully translated to wffs: $\forall x [x \in \text{dom}\,f \implies \forall y \forall z (\langle x,y \rangle \in f \& \langle x,z \rangle \in g \implies y=z)]$ $\forall x [x \in \text{dom}\,f \implies (\text{$f$ and $g$ are functions defined over x} \implies \forall y \forall z (\langle x,y \rangle \in f \& \langle x,z \rangle \in g \implies y=z))]$ $\forall x [x \in \text{dom}\,f \implies (\text{$f$ and $g$ are functions defined over x} \implies \exists y (\langle x,y \rangle \in f \& \langle x,y \rangle \in g))]$ They all seem to be sufficient conditions for $f \subseteq g$, because they guarantee, together with the other premises, the equality of $f(x)$ and $g(x)$ for every $x \in \text{dom} \, f$. However, they are clearly not equivalent. Is there a true or real ambiguity in the statement of the problem or am I missing something?","In chapter 3 of his book Elements of Set Theory, Enderton defines the value of a funtion $F$ at a point $x$ in its domain $\text{dom} \, F$ to be the unique $y$ such that $\langle x,y \rangle \in F$, and denotes it by $F(x)$. Then, he explicitly resolves to use this notation only when $F$ is a function and $x \in \text{dom} \, F$. Now consider the following problem (exercise 12 of the same chapter): Assume that $f$ and $g$ are functions and show that $$ f \subseteq g \iff  \text{dom} \, f \subseteq \text{dom} \, g \ \& \ (\forall x \in \text{dom}\,f) f(x) = g(x)$$ I'm having trouble going from the right to the left-hand side. It is intuitively clear to me that the implication is true. However, when trying to formalize my intuition, I get stuck. In particular, when trying to translate the statement $$(\forall x \in \text{dom}\,f) f(x) = g(x)$$ to a well formed formula (wff) , I don't know how to handle the fact that if $x$ is not in $\text{dom}\,g$, then the expression $g(x)$ is meaningless (according to the notational convention stated above). I am aware that if the other right-hand side condition, $\text{dom} \, f \subseteq \text{dom} \, g$, is true, then $g(x)$ will always be meaningful. However, this doesn't seem to be of any help in obtaining a wff for  the previous expression, which should be meaningful independently of any conjuncts we might attach to it. I attempted a few different interpretations, which I later fully translated to wffs: $\forall x [x \in \text{dom}\,f \implies \forall y \forall z (\langle x,y \rangle \in f \& \langle x,z \rangle \in g \implies y=z)]$ $\forall x [x \in \text{dom}\,f \implies (\text{$f$ and $g$ are functions defined over x} \implies \forall y \forall z (\langle x,y \rangle \in f \& \langle x,z \rangle \in g \implies y=z))]$ $\forall x [x \in \text{dom}\,f \implies (\text{$f$ and $g$ are functions defined over x} \implies \exists y (\langle x,y \rangle \in f \& \langle x,y \rangle \in g))]$ They all seem to be sufficient conditions for $f \subseteq g$, because they guarantee, together with the other premises, the equality of $f(x)$ and $g(x)$ for every $x \in \text{dom} \, f$. However, they are clearly not equivalent. Is there a true or real ambiguity in the statement of the problem or am I missing something?",,"['elementary-set-theory', 'first-order-logic']"
2,system set theory,system set theory,,"I got the following problem Let $A_1...A_n$ be n sets. A sequence $x_1...x_n$ is called representative of $A_1 ... A_n$ if $x_i \in A_i$ and $x_i \neq x_j$ Proof the following: A representative sequence exists if and only if the union of $m \in \{1,2,3...n \}$ sets of different $A_i$ has at least $m$ elements Let P be such a union  and $x_n$ be the representative sequence then $\{ x_{k_1},x_{k_2} ...x_{k_m} \} \subset P$ and hence $|P|\ge m$ However, I dont know how to show the other direction. Would appreciate any help","I got the following problem Let $A_1...A_n$ be n sets. A sequence $x_1...x_n$ is called representative of $A_1 ... A_n$ if $x_i \in A_i$ and $x_i \neq x_j$ Proof the following: A representative sequence exists if and only if the union of $m \in \{1,2,3...n \}$ sets of different $A_i$ has at least $m$ elements Let P be such a union  and $x_n$ be the representative sequence then $\{ x_{k_1},x_{k_2} ...x_{k_m} \} \subset P$ and hence $|P|\ge m$ However, I dont know how to show the other direction. Would appreciate any help",,"['sequences-and-series', 'elementary-set-theory']"
3,Pair of numbers using pigeon hole principle,Pair of numbers using pigeon hole principle,,"n ∈ N, A ⊆ {1, . . . , 2n}, |A| = n + 1. Show that: a) In A there is a pair of numbers whose sum is equal to 2n + 1. b) In A there is a pair of relatively prime numbers. c) In A there is a pair of numbers, such that one is a multiple of the other. For the first part, I started by making pairs of numbers whose sum equals 2n + 1, which is literally the first number and the last one in the set A,  {2n + 1, 2n - 1 + 2, 2n - 2 + 3 ...} I'm not sure how to prove that there exists this pair, when it clearly does. I'm not sure how to go about part b) and c) any hint would be much appreciated.","n ∈ N, A ⊆ {1, . . . , 2n}, |A| = n + 1. Show that: a) In A there is a pair of numbers whose sum is equal to 2n + 1. b) In A there is a pair of relatively prime numbers. c) In A there is a pair of numbers, such that one is a multiple of the other. For the first part, I started by making pairs of numbers whose sum equals 2n + 1, which is literally the first number and the last one in the set A,  {2n + 1, 2n - 1 + 2, 2n - 2 + 3 ...} I'm not sure how to prove that there exists this pair, when it clearly does. I'm not sure how to go about part b) and c) any hint would be much appreciated.",,"['elementary-set-theory', 'pigeonhole-principle']"
4,Showing that the union of transitive relations need not be transitive.,Showing that the union of transitive relations need not be transitive.,,"I have a counterexample of the following statement but I am not sure if it is correct: Suppose $R_1$ and $R_2$ are relations on A. If $R_1$ and $R_2$ are transitive, then $R_1 \cup R_2$ is transitive. Prove or provide a counterexample. To me, this is of the form: If: $$((x,y)\in R_1 \land (y,z) \in R_1 \implies (x,z)\in R_1) \land ((x,y)\in R_2 \land (y,z) \in R_2 \implies (x,z)\in R_2) $$ Then: $$ ((x,y)\in R_1 \lor (x,y) \in R_2) \land ((y,z)\in R_1 \lor (y,z)\in R_2) \implies ((x,z)\in R_1 \lor (x,z)\in R_2)   $$ My counterexample: \begin{align*} A&=\{ 1,2,3\} \\ R_1&= \{(1,2)\} \\ R_2&= \{(2,3)\}  \end{align*} Then if we take $x=1,y=2,z=3$ , it should yield the following: If: $$(\underbrace{(x,y)\in R_1 \land (y,z) \in R_1}_{\text{false}} \implies \underbrace{(x,z)\in R_1}_{\text{false}}) \land (\underbrace{(x,y)\in R_2 \land (y,z) \in R_2}_{\text{false}} \implies \underbrace{(x,z)\in R_2}_{\text{false}}) $$ Then: $$ (\underbrace{(x,y)\in R_1 \lor (x,y) \in R_2)}_{\text{true}} \land (\underbrace{(y,z)\in R_1 \lor (y,z)\in R_2)}_{\text{true}} \implies (\underbrace{(x,z)\in R_1 \lor (x,z)\in R_2}_{\text{false}})   $$ I know it's a mess, but it's the best I can do to illustrate my idea clearly. Could anyone please help? Thank you so much!","I have a counterexample of the following statement but I am not sure if it is correct: Suppose and are relations on A. If and are transitive, then is transitive. Prove or provide a counterexample. To me, this is of the form: If: Then: My counterexample: Then if we take , it should yield the following: If: Then: I know it's a mess, but it's the best I can do to illustrate my idea clearly. Could anyone please help? Thank you so much!","R_1 R_2 R_1 R_2 R_1 \cup R_2 ((x,y)\in R_1 \land (y,z) \in R_1 \implies (x,z)\in R_1) \land ((x,y)\in R_2 \land (y,z) \in R_2 \implies (x,z)\in R_2)   ((x,y)\in R_1 \lor (x,y) \in R_2) \land ((y,z)\in R_1 \lor (y,z)\in R_2) \implies ((x,z)\in R_1 \lor (x,z)\in R_2)    \begin{align*}
A&=\{ 1,2,3\} \\
R_1&= \{(1,2)\} \\
R_2&= \{(2,3)\} 
\end{align*} x=1,y=2,z=3 (\underbrace{(x,y)\in R_1 \land (y,z) \in R_1}_{\text{false}} \implies \underbrace{(x,z)\in R_1}_{\text{false}}) \land (\underbrace{(x,y)\in R_2 \land (y,z) \in R_2}_{\text{false}} \implies \underbrace{(x,z)\in R_2}_{\text{false}})   (\underbrace{(x,y)\in R_1 \lor (x,y) \in R_2)}_{\text{true}} \land (\underbrace{(y,z)\in R_1 \lor (y,z)\in R_2)}_{\text{true}} \implies (\underbrace{(x,z)\in R_1 \lor (x,z)\in R_2}_{\text{false}})   ","['elementary-set-theory', 'solution-verification', 'relations']"
5,"Understanding a proof of ""Every set has a group structure implies Axiom of Choice""","Understanding a proof of ""Every set has a group structure implies Axiom of Choice""",,"I am following this answer by Asaf to a question, whether every set has a group structure. The main part is the following: To prove that ""every set can be made into a group $\Rightarrow$ Axiom of choice"" Given an infinite set $X$ we define $H(X)$ to be the least ordinal $\alpha$ that there is no injection $g:\alpha\to X$ (this is known as the Hartog number of $X$) If $X$ can be injected into $H(X)$ then $X$ can be well ordered, since being injected into an ordinal means that $X$ inherits a well order. Using the assumption that every set can be given a group structure we give a group structure to $X\cup H(X)$, and from this we deduce that there exists an injection from $X$ into $H(X)$. Therefore if every set can be given a group structure, every set can be well ordered and therefore the axiom of choice holds. With this (part o answer), I have a very simple question, which came to me while considering necessaties of the objects used in the arguments. What is the necessity of taking ""$H(X)$, least ordinal etc"" , in the arguments? I mean, can we take simply $\mathcal{P}(X)$, the power set of $X$, instead of these objects ""$H(X)$, least ordinal "" in the arguments, and carry proof?","I am following this answer by Asaf to a question, whether every set has a group structure. The main part is the following: To prove that ""every set can be made into a group $\Rightarrow$ Axiom of choice"" Given an infinite set $X$ we define $H(X)$ to be the least ordinal $\alpha$ that there is no injection $g:\alpha\to X$ (this is known as the Hartog number of $X$) If $X$ can be injected into $H(X)$ then $X$ can be well ordered, since being injected into an ordinal means that $X$ inherits a well order. Using the assumption that every set can be given a group structure we give a group structure to $X\cup H(X)$, and from this we deduce that there exists an injection from $X$ into $H(X)$. Therefore if every set can be given a group structure, every set can be well ordered and therefore the axiom of choice holds. With this (part o answer), I have a very simple question, which came to me while considering necessaties of the objects used in the arguments. What is the necessity of taking ""$H(X)$, least ordinal etc"" , in the arguments? I mean, can we take simply $\mathcal{P}(X)$, the power set of $X$, instead of these objects ""$H(X)$, least ordinal "" in the arguments, and carry proof?",,"['elementary-set-theory', 'proof-explanation']"
6,Prove existence a maximal pairwise disjoint subfamily $\mathcal{S} \subseteq \mathcal{R}$,Prove existence a maximal pairwise disjoint subfamily,\mathcal{S} \subseteq \mathcal{R},"Can anyone help me with this: Suppose $\mathcal{R}$ is any family of sets. Prove that there exists set $\mathcal{S} \subseteq \mathcal{R}$, which is pairwise disjoint and for each $A \in \mathcal{R}-\mathcal{S}$, there exists $B  \in  \mathcal{S}$ with following property: $A  \cap  B \neq \emptyset$. I have no idea where to start. Thanks in advance for help.","Can anyone help me with this: Suppose $\mathcal{R}$ is any family of sets. Prove that there exists set $\mathcal{S} \subseteq \mathcal{R}$, which is pairwise disjoint and for each $A \in \mathcal{R}-\mathcal{S}$, there exists $B  \in  \mathcal{S}$ with following property: $A  \cap  B \neq \emptyset$. I have no idea where to start. Thanks in advance for help.",,['elementary-set-theory']
7,How to denote the comma as an element of a set,How to denote the comma as an element of a set,,"I have a set whose elements include the comma character "","". But the comma is used as a separator when listing the elements of a set. Any suggestions for a sensible notation to use in this case?","I have a set whose elements include the comma character "","". But the comma is used as a separator when listing the elements of a set. Any suggestions for a sensible notation to use in this case?",,"['elementary-set-theory', 'notation']"
8,Prove that 'isomorphism' is an equivalence relation (on any set of sets),Prove that 'isomorphism' is an equivalence relation (on any set of sets),,"Consider identity function $1_A: A \to A.$ The identity function is bijective, so isomorphism is reflexive. Inverse of a bijection is bijection, so isomorphism is symmetric. Composition of two bijections is bijection, so isomorphism is transitive. Then isomorphism on any set of sets is an equivalence relation. Please, see if this argument works.","Consider identity function $1_A: A \to A.$ The identity function is bijective, so isomorphism is reflexive. Inverse of a bijection is bijection, so isomorphism is symmetric. Composition of two bijections is bijection, so isomorphism is transitive. Then isomorphism on any set of sets is an equivalence relation. Please, see if this argument works.",,"['elementary-set-theory', 'proof-verification']"
9,Some questions about the cartesian product,Some questions about the cartesian product,,"I understand that the cartesian product of $A \times B$ is a set with elements of the form $(a,b)$ where $a\in A$, $b\in B$. My question arise from the fact that I was described $\Bbb{R}^3$ as $\Bbb{R} \times \Bbb{R} \times \Bbb{R}$, but elements of $\Bbb{R}^3$ have the form $(x,y,z)$, while elements of $\Bbb{R} \times \Bbb{R} \times \Bbb{R}$ should have the form $((x,y),z)$ where $(x,y)\in \Bbb{R}^2,z\in\Bbb{R}$. If this sets are different, how do we construct $\Bbb{R}^n$ with elements of the form $(x_1,x_2,...,x_n)$?","I understand that the cartesian product of $A \times B$ is a set with elements of the form $(a,b)$ where $a\in A$, $b\in B$. My question arise from the fact that I was described $\Bbb{R}^3$ as $\Bbb{R} \times \Bbb{R} \times \Bbb{R}$, but elements of $\Bbb{R}^3$ have the form $(x,y,z)$, while elements of $\Bbb{R} \times \Bbb{R} \times \Bbb{R}$ should have the form $((x,y),z)$ where $(x,y)\in \Bbb{R}^2,z\in\Bbb{R}$. If this sets are different, how do we construct $\Bbb{R}^n$ with elements of the form $(x_1,x_2,...,x_n)$?",,['elementary-set-theory']
10,Existence of infinite set and axiom schema of replacement imply axiom of infinity,Existence of infinite set and axiom schema of replacement imply axiom of infinity,,"I'm self-teaching an intro to set theory course, and came across this exercise: Show that the existence of an infinite set is equivalent to the existence of an inductive set.  For the notion of finiteness without reference to natural numbers, we use the given Tarski definition of finiteness: A set $x$ is finite if, for every non-empty $a\subseteq \mathcal{P}(x)$, there exists a set $b\in a$ that is $\subseteq$-minimal, that is, there is no $c\in a$ such that $c\subsetneq b$.  A set is called infinite if, of course, it is not finite. Now, the right-to-left implication is clear, as it is merely assuming the axiom of infinity and asking to show that there is an infinite set--likely something the author of these notes overlooked, since (of course) the notes up to that point has already established $\omega$ is an infinite set, so only the left-to-right implication needs proving. Before I begin discussing my issue solving the problem, let me state that I've just looked at a view answered questions about ZFC, minus the axiom of infinity or also with the axiom negated.  I haven't seen this specific question, though I've seen it alluded to.  I saw a suggestion to use the axiom of choice due to the well-ordering theorem, but in the notes I'm using the well-ordering theorem has not been proven yet.  Furthermore, I also shouldn't be able to reference ordinals, as the notes haven't defined ordinals yet (this is the next chapter, actually!).  The sequence has been: all of the ZFC axioms, the definition of $\omega$, proofs of the properties of $\omega$ (transitivity, recursive definition, linear ordering by $\in$, etc.) and then the concept of (Tarski) finite sets.  With regards to finiteness, I know that, if $x$ is a finite set, subsets of $x$ are finite, union with a finite set $y$ is finite, surjective image of $x$ is finite, and the power set of $x$ is finite.  Furthermore, we have proven already that every finite set is the bijective image of a natural number and every infinite set contains an injective image of $\omega$.  This is all, of course, assuming the Axiom of Infinity, but I wanted to make sure my allowed tools were known. Now, in my attempt to search for a solution after being stumped, I found another book on set theory that merely said that, assuming the existence of an infinite set, say, $x$, all we need to do is apply the axiom schema of replacement to the set $\mathcal{F}(x)$ of finite sets of $x$.  The specific class function was left unclear, though judging by the alternate definition this book used for finiteness (they switched to existence of bijection with a natural number as the preferred definition), it appears the function they would refer to would be that which sends a finite set to the natural number it is in bijection with.  However, without the axiom of infinity, there is no $\omega$ we can refer to as of yet, and hence no (clear, at least to me) way to inductively show that the ""bijection-to-a-natural"" definition is equivalent to the Tarski definition, which is what the notes I'm using instruct to use.  However, once I construct the desired class function $F$, I know the replacement schema implies that the image of $\mathcal{F}(x)$ under $F$ is a set, and can prove from there that it is inductive. So without $\omega$, how am I to approach defining such a function?  Or alternatively, how do I use AC to prove the existence of $\omega$?  Any hints on this would be amazing.  I would not be content if I had to leave this exercise undone.  Apologies in advance if this is deemed a duplicate.  Thank you.","I'm self-teaching an intro to set theory course, and came across this exercise: Show that the existence of an infinite set is equivalent to the existence of an inductive set.  For the notion of finiteness without reference to natural numbers, we use the given Tarski definition of finiteness: A set $x$ is finite if, for every non-empty $a\subseteq \mathcal{P}(x)$, there exists a set $b\in a$ that is $\subseteq$-minimal, that is, there is no $c\in a$ such that $c\subsetneq b$.  A set is called infinite if, of course, it is not finite. Now, the right-to-left implication is clear, as it is merely assuming the axiom of infinity and asking to show that there is an infinite set--likely something the author of these notes overlooked, since (of course) the notes up to that point has already established $\omega$ is an infinite set, so only the left-to-right implication needs proving. Before I begin discussing my issue solving the problem, let me state that I've just looked at a view answered questions about ZFC, minus the axiom of infinity or also with the axiom negated.  I haven't seen this specific question, though I've seen it alluded to.  I saw a suggestion to use the axiom of choice due to the well-ordering theorem, but in the notes I'm using the well-ordering theorem has not been proven yet.  Furthermore, I also shouldn't be able to reference ordinals, as the notes haven't defined ordinals yet (this is the next chapter, actually!).  The sequence has been: all of the ZFC axioms, the definition of $\omega$, proofs of the properties of $\omega$ (transitivity, recursive definition, linear ordering by $\in$, etc.) and then the concept of (Tarski) finite sets.  With regards to finiteness, I know that, if $x$ is a finite set, subsets of $x$ are finite, union with a finite set $y$ is finite, surjective image of $x$ is finite, and the power set of $x$ is finite.  Furthermore, we have proven already that every finite set is the bijective image of a natural number and every infinite set contains an injective image of $\omega$.  This is all, of course, assuming the Axiom of Infinity, but I wanted to make sure my allowed tools were known. Now, in my attempt to search for a solution after being stumped, I found another book on set theory that merely said that, assuming the existence of an infinite set, say, $x$, all we need to do is apply the axiom schema of replacement to the set $\mathcal{F}(x)$ of finite sets of $x$.  The specific class function was left unclear, though judging by the alternate definition this book used for finiteness (they switched to existence of bijection with a natural number as the preferred definition), it appears the function they would refer to would be that which sends a finite set to the natural number it is in bijection with.  However, without the axiom of infinity, there is no $\omega$ we can refer to as of yet, and hence no (clear, at least to me) way to inductively show that the ""bijection-to-a-natural"" definition is equivalent to the Tarski definition, which is what the notes I'm using instruct to use.  However, once I construct the desired class function $F$, I know the replacement schema implies that the image of $\mathcal{F}(x)$ under $F$ is a set, and can prove from there that it is inductive. So without $\omega$, how am I to approach defining such a function?  Or alternatively, how do I use AC to prove the existence of $\omega$?  Any hints on this would be amazing.  I would not be content if I had to leave this exercise undone.  Apologies in advance if this is deemed a duplicate.  Thank you.",,"['elementary-set-theory', 'cardinals', 'infinity']"
11,finding a bijective function from the real plane to the real line,finding a bijective function from the real plane to the real line,,"As part of a HW assignment in the course elementary set theory, I was given the following question: Prove explicitly (don't use any theorems or known facts, but find a bijective function) that $\vert\mathbb R\vert=\vert \mathbb R\times \mathbb R\vert$ I've already encountered with the following suggestion: for any $(x,y)\in \mathbb R$ with the decimal expansion $x=n_1+0.a_1 a_2 a_3 \ldots$ for some $n_1\in \mathbb Z$ and $0\leq a_i \leq 9$ and $y=n_2+0.b_1 b_2 b_3 \ldots$ for some $n_2\in \mathbb Z$ and $0\leq b_i \leq 9$. if $x$ or $y$ have two different decimal expansions then take the one that ends with an infinite string of 9's. then define $f : \mathbb R\times \mathbb R\longrightarrow \mathbb R$ by: $f((x,y))=n_1 +n_2 +0.a_1 b_1 a_2 b_2 a_3 b_3 \ldots$ $f$ is injective (I know that it is not accurate because I can choose $n_1$ and $n_2$ as I wish as long as their sum remains the same but the following was the more important part)  but it is not onto $\mathbb R$ because for example: $0.12020202\ldots \in \mathbb R$ but there is no $(x,y)\in \mathbb R\times \mathbb R$ such that $f((x,y))=0.12020202\ldots$ because the only ""candidates"" are $x=0.10000\ldots$ and $y=0.2222\ldots$ but the number $0.10000\ldots $ does not belong to the representation that we agreed upon. I feel that it can be fixed somehow but I can't manage to do it. I would really appreciate if anyone can give me a bijective function that fits. (also how can I fix $f$ to be injective).","As part of a HW assignment in the course elementary set theory, I was given the following question: Prove explicitly (don't use any theorems or known facts, but find a bijective function) that $\vert\mathbb R\vert=\vert \mathbb R\times \mathbb R\vert$ I've already encountered with the following suggestion: for any $(x,y)\in \mathbb R$ with the decimal expansion $x=n_1+0.a_1 a_2 a_3 \ldots$ for some $n_1\in \mathbb Z$ and $0\leq a_i \leq 9$ and $y=n_2+0.b_1 b_2 b_3 \ldots$ for some $n_2\in \mathbb Z$ and $0\leq b_i \leq 9$. if $x$ or $y$ have two different decimal expansions then take the one that ends with an infinite string of 9's. then define $f : \mathbb R\times \mathbb R\longrightarrow \mathbb R$ by: $f((x,y))=n_1 +n_2 +0.a_1 b_1 a_2 b_2 a_3 b_3 \ldots$ $f$ is injective (I know that it is not accurate because I can choose $n_1$ and $n_2$ as I wish as long as their sum remains the same but the following was the more important part)  but it is not onto $\mathbb R$ because for example: $0.12020202\ldots \in \mathbb R$ but there is no $(x,y)\in \mathbb R\times \mathbb R$ such that $f((x,y))=0.12020202\ldots$ because the only ""candidates"" are $x=0.10000\ldots$ and $y=0.2222\ldots$ but the number $0.10000\ldots $ does not belong to the representation that we agreed upon. I feel that it can be fixed somehow but I can't manage to do it. I would really appreciate if anyone can give me a bijective function that fits. (also how can I fix $f$ to be injective).",,"['elementary-set-theory', 'cardinals']"
12,Does a logical matrix representing sets have a name or special properties?,Does a logical matrix representing sets have a name or special properties?,,"Imagine a collection of separate objects and several sets. These sets can be represented using a logical matrix . $M = \begin{bmatrix} 1 & 1 & 1 & 1 & 0 & 0\\ 0 & 0 & 1 & 1 & 0 & 0\\ 0 & 1 & 0 & 0 & 0 & 1\\ 0 & 0 & 0 & 0 & 1 & 0\end{bmatrix}$ Each line corresponds to a set, and each column corresponds to an object. So $M_{i,j} = 1$ if $Set_i$ contains $Object_j$, else $0$. I wondered if this kind of matrix, used to represent sets, had a special name? And if, in addition, there was some interesting properties? For example, to represent a graph, one can use an adjacency matrix, which is a logical matrix too. By raising it to the n-th power, each $x_{i,j}$ obtained indicates the number of existing n-length paths from i to j. I am in search of similar property (which may be about subset or superset for example), or a name to this matrix that would allow me to further my research.","Imagine a collection of separate objects and several sets. These sets can be represented using a logical matrix . $M = \begin{bmatrix} 1 & 1 & 1 & 1 & 0 & 0\\ 0 & 0 & 1 & 1 & 0 & 0\\ 0 & 1 & 0 & 0 & 0 & 1\\ 0 & 0 & 0 & 0 & 1 & 0\end{bmatrix}$ Each line corresponds to a set, and each column corresponds to an object. So $M_{i,j} = 1$ if $Set_i$ contains $Object_j$, else $0$. I wondered if this kind of matrix, used to represent sets, had a special name? And if, in addition, there was some interesting properties? For example, to represent a graph, one can use an adjacency matrix, which is a logical matrix too. By raising it to the n-th power, each $x_{i,j}$ obtained indicates the number of existing n-length paths from i to j. I am in search of similar property (which may be about subset or superset for example), or a name to this matrix that would allow me to further my research.",,"['elementary-set-theory', 'boolean-algebra']"
13,How to prove countably infinite?,How to prove countably infinite?,,"How do I prove the following set is countably infinite?  $\{\frac{1}{n}: n\in\mathbb{Z}\setminus\{0\}\}$ I know that I can say this set is a subset of $\mathbb{Q}$, and that $\mathbb{Q}$ is infinite, thus this set is infinite. However, I've not yet proven that the rational numbers are countable, so I'm unsure how to proceed in proving this set countable.","How do I prove the following set is countably infinite?  $\{\frac{1}{n}: n\in\mathbb{Z}\setminus\{0\}\}$ I know that I can say this set is a subset of $\mathbb{Q}$, and that $\mathbb{Q}$ is infinite, thus this set is infinite. However, I've not yet proven that the rational numbers are countable, so I'm unsure how to proceed in proving this set countable.",,['elementary-set-theory']
14,Prove that ≿ is transitive iff ≻ and ∼ are transitive,Prove that ≿ is transitive iff ≻ and ∼ are transitive,,"Let ≿ be a complete preference relation (as in game theory). How to prove that ≿ is transitive if and only if ≻ and ∼ are both transitive? My reasoning is as follows. a ≿ b probably means (a ≻ b) ∨ (a ∼ b) , by analogy with ≥, which means greater OR equal. Transitivity means (a ≿ b) ∧ (b ≿ c) → (a ≿ c) . Therefore we must prove that following expression is valid: $$[(a \succ b) \wedge (b \succ c) \rightarrow (a \succ c)] \wedge [(a \sim b) \wedge (b \sim c) \rightarrow (a \sim c)] \equiv [((a \succ b) \vee (a \sim b)) \wedge ((b \succ c) \vee (b \sim c)) \rightarrow ((a \succ c) \vee (a \sim c))]$$ For brevity, let's substitute the relations with capital letters: a ≻ b: A a ∼ b: B b ≻ c: C b ∼ c: D a ≻ c: E a ∼ c: F The expression then becomes: $$(A \wedge C \rightarrow E) \wedge (B \wedge D \rightarrow F) \equiv [(A \vee B) \wedge (C \vee D) \rightarrow (E \vee F)]$$ No amount of logical manipulation allows to prove that LHS is equivalent to RHS. What am I doing wrong? Ideally, your answer would consist of a hint that would allow me to solve the problem myself without giving out the answer.","Let ≿ be a complete preference relation (as in game theory). How to prove that ≿ is transitive if and only if ≻ and ∼ are both transitive? My reasoning is as follows. a ≿ b probably means (a ≻ b) ∨ (a ∼ b) , by analogy with ≥, which means greater OR equal. Transitivity means (a ≿ b) ∧ (b ≿ c) → (a ≿ c) . Therefore we must prove that following expression is valid: $$[(a \succ b) \wedge (b \succ c) \rightarrow (a \succ c)] \wedge [(a \sim b) \wedge (b \sim c) \rightarrow (a \sim c)] \equiv [((a \succ b) \vee (a \sim b)) \wedge ((b \succ c) \vee (b \sim c)) \rightarrow ((a \succ c) \vee (a \sim c))]$$ For brevity, let's substitute the relations with capital letters: a ≻ b: A a ∼ b: B b ≻ c: C b ∼ c: D a ≻ c: E a ∼ c: F The expression then becomes: $$(A \wedge C \rightarrow E) \wedge (B \wedge D \rightarrow F) \equiv [(A \vee B) \wedge (C \vee D) \rightarrow (E \vee F)]$$ No amount of logical manipulation allows to prove that LHS is equivalent to RHS. What am I doing wrong? Ideally, your answer would consist of a hint that would allow me to solve the problem myself without giving out the answer.",,"['elementary-set-theory', 'relations', 'propositional-calculus']"
15,Sum and product of Cardinal numbers,Sum and product of Cardinal numbers,,"Define the sum and the product of two cardinal numbers and show that these are well-defined operations. That's what I have tried: Let $A,B$ sets with $A \cap B=\varnothing, card(A)=m, card(B)=n$. We define the sum $m+n$ of the cardinal numbers $m,n$ as the cardinal number of the union of $A$ and $B$, i.e. $$m+n=card(A \cup B)$$ We will show that the sum of two cardinal numbers is well-defined. It suffices to show that if $A_1 \sim B_1, A_2 \sim B_2$ with $A_1 \cap A_2=\varnothing, B_1 \cap B_2=\varnothing$ then $A_1 \cup A_2 \sim B_1 \cup B_2$. We know that there are bijective functions $f: A_1 \to A_2, g:B_1 \to B_2$. We want to show that there is a bijective function $h: A_1 \cup A_2 \to B_1 \cup B_2$. We set $ h(x)=f(x)$ if $x \in A_1, h(x)=g(x)$ if $x \in A_2$. We will show  that $h$ is 1-1. Let $x_1, x_2 \in A_1 \cup A_2$ with $h(x_1)=h(x_2)$. If $x_1, x_2 \in A_1$ then $h(x_1)=f(x_1), h(x_2)=f(x_2)$ and so $f(x_1)=f(x_2) \Rightarrow x_1=x_2$ If $x_1, x_2 \in A_2$ then $h(x_1)=g(x_1), h(x_2)=g(x_2)$ and so $g(x_1)=g(x_2) \Rightarrow x_1=x_2$ since $g$ is injective. If $x_1 \in A_1, x_2 \in A_2$ then $h(x_1)=h(x_2) \Rightarrow f(x_1)=f(x_2)$ that cannot be true because $B_1 \cap B_2=\varnothing$. We will show that $h$ is surjective, i.e. that $\forall y \in B_1 \cup B_2, \exists x \in A_1 \cup B_2$ such that $f(x)=y$. If $y \in B_1$ then we know that there will be a $x \in A_1$ such that $h(x)=y \Rightarrow f(x)=y$ since $f$ is surjective. If $y \in B_2$ then we know that there will be a $x \in A_2$ such that $h(x)=y \Rightarrow g(x)=y$ since $g$ is surjective. We define the product $m \cdot n$ of the cardinal numbers $m,n$ as the cardinal number of the cartesian product of $A$ and $B$, i.e. $$m \cdot n=card(A \times B)$$ We will show that the product of two cardinal numbers is well-defined. It suffices to show that if $A_1 \sim B_1, A_2 \sim B_2$ with $A_1 \cap A_2=\varnothing, B_1 \cap B_2=\varnothing$ then $A_1 \times A_2 \sim B_1 \times B_2$. We know that there are bijective functions $f: A_1 \to A_2, g:B_1 \to B_2$. We want to show that there is a bijective function $h: A_1 \times A_2 \to B_1 \times B_2$. We define $h: A_1 \times A_2 \to B_1 \times B_2$ such that $\langle n,m \rangle \mapsto \langle f(n),g(m) \rangle$ We will show  that $h$ is 1-1. Let $\langle m_1, n_1 \rangle, \langle m_2, n_2 \rangle \in A_1 \times A_2$ with $h(\langle m_1, n_1 \rangle)=h(\langle m_2, n_2 \rangle) \rightarrow \langle f(n_1),g(m_1) \rangle=\langle f(n_2),g(m_2) \rangle \rightarrow f(n_1))=f(n_2) \wedge g(m_1)=g(m_2) \overset{\text{f,g:} 1-1 }{\rightarrow} m_1=m_2 \wedge n_1=n_2 \rightarrow \langle m_1,n_1 \rangle=\langle m_2,n_2 \rangle$ From the surjectivity of $f,g$ we can conclude that $h$ is surjective. Could you tell me if it is right?","Define the sum and the product of two cardinal numbers and show that these are well-defined operations. That's what I have tried: Let $A,B$ sets with $A \cap B=\varnothing, card(A)=m, card(B)=n$. We define the sum $m+n$ of the cardinal numbers $m,n$ as the cardinal number of the union of $A$ and $B$, i.e. $$m+n=card(A \cup B)$$ We will show that the sum of two cardinal numbers is well-defined. It suffices to show that if $A_1 \sim B_1, A_2 \sim B_2$ with $A_1 \cap A_2=\varnothing, B_1 \cap B_2=\varnothing$ then $A_1 \cup A_2 \sim B_1 \cup B_2$. We know that there are bijective functions $f: A_1 \to A_2, g:B_1 \to B_2$. We want to show that there is a bijective function $h: A_1 \cup A_2 \to B_1 \cup B_2$. We set $ h(x)=f(x)$ if $x \in A_1, h(x)=g(x)$ if $x \in A_2$. We will show  that $h$ is 1-1. Let $x_1, x_2 \in A_1 \cup A_2$ with $h(x_1)=h(x_2)$. If $x_1, x_2 \in A_1$ then $h(x_1)=f(x_1), h(x_2)=f(x_2)$ and so $f(x_1)=f(x_2) \Rightarrow x_1=x_2$ If $x_1, x_2 \in A_2$ then $h(x_1)=g(x_1), h(x_2)=g(x_2)$ and so $g(x_1)=g(x_2) \Rightarrow x_1=x_2$ since $g$ is injective. If $x_1 \in A_1, x_2 \in A_2$ then $h(x_1)=h(x_2) \Rightarrow f(x_1)=f(x_2)$ that cannot be true because $B_1 \cap B_2=\varnothing$. We will show that $h$ is surjective, i.e. that $\forall y \in B_1 \cup B_2, \exists x \in A_1 \cup B_2$ such that $f(x)=y$. If $y \in B_1$ then we know that there will be a $x \in A_1$ such that $h(x)=y \Rightarrow f(x)=y$ since $f$ is surjective. If $y \in B_2$ then we know that there will be a $x \in A_2$ such that $h(x)=y \Rightarrow g(x)=y$ since $g$ is surjective. We define the product $m \cdot n$ of the cardinal numbers $m,n$ as the cardinal number of the cartesian product of $A$ and $B$, i.e. $$m \cdot n=card(A \times B)$$ We will show that the product of two cardinal numbers is well-defined. It suffices to show that if $A_1 \sim B_1, A_2 \sim B_2$ with $A_1 \cap A_2=\varnothing, B_1 \cap B_2=\varnothing$ then $A_1 \times A_2 \sim B_1 \times B_2$. We know that there are bijective functions $f: A_1 \to A_2, g:B_1 \to B_2$. We want to show that there is a bijective function $h: A_1 \times A_2 \to B_1 \times B_2$. We define $h: A_1 \times A_2 \to B_1 \times B_2$ such that $\langle n,m \rangle \mapsto \langle f(n),g(m) \rangle$ We will show  that $h$ is 1-1. Let $\langle m_1, n_1 \rangle, \langle m_2, n_2 \rangle \in A_1 \times A_2$ with $h(\langle m_1, n_1 \rangle)=h(\langle m_2, n_2 \rangle) \rightarrow \langle f(n_1),g(m_1) \rangle=\langle f(n_2),g(m_2) \rangle \rightarrow f(n_1))=f(n_2) \wedge g(m_1)=g(m_2) \overset{\text{f,g:} 1-1 }{\rightarrow} m_1=m_2 \wedge n_1=n_2 \rightarrow \langle m_1,n_1 \rangle=\langle m_2,n_2 \rangle$ From the surjectivity of $f,g$ we can conclude that $h$ is surjective. Could you tell me if it is right?",,['elementary-set-theory']
16,How can I prove this relation between the elementary set theory and the elementary logic?,How can I prove this relation between the elementary set theory and the elementary logic?,,"If you need to prove an equality like $A\Delta B=(B\setminus C)\cup[C\cap (B\Delta A)]$ we can first prove $p\underline{\lor} q\Longleftrightarrow (q\land\overline{r})\lor(q\underline{\lor}p)$ (with a truth table for example) and then use it whith $p=x\in A$, $q=x \in B$ and $r=x \in C$. So, if we now that $p\underline{\lor} q\Longleftrightarrow (q\land\overline{r})\lor(q\underline{\lor}p)$ then we now that $A\Delta B=(B\setminus C)\cup[C\cap (B\Delta A)]$. But my question is. is true in general (with a general set equation) the reverse implication? that is  $A\Delta B=(B\setminus C)\cup[C\cap (B\Delta A)]$ implies $p\underline{\lor} q\Longleftrightarrow (q\land\overline{r})\lor(q\underline{\lor}p)$.","If you need to prove an equality like $A\Delta B=(B\setminus C)\cup[C\cap (B\Delta A)]$ we can first prove $p\underline{\lor} q\Longleftrightarrow (q\land\overline{r})\lor(q\underline{\lor}p)$ (with a truth table for example) and then use it whith $p=x\in A$, $q=x \in B$ and $r=x \in C$. So, if we now that $p\underline{\lor} q\Longleftrightarrow (q\land\overline{r})\lor(q\underline{\lor}p)$ then we now that $A\Delta B=(B\setminus C)\cup[C\cap (B\Delta A)]$. But my question is. is true in general (with a general set equation) the reverse implication? that is  $A\Delta B=(B\setminus C)\cup[C\cap (B\Delta A)]$ implies $p\underline{\lor} q\Longleftrightarrow (q\land\overline{r})\lor(q\underline{\lor}p)$.",,['elementary-set-theory']
17,Question concerning the universe of sets.,Question concerning the universe of sets.,,"I am reading Charles Pinter's Introduction to Set Theory Every proper class is in one-to-one correspondence with the universal class $\mathscr{U}$, that is, the class of all sets [emph. added]. He uses the term in the beginning of the book, and then makes a sudden transition to the term ""universe of sets,"" denoted by $V$. What's the difference between $\mathscr{U}$ and $V$? If they are the same,why use different terms? Any clarification is appreciated.","I am reading Charles Pinter's Introduction to Set Theory Every proper class is in one-to-one correspondence with the universal class $\mathscr{U}$, that is, the class of all sets [emph. added]. He uses the term in the beginning of the book, and then makes a sudden transition to the term ""universe of sets,"" denoted by $V$. What's the difference between $\mathscr{U}$ and $V$? If they are the same,why use different terms? Any clarification is appreciated.",,"['elementary-set-theory', 'notation']"
18,"Prove that if $A$ is a set with infinite cardinality, then there exists a bijection between $A$ and $A^2$. [duplicate]","Prove that if  is a set with infinite cardinality, then there exists a bijection between  and . [duplicate]",A A A^2,"This question already has an answer here : Cardinal of $X^2$ (1 answer) Closed 9 years ago . Prove that if $A$ is a set with infinite cardinality, then there exists a bijection between $A$ and $A^2$. I know that there exists a bijection between $\Bbb{R}$ and $\Bbb{R^2}$, but I don't think that technique can be generalized. I think the proof of this may be highly non-trivial. Any help would be great.","This question already has an answer here : Cardinal of $X^2$ (1 answer) Closed 9 years ago . Prove that if $A$ is a set with infinite cardinality, then there exists a bijection between $A$ and $A^2$. I know that there exists a bijection between $\Bbb{R}$ and $\Bbb{R^2}$, but I don't think that technique can be generalized. I think the proof of this may be highly non-trivial. Any help would be great.",,['elementary-set-theory']
19,Proof for $n<m$ iff $n\leq m$ and $n\ne m$,Proof for  iff  and,n<m n\leq m n\ne m,"It's a basic exrecise on Set Theory course. We constructed the natural numbers by $0=\emptyset$ and $n+1=n\cup \{n\}$. So basically the order relation defined by $m<n$ if $m\in n$, and $m\leq n$ if $m\subseteq n$. We need to prove (by induction? I guess..) that: $n\in m$ iff $n\subseteq m$ and $n\ne m$ I don't see how to even begin. please, help.","It's a basic exrecise on Set Theory course. We constructed the natural numbers by $0=\emptyset$ and $n+1=n\cup \{n\}$. So basically the order relation defined by $m<n$ if $m\in n$, and $m\leq n$ if $m\subseteq n$. We need to prove (by induction? I guess..) that: $n\in m$ iff $n\subseteq m$ and $n\ne m$ I don't see how to even begin. please, help.",,['elementary-set-theory']
20,How to calculate the product of a set,How to calculate the product of a set,,"How can you calculate the product of a set $A$, denoted by $\Pi A$ and defined by $\forall z \in \Pi A(z \subseteq \bigcup A \wedge \forall y \in A (\exists x (z \cap y = \lbrace x \rbrace)))  $ Also, is it different for finite and infinite sets?","How can you calculate the product of a set $A$, denoted by $\Pi A$ and defined by $\forall z \in \Pi A(z \subseteq \bigcup A \wedge \forall y \in A (\exists x (z \cap y = \lbrace x \rbrace)))  $ Also, is it different for finite and infinite sets?",,"['elementary-set-theory', 'products']"
21,A finite alternative to Hilbert's Hotel?,A finite alternative to Hilbert's Hotel?,,"Here, I propose a finite alternative to Hilbert's hotel as the intuition for logically developing Dedekind's definition of infinite. I would like to know if this analogy entirely justifies the given formalism. If not, can anyone suggest changes? A walk through a finite village Suppose you start at any house in this finite village, and set out on a walk through the village, going from one house to another. Suppose further that, after you set out, you do not go to any house in the village (including your starting point) more than once . And after you set out, you also do not stop unless you return to your starting point.  You may or may not go to every house in the village. Intuitively, you could not avoid returning to your starting point under these conditions.  You could, of course, return to your starting point without first going to every other house in the village. If you kept going, however, you would eventually run out of different places to go, and you would have to return to your starting point. Going anywhere else would be going there more than once. This would be true of any finite village. (It would not be true of any infinite village.) How can we describe such paths mathematically? We can let $S$ be the set of houses in the village. Every path as described above can be represented (up to and including the point of return) by an injective function $f: S\to S$. If you are at house $x$, then the next house on your walk would be uniquely given by $f(x)$. Why an injective function? To ensure that you visit each house no more than once, $f$ must be injective, i.e. if $f(x) = f(y)$, then $x = y$. Suppose we let $x_0$ be the house that is your starting point. Since you must eventually return to $x_0$, there must exist a house $x_n$ such that $f(x_n) = x_0$, i.e. $x_n$ would be last house you visited before returning to your starting point $x_0$. A set $S$ can then be said to finite if and only if $\forall x_0, f:[x_0 \in S \land f:S\to S\implies [Injective(f) \implies \exists x_n \in S: f(x_n)=x_0]$ This can be shown to be equivalent to Dedekind's definition of finite, with it's negation being the definition of infinite.","Here, I propose a finite alternative to Hilbert's hotel as the intuition for logically developing Dedekind's definition of infinite. I would like to know if this analogy entirely justifies the given formalism. If not, can anyone suggest changes? A walk through a finite village Suppose you start at any house in this finite village, and set out on a walk through the village, going from one house to another. Suppose further that, after you set out, you do not go to any house in the village (including your starting point) more than once . And after you set out, you also do not stop unless you return to your starting point.  You may or may not go to every house in the village. Intuitively, you could not avoid returning to your starting point under these conditions.  You could, of course, return to your starting point without first going to every other house in the village. If you kept going, however, you would eventually run out of different places to go, and you would have to return to your starting point. Going anywhere else would be going there more than once. This would be true of any finite village. (It would not be true of any infinite village.) How can we describe such paths mathematically? We can let $S$ be the set of houses in the village. Every path as described above can be represented (up to and including the point of return) by an injective function $f: S\to S$. If you are at house $x$, then the next house on your walk would be uniquely given by $f(x)$. Why an injective function? To ensure that you visit each house no more than once, $f$ must be injective, i.e. if $f(x) = f(y)$, then $x = y$. Suppose we let $x_0$ be the house that is your starting point. Since you must eventually return to $x_0$, there must exist a house $x_n$ such that $f(x_n) = x_0$, i.e. $x_n$ would be last house you visited before returning to your starting point $x_0$. A set $S$ can then be said to finite if and only if $\forall x_0, f:[x_0 \in S \land f:S\to S\implies [Injective(f) \implies \exists x_n \in S: f(x_n)=x_0]$ This can be shown to be equivalent to Dedekind's definition of finite, with it's negation being the definition of infinite.",,"['elementary-set-theory', 'soft-question']"
22,Compositions of filters on finite unions of Cartesian products,Compositions of filters on finite unions of Cartesian products,,"Let $\Gamma$ be the lattice of all finite unions of Cartesian products $A\times B$ of two arbitrary sets $A,B\subseteq U$ for some set $U$. See this note for other equivalent ways to describe the set $\Gamma$: http://www.mathematics21.org/binaries/funcoids-are-filters.pdf It is obvious that $G\circ F\in\Gamma$ for every binary relations $F,G\in\Gamma$. Thus for every filters $f$ and $g$ on $\Gamma$ we can define $g\circ f$ as the filter on $\Gamma$ defined by the base $\{ G\circ F \mid F\in f,G\in g \}$. I need to prove (or disprove) that if $K\in g\circ f$ then there exist $F\in f$ and $G\in g$ such that $K\supseteq G\circ F$ (for all filters $f$, $g$ on $\Gamma$). It seems that it's enough to prove this conjecture only for the case if $f$ or $g$ is a principal filter.","Let $\Gamma$ be the lattice of all finite unions of Cartesian products $A\times B$ of two arbitrary sets $A,B\subseteq U$ for some set $U$. See this note for other equivalent ways to describe the set $\Gamma$: http://www.mathematics21.org/binaries/funcoids-are-filters.pdf It is obvious that $G\circ F\in\Gamma$ for every binary relations $F,G\in\Gamma$. Thus for every filters $f$ and $g$ on $\Gamma$ we can define $g\circ f$ as the filter on $\Gamma$ defined by the base $\{ G\circ F \mid F\in f,G\in g \}$. I need to prove (or disprove) that if $K\in g\circ f$ then there exist $F\in f$ and $G\in g$ such that $K\supseteq G\circ F$ (for all filters $f$, $g$ on $\Gamma$). It seems that it's enough to prove this conjecture only for the case if $f$ or $g$ is a principal filter.",,"['elementary-set-theory', 'lattice-orders', 'products', 'filters']"
23,"Using expressions like $ \langle x,y \rangle$ in predicate logic formulas",Using expressions like  in predicate logic formulas," \langle x,y \rangle","I don't like how books on set theory write logic formulas when describing complex sets. For example that is how a regular book can show that some set $s$ is not a pair: $$\forall x \forall y (\langle x,y \rangle \neq s)$$ Or by this way a book can show that some set $s$ is a relation: $$\forall p (p \in s \implies \exists x \exists y (\langle x,y \rangle = p))$$ The expression $\langle x,y \rangle$ when used in formulas confuses me. It is like you create an object on the fly . If the object $\langle x,y \rangle$ were constant, it would be fine, but it depends on the quantifiers $x$ and $y$, and outside of the formula doesn't make sense. And the books do it all the time. I haven't learned logic deeply but it seems to me that the given formulas are not formulas of predicate logic. In predicate logic you have simple quantifiers like $\forall x$ that range over objects and you have predicates that evaluate either to true or false, not to other objects. But in these formulas it is like you can use a complex quantifier: $\forall \langle x,y \rangle$ that ranges over all pairs. The authors of the books on set theory start using this way of writing without any explanation what they are doing. It is like they were saying: ""you will understand it when you take a course on logic, and now watch what we do and do the same."" But, alas, they don't even make this clear. I see only two possibilities: 1) these are legitimate formulas in predicate logic, and my confusion is due to not knowing logic well, or 2) this is just an informal way to express complex ideas, and we can always translate any formula written in this informal way to a legitimate predicate logic formula. That's how I would express that some set $s$ is not a pair. Let's create a property $P(x,y,z)$ which is true iff $\langle x,y \rangle = z$: $$P(x,y,z) \iff \exists a ( x \in a \land \forall v (v \in a \implies v =x) \land \exists b(x \in b \land y \in b \land \forall v (v \in b \implies v = x \lor v = y)) \land a \in z \land b \in z \land \forall v (v \in z \implies v = a \lor v = b)))  $$ Given that property we can express that some set $s$ is not a pair: $\forall x \forall y (\lnot P(x,y,s))$. Here if we substitute $P(x,y,s)$ with the big formula given above, we would get a legitimate predicate logic formula. We can also express that some set $f$ is a function: $$\forall p (p \in f \implies (\exists x \exists y P(x,y,p) \land \lnot \exists y' \exists p'(y \neq y' \land P(x,y',p') \land p' \in f)))$$","I don't like how books on set theory write logic formulas when describing complex sets. For example that is how a regular book can show that some set $s$ is not a pair: $$\forall x \forall y (\langle x,y \rangle \neq s)$$ Or by this way a book can show that some set $s$ is a relation: $$\forall p (p \in s \implies \exists x \exists y (\langle x,y \rangle = p))$$ The expression $\langle x,y \rangle$ when used in formulas confuses me. It is like you create an object on the fly . If the object $\langle x,y \rangle$ were constant, it would be fine, but it depends on the quantifiers $x$ and $y$, and outside of the formula doesn't make sense. And the books do it all the time. I haven't learned logic deeply but it seems to me that the given formulas are not formulas of predicate logic. In predicate logic you have simple quantifiers like $\forall x$ that range over objects and you have predicates that evaluate either to true or false, not to other objects. But in these formulas it is like you can use a complex quantifier: $\forall \langle x,y \rangle$ that ranges over all pairs. The authors of the books on set theory start using this way of writing without any explanation what they are doing. It is like they were saying: ""you will understand it when you take a course on logic, and now watch what we do and do the same."" But, alas, they don't even make this clear. I see only two possibilities: 1) these are legitimate formulas in predicate logic, and my confusion is due to not knowing logic well, or 2) this is just an informal way to express complex ideas, and we can always translate any formula written in this informal way to a legitimate predicate logic formula. That's how I would express that some set $s$ is not a pair. Let's create a property $P(x,y,z)$ which is true iff $\langle x,y \rangle = z$: $$P(x,y,z) \iff \exists a ( x \in a \land \forall v (v \in a \implies v =x) \land \exists b(x \in b \land y \in b \land \forall v (v \in b \implies v = x \lor v = y)) \land a \in z \land b \in z \land \forall v (v \in z \implies v = a \lor v = b)))  $$ Given that property we can express that some set $s$ is not a pair: $\forall x \forall y (\lnot P(x,y,s))$. Here if we substitute $P(x,y,s)$ with the big formula given above, we would get a legitimate predicate logic formula. We can also express that some set $f$ is a function: $$\forall p (p \in f \implies (\exists x \exists y P(x,y,p) \land \lnot \exists y' \exists p'(y \neq y' \land P(x,y',p') \land p' \in f)))$$",,"['elementary-set-theory', 'predicate-logic']"
24,"Well ordered sets, set theory","Well ordered sets, set theory",,"Define a relation $R$ among ordered pairs of ordinals by $(\gamma,\delta)R(\lambda,\kappa)$ if $\gamma +\delta<\lambda +\kappa$ or $\gamma +\delta=\lambda +\kappa$ and $\gamma<\lambda$ (1) Prove that this is a well-order in  the class of ordered pairs of ordinals and that for every $(\lambda,\kappa)$ the class $\{(\gamma,\delta): (\gamma,\delta)R(\lambda,\kappa)\}$ is a set. First we have to show that it is a strict linear order, i.e., $R$ is irreflexive, transitive and linear relation, and after that the wellfoundedness part of finding the least element. How can I show the wellfoundness part? And to prove that it is a set, what shall I use? Replacement?  Thanks for any help, I really appreciate your answers.","Define a relation $R$ among ordered pairs of ordinals by $(\gamma,\delta)R(\lambda,\kappa)$ if $\gamma +\delta<\lambda +\kappa$ or $\gamma +\delta=\lambda +\kappa$ and $\gamma<\lambda$ (1) Prove that this is a well-order in  the class of ordered pairs of ordinals and that for every $(\lambda,\kappa)$ the class $\{(\gamma,\delta): (\gamma,\delta)R(\lambda,\kappa)\}$ is a set. First we have to show that it is a strict linear order, i.e., $R$ is irreflexive, transitive and linear relation, and after that the wellfoundedness part of finding the least element. How can I show the wellfoundness part? And to prove that it is a set, what shall I use? Replacement?  Thanks for any help, I really appreciate your answers.",,['elementary-set-theory']
25,Is there an established notion for the square root of a set?,Is there an established notion for the square root of a set?,,"I'm looking for reading I could do around the concept of square rooting a set. I'm defining$\sqrt{A}$ to be the largest $B$ (by $\subseteq$), s.t. $B^2 \subseteq A$. So $\sqrt{A\times B} = A \cap B$. I'd like to know whether it has an established name, alternate descriptions, documented inequalities, etc., also can it be written as a fixed point of some set transformation function? Thanks in advance :)","I'm looking for reading I could do around the concept of square rooting a set. I'm defining$\sqrt{A}$ to be the largest $B$ (by $\subseteq$), s.t. $B^2 \subseteq A$. So $\sqrt{A\times B} = A \cap B$. I'd like to know whether it has an established name, alternate descriptions, documented inequalities, etc., also can it be written as a fixed point of some set transformation function? Thanks in advance :)",,['elementary-set-theory']
26,Unit for Left Adjoint to the Inclusion Functor,Unit for Left Adjoint to the Inclusion Functor,,"I have the following construction, which seems too easy. Could you review and comment? Thanks in advance. Suppose $I$  is a set, and $P(I)$ is its power set, viewed as a category whose arrows are set inclusion. Then the functor $i:P(I)\rightarrow Set/I$ defined in the obvious way by $U(\subset I)\mapsto(U\hookrightarrow I)$ and $(U\subset V)\mapsto $  \begin{array}{&&}  U & {\to} & V\\ & \searrow & \downarrow  \\   & & I \end{array} (where all the arrows are inclusions) has a left adjoint, $F$. $F:Set/I\rightarrow P(I)$ just takes any $h:X\rightarrow I$ to $h(X)$. On arrows $\varphi :h\rightarrow h'$, we have  \begin{array}{&&}  X & \stackrel{\varphi}{\to} & X' \\ & h \searrow & \downarrow h' \\   & & I \end{array} so that $h(X)\subset h'(X')$ as required. The unit, $\eta _{h}:h\rightarrow (i\circ F)h$ is then $h \rightarrow (h(X)\hookrightarrow I)$. If $f:h\rightarrow i(V)$ then $h(X)\subset V$ and so we get our (unique) $ \overline f:Fh\rightarrow V$. To show that  \begin{array}{&&}  h & \stackrel{\eta _{h}}{\to} & i(Fh) \\ & f \searrow & \downarrow i(\overline f) \\   & & i(V) \end{array} commutes just amounts to observing that $f=h$.","I have the following construction, which seems too easy. Could you review and comment? Thanks in advance. Suppose $I$  is a set, and $P(I)$ is its power set, viewed as a category whose arrows are set inclusion. Then the functor $i:P(I)\rightarrow Set/I$ defined in the obvious way by $U(\subset I)\mapsto(U\hookrightarrow I)$ and $(U\subset V)\mapsto $  \begin{array}{&&}  U & {\to} & V\\ & \searrow & \downarrow  \\   & & I \end{array} (where all the arrows are inclusions) has a left adjoint, $F$. $F:Set/I\rightarrow P(I)$ just takes any $h:X\rightarrow I$ to $h(X)$. On arrows $\varphi :h\rightarrow h'$, we have  \begin{array}{&&}  X & \stackrel{\varphi}{\to} & X' \\ & h \searrow & \downarrow h' \\   & & I \end{array} so that $h(X)\subset h'(X')$ as required. The unit, $\eta _{h}:h\rightarrow (i\circ F)h$ is then $h \rightarrow (h(X)\hookrightarrow I)$. If $f:h\rightarrow i(V)$ then $h(X)\subset V$ and so we get our (unique) $ \overline f:Fh\rightarrow V$. To show that  \begin{array}{&&}  h & \stackrel{\eta _{h}}{\to} & i(Fh) \\ & f \searrow & \downarrow i(\overline f) \\   & & i(V) \end{array} commutes just amounts to observing that $f=h$.",,"['elementary-set-theory', 'category-theory']"
27,Do we need AC to prove Principle of Dependent Choices,Do we need AC to prove Principle of Dependent Choices,,"For any nonempty set $X$ and any entire binary relation $R$ on $X$, there is a sequence $(x_n)$ in $X$ such that $x_nRx_{n+1}$ for each $n \in \mathbb{N}$. (Here an entire binary relation on $X$ is one such that for each $a$ in $X$ there is a $b$ in $X$ such that $aRb$.) I cant understand why we cant prove DC bu usual induction: let $x_1=x$ for some $x \in X$ and given $x_n$ there exist $y_n$ such that $x_nRy_n$. We set $x_{n+1}=y_n$. It seems that we dont need AC in proving this theorem.","For any nonempty set $X$ and any entire binary relation $R$ on $X$, there is a sequence $(x_n)$ in $X$ such that $x_nRx_{n+1}$ for each $n \in \mathbb{N}$. (Here an entire binary relation on $X$ is one such that for each $a$ in $X$ there is a $b$ in $X$ such that $aRb$.) I cant understand why we cant prove DC bu usual induction: let $x_1=x$ for some $x \in X$ and given $x_n$ there exist $y_n$ such that $x_nRy_n$. We set $x_{n+1}=y_n$. It seems that we dont need AC in proving this theorem.",,"['elementary-set-theory', 'axiom-of-choice']"
28,Convert expression using only basic logical symbols - have trouble making the two sides apart,Convert expression using only basic logical symbols - have trouble making the two sides apart,,"I have this expression: $F \subseteq P(A)$ Where $F$ is some family of sets and $P(A)$ is the power set of $A$. I need to express this with using only: $\in, \notin, =, \neq, \wedge, \vee, \rightarrow, \leftrightarrow, \forall, \exists$ I first started out at writing $F$ as: $\forall x(\exists A(\forall y \in A(y\in F)))...$ However I think the notation is totally wrong. Am I supposed to somehow use indices to describe F with only these symbols?","I have this expression: $F \subseteq P(A)$ Where $F$ is some family of sets and $P(A)$ is the power set of $A$. I need to express this with using only: $\in, \notin, =, \neq, \wedge, \vee, \rightarrow, \leftrightarrow, \forall, \exists$ I first started out at writing $F$ as: $\forall x(\exists A(\forall y \in A(y\in F)))...$ However I think the notation is totally wrong. Am I supposed to somehow use indices to describe F with only these symbols?",,['elementary-set-theory']
29,proving for cantor set: $\mathcal C=\frac13\mathcal C\cup\left(\frac23+\frac13\mathcal C\right)$,proving for cantor set:,\mathcal C=\frac13\mathcal C\cup\left(\frac23+\frac13\mathcal C\right),"Let $\mathcal C$ be the Cantor set. Then $$\mathcal C=\frac13\mathcal C\cup\left(\frac23+\frac13\mathcal C\right)$$ with $\frac13\mathcal C:=\{\frac13x:x\in\mathcal C\}$ and $\frac23+\frac12\mathcal C:=\{\frac23+\frac13x:x\in\mathcal C\}$. In lecture we had the following proof: \begin{align} \mathcal C&=\bigcap_{n=0}^\infty \mathcal C_n \tag{1}\\ &=\bigcap_{n=0}^\infty \left(\frac13\mathcal C_n\cup\left(\frac23+\frac13\mathcal C_n\right)\right)\tag{2}\\ &\supset\bigcap_{i,j=0}^\infty\left(\frac13\mathcal C_i\cup\left(\frac23+\frac13\mathcal C_j\right)\right)\tag{3}\\ &=\left(\frac13\bigcap_{i=0}^\infty \mathcal C_i\right)\cup\left(\frac23+\frac12\bigcap_{j=0}^\infty \mathcal C_j\right)\tag{4}\\ &=\frac13\mathcal C\cup\left(\frac23+\frac13\mathcal C\right)\tag{5} \end{align} Otherwise\begin{align} \frac13\mathcal C\cup\left(\frac23+\frac12\mathcal C\right)&=\left(\frac13\bigcap_{i=0}^\infty \mathcal C_i\right)\cup\left(\frac23+\frac12\bigcap_{j=0}^\infty \mathcal C_j\right) \tag{6}\\ &= \bigcap_{i,j=0}^\infty \left(\frac13\mathcal C_i\cup\left(\frac23+\frac13\mathcal C_j\right)\right)\tag{7}\\ &\supset\bigcap_{i,j=0}^\infty \left(\frac13\mathcal C_{\max\{i,j\}}\cup\left(\frac23+\frac13\mathcal C_{\max\{i,j\}}\right)\right)\tag{8}\\ &=\bigcap_{n=0}^\infty \left(\frac13\mathcal C_n\cup\left(\frac23+\frac13\mathcal C_n\right)\right)\tag{9}\\ &=\mathcal C\tag{10} \end{align} Now I have some problems reproducing the proof. I've proved myself $$\mathcal C_{n+1}=\frac13\mathcal C_n\cup\left(\frac23+\frac13\mathcal C_n\right)$$ So (1) and (2) are obvious. But what about (3)? Why are there two different indices? And why does it hold? Then (4),(5),(6),(7) are clear. But why do you have to take the maximum in (8) for the subset? The (9) follows clearly by naming the maximum $n$. (10) similar to (1)-(2).","Let $\mathcal C$ be the Cantor set. Then $$\mathcal C=\frac13\mathcal C\cup\left(\frac23+\frac13\mathcal C\right)$$ with $\frac13\mathcal C:=\{\frac13x:x\in\mathcal C\}$ and $\frac23+\frac12\mathcal C:=\{\frac23+\frac13x:x\in\mathcal C\}$. In lecture we had the following proof: \begin{align} \mathcal C&=\bigcap_{n=0}^\infty \mathcal C_n \tag{1}\\ &=\bigcap_{n=0}^\infty \left(\frac13\mathcal C_n\cup\left(\frac23+\frac13\mathcal C_n\right)\right)\tag{2}\\ &\supset\bigcap_{i,j=0}^\infty\left(\frac13\mathcal C_i\cup\left(\frac23+\frac13\mathcal C_j\right)\right)\tag{3}\\ &=\left(\frac13\bigcap_{i=0}^\infty \mathcal C_i\right)\cup\left(\frac23+\frac12\bigcap_{j=0}^\infty \mathcal C_j\right)\tag{4}\\ &=\frac13\mathcal C\cup\left(\frac23+\frac13\mathcal C\right)\tag{5} \end{align} Otherwise\begin{align} \frac13\mathcal C\cup\left(\frac23+\frac12\mathcal C\right)&=\left(\frac13\bigcap_{i=0}^\infty \mathcal C_i\right)\cup\left(\frac23+\frac12\bigcap_{j=0}^\infty \mathcal C_j\right) \tag{6}\\ &= \bigcap_{i,j=0}^\infty \left(\frac13\mathcal C_i\cup\left(\frac23+\frac13\mathcal C_j\right)\right)\tag{7}\\ &\supset\bigcap_{i,j=0}^\infty \left(\frac13\mathcal C_{\max\{i,j\}}\cup\left(\frac23+\frac13\mathcal C_{\max\{i,j\}}\right)\right)\tag{8}\\ &=\bigcap_{n=0}^\infty \left(\frac13\mathcal C_n\cup\left(\frac23+\frac13\mathcal C_n\right)\right)\tag{9}\\ &=\mathcal C\tag{10} \end{align} Now I have some problems reproducing the proof. I've proved myself $$\mathcal C_{n+1}=\frac13\mathcal C_n\cup\left(\frac23+\frac13\mathcal C_n\right)$$ So (1) and (2) are obvious. But what about (3)? Why are there two different indices? And why does it hold? Then (4),(5),(6),(7) are clear. But why do you have to take the maximum in (8) for the subset? The (9) follows clearly by naming the maximum $n$. (10) similar to (1)-(2).",,['real-analysis']
30,order preserving implies isomorphism,order preserving implies isomorphism,,"Let $M = (M, <)$ and $N = (N, <)$ be two dense totally ordered sets without endpoints. Let $F$ be the collection of order preserving maps between finite subsets of $M,N$ respectively. Then $F$ is a non-empty family of partial isomorphisms between $M$ and $N$ with the back-and-forth property. It's clear that $F$ is non-empty and each member of $F$ is an injective map, but how can I show it's onto?","Let and be two dense totally ordered sets without endpoints. Let be the collection of order preserving maps between finite subsets of respectively. Then is a non-empty family of partial isomorphisms between and with the back-and-forth property. It's clear that is non-empty and each member of is an injective map, but how can I show it's onto?","M = (M, <) N = (N, <) F M,N F M N F F","['elementary-set-theory', 'order-theory']"
31,Double set difference,Double set difference,,"Let $A,B \subset X$ and $A \cap B = \emptyset$. What is $A \setminus (A \setminus B)$? Since $A,B$ are disjoint, $A \setminus B = A$, whence $A \setminus (A \setminus B) = A \setminus A$.  Now what is this set? It's the set of elements of $A$ that are not elements of $A$. Well, there are no such elements in $A$, right? Thus $A \setminus A = \emptyset$. Is this correct? This is related to an exercise (my first ever) in measure theory, if you're wondering where this question could possibly come from.","Let $A,B \subset X$ and $A \cap B = \emptyset$. What is $A \setminus (A \setminus B)$? Since $A,B$ are disjoint, $A \setminus B = A$, whence $A \setminus (A \setminus B) = A \setminus A$.  Now what is this set? It's the set of elements of $A$ that are not elements of $A$. Well, there are no such elements in $A$, right? Thus $A \setminus A = \emptyset$. Is this correct? This is related to an exercise (my first ever) in measure theory, if you're wondering where this question could possibly come from.",,['elementary-set-theory']
32,About binary relations under certain conditions and their composition,About binary relations under certain conditions and their composition,,"(I have edited it. The previous version was with errors.) Let $A$ be a set. Let $\pi_0$, $\pi_1$ be projections from $A\times A$. Let $F_0$, $F_1$, $G_0$, $G_1$ be binary relations on $A$. Let $\Phi_A$ be the maximal binary relation in $(A\times A)\times(A\times A)$ such that $\pi_0\circ\Phi_A\subseteq F_0\circ\pi_0$ and $\pi_1\circ\Phi_A\subseteq F_1\circ\pi_1$. Let $\Phi_B$ be the maximal binary relation in $(A\times A)\times(A\times A)$ such that $\pi_0\circ\Phi_B\subseteq G_0\circ\pi_0$ and $\pi_1\circ\Phi_B\subseteq G_1\circ\pi_1$. Prove (or disprove) that $\Sigma=\Phi_B\circ\Phi_A$ is the maximal binary relation on $A$ such that $\pi_0\circ\Sigma\subseteq G_0\circ F_0\circ\pi_0$ and $\pi_1\circ\Sigma\subseteq G_1\circ F_1\circ\pi_1$.","(I have edited it. The previous version was with errors.) Let $A$ be a set. Let $\pi_0$, $\pi_1$ be projections from $A\times A$. Let $F_0$, $F_1$, $G_0$, $G_1$ be binary relations on $A$. Let $\Phi_A$ be the maximal binary relation in $(A\times A)\times(A\times A)$ such that $\pi_0\circ\Phi_A\subseteq F_0\circ\pi_0$ and $\pi_1\circ\Phi_A\subseteq F_1\circ\pi_1$. Let $\Phi_B$ be the maximal binary relation in $(A\times A)\times(A\times A)$ such that $\pi_0\circ\Phi_B\subseteq G_0\circ\pi_0$ and $\pi_1\circ\Phi_B\subseteq G_1\circ\pi_1$. Prove (or disprove) that $\Sigma=\Phi_B\circ\Phi_A$ is the maximal binary relation on $A$ such that $\pi_0\circ\Sigma\subseteq G_0\circ F_0\circ\pi_0$ and $\pi_1\circ\Sigma\subseteq G_1\circ F_1\circ\pi_1$.",,"['elementary-set-theory', 'relations', 'products']"
33,Logic: what are the cardinalities of the following sets?,Logic: what are the cardinalities of the following sets?,,"Let $X$ $\subseteq$ $\mathcal P \left({\mathbb{N}}\right)$. Determine the cardinalities of the following sets: $X = \{ A \subseteq \mathbb{N} |$ for every $B\subseteq\mathbb{N}$: $A\cap B=\emptyset$ or $A\cap B=A$ $\}$ $X = \{ A \subseteq \mathbb{N} |$ both $A$ and $\mathbb{N}-A$ are infinite$\}$ $X = \{ A \subseteq \mathbb{N} |$ for every ascending sequence $(a_n)_{n\in\mathbb{N}} \in \mathbb{N}$ there is an $a_n \in A$ with $n \in \mathbb{N}$$\}$ For the first one, I think that $|X|={|\mathbb{N}|}$ (because every $A$ consists of just one natural number). My guess for the second one would be $|X|={|\mathbb{N}|}$, because every $A$ would be of the form $\mathbb{N}-B$ with $B$ some infinite set. For the third one I have actually no idea. Edit The cardinality of the first set is $\mathbb{N}$ and the second set is $2^{\mathbb{N}}$","Let $X$ $\subseteq$ $\mathcal P \left({\mathbb{N}}\right)$. Determine the cardinalities of the following sets: $X = \{ A \subseteq \mathbb{N} |$ for every $B\subseteq\mathbb{N}$: $A\cap B=\emptyset$ or $A\cap B=A$ $\}$ $X = \{ A \subseteq \mathbb{N} |$ both $A$ and $\mathbb{N}-A$ are infinite$\}$ $X = \{ A \subseteq \mathbb{N} |$ for every ascending sequence $(a_n)_{n\in\mathbb{N}} \in \mathbb{N}$ there is an $a_n \in A$ with $n \in \mathbb{N}$$\}$ For the first one, I think that $|X|={|\mathbb{N}|}$ (because every $A$ consists of just one natural number). My guess for the second one would be $|X|={|\mathbb{N}|}$, because every $A$ would be of the form $\mathbb{N}-B$ with $B$ some infinite set. For the third one I have actually no idea. Edit The cardinality of the first set is $\mathbb{N}$ and the second set is $2^{\mathbb{N}}$",,"['elementary-set-theory', 'logic']"
34,Validity of my proof about $A \preceq B$ if and only if $\#A \le \#B$,Validity of my proof about  if and only if,A \preceq B \#A \le \#B,"I'd like to know if my proof of the next theorem is correct or maybe need some adjustments to be correct. Definition: Let $A,B$ be sets. We write $A\preceq B\iff$ there exists an injection $A\to B$. Theorem: Let $A, B$ be finite sets. Then, $A \preceq B$ if and only if $\#A \le \#B$. Proof: ($\Rightarrow$) Let $\varphi(n)$ be the statement ""B is a set of size $\,n\,$ and $A \preceq B \rightarrow \#A \le n$."" $$S = \left\{\,n\in \omega:\varphi(n)\, \right\}.$$ For $n = 0\,$, B is the empty set, and the only injection is to itself. So, clearly $0 \in S.$ Assume $n \in S $ we need to show that $n^{+} \in S$. Suppose  $ \#B =n^{+}$ and $\,f: A \rightarrow B\,$ is an injective map. We choose an element $b\in B$. If $\,b \in f[A] $ therefore $ f(a) = b\,$ for a unique $a\in A$. Let $A^{*} = A-\left\{a \right\}$ and $\,B^{*} = B -\left\{b \right\}$. We define the function $g: A^{*} \rightarrow B^{*}$ to be the restriction of $f$ in $A^{*}$, i.e., $\,g = f\restriction_{A^{*}}$. Then, $g\,$ is a one-to-one function and by our inductive hypothesis $\#A^{*} \le \#B^{*}.$ But since $\#A^{*} = \#A-1\,$ and $\#B^{*} = n$. Then, $\#A-1 \le \ n \rightarrow \#A \le n^{+} .$ If $b \notin f[A]$. Let $B^{*} = B-\left\{b \right\}$. Where $f: A \rightarrow B^{*}$ is a one-to-one function, and by inductive hypothesis $\#A \le \#B^{*}.$ But since $\#B^{*} = \#B-1 = n$. Then, $\#A \le n^{+} $. Hence $n^{+} \in S$ which close the induction. ($\Leftarrow$) We need to show that $\#A \le \#B$ implies the existence of an injective map $f: A\rightarrow B$. For $\#B = 0\,$, that means $\#A = 0$. And clearly $f: \emptyset \rightarrow \emptyset $ is an injection. Suppose our claims holds for n, we need to show that also holds for $n^{+}$. For $\# B = n^{+}$, as $n^{+} \not = 0\,$ the set is nonempty, so  there exist an element $b \in B$. Let $B^{*} = B -\left\{b \right\}$, then we have that $\#B^{*} = n$. If $\#A \le \#B^{*}$ by our inductive hypothesis, there exist a injective map $g : A \rightarrow B^{*}$. Let $i_{ B^{*} \rightarrow B}$ be the inclusion map, i.e., $i_{ B^{*} \rightarrow B}: B^{*} \rightarrow B : j \mapsto j\,$, which is an injection. Therefore, the composition $\, i_{ B^{*} \rightarrow B} \circ g: A \rightarrow B\,$, is an injection as desired. If $\, \#A \not\le \#B^{*}$ but $ \#A \le \#B $, i.e., $ \#A = n^{+}$. We set $A^{*} = A-\left\{a \right\}$. Then $\#A^{*}\le \#B^{*}$ and by the inductive hypothesis there exist an injective map $h': A^{*} \rightarrow B^{*}$. We can define the function $h: A \rightarrow B$, by adding the ordered pair $ \langle a, b \rangle $ to the function $h'$. That is, $h: = h' \cup \left\{\,  \langle a, b \rangle  \, \right\}$ (as $ \langle a, b \rangle $ is a genuine extra element, the map $h$ is one-to-one).  $\;\;\ \Box$ As always thanks in advance.","I'd like to know if my proof of the next theorem is correct or maybe need some adjustments to be correct. Definition: Let $A,B$ be sets. We write $A\preceq B\iff$ there exists an injection $A\to B$. Theorem: Let $A, B$ be finite sets. Then, $A \preceq B$ if and only if $\#A \le \#B$. Proof: ($\Rightarrow$) Let $\varphi(n)$ be the statement ""B is a set of size $\,n\,$ and $A \preceq B \rightarrow \#A \le n$."" $$S = \left\{\,n\in \omega:\varphi(n)\, \right\}.$$ For $n = 0\,$, B is the empty set, and the only injection is to itself. So, clearly $0 \in S.$ Assume $n \in S $ we need to show that $n^{+} \in S$. Suppose  $ \#B =n^{+}$ and $\,f: A \rightarrow B\,$ is an injective map. We choose an element $b\in B$. If $\,b \in f[A] $ therefore $ f(a) = b\,$ for a unique $a\in A$. Let $A^{*} = A-\left\{a \right\}$ and $\,B^{*} = B -\left\{b \right\}$. We define the function $g: A^{*} \rightarrow B^{*}$ to be the restriction of $f$ in $A^{*}$, i.e., $\,g = f\restriction_{A^{*}}$. Then, $g\,$ is a one-to-one function and by our inductive hypothesis $\#A^{*} \le \#B^{*}.$ But since $\#A^{*} = \#A-1\,$ and $\#B^{*} = n$. Then, $\#A-1 \le \ n \rightarrow \#A \le n^{+} .$ If $b \notin f[A]$. Let $B^{*} = B-\left\{b \right\}$. Where $f: A \rightarrow B^{*}$ is a one-to-one function, and by inductive hypothesis $\#A \le \#B^{*}.$ But since $\#B^{*} = \#B-1 = n$. Then, $\#A \le n^{+} $. Hence $n^{+} \in S$ which close the induction. ($\Leftarrow$) We need to show that $\#A \le \#B$ implies the existence of an injective map $f: A\rightarrow B$. For $\#B = 0\,$, that means $\#A = 0$. And clearly $f: \emptyset \rightarrow \emptyset $ is an injection. Suppose our claims holds for n, we need to show that also holds for $n^{+}$. For $\# B = n^{+}$, as $n^{+} \not = 0\,$ the set is nonempty, so  there exist an element $b \in B$. Let $B^{*} = B -\left\{b \right\}$, then we have that $\#B^{*} = n$. If $\#A \le \#B^{*}$ by our inductive hypothesis, there exist a injective map $g : A \rightarrow B^{*}$. Let $i_{ B^{*} \rightarrow B}$ be the inclusion map, i.e., $i_{ B^{*} \rightarrow B}: B^{*} \rightarrow B : j \mapsto j\,$, which is an injection. Therefore, the composition $\, i_{ B^{*} \rightarrow B} \circ g: A \rightarrow B\,$, is an injection as desired. If $\, \#A \not\le \#B^{*}$ but $ \#A \le \#B $, i.e., $ \#A = n^{+}$. We set $A^{*} = A-\left\{a \right\}$. Then $\#A^{*}\le \#B^{*}$ and by the inductive hypothesis there exist an injective map $h': A^{*} \rightarrow B^{*}$. We can define the function $h: A \rightarrow B$, by adding the ordered pair $ \langle a, b \rangle $ to the function $h'$. That is, $h: = h' \cup \left\{\,  \langle a, b \rangle  \, \right\}$ (as $ \langle a, b \rangle $ is a genuine extra element, the map $h$ is one-to-one).  $\;\;\ \Box$ As always thanks in advance.",,['elementary-set-theory']
35,"Halmos ""Measure Theory"" section 6 problem 3","Halmos ""Measure Theory"" section 6 problem 3",,"This question reads: if the smallest normal class containing a class E is denoted by N(E) , then , for every semiring P , N(P) = S(P) . Has anyone had any joy with this? I've been working under the assumption that the proof of this assertion goes very much like that of Theorem B above ( if R is a ring, then M(R) = S(R) ) So I'm hunting for a class K (F) to take a role similar to that in the theorem. But all my choices fail, either to be closed to (even finite) unions of discrete sets, or to satisfy "" N ⊂ K (E) ∀ E in N implies that N is a semiring"". Am I taking completely the wrong approach? Any hints appreciated.","This question reads: if the smallest normal class containing a class E is denoted by N(E) , then , for every semiring P , N(P) = S(P) . Has anyone had any joy with this? I've been working under the assumption that the proof of this assertion goes very much like that of Theorem B above ( if R is a ring, then M(R) = S(R) ) So I'm hunting for a class K (F) to take a role similar to that in the theorem. But all my choices fail, either to be closed to (even finite) unions of discrete sets, or to satisfy "" N ⊂ K (E) ∀ E in N implies that N is a semiring"". Am I taking completely the wrong approach? Any hints appreciated.",,['elementary-set-theory']
36,Generlized Büchi Games and Closed under superset Muller Games,Generlized Büchi Games and Closed under superset Muller Games,,"For a unique infinite play $p$ in a 2-Player game $G=(V_0,V_1,E)$. Let $$ \inf(p) \subseteq V_0 \cup V_1 $$ be the set of vertices which occur infinitly often in $p$. Generlized Büchi (GB) Games are infinite games with a certain winning condition. Let $\mathcal{B} = \{B_1, \dots , B_k\}$ with $B_i \subset V$. Player $0$ wins the GB-game play $p$ iff for each $i$ $$ B_i \cap \inf(p) \neq \emptyset.$$ Which means that in each of the $B_i$ sets at least one vertex occurs infinitly often in the game. Muller games are more general. The winning condition consists of a set $\mathcal{F_0} \subseteq \mathcal{P}(V)$ and Player $0$ wins a play $p$ iff $$\inf(p) \in \mathcal{F}_0.$$ Muller games closed under superset are Muller games such that $\mathcal{F}_0$ is closed under supersets: $$ X \in \mathcal{F}_0, X \subseteq Y \Rightarrow Y \in \mathcal{F}_0.$$ The taks now is to prove that GB-games and Muller games closed under superset are the same winning conditions. One direction is easy. Just show that $\mathcal{F}_0 := \{X \subset V \mid \forall 1 \leq i \leq k, X \cap B_i \neq \emptyset\}$ is closed under supersets. The other direction is a little bit more tricky: Show that for each muller condition closed under supersets there is a GB condition with the same $\inf$-set for each game. E.g. : $$ V=\{1,2,3,4\} ~~ \mathcal{F}_0=\{\{1,2\},\{3,4\},\{1,2,3,4\}\}$$ The muller condition is closed under supersets. Now the GB-Condition $$\{\{1,3\},\{2,4\}, \dots$$ Here is where I'm stuck. How do I prevent $\inf(p)=\{1,4\}$ or $\inf(p)=\{2,3\}$? There is no construction for ""forbidden combinations"". Any ideas?","For a unique infinite play $p$ in a 2-Player game $G=(V_0,V_1,E)$. Let $$ \inf(p) \subseteq V_0 \cup V_1 $$ be the set of vertices which occur infinitly often in $p$. Generlized Büchi (GB) Games are infinite games with a certain winning condition. Let $\mathcal{B} = \{B_1, \dots , B_k\}$ with $B_i \subset V$. Player $0$ wins the GB-game play $p$ iff for each $i$ $$ B_i \cap \inf(p) \neq \emptyset.$$ Which means that in each of the $B_i$ sets at least one vertex occurs infinitly often in the game. Muller games are more general. The winning condition consists of a set $\mathcal{F_0} \subseteq \mathcal{P}(V)$ and Player $0$ wins a play $p$ iff $$\inf(p) \in \mathcal{F}_0.$$ Muller games closed under superset are Muller games such that $\mathcal{F}_0$ is closed under supersets: $$ X \in \mathcal{F}_0, X \subseteq Y \Rightarrow Y \in \mathcal{F}_0.$$ The taks now is to prove that GB-games and Muller games closed under superset are the same winning conditions. One direction is easy. Just show that $\mathcal{F}_0 := \{X \subset V \mid \forall 1 \leq i \leq k, X \cap B_i \neq \emptyset\}$ is closed under supersets. The other direction is a little bit more tricky: Show that for each muller condition closed under supersets there is a GB condition with the same $\inf$-set for each game. E.g. : $$ V=\{1,2,3,4\} ~~ \mathcal{F}_0=\{\{1,2\},\{3,4\},\{1,2,3,4\}\}$$ The muller condition is closed under supersets. Now the GB-Condition $$\{\{1,3\},\{2,4\}, \dots$$ Here is where I'm stuck. How do I prevent $\inf(p)=\{1,4\}$ or $\inf(p)=\{2,3\}$? There is no construction for ""forbidden combinations"". Any ideas?",,"['elementary-set-theory', 'logic', 'game-theory', 'infinity']"
37,Question about cumulative hierarchy,Question about cumulative hierarchy,,"In the following let $\mathbf{V} = \bigcup_{\alpha \in \mathbf{ON}} V_\alpha$ denote the cumulative hierarchy. Let $\{\varphi_0, \dots, \varphi_n, \dots \}$ denote a list of all $ZF$ axioms. I am reading the following sentence: ""Given $n \in \omega$, the symbols ""$\mathbf{V} \models \{\varphi_0, \dots, \varphi_n\}$"" and ""$\varphi_0 \land \dots \land \varphi_n$"" stand for exactly the same thing."" (Just/Weese, p 192) I don't understand how this is true. The first expression says that $\varphi_i$ are all true in $\mathbf{V}$ given any valuation. The second expression seems to be a formula that may or may not be true but there is nothing saying that it is true in $\mathbf{V}$. Thank you for shedding light into my confusion.","In the following let $\mathbf{V} = \bigcup_{\alpha \in \mathbf{ON}} V_\alpha$ denote the cumulative hierarchy. Let $\{\varphi_0, \dots, \varphi_n, \dots \}$ denote a list of all $ZF$ axioms. I am reading the following sentence: ""Given $n \in \omega$, the symbols ""$\mathbf{V} \models \{\varphi_0, \dots, \varphi_n\}$"" and ""$\varphi_0 \land \dots \land \varphi_n$"" stand for exactly the same thing."" (Just/Weese, p 192) I don't understand how this is true. The first expression says that $\varphi_i$ are all true in $\mathbf{V}$ given any valuation. The second expression seems to be a formula that may or may not be true but there is nothing saying that it is true in $\mathbf{V}$. Thank you for shedding light into my confusion.",,"['elementary-set-theory', 'model-theory']"
38,$\mathbb{N}$ is the smallest infinite set,is the smallest infinite set,\mathbb{N},"We work in $\mathsf{ZF}$ . Given sets $A, B \neq \emptyset$ , we define the following relations: $A <_{\text{inj}} B$ $\Leftrightarrow$ $\exists f: A \hookrightarrow B$ : $f$ is injective and $\not\exists g: B \hookrightarrow A$ : $g$ is injective $A <_{\text{surj}} B$ $\Leftrightarrow$ $\exists f: B \twoheadrightarrow A$ : $f$ is surjective and $\not\exists g: A \twoheadrightarrow B$ : $g$ is surjective We say that a set $C \neq \emptyset$ is finite if there exists $n \in \mathbb{N}$ and a bijection $C \leftrightarrow \{1, \ldots, n\}$ . Say that a set $X \neq \emptyset$ is injectively small if we have $X <_{\text{inj}} \mathbb{N}$ . Say that a set $X \neq \emptyset$ is surjectively small if we have $X <_{\text{surj}} \mathbb{N}$ . Can we show that there exists no infinite injectively small set $X \neq \emptyset$ ? Can we show that there exists no infinite surjectively small set $X \neq \emptyset$ ? My attempt at a proof that there exists no infinite injectively small set $X \neq \emptyset$ : Assume that $X \neq \emptyset$ is infinite and injectively small, hence there is an injection $f: X \hookrightarrow \mathbb{N}$ . Since $X$ is nonempty, let $n_1 = \operatorname{min} f(X)$ and $x_1 \in X$ with $f(x_1) = n_1$ . Since $X$ is not in bijection with $\{1\}$ , we have $f(X) \setminus \{n_1\} \neq \emptyset$ . Let $n_2 = \operatorname{min} f(X) \setminus \{n_1\}$ and $x_2 \in X$ with $f(x_2) = n_2$ . Since $X$ is not in bijection with $\{1, 2\}$ , we have $f(X) \setminus \{n_1, n_2\} \neq \emptyset$ . Let $n_3 = \operatorname{min} f(X) \setminus \{n_1, n_2\}$ and $x_3 \in X$ with $f(x_3) = n_3$ . Continue inductively, obtaining a sequence $(x_k)_{k \in \mathbb{N}}$ with distinct terms. Now, define $g: \mathbb{N} \hookrightarrow X, g(k) = x_k$ . Since the terms of $(x_k)_{k \in \mathbb{N}}$ are distinct, $g$ is injective (in fact bijective), a contradiction. My attempt at a proof that there exists no infinite surjectively small set $X \neq \emptyset$ : Assume that $X \neq \emptyset$ is infinite and surjectively small, hence there is a surjection $f: \mathbb{N} \twoheadrightarrow X$ . For each $x \in X$ , set $n_x = \operatorname{min} f^{-1}(\{x\})$ . Now, the mapping $x \mapsto n_x$ is an injection $X \hookrightarrow \mathbb{N}$ , hence by an analogous argument there is a bijection $X \leftrightarrow \mathbb{N}$ , contradicting our assumption. Are these proofs correct? In particular, am I correct in that they do not depend on the axiom of choice in any way? Can we show that there is no infinite surjectively small set by directly exhibiting a surjection in the other direction and arriving at a contradiction?","We work in . Given sets , we define the following relations: : is injective and : is injective : is surjective and : is surjective We say that a set is finite if there exists and a bijection . Say that a set is injectively small if we have . Say that a set is surjectively small if we have . Can we show that there exists no infinite injectively small set ? Can we show that there exists no infinite surjectively small set ? My attempt at a proof that there exists no infinite injectively small set : Assume that is infinite and injectively small, hence there is an injection . Since is nonempty, let and with . Since is not in bijection with , we have . Let and with . Since is not in bijection with , we have . Let and with . Continue inductively, obtaining a sequence with distinct terms. Now, define . Since the terms of are distinct, is injective (in fact bijective), a contradiction. My attempt at a proof that there exists no infinite surjectively small set : Assume that is infinite and surjectively small, hence there is a surjection . For each , set . Now, the mapping is an injection , hence by an analogous argument there is a bijection , contradicting our assumption. Are these proofs correct? In particular, am I correct in that they do not depend on the axiom of choice in any way? Can we show that there is no infinite surjectively small set by directly exhibiting a surjection in the other direction and arriving at a contradiction?","\mathsf{ZF} A, B \neq \emptyset A <_{\text{inj}} B \Leftrightarrow \exists f: A \hookrightarrow B f \not\exists g: B \hookrightarrow A g A <_{\text{surj}} B \Leftrightarrow \exists f: B \twoheadrightarrow A f \not\exists g: A \twoheadrightarrow B g C \neq \emptyset n \in \mathbb{N} C \leftrightarrow \{1, \ldots, n\} X \neq \emptyset X <_{\text{inj}} \mathbb{N} X \neq \emptyset X <_{\text{surj}} \mathbb{N} X \neq \emptyset X \neq \emptyset X \neq \emptyset X \neq \emptyset f: X \hookrightarrow \mathbb{N} X n_1 = \operatorname{min} f(X) x_1 \in X f(x_1) = n_1 X \{1\} f(X) \setminus \{n_1\} \neq \emptyset n_2 = \operatorname{min} f(X) \setminus \{n_1\} x_2 \in X f(x_2) = n_2 X \{1, 2\} f(X) \setminus \{n_1, n_2\} \neq \emptyset n_3 = \operatorname{min} f(X) \setminus \{n_1, n_2\} x_3 \in X f(x_3) = n_3 (x_k)_{k \in \mathbb{N}} g: \mathbb{N} \hookrightarrow X, g(k) = x_k (x_k)_{k \in \mathbb{N}} g X \neq \emptyset X \neq \emptyset f: \mathbb{N} \twoheadrightarrow X x \in X n_x = \operatorname{min} f^{-1}(\{x\}) x \mapsto n_x X \hookrightarrow \mathbb{N} X \leftrightarrow \mathbb{N}","['elementary-set-theory', 'solution-verification', 'set-theory']"
39,"In the set $P$ of all circles over $\mathbb{R}^2$, ordered by $(P, \subseteq)$, do two circles always have an infimum?","In the set  of all circles over , ordered by , do two circles always have an infimum?","P \mathbb{R}^2 (P, \subseteq)","I was aked to determine whether the following statement is true or false. Let $$\mathcal{D} \left( (x_0, y_0), r \right) = \left\{ (x, y) \in \mathbb{R}^2 : (x - x_0)^2 + (y - y_0)^2 \leq r^2 \right\} $$ Let $P = \left\{ \emptyset \right\} \cup \left\{ \mathcal{D}\left( (x_0,y_0), r \right) : x_0, y_0 \in \mathbb{R}, r > 0  \right\} $ . In the poset $(P, \subseteq ) $ , there is always $\text{inf}\left\{ D_1, D_2\right\} $ , for any $D_1, D_2 \in P$ . I think I came to the right conclusion but I'm thinking one could be more rigorous than I was. Here is what I attempted. Consider that $\mathcal{D}\left( (x_0, y_0), r \right)$ is the set of points within a circumference with center $(x_0, y_0)$ and radius $r$ . So we can think of $P$ as the set of all (filled) circles, including $\emptyset$ . Two circles may be related in one of the ways schematized by the following Venn diagrams: Formally, for $D_1, D_2 \in P$ , the image depicts the following exhaustive and mutually exclusive cases: $D_1 \subseteq  D_2$ $ D_1 \cap D_2 \neq \emptyset$ but $D_1 \not\subseteq D_2$ $D_1 \cap D_2 = \emptyset$ . (1) If $D_1 \subseteq  D_2$ then evidently $\text{inf}\left\{ D_1, D_2 \right\} = D_1$ , because $D_1$ would be the greatest circle that is a subset of itself and of $D_2$ . (2) If $D_1 \cap D_2 = \emptyset$ , evidently $\text{inf}\left\{ D_1, D_2 \right\} = \emptyset$ ,. (3) The case $D_1 \cap D_2 \neq \emptyset$ with $D_1 \not\subseteq D_2$ is the one that ruins the beauty. Let $D_3$ a circle s.t. $D_3 \subseteq D_1 \cap D_3$ ---this is, $D_3$ is an arbitrary, non-empty lower bound of $\left\{ D_1, D_2 \right\} $ . Observe that we can choose any arbitrary point $(z_1, z_2) \not\in D_3$ that lies in $D_1 \cap D_2$ , and make $D_z = \mathcal{D}((z_1, z_2), \epsilon)$ , with $\epsilon > 0$ a quantity sufficiently small to guarantee $D_z \cap D_3 = \emptyset$ and $D_z \in D_1 \cap D_2$ . It is evident that $D_z \subseteq D_1$ and $D_z \subseteq D_2$ , so $D_z$ is a lower bound of $\left\{ D_1, D_2 \right\} $ ; but since $D_z \not\subseteq D_3$ we cannot say $D_3$ is the greatest lower bound. The argument above holds for any $D_3 \subseteq D_1 \cap D_2$ . In general terms, we have shown that, in the case $D_1 \cap D_2 \neq \emptyset, D_1 \not\subseteq D_2$ , for any lower bound $D_3$ of $\left\{ D_1, D_2 \right\} $ , we can find a lower bound $D_z$ that is not a subset of $D_3$ . Therefore no greater lower bound exists and there is no infimum. Two questions arise. The most fundamental: Is this proof correct? But also, was there a simpler way to tackle the problem?","I was aked to determine whether the following statement is true or false. Let Let . In the poset , there is always , for any . I think I came to the right conclusion but I'm thinking one could be more rigorous than I was. Here is what I attempted. Consider that is the set of points within a circumference with center and radius . So we can think of as the set of all (filled) circles, including . Two circles may be related in one of the ways schematized by the following Venn diagrams: Formally, for , the image depicts the following exhaustive and mutually exclusive cases: but . (1) If then evidently , because would be the greatest circle that is a subset of itself and of . (2) If , evidently ,. (3) The case with is the one that ruins the beauty. Let a circle s.t. ---this is, is an arbitrary, non-empty lower bound of . Observe that we can choose any arbitrary point that lies in , and make , with a quantity sufficiently small to guarantee and . It is evident that and , so is a lower bound of ; but since we cannot say is the greatest lower bound. The argument above holds for any . In general terms, we have shown that, in the case , for any lower bound of , we can find a lower bound that is not a subset of . Therefore no greater lower bound exists and there is no infimum. Two questions arise. The most fundamental: Is this proof correct? But also, was there a simpler way to tackle the problem?","\mathcal{D} \left( (x_0, y_0), r \right) = \left\{ (x, y) \in \mathbb{R}^2 : (x - x_0)^2 + (y - y_0)^2 \leq r^2 \right\}  P = \left\{ \emptyset \right\} \cup \left\{ \mathcal{D}\left( (x_0,y_0), r \right) : x_0, y_0 \in \mathbb{R}, r > 0  \right\}  (P, \subseteq )  \text{inf}\left\{ D_1, D_2\right\}  D_1, D_2 \in P \mathcal{D}\left( (x_0, y_0), r \right) (x_0, y_0) r P \emptyset D_1, D_2 \in P D_1 \subseteq  D_2  D_1 \cap D_2 \neq \emptyset D_1 \not\subseteq D_2 D_1 \cap D_2 = \emptyset D_1 \subseteq  D_2 \text{inf}\left\{ D_1, D_2 \right\} =
D_1 D_1 D_2 D_1 \cap D_2 = \emptyset \text{inf}\left\{ D_1,
D_2 \right\} = \emptyset D_1 \cap D_2 \neq \emptyset D_1 \not\subseteq D_2 D_3 D_3 \subseteq D_1
\cap D_3 D_3 \left\{
D_1, D_2 \right\}  (z_1, z_2) \not\in D_3 D_1 \cap D_2 D_z = \mathcal{D}((z_1, z_2), \epsilon) \epsilon > 0 D_z \cap D_3 =
\emptyset D_z \in D_1 \cap D_2 D_z \subseteq D_1 D_z \subseteq D_2 D_z \left\{ D_1, D_2 \right\}
 D_z \not\subseteq D_3 D_3 D_3 \subseteq D_1 \cap D_2 D_1 \cap D_2 \neq \emptyset, D_1 \not\subseteq D_2 D_3 \left\{ D_1, D_2 \right\}  D_z D_3","['elementary-set-theory', 'logic']"
40,Difficulty in reading Introduction to Set Theory by Hrbacek,Difficulty in reading Introduction to Set Theory by Hrbacek,,"Background: I was reading Karel Hrbacek's Introduction to Set Theory and need help with understanding this snippet: What I don't understand/need to clarify: In order to be allowed to use the notion $\{x| P(x)\}$ I need to prove that: $\exists A:\forall x:\big(P(x)\implies x\in A\big)\implies \{x\in A|P(x)\}\textit{ exists and it's unique}$ , right? I've noticed that sometimes it's not mandatory to prove the existence and uniqueness of an object to define it. For instance: When defined what $A\subseteq B$ mean for two given sets $A$ and $B$ . So, when is it mandatory to prove the existence and uniqueness of an object in order to define it? Update: Why is it even mandatory to prove the existence and uniqueness of an object to define it?","Background: I was reading Karel Hrbacek's Introduction to Set Theory and need help with understanding this snippet: What I don't understand/need to clarify: In order to be allowed to use the notion I need to prove that: , right? I've noticed that sometimes it's not mandatory to prove the existence and uniqueness of an object to define it. For instance: When defined what mean for two given sets and . So, when is it mandatory to prove the existence and uniqueness of an object in order to define it? Update: Why is it even mandatory to prove the existence and uniqueness of an object to define it?",\{x| P(x)\} \exists A:\forall x:\big(P(x)\implies x\in A\big)\implies \{x\in A|P(x)\}\textit{ exists and it's unique} A\subseteq B A B,[]
41,"If sets $A, B$ are countable infinite then also $A \cup B$",If sets  are countable infinite then also,"A, B A \cup B","This is my first „own“ proof I created. Is it ok? Are there things fishy? I‘d appreciate if someone could go thru my proof step by step and point out mistakes if there are any. $\Bbb N^{2n}$ means the even natural numbers and $\Bbb N^{2n+1}$ means the odd natural numbers. Theorem: If sets $A, B$ are countable infinite then also $A \cup B$ . Proof: We assume that sets $A,B$ are countable infinite, i.e. $|A| = |\Bbb N| = |B|$ , i.e. $f: A \to \Bbb N$ and $g: B \to \Bbb N$ are bijective. We also know that $|\Bbb N^{2n}| = |\Bbb N| = |\Bbb N^{2n+1}|$ . It follows $|A| = |\Bbb N^{2n}|$ and $ |B| = |\Bbb N^{2n+1}|$ , i.e. $f‘: A \to \Bbb N^{2n}$ and $g‘: B \to \Bbb N^{2n+1}$ are bijective. Now we assume a function $h: A \cup B \to \Bbb N$ thru the rule: if $x \in A$ then $f‘(x)$ , if $x \in B-A$ then $g‘(x)$ . The function $h$ is bijective. First it is injective because every preimage $x \in A \cup B$ has exactly one image due to the distribution of $f‘(x)$ and $g‘(x)$ . It is also surjective because every image in $\Bbb N$ has exactly one preimage due to $f‘$ , $g‘$ . But since $h$ is bijective it follows by definition $|A \cup B| = |\Bbb N|$ and that‘s by definition a case of countable infinity for $A \cup B$ .","This is my first „own“ proof I created. Is it ok? Are there things fishy? I‘d appreciate if someone could go thru my proof step by step and point out mistakes if there are any. means the even natural numbers and means the odd natural numbers. Theorem: If sets are countable infinite then also . Proof: We assume that sets are countable infinite, i.e. , i.e. and are bijective. We also know that . It follows and , i.e. and are bijective. Now we assume a function thru the rule: if then , if then . The function is bijective. First it is injective because every preimage has exactly one image due to the distribution of and . It is also surjective because every image in has exactly one preimage due to , . But since is bijective it follows by definition and that‘s by definition a case of countable infinity for .","\Bbb N^{2n} \Bbb N^{2n+1} A, B A \cup B A,B |A| = |\Bbb N| = |B| f: A \to \Bbb N g: B \to \Bbb N |\Bbb N^{2n}| = |\Bbb N| = |\Bbb N^{2n+1}| |A| = |\Bbb N^{2n}|  |B| = |\Bbb N^{2n+1}| f‘: A \to \Bbb N^{2n} g‘: B \to \Bbb N^{2n+1} h: A \cup B \to \Bbb N x \in A f‘(x) x \in B-A g‘(x) h x \in A \cup B f‘(x) g‘(x) \Bbb N f‘ g‘ h |A \cup B| = |\Bbb N| A \cup B",[]
42,Bijection between the power set of $\mathbb R$ and $\mathbb R^{\mathbb R}$,Bijection between the power set of  and,\mathbb R \mathbb R^{\mathbb R},"I want to prove that the power set of $\mathbb R$ , which can be naturally identified as $\{0,1\}^{\mathbb R}$ , is bijective to the set $\mathbb R^{\mathbb R}$ . Can the following attempt be altered to get a bijection without invoking Cantor-Schröder-Bernstein ? Here is my attempt: Notation. For any $f:\mathbb R\to\mathbb R$ , let $\operatorname{graph}f\overset{\text{Def.}}=\{(x, f(x))\in\mathbb R^2: x\in\mathbb R\}$ . Let $g:\mathbb R\to\mathbb R^2$ be a bijection. ${}^1$ ${}^2$ ${}^3$ Now I define the operator \begin{split}B:\mathbb R^{\mathbb R}&\to\{0,1\}^{\mathbb R}, \\ f&\mapsto B(f),\end{split} where \begin{split} B(f): \mathbb R&\to\{0,1\}, \\  r&\mapsto \begin{cases} 1&\text{if } g(r)\in\operatorname{graph} f\\ 0&\text{if } g(r)\not\in\operatorname{graph} f \end{cases} \end{split} Now, $B$ is injective, because if $f_1, f_2:\mathbb R\to\mathbb R$ satisfy $B(f_1)=B(f_2)$ , then, since $g$ is a bijection, for any $(y^1, y^2)\in\mathbb R$ , we have $(y^1,y^2)\in\operatorname{graph} f_1\iff (y^1, y^2)\in\operatorname{graph} f_2$ , i.e. $f_1(y^1)=y^2\iff f_2(y^1)=y^2$ for any $(y^1,y^2)\in\mathbb R^2$ , which means that $f_1=f_2$ . However, $B$ is sadly not surjective. Since the inclusion $\{0,1\}^{\mathbb R}\to\mathbb R^{\mathbb R}$ is trivially injective, Cantor-Schröder-Bernstein implies that the two sets are bijective.","I want to prove that the power set of , which can be naturally identified as , is bijective to the set . Can the following attempt be altered to get a bijection without invoking Cantor-Schröder-Bernstein ? Here is my attempt: Notation. For any , let . Let be a bijection. Now I define the operator where Now, is injective, because if satisfy , then, since is a bijection, for any , we have , i.e. for any , which means that . However, is sadly not surjective. Since the inclusion is trivially injective, Cantor-Schröder-Bernstein implies that the two sets are bijective.","\mathbb R \{0,1\}^{\mathbb R} \mathbb R^{\mathbb R} f:\mathbb R\to\mathbb R \operatorname{graph}f\overset{\text{Def.}}=\{(x, f(x))\in\mathbb R^2: x\in\mathbb R\} g:\mathbb R\to\mathbb R^2 {}^1 {}^2 {}^3 \begin{split}B:\mathbb R^{\mathbb R}&\to\{0,1\}^{\mathbb R}, \\ f&\mapsto B(f),\end{split} \begin{split} B(f): \mathbb R&\to\{0,1\}, \\ 
r&\mapsto
\begin{cases}
1&\text{if } g(r)\in\operatorname{graph} f\\
0&\text{if } g(r)\not\in\operatorname{graph} f
\end{cases}
\end{split} B f_1, f_2:\mathbb R\to\mathbb R B(f_1)=B(f_2) g (y^1, y^2)\in\mathbb R (y^1,y^2)\in\operatorname{graph} f_1\iff (y^1, y^2)\in\operatorname{graph} f_2 f_1(y^1)=y^2\iff f_2(y^1)=y^2 (y^1,y^2)\in\mathbb R^2 f_1=f_2 B \{0,1\}^{\mathbb R}\to\mathbb R^{\mathbb R}","['elementary-set-theory', 'cardinals']"
43,Why we don't use the universal quantifier in the usual definition of the cartesian product?,Why we don't use the universal quantifier in the usual definition of the cartesian product?,,"I see everywhere that the usual definition of a cartesian product between two set is : $$\mathrm{A} \times \mathrm{B} = \{(a,b): a \in \mathrm{A}, b \in \mathrm{B} \}$$ I wondered why we don't add a universal quantifier like so : $$\mathrm{A} \times \mathrm{B} = \{(a,b): \forall a \in \mathrm{A}, \forall b \in \mathrm{B} \}$$ Asking myself this question led me to the following reflection : I know that a set-builder notation is of the form : $$   \{x: \Phi (x)\}$$ where : $\Phi (x)$ is a logical predicate such that all values of x for which the predicate holds belongs to the set being defined I do think $x$ is what we call ""an unbound variable"" in logic Hence $\{x: \Phi (x)\}$ can be interpreted as ""all mathematical objects for which the predicate holds belongs to the set being defined"" Therefore, the notation : $$\mathrm{A} \times \mathrm{B} = \{(a,b): a \in \mathrm{A}, b \in \mathrm{B} \}$$ can be interpreted as : ""all ordered pair for which it's first element is in $\mathrm{A}$ and it's second is in $\mathrm{B}$ belongs to the cartesian product of those sets (which is a set)"". So in the notation where I add the universal quantifier, I made a grammatical mistake, because ""for all"" is not to be added with the usage of a free variable), my question was why (when I didn't know the existence of ""unbound variable"") we don't have to put a universal quantifier this way : $$\mathrm{A} \times \mathrm{B} = \{\forall(a,b): a \in \mathrm{A}, b \in \mathrm{B} \}$$ After all, a quantifier ("" $\exists$ "") is used in the correct definition, so why can't we use an other? I'm pretty sure it is related to bond and free variables : if one choose the last definition I wrote, one makes the variable $(a,b)$ bounded, if one choose the usual definition, one use a free variable, therefore if the last definition I wrote is wrong, it might be because we can't use bounded variable in the set builder notation (outside the predicate), isn't it? If it the case, why? Does the formula "" $\mathrm{A} \times \mathrm{B} = \{(a,b): a \in \mathrm{A}, b \in \mathrm{B} \}$ "" belongs to first-order logic or Higher-order logic (I'm a beginner in formal logic)? Thank you","I see everywhere that the usual definition of a cartesian product between two set is : I wondered why we don't add a universal quantifier like so : Asking myself this question led me to the following reflection : I know that a set-builder notation is of the form : where : is a logical predicate such that all values of x for which the predicate holds belongs to the set being defined I do think is what we call ""an unbound variable"" in logic Hence can be interpreted as ""all mathematical objects for which the predicate holds belongs to the set being defined"" Therefore, the notation : can be interpreted as : ""all ordered pair for which it's first element is in and it's second is in belongs to the cartesian product of those sets (which is a set)"". So in the notation where I add the universal quantifier, I made a grammatical mistake, because ""for all"" is not to be added with the usage of a free variable), my question was why (when I didn't know the existence of ""unbound variable"") we don't have to put a universal quantifier this way : After all, a quantifier ("" "") is used in the correct definition, so why can't we use an other? I'm pretty sure it is related to bond and free variables : if one choose the last definition I wrote, one makes the variable bounded, if one choose the usual definition, one use a free variable, therefore if the last definition I wrote is wrong, it might be because we can't use bounded variable in the set builder notation (outside the predicate), isn't it? If it the case, why? Does the formula "" "" belongs to first-order logic or Higher-order logic (I'm a beginner in formal logic)? Thank you","\mathrm{A} \times \mathrm{B} = \{(a,b): a \in \mathrm{A}, b \in \mathrm{B} \} \mathrm{A} \times \mathrm{B} = \{(a,b): \forall a \in \mathrm{A}, \forall b \in \mathrm{B} \}    \{x: \Phi (x)\} \Phi (x) x \{x: \Phi (x)\} \mathrm{A} \times \mathrm{B} = \{(a,b): a \in \mathrm{A}, b \in \mathrm{B} \} \mathrm{A} \mathrm{B} \mathrm{A} \times \mathrm{B} = \{\forall(a,b): a \in \mathrm{A}, b \in \mathrm{B} \} \exists (a,b) \mathrm{A} \times \mathrm{B} = \{(a,b): a \in \mathrm{A}, b \in \mathrm{B} \}","['elementary-set-theory', 'logic']"
44,Understand if my proof is fallacious.,Understand if my proof is fallacious.,,"I would like to know if my attempted solution to problem 4 of chapter 3.5 from Velleman's book How to Prove It is valid. My solution is different from the one suggested by the book and I want to know if my reasoning is fallacious to avoid repeating it in the future, if that is the case. The problem is as follows: Suppose $A\cap C \subseteq B \cap C$ and $A \cup C \subseteq B \cup C$ . Prove that $A\subseteq B$ . This is my proof attempt: Suppose $A\cap C \subseteq B \cap C$ and $A \cup C \subseteq B \cup C$ . Let $x$ be arbitrary and suppose $x \in A$ . Since $x \in A$ it follows that $x \in A \cup C$ . But we know that $ A \cup C \subseteq B \cup C$ , so $x \in B$ or $x \in C$ . We will consider these cases separately. Case $x \in B$ : then no further reasoning is needed. Case $x \in C$ : then $x \in A \cap C$ , so since $A\cap C \subseteq B \cap C$ it follows that $x \in B$ Thus $x \in B$ . Since $x$ was an arbitrary member of $A$ we can conclude that $A \subseteq B$ . $\blacksquare$ And this is the book's solution: Suppose $x \in A$ . We now consider two cases: Case $x\in C$ . Then $x \in A \cap C$ , so since $A\cap B \subseteq B \cap C$ , $x \in B \cap C$ and therefore $x \in B$ . Case $x \notin C$ . Since $x \in A$ , $x \in A \cup C$ , so since $A\cap B \subseteq B \cap C$ , $x \in B \cup C$ . But $x \notin C$ , so we must have $x \in B$ . Thus, $x \in B$ , and since $x$ was arbitrary, $A \subseteq B$ . $\blacksquare$ So, the book's proof uses a division into cases that are not suggested by any of the assumptions and that I did not think of. Is there any problem with my proof?","I would like to know if my attempted solution to problem 4 of chapter 3.5 from Velleman's book How to Prove It is valid. My solution is different from the one suggested by the book and I want to know if my reasoning is fallacious to avoid repeating it in the future, if that is the case. The problem is as follows: Suppose and . Prove that . This is my proof attempt: Suppose and . Let be arbitrary and suppose . Since it follows that . But we know that , so or . We will consider these cases separately. Case : then no further reasoning is needed. Case : then , so since it follows that Thus . Since was an arbitrary member of we can conclude that . And this is the book's solution: Suppose . We now consider two cases: Case . Then , so since , and therefore . Case . Since , , so since , . But , so we must have . Thus, , and since was arbitrary, . So, the book's proof uses a division into cases that are not suggested by any of the assumptions and that I did not think of. Is there any problem with my proof?",A\cap C \subseteq B \cap C A \cup C \subseteq B \cup C A\subseteq B A\cap C \subseteq B \cap C A \cup C \subseteq B \cup C x x \in A x \in A x \in A \cup C  A \cup C \subseteq B \cup C x \in B x \in C x \in B x \in C x \in A \cap C A\cap C \subseteq B \cap C x \in B x \in B x A A \subseteq B \blacksquare x \in A x\in C x \in A \cap C A\cap B \subseteq B \cap C x \in B \cap C x \in B x \notin C x \in A x \in A \cup C A\cap B \subseteq B \cap C x \in B \cup C x \notin C x \in B x \in B x A \subseteq B \blacksquare,"['elementary-set-theory', 'solution-verification', 'alternative-proof']"
45,"$(0,1)$ without union of intervals centered at rational numbers",without union of intervals centered at rational numbers,"(0,1)","Let $(a_n)$ be a sequence of all rational numbers in $(0,1)$ and let $$\mathscr{I}_t:=\bigcup_i\left(a_i-\frac{t}{2^{i+1}},a_i+\frac{t}{2^{i+1}}\right)\bigcap\,(0,1)\text{.}$$ Then $\lambda(\mathscr{I}_t)\leq t$ because $\displaystyle\sum_n\frac{t}{2^n}=t$ where $\lambda$ is the Lebesgue measure. That means $\mathscr{I}_t\subsetneq(0,1)$ for $t<1$ . I'm trying to understand what $(0,1)\setminus\mathscr{I}_t$ looks like and in which way it depends on the enumeration of the rationals. My thoughts: Obviously it would only contain irrational numbers. Any $x\in(0,1)\setminus\mathscr{I}_t$ has to satisfy $\mid x-a_i\mid\geq\frac{t}{2^{i+1}}\forall i$ . But I'm trying to build an intuitive understanding and don't know how such an $x$ would look like.",Let be a sequence of all rational numbers in and let Then because where is the Lebesgue measure. That means for . I'm trying to understand what looks like and in which way it depends on the enumeration of the rationals. My thoughts: Obviously it would only contain irrational numbers. Any has to satisfy . But I'm trying to build an intuitive understanding and don't know how such an would look like.,"(a_n) (0,1) \mathscr{I}_t:=\bigcup_i\left(a_i-\frac{t}{2^{i+1}},a_i+\frac{t}{2^{i+1}}\right)\bigcap\,(0,1)\text{.} \lambda(\mathscr{I}_t)\leq t \displaystyle\sum_n\frac{t}{2^n}=t \lambda \mathscr{I}_t\subsetneq(0,1) t<1 (0,1)\setminus\mathscr{I}_t x\in(0,1)\setminus\mathscr{I}_t \mid x-a_i\mid\geq\frac{t}{2^{i+1}}\forall i x","['elementary-set-theory', 'lebesgue-measure']"
46,Terence Tao Analysis 1 Excercise 8.3.2 Proof Verification,Terence Tao Analysis 1 Excercise 8.3.2 Proof Verification,,"I am working on excercise 8.3.2 in Tao Analysis 1. This is my answer to the excercise. The question statement is: Let $A$ , $B$ , $C$ be sets such that $A \subseteq B \subseteq C$ , and suppose that there is an injection $f : C → A$ . Define the sets $D_0$ , $D_1$ , $D_2$ ,... recursively by setting $D_0 := B\setminus A$ , and then $D_{n+1} := f(D_n)$ for all natural numbers $n$ . Prove that the sets $D_0$ , $D_1$ ,... are all disjoint from each other (i.e., $D_n ∩ D_m = ∅$ whenever $n \neq m$ ). Also show that if $g : A → B$ is the function defined by setting $g(x) := f^{−1}(x)$ when $x \in \cup_{n=0}^{\infty}D_n$ , and $g(x) := x$ when $x \not \in \cup_{n=0}^{\infty}D_n$ , then $g$ does indeed map $A$ to $B$ and is a bijection between the two. In particular, $A$ and $B$ have the same cardinality. My work: The first step is to prove all the sets are disjoint from each other. Assume there are two sets $D_{n_0}$ and $D_{m_0}$ are not disjoint. The aim is to prove this contradicts the injectivity of $f$ . Assume without loss of generality that $n_0 > m_0$ . Define the two sequences $\{n_{k}:k \in \mathbb{Z}^{+}$ } and $\{m_{k}:k \in \mathbb{Z}^{+}$ } as follows: $n_k = n-k$ , $m_k = m-k$ . Consider $D_{n_1}$ and $D_{m_1}$ . If they are disjoint, stop here, if not, consider $D_{n_2}$ and $D_{m_2}$ and then $D_{n_3}$ and $D_{m_3}$ , etc... until for some $k$ , we find that $D_{n_k}$ and $D_{m_k}$ are disjoint (and such a k does exist, because if $D_{n_k}$ and $D_{m_k}$ are not disjoint for all $k<m$ , then for $k=m$ , we have the two sets $D_{n_m}$ and $D_0$ which are certainly disjoint). Now we have arrived at the following: For the $k$ that was found, $D_{n_{k-1}} \cap D_{m_{k-1}} \neq \phi$ and $D_{n_{k}} \cap D_{m_{k}} = \phi$ . So we have an $x$ such that $x \in D_{n_{k-1}}$ and $x \in D_{m_{k-1}}$ and so $x = f(y_1) = f(y_2)$ for some $y_1 \in D_{n_k}$ and $y_2 \in D_{m_k}$ . Since $D_{n_{k}} \cap D_{m_{k}} = \phi$ , $y_1 \neq y_2$ . We have found that $y_1 \neq y_2$ with $f(y_1) = f(y_2)$ , contradicting the injectivity of $f$ . So all the sets are piecewise disjoint. Next, given the function $g: A → B$ , need to prove $g$ is both injective and surjective. For injectivity, if $x_1 \neq x_2$ , then there are four possible cases: $\quad$ 1) $x_1 \in \cup_{n=0}^{\infty} D_n$ and $x_2 \in \cup_{n=0}^{\infty} D_n$ . $\quad$ 2) $x_1 \in \cup_{n=0}^{\infty} D_n$ and $x_2 \not \in \cup_{n=0}^{\infty} D_n$ $\quad$ 3) $x_1 \not \in \cup_{n=0}^{\infty} D_n$ and $x_2 \in \cup_{n=0}^{\infty} D_n$ $\quad$ 4) $x_1 \not \in \cup_{n=0}^{\infty} D_n$ and $x_2 \not \in \cup_{n=0}^{\infty} D_n$ In the first case, $g(x_1) = f^{-1}(x_1)$ and $g(x_2) = f^{-1}(x_2)$ . Clearly, $g(x_1) \neq g(x_2)$ or else the same element would map to two different images under $f$ . In the second case, $g(x_1) = f^{-1}(x_1) \in \cup_{n=0}^{\infty} D_n$ and $g(x_2) = x_2 \not \in \cup_{n=0}^{\infty} D_n$ so $g(x_1) \neq g(x_2)$ . The third case is similar to the second case, so its omitted. In the last case, $g(x_1) = x_1$ and $g(x_2) = x_2$ so $g(x_1) \neq g(x_2)$ . This proves that $x_1 \neq x_2 \implies g(x_1) \neq g(x_2)$ and $g$ is injective. To prove $g$ is surjective, let $x \in B$ . Then $x \in B \setminus A$ or $x \in A$ . If $x \in B \setminus A = D_0$ , then $\exists y_1 \in D_1$ such that $f(x)=y_1$ and $x = f^{-1}(y_1)$ so $x = g(y_1)$ . If $x \in A$ , then $x \in \cup_{n=0}^{\infty} D_n$ or $x \not \in \cup_{n=0}^{\infty} D_n$ . If $x \in \cup_{n=0}^{\infty} D_n$ , then $x \in D_n$ for some  and there exists a $y \in D_{n+1}$ such that $y = f(x)$ so that $x = f^{-1}(y)$ and $x = g(y)$ . If $x \not \in \cup_{n=0}^{\infty} D_n$ , then $g(x) = x$ . This shows that for every $x \in B$ , there exists a corresponding $y \in A$ such that $x = g(y)$ , and $g$ is surjective. Is this correct? Thanks for your time.","I am working on excercise 8.3.2 in Tao Analysis 1. This is my answer to the excercise. The question statement is: Let , , be sets such that , and suppose that there is an injection . Define the sets , , ,... recursively by setting , and then for all natural numbers . Prove that the sets , ,... are all disjoint from each other (i.e., whenever ). Also show that if is the function defined by setting when , and when , then does indeed map to and is a bijection between the two. In particular, and have the same cardinality. My work: The first step is to prove all the sets are disjoint from each other. Assume there are two sets and are not disjoint. The aim is to prove this contradicts the injectivity of . Assume without loss of generality that . Define the two sequences } and } as follows: , . Consider and . If they are disjoint, stop here, if not, consider and and then and , etc... until for some , we find that and are disjoint (and such a k does exist, because if and are not disjoint for all , then for , we have the two sets and which are certainly disjoint). Now we have arrived at the following: For the that was found, and . So we have an such that and and so for some and . Since , . We have found that with , contradicting the injectivity of . So all the sets are piecewise disjoint. Next, given the function , need to prove is both injective and surjective. For injectivity, if , then there are four possible cases: 1) and . 2) and 3) and 4) and In the first case, and . Clearly, or else the same element would map to two different images under . In the second case, and so . The third case is similar to the second case, so its omitted. In the last case, and so . This proves that and is injective. To prove is surjective, let . Then or . If , then such that and so . If , then or . If , then for some  and there exists a such that so that and . If , then . This shows that for every , there exists a corresponding such that , and is surjective. Is this correct? Thanks for your time.",A B C A \subseteq B \subseteq C f : C → A D_0 D_1 D_2 D_0 := B\setminus A D_{n+1} := f(D_n) n D_0 D_1 D_n ∩ D_m = ∅ n \neq m g : A → B g(x) := f^{−1}(x) x \in \cup_{n=0}^{\infty}D_n g(x) := x x \not \in \cup_{n=0}^{\infty}D_n g A B A B D_{n_0} D_{m_0} f n_0 > m_0 \{n_{k}:k \in \mathbb{Z}^{+} \{m_{k}:k \in \mathbb{Z}^{+} n_k = n-k m_k = m-k D_{n_1} D_{m_1} D_{n_2} D_{m_2} D_{n_3} D_{m_3} k D_{n_k} D_{m_k} D_{n_k} D_{m_k} k<m k=m D_{n_m} D_0 k D_{n_{k-1}} \cap D_{m_{k-1}} \neq \phi D_{n_{k}} \cap D_{m_{k}} = \phi x x \in D_{n_{k-1}} x \in D_{m_{k-1}} x = f(y_1) = f(y_2) y_1 \in D_{n_k} y_2 \in D_{m_k} D_{n_{k}} \cap D_{m_{k}} = \phi y_1 \neq y_2 y_1 \neq y_2 f(y_1) = f(y_2) f g: A → B g x_1 \neq x_2 \quad x_1 \in \cup_{n=0}^{\infty} D_n x_2 \in \cup_{n=0}^{\infty} D_n \quad x_1 \in \cup_{n=0}^{\infty} D_n x_2 \not \in \cup_{n=0}^{\infty} D_n \quad x_1 \not \in \cup_{n=0}^{\infty} D_n x_2 \in \cup_{n=0}^{\infty} D_n \quad x_1 \not \in \cup_{n=0}^{\infty} D_n x_2 \not \in \cup_{n=0}^{\infty} D_n g(x_1) = f^{-1}(x_1) g(x_2) = f^{-1}(x_2) g(x_1) \neq g(x_2) f g(x_1) = f^{-1}(x_1) \in \cup_{n=0}^{\infty} D_n g(x_2) = x_2 \not \in \cup_{n=0}^{\infty} D_n g(x_1) \neq g(x_2) g(x_1) = x_1 g(x_2) = x_2 g(x_1) \neq g(x_2) x_1 \neq x_2 \implies g(x_1) \neq g(x_2) g g x \in B x \in B \setminus A x \in A x \in B \setminus A = D_0 \exists y_1 \in D_1 f(x)=y_1 x = f^{-1}(y_1) x = g(y_1) x \in A x \in \cup_{n=0}^{\infty} D_n x \not \in \cup_{n=0}^{\infty} D_n x \in \cup_{n=0}^{\infty} D_n x \in D_n y \in D_{n+1} y = f(x) x = f^{-1}(y) x = g(y) x \not \in \cup_{n=0}^{\infty} D_n g(x) = x x \in B y \in A x = g(y) g,['elementary-set-theory']
47,How to Understand the Domain of a Function,How to Understand the Domain of a Function,,"Typically, a function $f: D \mapsto R$ is described as $$\forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right),$$ where $P$ is a predicate that specifies the relation between an input and the output, for instance, $y = 3x$ if $D \subseteq \mathbb{R}$ and $R \subseteq \mathbb{R}$ . However, this definition does not specify what happens outside $D$ . Should we explicitly specify that no element outside $D$ corresponds to an output under $f$ ? That is, should we use the following proposition $$\left(\forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right) \right) \wedge \left(\forall x \not\in {D}, \lnot \exists y, \left(x,y\right)\in f\right)$$ to describe $f$ ? My own understanding is as follows. In mathematical proofs, people are more concerned with the existence of such a function. That is, what happens outside $D$ does not matter. What matters is, such a function $f$ exists, so that the proof can move on. Specifically, when people talk about a function, they are saying: $$\exists f, \forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right).$$ And they can proceed with a particular example of such a function. In such a circumstance, the information of existing $f$ s outside $D$ is not of interest.","Typically, a function is described as where is a predicate that specifies the relation between an input and the output, for instance, if and . However, this definition does not specify what happens outside . Should we explicitly specify that no element outside corresponds to an output under ? That is, should we use the following proposition to describe ? My own understanding is as follows. In mathematical proofs, people are more concerned with the existence of such a function. That is, what happens outside does not matter. What matters is, such a function exists, so that the proof can move on. Specifically, when people talk about a function, they are saying: And they can proceed with a particular example of such a function. In such a circumstance, the information of existing s outside is not of interest.","f: D \mapsto R \forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right), P y = 3x D \subseteq \mathbb{R} R \subseteq \mathbb{R} D D f \left(\forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right) \right) \wedge \left(\forall x \not\in {D}, \lnot \exists y, \left(x,y\right)\in f\right) f D f \exists f, \forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right). f D",['elementary-set-theory']
48,"Cantor's diagonal argument, is this what it says?","Cantor's diagonal argument, is this what it says?",,"I've been reading about Cantor's diagonal argument all day, it's pretty confusing, but I think I get it now and I want to make sure asking you guys to confirm it. So, this is my understanding: Two sets, $A$ and $B$ have the same size if and only if there exists a one-to-one function that maps $A$ onto $B$ . A set $A$ is countably infinite if and only if there exists a one-to-one function that maps $A$ onto $ℕ$ . Now, if we want to show that the set $ℝ$ does not have the same cardinality as $ℕ$ and that ""it's larger"", from the above definition, we have to prove that there does not exists a one-to-one function that maps $ℕ$ onto $ℝ$ (or equivalently that $ℝ$ is not countably infinite). We proceed by contradiction: We suppose there exists a one-to-one function that maps $ℕ$ onto $ℝ$ . All these are real numbers $f(1), f(2), f(3), …, f(n), …$ we arrange these numbers in this way: \begin{matrix} f(1)=\:.\pmb{a_{11}}a_{12}a_{13}a_{14}…\\ f(2)=\:.a_{21}\pmb{a_{22}}a_{23}a_{24}…\\ f(3)=\:.a_{31}a_{32}\pmb{a_{33}}a_{34}…\\ …\\ f(n)=\:.a_{n1}a_{n2}a_{n3}a_{n4}…\\ ... \end{matrix} where all the $a_{ij}$ s represent random numbers from $0$ to $9$ (note the period at the beginning, it means that there should be another number there, like a normal decimal). Now if we find a number that is not in that list it means 2 things (which is actually the same thing): 1 - The function is not bijective (since at the beginning we supposed that there exists a one-to-one function that maps $ℕ$ onto $ℝ$ every element of $ℝ$ should have an element of $ℕ$ mapped to it, and we found an element of $ℝ$ that doesn't have one, since it's not in the list). 2 - That the set $ℝ$ is not countable, both because we can't ""list them"" (that list should represent every real number, but we missed one) and because that function is not bijective. To find this number that is not in the list we choose a number that should be in that list, let's say number $y$ , which since it has to to be real number it has the form of a decimal: $y=\:.y_1y_2y_3y_4…$ where again all the $y_i$ s are numbers between $0$ and $9$ , now to make different from all the other numbers, the trick is: Let the first digit $y_1$ be different from the first digit of the first number of that list, namely $a_{11}$ , the second digit $y_2$ be different from the second digit of the second number of that list, namely $a_{22}$ , $y_3$ different from $a_{33}$ and so on, so we will have a number that has at least 1 different digit from all those numbers and therefore it's none of those numbers, but at the same time since it's a decimal it should be in that list so we have a contradiction and we proved the 2 points, so in the end, even though $ℕ$ and $ℝ$ are both infinite they dont have the same number of elements, $ℝ$ has more since some elements ""stay free"" even after we paired every element of $ℕ$ with some element of $ℝ$ . Is this correct? I tried to explain it in the best way i can, i really hope it makes sense.. and please don't close the question, i know that there are a lot of questions about Cantor's diagonal argument but i can't be 100% sure i understand it if i don't write it down and someone confirms it. Thank you so much!","I've been reading about Cantor's diagonal argument all day, it's pretty confusing, but I think I get it now and I want to make sure asking you guys to confirm it. So, this is my understanding: Two sets, and have the same size if and only if there exists a one-to-one function that maps onto . A set is countably infinite if and only if there exists a one-to-one function that maps onto . Now, if we want to show that the set does not have the same cardinality as and that ""it's larger"", from the above definition, we have to prove that there does not exists a one-to-one function that maps onto (or equivalently that is not countably infinite). We proceed by contradiction: We suppose there exists a one-to-one function that maps onto . All these are real numbers we arrange these numbers in this way: where all the s represent random numbers from to (note the period at the beginning, it means that there should be another number there, like a normal decimal). Now if we find a number that is not in that list it means 2 things (which is actually the same thing): 1 - The function is not bijective (since at the beginning we supposed that there exists a one-to-one function that maps onto every element of should have an element of mapped to it, and we found an element of that doesn't have one, since it's not in the list). 2 - That the set is not countable, both because we can't ""list them"" (that list should represent every real number, but we missed one) and because that function is not bijective. To find this number that is not in the list we choose a number that should be in that list, let's say number , which since it has to to be real number it has the form of a decimal: where again all the s are numbers between and , now to make different from all the other numbers, the trick is: Let the first digit be different from the first digit of the first number of that list, namely , the second digit be different from the second digit of the second number of that list, namely , different from and so on, so we will have a number that has at least 1 different digit from all those numbers and therefore it's none of those numbers, but at the same time since it's a decimal it should be in that list so we have a contradiction and we proved the 2 points, so in the end, even though and are both infinite they dont have the same number of elements, has more since some elements ""stay free"" even after we paired every element of with some element of . Is this correct? I tried to explain it in the best way i can, i really hope it makes sense.. and please don't close the question, i know that there are a lot of questions about Cantor's diagonal argument but i can't be 100% sure i understand it if i don't write it down and someone confirms it. Thank you so much!","A B A B A A ℕ ℝ ℕ ℕ ℝ ℝ ℕ ℝ f(1), f(2), f(3), …, f(n), … \begin{matrix}
f(1)=\:.\pmb{a_{11}}a_{12}a_{13}a_{14}…\\
f(2)=\:.a_{21}\pmb{a_{22}}a_{23}a_{24}…\\
f(3)=\:.a_{31}a_{32}\pmb{a_{33}}a_{34}…\\
…\\
f(n)=\:.a_{n1}a_{n2}a_{n3}a_{n4}…\\
...
\end{matrix} a_{ij} 0 9 ℕ ℝ ℝ ℕ ℝ ℝ y y=\:.y_1y_2y_3y_4… y_i 0 9 y_1 a_{11} y_2 a_{22} y_3 a_{33} ℕ ℝ ℝ ℕ ℝ","['real-analysis', 'elementary-set-theory', 'real-numbers', 'infinity']"
49,Finding an uncountable chain of subsets the integers,Finding an uncountable chain of subsets the integers,,"How to find an uncountable subset of $P(\mathbb{N})$ such that every two elements of it can be compared. In fact, give an uncountable subset of $P(\mathbb{N})$ such that has totality property. We mean by $P(\mathbb{N})$, the powerset of natural numbers set $\mathbb{N}$.","How to find an uncountable subset of $P(\mathbb{N})$ such that every two elements of it can be compared. In fact, give an uncountable subset of $P(\mathbb{N})$ such that has totality property. We mean by $P(\mathbb{N})$, the powerset of natural numbers set $\mathbb{N}$.",,"['elementary-set-theory', 'order-theory']"
50,"For polyhedron $P$, vector $a$, scalar $b$, prove that $Q:=\{x\in P:a^tx\leq b\}$ is a polyhedron. Also, can $Q=P$?","For polyhedron , vector , scalar , prove that  is a polyhedron. Also, can ?",P a b Q:=\{x\in P:a^tx\leq b\} Q=P,"Let $P$ be a polyhedron in $\mathbb{R}^n, a\in\mathbb{R}^n$ a vector, and $b\in\mathbb{R}$ a scalar. Consider the set $Q=\{x\in P:a^tx\le b\}$ $a)$ Prove that $Q$ is a polyhedron $b)$ Is it always possible to choose $b$ in such way so that $Q=P$ ? Explain your answer Definition of polyhedron A polyhedron is the intersection of finitely many halfspaces: $$P=\{x∈\mathbb{R}^n,a^tx≤b\}$$ $a)$ Proof Let $Q:=\{x\in P:a_0^tx\le b\}$ Show that $Q$ is the intersection of finitely many half-spaces Since $P$ is a polyhedron we have $$\exists a_1^t\dots a_n^t\in\mathbb{R}^n,c_1\dots c_n\in\mathbb{R},s.t.$$ $$P=\{x\in\mathbb{R}^n:a_1^tx\le c_1\}\cap\dots\cap\{x\in\mathbb{R}^n:a_n^tx\le c_n\}$$ $$=\{x∈\mathbb{R}^n:a_1^tx≤c_1\wedge\dots\wedge a_n^tx\le c_n\}$$ Then $$Q=\{x\in P:a_0^tx\le b\}=\{x\in \mathbb{R}^n:x\in P\wedge a_0^tx\le b\}$$ $$=\{x\in \mathbb{R}^n:a_0^tx\le b\wedge a_1^tx≤c_1\wedge\dots\wedge a_n^tx\le c_n\}$$ $$=\{x\in \mathbb{R}^n:a_0^tx\le b\}\cap\{x\in\mathbb{R}^n:a_1^tx\le c_1\}\cap\dots\cap\{x\in\mathbb{R}^n:a_n^tx\le c_n\}$$ Which is the intersection of finite many half-spaces. $\tag*{$\square$}$ $b)$ No, consider case $n=1$ in $\mathbb{R}^2$ , if $P=\{x∈\mathbb{R}^2:x_1+x_2≤0\},Q=\{x\in P:x_1-x_2\le b\}$ Where $b\in\mathbb{R}$ Then $$Q=\{x∈\mathbb{R}^2:x_1-x_2\le b\wedge x_1+x_2≤0\}$$ For example $\left(\frac{b}{2},-\frac{b}{2}-1\right)$ is in $P$ but not in $Q$ . Since $\frac{b}{2}-\frac{b}{2}-1≤0$ that $\left(\frac{b}{2},-\frac{b}{2}-1\right)\in P$ But $\frac{b}{2}-\frac{b}{2}-1≤0\wedge\frac{b}{2}-(-\frac{b}{2}-1)\le b$ is false that $\left(\frac{b}{2},-\frac{b}{2}-1\right)\not\in Q$ for any real $b$ . That proves sometimes $$\forall b\in\mathbb{R},Q\neq P$$ $\tag*{$\square$}$ $\dots$ Is my proof correct ? Any suggestions would be appreciated. Also please tell me if there is a better method to prove it. Thanks for your help.","Let be a polyhedron in a vector, and a scalar. Consider the set Prove that is a polyhedron Is it always possible to choose in such way so that ? Explain your answer Definition of polyhedron A polyhedron is the intersection of finitely many halfspaces: Proof Let Show that is the intersection of finitely many half-spaces Since is a polyhedron we have Then Which is the intersection of finite many half-spaces. No, consider case in , if Where Then For example is in but not in . Since that But is false that for any real . That proves sometimes Is my proof correct ? Any suggestions would be appreciated. Also please tell me if there is a better method to prove it. Thanks for your help.","P \mathbb{R}^n, a\in\mathbb{R}^n b\in\mathbb{R} Q=\{x\in P:a^tx\le b\} a) Q b) b Q=P P=\{x∈\mathbb{R}^n,a^tx≤b\} a) Q:=\{x\in P:a_0^tx\le b\} Q P \exists a_1^t\dots a_n^t\in\mathbb{R}^n,c_1\dots c_n\in\mathbb{R},s.t. P=\{x\in\mathbb{R}^n:a_1^tx\le c_1\}\cap\dots\cap\{x\in\mathbb{R}^n:a_n^tx\le c_n\} =\{x∈\mathbb{R}^n:a_1^tx≤c_1\wedge\dots\wedge a_n^tx\le c_n\} Q=\{x\in P:a_0^tx\le b\}=\{x\in \mathbb{R}^n:x\in P\wedge a_0^tx\le b\} =\{x\in \mathbb{R}^n:a_0^tx\le b\wedge a_1^tx≤c_1\wedge\dots\wedge a_n^tx\le c_n\} =\{x\in \mathbb{R}^n:a_0^tx\le b\}\cap\{x\in\mathbb{R}^n:a_1^tx\le c_1\}\cap\dots\cap\{x\in\mathbb{R}^n:a_n^tx\le c_n\} \tag*{\square} b) n=1 \mathbb{R}^2 P=\{x∈\mathbb{R}^2:x_1+x_2≤0\},Q=\{x\in P:x_1-x_2\le b\} b\in\mathbb{R} Q=\{x∈\mathbb{R}^2:x_1-x_2\le b\wedge x_1+x_2≤0\} \left(\frac{b}{2},-\frac{b}{2}-1\right) P Q \frac{b}{2}-\frac{b}{2}-1≤0 \left(\frac{b}{2},-\frac{b}{2}-1\right)\in P \frac{b}{2}-\frac{b}{2}-1≤0\wedge\frac{b}{2}-(-\frac{b}{2}-1)\le b \left(\frac{b}{2},-\frac{b}{2}-1\right)\not\in Q b \forall b\in\mathbb{R},Q\neq P \tag*{\square} \dots","['proof-verification', 'elementary-set-theory', 'polyhedra', 'polytopes', 'discrete-geometry']"
51,Proof that a function is not surjective,Proof that a function is not surjective,,"I am trying to prove that this function is not surjective.Is this the right approach? Define a function $f:\mathbb{R} \rightarrow \mathbb{R}$ by $f(x)= \frac{2x-1}{x+1}$ After solving for $x$ and letting $y=f(x)$ I get $x= \frac{y+1}{2-y}$ Proof: In order for $f$ to be surjective $\forall y \in \mathbb{R}, \exists x \in \mathbb{R}$ such that $f(x)=y$ . Since there does not exist $y=2 \in \mathbb{R}$ such that $f(x)=y$ . $f$ is not surjective.",I am trying to prove that this function is not surjective.Is this the right approach? Define a function by After solving for and letting I get Proof: In order for to be surjective such that . Since there does not exist such that . is not surjective.,"f:\mathbb{R} \rightarrow \mathbb{R} f(x)= \frac{2x-1}{x+1} x y=f(x) x= \frac{y+1}{2-y} f \forall y \in \mathbb{R}, \exists x \in \mathbb{R} f(x)=y y=2 \in \mathbb{R} f(x)=y f",['proof-verification']
52,Prove that $(A \triangle C) \cap (B \triangle C) \subseteq (A \cap B) \triangle C$,Prove that,(A \triangle C) \cap (B \triangle C) \subseteq (A \cap B) \triangle C,"This is a exercise from How To Prove It by Velleman.  Exercise 3.5.24 to be exact.  The solutions I can find online involve using 4 cases.  My proof involves 2 so I was wondering if I was skipping some steps. Proof: Let x be an arbitrary element of $(A \triangle C) \cap (B \triangle C)$ .  It follows that $x \in A \triangle C$ and $x \in B \triangle C$ . We will consider 2 cases. Case 1: $x \in C$ .  Since $x \in A \triangle C$ , it follows that $x \notin A$ .  Also since $x \in B \triangle C$ , it follows that $x \notin B$ .  This means $x \in C \setminus (A \cap B)$ thus $x \in (A \cap B) \triangle C$ . Case 2: $x \notin C$ .  Since $x \in A \triangle C$ , it follows that $x \in A$ .  Also since $x \in B \triangle C$ , it follows that $x \in B$ .  This means $x \in (A \cap B) \setminus C$ thus $x \in (A \cap B) \triangle C$ . Both cases gave us $x \in (A \cap B) \triangle C$ and since x was arbitrary $(A \triangle C) \cap (B \triangle C)  \subseteq (A \cap B) \triangle C$ Is this proof a valid one?  Any feedback would be greatly appreciated. Thanks in advance.","This is a exercise from How To Prove It by Velleman.  Exercise 3.5.24 to be exact.  The solutions I can find online involve using 4 cases.  My proof involves 2 so I was wondering if I was skipping some steps. Proof: Let x be an arbitrary element of .  It follows that and . We will consider 2 cases. Case 1: .  Since , it follows that .  Also since , it follows that .  This means thus . Case 2: .  Since , it follows that .  Also since , it follows that .  This means thus . Both cases gave us and since x was arbitrary Is this proof a valid one?  Any feedback would be greatly appreciated. Thanks in advance.",(A \triangle C) \cap (B \triangle C) x \in A \triangle C x \in B \triangle C x \in C x \in A \triangle C x \notin A x \in B \triangle C x \notin B x \in C \setminus (A \cap B) x \in (A \cap B) \triangle C x \notin C x \in A \triangle C x \in A x \in B \triangle C x \in B x \in (A \cap B) \setminus C x \in (A \cap B) \triangle C x \in (A \cap B) \triangle C (A \triangle C) \cap (B \triangle C)  \subseteq (A \cap B) \triangle C,"['elementary-set-theory', 'solution-verification']"
53,Axiom of Foundation and transitive sets.,Axiom of Foundation and transitive sets.,,"Assuming the Axiom of Foundation, show that every non-empty transtive set contains $0$ and show that every non-singleton transitive set contains $1$ . It's straightfoward to show the first part. Suppose that $t$ is a nonempty transitive set. By the Axiom of Foundation, there is $r \in t$ such that $r \cap t = \emptyset$ . Now, as $r \in t$ and $t$ is transitive, we have that $r \subseteq t$ so that $\emptyset \subseteq r \subseteq r \cap t = \emptyset$ , so $\emptyset = r \in t$ . I'm stuck on the second part. If we suppose further that $t$ has at least two elements, then we may consider $q \in t$ with $q \neq \emptyset$ . We can find $p \in q$ with $q \cap p = \emptyset$ , but I don't know where to go from there.","Assuming the Axiom of Foundation, show that every non-empty transtive set contains and show that every non-singleton transitive set contains . It's straightfoward to show the first part. Suppose that is a nonempty transitive set. By the Axiom of Foundation, there is such that . Now, as and is transitive, we have that so that , so . I'm stuck on the second part. If we suppose further that has at least two elements, then we may consider with . We can find with , but I don't know where to go from there.",0 1 t r \in t r \cap t = \emptyset r \in t t r \subseteq t \emptyset \subseteq r \subseteq r \cap t = \emptyset \emptyset = r \in t t q \in t q \neq \emptyset p \in q q \cap p = \emptyset,['elementary-set-theory']
54,There's a matrix cookbook. Is there a set cookbook?,There's a matrix cookbook. Is there a set cookbook?,,"There's a matrix cookbook . Is there a set cookbook? I'm looking for a comprehensive list of properties, formulas, inclusions or lack thereof on the algebra of sets , De Morgan's laws , Cartesian products , infinite (countable or uncountable) intersections or unions, etc. For example, in topology, real analysis, probability theory or measure theory, I see a lot of expressions like $$\bigcup_{k=1}^{\infty} (A_k \cap B_k)$$ $$ (A \cup B) \times (C \cup D)$$ $$ \bigcap_{x \in X} (A_x \times B_x)^c$$ Sometimes I wonder if we can do things like put/remove a $\cap B$ or $\cup A$ to both sides of a set inclusion. If it's a set equality, I think there are cases where it's a no longer equality but merely an inclusion or sometimes not an inclusion at all. Expressions similar to the ones aforementioned don't always equal to something, they're usually just subsets or supersets of something else, and sometimes there's no (or no relevant) set inclusion. These are not difficult to prove; I'd just like to have a reference much like the matrix cookbook please. I'm interested mainly in the basics and not necessarily about open/closed, non-/measurable, counterexamples, etc. If a set inclusion is true and the reverse doesn't hold, I'll take the cookbook's word for it. I think this can be found in some appendix of some textbook. For example, a Calculus textbook appendix might have a list of trigonometric identities, without proofs, counterexamples or exercises. That's what I'm looking for. Wiki is helpful but doesn't have a lot of the properties. For example, the Cartesian products page doesn't have the second expression above (other than explaining what the second expression is not) and whether or not an empty Cartesian product implies one of the Cartesian factors is empty, but I was able to find both and more on stackexchange. There are books on these, but a lot of the properties are in exercises, some of which are determining true/false rather than dis/proving, so I'd have to try them myself or look up the solutions manual. I wish there was some compilation of all these folklores .","There's a matrix cookbook . Is there a set cookbook? I'm looking for a comprehensive list of properties, formulas, inclusions or lack thereof on the algebra of sets , De Morgan's laws , Cartesian products , infinite (countable or uncountable) intersections or unions, etc. For example, in topology, real analysis, probability theory or measure theory, I see a lot of expressions like $$\bigcup_{k=1}^{\infty} (A_k \cap B_k)$$ $$ (A \cup B) \times (C \cup D)$$ $$ \bigcap_{x \in X} (A_x \times B_x)^c$$ Sometimes I wonder if we can do things like put/remove a $\cap B$ or $\cup A$ to both sides of a set inclusion. If it's a set equality, I think there are cases where it's a no longer equality but merely an inclusion or sometimes not an inclusion at all. Expressions similar to the ones aforementioned don't always equal to something, they're usually just subsets or supersets of something else, and sometimes there's no (or no relevant) set inclusion. These are not difficult to prove; I'd just like to have a reference much like the matrix cookbook please. I'm interested mainly in the basics and not necessarily about open/closed, non-/measurable, counterexamples, etc. If a set inclusion is true and the reverse doesn't hold, I'll take the cookbook's word for it. I think this can be found in some appendix of some textbook. For example, a Calculus textbook appendix might have a list of trigonometric identities, without proofs, counterexamples or exercises. That's what I'm looking for. Wiki is helpful but doesn't have a lot of the properties. For example, the Cartesian products page doesn't have the second expression above (other than explaining what the second expression is not) and whether or not an empty Cartesian product implies one of the Cartesian factors is empty, but I was able to find both and more on stackexchange. There are books on these, but a lot of the properties are in exercises, some of which are determining true/false rather than dis/proving, so I'd have to try them myself or look up the solutions manual. I wish there was some compilation of all these folklores .",,"['elementary-set-theory', 'reference-request']"
55,"If $A$ and $B$ are countable, then $A\times B$ is countable","If  and  are countable, then  is countable",A B A\times B,"If $A$ and $B$ are countable, then $A\times B$ is countable. My attempt: Lemma 1 : $A$ is countable if and only if there exists a injective mapping $f:A \to \Bbb N$. Lemma 2 : $\Bbb N\times\Bbb N$ is countable. Since $A$ and $B$ are countable, there exist injections $j_A:A \to \Bbb N$ and $j_B:B \to \Bbb N$ by Lemma 1 . We define a mapping $j:A\times B \to \Bbb N\times\Bbb N$ by $j(a,b)=(j_A(a),j_B(b))$. It's clear that $j$ is injective. Since $\Bbb N\times\Bbb N$ is countable by Lemma 2 , there exists an injection $f:\Bbb N\times\Bbb N \to \Bbb N$ by Lemma 1 . Hence $f\circ j:A\times B \to \Bbb N$ in injective and hence $A\times B$ is countable by Lemma 1 . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!","If $A$ and $B$ are countable, then $A\times B$ is countable. My attempt: Lemma 1 : $A$ is countable if and only if there exists a injective mapping $f:A \to \Bbb N$. Lemma 2 : $\Bbb N\times\Bbb N$ is countable. Since $A$ and $B$ are countable, there exist injections $j_A:A \to \Bbb N$ and $j_B:B \to \Bbb N$ by Lemma 1 . We define a mapping $j:A\times B \to \Bbb N\times\Bbb N$ by $j(a,b)=(j_A(a),j_B(b))$. It's clear that $j$ is injective. Since $\Bbb N\times\Bbb N$ is countable by Lemma 2 , there exists an injection $f:\Bbb N\times\Bbb N \to \Bbb N$ by Lemma 1 . Hence $f\circ j:A\times B \to \Bbb N$ in injective and hence $A\times B$ is countable by Lemma 1 . Does this proof look fine or contain gaps? Do you have suggestions? Many thanks for your dedicated help!",,"['elementary-set-theory', 'proof-verification']"
56,Permutation of partitions,Permutation of partitions,,"Let $N \subset \mathbb N$ and $\Pi$ the set of partitions of $N$. I want to define a permutation such that the partition $\pi \in \Pi$ is identical with $\pi' \in \Pi$ up to a permutation $p : N \to N$ of the index $i \in N$. Exmaple Consider $N = \{1,2,3\}$ and $\pi = \{\{1\},\{2,3\}\}$. The permutation $p(N) = \{2,3,1\}$ shall result in $\pi' = \{\{2\},\{3,1\}\}$. Does there exist a common definition or how would you define $\pi'$ from $p$? Edit With respect to the comment one may defines $\rho : \Pi \to \Pi$ by $\rho(\pi) := \{\{p(i)\}_{i \in S} \mid S \in \pi\}$. Reconsdering the example $\pi = \{\{1\},\{2,3\}\}$ and $p(\{1,2,3\}) = \{2,3,1\}$ yields  \begin{align} \rho(\pi)& = \{\{p(i)\}_{i \in \{1\}}, \{p(i)\}_{i \in \{2,3\}}\}\\ & = \{\{p(1)\}, \{p(2),p(3)\}\\ & = \{\{2\},\{3,1\}\}\\ & = \pi'. \end{align} Is the definition sound?","Let $N \subset \mathbb N$ and $\Pi$ the set of partitions of $N$. I want to define a permutation such that the partition $\pi \in \Pi$ is identical with $\pi' \in \Pi$ up to a permutation $p : N \to N$ of the index $i \in N$. Exmaple Consider $N = \{1,2,3\}$ and $\pi = \{\{1\},\{2,3\}\}$. The permutation $p(N) = \{2,3,1\}$ shall result in $\pi' = \{\{2\},\{3,1\}\}$. Does there exist a common definition or how would you define $\pi'$ from $p$? Edit With respect to the comment one may defines $\rho : \Pi \to \Pi$ by $\rho(\pi) := \{\{p(i)\}_{i \in S} \mid S \in \pi\}$. Reconsdering the example $\pi = \{\{1\},\{2,3\}\}$ and $p(\{1,2,3\}) = \{2,3,1\}$ yields  \begin{align} \rho(\pi)& = \{\{p(i)\}_{i \in \{1\}}, \{p(i)\}_{i \in \{2,3\}}\}\\ & = \{\{p(1)\}, \{p(2),p(3)\}\\ & = \{\{2\},\{3,1\}\}\\ & = \pi'. \end{align} Is the definition sound?",,"['elementary-set-theory', 'definition']"
57,Are theories in standard mathematics defined on sets or on collections?,Are theories in standard mathematics defined on sets or on collections?,,"Generally, the structures that people study in every-day modern mathematics can be seen as defined on sets, so far as I know. (In the sense that they are collections of objects that don't give rise to russel's paradox). E.g. the collection of real numbers, or of $5$-dimensional manifolds or of symmetry maps on the unit circle or whatever, are all sets. However, I recall that sometimes structures cannot be assumed to be sets. E.g. we cannot speak of the Category of Categories apparently (unless we mean the category of small categories), since this would not be a set, and would give rise to russel's paradox (if I underatand correctly) My question is: is it generally required for any mathematical theory that the domain of any arbitrary structure that satiafies it is a set, rather than generally a collection? E.g. do we require that a group not only satiafies the axioms, but implicitly require also that the domain of a particular group is a set?","Generally, the structures that people study in every-day modern mathematics can be seen as defined on sets, so far as I know. (In the sense that they are collections of objects that don't give rise to russel's paradox). E.g. the collection of real numbers, or of $5$-dimensional manifolds or of symmetry maps on the unit circle or whatever, are all sets. However, I recall that sometimes structures cannot be assumed to be sets. E.g. we cannot speak of the Category of Categories apparently (unless we mean the category of small categories), since this would not be a set, and would give rise to russel's paradox (if I underatand correctly) My question is: is it generally required for any mathematical theory that the domain of any arbitrary structure that satiafies it is a set, rather than generally a collection? E.g. do we require that a group not only satiafies the axioms, but implicitly require also that the domain of a particular group is a set?",,"['elementary-set-theory', 'axioms']"
58,"Set and Inequality, something like generating function.","Set and Inequality, something like generating function.",,"Given positive integer $N$, whether there exist two distinct sets $A$, $B$ such that $\left| A\right|, \left| B\right| \leqslant N^2$, and for any $x\in (0,1)$, the following one holds:$$\left|\sum_{a\in A}x^{a}-\sum_{b\in B}x^{b}\right| \lt (1-x)^{N}?$$ I'm even not sure about the answer, but at least it is positive when $N=1$, and I guess that it’s the same for all $N$. I also think that it may be related to pigeonhole principle, like choosing a number of $(A, B)$ with some bound... Please help.","Given positive integer $N$, whether there exist two distinct sets $A$, $B$ such that $\left| A\right|, \left| B\right| \leqslant N^2$, and for any $x\in (0,1)$, the following one holds:$$\left|\sum_{a\in A}x^{a}-\sum_{b\in B}x^{b}\right| \lt (1-x)^{N}?$$ I'm even not sure about the answer, but at least it is positive when $N=1$, and I guess that it’s the same for all $N$. I also think that it may be related to pigeonhole principle, like choosing a number of $(A, B)$ with some bound... Please help.",,"['elementary-set-theory', 'inequality', 'generating-functions', 'pigeonhole-principle']"
59,Proving a set is a subset of another set,Proving a set is a subset of another set,,"Question: Let $S = [3] \times [3]$ (the Cartesian product of $\{1, 2, 3\}$ with itself). Let $T$ be the set of ordered pairs $(x,y) \in \mathbb{Z}\times\mathbb{Z}$ such that $0≤3x+y−4≤8$. Prove that $S ⊆ T$. Does equality hold? My attempt to prove that $S ⊆ T$: Attempt Could someone please tell me if this is the correct way to prove $S ⊆ T$? Also, in order to prove that equality holds, do I have to show that $T ⊆ S$ ?","Question: Let $S = [3] \times [3]$ (the Cartesian product of $\{1, 2, 3\}$ with itself). Let $T$ be the set of ordered pairs $(x,y) \in \mathbb{Z}\times\mathbb{Z}$ such that $0≤3x+y−4≤8$. Prove that $S ⊆ T$. Does equality hold? My attempt to prove that $S ⊆ T$: Attempt Could someone please tell me if this is the correct way to prove $S ⊆ T$? Also, in order to prove that equality holds, do I have to show that $T ⊆ S$ ?",,['elementary-set-theory']
60,Finding the Cardinality of a Cartesian Product,Finding the Cardinality of a Cartesian Product,,"Problem : $$A=\{ 1,2,3, \dots, n \}$$ $$\text{ Find the Cardinality of ... } $$$$\{(a,S) | a \in S, S \in P(A)\}$$ So the way I've approached this problem thus far was to find the cardinality of $S$ and then multiply it by the cardinality of $a$. If I'm not mistaken the cardinality of $S$ should be $2^n-1$ as $S$ cannot be an element of itself and the cardinality of $P(A)$ is $2^n$. However, I'm having difficulty finding the cardinality of $a$. Is it just n? And if so, why is that?","Problem : $$A=\{ 1,2,3, \dots, n \}$$ $$\text{ Find the Cardinality of ... } $$$$\{(a,S) | a \in S, S \in P(A)\}$$ So the way I've approached this problem thus far was to find the cardinality of $S$ and then multiply it by the cardinality of $a$. If I'm not mistaken the cardinality of $S$ should be $2^n-1$ as $S$ cannot be an element of itself and the cardinality of $P(A)$ is $2^n$. However, I'm having difficulty finding the cardinality of $a$. Is it just n? And if so, why is that?",,['elementary-set-theory']
61,Can it be useful to think of operations on subspaces in terms of operations in elementary set theory?,Can it be useful to think of operations on subspaces in terms of operations in elementary set theory?,,"This question is something that I have been thinking about on and off for a while. The basic premise is that, in Linear Algebra, a lot of the basic operations performed on subspaces have corresponding familiar operations that are performed on subsets of general sets. The operations on sets just have to be changed slightly to ensure that we always get subspaces. Below are some examples (in each example $V$ is a vectorspace and $U,W$ are subspaces of $V$): In a general set there is the concept of the empty set ($\emptyset$), which contains no elements and is a subset of every other set. However, $\emptyset$ is not a subspace. The subspace that corresponds to the $\emptyset$ would be $\{0\}$ where $0$ is the additive identity in $V$. This is clealy the smallest subspace and, like $\emptyset$, we have that $\{0\} \subseteq U$ for every subspace $U$. The set $U \cap W$ is a subspaces of $V$ for all subspaces $U,W$ so this does not need to be changed. $U \cup W$ may not be a subspace of $V$. The set $U + W$ can be thought of the corresponding subspace. $U \cup W$ is the smallest subset that contains both $U$ and $W$. Similarly $U + W$ is the smallest subspace that contains $U$ and $W$. We also have this relation. If $U \subseteq W$, then $U \cup W = W$ and $U + W = W$. If $U$ is a subspace, then $U^c$ will never be a subspace (as it does not contain $0$). One way to think about $U^c$ is that it is the unique subset of $V$ such that $U \cup U^c = V$ and $U \cap U^c = \emptyset$. We have subspace notions of $\cup$ and $\emptyset$, so we will want the subspace $W$ that corresponds to $U^c$ to be such that $U+W=V$ and $U \cap W = \{0\}$. Clearly there could be many such subspaces $W$ but, if we are working in an inner-product space, then $W=U^\perp$ is an obvious choice. I understant that this is quite a long post (thank you to those you have read this far). I would like to hear what people think about this, in particular: Do you think that this is a useful\interesting way to think about subspaces and operations defined on them? Could this way of thinking be perhaps be used as motivation when first introducing the concept of a subspace? How misleading could this way of thinking end up being? Thank you. Any answers/comments are greatly appreciated.","This question is something that I have been thinking about on and off for a while. The basic premise is that, in Linear Algebra, a lot of the basic operations performed on subspaces have corresponding familiar operations that are performed on subsets of general sets. The operations on sets just have to be changed slightly to ensure that we always get subspaces. Below are some examples (in each example $V$ is a vectorspace and $U,W$ are subspaces of $V$): In a general set there is the concept of the empty set ($\emptyset$), which contains no elements and is a subset of every other set. However, $\emptyset$ is not a subspace. The subspace that corresponds to the $\emptyset$ would be $\{0\}$ where $0$ is the additive identity in $V$. This is clealy the smallest subspace and, like $\emptyset$, we have that $\{0\} \subseteq U$ for every subspace $U$. The set $U \cap W$ is a subspaces of $V$ for all subspaces $U,W$ so this does not need to be changed. $U \cup W$ may not be a subspace of $V$. The set $U + W$ can be thought of the corresponding subspace. $U \cup W$ is the smallest subset that contains both $U$ and $W$. Similarly $U + W$ is the smallest subspace that contains $U$ and $W$. We also have this relation. If $U \subseteq W$, then $U \cup W = W$ and $U + W = W$. If $U$ is a subspace, then $U^c$ will never be a subspace (as it does not contain $0$). One way to think about $U^c$ is that it is the unique subset of $V$ such that $U \cup U^c = V$ and $U \cap U^c = \emptyset$. We have subspace notions of $\cup$ and $\emptyset$, so we will want the subspace $W$ that corresponds to $U^c$ to be such that $U+W=V$ and $U \cap W = \{0\}$. Clearly there could be many such subspaces $W$ but, if we are working in an inner-product space, then $W=U^\perp$ is an obvious choice. I understant that this is quite a long post (thank you to those you have read this far). I would like to hear what people think about this, in particular: Do you think that this is a useful\interesting way to think about subspaces and operations defined on them? Could this way of thinking be perhaps be used as motivation when first introducing the concept of a subspace? How misleading could this way of thinking end up being? Thank you. Any answers/comments are greatly appreciated.",,"['linear-algebra', 'elementary-set-theory', 'vector-spaces', 'soft-question', 'education']"
62,Is every recursively enumerable set many-one reducible to $L_\text{b}$?,Is every recursively enumerable set many-one reducible to ?,L_\text{b},"A URM $M$ b-accepts an input $x$ if in the overall course of its computation on $x$, the register $R_1$ contains only finitely many different values (thus, if $M$ halts on $x$, it always b-accepts, but the converse is not necessarily true). Let$$L_\text{b} := \{(x, y) : M_x \text{ b-accepts }y\}$$($M_x$ is the URM with code $x$). Is every recursively enumerable set many-one reducible to $L_\text{b}$?","A URM $M$ b-accepts an input $x$ if in the overall course of its computation on $x$, the register $R_1$ contains only finitely many different values (thus, if $M$ halts on $x$, it always b-accepts, but the converse is not necessarily true). Let$$L_\text{b} := \{(x, y) : M_x \text{ b-accepts }y\}$$($M_x$ is the URM with code $x$). Is every recursively enumerable set many-one reducible to $L_\text{b}$?",,"['elementary-set-theory', 'logic']"
63,Set Theory Computer Science A-Level Question Confusion,Set Theory Computer Science A-Level Question Confusion,,"I am studying for a Computer Science Degree and am using the book ""Essential Maths Skills for AS/A-Level Computer Science"" by Gavin Craddock and am on the Set Theory portion. There is a practice question that states: If: A = {1,2,3,4,5,6} B = {2,4,6,8} C = {6,7,8,9} Calculate: (C ∩ B) \ A I work this out as: 1. (C ∩ B) = {6,8} 2. {6,8} \ {1,2,3,4,5,6} = {8} However the answer paper gives this as an empty set {} or Ø What am I missing here?","I am studying for a Computer Science Degree and am using the book ""Essential Maths Skills for AS/A-Level Computer Science"" by Gavin Craddock and am on the Set Theory portion. There is a practice question that states: If: A = {1,2,3,4,5,6} B = {2,4,6,8} C = {6,7,8,9} Calculate: (C ∩ B) \ A I work this out as: 1. (C ∩ B) = {6,8} 2. {6,8} \ {1,2,3,4,5,6} = {8} However the answer paper gives this as an empty set {} or Ø What am I missing here?",,['elementary-set-theory']
64,"Methods to find $f$, given the functions $f \circ g$ and $g$","Methods to find , given the functions  and",f f \circ g g,"There is one way, which is to use the fact that $ \ f(g(g^{-1}(x)))=f(x)$. But this method only works if $g$ has a right inverse. There are other heuristic methods, which is to ""guess the shape"" of $ \ f$, given the composite function. But is there a more powerful method that can be profitably used by non-calculus students? What about methods from calculus? I ask this because the Malaysian public exams ask these questions a whole lot, and students normally jump right into these so-called ""find the outside function"" questions by assuming that $g$ is invertible, and then get into a knot when it's not.","There is one way, which is to use the fact that $ \ f(g(g^{-1}(x)))=f(x)$. But this method only works if $g$ has a right inverse. There are other heuristic methods, which is to ""guess the shape"" of $ \ f$, given the composite function. But is there a more powerful method that can be profitably used by non-calculus students? What about methods from calculus? I ask this because the Malaysian public exams ask these questions a whole lot, and students normally jump right into these so-called ""find the outside function"" questions by assuming that $g$ is invertible, and then get into a knot when it's not.",,"['elementary-set-theory', 'elementary-functions']"
65,"Deducing the existence of particular functions $\mathbb{N}\longrightarrow\mathbb{Q}$ in the context of Tom Leinster's ""Rethinking Set Theory""","Deducing the existence of particular functions  in the context of Tom Leinster's ""Rethinking Set Theory""",\mathbb{N}\longrightarrow\mathbb{Q},"This question concerns the set theory given by Tom Leinster in his paper ""Rethinking Set Theory,"" available here: http://arxiv.org/abs/1212.6543 In this paper, axioms for set theory are given in the spirit of category theory, i.e., in the spirit of Lawvere's ETCS, but are written to be understandable at the undergraduate level. I am just an undergrad, and I do not have very much experience with set theory at all, so I apologize for my lack of background in this context. My question is this: Leinster's Axiom 9 provides a system of natural numbers, from which one presumably may construct integers, rationals, etc. In my attempt to write out a quick construction of the real numbers as equivalence classes of Cauchy sequences, I am stuck on the following: Given a set of rational numbers $\{r_1,r_2,r_3,...\}$, do the axioms in this paper guarantee the existence of a function $f\in \mathbb{Q}^{\mathbb{N}}$ such that $f(1)=r_1,$ $f(2)=r_2,$ $f(3)=r_3,$ etc.? Leinster's axiom 6 states that the collection of functions between two sets is again a set, but I can't seem to understand how to deduce the existence of such a function within this theory. Given a function $g:\mathbb{N}\longrightarrow\mathbb{Q}$, I understand that $g(n)=g\circ n$, where $n:\mathbb{1}\longrightarrow \mathbb{N}$ denotes the element $n$, and that this shows $g(n)$ is indeed an element of $\mathbb{Q}.$ Can someone help me understand this? Again I apologize for my lack of understanding, I am merely fascinated by this paper and have not had any education in the area of set theory.","This question concerns the set theory given by Tom Leinster in his paper ""Rethinking Set Theory,"" available here: http://arxiv.org/abs/1212.6543 In this paper, axioms for set theory are given in the spirit of category theory, i.e., in the spirit of Lawvere's ETCS, but are written to be understandable at the undergraduate level. I am just an undergrad, and I do not have very much experience with set theory at all, so I apologize for my lack of background in this context. My question is this: Leinster's Axiom 9 provides a system of natural numbers, from which one presumably may construct integers, rationals, etc. In my attempt to write out a quick construction of the real numbers as equivalence classes of Cauchy sequences, I am stuck on the following: Given a set of rational numbers $\{r_1,r_2,r_3,...\}$, do the axioms in this paper guarantee the existence of a function $f\in \mathbb{Q}^{\mathbb{N}}$ such that $f(1)=r_1,$ $f(2)=r_2,$ $f(3)=r_3,$ etc.? Leinster's axiom 6 states that the collection of functions between two sets is again a set, but I can't seem to understand how to deduce the existence of such a function within this theory. Given a function $g:\mathbb{N}\longrightarrow\mathbb{Q}$, I understand that $g(n)=g\circ n$, where $n:\mathbb{1}\longrightarrow \mathbb{N}$ denotes the element $n$, and that this shows $g(n)$ is indeed an element of $\mathbb{Q}.$ Can someone help me understand this? Again I apologize for my lack of understanding, I am merely fascinated by this paper and have not had any education in the area of set theory.",,"['elementary-set-theory', 'category-theory']"
66,Distributing arbitrary union over arbitrary intersection (and vice versa),Distributing arbitrary union over arbitrary intersection (and vice versa),,"Suppose $I, J$ are arbitrary index sets. Let $X$ be a set and $X_{i, j} \subseteq X$. I claim that $$\bigcap_{i\in I} \bigcup_{j\in J} X_{i,j} = \bigcup_{(j_i) \in J^I}\: \bigcap_{i\in I} X_{i, j_i}.$$ $$\bigcup_{i\in I} \bigcap_{j\in J} X_{i,j} = \bigcap_{(j_i) \in J^I}\: \bigcup_{i\in I} X_{i, j_i}.$$ For the first result: $\newcommand{\lra}{\longleftrightarrow}$ \begin{align*} x \in \bigcap_{i\in I} \bigcup_{j\in J} X_{i,j} &\lra \forall i \in I\: \exists j \in J\: (x \in X_{i, j})\\ &\lra \exists (j_i) \in J^I \: \forall i \in I \: (x \in X_{i, j_i})\\ &\lra x \in \bigcup_{(j_i) \in J^I}\: \bigcap_{i\in I} X_{i, j_i}. \end{align*} For the second result, we employ the first combined with De Morgan's laws: \begin{align*} X - \bigcup_{i\in I} \bigcap_{j\in J} X_{i,j} &= \bigcap_{i\in I} \left[X-\bigcap_{j\in J} X_{i,j}\right]\\ &= \bigcap_{i\in I} \bigcup_{j\in J} (X - X_{i,j})\\ &= \bigcup_{(j_i) \in J^I}\: \bigcap_{i\in I} (X - X_{i,j_i})\\ &= \bigcup_{(j_i) \in J^I}\: \left[X - \bigcup_{i\in I} X_{i,j_i} \right]\\ &= X - \bigcap_{(j_i) \in J^I}\: \bigcup_{i\in I} X_{i,j_i}. \end{align*} Is this result true, and is my proof valid? I couldn't find such a general result on Google (only stuff about finite unions/intersections), so I wanted to double check.","Suppose $I, J$ are arbitrary index sets. Let $X$ be a set and $X_{i, j} \subseteq X$. I claim that $$\bigcap_{i\in I} \bigcup_{j\in J} X_{i,j} = \bigcup_{(j_i) \in J^I}\: \bigcap_{i\in I} X_{i, j_i}.$$ $$\bigcup_{i\in I} \bigcap_{j\in J} X_{i,j} = \bigcap_{(j_i) \in J^I}\: \bigcup_{i\in I} X_{i, j_i}.$$ For the first result: $\newcommand{\lra}{\longleftrightarrow}$ \begin{align*} x \in \bigcap_{i\in I} \bigcup_{j\in J} X_{i,j} &\lra \forall i \in I\: \exists j \in J\: (x \in X_{i, j})\\ &\lra \exists (j_i) \in J^I \: \forall i \in I \: (x \in X_{i, j_i})\\ &\lra x \in \bigcup_{(j_i) \in J^I}\: \bigcap_{i\in I} X_{i, j_i}. \end{align*} For the second result, we employ the first combined with De Morgan's laws: \begin{align*} X - \bigcup_{i\in I} \bigcap_{j\in J} X_{i,j} &= \bigcap_{i\in I} \left[X-\bigcap_{j\in J} X_{i,j}\right]\\ &= \bigcap_{i\in I} \bigcup_{j\in J} (X - X_{i,j})\\ &= \bigcup_{(j_i) \in J^I}\: \bigcap_{i\in I} (X - X_{i,j_i})\\ &= \bigcup_{(j_i) \in J^I}\: \left[X - \bigcup_{i\in I} X_{i,j_i} \right]\\ &= X - \bigcap_{(j_i) \in J^I}\: \bigcup_{i\in I} X_{i,j_i}. \end{align*} Is this result true, and is my proof valid? I couldn't find such a general result on Google (only stuff about finite unions/intersections), so I wanted to double check.",,"['elementary-set-theory', 'proof-verification']"
67,Is Cantor's Diagonal Argument Dependent on Tertium Non Datur,Is Cantor's Diagonal Argument Dependent on Tertium Non Datur,,"The standard presentation of Cantor's Diagonal argument on the uncountability of (0,1) starts with assuming the contrary through ""reduction ad absurdum"".  The intuitionist schools of mathematical regards ""Tertium Non Datur"" (bijection from N to R either exists or does not exist) untenable for infinite classes. However, the argument can be modified by applying the diagonal argument to any function $f:N\to R$ thereby producing an element of $R$ not in the codomain of the function f .  Because this was applied to ""any"" function from $N$ to $R$, this shows the impossibility of an onto function from $N$ to R; ergo the uncountability of (0,1) independent of tertium non datur / excluded middle. Is this conclusion/argument correct?","The standard presentation of Cantor's Diagonal argument on the uncountability of (0,1) starts with assuming the contrary through ""reduction ad absurdum"".  The intuitionist schools of mathematical regards ""Tertium Non Datur"" (bijection from N to R either exists or does not exist) untenable for infinite classes. However, the argument can be modified by applying the diagonal argument to any function $f:N\to R$ thereby producing an element of $R$ not in the codomain of the function f .  Because this was applied to ""any"" function from $N$ to $R$, this shows the impossibility of an onto function from $N$ to R; ergo the uncountability of (0,1) independent of tertium non datur / excluded middle. Is this conclusion/argument correct?",,['elementary-set-theory']
68,Proving there is no injection from $V^V$ to $V$,Proving there is no injection from  to,V^V V,"Let $V$ be a set such that $V$ is not a singleton. I have to prove that there doesn't exist an injection from $V^V$ to $V$. As predecessor to this exercise, I have proven that there doesn't exist a surjection from $V$ to $V^V$, and I was wondering if i) the method is correct at all and ii) if I could use the same method for this question: Proof. Suppose there exists a surjection $f:V\rightarrow V^V$. $V$ is not a singleton, so we can find distinct elements $v_0,v_1$ in $V$. We construct $g:V\rightarrow V$ such that there doesn't exist a $v\in V$ such that $f(v)=g$. Define $g$ as follows: If $v_0$ is a fixed point of $f(v_0)$, let $g(v_0)=v_1$, else let $g(v_0)=v_0$. From this we know $f(v_0)\neq g$. If $v_1$ is a fixed point of $f(v_1)$, let $g(v_1)=v_0$, else let $g(v_1)=v_1$. From this we know $f(v_1)\neq g$. Now let $v\in V\setminus\{v_0,v_1\}$. Repeat, if $v$ is a fixed point of $f(v)$, let $g(v)=v_0$, else $g(v)=v$. But then we know there is no $v\in V$ such that $f(v)=g$, so $f$ is no surjection.$\tag*{$\square$}$ Now, is this principle also applicable to the ""reverse""?","Let $V$ be a set such that $V$ is not a singleton. I have to prove that there doesn't exist an injection from $V^V$ to $V$. As predecessor to this exercise, I have proven that there doesn't exist a surjection from $V$ to $V^V$, and I was wondering if i) the method is correct at all and ii) if I could use the same method for this question: Proof. Suppose there exists a surjection $f:V\rightarrow V^V$. $V$ is not a singleton, so we can find distinct elements $v_0,v_1$ in $V$. We construct $g:V\rightarrow V$ such that there doesn't exist a $v\in V$ such that $f(v)=g$. Define $g$ as follows: If $v_0$ is a fixed point of $f(v_0)$, let $g(v_0)=v_1$, else let $g(v_0)=v_0$. From this we know $f(v_0)\neq g$. If $v_1$ is a fixed point of $f(v_1)$, let $g(v_1)=v_0$, else let $g(v_1)=v_1$. From this we know $f(v_1)\neq g$. Now let $v\in V\setminus\{v_0,v_1\}$. Repeat, if $v$ is a fixed point of $f(v)$, let $g(v)=v_0$, else $g(v)=v$. But then we know there is no $v\in V$ such that $f(v)=g$, so $f$ is no surjection.$\tag*{$\square$}$ Now, is this principle also applicable to the ""reverse""?",,['elementary-set-theory']
69,What do $\bigcup_{n=1}^\infty S_n$ and $\bigcap_{n=1}^\infty S_n$ mean?,What do  and  mean?,\bigcup_{n=1}^\infty S_n \bigcap_{n=1}^\infty S_n,"In some cases, we will have to consider the union or the intersection of several, even infinitely many sets, defined in the obvious way. For example, if for every positive integer $n$, we are given a set $S_n$, then   $$\bbox[border:1px solid red]{\bigcup_{n=1}^\infty S_n}=S_1\cup S_2\cup\cdots=\{x\mid x\in S_n\text{ for some }n\},$$   and   $$\bigcap_{n=1}^\infty S_n=S_1\cap S_2\cap\cdots=\{x\mid x\in S_n\text{ for all }n\}.$$   Two sets are said to be disjoint if their intersection is empty. More generally, several sets are said to be disjoint if no two of them have a common element. A collection of sets is said to be a partition of a set $S$ if the sets in the collection are disjoint and their union is $S$. Normally what I know is that you can make a union or an intersection between only two sets. In this expression, there is a big union of sets. I'm asking about the meaning of this expression – what does it mean? What does the infinity sign do at the top? Things are even more complicated with De Morgan's laws, which use the same expression: Two particularly useful properties are given by De Morgan's laws which state that   $$\left(\bigcup_nS_n\right)^c=\bigcap_nS_n^c,\quad\quad\quad\quad\left(\bigcap_nS_n\right)^c=\bigcup_nS_n^c.$$ Anyone who can explain to me the expression or De Morgan's laws would be much appreciated.","In some cases, we will have to consider the union or the intersection of several, even infinitely many sets, defined in the obvious way. For example, if for every positive integer $n$, we are given a set $S_n$, then   $$\bbox[border:1px solid red]{\bigcup_{n=1}^\infty S_n}=S_1\cup S_2\cup\cdots=\{x\mid x\in S_n\text{ for some }n\},$$   and   $$\bigcap_{n=1}^\infty S_n=S_1\cap S_2\cap\cdots=\{x\mid x\in S_n\text{ for all }n\}.$$   Two sets are said to be disjoint if their intersection is empty. More generally, several sets are said to be disjoint if no two of them have a common element. A collection of sets is said to be a partition of a set $S$ if the sets in the collection are disjoint and their union is $S$. Normally what I know is that you can make a union or an intersection between only two sets. In this expression, there is a big union of sets. I'm asking about the meaning of this expression – what does it mean? What does the infinity sign do at the top? Things are even more complicated with De Morgan's laws, which use the same expression: Two particularly useful properties are given by De Morgan's laws which state that   $$\left(\bigcup_nS_n\right)^c=\bigcap_nS_n^c,\quad\quad\quad\quad\left(\bigcap_nS_n\right)^c=\bigcup_nS_n^c.$$ Anyone who can explain to me the expression or De Morgan's laws would be much appreciated.",,"['probability', 'statistics', 'elementary-set-theory', 'notation']"
70,Initial and final topologies,Initial and final topologies,,"Suppose that $X_i$ are topological spaces, and $X_i \xrightarrow{f_i} Y$ are a family of maps into the set $Y$. The final topology on $Y$ is defined to be the finest topology on $Y$ such that each $f_i$ is continuous. I have also heard it described as ""the topology on $Y$ consisting of the images of saturated open sets in $X_i$"", but it seems this requires that every $y\in Y$ is in the image of some $X_i$. It also makes sense that we would mostly be interested in the final topology when $Y = \cup_i f_i(X_i)$; otherwise we just have this chunk of $Y$ hanging around with the discrete topology on it. Dually, suppose we have $X \xrightarrow{g_i} Y_i$ and we want to give $X$ the initial topology. Now is there some reason why $g_i$ should separate points? (I think this would be the dual requirement to $Y$ being the image.) Maybe if it does not, then points not separated are topologically indistinguishable? Would we ever care about the initial topology with respect to a single map which was not injective? The separating points reminds me of the characterization of initial topologies as separating points from closed sets","Suppose that $X_i$ are topological spaces, and $X_i \xrightarrow{f_i} Y$ are a family of maps into the set $Y$. The final topology on $Y$ is defined to be the finest topology on $Y$ such that each $f_i$ is continuous. I have also heard it described as ""the topology on $Y$ consisting of the images of saturated open sets in $X_i$"", but it seems this requires that every $y\in Y$ is in the image of some $X_i$. It also makes sense that we would mostly be interested in the final topology when $Y = \cup_i f_i(X_i)$; otherwise we just have this chunk of $Y$ hanging around with the discrete topology on it. Dually, suppose we have $X \xrightarrow{g_i} Y_i$ and we want to give $X$ the initial topology. Now is there some reason why $g_i$ should separate points? (I think this would be the dual requirement to $Y$ being the image.) Maybe if it does not, then points not separated are topologically indistinguishable? Would we ever care about the initial topology with respect to a single map which was not injective? The separating points reminds me of the characterization of initial topologies as separating points from closed sets",,"['general-topology', 'elementary-set-theory']"
71,"Metrics on $\mathbb R^n$, Counting continuous functions and Open sets","Metrics on , Counting continuous functions and Open sets",\mathbb R^n,"Given the set $\mathbb{R}^n$ with metric $d$. We define continuous functions from $\mathbb{R}^n$ to $\mathbb{R}^n$ by open sets -we say that function is continuous iff the pre-image of every open set is open. Let's say that number of open sets in $(\mathbb{R}^n,d)$ is $\mathfrak{c}$. Does that imply that the number of continuous function in $(\mathbb{R^n}, d)$ is $2^\mathfrak{c}$? Or maybe $\mathfrak{c}$? What if number of open sets is $2^\mathfrak{c}$? Is it an open problem or known one?","Given the set $\mathbb{R}^n$ with metric $d$. We define continuous functions from $\mathbb{R}^n$ to $\mathbb{R}^n$ by open sets -we say that function is continuous iff the pre-image of every open set is open. Let's say that number of open sets in $(\mathbb{R}^n,d)$ is $\mathfrak{c}$. Does that imply that the number of continuous function in $(\mathbb{R^n}, d)$ is $2^\mathfrak{c}$? Or maybe $\mathfrak{c}$? What if number of open sets is $2^\mathfrak{c}$? Is it an open problem or known one?",,"['general-topology', 'elementary-set-theory', 'metric-spaces']"
72,cardinality of $\mathbb R$ is the same as the cardinality of $\mathbb R^2$,cardinality of  is the same as the cardinality of,\mathbb R \mathbb R^2,"A problem in my homework is to prove the cardinality of $\mathbb R$ and the cardinality of $\mathbb R^2$ is the same. I'm in my first semester and I have no clue how to do this, do I need the axiom of choice to prove this? Can I find a bijection, or must I use Cantor-Schroeder-Bernstein? Apparently if we assume choice we can go further and prove the cardinality of any set $A$ is is equal to the cardinality of $A^2$ thank you very much, I need help. Regards.","A problem in my homework is to prove the cardinality of $\mathbb R$ and the cardinality of $\mathbb R^2$ is the same. I'm in my first semester and I have no clue how to do this, do I need the axiom of choice to prove this? Can I find a bijection, or must I use Cantor-Schroeder-Bernstein? Apparently if we assume choice we can go further and prove the cardinality of any set $A$ is is equal to the cardinality of $A^2$ thank you very much, I need help. Regards.",,['elementary-set-theory']
73,Metric-like families of relations,Metric-like families of relations,,"Let $X$ be an arbitrary set and to start with, let us consider a relation $\leq$ on $X$ (that is $\leq$ is a subset of $X^2$) which is reflexive and transitive. such a relation is called a preorder. Now, let us consider a similar object - a family of relations $\leq^\delta$ parametrized by $\delta\in[0,\infty)$ that satisfy the following properties: $x\leq^0 x$ for any $x\in X$, if $x\leq^\delta y$ and $y\leq^{\epsilon} z$ then $x\leq^{\delta+\epsilon} z$ for any $x,y,z\in X$. The first condition is obviously reflexivity, whereas the second can be understood as ""approximate transitivity"". It reminds of the triangular inequality. In fact, the function $$   d(x,y):=\inf\{\delta>0:x\leq^\delta y \text{ and }y\leq^\delta x\} $$ can be shown to be a pseudo-metric (a metric that can be zero outside of the diagonal). Is there any special name for the family $\leq^\delta$, or for its symmetrization $\approx^\delta$ where $$   x\approx^\delta y \iff x\leq^\delta y \text{ and }y\leq^\delta x. $$ Let me also mention that $\leq^0$ alone is a pre-order.","Let $X$ be an arbitrary set and to start with, let us consider a relation $\leq$ on $X$ (that is $\leq$ is a subset of $X^2$) which is reflexive and transitive. such a relation is called a preorder. Now, let us consider a similar object - a family of relations $\leq^\delta$ parametrized by $\delta\in[0,\infty)$ that satisfy the following properties: $x\leq^0 x$ for any $x\in X$, if $x\leq^\delta y$ and $y\leq^{\epsilon} z$ then $x\leq^{\delta+\epsilon} z$ for any $x,y,z\in X$. The first condition is obviously reflexivity, whereas the second can be understood as ""approximate transitivity"". It reminds of the triangular inequality. In fact, the function $$   d(x,y):=\inf\{\delta>0:x\leq^\delta y \text{ and }y\leq^\delta x\} $$ can be shown to be a pseudo-metric (a metric that can be zero outside of the diagonal). Is there any special name for the family $\leq^\delta$, or for its symmetrization $\approx^\delta$ where $$   x\approx^\delta y \iff x\leq^\delta y \text{ and }y\leq^\delta x. $$ Let me also mention that $\leq^0$ alone is a pre-order.",,"['general-topology', 'elementary-set-theory', 'metric-spaces', 'relations']"
74,The Theory of Probabilistic Sets,The Theory of Probabilistic Sets,,"${P}_m := \{ \Phi_{1m}, \Phi_{2m}, \ldots , \Phi_{nm} \}$  where $$|\Phi_{im} \rangle = \wp_{1m}  | \phi_1 \rangle + \wp_{2m} | \phi_{2m} \rangle + \cdots + \wp_{km} | \phi_{km} \rangle$$ such that $\wp_{im}$ is a probability amplitude for $\Phi_{im} \in \mathbb{P}_m$ being in it's $i^{th}$ state, $\phi_{im} $ Probability amplitudes are defined in such  a way that $|\wp_{1m}|^2 + |\wp_{2m}|^2 + \cdots + |\wp_{km}|^2 = 1$  and let $\mathbb{P}_m | i \rangle$ be the set $\mathbb{P}_m$ with each of its elements in the $i^{th}$ state. We define the sets to not be pairwise disjoint in the following way: Let $N$ be an index set such that $\forall m \in N$ let   $\mathbb{P}_m$ be a set. Therefore we have $$ \mathbb{P}_m \mid  \bigcap_{m \in N} \mathbb{P}_m | i \rangle\neq O$$ in other words  $\exists \phi_{i1} , \phi_{i2} , \ldots , \phi_{in} \in \mathbb{P}_1, \mathbb{P}_2, \ldots, \mathbb{P}_n  \mid \phi_{i1} \equiv \phi_{i2}  \equiv \cdots \equiv \phi_{in} $ The Mathematics of Probabilistic Sets A Probabilistic Set can be thought of as a set of normalised wave functions $\Phi_{im}$  that have at least one state in common and therefore have a finite probability of intersection. Union of Probabilistic Sets The union of probabilistic sets can be defined quite trivially as $$\bigcup_{m \in N} \mathbb{P}_m : = \{ \Phi_{11}, \Phi_{12}, \ldots, \Phi_{1N}, \Phi_{21}, \Phi_{22}, \ldots,  \Phi_{2N}, \ldots ,\Phi_{1n}, \Phi_{2n}, \ldots, \Phi_{nN} \}$$ Intersection of Probabilistic Sets It should be fairly clear that two probabilistic sets $\mathbb{P}_m$ and $\mathbb{P}_K$ do not have a well defined intersection. Instead we may discuss the \textit{probability} of two such sets intersecting. \  The probability of intersection of the probabilistic sets shall be denoted $$\mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big)$$  We can define $\Phi_{im} (\phi_{im})$ to be the wave function for $\Phi_{im}$ where $\phi_{im}  \equiv  [\alpha_i, \beta_i]$. So we define a state $\phi_{im}$ to be the corresponding interval $[\alpha_i,\beta_i]$ on the wave function $\Phi_{im} (\phi_{im})$. It now follows that the probability of finding the element $\Phi_{im}$ in the state $\phi_{im}$ is given by  $$ P_{\phi_{im} \in \Phi_{im}} = \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2$$ If only one such $\phi_{im}$ per set exists satisfying $\phi_{i1} , \phi_{i2} , \ldots , \phi_{in} \in \mathbb{P}_1, \mathbb{P}_2, \ldots, \mathbb{P}_n  \mid \phi_{i1} \equiv \phi_{i2}  \equiv \cdots \equiv \phi_{in} $, then the probability of the intersection of sets is given by  $$ \mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big) = \prod_{m \in N} \Big( \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2 \Big)_m$$  However if two such states are equivalent per set, call this second equivalent state $\phi_{jm}$ the probability becomes  $$  \mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big) = \prod_{m \in N} \Big( \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2  + \int_{\alpha_j}^{\beta_j} d \phi_{jm} \Big| \Phi_{jm} (\phi_{jm}) \Big|^2 \Big)_m$$ Now we extend this to the obvious case of: what if such elements share $\mathfrak{R}$ equivalent states? Well intuitively the probability of such an intersection occurring  approaches $1$ as $\mathfrak{R} \to n$. Trivially following from the previous two equations, the probability of intersection is given by  $$  \mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big) = \prod_{m \in N} \Big(  \sum_{\mathfrak{r} \leq \mathfrak{R}} \Big( \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2 \Big)_\mathfrak{r}  \Big)_m$$ Is everything I'm doing thus far correct? Is anything I'm doing thus far correct? I was just brainstorming ideas and this is what I came up with so I'd like to know if I'm right. Thanks Any input is appreciated","${P}_m := \{ \Phi_{1m}, \Phi_{2m}, \ldots , \Phi_{nm} \}$  where $$|\Phi_{im} \rangle = \wp_{1m}  | \phi_1 \rangle + \wp_{2m} | \phi_{2m} \rangle + \cdots + \wp_{km} | \phi_{km} \rangle$$ such that $\wp_{im}$ is a probability amplitude for $\Phi_{im} \in \mathbb{P}_m$ being in it's $i^{th}$ state, $\phi_{im} $ Probability amplitudes are defined in such  a way that $|\wp_{1m}|^2 + |\wp_{2m}|^2 + \cdots + |\wp_{km}|^2 = 1$  and let $\mathbb{P}_m | i \rangle$ be the set $\mathbb{P}_m$ with each of its elements in the $i^{th}$ state. We define the sets to not be pairwise disjoint in the following way: Let $N$ be an index set such that $\forall m \in N$ let   $\mathbb{P}_m$ be a set. Therefore we have $$ \mathbb{P}_m \mid  \bigcap_{m \in N} \mathbb{P}_m | i \rangle\neq O$$ in other words  $\exists \phi_{i1} , \phi_{i2} , \ldots , \phi_{in} \in \mathbb{P}_1, \mathbb{P}_2, \ldots, \mathbb{P}_n  \mid \phi_{i1} \equiv \phi_{i2}  \equiv \cdots \equiv \phi_{in} $ The Mathematics of Probabilistic Sets A Probabilistic Set can be thought of as a set of normalised wave functions $\Phi_{im}$  that have at least one state in common and therefore have a finite probability of intersection. Union of Probabilistic Sets The union of probabilistic sets can be defined quite trivially as $$\bigcup_{m \in N} \mathbb{P}_m : = \{ \Phi_{11}, \Phi_{12}, \ldots, \Phi_{1N}, \Phi_{21}, \Phi_{22}, \ldots,  \Phi_{2N}, \ldots ,\Phi_{1n}, \Phi_{2n}, \ldots, \Phi_{nN} \}$$ Intersection of Probabilistic Sets It should be fairly clear that two probabilistic sets $\mathbb{P}_m$ and $\mathbb{P}_K$ do not have a well defined intersection. Instead we may discuss the \textit{probability} of two such sets intersecting. \  The probability of intersection of the probabilistic sets shall be denoted $$\mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big)$$  We can define $\Phi_{im} (\phi_{im})$ to be the wave function for $\Phi_{im}$ where $\phi_{im}  \equiv  [\alpha_i, \beta_i]$. So we define a state $\phi_{im}$ to be the corresponding interval $[\alpha_i,\beta_i]$ on the wave function $\Phi_{im} (\phi_{im})$. It now follows that the probability of finding the element $\Phi_{im}$ in the state $\phi_{im}$ is given by  $$ P_{\phi_{im} \in \Phi_{im}} = \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2$$ If only one such $\phi_{im}$ per set exists satisfying $\phi_{i1} , \phi_{i2} , \ldots , \phi_{in} \in \mathbb{P}_1, \mathbb{P}_2, \ldots, \mathbb{P}_n  \mid \phi_{i1} \equiv \phi_{i2}  \equiv \cdots \equiv \phi_{in} $, then the probability of the intersection of sets is given by  $$ \mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big) = \prod_{m \in N} \Big( \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2 \Big)_m$$  However if two such states are equivalent per set, call this second equivalent state $\phi_{jm}$ the probability becomes  $$  \mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big) = \prod_{m \in N} \Big( \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2  + \int_{\alpha_j}^{\beta_j} d \phi_{jm} \Big| \Phi_{jm} (\phi_{jm}) \Big|^2 \Big)_m$$ Now we extend this to the obvious case of: what if such elements share $\mathfrak{R}$ equivalent states? Well intuitively the probability of such an intersection occurring  approaches $1$ as $\mathfrak{R} \to n$. Trivially following from the previous two equations, the probability of intersection is given by  $$  \mathcal{P} \Big( \bigcap_{m \in N} \mathbb{P}_m | i \rangle \Big) = \prod_{m \in N} \Big(  \sum_{\mathfrak{r} \leq \mathfrak{R}} \Big( \int_{\alpha_i}^{\beta_i} d \phi_{im} \Big| \Phi_{im} (\phi_{im}) \Big|^2 \Big)_\mathfrak{r}  \Big)_m$$ Is everything I'm doing thus far correct? Is anything I'm doing thus far correct? I was just brainstorming ideas and this is what I came up with so I'd like to know if I'm right. Thanks Any input is appreciated",,"['elementary-set-theory', 'mathematical-physics']"
75,How does the Tarski axiom relate to the Grothendieck universe?,How does the Tarski axiom relate to the Grothendieck universe?,,"It's claimed, e.g. in the formulation of Tarski–Grothendieck set theory , that the Tarski axiom implies that for every set, there is a Grothendieck universe containing it. However, I can't see how the Tarski axiom implies that the set which is being constructed is e.g. transitive. If $x$ is the set generating $U$ via the Tarski axiom and $x=\{y\}$. How do I show that $y\in U$? None of the points in Tarskis definition put elements of $x$ directly into $U$, only sets containing these. If we need some of the other axioms to do it, how?","It's claimed, e.g. in the formulation of Tarski–Grothendieck set theory , that the Tarski axiom implies that for every set, there is a Grothendieck universe containing it. However, I can't see how the Tarski axiom implies that the set which is being constructed is e.g. transitive. If $x$ is the set generating $U$ via the Tarski axiom and $x=\{y\}$. How do I show that $y\in U$? None of the points in Tarskis definition put elements of $x$ directly into $U$, only sets containing these. If we need some of the other axioms to do it, how?",,"['elementary-set-theory', 'foundations']"
76,"How can I prove $\sup(A+B)=\sup A+\sup B$ if $A+B=\{a+b\mid a\in A, b\in B\}$",How can I prove  if,"\sup(A+B)=\sup A+\sup B A+B=\{a+b\mid a\in A, b\in B\}","If $A,B$ non empty, upper bounded sets and $A+B=\{a+b\mid a\in A, b\in B\}$, how can I prove that $\sup(A+B)=\sup A+\sup B$?","If $A,B$ non empty, upper bounded sets and $A+B=\{a+b\mid a\in A, b\in B\}$, how can I prove that $\sup(A+B)=\sup A+\sup B$?",,"['real-analysis', 'supremum-and-infimum', 'sumset']"
77,One to one correspondence between transcendental and uncomputable numbers,One to one correspondence between transcendental and uncomputable numbers,,I know that both sets are uncountable infinite but the transcendentals are not a subset of the uncomputables. I don’t know if there exist uncomputable numbers that are not transcendental. But my question is whether the two sets have the same cardinality.,I know that both sets are uncountable infinite but the transcendentals are not a subset of the uncomputables. I don’t know if there exist uncomputable numbers that are not transcendental. But my question is whether the two sets have the same cardinality.,,"['elementary-set-theory', 'computability', 'transcendental-numbers']"
78,Problem understanding the concept of a union,Problem understanding the concept of a union,,"$A\cup B$ means that at least one of $A$, $B$ happens and $\bigcup_{k=n}^{\infty}A_k$ means that at least one of the events $A_k$ for $k\geq n$ happens. However, I am having trouble understanding this as intuitively I see $A\cup B$ as being a set that contains elements of BOTH $A$ and $B$ as it seems like $A\cup B$ contains elements in both $A$ and $B$. However, this is the definition of an intersection. Is there a way to intuitively understand why $\bigcup_{k=n}^{\infty}A_k$ implies least one of the events $A_k$ for $k\geq n$ happens? Would someone be able to give an intuitive example where we have $\bigcup_{k=n}^{\infty}A_k$ but ONLY one $A_k$ occurs? Thanks!","$A\cup B$ means that at least one of $A$, $B$ happens and $\bigcup_{k=n}^{\infty}A_k$ means that at least one of the events $A_k$ for $k\geq n$ happens. However, I am having trouble understanding this as intuitively I see $A\cup B$ as being a set that contains elements of BOTH $A$ and $B$ as it seems like $A\cup B$ contains elements in both $A$ and $B$. However, this is the definition of an intersection. Is there a way to intuitively understand why $\bigcup_{k=n}^{\infty}A_k$ implies least one of the events $A_k$ for $k\geq n$ happens? Would someone be able to give an intuitive example where we have $\bigcup_{k=n}^{\infty}A_k$ but ONLY one $A_k$ occurs? Thanks!",,['elementary-set-theory']
79,Can we have $x\in A$ and $x\in A\times B$?,Can we have  and ?,x\in A x\in A\times B,"Is it possible, for sets $A$ and $B$, to have $x\in A$ and $x\in A\times B$? It seems unlikely to me, but maybe some degenerate case? $x=\emptyset$?","Is it possible, for sets $A$ and $B$, to have $x\in A$ and $x\in A\times B$? It seems unlikely to me, but maybe some degenerate case? $x=\emptyset$?",,['elementary-set-theory']
80,What is the ordinal number for the set of binary strings ordered lexicographically?,What is the ordinal number for the set of binary strings ordered lexicographically?,,"Consider the set of all (finite) binary strings $\{0,1\}^*$ ordered lexicographically. What ordinal number corresponds to the ordering of this set? Does this ordinal have a nice closed-form/name?  If so, what is it?","Consider the set of all (finite) binary strings ordered lexicographically. What ordinal number corresponds to the ordering of this set? Does this ordinal have a nice closed-form/name?  If so, what is it?","\{0,1\}^*","['elementary-set-theory', 'ordinals']"
81,Cantor's Theorem Paradox? [closed],Cantor's Theorem Paradox? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 9 years ago . Improve this question Cantor's Theorem states that the cardinality of the power-set of any set is strictly greater than the cardinality of the set. That is to say, that you cannot establish a bijection between a set and its power-set. I seem to have found two counter-examples, and I would like to know what is my error. Let's consider the set of natural numbers plus zero, $N=\{0,1,2, ...\}$ and the set of powers of two, $B=\{2^0,2^1,2^2, ...\}$. It is trivial that $|N|=|B|$. You can easily establish a bijection $f$ between $N$ and $\mathcal{P}(B)$ by corresponding every natural number with its binary representation. $$f(0)\rightarrow \emptyset$$ $$f(1)\rightarrow \{{2^0\}}$$ $$f(2)\rightarrow \{{2^1\}}$$ $$f(3)\rightarrow \{{2^0,2^1\}}$$ $$f(4)\rightarrow \{{2^2\}}$$ $$f(5)\rightarrow \{{2^0,2^2\}}$$ ... and so on. This is a bijection because each natural number has a unique binary representation and any sum of powers of two equals a unique natural number. But this is not possible according to the Cantor's Theorem. (Note: In fact, in my exposition the bijection is between the set and the power-set of a subset, but it is trivially equivalent.) The other example is even worse and it is based on prime factorization. In this case I use the set of prime numbers, and I proceed in a similar way, but I establish a surjection between the power-set of the primes onto the naturals plus zero. Each natural number is corresponded with its prime factorization. In this case, each natural number has a unique prime factorization, but every subset of the prime number set is corresponded with infinite natural numbers as seen in the following examples: $$g(1)\rightarrow \emptyset$$ $$g(2)\rightarrow \{2\}$$ $$g(3)\rightarrow \{3\}$$ $$g(4=2^2)\rightarrow \{2\}$$ $$g(6=2\cdot3)\rightarrow \{2,3\}$$ Implying that $|\mathcal{P}(N)|<|N|$! Where is the problem?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 9 years ago . Improve this question Cantor's Theorem states that the cardinality of the power-set of any set is strictly greater than the cardinality of the set. That is to say, that you cannot establish a bijection between a set and its power-set. I seem to have found two counter-examples, and I would like to know what is my error. Let's consider the set of natural numbers plus zero, $N=\{0,1,2, ...\}$ and the set of powers of two, $B=\{2^0,2^1,2^2, ...\}$. It is trivial that $|N|=|B|$. You can easily establish a bijection $f$ between $N$ and $\mathcal{P}(B)$ by corresponding every natural number with its binary representation. $$f(0)\rightarrow \emptyset$$ $$f(1)\rightarrow \{{2^0\}}$$ $$f(2)\rightarrow \{{2^1\}}$$ $$f(3)\rightarrow \{{2^0,2^1\}}$$ $$f(4)\rightarrow \{{2^2\}}$$ $$f(5)\rightarrow \{{2^0,2^2\}}$$ ... and so on. This is a bijection because each natural number has a unique binary representation and any sum of powers of two equals a unique natural number. But this is not possible according to the Cantor's Theorem. (Note: In fact, in my exposition the bijection is between the set and the power-set of a subset, but it is trivially equivalent.) The other example is even worse and it is based on prime factorization. In this case I use the set of prime numbers, and I proceed in a similar way, but I establish a surjection between the power-set of the primes onto the naturals plus zero. Each natural number is corresponded with its prime factorization. In this case, each natural number has a unique prime factorization, but every subset of the prime number set is corresponded with infinite natural numbers as seen in the following examples: $$g(1)\rightarrow \emptyset$$ $$g(2)\rightarrow \{2\}$$ $$g(3)\rightarrow \{3\}$$ $$g(4=2^2)\rightarrow \{2\}$$ $$g(6=2\cdot3)\rightarrow \{2,3\}$$ Implying that $|\mathcal{P}(N)|<|N|$! Where is the problem?",,['elementary-set-theory']
82,When is the set statement: (A ∪ B) ⊆ (A ∩ B) true?,When is the set statement: (A ∪ B) ⊆ (A ∩ B) true?,,"""Where A is an arbitrary set and B is an arbitrary set, when is the statement: (A ∪ B) ⊆ (A ∩ B) true? Is it true all the time, sometimes, or is it never true? If it is sometimes true, explain the cases where it is."" Is there any other case aside from when A = B that this is a true statement?","""Where A is an arbitrary set and B is an arbitrary set, when is the statement: (A ∪ B) ⊆ (A ∩ B) true? Is it true all the time, sometimes, or is it never true? If it is sometimes true, explain the cases where it is."" Is there any other case aside from when A = B that this is a true statement?",,['elementary-set-theory']
83,Does a finite intersection (or union) generalise to an arbitrary one?,Does a finite intersection (or union) generalise to an arbitrary one?,,"Say we have a collection $\Omega$ of sets, and a statement $P(s)$ which can be either true or false depending on the input set $s$ . Say we take two arbitrary sets $a$ and $b$ in $\Omega$ and that for all $a,b\in\Omega$ , $P(a) \land P(b) \implies P(a \cap b)$ . Does this then imply that $\displaystyle \forall a\in\Omega\; P(a) \implies P\left(\bigcap_{s\in\Omega}s\right)$ ? Intuitively I can see how it would be true for collections with a finite or even countably infinite sizes, as you could just keep appending intersections with another element until you ""got them all"", like say if $\Omega = \{s_0,s_1,s_2,\cdots\}$ then you can do $$\displaystyle P(s_0) \Rightarrow P(s_0 \cap s_1) \Rightarrow P(s_0 \cap s_1 \cap s_2) \Rightarrow \cdots \Rightarrow P\left(\bigcap_{i\in\mathbb{N}}s_i\right)$$ but I don't necessarily know if this generalises to collections with uncountably infinite sizes since there really isn't that sort of inductive reasoning you can do to recursively append intersections when you're in the uncountably infinite. Does this intuitive implication hold true for collections of any size?","Say we have a collection of sets, and a statement which can be either true or false depending on the input set . Say we take two arbitrary sets and in and that for all , . Does this then imply that ? Intuitively I can see how it would be true for collections with a finite or even countably infinite sizes, as you could just keep appending intersections with another element until you ""got them all"", like say if then you can do but I don't necessarily know if this generalises to collections with uncountably infinite sizes since there really isn't that sort of inductive reasoning you can do to recursively append intersections when you're in the uncountably infinite. Does this intuitive implication hold true for collections of any size?","\Omega P(s) s a b \Omega a,b\in\Omega P(a) \land P(b) \implies P(a \cap b) \displaystyle \forall a\in\Omega\; P(a) \implies P\left(\bigcap_{s\in\Omega}s\right) \Omega = \{s_0,s_1,s_2,\cdots\} \displaystyle P(s_0) \Rightarrow P(s_0 \cap s_1) \Rightarrow P(s_0 \cap s_1 \cap s_2) \Rightarrow \cdots \Rightarrow P\left(\bigcap_{i\in\mathbb{N}}s_i\right)","['elementary-set-theory', 'set-theory']"
84,"How is the word ""contains"" defined in set theory? (In relation with neighborhoods in topology).","How is the word ""contains"" defined in set theory? (In relation with neighborhoods in topology).",,"From Wiki : Some basic sets of central importance are the empty set (the unique set containing no elements) Thus, this make me think that ""contained"" is equivalent to the $\in$, as in: if $a$ is contained in $X$, then we write $a \in X$. However, from this site: A neighborhood of $z$, which can be denoted $N_z$, is any subset of $S$ containing an open set of [the topological space] $T=(S,\tau)$ which itself contains $z$.   That is:   $$ \exists U \in \tau:z \in U \subseteq N_z \subseteq S $$ But shouldn't it actually be: $$ \exists U \in \tau:z \in U \ni N_z \subseteq S $$ because it says that $N_z$ contains an open set $U$? This is also consistent with the statement that $U$ contains $z$ which they write as $z \in U$. P.S. I'm only interested in set theory from an intuitive point of view and not from an axiomatic point of view.","From Wiki : Some basic sets of central importance are the empty set (the unique set containing no elements) Thus, this make me think that ""contained"" is equivalent to the $\in$, as in: if $a$ is contained in $X$, then we write $a \in X$. However, from this site: A neighborhood of $z$, which can be denoted $N_z$, is any subset of $S$ containing an open set of [the topological space] $T=(S,\tau)$ which itself contains $z$.   That is:   $$ \exists U \in \tau:z \in U \subseteq N_z \subseteq S $$ But shouldn't it actually be: $$ \exists U \in \tau:z \in U \ni N_z \subseteq S $$ because it says that $N_z$ contains an open set $U$? This is also consistent with the statement that $U$ contains $z$ which they write as $z \in U$. P.S. I'm only interested in set theory from an intuitive point of view and not from an axiomatic point of view.",,"['general-topology', 'elementary-set-theory', 'terminology', 'definition']"
85,Countable Intersection of Open Sets,Countable Intersection of Open Sets,,Is a countable intersection of open sets closed?,Is a countable intersection of open sets closed?,,"['general-topology', 'elementary-set-theory']"
86,"The ""elements"" of a real number","The ""elements"" of a real number",,"This question is essentially a paraphrase of a separate (deleted) question, which talks about a comment by Asaf Karagila about the ""elements of $\pi$ "". I'm aware of how natural numbers can be viewed as sets , so for example $3$ may be viewed as the set $\{\:\emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\:\}$ , so has elements $\emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}$ . This seems pretty concrete and natural. I can see that we can adapt this to deal with the integers, by for example adding in a second empty set as a ""marker"" element (so $-3$ corresponds to $\{\:\emptyset, \emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\:\}$ ). I can also see that we can adapt this ""marker"" idea to deal with the rational numbers (which are pairs of integers, and we ""mark"" the top one and the bottom one in a certain way). However, I am already getting nervous here as this seems much more synthetic than how we viewed the natural numbers. Anyway. It not clear to me how a number like $\pi$ or $e$ can have elements. One way might be to view these numbers as limits of sequences, and so as lists of rational numbers. However, this seems suspicious as these numbers are limits of multiples sequences, so this does not give me a canonical set which represents these numbers, but instead a family of sets. Is this OK, or is my reasoning broken? So what I want to ask is: What are the elements of $e$ ? Or, more subtly, does this question make sense, or should we remove the word ""the"" from it?","This question is essentially a paraphrase of a separate (deleted) question, which talks about a comment by Asaf Karagila about the ""elements of "". I'm aware of how natural numbers can be viewed as sets , so for example may be viewed as the set , so has elements . This seems pretty concrete and natural. I can see that we can adapt this to deal with the integers, by for example adding in a second empty set as a ""marker"" element (so corresponds to ). I can also see that we can adapt this ""marker"" idea to deal with the rational numbers (which are pairs of integers, and we ""mark"" the top one and the bottom one in a certain way). However, I am already getting nervous here as this seems much more synthetic than how we viewed the natural numbers. Anyway. It not clear to me how a number like or can have elements. One way might be to view these numbers as limits of sequences, and so as lists of rational numbers. However, this seems suspicious as these numbers are limits of multiples sequences, so this does not give me a canonical set which represents these numbers, but instead a family of sets. Is this OK, or is my reasoning broken? So what I want to ask is: What are the elements of ? Or, more subtly, does this question make sense, or should we remove the word ""the"" from it?","\pi 3 \{\:\emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\:\} \emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\} -3 \{\:\emptyset, \emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\:\} \pi e e",['elementary-set-theory']
87,Why Is $x \ne y$ Not Transitive on the Set of All integers?,Why Is  Not Transitive on the Set of All integers?,x \ne y,"I know this is a pretty simple question, but I'm just not getting the textbook... I'm taking a basic CS course and on one of the problems (not an assigned homework problem, just one I'm practicing on), it says that on the set of all integers, the relation $x \ne$ y is symmetric but not transitive where $(x,y) \in \Bbb R$. I understand why it's symmetric, but why is it not transitive? I'm thinking it has something to do with the definition of transitive including ALL $a,b,c \in A$, but I'm not sure. I understand transitive in the context of a finite set, but something about applying it to all integers is throwing me off.","I know this is a pretty simple question, but I'm just not getting the textbook... I'm taking a basic CS course and on one of the problems (not an assigned homework problem, just one I'm practicing on), it says that on the set of all integers, the relation $x \ne$ y is symmetric but not transitive where $(x,y) \in \Bbb R$. I understand why it's symmetric, but why is it not transitive? I'm thinking it has something to do with the definition of transitive including ALL $a,b,c \in A$, but I'm not sure. I understand transitive in the context of a finite set, but something about applying it to all integers is throwing me off.",,"['elementary-set-theory', 'relations']"
88,"How to prove $a \lt b$ for all $a \in A, b \in B$ implies $\sup A \leq \inf B$?",How to prove  for all  implies ?,"a \lt b a \in A, b \in B \sup A \leq \inf B","If $A, B$ are two non empty sets of real numbers and for every $a$ from $A$ and $b$ from $B$ $a < b$, how can I prove that $\sup A \leq \inf B$?","If $A, B$ are two non empty sets of real numbers and for every $a$ from $A$ and $b$ from $B$ $a < b$, how can I prove that $\sup A \leq \inf B$?",,"['real-analysis', 'elementary-set-theory', 'inequality', 'supremum-and-infimum']"
89,Why isn't Axiom of Choice a trivial result? Is it needed to prove existence of this recursive function?,Why isn't Axiom of Choice a trivial result? Is it needed to prove existence of this recursive function?,,"I mean, if we have the collection of sets $\mathcal{A}$ and we choose the set $B$ to contain only one element from each set in $\mathcal{A}$, then is quite trivial that $B\subseteq \bigcup_{A\in\mathcal{A}}A$. And this holds even if the sets in $\mathcal{A}$ are not pairwaise disjoint. Then it wouldn't be needed to assume it as an axiom. What is the error of this reasoning? In the other side, in Munkres' Topology 2nd Ed, he introduces this axiom when needs to proove the existence of an injection $f: \mathbb{Z}^{+} \rightarrow A$, for the infinite set $A$. So, let $a_1$ be an arbitrary element in $A$; when defining $f$ through induction as following $$ \begin{array}{l} f(1) = a_1 \\ f(n) = \textrm{arbitrary element of } A-f(\{1,2,...,n-1\}) \quad \textrm{; for }n>1 \end{array} $$ we can see there are infinite possible choices of the images $a_i$ that meets the above formula, then there exists at least one function $f$, which is injective because of its definition. Munkres uses the axiom of choice to satisfy the hyphotheses for the principle of recursive definition, so he can ensure such function (one which he defines with help of the function of choice) is unique. Although I cannot ensure this, I would say what I did is enough to prove the impication. Is this a valid argument, or is there any lack of rigor in it? Thanks in advance!","I mean, if we have the collection of sets $\mathcal{A}$ and we choose the set $B$ to contain only one element from each set in $\mathcal{A}$, then is quite trivial that $B\subseteq \bigcup_{A\in\mathcal{A}}A$. And this holds even if the sets in $\mathcal{A}$ are not pairwaise disjoint. Then it wouldn't be needed to assume it as an axiom. What is the error of this reasoning? In the other side, in Munkres' Topology 2nd Ed, he introduces this axiom when needs to proove the existence of an injection $f: \mathbb{Z}^{+} \rightarrow A$, for the infinite set $A$. So, let $a_1$ be an arbitrary element in $A$; when defining $f$ through induction as following $$ \begin{array}{l} f(1) = a_1 \\ f(n) = \textrm{arbitrary element of } A-f(\{1,2,...,n-1\}) \quad \textrm{; for }n>1 \end{array} $$ we can see there are infinite possible choices of the images $a_i$ that meets the above formula, then there exists at least one function $f$, which is injective because of its definition. Munkres uses the axiom of choice to satisfy the hyphotheses for the principle of recursive definition, so he can ensure such function (one which he defines with help of the function of choice) is unique. Although I cannot ensure this, I would say what I did is enough to prove the impication. Is this a valid argument, or is there any lack of rigor in it? Thanks in advance!",,"['elementary-set-theory', 'axiom-of-choice', 'alternative-proof']"
90,what is the cardinality of the injective functuons from R to R?,what is the cardinality of the injective functuons from R to R?,,"what is the cardinality of the injective functuons from R to R? lets say A={he injective functuons from R to R} obviously, A<= $2^א$ I have no Idea from which group I have to find an injective function to A to show (The Cantor-Schroeder-Bernstein theorem) that A=> $2^א$","what is the cardinality of the injective functuons from R to R? lets say A={he injective functuons from R to R} obviously, A<= I have no Idea from which group I have to find an injective function to A to show (The Cantor-Schroeder-Bernstein theorem) that A=>",2^א 2^א,"['elementary-set-theory', 'cardinals']"
91,Set theoretic difference $A-B$ contradicting $\emptyset \in B$?,Set theoretic difference  contradicting ?,A-B \emptyset \in B,"Set theoretic difference is defined as follows: Let $A,B$ be sets. Then the set theoretic difference of $A,B$ (written $A- B$ ) is the set defined by: $x \in A-B$ iff $x \in A$ and $x \notin B$ In the notes I'm studying, I came across an example that $\mathbb{N} - \mathbb{Z}=\emptyset$ . I realize that the point they're trying to get across is that the natural numbers are contained in the integers, but isn't it true that the empty set is in all sets? If so, does this not mean that $\emptyset \in A$ and $\emptyset \in B$ , which contradicts the definition? Sorry if this is too simple a question.","Set theoretic difference is defined as follows: Let be sets. Then the set theoretic difference of (written ) is the set defined by: iff and In the notes I'm studying, I came across an example that . I realize that the point they're trying to get across is that the natural numbers are contained in the integers, but isn't it true that the empty set is in all sets? If so, does this not mean that and , which contradicts the definition? Sorry if this is too simple a question.","A,B A,B A- B x \in A-B x \in A x \notin B \mathbb{N} - \mathbb{Z}=\emptyset \emptyset \in A \emptyset \in B",['elementary-set-theory']
92,Is infinite intersection empty if finite intersections are?,Is infinite intersection empty if finite intersections are?,,Suppose that $ A_1 \cap A_2 \cap \dots \cap A_n = \emptyset $ for all  $n \in \mathbb{N}$ Is it also true that $ A_1 \cap A_2 \cap \dots = \emptyset$ ? Could I have a hint as how to think about disproving this? (I'm assuming it's false with some fancy counterexample that I'm probably not going to guess...),Suppose that $ A_1 \cap A_2 \cap \dots \cap A_n = \emptyset $ for all  $n \in \mathbb{N}$ Is it also true that $ A_1 \cap A_2 \cap \dots = \emptyset$ ? Could I have a hint as how to think about disproving this? (I'm assuming it's false with some fancy counterexample that I'm probably not going to guess...),,['elementary-set-theory']
93,"If $A$ and $B$ are sets, then either $A \in B$ or $A\notin B$","If  and  are sets, then either  or",A B A \in B A\notin B,"Given that $A$ and $B$ are two sets, is the following proposition a tautology: $A\in B \vee A\notin B$. I do not know any set theory beyond the naive one.","Given that $A$ and $B$ are two sets, is the following proposition a tautology: $A\in B \vee A\notin B$. I do not know any set theory beyond the naive one.",,"['elementary-set-theory', 'logic']"
94,questions about well-order,questions about well-order,,"In Wikipedia , well-order is defined as a strict total order on a set $S$ with the property that every non-empty subset of $S$ has a least element in this ordering. But then later , well-order is defined as a total order on $S$ with the property that every non-empty subset of $S$ has a least element in this ordering. As far as I know, a total order and a strict total order are different. One is not the other. So I was wondering if well-order is defined for total order or strict total order or both? If for both, are they equivalent in the sense that if a total order is well-order, then its corresponding strict total order is also well-order? Vice versa? At the same Wikipedia page, it also says ""a well-ordering is a well-founded strict total order"". As I clicked into the definition of Well-founded_relation , it says ""a binary relation, $R$, is well-founded (or wellfounded) on a class $X$ if and only if every non-empty subset of $X$ has a minimal element with respect to $R$"". As minimal element is defined for partial order not for strict total order, is it true that well-founded order is a partial order and not a strict total order? So the aforementioned ""a well-ordering is a well-founded strict total order"" is not well-stated? Thanks and regards!","In Wikipedia , well-order is defined as a strict total order on a set $S$ with the property that every non-empty subset of $S$ has a least element in this ordering. But then later , well-order is defined as a total order on $S$ with the property that every non-empty subset of $S$ has a least element in this ordering. As far as I know, a total order and a strict total order are different. One is not the other. So I was wondering if well-order is defined for total order or strict total order or both? If for both, are they equivalent in the sense that if a total order is well-order, then its corresponding strict total order is also well-order? Vice versa? At the same Wikipedia page, it also says ""a well-ordering is a well-founded strict total order"". As I clicked into the definition of Well-founded_relation , it says ""a binary relation, $R$, is well-founded (or wellfounded) on a class $X$ if and only if every non-empty subset of $X$ has a minimal element with respect to $R$"". As minimal element is defined for partial order not for strict total order, is it true that well-founded order is a partial order and not a strict total order? So the aforementioned ""a well-ordering is a well-founded strict total order"" is not well-stated? Thanks and regards!",,"['elementary-set-theory', 'relations', 'order-theory', 'well-orders']"
95,Does the set of natural numbers contain infinity? [duplicate],Does the set of natural numbers contain infinity? [duplicate],,"This question already has answers here : Is aleph-$0$ a natural number? (2 answers) Closed 8 years ago . Let $N=\{1,2....\}$ be the set of naturals numbers. Is $\infty \in N$, as the list is never ending  ?","This question already has answers here : Is aleph-$0$ a natural number? (2 answers) Closed 8 years ago . Let $N=\{1,2....\}$ be the set of naturals numbers. Is $\infty \in N$, as the list is never ending  ?",,['elementary-set-theory']
96,Is $B = \{x:x \notin B\}$ a valid paradox in Naive Set Theory?,Is  a valid paradox in Naive Set Theory?,B = \{x:x \notin B\},"The version of Cantor's notion of sets that I've come across goes something like this: ""...collection of well defined, distinguishable objects of our intuition or of our thought to be conceived of as a whole. The objects are called the members of the set..."" With Russell's paradox $B = \{x:x \notin x\}$, I understand the mistake is assuming the collection $B$ is a set (i.e. if by sets we mean a collection which has the membership relation with its elements). The paradox shows not all collections are sets. So far I haven't seen any paradox phrased like this: $B = \{x:x \notin B\}$? It seems slightly different from Russell's paradox in that the question isn't so much about whether $B$ is a collection which is also a set, but whether $B$ is a collection at all. Is this formulation allowed in Cantor's notion of sets, where it must satisfy the criterion of being  well defined? Thanks!","The version of Cantor's notion of sets that I've come across goes something like this: ""...collection of well defined, distinguishable objects of our intuition or of our thought to be conceived of as a whole. The objects are called the members of the set..."" With Russell's paradox $B = \{x:x \notin x\}$, I understand the mistake is assuming the collection $B$ is a set (i.e. if by sets we mean a collection which has the membership relation with its elements). The paradox shows not all collections are sets. So far I haven't seen any paradox phrased like this: $B = \{x:x \notin B\}$? It seems slightly different from Russell's paradox in that the question isn't so much about whether $B$ is a collection which is also a set, but whether $B$ is a collection at all. Is this formulation allowed in Cantor's notion of sets, where it must satisfy the criterion of being  well defined? Thanks!",,"['elementary-set-theory', 'paradoxes']"
97,"Partition of a set, definition not clear","Partition of a set, definition not clear",,"From wikipedia: Equivalently, a set P is a partition of X if, and only if, it does not contain the empty set and: The union of the elements of P is equal to X. (The elements of P are said to cover X.) The intersection of any two distinct elements of P is empty. (We say the elements of P are pairwise disjoint.) I clearly understand that the intersection between partition is empty (point 2), but how can the union of a partition can be the all elements in the set? If it is a partition, shouldnt they be just a part? I imagine a set divided in 3 and the elements in the first part are not all the elements of the second part. How do you explain this?","From wikipedia: Equivalently, a set P is a partition of X if, and only if, it does not contain the empty set and: The union of the elements of P is equal to X. (The elements of P are said to cover X.) The intersection of any two distinct elements of P is empty. (We say the elements of P are pairwise disjoint.) I clearly understand that the intersection between partition is empty (point 2), but how can the union of a partition can be the all elements in the set? If it is a partition, shouldnt they be just a part? I imagine a set divided in 3 and the elements in the first part are not all the elements of the second part. How do you explain this?",,"['elementary-set-theory', 'definition', 'set-partition']"
98,Variables as place-holders and the set builder notation,Variables as place-holders and the set builder notation,,"In logic, variables don't have a meaning by themselves. They simply hold the place in an expression where the names of objects could be present. Adopting this placeholder viewpoint, I'm having trouble interpreting the set builder notation. Consider, for instance, the set of all natural numbers less than 10, denoted in the set builder notation as $$\{x:x<10\}$$ A common interpretation of this notation is The set of all x such that x is less than 10 This interpretation IMO doesn't go well with the placeholder viewpoint of variables, as when we replace ' x ' by say '2', we get the expression The set of all 2 such that 2 is less than 10 which doesn't make sense. So my question is how should I interpret $\{x:x<10\}$ from a placeholder viewpoint of variables? I can understand only the $x<10$ part from the placeholder viewpoint of variables as it is clearly an open sentence that gives a statement upon replacement of 'x' by appropriate constants. As an extension of this question, a similar issue arises when the domain of 'x' is specified in the set builder notation as: $$\{x \in N :x<10\}$$ This is often interpreted as The set of all x in N such that x is less than 10 Adopting the placeholder viewpoint, replacing 'x' by say '3' yields, The set of all 3 in N such that 3 is less than 10 Again only the '3 is less than 10' part of the expression makes sense.","In logic, variables don't have a meaning by themselves. They simply hold the place in an expression where the names of objects could be present. Adopting this placeholder viewpoint, I'm having trouble interpreting the set builder notation. Consider, for instance, the set of all natural numbers less than 10, denoted in the set builder notation as A common interpretation of this notation is The set of all x such that x is less than 10 This interpretation IMO doesn't go well with the placeholder viewpoint of variables, as when we replace ' x ' by say '2', we get the expression The set of all 2 such that 2 is less than 10 which doesn't make sense. So my question is how should I interpret from a placeholder viewpoint of variables? I can understand only the part from the placeholder viewpoint of variables as it is clearly an open sentence that gives a statement upon replacement of 'x' by appropriate constants. As an extension of this question, a similar issue arises when the domain of 'x' is specified in the set builder notation as: This is often interpreted as The set of all x in N such that x is less than 10 Adopting the placeholder viewpoint, replacing 'x' by say '3' yields, The set of all 3 in N such that 3 is less than 10 Again only the '3 is less than 10' part of the expression makes sense.",\{x:x<10\} \{x:x<10\} x<10 \{x \in N :x<10\},"['elementary-set-theory', 'logic', 'predicate-logic']"
99,B is an element of some power set of A such that A is an element of F.,B is an element of some power set of A such that A is an element of F.,,"$$B \in \{\,\mathcal P(A) \mid A \in F\,\}$$ I can't quite figure this out. My textbook says this statement is equivalent to $$\exists A \in F\ \forall x\ (x \in B \leftrightarrow \forall y\ (y \in x \rightarrow y \in A))$$ How do you derive the last statement from the first? And how would you read this in a natural language?","$$B \in \{\,\mathcal P(A) \mid A \in F\,\}$$ I can't quite figure this out. My textbook says this statement is equivalent to $$\exists A \in F\ \forall x\ (x \in B \leftrightarrow \forall y\ (y \in x \rightarrow y \in A))$$ How do you derive the last statement from the first? And how would you read this in a natural language?",,"['elementary-set-theory', 'quantifiers']"
