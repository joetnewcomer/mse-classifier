,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What is the probability of having a cycle in an directed Erdős-Rényi graph?,What is the probability of having a cycle in an directed Erdős-Rényi graph?,,"In a Erdős-Rényi graph $G_{n,1/n}$, i.e., $n$ nodes and each arc is formed independently with probability $1/n$, what is the probability that it has at least one cycle? I did refer to Erdős and Rényi's ON THE EVOLUTION OF RANDOM GRAPHS ( https://www.renyi.hu/~p_erdos/1960-10.pdf ). Although it talks about a non-directed graph, I believe the means should be the same. However, I don't really follow the proof of theorem 5b, in which they mention ""an obvious sieve"". I can show that the number of $k$ cycles follows a Poisson distribution with expectation asymptotically $1/k$. Of course, here two cycles are not independent so that the Poisson distributions do not add. And all the literature I found stops with finding the expectation of the total number of cycles, which I know is $\sum 1/k$. A simulation reveals that the probability is asymptotically 1, which I think is obvious since the dependence between cycles should be small. But I fail to find a way to give a precise proof. Can anyone give some hint?? Thanks!","In a Erdős-Rényi graph $G_{n,1/n}$, i.e., $n$ nodes and each arc is formed independently with probability $1/n$, what is the probability that it has at least one cycle? I did refer to Erdős and Rényi's ON THE EVOLUTION OF RANDOM GRAPHS ( https://www.renyi.hu/~p_erdos/1960-10.pdf ). Although it talks about a non-directed graph, I believe the means should be the same. However, I don't really follow the proof of theorem 5b, in which they mention ""an obvious sieve"". I can show that the number of $k$ cycles follows a Poisson distribution with expectation asymptotically $1/k$. Of course, here two cycles are not independent so that the Poisson distributions do not add. And all the literature I found stops with finding the expectation of the total number of cycles, which I know is $\sum 1/k$. A simulation reveals that the probability is asymptotically 1, which I think is obvious since the dependence between cycles should be small. But I fail to find a way to give a precise proof. Can anyone give some hint?? Thanks!",,"['probability', 'graph-theory', 'random-graphs']"
1,Iterated self convolution approaches gaussian. What is a good explanation / proof for this?,Iterated self convolution approaches gaussian. What is a good explanation / proof for this?,,"If we define convolution to be: $$(f_1 * f_2)(t) = \int_{-\infty}^{\infty}f_1(t)f_2(\tau -t)d\tau$$ For many functions $f$, iterated self convolution $(f*f*\cdots*f)(t)$ tends to create functions increasingly close to Gaussian - closer as the number of convolutions increase: $$g(x) = Ke^{-\frac{(x-\mu)^2}{\sigma^2}}$$ It is well known in many contexts. For example sums of Independent and Identically Distributed (IID) random variables in probability and behavior of filter in signals and systems. What is your favorite way to explain / show this?","If we define convolution to be: $$(f_1 * f_2)(t) = \int_{-\infty}^{\infty}f_1(t)f_2(\tau -t)d\tau$$ For many functions $f$, iterated self convolution $(f*f*\cdots*f)(t)$ tends to create functions increasingly close to Gaussian - closer as the number of convolutions increase: $$g(x) = Ke^{-\frac{(x-\mu)^2}{\sigma^2}}$$ It is well known in many contexts. For example sums of Independent and Identically Distributed (IID) random variables in probability and behavior of filter in signals and systems. What is your favorite way to explain / show this?",,"['probability', 'functional-analysis', 'analysis', 'fourier-analysis', 'convolution']"
2,Probability of decreasing random structures,Probability of decreasing random structures,,"Given that we have $N$ consecutive structures that can have a maximum height of $H$, where the individual height $h_i$ depends on random coin flips (for each structure, an additional height has a probability of 0.5. The probability is given by $p(h_i=x) = 0.5^{x + 1}$, except when $x=H$, then we get $p(h_i=x)=0.5^H$ Now I want to know, given $H$, what is the probability of having a random set of $N$ structures, where each structure is followed by another structure with the same height or less? Visual Representation Probabilities and possible structures +---+  +---+  +---+       +---+ 0.5^x     H   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+                ...    ...    ...         ...               +---+  +---+  +---+       +---+ 0.0625    3   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ 0.125     2   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ 0.25      1   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ 0.5       0   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ p(h_i=x)  h_i   1      2      3    ...    N Structures that satisfy the search criteria with N = 3, H = 2 (the zero height-level is always present) (1) +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (2) +---+ |   | +---+  +---+ |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (3) +---+ |   | +---+ |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (4) +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ ... Structures that do not satisfy the search criteria N = 3, H = 2 (again, the zero-level is present for all structures) (1) +---+         +---+ |   |         |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (2) +---+ |   | +---+         +---+ |   |         |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (3) +---+ |   | +---+         +---+ |   |         |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (4) +---+               |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ ... Partial Solution To my understanding (not a math-major), the first part (all structures having the same height-level) can be calculated by $$ p(\mbox{all same level}) = \sum_{i=1}^H 0.5^{i*n} $$ But I fail to see a possibility to calculate the second part (structures with decreasing levels). Any help is greatly appreciated. Background The solution to this problem finds the probability of having a Skip List with the worst setup, resulting in a search-time of $O(n)$ instead of $O(log(n))$ (and thus also an insertion- and deletion time of $O(n)$). Edit/Addition: Building the levels of the Structures As there are some discussions in the comments, I wanted to elaborate on the process that determines the height of each structure. The general idea is to toss a coin multiple times. If we get heads (1) that means we add a level, if we get tails (0) that means we leave the structure at the current level and move to the next structure. In pseudo-code, we would express the algorithm like this lvl = 0 while coin_flip() == heads:     lvl = lvl + 1 Addition 2: Sampled probabilities Inspired by Jens code, I wrote my own c++-function that runs 1mil. simulations per setting and computes the probabilities. You can run the code and experiment with it here: http://cpp.sh/5vtpl (alternative link at GitHub Gist ). So far I have gotten the following results Running 1000000 simulations each: ----------------------------------- N =   2 & H =  3 | chance = 0.671773 N =   3 & H =  3 | chance = 0.387352 N =   4 & H =  3 | chance = 0.208013 N =   5 & H =  3 | chance = 0.107015 N =   6 & H =  3 | chance = 0.054868 N =   7 & H =  3 | chance = 0.027476 N =   8 & H =  3 | chance = 0.013878 N =   9 & H =  3 | chance = 0.006773 N =  10 & H =  3 | chance = 0.003364 N =  11 & H =  3 | chance = 0.001791 N =  12 & H =  3 | chance = 0.000869 N =  13 & H =  3 | chance = 0.000439 N =  14 & H =  3 | chance = 0.000218 N =  15 & H =  3 | chance = 0.000139 N =  16 & H =  3 | chance = 0.000047 N =  17 & H =  3 | chance = 0.000022 N =  18 & H =  3 | chance = 0.000013 N =  19 & H =  3 | chance = 0.000009","Given that we have $N$ consecutive structures that can have a maximum height of $H$, where the individual height $h_i$ depends on random coin flips (for each structure, an additional height has a probability of 0.5. The probability is given by $p(h_i=x) = 0.5^{x + 1}$, except when $x=H$, then we get $p(h_i=x)=0.5^H$ Now I want to know, given $H$, what is the probability of having a random set of $N$ structures, where each structure is followed by another structure with the same height or less? Visual Representation Probabilities and possible structures +---+  +---+  +---+       +---+ 0.5^x     H   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+                ...    ...    ...         ...               +---+  +---+  +---+       +---+ 0.0625    3   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ 0.125     2   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ 0.25      1   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ 0.5       0   |   |  |   |  |   |  ...  |   |               +---+  +---+  +---+       +---+ p(h_i=x)  h_i   1      2      3    ...    N Structures that satisfy the search criteria with N = 3, H = 2 (the zero height-level is always present) (1) +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (2) +---+ |   | +---+  +---+ |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (3) +---+ |   | +---+ |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (4) +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ ... Structures that do not satisfy the search criteria N = 3, H = 2 (again, the zero-level is present for all structures) (1) +---+         +---+ |   |         |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (2) +---+ |   | +---+         +---+ |   |         |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (3) +---+ |   | +---+         +---+ |   |         |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ (4) +---+               |   | +---+  +---+  +---+ |   |  |   |  |   | +---+  +---+  +---+ ... Partial Solution To my understanding (not a math-major), the first part (all structures having the same height-level) can be calculated by $$ p(\mbox{all same level}) = \sum_{i=1}^H 0.5^{i*n} $$ But I fail to see a possibility to calculate the second part (structures with decreasing levels). Any help is greatly appreciated. Background The solution to this problem finds the probability of having a Skip List with the worst setup, resulting in a search-time of $O(n)$ instead of $O(log(n))$ (and thus also an insertion- and deletion time of $O(n)$). Edit/Addition: Building the levels of the Structures As there are some discussions in the comments, I wanted to elaborate on the process that determines the height of each structure. The general idea is to toss a coin multiple times. If we get heads (1) that means we add a level, if we get tails (0) that means we leave the structure at the current level and move to the next structure. In pseudo-code, we would express the algorithm like this lvl = 0 while coin_flip() == heads:     lvl = lvl + 1 Addition 2: Sampled probabilities Inspired by Jens code, I wrote my own c++-function that runs 1mil. simulations per setting and computes the probabilities. You can run the code and experiment with it here: http://cpp.sh/5vtpl (alternative link at GitHub Gist ). So far I have gotten the following results Running 1000000 simulations each: ----------------------------------- N =   2 & H =  3 | chance = 0.671773 N =   3 & H =  3 | chance = 0.387352 N =   4 & H =  3 | chance = 0.208013 N =   5 & H =  3 | chance = 0.107015 N =   6 & H =  3 | chance = 0.054868 N =   7 & H =  3 | chance = 0.027476 N =   8 & H =  3 | chance = 0.013878 N =   9 & H =  3 | chance = 0.006773 N =  10 & H =  3 | chance = 0.003364 N =  11 & H =  3 | chance = 0.001791 N =  12 & H =  3 | chance = 0.000869 N =  13 & H =  3 | chance = 0.000439 N =  14 & H =  3 | chance = 0.000218 N =  15 & H =  3 | chance = 0.000139 N =  16 & H =  3 | chance = 0.000047 N =  17 & H =  3 | chance = 0.000022 N =  18 & H =  3 | chance = 0.000013 N =  19 & H =  3 | chance = 0.000009",,['probability']
3,How to calculate expected value of an absolute sum,How to calculate expected value of an absolute sum,,"If I have two independent variables $x$ and $y$ with a uniform distribution between -1 and 1. How would I calculate the expected value of their absolute sum. e.g. $E(|x + y|)$ I wrote some code to brute force this here https://jsbin.com/xorixa/edit?js,console The result comes out to be $2/3$ but my question is how would I go about calculating this.","If I have two independent variables $x$ and $y$ with a uniform distribution between -1 and 1. How would I calculate the expected value of their absolute sum. e.g. $E(|x + y|)$ I wrote some code to brute force this here https://jsbin.com/xorixa/edit?js,console The result comes out to be $2/3$ but my question is how would I go about calculating this.",,"['probability', 'statistics']"
4,Probability of being a palindrome?,Probability of being a palindrome?,,"I often see how people points out that a certain number is a palindrome in some base, the implication being that it is somewhat a special number. Of course such considerations are rather subjective, but that made me wondering; is it the property of being a palindrome so rare ? To be precise: What is the probability that a given natural number $n$ is a palindrome in at least one base $b\in\{2,3,\ldots,10\}$? What about if we let $b\in\{2,3,\ldots,n-2\}$? For those who might be bothered for the use of ""probability that a given natural number"": You can understand that I am asking about the natural density of palindromes, with the above precisions. I just stated the question as it is because I might content myself with some simulation or insight on the subject (the reason being that I haven't found much about this on the web and couldn't come up with an answer myself, so just in case it is harder than expected...), and because of future readers who might also be intrigued about this and don't know about natural density.","I often see how people points out that a certain number is a palindrome in some base, the implication being that it is somewhat a special number. Of course such considerations are rather subjective, but that made me wondering; is it the property of being a palindrome so rare ? To be precise: What is the probability that a given natural number $n$ is a palindrome in at least one base $b\in\{2,3,\ldots,10\}$? What about if we let $b\in\{2,3,\ldots,n-2\}$? For those who might be bothered for the use of ""probability that a given natural number"": You can understand that I am asking about the natural density of palindromes, with the above precisions. I just stated the question as it is because I might content myself with some simulation or insight on the subject (the reason being that I haven't found much about this on the web and couldn't come up with an answer myself, so just in case it is harder than expected...), and because of future readers who might also be intrigued about this and don't know about natural density.",,['probability']
5,broken stick : average of the ratio of the shortest piece to the largest piece,broken stick : average of the ratio of the shortest piece to the largest piece,,"Frederick Mosteller , 'Fifty challenging problems of probability', Q.42 If a stick is broken in 2 at random, what is the average ratio of the smaller length to the larger ? the answer is given as: Breaking 'at random' means that all points of the stick are equally likely as a breaking point (uniform distribution).  We might suppose that the point fell in the right half. Then $\frac{1-x}{x}$ is the fraction of the stick if the stick is of unit length. Since $x$ is evenly distributed from $1 \over 2$ to $1$ the average value - instead of the intuitive $1 \over 3$ - is:  $$ 2 \int_{1 \over 2}^{1} \frac {1-x}{x}dx = 2 \ln(2)-1 \approx 0.386$$ I don't understand this. Why don't I need to somehow derive the probability density of the ratio of the 2 uniform random variables involved, and then integrate: $$ 2 \int_{1 \over 2}^{1} \frac {1-x}{x}\  \text{pdf_of_the_ratio}(x) \ dx =?$$","Frederick Mosteller , 'Fifty challenging problems of probability', Q.42 If a stick is broken in 2 at random, what is the average ratio of the smaller length to the larger ? the answer is given as: Breaking 'at random' means that all points of the stick are equally likely as a breaking point (uniform distribution).  We might suppose that the point fell in the right half. Then $\frac{1-x}{x}$ is the fraction of the stick if the stick is of unit length. Since $x$ is evenly distributed from $1 \over 2$ to $1$ the average value - instead of the intuitive $1 \over 3$ - is:  $$ 2 \int_{1 \over 2}^{1} \frac {1-x}{x}dx = 2 \ln(2)-1 \approx 0.386$$ I don't understand this. Why don't I need to somehow derive the probability density of the ratio of the 2 uniform random variables involved, and then integrate: $$ 2 \int_{1 \over 2}^{1} \frac {1-x}{x}\  \text{pdf_of_the_ratio}(x) \ dx =?$$",,"['probability', 'puzzle']"
6,Is a convex combination of conditional probabilities the conditional probability of a convex combination of unconditional probabilities?,Is a convex combination of conditional probabilities the conditional probability of a convex combination of unconditional probabilities?,,"Let $P_1,...,P_k$ be probability measures on $(\Omega, \mathcal{F})$, and let $E \in \mathcal{F}$ with $P_i(E) > 0$, $i=1...k$. Suppose $\beta_i \geq 0$, $i=1,...,k$, and $\sum_{i=1}^k \beta_i = 1$. Then, $\sum_{i=1}^k \beta_i P_i(\cdot \mid E)$ defines a probability measure on $(\Omega, \mathcal{F})$, because each conditional probability $P_i(\cdot \mid E)$ is a probability measure and a convex combination of probabilities is a probability. My question is whether $\sum_{i=1}^k \beta_i P_i(\cdot \mid E)$ can be expressed as the conditional probability, given $E$, of a convex combination of $P_1,...,P_k$. Question. Does there exist $\alpha_i \geq 0$, $i=1,...,k$, with $\sum_{i=1}^k \alpha_i = 1$ such that $(\sum_{i=1}^k \alpha_i P_i)(\cdot \mid E) = \sum_{i=1}^k \beta_i P_i(\cdot \mid E)$? I believe the answer is yes because I think I can verify the case $i=2$ by a brute force calculation that I won't reproduce here (it's quite messy and, I think, not very instructive). The trouble is, I get the feeling that I'm missing some basic fact or observation that would answer my question in a more elegant and illuminating way.","Let $P_1,...,P_k$ be probability measures on $(\Omega, \mathcal{F})$, and let $E \in \mathcal{F}$ with $P_i(E) > 0$, $i=1...k$. Suppose $\beta_i \geq 0$, $i=1,...,k$, and $\sum_{i=1}^k \beta_i = 1$. Then, $\sum_{i=1}^k \beta_i P_i(\cdot \mid E)$ defines a probability measure on $(\Omega, \mathcal{F})$, because each conditional probability $P_i(\cdot \mid E)$ is a probability measure and a convex combination of probabilities is a probability. My question is whether $\sum_{i=1}^k \beta_i P_i(\cdot \mid E)$ can be expressed as the conditional probability, given $E$, of a convex combination of $P_1,...,P_k$. Question. Does there exist $\alpha_i \geq 0$, $i=1,...,k$, with $\sum_{i=1}^k \alpha_i = 1$ such that $(\sum_{i=1}^k \alpha_i P_i)(\cdot \mid E) = \sum_{i=1}^k \beta_i P_i(\cdot \mid E)$? I believe the answer is yes because I think I can verify the case $i=2$ by a brute force calculation that I won't reproduce here (it's quite messy and, I think, not very instructive). The trouble is, I get the feeling that I'm missing some basic fact or observation that would answer my question in a more elegant and illuminating way.",,"['probability', 'probability-theory', 'convex-hulls']"
7,How do I maximize entropy?,How do I maximize entropy?,,"In the book on probability I am reading, I am asked to prove that the entropy of $X$ is maximized when $X$ is uniformly distributed. At first I came up empty and decided to check online. Most proofs made use of the AM-GM inequality which the book did not cover, so I was wondering if I could come up with a proof that relied on only things in the book. I try using the fact that  $$\begin{align} \ln x \le x-1 <x&\Rightarrow -x\ln x > -x^2 \\ &\Rightarrow -\sum_i p_i\ln p_i >- \sum_i p_i^2 \\ &\Rightarrow H(X) >-  \sum_i p_i^2 \end{align}$$ To maximize $H(x)$ we should maximize $F(\mathbf {p} )=-\sum_i p_i^2$ subject to the constraint $g(\mathbf {p} )=\sum_i p_i=1$. Using the method of Lagrange multipliers, we get that $p_i=p_j \quad \forall i\ne j$. I would like to know if this argument is correct or if there are easier ways to prove the result given that the book assumes knowledge of differential equations, multivariable calculus and linear algebra. I was also wondering if I could apply the method of Lagrange Multipliers to the entropy itself.","In the book on probability I am reading, I am asked to prove that the entropy of $X$ is maximized when $X$ is uniformly distributed. At first I came up empty and decided to check online. Most proofs made use of the AM-GM inequality which the book did not cover, so I was wondering if I could come up with a proof that relied on only things in the book. I try using the fact that  $$\begin{align} \ln x \le x-1 <x&\Rightarrow -x\ln x > -x^2 \\ &\Rightarrow -\sum_i p_i\ln p_i >- \sum_i p_i^2 \\ &\Rightarrow H(X) >-  \sum_i p_i^2 \end{align}$$ To maximize $H(x)$ we should maximize $F(\mathbf {p} )=-\sum_i p_i^2$ subject to the constraint $g(\mathbf {p} )=\sum_i p_i=1$. Using the method of Lagrange multipliers, we get that $p_i=p_j \quad \forall i\ne j$. I would like to know if this argument is correct or if there are easier ways to prove the result given that the book assumes knowledge of differential equations, multivariable calculus and linear algebra. I was also wondering if I could apply the method of Lagrange Multipliers to the entropy itself.",,"['probability', 'proof-verification', 'entropy']"
8,"Compute $E(X\mid X+Y)$ if $(X,Y)$ is centered normal with known covariance matrix [closed]",Compute  if  is centered normal with known covariance matrix [closed],"E(X\mid X+Y) (X,Y)","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question The random variable $(X,Y)$ has a two dimensional normal distribution with mean $(0,0)$ and covariance matrix $\begin{pmatrix}  4&2 \\   2&2  \end{pmatrix}$. Find $E(X\mid X+Y)$. I am completely lost with this question.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question The random variable $(X,Y)$ has a two dimensional normal distribution with mean $(0,0)$ and covariance matrix $\begin{pmatrix}  4&2 \\   2&2  \end{pmatrix}$. Find $E(X\mid X+Y)$. I am completely lost with this question.",,"['probability', 'covariance']"
9,Convolution of PDFs is a PDF,Convolution of PDFs is a PDF,,"Suppose $f$ and $g$ are PDFs of real-valued random variables. Show that the convolution $f\ast g$ of $f$ and $g$ (defined below) is also a PDF.   $$(f\ast g)(x)=\int_{-\infty}^\infty f(y)g(x-y)\,dy.$$ Firstly, I am not certain exactly what I need to show. In the text, we started with a random variable and defined from that the PDF, and then observed that it had the property that its integral over $\Bbb{R}$ was $1$. For this reason I am thinking that if I can show $\int_\Bbb{R} (f\ast g)(x)\,dx=1$, then I will be done. Would the following be sufficient to prove that the convolution is a PDF? \begin{align} \int_{-\infty}^\infty\int_{-\infty}^\infty f(y)g(x-y)\,dy\,dx  &= \int_{-\infty}^\infty f(y)\bigg(\int_{-\infty}^\infty g(x-y)\,dx\bigg)\,dy\\ &= \int_{-\infty}^\infty f(y)\cdot1\,dy =1, \end{align} Using that $f$ and $g$ are PDFs in the bottom line.","Suppose $f$ and $g$ are PDFs of real-valued random variables. Show that the convolution $f\ast g$ of $f$ and $g$ (defined below) is also a PDF.   $$(f\ast g)(x)=\int_{-\infty}^\infty f(y)g(x-y)\,dy.$$ Firstly, I am not certain exactly what I need to show. In the text, we started with a random variable and defined from that the PDF, and then observed that it had the property that its integral over $\Bbb{R}$ was $1$. For this reason I am thinking that if I can show $\int_\Bbb{R} (f\ast g)(x)\,dx=1$, then I will be done. Would the following be sufficient to prove that the convolution is a PDF? \begin{align} \int_{-\infty}^\infty\int_{-\infty}^\infty f(y)g(x-y)\,dy\,dx  &= \int_{-\infty}^\infty f(y)\bigg(\int_{-\infty}^\infty g(x-y)\,dx\bigg)\,dy\\ &= \int_{-\infty}^\infty f(y)\cdot1\,dy =1, \end{align} Using that $f$ and $g$ are PDFs in the bottom line.",,"['probability', 'proof-verification', 'random-variables']"
10,What is the expected number of steps in a random walk from leaf to leaf in a full binary tree?,What is the expected number of steps in a random walk from leaf to leaf in a full binary tree?,,"Let $h \geq 2$ be a natural number. Consider a complete binary tree of height $h$. Say we take a random walk starting from the ""leftmost"" leaf. What is the expected number of steps before the ""rightmost"" leaf is visited? Is there a known closed form for this? If not, are there any lower or upper bounds? As an example, let $h = 3$. Then we are looking at the above tree and asking what the expected number of steps to walk from node 4 to node 7 is. What I've found: Denote $n = 2^h - 1$ to be the number of nodes in the tree. This problem can be viewed as a system of linear equations. Let $x_i$ denote the expected number of steps to walk from node $i$ to node $n$. We are trying to find $x_{(n+1)/2}$ in the system $$ \begin{cases}   x_1 = 1 + \frac{1}{2}x_2 + \frac{1}{2}x_3 \\   x_i = 1 + \frac{1}{3}x_{\lfloor i/2 \rfloor} + \frac{1}{3}x_{2i} + \frac{1}{3}x_{2i+1} & \text{for } 1 < i < \frac{n+1}{2} \\   x_i = 1 + x_{\lfloor i/2 \rfloor} & \text{for } \frac{n+1}{2} \leq i < n \\   x_n = 0. \end{cases} $$ I wrote a Python program to solve this system. I found the following values: $$ \begin{array}{c|c} h & \text{expected number of steps} \\ \hline 2 & 4 \\ \hline 3 & 24 \\ \hline 4 & 84 \\ \hline 5 & 240 \\ \hline 6 & 620 \\ \hline 7 & 1512 \\ \hline 8 & 3556 \\ \hline 9 & 8160 \\ \hline 10 & 18396 \end{array} $$ I plugged these values into OEIS, but there was no matching sequence. Although I do not know how to solve for an exact value, I can provide a lower bound of $2^{h+1} - 3h - 1$. Note that a walk from the leftmost leaf to the rightmost leaf must pass through the root. Therefore, we can lower bound the desired value by the expected number of steps before the root is visited in a random walk starting from the leftmost leaf. Then we are just asking how many steps it takes to randomly walk from a node at level $h$ to the root node at level $1$. At level $h$, you always step to level $h-1$. At level $i$ where $1 < i < h$, you have a $\frac{2}{3}$ chance of stepping to a child at level $i+1$ and a $\frac{1}{3}$ chance of stepping to the parent at level $i-1$. Let $x_i$ denote the expected number of steps to randomly walk from level $h-i+1$ to level 1. We are then trying to find $x_1$ in the system of equations $$ \begin{cases} x_h = 0\\ x_i = 1 + \frac{2}{3}x_{i-1} + \frac{1}{3}x_{i+1} & \text{for } 1 < i < h\\ x_1 = 1 + x_2. \end{cases} $$ I claim that $x_{i-1} = x_i + 2^i - 3$ for $1 < i \leq n$. Proceed by induction. As the case case, we have $x_1 = x_2 + 1 = x_2 + 2^2 - 3$. For the induction hypothesis, suppose that $x_{k-1} = x_k + 2^k - 3$. Then for our induction step, we have $$ \begin{align*}   x_k &= 1 + \frac{2}{3}x_{k-1} + \frac{1}{3}x_{k+1} \\       &= 1 + \frac{2}{3}\left(x_k + 2^k - 3\right) + \frac{1}{3}x_{k+1} \end{align*} $$ which rearranges to $x_k = x_{k+1} + 2^{k+1} - 3$, proving the claim. Then we have $$ x_1 = \sum_{i=2}^h \left( 2^i - 3 \right) = 2^{h+1} - 3h - 1. $$ Hence the expected number of steps to reach the root from a leaf is $2^{h+1} - 3h - 1$. This gives our lower bound. I do not know where to go from here. Looking at the numbers, I suspect one might be able to prove a $\Omega(h2^h)$ lower bound.","Let $h \geq 2$ be a natural number. Consider a complete binary tree of height $h$. Say we take a random walk starting from the ""leftmost"" leaf. What is the expected number of steps before the ""rightmost"" leaf is visited? Is there a known closed form for this? If not, are there any lower or upper bounds? As an example, let $h = 3$. Then we are looking at the above tree and asking what the expected number of steps to walk from node 4 to node 7 is. What I've found: Denote $n = 2^h - 1$ to be the number of nodes in the tree. This problem can be viewed as a system of linear equations. Let $x_i$ denote the expected number of steps to walk from node $i$ to node $n$. We are trying to find $x_{(n+1)/2}$ in the system $$ \begin{cases}   x_1 = 1 + \frac{1}{2}x_2 + \frac{1}{2}x_3 \\   x_i = 1 + \frac{1}{3}x_{\lfloor i/2 \rfloor} + \frac{1}{3}x_{2i} + \frac{1}{3}x_{2i+1} & \text{for } 1 < i < \frac{n+1}{2} \\   x_i = 1 + x_{\lfloor i/2 \rfloor} & \text{for } \frac{n+1}{2} \leq i < n \\   x_n = 0. \end{cases} $$ I wrote a Python program to solve this system. I found the following values: $$ \begin{array}{c|c} h & \text{expected number of steps} \\ \hline 2 & 4 \\ \hline 3 & 24 \\ \hline 4 & 84 \\ \hline 5 & 240 \\ \hline 6 & 620 \\ \hline 7 & 1512 \\ \hline 8 & 3556 \\ \hline 9 & 8160 \\ \hline 10 & 18396 \end{array} $$ I plugged these values into OEIS, but there was no matching sequence. Although I do not know how to solve for an exact value, I can provide a lower bound of $2^{h+1} - 3h - 1$. Note that a walk from the leftmost leaf to the rightmost leaf must pass through the root. Therefore, we can lower bound the desired value by the expected number of steps before the root is visited in a random walk starting from the leftmost leaf. Then we are just asking how many steps it takes to randomly walk from a node at level $h$ to the root node at level $1$. At level $h$, you always step to level $h-1$. At level $i$ where $1 < i < h$, you have a $\frac{2}{3}$ chance of stepping to a child at level $i+1$ and a $\frac{1}{3}$ chance of stepping to the parent at level $i-1$. Let $x_i$ denote the expected number of steps to randomly walk from level $h-i+1$ to level 1. We are then trying to find $x_1$ in the system of equations $$ \begin{cases} x_h = 0\\ x_i = 1 + \frac{2}{3}x_{i-1} + \frac{1}{3}x_{i+1} & \text{for } 1 < i < h\\ x_1 = 1 + x_2. \end{cases} $$ I claim that $x_{i-1} = x_i + 2^i - 3$ for $1 < i \leq n$. Proceed by induction. As the case case, we have $x_1 = x_2 + 1 = x_2 + 2^2 - 3$. For the induction hypothesis, suppose that $x_{k-1} = x_k + 2^k - 3$. Then for our induction step, we have $$ \begin{align*}   x_k &= 1 + \frac{2}{3}x_{k-1} + \frac{1}{3}x_{k+1} \\       &= 1 + \frac{2}{3}\left(x_k + 2^k - 3\right) + \frac{1}{3}x_{k+1} \end{align*} $$ which rearranges to $x_k = x_{k+1} + 2^{k+1} - 3$, proving the claim. Then we have $$ x_1 = \sum_{i=2}^h \left( 2^i - 3 \right) = 2^{h+1} - 3h - 1. $$ Hence the expected number of steps to reach the root from a leaf is $2^{h+1} - 3h - 1$. This gives our lower bound. I do not know where to go from here. Looking at the numbers, I suspect one might be able to prove a $\Omega(h2^h)$ lower bound.",,"['probability', 'markov-chains', 'random-walk']"
11,Probability that out of 600 crabs 60 are still alive after 9 months.,Probability that out of 600 crabs 60 are still alive after 9 months.,,"A crabs' life expectancy can be modeled exponentially, and a crab lives 3 months on average. I am absolutely not sure about this, because there is nothing concerning this in our book, so I guess it was meant to be solved in some obvious/easy fashion, here's what I tried: If it were only one crab, I could simply plug 9 into $\lambda e^{-\lambda x}$ , where $\lambda=1/3$ . $60$ is $10\%$ of $600$ , so maybe I need to look after what time 90% died, intuitively I would resort to $$1-e^{-x/3}=0.9$$ $$0.1=e^{-x/3}$$ and so on, which would give me $\approx 6.9$ months, and then do something about the remaining $2.1$ months. The last thing I was thinking of is to calculate the probability for 540 crabs dying at some point before the 9 month mark, and then taking the converse probability, but that I'd only know how to do with the help of a computer.","A crabs' life expectancy can be modeled exponentially, and a crab lives 3 months on average. I am absolutely not sure about this, because there is nothing concerning this in our book, so I guess it was meant to be solved in some obvious/easy fashion, here's what I tried: If it were only one crab, I could simply plug 9 into , where . is of , so maybe I need to look after what time 90% died, intuitively I would resort to and so on, which would give me months, and then do something about the remaining months. The last thing I was thinking of is to calculate the probability for 540 crabs dying at some point before the 9 month mark, and then taking the converse probability, but that I'd only know how to do with the help of a computer.",\lambda e^{-\lambda x} \lambda=1/3 60 10\% 600 1-e^{-x/3}=0.9 0.1=e^{-x/3} \approx 6.9 2.1,['probability']
12,What is the probability that a pokemon gets frozen within 3 turns using ice beam?,What is the probability that a pokemon gets frozen within 3 turns using ice beam?,,"Ice beam is a pokemon move that has a 10% chance to freeze the enemy pokemon each turn.  What is the probability that I freeze the enemy pokemon if I have 3 turns? On one hand 'logically' the answer should be 30% On the other hand, if we add up all the cases we get 27.1%: (1) Freeze on the first turn 10% (2) Freeze on the second turn, but not the first: 90% * 10% (3) Freeze on the third turn, but not the first/second: 90% * 90% * 10% What is the correct way to go about this? Also, I observe that both methods are very close to each other.  Is it generally true that the probability of an event firing within N turns is the same (or very close to) as the probability of the event firing * N?","Ice beam is a pokemon move that has a 10% chance to freeze the enemy pokemon each turn.  What is the probability that I freeze the enemy pokemon if I have 3 turns? On one hand 'logically' the answer should be 30% On the other hand, if we add up all the cases we get 27.1%: (1) Freeze on the first turn 10% (2) Freeze on the second turn, but not the first: 90% * 10% (3) Freeze on the third turn, but not the first/second: 90% * 90% * 10% What is the correct way to go about this? Also, I observe that both methods are very close to each other.  Is it generally true that the probability of an event firing within N turns is the same (or very close to) as the probability of the event firing * N?",,['probability']
13,How to test if vectors are equidistributed on the unit sphere,How to test if vectors are equidistributed on the unit sphere,,I can create a large collection of normalized real valued $n$-dimensional vectors from some random process which I hypothesis should be equidistributed on the unit sphere.  I would like to test this hypothesis. What is a good way numerically to test if vectors are equidistributed on the unit sphere? I am writing computer code so I will be testing that way Is there some way to visualise the distribution given that my vectors are in $n$ dimensions?,I can create a large collection of normalized real valued $n$-dimensional vectors from some random process which I hypothesis should be equidistributed on the unit sphere.  I would like to test this hypothesis. What is a good way numerically to test if vectors are equidistributed on the unit sphere? I am writing computer code so I will be testing that way Is there some way to visualise the distribution given that my vectors are in $n$ dimensions?,,['probability']
14,How to calculate the expected value of the Powerball Lottery?,How to calculate the expected value of the Powerball Lottery?,,"The current Powerball jackpot is at roughly 675 million USD and the chances of winning with one random ticket is 1 in 292.2 million. Each ticket costs 2 USD. From a general perspective, it appears that the Powerball lottery tickets have a positive expected value but we didn't include all the other factors yet. If we decide to take the entire winnings at once instead of getting paid over 30 years, we should be expecting to receive 428 million before taxes. Then we have to include both state and (25%) federal tax which shaves off at least another 100 million for the United States. Then we would also have to include the possible of the Powerball having multiple winners. We could estimate how many people will purchase tickets for the next drawing based on how many purchased for the last one. Lastly, we would also have to factor in the cost of maintenance for this large amount of money. How can we go about calculating our expected value when purchasing a ticket in hopes of hitting the jackpot? Do these tickets truly give us a positive return at its current price? Source for Powerball statistics","The current Powerball jackpot is at roughly 675 million USD and the chances of winning with one random ticket is 1 in 292.2 million. Each ticket costs 2 USD. From a general perspective, it appears that the Powerball lottery tickets have a positive expected value but we didn't include all the other factors yet. If we decide to take the entire winnings at once instead of getting paid over 30 years, we should be expecting to receive 428 million before taxes. Then we have to include both state and (25%) federal tax which shaves off at least another 100 million for the United States. Then we would also have to include the possible of the Powerball having multiple winners. We could estimate how many people will purchase tickets for the next drawing based on how many purchased for the last one. Lastly, we would also have to factor in the cost of maintenance for this large amount of money. How can we go about calculating our expected value when purchasing a ticket in hopes of hitting the jackpot? Do these tickets truly give us a positive return at its current price? Source for Powerball statistics",,"['probability', 'sequences-and-series']"
15,Why are odds of a coin landing heads $50\%$ after $'n'$ consecutive heads,Why are odds of a coin landing heads  after  consecutive heads,50\% 'n',"I'm trying to understand how the odds of flipping a fair coin $4$ times in a row and landing heads each time is $\frac{1}{2^4}=\frac{1}{16}=6.25\%$; But at the same time if I've just flipped the coin heads $3$ times my odds of it landing heads a fourth time are $50\%.$ These numbers seem to contradict one another. I think I figured it out when I was writing this question, but wanted to confirm. Of the 16 possible ways that $4$ coin flips can go, $2$ have $3$ consecutive heads (below). So if I flip heads $3$ times and am about to flip it a fourth, there are two possible outcomes: $$ % inner array of minimum values \begin{array}{c|cccc} \text{series} & 1 & 2 & 3 & 4\\ \hline 1 & T & T & T & T\\ ... & ... & ... & ... & ...\\ 15 & H & H & H & T\\ 16 & H & H & H & H \end{array} $$ making the probability of getting a fourth head $= \frac{1 outcome}{2 possibilities} = 50\%$. Is this correct?","I'm trying to understand how the odds of flipping a fair coin $4$ times in a row and landing heads each time is $\frac{1}{2^4}=\frac{1}{16}=6.25\%$; But at the same time if I've just flipped the coin heads $3$ times my odds of it landing heads a fourth time are $50\%.$ These numbers seem to contradict one another. I think I figured it out when I was writing this question, but wanted to confirm. Of the 16 possible ways that $4$ coin flips can go, $2$ have $3$ consecutive heads (below). So if I flip heads $3$ times and am about to flip it a fourth, there are two possible outcomes: $$ % inner array of minimum values \begin{array}{c|cccc} \text{series} & 1 & 2 & 3 & 4\\ \hline 1 & T & T & T & T\\ ... & ... & ... & ... & ...\\ 15 & H & H & H & T\\ 16 & H & H & H & H \end{array} $$ making the probability of getting a fourth head $= \frac{1 outcome}{2 possibilities} = 50\%$. Is this correct?",,"['probability', 'gambling']"
16,Expected value for the number of tries to draw the black ball from the bag,Expected value for the number of tries to draw the black ball from the bag,,"We have a bag with $4$ white balls and $1$ black ball. We are drawing balls without replacement. Find expected value for the number of tries to  draw the black ball from the bag. Progress. The probability to draw a black ball from first trial is $1/5$. The problem is how to find the probability to draw black ball from $2$nd, $3$rd, $ \ldots, 5$th trial. When I know all this probabilities I can find expected value as $1\cdot(1/5) + 2 p_2 + \dots + 5 p_5$.","We have a bag with $4$ white balls and $1$ black ball. We are drawing balls without replacement. Find expected value for the number of tries to  draw the black ball from the bag. Progress. The probability to draw a black ball from first trial is $1/5$. The problem is how to find the probability to draw black ball from $2$nd, $3$rd, $ \ldots, 5$th trial. When I know all this probabilities I can find expected value as $1\cdot(1/5) + 2 p_2 + \dots + 5 p_5$.",,"['probability', 'balls-in-bins']"
17,Show that if $a_n(X_n-X) \overset{\mathcal{D}}\to Z$ then $X_n \overset{P}\to X$.,Show that if  then .,a_n(X_n-X) \overset{\mathcal{D}}\to Z X_n \overset{P}\to X,"Let $(a_n)\subseteq \Bbb{R}$ be a sequence such that $a_n \to \infty$ . Let $(X_n)$ be a sequence of random variables such that $a_n(X_n-X) \overset{\mathcal{D}}\to Z$ fore some random variables $X$ and $Z$ . Show that $X_n \overset{P}\to X$ . So I have some sort of Idea why should this happen. Since $a_n \to \infty$ for $a_n(X_n - X)$ to have a ""finite"" limit, say $Z$ , then $X_n - X \to 0$ somehow. (The excercise says that the convergence must be in probability.) But Im having a lot of trouble in making this ideas more precise. I've tried with characteristic functions for the convergence in distribution. Got to nothing. Any hint?","Let be a sequence such that . Let be a sequence of random variables such that fore some random variables and . Show that . So I have some sort of Idea why should this happen. Since for to have a ""finite"" limit, say , then somehow. (The excercise says that the convergence must be in probability.) But Im having a lot of trouble in making this ideas more precise. I've tried with characteristic functions for the convergence in distribution. Got to nothing. Any hint?",(a_n)\subseteq \Bbb{R} a_n \to \infty (X_n) a_n(X_n-X) \overset{\mathcal{D}}\to Z X Z X_n \overset{P}\to X a_n \to \infty a_n(X_n - X) Z X_n - X \to 0,"['probability', 'probability-theory', 'random-variables', 'characteristic-functions']"
18,Finding the probability mass function given the cumulative distribution function,Finding the probability mass function given the cumulative distribution function,,"Suppose that the cumulative distribution function of a random variable X is given by $ F(a) =  \begin{cases}      0,& a < 0 \\     1/5, & 0 \leq a < 2 \\     2/5, & 2 \leq a < 4 \\     1, & a \geq 4  \end{cases} $ Find the probability mass function of X? My reasoning is as follows: The cdf is discontinuous at the points 0, 2, and 4. Between these $F'(a)$ is defined and $=0$, hence the pmf needs definition only at these points. But how do we get the probabilities at a = 0, 2, 4?","Suppose that the cumulative distribution function of a random variable X is given by $ F(a) =  \begin{cases}      0,& a < 0 \\     1/5, & 0 \leq a < 2 \\     2/5, & 2 \leq a < 4 \\     1, & a \geq 4  \end{cases} $ Find the probability mass function of X? My reasoning is as follows: The cdf is discontinuous at the points 0, 2, and 4. Between these $F'(a)$ is defined and $=0$, hence the pmf needs definition only at these points. But how do we get the probabilities at a = 0, 2, 4?",,"['probability', 'probability-distributions']"
19,Quantile(X + constant) = Quantile(X) + constant?,Quantile(X + constant) = Quantile(X) + constant?,,"I would like to 'prove' that $$q_{\alpha}(X + c) = q_{\alpha}(X) + c $$ For c  $\in \Bbb{R}$, $X$ a random variable, and $q_{\alpha}$ the quantile of order ${\alpha}$. I would actually like to prove this for conditional quantile (but I think it does not really impact the proof). I saw the 'equivariance of quantile under monotone transformation' property, which is a way stronger property (and I did not find any proof for this either anyway), so I think that $q_{\alpha}(X + c) = q_{\alpha}(X) + c $ is true (or maybe there are some particular cases in which it does not hold? I cannot think of any). The only problem is I don't know how to prove it. To me it seems quite intuitive, but I'm not sure I am allowed to write this without proving it (and there might be some special case I'm not thinking of). I would also appreciate if anyone got a link to a formal proof of the equivariance of quantile under monotone transformation. Thanks in advance.","I would like to 'prove' that $$q_{\alpha}(X + c) = q_{\alpha}(X) + c $$ For c  $\in \Bbb{R}$, $X$ a random variable, and $q_{\alpha}$ the quantile of order ${\alpha}$. I would actually like to prove this for conditional quantile (but I think it does not really impact the proof). I saw the 'equivariance of quantile under monotone transformation' property, which is a way stronger property (and I did not find any proof for this either anyway), so I think that $q_{\alpha}(X + c) = q_{\alpha}(X) + c $ is true (or maybe there are some particular cases in which it does not hold? I cannot think of any). The only problem is I don't know how to prove it. To me it seems quite intuitive, but I'm not sure I am allowed to write this without proving it (and there might be some special case I'm not thinking of). I would also appreciate if anyone got a link to a formal proof of the equivariance of quantile under monotone transformation. Thanks in advance.",,"['probability', 'probability-distributions', 'quantile']"
20,Proof of chain rule for entropy of random variables,Proof of chain rule for entropy of random variables,,"I have the following proof for the chain rule for entropy of random variables: We write: \begin{eqnarray*} H(X_1,X_2,...,X_n)&=&-\sum\limits_{x_1,x_2,...,x_n}p(x_1,x_2,...,x_n)logp(x_1,x_2,...,x_n) \\&=&-\sum\limits_{x_1,x_2,...,x_n}p(x_1,x_2,...,x_n)log\prod\limits_{i=1}^{n}p(x_i|x_{i-1},...,x_1) \\&=&-\sum\limits_{x_1,x_2,...,x_n}\sum\limits_{i=1}^n p(x_1,x_2,...,x_n)logp(x_i|x_{i-1},...,x_1) \\&=&-\sum\limits_{x_1,x_2,...,x_i}\sum\limits_{i=1}^n p(x_1,x_2,...,x_n)logp(x_i|x_{i-1},...,x_1) \\&=&\sum\limits_{i=1}^n H(X_i|X_{i-1},...,X_1) \end{eqnarray*} Basically, I have 2 questions: first how we get from line 1 to line 2. Is it some kind of Markov property? And second, why the summation lower boundary changes in line 4?","I have the following proof for the chain rule for entropy of random variables: We write: \begin{eqnarray*} H(X_1,X_2,...,X_n)&=&-\sum\limits_{x_1,x_2,...,x_n}p(x_1,x_2,...,x_n)logp(x_1,x_2,...,x_n) \\&=&-\sum\limits_{x_1,x_2,...,x_n}p(x_1,x_2,...,x_n)log\prod\limits_{i=1}^{n}p(x_i|x_{i-1},...,x_1) \\&=&-\sum\limits_{x_1,x_2,...,x_n}\sum\limits_{i=1}^n p(x_1,x_2,...,x_n)logp(x_i|x_{i-1},...,x_1) \\&=&-\sum\limits_{x_1,x_2,...,x_i}\sum\limits_{i=1}^n p(x_1,x_2,...,x_n)logp(x_i|x_{i-1},...,x_1) \\&=&\sum\limits_{i=1}^n H(X_i|X_{i-1},...,X_1) \end{eqnarray*} Basically, I have 2 questions: first how we get from line 1 to line 2. Is it some kind of Markov property? And second, why the summation lower boundary changes in line 4?",,"['probability', 'summation', 'random-variables', 'entropy']"
21,Confusing probability problems based on product rule and combinations,Confusing probability problems based on product rule and combinations,,"I am going thru probability exercise. Faced first problem: Book Q1. Ten tickets are numbered 1,2,3,...,10. Six tickets are selected at random one at a time with replacement . What is the probability the largest number appearing on the selected tickets is 7? My logic: if one of six tickets should be 7, the $\color{red}{\text{remaining 5}}$ can be any of 1 to 7, so it should be $7^5$. But turns out that the given solution is $\frac{7^6-6^6}{10^6}$. My Q1. Though I understood the logic behind $\frac{7^6-6^6}{10^6}$, I was wondering what is exact logical mistake with $7^5$? I guessed that $7^5$ completely ignores what should be 6th ticket, it only puts restriction on 5 tickets. Is it like that? Then I came across similar but more involved problem, with significant difference from above one that it performs action without replacement: Book Q2. Three numbers are chosen at random without replacement from (1,2,3,...,10). What is the probability that the minimum number is 3 or the maximum number is 7? My logic: Noticing that this is without replacement, I guessed the solution should be  $$ = \begin{pmatrix}  \text{selections with}\\  \text{minimum}\\  \text{number is 3}  \end{pmatrix} + \begin{pmatrix}  \text{selections with}\\  \text{maximum}\\  \text{number is 7}  \end{pmatrix}  - \begin{pmatrix}  \text{selections with}\\  \text{maximum}\\  \text{number is 7}\\  \text{and minimum}\\  \text{number is 3}  \end{pmatrix}  $$ $$= \frac{ \overbrace{(\binom{8}{3}-\binom{7}{3})}^{\text{#selections with min 3}} + \overbrace{(\binom{7}{3}-\binom{6}{3})}^{\text{#selections with max 7}} - \overbrace{3\times {^3P_3}}^{\text{#selections with max 7 and min 3}} } {\binom{10}{3} } $$ But the book solutions says: P(minimum 3) or P(maximum 7) P(minimum 3) $=\frac{\binom{7}{2}}{\binom{10}{3}}=\frac{21}{120}$ P(max 7) $=\frac{\binom{6}{2}}{\binom{10}{2}}=\frac{15}{120}$ Thus the solution is $\frac{11}{40}$ My Q2. How even by books logic the solution $\frac{11}{40}$ is achieved. I am unable to understand it as I find the explanation insufficient. My Q3. If book Q2 answer is correct then why for book Q1 solution is not $7^5$ which is what I initially guessed (because the only difference being with / without replacement, the logic of getting $\color{red}{\text{remaining m}}$ stuffs out n should remain same)? My Q4. If we make first question without replacement, will the solution be $\frac{\binom{7}{6}-\binom{6}{6}}{\binom{10}{6}}$? My Q5. What will be the solution if we make book Q2 with replacement? My Q6. Where my logic for solution to Book's Q2 is wrong?","I am going thru probability exercise. Faced first problem: Book Q1. Ten tickets are numbered 1,2,3,...,10. Six tickets are selected at random one at a time with replacement . What is the probability the largest number appearing on the selected tickets is 7? My logic: if one of six tickets should be 7, the $\color{red}{\text{remaining 5}}$ can be any of 1 to 7, so it should be $7^5$. But turns out that the given solution is $\frac{7^6-6^6}{10^6}$. My Q1. Though I understood the logic behind $\frac{7^6-6^6}{10^6}$, I was wondering what is exact logical mistake with $7^5$? I guessed that $7^5$ completely ignores what should be 6th ticket, it only puts restriction on 5 tickets. Is it like that? Then I came across similar but more involved problem, with significant difference from above one that it performs action without replacement: Book Q2. Three numbers are chosen at random without replacement from (1,2,3,...,10). What is the probability that the minimum number is 3 or the maximum number is 7? My logic: Noticing that this is without replacement, I guessed the solution should be  $$ = \begin{pmatrix}  \text{selections with}\\  \text{minimum}\\  \text{number is 3}  \end{pmatrix} + \begin{pmatrix}  \text{selections with}\\  \text{maximum}\\  \text{number is 7}  \end{pmatrix}  - \begin{pmatrix}  \text{selections with}\\  \text{maximum}\\  \text{number is 7}\\  \text{and minimum}\\  \text{number is 3}  \end{pmatrix}  $$ $$= \frac{ \overbrace{(\binom{8}{3}-\binom{7}{3})}^{\text{#selections with min 3}} + \overbrace{(\binom{7}{3}-\binom{6}{3})}^{\text{#selections with max 7}} - \overbrace{3\times {^3P_3}}^{\text{#selections with max 7 and min 3}} } {\binom{10}{3} } $$ But the book solutions says: P(minimum 3) or P(maximum 7) P(minimum 3) $=\frac{\binom{7}{2}}{\binom{10}{3}}=\frac{21}{120}$ P(max 7) $=\frac{\binom{6}{2}}{\binom{10}{2}}=\frac{15}{120}$ Thus the solution is $\frac{11}{40}$ My Q2. How even by books logic the solution $\frac{11}{40}$ is achieved. I am unable to understand it as I find the explanation insufficient. My Q3. If book Q2 answer is correct then why for book Q1 solution is not $7^5$ which is what I initially guessed (because the only difference being with / without replacement, the logic of getting $\color{red}{\text{remaining m}}$ stuffs out n should remain same)? My Q4. If we make first question without replacement, will the solution be $\frac{\binom{7}{6}-\binom{6}{6}}{\binom{10}{6}}$? My Q5. What will be the solution if we make book Q2 with replacement? My Q6. Where my logic for solution to Book's Q2 is wrong?",,"['probability', 'combinatorics']"
22,Law of Large Numbers - utility/difficulty of various versions.,Law of Large Numbers - utility/difficulty of various versions.,,"This may or may not be an answer to Is there an easy proof that the set of $x \in [0,1]$ whose limit of proportion of 1's in binary expansion of $x$ does not exist has measure zero? , depending on how easy a proof has to be to count as easy. The law of large numbers comes in various versions: LLN${}_p$ Suppose $X_1,\dots$ are iid with $\Bbb EX_1=0$ and $\Bbb E|X_1|^p<\infty$. Then $\frac1n(X_1+\dots+X_n)\to0$ almost surely. Proving LLN${}_1$ is considerably harder than proving LLN${}_2$. My impression is that this gives LLN${}_2$ a higher utility/difficulty ratio, since it suffices for many applications. Seems to me that LLN${}_4$ has yet a much higher utility/difficulty ratio. There's an awesomely easy proof of LLN${}_4$. The obligatory question then is this: Question Are there a lot of standard probability distributions out there, that actually come up, that give $\Bbb E X^4=\infty$ but $\Bbb E X^2<\infty$? Hoping for an answer to that question is why I'm posting this. The idea that people might be amused by the proof of LLN${}_4$ is absolutely no part of my motivation, I swear; that would not be a legal reason for this post's existence. Of course you need to see the proof I have in mind in order to evaluate that utility/difficulty ratio: Say $S_n = X_1+\dots+X_n$. Multiply out the product $S_n^4$: $$S_n^4=\sum X_{j_1}X_{j_2}X_{j_3}X_{j_4}.$$Independence shows that most of those terms have mean $0$; the only terms with non-zero mean are of the form $X_j^4$ or a ""permutation"" of $X_j^2X_k^2$. A trivial bit of combinatorics shows then that $$\Bbb ES_n^4\le cn^2.$$ Monotone convergence shows that $$\Bbb E\left[\sum\left(\frac 1n S_n\right)^4\right]<\infty.$$Hence $\sum\left(\frac 1n S_n\right)^4<\infty$ almost surely, so $\frac1nS_n\to0$ almost surely. (Note I'm not claiming to be smart here; I saw this somewhere many years ago.)","This may or may not be an answer to Is there an easy proof that the set of $x \in [0,1]$ whose limit of proportion of 1's in binary expansion of $x$ does not exist has measure zero? , depending on how easy a proof has to be to count as easy. The law of large numbers comes in various versions: LLN${}_p$ Suppose $X_1,\dots$ are iid with $\Bbb EX_1=0$ and $\Bbb E|X_1|^p<\infty$. Then $\frac1n(X_1+\dots+X_n)\to0$ almost surely. Proving LLN${}_1$ is considerably harder than proving LLN${}_2$. My impression is that this gives LLN${}_2$ a higher utility/difficulty ratio, since it suffices for many applications. Seems to me that LLN${}_4$ has yet a much higher utility/difficulty ratio. There's an awesomely easy proof of LLN${}_4$. The obligatory question then is this: Question Are there a lot of standard probability distributions out there, that actually come up, that give $\Bbb E X^4=\infty$ but $\Bbb E X^2<\infty$? Hoping for an answer to that question is why I'm posting this. The idea that people might be amused by the proof of LLN${}_4$ is absolutely no part of my motivation, I swear; that would not be a legal reason for this post's existence. Of course you need to see the proof I have in mind in order to evaluate that utility/difficulty ratio: Say $S_n = X_1+\dots+X_n$. Multiply out the product $S_n^4$: $$S_n^4=\sum X_{j_1}X_{j_2}X_{j_3}X_{j_4}.$$Independence shows that most of those terms have mean $0$; the only terms with non-zero mean are of the form $X_j^4$ or a ""permutation"" of $X_j^2X_k^2$. A trivial bit of combinatorics shows then that $$\Bbb ES_n^4\le cn^2.$$ Monotone convergence shows that $$\Bbb E\left[\sum\left(\frac 1n S_n\right)^4\right]<\infty.$$Hence $\sum\left(\frac 1n S_n\right)^4<\infty$ almost surely, so $\frac1nS_n\to0$ almost surely. (Note I'm not claiming to be smart here; I saw this somewhere many years ago.)",,"['probability', 'law-of-large-numbers']"
23,Doubt about a probability excercise,Doubt about a probability excercise,,"I'm a statistics teacher at a college. One day a student came with a doubt about an exercise about probability. The text goes like this: A person has two boxes $A$ and $B$. In the first one has $4$ white balls and $5$ black balls and in the second has $5$ white balls and $4$ black balls. This person takes randomly one ball from the first box and put it into the second box. After that he takes a ball from the second box. Find the probability of taking balls of the same color in this process (i.e, the one that is taken from box $A$ to $B$ and the one taken from box $B$). The student made the following: Let $C$ be the event of taking balls of the same color in the process above described. Let $W$ be the event of taking White balls from both boxes and $Bl$ the event of taking black balls from both boxes. Let $Wb_1$ be the event of taking a white ball from the first box and $Wb_2$ the event of taking a white ball from the second box. The same with $Blb_1$ and $Blb_2$. Then, \begin{align} \mathbb P(C)&=\mathbb P(W)+\mathbb P(Bl)\\ &= \mathbb P(Wb_1)\mathbb P(Wb_2)+\mathbb P(Blb_1)\mathbb P(Blb_2)\\&= \frac49 \cdot\frac6{10} + \frac59\cdot\frac5{10} \end{align} I told the student the reasoning was wrong because he has to use conditional probability because events $Wb_1$ and $Wb_2$ as well as $Blb_1$ and $Blb_2$ are not independent. A probability teacher (his actual teacher) told the student he was right and that's why I make this post. ¿Who is right? Thanks!","I'm a statistics teacher at a college. One day a student came with a doubt about an exercise about probability. The text goes like this: A person has two boxes $A$ and $B$. In the first one has $4$ white balls and $5$ black balls and in the second has $5$ white balls and $4$ black balls. This person takes randomly one ball from the first box and put it into the second box. After that he takes a ball from the second box. Find the probability of taking balls of the same color in this process (i.e, the one that is taken from box $A$ to $B$ and the one taken from box $B$). The student made the following: Let $C$ be the event of taking balls of the same color in the process above described. Let $W$ be the event of taking White balls from both boxes and $Bl$ the event of taking black balls from both boxes. Let $Wb_1$ be the event of taking a white ball from the first box and $Wb_2$ the event of taking a white ball from the second box. The same with $Blb_1$ and $Blb_2$. Then, \begin{align} \mathbb P(C)&=\mathbb P(W)+\mathbb P(Bl)\\ &= \mathbb P(Wb_1)\mathbb P(Wb_2)+\mathbb P(Blb_1)\mathbb P(Blb_2)\\&= \frac49 \cdot\frac6{10} + \frac59\cdot\frac5{10} \end{align} I told the student the reasoning was wrong because he has to use conditional probability because events $Wb_1$ and $Wb_2$ as well as $Blb_1$ and $Blb_2$ are not independent. A probability teacher (his actual teacher) told the student he was right and that's why I make this post. ¿Who is right? Thanks!",,"['probability', 'statistics', 'bayes-theorem']"
24,Calculating the probability to win with martingale in roulette,Calculating the probability to win with martingale in roulette,,"I've made a python program that uses martingale betting method to see what the probability is to double your starting pot and then stop at European roulette (no double 00). The program works like this, You got $100$ dollars in the beginning and the starting bet is $1$ dollar. The program always bet on red and if it wins it will bet $1$ dollar again. If it loses it will double the initial bet. $1,2,4,8$ etc until it either goes bankrupt or wins. I've made the program do this a million times and then divide the times it doubled it's money by a million and i got $0.304063$. My question is how would I calculate this value without having to use the program? The probability of getting red is $\frac{18}{37}$. You play until you have either won $100$ dollars or lost everything.","I've made a python program that uses martingale betting method to see what the probability is to double your starting pot and then stop at European roulette (no double 00). The program works like this, You got $100$ dollars in the beginning and the starting bet is $1$ dollar. The program always bet on red and if it wins it will bet $1$ dollar again. If it loses it will double the initial bet. $1,2,4,8$ etc until it either goes bankrupt or wins. I've made the program do this a million times and then divide the times it doubled it's money by a million and i got $0.304063$. My question is how would I calculate this value without having to use the program? The probability of getting red is $\frac{18}{37}$. You play until you have either won $100$ dollars or lost everything.",,['probability']
25,A probability puzzle about mountain villages,A probability puzzle about mountain villages,,"I hope this puzzle will be of some interest. The mountain villages $A,B,C$ and $D$ lie at the vertices of a tetrahedron, and each pair of villages is joined by a road. After a snowfall the probability that any road is blocked is $p$, and is independent of the conditions of any other road. The probability that, after a snowfall, it is possible to travel from any village to any other village by some route is $P$. What is $P$ in terms of the probability $p$?","I hope this puzzle will be of some interest. The mountain villages $A,B,C$ and $D$ lie at the vertices of a tetrahedron, and each pair of villages is joined by a road. After a snowfall the probability that any road is blocked is $p$, and is independent of the conditions of any other road. The probability that, after a snowfall, it is possible to travel from any village to any other village by some route is $P$. What is $P$ in terms of the probability $p$?",,['probability']
26,Largest jumps of a spectrally positive $\alpha$-stable process,Largest jumps of a spectrally positive -stable process,\alpha,"Let $X(.)$ be a (strictly) $\alpha$-stable process (with $\alpha \in (1,2)$). Assume also that $X(.)$ is spectrally positive (its Lévy measure is concentrated in $[0,+\infty)$). I am looking for a result that qualitatively says that the set of jumps heights of $X(.)$ is unbounded. More formally, define $J_t(x(.)) := \sup_{0\leq s \leq t} \{\vert x(s) - x(s^-)\vert\}$. Is it true that \begin{equation} J_t(X(.)) \stackrel{t\rightarrow\infty}{\longrightarrow}  + \infty\qquad \mathrm {a.s.} \end{equation} or any other suitable convergence?","Let $X(.)$ be a (strictly) $\alpha$-stable process (with $\alpha \in (1,2)$). Assume also that $X(.)$ is spectrally positive (its Lévy measure is concentrated in $[0,+\infty)$). I am looking for a result that qualitatively says that the set of jumps heights of $X(.)$ is unbounded. More formally, define $J_t(x(.)) := \sup_{0\leq s \leq t} \{\vert x(s) - x(s^-)\vert\}$. Is it true that \begin{equation} J_t(X(.)) \stackrel{t\rightarrow\infty}{\longrightarrow}  + \infty\qquad \mathrm {a.s.} \end{equation} or any other suitable convergence?",,"['probability', 'stochastic-processes', 'levy-processes']"
27,martingale and expectation,martingale and expectation,,"The following is an old exam problem: Let $\{X_n\}$, $n\geq0$, be a process adapted to a filtration $F_n$. Prove that $(X_n,F_n)$ is a martingale, if and only if for all bounded $F_n$-stopping time $\tau$, $EX_{\tau}=EX_0$ holds. I know if $X_n$ is a martingale, then $X_{\tau}$ is a martingale by optional stopping theorem. Hence $E(X_{\tau})=E(E(X_{\tau}|F_{0}))=E(X_0)$. However I have trouble connecting the expectation to the conditional expectation for the other direction. It seems like it needs some smart way to define $\tau$ while I haven't thought of one. Thanks for any help.","The following is an old exam problem: Let $\{X_n\}$, $n\geq0$, be a process adapted to a filtration $F_n$. Prove that $(X_n,F_n)$ is a martingale, if and only if for all bounded $F_n$-stopping time $\tau$, $EX_{\tau}=EX_0$ holds. I know if $X_n$ is a martingale, then $X_{\tau}$ is a martingale by optional stopping theorem. Hence $E(X_{\tau})=E(E(X_{\tau}|F_{0}))=E(X_0)$. However I have trouble connecting the expectation to the conditional expectation for the other direction. It seems like it needs some smart way to define $\tau$ while I haven't thought of one. Thanks for any help.",,['probability']
28,conditional probability combining discrete and continous random variables,conditional probability combining discrete and continous random variables,,"Let us define $Y$ a continuous random variable having  density $f(y,\theta)$ and X a discrete random variable such that $X=\mathbf{1}_{ \{Y \in [a_{i-1}, a_{i}) \}}$ . I want to compute the conditional density of Y given X. So I write $f_{Y}(y \mid X=x)= \frac{f_{Y X} (y,x)}{f_{X}(x)}$.  Since I have 2 different types of random variables (discrete and continous) I have $f_{Y X} (y,x)= P(X=x \mid Y=y) f(Y=y)$. The problem is that I am familiar with computing the conditional  probability of two random variables having the same type but in the mixed case I do not know how to proceed to compute $P(X=x \mid Y=y)$. Can someone help me?","Let us define $Y$ a continuous random variable having  density $f(y,\theta)$ and X a discrete random variable such that $X=\mathbf{1}_{ \{Y \in [a_{i-1}, a_{i}) \}}$ . I want to compute the conditional density of Y given X. So I write $f_{Y}(y \mid X=x)= \frac{f_{Y X} (y,x)}{f_{X}(x)}$.  Since I have 2 different types of random variables (discrete and continous) I have $f_{Y X} (y,x)= P(X=x \mid Y=y) f(Y=y)$. The problem is that I am familiar with computing the conditional  probability of two random variables having the same type but in the mixed case I do not know how to proceed to compute $P(X=x \mid Y=y)$. Can someone help me?",,"['probability', 'probability-distributions']"
29,Showing that supremum function is integrable,Showing that supremum function is integrable,,"Let $g_1(\omega),g_2(\omega),...$ be integrable functions defined on $\Omega$ with $g_n\rightarrow g$ and $g$ is integrable and also $\lim \int g_n=\int g$ . Define $h(\omega)= \sup_n g_n(\omega)$. How do we show that $h$ is integrable? I was trying to use fatou's lemma, but I'm stuck.","Let $g_1(\omega),g_2(\omega),...$ be integrable functions defined on $\Omega$ with $g_n\rightarrow g$ and $g$ is integrable and also $\lim \int g_n=\int g$ . Define $h(\omega)= \sup_n g_n(\omega)$. How do we show that $h$ is integrable? I was trying to use fatou's lemma, but I'm stuck.",,"['probability', 'integration', 'measure-theory']"
30,Probability question on finding a defective ball in a specific box,Probability question on finding a defective ball in a specific box,,"There are two boxes, each containing two balls. Each ball is defective with probability 1/4, independent of other balls. The probability that exactly one box contains exactly one defective ball is (A) 3/8  (B) 5/8  (C) 15/32  (D) 17/32 One box can be picked in 2 ways and 1 ball in that box can be picked in 2 ways. So, 4 ways. The probability of 1 defective and 3 normal balls is 27/256. The total number of possibilities is 4C0(81/256)+4C1(27/256)+4C2(9/256)+4C3(3/256)+4C4(1/256)=256/256=1. So, I thought the answer should be 27/64. This is different from the given choices. Is my method wrong ?","There are two boxes, each containing two balls. Each ball is defective with probability 1/4, independent of other balls. The probability that exactly one box contains exactly one defective ball is (A) 3/8  (B) 5/8  (C) 15/32  (D) 17/32 One box can be picked in 2 ways and 1 ball in that box can be picked in 2 ways. So, 4 ways. The probability of 1 defective and 3 normal balls is 27/256. The total number of possibilities is 4C0(81/256)+4C1(27/256)+4C2(9/256)+4C3(3/256)+4C4(1/256)=256/256=1. So, I thought the answer should be 27/64. This is different from the given choices. Is my method wrong ?",,['probability']
31,Expected value of money left from a coin flipping game,Expected value of money left from a coin flipping game,,"Say we were to play a game. We started off with \$100 and kept flipping a fair coin. If it turned out heads, we won \$1, else our money got inverted. For example, if on the first flip we got heads, then we'd have \$101. And if we got tails, we'd have \$0.01. What is the expected value of the money we have after N flips? One way to think about it is to use recursion, i.e. to find the recursive relation between f(n) and f(n-1), where f(n) is the expected money after n flips. Without too much effort we can find: $$f(n) = \frac{1}{2}(f(n-1)+1) + \frac{1}{2f(n-1)}$$ However, if we use this relation, we'll have our money go down exponentially fast, which goes against common sense. For example, if we use the above relation, starting off with \$100, after 7 flips, we'll have around \$1. But a simple computer simulation shows it should be slightly above \$18. Can anyone help shed some light on this problem?","Say we were to play a game. We started off with \$100 and kept flipping a fair coin. If it turned out heads, we won \$1, else our money got inverted. For example, if on the first flip we got heads, then we'd have \$101. And if we got tails, we'd have \$0.01. What is the expected value of the money we have after N flips? One way to think about it is to use recursion, i.e. to find the recursive relation between f(n) and f(n-1), where f(n) is the expected money after n flips. Without too much effort we can find: $$f(n) = \frac{1}{2}(f(n-1)+1) + \frac{1}{2f(n-1)}$$ However, if we use this relation, we'll have our money go down exponentially fast, which goes against common sense. For example, if we use the above relation, starting off with \$100, after 7 flips, we'll have around \$1. But a simple computer simulation shows it should be slightly above \$18. Can anyone help shed some light on this problem?",,"['probability', 'recurrence-relations', 'markov-chains']"
32,n distinguishable balls into n boxes,n distinguishable balls into n boxes,,"We have n distinguishable balls (say they have different labels or colours). If these  balls are dropped at random in n boxes, what is the probability that: 1- No box is empty? 2- Exactly one box is empty? For 1, I figured that we have $n^n$ ways to put the n balls into the n boxes. And I figured there are $n!$ to sort the balls so there is one ball for each box. So is the answer to question 1 $n!/(n^n)$? For 2, there are $n-1$ ways for the boxes to be empty. This is because you can have box 1 be empty (and just that), box 2 be empty and just that, so ultimately you can have at most $n-1$ variations of empty boxes. So I figured the solution to part 2 was $\frac{n-1}{n^n}$ Is any of this right?","We have n distinguishable balls (say they have different labels or colours). If these  balls are dropped at random in n boxes, what is the probability that: 1- No box is empty? 2- Exactly one box is empty? For 1, I figured that we have $n^n$ ways to put the n balls into the n boxes. And I figured there are $n!$ to sort the balls so there is one ball for each box. So is the answer to question 1 $n!/(n^n)$? For 2, there are $n-1$ ways for the boxes to be empty. This is because you can have box 1 be empty (and just that), box 2 be empty and just that, so ultimately you can have at most $n-1$ variations of empty boxes. So I figured the solution to part 2 was $\frac{n-1}{n^n}$ Is any of this right?",,"['probability', 'combinatorics']"
33,Probability of knocking off all of a dragon's heads,Probability of knocking off all of a dragon's heads,,"You are fighting a dragon with three heads. Each time you swing at the dragon, you have a $20\%$ of hitting off two heads, a $60\%$ chance of hitting off one head and a $20\%$ of missing altogether. If you knock off one head, the head grows back immediately before the next iteration. If you miss, an additional head grows immediately before the next iteration. If you knock off two heads, the heads stay knocked off and you move to the next iteration. You win if you knock off all of the dragon's heads and the dragon wins if at any time it has five heads. What are the odds you win the game? Anyone have a definitive answer for this? Was able to get an answer finding the probabilities for each potential number of heads and the chances of winning/losing within $3$ iterations, but wanted to see if it is right. Then if you get back to $3$ heads, multiply by $p$ through recursion. Can you ignore the $60\%$ as nothing in the game changes if this occurs? I thought: $p$ = chance of two hits in a row + chance of two hits, one miss + probability of getting back to $3$ heads with two miss, $$\text{one hit}*p = (1/5*1/5) + 2\left(1/5*1/5*1/5\right) + 2\left(1/5*1/5*1/5\right)*p$$ Seems a bit low, likely because I'm leaving out that $60\%$.. but not sure where to include it. Any help would be greatly appreciated.","You are fighting a dragon with three heads. Each time you swing at the dragon, you have a $20\%$ of hitting off two heads, a $60\%$ chance of hitting off one head and a $20\%$ of missing altogether. If you knock off one head, the head grows back immediately before the next iteration. If you miss, an additional head grows immediately before the next iteration. If you knock off two heads, the heads stay knocked off and you move to the next iteration. You win if you knock off all of the dragon's heads and the dragon wins if at any time it has five heads. What are the odds you win the game? Anyone have a definitive answer for this? Was able to get an answer finding the probabilities for each potential number of heads and the chances of winning/losing within $3$ iterations, but wanted to see if it is right. Then if you get back to $3$ heads, multiply by $p$ through recursion. Can you ignore the $60\%$ as nothing in the game changes if this occurs? I thought: $p$ = chance of two hits in a row + chance of two hits, one miss + probability of getting back to $3$ heads with two miss, $$\text{one hit}*p = (1/5*1/5) + 2\left(1/5*1/5*1/5\right) + 2\left(1/5*1/5*1/5\right)*p$$ Seems a bit low, likely because I'm leaving out that $60\%$.. but not sure where to include it. Any help would be greatly appreciated.",,"['probability', 'recursion']"
34,Expectation of product of two random variables,Expectation of product of two random variables,,"Let $X,Y$, two random variables which are indicators. Lets assume $P(X=1)=p$ and $P(Y=1)=q$ for some $0 \le p,q \le 1$. I've understood that: $E[XY] = P(X=1, Y=1)$. How to show it? $$E[XY] = \sum_{i=0}^1 XY\cdot Pr(?)$$ I guess it should be $Pr(X=i, Y=i)$ and of course, when $i=0$ the all expression equals to $0$. But, why is it $Pr(X=i, Y=i)$? I'd be glad for both algebraic and intuitive explanation. Thanks!","Let $X,Y$, two random variables which are indicators. Lets assume $P(X=1)=p$ and $P(Y=1)=q$ for some $0 \le p,q \le 1$. I've understood that: $E[XY] = P(X=1, Y=1)$. How to show it? $$E[XY] = \sum_{i=0}^1 XY\cdot Pr(?)$$ I guess it should be $Pr(X=i, Y=i)$ and of course, when $i=0$ the all expression equals to $0$. But, why is it $Pr(X=i, Y=i)$? I'd be glad for both algebraic and intuitive explanation. Thanks!",,"['probability', 'random-variables', 'expectation']"
35,Probability of some die face being missed N or more times in a row in M rolls? [Clarified],Probability of some die face being missed N or more times in a row in M rolls? [Clarified],,"2015/01/28 Clarification: Question rewritten to remove ambiguity that elicited (interesting) responses to a different problem (use edit should you wish to view). From Markus' feedback on the earlier question: Let's consider a die with $F$ faces. This die is rolled $M$ times. What is the probability, that each window of size $N \leq M$ within this series of $M$ rolls contains always all $F$ faces? Or alternatively, consider an urn with $F$ differently colored balls, where $M$ balls are drawn (with replacement after each draw) and the colors noted. What is the probability given $F$, $M$, and some $N \leq M$ that every consecutive $N$ draws of the $M$ total draws exhibited at least one example each of all $F$ colors? Obviously, if $M<N$ or $N<F$ the probability is 0. I'm stuck for the $F\leq N \leq M$ cases. I can do this using recursive calculation or a Markov chain, but only for the most trivial (small) cases, since the state space obviously explodes quite quickly. I thought of treating it like a runs/streak problem, that is, I thought that if some face/color is seen, followed by $N$ all of differing face/color resulting in a ""failure"", I could just use existing means of calculating a streak of $N$ events with probability $(faces - 1)/(faces)$ for the event of a differing face/color. I was unable to arrive at a solution this way. I then thought of treating it as a coupon collector's problem. I can easily calculate the probability of all faces/colors being seen in the first $N$, so I thought using that, the next ""window"" from 2 to N+1 is a ""failure"" if those $N$ are all different from the 1st element (probability $((faces - 1)/(faces))^N$), continuing this for each step of the ""window"" by 1 to get a net probability. I get stuck here with the dependency between successive ""windows"", and I'm not even sure if it's a valid tack. I attempted to find a generating function by looking at actual example counts of differing cases, and searching OEIS for sequences along with checking for generating/sequence functions in Mathematica . I found no matches, and I'm a neophyte with generating functions, so I hit a dead end there. Bottom line, given $F, M, N$, how might I calculate this? A couple of examples follow to clarify the above problem description. Given an alphabet of two elements ${0,1}$, ($F=2$) the possible words of length 4 ($M=4$) are With a ""window"" of 3 ($N=3$), the only length 4 words that have no missing alphabet elements in all possible length 3 ""windows"" are So, my probability of missing some alphabet element in a 3-windowed 4-length string on a 2-element alphabet is 6/16. For a more involved example, take the length 6 strings on $0,1,2,3$. There are 4096 of them (I'll not list them for obvious reasons). For a ""window"" of 5, only 528 of them have the complete alphabet in all possible length 5 consecutive positions. A few examples: Note that in all of these, positions 1 through 5 and 2 through 6 for each have at least one example of every element in the alphabet. That number (528 in this example, or equivalently 3568 for the complement) is what I'm after. I hope that clarifies the question, apologies to readers for any confusion I caused. 2015/01/30 - I've awarded the current bounty to Markus, even though the answer was for a different problem (my fault, my ambiguously written OP), rather than have it vanish into the ether. His response prompted me to look at the problem in other ways and was most interesting in itself. I shall add another bounty if/when it is allowed, and/or award one manually should a solution present itself.","2015/01/28 Clarification: Question rewritten to remove ambiguity that elicited (interesting) responses to a different problem (use edit should you wish to view). From Markus' feedback on the earlier question: Let's consider a die with $F$ faces. This die is rolled $M$ times. What is the probability, that each window of size $N \leq M$ within this series of $M$ rolls contains always all $F$ faces? Or alternatively, consider an urn with $F$ differently colored balls, where $M$ balls are drawn (with replacement after each draw) and the colors noted. What is the probability given $F$, $M$, and some $N \leq M$ that every consecutive $N$ draws of the $M$ total draws exhibited at least one example each of all $F$ colors? Obviously, if $M<N$ or $N<F$ the probability is 0. I'm stuck for the $F\leq N \leq M$ cases. I can do this using recursive calculation or a Markov chain, but only for the most trivial (small) cases, since the state space obviously explodes quite quickly. I thought of treating it like a runs/streak problem, that is, I thought that if some face/color is seen, followed by $N$ all of differing face/color resulting in a ""failure"", I could just use existing means of calculating a streak of $N$ events with probability $(faces - 1)/(faces)$ for the event of a differing face/color. I was unable to arrive at a solution this way. I then thought of treating it as a coupon collector's problem. I can easily calculate the probability of all faces/colors being seen in the first $N$, so I thought using that, the next ""window"" from 2 to N+1 is a ""failure"" if those $N$ are all different from the 1st element (probability $((faces - 1)/(faces))^N$), continuing this for each step of the ""window"" by 1 to get a net probability. I get stuck here with the dependency between successive ""windows"", and I'm not even sure if it's a valid tack. I attempted to find a generating function by looking at actual example counts of differing cases, and searching OEIS for sequences along with checking for generating/sequence functions in Mathematica . I found no matches, and I'm a neophyte with generating functions, so I hit a dead end there. Bottom line, given $F, M, N$, how might I calculate this? A couple of examples follow to clarify the above problem description. Given an alphabet of two elements ${0,1}$, ($F=2$) the possible words of length 4 ($M=4$) are With a ""window"" of 3 ($N=3$), the only length 4 words that have no missing alphabet elements in all possible length 3 ""windows"" are So, my probability of missing some alphabet element in a 3-windowed 4-length string on a 2-element alphabet is 6/16. For a more involved example, take the length 6 strings on $0,1,2,3$. There are 4096 of them (I'll not list them for obvious reasons). For a ""window"" of 5, only 528 of them have the complete alphabet in all possible length 5 consecutive positions. A few examples: Note that in all of these, positions 1 through 5 and 2 through 6 for each have at least one example of every element in the alphabet. That number (528 in this example, or equivalently 3568 for the complement) is what I'm after. I hope that clarifies the question, apologies to readers for any confusion I caused. 2015/01/30 - I've awarded the current bounty to Markus, even though the answer was for a different problem (my fault, my ambiguously written OP), rather than have it vanish into the ether. His response prompted me to look at the problem in other ways and was most interesting in itself. I shall add another bounty if/when it is allowed, and/or award one manually should a solution present itself.",,"['probability', 'combinatorics', 'dice']"
36,"Two Urns contain white and black balls, drawn using a set of rules. Probability that nth ball drawn is white.","Two Urns contain white and black balls, drawn using a set of rules. Probability that nth ball drawn is white.",,"Two urns contain respectively 'a white and b black' and 'b white and a black' balls. A series of drawings is made according to the following rules: (i) Each time only ball is drawn and immediately returned to the same urn it came from. (ii) If the ball drawn is white, the next drawing is made from the first urn. (iii) If it is black, the next drawing is made from the second urn. (iv)The first ball drawn comes from the first urn. What is the probability that nth ball drawn will be white ? My Attempt Probability of White ball from urn 1: $\frac{a}{a+b}$ Probability of Black ball from urn 1: $\frac{b}{a+b}$ Probability of White ball from urn2: $\frac{b}{a+b}$ Probability of Black ball from urn 2: $\frac{a}{a+b}$ I don't know how to proceed mathematically from here, but from trial and error: $$ \sum_{i=0}^n \binom {n}{i} (\frac{a}{a+b})^{n-i} (\frac{b}{a+b})^i $$ I couldn't find this question anywhere online. Sorry if repost.. Thanks in advance!","Two urns contain respectively 'a white and b black' and 'b white and a black' balls. A series of drawings is made according to the following rules: (i) Each time only ball is drawn and immediately returned to the same urn it came from. (ii) If the ball drawn is white, the next drawing is made from the first urn. (iii) If it is black, the next drawing is made from the second urn. (iv)The first ball drawn comes from the first urn. What is the probability that nth ball drawn will be white ? My Attempt Probability of White ball from urn 1: $\frac{a}{a+b}$ Probability of Black ball from urn 1: $\frac{b}{a+b}$ Probability of White ball from urn2: $\frac{b}{a+b}$ Probability of Black ball from urn 2: $\frac{a}{a+b}$ I don't know how to proceed mathematically from here, but from trial and error: $$ \sum_{i=0}^n \binom {n}{i} (\frac{a}{a+b})^{n-i} (\frac{b}{a+b})^i $$ I couldn't find this question anywhere online. Sorry if repost.. Thanks in advance!",,"['probability', 'combinatorics']"
37,"""Back to square one"" problem","""Back to square one"" problem",,"There's a problem I've been stuck on in preparation for junior programming contest I'm going to participate in. It is as follows: The ""back to square one"" problem is played on a board that has $n$ squares in a row and $n-1$ probabilities. Players take turns playing. On their first turn, a player advances to square $1$.After the first turn, if a player is on square $i$ , the player advances to square $i + 1$ with probability $p(i)$ , and returns to square 1 with probability $1-p(i)$ .The player is finished upon reaching square $n$. Compute the expected number of turns to complete the game. $\textbf{My Attempt:}$ From the definition of expectation we know that $$E[X] = \sum_{i=1}^{n-1}i\cdot P(i)= \sum_{i=1}^{n-1}i\cdot(1-p(i))\cdot p(i)$$ I'm not really sure what to do with this expression. Perhaps it follows a negative binomial distribution. But, the CDF for this is really ugly and I think it would be beyond the scope of this contest.","There's a problem I've been stuck on in preparation for junior programming contest I'm going to participate in. It is as follows: The ""back to square one"" problem is played on a board that has $n$ squares in a row and $n-1$ probabilities. Players take turns playing. On their first turn, a player advances to square $1$.After the first turn, if a player is on square $i$ , the player advances to square $i + 1$ with probability $p(i)$ , and returns to square 1 with probability $1-p(i)$ .The player is finished upon reaching square $n$. Compute the expected number of turns to complete the game. $\textbf{My Attempt:}$ From the definition of expectation we know that $$E[X] = \sum_{i=1}^{n-1}i\cdot P(i)= \sum_{i=1}^{n-1}i\cdot(1-p(i))\cdot p(i)$$ I'm not really sure what to do with this expression. Perhaps it follows a negative binomial distribution. But, the CDF for this is really ugly and I think it would be beyond the scope of this contest.",,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes']"
38,Ratio of expectations for integer-valued random variable,Ratio of expectations for integer-valued random variable,,"For a nonnegative integer-valued random variable $Y$ with positive expectation, show that $$\dfrac{E[Y]^2}{E[Y^2]}\leq\Pr[Y\neq 0].$$ I suppose that the probability that $Y=i$ is $x_i$, for $i=0,1,2,\ldots$. Then the inequality becomes $$\dfrac{(x_1+2x_2+3x_3+\cdots)^2}{x_1+4x_2+9x_3+\cdots}\leq 1-x_1-x_2-\cdots$$ How can this be shown?","For a nonnegative integer-valued random variable $Y$ with positive expectation, show that $$\dfrac{E[Y]^2}{E[Y^2]}\leq\Pr[Y\neq 0].$$ I suppose that the probability that $Y=i$ is $x_i$, for $i=0,1,2,\ldots$. Then the inequality becomes $$\dfrac{(x_1+2x_2+3x_3+\cdots)^2}{x_1+4x_2+9x_3+\cdots}\leq 1-x_1-x_2-\cdots$$ How can this be shown?",,"['probability', 'random-variables']"
39,A martingale with bounded increments either converges or diverges to both infinities a.s.,A martingale with bounded increments either converges or diverges to both infinities a.s.,,"I am reading page 236 ""Probability : theory and examples"" by R. Durrett. Theorem 31. Let $X_1, X_2,\ldots$ be a martingale with $|X_{n+1}-X_n|\leq M<\infty$. Let $C=\{\lim X_n \;\;\; \text{exists and finite} \}$ $D=\{\limsup X_n =\infty \;\;\; \text{and}\;\; \liminf X_n =-\infty \}$ then $P(C\cup D)=1$. Proof Since $X_n-X_0$ is a martingale , so we can without loss of generality suppose that $X_0=0$. Now let $0<K<\infty$ and let $N=\inf\{n : X_n\leq -K\}$. $X_{n\wedge N}$ is a martingale with $X_{n\wedge N}\geq -K-M$. By applying (2.11) for $X_{n\wedge N}+K+M$,  $\lim X_n$ exists on $\{ N=\infty\}$. By letting $K\to \infty$, we see that the limit exists on $\{\liminf X_n>-\infty\}$. $\Box$ My questions are: Why $X_{n\wedge N}\geq -K-M$? isn't it $X_{n\wedge N}\geq -K$ ? Why does the limit exist on $\{\liminf X_n>-\infty\}$ ? It would be greatly appreciated if some one could help me on this. Thanks for your time.","I am reading page 236 ""Probability : theory and examples"" by R. Durrett. Theorem 31. Let $X_1, X_2,\ldots$ be a martingale with $|X_{n+1}-X_n|\leq M<\infty$. Let $C=\{\lim X_n \;\;\; \text{exists and finite} \}$ $D=\{\limsup X_n =\infty \;\;\; \text{and}\;\; \liminf X_n =-\infty \}$ then $P(C\cup D)=1$. Proof Since $X_n-X_0$ is a martingale , so we can without loss of generality suppose that $X_0=0$. Now let $0<K<\infty$ and let $N=\inf\{n : X_n\leq -K\}$. $X_{n\wedge N}$ is a martingale with $X_{n\wedge N}\geq -K-M$. By applying (2.11) for $X_{n\wedge N}+K+M$,  $\lim X_n$ exists on $\{ N=\infty\}$. By letting $K\to \infty$, we see that the limit exists on $\{\liminf X_n>-\infty\}$. $\Box$ My questions are: Why $X_{n\wedge N}\geq -K-M$? isn't it $X_{n\wedge N}\geq -K$ ? Why does the limit exist on $\{\liminf X_n>-\infty\}$ ? It would be greatly appreciated if some one could help me on this. Thanks for your time.",,"['probability', 'martingales', 'stopping-times']"
40,"Finding correlation of Max and Min of two IID random variable in U[0,1]","Finding correlation of Max and Min of two IID random variable in U[0,1]",,"I have a hw problem and can't figure out how to do it. Basically, $X,Y$ are iid $U[0,1]$, we need to find the correlation between max$(X,Y)$ and min$(X,Y)$. My thought is to find the pdf of $U=$max$(X,Y)$ and $V=$min$(X,Y)$ and then find pdf of UV and use the definition of Variance to find the correaltion. But this seems way to substantial to do. I wonder if there is some simpler method.","I have a hw problem and can't figure out how to do it. Basically, $X,Y$ are iid $U[0,1]$, we need to find the correlation between max$(X,Y)$ and min$(X,Y)$. My thought is to find the pdf of $U=$max$(X,Y)$ and $V=$min$(X,Y)$ and then find pdf of UV and use the definition of Variance to find the correaltion. But this seems way to substantial to do. I wonder if there is some simpler method.",,"['probability', 'uniform-distribution']"
41,probability of sequence of integers,probability of sequence of integers,,"Suppose you have numbers from 1 to 10. You can choose four of them but the contiguous numbers should have an absolute difference greater than 1. For example, you can choose $$ 1-3-6-10$$ $$ 4-2-5-1$$ but you cannot choose $$ 1-2-4-8$$ $$ 4-1-3-2$$ What is the probability that you choose an admissible sequence? I could not solve it mathematically so I wrote a short code in R require(gtools) x=permutations(10 ,4) y = abs(apply(x,1,diff)) cf = function(x){   is.element(1,x) } z=apply(y,2,cf) x[z==F,] sum(z==F)/(dim(x)[1]) If I am not mistaken, you can choose an admissible sequence with $0.4861111$ probability. Can you show it mathematically?","Suppose you have numbers from 1 to 10. You can choose four of them but the contiguous numbers should have an absolute difference greater than 1. For example, you can choose $$ 1-3-6-10$$ $$ 4-2-5-1$$ but you cannot choose $$ 1-2-4-8$$ $$ 4-1-3-2$$ What is the probability that you choose an admissible sequence? I could not solve it mathematically so I wrote a short code in R require(gtools) x=permutations(10 ,4) y = abs(apply(x,1,diff)) cf = function(x){   is.element(1,x) } z=apply(y,2,cf) x[z==F,] sum(z==F)/(dim(x)[1]) If I am not mistaken, you can choose an admissible sequence with $0.4861111$ probability. Can you show it mathematically?",,"['probability', 'permutations']"
42,"If $ X = \sqrt{Y_{1} Y_{2}} $, then find a multiple of $ X $ that is an unbiased estimator for $ \theta $.","If , then find a multiple of  that is an unbiased estimator for .", X = \sqrt{Y_{1} Y_{2}}   X   \theta ,"Problem: Suppose that $ (Y_{1},Y_{2},Y_{3},Y_{4}) $ denotes a random sample of size $ 4 $ from a population with an exponential distribution whose probability density function $ f $ is given by   $$ f(y) = \begin{cases} \dfrac{1}{\theta} e^{− \frac{y}{\theta}} & \text{if $ y > 0 $}; \\\\ 0                                        & \text{elsewhere}. \end{cases} $$   Let $ X = \sqrt{Y_{1} Y_{2}} $. Then find a multiple of $ X $ that is an unbiased estimator for $ \theta $. Hint: Use your knowledge of the gamma distribution and the fact that $ \Gamma \! \left( \dfrac{1}{2} \right) = \sqrt{\pi} $ to find $ \mathsf{E} \! \left( \sqrt{Y_{1}} \right) $. Recall that the $ Y_{i} $’s are independent random variables. I am told that $ \mathsf{E} \! \left( \sqrt{Y} \right) = \dfrac{1}{2} \sqrt{\pi \theta} $. Could anyone help me with the intermediate steps? Thanks!","Problem: Suppose that $ (Y_{1},Y_{2},Y_{3},Y_{4}) $ denotes a random sample of size $ 4 $ from a population with an exponential distribution whose probability density function $ f $ is given by   $$ f(y) = \begin{cases} \dfrac{1}{\theta} e^{− \frac{y}{\theta}} & \text{if $ y > 0 $}; \\\\ 0                                        & \text{elsewhere}. \end{cases} $$   Let $ X = \sqrt{Y_{1} Y_{2}} $. Then find a multiple of $ X $ that is an unbiased estimator for $ \theta $. Hint: Use your knowledge of the gamma distribution and the fact that $ \Gamma \! \left( \dfrac{1}{2} \right) = \sqrt{\pi} $ to find $ \mathsf{E} \! \left( \sqrt{Y_{1}} \right) $. Recall that the $ Y_{i} $’s are independent random variables. I am told that $ \mathsf{E} \! \left( \sqrt{Y} \right) = \dfrac{1}{2} \sqrt{\pi \theta} $. Could anyone help me with the intermediate steps? Thanks!",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
43,Why is probability so unintuitive to us? [closed],Why is probability so unintuitive to us? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 10 years ago . Improve this question There are so many famous paradoxes which are examples of how humans are unable to intuitively understand probability -- there's a discrepancy between their supposed actual experience and the mathematical evidence. There's things like the birthday problem where what we would expect the probability to be is much less than the actual, but also the monty hall problem where the confusion comes in why the answer is what it is. My question is, what is the cause of this? Why are we biased into thinking things are more or less likely than they really are? Why do we find it so difficult to accept and understand the correct probability in the case of the monty hall problem, burnt pancake problem, etc.?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 10 years ago . Improve this question There are so many famous paradoxes which are examples of how humans are unable to intuitively understand probability -- there's a discrepancy between their supposed actual experience and the mathematical evidence. There's things like the birthday problem where what we would expect the probability to be is much less than the actual, but also the monty hall problem where the confusion comes in why the answer is what it is. My question is, what is the cause of this? Why are we biased into thinking things are more or less likely than they really are? Why do we find it so difficult to accept and understand the correct probability in the case of the monty hall problem, burnt pancake problem, etc.?",,"['probability', 'soft-question']"
44,Convergence of Random Variables in mean,Convergence of Random Variables in mean,,If $$E[|X_n-X|^r]\rightarrow0$$ prove that $$E|X_n^r|\rightarrow E|X^r| $$ for every $r\ge 1$ This is the very notation used. I believe it should be:  $$E[|X_n|^r]\rightarrow E[|X|]^r $$ Attempt I think I can obtain $E[X_n]\rightarrow E[X]$ using Jensen Inequality but I don't think this helps. I have no further idea.,If $$E[|X_n-X|^r]\rightarrow0$$ prove that $$E|X_n^r|\rightarrow E|X^r| $$ for every $r\ge 1$ This is the very notation used. I believe it should be:  $$E[|X_n|^r]\rightarrow E[|X|]^r $$ Attempt I think I can obtain $E[X_n]\rightarrow E[X]$ using Jensen Inequality but I don't think this helps. I have no further idea.,,"['probability', 'convergence-divergence', 'random-variables']"
45,How am I counting the possibilities incorrectly in this combinatorics problem?,How am I counting the possibilities incorrectly in this combinatorics problem?,,"I've been working through some problems in Statistical Inference Second Edition (George Casella, Roger L. Berger), one of which is this already discussed problem . While the answer given makes sense, I'm having trouble understanding why the same probability can't be arrived at by calculating possible $\mathit{unordered}$ outcomes of calls mapped to days. Question restated: ""My telephone rings 12 times each week, the calls being randomly distributed among the 7 days. What is the probability that I get a least one call each day?"" While I am not interested in the answer, as it is already given, I am interested in why the following alternative approach doesn't work. What am I incorrect in assuming? Number of possible ways the 12 indistinguishable calls could be arranged among 7 days: $$\text{unordered with replacement} \Rightarrow \binom{7 + 12 - 1}{12} = \binom{18}{12}$$ To find the number of ways 12 calls could be spread among 7 days with at least one call per day, we first assign 1 call to each day. Next, the 5 remaining calls must be placed in some combination among the 7 days. $$\text{again, unordered with replacement} \Rightarrow \binom{7 + 5 - 1}{5} = \binom{11}{5}$$ My thinking was then, having determined the total number of call-day combinations, as well as the total number of combinations with at least one call per day, the probability that each day had one call was trivially $\dots$ $$P(\text{one call per day}) = \frac{\binom{11}{5}}{\binom{18}{12}} = \frac{11}{442} \not\approx 0.2285$$ Where am I going wrong?","I've been working through some problems in Statistical Inference Second Edition (George Casella, Roger L. Berger), one of which is this already discussed problem . While the answer given makes sense, I'm having trouble understanding why the same probability can't be arrived at by calculating possible $\mathit{unordered}$ outcomes of calls mapped to days. Question restated: ""My telephone rings 12 times each week, the calls being randomly distributed among the 7 days. What is the probability that I get a least one call each day?"" While I am not interested in the answer, as it is already given, I am interested in why the following alternative approach doesn't work. What am I incorrect in assuming? Number of possible ways the 12 indistinguishable calls could be arranged among 7 days: $$\text{unordered with replacement} \Rightarrow \binom{7 + 12 - 1}{12} = \binom{18}{12}$$ To find the number of ways 12 calls could be spread among 7 days with at least one call per day, we first assign 1 call to each day. Next, the 5 remaining calls must be placed in some combination among the 7 days. $$\text{again, unordered with replacement} \Rightarrow \binom{7 + 5 - 1}{5} = \binom{11}{5}$$ My thinking was then, having determined the total number of call-day combinations, as well as the total number of combinations with at least one call per day, the probability that each day had one call was trivially $\dots$ $$P(\text{one call per day}) = \frac{\binom{11}{5}}{\binom{18}{12}} = \frac{11}{442} \not\approx 0.2285$$ Where am I going wrong?",,"['probability', 'combinatorics']"
46,Questions about Probability,Questions about Probability,,"We know that in a football game, Team $A$ wins against Team $B$ with probability $= 0.8$ We also know in a game, at the end of half-time, they tied. Then what's the probability $A$ wins against $B?$ Is it still $0.8$ or we should consider conditional probability?","We know that in a football game, Team $A$ wins against Team $B$ with probability $= 0.8$ We also know in a game, at the end of half-time, they tied. Then what's the probability $A$ wins against $B?$ Is it still $0.8$ or we should consider conditional probability?",,"['probability', 'discrete-mathematics']"
47,Probability with Calculus,Probability with Calculus,,"A point is chosen randomly in the region bounded by the curve $y = x^2$ and the line $y = 4$. Find the probability that the $y$-coordinate is less than $a$ for any $a$ in[0,4]. I think that I need to use calculus to find the area under the curve. However, since $y$ is bounded from 0 to 4, it seems like the answer should be $\frac{1}{2}$. Please help guide me in the right direction to get started, even if my intuition is correct.","A point is chosen randomly in the region bounded by the curve $y = x^2$ and the line $y = 4$. Find the probability that the $y$-coordinate is less than $a$ for any $a$ in[0,4]. I think that I need to use calculus to find the area under the curve. However, since $y$ is bounded from 0 to 4, it seems like the answer should be $\frac{1}{2}$. Please help guide me in the right direction to get started, even if my intuition is correct.",,"['calculus', 'probability']"
48,Asymptotics of the classical occupancy problem,Asymptotics of the classical occupancy problem,,"Classical Occupancy Problem . There are $n$ distinct labeled balls in an urn. $k$ of them of uniformly selected with replacement. What is the probability that the sample contains at least one ball of each kind. Let $(M_1,\ldots, M_n)$ be the vector of counts of each kind in the sample. The vector $(M_1,\ldots, M_n)$ follows multinomial distribution $\operatorname{Mult}\left(k, \{\frac{1}{n},\ldots, \frac{1}{n}\}\right)$, and the probability is $$    p_{k,n} = \Pr(M_1 > 0, \ldots, M_n >0)  \tag{1} $$ It can be explicitly computed either using inclusion-exclusion principle, or by building a recurrence relation for $p_{k,n}$: $$    p_{k,n} = \sum_{m=0}^n (-1)^m \binom{n}{m} \left(1-\frac{m}{n}\right)^k = \frac{n!}{n^k} \mathcal{S}_2\left(k, n\right) \tag{2} $$ where $\mathcal{S}_2\left(k, n\right)$ denotes Stirling number of the second kind . See Brian Gladman's notebook from mersseneforum.org or section 5.6 of Problems and snapshots from the world of probability for more details. For $k \ggg n$, the probability $p_{k,n}$ is very close to 1 (see DMLF for asymptotic behavior of the Stirling number). I am interested in obtaining more precise asymptotic expansion, perhaps by using CLT to evaluate $(1)$. References or explicit solutions are appreciated.","Classical Occupancy Problem . There are $n$ distinct labeled balls in an urn. $k$ of them of uniformly selected with replacement. What is the probability that the sample contains at least one ball of each kind. Let $(M_1,\ldots, M_n)$ be the vector of counts of each kind in the sample. The vector $(M_1,\ldots, M_n)$ follows multinomial distribution $\operatorname{Mult}\left(k, \{\frac{1}{n},\ldots, \frac{1}{n}\}\right)$, and the probability is $$    p_{k,n} = \Pr(M_1 > 0, \ldots, M_n >0)  \tag{1} $$ It can be explicitly computed either using inclusion-exclusion principle, or by building a recurrence relation for $p_{k,n}$: $$    p_{k,n} = \sum_{m=0}^n (-1)^m \binom{n}{m} \left(1-\frac{m}{n}\right)^k = \frac{n!}{n^k} \mathcal{S}_2\left(k, n\right) \tag{2} $$ where $\mathcal{S}_2\left(k, n\right)$ denotes Stirling number of the second kind . See Brian Gladman's notebook from mersseneforum.org or section 5.6 of Problems and snapshots from the world of probability for more details. For $k \ggg n$, the probability $p_{k,n}$ is very close to 1 (see DMLF for asymptotic behavior of the Stirling number). I am interested in obtaining more precise asymptotic expansion, perhaps by using CLT to evaluate $(1)$. References or explicit solutions are appreciated.",,"['probability', 'asymptotics']"
49,Does ergodicity imply stationarity?,Does ergodicity imply stationarity?,,"In general, if a random process is ergodic, does it imply that it is also stationary in any sense?","In general, if a random process is ergodic, does it imply that it is also stationary in any sense?",,"['probability', 'probability-theory']"
50,$L^1$ norm of product of independent random variables,norm of product of independent random variables,L^1,"I am trying to show that $\|XY\|_1 = \|X\|_1\|Y\|_1$ for $X,Y$ independent random variables, where $\|X\|_1 = \int{|X| d\mathbb{P}}$. I have a feeling that this result is intuitive, but could anyone explain from a measure theoretic perspective why this is true? Thanks","I am trying to show that $\|XY\|_1 = \|X\|_1\|Y\|_1$ for $X,Y$ independent random variables, where $\|X\|_1 = \int{|X| d\mathbb{P}}$. I have a feeling that this result is intuitive, but could anyone explain from a measure theoretic perspective why this is true? Thanks",,"['probability', 'statistics', 'measure-theory', 'probability-theory']"
51,Possibility of getting a 5 card hand all of the same suit,Possibility of getting a 5 card hand all of the same suit,,"How many five-card hands dealt from a standard deck of $52$ playing cards are all of the same suit? If a random hand is dealt, what is the probability that it will have this property? Would the probability be: $$\frac{\dbinom{13}{5}*\dbinom{4}{1}}{\dbinom{52}{5}}$$","How many five-card hands dealt from a standard deck of $52$ playing cards are all of the same suit? If a random hand is dealt, what is the probability that it will have this property? Would the probability be: $$\frac{\dbinom{13}{5}*\dbinom{4}{1}}{\dbinom{52}{5}}$$",,"['probability', 'combinatorics']"
52,"N tosses of a coin ,what is the probability that number of heads are even?","N tosses of a coin ,what is the probability that number of heads are even?",,"We have a coin with probability of head is p and probability for tail is (1-p). We toss the coin N times, what is the probability that the number of tosses that show head is even? What I've tried is to sum over all even k's (k= 0,2,4,...) and to sum up the probability that the number of heads is k. Is there a way to elinimate the sum and to give a closed formula?","We have a coin with probability of head is p and probability for tail is (1-p). We toss the coin N times, what is the probability that the number of tosses that show head is even? What I've tried is to sum over all even k's (k= 0,2,4,...) and to sum up the probability that the number of heads is k. Is there a way to elinimate the sum and to give a closed formula?",,['probability']
53,Confusion in stationary process and stationary distribution,Confusion in stationary process and stationary distribution,,"I have just started studying statistics, and have no background in this field(though I have a descent enough mathematical background). I was studying about stationary distributions and stationary processes, and the book I am reading says that A process is stationary if the joint distribution of random variables is same irrespective of time. Following are my doubts regarding this:- So does this mean that distribution(not joint) of all individual random variables (Xt) remains the same, independent of time ? I concluded from this that a stationary process is a process which has a stationary joint distribution of random variables , is this correct? If yes, then I guess it also implies stationary distribution of individual random variables(each Xt)? Lastly, it says on wikipedia page of stationary process that ""a stationary process is not the same thing as a ""process with a stationary distribution"""". This is the whole source of my confusion. A stationary process is something whose joint probability distribution doesn't change with time, so is there a difference between a stationary distribution and a distribution which doesn't change with time? (Is independent of time) Though I have no background of statistics, I am really eager to learn, and would be really grateful if someone could please explain in simple terms,i.e. of a beginner. Also, it'd be great if you could suggest a book which will help in understanding these concepts(specifically of stochastic modelling) easily. Thanks a ton.","I have just started studying statistics, and have no background in this field(though I have a descent enough mathematical background). I was studying about stationary distributions and stationary processes, and the book I am reading says that A process is stationary if the joint distribution of random variables is same irrespective of time. Following are my doubts regarding this:- So does this mean that distribution(not joint) of all individual random variables (Xt) remains the same, independent of time ? I concluded from this that a stationary process is a process which has a stationary joint distribution of random variables , is this correct? If yes, then I guess it also implies stationary distribution of individual random variables(each Xt)? Lastly, it says on wikipedia page of stationary process that ""a stationary process is not the same thing as a ""process with a stationary distribution"""". This is the whole source of my confusion. A stationary process is something whose joint probability distribution doesn't change with time, so is there a difference between a stationary distribution and a distribution which doesn't change with time? (Is independent of time) Though I have no background of statistics, I am really eager to learn, and would be really grateful if someone could please explain in simple terms,i.e. of a beginner. Also, it'd be great if you could suggest a book which will help in understanding these concepts(specifically of stochastic modelling) easily. Thanks a ton.",,"['probability', 'statistics', 'probability-distributions', 'stationary-processes']"
54,Sampling without replacement until object found,Sampling without replacement until object found,,"I'm wondering about sampling without replacement until an object is found. I can't seem to wrap my head around it. The random variable I want to use is X which I let bet the number of objects examined until the object is found. So I'm interested in the probability mass function here. My attempts so far are: (i) Take one sample at a time. Then each sample is a Bernoulli trial with probability at the k-th sample = 1/(n-k+1), 1 <= k <= n So to get P(X=x) I multiply each 1/(n-k+1) from 1 to k inclusive? i.e. P(X=x) = 1/(n-k+1)! (ii) The problem looks kind of like a hypergeometric distribution with parameters: number of draws = k, pop. size = n, contains 1 success But the hypergeometric pmf is constructed in terms of obtaining some number of successes from a potential group of successes within the population. For my problem however there is only one success in the potential success group and we want to stop when we get a success. So it's styled more in the way of a geometric distribution. Again, the random variable for a geometric dist. is number of trials needed to get a success. I'm confused anyway, if anyone could shed some light on this I'd be very grateful, thanks","I'm wondering about sampling without replacement until an object is found. I can't seem to wrap my head around it. The random variable I want to use is X which I let bet the number of objects examined until the object is found. So I'm interested in the probability mass function here. My attempts so far are: (i) Take one sample at a time. Then each sample is a Bernoulli trial with probability at the k-th sample = 1/(n-k+1), 1 <= k <= n So to get P(X=x) I multiply each 1/(n-k+1) from 1 to k inclusive? i.e. P(X=x) = 1/(n-k+1)! (ii) The problem looks kind of like a hypergeometric distribution with parameters: number of draws = k, pop. size = n, contains 1 success But the hypergeometric pmf is constructed in terms of obtaining some number of successes from a potential group of successes within the population. For my problem however there is only one success in the potential success group and we want to stop when we get a success. So it's styled more in the way of a geometric distribution. Again, the random variable for a geometric dist. is number of trials needed to get a success. I'm confused anyway, if anyone could shed some light on this I'd be very grateful, thanks",,"['probability', 'probability-distributions', 'random-variables']"
55,Ticket-Change probability problem,Ticket-Change probability problem,,"Here is another question from the book of V. Rohatgi and A. Saleh. I would like to ask help again. Here it goes: Waiting in line for a Saturday morning movie show are $2n$ children. Tickets are priced at a quarter each. Find the probability that nobody will have to wait for change if before a ticket is sold to the first customer, the cashier has $2k$ ($k<n$) quarters. Assume that it is equally likely that each ticket is paid for with a quarter or a half-dollar coin. I find it hard to understand the phrase ""nobody waits for change"". I hope someone can help. Thanks.","Here is another question from the book of V. Rohatgi and A. Saleh. I would like to ask help again. Here it goes: Waiting in line for a Saturday morning movie show are $2n$ children. Tickets are priced at a quarter each. Find the probability that nobody will have to wait for change if before a ticket is sold to the first customer, the cashier has $2k$ ($k<n$) quarters. Assume that it is equally likely that each ticket is paid for with a quarter or a half-dollar coin. I find it hard to understand the phrase ""nobody waits for change"". I hope someone can help. Thanks.",,"['probability', 'combinatorics', 'statistics']"
56,Birthday problem given the first birthday,Birthday problem given the first birthday,,"The famous 'birthday problem' finds that it takes 23 people to have a 50% chance of some two people having the same birthday. However, how does the question change if given that person 1's birthday is January 1st, how many people would it take to have 50% chance of another January 1st birthday? I think that the second question would require more people because we are looking for a specific pair while the original is looking for any pair. But exactly how are the numbers affected?","The famous 'birthday problem' finds that it takes 23 people to have a 50% chance of some two people having the same birthday. However, how does the question change if given that person 1's birthday is January 1st, how many people would it take to have 50% chance of another January 1st birthday? I think that the second question would require more people because we are looking for a specific pair while the original is looking for any pair. But exactly how are the numbers affected?",,"['probability', 'statistics', 'birthday']"
57,How to compute the relative difference between two numbers?,How to compute the relative difference between two numbers?,,"I currently do quality assurance work for a company that collects social media data and the term 1% gets tossed around a lot. They would like for to ensure that the data in our database has less than a 1% difference between the our database and source we are getting it from, but this is all relative to the value type. For example, if we are talking about Facebook ""likes"" then a difference of 2 and 4 isn't a big deal, but 20,000 and 40,000 is, however, with a typical percent difference formula both of these sets result in a percent difference of 100%. Is there some sort of formula that can is less sensitive for those extremely small values but is still sensitive enough to consider the difference between 10 and 20 to be greater than 1%?","I currently do quality assurance work for a company that collects social media data and the term 1% gets tossed around a lot. They would like for to ensure that the data in our database has less than a 1% difference between the our database and source we are getting it from, but this is all relative to the value type. For example, if we are talking about Facebook ""likes"" then a difference of 2 and 4 isn't a big deal, but 20,000 and 40,000 is, however, with a typical percent difference formula both of these sets result in a percent difference of 100%. Is there some sort of formula that can is less sensitive for those extremely small values but is still sensitive enough to consider the difference between 10 and 20 to be greater than 1%?",,"['probability', 'statistics']"
58,Asymptotics of maxima of i.i.d. chi-square random variables,Asymptotics of maxima of i.i.d. chi-square random variables,,"How to find the following: Let $X_1$, $X_2$, $X_3$,..., $X_n$, be i.i.d with chi-square distribution with one-degree of freedom. Find $a_n$ and $b_n$ such that $ a_n(\max_i X_i - b_n)$ converges in distribution to a nondegenerate random variable. I thought about Central limit theorem but i dont think here is the case?? Thanks a lot!","How to find the following: Let $X_1$, $X_2$, $X_3$,..., $X_n$, be i.i.d with chi-square distribution with one-degree of freedom. Find $a_n$ and $b_n$ such that $ a_n(\max_i X_i - b_n)$ converges in distribution to a nondegenerate random variable. I thought about Central limit theorem but i dont think here is the case?? Thanks a lot!",,"['probability', 'probability-theory', 'probability-distributions']"
59,Average absolute value of sum with Rademacher random variables,Average absolute value of sum with Rademacher random variables,,"Let $a_1, \ldots, a_n $ be independent Rademacher random variables with distribution $P(a_i=1) = P(a_i=-1) = \frac 12$. Estimate from below $$E \left|\sum_{i=1}^n a_i\right|.$$ I've reduced this problem to the next one (for even $n$): Estimate from below following $$\frac 1{2^{n-1}} \left(\sum_{k=n/2}^n kC_n^k - \sum_{k=0}^{n/2}kC_n^k\right).$$","Let $a_1, \ldots, a_n $ be independent Rademacher random variables with distribution $P(a_i=1) = P(a_i=-1) = \frac 12$. Estimate from below $$E \left|\sum_{i=1}^n a_i\right|.$$ I've reduced this problem to the next one (for even $n$): Estimate from below following $$\frac 1{2^{n-1}} \left(\sum_{k=n/2}^n kC_n^k - \sum_{k=0}^{n/2}kC_n^k\right).$$",,"['probability', 'probability-theory', 'inequality', 'binomial-coefficients', 'random-variables']"
60,"Is the mathematical concept of an ""operation"" necessarily deterministic?","Is the mathematical concept of an ""operation"" necessarily deterministic?",,"Does the mathematical concept of an operation require that the process is deterministic? If not, what are some example cases for non-deterministic operations? Motivation: I am coming from a software background and want to reconcile the subtle distinctions between the semantic intention of operators/operations in software and in pure math.  Obviously, operations in software applications can be non-deterministic, but I don't think this carries over to pure math.","Does the mathematical concept of an operation require that the process is deterministic? If not, what are some example cases for non-deterministic operations? Motivation: I am coming from a software background and want to reconcile the subtle distinctions between the semantic intention of operators/operations in software and in pure math.  Obviously, operations in software applications can be non-deterministic, but I don't think this carries over to pure math.",,"['probability', 'terminology', 'computer-science']"
61,How gaussian mixture models work?,How gaussian mixture models work?,,"I am given an example: Suppose 1000 observations are drawn from $N(0,1)$ and $N(5,2)$ with mixing parameters $\pi_{1}=0.2$ and $\pi_{2}=0.8$ respectively. Suppose we only know $\sigma$ and want to estimate $\mu$ and $\pi$. How does one go about using Gaussian Mixture models to estimate these parameters? I know I have to use the EM algorithm but I do not know where to start. I want to use this simple example to get a better understanding of how it works.","I am given an example: Suppose 1000 observations are drawn from $N(0,1)$ and $N(5,2)$ with mixing parameters $\pi_{1}=0.2$ and $\pi_{2}=0.8$ respectively. Suppose we only know $\sigma$ and want to estimate $\mu$ and $\pi$. How does one go about using Gaussian Mixture models to estimate these parameters? I know I have to use the EM algorithm but I do not know where to start. I want to use this simple example to get a better understanding of how it works.",,"['probability', 'machine-learning']"
62,How Can the Birthday Problem be solved directly,How Can the Birthday Problem be solved directly,,"How would one go about solving a variant of the birthday problem given below ""What is the probability of at least two people having the same birthday in a group of 23"" I know the answer is just above 0.5 but I am interested in how it is solved when one computes it by taking probabilities of two people having the same birthday, then of three people having the same birthday and so on rather solving it by finding the probability of people not having the same birthday.","How would one go about solving a variant of the birthday problem given below ""What is the probability of at least two people having the same birthday in a group of 23"" I know the answer is just above 0.5 but I am interested in how it is solved when one computes it by taking probabilities of two people having the same birthday, then of three people having the same birthday and so on rather solving it by finding the probability of people not having the same birthday.",,['probability']
63,A bound for the probability that a Brownian motion stays in an interval,A bound for the probability that a Brownian motion stays in an interval,,"Suppose I have a Brownian motion $X_t$ with $X_0=0$. Let $T$ be the first exit time of the interval $[-1,1]$. I'm trying to get a ""quick"" lower bound for the probability that $T$ is very large which is asymptotically reasonable. It's very easy to come up with nice upper bounds, but I can't find a way of bounding it below. I can get something with the reflection principle, but it's inelegant. Is there a trick or a pretty way of doing it.","Suppose I have a Brownian motion $X_t$ with $X_0=0$. Let $T$ be the first exit time of the interval $[-1,1]$. I'm trying to get a ""quick"" lower bound for the probability that $T$ is very large which is asymptotically reasonable. It's very easy to come up with nice upper bounds, but I can't find a way of bounding it below. I can get something with the reflection principle, but it's inelegant. Is there a trick or a pretty way of doing it.",,"['probability', 'stochastic-processes']"
64,$n$ balls into $n+1$ urns (with one special urn),balls into  urns (with one special urn),n n+1,"Assume that there are $n$ balls numbered from $1,2,\ldots,n$ and $n+1$ urns, numbered  as $0,1,\ldots,n$ Throw each ball randomly into one of $n$ urns: urn 1, urn 2, . . . , urn $n$. That is, any urn except urn $0$. (A ball goes to a certain urn with probability $1/n$) Check each urn and if there are more than one ball in an urn, choose one randomly and keep that in that urn and remove the other balls and put them into urn $0$. What is the probability that there are $k$ balls in urn 0?","Assume that there are $n$ balls numbered from $1,2,\ldots,n$ and $n+1$ urns, numbered  as $0,1,\ldots,n$ Throw each ball randomly into one of $n$ urns: urn 1, urn 2, . . . , urn $n$. That is, any urn except urn $0$. (A ball goes to a certain urn with probability $1/n$) Check each urn and if there are more than one ball in an urn, choose one randomly and keep that in that urn and remove the other balls and put them into urn $0$. What is the probability that there are $k$ balls in urn 0?",,"['probability', 'combinatorics', 'balls-in-bins']"
65,When does the next bus come?,When does the next bus come?,,"People arrive at a bus stop according to a Poisson process at rate $\lambda$ per minute. The bus leaves every $n$ minutes, but you have no idea when the last bus left. You observe that there are $k$ people waiting at the stop. Given this information, when do you expect the next bus to arrive? Part of me says this is elementary. But I can't think of where to even begin solving it.","People arrive at a bus stop according to a Poisson process at rate $\lambda$ per minute. The bus leaves every $n$ minutes, but you have no idea when the last bus left. You observe that there are $k$ people waiting at the stop. Given this information, when do you expect the next bus to arrive? Part of me says this is elementary. But I can't think of where to even begin solving it.",,"['probability', 'queueing-theory']"
66,Expectation value of $1/x$,Expectation value of,1/x,"Given a random variable $x$ which is assumed to follow a Gaussian distribution $x \sim N( \mu, \sigma^2 )$ and $x$ is further known to be positive, I am interested in the following expectation value: $E\left[ \frac{1}{x} \right]$  . In my case $\mu \gg 0$, which might allow to ignore that $x$ is always positive. Does anyone knows about a collection of known expectation values under the normal distribution? Many thanks in advance","Given a random variable $x$ which is assumed to follow a Gaussian distribution $x \sim N( \mu, \sigma^2 )$ and $x$ is further known to be positive, I am interested in the following expectation value: $E\left[ \frac{1}{x} \right]$  . In my case $\mu \gg 0$, which might allow to ignore that $x$ is always positive. Does anyone knows about a collection of known expectation values under the normal distribution? Many thanks in advance",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution']"
67,Covariance and variance of a Poisson r.v.,Covariance and variance of a Poisson r.v.,,"Given a Poisson process $N(t),t\geq 0$ with rate $\lambda$ and another r.v. $T$ independent of $N(t)$ with mean $\mu$ and variance $\sigma^2$, I would like to compute the following quantities: $$ \mathbb{Cov}(T,N(T)) \ \ \mbox{ and } \ \ \mathbb{Var}(N(T))$$ My guess is respectively: $\lambda \mu + \lambda \sigma^2$ and $\sigma^2\lambda$. But I am not sure it is correct nor how to justify some steps. Anyone knows? Thank you very much!","Given a Poisson process $N(t),t\geq 0$ with rate $\lambda$ and another r.v. $T$ independent of $N(t)$ with mean $\mu$ and variance $\sigma^2$, I would like to compute the following quantities: $$ \mathbb{Cov}(T,N(T)) \ \ \mbox{ and } \ \ \mathbb{Var}(N(T))$$ My guess is respectively: $\lambda \mu + \lambda \sigma^2$ and $\sigma^2\lambda$. But I am not sure it is correct nor how to justify some steps. Anyone knows? Thank you very much!",,['probability']
68,Multiple dice rolls (D&D Skill challenge),Multiple dice rolls (D&D Skill challenge),,"In Dungeons and Dragons there is something called a skill challenge, which involves rolling some dice (no surprise there). An example of a skill challenge: Skill challenge DC 25 thievery. Roll a d20* and add your thievery bonus (let's say 11) and check if the result matches or goes over 25 take note and roll again (next turn). As soon as you have five rolls under 25 you fail. As soon as you have 2 rolls over or equal to 25 you succeed in the skill challenge. How do I calculate the odds of being successful in a skill challenge? With the numbers I provided I need at least a 14 to match the DC 25. That means that I have $7/20$ odds of matching (or going over) the DC (and $13/20$ for the opposite). If I only had to match the DC once the math would be easy: $(13/20)^5$ is the probability of failing, so $1-(13/20)^5$ is the probability of succeeding. * d20 = 20 sided die, numbered 1-20.","In Dungeons and Dragons there is something called a skill challenge, which involves rolling some dice (no surprise there). An example of a skill challenge: Skill challenge DC 25 thievery. Roll a d20* and add your thievery bonus (let's say 11) and check if the result matches or goes over 25 take note and roll again (next turn). As soon as you have five rolls under 25 you fail. As soon as you have 2 rolls over or equal to 25 you succeed in the skill challenge. How do I calculate the odds of being successful in a skill challenge? With the numbers I provided I need at least a 14 to match the DC 25. That means that I have $7/20$ odds of matching (or going over) the DC (and $13/20$ for the opposite). If I only had to match the DC once the math would be easy: $(13/20)^5$ is the probability of failing, so $1-(13/20)^5$ is the probability of succeeding. * d20 = 20 sided die, numbered 1-20.",,"['probability', 'dice']"
69,Expected Number of Steps to Order First n Integers,Expected Number of Steps to Order First n Integers,,"Suppose we begin with a random permutation of the first $n$ integers. At each step, we do the following: Leave the integers already in the correct position where they are For the remaining integers, say $a_1, a_2, \ldots, a_{k},$ perform a (random) derangement (in other words, $\sigma$ has no fixed points) $\sigma: \{1, 2, \ldots, k\} \to \{1, 2, \ldots, k\}$ on the set of indices, i.e. take $\{a_1, a_2, \ldots, a_{k}\}$ to $\{a_{\sigma(1)}, a_{\sigma(2)},\ldots, a_{\sigma(k)}\}.$ Repeat this until we arrive at the correct ordering, namely $\{1, 2, 3, \ldots, n\}.$ What is the expected number of steps for this process? Example: If you start with the permutation $\{2, 1, 4, 3\},$ then there are $9$ possibilities for the next step (by composing with a derangement), namely:$\{1, 2, 3, 4\}, \{1, 3, 2, 4\}, \{1, 4, 3, 2\}, \{3, 2, 1, 4\},$ $\{3, 4, 2, 1\}, \{3, 4, 1, 2\}, \{4, 2, 3, 1\}, \{4, 3, 1, 2\},$ and $\{4, 3, 2, 1\}.$ If, instead, we had started with $\{1, 3, 4, 2\},$ then the possibilities would be $\{1, 2, 3, 4\}$ and $\{1, 4, 2, 3\}.$ See AoPS for the original discussion of this problem. It's not difficult to write a recursion for $E_n$ in terms of $E_{D_i},$ where $E_{D_i}$ is the expected number of steps given that we begin with precisely $(n-i)$ fixed points. However, the structure of each derangement plays a role as well, so the problem becomes extremely complicated, even for small values of $n.$","Suppose we begin with a random permutation of the first $n$ integers. At each step, we do the following: Leave the integers already in the correct position where they are For the remaining integers, say $a_1, a_2, \ldots, a_{k},$ perform a (random) derangement (in other words, $\sigma$ has no fixed points) $\sigma: \{1, 2, \ldots, k\} \to \{1, 2, \ldots, k\}$ on the set of indices, i.e. take $\{a_1, a_2, \ldots, a_{k}\}$ to $\{a_{\sigma(1)}, a_{\sigma(2)},\ldots, a_{\sigma(k)}\}.$ Repeat this until we arrive at the correct ordering, namely $\{1, 2, 3, \ldots, n\}.$ What is the expected number of steps for this process? Example: If you start with the permutation $\{2, 1, 4, 3\},$ then there are $9$ possibilities for the next step (by composing with a derangement), namely:$\{1, 2, 3, 4\}, \{1, 3, 2, 4\}, \{1, 4, 3, 2\}, \{3, 2, 1, 4\},$ $\{3, 4, 2, 1\}, \{3, 4, 1, 2\}, \{4, 2, 3, 1\}, \{4, 3, 1, 2\},$ and $\{4, 3, 2, 1\}.$ If, instead, we had started with $\{1, 3, 4, 2\},$ then the possibilities would be $\{1, 2, 3, 4\}$ and $\{1, 4, 2, 3\}.$ See AoPS for the original discussion of this problem. It's not difficult to write a recursion for $E_n$ in terms of $E_{D_i},$ where $E_{D_i}$ is the expected number of steps given that we begin with precisely $(n-i)$ fixed points. However, the structure of each derangement plays a role as well, so the problem becomes extremely complicated, even for small values of $n.$",,"['probability', 'combinatorics']"
70,Scaling of random variables,Scaling of random variables,,"Note: I will use $\mathbb{P}\{X \in dx\}$ to denote $f(x)dx$ where $f(x)$ is the pdf of $X$. While doing some homework, I came across a fault in my intuition. I was scaling a standard normally distributed random variable $Z$. Edit: I was missing the infinitesimals $dx$ and $dx/c$, so everything works out in the end. Thank you Jokiri! $$\mathbb{P}\{cX \in dx\} = \frac{e^{-x^2 / 2c^2}}{\sqrt{2\pi c^2}}$$ while $$\mathbb{P} \left\{X \in \frac{dx}{c}\right\} = \frac{e^{-(x/c)^2/2}}{\sqrt{2\pi}}$$ Could anyone help me understand why the following equality doesn't hold? Edit: it does, see edit below $$\mathbb{P}\{cX \in dx\} \ne  \mathbb{P} \left\{X \in \frac{dx}{c}\right\}$$ I have been looking around, and it seems that equality of the cdf holds, though: $$\mathbb{P}\{cX < x \} = \mathbb{P}\left\{X < \frac xc\right\}.$$ Thank you in advance! This question came out of a silly mistake on my part. Let me attempt to try to set things straight. Let $Y = cX$. Let $X$ have pdf $f_X$ and $Y$ have pdf $f_Y$. $$\mathbb{E}[Y] = \mathbb{E}[cX] = \int_{-\infty}^\infty cx\,f_X(x)\mathop{dx} =\int_{-\infty}^\infty y\, f_X(y/c) \frac{dy}{c}$$ So, $f_Y(y) = \frac 1c f_X(y/c)$. Thank you for the help, and sorry for my mistake.","Note: I will use $\mathbb{P}\{X \in dx\}$ to denote $f(x)dx$ where $f(x)$ is the pdf of $X$. While doing some homework, I came across a fault in my intuition. I was scaling a standard normally distributed random variable $Z$. Edit: I was missing the infinitesimals $dx$ and $dx/c$, so everything works out in the end. Thank you Jokiri! $$\mathbb{P}\{cX \in dx\} = \frac{e^{-x^2 / 2c^2}}{\sqrt{2\pi c^2}}$$ while $$\mathbb{P} \left\{X \in \frac{dx}{c}\right\} = \frac{e^{-(x/c)^2/2}}{\sqrt{2\pi}}$$ Could anyone help me understand why the following equality doesn't hold? Edit: it does, see edit below $$\mathbb{P}\{cX \in dx\} \ne  \mathbb{P} \left\{X \in \frac{dx}{c}\right\}$$ I have been looking around, and it seems that equality of the cdf holds, though: $$\mathbb{P}\{cX < x \} = \mathbb{P}\left\{X < \frac xc\right\}.$$ Thank you in advance! This question came out of a silly mistake on my part. Let me attempt to try to set things straight. Let $Y = cX$. Let $X$ have pdf $f_X$ and $Y$ have pdf $f_Y$. $$\mathbb{E}[Y] = \mathbb{E}[cX] = \int_{-\infty}^\infty cx\,f_X(x)\mathop{dx} =\int_{-\infty}^\infty y\, f_X(y/c) \frac{dy}{c}$$ So, $f_Y(y) = \frac 1c f_X(y/c)$. Thank you for the help, and sorry for my mistake.",,['probability']
71,Restrictions on a bounded variable's mean and standard deviation,Restrictions on a bounded variable's mean and standard deviation,,"Given a random variable whose values are between $0$ and $1$, it is not difficult to see that the mean, or the expected value, is between $0$ and $1$, and the standard deviation is between $0$ and $\tfrac{1}{2}$. However, not every combination is possible. If $\sigma=0$ then the mean could indeed be everywhere in $[0,1]$, but I tend to believe that $\sigma=\frac{1}{2}$ is only possible if $E[X] = \frac{1}{2}$. Am I right? Are there simple restrictions involving a bounded variable's expected value and standard deviation? Edit: Using the equality $\sigma(X) = \sigma(X-\frac{1}{2})$ we can get the equality $\sigma^2+(E[X]-\frac{1}{2})^2 = E[(X-\frac{1}{2})^2]$, the last expression being bounded by $0$ and $\frac{1}{4}$, so we get that the possible combinations must lie in the upper half circle (in the $\sigma-\mu$ plane) of radius $\frac{1}{2}$ around $\sigma=0,\mu=\frac{1}{2}$. Can we get a better result, or can any combination in the circle be reached?","Given a random variable whose values are between $0$ and $1$, it is not difficult to see that the mean, or the expected value, is between $0$ and $1$, and the standard deviation is between $0$ and $\tfrac{1}{2}$. However, not every combination is possible. If $\sigma=0$ then the mean could indeed be everywhere in $[0,1]$, but I tend to believe that $\sigma=\frac{1}{2}$ is only possible if $E[X] = \frac{1}{2}$. Am I right? Are there simple restrictions involving a bounded variable's expected value and standard deviation? Edit: Using the equality $\sigma(X) = \sigma(X-\frac{1}{2})$ we can get the equality $\sigma^2+(E[X]-\frac{1}{2})^2 = E[(X-\frac{1}{2})^2]$, the last expression being bounded by $0$ and $\frac{1}{4}$, so we get that the possible combinations must lie in the upper half circle (in the $\sigma-\mu$ plane) of radius $\frac{1}{2}$ around $\sigma=0,\mu=\frac{1}{2}$. Can we get a better result, or can any combination in the circle be reached?",,"['probability', 'statistics']"
72,What's the easiest way to show that a random walk can go arbitrarily far?,What's the easiest way to show that a random walk can go arbitrarily far?,,"Let's consider the simplest situation. On the one dimensional line of integers, and we starts from the origin. Each time we either move left or right (at the same probability) for 1 unit. How do I show that, for however large $m$, the probability that we eventually go farther than $m$ units from the origin is $1$?","Let's consider the simplest situation. On the one dimensional line of integers, and we starts from the origin. Each time we either move left or right (at the same probability) for 1 unit. How do I show that, for however large $m$, the probability that we eventually go farther than $m$ units from the origin is $1$?",,"['probability', 'random-walk']"
73,Sum of truncated normals,Sum of truncated normals,,"Suppose $X_1, \dots, X_n$ are truncated standard normal variables, truncated so that $X_i \geq 0$ (that is, $X_i$ is drawn as a standard normal, conditional on $X_i \geq 0$) Let $c_1, \dots, c_n$ be non-negative coefficients. What does the distribution of $\sum_i c_i Y_i$ look like? Does it have, or approximately have, a standard distribution, such as a truncated normal distribution? Original question : Suppose $X_1, \dots, X_n$ are iid Normal random variables, with mean 0 and variances $\sigma_1, \dots, \sigma_n$. Let $Y_i = \max(0,X_i)$. (So $Y_i$ is a truncated normal random variable). What does the distribution of $\sum_i Y_i$ look like? Does it have, or approximately have, a standard distribution?","Suppose $X_1, \dots, X_n$ are truncated standard normal variables, truncated so that $X_i \geq 0$ (that is, $X_i$ is drawn as a standard normal, conditional on $X_i \geq 0$) Let $c_1, \dots, c_n$ be non-negative coefficients. What does the distribution of $\sum_i c_i Y_i$ look like? Does it have, or approximately have, a standard distribution, such as a truncated normal distribution? Original question : Suppose $X_1, \dots, X_n$ are iid Normal random variables, with mean 0 and variances $\sigma_1, \dots, \sigma_n$. Let $Y_i = \max(0,X_i)$. (So $Y_i$ is a truncated normal random variable). What does the distribution of $\sum_i Y_i$ look like? Does it have, or approximately have, a standard distribution?",,"['probability', 'statistics']"
74,Probability and game,Probability and game,,"This should be known as ""gambler's ruin"".  In a game, at each step, you can win 1\$ or lose 1\$. Let $Z_i$ be a variable that can assume as values 1 or -1. Let $$ X_n=\sum_{i=0}^n Z_i . $$ Can you show me in details how to calculate $P(X_n \geq a)$ for a certain $a>0$?  I thought that it was the case to use the cumulative binomial distribution, but I tried to compare my results with the data I have and they did not match. As second question, I would appreciate just a little hint on how to compute that probability with excel.","This should be known as ""gambler's ruin"".  In a game, at each step, you can win 1\$ or lose 1\$. Let $Z_i$ be a variable that can assume as values 1 or -1. Let $$ X_n=\sum_{i=0}^n Z_i . $$ Can you show me in details how to calculate $P(X_n \geq a)$ for a certain $a>0$?  I thought that it was the case to use the cumulative binomial distribution, but I tried to compare my results with the data I have and they did not match. As second question, I would appreciate just a little hint on how to compute that probability with excel.",,['probability']
75,How does a function acting on a random variable change the probability density function of that random variable?,How does a function acting on a random variable change the probability density function of that random variable?,,"Given a random variable $X$ with probability density function $P(X)$, and given a transformation function $f(x)$, how does one determine the new resultant probability density function: $P(f(X))$? For example: Given random variable $X$ which is evenly distributed over the range $[0,2\pi ]$ such that $P(X) = \dfrac{1}{(2\pi)}$, what would be the probability density function of random variable $Y$ where $Y = \sin(X)$? This blog post, explains how to get the pdf for $\sin(X)$, but I'd like to know if there is a way to solve this problem in the general case for a transformation of $f(X)$.","Given a random variable $X$ with probability density function $P(X)$, and given a transformation function $f(x)$, how does one determine the new resultant probability density function: $P(f(X))$? For example: Given random variable $X$ which is evenly distributed over the range $[0,2\pi ]$ such that $P(X) = \dfrac{1}{(2\pi)}$, what would be the probability density function of random variable $Y$ where $Y = \sin(X)$? This blog post, explains how to get the pdf for $\sin(X)$, but I'd like to know if there is a way to solve this problem in the general case for a transformation of $f(X)$.",,"['probability', 'probability-distributions']"
76,"Probability that, given a set of uniform random variables, the difference between the two smallest values is greater than a certain value","Probability that, given a set of uniform random variables, the difference between the two smallest values is greater than a certain value",,"Let $\{X_i\}$  be $n$ iid uniform(0, 1) random variables.  How do I compute the probability that the difference between the second smallest value and the smallest value is at least $c$? I've messed around with this numerically and have arrived at the conjecture that the answer is $(1-c)^n$, but I haven't been able to derive this. I see that $(1-c)^n$ is the probability that all the values would be at least $c$, so perhaps this is related?","Let $\{X_i\}$  be $n$ iid uniform(0, 1) random variables.  How do I compute the probability that the difference between the second smallest value and the smallest value is at least $c$? I've messed around with this numerically and have arrived at the conjecture that the answer is $(1-c)^n$, but I haven't been able to derive this. I see that $(1-c)^n$ is the probability that all the values would be at least $c$, so perhaps this is related?",,"['probability', 'uniform-distribution']"
77,Ordering of a deck of cards,Ordering of a deck of cards,,"If you shuffle n cards as follows: Go through the deck one card at a time and at each card, flip a fair coin.  If the coin comes up head, then leave the card where it is, and if it comes up tails move that card to the end of the deck. For example, if n =4,  and the initial ordering is 1,2,3,4, and outcome of the successive flips is h,t,t,h, then the ordering at the end of the round is 1,4,2,3. Assuming all possible outcomes of the coin flips are equally likely, what is the probability that the ordering after one round is the same as the initial ordering? Attempt: If the ordering after n flips is the same as the initial ordering, then you would have to roll all heads since rolling heads doesn't change the ordering. So the answer would be (1/2)^n?","If you shuffle n cards as follows: Go through the deck one card at a time and at each card, flip a fair coin.  If the coin comes up head, then leave the card where it is, and if it comes up tails move that card to the end of the deck. For example, if n =4,  and the initial ordering is 1,2,3,4, and outcome of the successive flips is h,t,t,h, then the ordering at the end of the round is 1,4,2,3. Assuming all possible outcomes of the coin flips are equally likely, what is the probability that the ordering after one round is the same as the initial ordering? Attempt: If the ordering after n flips is the same as the initial ordering, then you would have to roll all heads since rolling heads doesn't change the ordering. So the answer would be (1/2)^n?",,['probability']
78,Maximizing growth rate in betting on multiple events,Maximizing growth rate in betting on multiple events,,"Suppose we have $n$ independent events. We know their probabilities $p_i,\dotsc,p_n$. We are given betting odds $c_1,\dotsc,c_n$. We can make bets to any of the events, and also any combination of events. For every bet (be it a single or combined-event), the bookkeepers take a certain percentage $t$ from the winnings amount. It is obvious that we can make $N=\sum_{i=1}^{n}\binom{n}{i}$ different bets. We bet a fraction $b_i$ of our ""bankroll"" for the $i$-th of the N possible bets. If $b_i=0$, it means we don't make the $i$-th bet at all. Is there a way of determining the optimal set of $b_1,\dotsc,b_N$ so that, in the long run, the ""bankroll"" increases maximally? (Something like the Kelly criterion)","Suppose we have $n$ independent events. We know their probabilities $p_i,\dotsc,p_n$. We are given betting odds $c_1,\dotsc,c_n$. We can make bets to any of the events, and also any combination of events. For every bet (be it a single or combined-event), the bookkeepers take a certain percentage $t$ from the winnings amount. It is obvious that we can make $N=\sum_{i=1}^{n}\binom{n}{i}$ different bets. We bet a fraction $b_i$ of our ""bankroll"" for the $i$-th of the N possible bets. If $b_i=0$, it means we don't make the $i$-th bet at all. Is there a way of determining the optimal set of $b_1,\dotsc,b_N$ so that, in the long run, the ""bankroll"" increases maximally? (Something like the Kelly criterion)",,"['probability', 'gambling']"
79,Bounds on off-diagonal entries of a correlation matrix,Bounds on off-diagonal entries of a correlation matrix,,Assume that all the entries of an $n \times n$ correlation matrix which are not on the main diagonal are equal to $q$. Find upper and lower bounds on the possible values of $q$. I know that the matrix should be positive semidefinite but how to proceed to get the upper and lower bounds? Thanks!,Assume that all the entries of an $n \times n$ correlation matrix which are not on the main diagonal are equal to $q$. Find upper and lower bounds on the possible values of $q$. I know that the matrix should be positive semidefinite but how to proceed to get the upper and lower bounds? Thanks!,,"['probability', 'matrices', 'correlation']"
80,"If $X_1, ..., X_n$ are Exp($\lambda$) random variables, what is the best unbiased estimator of $e^{-\lambda}$?","If  are Exp() random variables, what is the best unbiased estimator of ?","X_1, ..., X_n \lambda e^{-\lambda}","Let $X_1, ..., X_n$ be random variables with pdf $$\frac 1 \lambda e^{-x / \lambda} I(x > 0).$$ The goal is to find the best unbiased estimator of $h(\lambda) = e^{-\lambda}$ (incidentally, this is equal to $P(X_1 > \lambda^2)$). I'm currently tutoring some graduate students for a first year qualifying examination and in an embarrassing turn of events I've been unable to figure out the solution to this problem on a past exam. I'm sure I'm missing something obvious. Some thoughts: the MLE of $h(\lambda)$ is $e^{-\bar X}$. The expectation can be calculated easily, but it is hopelessly biased: $$E[e^{-\bar X}] = M_{\bar X} (-1) = M_{X_1} \left(-\frac 1 n\right)^n = \left(1 + \frac \lambda n\right)^{-n}$$ where $M_Y$ is the moment generating function of $Y$. There are only two ways of going about this that I can think of that are available to the students. One is to ""guess"" a $g(\bar X)$ such that $E[g(\bar X)] = e^{-\lambda}$. The other is to find an unbiased estimate of $e^{-\lambda}$ and Rao-Blackwell to finish it off (a prior part to the same question essentially sets up the ability to carry out such a calculation, so it is somewhat hinted at that this might work).","Let $X_1, ..., X_n$ be random variables with pdf $$\frac 1 \lambda e^{-x / \lambda} I(x > 0).$$ The goal is to find the best unbiased estimator of $h(\lambda) = e^{-\lambda}$ (incidentally, this is equal to $P(X_1 > \lambda^2)$). I'm currently tutoring some graduate students for a first year qualifying examination and in an embarrassing turn of events I've been unable to figure out the solution to this problem on a past exam. I'm sure I'm missing something obvious. Some thoughts: the MLE of $h(\lambda)$ is $e^{-\bar X}$. The expectation can be calculated easily, but it is hopelessly biased: $$E[e^{-\bar X}] = M_{\bar X} (-1) = M_{X_1} \left(-\frac 1 n\right)^n = \left(1 + \frac \lambda n\right)^{-n}$$ where $M_Y$ is the moment generating function of $Y$. There are only two ways of going about this that I can think of that are available to the students. One is to ""guess"" a $g(\bar X)$ such that $E[g(\bar X)] = e^{-\lambda}$. The other is to find an unbiased estimate of $e^{-\lambda}$ and Rao-Blackwell to finish it off (a prior part to the same question essentially sets up the ability to carry out such a calculation, so it is somewhat hinted at that this might work).",,"['probability', 'statistics']"
81,Nested sets convergence,Nested sets convergence,,"Define $\xi\in C^1([-1,1]\times[-1,1])$ such that $$ \int\limits_{-1}^1 \xi(x,y)\,dy = 1 $$ for all $x\in[-1,1]$ and $\xi\geq 0$. Put $A_0 = [0,1]$ and $$A_{n+1} = \left\{x\in A_n:\int\limits_{A_n}\xi(x,y)\,dy = 1\right\}.$$ Are there methods to find the rate of convergence of $\lambda(A_{n}\setminus A_{n+1})$ where $\lambda$ is a Lebesgue measure? Maybe you can refer me to the relevant literature? There are at least two kinds of situation: for some $N$  we have $A_N = \emptyset$, then $A_{N+1} = A_N$ and $\lambda(A_n\setminus A_{n+1}) = 0$ for $n\geq N$. for some $N$  we have $A_N = A_{N+1}$, then again $\lambda(A_n\setminus A_{n+1}) = 0$ for $n\geq N$. Can you help me to construct an example for the third case, namely when $A_n\neq A_{n+1}$ for all $n\geq0$ (of course if such an example exists)? We can also assume for this example that $\xi\in \operatorname{Lip}([-1,1]\times[-1,1])$, not necessary differentiable. I am mostly interested if it is possible to find a Lipschitz $\xi$ such that $A_n$ coincide with iterations of Smith-Volterra-Cantor set (Fat Cantor Set)?","Define $\xi\in C^1([-1,1]\times[-1,1])$ such that $$ \int\limits_{-1}^1 \xi(x,y)\,dy = 1 $$ for all $x\in[-1,1]$ and $\xi\geq 0$. Put $A_0 = [0,1]$ and $$A_{n+1} = \left\{x\in A_n:\int\limits_{A_n}\xi(x,y)\,dy = 1\right\}.$$ Are there methods to find the rate of convergence of $\lambda(A_{n}\setminus A_{n+1})$ where $\lambda$ is a Lebesgue measure? Maybe you can refer me to the relevant literature? There are at least two kinds of situation: for some $N$  we have $A_N = \emptyset$, then $A_{N+1} = A_N$ and $\lambda(A_n\setminus A_{n+1}) = 0$ for $n\geq N$. for some $N$  we have $A_N = A_{N+1}$, then again $\lambda(A_n\setminus A_{n+1}) = 0$ for $n\geq N$. Can you help me to construct an example for the third case, namely when $A_n\neq A_{n+1}$ for all $n\geq0$ (of course if such an example exists)? We can also assume for this example that $\xi\in \operatorname{Lip}([-1,1]\times[-1,1])$, not necessary differentiable. I am mostly interested if it is possible to find a Lipschitz $\xi$ such that $A_n$ coincide with iterations of Smith-Volterra-Cantor set (Fat Cantor Set)?",,"['probability', 'general-topology', 'functional-analysis', 'measure-theory', 'stochastic-processes']"
82,The infimum of a drifting Brownian motion,The infimum of a drifting Brownian motion,,"Using the reflection principle, it's easily shown that the infimum $\displaystyle \inf_{u \in [0, T]} B_u$ of a non-drifting Brownian motion $B_t$ has the same distribution as $-| B_T |$. The Cameron–Martin theorem tells us that a drifting Brownian motion $X_t = B_t + c t$ is a non-drifting one under a certain change of measure. Combining these two results, it seems to me that the p.d.f. of $\displaystyle \inf_{u \in [0, T]} X_u$ is $$\frac{2 \exp \left(-\frac{(x - c T)^2}{2 T} \right)}{\sqrt{2 \pi T}} + 2 c \exp \left( 2 c x \right) \Phi \left( \frac{x + c T}{\sqrt{T}} \right)$$ but I'm unsure of the correctness of my derivation, let alone the correctness of the result. I suspect it's wrong, but only because I can't get the correct result in a later calculation using this density function. Is the density function above wrong, and if so, what is the correct distribution? Edit : Tried the derivation again more carefully and got a different density, which seems more reasonable. Still have lingering doubts, however.","Using the reflection principle, it's easily shown that the infimum $\displaystyle \inf_{u \in [0, T]} B_u$ of a non-drifting Brownian motion $B_t$ has the same distribution as $-| B_T |$. The Cameron–Martin theorem tells us that a drifting Brownian motion $X_t = B_t + c t$ is a non-drifting one under a certain change of measure. Combining these two results, it seems to me that the p.d.f. of $\displaystyle \inf_{u \in [0, T]} X_u$ is $$\frac{2 \exp \left(-\frac{(x - c T)^2}{2 T} \right)}{\sqrt{2 \pi T}} + 2 c \exp \left( 2 c x \right) \Phi \left( \frac{x + c T}{\sqrt{T}} \right)$$ but I'm unsure of the correctness of my derivation, let alone the correctness of the result. I suspect it's wrong, but only because I can't get the correct result in a later calculation using this density function. Is the density function above wrong, and if so, what is the correct distribution? Edit : Tried the derivation again more carefully and got a different density, which seems more reasonable. Still have lingering doubts, however.",,"['probability', 'stochastic-processes', 'brownian-motion']"
83,Bertrand's paradox (statistics),Bertrand's paradox (statistics),,"I just learned about Bertrand paradox in today's class, and am very shocked. I was wondering if there are indeed only 3 (known?) unique ways of picking a chord in a circle at random, with 3 different probability values for the lengths being shorter than a side of an inscribed equilateral triangle, or whether there are infinitely many unique ways of picking a random chord in a circle of this length (and consequently infinitely many unique probabilities corresponding to each random picking method [countably/uncountably infinite then?]). Thanks!","I just learned about Bertrand paradox in today's class, and am very shocked. I was wondering if there are indeed only 3 (known?) unique ways of picking a chord in a circle at random, with 3 different probability values for the lengths being shorter than a side of an inscribed equilateral triangle, or whether there are infinitely many unique ways of picking a random chord in a circle of this length (and consequently infinitely many unique probabilities corresponding to each random picking method [countably/uncountably infinite then?]). Thanks!",,['probability']
84,How do you calculate the average length of a random binary tree?,How do you calculate the average length of a random binary tree?,,"Assuming that you start out with a root node, and decide with 50% probability whether or not to add two children nodes. If they do, repeat this process for them. How can you find the average length of this random binary tree? I'm thinking along the lines of $\displaystyle\lim_{n\to\infty}\sum\limits_{i=1}^n (\frac{n}{2})^2$. because 1/2 * n represents 50% probability, and I'm squaring it because the tree gets exponentially larger. However, I feel like I've done something terribly wrong (probably because I have). Can anyone give me some help?","Assuming that you start out with a root node, and decide with 50% probability whether or not to add two children nodes. If they do, repeat this process for them. How can you find the average length of this random binary tree? I'm thinking along the lines of $\displaystyle\lim_{n\to\infty}\sum\limits_{i=1}^n (\frac{n}{2})^2$. because 1/2 * n represents 50% probability, and I'm squaring it because the tree gets exponentially larger. However, I feel like I've done something terribly wrong (probably because I have). Can anyone give me some help?",,['probability']
85,What is the probability that the coin drawn is fair,What is the probability that the coin drawn is fair,,"A box contains $n$ number of coins, $m$ of which are fair and the rest are biased. The probability of getting a head when a fair coin is tossed is $1/2$, while it is $2/3$ when a biased coin is tossed. A coin is drawn from the box at random and is tossed twice. The first time it shows a head and the second time it shows tail. What is the probability that the coin drawn is fair.","A box contains $n$ number of coins, $m$ of which are fair and the rest are biased. The probability of getting a head when a fair coin is tossed is $1/2$, while it is $2/3$ when a biased coin is tossed. A coin is drawn from the box at random and is tossed twice. The first time it shows a head and the second time it shows tail. What is the probability that the coin drawn is fair.",,['probability']
86,Calculating a sample size based on a confidence level,Calculating a sample size based on a confidence level,,"It's been a while since my last statistics class... I have $404$ files that went through some automated generation process. I would like to manually verify some of them to make sure that their data is indeed correct. I want to use probability to help me out so that I don't need to check every single file. How would I calculate what sample size I should use to reach a certain confidence level? For example, if I would like to say with $95\%$ confidence that the files are correct, how many of them do I have to check? I found an online calculator , but I'm not entirely sure what I should put for the confidence interval. Say I put 20% and leave the confidence factor at $95\%$ . I get a sample size of 23. Let's say now that I tested 23 random files and all of them were fine. Does that mean that ""I can be $95\%$ confident that 80% to 100% of the files are correct""? Does this mean, then, that for my original question, I would need to use a 99% confidence level with a 4% confidence interval, then I would need to verify that the 291 files (the sample size it gave me) are all correct. And only then I can say with 95% confidence that the files are correct? (99% +- 4% = 95% to 100%) It also mentions something about percentages which I'm not quite clear on... does the fact that most (i.e. 100%) of the files I test are valid (since if I found an invalid one, I would stop the whole process and examine my generation process for errors) mean that I can use a smaller sample to get the same confidence factor? If so, how would I calculate it?","It's been a while since my last statistics class... I have files that went through some automated generation process. I would like to manually verify some of them to make sure that their data is indeed correct. I want to use probability to help me out so that I don't need to check every single file. How would I calculate what sample size I should use to reach a certain confidence level? For example, if I would like to say with confidence that the files are correct, how many of them do I have to check? I found an online calculator , but I'm not entirely sure what I should put for the confidence interval. Say I put 20% and leave the confidence factor at . I get a sample size of 23. Let's say now that I tested 23 random files and all of them were fine. Does that mean that ""I can be confident that 80% to 100% of the files are correct""? Does this mean, then, that for my original question, I would need to use a 99% confidence level with a 4% confidence interval, then I would need to verify that the 291 files (the sample size it gave me) are all correct. And only then I can say with 95% confidence that the files are correct? (99% +- 4% = 95% to 100%) It also mentions something about percentages which I'm not quite clear on... does the fact that most (i.e. 100%) of the files I test are valid (since if I found an invalid one, I would stop the whole process and examine my generation process for errors) mean that I can use a smaller sample to get the same confidence factor? If so, how would I calculate it?",404 95\% 95\% 95\%,"['probability', 'statistics']"
87,"Evaluating $ \lim_{n\to \infty} \frac{1}{n}\int_0^n \max(\{x\},\{\sqrt{2}x\},\{\sqrt{3}x\})dx $, where $\{x\}$ is the fractional part of $x$","Evaluating , where  is the fractional part of"," \lim_{n\to \infty} \frac{1}{n}\int_0^n \max(\{x\},\{\sqrt{2}x\},\{\sqrt{3}x\})dx  \{x\} x","I found an interesting problem on the internet: $\lim_{n\to \infty} \frac{1}{n}\int_0^n \max(\{x\},\{\sqrt{2}x\},\{\sqrt{3}x\})dx$ , where $\{x\}$ is the fractional part of $x$ . I have known that this problem can be regarded as calculating the expectation of the maximum of three independent uniform random variables $X_i \overset{i.i.d}{\sim} \mathrm{Unif}(0,1)$ . However, I do not understand the reasoning behind why this is the case.","I found an interesting problem on the internet: , where is the fractional part of . I have known that this problem can be regarded as calculating the expectation of the maximum of three independent uniform random variables . However, I do not understand the reasoning behind why this is the case.","\lim_{n\to \infty} \frac{1}{n}\int_0^n \max(\{x\},\{\sqrt{2}x\},\{\sqrt{3}x\})dx \{x\} x X_i \overset{i.i.d}{\sim} \mathrm{Unif}(0,1)","['calculus', 'probability', 'limits']"
88,Bounding L1 norm of gaussian convolution,Bounding L1 norm of gaussian convolution,,"Consider this Here I do not agree with the argument. In particular, I  do not see why the second line of the proof, where we seem to be using Cauchy-Swartz, must hold. I know that it is not Cauchy-Swartz as $L^1$ is not an inner product space. Can someone clarify what is going on?","Consider this Here I do not agree with the argument. In particular, I  do not see why the second line of the proof, where we seem to be using Cauchy-Swartz, must hold. I know that it is not Cauchy-Swartz as is not an inner product space. Can someone clarify what is going on?",L^1,"['probability', 'measure-theory']"
89,"Expectation of maximum number of non-overlapping random intervals inside $[0,1]$ out of $n$ intervals",Expectation of maximum number of non-overlapping random intervals inside  out of  intervals,"[0,1] n","Choose two random numbers from $[0,1]$ and let them be the endpoints of a random interval. Repeat this independently for $n$ times to get $n$ random subintervals (denoted as $U_1,\dots,U_n$ ). Let $T_n = \max\{|S|: S\subset\{U_1,\dots,U_n\}, U_i\cap U_j=\emptyset \mbox{ for any }U_i\not =U_j\in S\}$ , where $|S|$ denote the number of intervals in $S$ . I'm wondering what is the expectation of $T_n$ ? Or how fast does the expectation of $T_n$ increase with $n$ ? ( is it $O(n)$ , $O(\sqrt{n})$ or $O(\log n)$ ?)","Choose two random numbers from and let them be the endpoints of a random interval. Repeat this independently for times to get random subintervals (denoted as ). Let , where denote the number of intervals in . I'm wondering what is the expectation of ? Or how fast does the expectation of increase with ? ( is it , or ?)","[0,1] n n U_1,\dots,U_n T_n = \max\{|S|: S\subset\{U_1,\dots,U_n\}, U_i\cap U_j=\emptyset \mbox{ for any }U_i\not =U_j\in S\} |S| S T_n T_n n O(n) O(\sqrt{n}) O(\log n)","['probability', 'statistics']"
90,Did my TA make a mistake regarding probabilities?,Did my TA make a mistake regarding probabilities?,,"So I had an assignment due yesterday, regarding the probability of the attackers second highest dice roll, being strictly bigger than the defenders second highest dice roll, in the game Risk. In the game, the attacker has three dices and the defender has two. The highest dice of the attacker is compared with the highest dice of the defender, and the second-highest dice of the attacker is compared with the second highest dice of the defender. For the attacker to win, their dice must be strictly larger than the defender. The dice of the defender are $C_1$ and $C_2$ , ordered as $C_{(1)} \leq C_{(2)}$ , and the dice of the attacker are $B_1$ , $B_2$ and $B_3$ , ordered as $B_{(1)} \leq B_{(2)} \leq B_{(3)}$ I, with the help of this board wrote my answer as P(A>D) = $B_{(2)}>C_{(1)}$ : $$\sum_{k=2}^{6} \left(\sum_{n=1}^{k-1}\frac{13-2n}{36}\right) \cdot \frac{-6k^2+42k-20}{216} =\frac{1181}{1944} =0.6075 $$ Yet my TA had another answer. We both had the same probability for $B_{(2)}$ , ie. $P(B_{(2)}=k) = \frac{-6^2+42k-20}{216}$ but he used the distribution function for $B_{(2)},  P(B_{(2)}$ ≤k) $ = \frac{9k^2-k^3}{108}$ , instead of the probability function for $C_{(1)}$ which I used. He then multiplied the possibilities and took the sum, and got close to the same answer, but not the exact. $$\sum_{k=1}^{6} \frac{21k-3k^2-10}{108} \cdot \frac{9k^2-k^3}{108} = 0.598 $$ My question is, which of these are the correct way to find the probability of the attackers second dice being strictly larger than the defenders second dice roll?","So I had an assignment due yesterday, regarding the probability of the attackers second highest dice roll, being strictly bigger than the defenders second highest dice roll, in the game Risk. In the game, the attacker has three dices and the defender has two. The highest dice of the attacker is compared with the highest dice of the defender, and the second-highest dice of the attacker is compared with the second highest dice of the defender. For the attacker to win, their dice must be strictly larger than the defender. The dice of the defender are and , ordered as , and the dice of the attacker are , and , ordered as I, with the help of this board wrote my answer as P(A>D) = : Yet my TA had another answer. We both had the same probability for , ie. but he used the distribution function for ≤k) , instead of the probability function for which I used. He then multiplied the possibilities and took the sum, and got close to the same answer, but not the exact. My question is, which of these are the correct way to find the probability of the attackers second dice being strictly larger than the defenders second dice roll?","C_1 C_2 C_{(1)} \leq C_{(2)} B_1 B_2 B_3 B_{(1)} \leq B_{(2)} \leq B_{(3)} B_{(2)}>C_{(1)} \sum_{k=2}^{6} \left(\sum_{n=1}^{k-1}\frac{13-2n}{36}\right) \cdot \frac{-6k^2+42k-20}{216} =\frac{1181}{1944} =0.6075  B_{(2)} P(B_{(2)}=k) = \frac{-6^2+42k-20}{216} B_{(2)},  P(B_{(2)}  = \frac{9k^2-k^3}{108} C_{(1)} \sum_{k=1}^{6} \frac{21k-3k^2-10}{108} \cdot \frac{9k^2-k^3}{108} = 0.598 ",['probability']
91,Finding the expectation of the smallest value when $k$ numbers is taken from $1$ to $n$,Finding the expectation of the smallest value when  numbers is taken from  to,k 1 n,"Let X be the smallest value obtained when k numbers are randomly chosen from the set 1,...,n. Find E[X] by interpreting X as a negative hypergeometric random variable. This is Self Test Exercise 7.7 of Sheldon's A First Course in Probability. The way I approached this is to first consider (for example) P(X = 1). Using the suggestion to take X as a negative hypergeometric random variable, we have $$P(X = 1) = \frac{\binom{1}{1}\binom{n - 1}{k - 1}}{\binom{n}{k}}$$ My idea was that we have one element 1 and the rest $k - 1$ elements from ... the remaining $n - 1$ elements. Similarly, for $P(X = 2)$ , we have one way of getting the minimum element $2$ , and $\binom{n - 2}{k - 1}$ ways of getting the other elements (well, except 1). Similarly, we can deduce that $$P(X = i) = \frac{\binom{n - i}{k - 1}}{\binom{n}{k}}$$ As a result, I got $$E(X) = \sum_{i = 1}^n i \times \frac{\binom{n - i}{k - 1}}{\binom{n}{k}}$$ The answer in the book is $\frac{n + 1}{k + 1}$ , which is just so much more elegant than what I came up with, and I'm not seeing how my answer reduces to theirs. My questions are: Is my approach correct? If not, what mistake(s) did I make in my analysis? If my answer is correct, how do I get to the expected result?","Let X be the smallest value obtained when k numbers are randomly chosen from the set 1,...,n. Find E[X] by interpreting X as a negative hypergeometric random variable. This is Self Test Exercise 7.7 of Sheldon's A First Course in Probability. The way I approached this is to first consider (for example) P(X = 1). Using the suggestion to take X as a negative hypergeometric random variable, we have My idea was that we have one element 1 and the rest elements from ... the remaining elements. Similarly, for , we have one way of getting the minimum element , and ways of getting the other elements (well, except 1). Similarly, we can deduce that As a result, I got The answer in the book is , which is just so much more elegant than what I came up with, and I'm not seeing how my answer reduces to theirs. My questions are: Is my approach correct? If not, what mistake(s) did I make in my analysis? If my answer is correct, how do I get to the expected result?",P(X = 1) = \frac{\binom{1}{1}\binom{n - 1}{k - 1}}{\binom{n}{k}} k - 1 n - 1 P(X = 2) 2 \binom{n - 2}{k - 1} P(X = i) = \frac{\binom{n - i}{k - 1}}{\binom{n}{k}} E(X) = \sum_{i = 1}^n i \times \frac{\binom{n - i}{k - 1}}{\binom{n}{k}} \frac{n + 1}{k + 1},"['probability', 'expected-value']"
92,Show that $\liminf \frac{\vert S_n\vert}{\sqrt{n}} = 0$.,Show that .,\liminf \frac{\vert S_n\vert}{\sqrt{n}} = 0,"Let $X_1, X_2, \dots$ be i.i.d random variables with $\mathbb{E}(X_i) = 0$ and $0 < \operatorname{Var}(X_i) < \infty$ , then by the Central Limit Theorem and Kolmogorov’s 0-1 Law we can conclude that $$\limsup_{n\rightarrow\infty} \frac{S_n}{\sqrt{n}} = \infty, \ a.s.$$ Now my question is that can we establish that $$\liminf_{n\rightarrow\infty} \frac{\vert S_n\vert}{\sqrt{n}} = 0, \ a.s.$$ It seems that the approach to the problem above fails here. I also tried to use the law of iterated logarithm to solve it, but only ended up with failure. Any help will be greatly appreciated.","Let be i.i.d random variables with and , then by the Central Limit Theorem and Kolmogorov’s 0-1 Law we can conclude that Now my question is that can we establish that It seems that the approach to the problem above fails here. I also tried to use the law of iterated logarithm to solve it, but only ended up with failure. Any help will be greatly appreciated.","X_1, X_2, \dots \mathbb{E}(X_i) = 0 0 < \operatorname{Var}(X_i) < \infty \limsup_{n\rightarrow\infty} \frac{S_n}{\sqrt{n}} = \infty, \ a.s. \liminf_{n\rightarrow\infty} \frac{\vert S_n\vert}{\sqrt{n}} = 0, \ a.s.","['probability', 'probability-theory', 'probability-limit-theorems']"
93,Number of Rolls of Die Until Sum Exceeds 6,Number of Rolls of Die Until Sum Exceeds 6,,"What is the expected number of rolls of a 6-sided die until the sum exceeds 6? As the expected value of one roll is 3.5, why is the answer not just $\frac{6}{3.5}$ ?","What is the expected number of rolls of a 6-sided die until the sum exceeds 6? As the expected value of one roll is 3.5, why is the answer not just ?",\frac{6}{3.5},"['probability', 'expected-value', 'dice']"
94,Probability of dart hitting a point given that it hits a point in a finite set of points,Probability of dart hitting a point given that it hits a point in a finite set of points,,"I understand the probability of the dart hitting the center point is 0, and I think this is used as an example of how a probability of 0 doesn't mean something is impossible. Now image we define 3 arbitrary points on the dart board, say, the center point C, and the two points between the center and the top/bottom edges called T and B respectively. Also let's suppose the player throws the dart in such a way that it's equally likely to hit any point on the board. What's the probability of the dart having landed on C given that we know it already landed on one of the 3 points? Intuitively the answer seems to be 1/3. But working out the math would give an undefined result if I attempt to solve it like P(C|T∪C∪B) = P(C)/P(T∪C∪B) = 0/0. Is there a way to properly solve this? Or is the only way to just assign equal probabilities to all points and ignore the fact that the probability of hitting any one point is zero? EDIT: I think I made some progress thanks to your comments, but I hope someone smarter than myself can comment on my attempted solution. I think the zero probability comes from dividing 1/∞, which afaik is by itself not well defined. The full rigorous expression would be $\lim_{x \to \infty} \frac{1}{x}$ Intuitively $x$ is the number of points in the board, so the probabilities of the dart landing on each point is $1/x$ and the probability of landing on any of the 3 points is $3/$ x, so the full probability now becomes: $\lim_{x \to \infty} \frac{1/x}{3/x}$ Which if I'm not mistaken is just 1/3. EDIT 2: I get the impression that most comments and answers here suggest that it's impossible to calculate these probabilities unless we come up with some ad hoc definitions. I just want to clarify that the dart board is a metaphor for a random point in a circle which, in my above example, has a uniform distribution. Since the example is so trivial it provides little motivation to actually solve it, so here is another example that is a little less trivial based on @Vincent's comment. Imagine a random real generator R that generates a real number from -1 to +1 that has a probability density function D. Also, imagine that I wrap R into another function F that returns the absolute value of the number produced by R like F = ABS(R()) . So, let's say we run F and it outputs $n$ . What's the probability that the number generated by R was actually $n$ (as opposed to $-n$ ), given that we know the density function D? If I'm not mistaken, the probability is just $\frac{D(n)}{D(-n)+D(n)}$ , which I can't prove but intuitively seems right. Applying the same logic to the original dart problem would again give 1/3 without having to deal with divisions by zero (at least not explicitly) and without the need for any ad hoc definition.","I understand the probability of the dart hitting the center point is 0, and I think this is used as an example of how a probability of 0 doesn't mean something is impossible. Now image we define 3 arbitrary points on the dart board, say, the center point C, and the two points between the center and the top/bottom edges called T and B respectively. Also let's suppose the player throws the dart in such a way that it's equally likely to hit any point on the board. What's the probability of the dart having landed on C given that we know it already landed on one of the 3 points? Intuitively the answer seems to be 1/3. But working out the math would give an undefined result if I attempt to solve it like P(C|T∪C∪B) = P(C)/P(T∪C∪B) = 0/0. Is there a way to properly solve this? Or is the only way to just assign equal probabilities to all points and ignore the fact that the probability of hitting any one point is zero? EDIT: I think I made some progress thanks to your comments, but I hope someone smarter than myself can comment on my attempted solution. I think the zero probability comes from dividing 1/∞, which afaik is by itself not well defined. The full rigorous expression would be Intuitively is the number of points in the board, so the probabilities of the dart landing on each point is and the probability of landing on any of the 3 points is x, so the full probability now becomes: Which if I'm not mistaken is just 1/3. EDIT 2: I get the impression that most comments and answers here suggest that it's impossible to calculate these probabilities unless we come up with some ad hoc definitions. I just want to clarify that the dart board is a metaphor for a random point in a circle which, in my above example, has a uniform distribution. Since the example is so trivial it provides little motivation to actually solve it, so here is another example that is a little less trivial based on @Vincent's comment. Imagine a random real generator R that generates a real number from -1 to +1 that has a probability density function D. Also, imagine that I wrap R into another function F that returns the absolute value of the number produced by R like F = ABS(R()) . So, let's say we run F and it outputs . What's the probability that the number generated by R was actually (as opposed to ), given that we know the density function D? If I'm not mistaken, the probability is just , which I can't prove but intuitively seems right. Applying the same logic to the original dart problem would again give 1/3 without having to deal with divisions by zero (at least not explicitly) and without the need for any ad hoc definition.",\lim_{x \to \infty} \frac{1}{x} x 1/x 3/ \lim_{x \to \infty} \frac{1/x}{3/x} n n -n \frac{D(n)}{D(-n)+D(n)},"['probability', 'conditional-probability', 'infinitesimals']"
95,Vanquishing a dragon using one dimensional random walk with variable path lengths,Vanquishing a dragon using one dimensional random walk with variable path lengths,,"My friend posed a question a couple of days back which states the following. There is a dragon which starts with 3 heads, and we can cut one head at a time. Everytime we cut one head, either nothing happens, two heads grow back or three heads grow back. We are asked to find the probability of cutting off all heads. So I modelled this as a random walk on $\mathbb Z$ with an absorbing barrier at $x=0$ . We either go back one step, go forward one step or go forwards two steps, each with equal probability. Let us take $P_k$ to be the probability of starting at $x=k$ and hitting $x=0$ eventually. We then need to find $P_3$ . The recursion I am looking at is $$3P_k=P_{k-2}+P_{k-1}+P_{k+1}$$ with the obvious boundary condition $P_0=1$ . The solution to this recurrence is $$P_k=A+B(1-\sqrt2)^k+C(1+\sqrt2)^k$$ with $A+B+C=1$ . I want my probabilities to be bounded, so $C$ must be $0$ . But here I am stuck. I would need one more boundary condition to proceed, which I am not sure what it might be. I am trying to look at the fact that the mean motion is $2/3$ steps to the right and hence the probability of eventually getting absorbed must decrease (and hence $A=0$ ? But then the probabilites are negative at odd values of $k$ ). I am at a loss how to proceed, or maybe I have done something wrong. Any help is appreciated.","My friend posed a question a couple of days back which states the following. There is a dragon which starts with 3 heads, and we can cut one head at a time. Everytime we cut one head, either nothing happens, two heads grow back or three heads grow back. We are asked to find the probability of cutting off all heads. So I modelled this as a random walk on with an absorbing barrier at . We either go back one step, go forward one step or go forwards two steps, each with equal probability. Let us take to be the probability of starting at and hitting eventually. We then need to find . The recursion I am looking at is with the obvious boundary condition . The solution to this recurrence is with . I want my probabilities to be bounded, so must be . But here I am stuck. I would need one more boundary condition to proceed, which I am not sure what it might be. I am trying to look at the fact that the mean motion is steps to the right and hence the probability of eventually getting absorbed must decrease (and hence ? But then the probabilites are negative at odd values of ). I am at a loss how to proceed, or maybe I have done something wrong. Any help is appreciated.",\mathbb Z x=0 P_k x=k x=0 P_3 3P_k=P_{k-2}+P_{k-1}+P_{k+1} P_0=1 P_k=A+B(1-\sqrt2)^k+C(1+\sqrt2)^k A+B+C=1 C 0 2/3 A=0 k,"['probability', 'recurrence-relations', 'markov-chains', 'random-walk']"
96,Does weak convergence to a continuous distribution imply strong convergence of measures?,Does weak convergence to a continuous distribution imply strong convergence of measures?,,"Let $X_n$ be a sequence of real-valued random variables with cumulative distribution function $F_n$ . Let $X$ be another real-valued random variable with CDF $F$ . Here it is stated that $F_n$ converges strongly to $F$ if $F_n(x) \to F(x)$ for every $x\in\mathbb{R}$ . The book cites this paper as a reference. However, the paper defines strong convergence of measures (say $\mu_n$ converges strongly to $\mu$ ) if $\mu_n(A) \to \mu(A)$ for every set $A$ in the sigma field on which measures are defined. Are these two equivalent i.e. strong convergence of cdfs implies strong convergence of measures defined by the cdfs ?","Let be a sequence of real-valued random variables with cumulative distribution function . Let be another real-valued random variable with CDF . Here it is stated that converges strongly to if for every . The book cites this paper as a reference. However, the paper defines strong convergence of measures (say converges strongly to ) if for every set in the sigma field on which measures are defined. Are these two equivalent i.e. strong convergence of cdfs implies strong convergence of measures defined by the cdfs ?",X_n F_n X F F_n F F_n(x) \to F(x) x\in\mathbb{R} \mu_n \mu \mu_n(A) \to \mu(A) A,"['probability', 'probability-theory', 'measure-theory', 'probability-distributions', 'weak-convergence']"
97,Maximising the expected sum of random variables below a given threshold,Maximising the expected sum of random variables below a given threshold,,"I'm trying to understand the solution to Jane Street's Robot Long Jump puzzle. The optimal strategy ""waiting until a robot’s position was at least some threshold $x$ and then jumping"" makes sense to me, however, I'm not sure what's behind $(x^3 - 3x + 2)e^x = 3x$ equation for the threshold value. First of all, the solution of this equation $\sim0.416195355$ is not in vicinity of what my numerical simulation produces ( $\sim0.302$ ; the result fluctuates a bit from run to run). Secondly, I fail to come up with the analytical solution that agrees with either Jane Street's equation or simulation. Here is my attempt: Expected value of the jump after a single wait is $\int_x^{1}t\,dt=\frac{1-x^2}{2}$ as PDF for uniform distribution is $1$ . Expected value of the waiting further is harder to calculate as it gets recursive. I tried using Irwin-Hall PDF with increasing number of steps but I reckon this is wrong: $$\sum_{n=2}^{\infty}\int_x^1\frac{x^{n-1}}{(n-1)!}\, tdt=\sum_{n=2}^{\infty}\frac{x^{n-1}(1-x^2)}{2(n-1)!}=\frac{1}{2}(e^x-1)(1-x^2)$$ which then leads to the equation $\frac{1-x^2}{2}=(e^x-1)\frac{1-x^2}{2}$ or $x = \ln(2) \approx 0.69315$ . What's the correct approach to this problem?","I'm trying to understand the solution to Jane Street's Robot Long Jump puzzle. The optimal strategy ""waiting until a robot’s position was at least some threshold and then jumping"" makes sense to me, however, I'm not sure what's behind equation for the threshold value. First of all, the solution of this equation is not in vicinity of what my numerical simulation produces ( ; the result fluctuates a bit from run to run). Secondly, I fail to come up with the analytical solution that agrees with either Jane Street's equation or simulation. Here is my attempt: Expected value of the jump after a single wait is as PDF for uniform distribution is . Expected value of the waiting further is harder to calculate as it gets recursive. I tried using Irwin-Hall PDF with increasing number of steps but I reckon this is wrong: which then leads to the equation or . What's the correct approach to this problem?","x (x^3 - 3x + 2)e^x = 3x \sim0.416195355 \sim0.302 \int_x^{1}t\,dt=\frac{1-x^2}{2} 1 \sum_{n=2}^{\infty}\int_x^1\frac{x^{n-1}}{(n-1)!}\, tdt=\sum_{n=2}^{\infty}\frac{x^{n-1}(1-x^2)}{2(n-1)!}=\frac{1}{2}(e^x-1)(1-x^2) \frac{1-x^2}{2}=(e^x-1)\frac{1-x^2}{2} x = \ln(2) \approx 0.69315","['probability', 'probability-distributions']"
98,"If $X$ and $Y$ have the same distribution and $E[Y|X]=X$ almost surely, does that mean $X=Y$ almost surely?","If  and  have the same distribution and  almost surely, does that mean  almost surely?",X Y E[Y|X]=X X=Y,"Let $X$ and $Y$ be 2 random variables such that $X\sim Y$ and $E[Y|X]=X$ almost surely. Is it true that $X=Y$ almost surely? This is true in the Gaussian case and I was wondering if it was true in general. EDIT: I think I got it if $X$ and $Y$ are $L^2$ , can someone confirm? \begin{align*} E[(Y-X)^2] &= E[Y^2]-2E[YX]+E[X^2]\\ &= E[Y^2]-2E[E[YX|X]]+E[X^2]\\ &=E[Y^2]-E[X^2]\\ &=0 \end{align*} Hence $X=Y$ a.s. What about $L^1$ ?","Let and be 2 random variables such that and almost surely. Is it true that almost surely? This is true in the Gaussian case and I was wondering if it was true in general. EDIT: I think I got it if and are , can someone confirm? Hence a.s. What about ?","X Y X\sim Y E[Y|X]=X X=Y X Y L^2 \begin{align*}
E[(Y-X)^2]
&= E[Y^2]-2E[YX]+E[X^2]\\
&= E[Y^2]-2E[E[YX|X]]+E[X^2]\\
&=E[Y^2]-E[X^2]\\
&=0
\end{align*} X=Y L^1","['probability', 'probability-theory', 'probability-distributions', 'conditional-expectation']"
99,Ball color expected value,Ball color expected value,,"We have a box containing b black balls and r red balls which we will take out one at a time by placing them on the table in front of us. Before each extraction we write the color of the majority of the balls not yet extracted on a sheet of paper and only in the event of a tie between black and red can we write a random color (black or red). So, once the ball has been extracted, we can establish whether or not its color corresponds to the one written on the sheet. On average, how many times does the color written on the piece of paper coincide with the color of the ball drawn? Driven by curiosity, I simulated this game 1000 times considering a box containing b=26 black balls and r=26 red balls, obtaining an expected value approximately equal to 30 . I was wondering if a closed formula could be written. Thank you! Thanks to Parcly Taxel 's answer I was able to go back to the original problem whose solution is by John Henry Steelman , Indiana University of Pennsylvania, Indiana, PA (valid for $b \ge r$ ): $$ \mathbb{E}(b,r) = b + \sum_{k=0}^{r-1}\binom{b+r}{k}/\binom{b+r}{r} $$ from which: $$ \mathbb{E}(r,r) = r - \frac{1}{2} + \frac{2^{2r-1}}{\binom{2r}{r}}; \quad \mathbb{E}(26,26) = \frac{3724430600965475}{123979633237026} \approx 30.040664774713895\,. $$","We have a box containing b black balls and r red balls which we will take out one at a time by placing them on the table in front of us. Before each extraction we write the color of the majority of the balls not yet extracted on a sheet of paper and only in the event of a tie between black and red can we write a random color (black or red). So, once the ball has been extracted, we can establish whether or not its color corresponds to the one written on the sheet. On average, how many times does the color written on the piece of paper coincide with the color of the ball drawn? Driven by curiosity, I simulated this game 1000 times considering a box containing b=26 black balls and r=26 red balls, obtaining an expected value approximately equal to 30 . I was wondering if a closed formula could be written. Thank you! Thanks to Parcly Taxel 's answer I was able to go back to the original problem whose solution is by John Henry Steelman , Indiana University of Pennsylvania, Indiana, PA (valid for ): from which:","b \ge r 
\mathbb{E}(b,r) = b + \sum_{k=0}^{r-1}\binom{b+r}{k}/\binom{b+r}{r}
 
\mathbb{E}(r,r) = r - \frac{1}{2} + \frac{2^{2r-1}}{\binom{2r}{r}};
\quad
\mathbb{E}(26,26) = \frac{3724430600965475}{123979633237026} \approx 30.040664774713895\,.
",['probability']
