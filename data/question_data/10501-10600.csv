,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Need help with $\int_0^\infty e^{-x}\ln\ln\left(e^x+\sqrt{e^{2x}-1}\right)\,dx$",Need help with,"\int_0^\infty e^{-x}\ln\ln\left(e^x+\sqrt{e^{2x}-1}\right)\,dx","I need help with this integral: $$\int_0^\infty e^{-x}\ln\ln\left(e^x+\sqrt{e^{2x}-1}\right)\,dx\approx0.20597312051214...$$ Is it possible to evaluated it in a closed form?","I need help with this integral: $$\int_0^\infty e^{-x}\ln\ln\left(e^x+\sqrt{e^{2x}-1}\right)\,dx\approx0.20597312051214...$$ Is it possible to evaluated it in a closed form?",,"['calculus', 'integration', 'logarithms', 'improper-integrals', 'closed-form']"
1,"Integral $\int_0^1\frac{\ln x}{x^2+1}\cdot\ln\left(\frac{3\,x^2+1}{x^2+3}\right)dx$",Integral,"\int_0^1\frac{\ln x}{x^2+1}\cdot\ln\left(\frac{3\,x^2+1}{x^2+3}\right)dx","I need to evaluate the following integral: $$\int_0^1\frac{\ln x}{x^2+1}\cdot\ln\left(\frac{3\,x^2+1}{x^2+3}\right)dx.$$ Could you suggest how to find a closed form for it? I am not sure if there is one, but the integrand seems simple enough, so I hope it might exist.","I need to evaluate the following integral: $$\int_0^1\frac{\ln x}{x^2+1}\cdot\ln\left(\frac{3\,x^2+1}{x^2+3}\right)dx.$$ Could you suggest how to find a closed form for it? I am not sure if there is one, but the integrand seems simple enough, so I hope it might exist.",,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'closed-form']"
2,"Proving a sequence involved in Apéry's proof of the irrationality of $\zeta(3)$, converges","Proving a sequence involved in Apéry's proof of the irrationality of , converges",\zeta(3),"I am trying to understand Apery's 1978 proof that $\zeta(3) = \displaystyle \sum_{n=1}^\infty \frac{1}{n^3}$ is irrational. The idea behind the proof is to find an 'accelerated' series for $\zeta(3)$ which converges too fast to $\zeta(3)$, thus proving that $\zeta(3)$ cannot be rational. In particular, a particular quantity is defined: $$e_{n,k} = \displaystyle \sum_{m=1}^k \frac{(-1)^{m-1} (m!)^2 (n-m)!}{2m^3 (n+m)!},\quad k \leq n.$$ The key is to show that $\displaystyle \lim_{n \rightarrow \infty} e_{n,k} = 0$ uniformly in $k$, and I have no idea why this sum converges to 0. Any ideas?","I am trying to understand Apery's 1978 proof that $\zeta(3) = \displaystyle \sum_{n=1}^\infty \frac{1}{n^3}$ is irrational. The idea behind the proof is to find an 'accelerated' series for $\zeta(3)$ which converges too fast to $\zeta(3)$, thus proving that $\zeta(3)$ cannot be rational. In particular, a particular quantity is defined: $$e_{n,k} = \displaystyle \sum_{m=1}^k \frac{(-1)^{m-1} (m!)^2 (n-m)!}{2m^3 (n+m)!},\quad k \leq n.$$ The key is to show that $\displaystyle \lim_{n \rightarrow \infty} e_{n,k} = 0$ uniformly in $k$, and I have no idea why this sum converges to 0. Any ideas?",,"['calculus', 'sequences-and-series']"
3,"A function with a non-zero derivative, with an inverse function that has no derivative.","A function with a non-zero derivative, with an inverse function that has no derivative.",,"While studying calculus, I encountered the following statement: ""Given a function $f(x)$ with $f'(x_0)\neq 0$ , such that $f$ has an inverse in some neighborhood of $x_0$ , and such that $f$ is continuous on said neighborhood, then $f^{-1}$ has a derivative at $f(x_0)$ given by: $${f^{-1}}'(x_0)=\frac{1}{f'(x_0)}$$ My questions is - why does $f$ have to be continuous on a whole neighborhood of $x_0$ and not just at $x_0$ ? Is there some known counter-example for that?","While studying calculus, I encountered the following statement: ""Given a function with , such that has an inverse in some neighborhood of , and such that is continuous on said neighborhood, then has a derivative at given by: My questions is - why does have to be continuous on a whole neighborhood of and not just at ? Is there some known counter-example for that?",f(x) f'(x_0)\neq 0 f x_0 f f^{-1} f(x_0) {f^{-1}}'(x_0)=\frac{1}{f'(x_0)} f x_0 x_0,"['calculus', 'derivatives', 'proof-explanation', 'inverse-function', 'inverse-function-theorem']"
4,A closed form of $\sum_{n=1}^{\infty}(-1)^{n}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)$?,A closed form of ?,\sum_{n=1}^{\infty}(-1)^{n}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right),I'm curious about a possible closed form of the following series. $$ \sum_{n=1}^{\infty}(-1)^{n}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right) \tag1 $$ One may observe that $(1)$ is absolutely convergent. One may notice that apparently one can't apply the same route that proved $$ \sum_{n=1}^{\infty}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)=\frac12\ln^2 2. \tag2 $$,I'm curious about a possible closed form of the following series. $$ \sum_{n=1}^{\infty}(-1)^{n}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right) \tag1 $$ One may observe that $(1)$ is absolutely convergent. One may notice that apparently one can't apply the same route that proved $$ \sum_{n=1}^{\infty}\ln \!\left(1+\frac1{2n}\right) \!\ln\!\left(1+\frac1{2n+1}\right)=\frac12\ln^2 2. \tag2 $$,,"['calculus', 'integration', 'sequences-and-series', 'closed-form']"
5,A closed form for $\int_0^\infty\ln x\cdot\ln\left(1+\frac1{2\cosh x}\right)dx$,A closed form for,\int_0^\infty\ln x\cdot\ln\left(1+\frac1{2\cosh x}\right)dx,"Is it possible to evaluate this integral in a closed form? $$\int_0^\infty\ln x\cdot\ln\left(1+\frac1{2\cosh x}\right)dx=\int_0^\infty\ln x\cdot\ln\left(1+\frac1{e^{-x}+e^x}\right)dx$$ I tried to evaluate it with a CAS, and looked up in integral tables, but was not successful.","Is it possible to evaluate this integral in a closed form? $$\int_0^\infty\ln x\cdot\ln\left(1+\frac1{2\cosh x}\right)dx=\int_0^\infty\ln x\cdot\ln\left(1+\frac1{e^{-x}+e^x}\right)dx$$ I tried to evaluate it with a CAS, and looked up in integral tables, but was not successful.",,"['calculus', 'integration', 'logarithms', 'improper-integrals', 'closed-form']"
6,Integral $\int_0^{\pi/2}\frac{x}{\sin x}\log^2\left(\frac{1+\cos x-\sin x}{1+\cos x+\sin x}\right)dx$,Integral,\int_0^{\pi/2}\frac{x}{\sin x}\log^2\left(\frac{1+\cos x-\sin x}{1+\cos x+\sin x}\right)dx,Please help me to evaluate this integral: $$\large\int_0^{\pi/2}\frac{x}{\sin x}\log^2\left(\frac{1+\cos x-\sin x}{1+\cos x+\sin x}\right)dx$$,Please help me to evaluate this integral: $$\large\int_0^{\pi/2}\frac{x}{\sin x}\log^2\left(\frac{1+\cos x-\sin x}{1+\cos x+\sin x}\right)dx$$,,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'logarithms']"
7,Interesting closed form for $\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta$,Interesting closed form for,\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta,"Some time ago I used a formal approach to derive the following identity: $$\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta=\frac{3^{\frac{1}{12}}\pi\sqrt{2}}{AGM(1+\sqrt{3},\sqrt{8})}\tag{1}$$ where $AGM$ is the arithmetic-geometric mean . Wolfram Alpha does not tell me whether this is correct, but it does appear to be accurate to many decimal places. I have three questions: Can anyone verify whether $(1)$ is in fact correct? Is there a way of generalizing $(1)$ to integrals of the form $\int_0^{\frac{\pi}{2}}\left(a+\sin^2{\theta}\right)^{-\frac{1}{3}}\;d\theta$ or is this integral more special? My derivation (see below) appears to only work for $a=\frac{1}{3}$. There is a superficial similarity between $(1)$ and elliptic integrals (e.g. the $AGM$ evaluation ); is there a way to transform this integral into an elliptic integral that I have missed, or is it merely a coincidence that an integral of this form is the reciprocal of an $AGM$? Derivation : I have put this here in case it helps to see where I am coming from; I apologize for its length. I began by using a multiple integration trick of squaring the integral and converting to polar coordinates to evaluate $\int_0^\infty e^{-x^6}dx=\frac{1}{6}\Gamma(\frac{1}{6})$ as follows: $$\left[\int_0^\infty e^{-x^6}\;dx\right]^2=\int_0^\infty\int_0^{\frac{\pi}{2}}re^{-r^6(\cos^6\theta\;+\;\sin^6\theta)}\;d\theta\;dx={\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{3r^6\cos^2\theta\sin^2\theta}\;d\theta\;dx}$$ $$=\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{\frac{3r^6}{4}\sin^22\theta}\;d\theta\;dx={\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{\frac{3r^6}{4}\cos^2\theta}\;d\theta\;dx}$$ I then made use of the following formula (see here ): $$\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}x^n=\frac{2}{\pi}\int_0^{\frac{\pi}{2}}e^{4x\cos^2\theta}\;d\theta\tag{2}$$ Using $(2)$ and formally interchanging integration and summation we get: $$\frac{\Gamma(\frac{1}{6})^2}{36}=\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{4\left(\frac{3r^6}{16}\right)\cos^2\theta}\;d\theta\;dx=\frac{\pi}{2}\int_0^\infty re^{-r^6}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3r^6}{16}\right)^n\;dx$$ $$=\frac{\pi}{2}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3}{16}\right)^n \int_0^\infty r^{6n+1}e^{-r^6}\;dx=\frac{\pi}{12}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3}{16}\right)^n \Gamma\left(n+\frac{1}{3}\right)$$ I then used Laplace transform identities and $(2)$, freely interchanging integrals and sums, to write: $$\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\frac{\Gamma\left(n+\frac{1}{3}\right)}{s^{n+\frac{1}{3}}}=L\left[\sum_{n=0}^\infty \frac{(2n)!}{(n!)^3}t^{n-\frac{2}{3}}\right](s)={\frac{2}{\pi}L\left[t^{-\frac{2}{3}}\int_0^\frac{\pi}{2}e^{4t\cos^2\theta}\;d\theta\right](s)}={\frac{2}{\pi}\int_0^\frac{\pi}{2}L\left[t^{-\frac{2}{3}}e^{4t\cos^2\theta}\right](s)\;d\theta}={\frac{2}{\pi}\int_0^\frac{\pi}{2}\frac{\Gamma(\frac{1}{3})}{(s-4\cos^2\theta)^{\frac{1}{3}}}\;d\theta}$$ Accordingly, since $\frac{4}{3}-\cos^2\theta=\frac{1}{3}+\sin^2{\theta}$ we can deduce that: $$\frac{\Gamma(\frac{1}{6})^2}{36}=\frac{\Gamma(\frac{1}{3})}{6}\left(\frac{4}{3}\right)^\frac{1}{3}\int_0^\frac{\pi}{2}\frac{1}{(\frac{1}{3}+\sin^2\theta)^{\frac{1}{3}}}\;d\theta$$ Reflection and duplication give $\Gamma(\frac{1}{6})=2^{-\frac{1}{3}}\sqrt{\frac{3}{\pi}}\Gamma(\frac{1}{3})^2$ and hence we have the following identity: $$\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta=\frac{3^\frac{1}{3}\Gamma(\frac{1}{3})^3}{2^\frac{7}{3}\pi}\tag{3}$$ while $(1)$ may be obtained by using the following identity (see here ): $$\Gamma\left(\frac{1}{6}\right)=\frac{2^\frac{14}{9}3^\frac{1}{3}\pi^\frac{5}{6}}{AGM(1+\sqrt{3},\sqrt{8})^\frac{2}{3}}$$ This completes the derivation; I cannot see how a method like this (especially with the conversion to polar coordinates) could be used to give results more general than $(1)$ and $(3)$.","Some time ago I used a formal approach to derive the following identity: $$\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta=\frac{3^{\frac{1}{12}}\pi\sqrt{2}}{AGM(1+\sqrt{3},\sqrt{8})}\tag{1}$$ where $AGM$ is the arithmetic-geometric mean . Wolfram Alpha does not tell me whether this is correct, but it does appear to be accurate to many decimal places. I have three questions: Can anyone verify whether $(1)$ is in fact correct? Is there a way of generalizing $(1)$ to integrals of the form $\int_0^{\frac{\pi}{2}}\left(a+\sin^2{\theta}\right)^{-\frac{1}{3}}\;d\theta$ or is this integral more special? My derivation (see below) appears to only work for $a=\frac{1}{3}$. There is a superficial similarity between $(1)$ and elliptic integrals (e.g. the $AGM$ evaluation ); is there a way to transform this integral into an elliptic integral that I have missed, or is it merely a coincidence that an integral of this form is the reciprocal of an $AGM$? Derivation : I have put this here in case it helps to see where I am coming from; I apologize for its length. I began by using a multiple integration trick of squaring the integral and converting to polar coordinates to evaluate $\int_0^\infty e^{-x^6}dx=\frac{1}{6}\Gamma(\frac{1}{6})$ as follows: $$\left[\int_0^\infty e^{-x^6}\;dx\right]^2=\int_0^\infty\int_0^{\frac{\pi}{2}}re^{-r^6(\cos^6\theta\;+\;\sin^6\theta)}\;d\theta\;dx={\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{3r^6\cos^2\theta\sin^2\theta}\;d\theta\;dx}$$ $$=\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{\frac{3r^6}{4}\sin^22\theta}\;d\theta\;dx={\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{\frac{3r^6}{4}\cos^2\theta}\;d\theta\;dx}$$ I then made use of the following formula (see here ): $$\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}x^n=\frac{2}{\pi}\int_0^{\frac{\pi}{2}}e^{4x\cos^2\theta}\;d\theta\tag{2}$$ Using $(2)$ and formally interchanging integration and summation we get: $$\frac{\Gamma(\frac{1}{6})^2}{36}=\int_0^\infty re^{-r^6}\int_0^{\frac{\pi}{2}}e^{4\left(\frac{3r^6}{16}\right)\cos^2\theta}\;d\theta\;dx=\frac{\pi}{2}\int_0^\infty re^{-r^6}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3r^6}{16}\right)^n\;dx$$ $$=\frac{\pi}{2}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3}{16}\right)^n \int_0^\infty r^{6n+1}e^{-r^6}\;dx=\frac{\pi}{12}\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\left(\frac{3}{16}\right)^n \Gamma\left(n+\frac{1}{3}\right)$$ I then used Laplace transform identities and $(2)$, freely interchanging integrals and sums, to write: $$\sum_{n=0}^{\infty}\frac{(2n)!}{(n!)^3}\frac{\Gamma\left(n+\frac{1}{3}\right)}{s^{n+\frac{1}{3}}}=L\left[\sum_{n=0}^\infty \frac{(2n)!}{(n!)^3}t^{n-\frac{2}{3}}\right](s)={\frac{2}{\pi}L\left[t^{-\frac{2}{3}}\int_0^\frac{\pi}{2}e^{4t\cos^2\theta}\;d\theta\right](s)}={\frac{2}{\pi}\int_0^\frac{\pi}{2}L\left[t^{-\frac{2}{3}}e^{4t\cos^2\theta}\right](s)\;d\theta}={\frac{2}{\pi}\int_0^\frac{\pi}{2}\frac{\Gamma(\frac{1}{3})}{(s-4\cos^2\theta)^{\frac{1}{3}}}\;d\theta}$$ Accordingly, since $\frac{4}{3}-\cos^2\theta=\frac{1}{3}+\sin^2{\theta}$ we can deduce that: $$\frac{\Gamma(\frac{1}{6})^2}{36}=\frac{\Gamma(\frac{1}{3})}{6}\left(\frac{4}{3}\right)^\frac{1}{3}\int_0^\frac{\pi}{2}\frac{1}{(\frac{1}{3}+\sin^2\theta)^{\frac{1}{3}}}\;d\theta$$ Reflection and duplication give $\Gamma(\frac{1}{6})=2^{-\frac{1}{3}}\sqrt{\frac{3}{\pi}}\Gamma(\frac{1}{3})^2$ and hence we have the following identity: $$\int_0^{\frac{\pi}{2}}\frac{1}{\left(\frac{1}{3}+\sin^2{\theta}\right)^{\frac{1}{3}}}\;d\theta=\frac{3^\frac{1}{3}\Gamma(\frac{1}{3})^3}{2^\frac{7}{3}\pi}\tag{3}$$ while $(1)$ may be obtained by using the following identity (see here ): $$\Gamma\left(\frac{1}{6}\right)=\frac{2^\frac{14}{9}3^\frac{1}{3}\pi^\frac{5}{6}}{AGM(1+\sqrt{3},\sqrt{8})^\frac{2}{3}}$$ This completes the derivation; I cannot see how a method like this (especially with the conversion to polar coordinates) could be used to give results more general than $(1)$ and $(3)$.",,"['calculus', 'definite-integrals', 'closed-form', 'gamma-function', 'elliptic-integrals']"
8,Prove $|P(0)|\leq 2n+1$,Prove,|P(0)|\leq 2n+1,"Let $P(x)$ be a polynomial with degree $\leq n$ and $|P(x)|\leq\frac{1}{\sqrt{x}}$ for $x\in(0,1]$. Prove that $|P(0)|\leq 2n+1$. The idea should be that if $|P(0)|$ is too large, then the polynomial cannot change values fast enough to avoid intersecting the curve $ \pm 1/\sqrt{x}$, but I don't see how to formalize this.","Let $P(x)$ be a polynomial with degree $\leq n$ and $|P(x)|\leq\frac{1}{\sqrt{x}}$ for $x\in(0,1]$. Prove that $|P(0)|\leq 2n+1$. The idea should be that if $|P(0)|$ is too large, then the polynomial cannot change values fast enough to avoid intersecting the curve $ \pm 1/\sqrt{x}$, but I don't see how to formalize this.",,"['calculus', 'algebra-precalculus', 'polynomials', 'approximation-theory']"
9,Determine $x$ such that $\lim\limits_{n\to\infty} \sqrt{1+\sqrt{x+\sqrt{x^2…+\sqrt{x^n}}}} = 2$,Determine  such that,x \lim\limits_{n\to\infty} \sqrt{1+\sqrt{x+\sqrt{x^2…+\sqrt{x^n}}}} = 2,Find the value of $x$ such that $\lim\limits_{n\to\infty} \sqrt{1+\sqrt{x+\sqrt{x^2…+\sqrt{x^n}}}} = 2$ I tried getting rid of square roots and got $(...((9-x)^2-x^2)^2-...)^2-x^n = 0$ which I don't think helped. Please point me in the right direction.,Find the value of $x$ such that $\lim\limits_{n\to\infty} \sqrt{1+\sqrt{x+\sqrt{x^2…+\sqrt{x^n}}}} = 2$ I tried getting rid of square roots and got $(...((9-x)^2-x^2)^2-...)^2-x^n = 0$ which I don't think helped. Please point me in the right direction.,,"['calculus', 'sequences-and-series', 'limits', 'convergence-divergence', 'nested-radicals']"
10,Is there a closed form for $\int_0^{\pi/2} \frac{e^{-x}\sqrt{\cos x}}{\sqrt{\cos x}+\sqrt{\sin x}}dx $?,Is there a closed form for ?,\int_0^{\pi/2} \frac{e^{-x}\sqrt{\cos x}}{\sqrt{\cos x}+\sqrt{\sin x}}dx ,"Is there any closed formula for $\int_{0}^{\pi/2} \dfrac{e^{-x}\sqrt{\cos x}\ dx}{\sqrt{\cos x} + \sqrt{\sin x}}?$ I know $\int_{0}^{\pi/2} \dfrac{\sqrt{\cos x}\ dx}{\sqrt{\cos x} + \sqrt{\sin x}} = \dfrac{\pi}{4},$ replacing $x$ by $\frac{\pi}{2} - y$ .",Is there any closed formula for I know replacing by .,"\int_{0}^{\pi/2} \dfrac{e^{-x}\sqrt{\cos x}\ dx}{\sqrt{\cos x} + \sqrt{\sin x}}? \int_{0}^{\pi/2} \dfrac{\sqrt{\cos x}\ dx}{\sqrt{\cos x} + \sqrt{\sin x}} = \dfrac{\pi}{4}, x \frac{\pi}{2} - y","['calculus', 'integration', 'definite-integrals']"
11,Integral ${\large\int}_0^{\pi/2}\arctan^2\!\left(\frac{\sin x}{\sqrt3+\cos x}\right)dx$,Integral,{\large\int}_0^{\pi/2}\arctan^2\!\left(\frac{\sin x}{\sqrt3+\cos x}\right)dx,"I need to evaluate this integral: $$I=\int_0^{\pi/2}\arctan^2\!\left(\frac{\sin x}{\sqrt3+\cos x}\right)dx$$ Maple and Mathematica cannot evaluate it in this form. Its numeric value is $$I\approx0.156371391375711701230837603266631522020409597791339398428...$$ that is not recognized by WolframAlpha and Inverse Symbolic Calculator+ . Is it possible to evaluate this integral in a closed form? I found similar questions here , here and here , but approaches shown in the answers do not seem to be directly applicable here.","I need to evaluate this integral: $$I=\int_0^{\pi/2}\arctan^2\!\left(\frac{\sin x}{\sqrt3+\cos x}\right)dx$$ Maple and Mathematica cannot evaluate it in this form. Its numeric value is $$I\approx0.156371391375711701230837603266631522020409597791339398428...$$ that is not recognized by WolframAlpha and Inverse Symbolic Calculator+ . Is it possible to evaluate this integral in a closed form? I found similar questions here , here and here , but approaches shown in the answers do not seem to be directly applicable here.",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'closed-form']"
12,Recovering a quadratic polynomial from three values using calculus,Recovering a quadratic polynomial from three values using calculus,,"I'm asked to solve this using calculus: Let $$ f(x) = ax^2 + bx +c .$$ If $ f(1) = 3 $,  $f(2) = 7$, $f(3) = 13$, then find $a$, $b$, and $f(0)$. I know I can solve this using solving three equations simultaneously. And I can also solve this using Gauss Jordan or Gaussian elimination method by writing the augmented matrix.  But I'm wondering is there any other method to solve this. Solving by any method it turns out that $a = b = c = 1$.","I'm asked to solve this using calculus: Let $$ f(x) = ax^2 + bx +c .$$ If $ f(1) = 3 $,  $f(2) = 7$, $f(3) = 13$, then find $a$, $b$, and $f(0)$. I know I can solve this using solving three equations simultaneously. And I can also solve this using Gauss Jordan or Gaussian elimination method by writing the augmented matrix.  But I'm wondering is there any other method to solve this. Solving by any method it turns out that $a = b = c = 1$.",,"['calculus', 'algebra-precalculus', 'derivatives', 'polynomials', 'quadratics']"
13,How to determine equation for $\sum_{k=1}^n k^3$,How to determine equation for,\sum_{k=1}^n k^3,"How do you find an algebraic formula for $\sum_{k=1}^n k^3$? I am able to find one for $\sum_{k=1}^n k^2$, but not $k^3$. Any hints would be appreciated.","How do you find an algebraic formula for $\sum_{k=1}^n k^3$? I am able to find one for $\sum_{k=1}^n k^2$, but not $k^3$. Any hints would be appreciated.",,"['calculus', 'sequences-and-series', 'summation', 'faq']"
14,What is a simple example of a limit in the real world?,What is a simple example of a limit in the real world?,,"This morning, I read Wikipedia's informal definition of a limit: Informally, a function f assigns an output $f(x)$ to every input $x$. The   function has a limit $L$ at an input $p$ if $f(x)$ is ""close"" to $L$ whenever   $x$ is ""close"" to $p$. In other words, $f(x)$ becomes closer and closer to $L$   as $x$ moves closer and closer to $p$. To me that sounds like something that might be better described as a 'target'. If I take a simple function, say one that only multiplies the input by $2$; and if my limit is $10$ at an input $5$: then I've described something that seems to match the elements contained in Wikipedia's definition. I don't believe that that's right. To me it looks like an elementary-algebra problem ($2p = 10$). To make it more calculusy, I could graph the function's output when I use inputs other than $p$, but that really wouldn't give me anything but an illustration of the fact that one's answer moves farther from the right answer as it becomes more wrong (go figure). So limits are important; what I've just described is trivial. I do not understand them. I know calculus is often used for solving real-world challenges, and that limits are an important element of calculus, so I assume there must be some simple real-world examples of what it is that limits describe. What is a simple example of a limit in the real world? Thank you -Hal.","This morning, I read Wikipedia's informal definition of a limit: Informally, a function f assigns an output $f(x)$ to every input $x$. The   function has a limit $L$ at an input $p$ if $f(x)$ is ""close"" to $L$ whenever   $x$ is ""close"" to $p$. In other words, $f(x)$ becomes closer and closer to $L$   as $x$ moves closer and closer to $p$. To me that sounds like something that might be better described as a 'target'. If I take a simple function, say one that only multiplies the input by $2$; and if my limit is $10$ at an input $5$: then I've described something that seems to match the elements contained in Wikipedia's definition. I don't believe that that's right. To me it looks like an elementary-algebra problem ($2p = 10$). To make it more calculusy, I could graph the function's output when I use inputs other than $p$, but that really wouldn't give me anything but an illustration of the fact that one's answer moves farther from the right answer as it becomes more wrong (go figure). So limits are important; what I've just described is trivial. I do not understand them. I know calculus is often used for solving real-world challenges, and that limits are an important element of calculus, so I assume there must be some simple real-world examples of what it is that limits describe. What is a simple example of a limit in the real world? Thank you -Hal.",,"['calculus', 'algebra-precalculus', 'analysis', 'limits', 'applications']"
15,How to find length of a part of a curve?,How to find length of a part of a curve?,,"How can I find the length of a curve, for example $f(x) = x^3$, between two limits on $x$, for example $1$ and $8$? I was bored in a maths lesson at school and posed myself the question: What's the perimeter of the region bounded by the $x$-axis, the lines $x=1$ and $x=8$ and the curve $y=x^3$? Of course, the only ""difficult"" part of this is finding the length of the part of the curve between $x=1$ and $x=8$. Maybe there's an established method of doing this, but I as a 16 year-old calculus student don't know it yet. So my attempt at an approach was to superimpose many triangles onto the curve so that I could sum all of their hypotenuses. Just use many triangles like the above, $$ \lim_{\delta x\to 0}\frac{\sqrt{\left(1+\delta x-1\right)^2+\left(\left(1+\delta x\right)^3-1^3\right)^2}+\sqrt{\left(1+2\delta x-\left(1+\delta x\right)\right)^2+\left(\left(1+2\delta x\right)^3-\left(1+\delta x\right)^3\right)^2}+\cdots}{\frac7{\delta x}} $$ I'm not entirely sure if this approach is correct though, or how to go on from the stage I've already got to.","How can I find the length of a curve, for example $f(x) = x^3$, between two limits on $x$, for example $1$ and $8$? I was bored in a maths lesson at school and posed myself the question: What's the perimeter of the region bounded by the $x$-axis, the lines $x=1$ and $x=8$ and the curve $y=x^3$? Of course, the only ""difficult"" part of this is finding the length of the part of the curve between $x=1$ and $x=8$. Maybe there's an established method of doing this, but I as a 16 year-old calculus student don't know it yet. So my attempt at an approach was to superimpose many triangles onto the curve so that I could sum all of their hypotenuses. Just use many triangles like the above, $$ \lim_{\delta x\to 0}\frac{\sqrt{\left(1+\delta x-1\right)^2+\left(\left(1+\delta x\right)^3-1^3\right)^2}+\sqrt{\left(1+2\delta x-\left(1+\delta x\right)\right)^2+\left(\left(1+2\delta x\right)^3-\left(1+\delta x\right)^3\right)^2}+\cdots}{\frac7{\delta x}} $$ I'm not entirely sure if this approach is correct though, or how to go on from the stage I've already got to.",,"['calculus', 'limits', 'functions']"
16,"""What if"" math joke: the derivative of $\ln(x)^e$","""What if"" math joke: the derivative of",\ln(x)^e,"Randall Munroe, the creator of xkcd in his latest book What if writes (p. 175) that the mathematical analog of the phrase ""knock me over with a feather"" is seeing the expression $ \ln( x )^{e}$. And he writes regarding this expression: ""it's not that, taken literally, it doesn't make sense - it's that you can't imagine a situation where this would apply."" In the footer (same page) he also states that ""if you want to be mean to first year calculus students, you can ask them to take the derivative of $ \ln( x )^{e}$. It looks like it should be ""$1$"" or something but it's not."" I don't get the joke. I think I am not understanding something correctly and I'm not appreciating the irony. Any help?","Randall Munroe, the creator of xkcd in his latest book What if writes (p. 175) that the mathematical analog of the phrase ""knock me over with a feather"" is seeing the expression $ \ln( x )^{e}$. And he writes regarding this expression: ""it's not that, taken literally, it doesn't make sense - it's that you can't imagine a situation where this would apply."" In the footer (same page) he also states that ""if you want to be mean to first year calculus students, you can ask them to take the derivative of $ \ln( x )^{e}$. It looks like it should be ""$1$"" or something but it's not."" I don't get the joke. I think I am not understanding something correctly and I'm not appreciating the irony. Any help?",,"['calculus', 'derivatives', 'logarithms', 'exponential-function', 'popular-math']"
17,How to compute $\int_{-\infty}^\infty\exp\left(-\frac{(x^2-13x-1)^2}{611x^2}\right)\ dx$,How to compute,\int_{-\infty}^\infty\exp\left(-\frac{(x^2-13x-1)^2}{611x^2}\right)\ dx,"$$\int_{-\infty}^\infty\exp\left(-\frac{(x^2-13x-1)^2}{611x^2}\right)\ dx$$ WolframAlpha gives a numerical answer of $43.8122$, which appears to be $\sqrt{611\pi}$. And playing with that, it seems that replacing $611$ with $a$ just gives $\sqrt{a\pi}$. My trouble is that the stuff in the exponential always seems to be just a big mess, and I haven't been able to get it into a form I can understand or deal with. I would greatly appreciate seeing a method for solving this integral.","$$\int_{-\infty}^\infty\exp\left(-\frac{(x^2-13x-1)^2}{611x^2}\right)\ dx$$ WolframAlpha gives a numerical answer of $43.8122$, which appears to be $\sqrt{611\pi}$. And playing with that, it seems that replacing $611$ with $a$ just gives $\sqrt{a\pi}$. My trouble is that the stuff in the exponential always seems to be just a big mess, and I haven't been able to get it into a form I can understand or deal with. I would greatly appreciate seeing a method for solving this integral.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
18,Question about a rotating cube?,Question about a rotating cube?,,"I read an article not too long ago that posed the following problem: What is the volume of the solid of revolution created by spinning a unit cube about an axis joining two opposing vertices? So the shape generated will be two cones and a parabola-like curve in the ""middle"". I hope that makes sense. At first, I tried to find a cross section of the resulting structure and then integrating it with disks, but I think I am over-complicating it. How would I go about solving this problem if I define my unit cube to be on the first octant with $i, j,$ and $k$ (so the axis would be $r(t)=t\langle1,1,1\rangle,0 < t <1$)? Thank you.","I read an article not too long ago that posed the following problem: What is the volume of the solid of revolution created by spinning a unit cube about an axis joining two opposing vertices? So the shape generated will be two cones and a parabola-like curve in the ""middle"". I hope that makes sense. At first, I tried to find a cross section of the resulting structure and then integrating it with disks, but I think I am over-complicating it. How would I go about solving this problem if I define my unit cube to be on the first octant with $i, j,$ and $k$ (so the axis would be $r(t)=t\langle1,1,1\rangle,0 < t <1$)? Thank you.",,['calculus']
19,"Closed form for $\int_{-\infty}^0\operatorname{Ei}^3x\,dx$",Closed form for,"\int_{-\infty}^0\operatorname{Ei}^3x\,dx","Let $\operatorname{Ei}x$ denote the exponential integral : $$\operatorname{Ei}x=-\int_{-x}^\infty\frac{e^{-t}}tdt.\tag1$$ It's not difficult to find that $$\int\operatorname{Ei}x\,dx=x\,\operatorname{Ei}x-e^x,\tag2$$ $$\int\operatorname{Ei}^2x\,dx=x\,\operatorname{Ei}^2x-2\,e^x\operatorname{Ei}x+2\,\operatorname{Ei}(2x)\tag3$$ and $$\int_{-\infty}^0\operatorname{Ei}x\,dx=-1,\tag4$$ $$\int_{-\infty}^0\operatorname{Ei}^2x\,dx=\ln4.\tag5$$ Is it possible generalize these results for higher powers of $\operatorname{Ei}x$? In particular, are there closed forms for $$\int\operatorname{Ei}^3x\,dx\tag6$$ or $$\int_{-\infty}^0\operatorname{Ei}^3x\,dx\ ?\tag7$$","Let $\operatorname{Ei}x$ denote the exponential integral : $$\operatorname{Ei}x=-\int_{-x}^\infty\frac{e^{-t}}tdt.\tag1$$ It's not difficult to find that $$\int\operatorname{Ei}x\,dx=x\,\operatorname{Ei}x-e^x,\tag2$$ $$\int\operatorname{Ei}^2x\,dx=x\,\operatorname{Ei}^2x-2\,e^x\operatorname{Ei}x+2\,\operatorname{Ei}(2x)\tag3$$ and $$\int_{-\infty}^0\operatorname{Ei}x\,dx=-1,\tag4$$ $$\int_{-\infty}^0\operatorname{Ei}^2x\,dx=\ln4.\tag5$$ Is it possible generalize these results for higher powers of $\operatorname{Ei}x$? In particular, are there closed forms for $$\int\operatorname{Ei}^3x\,dx\tag6$$ or $$\int_{-\infty}^0\operatorname{Ei}^3x\,dx\ ?\tag7$$",,"['calculus', 'integration', 'definite-integrals', 'special-functions', 'closed-form']"
20,What is the gradient with respect to a vector $\mathbf x$?,What is the gradient with respect to a vector ?,\mathbf x,"What is the meaning of ""gradient with respect to $\mathbf x$""? http://en.wikipedia.org/wiki/Gradient I am talking about the symbol $$\nabla_\mathbf x$$ Does that simply mean derivative with respect to $\mathbf x$?","What is the meaning of ""gradient with respect to $\mathbf x$""? http://en.wikipedia.org/wiki/Gradient I am talking about the symbol $$\nabla_\mathbf x$$ Does that simply mean derivative with respect to $\mathbf x$?",,"['calculus', 'multivariable-calculus']"
21,Why is the derivative of a vector orthogonal to the vector itself?,Why is the derivative of a vector orthogonal to the vector itself?,,"$R(t) \cdot R'(t) = 0$, which is what every source I can find tells me. Even though I understand the proof I don't understand the underlying concept. If $R(t)\cdot R'(t) = 0$, then $R'(t)$ is orthogonal to $R(t)$, right? But you use the same derivative to find the tangent of a curve. Then somehow if you differentiate the tangent itself, you get the normal to the curve. I really can't wrap my head around this. Could someone help me understand?","$R(t) \cdot R'(t) = 0$, which is what every source I can find tells me. Even though I understand the proof I don't understand the underlying concept. If $R(t)\cdot R'(t) = 0$, then $R'(t)$ is orthogonal to $R(t)$, right? But you use the same derivative to find the tangent of a curve. Then somehow if you differentiate the tangent itself, you get the normal to the curve. I really can't wrap my head around this. Could someone help me understand?",,"['calculus', 'derivatives', 'vectors', 'orthogonality']"
22,Closer form for $\int_0^\infty\frac{(\arctan{x})^2\log^2({1+x^2})}{x^2}dx$,Closer form for,\int_0^\infty\frac{(\arctan{x})^2\log^2({1+x^2})}{x^2}dx,"I Would like to know the value of this integral. $$\int_0^\infty\frac{(\arctan{x})^2\log^2({1+x^2})}{x^2}dx$$  I think $$I=\frac{a}{b}(\pi^3\ln2)+\frac{c}{d}(\pi\ln^32)+\frac{e}{f}(\pi\ln^22)+\frac{g}{h}(\pi\ln2)+\frac{i}{j}(\pi^3)+\frac{k}{m}\zeta({3})??$$ Where a,b,c,d...are integers Thanks.","I Would like to know the value of this integral. $$\int_0^\infty\frac{(\arctan{x})^2\log^2({1+x^2})}{x^2}dx$$  I think $$I=\frac{a}{b}(\pi^3\ln2)+\frac{c}{d}(\pi\ln^32)+\frac{e}{f}(\pi\ln^22)+\frac{g}{h}(\pi\ln2)+\frac{i}{j}(\pi^3)+\frac{k}{m}\zeta({3})??$$ Where a,b,c,d...are integers Thanks.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
23,Find the value of $\space\large i^{i^i}$?,Find the value of ?,\space\large i^{i^i},Is $\large i^{i^i}$ real ? How to find it? Thank You!,Is $\large i^{i^i}$ real ? How to find it? Thank You!,,"['calculus', 'algebra-precalculus', 'complex-numbers']"
24,What is the importance of $\sinh(x)$?,What is the importance of ?,\sinh(x),"I stumbled across $\sinh(x)$. I am only a calculus uno student, but was wondering when this function comes into play, and what is its purpose? Last, does it have world applications, or is it a human-made concept?","I stumbled across $\sinh(x)$. I am only a calculus uno student, but was wondering when this function comes into play, and what is its purpose? Last, does it have world applications, or is it a human-made concept?",,"['calculus', 'hyperbolic-functions']"
25,Bijection between an open and a closed interval,Bijection between an open and a closed interval,,"Recently, I answered to this problem: Given $a<b\in \mathbb{R}$ , find explicitly a bijection $f(x)$ from $]a,b[$ to $[a,b]$ . using an ""iterative construction"" (see below the rule). My question is: is it possible to solve the problem finding a less exotic function? I mean: I know such a bijection cannot be monotone, nor globally continuous; but my $f(x)$ has a lot of jumps... Hence, can one do without so many discontinuities? W.l.o.g. assume $a=-1$ and $b=1$ (the general case can be handled by translation and rescaling). Let: ( 1 ) $X_0:=]-1,-\frac{1}{2}] \cup [\frac{1}{2} ,1[$ , and ( 2 ) $f_0(x):=\begin{cases}     -x-\frac{3}{2} &\text{, if } -1<x\leq -\frac{1}{2} \\ -x+\frac{3}{2} &\text{,     if } \frac{1}{2}\leq     x<1\\ 0 &\text{, otherwise} \end{cases}$ , so that the graph of $f_0(x)$ is made of two segments (parallel to the line $y=x$ ) and one segment laying on the $x$ axis; then define by induction: ( 3 ) $X_{n+1}:=\frac{1}{2} X_n$ , and ( 4 ) $f_{n+1}(x):= \frac{1}{2} f_n(2 x)$ for $n\in \mathbb{N}$ (hence $X_n=\frac{1}{2^n} X_0$ and $f_n=\frac{1}{2^n} f_0(2^n x)$ ). Then the function $f:]-1,1[\to \mathbb{R}$ : ( 5 ) $f(x):=\sum_{n=0}^{+\infty} f_n(x)$ is a bijection from $]-1,1[$ to $[-1,1]$ . Proof : i . First of all, note that $\{ X_n\}_{n\in \mathbb{N}}$ is a pairwise disjoint covering of $]-1,1[\setminus \{ 0\}$ . Moreover the range of each $f_n(x)$ is $f_n(]-1,1[)=[-\frac{1}{2^n}, -\frac{1}{2^{n+1}}[\cup \{ 0\} \cup ]\frac{1}{2^{n+1}}, \frac{1}{2^n}]$ . ii . Let $x\in ]-1,1[$ . If $x=0$ , then $f(x)=0$ by ( 5 ). If $x\neq 0$ , then there exists only one $\nu\in \mathbb{N}$ s.t. $x\in X_\nu$ , hence $f(x)=f_\nu (x)$ . Therefore $f(x)$ is well defined . iii . By i and ii , $f(x)\lesseqgtr 0$ for $x\lesseqgtr 0$ and the range of $f(x)$ is: $f(]-1,1[)=\bigcup_{n\in \mathbb{N}} f(]-1,1[) =[-1,1]$ , therefore $f(x)$ is surjective. iv . On the other hand, if $x\neq y \in ]-1,1[$ , then: if there exists $\nu \in \mathbb{N}$ s.t. $x,y\in X_\nu$ , then $f(x)=f_\nu (x)\neq f_\nu (y)=f(y)$ (for $f_\nu (x)$ restrited to $X_\nu$ is injective); if $x\in X_\nu$ and $y\in X_\mu$ , then $f(x)=f_\nu (x)\neq f_\mu(y)=f(y)$ (for the restriction of $f_\nu (x)$ to $X_\nu$ and of $f_\mu(x)$ to $X_\mu$ have disjoint ranges); finally if $x=0\neq y$ , then $f(x)=0\neq f(y)$ (because of ii ). Therefore $f(x)$ is injective, hence a bijection between $]-1,1[$ and $[-1,1]$ . $\square$","Recently, I answered to this problem: Given , find explicitly a bijection from to . using an ""iterative construction"" (see below the rule). My question is: is it possible to solve the problem finding a less exotic function? I mean: I know such a bijection cannot be monotone, nor globally continuous; but my has a lot of jumps... Hence, can one do without so many discontinuities? W.l.o.g. assume and (the general case can be handled by translation and rescaling). Let: ( 1 ) , and ( 2 ) , so that the graph of is made of two segments (parallel to the line ) and one segment laying on the axis; then define by induction: ( 3 ) , and ( 4 ) for (hence and ). Then the function : ( 5 ) is a bijection from to . Proof : i . First of all, note that is a pairwise disjoint covering of . Moreover the range of each is . ii . Let . If , then by ( 5 ). If , then there exists only one s.t. , hence . Therefore is well defined . iii . By i and ii , for and the range of is: , therefore is surjective. iv . On the other hand, if , then: if there exists s.t. , then (for restrited to is injective); if and , then (for the restriction of to and of to have disjoint ranges); finally if , then (because of ii ). Therefore is injective, hence a bijection between and .","a<b\in \mathbb{R} f(x) ]a,b[ [a,b] f(x) a=-1 b=1 X_0:=]-1,-\frac{1}{2}] \cup [\frac{1}{2} ,1[ f_0(x):=\begin{cases}
    -x-\frac{3}{2} &\text{, if } -1<x\leq -\frac{1}{2} \\ -x+\frac{3}{2} &\text{,
    if } \frac{1}{2}\leq
    x<1\\ 0 &\text{, otherwise} \end{cases} f_0(x) y=x x X_{n+1}:=\frac{1}{2} X_n f_{n+1}(x):= \frac{1}{2} f_n(2 x) n\in \mathbb{N} X_n=\frac{1}{2^n} X_0 f_n=\frac{1}{2^n} f_0(2^n x) f:]-1,1[\to \mathbb{R} f(x):=\sum_{n=0}^{+\infty} f_n(x) ]-1,1[ [-1,1] \{ X_n\}_{n\in \mathbb{N}} ]-1,1[\setminus \{ 0\} f_n(x) f_n(]-1,1[)=[-\frac{1}{2^n}, -\frac{1}{2^{n+1}}[\cup \{ 0\} \cup ]\frac{1}{2^{n+1}}, \frac{1}{2^n}] x\in ]-1,1[ x=0 f(x)=0 x\neq 0 \nu\in \mathbb{N} x\in X_\nu f(x)=f_\nu (x) f(x) f(x)\lesseqgtr 0 x\lesseqgtr 0 f(x) f(]-1,1[)=\bigcup_{n\in \mathbb{N}} f(]-1,1[) =[-1,1] f(x) x\neq y \in ]-1,1[ \nu \in \mathbb{N} x,y\in X_\nu f(x)=f_\nu (x)\neq f_\nu (y)=f(y) f_\nu (x) X_\nu x\in X_\nu y\in X_\mu f(x)=f_\nu (x)\neq f_\mu(y)=f(y) f_\nu (x) X_\nu f_\mu(x) X_\mu x=0\neq y f(x)=0\neq f(y) f(x) ]-1,1[ [-1,1] \square","['calculus', 'elementary-set-theory']"
26,Great books on all different types of integration techniques,Great books on all different types of integration techniques,,"It's coming up to Christmas so I can ask to have all the books I can't afford from begrudging relatives! I'm really interested (mainly from looking at some of the answers cleo and other fantastic users!) in being able to approach integrals from a variety of different ways and learning how to tackle  non-elementary integrals. I've gone over a lot of the standard techniques in my undergrad and this is just for a hobby, so don't want anything too 'heavy', just great explanations and a lot of questions to tackle. So far I've found Irresistible Integrals: Symbolics, Analysis and Experiments in the Evaluation of Integrals. Many thanks.","It's coming up to Christmas so I can ask to have all the books I can't afford from begrudging relatives! I'm really interested (mainly from looking at some of the answers cleo and other fantastic users!) in being able to approach integrals from a variety of different ways and learning how to tackle  non-elementary integrals. I've gone over a lot of the standard techniques in my undergrad and this is just for a hobby, so don't want anything too 'heavy', just great explanations and a lot of questions to tackle. So far I've found Irresistible Integrals: Symbolics, Analysis and Experiments in the Evaluation of Integrals. Many thanks.",,"['calculus', 'integration', 'soft-question', 'book-recommendation']"
27,What is the difference between writing $f$ and $f(x)$?,What is the difference between writing  and ?,f f(x),"I see a lot of professors in my calculus courses using $f$ and $f(x)$ in a way that looks interchangeable. Sometimes it drives me crazy because I always thought of them as being different. ( $f$ means an independent variable, $f(x)$ means a variable which is dependent on $x$ .) I also can't keep up with which variable is dependent on which... So, when a professor writes down $f$ instead of $f(x)$ or $x$ instead of $x(t)$ , do they actually mean that $x$ is in/dependent? Or are they intentionally not writing it fully? Thanks!","I see a lot of professors in my calculus courses using and in a way that looks interchangeable. Sometimes it drives me crazy because I always thought of them as being different. ( means an independent variable, means a variable which is dependent on .) I also can't keep up with which variable is dependent on which... So, when a professor writes down instead of or instead of , do they actually mean that is in/dependent? Or are they intentionally not writing it fully? Thanks!",f f(x) f f(x) x f f(x) x x(t) x,['calculus']
28,Any ideas on how I can prove this expression?,Any ideas on how I can prove this expression?,,"I don't have a lot of places to turn because i am still in high school. So please bear with me as i had to create some notation. In order to understand my notation you must observe this identity for bell polynomials $a = (f'(x),f''(x),\cdots)$ and $b = (g'(x),g''(x),\cdots)$ $$ B_{n,k}(f'(x),f''(x),\cdots,f^{(n-k+1)}(x))_{(f \rightarrow g)^c} = \frac{(a^{(k-c)_\diamond} \diamond b^{c_\diamond})_n}{(k-c)!c!} $$ Also note that $d_n= \frac{d^n}{dx^n}[f(x)\ln(g(x))]$ I must prove that $$ \sum_{k=1}^{n}\ln^k(g(x)) B_{n,k}(f'(x),f''(x),\cdots,f^{(n-k+1)}(x)) $$ $$ =\sum_{k=1}^n[ B_{n,k}(d_1,d_2,\cdots,d_{n-k+1})- \sum_{m=0}^{n-k}\sum_{j=0}^{m} {m \choose j} \frac{\ln^{m-j}(g(x))}{g(x)^k} \frac{d^j}{d(f(x))^j}[(f(x))_k] B_{n,m+k}(f'(x),\cdots,f^{(n-m-k+1)}(x))_{(f \rightarrow g)^k}] $$ Where $(f(x))_k$ is the Pochhammer symbol for falling factorial I have been trying to prove this for quite a while. Any advice on doing so would be amazing. Perhaps this can be put into a determinant or something of the sort, But I am not sure about that double summation. If you have advice PLEASE do so through a comment.","I don't have a lot of places to turn because i am still in high school. So please bear with me as i had to create some notation. In order to understand my notation you must observe this identity for bell polynomials $a = (f'(x),f''(x),\cdots)$ and $b = (g'(x),g''(x),\cdots)$ $$ B_{n,k}(f'(x),f''(x),\cdots,f^{(n-k+1)}(x))_{(f \rightarrow g)^c} = \frac{(a^{(k-c)_\diamond} \diamond b^{c_\diamond})_n}{(k-c)!c!} $$ Also note that $d_n= \frac{d^n}{dx^n}[f(x)\ln(g(x))]$ I must prove that $$ \sum_{k=1}^{n}\ln^k(g(x)) B_{n,k}(f'(x),f''(x),\cdots,f^{(n-k+1)}(x)) $$ $$ =\sum_{k=1}^n[ B_{n,k}(d_1,d_2,\cdots,d_{n-k+1})- \sum_{m=0}^{n-k}\sum_{j=0}^{m} {m \choose j} \frac{\ln^{m-j}(g(x))}{g(x)^k} \frac{d^j}{d(f(x))^j}[(f(x))_k] B_{n,m+k}(f'(x),\cdots,f^{(n-m-k+1)}(x))_{(f \rightarrow g)^k}] $$ Where $(f(x))_k$ is the Pochhammer symbol for falling factorial I have been trying to prove this for quite a while. Any advice on doing so would be amazing. Perhaps this can be put into a determinant or something of the sort, But I am not sure about that double summation. If you have advice PLEASE do so through a comment.",,"['calculus', 'combinatorics', 'derivatives', 'generating-functions']"
29,Can I ever go wrong if I keep thinking of derivatives as ratios?,Can I ever go wrong if I keep thinking of derivatives as ratios?,,"I have been forewarned about it, I have read the answers here, but I haven't seen a counter example where it doesn't work. I know that it isnt really a fraction, but does it effectively get the same result in all cases, or are there counterexamples I must be warned about. I do not mean obvious counter examples, like $$\frac{dy}{dx}+\frac{du}{dv} = \frac{dydv+dxdu}{dx dv}$$ which as far as I know doesn't really mean anything.","I have been forewarned about it, I have read the answers here, but I haven't seen a counter example where it doesn't work. I know that it isnt really a fraction, but does it effectively get the same result in all cases, or are there counterexamples I must be warned about. I do not mean obvious counter examples, like $$\frac{dy}{dx}+\frac{du}{dv} = \frac{dydv+dxdu}{dx dv}$$ which as far as I know doesn't really mean anything.",,['calculus']
30,Most general $A \subseteq \mathbb R$ to define derivative of $f: A \to \mathbb R$?,Most general  to define derivative of ?,A \subseteq \mathbb R f: A \to \mathbb R,"I was looking up the definition of the derivative in several books, and what was making me uneasy was the first sentence, generally along the lines of ""let $f$ be defined on..."". They don't seem to be able to agree on what $f$ should be defined on. Most books say ""interval""; one says ""open set""; another just says ""let $f$ be a real-valued function""; etc. So I decided to do a little investigation. At the end of the day, we always define the derivative as the limit of a difference quotient (two versions), so we need to look into limits of functions. It turns out that the limit of $f$ at $a$ is only defined for $a \in (\operatorname{dom} f)'$ (we'll denote the set of cluster points of $A$ by $A'$ for convenience), because otherwise, the $0 < |x - a| < \delta$ part of the definition can be made false by choosing $\delta$ small enough to isolate $a$, thereby making the implication vacuously true, which gives non-unique limits, but we don't want that. So at this point, we know that $a$ must be a cluster point of the domain of the difference quotient. A slight digression: It's easy to show that if $B$ is a finite set, then $A' = (A \cup B)' = (A \setminus B)'$. (That is, ""adding"" or ""subtracting"" a finite number of points doesn't affect the ""stickiness"" of a set.) Let $A \subseteq \mathbb R$ and let $f: A \to \mathbb R$. For each $a \in A$, we can define a difference quotient function $q_a: A \setminus \{a\} \to \mathbb R$ by $$q_a(x) = \frac{f(x) - f(a)}{x - a}.$$ Now, (in a rather perverted pseudo-self-referential manner), we can define $$f': \{a \in A \cap A': \lim_{x \to a} q_a(x) \in \mathbb R \} \to \mathbb R \qquad \text{by} \qquad f'(a) = \lim_{x \to a} q_a(x).$$ We need $a \in A$ because $f(a)$ is needed to evaluate $q_a$, and we need $a \in A' = (A \setminus \{a\})' = (\operatorname{dom} q_a)'$ for the limit to be defined. So really, derivatives can be defined on sets that are much more general than intervals: we really only need $\operatorname{dom} f \cap (\operatorname{dom} f)' \neq \varnothing$ in order to talk about the derivative of $f$ at some point (of course, the derivative itself need not exist, but at least we can talk about it not existing). And then I started getting worried... The function $f: \mathbb R \to \mathbb R$, defined by $$f(x) = \begin{cases} x, & x \in \mathbb Q, \\ 0, & x \notin \mathbb Q, \end{cases}$$ has no derivative anywhere. But if we restrict the domain to $\mathbb Q$, then suddenly every point is differentiable with derivative $1$? Now I'm starting to wonder if I made some stupid mistake in the development above, but I can't seem to find it. So the question is, is the bolded statement above true?","I was looking up the definition of the derivative in several books, and what was making me uneasy was the first sentence, generally along the lines of ""let $f$ be defined on..."". They don't seem to be able to agree on what $f$ should be defined on. Most books say ""interval""; one says ""open set""; another just says ""let $f$ be a real-valued function""; etc. So I decided to do a little investigation. At the end of the day, we always define the derivative as the limit of a difference quotient (two versions), so we need to look into limits of functions. It turns out that the limit of $f$ at $a$ is only defined for $a \in (\operatorname{dom} f)'$ (we'll denote the set of cluster points of $A$ by $A'$ for convenience), because otherwise, the $0 < |x - a| < \delta$ part of the definition can be made false by choosing $\delta$ small enough to isolate $a$, thereby making the implication vacuously true, which gives non-unique limits, but we don't want that. So at this point, we know that $a$ must be a cluster point of the domain of the difference quotient. A slight digression: It's easy to show that if $B$ is a finite set, then $A' = (A \cup B)' = (A \setminus B)'$. (That is, ""adding"" or ""subtracting"" a finite number of points doesn't affect the ""stickiness"" of a set.) Let $A \subseteq \mathbb R$ and let $f: A \to \mathbb R$. For each $a \in A$, we can define a difference quotient function $q_a: A \setminus \{a\} \to \mathbb R$ by $$q_a(x) = \frac{f(x) - f(a)}{x - a}.$$ Now, (in a rather perverted pseudo-self-referential manner), we can define $$f': \{a \in A \cap A': \lim_{x \to a} q_a(x) \in \mathbb R \} \to \mathbb R \qquad \text{by} \qquad f'(a) = \lim_{x \to a} q_a(x).$$ We need $a \in A$ because $f(a)$ is needed to evaluate $q_a$, and we need $a \in A' = (A \setminus \{a\})' = (\operatorname{dom} q_a)'$ for the limit to be defined. So really, derivatives can be defined on sets that are much more general than intervals: we really only need $\operatorname{dom} f \cap (\operatorname{dom} f)' \neq \varnothing$ in order to talk about the derivative of $f$ at some point (of course, the derivative itself need not exist, but at least we can talk about it not existing). And then I started getting worried... The function $f: \mathbb R \to \mathbb R$, defined by $$f(x) = \begin{cases} x, & x \in \mathbb Q, \\ 0, & x \notin \mathbb Q, \end{cases}$$ has no derivative anywhere. But if we restrict the domain to $\mathbb Q$, then suddenly every point is differentiable with derivative $1$? Now I'm starting to wonder if I made some stupid mistake in the development above, but I can't seem to find it. So the question is, is the bolded statement above true?",,[]
31,Compute close-form of $\int_0^{\frac\pi2}\frac{dt}{\sin t+\cos t+\tan t+\cot t+\csc t+\sec t}$,Compute close-form of,\int_0^{\frac\pi2}\frac{dt}{\sin t+\cos t+\tan t+\cot t+\csc t+\sec t},"I came across the improper trigonometric integral recently shared in a Chinese web forum \begin{align} \int_0^{\frac\pi2}\frac{dt}{\sin t+\cos t+\tan t+\cot t+\csc t+\sec t}\\ \end{align} which amuses me because of its appearance. What is more amusing is the claim, without providing the proof, that is has the close-form result \begin{align} \frac{\sqrt{8\sqrt2+2\sqrt7}}{7^{3/4} }\tanh^{-1}  \frac{\sqrt{2\sqrt7(4\sqrt2-5)}}{4\sqrt2-5 +\sqrt7} +\frac{\sqrt{8\sqrt2-2\sqrt7}}{7^{3/4} }\tan^{-1}\frac{\sqrt{2\sqrt7(4\sqrt2-5)}}{4\sqrt2-5 - \sqrt7} \end{align} I was able to verify it numerically; yet rather curious in how it could ever be derived. Based on my knowledge and experience, I do not assume it would be easy. I was able to find an unsolved post here from a long time ago, which only reexpresses the corresponding  indefinite integral via the tangent half-angle substitution as $$\int\frac{2t(1-t)} {2 t^4-3 t^3+3 t^2+t+1}dt$$ but gives up due to the complexity in partial fractionalization. I am doubtful that this approach would lead to the explicit expression claimed above. I am interested in any suitable methods producing the close-form.","I came across the improper trigonometric integral recently shared in a Chinese web forum which amuses me because of its appearance. What is more amusing is the claim, without providing the proof, that is has the close-form result I was able to verify it numerically; yet rather curious in how it could ever be derived. Based on my knowledge and experience, I do not assume it would be easy. I was able to find an unsolved post here from a long time ago, which only reexpresses the corresponding  indefinite integral via the tangent half-angle substitution as but gives up due to the complexity in partial fractionalization. I am doubtful that this approach would lead to the explicit expression claimed above. I am interested in any suitable methods producing the close-form.","\begin{align}
\int_0^{\frac\pi2}\frac{dt}{\sin t+\cos t+\tan t+\cot t+\csc t+\sec t}\\
\end{align} \begin{align}
\frac{\sqrt{8\sqrt2+2\sqrt7}}{7^{3/4} }\tanh^{-1}  \frac{\sqrt{2\sqrt7(4\sqrt2-5)}}{4\sqrt2-5 +\sqrt7}
+\frac{\sqrt{8\sqrt2-2\sqrt7}}{7^{3/4} }\tan^{-1}\frac{\sqrt{2\sqrt7(4\sqrt2-5)}}{4\sqrt2-5 - \sqrt7}
\end{align} \int\frac{2t(1-t)}
{2 t^4-3 t^3+3 t^2+t+1}dt","['calculus', 'integration', 'definite-integrals', 'closed-form', 'trigonometric-integrals']"
32,Prove $\int_0^{\infty} \left(\sqrt{1+x^{4}}-x^{2}\right)\ dx=\frac{\Gamma^{2}\left(\frac{1}{4}\right)}{6\sqrt{\pi}}$,Prove,\int_0^{\infty} \left(\sqrt{1+x^{4}}-x^{2}\right)\ dx=\frac{\Gamma^{2}\left(\frac{1}{4}\right)}{6\sqrt{\pi}},"I have in trouble for evaluating following integral $$\int_0^{\infty}  \left(\sqrt{1+x^{4}}-x^{2}\right)\ dx=\frac{\Gamma^{2}\left(\frac{1}{4}\right)}{6\sqrt{\pi}}$$ It seems really easy, but I don't know how to handle it at all. (The results are well known, here I tried to evaluate it but I failed) I tried to use the relation $$\sqrt{1+x^{4}}-x^{2}=\frac{1}{\sqrt{1+x^{4}}+x^{2}}$$ but I couldn't find the desired results.","I have in trouble for evaluating following integral $$\int_0^{\infty}  \left(\sqrt{1+x^{4}}-x^{2}\right)\ dx=\frac{\Gamma^{2}\left(\frac{1}{4}\right)}{6\sqrt{\pi}}$$ It seems really easy, but I don't know how to handle it at all. (The results are well known, here I tried to evaluate it but I failed) I tried to use the relation $$\sqrt{1+x^{4}}-x^{2}=\frac{1}{\sqrt{1+x^{4}}+x^{2}}$$ but I couldn't find the desired results.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
33,"Relation between differentiable,continuous and integrable functions.","Relation between differentiable,continuous and integrable functions.",,"I have been doing lots of calculus these days and i want to confirm with you guys my understanding of an important concept of calculus. Basically, in the initial phase,students assume that integration and differentiation are always associated to each other, i.e., a function which is integrable is also differentiable at the same time. But having explored on it more, i found out its not true at all and does not hold always. Many a times (or should i say infinitely times) a function can be integrable on an interval while its not differentiable on that same interval (and vice versa) . What i want to ask is this : i recently read a conclusion on the above mentioned concept which is : {Differentiable functions} $\subset$ {Continuous functions} $\subset$ {Integrable functions} i.e., each is a proper subset of the next. Now, ""Differentiable functions set"" is a proper subset of ""Continuous functions set""... that is very well understood without a doubt as every continuous function may or may not be differentiable. I have problem with the next relation which is : $\\\\$ ""Continuous functions set"" is a proper subset of ""Integrable functions set""...Why is this so??? $\\\\$ I am just not able to visualize this. I know that a bounded continuous function on a closed interval is integrable, well and fine, but there are unbounded continuous functions too with domain R , which we cant say will be integrable or not. So, my question is simple. Why are there more number of elements in the ""Integrable functions set"" than ""Continuous functions set"" (here by elements i mean integrable and continuous functions ofcourse) ???. So,this is it... Can anyone plz help me understand this out in as simple words as possible. I know i need some kind of visualization which i guess is easy, but i could not make it out on my own, so i turned to u guys.Thanks for any help.","I have been doing lots of calculus these days and i want to confirm with you guys my understanding of an important concept of calculus. Basically, in the initial phase,students assume that integration and differentiation are always associated to each other, i.e., a function which is integrable is also differentiable at the same time. But having explored on it more, i found out its not true at all and does not hold always. Many a times (or should i say infinitely times) a function can be integrable on an interval while its not differentiable on that same interval (and vice versa) . What i want to ask is this : i recently read a conclusion on the above mentioned concept which is : {Differentiable functions} $\subset$ {Continuous functions} $\subset$ {Integrable functions} i.e., each is a proper subset of the next. Now, ""Differentiable functions set"" is a proper subset of ""Continuous functions set""... that is very well understood without a doubt as every continuous function may or may not be differentiable. I have problem with the next relation which is : $\\\\$ ""Continuous functions set"" is a proper subset of ""Integrable functions set""...Why is this so??? $\\\\$ I am just not able to visualize this. I know that a bounded continuous function on a closed interval is integrable, well and fine, but there are unbounded continuous functions too with domain R , which we cant say will be integrable or not. So, my question is simple. Why are there more number of elements in the ""Integrable functions set"" than ""Continuous functions set"" (here by elements i mean integrable and continuous functions ofcourse) ???. So,this is it... Can anyone plz help me understand this out in as simple words as possible. I know i need some kind of visualization which i guess is easy, but i could not make it out on my own, so i turned to u guys.Thanks for any help.",,"['calculus', 'functions']"
34,Integrating the formula for the sum of the first $n$ natural numbers,Integrating the formula for the sum of the first  natural numbers,n,"I was messing around with some math formulas today and came up with a result that I found pretty neat, and I would appreciate it if anyone could explain it to me. The formula for an infinite arithmetic sum is $$\sum_{i=1}^{n}a_i=\frac{n(a_1+a_n)}{2},$$ so if you want to find the sum of the natural numbers from $1$ to $n$, this equation becomes $$\frac{n^2+n}{2},$$ and the roots of this quadratic are at $n=-1$ and $0$. What I find really interesting is that $$\int_{-1}^0 \frac{n^2+n}{2}dn=-\frac{1}{12}$$ There are a lot of people who claim that the sum of all natural numbers is $-\frac{1}{12}$, so I was wondering if this result is a complete coincidence or if there's something else to glean from it.","I was messing around with some math formulas today and came up with a result that I found pretty neat, and I would appreciate it if anyone could explain it to me. The formula for an infinite arithmetic sum is $$\sum_{i=1}^{n}a_i=\frac{n(a_1+a_n)}{2},$$ so if you want to find the sum of the natural numbers from $1$ to $n$, this equation becomes $$\frac{n^2+n}{2},$$ and the roots of this quadratic are at $n=-1$ and $0$. What I find really interesting is that $$\int_{-1}^0 \frac{n^2+n}{2}dn=-\frac{1}{12}$$ There are a lot of people who claim that the sum of all natural numbers is $-\frac{1}{12}$, so I was wondering if this result is a complete coincidence or if there's something else to glean from it.",,"['calculus', 'integration', 'sequences-and-series', 'summation']"
35,"Prove ${\large\int}_0^\infty\left({_2F_1}\left(\frac16,\frac12;\frac13;-x\right)\right)^{12}dx\stackrel{\color{#808080}?}=\frac{80663}{153090}$",Prove,"{\large\int}_0^\infty\left({_2F_1}\left(\frac16,\frac12;\frac13;-x\right)\right)^{12}dx\stackrel{\color{#808080}?}=\frac{80663}{153090}","I discovered the following conjectured identity numerically (it holds with at least $1000$ digits of precision). How can I prove it? $${\large\int}_0^\infty\left({_2F_1}\left(\frac16,\frac12;\frac13;-x\right)\right)^{12}dx\stackrel{\color{#808080}?}=\frac{80663}{153090}$$ Update: It looks like this hypergeometric function assumes algebraic values at algebraic points (it's only a guess because I have only approximations to those algebraic numbers). Looking at those values, I was able to further conjecture that the hypergeometric function for $x<0$ is actually the following elementary function: $$ {_2F_1}\left(\frac16,\frac12;\frac13;x\right)\stackrel{\color{#808080}?}= \\ \frac1{\sqrt[4]2\sqrt3}\cdot\sqrt{\frac{\alpha}{1-x}+\frac{1}{\alpha} \sqrt{\frac{4\left(\alpha\sqrt{2}+2\right)+x\left(\sqrt[3]{4\beta}-2\left(\alpha\sqrt{2}+4\right)\right)+2\sqrt[3]{2\beta^2}}{1-x}}}~, $$ where $$\alpha=\sqrt{2-2x+\sqrt[3]{2\beta^2}}~,\qquad\beta=x(x-1)~.$$","I discovered the following conjectured identity numerically (it holds with at least $1000$ digits of precision). How can I prove it? $${\large\int}_0^\infty\left({_2F_1}\left(\frac16,\frac12;\frac13;-x\right)\right)^{12}dx\stackrel{\color{#808080}?}=\frac{80663}{153090}$$ Update: It looks like this hypergeometric function assumes algebraic values at algebraic points (it's only a guess because I have only approximations to those algebraic numbers). Looking at those values, I was able to further conjecture that the hypergeometric function for $x<0$ is actually the following elementary function: $$ {_2F_1}\left(\frac16,\frac12;\frac13;x\right)\stackrel{\color{#808080}?}= \\ \frac1{\sqrt[4]2\sqrt3}\cdot\sqrt{\frac{\alpha}{1-x}+\frac{1}{\alpha} \sqrt{\frac{4\left(\alpha\sqrt{2}+2\right)+x\left(\sqrt[3]{4\beta}-2\left(\alpha\sqrt{2}+4\right)\right)+2\sqrt[3]{2\beta^2}}{1-x}}}~, $$ where $$\alpha=\sqrt{2-2x+\sqrt[3]{2\beta^2}}~,\qquad\beta=x(x-1)~.$$",,"['calculus', 'integration', 'special-functions', 'improper-integrals', 'hypergeometric-function']"
36,Defining the derivative without limits,Defining the derivative without limits,,"These days, the standard way to present differential calculus is by introducing the Cauchy-Weierstrass definition of the limit. One then defines the derivative as a limit, proves results like the Leibniz and chain rules, and uses this machinery to differentiate some simple functions such as polynomials. The purpose of my question is to see what creative alternatives people can describe to this approach. The nature of the question is that there is not going to be a single best answer. I have several methods that I've collected which I'll put in as answers to my own question. It's not reasonable to expect answers to include an entire introductory textbook treatment of differentiation, nor would anyone want to read answers that were that lengthy. A sketch is fine. Lack of rigor is fine. Well known notation and terminology can be assumed. It would be nice to develop things to the point where one can differentiate a polynomial, since that would help to illustrate how your method works and demonstrate that it's usable. For this purpose, it suffices to prove that if $n>0$ is an integer, the derivative of $x^n$ equals $0$ at $0$ and equals $n$ at $1$; the result at other nonzero values of $x$ follows by scaling. Doing this for $n=2$ is fine if the generalization to $n>2$ is obvious.","These days, the standard way to present differential calculus is by introducing the Cauchy-Weierstrass definition of the limit. One then defines the derivative as a limit, proves results like the Leibniz and chain rules, and uses this machinery to differentiate some simple functions such as polynomials. The purpose of my question is to see what creative alternatives people can describe to this approach. The nature of the question is that there is not going to be a single best answer. I have several methods that I've collected which I'll put in as answers to my own question. It's not reasonable to expect answers to include an entire introductory textbook treatment of differentiation, nor would anyone want to read answers that were that lengthy. A sketch is fine. Lack of rigor is fine. Well known notation and terminology can be assumed. It would be nice to develop things to the point where one can differentiate a polynomial, since that would help to illustrate how your method works and demonstrate that it's usable. For this purpose, it suffices to prove that if $n>0$ is an integer, the derivative of $x^n$ equals $0$ at $0$ and equals $n$ at $1$; the result at other nonzero values of $x$ follows by scaling. Doing this for $n=2$ is fine if the generalization to $n>2$ is obvious.",,"['calculus', 'limits']"
37,What is wrong with the following u-substitution?,What is wrong with the following u-substitution?,,"We will calculate $\displaystyle\int^{2 \pi}_0 x \, dx$.  Let $u=\sin (x)$, and observe that $\sin(2 \pi)=0$ and $\sin(0)=0$.  We also have that $\frac{du}{dx}=\cos(x)=\sqrt{1-u^2}$. Hence, $$ \int^{2 \pi}_0 x \, dx=\int^0_0 \frac{\sin^{-1}(u)}{\sqrt{1-u^2}} \, du = 0. $$ This is very obviously wrong, but I am not sure how to explain the error formally. Edit: Thanks for the responses and in particular the link below to the related problem!  The error is indeed caused by the substitution $x=\sin^{-1}(u)$.  The integration is performed over $[0,2 \pi]$ which is outside the range of the $\sin^{-1}$ function. Remark The error is slightly better disguised when calculating $\displaystyle\int^1_{-1}\frac{2x}{1+x^2} \, dx.$ Let $u(x)=1+x^2$, and observe that $u(1)=u(-1)=2$.  Then since $dx=\frac{1}{2x} du$, we have that $$ \int^1_{-1} \frac{2x}{1+x^2} \, dx =  \int^2_2 \frac{1}{u} \, du=0. $$ This time, no trigonometric substitution is used, but it is still an incorrect proof for the same reason as above.  A correct proof can be obtained by using the fact that $x \mapsto \displaystyle\frac{2x}{1+x^2}$ is odd. This example is more disturbing because the procedures above are entirely intuitive and yield the correct result. It seems to me that students when taught integration by substitution of definite integrals should also be taught that great care be exercised in checking the range of integration, particularly when the (apparent) substituting function is not invertible in that range.","We will calculate $\displaystyle\int^{2 \pi}_0 x \, dx$.  Let $u=\sin (x)$, and observe that $\sin(2 \pi)=0$ and $\sin(0)=0$.  We also have that $\frac{du}{dx}=\cos(x)=\sqrt{1-u^2}$. Hence, $$ \int^{2 \pi}_0 x \, dx=\int^0_0 \frac{\sin^{-1}(u)}{\sqrt{1-u^2}} \, du = 0. $$ This is very obviously wrong, but I am not sure how to explain the error formally. Edit: Thanks for the responses and in particular the link below to the related problem!  The error is indeed caused by the substitution $x=\sin^{-1}(u)$.  The integration is performed over $[0,2 \pi]$ which is outside the range of the $\sin^{-1}$ function. Remark The error is slightly better disguised when calculating $\displaystyle\int^1_{-1}\frac{2x}{1+x^2} \, dx.$ Let $u(x)=1+x^2$, and observe that $u(1)=u(-1)=2$.  Then since $dx=\frac{1}{2x} du$, we have that $$ \int^1_{-1} \frac{2x}{1+x^2} \, dx =  \int^2_2 \frac{1}{u} \, du=0. $$ This time, no trigonometric substitution is used, but it is still an incorrect proof for the same reason as above.  A correct proof can be obtained by using the fact that $x \mapsto \displaystyle\frac{2x}{1+x^2}$ is odd. This example is more disturbing because the procedures above are entirely intuitive and yield the correct result. It seems to me that students when taught integration by substitution of definite integrals should also be taught that great care be exercised in checking the range of integration, particularly when the (apparent) substituting function is not invertible in that range.",,"['calculus', 'integration', 'analysis']"
38,"Closed form for $\int_0^\infty\frac{\sin x\,\cdot\,\operatorname{Ci}x-\cos x\,\cdot\,\operatorname{Si}x}{\sqrt{16\,x^2+1}}dx$",Closed form for,"\int_0^\infty\frac{\sin x\,\cdot\,\operatorname{Ci}x-\cos x\,\cdot\,\operatorname{Si}x}{\sqrt{16\,x^2+1}}dx","Is it possible to find a closed form for this integral? $$\mathcal{S}=\int_0^\infty\frac{\sin x\cdot\operatorname{Ci}x-\cos x\cdot\operatorname{Si}x}{\sqrt{16\,x^2+1}}dx,$$ where $\operatorname{Ci}x$ is the cosine integral and $\operatorname{Si}x$ is the sine integral : $$\operatorname{Ci}x=-\int_x^\infty\frac{\cos t}t dt,\ \operatorname{Si}x=\int_0^x\frac{\sin t}t dt.$$ Numerical integration gives $$\mathcal{S}\approx0.133456902778362645676629...$$","Is it possible to find a closed form for this integral? $$\mathcal{S}=\int_0^\infty\frac{\sin x\cdot\operatorname{Ci}x-\cos x\cdot\operatorname{Si}x}{\sqrt{16\,x^2+1}}dx,$$ where $\operatorname{Ci}x$ is the cosine integral and $\operatorname{Si}x$ is the sine integral : $$\operatorname{Ci}x=-\int_x^\infty\frac{\cos t}t dt,\ \operatorname{Si}x=\int_0^x\frac{\sin t}t dt.$$ Numerical integration gives $$\mathcal{S}\approx0.133456902778362645676629...$$",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
39,Problem when integrating $e^x / x$.,Problem when integrating .,e^x / x,"I made up some integrals to do for fun, and I had a real problem with this one. I've since found out that there's no solution in terms of elementary functions, but when I attempt to integrate it, I end up with infinite values. Could somebody point out where I go wrong? So, I'm trying to determine: $$ \int{\frac{e^x}{x}} \, dx $$ Integrate by parts, where $u = 1/x$, and $v \, ' = e^x$. Then $u \, ' = - 1/x^2$, and $v=e^x$. So, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \int{\frac{e^x}{x^2}} \, dx$$ Integrate by parts again, $u = 1/x^2$, $v \, ' = e^x$, so that $u \, ' = -2/x^3$ and $v=e^x$. So, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \frac{e^x}{x^2} + 2\int{\frac{e^x}{x^3}} \, dx$$ Repeat this process ad infinitum to get, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \frac{e^x}{x^2} + 2 \left( \frac{e^x}{x^3} + 3 \left( \frac{e^x}{x^4} + 4 \left( \frac{e^x}{x^5} + \, \cdots \right) \right) \right) $$ Expanding this gives, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \frac{e^x}{x^2} + \frac{2e^x}{x^3} + \frac{6 e^x}{x^4} + \frac{24 e^x}{x^5} + \cdots $$ And factoring that gives, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} \left(  1 + \frac{1}{x} + \frac{2}{x^2} + \frac{6}{x^3} + \frac{24}{x^4} + \cdots \right) $$ Now, considering the series itself, the ratio between the $n^{th}$ term and the $(n-1)^{th}$ term = $\Large \frac{n}{x}$. Eventually, $n$ will be larger than $x$, so the ratio between successive terms will be positive, so (assuming $x$ is positive), the series diverges, meaning (and I'm sure everybody will cringe upon seeing notation used like this), that: $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} \left( \infty \right) = \infty $$","I made up some integrals to do for fun, and I had a real problem with this one. I've since found out that there's no solution in terms of elementary functions, but when I attempt to integrate it, I end up with infinite values. Could somebody point out where I go wrong? So, I'm trying to determine: $$ \int{\frac{e^x}{x}} \, dx $$ Integrate by parts, where $u = 1/x$, and $v \, ' = e^x$. Then $u \, ' = - 1/x^2$, and $v=e^x$. So, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \int{\frac{e^x}{x^2}} \, dx$$ Integrate by parts again, $u = 1/x^2$, $v \, ' = e^x$, so that $u \, ' = -2/x^3$ and $v=e^x$. So, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \frac{e^x}{x^2} + 2\int{\frac{e^x}{x^3}} \, dx$$ Repeat this process ad infinitum to get, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \frac{e^x}{x^2} + 2 \left( \frac{e^x}{x^3} + 3 \left( \frac{e^x}{x^4} + 4 \left( \frac{e^x}{x^5} + \, \cdots \right) \right) \right) $$ Expanding this gives, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} + \frac{e^x}{x^2} + \frac{2e^x}{x^3} + \frac{6 e^x}{x^4} + \frac{24 e^x}{x^5} + \cdots $$ And factoring that gives, $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} \left(  1 + \frac{1}{x} + \frac{2}{x^2} + \frac{6}{x^3} + \frac{24}{x^4} + \cdots \right) $$ Now, considering the series itself, the ratio between the $n^{th}$ term and the $(n-1)^{th}$ term = $\Large \frac{n}{x}$. Eventually, $n$ will be larger than $x$, so the ratio between successive terms will be positive, so (assuming $x$ is positive), the series diverges, meaning (and I'm sure everybody will cringe upon seeing notation used like this), that: $$\int{\frac{e^x}{x}} \, dx = \frac{e^x}{x} \left( \infty \right) = \infty $$",,"['calculus', 'sequences-and-series', 'integration', 'fake-proofs']"
40,"A closed form for $\int_0^\infty\frac{e^{-x}\ J_0(x)\ \sin\left(x\,\sqrt[3]{2}\right)}{x}dx$",A closed form for,"\int_0^\infty\frac{e^{-x}\ J_0(x)\ \sin\left(x\,\sqrt[3]{2}\right)}{x}dx","I am stuck with this integral: $$\int_0^\infty\frac{e^{-x}\ J_0(x)\ \sin\left(x\,\sqrt[3]{2}\right)}{x}dx,$$ where $J_0$ is the Bessel function of the first kind. Is it possible to express this integral in a closed form (preferably, using elementary functions, Bessel functions, integers and basic constants)?","I am stuck with this integral: $$\int_0^\infty\frac{e^{-x}\ J_0(x)\ \sin\left(x\,\sqrt[3]{2}\right)}{x}dx,$$ where $J_0$ is the Bessel function of the first kind. Is it possible to express this integral in a closed form (preferably, using elementary functions, Bessel functions, integers and basic constants)?",,"['calculus', 'integration', 'special-functions', 'definite-integrals', 'closed-form']"
41,Is there a fundamental theorem of calculus for improper integrals?,Is there a fundamental theorem of calculus for improper integrals?,,"Let $f\,\,$ be a continuous function on $[a,\infty)$ such that $\int_a^\infty f(t)\,dt$ converges. Define the function $F\,$ on $[a,\infty)$ with $$F(x) := -\int_x^\infty f(t)\,dt \qquad\text{for all}\quad x\in[a,\infty).$$ Can we somehow deduce from this—using the regular fundamental theorem of calculus—that $F\,\,$ is continuous and differentiable on $(a,\infty)$, and that $F\,\,'(x) = f(x)$ for all $x\in(a,\infty)$? If so, how? Are such “improper” versions of the fundamental theorem to be found in some book out there that I can reference?","Let $f\,\,$ be a continuous function on $[a,\infty)$ such that $\int_a^\infty f(t)\,dt$ converges. Define the function $F\,$ on $[a,\infty)$ with $$F(x) := -\int_x^\infty f(t)\,dt \qquad\text{for all}\quad x\in[a,\infty).$$ Can we somehow deduce from this—using the regular fundamental theorem of calculus—that $F\,\,$ is continuous and differentiable on $(a,\infty)$, and that $F\,\,'(x) = f(x)$ for all $x\in(a,\infty)$? If so, how? Are such “improper” versions of the fundamental theorem to be found in some book out there that I can reference?",,[]
42,Derivative of a vector with respect to a matrix,Derivative of a vector with respect to a matrix,,let $W$ be a $n\times m$ matrix and $\textbf{x}$ be a $m\times1$ vector. How do we calculate the following then? $$\frac{dW\textbf{x}}{dW}$$ Thanks in advance.,let $W$ be a $n\times m$ matrix and $\textbf{x}$ be a $m\times1$ vector. How do we calculate the following then? $$\frac{dW\textbf{x}}{dW}$$ Thanks in advance.,,"['calculus', 'linear-algebra', 'matrix-calculus', 'tensors']"
43,"Conjecture: $\int_0^1\frac{3x^3-2x}{(1+x)\sqrt{1-x}}K\big(\!\frac{2x}{1+x}\!\big)\,dx\stackrel ?=\frac\pi{5\sqrt2}$",Conjecture:,"\int_0^1\frac{3x^3-2x}{(1+x)\sqrt{1-x}}K\big(\!\frac{2x}{1+x}\!\big)\,dx\stackrel ?=\frac\pi{5\sqrt2}","$$\int_0^1\frac{3x^3-2x}{(1+x)\sqrt{1-x}}K\left(\frac{2x}{1+x}\right)\,dx\stackrel ?=\frac\pi{5\sqrt2}$$ The integral above comes from the evaluation of the integral $A=\int_0^{\pi/2}\frac{f(\theta)}\pi d\theta$, where $$f(\theta)=\int_0^\pi\frac{(3\sin^2\theta-2)\sin\theta\,d\phi}{\sqrt{2+2\sin\theta\cos\phi}}=\frac{\sqrt2(3\sin^2\theta-2)}{\csc\theta\sqrt{1+\sin\theta}}\int_0^{\pi/2}\left(1-\frac{2\sin\theta}{1+\sin\theta}\sin^2\gamma\right)^{-1/2}d\gamma,$$ where $\gamma=\phi/2$, and the right side integral is $K\big(\!\frac{2\sin\theta}{1+\sin\theta}\!\big)$ by definition. After substitutions $x=\sin\theta$ and $y=\frac{2x}{1+x}$ we get $$\begin{align}A&=\frac{\sqrt2}\pi\int_0^1\frac{3x^3-2x}{(1+x)\sqrt{1-x}}K\left(\frac{2x}{1+x}\right)\,dx\\ &=\frac1\pi\int_0^1\frac{y^3+8y^2-8y}{(2-y)^3\sqrt{y^2-3y+2}}K(y)\,dy\stackrel ?=\frac15,\end{align}$$ where the integral has been numerically evaluated to suggest the analytic result on the right to several thousand digits. Is there any way to prove this equality, and are there any generalizations of this conjecture to include other parameters? P.S. Not that it's overly relevant to the question, but for the interested reader, the original integral comes from the following physics problem: [Morin Intro to Classical Mechanics , Ex. 10.12] The earth bulges slightly at the equator, due to the centrifugal force in the earth’s rotating frame. The goal of this exercise is to find the shape of the earth, first incorrectly, and then correctly. (a) The common incorrect method is to assume that the gravitation force from the slightly nonspherical earth points toward the center, and to then calculate the equipotential surface (incorporating both the gravitational and centrifugal forces). Show that this method leads to a surface whose height (relative to a spherical earth of the same volume) is given by $h(\theta)=R\big(\!\frac{R\omega^2}{6g}\!\big)(3\sin^2⁡\theta-2)$, where $\theta$ is the polar angle (the angle down from the north pole), and $R$ is the radius of the earth. (b) The above method is incorrect, because the slight distortion of the earth causes the gravitational force to not point toward the center of the earth (except at the equator and the poles). This tilt in the force direction then changes the slope of the equipotential surface, and it turns out (although this is by no means obvious) that this effect is of the same order as the slope of the surface found in part (a). Your task: Assuming that the density of the earth is constant, and that the correct height takes the form of some constant factor $f$ times the result found in part (a), show that $f=5/2$. Do this by demanding that the potential at a pole equals the potential at the equator.","$$\int_0^1\frac{3x^3-2x}{(1+x)\sqrt{1-x}}K\left(\frac{2x}{1+x}\right)\,dx\stackrel ?=\frac\pi{5\sqrt2}$$ The integral above comes from the evaluation of the integral $A=\int_0^{\pi/2}\frac{f(\theta)}\pi d\theta$, where $$f(\theta)=\int_0^\pi\frac{(3\sin^2\theta-2)\sin\theta\,d\phi}{\sqrt{2+2\sin\theta\cos\phi}}=\frac{\sqrt2(3\sin^2\theta-2)}{\csc\theta\sqrt{1+\sin\theta}}\int_0^{\pi/2}\left(1-\frac{2\sin\theta}{1+\sin\theta}\sin^2\gamma\right)^{-1/2}d\gamma,$$ where $\gamma=\phi/2$, and the right side integral is $K\big(\!\frac{2\sin\theta}{1+\sin\theta}\!\big)$ by definition. After substitutions $x=\sin\theta$ and $y=\frac{2x}{1+x}$ we get $$\begin{align}A&=\frac{\sqrt2}\pi\int_0^1\frac{3x^3-2x}{(1+x)\sqrt{1-x}}K\left(\frac{2x}{1+x}\right)\,dx\\ &=\frac1\pi\int_0^1\frac{y^3+8y^2-8y}{(2-y)^3\sqrt{y^2-3y+2}}K(y)\,dy\stackrel ?=\frac15,\end{align}$$ where the integral has been numerically evaluated to suggest the analytic result on the right to several thousand digits. Is there any way to prove this equality, and are there any generalizations of this conjecture to include other parameters? P.S. Not that it's overly relevant to the question, but for the interested reader, the original integral comes from the following physics problem: [Morin Intro to Classical Mechanics , Ex. 10.12] The earth bulges slightly at the equator, due to the centrifugal force in the earth’s rotating frame. The goal of this exercise is to find the shape of the earth, first incorrectly, and then correctly. (a) The common incorrect method is to assume that the gravitation force from the slightly nonspherical earth points toward the center, and to then calculate the equipotential surface (incorporating both the gravitational and centrifugal forces). Show that this method leads to a surface whose height (relative to a spherical earth of the same volume) is given by $h(\theta)=R\big(\!\frac{R\omega^2}{6g}\!\big)(3\sin^2⁡\theta-2)$, where $\theta$ is the polar angle (the angle down from the north pole), and $R$ is the radius of the earth. (b) The above method is incorrect, because the slight distortion of the earth causes the gravitational force to not point toward the center of the earth (except at the equator and the poles). This tilt in the force direction then changes the slope of the equipotential surface, and it turns out (although this is by no means obvious) that this effect is of the same order as the slope of the surface found in part (a). Your task: Assuming that the density of the earth is constant, and that the correct height takes the form of some constant factor $f$ times the result found in part (a), show that $f=5/2$. Do this by demanding that the potential at a pole equals the potential at the equator.",,"['calculus', 'integration', 'closed-form', 'conjectures', 'elliptic-functions']"
44,Strange symmetry regarding sum $\sum_{n=0}^\infty\frac{n^ne^{-bn}}{\Gamma(n+1)}$ and integral $\int_{0}^\infty\frac{x^xe^{-bx}}{\Gamma(x+1)}dx$,Strange symmetry regarding sum  and integral,\sum_{n=0}^\infty\frac{n^ne^{-bn}}{\Gamma(n+1)} \int_{0}^\infty\frac{x^xe^{-bx}}{\Gamma(x+1)}dx,"One can show by computation the following for $b>1$ $$\sum_{n=0}^\infty\frac{n^ne^{-b n}}{\Gamma(n+1)}=\frac{1}{1+W_{\color{blue}{0}}(-e^{-b})},\tag{1}$$ (here one assumes that the term with $n=0$ is understood as the limit $\lim_{n\to 0}$ and is equal to $1$) and $$\int_{0}^\infty\frac{x^xe^{-b x}}{\Gamma(x+1)}dx=\boldsymbol{\color{red}{-}}\frac{1}{1+W_{\color{red}{-1}}(-e^{-b})}.\tag{2}$$ $W_0$ and $W_{-1}$ are different branches of the Lambert W function . One can see that this formulas look similar. I considered them in the hope of obtaining a function for which sum equals integral: $$ \sum_{n=0}^\infty f(n)=\int_0^\infty f(x) dx. $$ $(1)$ is the consequence of Lagrange inversion and the integral arises in the probability distribution theory, namely the Kadell-Ressel pdf (see also this MSE post ). Question 1. Can anybody explain the symmetry between $(1)$ and $(2)$ without resorting to direct calculation ? Question 2. Is it possible to alter $(1)$ and $(2)$ to obtain a nice function for which sum equals integral? If $b=1$ then there is the Knuth series $$ \sum_{n=1}^\infty\left(\frac{n^ne^{-n}}{\Gamma(n+1)}-\frac1{\sqrt{2\pi n}}\right)=-\frac23-\frac1{\sqrt{2\pi}}\zeta(1/2),\tag{3} $$ and the ""Knuth integral"" $$ \int_0^\infty\left(\frac{x^xe^{-x}}{\Gamma(x+1)}-\frac1{\sqrt{2\pi x}}\right)dx=-\frac13.\tag{4} $$ Again we see there is a discrepancy. Question 3. Is it possible to modify the term $\frac1{\sqrt{2\pi x}}$ in $(3)$ and $(4)$ so that the series and the integral agree? Edit. Of course by mounting some additional terms and parameters one can come up with a formula that technically answers question 2 or 3. What is meant as nice in question 2 might be difficult to formulate explicitly. It is best illustrated by formulas in this MSE post .","One can show by computation the following for $b>1$ $$\sum_{n=0}^\infty\frac{n^ne^{-b n}}{\Gamma(n+1)}=\frac{1}{1+W_{\color{blue}{0}}(-e^{-b})},\tag{1}$$ (here one assumes that the term with $n=0$ is understood as the limit $\lim_{n\to 0}$ and is equal to $1$) and $$\int_{0}^\infty\frac{x^xe^{-b x}}{\Gamma(x+1)}dx=\boldsymbol{\color{red}{-}}\frac{1}{1+W_{\color{red}{-1}}(-e^{-b})}.\tag{2}$$ $W_0$ and $W_{-1}$ are different branches of the Lambert W function . One can see that this formulas look similar. I considered them in the hope of obtaining a function for which sum equals integral: $$ \sum_{n=0}^\infty f(n)=\int_0^\infty f(x) dx. $$ $(1)$ is the consequence of Lagrange inversion and the integral arises in the probability distribution theory, namely the Kadell-Ressel pdf (see also this MSE post ). Question 1. Can anybody explain the symmetry between $(1)$ and $(2)$ without resorting to direct calculation ? Question 2. Is it possible to alter $(1)$ and $(2)$ to obtain a nice function for which sum equals integral? If $b=1$ then there is the Knuth series $$ \sum_{n=1}^\infty\left(\frac{n^ne^{-n}}{\Gamma(n+1)}-\frac1{\sqrt{2\pi n}}\right)=-\frac23-\frac1{\sqrt{2\pi}}\zeta(1/2),\tag{3} $$ and the ""Knuth integral"" $$ \int_0^\infty\left(\frac{x^xe^{-x}}{\Gamma(x+1)}-\frac1{\sqrt{2\pi x}}\right)dx=-\frac13.\tag{4} $$ Again we see there is a discrepancy. Question 3. Is it possible to modify the term $\frac1{\sqrt{2\pi x}}$ in $(3)$ and $(4)$ so that the series and the integral agree? Edit. Of course by mounting some additional terms and parameters one can come up with a formula that technically answers question 2 or 3. What is meant as nice in question 2 might be difficult to formulate explicitly. It is best illustrated by formulas in this MSE post .",,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'special-functions']"
45,$f\colon I\rightarrow G$ and Gromov $\delta$-hyperbolicity,and Gromov -hyperbolicity,f\colon I\rightarrow G \delta,"Please recall that $\left|\int_0^1 f(t)\,dt -w\right|\leq \int_0^1|f(t)-w|\,dt$. In general, let $(X,d)$ be a metric space. Given a function $f:I\to X$ let $m_f\in X$ be such that $d(m_f,w)\leq \int_0^1 d(f(t),w)\,dt$ for every $w\in X$. If such $m_f\in X$ exists then we call $f$ as $D$-integrable with $D$-integral $m_f$. ($I=[0,1]$.) Question: Given a finitely generated group $G$ (with a usual word distance), does there exist a condition on the set of $D$-integrable functions $f: I\to G$ (which uses $D$-integrability) for the Gromov $\delta$-hyperbolicity of $G$? I.e, what is the characterization of hyperbolicity in terms of $D$-integrability? (It seems to me that the real question here should be: how can one extract group theoretic intel from $D$-integrability?)","Please recall that $\left|\int_0^1 f(t)\,dt -w\right|\leq \int_0^1|f(t)-w|\,dt$. In general, let $(X,d)$ be a metric space. Given a function $f:I\to X$ let $m_f\in X$ be such that $d(m_f,w)\leq \int_0^1 d(f(t),w)\,dt$ for every $w\in X$. If such $m_f\in X$ exists then we call $f$ as $D$-integrable with $D$-integral $m_f$. ($I=[0,1]$.) Question: Given a finitely generated group $G$ (with a usual word distance), does there exist a condition on the set of $D$-integrable functions $f: I\to G$ (which uses $D$-integrability) for the Gromov $\delta$-hyperbolicity of $G$? I.e, what is the characterization of hyperbolicity in terms of $D$-integrability? (It seems to me that the real question here should be: how can one extract group theoretic intel from $D$-integrability?)",,"['calculus', 'group-theory', 'metric-spaces']"
46,Prove that If $f$ is polynomial function of even degree $n$ with always $f\geq0$ then $f+f'+f''+\cdots+f^{(n)}\geq 0$. [duplicate],Prove that If  is polynomial function of even degree  with always  then . [duplicate],f n f\geq0 f+f'+f''+\cdots+f^{(n)}\geq 0,This question already has answers here : Sum of derivatives of a polynomial (3 answers) Closed 11 years ago . I can't solve this problem: Suppose $f$ is polynomial function of even degree $n$ with always $f\geq0$. Prove that $f+f'+f''+\cdots+f^{(n)}\geq 0$.,This question already has answers here : Sum of derivatives of a polynomial (3 answers) Closed 11 years ago . I can't solve this problem: Suppose $f$ is polynomial function of even degree $n$ with always $f\geq0$. Prove that $f+f'+f''+\cdots+f^{(n)}\geq 0$.,,"['calculus', 'polynomials']"
47,When do Taylor series provide a perfect approximation?,When do Taylor series provide a perfect approximation?,,"To my understanding, the Taylor series is a type of power series that provides an approximation of a function at some particular point $x=a$. But under what circumstances is this approximation perfect, and under what circumstances is it ""off"" even at infinity? I realize is a little hazy so I'll rephrase: By ""perfect"" I refer to how a regular limit doesn't ever actually reach something but instead provides a sort of error term that you can make as small as you want, so for all practical purposes we treat it as zero error. Whereas for something that is an imperfect approximation maybe that arbitrarily small error piece doesn't exist, or maybe the function is only correct for that particular point and nowhere else, etc. So maybe what I am asking is when the Taylor series provides an equivalent representation of the function over all $x$ in $f$'s domain, and when does it not? And when it doesn't, how do we even know?","To my understanding, the Taylor series is a type of power series that provides an approximation of a function at some particular point $x=a$. But under what circumstances is this approximation perfect, and under what circumstances is it ""off"" even at infinity? I realize is a little hazy so I'll rephrase: By ""perfect"" I refer to how a regular limit doesn't ever actually reach something but instead provides a sort of error term that you can make as small as you want, so for all practical purposes we treat it as zero error. Whereas for something that is an imperfect approximation maybe that arbitrarily small error piece doesn't exist, or maybe the function is only correct for that particular point and nowhere else, etc. So maybe what I am asking is when the Taylor series provides an equivalent representation of the function over all $x$ in $f$'s domain, and when does it not? And when it doesn't, how do we even know?",,"['calculus', 'derivatives', 'taylor-expansion', 'definition', 'approximation']"
48,"Is it okay to ""ignore"" small numbers in limits where $x$ approaches infinity?","Is it okay to ""ignore"" small numbers in limits where  approaches infinity?",x,"I got a limit: $$\lim_{x\to\infty}\frac {(2x+3)^3(3x-2)^2} {(x^5 + 5)}$$ As far as $x$ approaches infinity, can I just forget about 'small' numbers (like $3$, $-2$ and $5$ in this example)? I mean is it legal to make a transition to: $$\lim_{x\to\infty}\frac {(2x)^3(3x)^2} {x^5}$$ Or if it is not always okay — in what cases such transitions are okay?","I got a limit: $$\lim_{x\to\infty}\frac {(2x+3)^3(3x-2)^2} {(x^5 + 5)}$$ As far as $x$ approaches infinity, can I just forget about 'small' numbers (like $3$, $-2$ and $5$ in this example)? I mean is it legal to make a transition to: $$\lim_{x\to\infty}\frac {(2x)^3(3x)^2} {x^5}$$ Or if it is not always okay — in what cases such transitions are okay?",,"['calculus', 'limits']"
49,An integral for the New Year 2016,An integral for the New Year 2016,,I have built this integral with the purpose of presenting a question. I find interesting and pleasant to readers MSE for the New Year 2016 and expecting to see different methods of solution. I can confirm that this has been the case by the welcome that has been given and the two motivated answers it have had. Calculate: $$\large \int_{2016}^{3\cdot 2016}\frac{\sqrt[5]{3\cdot 2016-x} }{\sqrt[5]{3\cdot 2016-x}+\sqrt[5]{x-2016}}\mathrm dx$$,I have built this integral with the purpose of presenting a question. I find interesting and pleasant to readers MSE for the New Year 2016 and expecting to see different methods of solution. I can confirm that this has been the case by the welcome that has been given and the two motivated answers it have had. Calculate:,\large \int_{2016}^{3\cdot 2016}\frac{\sqrt[5]{3\cdot 2016-x} }{\sqrt[5]{3\cdot 2016-x}+\sqrt[5]{x-2016}}\mathrm dx,"['calculus', 'integration', 'definite-integrals']"
50,Integral $\int_0^{\infty} \frac{\log x}{\cosh^2x} \ \mathrm{d}x = \log\frac {\pi}4- \gamma$,Integral,\int_0^{\infty} \frac{\log x}{\cosh^2x} \ \mathrm{d}x = \log\frac {\pi}4- \gamma,"Inspired by the user @Integrals, I thought I'd find some nice integrals! Especially interesting are those involving $\log \pi$. From Borwein and Devlin's ""The Computer as Crucible"", pg. 58 - show that $$\displaystyle \int_0^{\infty} \frac{\log x}{\cosh^2x} \ \mathrm{d}x = \log\frac {\pi}4 - \gamma,$$ where $\gamma$ is the Euler-Mascheroni constant.","Inspired by the user @Integrals, I thought I'd find some nice integrals! Especially interesting are those involving $\log \pi$. From Borwein and Devlin's ""The Computer as Crucible"", pg. 58 - show that $$\displaystyle \int_0^{\infty} \frac{\log x}{\cosh^2x} \ \mathrm{d}x = \log\frac {\pi}4 - \gamma,$$ where $\gamma$ is the Euler-Mascheroni constant.",,"['calculus', 'integration', 'definite-integrals', 'contour-integration']"
51,How to prove that $\lim_{n \to \infty} n x^{n} = 0 $ when $0<x<1$?,How to prove that  when ?,\lim_{n \to \infty} n x^{n} = 0  0<x<1,"Intuitively it's easy, but hard to prove by the epsilon-delta method: $$ \lim_{n \to \infty} n x^{n} = 0$$","Intuitively it's easy, but hard to prove by the epsilon-delta method: $$ \lim_{n \to \infty} n x^{n} = 0$$",,"['calculus', 'limits']"
52,Is Calculus necessary for computer science student? [closed],Is Calculus necessary for computer science student? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 4 years ago . Improve this question I'm a freshman in university and I'm studying Computer science and engineering. This will be my second year of studying. We don't have Calculus as a mandatory class but I can take it from elective classes. More senior students are telling me calculus is a very hard class and I shouldn't take it. Should I take easier classes just to pass? Or should I take it anyway even if I'm really bad at math but enjoy math a lot? Is calculus necessary for my future as a student and would it help me in data science or AI? That's what I'm really interested in and I want to work for either of them. Would Calculus make my education easier in the future and in my work or should I just take something just to pass? In my next semesters, I want to take just AI and DS classes (Data mining, Data Science, Mechanical Learning, etc). Thanks for your time reading and answering my question.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 4 years ago . Improve this question I'm a freshman in university and I'm studying Computer science and engineering. This will be my second year of studying. We don't have Calculus as a mandatory class but I can take it from elective classes. More senior students are telling me calculus is a very hard class and I shouldn't take it. Should I take easier classes just to pass? Or should I take it anyway even if I'm really bad at math but enjoy math a lot? Is calculus necessary for my future as a student and would it help me in data science or AI? That's what I'm really interested in and I want to work for either of them. Would Calculus make my education easier in the future and in my work or should I just take something just to pass? In my next semesters, I want to take just AI and DS classes (Data mining, Data Science, Mechanical Learning, etc). Thanks for your time reading and answering my question.",,"['calculus', 'soft-question', 'computer-science', 'education']"
53,"If $f(x)$ has a vertical asymptote, does $f'(x)$ have one too?","If  has a vertical asymptote, does  have one too?",f(x) f'(x),"So here is what I understand: If $f(x)$ is increasing/decreasing , then its derivative $f'(x)$ is positive/negative and... If $f(x)$ is increasing/decreasing , then the derivative of $f'(x)$ (which is $f''(x)$) is concave up/concave down So my question is: if a graph has a vertical asymptote, the derivative must also have a vertical asymptote, too, right? Does it also work vice versa ? I feel like there is a trick to it, but I'm not sure. I have a graph from GeoGebra here . The dotted line is the derivative.","So here is what I understand: If $f(x)$ is increasing/decreasing , then its derivative $f'(x)$ is positive/negative and... If $f(x)$ is increasing/decreasing , then the derivative of $f'(x)$ (which is $f''(x)$) is concave up/concave down So my question is: if a graph has a vertical asymptote, the derivative must also have a vertical asymptote, too, right? Does it also work vice versa ? I feel like there is a trick to it, but I'm not sure. I have a graph from GeoGebra here . The dotted line is the derivative.",,"['calculus', 'functions', 'derivatives']"
54,"Evaluating $\int_0^{\large\frac{\pi}{4}} \log\left( \cos x\right) \, \mathrm{d}x $",Evaluating,"\int_0^{\large\frac{\pi}{4}} \log\left( \cos x\right) \, \mathrm{d}x ","It's my first  post here  and I was wondering  if someone  could help me with evaluating the definite integral  $$ \int_0^{\Large\frac{\pi}{4}} \log\left( \cos x\right) \, \mathrm{d}x $$ Thanks in advance, any help would be appreciated.","It's my first  post here  and I was wondering  if someone  could help me with evaluating the definite integral  $$ \int_0^{\Large\frac{\pi}{4}} \log\left( \cos x\right) \, \mathrm{d}x $$ Thanks in advance, any help would be appreciated.",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'logarithms']"
55,How is it that treating Leibniz notation as a fraction is fundamentally incorrect but at the same time useful?,How is it that treating Leibniz notation as a fraction is fundamentally incorrect but at the same time useful?,,"I have long struggled with the idea of Leibniz notation and the way it is used, especially in integration. These threads discuss why treating Leibniz notation as a fraction and cancelling differentials is incorrect, but also go on to say that the notation is suggestive and we use it because it simplifies things: What is the practical difference between a differential and a derivative? If dy/dt * dt doesn't cancel, then what do you call it? In them they say to treat the differential at the end of an integration expression as a ""right parenthesis"". This throws me off a bit because we can so easily do something like: $$\int\cos(3x) \, dx\\ u=3x\\[2ex] du=3\,dx\\[2ex] \frac{1}{3}du=dx$$ and then proceed to integrate: $$\frac{1}{3}\int\cos(u) \, du$$ and arrive at the correct answer with ""incorrect"" notation. I am supposed to treat the differential as a parenthesis but using this notation the differential seems to have a value. How does this incorrect notation do such a good job ensuring that we do not disobey the ""reverse chain rule"" and ensures that our integrand is in the form $f'(g(x))\,g'(x)$ ? People often say that it is very suggestive and I am wondering how. Excuse the LaTeX if it looks weird. This is my first time using it.","I have long struggled with the idea of Leibniz notation and the way it is used, especially in integration. These threads discuss why treating Leibniz notation as a fraction and cancelling differentials is incorrect, but also go on to say that the notation is suggestive and we use it because it simplifies things: What is the practical difference between a differential and a derivative? If dy/dt * dt doesn't cancel, then what do you call it? In them they say to treat the differential at the end of an integration expression as a ""right parenthesis"". This throws me off a bit because we can so easily do something like: and then proceed to integrate: and arrive at the correct answer with ""incorrect"" notation. I am supposed to treat the differential as a parenthesis but using this notation the differential seems to have a value. How does this incorrect notation do such a good job ensuring that we do not disobey the ""reverse chain rule"" and ensures that our integrand is in the form ? People often say that it is very suggestive and I am wondering how. Excuse the LaTeX if it looks weird. This is my first time using it.","\int\cos(3x) \, dx\\
u=3x\\[2ex]
du=3\,dx\\[2ex]
\frac{1}{3}du=dx \frac{1}{3}\int\cos(u) \, du f'(g(x))\,g'(x)","['calculus', 'integration', 'notation', 'math-history', 'differential']"
56,Calculus and Category theory,Calculus and Category theory,,"Quick question: Is it possible to differentiate a function with respect to another function, or is it limited to a particular variable? I tried thinking around how to make this question make sense, but I can't figure it out! I mean, $\frac{\mathrm{d}}{\mathrm{d}x}$ is a function which accepts a function, and returns a function (the derivative of the original function). However, $\frac{\mathrm{d}}{\mathrm{d}x}$ is not equal to $\frac{\mathrm{d}}{\mathrm{d}y}$, and not equal to $\frac{\mathrm{d}}{\mathrm{d}z}$, so it appears that the function for differentiation would be: derivative :: (real -> real) -> variable with respect to which you are differentiating -> (real -> real) so, why can't I do: $$ \begin{align} \text{let }f(x) &= \sin(x)\\ \text{let }g(x) &= \cos(x)\\ \frac{\mathrm{d}}{\mathrm{d}g} f(x) &=\ ??? \end{align} $$ and if I can, what is this called and where can I read more about this? Sorry for badly formulating the question, but I am really curious on how to understand this idea, as I feel like I huge gap in understanding... I would formulate this better, but the books on Calculus are so focused on applications and proofs, rather than explaining what it is, and when they try to explain what it is, they still do not explain it in terms that are useful to me. I am trying to understand how Calculus can be visualized under Category Theory, so that I can model it better in Haskell other programming languages. Thanks! ~Dmitry","Quick question: Is it possible to differentiate a function with respect to another function, or is it limited to a particular variable? I tried thinking around how to make this question make sense, but I can't figure it out! I mean, $\frac{\mathrm{d}}{\mathrm{d}x}$ is a function which accepts a function, and returns a function (the derivative of the original function). However, $\frac{\mathrm{d}}{\mathrm{d}x}$ is not equal to $\frac{\mathrm{d}}{\mathrm{d}y}$, and not equal to $\frac{\mathrm{d}}{\mathrm{d}z}$, so it appears that the function for differentiation would be: derivative :: (real -> real) -> variable with respect to which you are differentiating -> (real -> real) so, why can't I do: $$ \begin{align} \text{let }f(x) &= \sin(x)\\ \text{let }g(x) &= \cos(x)\\ \frac{\mathrm{d}}{\mathrm{d}g} f(x) &=\ ??? \end{align} $$ and if I can, what is this called and where can I read more about this? Sorry for badly formulating the question, but I am really curious on how to understand this idea, as I feel like I huge gap in understanding... I would formulate this better, but the books on Calculus are so focused on applications and proofs, rather than explaining what it is, and when they try to explain what it is, they still do not explain it in terms that are useful to me. I am trying to understand how Calculus can be visualized under Category Theory, so that I can model it better in Haskell other programming languages. Thanks! ~Dmitry",,"['calculus', 'category-theory']"
57,Motivating infinite series,Motivating infinite series,,"What are some good ways to motivate the material on infinite series that appears at the end of a typical American Calculus II course? My students in this course are generally from biochemistry, computer science, economics, business, and physics (with a few humanities folks taking the course for fun) - not just math majors. I have struggled some in the past to motivate the infinite series material to these students.  For one, it doesn't fit with the rest of Calc II, which is on the integral.  Over the years I have ""converged"" on telling them that the main point of the unit is Taylor series and that the rest of the material is there primarily so that we have the tools we need in order to understand Taylor series.  Then I illustrate some of the many uses of Taylor series (mainly function approximation, at this level).  This approach works better than anything I've come up with thus far with respect to getting my students to care about infinite series, but I feel a little like I'm selling the rest of the material short by subordinating it to Taylor series.  Does anyone have other ways of motivating infinite series that they would like to share?  (Again, only a small percentage of the students in my class are math majors.) Background: The material in this unit typically consists of sequences, basic series (like geometric and telescoping ones), a slew of tests for convergence (e.g., integral test, ratio test, root test), an introduction to power series, Taylor and Maclaurin series, and maybe binomial series.","What are some good ways to motivate the material on infinite series that appears at the end of a typical American Calculus II course? My students in this course are generally from biochemistry, computer science, economics, business, and physics (with a few humanities folks taking the course for fun) - not just math majors. I have struggled some in the past to motivate the infinite series material to these students.  For one, it doesn't fit with the rest of Calc II, which is on the integral.  Over the years I have ""converged"" on telling them that the main point of the unit is Taylor series and that the rest of the material is there primarily so that we have the tools we need in order to understand Taylor series.  Then I illustrate some of the many uses of Taylor series (mainly function approximation, at this level).  This approach works better than anything I've come up with thus far with respect to getting my students to care about infinite series, but I feel a little like I'm selling the rest of the material short by subordinating it to Taylor series.  Does anyone have other ways of motivating infinite series that they would like to share?  (Again, only a small percentage of the students in my class are math majors.) Background: The material in this unit typically consists of sequences, basic series (like geometric and telescoping ones), a slew of tests for convergence (e.g., integral test, ratio test, root test), an introduction to power series, Taylor and Maclaurin series, and maybe binomial series.",,"['calculus', 'sequences-and-series', 'education']"
58,"If $\frac{dy}{dt}dt$ doesn't cancel, then what do you call it?","If  doesn't cancel, then what do you call it?",\frac{dy}{dt}dt,"I have $y$ is a function of $t$. I have reached a situation here where I need to evaluate $$\displaystyle \int_0^b{\frac{dy}{dt}dt}$$ Now clearly $y$ has dependence on $t$, otherwise $\displaystyle \frac{dy}{dt}$ should be 0. So now I write $$\displaystyle \int_{y(0)}^{y(b)}{dy} = y \rvert_{y(0)}^{y(b)} = y(b) - y(0)$$ I know that dt's don't cancel , but what do you call it, then?  Just a ""change of variables""?  How do we justify where $dt$ went?","I have $y$ is a function of $t$. I have reached a situation here where I need to evaluate $$\displaystyle \int_0^b{\frac{dy}{dt}dt}$$ Now clearly $y$ has dependence on $t$, otherwise $\displaystyle \frac{dy}{dt}$ should be 0. So now I write $$\displaystyle \int_{y(0)}^{y(b)}{dy} = y \rvert_{y(0)}^{y(b)} = y(b) - y(0)$$ I know that dt's don't cancel , but what do you call it, then?  Just a ""change of variables""?  How do we justify where $dt$ went?",,"['calculus', 'notation']"
59,How to prove $(1+1/x)^x$ is increasing when $x>0$?,How to prove  is increasing when ?,(1+1/x)^x x>0,Let $F(x)=(1+\frac{1}{x})^x$. How do we prove $F(x)$ is increasing when $x>0$?,Let $F(x)=(1+\frac{1}{x})^x$. How do we prove $F(x)$ is increasing when $x>0$?,,"['calculus', 'analysis']"
60,"If $\alpha$ is an acute angle, show that $\int_0^1 \frac{dx}{x^2+2x\cos{\alpha}+1} = \frac{\alpha}{2\sin{\alpha}}.$","If  is an acute angle, show that",\alpha \int_0^1 \frac{dx}{x^2+2x\cos{\alpha}+1} = \frac{\alpha}{2\sin{\alpha}}.,"If $\alpha$ is an acute angle, show that $\displaystyle  \int_0^1 \frac{dx}{x^2+2x\cos{\alpha}+1} = \frac{\alpha}{2\sin{\alpha}}.$ My attempt: Write $x^2+2x\cos{\alpha}+1 = (x+\cos{\alpha})^2+1-\cos^2{\alpha} = (x+\cos{\alpha})^2+\sin^2{\alpha}$, we have: $\displaystyle  \begin{aligned}\int_0^1 \frac{dx}{x^2+2x\cos{\alpha}+1} & = \int_0^1 \frac{dx}{(x+\cos{\alpha})^2+\sin^2{\alpha}} = \bigg[\frac{1}{\sin{\alpha}}\tan^{-1}\left(\frac{x+\cos{\alpha}}{\sin{\alpha}}\right)\bigg]_{x=0}^1 \\ & = \frac{1}{\sin{\alpha}}\bigg[\color{blue}{\tan^{-1}\left(\frac{1+\cos{\alpha}}{\sin{\alpha}}\right)-\tan^{-1}\left(\frac{\cos{\alpha}}{\sin{\alpha}}\right)}\bigg] \end{aligned}$ I'm not sure, however, how the blue bit reduces to $\frac{1}{2}\alpha$. Any hints/suggestions? Thanks.","If $\alpha$ is an acute angle, show that $\displaystyle  \int_0^1 \frac{dx}{x^2+2x\cos{\alpha}+1} = \frac{\alpha}{2\sin{\alpha}}.$ My attempt: Write $x^2+2x\cos{\alpha}+1 = (x+\cos{\alpha})^2+1-\cos^2{\alpha} = (x+\cos{\alpha})^2+\sin^2{\alpha}$, we have: $\displaystyle  \begin{aligned}\int_0^1 \frac{dx}{x^2+2x\cos{\alpha}+1} & = \int_0^1 \frac{dx}{(x+\cos{\alpha})^2+\sin^2{\alpha}} = \bigg[\frac{1}{\sin{\alpha}}\tan^{-1}\left(\frac{x+\cos{\alpha}}{\sin{\alpha}}\right)\bigg]_{x=0}^1 \\ & = \frac{1}{\sin{\alpha}}\bigg[\color{blue}{\tan^{-1}\left(\frac{1+\cos{\alpha}}{\sin{\alpha}}\right)-\tan^{-1}\left(\frac{\cos{\alpha}}{\sin{\alpha}}\right)}\bigg] \end{aligned}$ I'm not sure, however, how the blue bit reduces to $\frac{1}{2}\alpha$. Any hints/suggestions? Thanks.",,"['calculus', 'integration', 'trigonometry']"
61,A closed form of $\int_0^1\frac{\ln\ln\left({1}/{x}\right)}{x^2-x+1}\mathrm dx$,A closed form of,\int_0^1\frac{\ln\ln\left({1}/{x}\right)}{x^2-x+1}\mathrm dx,"This integral has been bugging me since yesterday: $$\int_0^1\frac{\ln\ln\left({1}/{x}\right)}{x^2-x+1}\mathrm dx$$ I've tried substitution $y={1}/{x}$ and $e^y={1}/{x}$, but those didn't help much. Wolfram Alpha gives me result: $-0.67172$. Could anyone here please help me to obtain the closed form of the integral preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","This integral has been bugging me since yesterday: $$\int_0^1\frac{\ln\ln\left({1}/{x}\right)}{x^2-x+1}\mathrm dx$$ I've tried substitution $y={1}/{x}$ and $e^y={1}/{x}$, but those didn't help much. Wolfram Alpha gives me result: $-0.67172$. Could anyone here please help me to obtain the closed form of the integral preferably ( if possible ) with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
62,"Find the value of $\int_{0}^{\infty}\frac{x^3}{e^x-1}\ln(e^x - 1)\,dx$",Find the value of,"\int_{0}^{\infty}\frac{x^3}{e^x-1}\ln(e^x - 1)\,dx","I'm trying to figure out how to evaluate the following: $$ J=\int_{0}^{\infty}\frac{x^3}{e^x-1}\ln(e^x - 1)\,dx $$ I'm tried considering $I(s) = \int_{0}^{\infty}\frac{x^3}{(e^x-1)^s}\,dx\implies J=-I'(1)$, but I couldn't figure out what $I(s)$ was. My other idea was contour integration, but I'm not sure how to deal with the logarithm. Mathematica says that $J\approx24.307$. I've asked a similar question and the answer involved $\zeta(s)$ so I suspect that this one will as well.","I'm trying to figure out how to evaluate the following: $$ J=\int_{0}^{\infty}\frac{x^3}{e^x-1}\ln(e^x - 1)\,dx $$ I'm tried considering $I(s) = \int_{0}^{\infty}\frac{x^3}{(e^x-1)^s}\,dx\implies J=-I'(1)$, but I couldn't figure out what $I(s)$ was. My other idea was contour integration, but I'm not sure how to deal with the logarithm. Mathematica says that $J\approx24.307$. I've asked a similar question and the answer involved $\zeta(s)$ so I suspect that this one will as well.",,"['calculus', 'integration', 'special-functions', 'definite-integrals', 'riemann-zeta']"
63,Integral $\int_0^1\frac{\ln x}{x-1}\ln\left(1+\frac1{\ln^2x}\right)dx$,Integral,\int_0^1\frac{\ln x}{x-1}\ln\left(1+\frac1{\ln^2x}\right)dx,"Is it possible to evaluate this integral in a closed form? $$ I \equiv \int_{0}^{1}{\ln\left(x\right) \over x - 1}\, \ln\left(1 + {1 \over \ln^{2}\left(x\right)}\right)\,{\rm d}x $$ Numerically, $$I\approx2.18083278090426462584033339029703713513\dots$$","Is it possible to evaluate this integral in a closed form? $$ I \equiv \int_{0}^{1}{\ln\left(x\right) \over x - 1}\, \ln\left(1 + {1 \over \ln^{2}\left(x\right)}\right)\,{\rm d}x $$ Numerically, $$I\approx2.18083278090426462584033339029703713513\dots$$",,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'closed-form']"
64,Difference between functional and function.,Difference between functional and function.,,"I have come across the term 'functional'. How is a 'functional' different from a 'function'? The exact term I came across was 'statistical functional.' In terms of the background, can you please focus on the first few lines followed by the four examples in http://sites.stat.psu.edu/~dhunter/asymp/fall2002/lectures/ln14.pdf ? The definition is seeming to be quite generalized given the examples. Is there a crux of the definition that is not too general nor too restricted?","I have come across the term 'functional'. How is a 'functional' different from a 'function'? The exact term I came across was 'statistical functional.' In terms of the background, can you please focus on the first few lines followed by the four examples in http://sites.stat.psu.edu/~dhunter/asymp/fall2002/lectures/ln14.pdf ? The definition is seeming to be quite generalized given the examples. Is there a crux of the definition that is not too general nor too restricted?",,"['calculus', 'functions', 'terminology']"
65,"Why is the definition of ""limit"" difficult to understand at first? [duplicate]","Why is the definition of ""limit"" difficult to understand at first? [duplicate]",,"This question already has answers here : Why are epsilon-delta proofs difficult? (8 answers) Closed 6 months ago . Tomorrow I teach my students about limits of sequences.  I have heard that the definition of limit is often difficult for students to understand, and I want to make it easier.  But first I need to know, why would the definition be difficult to understand?  Too many logical quantifiers?  The definition of ""sequence"" itself is vague?  The usual examples are not enough to develop intuition? I hope this question is not too vague.","This question already has answers here : Why are epsilon-delta proofs difficult? (8 answers) Closed 6 months ago . Tomorrow I teach my students about limits of sequences.  I have heard that the definition of limit is often difficult for students to understand, and I want to make it easier.  But first I need to know, why would the definition be difficult to understand?  Too many logical quantifiers?  The definition of ""sequence"" itself is vague?  The usual examples are not enough to develop intuition? I hope this question is not too vague.",,"['calculus', 'sequences-and-series', 'limits', 'soft-question', 'education']"
66,Integral of Binomial Coefficient,Integral of Binomial Coefficient,,"We all know the famous theorem that: $$\sum_{i=1}^n\binom{n}{i}=2^n$$ This theorem got me wondering about a similar formula - the properties of the following function: $$I(n)=\int_{0}^{n} \binom{n}{k}\,\,\mathrm{d}k$$ where $n$ is any positive integer and the definition of binomial coefficient is ""extended"" by way of gamma functions (i.e the integrand is really $\frac{\Gamma(n+1)}{\Gamma(k+1)\Gamma(n-k+1)}$ ).  What I found, experimentally, is pretty cool. It seems that the following is true: $$I(n)=\frac{2}{\pi} \sum_{i=1}^n \binom{n}{i}\operatorname{SinInt}(\pi i)$$ Where $\operatorname{SinInt}(x)$ is the Sine Integral , or $\int_0^x \frac{\sin t}{t}dt$ . To me, this is quite interesting as the Sine Integral tends to $\pi/2$ so the above formula will tend to $2^n$ , so the integral is just the sum with some error term. But how would I go about proving it?","We all know the famous theorem that: This theorem got me wondering about a similar formula - the properties of the following function: where is any positive integer and the definition of binomial coefficient is ""extended"" by way of gamma functions (i.e the integrand is really ).  What I found, experimentally, is pretty cool. It seems that the following is true: Where is the Sine Integral , or . To me, this is quite interesting as the Sine Integral tends to so the above formula will tend to , so the integral is just the sum with some error term. But how would I go about proving it?","\sum_{i=1}^n\binom{n}{i}=2^n I(n)=\int_{0}^{n} \binom{n}{k}\,\,\mathrm{d}k n \frac{\Gamma(n+1)}{\Gamma(k+1)\Gamma(n-k+1)} I(n)=\frac{2}{\pi} \sum_{i=1}^n \binom{n}{i}\operatorname{SinInt}(\pi i) \operatorname{SinInt}(x) \int_0^x \frac{\sin t}{t}dt \pi/2 2^n","['calculus', 'integration', 'definite-integrals']"
67,Is there an expression for $I(n)=\int_{0}^{\frac{\pi}{4}}x\tan^{n}x dx$?,Is there an expression for ?,I(n)=\int_{0}^{\frac{\pi}{4}}x\tan^{n}x dx,"I've played around a little with this integral, and I can straightforwardly evaluate it with a substitution $\tan x\mapsto x$ in terms of the Beta function if the bounds were $(0,\pi /2)$ . But for the bounds $(0,\pi /4)$ the substitution takes the bounds to $(0,1)$ which can't be done with the Beta function. Alternatively, if we substitute $\tan 2x \mapsto x$ , we get that $$I(n)=\frac{1}{4}\int\limits_{0}^{\infty}\frac{\left(\sqrt{x^{2}+1}-1\right)^{n}\tan^{-1}x}{x^{n}\left(1-x^{2}\right)}dx=\frac{1}{4}\int\limits_{0}^{\infty}\frac{x^{n}\tan^{-1}x}{\left(1-x^{2}\right)\left(\sqrt{x^{2}+1}+1\right)^{n}}dx$$ I'm wondering if there is a nice expression for this integral. Side note, I'm only actually interested in what it is for $n\geq1$ . Checking with Wolfram Alpha, it seems that the integral behaves slightly differently for odd and even $n$ . For $n=2k-1$ , $k$ $n$ $I(2k-1)$ $1$ $1$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2$ $2$ $3$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{4}\pi+\frac{1}{2}\right)$ $3$ $5$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{4}\pi+\frac{2}{3}$ $4$ $7$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{3}\pi+\frac{73}{90}\right)$ $5$ $9$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{3}\pi+\frac{284}{315}$ $6$ $11$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{23}{60}\pi+\frac{3103}{3150}\right)$ $7$ $13$ $\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{23}{60}\pi+\frac{54472}{51975}$ $9$ $15$ $-\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{44}{105}\pi+\frac{10459489}{9459450}\right)$ (where $G$ is Catalan's constant.) $I(n)$ for odd $n$ takes the form of $(-1)^{k-1}\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-p_{k}\pi+q_{k}\right)$ where $p$ and $q$ form some kind of sequence of rational numbers. If we plot a graph of $p_{k}$ (purple) and $q_{k}$ (red) against $k$ , we get something that looks like a logarithm but is also not really: Whereas for $n=2k$ , $k$ $n$ $I(2k)$ $1$ $2$ $\frac{1}{4}\pi-\frac{1}{32}\pi^{2}-\frac{1}{2}\ln 2$ $2$ $4$ $-\left(\frac{1}{6}+\frac{1}{6}\pi-\frac{1}{32}\pi^{2}-\frac{2}{3}\ln2\right)$ $3$ $6$ $\frac{13}{60}+\frac{13}{60}\pi-\frac{1}{32}\pi^{2}-\frac{23}{30}\ln 2$ $4$ $8$ $-\left(\frac{29}{105}+\frac{19}{105}\pi-\frac{1}{32}\pi^{2}-\frac{88}{105}\ln2\right)$ $5$ $10$ $\frac{2333}{7560}+\frac{263}{1260}\pi-\frac{1}{32}\pi^{2}-\frac{563}{630}\ln 2$ The first thing I noticed was the denominator. If we make them the same each time, we get $k$ $n$ $I(2k)$ $1$ $2$ $\frac{1}{4}\pi-\frac{1}{32}\pi^{2}-\frac{2}{4}\ln 2$ $2$ $4$ $-\left(\frac{1}{6}+\frac{1}{6}\pi-\frac{1}{32}\pi^{2}-\frac{4}{6}\ln2\right)$ $3$ $6$ $\frac{13}{60}+\frac{13}{60}\pi-\frac{1}{32}\pi^{2}-\frac{46}{60}\ln 2$ $4$ $8$ $-\left(\frac{29}{105}+\frac{19}{105}\pi-\frac{1}{32}\pi^{2}-\frac{88}{105}\ln2\right)$ $5$ $10$ $\frac{2333}{7560}+\frac{1578}{7560}\pi-\frac{1}{32}\pi^{2}-\frac{6756}{7560}\ln 2$ Which indicates that $I(n)$ for even $n$ takes the form of $(-1)^{k-1}\left(-\frac{1}{32}\pi^{2}+\frac{1}{r_{k}}\left(a_{k}+b_{k}\pi-c_{k}\ln{2}\right)\right)$ where $r,a,b,c$ form a sequence in the natural numbers. Plotting $r$ (black), $b$ (blue) and $c$ (green) against $k$ yields these exponential graphs: But $a_{1}=0$ , and its graph (red) looks like this: Seems like they're in pairs, but I also fail to see any relation between the numbers at all. If we plot $\frac{a}{r},\frac{b}{r},\frac{c}{r}$ against $k$ , we get We see that $\frac{b}{r}$ approaches some value around $0.19$ . None of the number sequences mentioned above show up on OEIS. I have been stuck here for a few days, and any insight would be highly welcomed. Kisaragi Ayami","I've played around a little with this integral, and I can straightforwardly evaluate it with a substitution in terms of the Beta function if the bounds were . But for the bounds the substitution takes the bounds to which can't be done with the Beta function. Alternatively, if we substitute , we get that I'm wondering if there is a nice expression for this integral. Side note, I'm only actually interested in what it is for . Checking with Wolfram Alpha, it seems that the integral behaves slightly differently for odd and even . For , (where is Catalan's constant.) for odd takes the form of where and form some kind of sequence of rational numbers. If we plot a graph of (purple) and (red) against , we get something that looks like a logarithm but is also not really: Whereas for , The first thing I noticed was the denominator. If we make them the same each time, we get Which indicates that for even takes the form of where form a sequence in the natural numbers. Plotting (black), (blue) and (green) against yields these exponential graphs: But , and its graph (red) looks like this: Seems like they're in pairs, but I also fail to see any relation between the numbers at all. If we plot against , we get We see that approaches some value around . None of the number sequences mentioned above show up on OEIS. I have been stuck here for a few days, and any insight would be highly welcomed. Kisaragi Ayami","\tan x\mapsto x (0,\pi /2) (0,\pi /4) (0,1) \tan 2x \mapsto x I(n)=\frac{1}{4}\int\limits_{0}^{\infty}\frac{\left(\sqrt{x^{2}+1}-1\right)^{n}\tan^{-1}x}{x^{n}\left(1-x^{2}\right)}dx=\frac{1}{4}\int\limits_{0}^{\infty}\frac{x^{n}\tan^{-1}x}{\left(1-x^{2}\right)\left(\sqrt{x^{2}+1}+1\right)^{n}}dx n\geq1 n n=2k-1 k n I(2k-1) 1 1 \frac{1}{2}G-\frac{\pi}{8}\ln 2 2 3 -\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{4}\pi+\frac{1}{2}\right) 3 5 \frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{4}\pi+\frac{2}{3} 4 7 -\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{3}\pi+\frac{73}{90}\right) 5 9 \frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{1}{3}\pi+\frac{284}{315} 6 11 -\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{23}{60}\pi+\frac{3103}{3150}\right) 7 13 \frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{23}{60}\pi+\frac{54472}{51975} 9 15 -\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-\frac{44}{105}\pi+\frac{10459489}{9459450}\right) G I(n) n (-1)^{k-1}\left(\frac{1}{2}G-\frac{\pi}{8}\ln 2-p_{k}\pi+q_{k}\right) p q p_{k} q_{k} k n=2k k n I(2k) 1 2 \frac{1}{4}\pi-\frac{1}{32}\pi^{2}-\frac{1}{2}\ln 2 2 4 -\left(\frac{1}{6}+\frac{1}{6}\pi-\frac{1}{32}\pi^{2}-\frac{2}{3}\ln2\right) 3 6 \frac{13}{60}+\frac{13}{60}\pi-\frac{1}{32}\pi^{2}-\frac{23}{30}\ln 2 4 8 -\left(\frac{29}{105}+\frac{19}{105}\pi-\frac{1}{32}\pi^{2}-\frac{88}{105}\ln2\right) 5 10 \frac{2333}{7560}+\frac{263}{1260}\pi-\frac{1}{32}\pi^{2}-\frac{563}{630}\ln 2 k n I(2k) 1 2 \frac{1}{4}\pi-\frac{1}{32}\pi^{2}-\frac{2}{4}\ln 2 2 4 -\left(\frac{1}{6}+\frac{1}{6}\pi-\frac{1}{32}\pi^{2}-\frac{4}{6}\ln2\right) 3 6 \frac{13}{60}+\frac{13}{60}\pi-\frac{1}{32}\pi^{2}-\frac{46}{60}\ln 2 4 8 -\left(\frac{29}{105}+\frac{19}{105}\pi-\frac{1}{32}\pi^{2}-\frac{88}{105}\ln2\right) 5 10 \frac{2333}{7560}+\frac{1578}{7560}\pi-\frac{1}{32}\pi^{2}-\frac{6756}{7560}\ln 2 I(n) n (-1)^{k-1}\left(-\frac{1}{32}\pi^{2}+\frac{1}{r_{k}}\left(a_{k}+b_{k}\pi-c_{k}\ln{2}\right)\right) r,a,b,c r b c k a_{1}=0 \frac{a}{r},\frac{b}{r},\frac{c}{r} k \frac{b}{r} 0.19","['calculus', 'integration', 'definite-integrals', 'taylor-expansion', 'catalans-constant']"
68,The sum of $(-1)^n \frac{\ln n}{n}$,The sum of,(-1)^n \frac{\ln n}{n},"I'm stuck trying to show that $$\sum_{n=2}^{\infty} (-1)^n \frac{\ln n}{n}=\gamma \ln 2- \frac{1}{2}(\ln 2)^2$$ This is a problem in Calculus by Simmons. It's in the end of chapter review and it's associated with the section about the alternating series test. There's a hint: refer to an equation from a previous section on the integral test. Specifically: $$L=\lim_{n\to\infty} F(n)=\lim_{n\to\infty}\left[a_1+a_2+\cdots+a_n-\int_1^n\! f(x)\,\mathrm{d}x\right]$$ Here, $\{a_n\}$ is a decreasing sequence of positive numbers and $f(x)$ is a decreasing function such that $f(n)=a_n$, and $\gamma$ is this limit in the case that $a_n=\frac{ 1}{n}$. New users can't answer their own questions inside of 8 hours, so I'm editing my question to reflect the answer. Ok, I got it. Following the hint in the book $$L=\lim_{n\to\infty}\left[\frac{\ln 2}{2}+\frac{\ln 3}{3}+\cdots+\frac{\ln n}{n}-\int_2^n\! \frac{\ln x}{x}\,\mathrm{d}x\right]$$ $$=\lim\left[\frac{ \ln 2}{2}+\cdots+\frac{ \ln n}{n}-\left.\frac{ \ln^2x}{2}\right|_2^n\right]$$ The partial sum for the positive series is: $$\left(\frac{\ln^2n}{2}-\frac{\ln^2}{2}\right)+L+o(1)$$ Returning to the original, alternating series: $$-S_{2n}=\frac{ -\ln 2}{2}+\frac{ \ln 3}{3}-\frac{\ln 4}{4}+\frac{\ln 5}{5}-\cdots$$ $$=\frac{\ln 2}{2}+\frac{\ln 3}{3}+\cdots+\frac{\ln 2n}{2n}-2\left(\frac{\ln 2}{2}+\frac{\ln 4}{4}+\cdots+\frac{\ln 2n}{2n}\right)$$ Consider the partial sum in parentheses $$ \frac{\ln 2}{2}+\frac{\ln 4}{4}+\cdots+\frac{\ln 2n}{2n}=\frac{\ln 2}{2}+\frac{\ln 2 +\ln 2}{4}+\frac{\ln 2+\ln 3}{6}+\cdots+\frac{\ln 2+\ln n}{2n}$$ $$=\frac{1}{2}\left(\ln 2\left(1+\frac{ 1}{2}+\cdots+\frac{ 1}{n}\right)+\left(\frac{ \ln 2}{2}+\frac{ \ln 3}{3}+\cdots+\frac{ \ln n}{n}\right)\right)$$ Now, plug that back in $$-S_{2n}=\left(\frac{\ln 2}{2}+\cdots+\frac{ \ln 2n}{2n}\right)-\ln 2\left(1+\frac{ 1}{2}+\cdots+\frac{ 1}{n}\right)-\left(\frac{ \ln 2}{2}+\frac{ \ln 3}{3}+\cdots+\frac{ \ln n}{n}\right)$$ $$=\frac{ \ln^2(2n)}{2}-\frac{ \ln^2 2}{2}+L+o(1)-\ln 2\left(\ln n +\gamma+o(1)\right)-\left(\frac{ \ln^2 n}{2}-\frac{ \ln^2 2}{2}+L+o(1)\right)$$ $$=\frac{ (\ln 2 +\ln n)^2}{2}-(\ln 2)(\ln n)-\gamma\ln 2-\frac{ \ln^2 n}{2}+o(1)$$ $$=\frac{ \ln^2 2}{2}+(\ln 2)(\ln n)+\frac{ \ln^2 n}{2}-(\ln 2)(\ln n)-\gamma \ln 2 - \frac{ \ln^2 n}{2}+o(1)$$ $$-S_{2n}\to\frac{ \ln^2}{2}-\gamma\ln 2$$ Which gives the desired result $$\sum_2^{\infty}(-1)^n \frac{ \ln n}{n}=\gamma\ln 2 -\frac{ \ln^2 2}{2}$$","I'm stuck trying to show that $$\sum_{n=2}^{\infty} (-1)^n \frac{\ln n}{n}=\gamma \ln 2- \frac{1}{2}(\ln 2)^2$$ This is a problem in Calculus by Simmons. It's in the end of chapter review and it's associated with the section about the alternating series test. There's a hint: refer to an equation from a previous section on the integral test. Specifically: $$L=\lim_{n\to\infty} F(n)=\lim_{n\to\infty}\left[a_1+a_2+\cdots+a_n-\int_1^n\! f(x)\,\mathrm{d}x\right]$$ Here, $\{a_n\}$ is a decreasing sequence of positive numbers and $f(x)$ is a decreasing function such that $f(n)=a_n$, and $\gamma$ is this limit in the case that $a_n=\frac{ 1}{n}$. New users can't answer their own questions inside of 8 hours, so I'm editing my question to reflect the answer. Ok, I got it. Following the hint in the book $$L=\lim_{n\to\infty}\left[\frac{\ln 2}{2}+\frac{\ln 3}{3}+\cdots+\frac{\ln n}{n}-\int_2^n\! \frac{\ln x}{x}\,\mathrm{d}x\right]$$ $$=\lim\left[\frac{ \ln 2}{2}+\cdots+\frac{ \ln n}{n}-\left.\frac{ \ln^2x}{2}\right|_2^n\right]$$ The partial sum for the positive series is: $$\left(\frac{\ln^2n}{2}-\frac{\ln^2}{2}\right)+L+o(1)$$ Returning to the original, alternating series: $$-S_{2n}=\frac{ -\ln 2}{2}+\frac{ \ln 3}{3}-\frac{\ln 4}{4}+\frac{\ln 5}{5}-\cdots$$ $$=\frac{\ln 2}{2}+\frac{\ln 3}{3}+\cdots+\frac{\ln 2n}{2n}-2\left(\frac{\ln 2}{2}+\frac{\ln 4}{4}+\cdots+\frac{\ln 2n}{2n}\right)$$ Consider the partial sum in parentheses $$ \frac{\ln 2}{2}+\frac{\ln 4}{4}+\cdots+\frac{\ln 2n}{2n}=\frac{\ln 2}{2}+\frac{\ln 2 +\ln 2}{4}+\frac{\ln 2+\ln 3}{6}+\cdots+\frac{\ln 2+\ln n}{2n}$$ $$=\frac{1}{2}\left(\ln 2\left(1+\frac{ 1}{2}+\cdots+\frac{ 1}{n}\right)+\left(\frac{ \ln 2}{2}+\frac{ \ln 3}{3}+\cdots+\frac{ \ln n}{n}\right)\right)$$ Now, plug that back in $$-S_{2n}=\left(\frac{\ln 2}{2}+\cdots+\frac{ \ln 2n}{2n}\right)-\ln 2\left(1+\frac{ 1}{2}+\cdots+\frac{ 1}{n}\right)-\left(\frac{ \ln 2}{2}+\frac{ \ln 3}{3}+\cdots+\frac{ \ln n}{n}\right)$$ $$=\frac{ \ln^2(2n)}{2}-\frac{ \ln^2 2}{2}+L+o(1)-\ln 2\left(\ln n +\gamma+o(1)\right)-\left(\frac{ \ln^2 n}{2}-\frac{ \ln^2 2}{2}+L+o(1)\right)$$ $$=\frac{ (\ln 2 +\ln n)^2}{2}-(\ln 2)(\ln n)-\gamma\ln 2-\frac{ \ln^2 n}{2}+o(1)$$ $$=\frac{ \ln^2 2}{2}+(\ln 2)(\ln n)+\frac{ \ln^2 n}{2}-(\ln 2)(\ln n)-\gamma \ln 2 - \frac{ \ln^2 n}{2}+o(1)$$ $$-S_{2n}\to\frac{ \ln^2}{2}-\gamma\ln 2$$ Which gives the desired result $$\sum_2^{\infty}(-1)^n \frac{ \ln n}{n}=\gamma\ln 2 -\frac{ \ln^2 2}{2}$$",,"['calculus', 'sequences-and-series', 'stieltjes-constants']"
69,What did Newton and Leibniz actually discover?,What did Newton and Leibniz actually discover?,,Most popular sources credit Newton and Leibniz with the creation and the discovery of calculus. However there are many things that are normally regarded as a part of calculus (such as the notion of a limit with its $\epsilon$-$\delta$ definition) that seem to have been developed only much later (in this case in the late $18$th and early $19$th century). Hence the question - what is it that Newton and Leibniz discovered?,Most popular sources credit Newton and Leibniz with the creation and the discovery of calculus. However there are many things that are normally regarded as a part of calculus (such as the notion of a limit with its $\epsilon$-$\delta$ definition) that seem to have been developed only much later (in this case in the late $18$th and early $19$th century). Hence the question - what is it that Newton and Leibniz discovered?,,"['calculus', 'reference-request', 'math-history']"
70,suggest textbook on calculus,suggest textbook on calculus,,"I read single variable calculus this semester, and the course is using Thomas Calculus as the textbook. But this book is just too huge, a single chapter contains 100 exercise questions! Now I'm looking for a concise and complete textbook. I'm not interested in routine, computational exercises, but rather some challenging problem sets. I have quite a strong basic knowledge of calculus from high school, but I still have difficulties in solving a few questions from past exam papers. So I'm looking for more challenging exercises. In fact, I'm looking forward to solving Putnam level questions. Please suggest some textbooks with these features. Thanks in advance.","I read single variable calculus this semester, and the course is using Thomas Calculus as the textbook. But this book is just too huge, a single chapter contains 100 exercise questions! Now I'm looking for a concise and complete textbook. I'm not interested in routine, computational exercises, but rather some challenging problem sets. I have quite a strong basic knowledge of calculus from high school, but I still have difficulties in solving a few questions from past exam papers. So I'm looking for more challenging exercises. In fact, I'm looking forward to solving Putnam level questions. Please suggest some textbooks with these features. Thanks in advance.",,"['calculus', 'reference-request', 'book-recommendation']"
71,"Show that $\frac{x^3}{x^2+y^2}$ is not differentiable at $(0,0)$, even though all directional derivatives exist","Show that  is not differentiable at , even though all directional derivatives exist","\frac{x^3}{x^2+y^2} (0,0)","Consider the function : $$f: \mathbb{R}^2 \rightarrow \mathbb{R} , (x,y) \mapsto   \begin{cases}         0 & \text{for } (x,y)=(0,0) \\    \frac{x^3}{x^2+y^2}       & \text{for } (x,y) \neq (0,0)   \end{cases} $$ Show that $f$ not differentiable at $(0,0)$ but all directional derivatives exist. I don't know how to tackle this problem. Can someone give some hints or solve the problem? Thanks :)","Consider the function : $$f: \mathbb{R}^2 \rightarrow \mathbb{R} , (x,y) \mapsto   \begin{cases}         0 & \text{for } (x,y)=(0,0) \\    \frac{x^3}{x^2+y^2}       & \text{for } (x,y) \neq (0,0)   \end{cases} $$ Show that $f$ not differentiable at $(0,0)$ but all directional derivatives exist. I don't know how to tackle this problem. Can someone give some hints or solve the problem? Thanks :)",,"['calculus', 'analysis', 'derivatives']"
72,A limit wrong using Wolfram Alpha,A limit wrong using Wolfram Alpha,,"I want to calculate the following limit: $$\displaystyle{\lim_{x \to 0} \cfrac{\displaystyle{\int_1^{x^2+1} \cfrac{e^{-t}}{t} \; dt}}{3x^2}}$$ For that, I use L'Hopital and the Fundamental Theorem of Calculus, obtaining the following: $$\displaystyle{\lim_{x \to 0} \cfrac{\displaystyle{\int_1^{x^2+1} \cfrac{e^{-t}}{t} \; dt}}{3x^2}}=\displaystyle{\lim_{x \to 0} \cfrac{\frac{e^{-(x^2+1)}}{x^2+1} \cdot 2x}{6x}}=\lim_{x \to 0} \cfrac{e^{-(x^2+1)}}{3(x^2+1)}=\cfrac{e^{-1}}{3}$$ But if I calculate the limit in Wolfram Alpha, I get the following. I calculated the limit also in Mathematica 8.0, and the result is still the same: $\frac 13(\frac 1e-1) $ So, what is my mistake calculating the limit?","I want to calculate the following limit: $$\displaystyle{\lim_{x \to 0} \cfrac{\displaystyle{\int_1^{x^2+1} \cfrac{e^{-t}}{t} \; dt}}{3x^2}}$$ For that, I use L'Hopital and the Fundamental Theorem of Calculus, obtaining the following: $$\displaystyle{\lim_{x \to 0} \cfrac{\displaystyle{\int_1^{x^2+1} \cfrac{e^{-t}}{t} \; dt}}{3x^2}}=\displaystyle{\lim_{x \to 0} \cfrac{\frac{e^{-(x^2+1)}}{x^2+1} \cdot 2x}{6x}}=\lim_{x \to 0} \cfrac{e^{-(x^2+1)}}{3(x^2+1)}=\cfrac{e^{-1}}{3}$$ But if I calculate the limit in Wolfram Alpha, I get the following. I calculated the limit also in Mathematica 8.0, and the result is still the same: $\frac 13(\frac 1e-1) $ So, what is my mistake calculating the limit?",,"['calculus', 'wolfram-alpha']"
73,An awful identity,An awful identity,,"We take place on $\mathbb C(x_1,...,x_r,x'_1,...,x'_p,u_0,...,u_r,u'_0,...,u'_p)$ with $r,p\in \mathbb N$ Show that :   $$\displaystyle{\sum_{i=1}^r \left(   \frac{\prod_{j=0}^r (u_j-x_i) \prod_{j=1}^p (x'_j-x_i) }{  \prod_{1\leq j\leq r, j\neq i     }(x_j-x_i) \prod_{j=0}^p (u'_j-x_i)}      \right)}-\displaystyle{\sum_{i=0}^p \left(   \frac{\prod_{j=0}^r (u'_i-u_j) \prod_{j=1}^p (u'_i-x'_j) }{  \prod_{0\leq j\leq p, j\neq i     }(u'_i-u'_j) \prod_{j=1}^r (u'_i-x_j)}      \right)}=\displaystyle{\sum_{i=1}^p x'_i +\sum_{i=0}^r u_i -\sum_{i=1}^r x_i-\sum_{i=0}^p u'_i}$$ I have seen this exercise in an old book at the library. Unfortunately there was no indication how can I solve the problem. Anyway if someone can give me some ideas it will be greatful. NB: Sorry for the title, I have not had other ideas","We take place on $\mathbb C(x_1,...,x_r,x'_1,...,x'_p,u_0,...,u_r,u'_0,...,u'_p)$ with $r,p\in \mathbb N$ Show that :   $$\displaystyle{\sum_{i=1}^r \left(   \frac{\prod_{j=0}^r (u_j-x_i) \prod_{j=1}^p (x'_j-x_i) }{  \prod_{1\leq j\leq r, j\neq i     }(x_j-x_i) \prod_{j=0}^p (u'_j-x_i)}      \right)}-\displaystyle{\sum_{i=0}^p \left(   \frac{\prod_{j=0}^r (u'_i-u_j) \prod_{j=1}^p (u'_i-x'_j) }{  \prod_{0\leq j\leq p, j\neq i     }(u'_i-u'_j) \prod_{j=1}^r (u'_i-x_j)}      \right)}=\displaystyle{\sum_{i=1}^p x'_i +\sum_{i=0}^r u_i -\sum_{i=1}^r x_i-\sum_{i=0}^p u'_i}$$ I have seen this exercise in an old book at the library. Unfortunately there was no indication how can I solve the problem. Anyway if someone can give me some ideas it will be greatful. NB: Sorry for the title, I have not had other ideas",,"['calculus', 'analysis', 'polynomials']"
74,A curious coincidence: $\prod\limits_{k=1}^\infty\left(1+\int_{k}^{k+1}\left(\frac{\sin (\pi x)}{x}\right)^2\mathrm dx\right)\overset{?}{=}\pi/2$,A curious coincidence:,\prod\limits_{k=1}^\infty\left(1+\int_{k}^{k+1}\left(\frac{\sin (\pi x)}{x}\right)^2\mathrm dx\right)\overset{?}{=}\pi/2,It is known that $\int_0^\infty \frac{\sin x}{x} \mathrm dx=\dfrac{\pi}{2}$ ( proof ) and $\int_0^\infty\left(\frac{\sin x}{x}\right)^2\mathrm dx=\dfrac{\pi}{2}$ ( proof ). Numerical investigation suggests that we also have: $$\prod\limits_{k=1}^\infty\left(1+\int_{k}^{k+1}\left(\frac{\sin (\pi x)}{x}\right)^2\mathrm dx\right)=\dfrac{\pi}{2}$$ But I do not know how to prove this. $\int\left(\frac{\sin (\pi x)}{x}\right)^2\mathrm dx$ cannot be expressed in terms of elementary functions. Is this infinite product really equal to $\dfrac{\pi}{2}$ ?,It is known that ( proof ) and ( proof ). Numerical investigation suggests that we also have: But I do not know how to prove this. cannot be expressed in terms of elementary functions. Is this infinite product really equal to ?,\int_0^\infty \frac{\sin x}{x} \mathrm dx=\dfrac{\pi}{2} \int_0^\infty\left(\frac{\sin x}{x}\right)^2\mathrm dx=\dfrac{\pi}{2} \prod\limits_{k=1}^\infty\left(1+\int_{k}^{k+1}\left(\frac{\sin (\pi x)}{x}\right)^2\mathrm dx\right)=\dfrac{\pi}{2} \int\left(\frac{\sin (\pi x)}{x}\right)^2\mathrm dx \dfrac{\pi}{2},"['calculus', 'integration', 'trigonometry', 'infinite-product', 'conjectures']"
75,Is $K\left(\frac{\sqrt{2-\sqrt3}}2\right)\stackrel?=\frac{\Gamma\left(\frac16\right)\Gamma\left(\frac13\right)}{4\ \sqrt[4]3\ \sqrt\pi}$,Is,K\left(\frac{\sqrt{2-\sqrt3}}2\right)\stackrel?=\frac{\Gamma\left(\frac16\right)\Gamma\left(\frac13\right)}{4\ \sqrt[4]3\ \sqrt\pi},"Working on this conjecture , I found its corollary, which is also supported by numeric calculations up to at least $10^5$ decimal digits: $$K\left(\frac{\sqrt{2-\sqrt3}}2\right)\stackrel?=\frac{\Gamma\left(\frac16\right)\Gamma\left(\frac13\right)}{4\ \sqrt[4]3\ \sqrt\pi},$$ where $K(x)$ is the complete elliptic integral of the 1st kind . I did not find this specific value at MathWorld , Wolfram Functions Site , Wikipedia or DLMF . Is it a known value?","Working on this conjecture , I found its corollary, which is also supported by numeric calculations up to at least $10^5$ decimal digits: $$K\left(\frac{\sqrt{2-\sqrt3}}2\right)\stackrel?=\frac{\Gamma\left(\frac16\right)\Gamma\left(\frac13\right)}{4\ \sqrt[4]3\ \sqrt\pi},$$ where $K(x)$ is the complete elliptic integral of the 1st kind . I did not find this specific value at MathWorld , Wolfram Functions Site , Wikipedia or DLMF . Is it a known value?",,"['calculus', 'special-functions', 'gamma-function', 'closed-form', 'conjectures']"
76,Find $\lim_{n\to\infty}\sqrt{6}^{\ n}\underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\dotsb+\sqrt{6}}}}}_{n\text{ square root signs}}$,Find,\lim_{n\to\infty}\sqrt{6}^{\ n}\underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\dotsb+\sqrt{6}}}}}_{n\text{ square root signs}},"We have the following representation of pi: $$\pi=\lim_{n\to\infty}2^n \underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\dotsb+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2}}}}}}}}}}_{n\text{ square root signs}}$$ which can be proven using the identity $\sin\left(\dfrac\pi{2^{n+1}}\right)=\dfrac12\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dotsb+\sqrt{2}}}}}_{n\text{ square root signs}}$. (There's similar one for $\cos$, except without the minus sign.) This made me wonder: Is there a closed form for: $$\lim_{n\to\infty}3^n \underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6+\dotsb+\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6}}}}}}}}}}_{n\text{ square root signs}}$$ (Note that $\sqrt{6+\sqrt{6+\sqrt{\dots}}}=3$, so this question is of the form $\infty\times0$.) EDIT: It seems like that doesn't converge, but this does: $$\lim_{n\to\infty}\sqrt{6}^{\ n}\underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6+\dotsb+\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6}}}}}}}}}}_{n\text{ square root signs}}\approx4.49377$$","We have the following representation of pi: $$\pi=\lim_{n\to\infty}2^n \underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\dotsb+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2}}}}}}}}}}_{n\text{ square root signs}}$$ which can be proven using the identity $\sin\left(\dfrac\pi{2^{n+1}}\right)=\dfrac12\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dotsb+\sqrt{2}}}}}_{n\text{ square root signs}}$. (There's similar one for $\cos$, except without the minus sign.) This made me wonder: Is there a closed form for: $$\lim_{n\to\infty}3^n \underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6+\dotsb+\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6}}}}}}}}}}_{n\text{ square root signs}}$$ (Note that $\sqrt{6+\sqrt{6+\sqrt{\dots}}}=3$, so this question is of the form $\infty\times0$.) EDIT: It seems like that doesn't converge, but this does: $$\lim_{n\to\infty}\sqrt{6}^{\ n}\underbrace{\sqrt{3-\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6+\dotsb+\sqrt{6+\sqrt{6+\sqrt{6+\sqrt{6}}}}}}}}}}_{n\text{ square root signs}}\approx4.49377$$",,"['calculus', 'limits', 'arithmetic', 'pi']"
77,Prove $\int_0^{\pi/2}{\frac{1+2\cos 2x\cdot\ln\tan x}{1+\tan^{2\sqrt{2}} x}}\tan^{1/\sqrt{2}} x~dx=0$,Prove,\int_0^{\pi/2}{\frac{1+2\cos 2x\cdot\ln\tan x}{1+\tan^{2\sqrt{2}} x}}\tan^{1/\sqrt{2}} x~dx=0,"I'm curious, how one can prove the following integral $$ \int_0^{\pi/2}{\frac{1+2\cos 2x\cdot\ln\tan x}{1+\tan^{2\sqrt{2}} x}}\tan^{1/\sqrt{2}} x~dx=0 $$ Here is the Wolfram Alpha computation which shows that it is correct to at least 45 digits. My attempt: I knew the integral $$ \int_0^{\pi/2}\frac{1}{1+\tan^\alpha\phi}d\phi=\int_0^{\pi/4}\frac{1}{1+\tan^\alpha\phi}d\phi+\int_0^{\pi/4}\frac{\tan^\alpha\phi}{1+\tan^\alpha\phi}d\phi=\frac{\pi}{4} $$ which can be calculated for all values of $\alpha$. I tried to find an analogous symmetry that will allow me to cancel all the terms also in this case, but so far no luck. I also suspect that this integral might be related to derivative of Herglotz integral . Herglotz showed that  $$ \int_{0}^{1} \frac{\ln\left(1 + t^{\,{\large\alpha}}\right)}{1 + t}\,{\rm d}t $$ can be computed for some algebraic values of $\alpha$, e.g. $\alpha=4+\sqrt{5}$. If we take derivative of this integral with respect to $\alpha$ then we get $$ \int_{0}^{1} \frac{t^\alpha\ln t}{(1 + t)(1+t^\alpha)}\,{\rm d}t $$ Change of variables $t=\tan^2\phi$ gives $$ 4\int_{0}^{\pi/4} \frac{\tan^{2\alpha+1}\phi\cdot\ln \tan\phi}{1+\tan^{2\alpha}\phi}\,{\rm d}\phi $$ which looks quite similar to the integral under consideration.","I'm curious, how one can prove the following integral $$ \int_0^{\pi/2}{\frac{1+2\cos 2x\cdot\ln\tan x}{1+\tan^{2\sqrt{2}} x}}\tan^{1/\sqrt{2}} x~dx=0 $$ Here is the Wolfram Alpha computation which shows that it is correct to at least 45 digits. My attempt: I knew the integral $$ \int_0^{\pi/2}\frac{1}{1+\tan^\alpha\phi}d\phi=\int_0^{\pi/4}\frac{1}{1+\tan^\alpha\phi}d\phi+\int_0^{\pi/4}\frac{\tan^\alpha\phi}{1+\tan^\alpha\phi}d\phi=\frac{\pi}{4} $$ which can be calculated for all values of $\alpha$. I tried to find an analogous symmetry that will allow me to cancel all the terms also in this case, but so far no luck. I also suspect that this integral might be related to derivative of Herglotz integral . Herglotz showed that  $$ \int_{0}^{1} \frac{\ln\left(1 + t^{\,{\large\alpha}}\right)}{1 + t}\,{\rm d}t $$ can be computed for some algebraic values of $\alpha$, e.g. $\alpha=4+\sqrt{5}$. If we take derivative of this integral with respect to $\alpha$ then we get $$ \int_{0}^{1} \frac{t^\alpha\ln t}{(1 + t)(1+t^\alpha)}\,{\rm d}t $$ Change of variables $t=\tan^2\phi$ gives $$ 4\int_{0}^{\pi/4} \frac{\tan^{2\alpha+1}\phi\cdot\ln \tan\phi}{1+\tan^{2\alpha}\phi}\,{\rm d}\phi $$ which looks quite similar to the integral under consideration.",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
78,Show that $(\sqrt{y^2-x}-x)(\sqrt{x^2+y}-y)=y \iff x+y=0$,Show that,(\sqrt{y^2-x}-x)(\sqrt{x^2+y}-y)=y \iff x+y=0,"Let $x,y$ be real numbers such that   $$\left(\sqrt{y^{2} - x\,\,}\, - x\right)\left(\sqrt{x^{2} + y\,\,}\, - y\right)=y$$   Show that $x+y=0$. My try: Let $$\sqrt{y^2-x}-x=a,\sqrt{x^2+y}-y=b\Longrightarrow ab=y$$ and then $$\begin{cases} y^2=a^2+(2a+1)x+x^2\cdots\cdots (1)\\ x^2=b^2+(2b-1)y+y^2\cdots\cdots \end{cases}$$ $(1)+(2)$ then $$x=-\dfrac{a^2+b^2+(2b-1)ab}{2a+1}\cdots\cdots (3)$$ so $$x+y=ab-\dfrac{a^2+b^2+(2b-1)ab}{2a+1}=\dfrac{(a-b)(2ab-a+b)}{2a+1}$$ we take $(3)$ in $(2)$,we have $$b^2+(2b-1)y+y^2-x^2=\dfrac{(2ab-a+b)(2a^3b+a^3+3a^2b-2ab^3+ab^2+4ab-b^3+b)}{(2a+1)^2}=0$$ so $$(2ab-a+b)=0$$ or $$2a^3b+a^3+3a^2b-2ab^3+ab^2+4ab-b^3+b=0$$ if $$2ab-a+b=0\Longrightarrow x+y=\dfrac{(a-b)(2ab-a+b)}{2a+1}=0$$ and if $$2a^3b+a^3+3a^2b-2ab^3+ab^2+4ab-b^3+b=0$$ I don't prove $$x+y=\dfrac{(a-b)(2ab-a+b)}{2a+1}=0?$$","Let $x,y$ be real numbers such that   $$\left(\sqrt{y^{2} - x\,\,}\, - x\right)\left(\sqrt{x^{2} + y\,\,}\, - y\right)=y$$   Show that $x+y=0$. My try: Let $$\sqrt{y^2-x}-x=a,\sqrt{x^2+y}-y=b\Longrightarrow ab=y$$ and then $$\begin{cases} y^2=a^2+(2a+1)x+x^2\cdots\cdots (1)\\ x^2=b^2+(2b-1)y+y^2\cdots\cdots \end{cases}$$ $(1)+(2)$ then $$x=-\dfrac{a^2+b^2+(2b-1)ab}{2a+1}\cdots\cdots (3)$$ so $$x+y=ab-\dfrac{a^2+b^2+(2b-1)ab}{2a+1}=\dfrac{(a-b)(2ab-a+b)}{2a+1}$$ we take $(3)$ in $(2)$,we have $$b^2+(2b-1)y+y^2-x^2=\dfrac{(2ab-a+b)(2a^3b+a^3+3a^2b-2ab^3+ab^2+4ab-b^3+b)}{(2a+1)^2}=0$$ so $$(2ab-a+b)=0$$ or $$2a^3b+a^3+3a^2b-2ab^3+ab^2+4ab-b^3+b=0$$ if $$2ab-a+b=0\Longrightarrow x+y=\dfrac{(a-b)(2ab-a+b)}{2a+1}=0$$ and if $$2a^3b+a^3+3a^2b-2ab^3+ab^2+4ab-b^3+b=0$$ I don't prove $$x+y=\dfrac{(a-b)(2ab-a+b)}{2a+1}=0?$$",,"['calculus', 'algebra-precalculus', 'arithmetic', 'radicals']"
79,"Simplify $\frac{_3F_2\left(\frac{1}{2},\frac{3}{4},\frac{5}{4};1,\frac{3}{2};\frac{3}{4}\right)}{\Pi\left(\frac{1}{4}\big|\frac{1}{\sqrt{3}}\right)}$",Simplify,"\frac{_3F_2\left(\frac{1}{2},\frac{3}{4},\frac{5}{4};1,\frac{3}{2};\frac{3}{4}\right)}{\Pi\left(\frac{1}{4}\big|\frac{1}{\sqrt{3}}\right)}","Is it possible to simplify the ratio $$\mathcal{E}=\frac{_3F_2\left(\frac{1}{2},\frac{3}{4},\frac{5}{4};\ 1,\frac{3}{2};\ \frac{3}{4}\right)}{\Pi\left(\frac{1}{4}\Big|\frac{1}{\sqrt{3}}\right)},$$ where $\Pi(n|k)$ is the complete elliptic integral of the third kind ? Its numeric value is approximately $\mathcal{E}\approx0.73510519389572273268...$, that looks like $\frac{4}{\pi\sqrt{3}}$.","Is it possible to simplify the ratio $$\mathcal{E}=\frac{_3F_2\left(\frac{1}{2},\frac{3}{4},\frac{5}{4};\ 1,\frac{3}{2};\ \frac{3}{4}\right)}{\Pi\left(\frac{1}{4}\Big|\frac{1}{\sqrt{3}}\right)},$$ where $\Pi(n|k)$ is the complete elliptic integral of the third kind ? Its numeric value is approximately $\mathcal{E}\approx0.73510519389572273268...$, that looks like $\frac{4}{\pi\sqrt{3}}$.",,"['calculus', 'closed-form', 'conjectures', 'hypergeometric-function', 'elliptic-integrals']"
80,A question about series with a strange property.,A question about series with a strange property.,,"Does there exist a sequence $\left(a_n\right)_{n\ge1}$ with $a_n < a_{n+1}+a_{n^2}, \forall n=1,2,3,\ldots$ such that the series $\displaystyle{\sum_{n=1}^{\infty}a_n}$ converges? This is the first part of this question which has an (accepted) answer for its second part only: The last sentence of the answer is: ""Now we note that $\sum_{i=1}^{\infty}a_i\geq\sum_{k=0}^{\infty}\sum_{i\in J_k}a_i>\sum_{k=0}^{\infty}a_n$, so the sum diverges."" For the inequality $\sum_{i=1}^{\infty}a_i\geq\sum_{k=0}^{\infty}\sum_{i\in J_k}a_i$ to be valid, we have to assume the positivity of $(a_n)_{n\in\mathbb N}$ since $\displaystyle{\bigcup_{k\in\mathbb N}J_k\neq\mathbb N}$. According to the comments the first part is a difficult question.","Does there exist a sequence $\left(a_n\right)_{n\ge1}$ with $a_n < a_{n+1}+a_{n^2}, \forall n=1,2,3,\ldots$ such that the series $\displaystyle{\sum_{n=1}^{\infty}a_n}$ converges? This is the first part of this question which has an (accepted) answer for its second part only: The last sentence of the answer is: ""Now we note that $\sum_{i=1}^{\infty}a_i\geq\sum_{k=0}^{\infty}\sum_{i\in J_k}a_i>\sum_{k=0}^{\infty}a_n$, so the sum diverges."" For the inequality $\sum_{i=1}^{\infty}a_i\geq\sum_{k=0}^{\infty}\sum_{i\in J_k}a_i$ to be valid, we have to assume the positivity of $(a_n)_{n\in\mathbb N}$ since $\displaystyle{\bigcup_{k\in\mathbb N}J_k\neq\mathbb N}$. According to the comments the first part is a difficult question.",,"['calculus', 'sequences-and-series', 'analysis', 'contest-math']"
81,Evaluate $\int (1-x^{2008})^{\frac{1}{2007}} (1-x^{2007})^{\frac{1}{2008}} dx$,Evaluate,\int (1-x^{2008})^{\frac{1}{2007}} (1-x^{2007})^{\frac{1}{2008}} dx,Evaluate the given integral $$\int (1-x^{2008})^{\frac{1}{2007}} (1-x^{2007})^{\frac{1}{2008}} dx$$ Using integration by parts is out of equation because we can't integrate any of two brackets. I also cannot think of any substitution that can lead to integration. Could someone help me with this?,Evaluate the given integral $$\int (1-x^{2008})^{\frac{1}{2007}} (1-x^{2007})^{\frac{1}{2008}} dx$$ Using integration by parts is out of equation because we can't integrate any of two brackets. I also cannot think of any substitution that can lead to integration. Could someone help me with this?,,"['calculus', 'integration', 'indefinite-integrals']"
82,"Closed form for this integral $\int_{0}^{\infty}\frac{dx}{\sqrt{x}}\, e^{-x^{2}-\frac{b^{2}}{x}}$",Closed form for this integral,"\int_{0}^{\infty}\frac{dx}{\sqrt{x}}\, e^{-x^{2}-\frac{b^{2}}{x}}","How would you evaluate this integral? \begin{equation}\int_{0}^{\infty}\frac{dx}{\sqrt{x}}\, e^{-x^{2}-\frac{b^{2}}{x}}\end{equation} It reminds me of the form of a modified Bessel function of the second kind, but is slightly different because of the $x^{2}$ term. I can series expand it in terms of a sum of Gamma functions, but I don't know what that sum converges to.","How would you evaluate this integral? \begin{equation}\int_{0}^{\infty}\frac{dx}{\sqrt{x}}\, e^{-x^{2}-\frac{b^{2}}{x}}\end{equation} It reminds me of the form of a modified Bessel function of the second kind, but is slightly different because of the $x^{2}$ term. I can series expand it in terms of a sum of Gamma functions, but I don't know what that sum converges to.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
83,What is an intuitive approach to solving $\lim_{n\rightarrow\infty}\biggl(\frac{1}{n^2} + \frac{2}{n^2} + \frac{3}{n^2}+\dots+\frac{n}{n^2}\biggr)$?,What is an intuitive approach to solving ?,\lim_{n\rightarrow\infty}\biggl(\frac{1}{n^2} + \frac{2}{n^2} + \frac{3}{n^2}+\dots+\frac{n}{n^2}\biggr),"$$\lim_{n\rightarrow\infty}\biggl(\frac{1}{n^2} + \frac{2}{n^2} + \frac{3}{n^2}+\dots+\frac{n}{n^2}\biggr)$$ I managed to get the answer as $1$ by standard methods of solving, learned from teachers, but my intuition says that the denominator of every term grows much faster than the numerator so limit must equal to zero. Where is my mistake? Please explain very intuitively.","$$\lim_{n\rightarrow\infty}\biggl(\frac{1}{n^2} + \frac{2}{n^2} + \frac{3}{n^2}+\dots+\frac{n}{n^2}\biggr)$$ I managed to get the answer as $1$ by standard methods of solving, learned from teachers, but my intuition says that the denominator of every term grows much faster than the numerator so limit must equal to zero. Where is my mistake? Please explain very intuitively.",,"['calculus', 'algebra-precalculus', 'limits', 'limits-without-lhopital']"
84,Why does a distance and its square reach their minimum at the same point?,Why does a distance and its square reach their minimum at the same point?,,"There is a question in my calculus textbook that asks to find a point on the parabola $y^2 = 2x$ that is closest to point $(1,4)$. They want us to first use the distance formula, but then proceeded to square it leaving us with $d^2 = (y^2/2 - 1)^2 + (y-4)^2$. I am following the math up to this point, where I get lost is when the textbook states ""You should convince yourself that the minimum of $d^2$ occurs at the same point as the minimum of $d$, but $d^2$ is easier to work with"" . I don't understand how that can be true at all, $d$ is a distance between a fixed point and another point on the graph $y^2 = 2x$. $d^2$ must be that distance scaled by itself, how can the minimum be the same then? I've worked out the math for $d$ and $d^2$ and I do get the same point but I don't understand why.","There is a question in my calculus textbook that asks to find a point on the parabola $y^2 = 2x$ that is closest to point $(1,4)$. They want us to first use the distance formula, but then proceeded to square it leaving us with $d^2 = (y^2/2 - 1)^2 + (y-4)^2$. I am following the math up to this point, where I get lost is when the textbook states ""You should convince yourself that the minimum of $d^2$ occurs at the same point as the minimum of $d$, but $d^2$ is easier to work with"" . I don't understand how that can be true at all, $d$ is a distance between a fixed point and another point on the graph $y^2 = 2x$. $d^2$ must be that distance scaled by itself, how can the minimum be the same then? I've worked out the math for $d$ and $d^2$ and I do get the same point but I don't understand why.",,"['calculus', 'multivariable-calculus', 'optimization']"
85,How to show that $f(x)=x^2$ is continuous at $x=1$? [closed],How to show that  is continuous at ? [closed],f(x)=x^2 x=1,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How to show that $f(x)=x^2$ is continuous at $x=1$?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How to show that $f(x)=x^2$ is continuous at $x=1$?",,['calculus']
86,Help with $\int _0^{\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x$,Help with,\int _0^{\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x,"I want to know how to prove that $$\int _0^{+\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x=\frac{4G}{\pi }$$ Here $G$ denotes Catalan's constant, I obtained such result with the help of mathematica. I also found that the integral equals a certain infinite series $$\int _0^{+\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x=\sum _{n=0}^{+\infty }\frac{\binom{2n}{n}^2}{16^n\left(2n+1\right)}=\frac{4G}{\pi }$$ which can also be found in this link . So I've $2$ questions $1)$$¿$ How can we transform the integral into the mentioned series? $2)$$¿$ Is there a simple way to evaluate the main integral without resorting to series expansion? What I did for question $\#2$ is to employ the substitution $x=\ln\left(t\right)$ $$\int _0^{+\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x=-2\int _1^{\infty }\frac{1-t^2}{\ln \left(t\right)\left(1+t^2\right)^2}\:\mathrm{d}t$$ But I'm not sure how to proceed.","I want to know how to prove that Here denotes Catalan's constant, I obtained such result with the help of mathematica. I also found that the integral equals a certain infinite series which can also be found in this link . So I've questions How can we transform the integral into the mentioned series? Is there a simple way to evaluate the main integral without resorting to series expansion? What I did for question is to employ the substitution But I'm not sure how to proceed.",\int _0^{+\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x=\frac{4G}{\pi } G \int _0^{+\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x=\sum _{n=0}^{+\infty }\frac{\binom{2n}{n}^2}{16^n\left(2n+1\right)}=\frac{4G}{\pi } 2 1)¿ 2)¿ \#2 x=\ln\left(t\right) \int _0^{+\infty }\frac{\sinh \left(x\right)}{x\cosh ^2\left(x\right)}\:\mathrm{d}x=-2\int _1^{\infty }\frac{1-t^2}{\ln \left(t\right)\left(1+t^2\right)^2}\:\mathrm{d}t,"['calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
87,Do inequalities hold under differentiation?,Do inequalities hold under differentiation?,,"If I have the inequality $f \leq g$, does this imply $f'\leq g'$? The reason I am asking is because I am using this fact to prove a question with Taylor theorem.","If I have the inequality $f \leq g$, does this imply $f'\leq g'$? The reason I am asking is because I am using this fact to prove a question with Taylor theorem.",,"['calculus', 'derivatives', 'inequality']"
88,Integrate $\int \frac{1}{a + \cos x} dx$,Integrate,\int \frac{1}{a + \cos x} dx,"How do you integrate $$\int \frac{1}{a + \cos x} dx$$ Is it solvable by elementary methods? I was trying to do it while incorrectly solving a homework problem. But, I couldn't find the answer. Thanks!","How do you integrate Is it solvable by elementary methods? I was trying to do it while incorrectly solving a homework problem. But, I couldn't find the answer. Thanks!",\int \frac{1}{a + \cos x} dx,"['calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
89,Efficiently evaluating $\int x^{4}e^{-x}dx$ [duplicate],Efficiently evaluating  [duplicate],\int x^{4}e^{-x}dx,This question already has answers here : How to integrate $ \int x^n e^x dx$? (4 answers) Closed 8 years ago . The integral I am trying to compute is this: $$\int x^{4}e^{-x}dx$$ I got the right answer but I had to integrate by parts multiple times. Only thing is it took a long time to do the computations. I was wondering whether there are any more efficient ways of computing this integral or is integration by parts the only way to do this question? Edit: This question is similar to the question linked but slightly different because in the other question they are asking for any method to integrate the function which included integration by parts. In this question I acknowledge that integration by parts is a method that can be used to evaluate the integral but am looking for the most efficient way. This question has also generated different responses than the question linked such as the tabular method.,This question already has answers here : How to integrate $ \int x^n e^x dx$? (4 answers) Closed 8 years ago . The integral I am trying to compute is this: $$\int x^{4}e^{-x}dx$$ I got the right answer but I had to integrate by parts multiple times. Only thing is it took a long time to do the computations. I was wondering whether there are any more efficient ways of computing this integral or is integration by parts the only way to do this question? Edit: This question is similar to the question linked but slightly different because in the other question they are asking for any method to integrate the function which included integration by parts. In this question I acknowledge that integration by parts is a method that can be used to evaluate the integral but am looking for the most efficient way. This question has also generated different responses than the question linked such as the tabular method.,,"['calculus', 'integration']"
90,What does the integral of position with respect to time mean?,What does the integral of position with respect to time mean?,,"The integral of acceleration with respect to time is velocity. The integral of velocity with respect to time is position. What is the integral of position with respect to time, and what does it mean? Please explain so that your answer is understandable by someone who took calculus I.","The integral of acceleration with respect to time is velocity. The integral of velocity with respect to time is position. What is the integral of position with respect to time, and what does it mean? Please explain so that your answer is understandable by someone who took calculus I.",,"['calculus', 'integration', 'physics', 'intuition']"
91,An infinitely powered expression [duplicate],An infinitely powered expression [duplicate],,"This question already has answers here : Are these solutions of $2 = x^{x^{x^{\:\cdot^{\:\cdot^{\:\cdot}}}}}$ correct? (4 answers) Closed 8 years ago . Here's an expression I am struggling to evaluate: $$\LARGE   {\sqrt{2}^{\sqrt{2}^{\sqrt{2}^{\:\cdot^{\:\cdot^{\:\cdot}}}}}} $$ The value turns out be $2$, but I don't understand how do we get it. Can anyone give the solution? EDIT: The original problem is as follows: If $y(x)= { x }^{ { x }^{ { x }^{ { x }^{.  } } } }$, then evaluate $y(\sqrt { 2 })$.","This question already has answers here : Are these solutions of $2 = x^{x^{x^{\:\cdot^{\:\cdot^{\:\cdot}}}}}$ correct? (4 answers) Closed 8 years ago . Here's an expression I am struggling to evaluate: $$\LARGE   {\sqrt{2}^{\sqrt{2}^{\sqrt{2}^{\:\cdot^{\:\cdot^{\:\cdot}}}}}} $$ The value turns out be $2$, but I don't understand how do we get it. Can anyone give the solution? EDIT: The original problem is as follows: If $y(x)= { x }^{ { x }^{ { x }^{ { x }^{.  } } } }$, then evaluate $y(\sqrt { 2 })$.",,"['calculus', 'algebra-precalculus']"
92,What are some interesting calculus facts your calculus teachers didn't teach you? [closed],What are some interesting calculus facts your calculus teachers didn't teach you? [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I recently learned an interesting fact about what the value of a Lagrange multiplier represents: suppose the maximum of some real-valued function $f(\vec{x})$ subject to a constraint $g(\vec{x})=c$ is $M$ (of course, $M$ depends on $c$), which you obtained via Lagrange multipliers (solving $\nabla f = \lambda \nabla g$).  Then, it's easy to show (using the chain rule) that the multiplier $\lambda$ can be interpreted as the change of the maximum with respect to perturbations of the level set $g=c$. That is, $$ \lambda = \frac{d M}{dc} $$ I think this is a pretty cool result and I never it heard about during my time as an undergraduate. What are some interesting calculus (or undergraduate mathematics) results nobody told you about during your calculus (or undergraduate) education?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question I recently learned an interesting fact about what the value of a Lagrange multiplier represents: suppose the maximum of some real-valued function $f(\vec{x})$ subject to a constraint $g(\vec{x})=c$ is $M$ (of course, $M$ depends on $c$), which you obtained via Lagrange multipliers (solving $\nabla f = \lambda \nabla g$).  Then, it's easy to show (using the chain rule) that the multiplier $\lambda$ can be interpreted as the change of the maximum with respect to perturbations of the level set $g=c$. That is, $$ \lambda = \frac{d M}{dc} $$ I think this is a pretty cool result and I never it heard about during my time as an undergraduate. What are some interesting calculus (or undergraduate mathematics) results nobody told you about during your calculus (or undergraduate) education?",,"['calculus', 'multivariable-calculus', 'soft-question']"
93,Ways to show that $\int_{0}^{1}((1-x^r)^{1/r}-x)^{2k}dx=\frac{1}{2k+1}$,Ways to show that,\int_{0}^{1}((1-x^r)^{1/r}-x)^{2k}dx=\frac{1}{2k+1},"Through some calculation, I found that for all $r>0$ $$ \begin{array}{rcl} {\displaystyle\int_{0}^{1}\left[\left(1 - x^{r}\right)^{1/r} - x\right]^{2}\,\mathrm{d}x} &  {\displaystyle =} & {\displaystyle{1 \over 3}} \\ {\displaystyle\int_{0}^{1}\left[\left(1 - x^{r}\right)^{1/r} - x\right]^{4}\,\mathrm{d}x} &  {\displaystyle =} & {\displaystyle{1 \over 5}} \\ {\displaystyle\int_{0}^{1}\left[\left(1 - x^{r}\right)^{1/r} - x\right]^{6}\,\mathrm{d}x} &  {\displaystyle =} & {\displaystyle{1 \over 7}} \end{array} $$ It seems like for $k \in \mathbb{N}$ $$ \int_{0}^{1} \left[\left(1 - x^{r}\right)^{1/r} - x\right]^{2k}\mathrm{d}x = {1 \over 2k + 1} $$ I want to prove this general form. Someone suggested to make the substitution $$y=(1-x^r)^{1/r}$$ Let $n=2k$ , and I rewrote the integral into $$\int_{0}^{1}((1-x^r)^{1/r}-x)^ndx=\int_{0}^{1}(y-x)^ndx$$ and tried to use the binomial formula: $$(y-x)^{n}=\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}x^{n-k}y^{k}$$ The integral then becomes $$\begin{align} \int_{0}^{1}(y-x)^ndx&=\int_{0}^{1}\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}x^{n-k}y^{k}dx\\ &=\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}\int_{0}^{1}x^{n-k}y^{k}dx\\ &=\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}\int_{0}^{1}x^{n-k}(1-x^r)^{k/r}dx\\ \end{align}$$ Now I think I need to use Beta function: $$B(x,y) = \frac{(x-1)!(y-1)!}{(x+y-1)!}= \int_{0}^{1}u^{x-1}(1-u)^{y-1}du=\sum_{n=0}^{\infty}\frac{{\binom{n-y}{n}}}{x+n}$$ Am I on the right track? Are here any easier ways to prove the general form?","Through some calculation, I found that for all It seems like for I want to prove this general form. Someone suggested to make the substitution Let , and I rewrote the integral into and tried to use the binomial formula: The integral then becomes Now I think I need to use Beta function: Am I on the right track? Are here any easier ways to prove the general form?","r>0 
\begin{array}{rcl}
{\displaystyle\int_{0}^{1}\left[\left(1 - x^{r}\right)^{1/r} - x\right]^{2}\,\mathrm{d}x} &  {\displaystyle =} &
{\displaystyle{1 \over 3}}
\\
{\displaystyle\int_{0}^{1}\left[\left(1 - x^{r}\right)^{1/r} - x\right]^{4}\,\mathrm{d}x} &  {\displaystyle =} &
{\displaystyle{1 \over 5}}
\\
{\displaystyle\int_{0}^{1}\left[\left(1 - x^{r}\right)^{1/r} - x\right]^{6}\,\mathrm{d}x} &  {\displaystyle =} &
{\displaystyle{1 \over 7}}
\end{array}
 k \in \mathbb{N} 
\int_{0}^{1}
\left[\left(1 - x^{r}\right)^{1/r} - x\right]^{2k}\mathrm{d}x = {1 \over 2k + 1}
 y=(1-x^r)^{1/r} n=2k \int_{0}^{1}((1-x^r)^{1/r}-x)^ndx=\int_{0}^{1}(y-x)^ndx (y-x)^{n}=\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}x^{n-k}y^{k} \begin{align}
\int_{0}^{1}(y-x)^ndx&=\int_{0}^{1}\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}x^{n-k}y^{k}dx\\
&=\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}\int_{0}^{1}x^{n-k}y^{k}dx\\
&=\sum _{k=0}^{n}{\binom {n}{k}}(-1)^{n-k}\int_{0}^{1}x^{n-k}(1-x^r)^{k/r}dx\\
\end{align} B(x,y) = \frac{(x-1)!(y-1)!}{(x+y-1)!}= \int_{0}^{1}u^{x-1}(1-u)^{y-1}du=\sum_{n=0}^{\infty}\frac{{\binom{n-y}{n}}}{x+n}","['calculus', 'integration', 'definite-integrals']"
94,Where is the absolute value when computing antiderivatives?,Where is the absolute value when computing antiderivatives?,,"Here is a typical second-semester single-variable calculus question: $$ \int \frac{1}{\sqrt{1-x^2}} \, dx $$ Students are probably taught to just memorize the result of this since the derivative of $\arcsin(x)$ is taught as a rule to memorize. However, if we were to actually try and find an antiderivative, we might let $$ x = \sin \theta \quad \implies \quad dx = \cos \theta \, d \theta $$ so the integral may be rewritten as $$ \int \frac{\cos \theta}{\sqrt{1 - \sin^2 \theta}} \, d \theta  = \int \frac{\cos \theta}{\sqrt{\cos^2 \theta}} \, d \theta $$ At this point, students then simplify the denominator to just $\cos \theta$, which boils the integral down to $$ \int 1 \, d \theta = \theta + C = \arcsin x + C $$ which is the correct antiderivative. However, by definition, $\sqrt{x^2} = |x|$, implying that the integral above should really be simplified to $$ \int \frac{\cos \theta}{|\cos \theta|} \, d \theta = \int \pm 1 \, d \theta $$ depending on the interval for $\theta$. At this point, it looks like the answer that we will eventually arrive at is different from what we know the correct answer to be. Why is the first way correct even though we're not simplifying correctly, while the second way is... weird... while simplifying correctly?","Here is a typical second-semester single-variable calculus question: $$ \int \frac{1}{\sqrt{1-x^2}} \, dx $$ Students are probably taught to just memorize the result of this since the derivative of $\arcsin(x)$ is taught as a rule to memorize. However, if we were to actually try and find an antiderivative, we might let $$ x = \sin \theta \quad \implies \quad dx = \cos \theta \, d \theta $$ so the integral may be rewritten as $$ \int \frac{\cos \theta}{\sqrt{1 - \sin^2 \theta}} \, d \theta  = \int \frac{\cos \theta}{\sqrt{\cos^2 \theta}} \, d \theta $$ At this point, students then simplify the denominator to just $\cos \theta$, which boils the integral down to $$ \int 1 \, d \theta = \theta + C = \arcsin x + C $$ which is the correct antiderivative. However, by definition, $\sqrt{x^2} = |x|$, implying that the integral above should really be simplified to $$ \int \frac{\cos \theta}{|\cos \theta|} \, d \theta = \int \pm 1 \, d \theta $$ depending on the interval for $\theta$. At this point, it looks like the answer that we will eventually arrive at is different from what we know the correct answer to be. Why is the first way correct even though we're not simplifying correctly, while the second way is... weird... while simplifying correctly?",,"['calculus', 'absolute-value']"
95,What is the meaning of infinitesimal?,What is the meaning of infinitesimal?,,"I have read that an infinitesimal is very small, it is unthinkably small but I am not quite comfortable with with its applications. My first question is that is an infinitesimal a stationary value? It cannot be a stationary value because if so then a smaller value on real number line exist, so it must be a moving value. Moving value towards $0$ so in most places we use its magnitude equal to zero but at the same time we also know that infinitesimal is not equal so in all those places were we use value of infinitesimal equal to $0$ we are making an infinitesimal error and are not $100\%$ accurate, maybe $99.9999\dots\%$ accurate, but no $100\%$! So please explain infinitesimal and its applications and methodology in context to the above paragraph or elsewise intuitively please.","I have read that an infinitesimal is very small, it is unthinkably small but I am not quite comfortable with with its applications. My first question is that is an infinitesimal a stationary value? It cannot be a stationary value because if so then a smaller value on real number line exist, so it must be a moving value. Moving value towards $0$ so in most places we use its magnitude equal to zero but at the same time we also know that infinitesimal is not equal so in all those places were we use value of infinitesimal equal to $0$ we are making an infinitesimal error and are not $100\%$ accurate, maybe $99.9999\dots\%$ accurate, but no $100\%$! So please explain infinitesimal and its applications and methodology in context to the above paragraph or elsewise intuitively please.",,"['calculus', 'terminology', 'intuition', 'nonstandard-analysis', 'infinitesimals']"
96,how to strictly prove $\sin x<x$ for $0<x<\frac{\pi}{2}$ [duplicate],how to strictly prove  for  [duplicate],\sin x<x 0<x<\frac{\pi}{2},"This question already has answers here : Prove the inequality $\frac{\sin(x)}{x}<1$ (4 answers) Closed 1 year ago . $$\sin x<x\,(0<x<\frac{\pi}{2})$$ In most textbooks, to prove this inequality is based on geometry illustration (draw a circle, compare arc length and chord ), but I think that strict proof should be based on analysis reasoning without geometry illustration. Who can prove it? Thank you very much. ps : By differentiation, monotonicity and Taylor formula, all are wrong, because $(\sin x)'=\cos x$ must use $\lim_{x \to 0}\frac{\sin x}{x}=1$, and this formula must use $\sin x< x$. This is vicious circle. If we use Taylor series of $\sin x$ to define $\sin x$, strictly prove $\sin x<x$ is very easy, but how can we obtain geometry meaning of $\sin x$?","This question already has answers here : Prove the inequality $\frac{\sin(x)}{x}<1$ (4 answers) Closed 1 year ago . $$\sin x<x\,(0<x<\frac{\pi}{2})$$ In most textbooks, to prove this inequality is based on geometry illustration (draw a circle, compare arc length and chord ), but I think that strict proof should be based on analysis reasoning without geometry illustration. Who can prove it? Thank you very much. ps : By differentiation, monotonicity and Taylor formula, all are wrong, because $(\sin x)'=\cos x$ must use $\lim_{x \to 0}\frac{\sin x}{x}=1$, and this formula must use $\sin x< x$. This is vicious circle. If we use Taylor series of $\sin x$ to define $\sin x$, strictly prove $\sin x<x$ is very easy, but how can we obtain geometry meaning of $\sin x$?",,"['calculus', 'trigonometry', 'inequality']"
97,"When two functions are equal, but not.","When two functions are equal, but not.",,"I haven't looked into it much, but this is something I've been aware of that I know I need to look into. When I have a function $f(x)=\frac{x+1}{x+1}$, There is a discontinuity at $x=-1$, yet $\frac{x+1}{x+1}=1$ and has no discontinuity.  It's like they're equal but not. The qualities of the function are not preserved after the algebraic manipulation, so I can't strictly say that $\frac{x+1}{x+1}=1$. This is an issue for me when understanding integrals.  For instance, finding the definite integral of the quotient, if the discontinuity is within my limits, doesn't make sense.  But after changing the quotient to a constant, it's possible: but I've found the area under a curve that wasn't complete.  I've found a solution for an unanswerable, insensible question. I hope I've made this clear.  My question is, is this right?  How do I come to terms with this?","I haven't looked into it much, but this is something I've been aware of that I know I need to look into. When I have a function $f(x)=\frac{x+1}{x+1}$, There is a discontinuity at $x=-1$, yet $\frac{x+1}{x+1}=1$ and has no discontinuity.  It's like they're equal but not. The qualities of the function are not preserved after the algebraic manipulation, so I can't strictly say that $\frac{x+1}{x+1}=1$. This is an issue for me when understanding integrals.  For instance, finding the definite integral of the quotient, if the discontinuity is within my limits, doesn't make sense.  But after changing the quotient to a constant, it's possible: but I've found the area under a curve that wasn't complete.  I've found a solution for an unanswerable, insensible question. I hope I've made this clear.  My question is, is this right?  How do I come to terms with this?",,"['calculus', 'integration', 'limits']"
98,Definite integral of infinite product,Definite integral of infinite product,,"I have been struggling for a while on evaluating this definite infinite product integral: $$\int_{-\frac{\pi}{4}}^0(1+\tan{x})(1+\tan^2x)(1+\tan^4x)(1+\tan^8x)(1+\tan^{16}x)...dx$$ This is a question given by my maths teacher a while back and I have been struggling with it ever since. I have tried so many different substitutions and I have even tried integrating by parts (do NOT do this), but nothing has led me even close to an answer. I'm guessing there is trig identity I must be missing in order to simplify the inside of the integral? or some wonder substitution? Any help would be greatly appreciated.","I have been struggling for a while on evaluating this definite infinite product integral: This is a question given by my maths teacher a while back and I have been struggling with it ever since. I have tried so many different substitutions and I have even tried integrating by parts (do NOT do this), but nothing has led me even close to an answer. I'm guessing there is trig identity I must be missing in order to simplify the inside of the integral? or some wonder substitution? Any help would be greatly appreciated.",\int_{-\frac{\pi}{4}}^0(1+\tan{x})(1+\tan^2x)(1+\tan^4x)(1+\tan^8x)(1+\tan^{16}x)...dx,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'trigonometric-integrals']"
99,How does partial fraction decomposition avoid division by zero?,How does partial fraction decomposition avoid division by zero?,,"This may be an incredibly stupid question, but why does partial fraction decomposition avoid division by zero?  Let me give an example: $$\frac{3x+2}{x(x+1)}=\frac{A}{x}+\frac{B}{x+1}$$ Multiplying both sides by $x(x+1)$ we have: $$3x+2=A(x+1)+Bx$$ when $x \neq -1$ and $x \neq 0$. What is traditionally done here is $x$ is set to $-1$ and $0$ to reveal: $$-3+2=-B \implies 1=B$$ and  $$2=A$$ so we find that $$\frac{3x+2}{x(x+1)}=\frac{2}{x}+\frac{1}{x+1}$$ Why can $x$ be set equal to the roots of the denominator (in this case, $0$ and $-1$) without creating a division by zero problem?","This may be an incredibly stupid question, but why does partial fraction decomposition avoid division by zero?  Let me give an example: $$\frac{3x+2}{x(x+1)}=\frac{A}{x}+\frac{B}{x+1}$$ Multiplying both sides by $x(x+1)$ we have: $$3x+2=A(x+1)+Bx$$ when $x \neq -1$ and $x \neq 0$. What is traditionally done here is $x$ is set to $-1$ and $0$ to reveal: $$-3+2=-B \implies 1=B$$ and  $$2=A$$ so we find that $$\frac{3x+2}{x(x+1)}=\frac{2}{x}+\frac{1}{x+1}$$ Why can $x$ be set equal to the roots of the denominator (in this case, $0$ and $-1$) without creating a division by zero problem?",,"['calculus', 'algebra-precalculus', 'polynomials', 'partial-fractions', 'rational-functions']"
