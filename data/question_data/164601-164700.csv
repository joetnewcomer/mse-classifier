,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Remove even elements of partition of integration set,Remove even elements of partition of integration set,,"Suppose I am integrating a continuous $f:\mathbb{R}\rightarrow\mathbb{R}$ in a measurable set $A\subseteq I$ , where $I$ is an interval: $$ \int_{A}f(x)dx $$ Now suppose I partition the set $I$ in $N$ intervals $I_{i}$ of equal length: $I=\cup_{n=1}^{N}I_{n}$ . Let $A_{n}=A\cap I_{n}$ , so that $\{A_{n}:n\in\{1,..,N\}\}$ is a partition of $A$ . Let $E_N=\cup_{n=1}^{N/2}A_{2n}$ (it considers only the even elements of the partition of $A$ ). I am trying to show that $$ \lim_{N\rightarrow\infty}\int_{E_N}f(x)dx=\frac{1}{2}\int_{A}f(x)dx $$ But no success. I figured this may be a known result, is it?","Suppose I am integrating a continuous in a measurable set , where is an interval: Now suppose I partition the set in intervals of equal length: . Let , so that is a partition of . Let (it considers only the even elements of the partition of ). I am trying to show that But no success. I figured this may be a known result, is it?","f:\mathbb{R}\rightarrow\mathbb{R} A\subseteq I I 
\int_{A}f(x)dx
 I N I_{i} I=\cup_{n=1}^{N}I_{n} A_{n}=A\cap I_{n} \{A_{n}:n\in\{1,..,N\}\} A E_N=\cup_{n=1}^{N/2}A_{2n} A 
\lim_{N\rightarrow\infty}\int_{E_N}f(x)dx=\frac{1}{2}\int_{A}f(x)dx
","['integration', 'measure-theory', 'definite-integrals']"
1,A limit of an integral of a quotient related to fractional Sobolev space,A limit of an integral of a quotient related to fractional Sobolev space,,"Let $0<\alpha<1$ and $1\leq p<\infty$ . Suppose $f\in L^p(\mathbb{R}^n)$ satisfies \begin{align} \int_{\mathbb{R}^n}\int_{\mathbb{R}^n}\frac{|f(x)-f(y)|^p}{|x-y|^{n+\alpha p}}dxdy<\infty \end{align} Is it true that \begin{align} \int_{B(0,r)}\frac{|f(x+h)-f(x)|^p}{|h|^{n+\alpha p}}dh\to 0\qquad\text{as}\qquad r\to 0 \end{align} for a.e. $x\in\mathbb{R}^n$ ? Since this is an integration over the ball $B(0,r)$ (of radius $r$ ), at first I tried to look at Lebesgue-Besicovitch differentiation theorem, but the theorem actually involves the average (i.e. we need to take care of $|B(0,r)|^{-1}$ too). Now I have no idea where to start. Any hint, comment and answer are greatly appreciated.","Let and . Suppose satisfies Is it true that for a.e. ? Since this is an integration over the ball (of radius ), at first I tried to look at Lebesgue-Besicovitch differentiation theorem, but the theorem actually involves the average (i.e. we need to take care of too). Now I have no idea where to start. Any hint, comment and answer are greatly appreciated.","0<\alpha<1 1\leq p<\infty f\in L^p(\mathbb{R}^n) \begin{align}
\int_{\mathbb{R}^n}\int_{\mathbb{R}^n}\frac{|f(x)-f(y)|^p}{|x-y|^{n+\alpha p}}dxdy<\infty
\end{align} \begin{align}
\int_{B(0,r)}\frac{|f(x+h)-f(x)|^p}{|h|^{n+\alpha p}}dh\to 0\qquad\text{as}\qquad r\to 0
\end{align} x\in\mathbb{R}^n B(0,r) r |B(0,r)|^{-1}","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
2,Prove the following statement about measurable sets and functions,Prove the following statement about measurable sets and functions,,"Let $(f_n)_{n = 1}^{\infty}$ be a sequence of measurable functions defined on a measurable set $E$ , $m(E) < \infty.$ Suppose that $(\forall x \in E)(\exists M_x \in \mathbb{R})$ such that $\sup_n \mid f_n(x) \mid \le M_x.$ Prove that $\forall \varepsilon > 0$ there exists $F$ , a measurable subset of $E$ , $m(E \setminus F) < \varepsilon$ and $M = M(F, \varepsilon)$ such that $\mid f_n(x) \mid \le M$ for all $n \in \mathbb{N}$ and every $x \in F.$ I can't think what would the set $F$ look like. Something hints me that I should have used the fact that $f_n$ are measurable and $[0, M_x]$ are closed, but I can't figure it out. Any help is appreciated.","Let be a sequence of measurable functions defined on a measurable set , Suppose that such that Prove that there exists , a measurable subset of , and such that for all and every I can't think what would the set look like. Something hints me that I should have used the fact that are measurable and are closed, but I can't figure it out. Any help is appreciated.","(f_n)_{n = 1}^{\infty} E m(E) < \infty. (\forall x \in E)(\exists M_x \in \mathbb{R}) \sup_n \mid f_n(x) \mid \le M_x. \forall \varepsilon > 0 F E m(E \setminus F) < \varepsilon M = M(F, \varepsilon) \mid f_n(x) \mid \le M n \in \mathbb{N} x \in F. F f_n [0, M_x]","['measure-theory', 'measurable-functions']"
3,Lebesgue measure zero vs Jordan content zero,Lebesgue measure zero vs Jordan content zero,,"Is a set of Lebesgue measure zero necessarily a countable union of sets of Jordan content zero? This was a question posed by a student in my undergraduate analysis course. I asked an analyst colleague about this and he did not have an answer off the top of his head. Here are a few thoughts about this question. Since the closure of a set of Jordan content 0 also has content 0 and a compact set has measure 0 iff it has content 0, this question can be rephrased as follows: is any Lebesgue measurable set contained in an $F_\sigma$ set of the same measure? Off hand this might seem to be rather implausible. However it is true for open sets. They are countable unions of open balls and are contained in the corresponding union of closed balls.","Is a set of Lebesgue measure zero necessarily a countable union of sets of Jordan content zero? This was a question posed by a student in my undergraduate analysis course. I asked an analyst colleague about this and he did not have an answer off the top of his head. Here are a few thoughts about this question. Since the closure of a set of Jordan content 0 also has content 0 and a compact set has measure 0 iff it has content 0, this question can be rephrased as follows: is any Lebesgue measurable set contained in an set of the same measure? Off hand this might seem to be rather implausible. However it is true for open sets. They are countable unions of open balls and are contained in the corresponding union of closed balls.",F_\sigma,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
4,Identification between von Neumann algebras and measure spaces,Identification between von Neumann algebras and measure spaces,,"I could show that if $\pi:(X.\mathcal{M},\nu) \to (Y,\mathcal{N},\eta)$ is a measurable map with $\pi_*(\nu)<<\eta$ , then the induced map $\tilde{\pi}: L^{\infty}(Y,\mathcal{N},\eta)\to L^{\infty}(X,\mathcal{M},\nu)$ with $\tilde{\pi}(f)=f\circ\pi$ is well defined. Moreover, I could show that $\|\tilde{\pi}(f)\|_{\infty} \le \|f\|_{\infty}$ . The link to the same can be found here. It is clear that $\tilde{\pi}$ defined above a $*$ -homomorphism. Since $\tilde{\pi}\left(L^{\infty}(Y,\mathcal{N},\eta)\right)$ is norm closed $*$ -subalgebra of $L^{\infty}(X,\mathcal{M},\nu)$ , it is also weak $^*$ -closed, hence a von Neumann subalgebra of $L^{\infty}(X,\mathcal{M},\nu)$ . I am trying to know if the converse to the above holds: Suppose that $\mathcal{A}$ is a von Neumann subalgebra of $L^{\infty}(X,\mathcal{M},\nu)$ . Then there exists a measurable map $\pi:(X,\mathcal{M},\nu) \to (Y,\mathcal{N},\eta)$ with $\pi_*(\nu)<<\eta$ such that $\mathcal{A}$ is isomorphic to $L^{\infty}(Y,\mathcal{N},\eta)$ as a von Neumann algebra . I came across the theorem of Mackey which is known as Mackey's point realization which says the following: Let $(X,\mathcal{M},\nu)$ be a standard Borel space and let $\mathcal{A}'\subset \mathcal{M}$ be a sub-sigma algebra which is $\nu$ -complete. Then there exists a standard Borel space $(Y,\mathcal{N},\eta)$ and a measurable map $\pi: (X,\mathcal{M},\nu) \to (Y,\mathcal{N},\eta)$ with $\pi_*(\nu)=\eta$ and $\mathcal{A}'=\{\pi^{-1}(E): E \in \mathcal{N}\}$ I am trying to use this theorem to establish my claim. First, since $\mathcal{A}$ is an abelian von Neumann algebra, $\mathcal{A}$ is of the form $L^{\infty}(Z,\mathcal{N}',\eta')$ . Let $\mathcal{A}'=\{\varphi(\chi_E): E \in \mathcal{N}'\}$ , where $\varphi$ is the weak $^*$ isomorphism between $\mathcal{A}$ and $L^{\infty}(Z,\mathcal{N}',\eta')$ . I think that $\varphi$ must take characteristic functions to characteristic functions and that $\varphi(\chi_E)=\chi_{\varphi(E)}$ . If this is the case, then $\mathcal{A}'$ is a sub-sigma algebra of $\mathcal{M}$ . I want to show that $\mathcal{A}'$ is $\nu$ -complete. Towards that end, let $S \subset\varphi(E)$ such that $\nu(\varphi(E))=0$ . The completeness of $\nu$ is not a big deal as I can always complete the sub-sigma algebra by adding the subsets of the measure zero sets but I am not sure if there is any other way of proving this. The only other possibility is that $S=\varphi(\varphi^{-1}(S))$ but why should $\varphi^{-1}(S) \in \mathcal{N}'$ ? Assuming all these, I am a little confused as to what I have shown in all these and how to go forward. A little hint would suffice. Thanks for the help!!","I could show that if is a measurable map with , then the induced map with is well defined. Moreover, I could show that . The link to the same can be found here. It is clear that defined above a -homomorphism. Since is norm closed -subalgebra of , it is also weak -closed, hence a von Neumann subalgebra of . I am trying to know if the converse to the above holds: Suppose that is a von Neumann subalgebra of . Then there exists a measurable map with such that is isomorphic to as a von Neumann algebra . I came across the theorem of Mackey which is known as Mackey's point realization which says the following: Let be a standard Borel space and let be a sub-sigma algebra which is -complete. Then there exists a standard Borel space and a measurable map with and I am trying to use this theorem to establish my claim. First, since is an abelian von Neumann algebra, is of the form . Let , where is the weak isomorphism between and . I think that must take characteristic functions to characteristic functions and that . If this is the case, then is a sub-sigma algebra of . I want to show that is -complete. Towards that end, let such that . The completeness of is not a big deal as I can always complete the sub-sigma algebra by adding the subsets of the measure zero sets but I am not sure if there is any other way of proving this. The only other possibility is that but why should ? Assuming all these, I am a little confused as to what I have shown in all these and how to go forward. A little hint would suffice. Thanks for the help!!","\pi:(X.\mathcal{M},\nu) \to (Y,\mathcal{N},\eta) \pi_*(\nu)<<\eta \tilde{\pi}: L^{\infty}(Y,\mathcal{N},\eta)\to L^{\infty}(X,\mathcal{M},\nu) \tilde{\pi}(f)=f\circ\pi \|\tilde{\pi}(f)\|_{\infty} \le \|f\|_{\infty} \tilde{\pi} * \tilde{\pi}\left(L^{\infty}(Y,\mathcal{N},\eta)\right) * L^{\infty}(X,\mathcal{M},\nu) ^* L^{\infty}(X,\mathcal{M},\nu) \mathcal{A} L^{\infty}(X,\mathcal{M},\nu) \pi:(X,\mathcal{M},\nu) \to (Y,\mathcal{N},\eta) \pi_*(\nu)<<\eta \mathcal{A} L^{\infty}(Y,\mathcal{N},\eta) (X,\mathcal{M},\nu) \mathcal{A}'\subset \mathcal{M} \nu (Y,\mathcal{N},\eta) \pi: (X,\mathcal{M},\nu) \to (Y,\mathcal{N},\eta) \pi_*(\nu)=\eta \mathcal{A}'=\{\pi^{-1}(E): E \in \mathcal{N}\} \mathcal{A} \mathcal{A} L^{\infty}(Z,\mathcal{N}',\eta') \mathcal{A}'=\{\varphi(\chi_E): E \in \mathcal{N}'\} \varphi ^* \mathcal{A} L^{\infty}(Z,\mathcal{N}',\eta') \varphi \varphi(\chi_E)=\chi_{\varphi(E)} \mathcal{A}' \mathcal{M} \mathcal{A}' \nu S \subset\varphi(E) \nu(\varphi(E))=0 \nu S=\varphi(\varphi^{-1}(S)) \varphi^{-1}(S) \in \mathcal{N}'","['functional-analysis', 'measure-theory', 'lp-spaces', 'von-neumann-algebras']"
5,General conditions for a measurable set,General conditions for a measurable set,,"Let $A \subset [0, 1]$ and suppose $A$ has finite, strictly positive Lebesgue measure. Is it possible that for all $x, y \in A$ it happens that $ x - y \in \mathbb{Q}$ ? My proposed solution: Since $A$ has strictly positive measure, $A$ cannot be countable, and so $A$ cannot consist solely of rational numbers. Since the difference of an irrational and a rational is irrational, the answer to the question is no in this case. Now if $A$ consists solely of irrationals, then I want to say that it is impossible for every difference to be rational. How do I prove this last statement?","Let and suppose has finite, strictly positive Lebesgue measure. Is it possible that for all it happens that ? My proposed solution: Since has strictly positive measure, cannot be countable, and so cannot consist solely of rational numbers. Since the difference of an irrational and a rational is irrational, the answer to the question is no in this case. Now if consists solely of irrationals, then I want to say that it is impossible for every difference to be rational. How do I prove this last statement?","A \subset [0, 1] A x, y \in A  x - y \in \mathbb{Q} A A A A","['real-analysis', 'measure-theory']"
6,Prove that $\inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} > 0$,Prove that,\inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} > 0,"The next problem appears in the book ""Real analysis"" by  Thomson/Bruckner in the chapter of Integrable functions. My proof seems good to me but I'm not confident enough with my proofs in this subject. Here, $(X, \sigma, \mu)$ is a measurable space. I use the following: Definition Given a succession $(E_n)$ of measurable sets, $\limsup E_n = \{x \in X : x$ belongs to $E_j$ for infinitely many $j \}$ Theorem: if $(E_n)$ is a succession of measurable sets and $\mu (\cup E_n) < \infty$ then $\limsup \mu(E_n) \leq \mu(\limsup E_n)$ Problem: Suppose that $f \in L_1(X)$ , that $f(x)>0$ for all $x \in X$ , and that $0 < \alpha < \mu(X) < \infty $ . Prove that $$ \inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} > 0. $$ My attempt: Suppose that $\inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} = 0$ . Then, we can choose a succession $(E_n)_{n \geq 1}$ such that $\mu(E_n) \geq \alpha$ and $$ \int_{En} f < \frac{\alpha}{2^n}.$$ Then, $f|_{E_n} < \frac{1}{2^n} $ . For if $f|_{E_n} \geq \frac{1}{2^n} $ then we have $$ \frac{\alpha}{2^n} > \int_{E_n} f d \mu \geq \int_{E_n} \frac{d \mu}{2^n} = \frac{\mu(E_n)}{2^n} \geq \frac{\alpha}{2^n},$$ a contradiction. Now, if there exist $ x \in X$ such that $x \in \limsup E_n$ then $f(x)<\frac{\alpha}{2^j}$ , for infinitely many $j's$ . So we must have $f(x) = 0$ , contradicting that $f > 0$ . Therefore $\limsup E_n = \emptyset$ and $\mu (\limsup E_n)=0$ . However $\limsup \mu(E_n) \geq \alpha$ because $\mu(E_n) \geq \alpha$ for every $n$ .  And because we are in a space of finite measure, we can aply the above theorem and obtain $$  0 < \alpha \leq \limsup \mu(E_n) \leq \mu (\limsup E_n) = 0. $$ So $\alpha = 0$ is our final contradiction.","The next problem appears in the book ""Real analysis"" by  Thomson/Bruckner in the chapter of Integrable functions. My proof seems good to me but I'm not confident enough with my proofs in this subject. Here, is a measurable space. I use the following: Definition Given a succession of measurable sets, belongs to for infinitely many Theorem: if is a succession of measurable sets and then Problem: Suppose that , that for all , and that . Prove that My attempt: Suppose that . Then, we can choose a succession such that and Then, . For if then we have a contradiction. Now, if there exist such that then , for infinitely many . So we must have , contradicting that . Therefore and . However because for every .  And because we are in a space of finite measure, we can aply the above theorem and obtain So is our final contradiction.","(X, \sigma, \mu) (E_n) \limsup E_n = \{x \in X : x E_j j \} (E_n) \mu (\cup E_n) < \infty \limsup \mu(E_n) \leq \mu(\limsup E_n) f \in L_1(X) f(x)>0 x \in X 0 < \alpha < \mu(X) < \infty   \inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} > 0.  \inf \left\{ \int_E f d\mu : \mu (E) \geq \alpha\right\} = 0 (E_n)_{n \geq 1} \mu(E_n) \geq \alpha  \int_{En} f < \frac{\alpha}{2^n}. f|_{E_n} < \frac{1}{2^n}  f|_{E_n} \geq \frac{1}{2^n}   \frac{\alpha}{2^n} > \int_{E_n} f d \mu \geq \int_{E_n} \frac{d \mu}{2^n} = \frac{\mu(E_n)}{2^n} \geq \frac{\alpha}{2^n},  x \in X x \in \limsup E_n f(x)<\frac{\alpha}{2^j} j's f(x) = 0 f > 0 \limsup E_n = \emptyset \mu (\limsup E_n)=0 \limsup \mu(E_n) \geq \alpha \mu(E_n) \geq \alpha n   0 < \alpha \leq \limsup \mu(E_n) \leq \mu (\limsup E_n) = 0.  \alpha = 0","['measure-theory', 'proof-verification', 'lebesgue-integral']"
7,Convergence of probability measure,Convergence of probability measure,,"Let $X_1,X_2,...$ be iid random variables with density $(1-\cos x)/\pi x^2$ . How do we show that $$\lim\limits_{n\to\infty}\mathbb{P}\left(\frac{X_1+...+X_n}{n}\leq x\right)=\frac{1}{2}+\pi^{-1}\arctan x?$$ Maybe using the characteristic functions? Then $$\phi_X(u)=\int e^{iux}(1-\cos x)/\pi x^2dx.$$ But how do we proceed?",Let be iid random variables with density . How do we show that Maybe using the characteristic functions? Then But how do we proceed?,"X_1,X_2,... (1-\cos x)/\pi x^2 \lim\limits_{n\to\infty}\mathbb{P}\left(\frac{X_1+...+X_n}{n}\leq x\right)=\frac{1}{2}+\pi^{-1}\arctan x? \phi_X(u)=\int e^{iux}(1-\cos x)/\pi x^2dx.","['probability', 'measure-theory', 'convergence-divergence']"
8,Prove that integral of infinite sum is in $L^1$,Prove that integral of infinite sum is in,L^1,"The function $g$ is a composition of functions as follows ( $\chi_A$ is the characteristic function of the set $A$ ): $$f(x) = \frac{1}{\sqrt{x}} \chi_{[0,1]}(x)$$ For an enumeration of the rationals $\{r_i\}$ : $$g(x) = \sum_{n=1}^\infty 2^{-n}f(x-r_n)$$ Prove that $g \in L^1(m)$ where $m$ is the Lebesgue measure for $m$ almost everywhere on $x$ . Prove that $g$ is unbounded on every open interval $I \in [0,1]$ and that $\forall I, \forall N \in \mathbb{N} \Rightarrow m(\{x\in I : g(x)>N\}) > 0$ Putting everything in place, we have $$\int \sum_{n=1}^\infty 2^{-n}\frac{\chi_{[0,1](x-r_n)}}{\sqrt{x-r_n}} dm$$ Analyzing the parts of this function, we see that $2^{-n} \geq 0; \chi \geq 0$ I don't know how to show that with the denominator this is a function in $L^+$ . I know that for being in $L^1$ I am interested in $|f|$ but I am still unsure if I should and how to proceed about this. If I could show that, then we can swap the sum and the integral and get $$\sum_{n=1}^\infty \int 2^{-n}\frac{\chi_{[0,1](x-r_n)}}{\sqrt{x-r_n}} dm$$ where $$\int 2^{-n}\frac{\chi_{[0,1](x-r_n)}}{\sqrt{x-r_n}} dm \leq \int 2^{-n}\frac{1}{\sqrt{x-r_n}} dm \leq \int \frac{1}{\sqrt{x-r_n}}dm$$ Do I proceed with some sort of limit theorem or keep trying to prove that this is less than some other function?","The function is a composition of functions as follows ( is the characteristic function of the set ): For an enumeration of the rationals : Prove that where is the Lebesgue measure for almost everywhere on . Prove that is unbounded on every open interval and that Putting everything in place, we have Analyzing the parts of this function, we see that I don't know how to show that with the denominator this is a function in . I know that for being in I am interested in but I am still unsure if I should and how to proceed about this. If I could show that, then we can swap the sum and the integral and get where Do I proceed with some sort of limit theorem or keep trying to prove that this is less than some other function?","g \chi_A A f(x) = \frac{1}{\sqrt{x}} \chi_{[0,1]}(x) \{r_i\} g(x) = \sum_{n=1}^\infty 2^{-n}f(x-r_n) g \in L^1(m) m m x g I \in [0,1] \forall I, \forall N \in \mathbb{N} \Rightarrow m(\{x\in I : g(x)>N\}) > 0 \int \sum_{n=1}^\infty 2^{-n}\frac{\chi_{[0,1](x-r_n)}}{\sqrt{x-r_n}} dm 2^{-n} \geq 0; \chi \geq 0 L^+ L^1 |f| \sum_{n=1}^\infty \int 2^{-n}\frac{\chi_{[0,1](x-r_n)}}{\sqrt{x-r_n}} dm \int 2^{-n}\frac{\chi_{[0,1](x-r_n)}}{\sqrt{x-r_n}} dm \leq \int 2^{-n}\frac{1}{\sqrt{x-r_n}} dm \leq \int \frac{1}{\sqrt{x-r_n}}dm","['real-analysis', 'integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
9,"Let $S_1,S_2$ be measurable with $d(S_1,S_2)>0$. Show that $\mu(S_1\cup S_2)=\mu S_1+\mu S_2$",Let  be measurable with . Show that,"S_1,S_2 d(S_1,S_2)>0 \mu(S_1\cup S_2)=\mu S_1+\mu S_2","Measure here is Jordan Measure. $d(A,B)=\inf\{\vert x-y:x\in A,y\in B\}$ So I can show the first direction fairly easily because it doesn't use the condition. $\leq$ Since $S_i$ are measurable there exists poly rectangles $P_i$ such that $\mu S_i\leq\vert P_i\vert\leq \mu (S_i)+\frac{\epsilon}{2}$ . Since $S_i\subseteq P_i$ , $S_1\cup S_2\subseteq P_1\cup P_2$ thus $\mu(S_1\cup S_2\leq \vert P_1\cup P_2\vert=\vert P_1\vert+\vert P_2\vert\leq \mu S_1+\mu S_2+\epsilon$ so $\mu (S_1\cup S_2)\leq \mu S_1 +\mu S_2$ But to show $\mu (S_1\cup S_2) \geq \mu S_1 + \mu S_2$ I'm not sure. Obviously since the distance between any 2 points between them is always positive they don't share any points. Which I believe should mean I can construct poly rectangles $P_i$ for each $S_i$ which have lengths less then $d(S_1,S_2)$ such that $P_1\cup P_2$ should still cover $S_1 \cup S_2$","Measure here is Jordan Measure. So I can show the first direction fairly easily because it doesn't use the condition. Since are measurable there exists poly rectangles such that . Since , thus so But to show I'm not sure. Obviously since the distance between any 2 points between them is always positive they don't share any points. Which I believe should mean I can construct poly rectangles for each which have lengths less then such that should still cover","d(A,B)=\inf\{\vert x-y:x\in A,y\in B\} \leq S_i P_i \mu S_i\leq\vert P_i\vert\leq \mu (S_i)+\frac{\epsilon}{2} S_i\subseteq P_i S_1\cup S_2\subseteq P_1\cup P_2 \mu(S_1\cup S_2\leq \vert P_1\cup P_2\vert=\vert P_1\vert+\vert P_2\vert\leq \mu S_1+\mu S_2+\epsilon \mu (S_1\cup S_2)\leq \mu S_1 +\mu S_2 \mu (S_1\cup S_2) \geq \mu S_1 + \mu S_2 P_i S_i d(S_1,S_2) P_1\cup P_2 S_1 \cup S_2","['real-analysis', 'measure-theory']"
10,Change variable in the integral with nonnegative measure,Change variable in the integral with nonnegative measure,,"Just ask a very fundamental problem of changing variable when doing integration. I am a bit confused about the following: Suppose I want to do the integral $$\int_X v(x) d\mu(\gamma^{-1}x)$$ where $\gamma: X\mapsto X$ and $\gamma$ is invertible, i.e., $\gamma^{-1}$ exists. You can think $\gamma \in O(n)$ , the orthogonal gruop. $\mu$ is a nonnegative measure. $\,v:X\mapsto \mathbb{R}$ is continuous. Let $y=\gamma^{-1}x$ . So $x=\gamma y$ . Integration over $X$ becomes over $\gamma^{-1}X$ . So we obtain $$\int_{\gamma^{-1}X} v(\gamma y) d\mu(y)$$ Now, change $y$ back to $x$ , $$\int_{\gamma^{-1}X} v(\gamma x) d\mu(x)$$ I am not sure if my derivation makes any sense. In particular, the part of $\gamma^{-1}X$ . Thanks!","Just ask a very fundamental problem of changing variable when doing integration. I am a bit confused about the following: Suppose I want to do the integral where and is invertible, i.e., exists. You can think , the orthogonal gruop. is a nonnegative measure. is continuous. Let . So . Integration over becomes over . So we obtain Now, change back to , I am not sure if my derivation makes any sense. In particular, the part of . Thanks!","\int_X v(x) d\mu(\gamma^{-1}x) \gamma: X\mapsto X \gamma \gamma^{-1} \gamma \in O(n) \mu \,v:X\mapsto \mathbb{R} y=\gamma^{-1}x x=\gamma y X \gamma^{-1}X \int_{\gamma^{-1}X} v(\gamma y) d\mu(y) y x \int_{\gamma^{-1}X} v(\gamma x) d\mu(x) \gamma^{-1}X","['integration', 'measure-theory', 'change-of-variable']"
11,Exchange limit on bounds of Lebesgue integral,Exchange limit on bounds of Lebesgue integral,,Let $(E_n)_{n \in \mathbb{N}}$ be a sequence of measurable sets such that $\lim_{n \to \infty} E_n =E$ for some measurable set $E$ . When does it hold that $$ \lim_{n \to \infty}\int_{E_n}f d \mu = \int_{E}f d\mu$$ What if we replace $\lim$ with $\lim \sup$ or $\lim \inf$ ?,Let be a sequence of measurable sets such that for some measurable set . When does it hold that What if we replace with or ?,(E_n)_{n \in \mathbb{N}} \lim_{n \to \infty} E_n =E E  \lim_{n \to \infty}\int_{E_n}f d \mu = \int_{E}f d\mu \lim \lim \sup \lim \inf,"['measure-theory', 'lebesgue-integral']"
12,"What is the canonical process of a measure space $(\Omega, \mathscr{F}, \mathbb{Q})$?",What is the canonical process of a measure space ?,"(\Omega, \mathscr{F}, \mathbb{Q})","I was reading  paper which referred to a canonical process within the context of a measure space $(\Omega, \mathscr{F}, \mathbb{Q})$ . The surrounding discussion was of functions $a:[t,T] \rightarrow \Omega$ , and the canonical process was denoted $(\mathbb{S}_t)^T_{t=0}$ . It may be useful to know that the term was used when defining a ""martingale measure"". A measure $\mathbb{Q}$ was said to be a martingale measure if the canonical process is a local martingale with respect to the measure and $\mathbb{S}(0) = 1$ a.s. What could this canonical process be? Any help is appreciated.","I was reading  paper which referred to a canonical process within the context of a measure space . The surrounding discussion was of functions , and the canonical process was denoted . It may be useful to know that the term was used when defining a ""martingale measure"". A measure was said to be a martingale measure if the canonical process is a local martingale with respect to the measure and a.s. What could this canonical process be? Any help is appreciated.","(\Omega, \mathscr{F}, \mathbb{Q}) a:[t,T] \rightarrow \Omega (\mathbb{S}_t)^T_{t=0} \mathbb{Q} \mathbb{S}(0) = 1","['measure-theory', 'stochastic-processes']"
13,Help save this proof about the regularity of the lebesgue measure on $\mathbb{R}^d$,Help save this proof about the regularity of the lebesgue measure on,\mathbb{R}^d,"In a previous homework our task was to prove the regularity of the Lebegue-measure on $\mathbb{R}^d$ . More precisely: Let $(\mathbb{R}^d, \mathcal{M}^*, \lambda)$ be a measure space and $\mathcal{M}^* := \mathcal{M}^*(\mathbb{R}^d)$ be the $\sigma$ -algebra of the $\lambda^*$ -measurable sets, with $\lambda$ being the by the Lebesgue-outer-measure $\lambda^*$ induced measure. Show that \begin{align*} \lambda(A) & = \inf\{\lambda(O) \mid O \subset \mathbb{R}^d \text{ is open and } A \subset O \} \\ & = \sup\{\lambda(K) \mid K \subset \mathbb{R}^d \text{ is compact and } K \subset A \}. \end{align*} Our attempt goes as follows: For all $A \in \mathcal{M}^*$ we want to show \begin{equation*} \lambda(A) \ge \inf\{ \lambda(O): O \subset \mathbb{R}^d \text{ open und } A \subset O \} \ge \sup\{ \lambda(K): K \subset \mathbb{R}^d \text{ compact and } K \subset A \} \ge \lambda(A) \end{equation*} First inequality: If $\lambda(A) = \infty$ , because of the monotonicity of the measure, we have $\lambda(O) = \infty$ for all open sets $O$ with $A \subset O$ . If $\lambda(A) < \infty$ , we define $A_{\delta} := \bigcup_{a \in A} U_{\delta}(a)$ , which is a open and therefore measurable set with $A \subset A_{\delta}$ . Now we have $A_{\delta} \setminus A \xrightarrow{\delta \to 0} \emptyset$ and because of the continuity from below in the emptyset of $\lambda$ , and, because $A_{\delta} \setminus A$ is measurable, because it's the difference of measurable sets, \begin{equation*} \forall \varepsilon > 0 \  \exists \delta > 0: \lambda(A_{\delta} \setminus A) < \varepsilon. \end{equation*} Because $A_{\delta}$ is open and $\sigma$ -additivity of $\lambda$ we have \begin{equation*} \inf\{ \lambda(O): O \subset \mathbb{R}^d \text{ open und } A \subset O \} \le \lambda(A_{\delta}) = \lambda(A_{\delta} \setminus A) + \lambda(A) < \varepsilon + \lambda(A). \end{equation*} Because $\varepsilon > 0$ was arbitrary, the inequality follows. The second inequality follows from the monotonicity of $\lambda^*$ :         From $K \subset A \subset O$ we have $\lambda(K) \le \lambda(O)$ for $K$ und $O$ as defined above. Because taking the supremum or infimum doesn't change weak inequalities, the inequality follows. The third inequality: One can show, that every open set is $\sigma$ -compact. Lemma Let $A_{\delta} \subset \mathbb{R}^d$ be an open subset. Then there exists a countable family of closed bounded axially parallel cubes $(W_k)_{k \in \mathbb{N}}$ , so that $A_{\delta}  = \bigcup_{n \in \mathbb{N}} W_n$ . Proof Let $a \in A_{\delta} $ . Because $A_{\delta} $ is open, there exists an $\varepsilon_{a} > 0$ , so that $U_{\varepsilon_a}(a) \subset A_{\delta} $ . For every $a \in A_{\delta} $ we choose a bounded closed axially parallel cube $W_a$ with rational midpoint from $\mathbb{Q}^d$ and rational edge length $q \in \mathbb{Q}$ , so that \begin{equation*} a \in W_{a} \subset U_{\varepsilon_a}(a) \subset A_{\delta} . \end{equation*} This is always possible, because $\mathbb{Q}$ is dense in $\mathbb{R}$ . Therefore, we have $A_{\delta} = \bigcup_{n \in \mathbb{N}} W_n$ . Since there are only countable many cubes of this form, the union is countable. $\square$ We let $K_n := \bigcup_{j = 1}^{n} W_j$ , which is compact as union of compact sets. Then $K_n \xrightarrow{n \to \infty} A_{\delta}$ . Now we have $A_{\delta} \setminus K_n \xrightarrow{n \to \infty} \emptyset$ and with analogous argumentation as above \begin{equation*} \forall \varepsilon > 0 \  \exists N \in \mathbb{N}: \lambda(A_{\delta} \setminus K_n) < \varepsilon \  \forall n > N. \end{equation*} Therefore follows for all $\varepsilon > 0$ \begin{align*} \lambda(A) \le \lambda(A_{\delta}) \le \lambda(A_{\delta}\setminus K_n) + \lambda(K_n) < \varepsilon + \sup\{ \lambda(K): K \subset \mathbb{R}^d \text{ compact und } K \subset A_{\delta} \}, \end{align*} Because $\varepsilon > 0$ was arbitrary and $\delta$ can be arbitrarily small, the inequality follows. My problem I assume the proof of the second inequality is right. But: I not sure if the reasoning at the end of the proof of the last inequality is rigorous enough. Especially, if you take $A := \mathbb{Q}$ in the proof of the first inequality, then for every $\delta > 0$ , we have $A_{\delta} = \mathbb{R}$ and therefore, we don't have $A_{\delta} \setminus A \to \emptyset$ or even $\lambda(A_{\delta} \setminus A) \to 0$ . Is there anyway to ''save'' this proof by fixing it and not changing the approach? Correct Proof First inequality Case 1: $\lambda(A) = \infty$ . As above. Case 2: $\lambda(A) < \infty$ . Utilising the Caratheodory construction of the Lebesgue measure, we know that $$ \forall \varepsilon > 0 \ \exists (a_n,b_n] := \prod_{i=1}^d \left(a_{n}^{(i)},b_{n}^{(i)}\right]:  A \subset \bigcup_{n \in \mathbb{N}} (a_n,b_n] \quad \text{and} \quad \sum_{k=1}^\infty \lambda \left((a_k,b_k]\right) < \lambda(A) + \frac{\varepsilon}{2}, $$ where the $d$ -dimensional cubes $(a_n,b_n]$ are pairwise disjoint. Now let $$ U := \bigcup_{n=1}^\infty (a_n, b_n+ t_n \varepsilon) \qquad \text{with} \qquad t_n := 2^{-n-2d-1} \max\{1,b_{n}^{(i)} -a_{n}^{(i)}\}^{-(d-1)}. $$ Now we have $A \subset \bigcup_{n=1}^\infty (a_n,b_n] \subset U$ and $\lambda(U) < \lambda(A) + \varepsilon$ . Therefore, we have \begin{equation*} \inf\{ \lambda(O): O \subset \mathbb{R}^d \text{ open und } A \subset O \} \le \lambda(U) < \lambda(A) + \varepsilon. \end{equation*} Because $\varepsilon > 0$ was arbitrary, the inequality follows. Second inequality Same as above Third inequality From a previous homework we know that $\mathcal{B}(\mathbb{R}^d) \subset \mathcal{M}^*$ and therefore, that \begin{equation*} \forall M \in \mathcal{M}^* \ \exists B \in \mathcal{B}(\mathbb{R}^d), N \in \mathcal{N}: M = B \cup N, \end{equation*} where $\mathcal{N}$ is the set of borel-null-sets. Now define \begin{equation*} \mathcal{D} := \{ B \in \mathcal{B}(\mathbb{R}^d): \lambda(B) = \sup\{\lambda(K) \mid K \subset \mathbb{R}^d \text{ is compact and } K \subset B \} \} \end{equation*} as the set of all inner regular sets in the borel $\sigma$ -algebra, which, by construction is a subset of $\mathcal{B}(\mathbb{R}^d)$ . Now we want to show, that $\mathcal{B}(\mathbb{R}^d) \subset \mathcal{D}$ to conclude $\mathcal{B}(\mathbb{R}^d) = \mathcal{D}$ . From the above lemma we know, that for all open sets $\mathcal{O} \subset \mathbb{R}^d$ we have $\mathcal{O} \in \mathcal{D}$ , since by the continuity of the Lebesgue-measure, for all $\varepsilon > 0$ we have $\lambda(A) \le \lambda(\bigcup_{n \in \mathbb{N}} W_n) + \varepsilon$ . Since the set of open sets is a $\cap$ -stable generator of $\mathcal{B}(\mathbb{R}^d) \subset \mathcal{P}(\mathbb{R})^d$ , we only need to show that $\mathcal{D}$ is a dynkin system. ( German Wikipedia article on this line of argument ) We have $\mathbb{R}^d \in \mathcal{D}$ , because $\lambda(\mathbb{R}^d) = \infty = \sup\{\lambda(K): K \subset \mathbb{R}^d \}$ . Let $D \in \mathcal{D}$ . Then ?? Let $\{ A_n \}_{n \in \mathbb{N}} \subset \mathcal{D}$ be a family of disjoint subsets. Then","In a previous homework our task was to prove the regularity of the Lebegue-measure on . More precisely: Let be a measure space and be the -algebra of the -measurable sets, with being the by the Lebesgue-outer-measure induced measure. Show that Our attempt goes as follows: For all we want to show First inequality: If , because of the monotonicity of the measure, we have for all open sets with . If , we define , which is a open and therefore measurable set with . Now we have and because of the continuity from below in the emptyset of , and, because is measurable, because it's the difference of measurable sets, Because is open and -additivity of we have Because was arbitrary, the inequality follows. The second inequality follows from the monotonicity of :         From we have for und as defined above. Because taking the supremum or infimum doesn't change weak inequalities, the inequality follows. The third inequality: One can show, that every open set is -compact. Lemma Let be an open subset. Then there exists a countable family of closed bounded axially parallel cubes , so that . Proof Let . Because is open, there exists an , so that . For every we choose a bounded closed axially parallel cube with rational midpoint from and rational edge length , so that This is always possible, because is dense in . Therefore, we have . Since there are only countable many cubes of this form, the union is countable. We let , which is compact as union of compact sets. Then . Now we have and with analogous argumentation as above Therefore follows for all Because was arbitrary and can be arbitrarily small, the inequality follows. My problem I assume the proof of the second inequality is right. But: I not sure if the reasoning at the end of the proof of the last inequality is rigorous enough. Especially, if you take in the proof of the first inequality, then for every , we have and therefore, we don't have or even . Is there anyway to ''save'' this proof by fixing it and not changing the approach? Correct Proof First inequality Case 1: . As above. Case 2: . Utilising the Caratheodory construction of the Lebesgue measure, we know that where the -dimensional cubes are pairwise disjoint. Now let Now we have and . Therefore, we have Because was arbitrary, the inequality follows. Second inequality Same as above Third inequality From a previous homework we know that and therefore, that where is the set of borel-null-sets. Now define as the set of all inner regular sets in the borel -algebra, which, by construction is a subset of . Now we want to show, that to conclude . From the above lemma we know, that for all open sets we have , since by the continuity of the Lebesgue-measure, for all we have . Since the set of open sets is a -stable generator of , we only need to show that is a dynkin system. ( German Wikipedia article on this line of argument ) We have , because . Let . Then ?? Let be a family of disjoint subsets. Then","\mathbb{R}^d (\mathbb{R}^d, \mathcal{M}^*, \lambda) \mathcal{M}^* := \mathcal{M}^*(\mathbb{R}^d) \sigma \lambda^* \lambda \lambda^* \begin{align*}
\lambda(A)
& = \inf\{\lambda(O) \mid O \subset \mathbb{R}^d \text{ is open and } A \subset O \} \\
& = \sup\{\lambda(K) \mid K \subset \mathbb{R}^d \text{ is compact and } K \subset A \}.
\end{align*} A \in \mathcal{M}^* \begin{equation*}
\lambda(A)
\ge \inf\{ \lambda(O): O \subset \mathbb{R}^d \text{ open und } A \subset O \}
\ge \sup\{ \lambda(K): K \subset \mathbb{R}^d \text{ compact and } K \subset A \}
\ge \lambda(A)
\end{equation*} \lambda(A) = \infty \lambda(O) = \infty O A \subset O \lambda(A) < \infty A_{\delta} := \bigcup_{a \in A} U_{\delta}(a) A \subset A_{\delta} A_{\delta} \setminus A \xrightarrow{\delta \to 0} \emptyset \lambda A_{\delta} \setminus A \begin{equation*}
\forall \varepsilon > 0 \ 
\exists \delta > 0:
\lambda(A_{\delta} \setminus A) < \varepsilon.
\end{equation*} A_{\delta} \sigma \lambda \begin{equation*}
\inf\{ \lambda(O): O \subset \mathbb{R}^d \text{ open und } A \subset O \}
\le \lambda(A_{\delta})
= \lambda(A_{\delta} \setminus A) + \lambda(A)
< \varepsilon + \lambda(A).
\end{equation*} \varepsilon > 0 \lambda^* K \subset A \subset O \lambda(K) \le \lambda(O) K O \sigma A_{\delta} \subset \mathbb{R}^d (W_k)_{k \in \mathbb{N}} A_{\delta}  = \bigcup_{n \in \mathbb{N}} W_n a \in A_{\delta}  A_{\delta}  \varepsilon_{a} > 0 U_{\varepsilon_a}(a) \subset A_{\delta}  a \in A_{\delta}  W_a \mathbb{Q}^d q \in \mathbb{Q} \begin{equation*}
a
\in W_{a}
\subset U_{\varepsilon_a}(a)
\subset A_{\delta} .
\end{equation*} \mathbb{Q} \mathbb{R} A_{\delta} = \bigcup_{n \in \mathbb{N}} W_n \square K_n := \bigcup_{j = 1}^{n} W_j K_n \xrightarrow{n \to \infty} A_{\delta} A_{\delta} \setminus K_n \xrightarrow{n \to \infty} \emptyset \begin{equation*}
\forall \varepsilon > 0 \ 
\exists N \in \mathbb{N}:
\lambda(A_{\delta} \setminus K_n) < \varepsilon \ 
\forall n > N.
\end{equation*} \varepsilon > 0 \begin{align*}
\lambda(A)
\le \lambda(A_{\delta})
\le \lambda(A_{\delta}\setminus K_n) + \lambda(K_n)
< \varepsilon + \sup\{ \lambda(K): K \subset \mathbb{R}^d \text{ compact und } K \subset A_{\delta} \},
\end{align*} \varepsilon > 0 \delta A := \mathbb{Q} \delta > 0 A_{\delta} = \mathbb{R} A_{\delta} \setminus A \to \emptyset \lambda(A_{\delta} \setminus A) \to 0 \lambda(A) = \infty \lambda(A) < \infty 
\forall \varepsilon > 0 \
\exists (a_n,b_n] := \prod_{i=1}^d \left(a_{n}^{(i)},b_{n}^{(i)}\right]: 
A \subset \bigcup_{n \in \mathbb{N}} (a_n,b_n]
\quad \text{and} \quad
\sum_{k=1}^\infty \lambda \left((a_k,b_k]\right)
< \lambda(A) + \frac{\varepsilon}{2},
 d (a_n,b_n] 
U := \bigcup_{n=1}^\infty (a_n, b_n+ t_n \varepsilon)
\qquad \text{with} \qquad t_n := 2^{-n-2d-1} \max\{1,b_{n}^{(i)} -a_{n}^{(i)}\}^{-(d-1)}.
 A \subset \bigcup_{n=1}^\infty (a_n,b_n] \subset U \lambda(U) < \lambda(A) + \varepsilon \begin{equation*}
\inf\{ \lambda(O): O \subset \mathbb{R}^d \text{ open und } A \subset O \}
\le \lambda(U)
< \lambda(A) + \varepsilon.
\end{equation*} \varepsilon > 0 \mathcal{B}(\mathbb{R}^d) \subset \mathcal{M}^* \begin{equation*}
\forall M \in \mathcal{M}^* \
\exists B \in \mathcal{B}(\mathbb{R}^d), N \in \mathcal{N}:
M = B \cup N,
\end{equation*} \mathcal{N} \begin{equation*}
\mathcal{D}
:= \{ B \in \mathcal{B}(\mathbb{R}^d): \lambda(B) = \sup\{\lambda(K) \mid K \subset \mathbb{R}^d \text{ is compact and } K \subset B \} \}
\end{equation*} \sigma \mathcal{B}(\mathbb{R}^d) \mathcal{B}(\mathbb{R}^d) \subset \mathcal{D} \mathcal{B}(\mathbb{R}^d) = \mathcal{D} \mathcal{O} \subset \mathbb{R}^d \mathcal{O} \in \mathcal{D} \varepsilon > 0 \lambda(A) \le \lambda(\bigcup_{n \in \mathbb{N}} W_n) + \varepsilon \cap \mathcal{B}(\mathbb{R}^d) \subset \mathcal{P}(\mathbb{R})^d \mathcal{D} \mathbb{R}^d \in \mathcal{D} \lambda(\mathbb{R}^d) = \infty = \sup\{\lambda(K): K \subset \mathbb{R}^d \} D \in \mathcal{D} \{ A_n \}_{n \in \mathbb{N}} \subset \mathcal{D}","['real-analysis', 'measure-theory', 'lebesgue-measure']"
14,Calculate $\lim_{n \to \infty} \int_{\mathbb{R_{+}}} \exp((\cos^n x) -x) d\lambda(x)$,Calculate,\lim_{n \to \infty} \int_{\mathbb{R_{+}}} \exp((\cos^n x) -x) d\lambda(x),"the exponential function being increasing we have $| \exp((\cos^n x) -x)| \leq \exp(1 -x) \in L^1([0,+\infty[) $ so $x \to \exp((\cos^n x) -x)$ is Riemann absolutely convergent therefore $l = \lim_{n \to \infty} \int_{\mathbb{R_{+}}} \exp((\cos x^n) -x) d\lambda(x) =\lim_{n \to \infty} \int_{0}^{+\infty} \exp((\cos^n x) -x) dx $ by the dominated convergence theorem  : $l = \int_{0}^{+\infty} \lim_{n \to \infty}  \exp((\cos^n x) -x) dx$ I don't know how to deal with this limit, as $x$ is in $\mathbb{R_{+}}$ I can't even use a taylor expression around $0$ any hints ?","the exponential function being increasing we have so is Riemann absolutely convergent therefore by the dominated convergence theorem  : I don't know how to deal with this limit, as is in I can't even use a taylor expression around any hints ?","| \exp((\cos^n x) -x)| \leq \exp(1 -x) \in L^1([0,+\infty[)  x \to \exp((\cos^n x) -x) l = \lim_{n \to \infty} \int_{\mathbb{R_{+}}} \exp((\cos x^n) -x) d\lambda(x) =\lim_{n \to \infty} \int_{0}^{+\infty} \exp((\cos^n x) -x) dx  l = \int_{0}^{+\infty} \lim_{n \to \infty}  \exp((\cos^n x) -x) dx x \mathbb{R_{+}} 0","['integration', 'measure-theory', 'improper-integrals', 'lebesgue-integral', 'lebesgue-measure']"
15,Interchanging limit and integral.,Interchanging limit and integral.,,"Suppose $(X,\mu)$ is a probability space, $W\in L^1(X)$ , $V\in L^\infty(X)$ , and $V_n\to V$ in $L^2(X)$ (in my situation $V_n$ is the partial Fourier sum and so the $L^2(X)$ convergence is automatic). Can we say that $\int_X WVd\mu= \lim_{n\to\infty}\int_X WV_nd\mu$ ? I think so, but I am having trouble showing this. If $W$ is square integrable then the result follows from Cauchy-Schwarz. But of course this argument does not work for less regular $W$ . I have considered dominated convergence theorem and it's variation, but finding a dominating function is eluding me. Could anyone help out? Both suggestions and solutions are welcome. Thanks in advance!","Suppose is a probability space, , , and in (in my situation is the partial Fourier sum and so the convergence is automatic). Can we say that ? I think so, but I am having trouble showing this. If is square integrable then the result follows from Cauchy-Schwarz. But of course this argument does not work for less regular . I have considered dominated convergence theorem and it's variation, but finding a dominating function is eluding me. Could anyone help out? Both suggestions and solutions are welcome. Thanks in advance!","(X,\mu) W\in L^1(X) V\in L^\infty(X) V_n\to V L^2(X) V_n L^2(X) \int_X WVd\mu= \lim_{n\to\infty}\int_X WV_nd\mu W W","['measure-theory', 'fourier-analysis', 'lp-spaces', 'cauchy-schwarz-inequality', 'holder-inequality']"
16,Infinitesimal generator : what is it exactly?,Infinitesimal generator : what is it exactly?,,"Let $(X_t)$ an diffusion Itô process, i.e. a solution of $$dX_t=b(X_t)dt+\sigma (X_t)dB_t.$$ The infinitesimal generator of $(X_t)$ is $$Af(x)=\lim_{t\to 0^+}\frac{\mathbb E^x[f(X_t)]-f(x)}{t},$$ where $\mathbb E^x$ is the expectation wrt $\mathbb P^x$ . Q1) What represent exactly $Af(x)$ for $X_t$ ? For example, for a Brownian motion, if $f$ is $C^2$ then $$A f(x)=\frac{1}{2}\Delta f(x).$$ But I don't really understand which information does $A$ give is. Is it a sort of derivative of $X_t$ ? Q2) What is exactely the measure $\mathbb P^x$ ? I know it is $\mathbb P^x\{X_t\in A\}=\mathbb P(\{X_t\in A\}\mid \{X_0=x\}),$ But does it mean that on $(\Omega ,\mathcal F,\mathbb P^x)$ we have that $\mathbb P\{X_0=x\}=1$ ? (i.e. is deterministic).","Let an diffusion Itô process, i.e. a solution of The infinitesimal generator of is where is the expectation wrt . Q1) What represent exactly for ? For example, for a Brownian motion, if is then But I don't really understand which information does give is. Is it a sort of derivative of ? Q2) What is exactely the measure ? I know it is But does it mean that on we have that ? (i.e. is deterministic).","(X_t) dX_t=b(X_t)dt+\sigma (X_t)dB_t. (X_t) Af(x)=\lim_{t\to 0^+}\frac{\mathbb E^x[f(X_t)]-f(x)}{t}, \mathbb E^x \mathbb P^x Af(x) X_t f C^2 A f(x)=\frac{1}{2}\Delta f(x). A X_t \mathbb P^x \mathbb P^x\{X_t\in A\}=\mathbb P(\{X_t\in A\}\mid \{X_0=x\}), (\Omega ,\mathcal F,\mathbb P^x) \mathbb P\{X_0=x\}=1","['probability', 'measure-theory']"
17,Are projection valued measures continuous?,Are projection valued measures continuous?,,"Let $U_t$ be a one parameter subgroup of normal bounded operators on a complex Hilbert space $H$ . For each $t\in \mathbb{R}$ , $U_t$ defines on the Borel subsets of $\mathbb{C}$ a projection valued measure $P_t:\mathcal{B}(\mathbb{C}) \to B(H)$ . Now let $f \in C(\mathbb{C})$ is the map $F:\mathbb{R} \to B(H)$ defined by: $$ \int_{\mathbb{C}}f(s)dP_t(s)$$ Is it continuous. All of this is very new to me so I hope that the question makes sense.","Let be a one parameter subgroup of normal bounded operators on a complex Hilbert space . For each , defines on the Borel subsets of a projection valued measure . Now let is the map defined by: Is it continuous. All of this is very new to me so I hope that the question makes sense.",U_t H t\in \mathbb{R} U_t \mathbb{C} P_t:\mathcal{B}(\mathbb{C}) \to B(H) f \in C(\mathbb{C}) F:\mathbb{R} \to B(H)  \int_{\mathbb{C}}f(s)dP_t(s),"['measure-theory', 'operator-theory', 'spectral-theory']"
18,Is the function measurable with respect to Lebesgue measure,Is the function measurable with respect to Lebesgue measure,,"Let $h: [a,b]\rightarrow \mathbb{R}$ be a continuous function. For every $y\in \mathbb{R}$ , denote $$ S(y)=\begin{cases} 0 & \text{, if } h^{-1}(y) = \emptyset \\ \# h^{-1}(y) &\text{, if } h^{-1}(y) \text{ is finite}\\ \infty, &\text{, if } h^{-1}(y) \text{ is infinite}     \end{cases} $$ Is the function measurable (as a function from $\mathbb{R} \mapsto \mathbb{R}$ ) with respect to the Lebesgue measure in $\mathbb{R}$ ?","Let be a continuous function. For every , denote Is the function measurable (as a function from ) with respect to the Lebesgue measure in ?","h: [a,b]\rightarrow \mathbb{R} y\in \mathbb{R} 
S(y)=\begin{cases} 0 & \text{, if } h^{-1}(y) = \emptyset \\
\# h^{-1}(y) &\text{, if } h^{-1}(y) \text{ is finite}\\
\infty, &\text{, if } h^{-1}(y) \text{ is infinite}    
\end{cases}
 \mathbb{R} \mapsto \mathbb{R} \mathbb{R}","['real-analysis', 'measure-theory', 'lebesgue-measure']"
19,Showing a sequence of functions $f_n$ does not converge uniformly to $f$ on an interval.,Showing a sequence of functions  does not converge uniformly to  on an interval.,f_n f,"Suppose for each $n \in \mathbb{N}$ we have a function $f_n:[0,1] \to [0,1]$ by $f_n(x)=nx$ on the interval $x \in [0,\frac{1}{n}]$ and $1$ if $x \in (\frac{1}{n},1]$ , and define $f=\lim_{n \to \infty} f_n$ . I want to show that for any Lebesgue measurable $B \subseteq [0,1]$ with Lebesgue measure $\lambda(B)=0$ that the functions $f_n$ do not converge to $f$ uniformly on $[0,1] \backslash B$ . Now clearly we have the the limit $f$ is equal to $0$ at $x=0$ and is equal to $1$ elsewhere, but I am struggling to figure out how to implement the fact that we remove the zero measure interval $B$ . Firstly my thought was to use the uniform convergence theorem, which would work with showing that the functions $f_n$ do not converge uniformly to $f$ as each of the functions $f_n$ is continuous we can use the uniform limit theorem to show that $f_n$ does not converge to $f$ . I am wondering whether there is a simple result that I am missing that ensures this transfers to the same sort of result when we take away a set of measure $0$ , for example does continuity of each $f_n$ still hold in this case in which I can still apply the theorem? Any insight would be much appreciated thanks :)","Suppose for each we have a function by on the interval and if , and define . I want to show that for any Lebesgue measurable with Lebesgue measure that the functions do not converge to uniformly on . Now clearly we have the the limit is equal to at and is equal to elsewhere, but I am struggling to figure out how to implement the fact that we remove the zero measure interval . Firstly my thought was to use the uniform convergence theorem, which would work with showing that the functions do not converge uniformly to as each of the functions is continuous we can use the uniform limit theorem to show that does not converge to . I am wondering whether there is a simple result that I am missing that ensures this transfers to the same sort of result when we take away a set of measure , for example does continuity of each still hold in this case in which I can still apply the theorem? Any insight would be much appreciated thanks :)","n \in \mathbb{N} f_n:[0,1] \to [0,1] f_n(x)=nx x \in [0,\frac{1}{n}] 1 x \in (\frac{1}{n},1] f=\lim_{n \to \infty} f_n B \subseteq [0,1] \lambda(B)=0 f_n f [0,1] \backslash B f 0 x=0 1 B f_n f f_n f_n f 0 f_n","['measure-theory', 'lebesgue-measure']"
20,Why $\mathbb P(X_t=Y_t\text{ for all }t)=1$ if $\mathbb P(X_t=Y_t)=1$ for all $t$?,Why  if  for all ?,\mathbb P(X_t=Y_t\text{ for all }t)=1 \mathbb P(X_t=Y_t)=1 t,"Let $X_t$ and $Y_t$ two continuous stochastic process on $(\Omega ,\mathcal F,\mathbb P)$ s.t. $X_t=Y_t$ a.s. for all $t$ . Why $\mathbb P\{X_t=Y_t\text{ for all }t\}=1$ ? The solution goes as : We have that $X_r=Y_r$ a.s. for all $r\in\mathbb Q$ . Therefore, $\mathbb P\{\sup_{s\in\mathbb R}|X_s-Y_s|>0\}=0$ . The claim follow. I really don't understand the argument. And for me $\mathbb P(X_t=Y_t)=1$ for all $t$ is really the same as $\mathbb P(X_t=Y_t\text{ for all }t)=1$ . I don't see the difference.","Let and two continuous stochastic process on s.t. a.s. for all . Why ? The solution goes as : We have that a.s. for all . Therefore, . The claim follow. I really don't understand the argument. And for me for all is really the same as . I don't see the difference.","X_t Y_t (\Omega ,\mathcal F,\mathbb P) X_t=Y_t t \mathbb P\{X_t=Y_t\text{ for all }t\}=1 X_r=Y_r r\in\mathbb Q \mathbb P\{\sup_{s\in\mathbb R}|X_s-Y_s|>0\}=0 \mathbb P(X_t=Y_t)=1 t \mathbb P(X_t=Y_t\text{ for all }t)=1","['probability', 'measure-theory']"
21,Showing that a set is Lebesgue Measurable in Higher Dimensions and Applying Fubini's Theorem,Showing that a set is Lebesgue Measurable in Higher Dimensions and Applying Fubini's Theorem,,"I have an idea of how to proceed, but I'm suspicious that my efforts were of no use. Let $A\in\mathcal{M}$ be Lebesgue measurable, and let $g,h:A \rightarrow \bar{\mathbb{R}}$ be Lebesgue measurable functions with $g(x)\leq h(x) \ \forall x \in A$ . With this, we define $E=\{(x,y) \in \mathbb{R^2} : g(x) \leq y \leq h(x)\}$ . Prove that $E\in \mathcal{M^2}=\mathcal{M} \times \mathcal{M}$ . And following this, show that if $f:E \rightarrow [0,\infty]$ is $\mathcal{M^2}$ measurable, then $\displaystyle\int_Ef dm^2=\int_A(\int_{g(x)}^{h(x)}f(x,y) \ dy) \ dx$ , where $m^2=m \times m$ . For the first part, may we write $E=\{(x,y) \in \mathbb{R^2} : g(x) \leq y\} \cap \{(x,y) \in \mathbb{R^2} : y \leq h(x)\}$ $\Rightarrow E=\bigcup\limits_{q \in \mathbb{Q}} \{(x,y) \in \mathbb{R^2} : g(x) \leq q \leq y\} \cap \{(x,y) \in \mathbb{R^2} : y \leq q \leq h(x)\}$ and since $h$ and $g$ are measurable, this is a countable union of measurable sets? I don't feel so good about this reasoning, as I'm pretty sure that I would have to find a way to rewrite $E$ as cartesian product of 2 Lebesgue measurable sets (ideally, one with respect to x and the other with respect to y). So perhaps $E=(g^{-1}[-\infty,y]\cap h^{-1}[y,\infty]) \times \{y\}$ works instead? As for the second part, I'm not particularly sure how to use Fubini's in this scenario. I'd be very gracious for any help and guidance.","I have an idea of how to proceed, but I'm suspicious that my efforts were of no use. Let be Lebesgue measurable, and let be Lebesgue measurable functions with . With this, we define . Prove that . And following this, show that if is measurable, then , where . For the first part, may we write and since and are measurable, this is a countable union of measurable sets? I don't feel so good about this reasoning, as I'm pretty sure that I would have to find a way to rewrite as cartesian product of 2 Lebesgue measurable sets (ideally, one with respect to x and the other with respect to y). So perhaps works instead? As for the second part, I'm not particularly sure how to use Fubini's in this scenario. I'd be very gracious for any help and guidance.","A\in\mathcal{M} g,h:A \rightarrow \bar{\mathbb{R}} g(x)\leq h(x) \ \forall x \in A E=\{(x,y) \in \mathbb{R^2} : g(x) \leq y \leq h(x)\} E\in \mathcal{M^2}=\mathcal{M} \times \mathcal{M} f:E \rightarrow [0,\infty] \mathcal{M^2} \displaystyle\int_Ef dm^2=\int_A(\int_{g(x)}^{h(x)}f(x,y) \ dy) \ dx m^2=m \times m E=\{(x,y) \in \mathbb{R^2} : g(x) \leq y\} \cap \{(x,y) \in \mathbb{R^2} : y \leq h(x)\} \Rightarrow E=\bigcup\limits_{q \in \mathbb{Q}} \{(x,y) \in \mathbb{R^2} : g(x) \leq q \leq y\} \cap \{(x,y) \in \mathbb{R^2} : y \leq q \leq h(x)\} h g E E=(g^{-1}[-\infty,y]\cap h^{-1}[y,\infty]) \times \{y\}","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'measurable-functions']"
22,Improper integral over the rationals,Improper integral over the rationals,,"Question: Suppose that I wish to integrate a function over the natural numbers. How could I do this? Answer: Consider the definite integral $\int_a^bf(x)\ dx$ . If we consider this as the 'area under the curve' between $x=a$ and $x=b$ , then $\int_a^bf(x)\ dx$ is the sum of the areas infinitely many rectangles, each with an area of $f(x)\epsilon$ , where $\forall x\in\mathbb{R}^+.\epsilon<x$ . Thus: $$\int_a^bf(x)\ dx=\lim_{\epsilon\to0}\sum_{x=a}^{b/\epsilon}f(x)\epsilon$$ For $x\in\mathbb{N}$ , this is simply a finite sum, since there are no terms between $x=n$ and $x=n+1$ : $$\int_{M\subset\mathbb{N}}f(x)\ dx=\int_a^bf(x)\ dx=\lim_{\epsilon\to 0}\sum_{x=a}^{b}f(x)\epsilon\ \mid a,b,x\in\mathbb{N}$$ This summation is zero for all $a$ and $b$ , UNLESS $b=\infty$ and $a<b$ , in which case the infinite sum, corresponding to the improper integral $\int_a^\infty f(x)\ dx$ can be nonzero, the nicest case being $a=0$ : $$f:\mathbb{N}\to X\implies\int_0^\infty f(x)\ dx=\lim_{\epsilon\to0}\sum_{x=0}^\infty f(x)\epsilon>0$$ Evaluating this sum can be incredibly difficult, but it is possible. Now, the big question : What is the improper integral of $f(x)$ over the rationals? i.e.: $$f:\mathbb{Q}\to X\implies\int_0^\infty f(x)\ dx=\ \Large?$$ I would assume that because the rationals are dense $$f:\mathbb{Q}\to X\land g:\mathbb{N}\to X\implies\int_0^\infty f(x)\ dx\gg\int_0^\infty g(n)\ dn$$ This following from the fact that for a finite natural number $b$ : $$\sum_{0\leq x\leq b\\x\in\mathbb{Q}}f(x)\gg\sum_{0\leq x\leq b\\x\in\mathbb{N}}f(x)$$","Question: Suppose that I wish to integrate a function over the natural numbers. How could I do this? Answer: Consider the definite integral . If we consider this as the 'area under the curve' between and , then is the sum of the areas infinitely many rectangles, each with an area of , where . Thus: For , this is simply a finite sum, since there are no terms between and : This summation is zero for all and , UNLESS and , in which case the infinite sum, corresponding to the improper integral can be nonzero, the nicest case being : Evaluating this sum can be incredibly difficult, but it is possible. Now, the big question : What is the improper integral of over the rationals? i.e.: I would assume that because the rationals are dense This following from the fact that for a finite natural number :","\int_a^bf(x)\ dx x=a x=b \int_a^bf(x)\ dx f(x)\epsilon \forall x\in\mathbb{R}^+.\epsilon<x \int_a^bf(x)\ dx=\lim_{\epsilon\to0}\sum_{x=a}^{b/\epsilon}f(x)\epsilon x\in\mathbb{N} x=n x=n+1 \int_{M\subset\mathbb{N}}f(x)\ dx=\int_a^bf(x)\ dx=\lim_{\epsilon\to 0}\sum_{x=a}^{b}f(x)\epsilon\ \mid a,b,x\in\mathbb{N} a b b=\infty a<b \int_a^\infty f(x)\ dx a=0 f:\mathbb{N}\to X\implies\int_0^\infty f(x)\ dx=\lim_{\epsilon\to0}\sum_{x=0}^\infty f(x)\epsilon>0 f(x) f:\mathbb{Q}\to X\implies\int_0^\infty f(x)\ dx=\ \Large? f:\mathbb{Q}\to X\land g:\mathbb{N}\to X\implies\int_0^\infty f(x)\ dx\gg\int_0^\infty g(n)\ dn b \sum_{0\leq x\leq b\\x\in\mathbb{Q}}f(x)\gg\sum_{0\leq x\leq b\\x\in\mathbb{N}}f(x)","['sequences-and-series', 'measure-theory', 'improper-integrals', 'nonstandard-analysis', 'indeterminate-forms']"
23,Find the Lebesgue set w.r.t. to the functions,Find the Lebesgue set w.r.t. to the functions,,"I'm working on a problem in measure theory: Find the Lebesgue set $L_f=\{x:\lim_{r\to 0} \frac{1}{m(B(r,x))} \int_{B(r,x)}\lvert f(y)-f(x)\rvert dy=0\}$ if: $f:\mathbb R^n \to \mathbb C$ is continuous $f=\chi_{E}$ , where $E\in\mathbb R^n$ is Lebesgue null; $m(E)=0$ . $\chi$ denotes the indicator function. $f(x)=\lfloor x\rfloor$ on $\mathbb R$ I'm having a bit of a tough time wrapping my head around what the Lebesgue sets really are, and consequently is struggling to characterize the Lebesgue sets w.r.t to these functions. I could really use some help on these!","I'm working on a problem in measure theory: Find the Lebesgue set if: is continuous , where is Lebesgue null; . denotes the indicator function. on I'm having a bit of a tough time wrapping my head around what the Lebesgue sets really are, and consequently is struggling to characterize the Lebesgue sets w.r.t to these functions. I could really use some help on these!","L_f=\{x:\lim_{r\to 0} \frac{1}{m(B(r,x))} \int_{B(r,x)}\lvert f(y)-f(x)\rvert dy=0\} f:\mathbb R^n \to \mathbb C f=\chi_{E} E\in\mathbb R^n m(E)=0 \chi f(x)=\lfloor x\rfloor \mathbb R","['real-analysis', 'measure-theory']"
24,Is it possible to prove Fubini’s Theorem without Dynkin’s Theorem or the Monotone Class Theorem?,Is it possible to prove Fubini’s Theorem without Dynkin’s Theorem or the Monotone Class Theorem?,,"Fubini’s Theorem for Lebesgue integrals states that if $X$ and $Y$ are Sigma-finite measure spaces then the integral of a (well-behaved) function $f(x,y)$ with respect to the product measure on $X\times Y$ is equal to the iterated integral of $f$ with respect to the measure on $X$ and the measure on $Y$ . The standard way to prove Fubini’s theorem is to prove it first for characteristic functions, then for simple functions, then for non-negative measurable functions, etc. The hard part is proving it for characteristic functions.  You first prove it for characteristic functions of measurable rectangles, i.e. Cartesian products of measurable sets in $X$ and measurable sets in $Y$ . Then you have to somehow use that to prove it for characteristic functions of all measurable sets in the product measure space.  This is usually done using one of two theorems: Dynkin’s pi-lambda theorem , which states that if a pi-system of sets is contained in a lambda-system of sets, then the sigma algebra generated by the pi-system is also contained in the lambda system. Halmos’ monotone class theorem , which states that if an algebra of sets is contained in a monotone class of sets, then the sigma algebra generated by the algebra is also contained in the monotone class. Both these theorems apply because the collection of measurable rectangles is both a pi-system and an algebra, and the collection of sets whose characteristic functions satisfy Fubini’s theorem is both a lambda-system anda monotone class. My question is, is it possible to prove Fubini’s theorem without using either of these results?  I assume that there would be some way, considering that Fubini proved his theorem long before Eugene Dynkin and Paul Halmos were even born.","Fubini’s Theorem for Lebesgue integrals states that if and are Sigma-finite measure spaces then the integral of a (well-behaved) function with respect to the product measure on is equal to the iterated integral of with respect to the measure on and the measure on . The standard way to prove Fubini’s theorem is to prove it first for characteristic functions, then for simple functions, then for non-negative measurable functions, etc. The hard part is proving it for characteristic functions.  You first prove it for characteristic functions of measurable rectangles, i.e. Cartesian products of measurable sets in and measurable sets in . Then you have to somehow use that to prove it for characteristic functions of all measurable sets in the product measure space.  This is usually done using one of two theorems: Dynkin’s pi-lambda theorem , which states that if a pi-system of sets is contained in a lambda-system of sets, then the sigma algebra generated by the pi-system is also contained in the lambda system. Halmos’ monotone class theorem , which states that if an algebra of sets is contained in a monotone class of sets, then the sigma algebra generated by the algebra is also contained in the monotone class. Both these theorems apply because the collection of measurable rectangles is both a pi-system and an algebra, and the collection of sets whose characteristic functions satisfy Fubini’s theorem is both a lambda-system anda monotone class. My question is, is it possible to prove Fubini’s theorem without using either of these results?  I assume that there would be some way, considering that Fubini proved his theorem long before Eugene Dynkin and Paul Halmos were even born.","X Y f(x,y) X\times Y f X Y X Y","['measure-theory', 'lebesgue-integral', 'math-history', 'alternative-proof', 'multiple-integral']"
25,$f = g$ almost everywhere implies $f =g$ for any continuous function $f$ and $g$.,almost everywhere implies  for any continuous function  and .,f = g f =g f g,"Let $f,g : [0,T] \to X$ be continuous $X$ -valued functions for Banach Space $(X,||\, \cdot\,||)$ . Suppose that $f = g$ almost everywhere in $C([0,T],X)$ , then $f = g$ in $C([0,T],X)$ . This is my attempt so far : First, $f = g$ almost everywhere in $C([0,T],X)$ means $\forall t \in [0,T]\backslash M, f(t) = g(t)$ for some $M$ measure zero set. Therefore, our claim is $M \neq \emptyset$ . By contradiction, suppose there exists $t_{1} \in M\subset [0,T]$ such that $f(t_{1}) \neq g(t_{1})$ . Then, we know that $||f(t_{1}) - g(t_{1})|| \neq 0$ . Furthermore, from our assumption, we know that $\forall t \in [0,T]\backslash M, ||f(t) - g(t)|| = 0$ . However, since $f$ and $g$ are in $C([0,T],X)$ , then $\forall \varepsilon > 0, \exists \delta > 0$ such that $\forall t \in (t_{1}-\delta, t_{1}+\delta), f(t)\neq g(t)$ . Therefore, $\forall t \in (t_{1}-\delta, t_{1}+\delta), ||f(t) - g(t)||\neq 0$ . Fix $\varepsilon = \varepsilon_{1}$ to obtain $\delta = \delta_{1}$ . Then, $(t_{1}-\delta_{1},t_{1}+\delta_{1}) \subset M$ which means measure of $M$ is not zero. This is a contradiction and therefore $M = \emptyset$ which implies $\forall t \in [0,T], f(t) = g(t)$ in $C([0,T],X)$ . So my question is where did I make any mistake? Also, I want to make this argument more rigorous so I would like to ensure $f(t) \neq g(t)$ in $(t_{1} - \delta_{1}, t_{1} + \delta_{1}$ ). Is my reasoning enough to ensure that? I tried to use $\varepsilon_{1} = \frac{1}{2}||f(t_{1}) - g(t_{1})||$ but I am unsure whether I am correct or not. Any help is very much appreciated! Thank you!","Let be continuous -valued functions for Banach Space . Suppose that almost everywhere in , then in . This is my attempt so far : First, almost everywhere in means for some measure zero set. Therefore, our claim is . By contradiction, suppose there exists such that . Then, we know that . Furthermore, from our assumption, we know that . However, since and are in , then such that . Therefore, . Fix to obtain . Then, which means measure of is not zero. This is a contradiction and therefore which implies in . So my question is where did I make any mistake? Also, I want to make this argument more rigorous so I would like to ensure in ). Is my reasoning enough to ensure that? I tried to use but I am unsure whether I am correct or not. Any help is very much appreciated! Thank you!","f,g : [0,T] \to X X (X,||\, \cdot\,||) f = g C([0,T],X) f = g C([0,T],X) f = g C([0,T],X) \forall t \in [0,T]\backslash M, f(t) = g(t) M M \neq \emptyset t_{1} \in M\subset [0,T] f(t_{1}) \neq g(t_{1}) ||f(t_{1}) - g(t_{1})|| \neq 0 \forall t \in [0,T]\backslash M, ||f(t) - g(t)|| = 0 f g C([0,T],X) \forall \varepsilon > 0, \exists \delta > 0 \forall t \in (t_{1}-\delta, t_{1}+\delta), f(t)\neq g(t) \forall t \in (t_{1}-\delta, t_{1}+\delta), ||f(t) - g(t)||\neq 0 \varepsilon = \varepsilon_{1} \delta = \delta_{1} (t_{1}-\delta_{1},t_{1}+\delta_{1}) \subset M M M = \emptyset \forall t \in [0,T], f(t) = g(t) C([0,T],X) f(t) \neq g(t) (t_{1} - \delta_{1}, t_{1} + \delta_{1} \varepsilon_{1} = \frac{1}{2}||f(t_{1}) - g(t_{1})||","['measure-theory', 'continuity', 'banach-spaces', 'almost-everywhere']"
26,"$\mu,\nu$ $\sigma$-finite and $\nu \le \mu$. Then there exists a $\mu$-almost-everywhere unique function $f$ with $0 \le f \le 1 \ \mu \ a.e.$",-finite and . Then there exists a -almost-everywhere unique function  with,"\mu,\nu \sigma \nu \le \mu \mu f 0 \le f \le 1 \ \mu \ a.e.","Let $\mu,\nu$ be $\sigma$ -finite on $(\Omega,\mathcal{A})$ and $\nu  \le \mu$ . Then there exists a $\mu$ -almost-everywhere unique function $f=\frac{d\nu}{d\mu}$ with $0 \le f \le 1 \ \mu \ a.e.$ As both measures are $\sigma$ finite and $\nu \le \mu \Rightarrow \nu << \mu$ the Radon-Nikodym-Theorem tell us that there exists such a function $f$ which fulfils $f\ge 0$ $\mu \ a.e.$ and this $f$ is unique $a.e.$ The only thing that is left to show is that $f \le 1 \ a.e.$ . For this I tried a proof by contradiction: Let $A \in \mathcal A$ with $\mu (A)>0$ and $\forall x \in A:f(x)>1$ Then $\nu(A)=\int_A f d \mu>\int_A 1 d \mu=\mu(A)$ which is a contradiction because $\nu \le \mu$ and therefore $f \le 1 \ a.e$ . Is my way to show $f \le1$ correct?",Let be -finite on and . Then there exists a -almost-everywhere unique function with As both measures are finite and the Radon-Nikodym-Theorem tell us that there exists such a function which fulfils and this is unique The only thing that is left to show is that . For this I tried a proof by contradiction: Let with and Then which is a contradiction because and therefore . Is my way to show correct?,"\mu,\nu \sigma (\Omega,\mathcal{A}) \nu  \le \mu \mu f=\frac{d\nu}{d\mu} 0 \le f \le 1 \ \mu \ a.e. \sigma \nu \le \mu \Rightarrow \nu << \mu f f\ge 0 \mu \ a.e. f a.e. f \le 1 \ a.e. A \in \mathcal A \mu (A)>0 \forall x \in A:f(x)>1 \nu(A)=\int_A f d \mu>\int_A 1 d \mu=\mu(A) \nu \le \mu f \le 1 \ a.e f \le1",['measure-theory']
27,Inequality of real numbers with exponent,Inequality of real numbers with exponent,,"For $a,b>0$ are two real numbers and $p\geq 1$ . Is the following inequality true $$|a^p-b^p|\leq|a-b|^p\;\;?$$",For are two real numbers and . Is the following inequality true,"a,b>0 p\geq 1 |a^p-b^p|\leq|a-b|^p\;\;?","['real-analysis', 'measure-theory', 'inequality', 'lp-spaces']"
28,Is every measure $0$ set a set of discontinuities of a Riemann integrable function?,Is every measure  set a set of discontinuities of a Riemann integrable function?,0,"Let $f:[a,b]\rightarrow\mathbb{R}$ be bounded, and let $D$ be its set of discontinuities.  Then Lebesgue's criterion states that $f$ is Riemann-integrable if and only if $D$ has Lebesgue measure $0$ . My question is, for any subset $D$ of $[a,b]$ with Lebesgue measure $0$ , does there exist a Riemann integrable function $f:[a,b]\rightarrow\mathbb{R}$ whose set of discontinuities is $D$ ?  Would the characteristic function of $D$ suffice, or is more complicated than that?","Let be bounded, and let be its set of discontinuities.  Then Lebesgue's criterion states that is Riemann-integrable if and only if has Lebesgue measure . My question is, for any subset of with Lebesgue measure , does there exist a Riemann integrable function whose set of discontinuities is ?  Would the characteristic function of suffice, or is more complicated than that?","f:[a,b]\rightarrow\mathbb{R} D f D 0 D [a,b] 0 f:[a,b]\rightarrow\mathbb{R} D D","['real-analysis', 'measure-theory', 'lebesgue-measure', 'riemann-integration', 'continuity']"
29,Proving pointwise convergence almost everywhere,Proving pointwise convergence almost everywhere,,"I would like to prove the following statement: Let $(X, F, \mu)$ be a measure space, not necessarily finite. Suppose that for every $\epsilon > 0$ there exists a natural number $N$ such that $ \mu(\bigcup_{n = N}^{\infty} \{x \in X : |(f_n(x) - f(x)| > \epsilon \}) < \epsilon $ . Then $f_n \to f$ pointwise almost everywhere. My idea was to prove the statement by contradiction, i.e. assuming the negation of pointwise convergence almost everywhere: Suppose there exists an $\epsilon'$ such that for all $N$ there exists an $n \geq N$ with $|f_n(x) - f(x)| > \epsilon$ for almost every $x \in X$ . By assumption we know that for any $\epsilon$ , in particular for $\epsilon'$ , we can find an $N_0$ such that for all $n \geq N_0$ we have $|f_n(x) - f(x)| > \epsilon'$ for almost every $x \in X$ . I thought this would imply that $\mu(\bigcup_{n = N_0}^{\infty} \{x \in X : |(f_n(x) - f(x)| > \epsilon' \}) = \mu(X)$ , but even if that were the case, I do not see a way to reach a contradiction as I cannot assume that $\mu(X) > \epsilon$ , I've probably made a mistake, but I cannot see where. Is there any way I could complete this proof, or is there a better way? Thank you in advance.","I would like to prove the following statement: Let be a measure space, not necessarily finite. Suppose that for every there exists a natural number such that . Then pointwise almost everywhere. My idea was to prove the statement by contradiction, i.e. assuming the negation of pointwise convergence almost everywhere: Suppose there exists an such that for all there exists an with for almost every . By assumption we know that for any , in particular for , we can find an such that for all we have for almost every . I thought this would imply that , but even if that were the case, I do not see a way to reach a contradiction as I cannot assume that , I've probably made a mistake, but I cannot see where. Is there any way I could complete this proof, or is there a better way? Thank you in advance.","(X, F, \mu) \epsilon > 0 N  \mu(\bigcup_{n = N}^{\infty} \{x \in X : |(f_n(x) - f(x)| > \epsilon \}) < \epsilon  f_n \to f \epsilon' N n \geq N |f_n(x) - f(x)| > \epsilon x \in X \epsilon \epsilon' N_0 n \geq N_0 |f_n(x) - f(x)| > \epsilon' x \in X \mu(\bigcup_{n = N_0}^{\infty} \{x \in X : |(f_n(x) - f(x)| > \epsilon' \}) = \mu(X) \mu(X) > \epsilon","['measure-theory', 'convergence-divergence']"
30,"Show that $\mathbb Q\cap [0,1]$ is not Jordan measurable.",Show that  is not Jordan measurable.,"\mathbb Q\cap [0,1]","I'm trying to show two things: 1. $J^*([0,1])=1$ , where $J^*$ is the Jordan outer measure. 2. $\mathbb Q\cap [0,1]$ is not Jordan measurable - i.e. the Jordan outer and inner measures do not agree. The Jordan measures here are defined on finite union of open intervals. Any hints or proof help would be greatly appreciated.","I'm trying to show two things: 1. , where is the Jordan outer measure. 2. is not Jordan measurable - i.e. the Jordan outer and inner measures do not agree. The Jordan measures here are defined on finite union of open intervals. Any hints or proof help would be greatly appreciated.","J^*([0,1])=1 J^* \mathbb Q\cap [0,1]",['measure-theory']
31,Choosing eigenvectors and eigenvalues continuously,Choosing eigenvectors and eigenvalues continuously,,"Let $H=L^2(X)$ for some compact space $X$ . We denote by $U(H)$ the space of unitary operators on $H$ with the topology induced by the operator norm. Given a continuous map $t\mapsto S_t$ from $[0,1]$ to $U(H)$ . Is there a continuous (or at least Borel) maps $t\mapsto \lambda_t$ and $t\mapsto f_t$ the first with values in $S^1$ and the second with values in $H\backslash\{0\}$ such that $S_t f_t =\lambda_t f_t$ ?",Let for some compact space . We denote by the space of unitary operators on with the topology induced by the operator norm. Given a continuous map from to . Is there a continuous (or at least Borel) maps and the first with values in and the second with values in such that ?,"H=L^2(X) X U(H) H t\mapsto S_t [0,1] U(H) t\mapsto \lambda_t t\mapsto f_t S^1 H\backslash\{0\} S_t f_t =\lambda_t f_t","['general-topology', 'measure-theory', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
32,Exercise 4.E - The Elements of Integration and Lebesgue Measure by Bartle,Exercise 4.E - The Elements of Integration and Lebesgue Measure by Bartle,,"$4.E.$ Let $f,g\in M^{+},$ let $\omega\in M^{+}$ be a simple function such that $\omega\leq f+g$ and let $\phi_{n}(x)=\sup\{(m/n)\omega(x): 0\leq  m\leq n, (m/n)\omega(x)\leq f(x)\}$ . Also let $\psi_{n}(x)=\sup\{(1-\frac{1}{n})\omega(x)-\phi_{n}(x),0\}$ . Show that $(1-\frac{1}{n})\omega\leq\psi_{n}+\phi_{n}$ , $\phi_{n}\leq f$ , $\psi_{n}\leq g$ . I was able to prove the first two inequalities, it's just use the definition of $\phi_n$ and $\psi_n$ and observe that $f$ is an upper bound for the set $\{(m/n)\omega(x): 0\leq  m\leq n, (m/n)\omega(x)\leq f(x)\}$ , but I'm stuck in prove that $\psi_n \leq g$ . Can anyone give me a hint in order to prove this inequality? $\textbf{P.S.: read the comments of mojobask's answer.}$","Let let be a simple function such that and let . Also let . Show that , , . I was able to prove the first two inequalities, it's just use the definition of and and observe that is an upper bound for the set , but I'm stuck in prove that . Can anyone give me a hint in order to prove this inequality?","4.E. f,g\in M^{+}, \omega\in M^{+} \omega\leq f+g \phi_{n}(x)=\sup\{(m/n)\omega(x): 0\leq 
m\leq n, (m/n)\omega(x)\leq f(x)\} \psi_{n}(x)=\sup\{(1-\frac{1}{n})\omega(x)-\phi_{n}(x),0\} (1-\frac{1}{n})\omega\leq\psi_{n}+\phi_{n} \phi_{n}\leq f \psi_{n}\leq g \phi_n \psi_n f \{(m/n)\omega(x): 0\leq 
m\leq n, (m/n)\omega(x)\leq f(x)\} \psi_n \leq g \textbf{P.S.: read the comments of mojobask's answer.}",['measure-theory']
33,"If $\int f(x)dx\leq \liminf\int f_n(x) dx$, then $\lim\limits_{n\to\infty}\int f_n(x)dx=\int \lim\limits_{n\to\infty}f_n(x)dx=\int f(x)dx$","If , then",\int f(x)dx\leq \liminf\int f_n(x) dx \lim\limits_{n\to\infty}\int f_n(x)dx=\int \lim\limits_{n\to\infty}f_n(x)dx=\int f(x)dx,"I found this question in my schools's Riemann's past question. Let $\{f_n\}$ be a sequence of non-negative function which converges to an integrable function $f$ and supposing $ f_{n}\leq f(x)$ for each $n$. It is known that  \begin{align} \int f(x)dx\leq \liminf\int f_n(x) dx\end{align} Then, show that \begin{align} \lim\limits_{n\to\infty}\int f_n(x)dx=\int \lim\limits_{n\to\infty}f_n(x)dx=\int f(x)dx\end{align} QUESTIONS I believe this question is based on measure theory. Should this question appear at all in Riemann integration? Can we do this proof by Riemann integration? If no, then I'll need help but below is my trial. MY TRIAL Since $f_{n}\leq f(x)$ for each $n$, then \begin{align} \int \liminf f_n(x)dx \leq\int f(x)dx\end{align} I cannot interchange limit and integral since I am not sure if $f_n$ converges to $f$ uniformly. SO, I'm stuck here. Please, can someone help me? Mind you I have not been introduced to Measure theory yet but I can learn the steps if someone puts me through. That's if there's no other way but Measure theory approach. Thanks!","I found this question in my schools's Riemann's past question. Let $\{f_n\}$ be a sequence of non-negative function which converges to an integrable function $f$ and supposing $ f_{n}\leq f(x)$ for each $n$. It is known that  \begin{align} \int f(x)dx\leq \liminf\int f_n(x) dx\end{align} Then, show that \begin{align} \lim\limits_{n\to\infty}\int f_n(x)dx=\int \lim\limits_{n\to\infty}f_n(x)dx=\int f(x)dx\end{align} QUESTIONS I believe this question is based on measure theory. Should this question appear at all in Riemann integration? Can we do this proof by Riemann integration? If no, then I'll need help but below is my trial. MY TRIAL Since $f_{n}\leq f(x)$ for each $n$, then \begin{align} \int \liminf f_n(x)dx \leq\int f(x)dx\end{align} I cannot interchange limit and integral since I am not sure if $f_n$ converges to $f$ uniformly. SO, I'm stuck here. Please, can someone help me? Mind you I have not been introduced to Measure theory yet but I can learn the steps if someone puts me through. That's if there's no other way but Measure theory approach. Thanks!",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'riemann-integration']"
34,Converse of Comparison Theorems for Lebesgue Integrals,Converse of Comparison Theorems for Lebesgue Integrals,,"Let $(\Omega,\mathcal{F},\mu)$ be a measure space and $f,g:\Omega\to[0,\infty]$ be two non-negative measurable functions. If $\forall A\in\mathcal{F}: \int_A fd\mu\geq \int_A gd\mu$, can we conclude $f\geq g \, \mu-$a.e.? I know that in case $f,g:\Omega\to\mathbb{R}$ and $f,g\in L^1(\mu)$ the result holds, since $\infty-\infty$ does not happen and the theorem becomes equivalent to $\forall A\in\mathcal{F}: \int_A f-gd\mu\geq0\implies f-g\geq0\, \mu-$a.e., which I know the proof. Is this still true without $L^1$ assumption for non-negative measurable functions, where integral can become $+\infty$ and how can I prove that?","Let $(\Omega,\mathcal{F},\mu)$ be a measure space and $f,g:\Omega\to[0,\infty]$ be two non-negative measurable functions. If $\forall A\in\mathcal{F}: \int_A fd\mu\geq \int_A gd\mu$, can we conclude $f\geq g \, \mu-$a.e.? I know that in case $f,g:\Omega\to\mathbb{R}$ and $f,g\in L^1(\mu)$ the result holds, since $\infty-\infty$ does not happen and the theorem becomes equivalent to $\forall A\in\mathcal{F}: \int_A f-gd\mu\geq0\implies f-g\geq0\, \mu-$a.e., which I know the proof. Is this still true without $L^1$ assumption for non-negative measurable functions, where integral can become $+\infty$ and how can I prove that?",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
35,Norm of a functional defined by an integral,Norm of a functional defined by an integral,,"Show that $\phi: L^{\frac{3}{2}}\left(\left(0,\frac{1}{2} \right] \right) \to \mathbb{R}$ defined by $$u\mapsto\int_0^{\frac{1}{2}}u \, dx$$ is linear. Find $\|\phi\|_{\mathcal{L}}$. My try Clearly $\forall u, v\in L^{\frac{3}{2}}\left(\left(0,\frac{1}{2}\right]\right)$ and $\lambda\in\mathbb{R}$ $\\ \phi(u+v)=\int_{0}^{\frac{1}{2}}(u+v)dx=\\ =\int_{0}^{\frac{1}{2}} u \, dx+\int_0^{\frac{1}{2}} v \, dx=\\ =\phi(u)+\phi(v)$ $\phi(\lambda u)=\int_{0}^{\frac{1}{2}}\lambda u \, dx = \lambda \int_0^{\frac{1}{2}} u \, dx=\lambda\phi(u)$ so the linearity of the functional is easy to prove (right?), but what can I do to evaluate its norm? Maybe it can be useful the Holder Inequality? I think it's not the right idea. Any help would be appreciated.","Show that $\phi: L^{\frac{3}{2}}\left(\left(0,\frac{1}{2} \right] \right) \to \mathbb{R}$ defined by $$u\mapsto\int_0^{\frac{1}{2}}u \, dx$$ is linear. Find $\|\phi\|_{\mathcal{L}}$. My try Clearly $\forall u, v\in L^{\frac{3}{2}}\left(\left(0,\frac{1}{2}\right]\right)$ and $\lambda\in\mathbb{R}$ $\\ \phi(u+v)=\int_{0}^{\frac{1}{2}}(u+v)dx=\\ =\int_{0}^{\frac{1}{2}} u \, dx+\int_0^{\frac{1}{2}} v \, dx=\\ =\phi(u)+\phi(v)$ $\phi(\lambda u)=\int_{0}^{\frac{1}{2}}\lambda u \, dx = \lambda \int_0^{\frac{1}{2}} u \, dx=\lambda\phi(u)$ so the linearity of the functional is easy to prove (right?), but what can I do to evaluate its norm? Maybe it can be useful the Holder Inequality? I think it's not the right idea. Any help would be appreciated.",,"['functional-analysis', 'measure-theory', 'definite-integrals']"
36,Covering $X^2$ with countable subsets of $X$ for uncountable set $X$,Covering  with countable subsets of  for uncountable set,X^2 X X,"Let $X$ be an uncountable set and consider a map $x\mapsto C_x$ assigning to every $x\in X$ a countable subset $C_x$ of $X$. Now for any $x\in X$ define $$R_x:=\{x'\in X|x\in C_{x'}\}.$$ Obviously $R_x$ can be any subset of $X$. It is also clear that $R_x=X$ can hold for at most countably many $x$. But what happens if $R_x$ is just a bit smaller than $X$? Specifically, is it possible that $R_x$ is co-countable for all $x$? My intuition says NO. It is based on the following picture. For each $x$ $C_x$ can be taken to define a column in $X^2$: $$C_x':=\{(x,y)\in X^2|y\in C_x\}.$$ The union of all these columns defines a very ""sparse"" subset of $X^2$. The union can also be written as the union of all rows. If these rows would all be co-countable, the set doesn't look that ""sparse"" anymore. However, making this precise by turning $X^2$ into a measure space doesn't seem the way to go as the sets $C_x$ can be very wild.","Let $X$ be an uncountable set and consider a map $x\mapsto C_x$ assigning to every $x\in X$ a countable subset $C_x$ of $X$. Now for any $x\in X$ define $$R_x:=\{x'\in X|x\in C_{x'}\}.$$ Obviously $R_x$ can be any subset of $X$. It is also clear that $R_x=X$ can hold for at most countably many $x$. But what happens if $R_x$ is just a bit smaller than $X$? Specifically, is it possible that $R_x$ is co-countable for all $x$? My intuition says NO. It is based on the following picture. For each $x$ $C_x$ can be taken to define a column in $X^2$: $$C_x':=\{(x,y)\in X^2|y\in C_x\}.$$ The union of all these columns defines a very ""sparse"" subset of $X^2$. The union can also be written as the union of all rows. If these rows would all be co-countable, the set doesn't look that ""sparse"" anymore. However, making this precise by turning $X^2$ into a measure space doesn't seem the way to go as the sets $C_x$ can be very wild.",,"['measure-theory', 'set-theory']"
37,Exercise 1.21 of Villani Topics in Optimal Transportation,Exercise 1.21 of Villani Topics in Optimal Transportation,,"I'm stuck on this exercise, can you please help me? 1.2.2. Transshipment. The Kantorovich-Rubinstein theorem implies that   the total cost only depends on the difference $\mu-\nu$ . Thus, when the cost   function is a metric, the Kantorovich optimal transportation problem is   equivalent to the Kantorovich-Rubinstein transshipment problem : $$\inf \{I[\pi] ; \quad \pi[A \times X]-\pi[X \times A]=(\mu-\nu)[A]\}$$ The condition appearing above should be compared to the condition for $\pi \in \Pi(\mu, \nu),$ which is $\pi[A \times X]=\mu[A], \pi[X \times A]=\nu[A] .$ For a general cost function, the transshipment problem is a strongly relaxed version of   the transportation problem. For instance, in the case of a quadratic cost   in $\mathbb{R}^{n},$ the optimal transshipment cost between two given measures is in   general 0. We shall not study the transhipment problem in this course, and   refer to $[211]$ for motivations and detailed study. Exercise 1.20. Give an interpretation of the Kantorovich-Rubinstein transshipment problem in (say) economics terms; contrast this interpretation with   that of the Monge-Kantorovich problem. Exercise 1.21 (Transshipment sometimes costs (almost) nothing). Let $c(x, y)=|x-y|^{2}$ in $\mathbb{R}^{n},$ and let $\mu, \nu$ be two probability measures   on $\mathbb{R}^{n},$ such that $\mathcal T_{c}(\mu, \nu)<+\infty .$ Let $\pi \in \Pi(\mu, \nu)$ be any transference plan such that $I[\pi]<+\infty$ . Of course this transference plan can also be   considered as a transhipment plan, with an associated transshiping cost.   In order to lower this transshipment cost, you wish to improve this plan,   and you come up with the following strategy. Whenever $x$ and $y$ are some   initial and final points, respectively, instead of shipping $x$ to $y,$ you ship $x$ to $(x+y) / 2$ and simultaneously $(x+y) / 2$ to $y$ . Show that this strategy   can be implemented with an admissible transshipment plan, and express it   in terms of image measures of $\pi .$ Make a schematic picture of how $\pi$ is modified by this transformation. Show that the cost has been lowered by a   factor $2 .$ Deduce that the optimal transshipment cost is $0,$ which of course   is not attained unless $\mu=\nu .$ Show that the conclusion is still valid for any power $|x-y|^{p}, p>1,$ or more generally as soon as $c(x, y)=\phi(|x-y|)$ where $\phi$ is nondecreasing on $\mathbb{R}_{+}, \phi(0)=0, \phi^{\prime}(0)=0$ . (Original screenshot of text - Text Part 1 Text Part 2 ) Following the notation of the book, $\Pi(\mu,\nu)$ is the set of probability measures $\pi$ on $\mathbb{R}^n\times \mathbb{R}^n $ such that $$\pi(A\times \mathbb{R}^n )= \mu(A), \qquad \pi( \mathbb{R}^n \times A)= \nu(A)$$ and $$I[\pi]:=\int_{\mathbb{R}^n\times \mathbb{R}^n} c(x,y)\,d\pi(x,y)$$ and $$\mathcal{T}_{c}(\mu,\nu):=\inf_{\pi \in \Pi(\mu,\nu)}I[\pi]\,. $$ Following the hint in the exercise, my attempt was to consider the measure $$\pi':= \frac{c(x,\frac{x+y}{2})}{c(x,y)}\cdot T_{1}\sharp \pi+ \frac{c(\frac{x+y}{2},y)}{c(x,y)}\cdot T_{2}\sharp \pi$$ where $$T_{1}: (x,y)\mapsto (x, \frac{x+y}{2}) $$ $$T_{2}: (x,y)\mapsto (\frac{x+y}{2}, y ) $$ but I haven't been able to show that $I[\pi']\leq\frac{1}{2}I[\pi]$ .","I'm stuck on this exercise, can you please help me? 1.2.2. Transshipment. The Kantorovich-Rubinstein theorem implies that   the total cost only depends on the difference . Thus, when the cost   function is a metric, the Kantorovich optimal transportation problem is   equivalent to the Kantorovich-Rubinstein transshipment problem : The condition appearing above should be compared to the condition for which is For a general cost function, the transshipment problem is a strongly relaxed version of   the transportation problem. For instance, in the case of a quadratic cost   in the optimal transshipment cost between two given measures is in   general 0. We shall not study the transhipment problem in this course, and   refer to for motivations and detailed study. Exercise 1.20. Give an interpretation of the Kantorovich-Rubinstein transshipment problem in (say) economics terms; contrast this interpretation with   that of the Monge-Kantorovich problem. Exercise 1.21 (Transshipment sometimes costs (almost) nothing). Let in and let be two probability measures   on such that Let be any transference plan such that . Of course this transference plan can also be   considered as a transhipment plan, with an associated transshiping cost.   In order to lower this transshipment cost, you wish to improve this plan,   and you come up with the following strategy. Whenever and are some   initial and final points, respectively, instead of shipping to you ship to and simultaneously to . Show that this strategy   can be implemented with an admissible transshipment plan, and express it   in terms of image measures of Make a schematic picture of how is modified by this transformation. Show that the cost has been lowered by a   factor Deduce that the optimal transshipment cost is which of course   is not attained unless Show that the conclusion is still valid for any power or more generally as soon as where is nondecreasing on . (Original screenshot of text - Text Part 1 Text Part 2 ) Following the notation of the book, is the set of probability measures on such that and and Following the hint in the exercise, my attempt was to consider the measure where but I haven't been able to show that .","\mu-\nu \inf \{I[\pi] ; \quad \pi[A \times X]-\pi[X \times A]=(\mu-\nu)[A]\} \pi \in \Pi(\mu, \nu), \pi[A \times X]=\mu[A], \pi[X \times A]=\nu[A] . \mathbb{R}^{n}, [211] c(x, y)=|x-y|^{2} \mathbb{R}^{n}, \mu, \nu \mathbb{R}^{n}, \mathcal T_{c}(\mu, \nu)<+\infty . \pi \in \Pi(\mu, \nu) I[\pi]<+\infty x y x y, x (x+y) / 2 (x+y) / 2 y \pi . \pi 2 . 0, \mu=\nu . |x-y|^{p}, p>1, c(x, y)=\phi(|x-y|) \phi \mathbb{R}_{+}, \phi(0)=0, \phi^{\prime}(0)=0 \Pi(\mu,\nu) \pi \mathbb{R}^n\times \mathbb{R}^n  \pi(A\times \mathbb{R}^n )= \mu(A), \qquad \pi( \mathbb{R}^n \times A)= \nu(A) I[\pi]:=\int_{\mathbb{R}^n\times \mathbb{R}^n} c(x,y)\,d\pi(x,y) \mathcal{T}_{c}(\mu,\nu):=\inf_{\pi \in \Pi(\mu,\nu)}I[\pi]\,.  \pi':= \frac{c(x,\frac{x+y}{2})}{c(x,y)}\cdot T_{1}\sharp \pi+ \frac{c(\frac{x+y}{2},y)}{c(x,y)}\cdot T_{2}\sharp \pi T_{1}: (x,y)\mapsto (x, \frac{x+y}{2})  T_{2}: (x,y)\mapsto (\frac{x+y}{2}, y )  I[\pi']\leq\frac{1}{2}I[\pi]","['measure-theory', 'optimization', 'calculus-of-variations', 'optimal-transport']"
38,About a uniformly integrable sequence of functions,About a uniformly integrable sequence of functions,,"I'm working with the following sequence of functions $$\begin{cases}     f(x), & f(x)\leq n, \\     n, & f(x)>n.   \end{cases}$$ Here $f$ is a non-negative measurable function and $I=\lbrack 0,1\rbrack$. I'm told to prove the following: Show that $\displaystyle\lim_{n\to\infty}\int_I f_n(x)\,dx=\int_{I}f(x) \, dx$. Show that given $\varepsilon>0$, there exists a $\delta>0$ such that if $A\subseteq I$ with $m(A)<\delta$, then $\int_Af_ndx<\varepsilon$. Now if we assume $f$ is integrable, show that if $A\subseteq I$ with $m(A)<\delta$, then $\int_Afdx<\varepsilon$. I worked through this as follows and I would like to see if you can help me out with my mistakes and doubts. I readily noticed that $f_n(x)=\min\{f(x),n\}$, however I don't see how that can help me. For part 1. I used the monotone convergence theorem. For this I (almost) proved that $(f_n)$ is an increasing sequence of functions. This is because $$ f_n(x)\leq f_{n+1}(x)\iff \begin{cases} f(x) = f(x) &\text{ when } f(x)\leq n,\\ n\leq f(x) &\text{ when } n< f(x)\leq n+1,\\ n<n+1 &\text{ when } f(x)>n+1.\\ \end{cases} $$ The part of this argument I'm not so sure of is why does $n\leq f(x)$ when $ n< f(x)\leq n+1$? I tried drawing the function and the sequence on a piece of paper and it does make sense that $f_{n+1}\geq f_n$ in any of those sets. My justification is along the lines of ""if $f$ were less than $n$, it would occur that $f_n$ would also equal $f$ in that set and so $f=f$ gives no contradiction"".  I feel like my intuition is right but I can't formalize it. To complete the first part and apply the MCT I have to show that there exists a function $\phi\in L(I)$ such that $\phi\leq f_n$ for all $n$. The prime candidate for this function would be $\phi=f_1$. The question then reduces to the integrability of $f_1$ which I worked like this \begin{align*} \int_{I}f_1d x &=\int_{\{f>1\}}f_1d x+\int_{\{f\leq 1\}}f_1dx=\int_{\{f>1\}}1d x+\int_{\{f\leq 1\}}fdx\\ &=m(\{f>1\})+\int_{\{0\leq f\leq 1\}}fdx\leq m(\{f>1\})+m(\{0\leq f\leq 1\})\\ &=m(\{f\geq 0\}). \end{align*} Now since $f$ is measurable the latter set is measurable. But now I have another problem, how do I handle the case when the measure of the set is infinite? Is my process of showing that $f_1$ integrable even correct? EDIT1: Since $\{f\geq 0\}\subseteq I$ and both are measurable sets, it follows that  $m(\{f\geq 0\})\leq m(I)=1$. By this it follows that $f_1$'s integral is finite thus $f_1\in L(I)$. Now we can apply the MCT to show the first part. Is this reasoning correct? If it were the case that all the answers were positive then by MCT we get the first part of the problem. For the second and third parts I'm stumped. I know that the condition in question is uniform integrability. I tried taking the integral of $f_n$ over $I$, but this time I separated it into $\{f>n\}$ and $\{f\leq n\}$ then it followed that \begin{align*} \int_{I}f_nd x &=\int_{\{f>n\}}f_nd x+\int_{\{f\leq n\}}f_ndx=\int_{\{f>n\}}nd x+\int_{\{f\leq n\}}fdx\\ &=m(\{f>n\})+\int_{\{0\leq f\leq n\}}fdx\leq nm(\{f>n\})+nm(\{0\leq f\leq n\})\\ &=nm(\{f\geq 0\}). \end{align*} How can I choose my $\delta$ with the quantity $nm(\{f\geq 0\})$? Once again I also have the question about my treatment of the past integral, is it done correctly? EDIT1: Following the same reasoning as the edit above, $nm(\{f\geq 0\})$ is bounded above by $n$. But this still doesn't lead me to a choice of an appropiate $\delta$... For the third part I can write $f$ as $f-f_n+f_n$ and since $f$ is integrable the difference of integrals has no problem. Then if $A$ is the set of the last item we have \begin{align*} \int_A|f| dx&\leq\int_A |f_n-f|dx+\int_A|f_n|dx\\ &<\eta m(A)+\varepsilon. \end{align*} The last quantity is ""small"" so I feel like I can take $\eta=\varepsilon$ and then we will get a multiple of $\varepsilon$ so the whole integral is small. I feel like this needs to be formalized but I can't quite grasp it since I'm yet not sure about the second item. This is the whole of my process, any comments and suggestions will be very welcome.","I'm working with the following sequence of functions $$\begin{cases}     f(x), & f(x)\leq n, \\     n, & f(x)>n.   \end{cases}$$ Here $f$ is a non-negative measurable function and $I=\lbrack 0,1\rbrack$. I'm told to prove the following: Show that $\displaystyle\lim_{n\to\infty}\int_I f_n(x)\,dx=\int_{I}f(x) \, dx$. Show that given $\varepsilon>0$, there exists a $\delta>0$ such that if $A\subseteq I$ with $m(A)<\delta$, then $\int_Af_ndx<\varepsilon$. Now if we assume $f$ is integrable, show that if $A\subseteq I$ with $m(A)<\delta$, then $\int_Afdx<\varepsilon$. I worked through this as follows and I would like to see if you can help me out with my mistakes and doubts. I readily noticed that $f_n(x)=\min\{f(x),n\}$, however I don't see how that can help me. For part 1. I used the monotone convergence theorem. For this I (almost) proved that $(f_n)$ is an increasing sequence of functions. This is because $$ f_n(x)\leq f_{n+1}(x)\iff \begin{cases} f(x) = f(x) &\text{ when } f(x)\leq n,\\ n\leq f(x) &\text{ when } n< f(x)\leq n+1,\\ n<n+1 &\text{ when } f(x)>n+1.\\ \end{cases} $$ The part of this argument I'm not so sure of is why does $n\leq f(x)$ when $ n< f(x)\leq n+1$? I tried drawing the function and the sequence on a piece of paper and it does make sense that $f_{n+1}\geq f_n$ in any of those sets. My justification is along the lines of ""if $f$ were less than $n$, it would occur that $f_n$ would also equal $f$ in that set and so $f=f$ gives no contradiction"".  I feel like my intuition is right but I can't formalize it. To complete the first part and apply the MCT I have to show that there exists a function $\phi\in L(I)$ such that $\phi\leq f_n$ for all $n$. The prime candidate for this function would be $\phi=f_1$. The question then reduces to the integrability of $f_1$ which I worked like this \begin{align*} \int_{I}f_1d x &=\int_{\{f>1\}}f_1d x+\int_{\{f\leq 1\}}f_1dx=\int_{\{f>1\}}1d x+\int_{\{f\leq 1\}}fdx\\ &=m(\{f>1\})+\int_{\{0\leq f\leq 1\}}fdx\leq m(\{f>1\})+m(\{0\leq f\leq 1\})\\ &=m(\{f\geq 0\}). \end{align*} Now since $f$ is measurable the latter set is measurable. But now I have another problem, how do I handle the case when the measure of the set is infinite? Is my process of showing that $f_1$ integrable even correct? EDIT1: Since $\{f\geq 0\}\subseteq I$ and both are measurable sets, it follows that  $m(\{f\geq 0\})\leq m(I)=1$. By this it follows that $f_1$'s integral is finite thus $f_1\in L(I)$. Now we can apply the MCT to show the first part. Is this reasoning correct? If it were the case that all the answers were positive then by MCT we get the first part of the problem. For the second and third parts I'm stumped. I know that the condition in question is uniform integrability. I tried taking the integral of $f_n$ over $I$, but this time I separated it into $\{f>n\}$ and $\{f\leq n\}$ then it followed that \begin{align*} \int_{I}f_nd x &=\int_{\{f>n\}}f_nd x+\int_{\{f\leq n\}}f_ndx=\int_{\{f>n\}}nd x+\int_{\{f\leq n\}}fdx\\ &=m(\{f>n\})+\int_{\{0\leq f\leq n\}}fdx\leq nm(\{f>n\})+nm(\{0\leq f\leq n\})\\ &=nm(\{f\geq 0\}). \end{align*} How can I choose my $\delta$ with the quantity $nm(\{f\geq 0\})$? Once again I also have the question about my treatment of the past integral, is it done correctly? EDIT1: Following the same reasoning as the edit above, $nm(\{f\geq 0\})$ is bounded above by $n$. But this still doesn't lead me to a choice of an appropiate $\delta$... For the third part I can write $f$ as $f-f_n+f_n$ and since $f$ is integrable the difference of integrals has no problem. Then if $A$ is the set of the last item we have \begin{align*} \int_A|f| dx&\leq\int_A |f_n-f|dx+\int_A|f_n|dx\\ &<\eta m(A)+\varepsilon. \end{align*} The last quantity is ""small"" so I feel like I can take $\eta=\varepsilon$ and then we will get a multiple of $\varepsilon$ so the whole integral is small. I feel like this needs to be formalized but I can't quite grasp it since I'm yet not sure about the second item. This is the whole of my process, any comments and suggestions will be very welcome.",,"['measure-theory', 'proof-verification', 'proof-writing', 'lebesgue-integral']"
39,"Does the set of characters, $\Omega(\mathcal{A})$, over a C${}^{\ast}$-algebra, $\mathcal{A}$, generate a weakly dense subspace of $\mathcal{A}'$?","Does the set of characters, , over a C-algebra, , generate a weakly dense subspace of ?",\Omega(\mathcal{A}) {}^{\ast} \mathcal{A} \mathcal{A}',"Let $\mathcal{A}$ be an abelian C${}^{\ast}$-Algebra with unit. We know that $\mathcal{A}\cong C(\Omega(\mathcal{A}))$, where $\Omega(\mathcal{A})\subseteq\mathcal{A}'_{\geq 0}$. Note that for $\varphi\in\mathcal{A}'$ we define $\varphi\geq 0$ exactly in case $\langle f,\varphi\rangle$ for all $f\in\mathcal{A}$ with $f\geq 0$ (whereby the order relation is the usual one on C${}^{\ast}$-Algebras). Consider now the linear hull $\langle\Omega(\mathcal{A})\rangle$. Question 1. Is this dense in $\mathcal{A}'$ under the weak topology, that is, is it $\sigma(\mathcal{A}',\mathcal{A}'')$-weakly dense? Application. Suppose that $\xi,\eta\in\mathcal{A}''$ satisfy $\xi\leq\eta$ on $\Omega(\mathcal{A})$, that is $\langle\xi,\varphi\rangle\leq\langle\eta,\varphi\rangle$ for all $\varphi\in\Omega(\mathcal{A})$. If the above is true, then it holds that $\xi\leq\eta$, that is, that $\langle\xi,\varphi\rangle\leq\langle\eta,\varphi\rangle$ for all $\varphi\in\mathcal{A}'$ with $\varphi\geq 0$. It is trivial to show this for $\xi,\eta\in\mathcal{A}$ (viewed as a subspace of $\mathcal{A}''$ in the canonical fashion), but I cannot seem to show this without the above result. Perhaps there is a counterexample, so that the desired application fails and the above result is necessarily false. Further observations. Due to the Riesz-Representation theorem, and since $\Omega(\mathcal{A})$ is compact Hausdorff for abelian C${}^{\ast}$-Algebras with a unit, we have $\mathcal{A}'\cong C(\Omega(\mathcal{A}))'=\langle\{T_{\mu}\mid\mu~\text{(reg.) prob. meas. on $\Omega(\mathcal{A})$}\}\rangle$, where $T_{\mu}:f\in C(\Omega(\mathcal{A}))\mapsto\int f~\mathrm{d}\mu$. So it is necessary and sufficient to show that all probability measures on $\Omega(\mathcal{A})$ can be weakly approximated by linear combinations of characters. Here we replace/identify each character $\tau\in\Omega(\mathcal{A})$ with $\hat{\tau}:\hat{a}\in C(\Omega(\mathcal{A}))\mapsto \tau(a)=\hat{a}(\tau)$, where $a\in\mathcal{A}\mapsto\hat{a}\in C(\Omega(\mathcal{A}))$ is the canonical Gelfand-C${}^{\ast}$-isomorphism. That is, each character is the identified with the point measure $\hat{\tau}=\delta_{\tau}$. Now, the convex hull of the set of point measures can be easily shown to be $w^{\ast}$-dense in the set of probability measures identified as a subspace of $C(K)'$, where $K=\Omega(\mathcal{A})$. Is it also $w$-dense? Hence the reduced problem: Question 2. Is the convex hull of the set of point measures over a compact Hausdorff space weakly dense in the set of probability measures?","Let $\mathcal{A}$ be an abelian C${}^{\ast}$-Algebra with unit. We know that $\mathcal{A}\cong C(\Omega(\mathcal{A}))$, where $\Omega(\mathcal{A})\subseteq\mathcal{A}'_{\geq 0}$. Note that for $\varphi\in\mathcal{A}'$ we define $\varphi\geq 0$ exactly in case $\langle f,\varphi\rangle$ for all $f\in\mathcal{A}$ with $f\geq 0$ (whereby the order relation is the usual one on C${}^{\ast}$-Algebras). Consider now the linear hull $\langle\Omega(\mathcal{A})\rangle$. Question 1. Is this dense in $\mathcal{A}'$ under the weak topology, that is, is it $\sigma(\mathcal{A}',\mathcal{A}'')$-weakly dense? Application. Suppose that $\xi,\eta\in\mathcal{A}''$ satisfy $\xi\leq\eta$ on $\Omega(\mathcal{A})$, that is $\langle\xi,\varphi\rangle\leq\langle\eta,\varphi\rangle$ for all $\varphi\in\Omega(\mathcal{A})$. If the above is true, then it holds that $\xi\leq\eta$, that is, that $\langle\xi,\varphi\rangle\leq\langle\eta,\varphi\rangle$ for all $\varphi\in\mathcal{A}'$ with $\varphi\geq 0$. It is trivial to show this for $\xi,\eta\in\mathcal{A}$ (viewed as a subspace of $\mathcal{A}''$ in the canonical fashion), but I cannot seem to show this without the above result. Perhaps there is a counterexample, so that the desired application fails and the above result is necessarily false. Further observations. Due to the Riesz-Representation theorem, and since $\Omega(\mathcal{A})$ is compact Hausdorff for abelian C${}^{\ast}$-Algebras with a unit, we have $\mathcal{A}'\cong C(\Omega(\mathcal{A}))'=\langle\{T_{\mu}\mid\mu~\text{(reg.) prob. meas. on $\Omega(\mathcal{A})$}\}\rangle$, where $T_{\mu}:f\in C(\Omega(\mathcal{A}))\mapsto\int f~\mathrm{d}\mu$. So it is necessary and sufficient to show that all probability measures on $\Omega(\mathcal{A})$ can be weakly approximated by linear combinations of characters. Here we replace/identify each character $\tau\in\Omega(\mathcal{A})$ with $\hat{\tau}:\hat{a}\in C(\Omega(\mathcal{A}))\mapsto \tau(a)=\hat{a}(\tau)$, where $a\in\mathcal{A}\mapsto\hat{a}\in C(\Omega(\mathcal{A}))$ is the canonical Gelfand-C${}^{\ast}$-isomorphism. That is, each character is the identified with the point measure $\hat{\tau}=\delta_{\tau}$. Now, the convex hull of the set of point measures can be easily shown to be $w^{\ast}$-dense in the set of probability measures identified as a subspace of $C(K)'$, where $K=\Omega(\mathcal{A})$. Is it also $w$-dense? Hence the reduced problem: Question 2. Is the convex hull of the set of point measures over a compact Hausdorff space weakly dense in the set of probability measures?",,"['measure-theory', 'banach-spaces', 'c-star-algebras', 'dual-spaces', 'weak-topology']"
40,Explain why a given function does not contradict Fubini's Theorem,Explain why a given function does not contradict Fubini's Theorem,,"Suppose $\{I_n\}$ is a pairwise disjoint sequence of sub intervals of $[0,1]$ of positive length. For each $n$ let $a_n$ be the reciprocal of the length of $I_n$, and let $g_n$ be the characteristic function of $I_n$ multiplied by $a_n$. Define $f$ by $$f(x,y)=\sum_{n=1}^{\infty} [g_n(x)-g_{n+1}(x)]g_n(y)$$ for $0\leq x, y\leq 1$. I have shown that $$\int_0^1 \int_0^1 f(x,y) dx dy = 0 \qquad \int_0^1 \int_0^1 f(x,y) dy dx = 1 $$ I now need to explain why this does not contradict Fubini's Theorem. My guess is that $|f(x,y)|$ is not integrable, but I'm not sure how to calculate that integral to prove that.","Suppose $\{I_n\}$ is a pairwise disjoint sequence of sub intervals of $[0,1]$ of positive length. For each $n$ let $a_n$ be the reciprocal of the length of $I_n$, and let $g_n$ be the characteristic function of $I_n$ multiplied by $a_n$. Define $f$ by $$f(x,y)=\sum_{n=1}^{\infty} [g_n(x)-g_{n+1}(x)]g_n(y)$$ for $0\leq x, y\leq 1$. I have shown that $$\int_0^1 \int_0^1 f(x,y) dx dy = 0 \qquad \int_0^1 \int_0^1 f(x,y) dy dx = 1 $$ I now need to explain why this does not contradict Fubini's Theorem. My guess is that $|f(x,y)|$ is not integrable, but I'm not sure how to calculate that integral to prove that.",,"['measure-theory', 'lebesgue-integral']"
41,Lebesgue measure of boundary of sets of roots,Lebesgue measure of boundary of sets of roots,,"Suppose $f:(0,1)^n\to \mathbb{R}$ is continuous. Does the boundary of the set  of its roots have Lebesgue measure 0?  I guess the answer is negative, in that case, are there any reasonable conditions on $f$, e.g. Lipschitz continuity or (continuous) differentiability, that make the answer positive? Thanks a lot, I'd appreciate any input.","Suppose $f:(0,1)^n\to \mathbb{R}$ is continuous. Does the boundary of the set  of its roots have Lebesgue measure 0?  I guess the answer is negative, in that case, are there any reasonable conditions on $f$, e.g. Lipschitz continuity or (continuous) differentiability, that make the answer positive? Thanks a lot, I'd appreciate any input.",,"['measure-theory', 'lebesgue-measure', 'roots']"
42,Construction of measure in Riesz Repr. Thm. (Rudin),Construction of measure in Riesz Repr. Thm. (Rudin),,"In the proof of Riesz Representation Theorem in Rudin; Real and Complex Analysis (theorem 2.14, page 41/42), regarding construction of the measure, Rudin goes as follows. For every open set V in X define: \begin{equation} \mu (V) = \sup \{ \Lambda f:f \prec V\}  \label{1} \end{equation} If ${V_1} \subset {V_2}$ also $\mu ({V_1}) \le \mu ({V_2})$ And now the tricky part, my question is, why is the following a consistent definition? and why for every $E$? It seems reasonable since X is locally compact Hausdorff according to the assumptions in the theorem, but I am unable to come up with a rigorous proof. The consistent definition: $$\mu (E) = inf\{ \mu (V):E \subset V,V\,open\} $$ if $E$ is an open set, and $\mu(E)$ is consistent to the before mentioned definition for every $E\subset{X}$. Note: $$f \prec V$$ Is notation for that $V$ is open, $f \in {C_c}(X)$, i.e. $f$ is continuous with compact support, $ 0 \le f \le 1 $ and the support lies in $V$. Also $\Lambda$ is a positive linear functional. Thank you very much in advance!","In the proof of Riesz Representation Theorem in Rudin; Real and Complex Analysis (theorem 2.14, page 41/42), regarding construction of the measure, Rudin goes as follows. For every open set V in X define: \begin{equation} \mu (V) = \sup \{ \Lambda f:f \prec V\}  \label{1} \end{equation} If ${V_1} \subset {V_2}$ also $\mu ({V_1}) \le \mu ({V_2})$ And now the tricky part, my question is, why is the following a consistent definition? and why for every $E$? It seems reasonable since X is locally compact Hausdorff according to the assumptions in the theorem, but I am unable to come up with a rigorous proof. The consistent definition: $$\mu (E) = inf\{ \mu (V):E \subset V,V\,open\} $$ if $E$ is an open set, and $\mu(E)$ is consistent to the before mentioned definition for every $E\subset{X}$. Note: $$f \prec V$$ Is notation for that $V$ is open, $f \in {C_c}(X)$, i.e. $f$ is continuous with compact support, $ 0 \le f \le 1 $ and the support lies in $V$. Also $\Lambda$ is a positive linear functional. Thank you very much in advance!",,"['real-analysis', 'measure-theory']"
43,Which convergence can be deduced for $\sqrt{X_n}$?,Which convergence can be deduced for ?,\sqrt{X_n},"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space (but the question is interesting for a general measure space). Let $X_n$ be a sequence of random variables converging in $L^1(\Omega)$ to a random variable $X_{\infty}.$ My question is: which convergence can be deduced for the random variables $\sqrt{X_n}$ to the variable $\sqrt{X_\infty}$? I can't believe there is none, and I tried to verify it with the $L^2$ and $L^1$ norms, but I couldn't handle terms like $\mathbb{E}[\sqrt{X_nX_\infty}].$ Thanks for any help!","Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space (but the question is interesting for a general measure space). Let $X_n$ be a sequence of random variables converging in $L^1(\Omega)$ to a random variable $X_{\infty}.$ My question is: which convergence can be deduced for the random variables $\sqrt{X_n}$ to the variable $\sqrt{X_\infty}$? I can't believe there is none, and I tried to verify it with the $L^2$ and $L^1$ norms, but I couldn't handle terms like $\mathbb{E}[\sqrt{X_nX_\infty}].$ Thanks for any help!",,"['probability', 'functional-analysis', 'measure-theory', 'lp-spaces']"
44,Limit of $\sin(kx)$ as k tends to infinity,Limit of  as k tends to infinity,\sin(kx),"I am have been thinking lately of the sequence of functions $$ f_n = \sin nx $$ and its limit as n tends to infinity. I am quite comfortable with the fact that viewing this sequence in $\mathcal{C}([a,b],\mathbb{R})$ this has no limit. However I have recently finished a course at on Hilbert Spaces, where we were teased with function spaces like $L^2([-\pi,\pi])$ and $L^1([a,b])$. Now we were not given any rigorous definitions of these spaces but I am wondering if this sequence does have a limit in a more abstract space. I am mainly wondering about its limit in $L^2([-\pi,\pi])$.  The reason I am wondering about this space in particular is because to me it seems to the limit of this function sequence, if it exists, will be 1 and -1 at an infinite number of points in the interval $[-\pi,\pi]$, however the set of these points seems countable and therefore the set of such points have a measure of zero. If this seems a little like a waffle session, I apologise, I do not have a lot of experience in measure and integration theory just yet. (I will be doing that next year)","I am have been thinking lately of the sequence of functions $$ f_n = \sin nx $$ and its limit as n tends to infinity. I am quite comfortable with the fact that viewing this sequence in $\mathcal{C}([a,b],\mathbb{R})$ this has no limit. However I have recently finished a course at on Hilbert Spaces, where we were teased with function spaces like $L^2([-\pi,\pi])$ and $L^1([a,b])$. Now we were not given any rigorous definitions of these spaces but I am wondering if this sequence does have a limit in a more abstract space. I am mainly wondering about its limit in $L^2([-\pi,\pi])$.  The reason I am wondering about this space in particular is because to me it seems to the limit of this function sequence, if it exists, will be 1 and -1 at an infinite number of points in the interval $[-\pi,\pi]$, however the set of these points seems countable and therefore the set of such points have a measure of zero. If this seems a little like a waffle session, I apologise, I do not have a lot of experience in measure and integration theory just yet. (I will be doing that next year)",,"['functional-analysis', 'measure-theory', 'lebesgue-measure', 'sequence-of-function']"
45,Probability of $\lim \sup$ of intersection,Probability of  of intersection,\lim \sup,"I'm given two sequences of events $\{A_n\}$ and $\{B_n\}$ with $ \mathbb{P}(\liminf_n A_n) = \mathbb{P}(\limsup_n B_n) = 1$ . Can we deduce that $\mathbb{P}(\limsup_n A_n \cap B_n) = 1$ ? My attempt was to write $$ \mathbb{P}(\liminf_n A_n) = 1 \Rightarrow \mathbb{P}\left( \left\{ w : \sum_n 1_{A_n}(w) \text{ finite} \right\} \right) = 0 $$ Additionally, we know that $$ \mathbb{P}(\limsup_n (A_n \cap B_n)) = \mathbb{P}\left(\left\{w : \sum_{n=1}^{\infty} 1_{A_n}(w) \cdot 1_{B_n}(w) =\infty \right\}\right) \\= \mathbb{P}\left( \left\{ w : \sum_n 1_{A_n}(w) = \infty, \sum_n 1_{A_n}(w) \cdot 1_{B_n}(w) = \infty \right\} \cup \left\{ w : \sum_n 1_{A_n}(w) < \infty, \sum_n 1_{A_n}(w) \cdot 1_{B_n}(w) = \infty \right\} \right) \\ =  \mathbb{P}\left(\left\{    w: \sum_{k=1}^{\infty} 1_{B_{n_k}}(w) = \infty \right\}\right) + 0 = \mathbb{P}(\limsup_n B_n) = 1 $$ where in the above we made use of the fact that since $w \in \liminf_n A_n$ , the terms in the sum $\sum_n 1_{A_n} 1_{B_n}(w)$ have $1_{A_n} = 0$ for only a finite set of indices. Is that correct, or am I missing something? Additionally, does this hold when I change the condition of $\mathbb{P}(\liminf_n A_n) = 1$ to $\mathbb{P}(\limsup_n A_n) = 1$ ? I've been trying to find a counterexample to no avail.","I'm given two sequences of events and with . Can we deduce that ? My attempt was to write Additionally, we know that where in the above we made use of the fact that since , the terms in the sum have for only a finite set of indices. Is that correct, or am I missing something? Additionally, does this hold when I change the condition of to ? I've been trying to find a counterexample to no avail.","\{A_n\} \{B_n\} 
\mathbb{P}(\liminf_n A_n) = \mathbb{P}(\limsup_n B_n) = 1 \mathbb{P}(\limsup_n A_n \cap B_n) = 1 
\mathbb{P}(\liminf_n A_n) = 1 \Rightarrow
\mathbb{P}\left( \left\{ w : \sum_n 1_{A_n}(w) \text{ finite} \right\} \right) = 0
 
\mathbb{P}(\limsup_n (A_n \cap B_n)) = \mathbb{P}\left(\left\{w : \sum_{n=1}^{\infty} 1_{A_n}(w) \cdot
1_{B_n}(w) =\infty \right\}\right) \\=
\mathbb{P}\left(
\left\{ w : \sum_n 1_{A_n}(w) = \infty, \sum_n 1_{A_n}(w) \cdot 1_{B_n}(w) =
\infty
\right\} \cup \left\{
w : \sum_n 1_{A_n}(w) < \infty, \sum_n 1_{A_n}(w) \cdot 1_{B_n}(w) = \infty
\right\}
\right) \\ = 
\mathbb{P}\left(\left\{
   w: \sum_{k=1}^{\infty} 1_{B_{n_k}}(w) = \infty
\right\}\right) + 0 = \mathbb{P}(\limsup_n B_n) = 1
 w \in \liminf_n A_n \sum_n 1_{A_n} 1_{B_n}(w) 1_{A_n} = 0 \mathbb{P}(\liminf_n A_n) = 1 \mathbb{P}(\limsup_n A_n) = 1","['probability', 'measure-theory', 'proof-verification', 'limsup-and-liminf']"
46,Are polynomials dense in $H^\infty$,Are polynomials dense in,H^\infty,Let $H^\infty(D)=\{f:D\longrightarrow \mathbb{C}: f \;\text{is bounded and analytic on}\; {D}\}$ where $D=\{z\in\mathbb{C}: |z|<1\}$. Are the polynomials dense in $H^\infty(D)$? I know that they are dense in  other Hardy spaces $H^p(D)$ for $0<p<\infty$.,Let $H^\infty(D)=\{f:D\longrightarrow \mathbb{C}: f \;\text{is bounded and analytic on}\; {D}\}$ where $D=\{z\in\mathbb{C}: |z|<1\}$. Are the polynomials dense in $H^\infty(D)$? I know that they are dense in  other Hardy spaces $H^p(D)$ for $0<p<\infty$.,,"['functional-analysis', 'measure-theory', 'hardy-spaces']"
47,Question about positive variations of function,Question about positive variations of function,,"Given a function $f:\mathbb{R} \to \mathbb{C}$, Folland in his book ""Real Analysis"" defines the total variation of $f$ at $x \in \mathbb{R}$ as $$ T_f(x) = \sup \left\{\sum_{1}^n |f(x_j)-f(x_{j-1})|: -\infty < x_0 <x_1 < \dots x_n = x , n \in \mathbb{N} \right \} $$ and the space $BV(R)$ as the set of those functions with finite $T_f(x)$ for $x \in \mathbb{R}$. Then, for $f \in BV(R)$, he defines the positive variation of $f$ denoted by  $v(f)^+$ $$ v(f)^+ := \frac{1}{2} (T_f+f)(x) = \sup \left\{\sum_{1}^n [f(x_j)-f(x_{j-1})]^+: -\infty < x_0 <x_1 < \dots x_n = x , n \in \mathbb{N} \right \} + f(-\infty)$$ but I do not understand where the term $f(-\infty)$ comes from. What I was able to get is $$  v(f)^+  =  \sup \left\{\sum_{1}^n [f(x_j)-f(x_{j-1})]^+ + \frac{1}{2}f(x_0): -\infty < x_0 <x_1 < \dots x_n = x , n \in \mathbb{N} \right \} $$ What am I missing?","Given a function $f:\mathbb{R} \to \mathbb{C}$, Folland in his book ""Real Analysis"" defines the total variation of $f$ at $x \in \mathbb{R}$ as $$ T_f(x) = \sup \left\{\sum_{1}^n |f(x_j)-f(x_{j-1})|: -\infty < x_0 <x_1 < \dots x_n = x , n \in \mathbb{N} \right \} $$ and the space $BV(R)$ as the set of those functions with finite $T_f(x)$ for $x \in \mathbb{R}$. Then, for $f \in BV(R)$, he defines the positive variation of $f$ denoted by  $v(f)^+$ $$ v(f)^+ := \frac{1}{2} (T_f+f)(x) = \sup \left\{\sum_{1}^n [f(x_j)-f(x_{j-1})]^+: -\infty < x_0 <x_1 < \dots x_n = x , n \in \mathbb{N} \right \} + f(-\infty)$$ but I do not understand where the term $f(-\infty)$ comes from. What I was able to get is $$  v(f)^+  =  \sup \left\{\sum_{1}^n [f(x_j)-f(x_{j-1})]^+ + \frac{1}{2}f(x_0): -\infty < x_0 <x_1 < \dots x_n = x , n \in \mathbb{N} \right \} $$ What am I missing?",,"['real-analysis', 'measure-theory']"
48,Is the space of random continuous functions separable?,Is the space of random continuous functions separable?,,"Let $\Omega$ and $X$ be compact metric spaces with $P$ a probability measure on $\Omega$. Then we get the following definition of random continuous functions from ""Random Probability Measures on Polish Spaces, H. Crauel page 21"": let $f : X \times \Omega \to \mathbb{R}$ be a function such that: for all $x \in X$ the map $\omega \mapsto f(x, \omega)$ is measurable, for all $\omega \in \Omega$ the map $x \mapsto f(x, \omega)$ is continuous and bounded, $\omega \mapsto \sup\{|f (x, ω)| : x \in X\}$ is integrable with respect to P (it is measurable by separability of X). If $f$ and $g$ are both functions satisfying (1)-(3) then identify f and g if $P(\{\omega : f(\cdot, \omega) \not= g(\cdot, \omega) \}$. Finally, a random continuous function is (the equivalence class of) a function $f : X \times \Omega \to \mathbb{R}$ satisfying (1)–(3) above. The set of all random continuous functions is a linear space, denoted by $C_\Omega(X)$ and a norm can be defined by $$ |f|_\infty = \int \sup_{x \in X}|f(x, \omega)|dP(\omega). $$ My question : is $C_\Omega(X)$ separable?","Let $\Omega$ and $X$ be compact metric spaces with $P$ a probability measure on $\Omega$. Then we get the following definition of random continuous functions from ""Random Probability Measures on Polish Spaces, H. Crauel page 21"": let $f : X \times \Omega \to \mathbb{R}$ be a function such that: for all $x \in X$ the map $\omega \mapsto f(x, \omega)$ is measurable, for all $\omega \in \Omega$ the map $x \mapsto f(x, \omega)$ is continuous and bounded, $\omega \mapsto \sup\{|f (x, ω)| : x \in X\}$ is integrable with respect to P (it is measurable by separability of X). If $f$ and $g$ are both functions satisfying (1)-(3) then identify f and g if $P(\{\omega : f(\cdot, \omega) \not= g(\cdot, \omega) \}$. Finally, a random continuous function is (the equivalence class of) a function $f : X \times \Omega \to \mathbb{R}$ satisfying (1)–(3) above. The set of all random continuous functions is a linear space, denoted by $C_\Omega(X)$ and a norm can be defined by $$ |f|_\infty = \int \sup_{x \in X}|f(x, \omega)|dP(\omega). $$ My question : is $C_\Omega(X)$ separable?",,"['measure-theory', 'metric-spaces']"
49,"How to compute the Hausdorff dimension of a ""semi"" self-similar shape?","How to compute the Hausdorff dimension of a ""semi"" self-similar shape?",,"The essence of self-similar fractals is that rescaling the original shape and gluing together a number of identical copies will produce the same overall shape. The quadratic type 2 curve is an example of such a fractal. You scale down the original shape by a factor of $1/4$ and piece together $8$ copies to get the same fractal: This results in a fractal with dimension $\log_{4}{8} = 1.5$: What I'm interested in, and what I mean by ""semi"" self-similar , is fractals where there are differently scaled copies of the shape building up the entire image. For example, if the vertical ""middle"" of the quadratic type 2 curve is treated as one iteration, rather than two, then the copy of the curve making up this piece is only scaled by $1/2$, while all of the other pieces are scaled by the original $1/4$. This ends up producing quite a different-looking fractal: Basic Structure: Limit Fractal: Another example would be a ""shark fin"" fractal, similar to the Koch snowflake, but where the ""middle third"" has a right triangle with height $1/3$, and hypotenuse $\sqrt{2}/3$: Basic Structure: Limit Fractal: Any ideas about how to calculate the Hausdorff dimensions of such shapes would be greatly appreciated!","The essence of self-similar fractals is that rescaling the original shape and gluing together a number of identical copies will produce the same overall shape. The quadratic type 2 curve is an example of such a fractal. You scale down the original shape by a factor of $1/4$ and piece together $8$ copies to get the same fractal: This results in a fractal with dimension $\log_{4}{8} = 1.5$: What I'm interested in, and what I mean by ""semi"" self-similar , is fractals where there are differently scaled copies of the shape building up the entire image. For example, if the vertical ""middle"" of the quadratic type 2 curve is treated as one iteration, rather than two, then the copy of the curve making up this piece is only scaled by $1/2$, while all of the other pieces are scaled by the original $1/4$. This ends up producing quite a different-looking fractal: Basic Structure: Limit Fractal: Another example would be a ""shark fin"" fractal, similar to the Koch snowflake, but where the ""middle third"" has a right triangle with height $1/3$, and hypotenuse $\sqrt{2}/3$: Basic Structure: Limit Fractal: Any ideas about how to calculate the Hausdorff dimensions of such shapes would be greatly appreciated!",,"['measure-theory', 'fractals', 'hausdorff-measure']"
50,Integral with respect to random measure is measurable,Integral with respect to random measure is measurable,,"Let $(\Omega, \mathcal{F})$ be a measurable space and $P$ be a random, $\mathcal{G}$-measurable finite measure on $(\Omega, \mathcal{F})$, with $\mathcal{G} \subseteq \mathcal{F}$. Is the following proposition true? Is my proof correct? Proposition . The function $f(\omega) = \int g dP(\omega)$ is $\mathcal{G}$-measurable for all bounded, $\mathcal{F}$-measurable functions $g$. Proof . The proposition holds if $g$ is the indicator function of $A \in \mathcal{F}$ simply because $P(A)(\omega)$ is $\mathcal{G}$-measurable in $\omega$ by definition. Since the bounded $\mathcal{G}$-measurable functions are closed under linear combinations and uniform limits, the entire proposition follows. Is that sufficient? I'm somehow not fully confident about the last sentence of the proof. Should I add that the bounded convergence theorem is used for the limit step?","Let $(\Omega, \mathcal{F})$ be a measurable space and $P$ be a random, $\mathcal{G}$-measurable finite measure on $(\Omega, \mathcal{F})$, with $\mathcal{G} \subseteq \mathcal{F}$. Is the following proposition true? Is my proof correct? Proposition . The function $f(\omega) = \int g dP(\omega)$ is $\mathcal{G}$-measurable for all bounded, $\mathcal{F}$-measurable functions $g$. Proof . The proposition holds if $g$ is the indicator function of $A \in \mathcal{F}$ simply because $P(A)(\omega)$ is $\mathcal{G}$-measurable in $\omega$ by definition. Since the bounded $\mathcal{G}$-measurable functions are closed under linear combinations and uniform limits, the entire proposition follows. Is that sufficient? I'm somehow not fully confident about the last sentence of the proof. Should I add that the bounded convergence theorem is used for the limit step?",,"['real-analysis', 'integration', 'measure-theory', 'proof-verification', 'random-functions']"
51,Why are Lebesgue measurable sets defined in connection to intersections with other sets?,Why are Lebesgue measurable sets defined in connection to intersections with other sets?,,"$A\subset\mathbb R^n$ is measurable if for all $B\subset \mathbb R^n$ $$m^*(B)=m^*(B\cap A)+m^*(B\setminus A)$$ This is just a definition, and it basically says that the outer measure can be partitioned into the outer measure of the intersection of set $A$ with any other set, and the outer measure of the intersection of that set with the complement of $A.$ But why is it defined as such? One thing it achieves is countable additivity: given two disjoint Lebesgue measurable sets $E$ and $F:$ $$\begin{align}m^*(E\cap F)&= m^*\left((E\cap F) \cap E \right ) + m^*\left((E\cap F) \cap E^c \right )\\[2ex] &=m^*(E )+ m^*(F) \end{align}$$ And relatedly, how does it connect with the alternative definition : For all $\epsilon>0$ there exist an open set $G$ and a closed set $F$ such that $F\subset A\subset G$ and $m^*(G\setminus F)<\epsilon$   ?","$A\subset\mathbb R^n$ is measurable if for all $B\subset \mathbb R^n$ $$m^*(B)=m^*(B\cap A)+m^*(B\setminus A)$$ This is just a definition, and it basically says that the outer measure can be partitioned into the outer measure of the intersection of set $A$ with any other set, and the outer measure of the intersection of that set with the complement of $A.$ But why is it defined as such? One thing it achieves is countable additivity: given two disjoint Lebesgue measurable sets $E$ and $F:$ $$\begin{align}m^*(E\cap F)&= m^*\left((E\cap F) \cap E \right ) + m^*\left((E\cap F) \cap E^c \right )\\[2ex] &=m^*(E )+ m^*(F) \end{align}$$ And relatedly, how does it connect with the alternative definition : For all $\epsilon>0$ there exist an open set $G$ and a closed set $F$ such that $F\subset A\subset G$ and $m^*(G\setminus F)<\epsilon$   ?",,"['measure-theory', 'lebesgue-measure']"
52,"The Integral of which the real part is the Poisson Integral of $f$, is Holomorphic","The Integral of which the real part is the Poisson Integral of , is Holomorphic",f,"This comes from Rudin's Real and Complex Analysis, in which there is a claim, regarding the integral in the title. (i) Let $0<r<1,\ T$ be the unit circle in $\mathbb C, \ f\in L^1(T),\ $ and $z=re^{it}$. Then the following fact shows that $\int _T\frac{e^{it}+z}{e^{it}-z}f(t)dt$ is a holomorphic function of $z$: (ii) Suppose $\mu$ is a complex measure on $X$ and $\phi:X\to \mathbb C.$ If $\phi(X)$ does not intersect the open set $\Omega$ in $\mathbb C$ then $f(z)=\int _X \frac{d\mu (x)}{\phi (x)-z}$ is holomorphic for $z\in \Omega.$ So in this exercise, $X=T=[-\pi,\pi]$ Here is my attempt at showing that (ii) implies (i), which I would like feedback on. Is it correct? If so, is there an easier way to do it? If not, where is the error? I think a direct approach would also work, although I have not written it out. Take $\gamma (t)=e^{it},$ define $d\mu=\gamma'(t)dt,$ and $d \nu_1=fdt,\ d \nu_2=fd\mu$ where $dt$ is Lebesgue measure on $T$.  Then, we have $\int _T\frac{e^{it}+z}{e^{it}-z}f(t)dt=\int _T\frac{e^{it}}{e^{it}-z}f(t)dt+z\int _T\frac{1}{e^{it}-z}f(t)dt.$ So, with $\phi(t)=\gamma (t)=e^{it},$ the first integral is $\frac{1}{i}\int_T\frac{d\nu_2}{\phi(t)-z}$ and the second is $z\int_T\frac{d\nu_1}{\phi(t)-z},\ $ which proves the claim.","This comes from Rudin's Real and Complex Analysis, in which there is a claim, regarding the integral in the title. (i) Let $0<r<1,\ T$ be the unit circle in $\mathbb C, \ f\in L^1(T),\ $ and $z=re^{it}$. Then the following fact shows that $\int _T\frac{e^{it}+z}{e^{it}-z}f(t)dt$ is a holomorphic function of $z$: (ii) Suppose $\mu$ is a complex measure on $X$ and $\phi:X\to \mathbb C.$ If $\phi(X)$ does not intersect the open set $\Omega$ in $\mathbb C$ then $f(z)=\int _X \frac{d\mu (x)}{\phi (x)-z}$ is holomorphic for $z\in \Omega.$ So in this exercise, $X=T=[-\pi,\pi]$ Here is my attempt at showing that (ii) implies (i), which I would like feedback on. Is it correct? If so, is there an easier way to do it? If not, where is the error? I think a direct approach would also work, although I have not written it out. Take $\gamma (t)=e^{it},$ define $d\mu=\gamma'(t)dt,$ and $d \nu_1=fdt,\ d \nu_2=fd\mu$ where $dt$ is Lebesgue measure on $T$.  Then, we have $\int _T\frac{e^{it}+z}{e^{it}-z}f(t)dt=\int _T\frac{e^{it}}{e^{it}-z}f(t)dt+z\int _T\frac{1}{e^{it}-z}f(t)dt.$ So, with $\phi(t)=\gamma (t)=e^{it},$ the first integral is $\frac{1}{i}\int_T\frac{d\nu_2}{\phi(t)-z}$ and the second is $z\int_T\frac{d\nu_1}{\phi(t)-z},\ $ which proves the claim.",,"['real-analysis', 'measure-theory', 'fourier-analysis', 'harmonic-analysis']"
53,Proof of a measure as finitely additive but not countable additive,Proof of a measure as finitely additive but not countable additive,,"I am (self) studying probability theory and measure using the book from Ash, R. et al. [ 1 ]. I am trying to solve one of the basic problems (Section 1.2, problem 3) but with no avail...here is the link to the problem: Let $\Omega$ be a countable infinite set, and let $\mathcal{F}$ be the field consisting of all finite subsets of $\Omega$ and their complements. If $A$ is finite, set $\mu(A) = 0$, and if $A^{c}$ is finite, set $\mu(A) = 1$. (a) show that $\mu$ is finitely additive but not countable additive. (b) show that $\Omega$ is the limit of an increasing sequence of sets $A_{n} \in \mathcal{F}$, with $\mu(A_{n}) = 0$ for all $n$, but $\mu(\Omega)=1$ I would like to get some help as where to begin with...","I am (self) studying probability theory and measure using the book from Ash, R. et al. [ 1 ]. I am trying to solve one of the basic problems (Section 1.2, problem 3) but with no avail...here is the link to the problem: Let $\Omega$ be a countable infinite set, and let $\mathcal{F}$ be the field consisting of all finite subsets of $\Omega$ and their complements. If $A$ is finite, set $\mu(A) = 0$, and if $A^{c}$ is finite, set $\mu(A) = 1$. (a) show that $\mu$ is finitely additive but not countable additive. (b) show that $\Omega$ is the limit of an increasing sequence of sets $A_{n} \in \mathcal{F}$, with $\mu(A_{n}) = 0$ for all $n$, but $\mu(\Omega)=1$ I would like to get some help as where to begin with...",,['measure-theory']
54,Why isn't minimal sigma-algebra simply the set containing all countable unions and complements [duplicate],Why isn't minimal sigma-algebra simply the set containing all countable unions and complements [duplicate],,"This question already has answers here : Generate the smallest $\sigma$-algebra containing a given family of sets (3 answers) Closed 6 years ago . For $X$ a set and $A\subset X$ the sigma-algebra generated by $A$ is $$\sigma(A)=\bigcap\{\Sigma: \text{$\Sigma$ $\sigma$-algebra s.t. $A\subset\Sigma$}\}.$$ However why can' t we simply say $$\sigma(A)=\{\text{all countable unions and complements of elements of $A$}\}\cup \{\emptyset,X\}?$$ What would be a good counterexample?","This question already has answers here : Generate the smallest $\sigma$-algebra containing a given family of sets (3 answers) Closed 6 years ago . For $X$ a set and $A\subset X$ the sigma-algebra generated by $A$ is $$\sigma(A)=\bigcap\{\Sigma: \text{$\Sigma$ $\sigma$-algebra s.t. $A\subset\Sigma$}\}.$$ However why can' t we simply say $$\sigma(A)=\{\text{all countable unions and complements of elements of $A$}\}\cup \{\emptyset,X\}?$$ What would be a good counterexample?",,['measure-theory']
55,"Sequence Converging to Another Sequence, Can We Apply DCT?","Sequence Converging to Another Sequence, Can We Apply DCT?",,"Suppose I have integrable function sequences $f_n(x)$ and $g_n(x)$ and we know that point wisely, $f_n(x)\to g_n(x)$, to be more specific, $\forall x$ and $\forall \epsilon>0$, $\exists N$ such that $\forall n>N$, we have $$|f_n(x)-g_n(x)|<\epsilon.$$ and that both $f_n(x)$ and $g_n(x)$ are dominated by some integrable function $h(x)$. Can we conclude via some version of DCT that $$\int f_n(x)dx \to \int g_n(x)dx?$$","Suppose I have integrable function sequences $f_n(x)$ and $g_n(x)$ and we know that point wisely, $f_n(x)\to g_n(x)$, to be more specific, $\forall x$ and $\forall \epsilon>0$, $\exists N$ such that $\forall n>N$, we have $$|f_n(x)-g_n(x)|<\epsilon.$$ and that both $f_n(x)$ and $g_n(x)$ are dominated by some integrable function $h(x)$. Can we conclude via some version of DCT that $$\int f_n(x)dx \to \int g_n(x)dx?$$",,"['measure-theory', 'convergence-divergence']"
56,Is the style of _Scott 1967_ outdated in discussing continuum hypothesis in a probability space?,Is the style of _Scott 1967_ outdated in discussing continuum hypothesis in a probability space?,,"Here is the article I am considering: Scott, D. Math. Systems Theory (1967) 1: 89 (see here ), an article named A proof of the independence of the continuum hypothesis . He shows that CH is not true in a model of set theory--something like a special probability measurable space $(\Omega,\Sigma, P)$ where $\Omega=[0,1]^I, I>\omega_1$. Of course on that time the methods such as forcing was not written the same as that of today and therefore the style of the article may be out of fashion. So here are my 3 questions Is this presentation of this article out of fashion? Some people I know thought this article was quite confusing and is not helpful. Is it really a confusing and strange article? If so, why is it strange? Is the such an article misleading and inappropriate for beginners of set theory to study? Just give me some ideas so I would be assured.","Here is the article I am considering: Scott, D. Math. Systems Theory (1967) 1: 89 (see here ), an article named A proof of the independence of the continuum hypothesis . He shows that CH is not true in a model of set theory--something like a special probability measurable space $(\Omega,\Sigma, P)$ where $\Omega=[0,1]^I, I>\omega_1$. Of course on that time the methods such as forcing was not written the same as that of today and therefore the style of the article may be out of fashion. So here are my 3 questions Is this presentation of this article out of fashion? Some people I know thought this article was quite confusing and is not helpful. Is it really a confusing and strange article? If so, why is it strange? Is the such an article misleading and inappropriate for beginners of set theory to study? Just give me some ideas so I would be assured.",,"['measure-theory', 'set-theory', 'cardinals', 'meta-math']"
57,"($f:R\subset \Bbb R^n\to \Bbb R$, $f\geq 0$, $\int\limits_R f(x)\,dx=0$) $\implies$ ($f=0$ almost everywhere)","(, , )  ( almost everywhere)","f:R\subset \Bbb R^n\to \Bbb R f\geq 0 \int\limits_R f(x)\,dx=0 \implies f=0","I want to prove the following If $R\subset \Bbb R^m$ is a $m$-dimensional rectangle and $f:R\to \Bbb R$ is a non-negative integrable function with $\displaystyle \int\limits_R f(x)\,dx=0$, then $f$ is zero almost everywhere (i.e. the set $\mathrm{supp}(f)=\{x\in R\,|\, f(x)>0\}$ has zero measure). Here is my try: For each $n\in \Bbb N$, define $S_n=\left\{x\in R\,|\, f(x)>\dfrac{1}{n}\right\}$. We see that $\displaystyle\mathrm{supp}(f)=\bigcup_{n\in \Bbb N}S_n$ and, since countable unions of zero measure sets is itself a zero measure set, we are done IF we show that each $S_n$ has zero measure. We have $$0=\int\limits_Rf(x)\,dx\geq \int\limits_{S_n}f(x)\,dx\geq \int\limits_{S_n}\frac{1}{n}\,dx=\frac{1}{n}\int\limits_{S_n}\,dx=\frac{1}{n}\mu(S_n),$$ and, therefore, we must necessarily have $\mu(S_n)=0$. That is my argument. But after thinking a while, I've thought: ""But hey! Who said that such integral $\displaystyle \int\limits_{S_n}\,dx$ does exist?"" I mean,  what is the negation of the claim ""$A$ has zero measure""? I was tempted to say: ""$A$ has positive measure"". But, what if $A$ has not measure at all ? (i.e. $\displaystyle \int_A\,dx$ does not exist) So, what's the proper way to prove this fact, if it is true indeed?","I want to prove the following If $R\subset \Bbb R^m$ is a $m$-dimensional rectangle and $f:R\to \Bbb R$ is a non-negative integrable function with $\displaystyle \int\limits_R f(x)\,dx=0$, then $f$ is zero almost everywhere (i.e. the set $\mathrm{supp}(f)=\{x\in R\,|\, f(x)>0\}$ has zero measure). Here is my try: For each $n\in \Bbb N$, define $S_n=\left\{x\in R\,|\, f(x)>\dfrac{1}{n}\right\}$. We see that $\displaystyle\mathrm{supp}(f)=\bigcup_{n\in \Bbb N}S_n$ and, since countable unions of zero measure sets is itself a zero measure set, we are done IF we show that each $S_n$ has zero measure. We have $$0=\int\limits_Rf(x)\,dx\geq \int\limits_{S_n}f(x)\,dx\geq \int\limits_{S_n}\frac{1}{n}\,dx=\frac{1}{n}\int\limits_{S_n}\,dx=\frac{1}{n}\mu(S_n),$$ and, therefore, we must necessarily have $\mu(S_n)=0$. That is my argument. But after thinking a while, I've thought: ""But hey! Who said that such integral $\displaystyle \int\limits_{S_n}\,dx$ does exist?"" I mean,  what is the negation of the claim ""$A$ has zero measure""? I was tempted to say: ""$A$ has positive measure"". But, what if $A$ has not measure at all ? (i.e. $\displaystyle \int_A\,dx$ does not exist) So, what's the proper way to prove this fact, if it is true indeed?",,"['integration', 'measure-theory', 'multivariable-calculus', 'multiple-integral']"
58,Is the total variation norm of a measure equal to its norm as a bounded functional?,Is the total variation norm of a measure equal to its norm as a bounded functional?,,"Let $X$ be a topological space and let $\mu$ be a Borel, regular measure, with finite total variation $\| \mu \| _{TV}$. One may view $\mu$ as a bounded linear functional on the Banach space $C_b (X)$ of the bounded continuous functions on $X$; as such, it has a norm given by $\| \mu \| = \sup _{\| f \| = 1} \left| \int _X f \ \mathrm d \mu \right|$. Are the two norms of $\mu$ equal? (In particular, an affirmative answer would clarify why the total variation norm has this slightly unintuitive definition.)","Let $X$ be a topological space and let $\mu$ be a Borel, regular measure, with finite total variation $\| \mu \| _{TV}$. One may view $\mu$ as a bounded linear functional on the Banach space $C_b (X)$ of the bounded continuous functions on $X$; as such, it has a norm given by $\| \mu \| = \sup _{\| f \| = 1} \left| \int _X f \ \mathrm d \mu \right|$. Are the two norms of $\mu$ equal? (In particular, an affirmative answer would clarify why the total variation norm has this slightly unintuitive definition.)",,"['functional-analysis', 'measure-theory', 'banach-spaces', 'normed-spaces']"
59,A question related to Kolmogorov's $0$-$1$ law,A question related to Kolmogorov's - law,0 1,Let $\{X_n\}_{n=1}^\infty$ be a sequence of mutually independent random variables such that for each $n$ there exists a finite set $F_n$ such that $\mathbb{P}(X_n\in F_n)=1$; $S=\lim_{n\rightarrow\infty}\sum_{i=1}^n X_i$ exists and is finite almost surely. Prove that either there is a countable set $A$ such that $\mathbb{P}(S\in A)=1$ or there is no $\alpha\in\mathbb{R}$ such that $\mathbb{P}(S=\alpha)>0$. It seems that we need to use Kolmogorov's $0$-$1$ law to solve above problem but I have no idea how to construct corresponding tail $\sigma$-algebra. Any help is appreciated.,Let $\{X_n\}_{n=1}^\infty$ be a sequence of mutually independent random variables such that for each $n$ there exists a finite set $F_n$ such that $\mathbb{P}(X_n\in F_n)=1$; $S=\lim_{n\rightarrow\infty}\sum_{i=1}^n X_i$ exists and is finite almost surely. Prove that either there is a countable set $A$ such that $\mathbb{P}(S\in A)=1$ or there is no $\alpha\in\mathbb{R}$ such that $\mathbb{P}(S=\alpha)>0$. It seems that we need to use Kolmogorov's $0$-$1$ law to solve above problem but I have no idea how to construct corresponding tail $\sigma$-algebra. Any help is appreciated.,,"['real-analysis', 'probability', 'measure-theory']"
60,"Normed bounded sequence of $L^2[0,1]$",Normed bounded sequence of,"L^2[0,1]","I was working for my final exam in analysis from Aliprantis and Burkinshaw's Principles of Real Analysis . I got stuck at this problem. Any help is appreciated. If $\{f_n\}$ is a norm bounded sequence of $L^2[0,1]$, then show that $\dfrac{f_n}{n} \overset{\text{a.e.}}{\longrightarrow}0$.","I was working for my final exam in analysis from Aliprantis and Burkinshaw's Principles of Real Analysis . I got stuck at this problem. Any help is appreciated. If $\{f_n\}$ is a norm bounded sequence of $L^2[0,1]$, then show that $\dfrac{f_n}{n} \overset{\text{a.e.}}{\longrightarrow}0$.",,"['measure-theory', 'lebesgue-measure', 'lp-spaces', 'almost-everywhere']"
61,Lipschitz continuous function whose derivative is not continuous almost everywhere,Lipschitz continuous function whose derivative is not continuous almost everywhere,,"I want to disprove the following statement. Every Lipschitz-Continuous function is almost everywhere continuous differentiable. From Whitney-Extension theorem, we know that the derivative of a Lipschitz-continuous function is continuous on a set being arbitrary close to a co-nullset. Does there exist a counter-example for the statement on a co-null set? (Everything on the space with lebesgue measure) My idea is to consider a nowhere continuous function $g(x)$ on a non-lebesgue null set, which is bounded $|g(x)|\leq M$ . Then, setting $$f(y)=\int_0^yg(x)dx$$, the function $f(x)$ is Lipschitz continuous. Using Rademacher-theorem, the derivative of $f$ is g. However, it is not obvious to me if such $g(x)$ exists and how does it looks like.","I want to disprove the following statement. Every Lipschitz-Continuous function is almost everywhere continuous differentiable. From Whitney-Extension theorem, we know that the derivative of a Lipschitz-continuous function is continuous on a set being arbitrary close to a co-nullset. Does there exist a counter-example for the statement on a co-null set? (Everything on the space with lebesgue measure) My idea is to consider a nowhere continuous function $g(x)$ on a non-lebesgue null set, which is bounded $|g(x)|\leq M$ . Then, setting $$f(y)=\int_0^yg(x)dx$$, the function $f(x)$ is Lipschitz continuous. Using Rademacher-theorem, the derivative of $f$ is g. However, it is not obvious to me if such $g(x)$ exists and how does it looks like.",,"['measure-theory', 'geometric-measure-theory']"
62,"$f_{n} \in L^{p}(X),$ such that $\lVert f_{n}-f_{n+1}\rVert_{p} \leq \frac{1}{n^2}$. Prove $f_{n}$ converges a.e.",such that . Prove  converges a.e.,"f_{n} \in L^{p}(X), \lVert f_{n}-f_{n+1}\rVert_{p} \leq \frac{1}{n^2} f_{n}","Here's the problem at hand: Let $(X,\mu)$ be a measure space, let $f_{n} \in L^{p}(X)$ for each $n$ and some $p>1$ , such that $\lVert f_{n}-f_{n+1}\rVert_{p} \leq \frac{1}{n^2}$ . If $A_{n} = \left\lbrace x \in X : \lvert f_{n}(x)-f_{n+1}(x)\rvert \geq \frac{1}{n} \right\rbrace$ , prove that: $\mu(A_{n}) \leq \frac{1}{n^p};$ $\mu\mathopen{}\left(\overline{\lim}A_{n}\right)\mathclose{}=0;$ $f_{n}$ converges a.e. I've done 1. and 2, but I can't finish 3. Here's the proof of 1. and 2: follows from $\frac{1}{n^p} \mu(A_{n}) = \int_{A_{n}}\lvert f_{n}-f_{n+1}\rvert^p d\mu \leq \int_{X} \left\lvert f_{n}-f_{n+1}\right\rvert^p d\mu \leq \frac{1}{n^{2p}}$ . For 2, note that $\overline{\lim}A_{n} = \bigcap_{n=1}^{\infty} \bigcup_{k=n}^{\infty} A_{k} =: \bigcap_{n=1}^{\infty} B_{n}$ . $B_{n}$ is a decreasing sequence, and $\mu(B_{1}) \leq \sum_{n=1}^{\infty} \frac{1}{n^p} < +\infty$ , so by continuity from above, we get $ 0 \leq \mu\mathopen{}\left(\overline{\lim}A_{n}\right)\mathclose{} = \lim_{n\to \infty} \mu(B_{n}) \leq \lim_{n\to \infty} \sum_{k=n}^{\infty} \frac{1}{n^p} = 0$ . Now, I also note that $\lVert f_{m} - f_{n}\rVert_{p} \leq \sum_{k=n+1}^{m} \frac{1}{k^2} < \varepsilon$ , for sufficiently large $m, n$ , and arbitrary $\varepsilon$ , so $f_{n}$ is Cauchy in $L^p$ so it's convergent in $L^p$ ; so now, as a corollary, there exists an $f$ such that $f_{n} \xrightarrow{\mu} f$ , and so we have a subsequence $f_{n_{k}}$ which converges to $f$ a.e. How do I prove that the whole sequence has to converge to $f$ a.e?","Here's the problem at hand: Let be a measure space, let for each and some , such that . If , prove that: converges a.e. I've done 1. and 2, but I can't finish 3. Here's the proof of 1. and 2: follows from . For 2, note that . is a decreasing sequence, and , so by continuity from above, we get . Now, I also note that , for sufficiently large , and arbitrary , so is Cauchy in so it's convergent in ; so now, as a corollary, there exists an such that , and so we have a subsequence which converges to a.e. How do I prove that the whole sequence has to converge to a.e?","(X,\mu) f_{n} \in L^{p}(X) n p>1 \lVert f_{n}-f_{n+1}\rVert_{p} \leq \frac{1}{n^2} A_{n} = \left\lbrace x \in X : \lvert f_{n}(x)-f_{n+1}(x)\rvert \geq \frac{1}{n} \right\rbrace \mu(A_{n}) \leq \frac{1}{n^p}; \mu\mathopen{}\left(\overline{\lim}A_{n}\right)\mathclose{}=0; f_{n} \frac{1}{n^p} \mu(A_{n}) = \int_{A_{n}}\lvert f_{n}-f_{n+1}\rvert^p d\mu \leq \int_{X} \left\lvert f_{n}-f_{n+1}\right\rvert^p d\mu \leq \frac{1}{n^{2p}} \overline{\lim}A_{n} = \bigcap_{n=1}^{\infty} \bigcup_{k=n}^{\infty} A_{k} =: \bigcap_{n=1}^{\infty} B_{n} B_{n} \mu(B_{1}) \leq \sum_{n=1}^{\infty} \frac{1}{n^p} < +\infty  0 \leq \mu\mathopen{}\left(\overline{\lim}A_{n}\right)\mathclose{} = \lim_{n\to \infty} \mu(B_{n}) \leq \lim_{n\to \infty} \sum_{k=n}^{\infty} \frac{1}{n^p} = 0 \lVert f_{m} - f_{n}\rVert_{p} \leq \sum_{k=n+1}^{m} \frac{1}{k^2} < \varepsilon m, n \varepsilon f_{n} L^p L^p f f_{n} \xrightarrow{\mu} f f_{n_{k}} f f","['measure-theory', 'lp-spaces']"
63,A sequence of absolutely continuous functions whose derivatives converge to $0$ a.e,A sequence of absolutely continuous functions whose derivatives converge to  a.e,0,"Here's the problem I'm having trouble with: Let $f_{n}:[a,b] \to \mathbb{R}$ be a sequence of absolutely continuous functions such that $f_{n}(a)=0$ , $||f_{n}'||_{2} \leq 1$ and $f_{n}' \to 0$ a.e. (in the standard Lebesgue measure): Prove that $||f_{n}'||_{1} \to 0$ . Prove that $f_{n} \to 0$ a.e. I know how to do part 2. once I do part 1: $|f_{n}(x)| = | \int_{a}^{x} f_{n}'(t)|dt \leq \int_{a}^{x}|f_{n}'(t)|dt \leq \int_{a}^{b} |f_{n}'(t)|dt \xrightarrow{n \to +\infty}0.$ I've tried solving one using the Holder inequality, as well as through the dominated convergence theorem (my attempt was, if $f_{n}$ is abs. cont, and $f'_{n}$ is bounded a.e, then $f_{n}$ is Lipschitz and has bounded derivative, so I can use the dominated convergence theorem. Unfortunately, $f_{n}'$ needn't be bounded, even if it tends to zero at a.e. point. How can I prove 1?","Here's the problem I'm having trouble with: Let be a sequence of absolutely continuous functions such that , and a.e. (in the standard Lebesgue measure): Prove that . Prove that a.e. I know how to do part 2. once I do part 1: I've tried solving one using the Holder inequality, as well as through the dominated convergence theorem (my attempt was, if is abs. cont, and is bounded a.e, then is Lipschitz and has bounded derivative, so I can use the dominated convergence theorem. Unfortunately, needn't be bounded, even if it tends to zero at a.e. point. How can I prove 1?","f_{n}:[a,b] \to \mathbb{R} f_{n}(a)=0 ||f_{n}'||_{2} \leq 1 f_{n}' \to 0 ||f_{n}'||_{1} \to 0 f_{n} \to 0 |f_{n}(x)| = | \int_{a}^{x} f_{n}'(t)|dt \leq \int_{a}^{x}|f_{n}'(t)|dt \leq \int_{a}^{b} |f_{n}'(t)|dt \xrightarrow{n \to +\infty}0. f_{n} f'_{n} f_{n} f_{n}'","['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
64,Characterize sigma algebra generated by a set,Characterize sigma algebra generated by a set,,Let $E$ be a set. Let $C$ be a collection of subsets of E. Denote by $\sigma(C)$ the $\sigma$-algebra generated by $C$ i.e. the intersection of all $\sigma$-algebra containing $C$. Is it true that any element $A \in \sigma(C)$ can be written as a countable union/intersection/complement of elements of $C$? I would say that it is true but was told that it is only true if $E$ is a separable set. Why is that so?,Let $E$ be a set. Let $C$ be a collection of subsets of E. Denote by $\sigma(C)$ the $\sigma$-algebra generated by $C$ i.e. the intersection of all $\sigma$-algebra containing $C$. Is it true that any element $A \in \sigma(C)$ can be written as a countable union/intersection/complement of elements of $C$? I would say that it is true but was told that it is only true if $E$ is a separable set. Why is that so?,,['measure-theory']
65,Measure of the image of a function,Measure of the image of a function,,"Suppose $f:\mathbb{R}\rightarrow\mathbb{R}$ is a non-decreasing continuous function (probably continuous isn't needed). Let $g(x)=f(x)+x$. Does it follow that for any measurable set $S$, $m(g(S))=m(f(S))+m(S)$? I'm pretty sure it does, but can't figure out how to prove it. This came up while trying to prove Folland 2.1.9.c (where $f$ is the Cantor function and $S$ is the Cantor set).","Suppose $f:\mathbb{R}\rightarrow\mathbb{R}$ is a non-decreasing continuous function (probably continuous isn't needed). Let $g(x)=f(x)+x$. Does it follow that for any measurable set $S$, $m(g(S))=m(f(S))+m(S)$? I'm pretty sure it does, but can't figure out how to prove it. This came up while trying to prove Folland 2.1.9.c (where $f$ is the Cantor function and $S$ is the Cantor set).",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
66,question about the spectral theorem of self-adjoint operators,question about the spectral theorem of self-adjoint operators,,"Let $A\in\mathcal{L}(E)$ be a self-adjoint operator on a separable complex Hilbert space $E$. Then there exists a $\sigma$-finite measure space $(X,\mu)$, a bounded, measurable, real-valued function $\varphi$ on $X$, and a unitary map $U: E\rightarrow L^2(X, \mu)$ such that $$\left[UAU^*f\right](\lambda)=\varphi(\lambda)f(\lambda),\;\forall f\in L^2(X, \mu).$$ I want to know what happen if $E$ is not separable. Thank you!","Let $A\in\mathcal{L}(E)$ be a self-adjoint operator on a separable complex Hilbert space $E$. Then there exists a $\sigma$-finite measure space $(X,\mu)$, a bounded, measurable, real-valued function $\varphi$ on $X$, and a unitary map $U: E\rightarrow L^2(X, \mu)$ such that $$\left[UAU^*f\right](\lambda)=\varphi(\lambda)f(\lambda),\;\forall f\in L^2(X, \mu).$$ I want to know what happen if $E$ is not separable. Thank you!",,"['functional-analysis', 'measure-theory', 'hilbert-spaces', 'spectral-theory']"
67,On the Riemann Sum Like of $L^{p}$ Functions,On the Riemann Sum Like of  Functions,L^{p},"If $f$ is a continuous function on $[0,1]$, then the following is clear: \begin{align*} \lim_{n\rightarrow\infty}n\sum_{k=0}^{n-1}\left(\int_{k/n}^{(k+1)/n}f(x)dx\right)^{2}=\int_{0}^{1}f^{2}(x)dx, \end{align*} but that is also true for $L^{2}[0,1]$, I tried to approximate using mollifier but no help. And I wonder why the Hilbert space $L^{2}$ does matter, that is, does this also hold for any $L^{p}$ for $1\leq p<\infty$ for nonnegative function $f$: \begin{align*} \lim_{n\rightarrow\infty}n^{p-1}\sum_{k=0}^{n-1}\left(\int_{k/n}^{(k+1)/n}f(x)dx\right)^{p}=\int_{0}^{1}f^{p}(x)dx. \end{align*}","If $f$ is a continuous function on $[0,1]$, then the following is clear: \begin{align*} \lim_{n\rightarrow\infty}n\sum_{k=0}^{n-1}\left(\int_{k/n}^{(k+1)/n}f(x)dx\right)^{2}=\int_{0}^{1}f^{2}(x)dx, \end{align*} but that is also true for $L^{2}[0,1]$, I tried to approximate using mollifier but no help. And I wonder why the Hilbert space $L^{2}$ does matter, that is, does this also hold for any $L^{p}$ for $1\leq p<\infty$ for nonnegative function $f$: \begin{align*} \lim_{n\rightarrow\infty}n^{p-1}\sum_{k=0}^{n-1}\left(\int_{k/n}^{(k+1)/n}f(x)dx\right)^{p}=\int_{0}^{1}f^{p}(x)dx. \end{align*}",,"['real-analysis', 'functional-analysis', 'measure-theory']"
68,Ergodicity of a measurable transformation on $\mathbb{T}^2$,Ergodicity of a measurable transformation on,\mathbb{T}^2,"Let the dynamical system $(\mathbb{T}^2,\mathcal{B}_{\mathbb{T}^2},m_{\mathbb{T^2}},T)$ where $m_{\Bbb{T}^2}=m_{\Bbb{T}} \times m_{\Bbb{T}}$ the product measure of the Lebesgue measure $m$ on the circle $\Bbb{T}$ and $$T(x,y)=(x+a,y+2x+b) \text{mod1}$$ It is not difficult to prove using Fubini's theorem that $T$ is measure preserving For which $a,b \in \Bbb{R}$ is $T$  ergodic? I'm new to ergodic theory and i would appreciate any help solving this problem. My thoughts are to use the theorem which states that: If $f:\Bbb{T^2} \to \Bbb{T}^2$ such that $f \in L^2(\Bbb{T}^2)$ and  $f(T(x,y))=f(x,y) \Rightarrow$ $f$ is constant almost everywhere,then $T$ is ergodic. To use this i took the Fourier expansion of $f$ in $\Bbb{T^2}$ (which converges to $f$ with respect to the $L^2$ norm) to find the form of the values $a,b$ but i could not solve it. Can someone help me? Thank you in advance.","Let the dynamical system $(\mathbb{T}^2,\mathcal{B}_{\mathbb{T}^2},m_{\mathbb{T^2}},T)$ where $m_{\Bbb{T}^2}=m_{\Bbb{T}} \times m_{\Bbb{T}}$ the product measure of the Lebesgue measure $m$ on the circle $\Bbb{T}$ and $$T(x,y)=(x+a,y+2x+b) \text{mod1}$$ It is not difficult to prove using Fubini's theorem that $T$ is measure preserving For which $a,b \in \Bbb{R}$ is $T$  ergodic? I'm new to ergodic theory and i would appreciate any help solving this problem. My thoughts are to use the theorem which states that: If $f:\Bbb{T^2} \to \Bbb{T}^2$ such that $f \in L^2(\Bbb{T}^2)$ and  $f(T(x,y))=f(x,y) \Rightarrow$ $f$ is constant almost everywhere,then $T$ is ergodic. To use this i took the Fourier expansion of $f$ in $\Bbb{T^2}$ (which converges to $f$ with respect to the $L^2$ norm) to find the form of the values $a,b$ but i could not solve it. Can someone help me? Thank you in advance.",,"['measure-theory', 'fourier-analysis', 'dynamical-systems', 'ergodic-theory']"
69,Showing an integral/kernel function is measurable.,Showing an integral/kernel function is measurable.,,"We have two measurable spaces $(X,A)$ and $(Y, B)$, and a kernel $K(x,y)$. Also, $f$ is some $B$- measurable function. We wish to show that $x \to \int f(y)K(x,y)$ is $A$-measurable. My thought process: Call the function in question $g(x)$. For our function to be $A$-measurable, we need that for any $b \in B$ $g^{-1}(b) \in A$. Now, we assumed $f$ is $B$-measurable and we know that by definition, for each $x \in X$, $b \to K(x,b)$ is a measure on $(Y,B)$. So the integral is well defined (with $K$ being like a very general version of ""dx"" in a sense, I think...) Though, none of this gives me a clue on how to tie it to $A$-measurability. Any suggestions?","We have two measurable spaces $(X,A)$ and $(Y, B)$, and a kernel $K(x,y)$. Also, $f$ is some $B$- measurable function. We wish to show that $x \to \int f(y)K(x,y)$ is $A$-measurable. My thought process: Call the function in question $g(x)$. For our function to be $A$-measurable, we need that for any $b \in B$ $g^{-1}(b) \in A$. Now, we assumed $f$ is $B$-measurable and we know that by definition, for each $x \in X$, $b \to K(x,b)$ is a measure on $(Y,B)$. So the integral is well defined (with $K$ being like a very general version of ""dx"" in a sense, I think...) Though, none of this gives me a clue on how to tie it to $A$-measurability. Any suggestions?",,"['integration', 'measure-theory']"
70,"What does the phrase ""Lusin-type"" mean?","What does the phrase ""Lusin-type"" mean?",,"This might be a English question rather than a mathematical question, however I was wondering what the phrase ""Lusin-type"" refers to. I have seen a lot of theorems so-called ""Lusin-type theorem"" or ""quantitative Lusin-type theorem"". However I am not in the field of measure theory, I only know the Lusin's theorem, informally saying that ""every measurable function is nearly continuous"". I feel the phrase ""Lusin-type"" means, except on a set of small measure, some property holds almost everywhere on the rest of domain.","This might be a English question rather than a mathematical question, however I was wondering what the phrase ""Lusin-type"" refers to. I have seen a lot of theorems so-called ""Lusin-type theorem"" or ""quantitative Lusin-type theorem"". However I am not in the field of measure theory, I only know the Lusin's theorem, informally saying that ""every measurable function is nearly continuous"". I feel the phrase ""Lusin-type"" means, except on a set of small measure, some property holds almost everywhere on the rest of domain.",,"['measure-theory', 'partial-differential-equations', 'terminology', 'sobolev-spaces']"
71,Prove that two definitions of Separable Processes are equivalent,Prove that two definitions of Separable Processes are equivalent,,"In a number of sources eg (Doob 1950 Stochastic Processes), the definition of a separable stochastic process is as follows: A random process $ X(t), t \in \mathbb{R} $ is separable if there exists a countable set $ D \subset \mathbb{R} $ and a fixed event $ N $ for which $ \mathbb{P}(N) = 0 $, such that for any closed interval $ B \subset \mathbb{R}$ and open interval $ I \subset \mathbb{R} $ the two sets     \begin{equation*} 	\left\lbrace \omega: X(t,w) \in B, \text{ for all } t \in I \right\rbrace\text{ and }\left\lbrace \omega: X(t,w) \in B, \text{ for all } t \in I \cap D \right\rbrace 	\end{equation*}     differ by a subset of $ N. $ Billingsley uses the follow definition: A random process $ X(t), t \in \mathbb{R} $ is separable if there exists a countable set $ D \subset \mathbb{R} $ such that (with probability 1) for each $ t \in \mathbb{R}$ there exists a sequence $ t_1, t_2, \dots $ such that  \begin{equation*} 	t_n \in D,\quad  t_n \longrightarrow t, \quad x(t_n) \longrightarrow x(t). \end{equation*} The second definition seems much nicer, more intuitive and easier to use. But I'm struggling to show that these definitions are equivalent. I know that the second definition is equivalent to supposing that for every open interval $I$ containing $t$, $X(t)$ lies in the closure of $[X(s):s \in I\cap D]$ which looks promising but I'm not sure how to use it. Any ideas?","In a number of sources eg (Doob 1950 Stochastic Processes), the definition of a separable stochastic process is as follows: A random process $ X(t), t \in \mathbb{R} $ is separable if there exists a countable set $ D \subset \mathbb{R} $ and a fixed event $ N $ for which $ \mathbb{P}(N) = 0 $, such that for any closed interval $ B \subset \mathbb{R}$ and open interval $ I \subset \mathbb{R} $ the two sets     \begin{equation*} 	\left\lbrace \omega: X(t,w) \in B, \text{ for all } t \in I \right\rbrace\text{ and }\left\lbrace \omega: X(t,w) \in B, \text{ for all } t \in I \cap D \right\rbrace 	\end{equation*}     differ by a subset of $ N. $ Billingsley uses the follow definition: A random process $ X(t), t \in \mathbb{R} $ is separable if there exists a countable set $ D \subset \mathbb{R} $ such that (with probability 1) for each $ t \in \mathbb{R}$ there exists a sequence $ t_1, t_2, \dots $ such that  \begin{equation*} 	t_n \in D,\quad  t_n \longrightarrow t, \quad x(t_n) \longrightarrow x(t). \end{equation*} The second definition seems much nicer, more intuitive and easier to use. But I'm struggling to show that these definitions are equivalent. I know that the second definition is equivalent to supposing that for every open interval $I$ containing $t$, $X(t)$ lies in the closure of $[X(s):s \in I\cap D]$ which looks promising but I'm not sure how to use it. Any ideas?",,"['probability', 'measure-theory', 'stochastic-processes']"
72,"On a finite measure space, $f_n \to f$ uniform and $f$ integrable implies $f_n$ integrable and $\int_{\Omega}f_nd\mu\to\int_{\Omega}fd\mu$","On a finite measure space,  uniform and  integrable implies  integrable and",f_n \to f f f_n \int_{\Omega}f_nd\mu\to\int_{\Omega}fd\mu,"I try to prove the following. Let ($\Omega, \mathcal{A}, \mu)$ be a finite measure space and suppose $f_n:\Omega\to\mathbb{R}$, $n\in\mathbb{N}$ and $f:\Omega\to\mathbb{R}$ are measurable functions. In addition, assume $f$ is integrable. Show that, if $f_n\to f$ uniform, then, for large $n$, $f_n$ is integrable and \begin{equation} \int_{\Omega}f_nd\mu\to\int_{\Omega}fd\mu. \end{equation} So we know that $\mu(\Omega)<\infty$, $\int_{\Omega}fd\mu<\infty$ and that  \begin{equation} \forall \epsilon>0 \quad \exists N>0 \quad \text{s.t.} \quad n\geq N \quad \implies \quad |f_n(\omega)-f(\omega)|<\epsilon\quad\forall\omega\in\Omega \end{equation} I think these together imply that $\int_{\Omega}|f_n-f|d\mu<\infty$ and since \begin{equation} \int_{\Omega}|f_n-f|d\mu\leq\int_{\Omega}|f_n|d\mu-\int_{\Omega}|f|d\mu<\infty, \end{equation} $\int_{\Omega}|f_n|d\mu<\infty$, thus $f_n$ is integrable for large enough n. I hope that the second result also follows from something like this, and that this argument is correct. Any hints or tips are greatly appreciated, thank you.","I try to prove the following. Let ($\Omega, \mathcal{A}, \mu)$ be a finite measure space and suppose $f_n:\Omega\to\mathbb{R}$, $n\in\mathbb{N}$ and $f:\Omega\to\mathbb{R}$ are measurable functions. In addition, assume $f$ is integrable. Show that, if $f_n\to f$ uniform, then, for large $n$, $f_n$ is integrable and \begin{equation} \int_{\Omega}f_nd\mu\to\int_{\Omega}fd\mu. \end{equation} So we know that $\mu(\Omega)<\infty$, $\int_{\Omega}fd\mu<\infty$ and that  \begin{equation} \forall \epsilon>0 \quad \exists N>0 \quad \text{s.t.} \quad n\geq N \quad \implies \quad |f_n(\omega)-f(\omega)|<\epsilon\quad\forall\omega\in\Omega \end{equation} I think these together imply that $\int_{\Omega}|f_n-f|d\mu<\infty$ and since \begin{equation} \int_{\Omega}|f_n-f|d\mu\leq\int_{\Omega}|f_n|d\mu-\int_{\Omega}|f|d\mu<\infty, \end{equation} $\int_{\Omega}|f_n|d\mu<\infty$, thus $f_n$ is integrable for large enough n. I hope that the second result also follows from something like this, and that this argument is correct. Any hints or tips are greatly appreciated, thank you.",,"['integration', 'measure-theory']"
73,Sequences of Simple Functions Increasing and Decreasing,Sequences of Simple Functions Increasing and Decreasing,,"Let $f : E \to \Bbb{R}$ be a bounded measurable function. Show that there are sequences of simple functions on $E$, $\{\varphi_n \}$ and $\{\phi_n \}$, such that one is increasing an the other is decreasing, and both of which converge uniformly to $f$ on $E$. I realize this has been asked on this website, but all of the solutions offered seemed rather complicated. So I want to present my solution which I open up to criticism (please do, especially if you think it is wrong)","Let $f : E \to \Bbb{R}$ be a bounded measurable function. Show that there are sequences of simple functions on $E$, $\{\varphi_n \}$ and $\{\phi_n \}$, such that one is increasing an the other is decreasing, and both of which converge uniformly to $f$ on $E$. I realize this has been asked on this website, but all of the solutions offered seemed rather complicated. So I want to present my solution which I open up to criticism (please do, especially if you think it is wrong)",,"['real-analysis', 'measure-theory', 'proof-verification']"
74,Lebesgue measurable sets are invariant under translations and dilations?,Lebesgue measurable sets are invariant under translations and dilations?,,"From Folland's book, this theorem is proved as following: Actually I am pretty confused about this proof, is there any other way to prove this theorem? More explicitly, can we use the following theorem to prove this? I really appreciate your help","From Folland's book, this theorem is proved as following: Actually I am pretty confused about this proof, is there any other way to prove this theorem? More explicitly, can we use the following theorem to prove this? I really appreciate your help",,['measure-theory']
75,"Show that $f(x)=\mu((A+x) \cap B)$ is continues, where $A,B \subset \Bbb R$ are measurable sets with a positive and finite measure","Show that  is continues, where  are measurable sets with a positive and finite measure","f(x)=\mu((A+x) \cap B) A,B \subset \Bbb R","Let $A,B \subset \Bbb R$ be measurable sets with a positive and finite measure, and let $\mu$ be the Lebesgue measure. Define $f(x)=\mu((A+x) \cap B)$. Show that $f$ is continues. I'm not sure how to approach this. Any clues?","Let $A,B \subset \Bbb R$ be measurable sets with a positive and finite measure, and let $\mu$ be the Lebesgue measure. Define $f(x)=\mu((A+x) \cap B)$. Show that $f$ is continues. I'm not sure how to approach this. Any clues?",,"['measure-theory', 'lebesgue-measure']"
76,"We define a map $T: L^2[0,1] \to L^2[0,1]$ s.t $T(f)=\int_0^1 fgdx$. Determine $||T||$.",We define a map  s.t . Determine .,"T: L^2[0,1] \to L^2[0,1] T(f)=\int_0^1 fgdx ||T||","Let $g \in L^ {\infty}$ we define a map $T: L^2[0,1] \to L^2[0,1]$ s.t $T(f)=\int_0^1 fgdx$. Determine $||T||$. I have seen that $||T||=\sup \{||T(f)|| : ||f||=1\} \leq ||g||_{\infty}$ How to prove the converse? I also know that the set $E_n=\{x \in [0,1]:  |g(x) >||g||_{\infty} - \frac1n\}$ has positive measure. So please check what I have done is right or not and provide the answer in details.","Let $g \in L^ {\infty}$ we define a map $T: L^2[0,1] \to L^2[0,1]$ s.t $T(f)=\int_0^1 fgdx$. Determine $||T||$. I have seen that $||T||=\sup \{||T(f)|| : ||f||=1\} \leq ||g||_{\infty}$ How to prove the converse? I also know that the set $E_n=\{x \in [0,1]:  |g(x) >||g||_{\infty} - \frac1n\}$ has positive measure. So please check what I have done is right or not and provide the answer in details.",,"['functional-analysis', 'measure-theory', 'lp-spaces']"
77,How common are probability distributions with a finite variance?,How common are probability distributions with a finite variance?,,"It's always very surprising to learn that some of the entities one has been assiduously studying actually represent negligibly tiny minorities (e.g. continuous functions vis-à-vis all functions)... Now, the Central Limit Theorem, for one, holds only for probability distributions with a finite variance. How common are such distributions in the space of all probability distributions? More formally, let $U$ be the set of all probability distributions on $\mathbb{R}$ (say), and $F \subset U$ be the subset of those probability distributions that have a finite variance.  I expect that, of the cardinalities $|F|$ and $|U\setminus F|$, one will be a strictly larger infinity than the other, but I have no intuition as to which. (I guess this is a ""meta-measure theory"" question.)","It's always very surprising to learn that some of the entities one has been assiduously studying actually represent negligibly tiny minorities (e.g. continuous functions vis-à-vis all functions)... Now, the Central Limit Theorem, for one, holds only for probability distributions with a finite variance. How common are such distributions in the space of all probability distributions? More formally, let $U$ be the set of all probability distributions on $\mathbb{R}$ (say), and $F \subset U$ be the subset of those probability distributions that have a finite variance.  I expect that, of the cardinalities $|F|$ and $|U\setminus F|$, one will be a strictly larger infinity than the other, but I have no intuition as to which. (I guess this is a ""meta-measure theory"" question.)",,"['probability', 'measure-theory', 'probability-distributions', 'set-theory', 'central-limit-theorem']"
78,"If $f\in L^1_{loc}$, does it mean that $f$ is continuous on $\mathbb{R}$?","If , does it mean that  is continuous on ?",f\in L^1_{loc} f \mathbb{R},"Let $L^1_{\text{loc}}$ denote locally compact and $(Arf)$ denote the average of a function $f$.  I already have the proof for the following Theorem state as $\text{Theorem:  If} ~~f\in L^1_{loc}~~\text{then}~~ \lim_{r\to 0}(Ar f )(x) = f (x)$ for $m$ — a.e. $x\in \mathbb{R}^n$. Now, I want to construct a parallel proof for the following statement: $$\text{If}~ f(x)~\text{ is continuous on}~ \mathbb{R,}~\text{ prove that}~\lim_{r\to 0}(Arf)(x) = f(x)$$ for all $x$. My questions are; what modifications do I have to make in the above Theorem so as to write an independent proof to my statement?  What is the relationship between $\mathbb{R}$ and $L^1_{\text{loc}}$?","Let $L^1_{\text{loc}}$ denote locally compact and $(Arf)$ denote the average of a function $f$.  I already have the proof for the following Theorem state as $\text{Theorem:  If} ~~f\in L^1_{loc}~~\text{then}~~ \lim_{r\to 0}(Ar f )(x) = f (x)$ for $m$ — a.e. $x\in \mathbb{R}^n$. Now, I want to construct a parallel proof for the following statement: $$\text{If}~ f(x)~\text{ is continuous on}~ \mathbb{R,}~\text{ prove that}~\lim_{r\to 0}(Arf)(x) = f(x)$$ for all $x$. My questions are; what modifications do I have to make in the above Theorem so as to write an independent proof to my statement?  What is the relationship between $\mathbb{R}$ and $L^1_{\text{loc}}$?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
79,Generating a countable mutually disjoint collection of arbitarally small measurable sets.,Generating a countable mutually disjoint collection of arbitarally small measurable sets.,,More specifically Assume that X has a collection of arbitarally small measurable sets. Is it possible to then generate a countable mutually disjoint collection of arbitarally small measurable sets. It is obvious that you can make a countable collection. It isn't so obvious that you can make a disjoint collection.,More specifically Assume that X has a collection of arbitarally small measurable sets. Is it possible to then generate a countable mutually disjoint collection of arbitarally small measurable sets. It is obvious that you can make a countable collection. It isn't so obvious that you can make a disjoint collection.,,"['real-analysis', 'measure-theory']"
80,Proving a key theorem for an additive but not sigma additive measure,Proving a key theorem for an additive but not sigma additive measure,,"I am confused by a maths book I am reading. It says: let $\mu$ be a measure that is additive but not $\sigma$ additive, prove that theorem 1 still continues to hold, despite the non-$\sigma$ additivity. And this theorem 1 is the following: Theorem 1: Let $\mu$ be a $\sigma$ additive measure on a semiring $F_{\mu}$, and suppose the sets $A,A_{1},A_{2},A_{3} $... where $A_{1},A_{2},A_{3}... $are pairwise disjoint sets of $A$, all belong to $F_{\mu}$, then $\sum_{k=1}^{\infty }\mu\left ( A_{k} \right )\leqslant \mu\left ( A \right )$ Does this theorem 1 really hold without $\sigma$ additivity? If so, how do I prove it? I am confused because the theorem appears to require $\sigma$ additivity to hold. I am sort of wondering if it is a mistake in the book.","I am confused by a maths book I am reading. It says: let $\mu$ be a measure that is additive but not $\sigma$ additive, prove that theorem 1 still continues to hold, despite the non-$\sigma$ additivity. And this theorem 1 is the following: Theorem 1: Let $\mu$ be a $\sigma$ additive measure on a semiring $F_{\mu}$, and suppose the sets $A,A_{1},A_{2},A_{3} $... where $A_{1},A_{2},A_{3}... $are pairwise disjoint sets of $A$, all belong to $F_{\mu}$, then $\sum_{k=1}^{\infty }\mu\left ( A_{k} \right )\leqslant \mu\left ( A \right )$ Does this theorem 1 really hold without $\sigma$ additivity? If so, how do I prove it? I am confused because the theorem appears to require $\sigma$ additivity to hold. I am sort of wondering if it is a mistake in the book.",,"['real-analysis', 'measure-theory']"
81,"Let $f:[a,b]\times[c,d]\rightarrow\mathbb{R}$ be continuous. Prove continuity of the function $F$",Let  be continuous. Prove continuity of the function,"f:[a,b]\times[c,d]\rightarrow\mathbb{R} F","Let $f:[a,b]\times[c,d]\rightarrow\mathbb{R}$ be continuous. Prove continuity of the function $F:[a,b]\rightarrow\mathbb{R}$ defined by $F(s)=\int_c^d f(s,t)dt$ *Here's what I tried to do (with questions): Since $f$ is continuous, $f$ is Riemann integrable. (Can I conclude $f$ is separately continuous? that is $f(s,t)$ is continuous in $s$ for each fixed $t$.) Since $f$ is integrable, so linearity holds (If not integrable, then linearity cannot hold, right?) Thus, $|\int_c^df(x,t)dt-\int_c^df(y,t)dt|=|\int_c^d(f(x,t)-f(y,t))dt|$. ($t$ is the variable, and $x,y$ are fixed. So if $f(s,t)$ is continuous in $t$ for each fixed $s$, can we also conclude the same equality?) Since $f$ is uniformly continuous, because the domain is compact, $\exists\delta>0$, such that $|x-y|<\delta$, then $|f(x,t)-f(y,t)|<\frac{\epsilon}{|c-d|}$ (Would $f$ be separately continuous be enough for this inequality?) If the above is correct, then the result follows, i.e.$F$ is continuous.","Let $f:[a,b]\times[c,d]\rightarrow\mathbb{R}$ be continuous. Prove continuity of the function $F:[a,b]\rightarrow\mathbb{R}$ defined by $F(s)=\int_c^d f(s,t)dt$ *Here's what I tried to do (with questions): Since $f$ is continuous, $f$ is Riemann integrable. (Can I conclude $f$ is separately continuous? that is $f(s,t)$ is continuous in $s$ for each fixed $t$.) Since $f$ is integrable, so linearity holds (If not integrable, then linearity cannot hold, right?) Thus, $|\int_c^df(x,t)dt-\int_c^df(y,t)dt|=|\int_c^d(f(x,t)-f(y,t))dt|$. ($t$ is the variable, and $x,y$ are fixed. So if $f(s,t)$ is continuous in $t$ for each fixed $s$, can we also conclude the same equality?) Since $f$ is uniformly continuous, because the domain is compact, $\exists\delta>0$, such that $|x-y|<\delta$, then $|f(x,t)-f(y,t)|<\frac{\epsilon}{|c-d|}$ (Would $f$ be separately continuous be enough for this inequality?) If the above is correct, then the result follows, i.e.$F$ is continuous.",,"['real-analysis', 'measure-theory', 'riemann-integration']"
82,Difference between the volume/covolume of a lattice,Difference between the volume/covolume of a lattice,,"I am trying to learn some basic knowledge on lattices for studying Minkowski's theorems and Dirichlet's unit theorem. My problem is, I could not build the basics of  lattice theory and there are some blurred parts. I will give some definitons and then ask my questions . Let $L \subset \mathbb{R}^n$ be a lattice. It is a set $\{ \sum \alpha_i x_i | \alpha_i \in \mathbb{Z}\}$ where $\{x_1,\dots,x_n\}$ is a linearly independent set in $\mathbb{R}^n$. So we can either say that $L$ is the set above or we can define a matrix $$B=[ (x_1)_{n\times 1}   \dots (x_n)_{n \times 1}]_{n \times n}$$- generator matrix of $L$-  and say $L = \{Bv : v \in \mathbb{Z}^{n \times 1} \}$. I saw that $vol(L)$ is defined as Lebesgue measure $\mu(P)$ where $P=\{ \sum a_i x_i | 0\le a_i <1 \}$, the parallelpipped of $L$ with respect to base $\{x_1,\dots,x_n\}$. Now, i)Is $vol(L) = \det(B)$, or, $\det(B)=vol(\mathbb{R}^n / L)$?  If the latter is correct, what is $\mathbb{R}^n / L$, exactly? ii)What is the difference between covolume$(L)$ and volume$(L)$?","I am trying to learn some basic knowledge on lattices for studying Minkowski's theorems and Dirichlet's unit theorem. My problem is, I could not build the basics of  lattice theory and there are some blurred parts. I will give some definitons and then ask my questions . Let $L \subset \mathbb{R}^n$ be a lattice. It is a set $\{ \sum \alpha_i x_i | \alpha_i \in \mathbb{Z}\}$ where $\{x_1,\dots,x_n\}$ is a linearly independent set in $\mathbb{R}^n$. So we can either say that $L$ is the set above or we can define a matrix $$B=[ (x_1)_{n\times 1}   \dots (x_n)_{n \times 1}]_{n \times n}$$- generator matrix of $L$-  and say $L = \{Bv : v \in \mathbb{Z}^{n \times 1} \}$. I saw that $vol(L)$ is defined as Lebesgue measure $\mu(P)$ where $P=\{ \sum a_i x_i | 0\le a_i <1 \}$, the parallelpipped of $L$ with respect to base $\{x_1,\dots,x_n\}$. Now, i)Is $vol(L) = \det(B)$, or, $\det(B)=vol(\mathbb{R}^n / L)$?  If the latter is correct, what is $\mathbb{R}^n / L$, exactly? ii)What is the difference between covolume$(L)$ and volume$(L)$?",,"['measure-theory', 'algebraic-geometry', 'algebraic-number-theory', 'integer-lattices', 'lattices-in-lie-groups']"
83,Subsets of $\mathbb{R}$ with the same Lebesgue measure on any open set,Subsets of  with the same Lebesgue measure on any open set,\mathbb{R},"I'm looking for two sets in $\mathbb{R}$ which are both uncountable and dense, and where one is the complement of the other. I know the question has already been asked here , but the solutions still didn't feel quite right to me: the sets didn't feel ""even"" enough in $\mathbb{R}$. So I realized what the question was that I really wanted answered. Are there two Lebesgue measurable subsets of $\mathbb{R}$, one of which is the complement of the other, which have the same Lebesgue measure on any open bounded subset of $\mathbb{R}$? The density of each set in $\mathbb{R}$ is as well as their uncountability is obvious, and the sets feel ""even"" everywhere.","I'm looking for two sets in $\mathbb{R}$ which are both uncountable and dense, and where one is the complement of the other. I know the question has already been asked here , but the solutions still didn't feel quite right to me: the sets didn't feel ""even"" enough in $\mathbb{R}$. So I realized what the question was that I really wanted answered. Are there two Lebesgue measurable subsets of $\mathbb{R}$, one of which is the complement of the other, which have the same Lebesgue measure on any open bounded subset of $\mathbb{R}$? The density of each set in $\mathbb{R}$ is as well as their uncountability is obvious, and the sets feel ""even"" everywhere.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'real-numbers']"
84,Borel Sets and Homeomorphism ($ \mathbb C$ and $\mathbb R^2$),Borel Sets and Homeomorphism ( and ), \mathbb C \mathbb R^2,"I understand that that the Borel sigma algebra on the product topology of second countable metric spaces is the same as the sigma algebra generated from the product of their individual sigma algebras. In particular, $\mathscr B (\mathbb R^2) = \mathscr B (\mathbb R) \otimes \mathscr B (\mathbb R) $ Secondly, with their standard topologies,  $ \mathbb C$ is isometrically homeomorphic to $\mathbb R^2$. What is the relationship between $\mathscr B (\mathbb R^2) $ and $\mathscr B (\mathbb C) $ ? One reference I have says they are the same, but I think some form of isomorphism is more likely. And, knowing that a function from a product Borel space (to another Borel space) is measurable if and only if its projections are measurable, how would one use that rigorously to show the same for the real and imaginary parts of a complex valued function ? Update: the last part I think I have solved. Just use the continuity of the homeomorphism and the fact that compositions of continuous and Borel measurable functions are Borel measurable.","I understand that that the Borel sigma algebra on the product topology of second countable metric spaces is the same as the sigma algebra generated from the product of their individual sigma algebras. In particular, $\mathscr B (\mathbb R^2) = \mathscr B (\mathbb R) \otimes \mathscr B (\mathbb R) $ Secondly, with their standard topologies,  $ \mathbb C$ is isometrically homeomorphic to $\mathbb R^2$. What is the relationship between $\mathscr B (\mathbb R^2) $ and $\mathscr B (\mathbb C) $ ? One reference I have says they are the same, but I think some form of isomorphism is more likely. And, knowing that a function from a product Borel space (to another Borel space) is measurable if and only if its projections are measurable, how would one use that rigorously to show the same for the real and imaginary parts of a complex valued function ? Update: the last part I think I have solved. Just use the continuity of the homeomorphism and the fact that compositions of continuous and Borel measurable functions are Borel measurable.",,"['general-topology', 'measure-theory', 'borel-sets']"
85,Finding the inverse of a infimum function,Finding the inverse of a infimum function,,"What is the inverse function of $$f:t\mapsto \inf\{s\geq 0:\mu([0,s])>t\}$$ Can I just write: $$f^{-1}:s\mapsto \inf\{t\geq 0:\mu([0,s])\leq t\}$$ $\mu$ is a measure.","What is the inverse function of $$f:t\mapsto \inf\{s\geq 0:\mu([0,s])>t\}$$ Can I just write: $$f^{-1}:s\mapsto \inf\{t\geq 0:\mu([0,s])\leq t\}$$ $\mu$ is a measure.",,"['calculus', 'real-analysis', 'measure-theory', 'functions', 'inverse-function']"
86,Inequality in the proof of Fatou's Lemma,Inequality in the proof of Fatou's Lemma,,Fatou's lemma says that for any sequence $(f_n)$ of positive measurable functions. $$\int_X \lim \inf f_n du \leq \lim \inf \int_Xf_n du$$ Here is a proof: Set $g_k = \inf_{n\geq k} f_n$ then $(g_k)$ is an increasing sequence of positive measurable functions such that $g_k \rightarrow \lim \inf_n f_n$ as $k \rightarrow \infty$; and $g_k \leq f_k$ for any $k$ therefore by monotone convergence theorem $$\int_X \lim \inf_n f_n du = \lim_{n \rightarrow \infty} \int_X g_n du = \lim \inf_n \int_X g_n du \leq \lim \inf_n \int_X f_n du.$$ My questoin is: why can we say $\lim_{n \rightarrow \infty} \int_X g_n du = \lim \inf_n \int_X g_n du$ Should the equality not be a $\leq$sign? Since the limit may not exist? How is this proof working?,Fatou's lemma says that for any sequence $(f_n)$ of positive measurable functions. $$\int_X \lim \inf f_n du \leq \lim \inf \int_Xf_n du$$ Here is a proof: Set $g_k = \inf_{n\geq k} f_n$ then $(g_k)$ is an increasing sequence of positive measurable functions such that $g_k \rightarrow \lim \inf_n f_n$ as $k \rightarrow \infty$; and $g_k \leq f_k$ for any $k$ therefore by monotone convergence theorem $$\int_X \lim \inf_n f_n du = \lim_{n \rightarrow \infty} \int_X g_n du = \lim \inf_n \int_X g_n du \leq \lim \inf_n \int_X f_n du.$$ My questoin is: why can we say $\lim_{n \rightarrow \infty} \int_X g_n du = \lim \inf_n \int_X g_n du$ Should the equality not be a $\leq$sign? Since the limit may not exist? How is this proof working?,,['measure-theory']
87,Lebesgue outer measure of image of function with bounded derivative,Lebesgue outer measure of image of function with bounded derivative,,"I encountered the following problem in my real analysis course this past semester: Let $f$ be a real-valued function on $[a,b]$. Suppose that $E \subset [a,b]$ and that $f'$ exists and is bounded on $E$, say, by $M$. Prove that $\lambda^*(f(E)) \leq M\lambda^*(E)$. (source: Exercise 8.18 in A Course in Real Analysis 2nd Ed., by McDonald and Weiss) Here is what I have so far: Consider the special case when $E$ is an open set. Then $E$ is the disjoint union of countably many open intervals $(I_n)_n$. Pick any such open interval $I_n$. Let $x,y \in I_n$. By the Mean Value Theorem, $|f(x)-f(y)| \leq M|x-y|$. But $|x-y| \leq \lambda^*(I_n)$. Therefore $|f(x) - f(y)| \leq M\lambda^*(I_n)$ for any $x,y \in I_n$. It follows that $\lambda^*(f(I_n)) \leq M\lambda^*(I_n)$. Summing over all $n$ and using subadditivity of Lebesgue outer measure yields the desired inequality. For an arbitrary set $E$, I considered using the formal definition of Lebesgue outer measure. Pick a countable set of open intervals $(I_n)_n$ that covers $E$. I may assume without loss of generality that the sum of lengths is within some $\epsilon > 0$ of $\lambda^*(E)$. Then I wish to show that there is some countable set of open intervals $(J_n)_n$ that covers $f(E)$ so that $$\sum_{n=1}^\infty l(f(J_n)) \leq M\sum_{n=1}^\infty l(f(I_n)).$$ However, this seems to me equally insoluble. The fact that $f'$ may not be bounded and may not even exist outside $E$ seems to make things particularly complicated, since an interval $I_n$ may not be contained in $E$. What key insights am I missing?","I encountered the following problem in my real analysis course this past semester: Let $f$ be a real-valued function on $[a,b]$. Suppose that $E \subset [a,b]$ and that $f'$ exists and is bounded on $E$, say, by $M$. Prove that $\lambda^*(f(E)) \leq M\lambda^*(E)$. (source: Exercise 8.18 in A Course in Real Analysis 2nd Ed., by McDonald and Weiss) Here is what I have so far: Consider the special case when $E$ is an open set. Then $E$ is the disjoint union of countably many open intervals $(I_n)_n$. Pick any such open interval $I_n$. Let $x,y \in I_n$. By the Mean Value Theorem, $|f(x)-f(y)| \leq M|x-y|$. But $|x-y| \leq \lambda^*(I_n)$. Therefore $|f(x) - f(y)| \leq M\lambda^*(I_n)$ for any $x,y \in I_n$. It follows that $\lambda^*(f(I_n)) \leq M\lambda^*(I_n)$. Summing over all $n$ and using subadditivity of Lebesgue outer measure yields the desired inequality. For an arbitrary set $E$, I considered using the formal definition of Lebesgue outer measure. Pick a countable set of open intervals $(I_n)_n$ that covers $E$. I may assume without loss of generality that the sum of lengths is within some $\epsilon > 0$ of $\lambda^*(E)$. Then I wish to show that there is some countable set of open intervals $(J_n)_n$ that covers $f(E)$ so that $$\sum_{n=1}^\infty l(f(J_n)) \leq M\sum_{n=1}^\infty l(f(I_n)).$$ However, this seems to me equally insoluble. The fact that $f'$ may not be bounded and may not even exist outside $E$ seems to make things particularly complicated, since an interval $I_n$ may not be contained in $E$. What key insights am I missing?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
88,Completion (!) of proof of VI.3.4 (completeness of L1) in Lang's Real and Functional Analysis,Completion (!) of proof of VI.3.4 (completeness of L1) in Lang's Real and Functional Analysis,,"Lang starts the proof that the $\mathcal{L}^1(\mu_X, E)$ - defined as the space of pointwise a.e. limits of Cauchy sequences of step maps (defined to vanish outside sets of finite measure) - is complete in the $L^1$-norm (functions $X \to E$, $E$ Banach) by using the fact that step functions are dense in $\mathcal{L}^1$.  This is obviously a true fact but I don't see how it follows from the three facts he has already proven (no monotone or dominated convergence): VI.3.1: A Cauchy sequence of step maps has a subsequence which both converges both pointwise a.e. and converges uniformly outside a set of arbitrarily small positive measure. VI.3.2: If $(f_n)$, $(g_n)$ are Cauchy sequences of step maps converging pointwise a.e. to $f$, $g$, then $\lim\int{f_n}$, $\lim\int{g_n}$ exist and are equal, and $||f_n - g_n||_1 \to 0$.  (Thus, $\int$ is well-defined.) VI.3.3: If $(f_n)$ is a Cauchy sequence of step maps and converges pointwise a.e. to $f$, then the same for $|f_n|$ and $|f|$.  (Thus, $||\cdot||_1$ is well-defined.) Essentially what we haven't proved is that Cauchy+p.w. a.e convergence of step maps implies $L^1$-convergence to the limit function ... is this an obvious fact that I'm missing (i.e., easier than proving later theorems directly and invoking them)?","Lang starts the proof that the $\mathcal{L}^1(\mu_X, E)$ - defined as the space of pointwise a.e. limits of Cauchy sequences of step maps (defined to vanish outside sets of finite measure) - is complete in the $L^1$-norm (functions $X \to E$, $E$ Banach) by using the fact that step functions are dense in $\mathcal{L}^1$.  This is obviously a true fact but I don't see how it follows from the three facts he has already proven (no monotone or dominated convergence): VI.3.1: A Cauchy sequence of step maps has a subsequence which both converges both pointwise a.e. and converges uniformly outside a set of arbitrarily small positive measure. VI.3.2: If $(f_n)$, $(g_n)$ are Cauchy sequences of step maps converging pointwise a.e. to $f$, $g$, then $\lim\int{f_n}$, $\lim\int{g_n}$ exist and are equal, and $||f_n - g_n||_1 \to 0$.  (Thus, $\int$ is well-defined.) VI.3.3: If $(f_n)$ is a Cauchy sequence of step maps and converges pointwise a.e. to $f$, then the same for $|f_n|$ and $|f|$.  (Thus, $||\cdot||_1$ is well-defined.) Essentially what we haven't proved is that Cauchy+p.w. a.e convergence of step maps implies $L^1$-convergence to the limit function ... is this an obvious fact that I'm missing (i.e., easier than proving later theorems directly and invoking them)?",,"['real-analysis', 'functional-analysis', 'measure-theory']"
89,How can we control $\beta$ to make the mass of the n-dimensional unit ball concentrate in a layer?,How can we control  to make the mass of the n-dimensional unit ball concentrate in a layer?,\beta,"As a special phenomenon of high dimension, we know that for arbitary $\epsilon>0$,  as $n \rightarrow ∞$. we have: Where $m$ denotes the Jordan measure and $B_n$ denotes the $n$-dimensional unit ball. We say that the mass of the ball $B_n$ concentrates in an $O(n^α)$ boundary layer if Now I am asked to find a infimum for $\alpha$ to make the mass concentrates in an $O(n^α)$ boundary layer. That is, find the $\beta$ defined as: $\beta:=inf\lbrace α < 0 :$ Mass of $B_n$ concentrates in an $O(n^α)$ boundary layer.$\rbrace$. And once we find the $\beta$, may I ask what can we say about the concentration of mass if (1)$α < β$, (2)$ \alpha=\beta$, (3) $\alpha>\beta$? I have not exposed to some convoluted high-dimensional geometry context and I find myself lost in this question so far. I searched but I cannot find any material which can lead me to a start point. May I please ask for an answer (together with some explaination) if possible? Or any help or reference would be appreciate. Thanks in advance!","As a special phenomenon of high dimension, we know that for arbitary $\epsilon>0$,  as $n \rightarrow ∞$. we have: Where $m$ denotes the Jordan measure and $B_n$ denotes the $n$-dimensional unit ball. We say that the mass of the ball $B_n$ concentrates in an $O(n^α)$ boundary layer if Now I am asked to find a infimum for $\alpha$ to make the mass concentrates in an $O(n^α)$ boundary layer. That is, find the $\beta$ defined as: $\beta:=inf\lbrace α < 0 :$ Mass of $B_n$ concentrates in an $O(n^α)$ boundary layer.$\rbrace$. And once we find the $\beta$, may I ask what can we say about the concentration of mass if (1)$α < β$, (2)$ \alpha=\beta$, (3) $\alpha>\beta$? I have not exposed to some convoluted high-dimensional geometry context and I find myself lost in this question so far. I searched but I cannot find any material which can lead me to a start point. May I please ask for an answer (together with some explaination) if possible? Or any help or reference would be appreciate. Thanks in advance!",,"['real-analysis', 'geometry', 'measure-theory', 'volume']"
90,How do I show that the limit of the quotient of $n^{th}$ and $(n+1)^{th}$ norm of a function equals its infinity norm?,How do I show that the limit of the quotient of  and  norm of a function equals its infinity norm?,n^{th} (n+1)^{th},"This is an exercise from Rudin's Real and Complex analysis, which I'm solving. The question asks me to show that if $a_n=\int_{X}|f|^n d\mu$, then the limit of $\frac{a_{n+1}}{a_n}$ goes to $||f||_{\infty}$ as $n\rightarrow\infty$. I've easily shown the direction that the limit is $\le$ the infinity norm. I can't quite show the other direction, and would appreciate some help. I've tried splitting the integral in $a_n$ into two pieces, one over the set when $|f|\leq c$ for any $0<c<||f||_\infty$ and another over its complement. This is basically trying to imitate the proof of the fact that the infinity norm is the limit of $p$ norms. However, I can't manipulate this to show that the $lim $ $inf$ of the quotient is $\geq$ the infinity norm. I would really appreciate some help on this. Thank you.","This is an exercise from Rudin's Real and Complex analysis, which I'm solving. The question asks me to show that if $a_n=\int_{X}|f|^n d\mu$, then the limit of $\frac{a_{n+1}}{a_n}$ goes to $||f||_{\infty}$ as $n\rightarrow\infty$. I've easily shown the direction that the limit is $\le$ the infinity norm. I can't quite show the other direction, and would appreciate some help. I've tried splitting the integral in $a_n$ into two pieces, one over the set when $|f|\leq c$ for any $0<c<||f||_\infty$ and another over its complement. This is basically trying to imitate the proof of the fact that the infinity norm is the limit of $p$ norms. However, I can't manipulate this to show that the $lim $ $inf$ of the quotient is $\geq$ the infinity norm. I would really appreciate some help on this. Thank you.",,"['integration', 'measure-theory', 'lp-spaces']"
91,Translational Invariance of a Sigma Algebra.,Translational Invariance of a Sigma Algebra.,,"There are several questions relating to this topic, but these tend to be about Borel $\sigma$-algebras or the generators of $\sigma$-algebras. I would instead like this question to be answered using the following definition; Let $X$ be a set. A collection $\Sigma$ of subsets of $X$ is called a sigma-algebra if 1) $\emptyset \in \Sigma$; 2) $E \in \sigma$ implies $X\setminus E \in \Sigma  $; 3) $E_n \in \Sigma, n\geq 1$ implies $\cup^{\infty}_{n=1}E_n \in \Sigma$. My question is this: Let $X = \mathbb{R}$ and let $x \in R$ be a fixed number. Prove that the collection of sets $\{A+x : A \in \Sigma \}$, denoted $\Sigma + x$, is a sigma-algebra of subsets of $\mathbb{R}$. Here $A+x=\{a+x: a\in A \}$. The first criterion of the definition seems quite straightforward, but I am struggling with the other two.","There are several questions relating to this topic, but these tend to be about Borel $\sigma$-algebras or the generators of $\sigma$-algebras. I would instead like this question to be answered using the following definition; Let $X$ be a set. A collection $\Sigma$ of subsets of $X$ is called a sigma-algebra if 1) $\emptyset \in \Sigma$; 2) $E \in \sigma$ implies $X\setminus E \in \Sigma  $; 3) $E_n \in \Sigma, n\geq 1$ implies $\cup^{\infty}_{n=1}E_n \in \Sigma$. My question is this: Let $X = \mathbb{R}$ and let $x \in R$ be a fixed number. Prove that the collection of sets $\{A+x : A \in \Sigma \}$, denoted $\Sigma + x$, is a sigma-algebra of subsets of $\mathbb{R}$. Here $A+x=\{a+x: a\in A \}$. The first criterion of the definition seems quite straightforward, but I am struggling with the other two.",,"['real-analysis', 'measure-theory', 'borel-sets']"
92,Pre-image of random variable,Pre-image of random variable,,"The definition from my lecture notes of a random variable is as follows: $\textbf{Definition} \hspace{2mm} \text{A random variable is a map X}:\Omega \rightarrow \mathbb{R} \text{ such that for any} A  \in \mathscr{B}(\mathbb{R}),$ $$X^{-1}(A) = \{\omega \in \Omega:X(\omega)\in A\} \in \mathscr{F}.$$ Surely, for example, if we take X to be the number of even numbers in two rolls of a die and we take some arbitrary interval in the set of Borel $\sigma$ -algebras of $\mathbb{R}$ , such as $(-1,2)$ , not every member of this set can be mapped back to a sample point? What would $X^{-1}(-1,2)$ represent? Edit: Also, what is $X(\emptyset)$ ?","The definition from my lecture notes of a random variable is as follows: Surely, for example, if we take X to be the number of even numbers in two rolls of a die and we take some arbitrary interval in the set of Borel -algebras of , such as , not every member of this set can be mapped back to a sample point? What would represent? Edit: Also, what is ?","\textbf{Definition} \hspace{2mm} \text{A random variable is a map X}:\Omega \rightarrow \mathbb{R} \text{ such that for any} A  \in \mathscr{B}(\mathbb{R}), X^{-1}(A) = \{\omega \in \Omega:X(\omega)\in A\} \in \mathscr{F}. \sigma \mathbb{R} (-1,2) X^{-1}(-1,2) X(\emptyset)",['measure-theory']
93,Showing a measure is $\sigma$-finite,Showing a measure is -finite,\sigma,"Let ${(X_n, \mathcal A_n, \mu_n)_{n \in \mathbb N}}$ be measure spaces. Let $X_n$ be pairwise disjoint. Define $(X, \mathcal A, \mu)$ by$X=\bigcup_{i=1}^{\infty} X_n$ $\mathcal A=\{E \subset X: E \cap X_n \in \mathcal A_n \; \forall n \in \mathbb N\}$ and $\mu(E)=\sum_n \mu_n(E \cap X_n)$ I want to show that if all $\mu_n$ are $\sigma$-finite than $\mu$ is $\sigma$-finite aswell. My attempt:  I wanted to take the sequence of the unions of the sequences that make $\mu_n$ sigma finite. So the first element is the union of all the first parts of the each sequence and so on. Showing that the union is of all these equals $X$ is easy, but I fail at showing that each element has finite measure and that each element is contained in $A$ and hoped that someone could help me here.","Let ${(X_n, \mathcal A_n, \mu_n)_{n \in \mathbb N}}$ be measure spaces. Let $X_n$ be pairwise disjoint. Define $(X, \mathcal A, \mu)$ by$X=\bigcup_{i=1}^{\infty} X_n$ $\mathcal A=\{E \subset X: E \cap X_n \in \mathcal A_n \; \forall n \in \mathbb N\}$ and $\mu(E)=\sum_n \mu_n(E \cap X_n)$ I want to show that if all $\mu_n$ are $\sigma$-finite than $\mu$ is $\sigma$-finite aswell. My attempt:  I wanted to take the sequence of the unions of the sequences that make $\mu_n$ sigma finite. So the first element is the union of all the first parts of the each sequence and so on. Showing that the union is of all these equals $X$ is easy, but I fail at showing that each element has finite measure and that each element is contained in $A$ and hoped that someone could help me here.",,['measure-theory']
94,"Confused with the proof that the total variation is a positive measure, how to write a double infinite series as one infinite series,","Confused with the proof that the total variation is a positive measure, how to write a double infinite series as one infinite series,",,"I am confused with a step in the proof of Theorem 6.2 in Rudin's Real and Complex Analysis which is in page 117. It claims that $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$ since $A_{ij}$ is a partition of $E$, by the definition of the total variation, which is, $|\mu|(E)=$sup$\sum_i|\mu(E_i)|$ where the supremum is taken over all partitions $E_i$ of $E$, it seems that we should write $\sum_{i,j}|\mu(A_{ij})|$ as an infinite series rather than a double infinite series to get the conclusion. By Cantor's diagonal argument, $\{A_{ij},i,j=1,...\}$ can be written as $\{A_{11},A_{12},A_{21},A_{31},A_{22},A_{13},...\}$, denote it by $\{A_1,A_2,...\}$, is it true that $\sum_{i,j}|\mu(A_{ij})|=\sum_i|\mu(A_i)|$? Rudin says it uses the Corollary of Theorem 2.17 in the step $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$, which is, $\sum_i\sum_ja_{ij}=\sum_j\sum_ia_{ij},a_{ij}\ge0$, it does not make any sense to me, how can that lead to $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$, can anyone explain it to me? Here are the Theorem 6.2 with its proof: click here . Apologize for my poor language, I am not a native speaker. And this is my first question, appreciate for your help. UPDATE: Suppose $a_{ij}\ge0,a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ converges. Let $b_k=\sum_{i+j=k}{a_{ij}}$, then $\sum_ib_i=(a_{11})+(a_{12}+a_{21})+(a_{31}+a_{22}+a_{13})=a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ since $a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ is convergent, so my first question can be restated as: is it true that $\sum_i\sum_ja_{ij}=\sum_ib_i$?","I am confused with a step in the proof of Theorem 6.2 in Rudin's Real and Complex Analysis which is in page 117. It claims that $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$ since $A_{ij}$ is a partition of $E$, by the definition of the total variation, which is, $|\mu|(E)=$sup$\sum_i|\mu(E_i)|$ where the supremum is taken over all partitions $E_i$ of $E$, it seems that we should write $\sum_{i,j}|\mu(A_{ij})|$ as an infinite series rather than a double infinite series to get the conclusion. By Cantor's diagonal argument, $\{A_{ij},i,j=1,...\}$ can be written as $\{A_{11},A_{12},A_{21},A_{31},A_{22},A_{13},...\}$, denote it by $\{A_1,A_2,...\}$, is it true that $\sum_{i,j}|\mu(A_{ij})|=\sum_i|\mu(A_i)|$? Rudin says it uses the Corollary of Theorem 2.17 in the step $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$, which is, $\sum_i\sum_ja_{ij}=\sum_j\sum_ia_{ij},a_{ij}\ge0$, it does not make any sense to me, how can that lead to $\sum_{i,j}|\mu(A_{ij})|\le|\mu|(E)$, can anyone explain it to me? Here are the Theorem 6.2 with its proof: click here . Apologize for my poor language, I am not a native speaker. And this is my first question, appreciate for your help. UPDATE: Suppose $a_{ij}\ge0,a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ converges. Let $b_k=\sum_{i+j=k}{a_{ij}}$, then $\sum_ib_i=(a_{11})+(a_{12}+a_{21})+(a_{31}+a_{22}+a_{13})=a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ since $a_{11}+a_{12}+a_{21}+a_{31}+a_{22}+a_{13}+...$ is convergent, so my first question can be restated as: is it true that $\sum_i\sum_ja_{ij}=\sum_ib_i$?",,"['real-analysis', 'sequences-and-series', 'measure-theory']"
95,Do continuous functions preserve Lebesgue Measure to any degree?,Do continuous functions preserve Lebesgue Measure to any degree?,,"So I'm trying to prove a homework problem, and as a lemma I'd like the following to be true, although I'm not sure it is: If $f$ continuous and $\mu(f(A)) = c >0$ then for all continuous and $\|g-f\|< \epsilon$ then $|\mu(g(A)) - c|<\epsilon$. If necessary, we can take $A$ compact (it is, in my problem). Moreover, the final restriction isn't necessary for my problem. If $\mu(f(A))>0$ then I'd like to be able to show that in some ball around $f$ (in the standard function norm), $\mu(g(A))>0$. This would suffice for my purposes. Here we take $\mu$ to be the Lebesgue measure and functions being continuous mappings of $[0,1]$ onto $[0,1]$. I tried something, but it ended up being a false proof. It used compactness to extract a finite number of intervals covering $f(A)$ and $g(A)$, but I couldn't send the differences between their measures to zero uniformly.","So I'm trying to prove a homework problem, and as a lemma I'd like the following to be true, although I'm not sure it is: If $f$ continuous and $\mu(f(A)) = c >0$ then for all continuous and $\|g-f\|< \epsilon$ then $|\mu(g(A)) - c|<\epsilon$. If necessary, we can take $A$ compact (it is, in my problem). Moreover, the final restriction isn't necessary for my problem. If $\mu(f(A))>0$ then I'd like to be able to show that in some ball around $f$ (in the standard function norm), $\mu(g(A))>0$. This would suffice for my purposes. Here we take $\mu$ to be the Lebesgue measure and functions being continuous mappings of $[0,1]$ onto $[0,1]$. I tried something, but it ended up being a false proof. It used compactness to extract a finite number of intervals covering $f(A)$ and $g(A)$, but I couldn't send the differences between their measures to zero uniformly.",,"['measure-theory', 'continuity', 'lebesgue-measure']"
96,Is the Haar measure on $\mathbb{Q}_p$ complete?,Is the Haar measure on  complete?,\mathbb{Q}_p,"The field of $p$-adic numbers $\mathbb{Q}_p$ is locally compact, and so there exists a Haar measure on $(\mathbb{Q}_p,+)$. My question is whether a Haar measure on $\mathbb{Q}_p$ will also be a complete measure? The reason this question came to my mind is that I am studying about adeles and I noticed that we take the Haar measure on the infinite place, $\mathbb{R}$, to be the Lebesgue measure and not the Borel measure restricted to the Borel sets. So I wondered whether the Haar measure on $\mathbb{Q}_p$ is also complete, but I couldn't find any way to answer the question because we simply assert the existence of Haar measures on $\mathbb{Q}_p$ and move on to computing integrals with respect to this measure.","The field of $p$-adic numbers $\mathbb{Q}_p$ is locally compact, and so there exists a Haar measure on $(\mathbb{Q}_p,+)$. My question is whether a Haar measure on $\mathbb{Q}_p$ will also be a complete measure? The reason this question came to my mind is that I am studying about adeles and I noticed that we take the Haar measure on the infinite place, $\mathbb{R}$, to be the Lebesgue measure and not the Borel measure restricted to the Borel sets. So I wondered whether the Haar measure on $\mathbb{Q}_p$ is also complete, but I couldn't find any way to answer the question because we simply assert the existence of Haar measures on $\mathbb{Q}_p$ and move on to computing integrals with respect to this measure.",,"['measure-theory', 'p-adic-number-theory']"
97,Gaussian measure on sequence space,Gaussian measure on sequence space,,"We had the following definition of a Gaussian measure on a Banach space: A Gaussian probabilty measure $\mu$ on a Banach space $B$ is a Borel measure such that $\ell^*\mu$ is a real Gaussian probability measure on $\mathbb R$ for every linear functional $\ell: B\rightarrow \mathbb R$ . Where we used the push-forward of a measure $(f^*\mu)(A)=\mu(f^{-1}(A))$ . Now, let $\{\xi_n\}$ be a sequence of i.i.d. $N(0,1)$ random variables and let $\{a_n\}$ be a sequence of real numbers. Show that the law of $(a_0\xi_0,a_1\xi_1,...)$ determines a Gaussian measure on $\ell^2$ if and only if $\sum_{n\geq0}a_n^2<\infty$ . I guess, here $\ell^2$ is the space of square summable sequences. I don't really know how to prove this. The law of $(a_0\xi_0,a_1\xi_1,...)$ would be something like $\mathbb P(\{(c_n)_n:(a_0\xi_0(c_0),a_1\xi_1(c_1),....)\in A\})$ right? As a linear functional that appears in the definition one might take $\ell((c_n)_n)=\sum c_n^2$ . However, it must be for every linear functional. I also don't see the other direction. Can somebody help me with this? This is exercise 3.5 from Hairer's notes https://www.hairer.org/notes/SPDEs.pdf .","We had the following definition of a Gaussian measure on a Banach space: A Gaussian probabilty measure on a Banach space is a Borel measure such that is a real Gaussian probability measure on for every linear functional . Where we used the push-forward of a measure . Now, let be a sequence of i.i.d. random variables and let be a sequence of real numbers. Show that the law of determines a Gaussian measure on if and only if . I guess, here is the space of square summable sequences. I don't really know how to prove this. The law of would be something like right? As a linear functional that appears in the definition one might take . However, it must be for every linear functional. I also don't see the other direction. Can somebody help me with this? This is exercise 3.5 from Hairer's notes https://www.hairer.org/notes/SPDEs.pdf .","\mu B \ell^*\mu \mathbb R \ell: B\rightarrow \mathbb R (f^*\mu)(A)=\mu(f^{-1}(A)) \{\xi_n\} N(0,1) \{a_n\} (a_0\xi_0,a_1\xi_1,...) \ell^2 \sum_{n\geq0}a_n^2<\infty \ell^2 (a_0\xi_0,a_1\xi_1,...) \mathbb P(\{(c_n)_n:(a_0\xi_0(c_0),a_1\xi_1(c_1),....)\in A\}) \ell((c_n)_n)=\sum c_n^2","['probability', 'measure-theory', 'banach-spaces']"
98,"Can we define some like a ""dimensionality"" to infinite sets?","Can we define some like a ""dimensionality"" to infinite sets?",,"Consider, for example the following sets: ${x,y,z} \in \mathbb{R}^3$ for which $x^2+y^2<1$ ${x,y,z} \in \mathbb{R}^3$ for which $x^2<1$ $\mathbb{R}^3$ Of course, the cardinality is $2^{\aleph_0}$ of all. Also their volume is infinite. But, I intuitive feel, somehow there should some... measurement, some terminology exist, which would somehow differentiate some like a ""1-dimensional infinity"" of (1), the ""2-dimensional infinity"" of (2) and the ""3-dimensional infinity"" of 3. I suspect, it may have more to do with analysis as with set theory. Does any similar, well-defined terminology exist to make a distinction between (1), (2) and (3)? Edit: the ""dimensionality"" of the points closer as 1 to the $x^2=y$ parabola should be also 1.","Consider, for example the following sets: ${x,y,z} \in \mathbb{R}^3$ for which $x^2+y^2<1$ ${x,y,z} \in \mathbb{R}^3$ for which $x^2<1$ $\mathbb{R}^3$ Of course, the cardinality is $2^{\aleph_0}$ of all. Also their volume is infinite. But, I intuitive feel, somehow there should some... measurement, some terminology exist, which would somehow differentiate some like a ""1-dimensional infinity"" of (1), the ""2-dimensional infinity"" of (2) and the ""3-dimensional infinity"" of 3. I suspect, it may have more to do with analysis as with set theory. Does any similar, well-defined terminology exist to make a distinction between (1), (2) and (3)? Edit: the ""dimensionality"" of the points closer as 1 to the $x^2=y$ parabola should be also 1.",,"['integration', 'general-topology', 'measure-theory']"
99,Eigenvalues of the Frobenius-Perron Operator,Eigenvalues of the Frobenius-Perron Operator,,"Say I have a map ${\bf X}_n = {\bf F}({\bf X}_{n-1})$, ${\bf X_n} \in \mathbb{R}^N$. The Frobenius-Perron operator $L$ transfers the probability measure in phase space according to the dynamics defined by the map, ${\bf F}$. That is,  $L \mu_n = \mu_{n+1}$, where $\mu_n$ is the probability distribution in phase space at time $n$. $\mu_0$ is the initial distribution. We know that the map has an invariant measure $\mu$. In other words, $L$ has an eigenvalue 1 with eigenfunction $\mu$. My question is: under what conditions, (on ${\bf F}$ and $L$) will $L$ have an at most countably infinite set of eigenvalues?  I know that compact operators on separable Hilbert spaces can be shown to have at most countably infinite set of eigenvalues but I have never studied the space of measures formally and am not sure how to think about this. Thank you very much for your time!","Say I have a map ${\bf X}_n = {\bf F}({\bf X}_{n-1})$, ${\bf X_n} \in \mathbb{R}^N$. The Frobenius-Perron operator $L$ transfers the probability measure in phase space according to the dynamics defined by the map, ${\bf F}$. That is,  $L \mu_n = \mu_{n+1}$, where $\mu_n$ is the probability distribution in phase space at time $n$. $\mu_0$ is the initial distribution. We know that the map has an invariant measure $\mu$. In other words, $L$ has an eigenvalue 1 with eigenfunction $\mu$. My question is: under what conditions, (on ${\bf F}$ and $L$) will $L$ have an at most countably infinite set of eigenvalues?  I know that compact operators on separable Hilbert spaces can be shown to have at most countably infinite set of eigenvalues but I have never studied the space of measures formally and am not sure how to think about this. Thank you very much for your time!",,"['measure-theory', 'dynamical-systems', 'chaos-theory']"
