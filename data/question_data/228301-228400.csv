,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Complement Set of Cartesian product,Complement Set of Cartesian product,,I have a hard time knowing what it means for a thing to be a complement of a cartesian coordinate. So let's say I have the arbitrary non empty sets $A$ and $B$: $$ (A \times B)^c$$ does this equal the individual parts: $$(A \times B)^c = A^c \times B^c?$$ If so then why?,I have a hard time knowing what it means for a thing to be a complement of a cartesian coordinate. So let's say I have the arbitrary non empty sets $A$ and $B$: $$ (A \times B)^c$$ does this equal the individual parts: $$(A \times B)^c = A^c \times B^c?$$ If so then why?,,['elementary-set-theory']
1,cardinality of the set of $ \varphi: \mathbb N \to \mathbb N$ such that $\varphi$ is an increasing sequence,cardinality of the set of  such that  is an increasing sequence, \varphi: \mathbb N \to \mathbb N \varphi,"I know that the set of functions $ f:\mathbb N \to \mathbb N$ is uncountable, but what if we consider only $f$ such that $f$ is increasing? I want to know if this set is countable D: and also the case of bijective and increasing (clearly if the firstone holds then this too). I think that it could be possible that it's countable","I know that the set of functions $ f:\mathbb N \to \mathbb N$ is uncountable, but what if we consider only $f$ such that $f$ is increasing? I want to know if this set is countable D: and also the case of bijective and increasing (clearly if the firstone holds then this too). I think that it could be possible that it's countable",,"['elementary-set-theory', 'cardinals']"
2,Proof of $A\cap(B\cup C) = (A\cap B)\cup(A\cap C)$,Proof of,A\cap(B\cup C) = (A\cap B)\cup(A\cap C),"I have to resit a calculus exam and for some reason set proofs were never my best friend... Anyway, on a practice exam I encountered the following proof: $$A\cap(B\cup C) = (A\cap B)\cup(A\cap C)$$ When I draw a Venn-diagram it seems quite obvious but I couldn't manage to write the proof down properly. If someone could help me, that'd be great!","I have to resit a calculus exam and for some reason set proofs were never my best friend... Anyway, on a practice exam I encountered the following proof: $$A\cap(B\cup C) = (A\cap B)\cup(A\cap C)$$ When I draw a Venn-diagram it seems quite obvious but I couldn't manage to write the proof down properly. If someone could help me, that'd be great!",,['elementary-set-theory']
3,"I thought the | symbol meant ""divides by"", but in set theory, does it mean something different?","I thought the | symbol meant ""divides by"", but in set theory, does it mean something different?",,"I thought the | symbol meant ""divides by"", but in set theory it seems that it means ""such that.""  However, I thought we wrote ""such that"" as : . Can anybody elaborate?","I thought the | symbol meant ""divides by"", but in set theory it seems that it means ""such that.""  However, I thought we wrote ""such that"" as : . Can anybody elaborate?",,"['elementary-set-theory', 'soft-question', 'notation']"
4,Is the product of two sets well-defined if one is empty [duplicate],Is the product of two sets well-defined if one is empty [duplicate],,"This question already has answers here : How do the sets $\emptyset\times B,\ A\ \times \emptyset, \ \emptyset \times \emptyset $ look like? (6 answers) Closed 10 years ago . Let $X$ be a set. What is $X\times \emptyset$ supposed to mean? Is it just the empty set?","This question already has answers here : How do the sets $\emptyset\times B,\ A\ \times \emptyset, \ \emptyset \times \emptyset $ look like? (6 answers) Closed 10 years ago . Let $X$ be a set. What is $X\times \emptyset$ supposed to mean? Is it just the empty set?",,['elementary-set-theory']
5,Is it correct to say that $\mathbb{R}$ has fewer elements than $\mathbb{C}$ if both are infinite?,Is it correct to say that  has fewer elements than  if both are infinite?,\mathbb{R} \mathbb{C},"My math teacher said that. I disagreed, but he said that I was wrong. But I'm not convinced - is it really right? Please notice that I'm not talking about $\mathbb{R}$ $⊂$ $\mathbb{C}$,  but $\mathbb{R}$ $<$ $\mathbb{C}$.","My math teacher said that. I disagreed, but he said that I was wrong. But I'm not convinced - is it really right? Please notice that I'm not talking about $\mathbb{R}$ $⊂$ $\mathbb{C}$,  but $\mathbb{R}$ $<$ $\mathbb{C}$.",,"['elementary-set-theory', 'complex-numbers']"
6,Why should $|2^\mathbb{N}|>|\mathbb{N}^2|$ be true?,Why should  be true?,|2^\mathbb{N}|>|\mathbb{N}^2|,"I've been thinking a bit about infinite things lately, and this question I had wondered about came back to me. One of the classic expository demonstrations of Cantor's work is the two equally surprising facts that there are as many rationals as natural numbers, but there are more reals than natural numbers. This can be reduced to a statement in cardinal arithmetic, namely that $$|2^\mathbb{N}|>|\mathbb{N}^2|$$ Now, we can think of these sets as two collections of functions, $2^\mathbb{N}=\{f:\mathbb{N}\to \{0,1\}\}$ and $\mathbb{N}^2=\{f:\{0,1\}\to\mathbb{N}\}$. So it seems that what this statement (and others like it) is saying, is that if you want more functions, you're better off having a large domain than a large codomain. Is there an intuitive explanation for why this should be true?","I've been thinking a bit about infinite things lately, and this question I had wondered about came back to me. One of the classic expository demonstrations of Cantor's work is the two equally surprising facts that there are as many rationals as natural numbers, but there are more reals than natural numbers. This can be reduced to a statement in cardinal arithmetic, namely that $$|2^\mathbb{N}|>|\mathbb{N}^2|$$ Now, we can think of these sets as two collections of functions, $2^\mathbb{N}=\{f:\mathbb{N}\to \{0,1\}\}$ and $\mathbb{N}^2=\{f:\{0,1\}\to\mathbb{N}\}$. So it seems that what this statement (and others like it) is saying, is that if you want more functions, you're better off having a large domain than a large codomain. Is there an intuitive explanation for why this should be true?",,"['elementary-set-theory', 'intuition']"
7,The set of rationals has the same cardinality as the set of integers,The set of rationals has the same cardinality as the set of integers,,"The set of rationals $\mathbb{Q}$ has the same cardinality as the set of integers $\mathbb{Z}$. True or false? This was a question on an old exam for our class. The correct answer is true. However, I did some additional reading and came across Cantor's transfinite numbers. In the book I'm reading, it says that ""there are more real numbers (which include rational and irrational numbers) than there are integers"". So can it also be said that there are more rational numbers than integers? And so can we say that the above statement is false?","The set of rationals $\mathbb{Q}$ has the same cardinality as the set of integers $\mathbb{Z}$. True or false? This was a question on an old exam for our class. The correct answer is true. However, I did some additional reading and came across Cantor's transfinite numbers. In the book I'm reading, it says that ""there are more real numbers (which include rational and irrational numbers) than there are integers"". So can it also be said that there are more rational numbers than integers? And so can we say that the above statement is false?",,"['elementary-set-theory', 'integers', 'rational-numbers']"
8,Why is there both `:=` and `=` used in set notation? [duplicate],Why is there both `:=` and `=` used in set notation? [duplicate],,"This question already has answers here : Difference between $:=$ and $=$ (3 answers) Closed 5 years ago . I see two kinds of equal signs in different resources in regards to defining sets. One is := and the other is = An example : S = {1, 2, 3} or S := {1, 2, 3} I realized that resources concerned with mathematical analysis uses the latter whereas others use the former. Is there any difference in the meaning of both notations?","This question already has answers here : Difference between $:=$ and $=$ (3 answers) Closed 5 years ago . I see two kinds of equal signs in different resources in regards to defining sets. One is := and the other is = An example : S = {1, 2, 3} or S := {1, 2, 3} I realized that resources concerned with mathematical analysis uses the latter whereas others use the former. Is there any difference in the meaning of both notations?",,"['elementary-set-theory', 'notation']"
9,Proof for the theorem that the empty set is a subset of every set,Proof for the theorem that the empty set is a subset of every set,,"I'm new in here. Considering my person: I am physics student (BSc.) who has finished 2 semesters by now. Within the first two semesters, I discovered that mathematics is beautiful and that I want to learn maths in more depth than the courses at my university teach it. Therefore I'm trying to self-study the book ""Principles of Mathematical Analysis"", by Walter Rudin, in my leisure time. I have a question concerning Chapter 2, Exercise 1: Prove that the empty set is a subset of every set. My first intention would have been: Let X be an arbitrary set, then $\varnothing \cup X = X \cup \varnothing = X \implies \varnothing \subseteq X$ since $S \subseteq S \cup T$ and $T \subseteq S \cup T$ for arbitrary sets $S$ and $T$. $X$ was arbitrary, thus the assertion holds. $\Box$ But I'm not completely sure, if the prove is complete, as I haven't seen this version anywhere within a quick google search. What would you say?","I'm new in here. Considering my person: I am physics student (BSc.) who has finished 2 semesters by now. Within the first two semesters, I discovered that mathematics is beautiful and that I want to learn maths in more depth than the courses at my university teach it. Therefore I'm trying to self-study the book ""Principles of Mathematical Analysis"", by Walter Rudin, in my leisure time. I have a question concerning Chapter 2, Exercise 1: Prove that the empty set is a subset of every set. My first intention would have been: Let X be an arbitrary set, then $\varnothing \cup X = X \cup \varnothing = X \implies \varnothing \subseteq X$ since $S \subseteq S \cup T$ and $T \subseteq S \cup T$ for arbitrary sets $S$ and $T$. $X$ was arbitrary, thus the assertion holds. $\Box$ But I'm not completely sure, if the prove is complete, as I haven't seen this version anywhere within a quick google search. What would you say?",,['elementary-set-theory']
10,Unions and Functions on Sets,Unions and Functions on Sets,,"Given these conditions, I seek a proof. Let $f: A \rightarrow B$ be a function, and let $X$ and $Y$ be subsets of $A$. Prove that $f(X \cup Y) = f(X) \cup f(Y)$. I can't seem to figure it out. It appears obvious, but materializing a proof is troubling me. What is the best method of proof for this?","Given these conditions, I seek a proof. Let $f: A \rightarrow B$ be a function, and let $X$ and $Y$ be subsets of $A$. Prove that $f(X \cup Y) = f(X) \cup f(Y)$. I can't seem to figure it out. It appears obvious, but materializing a proof is troubling me. What is the best method of proof for this?",,['elementary-set-theory']
11,Is $\emptyset \in \emptyset$ or $\emptyset \subseteq \emptyset$?,Is  or ?,\emptyset \in \emptyset \emptyset \subseteq \emptyset,"Can someone give an argument, if possible using only the axioms of set theory, because I'm very weak there and have virtually no background, except the usual knowledge of the operation with sets one has to have when doing non-set theoretic non-research mathematics, why $\emptyset \in \emptyset$ or $\emptyset \subseteq \emptyset$ should or should not hold?","Can someone give an argument, if possible using only the axioms of set theory, because I'm very weak there and have virtually no background, except the usual knowledge of the operation with sets one has to have when doing non-set theoretic non-research mathematics, why $\emptyset \in \emptyset$ or $\emptyset \subseteq \emptyset$ should or should not hold?",,['elementary-set-theory']
12,"The usage of the term ""family"" in mathematics","The usage of the term ""family"" in mathematics",,"In our lecture notes, the term ""family"" is used quite persistently and with no definition given. Some examples: (i) Let V be a vectorspace and $(v_i)_{i \in I}$ a family of vectors...              (Linear Algebra, Vector Spaces) (ii)   Let F be a family of balls $B = B_r(x) \subset \mathbb R^n$ ...            (Measure Theory, Vitali Covering Lemma ) (iii) $(A_\iota)_{\iota \in I} \subset M, \ \exists g: I \rightarrow M$ s.t. for $\forall .. $              (Analysis, Axiom of Choice) I was always assuming that this term is used to avoid talking about ""sets of sets"" with regards to Russells Paradox. Is this correct andor are there any further reasons? Thanks","In our lecture notes, the term ""family"" is used quite persistently and with no definition given. Some examples: (i) Let V be a vectorspace and $(v_i)_{i \in I}$ a family of vectors...              (Linear Algebra, Vector Spaces) (ii)   Let F be a family of balls $B = B_r(x) \subset \mathbb R^n$ ...            (Measure Theory, Vitali Covering Lemma ) (iii) $(A_\iota)_{\iota \in I} \subset M, \ \exists g: I \rightarrow M$ s.t. for $\forall .. $              (Analysis, Axiom of Choice) I was always assuming that this term is used to avoid talking about ""sets of sets"" with regards to Russells Paradox. Is this correct andor are there any further reasons? Thanks",,"['elementary-set-theory', 'terminology']"
13,Notation for image and preimage,Notation for image and preimage,,"Let $X$, $Y$ be sets and $f:X\rightarrow Y$ be a map.  Denoting the image of $D\subset X$ under $f$ by $f(D)$ can sometimes be confusing. As for preimages, I've seen unambiguous notation like $f^*\mathcal{O}$, where $\mathcal{O} \subset \mathcal{P}(Y)$. (This is also an example of the ""confusing"" notation of an image, though). For images, is analogous notation $f_*D$ for denoting the image of $D\subset X$ under $f$ used in the literature?","Let $X$, $Y$ be sets and $f:X\rightarrow Y$ be a map.  Denoting the image of $D\subset X$ under $f$ by $f(D)$ can sometimes be confusing. As for preimages, I've seen unambiguous notation like $f^*\mathcal{O}$, where $\mathcal{O} \subset \mathcal{P}(Y)$. (This is also an example of the ""confusing"" notation of an image, though). For images, is analogous notation $f_*D$ for denoting the image of $D\subset X$ under $f$ used in the literature?",,"['elementary-set-theory', 'notation']"
14,Does the set of all fields exist ?,Does the set of all fields exist ?,,"We often say ""let F be a field"", so I was wondering if we could consider, in ZFC, the set of all fields without some contradictions arising (so that we wouldn't have to use the global axiom of choice in the class of all fields to choose one)","We often say ""let F be a field"", so I was wondering if we could consider, in ZFC, the set of all fields without some contradictions arising (so that we wouldn't have to use the global axiom of choice in the class of all fields to choose one)",,"['elementary-set-theory', 'field-theory']"
15,"cartesian product $A^2 = A$, possible?","cartesian product , possible?",A^2 = A,"Do there exist non-empty sets $A$ such that $A\times A = A$? $A\times A = A$ looks a little strange to me, since $A\times A$ seems somehow more complicated than $A$, hence it is unlike that they are equal, but then, I cannot think of any reason why there should not be such a (non-empty) set.","Do there exist non-empty sets $A$ such that $A\times A = A$? $A\times A = A$ looks a little strange to me, since $A\times A$ seems somehow more complicated than $A$, hence it is unlike that they are equal, but then, I cannot think of any reason why there should not be such a (non-empty) set.",,['elementary-set-theory']
16,How many subsets are there in a set of size $n$? No combinatorics,How many subsets are there in a set of size ? No combinatorics,n,Prove that a set of size $n$ contains $2^n$ subsets without the binomial expansion.  (Suppose you were starting out with only knowledge of set theory).  This has been bugging me for a while so help is appreciated.,Prove that a set of size $n$ contains $2^n$ subsets without the binomial expansion.  (Suppose you were starting out with only knowledge of set theory).  This has been bugging me for a while so help is appreciated.,,['elementary-set-theory']
17,Simple Set Theory Question,Simple Set Theory Question,,"I'm starting to learn Set Theory and I'm stuck on a question: Show that the relations $$(A \cup C)\subset(A\cup B), (A\cap C) \subset (A\cap B)$$ when combined, imply $C\subset B$. If it's in anyone's interest, this is from the online textbook ""Basic Concepts of Mathematics"" by Elias Zakon. I'm afraid I've no idea where to start. Any help would be much appreciated.","I'm starting to learn Set Theory and I'm stuck on a question: Show that the relations $$(A \cup C)\subset(A\cup B), (A\cap C) \subset (A\cap B)$$ when combined, imply $C\subset B$. If it's in anyone's interest, this is from the online textbook ""Basic Concepts of Mathematics"" by Elias Zakon. I'm afraid I've no idea where to start. Any help would be much appreciated.",,['elementary-set-theory']
18,"Chain of length $2^{\aleph_0}$ in $ (P(\mathbb{N}),\subseteq)$",Chain of length  in,"2^{\aleph_0}  (P(\mathbb{N}),\subseteq)","How can I find a chain of length $2^{\aleph_0}$ in $ (P(\mathbb{N}), \subseteq )$. The only chain I have in mind is $$\{\{0 \},\{0,1 \},\{0,1,2 \},\{ 0,1,2,3\},...,\{\mathbb{N} \} \}$$ But the chain is of length $\aleph_0$, right?","How can I find a chain of length $2^{\aleph_0}$ in $ (P(\mathbb{N}), \subseteq )$. The only chain I have in mind is $$\{\{0 \},\{0,1 \},\{0,1,2 \},\{ 0,1,2,3\},...,\{\mathbb{N} \} \}$$ But the chain is of length $\aleph_0$, right?",,"['elementary-set-theory', 'order-theory']"
19,Axiom of Double Induction?,Axiom of Double Induction?,,"What would the set-theoretical axiom of induction look like for double induction * when stated in the mathematical language of first- or second-order logic? * References as to What Double Induction Is : To questions on this StackExchange: 'Double Induction' 'Good Examples of Double Induction' 'A case of double induction?' 'Divisibility Proof with Induction - Stuck on Induction Step' ( this answer , in particular…) To other sources: 'Proof method:  Multidimensional induction' 'Mathematical Induction' (PDF) (See §14.2.4, 'Appendix 2 — The Basic Schemes of Induction:  Induction for the Natural Numbers:  Double Induction (Weak Form)' on p. 15…) 'Mathematical induction:  variants and subtleties' (PDF) (See §3, which starts at the end of p. 2…) 'Different kinds of Mathematical Induction' (PDF) (See variant 11 at the end of p. 2…) 'Proof by Mathematical Induction'/'[The] Principle of Mathematical Induction' (PDF) (See the section on 'Double Induction' that starts at the end of p. 12…)","What would the set-theoretical axiom of induction look like for double induction * when stated in the mathematical language of first- or second-order logic? * References as to What Double Induction Is : To questions on this StackExchange: 'Double Induction' 'Good Examples of Double Induction' 'A case of double induction?' 'Divisibility Proof with Induction - Stuck on Induction Step' ( this answer , in particular…) To other sources: 'Proof method:  Multidimensional induction' 'Mathematical Induction' (PDF) (See §14.2.4, 'Appendix 2 — The Basic Schemes of Induction:  Induction for the Natural Numbers:  Double Induction (Weak Form)' on p. 15…) 'Mathematical induction:  variants and subtleties' (PDF) (See §3, which starts at the end of p. 2…) 'Different kinds of Mathematical Induction' (PDF) (See variant 11 at the end of p. 2…) 'Proof by Mathematical Induction'/'[The] Principle of Mathematical Induction' (PDF) (See the section on 'Double Induction' that starts at the end of p. 12…)",,"['elementary-set-theory', 'logic', 'induction']"
20,Is there a graphical way to represent limit ordinals up to $\omega_1$?,Is there a graphical way to represent limit ordinals up to ?,\omega_1,"For some countable ordinals, I found that there are some, such as the graphical “matchstick” representation of the ordinal $\omega^2$ , and the spiral representation of the ordinal numbers up to $\omega^\omega$. Additional caveats: Both use the intuitive trick of ""compressing"" the naturals (countable infinitely many) as they approach a limit ordinal. They compress them in a ""similar"" way as the peaks of the function $\sin(1/x)$ as $x$ approaches zero. So in some way, these representations make use of a higher cardinality set: the real line. But there are uncountable many limit ordinals, and they compress from countable many into uncountable many as we approach $\omega_1$. So, shouldn't we need a set of cardinality $\aleph_2$ to represent how a set of cardinality $\aleph_1$ can compress to reach a limit? Is there any graphical representation of a set of cardinality $\aleph_2$ anyways? (or are we limited by our intuition to cardinality $\aleph_1$, as physical 3-D space is of that same cardinality?","For some countable ordinals, I found that there are some, such as the graphical “matchstick” representation of the ordinal $\omega^2$ , and the spiral representation of the ordinal numbers up to $\omega^\omega$. Additional caveats: Both use the intuitive trick of ""compressing"" the naturals (countable infinitely many) as they approach a limit ordinal. They compress them in a ""similar"" way as the peaks of the function $\sin(1/x)$ as $x$ approaches zero. So in some way, these representations make use of a higher cardinality set: the real line. But there are uncountable many limit ordinals, and they compress from countable many into uncountable many as we approach $\omega_1$. So, shouldn't we need a set of cardinality $\aleph_2$ to represent how a set of cardinality $\aleph_1$ can compress to reach a limit? Is there any graphical representation of a set of cardinality $\aleph_2$ anyways? (or are we limited by our intuition to cardinality $\aleph_1$, as physical 3-D space is of that same cardinality?",,"['elementary-set-theory', 'ordinals']"
21,Cardinality of the Mandelbrot set,Cardinality of the Mandelbrot set,,"Is the Mandelbrot set countable or of the cardinality $2^{\aleph_0}$? My intuition says the latter, but I couldn't find a bijection.","Is the Mandelbrot set countable or of the cardinality $2^{\aleph_0}$? My intuition says the latter, but I couldn't find a bijection.",,['elementary-set-theory']
22,Cardinal equalities: $\aleph_0^\mathfrak c=2^\mathfrak c$,Cardinal equalities:,\aleph_0^\mathfrak c=2^\mathfrak c,"$\aleph_0^\mathfrak c=2^\mathfrak c$ This is a question on my homework, and I am not sure how to show they equal each other, I tried Cantor-Schroeder-Bernstein but got stuck, any help would be great.","$\aleph_0^\mathfrak c=2^\mathfrak c$ This is a question on my homework, and I am not sure how to show they equal each other, I tried Cantor-Schroeder-Bernstein but got stuck, any help would be great.",,['elementary-set-theory']
23,Set theory: cardinality of a subset of a finite set.,Set theory: cardinality of a subset of a finite set.,,Suppose $A$ is a finite set of cardinality $n$. And Let $B$ be a subset of $A$ and the cardinality of $B$ equals $n$. Then $B=A$. Many texts use this fact very frequently but it seems that they just take it for granted. How can I prove this rigorously? Any help will be appreciated.,Suppose $A$ is a finite set of cardinality $n$. And Let $B$ be a subset of $A$ and the cardinality of $B$ equals $n$. Then $B=A$. Many texts use this fact very frequently but it seems that they just take it for granted. How can I prove this rigorously? Any help will be appreciated.,,['elementary-set-theory']
24,A help to understand the generalized version of the associative law of union,A help to understand the generalized version of the associative law of union,,"While I was looking for a better understanding of the the concept of families (which is not yet entirely clear) in the Halmos book, I found me with this: Let $\left\{ I_j \right\}$ be a family of sets with domain $J$; write $K = \bigcup_j I_j$ and let $\left\{ A_k \right\}$ be a family of sets with domain $K$. It is not difficult to prove that: $$\bigcup_k A_k = \bigcup_{j\in J} \bigg( \, \bigcup_ {i\in I_j}A_i\, \bigg) $$ So, I have two question about this: First: Is the next proof correct? $$\bigcup_k A_k = \bigcup_{j\in J} \bigg( \, \bigcup_ {i\in I_j}A_i\, \bigg) $$ ($\Rightarrow$) Suppose $z\in \bigcup_k A_k $. Then there is some $k\in K$ such that $z\in A_k$. But since  $K = \bigcup_j I_j$, $k\in K$ means  $k\in I_j$ for at least one $j\in J$. So, $z\in A_k$ for some $k\in I_j$, i.e., $z\in \bigcup_{k\in I_j} A_k$; for at least one $j\in J$. So then, $z\in \bigcup_{k\in I_j} A_k$ for some $j\in J$, i.e., $z\in \bigcup_{j\in J} \big( \, \bigcup_ {k\in I_j}A_k\, \big).$ ($\Leftarrow$) Now suppose $z \in \bigcup_{j\in J} \big( \, \bigcup_ {i\in I_j}A_i\, \big)$. Then there is some $j\in J$ such that $z \in \bigcup_ {i\in I_j}A_i$. For $z \in \bigcup_ {i\in I_j}A_i$ in turn there is an $i\in I_j$ such that $z\in A_i$. Let's define the set $K := \bigcup_j I_j$ so clearly $i \in K$. Then there exists an $i \in K$ such that $z\in A_i$, so $z\in \bigcup_{i\in k} A_i$. $\;\;\; \Box$ And second: At the end of the paragraph the author says: ""This is the generalized version of the associative law of union"". But I cannot see how that generalized the associative law. Could somebody explain me the reason for which it is the generalized form, if it is not too much trouble, please? As usual thanks in advance.","While I was looking for a better understanding of the the concept of families (which is not yet entirely clear) in the Halmos book, I found me with this: Let $\left\{ I_j \right\}$ be a family of sets with domain $J$; write $K = \bigcup_j I_j$ and let $\left\{ A_k \right\}$ be a family of sets with domain $K$. It is not difficult to prove that: $$\bigcup_k A_k = \bigcup_{j\in J} \bigg( \, \bigcup_ {i\in I_j}A_i\, \bigg) $$ So, I have two question about this: First: Is the next proof correct? $$\bigcup_k A_k = \bigcup_{j\in J} \bigg( \, \bigcup_ {i\in I_j}A_i\, \bigg) $$ ($\Rightarrow$) Suppose $z\in \bigcup_k A_k $. Then there is some $k\in K$ such that $z\in A_k$. But since  $K = \bigcup_j I_j$, $k\in K$ means  $k\in I_j$ for at least one $j\in J$. So, $z\in A_k$ for some $k\in I_j$, i.e., $z\in \bigcup_{k\in I_j} A_k$; for at least one $j\in J$. So then, $z\in \bigcup_{k\in I_j} A_k$ for some $j\in J$, i.e., $z\in \bigcup_{j\in J} \big( \, \bigcup_ {k\in I_j}A_k\, \big).$ ($\Leftarrow$) Now suppose $z \in \bigcup_{j\in J} \big( \, \bigcup_ {i\in I_j}A_i\, \big)$. Then there is some $j\in J$ such that $z \in \bigcup_ {i\in I_j}A_i$. For $z \in \bigcup_ {i\in I_j}A_i$ in turn there is an $i\in I_j$ such that $z\in A_i$. Let's define the set $K := \bigcup_j I_j$ so clearly $i \in K$. Then there exists an $i \in K$ such that $z\in A_i$, so $z\in \bigcup_{i\in k} A_i$. $\;\;\; \Box$ And second: At the end of the paragraph the author says: ""This is the generalized version of the associative law of union"". But I cannot see how that generalized the associative law. Could somebody explain me the reason for which it is the generalized form, if it is not too much trouble, please? As usual thanks in advance.",,['elementary-set-theory']
25,Complete first order theory with finite model is categorical,Complete first order theory with finite model is categorical,,"I am trying to prove that if $T$ is a complete first order theory that has a finite model then it has exactly one model up to isomorphism. To this end, I assumed that $T$ is complete with a finite model $M_n$. Then I assumed that $M_m$ was another model of size $m \geq n$. We know that if a theory has two finite models with different cardinalities then the theory is incomplete hence $m = n$. Now two things remain to be shown: one is that any two models of finite size $n$ are isomorphic and the other is that every infinite model is also isomorphic to this finite model (is this even possible? but we clearly need to do something about the infinite case) Thanks for helping me finish this proof. For the record: this is an exercise in Just/Weese, page 84. Edit I'm looking for a sentence $\varphi$ such that if $M_n \models \varphi$ then $M_n \cong M_m$. There are no assumptions on the language. But I think it's not possible to have a finite model for an infinite language so the language must be finite. Edit 2 After some more thinking, if there is a finite model $M$ of size $n$, let $$ \varphi = \exists v_1, \dots , v_n ((v_1 \neq v_2) \land \dots \land (v_{n-1} \neq v_n)) \land \lnot \exists v_{n+1} ((v_{n+1} \neq v_1) \land \dots \land (v_{n+1} \neq v_n))$$ that is, $\varphi$ says that the model has exactly $n$ elements. Since $T$ is complete, either $\varphi$ or $\lnot \varphi$ is provable from $T$. Since we have a model in which $\varphi$ is true we therefore know that $T \vdash \varphi$. Hence any model of $T$ must have exactly $n$ elements. Now the question is, how do I show that any two $n$-element models of $T$ must be isomorphic?","I am trying to prove that if $T$ is a complete first order theory that has a finite model then it has exactly one model up to isomorphism. To this end, I assumed that $T$ is complete with a finite model $M_n$. Then I assumed that $M_m$ was another model of size $m \geq n$. We know that if a theory has two finite models with different cardinalities then the theory is incomplete hence $m = n$. Now two things remain to be shown: one is that any two models of finite size $n$ are isomorphic and the other is that every infinite model is also isomorphic to this finite model (is this even possible? but we clearly need to do something about the infinite case) Thanks for helping me finish this proof. For the record: this is an exercise in Just/Weese, page 84. Edit I'm looking for a sentence $\varphi$ such that if $M_n \models \varphi$ then $M_n \cong M_m$. There are no assumptions on the language. But I think it's not possible to have a finite model for an infinite language so the language must be finite. Edit 2 After some more thinking, if there is a finite model $M$ of size $n$, let $$ \varphi = \exists v_1, \dots , v_n ((v_1 \neq v_2) \land \dots \land (v_{n-1} \neq v_n)) \land \lnot \exists v_{n+1} ((v_{n+1} \neq v_1) \land \dots \land (v_{n+1} \neq v_n))$$ that is, $\varphi$ says that the model has exactly $n$ elements. Since $T$ is complete, either $\varphi$ or $\lnot \varphi$ is provable from $T$. Since we have a model in which $\varphi$ is true we therefore know that $T \vdash \varphi$. Hence any model of $T$ must have exactly $n$ elements. Now the question is, how do I show that any two $n$-element models of $T$ must be isomorphic?",,"['elementary-set-theory', 'model-theory']"
26,What are the cases of not using  (countable) induction?,What are the cases of not using  (countable) induction?,,"In countably infinite union of countably infinite sets is countable the proof has been given, but when as a student I attempted the question, I tried using induction ( later to found it to be wrong way of going about that problem) but the reasoning was quite simple. I.Union of 1,2 countable set is counatble ( obvious ) II.Suppose I is true up some n. III.For case n+1 we get union of all the sets up to n, which was true by II , so we get back to case of union of two countable sets which is true. I couldn't see any flows with the above, but it was wrong, I think it was due to the fact that proving something holds for all finite n, is not the same as proving it for the infinite case. My question is, why proving something for all finite n ( after all any nu,ber that can be picked is finite), is not same as proving the infinite case ? Is there any other example induction failing for infinite clause? Another question is : Is uncountable ( infinite of course :) union of countable ( finite or infinite) is countable? (The wrong induction method I used can't even be used for this one.) Thank you PS : Modified the title as it was sugeestive of induction failing, where is the case is it is being misused.","In countably infinite union of countably infinite sets is countable the proof has been given, but when as a student I attempted the question, I tried using induction ( later to found it to be wrong way of going about that problem) but the reasoning was quite simple. I.Union of 1,2 countable set is counatble ( obvious ) II.Suppose I is true up some n. III.For case n+1 we get union of all the sets up to n, which was true by II , so we get back to case of union of two countable sets which is true. I couldn't see any flows with the above, but it was wrong, I think it was due to the fact that proving something holds for all finite n, is not the same as proving it for the infinite case. My question is, why proving something for all finite n ( after all any nu,ber that can be picked is finite), is not same as proving the infinite case ? Is there any other example induction failing for infinite clause? Another question is : Is uncountable ( infinite of course :) union of countable ( finite or infinite) is countable? (The wrong induction method I used can't even be used for this one.) Thank you PS : Modified the title as it was sugeestive of induction failing, where is the case is it is being misused.",,"['logic', 'elementary-set-theory', 'induction']"
27,Subtracting two infinities,Subtracting two infinities,,"I am Curious if the following is mathematically correct: Let $a$ be the infinite set of all nonnegative integers $0,1,2,3...$. I take from $a$ some of its elements, say integers $10$, $11$, and $12$ only. So now we have a new set $a'$ that is the infinite set of all nonnegative integers $0,1,2,3...$ except for $10$, $11$, and $12$. If I subtract: $a-a'$ the result is a set comprised of $10$, $11$, $12$ only. Is this correct? Can one subtract infinities like this? If yes, does this mean that $a \gt a'$(despite that both are infinite)?","I am Curious if the following is mathematically correct: Let $a$ be the infinite set of all nonnegative integers $0,1,2,3...$. I take from $a$ some of its elements, say integers $10$, $11$, and $12$ only. So now we have a new set $a'$ that is the infinite set of all nonnegative integers $0,1,2,3...$ except for $10$, $11$, and $12$. If I subtract: $a-a'$ the result is a set comprised of $10$, $11$, $12$ only. Is this correct? Can one subtract infinities like this? If yes, does this mean that $a \gt a'$(despite that both are infinite)?",,"['elementary-set-theory', 'infinity']"
28,Infinite DeMorgan laws,Infinite DeMorgan laws,,"Let $X$ be a set and $\{Y_\alpha\}$ is infinite system of some subsets of $X$. Is it true that: $$\bigcup_\alpha(X\setminus Y_\alpha)=X\setminus\bigcap_\alpha Y_\alpha,$$ $$\bigcap_\alpha(X\setminus Y_\alpha)=X\setminus\bigcup_\alpha Y_\alpha.$$ (infinite DeMorgan laws) Thanks a lot!","Let $X$ be a set and $\{Y_\alpha\}$ is infinite system of some subsets of $X$. Is it true that: $$\bigcup_\alpha(X\setminus Y_\alpha)=X\setminus\bigcap_\alpha Y_\alpha,$$ $$\bigcap_\alpha(X\setminus Y_\alpha)=X\setminus\bigcup_\alpha Y_\alpha.$$ (infinite DeMorgan laws) Thanks a lot!",,['elementary-set-theory']
29,Proving that the empty set is unique,Proving that the empty set is unique,,"I haven't been able to figure out if the following reasoning is correct, so I'd like to have the opinion of other people on that. The goal is to prove that the empty set is unique. In order to do that, let $E$ be a set, $A$ be an empty set and  $B$ be an empty set. I want to prove that $A = B$. First, I can try proving that $A \subset B$. I know that $\forall x \in E, x \notin A$. Now I can consider this proposition : $x \in A \Rightarrow x \in B$ Since $x \notin A$, I can safely say that that the proposition above is true. Hence, I can conclude that $A \subset B$ Am I right in my conclusion?","I haven't been able to figure out if the following reasoning is correct, so I'd like to have the opinion of other people on that. The goal is to prove that the empty set is unique. In order to do that, let $E$ be a set, $A$ be an empty set and  $B$ be an empty set. I want to prove that $A = B$. First, I can try proving that $A \subset B$. I know that $\forall x \in E, x \notin A$. Now I can consider this proposition : $x \in A \Rightarrow x \in B$ Since $x \notin A$, I can safely say that that the proposition above is true. Hence, I can conclude that $A \subset B$ Am I right in my conclusion?",,['elementary-set-theory']
30,Can any subset of $x$ be moved out of $x$?,Can any subset of  be moved out of ?,x x,"Let $x$ be a set and let $y\subset x$. Does there exist a set $z$ such that: (1) $z\cap x=\emptyset$ and (2) there exists a bijection $y \to z$ ? It is quite intuitive that the answer should be yes. My first attempt was to take a set $x'\notin x$ and to consider $z=y\times \{ x'\}$. But I am unable to show $z\cap x=\emptyset$. I could imagine a proof with the axiom of choice, but I'd prefer to avoid it if possible.","Let $x$ be a set and let $y\subset x$. Does there exist a set $z$ such that: (1) $z\cap x=\emptyset$ and (2) there exists a bijection $y \to z$ ? It is quite intuitive that the answer should be yes. My first attempt was to take a set $x'\notin x$ and to consider $z=y\times \{ x'\}$. But I am unable to show $z\cap x=\emptyset$. I could imagine a proof with the axiom of choice, but I'd prefer to avoid it if possible.",,['elementary-set-theory']
31,Is $0^\omega=1$?,Is ?,0^\omega=1,"According to a definition of ordinal exponentiation defined in Kunen's Set Theory: An Introduction to Independence Proofs (pp. 26), we define $$\begin{align} \alpha^0&=1\\ \alpha^{(\beta+1)}&=\alpha^\beta\cdot\alpha\\ \alpha^\beta&=\bigcup\{\alpha^\gamma:\gamma<\beta\}&\text{if }\beta\text{ is a limit}. \end{align}$$ So, it is correct to conclude that $0^\omega=1$, right? (In fact, we have $0^\beta=1$ for all limit $\beta$). This is quite surprising for me since I never think that other exponentiations of $0$, except $0^0$, can be $1$. Furthermore, there is another definition of ordinal exponentiation defined in Kunen's (pp. 43). It can be defined as follows. Let $$F(\alpha,\beta)=\{f\in{^\beta\alpha}:|\{\xi:f(\xi)\ne0\}|<\omega\}.$$ For any $f,g\in F(\alpha,\beta)$ such that $f\ne g$, say $f\lhd g$ iff $f(\xi)<g(\xi)$, where $\xi$ is the largest ordinal such that $f(\xi)\ne g(\xi)$. Then $\alpha^\beta=\operatorname{type}(\langle F(\alpha,\beta),\lhd\rangle)$. The book claims that this definition is equivalent to the above definition. But, as we can see, for $0^\omega$, we consider $F(0,\omega)$, which is $\emptyset$. So $\operatorname{type}(\langle F(0,\omega),\lhd\rangle)=0$. Which one is a correct one, or if you think none of them is wrong, which one is much more make sense to you?","According to a definition of ordinal exponentiation defined in Kunen's Set Theory: An Introduction to Independence Proofs (pp. 26), we define $$\begin{align} \alpha^0&=1\\ \alpha^{(\beta+1)}&=\alpha^\beta\cdot\alpha\\ \alpha^\beta&=\bigcup\{\alpha^\gamma:\gamma<\beta\}&\text{if }\beta\text{ is a limit}. \end{align}$$ So, it is correct to conclude that $0^\omega=1$, right? (In fact, we have $0^\beta=1$ for all limit $\beta$). This is quite surprising for me since I never think that other exponentiations of $0$, except $0^0$, can be $1$. Furthermore, there is another definition of ordinal exponentiation defined in Kunen's (pp. 43). It can be defined as follows. Let $$F(\alpha,\beta)=\{f\in{^\beta\alpha}:|\{\xi:f(\xi)\ne0\}|<\omega\}.$$ For any $f,g\in F(\alpha,\beta)$ such that $f\ne g$, say $f\lhd g$ iff $f(\xi)<g(\xi)$, where $\xi$ is the largest ordinal such that $f(\xi)\ne g(\xi)$. Then $\alpha^\beta=\operatorname{type}(\langle F(\alpha,\beta),\lhd\rangle)$. The book claims that this definition is equivalent to the above definition. But, as we can see, for $0^\omega$, we consider $F(0,\omega)$, which is $\emptyset$. So $\operatorname{type}(\langle F(0,\omega),\lhd\rangle)=0$. Which one is a correct one, or if you think none of them is wrong, which one is much more make sense to you?",,"['elementary-set-theory', 'exponentiation', 'ordinals']"
32,Is the fact that there are more irrational numbers than rational numbers useful?,Is the fact that there are more irrational numbers than rational numbers useful?,,"Although it is known that the cardinality of the set of irrational numbers is greater than the cardinality of the set of rational numbers, is there any usefulness/applications of this fact outside of mathematics?","Although it is known that the cardinality of the set of irrational numbers is greater than the cardinality of the set of rational numbers, is there any usefulness/applications of this fact outside of mathematics?",,"['elementary-set-theory', 'irrational-numbers', 'rational-numbers']"
33,$R$ is transitive if and only if $ R \circ R \subseteq R$,is transitive if and only if,R  R \circ R \subseteq R,"Question: Let $R$ be a relation on a set $S$. Prove the following. $R$ is transitive if and only if $ R \circ R \subseteq R$. Definition 6.3.9 states that we let $R_1$ and $R_2$ be relations on a set $S$. The composition of $R_2$ with $R_1$ is the relation $R_2 \circ R_1 =[(x,y) \in S \times S :(\exists v \in S)((x,v) \in R_1 \land (v,y) \in R_2$. Definition 6.2.9 states that we let $R$ be an equivalence relation on a set $S$. For each element $x \in S $ the set $[x]=[y \in S: (x,y) \in R$ is the equivalence class with respect to $R$. Definition 6.2.3 states that $R$ is transitive if $( \forall x, y,z \in S)((x,y) \in R \land (y,z) \in R) \rightarrow (x,z) \in R)$ Definition 3.1.2 states that we let $A$ and $B$ be sets. Then A is the subset of B, written $ A \subseteq B$ when the statement $(\forall x)[x \in A \rightarrow x \in B]$ My attempt: We have a biconditional statement. If $R$ is transitive, then $R \circ R \subseteq R$. By definition 6.2.3 $R$ is transitive if $( \forall x, y,z \in S)((x,y) \in R \land (y,z) \in R) \rightarrow (x,z) \in R)$ The final result of the proof has to be $(x,z)$ but I don't know the steps...then afterwards by applying definition 6.3.9, we have $R \circ R =[(x,z) \in S \times S :(\exists v \in S)((x,v) \in R \land (v,z) \in R$. Next, we apply definition 6.2.9 , so we have,   $[x]=[z \in S: (x,z) \in R$ Since $ R \circ R \subseteq R$ from definition 3.1.2, we know that $R \circ R$ is a subset of $R$. They have elements in common as well. If $R \circ R \subseteq R$, then $R$ is transitive. By definition 3.1.2, we have $(\forall x)[x \in R \circ R \rightarrow x \in R]$ By definition 6.3.9, we have $R \circ R =[(x,y) \in S \times S :(\exists v \in S)((x,v) \in R \land (v,y) \in R$. So, I know that we have $(x,y)$ involved for $R \circ R \subseteq R$, but what I don't understand is how to bring the $z$ into the picture because the transitive definition has $\forall x,y,z $, so there's like three elements while $ R \circ R$ and $R$ has two. I can see that they do belong to each other because both of them have $(x,y)$ in the definitions. Somehow I need to have the $(x,z)$ as the final result, but the problem is that I don't know how to prove that R is transitive...this was a part of my last homework and I didn't do too well on that part. If only $R$ was reflexive or symmetric then I would know what's going on because there are two elements which are $x$ and $y$.","Question: Let $R$ be a relation on a set $S$. Prove the following. $R$ is transitive if and only if $ R \circ R \subseteq R$. Definition 6.3.9 states that we let $R_1$ and $R_2$ be relations on a set $S$. The composition of $R_2$ with $R_1$ is the relation $R_2 \circ R_1 =[(x,y) \in S \times S :(\exists v \in S)((x,v) \in R_1 \land (v,y) \in R_2$. Definition 6.2.9 states that we let $R$ be an equivalence relation on a set $S$. For each element $x \in S $ the set $[x]=[y \in S: (x,y) \in R$ is the equivalence class with respect to $R$. Definition 6.2.3 states that $R$ is transitive if $( \forall x, y,z \in S)((x,y) \in R \land (y,z) \in R) \rightarrow (x,z) \in R)$ Definition 3.1.2 states that we let $A$ and $B$ be sets. Then A is the subset of B, written $ A \subseteq B$ when the statement $(\forall x)[x \in A \rightarrow x \in B]$ My attempt: We have a biconditional statement. If $R$ is transitive, then $R \circ R \subseteq R$. By definition 6.2.3 $R$ is transitive if $( \forall x, y,z \in S)((x,y) \in R \land (y,z) \in R) \rightarrow (x,z) \in R)$ The final result of the proof has to be $(x,z)$ but I don't know the steps...then afterwards by applying definition 6.3.9, we have $R \circ R =[(x,z) \in S \times S :(\exists v \in S)((x,v) \in R \land (v,z) \in R$. Next, we apply definition 6.2.9 , so we have,   $[x]=[z \in S: (x,z) \in R$ Since $ R \circ R \subseteq R$ from definition 3.1.2, we know that $R \circ R$ is a subset of $R$. They have elements in common as well. If $R \circ R \subseteq R$, then $R$ is transitive. By definition 3.1.2, we have $(\forall x)[x \in R \circ R \rightarrow x \in R]$ By definition 6.3.9, we have $R \circ R =[(x,y) \in S \times S :(\exists v \in S)((x,v) \in R \land (v,y) \in R$. So, I know that we have $(x,y)$ involved for $R \circ R \subseteq R$, but what I don't understand is how to bring the $z$ into the picture because the transitive definition has $\forall x,y,z $, so there's like three elements while $ R \circ R$ and $R$ has two. I can see that they do belong to each other because both of them have $(x,y)$ in the definitions. Somehow I need to have the $(x,z)$ as the final result, but the problem is that I don't know how to prove that R is transitive...this was a part of my last homework and I didn't do too well on that part. If only $R$ was reflexive or symmetric then I would know what's going on because there are two elements which are $x$ and $y$.",,"['elementary-set-theory', 'relations', 'equivalence-relations', 'function-and-relation-composition']"
34,Are there an infinite set of sets that only have one element in common with each other?,Are there an infinite set of sets that only have one element in common with each other?,,"In a card game called Dobble , there are 55 cards, each containing 8 symbols. For each group of two cards, there is only one symbol in common. (The goal of the game being to spot it faster than the other players, which is not the point of my question). If I translate that to  mathematical language, I would say that: $S = [S_1, S_2, ..., S_{55}]$. $S_n = [n_1, n_2, ..., n_8]$. For $S_n, S_m \in S$ there is one and only one $n_a = m_b$ My double (dobble) question is: Are there a finite or infinite number of sets and elements that allows such a property? I know there is one more with 30 sets containing 6 elements each (because of Dobble Kids, a lighter version of the game). How can I calculate the number of sets, the number of elements in the sets, how many different elements there are in all the sets and which elements go in which sets? Is there a formula or is it simply a step-by-step try and fail method? EDIT I realise that having sets like {1, 2, 3, 4}, {1, 5, 6, 7}, {1, 8, 9, 10}, ... answers the question (with 1 being the only element in common in each set). There is one more restriction: Each element used in the sets must appear the same number of times (for example, in 7 given sets). In the game, there are 50 symbols altogether. (55 cards, 8 symbols per card, 50 symbols altogether). I have figured out a simple example with 4 sets of 3 elements (6 elements overall): $$S_1 = [1, 2, 3], S_2 = [1, 4, 5], S_3 = [2, 5, 6], S_4 = [3, 4, 6]$$ Each element is present twice.","In a card game called Dobble , there are 55 cards, each containing 8 symbols. For each group of two cards, there is only one symbol in common. (The goal of the game being to spot it faster than the other players, which is not the point of my question). If I translate that to  mathematical language, I would say that: $S = [S_1, S_2, ..., S_{55}]$. $S_n = [n_1, n_2, ..., n_8]$. For $S_n, S_m \in S$ there is one and only one $n_a = m_b$ My double (dobble) question is: Are there a finite or infinite number of sets and elements that allows such a property? I know there is one more with 30 sets containing 6 elements each (because of Dobble Kids, a lighter version of the game). How can I calculate the number of sets, the number of elements in the sets, how many different elements there are in all the sets and which elements go in which sets? Is there a formula or is it simply a step-by-step try and fail method? EDIT I realise that having sets like {1, 2, 3, 4}, {1, 5, 6, 7}, {1, 8, 9, 10}, ... answers the question (with 1 being the only element in common in each set). There is one more restriction: Each element used in the sets must appear the same number of times (for example, in 7 given sets). In the game, there are 50 symbols altogether. (55 cards, 8 symbols per card, 50 symbols altogether). I have figured out a simple example with 4 sets of 3 elements (6 elements overall): $$S_1 = [1, 2, 3], S_2 = [1, 4, 5], S_3 = [2, 5, 6], S_4 = [3, 4, 6]$$ Each element is present twice.",,"['elementary-set-theory', 'recreational-mathematics']"
35,Notation for the set of all finite subsets of $\mathbb{N}$,Notation for the set of all finite subsets of,\mathbb{N},"Is there a ""standard"" notation to denote the set of all finite subsets of $\mathbb{N}$? (or any set, not just $\mathbb{N}$) Thanks","Is there a ""standard"" notation to denote the set of all finite subsets of $\mathbb{N}$? (or any set, not just $\mathbb{N}$) Thanks",,"['elementary-set-theory', 'notation']"
36,Properties that are true for finite sets but are (non-trivially) false for infinite sets,Properties that are true for finite sets but are (non-trivially) false for infinite sets,,"The finite analogue of the axiom of choice is true, and it seems highly intuitive that it would be true for the infinite case. It is, however, undecidable. When explaining this to myself or to others, what I typically note is that our intuitions about finite sets don't necessarily hold over for infinite sets, and we should try to discard them. But this itself is an intuition that I'm looking to fortify. I thus ask, what are examples of theorems that hold true for finite sets, and to most people would seem to hold true for infinite sets, but don't. I.e., I'm looking for something that's provably false for infinite sets rather than merely undecidable.","The finite analogue of the axiom of choice is true, and it seems highly intuitive that it would be true for the infinite case. It is, however, undecidable. When explaining this to myself or to others, what I typically note is that our intuitions about finite sets don't necessarily hold over for infinite sets, and we should try to discard them. But this itself is an intuition that I'm looking to fortify. I thus ask, what are examples of theorems that hold true for finite sets, and to most people would seem to hold true for infinite sets, but don't. I.e., I'm looking for something that's provably false for infinite sets rather than merely undecidable.",,['elementary-set-theory']
37,Set representation of natural numbers,Set representation of natural numbers,,"In Wolfgang Wechler's Universal Algebra for Computer Scientists, he says that natural numbers can be represented as finite sets: $0$ stands for $\emptyset$, $1$ for {$\emptyset$}, $2$ for {$\emptyset$,{$\emptyset$}}, $3$ for {$\emptyset$,{$\emptyset$,{$\emptyset$}}} and so on. Then he says that a more readable way is that $0 = \emptyset$ and $ n = \{0,1,\dots\,n-1\}$ for $n \ge 1$. But to me this seems different: in my opinion $3$ would be coded as $ \{\emptyset,\{\emptyset\},\{\emptyset,\{\emptyset\}\}\} $. Isn't this a mistake in the book? If it is, which construction is the ""right"" one?","In Wolfgang Wechler's Universal Algebra for Computer Scientists, he says that natural numbers can be represented as finite sets: $0$ stands for $\emptyset$, $1$ for {$\emptyset$}, $2$ for {$\emptyset$,{$\emptyset$}}, $3$ for {$\emptyset$,{$\emptyset$,{$\emptyset$}}} and so on. Then he says that a more readable way is that $0 = \emptyset$ and $ n = \{0,1,\dots\,n-1\}$ for $n \ge 1$. But to me this seems different: in my opinion $3$ would be coded as $ \{\emptyset,\{\emptyset\},\{\emptyset,\{\emptyset\}\}\} $. Isn't this a mistake in the book? If it is, which construction is the ""right"" one?",,['elementary-set-theory']
38,"Are ""pair, triple, quadruple"" considered to be sets?","Are ""pair, triple, quadruple"" considered to be sets?",,"I have always interpreted ""pair, triple, quadruple"" as ""sets containing two, three and four elements"". I have never checked this assumption. Consider the following examples: The pair $(V, \|\cdot\|)$ is a normed space. Another example is that of a graph with vertices and edges $(V, E)$. The triple (triplet) $(S, (u_i)_{i \in S}, (a_i)_{i \in S})$ is a game. The quadruple $(V, F, +, \times)$ is a vector space. Are these things sets? For example, I have seen people defining ""sub-graph"", ""sub-game"", etc. which essentially implied to me that these things are sets. It occurred to me that it might be strange to think of them as sets, because the set elements are vastly different from each other, e.g. the vector space example, or a digraph, where we insert an additional operation $o$ that specifies the orientation. What sort of mathematical structures are these objects? Is there anyway to define operations on these objects? What are all the operations that can be defined on these objects?","I have always interpreted ""pair, triple, quadruple"" as ""sets containing two, three and four elements"". I have never checked this assumption. Consider the following examples: The pair $(V, \|\cdot\|)$ is a normed space. Another example is that of a graph with vertices and edges $(V, E)$. The triple (triplet) $(S, (u_i)_{i \in S}, (a_i)_{i \in S})$ is a game. The quadruple $(V, F, +, \times)$ is a vector space. Are these things sets? For example, I have seen people defining ""sub-graph"", ""sub-game"", etc. which essentially implied to me that these things are sets. It occurred to me that it might be strange to think of them as sets, because the set elements are vastly different from each other, e.g. the vector space example, or a digraph, where we insert an additional operation $o$ that specifies the orientation. What sort of mathematical structures are these objects? Is there anyway to define operations on these objects? What are all the operations that can be defined on these objects?",,"['elementary-set-theory', 'definition']"
39,Intersection of Set A and a set containing empty set,Intersection of Set A and a set containing empty set,,"Give set $A = \{\emptyset, \{\emptyset\} , \{\{\emptyset\}\}\}$, is $\{\emptyset\} \cap A = \{\emptyset\}$ or just $\emptyset$?  I understand that $\emptyset \cap A = \emptyset$ (and why this is true), but I'm thrown off by the repeated nesting of empty sets within sets. Given that, I am under the impression that $\emptyset \cup A = A =\{\emptyset\} \cup A$.  Is this also true?","Give set $A = \{\emptyset, \{\emptyset\} , \{\{\emptyset\}\}\}$, is $\{\emptyset\} \cap A = \{\emptyset\}$ or just $\emptyset$?  I understand that $\emptyset \cap A = \emptyset$ (and why this is true), but I'm thrown off by the repeated nesting of empty sets within sets. Given that, I am under the impression that $\emptyset \cup A = A =\{\emptyset\} \cup A$.  Is this also true?",,['elementary-set-theory']
40,"Prove that for any set of 5 integers, there is at least one subset of 3 integers whose sum is divisible by 3","Prove that for any set of 5 integers, there is at least one subset of 3 integers whose sum is divisible by 3",,"How can I show that for any set of 5 integers, there is at least one subset of 3 integers whose sum is divisible by 3? I tried to think about it using the pigeonhole principle but I don't quite get it.","How can I show that for any set of 5 integers, there is at least one subset of 3 integers whose sum is divisible by 3? I tried to think about it using the pigeonhole principle but I don't quite get it.",,"['elementary-set-theory', 'integers', 'pigeonhole-principle']"
41,No set to which all functions belong,No set to which all functions belong,,"I want to prove ""There is no set to which every function belongs."" Can I approach it as follows? Attempt No. 1: Let $$F: A\rightarrow B$$ Since $$F\subset A\times B,$$ it follows that $$F\in \mathcal{P}(A\times B).$$ Now, let $$\mathcal{P}(A\times B)$$ be the set of all functions from A into B. Since $$\mathcal{P}(A\times B)\subseteq \mathcal{PP}(A\times B),$$ it follows that $$\mathcal{PP}(A\times B)$$ is also a set of all functions from A into B. Therefore $$\mathcal{P}(A\times B)=\mathcal{PP}(A\times B).$$ Attempt No. 2 is to approach it by the concept of Russel Paradox. Then I must build a set of all functions that are not in itself, but, honestly, I have not a clue of what constitute a function that is not in itself.","I want to prove ""There is no set to which every function belongs."" Can I approach it as follows? Attempt No. 1: Let $$F: A\rightarrow B$$ Since $$F\subset A\times B,$$ it follows that $$F\in \mathcal{P}(A\times B).$$ Now, let $$\mathcal{P}(A\times B)$$ be the set of all functions from A into B. Since $$\mathcal{P}(A\times B)\subseteq \mathcal{PP}(A\times B),$$ it follows that $$\mathcal{PP}(A\times B)$$ is also a set of all functions from A into B. Therefore $$\mathcal{P}(A\times B)=\mathcal{PP}(A\times B).$$ Attempt No. 2 is to approach it by the concept of Russel Paradox. Then I must build a set of all functions that are not in itself, but, honestly, I have not a clue of what constitute a function that is not in itself.",,['elementary-set-theory']
42,Can a countable set contain uncountably many infinite subsets such that the symmetric difference of any two such distinct subsets is finite?,Can a countable set contain uncountably many infinite subsets such that the symmetric difference of any two such distinct subsets is finite?,,"There is a similar topic about finite intersections and the constructs for that case are pretty clear (for example, limits of real numbers approached by monotonically increasing sequences of rational numbers). But, is that the case for finite symmetric differences? It not obvious at all for me... What the construct can be if it is possible (is it possible to find the bijection between almost disjoint family and a family of sets with finite symmetric differences)? What's the counter-example if it's not?","There is a similar topic about finite intersections and the constructs for that case are pretty clear (for example, limits of real numbers approached by monotonically increasing sequences of rational numbers). But, is that the case for finite symmetric differences? It not obvious at all for me... What the construct can be if it is possible (is it possible to find the bijection between almost disjoint family and a family of sets with finite symmetric differences)? What's the counter-example if it's not?",,['elementary-set-theory']
43,Prove the existence of some weird family of sets,Prove the existence of some weird family of sets,,"Prove the existence of uncountable family $\{X_i \subseteq \mathbb{N}\}_{i \in \mathbb{R}}$ such that intersection of any $k$ sets from this family is infinite and intersection of any $k+1$ sets is finite. $k \ge 2$, $\mathbb{N}$ means natural numbers, $\mathbb{R}$ means real numbers.","Prove the existence of uncountable family $\{X_i \subseteq \mathbb{N}\}_{i \in \mathbb{R}}$ such that intersection of any $k$ sets from this family is infinite and intersection of any $k+1$ sets is finite. $k \ge 2$, $\mathbb{N}$ means natural numbers, $\mathbb{R}$ means real numbers.",,"['elementary-set-theory', 'infinitary-combinatorics']"
44,Is the Cartesian product of sets associative? [duplicate],Is the Cartesian product of sets associative? [duplicate],,"This question already has an answer here : Associativity of Cartesian Product (1 answer) Closed 8 years ago . Is it associative? In general sense, if we compare $A \times (B \times C)$ and $(A \times B) \times C$, then $(a,(b,c))$ does not equal $((a,b),c)$, but both of those pairs may be interpreted as one triplet $(a,b,c)$. Is it correct to do that and can we use associativity of Cartesian product in set theory problems?","This question already has an answer here : Associativity of Cartesian Product (1 answer) Closed 8 years ago . Is it associative? In general sense, if we compare $A \times (B \times C)$ and $(A \times B) \times C$, then $(a,(b,c))$ does not equal $((a,b),c)$, but both of those pairs may be interpreted as one triplet $(a,b,c)$. Is it correct to do that and can we use associativity of Cartesian product in set theory problems?",,['elementary-set-theory']
45,Sequences of sets property,Sequences of sets property,,"I'm having trouble to prove the following question: Supose $\{A_n\}_{n\in\mathbb{N}}$ is a family of sets such that $A_1\subset A_2\subset A_3\subset\ldots$ (it's possible to have $A_n=A_{n+1}$). I need to prove that $$\lim_{n\to\infty}A_n = A_1\cup\bigcup_{n=2}^\infty(A_{n}\backslash A_{n-1}).$$ I'm not sure if this is useful, but I proved that $A_{n}\backslash A_{n-1}$ and $A_{n'}\backslash A_{n'-1}$ are disjoint if $n\neq n'$. Thank you.","I'm having trouble to prove the following question: Supose $\{A_n\}_{n\in\mathbb{N}}$ is a family of sets such that $A_1\subset A_2\subset A_3\subset\ldots$ (it's possible to have $A_n=A_{n+1}$). I need to prove that $$\lim_{n\to\infty}A_n = A_1\cup\bigcup_{n=2}^\infty(A_{n}\backslash A_{n-1}).$$ I'm not sure if this is useful, but I proved that $A_{n}\backslash A_{n-1}$ and $A_{n'}\backslash A_{n'-1}$ are disjoint if $n\neq n'$. Thank you.",,['elementary-set-theory']
46,Are there any nontrivial doubly-well-ordered sets?,Are there any nontrivial doubly-well-ordered sets?,,A set $A$ is well-ordered (by an ordering $R$) if there is an $R$-minimal element in every nonempty subset of $A$. Call $A$ doubly well-ordered (by $R$) if $R$ well-orders $A$ and $R^c$ (converse) well-orders $A$. Obviously if $A$ is finite than $A$ is doubly well-ordered by any strict order $R$. Are there any infinite sets with this property?,A set $A$ is well-ordered (by an ordering $R$) if there is an $R$-minimal element in every nonempty subset of $A$. Call $A$ doubly well-ordered (by $R$) if $R$ well-orders $A$ and $R^c$ (converse) well-orders $A$. Obviously if $A$ is finite than $A$ is doubly well-ordered by any strict order $R$. Are there any infinite sets with this property?,,"['elementary-set-theory', 'order-theory', 'ordinals']"
47,Factorial of Infinite Cardinal,Factorial of Infinite Cardinal,,I have been thinking about the following problem: Let $A$ be a set of cardinality $k$ and denote $\sum_A$ the set of all bijection from $A$ to $A$ . Also denote $k! = \mathrm{card}\left(\sum_A \right)$ . Prove that $k!=2^k$ . My proof consists of finding a bijection $F:\sum_A\to P(A)$ which associates each bijection from the left to the set of its fixed points. Then the result would follow. ( $P(A)$ =the power set of $A$ ). Since this proof seems quite easy I am afraid it is wrong. Can someone enlighten me? Thank you very much!,I have been thinking about the following problem: Let be a set of cardinality and denote the set of all bijection from to . Also denote . Prove that . My proof consists of finding a bijection which associates each bijection from the left to the set of its fixed points. Then the result would follow. ( =the power set of ). Since this proof seems quite easy I am afraid it is wrong. Can someone enlighten me? Thank you very much!,A k \sum_A A A k! = \mathrm{card}\left(\sum_A \right) k!=2^k F:\sum_A\to P(A) P(A) A,"['elementary-set-theory', 'cardinals']"
48,a set theoretical completion?,a set theoretical completion?,,"Is there such a thing as starting with a weak kind of set theory and making an argument to show that it should be expanded into a stronger set theory such as ZFC? Something similar to going from the rationals to the reals? With number systems, we have evidence which forces us into a stronger system (sqrt of 2). Is there such evidence with set theory? I mentioned the real numbers because in that situation there is obviously something missing. Is there obviously something missing from ""weak"" set theories? My interest is: to what extent can we justify the axioms of infinity and choice? Is there a higher level principle (of the ""there is something missing"" sort) which implies infinity and choice should be part of our system?","Is there such a thing as starting with a weak kind of set theory and making an argument to show that it should be expanded into a stronger set theory such as ZFC? Something similar to going from the rationals to the reals? With number systems, we have evidence which forces us into a stronger system (sqrt of 2). Is there such evidence with set theory? I mentioned the real numbers because in that situation there is obviously something missing. Is there obviously something missing from ""weak"" set theories? My interest is: to what extent can we justify the axioms of infinity and choice? Is there a higher level principle (of the ""there is something missing"" sort) which implies infinity and choice should be part of our system?",,"['elementary-set-theory', 'foundations']"
49,Prisoners Problem,Prisoners Problem,,"We have an infinite number of prisoners enumerated $\{1, 2, \dots\}$, and on each prisoner there is a hat of either blue or red color. The $n$th prisoner sees the hats of prisoners $\{n+1, n+2, \dots\}$. A warden asks each prisoner in succession, starting with prisoner $n=1$, ""What is the color of your hat?"" If any prisoner fails, then the warden executes that prisoner. Prisoners can not communicate. What strategy should the prisoners use (they discussed it before the moment that hats are put on them) to end up with a finite number of executions?","We have an infinite number of prisoners enumerated $\{1, 2, \dots\}$, and on each prisoner there is a hat of either blue or red color. The $n$th prisoner sees the hats of prisoners $\{n+1, n+2, \dots\}$. A warden asks each prisoner in succession, starting with prisoner $n=1$, ""What is the color of your hat?"" If any prisoner fails, then the warden executes that prisoner. Prisoners can not communicate. What strategy should the prisoners use (they discussed it before the moment that hats are put on them) to end up with a finite number of executions?",,"['elementary-set-theory', 'recreational-mathematics', 'puzzle']"
50,Is there a standard naming convention for set variables?,Is there a standard naming convention for set variables?,,"Is there a standard naming convention for variables that resemble sets? Because I want to name my variables so that reading becomes as easy and intuitive as possible. Details Currently, I'm overlining letters: I have $\mathit{S} \in M$ and $\mathbb{T} \in N$ ($M$ and $N$ are completely different sets, having nothing to do with each other) throughout my thesis, so I find it intuitive (and think I have seen it elsewhere) to use $\overline{\mathit{S}} \in 2^M, \overline{\mathbb{T}} \in 2^N$ and then $\mathit{S} \in \overline{\mathit{S}}$. That way, I have a strong connection between $\mathit{S}$ and $\overline{\mathit{S}}$ and can use this notation for all kind of symbols (e.g. $\mathit{S}$ as well as $\mathbb{T}$). I like this since it is consistent. But if I'm using both $\mathit{S}$ and $\overline{\mathit{S}}$ in one definition/lemma/..., I find it unintuitive because I tend to think that $\overline{\mathit{S}}$ is the value of $\mathit{S}$ under some function. So: Is my use of $\overline$ standard notation? Do you know of another standard? or more intuitive notation? Update Since $\overline$ has so many meanings already, what do you think about the following? $\ddot{\mathit{S}}$, or $\overbrace{\mathit{S}}$ (which looks less strange via pdflatex), or $_{2}\!\mathit{S}$","Is there a standard naming convention for variables that resemble sets? Because I want to name my variables so that reading becomes as easy and intuitive as possible. Details Currently, I'm overlining letters: I have $\mathit{S} \in M$ and $\mathbb{T} \in N$ ($M$ and $N$ are completely different sets, having nothing to do with each other) throughout my thesis, so I find it intuitive (and think I have seen it elsewhere) to use $\overline{\mathit{S}} \in 2^M, \overline{\mathbb{T}} \in 2^N$ and then $\mathit{S} \in \overline{\mathit{S}}$. That way, I have a strong connection between $\mathit{S}$ and $\overline{\mathit{S}}$ and can use this notation for all kind of symbols (e.g. $\mathit{S}$ as well as $\mathbb{T}$). I like this since it is consistent. But if I'm using both $\mathit{S}$ and $\overline{\mathit{S}}$ in one definition/lemma/..., I find it unintuitive because I tend to think that $\overline{\mathit{S}}$ is the value of $\mathit{S}$ under some function. So: Is my use of $\overline$ standard notation? Do you know of another standard? or more intuitive notation? Update Since $\overline$ has so many meanings already, what do you think about the following? $\ddot{\mathit{S}}$, or $\overbrace{\mathit{S}}$ (which looks less strange via pdflatex), or $_{2}\!\mathit{S}$",,"['elementary-set-theory', 'notation']"
51,Proving Dedekind finite implies finite assuming countable choice,Proving Dedekind finite implies finite assuming countable choice,,"I'd like to show that if a set $X$ is Dedekind finite then is is finite if we assume $(AC)_{\aleph_0}$. As set $X$ is called Dedekind finite if the following equivalent conditions are satisfied: (a) there is no injection $\omega \hookrightarrow X$ (b) every injection $X \to X$ is also a surjection. Countable choice $(AC)_{\aleph_0}$ says that every contable family of non-empty, pairwise disjoint sets has a choice function. There is the following theorem: from which I can prove what I want as follows: Pick an $x_0 \in X$. Define $G(F(0), \dots, F(n-1)) = \{x_0\}$ if $x_0 \notin \bigcup F(k)$ and $G(F(0), \dots , F(n-1)) = X \setminus \bigcup F(k)$ otherwise. Also, $G(\varnothing) = \{x_0\}$. Let $F: \omega \to X$ be as in the theorem. Then $F$ is injective by construction. The problem with that is that I suspect that the proof of theorem 24 needs countable choice. So what I am after is the following: consider the generalisation of theorem 24: (note the typo in $(R^\ast)$, it should be $F(z) \in G^\ast (F \mid I(z), z)$), and its proof (assuming AC): I want to modify this proof to prove the countable version of the theorem. But I can't seem to manage. I need a countable set $\{G^\ast \mid \{\langle f,z \rangle \} : \langle f,z \rangle \in dom(G^\ast) \}$. Ideas I had were along the lines of picking $f_0(x) = x_0$ the constant function and then to consider $\{G^\ast \mid \{\langle f_0,n \rangle \} : \langle f_0,n \rangle \in dom(G^\ast) \}$ but what then? Thanks for your help.","I'd like to show that if a set $X$ is Dedekind finite then is is finite if we assume $(AC)_{\aleph_0}$. As set $X$ is called Dedekind finite if the following equivalent conditions are satisfied: (a) there is no injection $\omega \hookrightarrow X$ (b) every injection $X \to X$ is also a surjection. Countable choice $(AC)_{\aleph_0}$ says that every contable family of non-empty, pairwise disjoint sets has a choice function. There is the following theorem: from which I can prove what I want as follows: Pick an $x_0 \in X$. Define $G(F(0), \dots, F(n-1)) = \{x_0\}$ if $x_0 \notin \bigcup F(k)$ and $G(F(0), \dots , F(n-1)) = X \setminus \bigcup F(k)$ otherwise. Also, $G(\varnothing) = \{x_0\}$. Let $F: \omega \to X$ be as in the theorem. Then $F$ is injective by construction. The problem with that is that I suspect that the proof of theorem 24 needs countable choice. So what I am after is the following: consider the generalisation of theorem 24: (note the typo in $(R^\ast)$, it should be $F(z) \in G^\ast (F \mid I(z), z)$), and its proof (assuming AC): I want to modify this proof to prove the countable version of the theorem. But I can't seem to manage. I need a countable set $\{G^\ast \mid \{\langle f,z \rangle \} : \langle f,z \rangle \in dom(G^\ast) \}$. Ideas I had were along the lines of picking $f_0(x) = x_0$ the constant function and then to consider $\{G^\ast \mid \{\langle f_0,n \rangle \} : \langle f_0,n \rangle \in dom(G^\ast) \}$ but what then? Thanks for your help.",,"['elementary-set-theory', 'axiom-of-choice']"
52,What if there are multiple conditions in set-builder notation?,What if there are multiple conditions in set-builder notation?,,"I've recently started learning about sets, and most examples of set-builder notation I've encountered: are infinite $A={\text{{set of all positive numbers}}}$ need only one condition (to define all the elements of the set) $A={\text{\{}x:x>0}\text{\}}$ have $x$ (the number to represent each element in the set) on LHS and a condition (to define all $x$) on the RHS with a colon in between The first bullet, I suppose, explains the other two bullets. The simple examples of set-builder notations I saw were all infinite. That's the main point. What if a set is not infinite , but rather can be represented as a interval of values? How to show such a set in the set-builder notation? Then the set will have multiple conditions and the format of the notation will have to change. For example, $$A={\text{{all numbers greater than zero}}} \\ B={\text{{all integers between 1 and 20}}}$$ A infinite set is like a ""super"" universal set which can have subsets. Set $A$ is a universe. A universe of all numbers greater than zero i.e. all positive integers. Its subset $B$ contains the first 20 positive integers i.e. $[1, 20\text{]}$. It's a small piece of a gigantic universe: a closed interval with endpoints. How will you show a set of... all integers greater than 0 but less than 6 all positive even integers less than 11 all perfect squares less than 101 in set-builder notation? EDIT: @5xum There were two questions. You missed the broad one. And it will be really helpful if you would have had explained how this format works. Otherwise, your answer seems like a bunch of back-of-book school textbook maths solutions. General guidelines help much more than complete solutions to specific problems.","I've recently started learning about sets, and most examples of set-builder notation I've encountered: are infinite $A={\text{{set of all positive numbers}}}$ need only one condition (to define all the elements of the set) $A={\text{\{}x:x>0}\text{\}}$ have $x$ (the number to represent each element in the set) on LHS and a condition (to define all $x$) on the RHS with a colon in between The first bullet, I suppose, explains the other two bullets. The simple examples of set-builder notations I saw were all infinite. That's the main point. What if a set is not infinite , but rather can be represented as a interval of values? How to show such a set in the set-builder notation? Then the set will have multiple conditions and the format of the notation will have to change. For example, $$A={\text{{all numbers greater than zero}}} \\ B={\text{{all integers between 1 and 20}}}$$ A infinite set is like a ""super"" universal set which can have subsets. Set $A$ is a universe. A universe of all numbers greater than zero i.e. all positive integers. Its subset $B$ contains the first 20 positive integers i.e. $[1, 20\text{]}$. It's a small piece of a gigantic universe: a closed interval with endpoints. How will you show a set of... all integers greater than 0 but less than 6 all positive even integers less than 11 all perfect squares less than 101 in set-builder notation? EDIT: @5xum There were two questions. You missed the broad one. And it will be really helpful if you would have had explained how this format works. Otherwise, your answer seems like a bunch of back-of-book school textbook maths solutions. General guidelines help much more than complete solutions to specific problems.",,['elementary-set-theory']
53,"Prob 8, Sec 7 in Munkres' TOPOLOGY 2nd ed: How do we show these sets have the same cardinality?","Prob 8, Sec 7 in Munkres' TOPOLOGY 2nd ed: How do we show these sets have the same cardinality?",,"Here's Prob. 8. Sec. 7 in Topology by James R. Munkres, 2nd edition: Let $X$ denote the two element set $\{0,1\}$; let $\mathscr{B}$ be the set of countable subsets of $X^{\omega}$. Show that $X^{\omega}$ and $\mathscr{B}$ have the smae cardinality. Here $X^{\omega}$ denotes the set of all infinite binary sequences (i.e., the set of all the functions each with domain the set $\mathbb{N}$ of natural numbers and range a (non-empty) subset of $\{0,1\}$). My effort: Using the Schroeder Bernstein theorem, our aim is to show the existence of injective maps $f \colon X^{\omega} \to \mathscr{B}$ and $g \colon \mathscr{B} \to X^{\omega}$. We can define $f$ as follows:  $$f(s) \colon= \{s\} \ \mbox{ for all } \ s \in X^{\omega}.$$ How do we define our desired map $g$?","Here's Prob. 8. Sec. 7 in Topology by James R. Munkres, 2nd edition: Let $X$ denote the two element set $\{0,1\}$; let $\mathscr{B}$ be the set of countable subsets of $X^{\omega}$. Show that $X^{\omega}$ and $\mathscr{B}$ have the smae cardinality. Here $X^{\omega}$ denotes the set of all infinite binary sequences (i.e., the set of all the functions each with domain the set $\mathbb{N}$ of natural numbers and range a (non-empty) subset of $\{0,1\}$). My effort: Using the Schroeder Bernstein theorem, our aim is to show the existence of injective maps $f \colon X^{\omega} \to \mathscr{B}$ and $g \colon \mathscr{B} \to X^{\omega}$. We can define $f$ as follows:  $$f(s) \colon= \{s\} \ \mbox{ for all } \ s \in X^{\omega}.$$ How do we define our desired map $g$?",,"['elementary-set-theory', 'cardinals']"
54,Does there exist a non-empty set that is a subset of its power set?,Does there exist a non-empty set that is a subset of its power set?,,"While working through Velleman, I proved that if $A \subseteq P(A)$, then $P(A) \subseteq P(P(A))$. One example where this may be the case is when $A = \emptyset$. Another may be when $\emptyset \in A$. I cannot think of any other example though. Supposing that $x$ and $y$ are two arbitrary elements of $A$, then $P(A)$ will always enclose those elements in a new set, thus $x,y \notin P(A) $ Thus my question is: Is there an example of a set, $A$, where $A \subseteq P(A)$ wand $A$ is non-empty and does not contain the empty set.","While working through Velleman, I proved that if $A \subseteq P(A)$, then $P(A) \subseteq P(P(A))$. One example where this may be the case is when $A = \emptyset$. Another may be when $\emptyset \in A$. I cannot think of any other example though. Supposing that $x$ and $y$ are two arbitrary elements of $A$, then $P(A)$ will always enclose those elements in a new set, thus $x,y \notin P(A) $ Thus my question is: Is there an example of a set, $A$, where $A \subseteq P(A)$ wand $A$ is non-empty and does not contain the empty set.",,['elementary-set-theory']
55,"Can we conclude $\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa=2^{\aleph_\alpha}$ in ZFC?",Can we conclude  in ZFC?,"\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa=2^{\aleph_\alpha}","In complex analysis, there is a function called Euler's Gamma function . Whenever given a positive integer $n+1$, it will return $n!=\prod_{i=1}^{i < n+1}i$. I'm not sure if there is similar function for infinite cardinals such that $$\Gamma(\aleph_\alpha)=\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa$$, but at least we can evaluate the value of that production. So my question : Is $\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa=2^{\aleph_\alpha}$?","In complex analysis, there is a function called Euler's Gamma function . Whenever given a positive integer $n+1$, it will return $n!=\prod_{i=1}^{i < n+1}i$. I'm not sure if there is similar function for infinite cardinals such that $$\Gamma(\aleph_\alpha)=\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa$$, but at least we can evaluate the value of that production. So my question : Is $\prod_{\kappa \in Crd, \kappa=1}^{\kappa<\aleph_\alpha}\kappa=2^{\aleph_\alpha}$?",,"['elementary-set-theory', 'cardinals']"
56,Indexed Family of Sets,Indexed Family of Sets,,"Most books write a family of sets $A_i$ with index set $I$ as $\{ A_i \}_{i \in I}$. However, I've read other books that have criticized this notation; they insist that one should write $(A_i )_{i \in I}$ for the family of sets $A_i$ indexed by $I$. Is there a difference between $\{ A_i \}_{i \in I}$ and $(A_i )_{i \in I}$? If so, could you please give a precise definition of each?","Most books write a family of sets $A_i$ with index set $I$ as $\{ A_i \}_{i \in I}$. However, I've read other books that have criticized this notation; they insist that one should write $(A_i )_{i \in I}$ for the family of sets $A_i$ indexed by $I$. Is there a difference between $\{ A_i \}_{i \in I}$ and $(A_i )_{i \in I}$? If so, could you please give a precise definition of each?",,"['elementary-set-theory', 'notation']"
57,"In a Venn diagram, where are other number sets located?","In a Venn diagram, where are other number sets located?",,"I remember of this image I've learned at school: I've heard about other number (which I'm not really sure if they belong to a new set) such as quaternions, p-adic numbers. Then I got three questions: Are these numbers on a new set? If yes, where are these sets located in the Venn diagram? Is there a master Venn diagram where I can visualize all sets known until today? Note: I wasn't sure on how to tag it.","I remember of this image I've learned at school: I've heard about other number (which I'm not really sure if they belong to a new set) such as quaternions, p-adic numbers. Then I got three questions: Are these numbers on a new set? If yes, where are these sets located in the Venn diagram? Is there a master Venn diagram where I can visualize all sets known until today? Note: I wasn't sure on how to tag it.",,"['elementary-set-theory', 'number-systems']"
58,The set of all finite sequences of members of a countable set is also countable,The set of all finite sequences of members of a countable set is also countable,,"While I was reading Enderton's ""A mathematical introduction to Logic"", I came across the proof of the following sentence: ""The set of all finite sequences of members of the countable set A is also countable"". Proof: The set S of all such finite sequences can be characterized by the equation  $$S=\bigcup_{n \in N} A^{n+1}$$ Since A is countable, we have a function f mapping A one-to-one into N. The basic idea is to map S one-to-one into N by assigning to $(a_0,a_1,...,a_m)$ the number $2^{f(a_0)+1}3^{f(a_1)+1}\cdot ... \cdot p_m^{f(a_m)+1}$, where $p_m$ is the $(m+1)$st prime. This suffers from the defect that this assignment might not be well-defined. For conceivably there could be $(a_0,a_1,...,a_m)=(b_0,b_1,...,b_n)$, with $a_i$ and $b_j$ in A but with $m\neq n$. But this is not serious; just assign to each member of S the smallest number obtainable in the above fashion. This gives us a well-defined map; it is easy to see that it is one-to-one. Note: P is a finite sequence of members of A iff for some positive integer $n$, we have $P=(x_1,...,x_n)$, where each $x_i \in A$. First of all, I cannot understand why the former assignment might not be well-defined and the latter assignment is well-defined. Secondly, I cannot understand what Enderton means by ""just assign to each member of S the smallest number obtainable in the above fashion"". By the way, is $(a,b,c,d) = ((a,b),(c,d))$ true? Also, in which cases can I omit/add parentheses in a tuple so as to have an equal tuple?","While I was reading Enderton's ""A mathematical introduction to Logic"", I came across the proof of the following sentence: ""The set of all finite sequences of members of the countable set A is also countable"". Proof: The set S of all such finite sequences can be characterized by the equation  $$S=\bigcup_{n \in N} A^{n+1}$$ Since A is countable, we have a function f mapping A one-to-one into N. The basic idea is to map S one-to-one into N by assigning to $(a_0,a_1,...,a_m)$ the number $2^{f(a_0)+1}3^{f(a_1)+1}\cdot ... \cdot p_m^{f(a_m)+1}$, where $p_m$ is the $(m+1)$st prime. This suffers from the defect that this assignment might not be well-defined. For conceivably there could be $(a_0,a_1,...,a_m)=(b_0,b_1,...,b_n)$, with $a_i$ and $b_j$ in A but with $m\neq n$. But this is not serious; just assign to each member of S the smallest number obtainable in the above fashion. This gives us a well-defined map; it is easy to see that it is one-to-one. Note: P is a finite sequence of members of A iff for some positive integer $n$, we have $P=(x_1,...,x_n)$, where each $x_i \in A$. First of all, I cannot understand why the former assignment might not be well-defined and the latter assignment is well-defined. Secondly, I cannot understand what Enderton means by ""just assign to each member of S the smallest number obtainable in the above fashion"". By the way, is $(a,b,c,d) = ((a,b),(c,d))$ true? Also, in which cases can I omit/add parentheses in a tuple so as to have an equal tuple?",,[]
59,Why is the axiom of countable choice constructively valid?,Why is the axiom of countable choice constructively valid?,,"I am reading Andrej Bauer's Five stages of accepting constructive mathematics . Theorem 1.3 proves that the axiom of choice implies excluded middle. Shortly afterwards Bauer implies that the axiom of countable choice is constructively valid. However I can't see why the same proof doesn't show that countable choice also implies excluded middle. The proof of Theorem 1.3 goes as follows: For an arbitrary proposition $P$ define $A = \{ x \in \{0,1\} | P \vee (x=0) \}$ and $B = \{ y \in \{0,1\} | P \vee (y=1) \}.$ Since each of $A$ and $B$ is inhabited (by 0 and 1 respectively), by choice there is a function $f \colon \{ A, B\} \rightarrow A \cup B$ such that $f(A) \in A$ and $f(B) \in B$ . Since $A, B \subseteq \{0,1\}$ , we have exhaustive cases: $f(A) = 1$ . Then $1 = f(A) \in A$ , so $P \vee (1=0) $ , which is equivalent to $P$ . $f(B) = 0$ . Then $0 = f(B) \in B$ , so $P \vee (0=1) $ , which is equivalent to $P$ . $f(A) = 0$ and $f(B) = 1$ . Then we have $\neg P$ , for if $P$ were true, then $A = B= \{0,1\}$ so $0 = f(A) = f(B) = 1$ , which is absurd. In each case we have decided either $P$ or $\neg P$ , so choice implies excluded middle. Why doesn't the same argument go through with countable choice (``every countable family of inhabited sets has a choice function'')? The set of sets we index over here, $\{A, B\}$ , is finite . What's to stop us defining $A_0$ and $A_1$ to be $A$ and $B$ above and then setting, e.g., $A_2 = \{2\}$ , $A_3 = \{3\} \ \dots $ and using the choice function given to us by countable choice to run the same argument again looking at the values $f(A_0)$ and $f(A_1)$ ?","I am reading Andrej Bauer's Five stages of accepting constructive mathematics . Theorem 1.3 proves that the axiom of choice implies excluded middle. Shortly afterwards Bauer implies that the axiom of countable choice is constructively valid. However I can't see why the same proof doesn't show that countable choice also implies excluded middle. The proof of Theorem 1.3 goes as follows: For an arbitrary proposition define and Since each of and is inhabited (by 0 and 1 respectively), by choice there is a function such that and . Since , we have exhaustive cases: . Then , so , which is equivalent to . . Then , so , which is equivalent to . and . Then we have , for if were true, then so , which is absurd. In each case we have decided either or , so choice implies excluded middle. Why doesn't the same argument go through with countable choice (``every countable family of inhabited sets has a choice function'')? The set of sets we index over here, , is finite . What's to stop us defining and to be and above and then setting, e.g., , and using the choice function given to us by countable choice to run the same argument again looking at the values and ?","P A = \{ x \in \{0,1\} | P \vee (x=0) \} B = \{ y \in \{0,1\} | P \vee (y=1) \}. A B f \colon \{ A, B\} \rightarrow A \cup B f(A) \in A f(B) \in B A, B \subseteq \{0,1\} f(A) = 1 1 = f(A) \in A P \vee (1=0)  P f(B) = 0 0 = f(B) \in B P \vee (0=1)  P f(A) = 0 f(B) = 1 \neg P P A = B= \{0,1\} 0 = f(A) = f(B) = 1 P \neg P \{A, B\} A_0 A_1 A B A_2 = \{2\} A_3 = \{3\} \ \dots  f(A_0) f(A_1)","['elementary-set-theory', 'logic', 'constructive-mathematics']"
60,"The ""Empty Tuple"" or ""0-Tuple"": Its Definition and Properties","The ""Empty Tuple"" or ""0-Tuple"": Its Definition and Properties",,"(I would like to link to a previous discussion on the subject: What is A Set Raised to the 0 Power? (In Relation to the Definition of a Nullary Operation) ) In axiomatic (ZFC) set theory, we define the ordered pair $(a,b)$ to equal $\{\{a\},\{a,b\}\}$. Then, we define the ordered triple in terms of the ordered pair: $(a,b,c):=((a,b),c)$. Similarly, we define the ordered quadruple as $(a,b,c,d)=((a,b,c),d)=(((a,b),c),d)$. In general, one can define the $n$- tuple using this nesting argument. To define $(x)$, Herbert Enderton's 1977 Elements of Set Theory suggests the convention $(x)=x$. This seems reasonable: note that if $S=\{a,b,c,d\}$, then $(a,b,c) \in S^3$, $(a,b) \in S^2$, you would also expect $(a) \in S$, which would be true if you defined $(a)=a \in S$. Finally, the ""Empty Tuple"" or ""$0$-Tuple"", $()$, is defined as \begin{equation} ()=\{\}=\emptyset \end{equation} This is confirmed by The Wikipedia Tuple page as the correct choice of definition for $()$. Moreover, this agrees with the conclusion we discovered in the previous discussion , in which we decided that $S^0=\{()\}=\{\emptyset\}=1$. For consistency, then, it is pleasing to know that $()=\emptyset$. My question, however, pertains to the properties of $()$. I have listed some which I believe true: $(())=(\emptyset)=\emptyset$. Thus $(())=()$. The "" dissolution property "": $((),s_1,\ldots,s_n)=(\emptyset,s_1,\ldots,s_n)=(s_1,\ldots,s_n)$ Any others? Although this doesn't have to do specifically with the empty tuple, as a follow-up to the dissolution property, it would be ideal if it were true that $((a,b),c)=(a,(b,c))$ (both suitable definitions for $(a,b,c)$), and possibly also $((a,b,c),d)=(a,(b,c,d))=((a,b),(c,d))$ (which are all suitable definitions for $(a,b,c,d)$), etc. The reason I want (2) to be true is because certain definitions like the nullary operation require that \begin{equation} S^0 \times S^n = \{()\} \times S^n = \{\emptyset\} \times S^n = S^n. \end{equation} For this to be true, however, would require that  $((),s_1,\ldots,s_n)=(\emptyset,s_1,\ldots,s_n)=(s_1,\ldots,s_n)$, i.e. property (2). However, I can't just ""want"" or ""believe"" these properties to be true; I need to prove them within ZFC set theory, using the set-theoretic definition of $n$-tuples. Any help with this? Thanks for reading my trail of thoughts, and please let me know if you see anything anywhere which is incorrect. Thanks! Edit 1: Looking at the ""Tuples as Nested Ordered Pairs"" section of the Wikipedia Tuple Page , I see they define $(a,b,c)$ not as $((a,b),c)$, but instead as $(a,(b,(c,\emptyset)))$. There are two thing strange about this to me: first why the nesting occurs on the right, and second why they choose to pair $c$ with $\emptyset$ instead of just writing it as $(a,(b,c))$. Any insight on this? I wish I could sort this all out. Thanks again! Edit 2: Chris Culter's answer points out a contradiction which may stem from the definition of $(a)=a$. Perhaps if we define $(x)=(\emptyset,x)=\{\{\emptyset\},\{\emptyset,x\}\}$ then all the desired properties, including the dissolution property, fall into place. So far we haven't been successful in letting $(\emptyset, a) = (a)$, however. But this is the property we need, i.e. we need $((),s_1,\ldots,s_n)=(s_1,\ldots,s_n)$ if we want $S^0 \times S^n = S^n$!","(I would like to link to a previous discussion on the subject: What is A Set Raised to the 0 Power? (In Relation to the Definition of a Nullary Operation) ) In axiomatic (ZFC) set theory, we define the ordered pair $(a,b)$ to equal $\{\{a\},\{a,b\}\}$. Then, we define the ordered triple in terms of the ordered pair: $(a,b,c):=((a,b),c)$. Similarly, we define the ordered quadruple as $(a,b,c,d)=((a,b,c),d)=(((a,b),c),d)$. In general, one can define the $n$- tuple using this nesting argument. To define $(x)$, Herbert Enderton's 1977 Elements of Set Theory suggests the convention $(x)=x$. This seems reasonable: note that if $S=\{a,b,c,d\}$, then $(a,b,c) \in S^3$, $(a,b) \in S^2$, you would also expect $(a) \in S$, which would be true if you defined $(a)=a \in S$. Finally, the ""Empty Tuple"" or ""$0$-Tuple"", $()$, is defined as \begin{equation} ()=\{\}=\emptyset \end{equation} This is confirmed by The Wikipedia Tuple page as the correct choice of definition for $()$. Moreover, this agrees with the conclusion we discovered in the previous discussion , in which we decided that $S^0=\{()\}=\{\emptyset\}=1$. For consistency, then, it is pleasing to know that $()=\emptyset$. My question, however, pertains to the properties of $()$. I have listed some which I believe true: $(())=(\emptyset)=\emptyset$. Thus $(())=()$. The "" dissolution property "": $((),s_1,\ldots,s_n)=(\emptyset,s_1,\ldots,s_n)=(s_1,\ldots,s_n)$ Any others? Although this doesn't have to do specifically with the empty tuple, as a follow-up to the dissolution property, it would be ideal if it were true that $((a,b),c)=(a,(b,c))$ (both suitable definitions for $(a,b,c)$), and possibly also $((a,b,c),d)=(a,(b,c,d))=((a,b),(c,d))$ (which are all suitable definitions for $(a,b,c,d)$), etc. The reason I want (2) to be true is because certain definitions like the nullary operation require that \begin{equation} S^0 \times S^n = \{()\} \times S^n = \{\emptyset\} \times S^n = S^n. \end{equation} For this to be true, however, would require that  $((),s_1,\ldots,s_n)=(\emptyset,s_1,\ldots,s_n)=(s_1,\ldots,s_n)$, i.e. property (2). However, I can't just ""want"" or ""believe"" these properties to be true; I need to prove them within ZFC set theory, using the set-theoretic definition of $n$-tuples. Any help with this? Thanks for reading my trail of thoughts, and please let me know if you see anything anywhere which is incorrect. Thanks! Edit 1: Looking at the ""Tuples as Nested Ordered Pairs"" section of the Wikipedia Tuple Page , I see they define $(a,b,c)$ not as $((a,b),c)$, but instead as $(a,(b,(c,\emptyset)))$. There are two thing strange about this to me: first why the nesting occurs on the right, and second why they choose to pair $c$ with $\emptyset$ instead of just writing it as $(a,(b,c))$. Any insight on this? I wish I could sort this all out. Thanks again! Edit 2: Chris Culter's answer points out a contradiction which may stem from the definition of $(a)=a$. Perhaps if we define $(x)=(\emptyset,x)=\{\{\emptyset\},\{\emptyset,x\}\}$ then all the desired properties, including the dissolution property, fall into place. So far we haven't been successful in letting $(\emptyset, a) = (a)$, however. But this is the property we need, i.e. we need $((),s_1,\ldots,s_n)=(s_1,\ldots,s_n)$ if we want $S^0 \times S^n = S^n$!",,"['elementary-set-theory', 'definition', 'relations', 'motivation']"
61,equivalence relation composition problem,equivalence relation composition problem,,"Let $R_1$, $R_2$ be two equivalence relations on $X$, prove that $R_1\circ R_2$ is an equivalence relation if and only if $R_1\circ R_2= R_2\circ R_1$ First I´m trying to prove that $R_1\circ R_2= R_2\circ R_1$ $\Rightarrow R_1\circ R_2$ is an equivalence relation; I have already shown that $R_1\circ R_2$ is reflexive and symmetric; to prove that is transitive: $(x,y)\in R_1\circ R_2$ and $(y,z)\in R_1\circ R_2$ $\Rightarrow (x,z)\in R_1\circ R_2$ but I don´t how to proceed from here, I would appreciate your help","Let $R_1$, $R_2$ be two equivalence relations on $X$, prove that $R_1\circ R_2$ is an equivalence relation if and only if $R_1\circ R_2= R_2\circ R_1$ First I´m trying to prove that $R_1\circ R_2= R_2\circ R_1$ $\Rightarrow R_1\circ R_2$ is an equivalence relation; I have already shown that $R_1\circ R_2$ is reflexive and symmetric; to prove that is transitive: $(x,y)\in R_1\circ R_2$ and $(y,z)\in R_1\circ R_2$ $\Rightarrow (x,z)\in R_1\circ R_2$ but I don´t how to proceed from here, I would appreciate your help",,"['elementary-set-theory', 'equivalence-relations']"
62,"Prove that [0,1] is equivalent to (0,1) and give an explicit description of a 1-1 function from [0,1] onto (0,1)","Prove that [0,1] is equivalent to (0,1) and give an explicit description of a 1-1 function from [0,1] onto (0,1)",,"The problem is stated as follows: Show that there is a one-to-one correspondence between the points of the closed interval $[0,1]$ and the points of the open interval $(0,1)$.  Give an explicit description of such a correspondence. Now, I think I can prove the first part of the problem by demonstrating the following: Define $f: (0,1) \to \mathbb{R}$ as follows. For $n \in \mathbb{N}$, $n \geq 2$, $\space{ }f(\frac{1}{n}) = \frac{1}{n-1}$  and for all other $x \in (0,1)$, $\space{}f(x) = x$ Prove that $f$ is a $1-1$ function from $(0,1)$ onto $(0,1]$ Slightly modify the above function to prove that $[0,1)$ is equivalent to $[0,1]$ Prove that $[0,1)$ is equivalent to $(0,1]$ Since the ""equivalent to"" relation is both symmetric and transitive, it should follow that $[0,1]$ is equivalent to $(0,1)$.  Hence, there does exist a one-to-one correspondence between $[0,1]$ and $(0,1)$. I have no trouble with the above.  My problem is in ""finding an explicit description of such a correspondence.""  Can I modify the above function, or will that not suffice?","The problem is stated as follows: Show that there is a one-to-one correspondence between the points of the closed interval $[0,1]$ and the points of the open interval $(0,1)$.  Give an explicit description of such a correspondence. Now, I think I can prove the first part of the problem by demonstrating the following: Define $f: (0,1) \to \mathbb{R}$ as follows. For $n \in \mathbb{N}$, $n \geq 2$, $\space{ }f(\frac{1}{n}) = \frac{1}{n-1}$  and for all other $x \in (0,1)$, $\space{}f(x) = x$ Prove that $f$ is a $1-1$ function from $(0,1)$ onto $(0,1]$ Slightly modify the above function to prove that $[0,1)$ is equivalent to $[0,1]$ Prove that $[0,1)$ is equivalent to $(0,1]$ Since the ""equivalent to"" relation is both symmetric and transitive, it should follow that $[0,1]$ is equivalent to $(0,1)$.  Hence, there does exist a one-to-one correspondence between $[0,1]$ and $(0,1)$. I have no trouble with the above.  My problem is in ""finding an explicit description of such a correspondence.""  Can I modify the above function, or will that not suffice?",,"['elementary-set-theory', 'contest-math']"
63,Set theory based on inclusion,Set theory based on inclusion,,"There are several axiomatizations of set theory based on inclusion rather than membership. I found only two papers, but they are both in German, and I could not read them even using a disctionary. Can anybody refer to any articles in English on this? The papers in German, which I have, are: H. Wegel. Axiomatische Mengenlehre ohne Elemente von Mengen. Math.Annalen, Bd. 131 S.435-462 (1956) A. Schoenflies. Zur Axiomatik der Mengenlehre. Math. Annalen 83, 173-200. Is there anybody aware of any translation in English of these articles? What I am mostly interested in, is whether or not in a set theory based on inclusion is possible to express the notion of ordered pair and power set.","There are several axiomatizations of set theory based on inclusion rather than membership. I found only two papers, but they are both in German, and I could not read them even using a disctionary. Can anybody refer to any articles in English on this? The papers in German, which I have, are: H. Wegel. Axiomatische Mengenlehre ohne Elemente von Mengen. Math.Annalen, Bd. 131 S.435-462 (1956) A. Schoenflies. Zur Axiomatik der Mengenlehre. Math. Annalen 83, 173-200. Is there anybody aware of any translation in English of these articles? What I am mostly interested in, is whether or not in a set theory based on inclusion is possible to express the notion of ordered pair and power set.",,"['reference-request', 'elementary-set-theory', 'logic']"
64,Proving that there is a bijection between $A$ and $B$.,Proving that there is a bijection between  and .,A B,If we set $A$ and $B$. Assuming that there exist an injective map from $A$ to $B$ and an injective map from $B$ to $A$. How to prove that there is a bijection between $A$ and $B$.,If we set $A$ and $B$. Assuming that there exist an injective map from $A$ to $B$ and an injective map from $B$ to $A$. How to prove that there is a bijection between $A$ and $B$.,,['elementary-set-theory']
65,Number of reflexive relations defined on a set A with n elements,Number of reflexive relations defined on a set A with n elements,,"Problem: If a set $A$ has $n$ elements in it, how many reflexive relations can be defined on it? My solution Is the answer summation of (n^2 - n)C(i)  for i=0 to n^2 -n $$\sum_{i=0}^{n^2-n} C(n^2-n,i) = \sum_{i=0}^{n^2-n} \binom{n^2-n}i$$ How? well if i make a matrix $n\times n$  now the diagonal elements have to be selected,out of remaining $n^2-n$ any number of elements can be selected.","Problem: If a set $A$ has $n$ elements in it, how many reflexive relations can be defined on it? My solution Is the answer summation of (n^2 - n)C(i)  for i=0 to n^2 -n $$\sum_{i=0}^{n^2-n} C(n^2-n,i) = \sum_{i=0}^{n^2-n} \binom{n^2-n}i$$ How? well if i make a matrix $n\times n$  now the diagonal elements have to be selected,out of remaining $n^2-n$ any number of elements can be selected.",,"['elementary-set-theory', 'relations']"
66,Does a countably infinite power set exist?,Does a countably infinite power set exist?,,"Let $A$ be a set. If $A$ is finite then so is $\mathcal{P}(A)$. If $A$ is not finite then it has a countably infinite subset $B$, in which case $\mathcal{P}(B)$ is uncountable and thus so is $\mathcal{P}(A)$. Can I say that given an arbitrary set its power set may be finite or uncountably infinite but never countably infinite?","Let $A$ be a set. If $A$ is finite then so is $\mathcal{P}(A)$. If $A$ is not finite then it has a countably infinite subset $B$, in which case $\mathcal{P}(B)$ is uncountable and thus so is $\mathcal{P}(A)$. Can I say that given an arbitrary set its power set may be finite or uncountably infinite but never countably infinite?",,['elementary-set-theory']
67,Distributivity of ordinal arithmetic,Distributivity of ordinal arithmetic,,"Let greek letters be ordinals. I want to prove $\alpha(\beta + \gamma) = \alpha\beta + \alpha\gamma$ by induction on $\gamma$ and I already know it holds true for $\gamma = \emptyset$ and $\gamma$ a successor ordinal. Let $\gamma$ be a limit ordinal. I found $$ \alpha(\beta + \gamma) = \alpha \cdot \sup_{\epsilon < \gamma} (\beta + \epsilon) = \sup_{\epsilon < \gamma} (\alpha(\beta + \epsilon)) = \sup_{\epsilon < \gamma} (\alpha\beta + \alpha\epsilon) = \alpha\beta + \alpha\gamma, $$ but I am suddenly doubting if the second equality is justified. Question: Is the second equality correct?","Let greek letters be ordinals. I want to prove $\alpha(\beta + \gamma) = \alpha\beta + \alpha\gamma$ by induction on $\gamma$ and I already know it holds true for $\gamma = \emptyset$ and $\gamma$ a successor ordinal. Let $\gamma$ be a limit ordinal. I found $$ \alpha(\beta + \gamma) = \alpha \cdot \sup_{\epsilon < \gamma} (\beta + \epsilon) = \sup_{\epsilon < \gamma} (\alpha(\beta + \epsilon)) = \sup_{\epsilon < \gamma} (\alpha\beta + \alpha\epsilon) = \alpha\beta + \alpha\gamma, $$ but I am suddenly doubting if the second equality is justified. Question: Is the second equality correct?",,"['elementary-set-theory', 'ordinals']"
68,"How can I represent the (haskell, python etc.) zip function in math notation?","How can I represent the (haskell, python etc.) zip function in math notation?",,"It is similar to cartesian product of sets $\{a,b\} \times \{c,d\} = \{(a,c), (a,d), (b,c), (b,d)\}$ , but applied to (ordered) tuples and without the permutations that don't match, i.e. $\langle a,b\rangle zip \langle c,d\rangle = \langle(a,c), (b,d)\rangle$ .","It is similar to cartesian product of sets , but applied to (ordered) tuples and without the permutations that don't match, i.e. .","\{a,b\} \times \{c,d\} = \{(a,c), (a,d), (b,c), (b,d)\} \langle a,b\rangle zip \langle c,d\rangle = \langle(a,c), (b,d)\rangle",['elementary-set-theory']
69,Constructive proof of a classical result,Constructive proof of a classical result,,"In a document about constructive maths, I saw the following exercise : prove that $f^{-1}: \mathcal{P}(Y) \to \mathcal{P}(X)$ is injective if and only if $f$ is surjective. There is an easy constructive proof of the ""if $f$ is surjective part"". However the ""if $f^{-1}$ is injective"" part eludes me: Let $y\in Y$. Then $\{y\}\neq \emptyset$ so $f^{-1}(\{y\}) \neq f^{-1}(\emptyset)=\emptyset$. But how can I conclude from $A\neq \emptyset$ that there is $x\in A$ constructively ? If I'm not mistaken, you can't (in the topos $\mathbf{Set}^2$, $(1, 0)$ has no global element though it's not the initial object - I don't know much about topos theory yet so I can't formalize this but heuristically this seems to indicate that there is no proof of $A\neq \emptyset \vdash \exists x, x\in A$) So this route seems doomed. Obviously I can't use the contrapositive because I would only get ""If $f^{-1}$ is injective then $f$ is not not surjective"" (and I'm not even sure there's an easy constructive proof of the contrapositive) I'm afraid I'm missing something obvious, but I'm not used to constructive reasoning at all so it would be of great help ! And also, can my argument about $\mathbf{Set}^2$ be formalized ?","In a document about constructive maths, I saw the following exercise : prove that $f^{-1}: \mathcal{P}(Y) \to \mathcal{P}(X)$ is injective if and only if $f$ is surjective. There is an easy constructive proof of the ""if $f$ is surjective part"". However the ""if $f^{-1}$ is injective"" part eludes me: Let $y\in Y$. Then $\{y\}\neq \emptyset$ so $f^{-1}(\{y\}) \neq f^{-1}(\emptyset)=\emptyset$. But how can I conclude from $A\neq \emptyset$ that there is $x\in A$ constructively ? If I'm not mistaken, you can't (in the topos $\mathbf{Set}^2$, $(1, 0)$ has no global element though it's not the initial object - I don't know much about topos theory yet so I can't formalize this but heuristically this seems to indicate that there is no proof of $A\neq \emptyset \vdash \exists x, x\in A$) So this route seems doomed. Obviously I can't use the contrapositive because I would only get ""If $f^{-1}$ is injective then $f$ is not not surjective"" (and I'm not even sure there's an easy constructive proof of the contrapositive) I'm afraid I'm missing something obvious, but I'm not used to constructive reasoning at all so it would be of great help ! And also, can my argument about $\mathbf{Set}^2$ be formalized ?",,"['elementary-set-theory', 'logic', 'topos-theory', 'constructive-mathematics']"
70,Proof by Iteration,Proof by Iteration,,"It seems that I suffer the ""too-much-logic-too-pedantic-too-confused""-disease. (You know? This very disease which lets you doubt everything and lets you yell for formalized proof. It's annoying, especially in real life.)  The last days I've been trying to understand a certain argument which uses ""iteration"" (it is out of Hatcher's ""Algebraic Topology"", the proof for proposition 2B.1. a), page 169 -- but it doesn't matter, I would say). The generalized problem Generalized, what I want to proof are the following two claims: 1) For an intervall $I$, assuming $A(I)$, one can construct an intervall $J$, such that $J \subsetneqq I$, $length(I) = 2\cdot length(J)$ and that $A(J)$ holds. 2) Then , by iteration , one has intervals $$I_0 \supsetneqq I_1 \supsetneqq \ldots$$ with $A(I_m)$ for every $m\in\mathbb{N}$. Where I stumble While 1) just goes through by instantiating an arbitrary interval $I$ and constructing a $J$, part 2) seems quite hard to conclude, but just in a detail. In fact, 1) is the inductive step with the exception, that I have nothing which is a successor of something, as $J$ was constructed within the induction. If I would have a sequence of intervals $\{I_m\}_{m\in\mathbb{N}}$, then of course, I could just run induction on it, using 1). But $I$ and $J$ are not related in this sense. Ideas The very first idea is: I'm just confused. This can happen from time to time, especially the more (mathematical) logic I consume. And I did. The second idea: The sequence of intervals I would need to construct unravels (don't know if this is the right word here...). Take $I_0 = [0,1]$ for example. There are two possibilities (in Hatcher's proof) $[0,\frac{1}{2}]$ and $[\frac{1}{2},1]$. If it was the first, the sequence continues with either $[0,\frac{1}{4}]$ or $[\frac{1}{4},\frac{1}{2}]$. As I know the borders explicitly, maybe I could modify 1) into something where $$J = [\frac{b}{2},b]\text{ or }[a,\frac{b}{2}]$$ and use this? Not sure. The third idea: putting the borders as a ""depending sequence"", $a_{n+1} = f(a_n)$, but I have no clue what that should be. Thanks for any help. PS: Of course, this is just about formalizing as I cannot see how to give a more pedantic proof. I see the argument, but saying ""then run the argument again"", which has to happen infinite times, is not a proof at all, as it would need infinite steps.","It seems that I suffer the ""too-much-logic-too-pedantic-too-confused""-disease. (You know? This very disease which lets you doubt everything and lets you yell for formalized proof. It's annoying, especially in real life.)  The last days I've been trying to understand a certain argument which uses ""iteration"" (it is out of Hatcher's ""Algebraic Topology"", the proof for proposition 2B.1. a), page 169 -- but it doesn't matter, I would say). The generalized problem Generalized, what I want to proof are the following two claims: 1) For an intervall $I$, assuming $A(I)$, one can construct an intervall $J$, such that $J \subsetneqq I$, $length(I) = 2\cdot length(J)$ and that $A(J)$ holds. 2) Then , by iteration , one has intervals $$I_0 \supsetneqq I_1 \supsetneqq \ldots$$ with $A(I_m)$ for every $m\in\mathbb{N}$. Where I stumble While 1) just goes through by instantiating an arbitrary interval $I$ and constructing a $J$, part 2) seems quite hard to conclude, but just in a detail. In fact, 1) is the inductive step with the exception, that I have nothing which is a successor of something, as $J$ was constructed within the induction. If I would have a sequence of intervals $\{I_m\}_{m\in\mathbb{N}}$, then of course, I could just run induction on it, using 1). But $I$ and $J$ are not related in this sense. Ideas The very first idea is: I'm just confused. This can happen from time to time, especially the more (mathematical) logic I consume. And I did. The second idea: The sequence of intervals I would need to construct unravels (don't know if this is the right word here...). Take $I_0 = [0,1]$ for example. There are two possibilities (in Hatcher's proof) $[0,\frac{1}{2}]$ and $[\frac{1}{2},1]$. If it was the first, the sequence continues with either $[0,\frac{1}{4}]$ or $[\frac{1}{4},\frac{1}{2}]$. As I know the borders explicitly, maybe I could modify 1) into something where $$J = [\frac{b}{2},b]\text{ or }[a,\frac{b}{2}]$$ and use this? Not sure. The third idea: putting the borders as a ""depending sequence"", $a_{n+1} = f(a_n)$, but I have no clue what that should be. Thanks for any help. PS: Of course, this is just about formalizing as I cannot see how to give a more pedantic proof. I see the argument, but saying ""then run the argument again"", which has to happen infinite times, is not a proof at all, as it would need infinite steps.",,"['elementary-set-theory', 'logic', 'induction', 'recursion']"
71,Search for a good analogy in the real world for the mathematical concept of set,Search for a good analogy in the real world for the mathematical concept of set,,"I looked for a good explanation of a set for a course. Therefore I want to find a good analogy of this concept in real life. First I thought of explaining the set as something like a container such as a box. But a box has an identity regardless of its content, i.e. the box stays the same if its content changes. In contrast the identity of a set depends highly on its elements. If you add an object to a set you get a new one. Second thoughts were something like a school class or a band. But also a school class remains the same if a new pupil joins the class during the year and band members can change. Do you know a good analogy of a set in real life – some kind of collection which changes (or we think of it as to be a new collection) if its elements changes? To explain the concept of sets I want to say: ""A set is something like ..."" And ... shall be something everyone knows from his everyday life.","I looked for a good explanation of a set for a course. Therefore I want to find a good analogy of this concept in real life. First I thought of explaining the set as something like a container such as a box. But a box has an identity regardless of its content, i.e. the box stays the same if its content changes. In contrast the identity of a set depends highly on its elements. If you add an object to a set you get a new one. Second thoughts were something like a school class or a band. But also a school class remains the same if a new pupil joins the class during the year and band members can change. Do you know a good analogy of a set in real life – some kind of collection which changes (or we think of it as to be a new collection) if its elements changes? To explain the concept of sets I want to say: ""A set is something like ..."" And ... shall be something everyone knows from his everyday life.",,['elementary-set-theory']
72,Help with understanding $V_\omega$,Help with understanding,V_\omega,"Let $V_\omega$ denote the set of all hereditarily finite sets. A set $S$ is called hereditarily finite if and only if its transitive closure is finite, that is, $TC(S) = \bigcup \{ S, \bigcup S, \bigcup \bigcup S, \dots \}$ is finite. Let $P(S)$ denote the power set of $S$ and let $\omega$ denote the natural numbers. I am trying to understand what $V_\omega$ looks like and to this end I thought I could work out the relationship between $V_\omega$ and $P(\omega)$: Of course, since $V_\omega$ is a model of $ZFC$ without the axiom of infinity, neither $\omega$ nor $P(\omega)$ are elements of $V_\omega$. Hence $P(\omega) \nsubseteq V_\omega$. On the other hand, $\{\{\{\varnothing\}\}\}$ is in $V_\omega$ but not in $P(\omega)$. Hence $V_\omega \nsubseteq P(\omega)$. So this is not going to give me any information about $V_\omega$. Yet, since hereditary finiteness is a stronger condition than finiteness ($\{\omega\}$ is a finite set that is not hereditarily finite) I am tempted to think that perhaps $V_\omega$ might somehow be in bijection with a subset of $P(\omega)$. Question: Is there such a bijection? If not: what's a good intuition to think about $V_\omega$? What does $V_\omega$ look like? Thanks for your help.","Let $V_\omega$ denote the set of all hereditarily finite sets. A set $S$ is called hereditarily finite if and only if its transitive closure is finite, that is, $TC(S) = \bigcup \{ S, \bigcup S, \bigcup \bigcup S, \dots \}$ is finite. Let $P(S)$ denote the power set of $S$ and let $\omega$ denote the natural numbers. I am trying to understand what $V_\omega$ looks like and to this end I thought I could work out the relationship between $V_\omega$ and $P(\omega)$: Of course, since $V_\omega$ is a model of $ZFC$ without the axiom of infinity, neither $\omega$ nor $P(\omega)$ are elements of $V_\omega$. Hence $P(\omega) \nsubseteq V_\omega$. On the other hand, $\{\{\{\varnothing\}\}\}$ is in $V_\omega$ but not in $P(\omega)$. Hence $V_\omega \nsubseteq P(\omega)$. So this is not going to give me any information about $V_\omega$. Yet, since hereditary finiteness is a stronger condition than finiteness ($\{\omega\}$ is a finite set that is not hereditarily finite) I am tempted to think that perhaps $V_\omega$ might somehow be in bijection with a subset of $P(\omega)$. Question: Is there such a bijection? If not: what's a good intuition to think about $V_\omega$? What does $V_\omega$ look like? Thanks for your help.",,['elementary-set-theory']
73,"Prove: If $A \subseteq C$ and $B \subseteq D$, then $A \cap B \subseteq C \cap D$","Prove: If  and , then",A \subseteq C B \subseteq D A \cap B \subseteq C \cap D,"Is the form and correctness of my elementwise proof of this correct? I don't have any other way of getting feedback for my proofs and I want to improve. Proof. Suppose $A, B, C, D$ are sets such that $A \subseteq C$ and $B \subseteq D$ and let $x \in A \cap B$. It has to be shown that $x \in C \cap D$. $x \in A \cap B$ means that $x \in A$ and $x\in B$. Because $A \subseteq C$, $x \in C$ and because $B \subseteq D$, $x \in D$. Thus, $x \in C \cap D$. Thus, if $A \subseteq C$ and $B \subseteq D$, then $A \cap B \subseteq C \cap D$.","Is the form and correctness of my elementwise proof of this correct? I don't have any other way of getting feedback for my proofs and I want to improve. Proof. Suppose $A, B, C, D$ are sets such that $A \subseteq C$ and $B \subseteq D$ and let $x \in A \cap B$. It has to be shown that $x \in C \cap D$. $x \in A \cap B$ means that $x \in A$ and $x\in B$. Because $A \subseteq C$, $x \in C$ and because $B \subseteq D$, $x \in D$. Thus, $x \in C \cap D$. Thus, if $A \subseteq C$ and $B \subseteq D$, then $A \cap B \subseteq C \cap D$.",,['elementary-set-theory']
74,Let $X$ and $Y$ be countable sets. Then $X\cup Y$ is countable,Let  and  be countable sets. Then  is countable,X Y X\cup Y,"Since $X$ and $Y$ are countable, we have two bijections: (1) $f: \mathbb{N} \rightarrow X$ ; (2) $g: \mathbb{N} \rightarrow Y$. So to prove that $X\cup Y$ is countable, I figure I need to define some function, h: $\mathbb{N} \rightarrow X\cup Y$ Thus, I was wondering if I could claim something similar to the following: since we have (1) & (2) it follows that we also have the bijections $\alpha : \{n\in \mathbb{N} : n = 2k + 1, k\in \mathbb{N}\} \rightarrow X$; $\beta : \{n\in \mathbb{N} : n = 2k, k\in \mathbb{N}\} \rightarrow Y$; because we have bijections from $\mathbb{N}$ to the evens and odds respectively. Then define $h := \alpha$ for odd $n$, $h := \beta$ for even $n$. Thus, since $\forall n\in \mathbb{N}$(either $n$ is even or $n$ is odd but not both) $h$ is a bijection from $\mathbb{N}$ to $X\cup Y$. Thanks for reading, and for answering if you answer. I'm just really unsure if my logic holds here, or if I'm even approaching this right because I've been stuck on this problem for a little while today. p.s sorry for asking so many questions recently, I'm trying to study on my own and apparently I get confused and stuck more easily than I thought I would without a teacher. EDIT: (1) fixed the even and odd.  (2) I do mean countably infinite. My bad, going through some notes I found online they were using the notation of ""countable"" for what you call ""countably infinite"", and ""at most countable"" for what you called ""countable"" (3) Thanks for the good answers, I do see now that this makes breaks down when they are not disjoint, but at least I'm not too far off.","Since $X$ and $Y$ are countable, we have two bijections: (1) $f: \mathbb{N} \rightarrow X$ ; (2) $g: \mathbb{N} \rightarrow Y$. So to prove that $X\cup Y$ is countable, I figure I need to define some function, h: $\mathbb{N} \rightarrow X\cup Y$ Thus, I was wondering if I could claim something similar to the following: since we have (1) & (2) it follows that we also have the bijections $\alpha : \{n\in \mathbb{N} : n = 2k + 1, k\in \mathbb{N}\} \rightarrow X$; $\beta : \{n\in \mathbb{N} : n = 2k, k\in \mathbb{N}\} \rightarrow Y$; because we have bijections from $\mathbb{N}$ to the evens and odds respectively. Then define $h := \alpha$ for odd $n$, $h := \beta$ for even $n$. Thus, since $\forall n\in \mathbb{N}$(either $n$ is even or $n$ is odd but not both) $h$ is a bijection from $\mathbb{N}$ to $X\cup Y$. Thanks for reading, and for answering if you answer. I'm just really unsure if my logic holds here, or if I'm even approaching this right because I've been stuck on this problem for a little while today. p.s sorry for asking so many questions recently, I'm trying to study on my own and apparently I get confused and stuck more easily than I thought I would without a teacher. EDIT: (1) fixed the even and odd.  (2) I do mean countably infinite. My bad, going through some notes I found online they were using the notation of ""countable"" for what you call ""countably infinite"", and ""at most countable"" for what you called ""countable"" (3) Thanks for the good answers, I do see now that this makes breaks down when they are not disjoint, but at least I'm not too far off.",,"['elementary-set-theory', 'cardinals']"
75,Proving there is no natural number which is both even and odd,Proving there is no natural number which is both even and odd,,"I've run into a small problem while working through Enderton's Elements of Set Theory. I'm doing the following problem: Call a natural number even if it has the form $2\cdot m$ for some $m$. Call it odd if it has the form $(2\cdot p)+1$ for some $p$. Show that each natural number number is either even or odd, but never both. I've shown most of this, and along the way I've derived many of the results found in Arturo Magidin's great post on addition , so any of the theorems there may be used. It is the 'never both' part with which I'm having trouble. This is some of what I have: Let $$ B=\{n\in\omega\ |\neg(\exists m(n=2\cdot m)\wedge\exists p(n=2\cdot p+1))\}, $$ the set of all natural numbers that are not both even and odd. Since $m\cdot 0=0$, $0$ is even. Also $0$ is not odd, for if $0=2\cdot p+1$, then $0=(2\cdot p)^+=\sigma(2\cdot p)$, but then $0\in\text{ran}\ \sigma$, contrary to the first Peano postulate. Hence $0\in B$. Suppose $k\in B$. Suppose $k$ is odd but not even, so $k=2\cdot p+1$ for some $p$. Earlier work of mine shows that $k^+$ is even. However, $k^+$ is not odd, for if $k^+=2\cdot m+1$ for some $m$, then since the successor function $\sigma$ is injective, we have $$ k^+=2\cdot m+1=(2\cdot m)^+\implies k=2\cdot m $$ contrary to the fact that $k$ is not even. Now suppose $k$ is even, but not odd. I have been able to show that $k^+$ is odd, but I can't figure a way to show that $k^+$ is not even. I suppose it must be simple, but I'm just not seeing it. Could someone explain this little part? Thank you.","I've run into a small problem while working through Enderton's Elements of Set Theory. I'm doing the following problem: Call a natural number even if it has the form $2\cdot m$ for some $m$. Call it odd if it has the form $(2\cdot p)+1$ for some $p$. Show that each natural number number is either even or odd, but never both. I've shown most of this, and along the way I've derived many of the results found in Arturo Magidin's great post on addition , so any of the theorems there may be used. It is the 'never both' part with which I'm having trouble. This is some of what I have: Let $$ B=\{n\in\omega\ |\neg(\exists m(n=2\cdot m)\wedge\exists p(n=2\cdot p+1))\}, $$ the set of all natural numbers that are not both even and odd. Since $m\cdot 0=0$, $0$ is even. Also $0$ is not odd, for if $0=2\cdot p+1$, then $0=(2\cdot p)^+=\sigma(2\cdot p)$, but then $0\in\text{ran}\ \sigma$, contrary to the first Peano postulate. Hence $0\in B$. Suppose $k\in B$. Suppose $k$ is odd but not even, so $k=2\cdot p+1$ for some $p$. Earlier work of mine shows that $k^+$ is even. However, $k^+$ is not odd, for if $k^+=2\cdot m+1$ for some $m$, then since the successor function $\sigma$ is injective, we have $$ k^+=2\cdot m+1=(2\cdot m)^+\implies k=2\cdot m $$ contrary to the fact that $k$ is not even. Now suppose $k$ is even, but not odd. I have been able to show that $k^+$ is odd, but I can't figure a way to show that $k^+$ is not even. I suppose it must be simple, but I'm just not seeing it. Could someone explain this little part? Thank you.",,"['elementary-set-theory', 'arithmetic', 'natural-numbers']"
76,What am I missing with Cantor's diagonal argument?,What am I missing with Cantor's diagonal argument?,,"Let's start with Hilbert's Hotel . A hotel exists with infinite rooms. The rooms are all full with infinite guests. A new guest arrives. The manager asks every person to go to their room number plus one and voila - Room 1 is open for the new guest. $\infty + 1 = \infty$ . Now let's look at Cantor's diagonal argument . Are there more natural numbers than numbers between 0 and 1? We have an infinite sheet of paper. On the left we write our naturals, 1, 2, 3, and so on. On the right we write numbers between 0 and 1 in any order. The argument says I can add a new number to the right by adding 1 to the nth decimal place of the nth number on the list. And it must be unique. Therefore the list wasn't complete and it proves that there are more of these than integers. I just don't agree with this logic. I'm wrong but I can't grasp why I am wrong and what I am missing. If $\infty + 1 = \infty$ (Hilbert) then why does $\infty + 1 = uncountable$ $\infty$ (Cantor)? If all we did in Cantor is prove that the list of decimals between 0 and 1 was incomplete, then didn't we prove that the list of integers was incomplete in Hilbert? Seems like the same argument? Can't the last guy that moved have taken a number mapping to Cantor's new found number? I can directly map a 1-1 set of all rational numbers in the set [0, 1) to integers. How? Take any integer and reverse the digits. Now add ""0."" to the start. So the integer 12345 becomes 0.54321 and the integer 100 becomes 0.001. The reason for the reversal is because 10 and 100 would map  to 0.10 and 0.100 which is the same thing if you didn't do this. Any decimal you give me I can remove the ""0."" from it, reverse it, and make it a new and unique integer. Doing this I can find Cantor's new number found by the diagonal modification. If Cantor's argument included irrational numbers from the start then the argument was never needed. The entire natural set of numbers could be represented as $\frac{\sqrt 2}{n}$ (except 1) and fit between [0,1) no problem. And that's only covering irrationals and only a small fraction of those. I understand that there are different levels of infinity, but the count of all natural numbers and the count of rationals between [0,1) seem to both be $\aleph_0$ to me.","Let's start with Hilbert's Hotel . A hotel exists with infinite rooms. The rooms are all full with infinite guests. A new guest arrives. The manager asks every person to go to their room number plus one and voila - Room 1 is open for the new guest. . Now let's look at Cantor's diagonal argument . Are there more natural numbers than numbers between 0 and 1? We have an infinite sheet of paper. On the left we write our naturals, 1, 2, 3, and so on. On the right we write numbers between 0 and 1 in any order. The argument says I can add a new number to the right by adding 1 to the nth decimal place of the nth number on the list. And it must be unique. Therefore the list wasn't complete and it proves that there are more of these than integers. I just don't agree with this logic. I'm wrong but I can't grasp why I am wrong and what I am missing. If (Hilbert) then why does (Cantor)? If all we did in Cantor is prove that the list of decimals between 0 and 1 was incomplete, then didn't we prove that the list of integers was incomplete in Hilbert? Seems like the same argument? Can't the last guy that moved have taken a number mapping to Cantor's new found number? I can directly map a 1-1 set of all rational numbers in the set [0, 1) to integers. How? Take any integer and reverse the digits. Now add ""0."" to the start. So the integer 12345 becomes 0.54321 and the integer 100 becomes 0.001. The reason for the reversal is because 10 and 100 would map  to 0.10 and 0.100 which is the same thing if you didn't do this. Any decimal you give me I can remove the ""0."" from it, reverse it, and make it a new and unique integer. Doing this I can find Cantor's new number found by the diagonal modification. If Cantor's argument included irrational numbers from the start then the argument was never needed. The entire natural set of numbers could be represented as (except 1) and fit between [0,1) no problem. And that's only covering irrationals and only a small fraction of those. I understand that there are different levels of infinity, but the count of all natural numbers and the count of rationals between [0,1) seem to both be to me.",\infty + 1 = \infty \infty + 1 = \infty \infty + 1 = uncountable \infty \frac{\sqrt 2}{n} \aleph_0,"['elementary-set-theory', 'infinity']"
77,Pushout in the category of Sets: proof,Pushout in the category of Sets: proof,,"Let $f\colon Z\to X$ and $g\colon Z\to Y$ be functions. What is a pushout of $f$ and $g$ in $\mathsf{Set}$ ? Different sources and questions on this site claim that it's the quotient of the disjoint union $X\sqcup Y$ by the equivalence relation $\sim_R$ generated by the relation $R = \{ ((0,x),(1,y)) \in (X\sqcup Y)\times (X\sqcup Y) \mid \exists z \in Z, x = f(z)$ and $y = g(z) \}$ . Define functions $i_1\colon X\to X\sqcup Y/{\sim_R}$ and $i_2\colon Y\to X\sqcup Y/{\sim_R}$ by setting $i_1$ to map each $x \in X$ to the equivalence class $[(0,x)]$ and $i_2$ to map each $y \in Y$ to the equivalence class $[(1,y)]$ . For $X\sqcup Y/{\sim_R}$ together with $i_1$ and $i_2$ to be a pushout in $\mathsf{Set}$ , we first must have $i_2\circ f = i_2\circ g$ . It's easy to check that it's so. Now, let $j_1\colon X\to Q$ and $j_2\colon Y\to Q$ be functions so that $j_1\circ f = j_2\circ g$ . We seek a function $u\colon X\sqcup Y/{\sim_R} \to Q$ . $u\circ i_1 = j_1$ and $u\circ i_2 = j_2$ . Of course, for these identities to hold, this hypothetical function $u$ must satisfy $u([(0,x)]) = j_1(x)$ and $u([(1,y)]) = j_2(y)$ for any $x \in X$ and $y \in Y$ . But I'm not sure how to prove that this data indeed defines a function. We need to prove that it is independent of the choice of $x$ and $y$ . Of course, this needs to use the fact that $j_1\circ f = j_2\circ g$ .","Let and be functions. What is a pushout of and in ? Different sources and questions on this site claim that it's the quotient of the disjoint union by the equivalence relation generated by the relation and . Define functions and by setting to map each to the equivalence class and to map each to the equivalence class . For together with and to be a pushout in , we first must have . It's easy to check that it's so. Now, let and be functions so that . We seek a function . and . Of course, for these identities to hold, this hypothetical function must satisfy and for any and . But I'm not sure how to prove that this data indeed defines a function. We need to prove that it is independent of the choice of and . Of course, this needs to use the fact that .","f\colon Z\to X g\colon Z\to Y f g \mathsf{Set} X\sqcup Y \sim_R R = \{ ((0,x),(1,y)) \in (X\sqcup Y)\times (X\sqcup Y) \mid \exists z \in Z, x = f(z) y = g(z) \} i_1\colon X\to X\sqcup Y/{\sim_R} i_2\colon Y\to X\sqcup Y/{\sim_R} i_1 x \in X [(0,x)] i_2 y \in Y [(1,y)] X\sqcup Y/{\sim_R} i_1 i_2 \mathsf{Set} i_2\circ f = i_2\circ g j_1\colon X\to Q j_2\colon Y\to Q j_1\circ f = j_2\circ g u\colon X\sqcup Y/{\sim_R} \to Q u\circ i_1 = j_1 u\circ i_2 = j_2 u u([(0,x)]) = j_1(x) u([(1,y)]) = j_2(y) x \in X y \in Y x y j_1\circ f = j_2\circ g","['elementary-set-theory', 'category-theory']"
78,"What was the original German word Cantor used for ""countable"" and/or ""uncountable""","What was the original German word Cantor used for ""countable"" and/or ""uncountable""",,"Apologies if this is slightly off-topic - it's about history of mathematics, but linguistic history specifically:  I suspect I'd get a better answer here than the language SE site due to domain knowledge. I was explaining the concept of countably vs. uncountably infinite sets to a friend, and he had a (probably-not-uncommon?) viscerally negative reaction to that terminology. So I started wondering: how closely do those English terms - ""countable"" and ""uncountable"" - hew to whatever the original German terms Cantor published? I.e., is this a problem of translation or just a normal specialized-jargon-can-be-confusing issue?","Apologies if this is slightly off-topic - it's about history of mathematics, but linguistic history specifically:  I suspect I'd get a better answer here than the language SE site due to domain knowledge. I was explaining the concept of countably vs. uncountably infinite sets to a friend, and he had a (probably-not-uncommon?) viscerally negative reaction to that terminology. So I started wondering: how closely do those English terms - ""countable"" and ""uncountable"" - hew to whatever the original German terms Cantor published? I.e., is this a problem of translation or just a normal specialized-jargon-can-be-confusing issue?",,"['elementary-set-theory', 'reference-request', 'cardinals', 'math-history']"
79,Notation for Average of a Set?,Notation for Average of a Set?,,"In particular, I have some set $S = \{s_1, s_2, s_3, ..., s_n\}$ and a subset $S^\prime$, and I want to denote the average of the elements in $S^\prime$. I would generally just use $\frac{\sum\limits_{i=1}^n s_i}{n}$, but $S^\prime$ only contains some of the elements of $S$ and so this won't work. This page suggests that the proper notation is $\left<S^\prime\right>$, but I wasn't able to find this anywhere else. Is this notation common, or is there some other accepted notation that I could use? Thanks! (This is in a computer science paper, if it makes a difference.)","In particular, I have some set $S = \{s_1, s_2, s_3, ..., s_n\}$ and a subset $S^\prime$, and I want to denote the average of the elements in $S^\prime$. I would generally just use $\frac{\sum\limits_{i=1}^n s_i}{n}$, but $S^\prime$ only contains some of the elements of $S$ and so this won't work. This page suggests that the proper notation is $\left<S^\prime\right>$, but I wasn't able to find this anywhere else. Is this notation common, or is there some other accepted notation that I could use? Thanks! (This is in a computer science paper, if it makes a difference.)",,"['elementary-set-theory', 'notation', 'average']"
80,"Proving the generalized intersection of the interval (0, 1/n) is the empty set?","Proving the generalized intersection of the interval (0, 1/n) is the empty set?",,"Prove that the generalized intersection of the interval (0,1/n) is the empty set? Aka prove that $(0,1) \cap (0, 1/2) \cap (0, 1/3) \cap (0, 1/4) ... = \emptyset$. I know that I need to prove this by contradiction, by assuming that there exists an x in the intersection and then choosing a positive integer n s.t. 1/n < x. I'm having trouble putting it all together, especially since I'm supposed to use this fact: For all x in R, there exists k in N s.t. k > x. When I flip this around, I get that 1/k < 1/x, which isn't what I want. I understand how and why the proof works, I just can't seem to format it with enough rigor.","Prove that the generalized intersection of the interval (0,1/n) is the empty set? Aka prove that $(0,1) \cap (0, 1/2) \cap (0, 1/3) \cap (0, 1/4) ... = \emptyset$. I know that I need to prove this by contradiction, by assuming that there exists an x in the intersection and then choosing a positive integer n s.t. 1/n < x. I'm having trouble putting it all together, especially since I'm supposed to use this fact: For all x in R, there exists k in N s.t. k > x. When I flip this around, I get that 1/k < 1/x, which isn't what I want. I understand how and why the proof works, I just can't seem to format it with enough rigor.",,['elementary-set-theory']
81,"If $\alpha\leq \beta,\gamma\leq \delta$ then $\alpha+\gamma\leq \beta+\delta$",If  then,"\alpha\leq \beta,\gamma\leq \delta \alpha+\gamma\leq \beta+\delta","The title is one of my homework assigments, (and the above greek letters are ordinal numbers) but this is the first one containing inequalities, and I dont really know how to do it. My guess is induction, and I think this might be a way to do it: First we prove that $\alpha\leq \beta$ imply that $\alpha+\gamma \leq \beta +\gamma$: Induction on $\gamma$. If $\gamma=0$ then the statement is trivial. Now assume that the statement holds for all $x<\gamma$. If $\gamma$ is a succesor, then there exists a $y$ such that $Sy=\gamma$, then:$$\alpha+\gamma=S(\alpha+y)\leq S(\beta+y)=\beta+\gamma$$If $\gamma$ is a limit ordinal, then:$$\alpha+\gamma=\mbox{sup}(\alpha+x: x<\gamma)\leq  \mbox{sup}(\beta+x: x<\gamma)=\beta+\gamma$$and thus we have that $\alpha+\gamma\leq \beta+\gamma$. Then my idea is to prove that if $\gamma\leq \delta$, then we have that $\beta+\gamma\leq \beta+\delta$ and then the statement would follow. My question: For this last part do we do induction with base case $\delta=\gamma$? and then do the same routine of considering cases when $\delta$ is a limit or a successor. Is there another way to tackle this problem? Thanks!","The title is one of my homework assigments, (and the above greek letters are ordinal numbers) but this is the first one containing inequalities, and I dont really know how to do it. My guess is induction, and I think this might be a way to do it: First we prove that $\alpha\leq \beta$ imply that $\alpha+\gamma \leq \beta +\gamma$: Induction on $\gamma$. If $\gamma=0$ then the statement is trivial. Now assume that the statement holds for all $x<\gamma$. If $\gamma$ is a succesor, then there exists a $y$ such that $Sy=\gamma$, then:$$\alpha+\gamma=S(\alpha+y)\leq S(\beta+y)=\beta+\gamma$$If $\gamma$ is a limit ordinal, then:$$\alpha+\gamma=\mbox{sup}(\alpha+x: x<\gamma)\leq  \mbox{sup}(\beta+x: x<\gamma)=\beta+\gamma$$and thus we have that $\alpha+\gamma\leq \beta+\gamma$. Then my idea is to prove that if $\gamma\leq \delta$, then we have that $\beta+\gamma\leq \beta+\delta$ and then the statement would follow. My question: For this last part do we do induction with base case $\delta=\gamma$? and then do the same routine of considering cases when $\delta$ is a limit or a successor. Is there another way to tackle this problem? Thanks!",,"['elementary-set-theory', 'ordinals']"
82,Do there exist sets $A\subseteq X$ and $B\subseteq Y$ such that $f(A)=B$ and $g(Y-B)=X-A$?,Do there exist sets  and  such that  and ?,A\subseteq X B\subseteq Y f(A)=B g(Y-B)=X-A,"This is a little exercise I've been fiddling with for a while now. Let $f\colon X\to Y$ and $g\colon Y\to X$ be functions. I want to show that there are subsets $A\subseteq X$ and $B\subseteq Y$ such that $f(A)=B$ and $g(Y-B)=X-A$. Of course, if $f$ is surjective, then taking $A=X$, one has $f(A)=B=Y$ and $g(Y-Y)=g(\emptyset)=\emptyset=X-X=X-A$, and you're done. So I suppose $f$ is not surjective. I tried to approach it by contradiction. It seems that for any $A\subseteq X$, there is obviously a $B\subseteq Y$ such that $f(A)=B$, so if the result is not the case, for each pair of subsets $A$ and $f(A)$, we must have $g(Y-f(A))\neq X-A$. Then for every $f(A)\subseteq Y$, there exists a $y\in Y-f(A)$ such that $g(y)\notin X-A$. This would imply $g(y)\notin X \lor g(y)\in A$, but since $g(y)\in X$, we must have $g(y)\in A$. The only thing I can glean from this is that $g$ is surjective, since for any singleton $\{x\}\subseteq X$, we could then find a $y\in Y-\{f(x)\}$ such that $g(y)=x$. But I don't quite see how to get a contradiction. What direction should I head? I attempted to apply the fact that a monotone function on power sets has a fixed point, but that only seems to apply then the function maps from a power set into itself. Thanks!","This is a little exercise I've been fiddling with for a while now. Let $f\colon X\to Y$ and $g\colon Y\to X$ be functions. I want to show that there are subsets $A\subseteq X$ and $B\subseteq Y$ such that $f(A)=B$ and $g(Y-B)=X-A$. Of course, if $f$ is surjective, then taking $A=X$, one has $f(A)=B=Y$ and $g(Y-Y)=g(\emptyset)=\emptyset=X-X=X-A$, and you're done. So I suppose $f$ is not surjective. I tried to approach it by contradiction. It seems that for any $A\subseteq X$, there is obviously a $B\subseteq Y$ such that $f(A)=B$, so if the result is not the case, for each pair of subsets $A$ and $f(A)$, we must have $g(Y-f(A))\neq X-A$. Then for every $f(A)\subseteq Y$, there exists a $y\in Y-f(A)$ such that $g(y)\notin X-A$. This would imply $g(y)\notin X \lor g(y)\in A$, but since $g(y)\in X$, we must have $g(y)\in A$. The only thing I can glean from this is that $g$ is surjective, since for any singleton $\{x\}\subseteq X$, we could then find a $y\in Y-\{f(x)\}$ such that $g(y)=x$. But I don't quite see how to get a contradiction. What direction should I head? I attempted to apply the fact that a monotone function on power sets has a fixed point, but that only seems to apply then the function maps from a power set into itself. Thanks!",,"['elementary-set-theory', 'fixed-point-theorems']"
83,A total well ordered set cannot be dense,A total well ordered set cannot be dense,,"Let $E$ be totally ordered under $<$ , and dense. I would like to prove that a well ordered set is never dense. To prove this, I tried to fid a non-empty subset $X$ of $E$ such that there is no least element. So, I take $X=\{z\in E: \forall x,y\in E\quad x<z<y\}$, it's non-empty because E is dense. If I assume that there is a least element, noted $l$. We have $$\forall w\in X\quad l<w.$$ As $l\in X$ and $<$ is dense, we can find an element between $x$ and $l$, therefore $l$ is not a least element. Is it correct?","Let $E$ be totally ordered under $<$ , and dense. I would like to prove that a well ordered set is never dense. To prove this, I tried to fid a non-empty subset $X$ of $E$ such that there is no least element. So, I take $X=\{z\in E: \forall x,y\in E\quad x<z<y\}$, it's non-empty because E is dense. If I assume that there is a least element, noted $l$. We have $$\forall w\in X\quad l<w.$$ As $l\in X$ and $<$ is dense, we can find an element between $x$ and $l$, therefore $l$ is not a least element. Is it correct?",,"['elementary-set-theory', 'proof-verification', 'order-theory']"
84,Prove that $\mathcal{P}(A)\cup \mathcal{P}(B) \subseteq \mathcal{P}(A\cup B)$.,Prove that .,\mathcal{P}(A)\cup \mathcal{P}(B) \subseteq \mathcal{P}(A\cup B),"I have a presentation this Monday. I thought it was pretty straight forward but my professor wrote ""You need to show why $X$ is in $\mathcal{P}(A\cup B)$ , not just state that it is."" I thought that I had. Here's what I have: Proof Suppose $X\in\mathcal{P}(A)\cup\mathcal{P}(B)$ . By definition of union, this means $X\in\mathcal{P}(A)$ or $X\in\mathcal{P}(B)$ . By definition of power sets $X \subseteq A$ or $X \subseteq B$ . Case 1: Suppose $X \subseteq A$ . Then $X \subseteq A\cup B$ , and this means $X\in\mathcal{P}(A\cup B)$ . Case 2: Suppose $X \subseteq B$ . Then $X \subseteq A\cup B$ , and this means $X\in\mathcal{P}(A\cup B)$ . By case 1 and 2, $X\in\mathcal{P}(A\cup B)$ . Thus $X\in\mathcal{P}(A)\cup \mathcal{P}(B)$ implies $X\in\mathcal{P}(A\cup B)$ , and therefore $\mathcal{P}(A)\cup \mathcal{P}(B)\subseteq \mathcal{P}(A\cup B). \blacksquare$ I am so bad at this. I feel so stupid.","I have a presentation this Monday. I thought it was pretty straight forward but my professor wrote ""You need to show why is in , not just state that it is."" I thought that I had. Here's what I have: Proof Suppose . By definition of union, this means or . By definition of power sets or . Case 1: Suppose . Then , and this means . Case 2: Suppose . Then , and this means . By case 1 and 2, . Thus implies , and therefore I am so bad at this. I feel so stupid.",X \mathcal{P}(A\cup B) X\in\mathcal{P}(A)\cup\mathcal{P}(B) X\in\mathcal{P}(A) X\in\mathcal{P}(B) X \subseteq A X \subseteq B X \subseteq A X \subseteq A\cup B X\in\mathcal{P}(A\cup B) X \subseteq B X \subseteq A\cup B X\in\mathcal{P}(A\cup B) X\in\mathcal{P}(A\cup B) X\in\mathcal{P}(A)\cup \mathcal{P}(B) X\in\mathcal{P}(A\cup B) \mathcal{P}(A)\cup \mathcal{P}(B)\subseteq \mathcal{P}(A\cup B). \blacksquare,"['elementary-set-theory', 'proof-writing']"
85,Existence of a certain subset of $\mathbb{R}$,Existence of a certain subset of,\mathbb{R},"To every real $x$ assign a finite set $\mathcal{A}(x)\subset \mathbb{R}$   where $x\not\in \mathcal{A}(x)$. Does there exist $\mathcal{W}\subset  \mathbb{R}$ such that: $$1.\;\;\mathcal{W}\cap \mathcal{A}(\mathcal{W})=\varnothing\qquad  2.\;\;|\mathcal{W}|=|\mathbb{R}|$$ This interesting problem was given to me by a friend, but I can't do it. Any ideas?","To every real $x$ assign a finite set $\mathcal{A}(x)\subset \mathbb{R}$   where $x\not\in \mathcal{A}(x)$. Does there exist $\mathcal{W}\subset  \mathbb{R}$ such that: $$1.\;\;\mathcal{W}\cap \mathcal{A}(\mathcal{W})=\varnothing\qquad  2.\;\;|\mathcal{W}|=|\mathbb{R}|$$ This interesting problem was given to me by a friend, but I can't do it. Any ideas?",,['elementary-set-theory']
86,Intuition behind proof and verification partially ordered sets,Intuition behind proof and verification partially ordered sets,,"Hi everyone in the book that I read I have trouble to understand the argument of the proof at the below proposition. There is a lot of point which are  left as exercises, which is great. One of these is the following claim I put all the proposition for the sake of the completeness but not the entire proof. My questions are: Is the proof of the claim correct (I use the hints which the book give us)? What is the intuition behind the claim? I mean, the entire construction of the ""good sets"" is rather artificial to me, what would be a possible motivation for them? I don't quite understand all the approach. Any suggestion, advice, whatever would be great thanks in advance. If someone consider opportune I'd put the entire proof or change the title (if there is one better). Proposition : Let $X$ be a partially ordered set with ordering relation $\le_X $, and let $x_0\in X$. Then there is a well ordered subset $Y$ of $X$ which has $x_0$ as its minimum element, and which has no strict upper bound. Proof: Suppose for the sake of contradiction that every well-ordered subset $Y$ of $X$ which has $x_0$ as its minimum element contain at least one strict upper bound. Using the axiom of choice we can thus assign a strict upper bound $s(Y)$ to each well-ordered subset $Y$ of $X$ which has $x_0$ as its minimum element. Let us define a special class of subsets $Y$ of $X$. We say that a subset $Y$ of $X$ is a good set iff is well-ordered, contain $x_0$ as its minimum element and obey the property $$x=s(\{y\in Y: y<x\})\; \text{for all }\;  x\in Y\backslash \{x_0\}$$ The collection $\Omega:=\{ Y: Y\; \text{is a good set}\;\}$ is non-empty since contains the set $\{x_0\}$. Claim 1 : Let $Y, Y' \in \Omega$, i.e., both are good sets. Then each element in $Y'\backslash Y$ is a strict upper bound for $Y$. Similarly each element in $Y\backslash Y'$ is a strict upper bound for $Y'$. Proof of the Claim 1: Note that $Y\cap Y' \not= \varnothing$ because both contains at least $x_0$. First we'd like to show that for all $x\in Y\cap Y'$ we have the following equality: $$\{y\in Y: y\le x \}=\{y\in Y': y\le x \}=\{y\in Y\cap Y': y\le x \}$$ We may use strong induction for this purpose (this is possible because everyone of the above sets is well-ordered). Suppose that the assertion hold for each $y\in Y\cap Y'$ such that $y<x$, in other words we have the equality $\{y\in Y: y< x \}=\{y\in Y': y< x \}=\{y\in Y\cap Y': y< x \}$. We shall show that also hold when $y=x$. We have $x=s(\{y\in Y: y< x \})=s(\{y\in Y': y< x \})$ because both are good sets. Then the equality of the first two sets hold. So, if $y\in Y,\; y=x$ and $y\in Y,\;y= x$ are equal for $x\in Y\cap Y'$. Thus the claim follows for the third set. (2) Now we wish to show that $Y\cap Y'$ is itself a good set. Note that automatically is a well-ordered set, since every subset of a well-ordered set is well-ordered. And also contain $x_0$ as its minimum element. So, only we have to show that obey the third property. In other words our task is to show $$x=s(\{y\in Y \cap Y': y<x\})\; \text{for all }\;  x\in (Y\cap Y')\backslash \{x_0\}$$ We may assume $(Y\cap Y')\backslash \{x_0\} \not= \varnothing$ since otherwise is a good set and there is nothing to prove. Let $x\in (Y\cap Y')\backslash \{x_0\} $, and we set $\{y\in Y \cap Y': y<x\}$. For the first part of the proof we already known $\{y\in Y \cap Y': y<x\}=\{y\in Y: y< x \}$ for all $x\in (Y\cap Y')\backslash \{x_0\} \subset Y\cap Y'$. Thus $x=s(\{y\in Y: y< x \})=s(\{y\in Y \cap Y': y<x\})$, which shows that the set is a good set. (3) For the above part of the claim we know that $s(Y\cap Y')$ exists. We shall show that if $Y'\backslash Y\not= \varnothing$, then  $s(Y\cap Y')= \text{min}(Y'\backslash Y)$. Similarly with the roles of $Y$ and $Y'$ interchanged. Suppose the set $Y'\backslash Y$ is non-empty, then contains a minimum element because is a well-ordered set. Let a call it for brevity $x_0$. Thus for all $y<x_0$ we have $\{y\in Y': y<x_0 \} \subset Y$ using the minimality of $x_0$. Also is easy to check that $y\in Y \cap Y'$ iff $y<x_0$. So $\{y\in Y': y<x_0 \}=\{y\in Y\cap Y': y<x_0 \}$. Then $x_0=s(\{y\in Y\cap Y': y<x_0 \})$ because as we have shown is a good set. In other words $x_0= \text{min} (Y'\backslash Y) =s(\{y\in Y\cap Y': y<x_0 \})$. It's trivial to show $s(\{y\in Y\cap Y': y<x_0 \}) =s(Y\cap Y') $ this follows immediately for the way in which $x_0$ was specified since $\{y\in Y\cap Y': y<x_0 \}=Y\cap Y'$, one inclusion is obvious and the other follows because if $y\in Y\cap Y' \subset Y$ thus it can't be greater than $x_0$. Note that exactly the same argument applies only with the roles interchanged of $Y, Y'$ when we assumme $Y\backslash Y'\not= \varnothing$. (4) If $Y,Y' \in \Omega$ are good sets. Then either $Y\backslash Y'$ is non-empty or $Y'\backslash Y$ is non-empty but not both at the same time. Suppose for the sake of contradiction that both cases occurs at the same time, i.e., $Y\backslash Y'\not= \varnothing$ and $Y' \backslash Y\not= \varnothing$. Let $x= \text{min} (Y\backslash Y')$ and $x'= \text{min} (Y'\backslash Y)$. We know by (3) that $x= s(Y\cap Y')$ and also  $x'=s(Y\cap Y')$, which would imply that $x=x'$ but this means that $x,x'\in Y\cap Y'$ which is a contradiction. Hence, it is not possible that both holds at the same time. Also we can show that either $Y\subset Y'$ or $Y' \subset Y$, if were not the case, i.e., $Y\not\subset Y'$ and $Y' \not\subset Y$. Then $Y'\backslash Y$ and $Y\backslash Y'$ are both non-empty which as we have shown above leads a contradiction. (5) To conclude the proof of the claim we shall show that all the elements in $Y'\backslash Y$ are strict upper bounds for $Y$. Note it is not necessary shows that the elements in $Y\backslash Y'$ a strict upper bounds for $Y'$ because exactly the same arguments apply. Let $Y,Y' \in \Omega$, so both are good sets.Then either $Y'\backslash Y$ is empty or not. If the set is empty is vacuously true that each of its element is a strict upper bound for $Y$. If were not the case, this meant $Y\subset Y'$ and $Y\cap Y'=Y$ for what shown in (4). Then $s(Y\cap Y')= s(Y)= \text{min}(Y'\backslash Y)$. So, the minimum element of $Y'\backslash Y$ is an upper bound for $Y$ and so, each element in $Y'\backslash Y$ is strictly greater than each element in $Y$ by transitivity, i.e., are strict upper bounds for $Y$. Hence the claim follows  as desired. I think there is an intimate relation of this proposition and the Zorn's lemma. Am I right?","Hi everyone in the book that I read I have trouble to understand the argument of the proof at the below proposition. There is a lot of point which are  left as exercises, which is great. One of these is the following claim I put all the proposition for the sake of the completeness but not the entire proof. My questions are: Is the proof of the claim correct (I use the hints which the book give us)? What is the intuition behind the claim? I mean, the entire construction of the ""good sets"" is rather artificial to me, what would be a possible motivation for them? I don't quite understand all the approach. Any suggestion, advice, whatever would be great thanks in advance. If someone consider opportune I'd put the entire proof or change the title (if there is one better). Proposition : Let $X$ be a partially ordered set with ordering relation $\le_X $, and let $x_0\in X$. Then there is a well ordered subset $Y$ of $X$ which has $x_0$ as its minimum element, and which has no strict upper bound. Proof: Suppose for the sake of contradiction that every well-ordered subset $Y$ of $X$ which has $x_0$ as its minimum element contain at least one strict upper bound. Using the axiom of choice we can thus assign a strict upper bound $s(Y)$ to each well-ordered subset $Y$ of $X$ which has $x_0$ as its minimum element. Let us define a special class of subsets $Y$ of $X$. We say that a subset $Y$ of $X$ is a good set iff is well-ordered, contain $x_0$ as its minimum element and obey the property $$x=s(\{y\in Y: y<x\})\; \text{for all }\;  x\in Y\backslash \{x_0\}$$ The collection $\Omega:=\{ Y: Y\; \text{is a good set}\;\}$ is non-empty since contains the set $\{x_0\}$. Claim 1 : Let $Y, Y' \in \Omega$, i.e., both are good sets. Then each element in $Y'\backslash Y$ is a strict upper bound for $Y$. Similarly each element in $Y\backslash Y'$ is a strict upper bound for $Y'$. Proof of the Claim 1: Note that $Y\cap Y' \not= \varnothing$ because both contains at least $x_0$. First we'd like to show that for all $x\in Y\cap Y'$ we have the following equality: $$\{y\in Y: y\le x \}=\{y\in Y': y\le x \}=\{y\in Y\cap Y': y\le x \}$$ We may use strong induction for this purpose (this is possible because everyone of the above sets is well-ordered). Suppose that the assertion hold for each $y\in Y\cap Y'$ such that $y<x$, in other words we have the equality $\{y\in Y: y< x \}=\{y\in Y': y< x \}=\{y\in Y\cap Y': y< x \}$. We shall show that also hold when $y=x$. We have $x=s(\{y\in Y: y< x \})=s(\{y\in Y': y< x \})$ because both are good sets. Then the equality of the first two sets hold. So, if $y\in Y,\; y=x$ and $y\in Y,\;y= x$ are equal for $x\in Y\cap Y'$. Thus the claim follows for the third set. (2) Now we wish to show that $Y\cap Y'$ is itself a good set. Note that automatically is a well-ordered set, since every subset of a well-ordered set is well-ordered. And also contain $x_0$ as its minimum element. So, only we have to show that obey the third property. In other words our task is to show $$x=s(\{y\in Y \cap Y': y<x\})\; \text{for all }\;  x\in (Y\cap Y')\backslash \{x_0\}$$ We may assume $(Y\cap Y')\backslash \{x_0\} \not= \varnothing$ since otherwise is a good set and there is nothing to prove. Let $x\in (Y\cap Y')\backslash \{x_0\} $, and we set $\{y\in Y \cap Y': y<x\}$. For the first part of the proof we already known $\{y\in Y \cap Y': y<x\}=\{y\in Y: y< x \}$ for all $x\in (Y\cap Y')\backslash \{x_0\} \subset Y\cap Y'$. Thus $x=s(\{y\in Y: y< x \})=s(\{y\in Y \cap Y': y<x\})$, which shows that the set is a good set. (3) For the above part of the claim we know that $s(Y\cap Y')$ exists. We shall show that if $Y'\backslash Y\not= \varnothing$, then  $s(Y\cap Y')= \text{min}(Y'\backslash Y)$. Similarly with the roles of $Y$ and $Y'$ interchanged. Suppose the set $Y'\backslash Y$ is non-empty, then contains a minimum element because is a well-ordered set. Let a call it for brevity $x_0$. Thus for all $y<x_0$ we have $\{y\in Y': y<x_0 \} \subset Y$ using the minimality of $x_0$. Also is easy to check that $y\in Y \cap Y'$ iff $y<x_0$. So $\{y\in Y': y<x_0 \}=\{y\in Y\cap Y': y<x_0 \}$. Then $x_0=s(\{y\in Y\cap Y': y<x_0 \})$ because as we have shown is a good set. In other words $x_0= \text{min} (Y'\backslash Y) =s(\{y\in Y\cap Y': y<x_0 \})$. It's trivial to show $s(\{y\in Y\cap Y': y<x_0 \}) =s(Y\cap Y') $ this follows immediately for the way in which $x_0$ was specified since $\{y\in Y\cap Y': y<x_0 \}=Y\cap Y'$, one inclusion is obvious and the other follows because if $y\in Y\cap Y' \subset Y$ thus it can't be greater than $x_0$. Note that exactly the same argument applies only with the roles interchanged of $Y, Y'$ when we assumme $Y\backslash Y'\not= \varnothing$. (4) If $Y,Y' \in \Omega$ are good sets. Then either $Y\backslash Y'$ is non-empty or $Y'\backslash Y$ is non-empty but not both at the same time. Suppose for the sake of contradiction that both cases occurs at the same time, i.e., $Y\backslash Y'\not= \varnothing$ and $Y' \backslash Y\not= \varnothing$. Let $x= \text{min} (Y\backslash Y')$ and $x'= \text{min} (Y'\backslash Y)$. We know by (3) that $x= s(Y\cap Y')$ and also  $x'=s(Y\cap Y')$, which would imply that $x=x'$ but this means that $x,x'\in Y\cap Y'$ which is a contradiction. Hence, it is not possible that both holds at the same time. Also we can show that either $Y\subset Y'$ or $Y' \subset Y$, if were not the case, i.e., $Y\not\subset Y'$ and $Y' \not\subset Y$. Then $Y'\backslash Y$ and $Y\backslash Y'$ are both non-empty which as we have shown above leads a contradiction. (5) To conclude the proof of the claim we shall show that all the elements in $Y'\backslash Y$ are strict upper bounds for $Y$. Note it is not necessary shows that the elements in $Y\backslash Y'$ a strict upper bounds for $Y'$ because exactly the same arguments apply. Let $Y,Y' \in \Omega$, so both are good sets.Then either $Y'\backslash Y$ is empty or not. If the set is empty is vacuously true that each of its element is a strict upper bound for $Y$. If were not the case, this meant $Y\subset Y'$ and $Y\cap Y'=Y$ for what shown in (4). Then $s(Y\cap Y')= s(Y)= \text{min}(Y'\backslash Y)$. So, the minimum element of $Y'\backslash Y$ is an upper bound for $Y$ and so, each element in $Y'\backslash Y$ is strictly greater than each element in $Y$ by transitivity, i.e., are strict upper bounds for $Y$. Hence the claim follows  as desired. I think there is an intimate relation of this proposition and the Zorn's lemma. Am I right?",,"['elementary-set-theory', 'proof-writing', 'self-learning', 'proof-verification', 'order-theory']"
87,Why differentiate between subset and proper subset,Why differentiate between subset and proper subset,,"I am beginning to read through Rudin's book, Principles of Mathematical Analysis (ed. 3) - currently at the part on the set theory definitions he uses (pp. 3). Some of these definitions are: Definition 1: If $A$ and $B$ are sets, and if every element of $A$ is an element of $B$, we say that $A$ is a subset of $B$, and write $A \subset B$. If, in addition, there is an element of $B$ which is not in $A$, then $A$ is said to be a proper subset of $B$. Definition 2: If $A \subset B$ and $B \subset A$, we write $A=B$. Otherwise $A \ne B$. Based upon these definitions, it seems needless to differentiate between subset and proper subset. Take the following conjecture. Conjecture: Suppose $A \subset B$, and $A$ is not a proper subset of $B$. Then $A=B$ Proof: If $A$ is not a proper subset of $B$, then taking the converse of Definition 1 on proper subsets, there does not exist an element of $B$ that does not belong to $A$. However, that means that every element of $B$ must belog to $A$, which according to Definition 1 on subsets, $B \subset A$ and according Definition 2, $A=B$ Following what I had worked out above, what I am wondering is - Why differentiate between subset and proper subset? Given the fact that equality if provided by Definition 2, it seems to me that the retaining a concept of ""proper subset"" is frivolous.","I am beginning to read through Rudin's book, Principles of Mathematical Analysis (ed. 3) - currently at the part on the set theory definitions he uses (pp. 3). Some of these definitions are: Definition 1: If $A$ and $B$ are sets, and if every element of $A$ is an element of $B$, we say that $A$ is a subset of $B$, and write $A \subset B$. If, in addition, there is an element of $B$ which is not in $A$, then $A$ is said to be a proper subset of $B$. Definition 2: If $A \subset B$ and $B \subset A$, we write $A=B$. Otherwise $A \ne B$. Based upon these definitions, it seems needless to differentiate between subset and proper subset. Take the following conjecture. Conjecture: Suppose $A \subset B$, and $A$ is not a proper subset of $B$. Then $A=B$ Proof: If $A$ is not a proper subset of $B$, then taking the converse of Definition 1 on proper subsets, there does not exist an element of $B$ that does not belong to $A$. However, that means that every element of $B$ must belog to $A$, which according to Definition 1 on subsets, $B \subset A$ and according Definition 2, $A=B$ Following what I had worked out above, what I am wondering is - Why differentiate between subset and proper subset? Given the fact that equality if provided by Definition 2, it seems to me that the retaining a concept of ""proper subset"" is frivolous.",,['elementary-set-theory']
88,Cardinality of power set of empty set,Cardinality of power set of empty set,,"I'm trying to show that class $C$ of all even-cardinality sets is not closed over powerset via counter-example. Is it not closed because $|\wp(\{\emptyset\})|=1$ therefore it is not in $C$? I was wondering mainly if the statement ""$|\wp(\{\emptyset\})|=1$ because $\wp\{\emptyset\}=\{\{\emptyset\}\}$"" was true.","I'm trying to show that class $C$ of all even-cardinality sets is not closed over powerset via counter-example. Is it not closed because $|\wp(\{\emptyset\})|=1$ therefore it is not in $C$? I was wondering mainly if the statement ""$|\wp(\{\emptyset\})|=1$ because $\wp\{\emptyset\}=\{\{\emptyset\}\}$"" was true.",,['elementary-set-theory']
89,Is $\log(\aleph_0)$ undefined? [duplicate],Is  undefined? [duplicate],\log(\aleph_0),"This question already has answers here : Is the logarithm of $\aleph_0$ infinite? (4 answers) Closed 7 months ago . NOTE: In the context of this question, the base of $\log(x)$ is $10$ . I was researching cardinal arithmetic when I found out about logarithms of infinite cardinal numbers. Assuming the axiom of choice and given a infinite cardinal $κ$ and a finite cardinal $μ$ greater than 1, there may or may not exist a cardinal $λ$ which satisfies $μ^κ=λ$ . If $λ$ does exist, then it is infinite and less than $κ$ . Since $\aleph_0$ is the smallest infinite cardinal number, $λ$ cannot exist, so does that mean $\log(\aleph_0)$ is undefined?","This question already has answers here : Is the logarithm of $\aleph_0$ infinite? (4 answers) Closed 7 months ago . NOTE: In the context of this question, the base of is . I was researching cardinal arithmetic when I found out about logarithms of infinite cardinal numbers. Assuming the axiom of choice and given a infinite cardinal and a finite cardinal greater than 1, there may or may not exist a cardinal which satisfies . If does exist, then it is infinite and less than . Since is the smallest infinite cardinal number, cannot exist, so does that mean is undefined?",\log(x) 10 κ μ λ μ^κ=λ λ κ \aleph_0 λ \log(\aleph_0),"['elementary-set-theory', 'cardinals']"
90,"Is there a permutation on $\mathbb{N}$ that, if repeated often enough, eventually shuffles the whole set?","Is there a permutation on  that, if repeated often enough, eventually shuffles the whole set?",\mathbb{N},"Does there exist a computable $\pi : \mathbb{N} \to \mathbb{N}$, bijective † and such that for all $i,j\in\mathbb{N}$ there is a $k\in\mathbb{N}$ with $$   \pi^k(i) > j, $$ and, if yes, what is a natural example? † I'm reasonably sure that at least the inverse will have to be uncomputable, but I would need only $\pi$ itself to be computable.","Does there exist a computable $\pi : \mathbb{N} \to \mathbb{N}$, bijective † and such that for all $i,j\in\mathbb{N}$ there is a $k\in\mathbb{N}$ with $$   \pi^k(i) > j, $$ and, if yes, what is a natural example? † I'm reasonably sure that at least the inverse will have to be uncomputable, but I would need only $\pi$ itself to be computable.",,"['elementary-set-theory', 'permutations', 'computability']"
91,$A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset$ holds for all $n$. Must it be that $\bigcap_{n = 1}^{\infty} A_n \ne \emptyset$?,holds for all . Must it be that ?,A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset n \bigcap_{n = 1}^{\infty} A_n \ne \emptyset,"Let $A_1, A_2, A_3, \,\ldots$ be sets such that $A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset$ holds for all $n$ . Must it be that $\bigcap_{n = 1}^{\infty}A_n  \ne \emptyset$ ? I answered no. Here is my ""proof"". Define $A_n = \{n+1, n+2, \,\ldots\}$ . Then $A_1 \cap A_2 \cap \cdots \cap A_n = \{n+1, n+2, \,\ldots\}$ . For all integers $n$ , $\{n+1, n+2, \,\ldots\} \ne \emptyset$ , since it contains $n+1$ , and there is no largest integer. Now consider $\bigcap_{n = 1}^{\infty} A_n$ . Suppose it contains an integer $m$ . But $m \notin A_{m}$ by definition, hence $m \notin \bigcap_{n = 1}^{\infty} A_n$ , so $\bigcap_{n = 1}^{\infty} A_n = \emptyset$ . $$\tag*{$\blacksquare$}$$ Is that correct? I ask because in my lecture notes, the definition of $\bigcap_{n = 1}^{\infty} A_n$ is $\{x : x \in A_n \ \forall n \}$ which (to me) seems to be equivalent to "" $A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset$ holds for all $n$ "", which would of course mean the answer is yes.","Let be sets such that holds for all . Must it be that ? I answered no. Here is my ""proof"". Define . Then . For all integers , , since it contains , and there is no largest integer. Now consider . Suppose it contains an integer . But by definition, hence , so . Is that correct? I ask because in my lecture notes, the definition of is which (to me) seems to be equivalent to "" holds for all "", which would of course mean the answer is yes.","A_1, A_2, A_3, \,\ldots A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset n \bigcap_{n = 1}^{\infty}A_n  \ne \emptyset A_n = \{n+1, n+2, \,\ldots\} A_1 \cap A_2 \cap \cdots \cap A_n = \{n+1, n+2, \,\ldots\} n \{n+1, n+2, \,\ldots\} \ne \emptyset n+1 \bigcap_{n = 1}^{\infty} A_n m m \notin A_{m} m \notin \bigcap_{n = 1}^{\infty} A_n \bigcap_{n = 1}^{\infty} A_n = \emptyset \tag*{\blacksquare} \bigcap_{n = 1}^{\infty} A_n \{x : x \in A_n \ \forall n \} A_1 \cap A_2 \cap \cdots \cap A_n \ne \emptyset n",['elementary-set-theory']
92,First usage of the symbol ∈,First usage of the symbol ∈,,"Concerning a book [1] I am reading the symbol $\in$ was first used by Giuseppe Peano and is the first letter $\epsilon$ ( epsilon ) of the word ἐστί (means ""is""). Does anyone know in which work of Peano $\in$ was first used? [1] Ingmar Lehmann, Wolfgang Schulz: ""Mengen, Relationen, Funktionen"" (3. Auflage, 2007), page 10 Similar question: What is the name of the ∈ symbol and where does it come from?","Concerning a book [1] I am reading the symbol $\in$ was first used by Giuseppe Peano and is the first letter $\epsilon$ ( epsilon ) of the word ἐστί (means ""is""). Does anyone know in which work of Peano $\in$ was first used? [1] Ingmar Lehmann, Wolfgang Schulz: ""Mengen, Relationen, Funktionen"" (3. Auflage, 2007), page 10 Similar question: What is the name of the ∈ symbol and where does it come from?",,"['elementary-set-theory', 'reference-request', 'notation', 'math-history']"
93,Intersection of intervals,Intersection of intervals,,"Let $a\in\mathbb{N}_{\geq3}$. How can one prove that $$\bigcap_{i = 1}^{a} \bigcup_{j = 0}^{i-1} \left[\frac{1+aj}{i},\frac{a(j+1)-1}{i}\right] = \varnothing,$$ where $\varnothing$ is the empty set? Example for $a=5$: Red is the interval, Yellow are the gaps between the intervals that cause the intersection to be a null set, white gaps do not effect the intersection.","Let $a\in\mathbb{N}_{\geq3}$. How can one prove that $$\bigcap_{i = 1}^{a} \bigcup_{j = 0}^{i-1} \left[\frac{1+aj}{i},\frac{a(j+1)-1}{i}\right] = \varnothing,$$ where $\varnothing$ is the empty set? Example for $a=5$: Red is the interval, Yellow are the gaps between the intervals that cause the intersection to be a null set, white gaps do not effect the intersection.",,['elementary-set-theory']
94,Can we define a function as a cartesian product of *tuples*? Could we make use of the implict indices of the variables when defining the function?,Can we define a function as a cartesian product of *tuples*? Could we make use of the implict indices of the variables when defining the function?,,"First, as noted in the comments, this question is on notation and so it might not be the easiest to understand. The crux of my question is whether the notation that I am using makes sense and whether one could use such ideas (e.g., making use of the value of the index of a variable within some tuple) We will say that an n-tuple $(a_0, a_1,...,a_n)$ is the ordered collection that has $a_i$ as its i-th element for all integers i such that $0 \leq i \leq n$ Two n-tuples are equal if each pair of corresponding entries are equal. That is, $(a_0, a_1,...,a_n) = (b_0, b_1,...,a_n)$ if and only if $a_i = b_i$ for all $i \in$ {$0,1,2,...,n$} Also note the following: We will be considering only finite tuples where no tuple contains repeated elements. That is, each element in the tuples we are   considering is distinct. Now, as for the definition of an n-tuple we could get more technical, but I don't believe it should matter. The main point I want to utilize about tuples is that they have index values (that is, their elements are ordered). And in our case, I want to utilize the fact that the  each element corresponds to a unique index. This holds in our case since no tuple has repeated elements. I will now give some examples of what I would like to do. I am wondering if such things are conventional, and if not, whether they would still be acceptable. Consider the 2 tuples $t = (a, b, c)$ and $r = (a, d, f)$ and the set $S = $ {$ {a,b,c}$ } First: Does it make sense to ask something like ""Is $a \in t$?""  as we do when we ask (for example as exercises in some introduction to set-theory book) ""Is $a \in S$?"" ? Does the symbol  $'\in$'make sense when applied to tuples? I am working on something where I am explicitly working with tuples and I would like to be able to pose statements such as ""if x is an element of tuple t, then..."". But I am not sure if that even makes mathematical sense . To talk of ""elements"" of a tuple, I think intuitively makes sense, but I am not sure if technically the '$\in$' symbol is how one goes about doing it. Remark : And if I am to use '$\forall x \in t$' I mean all values in the tuple $t$ in the same way that $\forall x \in S$ means all values in $S$. Second: Could we have a Cartesian product of the 2 tuples? If using the $\in$ symbol like I did in the first question makes sense, then can we define the Cartesian-product of two tuples as: The Cartesian-Product of two tuples $t$ and $r$ denoted by ($t \times r$) is the set of ordered-pairs $(a,b)$ where $a \in t$ and $b \in r$. That is, (just like the definition w.r.t. sets), we have that ($t \times r) := ${  $(a, b) : a \in t \wedge b \in r$} Is this used at all, if not, would it be acceptable? Example: Using the tuples $t$, $r$ defined earlier, ($t \times r) =$        {$(a,a) ,(a,d) , (a,f) , (b,a) , (b,d) , (b,f) , (c,a) , (c,d) , (c,f) $} Note, this results in a set , not a tuple. Third: First, let us also say that for any tuple $t$ (where the domain consists of only the kinds of tuples we are considering), $I_t(x) $ denotes the value-of-the-index associated with the element x of the tuple t, for all x in t. Ok, now I am also curious about whether the following kind of statement makes sense or not. What I want to do is define a function but when defining this function I want to make use of the implict-indices associated with the values of the tuples we are considering. What I want is to have a tuple itself be the domain . That is, I want to have a function a $f$: $t \rightarrow$ $\mathbb{N}$ So what does this mean? I want the domain to be all the values of the tuple $t$, but I don't just want the values. I also want to make use of the values of the indices . That is, I want those values to in some way be part of the input-argument . So why not just create a set whose elements are all those elements in the tuple $t$? Well, the problem is that there would be no associated index-values with those elements. Only the elements of a tuple have an associated index (in our case, each value has a unique associated index). I want to define $f$ as something like: for each tuple $t$, we define a function $f: t \rightarrow \mathbb{N}$ as being $f(x) = I_t(x) + 2$ ,  $\forall x \in t $. Example: Using the tuple $r$ defined in the beginning, $f(d) = 1 + 2 = 3$ The point is, that I want the value of the function to—in part—be determined by the index that the argument is associated with/resides in, with respect to the tuple that it comes from. My question is whether this is done anywhere in mathematics, and if it isn't, would it be acceptable to do so provided I give the explanation I am giving here (with slightly more rigor)? Fourth: Taking things one step further, I would also like to have a function that goes from the Cartesian-product of 2 tuples $a$ and $b$ to the natural-numbers. That is I would like to have, $g : (a \times b) \rightarrow \mathbb{N}$ And then define $g$ to be something like $g( (x,y) ) = I_a(x) + I_b(y) + 2$ for all $x \in a$ and $b \in b$ Example: Again using the already defined tuples $t$ and $r$, g((c,d)) = 2 + 1 + 2 = 5 The thing about mathematics though is that it is about creation in a lot of ways, as long as you are precise enough. So even if these ideas aren’t really conventional, am I coming off (more-or-less) precise enough so that I could use these ideas? My concern is that maybe having a tuple itself be a domain, for example, is too outside the realm of normalcy. Thank you for taking the time to read it all, I hope it makes sense.","First, as noted in the comments, this question is on notation and so it might not be the easiest to understand. The crux of my question is whether the notation that I am using makes sense and whether one could use such ideas (e.g., making use of the value of the index of a variable within some tuple) We will say that an n-tuple $(a_0, a_1,...,a_n)$ is the ordered collection that has $a_i$ as its i-th element for all integers i such that $0 \leq i \leq n$ Two n-tuples are equal if each pair of corresponding entries are equal. That is, $(a_0, a_1,...,a_n) = (b_0, b_1,...,a_n)$ if and only if $a_i = b_i$ for all $i \in$ {$0,1,2,...,n$} Also note the following: We will be considering only finite tuples where no tuple contains repeated elements. That is, each element in the tuples we are   considering is distinct. Now, as for the definition of an n-tuple we could get more technical, but I don't believe it should matter. The main point I want to utilize about tuples is that they have index values (that is, their elements are ordered). And in our case, I want to utilize the fact that the  each element corresponds to a unique index. This holds in our case since no tuple has repeated elements. I will now give some examples of what I would like to do. I am wondering if such things are conventional, and if not, whether they would still be acceptable. Consider the 2 tuples $t = (a, b, c)$ and $r = (a, d, f)$ and the set $S = $ {$ {a,b,c}$ } First: Does it make sense to ask something like ""Is $a \in t$?""  as we do when we ask (for example as exercises in some introduction to set-theory book) ""Is $a \in S$?"" ? Does the symbol  $'\in$'make sense when applied to tuples? I am working on something where I am explicitly working with tuples and I would like to be able to pose statements such as ""if x is an element of tuple t, then..."". But I am not sure if that even makes mathematical sense . To talk of ""elements"" of a tuple, I think intuitively makes sense, but I am not sure if technically the '$\in$' symbol is how one goes about doing it. Remark : And if I am to use '$\forall x \in t$' I mean all values in the tuple $t$ in the same way that $\forall x \in S$ means all values in $S$. Second: Could we have a Cartesian product of the 2 tuples? If using the $\in$ symbol like I did in the first question makes sense, then can we define the Cartesian-product of two tuples as: The Cartesian-Product of two tuples $t$ and $r$ denoted by ($t \times r$) is the set of ordered-pairs $(a,b)$ where $a \in t$ and $b \in r$. That is, (just like the definition w.r.t. sets), we have that ($t \times r) := ${  $(a, b) : a \in t \wedge b \in r$} Is this used at all, if not, would it be acceptable? Example: Using the tuples $t$, $r$ defined earlier, ($t \times r) =$        {$(a,a) ,(a,d) , (a,f) , (b,a) , (b,d) , (b,f) , (c,a) , (c,d) , (c,f) $} Note, this results in a set , not a tuple. Third: First, let us also say that for any tuple $t$ (where the domain consists of only the kinds of tuples we are considering), $I_t(x) $ denotes the value-of-the-index associated with the element x of the tuple t, for all x in t. Ok, now I am also curious about whether the following kind of statement makes sense or not. What I want to do is define a function but when defining this function I want to make use of the implict-indices associated with the values of the tuples we are considering. What I want is to have a tuple itself be the domain . That is, I want to have a function a $f$: $t \rightarrow$ $\mathbb{N}$ So what does this mean? I want the domain to be all the values of the tuple $t$, but I don't just want the values. I also want to make use of the values of the indices . That is, I want those values to in some way be part of the input-argument . So why not just create a set whose elements are all those elements in the tuple $t$? Well, the problem is that there would be no associated index-values with those elements. Only the elements of a tuple have an associated index (in our case, each value has a unique associated index). I want to define $f$ as something like: for each tuple $t$, we define a function $f: t \rightarrow \mathbb{N}$ as being $f(x) = I_t(x) + 2$ ,  $\forall x \in t $. Example: Using the tuple $r$ defined in the beginning, $f(d) = 1 + 2 = 3$ The point is, that I want the value of the function to—in part—be determined by the index that the argument is associated with/resides in, with respect to the tuple that it comes from. My question is whether this is done anywhere in mathematics, and if it isn't, would it be acceptable to do so provided I give the explanation I am giving here (with slightly more rigor)? Fourth: Taking things one step further, I would also like to have a function that goes from the Cartesian-product of 2 tuples $a$ and $b$ to the natural-numbers. That is I would like to have, $g : (a \times b) \rightarrow \mathbb{N}$ And then define $g$ to be something like $g( (x,y) ) = I_a(x) + I_b(y) + 2$ for all $x \in a$ and $b \in b$ Example: Again using the already defined tuples $t$ and $r$, g((c,d)) = 2 + 1 + 2 = 5 The thing about mathematics though is that it is about creation in a lot of ways, as long as you are precise enough. So even if these ideas aren’t really conventional, am I coming off (more-or-less) precise enough so that I could use these ideas? My concern is that maybe having a tuple itself be a domain, for example, is too outside the realm of normalcy. Thank you for taking the time to read it all, I hope it makes sense.",,"['elementary-set-theory', 'logic', 'notation', 'convention']"
95,Why is the axiom of choice controversial? [duplicate],Why is the axiom of choice controversial? [duplicate],,"This question already has answers here : Why is the axiom of choice separated from the other axioms? (4 answers) Closed 7 years ago . In other words, what are the arguments for ZF over ZFC, and what philosophical issues have people raised against including it as a standard axiom of set theory?","This question already has answers here : Why is the axiom of choice separated from the other axioms? (4 answers) Closed 7 years ago . In other words, what are the arguments for ZF over ZFC, and what philosophical issues have people raised against including it as a standard axiom of set theory?",,"['elementary-set-theory', 'axiom-of-choice']"
96,Is the limit of a recursive sequence of recursive ordinals itself a recursive ordinal?,Is the limit of a recursive sequence of recursive ordinals itself a recursive ordinal?,,"Is the limit of a recursive sequence of recursive ordinals itself a recursive ordinal? If so, is there a nice proof of this?","Is the limit of a recursive sequence of recursive ordinals itself a recursive ordinal? If so, is there a nice proof of this?",,"['elementary-set-theory', 'computability', 'ordinals']"
97,How to extract an element from a set?,How to extract an element from a set?,,"Given for example $B=\{A\}$, how do you express $A$ in formal set theory? You'd be tempted to say ""the unique element $X$ such that $X$ is a member of $B$"", but the only way I know to express ""such that"" in set theory is with set builder notation: $$\{X | X \in B\}$$ But this is useless since we've wrapped $A$ up inside a set once again. This strikes me as an important question, since otherwise how can we express $f(x)$? You'd need something like ""the second member of the ordered pair in $f$ whose first member is $x$"", which is a more complicated version of the above problem.","Given for example $B=\{A\}$, how do you express $A$ in formal set theory? You'd be tempted to say ""the unique element $X$ such that $X$ is a member of $B$"", but the only way I know to express ""such that"" in set theory is with set builder notation: $$\{X | X \in B\}$$ But this is useless since we've wrapped $A$ up inside a set once again. This strikes me as an important question, since otherwise how can we express $f(x)$? You'd need something like ""the second member of the ordered pair in $f$ whose first member is $x$"", which is a more complicated version of the above problem.",,['elementary-set-theory']
98,"Cardinality of $\{\emptyset, \mathcal{P}(\emptyset), \{\emptyset\} \} $",Cardinality of,"\{\emptyset, \mathcal{P}(\emptyset), \{\emptyset\} \} ","This is an old exam question from ""Diskrete Mathematik"" at ETH Zurich $\mathcal{P}(A)$ denotes the Powerset, which is the set of all subsets of A: $\mathcal{P}(A) := \{S|S\subseteq A \}$. I believe that  $\{\emptyset, \mathcal{P}(\emptyset), \{\emptyset\} \} $ since $\mathcal{P}(\emptyset) = \{\emptyset\} $ can be reduced to $\{\emptyset, \{\emptyset\} \} $ and thus the cardinality of said set would be 2. However, the inofficial solution is 3.","This is an old exam question from ""Diskrete Mathematik"" at ETH Zurich $\mathcal{P}(A)$ denotes the Powerset, which is the set of all subsets of A: $\mathcal{P}(A) := \{S|S\subseteq A \}$. I believe that  $\{\emptyset, \mathcal{P}(\emptyset), \{\emptyset\} \} $ since $\mathcal{P}(\emptyset) = \{\emptyset\} $ can be reduced to $\{\emptyset, \{\emptyset\} \} $ and thus the cardinality of said set would be 2. However, the inofficial solution is 3.",,['elementary-set-theory']
99,Is a transitive and Euclidean relation necessarily symmetric?,Is a transitive and Euclidean relation necessarily symmetric?,,"The Wikipedia article on Euclidean relation reads: A transitive relation is Euclidean only if it is also symmetric. Only a symmetric Euclidean relation is transitive. It seems to be claimed that every transitive and Euclidean relation is symmetric. However, consider the following relation, where $a$, $b$, and $c$ are distinct elements: $R = \{\langle a, b \rangle, \langle a, c \rangle, \langle b, b \rangle, \langle b, c \rangle, \langle c, b \rangle, \langle c, c \rangle\}.$ I think $R$ is transitive and Euclidean but not symmetric, so the claim appears to be wrong to me. This version of the Wikipedia article is due to the edit done on March 8, 2016, and the version before the edit seems correct and precise. Am I correct or mistaken?","The Wikipedia article on Euclidean relation reads: A transitive relation is Euclidean only if it is also symmetric. Only a symmetric Euclidean relation is transitive. It seems to be claimed that every transitive and Euclidean relation is symmetric. However, consider the following relation, where $a$, $b$, and $c$ are distinct elements: $R = \{\langle a, b \rangle, \langle a, c \rangle, \langle b, b \rangle, \langle b, c \rangle, \langle c, b \rangle, \langle c, c \rangle\}.$ I think $R$ is transitive and Euclidean but not symmetric, so the claim appears to be wrong to me. This version of the Wikipedia article is due to the edit done on March 8, 2016, and the version before the edit seems correct and precise. Am I correct or mistaken?",,"['elementary-set-theory', 'logic', 'relations']"
