,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Understanding twisted differential forms,Understanding twisted differential forms,,"I'm trying to understand twisted differential forms.  I do know that they are like regular differential forms but under coordinate transformations they pick up an extra factor of the sign of the determinant of the transformation.  Somehow this means that they can be used to integrate on non-orientable manifolds. (???) While Googling, I saw this question on Physics Forums , where one of the answers seems like a good start at understanding twisted differential forms.  I'll quote the answer here for reference. Consider a line segment. There are two ways one can orient this: along the segment and across the segment. For example, if you wanted to represent a segment of the world-line of a particle, then the first type of orientation is appropriate. On the other hand, imagine a circle drawn on a plane. A segment of this circle naturally has an orientation of the second type: it is oriented 'across' the segment, depending on which side of the circle is 'inside' and which is 'outside' This is the main difference between differential forms and their twisted counterparts, i.e. the type of orientation. The contour lines of a function have the 'across' orientation, and are represented by 1-forms. But if we wanted to represent coutour lines with an orientation along them instead of across, you would use a twisted 1-form. Imagine 2+1 dimensional spacetime. I assume you're familiar with the usual picture of a 2-form in a three dimensional space. The 'tubes' or 'boxes' in the picture of this 2-form will have an orientation that is 'around' them, i.e. clockwise or anticlockwise. Of course, one can always convert from clockwise/anticlockwise to up/down using things like right-hand rules, but that is not the natural type of orientation of a current. For a twisted 2-form, on the other hand, the tubes or boxes will have the correct 'along' orientation. So, in 2+1 dimensional spacetime, current density is a twisted 2-form. Similarly, in 3+1 dimensions, it is a twisted 3-form. Though this isn't the way I usually think of differential forms, I am somewhat familiar with the geometric interpretation -- at least for $1$ -forms -- as stacks through which vectors penetrate.  However I'm still not entirely able to see what a twisted differential $1$ -form would be.  Geometrically, is it supposed to be like a curve which ""counts"" the projections of the tangent vectors onto the tangents of the curve along it?  If so, how is that picture obtained from the definition?  And how does one visualize higher dimensional twisted forms -- because I don't really understand that part of the post at all.","I'm trying to understand twisted differential forms.  I do know that they are like regular differential forms but under coordinate transformations they pick up an extra factor of the sign of the determinant of the transformation.  Somehow this means that they can be used to integrate on non-orientable manifolds. (???) While Googling, I saw this question on Physics Forums , where one of the answers seems like a good start at understanding twisted differential forms.  I'll quote the answer here for reference. Consider a line segment. There are two ways one can orient this: along the segment and across the segment. For example, if you wanted to represent a segment of the world-line of a particle, then the first type of orientation is appropriate. On the other hand, imagine a circle drawn on a plane. A segment of this circle naturally has an orientation of the second type: it is oriented 'across' the segment, depending on which side of the circle is 'inside' and which is 'outside' This is the main difference between differential forms and their twisted counterparts, i.e. the type of orientation. The contour lines of a function have the 'across' orientation, and are represented by 1-forms. But if we wanted to represent coutour lines with an orientation along them instead of across, you would use a twisted 1-form. Imagine 2+1 dimensional spacetime. I assume you're familiar with the usual picture of a 2-form in a three dimensional space. The 'tubes' or 'boxes' in the picture of this 2-form will have an orientation that is 'around' them, i.e. clockwise or anticlockwise. Of course, one can always convert from clockwise/anticlockwise to up/down using things like right-hand rules, but that is not the natural type of orientation of a current. For a twisted 2-form, on the other hand, the tubes or boxes will have the correct 'along' orientation. So, in 2+1 dimensional spacetime, current density is a twisted 2-form. Similarly, in 3+1 dimensions, it is a twisted 3-form. Though this isn't the way I usually think of differential forms, I am somewhat familiar with the geometric interpretation -- at least for -forms -- as stacks through which vectors penetrate.  However I'm still not entirely able to see what a twisted differential -form would be.  Geometrically, is it supposed to be like a curve which ""counts"" the projections of the tangent vectors onto the tangents of the curve along it?  If so, how is that picture obtained from the definition?  And how does one visualize higher dimensional twisted forms -- because I don't really understand that part of the post at all.",1 1,"['differential-geometry', 'mathematical-physics', 'differential-forms']"
1,"Is geodesic distance equivalent to ""norm distance"" in $SL_n(\mathbb{R})$?","Is geodesic distance equivalent to ""norm distance"" in ?",SL_n(\mathbb{R}),"Take any norm, $\|\cdot\|$on $\mathbb{R}^n,$ and consider the resulting norm on $SL_n(\mathbb{R})$: $$\|A\|:= sup\{\|Av\|: \|v\|=1\}.$$ Now take any left-invariant Riemannian metric, $g$, on $SL_n$. How do the geodesic balls, $B_g(I, r)$ around the identity matrix, $I$, compare with the metric balls, $B_{\|\cdot\|}(I,r)$ coming from $\|\cdot\|$?  In particular do there exist $c, C$ such that $$B_{\|\cdot\|}(I,cr)\subset B_g(I, r) \subset B_{\|\cdot\|}(I,Cr)$$ for all sufficiently small $r$?  Or anything of the sort?","Take any norm, $\|\cdot\|$on $\mathbb{R}^n,$ and consider the resulting norm on $SL_n(\mathbb{R})$: $$\|A\|:= sup\{\|Av\|: \|v\|=1\}.$$ Now take any left-invariant Riemannian metric, $g$, on $SL_n$. How do the geodesic balls, $B_g(I, r)$ around the identity matrix, $I$, compare with the metric balls, $B_{\|\cdot\|}(I,r)$ coming from $\|\cdot\|$?  In particular do there exist $c, C$ such that $$B_{\|\cdot\|}(I,cr)\subset B_g(I, r) \subset B_{\|\cdot\|}(I,Cr)$$ for all sufficiently small $r$?  Or anything of the sort?",,"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
2,Why is the Leibniz rule a sufficient ingredient in the construction of the tangent space?,Why is the Leibniz rule a sufficient ingredient in the construction of the tangent space?,,"This is a very soft question, but I am wondering if anyone can shed light on why it is that the product rule (and linearity) provide exactly the right requirement for the space of derivations to be the tangent space? A similar dependence on the product rule seems to pop up if you want to define the cotangent space at p as $m_p / m_p^2$ in the stalk at p of the sheaf of differentiable functions. What is it that makes the product rule the identifying feature of differentiation among all linear functions?","This is a very soft question, but I am wondering if anyone can shed light on why it is that the product rule (and linearity) provide exactly the right requirement for the space of derivations to be the tangent space? A similar dependence on the product rule seems to pop up if you want to define the cotangent space at p as $m_p / m_p^2$ in the stalk at p of the sheaf of differentiable functions. What is it that makes the product rule the identifying feature of differentiation among all linear functions?",,"['algebraic-geometry', 'differential-geometry', 'soft-question']"
3,Why does the Gauss-Bonnet theorem apply only to even number of dimensons?,Why does the Gauss-Bonnet theorem apply only to even number of dimensons?,,"One can use the Gauss-Bonnet theorem in 2D or 4D to deduce topological characteristics of a manifold by doing integrals over the curvature at each point. First, why isn't there an equivalent theorem in 3D? Why can not the theorem be proved for odd number of dimensions (i.e. what part of the proof prohibits such generalization)? Second and related, if there was such a theorem, what interesting and difficult problem would become easy/inconsistent? (the second question is intentionally vague, no need to answer if it is not clear)","One can use the Gauss-Bonnet theorem in 2D or 4D to deduce topological characteristics of a manifold by doing integrals over the curvature at each point. First, why isn't there an equivalent theorem in 3D? Why can not the theorem be proved for odd number of dimensions (i.e. what part of the proof prohibits such generalization)? Second and related, if there was such a theorem, what interesting and difficult problem would become easy/inconsistent? (the second question is intentionally vague, no need to answer if it is not clear)",,"['differential-geometry', 'differential-topology']"
4,What is the universal property of the tangent bundle of a smooth manifold?,What is the universal property of the tangent bundle of a smooth manifold?,,"The process of writing my own notes on smooth manifolds have led me to wonder about this. All I've really found is the following: In addition to Madame Ehresmann's references, there is in   Spivak's Comprehensive Introduction... an abstract    characterization of the tangent bundle ( removed from the   main text in the second edition `due to the pressure of public    distaste') Taken from http://permalink.gmane.org/gmane.science.mathematics.categories/1189 I have neither Madame Ehresmann's notes, nor an older edition of Spivak. Sincerely, Eivind","The process of writing my own notes on smooth manifolds have led me to wonder about this. All I've really found is the following: In addition to Madame Ehresmann's references, there is in   Spivak's Comprehensive Introduction... an abstract    characterization of the tangent bundle ( removed from the   main text in the second edition `due to the pressure of public    distaste') Taken from http://permalink.gmane.org/gmane.science.mathematics.categories/1189 I have neither Madame Ehresmann's notes, nor an older edition of Spivak. Sincerely, Eivind",,['differential-geometry']
5,When is an $n$-dimensional manifold characterized by its $m$-dimensional submanifolds?,When is an -dimensional manifold characterized by its -dimensional submanifolds?,n m,"For which $m$, $n$ (if any) is the following true: if $M$ and $M'$ are smooth manifolds of dimension $n$, and $\Phi$ is a bijection from $M$ to $M'$ such that for any subset $S$ of $M$, $\Phi(S)$ is an embedded submanifold of $M'$ of dimension $m$ iff $S$ is an embedded submanifold of $M$ of dimension $m$, then $\Phi$ is a diffeomorphism? This is clearly false when $m=0$ and when $m=n$.  I thought it looked plausible when, for example, $m=1$ and $n\geq 2$; but I can't see how to prove it.","For which $m$, $n$ (if any) is the following true: if $M$ and $M'$ are smooth manifolds of dimension $n$, and $\Phi$ is a bijection from $M$ to $M'$ such that for any subset $S$ of $M$, $\Phi(S)$ is an embedded submanifold of $M'$ of dimension $m$ iff $S$ is an embedded submanifold of $M$ of dimension $m$, then $\Phi$ is a diffeomorphism? This is clearly false when $m=0$ and when $m=n$.  I thought it looked plausible when, for example, $m=1$ and $n\geq 2$; but I can't see how to prove it.",,['differential-geometry']
6,Centralizer of one element on a compact connected Lie group,Centralizer of one element on a compact connected Lie group,,"Exercise 16.2 from Daniel Bump - Lie Groups . Let $G$ be a compact connected Lie group and let $g\in G$ . Show that the centralizer $C_G(g)$ of $g$ is connected. I have some problems verifying this, I have tried to use that in that case the exponential map is surjective, and think of the maximal torus, but I have not achieved it, I would appreciate some answer.","Exercise 16.2 from Daniel Bump - Lie Groups . Let be a compact connected Lie group and let . Show that the centralizer of is connected. I have some problems verifying this, I have tried to use that in that case the exponential map is surjective, and think of the maximal torus, but I have not achieved it, I would appreciate some answer.",G g\in G C_G(g) g,"['differential-geometry', 'representation-theory', 'lie-groups']"
7,The 4-sphere does not admit dimension 2 foliations,The 4-sphere does not admit dimension 2 foliations,,"I want to know if the 4-sphere admits dimension 2 foliations. I found the following theorem in a dissertation by Jonathan Bowden (this is googleable, but I won't link it because I don't know exactly what the copyright issues might be). Anyway, here it is: A closed, oriented 4-manifold admits an oriented 2-plane distribution if and only if  there exists a pair  $K_+,K_-\in H^2(M)$ such that $$\langle K_\pm^2,[M]\rangle = \pm 2\chi(M)+3\sigma(M)$$ $$K_\pm\equiv w_2(M)\mod 2$$ Since a requirement for a $n$-dimensional foliation is a 2-plane distribution, and a sphere has trivial middle homology, I think this implies the 4-sphere has no dimension 2 foliations. Am I correct? EDIT: For any complex manifold $M$ we have the canonical line bundle $K_M=det_{\mathbb{C}}T^*_M$, and $$K_M\cdot K_M=3\sigma (M)+2\chi(M)$$ So I'm not sure about the equivalence of these notations; I think that pairing over $[M]$ might be implied in the second one since if you represent these classes as forms you need to integrate over the manifold to get integers. But then again the 4-sphere is not a complex manifold, but maybe there is some connection between complex 2-manifolds and when they can be foliated in dimension 2? EDIT': I have posted a followup: Examples of 2-dimensional foliations of a 4-sphere.","I want to know if the 4-sphere admits dimension 2 foliations. I found the following theorem in a dissertation by Jonathan Bowden (this is googleable, but I won't link it because I don't know exactly what the copyright issues might be). Anyway, here it is: A closed, oriented 4-manifold admits an oriented 2-plane distribution if and only if  there exists a pair  $K_+,K_-\in H^2(M)$ such that $$\langle K_\pm^2,[M]\rangle = \pm 2\chi(M)+3\sigma(M)$$ $$K_\pm\equiv w_2(M)\mod 2$$ Since a requirement for a $n$-dimensional foliation is a 2-plane distribution, and a sphere has trivial middle homology, I think this implies the 4-sphere has no dimension 2 foliations. Am I correct? EDIT: For any complex manifold $M$ we have the canonical line bundle $K_M=det_{\mathbb{C}}T^*_M$, and $$K_M\cdot K_M=3\sigma (M)+2\chi(M)$$ So I'm not sure about the equivalence of these notations; I think that pairing over $[M]$ might be implied in the second one since if you represent these classes as forms you need to integrate over the manifold to get integers. But then again the 4-sphere is not a complex manifold, but maybe there is some connection between complex 2-manifolds and when they can be foliated in dimension 2? EDIT': I have posted a followup: Examples of 2-dimensional foliations of a 4-sphere.",,"['differential-geometry', 'foliations']"
8,Smoothness of $O(n)$-equivariant maps of positive-definite matrices,Smoothness of -equivariant maps of positive-definite matrices,O(n),"$\def\sp{\mathrm{Sym}^+}$Let $\sp \subset GL(n,\mathbb R)$ denote the manifold of positive-definite symmetric $n \times n$ matrices. I am interested in functions $A : \sp \to \sp$ that are equivariant under the natural conjugation action of $O(n)$; i.e. such that$$A(R^T X R) = R^T A(X) R$$ for all $X \in \sp, R \in O(n)$. By choosing $R \in O(n)$ to diagonalize $X$ and then letting $R$ range over reflection and permutation matrices, one can characterize these $A$ as exactly those of the form $$A(X) = \sum_{k=1}^n a(\lambda_k; \lambda_1, \ldots, \widehat{\lambda_k}, \ldots, \lambda_n)e_k \otimes e_k$$ where $\lambda_k>0$ are the (repeated) eigenvalues of $X$ with corresponding (orthonormal) eigenvectors $e_k$ and $a : (0,\infty)^n \to (0,\infty)$ is symmetric in its last $n-1$ arguments. (The $\widehat \lambda_k$ denotes omission.) Since $a(\lambda_1;\lambda_2,\ldots,\lambda_n) = A^{11}(\mathrm{diag}(\lambda_1,\ldots,\lambda_n))$, we know that $A \in C^\infty \implies a \in C^\infty$. My question is: Does the converse hold; i.e. if $a$ is smooth can we conclude that $A$ is smooth? In the analogous problem for $O(n)$-invariant maps $A : \sp \to \mathbb R$ (which reduce to symmetric functions $a : (0,\infty)^n \to \mathbb R$ of the eigenvalues), we can solve this problem using Glaeser's ""differentiable Newton's theorem"" - we get that a smooth symmetric function of the eigenvalues is a smooth function of the symmetric matrix invariants , which are in turn smooth functions of the matrix itself. However, I'm unsure how to transfer this kind of idea to the matrix-valued setting - all I can find are references about invariant scalars (e.g. Schwarz is a nice generalization of Glaeser's result, but still not obviously of use to me). I guess my issue is that I don't know how to retain any regularity when ""packing the eigenvalues back in"", since the eigenspaces are not smooth functions of the matrix. I guess one way you could think of this is as a generalization of functional calculus - if we restrict to $a$ that depend only on their first argument, then (from what I understand) functional calculus is exactly the construction of $A$ from $a$. Some progress: I have managed to prove the polynomial version by finding a recurrence relation of equivariant matrices that induces Newton's identities on the eigenvalues: If $a : (0,\infty)^n \to (0,\infty)$ is a polynomial symmetric in its last $n-1$ arguments, then the output components of the corresponding map $A : \sp \to \sp$ are polynomials in the input components. However, in retrospect I'm not sure if this helps at all in attaining the smooth version. Any input from someone more familiar with this kind of stuff would be greatly appreciated - my representation/invariant/????? theory background is lacking.","$\def\sp{\mathrm{Sym}^+}$Let $\sp \subset GL(n,\mathbb R)$ denote the manifold of positive-definite symmetric $n \times n$ matrices. I am interested in functions $A : \sp \to \sp$ that are equivariant under the natural conjugation action of $O(n)$; i.e. such that$$A(R^T X R) = R^T A(X) R$$ for all $X \in \sp, R \in O(n)$. By choosing $R \in O(n)$ to diagonalize $X$ and then letting $R$ range over reflection and permutation matrices, one can characterize these $A$ as exactly those of the form $$A(X) = \sum_{k=1}^n a(\lambda_k; \lambda_1, \ldots, \widehat{\lambda_k}, \ldots, \lambda_n)e_k \otimes e_k$$ where $\lambda_k>0$ are the (repeated) eigenvalues of $X$ with corresponding (orthonormal) eigenvectors $e_k$ and $a : (0,\infty)^n \to (0,\infty)$ is symmetric in its last $n-1$ arguments. (The $\widehat \lambda_k$ denotes omission.) Since $a(\lambda_1;\lambda_2,\ldots,\lambda_n) = A^{11}(\mathrm{diag}(\lambda_1,\ldots,\lambda_n))$, we know that $A \in C^\infty \implies a \in C^\infty$. My question is: Does the converse hold; i.e. if $a$ is smooth can we conclude that $A$ is smooth? In the analogous problem for $O(n)$-invariant maps $A : \sp \to \mathbb R$ (which reduce to symmetric functions $a : (0,\infty)^n \to \mathbb R$ of the eigenvalues), we can solve this problem using Glaeser's ""differentiable Newton's theorem"" - we get that a smooth symmetric function of the eigenvalues is a smooth function of the symmetric matrix invariants , which are in turn smooth functions of the matrix itself. However, I'm unsure how to transfer this kind of idea to the matrix-valued setting - all I can find are references about invariant scalars (e.g. Schwarz is a nice generalization of Glaeser's result, but still not obviously of use to me). I guess my issue is that I don't know how to retain any regularity when ""packing the eigenvalues back in"", since the eigenspaces are not smooth functions of the matrix. I guess one way you could think of this is as a generalization of functional calculus - if we restrict to $a$ that depend only on their first argument, then (from what I understand) functional calculus is exactly the construction of $A$ from $a$. Some progress: I have managed to prove the polynomial version by finding a recurrence relation of equivariant matrices that induces Newton's identities on the eigenvalues: If $a : (0,\infty)^n \to (0,\infty)$ is a polynomial symmetric in its last $n-1$ arguments, then the output components of the corresponding map $A : \sp \to \sp$ are polynomials in the input components. However, in retrospect I'm not sure if this helps at all in attaining the smooth version. Any input from someone more familiar with this kind of stuff would be greatly appreciated - my representation/invariant/????? theory background is lacking.",,"['differential-geometry', 'representation-theory', 'matrix-calculus', 'invariant-theory', 'functional-calculus']"
9,Turning number VS winding number,Turning number VS winding number,,"To avoid confusion, here are the definitions of the objects in this question: 1) Let $\gamma:S^1\to\mathbb{R}^2\setminus\{0\}$ a smooth loop. The winding number of $\gamma$ is the number of times $\gamma$ encircles $0$. Similarly, if $\gamma:S^1\to\mathbb{R}^2\setminus\{p\}$ for some $p\in\mathbb{R}^2$, the winding number of $\gamma$ around $p$ is the winding number of the translation $\gamma-p$. As we all know, the winding number can be defined rigorously by means of algebraic topology / two-variable calculus / complex variables. 2) Let $\gamma:S^1\to\mathbb{R}^2$ smooth with non-vanishing derivative. The turning number of $\gamma$ is the winding number of $\dot{\gamma}$. My question is about the following Claim: Let $\gamma:S^1\to\mathbb{R}^2$ be a simple loop with non-vanishing derivative. Then the turning number of $\gamma$ is either $1$ or $-1$. Furthermore, for any $p$ in the area enclosed by $\gamma$, the winding number of $\gamma$ around $p$ is equal to the turning number. This claim seems to be rather intuitive, but I can't think of an elementary way to prove it. One way, I guess, is to use the fact that any such loop is isotopic either to the standard embedding $S^1\hookrightarrow\mathbb{R}^2$, or to an embedding with the same image but reversed orientation. For these two embeddings the turning number can be computed directly, and then the claim follows from invariance under isotopy. However, the fact that every such $\gamma$ is isotopic to the unit circle is not so elementary, and so neither is this proof. Any other approach? Any insight regarding turning numbers of simple loops? Anything simpler than the above argument?","To avoid confusion, here are the definitions of the objects in this question: 1) Let $\gamma:S^1\to\mathbb{R}^2\setminus\{0\}$ a smooth loop. The winding number of $\gamma$ is the number of times $\gamma$ encircles $0$. Similarly, if $\gamma:S^1\to\mathbb{R}^2\setminus\{p\}$ for some $p\in\mathbb{R}^2$, the winding number of $\gamma$ around $p$ is the winding number of the translation $\gamma-p$. As we all know, the winding number can be defined rigorously by means of algebraic topology / two-variable calculus / complex variables. 2) Let $\gamma:S^1\to\mathbb{R}^2$ smooth with non-vanishing derivative. The turning number of $\gamma$ is the winding number of $\dot{\gamma}$. My question is about the following Claim: Let $\gamma:S^1\to\mathbb{R}^2$ be a simple loop with non-vanishing derivative. Then the turning number of $\gamma$ is either $1$ or $-1$. Furthermore, for any $p$ in the area enclosed by $\gamma$, the winding number of $\gamma$ around $p$ is equal to the turning number. This claim seems to be rather intuitive, but I can't think of an elementary way to prove it. One way, I guess, is to use the fact that any such loop is isotopic either to the standard embedding $S^1\hookrightarrow\mathbb{R}^2$, or to an embedding with the same image but reversed orientation. For these two embeddings the turning number can be computed directly, and then the claim follows from invariance under isotopy. However, the fact that every such $\gamma$ is isotopic to the unit circle is not so elementary, and so neither is this proof. Any other approach? Any insight regarding turning numbers of simple loops? Anything simpler than the above argument?",,['differential-geometry']
10,Why 'closed differential forms' are called 'closed'?,Why 'closed differential forms' are called 'closed'?,,"As is well known a differential form $ \omega $ is called closed differential form if it satisfies $ \mbox{d} \omega = 0 \, \, (\ast) \, $ where $ \mbox {d} $ is the exterior derivative. I think the terminology, ' closed ' (which we give the differential forms $ \omega $ satisfying the equation $ \, \, (\ast) \; $) refers to something that motivated the definition. The question is as follows. Why 'closed differential forms' are called 'closed' ?","As is well known a differential form $ \omega $ is called closed differential form if it satisfies $ \mbox{d} \omega = 0 \, \, (\ast) \, $ where $ \mbox {d} $ is the exterior derivative. I think the terminology, ' closed ' (which we give the differential forms $ \omega $ satisfying the equation $ \, \, (\ast) \; $) refers to something that motivated the definition. The question is as follows. Why 'closed differential forms' are called 'closed' ?",,"['differential-geometry', 'terminology', 'differential-topology', 'differential-forms']"
11,do Carmo: Second Variation Formula,do Carmo: Second Variation Formula,,"I have some trouble with the derivation of the second variation formula in do Carmo's famous ""Riemannian Geometry"" (p. 197f.). The proposition is the following: 2.8 Proposition Let $(M,\langle\cdot,\cdot\rangle)$ be a Riemannian manifold and let $\gamma:[0,a]\to M$ be a geodesic. Assume that $f:(-\epsilon,\epsilon)\times[0,a]\to M$ is a proper variation of $\gamma$. Let $E:(-\epsilon,\epsilon)\to\mathbb{R}$ be the energy function associated to $f$, i.e.: $$E(s):=\int_{0}^{a}\left\langle\frac{\partial f}{\partial s}(s,t),\frac{\partial f}{\partial s}(s,t)\right\rangle\operatorname{d}\!t$$ Then: $$\frac{1}{2}E''(0)=-\int_{0}^{a}\left\langle V(t),\frac{D^{2}V}{dt}+R\left(\dot{\gamma},V\right)\dot{\gamma}\right\rangle\operatorname{d}\!t-\sum_{i=1}^{k}\left\langle V(t_{i}),\frac{DV}{dt}(t_{i}^{+})-\frac{DV}{dt}(t_{i}^{-})\right\rangle$$ where $R$ is the curvature on $M$ and $V:[0,a]\to TM$ is the variational field given by $V(t):=\frac{\partial f}{\partial s}(0,t)$ - is this well-defined everywhere? - and: $$\frac{DV}{dt}(t_{i}^{+}):=\lim_{t\downarrow t_{i}}\frac{DV}{dt}(t)\quad \frac{DV}{dt}(t_{i}^{-}):=\lim_{t\uparrow t_{i}}\frac{DV}{dt}(t)$$ I know that the proposition still is not well-defined as it is not clear what the $t_{i}$ stand for and so on. Let me start with a few comments on notation: $\frac{D}{dt}$ denotes the covariant derivative along a curve, or if $f:(-\epsilon,\epsilon)\times [0,a]\to M$ is a parametrized surface, then by convention $\frac{D}{\partial t}V(s_{0},t_{0})$ is the covariant derivative of the field $V:(-\epsilon,\epsilon)\times [0,a]\to TM$ along the curve defined by $t\mapsto f(s_{0},t)$ at the point $t_{0}$ and similarly for the operator $\frac{D}{\partial s}$. Now I give you the definition of a variation as it appears in do Carmo's book: Let $c:[0,a]\to M$ be a piecewise differentiable curve. A function $f:(-\epsilon,\epsilon)\times[0,a]\to M$ is a variation of $c$ iff: $f(0,t)=c(t)$ for all $t\in[0,a]$ There exists a partition $0=t_{0}<\cdots<t_{k+1}=a$ such that $f\big|_{(-\epsilon,\epsilon)\times[t_{i},t_{i+1}]}$ is differentiable for all $0\leq i\leq k$. $f$ is a proper variation of $c$ if $f(s,0)=c(0)$ and $f(s,a)=c(a)$ for all $s\in(-\epsilon,\epsilon)$. At the time it is already clear that: $$\frac{1}{2}E'(s)=\sum_{i=0}^{k}\left.\left\langle\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$ and hence differentiation with respect to $s$ yields: $$\frac{1}{2}E''(s)=\sum_{i=0}^{k}\left.\frac{d}{ds}\left\langle\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\frac{d}{ds}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$ Using standard properties of the Levi-Civita connection, this yields: $$\frac{1}{2}E''(s)=\sum_{i=0}^{k}\left.\left\langle\frac{D}{\partial s}\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}+\sum_{i=0}^{k}\left.\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial s}\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\left\langle\frac{D}{\partial s}\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t-\int_{0}^{a}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial s}\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$ So far so good. The issue now is the following: ""Putting $s=0$ in the expression above, we obtain that the first [...] $<$term is$>$ zero, since $f$ is proper and $\gamma$ is a geodesic."" I do not see the reason for this. There are two obvious options: it clearly holds if for all $i$ the map $s\mapsto f(s,t_{i})$ is a geodesic or if $\frac{\partial f}{\partial t}(0,t)\equiv 0$. The latter is false by assumption (somewhere in the beginning of the book: geodesics are by definition non-trivial). The second is a rather strong assumptionand would be mentioned somewhere. A third possibility would be that the map $t\mapsto\frac{D}{\partial s}\frac{\partial f}{\partial s}(s,t)$ is continuous and indeed I assume that this is the case. I do not see why this follows from the definition of a variation. Does anybody have an idea?","I have some trouble with the derivation of the second variation formula in do Carmo's famous ""Riemannian Geometry"" (p. 197f.). The proposition is the following: 2.8 Proposition Let $(M,\langle\cdot,\cdot\rangle)$ be a Riemannian manifold and let $\gamma:[0,a]\to M$ be a geodesic. Assume that $f:(-\epsilon,\epsilon)\times[0,a]\to M$ is a proper variation of $\gamma$. Let $E:(-\epsilon,\epsilon)\to\mathbb{R}$ be the energy function associated to $f$, i.e.: $$E(s):=\int_{0}^{a}\left\langle\frac{\partial f}{\partial s}(s,t),\frac{\partial f}{\partial s}(s,t)\right\rangle\operatorname{d}\!t$$ Then: $$\frac{1}{2}E''(0)=-\int_{0}^{a}\left\langle V(t),\frac{D^{2}V}{dt}+R\left(\dot{\gamma},V\right)\dot{\gamma}\right\rangle\operatorname{d}\!t-\sum_{i=1}^{k}\left\langle V(t_{i}),\frac{DV}{dt}(t_{i}^{+})-\frac{DV}{dt}(t_{i}^{-})\right\rangle$$ where $R$ is the curvature on $M$ and $V:[0,a]\to TM$ is the variational field given by $V(t):=\frac{\partial f}{\partial s}(0,t)$ - is this well-defined everywhere? - and: $$\frac{DV}{dt}(t_{i}^{+}):=\lim_{t\downarrow t_{i}}\frac{DV}{dt}(t)\quad \frac{DV}{dt}(t_{i}^{-}):=\lim_{t\uparrow t_{i}}\frac{DV}{dt}(t)$$ I know that the proposition still is not well-defined as it is not clear what the $t_{i}$ stand for and so on. Let me start with a few comments on notation: $\frac{D}{dt}$ denotes the covariant derivative along a curve, or if $f:(-\epsilon,\epsilon)\times [0,a]\to M$ is a parametrized surface, then by convention $\frac{D}{\partial t}V(s_{0},t_{0})$ is the covariant derivative of the field $V:(-\epsilon,\epsilon)\times [0,a]\to TM$ along the curve defined by $t\mapsto f(s_{0},t)$ at the point $t_{0}$ and similarly for the operator $\frac{D}{\partial s}$. Now I give you the definition of a variation as it appears in do Carmo's book: Let $c:[0,a]\to M$ be a piecewise differentiable curve. A function $f:(-\epsilon,\epsilon)\times[0,a]\to M$ is a variation of $c$ iff: $f(0,t)=c(t)$ for all $t\in[0,a]$ There exists a partition $0=t_{0}<\cdots<t_{k+1}=a$ such that $f\big|_{(-\epsilon,\epsilon)\times[t_{i},t_{i+1}]}$ is differentiable for all $0\leq i\leq k$. $f$ is a proper variation of $c$ if $f(s,0)=c(0)$ and $f(s,a)=c(a)$ for all $s\in(-\epsilon,\epsilon)$. At the time it is already clear that: $$\frac{1}{2}E'(s)=\sum_{i=0}^{k}\left.\left\langle\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$ and hence differentiation with respect to $s$ yields: $$\frac{1}{2}E''(s)=\sum_{i=0}^{k}\left.\frac{d}{ds}\left\langle\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\frac{d}{ds}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$ Using standard properties of the Levi-Civita connection, this yields: $$\frac{1}{2}E''(s)=\sum_{i=0}^{k}\left.\left\langle\frac{D}{\partial s}\frac{\partial f}{\partial s},\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}+\sum_{i=0}^{k}\left.\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial s}\frac{\partial f}{\partial t}\right\rangle\right|_{t_{i}}^{t_{i+1}}-\int_{0}^{a}\left\langle\frac{D}{\partial s}\frac{\partial f}{\partial s},\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t-\int_{0}^{a}\left\langle\frac{\partial f}{\partial s},\frac{D}{\partial s}\frac{D}{\partial t}\frac{\partial f}{\partial t}\right\rangle\operatorname{d}\!t$$ So far so good. The issue now is the following: ""Putting $s=0$ in the expression above, we obtain that the first [...] $<$term is$>$ zero, since $f$ is proper and $\gamma$ is a geodesic."" I do not see the reason for this. There are two obvious options: it clearly holds if for all $i$ the map $s\mapsto f(s,t_{i})$ is a geodesic or if $\frac{\partial f}{\partial t}(0,t)\equiv 0$. The latter is false by assumption (somewhere in the beginning of the book: geodesics are by definition non-trivial). The second is a rather strong assumptionand would be mentioned somewhere. A third possibility would be that the map $t\mapsto\frac{D}{\partial s}\frac{\partial f}{\partial s}(s,t)$ is continuous and indeed I assume that this is the case. I do not see why this follows from the definition of a variation. Does anybody have an idea?",,"['differential-geometry', 'riemannian-geometry']"
12,"An irregular ball rolling on a plane, if know the path on ball surface, how to find the path on the plane?","An irregular ball rolling on a plane, if know the path on ball surface, how to find the path on the plane?",,"An irregular ball has its local radius or curvature different at any surface point. It has pure rolling movement on the plane P. Several questions here: If I know the path curve from A to B on the ball, how to know the path on the plane, and vice versa? If I know the path on the ball is the geodesic from A to B , does it have a simpler solution on the plane? Or the other way, if the path on plane is straight, how is the path on the irregular ball? Is there a situation(for example how the ball have to be, or probably the plane have to be some kind of special curved plane,etc), the problem becomes path independent, that is to say, if I know the destination point B (and start point A) on the ball, I then know the point B on the (special) plane and vice versa. If only specify on the ball the start point A and a tangent direction $\hat{t}_A$ at A, the destination B and a tangent direction $\hat{t}_B$ at point B, meanwhile on the plane the start point A' and a tangent direction $\hat{t}_A'$ at A', the destination B' and a tangent direction $\hat{t}_B'$ at point B', is it possible to find a path on the ball (and the correspondent path on the plane), so that point A and A', point B and B', direction $\hat{t}_A$ and $\hat{t}_A'$ ,direction $\hat{t}_B$ and $\hat{t}_B'$ coincide, respectively? Thanks!","An irregular ball has its local radius or curvature different at any surface point. It has pure rolling movement on the plane P. Several questions here: If I know the path curve from A to B on the ball, how to know the path on the plane, and vice versa? If I know the path on the ball is the geodesic from A to B , does it have a simpler solution on the plane? Or the other way, if the path on plane is straight, how is the path on the irregular ball? Is there a situation(for example how the ball have to be, or probably the plane have to be some kind of special curved plane,etc), the problem becomes path independent, that is to say, if I know the destination point B (and start point A) on the ball, I then know the point B on the (special) plane and vice versa. If only specify on the ball the start point A and a tangent direction at A, the destination B and a tangent direction at point B, meanwhile on the plane the start point A' and a tangent direction at A', the destination B' and a tangent direction at point B', is it possible to find a path on the ball (and the correspondent path on the plane), so that point A and A', point B and B', direction and ,direction and coincide, respectively? Thanks!",\hat{t}_A \hat{t}_B \hat{t}_A' \hat{t}_B' \hat{t}_A \hat{t}_A' \hat{t}_B \hat{t}_B',['differential-geometry']
13,Generalizing results on dynamical systems on $\mathbb{R}^n$ to results on general manifolds,Generalizing results on dynamical systems on  to results on general manifolds,\mathbb{R}^n,"I am trying to self-learn dynamical systems but I am having the following problem: most books, especially introductory texts, all results are given as results about dynamical systems defined by evolution functions $f: \mathbb{R}^n \rightarrow \mathbb{R}^n $. To what degree can I expect these results to generalize to dynamical systems on manifolds given by $f: M \rightarrow TM$ and is there anything in particular I should be ""careful"" about. Maybe to make the situation a little more specific here are some theorems I have thought about in particular: 1) Smales result that the (un)stable invariant manifold of a hyperbolic fixed point is an injective immersion of the (un)stable tangent space. Is there an analogy for manifolds? How would such a thing work on compact manifolds? It implies that there is some canonical way to map a subspace of the tangent space into a immersed submanifold, this should require extra structure on the manifold. Is it obvious where this comes from? 2) Shadowing lemmas For these clearly we need a metric on the manifold. Again, is there an obvious way to choose this? What if we have a hamiltonian system defined by a symplectic form, there is no ""natural"" way to define length, so how should I think about these things? I would appreciate any help or perhaps even a recommended resource which will help me with these embarrassingly easy questions.","I am trying to self-learn dynamical systems but I am having the following problem: most books, especially introductory texts, all results are given as results about dynamical systems defined by evolution functions $f: \mathbb{R}^n \rightarrow \mathbb{R}^n $. To what degree can I expect these results to generalize to dynamical systems on manifolds given by $f: M \rightarrow TM$ and is there anything in particular I should be ""careful"" about. Maybe to make the situation a little more specific here are some theorems I have thought about in particular: 1) Smales result that the (un)stable invariant manifold of a hyperbolic fixed point is an injective immersion of the (un)stable tangent space. Is there an analogy for manifolds? How would such a thing work on compact manifolds? It implies that there is some canonical way to map a subspace of the tangent space into a immersed submanifold, this should require extra structure on the manifold. Is it obvious where this comes from? 2) Shadowing lemmas For these clearly we need a metric on the manifold. Again, is there an obvious way to choose this? What if we have a hamiltonian system defined by a symplectic form, there is no ""natural"" way to define length, so how should I think about these things? I would appreciate any help or perhaps even a recommended resource which will help me with these embarrassingly easy questions.",,"['differential-geometry', 'dynamical-systems', 'symplectic-geometry', 'hamilton-equations']"
14,"Integral $(1, 1)$ forms and holomorphic line bundles",Integral  forms and holomorphic line bundles,"(1, 1)","Let $X$ be a complex manifold. We say that a cohomology class in $H^2(X,\mathbb{C})$ is integral if it lies in the image of the natural morphism $j : H^2(X,\mathbb{Z}) \longrightarrow H^2(X,\mathbb{C})$. Define the first Chern class of a holomorphic line bundle $L \in \text{Pic}(X)$ on $X$ as the image of $L$ under the boundary map $c_1: \text{Pic}(X) \cong H^1(X,\mathcal{O}^*_X) \longrightarrow H^2(X,\mathbb{Z})$. Question : Given a $d$-closed differential form $\omega$ of type $(1,1)$ on $X$ with integral class $[\omega] \in H^2(X,\mathbb{C})$, does it follow automatically that there exists a holomorphic line bundle $L \in \text{Pic}(X)$ such that the image of $c_1(L)$ under $j$ is equal to $[\omega]$, up to some $2\pi i$ factor or so? I would like an answer without assuming that $X$ is compact Kähler, so that Lefschetz's theorem on $(1,1)$ classes does not apply. Also, in case the answer is positive, can anyone point out a reference?","Let $X$ be a complex manifold. We say that a cohomology class in $H^2(X,\mathbb{C})$ is integral if it lies in the image of the natural morphism $j : H^2(X,\mathbb{Z}) \longrightarrow H^2(X,\mathbb{C})$. Define the first Chern class of a holomorphic line bundle $L \in \text{Pic}(X)$ on $X$ as the image of $L$ under the boundary map $c_1: \text{Pic}(X) \cong H^1(X,\mathcal{O}^*_X) \longrightarrow H^2(X,\mathbb{Z})$. Question : Given a $d$-closed differential form $\omega$ of type $(1,1)$ on $X$ with integral class $[\omega] \in H^2(X,\mathbb{C})$, does it follow automatically that there exists a holomorphic line bundle $L \in \text{Pic}(X)$ such that the image of $c_1(L)$ under $j$ is equal to $[\omega]$, up to some $2\pi i$ factor or so? I would like an answer without assuming that $X$ is compact Kähler, so that Lefschetz's theorem on $(1,1)$ classes does not apply. Also, in case the answer is positive, can anyone point out a reference?",,"['algebraic-geometry', 'differential-geometry', 'complex-geometry']"
15,Proof of holomorphic Lefschetz fixed point formula using currents in Griffiths and Harris,Proof of holomorphic Lefschetz fixed point formula using currents in Griffiths and Harris,,"I am trying to understand the proof of the Holomorphic Lefschetz fixed point formula on page 426 in Griffiths and Harris.  However, I find their use of currents extremely confusing.  They seem to go back and forth between currents and forms without a thought, which is confusing to me as I don't know much about currents. Definitions: given a manifold $M$ and a smooth $p$-form $\phi$, the current induced by $\phi$ is the linear functional $T_\phi:\Omega^{n-p}_c(M)\to\mathbb{R}$ given by $T_\phi(\omega)=\int_M\phi\wedge\omega$.  Here $\Omega^{n-p}_c(M)$ denotes compactly supported smooth $(n-p)$-forms.  A current $T$ restricts to an open subset $U$ by extending a compactly supported form $\omega$ on $U$ by $0$ and then applying $T$.  In my case I am interested in complex currents, which are defined analagously with respect to Dolbeault cohomology. As best as I can tell, the situation is that we have we have a compact manifold $M$ of dimension $n$, a compact submanifold $A$ of dimension $k$, and smooth currents $T_\phi$ and $T_\psi$ where $\phi$ and $\psi$ are closed smooth $k$-forms on $M$.  It seems they are implicitly using that if $T_\phi$ restricted to a coordinate neighborhood $U$ of $M$ is zero, then $\int_A\phi=\int_{A-U}\phi$, and further if $T_\phi=T_\psi$ on an open set $W$ such that $A - U \subset W$ then $\int_{A-U}\phi=\int_{A-U}\psi$. Do the statements above make sense?  Are they true? Or do Griffiths and Harris mean something else?  (Note I have used somewhat different notation than they used to not clutter this question.  ) BOUNTY:  I'm setting a bounty for someone who can give a satisfactory explanation as to why, in the notation of the book, $$\int_{\Gamma_f}\phi=-\int_{\Gamma_f-\cup B_\epsilon(p_\alpha,p_\alpha)} \bar\partial k$$ This could mean proving or giving a reference to the two statements I stated above, of if those statements are not correct, then proving the above equality using the information given on page 426. UPDATE:  It seems that Poincare duality for noncompact manifolds implies by the hypotheses that on $U$, $\phi=0$ up to an exact form, and on $W$, $\phi=\psi$ up to an exact form.  However, $A-U$ will have boundary.  So I still haven't solved the problem.","I am trying to understand the proof of the Holomorphic Lefschetz fixed point formula on page 426 in Griffiths and Harris.  However, I find their use of currents extremely confusing.  They seem to go back and forth between currents and forms without a thought, which is confusing to me as I don't know much about currents. Definitions: given a manifold $M$ and a smooth $p$-form $\phi$, the current induced by $\phi$ is the linear functional $T_\phi:\Omega^{n-p}_c(M)\to\mathbb{R}$ given by $T_\phi(\omega)=\int_M\phi\wedge\omega$.  Here $\Omega^{n-p}_c(M)$ denotes compactly supported smooth $(n-p)$-forms.  A current $T$ restricts to an open subset $U$ by extending a compactly supported form $\omega$ on $U$ by $0$ and then applying $T$.  In my case I am interested in complex currents, which are defined analagously with respect to Dolbeault cohomology. As best as I can tell, the situation is that we have we have a compact manifold $M$ of dimension $n$, a compact submanifold $A$ of dimension $k$, and smooth currents $T_\phi$ and $T_\psi$ where $\phi$ and $\psi$ are closed smooth $k$-forms on $M$.  It seems they are implicitly using that if $T_\phi$ restricted to a coordinate neighborhood $U$ of $M$ is zero, then $\int_A\phi=\int_{A-U}\phi$, and further if $T_\phi=T_\psi$ on an open set $W$ such that $A - U \subset W$ then $\int_{A-U}\phi=\int_{A-U}\psi$. Do the statements above make sense?  Are they true? Or do Griffiths and Harris mean something else?  (Note I have used somewhat different notation than they used to not clutter this question.  ) BOUNTY:  I'm setting a bounty for someone who can give a satisfactory explanation as to why, in the notation of the book, $$\int_{\Gamma_f}\phi=-\int_{\Gamma_f-\cup B_\epsilon(p_\alpha,p_\alpha)} \bar\partial k$$ This could mean proving or giving a reference to the two statements I stated above, of if those statements are not correct, then proving the above equality using the information given on page 426. UPDATE:  It seems that Poincare duality for noncompact manifolds implies by the hypotheses that on $U$, $\phi=0$ up to an exact form, and on $W$, $\phi=\psi$ up to an exact form.  However, $A-U$ will have boundary.  So I still haven't solved the problem.",,"['differential-geometry', 'complex-geometry', 'differential-forms']"
16,The shape of a candle flame,The shape of a candle flame,,"Has anyone worked out a physically justified equation (perhaps parametrized) for the characteristic  (2D outline) shape of a candle flame? Just one half suffices, as it is clearly symmetric about a vertical (in the absence of wind). (Image from this link .) Motivation: To make realistic candle flames in computer graphics. We recognize the shape when we see it. And when it is not quite right, we notice the discrepancy. I want to get it right.","Has anyone worked out a physically justified equation (perhaps parametrized) for the characteristic  (2D outline) shape of a candle flame? Just one half suffices, as it is clearly symmetric about a vertical (in the absence of wind). (Image from this link .) Motivation: To make realistic candle flames in computer graphics. We recognize the shape when we see it. And when it is not quite right, we notice the discrepancy. I want to get it right.",,"['differential-geometry', 'mathematical-physics', 'parametrization']"
17,Developing intuition in algebraic geometry through differential geometry?,Developing intuition in algebraic geometry through differential geometry?,,"I'm interested in algebraic geometry (I'm working through Ravi Vakil's notes and also have worked with curves and general varieties in the past), and I have seen some basic definitions from differential geometry, e.g. vector bundles, (co)tangent spaces, differential forms. However, I don't have great intuition for such objects and as a result I feel a bit hindered as far as developing good geometric intuition in AG. Are there any suggestions as to resources I can look at for efficiently gaining a solidly intuitive, but not necessarily deep, understanding of differential geometry specifically for the purpose of motivating related ideas in algebraic geometry? Or, perhaps, is it essential that I learn differential geometry as thoroughly as I can before trying to study algebraic geometry seriously?","I'm interested in algebraic geometry (I'm working through Ravi Vakil's notes and also have worked with curves and general varieties in the past), and I have seen some basic definitions from differential geometry, e.g. vector bundles, (co)tangent spaces, differential forms. However, I don't have great intuition for such objects and as a result I feel a bit hindered as far as developing good geometric intuition in AG. Are there any suggestions as to resources I can look at for efficiently gaining a solidly intuitive, but not necessarily deep, understanding of differential geometry specifically for the purpose of motivating related ideas in algebraic geometry? Or, perhaps, is it essential that I learn differential geometry as thoroughly as I can before trying to study algebraic geometry seriously?",,"['algebraic-geometry', 'differential-geometry', 'reference-request', 'intuition']"
18,show that $\omega$ is exact if and only if the integral of $\omega$ over every $p$-cycle is $0$,show that  is exact if and only if the integral of  over every -cycle is,\omega \omega p 0,"Let $M$ be an oriented smooth manifold and $\omega$ a closed $p$-form on $M$. Show that $\omega$ is exact if and only if the integral of $\omega$ over every $p$-cycle is $0$. In particular, how to prove that if the integral of $\omega$ over every $p$-cycle is $0$, then  $\omega$ is exact?","Let $M$ be an oriented smooth manifold and $\omega$ a closed $p$-form on $M$. Show that $\omega$ is exact if and only if the integral of $\omega$ over every $p$-cycle is $0$. In particular, how to prove that if the integral of $\omega$ over every $p$-cycle is $0$, then  $\omega$ is exact?",,"['differential-geometry', 'differential-topology', 'differential-forms', 'de-rham-cohomology']"
19,Car movement - differential geometry interpretation,Car movement - differential geometry interpretation,,"The problem presented below is from my differential geometry course. The initial reference is Nelson, Tensor Analysis 1967. The car is modelled as follows: Denote by $C(x,y)$ the center of the back wheel line, $\theta$ the angle of the direction of the car with the horizontal direction, $\phi$ the angle made by the front wheels with the direction of the car and $L$ the length of the car. The possible movements of the car are denoted as follows: steering: $S=\displaystyle\frac{\partial}{\partial \phi}$; drive: $D=\displaystyle\cos \theta \frac{\partial}{\partial x}+\sin\theta \frac{\partial}{\partial y}+\frac{\tan \phi}{L}\frac{\partial}{\partial \theta}$; rotation: $R=[S,D]=\displaystyle\frac{1}{L\cos^2 \phi}\frac{\partial }{\partial \theta}$; translation: $T=[R,D]=\displaystyle\frac{\cos \theta}{L\cos^2 \phi}\frac{\partial}{\partial y}-\frac{\sin\theta}{L\cos^2\phi}\frac{\partial}{\partial x}$ Where $[X,Y]=XY-YX$ (I can't remember the English word now). All these transformations seem very logical. My question is: How can we justify the mathematical interpretation made above, especially the part with the rotations and translations? The interpretations are quite interesting: from the expression of $D$, when the car is shorter, you can change the orientation of the car very easily, but when it is longer, like a truck, you it is not that easy ( see the term with $\frac{\partial}{\partial \theta}$) the rotation is faster for smaller cars, and for greater steering angle translation is easier for smaller cars.","The problem presented below is from my differential geometry course. The initial reference is Nelson, Tensor Analysis 1967. The car is modelled as follows: Denote by $C(x,y)$ the center of the back wheel line, $\theta$ the angle of the direction of the car with the horizontal direction, $\phi$ the angle made by the front wheels with the direction of the car and $L$ the length of the car. The possible movements of the car are denoted as follows: steering: $S=\displaystyle\frac{\partial}{\partial \phi}$; drive: $D=\displaystyle\cos \theta \frac{\partial}{\partial x}+\sin\theta \frac{\partial}{\partial y}+\frac{\tan \phi}{L}\frac{\partial}{\partial \theta}$; rotation: $R=[S,D]=\displaystyle\frac{1}{L\cos^2 \phi}\frac{\partial }{\partial \theta}$; translation: $T=[R,D]=\displaystyle\frac{\cos \theta}{L\cos^2 \phi}\frac{\partial}{\partial y}-\frac{\sin\theta}{L\cos^2\phi}\frac{\partial}{\partial x}$ Where $[X,Y]=XY-YX$ (I can't remember the English word now). All these transformations seem very logical. My question is: How can we justify the mathematical interpretation made above, especially the part with the rotations and translations? The interpretations are quite interesting: from the expression of $D$, when the car is shorter, you can change the orientation of the car very easily, but when it is longer, like a truck, you it is not that easy ( see the term with $\frac{\partial}{\partial \theta}$) the rotation is faster for smaller cars, and for greater steering angle translation is easier for smaller cars.",,"['differential-geometry', 'classical-mechanics']"
20,Does Hodge-star commute with metric connections?,Does Hodge-star commute with metric connections?,,"Let $E $ be a smooth oriented vector bundle over a manifold $M$ . Suppose $E$ is equipped with a metric $\eta$ , and a compatible connection $\nabla$ . Denote the dimension of $E$ 's fibers by $d$ . Let $\Lambda_k(E)$ denote the exterior algebra bundle of $E$ of degree $k$ . The orientation and metric on $E$ induce a Hodge-star operator: $ \star_k:\Lambda_k(E) \to \Lambda_{d-k}(E)$ . $\nabla$ induce a connection on $\Lambda_k(E)$ (which we also denote by $\nabla$ ). Note that this induced connection is compatible with the metric on $\Lambda_k(E)$ by $\eta$ . Question: Does $\star,\nabla$ commute? i.e, is it true that $ \star_k (\nabla_X  \beta)=\nabla_X (\star_k \beta)$ for every $\beta \in \Lambda_k(E),X \in \Gamma(TM)$ ? It can be shown that the answer is positive if and only if $\nabla_X (\star_0 1)=0$ (for every $X \in \Gamma(TM)$ ): Step I: We reduce the assertion to the case $k=0$ (see details below). Step II: Further reduction to $\nabla_X (\star_0 1)=0$ : I think I can verify $\nabla_X (\star_0 1)=0$ in the case where $\nabla$ is flat (See step III below). However, I am interested in the general case. Proof of Step II: Let $\beta \in  \Lambda_0(E)=C^{\infty}(M)$ . $$ (1) \, \, \star_0 (\nabla_X  \beta)=\star_0 \big((\nabla_X  \beta) \cdot 1\big) = (\nabla_X  \beta) \cdot (\star_0 1) $$ Also, $$ (2) \, \, \nabla_X (\star_0 \beta)= \nabla_X (\star_0 (\beta \cdot 1))=\nabla_X \big(\beta \cdot (\star_0   1)\big)=(\nabla_X \beta) \cdot (\star_0 1 )+ \beta \cdot \nabla _X (\star_0 1),$$ so by equations $(1),(2)$ above, $\star_0 (\nabla_X  \beta)=\nabla_X (\star_0 \beta)$ ,  if and only if $\nabla_X (\star_0 1)=0$ . Proof of the reduction to the case $k=0$ (Step I): Recall the Hodge-star is defined via $$ \star_0 \langle v,w \rangle= w \wedge \star_k v$$ for every $v,w \in \Lambda_k(E)$ . Let $v,w \in \Lambda_k(E)$ . Then, $$ (1)  \, \,\nabla_X (v \wedge \star_k w)=\nabla_X v \wedge \star_k w+ v \wedge \nabla_X(\star_k w)=\star_0  \langle \nabla_X v,w \rangle+v \wedge \nabla_X(\star_k w)$$ Moreover, $$ (2) \, \, \nabla_X (v \wedge \star_k w)=\nabla_X (\star_0 \langle v,w \rangle) \stackrel{(*)}{=} \star_0 \big(\nabla_X  \langle v,w \rangle\big)=\star_0 \big(  \langle \nabla_X v,w \rangle+  \langle v, \nabla_X w \rangle\big)=$$ $$ \star_0  \langle \nabla_X v,w \rangle + \star_0 \langle v, \nabla_X w \rangle$$ Where equality $(*)$ is exactly the statement for $k=0$ . Equalities $(1),(2)$ imply: $$  v \wedge \nabla_X(\star_k w)=\star_0 \langle v, \nabla_X w \rangle=v \wedge \star_k (\nabla_X w).$$ The uniqueness of the Hodge_star imply $\nabla_X(\star_k w) =  \star_k (\nabla_X w)$ . Proof of step III: $\nabla$ is flat $\Rightarrow$ $\nabla_X (\star_0 1)=0$ . We can work locally: Since $\nabla$ is flat, parallel transport is path-independent (see here ), so we can build a positively-oriented parallel orthonormal frame for $E$ over a small enough neighbourhood around each point in $M$ . Given such frame $E_i$ , we have $\nabla_X E_i=0$ . Thus, $$ \nabla_X (\star_0 1)=\nabla_X (E_1 \wedge \dots \wedge E_d )=\sum_i E_1 \wedge \dots \wedge \nabla_X E_i \wedge \dots \wedge E_d=0.$$","Let be a smooth oriented vector bundle over a manifold . Suppose is equipped with a metric , and a compatible connection . Denote the dimension of 's fibers by . Let denote the exterior algebra bundle of of degree . The orientation and metric on induce a Hodge-star operator: . induce a connection on (which we also denote by ). Note that this induced connection is compatible with the metric on by . Question: Does commute? i.e, is it true that for every ? It can be shown that the answer is positive if and only if (for every ): Step I: We reduce the assertion to the case (see details below). Step II: Further reduction to : I think I can verify in the case where is flat (See step III below). However, I am interested in the general case. Proof of Step II: Let . Also, so by equations above, ,  if and only if . Proof of the reduction to the case (Step I): Recall the Hodge-star is defined via for every . Let . Then, Moreover, Where equality is exactly the statement for . Equalities imply: The uniqueness of the Hodge_star imply . Proof of step III: is flat . We can work locally: Since is flat, parallel transport is path-independent (see here ), so we can build a positively-oriented parallel orthonormal frame for over a small enough neighbourhood around each point in . Given such frame , we have . Thus,","E  M E \eta \nabla E d \Lambda_k(E) E k E  \star_k:\Lambda_k(E) \to \Lambda_{d-k}(E) \nabla \Lambda_k(E) \nabla \Lambda_k(E) \eta \star,\nabla  \star_k (\nabla_X  \beta)=\nabla_X (\star_k \beta) \beta \in \Lambda_k(E),X \in \Gamma(TM) \nabla_X (\star_0 1)=0 X \in \Gamma(TM) k=0 \nabla_X (\star_0 1)=0 \nabla_X (\star_0 1)=0 \nabla \beta \in  \Lambda_0(E)=C^{\infty}(M)  (1) \, \, \star_0 (\nabla_X  \beta)=\star_0 \big((\nabla_X  \beta) \cdot 1\big) = (\nabla_X  \beta) \cdot (\star_0 1)   (2) \, \, \nabla_X (\star_0 \beta)= \nabla_X (\star_0 (\beta \cdot 1))=\nabla_X \big(\beta \cdot (\star_0   1)\big)=(\nabla_X \beta) \cdot (\star_0 1 )+ \beta \cdot \nabla _X (\star_0 1), (1),(2) \star_0 (\nabla_X  \beta)=\nabla_X (\star_0 \beta) \nabla_X (\star_0 1)=0 k=0  \star_0 \langle v,w \rangle= w \wedge \star_k v v,w \in \Lambda_k(E) v,w \in \Lambda_k(E)  (1)  \, \,\nabla_X (v \wedge \star_k w)=\nabla_X v \wedge \star_k w+ v \wedge \nabla_X(\star_k w)=\star_0  \langle \nabla_X v,w \rangle+v \wedge \nabla_X(\star_k w)  (2) \, \, \nabla_X (v \wedge \star_k w)=\nabla_X (\star_0 \langle v,w \rangle) \stackrel{(*)}{=} \star_0 \big(\nabla_X  \langle v,w \rangle\big)=\star_0 \big(  \langle \nabla_X v,w \rangle+  \langle v, \nabla_X w \rangle\big)=  \star_0  \langle \nabla_X v,w \rangle + \star_0 \langle v, \nabla_X w \rangle (*) k=0 (1),(2)   v \wedge \nabla_X(\star_k w)=\star_0 \langle v, \nabla_X w \rangle=v \wedge \star_k (\nabla_X w). \nabla_X(\star_k w) =  \star_k (\nabla_X w) \nabla \Rightarrow \nabla_X (\star_0 1)=0 \nabla E M E_i \nabla_X E_i=0  \nabla_X (\star_0 1)=\nabla_X (E_1 \wedge \dots \wedge E_d )=\sum_i E_1 \wedge \dots \wedge \nabla_X E_i \wedge \dots \wedge E_d=0.","['differential-geometry', 'riemannian-geometry', 'vector-bundles', 'connections']"
21,Prerequisites for studying Perelman's proof of the Geometrization Conjecture,Prerequisites for studying Perelman's proof of the Geometrization Conjecture,,"I want to set a course toward understanding Perelman's proof of the Geometrization Conjecture. I realize this will be a lengthy undertaking, but hopefully only on the order of one to two years. I am currently studying John Lee's Introduction to Smooth Manifolds and Steven Weintraub's Fundamentals of Algebraic Topology . I will be taking a graduate course on 4-manifolds next semester. Could you please suggest (1) which subject areas I should study toward this eventual goal and (2) any texts you particularly like?","I want to set a course toward understanding Perelman's proof of the Geometrization Conjecture. I realize this will be a lengthy undertaking, but hopefully only on the order of one to two years. I am currently studying John Lee's Introduction to Smooth Manifolds and Steven Weintraub's Fundamentals of Algebraic Topology . I will be taking a graduate course on 4-manifolds next semester. Could you please suggest (1) which subject areas I should study toward this eventual goal and (2) any texts you particularly like?",,"['differential-geometry', 'algebraic-topology', 'geometric-topology', 'low-dimensional-topology']"
22,Newton iteration on Riemannian manifolds,Newton iteration on Riemannian manifolds,,"Suppose $f:M \to N$ is a smooth map between complete Riemannian manifolds of the same dimension. Suppose $Df(m_0)$ is invertible, and $n$ is a point close to $f(m_0)$. Can we perform Newton iteration to find a point $m^*$ mapping to $n$ as we do in the proof of the Inverse Function Theorem, by taking $m_{i+1} = \exp_{m_i} \circ (Df_{m_i})^{-1} \circ \log_{f(m_i)}(n)$? Hopefully we would expect this to converge to a point mapping to $n$ if $n$ is chosen close enough to $f(m_0)$. My apologies if this is nonsense; I'm still learning about Riemannian manifolds, $\log$, $\exp$, etc.","Suppose $f:M \to N$ is a smooth map between complete Riemannian manifolds of the same dimension. Suppose $Df(m_0)$ is invertible, and $n$ is a point close to $f(m_0)$. Can we perform Newton iteration to find a point $m^*$ mapping to $n$ as we do in the proof of the Inverse Function Theorem, by taking $m_{i+1} = \exp_{m_i} \circ (Df_{m_i})^{-1} \circ \log_{f(m_i)}(n)$? Hopefully we would expect this to converge to a point mapping to $n$ if $n$ is chosen close enough to $f(m_0)$. My apologies if this is nonsense; I'm still learning about Riemannian manifolds, $\log$, $\exp$, etc.",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
23,Why is the manifold structure on the tangent bundle unique?,Why is the manifold structure on the tangent bundle unique?,,"...subject to the conditions that (i) the projection be smooth and that (ii) smooth sections correspond to smooth vector fields. This homework problem is really bugging the hell out of me.  Of course it can be checked locally, so we'll look at an open neighborhood $U\in \mathbb{R}^n$ and check that $TU\cong U\times \mathbb{R}^n$ (where the isomorphism is as topological spaces with sheaves of functions that we declare to be smooth).  On the one hand, it's easy to see that $U \times \mathbb{R}^n$ satisfies these two conditions, since the projection is literally just a projection (in coordinates) and the correspondence is $X$ a vector field --> $s = (x_1,\ldots, x_n, X(\partial/\partial x_1), \ldots, X(\partial/\partial x_n))$ $s=(s_1,\ldots, s_n)$ a smooth section --> $X = \sum_i s_i\cdot\partial/\partial x_i $. On the other hand, I'm having a lot of trouble showing that the obvious sheaf (which I'll denote $O_{TU}$) is the unique one with properties (i) and (ii). For example, suppose $\mathcal{F}$ is another sheaf of functions on $U\times \mathbb{R}^n$.  Suppose that $f \in \mathcal{F}(V) \backslash \mathcal{O}_{TU}$ for some open set $V\subseteq U$.  There really doesn't seem to be any way to show that this violates property (i), because what it really means is that for any $g\in O_U$, $g \circ \pi \in O_{TU}$, and the hypothesis of this statement begins with a function on $U$, not $TU$.  On the other hand, I don't see any way to make a vector field on $U$ out of $f$, and (according to this question ) it feels likely that I can't necessarily get a section that detects the failure of $f$ to be $O_{TU}$-smooth.  Nor am I having much luck deriving a contradiction from $f \in O_{TU}(V) \backslash \mathcal{F}(V)$. So, I'd welcome any suggestions as to how I should proceed.","...subject to the conditions that (i) the projection be smooth and that (ii) smooth sections correspond to smooth vector fields. This homework problem is really bugging the hell out of me.  Of course it can be checked locally, so we'll look at an open neighborhood $U\in \mathbb{R}^n$ and check that $TU\cong U\times \mathbb{R}^n$ (where the isomorphism is as topological spaces with sheaves of functions that we declare to be smooth).  On the one hand, it's easy to see that $U \times \mathbb{R}^n$ satisfies these two conditions, since the projection is literally just a projection (in coordinates) and the correspondence is $X$ a vector field --> $s = (x_1,\ldots, x_n, X(\partial/\partial x_1), \ldots, X(\partial/\partial x_n))$ $s=(s_1,\ldots, s_n)$ a smooth section --> $X = \sum_i s_i\cdot\partial/\partial x_i $. On the other hand, I'm having a lot of trouble showing that the obvious sheaf (which I'll denote $O_{TU}$) is the unique one with properties (i) and (ii). For example, suppose $\mathcal{F}$ is another sheaf of functions on $U\times \mathbb{R}^n$.  Suppose that $f \in \mathcal{F}(V) \backslash \mathcal{O}_{TU}$ for some open set $V\subseteq U$.  There really doesn't seem to be any way to show that this violates property (i), because what it really means is that for any $g\in O_U$, $g \circ \pi \in O_{TU}$, and the hypothesis of this statement begins with a function on $U$, not $TU$.  On the other hand, I don't see any way to make a vector field on $U$ out of $f$, and (according to this question ) it feels likely that I can't necessarily get a section that detects the failure of $f$ to be $O_{TU}$-smooth.  Nor am I having much luck deriving a contradiction from $f \in O_{TU}(V) \backslash \mathcal{F}(V)$. So, I'd welcome any suggestions as to how I should proceed.",,['differential-geometry']
24,Local systems defined by higher homotopy groups,Local systems defined by higher homotopy groups,,"I should mention I have very little background in algebraic topology and don't really know much about homotopy groups besides the definition. I am aware that for a topological space $X$ and a point $x \in X$ the fundamental group $\pi_1(X,x)$ acts on all homotopy groups $\pi_n(X,x)$ . In particular, this means the $\mathbf{Q}$ -vector space $\mathbf{Q} \otimes_\mathbf{Z}\pi_n(X,x)$ is endowed with a linear action by $\pi_1(X,x)$ and hence defines a local system of $\mathbf{Q}$ -vector spaces on $X$ . If $X$ is a (complex) manifold or something and one can appeal to tools akin to the Riemann-Hilbert correspondence and other interpretations of these objects, can one describe these explicitly? Are they 'tautological' local systems in some sense... ? Can anything be said about the family of local systems $(\mathbf{Q}\otimes_\mathbf{Z}\pi_n(X,x))_{n \geq 2}$ and can these be recognised as something else? I'm not sure my question makes much sense and I was just trying to satiate a curiosity :) Any words of wisdom are appreciated and thank you very much! :D Edit: moved to MO","I should mention I have very little background in algebraic topology and don't really know much about homotopy groups besides the definition. I am aware that for a topological space and a point the fundamental group acts on all homotopy groups . In particular, this means the -vector space is endowed with a linear action by and hence defines a local system of -vector spaces on . If is a (complex) manifold or something and one can appeal to tools akin to the Riemann-Hilbert correspondence and other interpretations of these objects, can one describe these explicitly? Are they 'tautological' local systems in some sense... ? Can anything be said about the family of local systems and can these be recognised as something else? I'm not sure my question makes much sense and I was just trying to satiate a curiosity :) Any words of wisdom are appreciated and thank you very much! :D Edit: moved to MO","X x \in X \pi_1(X,x) \pi_n(X,x) \mathbf{Q} \mathbf{Q} \otimes_\mathbf{Z}\pi_n(X,x) \pi_1(X,x) \mathbf{Q} X X (\mathbf{Q}\otimes_\mathbf{Z}\pi_n(X,x))_{n \geq 2}","['differential-geometry', 'algebraic-geometry', 'algebraic-topology', 'complex-geometry']"
25,Every vector bundle has a metric connection?,Every vector bundle has a metric connection?,,"Let $(E,g)$ be a vector bundle with a metric over a manifold $M$. Does $(E,g)$ always admit a compatible (metric) connection? If so, are there examples where there exists only one such metric connection?","Let $(E,g)$ be a vector bundle with a metric over a manifold $M$. Does $(E,g)$ always admit a compatible (metric) connection? If so, are there examples where there exists only one such metric connection?",,"['differential-geometry', 'vector-bundles', 'connections']"
26,"Intuitively, what does it mean that two charts are compatible?","Intuitively, what does it mean that two charts are compatible?",,"Let $(U, \phi), (V, \psi)$ two charts of the same manifold. We say that two charts are $C^\infty$-compatible if the following two maps $$\phi \circ \psi^{-1} : \psi(U \cap V) \to \phi(U \cap V), \; \psi \circ \phi^{-1} : \phi(U \cap V) \to \psi(U \cap V)$$ are $C^\infty$. Can someone explain me what's the intuitive meaning of charts compatibility?","Let $(U, \phi), (V, \psi)$ two charts of the same manifold. We say that two charts are $C^\infty$-compatible if the following two maps $$\phi \circ \psi^{-1} : \psi(U \cap V) \to \phi(U \cap V), \; \psi \circ \phi^{-1} : \phi(U \cap V) \to \psi(U \cap V)$$ are $C^\infty$. Can someone explain me what's the intuitive meaning of charts compatibility?",,"['differential-geometry', 'manifolds']"
27,Is the surface of a sphere and a crayon the same manifold?,Is the surface of a sphere and a crayon the same manifold?,,"In Schutz, Geometrical Methods of Mathematical Physics book, pg. 29, it was said that the sphere $S^2$ and the surface of a crayon has the same global structure: I also read that two spaces are the 'same' as manifolds if they are diffeomorphic. But I find it hard to visualise that these two surfaces have the same global structure. They clearly look very different in 3D space. What exactly does global structure mean?","In Schutz, Geometrical Methods of Mathematical Physics book, pg. 29, it was said that the sphere and the surface of a crayon has the same global structure: I also read that two spaces are the 'same' as manifolds if they are diffeomorphic. But I find it hard to visualise that these two surfaces have the same global structure. They clearly look very different in 3D space. What exactly does global structure mean?",S^2,['differential-geometry']
28,Reference request: Vector bundles and line bundles etc.,Reference request: Vector bundles and line bundles etc.,,"I am interested in learning algebraic geometry and I talked to one of my professors today (who is, in part, an algebraic geometer) and he recommended I understand the analytic analogue of the ideas in algebraic geometry so it's not just abstract nonsense when I first see it. Some of specific words he mentioned were vector bundles and line bundles but he could not give any recommendations on the spot and recommended that I ask here. There are only two sources that I know of which cover these subjects in a way that I think coincide with my relatively modest understanding of mathematics (which I will cover a bit later) are the first part of Hatcher's book on K-theory and Spivak's Comprehensive Introduction to Differential Geometry although the latter will, admittedly, cover much more than I need or could handle at the moment. If there are any more differential geometry concepts of which I should be aware as well, please feel free to include that as well. I am also aware that I will need to know some commutative algebra and complex analysis and I have gotten some solid recommendations on those topics (some from here, in fact). These are the courses I've taken which I think are relevant to recommendations (all courses are undergraduate): algebra, analysis 1/advanced calculus, differential geometry, proof-based linear algebra, and I am familiar with some topology (in that I know what a topological space is and what a fundamental group is. I will definitely study that more over the summer), I did a reading course on algebraic curves covering the first three chapters of Fulton plus the proof of Bézout's theorem, and I have done an almost reading course in geometry/topology so I am aware of what manifolds are and some of the relevant topology.","I am interested in learning algebraic geometry and I talked to one of my professors today (who is, in part, an algebraic geometer) and he recommended I understand the analytic analogue of the ideas in algebraic geometry so it's not just abstract nonsense when I first see it. Some of specific words he mentioned were vector bundles and line bundles but he could not give any recommendations on the spot and recommended that I ask here. There are only two sources that I know of which cover these subjects in a way that I think coincide with my relatively modest understanding of mathematics (which I will cover a bit later) are the first part of Hatcher's book on K-theory and Spivak's Comprehensive Introduction to Differential Geometry although the latter will, admittedly, cover much more than I need or could handle at the moment. If there are any more differential geometry concepts of which I should be aware as well, please feel free to include that as well. I am also aware that I will need to know some commutative algebra and complex analysis and I have gotten some solid recommendations on those topics (some from here, in fact). These are the courses I've taken which I think are relevant to recommendations (all courses are undergraduate): algebra, analysis 1/advanced calculus, differential geometry, proof-based linear algebra, and I am familiar with some topology (in that I know what a topological space is and what a fundamental group is. I will definitely study that more over the summer), I did a reading course on algebraic curves covering the first three chapters of Fulton plus the proof of Bézout's theorem, and I have done an almost reading course in geometry/topology so I am aware of what manifolds are and some of the relevant topology.",,"['reference-request', 'algebraic-geometry', 'differential-geometry']"
29,A question about Killing vector and Riemann curvature tensor,A question about Killing vector and Riemann curvature tensor,,"In Sean Carroll's Spacetime and Geometry , a formula is given as $${\nabla _\mu }{\nabla _\sigma }{K^\rho } = {R^\rho }_{\sigma \mu \nu }{K^\nu },$$ where $K^\mu$ is a Killing vector satisfying Killing's equation ${\nabla _\mu }{K_\nu } +{\nabla _\nu }{K_\mu }=0$ and the convention of Riemann curvature tensor is $$\left[\nabla_{\mu},\nabla_{\nu}\right]V^{\rho}={R^\rho}_{\sigma\mu\nu}V^{\sigma}.$$ So how to prove the this formula (the connection is Levi-Civita)?","In Sean Carroll's Spacetime and Geometry , a formula is given as $${\nabla _\mu }{\nabla _\sigma }{K^\rho } = {R^\rho }_{\sigma \mu \nu }{K^\nu },$$ where $K^\mu$ is a Killing vector satisfying Killing's equation ${\nabla _\mu }{K_\nu } +{\nabla _\nu }{K_\mu }=0$ and the convention of Riemann curvature tensor is $$\left[\nabla_{\mu},\nabla_{\nu}\right]V^{\rho}={R^\rho}_{\sigma\mu\nu}V^{\sigma}.$$ So how to prove the this formula (the connection is Levi-Civita)?",,['differential-geometry']
30,Differential Geometry past an introductory course?,Differential Geometry past an introductory course?,,"I'll be doing an independent study with one of my profs in differential geometry next semester (my university did not happen to offer an intro diff. geometry course next semester like it usually does).  I'll be mainly working out of Barrett O'Neill's book but will also be checking out different perspectives by looking at do Carmo's book (and maybe Spivak's?)  I've been planning out the rest of my semesters and even if I end up taking courses in a wide range of branches in mathematics, I'll still have quite a bit of free credits to delve more deeply into one subject.  If I do choose to go further into differential geometry, what are some important classes to take/books to read?  Books I've looked into so far are Do Carmo's Riemannian Geometry, Barrett O'neill's Semi-Riemannian Geometry, as well as differential topology books like Milnor's topology from a differentiable viewpoint or Lee's introduction to smooth manifolds (I understand these are important for more advanced work in differential geometry?)  What is the recommended order I should learn these subjects in?  Any other suggestions/recommendations? Thanks!","I'll be doing an independent study with one of my profs in differential geometry next semester (my university did not happen to offer an intro diff. geometry course next semester like it usually does).  I'll be mainly working out of Barrett O'Neill's book but will also be checking out different perspectives by looking at do Carmo's book (and maybe Spivak's?)  I've been planning out the rest of my semesters and even if I end up taking courses in a wide range of branches in mathematics, I'll still have quite a bit of free credits to delve more deeply into one subject.  If I do choose to go further into differential geometry, what are some important classes to take/books to read?  Books I've looked into so far are Do Carmo's Riemannian Geometry, Barrett O'neill's Semi-Riemannian Geometry, as well as differential topology books like Milnor's topology from a differentiable viewpoint or Lee's introduction to smooth manifolds (I understand these are important for more advanced work in differential geometry?)  What is the recommended order I should learn these subjects in?  Any other suggestions/recommendations? Thanks!",,"['differential-geometry', 'soft-question', 'advice']"
31,What is $T\mathbb{S}^2$?,What is ?,T\mathbb{S}^2,"I recently learned that the only parallelizable spheres are $\mathbb{S}^1$, $\mathbb{S}^3$, and $\mathbb{S}^7$.  This led me to wonder: What is $T\mathbb{S}^2$?  Is it diffeomorphic to a more familiar space?  What about $T\mathbb{S}^n$ for $n \neq 1, 3, 7$? EDIT (for precision): Is $T\mathbb{S}^2$ diffeomorphic to some finite product, connected sum, and/or quotient of spheres, projective spaces, euclidean spaces, and linear groups?","I recently learned that the only parallelizable spheres are $\mathbb{S}^1$, $\mathbb{S}^3$, and $\mathbb{S}^7$.  This led me to wonder: What is $T\mathbb{S}^2$?  Is it diffeomorphic to a more familiar space?  What about $T\mathbb{S}^n$ for $n \neq 1, 3, 7$? EDIT (for precision): Is $T\mathbb{S}^2$ diffeomorphic to some finite product, connected sum, and/or quotient of spheres, projective spaces, euclidean spaces, and linear groups?",,"['differential-geometry', 'differential-topology']"
32,Shortest path on a sphere,Shortest path on a sphere,,I'm quite a newbie in differential geometry. Calculus is not my cup of tea ; but I find geometrical proofs really beautiful. So I'm looking for a simple - by simple I mean with almost no calculus - proof that the shortest path between two points on a sphere is the arc of the great circle on which they lie. Any hint ? Edit: Or at least a reference ?,I'm quite a newbie in differential geometry. Calculus is not my cup of tea ; but I find geometrical proofs really beautiful. So I'm looking for a simple - by simple I mean with almost no calculus - proof that the shortest path between two points on a sphere is the arc of the great circle on which they lie. Any hint ? Edit: Or at least a reference ?,,['differential-geometry']
33,Is there a minimal graph in $\mathbb{R}^3$ which is not area-minimizing?,Is there a minimal graph in  which is not area-minimizing?,\mathbb{R}^3,"Let $\Omega\subset\mathbb{R}^2$ be an open subset such that $\partial\Omega$ is a closed, simple curve. I'm trying to find an example of an $u:\overline{\Omega}\to\mathbb{R}$ such that $\Sigma:=\text{graph}(u)$ is a minimal surface and, yet, there exists another minimal surface $\Sigma'$ with $\partial\Sigma'=\partial\Sigma$ and $\text{Area}(\Sigma')<\text{Area}(\Sigma)$. Does such an example exist?","Let $\Omega\subset\mathbb{R}^2$ be an open subset such that $\partial\Omega$ is a closed, simple curve. I'm trying to find an example of an $u:\overline{\Omega}\to\mathbb{R}$ such that $\Sigma:=\text{graph}(u)$ is a minimal surface and, yet, there exists another minimal surface $\Sigma'$ with $\partial\Sigma'=\partial\Sigma$ and $\text{Area}(\Sigma')<\text{Area}(\Sigma)$. Does such an example exist?",,"['differential-geometry', 'riemannian-geometry', 'minimal-surfaces', 'calibrated-geometry']"
34,Geodesic of a curved surface,Geodesic of a curved surface,,"I'm trying to read Lambourne's Relativity, Gravitation and Cosmology, but as this seems more of a maths question I've posted it here rather than in the physics forum. The author talks about affinely parameterized geodesics and then, in Exercise 3.9, shows that the equator on the surface of a sphere is a geodesic. My question is this: How do you find the geodesic of a simple curved surface that isn't a sphere (for example, $z = x^2 + y^2$)? I'm guessing that because the geodesic equation contains Christoffel symbols I would first need to find the metric for that particular surface, but I don't know how to do that. I'm therefore guessing that my second question would need to be how do you find the metric for a simple curved surface (again for example $z = x^2 + y^2$). Apologies if I've asked anything ridiculous. Thank you.","I'm trying to read Lambourne's Relativity, Gravitation and Cosmology, but as this seems more of a maths question I've posted it here rather than in the physics forum. The author talks about affinely parameterized geodesics and then, in Exercise 3.9, shows that the equator on the surface of a sphere is a geodesic. My question is this: How do you find the geodesic of a simple curved surface that isn't a sphere (for example, $z = x^2 + y^2$)? I'm guessing that because the geodesic equation contains Christoffel symbols I would first need to find the metric for that particular surface, but I don't know how to do that. I'm therefore guessing that my second question would need to be how do you find the metric for a simple curved surface (again for example $z = x^2 + y^2$). Apologies if I've asked anything ridiculous. Thank you.",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
35,Definition of Maximal atlas,Definition of Maximal atlas,,"I some how could not find the definition of maximal atlas on a manifold. What I see is that an atlas is said to be maximal atlas if it is not contained in any other atlas. What does this containment actually mean? Let $\mathcal{A}$  be an atlas and $\mathcal{B}$ be another atlas. When do we say that $\mathcal{A}$ is contained in $\mathcal{B}$? I was not able to find definition of this. Another confusion is about union of atlases. Let $\mathcal{A}$ and $\mathcal{B}$ be two atlases. What do we mean by union of atlases? Is it just the union $\{(U,\phi)_{\phi\in \mathcal{A}},(V,\psi)_{\psi\in \mathcal{B}}\}$? It may happen that this union is not an atlas i.e., there can be two charts $\phi_\mathcal{A}$ and $\psi_{\mathcal{B}}$such that $\phi_{\mathcal{A}}$ and $\psi_{\mathcal{B}}$    are not compatible. By maximal atlas do I mean an atlas $\mathcal{A}$ such that for any other atlas $\mathcal{B}$, the union as above is not an atlas? Any reference for the definition is welcome.","I some how could not find the definition of maximal atlas on a manifold. What I see is that an atlas is said to be maximal atlas if it is not contained in any other atlas. What does this containment actually mean? Let $\mathcal{A}$  be an atlas and $\mathcal{B}$ be another atlas. When do we say that $\mathcal{A}$ is contained in $\mathcal{B}$? I was not able to find definition of this. Another confusion is about union of atlases. Let $\mathcal{A}$ and $\mathcal{B}$ be two atlases. What do we mean by union of atlases? Is it just the union $\{(U,\phi)_{\phi\in \mathcal{A}},(V,\psi)_{\psi\in \mathcal{B}}\}$? It may happen that this union is not an atlas i.e., there can be two charts $\phi_\mathcal{A}$ and $\psi_{\mathcal{B}}$such that $\phi_{\mathcal{A}}$ and $\psi_{\mathcal{B}}$    are not compatible. By maximal atlas do I mean an atlas $\mathcal{A}$ such that for any other atlas $\mathcal{B}$, the union as above is not an atlas? Any reference for the definition is welcome.",,['differential-geometry']
36,Geodesic curvature of sphere parallels,Geodesic curvature of sphere parallels,,"I want to compute the geodesic curvature of any circle on a sphere (not necessarily a great circle). $$$$ The geodesic curvature is given by the formula $$\kappa_g=\gamma'' \cdot (\textbf{N}\times \gamma ')$$ or $$\kappa_g=\pm \kappa \sin \psi$$  where $\gamma$ is a unit-speed curve of the surface, $\textbf{N}$ is the normal unit of the surface, $\kappa$ is the curvature of $\gamma$ and $\psi$ is the angle between $\textbf{N}$ and the principal normal $n$ of $\gamma$. $$$$ We consider a circle of radius $r$. Could you give me some hints how we could calculate the geodesic curvature? $$$$ EDIT:","I want to compute the geodesic curvature of any circle on a sphere (not necessarily a great circle). $$$$ The geodesic curvature is given by the formula $$\kappa_g=\gamma'' \cdot (\textbf{N}\times \gamma ')$$ or $$\kappa_g=\pm \kappa \sin \psi$$  where $\gamma$ is a unit-speed curve of the surface, $\textbf{N}$ is the normal unit of the surface, $\kappa$ is the curvature of $\gamma$ and $\psi$ is the angle between $\textbf{N}$ and the principal normal $n$ of $\gamma$. $$$$ We consider a circle of radius $r$. Could you give me some hints how we could calculate the geodesic curvature? $$$$ EDIT:",,"['differential-geometry', 'curvature', 'geodesic']"
37,Curvature of a regular curve is a smooth function of parameter if it does not vanish,Curvature of a regular curve is a smooth function of parameter if it does not vanish,,"We have that the curvature of a curve $\gamma (t)$ is given by $K(t)=\|\gamma ''(t)\|$ iff $\|\gamma '(t)\|=1$. If $\|\gamma '(t)\| \neq 1$, then we find the arclength $s(t)=\int_0^t \|\gamma '(u)\|du=g(t)$, then we solve for $t=g^{-1}(s)$. Then we have that $\gamma (s)=\gamma (g^{-1}(s)) \Rightarrow \|\gamma '(s)\|=1$. So we find the curvature by the formula $K(s)=\|\gamma ''(s)\|$. When the curvature of a regular curve $\gamma (t)$ is everywhere $>0$, then show that the curvature is a smooth function of $t$. Could you give me some hints how we could show this?","We have that the curvature of a curve $\gamma (t)$ is given by $K(t)=\|\gamma ''(t)\|$ iff $\|\gamma '(t)\|=1$. If $\|\gamma '(t)\| \neq 1$, then we find the arclength $s(t)=\int_0^t \|\gamma '(u)\|du=g(t)$, then we solve for $t=g^{-1}(s)$. Then we have that $\gamma (s)=\gamma (g^{-1}(s)) \Rightarrow \|\gamma '(s)\|=1$. So we find the curvature by the formula $K(s)=\|\gamma ''(s)\|$. When the curvature of a regular curve $\gamma (t)$ is everywhere $>0$, then show that the curvature is a smooth function of $t$. Could you give me some hints how we could show this?",,"['differential-geometry', 'curves', 'curvature']"
38,A vector field is a section of $T\mathcal{M}$.,A vector field is a section of .,T\mathcal{M},"By definition, a vector field is a section of $T\mathcal{M}$. I am familiar with the concept of vector field, as well as tangent plane of a manifold. But such definition is not intuitive to me at all. Could some one give me some intuition? Thank you very much!","By definition, a vector field is a section of $T\mathcal{M}$. I am familiar with the concept of vector field, as well as tangent plane of a manifold. But such definition is not intuitive to me at all. Could some one give me some intuition? Thank you very much!",,['differential-geometry']
39,Question about orientable manifolds,Question about orientable manifolds,,"Let $M$ be a connected orientable smooth manifold. Is it true that $M$ must have only 2 orientations? If yes, why?","Let $M$ be a connected orientable smooth manifold. Is it true that $M$ must have only 2 orientations? If yes, why?",,['differential-geometry']
40,What is the difference between a Germ and a 1-form,What is the difference between a Germ and a 1-form,,The germ captures the local behaviour of a function at a point of a topological space. I'd like to know how it is different from a 1-form or its relationship with a 1-form. Pardon me if its a naive question in case its too simple please give a link adding a comment.,The germ captures the local behaviour of a function at a point of a topological space. I'd like to know how it is different from a 1-form or its relationship with a 1-form. Pardon me if its a naive question in case its too simple please give a link adding a comment.,,['differential-geometry']
41,"Do ""exotic vectorfields"" exist?","Do ""exotic vectorfields"" exist?",,"By an exotic vectorfield on $\mathbb{R}^n$, I mean a non-zero derivation on the algebra $C^0(\mathbb{R}^n)$. Do such things exist?","By an exotic vectorfield on $\mathbb{R}^n$, I mean a non-zero derivation on the algebra $C^0(\mathbb{R}^n)$. Do such things exist?",,"['differential-geometry', 'examples-counterexamples']"
42,Covariant derivative versus exterior derivative,Covariant derivative versus exterior derivative,,"$\def\alt{\textrm{Alt}} \def\d{\mathrm{d}}  \def\sgn{\mathrm{sgn}\,}$Let $\nabla$ be a symmetric linear connection in $M$, and $\omega$ be a $k$-form in $M$. I'm trying to find a relation between $\d\omega$ and $\nabla \omega$. I follow Spivak's notation in Calculus on Manifolds and write $$\alt(\nabla \omega)(X_1,\cdots,X_{k+1}) = \frac{1}{(k+1)!}\sum_{\sigma \in S_{k+1}} (\sgn \sigma)\nabla\omega(X_{\sigma(1)},\cdots,X_{\sigma(k+1)}).$$I also assume the formula $$\d\omega(X_1,\cdots,X_{k+1})=\sum_{i=1}^k(-1)^{i+1}X_i(\omega(X_1,\cdots,\widehat{X_i},\cdots,X_{k+1})) + \sum_{i<j}(-1)^{i+j}\omega([X_i,X_j],X_1,\cdots,\widehat{X_i},\cdots,\widehat{X_j},\cdots,X_{k+1}).$$I'd expect something like $\alt(\nabla\omega) = \d \omega$, apart from a multiplicative constant, maybe. I'm stuck. For $k=1$ I got $$\alt(\nabla \omega) = -\frac{1}{2}\d \omega.$$The $1/2$ I can accept, but the minus sign puts me off. I tried brute forcing my way through $k=2$ but I guess I just suck at doing computations like this. The best I can come up with is $$\begin{align} (k+1)!\alt(&\nabla\omega)(X_1,\cdots,X_{k+1}) = \sum_{\sigma \in S_{k+1}} (\sgn\sigma) \nabla\omega(X_{\sigma(1)},\cdots,X_{\sigma(k+1)}) \\ &= \sum_{\sigma \in S_{k+1}} (\sgn\sigma) \nabla_{X_{\sigma(k+1)}}\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)}) \\ &= \sum_{\sigma \in S_{k+1}}(\sgn\sigma)\left(X_{\sigma(k+1)}(\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)})) - \sum_{i=1}^n\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)})\right)\\ &= \sum_{\sigma \in S_{k+1}}(\sgn\sigma)X_{\sigma(k+1)}(\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)})) - \sum_{\sigma \in S_{k+1}}\sum_{i=1}^n(\sgn \sigma)\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)}) \\ &\stackrel{\color{red}{(\ast)}}{=} \sum_{\sigma \in S_{k+1}}X_{\sigma(k+1)}(\omega(X_1,\cdots,X_k)) - \sum_{\sigma \in S_{k+1}}\sum_{i=1}^n(\sgn \sigma)\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)})\end{align}$$ and I'm stuck. I'm not sure of the $\color{red}{(\ast)}$ step either. I know that we must use that $\nabla$ is symmetric to get rid of all these $\nabla$ but I don't know how to do this. What is the smart way to do this? This answer is the most similar thing to what I'm trying to do that I found, but I don't find it easy to see such relation, as it is said there. Also, I'd like to avoid coordinate computations if possible. I'll ignore the $\color{red}{(\ast)}$ step since I think it is wrong. I don't know how to write it neatly, but doing it for $k=1$ and $k=2$ suggests $$\sum_{\sigma \in S_{k+1}}(\sgn \sigma)X_{\sigma(k+1)}(\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)})) = (-1)^kk!\sum_{i=1}^k(-1)^iX_i(\omega(X_1,\cdots,\widehat{X_i},\cdots,X_{k+1})).$$Also, it seems that $$\sum_{\sigma \in S_{k+1}}\sum_{i=1}^k(\sgn \sigma)\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)})=(-1)^{k+1}k!\sum_{i<j}(-1)^{i+j}\omega([X_i,X_j],X_1,\cdots,\widehat{X_i},\cdots,\widehat{X_j},\cdots,X_{k+1})$$ So: $$(k+1)! {\rm Alt}(\nabla \omega) = (-1)^kk!{\rm d}\omega \implies (-1)^k(k+1)\alt(\nabla \omega) = {\rm d}\omega.$$","$\def\alt{\textrm{Alt}} \def\d{\mathrm{d}}  \def\sgn{\mathrm{sgn}\,}$Let $\nabla$ be a symmetric linear connection in $M$, and $\omega$ be a $k$-form in $M$. I'm trying to find a relation between $\d\omega$ and $\nabla \omega$. I follow Spivak's notation in Calculus on Manifolds and write $$\alt(\nabla \omega)(X_1,\cdots,X_{k+1}) = \frac{1}{(k+1)!}\sum_{\sigma \in S_{k+1}} (\sgn \sigma)\nabla\omega(X_{\sigma(1)},\cdots,X_{\sigma(k+1)}).$$I also assume the formula $$\d\omega(X_1,\cdots,X_{k+1})=\sum_{i=1}^k(-1)^{i+1}X_i(\omega(X_1,\cdots,\widehat{X_i},\cdots,X_{k+1})) + \sum_{i<j}(-1)^{i+j}\omega([X_i,X_j],X_1,\cdots,\widehat{X_i},\cdots,\widehat{X_j},\cdots,X_{k+1}).$$I'd expect something like $\alt(\nabla\omega) = \d \omega$, apart from a multiplicative constant, maybe. I'm stuck. For $k=1$ I got $$\alt(\nabla \omega) = -\frac{1}{2}\d \omega.$$The $1/2$ I can accept, but the minus sign puts me off. I tried brute forcing my way through $k=2$ but I guess I just suck at doing computations like this. The best I can come up with is $$\begin{align} (k+1)!\alt(&\nabla\omega)(X_1,\cdots,X_{k+1}) = \sum_{\sigma \in S_{k+1}} (\sgn\sigma) \nabla\omega(X_{\sigma(1)},\cdots,X_{\sigma(k+1)}) \\ &= \sum_{\sigma \in S_{k+1}} (\sgn\sigma) \nabla_{X_{\sigma(k+1)}}\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)}) \\ &= \sum_{\sigma \in S_{k+1}}(\sgn\sigma)\left(X_{\sigma(k+1)}(\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)})) - \sum_{i=1}^n\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)})\right)\\ &= \sum_{\sigma \in S_{k+1}}(\sgn\sigma)X_{\sigma(k+1)}(\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)})) - \sum_{\sigma \in S_{k+1}}\sum_{i=1}^n(\sgn \sigma)\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)}) \\ &\stackrel{\color{red}{(\ast)}}{=} \sum_{\sigma \in S_{k+1}}X_{\sigma(k+1)}(\omega(X_1,\cdots,X_k)) - \sum_{\sigma \in S_{k+1}}\sum_{i=1}^n(\sgn \sigma)\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)})\end{align}$$ and I'm stuck. I'm not sure of the $\color{red}{(\ast)}$ step either. I know that we must use that $\nabla$ is symmetric to get rid of all these $\nabla$ but I don't know how to do this. What is the smart way to do this? This answer is the most similar thing to what I'm trying to do that I found, but I don't find it easy to see such relation, as it is said there. Also, I'd like to avoid coordinate computations if possible. I'll ignore the $\color{red}{(\ast)}$ step since I think it is wrong. I don't know how to write it neatly, but doing it for $k=1$ and $k=2$ suggests $$\sum_{\sigma \in S_{k+1}}(\sgn \sigma)X_{\sigma(k+1)}(\omega(X_{\sigma(1)},\cdots,X_{\sigma(k)})) = (-1)^kk!\sum_{i=1}^k(-1)^iX_i(\omega(X_1,\cdots,\widehat{X_i},\cdots,X_{k+1})).$$Also, it seems that $$\sum_{\sigma \in S_{k+1}}\sum_{i=1}^k(\sgn \sigma)\omega(X_{\sigma(1)},\cdots, \nabla_{X_{\sigma(k+1)}}X_{\sigma(i)},\cdots,X_{\sigma(k)})=(-1)^{k+1}k!\sum_{i<j}(-1)^{i+j}\omega([X_i,X_j],X_1,\cdots,\widehat{X_i},\cdots,\widehat{X_j},\cdots,X_{k+1})$$ So: $$(k+1)! {\rm Alt}(\nabla \omega) = (-1)^kk!{\rm d}\omega \implies (-1)^k(k+1)\alt(\nabla \omega) = {\rm d}\omega.$$",,"['differential-geometry', 'differential-forms', 'connections']"
43,Parametrization of the lemniscate,Parametrization of the lemniscate,,"All over the net, it is stated that the parametrization of the lemniscate with Cartesian equation $(x^2 + y^2)^2 = 2a^2 (x^2 - y^2)$ is: $$\varphi: t \mapsto \left(\frac{a\sqrt{2}\cos(t)}{1+\sin^2(t)}, \frac{a\sqrt{2}\cos(t)\sin(t)}{1+\sin^2(t)}\right)$$ I don't understand how to get there… My method is as follows: I transform the Cartesian equation to polar coördinates, and I find: $$r=a\sqrt{2\cos(2\vartheta)}$$ Then replacing $r$ in $(r\cos(\vartheta), r\sin(\vartheta))$ gives: $$\psi: t \mapsto \left(a\sqrt{2\cos(2t)}\cos(t),a\sqrt{2\cos(2t)}\sin(t) \right)$$ Are these equivalent? (I guess theory says that there must be a certain function which maps $\psi$ into $\varphi$; I can't seem to find which function…)","All over the net, it is stated that the parametrization of the lemniscate with Cartesian equation $(x^2 + y^2)^2 = 2a^2 (x^2 - y^2)$ is: $$\varphi: t \mapsto \left(\frac{a\sqrt{2}\cos(t)}{1+\sin^2(t)}, \frac{a\sqrt{2}\cos(t)\sin(t)}{1+\sin^2(t)}\right)$$ I don't understand how to get there… My method is as follows: I transform the Cartesian equation to polar coördinates, and I find: $$r=a\sqrt{2\cos(2\vartheta)}$$ Then replacing $r$ in $(r\cos(\vartheta), r\sin(\vartheta))$ gives: $$\psi: t \mapsto \left(a\sqrt{2\cos(2t)}\cos(t),a\sqrt{2\cos(2t)}\sin(t) \right)$$ Are these equivalent? (I guess theory says that there must be a certain function which maps $\psi$ into $\varphi$; I can't seem to find which function…)",,"['differential-geometry', 'parametric', 'plane-curves']"
44,Does the curvature determine the metric?,Does the curvature determine the metric?,,"Here I asked the question whether the curvature deterined the metric. Since I am unfortunately completely new to Riemannian geometry, I wanted to ask, if somebody could give and explain a concrete example to me , as far as the following is concerned: At the MO page (as cited above) I got the following answer to the question Given a compact Riemannian manifold M, are there two metrics g1 and g2, which are not everywhere flat, such that they are not isometric to one another, but that there is a diffeomorphism which preserves the curvature? If the answer is yes: Can we chose M to be a compact 2-manifold? On the positive side, if $M$ is compact of dimension $\ge 3$ and has nowhere constant sectional curvature, then combination of results of Kulkarni and Yau show that    a diffeomorphism preserving sectional curvature is necessarily an isometry. Concerning 2-dimensional counter-examples: First of all, every surface which admits an open subset where curvature is (nonzero) constant would obviously yield a counter-example. Thus, I will assume now that curvature is nowhere constant. Kulkarni refers to Kreyszig's ""Introduction to Differential Geometry and Riemannian Geometry"", p. 164, for a counter-example attributed to  Stackel and Wangerin. You probably can get the book through interlibrary loan if you are in the US. I looked up the example in Kreyszig's ""Introduction to Differential Geometry and Riemannian Geometry"", p. 164: If we rotate the curve $x_3=\log x_1$ about the $x_3$-axis in space,  we obtain the surface of revolution $X(u_1,u_2)=(u_2\cos(u_1), u_2\sin(u_1),\log(u_2))$, $u_2>0$. This is diffeomorphic to the helicoid $X(u_1,u_2) =(u_2\cos(u_1),u_2\sin(u_1),u_1)$. I think, these manifolds are not compact (but I assumed compactness of the manifold in my question on MO). I don't understand, how to manipulate this example in order to get a compact manifold. Thank you for your help.","Here I asked the question whether the curvature deterined the metric. Since I am unfortunately completely new to Riemannian geometry, I wanted to ask, if somebody could give and explain a concrete example to me , as far as the following is concerned: At the MO page (as cited above) I got the following answer to the question Given a compact Riemannian manifold M, are there two metrics g1 and g2, which are not everywhere flat, such that they are not isometric to one another, but that there is a diffeomorphism which preserves the curvature? If the answer is yes: Can we chose M to be a compact 2-manifold? On the positive side, if $M$ is compact of dimension $\ge 3$ and has nowhere constant sectional curvature, then combination of results of Kulkarni and Yau show that    a diffeomorphism preserving sectional curvature is necessarily an isometry. Concerning 2-dimensional counter-examples: First of all, every surface which admits an open subset where curvature is (nonzero) constant would obviously yield a counter-example. Thus, I will assume now that curvature is nowhere constant. Kulkarni refers to Kreyszig's ""Introduction to Differential Geometry and Riemannian Geometry"", p. 164, for a counter-example attributed to  Stackel and Wangerin. You probably can get the book through interlibrary loan if you are in the US. I looked up the example in Kreyszig's ""Introduction to Differential Geometry and Riemannian Geometry"", p. 164: If we rotate the curve $x_3=\log x_1$ about the $x_3$-axis in space,  we obtain the surface of revolution $X(u_1,u_2)=(u_2\cos(u_1), u_2\sin(u_1),\log(u_2))$, $u_2>0$. This is diffeomorphic to the helicoid $X(u_1,u_2) =(u_2\cos(u_1),u_2\sin(u_1),u_1)$. I think, these manifolds are not compact (but I assumed compactness of the manifold in my question on MO). I don't understand, how to manipulate this example in order to get a compact manifold. Thank you for your help.",,"['differential-geometry', 'riemannian-geometry']"
45,How to Classify $2$-Plane Bundles over $S^2$?,How to Classify -Plane Bundles over ?,2 S^2,"I'm curious how one can classify the bundles over a given manifold. I recently read this paper on classifying $2$-sphere bundles over compact surfaces. A lot of the concepts went over my head since I'm still having trouble doing more ""trivial"" classifications. To get used to harder classifications, I'm hoping to get used to doing easier ones first. Thus, I'm curious how one can classify the $2$-plane bundles over $S^2$. To be honest, I'm not sure how to even approach such a problem.","I'm curious how one can classify the bundles over a given manifold. I recently read this paper on classifying $2$-sphere bundles over compact surfaces. A lot of the concepts went over my head since I'm still having trouble doing more ""trivial"" classifications. To get used to harder classifications, I'm hoping to get used to doing easier ones first. Thus, I'm curious how one can classify the $2$-plane bundles over $S^2$. To be honest, I'm not sure how to even approach such a problem.",,"['differential-geometry', 'low-dimensional-topology', 'geometric-topology']"
46,Differential operators as sections of a vector bundle,Differential operators as sections of a vector bundle,,"Most of the books which need to use differential operators in a hands on way adopt some variation of the following definition (here for simplicity I am avoiding discussion of differential operators between bundles): Defintion 1. A differential operator of order $\leq k$ on a smooth manifold $M$ is an $\mathbb{R}$ -linear map $D:C^{\infty}(M) \to C^{\infty} (M)$ such that in local coordinates it looks like $D f (p)= \sum_{i_1+...+i_n \leq k} A_{i_1 ... i_n}(p) \frac{\partial^{i_1+...+i_n} f}{\partial x_1^{i_1} ...x_n^{i_n}}|_p$ for some smooth functions $A_{i_1 ... i_n}$ . I have been searching for a different definition that  didn't employ coordinates right away, and I found the following definition in the ""Lectures on the geometry of manifolds"" by Liviu Nicolaescu and lecture notes of Misha Verbitsky (which are in Russian), which is, I believe, due to Grothendieck: Definition 2. Define differential operator of order zero to be the multiplication by a smooth function $m_f (g) = f \cdot g$ , or alternatively an operator $D$ such that the commutator $[D, m_g]=D \circ m_g - m_g \circ D$ is zero for any smooth function g. Define inductively differential operator of order $\leq k$ to be an operator $D$ such that $[D, m_g]$ is a differential operator of order $\leq k-1$ for any smooth $g$ . Denote the set of all differential operators of order $\leq k$ by $Diff^k (M)$ . Luviu's book than proves that differential operators are local in the sense that supp $D(f) \subset$ supp $f$ , which means that we can restrict those operators to  open subsets of $M$ , as is usually done to show that differential forms form a sheaf if one starts with top-down approach thinking of differential forms as alternating $C^{\infty}(M)$ multilinear maps of vector fields. This naturally brings me to the first question: Shouldn't the second definition be modified so that a differential operator is a sheaf homomorphism instead of just being a linear map between globally defined functions? Misha later on in his notes shows in a series of exercises, that if one defines the symbol algebra $\oplus S^i := \oplus \frac{Diff^i(M)}{Diff^{i-1}(M)}$ , which is an algebra over $C^{\infty}(M)$ , then it is isomorphic to $Sym^{\bullet} \mathfrak{X}$ - symmetric algebra over the vector fields. Finally he asks the reader to prove that for the case $M=\mathbb{R}^n$ we have an isomorphism of algebras $Diff^k(\mathbb{R}^n) \cong \oplus_{i \leq k} Sym^i \mathfrak{X(\mathbb{R}^n)}$ , which is basically the local form of the first definition. The latter algebra is just the space of global sections of the bundle $\oplus_{i \leq k} Sym^i (T \mathbb{R}^n)$ , which brings me to my second question: Can a differential operator of order $\leq k$ on M be thought of as a global section of some bundle of ""differential operators""? By the usual correspondence, that would imply that differential operators of order $\leq k$ form a locally trivial sheaf of $C^{\infty}(M)$ modules. Misha says that this is indeed the case in the last problem of his problem set, but I can't make a rigorous proof of it and I am asking for a reference where this approach is presented in detail. I am also puzzled by the fact that it is not usually mentioned in most of the references I've looked at that differential operators can be thought of as sections of some bundle, which seems to be very fundamental from a differential-geometric perspective. Moreover, this approach can further be developed into a very elegant treatment of the symbol.","Most of the books which need to use differential operators in a hands on way adopt some variation of the following definition (here for simplicity I am avoiding discussion of differential operators between bundles): Defintion 1. A differential operator of order on a smooth manifold is an -linear map such that in local coordinates it looks like for some smooth functions . I have been searching for a different definition that  didn't employ coordinates right away, and I found the following definition in the ""Lectures on the geometry of manifolds"" by Liviu Nicolaescu and lecture notes of Misha Verbitsky (which are in Russian), which is, I believe, due to Grothendieck: Definition 2. Define differential operator of order zero to be the multiplication by a smooth function , or alternatively an operator such that the commutator is zero for any smooth function g. Define inductively differential operator of order to be an operator such that is a differential operator of order for any smooth . Denote the set of all differential operators of order by . Luviu's book than proves that differential operators are local in the sense that supp supp , which means that we can restrict those operators to  open subsets of , as is usually done to show that differential forms form a sheaf if one starts with top-down approach thinking of differential forms as alternating multilinear maps of vector fields. This naturally brings me to the first question: Shouldn't the second definition be modified so that a differential operator is a sheaf homomorphism instead of just being a linear map between globally defined functions? Misha later on in his notes shows in a series of exercises, that if one defines the symbol algebra , which is an algebra over , then it is isomorphic to - symmetric algebra over the vector fields. Finally he asks the reader to prove that for the case we have an isomorphism of algebras , which is basically the local form of the first definition. The latter algebra is just the space of global sections of the bundle , which brings me to my second question: Can a differential operator of order on M be thought of as a global section of some bundle of ""differential operators""? By the usual correspondence, that would imply that differential operators of order form a locally trivial sheaf of modules. Misha says that this is indeed the case in the last problem of his problem set, but I can't make a rigorous proof of it and I am asking for a reference where this approach is presented in detail. I am also puzzled by the fact that it is not usually mentioned in most of the references I've looked at that differential operators can be thought of as sections of some bundle, which seems to be very fundamental from a differential-geometric perspective. Moreover, this approach can further be developed into a very elegant treatment of the symbol.","\leq k M \mathbb{R} D:C^{\infty}(M) \to C^{\infty} (M) D f (p)= \sum_{i_1+...+i_n \leq k} A_{i_1 ... i_n}(p) \frac{\partial^{i_1+...+i_n} f}{\partial x_1^{i_1} ...x_n^{i_n}}|_p A_{i_1 ... i_n} m_f (g) = f \cdot g D [D, m_g]=D \circ m_g - m_g \circ D \leq k D [D, m_g] \leq k-1 g \leq k Diff^k (M) D(f) \subset f M C^{\infty}(M) \oplus S^i := \oplus \frac{Diff^i(M)}{Diff^{i-1}(M)} C^{\infty}(M) Sym^{\bullet} \mathfrak{X} M=\mathbb{R}^n Diff^k(\mathbb{R}^n) \cong \oplus_{i \leq k} Sym^i \mathfrak{X(\mathbb{R}^n)} \oplus_{i \leq k} Sym^i (T \mathbb{R}^n) \leq k \leq k C^{\infty}(M)","['differential-geometry', 'partial-differential-equations']"
47,Intuition of Chern-Weil theory,Intuition of Chern-Weil theory,,"Let $ P \rightarrow M$ be a $G$-principal bundle. The lie algebra of $G$ is $\frak{g}$ and $P$ has connection form $\omega \in H^1(P,\frak{g})$ and curvature form $\Omega \in H^2(P,\frak{g})$. We consider $I^*(G)$ the set of invariant polynomials of $G$ ie the multilinear functions $f: \frak{g} \times ... \times \frak{g} \rightarrow \mathbb{R}$ satsifying $f(Ad(g)X_1,...,Ad(g)X_k) = f(X_1,...,X_n)$ for all $g \in G$ with $Ad(g) = (R_g)_*$ the map induced on $\frak{g}$ by the right multiplication with an element of $G$. It turns out very surprisingly that 1)the form $f(\Omega)(V_1,...,V_{2k}) = f(\Omega(V_1,V_2),...,\Omega(V_{2k-1},V_{2k}))$ can be projected to a form in $H^{2k}(M)$ is independant of the choice of connection for $P$ and 2) in the case of the $GL(n,\mathbb{K})$-bundle (with $\mathbb{K} = \mathbb{R} $ or $ \mathbb{C}$) associated to a vector bundle this form represents a characteristic class of the bundle. My problem is that I have read proofs of the statements but I do not feel I understand why they are true. In other words, what made Chern and Weil expect that this construction would yeild characteristic classes?","Let $ P \rightarrow M$ be a $G$-principal bundle. The lie algebra of $G$ is $\frak{g}$ and $P$ has connection form $\omega \in H^1(P,\frak{g})$ and curvature form $\Omega \in H^2(P,\frak{g})$. We consider $I^*(G)$ the set of invariant polynomials of $G$ ie the multilinear functions $f: \frak{g} \times ... \times \frak{g} \rightarrow \mathbb{R}$ satsifying $f(Ad(g)X_1,...,Ad(g)X_k) = f(X_1,...,X_n)$ for all $g \in G$ with $Ad(g) = (R_g)_*$ the map induced on $\frak{g}$ by the right multiplication with an element of $G$. It turns out very surprisingly that 1)the form $f(\Omega)(V_1,...,V_{2k}) = f(\Omega(V_1,V_2),...,\Omega(V_{2k-1},V_{2k}))$ can be projected to a form in $H^{2k}(M)$ is independant of the choice of connection for $P$ and 2) in the case of the $GL(n,\mathbb{K})$-bundle (with $\mathbb{K} = \mathbb{R} $ or $ \mathbb{C}$) associated to a vector bundle this form represents a characteristic class of the bundle. My problem is that I have read proofs of the statements but I do not feel I understand why they are true. In other words, what made Chern and Weil expect that this construction would yeild characteristic classes?",,"['differential-geometry', 'algebraic-topology', 'characteristic-classes', 'principal-bundles']"
48,Closed space curves of constant curvature,Closed space curves of constant curvature,,"Which closed space curves of constant curvature are there? Two families spring to mind: circles and closed helices around a torus (both having - in addition - constant torsion) . What other families of curves of constant curvature are there? Are there especially knots of constant curvature? Can - for example - the trefoil knot be realized by a curve of constant curvature? Added : If it were possible to wind a curve around a cylinder, and to bend the cylinder back to itself - while keeping the curvature of the helix constant by appropriate adjustments -, thus forming an eventually arbitrarily knotted torus with a closed helix on it, one could have every knot as a curve of constant curvature. The paper Knots of Constant Curvature might be related to this point of view. It is interesting, but it is not exactly what I am looking for.","Which closed space curves of constant curvature are there? Two families spring to mind: circles and closed helices around a torus (both having - in addition - constant torsion) . What other families of curves of constant curvature are there? Are there especially knots of constant curvature? Can - for example - the trefoil knot be realized by a curve of constant curvature? Added : If it were possible to wind a curve around a cylinder, and to bend the cylinder back to itself - while keeping the curvature of the helix constant by appropriate adjustments -, thus forming an eventually arbitrarily knotted torus with a closed helix on it, one could have every knot as a curve of constant curvature. The paper Knots of Constant Curvature might be related to this point of view. It is interesting, but it is not exactly what I am looking for.",,['differential-geometry']
49,Pushforward of inverse map at the identity?,Pushforward of inverse map at the identity?,,"Let $G$ be a Lie group and $i:G \rightarrow G$ denote the inversion map $i(x) = x^{-1}$ . (Notation: $f_*$ is the pushforward map $F_*:T_pG \rightarrow T_{i(p)}G$ which takes $(F_{*}X)(f)=X(f\circ F)$ and $X$ is a tangent vector, $X\in T_pG$ .) I wish to show that $i_{*}:T_{e}G\rightarrow T_{e}G$ is given by $i_{*}(X)=-X$ As a first step, it is trivial to prove that $i_*$ is an involution as $\mbox{Id}_{*}=(i\circ i)_{*}=i_{*}\circ i_{*}$ but I can't seem to make any further progress. Any help would be appreciated.","Let be a Lie group and denote the inversion map . (Notation: is the pushforward map which takes and is a tangent vector, .) I wish to show that is given by As a first step, it is trivial to prove that is an involution as but I can't seem to make any further progress. Any help would be appreciated.",G i:G \rightarrow G i(x) = x^{-1} f_* F_*:T_pG \rightarrow T_{i(p)}G (F_{*}X)(f)=X(f\circ F) X X\in T_pG i_{*}:T_{e}G\rightarrow T_{e}G i_{*}(X)=-X i_* \mbox{Id}_{*}=(i\circ i)_{*}=i_{*}\circ i_{*},"['differential-geometry', 'lie-groups', 'pushforward']"
50,Topological rings which are manifolds,Topological rings which are manifolds,,"Is the following statement true: ""Every smooth manifold $M$, which is a ring in the category of manifolds, must be diffeomorphic to $\mathbb{R}^n$.""? (Actually, homeomorphic would suffice.) I assume manifolds to be Hausdorff, second-countable and positive-dimensional, to exclude finite rings. I have strong feelings that this must be the case. Is there a ""simple"" proof of it? I know next to nothing about the theory of Lie groups, so any argument using these would have to be simple for me to understand it. On the other hand, I feel quite comfortable with ""standard"" algebraic topology (elementary homotopy theory, homology, cohomology rings and so on...). Edit: I am very sorry for not making this clear the first time, but I assume all manifolds to be without boundary.","Is the following statement true: ""Every smooth manifold $M$, which is a ring in the category of manifolds, must be diffeomorphic to $\mathbb{R}^n$.""? (Actually, homeomorphic would suffice.) I assume manifolds to be Hausdorff, second-countable and positive-dimensional, to exclude finite rings. I have strong feelings that this must be the case. Is there a ""simple"" proof of it? I know next to nothing about the theory of Lie groups, so any argument using these would have to be simple for me to understand it. On the other hand, I feel quite comfortable with ""standard"" algebraic topology (elementary homotopy theory, homology, cohomology rings and so on...). Edit: I am very sorry for not making this clear the first time, but I assume all manifolds to be without boundary.",,"['algebraic-topology', 'differential-geometry', 'topological-groups']"
51,Using Stokes' theorem to define the exterior derivative operator,Using Stokes' theorem to define the exterior derivative operator,,"In the excellent paper ""Differential forms and integration"" by Terence Tao, the author has mentioned that ""... one can view Stokes' theorem as a definition of the derivative operation $\omega\rightarrow d\omega$,  thus differentiation is the adjoint of the boundary operation"". My question is how exactly (rigorously) can one define the exterior derivative via Stokes' theorem? Where can I read about that in detail?","In the excellent paper ""Differential forms and integration"" by Terence Tao, the author has mentioned that ""... one can view Stokes' theorem as a definition of the derivative operation $\omega\rightarrow d\omega$,  thus differentiation is the adjoint of the boundary operation"". My question is how exactly (rigorously) can one define the exterior derivative via Stokes' theorem? Where can I read about that in detail?",,['differential-geometry']
52,Are $T\mathbb{S}^2$ and $\mathbb{S}^2 \times \mathbb{R}^2$ different?,Are  and  different?,T\mathbb{S}^2 \mathbb{S}^2 \times \mathbb{R}^2,"I have seen the claim that $T\mathbb{S}^2$ and $\mathbb{S}^2 \times \mathbb{R}^2$ are not diffeomorphic, but I have only ever seen the proof that they are not isomorphic as vector bundles (which is a cute application of the hairy ball theorem). How would I prove that they are indeed not diffeomorphic (or better, not homeomorphic)?","I have seen the claim that and are not diffeomorphic, but I have only ever seen the proof that they are not isomorphic as vector bundles (which is a cute application of the hairy ball theorem). How would I prove that they are indeed not diffeomorphic (or better, not homeomorphic)?",T\mathbb{S}^2 \mathbb{S}^2 \times \mathbb{R}^2,"['differential-geometry', 'algebraic-topology', 'tangent-bundle']"
53,Taylor's theorem on manifold,Taylor's theorem on manifold,,"Taylor's theorem for real-valued functions on manifolds is straightforward, and doesn't even require anything beyond differential structure. How does Taylor's theorem work for manifold-valued functions? Suppose you have a function $f:\mathbb{R}\to M$, where $M$ is a manifold (i.e., $f$ is a curve on $M$). Is there some notion of a Taylor's theorem on $M$, i.e., a way to write $f(t)$ only in terms of $f$ and its derivatives at $t=0$? I assume at minimum $M$ needs a connection, since otherwise I'm not sure how to even define the second and higher-order derivatives of $f$. With a metric one can define a ""first-order approximation"" of $f$ by $$f(t) \approx \exp_{f(0)} \left[t f'(0)\right]$$ but what would the higher-order approximations look like?","Taylor's theorem for real-valued functions on manifolds is straightforward, and doesn't even require anything beyond differential structure. How does Taylor's theorem work for manifold-valued functions? Suppose you have a function $f:\mathbb{R}\to M$, where $M$ is a manifold (i.e., $f$ is a curve on $M$). Is there some notion of a Taylor's theorem on $M$, i.e., a way to write $f(t)$ only in terms of $f$ and its derivatives at $t=0$? I assume at minimum $M$ needs a connection, since otherwise I'm not sure how to even define the second and higher-order derivatives of $f$. With a metric one can define a ""first-order approximation"" of $f$ by $$f(t) \approx \exp_{f(0)} \left[t f'(0)\right]$$ but what would the higher-order approximations look like?",,"['differential-geometry', 'taylor-expansion']"
54,Parallel Transport - Path independence,Parallel Transport - Path independence,,"I'm trying to solve this problem: Prove that if the parallel transport is path independent, i.e., given two points $p,q \in S$ the parallel transport from $p$ to $q$ is the same, no matter the curve chosen, then the Gaussian curvature of the surface must be zero. What I have is: Given the points $p, q \in S$, Let $\alpha : I \rightarrow S$ and $\beta : I \rightarrow S$ be two curves, which $\alpha(0) = p = \beta(0)$ and $\alpha(t_1) = q = \beta(t_2)$. And $w_{\alpha}(t)$ a parallel vector field along $\alpha$ and $w_{\beta}(t)$ a parallel vector field along $\beta$ such that $w_0 = w_\alpha(0) = w_\beta(0)$. Since parallel transport is the same at point $q$ then, must be $w_\alpha(t_1) = w_\beta(t_2)$. And also we have that $D_{\alpha'(t)}w_\alpha = D_{\beta'(t)}w_\beta = 0$ My idea is to prove that the Christoffel symbols are all zero, and consequently K = 0. Is that the right approach here? I also ask to not use the concepts of Riemannian Manifolds, tensor calculus, if possible. Thank you","I'm trying to solve this problem: Prove that if the parallel transport is path independent, i.e., given two points $p,q \in S$ the parallel transport from $p$ to $q$ is the same, no matter the curve chosen, then the Gaussian curvature of the surface must be zero. What I have is: Given the points $p, q \in S$, Let $\alpha : I \rightarrow S$ and $\beta : I \rightarrow S$ be two curves, which $\alpha(0) = p = \beta(0)$ and $\alpha(t_1) = q = \beta(t_2)$. And $w_{\alpha}(t)$ a parallel vector field along $\alpha$ and $w_{\beta}(t)$ a parallel vector field along $\beta$ such that $w_0 = w_\alpha(0) = w_\beta(0)$. Since parallel transport is the same at point $q$ then, must be $w_\alpha(t_1) = w_\beta(t_2)$. And also we have that $D_{\alpha'(t)}w_\alpha = D_{\beta'(t)}w_\beta = 0$ My idea is to prove that the Christoffel symbols are all zero, and consequently K = 0. Is that the right approach here? I also ask to not use the concepts of Riemannian Manifolds, tensor calculus, if possible. Thank you",,"['differential-geometry', 'surfaces']"
55,Volume form on a sphere.,Volume form on a sphere.,,"Let $S^n(r)$ be the sphere of radius $r$ , $x_1^2 + ... + x_{n+1}^2 = r^2$ and let $$w = \frac{1}{r} \sum_{i=1}^{n+1} (-1)^{i-1} x_i dx_1 \cdots\hat{dx_i},\cdots dx_{n+1} $$ Write $S^n$ for the unit sphere $S^n(1)$. Compute the integral $$\int\limits_{S^n}w$$ and conclude that $w$ is not exact. For me this is a hard exercise. I understand that from (a) we obtain an explicit formula for the generator of the top cohomology of $S^n$ (although not as a bump form).","Let $S^n(r)$ be the sphere of radius $r$ , $x_1^2 + ... + x_{n+1}^2 = r^2$ and let $$w = \frac{1}{r} \sum_{i=1}^{n+1} (-1)^{i-1} x_i dx_1 \cdots\hat{dx_i},\cdots dx_{n+1} $$ Write $S^n$ for the unit sphere $S^n(1)$. Compute the integral $$\int\limits_{S^n}w$$ and conclude that $w$ is not exact. For me this is a hard exercise. I understand that from (a) we obtain an explicit formula for the generator of the top cohomology of $S^n$ (although not as a bump form).",,"['differential-geometry', 'differential-topology']"
56,Are there exotic symplectic structures on $ S^2 $?,Are there exotic symplectic structures on ?, S^2 ,"Besides the obvoius symplectic structure on $ S^2$ given by the area element in the standard embedding $ S^2 \to \Bbb R^3$, are there any other closed 2-forms on $ S^2$ which produce nonisomorphic symplectic structures on $ S^2$? If yes, is there a complete classification of isomorphy classes of symplectic $ S^2$'s?","Besides the obvoius symplectic structure on $ S^2$ given by the area element in the standard embedding $ S^2 \to \Bbb R^3$, are there any other closed 2-forms on $ S^2$ which produce nonisomorphic symplectic structures on $ S^2$? If yes, is there a complete classification of isomorphy classes of symplectic $ S^2$'s?",,"['differential-geometry', 'surfaces', 'spherical-geometry', 'symplectic-geometry']"
57,Curvature of the earth from Theorema Egregium,Curvature of the earth from Theorema Egregium,,"I recently learned Gauss's Theorema Egregium for surfaces embedded in $\mathbb{R}^3$. A TA for my class suggestively said that from this, i.e. that Gaussian curvature depends only on the first fundamental form of a surface, we may calculate the curvature of the earth without leaving its surface. I understand that with knowledge of the first fundamental form, we may calculate the curvature, but for this question I'm not sure how to proceed, since we don't have a priori the first fundamental form of the earth given. It seems to me like we need to find that. I saw some answers using the Gauss-Bonnet theorem, but I think that deals with total curvature, and I'm speaking of Gaussian curvature (I may be wrong here, I don't really know that theorem well). Does it have something to do with measure triangles and angles? And if so, can someone help me relate this back to Gauss's theorem and the first fundamental form? Another point of confusion: How do I even know what a triangle is on an arbitrary surface? A triangle is made by connecting three points with the curve that attains the shortest possible distance between those points, right? So on a plain, that's the normal line segment, but what about for arbitrary surfaces?","I recently learned Gauss's Theorema Egregium for surfaces embedded in $\mathbb{R}^3$. A TA for my class suggestively said that from this, i.e. that Gaussian curvature depends only on the first fundamental form of a surface, we may calculate the curvature of the earth without leaving its surface. I understand that with knowledge of the first fundamental form, we may calculate the curvature, but for this question I'm not sure how to proceed, since we don't have a priori the first fundamental form of the earth given. It seems to me like we need to find that. I saw some answers using the Gauss-Bonnet theorem, but I think that deals with total curvature, and I'm speaking of Gaussian curvature (I may be wrong here, I don't really know that theorem well). Does it have something to do with measure triangles and angles? And if so, can someone help me relate this back to Gauss's theorem and the first fundamental form? Another point of confusion: How do I even know what a triangle is on an arbitrary surface? A triangle is made by connecting three points with the curve that attains the shortest possible distance between those points, right? So on a plain, that's the normal line segment, but what about for arbitrary surfaces?",,"['differential-geometry', 'curvature']"
58,Why use geometric algebra and not differential forms?,Why use geometric algebra and not differential forms?,,"This is somewhat similar to Are Clifford algebras and differential forms equivalent frameworks for differential geometry? , but I want to restrict discussion to $\mathbb{R}^n$, not arbitrary manifolds. Moreover, I am interested specifically in whether $$(\text{differential forms on }\mathbb{R}^n\text{ + a notion of inner product defined on them}) \simeq \text{geometric algebra over }\mathbb{R}^n$$ where the isomorphism is as Clifford algebras. ( I.e., is geometric algebra just the description of the algebraic properties of differential forms when endowed with a suitable notion of inner product? ) 1. Is any geometric algebra over $\mathbb{R}^n$ isomorphic to the exterior algebra over $\mathbb{R}^n$ in the following senses: as a vector space? ( Should be yes. ) as an exterior algebra? (Obviously they are not isomorphic as Clifford algebras unless our quadratic form is the zero quadratic form.) Since the basis of the geometric algebra (as a vector space) is the same (or at least isomorphic to) the basis of the exterior algebra over $\mathbb{R}^n$, the answer seems to be yes. Also because the standard embedding of any geometric algebra over $\mathbb{R}^n$ into the tensor algebra over $\mathbb{R}^n$ always ""piggybacks"" on the embedding of the exterior algebra over $\mathbb{R}^n$, see this MathOverflow question . 2. Are differential forms the standard construction of an object satisfying the algebraic properties of the exterior algebra over $\mathbb{R}^n$? 3. Does the answers to 1. and 2. being yes imply that the part in yellow is true? EDIT: It seems like the only problem might be that differential forms are covariant tensors, whereas I imagine that multivectors are generally assumed to be contravariant. However, distinguishing between co- and contravariant tensors is a standard issue in tensor analysis, so this doesn't really seem like an important issue to me. Assuming that I am reading this correctly, it seems like the elementary construction of the geometric algebra with respect to the standard inner product over $\mathbb{R}^n$ given by Alan MacDonald here is exactly just the exterior algebra over $\mathbb{R}^n$ with inner product. David Hestenes seems to try and explain some of this somewhat here and here , although I don't quite understand what he is getting at. (Also his claim in the first document that matrix algebra is subsumed by geometric algebra seems completely false, since he only addresses those aspects which relate to alternating tensors.)","This is somewhat similar to Are Clifford algebras and differential forms equivalent frameworks for differential geometry? , but I want to restrict discussion to $\mathbb{R}^n$, not arbitrary manifolds. Moreover, I am interested specifically in whether $$(\text{differential forms on }\mathbb{R}^n\text{ + a notion of inner product defined on them}) \simeq \text{geometric algebra over }\mathbb{R}^n$$ where the isomorphism is as Clifford algebras. ( I.e., is geometric algebra just the description of the algebraic properties of differential forms when endowed with a suitable notion of inner product? ) 1. Is any geometric algebra over $\mathbb{R}^n$ isomorphic to the exterior algebra over $\mathbb{R}^n$ in the following senses: as a vector space? ( Should be yes. ) as an exterior algebra? (Obviously they are not isomorphic as Clifford algebras unless our quadratic form is the zero quadratic form.) Since the basis of the geometric algebra (as a vector space) is the same (or at least isomorphic to) the basis of the exterior algebra over $\mathbb{R}^n$, the answer seems to be yes. Also because the standard embedding of any geometric algebra over $\mathbb{R}^n$ into the tensor algebra over $\mathbb{R}^n$ always ""piggybacks"" on the embedding of the exterior algebra over $\mathbb{R}^n$, see this MathOverflow question . 2. Are differential forms the standard construction of an object satisfying the algebraic properties of the exterior algebra over $\mathbb{R}^n$? 3. Does the answers to 1. and 2. being yes imply that the part in yellow is true? EDIT: It seems like the only problem might be that differential forms are covariant tensors, whereas I imagine that multivectors are generally assumed to be contravariant. However, distinguishing between co- and contravariant tensors is a standard issue in tensor analysis, so this doesn't really seem like an important issue to me. Assuming that I am reading this correctly, it seems like the elementary construction of the geometric algebra with respect to the standard inner product over $\mathbb{R}^n$ given by Alan MacDonald here is exactly just the exterior algebra over $\mathbb{R}^n$ with inner product. David Hestenes seems to try and explain some of this somewhat here and here , although I don't quite understand what he is getting at. (Also his claim in the first document that matrix algebra is subsumed by geometric algebra seems completely false, since he only addresses those aspects which relate to alternating tensors.)",,"['differential-geometry', 'soft-question', 'differential-forms', 'tensors', 'geometric-algebras']"
59,Centre of the circle,Centre of the circle,,"Another approach to the curvature of a unit-speed plane curve $\gamma$ at a point $\gamma (s_0)$ is to look for the ‘best approximating circle’ at this point. We can then define the curvature of $\gamma$ to be the reciprocal of the radius of this circle. Carry out this programme by showing that the centre of the circle which passes through three nearby points $\gamma (s_0)$ and $\gamma (s_0 \pm \delta_s)$ on $\gamma$ approaches the point $$\epsilon (s_0) = \gamma (s_0) + \frac{1}{\kappa_s (s_0)}n_s(s_0)$$ as $\delta_s$ tends to zero. The circle $C$ with centre $\epsilon (s_0)$ passing through $\gamma (s_0)$ is called the osculating circle to $\gamma$ at the point $\gamma (s_0)$ , and $\epsilon (s_0)$ is called the centre of curvature of $\gamma$ at $\gamma (s_0)$ . The radius of $C$ is $\frac{1}{|\kappa_s (s_0)|} = \frac{1}{\kappa (s_0)}$ , where $\kappa$ is the curvature of $\gamma$ – this is called the radius of curvature of $\gamma$ at $\gamma (s_0)$ . I have done the following:  The three points $\gamma (s_0), \gamma (s_0 + \delta_s), \gamma (s_0 - \delta_s)$ are on the circle with radius $r$ and centre $\epsilon$ .  So $$r^2=\|\gamma (s_0)-\epsilon\|^2=\|\gamma (s_0 + \delta_s)-\epsilon\|^2=\|\gamma (s_0 - \delta_s)-\epsilon\|^2$$ Since we want show that the centre of the circle tends to $\epsilon (s_0)$ we do the following: \begin{align} |\epsilon (s_0)-\epsilon| &=|\gamma (s_0) + \frac{1}{\kappa_s (s_0)}n_s(s_0)-\epsilon| \\ &\leq | \gamma (s_0) -\epsilon|+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\ &=r+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)|. \end{align} Is this correct so far? How could we continue? EDIT: We have that the radius of $C$ is $\frac{1}{|\kappa_s (s_0)|}$ so we get \begin{align} |\epsilon (s_0)-\epsilon| &=|\gamma (s_0) + \frac{1}{\kappa_s (s_0)}n_s(s_0)-\epsilon| \\ &\leq | \gamma (s_0) -\epsilon|+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\ &=r+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\ &=\frac{1}{|\kappa_s (s_0)|}+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\ &=\frac{1}{|\kappa_s (s_0)|}(1+|n_s(s_0)|) \\ &=\frac{1}{|\kappa (s_0)|}(1+|n_s(s_0)|). \end{align} What do we get from that?","Another approach to the curvature of a unit-speed plane curve at a point is to look for the ‘best approximating circle’ at this point. We can then define the curvature of to be the reciprocal of the radius of this circle. Carry out this programme by showing that the centre of the circle which passes through three nearby points and on approaches the point as tends to zero. The circle with centre passing through is called the osculating circle to at the point , and is called the centre of curvature of at . The radius of is , where is the curvature of – this is called the radius of curvature of at . I have done the following:  The three points are on the circle with radius and centre .  So Since we want show that the centre of the circle tends to we do the following: Is this correct so far? How could we continue? EDIT: We have that the radius of is so we get What do we get from that?","\gamma \gamma (s_0) \gamma \gamma (s_0) \gamma (s_0 \pm \delta_s) \gamma \epsilon (s_0) = \gamma (s_0) + \frac{1}{\kappa_s (s_0)}n_s(s_0) \delta_s C \epsilon (s_0) \gamma (s_0) \gamma \gamma (s_0) \epsilon (s_0) \gamma \gamma (s_0) C \frac{1}{|\kappa_s (s_0)|} = \frac{1}{\kappa (s_0)} \kappa \gamma \gamma \gamma (s_0) \gamma (s_0), \gamma (s_0 + \delta_s), \gamma (s_0 - \delta_s) r \epsilon r^2=\|\gamma (s_0)-\epsilon\|^2=\|\gamma (s_0 + \delta_s)-\epsilon\|^2=\|\gamma (s_0 - \delta_s)-\epsilon\|^2 \epsilon (s_0) \begin{align}
|\epsilon (s_0)-\epsilon|
&=|\gamma (s_0) + \frac{1}{\kappa_s (s_0)}n_s(s_0)-\epsilon| \\
&\leq | \gamma (s_0) -\epsilon|+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\ &=r+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)|.
\end{align} C \frac{1}{|\kappa_s (s_0)|} \begin{align}
|\epsilon (s_0)-\epsilon|
&=|\gamma (s_0) + \frac{1}{\kappa_s (s_0)}n_s(s_0)-\epsilon| \\
&\leq | \gamma (s_0) -\epsilon|+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\
&=r+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\
&=\frac{1}{|\kappa_s (s_0)|}+\frac{1}{|\kappa_s (s_0)|}|n_s(s_0)| \\
&=\frac{1}{|\kappa_s (s_0)|}(1+|n_s(s_0)|) \\
&=\frac{1}{|\kappa (s_0)|}(1+|n_s(s_0)|).
\end{align}","['differential-geometry', 'circles', 'curvature']"
60,Every $\mathcal{C}^1$ manifold can be made smooth?,Every  manifold can be made smooth?,\mathcal{C}^1,"I heard of a theorem saying that each $\mathcal{C}^k$-manifold with $k\geq 1$ can be made into a smooth manifold, i.e. $\mathcal{C}^{\infty}$ (by restriction of the atlas). However, I cannot find this theorem anywhere. Can anyone point me in the write direction (book, paper, webpage, ...) and/or give me the proof?","I heard of a theorem saying that each $\mathcal{C}^k$-manifold with $k\geq 1$ can be made into a smooth manifold, i.e. $\mathcal{C}^{\infty}$ (by restriction of the atlas). However, I cannot find this theorem anywhere. Can anyone point me in the write direction (book, paper, webpage, ...) and/or give me the proof?",,"['differential-geometry', 'reference-request', 'manifolds', 'smooth-manifolds']"
61,Orientability of a product of smooth manifolds implies orientability of each factor,Orientability of a product of smooth manifolds implies orientability of each factor,,"I've been learning a bit about orientability on smooth manifolds. I'm having torubles with this exercise: Given two smooth manifolds $M$ and $N$, show that the product manifold   $M \times N$ is orientable if and only if $M$ and $N$ are orientable. Using the orientability of $M$ and $N$ one can obtain an oriented atlas for each manifold and the construct an oriented atlas for the product formed by the product charts (i.e. charts of the form $(U \times V, \phi \times \psi)$ with $(U, \phi)$ a chart of $M$ and $(V, \psi)$ a chart of $N$). I'm stuck on proving the converse. Given an oriented atlas for $M \times N$ one can obtain another oriented atlas formed by charts with basic open sets as domains. But from this atlas I don't know how to extract an atlas for $M$. I was given the following hint: If $M \times N$ is orientable then $M \times \mathbb{R}^n$ is orientable where $n$ is the dimension of $N$. I don't know either how to prove it nor how to use it.","I've been learning a bit about orientability on smooth manifolds. I'm having torubles with this exercise: Given two smooth manifolds $M$ and $N$, show that the product manifold   $M \times N$ is orientable if and only if $M$ and $N$ are orientable. Using the orientability of $M$ and $N$ one can obtain an oriented atlas for each manifold and the construct an oriented atlas for the product formed by the product charts (i.e. charts of the form $(U \times V, \phi \times \psi)$ with $(U, \phi)$ a chart of $M$ and $(V, \psi)$ a chart of $N$). I'm stuck on proving the converse. Given an oriented atlas for $M \times N$ one can obtain another oriented atlas formed by charts with basic open sets as domains. But from this atlas I don't know how to extract an atlas for $M$. I was given the following hint: If $M \times N$ is orientable then $M \times \mathbb{R}^n$ is orientable where $n$ is the dimension of $N$. I don't know either how to prove it nor how to use it.",,"['differential-geometry', 'smooth-manifolds']"
62,Understand Cotangent Space as an Equivalence Class,Understand Cotangent Space as an Equivalence Class,,"In my differential geometry class, my teacher defined the co-tangent space as follows. Let $M$ be a smooth manifold and $p$ is a point on $M$. Now define two sets of $C^\infty$ real-valued functions defined on $M$. $\mathcal I_p := \left\{f\in C^\infty(M)\bigr|f(p)=0 \right\}.$ That is, the set of functions that vanish at $p$. This is not hard to imagine. $\mathcal I_p^2 := \left\{\displaystyle\sum_{i=i}^n f_ig_i\bigr|f_i, g_i\in \mathcal I_p \right\}.$ I could not visualise what this set looks like. Is it a subset of $\mathcal I_p$ or a bigger set and why? After the definition of these two sets comes the even harder concept of quotient as follows. My teacher defined the co-tangent space $T_p^*M$ as the quotient space $\mathcal I_p/\mathcal I_p^2$. I have difficulty in understanding quotient thing in general, especially I have no idea of what this quotient looks like. Is there an intuitive way to understand this concept, please? Thank you!","In my differential geometry class, my teacher defined the co-tangent space as follows. Let $M$ be a smooth manifold and $p$ is a point on $M$. Now define two sets of $C^\infty$ real-valued functions defined on $M$. $\mathcal I_p := \left\{f\in C^\infty(M)\bigr|f(p)=0 \right\}.$ That is, the set of functions that vanish at $p$. This is not hard to imagine. $\mathcal I_p^2 := \left\{\displaystyle\sum_{i=i}^n f_ig_i\bigr|f_i, g_i\in \mathcal I_p \right\}.$ I could not visualise what this set looks like. Is it a subset of $\mathcal I_p$ or a bigger set and why? After the definition of these two sets comes the even harder concept of quotient as follows. My teacher defined the co-tangent space $T_p^*M$ as the quotient space $\mathcal I_p/\mathcal I_p^2$. I have difficulty in understanding quotient thing in general, especially I have no idea of what this quotient looks like. Is there an intuitive way to understand this concept, please? Thank you!",,['differential-geometry']
63,Almost A Vector Bundle,Almost A Vector Bundle,,I'm trying to get some intuition for vector bundles. Does anyone have good examples of constructions which are not vector bundles for some nontrivial reason. Ideally I want to test myself by seeing some difficult/pathological spaces where my naive intuition fails me! Apologies if this isn't a particularly well-defined question - hopefully it's clear enough to solicit some useful responses!,I'm trying to get some intuition for vector bundles. Does anyone have good examples of constructions which are not vector bundles for some nontrivial reason. Ideally I want to test myself by seeing some difficult/pathological spaces where my naive intuition fails me! Apologies if this isn't a particularly well-defined question - hopefully it's clear enough to solicit some useful responses!,,"['differential-geometry', 'examples-counterexamples', 'vector-bundles']"
64,Does the group of Diffeomorphisms act transitively on the space of Riemannian metrics?,Does the group of Diffeomorphisms act transitively on the space of Riemannian metrics?,,"Let $M$ be a smooth manifold (maybe compact, if that helps). Denote by $\operatorname{Diff}(M)$ the group of diffeomorphisms $M\to M$ and by $R(M)$ the space of Riemannian metrics on $M$. We obtain a canonical group action $$ R(M) \times \operatorname{Diff}(M) \to R(M), (g,F) \mapsto F^*g, $$ where $F^*g$ denotes the pullback of $g$ along $F$. Is this action transitive? In other words, is it possible for any two Riemannian metrics $g,h$ on $M$ to find a diffeomorphism $F$ such that $F^*g=h$? Do you know any references for this type of questions?","Let $M$ be a smooth manifold (maybe compact, if that helps). Denote by $\operatorname{Diff}(M)$ the group of diffeomorphisms $M\to M$ and by $R(M)$ the space of Riemannian metrics on $M$. We obtain a canonical group action $$ R(M) \times \operatorname{Diff}(M) \to R(M), (g,F) \mapsto F^*g, $$ where $F^*g$ denotes the pullback of $g$ along $F$. Is this action transitive? In other words, is it possible for any two Riemannian metrics $g,h$ on $M$ to find a diffeomorphism $F$ such that $F^*g=h$? Do you know any references for this type of questions?",,"['reference-request', 'differential-geometry']"
65,"If $\pi:X\to Y$ is a surjective local homeomorphism and $X$ is a smooth manifold, then does $Y$ become a smooth manifold?","If  is a surjective local homeomorphism and  is a smooth manifold, then does  become a smooth manifold?",\pi:X\to Y X Y,"Update: Thanks to some comments below, I realized that the properties of $M$ and $\Gamma$ are also important, taking which into consideration I have obtained a new similar proposition below. I'll provide my proof as an answer. Welcome to point out any mistake or comment on other aspects! Some notations: Let $M$ be a manifold with a certain structure. Let $G$ be a group of transformations that preserves this structure (for example, if $M$ is a topological manifold, then $G$ consists of homeomorphisms; if $M$ is a smooth manifold, then $G$ consists of diffeomorphisms; if $M$ has a metric, then $G$ consists of isometries). $G$ is said to act on $M$ properly discontinuously if for all $x\in M$ there is a neighborhood $U_x$ of $x$ such that $\{g\in G:gU_x\cap U_x=\varnothing\}$ is a finite set. Proposition: Let $M$ be as above. Let $G$ be a group of transformations that preserves the structure of $G$ . If $G$ acts properly discontinuous and without fixed points, then the natural projection ( $\bar x\in M/G$ is the equivalence class of $x\in M$ ) $$\pi:M\to M/G$$ $$x\mapsto\bar x$$ is a local homeomorphism. In particular, for every $x\in M$ , there is a coordinate neighborhood $U_x$ of $x$ such that $\pi|_{U_x}:U_x\to\pi(U_x)$ is a homeomorphism. Moreover, if we denote the corresponding chart of $U_x$ by $\varphi_x$ , then the maps $\varphi_x(\pi|_{U_x})^{-1}$ constitute an atlas of $M/G$ that assigns to $M/G$ the same type of structure of $M$ . Original question: I am trying to determine whether this proposition is true. Let $X$ be an $n$ -dimensional smooth manifold, $Y$ a topological space and $\pi:X\to Y$ a local homeomorphism. Then we can assign to $Y$ a differentiable structure such that $\pi$ is a smooth map. My idea is to define an atlas on $Y$ as follows. For any $y\in Y$ , take any $x\in \pi^{-1}(y)$ . Since $\pi$ is a local homeomorphism, there is a neighborhood $U_x$ of $x$ such that $$\pi|_{U_x}:U_x\to\pi(U_x)$$ is a homeomorphism. By taking an intersection if necessary, we can assume $U_x$ is a coordinate chart $\varphi_x$ . Apparently $\pi(U_x)$ is a neighborhood of $y$ , hence we can define a chart near $y$ as $$\psi_y=\varphi_x(\pi|_{U_x})^{-1}$$ The problem is, I cannot verify that transition maps are smooth. Suppose for the same $y$ , we have two different $x_1,x_2\in \pi^{-1}(y)$ . Then by the reasoning above there are two coordinate neighborhoods $U_{x_1},U_{x_2}$ . By the Hausdorff property of $X$ we may assume $U_{x_1}$ and $U_{x_2}$ are disjoint, then there is at least one transition map of the form $$\varphi_{x_1}(\pi|_{U_{x_1}})^{-1}(\pi|_{U_{x_2}})\varphi_{x_2}^{-1}$$ However, since $U_{x_1}$ and $U_{x_2}$ are disjoint, the middle part $(\pi|_{U_{x_1}})^{-1}(\pi|_{U_{x_2}})$ does not cancel, and I cannot conclude that the transition map is smooth. Questions: (1) Can I fix this by removing some charts of the form above? (2) If not, can I impose some more conditions to make the proposition true? In particular, I want to apply this to quotients like $\mathbb C/M$ and $\mathbb H/\Gamma$ and conclude that they are Riemann surfaces. Is there anything special about $\mathbb C$ , $\mathbb H$ , $M$ or $\Gamma$ that I fail to include in the assumptions of the suggested proposition? Some clarification: $M$ is a lattice of rank 2 in $\mathbb C$ and $\Gamma$ is a discrete subgroup of $PSL(2,\mathbb R)$ . What I am interested in is, are the properties of $M$ and $\Gamma$ necessary for $\mathbb C/M$ and $\mathbb H/\Gamma$ to become a Riemann surface? In a textbook, the argument is made by showing the natural projection is a local homeomorphism, so I was wondering whether a (surjective) local homeomorphism is enough.","Update: Thanks to some comments below, I realized that the properties of and are also important, taking which into consideration I have obtained a new similar proposition below. I'll provide my proof as an answer. Welcome to point out any mistake or comment on other aspects! Some notations: Let be a manifold with a certain structure. Let be a group of transformations that preserves this structure (for example, if is a topological manifold, then consists of homeomorphisms; if is a smooth manifold, then consists of diffeomorphisms; if has a metric, then consists of isometries). is said to act on properly discontinuously if for all there is a neighborhood of such that is a finite set. Proposition: Let be as above. Let be a group of transformations that preserves the structure of . If acts properly discontinuous and without fixed points, then the natural projection ( is the equivalence class of ) is a local homeomorphism. In particular, for every , there is a coordinate neighborhood of such that is a homeomorphism. Moreover, if we denote the corresponding chart of by , then the maps constitute an atlas of that assigns to the same type of structure of . Original question: I am trying to determine whether this proposition is true. Let be an -dimensional smooth manifold, a topological space and a local homeomorphism. Then we can assign to a differentiable structure such that is a smooth map. My idea is to define an atlas on as follows. For any , take any . Since is a local homeomorphism, there is a neighborhood of such that is a homeomorphism. By taking an intersection if necessary, we can assume is a coordinate chart . Apparently is a neighborhood of , hence we can define a chart near as The problem is, I cannot verify that transition maps are smooth. Suppose for the same , we have two different . Then by the reasoning above there are two coordinate neighborhoods . By the Hausdorff property of we may assume and are disjoint, then there is at least one transition map of the form However, since and are disjoint, the middle part does not cancel, and I cannot conclude that the transition map is smooth. Questions: (1) Can I fix this by removing some charts of the form above? (2) If not, can I impose some more conditions to make the proposition true? In particular, I want to apply this to quotients like and and conclude that they are Riemann surfaces. Is there anything special about , , or that I fail to include in the assumptions of the suggested proposition? Some clarification: is a lattice of rank 2 in and is a discrete subgroup of . What I am interested in is, are the properties of and necessary for and to become a Riemann surface? In a textbook, the argument is made by showing the natural projection is a local homeomorphism, so I was wondering whether a (surjective) local homeomorphism is enough.","M \Gamma M G M G M G M G G M x\in M U_x x \{g\in G:gU_x\cap U_x=\varnothing\} M G G G \bar x\in M/G x\in M \pi:M\to M/G x\mapsto\bar x x\in M U_x x \pi|_{U_x}:U_x\to\pi(U_x) U_x \varphi_x \varphi_x(\pi|_{U_x})^{-1} M/G M/G M X n Y \pi:X\to Y Y \pi Y y\in Y x\in \pi^{-1}(y) \pi U_x x \pi|_{U_x}:U_x\to\pi(U_x) U_x \varphi_x \pi(U_x) y y \psi_y=\varphi_x(\pi|_{U_x})^{-1} y x_1,x_2\in \pi^{-1}(y) U_{x_1},U_{x_2} X U_{x_1} U_{x_2} \varphi_{x_1}(\pi|_{U_{x_1}})^{-1}(\pi|_{U_{x_2}})\varphi_{x_2}^{-1} U_{x_1} U_{x_2} (\pi|_{U_{x_1}})^{-1}(\pi|_{U_{x_2}}) \mathbb C/M \mathbb H/\Gamma \mathbb C \mathbb H M \Gamma M \mathbb C \Gamma PSL(2,\mathbb R) M \Gamma \mathbb C/M \mathbb H/\Gamma","['differential-geometry', 'manifolds', 'riemann-surfaces']"
66,Is there a Rellich-Kondrachov theorem for manifolds with boundary?,Is there a Rellich-Kondrachov theorem for manifolds with boundary?,,"As special case, consider the cylinder $C=[0,T]\times S^n$. Is there a compact embedding $H^1(C)\subset\subset L^2(C)$? The Wikipedia entry to the Rellich-Kondrachov theorem claims that such an embedding exists for every compact manifold with $C^1$ boundary, but does not give a reference, nor clarifies what is meant by a compact manifold. But this is crucial since most books don't treat manifolds with boundary. Is there a good reference that treats the case I need?","As special case, consider the cylinder $C=[0,T]\times S^n$. Is there a compact embedding $H^1(C)\subset\subset L^2(C)$? The Wikipedia entry to the Rellich-Kondrachov theorem claims that such an embedding exists for every compact manifold with $C^1$ boundary, but does not give a reference, nor clarifies what is meant by a compact manifold. But this is crucial since most books don't treat manifolds with boundary. Is there a good reference that treats the case I need?",,"['differential-geometry', 'reference-request', 'sobolev-spaces']"
67,Ways of thinking about vector-valued differential forms,Ways of thinking about vector-valued differential forms,,"I am trying to get a better intuition of vector-valued differential forms. Let $V$ be a vector space and $M$ a smooth manifold. Consider the space $\Omega^k(M;V)=\Gamma((M\times V)\otimes \Lambda^k(T^*M))$. That is, the space of $V$ valued $k$-forms on $M$. Intuitively I think of this definition as: For each $x\in M$, $\omega(x)$ is an alternating multi-linear map that maps $k$ tangent vectors at $x$ to a vector $v\in V$. In terms of the precise definition: For $x\in M$, if $\omega\in \Omega^k(M;V)$, we have $\omega(x)\in (\pi^{-1}(x))\otimes \{x\}\times\Lambda^k(T^*_xM)$ Firstly - is the above line correct? Since $\Lambda^k(T^*M)$ is a disjoint union, I would think that a section of $\Lambda^k(T^*M)$ would map an element $x$ of $M$ to $\{x\}\times T^*_xM$. So, because of the $\{x\}$ in the above equation, I feel like it is much more natural to think of $\omega(x)$ as the map described above but that it also outputs the point $x$ as well. That is, $\omega(x)(X_1,\dots,X_k)=(x,v)$. Is this wrong? What makes me a little uneasy is that since the bundle we are considering is trivial, does it not follow that $\pi^{-1}(x)$ is precisely $\{x\}\times V$? So then should it be $\omega(x)\in (\{x\}\times V)\otimes (\{x\}\times \Lambda^k(T^*_x M))$... Which just looks weird... My understanding is not quite there yet. If anyone could help with this, it would be much appreciated.","I am trying to get a better intuition of vector-valued differential forms. Let $V$ be a vector space and $M$ a smooth manifold. Consider the space $\Omega^k(M;V)=\Gamma((M\times V)\otimes \Lambda^k(T^*M))$. That is, the space of $V$ valued $k$-forms on $M$. Intuitively I think of this definition as: For each $x\in M$, $\omega(x)$ is an alternating multi-linear map that maps $k$ tangent vectors at $x$ to a vector $v\in V$. In terms of the precise definition: For $x\in M$, if $\omega\in \Omega^k(M;V)$, we have $\omega(x)\in (\pi^{-1}(x))\otimes \{x\}\times\Lambda^k(T^*_xM)$ Firstly - is the above line correct? Since $\Lambda^k(T^*M)$ is a disjoint union, I would think that a section of $\Lambda^k(T^*M)$ would map an element $x$ of $M$ to $\{x\}\times T^*_xM$. So, because of the $\{x\}$ in the above equation, I feel like it is much more natural to think of $\omega(x)$ as the map described above but that it also outputs the point $x$ as well. That is, $\omega(x)(X_1,\dots,X_k)=(x,v)$. Is this wrong? What makes me a little uneasy is that since the bundle we are considering is trivial, does it not follow that $\pi^{-1}(x)$ is precisely $\{x\}\times V$? So then should it be $\omega(x)\in (\{x\}\times V)\otimes (\{x\}\times \Lambda^k(T^*_x M))$... Which just looks weird... My understanding is not quite there yet. If anyone could help with this, it would be much appreciated.",,"['differential-geometry', 'manifolds', 'differential-forms', 'vector-bundles', 'smooth-manifolds']"
68,Exercises to help in the understanding of differential forms?,Exercises to help in the understanding of differential forms?,,"I've been trying to grasp the concept of differential forms, which I have been encountering while studying the text ""Geometric Measure Theory"" by Frank Morgan. Unfortunately the explanation is very sparse and while the internet contains many definitions, I have a hard time getting the bigger picture from just reading them. Are there any lists of exercises that I could do to assist my understanding by just working with them? Thank you.","I've been trying to grasp the concept of differential forms, which I have been encountering while studying the text ""Geometric Measure Theory"" by Frank Morgan. Unfortunately the explanation is very sparse and while the internet contains many definitions, I have a hard time getting the bigger picture from just reading them. Are there any lists of exercises that I could do to assist my understanding by just working with them? Thank you.",,['differential-geometry']
69,A question about curves in $\mathbb{R}^2$,A question about curves in,\mathbb{R}^2,"I need to show this result: Let $\alpha :I\rightarrow \mathbb{R}^2$ a smooth curve, where $I$ is a compact interval of the real line. If $\lVert \alpha (s) - \alpha (t) \rVert$ depends only on $|s-t|$, for all $s$, $t$ in $I$, then $\alpha$ must be a subset of a line or a circle. I have tried calling $\lVert \alpha (s) - \alpha (t) \rVert=f(|s-t|)$, where $f$ is smooth but this led me nowhere. Also, I had a suggestion to fixing $t$ as $0$ and $\alpha(0)=0$ through reparametrization and a rigid movement, so I would have $\lVert\alpha(s) \rVert=f(|s|)$, $f$ is smooth; this lead to nothing also. I strongly believe I must show that the curvature of this function if constant, either $0$ (then it is a line) or it is a constant $\neq 0$ from where it is in a circle. Can someone please give me a hint?","I need to show this result: Let $\alpha :I\rightarrow \mathbb{R}^2$ a smooth curve, where $I$ is a compact interval of the real line. If $\lVert \alpha (s) - \alpha (t) \rVert$ depends only on $|s-t|$, for all $s$, $t$ in $I$, then $\alpha$ must be a subset of a line or a circle. I have tried calling $\lVert \alpha (s) - \alpha (t) \rVert=f(|s-t|)$, where $f$ is smooth but this led me nowhere. Also, I had a suggestion to fixing $t$ as $0$ and $\alpha(0)=0$ through reparametrization and a rigid movement, so I would have $\lVert\alpha(s) \rVert=f(|s|)$, $f$ is smooth; this lead to nothing also. I strongly believe I must show that the curvature of this function if constant, either $0$ (then it is a line) or it is a constant $\neq 0$ from where it is in a circle. Can someone please give me a hint?",,"['differential-geometry', 'plane-curves']"
70,Example of a flat manifold with non-zero (global) holonomy group.,Example of a flat manifold with non-zero (global) holonomy group.,,"I'm having some trouble coming to terms with there being non-zero global holonomy but zero local holonomy. Is there an easy to visualize example of a manifold whose curvature is zero but has non-zero Riemann holonomy group? Or maybe a flat vector bundle on $S^1 \times S^1$ with non-trivial holonomy, which is easy to visualize?","I'm having some trouble coming to terms with there being non-zero global holonomy but zero local holonomy. Is there an easy to visualize example of a manifold whose curvature is zero but has non-zero Riemann holonomy group? Or maybe a flat vector bundle on $S^1 \times S^1$ with non-trivial holonomy, which is easy to visualize?",,"['differential-geometry', 'intuition']"
71,Is an immersed submanifold second-countable?,Is an immersed submanifold second-countable?,,"By general manifold I mean Hausdorff differential manifold not necessarily second-countable. By standard manifold I mean Hausdorff, second-countable differential manifold. So my question is, we have an injective immersion, ie with a non singular derivative, $\iota\colon M\to N$. Where $M$ is a connected general manifold and $N$ is a standard manifold. Is it true that $M$ is second-countable. Note that if we take away the connection hypothesis then it is false. If we consider $M$ to be $(0,1)\times (0,1)$ with the horizontal topology, ie open basis of the form ${a}\times U$ with U open set of $(0,1)$; $N$ to be $(0,1)\times (0,1)$ with the standard topology, and $\iota$ to be the identity then it is false. If we take away the injective hypothesis I think it is also false. I'm not really sure if it can be done, but if it is possible to wind up the long line around $\mathbb S^1$ similar to how we do with $\mathbb R$ it would be a counterexample. I've been told it can be done with Riemann manifolds. Something like: $N$ has a riemann metric because it is second-countable, $\iota(M)$ has a riemann metric induced by $N$, taking it back to $M$ by $\iota$, you get a metric in $M$ so it has to be second-countable. However I don't know anything about Riemann Geometry so I'd prefer a pure topological/differential proof. I'm interested because it allows you in the proof of the Frobenius theorem not to check about second-countable in the manifold you obtain.","By general manifold I mean Hausdorff differential manifold not necessarily second-countable. By standard manifold I mean Hausdorff, second-countable differential manifold. So my question is, we have an injective immersion, ie with a non singular derivative, $\iota\colon M\to N$. Where $M$ is a connected general manifold and $N$ is a standard manifold. Is it true that $M$ is second-countable. Note that if we take away the connection hypothesis then it is false. If we consider $M$ to be $(0,1)\times (0,1)$ with the horizontal topology, ie open basis of the form ${a}\times U$ with U open set of $(0,1)$; $N$ to be $(0,1)\times (0,1)$ with the standard topology, and $\iota$ to be the identity then it is false. If we take away the injective hypothesis I think it is also false. I'm not really sure if it can be done, but if it is possible to wind up the long line around $\mathbb S^1$ similar to how we do with $\mathbb R$ it would be a counterexample. I've been told it can be done with Riemann manifolds. Something like: $N$ has a riemann metric because it is second-countable, $\iota(M)$ has a riemann metric induced by $N$, taking it back to $M$ by $\iota$, you get a metric in $M$ so it has to be second-countable. However I don't know anything about Riemann Geometry so I'd prefer a pure topological/differential proof. I'm interested because it allows you in the proof of the Frobenius theorem not to check about second-countable in the manifold you obtain.",,"['differential-geometry', 'differential-topology']"
72,"Is the exponential map to the indefinite special orthogonal groups $SO^+(p,q)$ surjective?",Is the exponential map to the indefinite special orthogonal groups  surjective?,"SO^+(p,q)","Is the exponential map to the identity component of the special indefinite orthogonal groups $$ \mathrm{exp} \colon \mathfrak{so}(p,q) \to SO^+(p,q)$$ surjective?","Is the exponential map to the identity component of the special indefinite orthogonal groups $$ \mathrm{exp} \colon \mathfrak{so}(p,q) \to SO^+(p,q)$$ surjective?",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'special-relativity']"
73,Curvature of geodesic circles on surface with constant curvature,Curvature of geodesic circles on surface with constant curvature,,"I am trying to solve the following exercise: Prove that on a surface of constant curvature the geodesic circles have constant curvature. ""Constant curvature"" in case of the surface I take to refer to the Gaussian curvature. Now, the geodesic curvature of a curve parameterized by arc length in orthogonal coordinates is given by $$k_g(s) = \frac{1}{2 \sqrt{EG}} \left(G_u v'- E_v u' \right)+ \phi',$$ where $\cdot'$ denotes the derivative with respect to $s$, and $\phi$ is the angle the tangent of the curve makes with $x_u$. Using geodesic polar coordinates (setting $u = \rho$ and $v = \theta$), a surface with constant Gaussian curvature $K$ satisfies $$(\sqrt{G}_{\rho\rho}) + K \sqrt{G} = 0$$ Also, we get $E=1$, $F=0$, and a geodesic circle has the equation $\rho = \mathrm{const.}$ Therefore, the first equation above yields $$ k_g(s) = \frac{G_\rho \theta'}{2\sqrt{G}} $$ It seems to prove that $k_g$ is constant, you would have to show that its derivative is 0. I tried that, but the derivative gets rather ugly and I don't see how to proceed.","I am trying to solve the following exercise: Prove that on a surface of constant curvature the geodesic circles have constant curvature. ""Constant curvature"" in case of the surface I take to refer to the Gaussian curvature. Now, the geodesic curvature of a curve parameterized by arc length in orthogonal coordinates is given by $$k_g(s) = \frac{1}{2 \sqrt{EG}} \left(G_u v'- E_v u' \right)+ \phi',$$ where $\cdot'$ denotes the derivative with respect to $s$, and $\phi$ is the angle the tangent of the curve makes with $x_u$. Using geodesic polar coordinates (setting $u = \rho$ and $v = \theta$), a surface with constant Gaussian curvature $K$ satisfies $$(\sqrt{G}_{\rho\rho}) + K \sqrt{G} = 0$$ Also, we get $E=1$, $F=0$, and a geodesic circle has the equation $\rho = \mathrm{const.}$ Therefore, the first equation above yields $$ k_g(s) = \frac{G_\rho \theta'}{2\sqrt{G}} $$ It seems to prove that $k_g$ is constant, you would have to show that its derivative is 0. I tried that, but the derivative gets rather ugly and I don't see how to proceed.",,['differential-geometry']
74,How to induce a connection on a submanifold?,How to induce a connection on a submanifold?,,"Suppose an affine connection is given on a smooth manifold $M$ and let $N\subset M$ be an embedded submanifold. Is there a canonical way of defining an induced connection on $N$? In classical differential geometry of smooth surfaces in Euclidean 3-space, the corresponding construction is that of covariant derivative (cfr. Do Carmo, Differential geometry of curves and surfaces §4-4). The covariant derivative of a vector field along a curve on the surface is defined as the orthogonal projection of the ordinary Euclidean derivative onto the plane tangent to the surfaces. I wonder how (and if) this can be ported to the language of connections. Wikipedia's entry does something like that by means of the Riemannian structure: I wonder if this extra structure is really necessary.","Suppose an affine connection is given on a smooth manifold $M$ and let $N\subset M$ be an embedded submanifold. Is there a canonical way of defining an induced connection on $N$? In classical differential geometry of smooth surfaces in Euclidean 3-space, the corresponding construction is that of covariant derivative (cfr. Do Carmo, Differential geometry of curves and surfaces §4-4). The covariant derivative of a vector field along a curve on the surface is defined as the orthogonal projection of the ordinary Euclidean derivative onto the plane tangent to the surfaces. I wonder how (and if) this can be ported to the language of connections. Wikipedia's entry does something like that by means of the Riemannian structure: I wonder if this extra structure is really necessary.",,"['differential-geometry', 'riemannian-geometry']"
75,Compact Lie group bi-invariant metric,Compact Lie group bi-invariant metric,,"Let $G$ be a compact Lie group and $\left\langle ,\right\rangle $ be a left invariant metric on $G$; $\omega$ be a positive differential $n$-form on $G$ which is left invariant. Consider the metric $(,)$ on $G$ given by: $$ \left(u,v\right)=\int_{G}\left\langle (dR_{x})_{y}u,(dR_{x})_{y}v\right\rangle _{yx}\omega$$  It's not too hard to show that this is left-invariant but I'm wondering how to show that $\left(,\right)$ is right-invariant?","Let $G$ be a compact Lie group and $\left\langle ,\right\rangle $ be a left invariant metric on $G$; $\omega$ be a positive differential $n$-form on $G$ which is left invariant. Consider the metric $(,)$ on $G$ given by: $$ \left(u,v\right)=\int_{G}\left\langle (dR_{x})_{y}u,(dR_{x})_{y}v\right\rangle _{yx}\omega$$  It's not too hard to show that this is left-invariant but I'm wondering how to show that $\left(,\right)$ is right-invariant?",,"['differential-geometry', 'riemannian-geometry']"
76,Geodesics and Distance in Hyperbolic Space,Geodesics and Distance in Hyperbolic Space,,"I am trying to understand geodesics and distance in hyperbolic space $H^n$ (Inverse image of $-1$ under $f(x_0,x_1,\dots,x_n)=-x_0^2+x_1^2+\dots+x_n^2$ and with the inherited metric). More precisely, I want to show that the Riemann distance between two points $p,q$ is $d(p,q)=arccosh(-p\cdot q)$ . Easy I thought, just compute the geodesics between two points $p,q$ and evaluate the length. However, I don't really understand how to do this and would appreciate some help. How do I get a nice analytical formula which I can just ""evaluate"" to obtain the distance? In all the books I've read there are only very geometric arguments which don't really produce formulas and I don't really understand how to go between the two...","I am trying to understand geodesics and distance in hyperbolic space (Inverse image of under and with the inherited metric). More precisely, I want to show that the Riemann distance between two points is . Easy I thought, just compute the geodesics between two points and evaluate the length. However, I don't really understand how to do this and would appreciate some help. How do I get a nice analytical formula which I can just ""evaluate"" to obtain the distance? In all the books I've read there are only very geometric arguments which don't really produce formulas and I don't really understand how to go between the two...","H^n -1 f(x_0,x_1,\dots,x_n)=-x_0^2+x_1^2+\dots+x_n^2 p,q d(p,q)=arccosh(-p\cdot q) p,q","['differential-geometry', 'riemannian-geometry']"
77,On the definition of the geodesic curvature and its relation to concepts from Riemannian geometry,On the definition of the geodesic curvature and its relation to concepts from Riemannian geometry,,"In the paper that can be found in this link: https://arxiv.org/pdf/1712.00082.pdf there is a definition of the geodesic curvature that I can't quite understand. Here is how this article presents it: Let $\vec{X}(s)$ be a curve on a 2D manifold in $R^3$ which is parametrized by  the arc length $s$ as shown in the following figure. Choose a vector function $\vec{V}(s)$ living in the tangent space at the position $\vec{X}(s)$ and is paralely transported along the curve. Then $k_g=\frac{d\theta}{ds}$, where $\theta$ is the angle between the velocity vector $\vec{T}=\frac{d\vec{X}(s)}{ds}$ and $\vec{V}(s)$, is defined as the geodesic curvature. The paper states that the geodesic curvature $k_g$  reflects the deviation of the curve from the local geodesics. What I don't understand are the following: $1)$ Since $\vec{T}=\frac{d\vec{X}(s)}{ds}$ and $\vec{V}(s)$ are both parallely transported along the curve(former is a velocity vector and later is given), then shouldn't the angle between them remain constant? In Riemannian geometry, when we parallel transport a vector along a curve, its angle with the velocity vector of the curve remain constant. Is it that the author might not use an affine connection that is compatible with the metric, which is the property that an affine connection needs in order to preserve lengths of vectors and angles between vectors during parallel transport? (see for example Do Carmo's Riemannian geometry, p.53 on Riemannian connections) $2)$ How does the geodesic curvature relate to the Riemannian curvature found in Riemannian geometry? Also, is it an intrinsic quantity or an extrinsic one? Finally, how does it generalize to higher-dimensional manifolds that are not embedded in higher-dimensional manifolds?","In the paper that can be found in this link: https://arxiv.org/pdf/1712.00082.pdf there is a definition of the geodesic curvature that I can't quite understand. Here is how this article presents it: Let $\vec{X}(s)$ be a curve on a 2D manifold in $R^3$ which is parametrized by  the arc length $s$ as shown in the following figure. Choose a vector function $\vec{V}(s)$ living in the tangent space at the position $\vec{X}(s)$ and is paralely transported along the curve. Then $k_g=\frac{d\theta}{ds}$, where $\theta$ is the angle between the velocity vector $\vec{T}=\frac{d\vec{X}(s)}{ds}$ and $\vec{V}(s)$, is defined as the geodesic curvature. The paper states that the geodesic curvature $k_g$  reflects the deviation of the curve from the local geodesics. What I don't understand are the following: $1)$ Since $\vec{T}=\frac{d\vec{X}(s)}{ds}$ and $\vec{V}(s)$ are both parallely transported along the curve(former is a velocity vector and later is given), then shouldn't the angle between them remain constant? In Riemannian geometry, when we parallel transport a vector along a curve, its angle with the velocity vector of the curve remain constant. Is it that the author might not use an affine connection that is compatible with the metric, which is the property that an affine connection needs in order to preserve lengths of vectors and angles between vectors during parallel transport? (see for example Do Carmo's Riemannian geometry, p.53 on Riemannian connections) $2)$ How does the geodesic curvature relate to the Riemannian curvature found in Riemannian geometry? Also, is it an intrinsic quantity or an extrinsic one? Finally, how does it generalize to higher-dimensional manifolds that are not embedded in higher-dimensional manifolds?",,"['differential-geometry', 'riemannian-geometry', 'curvature', 'connections']"
78,How does a metric tensor describe geometry on a manifold?,How does a metric tensor describe geometry on a manifold?,,"I’m fairly new to the subject to the area of differential geometry, but as I understand it, the metric tensor $g$ is a tensor field that acts on the tangent space $T_{p}M$ to each point $p$ on a (Riemannian) manifold $M$. Specifically, it is defined as a mapping $g:T_{p}M\times T_{p}M\rightarrow\mathbb{R}$ such that $(v,w)\mapsto g(v,w)$ where $v,w \in T_{p}M$. The metric tensor intuitively gives the inner product of two vectors in a vector space, and thus can be used to determine magnitudes of vectors as well as the angle between intersecting curves tangent to two tangent vectors at a given point. What I’m really unsure about is how the metric actually describes geometry on the manifold $M$? I know that one can choose a set of basis vectors adapted to a given set of coordinates on the manifold, a coordinate basis, such that the metric takes the form $$g=g_{\mu\nu}(x)dx^{\mu}\otimes dx^{\nu}\equiv g_{\mu\nu}(x)dx^{\mu}dx^{\nu}$$ where $g_{\mu\nu}(x)=g\left(\frac{\partial}{\partial x^{\mu}}, \frac{\partial}{\partial x^{\nu}}\right)$. But this just gives the metric tensor at a point. How can one use $g_{\mu\nu}(x)$ in the entire coordinate chart? Or is the point that one evaluates $g_{\mu\nu}(x)$ at each point lying within the domain of the coordinate chart?","I’m fairly new to the subject to the area of differential geometry, but as I understand it, the metric tensor $g$ is a tensor field that acts on the tangent space $T_{p}M$ to each point $p$ on a (Riemannian) manifold $M$. Specifically, it is defined as a mapping $g:T_{p}M\times T_{p}M\rightarrow\mathbb{R}$ such that $(v,w)\mapsto g(v,w)$ where $v,w \in T_{p}M$. The metric tensor intuitively gives the inner product of two vectors in a vector space, and thus can be used to determine magnitudes of vectors as well as the angle between intersecting curves tangent to two tangent vectors at a given point. What I’m really unsure about is how the metric actually describes geometry on the manifold $M$? I know that one can choose a set of basis vectors adapted to a given set of coordinates on the manifold, a coordinate basis, such that the metric takes the form $$g=g_{\mu\nu}(x)dx^{\mu}\otimes dx^{\nu}\equiv g_{\mu\nu}(x)dx^{\mu}dx^{\nu}$$ where $g_{\mu\nu}(x)=g\left(\frac{\partial}{\partial x^{\mu}}, \frac{\partial}{\partial x^{\nu}}\right)$. But this just gives the metric tensor at a point. How can one use $g_{\mu\nu}(x)$ in the entire coordinate chart? Or is the point that one evaluates $g_{\mu\nu}(x)$ at each point lying within the domain of the coordinate chart?",,"['differential-geometry', 'metric-spaces', 'riemannian-geometry']"
79,Advanced beginners textbook on Lie theory from a geometric viewpoint,Advanced beginners textbook on Lie theory from a geometric viewpoint,,"There are several questions resembling this one but none of them are quite the same I believe. I have a background in differential geometry and topology, as well as analysis (locally convex spaces). I have a very basic familiarity with lie groups since they tend to pop out quite a lot in differential geometry. Lately I found out I have a tendency to think about a lot of problems in differential geometry in terms of lie groups. Unfortunately whenever I do that kind of thing i get stuck due to a lack of solid background. I've decided to pick up a serious text on lie theory and fill this gap. I prefer a book that would help me understand the geometry better rather than the algebraic framework. Here is a list of the applications I have in mind for the theory. Recognizing homogeneous spaces, describing them in terms of coset spaces and proving stuff about them using that information. (For example the answer to this MSE question ) Spin geometry and symplectic geometry. G-bundles and gauge theory. Holonomy groups and Riemannian symmetric spaces. Prefarably the book would contain some exercise problems besides the theory.","There are several questions resembling this one but none of them are quite the same I believe. I have a background in differential geometry and topology, as well as analysis (locally convex spaces). I have a very basic familiarity with lie groups since they tend to pop out quite a lot in differential geometry. Lately I found out I have a tendency to think about a lot of problems in differential geometry in terms of lie groups. Unfortunately whenever I do that kind of thing i get stuck due to a lack of solid background. I've decided to pick up a serious text on lie theory and fill this gap. I prefer a book that would help me understand the geometry better rather than the algebraic framework. Here is a list of the applications I have in mind for the theory. Recognizing homogeneous spaces, describing them in terms of coset spaces and proving stuff about them using that information. (For example the answer to this MSE question ) Spin geometry and symplectic geometry. G-bundles and gauge theory. Holonomy groups and Riemannian symmetric spaces. Prefarably the book would contain some exercise problems besides the theory.",,"['differential-geometry', 'representation-theory', 'lie-groups', 'lie-algebras', 'book-recommendation']"
80,Sections of associated bundles,Sections of associated bundles,,"Let $\pi:P\rightarrow M$ be a Principal bundle and $\pi_V:P\times_G F\rightarrow M$ be its associated bundle via the representation $\rho:G\rightarrow GL(V)$. Fact: $\Gamma(P\times_G V)\simeq\{f:P\rightarrow V: f(pg)=\rho(g^{-1})f(p)\}=:A$ I am trying to get a better understanding of this statement. Suppose $f\in A$. We want to show that this $f$ corresponds to a unique $\sigma\in \Gamma(P\times_G V)$. So unless I'm mistaken, given $f$, we want to construct a map $\sigma:M\rightarrow P\times_G V$ such that $\pi_V\circ \sigma=\text{id}$. Based on lecture notes found here , I think the first step in this process is to define the map $F:P\rightarrow P\times_G V$ by $F=[\text{id}\times f]$. Then $F(pg)=[pg,\rho(g^{-1})f(p)]=[p,f(p)]=F(p)$ The lecture notes then say this map 'descends' to a section $\sigma:M\rightarrow P\times_G V$. I am wondering how to construct this 'descent'? Is it done by defining $\sigma=F\circ \pi^{-1}$? Does this make sense? It seems to be 'well defined' since we just take any $x\in M$ to its fiber which is then mapped uniquely to an equivalence class. Just seems a bit dodgy as $\pi^{-1}$ isn't a function per say. Conversely, if $\sigma\in \Gamma(P\times_G V)$, then $\sigma$ 'lifts' to a map $F:P\rightarrow P\times_G V$ and since $\pi_F\circ \sigma=\text{id}$, it follows that $F=\text{id}\times f$. I can't seem to get my head around this explanation of the converse argument and I am hoping someone is able to help me.","Let $\pi:P\rightarrow M$ be a Principal bundle and $\pi_V:P\times_G F\rightarrow M$ be its associated bundle via the representation $\rho:G\rightarrow GL(V)$. Fact: $\Gamma(P\times_G V)\simeq\{f:P\rightarrow V: f(pg)=\rho(g^{-1})f(p)\}=:A$ I am trying to get a better understanding of this statement. Suppose $f\in A$. We want to show that this $f$ corresponds to a unique $\sigma\in \Gamma(P\times_G V)$. So unless I'm mistaken, given $f$, we want to construct a map $\sigma:M\rightarrow P\times_G V$ such that $\pi_V\circ \sigma=\text{id}$. Based on lecture notes found here , I think the first step in this process is to define the map $F:P\rightarrow P\times_G V$ by $F=[\text{id}\times f]$. Then $F(pg)=[pg,\rho(g^{-1})f(p)]=[p,f(p)]=F(p)$ The lecture notes then say this map 'descends' to a section $\sigma:M\rightarrow P\times_G V$. I am wondering how to construct this 'descent'? Is it done by defining $\sigma=F\circ \pi^{-1}$? Does this make sense? It seems to be 'well defined' since we just take any $x\in M$ to its fiber which is then mapped uniquely to an equivalence class. Just seems a bit dodgy as $\pi^{-1}$ isn't a function per say. Conversely, if $\sigma\in \Gamma(P\times_G V)$, then $\sigma$ 'lifts' to a map $F:P\rightarrow P\times_G V$ and since $\pi_F\circ \sigma=\text{id}$, it follows that $F=\text{id}\times f$. I can't seem to get my head around this explanation of the converse argument and I am hoping someone is able to help me.",,"['differential-geometry', 'manifolds', 'lie-groups', 'principal-bundles']"
81,Why is the Riemann curvature tensor the technical expression of curvature?,Why is the Riemann curvature tensor the technical expression of curvature?,,"According to my textbook on general relativity (Sean Carrol's book) and differential geometry, the Reimann curvature tensor is the technical expression of curvature. What makes the tensor so special? Why is the Riemann curvature tensor the technical expression of curvature?","According to my textbook on general relativity (Sean Carrol's book) and differential geometry, the Reimann curvature tensor is the technical expression of curvature. What makes the tensor so special? Why is the Riemann curvature tensor the technical expression of curvature?",,['differential-geometry']
82,Equivalent definitions of vector field,Equivalent definitions of vector field,,"There are two definitions of a vector field on a smooth manifold $M$. A smooth map $V:M \rightarrow TM, \forall p \in M:V(p) \in T_p M$. A linear map $V:C^{\infty}(M) \rightarrow C^{\infty}(M), \forall f,g:V(fg)=fV(g)+gV(f)$ I can't undestand why they are equivalent. We must somehow build $2$ maps and show that their composition is $id$, but i don't have any ideas how. Please help.","There are two definitions of a vector field on a smooth manifold $M$. A smooth map $V:M \rightarrow TM, \forall p \in M:V(p) \in T_p M$. A linear map $V:C^{\infty}(M) \rightarrow C^{\infty}(M), \forall f,g:V(fg)=fV(g)+gV(f)$ I can't undestand why they are equivalent. We must somehow build $2$ maps and show that their composition is $id$, but i don't have any ideas how. Please help.",,"['differential-geometry', 'riemannian-geometry']"
83,On the definition of a geodesic in a metric space,On the definition of a geodesic in a metric space,,"I am interested in the definition of geodesics in metric spaces. A definition which seems reasonable to me is that a geodesic should locally be a distance minimizer. Wikipedia ( http://en.wikipedia.org/wiki/Geodesic#Metric_geometry ) states that this naturally leads one to define a geodesic as a curve $\gamma: I \to M$, with $I\subset \mathbb{R}$ an interval and $M$ a metric space, such that for any $t \in I$ there is a neighbourhood $J$ of $t$ so that for any $t_1, t_2 \in J$ we have $$ d(\gamma(t_1), \gamma(t_2)) = v |t_1 -t_2|, $$ where $v \geq 0$ is any constant. Am I missing something obvious? Why is it that a curve satisfying this formula is locally minimizing the distance between its points? I have no reason to think this is false, but also no intuition as to why this is true. Thank you in advance!","I am interested in the definition of geodesics in metric spaces. A definition which seems reasonable to me is that a geodesic should locally be a distance minimizer. Wikipedia ( http://en.wikipedia.org/wiki/Geodesic#Metric_geometry ) states that this naturally leads one to define a geodesic as a curve $\gamma: I \to M$, with $I\subset \mathbb{R}$ an interval and $M$ a metric space, such that for any $t \in I$ there is a neighbourhood $J$ of $t$ so that for any $t_1, t_2 \in J$ we have $$ d(\gamma(t_1), \gamma(t_2)) = v |t_1 -t_2|, $$ where $v \geq 0$ is any constant. Am I missing something obvious? Why is it that a curve satisfying this formula is locally minimizing the distance between its points? I have no reason to think this is false, but also no intuition as to why this is true. Thank you in advance!",,"['differential-geometry', 'metric-spaces']"
84,Submanifold of a regular value of a manifold with boundary,Submanifold of a regular value of a manifold with boundary,,"Question: Suppose $M$ is a smooth manifold with boundary, $N$ is a smooth manifold, and $F:M\rightarrow N$ is a smooth map. Let $S=F^{-1}(c)$, where $c\in N$ is a regular value of both $F$ and $F\left|_{\partial M}\right. $. Prove that $S$ is a smooth submanifold with boundary in $M$, with $\partial S=S\cap \partial M$. Work: OK so let $n=\dim(N)$ and $m=\dim(M)$ and let $c$ be a   regular value of both $F$ and $F\left|_{\partial M}\right.$. Then there are charts $(U,\phi)$ and $(V,\psi)$ centered at $c$ and $F(c)$ such that $c\in U$ and $F(U)\subset V$. Note that $(U,\phi)$ is a boundary chart for $M$. We have that the function $\widetilde{F}=\psi\circ F\circ\phi^{-1} $ is smooth so there is an open neighborhood $U'$ of $\phi(c)$ such that there is an smooth extension of $G$ of $\widetilde{F}$ on $U'$. Notice that we have that $G^{-1}(c)\cap H^{m}=\widetilde{F}^{-1}(c)\cap U'$. Now this is where I'm stuck, not sure where to go from here any tips?","Question: Suppose $M$ is a smooth manifold with boundary, $N$ is a smooth manifold, and $F:M\rightarrow N$ is a smooth map. Let $S=F^{-1}(c)$, where $c\in N$ is a regular value of both $F$ and $F\left|_{\partial M}\right. $. Prove that $S$ is a smooth submanifold with boundary in $M$, with $\partial S=S\cap \partial M$. Work: OK so let $n=\dim(N)$ and $m=\dim(M)$ and let $c$ be a   regular value of both $F$ and $F\left|_{\partial M}\right.$. Then there are charts $(U,\phi)$ and $(V,\psi)$ centered at $c$ and $F(c)$ such that $c\in U$ and $F(U)\subset V$. Note that $(U,\phi)$ is a boundary chart for $M$. We have that the function $\widetilde{F}=\psi\circ F\circ\phi^{-1} $ is smooth so there is an open neighborhood $U'$ of $\phi(c)$ such that there is an smooth extension of $G$ of $\widetilde{F}$ on $U'$. Notice that we have that $G^{-1}(c)\cap H^{m}=\widetilde{F}^{-1}(c)\cap U'$. Now this is where I'm stuck, not sure where to go from here any tips?",,"['differential-geometry', 'manifolds']"
85,Smooth maps (between manifolds) are continuous (comment in Barrett O'Neill's textbook),Smooth maps (between manifolds) are continuous (comment in Barrett O'Neill's textbook),,"(Needless to say, I'm a total newbie in differential geometry so I apologize if this seems rather too obvious to many of you). As a comment on his definition of smooth mapping, Barrett O'Neill in his Semi-Riemannian Geometry book states that smooth mappings are continuous. I've been thinking how to prove it, to no avail. His definition is: ""A mapping $\phi:M\longrightarrow N$ is smooth provided that for every coordinate system $\xi$ in M and $\eta$ in N the coordinate expression $\eta\circ\phi\circ\xi^{-1}$ is Euclidean smooth (and defined on an open set of $\mathbb{R}^m$ [which I assume to be $\xi(U)$ where $U$ is the domain of $\xi$] )."" In his definition of smooth manifolds the set $M$ has a topology, and the rest I assume you know (atlas, smooth overlap, etc.). Thank you very much.","(Needless to say, I'm a total newbie in differential geometry so I apologize if this seems rather too obvious to many of you). As a comment on his definition of smooth mapping, Barrett O'Neill in his Semi-Riemannian Geometry book states that smooth mappings are continuous. I've been thinking how to prove it, to no avail. His definition is: ""A mapping $\phi:M\longrightarrow N$ is smooth provided that for every coordinate system $\xi$ in M and $\eta$ in N the coordinate expression $\eta\circ\phi\circ\xi^{-1}$ is Euclidean smooth (and defined on an open set of $\mathbb{R}^m$ [which I assume to be $\xi(U)$ where $U$ is the domain of $\xi$] )."" In his definition of smooth manifolds the set $M$ has a topology, and the rest I assume you know (atlas, smooth overlap, etc.). Thank you very much.",,"['differential-geometry', 'manifolds']"
86,Need help with planning self study for learning differential/Riemannian geometry and General Relativity rigorously.,Need help with planning self study for learning differential/Riemannian geometry and General Relativity rigorously.,,"I would like to learn Mathematics for understanding GR, Differential Geometry, Riemannian Geometry and related research papers rigorously . I would like to carve out a clear path to understand these topics by listing out all the necessary prerequisites. I have undergrad Math under my belt such as: Real Analysis, Algebra, Topology and ODEs. I am missing intro to PDEs at this point. I have also created a diagram of the prerequisites in which each bubble represents a subject along with textbooks written in blue. Please take a look at the attached image/file. UG means ""Undergrad"" in the diagram. Specifically, I need help with the following questions: Is my goal (the center bubble) well defined? I know it may not be specific enough yet, but I have tried to list down some topics I am interested in RED color. Have I listed all the subjects? Am I missing any subject? Is Lie Groups worthy of mention here? Or, would it just fit under Algebra ? Is Hyperbolic Geometry worthy of mention here? Is it relevant? How do I learn it? Any textbooks for it? Would anyone please help me break down the following subjects into specific topics that are necessary for my goal: Manifolds, Riemannian Geometry, Real Analysis (grad version), PDEs (grad version), Algebra (grad version).","I would like to learn Mathematics for understanding GR, Differential Geometry, Riemannian Geometry and related research papers rigorously . I would like to carve out a clear path to understand these topics by listing out all the necessary prerequisites. I have undergrad Math under my belt such as: Real Analysis, Algebra, Topology and ODEs. I am missing intro to PDEs at this point. I have also created a diagram of the prerequisites in which each bubble represents a subject along with textbooks written in blue. Please take a look at the attached image/file. UG means ""Undergrad"" in the diagram. Specifically, I need help with the following questions: Is my goal (the center bubble) well defined? I know it may not be specific enough yet, but I have tried to list down some topics I am interested in RED color. Have I listed all the subjects? Am I missing any subject? Is Lie Groups worthy of mention here? Or, would it just fit under Algebra ? Is Hyperbolic Geometry worthy of mention here? Is it relevant? How do I learn it? Any textbooks for it? Would anyone please help me break down the following subjects into specific topics that are necessary for my goal: Manifolds, Riemannian Geometry, Real Analysis (grad version), PDEs (grad version), Algebra (grad version).",,"['differential-geometry', 'reference-request', 'soft-question', 'riemannian-geometry', 'general-relativity']"
87,defining smooth functions on manifolds *without* smooth chart transitions,defining smooth functions on manifolds *without* smooth chart transitions,,"Let $M$ be a topological manifold, covered by an atlas of charts ${(U,\phi_U)}$ (which are homeomorphisms into Euclidean space), and let $p\in M$. Say a function $f:M\to\mathbb{R}$ is smooth at $p$ if $f\circ\phi^{-1}$ is smooth for all charts in the atlas that contain $p$. (Note that this definition says nothing about smooth chart transitions on the domain where two charts overlap.) This definition is enough to pick out a collection of smooth functions on $M$. So it must be that we don't need the apparatus of smooth atlases, i.e. atlases composed of charts with smooth transitions, just to talk about the collection of smooth functions on a manifold. So what do we need the extra structure for? In other words, why is this a bad definition? What do we want/need it do that it does not allow us to do? (Note that ""it doesn't allow us to talk about smooth chart transitions,"" by itself, is not an answer: it doesn't explain what we need that condition for .) For a concrete example, take $M$ to be the interval $(-2,2)\subset\mathbb{R}$ with charts $$U=(-2,1),\phi_U(x)=x\,\,\,\text{(so $\phi_U^{-1}=x$)}$$ and $$V=(-1,2),\phi_V(x)=\sqrt[3]{x}\,\,\,\text{(so $\phi_V^{-1}=x^3$)}$$ This is a topological manifold equipped with an atlas. And the definition above allows us to say which functions are smooth at, say, $x=0$ on $M$. For example, $f(x)=\sqrt[3]{x}$ is not smooth at $x=0$ according to the definition, because it fails to be smooth using the chart $U$. However, $f(x)=x$ is smooth in both charts. EDIT: I realize that one reason this definition is bad is that it requires us to check smoothness of $f$ in all charts in the atlas, whereas smooth transitions allow us to check only in one chart. I'm not dissatisfied with that response as a basis for rejecting this definition; I'm just interested in what this structure does entail, and how else it might be pathological or deviate from the usual definition. (I'm basically trying to understand how to pick out the usual notion of smoothness as requiring an atlas with smooth transitions from alternative definitions of smoothness. This is one alternative.)","Let $M$ be a topological manifold, covered by an atlas of charts ${(U,\phi_U)}$ (which are homeomorphisms into Euclidean space), and let $p\in M$. Say a function $f:M\to\mathbb{R}$ is smooth at $p$ if $f\circ\phi^{-1}$ is smooth for all charts in the atlas that contain $p$. (Note that this definition says nothing about smooth chart transitions on the domain where two charts overlap.) This definition is enough to pick out a collection of smooth functions on $M$. So it must be that we don't need the apparatus of smooth atlases, i.e. atlases composed of charts with smooth transitions, just to talk about the collection of smooth functions on a manifold. So what do we need the extra structure for? In other words, why is this a bad definition? What do we want/need it do that it does not allow us to do? (Note that ""it doesn't allow us to talk about smooth chart transitions,"" by itself, is not an answer: it doesn't explain what we need that condition for .) For a concrete example, take $M$ to be the interval $(-2,2)\subset\mathbb{R}$ with charts $$U=(-2,1),\phi_U(x)=x\,\,\,\text{(so $\phi_U^{-1}=x$)}$$ and $$V=(-1,2),\phi_V(x)=\sqrt[3]{x}\,\,\,\text{(so $\phi_V^{-1}=x^3$)}$$ This is a topological manifold equipped with an atlas. And the definition above allows us to say which functions are smooth at, say, $x=0$ on $M$. For example, $f(x)=\sqrt[3]{x}$ is not smooth at $x=0$ according to the definition, because it fails to be smooth using the chart $U$. However, $f(x)=x$ is smooth in both charts. EDIT: I realize that one reason this definition is bad is that it requires us to check smoothness of $f$ in all charts in the atlas, whereas smooth transitions allow us to check only in one chart. I'm not dissatisfied with that response as a basis for rejecting this definition; I'm just interested in what this structure does entail, and how else it might be pathological or deviate from the usual definition. (I'm basically trying to understand how to pick out the usual notion of smoothness as requiring an atlas with smooth transitions from alternative definitions of smoothness. This is one alternative.)",,"['differential-geometry', 'definition']"
88,Book for Undergrad Differential Geometry,Book for Undergrad Differential Geometry,,"I am soon going to start learning differential geometry on my own (I'm trying to learn the math behind General Relativity before I take it next year).  I got the sense that a good, standard 1st book on the subject was do Carmo's Differential Geometry of Curves and Surfaces and so that was the book I planned on reading.  However I just read this question on mathoverflow, and both answers to it suggested that the professor NOT teach a class from a book like do Carmo's because it doesn't cover differential forms. Would you guys agree that I should find a book that introduces differential forms (and tensors?) given that I am an undergrad physics major who plans to study relativity theory?  If so, what books would you recommend?","I am soon going to start learning differential geometry on my own (I'm trying to learn the math behind General Relativity before I take it next year).  I got the sense that a good, standard 1st book on the subject was do Carmo's Differential Geometry of Curves and Surfaces and so that was the book I planned on reading.  However I just read this question on mathoverflow, and both answers to it suggested that the professor NOT teach a class from a book like do Carmo's because it doesn't cover differential forms. Would you guys agree that I should find a book that introduces differential forms (and tensors?) given that I am an undergrad physics major who plans to study relativity theory?  If so, what books would you recommend?",,"['reference-request', 'differential-geometry', 'book-recommendation']"
89,"Showing $\int_{-1}^1\frac{m(2m-1)x^{2m-2}(1-x^{2m})+m^2x^{4m-2}}{(m^2x^{4m-2}+1-x^{2m})\sqrt{1-x^{2m}}}dx=\pi$, algebraically","Showing , algebraically",\int_{-1}^1\frac{m(2m-1)x^{2m-2}(1-x^{2m})+m^2x^{4m-2}}{(m^2x^{4m-2}+1-x^{2m})\sqrt{1-x^{2m}}}dx=\pi,"Is there a nice algebraic way to solve the following geometrically motivated integral? $$\int_{-1}^1\frac{m(2m-1)x^{2m-2}(1-x^{2m})+m^2x^{4m-2}}{(m^2x^{4m-2}+1-x^{2m})\sqrt{1-x^{2m}}}dx,$$ where $m$ is a positive integer. In fact, this integral can be shown to be the integral of the curvature of the plane curve $x^{2m}+y^2=1, y\geq0$ , which is the angle rotated by the tangent vector of the curve as it traverses along the curve. So this integral is $\pi$ , but I would like to see some alternative, algebraic solutions.","Is there a nice algebraic way to solve the following geometrically motivated integral? where is a positive integer. In fact, this integral can be shown to be the integral of the curvature of the plane curve , which is the angle rotated by the tangent vector of the curve as it traverses along the curve. So this integral is , but I would like to see some alternative, algebraic solutions.","\int_{-1}^1\frac{m(2m-1)x^{2m-2}(1-x^{2m})+m^2x^{4m-2}}{(m^2x^{4m-2}+1-x^{2m})\sqrt{1-x^{2m}}}dx, m x^{2m}+y^2=1, y\geq0 \pi","['differential-geometry', 'definite-integrals', 'curvature']"
90,Definitions for Norm of a Tensor,Definitions for Norm of a Tensor,,"I am reading a book on differential geometry and at one point the following statement is made: $|\text{Ric} + \text{Hess}(f)|^2 \geq \frac{1}{n}|R+\Delta f|^2.$ The justification is that 'we have estimated the norm of the symmetric tensor $\text{Ric} + \text{Hess}(f)$ in terms of its trace'.  I know a bit about matrix norms and norms of bounded linear operators, but I am curious what exactly is the norm of an arbitrary tensor. Is it just the Frobenius or $l^2$ norm for an arbitrary tensor?  So if it is rank 4, you take the tensor and contract with itself over the 4 indices and take the square root of the result, but then where is the $1/n$ coming from? I know $n$ would be the dimension of the space, but why do we need to divide by this and why is the Frobenius norm always bigger than or equal to the trace (the sum of the diagonal elements in matrix terms).","I am reading a book on differential geometry and at one point the following statement is made: The justification is that 'we have estimated the norm of the symmetric tensor in terms of its trace'.  I know a bit about matrix norms and norms of bounded linear operators, but I am curious what exactly is the norm of an arbitrary tensor. Is it just the Frobenius or norm for an arbitrary tensor?  So if it is rank 4, you take the tensor and contract with itself over the 4 indices and take the square root of the result, but then where is the coming from? I know would be the dimension of the space, but why do we need to divide by this and why is the Frobenius norm always bigger than or equal to the trace (the sum of the diagonal elements in matrix terms).",|\text{Ric} + \text{Hess}(f)|^2 \geq \frac{1}{n}|R+\Delta f|^2. \text{Ric} + \text{Hess}(f) l^2 1/n n,"['differential-geometry', 'inequality', 'normed-spaces', 'tensors']"
91,Euler characteristic is equal to self-intersection number of zero-section?,Euler characteristic is equal to self-intersection number of zero-section?,,"As I recall (from Guillemin and Pollack ""Differential Topology"") the Euler characteristic of a  (for my purposes, compact and oriented) smooth manifold X is defined as $\chi(X)=I(\Delta,\Delta)$, where $I(\Delta, \Delta)$ is the intersection number of the diagonal in $X\times X$ with itself.  I have recently become interested in characteristic classes, and in the first page of the notes I'm reading, the author states this definition, and says $\chi(X)$ may equivalently be defined to be $I(X_0,X_0)$, the intersection of the zero-section in the tangent bundle of $X$ with itself.  Can anyone explain how these definitions are equivalent?","As I recall (from Guillemin and Pollack ""Differential Topology"") the Euler characteristic of a  (for my purposes, compact and oriented) smooth manifold X is defined as $\chi(X)=I(\Delta,\Delta)$, where $I(\Delta, \Delta)$ is the intersection number of the diagonal in $X\times X$ with itself.  I have recently become interested in characteristic classes, and in the first page of the notes I'm reading, the author states this definition, and says $\chi(X)$ may equivalently be defined to be $I(X_0,X_0)$, the intersection of the zero-section in the tangent bundle of $X$ with itself.  Can anyone explain how these definitions are equivalent?",,"['differential-geometry', 'manifolds', 'differential-topology', 'characteristic-classes']"
92,Integral of wedge product of two one forms on a Riemann surface,Integral of wedge product of two one forms on a Riemann surface,,"I'm having trouble verifying an elementary assertion made in this answer on MathOverflow.  It seems more like a math.stackexchange question, so I'm asking it here. Anyway, the assertion is as follows (mostly copied from the question) : ""Let $X$ be a genus $g$ surface, with $a_1$, ..., $a_g$, $b_1$, ..., $b_g$ a standard basis [for $H_1(X;\mathbb{Z})$]. Let $\omega$ and $\eta$ be two one-forms. Let $(u_1, u_2, \ldots, u_{2g})$ be the integrals $(\int_{a_1} \omega, \ldots, \int_{a_g} \omega, \int_{b_1} \omega, \ldots, \int_{b_g} \omega)$. Let $(v_1, \ldots, v_{2g})$ be the same integrals for $\eta$. Now, in terms of the $u$'s and the $v$'s, what is $\int_X \omega \wedge \eta$? The answer, which I leave for you to check, is $u_1 v_{g+1} + u_2 v_{g+2} + \cdots + u_g v_{2g} - u_{g+1} v_1 - u_{g+2} v_2 - \cdots - u_{2g} v_g$.""  Can anyone help me verify this? EDIT : On MathOverflow, David Speyer applies this to the case where $\omega$ and $\eta$ are holomorphic $1$-forms, and thus closed.  Maybe this condition is necessary?  It feels like one should somehow apply Stokes's theorem to the $4g$-gon obtained as a fundamental domain for the universal cover of $X$; the $a_i$ and $b_i$ will be the boundary components.  But I don't quite see how to do this. EDIT 2 : It's now been answered, but just in case someone comes across this later I thought I'd point out that the question as posed did not make any sense unless you assumed that $\omega$ and $\eta$ are closed -- otherwise, it would not make sense to integrate them along homology classes!","I'm having trouble verifying an elementary assertion made in this answer on MathOverflow.  It seems more like a math.stackexchange question, so I'm asking it here. Anyway, the assertion is as follows (mostly copied from the question) : ""Let $X$ be a genus $g$ surface, with $a_1$, ..., $a_g$, $b_1$, ..., $b_g$ a standard basis [for $H_1(X;\mathbb{Z})$]. Let $\omega$ and $\eta$ be two one-forms. Let $(u_1, u_2, \ldots, u_{2g})$ be the integrals $(\int_{a_1} \omega, \ldots, \int_{a_g} \omega, \int_{b_1} \omega, \ldots, \int_{b_g} \omega)$. Let $(v_1, \ldots, v_{2g})$ be the same integrals for $\eta$. Now, in terms of the $u$'s and the $v$'s, what is $\int_X \omega \wedge \eta$? The answer, which I leave for you to check, is $u_1 v_{g+1} + u_2 v_{g+2} + \cdots + u_g v_{2g} - u_{g+1} v_1 - u_{g+2} v_2 - \cdots - u_{2g} v_g$.""  Can anyone help me verify this? EDIT : On MathOverflow, David Speyer applies this to the case where $\omega$ and $\eta$ are holomorphic $1$-forms, and thus closed.  Maybe this condition is necessary?  It feels like one should somehow apply Stokes's theorem to the $4g$-gon obtained as a fundamental domain for the universal cover of $X$; the $a_i$ and $b_i$ will be the boundary components.  But I don't quite see how to do this. EDIT 2 : It's now been answered, but just in case someone comes across this later I thought I'd point out that the question as posed did not make any sense unless you assumed that $\omega$ and $\eta$ are closed -- otherwise, it would not make sense to integrate them along homology classes!",,"['algebraic-geometry', 'differential-geometry', 'differential-forms', 'surfaces']"
93,Existence of geodesic on a compact Riemannian manifold,Existence of geodesic on a compact Riemannian manifold,,"I have a question about the existence of geodesics on a compact Riemannian manifold $M$. Is there an elementary way to prove that in each nontrivial free homotopy class of loops, there is a closed geodesic $\gamma$ on $M$?","I have a question about the existence of geodesics on a compact Riemannian manifold $M$. Is there an elementary way to prove that in each nontrivial free homotopy class of loops, there is a closed geodesic $\gamma$ on $M$?",,"['differential-geometry', 'differential-topology']"
94,O(n) as embedded submanifold,O(n) as embedded submanifold,,"I want to show that the set of orthogonal matrices, $O(n) = \{A \in M_{n \times n} | A^tA=Id\}$, is an embedded submanifold of the set of all $n \times n$ matrices $M_{n \times n}$. So far, I have used that this set can be described as $O(n) = f^{-1}(Id)$, where $f: M_{n \times n} \rightarrow Sym_n = \{A \in M_{n \times n} | A^t = A\}$ is given by $f(A) = AA^t$, and that the map $f$ is smooth. Hence I still need to show that $Id$ is a regular point of this map, i.e. that the differential map $f_*$ (or $df$ if you wish) has maximal rank in all points of $O(n)$. How do I find this map? I tried taking a path $\gamma = A + tX$ in $O(n)$ and finding the speed of $f \circ \gamma$ at $t=0$, which appears to be $XA^t + AX^t$, but don't see how to proceed. Another way I thought of was by expressing everything as vectors in $\mathbb{R}^{n^2}$ and $\mathbb{R}^{\frac{n(n+1)}{2}}$, but the expressions got too complicated and I lost track.","I want to show that the set of orthogonal matrices, $O(n) = \{A \in M_{n \times n} | A^tA=Id\}$, is an embedded submanifold of the set of all $n \times n$ matrices $M_{n \times n}$. So far, I have used that this set can be described as $O(n) = f^{-1}(Id)$, where $f: M_{n \times n} \rightarrow Sym_n = \{A \in M_{n \times n} | A^t = A\}$ is given by $f(A) = AA^t$, and that the map $f$ is smooth. Hence I still need to show that $Id$ is a regular point of this map, i.e. that the differential map $f_*$ (or $df$ if you wish) has maximal rank in all points of $O(n)$. How do I find this map? I tried taking a path $\gamma = A + tX$ in $O(n)$ and finding the speed of $f \circ \gamma$ at $t=0$, which appears to be $XA^t + AX^t$, but don't see how to proceed. Another way I thought of was by expressing everything as vectors in $\mathbb{R}^{n^2}$ and $\mathbb{R}^{\frac{n(n+1)}{2}}$, but the expressions got too complicated and I lost track.",,"['differential-geometry', 'manifolds']"
95,Non-vanishing differential form: what does it mean?,Non-vanishing differential form: what does it mean?,,"A $1$-form $\alpha$ over a smooth manifold is non vanishing if for every $p\in M$, $\alpha_p\neq 0$. But $\alpha_p$ is a linear map $T_p M\to \mathbb R$ hence $\alpha_p(0)=0$.  So confusion arises and the precise question is: What does non vanishing mean for differential forms? And what does $\alpha\wedge..\wedge\alpha\neq 0$ mean?","A $1$-form $\alpha$ over a smooth manifold is non vanishing if for every $p\in M$, $\alpha_p\neq 0$. But $\alpha_p$ is a linear map $T_p M\to \mathbb R$ hence $\alpha_p(0)=0$.  So confusion arises and the precise question is: What does non vanishing mean for differential forms? And what does $\alpha\wedge..\wedge\alpha\neq 0$ mean?",,"['differential-geometry', 'manifolds', 'definition', 'differential-forms']"
96,Why do horizontal curves have zero covariant derivative along their projection?,Why do horizontal curves have zero covariant derivative along their projection?,,"Background: Let $(M,g)$ be a Riemannian manifold.  Let $(p,v) \in TM$ and $V, W \in T_{(p,v)}TM$.  We can introduce a Riemannian metric on $TM$ via $$\langle V, W\rangle_{(p,v)} = \langle d\pi(V), d\pi(W) \rangle_p + \left\langle \frac{D\alpha}{dt}\!(0), \frac{D\beta}{dt}\!(0)\right\rangle_p,$$ where $\alpha, \beta\colon I \to TM$ are curves in $TM$ with $\alpha(0) = \beta(0) = (p,v)$ and $\alpha'(0) = V$ and $\beta'(0) = W$, and $\pi\colon TM \to M$ is the natural projection. Given this metric on $TM$, we then call $\text{Ker}(d\pi) \subset T_{(p,v)}TM$ the vertical space , and its orthogonal complement the horizontal space .  We say that a curve $\alpha\colon I \to TM$ is horizontal iff its tangent vector $\alpha'(t) \in T_{\alpha(t)}TM$ is horizontal for all $t \in I$. Question: How can one show that a curve $\alpha\colon I \to TM$ is horizontal if and only if $\alpha$ is parallel along its projection curve $\pi\circ \alpha$? Source/Motivation: This is Problem 2(b) from Chapter 3 of do Carmo's ""Riemannian Geometry.""  It was assigned as a homework problem, and the homework was collected the other day (Oct 27), but I was unable to do the forward direction $(\implies)$ of the problem. I would especially appreciate a coordinate-free proof if possible. My Attempt: Suppose $\alpha'(t)$ is horizontal, so $\langle \alpha'(t), W \rangle_{\alpha(t)} = 0$ for any vertical vector $W \in T_{\alpha(t)}M$.  Since $d\pi(W) = 0$, we have that $0 = \langle \alpha'(t), W \rangle_{\alpha(t)} = \langle \frac{D\alpha}{dt}\!(0), \frac{D\beta}{dt}\!(0)\rangle_{(\pi\circ\alpha)(t)}$, where $\beta\colon I \to TM$ is a curve with $\beta(0) = \alpha(0)$ and $\beta'(0) = W$. It seems to me that if we chose $W$ cleverly enough, then we could perhaps conclude that $\frac{D\alpha}{dt}\!(0) = 0$, which is what we want to show. Other thoughts: Perhaps an application of Gauss' Lemma could help somewhere? While attempting to prove this problem, I conjectured that if $\alpha'(t) \in T_{\alpha(t)}TM$ is horizontal, then $d\pi(\alpha'(t)) = \alpha(t)$.  However, even if this is true -- it certainly seems likely -- I am not sure how to apply it to get a solution.","Background: Let $(M,g)$ be a Riemannian manifold.  Let $(p,v) \in TM$ and $V, W \in T_{(p,v)}TM$.  We can introduce a Riemannian metric on $TM$ via $$\langle V, W\rangle_{(p,v)} = \langle d\pi(V), d\pi(W) \rangle_p + \left\langle \frac{D\alpha}{dt}\!(0), \frac{D\beta}{dt}\!(0)\right\rangle_p,$$ where $\alpha, \beta\colon I \to TM$ are curves in $TM$ with $\alpha(0) = \beta(0) = (p,v)$ and $\alpha'(0) = V$ and $\beta'(0) = W$, and $\pi\colon TM \to M$ is the natural projection. Given this metric on $TM$, we then call $\text{Ker}(d\pi) \subset T_{(p,v)}TM$ the vertical space , and its orthogonal complement the horizontal space .  We say that a curve $\alpha\colon I \to TM$ is horizontal iff its tangent vector $\alpha'(t) \in T_{\alpha(t)}TM$ is horizontal for all $t \in I$. Question: How can one show that a curve $\alpha\colon I \to TM$ is horizontal if and only if $\alpha$ is parallel along its projection curve $\pi\circ \alpha$? Source/Motivation: This is Problem 2(b) from Chapter 3 of do Carmo's ""Riemannian Geometry.""  It was assigned as a homework problem, and the homework was collected the other day (Oct 27), but I was unable to do the forward direction $(\implies)$ of the problem. I would especially appreciate a coordinate-free proof if possible. My Attempt: Suppose $\alpha'(t)$ is horizontal, so $\langle \alpha'(t), W \rangle_{\alpha(t)} = 0$ for any vertical vector $W \in T_{\alpha(t)}M$.  Since $d\pi(W) = 0$, we have that $0 = \langle \alpha'(t), W \rangle_{\alpha(t)} = \langle \frac{D\alpha}{dt}\!(0), \frac{D\beta}{dt}\!(0)\rangle_{(\pi\circ\alpha)(t)}$, where $\beta\colon I \to TM$ is a curve with $\beta(0) = \alpha(0)$ and $\beta'(0) = W$. It seems to me that if we chose $W$ cleverly enough, then we could perhaps conclude that $\frac{D\alpha}{dt}\!(0) = 0$, which is what we want to show. Other thoughts: Perhaps an application of Gauss' Lemma could help somewhere? While attempting to prove this problem, I conjectured that if $\alpha'(t) \in T_{\alpha(t)}TM$ is horizontal, then $d\pi(\alpha'(t)) = \alpha(t)$.  However, even if this is true -- it certainly seems likely -- I am not sure how to apply it to get a solution.",,"['differential-geometry', 'riemannian-geometry']"
97,Is there a generalization of the helix from $\mathbb{R}^3$ to $\mathbb{R}^4$?,Is there a generalization of the helix from  to ?,\mathbb{R}^3 \mathbb{R}^4,"The helix is a curve $x(t) \in \mathbb{R}^3$ defined by: $$ x(t) = \begin{bmatrix} \sin(t) \\ \cos(t) \\ t \end{bmatrix} $$ and it takes the classic shape: Does this have a natural extension from $\mathbb{R}^3$ to $\mathbb{R}^4$ ?  (Or even $\mathbb{R}^n$ ?) What I've tried so far: The classic $\mathbb{R}^3$ helix curve above has two nice properties: $x(t)$ has constant distance from the axis of propagation $\hat{e}_3$ , where $\hat{e}_3 = \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}$ $x(t)$ has constant angular velocity when projected onto the plane normal to $\hat{e}_3$ .  i.e. the vector $(x_1(t), x_2(t))$ has polar coordinates $(r, \theta) = (1, t)$ , so $\dot{\theta} \equiv 1$ . The classic helix can be viewed as a parametric walk of a circle in $\mathbb{R}^2$ , with the parameter $t$ added as the third dimension.  A natural extension to a helix in $\mathbb{R}^n$ would be a parametric walk of a curve on a hypersphere in $\mathbb{R}^{n-1}$ , with parameter $t$ added as the nth dimension.  So for $\mathbb{R}^4$ , one could choose a spherical spiral to walk the sphere in $\mathbb{R}^3$ , and use parameter t as the 4th dimension: $$ x(t) = \begin{bmatrix} \sin(t) \cos(ct) \\ \sin(t) \sin(ct) \\ \cos(t) \\ t \end{bmatrix} $$ The first three components are rendered on wikipedia as: This construction matches the two properties I listed: $x(t)$ has constant distance from the axis of propagation $\hat{e}_4$ , where $\hat{e}_4 = \begin{bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{bmatrix}$ When $c=1$ , $x(t)$ has constant angular velocity when projected onto the 3-plane normal to $\hat{e}_4$ .  i.e. the vector $(x_1(t), x_2(t), x_3(t))$ has spherical coordinates $(r, \theta, \phi) = (1, t, t)$ , so $\dot{\theta} = \dot{\phi} \equiv 1$ . It's technically a direct extension of the $\mathbb{R}^3$ helix, since $c=0$ induces an identical curve (up to a projection.)  But it still feels a little arbitrary, and the closed form will be quite ugly in higher dimensions. Is there a generally accepted extension of the classical circular helix in $\mathbb{R}^3$ to $\mathbb{R}^4$ ?  (Or even $\mathbb{R}^n$ ?)  And do its properties or construction at all resemble the above? After some research, I've learned that there are interesting generalizations of helices in $\mathbb{R}^n$ , defined in terms of derivative constraints, Frenet frames, etc. such that even polynomial curves can behave as helices. [ Altunkaya and Kula 2018 ].  However, that's much more general than I'm seeking, since those are aperiodic, and may have unbounded distance from the axis of propagation.  But the existence of such work is promising - I just don't know how to search this space well.","The helix is a curve defined by: and it takes the classic shape: Does this have a natural extension from to ?  (Or even ?) What I've tried so far: The classic helix curve above has two nice properties: has constant distance from the axis of propagation , where has constant angular velocity when projected onto the plane normal to .  i.e. the vector has polar coordinates , so . The classic helix can be viewed as a parametric walk of a circle in , with the parameter added as the third dimension.  A natural extension to a helix in would be a parametric walk of a curve on a hypersphere in , with parameter added as the nth dimension.  So for , one could choose a spherical spiral to walk the sphere in , and use parameter t as the 4th dimension: The first three components are rendered on wikipedia as: This construction matches the two properties I listed: has constant distance from the axis of propagation , where When , has constant angular velocity when projected onto the 3-plane normal to .  i.e. the vector has spherical coordinates , so . It's technically a direct extension of the helix, since induces an identical curve (up to a projection.)  But it still feels a little arbitrary, and the closed form will be quite ugly in higher dimensions. Is there a generally accepted extension of the classical circular helix in to ?  (Or even ?)  And do its properties or construction at all resemble the above? After some research, I've learned that there are interesting generalizations of helices in , defined in terms of derivative constraints, Frenet frames, etc. such that even polynomial curves can behave as helices. [ Altunkaya and Kula 2018 ].  However, that's much more general than I'm seeking, since those are aperiodic, and may have unbounded distance from the axis of propagation.  But the existence of such work is promising - I just don't know how to search this space well.","x(t) \in \mathbb{R}^3 
x(t) = \begin{bmatrix}
\sin(t) \\
\cos(t) \\
t
\end{bmatrix}
 \mathbb{R}^3 \mathbb{R}^4 \mathbb{R}^n \mathbb{R}^3 x(t) \hat{e}_3 \hat{e}_3 = \begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix} x(t) \hat{e}_3 (x_1(t), x_2(t)) (r, \theta) = (1, t) \dot{\theta} \equiv 1 \mathbb{R}^2 t \mathbb{R}^n \mathbb{R}^{n-1} t \mathbb{R}^4 \mathbb{R}^3 
x(t) = \begin{bmatrix}
\sin(t) \cos(ct) \\
\sin(t) \sin(ct) \\
\cos(t) \\
t
\end{bmatrix}
 x(t) \hat{e}_4 \hat{e}_4 = \begin{bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{bmatrix} c=1 x(t) \hat{e}_4 (x_1(t), x_2(t), x_3(t)) (r, \theta, \phi) = (1, t, t) \dot{\theta} = \dot{\phi} \equiv 1 \mathbb{R}^3 c=0 \mathbb{R}^3 \mathbb{R}^4 \mathbb{R}^n \mathbb{R}^n","['differential-geometry', 'curves']"
98,Rank theorem on manifolds,Rank theorem on manifolds,,"Rank theorem on manifolds says that : Suppose $M$ and $N$ are two smooth manifolds of dimensions $m$ and $n$ , respectively, and $F:M\rightarrow N$ be a smooth map with constant rank $r$ . For each $p\in M$ there exists a smooth chart $(U,\varphi)$ around $p$ and a smooth chart $(V,\psi)$ around $F(p)$ such that $F(U)\subseteq V$ and $$\psi\circ F\circ \varphi^{-1}:\varphi^{-1} (U)\subseteq \mathbb{R}^m\rightarrow\psi(V)\subseteq \mathbb{R}^n$$ is given by $(a_1,\cdots,a_m)=(a_1,\cdots,a_r,0,\cdots,0)$ . There are many books where proof of this has been discussed but none of the books I have seen has proof that I feel excited. So, I am trying to produce another proof which I think is most natural. Let $p\in M$ . As $F$ is a map of constant rank, $dF_p:T_pM\rightarrow T_{F(p)}(N)$ is of rank $r$ . A Linear algebra results says that, in this case, there exists basis for $T_pM$ and a basis for $T_{F(p)}(N)$ such that $dF_p:T_pM\rightarrow T_{F(p)}N$ is represented by matrix $\begin{bmatrix}I_r&0\\0&0\end{bmatrix}$ i.e., it is given by $$(v_1,\cdots,v_r,v_{r+1},\cdots,v_m)\rightarrow (v_1,\cdots,v_r,0,\cdots,0).$$ I am almost sure that the basis of $T_pM$ and the basis of $T_{F(p)}N$ that we choose above corresponds to charts around $p$ and $F(p)$ respectively. I will try to elaborate what I said. How do we think of a basis of tangent space at a point? Given $p\in M$ , we take any chart $(U,\varphi)$ around that point given by $\varphi=(x_1,\cdots,x_n)$ and then see that $$\left\{\frac{\partial}{\partial x_i}\bigg|_p:1\leq i\leq n\right\}$$ is a basis for $T_pM$ . Now I am hoping to trace back. Given a basis of $T_pM$ can we trace back to obtain a chart $(U,\varphi)$ at $p$ . Suppose we could find that charts $(U,\varphi)$ at $p$ and $(V,\psi)$ at $F(p)$ such that the corresponding basis at tangent spaces is the choice of basis that we have made above. Let $(U,\varphi=(x_1,\cdots,x_m))$ be chart based at $p$ . Then $\{\partial/\partial x_i|_p:1\leq i\leq m\}$ is the basis of $T_pM$ that we have mentioned above and similarly $(V,\psi=(y_1,\cdots,y_n))$ be chart based at $F(p)$ and $\{\partial/\partial y_j|_{F(p)}:1\leq i\leq n\}$ is the basis of $T_{F(p)}N$ that we have mentioned above. So, we have $$dF_p(a_1,\cdots,a_m)=(a_1,\cdots,a_r,0,\cdots,0).$$ So, $$dF_p\left(\sum_{i=1}^ma_i\frac{\partial}{\partial x_i}\bigg|_p\right) =\sum_{i=1}^ra_i\frac{\partial}{\partial y_i}\bigg|_{F(p)}$$ $$\sum_{i=1}^ma_idF_p\left(\frac{\partial}{\partial x_i}\bigg|_p\right) =\sum_{i=1}^ra_i\frac{\partial}{\partial y_i}\bigg|_{F(p)}$$ $$\sum_{i=1}^ma_i\left(\sum_{k=1}^n\frac{\partial F^k}{\partial x_i}\frac{\partial}{\partial y^k} \bigg|_{F(p)}\right) =\sum_{i=1}^ra_i\frac{\partial}{\partial y_i}\bigg|_{F(p)}$$ Here I have assumed $F$ to be a map (locally) from $\mathbb{R}^m\rightarrow \mathbb{R}^n$ and $F^k$ are the corresponding functions of $F$ . I still do not see how to use this and conclude that $\psi\circ F\circ \varphi^{-1}(a_1,\cdots,a_m)=(a_1,\cdots,a_r,0,\cdots,0).$ Am I going in correct way? Can you suggest something to complete this proof","Rank theorem on manifolds says that : Suppose and are two smooth manifolds of dimensions and , respectively, and be a smooth map with constant rank . For each there exists a smooth chart around and a smooth chart around such that and is given by . There are many books where proof of this has been discussed but none of the books I have seen has proof that I feel excited. So, I am trying to produce another proof which I think is most natural. Let . As is a map of constant rank, is of rank . A Linear algebra results says that, in this case, there exists basis for and a basis for such that is represented by matrix i.e., it is given by I am almost sure that the basis of and the basis of that we choose above corresponds to charts around and respectively. I will try to elaborate what I said. How do we think of a basis of tangent space at a point? Given , we take any chart around that point given by and then see that is a basis for . Now I am hoping to trace back. Given a basis of can we trace back to obtain a chart at . Suppose we could find that charts at and at such that the corresponding basis at tangent spaces is the choice of basis that we have made above. Let be chart based at . Then is the basis of that we have mentioned above and similarly be chart based at and is the basis of that we have mentioned above. So, we have So, Here I have assumed to be a map (locally) from and are the corresponding functions of . I still do not see how to use this and conclude that Am I going in correct way? Can you suggest something to complete this proof","M N m n F:M\rightarrow N r p\in M (U,\varphi) p (V,\psi) F(p) F(U)\subseteq V \psi\circ F\circ \varphi^{-1}:\varphi^{-1}
(U)\subseteq \mathbb{R}^m\rightarrow\psi(V)\subseteq \mathbb{R}^n (a_1,\cdots,a_m)=(a_1,\cdots,a_r,0,\cdots,0) p\in M F dF_p:T_pM\rightarrow T_{F(p)}(N) r T_pM T_{F(p)}(N) dF_p:T_pM\rightarrow T_{F(p)}N \begin{bmatrix}I_r&0\\0&0\end{bmatrix} (v_1,\cdots,v_r,v_{r+1},\cdots,v_m)\rightarrow (v_1,\cdots,v_r,0,\cdots,0). T_pM T_{F(p)}N p F(p) p\in M (U,\varphi) \varphi=(x_1,\cdots,x_n) \left\{\frac{\partial}{\partial x_i}\bigg|_p:1\leq i\leq n\right\} T_pM T_pM (U,\varphi) p (U,\varphi) p (V,\psi) F(p) (U,\varphi=(x_1,\cdots,x_m)) p \{\partial/\partial x_i|_p:1\leq i\leq m\} T_pM (V,\psi=(y_1,\cdots,y_n)) F(p) \{\partial/\partial y_j|_{F(p)}:1\leq i\leq n\} T_{F(p)}N dF_p(a_1,\cdots,a_m)=(a_1,\cdots,a_r,0,\cdots,0). dF_p\left(\sum_{i=1}^ma_i\frac{\partial}{\partial x_i}\bigg|_p\right)
=\sum_{i=1}^ra_i\frac{\partial}{\partial y_i}\bigg|_{F(p)} \sum_{i=1}^ma_idF_p\left(\frac{\partial}{\partial x_i}\bigg|_p\right)
=\sum_{i=1}^ra_i\frac{\partial}{\partial y_i}\bigg|_{F(p)} \sum_{i=1}^ma_i\left(\sum_{k=1}^n\frac{\partial F^k}{\partial x_i}\frac{\partial}{\partial y^k} \bigg|_{F(p)}\right)
=\sum_{i=1}^ra_i\frac{\partial}{\partial y_i}\bigg|_{F(p)} F \mathbb{R}^m\rightarrow \mathbb{R}^n F^k F \psi\circ F\circ \varphi^{-1}(a_1,\cdots,a_m)=(a_1,\cdots,a_r,0,\cdots,0).",['differential-geometry']
99,Euler Characteristic of fiber bundle using Differential Geometry,Euler Characteristic of fiber bundle using Differential Geometry,,"According to the last answer to this question . It seems there is a way, using Differential Geometry, to proof that Euler Characteristic is multiplicative on fiber bundles i.e.: $$\chi(E)=\chi(F)\cdot \chi(B)$$ where $p\colon E\to B$ is a smooth fiber bundle with fiber $F$. My question: Could you give me a reference (article or book) for a proof of the multiplicativity of Euler characteristic on smooth fiber bundles which uses Riemanninan Geometry or Differential Geometry. Remark: I am aware of the proof using spectral sequences and the combinatorial one. Thanks in advance!","According to the last answer to this question . It seems there is a way, using Differential Geometry, to proof that Euler Characteristic is multiplicative on fiber bundles i.e.: $$\chi(E)=\chi(F)\cdot \chi(B)$$ where $p\colon E\to B$ is a smooth fiber bundle with fiber $F$. My question: Could you give me a reference (article or book) for a proof of the multiplicativity of Euler characteristic on smooth fiber bundles which uses Riemanninan Geometry or Differential Geometry. Remark: I am aware of the proof using spectral sequences and the combinatorial one. Thanks in advance!",,"['differential-geometry', 'reference-request', 'algebraic-topology', 'differential-topology', 'riemannian-geometry']"
