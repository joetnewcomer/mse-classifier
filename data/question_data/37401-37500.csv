,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"In what sense is the ""average"" of $\sin(x)$ equal to $0$?","In what sense is the ""average"" of  equal to ?",\sin(x) 0,"I think it makes intuitive sense that if a phenomenon is described by simple sinusoidal oscillation, it is ""on average"" equal to its midrange, but I think I failed in trying to make that statement more rigorous. Let's focus on $\sin(x)$ . In a finite interval covering an integral number of cycles, it's obvious -- we can either throw a uniform distribution on the interval or just integrate and it'll be 0. Unfortunately there's no (proper) infinite analog to the uniform distribution, and even if we use the improper version (density = 1 everywhere), the infinite integral of $\sin(x)$ strikes me as divergent because its partial sums diverge. One workaround to this I came up with is: $$\intop_{-\infty}^{\infty}\sin(x)dx = \sum_{k\in\mathbb{N}}\left(\intop_{2\pi k}^{2\pi(k+1)}\sin(x) dx\right)=0$$ But that strikes me as a bit fishy (e.g., we should require that the LHS exists before throwing an equals sign down, correct?). Is there any sense, then, in which the average of $\sin(x)=0$ ? Take a pendulum. I conjecture that if asked to guess where the pendulum is at a random time, under any symmetric, $0$ -modal loss function, your best bet would be to choose that it's in the middle.","I think it makes intuitive sense that if a phenomenon is described by simple sinusoidal oscillation, it is ""on average"" equal to its midrange, but I think I failed in trying to make that statement more rigorous. Let's focus on . In a finite interval covering an integral number of cycles, it's obvious -- we can either throw a uniform distribution on the interval or just integrate and it'll be 0. Unfortunately there's no (proper) infinite analog to the uniform distribution, and even if we use the improper version (density = 1 everywhere), the infinite integral of strikes me as divergent because its partial sums diverge. One workaround to this I came up with is: But that strikes me as a bit fishy (e.g., we should require that the LHS exists before throwing an equals sign down, correct?). Is there any sense, then, in which the average of ? Take a pendulum. I conjecture that if asked to guess where the pendulum is at a random time, under any symmetric, -modal loss function, your best bet would be to choose that it's in the middle.",\sin(x) \sin(x) \intop_{-\infty}^{\infty}\sin(x)dx = \sum_{k\in\mathbb{N}}\left(\intop_{2\pi k}^{2\pi(k+1)}\sin(x) dx\right)=0 \sin(x)=0 0,"['probability', 'average']"
1,"Combinatorics 8 men, 8 women, each choosing red or blue balls from bin","Combinatorics 8 men, 8 women, each choosing red or blue balls from bin",,"My sister posed this question to me and I'm a little surprised to be struggling so much with it. 8 men and 8 women choose balls from a bin that contains 8 blue balls and 8 red balls. After the selection is done, what is the probability of that 4 men have a red ball and 4 men have a blue ball? I was able to brute force the problem for 2 men, 2 women, 2 red and 2 blue balls (answer is 2/3) and I wrote a little script to brute force the answer for 4 men, 4 women, 4 red and 4 blue balls (answer is 20736 / 40320). I can't figure out how to generalize the count though. Any help would be much appreciated.","My sister posed this question to me and I'm a little surprised to be struggling so much with it. 8 men and 8 women choose balls from a bin that contains 8 blue balls and 8 red balls. After the selection is done, what is the probability of that 4 men have a red ball and 4 men have a blue ball? I was able to brute force the problem for 2 men, 2 women, 2 red and 2 blue balls (answer is 2/3) and I wrote a little script to brute force the answer for 4 men, 4 women, 4 red and 4 blue balls (answer is 20736 / 40320). I can't figure out how to generalize the count though. Any help would be much appreciated.",,"['probability', 'combinatorics']"
2,"If $X$ is beta distributed, how can you show that $1-X$ is also beta distributed? [closed]","If  is beta distributed, how can you show that  is also beta distributed? [closed]",X 1-X,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Can you just plug in $1-X$ into the Beta Density Function?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Can you just plug in $1-X$ into the Beta Density Function?",,['probability']
3,matching problem - find variance using indicator variables,matching problem - find variance using indicator variables,,"The question I am trying to solve is finding the $\mathsf E(X^2)$ in the matching problem (Let $X$ be the total number of matches if there are $n$ letters and $n$ envelopes randomly matched, etc). I understand using the indicator variable method in order to find that $\mathsf E(X)=1$. I am having issues figuring out why $\mathsf E(X^2)=2$ so that $\mathsf {Var}(X)=\mathsf E(X^2)-(\mathsf E(X))^2 = 1$. Any help is appreciated! Thanks.","The question I am trying to solve is finding the $\mathsf E(X^2)$ in the matching problem (Let $X$ be the total number of matches if there are $n$ letters and $n$ envelopes randomly matched, etc). I understand using the indicator variable method in order to find that $\mathsf E(X)=1$. I am having issues figuring out why $\mathsf E(X^2)=2$ so that $\mathsf {Var}(X)=\mathsf E(X^2)-(\mathsf E(X))^2 = 1$. Any help is appreciated! Thanks.",,"['probability', 'statistics', 'expectation']"
4,Is conditional probability always meaningful,Is conditional probability always meaningful,,Problem: A bag contains $4$ red and $5$ white balls. Balls are drawn from the bag without replacement. Let $A$ be the event that first ball drawn is white and let $B$ denote the event that the second ball drawn is red. Find (i) $P(B\mid A)$ (ii) $P(A\mid B)$ My confusion is that should $P(A\mid B)=P(A)$ Can we say that in general if $P(A\mid B)$ exists then $P(B\mid A)$ should also exist?,Problem: A bag contains $4$ red and $5$ white balls. Balls are drawn from the bag without replacement. Let $A$ be the event that first ball drawn is white and let $B$ denote the event that the second ball drawn is red. Find (i) $P(B\mid A)$ (ii) $P(A\mid B)$ My confusion is that should $P(A\mid B)=P(A)$ Can we say that in general if $P(A\mid B)$ exists then $P(B\mid A)$ should also exist?,,"['probability', 'probability-theory']"
5,Maximum and minimum Expected values when taking colored balls,Maximum and minimum Expected values when taking colored balls,,"We have a sack with $60$ balls. From them $15$ balls are red, $15$ green, $15$ blue and $15$ yellow. We take $30$ balls from the sack. What's the expected number of balls of the color from which the most balls had been taken? And from the color from which the least balls had been taken? Expressed in the notation I begun to solve this unsuccesfully: Let $X_i$ be a random event for the number of balls taken of the color $i$. I look for: $E[\max(X_1,X_2,X_3,X_4)]$ and $E[\min(X_1,X_2,X_3,X_4)]$ I got that $P(X_i=x)=\frac{\binom{15}{x}\binom{45}{30-x}}{\binom{60}{30}}$","We have a sack with $60$ balls. From them $15$ balls are red, $15$ green, $15$ blue and $15$ yellow. We take $30$ balls from the sack. What's the expected number of balls of the color from which the most balls had been taken? And from the color from which the least balls had been taken? Expressed in the notation I begun to solve this unsuccesfully: Let $X_i$ be a random event for the number of balls taken of the color $i$. I look for: $E[\max(X_1,X_2,X_3,X_4)]$ and $E[\min(X_1,X_2,X_3,X_4)]$ I got that $P(X_i=x)=\frac{\binom{15}{x}\binom{45}{30-x}}{\binom{60}{30}}$",,"['probability', 'combinatorics', 'statistics']"
6,"Probability that after 10,000 steps (+-1) you'll end up at the origin. How to use Central Limit Theorem?","Probability that after 10,000 steps (+-1) you'll end up at the origin. How to use Central Limit Theorem?",,"Starting at the origin and taking one step left or right with equal probability, what is the probability that you'll end up at 0 after 10,000 steps? I figured it'd be $\frac1{2^{10000}}\binom{10000}{5000}$ since you will be taking half of the steps in one direction and half in the other in no particular order and then divide the number of all possible paths that land you at 0 by the total possible number of paths. I got probability of about 0.008. But how do I get this result using central limit theorem?","Starting at the origin and taking one step left or right with equal probability, what is the probability that you'll end up at 0 after 10,000 steps? I figured it'd be $\frac1{2^{10000}}\binom{10000}{5000}$ since you will be taking half of the steps in one direction and half in the other in no particular order and then divide the number of all possible paths that land you at 0 by the total possible number of paths. I got probability of about 0.008. But how do I get this result using central limit theorem?",,"['probability', 'random-walk']"
7,Random Uniformly Distributed Points in a Circle,Random Uniformly Distributed Points in a Circle,,"I know that by just using a random angle and a random radius within the bounds of your circle, you will end up with points near the center of a circle.  Whereas if you do $\sqrt{Random(0,1)}*MaxRadius$ for your radius, you will end up with what appears to be a uniformly random point.  I am happy this works but I would like to understand where the square root comes from.  The Square Root function in this calculation seems magical to me and I would like to know what it means in this context.","I know that by just using a random angle and a random radius within the bounds of your circle, you will end up with points near the center of a circle.  Whereas if you do $\sqrt{Random(0,1)}*MaxRadius$ for your radius, you will end up with what appears to be a uniformly random point.  I am happy this works but I would like to understand where the square root comes from.  The Square Root function in this calculation seems magical to me and I would like to know what it means in this context.",,"['probability', 'polar-coordinates', 'random']"
8,Why is an entropy of $\text{log}(n)$ only compatible with the uniform distribution,Why is an entropy of  only compatible with the uniform distribution,\text{log}(n),I have a random variable $X$ and want to show that having an entropy  $$ H(X) = - \sum_{i=1}^n p_i \text{log}(p_i) = \text{log}(n)$$ is equivalent to the distribution of $X$ being uniform. Starting with the distribution is straightforward but I don't see how I can deduce the other implication.,I have a random variable $X$ and want to show that having an entropy  $$ H(X) = - \sum_{i=1}^n p_i \text{log}(p_i) = \text{log}(n)$$ is equivalent to the distribution of $X$ being uniform. Starting with the distribution is straightforward but I don't see how I can deduce the other implication.,,"['probability', 'probability-theory', 'information-theory']"
9,Limits for the integral of a joint distribution,Limits for the integral of a joint distribution,,"I'm slightly confused on how to calculate the limits of a joint probabibilty distribution (continous case). For example, the following question I'm unsure of how the limits for the respective integrals were calculated, and would appreciate if someone could talk me through how to find the limits for the integral in general. Thanks. Edit: I understand why the inner integral is from 0 to 1-y, but if I used the same principle to calculate this, shouldn't the outer integral be from 0 to 1-x? I'm simply looking for the highest and lowest values of x and y which satisfy each inequality given in the question.","I'm slightly confused on how to calculate the limits of a joint probabibilty distribution (continous case). For example, the following question I'm unsure of how the limits for the respective integrals were calculated, and would appreciate if someone could talk me through how to find the limits for the integral in general. Thanks. Edit: I understand why the inner integral is from 0 to 1-y, but if I used the same principle to calculate this, shouldn't the outer integral be from 0 to 1-x? I'm simply looking for the highest and lowest values of x and y which satisfy each inequality given in the question.",,['probability']
10,Two cards are drawn from a deck of 52. Let event A be that two cards have the same value and event B be the same suit. Are these independent?,Two cards are drawn from a deck of 52. Let event A be that two cards have the same value and event B be the same suit. Are these independent?,,"I'm not sure that I totally understand independent events. If the cards are the same suit or rank, then they have a 13/52 and 4/52 probability, respectively. However, I'm not totally sure how these two events relate to one another. I believe that they are independent.","I'm not sure that I totally understand independent events. If the cards are the same suit or rank, then they have a 13/52 and 4/52 probability, respectively. However, I'm not totally sure how these two events relate to one another. I believe that they are independent.",,['probability']
11,Choosing new teammates,Choosing new teammates,,"My sister gave me a combinatorical riddle. It doesn't appear to be hard, but I ask you if my thoughts are right, just for certainty. Here it is. Assume you belong to a group of $100$ people, and you are in a team of $10$ people, being a subset of those $100$ people. Assume that you break up, and you randomly choose people among the the $99$ persons to make a new team of $10$ persons. How big is the chance that you end up with a team without any old team mates? I thought the chance would be $$ \frac{90}{99} \cdot \frac{89}{98} \cdot \frac{88}{97} \cdots\frac{82}{91} $$ Since you have to pick out $9$ persons, and every time you pick someone from A, the chance that the person is ""new"" is $$ \frac{|A| \ - \ |\{\text{old team mates in } A\}|}{|A|} $$ Multiplying the chances gives my guess. Do you think this is right?","My sister gave me a combinatorical riddle. It doesn't appear to be hard, but I ask you if my thoughts are right, just for certainty. Here it is. Assume you belong to a group of $100$ people, and you are in a team of $10$ people, being a subset of those $100$ people. Assume that you break up, and you randomly choose people among the the $99$ persons to make a new team of $10$ persons. How big is the chance that you end up with a team without any old team mates? I thought the chance would be $$ \frac{90}{99} \cdot \frac{89}{98} \cdot \frac{88}{97} \cdots\frac{82}{91} $$ Since you have to pick out $9$ persons, and every time you pick someone from A, the chance that the person is ""new"" is $$ \frac{|A| \ - \ |\{\text{old team mates in } A\}|}{|A|} $$ Multiplying the chances gives my guess. Do you think this is right?",,"['probability', 'combinatorics', 'recreational-mathematics']"
12,Random directions on hemisphere oriented by an arbitrary vector,Random directions on hemisphere oriented by an arbitrary vector,,"Hy, i'm writing a raytracer, and for that I need to generate n random vectors that are inside an hemisphere oriented by the surface normal. Ideally, I would also like being able to restrict the rays so that the angle with the normal is <= some alpha. I don't require mathematics strictness, it can be an approximation. What I have been doing is creating an arbitrary tangent frame, and a random vector where the x and y coordinate go from -1 to 1 and the z coordinate from 0 to 1, and then multiplying it with the tangent frame, but for some reason this is making the rays to go along a direction, instead of covering the entire hemisphere. Here's some pseudo code, based on what i'm using, but removed the HLSL clumsy things: dir = normal  ray.x = GetRandomFloat(-1, 1) ray.y = GetRandomFloat(-1, 1) ray.z = GetRandomFloat(0, 1)  N = abs(normal)  if( N.z > N.x and N.z > N.y )     rt = (1, 0, 0) else     rt = (0, 0, 1)  rt = normalize(rt - normal.xzy * dot(rt, In)) rtb = cross(rt, normal.xzy)  rt.xyz = rt.xzy rtb.xyz = rtb.xzy  ray = normalize(ray.x * rbt + (ray.y * rt + (ray.z * dir))) If someone can provide some insight into this, I would be grateful. It doesn't need to be code, even a math formula will do. Also, distribution doesn't need to be uniform, just look ""good"" and 1/0 or 0/0 in some cases are allowed, as they map to INF or NaN, and I can handle that without problems. EDIT: While a PDF that fits this is interesting, it will require a random number generator based on a PDF, and that's really expensive, and not actually what I'm looking for. EDIT 2: If it can be done, it would be better not to use inverse trigonometric functions, even if it sacrifices uniformity EDIT 3: Tried Tryss method, but the results are the same, here's a screen to show what I mean: It is clear that the rays aren't generated along all directions. I'm using the second method to generate the rays, and then using the same process I had before to orientate it, that is constructing a basis change matrix from the normal and an arbitrary tangent vector. That might be what is wrong, can anyone provide some insight if the code I have posted earlier actually orients the directions from the z up hemisphere to the hemisphere oriented by the vector ""normal"" EDIT 4: I'll try to make the problem more clear. I want to generate n random rays, in an hemisphere oriented by an arbitrary direction. I do not require an uniform distribution. The first part has been answered, taking x = rand(-1,1) y = rand(-1,1) z = rand(0,1) and then normalizing, while not uniform, produces acceptable results and is fast enough. Now the second part is transforming that vector so that it is oriented by an arbitrary direction, in a way that (0,0,1) -> (nx,ny,nz) , where (nx,ny,nz) is the arbitrary vector. The coordinate system for the final vector and the arbitrary directions is a left handed system where x is left and right, z is front and back and y is up and down. I know that this matrix does the transformation I want, because I do the same coordinate change for normal mapping ( http://en.wikipedia.org/wiki/Normal_mapping ) (bitangent.x, bitangent.y, bitangent.z) (tangent.x  , tangent.y  , tangent.z  ) (normal.x   , normal.y   , normal.z   ) Where bitangent is normal X tangent The problem now is that I only have the ""normal"" vector, so I need to generate an arbitrary ""tangent"" vector to construct that matrix. How can I do that, in a way that the rays get properly transformed ( they don't biased to a direction, like in the screen I showed) ? The code I was using earlier is at the top of the page, but it produces the biasing I want to avoid.","Hy, i'm writing a raytracer, and for that I need to generate n random vectors that are inside an hemisphere oriented by the surface normal. Ideally, I would also like being able to restrict the rays so that the angle with the normal is <= some alpha. I don't require mathematics strictness, it can be an approximation. What I have been doing is creating an arbitrary tangent frame, and a random vector where the x and y coordinate go from -1 to 1 and the z coordinate from 0 to 1, and then multiplying it with the tangent frame, but for some reason this is making the rays to go along a direction, instead of covering the entire hemisphere. Here's some pseudo code, based on what i'm using, but removed the HLSL clumsy things: dir = normal  ray.x = GetRandomFloat(-1, 1) ray.y = GetRandomFloat(-1, 1) ray.z = GetRandomFloat(0, 1)  N = abs(normal)  if( N.z > N.x and N.z > N.y )     rt = (1, 0, 0) else     rt = (0, 0, 1)  rt = normalize(rt - normal.xzy * dot(rt, In)) rtb = cross(rt, normal.xzy)  rt.xyz = rt.xzy rtb.xyz = rtb.xzy  ray = normalize(ray.x * rbt + (ray.y * rt + (ray.z * dir))) If someone can provide some insight into this, I would be grateful. It doesn't need to be code, even a math formula will do. Also, distribution doesn't need to be uniform, just look ""good"" and 1/0 or 0/0 in some cases are allowed, as they map to INF or NaN, and I can handle that without problems. EDIT: While a PDF that fits this is interesting, it will require a random number generator based on a PDF, and that's really expensive, and not actually what I'm looking for. EDIT 2: If it can be done, it would be better not to use inverse trigonometric functions, even if it sacrifices uniformity EDIT 3: Tried Tryss method, but the results are the same, here's a screen to show what I mean: It is clear that the rays aren't generated along all directions. I'm using the second method to generate the rays, and then using the same process I had before to orientate it, that is constructing a basis change matrix from the normal and an arbitrary tangent vector. That might be what is wrong, can anyone provide some insight if the code I have posted earlier actually orients the directions from the z up hemisphere to the hemisphere oriented by the vector ""normal"" EDIT 4: I'll try to make the problem more clear. I want to generate n random rays, in an hemisphere oriented by an arbitrary direction. I do not require an uniform distribution. The first part has been answered, taking x = rand(-1,1) y = rand(-1,1) z = rand(0,1) and then normalizing, while not uniform, produces acceptable results and is fast enough. Now the second part is transforming that vector so that it is oriented by an arbitrary direction, in a way that (0,0,1) -> (nx,ny,nz) , where (nx,ny,nz) is the arbitrary vector. The coordinate system for the final vector and the arbitrary directions is a left handed system where x is left and right, z is front and back and y is up and down. I know that this matrix does the transformation I want, because I do the same coordinate change for normal mapping ( http://en.wikipedia.org/wiki/Normal_mapping ) (bitangent.x, bitangent.y, bitangent.z) (tangent.x  , tangent.y  , tangent.z  ) (normal.x   , normal.y   , normal.z   ) Where bitangent is normal X tangent The problem now is that I only have the ""normal"" vector, so I need to generate an arbitrary ""tangent"" vector to construct that matrix. How can I do that, in a way that the rays get properly transformed ( they don't biased to a direction, like in the screen I showed) ? The code I was using earlier is at the top of the page, but it produces the biasing I want to avoid.",,"['linear-algebra', 'probability', 'random', 'monte-carlo']"
13,Cummulative Probability 5% chance per iteration,Cummulative Probability 5% chance per iteration,,"Let's say you eat at some very cheap restaurant and every time you do there's a 5% chance you'll get food poisoning. How do you calculate the probability of getting food poisoning if you eat there x days in a row?  Obviously eating there 20 days in a row doesn't give you a 100% chance, but I'm really not sure how that kind of probability works.","Let's say you eat at some very cheap restaurant and every time you do there's a 5% chance you'll get food poisoning. How do you calculate the probability of getting food poisoning if you eat there x days in a row?  Obviously eating there 20 days in a row doesn't give you a 100% chance, but I'm really not sure how that kind of probability works.",,['probability']
14,Probability involving chess board,Probability involving chess board,,if 2 cells are chosen at random on a chess board what is the probability that they will have a common side i tried solving the question by considering different cases for the cells on: 1. corner 2. edge other than corner 3. cell in middle but i guess the cases might be repeating  so please help,if 2 cells are chosen at random on a chess board what is the probability that they will have a common side i tried solving the question by considering different cases for the cells on: 1. corner 2. edge other than corner 3. cell in middle but i guess the cases might be repeating  so please help,,"['probability', 'combinatorics', 'permutations']"
15,Independence of two normally distributed random variables,Independence of two normally distributed random variables,,"Let $X \sim \mathcal{N}(0, 1)$ and $Y$ be a random variable independent of $X$ such that   \begin{align*} P(Y=y) = \begin{cases} \frac{1}{2} & y = -1\\ \frac{1}{2} & y = 1\\ 0 & otherwise \end{cases} \end{align*}   If $Z = XY$, are $Z$ and $X$ independent? I've found that the correlation between $X$ and $Z$ is 0; however, I know that this does not say anything about their independence. From the problem, it is quite obvious that the two variables are not independent; however, I am having trouble showing this formally. I want to find some way to show $f_{X,Z}(x,z)\neq f_X(x) \cdot f_Z(z)$ for some $(x, z)$, but I'm not sure what the joint density function actually is. Since both $X$ and $Z$ follow $\mathcal{N}(0,1)$, I assume that the density function for both variables is the normal density. What, then, would be the joint density?","Let $X \sim \mathcal{N}(0, 1)$ and $Y$ be a random variable independent of $X$ such that   \begin{align*} P(Y=y) = \begin{cases} \frac{1}{2} & y = -1\\ \frac{1}{2} & y = 1\\ 0 & otherwise \end{cases} \end{align*}   If $Z = XY$, are $Z$ and $X$ independent? I've found that the correlation between $X$ and $Z$ is 0; however, I know that this does not say anything about their independence. From the problem, it is quite obvious that the two variables are not independent; however, I am having trouble showing this formally. I want to find some way to show $f_{X,Z}(x,z)\neq f_X(x) \cdot f_Z(z)$ for some $(x, z)$, but I'm not sure what the joint density function actually is. Since both $X$ and $Z$ follow $\mathcal{N}(0,1)$, I assume that the density function for both variables is the normal density. What, then, would be the joint density?",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
16,"Why does $E(XY)^2 \le E(X^2)E(Y^2)$ fail to hold for complex $X, Y$?",Why does  fail to hold for complex ?,"E(XY)^2 \le E(X^2)E(Y^2) X, Y",Does the Cauchy-Schwarz inequality hold only for real vectors? Why is that so?,Does the Cauchy-Schwarz inequality hold only for real vectors? Why is that so?,,"['probability', 'inequality', 'expectation']"
17,Probably of 2 six in 5 dice rolls,Probably of 2 six in 5 dice rolls,,"What is the probability of obtaining exatcly 2 six when rolling a dice 5 times? In order to obtain this probability, I will need to devide the number of favorable events by the number of possible events. I believe the denominator is $6^5$. But I am having troubles figuring out the numerator.","What is the probability of obtaining exatcly 2 six when rolling a dice 5 times? In order to obtain this probability, I will need to devide the number of favorable events by the number of possible events. I believe the denominator is $6^5$. But I am having troubles figuring out the numerator.",,"['probability', 'self-learning', 'dice']"
18,Applying the Law of Large Numbers?,Applying the Law of Large Numbers?,,"$X_k$, $k \geq 1$ are iid random variables such that $$\limsup_{n\rightarrow\infty} \frac{X_n}{n} < \infty$$ with probability 1. We want to show that $$\limsup_{n\rightarrow\infty} \frac{\sum_{i=1}^n X_i}{n} < \infty$$ with probability 1. The hint says to apply the law of large numbers to the sequence $\max(X_k,0), k \geq 1$. SLLN gives that $$\frac{\sum_{i=1}^n \max(X_i,0)}{n} \rightarrow \mathbb{E}\max(X,0) = \mathbb{E}(X; X>0)$$ almost surely. I feel that the idea here is that $\limsup X_n/n < \infty$ a.s. implies that $\mathbb{E}(X;X>0)$, but I am not really sure how to approach this...","$X_k$, $k \geq 1$ are iid random variables such that $$\limsup_{n\rightarrow\infty} \frac{X_n}{n} < \infty$$ with probability 1. We want to show that $$\limsup_{n\rightarrow\infty} \frac{\sum_{i=1}^n X_i}{n} < \infty$$ with probability 1. The hint says to apply the law of large numbers to the sequence $\max(X_k,0), k \geq 1$. SLLN gives that $$\frac{\sum_{i=1}^n \max(X_i,0)}{n} \rightarrow \mathbb{E}\max(X,0) = \mathbb{E}(X; X>0)$$ almost surely. I feel that the idea here is that $\limsup X_n/n < \infty$ a.s. implies that $\mathbb{E}(X;X>0)$, but I am not really sure how to approach this...",,"['probability', 'probability-theory']"
19,Probability of picking two letters from the word MATHEMATICAL [closed],Probability of picking two letters from the word MATHEMATICAL [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question If you select 3 letters (with replacement) from the word MATHEMATICAL, what is the probability of getting two 'M's.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question If you select 3 letters (with replacement) from the word MATHEMATICAL, what is the probability of getting two 'M's.",,['probability']
20,Probability: Cards,Probability: Cards,,"A 52-card deck contains 13 cards from each of the four suits: clubs , diamonds , hearts , and spades . You deal 4 cards without replacement from a well shuffled deck, so that you are equally likely to deal any 4 cards. The probability that you deal no clubs is?","A 52-card deck contains 13 cards from each of the four suits: clubs , diamonds , hearts , and spades . You deal 4 cards without replacement from a well shuffled deck, so that you are equally likely to deal any 4 cards. The probability that you deal no clubs is?",,['probability']
21,$p$-th moments and tail distribution,-th moments and tail distribution,p,"Let $X$ be a random variable. Then for the $p$-th moment $p\geq 0$ we have $\mathbb{E}(|X|^p)=p\int_0^{+\infty}x^{p-1}\,\mathrm P(|X|\geqslant x)\,\mathrm dx $ I am looking for the proof of this statement (a reference in the literature to a full proof is enough).","Let $X$ be a random variable. Then for the $p$-th moment $p\geq 0$ we have $\mathbb{E}(|X|^p)=p\int_0^{+\infty}x^{p-1}\,\mathrm P(|X|\geqslant x)\,\mathrm dx $ I am looking for the proof of this statement (a reference in the literature to a full proof is enough).",,['probability']
22,Explain the Birthday Paradox,Explain the Birthday Paradox,,"I recently read about the Birthday Paradox which states that in a group of 23 people, there's a probability of 50% that 2 people share their birthday, probability wise. I calculated and don't think it's possible that it's true in any case (unless my math is wrong). So, can anyone please tell me how to prove or disprove it mathematically ?","I recently read about the Birthday Paradox which states that in a group of 23 people, there's a probability of 50% that 2 people share their birthday, probability wise. I calculated and don't think it's possible that it's true in any case (unless my math is wrong). So, can anyone please tell me how to prove or disprove it mathematically ?",,"['probability', 'paradoxes', 'birthday']"
23,Expected number of spins,Expected number of spins,,"A spinner has 4 sectors of area 10%, 20%, 30% and 40%. What is the expected # of spins for the spinner to stop on each sector at least once ? edit If areas were equal, it'd be 4/4 +4/3 +4/2 +4/1 = 8.33 and with the unequal probabilities above, it'd be > 10 as pointed out by @Hagen, but how do we get the exact value ? edit2 I have already provided some context in the first edit. I am not a mathematician, just a puzzle aficionado, so the simpler the explanation, the better for me.","A spinner has 4 sectors of area 10%, 20%, 30% and 40%. What is the expected # of spins for the spinner to stop on each sector at least once ? edit If areas were equal, it'd be 4/4 +4/3 +4/2 +4/1 = 8.33 and with the unequal probabilities above, it'd be > 10 as pointed out by @Hagen, but how do we get the exact value ? edit2 I have already provided some context in the first edit. I am not a mathematician, just a puzzle aficionado, so the simpler the explanation, the better for me.",,['probability']
24,Probability of arriving at office before $9$ am,Probability of arriving at office before  am,9,"I'm having trouble answering this question: A person leaves for work between $8:00$ A.M. and $8:30$ A.M. and takes between $40$ and $50$ minutes to get to his office. Let $X$ denote the time of departure and let $Y$ denote the time of travel. If we assume that these random variables are independent and uniformly distributed, find the probability that he arrives at the office before $9:00$ A.M. Any help would be appreciated.","I'm having trouble answering this question: A person leaves for work between $8:00$ A.M. and $8:30$ A.M. and takes between $40$ and $50$ minutes to get to his office. Let $X$ denote the time of departure and let $Y$ denote the time of travel. If we assume that these random variables are independent and uniformly distributed, find the probability that he arrives at the office before $9:00$ A.M. Any help would be appreciated.",,"['probability', 'probability-distributions']"
25,Conditional Probability Summation Rule Problem,Conditional Probability Summation Rule Problem,,"From Blitzstein, Introduction to Probability (2019 2 edn), Chapter 2, Exercise 25, p 87. A crime is committed by one of two suspects, A and B. Initially, there is equal evidence against both of them. In further investigation at the crime scene, it is found that the guilty party had a blood type found in 10% of the population. Suspect A does match this blood type, whereas the blood type of Suspect B is unknown. (a) Given this new information, what is the probability that A is the guilty party? So here is my approach. Let $A$ stands for ""A gulity"", $M$ for ""A matching the blood type"" and $N$ for ""B matching the blood type"". Then $$P(A|M) = P(A|M,N)P(N|M) + P(A|M,N^{C})P(N^{C}|M)$$ $$P(A|M) = \frac{1}{2}\frac{1}{10} + 1\frac{9}{10} = \frac{19}{20}$$ Here it is inferred that the blood type of B is independant of that of A and that if both have the matching blood type they are equally likely to be guilty. Where is the flaw in the application of the summation rule above? The correct answer is $\frac{10}{11}$ .","From Blitzstein, Introduction to Probability (2019 2 edn), Chapter 2, Exercise 25, p 87. A crime is committed by one of two suspects, A and B. Initially, there is equal evidence against both of them. In further investigation at the crime scene, it is found that the guilty party had a blood type found in 10% of the population. Suspect A does match this blood type, whereas the blood type of Suspect B is unknown. (a) Given this new information, what is the probability that A is the guilty party? So here is my approach. Let stands for ""A gulity"", for ""A matching the blood type"" and for ""B matching the blood type"". Then Here it is inferred that the blood type of B is independant of that of A and that if both have the matching blood type they are equally likely to be guilty. Where is the flaw in the application of the summation rule above? The correct answer is .","A M N P(A|M) = P(A|M,N)P(N|M) + P(A|M,N^{C})P(N^{C}|M) P(A|M) = \frac{1}{2}\frac{1}{10} + 1\frac{9}{10} = \frac{19}{20} \frac{10}{11}","['probability', 'probability-theory', 'conditional-probability']"
26,"Density of the sum of $n$ uniform(0,1) distributed random variables","Density of the sum of  uniform(0,1) distributed random variables",n,"I am working on the following problem: Let $X_1, X_2, \ldots, X_n, \ldots$ be iid. random variables, each of Uniform$(0,1)$ distribution. Denote by $f_n(x)$ the density of the random variable $S_n := \sum_{k = 1}^n X_k$. Then    \begin{align*} f_n(x) = \frac{1}{(n-1)!} \sum_{k = 0}^{[x]} (-1)^k \binom{n}{k} (x-k)^{n-1}, \end{align*}   where $[x]$ denotes the floor function. I tried this, but I think something went wrong: Prove by induction. For $n = 1$ \begin{align*} f_1(x) = \frac{1}{(1-1)!} \sum_{k = 0}^{[x]} (-1)^k \binom{1}{k} (x-k)^{1-1} &= \sum_{k = 0}^{[x]} (-1)^k \binom{1}{k} =\begin{cases} 1, & 0 \le x < 1 \\ 0, & \text{otherwise} \end{cases} \end{align*} Furthermore \begin{align*} f_{n+1}(x) &= \mathbb P(S_{n+1} = x) = \mathbb P(S_n + X_{n+1} = x) \\ &= \sum_{m = 0}^{\infty} \mathbb P(S_n + X_{n+1} = x \mid X_{n+1} = m) \mathbb P(X_{n+1} = m) \\ &= \sum_{m = 0}^{\infty} \mathbb P(S_n + m = x)  \cdot 1_{[0,1]}(m)  = \mathbb P(S_n = x) + \mathbb P(S_n = x-1) \\ &= \frac{1}{(n-1)!} \sum_{k = 0}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} + \frac{1}{(n-1)!} \sum_{k = 0}^{[x-1]} (-1)^k\binom{n}{k}(x-1-k)^{n-1} \\ &=  \frac{1}{(n-1)!}\left(\sum_{k = 0}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} + \sum_{k = 0}^{[x]-1} (-1)^k\binom{n}{k}(x-1-k)^{n-1}\right) \\ &=  \frac{1}{(n-1)!}\left(x^{n-1}+\sum_{k = 1}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} + \sum_{k = 1}^{[x]} (-1)^{k-1}\binom{n}{k-1}(x-1-(k-1))^{n-1}\right) \\ &=  \frac{1}{(n-1)!}\left(x^{n-1}+\sum_{k = 1}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} - (-1)^{k}\binom{n}{k-1}(x-k)^{n-1}\right). \end{align*} How can I solve this? Edit: \begin{align*} f_{n+1}(x) &= (f_n * f_{X_{n+1}})(x)  = \int_{-\infty}^\infty f_{n}(y) f_{X_{n+1}}(x-y) \, dy \\ &= \int_{-\infty}^\infty \frac{1}{(n-1)!} \sum_{k = 0}^{[y]} (-1)^k \binom{n}{k}(y-k)^{n-1} \cdot 1_{(0,1)}(x-y) \, dy \\ &= \frac{1}{(n-1)!} \int_{-\infty}^{\infty} \sum_{k = 0}^{[y]} (-1)^k \binom{n}{k}(y-k)^{n-1} \cdot 1_{(x-1, x)}(y)\, dy \\ &= \frac{1}{(n-1)!} \int_{x-1}^{x} \sum_{k = 0}^{[y]} (-1)^k \binom{n}{k}(y-k)^{n-1} \, dy \end{align*} I want to swap the sum and the integral, but the sum depends on $y$.","I am working on the following problem: Let $X_1, X_2, \ldots, X_n, \ldots$ be iid. random variables, each of Uniform$(0,1)$ distribution. Denote by $f_n(x)$ the density of the random variable $S_n := \sum_{k = 1}^n X_k$. Then    \begin{align*} f_n(x) = \frac{1}{(n-1)!} \sum_{k = 0}^{[x]} (-1)^k \binom{n}{k} (x-k)^{n-1}, \end{align*}   where $[x]$ denotes the floor function. I tried this, but I think something went wrong: Prove by induction. For $n = 1$ \begin{align*} f_1(x) = \frac{1}{(1-1)!} \sum_{k = 0}^{[x]} (-1)^k \binom{1}{k} (x-k)^{1-1} &= \sum_{k = 0}^{[x]} (-1)^k \binom{1}{k} =\begin{cases} 1, & 0 \le x < 1 \\ 0, & \text{otherwise} \end{cases} \end{align*} Furthermore \begin{align*} f_{n+1}(x) &= \mathbb P(S_{n+1} = x) = \mathbb P(S_n + X_{n+1} = x) \\ &= \sum_{m = 0}^{\infty} \mathbb P(S_n + X_{n+1} = x \mid X_{n+1} = m) \mathbb P(X_{n+1} = m) \\ &= \sum_{m = 0}^{\infty} \mathbb P(S_n + m = x)  \cdot 1_{[0,1]}(m)  = \mathbb P(S_n = x) + \mathbb P(S_n = x-1) \\ &= \frac{1}{(n-1)!} \sum_{k = 0}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} + \frac{1}{(n-1)!} \sum_{k = 0}^{[x-1]} (-1)^k\binom{n}{k}(x-1-k)^{n-1} \\ &=  \frac{1}{(n-1)!}\left(\sum_{k = 0}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} + \sum_{k = 0}^{[x]-1} (-1)^k\binom{n}{k}(x-1-k)^{n-1}\right) \\ &=  \frac{1}{(n-1)!}\left(x^{n-1}+\sum_{k = 1}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} + \sum_{k = 1}^{[x]} (-1)^{k-1}\binom{n}{k-1}(x-1-(k-1))^{n-1}\right) \\ &=  \frac{1}{(n-1)!}\left(x^{n-1}+\sum_{k = 1}^{[x]} (-1)^k\binom{n}{k}(x-k)^{n-1} - (-1)^{k}\binom{n}{k-1}(x-k)^{n-1}\right). \end{align*} How can I solve this? Edit: \begin{align*} f_{n+1}(x) &= (f_n * f_{X_{n+1}})(x)  = \int_{-\infty}^\infty f_{n}(y) f_{X_{n+1}}(x-y) \, dy \\ &= \int_{-\infty}^\infty \frac{1}{(n-1)!} \sum_{k = 0}^{[y]} (-1)^k \binom{n}{k}(y-k)^{n-1} \cdot 1_{(0,1)}(x-y) \, dy \\ &= \frac{1}{(n-1)!} \int_{-\infty}^{\infty} \sum_{k = 0}^{[y]} (-1)^k \binom{n}{k}(y-k)^{n-1} \cdot 1_{(x-1, x)}(y)\, dy \\ &= \frac{1}{(n-1)!} \int_{x-1}^{x} \sum_{k = 0}^{[y]} (-1)^k \binom{n}{k}(y-k)^{n-1} \, dy \end{align*} I want to swap the sum and the integral, but the sum depends on $y$.",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
27,Expected number of rolls required to get sum greater than n for n faced die?,Expected number of rolls required to get sum greater than n for n faced die?,,Suppose a guy has a die with $n$ faces. He can go on rolling it as many times as possible and add the sum of each outcome. What is the expected number of rolls after which the sum is at least $n$?,Suppose a guy has a die with $n$ faces. He can go on rolling it as many times as possible and add the sum of each outcome. What is the expected number of rolls after which the sum is at least $n$?,,"['probability', 'dice', 'expectation']"
28,Expectation of throwing $n$ balls into $n$ bins [duplicate],Expectation of throwing  balls into  bins [duplicate],n n,"This question already has answers here : another balls and bins question (3 answers) Closed 8 years ago . Suppose we throw $n$ indistinguishable balls in $n$ bins at random. The throws are independent. What is the expected number of empty bins? What is the expected number of bins with one ball. Using indicator random variables, expectations, some sloppy math and some questionable logic, I arrive at the conclusion that both are approximately $n/e$. I'm not able to find simple formulas. It also sounds very counter-intuitive to me. Worse, I wrote a small Ruby program to simulate it and the results appear to be (approximately) correct. Can anybody show me a good solution?","This question already has answers here : another balls and bins question (3 answers) Closed 8 years ago . Suppose we throw $n$ indistinguishable balls in $n$ bins at random. The throws are independent. What is the expected number of empty bins? What is the expected number of bins with one ball. Using indicator random variables, expectations, some sloppy math and some questionable logic, I arrive at the conclusion that both are approximately $n/e$. I'm not able to find simple formulas. It also sounds very counter-intuitive to me. Worse, I wrote a small Ruby program to simulate it and the results appear to be (approximately) correct. Can anybody show me a good solution?",,"['probability', 'expectation', 'balls-in-bins']"
29,Does The Monty Hall Problem Still Apply With Infinite Doors?,Does The Monty Hall Problem Still Apply With Infinite Doors?,,"Here's been a bunch of questions on the Monty Hall problem, so I'll assume people know the basics. This answer helped clarify a few things for me, but talking with some colleagues yesterday, someone brought up the idea that as you increase the number of doors, the probability of winning the car by switching approaches 1. Intuitively, this makes sense, but I also know that infinite sets aren't always intuitive. Is it really the case that if the number of doors increases to infinity, the probability of winning approaches 1? If not, why not? EDIT: To clarify, the infinite case would look as follows: There are an infinite number of doors. One has a car behind it, the others have goats. The host knows which door has the car behind it. The contestant selects a door All doors except the selected door and an additional one are opened revealing goats. The contestant is asked if they would like to switch doors. The question is: in this case, does P(winning by switching doors) = 1? Or is this even well defined? What changes when the number of doors is large but finite?","Here's been a bunch of questions on the Monty Hall problem, so I'll assume people know the basics. This answer helped clarify a few things for me, but talking with some colleagues yesterday, someone brought up the idea that as you increase the number of doors, the probability of winning the car by switching approaches 1. Intuitively, this makes sense, but I also know that infinite sets aren't always intuitive. Is it really the case that if the number of doors increases to infinity, the probability of winning approaches 1? If not, why not? EDIT: To clarify, the infinite case would look as follows: There are an infinite number of doors. One has a car behind it, the others have goats. The host knows which door has the car behind it. The contestant selects a door All doors except the selected door and an additional one are opened revealing goats. The contestant is asked if they would like to switch doors. The question is: in this case, does P(winning by switching doors) = 1? Or is this even well defined? What changes when the number of doors is large but finite?",,"['probability', 'infinity', 'monty-hall']"
30,Can you split up expectation over multiplication? [closed],Can you split up expectation over multiplication? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I was wondering if the property exists where if you have $\ E[(Y- \mu)^3]$ you can write it as $\ E[(Y- \mu)^2] E[(Y- \mu)] $ ?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I was wondering if the property exists where if you have $\ E[(Y- \mu)^3]$ you can write it as $\ E[(Y- \mu)^2] E[(Y- \mu)] $ ?",,"['probability', 'probability-theory', 'expectation']"
31,Conditional Probability Question,Conditional Probability Question,,"EDIT!!! a)  ￼The probability that any child in a certain family will have blue eyes is 1/4, and this feature is inherited independently by different children in the family.  If there are five children in the family and it is known that at least one of these children has blue eyes, what is the probability that at least three of the children have blue eyes? b)  Consider a family with the five children just described.  If it is known that the youngest child in the family has blue eyes, what is the probability that at least three of the children have blue eyes? Hello!  I'm pretty sure I understand part (a), but I'm not sure about part b.  Since the child is actually distinguished in this case, does it change the denominator? So since its distinguished who actually has the blue eyes, namely, the young child, does the denominator just become 1/4? Actually it turns out that the denominator is actually 1.  Can someone please explain? Please note that the answers in (a) and (b) are actually different.  They are NOT the same.  It turns out that knowing who the child is actually simplifies the problem and removes the necessity of using conditionals. Thanks in advance! Part a: Let: A= event that at least 3 children have blue eyes B= event that at least 1 child has blue eyes $\therefore A \subset B$ $\Pr(A \mid B)=\cfrac{\Pr(A \cap B)}{\Pr(B)}=\cfrac{\Pr(A)}{\Pr(B)}=\cfrac{ \sum\limits_{i=3}^5 \binom{5}{i} \cdot (0.25)^i \cdot 0.75^{5-i}}{1-0.75^5}=0.1357\tag{1}$ Part b: A=event youngest child has blue eyes B=event at least 3 children have blue eyes $\Pr(A \mid B)=\cfrac{ \sum\limits_{i=2}^4 \binom{4}{i} \cdot (0.25)^i \cdot 0.75^{4-i}}{1/4??}\tag{2}$","EDIT!!! a)  ￼The probability that any child in a certain family will have blue eyes is 1/4, and this feature is inherited independently by different children in the family.  If there are five children in the family and it is known that at least one of these children has blue eyes, what is the probability that at least three of the children have blue eyes? b)  Consider a family with the five children just described.  If it is known that the youngest child in the family has blue eyes, what is the probability that at least three of the children have blue eyes? Hello!  I'm pretty sure I understand part (a), but I'm not sure about part b.  Since the child is actually distinguished in this case, does it change the denominator? So since its distinguished who actually has the blue eyes, namely, the young child, does the denominator just become 1/4? Actually it turns out that the denominator is actually 1.  Can someone please explain? Please note that the answers in (a) and (b) are actually different.  They are NOT the same.  It turns out that knowing who the child is actually simplifies the problem and removes the necessity of using conditionals. Thanks in advance! Part a: Let: A= event that at least 3 children have blue eyes B= event that at least 1 child has blue eyes Part b: A=event youngest child has blue eyes B=event at least 3 children have blue eyes",\therefore A \subset B \Pr(A \mid B)=\cfrac{\Pr(A \cap B)}{\Pr(B)}=\cfrac{\Pr(A)}{\Pr(B)}=\cfrac{ \sum\limits_{i=3}^5 \binom{5}{i} \cdot (0.25)^i \cdot 0.75^{5-i}}{1-0.75^5}=0.1357\tag{1} \Pr(A \mid B)=\cfrac{ \sum\limits_{i=2}^4 \binom{4}{i} \cdot (0.25)^i \cdot 0.75^{4-i}}{1/4??}\tag{2},['probability']
32,Balls and bins conditioned on the number of non-empty bins,Balls and bins conditioned on the number of non-empty bins,,"The expected number of occupied bins in the standard balls and bins problem (with $m$ balls into $N$ bins) is $N\left( {1 - {{\left( {1 - \frac{1}{N}} \right)}^m}} \right)$. How do I compute this expectation given that at least $k$ bins are non-empty after the $m$ balls were thrown? In particular, how do I formulate the probability that some $i^{th}$ bin is empty given that at least $k$ bins are non-empty? in addition, it seems obivious, but how do I prove that the conditional expectation is a monotonic increasing function of $k$?","The expected number of occupied bins in the standard balls and bins problem (with $m$ balls into $N$ bins) is $N\left( {1 - {{\left( {1 - \frac{1}{N}} \right)}^m}} \right)$. How do I compute this expectation given that at least $k$ bins are non-empty after the $m$ balls were thrown? In particular, how do I formulate the probability that some $i^{th}$ bin is empty given that at least $k$ bins are non-empty? in addition, it seems obivious, but how do I prove that the conditional expectation is a monotonic increasing function of $k$?",,"['probability', 'balls-in-bins']"
33,probability that broken sticks will not form a triangle.,probability that broken sticks will not form a triangle.,,"A stick of unit length is broken into two at a point chosen at random. Then, the larger part of the stick is further divided into two parts in the ratio 4:3. What is the probability that the three sticks that are left CANNOT form a triangle? in this problem i am not getting how to proceed like  what is  sample space?it is quiet confusing to me. Please give any simple view for this problem.","A stick of unit length is broken into two at a point chosen at random. Then, the larger part of the stick is further divided into two parts in the ratio 4:3. What is the probability that the three sticks that are left CANNOT form a triangle? in this problem i am not getting how to proceed like  what is  sample space?it is quiet confusing to me. Please give any simple view for this problem.",,"['probability', 'probability-theory', 'puzzle']"
34,Range of variance,Range of variance,,"If you have a random variable which takes on values in the range $[a, b]$, is it necessary that the variance be in the range $[a, b]$? What is the range of variance in general? I feel like this is important to understanding it intuitively as a measure of ``how spread out the data is"".","If you have a random variable which takes on values in the range $[a, b]$, is it necessary that the variance be in the range $[a, b]$? What is the range of variance in general? I feel like this is important to understanding it intuitively as a measure of ``how spread out the data is"".",,"['probability', 'probability-distributions']"
35,The Effect of Perspective on Probability,The Effect of Perspective on Probability,,"My friend and I are tearing each other to bits over this, hope someone can help. Coin flip experiment: Define a single trial as 10 coin flips of a fair coin. Perform an arbitrarily large number of trials. At some number of trials n, you notice that your distribution is extremely skewed in one direction (i.e., the ""average"" of your 10-flip sets is far away from 5 heads and 5 tails). My reaction: Because you are guaranteed to hit a 5H/5T mean as n approaches infinity, the probability that the next n trials contains an equal skew in the opposite direction increases. In other words, given 2*n* trials, if the first n are skewed in one direction, than the remaining n are probably skewed in the other direction such that the overall distribution of your 2*n* trials is normal and centered around 5H/5T. My friend's reaction: It doesn't matter if your first n trials is skewed, the next n trials should still represent an unmodified 5H/5T distribution regardless. The probability of the next n trials being skewed in the opposite direction is unchanged and low. Who's right, and why?","My friend and I are tearing each other to bits over this, hope someone can help. Coin flip experiment: Define a single trial as 10 coin flips of a fair coin. Perform an arbitrarily large number of trials. At some number of trials n, you notice that your distribution is extremely skewed in one direction (i.e., the ""average"" of your 10-flip sets is far away from 5 heads and 5 tails). My reaction: Because you are guaranteed to hit a 5H/5T mean as n approaches infinity, the probability that the next n trials contains an equal skew in the opposite direction increases. In other words, given 2*n* trials, if the first n are skewed in one direction, than the remaining n are probably skewed in the other direction such that the overall distribution of your 2*n* trials is normal and centered around 5H/5T. My friend's reaction: It doesn't matter if your first n trials is skewed, the next n trials should still represent an unmodified 5H/5T distribution regardless. The probability of the next n trials being skewed in the opposite direction is unchanged and low. Who's right, and why?",,"['probability', 'probability-theory']"
36,Probability notation,Probability notation,,"Hey guys, I was just wondering why in my textbook(A First Course in Probability, 8th edition) and basically everywhere I've looked at when we have some random variable(assume for the sake of the following example that it is discrete) denoted by $X$ and we want to write down the expression for the probability of $X$ assuming the value of $k$ we do it as follows:  $$P\{X=k\} = ...$$ and not as $$P(X=K)=...$$ Why the curly brackets? Does it have anything to do with sets or is it just convention? The same question applies to expected values - why $E[X]$ and not $E(X)$  although variance is usually denoted as $Var(X)$ ?","Hey guys, I was just wondering why in my textbook(A First Course in Probability, 8th edition) and basically everywhere I've looked at when we have some random variable(assume for the sake of the following example that it is discrete) denoted by $X$ and we want to write down the expression for the probability of $X$ assuming the value of $k$ we do it as follows:  $$P\{X=k\} = ...$$ and not as $$P(X=K)=...$$ Why the curly brackets? Does it have anything to do with sets or is it just convention? The same question applies to expected values - why $E[X]$ and not $E(X)$  although variance is usually denoted as $Var(X)$ ?",,"['probability', 'probability-theory', 'notation']"
37,Safes and keys probability puzzle [duplicate],Safes and keys probability puzzle [duplicate],,"This question already has answers here : Probability of opening all piggy banks (2 answers) Closed 11 years ago . I have $100$ keys and $100$ safes. Each key opens only one safe, and each safe is opened only by one key. Every safe contains a random key. 98 of these safes are locked. What's the probability that I can open all the safes? This question is confusing for me. Can you walk me through it step-by-step?","This question already has answers here : Probability of opening all piggy banks (2 answers) Closed 11 years ago . I have $100$ keys and $100$ safes. Each key opens only one safe, and each safe is opened only by one key. Every safe contains a random key. 98 of these safes are locked. What's the probability that I can open all the safes? This question is confusing for me. Can you walk me through it step-by-step?",,"['probability', 'combinatorics', 'puzzle']"
38,Rolling dice Probability that Sum,Rolling dice Probability that Sum,,"If 10 pairs of fair dice are rolled, approximate the probability that the sum of the values obtained (which ranges from 20 to 120) is between 30 and 40 inclusive. I dont know where to start with this one. I have been looking all over the web for example, but nothing i find is applicable for finding the sum of numbers. any advice would be great","If 10 pairs of fair dice are rolled, approximate the probability that the sum of the values obtained (which ranges from 20 to 120) is between 30 and 40 inclusive. I dont know where to start with this one. I have been looking all over the web for example, but nothing i find is applicable for finding the sum of numbers. any advice would be great",,"['probability', 'dice']"
39,What's the expected number of coin tosses in order to get a sequence HHTTHH?,What's the expected number of coin tosses in order to get a sequence HHTTHH?,,"Assume you have a fair coin. What's the expected number of coin tosses in order to get a sequence HHTTHH? (H=head,T=tail). Assuming you start tossing and keep going until your last six tosses match the sequence. I want to know if there is a general formula for this kinds of problems?","Assume you have a fair coin. What's the expected number of coin tosses in order to get a sequence HHTTHH? (H=head,T=tail). Assuming you start tossing and keep going until your last six tosses match the sequence. I want to know if there is a general formula for this kinds of problems?",,['probability']
40,Probability that numbers 1...6 show up at least once when rolling 8 dice,Probability that numbers 1...6 show up at least once when rolling 8 dice,,Probability that numbers 1...6 show up at least once when rolling 8 dice How can this be solved using the inclusion-exclusion principle.,Probability that numbers 1...6 show up at least once when rolling 8 dice How can this be solved using the inclusion-exclusion principle.,,"['probability', 'probability-theory', 'inclusion-exclusion']"
41,A problem on left skip free random walk with downward drift,A problem on left skip free random walk with downward drift,,"Let $X_i$, $i \geq 1$ be i.i.d random variables. Let $P_j=P(X_i = j)$ and suppose that $$\sum_{j=-1}^{\infty} P_j=1$$. That is the possible values of the $X_i$ are $-1,0,1,\dots$. If we take $$S_0=0, S_n=\sum_{i=1}^{n}X_i$$ then the sequence of random variables $S_n, n\geq 0$ is called a left skip free random walk. Also, $E[X_i] < 0$ (downward drift). We need to prove that $$P(S_n <0, \forall n \geq 1)= P(S_n \neq 0, \forall n \geq 1)$$","Let $X_i$, $i \geq 1$ be i.i.d random variables. Let $P_j=P(X_i = j)$ and suppose that $$\sum_{j=-1}^{\infty} P_j=1$$. That is the possible values of the $X_i$ are $-1,0,1,\dots$. If we take $$S_0=0, S_n=\sum_{i=1}^{n}X_i$$ then the sequence of random variables $S_n, n\geq 0$ is called a left skip free random walk. Also, $E[X_i] < 0$ (downward drift). We need to prove that $$P(S_n <0, \forall n \geq 1)= P(S_n \neq 0, \forall n \geq 1)$$",,['probability']
42,"$X$ is $\text{Exp}(\lambda)$, $Y$ is $\text{Uniform}(0,X)$. How can I find $\Bbb E[Y]$ and $\text{Var}(Y)$?","is ,  is . How can I find  and ?","X \text{Exp}(\lambda) Y \text{Uniform}(0,X) \Bbb E[Y] \text{Var}(Y)","$X$ is $\text{Exp}(\lambda)$, $Y$ is $\text{Uniform}(0,X)$. How can I find $\Bbb E[Y]$ and $\text{Var}(Y)$? I did tried to plug it like double integral of $\Bbb E[Y]$ from 0 to X which $f(t)$ is $\text{Exp}(\lambda)$. But I could not solve it. Could anyone point or hint me? Thank you","$X$ is $\text{Exp}(\lambda)$, $Y$ is $\text{Uniform}(0,X)$. How can I find $\Bbb E[Y]$ and $\text{Var}(Y)$? I did tried to plug it like double integral of $\Bbb E[Y]$ from 0 to X which $f(t)$ is $\text{Exp}(\lambda)$. But I could not solve it. Could anyone point or hint me? Thank you",,"['probability', 'probability-distributions', 'exponential-function']"
43,Probability of getting 5 multiple-choice questions answered correctly,Probability of getting 5 multiple-choice questions answered correctly,,"What is the probability of getting 5 multiple-choice questions answered correctly, if for each question the probability of answering it correctly is 1/3. The answer is 45/118, but I am unsure of how. Update : The book may have had the question worded incorrectly, because the answer stated is incorrect. What i know : Each question has 3 selections, and the probability of getting one wrong is 2/3. I thought it would be as simple as the multiplicative rule, but there's more to it apparently. I think it has to do with a formula as you go along in the questions, but it states that each probability is equal, as a 1/3 chance. Any suggestions?","What is the probability of getting 5 multiple-choice questions answered correctly, if for each question the probability of answering it correctly is 1/3. The answer is 45/118, but I am unsure of how. Update : The book may have had the question worded incorrectly, because the answer stated is incorrect. What i know : Each question has 3 selections, and the probability of getting one wrong is 2/3. I thought it would be as simple as the multiplicative rule, but there's more to it apparently. I think it has to do with a formula as you go along in the questions, but it states that each probability is equal, as a 1/3 chance. Any suggestions?",,['probability']
44,Why do I need the derivative in variable substitution for probability density function?,Why do I need the derivative in variable substitution for probability density function?,,If $y = g(x)$ and $f_X(x)$ the probability density function of X $x = g^{-1}(y);$ Then  $f_Y(y) = f_X(g^{-1}(y)) * (g^{-1})'(y)$ Why do I need to multiply by $(g^{-1})'(y)$? And not simply: $f_Y(y) = f_X(g^{-1}(y))$,If $y = g(x)$ and $f_X(x)$ the probability density function of X $x = g^{-1}(y);$ Then  $f_Y(y) = f_X(g^{-1}(y)) * (g^{-1})'(y)$ Why do I need to multiply by $(g^{-1})'(y)$? And not simply: $f_Y(y) = f_X(g^{-1}(y))$,,"['calculus', 'probability']"
45,Probability that z precedes both a and b in the permutation?,Probability that z precedes both a and b in the permutation?,,"What is the probability of the event that z precedes both a and b when we randomly select a permutation of the 26 lowercase letters of the English alphabet? Currently, my thoughts are: P(25,25)x24      There are p(25,25) ways to get certain letters of the alphabet 24 ways to place z, it can't be in the last 2 spots since it has to precede a and b .","What is the probability of the event that z precedes both a and b when we randomly select a permutation of the 26 lowercase letters of the English alphabet? Currently, my thoughts are: P(25,25)x24      There are p(25,25) ways to get certain letters of the alphabet 24 ways to place z, it can't be in the last 2 spots since it has to precede a and b .",,['probability']
46,Help me understand the (continuous) uniform distribution,Help me understand the (continuous) uniform distribution,,"I think I didn't pay attention to uniform distributions because they're too easy. So I have this problem It takes a professor a random time between 20 and 27 minutes to walk from his home to school every day. If he has a class at 9.00 a.m. and he leaves home at 8.37 a.m., find the probability that he reaches his class on time. I am not sure I know how to do it. I think I would use $F(x)$, and I tried to look up how to figure it out but could only find the answer $F(x)=(x-a)/(b-a)$. So I input the numbers and got $(23-20)/(27-20)$ which is $3/7$ but I am not sure that is the corret answer, though it seems right to me. I'm not here for homework help (I am not being graded on this problem or anything), but I do want to understand the concepts. Too often I just learn how to do math and don't ""really"" understand it. So I would like to know how to properly do uniform distribution problems (of continuous variable) and maybe how to find the $F(x)$. I thought it was the integral but I didn't get the same answer. Remember I want to understand this. Thanks so much for your time.","I think I didn't pay attention to uniform distributions because they're too easy. So I have this problem It takes a professor a random time between 20 and 27 minutes to walk from his home to school every day. If he has a class at 9.00 a.m. and he leaves home at 8.37 a.m., find the probability that he reaches his class on time. I am not sure I know how to do it. I think I would use $F(x)$, and I tried to look up how to figure it out but could only find the answer $F(x)=(x-a)/(b-a)$. So I input the numbers and got $(23-20)/(27-20)$ which is $3/7$ but I am not sure that is the corret answer, though it seems right to me. I'm not here for homework help (I am not being graded on this problem or anything), but I do want to understand the concepts. Too often I just learn how to do math and don't ""really"" understand it. So I would like to know how to properly do uniform distribution problems (of continuous variable) and maybe how to find the $F(x)$. I thought it was the integral but I didn't get the same answer. Remember I want to understand this. Thanks so much for your time.",,"['probability', 'statistics']"
47,Monty hall problem with leftmost goat selection.,Monty hall problem with leftmost goat selection.,,"We've all heard of the famous Monty Hall problem . However, what if Monty always picks the leftmost goat (and the player knows this)? Does this change the problem? I don't think it does because Monty is always picking a goat door anyway. Does that make sense?","We've all heard of the famous Monty Hall problem . However, what if Monty always picks the leftmost goat (and the player knows this)? Does this change the problem? I don't think it does because Monty is always picking a goat door anyway. Does that make sense?",,"['probability', 'monty-hall']"
48,General Addition Rule for Probability extended to 4 events?,General Addition Rule for Probability extended to 4 events?,,I just started statistics and need to use the general addition rule. I know what it looks like for $3$ events: $$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) - (2 * P(A \cap B \cap C)) + P(A'\cup B' \cup C').$$ But I'm confused to exactly how it extends to 4 events? Thanks.,I just started statistics and need to use the general addition rule. I know what it looks like for $3$ events: $$P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) - (2 * P(A \cap B \cap C)) + P(A'\cup B' \cup C').$$ But I'm confused to exactly how it extends to 4 events? Thanks.,,['probability']
49,"A, B, C and D, and we are trying to find the probability that exactly one event occurs.","A, B, C and D, and we are trying to find the probability that exactly one event occurs.",,"Truthfully, this is a homework problem. I've come across a solution, but I'm really trying to figure out how this works, hopefully at an intuitive level. We have four events, A, B, C and D, and we are trying to find the probability that exactly one event occurs. I've seen the ""Inclusion exclusion principle"", and that would help if I had to find the probability of A or B or C or D. I feel this should be trivial, probability is my weakest math, which is why I'm taking it, but this particular problem is giving me a lot of trouble. Any help would be greatly appreciated.","Truthfully, this is a homework problem. I've come across a solution, but I'm really trying to figure out how this works, hopefully at an intuitive level. We have four events, A, B, C and D, and we are trying to find the probability that exactly one event occurs. I've seen the ""Inclusion exclusion principle"", and that would help if I had to find the probability of A or B or C or D. I feel this should be trivial, probability is my weakest math, which is why I'm taking it, but this particular problem is giving me a lot of trouble. Any help would be greatly appreciated.",,['probability']
50,"If I flip 10 dice, what's the probability I get 1 1, 2 2s, 3 3s, and 4 4s?","If I flip 10 dice, what's the probability I get 1 1, 2 2s, 3 3s, and 4 4s?",,"If I flip 10 dice, what's the probability I get 1 1, 2 2s, 3 3s, and 4 4s? Here is what I tried: I realized that we can model this question in terms of bit strings. A 0 can represent a single dice roll. Since we roll 10 dice, we have 10 0s. A 1 can represent a separator between different values. Since a dice has 6 possible outcomes, we need 5 1s to separate these values. For instance, the bit string 010010001000011 represents rolling 1 1, 2 2s, 3 3s, and 4 4s. There are ${10 + 6 - 1}\choose{10}$ ways of forming bit strings with 10 0s and 6 - 1 = 5 1s, and the above string is only 1 of these ways. Thus, the answer to the original question is $\frac{1}{{10 + 6 - 1}\choose{10}} = \frac{1}{3003}$. However, my concern is that my example with the bit strings does not perfectly biject to the original question. Each bit string is equally likely to occur. However, are all combinations of rolls of the 30 dice equally likely to appear? For instance, would rolling 10 1s be less likely than rolling 5 1s and 5 2s since the latter has more permutations?","If I flip 10 dice, what's the probability I get 1 1, 2 2s, 3 3s, and 4 4s? Here is what I tried: I realized that we can model this question in terms of bit strings. A 0 can represent a single dice roll. Since we roll 10 dice, we have 10 0s. A 1 can represent a separator between different values. Since a dice has 6 possible outcomes, we need 5 1s to separate these values. For instance, the bit string 010010001000011 represents rolling 1 1, 2 2s, 3 3s, and 4 4s. There are ${10 + 6 - 1}\choose{10}$ ways of forming bit strings with 10 0s and 6 - 1 = 5 1s, and the above string is only 1 of these ways. Thus, the answer to the original question is $\frac{1}{{10 + 6 - 1}\choose{10}} = \frac{1}{3003}$. However, my concern is that my example with the bit strings does not perfectly biject to the original question. Each bit string is equally likely to occur. However, are all combinations of rolls of the 30 dice equally likely to appear? For instance, would rolling 10 1s be less likely than rolling 5 1s and 5 2s since the latter has more permutations?",,['probability']
51,Working through an example of measure theoretic conditional expectation,Working through an example of measure theoretic conditional expectation,,"I am trying to internalise the measure theoretic definition of conditional expectation. Consider a fair six-sided die. Formally the probability space is $(\{1, 2, 3, 4, 5,6\}, \mathcal{P}(1, 2, 3, 4, 5, 6), U)$ where $U$ is the discrete uniform distribution. Let the real-valued random variable map the identity map on the sample space so that $X(\omega) = \omega$. Byron Schmuland answered this question in a way that gives a lot of intuition. Suppose that after the die is rolled you will be told if the value is odd or even. Then you should use a rule for the expectation that depends on the parity. However I still don't see how to formalise his point. Let the conditioning $\sigma$-field be $\mathcal{G} = \{\emptyset, \Omega, \{1, 3, 5\}, \{2, 4, 6\}\}$ as this includes the events that the value is even or odd. My question is, what is a full and formal description of $E(X | \mathcal{G})$. Is it this? \begin{equation}   E(X | \mathcal{G}) =    \begin{cases}   0 & \mbox{if $A = \emptyset$} \\   3.5 & \mbox{if $A = \Omega$} \\   3 & \mbox{if $A = \{1, 3, 5\}$} \\   4 & \mbox{if $A = \{2, 4, 6\}$}   \end{cases} \end{equation} In particular I feel unsure about the cases where $A = \emptyset$ and $A = \Omega$.","I am trying to internalise the measure theoretic definition of conditional expectation. Consider a fair six-sided die. Formally the probability space is $(\{1, 2, 3, 4, 5,6\}, \mathcal{P}(1, 2, 3, 4, 5, 6), U)$ where $U$ is the discrete uniform distribution. Let the real-valued random variable map the identity map on the sample space so that $X(\omega) = \omega$. Byron Schmuland answered this question in a way that gives a lot of intuition. Suppose that after the die is rolled you will be told if the value is odd or even. Then you should use a rule for the expectation that depends on the parity. However I still don't see how to formalise his point. Let the conditioning $\sigma$-field be $\mathcal{G} = \{\emptyset, \Omega, \{1, 3, 5\}, \{2, 4, 6\}\}$ as this includes the events that the value is even or odd. My question is, what is a full and formal description of $E(X | \mathcal{G})$. Is it this? \begin{equation}   E(X | \mathcal{G}) =    \begin{cases}   0 & \mbox{if $A = \emptyset$} \\   3.5 & \mbox{if $A = \Omega$} \\   3 & \mbox{if $A = \{1, 3, 5\}$} \\   4 & \mbox{if $A = \{2, 4, 6\}$}   \end{cases} \end{equation} In particular I feel unsure about the cases where $A = \emptyset$ and $A = \Omega$.",,['probability']
52,Find distribution that has pdf $\frac{1}{\sqrt{\pi}}t^{-1/2} e^{-t}$ on the positive reals.,Find distribution that has pdf  on the positive reals.,\frac{1}{\sqrt{\pi}}t^{-1/2} e^{-t},Is there a well-known prob. distribution (or a combination thereof) that has pdf: $$\frac{1}{\sqrt{\pi}}t^{-1/2} e^{-t}$$ on $t \ge 0$ and $0$ everywhere else.,Is there a well-known prob. distribution (or a combination thereof) that has pdf: $$\frac{1}{\sqrt{\pi}}t^{-1/2} e^{-t}$$ on $t \ge 0$ and $0$ everywhere else.,,['probability']
53,Why is the probability that a prime p is a factor of a number n equal to 1/p,Why is the probability that a prime p is a factor of a number n equal to 1/p,,I'm learning some number theory and I can't seem to understand why this is the case.,I'm learning some number theory and I can't seem to understand why this is the case.,,"['probability', 'number-theory']"
54,How long does it take to complete a sticker album?,How long does it take to complete a sticker album?,,"We are collecing stickers in chocolate bars and whenever we open a bar we get a random new sticker. There are many different stickers and we try to collect them all. We open the first bar and get a sticker. We open the second bar and we get another sticker, but there is now a chance that it's the one we already got. Doubles are thrown away. As we collect more and more different stickers, the chance gets worse and worse. So if there are a total of $N$ different possible stickers and we already got $n$, how much chocolate bars $d(N,n)$ do we have to open before we get another one, i.e. the $(n+1)^{th}$ sticker? From this it should also be possible to compute the total number of bars we have to open  (sum of average openings).","We are collecing stickers in chocolate bars and whenever we open a bar we get a random new sticker. There are many different stickers and we try to collect them all. We open the first bar and get a sticker. We open the second bar and we get another sticker, but there is now a chance that it's the one we already got. Doubles are thrown away. As we collect more and more different stickers, the chance gets worse and worse. So if there are a total of $N$ different possible stickers and we already got $n$, how much chocolate bars $d(N,n)$ do we have to open before we get another one, i.e. the $(n+1)^{th}$ sticker? From this it should also be possible to compute the total number of bars we have to open  (sum of average openings).",,"['probability', 'combinatorics', 'statistics', 'probability-distributions', 'average']"
55,How does one calculate the expected number of coin flips for this game to last?,How does one calculate the expected number of coin flips for this game to last?,,"A biased coin yields heads with probability $\frac{1}{3}$ and tails with probability $\frac{2}{3}$. Adam and Bob use this coin to play a game, in which I flip the coin twice. If both flips are tails, Adam wins. If the flips differ, then Bob wins. Otherwise, this process is immediately repeated. How many flips are expected in a game (until either player wins)?","A biased coin yields heads with probability $\frac{1}{3}$ and tails with probability $\frac{2}{3}$. Adam and Bob use this coin to play a game, in which I flip the coin twice. If both flips are tails, Adam wins. If the flips differ, then Bob wins. Otherwise, this process is immediately repeated. How many flips are expected in a game (until either player wins)?",,['probability']
56,Probability of absorption in a discrete Markov chain,Probability of absorption in a discrete Markov chain,,"Let $\{X_{n}\}$ be a Markov Chain on the state space $S=\{1,...,100\}$ with $X_{0}=30$, and transition probabilities given by $p_{1,1}=p_{100,100}=1$, $p_{99,100}=p_{99,98}=1/2$ and for $2\leq i\leq98$, $p_{i,i-1}=2/3$ and $p_{i,i+2}=1/3$. Let $T=\inf\{n\geq0:X_{n}=1\mbox{ or 100}\}$. How can we show that $\mathbb{P}(T<\infty)=1$, that is the chain will eventually get absorbed at 1 or 100 with probability 1.","Let $\{X_{n}\}$ be a Markov Chain on the state space $S=\{1,...,100\}$ with $X_{0}=30$, and transition probabilities given by $p_{1,1}=p_{100,100}=1$, $p_{99,100}=p_{99,98}=1/2$ and for $2\leq i\leq98$, $p_{i,i-1}=2/3$ and $p_{i,i+2}=1/3$. Let $T=\inf\{n\geq0:X_{n}=1\mbox{ or 100}\}$. How can we show that $\mathbb{P}(T<\infty)=1$, that is the chain will eventually get absorbed at 1 or 100 with probability 1.",,"['probability', 'markov-chains']"
57,Keeping track of how to calculate probability/permutations/combinations?,Keeping track of how to calculate probability/permutations/combinations?,,"I'm absolutely terrible at calculating these things and I would like to, especially with SATs coming up, improve my capabilities. What always gets me is that there are so many types of ways to combine items. One way might be to figure out rearrangements of a set: abcd => abcd abdc acbd acdb adbc adcb bacd badc... ...or combinations of the elements of the set used more than once abcd => aaaa aaab aaac aaad aaba aabb ... ...or combinations limited to two elements abcd => aa ab ac ad ba bb bc bd ca cb cc... ...or in threes abcd => aaa aab aac aad aba abb abc abd... ...or ways to combine the elements in pairs abcd => ab ac ad ba bc bd ca cb cd da... ...or pairs without repeating abcd => ab ac ad bc bd... Point taken, I'm sure. I know they're all incredibly simple: multiply two numbers or find the summation and then divide by the number or times it's going to repeat... Again though, I have no idea which calculations to apply to which variations. I know it should be logical, but I can never quite figure it out. And then there was an SAT practice problem online... http://sat.collegeboard.org/practice/sat-question-of-the-day?questionId=20120221&oq=1 Of 5 employees, 3 are to be assigned an office and 2 are to be assigned a   cubicle. If 3 of the employees are men and 2 are women, and if those   assigned an office are to be chosen at random, what is the probability   that the offices will be assigned to 2 of the men and 1 of the women? I don't even know where to begin to solve this problem..","I'm absolutely terrible at calculating these things and I would like to, especially with SATs coming up, improve my capabilities. What always gets me is that there are so many types of ways to combine items. One way might be to figure out rearrangements of a set: abcd => abcd abdc acbd acdb adbc adcb bacd badc... ...or combinations of the elements of the set used more than once abcd => aaaa aaab aaac aaad aaba aabb ... ...or combinations limited to two elements abcd => aa ab ac ad ba bb bc bd ca cb cc... ...or in threes abcd => aaa aab aac aad aba abb abc abd... ...or ways to combine the elements in pairs abcd => ab ac ad ba bc bd ca cb cd da... ...or pairs without repeating abcd => ab ac ad bc bd... Point taken, I'm sure. I know they're all incredibly simple: multiply two numbers or find the summation and then divide by the number or times it's going to repeat... Again though, I have no idea which calculations to apply to which variations. I know it should be logical, but I can never quite figure it out. And then there was an SAT practice problem online... http://sat.collegeboard.org/practice/sat-question-of-the-day?questionId=20120221&oq=1 Of 5 employees, 3 are to be assigned an office and 2 are to be assigned a   cubicle. If 3 of the employees are men and 2 are women, and if those   assigned an office are to be chosen at random, what is the probability   that the offices will be assigned to 2 of the men and 1 of the women? I don't even know where to begin to solve this problem..",,"['probability', 'combinatorics', 'permutations']"
58,pdf of a quotient of uniform random variables,pdf of a quotient of uniform random variables,,"Suppose $x_1, x_2$ are IDD random variables uniformly distributed on the interval $(0,1)$.  What is the pdf of the quotient $x_2 / x_1$?","Suppose $x_1, x_2$ are IDD random variables uniformly distributed on the interval $(0,1)$.  What is the pdf of the quotient $x_2 / x_1$?",,"['probability', 'probability-distributions']"
59,Expected value of function of random walk,Expected value of function of random walk,,"I am trying to calculate $\lim_{n \to \infty} {E[e^{i \theta \frac{S_n}{n}}]}$. Where $\theta \in \mathbb{R}$, and $S_n$ is simple random walk. I could simplify it to $\lim_{n \to \infty}E[\cos(\theta \frac{S_n}{n})]$, but I don't know what to do next.. Can you help me? The hint in the book says that I should use Taylor expansion of $\ln(\cos(x))$ around $x=0$, but I don't see how it can be applied here.","I am trying to calculate $\lim_{n \to \infty} {E[e^{i \theta \frac{S_n}{n}}]}$. Where $\theta \in \mathbb{R}$, and $S_n$ is simple random walk. I could simplify it to $\lim_{n \to \infty}E[\cos(\theta \frac{S_n}{n})]$, but I don't know what to do next.. Can you help me? The hint in the book says that I should use Taylor expansion of $\ln(\cos(x))$ around $x=0$, but I don't see how it can be applied here.",,"['probability', 'statistics', 'random-walk']"
60,What is an intuitive meaning of $E(\overline { X } )$ and $Var(\overline { X } )$?,What is an intuitive meaning of  and ?,E(\overline { X } ) Var(\overline { X } ),"Let $X$ be a random variable distributed over, for example say, the Binomial Distribution. Then $P(X)$ is the probability of getting $x$ successful trials in $n$ total trials. So I saw a notation that represents the mean of random variables that made me I feel sceptical about my understanding of all the notations I have known. So here's my understanding of the notations: When it says the expectation of $X$, $E(X)$, does it mean over a long   run, $E(X)$ is the likely number of successful trials? In other words,   the expected value of $X$ is the expected number of successful trials   we would expect in a long run? When it says the variance of $X$, $Var(X)$, does it mean how spread   out the probability of successful trials are? Like how far apart the   probability between the successful trials are? Now, here's the confusing part. I see a notation like this: $\overline { X } =\frac { 1 }{ n } \sum _{ i=1 }^{ n }{ { X }_{ i } }  $ and this is called the mean of all the random variables. But it doesn't seem to make sense to me. $X$ is the random variable and carries the value that is the number of successful trials. The average of $X$ is like the average number of successful trials? Does it then mean $\overline { X } =E(X)$? Then, there is also the expectation of the mean of all the random variables, $E(\overline { X } )$. So does this represent the average of the average of all the random variables, which means $E(\overline { X } )=E(E(X))$? But at this point, I couldn't understand what it means intuitively. What does it mean here to say the average of the average of all random variables? Similarly, $Var(\overline { X } )$ is also a confusing term to me. Since $\overline { X } $ is just the average value, what spread does it have? What is the intuitive meaning of this $\overline { X } $ mean of all random variables $X$ and what does this add on to the meaning of $E(\overline { X } )$ and $Var(\overline { X } )$?","Let $X$ be a random variable distributed over, for example say, the Binomial Distribution. Then $P(X)$ is the probability of getting $x$ successful trials in $n$ total trials. So I saw a notation that represents the mean of random variables that made me I feel sceptical about my understanding of all the notations I have known. So here's my understanding of the notations: When it says the expectation of $X$, $E(X)$, does it mean over a long   run, $E(X)$ is the likely number of successful trials? In other words,   the expected value of $X$ is the expected number of successful trials   we would expect in a long run? When it says the variance of $X$, $Var(X)$, does it mean how spread   out the probability of successful trials are? Like how far apart the   probability between the successful trials are? Now, here's the confusing part. I see a notation like this: $\overline { X } =\frac { 1 }{ n } \sum _{ i=1 }^{ n }{ { X }_{ i } }  $ and this is called the mean of all the random variables. But it doesn't seem to make sense to me. $X$ is the random variable and carries the value that is the number of successful trials. The average of $X$ is like the average number of successful trials? Does it then mean $\overline { X } =E(X)$? Then, there is also the expectation of the mean of all the random variables, $E(\overline { X } )$. So does this represent the average of the average of all the random variables, which means $E(\overline { X } )=E(E(X))$? But at this point, I couldn't understand what it means intuitively. What does it mean here to say the average of the average of all random variables? Similarly, $Var(\overline { X } )$ is also a confusing term to me. Since $\overline { X } $ is just the average value, what spread does it have? What is the intuitive meaning of this $\overline { X } $ mean of all random variables $X$ and what does this add on to the meaning of $E(\overline { X } )$ and $Var(\overline { X } )$?",,"['probability', 'statistics']"
61,$k$-out-of-$n$ system probabilities,-out-of- system probabilities,k n,"An engineering system consisting of $n$ components is said to be a $k$-out-of-$n$ system ($k \le n$) when the system functions if and only if at least $k$ out of the $n$ components function. Suppose that all components function independently of each other. If the $i^{th}$ component functions with probability $p_i$, $i = 1, 2, 3, 4$, compute the probability that a 2-out-of-4 system functions. This problem in itself does not seem very difficult to solve, but I suspect I am not doing it the way it was intended to be done, because the formulas that come out are very ugly. I calculated the probability by conditioning on whether or not the $1^{st}$ and $2^{nd}$ components worked, and it came out to be $$ p_3 p_4 + p_2 (p_3 + p_4 - 2 p_3 p_4) +  p_1 (p_3 + p_4 - 2 p_3 p_4 + p_2 (1 - 2 p_3 - 2 p_4 + 3 p_3 p_4)) $$ Even if this is right, there's no way it's what the answer is supposed to look like. Can someone give me a push in the right direction?","An engineering system consisting of $n$ components is said to be a $k$-out-of-$n$ system ($k \le n$) when the system functions if and only if at least $k$ out of the $n$ components function. Suppose that all components function independently of each other. If the $i^{th}$ component functions with probability $p_i$, $i = 1, 2, 3, 4$, compute the probability that a 2-out-of-4 system functions. This problem in itself does not seem very difficult to solve, but I suspect I am not doing it the way it was intended to be done, because the formulas that come out are very ugly. I calculated the probability by conditioning on whether or not the $1^{st}$ and $2^{nd}$ components worked, and it came out to be $$ p_3 p_4 + p_2 (p_3 + p_4 - 2 p_3 p_4) +  p_1 (p_3 + p_4 - 2 p_3 p_4 + p_2 (1 - 2 p_3 - 2 p_4 + 3 p_3 p_4)) $$ Even if this is right, there's no way it's what the answer is supposed to look like. Can someone give me a push in the right direction?",,['probability']
62,Find the expected number of rolls for a fair die until two different number show up,Find the expected number of rolls for a fair die until two different number show up,,"A fair 6-sided die is thrown repeatedly until two different numbers appear. What is the expected number of rolls? My intuition tells that this is a geometric distribution with parameter $(\dfrac{5}{6})$ . So the expected value is $\dfrac{6}{5}$. But I am not sure. The place where I am confused is a general geometric distribution random variable is defined by its pdf $P(X=k) = (1-p)^{k-1}p, k = \{1,2,3,...\}$. However, in this question, it seems it is off by 1 since $P(X=1)=0$. Can someone explain this to me?","A fair 6-sided die is thrown repeatedly until two different numbers appear. What is the expected number of rolls? My intuition tells that this is a geometric distribution with parameter $(\dfrac{5}{6})$ . So the expected value is $\dfrac{6}{5}$. But I am not sure. The place where I am confused is a general geometric distribution random variable is defined by its pdf $P(X=k) = (1-p)^{k-1}p, k = \{1,2,3,...\}$. However, in this question, it seems it is off by 1 since $P(X=1)=0$. Can someone explain this to me?",,"['probability', 'probability-distributions']"
63,Mills' Ratio for Gaussian Q Function,Mills' Ratio for Gaussian Q Function,,"Suppose I have the following lower and upper bound for the Gaussian Q Function: $$ \frac{x}{x^2 + 1} \varphi(x) < Q(x) < \frac{1}{x} \varphi(x), \quad \quad \text{for } x > 0,$$ where $Q(x) = \int_x^\infty \frac{1}{\sqrt{2\pi}} e^{-\frac{u^2}{2}} \, \mathrm{d}u$ and $\varphi(x) = \frac{1}{\sqrt{2 \pi}} e^{-x^2 / 2}$ . How do I show $Q(x) \sim \varphi(x)/x$ as $x \to \infty$ ? Apparently, this fact can be shown simply from the upper and lower bounds. Also, I am unsure how the limit $\lim_{x \to \infty} \frac{Q(x)}{\varphi(x)} = \frac{1}{x}$ (which I can verify through L'Hopital's Rule) proves $Q(x) \sim \varphi(x)/x$ , since the claim $\lim_{x \to \infty} \frac{A}{B} = C \iff \lim_{x \to \infty} A = \left(\lim_{x \to \infty} B \right) \times C$ doesn't seem to be legitimate. Thanks","Suppose I have the following lower and upper bound for the Gaussian Q Function: where and . How do I show as ? Apparently, this fact can be shown simply from the upper and lower bounds. Also, I am unsure how the limit (which I can verify through L'Hopital's Rule) proves , since the claim doesn't seem to be legitimate. Thanks"," \frac{x}{x^2 + 1} \varphi(x) < Q(x) < \frac{1}{x} \varphi(x), \quad \quad \text{for } x > 0, Q(x) = \int_x^\infty \frac{1}{\sqrt{2\pi}} e^{-\frac{u^2}{2}} \, \mathrm{d}u \varphi(x) = \frac{1}{\sqrt{2 \pi}} e^{-x^2 / 2} Q(x) \sim \varphi(x)/x x \to \infty \lim_{x \to \infty} \frac{Q(x)}{\varphi(x)} = \frac{1}{x} Q(x) \sim \varphi(x)/x \lim_{x \to \infty} \frac{A}{B} = C \iff \lim_{x \to \infty} A = \left(\lim_{x \to \infty} B \right) \times C","['calculus', 'probability']"
64,grid puzzle about combinatorics,grid puzzle about combinatorics,,"Here is a puzzle about combinatorics. Suppose you have a square grid with $n^2$ points. You want to go from the origin $(0, 0)$ to $(n-1, n-1)$. Assuming you can only go right or up, in how many ways can you reach destination?","Here is a puzzle about combinatorics. Suppose you have a square grid with $n^2$ points. You want to go from the origin $(0, 0)$ to $(n-1, n-1)$. Assuming you can only go right or up, in how many ways can you reach destination?",,"['probability', 'puzzle', 'problem-solving']"
65,Finding probability of an unfair coin,Finding probability of an unfair coin,,An unfair coin is tossed giving heads with probability $p$ and tails with probability $1-p$. How many tosses do we have to perform if we want to find $p$ with a desired accuracy ? There is an obvious bound of $N$ tosses for $\lfloor \log_{10}{N} \rfloor$ digits of $p$; is there a better bound?,An unfair coin is tossed giving heads with probability $p$ and tails with probability $1-p$. How many tosses do we have to perform if we want to find $p$ with a desired accuracy ? There is an obvious bound of $N$ tosses for $\lfloor \log_{10}{N} \rfloor$ digits of $p$; is there a better bound?,,['probability']
66,What is the probability that the boy is telling the truth?,What is the probability that the boy is telling the truth?,,"My professor and I have came to a disagreement. My problem is with question number 8. I am pretty sure that you have to use the Bayes'thm for the question. I have tried ONCE to convince him, but regrettably, I have failed. Here is the question(s). I have included the previous questions because some of the information (from previous questions) was used to solve the question 8. start For questions 5 and 6 use the following information:  Diabetes - physicians recommend that children with type-1 diabetes keep up with insulin shots to minimize the chance of long-term complications. in addition, some diabetes researchers have observed that growth rate of weight during adolescence among diabetic patients is affected by level of compliance with insulin therapy. suppose 12 year old type-1 diabetic boys who comply with their insulin shots have a weight gain over 1 year that is normal distributed, with mean=12 lbs and variance =12 lbs. Q5) what is the probability that compliant type-1 diabetic 12 year old boys will gain at least 15 pounds over 1 year? no continuity correction. Q6) repeat problem #5 but now use the continuity correction (unit of measure is one pound). Q7) Conversely, 12 year old type-1 diabetic boys who do not take their insulin shots (non compliant) have a weight gain over 1 year that is normally distributed with a mean of 8 pounds and a variance of 12 pounds. what is the probability that these non compliant boys will gain at least 15 pounds over 1 year? no continuity correction. Q8) for the following problem, notice how the continuity correction is already built into the question: it is generally assumed that 75% of type-1 diabetics comply with their insulin regimen. suppose that a 12 year old type-1 diabetic boy comes to clinic and shows a 5lb weight gain over 1 year. (actually because of measurement error, assume this is an actual weight gain from 4.5 to 5.5 lbs). the boy claims to be taking his insulin medication. what is the probability that he is telling the truth? end I will jump right into the question. The question asked what is the P(he is telling the truth) i.e. pr(taking medication | weight gain of 5lbs). To me, this is unmistakably conditional. find P(A|B) where  A= taking medication B= weight gain of 5lbs. Bayes' thm states...  P(A|B) = P(B|A)P(A) / P(B) Find P(B|A) i.e. what is the probability that he gains weight given he is taking med? Given: mu=12 theta= root 12. Using the continuity correction... area: min to 5.5 z = (x-mu)/theta = (5.5-12)/root 12 = -1.88 <-> A1 = 0.0301 area: min to 4.5 z = (x-mu)/theta = (4.5-12)/root 12 = -2.17 <-> A2 = 0.0150 A1-A2=0.0151 P(B|A)=0.0151* Find P(A) i.e. what is the probability that he is taking med. Given: In question 8, this was given as 75% or 0.75. Find P(B) i.e. what is the probability that he gains weight of 5lbs? Bayes' thm also states...  P(B) = P(A int B)+(not A int B) = P(B|A)P(A) + P(B|not A)P(not A) i.e. P(weight gain given taking med) + P(weight gain given not taking med) We already found P(weight gain given taking med) = 0.0151* so find P(weight gain given not taking med) Given:mu=8 theta=root 12. Using the continuity correction... area: min to 5.5 z = (x-mu)/theta = (5.5-8)/root 12 = -0.72 <-> A1 = 0.2358 area: min to 4.5 z = (x-mu)/theta = (4.5-8)/root 12 = -1.01 <-> A2 = 0.1562 A1-A2=0.0796 so, P(B) = 0.0151+0.0796 Putting P(B|A), P(A), and P(B) together... P(A|B) = P(B|A)P(A) / P(B) = (0.0151)(0.75)/(0.0151+0.0796) = 0.1196 = 11.96% The following is what my professor said about the question: start Jeff –      As worded, it is not a conditional probability problem, therefore you do not use posterior probability.  I strongly believe that the correct answer is the area from min to 5.5 (answer is then 0.0301).  However most students found the area from 4.5 to 5.5 (answer is 0.015) because I mentioned the continuity correction and they were confused so I let this answer stand.  In reality, from min to 5.5 would be non-compliance.  In fact and specific number, even if compliant (e.g., Pr(X = 17)) would be a SMALL number.  Thus the probability really should be 5 or less or Min to 5.5 with the continuity correction. end What I think he said was to find the area under the normal distribution curve (as in question 5) from min to 5.5, but that could not possibly be the final answer because the area under the curve is the probability that the boy gains 5lbs., assuming that he is compliant. I went to his office hour and asked him to explain himself. Unfortunately, I did not understand what he was saying. I feel like I just took a crazy pill. I don't see any logical mistakes in my part. If there is any algebraic mistakes that I've made, please let me know. Thank you! my best,  Jeff Kwak","My professor and I have came to a disagreement. My problem is with question number 8. I am pretty sure that you have to use the Bayes'thm for the question. I have tried ONCE to convince him, but regrettably, I have failed. Here is the question(s). I have included the previous questions because some of the information (from previous questions) was used to solve the question 8. start For questions 5 and 6 use the following information:  Diabetes - physicians recommend that children with type-1 diabetes keep up with insulin shots to minimize the chance of long-term complications. in addition, some diabetes researchers have observed that growth rate of weight during adolescence among diabetic patients is affected by level of compliance with insulin therapy. suppose 12 year old type-1 diabetic boys who comply with their insulin shots have a weight gain over 1 year that is normal distributed, with mean=12 lbs and variance =12 lbs. Q5) what is the probability that compliant type-1 diabetic 12 year old boys will gain at least 15 pounds over 1 year? no continuity correction. Q6) repeat problem #5 but now use the continuity correction (unit of measure is one pound). Q7) Conversely, 12 year old type-1 diabetic boys who do not take their insulin shots (non compliant) have a weight gain over 1 year that is normally distributed with a mean of 8 pounds and a variance of 12 pounds. what is the probability that these non compliant boys will gain at least 15 pounds over 1 year? no continuity correction. Q8) for the following problem, notice how the continuity correction is already built into the question: it is generally assumed that 75% of type-1 diabetics comply with their insulin regimen. suppose that a 12 year old type-1 diabetic boy comes to clinic and shows a 5lb weight gain over 1 year. (actually because of measurement error, assume this is an actual weight gain from 4.5 to 5.5 lbs). the boy claims to be taking his insulin medication. what is the probability that he is telling the truth? end I will jump right into the question. The question asked what is the P(he is telling the truth) i.e. pr(taking medication | weight gain of 5lbs). To me, this is unmistakably conditional. find P(A|B) where  A= taking medication B= weight gain of 5lbs. Bayes' thm states...  P(A|B) = P(B|A)P(A) / P(B) Find P(B|A) i.e. what is the probability that he gains weight given he is taking med? Given: mu=12 theta= root 12. Using the continuity correction... area: min to 5.5 z = (x-mu)/theta = (5.5-12)/root 12 = -1.88 <-> A1 = 0.0301 area: min to 4.5 z = (x-mu)/theta = (4.5-12)/root 12 = -2.17 <-> A2 = 0.0150 A1-A2=0.0151 P(B|A)=0.0151* Find P(A) i.e. what is the probability that he is taking med. Given: In question 8, this was given as 75% or 0.75. Find P(B) i.e. what is the probability that he gains weight of 5lbs? Bayes' thm also states...  P(B) = P(A int B)+(not A int B) = P(B|A)P(A) + P(B|not A)P(not A) i.e. P(weight gain given taking med) + P(weight gain given not taking med) We already found P(weight gain given taking med) = 0.0151* so find P(weight gain given not taking med) Given:mu=8 theta=root 12. Using the continuity correction... area: min to 5.5 z = (x-mu)/theta = (5.5-8)/root 12 = -0.72 <-> A1 = 0.2358 area: min to 4.5 z = (x-mu)/theta = (4.5-8)/root 12 = -1.01 <-> A2 = 0.1562 A1-A2=0.0796 so, P(B) = 0.0151+0.0796 Putting P(B|A), P(A), and P(B) together... P(A|B) = P(B|A)P(A) / P(B) = (0.0151)(0.75)/(0.0151+0.0796) = 0.1196 = 11.96% The following is what my professor said about the question: start Jeff –      As worded, it is not a conditional probability problem, therefore you do not use posterior probability.  I strongly believe that the correct answer is the area from min to 5.5 (answer is then 0.0301).  However most students found the area from 4.5 to 5.5 (answer is 0.015) because I mentioned the continuity correction and they were confused so I let this answer stand.  In reality, from min to 5.5 would be non-compliance.  In fact and specific number, even if compliant (e.g., Pr(X = 17)) would be a SMALL number.  Thus the probability really should be 5 or less or Min to 5.5 with the continuity correction. end What I think he said was to find the area under the normal distribution curve (as in question 5) from min to 5.5, but that could not possibly be the final answer because the area under the curve is the probability that the boy gains 5lbs., assuming that he is compliant. I went to his office hour and asked him to explain himself. Unfortunately, I did not understand what he was saying. I feel like I just took a crazy pill. I don't see any logical mistakes in my part. If there is any algebraic mistakes that I've made, please let me know. Thank you! my best,  Jeff Kwak",,['probability']
67,When is cdf $F_{X_1+\dots+X_n}(c)$ of sum of iid zero mean random variables decreasing in sample size $n$?,When is cdf  of sum of iid zero mean random variables decreasing in sample size ?,F_{X_1+\dots+X_n}(c) n,"Let $X_1, X_2, \dots$ be a sequence of i.i.d. random variables with mean zero (e.g., $N(0,1)$ ). Let $n > m$ and $c \geq 0$ . I want to show that $$ P\left(\sum_{i=1}^n X_i \leq c \right) \leq P \left( \sum_{i=1}^m X_i \leq c \right).$$ In view of existing concentration bounds like Hoeffding's inequlity which scale with the the length of the sequence, i.e. $n$ and $m$ , I would think that the above statement should hold. Edit: Since it was pointed out that this doesn't hold for specific cases where $n$ and $m$ are small and the distribution of $X_i$ is discrete, assume that $X_1, X_2, \dots$ are Gaussian and $n$ sufficiently large.","Let be a sequence of i.i.d. random variables with mean zero (e.g., ). Let and . I want to show that In view of existing concentration bounds like Hoeffding's inequlity which scale with the the length of the sequence, i.e. and , I would think that the above statement should hold. Edit: Since it was pointed out that this doesn't hold for specific cases where and are small and the distribution of is discrete, assume that are Gaussian and sufficiently large.","X_1, X_2, \dots N(0,1) n > m c \geq 0  P\left(\sum_{i=1}^n X_i \leq c \right) \leq P \left( \sum_{i=1}^m X_i \leq c \right). n m n m X_i X_1, X_2, \dots n","['probability', 'probability-theory', 'concentration-of-measure']"
68,How many possible pairs in a random 5-card poker hand?,How many possible pairs in a random 5-card poker hand?,,"This question is from Introduction to Probability, question 32b. I've seen the solution and I understand it clearly. $$\frac{\binom{13}{2}\times \binom{4}{2}\times \binom{4}{2} \times 44}{\binom{52}{5}}$$ The $\binom{13}{2}$ is from the different pairs of values I can have. The two $\binom{4}{2}$ is for the two same values from the possible four cards. The 44 is the fifth card I can have which is different from the previous four. I came up with my own answer (which is obviously wrong) but I can't understand why it doesn't equal to the above. My own answer is $$\frac{\frac{52}{2!} \times \frac{(52-4)}{2!} \times 44} {3!}$$ $\frac{52}{2!}$ is for the first possible card I can choose. Therefore, the second one must be the same. The 2! is because order doesn't matter. $\frac{52-4}{2!}$ is for the third possible card I can choose. Therefore, the fourth one must be the same. 44 is the rest of the card that I can choose. 3! is for the order of the two pairs and the last card doesn't matter. It seems like I undercount it but I can't understand why. Please show me what I am missing. Thank you very much.","This question is from Introduction to Probability, question 32b. I've seen the solution and I understand it clearly. The is from the different pairs of values I can have. The two is for the two same values from the possible four cards. The 44 is the fifth card I can have which is different from the previous four. I came up with my own answer (which is obviously wrong) but I can't understand why it doesn't equal to the above. My own answer is is for the first possible card I can choose. Therefore, the second one must be the same. The 2! is because order doesn't matter. is for the third possible card I can choose. Therefore, the fourth one must be the same. 44 is the rest of the card that I can choose. 3! is for the order of the two pairs and the last card doesn't matter. It seems like I undercount it but I can't understand why. Please show me what I am missing. Thank you very much.",\frac{\binom{13}{2}\times \binom{4}{2}\times \binom{4}{2} \times 44}{\binom{52}{5}} \binom{13}{2} \binom{4}{2} \frac{\frac{52}{2!} \times \frac{(52-4)}{2!} \times 44} {3!} \frac{52}{2!} \frac{52-4}{2!},"['probability', 'combinatorics', 'combinations', 'card-games']"
69,If $Y_n \rightarrow Y$ in distribution then $P(Y \geq M) \geq \liminf_{n\rightarrow \infty} P(Y_n \geq M)$ for $M \in \mathbb{R}$,If  in distribution then  for,Y_n \rightarrow Y P(Y \geq M) \geq \liminf_{n\rightarrow \infty} P(Y_n \geq M) M \in \mathbb{R},Let $Y_n$ be a sequence of real random variables converging in distribution to a random variable $Y$ and let $M \in \mathbb{R}$ be a fixed real number. I would like to prove that $P(Y \geq M) \geq \liminf_{n\rightarrow \infty} P(Y_n \geq M)$ . This seems like it should be very easy to prove since if $x_n \rightarrow x$ then $x \geq \liminf_{n\rightarrow \infty} x_n$ for any convergent sequence of real numbers. But since we only have convergence in distribution and the limit is outside the measure $P$ I am having some trouble formalizing everything. How can one prove this?,Let be a sequence of real random variables converging in distribution to a random variable and let be a fixed real number. I would like to prove that . This seems like it should be very easy to prove since if then for any convergent sequence of real numbers. But since we only have convergence in distribution and the limit is outside the measure I am having some trouble formalizing everything. How can one prove this?,Y_n Y M \in \mathbb{R} P(Y \geq M) \geq \liminf_{n\rightarrow \infty} P(Y_n \geq M) x_n \rightarrow x x \geq \liminf_{n\rightarrow \infty} x_n P,"['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'convergence-divergence']"
70,Probability that an item from a group is not in a random sample (sampling without replacement),Probability that an item from a group is not in a random sample (sampling without replacement),,"I have a dataset of $3600$ items. There are $120$ item groups, each containing $30$ items. I create a test set by randomly sampling $720$ items without replacement from the dataset. What is the probability that there is at least one item of every item group in the sampled set? And what is the probability that at least $x$ item groups are not in the sampled set? (any combination of item groups, not specific item groups) Thanks a lot to the efforts of Gabriel Romon and RyRy The Fly Guy . Extra info : Brute forcing leads to a result of about $0.865$ Initially, I started with a easy approach that said: Every item group has the same probability of being sampled, so let's dumb it down to sampling from 120 item groups with equal probability. But obviously that does not work, as it would sample $\frac{720}{30} = 24$ item groups and ignores that every item group can be sampled.","I have a dataset of items. There are item groups, each containing items. I create a test set by randomly sampling items without replacement from the dataset. What is the probability that there is at least one item of every item group in the sampled set? And what is the probability that at least item groups are not in the sampled set? (any combination of item groups, not specific item groups) Thanks a lot to the efforts of Gabriel Romon and RyRy The Fly Guy . Extra info : Brute forcing leads to a result of about Initially, I started with a easy approach that said: Every item group has the same probability of being sampled, so let's dumb it down to sampling from 120 item groups with equal probability. But obviously that does not work, as it would sample item groups and ignores that every item group can be sampled.",3600 120 30 720 x 0.865 \frac{720}{30} = 24,"['probability', 'combinatorics', 'probability-theory']"
71,How can I calculate this integral? $ \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^c \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x$,How can I calculate this integral?, \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^c \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x,"I know how to calculate this: $ \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x=\Phi\left(\frac{b}{\sqrt{1+a^2}}\right)$ but i am struggling with this: $ \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^c \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x=\Phi_2\left(\frac{b}{\sqrt{1+a^2}}, c ;-\frac{a}{\sqrt{1+a^2}}\right)$ . where $\Phi_2\left(\cdot, \cdot ;\rho \right)$ is the bivariate cummulative Gaussian distribution with correlation $\rho$ . Can anyone help me?",I know how to calculate this: but i am struggling with this: . where is the bivariate cummulative Gaussian distribution with correlation . Can anyone help me?,"
\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x=\Phi\left(\frac{b}{\sqrt{1+a^2}}\right) 
\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^c \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x=\Phi_2\left(\frac{b}{\sqrt{1+a^2}}, c ;-\frac{a}{\sqrt{1+a^2}}\right) \Phi_2\left(\cdot, \cdot ;\rho \right) \rho","['probability', 'normal-distribution', 'integration']"
72,"Computing the variance of a ""complicated"" random variable","Computing the variance of a ""complicated"" random variable",,"Let $f_{X}(x)=\frac{1}{(x+1)^2}$ when $x\geq 0$ , and $0$ otherwise. I'm being asked to compute the following expectation: $\mathbb{E}[(1+X)^2e^{-2X}].$ Now, I have decomposed the expression in this way: $$\mathbb{E}[(1+X)^2e^{-2X}]= \mathbb{E}[X^2e^{-2X}]+\mathbb{E}[2Xe^{-2X}]+\mathbb{E}[e^{-2X}].$$ Assuming the multiplication of two random variables allow you to just multiply them in the definition of the expectation, I get complicated expressions that suggest to me I'm in the wrong track or there's something I'm not seeing. For example: $$\mathbb{E}[X^2e^{-2X}]=\int_{0}^{\infty}x^2 \left(\frac{1}{(x+1)^2}\right)e^{-\frac{2}{(1+x)^2}}.$$ The similarity with the normal distribution tells me that maybe it's part of the solution. But again, I'm not sure I'm even on the right track with this. Thank you.","Let when , and otherwise. I'm being asked to compute the following expectation: Now, I have decomposed the expression in this way: Assuming the multiplication of two random variables allow you to just multiply them in the definition of the expectation, I get complicated expressions that suggest to me I'm in the wrong track or there's something I'm not seeing. For example: The similarity with the normal distribution tells me that maybe it's part of the solution. But again, I'm not sure I'm even on the right track with this. Thank you.",f_{X}(x)=\frac{1}{(x+1)^2} x\geq 0 0 \mathbb{E}[(1+X)^2e^{-2X}]. \mathbb{E}[(1+X)^2e^{-2X}]= \mathbb{E}[X^2e^{-2X}]+\mathbb{E}[2Xe^{-2X}]+\mathbb{E}[e^{-2X}]. \mathbb{E}[X^2e^{-2X}]=\int_{0}^{\infty}x^2 \left(\frac{1}{(x+1)^2}\right)e^{-\frac{2}{(1+x)^2}}.,"['probability', 'expected-value', 'variance']"
73,Determining the distribution of random variable by observation,Determining the distribution of random variable by observation,,"We have two probability distributions $\mu, \nu$ on $\mathbb R$ . There is a positive measurable function $f$ on $\mathbb R$ with $$\mu(A) = \int_A f \text d\nu $$ for all Borel measurable $A$ . Let $X$ be a random variable whose distribution is $\mu$ or $\nu$ . We want to determine which is right distribution after observing an instance of $X$ . We have a following strategy: Choose a Borel set $B$ a priori. Observe $X$ ; after observation, we claim that $\mu$ is right if $X \in B$ and $\nu$ is right for $X \not\in B$ . The problem suddenly suggests the function $\phi$ , as $$\phi(B,a) = a \mu(B^c) + (1-a)\nu (B)$$ for al fixed real number $a \in (0,1)$ . The problem says: describe the meaning of $\phi$ , and for a given $a\in(0,1)$ , find $B$ such that $\phi(B,a)$ is minimal. Additionally, the problem asks: what is $f$ , if both $\mu$ and $\nu$ admit positive probability density functions in $\mathbb R$ ? However, I have no idea why the problem suggested such a function $\phi$ and what is $\phi$ having to do with guessing the distribution of $X$ . Plus, why is problem asking what happens if $\mu,\nu$ admit density? I cannot see the link between the setting (guessing the distribution) and the actual thing that the problem is asking for. Thanks in advance for any form of help, hint, or solution.","We have two probability distributions on . There is a positive measurable function on with for all Borel measurable . Let be a random variable whose distribution is or . We want to determine which is right distribution after observing an instance of . We have a following strategy: Choose a Borel set a priori. Observe ; after observation, we claim that is right if and is right for . The problem suddenly suggests the function , as for al fixed real number . The problem says: describe the meaning of , and for a given , find such that is minimal. Additionally, the problem asks: what is , if both and admit positive probability density functions in ? However, I have no idea why the problem suggested such a function and what is having to do with guessing the distribution of . Plus, why is problem asking what happens if admit density? I cannot see the link between the setting (guessing the distribution) and the actual thing that the problem is asking for. Thanks in advance for any form of help, hint, or solution.","\mu, \nu \mathbb R f \mathbb R \mu(A) = \int_A f \text d\nu  A X \mu \nu X B X \mu X \in B \nu X \not\in B \phi \phi(B,a) = a \mu(B^c) + (1-a)\nu (B) a \in (0,1) \phi a\in(0,1) B \phi(B,a) f \mu \nu \mathbb R \phi \phi X \mu,\nu","['probability', 'probability-theory', 'measure-theory', 'probability-distributions', 'random-variables']"
74,$\mathbb{E}\left[\frac{X}{Y}\right]$ relationship to $\frac{\mathbb{E}[X]}{\mathbb{E}[Y]}$ for random variables X and Y that are not independent,relationship to  for random variables X and Y that are not independent,\mathbb{E}\left[\frac{X}{Y}\right] \frac{\mathbb{E}[X]}{\mathbb{E}[Y]},"Suppose $Y > 0$ with probability 1, $\mathbb{E}[X]$ and $\mathbb{E}\left[\frac{1}{Y}\right]$ are finite, and $\mathbb{E}[X] > 0$ . I know that if X and Y are independent, then we have $\mathbb{E}\left[\frac{X}{Y}\right] = \mathbb{E}[X]\mathbb{E}\left[\frac{1}{Y}\right]$ , and we can use Jensen's Inequality to say that $\mathbb{E}\left[\frac{X}{Y}\right] \geq \frac{\mathbb{E}[X]}{\mathbb{E}[Y]}$ . But what if X and Y are dependent? Can we still derive the same inequality?","Suppose with probability 1, and are finite, and . I know that if X and Y are independent, then we have , and we can use Jensen's Inequality to say that . But what if X and Y are dependent? Can we still derive the same inequality?",Y > 0 \mathbb{E}[X] \mathbb{E}\left[\frac{1}{Y}\right] \mathbb{E}[X] > 0 \mathbb{E}\left[\frac{X}{Y}\right] = \mathbb{E}[X]\mathbb{E}\left[\frac{1}{Y}\right] \mathbb{E}\left[\frac{X}{Y}\right] \geq \frac{\mathbb{E}[X]}{\mathbb{E}[Y]},"['probability', 'probability-theory', 'inequality', 'random-variables', 'expected-value']"
75,Probability of getting 2 cards with the same color,Probability of getting 2 cards with the same color,,"You have two decks of cards: a 52 card deck (26 black, 26 red) and a 26 card deck (13 black, 13 red). You randomly draw two cards and win if both are the same color. Which deck would you prefer? What if the 26 card deck was randomly drawn from the 52 card deck? Which deck would you prefer then? The first question is straightforward. By symmetry, $$P(\text{same color}) = 2P(\text{two red}) = 2P(\text{second red}|\text{first red})P(\text{first red}).$$ In the 52 card deck, the probability is thus $2 \cdot\frac{25}{51}\frac 12 = \frac{25}{51}$ while in the 26 card deck, it is $2 \cdot \frac{12}{25}\frac 12 = \frac{12}{25}$ , and since $\frac{25}{51}> \frac{12}{25}$ the first deck has higher winning odds. For the second question, here's my approach. Let $R$ be a r.v. modelling the number of red cards in the smaller deck. $R$ follows a hypergeometric distribution: $$P(R=r) = \frac{\binom{26}{r}\binom{26}{26-r}}{\binom{52}{26}},$$ thus $$\begin{align} P(\text{same color})  &= P(\text{two red})+P(\text{two black})  \\ &= \sum_{r=0}^{26} P(\text{second red}|\text{first red, }R=r)P(\text{first red}|R=r)P(R=r) + P(\text{second black}|\text{first black, }R=r)P(\text{first black}|R=r)P(R=r) \\  &=\sum_{r=0}^{26} (\frac{r-1}{25} \frac{r}{26} + \frac{25-r}{25} \frac{r}{26})\frac{\binom{26-r}{r}) \binom{26}{26-r}}{\binom{52}{26}} \\ &= \frac{2}{25\cdot 26} E[R(R-1)] = \frac{2}{25\cdot 26}(V[R]+E[R]^2-E[R]) = \frac{25}{51} \end{align} $$ This is the same probability as for the full deck ! I'm very surprised with this result, I'd like to see an intuitive explanation or a shorter proof that doesn't involve as many computations.","You have two decks of cards: a 52 card deck (26 black, 26 red) and a 26 card deck (13 black, 13 red). You randomly draw two cards and win if both are the same color. Which deck would you prefer? What if the 26 card deck was randomly drawn from the 52 card deck? Which deck would you prefer then? The first question is straightforward. By symmetry, In the 52 card deck, the probability is thus while in the 26 card deck, it is , and since the first deck has higher winning odds. For the second question, here's my approach. Let be a r.v. modelling the number of red cards in the smaller deck. follows a hypergeometric distribution: thus This is the same probability as for the full deck ! I'm very surprised with this result, I'd like to see an intuitive explanation or a shorter proof that doesn't involve as many computations.","P(\text{same color}) = 2P(\text{two red}) = 2P(\text{second red}|\text{first red})P(\text{first red}). 2 \cdot\frac{25}{51}\frac 12 = \frac{25}{51} 2 \cdot \frac{12}{25}\frac 12 = \frac{12}{25} \frac{25}{51}> \frac{12}{25} R R P(R=r) = \frac{\binom{26}{r}\binom{26}{26-r}}{\binom{52}{26}}, \begin{align}
P(\text{same color}) 
&= P(\text{two red})+P(\text{two black}) 
\\
&= \sum_{r=0}^{26} P(\text{second red}|\text{first red, }R=r)P(\text{first red}|R=r)P(R=r) + P(\text{second black}|\text{first black, }R=r)P(\text{first black}|R=r)P(R=r)
\\ 
&=\sum_{r=0}^{26} (\frac{r-1}{25} \frac{r}{26} + \frac{25-r}{25} \frac{r}{26})\frac{\binom{26-r}{r}) \binom{26}{26-r}}{\binom{52}{26}}
\\
&= \frac{2}{25\cdot 26} E[R(R-1)] = \frac{2}{25\cdot 26}(V[R]+E[R]^2-E[R]) = \frac{25}{51}
\end{align}
","['probability', 'conditional-probability', 'card-games']"
76,Successive dice pool probabilities,Successive dice pool probabilities,,"So, I cannot wrap my head around how to calculate this. Here is my problem: In Warhammer you roll a pool of attacks, the attacks hit (for example) on a result of 4+ on a six sided dice. Then all the hits form a new dice pool and get rolled again transforming into wounds on a 3 or more. How do I calculate my probability to get an arbitrary number of wounds? Calculating the average is fairly straightforward but it seems to me that the fact that size of the second pool of dice is dependent on the result of the first should have some kind of bearing on the formula that I am not seeing.","So, I cannot wrap my head around how to calculate this. Here is my problem: In Warhammer you roll a pool of attacks, the attacks hit (for example) on a result of 4+ on a six sided dice. Then all the hits form a new dice pool and get rolled again transforming into wounds on a 3 or more. How do I calculate my probability to get an arbitrary number of wounds? Calculating the average is fairly straightforward but it seems to me that the fact that size of the second pool of dice is dependent on the result of the first should have some kind of bearing on the formula that I am not seeing.",,['probability']
77,"How to make sure a team wins more often than it loses in a tournament with n matches having equal probabilities of wins, losses and draws each?","How to make sure a team wins more often than it loses in a tournament with n matches having equal probabilities of wins, losses and draws each?",,"In a tournament, team X plays with each of six other teams once. For each match the probabilities of a win, a draw and a loss are equal. Find the probability that team X finishes with more wins than losses. I don't know if I can call it exactly a binomial probability problem but here's how I approached it: We know that probability of win, loss or draw is $\frac{1}{3}$ each. Let's make some cases: CASE 1: When number of draws is 0: It would be 6, 5 or 4 wins. $(\frac{1}{3})^6(\binom{6}{6}+ \binom{6}{5} + \binom{6}{4})$ CASE 2: When there is 1 draw. It would be 5, 4 or 3 wins. $(\frac{1}{3})^6(\frac{6!}{5!}+\frac{6!}{4!}+\frac{6!}{3!2!})$ CASE 3: 2 Draws, thus 4 or 3 wins $(\frac{1}{3})^6(\frac{6!}{4!2!}+\frac{6!}{3!2})$ CASE 4: 3 draws, thus 3 or 2 wins $(\frac{1}{3})^6(\frac{6!}{3!3!}+\frac{6!}{3!2!})$ CASE 5: 4 draws, thus 2 wins $(\frac{1}{3})^6(\frac{6!}{2!4!})$ CASE 6: 5 draws, thus 1 win $(\frac{1}{3})^6(\frac{6!}{5!})$ Adding them all up gives the result: $\frac{284}{729}$ . What am I doing wrong here? Edit: The correct answer is $\frac{98}{243}$ .","In a tournament, team X plays with each of six other teams once. For each match the probabilities of a win, a draw and a loss are equal. Find the probability that team X finishes with more wins than losses. I don't know if I can call it exactly a binomial probability problem but here's how I approached it: We know that probability of win, loss or draw is each. Let's make some cases: CASE 1: When number of draws is 0: It would be 6, 5 or 4 wins. CASE 2: When there is 1 draw. It would be 5, 4 or 3 wins. CASE 3: 2 Draws, thus 4 or 3 wins CASE 4: 3 draws, thus 3 or 2 wins CASE 5: 4 draws, thus 2 wins CASE 6: 5 draws, thus 1 win Adding them all up gives the result: . What am I doing wrong here? Edit: The correct answer is .",\frac{1}{3} (\frac{1}{3})^6(\binom{6}{6}+ \binom{6}{5} + \binom{6}{4}) (\frac{1}{3})^6(\frac{6!}{5!}+\frac{6!}{4!}+\frac{6!}{3!2!}) (\frac{1}{3})^6(\frac{6!}{4!2!}+\frac{6!}{3!2}) (\frac{1}{3})^6(\frac{6!}{3!3!}+\frac{6!}{3!2!}) (\frac{1}{3})^6(\frac{6!}{2!4!}) (\frac{1}{3})^6(\frac{6!}{5!}) \frac{284}{729} \frac{98}{243},"['probability', 'combinatorics']"
78,"Lognormal Distribution, mean and variance of logarithm of distribution","Lognormal Distribution, mean and variance of logarithm of distribution",,"Let Y be a lognormally distributed random variable with mean $\mu_Y$ and standard deviation $\sigma_Y$ . Assume $\ln(Y)$ is normally distributed with mean $\u$ and variance $\sigma^2$ . According to my source, the mean of the lognormal distribution satisfies $\mu_Y=\ln(\frac{\mu\sigma}{\sqrt{1+w}})$ and variance $\sigma^{2}_Y=\ln(1+w)$ where $w=(\sigma_Y/\mu_Y)^2$ . I am questioning the correctness of this result. I have attempted to derive this formula as follows. We know that if Y is the logarithm of the normal distribution with mean $\mu$ and variance $\sigma^2$ , then the mean of Y is given by (1) $\mu_Y=e^{\mu + \frac{1}{2}\sigma^2}$ , and (2) $\sigma_Y^2=(e^{\sigma^2} -1)\mu_Y^2$ Setting $w$ the same value as above, the second equation implies that $w=e^{\sigma^2} -1$ so that $\sigma^2=\ln(w+1)$ just as claimed above. On the other hand, now that we have $\sigma^2$ , we substitute this value into equation (1) we get $\mu_Y=e^{\mu + \frac{1}{2}\ln(w+1)}$ , which, to my algebra, yields $\mu =\ln(\frac{\mu_Y}{\sqrt{w+1}})$ . Hoping that somebody here can verify my sanity, or explain why the formula for the mean given in my source is correct.","Let Y be a lognormally distributed random variable with mean and standard deviation . Assume is normally distributed with mean and variance . According to my source, the mean of the lognormal distribution satisfies and variance where . I am questioning the correctness of this result. I have attempted to derive this formula as follows. We know that if Y is the logarithm of the normal distribution with mean and variance , then the mean of Y is given by (1) , and (2) Setting the same value as above, the second equation implies that so that just as claimed above. On the other hand, now that we have , we substitute this value into equation (1) we get , which, to my algebra, yields . Hoping that somebody here can verify my sanity, or explain why the formula for the mean given in my source is correct.",\mu_Y \sigma_Y \ln(Y) \u \sigma^2 \mu_Y=\ln(\frac{\mu\sigma}{\sqrt{1+w}}) \sigma^{2}_Y=\ln(1+w) w=(\sigma_Y/\mu_Y)^2 \mu \sigma^2 \mu_Y=e^{\mu + \frac{1}{2}\sigma^2} \sigma_Y^2=(e^{\sigma^2} -1)\mu_Y^2 w w=e^{\sigma^2} -1 \sigma^2=\ln(w+1) \sigma^2 \mu_Y=e^{\mu + \frac{1}{2}\ln(w+1)} \mu =\ln(\frac{\mu_Y}{\sqrt{w+1}}),"['probability', 'statistics']"
79,Why doesn't my approach work for this probability question?,Why doesn't my approach work for this probability question?,,"So there's this dungeons and dragons themed question where you're a wizard facing 6 trolls. The trolls spawn with 1d4 health (meaning that their health points are chosen randomly from 1-4) and the wizard is able to attack all of them with a fireball that deals 2d2 damage (the damage is calculated by randomly choosing two numbers from the set {1,2} and adding them together). The question asks to find the probability that all of the trolls are killed. The way I approached this problem is by looking at one troll and using case decomposition. If the troll has 1 or 2 health points, then no matter what I roll for the fireball, it will be killed. If it has 3 health points, there's only one way it survives: if I roll a 1,1 so there's a 75% I kill it in this case. And if it has 4 health points, I can only kill it if I roll a 2,2 => 25% chance. So the probability I kill a single troll is 75% and for the wizard to kill 6 trolls, the probability must be (0.75)^6 = 0.17798. To check my answer, I simulated the scenario in Matlab as shown below: %this function calculates the probability that the fireball %killed all of the trolls  function prob = probAllKilled()     N = 10e6;          count = 0;          %for each simulation     for i = 1:N                  %set the damage for the fireball         damage = randi([1, 2]) + randi([1, 2]);          %we generate the 6 trolls and check how many were killed by the          %fireball. If all were killed, we increment the count         if sum((randi([1, 4], 6, 1) - damage) <= 0) == 6             count = count + 1;         end              end     %then we divide by N to get the probability     prob = count/N;  end However, this gave me that the probability is 0.34295 which is nearly twice what I got on paper. I found out that in my calculations, I must have assumed that I was rolling for the fireball damage for each troll. To check this, I modified my code so that it matches my assumption: function prob = probAllKilled()     N = 10e6;          count = 0;          %for each simulation     for i = 1:N                  %set the damage for the fireball         %damage = randi([1, 2]) + randi([1, 2]);          %we generate the 6 trolls and check how many were killed by the          %fireball. If all were killed, we increment the count         if sum((randi([1, 4], 6, 1) - randi([1, 2], 6, 1) - randi([1, 2], 6, 1) ) <= 0) == 6             count = count + 1;         end              end     %then we divide by N to get the probability     prob = count/N;  end and that gave me a probability of 0.17807. I don't really understand where in my calculations I made the assumption that I was rolling every time I dealt damage to a troll. And I'm not really sure how I should approach the problem differently so that I don't make that assumption.","So there's this dungeons and dragons themed question where you're a wizard facing 6 trolls. The trolls spawn with 1d4 health (meaning that their health points are chosen randomly from 1-4) and the wizard is able to attack all of them with a fireball that deals 2d2 damage (the damage is calculated by randomly choosing two numbers from the set {1,2} and adding them together). The question asks to find the probability that all of the trolls are killed. The way I approached this problem is by looking at one troll and using case decomposition. If the troll has 1 or 2 health points, then no matter what I roll for the fireball, it will be killed. If it has 3 health points, there's only one way it survives: if I roll a 1,1 so there's a 75% I kill it in this case. And if it has 4 health points, I can only kill it if I roll a 2,2 => 25% chance. So the probability I kill a single troll is 75% and for the wizard to kill 6 trolls, the probability must be (0.75)^6 = 0.17798. To check my answer, I simulated the scenario in Matlab as shown below: %this function calculates the probability that the fireball %killed all of the trolls  function prob = probAllKilled()     N = 10e6;          count = 0;          %for each simulation     for i = 1:N                  %set the damage for the fireball         damage = randi([1, 2]) + randi([1, 2]);          %we generate the 6 trolls and check how many were killed by the          %fireball. If all were killed, we increment the count         if sum((randi([1, 4], 6, 1) - damage) <= 0) == 6             count = count + 1;         end              end     %then we divide by N to get the probability     prob = count/N;  end However, this gave me that the probability is 0.34295 which is nearly twice what I got on paper. I found out that in my calculations, I must have assumed that I was rolling for the fireball damage for each troll. To check this, I modified my code so that it matches my assumption: function prob = probAllKilled()     N = 10e6;          count = 0;          %for each simulation     for i = 1:N                  %set the damage for the fireball         %damage = randi([1, 2]) + randi([1, 2]);          %we generate the 6 trolls and check how many were killed by the          %fireball. If all were killed, we increment the count         if sum((randi([1, 4], 6, 1) - randi([1, 2], 6, 1) - randi([1, 2], 6, 1) ) <= 0) == 6             count = count + 1;         end              end     %then we divide by N to get the probability     prob = count/N;  end and that gave me a probability of 0.17807. I don't really understand where in my calculations I made the assumption that I was rolling every time I dealt damage to a troll. And I'm not really sure how I should approach the problem differently so that I don't make that assumption.",,"['probability', 'discrete-mathematics', 'recreational-mathematics', 'problem-solving']"
80,There are two multisets of circles and squares. Probabilty of pulling a circle from second multiset after two transfers between the two sets,There are two multisets of circles and squares. Probabilty of pulling a circle from second multiset after two transfers between the two sets,,"I am trying to solve a probability problem with coins of two types. I will refer to them as circles and squares. The task is: A boy has 4 circles and 3 squares in his left pocket and 2 circles and 1 square in his right pocket. The boy transfers 2 random objects from his left pocket to his right pocket. Then he transfers two random objects from his right pocket back to his left pocket. The boy then pulls an object from his right pocket. What is the probability he has pulled a circle? I tried forming Hypotheses $H_{cc}, H_{cr}, H_{rr}, F_{cc}, F_{cr}, F_{rr}$ for the corresponding transfers: Let $H_{ij}$ , for $i,j\in\{c,r\}$ , represent taking two circles, a circle and a rectangle, or two rectangles in the transfer from the left to the right pocket. The definition of $F_{xy}$ is similar, but in the opposite direction. I realised it's unwise to then calculate $P(F_{xy}|H_{ij})$ , so I gave up on that idea. I considered the following aproach instead: Let $k$ be the number of cirlces moved from the left pocket to the right pocket. Let $l$ be the number of circles moved from the right pocket to the left pocket. Thus the probability of moving $k$ circles to the right pocket is $\frac{C^k_4\times C^{2-k}_3}{C^2_7}$ moving $l$ circles back to the left pocket is: $\frac{C^l_{2+k}\times C^{2-l}_{1+2-k}}{C^2_5}$ pulling a circle out of the right pocket after moving two object from left to right and then two object from right to left is $\frac{2+k-l}{3}$ How can I calculate the probabilty? If $A=\{\text{pulling a circle from the right pocket after the transfers}\}$ , then $$P(A)=\sum{P(A|F_{xy})P(F_{xy})}$$ I am not sure what to do next. EDIT: If I rename my hypotheses as $H_k$ and $F_l$ , where $k$ and $l$ are the number of circles transferred, resp, left $\to$ right and right $\to$ left, then $$P(A)=\sum_{l=0}^2{P(A|F_l)P(F_l)}$$ but $P(F_l)$ should be $P(F_l|H_k)P(H_k)$ , therefore $$P(A)=\sum_{k=0}^2{\sum_{l=0}^2{\frac{2+k-l}{3}\times\frac{C^l_{2+k}\times C^{2-l}_{1+2-k}}{C^2_5}\times\frac{C^k_4\times C^{2-k}_3}{C^2_7}}}$$ Am I correct?","I am trying to solve a probability problem with coins of two types. I will refer to them as circles and squares. The task is: A boy has 4 circles and 3 squares in his left pocket and 2 circles and 1 square in his right pocket. The boy transfers 2 random objects from his left pocket to his right pocket. Then he transfers two random objects from his right pocket back to his left pocket. The boy then pulls an object from his right pocket. What is the probability he has pulled a circle? I tried forming Hypotheses for the corresponding transfers: Let , for , represent taking two circles, a circle and a rectangle, or two rectangles in the transfer from the left to the right pocket. The definition of is similar, but in the opposite direction. I realised it's unwise to then calculate , so I gave up on that idea. I considered the following aproach instead: Let be the number of cirlces moved from the left pocket to the right pocket. Let be the number of circles moved from the right pocket to the left pocket. Thus the probability of moving circles to the right pocket is moving circles back to the left pocket is: pulling a circle out of the right pocket after moving two object from left to right and then two object from right to left is How can I calculate the probabilty? If , then I am not sure what to do next. EDIT: If I rename my hypotheses as and , where and are the number of circles transferred, resp, left right and right left, then but should be , therefore Am I correct?","H_{cc}, H_{cr}, H_{rr}, F_{cc}, F_{cr}, F_{rr} H_{ij} i,j\in\{c,r\} F_{xy} P(F_{xy}|H_{ij}) k l k \frac{C^k_4\times C^{2-k}_3}{C^2_7} l \frac{C^l_{2+k}\times C^{2-l}_{1+2-k}}{C^2_5} \frac{2+k-l}{3} A=\{\text{pulling a circle from the right pocket after the transfers}\} P(A)=\sum{P(A|F_{xy})P(F_{xy})} H_k F_l k l \to \to P(A)=\sum_{l=0}^2{P(A|F_l)P(F_l)} P(F_l) P(F_l|H_k)P(H_k) P(A)=\sum_{k=0}^2{\sum_{l=0}^2{\frac{2+k-l}{3}\times\frac{C^l_{2+k}\times C^{2-l}_{1+2-k}}{C^2_5}\times\frac{C^k_4\times C^{2-k}_3}{C^2_7}}}","['probability', 'conditional-probability', 'bayesian']"
81,Expected value of objects with a serial number greater than a given number,Expected value of objects with a serial number greater than a given number,,"I have $n$ objects, numbered $1$ to $n$ . If I take out $m$ objects randomly, then what is the expected value of the number of objects whose serial number is greater than to $x$ ? $ (1 \le x \le n) $ EDIT 1: Here's my best attempt. If I denote the probability that exactly $i$ objects have a serial number greater than $x$ as $p(i)$ , then the expected value is $\sum_{i=1}^{n} ip(i)$ There are $x$ objects whose serial number is not greater than $x$ and $n-x$ objects whose is. Therefore the probability that exactly $i$ objects have a serial number greater than $x$ is.... I'm not sure. I'm guessing $$ \frac{\binom{x}{m-i} \binom{n-x}{i}}{\binom{n}{m}} $$ I don't know if this is correct or whether this sum has a closed form","I have objects, numbered to . If I take out objects randomly, then what is the expected value of the number of objects whose serial number is greater than to ? EDIT 1: Here's my best attempt. If I denote the probability that exactly objects have a serial number greater than as , then the expected value is There are objects whose serial number is not greater than and objects whose is. Therefore the probability that exactly objects have a serial number greater than is.... I'm not sure. I'm guessing I don't know if this is correct or whether this sum has a closed form",n 1 n m x  (1 \le x \le n)  i x p(i) \sum_{i=1}^{n} ip(i) x x n-x i x  \frac{\binom{x}{m-i} \binom{n-x}{i}}{\binom{n}{m}} ,"['probability', 'combinatorics']"
82,What Laws of Mathematics Best Explain How Surveys Work?,What Laws of Mathematics Best Explain How Surveys Work?,,"Suppose I have some probability distribution - as an example, I choose the Normal Distribution with some very large variance. Suppose I assume that the distribution of the number of calories eaten a day follows such a Normal Distribution in a country (population = 1000000 people) with a very large population. Now, let's say that I can only ask a very small percentage (50 people) of these people how many calories they consume every day, and I am interested in estimating the true number of calories the average person eats in one day within the population. Here is some R code to simulate this: # lets assume that the true average is 2000 calories, but this is unknown set.seed(123) population_calories = rnorm(1000000, 2000, 1000) Suppose a researcher randomly selects 50 people from this country and asks how many calories   they eat and takes the average: mean(sample(population_calories , 50, replace=FALSE)) [1] 1988.098 As we see, this number is very close to the actual average. Now, if we repeat this for 100 researchers: my_list = list()  for (i in 1:100)  { sample_i = mean(sample(population_calories , 50, replace=FALSE)) my_list[[i]] = data.frame(i,sample_i) } Looking at the distribution of these results: m = do.call(rbind.data.frame, my_list) plot(density(m $sample_i)) mean(m$ sample_i) [1] 1999.711 We see that the average estimates from a very small sample (0.005% of the population) from a  population with considerably large variance comes very close to the true value! Furthermore, I have heard that even when the underlying distribution is not a Normal Distribution, the above phenomena would still repeat. I was wondering - what principles of mathematics best explain this above phenomena? Is this more an application of the ""Central Limit Theorem"" ( https://en.wikipedia.org/wiki/Central_limit_theorem ) or ""Weak Law of Large Numbers"" ( https://en.wikipedia.org/wiki/Law_of_large_numbers )? Thanks!","Suppose I have some probability distribution - as an example, I choose the Normal Distribution with some very large variance. Suppose I assume that the distribution of the number of calories eaten a day follows such a Normal Distribution in a country (population = 1000000 people) with a very large population. Now, let's say that I can only ask a very small percentage (50 people) of these people how many calories they consume every day, and I am interested in estimating the true number of calories the average person eats in one day within the population. Here is some R code to simulate this: # lets assume that the true average is 2000 calories, but this is unknown set.seed(123) population_calories = rnorm(1000000, 2000, 1000) Suppose a researcher randomly selects 50 people from this country and asks how many calories   they eat and takes the average: mean(sample(population_calories , 50, replace=FALSE)) [1] 1988.098 As we see, this number is very close to the actual average. Now, if we repeat this for 100 researchers: my_list = list()  for (i in 1:100)  { sample_i = mean(sample(population_calories , 50, replace=FALSE)) my_list[[i]] = data.frame(i,sample_i) } Looking at the distribution of these results: m = do.call(rbind.data.frame, my_list) plot(density(m sample_i) [1] 1999.711 We see that the average estimates from a very small sample (0.005% of the population) from a  population with considerably large variance comes very close to the true value! Furthermore, I have heard that even when the underlying distribution is not a Normal Distribution, the above phenomena would still repeat. I was wondering - what principles of mathematics best explain this above phenomena? Is this more an application of the ""Central Limit Theorem"" ( https://en.wikipedia.org/wiki/Central_limit_theorem ) or ""Weak Law of Large Numbers"" ( https://en.wikipedia.org/wiki/Law_of_large_numbers )? Thanks!","sample_i))
mean(m","['probability', 'statistics']"
83,How Well Do Logarithms Preserve Properties Of A Function?,How Well Do Logarithms Preserve Properties Of A Function?,,"This is a question I have always had, relating to probability and statistics. In many applications (e.g. estimating the parameters of a probability distribution function),  we almost always end up trying to optimize the ""log likelihood"" instead of just the ""likelihood"". From a computational standpoint, I have heard that this is much easier - for example, diffrentiating the log likelihood can remove exponent terms and thus make the optimization process simpler. From a mathematical standpoint, we are often told (without explanation) that optimizating the log likelihood function is equivalent to maximizing the original likelihood function - for example, the stationary points (i.e. where the derivatives are 0) on the log likelihood function are apparently equivalent to the stationary points on the original likelihood function. Therefore, optimizing the log likelihood function or the original likelihood function will result in identical parameter estimates. My question relates to the mathematics of this phenomenon : Does the logarithm of a function always preserve the stationary points of the original function - and if so, why does this happen? As a reference, I found the following quote ( Why we consider log likelihood instead of Likelihood in Gaussian Distribution ): ""Because the logarithm is monotonically increasing function of its argument, maximization of the log of a function is equivalent to maximization of the function itself."" Thus - how do I know that the above is true? I will assume that ""a logarithm is montonically increasing function of its argument"" is true by definition - can we mathematically prove that : Maximizing the log of a function is ALWAYS equivalent to maximizing the function itself? Given any montonically increasing function - does maximizing a function and any montonically increasing transformation of this original function ALWAYS results in identical results? Thanks!","This is a question I have always had, relating to probability and statistics. In many applications (e.g. estimating the parameters of a probability distribution function),  we almost always end up trying to optimize the ""log likelihood"" instead of just the ""likelihood"". From a computational standpoint, I have heard that this is much easier - for example, diffrentiating the log likelihood can remove exponent terms and thus make the optimization process simpler. From a mathematical standpoint, we are often told (without explanation) that optimizating the log likelihood function is equivalent to maximizing the original likelihood function - for example, the stationary points (i.e. where the derivatives are 0) on the log likelihood function are apparently equivalent to the stationary points on the original likelihood function. Therefore, optimizing the log likelihood function or the original likelihood function will result in identical parameter estimates. My question relates to the mathematics of this phenomenon : Does the logarithm of a function always preserve the stationary points of the original function - and if so, why does this happen? As a reference, I found the following quote ( Why we consider log likelihood instead of Likelihood in Gaussian Distribution ): ""Because the logarithm is monotonically increasing function of its argument, maximization of the log of a function is equivalent to maximization of the function itself."" Thus - how do I know that the above is true? I will assume that ""a logarithm is montonically increasing function of its argument"" is true by definition - can we mathematically prove that : Maximizing the log of a function is ALWAYS equivalent to maximizing the function itself? Given any montonically increasing function - does maximizing a function and any montonically increasing transformation of this original function ALWAYS results in identical results? Thanks!",,"['calculus', 'probability', 'statistics', 'optimization']"
84,"If $12$ distinct balls are distributed to $8$ numbered cells, what is the probability that there is no empty cell?","If  distinct balls are distributed to  numbered cells, what is the probability that there is no empty cell?",12 8,"I am trying to solve this question: Let us assume we are distributing 12 different balls between 8 numbered cells, so that each distribution of balls into cells is obtained with equal probability. What is the probability that there is no empty cell? At first I gave to each ball an unique ID, such that: 1 = ball number 1, 2 = ball number 2, and so on. Now i defined $\Omega =\left\{ \left( x_{1},\ldots ,x_{12}\right) | \forall i,x_{i}\in \left[ 8\right] \right\} =\left[ 8\right] ^{12}$ , and so the event we want to compute is: $A=\{ \left( x_{1},\ldots ,x_{12}\right) \in \Omega | \forall i\in \left[ 8\right] \exists j\in \left[ 12\right] ,x_{j}=i \}$ . At first I tried to work with $A^{c}$ , but then I noticed that I have duplicates, so I tried to compute $|A|$ directly. I said, in order for no cell to be empty, we will choose 8 balls out of the 12 and distribute them into the eight cells, so that each cell contains exactly one ball. Then, we will distribute the remaining four balls into the eight cells and finish. So let's do the math: Choose 8 unique balls out of 12 is $\begin{pmatrix} 12 \\ 8 \end{pmatrix}$ Distribute the balls to the cells is $8!$ Then, distribute the remaining four is $8^{4}$ So, overall we have: $|A| = \begin{pmatrix} 12 \\ 8 \end{pmatrix} \cdot 8! \cdot 8^{4}$ Now, $|\Omega| = 8^{12}$ , so finally we get: $\mathbb{P}(A) = \dfrac{\begin{pmatrix} 12 \\ 8 \end{pmatrix}\cdot 8!\cdot 8^{4}}{8^{12}} = 1.18961 >1$ . I don't understand what I'm doing wrong, so would glad for help.","I am trying to solve this question: Let us assume we are distributing 12 different balls between 8 numbered cells, so that each distribution of balls into cells is obtained with equal probability. What is the probability that there is no empty cell? At first I gave to each ball an unique ID, such that: 1 = ball number 1, 2 = ball number 2, and so on. Now i defined , and so the event we want to compute is: . At first I tried to work with , but then I noticed that I have duplicates, so I tried to compute directly. I said, in order for no cell to be empty, we will choose 8 balls out of the 12 and distribute them into the eight cells, so that each cell contains exactly one ball. Then, we will distribute the remaining four balls into the eight cells and finish. So let's do the math: Choose 8 unique balls out of 12 is Distribute the balls to the cells is Then, distribute the remaining four is So, overall we have: Now, , so finally we get: . I don't understand what I'm doing wrong, so would glad for help.","\Omega =\left\{ \left( x_{1},\ldots ,x_{12}\right) | \forall i,x_{i}\in \left[ 8\right] \right\} =\left[ 8\right] ^{12} A=\{ \left( x_{1},\ldots ,x_{12}\right) \in \Omega | \forall i\in \left[ 8\right] \exists j\in \left[ 12\right] ,x_{j}=i \} A^{c} |A| \begin{pmatrix} 12 \\ 8 \end{pmatrix} 8! 8^{4} |A| = \begin{pmatrix} 12 \\ 8 \end{pmatrix} \cdot 8! \cdot 8^{4} |\Omega| = 8^{12} \mathbb{P}(A) = \dfrac{\begin{pmatrix} 12 \\ 8 \end{pmatrix}\cdot 8!\cdot 8^{4}}{8^{12}} = 1.18961 >1","['probability', 'combinatorics']"
85,What is the probability of a polynomial with integer coefficients has rational roots? [closed],What is the probability of a polynomial with integer coefficients has rational roots? [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 1 year ago . Improve this question What is the probability of a polynomial with integer coefficients has rational roots? For some reason I feel like the probability of having rational roots assuming the coefficients are random integers would get smaller as the degree goes up. Degree 1: $ax+b=0$ always has 1 rational root Degree 2: $ax^2+bc+c=0$ has rational root(s) if $b^2-4ac$ is a perfect square ( side question: do we consider $0$ to be a perfect square since $0^2=0$ )? Degree 3: $ax^3+bx^2+cx+d=0$ I can't say much for this case but I know Cardano's formula has a lot of radicals (and nested radicals!) Anyone know any results/theorems in this direction?,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 1 year ago . Improve this question What is the probability of a polynomial with integer coefficients has rational roots? For some reason I feel like the probability of having rational roots assuming the coefficients are random integers would get smaller as the degree goes up. Degree 1: always has 1 rational root Degree 2: has rational root(s) if is a perfect square ( side question: do we consider to be a perfect square since )? Degree 3: I can't say much for this case but I know Cardano's formula has a lot of radicals (and nested radicals!) Anyone know any results/theorems in this direction?,ax+b=0 ax^2+bc+c=0 b^2-4ac 0 0^2=0 ax^3+bx^2+cx+d=0,"['probability', 'number-theory']"
86,How to reasonably (numerically) estimate $\int_0^1 (1 - x) \sqrt{2\over\pi} e^{x^2/2}dx$?,How to reasonably (numerically) estimate ?,\int_0^1 (1 - x) \sqrt{2\over\pi} e^{x^2/2}dx,"As the question suggests, I came across the following integral in a calculation: $$\int_0^1 (1 - x) \sqrt{2\over\pi} e^{x^2/2}dx.$$ According to Wolfram Alpha, this equals $$\text{erfi}\left({1\over{\sqrt{2}}}\right) - (\sqrt{e} - 1)\sqrt{2\over\pi} \approx 0.435834.$$ However, I'm wondering if anyone can give a reasonable numerical estimate for this integral from first principles (pencil and paper) without using a calculator or Wolfram Alpha. I've tried but made little to no progress, and two PhD students I consulted didn't know either, so I'm asking here.","As the question suggests, I came across the following integral in a calculation: According to Wolfram Alpha, this equals However, I'm wondering if anyone can give a reasonable numerical estimate for this integral from first principles (pencil and paper) without using a calculator or Wolfram Alpha. I've tried but made little to no progress, and two PhD students I consulted didn't know either, so I'm asking here.",\int_0^1 (1 - x) \sqrt{2\over\pi} e^{x^2/2}dx. \text{erfi}\left({1\over{\sqrt{2}}}\right) - (\sqrt{e} - 1)\sqrt{2\over\pi} \approx 0.435834.,"['real-analysis', 'probability', 'random-variables', 'normal-distribution', 'estimation']"
87,Sum of independent Gamma distributions is a Gamma or a normal distribution?,Sum of independent Gamma distributions is a Gamma or a normal distribution?,,"Let $ {\textstyle \{X_{1},\ldots ,X_{n},\ldots \}}$ be a sequence of independent random variables, each of those random variable follow a Gamma distribution. For the summation of those random variable: $ {\displaystyle {\bar {X}}_{n}\equiv {\frac {X_{1}+\cdots +X_{n}}{n}}}$ Question: Is the summation of independent Gamma distributions a Gamma distribution or a normal distribution ? Here is the confusion: the summation of Gamma distribution should still be a Gamma distribution. On the other hand, central limit theorem says that such summation should approach a normal distribution. which of those viewpoint is correct ?","Let be a sequence of independent random variables, each of those random variable follow a Gamma distribution. For the summation of those random variable: Question: Is the summation of independent Gamma distributions a Gamma distribution or a normal distribution ? Here is the confusion: the summation of Gamma distribution should still be a Gamma distribution. On the other hand, central limit theorem says that such summation should approach a normal distribution. which of those viewpoint is correct ?"," {\textstyle \{X_{1},\ldots ,X_{n},\ldots \}}  {\displaystyle {\bar {X}}_{n}\equiv {\frac {X_{1}+\cdots +X_{n}}{n}}}","['probability', 'random-variables']"
88,Random variable is poisson distributed,Random variable is poisson distributed,,"Let $\Omega = \mathbb{N}_0^2, \mathcal{A}=Pot(\Omega)$ and $\mathbb{P}$ the product of two poisson distributions with paremeter $\lambda_1,\lambda_>0$ , i.e $$ \mathbb{P}(\{(n_1,n_2)\})=\frac{\lambda_1^{n_1} \lambda_2^{n_2}}{n_1!n_2!} e^{-\lambda_1-\lambda_2}$$ Define then $X:\Omega\rightarrow \mathbb{N}_0,\ (n_1,n_2)\mapsto n_1+n_2$ . Prove that X is poisson distributed with parameter $\lambda_1+\lambda_2$ I've seen various proofs that similar to this one, Poisson Distribution of sum of two random independent variables $X$, $Y$ , but they are basically between independent variables. In this job it's about one single random variable. So what to prove is that $X$ ~ $\mathcal{P}(\lambda_1+\lambda_2)$ My attempt \begin{align}\mathbb{P}(X=n) &=\mathbb{P}(n_1+n_2=n)\\&=\sum_{k=0}^n\mathbb{P}(n_1=k,n_2=n-k)\\&= \sum_{k=0}^n\mathbb{P}(n_1=k)\mathbb{P}(n_2=n-k) \\&=\sum^n_{k=0}\frac{\lambda_1^k\lambda^{n-k}}{k!(n-1)!}e^{-(\lambda_1+\lambda_2)} \\&=\frac{(\lambda_1+\lambda_2)^n}{n_!}e^{-(\lambda_1+\lambda_2)} \end{align} This is obviously enough for $X$ ~ $\mathcal{P}(\lambda_1+\lambda_2)$ But my worries is that, in the brackets of $\mathbb{P}$ am I allowed to use this kind of notation $n_1=k, n_2=n-k$ , because from what I've learnd, in the brackts it should be a random variable equals to some real number, like $\mathbb{P}_X(\{t\})=\mathbb{P}(X=t)$ , but in the proof it is a real number equals to some real number, I don't know it's correct","Let and the product of two poisson distributions with paremeter , i.e Define then . Prove that X is poisson distributed with parameter I've seen various proofs that similar to this one, Poisson Distribution of sum of two random independent variables $X$, $Y$ , but they are basically between independent variables. In this job it's about one single random variable. So what to prove is that ~ My attempt This is obviously enough for ~ But my worries is that, in the brackets of am I allowed to use this kind of notation , because from what I've learnd, in the brackts it should be a random variable equals to some real number, like , but in the proof it is a real number equals to some real number, I don't know it's correct","\Omega = \mathbb{N}_0^2, \mathcal{A}=Pot(\Omega) \mathbb{P} \lambda_1,\lambda_>0  \mathbb{P}(\{(n_1,n_2)\})=\frac{\lambda_1^{n_1} \lambda_2^{n_2}}{n_1!n_2!} e^{-\lambda_1-\lambda_2} X:\Omega\rightarrow \mathbb{N}_0,\ (n_1,n_2)\mapsto n_1+n_2 \lambda_1+\lambda_2 X \mathcal{P}(\lambda_1+\lambda_2) \begin{align}\mathbb{P}(X=n)
&=\mathbb{P}(n_1+n_2=n)\\&=\sum_{k=0}^n\mathbb{P}(n_1=k,n_2=n-k)\\&=
\sum_{k=0}^n\mathbb{P}(n_1=k)\mathbb{P}(n_2=n-k)
\\&=\sum^n_{k=0}\frac{\lambda_1^k\lambda^{n-k}}{k!(n-1)!}e^{-(\lambda_1+\lambda_2)}
\\&=\frac{(\lambda_1+\lambda_2)^n}{n_!}e^{-(\lambda_1+\lambda_2)}
\end{align} X \mathcal{P}(\lambda_1+\lambda_2) \mathbb{P} n_1=k, n_2=n-k \mathbb{P}_X(\{t\})=\mathbb{P}(X=t)","['probability', 'probability-theory', 'probability-distributions']"
89,Conditional probability with an extra term,Conditional probability with an extra term,,"Consider an experiment having three possible outcomes that occur with probabilities $p_1$ , $p_2$ , and $p_3$ , respectively. Suppose n independent trials of the experiment are conducted and let $X_i$ denote the number of times the $i^{th}$ outcome occurs. What is the density of $X_1 + X_2?$ Find $P(X_2 = y \space|\space X_1 + X_2 = z), y = 0, 1, 2, ... ,z$ ? I have solved the first question correctly, but there is something wrong with my solution for the second part below; I have explained my approach for the second part. My approach: $P(X_2 = y \space|\space X_1 + X_2 = z) = \frac{P(X_1 + X_2 = z \space| \space X_2 = y) \space P(X_2 = y)} {P(X_1 + X_2 = z)} = \frac{P(X_1 = z-y\space| \space X_2 = y) \space P(X_2 = y)} {P(X_1 + X_2 = z)}$ Now, RHS terms: $P(X_1 = z-y\space| \space X_2 = y) = {n-y \choose z-y} p_1^{z-y}p_3^{n-z}$ $P(X_2 = y) = {n \choose y} p_2^{y}(1-p_2)^{n-y}$ $P(X_1 + X_2 = z) = {n \choose z} (p_1+p_2)^{z}(p_3)^{n-z}$ (This term was calculated in the first part of the question and hence its verified.) Substituting these terms in the equation, we get: $P(X_2 = y \space|\space X_1 + X_2 = z) = \frac{{n-y \choose z-y} p_1^{z-y}p_3^{n-z} {n \choose y} p_2^{y}(1-p_2)^{n-y}}{{n \choose z} (p_1+p_2)^{z}(p_3)^{n-z}}$ On simplifying the RHS, we get: $RHS = {z \choose y} (\frac{p_1}{p_1+p_2})^{z-y} (\frac{p_2}{p_1+p_2})^y (1-p_2)^{n-y}$ but the answer given in the book is: ${z \choose y} (\frac{p_1}{p_1+p_2})^{z-y} (\frac{p_2}{p_1+p_2})^y $ I have an extra term $(1-p_2)^{n-y}$ in my answer; I have rechecked it multiple times, and it doesn't seem like a calculation mistake. Am I making any conceptual mistakes? PS.: The question is from Introduction to Probability Theory, Hoel Port Stone, Chapter-3 Q22 . Okay, it seems the first term of the RHS in the original equation is wrong, as I can't use $p_1$ and $p_3$ because now the sample space has reduced; changing it to the following gives the correct answer: $P(X_1 = z-y\space| \space X_2 = y) = {n-y \choose z-y} (\frac{p_1}{p_1+p_3})^{z-y} (\frac{p_3}{p_1+p_3})^{n-z}$ Right? Also, can we directly state the answer using some argument along the lines of conditional probability?","Consider an experiment having three possible outcomes that occur with probabilities , , and , respectively. Suppose n independent trials of the experiment are conducted and let denote the number of times the outcome occurs. What is the density of Find ? I have solved the first question correctly, but there is something wrong with my solution for the second part below; I have explained my approach for the second part. My approach: Now, RHS terms: (This term was calculated in the first part of the question and hence its verified.) Substituting these terms in the equation, we get: On simplifying the RHS, we get: but the answer given in the book is: I have an extra term in my answer; I have rechecked it multiple times, and it doesn't seem like a calculation mistake. Am I making any conceptual mistakes? PS.: The question is from Introduction to Probability Theory, Hoel Port Stone, Chapter-3 Q22 . Okay, it seems the first term of the RHS in the original equation is wrong, as I can't use and because now the sample space has reduced; changing it to the following gives the correct answer: Right? Also, can we directly state the answer using some argument along the lines of conditional probability?","p_1 p_2 p_3 X_i i^{th} X_1 + X_2? P(X_2 = y \space|\space X_1 + X_2 = z), y = 0, 1, 2, ... ,z P(X_2 = y \space|\space X_1 + X_2 = z) = \frac{P(X_1 + X_2 = z \space| \space X_2 = y) \space P(X_2 = y)} {P(X_1 + X_2 = z)} = \frac{P(X_1 = z-y\space| \space X_2 = y) \space P(X_2 = y)} {P(X_1 + X_2 = z)} P(X_1 = z-y\space| \space X_2 = y) = {n-y \choose z-y} p_1^{z-y}p_3^{n-z} P(X_2 = y) = {n \choose y} p_2^{y}(1-p_2)^{n-y} P(X_1 + X_2 = z) = {n \choose z} (p_1+p_2)^{z}(p_3)^{n-z} P(X_2 = y \space|\space X_1 + X_2 = z) = \frac{{n-y \choose z-y} p_1^{z-y}p_3^{n-z} {n \choose y} p_2^{y}(1-p_2)^{n-y}}{{n \choose z} (p_1+p_2)^{z}(p_3)^{n-z}} RHS = {z \choose y} (\frac{p_1}{p_1+p_2})^{z-y} (\frac{p_2}{p_1+p_2})^y (1-p_2)^{n-y} {z \choose y} (\frac{p_1}{p_1+p_2})^{z-y} (\frac{p_2}{p_1+p_2})^y  (1-p_2)^{n-y} p_1 p_3 P(X_1 = z-y\space| \space X_2 = y) = {n-y \choose z-y} (\frac{p_1}{p_1+p_3})^{z-y} (\frac{p_3}{p_1+p_3})^{n-z}","['probability', 'probability-theory', 'random-variables', 'conditional-probability']"
90,Probability problem my AP statistics teacher can't solve,Probability problem my AP statistics teacher can't solve,,"This is a challenge problem that my AP Stat teacher can't solve, so I am hoping that I can find an answer here. I am aware that you could use a computer to run simulations to get an approximate, but I am looking for a more definitive answer. The question is: Assume 2 points are placed in rectangle $ABCD$ at random. A line is drawn connecting said points. What is the probability that the midpoint of the line drawn falls in the circle with a diameter of $w$ ? If you cannot see the image, here is a description of the model. There is a rectangle labeled $ABCD$ with one side length of $4w$ and another side length of $2w$ . In the center of the rectangle there is a circle with a diameter of $w$ .","This is a challenge problem that my AP Stat teacher can't solve, so I am hoping that I can find an answer here. I am aware that you could use a computer to run simulations to get an approximate, but I am looking for a more definitive answer. The question is: Assume 2 points are placed in rectangle at random. A line is drawn connecting said points. What is the probability that the midpoint of the line drawn falls in the circle with a diameter of ? If you cannot see the image, here is a description of the model. There is a rectangle labeled with one side length of and another side length of . In the center of the rectangle there is a circle with a diameter of .",ABCD w ABCD 4w 2w w,"['probability', 'geometric-probability']"
91,What is the probability that Camilla and Cameron are paired with each other?,What is the probability that Camilla and Cameron are paired with each other?,,"Textbook problem : A teacher with a math class of 20 students randomly pairs the students to take a test. What is the probability that Camilla and Cameron, two students in the class, are paired with each other? My answer : 1/190.  There is only one such pair out of the 20-choose-2 possible pairings. Their answer : 1/19.  Camilla can be paired with 19 students and only one such pairing is with Cameron. Question : What principle am I missing in my reasoning that would help me to see why their answer is right and mine wrong?  It's like I follow their line of reasoning too but don't see what underlying assumption differentiates the answers to see how I can frame the problem correctly on my own. Textbook : Chapter 26 from The Art of Problem Solving (Volume I) by Rusczyk and Lehoczky.","Textbook problem : A teacher with a math class of 20 students randomly pairs the students to take a test. What is the probability that Camilla and Cameron, two students in the class, are paired with each other? My answer : 1/190.  There is only one such pair out of the 20-choose-2 possible pairings. Their answer : 1/19.  Camilla can be paired with 19 students and only one such pairing is with Cameron. Question : What principle am I missing in my reasoning that would help me to see why their answer is right and mine wrong?  It's like I follow their line of reasoning too but don't see what underlying assumption differentiates the answers to see how I can frame the problem correctly on my own. Textbook : Chapter 26 from The Art of Problem Solving (Volume I) by Rusczyk and Lehoczky.",,"['probability', 'combinatorics']"
92,Does a distribution with the moments $E[X^k]=1_{k=2l} l!$ exists?,Does a distribution with the moments  exists?,E[X^k]=1_{k=2l} l!,Does a distribution on $\mathbb{R}$ exists such that for a random variable $X$ on $\mathbb{R}$ with said distribution we have $$ \mathbb{E}[X^{2l}] = l! \ \ \text{ and } \ \ \mathbb{E}[X^{2l+1}] = 0 $$ for all $l \in \mathbb{N}_0$ ? The equality $\mathbb{E}[X^{2l+1}] = 0$ clearly holds for every symmetric distribution (where the moments exist) but I don't know of a distribution with such even moments. Any help is much apprechiated.,Does a distribution on exists such that for a random variable on with said distribution we have for all ? The equality clearly holds for every symmetric distribution (where the moments exist) but I don't know of a distribution with such even moments. Any help is much apprechiated.,"\mathbb{R} X \mathbb{R} 
\mathbb{E}[X^{2l}] = l! \ \ \text{ and } \ \ \mathbb{E}[X^{2l+1}] = 0
 l \in \mathbb{N}_0 \mathbb{E}[X^{2l+1}] = 0","['probability', 'probability-distributions', 'distribution-theory']"
93,What is the Probability of Eating a Certain Meal on a Given Day?,What is the Probability of Eating a Certain Meal on a Given Day?,,"This is a problem that was given during a discussion section in the first week of my statistics class that I might be overthinking and misunderstanding. You prepare 5 meals for the week, 2 with vegetables and 3 without. Starting on Monday, a meal is consumed each day until Friday. What is the probability that you will eat a meal with vegetables on Wednesday? The answer to this problem was simply: $$\frac{(\text{# of Vegetable Meals})}{(\text{Total # of Meals})}$$ or $\frac{2}{5}$ . My confusion stems from, if a meal is consumed each day wouldn't the number of meals that we can choose from get smaller as we near the end of the week? So by Wednesday there would be only 3 meals to pick from. In addition, why do we not have consider the 3 different cases of the meals eaten before Wednesday? If a vegetable meal is eaten on Monday and Tuesday, then there would be a 0 chance of eating one on Wednesday. What about the cases where there was already 1 vegetable meal eaten before Wednesday? Would that not make the probability of eating a vegetable meal on Wednesday be: $$P(\text{Vegetable Meal on Wednesday)} = \frac{2}{5}*\frac{3}{4}*\frac{1}{3}$$ or if no vegetable meals are eaten before Wednesday at all: $$P(\text{Vegetable Meal on Wednesday})=\frac{3}{5}*\frac{2}{4}*\frac{2}{3}$$ Why would we not sum up these prbabilites to get the actual probability of eating a vegetable meal on Wednesday?","This is a problem that was given during a discussion section in the first week of my statistics class that I might be overthinking and misunderstanding. You prepare 5 meals for the week, 2 with vegetables and 3 without. Starting on Monday, a meal is consumed each day until Friday. What is the probability that you will eat a meal with vegetables on Wednesday? The answer to this problem was simply: or . My confusion stems from, if a meal is consumed each day wouldn't the number of meals that we can choose from get smaller as we near the end of the week? So by Wednesday there would be only 3 meals to pick from. In addition, why do we not have consider the 3 different cases of the meals eaten before Wednesday? If a vegetable meal is eaten on Monday and Tuesday, then there would be a 0 chance of eating one on Wednesday. What about the cases where there was already 1 vegetable meal eaten before Wednesday? Would that not make the probability of eating a vegetable meal on Wednesday be: or if no vegetable meals are eaten before Wednesday at all: Why would we not sum up these prbabilites to get the actual probability of eating a vegetable meal on Wednesday?",\frac{(\text{# of Vegetable Meals})}{(\text{Total # of Meals})} \frac{2}{5} P(\text{Vegetable Meal on Wednesday)} = \frac{2}{5}*\frac{3}{4}*\frac{1}{3} P(\text{Vegetable Meal on Wednesday})=\frac{3}{5}*\frac{2}{4}*\frac{2}{3},"['probability', 'combinatorics', 'statistics']"
94,Is it true that $P(A)=1$ if and only if $A=\Omega$?,Is it true that  if and only if ?,P(A)=1 A=\Omega,"I was wondering if the following statement is true: $P(A)=1$ if and only if $A=\Omega$ . Of course we know that $P(\Omega)=1$ . But if $P(A)=1$ , does it necessarily mean $A=\Omega$ ? Why?","I was wondering if the following statement is true: if and only if . Of course we know that . But if , does it necessarily mean ? Why?",P(A)=1 A=\Omega P(\Omega)=1 P(A)=1 A=\Omega,"['probability', 'probability-theory', 'analysis']"
95,Rolling dice game - who first will roll number 3,Rolling dice game - who first will roll number 3,,"Let's consider very easy game with players A and B - they roll a dice starting with player A. If any of players roll a three, then he wins. I want to calculate probability that player B wins. Intuition Intuition is that $P(\textrm{player B wins}) < P(\textrm{player A wins})$ because they have even chances on winning, and player A starts, so player A has one more roll, therefore bigger chance to win. In other words player A is one roll ahead of player B so what should hold is that: $$P(\textrm{player A wins}) = P(\textrm{player B wins}) + \frac 16$$ Out of this we can already calculate desire probability $P(\textrm{player B wins}) = \frac{5}{12}$ Normal approach I want to calculate this normally (without any tricks) to compare the results. Please see the probability tree that I've created: Out of this tree we can see that: $$P(\textrm{B won}) = \frac{5}{6} \cdot \frac 1 6 + (\frac{5}{6})^2 \cdot \frac{5}{6} \cdot \frac 1 6 + (\frac{5}{6})^4 \cdot \frac 1 6 + ... = \sum_{n = 0}^\infty (\frac 5 6)^{2n}\frac{5}{6}\frac{1}{6} = $$ $$= \sum_{n = 0}^\infty(\frac{25}{36})^n\frac{5}{6}\cdot \frac 1 6 = \frac{1}{1 - \frac{25}{36}} \cdot \frac{5}{36} = \frac{36}{11} \cdot \frac{5}{36} = \frac{5}{11}$$ Question As you can see those two probabilities differ. Second result also matches our intuition that $P(\textrm{player B wins}) < P(\textrm{Player A wins})$ but I want to ask you - which result is correct and where is the mistake with the wrong one?","Let's consider very easy game with players A and B - they roll a dice starting with player A. If any of players roll a three, then he wins. I want to calculate probability that player B wins. Intuition Intuition is that because they have even chances on winning, and player A starts, so player A has one more roll, therefore bigger chance to win. In other words player A is one roll ahead of player B so what should hold is that: Out of this we can already calculate desire probability Normal approach I want to calculate this normally (without any tricks) to compare the results. Please see the probability tree that I've created: Out of this tree we can see that: Question As you can see those two probabilities differ. Second result also matches our intuition that but I want to ask you - which result is correct and where is the mistake with the wrong one?",P(\textrm{player B wins}) < P(\textrm{player A wins}) P(\textrm{player A wins}) = P(\textrm{player B wins}) + \frac 16 P(\textrm{player B wins}) = \frac{5}{12} P(\textrm{B won}) = \frac{5}{6} \cdot \frac 1 6 + (\frac{5}{6})^2 \cdot \frac{5}{6} \cdot \frac 1 6 + (\frac{5}{6})^4 \cdot \frac 1 6 + ... = \sum_{n = 0}^\infty (\frac 5 6)^{2n}\frac{5}{6}\frac{1}{6} =  = \sum_{n = 0}^\infty(\frac{25}{36})^n\frac{5}{6}\cdot \frac 1 6 = \frac{1}{1 - \frac{25}{36}} \cdot \frac{5}{36} = \frac{36}{11} \cdot \frac{5}{36} = \frac{5}{11} P(\textrm{player B wins}) < P(\textrm{Player A wins}),"['probability', 'dice']"
96,Why is Borel measurability needed here?,Why is Borel measurability needed here?,,"Let $X,Y$ be random variables on the probability space $(\Omega,\mathcal{F})$ . Since $P(X|Y)$ is $\sigma(Y)$ -measurable, we have by the Doob-Dynkin lemma that $P(X|Y)=h(Y)$ for some Borel-measurable function $h$ . Now we define $P(X|Y=y):=h(y)$ . Suppose that there is some other $\alpha$ , such that $P(X|Y=y)=\alpha(y)$ , $PX^{-1}$ -a.e $y\in\mathbb{R}$ . Then if $\alpha$ is Borel measurable, $P(X|Y)=\alpha(Y)$ $P$ -a.e. $\omega\in\Omega$ . Why is the condition $\alpha$ is borel-measurable needed?","Let be random variables on the probability space . Since is -measurable, we have by the Doob-Dynkin lemma that for some Borel-measurable function . Now we define . Suppose that there is some other , such that , -a.e . Then if is Borel measurable, -a.e. . Why is the condition is borel-measurable needed?","X,Y (\Omega,\mathcal{F}) P(X|Y) \sigma(Y) P(X|Y)=h(Y) h P(X|Y=y):=h(y) \alpha P(X|Y=y)=\alpha(y) PX^{-1} y\in\mathbb{R} \alpha P(X|Y)=\alpha(Y) P \omega\in\Omega \alpha","['probability', 'probability-theory', 'conditional-probability', 'conditional-expectation']"
97,Link between Poisson distribution and Exponential distribution,Link between Poisson distribution and Exponential distribution,,"Let $(\sigma_i)_{i \geq 1}$ be i.i.d. random variables with Exponential distribution of parameter $\lambda$ , representing the waiting time between consecutive events . The arrival time of these events (from a $t=0$ origin) is: $$\tau_n = \sigma_1 + \sigma_2 + ... + \sigma_n$$ The number of those events happening between time $t_0=k$ and $t_1=k+1$ is: $$M_k :=\sum_{\quad j \geq 1 \\ k \leq \tau_j < k+1} 1$$ Is it true that $(M_k)$ , counting the number of events happening in a time-window $[k, k+1[$ , has a Poisson distribution? It seems true intuitively, but I would like to find a source / proof. NB: I have aleady read Link between Poisson and Exponential distribution and Relationship between Poisson and exponential distribution which may be linked, but it's not the same question. I wonder if the reciprocal is also true: let's say we have consecutive events with arrival times of $(\tau_i)_{i \geq 1}$ , such that the number $M_k$ of events happening between $[k, k+1]$ is a Poisson distribution of parameter $\lambda$ , for each integer $k$ . Can we conclude that $\sigma_i = \tau_i - \tau_{i-1}$ has an exponential distribution?","Let be i.i.d. random variables with Exponential distribution of parameter , representing the waiting time between consecutive events . The arrival time of these events (from a origin) is: The number of those events happening between time and is: Is it true that , counting the number of events happening in a time-window , has a Poisson distribution? It seems true intuitively, but I would like to find a source / proof. NB: I have aleady read Link between Poisson and Exponential distribution and Relationship between Poisson and exponential distribution which may be linked, but it's not the same question. I wonder if the reciprocal is also true: let's say we have consecutive events with arrival times of , such that the number of events happening between is a Poisson distribution of parameter , for each integer . Can we conclude that has an exponential distribution?","(\sigma_i)_{i \geq 1} \lambda t=0 \tau_n = \sigma_1 + \sigma_2 + ... + \sigma_n t_0=k t_1=k+1 M_k :=\sum_{\quad j \geq 1 \\ k \leq \tau_j < k+1} 1 (M_k) [k, k+1[ (\tau_i)_{i \geq 1} M_k [k, k+1] \lambda k \sigma_i = \tau_i - \tau_{i-1}","['probability', 'probability-distributions', 'random-variables', 'poisson-distribution', 'exponential-distribution']"
98,Wrong expected value definition in book? [duplicate],Wrong expected value definition in book? [duplicate],,"This question already has answers here : Intuition behind using complementary CDF to compute expectation for nonnegative random variables (4 answers) Closed 2 years ago . I am currently hospitalised and reading a queueing theory book. I encountered in a proof this, and I fail to understand how this is true: $$E[R_j]=\int_0^\infty{P(R_j>u)du}$$ Other than the fact that $R_j$ is a random variable defined in $[0,\infty)$ I dont think that any further context is needed for my question. Due to my hospitalisation I don't have good access to my more basic probability books but I really don't recall reading any similar alternative definition for the expected value. If someone is curious or believes that the context is important, in a stochastic renewal process with holding times $X_j$ , for a given value $x>0$ , $R_j$ is defined as $R_j=X_j$ when $X_j\le x$ , and $R_j=0$ otherwise. Regardless of context, however, I find the line in question hard to comprehend.","This question already has answers here : Intuition behind using complementary CDF to compute expectation for nonnegative random variables (4 answers) Closed 2 years ago . I am currently hospitalised and reading a queueing theory book. I encountered in a proof this, and I fail to understand how this is true: Other than the fact that is a random variable defined in I dont think that any further context is needed for my question. Due to my hospitalisation I don't have good access to my more basic probability books but I really don't recall reading any similar alternative definition for the expected value. If someone is curious or believes that the context is important, in a stochastic renewal process with holding times , for a given value , is defined as when , and otherwise. Regardless of context, however, I find the line in question hard to comprehend.","E[R_j]=\int_0^\infty{P(R_j>u)du} R_j [0,\infty) X_j x>0 R_j R_j=X_j X_j\le x R_j=0","['probability', 'probability-theory', 'expected-value', 'queueing-theory', 'renewal-processes']"
99,Exponential bound on the tail of a gaussian,Exponential bound on the tail of a gaussian,,"Let $Z$ be a centered normal variable of variance $\sigma^2$ , I am trying to prove that, $$\sup_{t>0} \left( \mathbb{P}(Z \geq t) \exp\left( \frac{t^2}{2 \sigma^2} \right) \right) = \frac{1}{2} $$ I have proven the quantity is at least $\frac{1}{2}$ , by looking at the limit for $t \to 0$ , I'm trying to upper bound the quantity inside the $\sup$ by $\frac{1}{2}$ . I've obviously tried re-writing the probability as an integral, and with a change of variable I'm able to write: $$ \mathbb{P}(Z \geq t) \exp\left( \frac{t^2}{2 \sigma^2} \right) = \int_0^{\infty} \exp \left( \frac{-u^2 - 2tu}{2 \sigma^2} \right) du $$ If I'm not mistaken we don't know how to explicitly calculate these types of integrals, and I see no obvious upper bounds. I've tried re-writing the exponential as a series (both in this expression and the original integral). I've tried integrating by parts the product of exponentials in this last expression, but it simply leads to a difference between two terms making it even harder to upper bound. I've also tried a Cauchy-Schwarz upper bound on the product of exponentials but it yields something proportional to $\frac{1}{t}$ , thus insufficient (which makes sense because only one of the functions depends on $t$ ).","Let be a centered normal variable of variance , I am trying to prove that, I have proven the quantity is at least , by looking at the limit for , I'm trying to upper bound the quantity inside the by . I've obviously tried re-writing the probability as an integral, and with a change of variable I'm able to write: If I'm not mistaken we don't know how to explicitly calculate these types of integrals, and I see no obvious upper bounds. I've tried re-writing the exponential as a series (both in this expression and the original integral). I've tried integrating by parts the product of exponentials in this last expression, but it simply leads to a difference between two terms making it even harder to upper bound. I've also tried a Cauchy-Schwarz upper bound on the product of exponentials but it yields something proportional to , thus insufficient (which makes sense because only one of the functions depends on ).",Z \sigma^2 \sup_{t>0} \left( \mathbb{P}(Z \geq t) \exp\left( \frac{t^2}{2 \sigma^2} \right) \right) = \frac{1}{2}  \frac{1}{2} t \to 0 \sup \frac{1}{2}  \mathbb{P}(Z \geq t) \exp\left( \frac{t^2}{2 \sigma^2} \right) = \int_0^{\infty} \exp \left( \frac{-u^2 - 2tu}{2 \sigma^2} \right) du  \frac{1}{t} t,"['probability', 'concentration-of-measure']"
