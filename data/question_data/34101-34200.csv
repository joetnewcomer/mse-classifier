,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What is the relationship between variance and energy,What is the relationship between variance and energy,,"I was speaking with someone today who told me that variance, in the sense of probability theory, is equivalent mathematically to energy in physics. Can anyone elaborate on this relationship?","I was speaking with someone today who told me that variance, in the sense of probability theory, is equivalent mathematically to energy in physics. Can anyone elaborate on this relationship?",,"['probability', 'probability-theory', 'soft-question', 'physics']"
1,The difference of meaning between X and E(X) or Y and E(Y) in covariance formula?,The difference of meaning between X and E(X) or Y and E(Y) in covariance formula?,,Is there some basic examples to show that there are difference meaning between X and E(X) in the covariance formula?,Is there some basic examples to show that there are difference meaning between X and E(X) in the covariance formula?,,"['probability', 'statistics']"
2,What's an atomic probability space?,What's an atomic probability space?,,What's an atomic probability space? Can a complete probability space be an atomic probability space?,What's an atomic probability space? Can a complete probability space be an atomic probability space?,,"['probability', 'probability-theory']"
3,Forms of the Levy-Khintchine formula,Forms of the Levy-Khintchine formula,,"I'm writing a survey that involves Levy processes and wanted to mention the different forms of the Levy-Khintchine formula found in literature. The most common version seems to give the Levy symbol as $$\Psi(u) = i\langle b,u \rangle - \frac{1}{2} \langle u,\Sigma u\rangle + \int_{\mathbb{R}^d} {(} e^{i\langle u,y \rangle}-1 - i\langle u,y \rangle\mathbf{1}_{|y|\le1}{)}\, dK(y)$$ while in other versions it seems to be given as $$\Psi(u) = i\langle b,u \rangle - \frac{1}{2} \langle u,\Sigma u\rangle + \int_{\mathbb{R}^d} {(} e^{i\langle u,y \rangle}-1 - \frac{ i\langle u,y \rangle}{1+|y|^2}{)} \, dK(y)$$ while at almostsure blog it is given as $$\Psi(u) = i\langle b,u \rangle - \frac{1}{2} \langle u,\Sigma u\rangle + \int_{\mathbb{R}^d}{(} e^{i\langle u,y \rangle}-1 - \frac{ i\langle u,y \rangle}{1+|y|}{)} \, dK(y).$$ Are all of these correct and equivalent? If the last one is, does anyone know a published source I could cite that mentions it?","I'm writing a survey that involves Levy processes and wanted to mention the different forms of the Levy-Khintchine formula found in literature. The most common version seems to give the Levy symbol as $$\Psi(u) = i\langle b,u \rangle - \frac{1}{2} \langle u,\Sigma u\rangle + \int_{\mathbb{R}^d} {(} e^{i\langle u,y \rangle}-1 - i\langle u,y \rangle\mathbf{1}_{|y|\le1}{)}\, dK(y)$$ while in other versions it seems to be given as $$\Psi(u) = i\langle b,u \rangle - \frac{1}{2} \langle u,\Sigma u\rangle + \int_{\mathbb{R}^d} {(} e^{i\langle u,y \rangle}-1 - \frac{ i\langle u,y \rangle}{1+|y|^2}{)} \, dK(y)$$ while at almostsure blog it is given as $$\Psi(u) = i\langle b,u \rangle - \frac{1}{2} \langle u,\Sigma u\rangle + \int_{\mathbb{R}^d}{(} e^{i\langle u,y \rangle}-1 - \frac{ i\langle u,y \rangle}{1+|y|}{)} \, dK(y).$$ Are all of these correct and equivalent? If the last one is, does anyone know a published source I could cite that mentions it?",,"['probability', 'reference-request', 'probability-theory', 'stochastic-processes']"
4,Independence of Random Variables (kernel ICA),Independence of Random Variables (kernel ICA),,"In the paper Bach, F. R., & Jordan, M. I. (2002). Kernel Independent Component   Analysis. Journal of Machine Learning Research, 3(1), 1-48.   doi:10.1162/153244303768966085 I stumpled upon the following claim involving a correlation measure the authors define, the $\mathcal F$- correlation of two univariate random variables $x_1,x_2$ relative to a vector space $\mathcal F$ of functions from $\mathbb R$ to $\mathbb R$, $$ \rho_{\mathcal F}= \sup_{f_1,f_2\in\mathcal F} \text{corr}\left(f_1(x_1),f_2(x_2)\right)= \sup_{f_1,f_2\in\mathcal F} \frac{ \text{cov}\left(f_1(x_1),f_2(x_2)\right) }{ \text{var}\left(f_1(x_1)\right)^{1/2} \text{var}\left(f_1(x_1)\right)^{1/2} }. $$ The authors state that if $x_1,x_2$ are independent, then $\rho_\mathcal{F}(x_1,x_2)=0$, but they also claim that the converse ($\rho_{\mathcal F}=0~\implies$ $x_1,x_2$ are independent) also holds when $\mathcal F$ is large enough. My question: As an example, they say that it is well known that if $\mathcal F$ contains the Fourier basis (i.e. functions $f_\omega(x) = \exp(i\omega x)$ with $\omega \in \mathbb R$) then $\rho_{\mathcal F}=0~\implies$ $x_1\bot\!\!\!\bot x_2$. My problem is, that I do not see how this is obviously true and I also failed at proving it. Unfortunately, there is no reference or proof for that claim in the paper. When I tried to prove it myself, I could not find a good starting point. First, I thought that the proof could be done via properties of the characteristic function, but I did not get far with that. I am explicitly interested in the claim for the Fourier basis and not so much in the more general claim of Bach and Jordan. If anyone could show me how to prove it (or point at a reference) I would be grateful?","In the paper Bach, F. R., & Jordan, M. I. (2002). Kernel Independent Component   Analysis. Journal of Machine Learning Research, 3(1), 1-48.   doi:10.1162/153244303768966085 I stumpled upon the following claim involving a correlation measure the authors define, the $\mathcal F$- correlation of two univariate random variables $x_1,x_2$ relative to a vector space $\mathcal F$ of functions from $\mathbb R$ to $\mathbb R$, $$ \rho_{\mathcal F}= \sup_{f_1,f_2\in\mathcal F} \text{corr}\left(f_1(x_1),f_2(x_2)\right)= \sup_{f_1,f_2\in\mathcal F} \frac{ \text{cov}\left(f_1(x_1),f_2(x_2)\right) }{ \text{var}\left(f_1(x_1)\right)^{1/2} \text{var}\left(f_1(x_1)\right)^{1/2} }. $$ The authors state that if $x_1,x_2$ are independent, then $\rho_\mathcal{F}(x_1,x_2)=0$, but they also claim that the converse ($\rho_{\mathcal F}=0~\implies$ $x_1,x_2$ are independent) also holds when $\mathcal F$ is large enough. My question: As an example, they say that it is well known that if $\mathcal F$ contains the Fourier basis (i.e. functions $f_\omega(x) = \exp(i\omega x)$ with $\omega \in \mathbb R$) then $\rho_{\mathcal F}=0~\implies$ $x_1\bot\!\!\!\bot x_2$. My problem is, that I do not see how this is obviously true and I also failed at proving it. Unfortunately, there is no reference or proof for that claim in the paper. When I tried to prove it myself, I could not find a good starting point. First, I thought that the proof could be done via properties of the characteristic function, but I did not get far with that. I am explicitly interested in the claim for the Fourier basis and not so much in the more general claim of Bach and Jordan. If anyone could show me how to prove it (or point at a reference) I would be grateful?",,"['probability', 'statistics', 'fourier-analysis', 'correlation']"
5,Exact Probability of Collision of Two Independent Random Walkers After N Steps,Exact Probability of Collision of Two Independent Random Walkers After N Steps,,"Two drunks start together at the origin at $t=0$ and every second they move with equal probability either to the right or to the left, each drunk independently from the other. What is the probability that after $N$ seconds they meet again? I may be on something but I don't know how to write this sum in a close form: \begin{equation} \sum_{n=0}^{[N/2]}\frac{N!}{n!n!(N-2n)!}\frac{1}{2^{N+2n}}  \end{equation} Any hints?","Two drunks start together at the origin at $t=0$ and every second they move with equal probability either to the right or to the left, each drunk independently from the other. What is the probability that after $N$ seconds they meet again? I may be on something but I don't know how to write this sum in a close form: \begin{equation} \sum_{n=0}^{[N/2]}\frac{N!}{n!n!(N-2n)!}\frac{1}{2^{N+2n}}  \end{equation} Any hints?",,"['probability', 'random-walk']"
6,Given K balls and N buckets what is the expected number of occupied buckets,Given K balls and N buckets what is the expected number of occupied buckets,,Given K balls and N buckets how do you calculate the expected number of buckets with at least 1 ball. Each ball is put in a bucket chosen at random with a uniform probability distribution. Assume also K $\leq$ N.,Given K balls and N buckets how do you calculate the expected number of buckets with at least 1 ball. Each ball is put in a bucket chosen at random with a uniform probability distribution. Assume also K $\leq$ N.,,"['probability', 'combinatorics']"
7,Probability of choosing the correct stick out of a hundred. Challenge from reality show.,Probability of choosing the correct stick out of a hundred. Challenge from reality show.,,So I was watching the amazing race last night and they had a mission in which the contestants had to eat from a bin with 100 popsicles where only one of those popsicles had a writing on its stick containing the clue. Immediately I thought well of course choosing the correct stick is 1 in a 100. So taking the correct stick on the first try probability is $\frac{1}{100}$. Then on the second attempt it should be  $\frac{1}{99}$ and so on.  Multiplying these results give a huge number and so it seems that the more times you try the probability of getting the correct stick decreases. while it seems that the more times you try it more probable for you to get the correct stick. So how do you calculate the probability of getting the correct one first try?  the second? What about last? I mean the probability of trying 100 times to get the correct stick? Thanks.,So I was watching the amazing race last night and they had a mission in which the contestants had to eat from a bin with 100 popsicles where only one of those popsicles had a writing on its stick containing the clue. Immediately I thought well of course choosing the correct stick is 1 in a 100. So taking the correct stick on the first try probability is $\frac{1}{100}$. Then on the second attempt it should be  $\frac{1}{99}$ and so on.  Multiplying these results give a huge number and so it seems that the more times you try the probability of getting the correct stick decreases. while it seems that the more times you try it more probable for you to get the correct stick. So how do you calculate the probability of getting the correct one first try?  the second? What about last? I mean the probability of trying 100 times to get the correct stick? Thanks.,,['probability']
8,Question about computing a Fourier transform of an integral transform related to fractional Brownian motion,Question about computing a Fourier transform of an integral transform related to fractional Brownian motion,,"I am trying to show an integral transform has a fixed point. Let $H \in (0,1)$ and consider the following integral transform whose kernel is the density of fractional Brownian motion: $$T_H f(x) = 2 \int_{0}^{\infty} \frac{1}{\sqrt{2 \pi y^{2H}}}\exp\left(\frac{-x^2}{2y^{2H}}\right) f(y) dy.$$ I want to show $T_H$ has a fixed point given by $ \phi(x) = \exp(-c|x|^{\frac{1}{2(1-H)}})$ for some $c \in \mathbb{R}$.  That is $T_H \phi (x) = \phi (x)$.  Although I do not know if this is true in general I know it is true for the case $H=\frac{1}{2}$. 1)  What is the Fourier transform of $T_H \phi(x)$ with respect x? Is it equal to a multiple of the Fourier transform of $\phi(x)$? The motivation for the problem is is that we know for the $H=\frac{1}{2}$ and $c=2$ then $\phi(x) = e^{-2|x|}$ is a fixed point for $T_{\frac{1}{2}}$.  That is the Fourier transform of  $T_{\frac{1}{2}}e^{-2|x|} = 2 \int_{0}^{\infty} \frac{e^{\frac{-x^2}{2y}}}{\sqrt{2 \pi y}} e^{-2y} dy$ is equal to $\frac{4}{k^2+4}$ which is the same as the Fourier transform of $e^{-2|x|}$.  This is from a paper titled iterated random walk by L. Turban if anyone is interested in the reference.","I am trying to show an integral transform has a fixed point. Let $H \in (0,1)$ and consider the following integral transform whose kernel is the density of fractional Brownian motion: $$T_H f(x) = 2 \int_{0}^{\infty} \frac{1}{\sqrt{2 \pi y^{2H}}}\exp\left(\frac{-x^2}{2y^{2H}}\right) f(y) dy.$$ I want to show $T_H$ has a fixed point given by $ \phi(x) = \exp(-c|x|^{\frac{1}{2(1-H)}})$ for some $c \in \mathbb{R}$.  That is $T_H \phi (x) = \phi (x)$.  Although I do not know if this is true in general I know it is true for the case $H=\frac{1}{2}$. 1)  What is the Fourier transform of $T_H \phi(x)$ with respect x? Is it equal to a multiple of the Fourier transform of $\phi(x)$? The motivation for the problem is is that we know for the $H=\frac{1}{2}$ and $c=2$ then $\phi(x) = e^{-2|x|}$ is a fixed point for $T_{\frac{1}{2}}$.  That is the Fourier transform of  $T_{\frac{1}{2}}e^{-2|x|} = 2 \int_{0}^{\infty} \frac{e^{\frac{-x^2}{2y}}}{\sqrt{2 \pi y}} e^{-2y} dy$ is equal to $\frac{4}{k^2+4}$ which is the same as the Fourier transform of $e^{-2|x|}$.  This is from a paper titled iterated random walk by L. Turban if anyone is interested in the reference.",,"['probability', 'real-analysis', 'fourier-analysis']"
9,"What is the probability that you toss next time, heads turns up","What is the probability that you toss next time, heads turns up",,"A bag contains 5 coins. Four of them are fair and one has heads on both sides. You randomly pulled one coin from the bag and tossed it 5 times, heads turned up all five times. What is the probability that you toss next time, heads turns up. (All this time you don't know you were tossing a fair coin or not).","A bag contains 5 coins. Four of them are fair and one has heads on both sides. You randomly pulled one coin from the bag and tossed it 5 times, heads turned up all five times. What is the probability that you toss next time, heads turns up. (All this time you don't know you were tossing a fair coin or not).",,['probability']
10,Probability of Drawing a Particular set of Cards from a Deck,Probability of Drawing a Particular set of Cards from a Deck,,"I think this is a pretty simple question. If I've got a deck composed of the following cards: 4x Red, 2x Green, 4x Blue, 8x Orange, 3x Purple What is the probability, after drawing 5 cards, that there will be at least 1 Red card and 1 Green card?","I think this is a pretty simple question. If I've got a deck composed of the following cards: 4x Red, 2x Green, 4x Blue, 8x Orange, 3x Purple What is the probability, after drawing 5 cards, that there will be at least 1 Red card and 1 Green card?",,['probability']
11,Density and expectation of the range of a sample of uniform random variables [closed],Density and expectation of the range of a sample of uniform random variables [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question If the variables $\alpha_1$...$\alpha_n$ are distributed uniformly in $(0,1)$, How do I show that the spread $\alpha_{(n)}$ - $\alpha_{(1)}$ has density $n (n-1) x^{n-2} (1-x)$ and expectation $(n-1)/(n+1)$? What is the probability that all $n$ points lie within an interval of length $t$?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question If the variables $\alpha_1$...$\alpha_n$ are distributed uniformly in $(0,1)$, How do I show that the spread $\alpha_{(n)}$ - $\alpha_{(1)}$ has density $n (n-1) x^{n-2} (1-x)$ and expectation $(n-1)/(n+1)$? What is the probability that all $n$ points lie within an interval of length $t$?",,[]
12,combination of brownian motion,combination of brownian motion,,"Suppose $B_t$ is a Brownian motion. As I understand, $B_2-B_1$ is independent of $B_3-B_2$ from properties of Brownian motion. Does it also mean that $B_1$ and $B_2$ are also independent? Can I use this independence to find the joint density of $B_1+B_2+B_3$ as each Brownian process is a normal process of mean 0 and variance t, it should be trivial. I've another related question. To find the expectation over a Brownian process, can I integrate my stochastic process over the normal density function for Brownian motion (mean 0 and variance t)? I hope this makes sense.","Suppose $B_t$ is a Brownian motion. As I understand, $B_2-B_1$ is independent of $B_3-B_2$ from properties of Brownian motion. Does it also mean that $B_1$ and $B_2$ are also independent? Can I use this independence to find the joint density of $B_1+B_2+B_3$ as each Brownian process is a normal process of mean 0 and variance t, it should be trivial. I've another related question. To find the expectation over a Brownian process, can I integrate my stochastic process over the normal density function for Brownian motion (mean 0 and variance t)? I hope this makes sense.",,"['probability', 'probability-theory', 'measure-theory', 'stochastic-processes']"
13,Finding a clever solution to a game of chance,Finding a clever solution to a game of chance,,"This question may smell like my older question A probability game , but this time my intentions are different. The above problem came from my friend. Or so I thought, it really came from me incorrectly remembering his problem. The problem he actually gave me was: Suppose you start with 1 dollar and flip a weighted coin. With probability 3/4 (call this heads) you win a dollar and with probability 1/4 (call this tails) you lose a dollar. What is the probability you eventually run out of money? (Suppose the house has as many dollar bills as needed). I know how to solve this problem in the following way: First observe the number of tails must equal the number of heads plus one. If a string of Hs and Ts satisfy this property, call it Good. Now we want to count the number of Good strings that don't have Good proper prefixes. For a string of length 2n-1 this is just the nth Catalan number. Now we just take the appropriate summation and we arrive at the probability we eventually run out of money which turns out to be 1/3. Now when my friend told me this problem, he said he was able to apply a clever trick and solve it almost instantly. The thing is, he doesn't remember how he did it. He says he vaguely remembers using a recurrence relation and then telescoping a sum. (Which sounds very plausible) So can you come up with a short and sweet solution? On a side note, I am aware my title is poor at best. If you can think of a better one, please let me know.","This question may smell like my older question A probability game , but this time my intentions are different. The above problem came from my friend. Or so I thought, it really came from me incorrectly remembering his problem. The problem he actually gave me was: Suppose you start with 1 dollar and flip a weighted coin. With probability 3/4 (call this heads) you win a dollar and with probability 1/4 (call this tails) you lose a dollar. What is the probability you eventually run out of money? (Suppose the house has as many dollar bills as needed). I know how to solve this problem in the following way: First observe the number of tails must equal the number of heads plus one. If a string of Hs and Ts satisfy this property, call it Good. Now we want to count the number of Good strings that don't have Good proper prefixes. For a string of length 2n-1 this is just the nth Catalan number. Now we just take the appropriate summation and we arrive at the probability we eventually run out of money which turns out to be 1/3. Now when my friend told me this problem, he said he was able to apply a clever trick and solve it almost instantly. The thing is, he doesn't remember how he did it. He says he vaguely remembers using a recurrence relation and then telescoping a sum. (Which sounds very plausible) So can you come up with a short and sweet solution? On a side note, I am aware my title is poor at best. If you can think of a better one, please let me know.",,['combinatorics']
14,Verify a solution for a recursion based probability problem and propose an alternative,Verify a solution for a recursion based probability problem and propose an alternative,,"Problem Statement: A trial succeeds at probability p, where $0 < p < 1$ . However, whenever the trial fails, p has a $\frac{2}{3}$ chance to be multiplied by $\frac{1}{2}$ and $\frac{1}{3}$ chance to be multiplied by $2$ (to a maximum of $1$ ). Is it guaranteed the trial will eventually succeed given infinite tries? My solution (I realized it is wrong after some simulations ): The decision tree (see the picture) showing all the possible events that can occur given the current probability p: Event 1: There's p chance that the process will end Event 2: There's $\frac{1}{3}(1-p)$ chance that the process will continue and p will double Event 3: There's $\frac{2}{3}(1-p)$ chance that the process will continue and p will be halved To calculate the chance that the process will stop we need to sum all the likelihoods of all of the paths that end in the tree. We do this with the following formula derived from the tree: $$f(p) = p + \frac{1}{3}(1-p) f(2p) + \frac{2}{3}(1-p) f(\frac{p}{2})$$ $$f(p) = p + (1-p)(\frac{1}{3} f(2p) + \frac{2}{3}f(\frac{p}{2}))$$ I'm not sure on the correctness of the following steps: It is intuitive and seems reasonable to say that $f(x \cdot p) = x \cdot f(p) $ . $f(p) = l$ , $f(2p) = 2l$ , $f(\frac{p}{2}) = \frac{l}{2}$ or alternatively, like with limits $f(p)=f(2p)=f(\frac{p}{2})$ ( both givin the same answer in the end, but we will use the first substitution ). $$l = p + (1-p)(\frac{1}{3} l + \frac{2}{3}l)$$ $$l = p + (1-p)l$$ $$l(1-1+p) = p$$ $$l \cdot p = p$$ $$l = 1 $$ And with this we conclude that it is guaranteed that the process will stop with infinite amount of steps. Edit: Perhaps we can upper bound $f(p)$ by assuming $f(2p) = 1$ and resolving the p<1 constraint. $$l = p + (1-p)(\frac{1}{3} + \frac{1}{3}l)$$ $$l = p + \frac{(1-p)}{3} + \frac{(1-p)}{3}l$$ $$l(1-\frac{(1-p)}{3}) = \frac{(2p+1)}{3}$$ $$l(\frac{(2+p)}{3}) = \frac{(2p+1)}{3}$$ $$l = \frac{2p+1}{p+2} $$ The only problems is that my experimental values for p = 0.125 are around 0.61 and this gives approximatively 0.588 Another upper bound can be $f(2p) = 1$ and $f(\frac{p}{2}) = f(p)$ which results in $x = 1$ meaning $f(p) < 1$","Problem Statement: A trial succeeds at probability p, where . However, whenever the trial fails, p has a chance to be multiplied by and chance to be multiplied by (to a maximum of ). Is it guaranteed the trial will eventually succeed given infinite tries? My solution (I realized it is wrong after some simulations ): The decision tree (see the picture) showing all the possible events that can occur given the current probability p: Event 1: There's p chance that the process will end Event 2: There's chance that the process will continue and p will double Event 3: There's chance that the process will continue and p will be halved To calculate the chance that the process will stop we need to sum all the likelihoods of all of the paths that end in the tree. We do this with the following formula derived from the tree: I'm not sure on the correctness of the following steps: It is intuitive and seems reasonable to say that . , , or alternatively, like with limits ( both givin the same answer in the end, but we will use the first substitution ). And with this we conclude that it is guaranteed that the process will stop with infinite amount of steps. Edit: Perhaps we can upper bound by assuming and resolving the p<1 constraint. The only problems is that my experimental values for p = 0.125 are around 0.61 and this gives approximatively 0.588 Another upper bound can be and which results in meaning",0 < p < 1 \frac{2}{3} \frac{1}{2} \frac{1}{3} 2 1 \frac{1}{3}(1-p) \frac{2}{3}(1-p) f(p) = p + \frac{1}{3}(1-p) f(2p) + \frac{2}{3}(1-p) f(\frac{p}{2}) f(p) = p + (1-p)(\frac{1}{3} f(2p) + \frac{2}{3}f(\frac{p}{2})) f(x \cdot p) = x \cdot f(p)  f(p) = l f(2p) = 2l f(\frac{p}{2}) = \frac{l}{2} f(p)=f(2p)=f(\frac{p}{2}) l = p + (1-p)(\frac{1}{3} l + \frac{2}{3}l) l = p + (1-p)l l(1-1+p) = p l \cdot p = p l = 1  f(p) f(2p) = 1 l = p + (1-p)(\frac{1}{3} + \frac{1}{3}l) l = p + \frac{(1-p)}{3} + \frac{(1-p)}{3}l l(1-\frac{(1-p)}{3}) = \frac{(2p+1)}{3} l(\frac{(2+p)}{3}) = \frac{(2p+1)}{3} l = \frac{2p+1}{p+2}  f(2p) = 1 f(\frac{p}{2}) = f(p) x = 1 f(p) < 1,"['probability', 'limits', 'recursion']"
15,"How many natural numbers $a\le100$ are there such that $a=[\frac a2]+[\frac a3]+[\frac a5]$, where [.] represents the greatest integer function?","How many natural numbers  are there such that , where [.] represents the greatest integer function?",a\le100 a=[\frac a2]+[\frac a3]+[\frac a5],"A natural number $a$ is selected from the first $100$ natural numbers. The probability that $a=[\frac a2]+[\frac a3]+[\frac a5]$ , where [.] represents greatest integer function, is $\frac mn$ where $m,n$ are coprime then $(m+n)$ is equal to My Attempt: Let $a=30n+\gamma$ , where $0\le\gamma\lt30$ Putting this in the given equation, I get, $n=\gamma-[\frac{\gamma}{2}]-[\frac{\gamma}{3}]-[\frac{\gamma}{5}]$ $\gamma=0$ doesn't satisfy but $\gamma=1, 2, ..., 29$ satisfy. So, the probability is $\frac{29}{100}$ . Is this correct?","A natural number is selected from the first natural numbers. The probability that , where [.] represents greatest integer function, is where are coprime then is equal to My Attempt: Let , where Putting this in the given equation, I get, doesn't satisfy but satisfy. So, the probability is . Is this correct?","a 100 a=[\frac a2]+[\frac a3]+[\frac a5] \frac mn m,n (m+n) a=30n+\gamma 0\le\gamma\lt30 n=\gamma-[\frac{\gamma}{2}]-[\frac{\gamma}{3}]-[\frac{\gamma}{5}] \gamma=0 \gamma=1, 2, ..., 29 \frac{29}{100}","['probability', 'combinatorics', 'discrete-mathematics', 'solution-verification', 'contest-math']"
16,Uniform Distribution Game,Uniform Distribution Game,,"Here is a probability game description: You generate a uniformly random number in the interval (0,1). You can generate additional random numbers as many times as you want for a fee of $ 0.02 per generation. This decision can be made with the information of all of the previous values that have been generated. Your payout is the maximum of all the numbers you generate. Under the optimal strategy, find your expected payout of this game. For this game, my approach was to determine the number of rolls n, at which the expected difference between the maximum of n rolls and n-1 rolls is below 0.02. This would be the point at which I wouldn't roll anymore, as the fee overshadows the expected gain. Setting this up as follows: $X = Max( X_1,...X_n)$ , $Y = Max(X_1,...,X_{n-1})$ $E(X) - E(Y) \leq 0.02 $ $\frac{n}{n+1} - \frac{n-1}{n} \leq 0.02$ Solving this, we get n = 6.58. Then, as the number of rolls is discrete, we take n=6. Then the expected payout should be: $Payout = \frac{6}{7} - 0.02*5 = 0.76$ However, the answer is 0.82. What is wrong with my logic?","Here is a probability game description: You generate a uniformly random number in the interval (0,1). You can generate additional random numbers as many times as you want for a fee of $ 0.02 per generation. This decision can be made with the information of all of the previous values that have been generated. Your payout is the maximum of all the numbers you generate. Under the optimal strategy, find your expected payout of this game. For this game, my approach was to determine the number of rolls n, at which the expected difference between the maximum of n rolls and n-1 rolls is below 0.02. This would be the point at which I wouldn't roll anymore, as the fee overshadows the expected gain. Setting this up as follows: , Solving this, we get n = 6.58. Then, as the number of rolls is discrete, we take n=6. Then the expected payout should be: However, the answer is 0.82. What is wrong with my logic?","X = Max( X_1,...X_n) Y = Max(X_1,...,X_{n-1}) E(X) - E(Y) \leq 0.02  \frac{n}{n+1} - \frac{n-1}{n} \leq 0.02 Payout = \frac{6}{7} - 0.02*5 = 0.76","['probability', 'expected-value', 'game-theory', 'uniform-distribution']"
17,Probability of following the right person,Probability of following the right person,,"The following question was found in my textbook on probability. It is a question from the math olympiade final in Belgium, edition 1992 (actually the Flemish part of Belgium, the contest is called 'De Vlaamse Wiskunde Olympiade). I gave it a shot. Below is the question and my attempt at a solution. Through an informant in the underworld, the police have learned where a gang gathers. The identity of the gang members is unknown. An agent is tasked with shadowing the leader of the gang. He only knows that the gang leader is the tallest of five individuals, all of different heights. After the meeting, the gangsters leave the building one by one, leaving a quarter of an hour between each departure. The agent cannot see who the tallest person is and decides to let the first two go, then follow the first one who is taller than those who left before him. What is the chance that the agent shadows the right man? According to my book, the correct answer should be $13/30$ . Attempt at a solution: There are a total of $5! = 120$ possibilities. We will count the favorable possibilities. Note that if the leader leaves the building first or second, the agent can not follow the leader. Therefore, we need to consider the leader leaving third, fourth or fifth. If the leader is the third person to leave : the agent will follow him, no matter the order the other gangsters appear in. Number of possibilities: $4! = 24$ If the leader is the fifth person to leave : the second tallest gangster had to leave first or second in order for the agent to follow the correct person. There are 3 remaining possibilities for the other gangster leaving first or second. The order of the remaining two gangsters is fixed: from largest to smallest. Therefore, there are a total of $2\cdot 3\cdot 1 \cdot 1 =    6$ possibilities to follow the leader if he appears last. If the leader is the fourth person to leave : We distinguish two cases: If the second tallest gangster appeared first or second, there is no problem. Number of possibilities: $2 \cdot 3! = 12$ . If the second talles gangster did not appear first or second, he needs to appear last. The third tallest gangster should then appear first or second, otherwise the agent will follow him. Therefore, there are $2\cdot 2\cdot 1 \cdot 1 = 4$ possibilities. This totals $24 + 6 + 12 + 4 = 46$ cases. Unfortunatly $46/120$ does not simplify to the desired answer. Question: What cases am I missing? I'm also interested to know other approaches to this problem. EDIT: as pointed out by Heropup and Bram28, I made a mistake in the part where the leader emerges last: the police only follows if a gangster is taller than all previous gangsters. Therefore, if the second tallest gangster left first or second, the police will follow the leader, no matter what order the other three gangster emerge. There are $2 \cdot 3! = 12$ possibilities instead of $6$ .}","The following question was found in my textbook on probability. It is a question from the math olympiade final in Belgium, edition 1992 (actually the Flemish part of Belgium, the contest is called 'De Vlaamse Wiskunde Olympiade). I gave it a shot. Below is the question and my attempt at a solution. Through an informant in the underworld, the police have learned where a gang gathers. The identity of the gang members is unknown. An agent is tasked with shadowing the leader of the gang. He only knows that the gang leader is the tallest of five individuals, all of different heights. After the meeting, the gangsters leave the building one by one, leaving a quarter of an hour between each departure. The agent cannot see who the tallest person is and decides to let the first two go, then follow the first one who is taller than those who left before him. What is the chance that the agent shadows the right man? According to my book, the correct answer should be . Attempt at a solution: There are a total of possibilities. We will count the favorable possibilities. Note that if the leader leaves the building first or second, the agent can not follow the leader. Therefore, we need to consider the leader leaving third, fourth or fifth. If the leader is the third person to leave : the agent will follow him, no matter the order the other gangsters appear in. Number of possibilities: If the leader is the fifth person to leave : the second tallest gangster had to leave first or second in order for the agent to follow the correct person. There are 3 remaining possibilities for the other gangster leaving first or second. The order of the remaining two gangsters is fixed: from largest to smallest. Therefore, there are a total of possibilities to follow the leader if he appears last. If the leader is the fourth person to leave : We distinguish two cases: If the second tallest gangster appeared first or second, there is no problem. Number of possibilities: . If the second talles gangster did not appear first or second, he needs to appear last. The third tallest gangster should then appear first or second, otherwise the agent will follow him. Therefore, there are possibilities. This totals cases. Unfortunatly does not simplify to the desired answer. Question: What cases am I missing? I'm also interested to know other approaches to this problem. EDIT: as pointed out by Heropup and Bram28, I made a mistake in the part where the leader emerges last: the police only follows if a gangster is taller than all previous gangsters. Therefore, if the second tallest gangster left first or second, the police will follow the leader, no matter what order the other three gangster emerge. There are possibilities instead of .}","13/30 5! = 120 4! = 24 2\cdot 3\cdot 1 \cdot 1 =
   6 2 \cdot 3! = 12 2\cdot 2\cdot 1 \cdot 1 = 4 24 + 6 + 12 + 4 = 46 46/120 2 \cdot 3! = 12 6","['probability', 'contest-math', 'recreational-mathematics']"
18,An Upper Bound for Entropy $H(X)$ in Terms of $\mathbb{E}(\log X)$,An Upper Bound for Entropy  in Terms of,H(X) \mathbb{E}(\log X),"Suppose that $X:\Omega\to\mathbb{N}$ is a discrete random variable with PMF $p:\mathbb{R}\to\mathbb{R}$ , where $\mathrm{supp} p = \mathrm{range} X = \mathbb{N}$ . I want to prove that If $\mathbb{E}(\log_2 X) < \infty$ then $H(X) < \infty$ . The first thing that comes to mind is to find an upper bound for $H(X)$ in terms of $\mathbb{E}(\log_2 X)$ . Expanding the expression for each of these we have $$ H(X) = \sum_{i=1}^{\infty}p(i)\log\frac{1}{p(i)}, \qquad \mathbb{E}(\log_2 X) = \sum_{i=1}^{\infty}p(i)\log_2 i. $$ I have no idea for going on.","Suppose that is a discrete random variable with PMF , where . I want to prove that If then . The first thing that comes to mind is to find an upper bound for in terms of . Expanding the expression for each of these we have I have no idea for going on.","X:\Omega\to\mathbb{N} p:\mathbb{R}\to\mathbb{R} \mathrm{supp} p = \mathrm{range} X = \mathbb{N} \mathbb{E}(\log_2 X) < \infty H(X) < \infty H(X) \mathbb{E}(\log_2 X) 
H(X) = \sum_{i=1}^{\infty}p(i)\log\frac{1}{p(i)}, \qquad
\mathbb{E}(\log_2 X) = \sum_{i=1}^{\infty}p(i)\log_2 i.
","['probability', 'analysis', 'upper-lower-bounds', 'entropy']"
19,The Probability of Two Contestants Meeting (Ross),The Probability of Two Contestants Meeting (Ross),,"This problem from Ross has been giving me grief, and none of the resources I’ve found have been helpful in elucidating where I’ve gone astray. $2^n$ players are paired off at random in a contest where each contestant is $50\%$ likely to win. The $2^{n-1}$ winners are paired off again randomly, and so on, until a single winner remains. Consider two contestants A and B, and events $A_i, i = 1, 2, …, n$ , and $E$ , defined by $A_i$ : A plays in exactly i contests. $E$ : A and B ever play each other during the course of the contest. (Not never!) What is $P(A_i)$ ? And what is $P(E)$ ? $P(A_i)$ is straightforward; $P(A_i) = (1/2)^i$ for $i=1,2,…,n-1$ and $P(A_n) = (1/2)^{n-1}$ . As for $P(E)$ , we can condition on the $A_i$ as they partition the space, but the trouble comes with calculating $P(E|A_i)$ . $P(E|A_1) = \frac{1}{2^n -1}$ . $P(E | A_2)$ to me seems to be $\frac{1}{2^n -1} + \frac{1}{2^n -2} \frac{1}{2}$ , as A can either meet B in round 1, or in round 2, if B wins in round 1. The formula for $P(E)$ gets messy in this case, and I’m further dissuaded from this answer by the hint that Ross provides, which is the formula $\sum_{i=1}^{n-1}ix^{i-1} = \frac{1-nx^{n-1} + (n-1)x^n}{(1-x)^2}$ Which suggests to me the possibility that $P(E|A_i) = \frac{i}{2^n -1}$ , which I could reason as A plays $i$ opponents, all of which are equally likely. But this does not arrive at the proper solution of $ P(E) = \frac{1}{2^{n-1}}$ either. What am I missing in my understanding of $P(E | A_i)$ ?","This problem from Ross has been giving me grief, and none of the resources I’ve found have been helpful in elucidating where I’ve gone astray. players are paired off at random in a contest where each contestant is likely to win. The winners are paired off again randomly, and so on, until a single winner remains. Consider two contestants A and B, and events , and , defined by : A plays in exactly i contests. : A and B ever play each other during the course of the contest. (Not never!) What is ? And what is ? is straightforward; for and . As for , we can condition on the as they partition the space, but the trouble comes with calculating . . to me seems to be , as A can either meet B in round 1, or in round 2, if B wins in round 1. The formula for gets messy in this case, and I’m further dissuaded from this answer by the hint that Ross provides, which is the formula Which suggests to me the possibility that , which I could reason as A plays opponents, all of which are equally likely. But this does not arrive at the proper solution of either. What am I missing in my understanding of ?","2^n 50\% 2^{n-1} A_i, i = 1, 2, …, n E A_i E P(A_i) P(E) P(A_i) P(A_i) = (1/2)^i i=1,2,…,n-1 P(A_n) = (1/2)^{n-1} P(E) A_i P(E|A_i) P(E|A_1) = \frac{1}{2^n -1} P(E | A_2) \frac{1}{2^n -1} + \frac{1}{2^n -2} \frac{1}{2} P(E) \sum_{i=1}^{n-1}ix^{i-1} = \frac{1-nx^{n-1} + (n-1)x^n}{(1-x)^2} P(E|A_i) = \frac{i}{2^n -1} i  P(E) = \frac{1}{2^{n-1}} P(E | A_i)","['probability', 'combinatorics']"
20,20 two colored balls into 4 bins,20 two colored balls into 4 bins,,"We have $16$ red identical balls and $4$ black identical balls. We have $4$ bins and put all balls randomly into the bins such that each bin contains $5$ balls at the end. Each arrangement has the same probability. How many ways are there to distribute the balls into the bins? What is the probability that all black balls are in different bins? My idea was to realize that the red balls have no influence, so the number of all arrangements is simply ${4+4-1\choose 4}$ . As all black balls are identical there is only one way that all black balls are in different bins, hence the probability is $\frac{1}{{7\choose 4}}$ . But this Sound too easy... what do I miss? Or is it correct?","We have red identical balls and black identical balls. We have bins and put all balls randomly into the bins such that each bin contains balls at the end. Each arrangement has the same probability. How many ways are there to distribute the balls into the bins? What is the probability that all black balls are in different bins? My idea was to realize that the red balls have no influence, so the number of all arrangements is simply . As all black balls are identical there is only one way that all black balls are in different bins, hence the probability is . But this Sound too easy... what do I miss? Or is it correct?",16 4 4 5 {4+4-1\choose 4} \frac{1}{{7\choose 4}},"['probability', 'combinatorics', 'balls-in-bins']"
21,Keep rolling two dice until the cumulative sum hits 1000,Keep rolling two dice until the cumulative sum hits 1000,,"Suppose I roll two dice until the cumulative sum hits 1000 (inclusive). What's the most likely last roll? That is, suppose $X$ is the sum of the two dice during the first roll that makes the cumulative sum go over 1000. What's its mode? I'm struggling to get the answer. I know the most likely sum from a roll of two dice is $7$ . I also know how to compute the expected value of the last roll if I were rolling just one die. However, I'm stuck on computing the mode of rolling tow dice. Can someone help?","Suppose I roll two dice until the cumulative sum hits 1000 (inclusive). What's the most likely last roll? That is, suppose is the sum of the two dice during the first roll that makes the cumulative sum go over 1000. What's its mode? I'm struggling to get the answer. I know the most likely sum from a roll of two dice is . I also know how to compute the expected value of the last roll if I were rolling just one die. However, I'm stuck on computing the mode of rolling tow dice. Can someone help?",X 7,"['probability', 'dice']"
22,Why study probabilities in deterministic dynamical systems?,Why study probabilities in deterministic dynamical systems?,,"When studying hyperbolic dynamics and ergodic theory, one often come with probabilities (measures that give to the total space measure 1) even in deterministic systems. Do these have some intuitive interpretation as a probability? Because it seems rather strange to me to put probabilities in deterministic systems, since it hardly seems to mean anything: any probability that you would put on it seems to be arbitrary and not actually meaning anything about the system. Or should it just be viewed (intuitively) as a usual measure (that is finite so you can make calculations easier but normalizing it)?","When studying hyperbolic dynamics and ergodic theory, one often come with probabilities (measures that give to the total space measure 1) even in deterministic systems. Do these have some intuitive interpretation as a probability? Because it seems rather strange to me to put probabilities in deterministic systems, since it hardly seems to mean anything: any probability that you would put on it seems to be arbitrary and not actually meaning anything about the system. Or should it just be viewed (intuitively) as a usual measure (that is finite so you can make calculations easier but normalizing it)?",,"['probability', 'measure-theory', 'soft-question', 'dynamical-systems', 'ergodic-theory']"
23,Joint pdf of the two highest values extracted from a uniform distribution,Joint pdf of the two highest values extracted from a uniform distribution,,"An observable $x$ follows a uniform distribution U([0,m]), where $m$ is a known parameter. Given $N$ independent observation, we retain only the two highest values among the N observations (let's call them $x_1$ and $x_2$ ). My goal is to determine the joint probability distribution $P(x_1,x_2)$ of $x_1$ and $x_2$ . I am aware that according to the definition, I can express this joint probability as \begin{equation} P(x_1,x_2)=P(x_1)P(x_2|x_1)=P(x_2)P(x_1|x_2), \end{equation} where $P(x_1)=\frac{N}{m^N}x_1^{N-1}$ is the probability of extracting the highest value, $P(x_2)=\frac{N(N-1)}{m^N}x_2^{N-2}(m-x_2)$ is the probability of extracting the second highest value, $P(x_1|x_2)$ or $P(x_2|x_1)$ are the conditional probabilities. How can I determine these two conditional probabilities?  Alternatively, is there a more effective method to calculate this joint probability?","An observable follows a uniform distribution U([0,m]), where is a known parameter. Given independent observation, we retain only the two highest values among the N observations (let's call them and ). My goal is to determine the joint probability distribution of and . I am aware that according to the definition, I can express this joint probability as where is the probability of extracting the highest value, is the probability of extracting the second highest value, or are the conditional probabilities. How can I determine these two conditional probabilities?  Alternatively, is there a more effective method to calculate this joint probability?","x m N x_1 x_2 P(x_1,x_2) x_1 x_2 \begin{equation}
P(x_1,x_2)=P(x_1)P(x_2|x_1)=P(x_2)P(x_1|x_2),
\end{equation} P(x_1)=\frac{N}{m^N}x_1^{N-1} P(x_2)=\frac{N(N-1)}{m^N}x_2^{N-2}(m-x_2) P(x_1|x_2) P(x_2|x_1)","['probability', 'conditional-probability']"
24,Probability of winning a match given probability of winning a game,Probability of winning a match given probability of winning a game,,"If a team has probability p of winning each game, and if the team wins/loses a match when it is 2 games ahead/behind the other team, is there an analytical formula or approximation for the probability that the team wins the match, as a function of p? One can of course resort to Monte Carlo. Here is what I tried: p = prob of A winning each game p1 = prob of A winning when match tied p2 = prob of A winning when ahead by 1 game p3 = prob of A winning when behind by 1 game  p1 = p*p2 + (1-p)*p3 = p*p2 + p3 - p*p3 p2 = p + (1-p)*p1    = p + p1 - p*p1 p3 = p*p1 + 1 - p    = p*p1 + 1 - p  plug last into first:  p1 = p*p2 + (1-p) * (p*p1 + 1 - p)  plug 2nd into above  p1 = p*(p + p1 - p*p1) + (1-p) * (p*p1 + 1 - p)    = p^2 + p*p1 - p^2*p1 + p*p1 + 1 - p - p^2*p1 - p + p^2  p1 = (2*p^2 - 2*p + 1)/(2*p^2 - p + 1) But for p=0 , this gives p1=1 , which is wrong.","If a team has probability p of winning each game, and if the team wins/loses a match when it is 2 games ahead/behind the other team, is there an analytical formula or approximation for the probability that the team wins the match, as a function of p? One can of course resort to Monte Carlo. Here is what I tried: p = prob of A winning each game p1 = prob of A winning when match tied p2 = prob of A winning when ahead by 1 game p3 = prob of A winning when behind by 1 game  p1 = p*p2 + (1-p)*p3 = p*p2 + p3 - p*p3 p2 = p + (1-p)*p1    = p + p1 - p*p1 p3 = p*p1 + 1 - p    = p*p1 + 1 - p  plug last into first:  p1 = p*p2 + (1-p) * (p*p1 + 1 - p)  plug 2nd into above  p1 = p*(p + p1 - p*p1) + (1-p) * (p*p1 + 1 - p)    = p^2 + p*p1 - p^2*p1 + p*p1 + 1 - p - p^2*p1 - p + p^2  p1 = (2*p^2 - 2*p + 1)/(2*p^2 - p + 1) But for p=0 , this gives p1=1 , which is wrong.",,['probability']
25,Is the Rényi entropy a continuous function with respect to the parameter $\alpha$?,Is the Rényi entropy a continuous function with respect to the parameter ?,\alpha,"The Rényi entropy of order $\alpha$ , where $\alpha > 0$ and $\alpha \neq 1$ , is defined as $$ \mathrm{H}_\alpha(X)=\frac{1}{1-\alpha} \log \left(\sum_{i=1}^n p_i^\alpha\right)  $$ Here, $X$ is a discrete random variable with possible outcomes in the set $\mathcal{A}=\left\{x_1, x_2, \ldots, x_n\right\}$ and corresponding probabilities $p_i \doteq \operatorname{Pr}\left(X=x_i\right)$ . I would like to know if $\mathrm{H}_\alpha(X)$ , considered as a function of $\alpha$ , is a continuous function. I think that, if the probability distribution function $p_i$ is $\neq0$ for all $i$ , then $\mathrm{H}_\alpha(X)$ will be a continuous function of $\alpha$ . This is because the sum and logarithm operations in the entropy formula are continuous functions, and the composition of continuous functions remains continuous. Is it true also if $p_i=0$ for some $i$ ?","The Rényi entropy of order , where and , is defined as Here, is a discrete random variable with possible outcomes in the set and corresponding probabilities . I would like to know if , considered as a function of , is a continuous function. I think that, if the probability distribution function is for all , then will be a continuous function of . This is because the sum and logarithm operations in the entropy formula are continuous functions, and the composition of continuous functions remains continuous. Is it true also if for some ?","\alpha \alpha > 0 \alpha \neq 1 
\mathrm{H}_\alpha(X)=\frac{1}{1-\alpha} \log \left(\sum_{i=1}^n p_i^\alpha\right) 
 X \mathcal{A}=\left\{x_1, x_2, \ldots, x_n\right\} p_i \doteq \operatorname{Pr}\left(X=x_i\right) \mathrm{H}_\alpha(X) \alpha p_i \neq0 i \mathrm{H}_\alpha(X) \alpha p_i=0 i","['probability', 'information-theory', 'entropy', 'renyi-entropy']"
26,"What is the probability that the first ball drawn was black, given the event $X_3 \leq 5$","What is the probability that the first ball drawn was black, given the event",X_3 \leq 5,"Im trying to solve the following question: There is a urn with 1 black ball and 1 red ball. A ball is drawn at random from the urn, it is placed back in the urn along with 2 more balls with the same color as the ball that was drawn. Denote the random variable Xi to be the number of black balls after the i-th draw, i = 1, 2, . . .. Note that $X_i$ is the random variable for number of black balls in the urn including the two new balls added after the i-th draw. What is the probability that the first ball drawn was black, given the event $X_3 \leq 5$ ? This is what I have so far: $$P(X_3=1 | X_3\leq 5)=\frac{P(X_3=1 \cap X_3\leq 5)}{P(X_3\leq 5)}=\frac{P(X_3=1)}{P(X_3=1)+P(X_3=3)+P(X_3=5)}$$ Hence, $$\frac{\frac{5}{16}}{\frac{5}{16}+\frac{3}{16}+\frac{3}{16}}$$ Correct?","Im trying to solve the following question: There is a urn with 1 black ball and 1 red ball. A ball is drawn at random from the urn, it is placed back in the urn along with 2 more balls with the same color as the ball that was drawn. Denote the random variable Xi to be the number of black balls after the i-th draw, i = 1, 2, . . .. Note that is the random variable for number of black balls in the urn including the two new balls added after the i-th draw. What is the probability that the first ball drawn was black, given the event ? This is what I have so far: Hence, Correct?",X_i X_3 \leq 5 P(X_3=1 | X_3\leq 5)=\frac{P(X_3=1 \cap X_3\leq 5)}{P(X_3\leq 5)}=\frac{P(X_3=1)}{P(X_3=1)+P(X_3=3)+P(X_3=5)} \frac{\frac{5}{16}}{\frac{5}{16}+\frac{3}{16}+\frac{3}{16}},"['probability', 'combinatorics', 'solution-verification']"
27,Upper Bounding the Discrete Entropy by the Expectation,Upper Bounding the Discrete Entropy by the Expectation,,"Let $\mathcal P$ be the set of probability mass functions (pmfs) on $\mathbb Z_{>0}$ , i.e. for $p=(p(x))_{x\in\mathbb Z_{>0}}\in\mathcal P$ we have $p\ge 0$ and $\sum_{x=1}^\infty p(x)=1$ . Let $H(p)=-\sum_{x=1}^\infty p(x)\ln(p(x))$ be the entropy and $E(p)=\sum_{x=1}^\infty p(x)x$ the expectation. Further, let $s(p)=|\{x\in\mathbb Z_{>0}:p(x)>0\}|$ be the size of the support of $p$ . For $s\in\mathbb Z_{>0}$ let $\mathcal P_s=\{p\in\mathcal P:s(p)=s\}$ , and further let $\mathcal P_\infty=\{p\in\mathcal P:s(p)=\infty,E(p)<\infty\}$ . Question : What are the best bounds for $r(s)=\sup_{p\in\mathcal P_s}H(p)/E(p)$ ? Motivation : I want good upper bounds for the entropy in terms of the support size and the expectation. Background : The question only makes sense if we consider strictly positive random variables, otherwise $r(s)$ would be infinite, which can be seen by taking limits towards the one-point mass on $0$ . For this question we can assume that $p$ is supported on $\{1,\dots,s\}$ , respectively $\mathbb Z_{>0}$ for $s=\infty$ , and non-increasing, since ordering the weights minimizes the expectation while preserving the entropy. For $s<\infty$ we have $r(s)\le\ln(s)$ because $H(p)\le\ln(s)$ is maximal for the uniform distribution and $E(p)\ge 1$ . Of course, with the uniform distribution we also get a lower bound, namely $r(s)\ge 2\ln(s)/(s+1)$ , which is not tight because the entropy is stationary at the uniform distribution while the expectation is not. Also, we know that the supremum is attained due to continuity. Of course, identifying the maximizers would be highly desirable. For $s=\infty$ it is known that $H(p)=E(p)=\infty$ is possible, as discussed here . As can be seen here , there are also quite a few follow-up questions. Unfortunately, I am not convinced by the given answer, and am still not aware of an answer to the question if $H(p)<\infty$ for all $p\in\mathcal P_\infty$ . Should this be true, we may of course still have $r(\infty)=\infty$ , and in any case explicit maximizing sequences would be highly desirable. Finally, a similar question regarding a lower bound can be found here . Update : A limiting argument directly yields that $r(s+1)\ge r(s)$ . As discussed here , we have $H(p)\le\ln(E(p)+0.5)+1$ given by Theorem 8 in this preprint. The map $f(x)=(\ln(x+0.5)+1)/x$ is decreasing on $[1,\infty)$ , with $f(x)=1$ for $x\approx 1.858$ . Since we can assume that $p$ is non-increasing, we have $E(p)\le\frac{1+s}{2}$ . We clearly have $r(1)=0$ and a discussion of $f(p_1)=\frac{H(p_1)}{p_1+2(1-p_1)}$ gives the maximizer $p_1=\frac{1}{2}(\sqrt 5-1)\approx 0.618$ , the expectation $E(p)\approx 1.382$ and $r(2)\approx 0.481$ . For $s=3$ we fix $\mu\in(1,2]$ and consider $p_1\ge p_2\ge p_3\ge 0$ with $p_1+p_2+p_3=1$ and $E(p)=\mu$ . Set $p_3=x$ and observe that $p_1=2-\mu+x$ , $p_2=\mu-1-2x$ , and that $\max(0,\frac{2}{3}\mu-1)\le x\le\frac{1}{3}(\mu-1)$ . The derivative $\ln(\frac{p_2^2}{p_1p_3})$ of the entropy on this restriction is decreasing with exactly one root $x=\frac{1}{2}\mu-\frac{1}{3}-\frac{1}{6}\sqrt{4-3(2-\mu)^2}$ . Numerical evaluation gives \begin{align*} p_1&\approx 0.544\\ p_2&\approx 0.296\\ p_3&\approx 0.161\\ E(p)&\approx 1.617\\ r(3)&\approx 0.609. \end{align*}","Let be the set of probability mass functions (pmfs) on , i.e. for we have and . Let be the entropy and the expectation. Further, let be the size of the support of . For let , and further let . Question : What are the best bounds for ? Motivation : I want good upper bounds for the entropy in terms of the support size and the expectation. Background : The question only makes sense if we consider strictly positive random variables, otherwise would be infinite, which can be seen by taking limits towards the one-point mass on . For this question we can assume that is supported on , respectively for , and non-increasing, since ordering the weights minimizes the expectation while preserving the entropy. For we have because is maximal for the uniform distribution and . Of course, with the uniform distribution we also get a lower bound, namely , which is not tight because the entropy is stationary at the uniform distribution while the expectation is not. Also, we know that the supremum is attained due to continuity. Of course, identifying the maximizers would be highly desirable. For it is known that is possible, as discussed here . As can be seen here , there are also quite a few follow-up questions. Unfortunately, I am not convinced by the given answer, and am still not aware of an answer to the question if for all . Should this be true, we may of course still have , and in any case explicit maximizing sequences would be highly desirable. Finally, a similar question regarding a lower bound can be found here . Update : A limiting argument directly yields that . As discussed here , we have given by Theorem 8 in this preprint. The map is decreasing on , with for . Since we can assume that is non-increasing, we have . We clearly have and a discussion of gives the maximizer , the expectation and . For we fix and consider with and . Set and observe that , , and that . The derivative of the entropy on this restriction is decreasing with exactly one root . Numerical evaluation gives","\mathcal P \mathbb Z_{>0} p=(p(x))_{x\in\mathbb Z_{>0}}\in\mathcal P p\ge 0 \sum_{x=1}^\infty p(x)=1 H(p)=-\sum_{x=1}^\infty p(x)\ln(p(x)) E(p)=\sum_{x=1}^\infty p(x)x s(p)=|\{x\in\mathbb Z_{>0}:p(x)>0\}| p s\in\mathbb Z_{>0} \mathcal P_s=\{p\in\mathcal P:s(p)=s\} \mathcal P_\infty=\{p\in\mathcal P:s(p)=\infty,E(p)<\infty\} r(s)=\sup_{p\in\mathcal P_s}H(p)/E(p) r(s) 0 p \{1,\dots,s\} \mathbb Z_{>0} s=\infty s<\infty r(s)\le\ln(s) H(p)\le\ln(s) E(p)\ge 1 r(s)\ge 2\ln(s)/(s+1) s=\infty H(p)=E(p)=\infty H(p)<\infty p\in\mathcal P_\infty r(\infty)=\infty r(s+1)\ge r(s) H(p)\le\ln(E(p)+0.5)+1 f(x)=(\ln(x+0.5)+1)/x [1,\infty) f(x)=1 x\approx 1.858 p E(p)\le\frac{1+s}{2} r(1)=0 f(p_1)=\frac{H(p_1)}{p_1+2(1-p_1)} p_1=\frac{1}{2}(\sqrt 5-1)\approx 0.618 E(p)\approx 1.382 r(2)\approx 0.481 s=3 \mu\in(1,2] p_1\ge p_2\ge p_3\ge 0 p_1+p_2+p_3=1 E(p)=\mu p_3=x p_1=2-\mu+x p_2=\mu-1-2x \max(0,\frac{2}{3}\mu-1)\le x\le\frac{1}{3}(\mu-1) \ln(\frac{p_2^2}{p_1p_3}) x=\frac{1}{2}\mu-\frac{1}{3}-\frac{1}{6}\sqrt{4-3(2-\mu)^2} \begin{align*}
p_1&\approx 0.544\\
p_2&\approx 0.296\\
p_3&\approx 0.161\\
E(p)&\approx 1.617\\
r(3)&\approx 0.609.
\end{align*}","['probability', 'probability-distributions', 'examples-counterexamples', 'information-theory', 'entropy']"
28,Azuma's inequality for a simple case of Polya's urn,Azuma's inequality for a simple case of Polya's urn,,"Suppose that an urn contains one red ball and one blue ball. A ball is drawn from the urn uniformly at random. After that, the ball is put back into the urn and another ball of the same colour is added to the urn. This process is repeated $n$ times. Denote by $X_n$ the proportion of red balls in the urn after these $n$ steps (i.e. number of red balls divided by total number of balls). Use Azuma’s inequality to prove that $$\mathbb{P}\bigg[ \bigg\lvert X_n - \frac{1}{2} \bigg\rvert\ge \varepsilon \bigg] \le 2\exp\bigg(-\frac{6\varepsilon^2}{2\pi^2-15} \bigg)$$ Remark: In class I learned the following version of Azuma's inequality: Let $(X_0, \ldots, X_n)$ be a martingale with $X_0 = 0$ and $\lvert X_i - X_{i-1} \rvert \le 1 \quad (\forall 1 \le i \le n)$ . Then for any $t > 0$ it holds $$\mathbb{P}\bigg[\lvert X_n - \mathbb{E}[X_n]\rvert \ge \varepsilon \bigg]   \le 2\exp\bigg(-\frac{\varepsilon^2}{2n} \bigg)$$ I already know that $(X_n)_n$ is a martingale that fullfills the conditions for Azuma's inequality and has the property that $\mathbb{E}[X_n] = 1/2$ .  However I do not see where the term $-\frac{6\varepsilon^2}{2\pi^2-15} $ should come from. Could you please give me a hint?","Suppose that an urn contains one red ball and one blue ball. A ball is drawn from the urn uniformly at random. After that, the ball is put back into the urn and another ball of the same colour is added to the urn. This process is repeated times. Denote by the proportion of red balls in the urn after these steps (i.e. number of red balls divided by total number of balls). Use Azuma’s inequality to prove that Remark: In class I learned the following version of Azuma's inequality: Let be a martingale with and . Then for any it holds I already know that is a martingale that fullfills the conditions for Azuma's inequality and has the property that .  However I do not see where the term should come from. Could you please give me a hint?","n X_n n \mathbb{P}\bigg[ \bigg\lvert X_n - \frac{1}{2} \bigg\rvert\ge \varepsilon \bigg] \le 2\exp\bigg(-\frac{6\varepsilon^2}{2\pi^2-15} \bigg) (X_0, \ldots, X_n) X_0 = 0 \lvert X_i - X_{i-1} \rvert \le 1 \quad (\forall 1 \le i \le n) t > 0 \mathbb{P}\bigg[\lvert X_n - \mathbb{E}[X_n]\rvert \ge \varepsilon \bigg]   \le 2\exp\bigg(-\frac{\varepsilon^2}{2n} \bigg) (X_n)_n \mathbb{E}[X_n] = 1/2 -\frac{6\varepsilon^2}{2\pi^2-15} ","['probability', 'probability-theory', 'martingales', 'upper-lower-bounds', 'polya-urn-model']"
29,Urn Ball Probability problem from Sheldon Ross' Probability Textbook,Urn Ball Probability problem from Sheldon Ross' Probability Textbook,,"Seven balls are randomly withdrawn from an urn that contains 12 red, 16 blue, and 18 green balls. Find the probability that (b) at least 2 red balls are withdrawn; I understand that one way to do the problem is to subtract the probability that 0 or 1 red ball is drawn from 1 to get the probability of at least 2 red balls being drawn. However, I don't understand why this method fails: Pick 2 red balls, then pick any 5 balls of the remaining 44. For the position of the red balls to not matter, take $\binom{7}{2}$ . The total number of possibilities is $\binom{46}{7}$ . So P(at least 2 red) = $\frac{\binom{12}{2} \binom{44}{5} \binom{7}{2}}{\binom{46}{7}}$ This is greater than 1, so it's definitely wrong.","Seven balls are randomly withdrawn from an urn that contains 12 red, 16 blue, and 18 green balls. Find the probability that (b) at least 2 red balls are withdrawn; I understand that one way to do the problem is to subtract the probability that 0 or 1 red ball is drawn from 1 to get the probability of at least 2 red balls being drawn. However, I don't understand why this method fails: Pick 2 red balls, then pick any 5 balls of the remaining 44. For the position of the red balls to not matter, take . The total number of possibilities is . So P(at least 2 red) = This is greater than 1, so it's definitely wrong.",\binom{7}{2} \binom{46}{7} \frac{\binom{12}{2} \binom{44}{5} \binom{7}{2}}{\binom{46}{7}},"['probability', 'combinations']"
30,How can we relate the mean of a function to the mean of some corresponding PDF?,How can we relate the mean of a function to the mean of some corresponding PDF?,,"Suppose $f:[a, b]\rightarrow\mathbb{R}$ is a real-valued function on a compact interval. For the sake of simplicity, let us also assume $f$ is continuously differentiable for now. The mean of $f$ is known to be \begin{align}\tag{1} \mu = \frac{1}{b-a}\int_{a}^{b} f(x)\, dx.  \end{align} What I am wondering is, how can we relate this to the mean of a PDF? The discrete analog of this question is easy enough. Given $\mu = (x_{1} + \cdots + x_{n})/n$ we can relate this to $\mu = \sum xp(x)$ by taking $p(x)$ to be the fraction of times $x$ appears in $x_{1}, \ldots, x_{n}$ . However, it doesn't seem as simple when we are dealing with continuous functions. Problem. To formulate my question more precisely, I'll state state my question in the form of a math problem. Given $f(x)$ can we find a probability density $p(y)$ such that if we choose $x\in [a, b]$ at uniform random (and apply $f$ ) then the probability density of obtaining $y$ is $p(y)$ ? In particular, given such a $p$ we should have \begin{align}\tag{2} \mu = \int_{-\infty}^{\infty} yp(y) \, dy.  \end{align} Example 1. Suppose $f:[a, b]\rightarrow\mathbb{R}$ is a constant function $f(x) = c$ . Then the corresponding probability density has to be $p(y) = \delta(y-c)$ where $\delta$ is the Dirac delta function. Example 2. If $f(x) = A + \frac{x-a}{b-a}(B-A)$ then the corresponding probability density has to be $$ p(y) = \begin{cases} \frac{1}{B-A} &\text{ if } y\in[A, B], \\ 0 &\text{ otherwise.} \end{cases}  $$ Approach 1. My first idea was to divide the codomain of $f$ into discrete intervals, writing $$ \mathbb{R} = \bigcup_{k} \,[\tfrac{k}{n}, \tfrac{k+1}{n}]. $$ Then define $$ p(y) = N \int_{a}^{b} I(\tfrac{\lfloor ny \rfloor}{n}\le f(x)\le \tfrac{\lfloor ny \rfloor + 1}{n}) \, dx $$ where $N$ is a normalization constant. Here $I(\cdots)$ is the indicator function that is $1$ if and only if the condition in the parentheses is satisfied, and $0$ otherwise. I imagine we obtain the desired PDF by sending $n\rightarrow\infty$ . Approach 2. Given the framing of my problem, $x$ has a uniform PDF $\lambda(x)$ on $[a, b]$ . It seems to be that $y= f(x)$ is a transformation of variables. Assuming $f$ is strictly increasing or strictly decreasing, the change of variables formula for PDFs gives us $$ p(y) = \lambda(f^{-1}(y)) \cdot |(f^{-1}(y))'| = \lambda(f^{-1}(y)) \frac{1}{|f'(f^{-1}(y))|}. $$ This makes sense because the steeper $f(x)$ is near output $y$ , the smaller probability density there is for getting $y$ . Unfortunately, this approach only seems to work when $f$ is strictly increasing or decreasing. I am wondering how we could incorporate the case where $f$ is constant like in the example above. My question is, is there a general way of approaching this that handles all examples? In particular, can we do this if we drop the condition that $f$ is injective (in Approach 2). What if we drop the condition that $f$ is continuously differentiable? Is this problem well-known or studied? It seems surprising I can't find anything immediately pertaining to this, because it seems like very a natural question to ask what is the relationship between $(1)$ and $(2)$ .","Suppose is a real-valued function on a compact interval. For the sake of simplicity, let us also assume is continuously differentiable for now. The mean of is known to be What I am wondering is, how can we relate this to the mean of a PDF? The discrete analog of this question is easy enough. Given we can relate this to by taking to be the fraction of times appears in . However, it doesn't seem as simple when we are dealing with continuous functions. Problem. To formulate my question more precisely, I'll state state my question in the form of a math problem. Given can we find a probability density such that if we choose at uniform random (and apply ) then the probability density of obtaining is ? In particular, given such a we should have Example 1. Suppose is a constant function . Then the corresponding probability density has to be where is the Dirac delta function. Example 2. If then the corresponding probability density has to be Approach 1. My first idea was to divide the codomain of into discrete intervals, writing Then define where is a normalization constant. Here is the indicator function that is if and only if the condition in the parentheses is satisfied, and otherwise. I imagine we obtain the desired PDF by sending . Approach 2. Given the framing of my problem, has a uniform PDF on . It seems to be that is a transformation of variables. Assuming is strictly increasing or strictly decreasing, the change of variables formula for PDFs gives us This makes sense because the steeper is near output , the smaller probability density there is for getting . Unfortunately, this approach only seems to work when is strictly increasing or decreasing. I am wondering how we could incorporate the case where is constant like in the example above. My question is, is there a general way of approaching this that handles all examples? In particular, can we do this if we drop the condition that is injective (in Approach 2). What if we drop the condition that is continuously differentiable? Is this problem well-known or studied? It seems surprising I can't find anything immediately pertaining to this, because it seems like very a natural question to ask what is the relationship between and .","f:[a, b]\rightarrow\mathbb{R} f f \begin{align}\tag{1}
\mu = \frac{1}{b-a}\int_{a}^{b} f(x)\, dx. 
\end{align} \mu = (x_{1} + \cdots + x_{n})/n \mu = \sum xp(x) p(x) x x_{1}, \ldots, x_{n} f(x) p(y) x\in [a, b] f y p(y) p \begin{align}\tag{2}
\mu = \int_{-\infty}^{\infty} yp(y) \, dy. 
\end{align} f:[a, b]\rightarrow\mathbb{R} f(x) = c p(y) = \delta(y-c) \delta f(x) = A + \frac{x-a}{b-a}(B-A) 
p(y) = \begin{cases}
\frac{1}{B-A} &\text{ if } y\in[A, B], \\
0 &\text{ otherwise.}
\end{cases} 
 f  \mathbb{R} = \bigcup_{k} \,[\tfrac{k}{n}, \tfrac{k+1}{n}].   p(y) = N \int_{a}^{b} I(\tfrac{\lfloor ny \rfloor}{n}\le f(x)\le \tfrac{\lfloor ny \rfloor + 1}{n}) \, dx  N I(\cdots) 1 0 n\rightarrow\infty x \lambda(x) [a, b] y= f(x) f  p(y) = \lambda(f^{-1}(y)) \cdot |(f^{-1}(y))'| = \lambda(f^{-1}(y)) \frac{1}{|f'(f^{-1}(y))|}.  f(x) y y f f f f (1) (2)","['real-analysis', 'probability', 'expected-value', 'density-function', 'average']"
31,"In the set {1, 2, 3, ..., 2019}, we pick a, b, and c randomly without any conditions. What is the probability for abc + bc + c to be divisible by 3?","In the set {1, 2, 3, ..., 2019}, we pick a, b, and c randomly without any conditions. What is the probability for abc + bc + c to be divisible by 3?",,"3 integers a, b, and c are randomly taken from the set {1, 2, 3, ..., 2019} without any conditions. What is the probability for abc + bc + c is divisible by 3? Correct me if I'm wrong please. abc + bc + c = c(ab + b + 1). We can conclude that c has to be a multiple of 3, so we have 1/3 probability for c. a and b are any integers from the set. AND, ab + b + 1 has to be  a multiple of 3 in the case that c is not a multiple of 3. ab + b + 1 = b(a + 1) + 1. b(a + 1) has to be in the form 3n - 1 for b(a + 1) + 1 to be a multiple of 3. And this is where I get stuck. New solutions, hints, or suggestions are welcome.","3 integers a, b, and c are randomly taken from the set {1, 2, 3, ..., 2019} without any conditions. What is the probability for abc + bc + c is divisible by 3? Correct me if I'm wrong please. abc + bc + c = c(ab + b + 1). We can conclude that c has to be a multiple of 3, so we have 1/3 probability for c. a and b are any integers from the set. AND, ab + b + 1 has to be  a multiple of 3 in the case that c is not a multiple of 3. ab + b + 1 = b(a + 1) + 1. b(a + 1) has to be in the form 3n - 1 for b(a + 1) + 1 to be a multiple of 3. And this is where I get stuck. New solutions, hints, or suggestions are welcome.",,"['probability', 'number-theory']"
32,Approximating the result of probability,Approximating the result of probability,,"So, here's a question asked in an interview: 10 dices are rolled simultaneously. What is the probability of getting the sum of numbers appearing on top of all the dice as 35? If we calculate manually, I think it's pretty tedious with no calculators allowed. So, I thought of approximating the answer. We know that rolling $10$ dice, has total number of ways as $6^{10}$ which is ~ $ 1e7$ which makes it ideal for using a normal distribution. So, mean of $10$ throws is $35$ and SD of 10 throws is ~ $ 5.4$ and so $Z = \dfrac{(X-35)}{5.4}$ and so we want $P(\leq35) - P(\leq34)$ as my answer, $P(\leq35) = 1/2$ and the other one can be obtained from the Normal graph and hence, we have the answer. But to my surprise, the interviewer didn't seem convinced! Is there something wrong with my method? Please point out. Thanks!","So, here's a question asked in an interview: 10 dices are rolled simultaneously. What is the probability of getting the sum of numbers appearing on top of all the dice as 35? If we calculate manually, I think it's pretty tedious with no calculators allowed. So, I thought of approximating the answer. We know that rolling dice, has total number of ways as which is ~ which makes it ideal for using a normal distribution. So, mean of throws is and SD of 10 throws is ~ and so and so we want as my answer, and the other one can be obtained from the Normal graph and hence, we have the answer. But to my surprise, the interviewer didn't seem convinced! Is there something wrong with my method? Please point out. Thanks!",10 6^{10}  1e7 10 35  5.4 Z = \dfrac{(X-35)}{5.4} P(\leq35) - P(\leq34) P(\leq35) = 1/2,['probability']
33,Bayes' Theorem in Conditional Probability,Bayes' Theorem in Conditional Probability,,"The scenario given by the problem is as follows: We are testing for a disease D that we think is present, D+, with probability 0.4, and absent, D-, with probability 0.6.  We believe that a test has sensitivity P{T+|D+}=0.75 and specificity P{T-|D-}=0.8. Q1: What is our probability that the disease is present if we perform the test and it is positive, T+, and our probability the disease is absent if that test is negative, T-? My ans: We can apply Bayes' formula to calculate P{D+|T+} and P{D-|T-}. P{D+|T+} = 5/7 P{D-|T-} = 24/29 Q2: Suppose we perform three tests, conditionally independent given D.  Given each possible number of positive test results, 0, 1, 2, or 3, what is our probability that the disease is present? My ans: Let k denote the number of positive test results. We know that P{ [exactly] k successes in n trials | p } = (nCk)x(p^k)x((1−p)^(n−k)), hence we can calculate P{k=0|D+} and P{k=0|D-}. We can then apply Bayes' formula to calculate P{D+|k=0}. P{D+|k=0} = 0.692 Using the same approach for k=1:3, we derive: P{D+|k=1} = 0.5 P{D+|k=2} = 0.308 P{D+|k=3} = 0.165 Would really appreciate it if someone can verify whether my reasoning and answers are correct. Thank you for your help in advance.","The scenario given by the problem is as follows: We are testing for a disease D that we think is present, D+, with probability 0.4, and absent, D-, with probability 0.6.  We believe that a test has sensitivity P{T+|D+}=0.75 and specificity P{T-|D-}=0.8. Q1: What is our probability that the disease is present if we perform the test and it is positive, T+, and our probability the disease is absent if that test is negative, T-? My ans: We can apply Bayes' formula to calculate P{D+|T+} and P{D-|T-}. P{D+|T+} = 5/7 P{D-|T-} = 24/29 Q2: Suppose we perform three tests, conditionally independent given D.  Given each possible number of positive test results, 0, 1, 2, or 3, what is our probability that the disease is present? My ans: Let k denote the number of positive test results. We know that P{ [exactly] k successes in n trials | p } = (nCk)x(p^k)x((1−p)^(n−k)), hence we can calculate P{k=0|D+} and P{k=0|D-}. We can then apply Bayes' formula to calculate P{D+|k=0}. P{D+|k=0} = 0.692 Using the same approach for k=1:3, we derive: P{D+|k=1} = 0.5 P{D+|k=2} = 0.308 P{D+|k=3} = 0.165 Would really appreciate it if someone can verify whether my reasoning and answers are correct. Thank you for your help in advance.",,"['probability', 'conditional-probability', 'bayes-theorem']"
34,"Intuitively, why does it make sense to go second in dice game to maximize chance of winning?","Intuitively, why does it make sense to go second in dice game to maximize chance of winning?",,"Here's a question from a probability book I am working through: Let's add more fun to the triplet game. Instead of fixed triplets for the two players, the new game allows both to choose their own triplets. Player $1$ chooses a triplet first and announces it; then player $2$ chooses a different triplet. The players toss the coins until one of the two triplet sequences appears. The player whose chosen triplet appears first wins the game. If both player $1$ and player $2$ are perfectly rational and both want to maximize their probability of winning, would you go first (as player $1$ )? If you go second, what is your probability of winning? There's $8$ possible triplets sequences for each player: HHH, HHT, HTH, HTT, THH, THT, TTH, TTT The players can't have the same triplet, hence there being $64 - 8 = 56$ probability outcomes to calculate for player $2$ winning. After spending half an hour tediously calculating all $56$ , it turns out that player $2$ can always choose a triplet, dependent on what player $1$ picked, as to win with probability at least ${2\over3}$ . However, I am wondering if there is an intuitive way to see that without tediously doing all $56$ computations. Or if seeing that player $2$ can always win with probability at least ${2\over3}$ is too much to ask for of an intuitive heuristic, how can we see that player $2$ can always win with probability at least ${1\over2}$ ? Edit: Since the problem statement is referring to earlier parts of the problem, I am reproducing those problem statements here as well: Part A. If you keep on tossing a fair coin, what is the expected number of tosses such hat you have $HHH$ (heads heads heads) in a row? What is the expected number of tosses to have $THH$ (tails heads heads) in a row? Part B. Keep flipping a fair coin until either $HHH$ or $THH$ occurs in the sequence. What is the probability that you get an $HHH$ subsequence before $THH$ ?","Here's a question from a probability book I am working through: Let's add more fun to the triplet game. Instead of fixed triplets for the two players, the new game allows both to choose their own triplets. Player chooses a triplet first and announces it; then player chooses a different triplet. The players toss the coins until one of the two triplet sequences appears. The player whose chosen triplet appears first wins the game. If both player and player are perfectly rational and both want to maximize their probability of winning, would you go first (as player )? If you go second, what is your probability of winning? There's possible triplets sequences for each player: HHH, HHT, HTH, HTT, THH, THT, TTH, TTT The players can't have the same triplet, hence there being probability outcomes to calculate for player winning. After spending half an hour tediously calculating all , it turns out that player can always choose a triplet, dependent on what player picked, as to win with probability at least . However, I am wondering if there is an intuitive way to see that without tediously doing all computations. Or if seeing that player can always win with probability at least is too much to ask for of an intuitive heuristic, how can we see that player can always win with probability at least ? Edit: Since the problem statement is referring to earlier parts of the problem, I am reproducing those problem statements here as well: Part A. If you keep on tossing a fair coin, what is the expected number of tosses such hat you have (heads heads heads) in a row? What is the expected number of tosses to have (tails heads heads) in a row? Part B. Keep flipping a fair coin until either or occurs in the sequence. What is the probability that you get an subsequence before ?",1 2 1 2 1 8 64 - 8 = 56 2 56 2 1 {2\over3} 56 2 {2\over3} 2 {1\over2} HHH THH HHH THH HHH THH,"['probability', 'combinatorics', 'markov-chains', 'dice', 'gambling']"
35,Multiclass Classification: Why do we exponentiate the softmax function?,Multiclass Classification: Why do we exponentiate the softmax function?,,"In the context of neural networks, we use the softmax output in multiclassification models. Firstly, let $P(y) = \sigma (z(2y-1))$ , which comes from the definition of sigmoid units. We define $\bf z=\bf W^\intercal \bf h+\bf b$ , a linear layer predicting unnormalized log probabilities with $z_i = -\log P(y=i|x)$ . The softmax of $z_i$ would result in $$\text{softmax}(\textbf{z})_i = \frac{\exp(z_i)}{\sum_j\exp(z_j)}=\frac{e^{\log P(y=i|x)}}{\sum_j e^{\log P(y=j|x)}}$$ I understand the general idea behind the softmax output unit. For example, in a feedforward neural network, our data $\mathbb{X}$ would be linearly transformed in the first layer computing $z=\bf w^\intercal h+b$ , to then pass to the output softmax layer. This output layer would have $k$ units, one for each class, and would compute the log probability $z_i$ of each of them to evaluate in the softmax function. I know $a)$ $\forall z_i \space |\space \exp^{z_i} \in [1, e]$ . In other words, the numerator of the softmax function will be within $1$ and $e$ , and the denominator will be a sum of terms all between $1$ and $e$ . Naturally, the probability of each $z_i$ will be normalized (they will add up to one). If $z_i > z_j, \text{softmax}(z_i) > \text{softmax}(z_j)$ . Therefore, if class $i$ has a greater dichotomized probability ( $i$ versus all the rest of the clases) than class $j$ , the softmax will preserve this relationship. What I don't understand is why do we need to exponentiate at all. Both of the previous conditions (normalization, preserved order) would still hold if the softmax function was only of the form $\frac{(z_i)}{\sum_j z_j}$ . Now, my intuition tells me it has something to do with the fact that the cost function of the softmax is, as usual, a negative log probability. Probably the exponential makes calculations in the cost function easier? Thanks in advance.","In the context of neural networks, we use the softmax output in multiclassification models. Firstly, let , which comes from the definition of sigmoid units. We define , a linear layer predicting unnormalized log probabilities with . The softmax of would result in I understand the general idea behind the softmax output unit. For example, in a feedforward neural network, our data would be linearly transformed in the first layer computing , to then pass to the output softmax layer. This output layer would have units, one for each class, and would compute the log probability of each of them to evaluate in the softmax function. I know . In other words, the numerator of the softmax function will be within and , and the denominator will be a sum of terms all between and . Naturally, the probability of each will be normalized (they will add up to one). If . Therefore, if class has a greater dichotomized probability ( versus all the rest of the clases) than class , the softmax will preserve this relationship. What I don't understand is why do we need to exponentiate at all. Both of the previous conditions (normalization, preserved order) would still hold if the softmax function was only of the form . Now, my intuition tells me it has something to do with the fact that the cost function of the softmax is, as usual, a negative log probability. Probably the exponential makes calculations in the cost function easier? Thanks in advance.","P(y) = \sigma (z(2y-1)) \bf z=\bf W^\intercal \bf h+\bf b z_i = -\log P(y=i|x) z_i \text{softmax}(\textbf{z})_i = \frac{\exp(z_i)}{\sum_j\exp(z_j)}=\frac{e^{\log P(y=i|x)}}{\sum_j e^{\log P(y=j|x)}} \mathbb{X} z=\bf w^\intercal h+b k z_i a) \forall z_i \space |\space \exp^{z_i} \in [1, e] 1 e 1 e z_i z_i > z_j, \text{softmax}(z_i) > \text{softmax}(z_j) i i j \frac{(z_i)}{\sum_j z_j}","['probability', 'exponential-function', 'exponentiation', 'machine-learning', 'neural-networks']"
36,"Birth processes, X-Bacterias in a petri dish abide to the following rules...","Birth processes, X-Bacterias in a petri dish abide to the following rules...",,"Question X-Bacterias in a petri dish abide to the following rules: each bacteria evolves identically and independently from the others. each bacteria is replaced by four new bacterias after a random time with $e(\beta)$ -distribution, where $\beta = 1$ hours $^{−1}$ . Denote $X_t$ by the number of bacterias at time t and assume that $X_0 = n$ , where $n \ge 1$ . a) Show that $\mathbb E[X_t \mathbb{1}_{T_1\le t}]=e^{-\beta t}\int_{0}^{t}4\beta e^{\beta s}\mathbb E[X_s]ds$ b) Deduce that $\mathbb E[X_t]=e^{-\beta t}\int_{0}^{t}4\beta e^{\beta s}\mathbb E[X_s]ds +e^{-\beta t}$ c) Show that $\mathbb E[X_t]=e^{3\beta t}$ My attempt's a) I am unsure how to deal with the indicator. First instinct is to say $\mathbb E[X_t\mathbb{1}_{T_1\le t}]=\mathbb E[X_t |T_1\le t]$ , which I believe is incorrect, even still, then using conditional expectation on this is tricky. b) Feel like this requires part a) so haven't attempted this as of yet. c) As for this, assuming I have proved b), Let $\mu(t):=E[X_t]=e^{-\beta t}\int_{0}^{t}4\beta e^{\beta s}\mathbb E[X_s]ds +e^{-\beta t}$ Now computing the following, using Leibniz's integral rule: $\mu'(t)=\frac{d}{dt}\{\int_{0}^{t}4\beta e^{\beta (s-t)}\mu(s)ds+e^{-\beta t}\}$ , we get... $\mu'(t)=\frac{d}{dt}(t)\cdot4[\beta e^{\beta (s-t)}\mu(s)]_{s=t}-0+\int_{0}^{t}\partial_t\{4\beta e^{\beta (s-t)}\mu(s)\}ds-\beta e^{\beta s}=4\beta\mu(t)-\beta\int_{0}^{t}4\beta e^{\beta (s-t)}\mu(s)ds-\beta e^{\beta s}=4\beta\mu(t)-\beta[\int_{0}^{t}4\beta e^{\beta (s-t)}\mu(s)ds+e^{-\beta t}]=4\beta\mu(t)-\beta\mu(t)=3\beta\mu(t)$ Hence, we have the following differential equation: $\mu'(t)=3\beta\mu(t)$ $\therefore \mu(t)=\mathbb E[X_t]=e^{3\beta t}$ Comments Any hints with a) would be greatly appreciated, I feel like I am missing some crucial steps and haven't made much progress over the past few hours. Moreover, some alternative solutions would be interesting to see also:)","Question X-Bacterias in a petri dish abide to the following rules: each bacteria evolves identically and independently from the others. each bacteria is replaced by four new bacterias after a random time with -distribution, where hours . Denote by the number of bacterias at time t and assume that , where . a) Show that b) Deduce that c) Show that My attempt's a) I am unsure how to deal with the indicator. First instinct is to say , which I believe is incorrect, even still, then using conditional expectation on this is tricky. b) Feel like this requires part a) so haven't attempted this as of yet. c) As for this, assuming I have proved b), Let Now computing the following, using Leibniz's integral rule: , we get... Hence, we have the following differential equation: Comments Any hints with a) would be greatly appreciated, I feel like I am missing some crucial steps and haven't made much progress over the past few hours. Moreover, some alternative solutions would be interesting to see also:)",e(\beta) \beta = 1 ^{−1} X_t X_0 = n n \ge 1 \mathbb E[X_t \mathbb{1}_{T_1\le t}]=e^{-\beta t}\int_{0}^{t}4\beta e^{\beta s}\mathbb E[X_s]ds \mathbb E[X_t]=e^{-\beta t}\int_{0}^{t}4\beta e^{\beta s}\mathbb E[X_s]ds +e^{-\beta t} \mathbb E[X_t]=e^{3\beta t} \mathbb E[X_t\mathbb{1}_{T_1\le t}]=\mathbb E[X_t |T_1\le t] \mu(t):=E[X_t]=e^{-\beta t}\int_{0}^{t}4\beta e^{\beta s}\mathbb E[X_s]ds +e^{-\beta t} \mu'(t)=\frac{d}{dt}\{\int_{0}^{t}4\beta e^{\beta (s-t)}\mu(s)ds+e^{-\beta t}\} \mu'(t)=\frac{d}{dt}(t)\cdot4[\beta e^{\beta (s-t)}\mu(s)]_{s=t}-0+\int_{0}^{t}\partial_t\{4\beta e^{\beta (s-t)}\mu(s)\}ds-\beta e^{\beta s}=4\beta\mu(t)-\beta\int_{0}^{t}4\beta e^{\beta (s-t)}\mu(s)ds-\beta e^{\beta s}=4\beta\mu(t)-\beta[\int_{0}^{t}4\beta e^{\beta (s-t)}\mu(s)ds+e^{-\beta t}]=4\beta\mu(t)-\beta\mu(t)=3\beta\mu(t) \mu'(t)=3\beta\mu(t) \therefore \mu(t)=\mathbb E[X_t]=e^{3\beta t},"['probability', 'ordinary-differential-equations', 'solution-verification', 'expected-value', 'birth-death-process']"
37,"Could someone explain why $\sum_{\substack{a_1,\ldots,a_n\in\mathbb{N}_0\\a_1+\cdots+a_n=n}}\frac{n!}{a_1!\cdots a_n!}=n^n$?",Could someone explain why ?,"\sum_{\substack{a_1,\ldots,a_n\in\mathbb{N}_0\\a_1+\cdots+a_n=n}}\frac{n!}{a_1!\cdots a_n!}=n^n","I want to use this equality but I have no idea why it holds. Sure I can probably prove it via induction but it looks rather fiddly. (Let $n$ be a positive integer.) $$\sum_{\substack{a_1,\ldots,a_n\in\mathbb{N}_0\\a_1+\cdots+a_n=n}}\frac{n!}{a_1!\cdots a_n!}=n^n$$ Is there a simpler way/intuition to explain this equality? It looks like something from combinatorics/probability but I cannot exactly recall what. Thank you so much in advance! Edit: This arise from a homework problem where I am asked to look at the probability of arranging $n$ objects where there are indistinguishable items, $a_1$ number of first item etc and hence the expression in the sum. I wanted to sum up every possibility and thus I was curious why it would sum up to $n^n$ . (It sums up to $n^n$ , which was given in the original question but I wanted to know why.)","I want to use this equality but I have no idea why it holds. Sure I can probably prove it via induction but it looks rather fiddly. (Let be a positive integer.) Is there a simpler way/intuition to explain this equality? It looks like something from combinatorics/probability but I cannot exactly recall what. Thank you so much in advance! Edit: This arise from a homework problem where I am asked to look at the probability of arranging objects where there are indistinguishable items, number of first item etc and hence the expression in the sum. I wanted to sum up every possibility and thus I was curious why it would sum up to . (It sums up to , which was given in the original question but I wanted to know why.)","n \sum_{\substack{a_1,\ldots,a_n\in\mathbb{N}_0\\a_1+\cdots+a_n=n}}\frac{n!}{a_1!\cdots a_n!}=n^n n a_1 n^n n^n","['probability', 'combinatorics', 'tetration', 'power-towers']"
38,Doubt about Probability Question,Doubt about Probability Question,,"There is a box containing $20$ green marbles, $20$ blue marbles, and $20$ purple marbles. You draw $10$ marbles at random without replacement. What is the probability that you do not get all the colors? The solution in the book: $\Large 3\frac{\binom{20}{10} \binom{40}{0}}{\binom{60}{10}} + 3\frac{\binom{40}{10} \binom{20}{0}}{\binom{60}{10}} $ I believe the book seperated into cases. Case 1: All the marbles are exactly $1$ color. Case 2: All the marbles are exactly $2$ colors. I feel like the solution is wrong because there is overcounting in the second case. If we lump together $2$ colors , such as green and blue marbles, that gives us $40$ marbles and choose $10$ . However this also includes cases such as all green, since we could draw all $10$ green.","There is a box containing green marbles, blue marbles, and purple marbles. You draw marbles at random without replacement. What is the probability that you do not get all the colors? The solution in the book: I believe the book seperated into cases. Case 1: All the marbles are exactly color. Case 2: All the marbles are exactly colors. I feel like the solution is wrong because there is overcounting in the second case. If we lump together colors , such as green and blue marbles, that gives us marbles and choose . However this also includes cases such as all green, since we could draw all green.",20 20 20 10 \Large 3\frac{\binom{20}{10} \binom{40}{0}}{\binom{60}{10}} + 3\frac{\binom{40}{10} \binom{20}{0}}{\binom{60}{10}}  1 2 2 40 10 10,['probability']
39,A fair dice is to be rolled $n$ times. Find the probability of not getting three consecutive sixes.,A fair dice is to be rolled  times. Find the probability of not getting three consecutive sixes.,n,"A fair dice is to be rolled $n$ times. Find the probability of not getting three consecutive sixes. (Here $12664665$ or $12346522$ is a valid result while $12666555$ or $66664256$ isn't.) The problem is inspired from this problem . I think the problem can be solved by case working. But I am not interested in that kind of solution. Rather I am interested in a solution that uses recurrence relations like this solution of the original problem. I've thought of a way to solve the problem which is not complete: The main concern of solving the problem is to find the number of ways to arrange the numbers $1$ to $6$ such that no three sixes are consecutive. Now, we change all the digits which are not $6$ into $0$ . For example, if we get $1266564$ , we will change this as $0066060$ . Let $S_n$ be the number of such valid results that contain $0$ and $6$ only.   ​ Now, if the first rolled dice gets a $0$ then there are $n-1$ rolls still left. But any of the results will be similar to one of the configurations of $S_{n-1}$ . If the first rolled dice gets a $6$ and the second rolled dice gets a $0$ , then using the same logic above we get that there $S_{n-2}$ ways of getting a valid result. If the first rolled dice gets a $6$ and the second rolled dice gets a $6$ , then the third rolled dice will get a $0$ for the result to be valid. So, there will be $S_{n-3}$ ways of getting the result. Hence, we get a recurrence relation that is: $S_n=S_{n-1}+S_{n-2}+S_{n-3}$ . Now, my idea was to change all $0$ s into $1,2,3,4$ or $5$ . But I think that's not possible or that will be too complicated as there will be too many cases. So, I need a solution to the problem that uses recurrence relations.","A fair dice is to be rolled times. Find the probability of not getting three consecutive sixes. (Here or is a valid result while or isn't.) The problem is inspired from this problem . I think the problem can be solved by case working. But I am not interested in that kind of solution. Rather I am interested in a solution that uses recurrence relations like this solution of the original problem. I've thought of a way to solve the problem which is not complete: The main concern of solving the problem is to find the number of ways to arrange the numbers to such that no three sixes are consecutive. Now, we change all the digits which are not into . For example, if we get , we will change this as . Let be the number of such valid results that contain and only.   ​ Now, if the first rolled dice gets a then there are rolls still left. But any of the results will be similar to one of the configurations of . If the first rolled dice gets a and the second rolled dice gets a , then using the same logic above we get that there ways of getting a valid result. If the first rolled dice gets a and the second rolled dice gets a , then the third rolled dice will get a for the result to be valid. So, there will be ways of getting the result. Hence, we get a recurrence relation that is: . Now, my idea was to change all s into or . But I think that's not possible or that will be too complicated as there will be too many cases. So, I need a solution to the problem that uses recurrence relations.","n 12664665 12346522 12666555 66664256 1 6 6 0 1266564 0066060 S_n 0 6 0 n-1 S_{n-1} 6 0 S_{n-2} 6 6 0 S_{n-3} S_n=S_{n-1}+S_{n-2}+S_{n-3} 0 1,2,3,4 5","['probability', 'combinatorics', 'recurrence-relations', 'contest-math']"
40,How to compute $\sum_{k=0}^\infty {2k \choose k} p^k (1-p)^k$,How to compute,\sum_{k=0}^\infty {2k \choose k} p^k (1-p)^k,Trying to compute $$\sum_{k=0}^\infty {2k \choose k} p^k (1-p)^k$$ for $0 < p < 1$ . All I have been able to do so far is using the ratio test and Stirling's approximation to show that this sum is infinite iff $p=0.5$ .,Trying to compute for . All I have been able to do so far is using the ratio test and Stirling's approximation to show that this sum is infinite iff .,\sum_{k=0}^\infty {2k \choose k} p^k (1-p)^k 0 < p < 1 p=0.5,"['probability', 'binomial-coefficients', 'random-walk']"
41,Use Stirling's approximation to evaluate the probability $\lim_{n\to \infty}\binom{2n}{n}\left(\frac{1}{4}\right)^n$,Use Stirling's approximation to evaluate the probability,\lim_{n\to \infty}\binom{2n}{n}\left(\frac{1}{4}\right)^n,"As part of a some probability problem (probability of gettin $n$ heads and $n$ tails in $2n$ trials with a fair coin) I have derived the formula: $$p_n=\binom{2n}{n}\left(\frac{1}{4}\right)^n$$ I want to evaluate: $$\lim_{n\to \infty} p_n$$ for $n\in \mathbb N$ , using the following bound: $$e^{\frac{1}{12n+1}}<\frac{n!}{\sqrt{2\pi n}\left(\frac{n}{e}\right)^n}<e^{\frac{1}{12n}}$$ This is a ""special"" case of Stirling's approximation from Herbert Robbins that can be found here . I am stuck because I am not sure if my calculation is correct and the result makes no sense to me. When I calculate the limit I get zero . Does this not contradict the law of large numbers? Wouldn't I expect to get a distribution of $50 \%$ heads and $50\%$ tails if I toss a fair coin an infinite amount of times which then should imply $\lim_{n \to \infty} p_n=1$ ? What I have tried so far: $$\begin{equation*}\begin{split}\lim_{n\to \infty} p_n&=\lim_{n\to \infty} \binom{2n}{n} \left(\frac{1}{4}\right)^n \\[10pt] &=\lim_{n \to \infty} \frac{(2n)!}{(n!)^24^n} \end{split}\end{equation*}$$ Rewriting the approximation: $$ \begin{equation*}\begin{split} &\phantom{\iff} \, \, \, \,e^{\frac{1}{12n+1}}<\frac{n!}{\sqrt{2\pi n}\left(\frac{n}{e}\right)^n}<e^{\frac{1}{12n}} \\[10pt] & \iff e^{\frac{1}{12n+1}}  \sqrt{2\pi n}\left(\frac{n}{e}\right)^n < n!<e^{\frac{1}{12n}} \sqrt{2\pi n}\left(\frac{n}{e}\right)^n\end{split}\end{equation*}$$ Replacing $n!$ in $p_n$ $$\begin{equation*}\begin{split} &\phantom{iff}\frac{(2n)!}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}<\frac{(2n)!}{(n!)^2 4^n}<\frac{(2n)!}{\left(e^{\frac{1}{12n}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n} \\[10pt] &\iff\underbrace{\frac{1}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}}_{:=g(n)}<\underbrace{\frac{1}{(n!)^2 4^n}}_{:=f(n)}<\underbrace{\frac{1}{\left(e^{\frac{1}{12n}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}}_{:=h(n)}\end{split}\end{equation*}$$ From the squeeze theorem : If $\lim_{n\to \infty} g(n)=\lim_{n \to \infty} h(n)=L$ and $g(n) < f(n) < h(n)$ then $\lim_{n \to \infty} f(n)=L$ $$\begin{equation*}\begin{split}\lim_{n \to \infty} g(n) &= \lim_{n \to \infty} \frac{1}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n} \\[10pt] &=\frac{1}{2 \pi}\lim_{n \to \infty} \frac{1}{e^{\frac{2}{12n+1}} e^{(-2n)} n^{(2n+1)}4^n} \\[10pt] &= \frac{1}{2\pi} \lim_{n \to \infty }\frac{e^{-\frac{24n}{12n+1}}}{n^{2n+1}4^n}=0\end{split}\end{equation*}$$ Analogous $\lim_{n \to \infty} h(n)=0 \implies \lim_{n \to \infty } f(n)=0$ . Therefore, $$\lim_{n \to \infty}p_n=0$$","As part of a some probability problem (probability of gettin heads and tails in trials with a fair coin) I have derived the formula: I want to evaluate: for , using the following bound: This is a ""special"" case of Stirling's approximation from Herbert Robbins that can be found here . I am stuck because I am not sure if my calculation is correct and the result makes no sense to me. When I calculate the limit I get zero . Does this not contradict the law of large numbers? Wouldn't I expect to get a distribution of heads and tails if I toss a fair coin an infinite amount of times which then should imply ? What I have tried so far: Rewriting the approximation: Replacing in From the squeeze theorem : If and then Analogous . Therefore,","n n 2n p_n=\binom{2n}{n}\left(\frac{1}{4}\right)^n \lim_{n\to \infty} p_n n\in \mathbb N e^{\frac{1}{12n+1}}<\frac{n!}{\sqrt{2\pi n}\left(\frac{n}{e}\right)^n}<e^{\frac{1}{12n}} 50 \% 50\% \lim_{n \to \infty} p_n=1 \begin{equation*}\begin{split}\lim_{n\to \infty} p_n&=\lim_{n\to \infty} \binom{2n}{n} \left(\frac{1}{4}\right)^n \\[10pt] &=\lim_{n \to \infty} \frac{(2n)!}{(n!)^24^n} \end{split}\end{equation*}  \begin{equation*}\begin{split} &\phantom{\iff} \, \, \, \,e^{\frac{1}{12n+1}}<\frac{n!}{\sqrt{2\pi n}\left(\frac{n}{e}\right)^n}<e^{\frac{1}{12n}} \\[10pt] & \iff e^{\frac{1}{12n+1}}  \sqrt{2\pi n}\left(\frac{n}{e}\right)^n < n!<e^{\frac{1}{12n}} \sqrt{2\pi n}\left(\frac{n}{e}\right)^n\end{split}\end{equation*} n! p_n \begin{equation*}\begin{split} &\phantom{iff}\frac{(2n)!}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}<\frac{(2n)!}{(n!)^2 4^n}<\frac{(2n)!}{\left(e^{\frac{1}{12n}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n} \\[10pt] &\iff\underbrace{\frac{1}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}}_{:=g(n)}<\underbrace{\frac{1}{(n!)^2 4^n}}_{:=f(n)}<\underbrace{\frac{1}{\left(e^{\frac{1}{12n}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n}}_{:=h(n)}\end{split}\end{equation*} \lim_{n\to \infty} g(n)=\lim_{n \to \infty} h(n)=L g(n) < f(n) < h(n) \lim_{n \to \infty} f(n)=L \begin{equation*}\begin{split}\lim_{n \to \infty} g(n) &= \lim_{n \to \infty} \frac{1}{\left(e^{\frac{1}{12n+1}}\sqrt{2\pi n}\left(\frac{n}{e}\right)^n\right)^2 4^n} \\[10pt] &=\frac{1}{2 \pi}\lim_{n \to \infty} \frac{1}{e^{\frac{2}{12n+1}} e^{(-2n)} n^{(2n+1)}4^n} \\[10pt] &= \frac{1}{2\pi} \lim_{n \to \infty }\frac{e^{-\frac{24n}{12n+1}}}{n^{2n+1}4^n}=0\end{split}\end{equation*} \lim_{n \to \infty} h(n)=0 \implies \lim_{n \to \infty } f(n)=0 \lim_{n \to \infty}p_n=0","['probability', 'limits']"
42,Markov chain with exponentially decreasing transition probabilities,Markov chain with exponentially decreasing transition probabilities,,"I'm currently trying to figure out the steady-state vector of a particular infinite-state Markov chain. The chain has (countably) infinitely many states $S_0, S_1, \dots, S_i, \dots$ , such that for all $i$ : $$ \begin{align}  \mathbb{P}(S_i \to S_i) &= 0 \\  \mathbb{P}(S_i \to S_{i+1}) &= \frac{1}{2^i} \\  \mathbb{P}(S_i \to S_{i-1}) &= 1-\frac{1}{2^i}. \end{align} $$ So far, all I can tell that if $\mathbf{p}$ is the steady-state vector for this chain, then $\lim_{i\to\infty} \mathbf{p}_i = 0.$ I know that for a finite-state Markov chain, the rows of $P^\infty$ are equal to the steady-state vector — I'm assuming that this holds for a Markov chain with infinitely many states as well? For Markov chains with a small number of states (i.e. two or three), I can usually find $P^n$ by hand with diagonalization, but in this case I feel like there should be an easier way. How should I approach problems like this, and how would I find $\mathbf{p}$ in this case?","I'm currently trying to figure out the steady-state vector of a particular infinite-state Markov chain. The chain has (countably) infinitely many states , such that for all : So far, all I can tell that if is the steady-state vector for this chain, then I know that for a finite-state Markov chain, the rows of are equal to the steady-state vector — I'm assuming that this holds for a Markov chain with infinitely many states as well? For Markov chains with a small number of states (i.e. two or three), I can usually find by hand with diagonalization, but in this case I feel like there should be an easier way. How should I approach problems like this, and how would I find in this case?","S_0, S_1, \dots, S_i, \dots i 
\begin{align}
 \mathbb{P}(S_i \to S_i) &= 0 \\
 \mathbb{P}(S_i \to S_{i+1}) &= \frac{1}{2^i} \\
 \mathbb{P}(S_i \to S_{i-1}) &= 1-\frac{1}{2^i}.
\end{align}
 \mathbf{p} \lim_{i\to\infty} \mathbf{p}_i = 0. P^\infty P^n \mathbf{p}","['probability', 'stochastic-processes', 'markov-chains']"
43,"What algorithms exist, if any, for pseudo-random dice rolling with non-binominal aggregate properties?","What algorithms exist, if any, for pseudo-random dice rolling with non-binominal aggregate properties?",,"I wasn't sure whether to address this to CS SE, StackOverflow or Math SE, but here goes... What algorithms exist, if any, for (pseudo-) random dice rolls such that some aggregate properties across many rolls are obeyed, for example, I want to get to roll a 3-sided die (faces 'A', 'B', 'C') such that, if rolled 100 times: the expected numbers of 'A', 'B', 'C' are 90, 8, 2 respectively; the number of 'A' rolls will be between 89 and 91 with probability 67% or some other similar such specification. I am still looking for algorithms that can provide a random(-looking) single roll; but over many rolls I do not want the cumulative results to follow a binomial distribution but rather one like I've specified. What should I look into for such pseudo-random rolling algorithms? (Pseudo-code, or actual code in say R or Python or Mathematica, would also be very appreciated) EDIT: I know how to satisfy property (1), it's (2) I'm interested in","I wasn't sure whether to address this to CS SE, StackOverflow or Math SE, but here goes... What algorithms exist, if any, for (pseudo-) random dice rolls such that some aggregate properties across many rolls are obeyed, for example, I want to get to roll a 3-sided die (faces 'A', 'B', 'C') such that, if rolled 100 times: the expected numbers of 'A', 'B', 'C' are 90, 8, 2 respectively; the number of 'A' rolls will be between 89 and 91 with probability 67% or some other similar such specification. I am still looking for algorithms that can provide a random(-looking) single roll; but over many rolls I do not want the cumulative results to follow a binomial distribution but rather one like I've specified. What should I look into for such pseudo-random rolling algorithms? (Pseudo-code, or actual code in say R or Python or Mathematica, would also be very appreciated) EDIT: I know how to satisfy property (1), it's (2) I'm interested in",,"['probability', 'algorithms', 'random']"
44,On leap years and conditional probability,On leap years and conditional probability,,"Edit (Copying this from the end of my post and pasting it at the start because people are still voting to close this.) Before anyone flags this as a duplicate, I understand that the following exact problem has been posted before, but my post is about why my logic (for the second question below) is wrong (and not about what the correct answer should be). Problem A year in the 2020s (i.e. from 2020 to 2029 inclusive) is selected uniformly at random, a month is selected uniformly at random from that year and a day is selected uniformly at random from that month. What is the probability that the day is the 29th of February? Given that the day is the 29th, what is the probability that the month is February? My idea for Question 1 The first question is very clear-cut. First, we observe that only leap years have a ""29th of February"" and out of the entire decade, only 3 are leap years (i.e. 2020, 2024 and 2028), so we have a $\frac 3 {10}$ chance of picking a leap year. By the same logic, we have a $\frac 1 {12}$ chance of picking February out of the leap year we have chosen and we have a further $\frac 1 {29}$ chance of picking the 29th of February from the February of the leap year we have chosen. Thus, $\mathbb{P}(\mathrm{29th\ of\ February}) = (\frac 3 {10})(\frac 1 {12})(\frac 1 {29}) = \frac 1 {1160}$ . Okay. Easy. My idea for Question 2 Now, I understand that the second question is on conditional probability and Bayes' Theorem should be invoked. However, smart me thought I saw a short-cut (obviously incorrectly) and I have been wondering why my logic (as explained below) is wrong. Since we are ""given that the day is the 29th"", I thought that we need only pick a year and a month. In other words, once we have a year and a month set, the probability that the day is the 29th should be $1$ right? Thus, $\mathbb{P}(\mathrm{February\ |\ 29th}) = (\frac 3 {10})(\frac 1 {12}) = \frac 1 {40}$ . Again. Easy. Or so I thought. Suggested solution for Question 2 From the solution given (as explained below), it seems I have oversimplified Question 2. According to my professor, we need to break the question down much more than I had. First, we must observe that, out of the entire decade (i.e. 120 months), we have 3 months with 29 days, 40 months with 30 days (since 4 months in a year have 30 days) and 70 months with 31 days (since 7 months in a year have 31 days). We do not count the ""normal Februarys (i.e. the Februarys with 28 days)"" as it is obvious that we cannot possibly have a 29th day from those months. Thus, $\mathbb{P}(\mathrm{February\ |\ 29th}) = \frac {(\frac 3 {120})(\frac 1 {29})} {(\frac 3 {120})(\frac 1 {29}) + (\frac {40} {120})(\frac 1 {30}) + (\frac {70} {120})(\frac 1 {31})} = \frac {279} {9965}$ . While I perfectly understand my professor's logic for the second question, I cannot help but wonder why my idea is flawed. Any intuitive explanations will be greatly appreciated!","Edit (Copying this from the end of my post and pasting it at the start because people are still voting to close this.) Before anyone flags this as a duplicate, I understand that the following exact problem has been posted before, but my post is about why my logic (for the second question below) is wrong (and not about what the correct answer should be). Problem A year in the 2020s (i.e. from 2020 to 2029 inclusive) is selected uniformly at random, a month is selected uniformly at random from that year and a day is selected uniformly at random from that month. What is the probability that the day is the 29th of February? Given that the day is the 29th, what is the probability that the month is February? My idea for Question 1 The first question is very clear-cut. First, we observe that only leap years have a ""29th of February"" and out of the entire decade, only 3 are leap years (i.e. 2020, 2024 and 2028), so we have a chance of picking a leap year. By the same logic, we have a chance of picking February out of the leap year we have chosen and we have a further chance of picking the 29th of February from the February of the leap year we have chosen. Thus, . Okay. Easy. My idea for Question 2 Now, I understand that the second question is on conditional probability and Bayes' Theorem should be invoked. However, smart me thought I saw a short-cut (obviously incorrectly) and I have been wondering why my logic (as explained below) is wrong. Since we are ""given that the day is the 29th"", I thought that we need only pick a year and a month. In other words, once we have a year and a month set, the probability that the day is the 29th should be right? Thus, . Again. Easy. Or so I thought. Suggested solution for Question 2 From the solution given (as explained below), it seems I have oversimplified Question 2. According to my professor, we need to break the question down much more than I had. First, we must observe that, out of the entire decade (i.e. 120 months), we have 3 months with 29 days, 40 months with 30 days (since 4 months in a year have 30 days) and 70 months with 31 days (since 7 months in a year have 31 days). We do not count the ""normal Februarys (i.e. the Februarys with 28 days)"" as it is obvious that we cannot possibly have a 29th day from those months. Thus, . While I perfectly understand my professor's logic for the second question, I cannot help but wonder why my idea is flawed. Any intuitive explanations will be greatly appreciated!",\frac 3 {10} \frac 1 {12} \frac 1 {29} \mathbb{P}(\mathrm{29th\ of\ February}) = (\frac 3 {10})(\frac 1 {12})(\frac 1 {29}) = \frac 1 {1160} 1 \mathbb{P}(\mathrm{February\ |\ 29th}) = (\frac 3 {10})(\frac 1 {12}) = \frac 1 {40} \mathbb{P}(\mathrm{February\ |\ 29th}) = \frac {(\frac 3 {120})(\frac 1 {29})} {(\frac 3 {120})(\frac 1 {29}) + (\frac {40} {120})(\frac 1 {30}) + (\frac {70} {120})(\frac 1 {31})} = \frac {279} {9965},"['probability', 'combinatorics', 'statistics', 'conditional-probability', 'bayes-theorem']"
45,Binomial Distribution Word Problem,Binomial Distribution Word Problem,,"A student gets at least 8 hours of sleep 45% of the nights; the sleeping schedule is independent from night to night. Let Xi indicate whether the student gets at least 8 hours of sleep during the next 4 night respectively for i = 1, 2, 3, and 4. Let X = X1 + X2 + X3 + X4. Find the variance of X. I'm struggling to understand what kind of distribution this problem is follow. I think it would be binomial. In that case wouldn't the variance of having x successes in 4 nights (trials) be modelled by the binomial. Hence the variance of X is (npq)^0.5 ? However, I feel like the question wants me to do some RV algebra. But a bit stuck.","A student gets at least 8 hours of sleep 45% of the nights; the sleeping schedule is independent from night to night. Let Xi indicate whether the student gets at least 8 hours of sleep during the next 4 night respectively for i = 1, 2, 3, and 4. Let X = X1 + X2 + X3 + X4. Find the variance of X. I'm struggling to understand what kind of distribution this problem is follow. I think it would be binomial. In that case wouldn't the variance of having x successes in 4 nights (trials) be modelled by the binomial. Hence the variance of X is (npq)^0.5 ? However, I feel like the question wants me to do some RV algebra. But a bit stuck.",,"['probability', 'random-variables']"
46,Probability of stepping on n-th field in game where you move using dice,Probability of stepping on n-th field in game where you move using dice,,"We play a game where in each round we roll a six-sided dice and move the appropriate number of squares. How likely are we to step on the $n$ -th field during the game, if we started with the number $0$ ? The answer is sufficient in the form of a recurrent formula, which refers to a constant number of values for the lower one. Can you use only $2$ values for lower? I am kinda lost here. I did bit know how even approach this. Thanks to anyone who can help me guide to right direction I made this: | 1 | 1                                             |   | 2 | 1+1,2                                         |   | 3 | 1+1+1, 2+1, 3                                 |   | 4 | 1+1+1+1, 1+1+2, 1+3, 2+2, 4                   |   | 5 | 1+1+1+1+1, 1+1+1+2, 1+2+2, 1+1+3, 1+4, 2+3, 5 | But I can not see any pattern or how I can calculate probability from it. Does order of numbers matter ?","We play a game where in each round we roll a six-sided dice and move the appropriate number of squares. How likely are we to step on the -th field during the game, if we started with the number ? The answer is sufficient in the form of a recurrent formula, which refers to a constant number of values for the lower one. Can you use only values for lower? I am kinda lost here. I did bit know how even approach this. Thanks to anyone who can help me guide to right direction I made this: | 1 | 1                                             |   | 2 | 1+1,2                                         |   | 3 | 1+1+1, 2+1, 3                                 |   | 4 | 1+1+1+1, 1+1+2, 1+3, 2+2, 4                   |   | 5 | 1+1+1+1+1, 1+1+1+2, 1+2+2, 1+1+3, 1+4, 2+3, 5 | But I can not see any pattern or how I can calculate probability from it. Does order of numbers matter ?",n 0 2,['probability']
47,Confusion about simple probability,Confusion about simple probability,,"This Question stems from Ronald Fishers Tea problem in how to design experiments which I have reworded. Anyway, suppose you have 2 different items in front of you, 5 of each which we can just call red and blue. So you have 10 items total, and you want to randomly select the 5 red ones. The probability of getting this correct is $\frac{1}{10 \choose 5} $ but I can't shake the intuition that it would be $ \frac{5}{10} $ and I can't reason with myself as to why it wouldn't be. Can someone explain intuitively and not mathematically why it wouldn't be because I am able to conclude mathematically that it's not.","This Question stems from Ronald Fishers Tea problem in how to design experiments which I have reworded. Anyway, suppose you have 2 different items in front of you, 5 of each which we can just call red and blue. So you have 10 items total, and you want to randomly select the 5 red ones. The probability of getting this correct is but I can't shake the intuition that it would be and I can't reason with myself as to why it wouldn't be. Can someone explain intuitively and not mathematically why it wouldn't be because I am able to conclude mathematically that it's not.",\frac{1}{10 \choose 5}   \frac{5}{10} ,"['probability', 'combinatorics', 'intuition']"
48,What are the chances of rain on particular days,What are the chances of rain on particular days,,"I study maths as a hobby and am on to elementary theory of probability. I have come across this problem: Find the probability of events A, B and C given it rained on exactly 2 days last week. A: it rained Monday and Tuesday B: it rained on 2 consecutive days C: it rained neither Monday or Tuesday. My first thought was to work from the assumption that there was  a 2/7 chance of rain over the week and work out the probability for any particular day. But then I thought I should start by working out the total number of outcomes for 2 days rain in one week, which I take to  be $\binom {7}{2} = 21$ Now the answers given in the book are $\frac{1}{21}, \frac{2}{7}, \frac{10}{21}$ I can see that the probability of any particular 2 days having rain is $\frac{1}{21}$ so can see how the the first answer is correct, but even then I have doubts. As for the 2nd and 3rd answers, I cannot see where these come from.","I study maths as a hobby and am on to elementary theory of probability. I have come across this problem: Find the probability of events A, B and C given it rained on exactly 2 days last week. A: it rained Monday and Tuesday B: it rained on 2 consecutive days C: it rained neither Monday or Tuesday. My first thought was to work from the assumption that there was  a 2/7 chance of rain over the week and work out the probability for any particular day. But then I thought I should start by working out the total number of outcomes for 2 days rain in one week, which I take to  be Now the answers given in the book are I can see that the probability of any particular 2 days having rain is so can see how the the first answer is correct, but even then I have doubts. As for the 2nd and 3rd answers, I cannot see where these come from.","\binom {7}{2} = 21 \frac{1}{21}, \frac{2}{7}, \frac{10}{21} \frac{1}{21}",['probability']
49,"What is the probability of spelling out ""miss"" in ""mississippi""?","What is the probability of spelling out ""miss"" in ""mississippi""?",,"Suppose that the word ""mississippi"" is written on a piece of paper. If we cut this piece of paper into 11 smaller pieces of paper, each containing exactly one letter, and then place these letters in a bag, what is the probability that if we select four numbers at random with no replacement, the first letter will be ""m"", the second letter ""i"", the third letter ""s"", and the fourth letter is ""s"" (so that we form the word ""miss"")? At this point, I know that computing ${}_{11}P_4$ will give us the total number of ways we can form $4$ -letter words. Would I have to divide ${}_{11}P_4$ by $4!\cdot 4! \cdot 2!$ to get the total number of ways to uniquely spell out ""miss"". Then, I could find the probability by dividing $1$ by the total number of ways found?","Suppose that the word ""mississippi"" is written on a piece of paper. If we cut this piece of paper into 11 smaller pieces of paper, each containing exactly one letter, and then place these letters in a bag, what is the probability that if we select four numbers at random with no replacement, the first letter will be ""m"", the second letter ""i"", the third letter ""s"", and the fourth letter is ""s"" (so that we form the word ""miss"")? At this point, I know that computing will give us the total number of ways we can form -letter words. Would I have to divide by to get the total number of ways to uniquely spell out ""miss"". Then, I could find the probability by dividing by the total number of ways found?",{}_{11}P_4 4 {}_{11}P_4 4!\cdot 4! \cdot 2! 1,"['probability', 'combinatorics', 'permutations']"
50,Why does a cumulative distribution have the quality that $P(X<b)=\lim_{n\to\infty}\left[P\left(X\leqslant b-\frac1n\right)\right]$?,Why does a cumulative distribution have the quality that ?,P(X<b)=\lim_{n\to\infty}\left[P\left(X\leqslant b-\frac1n\right)\right],"I came across the following passage in Ross' ""First Course in Probability"": If we want to compute the probability that X is strictly less than b , we can apply the continuity property to obtain: $$P\bigl(X<b\bigr)=\lim_{n\to\infty}\left[P\left(X\leqslant b-\frac1n\right)\right].$$ The continuity Ross is referring to, is the right continuity of the cumulative function but the property he mentions seems to me to be a property of a left continuity since the sequence $b-\dfrac1n$ , where $n$ goes to infinity, is an increasing sequence that converges to $b$ from left to right. Will be grateful for any enlightening remarks on this.","I came across the following passage in Ross' ""First Course in Probability"": If we want to compute the probability that X is strictly less than b , we can apply the continuity property to obtain: The continuity Ross is referring to, is the right continuity of the cumulative function but the property he mentions seems to me to be a property of a left continuity since the sequence , where goes to infinity, is an increasing sequence that converges to from left to right. Will be grateful for any enlightening remarks on this.",P\bigl(X<b\bigr)=\lim_{n\to\infty}\left[P\left(X\leqslant b-\frac1n\right)\right]. b-\dfrac1n n b,"['probability', 'probability-theory', 'cumulative-distribution-functions']"
51,calculate $\mathbb{E}[X]$ . what is wrong in my attempt?,calculate  . what is wrong in my attempt?,\mathbb{E}[X],"friend A choose 3 cards from 10 cards packet, then he return the cards to the pack. friend B choose 3 cards from the same pack in an independent way from friend A. Let $X$ be the number of cards that didnt choose by any of the friends, calculate $\mathbb{E}[X]$ First I can see that $4\leq X \leq 7$ $${p(X=4)} ~=~ \frac{\binom{10}{3}\binom{7}{3}}{\binom{10}{3}\binom{10}{3}}.$$ $${p(X=5)} ~=~ \frac{\binom{10}{3}\binom{7}{2}\binom{3}{1}}{\binom{10}{3}\binom{10}{3}}.$$ $${p(X=6)} ~=~ \frac{\binom{10}{3}\binom{7}{1}\binom{3}{2}}{\binom{10}{3}\binom{10}{3}}.$$ $${p(X=7)} ~=~ \frac{\binom{10}{3}\binom{3}{3}}{\binom{10}{3}\binom{10}{3}}.$$ but I dont get the right answer when I calculate it according to $$ \mathbb{E}(X)=\sum_{t \in R_{X}} t \cdot \mathbb{P}(X=t) $$","friend A choose 3 cards from 10 cards packet, then he return the cards to the pack. friend B choose 3 cards from the same pack in an independent way from friend A. Let be the number of cards that didnt choose by any of the friends, calculate First I can see that but I dont get the right answer when I calculate it according to","X \mathbb{E}[X] 4\leq X \leq 7 {p(X=4)}
~=~ \frac{\binom{10}{3}\binom{7}{3}}{\binom{10}{3}\binom{10}{3}}. {p(X=5)}
~=~ \frac{\binom{10}{3}\binom{7}{2}\binom{3}{1}}{\binom{10}{3}\binom{10}{3}}. {p(X=6)}
~=~ \frac{\binom{10}{3}\binom{7}{1}\binom{3}{2}}{\binom{10}{3}\binom{10}{3}}. {p(X=7)}
~=~ \frac{\binom{10}{3}\binom{3}{3}}{\binom{10}{3}\binom{10}{3}}. 
\mathbb{E}(X)=\sum_{t \in R_{X}} t \cdot \mathbb{P}(X=t)
","['probability', 'expected-value']"
52,Struggling with intuition about this probability question. Symmetry argument of two balls drawn from an urn.,Struggling with intuition about this probability question. Symmetry argument of two balls drawn from an urn.,,"So the question is as follows: An urn contains m red balls and n blue balls. Two balls are drawn uniformly at random from the urn, without replacement. (a) What is the probability that the first ball drawn is red? (b) What is the probability that the second ball drawn is red?* The answer to a) quite clearly works out to be $\frac{m}{(m+n)}$ , but the answer to b turns out to be the same, and my tutor said this is intuitive by a symmetry argument. i.e. that $P(A_1)$ = $P(A_2)$ where $A_i$ is the event that a red ball is drawn on the ith turn. However I am struggling to see how this is evident, can anyone explain this?","So the question is as follows: An urn contains m red balls and n blue balls. Two balls are drawn uniformly at random from the urn, without replacement. (a) What is the probability that the first ball drawn is red? (b) What is the probability that the second ball drawn is red?* The answer to a) quite clearly works out to be , but the answer to b turns out to be the same, and my tutor said this is intuitive by a symmetry argument. i.e. that = where is the event that a red ball is drawn on the ith turn. However I am struggling to see how this is evident, can anyone explain this?",\frac{m}{(m+n)} P(A_1) P(A_2) A_i,['probability']
53,Probability problem from CMU contest prep course,Probability problem from CMU contest prep course,,"Your sports team is playing a best-of-15 series against a single opponent. Against this opponent, your team wins with probability 40%, unless it is behind in the series (with strictly fewer wins than losses so far in these 15-game finals), at which point your team wins with probability 60%. What is the probability that your team wins? I'm not great at math so I wrote a dynamic programming algorithm to solve it. If my algorithm is correct, the answer would be 40%. I found that if the number of matches is odd, the probability that you win is always 40%, for any number of matches. Can anyone verify this and provide a probabilistic explanation of the solution? Thanks!","Your sports team is playing a best-of-15 series against a single opponent. Against this opponent, your team wins with probability 40%, unless it is behind in the series (with strictly fewer wins than losses so far in these 15-game finals), at which point your team wins with probability 60%. What is the probability that your team wins? I'm not great at math so I wrote a dynamic programming algorithm to solve it. If my algorithm is correct, the answer would be 40%. I found that if the number of matches is odd, the probability that you win is always 40%, for any number of matches. Can anyone verify this and provide a probabilistic explanation of the solution? Thanks!",,"['probability', 'discrete-mathematics', 'contest-math', 'conditional-probability']"
54,Probability and the first uncountable ordinal number,Probability and the first uncountable ordinal number,,"Let's suppose we can put a probability measure on the set of countable ordinals. (which is the same as the first uncountable ordinal). Let's now play a game. I pick a countable ordinal, say $\alpha$ . Now you pick one. (Clearly our choices are independent). But $\alpha$ has countably many ordinals less than it and for you the number of choices greater than $\alpha$ are uncountable. So with a large probability, possibly one, your choice is bigger than mine. But the choices were independent!  How to explain? Of course, you could take this as a proof that no such measure exists but intuitively it seems to make sense that such a game could exist.","Let's suppose we can put a probability measure on the set of countable ordinals. (which is the same as the first uncountable ordinal). Let's now play a game. I pick a countable ordinal, say . Now you pick one. (Clearly our choices are independent). But has countably many ordinals less than it and for you the number of choices greater than are uncountable. So with a large probability, possibly one, your choice is bigger than mine. But the choices were independent!  How to explain? Of course, you could take this as a proof that no such measure exists but intuitively it seems to make sense that such a game could exist.",\alpha \alpha \alpha,"['probability', 'set-theory', 'paradoxes']"
55,Probability of breast cancer,Probability of breast cancer,,"I'm having trouble with a probability problem I've been trying to solve for a while. It's about the accuracy of breast cancer testing. Relevant probabilities are listed below, where: "" $\text{cancer}$ "" is the event ""has breast cancer"". "" $+$ "" is the event ""tests positive for breast cancer"". $P(\text{cancer}) = \frac{12}{1000}$ $P(+|\text{cancer}) = \frac{11}{12}$ $P(+) = \frac{31}{1000}$ $P(\text{cancer}|+) = 0.355$ This last line is a result from a previous problem. The next part involves updating the probability of having cancer, but I'm having trouble figuring out what the answer is. In the next part of the question, there's a woman who has tested positive and her doctor says she's part of a population for which there's a 40% chance of breast cancer. I need to find the probability that the woman has cancer. I am confused by this update to the cancer probability, but i will assume that this means $P(\text{cancer})$ has changed. I also assume this means I need to find a new value for $P(\text{cancer}|+)$ , but I'm not getting this right. $P(+ | \text{cancer}) = \frac{11}{12} = \frac{P(\text{cancer} | +)\cdot P(+)}{P(\text{cancer})} = \frac{P(\text{cancer} | +) \cdot \frac{31}{1000}}{0.40}$ $P(\text{cancer} | +) = \frac{11}{12} \cdot 0.40 \cdot \frac{1000}{31} = 11.828$ The result can't be correct because it's way over 1. How can i fix this? Thank you in advance for any insight.","I'm having trouble with a probability problem I've been trying to solve for a while. It's about the accuracy of breast cancer testing. Relevant probabilities are listed below, where: "" "" is the event ""has breast cancer"". "" "" is the event ""tests positive for breast cancer"". This last line is a result from a previous problem. The next part involves updating the probability of having cancer, but I'm having trouble figuring out what the answer is. In the next part of the question, there's a woman who has tested positive and her doctor says she's part of a population for which there's a 40% chance of breast cancer. I need to find the probability that the woman has cancer. I am confused by this update to the cancer probability, but i will assume that this means has changed. I also assume this means I need to find a new value for , but I'm not getting this right. The result can't be correct because it's way over 1. How can i fix this? Thank you in advance for any insight.",\text{cancer} + P(\text{cancer}) = \frac{12}{1000} P(+|\text{cancer}) = \frac{11}{12} P(+) = \frac{31}{1000} P(\text{cancer}|+) = 0.355 P(\text{cancer}) P(\text{cancer}|+) P(+ | \text{cancer}) = \frac{11}{12} = \frac{P(\text{cancer} | +)\cdot P(+)}{P(\text{cancer})} = \frac{P(\text{cancer} | +) \cdot \frac{31}{1000}}{0.40} P(\text{cancer} | +) = \frac{11}{12} \cdot 0.40 \cdot \frac{1000}{31} = 11.828,"['probability', 'conditional-probability', 'bayes-theorem']"
56,$n$-fold convolution of a CDF with itself,-fold convolution of a CDF with itself,n,"Problem: Suppose that $X_1,X_2,\dots$ are i.i.d. nonnegative integer-valued random variables with common CDF $F(x)$ . Assume that $F(0)<1$ and let $F^{(n)}$ denote th $n$ -fold convolution of $F$ . (This is the convolution of $n$ copies of $F$ .) Show that $\displaystyle\sum_{n=1}^\infty F^{(n)}(x)$ is finite for all $x\geq0.$ We want to find random variables $Y_i$ which depend on $x$ such that $E\lbrack Y_i\rbrack=F^{(n)}(x)$ and then show that the sum of $Y_i$ 's is also a random variable with finite expectation. The issue we are having is that we are not sure that our understanding of the $n$ -fold convolution of $F$ with itself is correct. We think that $$F^{(n)}(x)=\int_{0}^{x}\cdots\int_{0}^{x}F(x-x_1-\cdots-x_n)F(x_1)F(x_2)\cdots F(x_n)\,dx_1\cdots dx_n.$$ From this, we think that the $Y_i$ 's should be $$Y_i(x_1)=\int_{0}^{x}\cdots\int_{0}^{x}F(x-x_1-\cdots-x_n)F(x_1)F(x_2)\cdots F(x_n)\,dx_2\cdots dx_n.$$ Could anyone help us clearing the smoke out in this problem? Thank you for your time and feedback.","Problem: Suppose that are i.i.d. nonnegative integer-valued random variables with common CDF . Assume that and let denote th -fold convolution of . (This is the convolution of copies of .) Show that is finite for all We want to find random variables which depend on such that and then show that the sum of 's is also a random variable with finite expectation. The issue we are having is that we are not sure that our understanding of the -fold convolution of with itself is correct. We think that From this, we think that the 's should be Could anyone help us clearing the smoke out in this problem? Thank you for your time and feedback.","X_1,X_2,\dots F(x) F(0)<1 F^{(n)} n F n F \displaystyle\sum_{n=1}^\infty F^{(n)}(x) x\geq0. Y_i x E\lbrack Y_i\rbrack=F^{(n)}(x) Y_i n F F^{(n)}(x)=\int_{0}^{x}\cdots\int_{0}^{x}F(x-x_1-\cdots-x_n)F(x_1)F(x_2)\cdots F(x_n)\,dx_1\cdots dx_n. Y_i Y_i(x_1)=\int_{0}^{x}\cdots\int_{0}^{x}F(x-x_1-\cdots-x_n)F(x_1)F(x_2)\cdots F(x_n)\,dx_2\cdots dx_n.","['probability', 'probability-theory', 'probability-distributions', 'convolution']"
57,How do I determine sample size for a test?,How do I determine sample size for a test?,,"Say you have a die with $n$ number of sides.  Assume the die is weighted properly and each side has an equal chance of coming up. How do I determine the minimum number of rolls needed so that results show an equal distribution, within an expected margin of error? I assume there is a formula for this, but I am not a math person, so I don't know what to look for.  I have been searching online, but haven't found the right thing.","Say you have a die with number of sides.  Assume the die is weighted properly and each side has an equal chance of coming up. How do I determine the minimum number of rolls needed so that results show an equal distribution, within an expected margin of error? I assume there is a formula for this, but I am not a math person, so I don't know what to look for.  I have been searching online, but haven't found the right thing.",n,"['probability', 'statistics']"
58,Show that $P(A\mid B) > P(A\mid B^{c}) \implies P(B\mid A) > P(B\mid A^{c})$,Show that,P(A\mid B) > P(A\mid B^{c}) \implies P(B\mid A) > P(B\mid A^{c}),"My initial thought is to start from $P(A\mid B)$ and $P(A\mid B^{c})$ and transform them to expressions involving $P(B\mid A)$ and $P(B\mid A^{c})$ respectively. $P(A\mid B) = \dfrac{P(A)P(B\mid A)}{P(B)}$ $P(A\mid B^{c}) = \dfrac{P(A) - P(B) + P(A^{c})P(B\mid A^{c})}{P(B^{c})}$ The expressions get quite messy when I try to compare them, and I am wondering if there is a better a way.","My initial thought is to start from and and transform them to expressions involving and respectively. The expressions get quite messy when I try to compare them, and I am wondering if there is a better a way.",P(A\mid B) P(A\mid B^{c}) P(B\mid A) P(B\mid A^{c}) P(A\mid B) = \dfrac{P(A)P(B\mid A)}{P(B)} P(A\mid B^{c}) = \dfrac{P(A) - P(B) + P(A^{c})P(B\mid A^{c})}{P(B^{c})},"['probability', 'conditional-probability']"
59,"Show that $E(|S_n-np|) = 2vq b(v; n, p) $.",Show that .,"E(|S_n-np|) = 2vq b(v; n, p) ","(Feller Vol.1, P.241, Q.35) Let $S_n$ be the number of successes in $n$ Bernoulli trials. Prove $$E(|S_n-np|) = 2vq b(v; n, p) $$ where $v$ is the integer such that $np < v \le np+1$ and $b(v; n,p)$ is a binomial distribution with $v$ successes of $n$ trials. Hint: The left side $= \sum_{k=0}^{v-1} (np - k) \frac{n}{k} p^k q^{n-k}$ . My attempt: I found that $P(|S_n - np| = j)= b(np +j ; n, p)$ if $S_n \ge np$ , $b(np-j; n,p)$ if $S_n < np$ . Therefore, $$E(|S_n-np|)= \sum_{k=0}^{v-1} (np-k)b(k;n,p) + \sum_{k=v}^{n}(k-np)b(k; n,p).$$ I am stuck here, and don't know how to proceed. I would appreciate if you give some help.","(Feller Vol.1, P.241, Q.35) Let be the number of successes in Bernoulli trials. Prove where is the integer such that and is a binomial distribution with successes of trials. Hint: The left side . My attempt: I found that if , if . Therefore, I am stuck here, and don't know how to proceed. I would appreciate if you give some help.","S_n n E(|S_n-np|) = 2vq b(v; n, p)  v np < v \le np+1 b(v; n,p) v n = \sum_{k=0}^{v-1} (np - k) \frac{n}{k} p^k q^{n-k} P(|S_n - np| = j)= b(np +j ; n, p) S_n \ge np b(np-j; n,p) S_n < np E(|S_n-np|)= \sum_{k=0}^{v-1} (np-k)b(k;n,p) + \sum_{k=v}^{n}(k-np)b(k; n,p).","['probability', 'probability-distributions', 'binomial-distribution']"
60,Probability of Exiting A Roundabout,Probability of Exiting A Roundabout,,"I am piggybacking on this question: probability of leaving The question was closed, but I found it interesting and I would like feedback on what I have done with it, and I have more questions about it. I'm not sure what proper etiquette is for piggybacking on closed questions. I will rephrase the question as I understand it: In the diagram below, you start at the node marked with lowercase $a$ . From $a$ , you move to one of the adjacent nodes, chosen uniformly at random. That is, you move to $b$ , $d$ , or $A$ . If you are at a lowercase node, you continue in the same fashion, moving to an adjacent node uniformly at random. Once you reach an uppercase node, you have left the roundabout, and the journey stops. The question is, what are the probabilities of the journey ending at $A$ , $B$ , $C$ , and $D$ ? In the original question, there was an answer that used Markov chains, but I am wondering if there is a way to do it without that technique. I modeled this experiment in Excel, and after $100,000$ trials, the probabilities appear to be roughly: $P(A)=46.5\%$ $P(B)=P(D)=20\%$ $P(C)=13.5\%$ I have no way of knowing if these are the exact answers, or even if the exact answers are rational numbers, but they make intuitive sense to me because of the structure and symmetry in the diagram. I wonder if there is a way to ""juggle"" conditional probabilities to find exact answers to this question, without having to use Markov chains. I would start by calculating $P(A|a)$ , the probability of leaving at $A$ given you started at $a$ . By symmetry, $P(B|b)$ , $P(C|c)$ , and $P(D|d)$ would be the same as $P(A|a)$ . To get $P(A|a)$ , notice that the total length of the walk must be odd. Either you leave immediately ( $1$ step), or you take an even number of steps in the roundabout to return to $a$ , and then leave at $A$ ( $2m+1$ , for some integer $m$ , steps). For a given walk of $k$ steps, the probability of taking that walk is simply $(\frac13)^k$ . Let $N_k$ be the number of walks of $k$ steps that leave the roundabout at $A$ . Then $P(A|a)=\frac13+N_3\cdot(\frac13)^3+N_5\cdot(\frac13)^5+...$ I'm unable to find a systematic way of calculating $N_k$ . It is easy enough to do for $k=3$ or $5$ , but I can't be sure of what pattern is emerging. Beyond that, assuming I did have an exact answer for $P(A|a)$ , I would still need to figure out $P(B|a)$ . Would that just be $\frac13\cdot P(A|a)$ since there is a $\frac13$ probability of going to $b$ on the first step? By symmetry, $P(D|a)=P(B|a)$ , so if I had $P(A|a)$ and $P(B|a)$ , I could easily figure out all the probabilites. I would appreciate any input on this!","I am piggybacking on this question: probability of leaving The question was closed, but I found it interesting and I would like feedback on what I have done with it, and I have more questions about it. I'm not sure what proper etiquette is for piggybacking on closed questions. I will rephrase the question as I understand it: In the diagram below, you start at the node marked with lowercase . From , you move to one of the adjacent nodes, chosen uniformly at random. That is, you move to , , or . If you are at a lowercase node, you continue in the same fashion, moving to an adjacent node uniformly at random. Once you reach an uppercase node, you have left the roundabout, and the journey stops. The question is, what are the probabilities of the journey ending at , , , and ? In the original question, there was an answer that used Markov chains, but I am wondering if there is a way to do it without that technique. I modeled this experiment in Excel, and after trials, the probabilities appear to be roughly: I have no way of knowing if these are the exact answers, or even if the exact answers are rational numbers, but they make intuitive sense to me because of the structure and symmetry in the diagram. I wonder if there is a way to ""juggle"" conditional probabilities to find exact answers to this question, without having to use Markov chains. I would start by calculating , the probability of leaving at given you started at . By symmetry, , , and would be the same as . To get , notice that the total length of the walk must be odd. Either you leave immediately ( step), or you take an even number of steps in the roundabout to return to , and then leave at ( , for some integer , steps). For a given walk of steps, the probability of taking that walk is simply . Let be the number of walks of steps that leave the roundabout at . Then I'm unable to find a systematic way of calculating . It is easy enough to do for or , but I can't be sure of what pattern is emerging. Beyond that, assuming I did have an exact answer for , I would still need to figure out . Would that just be since there is a probability of going to on the first step? By symmetry, , so if I had and , I could easily figure out all the probabilites. I would appreciate any input on this!","a a b d A A B C D 100,000 P(A)=46.5\% P(B)=P(D)=20\% P(C)=13.5\% P(A|a) A a P(B|b) P(C|c) P(D|d) P(A|a) P(A|a) 1 a A 2m+1 m k (\frac13)^k N_k k A P(A|a)=\frac13+N_3\cdot(\frac13)^3+N_5\cdot(\frac13)^5+... N_k k=3 5 P(A|a) P(B|a) \frac13\cdot P(A|a) \frac13 b P(D|a)=P(B|a) P(A|a) P(B|a)","['probability', 'random-walk']"
61,Statistics of a Gaussian random variable with the floor function transformation,Statistics of a Gaussian random variable with the floor function transformation,,"Suppose $X$ is a Gaussian random variable, i.e., $X\sim N(\mu, \sigma)$ . Let $Y$ be defined as $Y=\lfloor X \rfloor$ , where $\lfloor \cdot \rfloor$ denotes the floor function (greatest integer lesser or equal than $X$ ). It can be seen from here that $$P(Y=y)=P(y\le X< y+1)=P(X<y+1)-P(X\le y)\\ =\Phi\left(\frac{y+1-\mu}{\sigma}\right)-\Phi\left(\frac{y-\mu}{\sigma}\right) \\ =\frac{1}{2}\left[1+\operatorname{erf}\left(\frac{y+1-\mu}{\sigma\sqrt{2}}\right)\right]-\frac{1}{2}\left[1+\operatorname{erf}\left(\frac{y-\mu}{\sigma\sqrt{2}}\right)\right]$$ where $\Phi(\cdot$ ) is the CDF for standard Gaussian and $\operatorname{erf}(\cdot)$ is the error function. I have two questions: (1) Is $Y$ a regular discrete random variable? Or it does not have a standard expression (i.e., does it belong to any families of distributions)? (2) More importantly , what is the mean and variance of random variable $Y$ ? Please help and thanks in advance!","Suppose is a Gaussian random variable, i.e., . Let be defined as , where denotes the floor function (greatest integer lesser or equal than ). It can be seen from here that where ) is the CDF for standard Gaussian and is the error function. I have two questions: (1) Is a regular discrete random variable? Or it does not have a standard expression (i.e., does it belong to any families of distributions)? (2) More importantly , what is the mean and variance of random variable ? Please help and thanks in advance!","X X\sim N(\mu, \sigma) Y Y=\lfloor X \rfloor \lfloor \cdot \rfloor X P(Y=y)=P(y\le X< y+1)=P(X<y+1)-P(X\le y)\\ =\Phi\left(\frac{y+1-\mu}{\sigma}\right)-\Phi\left(\frac{y-\mu}{\sigma}\right) \\ =\frac{1}{2}\left[1+\operatorname{erf}\left(\frac{y+1-\mu}{\sigma\sqrt{2}}\right)\right]-\frac{1}{2}\left[1+\operatorname{erf}\left(\frac{y-\mu}{\sigma\sqrt{2}}\right)\right] \Phi(\cdot \operatorname{erf}(\cdot) Y Y","['probability', 'probability-distributions', 'random-variables', 'normal-distribution', 'ceiling-and-floor-functions']"
62,Possibility of ants not being able to cross a grid shaped bridge,Possibility of ants not being able to cross a grid shaped bridge,,"The problem is really simple, but I have absolutely no idea on how to solve it. So there is an ant who really wants to get to the other side of a grid shaped bridge. However, a person decides to stop the ant from crossing over, so he gets a coin and starts throwing it for each of the 28 black line segments. If the coin that he threw is a tail, he cuts out that line segment, and if the coin that he threw is a head, he leaves the line segment alone. After he does this for every 28 black line segment, what is the possibility that the ant still can cross the bridge?","The problem is really simple, but I have absolutely no idea on how to solve it. So there is an ant who really wants to get to the other side of a grid shaped bridge. However, a person decides to stop the ant from crossing over, so he gets a coin and starts throwing it for each of the 28 black line segments. If the coin that he threw is a tail, he cuts out that line segment, and if the coin that he threw is a head, he leaves the line segment alone. After he does this for every 28 black line segment, what is the possibility that the ant still can cross the bridge?",,"['probability', 'combinatorics', 'combinations', 'game-theory', 'combinatorial-game-theory']"
63,What is the expected number of dice rolls to roll any number n times?,What is the expected number of dice rolls to roll any number n times?,,"I know that the expected number of rolls to roll a number x is 6, and from that I'm guessing that the expected number of rolls to roll an x n times is 6n. But I don't know the expected value if we're not looking for a specific x, but rather any number that gets rolled n times first.","I know that the expected number of rolls to roll a number x is 6, and from that I'm guessing that the expected number of rolls to roll an x n times is 6n. But I don't know the expected value if we're not looking for a specific x, but rather any number that gets rolled n times first.",,"['probability', 'probability-distributions', 'expected-value']"
64,How is $P(A^c \cap B^c)$ the same as $1-P(A \cup B)$?,How is  the same as ?,P(A^c \cap B^c) 1-P(A \cup B),"I don't understand how $P(A^c \cap B^c) = 1-P(A \cup B)$ is the same? If I draw $P(A^c \cap B^c)$ as a Venn diagram: If I draw $P(A \cup B)$ as a Venn diagram: So if I subtract $P(A \cup B)$ from 1, wouldn't that mean that I subtract $P(A \cup B)$ from the universe $\Omega$ , which would result int this: However, that would mean $P(A^c \cap B^c) \neq 1-P(A \cup B)$ Edit: As pointed out by multiple people. My diagram for $P(A^c \cap B^c)$ should look like the following and therefore the assumption of $P(A^c \cap B^c) = 1-P(A \cup B)$ is valid:","I don't understand how is the same? If I draw as a Venn diagram: If I draw as a Venn diagram: So if I subtract from 1, wouldn't that mean that I subtract from the universe , which would result int this: However, that would mean Edit: As pointed out by multiple people. My diagram for should look like the following and therefore the assumption of is valid:",P(A^c \cap B^c) = 1-P(A \cup B) P(A^c \cap B^c) P(A \cup B) P(A \cup B) P(A \cup B) \Omega P(A^c \cap B^c) \neq 1-P(A \cup B) P(A^c \cap B^c) P(A^c \cap B^c) = 1-P(A \cup B),"['probability', 'elementary-set-theory']"
65,Why does the beta distribution become U shaped when $\alpha$ and $\beta$ <1?,Why does the beta distribution become U shaped when  and  <1?,\alpha \beta,"In the Beta distribution (used to model Bernoulli probabilities), the $\alpha$ and $\beta$ parameters can be interpreted as the number of heads $+1$ and the number of tails $+1$ seen. So, if they were both $2$ , it would lean towards the coin being fair and have a maximum at $0.5$ . If they are both $20$ , the distribution would become even surer we're dealing with a fair coin and peak even more at $p=0.5$ . What I don't get is its behavior when $\alpha$ and $\beta$ both become $<1$ . In that case, it becomes U-shaped and the density peaks at $p=0$ and $p=1$ . Meaning the coin is likely to be two-sided. I know there is an intuition for this since I think I had an idea about it a long time ago. However, I've been trying to recollect all day and can't piece it together. Does anyone have an intuition?","In the Beta distribution (used to model Bernoulli probabilities), the and parameters can be interpreted as the number of heads and the number of tails seen. So, if they were both , it would lean towards the coin being fair and have a maximum at . If they are both , the distribution would become even surer we're dealing with a fair coin and peak even more at . What I don't get is its behavior when and both become . In that case, it becomes U-shaped and the density peaks at and . Meaning the coin is likely to be two-sided. I know there is an intuition for this since I think I had an idea about it a long time ago. However, I've been trying to recollect all day and can't piece it together. Does anyone have an intuition?",\alpha \beta +1 +1 2 0.5 20 p=0.5 \alpha \beta <1 p=0 p=1,"['probability', 'beta-function']"
66,Pointwise convergence vs. almost sure convergence,Pointwise convergence vs. almost sure convergence,,"I do not understand the difference between these two types of convergence for random variables. Actually, I am not seeing a lot of people using the notion of pointwise convergence for random variables. So, what is the difference? Does anyone have a memorable example illustrating the difference?","I do not understand the difference between these two types of convergence for random variables. Actually, I am not seeing a lot of people using the notion of pointwise convergence for random variables. So, what is the difference? Does anyone have a memorable example illustrating the difference?",,"['probability', 'probability-theory', 'random-variables']"
67,question about the notation of conditional expectation,question about the notation of conditional expectation,,"Let $X$ be a standard normal random variable. We need to compute the integral $$E(X~|X>0).$$ In the book, they give the answer ${1\over \sqrt{2\pi}}$ . Then I am confused with this conditional expectation notation. Since from my understanding, it should be $$\int_0^\infty 2\cdot {x\over \sqrt{2\pi}} e^{-{x^2\over 2}}\, dx$$ which gives the answer $\sqrt{{2\over\pi}}$ . I add a factor ""2"" here. Can anyone tell me this conditon expectation $E(X|X>0)$ notation meaning? Since it is not standard, we usually conditioning on a $\sigma$ -algebra, rather than a set.","Let be a standard normal random variable. We need to compute the integral In the book, they give the answer . Then I am confused with this conditional expectation notation. Since from my understanding, it should be which gives the answer . I add a factor ""2"" here. Can anyone tell me this conditon expectation notation meaning? Since it is not standard, we usually conditioning on a -algebra, rather than a set.","X E(X~|X>0). {1\over \sqrt{2\pi}} \int_0^\infty 2\cdot {x\over \sqrt{2\pi}} e^{-{x^2\over 2}}\, dx \sqrt{{2\over\pi}} E(X|X>0) \sigma","['probability', 'probability-theory', 'conditional-expectation', 'conditional-probability']"
68,"> Let $X$, $Y$, and $Z$ be three independent uniform random variables on $[0, 1]$. What is $P(XY < Z^2)$?","> Let , , and  be three independent uniform random variables on . What is ?","X Y Z [0, 1] P(XY < Z^2)","Let $X$ , $Y$ , and $Z$ be three independent uniform random variables on $[0, 1]$ . Compute the probability $P(XY < Z^2)$ . I used the following approach : Step 1 : Calculated the Probability distribution for $XY$ . It turns out to be $P(XY \leq K) = \frac 1K$ . Step 2 : Calculated the Probability distribution for $Z^2$ . It turns out to be $P(Z^2 \leq L) = P(-\root \of{L} \leq Z \leq \root \of{L}) = \root \of{L}$ . Step 3: Calculate the joint density function by multiplying the above functions and differentiating. I get $$f_{Q_1Q_2} (q_1,q_2) = \frac {-1}{2q_1^2\root\of{q_2}}$$ . where $Q_1 = XY$ , $Q_2 =Z^2$ . Step 4: Calculate the probability using the integral below. $$\int_{0}^{1}\int_{q_1}^{1}\frac{-1}{2q_1^2\root\of{q_2}}dq_2dq_1$$ There is definitely something wrong with this procedure. Any help will be appreciated.","Let , , and be three independent uniform random variables on . Compute the probability . I used the following approach : Step 1 : Calculated the Probability distribution for . It turns out to be . Step 2 : Calculated the Probability distribution for . It turns out to be . Step 3: Calculate the joint density function by multiplying the above functions and differentiating. I get . where , . Step 4: Calculate the probability using the integral below. There is definitely something wrong with this procedure. Any help will be appreciated.","X Y Z [0, 1] P(XY < Z^2) XY P(XY \leq K) = \frac 1K Z^2 P(Z^2 \leq L) = P(-\root \of{L} \leq Z \leq \root \of{L}) = \root \of{L} f_{Q_1Q_2} (q_1,q_2) = \frac {-1}{2q_1^2\root\of{q_2}} Q_1 = XY Q_2 =Z^2 \int_{0}^{1}\int_{q_1}^{1}\frac{-1}{2q_1^2\root\of{q_2}}dq_2dq_1",['probability']
69,Example of non random variable,Example of non random variable,,"Given that a random variable $X$ defined on a sample space which takes value on the real line is defined as the set of all outcomes such that $X(outcome)\le r$ , with $r$ a real number, that belongs to the event space for every $r$ , can you provide me with one example (or more) of a non-random variable?  Please give an example that contradicts the part of the statement relative to the fact that the set belongs to the event space, because it is easy to show that a $X$ not defined on the sample space or that takes values outside the real number set is non-random by definition. I could not use latex properly to write rigorously the definition, however is the definition of Mood, Introduction to the theory of Statistics.","Given that a random variable defined on a sample space which takes value on the real line is defined as the set of all outcomes such that , with a real number, that belongs to the event space for every , can you provide me with one example (or more) of a non-random variable?  Please give an example that contradicts the part of the statement relative to the fact that the set belongs to the event space, because it is easy to show that a not defined on the sample space or that takes values outside the real number set is non-random by definition. I could not use latex properly to write rigorously the definition, however is the definition of Mood, Introduction to the theory of Statistics.",X X(outcome)\le r r r X,"['probability', 'statistics', 'random-variables']"
70,probability picking parts no replacement,probability picking parts no replacement,,"In a bin containing 30 parts, 27 parts are good and 3 parts are defective. a) What is the probability that if you select 3 parts randomly, without replacing the parts in the bin, from the bin that you will have 1 defective part? I thought of $\dfrac{\dbinom{27}{1}\dbinom{26}{1}\dbinom{3}{1}}{\dbinom{30}{1}\dbinom{29}{1}\dbinom{28}{1}}$","In a bin containing 30 parts, 27 parts are good and 3 parts are defective. a) What is the probability that if you select 3 parts randomly, without replacing the parts in the bin, from the bin that you will have 1 defective part? I thought of",\dfrac{\dbinom{27}{1}\dbinom{26}{1}\dbinom{3}{1}}{\dbinom{30}{1}\dbinom{29}{1}\dbinom{28}{1}},['probability']
71,Binomial random variable with coin flips. How do we get the formula $P(X=h) = \binom{n}{h}p^h(1-p)^{n-h}$?,Binomial random variable with coin flips. How do we get the formula ?,P(X=h) = \binom{n}{h}p^h(1-p)^{n-h},"Let's say a coin produces $H$ (for heads) with probability $p$ (and thus it produces $T$ with probability $p-1$ . Let $X$ denote the number of $H$ s we see and let $h$ be an integer. Then, if we flip the coin $n$ times: $P(X=h) = \binom{n}{h}p^h(1-p)^{n-h}$ I'm not quite understanding where this formula is coming from. I can see that there are $\binom{n}{h}$ ways to choose a $h$ -length subset of an $n$ -length set (i.e. there are $\binom{n}{h}$ $n$ -length sequences where we see $h$ heads), but why do we multiply that with the probability? Furthermore, why do we multiply the probabilities of heads and tails together? I get that coin flipping is an independent repeated trial, but I'm not sure how to apply that here (or whether it's even relevant). Any help is appreciated!","Let's say a coin produces (for heads) with probability (and thus it produces with probability . Let denote the number of s we see and let be an integer. Then, if we flip the coin times: I'm not quite understanding where this formula is coming from. I can see that there are ways to choose a -length subset of an -length set (i.e. there are -length sequences where we see heads), but why do we multiply that with the probability? Furthermore, why do we multiply the probabilities of heads and tails together? I get that coin flipping is an independent repeated trial, but I'm not sure how to apply that here (or whether it's even relevant). Any help is appreciated!",H p T p-1 X H h n P(X=h) = \binom{n}{h}p^h(1-p)^{n-h} \binom{n}{h} h n \binom{n}{h} n h,"['probability', 'discrete-mathematics', 'binomial-coefficients']"
72,Does the Monty Hall problem occur on this situation?,Does the Monty Hall problem occur on this situation?,,"Lets say, I have the following situation: I know, that an alarm will go on on a certain day. It will go on on any day from Monday to Sunday. On the week before, I know that the possibility is equal (1/7). My question: When it's Wednesday, two days have passed. Is the possibility for the alarm getting on still 1/7 or is it changed? And why or why not? I think the possibility didn't change, because it seems like to be like the monty hall problem.","Lets say, I have the following situation: I know, that an alarm will go on on a certain day. It will go on on any day from Monday to Sunday. On the week before, I know that the possibility is equal (1/7). My question: When it's Wednesday, two days have passed. Is the possibility for the alarm getting on still 1/7 or is it changed? And why or why not? I think the possibility didn't change, because it seems like to be like the monty hall problem.",,"['probability', 'monty-hall']"
73,What is the probability that after this process the content in two bags remains unchanged?,What is the probability that after this process the content in two bags remains unchanged?,,"Each of Alice and Bob has an identical bag containing 6 balls numbered 1, 2, 3, 4, 5, and 6. Alice randomly selects one ball from her bag and places it in Bob’s bag, then Bob randomly selects one ball from his bag and places it in Alice’s bag. What is the probability that after this process the content in two bags remains unchanged? I would have thought that the probability would be $\frac{1}{6} + \frac{2}{7}$ as Alice picks 1 out of balls, now Bob has 7 balls and 2 contain the same number. Or should I have multiplied them in this scenario? The balls are indistinguishable.","Each of Alice and Bob has an identical bag containing 6 balls numbered 1, 2, 3, 4, 5, and 6. Alice randomly selects one ball from her bag and places it in Bob’s bag, then Bob randomly selects one ball from his bag and places it in Alice’s bag. What is the probability that after this process the content in two bags remains unchanged? I would have thought that the probability would be as Alice picks 1 out of balls, now Bob has 7 balls and 2 contain the same number. Or should I have multiplied them in this scenario? The balls are indistinguishable.",\frac{1}{6} + \frac{2}{7},['probability']
74,Gambler's Ruin Problem with Simple Solution - Different Approach,Gambler's Ruin Problem with Simple Solution - Different Approach,,"What is the probability that symmetric simple random walk starting at the origin reaches $−1$ before it reaches $9$ ? Briefly explain your answer. Solution: This is $p = 1$ gambler's ruin with states $0, 1, . . . , 10$ but the states have been relabelled $−1, 0, . . . , 9$ . The answer is $\frac{9}{10}$ because state 0 is one tenth of the way from $−1$ to $9$ . Unfortunately, I used a different and rather clumsy way to approach this question. My attempt was not successful but I was wondering if there is anyone who can tell me how to go further with it and arrive at the solution. My attempt: I drew it out like birth and death process with 11 states. With $-1$ and $9$ having the probability of returning to itself as 1 (absorbing state). Let's $P(X_i)$ be probability to reach $-1$ before reaching $9$ , starting from $i$ . Then I listed out $$P(X_0) = \frac{1}{2} + \frac{1}{2}P(X_1)$$ $$P(X_i) = \frac{1}{2}\left(P(X_{i-1}) + P(X_{i+1})\right) \ \ \text{ for } i \in\{1,2,3,...7\}$$ $$P(X_8) = \frac{1}{2}P(X_7) + 0$$ There are 9 equations and 9 unknowns. We should be able to calculate the result. However, how to go from here?","What is the probability that symmetric simple random walk starting at the origin reaches before it reaches ? Briefly explain your answer. Solution: This is gambler's ruin with states but the states have been relabelled . The answer is because state 0 is one tenth of the way from to . Unfortunately, I used a different and rather clumsy way to approach this question. My attempt was not successful but I was wondering if there is anyone who can tell me how to go further with it and arrive at the solution. My attempt: I drew it out like birth and death process with 11 states. With and having the probability of returning to itself as 1 (absorbing state). Let's be probability to reach before reaching , starting from . Then I listed out There are 9 equations and 9 unknowns. We should be able to calculate the result. However, how to go from here?","−1 9 p = 1 0, 1, . . . , 10 −1, 0, . . . , 9 \frac{9}{10} −1 9 -1 9 P(X_i) -1 9 i P(X_0) = \frac{1}{2} + \frac{1}{2}P(X_1) P(X_i) = \frac{1}{2}\left(P(X_{i-1}) + P(X_{i+1})\right) \ \ \text{ for } i \in\{1,2,3,...7\} P(X_8) = \frac{1}{2}P(X_7) + 0","['probability', 'statistics', 'stochastic-processes', 'markov-chains', 'gambling']"
75,Gambling Systems and Strong Convergence,Gambling Systems and Strong Convergence,,"Say you're betting on ""red"" at roulette.  From one trial to the next, you vary your bet size between the house minimum and maximum based on the outcomes of previous trials.  Can you prove that you go broke with probability 1, or that if you have an unlimited bankroll to start, your long-term return rate (winnings per unit wagered) converges to the expectation of a single unit wager? Well, with probability 1, at least.  That seems plausible.","Say you're betting on ""red"" at roulette.  From one trial to the next, you vary your bet size between the house minimum and maximum based on the outcomes of previous trials.  Can you prove that you go broke with probability 1, or that if you have an unlimited bankroll to start, your long-term return rate (winnings per unit wagered) converges to the expectation of a single unit wager? Well, with probability 1, at least.  That seems plausible.",,"['probability', 'gambling']"
76,Calculating the probability of $ (Z-1)^2 \leq XY$,Calculating the probability of, (Z-1)^2 \leq XY,"We randomly choose three numbers $X, Y, Z$ $\in [0,1]$ . Calculate the probability that $ (Z-1)^2 \leq XY$ . I have tried to observe just the ""edge"" i.e. $ (Z-1)^2  = XY$ but I am pretty much stuck on calculating the boundaries for double integral. Any hint helps!","We randomly choose three numbers . Calculate the probability that . I have tried to observe just the ""edge"" i.e. but I am pretty much stuck on calculating the boundaries for double integral. Any hint helps!","X, Y, Z \in [0,1]  (Z-1)^2 \leq XY  (Z-1)^2  = XY",['probability']
77,Conditional Probability and Shark Attacks,Conditional Probability and Shark Attacks,,Probability of being attacked on day n by shark given that you have not being attacked on days before n is $\cfrac{1}{n + 1}$ . What is the probability of the number of the day when shark attacks for the first time is n. Is it ok to think in the following way: $\mathbb{P}($ day of first attack = n $) = \mathbb{P}($ attack on day n $\land$ $\neg$ attack on day $(n-1)$ $\land$ $...$ $\land$ $\neg$ attack on day 1 $)$ $= \mathbb{P}($ attack on day n $|$ $\neg$ attack on day $(n-1)$ $\land$ $...$ $\land$ $\neg$ attack on day 1 $) \cdot \mathbb{P}($ $\neg$ attack on day $(n-1)$ $\land$ $...$ $\land$ $\neg$ attack on day 1 $)$ $=\cfrac{1}{n + 1} \cdot \Big( 1 - \cfrac{1}{n} \Big)\cdot ... \cdot \cfrac{1}{2} = \cfrac{1}{n + 1} \cdot \cfrac{n - 1}{n} \cdot \cfrac{n}{n - 1} \cdot ... \cdot \cfrac{1}{2} = \cfrac{1}{(n + 1)\cdot n}$,Probability of being attacked on day n by shark given that you have not being attacked on days before n is . What is the probability of the number of the day when shark attacks for the first time is n. Is it ok to think in the following way: day of first attack = n attack on day n attack on day attack on day 1 attack on day n attack on day attack on day 1 attack on day attack on day 1,\cfrac{1}{n + 1} \mathbb{P}( ) = \mathbb{P}( \land \neg (n-1) \land ... \land \neg ) = \mathbb{P}( | \neg (n-1) \land ... \land \neg ) \cdot \mathbb{P}( \neg (n-1) \land ... \land \neg ) =\cfrac{1}{n + 1} \cdot \Big( 1 - \cfrac{1}{n} \Big)\cdot ... \cdot \cfrac{1}{2} = \cfrac{1}{n + 1} \cdot \cfrac{n - 1}{n} \cdot \cfrac{n}{n - 1} \cdot ... \cdot \cfrac{1}{2} = \cfrac{1}{(n + 1)\cdot n},"['probability', 'proof-verification', 'conditional-probability']"
78,Probability of chossing two points from a segment of length L so that one is 2L/3 greater than another.,Probability of chossing two points from a segment of length L so that one is 2L/3 greater than another.,,"Two points are selected randomly on a line of length $L$ so as to be on the opposite sides of the midpoint of the line. In other words, two points X and Y are independent random variables such that X is uniformly distributed over $(0,L/2)$ and Y is so over $(L/2,0)$ . Find the probability that the distance between these two points is greater than $2L/3$ . Here's what I have done. Can I get some help to finish this.","Two points are selected randomly on a line of length so as to be on the opposite sides of the midpoint of the line. In other words, two points X and Y are independent random variables such that X is uniformly distributed over and Y is so over . Find the probability that the distance between these two points is greater than . Here's what I have done. Can I get some help to finish this.","L (0,L/2) (L/2,0) 2L/3","['probability', 'probability-theory', 'conditional-probability']"
79,Tail event example,Tail event example,,"In Durrett's Probability (4th edition), an example of a tail event (an event in the tail sigma-field $\bigcap_n \sigma(X_n, X_{n+1}, \dots)$ ) is the following: given independent random variables $X_1, X_2, \dots,$ and their partial sums $S_n = \sum_{i=1}^n X_i$ , the following event is a tail event ( Example 2.5.2 ): $$ \{ \limsup_n S_n > x c_n \}, \; c_n \to \infty. $$ I understand the high level idea of a tail event (i.e. only depends in the asymptotic behavior of the sum since $c_n$ go to infinity) but I cannot articulate a rigorous explanation. Is there a concrete way to show this?","In Durrett's Probability (4th edition), an example of a tail event (an event in the tail sigma-field ) is the following: given independent random variables and their partial sums , the following event is a tail event ( Example 2.5.2 ): I understand the high level idea of a tail event (i.e. only depends in the asymptotic behavior of the sum since go to infinity) but I cannot articulate a rigorous explanation. Is there a concrete way to show this?","\bigcap_n \sigma(X_n, X_{n+1}, \dots) X_1, X_2, \dots, S_n = \sum_{i=1}^n X_i 
\{ \limsup_n S_n > x c_n \}, \; c_n \to \infty.
 c_n","['probability', 'probability-theory', 'measure-theory', 'probability-limit-theorems']"
80,We throw $5$ dice: What is the probability to have $4$ different numbers?,We throw  dice: What is the probability to have  different numbers?,5 4,"We throw $5$ dice: What is the probability to have $4$ different numbers? I know it is $$\frac{6\cdot 5\cdot 4\cdot 3}{6^5}.$$ I wanted to use an other argument, but it look to not work : I take $\binom{6}{4}$ numbers. Then I have $$\frac{6\cdot 5\cdot 4\cdot 3}{4!}$$ possibilities. Then I have to multiply this result by $4!$ and I don't understand why. Indeed, I would like to multiply by $5!$ since we can distribute the $5$ colors in e.g. $1;2;3;4;4$ in $5!$ different ways. If I want all dice different, this argument works: I take $\binom{6}{5}$ number, then I can distribute the colors in $5!$ different way which give $\frac{5\cdot 5\cdot 4\cdot 3\cdot 2}{5!}5!=6\cdot 5\cdot 4\cdot 3\cdot 2$ possibilities, that is the correct answer. So why doesn't it work with the previous situation ?","We throw dice: What is the probability to have different numbers? I know it is I wanted to use an other argument, but it look to not work : I take numbers. Then I have possibilities. Then I have to multiply this result by and I don't understand why. Indeed, I would like to multiply by since we can distribute the colors in e.g. in different ways. If I want all dice different, this argument works: I take number, then I can distribute the colors in different way which give possibilities, that is the correct answer. So why doesn't it work with the previous situation ?",5 4 \frac{6\cdot 5\cdot 4\cdot 3}{6^5}. \binom{6}{4} \frac{6\cdot 5\cdot 4\cdot 3}{4!} 4! 5! 5 1;2;3;4;4 5! \binom{6}{5} 5! \frac{5\cdot 5\cdot 4\cdot 3\cdot 2}{5!}5!=6\cdot 5\cdot 4\cdot 3\cdot 2,"['probability', 'combinatorics']"
81,Conditional expectation of a function with independent random variables,Conditional expectation of a function with independent random variables,,"If $X_1, ..., X_{n+1}$ are independent real random variables and $h:\mathbb{R}^{n+1} \to \mathbb{R}$ a Borel function. Now taking the conditional expectation $\mathbb{E}[h(X_1, \ldots, X_{n+1})| \sigma(X_1, \ldots, X_n)]$ Assuming $\mathbb{E}[|h(X_1, \ldots, X_{n+1})|] < \infty $ show that if $g(x_1, \ldots, x_n) = \mathbb{E}[h(x_1, \ldots, x_n, X_{n+1})]$ then $g(X_1, \ldots, X_n)$ is a version of $\mathbb{E}[h(X_1, \ldots, X_{n+1})| \sigma(X_1, \ldots, X_n)]$ . The claim would follow from the definition of conditional expectation, if we can show that $$ \mathbb{E}[h(X_1, \ldots, X_{n+1}) \mathbf{1}_G] = \mathbb{E}[g(X_1, \ldots, X_{n}) \mathbf{1}_G], $$ for all $G \in \sigma(X_1, \ldots, X_n)$ . What I tried so far is trying to expand the expectations and rewrite them with Fubini's theorem. Assuming the underlying probability space is $(\Omega, \mathcal{F}, P)$ . I thought I could rewrite with a restricted push forward $P_{|G}^{X_i}(A) = P(X_i^{-1}(A) \cap G)$ to get $$ \mathbb{E}[h(X_1, \ldots, X_{n+1}) \mathbf{1}_G] = \int_{(x_1, \ldots x_{n+1})\in \mathbb{R}^{n+1}} h(x_1, \ldots, x_{n+1}) dP_{|G}^{X_1, \ldots, X_{n+1}} $$ All variables are $X_i$ independet so we can factor $dP_{|G}^{X_1, \ldots, X_{n+1}} = d \Pi_{i=1}^{n+1}  P_{|G}^{X_i}$ . $$ = \int_{(x_1, \ldots x_{n+1})\in \mathbb{R}^{n+1}} h(x_1, \ldots, x_{n+1}) d \Pi_{i=1}^{n+1} P_{|G}^{X_i} = \int_{(x_1, \ldots x_{n})\in \mathbb{R}^{n}} \left(\int_{x_{n+1}\in \mathbb{R}} h(x_1, \ldots, x_{n+1}) dP_{|G}^{X_{n+1}} \right) d \Pi_{i=1}^{n}  P_{|G}^{X_i}  $$ Now $P_{|G}^{X_{n+1}}(A) = P(X_{n+1}^{-1}(A)\cap G) = P(X_{n+1}^{-1}(A))P(G)$ , since $\sigma(X_{n+1})$ and $\sigma(X_1,\ldots, X_n)$ are independet. Since $\mathbb{E}[|h(X_1, \ldots, X_{n+1})|] < \infty $ Fubini applies and we get $$ \int_{(x_1, \ldots x_{n})\in \mathbb{R}^{n}} \left(\int_{x_{n+1} \in \mathbb{R}} h(x_1, \ldots, x_{n+1}) dP_{|G}^{X_{n+1}} \right) d \Pi_{i=0}^{n}  P_{|G}^{X_i} = P(G)\int_{(x_1, \ldots x_{n})\in \mathbb{R}} \left(\int_{x_{n+1} \in \mathbb{R}} h(x_1, \ldots, x_{n+1}) dP^{X_{n+1}} \right) d \Pi_{i=0}^{n}  P_{|G}^{X_i} $$ $$ = P(G) \int_{(x_1, \ldots x_{n}) \in \mathbb{R}^n} E[h(x_1, \ldots, X_{n+1})] d \Pi_{i=0}^{n}  P_{|G}^{X_i} = P(G) \int_{(x_1, \ldots x_{n})\in \mathbb{R}^n} g(x_1, \ldots, x_n)  d \Pi_{i=0}^{n}  P_{|G}^{X_i} = P(G)\mathbb{E}[g(X_1, \ldots, X_n) \mathbf{1}_G].   $$ So I the end I get $$ \mathbb{E}[h(X_1, \ldots, X_{n+1}) \mathbf{1}_G] = P(G)\mathbb{E}[g(X_1, \ldots, X_n) \mathbf{1}_G],$$ which is wrong according to the claim! I can't spot my mistake. So is the claim really true and if so where do I mess up?","If are independent real random variables and a Borel function. Now taking the conditional expectation Assuming show that if then is a version of . The claim would follow from the definition of conditional expectation, if we can show that for all . What I tried so far is trying to expand the expectations and rewrite them with Fubini's theorem. Assuming the underlying probability space is . I thought I could rewrite with a restricted push forward to get All variables are independet so we can factor . Now , since and are independet. Since Fubini applies and we get So I the end I get which is wrong according to the claim! I can't spot my mistake. So is the claim really true and if so where do I mess up?","X_1, ..., X_{n+1} h:\mathbb{R}^{n+1} \to \mathbb{R} \mathbb{E}[h(X_1, \ldots, X_{n+1})| \sigma(X_1, \ldots, X_n)] \mathbb{E}[|h(X_1, \ldots, X_{n+1})|] < \infty  g(x_1, \ldots, x_n) = \mathbb{E}[h(x_1, \ldots, x_n, X_{n+1})] g(X_1, \ldots, X_n) \mathbb{E}[h(X_1, \ldots, X_{n+1})| \sigma(X_1, \ldots, X_n)]  \mathbb{E}[h(X_1, \ldots, X_{n+1}) \mathbf{1}_G] = \mathbb{E}[g(X_1, \ldots, X_{n}) \mathbf{1}_G],  G \in \sigma(X_1, \ldots, X_n) (\Omega, \mathcal{F}, P) P_{|G}^{X_i}(A) = P(X_i^{-1}(A) \cap G)  \mathbb{E}[h(X_1, \ldots, X_{n+1}) \mathbf{1}_G] = \int_{(x_1, \ldots x_{n+1})\in \mathbb{R}^{n+1}} h(x_1, \ldots, x_{n+1}) dP_{|G}^{X_1, \ldots, X_{n+1}}  X_i dP_{|G}^{X_1, \ldots, X_{n+1}} = d \Pi_{i=1}^{n+1}  P_{|G}^{X_i}  = \int_{(x_1, \ldots x_{n+1})\in \mathbb{R}^{n+1}} h(x_1, \ldots, x_{n+1}) d \Pi_{i=1}^{n+1} P_{|G}^{X_i} = \int_{(x_1, \ldots x_{n})\in \mathbb{R}^{n}} \left(\int_{x_{n+1}\in \mathbb{R}} h(x_1, \ldots, x_{n+1}) dP_{|G}^{X_{n+1}} \right) d \Pi_{i=1}^{n}  P_{|G}^{X_i}   P_{|G}^{X_{n+1}}(A) = P(X_{n+1}^{-1}(A)\cap G) = P(X_{n+1}^{-1}(A))P(G) \sigma(X_{n+1}) \sigma(X_1,\ldots, X_n) \mathbb{E}[|h(X_1, \ldots, X_{n+1})|] < \infty   \int_{(x_1, \ldots x_{n})\in \mathbb{R}^{n}} \left(\int_{x_{n+1} \in \mathbb{R}} h(x_1, \ldots, x_{n+1}) dP_{|G}^{X_{n+1}} \right) d \Pi_{i=0}^{n}  P_{|G}^{X_i} = P(G)\int_{(x_1, \ldots x_{n})\in \mathbb{R}} \left(\int_{x_{n+1} \in \mathbb{R}} h(x_1, \ldots, x_{n+1}) dP^{X_{n+1}} \right) d \Pi_{i=0}^{n}  P_{|G}^{X_i}   = P(G) \int_{(x_1, \ldots x_{n}) \in \mathbb{R}^n} E[h(x_1, \ldots, X_{n+1})] d \Pi_{i=0}^{n}  P_{|G}^{X_i} = P(G) \int_{(x_1, \ldots x_{n})\in \mathbb{R}^n} g(x_1, \ldots, x_n)  d \Pi_{i=0}^{n}  P_{|G}^{X_i} = P(G)\mathbb{E}[g(X_1, \ldots, X_n) \mathbf{1}_G].     \mathbb{E}[h(X_1, \ldots, X_{n+1}) \mathbf{1}_G] = P(G)\mathbb{E}[g(X_1, \ldots, X_n) \mathbf{1}_G],","['probability', 'measure-theory', 'conditional-expectation']"
82,"A bag contains 4 Black and 3 Red balls, 2 balls are drawn one by one without replacement, what is the probability of both being red?","A bag contains 4 Black and 3 Red balls, 2 balls are drawn one by one without replacement, what is the probability of both being red?",,"I  tried searching the internet regarding the third approach i did , but did not find any explanation for the same, here i have tried approaching this problem in 3 different ways. approach 1: since two balls are drawn without replacement, this can be treated as $P (\text{selecting $2$ out of $7$ balls such that both are red})$ $=\frac{^3C_2}{^{7}C_2}$ approach 2: $P (\text{select 1 R out of 3R })\times$ $P (\text{select 1 out of 2 remaining R })$ $=\frac{^3C_1}{7C_1}\times$$\frac{^2C_1}{6C_1}$ approach 3: $P (\text{selecting 1 out of 3 R and then 1 out of 2 R balls in the second draw })$ $=\frac{N(RR)}{{N(RR)+N(RB)+N(BR)+N(BB)}}$ $=\frac{^3C_1\times^2C_1}{^3C_1\times^2C_1+^3C_1\times^4C_1+^4C_1\times^3C_1+^4C_1\times^3C_1}$ all the above approaches give correct answer, but i am not sure how approach 1 and approach 2 are equivalent, clearly this is a case of conditional probability without replacement, in the first case, i take 2 balls simultaneously out of 7 and compute probability of both being red, that is same as drawing 2 balls without replacement!  is this the correct way to approach a problem? in the approach 3 , i tried calculating the sample space where 2 balls are drawn without replacement, where there are four cases: Red in first and Red in second draw Red in first and Black in second draw Black in first and Red in second draw Black in first and Black in second draw I am quite unsure about the validity of approach 3! I am not sure if this is the right way to approach a problem.","I  tried searching the internet regarding the third approach i did , but did not find any explanation for the same, here i have tried approaching this problem in 3 different ways. approach 1: since two balls are drawn without replacement, this can be treated as approach 2: approach 3: all the above approaches give correct answer, but i am not sure how approach 1 and approach 2 are equivalent, clearly this is a case of conditional probability without replacement, in the first case, i take 2 balls simultaneously out of 7 and compute probability of both being red, that is same as drawing 2 balls without replacement!  is this the correct way to approach a problem? in the approach 3 , i tried calculating the sample space where 2 balls are drawn without replacement, where there are four cases: Red in first and Red in second draw Red in first and Black in second draw Black in first and Red in second draw Black in first and Black in second draw I am quite unsure about the validity of approach 3! I am not sure if this is the right way to approach a problem.",P (\text{selecting 2 out of 7 balls such that both are red}) =\frac{^3C_2}{^{7}C_2} P (\text{select 1 R out of 3R })\times P (\text{select 1 out of 2 remaining R }) =\frac{^3C_1}{7C_1}\times\frac{^2C_1}{6C_1} P (\text{selecting 1 out of 3 R and then 1 out of 2 R balls in the second draw }) =\frac{N(RR)}{{N(RR)+N(RB)+N(BR)+N(BB)}} =\frac{^3C_1\times^2C_1}{^3C_1\times^2C_1+^3C_1\times^4C_1+^4C_1\times^3C_1+^4C_1\times^3C_1},"['probability', 'conditional-probability']"
83,"What's the difference between the probability of the nth coin flip, vs. the probability of flipping all the coins and getting one outcome","What's the difference between the probability of the nth coin flip, vs. the probability of flipping all the coins and getting one outcome",,"So this is more of a problem with getting an intuitive understanding. I'm sure something like this has been asked before but I couldn't find it because I didn't have a clue what my problem was to start with. Here goes: Question: You have flipped a fair coin 9 times and it has landed on tails all 9 times in a row. What is the probability that the next flip will be tails? My understanding: If you've flipped 9 heads in a row, and are asked what is the probability that the next flip will be a head , that's not the same as asking what's the probability of flipping 10 heads in a row . I do understand that each coin flip is completely independent, and so will always be a 50-50 chance of heads or tails. The problem: Yet, I'm not quite sure why the probability of flipping 10 heads in a row is different from flipping a 10th head. Is it because we're only being asked to calculate the probability of that one event happening rather than the entire set of events? I think I may have inadvertently solved my own problem by asking this question because I had to think so much to ask it haha! I'm going to post it anyway just to ask if you can perhaps give me an example that will help me better grasp this? EDIT: I found another discussion here that asked a better, more illustrative question, and the Gambler's Fallacy, specifically the part on coin tosses, best explains the logical problem in my question. I'm placing this here in the hopes that it helps one of you future readers: Wikipedia: Gambler's Fallacy","So this is more of a problem with getting an intuitive understanding. I'm sure something like this has been asked before but I couldn't find it because I didn't have a clue what my problem was to start with. Here goes: Question: You have flipped a fair coin 9 times and it has landed on tails all 9 times in a row. What is the probability that the next flip will be tails? My understanding: If you've flipped 9 heads in a row, and are asked what is the probability that the next flip will be a head , that's not the same as asking what's the probability of flipping 10 heads in a row . I do understand that each coin flip is completely independent, and so will always be a 50-50 chance of heads or tails. The problem: Yet, I'm not quite sure why the probability of flipping 10 heads in a row is different from flipping a 10th head. Is it because we're only being asked to calculate the probability of that one event happening rather than the entire set of events? I think I may have inadvertently solved my own problem by asking this question because I had to think so much to ask it haha! I'm going to post it anyway just to ask if you can perhaps give me an example that will help me better grasp this? EDIT: I found another discussion here that asked a better, more illustrative question, and the Gambler's Fallacy, specifically the part on coin tosses, best explains the logical problem in my question. I'm placing this here in the hopes that it helps one of you future readers: Wikipedia: Gambler's Fallacy",,['probability']
84,"If $m$ tickets are drawn out of $n$ tickets numbered $1$ to $n$, find variance of the sum of the numbers on tickets","If  tickets are drawn out of  tickets numbered  to , find variance of the sum of the numbers on tickets",m n 1 n,"$m$ tickets are drawn out of $n$ tickets which are numbered from $1$ to $n$ . If $X$ denote the sum of the numbers on the tickets drawn. Find $V(X)$ . $X = X_1+X_2+\cdots+X_m$ , if $X_i$ can be treated as the $i$ th number drawn. Otherwise, $X_i$ can be treated as the indicator variable of the number $i=1,2,...,n$ . In either way, I am able to get expectation since dependence of variables does not matter. However, while calculating Variance, dependence does matter. While calculating $E(X_iX_j)$ the second draw is supposed to be dependent on the first draw since there is a constraint of the sum $X$ . Please answer.","tickets are drawn out of tickets which are numbered from to . If denote the sum of the numbers on the tickets drawn. Find . , if can be treated as the th number drawn. Otherwise, can be treated as the indicator variable of the number . In either way, I am able to get expectation since dependence of variables does not matter. However, while calculating Variance, dependence does matter. While calculating the second draw is supposed to be dependent on the first draw since there is a constraint of the sum . Please answer.","m n 1 n X V(X) X = X_1+X_2+\cdots+X_m X_i i X_i i=1,2,...,n E(X_iX_j) X","['probability', 'expected-value', 'variance']"
85,Covariance between an exponential random variable and the maximum of several exponential random variables,Covariance between an exponential random variable and the maximum of several exponential random variables,,"Suppose $X_1, \ldots, X_n$ are i.i.d. exponential RV with parameter $\lambda$. Let $Z = \max\{X_1, \ldots, X_6\}$. My goal is to find $\mathrm{cov}(X_1, Z)$. I already know the c.d.f., p.d.f., and expectations of each $X_i$ and $Z$, I think I even found the joint p.d.f. of $Z$ and $X_1$ as: $$f_{Z,\ X_1}(z,x_1) =  \begin{cases} 5\lambda^2 e^{-\lambda x_1}(1-e^{-\lambda z})^4 & z \geq x_1 \geq 0 \\ 0 & \mathrm{otherwise} \end{cases}. $$ (This joint distribution is not correct, see below). I found this by using $f_{Z,\ X_1} = f_{X_1} \ f_{Z|X_1}$ . But now I am sort of stuck because the integral  $$E[X_1 Z] = \int\int_{R^2} x_1 z \ f_{Z,\ X_1} \ \mathrm{d}A$$ needed for $\mathrm{cov}(X_1,Z)$ gets cumbersome (and on my first attempt did not converge). Is there some slick thing to notice or do that I am missing? Note I am not yet confident with generating functions and moments.","Suppose $X_1, \ldots, X_n$ are i.i.d. exponential RV with parameter $\lambda$. Let $Z = \max\{X_1, \ldots, X_6\}$. My goal is to find $\mathrm{cov}(X_1, Z)$. I already know the c.d.f., p.d.f., and expectations of each $X_i$ and $Z$, I think I even found the joint p.d.f. of $Z$ and $X_1$ as: $$f_{Z,\ X_1}(z,x_1) =  \begin{cases} 5\lambda^2 e^{-\lambda x_1}(1-e^{-\lambda z})^4 & z \geq x_1 \geq 0 \\ 0 & \mathrm{otherwise} \end{cases}. $$ (This joint distribution is not correct, see below). I found this by using $f_{Z,\ X_1} = f_{X_1} \ f_{Z|X_1}$ . But now I am sort of stuck because the integral  $$E[X_1 Z] = \int\int_{R^2} x_1 z \ f_{Z,\ X_1} \ \mathrm{d}A$$ needed for $\mathrm{cov}(X_1,Z)$ gets cumbersome (and on my first attempt did not converge). Is there some slick thing to notice or do that I am missing? Note I am not yet confident with generating functions and moments.",,"['probability', 'exponential-distribution']"
86,Rolling three dice - why is my reasoning wrong?,Rolling three dice - why is my reasoning wrong?,,"The problem I'm trying to solve goes like this: Suppose that you play a game by rolling three dice, and your score is the highest number that appears on any of the dice. Suppose your opponent's score is $4$. What is your probability of winning the game? The solution to the problem goes like this: the required probability is easier to compute as $1$ minus the probability that our score is $\leq 4$, which works out to be $1 - (\frac{2}{3})^3$. Now, when I worked out this problem, my reasoning was like this: We only need to work out the probability that one of the die returns a $5$ or $6$, and then the rest of the two can be anything. So, if I fix one of the dice as $5$, the total outcomes for this case are $6^2$ (because anything can appear on the other two dice), and the same goes for the case when I fix one of the dice as $6$. By my reasoning, the answer is $\frac{2 \times 6^2}{6^3} = \frac{1}{3}$. I have two questions here: Why is my reasoning wrong? Why does the solution say it's easier to compute it the other way?","The problem I'm trying to solve goes like this: Suppose that you play a game by rolling three dice, and your score is the highest number that appears on any of the dice. Suppose your opponent's score is $4$. What is your probability of winning the game? The solution to the problem goes like this: the required probability is easier to compute as $1$ minus the probability that our score is $\leq 4$, which works out to be $1 - (\frac{2}{3})^3$. Now, when I worked out this problem, my reasoning was like this: We only need to work out the probability that one of the die returns a $5$ or $6$, and then the rest of the two can be anything. So, if I fix one of the dice as $5$, the total outcomes for this case are $6^2$ (because anything can appear on the other two dice), and the same goes for the case when I fix one of the dice as $6$. By my reasoning, the answer is $\frac{2 \times 6^2}{6^3} = \frac{1}{3}$. I have two questions here: Why is my reasoning wrong? Why does the solution say it's easier to compute it the other way?",,"['probability', 'combinatorics']"
87,Stumped on basic statistics question.,Stumped on basic statistics question.,,"The question: Alfonso and Colin each bought one raffle ticket at the state fair. If $50$ tickets were randomly sold, what is the probability that Alfonso got ticket $14$ and Colin got ticket $23$? According to this , the answer should be $ \frac{1}{2450}$ which presumably comes from $\frac{1}{50}\times \frac{1}{49}$. But it seems that the order does not count. I did not assume that Alfonso got ticket $14$ first then Colin got ticket $23$ second. Update: What is wrong with this reasoning. When I said that I did not assume order, I meant that it's possible Alfonso got ticket $14$ first, then  Colin got ticket $23$, Colin got ticket $23$ first, then Alfonso got ticket $14$. Both of these possibilities are possible before the tickets are given out, so we can make an 'or' statement. Label the event Alfonso got ticket $14$ by $A_{14} $ and Colin got ticket $23$ by $A_{23}$. Then by the addition rule $ \Pr(\text{ ($A_{14}$ first and $C_{23}$ second)  or  ($C_{23}$ first and $A_{14}$ second}) )  \\ = \Pr(A_{14}) \times \Pr(C_{23} \mid A_{14}) + \Pr(C_{23}) \times \Pr(A_{14}\mid C_{23}) = \frac 1 {50} \times \frac 1 {49} \times 2.$ I realize that once the tickets are sold, then only one of $ \{ A_{14}C_{23}~ , ~ C_{23}A_{14} \}$ must occur, but before the tickets are sold both possibilities are plausible. Why would the probability change before and after the tickets are sold.","The question: Alfonso and Colin each bought one raffle ticket at the state fair. If $50$ tickets were randomly sold, what is the probability that Alfonso got ticket $14$ and Colin got ticket $23$? According to this , the answer should be $ \frac{1}{2450}$ which presumably comes from $\frac{1}{50}\times \frac{1}{49}$. But it seems that the order does not count. I did not assume that Alfonso got ticket $14$ first then Colin got ticket $23$ second. Update: What is wrong with this reasoning. When I said that I did not assume order, I meant that it's possible Alfonso got ticket $14$ first, then  Colin got ticket $23$, Colin got ticket $23$ first, then Alfonso got ticket $14$. Both of these possibilities are possible before the tickets are given out, so we can make an 'or' statement. Label the event Alfonso got ticket $14$ by $A_{14} $ and Colin got ticket $23$ by $A_{23}$. Then by the addition rule $ \Pr(\text{ ($A_{14}$ first and $C_{23}$ second)  or  ($C_{23}$ first and $A_{14}$ second}) )  \\ = \Pr(A_{14}) \times \Pr(C_{23} \mid A_{14}) + \Pr(C_{23}) \times \Pr(A_{14}\mid C_{23}) = \frac 1 {50} \times \frac 1 {49} \times 2.$ I realize that once the tickets are sold, then only one of $ \{ A_{14}C_{23}~ , ~ C_{23}A_{14} \}$ must occur, but before the tickets are sold both possibilities are plausible. Why would the probability change before and after the tickets are sold.",,"['probability', 'combinatorics']"
88,Variance of X vs Variance of a binary function of X,Variance of X vs Variance of a binary function of X,,"Let $X$ be a random variable in $[0, 1]$ and $m$ its median such that $P(X \le m) = P(X \ge m)$. Define $\beta(X)$ as $$\beta (x) =  \left\{  \begin{array}{c} \begin{align*} 1&,\space X \ge m; \\  0&,\space otherwise. \end{align*} \end{array} \right.  $$ (a) Is it true that $Var(X) \le Var(\beta(X))$? (b) What if $X$ is continuous? Where I got stuck: If $X$ is a discrete random variable, $\beta(X)$ is just Bernoulli with $p = 0.5$ and $Var(\beta(X)) = 0.25$. I couldn't come up with any discrete X whose variance is bigger than that. Tried simple Bernoulli; $X = 0.5^{i-1}$ with $p(x_{i})=0.5^i$. All variances are smaller than or equal to 0.25. However, I couldn't come up with a formal proof either. Reasoning for (b) will depend on the proof/counterexample with (a) I guess. Please help! P.S. First time poster hear. Apologies if something's wrong with my post","Let $X$ be a random variable in $[0, 1]$ and $m$ its median such that $P(X \le m) = P(X \ge m)$. Define $\beta(X)$ as $$\beta (x) =  \left\{  \begin{array}{c} \begin{align*} 1&,\space X \ge m; \\  0&,\space otherwise. \end{align*} \end{array} \right.  $$ (a) Is it true that $Var(X) \le Var(\beta(X))$? (b) What if $X$ is continuous? Where I got stuck: If $X$ is a discrete random variable, $\beta(X)$ is just Bernoulli with $p = 0.5$ and $Var(\beta(X)) = 0.25$. I couldn't come up with any discrete X whose variance is bigger than that. Tried simple Bernoulli; $X = 0.5^{i-1}$ with $p(x_{i})=0.5^i$. All variances are smaller than or equal to 0.25. However, I couldn't come up with a formal proof either. Reasoning for (b) will depend on the proof/counterexample with (a) I guess. Please help! P.S. First time poster hear. Apologies if something's wrong with my post",,"['probability', 'probability-distributions', 'random-variables', 'variance']"
89,Probability of exactly three of a kind in a roll of 5 dice,Probability of exactly three of a kind in a roll of 5 dice,,"The answer according to edx course HarvardX: FC1x Fat Chance: Probability from the Ground Up is $$\frac{6*5*5* \left(^5_2\right)}{6^5} =\frac{1500}{6^5}$$ The remaining two dice can be same say this is valid favourable outcome 4,4,4,5,5. But according to my reasoning the probability is much more than that, My reasoning: 6 options for 3 of a kind 5 options for 4th dice 4 options for 5th dice(let us consider only the cases where 4th and 5th dice are different, for sake of showing that even with excluding certain favourable outcomes, namely in which 4th and 5th dice are same, my probability is higher than the course answer.) therefore total number of ways $$ \frac{ 6*5*4*5!}{3!} = 2400$$ 5! ways of arranging 5 items, divided by 3!, since 3 are of a kind. $$ p=\frac{2400}{6^5} $$ Which is greater than the probability calculated by the edx course, and I have not even considered the case when we allow 4th and 5th dice to have same number. what is wrong with my reasoning?","The answer according to edx course HarvardX: FC1x Fat Chance: Probability from the Ground Up is $$\frac{6*5*5* \left(^5_2\right)}{6^5} =\frac{1500}{6^5}$$ The remaining two dice can be same say this is valid favourable outcome 4,4,4,5,5. But according to my reasoning the probability is much more than that, My reasoning: 6 options for 3 of a kind 5 options for 4th dice 4 options for 5th dice(let us consider only the cases where 4th and 5th dice are different, for sake of showing that even with excluding certain favourable outcomes, namely in which 4th and 5th dice are same, my probability is higher than the course answer.) therefore total number of ways $$ \frac{ 6*5*4*5!}{3!} = 2400$$ 5! ways of arranging 5 items, divided by 3!, since 3 are of a kind. $$ p=\frac{2400}{6^5} $$ Which is greater than the probability calculated by the edx course, and I have not even considered the case when we allow 4th and 5th dice to have same number. what is wrong with my reasoning?",,"['probability', 'dice']"
90,"Distribution of $X+\frac{2}{X}$ when $X\sim\mathcal U(1,2)$",Distribution of  when,"X+\frac{2}{X} X\sim\mathcal U(1,2)","I have the following question: If $X$ is a continuous random variable that is uniformly distributed on the interval $(1,2)$ what is the distribution function of $Y=X+\frac{2}{X}?$\ I have tried to calculate the inverse of the function $f(x)=x+\frac{2}{x}$ but didn't manage to complete the calculation. Any ideas?","I have the following question: If $X$ is a continuous random variable that is uniformly distributed on the interval $(1,2)$ what is the distribution function of $Y=X+\frac{2}{X}?$\ I have tried to calculate the inverse of the function $f(x)=x+\frac{2}{x}$ but didn't manage to complete the calculation. Any ideas?",,"['probability', 'probability-distributions']"
91,Distribution of infinite sum of Bernoulli,Distribution of infinite sum of Bernoulli,,"Let $(X_n)$ be a sequence of independent Bernoulli random variables of parameter $1/2.$ Let $Y_n=\sum_{k=1}^n\frac{X_k}{2^k}.$ We have $Y_n\overset{n\to\infty}\to\sum_{k=1}^{+\infty}\frac{X_k}{2^k},$ I would like to compute the distribution and to prove that $\vert F_n(x)-x\vert\le 1/2^n$ for all $x\in [0,1].$ We have $P_{Y_n}=\sum_{x\in Y_n(\Omega)}P(Y_n=x)\delta_x.$ If I am not mistaken we have $Y_n(\Omega):=\{\frac{k}{2^n}: k=0,1,\ldots,2^{n-1}\}.$ Now I just have to compute $P(Y_n=\frac{k}{2^n});$ if I write $Y_n=0.X_1X_2\ldots X_n$ I imagine we have $P(Y_n=\frac{k}{2^n})=P(X_1=a_1)P(X_2=a_2)\cdots P(X_n=a_n)=\frac{1}{2^n}.$ Therefore, $$P_{Y_n}=\frac{1}{2^n}\sum_{k=1}^{2^n-1}\delta_{k/2^n}.$$ I have no idea to prove that $\vert F_n(x)-x\vert\le 1/2^n,$ I tried wrting $x=\sum_k a_k/2^k$ but... Question: How can I prove formally that $$P(Y_n=\frac{k}{2^n})=\frac{1}{2^n}\; \mbox{and}\; \vert F_n(x)-x\vert\le 1/2^n ?$$","Let $(X_n)$ be a sequence of independent Bernoulli random variables of parameter $1/2.$ Let $Y_n=\sum_{k=1}^n\frac{X_k}{2^k}.$ We have $Y_n\overset{n\to\infty}\to\sum_{k=1}^{+\infty}\frac{X_k}{2^k},$ I would like to compute the distribution and to prove that $\vert F_n(x)-x\vert\le 1/2^n$ for all $x\in [0,1].$ We have $P_{Y_n}=\sum_{x\in Y_n(\Omega)}P(Y_n=x)\delta_x.$ If I am not mistaken we have $Y_n(\Omega):=\{\frac{k}{2^n}: k=0,1,\ldots,2^{n-1}\}.$ Now I just have to compute $P(Y_n=\frac{k}{2^n});$ if I write $Y_n=0.X_1X_2\ldots X_n$ I imagine we have $P(Y_n=\frac{k}{2^n})=P(X_1=a_1)P(X_2=a_2)\cdots P(X_n=a_n)=\frac{1}{2^n}.$ Therefore, $$P_{Y_n}=\frac{1}{2^n}\sum_{k=1}^{2^n-1}\delta_{k/2^n}.$$ I have no idea to prove that $\vert F_n(x)-x\vert\le 1/2^n,$ I tried wrting $x=\sum_k a_k/2^k$ but... Question: How can I prove formally that $$P(Y_n=\frac{k}{2^n})=\frac{1}{2^n}\; \mbox{and}\; \vert F_n(x)-x\vert\le 1/2^n ?$$",,['probability']
92,Expected Value of Normal Random Variable times its CDF,Expected Value of Normal Random Variable times its CDF,,"As usual, let $\Phi$ and $\varphi$ denote the cumulative density function and the density function of a standard normal random variable. On the wiki page "" List of integrals of Gaussian functions "", I have found an expected value integral involving  a standard normal r.v. and its cdf, $$I=\int_{-\infty}^{\infty}x\varphi(x)\Phi(a+bx)dx=\frac{b}{\sqrt{1+b^2}}\varphi\left(\frac{a}{\sqrt{1+b^2}}\right),$$ for which I do not know how to do the last step in my solution: My ansatz is to introduce a parameter integral, $I:=I(a)$, and finding its derivative: $$ \begin{align*} \frac{\partial I}{\partial a}&=\int_{-\infty}^{\infty}x\varphi(x)\varphi(a+bx)dx\\ &=\int_{-\infty}^{\infty}x\frac{e^{-\frac{1}{2}\left(x^2(1+b^2)+2abx+a^2\right)}}{2\pi}dx\\ &=a\frac{e^{-\frac{1}{2}\frac{a^2}{1+b^2}}}{\sqrt{1+b^2}\sqrt{2\pi}}\\ &=a\frac{\varphi\left(\frac{a}{\sqrt{1+b^2}}\right)}{\sqrt{1+b^2}} \end{align*} $$ Integrating the derivative, we obtain: $$ \begin{align} I&=\int \frac{\partial I}{\partial a}da + C\\ &=\frac{b}{\sqrt{1+b^2}}\varphi\left(\frac{a}{\sqrt{1+b^2}}\right)+C, \end{align} $$ which equals the solution on the wiki page plus a constant term $C$. From here on, I do not know how to get rid of the integration constant, i.e. how to show that $C=0$. I do know that for $b=0$ it holds that $I=0$. Is this be sufficient to pin down $C$ to zero? Or do I miss something completely?","As usual, let $\Phi$ and $\varphi$ denote the cumulative density function and the density function of a standard normal random variable. On the wiki page "" List of integrals of Gaussian functions "", I have found an expected value integral involving  a standard normal r.v. and its cdf, $$I=\int_{-\infty}^{\infty}x\varphi(x)\Phi(a+bx)dx=\frac{b}{\sqrt{1+b^2}}\varphi\left(\frac{a}{\sqrt{1+b^2}}\right),$$ for which I do not know how to do the last step in my solution: My ansatz is to introduce a parameter integral, $I:=I(a)$, and finding its derivative: $$ \begin{align*} \frac{\partial I}{\partial a}&=\int_{-\infty}^{\infty}x\varphi(x)\varphi(a+bx)dx\\ &=\int_{-\infty}^{\infty}x\frac{e^{-\frac{1}{2}\left(x^2(1+b^2)+2abx+a^2\right)}}{2\pi}dx\\ &=a\frac{e^{-\frac{1}{2}\frac{a^2}{1+b^2}}}{\sqrt{1+b^2}\sqrt{2\pi}}\\ &=a\frac{\varphi\left(\frac{a}{\sqrt{1+b^2}}\right)}{\sqrt{1+b^2}} \end{align*} $$ Integrating the derivative, we obtain: $$ \begin{align} I&=\int \frac{\partial I}{\partial a}da + C\\ &=\frac{b}{\sqrt{1+b^2}}\varphi\left(\frac{a}{\sqrt{1+b^2}}\right)+C, \end{align} $$ which equals the solution on the wiki page plus a constant term $C$. From here on, I do not know how to get rid of the integration constant, i.e. how to show that $C=0$. I do know that for $b=0$ it holds that $I=0$. Is this be sufficient to pin down $C$ to zero? Or do I miss something completely?",,"['probability', 'integration', 'probability-distributions', 'expectation']"
93,Two urns drawing out a single ball,Two urns drawing out a single ball,,"I have two urns, one with $2$ red, $3$ green, and $2$ blue balls and the other with $3$ red, $4$ green, and $3$ blue balls. If I pick an random urn and draw one ball, and that ball is blue, what is the probability it came from the first urn? So far, I have: $P(U1|B)=(P(B|U1)*P(U1))/P(B)$ Plugging in values, I use $(2/7*1/2)/5/17$ For that, I get $17/70$. If consider the numerator $P(U1,B)$ instead, I seem to come up with $2/5$ instead. What am I doing wrong?","I have two urns, one with $2$ red, $3$ green, and $2$ blue balls and the other with $3$ red, $4$ green, and $3$ blue balls. If I pick an random urn and draw one ball, and that ball is blue, what is the probability it came from the first urn? So far, I have: $P(U1|B)=(P(B|U1)*P(U1))/P(B)$ Plugging in values, I use $(2/7*1/2)/5/17$ For that, I get $17/70$. If consider the numerator $P(U1,B)$ instead, I seem to come up with $2/5$ instead. What am I doing wrong?",,"['probability', 'bayes-theorem']"
94,Probability of choosing value of variable in equation - 4 tuple ($x_1 +x_2+x_3+x_4=10$),Probability of choosing value of variable in equation - 4 tuple (),x_1 +x_2+x_3+x_4=10,"It may be the wording in this problem that is throwing me off but I can't seem to figure out the number of possible successful outcomes to calculate the probabiliy: Suppose a non-negative integer solution to the equation $w+x+y+z=10$ is chosen at random (each one being equally likely to be chosen). What is the probability that in this particular solution that $w$ is less than or equal to 2? Let $A = w \leq 2 $ To find P(A) I need: \begin{align} P(A)=\frac{|E|}{|S|} \end{align} Where |E| = Successful outcomes and |S| = Size of sample space. I start by finding the sample space of possible solutions, since this is a 4 tuple: ${\{w,x,y,z\}}$ --  order does not matter and repeats are allowed,  I would say the size of sample space is \begin{align} |S| = C(10+4-1,4) =C(13,4) \end{align} So this gives me: \begin{align} P(A)=\frac{|E|}{C(13,4)} \end{align} However, I can't seem to figure out $|E|$ as I don't know how to account for all cases... I am guessing since there are 4 variables: $\{w,x,y,z\}$ and we assume $w$ is aleady chosen from the following: $\{0,1,2\}$ (since $w\leq 2$) this leaves us with 3 variables left to determine. The number of outcomes for this would look like: $$ \begin{array}{c|lcr} case & \text{Number of outcomes} \\ \hline 0+x+y+z= 10  & C(10+3-1,3) = C(12,3) \\ 1+x+y+z= 10  & C(10+3-1,3) = C(12,3)\\ 2+x+y+z= 10  & C(10+3-1,3) = C(12,3)  \end{array} $$ This feels wrong.. or maybe I am overthinking it. But would the solution be: \begin{align} P(A)=\frac{3 \cdot C(12,3)}{C(13,4)} \end{align}","It may be the wording in this problem that is throwing me off but I can't seem to figure out the number of possible successful outcomes to calculate the probabiliy: Suppose a non-negative integer solution to the equation $w+x+y+z=10$ is chosen at random (each one being equally likely to be chosen). What is the probability that in this particular solution that $w$ is less than or equal to 2? Let $A = w \leq 2 $ To find P(A) I need: \begin{align} P(A)=\frac{|E|}{|S|} \end{align} Where |E| = Successful outcomes and |S| = Size of sample space. I start by finding the sample space of possible solutions, since this is a 4 tuple: ${\{w,x,y,z\}}$ --  order does not matter and repeats are allowed,  I would say the size of sample space is \begin{align} |S| = C(10+4-1,4) =C(13,4) \end{align} So this gives me: \begin{align} P(A)=\frac{|E|}{C(13,4)} \end{align} However, I can't seem to figure out $|E|$ as I don't know how to account for all cases... I am guessing since there are 4 variables: $\{w,x,y,z\}$ and we assume $w$ is aleady chosen from the following: $\{0,1,2\}$ (since $w\leq 2$) this leaves us with 3 variables left to determine. The number of outcomes for this would look like: $$ \begin{array}{c|lcr} case & \text{Number of outcomes} \\ \hline 0+x+y+z= 10  & C(10+3-1,3) = C(12,3) \\ 1+x+y+z= 10  & C(10+3-1,3) = C(12,3)\\ 2+x+y+z= 10  & C(10+3-1,3) = C(12,3)  \end{array} $$ This feels wrong.. or maybe I am overthinking it. But would the solution be: \begin{align} P(A)=\frac{3 \cdot C(12,3)}{C(13,4)} \end{align}",,"['probability', 'combinatorics', 'discrete-mathematics']"
95,Need a hint for an expected value problem,Need a hint for an expected value problem,,"You are allowed to write positive integers from 1 to 100 on 100 cards, you the show the 100 cards to a friend who will pick a number. You then shuffle the deck and flip off the top card. If the top card was the number your friend selected you pay him that number. Assuming your friend picks the number to maximize his expected value what numbers do you place on each of the 100 cards to minimize his expected value My strategy was to start from the highest number we can place in the deck and go down. For example we can't place a hundred in the deck because this would give an expected value of 1 if the friend picked 100, but this isn't giving me much progress. Any suggestions are appreciated","You are allowed to write positive integers from 1 to 100 on 100 cards, you the show the 100 cards to a friend who will pick a number. You then shuffle the deck and flip off the top card. If the top card was the number your friend selected you pay him that number. Assuming your friend picks the number to maximize his expected value what numbers do you place on each of the 100 cards to minimize his expected value My strategy was to start from the highest number we can place in the deck and go down. For example we can't place a hundred in the deck because this would give an expected value of 1 if the friend picked 100, but this isn't giving me much progress. Any suggestions are appreciated",,"['probability', 'expectation']"
96,Expected value of sum of a random number of i.i.d. random variables,Expected value of sum of a random number of i.i.d. random variables,,"The question: $X_1$, $X_2$, etc. are independent and identically distributed non-negative integer valued random variables. $N$ is a non-negative integer valued random variable which is independent of $X_1$, $X_2$ etc.., and $Y$ = $X_1 + X_2 + X_3 + … + X_N$ . (We take $Y = 0$ if $N = 0$). Prove that $\mathbb{E}[Y] = \mathbb{E}[X_1]\mathbb{E}[N]$. My attempt: I know that the probability generating $G_Y(s)$ of $Y$ is equal to $G_N(G_X(s))$... but I'm not sure how that's helpful here. My intuition leads me in this direction: $\mathbb{E}[Y] = \sum\limits_{n=0}^{\infty} \mathbb{E}[Y|N=n]\mathbb{P}(N=n)$ $= \sum\limits_{n=0}^{\infty} \mathbb{E}[nX_1|N = n]\mathbb{P}(N=n)$ $= \sum\limits_{n=0}^{\infty} n \mathbb{E}[X_1|N = n]\mathbb{P}(N=n)$ (is this step valid??) But I don't know where to go from here.","The question: $X_1$, $X_2$, etc. are independent and identically distributed non-negative integer valued random variables. $N$ is a non-negative integer valued random variable which is independent of $X_1$, $X_2$ etc.., and $Y$ = $X_1 + X_2 + X_3 + … + X_N$ . (We take $Y = 0$ if $N = 0$). Prove that $\mathbb{E}[Y] = \mathbb{E}[X_1]\mathbb{E}[N]$. My attempt: I know that the probability generating $G_Y(s)$ of $Y$ is equal to $G_N(G_X(s))$... but I'm not sure how that's helpful here. My intuition leads me in this direction: $\mathbb{E}[Y] = \sum\limits_{n=0}^{\infty} \mathbb{E}[Y|N=n]\mathbb{P}(N=n)$ $= \sum\limits_{n=0}^{\infty} \mathbb{E}[nX_1|N = n]\mathbb{P}(N=n)$ $= \sum\limits_{n=0}^{\infty} n \mathbb{E}[X_1|N = n]\mathbb{P}(N=n)$ (is this step valid??) But I don't know where to go from here.",,"['probability', 'random-variables']"
97,Random splitting of a the unit square,Random splitting of a the unit square,,"Consider the unit square $S=[0,1]^2$. Let us choose randomly a point $(x,y)$ in $S$ (uniformly over $S$) and consider the four triangles whose two vertices are a pair of consecutive vertices of $S$ and the third one is $(x,y)$. What is the expected area of the largest triangle?","Consider the unit square $S=[0,1]^2$. Let us choose randomly a point $(x,y)$ in $S$ (uniformly over $S$) and consider the four triangles whose two vertices are a pair of consecutive vertices of $S$ and the third one is $(x,y)$. What is the expected area of the largest triangle?",,"['probability', 'geometric-probability']"
98,How to check if its finite,How to check if its finite,,"For $X \sim Pois(\lambda)$, find $E(2^X)$ if it is finite. I know how to solve this (we use Law of Unconscious Statistician) but am doubtful as to how we specify the condition for which it is finite. Can someone tell me how we find the condition?","For $X \sim Pois(\lambda)$, find $E(2^X)$ if it is finite. I know how to solve this (we use Law of Unconscious Statistician) but am doubtful as to how we specify the condition for which it is finite. Can someone tell me how we find the condition?",,['probability']
99,Probability of winning tic tac toe game.,Probability of winning tic tac toe game.,,"You and your friend like to play tic tac toe, but are not very good at it. On each turn, the player picks a random empty square to place their mark. The game ends when the first person gets three in a row, as usual. If you make the first move, what is the probability that you win the game?  If you make the first move, what is the probability that you win the game? If the answer can be expressed as $\frac{a}{b}$, a and b are coprime, find a+b. My attempt: No of probable ways of arranging tic tac toe symbols so as to win the game =3horizontal ways+3 vertical ways+2 criss-cross ways=8 The total number of ways in which 3 spaces can be filled out of 9 spaces=9C3. Therefore, Total number of outcomes=The total number of ways in which 3 spaces can be filled out of 9 spaces (and) One extra space where either of the two tic tac toe symbols can be filled up=9C3*2 Probability=8/(2*(9C3))=1/21","You and your friend like to play tic tac toe, but are not very good at it. On each turn, the player picks a random empty square to place their mark. The game ends when the first person gets three in a row, as usual. If you make the first move, what is the probability that you win the game?  If you make the first move, what is the probability that you win the game? If the answer can be expressed as $\frac{a}{b}$, a and b are coprime, find a+b. My attempt: No of probable ways of arranging tic tac toe symbols so as to win the game =3horizontal ways+3 vertical ways+2 criss-cross ways=8 The total number of ways in which 3 spaces can be filled out of 9 spaces=9C3. Therefore, Total number of outcomes=The total number of ways in which 3 spaces can be filled out of 9 spaces (and) One extra space where either of the two tic tac toe symbols can be filled up=9C3*2 Probability=8/(2*(9C3))=1/21",,['probability']
