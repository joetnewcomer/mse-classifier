,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"If $A$ is invertible and $r^{\text{Gelf}}(BA^{-1}) < 1$, then $(A - B)$ is invertible.","If  is invertible and , then  is invertible.",A r^{\text{Gelf}}(BA^{-1}) < 1 (A - B),"Let $\mathcal{A}$ be a unital Banach algebra and define $r^{\text{Gelf}}(A) = \lim_{n \rightarrow +\infty} \| A^n \|^{1/n}$ . It is possible to show that $r^{\text{Gelf}}(A) = \lim_{n \rightarrow +\infty} \| A^n \|^{1/n} = \inf_{n \rightarrow +\infty} \| A^n \|^{1/n}$ . I need to show that if $A$ is invertible and $B$ is such that $r^{\text{Gelf}}(BA^{-1}) < 1$ , then $(A - B)$ is invertible. What I did is the following: consider the element $C = A^{-1} + A^{-1}\sum_{n=1}^{+\infty}(BA^{-1})^n$ . This is known as the Neumann series. If this series converges, it follows from a direct computation that $(A - B)^{-1} = C$ , but I am struggling to show that this series in fact converges. I tried to show if $r^{\text{Gelf}}(BA^{-1}) < 1$ , then $\| BA^{-1} \| < 1$ , but I did not succeed (and maybe this isn't even true). I would appreciate very much if someone could help me!","Let be a unital Banach algebra and define . It is possible to show that . I need to show that if is invertible and is such that , then is invertible. What I did is the following: consider the element . This is known as the Neumann series. If this series converges, it follows from a direct computation that , but I am struggling to show that this series in fact converges. I tried to show if , then , but I did not succeed (and maybe this isn't even true). I would appreciate very much if someone could help me!",\mathcal{A} r^{\text{Gelf}}(A) = \lim_{n \rightarrow +\infty} \| A^n \|^{1/n} r^{\text{Gelf}}(A) = \lim_{n \rightarrow +\infty} \| A^n \|^{1/n} = \inf_{n \rightarrow +\infty} \| A^n \|^{1/n} A B r^{\text{Gelf}}(BA^{-1}) < 1 (A - B) C = A^{-1} + A^{-1}\sum_{n=1}^{+\infty}(BA^{-1})^n (A - B)^{-1} = C r^{\text{Gelf}}(BA^{-1}) < 1 \| BA^{-1} \| < 1,"['functional-analysis', 'banach-algebras']"
1,An example of the Pseudo-inverse of an operator,An example of the Pseudo-inverse of an operator,,"Let $E$ an infinite dimensional complex Hilbert space and $\mathcal{L}(E)$ be the algebra of all bounded linear operators on $E$ . Definition: Let $T \in \mathcal{L}(E)$ . The Moore-Penrose inverse of $T$ , denoted by $T^{+}$ , is defined as the unique linear extension of $(\overline{T})^{-1}$ in $$D(T^{+}) = \mathcal{R}(T)+\mathcal{R}(T)^{\perp},$$ with $\mathcal{N}(T^{+}) = \mathcal{R}(T)^{\perp}$ and $\overline{T}$ is the isomorphism $$\overline{T}:=T|_{{\mathcal{N}(T)}^{\perp}}: {\mathcal{N}(T)}^{\perp} \longrightarrow \mathcal{R}(T).$$ Moreover, $T^{+}$ is the unique solution of the four ''Moore-Penrose equations'': $$TXT = T,\quad XTX = X,\quad XT = P_{N{(T)^{\bot}}}\,\,\mbox{and}\,\,\quad TX = P_{\overline{\mathcal{R}(T)}}{{|}_{D(T^{+})}}.$$ Here $\mathcal{R}(T)$ and $\mathcal{N}(T)$ denote respectively the range and the nullspace of $T$ . Also $P_{F}$ denote the orthogonal projection onto $F$ . I want to see with an example how we compute $T^{+}$ when $T$ is a non invertible operator acting on an infinite dimensional complex Hilbert space $E$ .","Let an infinite dimensional complex Hilbert space and be the algebra of all bounded linear operators on . Definition: Let . The Moore-Penrose inverse of , denoted by , is defined as the unique linear extension of in with and is the isomorphism Moreover, is the unique solution of the four ''Moore-Penrose equations'': Here and denote respectively the range and the nullspace of . Also denote the orthogonal projection onto . I want to see with an example how we compute when is a non invertible operator acting on an infinite dimensional complex Hilbert space .","E \mathcal{L}(E) E T \in \mathcal{L}(E) T T^{+} (\overline{T})^{-1} D(T^{+}) = \mathcal{R}(T)+\mathcal{R}(T)^{\perp}, \mathcal{N}(T^{+}) = \mathcal{R}(T)^{\perp} \overline{T} \overline{T}:=T|_{{\mathcal{N}(T)}^{\perp}}: {\mathcal{N}(T)}^{\perp} \longrightarrow \mathcal{R}(T). T^{+} TXT = T,\quad XTX = X,\quad XT = P_{N{(T)^{\bot}}}\,\,\mbox{and}\,\,\quad TX = P_{\overline{\mathcal{R}(T)}}{{|}_{D(T^{+})}}. \mathcal{R}(T) \mathcal{N}(T) T P_{F} F T^{+} T E","['functional-analysis', 'operator-theory', 'hilbert-spaces', 'pseudoinverse']"
2,Are distributions all continuous?,Are distributions all continuous?,,"By a distribution, I mean it is a linear functional of the space of smooth compactly supported functions over $\mathbb R^n$ , i.e. $C_c^{\infty}(\mathbb R^n).$ I am reading a textbook by Strichartz, named A Guild to Distribution Theory and Fourier Transforms. He wrote that linear functionals all tend to be continuous . As we know, there are plenty of linear functionals which are not continuous. So what he referred to may be distributions. i.e. Distributions all tend to be continuous. He gave a rough explanation which I think is not a proof. His explanation: Let $\varphi$ and $\varphi_1$ be in $C_c^{\infty}(\mathbb R^n),$ and $f$ be a distribution. And let $\varphi_2:=\varphi_1-\varphi$ Then $\varphi_1=\varphi+\varphi_2$ Move $\varphi_1$ closer to $\varphi$ by considering $\varphi+t\,\varphi_2$ and let $t$ get small. Then $\langle f,\varphi+t\,\varphi_2\rangle=\langle f,\varphi\rangle+t\,\langle f,\varphi_2\rangle$ by linearity, and as $t$ gets small this gets close to $\langle f,\varphi\rangle.$ End of explanation. I think, to prove the continuity of $f$ , we need to show $\langle f,\varphi_1\rangle\to\langle f,\varphi\rangle$ when $\varphi_1 \to \varphi.$ While in the explanation, what he proved is that $\langle f,\varphi+t\,\varphi_2\rangle\to\langle f,\varphi\rangle$ when $t\to 0.$ He also wrote that this does not constitute a proof of continuity, since the definition requires more ""uniformly"", but it should indicate that a certain amount of continuity is built into linearity. And, all distribution you will ever encounter will be continuous. So my problem is, are distributions all continuous? Thanks in advance.","By a distribution, I mean it is a linear functional of the space of smooth compactly supported functions over , i.e. I am reading a textbook by Strichartz, named A Guild to Distribution Theory and Fourier Transforms. He wrote that linear functionals all tend to be continuous . As we know, there are plenty of linear functionals which are not continuous. So what he referred to may be distributions. i.e. Distributions all tend to be continuous. He gave a rough explanation which I think is not a proof. His explanation: Let and be in and be a distribution. And let Then Move closer to by considering and let get small. Then by linearity, and as gets small this gets close to End of explanation. I think, to prove the continuity of , we need to show when While in the explanation, what he proved is that when He also wrote that this does not constitute a proof of continuity, since the definition requires more ""uniformly"", but it should indicate that a certain amount of continuity is built into linearity. And, all distribution you will ever encounter will be continuous. So my problem is, are distributions all continuous? Thanks in advance.","\mathbb R^n C_c^{\infty}(\mathbb R^n). \varphi \varphi_1 C_c^{\infty}(\mathbb R^n), f \varphi_2:=\varphi_1-\varphi \varphi_1=\varphi+\varphi_2 \varphi_1 \varphi \varphi+t\,\varphi_2 t \langle f,\varphi+t\,\varphi_2\rangle=\langle f,\varphi\rangle+t\,\langle f,\varphi_2\rangle t \langle f,\varphi\rangle. f \langle f,\varphi_1\rangle\to\langle f,\varphi\rangle \varphi_1 \to \varphi. \langle f,\varphi+t\,\varphi_2\rangle\to\langle f,\varphi\rangle t\to 0.","['functional-analysis', 'continuity', 'distribution-theory']"
3,Boundary Trace in Half Space,Boundary Trace in Half Space,,"Let $\Omega$ denote the upper half-plane in $\mathbb{R}^2$ , i.e. $$ \Omega = \left\{ (x_1,x_2) : x_2 > 0\right\}.  $$ Is it possible to find a function in $H^1_0(\Omega)$ whose boundary trace vanishes in $L^2(\partial \Omega)$ but not pointwise? I saw this question in a set of notes and, honestly, I'm not even sure how to understand the question itself. Functions in $H^1(\Omega)$ are actually equivalence classes of functions equal almost everywhere. So how does one even go about discussing pointwise convergence of the trace? Edit It turns out that one can find a function $u \in H_0^1(\Omega)\cap C(\Omega)$ whose boundary trace vanishes in $L^2(\partial \Omega)$ , with the property that $$ \lim_{\substack{x \to x_0\\ x \in \Omega}} u(x) \neq 0 $$ for at least one point $x_0 \in \partial\Omega$ . Still, I do not see how to construct such a function $u$ .","Let denote the upper half-plane in , i.e. Is it possible to find a function in whose boundary trace vanishes in but not pointwise? I saw this question in a set of notes and, honestly, I'm not even sure how to understand the question itself. Functions in are actually equivalence classes of functions equal almost everywhere. So how does one even go about discussing pointwise convergence of the trace? Edit It turns out that one can find a function whose boundary trace vanishes in , with the property that for at least one point . Still, I do not see how to construct such a function .","\Omega \mathbb{R}^2 
\Omega = \left\{ (x_1,x_2) : x_2 > 0\right\}. 
 H^1_0(\Omega) L^2(\partial \Omega) H^1(\Omega) u \in H_0^1(\Omega)\cap C(\Omega) L^2(\partial \Omega) 
\lim_{\substack{x \to x_0\\ x \in \Omega}} u(x) \neq 0
 x_0 \in \partial\Omega u",['functional-analysis']
4,Questions about uncountable orthonormal bases in Hilbert spaces,Questions about uncountable orthonormal bases in Hilbert spaces,,"I am currently reading the chapter on Hilbert spaces in the book Functional Analysis by Peter D. Lax and I am confused about whether the orthonormal sets being alluded to are uncountable or not. Specifically he states the following theorem Theorem 9. Every Hilbert space contains an orthonormal basis. The proof of this theorem never refers to whether the set obtained via an application of Zorn's lemma is countable or not. He then goes on to state that: Suppose that $H$ is a separable Hilbert space; that is, it contains a denumerable set of points that is dense. In this case every orthogonal basis is denumerable, and the basis elements can be constructed without appealing to transcendental arguments such as Zorn's lemma... so i assume that the theorem is valid for any Hilbert space. But then if $\{x_j\}$ is some orthonormal set in a Hilbert space then is it true, as is claimed in the book, that $\overline{\mathrm{span }\{x_j\}} = S$ where $S$ is the set of points \begin{align*} x = \sum (x,x_j)x_j,\quad \sum |(x,x_j)|^2<\infty. \end{align*} Are we to consider this as a transfinite sum? Could we go about proving this in the following way: Suppose that $\{x_j\}$ is uncountable and let $y\in \overline{\mathrm{span}\{x_j\}}$ then we could find a sequence $\{y_n\}$ together with an increasing sequence of finite index sets $\{F_n\}$ and scalars $\{c_{n,j}\}$ such that $$y_n = \sum_{j\in F_n}c_{n,j}x_j$$ and $\|y_n-y\|\rightarrow 0$ . By Pythagoras $$\|y-y_n\|\geq \|y-\sum_{j\in F_n}(y,x_j)x_j\|$$ and therefore $\sum_{j\in F_n}(y,x_j)x_j\rightarrow y$ as $n\rightarrow \infty$ . By Bessel's inequality we have for finite index sets $F$ $$\sum_{j\in F}|(y,x_j)|^2\leq \|y\|^2$$ and therefore $$\sum |(y,x_j)|^2 = \sup_{F\text{ is finite}}\sum_{j\in F}|(y,(x_j))|^2\leq \|y\|^2$$ which implies that $y\in S$ . But how is the sum $\sum(y,x_j)x_j$ defined? It is transfinite but not positive? As Asaf Karagila stated in the comments the fact that $\sum |(y,x_j)|^2<\infty$ implies that at most countably many $(y,x_j)$ are nonzero. Say that $G$ is a countable set which contains all indices $j$ such that $(y,x_j)\neq 0$ and let $G_n$ be some sequence of finite indices such that $\cup G_n = G$ . We want to show that $$\lim_n \sum_{G_n}(y,x_j)x_j = y.$$ Note that we can choose $G_n$ such that $F_n\setminus G_n$ only contains indices $j$ with the property that $(y,x_j) = 0$ then $$\|y-y_n\|\geq \|y-\sum_{G_n}(y,x_j)x_j\|$$ which proves the result.","I am currently reading the chapter on Hilbert spaces in the book Functional Analysis by Peter D. Lax and I am confused about whether the orthonormal sets being alluded to are uncountable or not. Specifically he states the following theorem Theorem 9. Every Hilbert space contains an orthonormal basis. The proof of this theorem never refers to whether the set obtained via an application of Zorn's lemma is countable or not. He then goes on to state that: Suppose that is a separable Hilbert space; that is, it contains a denumerable set of points that is dense. In this case every orthogonal basis is denumerable, and the basis elements can be constructed without appealing to transcendental arguments such as Zorn's lemma... so i assume that the theorem is valid for any Hilbert space. But then if is some orthonormal set in a Hilbert space then is it true, as is claimed in the book, that where is the set of points Are we to consider this as a transfinite sum? Could we go about proving this in the following way: Suppose that is uncountable and let then we could find a sequence together with an increasing sequence of finite index sets and scalars such that and . By Pythagoras and therefore as . By Bessel's inequality we have for finite index sets and therefore which implies that . But how is the sum defined? It is transfinite but not positive? As Asaf Karagila stated in the comments the fact that implies that at most countably many are nonzero. Say that is a countable set which contains all indices such that and let be some sequence of finite indices such that . We want to show that Note that we can choose such that only contains indices with the property that then which proves the result.","H \{x_j\} \overline{\mathrm{span }\{x_j\}} = S S \begin{align*}
x = \sum (x,x_j)x_j,\quad \sum |(x,x_j)|^2<\infty.
\end{align*} \{x_j\} y\in \overline{\mathrm{span}\{x_j\}} \{y_n\} \{F_n\} \{c_{n,j}\} y_n = \sum_{j\in F_n}c_{n,j}x_j \|y_n-y\|\rightarrow 0 \|y-y_n\|\geq \|y-\sum_{j\in F_n}(y,x_j)x_j\| \sum_{j\in F_n}(y,x_j)x_j\rightarrow y n\rightarrow \infty F \sum_{j\in F}|(y,x_j)|^2\leq \|y\|^2 \sum |(y,x_j)|^2 = \sup_{F\text{ is finite}}\sum_{j\in F}|(y,(x_j))|^2\leq \|y\|^2 y\in S \sum(y,x_j)x_j \sum |(y,x_j)|^2<\infty (y,x_j) G j (y,x_j)\neq 0 G_n \cup G_n = G \lim_n \sum_{G_n}(y,x_j)x_j = y. G_n F_n\setminus G_n j (y,x_j) = 0 \|y-y_n\|\geq \|y-\sum_{G_n}(y,x_j)x_j\|","['functional-analysis', 'hilbert-spaces']"
5,Extending the Fourier transform on $L^1(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$,Extending the Fourier transform on  to,L^1(\mathbb{R}^n) L^2(\mathbb{R}^n),"We define the Fourier transform of $f \in L^1(\mathbb{R}^n)$ with the usual formula $\int e^{-i k \cdot x} f(x) dx$. This does not work for the functions in $L^2(\mathbb{R}^n)$. The defining integral may not converge. However, we can extend Fourier transform to $L^2(\mathbb{R}^n)$ by its continuity. First show that Fourier transform on Schwartz functions $S \subset L^2(\mathbb{R}^2)$ is an isometry with respect to the $L^2$ norm. Then, by the continuity (isometries are continuous) of the Fourier transform on $S$ and the densinty of $S$ in $L^2(\mathbb{R}^n)$, we can extend Fourier transform to the whole $L^2(\mathbb{R}^n)$ as an isometry. $L^2(\mathbb{R^n})$ is complete so the extension is unique and surjective. Therefore it is unitary, not merely an isometry. Thus the Fourier transform of an $L^2(\mathbb{R^n})$ function is also an $L^2(\mathbb{R^n})$ function and it preserves the inner product. The above is a rather long quote from the material in a class I attend. I don't have strong background on analysis but am struggling to understand the above argument. I think I can understand most part except the uniqueness and surjectivity. Why the completeness ensures the uniqueness and surjectivity? I have read some textbooks on the same subject and found that the bijectivity is usually proved by the extension of the inversion formula on $S$ to $L^2$, which I can understand. For the uniqueness, I couldn't find any argument in my textbooks. Does the completeness of $L^2$ really ensure the uniqueness and surjectivity?","We define the Fourier transform of $f \in L^1(\mathbb{R}^n)$ with the usual formula $\int e^{-i k \cdot x} f(x) dx$. This does not work for the functions in $L^2(\mathbb{R}^n)$. The defining integral may not converge. However, we can extend Fourier transform to $L^2(\mathbb{R}^n)$ by its continuity. First show that Fourier transform on Schwartz functions $S \subset L^2(\mathbb{R}^2)$ is an isometry with respect to the $L^2$ norm. Then, by the continuity (isometries are continuous) of the Fourier transform on $S$ and the densinty of $S$ in $L^2(\mathbb{R}^n)$, we can extend Fourier transform to the whole $L^2(\mathbb{R}^n)$ as an isometry. $L^2(\mathbb{R^n})$ is complete so the extension is unique and surjective. Therefore it is unitary, not merely an isometry. Thus the Fourier transform of an $L^2(\mathbb{R^n})$ function is also an $L^2(\mathbb{R^n})$ function and it preserves the inner product. The above is a rather long quote from the material in a class I attend. I don't have strong background on analysis but am struggling to understand the above argument. I think I can understand most part except the uniqueness and surjectivity. Why the completeness ensures the uniqueness and surjectivity? I have read some textbooks on the same subject and found that the bijectivity is usually proved by the extension of the inversion formula on $S$ to $L^2$, which I can understand. For the uniqueness, I couldn't find any argument in my textbooks. Does the completeness of $L^2$ really ensure the uniqueness and surjectivity?",,"['functional-analysis', 'fourier-transform']"
6,Is every absorbing set a neighborhood of zero?,Is every absorbing set a neighborhood of zero?,,"I'm studying functional analysis, currently a chapter about topological vector spaces. It is stated that every neighborhood of zero is an absorbing set. But I was wondering if the reversed statement is also true? Isn't, as an counterexample, in $X =>R^1$ the disconnected set $A = [2,1) \cup \{0\} \cup (-1,-2]$ also absorbing and does not contain an open set, which contains zero (so isn't a neighborhood of zero)? For every $x\in X$ I can construct some $t>0, t=1/x \pm \epsilon$ such that $t \cdot x \in A$. For $x=0$ I can choose any $t>0$. Edit: We defined absorbing as follows. Let $X$ be a vector space, $A$ a subset of $X$. Then $A$ is called absorbing, if for every $x \in X$ there exists a $t > 0$ such that $tx \in A$.","I'm studying functional analysis, currently a chapter about topological vector spaces. It is stated that every neighborhood of zero is an absorbing set. But I was wondering if the reversed statement is also true? Isn't, as an counterexample, in $X =>R^1$ the disconnected set $A = [2,1) \cup \{0\} \cup (-1,-2]$ also absorbing and does not contain an open set, which contains zero (so isn't a neighborhood of zero)? For every $x\in X$ I can construct some $t>0, t=1/x \pm \epsilon$ such that $t \cdot x \in A$. For $x=0$ I can choose any $t>0$. Edit: We defined absorbing as follows. Let $X$ be a vector space, $A$ a subset of $X$. Then $A$ is called absorbing, if for every $x \in X$ there exists a $t > 0$ such that $tx \in A$.",,['functional-analysis']
7,Question regarding kernels in Hilbert-Schmidt operators,Question regarding kernels in Hilbert-Schmidt operators,,"I'm studying some Hilbert-Schmidt integral operator theory. I read that a Hilbert-Schmidt integral operator is uniquely determined by its kernel, and I wonder how exactly that is. I guess what I'm looking for are hints/suggestions on how to show that Hilbert-Schmidt integral operators are uniquely determined by their kernels. Here are the definitions I'm going by: $\textit{Let k be a function of two variables }(x,y)\in I \times I=I^2$ $\textit{ where }I\textit{ is a finite or infinite real interval. We define a linear integral operator K with kernel }$ $k(x,y)\textit{ as }$ $$Ku(x)=\int_{I}k(x,y)u(y)\ dy,\ \ x\in I$$ $\textit{whenever this integral makes sense. The domain D(K) will have to be specified in order to accomplish this.}$ $\textit{An integral operator on }L^2(I)\textit{ is called a Hilbert-Schmidt operator if the kernel }k\textit{ is in }L^2(I\times I),\textit{that is if}$ $$||k||_{L^{2}}^2=\int_{I}\int_{I}|k(x,y)|^2\ dxdy<\infty$$ The book I'm using now says it's possible to show that a Hilbert-Schmidt operator is uniquely determined by its kernel, that is, if $$\int_{I}k(x,y)u(y)\ dy=\int_{I}h(x,y)u(y)\ dy$$ for all $u\in L^2(I)$, then $k=h$ in $L^2(I\times I)$. This is where I'm unsure of how to show this. Thanks in advance!","I'm studying some Hilbert-Schmidt integral operator theory. I read that a Hilbert-Schmidt integral operator is uniquely determined by its kernel, and I wonder how exactly that is. I guess what I'm looking for are hints/suggestions on how to show that Hilbert-Schmidt integral operators are uniquely determined by their kernels. Here are the definitions I'm going by: $\textit{Let k be a function of two variables }(x,y)\in I \times I=I^2$ $\textit{ where }I\textit{ is a finite or infinite real interval. We define a linear integral operator K with kernel }$ $k(x,y)\textit{ as }$ $$Ku(x)=\int_{I}k(x,y)u(y)\ dy,\ \ x\in I$$ $\textit{whenever this integral makes sense. The domain D(K) will have to be specified in order to accomplish this.}$ $\textit{An integral operator on }L^2(I)\textit{ is called a Hilbert-Schmidt operator if the kernel }k\textit{ is in }L^2(I\times I),\textit{that is if}$ $$||k||_{L^{2}}^2=\int_{I}\int_{I}|k(x,y)|^2\ dxdy<\infty$$ The book I'm using now says it's possible to show that a Hilbert-Schmidt operator is uniquely determined by its kernel, that is, if $$\int_{I}k(x,y)u(y)\ dy=\int_{I}h(x,y)u(y)\ dy$$ for all $u\in L^2(I)$, then $k=h$ in $L^2(I\times I)$. This is where I'm unsure of how to show this. Thanks in advance!",,"['real-analysis', 'functional-analysis', 'operator-theory']"
8,"Define $T:L^2[0,1]\to L^2[0,1]$ by $Tf(t)=\int_0^1 \frac{f(s)ds}{1+s^2+t^2}$",Define  by,"T:L^2[0,1]\to L^2[0,1] Tf(t)=\int_0^1 \frac{f(s)ds}{1+s^2+t^2}","We want to show that $T$ is self-adjoint and compact. To show that $T$ is self-adjoint we show $$\begin{align}  \langle Tf(t),g(t)\rangle  &= \int_0^1 Tf(t)\cdot g(t)dt \\  & = \int_0^1 \left(g(t)\left( \int_0^1 \frac{f(s)ds}{1+s^2+t^2} \right)dt\right) \\  &=^? \int_0^1 \left( f(t) \left(\int_0^1 \frac{g(s)ds}{1+s^2+t^2} \right) dt\right) \\  &=\langle f(t),Tg(t)\rangle  \end{align}$$ Would you do this with a substitution? Maybe Fubini's theorem? I'm not really sure where to go with this. For compactness, consider a bounded sequence $\{f_n\}$, say by $M$, in $L^2[0,1]$. We need to show that $$Tf_n=\int_0^1 \frac{f_n(s)ds}{1+s^2+t^2}\leq M\int_0^1\frac{ds}{1+s^2+t^2}$$ has a convergent subsequence. This one I'm not sure how to approach at all. Any help for either problem would be much appreciated, thank you so much!","We want to show that $T$ is self-adjoint and compact. To show that $T$ is self-adjoint we show $$\begin{align}  \langle Tf(t),g(t)\rangle  &= \int_0^1 Tf(t)\cdot g(t)dt \\  & = \int_0^1 \left(g(t)\left( \int_0^1 \frac{f(s)ds}{1+s^2+t^2} \right)dt\right) \\  &=^? \int_0^1 \left( f(t) \left(\int_0^1 \frac{g(s)ds}{1+s^2+t^2} \right) dt\right) \\  &=\langle f(t),Tg(t)\rangle  \end{align}$$ Would you do this with a substitution? Maybe Fubini's theorem? I'm not really sure where to go with this. For compactness, consider a bounded sequence $\{f_n\}$, say by $M$, in $L^2[0,1]$. We need to show that $$Tf_n=\int_0^1 \frac{f_n(s)ds}{1+s^2+t^2}\leq M\int_0^1\frac{ds}{1+s^2+t^2}$$ has a convergent subsequence. This one I'm not sure how to approach at all. Any help for either problem would be much appreciated, thank you so much!",,"['real-analysis', 'functional-analysis', 'analysis']"
9,A function that is in $C^k_b(\mathbb R)$ but not in $C^{k+1}_b(\mathbb R)$,A function that is in  but not in,C^k_b(\mathbb R) C^{k+1}_b(\mathbb R),"Is there an example of a family of functions, index by $k$ , that is in $C_b^k(\mathbb R)$ but not in $C_b^{k+1}(\mathbb R)$ for arbitrary $k$ ? $C_b^k(\mathbb R)$ is the space of functions with continuous and bounded derivatives up to $k$ .","Is there an example of a family of functions, index by , that is in but not in for arbitrary ? is the space of functions with continuous and bounded derivatives up to .",k C_b^k(\mathbb R) C_b^{k+1}(\mathbb R) k C_b^k(\mathbb R) k,"['functional-analysis', 'special-functions']"
10,"Intuition behind : for all $x\in E$ there is $f_0\in E^*$ s.t. $\left<f_0,x_0\right>=\|x_0\|^2$ and $\|f_0\|=\|x_0\|$.",Intuition behind : for all  there is  s.t.  and .,"x\in E f_0\in E^* \left<f_0,x_0\right>=\|x_0\|^2 \|f_0\|=\|x_0\|","I'm seeing a theorem that say that for all $x\in E$ there is $f_0\in E^*$ s.t. $\left<f_0,x_0\right>=\|x_0\|^2$ and $\|f_0\|=\|x_0\|$. I recall that $E^*$ denote the topological dual of $E$. Is there a similar result for inner product spaces for example ? I don't really see the intuition behind this proposition.","I'm seeing a theorem that say that for all $x\in E$ there is $f_0\in E^*$ s.t. $\left<f_0,x_0\right>=\|x_0\|^2$ and $\|f_0\|=\|x_0\|$. I recall that $E^*$ denote the topological dual of $E$. Is there a similar result for inner product spaces for example ? I don't really see the intuition behind this proposition.",,['functional-analysis']
11,Dual norm of a product space,Dual norm of a product space,,"Suppose we have two spaces $X, Y$, each is a linear space equipped with norm $\|\cdot\|_X, \|\cdot\|_Y$, then we define a norm on the product space $Z = X\times Y: \|(x,y)\| = \sqrt{a\|x\|_X^2+b\|y\|_Y^2}$, where $a,b > 0$. I am wondering how to compute the dual norm of this norm. By the definition of dual norm, we need to find for $z^* \in Z^*$, $\|z^*\|_* = \underset{\|z\|=1}{\mathrm{sup}} \;z^*(z)$, but what is $z^*(z)$ here? What are the elements in $Z^*$ like?","Suppose we have two spaces $X, Y$, each is a linear space equipped with norm $\|\cdot\|_X, \|\cdot\|_Y$, then we define a norm on the product space $Z = X\times Y: \|(x,y)\| = \sqrt{a\|x\|_X^2+b\|y\|_Y^2}$, where $a,b > 0$. I am wondering how to compute the dual norm of this norm. By the definition of dual norm, we need to find for $z^* \in Z^*$, $\|z^*\|_* = \underset{\|z\|=1}{\mathrm{sup}} \;z^*(z)$, but what is $z^*(z)$ here? What are the elements in $Z^*$ like?",,"['functional-analysis', 'normed-spaces', 'dual-spaces']"
12,"Prove that $Tf(x)=\int^{1-x}_0 f(t) \, dt$ is compact and compute its spectrum.",Prove that  is compact and compute its spectrum.,"Tf(x)=\int^{1-x}_0 f(t) \, dt","Prove that $T:C^0([0,1])\longrightarrow C^0([0,1])$ defined as $$Tf(x)=\int^{1-x}_0 f(t) \, dt$$ is compact and compute its spectrum. - Compactness : Let $f_n$ be a bounded sequence, that is $\|f_n\|_\infty\leq C\,\,\forall\,n$. In order to prove that $Tf_n$ has a convergent subsequence we show that it is bounded and equicontinuous. It is easy to see that $T$ is continuous, then $Tf_n$ is bounded. Let $\varepsilon >0$ and $x_1, \,x_2 \in [0,\,1]$, then $$|Tf_n(x_1)-Tf_n(x_2)|\leq \|f\|_\infty | x_1-x_2| \leq C | x_1-x_2|.$$ If we choose $\delta=\varepsilon/C$ and $| x_1-x_2| < \delta$ then $$|Tf_n(x_1)-Tf_n(x_2)|< \varepsilon, \quad \forall \, n.$$ - Spectrum : Since $T$ is compact it is not invertible. Then $0\in \sigma (T)$. Now I have some questions : I know that for compact operators between Hilbert spaces if $\lambda\in \sigma(T),\,\lambda\neq0$ then $\lambda\in \sigma_p(T)$ and $\sigma_p(T)$ is finite or countable and $0$ is the only accumulation point of $\sigma_p(T)$. The proof that I have seen of this fact is based on the Fredholm Alternative Theorem (that I only know for Hilbert spaces). So I wonder if this property is still true if the operater is defined on a Banach space . If it is true then the exercise is more simple. I tried to compute $\sigma_p$ but I had some problem. Here some attempts. We are interested in solve $$ Tf(x)=\int^{1-x}_0 f(t) \, dt=\lambda f(x) $$ Since $f\in C^0$ we have $Tf\in C^1$ and $\lambda f\in C^1$ then, $$ -f(1-x)=\lambda f'(x) $$ And now ? It is not possible to solve by separation of variable. How to proceed? Thanks. UPDATE : I have consulted Conway's book A Course in Functional Analysis and I have verified that the properties of the spectrum of a compact operator that I mentioned above are also valid in the case of Banach spaces (Theorem 7.1). Therefore it is sufficient to compute $\sigma_p(T)$ and understand if $\,0\in \sigma_c(T)\, $ or $\,0\in \sigma_r(T)$ or $\,0\in \sigma_p(T)$.","Prove that $T:C^0([0,1])\longrightarrow C^0([0,1])$ defined as $$Tf(x)=\int^{1-x}_0 f(t) \, dt$$ is compact and compute its spectrum. - Compactness : Let $f_n$ be a bounded sequence, that is $\|f_n\|_\infty\leq C\,\,\forall\,n$. In order to prove that $Tf_n$ has a convergent subsequence we show that it is bounded and equicontinuous. It is easy to see that $T$ is continuous, then $Tf_n$ is bounded. Let $\varepsilon >0$ and $x_1, \,x_2 \in [0,\,1]$, then $$|Tf_n(x_1)-Tf_n(x_2)|\leq \|f\|_\infty | x_1-x_2| \leq C | x_1-x_2|.$$ If we choose $\delta=\varepsilon/C$ and $| x_1-x_2| < \delta$ then $$|Tf_n(x_1)-Tf_n(x_2)|< \varepsilon, \quad \forall \, n.$$ - Spectrum : Since $T$ is compact it is not invertible. Then $0\in \sigma (T)$. Now I have some questions : I know that for compact operators between Hilbert spaces if $\lambda\in \sigma(T),\,\lambda\neq0$ then $\lambda\in \sigma_p(T)$ and $\sigma_p(T)$ is finite or countable and $0$ is the only accumulation point of $\sigma_p(T)$. The proof that I have seen of this fact is based on the Fredholm Alternative Theorem (that I only know for Hilbert spaces). So I wonder if this property is still true if the operater is defined on a Banach space . If it is true then the exercise is more simple. I tried to compute $\sigma_p$ but I had some problem. Here some attempts. We are interested in solve $$ Tf(x)=\int^{1-x}_0 f(t) \, dt=\lambda f(x) $$ Since $f\in C^0$ we have $Tf\in C^1$ and $\lambda f\in C^1$ then, $$ -f(1-x)=\lambda f'(x) $$ And now ? It is not possible to solve by separation of variable. How to proceed? Thanks. UPDATE : I have consulted Conway's book A Course in Functional Analysis and I have verified that the properties of the spectrum of a compact operator that I mentioned above are also valid in the case of Banach spaces (Theorem 7.1). Therefore it is sufficient to compute $\sigma_p(T)$ and understand if $\,0\in \sigma_c(T)\, $ or $\,0\in \sigma_r(T)$ or $\,0\in \sigma_p(T)$.",,"['functional-analysis', 'spectral-theory', 'compact-operators']"
13,Determining an orthonormal set of basis vectors for the linear space,Determining an orthonormal set of basis vectors for the linear space,,"The following is example C.4 from Appendix C (Linear Spaces Review) of Introduction to Laplace Transforms and Fourier Series, Second Edition , by Phil Dyke: Example C.4 Determine an orthonormal set of vectors for the linear space that consists of all real linear functions: $$\{a+bx:a,b\in\mathbb{R}\ 0\leq x\leq1\}$$ using an inner product $$\langle f,g\rangle=\int_0^1f g\,dx.$$ Solution The set $\{1,x\}$ forms a basis, but is is not orthogonal. Let $a+bx$ and $c+dx$ be two vectors. In order to be orthogonal we must have $$\langle a+bx,c+dx\rangle=\int_0^1(a+bx)(c+dx)\,dx=0.$$ Performing the elementary integration gives the following condition on the constants $a,b,c$ and $d$ $$ac+\frac{1}{2}(bc+ad)+\frac{1}{3}bd=0.$$ In order to be orthonormal too we also need $$\|a+bc\|=1\,\text{ and }\,\|c+dx\|=1$$ and these give, additionally, $$a^2+b^2=1,\ c^2+d^2=1.$$ There are four unknowns and three equations here, so we can make a convenient choice. Let us set $$a=-b=\frac{1}{\sqrt{2}}$$ which gives $$\frac{1}{\sqrt{2}}(1-x)$$ as one vector. The first equation now gives $3c=-d$ from which $$c=\frac{1}{\sqrt{10}},\ \ d=-\frac{3}{\sqrt{10}}.$$ Hence the set $\{(1-x)/\sqrt{10},(1-3x)/\sqrt{10}\}$ is a possible orthonormal one. $\ $ $ \ $ Of course there are infinitely many possible orthonormal sets, the above was one simple choice. The next definition follows naturally. I have the following questions: How do we determine $a^2 + b^2 = 1$ and $c^2 + d^2 = 1$ from $\|a + bx\| = 1$ and $\|c + dx\| = 1$? This seems similar to the norm of a complex number $a + bi$, but we're not dealing with complex numbers in this case, since we're dealing with the space of all real linear functions, so I'm not sure how these are being derived? If we have $a = -b = \dfrac{1}{\sqrt{2}}$ and $3c = -d$, then we have the following: $$\begin{align} \dfrac{1}{\sqrt{2}}c + \dfrac{1}{2} \left[ \left( \dfrac{-1}{\sqrt{2}} \right)c + \left( \dfrac{1}{\sqrt{2}} \right) (-3c) \right] + \dfrac{1}{3} \left( \dfrac{-1}{\sqrt{2}} \right)(-3c) = 0 \\ \rightarrow \dfrac{c}{\sqrt{2}} - \dfrac{c}{2 \sqrt{2}} - \dfrac{3c}{2\sqrt{2}} + \dfrac{c}{\sqrt{2}} = 0 \\ \rightarrow \dfrac{2c}{\sqrt{2}} - \dfrac{4c}{2\sqrt{2}} = 0 \\ \rightarrow 0 = 0\ ?\end{align}$$ Have I made an error? Where does the $c = \dfrac{1}{\sqrt{10}}$ and $-\dfrac{3}{\sqrt{10}}$ come from? I would greatly appreciate it if people could please take the time to clarify these. EDIT: The following is proved in the textbook: Example C.3 Prove that $\|a\|=\sqrt{\langle\mathbf{a}.\mathbf{a}\rangle}\in V$ is indeed a norm for the vector space $V$ with inner product $\langle,\,\rangle$. Which seems to suggest that $\|x\| = \sqrt{\langle x,x\rangle}$?","The following is example C.4 from Appendix C (Linear Spaces Review) of Introduction to Laplace Transforms and Fourier Series, Second Edition , by Phil Dyke: Example C.4 Determine an orthonormal set of vectors for the linear space that consists of all real linear functions: $$\{a+bx:a,b\in\mathbb{R}\ 0\leq x\leq1\}$$ using an inner product $$\langle f,g\rangle=\int_0^1f g\,dx.$$ Solution The set $\{1,x\}$ forms a basis, but is is not orthogonal. Let $a+bx$ and $c+dx$ be two vectors. In order to be orthogonal we must have $$\langle a+bx,c+dx\rangle=\int_0^1(a+bx)(c+dx)\,dx=0.$$ Performing the elementary integration gives the following condition on the constants $a,b,c$ and $d$ $$ac+\frac{1}{2}(bc+ad)+\frac{1}{3}bd=0.$$ In order to be orthonormal too we also need $$\|a+bc\|=1\,\text{ and }\,\|c+dx\|=1$$ and these give, additionally, $$a^2+b^2=1,\ c^2+d^2=1.$$ There are four unknowns and three equations here, so we can make a convenient choice. Let us set $$a=-b=\frac{1}{\sqrt{2}}$$ which gives $$\frac{1}{\sqrt{2}}(1-x)$$ as one vector. The first equation now gives $3c=-d$ from which $$c=\frac{1}{\sqrt{10}},\ \ d=-\frac{3}{\sqrt{10}}.$$ Hence the set $\{(1-x)/\sqrt{10},(1-3x)/\sqrt{10}\}$ is a possible orthonormal one. $\ $ $ \ $ Of course there are infinitely many possible orthonormal sets, the above was one simple choice. The next definition follows naturally. I have the following questions: How do we determine $a^2 + b^2 = 1$ and $c^2 + d^2 = 1$ from $\|a + bx\| = 1$ and $\|c + dx\| = 1$? This seems similar to the norm of a complex number $a + bi$, but we're not dealing with complex numbers in this case, since we're dealing with the space of all real linear functions, so I'm not sure how these are being derived? If we have $a = -b = \dfrac{1}{\sqrt{2}}$ and $3c = -d$, then we have the following: $$\begin{align} \dfrac{1}{\sqrt{2}}c + \dfrac{1}{2} \left[ \left( \dfrac{-1}{\sqrt{2}} \right)c + \left( \dfrac{1}{\sqrt{2}} \right) (-3c) \right] + \dfrac{1}{3} \left( \dfrac{-1}{\sqrt{2}} \right)(-3c) = 0 \\ \rightarrow \dfrac{c}{\sqrt{2}} - \dfrac{c}{2 \sqrt{2}} - \dfrac{3c}{2\sqrt{2}} + \dfrac{c}{\sqrt{2}} = 0 \\ \rightarrow \dfrac{2c}{\sqrt{2}} - \dfrac{4c}{2\sqrt{2}} = 0 \\ \rightarrow 0 = 0\ ?\end{align}$$ Have I made an error? Where does the $c = \dfrac{1}{\sqrt{10}}$ and $-\dfrac{3}{\sqrt{10}}$ come from? I would greatly appreciate it if people could please take the time to clarify these. EDIT: The following is proved in the textbook: Example C.3 Prove that $\|a\|=\sqrt{\langle\mathbf{a}.\mathbf{a}\rangle}\in V$ is indeed a norm for the vector space $V$ with inner product $\langle,\,\rangle$. Which seems to suggest that $\|x\| = \sqrt{\langle x,x\rangle}$?",,"['linear-algebra', 'functional-analysis', 'normed-spaces', 'inner-products', 'orthonormal']"
14,Is completeness necessary? X separable iff weak* topology on closed unit ball of dual is metrizable.,Is completeness necessary? X separable iff weak* topology on closed unit ball of dual is metrizable.,,"First some references: [M] Megginson - An Introduction to Banach Space Theory [D] Denkowski, Migórski, Papageorgiou, Socrates - An Introduction to Nonlinear Analysis [B] Brezis - Functional Analysis, Sobolev Spaces and Partial Differential Equations [DS] Dunford and Schwartz - Linear Operators Part I: General Theory The following theorem appears in [M, p.231], [D, p.305], [B, p.74], [DS, p.426].  I'm sure it appears elsewhere too. Theorem. Let $X$ be a Banach space. Then $X$ is separable iff the closed unit ball of $X^*$ is metrizable in the weak* topology (inherited from X*). However, [M] only assumes $X$ is a normed space, not a Banach space. I've been through the proofs, and I can't see where completeness is being used. Question 1. Is completeness of $X$ really necessary? There is also a closely related theorem that appears in [D, p.305], [B, p.74], [DS, p.426]: Theorem. Let $X$ be a Banach space. Then $X^{*}$ is separable iff the closed unit ball of $X$ is metrizable in the weak topology (inherited from X). Question 2. Is completeness of $X$ really necessary?","First some references: [M] Megginson - An Introduction to Banach Space Theory [D] Denkowski, Migórski, Papageorgiou, Socrates - An Introduction to Nonlinear Analysis [B] Brezis - Functional Analysis, Sobolev Spaces and Partial Differential Equations [DS] Dunford and Schwartz - Linear Operators Part I: General Theory The following theorem appears in [M, p.231], [D, p.305], [B, p.74], [DS, p.426].  I'm sure it appears elsewhere too. Theorem. Let $X$ be a Banach space. Then $X$ is separable iff the closed unit ball of $X^*$ is metrizable in the weak* topology (inherited from X*). However, [M] only assumes $X$ is a normed space, not a Banach space. I've been through the proofs, and I can't see where completeness is being used. Question 1. Is completeness of $X$ really necessary? There is also a closely related theorem that appears in [D, p.305], [B, p.74], [DS, p.426]: Theorem. Let $X$ be a Banach space. Then $X^{*}$ is separable iff the closed unit ball of $X$ is metrizable in the weak topology (inherited from X). Question 2. Is completeness of $X$ really necessary?",,"['real-analysis', 'functional-analysis']"
15,"Properties of functional $F: W_{2}^{1} \to \mathbb{C}$, $ F(f) = f(0)$","Properties of functional ,",F: W_{2}^{1} \to \mathbb{C}  F(f) = f(0),"Let $W_{2}^{1} = \lbrace f:[0,1] \to \mathbb{C} : f \in AC[0,1], f' \in L^{2}[0,1] \rbrace$ be a Hilbert space with an inner product: $\langle f, g \rangle = \int_{0}^{1} f\overline{g}dx + \int_{0}^{1} f'\overline{g'}dx$, and let $F: W_{2}^{1} \to \mathbb{C}$ be a linear functional defined by evaluation at zero: $F(f) = f(0)$. I want to prove and obtain the following properties of $F$: I want to prove that $F$ is a bounded linear functional. I want to find the function $\phi$ s.t. $F(f) = \langle f, \phi \rangle$, and I want to find $||F||$. I instantly hit a wall in this problem. After some googling, I found out that $W_{2}^{1}$ is a kind of Sobolev space; however, this is a problem from functional analysis course, and Sobolev spaces haven't been covered. I think that this problem has a solution which doesn't use any properties of Sobolev spaces. I was able to prove that $F$ is bounded, albeit after some trouble: \begin{equation}  |F(f)| = |f(0)| = |f(t) - \int_{0}^{t} f'(s)ds| \leq |f(t)| + \int_{0}^{t} |f'(s)|ds \leq |f(t)| + \int_{0}^{1} |f'(s)|ds  \hspace{0.5cm}(1)\end{equation} Now, since $f$ is continuous, there exists a $t_{0}$ such that $m = |f(t_{0})| = \min_{t \in [0,1]}|f(t)|$. Then $m \leq \int_{0}^{1} |f(t)|dt$. Since $(1)$ holds for all $t \in [0,1]$, by inserting $t=t_{0}$ into $(1)$, we get \begin{equation} |f(0)| \leq m + \int_{0}^{1}|f'(s)|ds \leq \int_{0}^{1} |f(s)|ds + \int_{0}^{1} |f'(s)|ds \leq \sqrt{\int_{0}^{1} |f'(s)|^2ds} + \sqrt{\int_{0}^{1} |f(s)|^2ds} \leq \sqrt{2}||f||. \end{equation} For the next-to-last inequality I used Cauchy-Schwartz, and for the last inequality I used $\sqrt{a} + \sqrt{b} \leq \sqrt{2}\sqrt{a+b}$, which follows from the AM-GM inequality. Therefore, $||F|| \leq \sqrt{2}$. However, I'm not sure how to find $\phi$ with $F(f) = f(0) = \langle f, \phi \rangle$. If I were to find such a $\phi$, then obviously by the Riesz representation theorem, $||F|| = ||\phi||$. I took a look at Find $y \in W_{2}^{1}[-1,1]$ s.t. $\forall x \in W_{2}^{1}[-1,1]$, $f(x)=\langle x, y \rangle$ , but the operator there is very different from mine, and I can't get a differential equation out of the condition analogous to the one arctic tern obtained there. Is there a good ""algorithm"" for finding the corresponding vectors to Hilbert space functionals? Or at least in Hilbert spaces with integral inner products?","Let $W_{2}^{1} = \lbrace f:[0,1] \to \mathbb{C} : f \in AC[0,1], f' \in L^{2}[0,1] \rbrace$ be a Hilbert space with an inner product: $\langle f, g \rangle = \int_{0}^{1} f\overline{g}dx + \int_{0}^{1} f'\overline{g'}dx$, and let $F: W_{2}^{1} \to \mathbb{C}$ be a linear functional defined by evaluation at zero: $F(f) = f(0)$. I want to prove and obtain the following properties of $F$: I want to prove that $F$ is a bounded linear functional. I want to find the function $\phi$ s.t. $F(f) = \langle f, \phi \rangle$, and I want to find $||F||$. I instantly hit a wall in this problem. After some googling, I found out that $W_{2}^{1}$ is a kind of Sobolev space; however, this is a problem from functional analysis course, and Sobolev spaces haven't been covered. I think that this problem has a solution which doesn't use any properties of Sobolev spaces. I was able to prove that $F$ is bounded, albeit after some trouble: \begin{equation}  |F(f)| = |f(0)| = |f(t) - \int_{0}^{t} f'(s)ds| \leq |f(t)| + \int_{0}^{t} |f'(s)|ds \leq |f(t)| + \int_{0}^{1} |f'(s)|ds  \hspace{0.5cm}(1)\end{equation} Now, since $f$ is continuous, there exists a $t_{0}$ such that $m = |f(t_{0})| = \min_{t \in [0,1]}|f(t)|$. Then $m \leq \int_{0}^{1} |f(t)|dt$. Since $(1)$ holds for all $t \in [0,1]$, by inserting $t=t_{0}$ into $(1)$, we get \begin{equation} |f(0)| \leq m + \int_{0}^{1}|f'(s)|ds \leq \int_{0}^{1} |f(s)|ds + \int_{0}^{1} |f'(s)|ds \leq \sqrt{\int_{0}^{1} |f'(s)|^2ds} + \sqrt{\int_{0}^{1} |f(s)|^2ds} \leq \sqrt{2}||f||. \end{equation} For the next-to-last inequality I used Cauchy-Schwartz, and for the last inequality I used $\sqrt{a} + \sqrt{b} \leq \sqrt{2}\sqrt{a+b}$, which follows from the AM-GM inequality. Therefore, $||F|| \leq \sqrt{2}$. However, I'm not sure how to find $\phi$ with $F(f) = f(0) = \langle f, \phi \rangle$. If I were to find such a $\phi$, then obviously by the Riesz representation theorem, $||F|| = ||\phi||$. I took a look at Find $y \in W_{2}^{1}[-1,1]$ s.t. $\forall x \in W_{2}^{1}[-1,1]$, $f(x)=\langle x, y \rangle$ , but the operator there is very different from mine, and I can't get a differential equation out of the condition analogous to the one arctic tern obtained there. Is there a good ""algorithm"" for finding the corresponding vectors to Hilbert space functionals? Or at least in Hilbert spaces with integral inner products?",,"['functional-analysis', 'hilbert-spaces', 'sobolev-spaces']"
16,Definition of a Lie group representation of a Hilbert Space,Definition of a Lie group representation of a Hilbert Space,,"Let $G$ be a real Lie group, and $V$ a Hilbert space.  Wikipedia defines a unitary representation of $G$ on $V$ to be a homomorphism of $G$ into the group of unitary operators of $V$ such that for each $v \in V$, the map $g \mapsto \pi(g)v$ is continuous, where $V$ is given its norm topology. On the other hand, many places for example here (page 23, proposition 5.5(2)) seem to define a Hilbert space representation as one for which the product mapping $G \times V \rightarrow V, (g,v) \mapsto \pi(g)v$ is continuous. Are these inequivalent definitions?  Or does each $g \mapsto \pi(g)v$ being continuous imply the continuity of $(g,v) \mapsto \pi(g)v$?  Maybe by some application of the uniform boundedness principle.","Let $G$ be a real Lie group, and $V$ a Hilbert space.  Wikipedia defines a unitary representation of $G$ on $V$ to be a homomorphism of $G$ into the group of unitary operators of $V$ such that for each $v \in V$, the map $g \mapsto \pi(g)v$ is continuous, where $V$ is given its norm topology. On the other hand, many places for example here (page 23, proposition 5.5(2)) seem to define a Hilbert space representation as one for which the product mapping $G \times V \rightarrow V, (g,v) \mapsto \pi(g)v$ is continuous. Are these inequivalent definitions?  Or does each $g \mapsto \pi(g)v$ being continuous imply the continuity of $(g,v) \mapsto \pi(g)v$?  Maybe by some application of the uniform boundedness principle.",,"['functional-analysis', 'hilbert-spaces', 'lie-groups']"
17,A distribution as a linear combination of Dirac delta and its derivatives,A distribution as a linear combination of Dirac delta and its derivatives,,"This problem is from Exercise 1.13.22, Tao's An Epsilon of Room . Let $\lambda$ be a distribution whose domain is the set of compactly supported smooth functions on $\mathbb{R}$. (i) Show that if $\lambda$ is a distribution and $n\ge 1$ is an integer, then $\lambda x^n=0$ iff $\lambda$ is a linear combination of $\delta$ and its first $n-1$ derivatives $\delta', \delta'', ...,\delta^{(n-1)}$. (ii) Show that a distribution $\lambda$ is supported on ${0}$ iff it is a linear combination of $\delta$ and finitely many of its derivatives. My attempt: For both (i) and (ii), the 'if' parts are easy, and I already did them easily. The problems are the 'only if' parts. For the 'only if' part of (i), I let $a_i = (-1)^i \dfrac{\lambda(x^i)}{i!}$, and tried to prove that $\lambda= \sum_{i=0} ^{n-1}a_i \delta^{(i)}$, but I don't know how to proceed further. For the 'only if' part of (ii), I don't have any idea to proceed. Does anyone have ideas? Any hints or advices will help a lot! Thanks!","This problem is from Exercise 1.13.22, Tao's An Epsilon of Room . Let $\lambda$ be a distribution whose domain is the set of compactly supported smooth functions on $\mathbb{R}$. (i) Show that if $\lambda$ is a distribution and $n\ge 1$ is an integer, then $\lambda x^n=0$ iff $\lambda$ is a linear combination of $\delta$ and its first $n-1$ derivatives $\delta', \delta'', ...,\delta^{(n-1)}$. (ii) Show that a distribution $\lambda$ is supported on ${0}$ iff it is a linear combination of $\delta$ and finitely many of its derivatives. My attempt: For both (i) and (ii), the 'if' parts are easy, and I already did them easily. The problems are the 'only if' parts. For the 'only if' part of (i), I let $a_i = (-1)^i \dfrac{\lambda(x^i)}{i!}$, and tried to prove that $\lambda= \sum_{i=0} ^{n-1}a_i \delta^{(i)}$, but I don't know how to proceed further. For the 'only if' part of (ii), I don't have any idea to proceed. Does anyone have ideas? Any hints or advices will help a lot! Thanks!",,"['real-analysis', 'functional-analysis', 'distribution-theory']"
18,Which manifold is formed by the set of resolutions of the identity operator into orthogonal projectors?,Which manifold is formed by the set of resolutions of the identity operator into orthogonal projectors?,,"A resolution of the identity operator $I$ on $\mathbb{R}^n$ or $\mathbb{C}^n$ is a decomposition $$I = \sum_{i=1}^n P_i,$$ where the $\{P_i\}$ are a set of orthogonal rank-one projection operators. What is the manifold (or Lie group) structure of the set of all resolutions of the identity, or equivalently sets $P_i$? A naive guess is to express each $P_i$ as an outer product $|\psi_i\rangle \langle \psi_i|$ and identify every resolution of the identity with an orthonormal basis $\{|\psi_i\rangle\}$ - the set of which is diffeomorphic to $\mathrm{U}(n)$ (since you can rotate any orthonormal basis into another one via an appropriate unitary operator). But I don't think is quite right, because you could multiply any basis vector by a phase factor $e^{i \theta}$ (or in the real case, $-1$) without changing the corresponding projector $P_i$, so the orthonormal basis contains redundant information/degrees of freedom. (Permuting basis elements also leaves the decomposition unchanged, but we can ignore this possibility because it can't be done continuously.) Is the answer just $\mathrm{U}(n) / \mathrm{U}(1)^{\times n}$ to remove the $n$ redundant phase factors, or something more complicated? If so, is there a simpler expression for this quotient group?","A resolution of the identity operator $I$ on $\mathbb{R}^n$ or $\mathbb{C}^n$ is a decomposition $$I = \sum_{i=1}^n P_i,$$ where the $\{P_i\}$ are a set of orthogonal rank-one projection operators. What is the manifold (or Lie group) structure of the set of all resolutions of the identity, or equivalently sets $P_i$? A naive guess is to express each $P_i$ as an outer product $|\psi_i\rangle \langle \psi_i|$ and identify every resolution of the identity with an orthonormal basis $\{|\psi_i\rangle\}$ - the set of which is diffeomorphic to $\mathrm{U}(n)$ (since you can rotate any orthonormal basis into another one via an appropriate unitary operator). But I don't think is quite right, because you could multiply any basis vector by a phase factor $e^{i \theta}$ (or in the real case, $-1$) without changing the corresponding projector $P_i$, so the orthonormal basis contains redundant information/degrees of freedom. (Permuting basis elements also leaves the decomposition unchanged, but we can ignore this possibility because it can't be done continuously.) Is the answer just $\mathrm{U}(n) / \mathrm{U}(1)^{\times n}$ to remove the $n$ redundant phase factors, or something more complicated? If so, is there a simpler expression for this quotient group?",,"['functional-analysis', 'manifolds', 'hilbert-spaces', 'lie-groups', 'smooth-manifolds']"
19,"Separating compact, non-convex sets in $\mathbb R^n$","Separating compact, non-convex sets in",\mathbb R^n,"Let $m>1$. For disjoint compact subsets $E$ and $F$ of $\mathbb{R}^n$ we can define $$d(E,F) := \sup_\phi \inf \{\phi(x)-\phi(y)| x\in E, y\in F\},$$  where the supremum is taken over all bounded $\phi\in C^\infty(\mathbb R^n; \mathbb R )$ with $\|D^\alpha\phi\|_\infty \leq 1$ for $1\leq |\alpha| \leq m$. We easily get $d(E,F)\leq n^{1/2} \tilde d (E,F),$ for $\tilde d$ being the Euclidean distance. Since for compact convex sets we can always find a linear function with gradient of norm 1 such that $$\tilde d(E,F) = \inf \{\phi(x)-\phi(y)| x\in E, y\in F\},$$ we can approximate it by a sequence of bounded $C^\infty$ functions to obtain $\tilde d(E,F)\leq d (E,F),$ whenever $E, F \subseteq \mathbb R^n$ are two disjoint, compact and convex sets. The question I have been struggling with is: can we relax the condition that both sets need to be convex to obtain the above inequality (with possibly some extra, but uniform, constants)? I am particularly interested in the case when $E$ is the closed unit ball and $F$ is $\{x\in \mathbb R^n| 2\leq|x|\leq 4\}$. First I took a linear function as above separating $E$ and $B= \{x\in \mathbb R^n| |x-3e_1|\leq 1\}$ a compact and convex subset of $F$. This can't work though, because if I allow $y\in F\setminus B$ the infimum becomes negative. Should it be possible to construct some kind of a cut-off function with the above properties? I will be grateful for help! PS. the answer to the above question for $m=1$ is yes, since the distance function is Lipschitz continuous. Update: The claim holds for any disjoint closed subsets of $\mathbb R^n$. The idea of the following proof comes from Lemma 2.3 in this paper . Let $s=\tilde d(E,F) >0$ and $\psi \in C^\infty_c(\mathbb R^n)$, supported in the unit ball, with $\int \psi =1$. We consider the rescaled function $\psi_\varepsilon = \varepsilon^{-n}\psi(\cdot/\varepsilon)$ for $\varepsilon>0$. Let us fix $\varepsilon = \frac{s}{4}$ and denote the $\delta$-neighbourhood of $E$ w.r.t. $\tilde d$ by $\tilde E_\delta$. Define $C_\psi = \sum_{1\leq|\alpha|\leq m} \int |D^\alpha\psi|.$ We distinct two cases: Case 1. $\varepsilon\ge 1$ Let $\phi = \frac{\varepsilon}{C_\psi}\chi_{\tilde E_\varepsilon} \ast \psi_\varepsilon$. Then $\phi$ satisfies $\|D^\alpha\phi\|_\infty \leq 1$ for $1\leq |\alpha| \leq m$.  We obtain for $x\in E, y\in F$ $$ \begin{align} \phi(x)-\phi(y)=\phi (x) & = \frac{\varepsilon}{C_\psi}\int_{B(x,\varepsilon)} \psi_\varepsilon(x-z) dz \\ & = \frac{\varepsilon}{C_\psi}\ge C\tilde d(E,F)\end{align}. $$ Case 2. $\varepsilon\leq 1$ Let $\delta=\varepsilon^{\frac{1}{m}}$ and we set $\phi = \frac{\varepsilon}{C_\psi}\chi_{\tilde E_\delta} \ast \psi_\delta$. Then one checks that $\phi$ also satisfies $\|D^\alpha\phi\|_\infty \leq 1$ for $1\leq |\alpha| \leq m$. We have for $x\in E, y\in F$ $$ \begin{align} \phi(x)-\phi(y)=\phi (x) & = \frac{\varepsilon}{C_\psi}\int_{B(x,\delta)} \psi_\delta(x-z) dz \\ & = \frac{\varepsilon}{C_\psi}\ge C\tilde d(E,F)\end{align}. $$","Let $m>1$. For disjoint compact subsets $E$ and $F$ of $\mathbb{R}^n$ we can define $$d(E,F) := \sup_\phi \inf \{\phi(x)-\phi(y)| x\in E, y\in F\},$$  where the supremum is taken over all bounded $\phi\in C^\infty(\mathbb R^n; \mathbb R )$ with $\|D^\alpha\phi\|_\infty \leq 1$ for $1\leq |\alpha| \leq m$. We easily get $d(E,F)\leq n^{1/2} \tilde d (E,F),$ for $\tilde d$ being the Euclidean distance. Since for compact convex sets we can always find a linear function with gradient of norm 1 such that $$\tilde d(E,F) = \inf \{\phi(x)-\phi(y)| x\in E, y\in F\},$$ we can approximate it by a sequence of bounded $C^\infty$ functions to obtain $\tilde d(E,F)\leq d (E,F),$ whenever $E, F \subseteq \mathbb R^n$ are two disjoint, compact and convex sets. The question I have been struggling with is: can we relax the condition that both sets need to be convex to obtain the above inequality (with possibly some extra, but uniform, constants)? I am particularly interested in the case when $E$ is the closed unit ball and $F$ is $\{x\in \mathbb R^n| 2\leq|x|\leq 4\}$. First I took a linear function as above separating $E$ and $B= \{x\in \mathbb R^n| |x-3e_1|\leq 1\}$ a compact and convex subset of $F$. This can't work though, because if I allow $y\in F\setminus B$ the infimum becomes negative. Should it be possible to construct some kind of a cut-off function with the above properties? I will be grateful for help! PS. the answer to the above question for $m=1$ is yes, since the distance function is Lipschitz continuous. Update: The claim holds for any disjoint closed subsets of $\mathbb R^n$. The idea of the following proof comes from Lemma 2.3 in this paper . Let $s=\tilde d(E,F) >0$ and $\psi \in C^\infty_c(\mathbb R^n)$, supported in the unit ball, with $\int \psi =1$. We consider the rescaled function $\psi_\varepsilon = \varepsilon^{-n}\psi(\cdot/\varepsilon)$ for $\varepsilon>0$. Let us fix $\varepsilon = \frac{s}{4}$ and denote the $\delta$-neighbourhood of $E$ w.r.t. $\tilde d$ by $\tilde E_\delta$. Define $C_\psi = \sum_{1\leq|\alpha|\leq m} \int |D^\alpha\psi|.$ We distinct two cases: Case 1. $\varepsilon\ge 1$ Let $\phi = \frac{\varepsilon}{C_\psi}\chi_{\tilde E_\varepsilon} \ast \psi_\varepsilon$. Then $\phi$ satisfies $\|D^\alpha\phi\|_\infty \leq 1$ for $1\leq |\alpha| \leq m$.  We obtain for $x\in E, y\in F$ $$ \begin{align} \phi(x)-\phi(y)=\phi (x) & = \frac{\varepsilon}{C_\psi}\int_{B(x,\varepsilon)} \psi_\varepsilon(x-z) dz \\ & = \frac{\varepsilon}{C_\psi}\ge C\tilde d(E,F)\end{align}. $$ Case 2. $\varepsilon\leq 1$ Let $\delta=\varepsilon^{\frac{1}{m}}$ and we set $\phi = \frac{\varepsilon}{C_\psi}\chi_{\tilde E_\delta} \ast \psi_\delta$. Then one checks that $\phi$ also satisfies $\|D^\alpha\phi\|_\infty \leq 1$ for $1\leq |\alpha| \leq m$. We have for $x\in E, y\in F$ $$ \begin{align} \phi(x)-\phi(y)=\phi (x) & = \frac{\varepsilon}{C_\psi}\int_{B(x,\delta)} \psi_\delta(x-z) dz \\ & = \frac{\varepsilon}{C_\psi}\ge C\tilde d(E,F)\end{align}. $$",,"['real-analysis', 'functional-analysis', 'euclidean-geometry', 'special-functions']"
20,Why this is called semi norm?,Why this is called semi norm?,,"How to prove the following is semi-norm $$[u]_{s,p}=\Bigg(\int_{\Omega}\int_{\Omega}\frac{|u(x)-u(y)|^p}{|x-y|^{n+sp}}dxdy\Bigg)^{1/p}$$ where $\Omega$ open set in $\mathbb R^n$, $1\leq p<\infty$, $0<s<1$. As a semi-norm satisfying triangle inequality and homogeneous. I am facing problem in triangle inequality.","How to prove the following is semi-norm $$[u]_{s,p}=\Bigg(\int_{\Omega}\int_{\Omega}\frac{|u(x)-u(y)|^p}{|x-y|^{n+sp}}dxdy\Bigg)^{1/p}$$ where $\Omega$ open set in $\mathbb R^n$, $1\leq p<\infty$, $0<s<1$. As a semi-norm satisfying triangle inequality and homogeneous. I am facing problem in triangle inequality.",,"['real-analysis', 'functional-analysis', 'sobolev-spaces', 'lp-spaces', 'fractional-sobolev-spaces']"
21,"Can $f, g \in L^{1}(\mathbb{R})$ imply $ \lim_{x \to \infty} (f * g)(x) = 0 $",Can  imply,"f, g \in L^{1}(\mathbb{R})  \lim_{x \to \infty} (f * g)(x) = 0 ","Can $f, g \in L^{1}(\mathbb{R})$ imply  $$ \lim_{x \to \infty} (f * g)(x) = 0 $$ or not? $*$ denotes convolution here:  $$ (f*g)(x) = \int_{\mathbb{R}} f(t)g(x-t)\ dt $$ I read that when $f \in L^{p}$ and $g \in L^q$, we can prove $f * g(x)$ vanishes at infinity, using Holder's inequality to estimate $\int_{B(0,R)^C}| f(t)g(x-t) | dt$. But in the case of $L^1(\mathbb{R})$ I have difficulty in the estimation. I guess it is true but not so sure. Any help is appreciated!","Can $f, g \in L^{1}(\mathbb{R})$ imply  $$ \lim_{x \to \infty} (f * g)(x) = 0 $$ or not? $*$ denotes convolution here:  $$ (f*g)(x) = \int_{\mathbb{R}} f(t)g(x-t)\ dt $$ I read that when $f \in L^{p}$ and $g \in L^q$, we can prove $f * g(x)$ vanishes at infinity, using Holder's inequality to estimate $\int_{B(0,R)^C}| f(t)g(x-t) | dt$. But in the case of $L^1(\mathbb{R})$ I have difficulty in the estimation. I guess it is true but not so sure. Any help is appreciated!",,"['integration', 'functional-analysis', 'lp-spaces', 'convolution']"
22,Function composition in $L^2$,Function composition in,L^2,"Let $f\in L^2(0,\infty)$ with $|f(x)| \leq |x|$. Further, define $g(x)=d^x$ for some $d>1$. Question: Is $f\circ g \in L^2(\mathbb{R})$? If yes, how do I show this? If no, under which conditions does this hold? Intuitively, this should hold, but I have no clue if this can be shown based on the above conditions. Any hints?","Let $f\in L^2(0,\infty)$ with $|f(x)| \leq |x|$. Further, define $g(x)=d^x$ for some $d>1$. Question: Is $f\circ g \in L^2(\mathbb{R})$? If yes, how do I show this? If no, under which conditions does this hold? Intuitively, this should hold, but I have no clue if this can be shown based on the above conditions. Any hints?",,"['functional-analysis', 'function-and-relation-composition']"
23,A proof of a property of positive element in $C^{*}$-algebra.,A proof of a property of positive element in -algebra.,C^{*},"In W.Rudin's book P295, Theorem 11.28 is about the positive element(i.e. $a\geq 0$), the property: $\mathscr{A}$ is $C^{*}$-algebra, (e)If $a\in \mathscr{A}$, then $aa^{*}\geq 0$. (f)If $a\in \mathscr{A}$, then $e+aa^{*}$ is invertible in $\mathscr{A}$. Q1: I have other ways to approach the (e), but I do not totally sure it works.  My method is in the same way of W.Rudin at the beginning, considering the Gelfand transform $\Gamma$ in a maximal normal set of $a$ $\mathscr{B}\subset \mathscr{A}$, we have $$\Gamma(aa^{*})=\Gamma(a)\Gamma(a^{*})=\vert \Gamma(a)\vert^{2} \geq 0,$$ then $aa^{*} \geq 0.$ Q2: How to use the (e) to show (f)? $e+aa^{*}$ is invertible if and only if $\Vert aa^{*}\Vert \leq 1$.How to use it to show the (f)?","In W.Rudin's book P295, Theorem 11.28 is about the positive element(i.e. $a\geq 0$), the property: $\mathscr{A}$ is $C^{*}$-algebra, (e)If $a\in \mathscr{A}$, then $aa^{*}\geq 0$. (f)If $a\in \mathscr{A}$, then $e+aa^{*}$ is invertible in $\mathscr{A}$. Q1: I have other ways to approach the (e), but I do not totally sure it works.  My method is in the same way of W.Rudin at the beginning, considering the Gelfand transform $\Gamma$ in a maximal normal set of $a$ $\mathscr{B}\subset \mathscr{A}$, we have $$\Gamma(aa^{*})=\Gamma(a)\Gamma(a^{*})=\vert \Gamma(a)\vert^{2} \geq 0,$$ then $aa^{*} \geq 0.$ Q2: How to use the (e) to show (f)? $e+aa^{*}$ is invertible if and only if $\Vert aa^{*}\Vert \leq 1$.How to use it to show the (f)?",,"['functional-analysis', 'operator-theory']"
24,Bounded linear operator (between Banach spaces) with second category range has closed range,Bounded linear operator (between Banach spaces) with second category range has closed range,,"I'm attempting a problem about closed range of a bounded linear operator. Assume $X, Y$ are Banach spaces and $A$ is a bounded linear operator.    If $\operatorname{Ran}(A)$ is of the second category,   then show that $\operatorname{Ran}(A)$ is closed. I want to use the Closed Graph Theorem and assume that $Ax_i \to y$ in $Y$, if we can show that $x_i \to x$ in $X$, then the result follows by continuity of $A$. But I'm having a hard time showing that $\{x_i\}$ is a convergent sequence in $X$, and don't know how to use the fact that $\operatorname{Ran}(A)$ is of the second category. Any help would be appeciated!","I'm attempting a problem about closed range of a bounded linear operator. Assume $X, Y$ are Banach spaces and $A$ is a bounded linear operator.    If $\operatorname{Ran}(A)$ is of the second category,   then show that $\operatorname{Ran}(A)$ is closed. I want to use the Closed Graph Theorem and assume that $Ax_i \to y$ in $Y$, if we can show that $x_i \to x$ in $X$, then the result follows by continuity of $A$. But I'm having a hard time showing that $\{x_i\}$ is a convergent sequence in $X$, and don't know how to use the fact that $\operatorname{Ran}(A)$ is of the second category. Any help would be appeciated!",,['functional-analysis']
25,Homogeneous C*-algebras,Homogeneous C*-algebras,,"In a C*-algebras paper I've read recently, they state that every irreducible representation of the C*-algebra $C(X,\mathbb{C})$, where X is compact topological space, is 1-dimensional. They also state that every irreducible representation of $C(X,M_{n}(\mathbb{C}))$ is n-dimensional. (where again X is compact and $M_{n}(\mathbb{C})$ is C*-algebra of complex n*n matrices) They state these without proofs. Could you please help me how to prove these things, or tell me literature in which I can find proof/insight? Thanks.","In a C*-algebras paper I've read recently, they state that every irreducible representation of the C*-algebra $C(X,\mathbb{C})$, where X is compact topological space, is 1-dimensional. They also state that every irreducible representation of $C(X,M_{n}(\mathbb{C}))$ is n-dimensional. (where again X is compact and $M_{n}(\mathbb{C})$ is C*-algebra of complex n*n matrices) They state these without proofs. Could you please help me how to prove these things, or tell me literature in which I can find proof/insight? Thanks.",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
26,Description of projective and injective tensor products $\ell^2 \otimes \ell^2$?,Description of projective and injective tensor products ?,\ell^2 \otimes \ell^2,"The following question is probably too elementary and/or well-known for MathOverflow, so I'll try here: Let $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$ and $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$ refer to the (completed) projective and injective tensor products (as defined, say, in Wikipedia ), as Banach spaces, of the Hilbert space $\ell^2 = \{u\colon\mathbb{N}\to\mathbb{R} : \sum_{k=0}^{+\infty} u_k^2 < +\infty\}$ of square-summable sequences with itself. I understand that it is not easy to describe these spaces, but I wonder if it is still possible to give a reasonably concrete condition for a “sequence of sequences” (i.e., a function $\mathbb{N}^2 \to \mathbb{R}$) to belong to one or the other? More precisely, if we consider the continuous linear form $e_k^*\colon\ell^2\to\mathbb{R}$ which maps $u \in \ell^2$ to its $k$-th term $\langle u, e_k\rangle$, then the tensor product $e_m^* \otimes e_n^*$ defines a continuous linear form of norm $1$ on either $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$ or $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$, so an element $v$ in one of these spaces defines an array $J(v)\colon (m,n) \mapsto (e_m^* \otimes e_n^*)(v)$, which belongs to $\ell^\infty(\mathbb{N}^2)$ (the space of bounded functions $\mathbb{N}^2\to\mathbb{R}$).  This, in turn, defines a continuous linear map $J_\alpha \colon \ell^2 \mathbin{\hat\otimes_\alpha} \ell^2 \to \ell^\infty(\mathbb{N}^2)$ (of norm $1$) for $\alpha \in \{\pi,\varepsilon\}$.  I guess I have four questions: Is $J_\pi$ injective?  (Can $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$ be seen as a space of functions $\mathbb{N}^2\to\mathbb{R}$?) Is $J_\varepsilon$ injective?  (Can $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$ be seen as a space of functions $\mathbb{N}^2\to\mathbb{R}$?) What is the image of $J_\pi$?  (When does a function $\mathbb{N}^2\to\mathbb{R}$ belong to $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$?) What is the image of $J_\varepsilon$?  (When does a function $\mathbb{N}^2\to\mathbb{R}$ belong to $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$?)","The following question is probably too elementary and/or well-known for MathOverflow, so I'll try here: Let $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$ and $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$ refer to the (completed) projective and injective tensor products (as defined, say, in Wikipedia ), as Banach spaces, of the Hilbert space $\ell^2 = \{u\colon\mathbb{N}\to\mathbb{R} : \sum_{k=0}^{+\infty} u_k^2 < +\infty\}$ of square-summable sequences with itself. I understand that it is not easy to describe these spaces, but I wonder if it is still possible to give a reasonably concrete condition for a “sequence of sequences” (i.e., a function $\mathbb{N}^2 \to \mathbb{R}$) to belong to one or the other? More precisely, if we consider the continuous linear form $e_k^*\colon\ell^2\to\mathbb{R}$ which maps $u \in \ell^2$ to its $k$-th term $\langle u, e_k\rangle$, then the tensor product $e_m^* \otimes e_n^*$ defines a continuous linear form of norm $1$ on either $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$ or $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$, so an element $v$ in one of these spaces defines an array $J(v)\colon (m,n) \mapsto (e_m^* \otimes e_n^*)(v)$, which belongs to $\ell^\infty(\mathbb{N}^2)$ (the space of bounded functions $\mathbb{N}^2\to\mathbb{R}$).  This, in turn, defines a continuous linear map $J_\alpha \colon \ell^2 \mathbin{\hat\otimes_\alpha} \ell^2 \to \ell^\infty(\mathbb{N}^2)$ (of norm $1$) for $\alpha \in \{\pi,\varepsilon\}$.  I guess I have four questions: Is $J_\pi$ injective?  (Can $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$ be seen as a space of functions $\mathbb{N}^2\to\mathbb{R}$?) Is $J_\varepsilon$ injective?  (Can $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$ be seen as a space of functions $\mathbb{N}^2\to\mathbb{R}$?) What is the image of $J_\pi$?  (When does a function $\mathbb{N}^2\to\mathbb{R}$ belong to $\ell^2 \mathbin{\hat\otimes_\pi} \ell^2$?) What is the image of $J_\varepsilon$?  (When does a function $\mathbb{N}^2\to\mathbb{R}$ belong to $\ell^2 \mathbin{\hat\otimes_\varepsilon} \ell^2$?)",,"['functional-analysis', 'banach-spaces', 'tensor-products']"
27,Reality of the Spectrum of Unbounded Self-Adjoint Operators,Reality of the Spectrum of Unbounded Self-Adjoint Operators,,"Let $D$ be a closed unbounded operator densely defined on a Hilbert space $\cal{H}$. If $D$ is self-adjoint, then it is clear that its eigenvalues are real. Is it also clear that the elements of its spectrum are real?","Let $D$ be a closed unbounded operator densely defined on a Hilbert space $\cal{H}$. If $D$ is self-adjoint, then it is clear that its eigenvalues are real. Is it also clear that the elements of its spectrum are real?",,"['functional-analysis', 'operator-algebras', 'unbounded-operators']"
28,When $y(t) = \lambda x(t) - \int_{-1}^{1} (ts^2 + t^2 s^3 + t^3 s) x(s) ds$ has a solution?,When  has a solution?,y(t) = \lambda x(t) - \int_{-1}^{1} (ts^2 + t^2 s^3 + t^3 s) x(s) ds,The question is as follows: Estabilish conditions for the integral equation $$y(t) = \lambda x(t) - \int_{-1}^{1} (ts^2 + t^2 s^3 + t^3 s) x(s) ds$$ to have a solution. $\textbf{Definitions and efforts:}$ Actually I do not know what to do! It's my first of this kind and I am trying to learn! I just know that it is an integral equation which is said is Fredholm equation because the integration limits $a$ and $b$ are constants. Can someone please let me know how can we attack to this problem and what are techniques? Thanks!,The question is as follows: Estabilish conditions for the integral equation $$y(t) = \lambda x(t) - \int_{-1}^{1} (ts^2 + t^2 s^3 + t^3 s) x(s) ds$$ to have a solution. $\textbf{Definitions and efforts:}$ Actually I do not know what to do! It's my first of this kind and I am trying to learn! I just know that it is an integral equation which is said is Fredholm equation because the integration limits $a$ and $b$ are constants. Can someone please let me know how can we attack to this problem and what are techniques? Thanks!,,"['real-analysis', 'functional-analysis', 'integral-equations']"
29,Geometric Hahn-Banach theorem in complex case,Geometric Hahn-Banach theorem in complex case,,"A version of Hahn-Banach theorem says that in a real normed space, any closed convex subset is equal to the intersection of all closed half-spaces that contains it. Is there a similar statement in the complex case ? In other words is there a notion of half-space in a complex normed space (maybe by taking the real part of a linear form ?) that will give the same result in this case?","A version of Hahn-Banach theorem says that in a real normed space, any closed convex subset is equal to the intersection of all closed half-spaces that contains it. Is there a similar statement in the complex case ? In other words is there a notion of half-space in a complex normed space (maybe by taking the real part of a linear form ?) that will give the same result in this case?",,"['real-analysis', 'geometry', 'functional-analysis', 'convex-analysis']"
30,AF C*-Algebras and Continuous Functions on Totally Disconnected Sets,AF C*-Algebras and Continuous Functions on Totally Disconnected Sets,,"Why do the continuous functions on a totally disconnected set, such as the Cantor set, form an AF C$^*$-algebra?  Conversely, why do commutative AF C$^*$-algebras consist of continuous complex functions on a totally disconnected compact metrizable space?  I am new to operator theory and have only begun reading papers in the subject.  Both claims appear in different papers and I have not been able to find references for these results.","Why do the continuous functions on a totally disconnected set, such as the Cantor set, form an AF C$^*$-algebra?  Conversely, why do commutative AF C$^*$-algebras consist of continuous complex functions on a totally disconnected compact metrizable space?  I am new to operator theory and have only begun reading papers in the subject.  Both claims appear in different papers and I have not been able to find references for these results.",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'noncommutative-geometry']"
31,Differentiability of tempered distributions over $\mathbb{R}^3$,Differentiability of tempered distributions over,\mathbb{R}^3,"One of the topics I find interesting in physics is the time evolution of improper quantum states (physicists call them kets). My question to this mathematical community is: In what exact sense is a mapping $\phi:\mathbb{R}\to \mathcal{S}'(\mathbb{R}^3)$ , $t\mapsto\phi(t)$ continuous and furthermore differentiable in the variable/parameter "" $t$ ""? ( $\mathcal{S}'(\mathbb{R}^3)$ is of course the topological dual of the Schwartz test function space)","One of the topics I find interesting in physics is the time evolution of improper quantum states (physicists call them kets). My question to this mathematical community is: In what exact sense is a mapping , continuous and furthermore differentiable in the variable/parameter "" ""? ( is of course the topological dual of the Schwartz test function space)",\phi:\mathbb{R}\to \mathcal{S}'(\mathbb{R}^3) t\mapsto\phi(t) t \mathcal{S}'(\mathbb{R}^3),"['functional-analysis', 'distribution-theory']"
32,Maximal function is not bounded on $L^1(\Bbb R^n)$,Maximal function is not bounded on,L^1(\Bbb R^n),"Prove: There exists a constant $c_p,p>1$, with $c_p>{c}/{(p-1)}$, so that if $f$ in $L^p$ then $$\|Mf\|_P \ge c_p \|f\|_P$$. This is a problem in E.M stein's Harmonic analysis(8.14(b)). I can prove 8.14(a) that if $f$ is supported in a set of finite measure, then $Mf$ in $L_1$ iff $|f|log(1+|f|)$ in $L_1$. I prove 8.14(a) by using Calderon-Zygmund decomposition. I am not really sure where to begin with 8.14(b). Any help would be greatly appreciated.","Prove: There exists a constant $c_p,p>1$, with $c_p>{c}/{(p-1)}$, so that if $f$ in $L^p$ then $$\|Mf\|_P \ge c_p \|f\|_P$$. This is a problem in E.M stein's Harmonic analysis(8.14(b)). I can prove 8.14(a) that if $f$ is supported in a set of finite measure, then $Mf$ in $L_1$ iff $|f|log(1+|f|)$ in $L_1$. I prove 8.14(a) by using Calderon-Zygmund decomposition. I am not really sure where to begin with 8.14(b). Any help would be greatly appreciated.",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'lp-spaces', 'harmonic-analysis']"
33,Sorgenfrey Line is not a topological vector space,Sorgenfrey Line is not a topological vector space,,"Show that Sorgenfrey line is not a topological vector space. My attempt: We know that if $X$ is a topological vector space, then the map $$x\mapsto \alpha x$$ is a homeomorphism for each scalar $\alpha \neq 0.$ Hence, open sets under this map are mapped to open sets. In Sorgenfrey line, the set $A=[1,2)$ is open. But $-2A=(-4,-2]$ is not open. Therefore, Sorgenfrey line is not a topological vector space. Am I correct?","Show that Sorgenfrey line is not a topological vector space. My attempt: We know that if $X$ is a topological vector space, then the map $$x\mapsto \alpha x$$ is a homeomorphism for each scalar $\alpha \neq 0.$ Hence, open sets under this map are mapped to open sets. In Sorgenfrey line, the set $A=[1,2)$ is open. But $-2A=(-4,-2]$ is not open. Therefore, Sorgenfrey line is not a topological vector space. Am I correct?",,"['functional-analysis', 'topological-vector-spaces', 'sorgenfrey-line']"
34,"Prove that $D:C^1[0,1]\to C[0,1]$ is not continuous.",Prove that  is not continuous.,"D:C^1[0,1]\to C[0,1]","Let $C^1[0,1]$ be the space of continuous real valued functions on $[0,1]$ with continuous first derivative. Let $D:C^1[0,1]\to C[0,1]$ be the differentiation operator given by $D(f)(x)=f^\prime(x),\forall x\in [0,1]$. Suppose both spaces are given the sup norm $\|.\|_\infty$. Now it is required to prove that $D$ is not continuous. The following is my attempt: $D$ is a linear operator by the properties of differentiation. Hence $D$ is continuous if and only if $D$ is bounded on $C^1[0,1]$. Suppose $D$ is bounded. Then there exists $k>0$ such that for each $f\in C^1[0,1]$, $\|D(f)(x)\|_\infty\leq k\|f(x)\|_\infty$, i.e. $\|f'(x)\|_\infty\leq k\|f(x)\|_\infty$. Consider the function $g(x)=\sin(357kx)$ for each $x\in[0,1]$. Clearly $g\in C^1[0,1]$. Therefore $357k\leq\|g'(x)\|_\infty\leq k\|g(x)\|_\infty \leq k.1=k$ which is a contradiction. Therefore $D$ is not bounded and hence not continuous. Could someone please tell me if my argument is correct? Thanks.","Let $C^1[0,1]$ be the space of continuous real valued functions on $[0,1]$ with continuous first derivative. Let $D:C^1[0,1]\to C[0,1]$ be the differentiation operator given by $D(f)(x)=f^\prime(x),\forall x\in [0,1]$. Suppose both spaces are given the sup norm $\|.\|_\infty$. Now it is required to prove that $D$ is not continuous. The following is my attempt: $D$ is a linear operator by the properties of differentiation. Hence $D$ is continuous if and only if $D$ is bounded on $C^1[0,1]$. Suppose $D$ is bounded. Then there exists $k>0$ such that for each $f\in C^1[0,1]$, $\|D(f)(x)\|_\infty\leq k\|f(x)\|_\infty$, i.e. $\|f'(x)\|_\infty\leq k\|f(x)\|_\infty$. Consider the function $g(x)=\sin(357kx)$ for each $x\in[0,1]$. Clearly $g\in C^1[0,1]$. Therefore $357k\leq\|g'(x)\|_\infty\leq k\|g(x)\|_\infty \leq k.1=k$ which is a contradiction. Therefore $D$ is not bounded and hence not continuous. Could someone please tell me if my argument is correct? Thanks.",,"['functional-analysis', 'proof-verification']"
35,"If $ \Omega $ is a bounded domain, is a $ BV(\Omega) $ function also $ L^\infty(\Omega) $?","If  is a bounded domain, is a  function also ?", \Omega   BV(\Omega)   L^\infty(\Omega) ,"Let $ \Omega $ be a (non-empty) bounded domain. The space of functions of bounded variation is defined by  $$ BV(\Omega) = \{ u\in L^1(\Omega) \mid \|u\|_{TV} < \infty \} $$ where  $$ |u|_{TV} = \sup\left\{ \int_\Omega u\operatorname{div}\phi\,dx \mid \phi \in C_c^1(\Omega), |\phi|\leq 1 \right\}. $$ Does $ u \in BV(\Omega) $ imply that $ u \in L^\infty(\Omega) $, i.e. is it the case that $ BV(\Omega) \subset L^\infty(\Omega) $? In case it isn't true, then $ \operatorname{ess}\sup_{x\in\Omega} |u(x)| = \infty $. $ u $ being infinite everywhere whould make the TV-norm infinite, which is a contradiction, so $ u $ must be finite somewhere, say at $ y $. I feel like this jump from finiteness at $ y $ to whereever the essential supremum is attained should make the TV-norm infinite again, thus contradicting my initial assumption. However, I have no clue so far about how to go about it technically. Maybe my gut feeling is just plain wrong?","Let $ \Omega $ be a (non-empty) bounded domain. The space of functions of bounded variation is defined by  $$ BV(\Omega) = \{ u\in L^1(\Omega) \mid \|u\|_{TV} < \infty \} $$ where  $$ |u|_{TV} = \sup\left\{ \int_\Omega u\operatorname{div}\phi\,dx \mid \phi \in C_c^1(\Omega), |\phi|\leq 1 \right\}. $$ Does $ u \in BV(\Omega) $ imply that $ u \in L^\infty(\Omega) $, i.e. is it the case that $ BV(\Omega) \subset L^\infty(\Omega) $? In case it isn't true, then $ \operatorname{ess}\sup_{x\in\Omega} |u(x)| = \infty $. $ u $ being infinite everywhere whould make the TV-norm infinite, which is a contradiction, so $ u $ must be finite somewhere, say at $ y $. I feel like this jump from finiteness at $ y $ to whereever the essential supremum is attained should make the TV-norm infinite again, thus contradicting my initial assumption. However, I have no clue so far about how to go about it technically. Maybe my gut feeling is just plain wrong?",,"['functional-analysis', 'bounded-variation', 'total-variation']"
36,"Let $T(x_n)_{n \in \mathbb Z} = (x_{n+1})_{n \in \mathbb Z}$, proof that $\sigma(T) = S^1$.","Let , proof that .",T(x_n)_{n \in \mathbb Z} = (x_{n+1})_{n \in \mathbb Z} \sigma(T) = S^1,"Consider the unit operator $T: \ell^2(\mathbb Z) \to \ell^2(\mathbb Z), \, T(x_n)_{n \in \mathbb Z} = (x_{n+1})_{n \in \mathbb Z}$ .  I'm trying to understand the proof that $\sigma(T) = S^1$ given here . First we have the following results: $\forall \lambda \in \mathbb C, T - \lambda I$ is injective. If $E$ is a Banach Space, $S \in \mathcal B(E), z \in \mathbb C, z \neq 0, \, \sigma(zS) = z\sigma(S)$ . If $S,U \in \mathcal B(E), \, \sigma(U^{-1}SU) = \sigma(S)$ . Given $z \in S^1$ , we define the bounded operator in $\ell^2(\mathbb Z)$ , $$M_z(x_n)_{n \in \mathbb Z} = (...,\overline z ^{2}x_{-2}, \overline z ^{-1}x_{-1},x_0, zx_1, z^2 x_2,...).$$ Then, we have that $M_z^{-1}T M_z= zT$ . So, for each $z \in S^1$ , $$ \sigma(T) = \sigma(M_z ^{-1}T M_z) = \sigma(zT) = z\sigma(T). $$ In the proof given in the above link, Jonas Meyer used that exists $z_0 \in \sigma(T)$ with $|z_0| = 1.$ However, I couldn't see why this happens. QUESTION: If $|\lambda| < 1$ , how one can proof that $T - \lambda I$ is invertible? In particular, the above question implies in $\sigma(T) S^1$ , since $\sigma(T) \subset B[0, 1]$ . With this, I can conclude the argument, as follows: Since $\sigma(T) \neq \emptyset$ , then $\exists z_0 \in \sigma(T)$ . Given $z \in S^1$ , we have that $\sigma(T) = z\overline{z_0}\sigma(T)$ . Hence, $$ z_0 \in \sigma(T) \Rightarrow z = z(\overline{z_0}z_0) (z\overline{z_0})z_0 \in  z\overline{z_0}\sigma(T) = \sigma(T) \Rightarrow S^1\subset \sigma(T).$$ Help?","Consider the unit operator .  I'm trying to understand the proof that given here . First we have the following results: is injective. If is a Banach Space, . If . Given , we define the bounded operator in , Then, we have that . So, for each , In the proof given in the above link, Jonas Meyer used that exists with However, I couldn't see why this happens. QUESTION: If , how one can proof that is invertible? In particular, the above question implies in , since . With this, I can conclude the argument, as follows: Since , then . Given , we have that . Hence, Help?","T: \ell^2(\mathbb Z) \to \ell^2(\mathbb Z), \, T(x_n)_{n \in \mathbb Z} = (x_{n+1})_{n \in \mathbb Z} \sigma(T) = S^1 \forall \lambda \in \mathbb C, T - \lambda I E S \in \mathcal B(E), z \in \mathbb C, z \neq 0, \, \sigma(zS) = z\sigma(S) S,U \in \mathcal B(E), \, \sigma(U^{-1}SU) = \sigma(S) z \in S^1 \ell^2(\mathbb Z) M_z(x_n)_{n \in \mathbb Z} = (...,\overline z ^{2}x_{-2}, \overline z ^{-1}x_{-1},x_0, zx_1, z^2 x_2,...). M_z^{-1}T M_z= zT z \in S^1  \sigma(T) = \sigma(M_z ^{-1}T M_z) = \sigma(zT) = z\sigma(T).  z_0 \in \sigma(T) |z_0| = 1. |\lambda| < 1 T - \lambda I \sigma(T) S^1 \sigma(T) \subset B[0, 1] \sigma(T) \neq \emptyset \exists z_0 \in \sigma(T) z \in S^1 \sigma(T) = z\overline{z_0}\sigma(T)  z_0 \in \sigma(T) \Rightarrow z = z(\overline{z_0}z_0) (z\overline{z_0})z_0 \in  z\overline{z_0}\sigma(T) = \sigma(T) \Rightarrow S^1\subset \sigma(T).","['functional-analysis', 'operator-theory']"
37,What is the Fourier transform of a functional?,What is the Fourier transform of a functional?,,"Generally Fourier transforms are defined as follows: $$ F(s)=\int dxf(x)e^{-isx}.$$ Similarly, is it possible to define Fourier transform for a functional $\psi[\phi(x)]$ ?","Generally Fourier transforms are defined as follows: Similarly, is it possible to define Fourier transform for a functional ?", F(s)=\int dxf(x)e^{-isx}. \psi[\phi(x)],"['functional-analysis', 'fourier-transform']"
38,Limit of $n$-Cesaro summation as $n \to \infty$,Limit of -Cesaro summation as,n n \to \infty,"I recently learned that a Cesaro summation extends the usual summation in the following way:  Given a sequence $a_1, a_2, \ldots $ we construct the Cesaro sequence by defining $$\sigma_n = \frac{1}{n}\sum_{j=1}^n a_j$$ Then we say that $(a_j)$ is Cesaro summable if $\sigma_n$ coverages to some point. Now let's relabel the sequence $(\sigma_j)$ as $(\sigma^{1}_j)$, and say $(a_j)$ is $1$-Cesaro summable if it is Cesaro summable. We could, obviously, construct a new Cesaro sequence, call it $(\sigma^2_j)$, which is the Cesaro sequence of the original Cesaro sequence.  Then we say the sequence $(a_j)$ is $n$-Cesaro summable if the sequence $(\sigma^{n-1}_j)$ is Cesaro summable.  Clearly if a sequence is $n$-Cesaro summable then it is $j$-Cesaro summable for all $j\ge n$. Question:  Is there a proper way to define $\infty$-Cesaro summability? Are there sequences which are not $n$-Cesaro summable for any finite $n$ yet are $\infty$-Cesaro summable?  Finally, a good definition would require the existence of sequences which are not $\infty$-Cesaro.","I recently learned that a Cesaro summation extends the usual summation in the following way:  Given a sequence $a_1, a_2, \ldots $ we construct the Cesaro sequence by defining $$\sigma_n = \frac{1}{n}\sum_{j=1}^n a_j$$ Then we say that $(a_j)$ is Cesaro summable if $\sigma_n$ coverages to some point. Now let's relabel the sequence $(\sigma_j)$ as $(\sigma^{1}_j)$, and say $(a_j)$ is $1$-Cesaro summable if it is Cesaro summable. We could, obviously, construct a new Cesaro sequence, call it $(\sigma^2_j)$, which is the Cesaro sequence of the original Cesaro sequence.  Then we say the sequence $(a_j)$ is $n$-Cesaro summable if the sequence $(\sigma^{n-1}_j)$ is Cesaro summable.  Clearly if a sequence is $n$-Cesaro summable then it is $j$-Cesaro summable for all $j\ge n$. Question:  Is there a proper way to define $\infty$-Cesaro summability? Are there sequences which are not $n$-Cesaro summable for any finite $n$ yet are $\infty$-Cesaro summable?  Finally, a good definition would require the existence of sequences which are not $\infty$-Cesaro.",,"['functional-analysis', 'cesaro-summable']"
39,Distance from a point to a closed subspace,Distance from a point to a closed subspace,,"Let $H$ be a Hilbert space, $a\in H$ and $H_0$ be a closed subspace of $H$. Is it true that $d(a,H_0)=\max\{\langle u,a\rangle: \|u\|=1,\, u\in H_0^\perp\}$?","Let $H$ be a Hilbert space, $a\in H$ and $H_0$ be a closed subspace of $H$. Is it true that $d(a,H_0)=\max\{\langle u,a\rangle: \|u\|=1,\, u\in H_0^\perp\}$?",,"['functional-analysis', 'hilbert-spaces']"
40,Reflective subcategories of topological vector spaces,Reflective subcategories of topological vector spaces,,"Let $\mathsf{TopVect}$ be the category of TVS over $\mathbb K\in \{\mathbb R, \mathbb C\}$ with continuous linear maps as morphisms. Do the normed spaces or locally convex spaces form a reflective   subcategory of $\mathsf{TopVect}$? (in the latter case: do normed   spaces form a reflective subcategory of the locally convex spaces?). Basically: can you ""complete"" a TVS to a locally convex / normed space? I have virtually zero intution regarding this topic, but answering these questions might help with this question .","Let $\mathsf{TopVect}$ be the category of TVS over $\mathbb K\in \{\mathbb R, \mathbb C\}$ with continuous linear maps as morphisms. Do the normed spaces or locally convex spaces form a reflective   subcategory of $\mathsf{TopVect}$? (in the latter case: do normed   spaces form a reflective subcategory of the locally convex spaces?). Basically: can you ""complete"" a TVS to a locally convex / normed space? I have virtually zero intution regarding this topic, but answering these questions might help with this question .",,"['functional-analysis', 'category-theory']"
41,Poisson equation as a limit of Helmholtz equation,Poisson equation as a limit of Helmholtz equation,,"Assuming I can solve Helmholtz equation: $$ \nabla^2 \phi(\textbf r) - \kappa^2 \phi(\textbf r) = f(\textbf r), $$ with some given boundary conditions, where $f(\textbf r)$ is some given source.  If I take a limit of the solution when $\kappa \to 0$ am I always guaranteed to obtain the correct solution of the corresponding Poisson equation $$ \nabla^2 \phi(\textbf r) = f(\textbf r), $$ assuming the same boundary conditions?  Are there some contra examples where this would not be the case, e.g. $f$ is constant and we have an infinite volume or something. In other words, is there an example where for some setup we would not have $$ \phi_{P}(\textbf r) = \lim_{\kappa \to 0}  \phi_{H}(\textbf r)? $$","Assuming I can solve Helmholtz equation: $$ \nabla^2 \phi(\textbf r) - \kappa^2 \phi(\textbf r) = f(\textbf r), $$ with some given boundary conditions, where $f(\textbf r)$ is some given source.  If I take a limit of the solution when $\kappa \to 0$ am I always guaranteed to obtain the correct solution of the corresponding Poisson equation $$ \nabla^2 \phi(\textbf r) = f(\textbf r), $$ assuming the same boundary conditions?  Are there some contra examples where this would not be the case, e.g. $f$ is constant and we have an infinite volume or something. In other words, is there an example where for some setup we would not have $$ \phi_{P}(\textbf r) = \lim_{\kappa \to 0}  \phi_{H}(\textbf r)? $$",,"['functional-analysis', 'ordinary-differential-equations']"
42,"What do we need Sobolev-spaces $W^{k, p}$ with $p \neq 2$ for?",What do we need Sobolev-spaces  with  for?,"W^{k, p} p \neq 2","In the course on PDE's I took this semester we talked a lot about the theory of Sobolev-spaces $W^{k, p}(\Omega)$ for $\Omega \subset \mathbf{R}^n$ an open set, $k \in \mathbf{N}$ and $1 \leq p \leq \infty$. But then we only used the Sobolev-spaces with $p = 2$ to deal with PDE's, since we can use the Riesz-Representation theorem on a suitable subspace of $W^{k, 2}(\Omega)$ (which is a Hilbert-space). For $p \neq 2$, we can't use the Riesz-Representation theorem, so we don't get weak solutions for $W^{k, p}(\Omega)$. My question now is: Why do we introduce general Sobolev-spaces, instead of just limiting ourselves to $W^{k, 2}(\Omega)$? Are there any applications to the theory of PDE's (or other parts of mathematics) of Sobolev-spaces with $p \neq 2$? Thanks!","In the course on PDE's I took this semester we talked a lot about the theory of Sobolev-spaces $W^{k, p}(\Omega)$ for $\Omega \subset \mathbf{R}^n$ an open set, $k \in \mathbf{N}$ and $1 \leq p \leq \infty$. But then we only used the Sobolev-spaces with $p = 2$ to deal with PDE's, since we can use the Riesz-Representation theorem on a suitable subspace of $W^{k, 2}(\Omega)$ (which is a Hilbert-space). For $p \neq 2$, we can't use the Riesz-Representation theorem, so we don't get weak solutions for $W^{k, p}(\Omega)$. My question now is: Why do we introduce general Sobolev-spaces, instead of just limiting ourselves to $W^{k, 2}(\Omega)$? Are there any applications to the theory of PDE's (or other parts of mathematics) of Sobolev-spaces with $p \neq 2$? Thanks!",,"['real-analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
43,Distributivity in boolean subalgebras of orthomodular lattice,Distributivity in boolean subalgebras of orthomodular lattice,,"A boolean subalgebra $B$ of the orthomodular lattice $L$ of closed subspaces of a separable Hilbert space, may be defined like a sublattice with $0$ and $1$, with pairwise commuting elements. How to prove that, in this subalgebra, the distributive property holds?","A boolean subalgebra $B$ of the orthomodular lattice $L$ of closed subspaces of a separable Hilbert space, may be defined like a sublattice with $0$ and $1$, with pairwise commuting elements. How to prove that, in this subalgebra, the distributive property holds?",,"['abstract-algebra', 'functional-analysis', 'boolean-algebra', 'lattice-orders']"
44,Orthogonal polynomials of the second kind,Orthogonal polynomials of the second kind,,"Let $L:  \mathbb{R}[x] \rightarrow \mathbb{R}$ be a positive definite linear functional and let that $\{s_n\}$ be a positive semi-definite sequence such that $$L(x^n)= s_n, n\ge 0$$ and $$<p,q> = L(pq).$$ Given a positive definite sequence, we use the Gram-Schimdt orthogonalization method to construct a sequence of orthogonal polynomials $\{p_n\}$ whose leading coefficient is positive due to the  positivity nature of the sequence given. It turns out that this sequence of orthogonal polynomials  $\{p_n\}$ satsifies a three term recurrence relation given below \begin{equation} xp_n(x) =b_np_{n+1}(x)+a_np_n(x)+b_{n-1}p_{n-1}(x) , \quad n\ge 0 \end{equation} We can see the sequence $p_n(x)$ as a solution to the three term recurrence relations stated above. Akhiezer http://www.maths.ed.ac.uk/~aar/papers/akhiezer.pdf as my reference introduced another solution to this three term recurrence relation by defining another solution by \begin{equation} q_n(x)= \displaystyle L\left(\frac{p_n(x)-p_n(y)}{x-y}\right) \end{equation} where the  quotient $\frac{p_n(x)-p_n(y)}{x-y}$  is a polynomial in $x$ and $y$ and $q_n(x)$ is a polynomial in variable $x$ and its degree is $n-1$ for any $x,y \in \mathbb{R}$ so that we have $ \displaystyle xq_n(x) =b_nq_{n+1}(x)+a_nq_n(x)+b_{n-1}q_{n-1}(x), n\ge 1$ with $q_0(x)=0$ and $q_1(x)= \frac{1}{b_0}$ Question: Akhiezer claimed that this sequence of polynomials $\{q_n\}$ is orthogonal. I dont understand how this is true. Can anyone please show me what this true? PS: Recall that $$<p,q> = L(pq)$$ defines an inner product","Let $L:  \mathbb{R}[x] \rightarrow \mathbb{R}$ be a positive definite linear functional and let that $\{s_n\}$ be a positive semi-definite sequence such that $$L(x^n)= s_n, n\ge 0$$ and $$<p,q> = L(pq).$$ Given a positive definite sequence, we use the Gram-Schimdt orthogonalization method to construct a sequence of orthogonal polynomials $\{p_n\}$ whose leading coefficient is positive due to the  positivity nature of the sequence given. It turns out that this sequence of orthogonal polynomials  $\{p_n\}$ satsifies a three term recurrence relation given below \begin{equation} xp_n(x) =b_np_{n+1}(x)+a_np_n(x)+b_{n-1}p_{n-1}(x) , \quad n\ge 0 \end{equation} We can see the sequence $p_n(x)$ as a solution to the three term recurrence relations stated above. Akhiezer http://www.maths.ed.ac.uk/~aar/papers/akhiezer.pdf as my reference introduced another solution to this three term recurrence relation by defining another solution by \begin{equation} q_n(x)= \displaystyle L\left(\frac{p_n(x)-p_n(y)}{x-y}\right) \end{equation} where the  quotient $\frac{p_n(x)-p_n(y)}{x-y}$  is a polynomial in $x$ and $y$ and $q_n(x)$ is a polynomial in variable $x$ and its degree is $n-1$ for any $x,y \in \mathbb{R}$ so that we have $ \displaystyle xq_n(x) =b_nq_{n+1}(x)+a_nq_n(x)+b_{n-1}q_{n-1}(x), n\ge 1$ with $q_0(x)=0$ and $q_1(x)= \frac{1}{b_0}$ Question: Akhiezer claimed that this sequence of polynomials $\{q_n\}$ is orthogonal. I dont understand how this is true. Can anyone please show me what this true? PS: Recall that $$<p,q> = L(pq)$$ defines an inner product",,"['real-analysis', 'linear-algebra', 'functional-analysis', 'operator-algebras', 'moment-problem']"
45,Is the nuclear norm equal to the Hilbert-Schmidt norm for a particular operator?,Is the nuclear norm equal to the Hilbert-Schmidt norm for a particular operator?,,"Suppose that $\varphi,\gamma\in L^2([0,1],\mathbb C)$ and define the operator $\varphi\otimes\gamma:L^2([0,1],\mathbb C)\to L^2([0,1],\mathbb C)$ by setting $\varphi\otimes\gamma=\langle\cdot,\gamma\rangle\varphi$. This is an integral operator with the kernel given by $\varphi(x)\overline\gamma(y)$ for each $x,y\in [0,1]$. Hence, the Hilbert-Schmidt norm of this operator is given by $$ \|\varphi\otimes\gamma\|_{HS}=\biggl(\int_0^1\int_0^1|\varphi(x)\overline\gamma(y)|^2dxdy\biggr)^{1/2}=\|\varphi\|\|\gamma\|. $$ I want to find the singular values of this operator so that I can obtain the nuclear norm. Since the adjoint of $\varphi\otimes\gamma$ is given by $\gamma\otimes\varphi$, we have that $$ (\varphi\otimes\gamma)^*(\varphi\otimes\gamma)(f)=\langle f,\gamma\rangle\|\varphi\|^2\gamma $$ and if we set $f=\gamma/\|\gamma\|$, we obtain $$ (\varphi\otimes\gamma)^*(\varphi\otimes\gamma)(\gamma\|\gamma\|)=\|\varphi\|^2\|\gamma\|^2\gamma/\|\gamma\|. $$ The composition of operators $(\varphi\otimes\gamma)^*(\varphi\otimes\gamma)$ has one non-zero eigenfunction $\gamma/\|\gamma\|$ with the corresponding eigenvalue $\|\varphi\|^2\|\gamma\|^2$. Hence, the operator $\varphi\otimes\gamma$ has one non-zero singular value given by $\|\varphi\|\|\gamma\|$ and the nuclear norm of $\varphi\otimes\gamma$ is equal to $\|\varphi\|\|\gamma\|$, which is also the Hilbert-Schmidt of this operator. Are my calculations correct? Does the composition of operators $(\varphi\otimes\gamma)^*(\varphi\otimes\gamma)$ have only one non-zero eigenfunction and the corresponding non-zero eigenvalue? Are the Hilbert-Schmidt and the nuclear norms really equal for this operator? Any help is much appreciated!","Suppose that $\varphi,\gamma\in L^2([0,1],\mathbb C)$ and define the operator $\varphi\otimes\gamma:L^2([0,1],\mathbb C)\to L^2([0,1],\mathbb C)$ by setting $\varphi\otimes\gamma=\langle\cdot,\gamma\rangle\varphi$. This is an integral operator with the kernel given by $\varphi(x)\overline\gamma(y)$ for each $x,y\in [0,1]$. Hence, the Hilbert-Schmidt norm of this operator is given by $$ \|\varphi\otimes\gamma\|_{HS}=\biggl(\int_0^1\int_0^1|\varphi(x)\overline\gamma(y)|^2dxdy\biggr)^{1/2}=\|\varphi\|\|\gamma\|. $$ I want to find the singular values of this operator so that I can obtain the nuclear norm. Since the adjoint of $\varphi\otimes\gamma$ is given by $\gamma\otimes\varphi$, we have that $$ (\varphi\otimes\gamma)^*(\varphi\otimes\gamma)(f)=\langle f,\gamma\rangle\|\varphi\|^2\gamma $$ and if we set $f=\gamma/\|\gamma\|$, we obtain $$ (\varphi\otimes\gamma)^*(\varphi\otimes\gamma)(\gamma\|\gamma\|)=\|\varphi\|^2\|\gamma\|^2\gamma/\|\gamma\|. $$ The composition of operators $(\varphi\otimes\gamma)^*(\varphi\otimes\gamma)$ has one non-zero eigenfunction $\gamma/\|\gamma\|$ with the corresponding eigenvalue $\|\varphi\|^2\|\gamma\|^2$. Hence, the operator $\varphi\otimes\gamma$ has one non-zero singular value given by $\|\varphi\|\|\gamma\|$ and the nuclear norm of $\varphi\otimes\gamma$ is equal to $\|\varphi\|\|\gamma\|$, which is also the Hilbert-Schmidt of this operator. Are my calculations correct? Does the composition of operators $(\varphi\otimes\gamma)^*(\varphi\otimes\gamma)$ have only one non-zero eigenfunction and the corresponding non-zero eigenvalue? Are the Hilbert-Schmidt and the nuclear norms really equal for this operator? Any help is much appreciated!",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators', 'nuclear-norm']"
46,unitization is complete,unitization is complete,,"Let $A$ be a nonunital $C^*$-algebra, $A^1=A\oplus \mathbb{C}$ as $\mathbb{C}$-vector space. Let $A^1$ be endowed with $(a+\lambda1)^*=a^*+\overline{\lambda}1$ as the involution and $(a+\lambda1)(b+\mu1)=ab+\mu a+\lambda b+\lambda\mu$ as the multiplication. We obtain a unital *-Algebra with unit $(0,1)$. A $C^*$-norm in $A^1$ is defined as follows: consider following *-homomorphism: $$L:A^1\to B(A),\; L_{(a+\lambda 1)}(b)=ab+\lambda b\in A$$for $a+\lambda 1\in A^1$ and $b\in A$. We define $$\|a+\lambda 1\|_{A^1}:=\|L_{(a+\lambda 1)}\|_{op}.$$ How to prove that $A^1$ is complete w.r.t. this norm? My guess is to start as follows: Let $(x_n)_n\subseteq A^1$ be a cauchy sequence, write $x_n=a_n+\lambda_n1$ for $n\in\mathbb{N}$. Can I conclude that $(a_n)_n$ is a cauchy sequence in $A$ and $(\lambda_n)_n$ a Cauchy sequence in $\mathbb{C}$? If yes, then the completeness for $A^1$ follows, since: Is $a$ the limit of $(a_n)_n$ in $A$ and $\lambda$ the limit of $(\lambda_n)_n$ in $\mathbb{C}$, write $x:=a+\lambda1$. For every $b\in B$, it follows: $\|(a_n-a)b+(\lambda_n -\lambda)b\|_{A}\le \|(a_n-a)\|\|b\|+|\lambda_n -\lambda|\|b\|\to 0$ for $n\to\infty$. If not, how to prove the completeness?","Let $A$ be a nonunital $C^*$-algebra, $A^1=A\oplus \mathbb{C}$ as $\mathbb{C}$-vector space. Let $A^1$ be endowed with $(a+\lambda1)^*=a^*+\overline{\lambda}1$ as the involution and $(a+\lambda1)(b+\mu1)=ab+\mu a+\lambda b+\lambda\mu$ as the multiplication. We obtain a unital *-Algebra with unit $(0,1)$. A $C^*$-norm in $A^1$ is defined as follows: consider following *-homomorphism: $$L:A^1\to B(A),\; L_{(a+\lambda 1)}(b)=ab+\lambda b\in A$$for $a+\lambda 1\in A^1$ and $b\in A$. We define $$\|a+\lambda 1\|_{A^1}:=\|L_{(a+\lambda 1)}\|_{op}.$$ How to prove that $A^1$ is complete w.r.t. this norm? My guess is to start as follows: Let $(x_n)_n\subseteq A^1$ be a cauchy sequence, write $x_n=a_n+\lambda_n1$ for $n\in\mathbb{N}$. Can I conclude that $(a_n)_n$ is a cauchy sequence in $A$ and $(\lambda_n)_n$ a Cauchy sequence in $\mathbb{C}$? If yes, then the completeness for $A^1$ follows, since: Is $a$ the limit of $(a_n)_n$ in $A$ and $\lambda$ the limit of $(\lambda_n)_n$ in $\mathbb{C}$, write $x:=a+\lambda1$. For every $b\in B$, it follows: $\|(a_n-a)b+(\lambda_n -\lambda)b\|_{A}\le \|(a_n-a)\|\|b\|+|\lambda_n -\lambda|\|b\|\to 0$ for $n\to\infty$. If not, how to prove the completeness?",,['functional-analysis']
47,finite dimensional function space,finite dimensional function space,,"I'm studying Arzela-Ascoli (particularly as a generalization of Bolzano-Weierstrass) and am wondering how to think of functions as generalizations of points in $\mathbb{R}^k$. Specifically, I'm looking for intuition motivated by basic linear algebra ideas (bases, relations between different dimensions of the space). So if I'm building toward understanding infinite dimensional function spaces, can you first describe how we move from $\mathbb{R}^k$ to finite dimensional function spaces as an intermediate step (particularly emphasizing the role of equicontinuity)?","I'm studying Arzela-Ascoli (particularly as a generalization of Bolzano-Weierstrass) and am wondering how to think of functions as generalizations of points in $\mathbb{R}^k$. Specifically, I'm looking for intuition motivated by basic linear algebra ideas (bases, relations between different dimensions of the space). So if I'm building toward understanding infinite dimensional function spaces, can you first describe how we move from $\mathbb{R}^k$ to finite dimensional function spaces as an intermediate step (particularly emphasizing the role of equicontinuity)?",,"['linear-algebra', 'functional-analysis']"
48,Is completeness a necessary assumption for the Birkhoff Transitivity Theorem?,Is completeness a necessary assumption for the Birkhoff Transitivity Theorem?,,"The Birkhoff Transitivity Theorem asserts that any dynamical system $T:X \to X$ on a complete separable metric space without isolated points is topologically transitive if and only if there is a point with dense orbit. A friend of mine and me were discussing whether completeness is a necessary assumption, but couldn't come up with a counterexample. We tried the restricted doubling map to the rationals mod $1$, but finding the obstruction seems rather hard, as the Baire Category Theorem is non-constructive. Does anyone know a counterexample? Thanks a lot!","The Birkhoff Transitivity Theorem asserts that any dynamical system $T:X \to X$ on a complete separable metric space without isolated points is topologically transitive if and only if there is a point with dense orbit. A friend of mine and me were discussing whether completeness is a necessary assumption, but couldn't come up with a counterexample. We tried the restricted doubling map to the rationals mod $1$, but finding the obstruction seems rather hard, as the Baire Category Theorem is non-constructive. Does anyone know a counterexample? Thanks a lot!",,"['real-analysis', 'functional-analysis', 'dynamical-systems', 'topological-dynamics']"
49,Show that a function is in Bergman space,Show that a function is in Bergman space,,"Consider the Bergman space $A^2(\mathbb{D})$, where $\mathbb{D}$ is the open unit disk in $\mathbb{C}$. Show that if $\sum_{n=0}^\infty |a_n|^2$ converges, then $\sum_{n=0}^\infty (n+1)^{1/2} a_n z^n$ is holomorphic in $\mathbb{D}$. I want to show $f(z)=\sum_{n=0}^\infty (n+1)^{1/2} a_n z^n$ is also in $A^2(\mathbb{D})$. I know that $\{e_n=\sqrt{\frac{n+1}{\pi}}z^n\}_{n\geq0}$ is an orthonormal basis of $A^2(\mathbb{D})$. Therefore I want to show that $f =\sum_{n=0}^\infty \langle f, e_n\rangle e_n$ $\langle f,e_n \rangle=\int_0^1 f \overline{e_n}dz = \int_0^1 \overline{\sqrt{\frac{n+1}{\pi}}z^n}\sum_{k=0}^\infty (k+1)^{1/2} a_n z^k dz$ Is this approach correct? I feel like I am complicating the problem. Why do we need $\sum |a_n|^2$ converges?","Consider the Bergman space $A^2(\mathbb{D})$, where $\mathbb{D}$ is the open unit disk in $\mathbb{C}$. Show that if $\sum_{n=0}^\infty |a_n|^2$ converges, then $\sum_{n=0}^\infty (n+1)^{1/2} a_n z^n$ is holomorphic in $\mathbb{D}$. I want to show $f(z)=\sum_{n=0}^\infty (n+1)^{1/2} a_n z^n$ is also in $A^2(\mathbb{D})$. I know that $\{e_n=\sqrt{\frac{n+1}{\pi}}z^n\}_{n\geq0}$ is an orthonormal basis of $A^2(\mathbb{D})$. Therefore I want to show that $f =\sum_{n=0}^\infty \langle f, e_n\rangle e_n$ $\langle f,e_n \rangle=\int_0^1 f \overline{e_n}dz = \int_0^1 \overline{\sqrt{\frac{n+1}{\pi}}z^n}\sum_{k=0}^\infty (k+1)^{1/2} a_n z^k dz$ Is this approach correct? I feel like I am complicating the problem. Why do we need $\sum |a_n|^2$ converges?",,"['functional-analysis', 'bergman-spaces']"
50,Eigenvalues of self-adjoint extension of the Laplacian,Eigenvalues of self-adjoint extension of the Laplacian,,"Consider the Laplace operator $-\Delta$ on $L^2(\mathbb{R}^3)$ with domain $C_0^{\infty}(\mathbb{R}^3 \backslash \{ 0 \})$, the smooth functions with compact support not near 0. I have had a look at this Solving Poisson Equation with domain $L^2(\mathbb{R}^3 \backslash \{ 0 \})$. But feel that what was missing here was that since we are away from zero, we can't simply solve $(\Delta^{\ast} \pm i)u =0$, it is better to solve ($\Delta^{\ast} \pm i)u =\delta$ for some $\delta$ function. In so doing, taking the Fourier transform yields that $$(4\pi^2 \left| \xi \right|^2 \pm i) \hat{u}(\xi) = 1,$$ and therefore, $$u = \frac{1}{4\pi} \frac{e^{i\sqrt{\pm i} \ |x|}}{|x|}. $$ From this, I want to show that all self-adjoint extensions of $-\Delta$ have a negative eigenvalue, except possibly one. I'm fairly sure we need to use the above formula that I've obtained for $u$, but am unsure. Also, how would we obtain the Friedrich's extension from this?","Consider the Laplace operator $-\Delta$ on $L^2(\mathbb{R}^3)$ with domain $C_0^{\infty}(\mathbb{R}^3 \backslash \{ 0 \})$, the smooth functions with compact support not near 0. I have had a look at this Solving Poisson Equation with domain $L^2(\mathbb{R}^3 \backslash \{ 0 \})$. But feel that what was missing here was that since we are away from zero, we can't simply solve $(\Delta^{\ast} \pm i)u =0$, it is better to solve ($\Delta^{\ast} \pm i)u =\delta$ for some $\delta$ function. In so doing, taking the Fourier transform yields that $$(4\pi^2 \left| \xi \right|^2 \pm i) \hat{u}(\xi) = 1,$$ and therefore, $$u = \frac{1}{4\pi} \frac{e^{i\sqrt{\pm i} \ |x|}}{|x|}. $$ From this, I want to show that all self-adjoint extensions of $-\Delta$ have a negative eigenvalue, except possibly one. I'm fairly sure we need to use the above formula that I've obtained for $u$, but am unsure. Also, how would we obtain the Friedrich's extension from this?",,"['functional-analysis', 'partial-differential-equations']"
51,Bessel's (in)equality confusion -- always an equality?,Bessel's (in)equality confusion -- always an equality?,,"Bessel's Inequality Let $(X, \langle\cdot,\cdot\rangle )$ be an inner product space and $(e_k)$ an orthonormal sequence in $X$. Then for every $x \in X$ : $$ \sum_{1}^{\infty} |\langle x,e_k\rangle |^2 \le ||x||^2$$ where $\| \cdot\|$ is of course the norm induced by the inner product. Now suppose we have a sequence of scalars $a_k$ and that the series $$ \sum_{1}^{\infty} a_k e_k = x $$ converges to a $x \in X$. Lemma 1 We can easily show that $a_k=\langle x,e_k\rangle $    (i'll do it fast) Proof. Denote $s_n$  the sequence of partial sums of the above series, which of course converges to $x$. Then for every $j<n$ , $ \langle s_n, e_j\rangle  = a_j$ and by continuuity of the inner product $a_j=\langle x,e_j\rangle $ Lemma 2 We can also show that since $s_n$ converges to $x$, then $σ_n = |a_1|^2 + ... + |a_2|^2 $ converges to $\|x\|^2 $ : Proof. $\|s_n\|^2 = \| a_1 e_1 +...+a_2 e_2\|^2 = |a_1|^2 + ... |a_n|^2  $ since $(e_k)$ are orthonormal (Pythagorean). But $||s_n||^2$ converges to $||x||^2 $ , which completes the proof. So we showed the following $$\sum_1^{\infty} |a_k|^2= \sum_1^\infty |\langle x,e_k\rangle |^2 = ||x||^2$$ Confusion So the equality holds for Bessel inequality, for $x$. We arbitrarily chose $a_k$, so does that mean the the equality holds for all $x \in X$ ? Obviously not, otherwise it would be Bessel's equality. What am I getting wrong?","Bessel's Inequality Let $(X, \langle\cdot,\cdot\rangle )$ be an inner product space and $(e_k)$ an orthonormal sequence in $X$. Then for every $x \in X$ : $$ \sum_{1}^{\infty} |\langle x,e_k\rangle |^2 \le ||x||^2$$ where $\| \cdot\|$ is of course the norm induced by the inner product. Now suppose we have a sequence of scalars $a_k$ and that the series $$ \sum_{1}^{\infty} a_k e_k = x $$ converges to a $x \in X$. Lemma 1 We can easily show that $a_k=\langle x,e_k\rangle $    (i'll do it fast) Proof. Denote $s_n$  the sequence of partial sums of the above series, which of course converges to $x$. Then for every $j<n$ , $ \langle s_n, e_j\rangle  = a_j$ and by continuuity of the inner product $a_j=\langle x,e_j\rangle $ Lemma 2 We can also show that since $s_n$ converges to $x$, then $σ_n = |a_1|^2 + ... + |a_2|^2 $ converges to $\|x\|^2 $ : Proof. $\|s_n\|^2 = \| a_1 e_1 +...+a_2 e_2\|^2 = |a_1|^2 + ... |a_n|^2  $ since $(e_k)$ are orthonormal (Pythagorean). But $||s_n||^2$ converges to $||x||^2 $ , which completes the proof. So we showed the following $$\sum_1^{\infty} |a_k|^2= \sum_1^\infty |\langle x,e_k\rangle |^2 = ||x||^2$$ Confusion So the equality holds for Bessel inequality, for $x$. We arbitrarily chose $a_k$, so does that mean the the equality holds for all $x \in X$ ? Obviously not, otherwise it would be Bessel's equality. What am I getting wrong?",,"['functional-analysis', 'inner-products']"
52,Uniform convergence and sequences of minima,Uniform convergence and sequences of minima,,"Let $\Omega \subset \mathbb{R}^n$,  $f \in C(\Omega)$ and $g \in C^1(\Omega)$ and assume that $f - g$ has a strict global minimum at $x \in \Omega$. Is the following true? there exists a sequence of functions $\{f_n\}$ such that $f_n \to f$ uniformly $\implies$ there is a sequence of points $x_n \to x$ such that $f_n(x_n) \to f(x)$ and  $f_n - g$ has a global minimum at $x_n$?","Let $\Omega \subset \mathbb{R}^n$,  $f \in C(\Omega)$ and $g \in C^1(\Omega)$ and assume that $f - g$ has a strict global minimum at $x \in \Omega$. Is the following true? there exists a sequence of functions $\{f_n\}$ such that $f_n \to f$ uniformly $\implies$ there is a sequence of points $x_n \to x$ such that $f_n(x_n) \to f(x)$ and  $f_n - g$ has a global minimum at $x_n$?",,['real-analysis']
53,On the interchange of limit and sup (with also an integral),On the interchange of limit and sup (with also an integral),,"Let $\{f_n\}$ be a sequence of continuous functions $f_n:\mathbb{R}  \to \mathbb{R}$. Suppose $\Vert f_n\Vert_\infty \le C$, $f_n \to f$ uniformly (we can also assume $f_n$ Lipschitz if necessary). Then $$\lim_{n \to \infty} \sup_{1 +\epsilon < k \le \frac{3}{2}}\int_{\mathbb{R}}\frac{f_n(x+t) - f_n(x)}{|t|^{k}}dt =  \sup_{1 +\epsilon < k \le \frac{3}{2}}\lim_{n \to \infty}\int_{\mathbb{R}}\frac{f_n(x+t) - f_n(x)}{|t|^{k}}dt.$$ Is this claim true? How can I prove it? If it is not true, what assumptions should we add so that the claim holds?","Let $\{f_n\}$ be a sequence of continuous functions $f_n:\mathbb{R}  \to \mathbb{R}$. Suppose $\Vert f_n\Vert_\infty \le C$, $f_n \to f$ uniformly (we can also assume $f_n$ Lipschitz if necessary). Then $$\lim_{n \to \infty} \sup_{1 +\epsilon < k \le \frac{3}{2}}\int_{\mathbb{R}}\frac{f_n(x+t) - f_n(x)}{|t|^{k}}dt =  \sup_{1 +\epsilon < k \le \frac{3}{2}}\lim_{n \to \infty}\int_{\mathbb{R}}\frac{f_n(x+t) - f_n(x)}{|t|^{k}}dt.$$ Is this claim true? How can I prove it? If it is not true, what assumptions should we add so that the claim holds?",,"['calculus', 'real-analysis']"
54,Hahn-Banach and seminorms,Hahn-Banach and seminorms,,"Let $V$ be a vector space, $\phi \in V'$, and let $p_1,\dots,p_n$ be seminorms on $V$ s.t. $|\phi (x) | \leq \sum_{k=1}^{n} p_k(x)$ for all $x \in V$. Prove that there are $\phi_1, \dots \phi_n \in V'$ s.t $$ \phi = \sum_{k=1}^{n} \phi_k, \\ |\phi_k (x) | \leq p_k (x) \ \forall x \in V. $$ I thought about considering the product space $V^n = V \times \dots \times V$, but I'm stuck at trying to figure out a seminorm on $V^n$. If I can figure out a seminorm, I can then consider the subspace $\{(x,\dots,x): x \in V \}$ and the functional $\phi(x,\dots,x) = \psi(x)$ and apply Hahn-Banach theorem.","Let $V$ be a vector space, $\phi \in V'$, and let $p_1,\dots,p_n$ be seminorms on $V$ s.t. $|\phi (x) | \leq \sum_{k=1}^{n} p_k(x)$ for all $x \in V$. Prove that there are $\phi_1, \dots \phi_n \in V'$ s.t $$ \phi = \sum_{k=1}^{n} \phi_k, \\ |\phi_k (x) | \leq p_k (x) \ \forall x \in V. $$ I thought about considering the product space $V^n = V \times \dots \times V$, but I'm stuck at trying to figure out a seminorm on $V^n$. If I can figure out a seminorm, I can then consider the subspace $\{(x,\dots,x): x \in V \}$ and the functional $\phi(x,\dots,x) = \psi(x)$ and apply Hahn-Banach theorem.",,['functional-analysis']
55,Adjoint of inverse map is the inverse of adjoint map?,Adjoint of inverse map is the inverse of adjoint map?,,"Let  $E,F$ be Banach normed spaces and $S,T \in L(E,F)$.Denote adjoint of  $T$ as $T^* .$ Prove that  if $   T^{-1}$ exist and $T(E)=F $, then $(T^{-1})^* = (T^*)^{-1}. $ Actually, I could not proceed beyond writing definition of adjoint map.","Let  $E,F$ be Banach normed spaces and $S,T \in L(E,F)$.Denote adjoint of  $T$ as $T^* .$ Prove that  if $   T^{-1}$ exist and $T(E)=F $, then $(T^{-1})^* = (T^*)^{-1}. $ Actually, I could not proceed beyond writing definition of adjoint map.",,['functional-analysis']
56,Grothendieck lemma for weakly compact sets,Grothendieck lemma for weakly compact sets,,"Does anyone have a reference for the following result? I need to know the proof but I can't find it anywhere. Lemma (Grothendieck, for weakly compact sets). Let $X$ be a Banach space, and $K \subset X$. If $K$ is weakly closed and bounded, and for all $\varepsilon >0$ there exists a weakly compact set $K_\varepsilon$ such that $K \subset K_\varepsilon + \varepsilon B_X$, then $K$ is weakly compact.","Does anyone have a reference for the following result? I need to know the proof but I can't find it anywhere. Lemma (Grothendieck, for weakly compact sets). Let $X$ be a Banach space, and $K \subset X$. If $K$ is weakly closed and bounded, and for all $\varepsilon >0$ there exists a weakly compact set $K_\varepsilon$ such that $K \subset K_\varepsilon + \varepsilon B_X$, then $K$ is weakly compact.",,"['functional-analysis', 'analysis', 'banach-spaces']"
57,For any bounded operator T on H there exists a sequence of finite rank operators $(T_n)_{n=1}^{\infty}$ such that $T_n → T$ strongly.,For any bounded operator T on H there exists a sequence of finite rank operators  such that  strongly.,(T_n)_{n=1}^{\infty} T_n → T,"I have come up with a proof which I want to confirm as some parts of it make me unsure whether its correct or not. Note: $T_n \to T$ strongly means  $$\|T_n(x)-T(x)\| \to 0 \ \ \ \forall x\in H.$$ Here is my proof attempt. Let $(e_j)_{j=1}^{\infty}$ be an orthonormal basis for $H$ ($H$ is assumed separable) and $(g_k)_{k=1}^{\infty}$ be a sequence consisting of finite linear combinations of $e_j$, more precisely for each g in H, we choose  $$g_k= \sum_{i=1}^{k} \langle g,e_i\rangle  e_i.$$  Now define $T_n$ by  $$T_n(g_k)=\begin{cases} T(g_k) & \text{for }k\leq n, \\ 0 &\text{for } k>n.\end{cases}$$ Clearly each $T_n$ has finite rank since the range of each $T_n$ is the span of $(g_1,..,g_n)$. Also $||T_n (g_k)-T(g_k)||=0$ for $n \geq k$ Let now g be an arbitrary element of H. Then since $(g_k)_{k=1}^{\infty}$ is dense in H, $||g-g_k||\to 0$ as $k\to \infty$. Then by the triangle inequality, $$||T_n(g)-T(g)||\leq ||T_n(g)-T_n(g_k)|| + ||T_n(g_k)-T(g)||$$ First taking the limit as $n\to \infty$, we get that the first term goes to 0 (by continuity of norm) since $T_n(g_k)=T_n(g)$ for $n\geq k$, and the second term goes to $||T(g_k)-T(g)||$. Now  $$||T(g_k)-T(g)||\leq \|T\| \|g_k-g\|$$  by definition of operator norm. Since $||T||<\infty$, taking the limit as k goes to $\infty$ and using the fact that $||g_k-g||\to 0$ we get that $||T_n(g)-T(g)||\to 0$ as $n\to\infty$ My question is, the definition my book uses for a basis is that $(e_n)$ is a basis if finite linear combinations are dense (in the norm) in H. Now for me that means for each g in H,given $\epsilon>0$ there exists a $(g_k)$ which is a finite linear combination of $e_j$ such that $||g_k-g||< \epsilon$. Is that equivalent to the existence of a sequence $(g_k)$ where each $g_k$ is a finite linear combination of $e_j$'s such that $||g_k-g||\to 0$ as $k\to \infty$ ? Also, is my proof correct? Taking limits with respect to k and n bothers me a bit whether I am allowed to do that or not. Thanks in advance for any comments. Edit: Reading my notes, it seems I need to be more precise on what the $g_k$ are. They depend on the g that would be chosen. More precisely, $g_k= \sum_{i=1}^{k} <g,e_i> e_i$. Then it works?","I have come up with a proof which I want to confirm as some parts of it make me unsure whether its correct or not. Note: $T_n \to T$ strongly means  $$\|T_n(x)-T(x)\| \to 0 \ \ \ \forall x\in H.$$ Here is my proof attempt. Let $(e_j)_{j=1}^{\infty}$ be an orthonormal basis for $H$ ($H$ is assumed separable) and $(g_k)_{k=1}^{\infty}$ be a sequence consisting of finite linear combinations of $e_j$, more precisely for each g in H, we choose  $$g_k= \sum_{i=1}^{k} \langle g,e_i\rangle  e_i.$$  Now define $T_n$ by  $$T_n(g_k)=\begin{cases} T(g_k) & \text{for }k\leq n, \\ 0 &\text{for } k>n.\end{cases}$$ Clearly each $T_n$ has finite rank since the range of each $T_n$ is the span of $(g_1,..,g_n)$. Also $||T_n (g_k)-T(g_k)||=0$ for $n \geq k$ Let now g be an arbitrary element of H. Then since $(g_k)_{k=1}^{\infty}$ is dense in H, $||g-g_k||\to 0$ as $k\to \infty$. Then by the triangle inequality, $$||T_n(g)-T(g)||\leq ||T_n(g)-T_n(g_k)|| + ||T_n(g_k)-T(g)||$$ First taking the limit as $n\to \infty$, we get that the first term goes to 0 (by continuity of norm) since $T_n(g_k)=T_n(g)$ for $n\geq k$, and the second term goes to $||T(g_k)-T(g)||$. Now  $$||T(g_k)-T(g)||\leq \|T\| \|g_k-g\|$$  by definition of operator norm. Since $||T||<\infty$, taking the limit as k goes to $\infty$ and using the fact that $||g_k-g||\to 0$ we get that $||T_n(g)-T(g)||\to 0$ as $n\to\infty$ My question is, the definition my book uses for a basis is that $(e_n)$ is a basis if finite linear combinations are dense (in the norm) in H. Now for me that means for each g in H,given $\epsilon>0$ there exists a $(g_k)$ which is a finite linear combination of $e_j$ such that $||g_k-g||< \epsilon$. Is that equivalent to the existence of a sequence $(g_k)$ where each $g_k$ is a finite linear combination of $e_j$'s such that $||g_k-g||\to 0$ as $k\to \infty$ ? Also, is my proof correct? Taking limits with respect to k and n bothers me a bit whether I am allowed to do that or not. Thanks in advance for any comments. Edit: Reading my notes, it seems I need to be more precise on what the $g_k$ are. They depend on the g that would be chosen. More precisely, $g_k= \sum_{i=1}^{k} <g,e_i> e_i$. Then it works?",,['functional-analysis']
58,Compact operators satisfying a certain relation must be finite-rank,Compact operators satisfying a certain relation must be finite-rank,,"Let $H$ be an infinite-dimensional Hilbert space, equipped with a given Hilbert basis $(e_i)_{i \in \mathbb{N}}$. Consider the following introductory problem : can we find a compact operator $A$ in $H$ that satisfies the relation $$ \sum \limits_{k=0}^n c_kA^k=0$$ for some given $(c_k)_k$, $c_k \in \mathbb{R}^{n+1}$ for all $k=0,...,n$ ? Two cases arise : $c_0 \neq 0$ : Suppose that $A$ is a compact operator satisfying the given relation. We can rewrite it as  $$c_nA^n+...+c_1A=-c_0Id$$ Factoring by $A$ and using the fact that $c_0 \neq 0$, we get that $$ \underbrace{A}_\text{compact} \circ(\underbrace{\frac{-c_n}{c_0}A^{n-1}+...+\frac{c_1}{c_0}Id}_\text{bounded})=Id$$ Set $B=\frac{-c_n}{c_0}A^{n-1}+...+\frac{c_1}{c_0}Id$. The composition $A \circ B$ will compact, because $A$ is compact and $B$ is a bounded operator. Therefore the $Id$ operator is compact, which is absurd because $H$ is infinite-dimensional. Therefore such an A cannot exist . $c_0=0$ : In this case we can find a compact operator with relative ease. Consider  $$ V= vect\left\{e_n : n \in \left\{0,...,N\right\}\right\}$$ where the $(e_n)$ are elements of the basis of $H$. It is finite-dimensional and thus closed, so let $A$ be the well-defined projection operator on $V$. We then have that  $$ A \circ A = A \iff A^2-A=0$$ and can thus create a relation of the given form. Since $dim(V) < +\infty$, $A$ is finite-rank, and thus compact. Now consider again the case where $c_0=0$. My question is the following : If $A$ is a compact operator satisfying this type of relation for given $(c_k)_k$, then must $A$ be finite-rank ? I suspect that the answer is yes (maybe an analogy can be made to the case of matrices that have $0$ as an eigenvalue), but don't really have a good idea of where to start. Decomposing a finite-rank operator in $(e_i)$ might shed some light on this but appart from that I am not sure of how to proceed.","Let $H$ be an infinite-dimensional Hilbert space, equipped with a given Hilbert basis $(e_i)_{i \in \mathbb{N}}$. Consider the following introductory problem : can we find a compact operator $A$ in $H$ that satisfies the relation $$ \sum \limits_{k=0}^n c_kA^k=0$$ for some given $(c_k)_k$, $c_k \in \mathbb{R}^{n+1}$ for all $k=0,...,n$ ? Two cases arise : $c_0 \neq 0$ : Suppose that $A$ is a compact operator satisfying the given relation. We can rewrite it as  $$c_nA^n+...+c_1A=-c_0Id$$ Factoring by $A$ and using the fact that $c_0 \neq 0$, we get that $$ \underbrace{A}_\text{compact} \circ(\underbrace{\frac{-c_n}{c_0}A^{n-1}+...+\frac{c_1}{c_0}Id}_\text{bounded})=Id$$ Set $B=\frac{-c_n}{c_0}A^{n-1}+...+\frac{c_1}{c_0}Id$. The composition $A \circ B$ will compact, because $A$ is compact and $B$ is a bounded operator. Therefore the $Id$ operator is compact, which is absurd because $H$ is infinite-dimensional. Therefore such an A cannot exist . $c_0=0$ : In this case we can find a compact operator with relative ease. Consider  $$ V= vect\left\{e_n : n \in \left\{0,...,N\right\}\right\}$$ where the $(e_n)$ are elements of the basis of $H$. It is finite-dimensional and thus closed, so let $A$ be the well-defined projection operator on $V$. We then have that  $$ A \circ A = A \iff A^2-A=0$$ and can thus create a relation of the given form. Since $dim(V) < +\infty$, $A$ is finite-rank, and thus compact. Now consider again the case where $c_0=0$. My question is the following : If $A$ is a compact operator satisfying this type of relation for given $(c_k)_k$, then must $A$ be finite-rank ? I suspect that the answer is yes (maybe an analogy can be made to the case of matrices that have $0$ as an eigenvalue), but don't really have a good idea of where to start. Decomposing a finite-rank operator in $(e_i)$ might shed some light on this but appart from that I am not sure of how to proceed.",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'compact-operators']"
59,$iV$ is open for $V$ open in real TVS,is open for  open in real TVS,iV V,"Let $E$ be a complex vector space. It induces a real vector space $E_0$. Suppose that on $E_0$ we have a topology compatible with the vector structure, ie. a real TVS. How do we prove that $E$ is a complex TVS with same topology? What I know is this: We have maps $$ \mathbb C \times E \to \mathbb R \times \mathbb R \times E \to E \times E \to E \\ (x + iy, e) \mapsto (x, y, e) \mapsto (xe, ye) \mapsto xe + iye $$ What's needed is $V$ open $\Rightarrow$ $iV$ open (ie. scalar multiplication by $i$ is continuous; note the inverse is $-i$). Alternatively, if the claim were to be false, a counter-example would be much appreciated.","Let $E$ be a complex vector space. It induces a real vector space $E_0$. Suppose that on $E_0$ we have a topology compatible with the vector structure, ie. a real TVS. How do we prove that $E$ is a complex TVS with same topology? What I know is this: We have maps $$ \mathbb C \times E \to \mathbb R \times \mathbb R \times E \to E \times E \to E \\ (x + iy, e) \mapsto (x, y, e) \mapsto (xe, ye) \mapsto xe + iye $$ What's needed is $V$ open $\Rightarrow$ $iV$ open (ie. scalar multiplication by $i$ is continuous; note the inverse is $-i$). Alternatively, if the claim were to be false, a counter-example would be much appreciated.",,"['linear-algebra', 'functional-analysis', 'topological-vector-spaces']"
60,How to concretely find the characters and pure states of $L^\infty$?,How to concretely find the characters and pure states of ?,L^\infty,"Let $(X, \mathcal X, \mu)$ be a space with measure. Out of curiosity I was trying to understand what the Gelfand-Naimark theorem and Glimm's abstract Stone-Weierstrass theorem give when applied to the $\Bbb C$ $*$-algebra $L^\infty(X,\mu)$. Sadly, I had to give up: given that its elements are not functions with pointwise values, how can I find the pure states and characters of $L^\infty$ (i.e see how they look like concretely)?","Let $(X, \mathcal X, \mu)$ be a space with measure. Out of curiosity I was trying to understand what the Gelfand-Naimark theorem and Glimm's abstract Stone-Weierstrass theorem give when applied to the $\Bbb C$ $*$-algebra $L^\infty(X,\mu)$. Sadly, I had to give up: given that its elements are not functions with pointwise values, how can I find the pure states and characters of $L^\infty$ (i.e see how they look like concretely)?",,"['functional-analysis', 'banach-spaces', 'lp-spaces', 'c-star-algebras', 'banach-algebras']"
61,$L^{p} (\mathbb T)$ is complete.,is complete.,L^{p} (\mathbb T),"I want to show that: $(1)$ $L^{p}(\mathbb T)$, where $\mathbb T$ is the circle is complete. $(2)$ $C(\mathbb T)$ is dense in $L^{p}(\mathbb T).$ Can you help me in (1) for any interval not necessarily the circle? Thanks.","I want to show that: $(1)$ $L^{p}(\mathbb T)$, where $\mathbb T$ is the circle is complete. $(2)$ $C(\mathbb T)$ is dense in $L^{p}(\mathbb T).$ Can you help me in (1) for any interval not necessarily the circle? Thanks.",,"['functional-analysis', 'measure-theory', 'fourier-analysis', 'lebesgue-measure', 'harmonic-analysis']"
62,Incorrect proof of the Open Mapping Theorem,Incorrect proof of the Open Mapping Theorem,,"I was following the proof of the Open Mapping Theorem in Lang's Real and Functional Analysis and something odd happened. I was able to simplify a lot his proof. Not only that, but I was able to improve the theorem itself. My proof is valid for any normed space, not only Banach spaces. Of course I know this can't be the case, but still, I wasn't able to find where my proof got wrong. If you spot the mistake, please tell me. Open Mapping Theorem: Let $X,Y$ be Banach spaces and let $f:X \to Y$ be a linear continuous map. If $f$ is surjective, then it is also open. Proof: For any $s>0$, we will denote $B_s = \{ x\in X:\ \|x\| < s \}$ and $C_s = \{ y \in Y:\ \|y\| < s \}$. First, note that since $X$ is surjective, we have $$ f(X) = f(\cup_{n=1}^\infty B_n) = Y.$$ Also, note that $s < t \implies B_s \subset B_t$. In particular, this means that $\cup_{n=1}^N B_n \subset B_t$, for any $t > N$. Then for any $r > 0$, there is a $k \in \mathbb{N}$ such that $C_r \subset f(B_{kr})$. Now let $U \subset X$ be an open set and let $x \in U$ be an arbitrary point. By definition, there is a $t > 0$ such that $x + B_t \subset U$. Then $$f(x+B_t) = f(x) + f(B_t) \subset f(U).$$ Given any $r>0$, we know there is a $k \in \mathbb{K}$ such that $C_r \subset f(B_{kr})$. The it follows that $$f(B_t) = f\left(\frac{t}{kr} B_{kr}\right) = \frac{t}{kr} f(B_{kr}) \supset \frac{t}{kr} C_r = C_\frac{t}{k}.$$ Therefore, $$f(x) + C_\frac{t}{r} \subset f(x) + f(B_t) \subset f(U). $$ This proves $f(x)$ is in the interior of $f(U)$. Since $x$ was arbitrary, we conclude that every point of $f(U)$ is in its interior, so $f(U)$ is open. $\hspace{1cm}\square$ Thank you!","I was following the proof of the Open Mapping Theorem in Lang's Real and Functional Analysis and something odd happened. I was able to simplify a lot his proof. Not only that, but I was able to improve the theorem itself. My proof is valid for any normed space, not only Banach spaces. Of course I know this can't be the case, but still, I wasn't able to find where my proof got wrong. If you spot the mistake, please tell me. Open Mapping Theorem: Let $X,Y$ be Banach spaces and let $f:X \to Y$ be a linear continuous map. If $f$ is surjective, then it is also open. Proof: For any $s>0$, we will denote $B_s = \{ x\in X:\ \|x\| < s \}$ and $C_s = \{ y \in Y:\ \|y\| < s \}$. First, note that since $X$ is surjective, we have $$ f(X) = f(\cup_{n=1}^\infty B_n) = Y.$$ Also, note that $s < t \implies B_s \subset B_t$. In particular, this means that $\cup_{n=1}^N B_n \subset B_t$, for any $t > N$. Then for any $r > 0$, there is a $k \in \mathbb{N}$ such that $C_r \subset f(B_{kr})$. Now let $U \subset X$ be an open set and let $x \in U$ be an arbitrary point. By definition, there is a $t > 0$ such that $x + B_t \subset U$. Then $$f(x+B_t) = f(x) + f(B_t) \subset f(U).$$ Given any $r>0$, we know there is a $k \in \mathbb{K}$ such that $C_r \subset f(B_{kr})$. The it follows that $$f(B_t) = f\left(\frac{t}{kr} B_{kr}\right) = \frac{t}{kr} f(B_{kr}) \supset \frac{t}{kr} C_r = C_\frac{t}{k}.$$ Therefore, $$f(x) + C_\frac{t}{r} \subset f(x) + f(B_t) \subset f(U). $$ This proves $f(x)$ is in the interior of $f(U)$. Since $x$ was arbitrary, we conclude that every point of $f(U)$ is in its interior, so $f(U)$ is open. $\hspace{1cm}\square$ Thank you!",,"['functional-analysis', 'proof-verification', 'banach-spaces', 'normed-spaces', 'open-map']"
63,"$X$ is a Banach space, $T \in B(X)$ and $T^*$ be its adjoint, show that $ \lVert Tx \rVert \geq \lVert (T^*)^{-1}\rVert^{-1}\lVert x \rVert$","is a Banach space,  and  be its adjoint, show that",X T \in B(X) T^*  \lVert Tx \rVert \geq \lVert (T^*)^{-1}\rVert^{-1}\lVert x \rVert,"Let X be a complex Banach space. Let $T\in B(X)$ be a bounded linear operator on $X$ . Let $T^*\in B(X^*)$ be the adjoint of $T$ . Prove: If $T^*$ is invertible, then for all elements $x\in X$ , $$ \|Tx \| \geq \| (T^*)^{-1}\|^{-1}\| x \|$$ and use the inequality to prove that $T$ is invertible","Let X be a complex Banach space. Let be a bounded linear operator on . Let be the adjoint of . Prove: If is invertible, then for all elements , and use the inequality to prove that is invertible",T\in B(X) X T^*\in B(X^*) T T^* x\in X  \|Tx \| \geq \| (T^*)^{-1}\|^{-1}\| x \| T,"['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'spectral-theory']"
64,"The functional derivative , Fréchet and Gâteaux differentiability of the energy operator","The functional derivative , Fréchet and Gâteaux differentiability of the energy operator",,"Consider the energy function $$F(u)=\int_\Omega \frac{1}{2}|\nabla u|^2+fu dx,$$ where $u\in W^{1,2}(\Omega)$, $\Omega$ is a bounded domain in $\mathbb{R}^n$, and $f\in L_2(\Omega)$. I'd like to find the first order functional derivative of $F$, and determine the Fréchet and Gâteaux differentiability of $F$. Here I present my work so far: The differential $d F$ due to an infinitestimal change $\delta u$ is given by $$\begin{aligned}d F&=F(u+\delta u)-F(u)=\int_\Omega \frac{1}{2}(|\nabla u+\nabla(\delta u)|^2-|\nabla u|^2)+f\delta ud x\\ &=\int_\Omega\nabla u\cdot\nabla\delta u+f\delta u+\frac{1}{2}|\nabla\delta u|^2d x\\ &=\int_\Omega \nabla\cdot((\nabla u)\delta u)-(\nabla\cdot(\nabla u))\delta u+f\delta u+\frac{1}{2}|\nabla\delta u|^2dx. \end{aligned}$$ Therefore the first order functional derivative is  $$\frac{\delta F}{\delta u}=-\nabla\cdot(\nabla u)+f=-\Delta u+f.$$ From the above computation we see that $$\begin{aligned}\frac{F(u+\epsilon y)-F(u)}{\epsilon}&=\frac{1}{\epsilon}\int_\Omega \frac{1}{2}(\epsilon(\nabla u\cdot\nabla y))+\epsilon fy+\frac{1}{2}\epsilon^2|\nabla y|^2dx\\ &=\int_\Omega \frac{1}{2}(\nabla u\cdot\nabla y)+fy+\frac{1}{2}\epsilon|\nabla y|^d x\\ &\to \int_\Omega \frac{1}{2}(\nabla u\cdot\nabla y)+fydx. \end{aligned}$$ Hence $F$ is Gâteaux differentiable at $u$, with $$F'(u)y=\int_\Omega \frac{1}{2}(\nabla u\cdot\nabla y)+fydx.$$ Finally for Fréchet  differentiability, this is the part I am not sure how to proceed. My idea to this is the following: we have $$F(u+y)-F(u)-L(u)y=\frac{1}{2}\int_\Omega \nabla u\cdot\nabla y+|\nabla y|^2d x=\frac{1}{2}\int_\Omega (\nabla u+\nabla y)\cdot\nabla yd x,$$ where $L$ is the bounded linear functional $$L(u)y=\int_\Omega fudx.$$ $F$ is Fréchet  differentiable at $u$ if and only if $$R(u,y):=\frac{\frac{1}{2}\int_\Omega (\nabla u+\nabla y)\cdot\nabla yd x}{\|y\|_{W^{1,2}(\Omega)}}\to 0,\text{ as }y\to 0.$$ When $\nabla u=0$, i.e. when $u=c$ for some constant $c$, we have $$R(u,y)=\frac{\int_\Omega\|\nabla y|^2dx}{2\|y\|_{W^{1,2}(\Omega)}}\leq\frac{\|y\|_{W^{1,2}(\Omega)}^2}{2\|y\|_{W^{1,2}(\Omega)}}\to 0,\text{ as }y\to 0,$$  and in this case the Fréchet derivative is given by $$L(u)y=c\int_\Omega fd x.$$ Then we are left with the case $|\nabla u|\neq 0$. I really didn't have much idea on dealing with this. Any one have some suggestions? Also it will be greatly appreciated if someone can verify my work so far.","Consider the energy function $$F(u)=\int_\Omega \frac{1}{2}|\nabla u|^2+fu dx,$$ where $u\in W^{1,2}(\Omega)$, $\Omega$ is a bounded domain in $\mathbb{R}^n$, and $f\in L_2(\Omega)$. I'd like to find the first order functional derivative of $F$, and determine the Fréchet and Gâteaux differentiability of $F$. Here I present my work so far: The differential $d F$ due to an infinitestimal change $\delta u$ is given by $$\begin{aligned}d F&=F(u+\delta u)-F(u)=\int_\Omega \frac{1}{2}(|\nabla u+\nabla(\delta u)|^2-|\nabla u|^2)+f\delta ud x\\ &=\int_\Omega\nabla u\cdot\nabla\delta u+f\delta u+\frac{1}{2}|\nabla\delta u|^2d x\\ &=\int_\Omega \nabla\cdot((\nabla u)\delta u)-(\nabla\cdot(\nabla u))\delta u+f\delta u+\frac{1}{2}|\nabla\delta u|^2dx. \end{aligned}$$ Therefore the first order functional derivative is  $$\frac{\delta F}{\delta u}=-\nabla\cdot(\nabla u)+f=-\Delta u+f.$$ From the above computation we see that $$\begin{aligned}\frac{F(u+\epsilon y)-F(u)}{\epsilon}&=\frac{1}{\epsilon}\int_\Omega \frac{1}{2}(\epsilon(\nabla u\cdot\nabla y))+\epsilon fy+\frac{1}{2}\epsilon^2|\nabla y|^2dx\\ &=\int_\Omega \frac{1}{2}(\nabla u\cdot\nabla y)+fy+\frac{1}{2}\epsilon|\nabla y|^d x\\ &\to \int_\Omega \frac{1}{2}(\nabla u\cdot\nabla y)+fydx. \end{aligned}$$ Hence $F$ is Gâteaux differentiable at $u$, with $$F'(u)y=\int_\Omega \frac{1}{2}(\nabla u\cdot\nabla y)+fydx.$$ Finally for Fréchet  differentiability, this is the part I am not sure how to proceed. My idea to this is the following: we have $$F(u+y)-F(u)-L(u)y=\frac{1}{2}\int_\Omega \nabla u\cdot\nabla y+|\nabla y|^2d x=\frac{1}{2}\int_\Omega (\nabla u+\nabla y)\cdot\nabla yd x,$$ where $L$ is the bounded linear functional $$L(u)y=\int_\Omega fudx.$$ $F$ is Fréchet  differentiable at $u$ if and only if $$R(u,y):=\frac{\frac{1}{2}\int_\Omega (\nabla u+\nabla y)\cdot\nabla yd x}{\|y\|_{W^{1,2}(\Omega)}}\to 0,\text{ as }y\to 0.$$ When $\nabla u=0$, i.e. when $u=c$ for some constant $c$, we have $$R(u,y)=\frac{\int_\Omega\|\nabla y|^2dx}{2\|y\|_{W^{1,2}(\Omega)}}\leq\frac{\|y\|_{W^{1,2}(\Omega)}^2}{2\|y\|_{W^{1,2}(\Omega)}}\to 0,\text{ as }y\to 0,$$  and in this case the Fréchet derivative is given by $$L(u)y=c\int_\Omega fd x.$$ Then we are left with the case $|\nabla u|\neq 0$. I really didn't have much idea on dealing with this. Any one have some suggestions? Also it will be greatly appreciated if someone can verify my work so far.",,"['functional-analysis', 'sobolev-spaces', 'calculus-of-variations']"
65,Comparing Lebesgue integral and Riemann Stieltjes integral,Comparing Lebesgue integral and Riemann Stieltjes integral,,"Please how can I justify that these two definitions can be the same thing or let me say how can I compare the following two definitions. If $g$ is a right continuous, increasing step function on $\mathbb{R}$ with  countable discontinuous points $x_1,x_2,\cdots,x_n$. Then for any function $f$, we define the integral $$\int_{\mathbb{R} }f dg =\sum_{k=1}^{n} f(x_k)\Delta g(x_k)$$where $\Delta g(x_n) = g(x_n^+)-g(x_n^-)> 0$. Let $(X, \mathcal{H}, \mu)$ be a measure space and let $f: X \rightarrow [0, \infty]$ be a  measurable function. We define the Lebesgue integral of $f$ over $X$ as $$\int_{X}f d \mu= \sup \left\{ \int_{X}g d \mu: 0 \le g \le f, g \,\, \text{is simple} \right\}.$$ I would be glad if a proof or correspondence can be given. Thanks for your help.","Please how can I justify that these two definitions can be the same thing or let me say how can I compare the following two definitions. If $g$ is a right continuous, increasing step function on $\mathbb{R}$ with  countable discontinuous points $x_1,x_2,\cdots,x_n$. Then for any function $f$, we define the integral $$\int_{\mathbb{R} }f dg =\sum_{k=1}^{n} f(x_k)\Delta g(x_k)$$where $\Delta g(x_n) = g(x_n^+)-g(x_n^-)> 0$. Let $(X, \mathcal{H}, \mu)$ be a measure space and let $f: X \rightarrow [0, \infty]$ be a  measurable function. We define the Lebesgue integral of $f$ over $X$ as $$\int_{X}f d \mu= \sup \left\{ \int_{X}g d \mu: 0 \le g \le f, g \,\, \text{is simple} \right\}.$$ I would be glad if a proof or correspondence can be given. Thanks for your help.",,"['real-analysis', 'functional-analysis', 'measure-theory', 'lebesgue-integral', 'riemann-integration']"
66,Applications of functional calculus [closed],Applications of functional calculus [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I want to show that every bounded self-adjoint operator is unitarily equivalent to multiplication by some $\lambda \in L^{\infty}(X)$ on an $L^2(X)$ for some measure space $X$ , $\sigma$ finite. I've been working with the Borel functional calculus for a while and have made no progress.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I want to show that every bounded self-adjoint operator is unitarily equivalent to multiplication by some on an for some measure space , finite. I've been working with the Borel functional calculus for a while and have made no progress.",\lambda \in L^{\infty}(X) L^2(X) X \sigma,"['real-analysis', 'functional-analysis']"
67,Is 0 an eigenvalue of the right shift operator?,Is 0 an eigenvalue of the right shift operator?,,"My friend and I are a little bit confused about this, the question we are working on asks us to find the eigenvalues of $R$, the right shift operator. The main point of contention is that $\sigma(R)$ is non-empty, and so should surely(?) contain an eigenvalue of $R$. Does the non-emptiness of $\sigma(R)$ only apply in finite dimensional Hilbert spaces? A detailed reply to clear up the confusion would be appreciated.","My friend and I are a little bit confused about this, the question we are working on asks us to find the eigenvalues of $R$, the right shift operator. The main point of contention is that $\sigma(R)$ is non-empty, and so should surely(?) contain an eigenvalue of $R$. Does the non-emptiness of $\sigma(R)$ only apply in finite dimensional Hilbert spaces? A detailed reply to clear up the confusion would be appreciated.",,"['functional-analysis', 'analysis', 'operator-theory', 'linear-transformations']"
68,"Under a finite dimensional norm-induced metric space, is every bounded sequence has a converging subsequence?","Under a finite dimensional norm-induced metric space, is every bounded sequence has a converging subsequence?",,"What I know is that every bounded sequence in $\Bbb R^n$ has a converging sub sequence regardless of the chosen norm, since this is true under the Euclidean norm, and all norms on $\Bbb R^n$ are equivalent. My question is Is every bounded sequence has a converging sub sequence for any norm-induced metric space? If not, a counter-example is appreciated. Thanks!","What I know is that every bounded sequence in $\Bbb R^n$ has a converging sub sequence regardless of the chosen norm, since this is true under the Euclidean norm, and all norms on $\Bbb R^n$ are equivalent. My question is Is every bounded sequence has a converging sub sequence for any norm-induced metric space? If not, a counter-example is appreciated. Thanks!",,"['real-analysis', 'functional-analysis']"
69,Regarding the dual cone in a normed space,Regarding the dual cone in a normed space,,"$X$ is a normed space and $C\subset X$ a convex and closed cone ( $\lambda C\subset C\ \forall \lambda\geq0$ ), and $C':=\{x'\in X':x'(x)\geq0\ \forall x\in C\}$ the dual cone of $C$ . I want to show: $(i):\quad C\neq X\Rightarrow C'\neq\{0\}$ $(ii):\quad x'(x)\geq0\ \forall x'\in C'\Rightarrow x\in C$ Because in class we talked about separation theorems, my approach so far was: Let $C\neq X$ then $\exists x_0\notin C$ . Then $\{x_0\}$ is closed and convex, the Hahn-Banach-Separation-Theorem provides $x_0'$ such that $x_0'(x_0)<\inf_{x\in C}x_0'(x)\leq0$ . This is were I'm stuck...","is a normed space and a convex and closed cone ( ), and the dual cone of . I want to show: Because in class we talked about separation theorems, my approach so far was: Let then . Then is closed and convex, the Hahn-Banach-Separation-Theorem provides such that . This is were I'm stuck...",X C\subset X \lambda C\subset C\ \forall \lambda\geq0 C':=\{x'\in X':x'(x)\geq0\ \forall x\in C\} C (i):\quad C\neq X\Rightarrow C'\neq\{0\} (ii):\quad x'(x)\geq0\ \forall x'\in C'\Rightarrow x\in C C\neq X \exists x_0\notin C \{x_0\} x_0' x_0'(x_0)<\inf_{x\in C}x_0'(x)\leq0,"['functional-analysis', 'normed-spaces', 'separation-axioms']"
70,Intermediate values of $p$-norms,Intermediate values of -norms,p,"Let $x,y \in [0,1]^n$ be $n$ dimensional vectors with elements in the continuous set $[0,1]$. Suppose we have the following conditions: 1) $\Vert x\Vert_1 = \Vert y \Vert_1=1$ , 2) $\Vert x\Vert_2 \geq \Vert y \Vert_2$ , 3) $\Vert x\Vert_\infty \geq \Vert y \Vert_\infty$, where $\Vert x\Vert_\alpha := \left( \sum x_i^\alpha\right)^{1/\alpha}.$ Can we deduce the following: $\Vert x\Vert_\alpha \geq \Vert y \Vert_\alpha$ for all $\alpha>1$?","Let $x,y \in [0,1]^n$ be $n$ dimensional vectors with elements in the continuous set $[0,1]$. Suppose we have the following conditions: 1) $\Vert x\Vert_1 = \Vert y \Vert_1=1$ , 2) $\Vert x\Vert_2 \geq \Vert y \Vert_2$ , 3) $\Vert x\Vert_\infty \geq \Vert y \Vert_\infty$, where $\Vert x\Vert_\alpha := \left( \sum x_i^\alpha\right)^{1/\alpha}.$ Can we deduce the following: $\Vert x\Vert_\alpha \geq \Vert y \Vert_\alpha$ for all $\alpha>1$?",,"['real-analysis', 'functional-analysis', 'measure-theory', 'normed-spaces']"
71,Determine the spectrum of a shift-operator,Determine the spectrum of a shift-operator,,"Let $\{a_n\}_{n=1}^{\infty} \subset \mathbb C$ be a sequence such that $|a_n|=r$ for all $n \geq 1$ and $r \geq 0$ Define $T: \ell^2 \to \ell^2$ by $T(x_1,x_2,x_3,...) = (0,a_1x_1,a_2x_2,....) $ with $(x_1,x_2,....) \in l^2$ Determine the spectrum of T. The spectrum of an operator is defined as $\{\lambda \in \mathbb{C}: T-\lambda I  \ \text{is not invertible}\}$ I know how to calculate the eigenvalues of a matrix, but here I have really no idea to start. Can anyone help?","Let $\{a_n\}_{n=1}^{\infty} \subset \mathbb C$ be a sequence such that $|a_n|=r$ for all $n \geq 1$ and $r \geq 0$ Define $T: \ell^2 \to \ell^2$ by $T(x_1,x_2,x_3,...) = (0,a_1x_1,a_2x_2,....) $ with $(x_1,x_2,....) \in l^2$ Determine the spectrum of T. The spectrum of an operator is defined as $\{\lambda \in \mathbb{C}: T-\lambda I  \ \text{is not invertible}\}$ I know how to calculate the eigenvalues of a matrix, but here I have really no idea to start. Can anyone help?",,"['functional-analysis', 'operator-theory']"
72,Is the pythagoras theorem true for an infinite set of vectors?,Is the pythagoras theorem true for an infinite set of vectors?,,Let $H$ be a Hilbert space. Consider a collection of orthogonal vectors $\{x_n\}_{n=1}^{k}$. We know that $$\left\|\sum_{n=1}^{k}x_n\right\|^2=\sum_{n=1}^{k}\|x_n\|^2$$ Now consider an infinite collection of orthogonal vectors $\{y_n\}_{n=1}^{\infty}.$ Is it true that  $$\left\|\sum_{n=1}^{\infty}y_n\right\|^2=\sum_{n=1}^{\infty}\|y_n\|^2$$,Let $H$ be a Hilbert space. Consider a collection of orthogonal vectors $\{x_n\}_{n=1}^{k}$. We know that $$\left\|\sum_{n=1}^{k}x_n\right\|^2=\sum_{n=1}^{k}\|x_n\|^2$$ Now consider an infinite collection of orthogonal vectors $\{y_n\}_{n=1}^{\infty}.$ Is it true that  $$\left\|\sum_{n=1}^{\infty}y_n\right\|^2=\sum_{n=1}^{\infty}\|y_n\|^2$$,,"['functional-analysis', 'hilbert-spaces']"
73,A spectrum of an invertible operator does not contain $0$,A spectrum of an invertible operator does not contain,0,"Let $A:D(A)\to X$ be closed linear operator in a Banach space. For some complex number $\lambda$, the resolvent operator $R(\lambda,A)$ is the inverse of the operator $\lambda I-A$ if it exists. In this book about the theory of semigroup of operators, page 243, 1.13 Spectral Mapping Theorem for the Resolvent, the authors gave a formula which links the spectrum of the operator $A$ with the spectrum of its resolvent operator $R(\lambda,A)$ for some $\lambda \in \mathbb{C}$. What I don't get in this formula is why the authors need to exlude $0$ from the spectrum of the resolvent operator $R(\lambda,A)$ ? isn't $0$ already not in the spectrum of $R(\lambda,A)$ because it is an invertible operator ?","Let $A:D(A)\to X$ be closed linear operator in a Banach space. For some complex number $\lambda$, the resolvent operator $R(\lambda,A)$ is the inverse of the operator $\lambda I-A$ if it exists. In this book about the theory of semigroup of operators, page 243, 1.13 Spectral Mapping Theorem for the Resolvent, the authors gave a formula which links the spectrum of the operator $A$ with the spectrum of its resolvent operator $R(\lambda,A)$ for some $\lambda \in \mathbb{C}$. What I don't get in this formula is why the authors need to exlude $0$ from the spectrum of the resolvent operator $R(\lambda,A)$ ? isn't $0$ already not in the spectrum of $R(\lambda,A)$ because it is an invertible operator ?",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'semigroup-of-operators']"
74,"Does boundedness of $\sigma(T)$ imply boundedness of $T$, $T$ an operator on a Banach space?","Does boundedness of  imply boundedness of ,  an operator on a Banach space?",\sigma(T) T T,"let $X$ be a Banach space and suppose $T$ is an operator on $X$. If $T$ is bounded, then clearly $\sigma(T)$ is also bounded in the sense that $r(T) := \sup_{\lambda\in \sigma(T)}|\lambda| < \infty.$ Does this follow the other way, viz. if $r(T) < \infty$ does it follow that $T$ is bounded? In the light of the counter-examples Tsemo and TrialAndError and Ben Wallis' comment, let us add the additional requirement that $r(T) > 0$ so operators with empty spectrum are not considered. I appreciate these answers and the people who wrote them, however we might agree that trivial cases are not generally the most interesting. The fault is mine for the imprecision.","let $X$ be a Banach space and suppose $T$ is an operator on $X$. If $T$ is bounded, then clearly $\sigma(T)$ is also bounded in the sense that $r(T) := \sup_{\lambda\in \sigma(T)}|\lambda| < \infty.$ Does this follow the other way, viz. if $r(T) < \infty$ does it follow that $T$ is bounded? In the light of the counter-examples Tsemo and TrialAndError and Ben Wallis' comment, let us add the additional requirement that $r(T) > 0$ so operators with empty spectrum are not considered. I appreciate these answers and the people who wrote them, however we might agree that trivial cases are not generally the most interesting. The fault is mine for the imprecision.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'spectral-theory']"
75,Pointwise convergence vs norm convergence in $X^*$,Pointwise convergence vs norm convergence in,X^*,"Let $X$ be a normed space, $X^*$ its dual space and $\left\|{T}\right\|=\sup\{|T(x)|:\left\|x\right\|=1\}$, the usual norm in $X^*$. Let $(T_n)\subseteq X^*$. It is true that if $T_n\to 0$ in $X^*$ then $T_n$ converges pointwise to zero, because for every $x\in X$ we have $|T_n(x)|\le \left\|{T_n}\right\|\left\|{x}\right\|$. The converse is not true. However, in all counterexamples I've seen we have $\dim X=\infty$. Could it be true if $\dim X<\infty$? If not, could anyone help me to find a counterexample even in this case? Thank you.","Let $X$ be a normed space, $X^*$ its dual space and $\left\|{T}\right\|=\sup\{|T(x)|:\left\|x\right\|=1\}$, the usual norm in $X^*$. Let $(T_n)\subseteq X^*$. It is true that if $T_n\to 0$ in $X^*$ then $T_n$ converges pointwise to zero, because for every $x\in X$ we have $|T_n(x)|\le \left\|{T_n}\right\|\left\|{x}\right\|$. The converse is not true. However, in all counterexamples I've seen we have $\dim X=\infty$. Could it be true if $\dim X<\infty$? If not, could anyone help me to find a counterexample even in this case? Thank you.",,"['functional-analysis', 'normed-spaces']"
76,Prove: For any sequence of linearly independent elements $y_j \in X$ and $a_j \in \mathbb R$ there exists an element $f \in X^*$ s.t. $f(y_j)=a_j$,Prove: For any sequence of linearly independent elements  and  there exists an element  s.t.,y_j \in X a_j \in \mathbb R f \in X^* f(y_j)=a_j,"I'm trying to solve the following problem but I have no clue how to do it. Let $(X,||.||)$ be a normed $\mathbb C$-vector space. Prove: For any sequence of linearly independent elements $y_j, 1 \leq j \leq N$, in $X$ and any sequence $(a_j)_{1 \leq j \leq N}$ in $\mathbb R$ there exists an element $f \in X^*$ s.t. $f(y_j)=a_j$ for any $1 \leq j \leq N$. The only thing I know is that I need at some point the Hahn-Banach Theorem. I would be grateful if someone could help me to prove this statement. Thanks!","I'm trying to solve the following problem but I have no clue how to do it. Let $(X,||.||)$ be a normed $\mathbb C$-vector space. Prove: For any sequence of linearly independent elements $y_j, 1 \leq j \leq N$, in $X$ and any sequence $(a_j)_{1 \leq j \leq N}$ in $\mathbb R$ there exists an element $f \in X^*$ s.t. $f(y_j)=a_j$ for any $1 \leq j \leq N$. The only thing I know is that I need at some point the Hahn-Banach Theorem. I would be grateful if someone could help me to prove this statement. Thanks!",,"['sequences-and-series', 'functional-analysis', 'vector-spaces', 'normed-spaces']"
77,Speed of convergence of $\frac1n\int_0^1 f(x/n)dx\to0$?,Speed of convergence of ?,\frac1n\int_0^1 f(x/n)dx\to0,"Let $f\in L^2(0,1)$, this implies that $$\frac1n\left|\int_0^1 f(x/n) dx\,\right| =\left|\int_0^{1/n} f(x) dx\,\right|=\left|\langle \chi_{[0,1/n]}, f\rangle_{L^2}\right|≤\|\chi_{[0,1/n]}\|_{L^2}\cdot \|f\|_{L_2}=\frac{\|f\|_{L^2}}{\sqrt{n}}$$ My question is whether there is a better bound on the speed of convergence than a $\frac1{\sqrt n}$ factor. I ask because playing around with different $f$ it looks like $$\sum_n \frac1{n^2}\left|\int_0^1 f(x/n) dx\,\right|^2$$ is always summable, and I would like to find a bound like $\sum_n\frac1{n^2}\left|\int_0^1 f(x/n)\, dx\right|^2≤M\|f\|_{L^2}^2$.","Let $f\in L^2(0,1)$, this implies that $$\frac1n\left|\int_0^1 f(x/n) dx\,\right| =\left|\int_0^{1/n} f(x) dx\,\right|=\left|\langle \chi_{[0,1/n]}, f\rangle_{L^2}\right|≤\|\chi_{[0,1/n]}\|_{L^2}\cdot \|f\|_{L_2}=\frac{\|f\|_{L^2}}{\sqrt{n}}$$ My question is whether there is a better bound on the speed of convergence than a $\frac1{\sqrt n}$ factor. I ask because playing around with different $f$ it looks like $$\sum_n \frac1{n^2}\left|\int_0^1 f(x/n) dx\,\right|^2$$ is always summable, and I would like to find a bound like $\sum_n\frac1{n^2}\left|\int_0^1 f(x/n)\, dx\right|^2≤M\|f\|_{L^2}^2$.",,"['integration', 'functional-analysis', 'convergence-divergence', 'asymptotics', 'lp-spaces']"
78,Find the operator norm.,Find the operator norm.,,"Let $A$ be an operator on the Hilbert space $L^2([0, \pi])$ defined by $$ A(f)(x) = \int_0^\pi \cos(x-y)f(y) \ dy ,$$ where $0 \leq x \leq \pi$. Find the operator norm of $A$. By definition $\| A \| = \sup_{\| f \| = 1} \| Af \|$. We also have  \begin{align*} \| Af \| &= \left( \int_0^\pi \left| \int_0^\pi \cos(x-y)f(y) \ dy \ \right| ^2  \ dx \right)^{1/2} \\ &\leq \| f \| \left( \int_0^\pi \int_0^\pi \left| \cos(x-y) \right|^2 \ dy  \  dx \right)^{1/2} \\ &=\| f \| \left( \int_0^\pi \int_0^\pi \cos^2(x-y)  \ dy  \  dx \right)^{1/2} \\ &= \|f\| \pi/\sqrt{2} \end{align*} Thus $\| A\| \leq \pi/\sqrt{2}$. But it is hard to find a function $f$ such that $\| Af \|$ equals $\| f \| \pi/\sqrt{2}$. May be I made a mistake or I need to use some other approach. Could you give me some tips please.","Let $A$ be an operator on the Hilbert space $L^2([0, \pi])$ defined by $$ A(f)(x) = \int_0^\pi \cos(x-y)f(y) \ dy ,$$ where $0 \leq x \leq \pi$. Find the operator norm of $A$. By definition $\| A \| = \sup_{\| f \| = 1} \| Af \|$. We also have  \begin{align*} \| Af \| &= \left( \int_0^\pi \left| \int_0^\pi \cos(x-y)f(y) \ dy \ \right| ^2  \ dx \right)^{1/2} \\ &\leq \| f \| \left( \int_0^\pi \int_0^\pi \left| \cos(x-y) \right|^2 \ dy  \  dx \right)^{1/2} \\ &=\| f \| \left( \int_0^\pi \int_0^\pi \cos^2(x-y)  \ dy  \  dx \right)^{1/2} \\ &= \|f\| \pi/\sqrt{2} \end{align*} Thus $\| A\| \leq \pi/\sqrt{2}$. But it is hard to find a function $f$ such that $\| Af \|$ equals $\| f \| \pi/\sqrt{2}$. May be I made a mistake or I need to use some other approach. Could you give me some tips please.",,"['functional-analysis', 'hilbert-spaces', 'normed-spaces']"
79,Push-forward measure's Radon-Nikodim Derivative,Push-forward measure's Radon-Nikodim Derivative,,"Suppose $\mu$ and $\nu$ are probability measures on $\langle \Omega,\mathfrak{F}\rangle$ such that $$ (\forall A \in \mathfrak{F})\, \mu(A) \triangleq\int_{\Omega}1_A(x)f(x)d\nu(x), $$ for some measurable function $f$.  Furthermore suppose that $\nu\sim\mu$ are equivalent probability measures. If $F:\langle \Omega,\mathfrak{F}\rangle\rightarrow \langle \Omega,\mathfrak{F}\rangle$ is a bijective measurable function with measurable inverse then is the push-forward measure $F_{\star}\mu$ of the form $$ F_{\star}\mu(A) = \int_{\Omega} 1_AF\circ fd\nu? $$","Suppose $\mu$ and $\nu$ are probability measures on $\langle \Omega,\mathfrak{F}\rangle$ such that $$ (\forall A \in \mathfrak{F})\, \mu(A) \triangleq\int_{\Omega}1_A(x)f(x)d\nu(x), $$ for some measurable function $f$.  Furthermore suppose that $\nu\sim\mu$ are equivalent probability measures. If $F:\langle \Omega,\mathfrak{F}\rangle\rightarrow \langle \Omega,\mathfrak{F}\rangle$ is a bijective measurable function with measurable inverse then is the push-forward measure $F_{\star}\mu$ of the form $$ F_{\star}\mu(A) = \int_{\Omega} 1_AF\circ fd\nu? $$",,"['functional-analysis', 'probability-theory']"
80,Vectors converging to linearly independent vectors are eventually linearly independent,Vectors converging to linearly independent vectors are eventually linearly independent,,"I hesitate if the following claim is true: Let $V$ be a normed vector space that is complete. For example, Hilbert space. And assume $\{v_1,...v_n\}$ is a subset of linearly independent vectors in $V$. Assume also that for any $v_k$ we have a sequence of vectors in $V$ that converges to $v_k$, denote it $({w_{m}}^k)_m$ . Is that true that there exists large enough $m$ for which the subset of vectors $\{{w_m}^1,...,{w_m}^n\}$ is linearly independent? Thank you in advance!","I hesitate if the following claim is true: Let $V$ be a normed vector space that is complete. For example, Hilbert space. And assume $\{v_1,...v_n\}$ is a subset of linearly independent vectors in $V$. Assume also that for any $v_k$ we have a sequence of vectors in $V$ that converges to $v_k$, denote it $({w_{m}}^k)_m$ . Is that true that there exists large enough $m$ for which the subset of vectors $\{{w_m}^1,...,{w_m}^n\}$ is linearly independent? Thank you in advance!",,['functional-analysis']
81,Understanding of the characterization of $H^{-1}$ in Evans's PDE book,Understanding of the characterization of  in Evans's PDE book,H^{-1},The following is the characterization theorem for $H^{-1}(U):=(H_0^1(U))^*$ in Evans's Partial Differential Equations : Here is my question : The proof says that (iii) directly follows from (i). Would anybody elaborate why it is so? $U$ is an open subset of $\mathbb{R}^{n}$ $H^{1}(U)$ is the Sobolev space of $L^{2}(U)$ functions with weak derivatives in $L^{2}(U)$ $H_{0}^{1}(U)$ is the closure of the subspace $\mathcal{C}_{c}^{\infty}(U)$ of compactly supported smooth functions on $U$ $H^{-1}(U)$ is the (continuous) dual of $H_{0}^{1}(U)$,The following is the characterization theorem for $H^{-1}(U):=(H_0^1(U))^*$ in Evans's Partial Differential Equations : Here is my question : The proof says that (iii) directly follows from (i). Would anybody elaborate why it is so? $U$ is an open subset of $\mathbb{R}^{n}$ $H^{1}(U)$ is the Sobolev space of $L^{2}(U)$ functions with weak derivatives in $L^{2}(U)$ $H_{0}^{1}(U)$ is the closure of the subspace $\mathcal{C}_{c}^{\infty}(U)$ of compactly supported smooth functions on $U$ $H^{-1}(U)$ is the (continuous) dual of $H_{0}^{1}(U)$,,['functional-analysis']
82,Approximation theory in Banach Spaces.,Approximation theory in Banach Spaces.,,"This semester I am taking a class on approximation theory (centred primarily on the best approximation of an element in a space from an element in a subspace) and so far most of our work has been done in the realm of inner product spaces and Hilbert spaces. Naturally things follow fairly fluidly within the framework of an inner product space, but what about when approximation theory is practiced in a Banach space? What results in the approximation of functions are much harder, perhaps impossible, to obtain in a Banach Space? And are there any open problems in the area? (After class my lecturer told me that there are some things we can do when approximating functions in a Hilbert space that we can't do in a Banach space; also that there are many things that have not yet been shown in a Banach space that hold in a Hilbert space with regards to the approximation of functions.)","This semester I am taking a class on approximation theory (centred primarily on the best approximation of an element in a space from an element in a subspace) and so far most of our work has been done in the realm of inner product spaces and Hilbert spaces. Naturally things follow fairly fluidly within the framework of an inner product space, but what about when approximation theory is practiced in a Banach space? What results in the approximation of functions are much harder, perhaps impossible, to obtain in a Banach Space? And are there any open problems in the area? (After class my lecturer told me that there are some things we can do when approximating functions in a Hilbert space that we can't do in a Banach space; also that there are many things that have not yet been shown in a Banach space that hold in a Hilbert space with regards to the approximation of functions.)",,"['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'approximation', 'approximation-theory']"
83,"$\|f\|^2 =\sum_j|\langle f, f_j \rangle|^2$ implies $\langle f, g \rangle=\sum_j \langle f, f_j\rangle\langle f_j, g\rangle$.",implies .,"\|f\|^2 =\sum_j|\langle f, f_j \rangle|^2 \langle f, g \rangle=\sum_j \langle f, f_j\rangle\langle f_j, g\rangle","Let $\mathcal{H}$ be a complex Hilbert space, let $f, g \in \mathcal{H}$ and let $(f_j)_{j \in J} \subset \mathcal{H}$, which is indexed by an index set $J \subseteq \mathbb{Z}$. Suppose $\langle f, f \rangle = \sum_{j \in J} | \langle f, f_j \rangle|^2$. Then    $$ \langle f, g \rangle = \sum_{j \in J} \langle f, f_j \rangle \langle f_j, g \rangle. $$ I have seen the above result several times, and it seems to be a standard result.  In general, it is mentioned that the result follows by ""polarisation"". However, I am not entirely sure how to apply the polarisation identity here. Any help and/or comment is highly appreciated.","Let $\mathcal{H}$ be a complex Hilbert space, let $f, g \in \mathcal{H}$ and let $(f_j)_{j \in J} \subset \mathcal{H}$, which is indexed by an index set $J \subseteq \mathbb{Z}$. Suppose $\langle f, f \rangle = \sum_{j \in J} | \langle f, f_j \rangle|^2$. Then    $$ \langle f, g \rangle = \sum_{j \in J} \langle f, f_j \rangle \langle f_j, g \rangle. $$ I have seen the above result several times, and it seems to be a standard result.  In general, it is mentioned that the result follows by ""polarisation"". However, I am not entirely sure how to apply the polarisation identity here. Any help and/or comment is highly appreciated.",,['functional-analysis']
84,polynomial approximation in Hardy space $H^\infty$,polynomial approximation in Hardy space,H^\infty,"$H^\infty$ is the Hardy space of bounded analytic functions on the open unit disk $|z| < 1$ with the norm $$\|f\|  = \sup_{ |z| \,< \,1}|f(z)|$$ It has two important subspaces : $H^\infty_C$ the (closed) subspace of analytic functions that stay continuous on the closed unit disk $|z|\le 1$. $H^\infty_K $ the subspace of functions whose Taylor series stay convergent on $|z| = 1$ Question : Can you show that $H^\infty_C \subseteq H^\infty_K$, or find a counter-example $f \in H^\infty_C, f \not\in H^\infty_K$  ? Attempt : $f \in H^\infty_C, f \not\in H^\infty_K$ means its Fourier series diverges, so it can't be Holder continuous on the boundary, and the Dini's criterion should diverge. That's why I thought to $f(z) = \frac{z}{\log(1-z)}$, but it seems its Taylor coefficients are all of the same sign, so Abel's lemma guarantees it converges. Next try  : things like $\frac{1}{\log \log (1-z)}$ or $\frac{1}{\log \log \log \log (1-z)}$ (the branch $\log(1) = 2i\pi$) there is a proof of existence (but no example) of a $2\pi$-periodic continuous function whose Fourier series diverges at one point (but it doesn't have to be analytic, so it doesn't apply here) $f_N(z) = \sum_{n=0}^N \frac{f^{(n)}(0)}{n!} z^n$ is the truncated Taylor series. With $r \to 1^-$ , and $N \to \infty$ : $$\begin{eqnarray}\|f(z)-f_N(rz)\| & \ =\ & \|(f(z)-f(rz))+(f(rz)-f_N(rz))\| \\ & \le &  \|f(z)-f(rz)\|+\|f(rz)-f_N(rz)\| \end{eqnarray} $$ $f \in H^\infty_C$ means it is uniformly continuous on $|z| \le 1$ so that $ \|f(z)-f(rz)\| = o(r)$, and $f(rz)$ is analytic on $1/r > 1$ hence it is approximated uniformly on $|z| \le 1$  by its truncated Taylor series $f_N(rz)$, so that $\|f(rz)-f_N(rz)\| = o_r(N)$ and $$\|f(z)-f_N(rz)\| = o(r)+o_r(N)$$ showing that the polynomials are dense in $H^\infty_C$. But doing the same for $\|f(z) - f_N(z)\|$ is more complicated : $$\begin{eqnarray}\|f(z)-f_N(z)\| & \ =\ & \|(f(z)-f_N(rz))+(f_N(rz)-f_N(z))\| \\ & \le &  \|f(z)-f_N(rz)\|+\|f_N(rz)-f_N(z)\| \\ & = & o(r)+o_r(N) + \mathcal{O}((r-1)N) \end{eqnarray} $$ Ideally, if $f \in H^\infty_K$ then we would have $\|f_N(rz)-f_N(z)\|< \alpha \|f(rz)-f(z)\| = o(r)$ so that $\|f(z)-f_N(z)\| = o(r) + o_r(N)$. Hence, for showing $f \in H^\infty_K$, one needs a good bound for $\|f_N(rz)-f_N(z)\|$, probably using that $$f_N(rz)-f_N(z) = \frac{1}{2i\pi} \int_{|s| = R} \frac{f(s)}{s} \left(\frac{1-(rz/s)^{N+1}}{1-rz/s}-\frac{1-(z/s)^{N+1}}{1-z/s}\right)ds$$","$H^\infty$ is the Hardy space of bounded analytic functions on the open unit disk $|z| < 1$ with the norm $$\|f\|  = \sup_{ |z| \,< \,1}|f(z)|$$ It has two important subspaces : $H^\infty_C$ the (closed) subspace of analytic functions that stay continuous on the closed unit disk $|z|\le 1$. $H^\infty_K $ the subspace of functions whose Taylor series stay convergent on $|z| = 1$ Question : Can you show that $H^\infty_C \subseteq H^\infty_K$, or find a counter-example $f \in H^\infty_C, f \not\in H^\infty_K$  ? Attempt : $f \in H^\infty_C, f \not\in H^\infty_K$ means its Fourier series diverges, so it can't be Holder continuous on the boundary, and the Dini's criterion should diverge. That's why I thought to $f(z) = \frac{z}{\log(1-z)}$, but it seems its Taylor coefficients are all of the same sign, so Abel's lemma guarantees it converges. Next try  : things like $\frac{1}{\log \log (1-z)}$ or $\frac{1}{\log \log \log \log (1-z)}$ (the branch $\log(1) = 2i\pi$) there is a proof of existence (but no example) of a $2\pi$-periodic continuous function whose Fourier series diverges at one point (but it doesn't have to be analytic, so it doesn't apply here) $f_N(z) = \sum_{n=0}^N \frac{f^{(n)}(0)}{n!} z^n$ is the truncated Taylor series. With $r \to 1^-$ , and $N \to \infty$ : $$\begin{eqnarray}\|f(z)-f_N(rz)\| & \ =\ & \|(f(z)-f(rz))+(f(rz)-f_N(rz))\| \\ & \le &  \|f(z)-f(rz)\|+\|f(rz)-f_N(rz)\| \end{eqnarray} $$ $f \in H^\infty_C$ means it is uniformly continuous on $|z| \le 1$ so that $ \|f(z)-f(rz)\| = o(r)$, and $f(rz)$ is analytic on $1/r > 1$ hence it is approximated uniformly on $|z| \le 1$  by its truncated Taylor series $f_N(rz)$, so that $\|f(rz)-f_N(rz)\| = o_r(N)$ and $$\|f(z)-f_N(rz)\| = o(r)+o_r(N)$$ showing that the polynomials are dense in $H^\infty_C$. But doing the same for $\|f(z) - f_N(z)\|$ is more complicated : $$\begin{eqnarray}\|f(z)-f_N(z)\| & \ =\ & \|(f(z)-f_N(rz))+(f_N(rz)-f_N(z))\| \\ & \le &  \|f(z)-f_N(rz)\|+\|f_N(rz)-f_N(z)\| \\ & = & o(r)+o_r(N) + \mathcal{O}((r-1)N) \end{eqnarray} $$ Ideally, if $f \in H^\infty_K$ then we would have $\|f_N(rz)-f_N(z)\|< \alpha \|f(rz)-f(z)\| = o(r)$ so that $\|f(z)-f_N(z)\| = o(r) + o_r(N)$. Hence, for showing $f \in H^\infty_K$, one needs a good bound for $\|f_N(rz)-f_N(z)\|$, probably using that $$f_N(rz)-f_N(z) = \frac{1}{2i\pi} \int_{|s| = R} \frac{f(s)}{s} \left(\frac{1-(rz/s)^{N+1}}{1-rz/s}-\frac{1-(z/s)^{N+1}}{1-z/s}\right)ds$$",,"['complex-analysis', 'functional-analysis', 'polynomials', 'fourier-series']"
85,"Example of a Banach algebra with identity $e$ such that $\|e\| = t$, where $t \geq 1$.","Example of a Banach algebra with identity  such that , where .",e \|e\| = t t \geq 1,"There is the following result: Suppose $X$ is a normed algebra with identity $e$. Then $\|e\| \geq 1$. I am looking for an example to show that even a Banach algebra $X$ with identity $e$ not necessarily satisfies $\|e\| = 1$. A general example such that $\|e\| = t$, where $t \geq 1$ would be even more interesting. I am aware of several examples of Banach algebras with identity, but these all have an identity with norm $1$. As algebras have exactly one identity, I think I cannot use the well-known Banach algebras as an example. Any help or comment is highly appreciated.","There is the following result: Suppose $X$ is a normed algebra with identity $e$. Then $\|e\| \geq 1$. I am looking for an example to show that even a Banach algebra $X$ with identity $e$ not necessarily satisfies $\|e\| = 1$. A general example such that $\|e\| = t$, where $t \geq 1$ would be even more interesting. I am aware of several examples of Banach algebras with identity, but these all have an identity with norm $1$. As algebras have exactly one identity, I think I cannot use the well-known Banach algebras as an example. Any help or comment is highly appreciated.",,['functional-analysis']
86,"$X,Y$ be NLS , $T:X \to Y$ be a linear map such that $T^{-1}(\{y\})$ is closed for every $y \in Y$ and $T$ has closed graph , then is $T$ continuous?","be NLS ,  be a linear map such that  is closed for every  and  has closed graph , then is  continuous?","X,Y T:X \to Y T^{-1}(\{y\}) y \in Y T T","Let $X,Y$ be NLS , $T:X \to Y$ be a linear map such that $T^{-1}(\{y\})$ is closed for every $y \in Y$ and $T$ has closed graph , then is it true that $T$ is continuous ? I know that the statement is true if $Y$ is finite dimensional because in that case $\ker T$ closed implies continuity of $T$  , and I also know that if $X,Y$ are Banach spaces then it is true by closed graph theorem . But I don't know what happens in general  . Since $T$ has closed graph , I know that $T$ maps compact sets to closed sets ; for general metric spaces I know that a function having closed graph and carrying compact sets to ""compact ""sets must be continuous , so it seems we are very close . Though for $\mathbb R$ and only maps ( not linear ) the statement is false as can be seen from $f : \mathbb R \to \mathbb R$ as $f(x)=1/x , \forall  x\ne 0 ; f(0)=0$","Let $X,Y$ be NLS , $T:X \to Y$ be a linear map such that $T^{-1}(\{y\})$ is closed for every $y \in Y$ and $T$ has closed graph , then is it true that $T$ is continuous ? I know that the statement is true if $Y$ is finite dimensional because in that case $\ker T$ closed implies continuity of $T$  , and I also know that if $X,Y$ are Banach spaces then it is true by closed graph theorem . But I don't know what happens in general  . Since $T$ has closed graph , I know that $T$ maps compact sets to closed sets ; for general metric spaces I know that a function having closed graph and carrying compact sets to ""compact ""sets must be continuous , so it seems we are very close . Though for $\mathbb R$ and only maps ( not linear ) the statement is false as can be seen from $f : \mathbb R \to \mathbb R$ as $f(x)=1/x , \forall  x\ne 0 ; f(0)=0$",,"['functional-analysis', 'metric-spaces']"
87,How to show that $\chi_R(x) \nabla \frac 1{|x|} \in L^1(\mathbb R^3) \cap L^{3/2}(\mathbb R^3)$,How to show that,\chi_R(x) \nabla \frac 1{|x|} \in L^1(\mathbb R^3) \cap L^{3/2}(\mathbb R^3),"Let $\chi_R(x)$ be a smooth function such that $\chi_R(x)=1$ if $|x| \le R$, $\chi_R(x) = 0$ if $|x| \ge 2R$, and $0 \le \chi_R(x) \le 1$ for all $x \in \mathbb R^3$. How can we show that  $\chi_R(x) \nabla \frac 1{|x|} \in L^1(\mathbb R^3) \cap L^{3/2}(\mathbb R^3)$? In particular, I'm stuck at the $\chi_R(x) \nabla \frac 1{|x|} \in L^{3/2}(\mathbb R^3)$ part, I got $$\int_{\mathbb R^n} \left|\chi_R(x) \nabla \frac 1{|x|}\right|^{3/2} dx \le \int_{B(0,2R)} \left|\nabla \frac 1{|x|}\right|^{3/2} dx = \int_{B(0,2R)}\frac 1{|x|^3} dx =\infty$$ so I got $\infty$ but obviously I'm trying to get less than $\infty$. I think my inequality might be too crude. Edit: This is more precise and seems to me more plausible, but I'm still not sure if this answers my question: $$\int_{\mathbb R^n} \left|\chi_R(x) \nabla \frac 1{|x|}\right|^{3/2} dx \color{red}{<} \int_{B(0,2R)} \left|\nabla \frac 1{|x|}\right|^{3/2} dx = \int_{B(0,2R)}\frac 1{|x|^3} dx =\infty$$ (I figured it was a strict inequality because $\chi_R(x) < 1$ as $|x|$ is close enough to $2R$. Wishful thinking, though: the first integral is still equal to $\infty$.)","Let $\chi_R(x)$ be a smooth function such that $\chi_R(x)=1$ if $|x| \le R$, $\chi_R(x) = 0$ if $|x| \ge 2R$, and $0 \le \chi_R(x) \le 1$ for all $x \in \mathbb R^3$. How can we show that  $\chi_R(x) \nabla \frac 1{|x|} \in L^1(\mathbb R^3) \cap L^{3/2}(\mathbb R^3)$? In particular, I'm stuck at the $\chi_R(x) \nabla \frac 1{|x|} \in L^{3/2}(\mathbb R^3)$ part, I got $$\int_{\mathbb R^n} \left|\chi_R(x) \nabla \frac 1{|x|}\right|^{3/2} dx \le \int_{B(0,2R)} \left|\nabla \frac 1{|x|}\right|^{3/2} dx = \int_{B(0,2R)}\frac 1{|x|^3} dx =\infty$$ so I got $\infty$ but obviously I'm trying to get less than $\infty$. I think my inequality might be too crude. Edit: This is more precise and seems to me more plausible, but I'm still not sure if this answers my question: $$\int_{\mathbb R^n} \left|\chi_R(x) \nabla \frac 1{|x|}\right|^{3/2} dx \color{red}{<} \int_{B(0,2R)} \left|\nabla \frac 1{|x|}\right|^{3/2} dx = \int_{B(0,2R)}\frac 1{|x|^3} dx =\infty$$ (I figured it was a strict inequality because $\chi_R(x) < 1$ as $|x|$ is close enough to $2R$. Wishful thinking, though: the first integral is still equal to $\infty$.)",,"['integration', 'functional-analysis', 'lebesgue-integral', 'normed-spaces']"
88,about representations of a simple $C^*$-algebra,about representations of a simple -algebra,C^*,"We know that every simple $C^*$-algebra is primitive, say it has a faithful non-zero irreducible representation. The converse is not necessarily true. An counterexample is just the $B(H)$ when $H$ is of infinite dimension. But if  every irreducible representation of $C^*$-algebra $A$ is faithful, whether $A$ is simple? Thank you for all helps!","We know that every simple $C^*$-algebra is primitive, say it has a faithful non-zero irreducible representation. The converse is not necessarily true. An counterexample is just the $B(H)$ when $H$ is of infinite dimension. But if  every irreducible representation of $C^*$-algebra $A$ is faithful, whether $A$ is simple? Thank you for all helps!",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
89,How to show that a Schwartz distribution is in a Lebesgue or Sobolev space?,How to show that a Schwartz distribution is in a Lebesgue or Sobolev space?,,"It is known that all $L^p$ spaces (and, consequently, all $W^{s,p}$ spaces) can be embedded in the space of Schwartz distributions $\mathcal D '$. There is a problem, though: how do I check whether some given distribution $u \in \mathcal D '$ belongs to any of the Lebesgue or Sobolev spaces mentioned above? (There are problems requiring the student to show this, and I have no clue what technique(s) to use and how to approach them.)","It is known that all $L^p$ spaces (and, consequently, all $W^{s,p}$ spaces) can be embedded in the space of Schwartz distributions $\mathcal D '$. There is a problem, though: how do I check whether some given distribution $u \in \mathcal D '$ belongs to any of the Lebesgue or Sobolev spaces mentioned above? (There are problems requiring the student to show this, and I have no clue what technique(s) to use and how to approach them.)",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'lp-spaces', 'distribution-theory']"
90,"Poincaré's inequality proof for $u \in W_0^{1,p}(\Omega)$.",Poincaré's inequality proof for .,"u \in W_0^{1,p}(\Omega)","I am trying to prove Poincare's inequality for $u \in W_0^{1,p}(\Omega)$, where $\Omega \subset \mathbb{R}^n$ is an open bounded set and $1 \leq p < \infty$. This is Poincare's inequality: $||u||_{L^p(\Omega)} \leq C ||\nabla u ||_{L^p(\Omega)}$. For $p < N$ the inequality follows applying Sobolev-Gagliardo-Nirenberg inequality. Indeed, $$||u||_{p^*} \leq C||\nabla u||_{p}, $$ and from the fact that $\Omega$ is bounded we have $||u||_p \leq \tilde{C} ||u||_{p^*} \leq C||\nabla u||_{p}$. How can I prove the inequality for $ N \leq p < \infty$ ?","I am trying to prove Poincare's inequality for $u \in W_0^{1,p}(\Omega)$, where $\Omega \subset \mathbb{R}^n$ is an open bounded set and $1 \leq p < \infty$. This is Poincare's inequality: $||u||_{L^p(\Omega)} \leq C ||\nabla u ||_{L^p(\Omega)}$. For $p < N$ the inequality follows applying Sobolev-Gagliardo-Nirenberg inequality. Indeed, $$||u||_{p^*} \leq C||\nabla u||_{p}, $$ and from the fact that $\Omega$ is bounded we have $||u||_p \leq \tilde{C} ||u||_{p^*} \leq C||\nabla u||_{p}$. How can I prove the inequality for $ N \leq p < \infty$ ?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'lp-spaces']"
91,$A$ has a countable dense subset. How to describe a possible countable dense subset in $M_n(A)$?,has a countable dense subset. How to describe a possible countable dense subset in ?,A M_n(A),"Let $A$ be a C$^*$-algebra and $M$ be a countable dense subset in $A$. Let $M_n(A)$ be the $C^*$-algebra of $n\times n$-matrices with entries in $A$, $n\in\mathbb{N}$. Then $M_n(A)$ should have a countable dense subset as well. Is $L=\{(a_{ij})_{i,j=1,\ldots,n}\in M_n(A):\;  a_{ij}\in M\; \text{for all}\; i,j \}$ such a subset? It is clear that $L$ is countable, but is $L$ dense in $M_n(A)$?","Let $A$ be a C$^*$-algebra and $M$ be a countable dense subset in $A$. Let $M_n(A)$ be the $C^*$-algebra of $n\times n$-matrices with entries in $A$, $n\in\mathbb{N}$. Then $M_n(A)$ should have a countable dense subset as well. Is $L=\{(a_{ij})_{i,j=1,\ldots,n}\in M_n(A):\;  a_{ij}\in M\; \text{for all}\; i,j \}$ such a subset? It is clear that $L$ is countable, but is $L$ dense in $M_n(A)$?",,"['functional-analysis', 'c-star-algebras']"
92,$\frac{d}{dt}$ on $\mathbb{R}$ is not a Fredholm operator?,on  is not a Fredholm operator?,\frac{d}{dt} \mathbb{R},"I encountered a statement in a book that $\frac{d}{dt} : L^2_1(\mathbb{R}) \longrightarrow L^2 (\mathbb{R})$ is not a Fredholm operator, where $L^2_1$ is the first Sobolev space of the $L^2$ space. Consider a sequence of function $g_n$ such that $g_n \equiv 1$ on $[-n,n]$, increasing on $[-n-1,-n]$ and decreasing on $ [n,n+1]$, and vanishes outside of $[-n-1,n+1]$. We have $\operatorname{lim}_{n\longrightarrow \infty}\limits \lVert g_n \rVert_{L^2_1} = \infty$ and $\lVert \frac{d}{dt} g_n \rVert_{L^2} \leq C$ for some constant $C$. Then the author says if $\frac{d}{dt} $ is Fredholm, then the sequence will imply a non-trivial kernel which is a contradiction. My question is how he knows the implication of non-trivial kernel? Thank you edit: The book I'm reading is ""Floer homology groups in Yang-Mills theory"" by Donaldson and this problem is on page 58.","I encountered a statement in a book that $\frac{d}{dt} : L^2_1(\mathbb{R}) \longrightarrow L^2 (\mathbb{R})$ is not a Fredholm operator, where $L^2_1$ is the first Sobolev space of the $L^2$ space. Consider a sequence of function $g_n$ such that $g_n \equiv 1$ on $[-n,n]$, increasing on $[-n-1,-n]$ and decreasing on $ [n,n+1]$, and vanishes outside of $[-n-1,n+1]$. We have $\operatorname{lim}_{n\longrightarrow \infty}\limits \lVert g_n \rVert_{L^2_1} = \infty$ and $\lVert \frac{d}{dt} g_n \rVert_{L^2} \leq C$ for some constant $C$. Then the author says if $\frac{d}{dt} $ is Fredholm, then the sequence will imply a non-trivial kernel which is a contradiction. My question is how he knows the implication of non-trivial kernel? Thank you edit: The book I'm reading is ""Floer homology groups in Yang-Mills theory"" by Donaldson and this problem is on page 58.",,"['real-analysis', 'functional-analysis']"
93,How can we prove that the space of trace class operators on a Hilbert space $H$ is the closure of $H\otimes H$ with respect to the trace norm?,How can we prove that the space of trace class operators on a Hilbert space  is the closure of  with respect to the trace norm?,H H\otimes H,"Let $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a separable Hilbert space over $\mathbb R$ $\mathfrak L^1(H)$ be the space of trace class operators on $H$ and $$\operatorname{tr}L:=\sum_{n\in\mathbb N}\langle Le_n,e_n\rangle\;\;\;\text{for }L\in\mathfrak L^1(H)$$ for some orthonormal basis $(e_n)_{n\in\mathbb N}$ of $H$ As you know, $\operatorname{tr}L$ is called the trace of $L\in\mathfrak L(H)$ and its value is finite and independent of the choice of $(e_n)_{n\in\mathbb N}$. I've read that the closure of the tensor product $H\otimes H$ with respect to the trace norm $$\operatorname{tr}|L|:=\sum_{n\in\mathbb N}\langle\left(L^\ast L\right)^{\frac 12}e_n,e_n\rangle\;\;\;\text{for }L\in\mathfrak L^1(H)$$ equals $\mathfrak L^1(H)$. How can we prove this statement rigorously? I suppose there is some identification going on here, cause otherwise it wouldn't make much sense to talk about the trace norm of a tensor.","Let $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a separable Hilbert space over $\mathbb R$ $\mathfrak L^1(H)$ be the space of trace class operators on $H$ and $$\operatorname{tr}L:=\sum_{n\in\mathbb N}\langle Le_n,e_n\rangle\;\;\;\text{for }L\in\mathfrak L^1(H)$$ for some orthonormal basis $(e_n)_{n\in\mathbb N}$ of $H$ As you know, $\operatorname{tr}L$ is called the trace of $L\in\mathfrak L(H)$ and its value is finite and independent of the choice of $(e_n)_{n\in\mathbb N}$. I've read that the closure of the tensor product $H\otimes H$ with respect to the trace norm $$\operatorname{tr}|L|:=\sum_{n\in\mathbb N}\langle\left(L^\ast L\right)^{\frac 12}e_n,e_n\rangle\;\;\;\text{for }L\in\mathfrak L^1(H)$$ equals $\mathfrak L^1(H)$. How can we prove this statement rigorously? I suppose there is some identification going on here, cause otherwise it wouldn't make much sense to talk about the trace norm of a tensor.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'trace']"
94,"if $A_n$ weakly converges to $A$, does $|A_n| \rightarrow _{wo} |A|$?","if  weakly converges to , does ?",A_n A |A_n| \rightarrow _{wo} |A|,"Suppose that $A_n,A$ are self-adjoint operators in $B(H)$. If $A_n$ weakly converges to $A$, does $|A_n| \rightarrow _{wo} |A|$? From Proposition. 2.3.2 of Pederson'book, I know the result holds in the strong case.","Suppose that $A_n,A$ are self-adjoint operators in $B(H)$. If $A_n$ weakly converges to $A$, does $|A_n| \rightarrow _{wo} |A|$? From Proposition. 2.3.2 of Pederson'book, I know the result holds in the strong case.",,"['functional-analysis', 'operator-algebras', 'von-neumann-algebras']"
95,"the ""real spectrum"" of an operator acting on a real Banach space","the ""real spectrum"" of an operator acting on a real Banach space",,"Let $X$ be a Banach space over the field $\mathbb{R}$, and denote by $\mathcal{L}(X)$ the space of continuous linear operators acting on $X$.  The spectrum $\sigma(T)$ of an operator $T\in\mathcal{L}(X)$ is defined as the set of all $\lambda\in\mathbb{C}$ for which the complexification shift $\lambda-T_\mathbb{C}$ is not invertible in $\mathcal{L}(X_\mathbb{C})$.  (See here for the definition of a complexification.) However, I am interested in invertibility in the real setting. The real spectrum of $T$, denoted $\sigma_\mathbb{R}(T)$, is the set of all $a\in\mathbb{R}$ such that $a-T$ does not have an inverse in $\mathcal{L}(X)$.  It is the complement of the real resolvent , defined as \begin{equation}\rho_\mathbb{R}(T):=\left\{a\in\mathbb{R}:\text{ there is }\;S\in\mathcal{L}(X)\;\text{ such that }\;S(a-T)=(a-T)S=I_X\right\},\end{equation} where $I_X\in\mathcal{L}(X)$ is the identity operator ($I_Xx=x\;\forall x\in X$). Question 1. I suspect (although I haven't verified it yet) that $\sigma_\mathbb{R}(T)=\mathbb{R}\cap\sigma(T)$. Is there a reference for this? Question 2. Suppose $r\in\partial\sigma_\mathbb{R}(T)$ and $(a_n)_{n=1}^\infty\subseteq\rho_\mathbb{R}(T)$ with $a_n\to r$.  Is it true that $\|(a_n-T)^{-1}\|\to\infty$? I would also be interested in any good literature on the real spectrum, if it is available. Thank you!","Let $X$ be a Banach space over the field $\mathbb{R}$, and denote by $\mathcal{L}(X)$ the space of continuous linear operators acting on $X$.  The spectrum $\sigma(T)$ of an operator $T\in\mathcal{L}(X)$ is defined as the set of all $\lambda\in\mathbb{C}$ for which the complexification shift $\lambda-T_\mathbb{C}$ is not invertible in $\mathcal{L}(X_\mathbb{C})$.  (See here for the definition of a complexification.) However, I am interested in invertibility in the real setting. The real spectrum of $T$, denoted $\sigma_\mathbb{R}(T)$, is the set of all $a\in\mathbb{R}$ such that $a-T$ does not have an inverse in $\mathcal{L}(X)$.  It is the complement of the real resolvent , defined as \begin{equation}\rho_\mathbb{R}(T):=\left\{a\in\mathbb{R}:\text{ there is }\;S\in\mathcal{L}(X)\;\text{ such that }\;S(a-T)=(a-T)S=I_X\right\},\end{equation} where $I_X\in\mathcal{L}(X)$ is the identity operator ($I_Xx=x\;\forall x\in X$). Question 1. I suspect (although I haven't verified it yet) that $\sigma_\mathbb{R}(T)=\mathbb{R}\cap\sigma(T)$. Is there a reference for this? Question 2. Suppose $r\in\partial\sigma_\mathbb{R}(T)$ and $(a_n)_{n=1}^\infty\subseteq\rho_\mathbb{R}(T)$ with $a_n\to r$.  Is it true that $\|(a_n-T)^{-1}\|\to\infty$? I would also be interested in any good literature on the real spectrum, if it is available. Thank you!",,"['functional-analysis', 'banach-spaces', 'spectral-theory']"
96,A uniformly continuous on the unit sphere of $c_0$ is bounded,A uniformly continuous on the unit sphere of  is bounded,c_0,"Let $S_{c_0}= \{ x\in c_0 \;: \Vert x \Vert =\;1\; \}$, where $c_0$ is the space of all sequences converging to zero and  $$f: S_{c_0} \rightarrow \mathbb R$$ is a uniformly continuous function. Prove that $f$ is  bounded. I thought that if I could show $S_{c_0}$ is a compact set then by using the continuity of $f$, I would result in the requested point, but I feel like I'm missing something. Could anyone please help or give some hints? Thanks in advance!","Let $S_{c_0}= \{ x\in c_0 \;: \Vert x \Vert =\;1\; \}$, where $c_0$ is the space of all sequences converging to zero and  $$f: S_{c_0} \rightarrow \mathbb R$$ is a uniformly continuous function. Prove that $f$ is  bounded. I thought that if I could show $S_{c_0}$ is a compact set then by using the continuity of $f$, I would result in the requested point, but I feel like I'm missing something. Could anyone please help or give some hints? Thanks in advance!",,"['real-analysis', 'functional-analysis', 'banach-spaces']"
97,Essential singularity of the resolvent operator of an unbounded operator,Essential singularity of the resolvent operator of an unbounded operator,,"Is there an unbounded operator with isolated points in the spectrum, not all of which are eigenvalues? For unbounded operators it is known that isolated spectral points are either poles or essential singularities, and every pole is an eigenvalue. Thus, I need an explicit operator $T$ with $\lambda \in \sigma(T)$ such that $\lambda$ is an essential singularity (and not a pole) of the resolvent operator of $T$.  Also, it would be better if someone can give such a point $\lambda$ other than infinity. I'm a little new to the $L^2$ spaces, but I'm quite comfortable working with $\ell^2$ space.","Is there an unbounded operator with isolated points in the spectrum, not all of which are eigenvalues? For unbounded operators it is known that isolated spectral points are either poles or essential singularities, and every pole is an eigenvalue. Thus, I need an explicit operator $T$ with $\lambda \in \sigma(T)$ such that $\lambda$ is an essential singularity (and not a pole) of the resolvent operator of $T$.  Also, it would be better if someone can give such a point $\lambda$ other than infinity. I'm a little new to the $L^2$ spaces, but I'm quite comfortable working with $\ell^2$ space.",,"['complex-analysis', 'functional-analysis', 'examples-counterexamples', 'unbounded-operators']"
98,Continuity of functional calculus,Continuity of functional calculus,,"Let $\mathcal{A}$ be an unital C*-Algebra. $a,b$ be normal elements in $\mathcal{A}$. $X\subset \Bbb C$ is a compact subset. $f:X\rightarrow \Bbb C$ is continuous.  I need to show that for all $\epsilon >0$ there exists $\delta>0$ such that $||f(a)-f(b)||<\epsilon$ whenever $||a-b||<\delta$ with $\sigma (a), \sigma (b)\subset X$. I have no clue on how to attack the problem as I know to define $f(a)$ by considering $C^*(a)$. Now that I have to work with both $f(a)$ and $f(b)$ I cannot use gelfand transformation directly. I tried to look at the definition of $f(a)$ and tried to write the map $f:\mathcal{A} \rightarrow \mathcal{A}$ explicitly that is giving all the identifications a name. But it got complicated and I could not work. Can you show me a way?","Let $\mathcal{A}$ be an unital C*-Algebra. $a,b$ be normal elements in $\mathcal{A}$. $X\subset \Bbb C$ is a compact subset. $f:X\rightarrow \Bbb C$ is continuous.  I need to show that for all $\epsilon >0$ there exists $\delta>0$ such that $||f(a)-f(b)||<\epsilon$ whenever $||a-b||<\delta$ with $\sigma (a), \sigma (b)\subset X$. I have no clue on how to attack the problem as I know to define $f(a)$ by considering $C^*(a)$. Now that I have to work with both $f(a)$ and $f(b)$ I cannot use gelfand transformation directly. I tried to look at the definition of $f(a)$ and tried to write the map $f:\mathcal{A} \rightarrow \mathcal{A}$ explicitly that is giving all the identifications a name. But it got complicated and I could not work. Can you show me a way?",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'spectral-theory', 'c-star-algebras']"
99,Gelfand transform on functions,Gelfand transform on functions,,"The Gelfand transformation identifies function spaces $C_0(X)$ for locally compact Haussdorff $X$ with commutative $C^*$ Algebras. Additionally there is a statement that if $f: X \to Y$ is a proper and continuous map, this induces a $*$-morphism $f_*: C_0(Y) \to C_0(X)$ via $f_*(g) = g \circ f$. The condition that the map be proper is needed for the induced map to be well defined, for example if $X$ is not compact then a constant map $f: X \to Y$ will not send $C_0$ functions to $C_0$ functions. On the other hand the proof that $f_*(g)$ is in $C_0(X)$ if $g \in C_0(Y)$ is rather easy: if $\epsilon >0$, $K$ compact so that $g(Y-K)\subset B_\epsilon(0)$ then $f^{-1}(K)$ is compact and $$f_*(g)(X-f^{-1}(K))=(g\circ f)(X-f^{-1}(K))\subset g(Y-K) \subset B_\epsilon(0)$$ There is another direction, given two commutative $C^*$ Algebras $A, B$ so that $A \cong C_0(X)$ and $B \cong C_0(Y)$ there is a statement that a proper $*$-morphism $\varphi: A \to B$ induces a proper continuous map $\varphi_*: Y \to X$. A $*$-morphism is called proper if it maps approximate identities to approximate identities. Can somebody tell me how this map can be constructed (and why proper-ness is needed)? Also can somebody show me an example of a non-proper $*$-morphism that isn't trivial (the zero map)?","The Gelfand transformation identifies function spaces $C_0(X)$ for locally compact Haussdorff $X$ with commutative $C^*$ Algebras. Additionally there is a statement that if $f: X \to Y$ is a proper and continuous map, this induces a $*$-morphism $f_*: C_0(Y) \to C_0(X)$ via $f_*(g) = g \circ f$. The condition that the map be proper is needed for the induced map to be well defined, for example if $X$ is not compact then a constant map $f: X \to Y$ will not send $C_0$ functions to $C_0$ functions. On the other hand the proof that $f_*(g)$ is in $C_0(X)$ if $g \in C_0(Y)$ is rather easy: if $\epsilon >0$, $K$ compact so that $g(Y-K)\subset B_\epsilon(0)$ then $f^{-1}(K)$ is compact and $$f_*(g)(X-f^{-1}(K))=(g\circ f)(X-f^{-1}(K))\subset g(Y-K) \subset B_\epsilon(0)$$ There is another direction, given two commutative $C^*$ Algebras $A, B$ so that $A \cong C_0(X)$ and $B \cong C_0(Y)$ there is a statement that a proper $*$-morphism $\varphi: A \to B$ induces a proper continuous map $\varphi_*: Y \to X$. A $*$-morphism is called proper if it maps approximate identities to approximate identities. Can somebody tell me how this map can be constructed (and why proper-ness is needed)? Also can somebody show me an example of a non-proper $*$-morphism that isn't trivial (the zero map)?",,"['functional-analysis', 'c-star-algebras', 'banach-algebras', 'gelfand-representation']"
