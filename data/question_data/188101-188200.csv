,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Show that a function $f(x)$ maps to a set of points.Fixed point theorem,Show that a function  maps to a set of points.Fixed point theorem,f(x),Show that the function $f(x)=\frac{1+x^2}{2}$ maps the set of points $0\leqslant   x\leqslant  1$ into itself and has a fixed point in that interval even though there does not exists a positive constant $K<1$ such that $\vert f(a)-f(b) \vert \leqslant   K \vert b-a\vert$.,Show that the function $f(x)=\frac{1+x^2}{2}$ maps the set of points $0\leqslant   x\leqslant  1$ into itself and has a fixed point in that interval even though there does not exists a positive constant $K<1$ such that $\vert f(a)-f(b) \vert \leqslant   K \vert b-a\vert$.,,"['functions', 'fixed-point-theorems']"
1,Metric Spaces of Continuous Function,Metric Spaces of Continuous Function,,"Let X be a metric space defined as such: $$ X =  f : [0,1] \to \Re : f \,\text{ is continuous}  $$ $$ d(f,g) = sup_{x\in[0,1]} | f(x) - g(x)|$$ I need to show: a) The neighborhood, $ N_r (0) $, is uncountably infinite. b) Let E = { $f \in X : f(0) = 0 $}. Prove or disprove E is bounded c)Prove X is not complete (I can't comment, but yes I need to prove it is not complete) I am not looking for someone to solve the problem for me, Just to point me in the right direction. I think this is saying that X is a metric space of function (?). I don't believe I've run into this before and don't know how to approach this. Any help would be greatly appreciated.","Let X be a metric space defined as such: $$ X =  f : [0,1] \to \Re : f \,\text{ is continuous}  $$ $$ d(f,g) = sup_{x\in[0,1]} | f(x) - g(x)|$$ I need to show: a) The neighborhood, $ N_r (0) $, is uncountably infinite. b) Let E = { $f \in X : f(0) = 0 $}. Prove or disprove E is bounded c)Prove X is not complete (I can't comment, but yes I need to prove it is not complete) I am not looking for someone to solve the problem for me, Just to point me in the right direction. I think this is saying that X is a metric space of function (?). I don't believe I've run into this before and don't know how to approach this. Any help would be greatly appreciated.",,"['real-analysis', 'functions', 'metric-spaces']"
2,How to graph trigonometric functions,How to graph trigonometric functions,,"I am trying to complete some homework for my physics course and I have come to realise that I do not understand how parameters inside a trigonometric function affect the function and therefore a graph of the function. I have the following question where I need to graph some functions on a disturbance vs time (t) graph where T is the period of the function. For an example the function $y=\sin{\left(\frac{2\pi t}{T}\right)}$, is one that I have to put on this graph.  My first idea was as the sine function has a period of $2\pi$ and $T$ is the given period of $y$ that I could cancel the two periods leaving just $\sin{(t)}$ but after more thought I do not really think this is correct as it is not given that $2\pi=T$.  After this I am not really sure how to further work the problem out. I would like to know how to visualise or workout how parameters inside a trig function affect the behaviour of the function. EDIT: I do not understand how to calculate the period of the function given above, I am confused because I understand the period of the function to be given by the coefficient of in this case $t$ as $t$ is multiplied by $2\pi$ and $\frac{1}{T}$ I am not sure which one I would use to calculate the period or both of them? I am mostly confused that the function presented above seems to include a variable for its period as a parameter which would then be used to calculate its period and I don't see how this can happen.  I hope that makes sense, at the moment basically when I look at the function and try to calculate its period I just see an infinite loop scenario, I hope that is clear and if it isn't let me know so I can clarify further.  Thanks! EDIT 2: Along with my last edit, the only real stab I could make at this would be the following the period $T$ is given by $T=\frac{2\pi}{2\pi}=1$, so in this case the function $y=\sin\left(\frac{2\pi t}{T}\right)$ would just have a period $T=1$ and therefore be a normal sine wave?","I am trying to complete some homework for my physics course and I have come to realise that I do not understand how parameters inside a trigonometric function affect the function and therefore a graph of the function. I have the following question where I need to graph some functions on a disturbance vs time (t) graph where T is the period of the function. For an example the function $y=\sin{\left(\frac{2\pi t}{T}\right)}$, is one that I have to put on this graph.  My first idea was as the sine function has a period of $2\pi$ and $T$ is the given period of $y$ that I could cancel the two periods leaving just $\sin{(t)}$ but after more thought I do not really think this is correct as it is not given that $2\pi=T$.  After this I am not really sure how to further work the problem out. I would like to know how to visualise or workout how parameters inside a trig function affect the behaviour of the function. EDIT: I do not understand how to calculate the period of the function given above, I am confused because I understand the period of the function to be given by the coefficient of in this case $t$ as $t$ is multiplied by $2\pi$ and $\frac{1}{T}$ I am not sure which one I would use to calculate the period or both of them? I am mostly confused that the function presented above seems to include a variable for its period as a parameter which would then be used to calculate its period and I don't see how this can happen.  I hope that makes sense, at the moment basically when I look at the function and try to calculate its period I just see an infinite loop scenario, I hope that is clear and if it isn't let me know so I can clarify further.  Thanks! EDIT 2: Along with my last edit, the only real stab I could make at this would be the following the period $T$ is given by $T=\frac{2\pi}{2\pi}=1$, so in this case the function $y=\sin\left(\frac{2\pi t}{T}\right)$ would just have a period $T=1$ and therefore be a normal sine wave?",,"['trigonometry', 'functions']"
3,Proof that an inverse of a possibly noncomputable function is possibly not decidable,Proof that an inverse of a possibly noncomputable function is possibly not decidable,,"I'm stuck with the following homework: Given an fixed function $f:\mathbb{N}\to\mathbb{N}$. $f$ is an arbitrary (possibly not computable, possibly partial) function. Show that the set $\{f(42)\}$ is decidable. Show that the set $f^{-1}(42)$ possibly isn't decidable. The first part is pretty easy: the set is decidable, because even though $f$ is possibly not defined, the set which contains it remains enumerable. The inverse thing $f^{-1}(42)$ is what confuses me. I can imagine that this could give me some innumerable infinite set, but couldn't this always be the case for a (possibly) noncomputable function?","I'm stuck with the following homework: Given an fixed function $f:\mathbb{N}\to\mathbb{N}$. $f$ is an arbitrary (possibly not computable, possibly partial) function. Show that the set $\{f(42)\}$ is decidable. Show that the set $f^{-1}(42)$ possibly isn't decidable. The first part is pretty easy: the set is decidable, because even though $f$ is possibly not defined, the set which contains it remains enumerable. The inverse thing $f^{-1}(42)$ is what confuses me. I can imagine that this could give me some innumerable infinite set, but couldn't this always be the case for a (possibly) noncomputable function?",,"['functions', 'computability', 'inverse']"
4,Can a sequence of functions converge to different functions pointwise and on average?,Can a sequence of functions converge to different functions pointwise and on average?,,"Is it possible for a sequence of functions in $\mathcal{C}\left[0,1\right]$   to converge to one function pointwise (not necessarily to a continuous function) and to a different function in average (i.e with respect to $\Vert f\Vert=\left(\int\limits _{0}^{1}\left|f\left(x\right)\right|^{2}dx\right)^{\frac{1}{2}}$ ? I know neither convergence mandates the other but I'm wondering whether it's possible for both convergences to occur but to different functions. Thanks in advance! Following some of the replies let's take as an example the sequence of functions defined by $f_{n}\left(x\right)=x^{n}$  , pointwise it has a limit which is $$f\left(x\right)=\begin{cases} 0 & x\in\left[0,1\right)\\ 1 & x=1 \end{cases}$$   but on average I can see that it converges to the zero function as $$\Vert f_{n}\left(x\right)-0\Vert\overset{n\to\infty}{\longrightarrow}0$$  Obviously $f\left(x\right)$   and $0$   are a.e equivalent so $f_{n}$   also converges to $f$   on average. However, while the zero function is in $\mathcal{C}\left[0,1\right]$   the pointwise limit $f$   is not. So unless I'm missing something here, the limit only has to be same up to a.e equivalence even if it's a sequence of continuous functions. I assume that if the pointwise limit was also continuous then it would have to be equivalent everywhere?","Is it possible for a sequence of functions in $\mathcal{C}\left[0,1\right]$   to converge to one function pointwise (not necessarily to a continuous function) and to a different function in average (i.e with respect to $\Vert f\Vert=\left(\int\limits _{0}^{1}\left|f\left(x\right)\right|^{2}dx\right)^{\frac{1}{2}}$ ? I know neither convergence mandates the other but I'm wondering whether it's possible for both convergences to occur but to different functions. Thanks in advance! Following some of the replies let's take as an example the sequence of functions defined by $f_{n}\left(x\right)=x^{n}$  , pointwise it has a limit which is $$f\left(x\right)=\begin{cases} 0 & x\in\left[0,1\right)\\ 1 & x=1 \end{cases}$$   but on average I can see that it converges to the zero function as $$\Vert f_{n}\left(x\right)-0\Vert\overset{n\to\infty}{\longrightarrow}0$$  Obviously $f\left(x\right)$   and $0$   are a.e equivalent so $f_{n}$   also converges to $f$   on average. However, while the zero function is in $\mathcal{C}\left[0,1\right]$   the pointwise limit $f$   is not. So unless I'm missing something here, the limit only has to be same up to a.e equivalence even if it's a sequence of continuous functions. I assume that if the pointwise limit was also continuous then it would have to be equivalent everywhere?",,"['sequences-and-series', 'functions', 'convergence-divergence']"
5,Proving $x+\sin\sqrt{x}$ is uniformly continuous - not sure of my solution,Proving  is uniformly continuous - not sure of my solution,x+\sin\sqrt{x},"Prove $x+\sin\sqrt{x}$ is uniformly continuous on $[0,\infty)$. Here's is my proof, but I'm worried of me $\delta$ choice being incorrect. If $x_1,x_2>0$ then $$|f(x_1)-f(x_2)|=|x_1+\sin\sqrt{x_1}-x_2-\sin\sqrt{x_2}|$$ Since $-1\le\sin x\le1$: $$|x_1+\sin\sqrt{x_1}-x_2-\sin\sqrt{x_2}|\le|x_1+1-x_2-(-1)|=|x_1-x_2+2|=|x_1-x_2|+2$$ Then let $\delta=\epsilon-2$ so that- $\forall x_1,x_2 |x_1-x_2|<\delta => |f(x_1)-f(x_2)|\le|x_1-x_2|+2<\epsilon-2+2=\epsilon$ End of proof. My problem is that my $delta$ is $\delta=\epsilon-2$, but $\delta$ is positive, so there is no $\delta$ for $\epsilon=1$ because then $\delta$ will be negative. So is my solution wrong and if so what the error? Thanks!","Prove $x+\sin\sqrt{x}$ is uniformly continuous on $[0,\infty)$. Here's is my proof, but I'm worried of me $\delta$ choice being incorrect. If $x_1,x_2>0$ then $$|f(x_1)-f(x_2)|=|x_1+\sin\sqrt{x_1}-x_2-\sin\sqrt{x_2}|$$ Since $-1\le\sin x\le1$: $$|x_1+\sin\sqrt{x_1}-x_2-\sin\sqrt{x_2}|\le|x_1+1-x_2-(-1)|=|x_1-x_2+2|=|x_1-x_2|+2$$ Then let $\delta=\epsilon-2$ so that- $\forall x_1,x_2 |x_1-x_2|<\delta => |f(x_1)-f(x_2)|\le|x_1-x_2|+2<\epsilon-2+2=\epsilon$ End of proof. My problem is that my $delta$ is $\delta=\epsilon-2$, but $\delta$ is positive, so there is no $\delta$ for $\epsilon=1$ because then $\delta$ will be negative. So is my solution wrong and if so what the error? Thanks!",,"['trigonometry', 'functions']"
6,How can you rewrite piecewise functions in terms of the unit step $u(t-a)$?,How can you rewrite piecewise functions in terms of the unit step ?,u(t-a),"Consider $ u(t-a) = \begin{cases} 0, & \text{if }t<a \\ 1, & \text{if }t\geq a \end{cases} $ How can we rewrite a function like $ f(t) = \begin{cases} \cos2t, & \text{if }0\leq t \lt 2\pi \\ 0, & \text{if }t\geq 2\pi \end{cases} $ in terms of the unit step function?  My textbook writes this particular example as $f(t) = [1-u(t-2\pi)]\cos2t$, but I don't understand how this was formulated nor how I can formulate other piecewise functions in terms of the unit step similarly.","Consider $ u(t-a) = \begin{cases} 0, & \text{if }t<a \\ 1, & \text{if }t\geq a \end{cases} $ How can we rewrite a function like $ f(t) = \begin{cases} \cos2t, & \text{if }0\leq t \lt 2\pi \\ 0, & \text{if }t\geq 2\pi \end{cases} $ in terms of the unit step function?  My textbook writes this particular example as $f(t) = [1-u(t-2\pi)]\cos2t$, but I don't understand how this was formulated nor how I can formulate other piecewise functions in terms of the unit step similarly.",,"['algebra-precalculus', 'functions']"
7,Simple inequality help,Simple inequality help,,"I need a function $f(x)$ that satisfies the properties bellow for all integers $k$ $$ \frac{\log(k+1)}{k+1}-\log\left(1+\frac 1 k\right)+f(k+1)-f(k)<0 \ $$ $$ \lim_{k \rightarrow \infty} f(k)=0 $$ I don't think it should be very hard sense if I let $f(x)=0$, the entire thing is already very close to zero. In addition if you find a function that doesn't work for the first few values 1,2,3.. etc, thats fine too. I would appreciate any help, thanks.","I need a function $f(x)$ that satisfies the properties bellow for all integers $k$ $$ \frac{\log(k+1)}{k+1}-\log\left(1+\frac 1 k\right)+f(k+1)-f(k)<0 \ $$ $$ \lim_{k \rightarrow \infty} f(k)=0 $$ I don't think it should be very hard sense if I let $f(x)=0$, the entire thing is already very close to zero. In addition if you find a function that doesn't work for the first few values 1,2,3.. etc, thats fine too. I would appreciate any help, thanks.",,"['functions', 'limits', 'inequality', 'logarithms']"
8,What are the different ways to prove a function is onto,What are the different ways to prove a function is onto,,you take $f(x)$ and isolate $x$? For instance $f(x) = x^2 = \sqrt{y} = x$ Set A = all rational numbers Set B = all rational numbers The function is not onto because $\sqrt{y}$ is an irrational number. Is this the only way to prove that a function is onto? What are the different techniques?,you take $f(x)$ and isolate $x$? For instance $f(x) = x^2 = \sqrt{y} = x$ Set A = all rational numbers Set B = all rational numbers The function is not onto because $\sqrt{y}$ is an irrational number. Is this the only way to prove that a function is onto? What are the different techniques?,,"['functions', 'discrete-mathematics']"
9,Proving that floor(n/2)=n/2 if n is an even integer and floor(n/2)=(n-1)/2 if n is an odd integer.,Proving that floor(n/2)=n/2 if n is an even integer and floor(n/2)=(n-1)/2 if n is an odd integer.,,"How would one go about proving the following. Any ideas as to where to start? For any integer n, the floor of n/2 equals n/2 if n is even and (n-1)/2 if n is odd. Summarize: [n/2] = n/2 if n = even  [n/2] = (n-1)/2 if n = odd Working through it, I try to initially set n = 2n for the even case but am stuck on how to show its a floor... thanks","How would one go about proving the following. Any ideas as to where to start? For any integer n, the floor of n/2 equals n/2 if n is even and (n-1)/2 if n is odd. Summarize: [n/2] = n/2 if n = even  [n/2] = (n-1)/2 if n = odd Working through it, I try to initially set n = 2n for the even case but am stuck on how to show its a floor... thanks",,"['elementary-number-theory', 'functions']"
10,Find all non-constant function $g$ such that $(g(x)-1)(g(-x)-1)=1$,Find all non-constant function  such that,g (g(x)-1)(g(-x)-1)=1,"Find all non-constant function $g$ such that  $$\big(g(x)-1\big)\big(g(-x)-1\big)=1.$$ I started with some special functions like $g(x)=1+e^x$. Then later: $g(x)=1+a^{bx}$ or $g(x)=1-a^{bx}$. I wonder there are more, or how to find all of them. Edit: At first, I didn't mentioned that I am interested only in those continuous function. Follows from Marvis's post, I think I got the answer. Let $h(x)=|g(x)−1|$. Then $h(x)h(−x)=1$ and hence $\ln(h(x))+\ln(h(−x))=0$. This implies that $\ln(h(x))=−\ln(h(−x))$. Now, $\ln(h(x))=k(x)$ where $k(x)$ is an odd function. So $h(x)=e^{k(x)}$ and hence $g(x)=1±e^{k(x)}$, where $k(x)$ is an odd function. Note that the base e can be changed to any base a with positive $a≠1$. Do I miss out anything? By the way, this questions was due to the following post which I wonder why the function $1+e^x$ is so special. And now, we can replace the $1+e^x$ with $1±a^{k(x)}$, where $k(x)$ is an odd function.","Find all non-constant function $g$ such that  $$\big(g(x)-1\big)\big(g(-x)-1\big)=1.$$ I started with some special functions like $g(x)=1+e^x$. Then later: $g(x)=1+a^{bx}$ or $g(x)=1-a^{bx}$. I wonder there are more, or how to find all of them. Edit: At first, I didn't mentioned that I am interested only in those continuous function. Follows from Marvis's post, I think I got the answer. Let $h(x)=|g(x)−1|$. Then $h(x)h(−x)=1$ and hence $\ln(h(x))+\ln(h(−x))=0$. This implies that $\ln(h(x))=−\ln(h(−x))$. Now, $\ln(h(x))=k(x)$ where $k(x)$ is an odd function. So $h(x)=e^{k(x)}$ and hence $g(x)=1±e^{k(x)}$, where $k(x)$ is an odd function. Note that the base e can be changed to any base a with positive $a≠1$. Do I miss out anything? By the way, this questions was due to the following post which I wonder why the function $1+e^x$ is so special. And now, we can replace the $1+e^x$ with $1±a^{k(x)}$, where $k(x)$ is an odd function.",,"['calculus', 'functions']"
11,Sets and functions proof help needed,Sets and functions proof help needed,,"I have a quiz tomorrow and while I was studying, I saw these questions at the book. Could you please help me to find the proper ways to solve these? Let $A$ and $B$ be sets, and let $f : A \to B$ be a function defined in $A$ with values in $B$. Prove the formula $f(A\cup B) = f(A)\cup f(B)$. Is it true that $f(A\setminus B) \subset f(A)\setminus f(B)$? Is it true that $f(A\setminus B) \supset f(A)\setminus f(B)$? Here is what I have done so far: I could not find a point to start proof. is wrong. If we take $f(x) = x^2$, then $f(2) = 4$ and it is not an element of $f(A)\setminus f(B)$. is wrong. Because if we again take $f(x) = x^2$, $A = \{0, 1, 2, 3, \dots\}$, $f(A) = B = \{0, 1, 4, 9, 16, 25, 36, \dots\}$, $f(B) = \{0, 1, 16, 81, \dots\}$, $f(A\setminus B) = \{2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, \dots\}$, $f(A)\setminus f(B) = \{4, 9, \dots\}$. $9 \in f(A)\setminus f(B)$ but $9\notin f(A\setminus B)$ therefore $f(A)\setminus f(B)$ is not a subset of $f(A\setminus B)$. Regards.","I have a quiz tomorrow and while I was studying, I saw these questions at the book. Could you please help me to find the proper ways to solve these? Let $A$ and $B$ be sets, and let $f : A \to B$ be a function defined in $A$ with values in $B$. Prove the formula $f(A\cup B) = f(A)\cup f(B)$. Is it true that $f(A\setminus B) \subset f(A)\setminus f(B)$? Is it true that $f(A\setminus B) \supset f(A)\setminus f(B)$? Here is what I have done so far: I could not find a point to start proof. is wrong. If we take $f(x) = x^2$, then $f(2) = 4$ and it is not an element of $f(A)\setminus f(B)$. is wrong. Because if we again take $f(x) = x^2$, $A = \{0, 1, 2, 3, \dots\}$, $f(A) = B = \{0, 1, 4, 9, 16, 25, 36, \dots\}$, $f(B) = \{0, 1, 16, 81, \dots\}$, $f(A\setminus B) = \{2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, \dots\}$, $f(A)\setminus f(B) = \{4, 9, \dots\}$. $9 \in f(A)\setminus f(B)$ but $9\notin f(A\setminus B)$ therefore $f(A)\setminus f(B)$ is not a subset of $f(A\setminus B)$. Regards.",,"['analysis', 'functions', 'elementary-set-theory']"
12,"Describe the partitions of the equivalence relations for the map $f:(x,y) \mapsto x$.",Describe the partitions of the equivalence relations for the map .,"f:(x,y) \mapsto x","Question: Describe the partitions of the equivalence relations for the map: $$f:(x,y) \mapsto x$$ I had a different question on my homework, but I'm not really sure what the question is asking, so maybe if I see the solution for this one example it would clarify things.","Question: Describe the partitions of the equivalence relations for the map: $$f:(x,y) \mapsto x$$ I had a different question on my homework, but I'm not really sure what the question is asking, so maybe if I see the solution for this one example it would clarify things.",,"['functions', 'equivalence-relations', 'projection']"
13,Write the above function in simplest form.,Write the above function in simplest form.,,"$$\tan^{-1}\left(\dfrac{3a^2x-x^3}{a^3-3ax^2}\right),\;a>0;\; -\frac{a}{\sqrt{3}}\leqslant x \leqslant \frac{a}{\sqrt{3}}$$ Hi,    Please help me to solve this problem. As I can solve simple inverse trigonometric functions.  Please help hanks in advance.","$$\tan^{-1}\left(\dfrac{3a^2x-x^3}{a^3-3ax^2}\right),\;a>0;\; -\frac{a}{\sqrt{3}}\leqslant x \leqslant \frac{a}{\sqrt{3}}$$ Hi,    Please help me to solve this problem. As I can solve simple inverse trigonometric functions.  Please help hanks in advance.",,"['trigonometry', 'functions', 'inverse']"
14,Is this function injective and surjective?,Is this function injective and surjective?,,"Let $f(x)=x^2$. Is this function injective and surjective if the function is defined as: $f: \mathbb{R} \longrightarrow [0,\infty)$. $f: \mathbb{C} \longrightarrow \mathbb{C}$. $f: \mathbb{R} \longrightarrow \mathbb{R}$. $f: \mathbb{R} \cup \{x \in \mathbb{C} : \mathrm{Re}(x) = 0\} \longrightarrow \mathbb{R}$. $f: \{z=x+iy: i^2=-1, y>0\} \cup \{z=x+iy: i^2=-1, y=0 \text{ and } x \ge 0\} \longrightarrow \mathbb{C}$. Thanks!","Let $f(x)=x^2$. Is this function injective and surjective if the function is defined as: $f: \mathbb{R} \longrightarrow [0,\infty)$. $f: \mathbb{C} \longrightarrow \mathbb{C}$. $f: \mathbb{R} \longrightarrow \mathbb{R}$. $f: \mathbb{R} \cup \{x \in \mathbb{C} : \mathrm{Re}(x) = 0\} \longrightarrow \mathbb{R}$. $f: \{z=x+iy: i^2=-1, y>0\} \cup \{z=x+iy: i^2=-1, y=0 \text{ and } x \ge 0\} \longrightarrow \mathbb{C}$. Thanks!",,"['functions', 'complex-numbers']"
15,Vector as argument of a function,Vector as argument of a function,,Given a function $f(x)=y$ is correct to say that $f\left(\left[\begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}\right]\right)=\left[\begin{array}{c} y_1 \\ y_2 \\ y_3 \end{array}\right]$?,Given a function $f(x)=y$ is correct to say that $f\left(\left[\begin{array}{c} x_1 \\ x_2 \\ x_3 \end{array}\right]\right)=\left[\begin{array}{c} y_1 \\ y_2 \\ y_3 \end{array}\right]$?,,"['functions', 'terminology']"
16,How to determine $\mathbb{E}$ for which a maximum defined function is a bijection?,How to determine  for which a maximum defined function is a bijection?,\mathbb{E},"Assume that $f\colon\mathbb{E}\subset\mathbb{R}\rightarrow\mathbb{R}$ , $f(x)=\max\lbrace2x-5,x-2\rbrace$ . Determine $\mathbb{E}$ for which $f$ is a bijection. I was thinking it is $\mathbb{R}$ ,  but I'm not sure. Can I get a confirmation and a way to prove it, please? Thank you very much!","Assume that , . Determine for which is a bijection. I was thinking it is ,  but I'm not sure. Can I get a confirmation and a way to prove it, please? Thank you very much!","f\colon\mathbb{E}\subset\mathbb{R}\rightarrow\mathbb{R} f(x)=\max\lbrace2x-5,x-2\rbrace \mathbb{E} f \mathbb{R}","['calculus', 'algebra-precalculus', 'functions']"
17,Prime Counting Function as Sum of Heaviside Step Functions,Prime Counting Function as Sum of Heaviside Step Functions,,"Inspired by Logarithmic derivative on the critical strip , I would like to ask, if it is possible to write $\pi(n)$ as a sum of step functions like the following: $$ \pi(n)=\sum_{k=1}^{N} H(n-p_k), \tag{$\ast$} $$ with $p_k$ the $k$th prime, $p_N\le n$ and $H(x)$ being the Heaviside Step Functions and further use $$ H(x) = \int_{-\infty}^x { \delta(t)} \, \mathrm{d}t, $$ such that ($\ast$) gets $$ \pi(n)=\sum_{k=1}^{N} \int_{-\infty}^{(n-p_k)} { \delta(t)} \, \mathrm{d}t ? $$","Inspired by Logarithmic derivative on the critical strip , I would like to ask, if it is possible to write $\pi(n)$ as a sum of step functions like the following: $$ \pi(n)=\sum_{k=1}^{N} H(n-p_k), \tag{$\ast$} $$ with $p_k$ the $k$th prime, $p_N\le n$ and $H(x)$ being the Heaviside Step Functions and further use $$ H(x) = \int_{-\infty}^x { \delta(t)} \, \mathrm{d}t, $$ such that ($\ast$) gets $$ \pi(n)=\sum_{k=1}^{N} \int_{-\infty}^{(n-p_k)} { \delta(t)} \, \mathrm{d}t ? $$",,"['functions', 'prime-numbers']"
18,What is the limit distance to the base function if offset curve is a function too?,What is the limit distance to the base function if offset curve is a function too?,,I asked a question about parallel functions in here . I understood that offset curves that are the parallels of a function may not be functions after J.M.'s answer. I got new questions after that answer. Q1) What is the limit distance to the base function if offset curve is a function too? Q2) It can be shown as geometrically that all parallel curves of line and half circle are also functions. What is the whole function family defination for such functions? Thanks for answers Please see parallel curve examples below. (Thanks to J.M. for the graphs),I asked a question about parallel functions in here . I understood that offset curves that are the parallels of a function may not be functions after J.M.'s answer. I got new questions after that answer. Q1) What is the limit distance to the base function if offset curve is a function too? Q2) It can be shown as geometrically that all parallel curves of line and half circle are also functions. What is the whole function family defination for such functions? Thanks for answers Please see parallel curve examples below. (Thanks to J.M. for the graphs),,"['differential-geometry', 'functions', 'plane-curves']"
19,Problems on Schwartz Functions,Problems on Schwartz Functions,,(1) What are all positive Schwartz Functions on $\mathbb R$  whose Fourier Transform is positive ? (2) What are all Schwartz Functions on $\mathbb R$  whose Fourier Transform is positive ? (3) What are all positive Schwartz Functions on $\mathbb R$  whose Fourier Transform is non-negative ? (4) What are all Schwartz Functions on $\mathbb R$  whose Fourier Transform is non-negative ?,(1) What are all positive Schwartz Functions on $\mathbb R$  whose Fourier Transform is positive ? (2) What are all Schwartz Functions on $\mathbb R$  whose Fourier Transform is positive ? (3) What are all positive Schwartz Functions on $\mathbb R$  whose Fourier Transform is non-negative ? (4) What are all Schwartz Functions on $\mathbb R$  whose Fourier Transform is non-negative ?,,"['functions', 'fourier-analysis', 'harmonic-analysis']"
20,Can the output of a mathematical function be another mathematical function?,Can the output of a mathematical function be another mathematical function?,,"Apologies if this is actually mathematical gibberish. I'm very familiar with mathematical functions at a simple level. A function relates a set of inputs to a set of outputs. What I'm trying to denote is a function, G, which, when given a set F and a true/false value, $\delta$, returns another function which has $n$ as a free variable. For reference, 'match' is another function that matches $n$ and $f$ according to some algorithm. $$ \mathrm{G}(F,\delta) \equiv (F=\varnothing  \vee  ( \delta \veebar \exists f \in F: \mathrm{match}(n,f))) $$ My concern with the expression above is that $n$ pops out of nowhere. What I'd like to get to is $$ A(n) \equiv G(F_A,\bot)$$ and $$ B(n) \equiv G(F_B,\top)$$ So, I guess my question is: does that notation make sense? Or are there more standard forms of expressing these ideas?","Apologies if this is actually mathematical gibberish. I'm very familiar with mathematical functions at a simple level. A function relates a set of inputs to a set of outputs. What I'm trying to denote is a function, G, which, when given a set F and a true/false value, $\delta$, returns another function which has $n$ as a free variable. For reference, 'match' is another function that matches $n$ and $f$ according to some algorithm. $$ \mathrm{G}(F,\delta) \equiv (F=\varnothing  \vee  ( \delta \veebar \exists f \in F: \mathrm{match}(n,f))) $$ My concern with the expression above is that $n$ pops out of nowhere. What I'd like to get to is $$ A(n) \equiv G(F_A,\bot)$$ and $$ B(n) \equiv G(F_B,\top)$$ So, I guess my question is: does that notation make sense? Or are there more standard forms of expressing these ideas?",,"['functions', 'elementary-set-theory', 'notation']"
21,"Change of coordinate codomain from $[-1,1]$ to $[0,1]$",Change of coordinate codomain from  to,"[-1,1] [0,1]","How does one translate coordinates from $[-1,1]$ to $[0,1]$? That is, suppose we have an ordered pair $(x,y)$ which lies between $[-1,1]$ and want to push into the range delimited by $[0,1]$. A lot of places does the transformation something like this: $$f(u) = ((u_1 + 1)/2)i + ((u_2 +1)/2)j$$ I'm not even sure if I may express it this way (?), here's the usual expression: $$x = (c_x + 1) / 2$$ $$y = (c_y + 1) / 2$$ I can see that that the addition of $1$ will force all the possible inputs into the $[0,2]$ range and that the division by the maximum of the range will force it to be expressed as a part of the whole, the whole being the dimensionless $1$, effectively expressing all values in the range of $[0,1]$. Is this all there is to this? Just a heuristic, trial and error technique until you get what you want? Or is there a more obvious, better, formalized way?","How does one translate coordinates from $[-1,1]$ to $[0,1]$? That is, suppose we have an ordered pair $(x,y)$ which lies between $[-1,1]$ and want to push into the range delimited by $[0,1]$. A lot of places does the transformation something like this: $$f(u) = ((u_1 + 1)/2)i + ((u_2 +1)/2)j$$ I'm not even sure if I may express it this way (?), here's the usual expression: $$x = (c_x + 1) / 2$$ $$y = (c_y + 1) / 2$$ I can see that that the addition of $1$ will force all the possible inputs into the $[0,2]$ range and that the division by the maximum of the range will force it to be expressed as a part of the whole, the whole being the dimensionless $1$, effectively expressing all values in the range of $[0,1]$. Is this all there is to this? Just a heuristic, trial and error technique until you get what you want? Or is there a more obvious, better, formalized way?",,"['functions', 'real-numbers']"
22,Algorithms for deciding whether a function over a finite ring is polynomial or not?,Algorithms for deciding whether a function over a finite ring is polynomial or not?,,"Let $R$ be a finite ring, and $f$ be a function from $R$ to $R.$ Suppose I want to know whether $f$ can be represented as a polynomial or not? Are there any good algorithms for finding this out?","Let $R$ be a finite ring, and $f$ be a function from $R$ to $R.$ Suppose I want to know whether $f$ can be represented as a polynomial or not? Are there any good algorithms for finding this out?",,"['abstract-algebra', 'functions', 'polynomials', 'algorithms', 'finite-rings']"
23,How do I find the discontinuity of the function $f(x) =\cos (x/(x - \pi))$?,How do I find the discontinuity of the function ?,f(x) =\cos (x/(x - \pi)),I need help in finding the discontinuity of the function: $$f(x) = \cos \left(\frac{x}{x - \pi}\right)$$ Any comments or advice will be much appreciated. Thanks.,I need help in finding the discontinuity of the function: $$f(x) = \cos \left(\frac{x}{x - \pi}\right)$$ Any comments or advice will be much appreciated. Thanks.,,"['analysis', 'trigonometry', 'functions']"
24,Is Bessel function $J_0(n)$ absolutely summable?,Is Bessel function  absolutely summable?,J_0(n),"Is the Bessel function $J_0(n)$ absolutely summable i.e $\sum_{n=0}^{\infty}|J_0(n)| < \rm C$? Since $\lim\limits_{n \to\infty} J_0(n) = 0$, I'd assume the absolute sum converges to a constant value too.","Is the Bessel function $J_0(n)$ absolutely summable i.e $\sum_{n=0}^{\infty}|J_0(n)| < \rm C$? Since $\lim\limits_{n \to\infty} J_0(n) = 0$, I'd assume the absolute sum converges to a constant value too.",,"['sequences-and-series', 'functions', 'special-functions']"
25,Associativity of pointwise addition of functions,Associativity of pointwise addition of functions,,"A quick check: Is it safe to claim that pointwise addition of functions (in general) is associative? where pointwise addition of functions is defined by $(f+g)(x)=f(x)+g(x)$. If not, I guess it is at least true for continuous functions on a closed interval? How general can I go? What are the conditions for this to be true?","A quick check: Is it safe to claim that pointwise addition of functions (in general) is associative? where pointwise addition of functions is defined by $(f+g)(x)=f(x)+g(x)$. If not, I guess it is at least true for continuous functions on a closed interval? How general can I go? What are the conditions for this to be true?",,['functions']
26,Fourier transform of gaussian times polynomial to a high power,Fourier transform of gaussian times polynomial to a high power,,"Anybody know of a clever way of finding the Fourier transform of  $$ F(x)  =  P(x)^n e^{-\pi x^2}$$ very $n$ is fairly large integer. It is to be used as part of a computation, so I would rather not multiply out the polynomial and then find the Fourier transform of each of the terms individually, hence I thought perhaps there is a way to use that my polynomial has few roots with high multiplicity to get a closed expression where $n$ features in an manageble way - perhaps something akin to the way factorials occur when $P(x)=x^n$. Any thoughts will be welcome. EDIT: The polynomial $P$ can be assumed to be either linear or quadratic - in case that simplifies.","Anybody know of a clever way of finding the Fourier transform of  $$ F(x)  =  P(x)^n e^{-\pi x^2}$$ very $n$ is fairly large integer. It is to be used as part of a computation, so I would rather not multiply out the polynomial and then find the Fourier transform of each of the terms individually, hence I thought perhaps there is a way to use that my polynomial has few roots with high multiplicity to get a closed expression where $n$ features in an manageble way - perhaps something akin to the way factorials occur when $P(x)=x^n$. Any thoughts will be welcome. EDIT: The polynomial $P$ can be assumed to be either linear or quadratic - in case that simplifies.",,"['calculus', 'functions']"
27,How to define the sign of a function,How to define the sign of a function,,"$$y=\arctan\frac{x+1}{x-3} + \frac{x}{4}$$ I know that is necessary to put the function $>$ than $0$, but then? $$\arctan\frac{x+1}{x-3} + \frac{x}{4}>0$$ It's a sum, so I can't set up a ""false system"" putting the two factors $>0$. In this case which is the rule to study the sign of this function? Note: These are not homeworks.","$$y=\arctan\frac{x+1}{x-3} + \frac{x}{4}$$ I know that is necessary to put the function $>$ than $0$, but then? $$\arctan\frac{x+1}{x-3} + \frac{x}{4}>0$$ It's a sum, so I can't set up a ""false system"" putting the two factors $>0$. In this case which is the rule to study the sign of this function? Note: These are not homeworks.",,"['functions', 'inequality']"
28,What is $V : S \to V$?,What is ?,V : S \to V,"I came across a problem where I don't know what field to consult. The problem is simple to explain: I have a geometric object $S$, and a finite set of maps $V$ from the points in this object to $V$. Intuitively, any $v \in V$ partitions $S$, and chosing one of these partitions yields a new such partitioning. What kind of thing is this and/or what could I google to get more information on it or similar structures? (I am particularly interested in iterated applications, given an initial element of $V$ (partitioning), to a given sequence of points.) Thank you in advance.","I came across a problem where I don't know what field to consult. The problem is simple to explain: I have a geometric object $S$, and a finite set of maps $V$ from the points in this object to $V$. Intuitively, any $v \in V$ partitions $S$, and chosing one of these partitions yields a new such partitioning. What kind of thing is this and/or what could I google to get more information on it or similar structures? (I am particularly interested in iterated applications, given an initial element of $V$ (partitioning), to a given sequence of points.) Thank you in advance.",,"['geometry', 'general-topology', 'functions']"
29,Can every line or every j-plane contain all integers exactly once in $\mathbb N^i$,Can every line or every j-plane contain all integers exactly once in,\mathbb N^i,"For which pairs of integers $0<j<i$, is there a function $f:\mathbb N^i \to \mathbb N$, $f(x_1,x_2,...,x_i)$ which outputs every positive integer exactly once when any $i-j$ of the variables are kept constant on any $(i-j)$-tuple of positive integers, while the other $j$ variables are varied over all $j$-tuples of positive integers? And is there a $g$, defined on all infinite sequences of positive integers, such that for all such sequences, if we replace any one element by a variable, say $x$, then $g(x)$ is a bijection between the integers? (ie. $j=1, i=\infty$)","For which pairs of integers $0<j<i$, is there a function $f:\mathbb N^i \to \mathbb N$, $f(x_1,x_2,...,x_i)$ which outputs every positive integer exactly once when any $i-j$ of the variables are kept constant on any $(i-j)$-tuple of positive integers, while the other $j$ variables are varied over all $j$-tuples of positive integers? And is there a $g$, defined on all infinite sequences of positive integers, such that for all such sequences, if we replace any one element by a variable, say $x$, then $g(x)$ is a bijection between the integers? (ie. $j=1, i=\infty$)",,"['real-analysis', 'combinatorics', 'number-theory', 'functions', 'elementary-set-theory']"
30,What is the property of the function corresponds to this definition?,What is the property of the function corresponds to this definition?,,"$\exists \epsilon>0$ $\forall\delta>0: |x-x_0|> \delta \to $ $|f(x) - f(x_0)| < \epsilon$ It is very similar to the continuity of the function at a point, but it is not it. I hope for your help! P.S. Sorry for my bad English.","$\exists \epsilon>0$ $\forall\delta>0: |x-x_0|> \delta \to $ $|f(x) - f(x_0)| < \epsilon$ It is very similar to the continuity of the function at a point, but it is not it. I hope for your help! P.S. Sorry for my bad English.",,['functions']
31,Families of functions under differential operation,Families of functions under differential operation,,"The function $f = \sin x$ is the member of a family of functions closed under the operation $\frac{d}{dx}$.  Are there other families of functions that are similarly closed under differentiation?  Certainly $e^x$ is a trivial example, and I am aware of a similar relationship for hyperbolic trig functions $\sinh x$ and $\cosh x$.","The function $f = \sin x$ is the member of a family of functions closed under the operation $\frac{d}{dx}$.  Are there other families of functions that are similarly closed under differentiation?  Certainly $e^x$ is a trivial example, and I am aware of a similar relationship for hyperbolic trig functions $\sinh x$ and $\cosh x$.",,"['analysis', 'functions']"
32,A question about composition of trigonometric functions,A question about composition of trigonometric functions,,"A little something I'm trying to understand: $\sin(\arcsin{x})$ is always $x$, but $\arcsin(\sin{x})$ is not always $x$ So my question is simple - why?  Since each cancels the other, it would make sense that $\arcsin(\sin{x})$ would always result in $x$. I'd appreciate any explanation. Thanks!","A little something I'm trying to understand: $\sin(\arcsin{x})$ is always $x$, but $\arcsin(\sin{x})$ is not always $x$ So my question is simple - why?  Since each cancels the other, it would make sense that $\arcsin(\sin{x})$ would always result in $x$. I'd appreciate any explanation. Thanks!",,"['trigonometry', 'functions']"
33,"Domain, interval, subset of a function","Domain, interval, subset of a function",,"Given the set of all real numbers, what's the subset of all real numbers that can server as a domain for this function: $f(x) = \sqrt{x}$ I know that the answer is $x \ge 0$. But is it the same as writing [$0,+\infty$) ? Or same thing as Solution $= \{ x \in \mathbb{R} | x \ge \frac{5}{3} \}$ ?","Given the set of all real numbers, what's the subset of all real numbers that can server as a domain for this function: $f(x) = \sqrt{x}$ I know that the answer is $x \ge 0$. But is it the same as writing [$0,+\infty$) ? Or same thing as Solution $= \{ x \in \mathbb{R} | x \ge \frac{5}{3} \}$ ?",,"['algebra-precalculus', 'functions']"
34,Modeling mathematical functions,Modeling mathematical functions,,"Here's something that's been bothering me for a while now, what I don't understand is, if I have a function and I wish to constrain it to specific values... And let's say I have three pairs of x,y values, why do I have to have three constraints? Can someone elaborate on that? $$f(x) = k_1e^{k_2x} + k_3$$ where $$f(0) = 0$$ $$f(0.1) = 1$$ $$f(1) = 100$$ For example, the $x = 0$ simply ""cancels"" the $e$ term. Therefore: $k_1+k_3= f(0) = 0$ And so forth... But why do I need three of them to model it properly?","Here's something that's been bothering me for a while now, what I don't understand is, if I have a function and I wish to constrain it to specific values... And let's say I have three pairs of x,y values, why do I have to have three constraints? Can someone elaborate on that? $$f(x) = k_1e^{k_2x} + k_3$$ where $$f(0) = 0$$ $$f(0.1) = 1$$ $$f(1) = 100$$ For example, the $x = 0$ simply ""cancels"" the $e$ term. Therefore: $k_1+k_3= f(0) = 0$ And so forth... But why do I need three of them to model it properly?",,['functions']
35,What is the name of this function on a graph?,What is the name of this function on a graph?,,"I would like to know how this function is named to find how to calculate it. I have a trend like this one and want to find the upper and lower lines, the red ones (as you can see I do not have a great level at mathematics :) ): EDIT: A better image using a real chart (in this case i need the name or the algorithm to find the black lines) EDIT2: I would define the function like: from a top in a given (t) trace a line to the next top that does not create a line that cross the function. From a down in a given (t) trace a line to the next down that does not creates a line that cross the function. This will create multiple lines, I'm ok with that, like in the following picture: I did the question 'cos I thought that this should be something common, please, if it's the first time you see something like this tell me and I will create everything from scratch!","I would like to know how this function is named to find how to calculate it. I have a trend like this one and want to find the upper and lower lines, the red ones (as you can see I do not have a great level at mathematics :) ): EDIT: A better image using a real chart (in this case i need the name or the algorithm to find the black lines) EDIT2: I would define the function like: from a top in a given (t) trace a line to the next top that does not create a line that cross the function. From a down in a given (t) trace a line to the next down that does not creates a line that cross the function. This will create multiple lines, I'm ok with that, like in the following picture: I did the question 'cos I thought that this should be something common, please, if it's the first time you see something like this tell me and I will create everything from scratch!",,"['functions', 'terminology']"
36,"Sequence of $L^2$-normed functions, s.t. $L^2$-norm of derivatives diverges","Sequence of -normed functions, s.t. -norm of derivatives diverges",L^2 L^2,"Does there exist a sequence of smooth functions $(f_n) \subset C^\infty([0,1])$ with $\|f_n\|_{L^2} = 1$ for all $n$ but $\|f^\prime_n\|_{L^2} \to \infty$? I looked already at approximations of the Dirac function, but they are all stated with the property $\|g_\epsilon\|_{L^1} = 1$, i.e. normed w.r.t the $L^1$-norm, and I couldn't adopt them. Thanks.","Does there exist a sequence of smooth functions $(f_n) \subset C^\infty([0,1])$ with $\|f_n\|_{L^2} = 1$ for all $n$ but $\|f^\prime_n\|_{L^2} \to \infty$? I looked already at approximations of the Dirac function, but they are all stated with the property $\|g_\epsilon\|_{L^1} = 1$, i.e. normed w.r.t the $L^1$-norm, and I couldn't adopt them. Thanks.",,"['calculus', 'real-analysis', 'functions']"
37,Notation of overloaded functions,Notation of overloaded functions,,"I define an overloaded function, for instance as follows: $$f: \mathbb{Set}_1 \rightarrow \mathbb{Set}_3$$    $$f: \mathbb{Set}_2 \times \mathbb{Set}_2 \rightarrow \mathbb{Set}_3$$ My first question is whether it is appropriate to define an overloaded function in math, which has no problem in some programming languages of computer science. My second question is, as there is no intersection between $\mathbb{Set}_1$ and $\mathbb{Set}_2 \times \mathbb{Set}_2$, if it is allowed to simply the notation like that: $$f: (\mathbb{Set}_1 \uplus (\mathbb{Set}_2 \times \mathbb{Set}_2)) \rightarrow \mathbb{Set}_3$$ Could anyone help? Thank you very much.","I define an overloaded function, for instance as follows: $$f: \mathbb{Set}_1 \rightarrow \mathbb{Set}_3$$    $$f: \mathbb{Set}_2 \times \mathbb{Set}_2 \rightarrow \mathbb{Set}_3$$ My first question is whether it is appropriate to define an overloaded function in math, which has no problem in some programming languages of computer science. My second question is, as there is no intersection between $\mathbb{Set}_1$ and $\mathbb{Set}_2 \times \mathbb{Set}_2$, if it is allowed to simply the notation like that: $$f: (\mathbb{Set}_1 \uplus (\mathbb{Set}_2 \times \mathbb{Set}_2)) \rightarrow \mathbb{Set}_3$$ Could anyone help? Thank you very much.",,"['functions', 'notation']"
38,Finding an equation to a function,Finding an equation to a function,,I can think of a visual example s.t. f in $\mathbf C^2$ ($\mathbf R^2$) has a single local minimum stationary point that is not a global minimum but I can't give it a concrete equation... If anyone can think of a better example (i.e. one with a simpler equation) that would be even better! Thanks.,I can think of a visual example s.t. f in $\mathbf C^2$ ($\mathbf R^2$) has a single local minimum stationary point that is not a global minimum but I can't give it a concrete equation... If anyone can think of a better example (i.e. one with a simpler equation) that would be even better! Thanks.,,['functions']
39,"Of two variables, which affects 'y' more?","Of two variables, which affects 'y' more?",,"I have two equations: (1) $\displaystyle y = \frac {0.0060}{k}$ (2) $\displaystyle y= \frac{0.00016}{m}$ In the first equation, $k$ is held constant and in the second equation, $m$ is held constant. How do I determine which variable has a greater affect on $y$? E.g., how do I determine if doubling $k$ as a greater effect on $y$ than doubling $m$ and so forth? Thanks!","I have two equations: (1) $\displaystyle y = \frac {0.0060}{k}$ (2) $\displaystyle y= \frac{0.00016}{m}$ In the first equation, $k$ is held constant and in the second equation, $m$ is held constant. How do I determine which variable has a greater affect on $y$? E.g., how do I determine if doubling $k$ as a greater effect on $y$ than doubling $m$ and so forth? Thanks!",,"['algebra-precalculus', 'functions']"
40,What's the name of this function property?,What's the name of this function property?,,"While playing around with least-fixed-point constructions on a powerset lattice, I've found this property to be useful. Let's say that $F : \mathcal{P(U)} \to \mathcal{P(U)}$, and that $A \subseteq F(A)$ for all $A \in \mathcal{P(U)}$. What's the name of this property $A \subseteq F(A)$? I've read that $F$ is sometimes called ""monotone"" or ""isotone,"" but I can't Google for those terms without running into the wrong definitions (i.e. what most call monotone: $A \subseteq B \implies F(A) \subseteq F(B)$).","While playing around with least-fixed-point constructions on a powerset lattice, I've found this property to be useful. Let's say that $F : \mathcal{P(U)} \to \mathcal{P(U)}$, and that $A \subseteq F(A)$ for all $A \in \mathcal{P(U)}$. What's the name of this property $A \subseteq F(A)$? I've read that $F$ is sometimes called ""monotone"" or ""isotone,"" but I can't Google for those terms without running into the wrong definitions (i.e. what most call monotone: $A \subseteq B \implies F(A) \subseteq F(B)$).",,"['functions', 'terminology', 'order-theory']"
41,Upper bound for Hypergeometric Function,Upper bound for Hypergeometric Function,,"We would like to find an upper bound on the following function: $\left(\frac{\omega_1}{\omega_2}\right)^{(\alpha_1-1)} \frac{\Gamma(\alpha_1+\alpha_2-1)}{\Gamma(\alpha_1)\Gamma(\alpha_2)} {}_2F_1\left(\alpha_1-1,\alpha_1+\alpha_2-1,\alpha_1,-\frac{\omega_1}{\omega_2}\right)$ for all $\omega_1,\omega_2 > 0$ and $\alpha_1,\alpha_2 >1$. From the way we derived this function, we know that it is smaller than 1, but we would like to find an upper bound (expressed in the parameters $\omega_1,\omega_2,\alpha_1,\alpha_2$) that is as tight as possible. Thank you in advance for all possible suggestions and insights! Sebas","We would like to find an upper bound on the following function: $\left(\frac{\omega_1}{\omega_2}\right)^{(\alpha_1-1)} \frac{\Gamma(\alpha_1+\alpha_2-1)}{\Gamma(\alpha_1)\Gamma(\alpha_2)} {}_2F_1\left(\alpha_1-1,\alpha_1+\alpha_2-1,\alpha_1,-\frac{\omega_1}{\omega_2}\right)$ for all $\omega_1,\omega_2 > 0$ and $\alpha_1,\alpha_2 >1$. From the way we derived this function, we know that it is smaller than 1, but we would like to find an upper bound (expressed in the parameters $\omega_1,\omega_2,\alpha_1,\alpha_2$) that is as tight as possible. Thank you in advance for all possible suggestions and insights! Sebas",,['functions']
42,Inverse function of summation,Inverse function of summation,,How to find the inverse function of the following: $f\left( x \right)=\sum_{i=0}^{x}{\frac{2^{i}}{i!}}$,How to find the inverse function of the following: $f\left( x \right)=\sum_{i=0}^{x}{\frac{2^{i}}{i!}}$,,"['sequences-and-series', 'functions']"
43,conversion of a powerseries $-3x+4x^2-5x^3+\ldots $ into $ -2+\frac 1 x - 0 - \frac 1 {x^3} + \ldots $,conversion of a powerseries  into,-3x+4x^2-5x^3+\ldots   -2+\frac 1 x - 0 - \frac 1 {x^3} + \ldots ,"This is initially a funny question, because I've found this on old notes but I do not find/recover my own derivation... But then the question is more general. Q1: I considered the function $ f(x) = - \frac {2x^2+3x}{(x+1)^2}  $ I expressed this by a powerseries $ f_1(x) = -3x + 4x^2 - 5x^3 + 6x^4 - \ldots $  and stated without the derivation that this is also $  f_2(x) = \frac {-2}{1} -\frac {-1}{x} + 0 - \frac  {1} {x^3} + \frac {2}{x^4} - \ldots + \ldots $ and - well: hell, - don't see it now how I did it. What was interesting to me was, that after looking for the fixpoints $ x_0=0, x_{1,2} =-2 $ the range of convergence in the expression by $f_1$ is obviously $ |x|<1 $ limited to the unit-interval but in that by $f_2$ it is infinity and $ |x|>1 $ . Q2: I would like to be able to translate also other powerseries into an $f_2$-type-expression. (I remember to have read a remark of ""expanding a powerseries at infinity"" but have never seen an explanation of this - so this might be irrelevant for this case?) So: what is the technique to do this given a function in terms of a usual powerseries, for instance for the geometric series $ g(x)=1+x+x^2+ \ldots $ or some series $ h(x) = K + a*x + b*x^2 + c*x^3 + \ldots $ ? [edit: minus-sign in f(x) was missing, one numerator in f2 was wrong]","This is initially a funny question, because I've found this on old notes but I do not find/recover my own derivation... But then the question is more general. Q1: I considered the function $ f(x) = - \frac {2x^2+3x}{(x+1)^2}  $ I expressed this by a powerseries $ f_1(x) = -3x + 4x^2 - 5x^3 + 6x^4 - \ldots $  and stated without the derivation that this is also $  f_2(x) = \frac {-2}{1} -\frac {-1}{x} + 0 - \frac  {1} {x^3} + \frac {2}{x^4} - \ldots + \ldots $ and - well: hell, - don't see it now how I did it. What was interesting to me was, that after looking for the fixpoints $ x_0=0, x_{1,2} =-2 $ the range of convergence in the expression by $f_1$ is obviously $ |x|<1 $ limited to the unit-interval but in that by $f_2$ it is infinity and $ |x|>1 $ . Q2: I would like to be able to translate also other powerseries into an $f_2$-type-expression. (I remember to have read a remark of ""expanding a powerseries at infinity"" but have never seen an explanation of this - so this might be irrelevant for this case?) So: what is the technique to do this given a function in terms of a usual powerseries, for instance for the geometric series $ g(x)=1+x+x^2+ \ldots $ or some series $ h(x) = K + a*x + b*x^2 + c*x^3 + \ldots $ ? [edit: minus-sign in f(x) was missing, one numerator in f2 was wrong]",,"['functions', 'functional-equations', 'taylor-expansion']"
44,Finding the maximum of an integral,Finding the maximum of an integral,,"I am wondering if it is possible to find the maximum ( $x_{\text{max}}$ , $v_{\text{max}}$ ), also an approximate one, of this integral as function of $x$ : $$v(x)=\int_0^{x+x_0} \frac{\exp \left[-\frac{(x-\tau )^2}{2}\right]}{\sqrt{\tau }} \, d\tau$$ Integrate[  1/Sqrt[\[Tau]] Exp[-((x - \[Tau])^2/2)], {\[Tau], 0, x + x0}] where $x_0>0$ and $x > -x_0$ . For example, for $x_0=4$ , we have varying $x$ : ListPlot[Table[{x,     NIntegrate[     1/Sqrt[\[Tau]] Exp[-((x - \[Tau])^2/2)], {\[Tau], 0, x + x0} /.       x0 -> 4]}, {x, -4, 15, 0.1}], Frame -> True,   FrameLabel -> {""x"", ""v(x)""}] From one side, I tried to find where $dv(x)/dx=0$ , using the Leibniz integral rule, for which $$\frac{dv}{dx}=\frac{e^{-\frac{x_0^2}{2}}}{\sqrt{x+x_0}}+\int_0^{x+x_0} \frac{e^{-\frac{1}{2} (x-\tau )^2} (\tau -x)}{\sqrt{\tau }} \, d\tau$$ 1/(E^(x0^2/2)*Sqrt[x + x0]) +   Integrate[(\[Tau] - x)/(E^((1/2)*(x - \[Tau])^2)*      Sqrt[\[Tau]]), {\[Tau], 0, x + x0}] but is seems that things get more complicated. On the other side, having checked that the maximum is near $t=0$ , I tried to sobstitute to the integrand in $v(x)$ its Taylor expansion around $t=0$ . In this case, the integral can be performed but the result is again much complicated depending on the number of terms kept from Taylor expansion. If $x_0\rightarrow \infty$ , the integral from $0$ to $\infty$ of the Taylor expansion of $$ \frac{\exp \left[-\frac{(x-\tau )^2}{2}\right]}{\sqrt{\tau }}$$ around $x=0$ truncated to the third order term is $$v(x)\approx -\frac{1}{6} \left(x^2-4\right) \left(2^{3/4} x \, \Gamma \left(\frac{7}{4}\right)+3 \sqrt[4]{2} \, \Gamma \left(\frac{5}{4}\right)\right)$$ The last function has a maximum of $v_\text{maxapprox}=2.52714$ at $x_\text{maxapprx}=0.651579$ with $$x_\text{maxapprox}=\frac{\frac{\sqrt{\sqrt{2} \Gamma \left(\frac{5}{4}\right)^2+\frac{8}{3} \sqrt{2} \Gamma \left(\frac{7}{4}\right)^2}}{2^{3/4}}-\frac{\Gamma \left(\frac{5}{4}\right)}{\sqrt{2}}}{\Gamma \left(\frac{7}{4}\right)}$$ (Numerically, for $x_0 \rightarrow \infty$ , the result should be $x_\text{max}=0.7649$ and $v_\text{max}=2.5596$ .) Any help or suggestion, also about the $x_0 \rightarrow \infty$ case, is really welcome.","I am wondering if it is possible to find the maximum ( , ), also an approximate one, of this integral as function of : Integrate[  1/Sqrt[\[Tau]] Exp[-((x - \[Tau])^2/2)], {\[Tau], 0, x + x0}] where and . For example, for , we have varying : ListPlot[Table[{x,     NIntegrate[     1/Sqrt[\[Tau]] Exp[-((x - \[Tau])^2/2)], {\[Tau], 0, x + x0} /.       x0 -> 4]}, {x, -4, 15, 0.1}], Frame -> True,   FrameLabel -> {""x"", ""v(x)""}] From one side, I tried to find where , using the Leibniz integral rule, for which 1/(E^(x0^2/2)*Sqrt[x + x0]) +   Integrate[(\[Tau] - x)/(E^((1/2)*(x - \[Tau])^2)*      Sqrt[\[Tau]]), {\[Tau], 0, x + x0}] but is seems that things get more complicated. On the other side, having checked that the maximum is near , I tried to sobstitute to the integrand in its Taylor expansion around . In this case, the integral can be performed but the result is again much complicated depending on the number of terms kept from Taylor expansion. If , the integral from to of the Taylor expansion of around truncated to the third order term is The last function has a maximum of at with (Numerically, for , the result should be and .) Any help or suggestion, also about the case, is really welcome.","x_{\text{max}} v_{\text{max}} x v(x)=\int_0^{x+x_0} \frac{\exp \left[-\frac{(x-\tau )^2}{2}\right]}{\sqrt{\tau }} \, d\tau x_0>0 x > -x_0 x_0=4 x dv(x)/dx=0 \frac{dv}{dx}=\frac{e^{-\frac{x_0^2}{2}}}{\sqrt{x+x_0}}+\int_0^{x+x_0} \frac{e^{-\frac{1}{2} (x-\tau )^2} (\tau -x)}{\sqrt{\tau }} \, d\tau t=0 v(x) t=0 x_0\rightarrow \infty 0 \infty  \frac{\exp \left[-\frac{(x-\tau )^2}{2}\right]}{\sqrt{\tau }} x=0 v(x)\approx -\frac{1}{6} \left(x^2-4\right) \left(2^{3/4} x \, \Gamma \left(\frac{7}{4}\right)+3 \sqrt[4]{2} \, \Gamma \left(\frac{5}{4}\right)\right) v_\text{maxapprox}=2.52714 x_\text{maxapprx}=0.651579 x_\text{maxapprox}=\frac{\frac{\sqrt{\sqrt{2} \Gamma \left(\frac{5}{4}\right)^2+\frac{8}{3} \sqrt{2} \Gamma \left(\frac{7}{4}\right)^2}}{2^{3/4}}-\frac{\Gamma \left(\frac{5}{4}\right)}{\sqrt{2}}}{\Gamma \left(\frac{7}{4}\right)} x_0 \rightarrow \infty x_\text{max}=0.7649 v_\text{max}=2.5596 x_0 \rightarrow \infty","['integration', 'functions', 'optimization']"
45,Equivalent characterizations of finite sets,Equivalent characterizations of finite sets,,"How can we show that the following notions of finiteness for a nonempty set $X$ are equivalent? There exists $n \in \mathbb{N}$ such that there is an injection $X \hookrightarrow \{1, \ldots, n\}$ There exists $n \in \mathbb{N}$ such that there is no injection $\{1, \ldots, n\} \hookrightarrow X$ There exists $n \in \mathbb{N}$ such that there is a surjection $\{1, \ldots, n\} \twoheadrightarrow X$ There exists $n \in \mathbb{N}$ such that there is no surjection $X \twoheadrightarrow \{1, \ldots, n\}$ There exists $n \in \mathbb{N}$ such that there is a bijection $X \leftrightarrow \{1, \ldots, n\}$ (5.) $\Rightarrow$ (1.) and (5.) $\Rightarrow$ (3.) are clear. I think I can show the following: (1.) $\Rightarrow$ (2.): By contradiction. Let $f: X \hookrightarrow \{1, \ldots, n\}$ be an injection. Assume that for all $m \in \mathbb{N}$ , there is an injection $\{1, \ldots, m\} \hookrightarrow X$ . In particular, take $m = n + 1$ and let $g: \{1, \ldots, n + 1\} \hookrightarrow X$ be an injection. Then $f \circ g: \{1, \ldots, n + 1\} \hookrightarrow \{1, \ldots, n\}$ is an injection, which is a contradiction. (3.) $\Rightarrow$ (4.): By contradiction. Let $f: \{1, \ldots, n\} \twoheadrightarrow X$ be a surjection. Assume that for all $m \in \mathbb{N}$ , there is a surjection $X \twoheadrightarrow \{1, \ldots, m\}$ . In particular, let $m = n + 1$ and let $g: X \twoheadrightarrow \{1, \ldots, n + 1\}$ be a surjection. Then $g \circ f: \{1, \ldots, n\} \twoheadrightarrow \{1, \ldots, n + 1\}$ is a surjection, which is a contradiction.","How can we show that the following notions of finiteness for a nonempty set are equivalent? There exists such that there is an injection There exists such that there is no injection There exists such that there is a surjection There exists such that there is no surjection There exists such that there is a bijection (5.) (1.) and (5.) (3.) are clear. I think I can show the following: (1.) (2.): By contradiction. Let be an injection. Assume that for all , there is an injection . In particular, take and let be an injection. Then is an injection, which is a contradiction. (3.) (4.): By contradiction. Let be a surjection. Assume that for all , there is a surjection . In particular, let and let be a surjection. Then is a surjection, which is a contradiction.","X n \in \mathbb{N} X \hookrightarrow \{1, \ldots, n\} n \in \mathbb{N} \{1, \ldots, n\} \hookrightarrow X n \in \mathbb{N} \{1, \ldots, n\} \twoheadrightarrow X n \in \mathbb{N} X \twoheadrightarrow \{1, \ldots, n\} n \in \mathbb{N} X \leftrightarrow \{1, \ldots, n\} \Rightarrow \Rightarrow \Rightarrow f: X \hookrightarrow \{1, \ldots, n\} m \in \mathbb{N} \{1, \ldots, m\} \hookrightarrow X m = n + 1 g: \{1, \ldots, n + 1\} \hookrightarrow X f \circ g: \{1, \ldots, n + 1\} \hookrightarrow \{1, \ldots, n\} \Rightarrow f: \{1, \ldots, n\} \twoheadrightarrow X m \in \mathbb{N} X \twoheadrightarrow \{1, \ldots, m\} m = n + 1 g: X \twoheadrightarrow \{1, \ldots, n + 1\} g \circ f: \{1, \ldots, n\} \twoheadrightarrow \{1, \ldots, n + 1\}","['functions', 'elementary-set-theory', 'natural-numbers']"
46,Prove that $f(A \cap f^{-1}(B))=f(A) \cap B$,Prove that,f(A \cap f^{-1}(B))=f(A) \cap B,"I'm attempting to prove that for a function $f: X \rightarrow Y$ and $A \subset X$ , $B \subset Y$ , the following equality holds: $$ f \left( A \cap f^{-1}(B) \right) = f(A) \cap B. $$ "" $\mathbf{\subset}$ "": Using that $f(A \cap A') \subset f(A) \cap f(A')$ and $f(f^{-1}(B)) \subset B$ , we get $$ f \left( A \cap f^{-1}(B) \right) \subset f(A) \cap f\left(f^{-1}(B)\right) \subset f(A) \cap B. $$ "" $\mathbf{\supset}$ "": For the reverse direction, I derived the following proof: $$ \begin{align*} y \in f(A) \cap B &\Longleftrightarrow y \in f(A) \wedge y \in B \\ &\Longleftrightarrow (\exists x \in A : f(x) = y) \wedge y \in B \\ &\Longleftrightarrow \exists x \in A : f(x) = y \wedge x \in f^{-1}(B) \\ &\Longleftrightarrow \exists x \in A \cap f^{-1}(B) : f(x) = y \\ &\Longleftrightarrow y \in f \left( A \cap f^{-1}(B) \right) \end{align*} $$ While I'm aware from other questions that the overall direction is correct, there seems to be a flaw in how I've articulated the proof since it demonstrates equality, which I suspect might not be accurate. I also apologize for the formatting issues but I couldn't manage the equation to be displayed as multi-line equation. Update I'm not a big fan of simply chaining equations without much explanation. However on of my professors uses this extensively in his course. Therefore I though this would be a good exercise. Furthermore I'm interested in whether the equivalency is true or not. I suspect it's not but am not sure where my error is.","I'm attempting to prove that for a function and , , the following equality holds: "" "": Using that and , we get "" "": For the reverse direction, I derived the following proof: While I'm aware from other questions that the overall direction is correct, there seems to be a flaw in how I've articulated the proof since it demonstrates equality, which I suspect might not be accurate. I also apologize for the formatting issues but I couldn't manage the equation to be displayed as multi-line equation. Update I'm not a big fan of simply chaining equations without much explanation. However on of my professors uses this extensively in his course. Therefore I though this would be a good exercise. Furthermore I'm interested in whether the equivalency is true or not. I suspect it's not but am not sure where my error is.","f: X \rightarrow Y A \subset X B \subset Y  f \left( A \cap f^{-1}(B) \right) = f(A) \cap B.  \mathbf{\subset} f(A \cap A') \subset f(A) \cap f(A') f(f^{-1}(B)) \subset B  f \left( A \cap f^{-1}(B) \right) \subset f(A) \cap f\left(f^{-1}(B)\right) \subset f(A) \cap B.  \mathbf{\supset}  \begin{align*}
y \in f(A) \cap B &\Longleftrightarrow y \in f(A) \wedge y \in B \\
&\Longleftrightarrow (\exists x \in A : f(x) = y) \wedge y \in B \\
&\Longleftrightarrow \exists x \in A : f(x) = y \wedge x \in f^{-1}(B) \\ &\Longleftrightarrow \exists x \in A \cap f^{-1}(B) : f(x) = y \\
&\Longleftrightarrow y \in f \left( A \cap f^{-1}(B) \right)
\end{align*} ","['functions', 'elementary-set-theory', 'solution-verification', 'proof-writing']"
47,Topological version of uniform convergence of functions,Topological version of uniform convergence of functions,,"We have a sequence of continuous functions $\{f_n\}$ on a Banach space $X$ and $f_n(x)\to f(x)$ for each $x\in X$ as $n\to\infty$ . Given an open ball $B\subset X$ and $\epsilon>0$ , we want to show that there exists another open ball $B_0\subset B$ and $m\geq 1$ such that $|f_m(x)-f(x)|\leq \epsilon$ , for all $x\in B_0$ . My approach: Let $Y$ be a closed ball in $B$ , fix $\epsilon>0$ and consider $E_l=\{x\in Y| \sup_{j,k\geq l} |f_j(x)-f_k(x)|< \epsilon\}$ . (Please check the following!) Then $E_l$ is open for each $l$ : this is because for any $x\in E_l$ , take the radius $r$ and corresponding ball $B_r(x)$ , such that both $d(f_j(x),f_j(x'))$ and $d(f_k(x),f_k(x'))<\delta/2$ where $\delta=\epsilon-\sup_{j,k\geq l} |f_j(x)-f_k(x)|$ (by taking the minimum $r$ at $x$ for $f_j$ and $f_k$ ), and therefore, we have $$\sup_{j,k\geq l} |f_j(x')-f_k(x')|=|f_{j'}(x')-f_{k'}(x')|$$ where $j', k'$ corresponds to the indices in the family $\{f_n\}$ corresponding to the supremum at the point $x'$ , then $$\leq |f_{j'}(x')-f_{j'}(x)+f_{j'}(x)-f_{k'}(x)+f_{k'}(x)-f_{k'}(x')|\leq \delta + \sup_{j,k\geq l}|f_j(x)-f_k(x)|< \epsilon$$ Then, notice that $E_1\subseteq E_2\subseteq E_3\dots$ and that $Y=\cup_{l=1}^\infty E_l$ . To prove this, take $(\cup_{l=1}^\infty E_l)^c=\cap_{l=1}^\infty E_l^c=\cap_{l=1}^\infty\{x\in Y: \dots \geq \epsilon \}=\varnothing$ by pointwise convergence of $f_n$ (for any $x$ , there is an $L$ such that for $l\geq L$ , $x\notin E_l^c$ . Now, I'm thinking that from this, the conclusion should follow but it feels like I'm missing something. We've covered Baire Category Theorem in class, and I'm sure this plays into the proof (at a higher level, whereas my approach is more bottom-up), but I'm unsure how to proceed and would therefore appreciate any help and/or feedback on my attempt. Notes: Recall a Baire space is a topological space such that the intersection of countably many dense open sets is still dense Recall Baire Category Theorem: Let $(X,\rho)$ be a complete metric space, then 1) if $\{U_n\}_1^\infty$ is an open dense set in $X$ , then $\cap_{n=1}^\infty \bar{U_n}=X$ , and also 2) $X$ is not meager. The version of BCT below follows from this. $A_l$ is clearly closed because for any $n$ and $x\in A_l$ , $\cdots\leq \epsilon$ , so $f(x)\leq \epsilon$ for any $x$ .","We have a sequence of continuous functions on a Banach space and for each as . Given an open ball and , we want to show that there exists another open ball and such that , for all . My approach: Let be a closed ball in , fix and consider . (Please check the following!) Then is open for each : this is because for any , take the radius and corresponding ball , such that both and where (by taking the minimum at for and ), and therefore, we have where corresponds to the indices in the family corresponding to the supremum at the point , then Then, notice that and that . To prove this, take by pointwise convergence of (for any , there is an such that for , . Now, I'm thinking that from this, the conclusion should follow but it feels like I'm missing something. We've covered Baire Category Theorem in class, and I'm sure this plays into the proof (at a higher level, whereas my approach is more bottom-up), but I'm unsure how to proceed and would therefore appreciate any help and/or feedback on my attempt. Notes: Recall a Baire space is a topological space such that the intersection of countably many dense open sets is still dense Recall Baire Category Theorem: Let be a complete metric space, then 1) if is an open dense set in , then , and also 2) is not meager. The version of BCT below follows from this. is clearly closed because for any and , , so for any .","\{f_n\} X f_n(x)\to f(x) x\in X n\to\infty B\subset X \epsilon>0 B_0\subset B m\geq 1 |f_m(x)-f(x)|\leq \epsilon x\in B_0 Y B \epsilon>0 E_l=\{x\in Y| \sup_{j,k\geq l} |f_j(x)-f_k(x)|< \epsilon\} E_l l x\in E_l r B_r(x) d(f_j(x),f_j(x')) d(f_k(x),f_k(x'))<\delta/2 \delta=\epsilon-\sup_{j,k\geq l} |f_j(x)-f_k(x)| r x f_j f_k \sup_{j,k\geq l} |f_j(x')-f_k(x')|=|f_{j'}(x')-f_{k'}(x')| j', k' \{f_n\} x' \leq |f_{j'}(x')-f_{j'}(x)+f_{j'}(x)-f_{k'}(x)+f_{k'}(x)-f_{k'}(x')|\leq \delta + \sup_{j,k\geq l}|f_j(x)-f_k(x)|< \epsilon E_1\subseteq E_2\subseteq E_3\dots Y=\cup_{l=1}^\infty E_l (\cup_{l=1}^\infty E_l)^c=\cap_{l=1}^\infty E_l^c=\cap_{l=1}^\infty\{x\in Y: \dots \geq \epsilon \}=\varnothing f_n x L l\geq L x\notin E_l^c (X,\rho) \{U_n\}_1^\infty X \cap_{n=1}^\infty \bar{U_n}=X X A_l n x\in A_l \cdots\leq \epsilon f(x)\leq \epsilon x","['real-analysis', 'general-topology', 'functional-analysis', 'analysis', 'functions']"
48,Finding general term for a sequence satisyfing provided conditions (with goniometric functions),Finding general term for a sequence satisyfing provided conditions (with goniometric functions),,"I want to inquire about how would one find the formula for $a_n$ (or reccurently) if we know: $$ \alpha_k = arctan\left(\frac{a_{(n+1)}}{a_n} \right) $$ $$ \sin{\alpha_k} = \sin{\alpha_{(k-1)}} \cdot \frac{ a_n }{a_{(n+1)}}  $$ This is also true for the first elements, the sequence entry condition is $$ \alpha_1 = \arctan{ \left( \frac{a_2}{a_1} \right)}$$ It does not matter what exact values $a_1 $ and $a_2$ hold as long as they satisfy this condition When I try to plug in those conditions together, I get $ a_{(n+1)} = a_{(n+1)} $ which is obviously true but also not helpful at all.","I want to inquire about how would one find the formula for (or reccurently) if we know: This is also true for the first elements, the sequence entry condition is It does not matter what exact values and hold as long as they satisfy this condition When I try to plug in those conditions together, I get which is obviously true but also not helpful at all.",a_n  \alpha_k = arctan\left(\frac{a_{(n+1)}}{a_n} \right)   \sin{\alpha_k} = \sin{\alpha_{(k-1)}} \cdot \frac{ a_n }{a_{(n+1)}}    \alpha_1 = \arctan{ \left( \frac{a_2}{a_1} \right)} a_1  a_2  a_{(n+1)} = a_{(n+1)} ,"['sequences-and-series', 'functions']"
49,Can a discontinuous function be increasing or decreasing,Can a discontinuous function be increasing or decreasing,,How would we decide increasing or decreasing function if the function is not differentiable? Can a discontinuous function be increasing or decreasing? And can it be monotonic?,How would we decide increasing or decreasing function if the function is not differentiable? Can a discontinuous function be increasing or decreasing? And can it be monotonic?,,"['calculus', 'functions', 'derivatives', 'monotone-functions']"
50,Domain of a function that accepts two vectors of $\mathbb R^n$?,Domain of a function that accepts two vectors of ?,\mathbb R^n,"Consider the function $f$ defined by $f(\vec{u}, \vec{v})=\vec{u}\cdot\vec{v}$ , where $\vec{u},\vec{v}\in\mathbb R^n$ . What is the domain of $f$ ? $\mathbb R^n\times\mathbb R^n=\mathbb R^{2n}$ ?","Consider the function defined by , where . What is the domain of ? ?","f f(\vec{u}, \vec{v})=\vec{u}\cdot\vec{v} \vec{u},\vec{v}\in\mathbb R^n f \mathbb R^n\times\mathbb R^n=\mathbb R^{2n}","['functions', 'vectors']"
51,Are all solutions f(x) for f(x) = f(cos(x)) constant?,Are all solutions f(x) for f(x) = f(cos(x)) constant?,,"Under a post in this forum, I found a comment ( https://math.stackexchange.com/a/46936/1173827 ) by Beni Bogosel that mentions the problem of finding all solutions for a function $f:\mathbb{R}\rightarrow\mathbb{R}$ with the property $f(x)=f(\cos x), \forall x \in \mathbb{R}$ . Out of interest, I began searching for a solution. Immediately the solution $f(x)=0$ came to mind. The next set of solutions is $f(x)=k, k\in\mathbb{R}$ . But now I wondered if there are non-constant solutions. I figure that the domain of $f$ must be confined to the interval [-1,1], since this is the output range of $\cos(x)$ . For my first attempt I considered if $f(x)=g_1(x)+g_2(x)$ , where the new two functions are switch functions that just turn into the other if $x$ or $\cos(x)$ is the input. But this is just a rephrasing of the problem and did not get me far. Then I remembered that the question under which I found this problem was about a solution for $x=\cos(x)$ , so I decided to approach the issue from that direction. When plugging $\cos(x)$ into $f(x)$ , I get $$f(\cos(x))=f(\cos(\cos(x)))$$ But from the defining property of $f(x)$ I know that $$f(x) = f(\cos(x))=f(\cos(\cos(x)))$$ I can repeat this forever until I have an infinitely nested $\cos(x)$ inside of $f(x)$ so that $$f(x) = f(\cos(\cos(\cos( \cdots ))))$$ I know that these nested $\cos(x)$ approach a constant with the approximate value $q\approx0.739085$ . But would this not imply that $f(x)=f(q)=k$ again? Is it true then that all solutions for $f(x)=f(\cos(x))$ are just constant? Does a non-constant solution truly not exist?","Under a post in this forum, I found a comment ( https://math.stackexchange.com/a/46936/1173827 ) by Beni Bogosel that mentions the problem of finding all solutions for a function with the property . Out of interest, I began searching for a solution. Immediately the solution came to mind. The next set of solutions is . But now I wondered if there are non-constant solutions. I figure that the domain of must be confined to the interval [-1,1], since this is the output range of . For my first attempt I considered if , where the new two functions are switch functions that just turn into the other if or is the input. But this is just a rephrasing of the problem and did not get me far. Then I remembered that the question under which I found this problem was about a solution for , so I decided to approach the issue from that direction. When plugging into , I get But from the defining property of I know that I can repeat this forever until I have an infinitely nested inside of so that I know that these nested approach a constant with the approximate value . But would this not imply that again? Is it true then that all solutions for are just constant? Does a non-constant solution truly not exist?","f:\mathbb{R}\rightarrow\mathbb{R} f(x)=f(\cos x), \forall x \in \mathbb{R} f(x)=0 f(x)=k, k\in\mathbb{R} f \cos(x) f(x)=g_1(x)+g_2(x) x \cos(x) x=\cos(x) \cos(x) f(x) f(\cos(x))=f(\cos(\cos(x))) f(x) f(x) = f(\cos(x))=f(\cos(\cos(x))) \cos(x) f(x) f(x) = f(\cos(\cos(\cos( \cdots )))) \cos(x) q\approx0.739085 f(x)=f(q)=k f(x)=f(\cos(x))","['functions', 'transcendental-equations']"
52,"Finding supremum of a given function, over a given domain.","Finding supremum of a given function, over a given domain.",,"Consider arbitrary $0 < \lambda \leqslant n$ , $1 \leqslant p < \infty$ and $\alpha,\beta > 0$ such that $\alpha < \frac{n-\lambda}{p} < \beta.$ My goal is to compute the supremum of the function $$ f(r) = r^{-\lambda}\left[ \frac{c(n)}{-\alpha p + n} + k(n)\left( \frac{r^{-\beta p + n}}{-\beta p + n} - \frac{1}{-\beta p + n}\right)\right]$$ where $c(n)$ and $k(n)$ are unknown positive constants, over $ r \geqslant 1$ . My attempt. Since $ \alpha < \frac{n-\lambda}{p}$ , we know that $-\alpha p + n > \lambda > 0,$ which implies that the term $c(n)/(-\alpha p + n)$ is positive. Therefore, $r^{-\lambda}\frac{c(n)}{-\alpha p + n}$ attains its supremum exactly when $r = 1$ . On the other hand, the other terms are quite hard to analyze: First, the inequality $\frac{n-\lambda}{p} < \beta$ doesn't give me any conclusion on the signal of $-\beta p + n$ , which complicates the calculations; On the other hand, we know that $-\beta p + n -\lambda < 0,$ which implies that the supremum of $r^{-\beta p + n - \lambda}$ is attained when $r=1$ ; If we assume that $-\beta p + n > 0,$ then the supremum of $k(n)\frac{r^{-\beta p+n-\lambda}}{-\beta p+n}$ is also attained when $r=1$ , just from what I wrote on the last point; Now, if we keep assuming that $-\beta p + n>0$ , then the sumpremum of $-k(n)\frac{r^{-\lambda}}{-\beta p + n}$ is attained when $r \to \infty$ . Clearly, from the points I stated above it is impossible to reach any conclusion. So, I am looking for a new way of approaching this problem. Ideally, I am looking for a solution that doesn't assume anything about $-\beta p + n$ , but I strongly believe this is not possible, so a solution that assumes that $-\beta p + n > 0$ will be good enough. Furthermore, if you have any other suggestion of assumptions (perhaps changing the initial inequalities to make the exercise easier) I am open to listen to them. Thanks for any help in advance.","Consider arbitrary , and such that My goal is to compute the supremum of the function where and are unknown positive constants, over . My attempt. Since , we know that which implies that the term is positive. Therefore, attains its supremum exactly when . On the other hand, the other terms are quite hard to analyze: First, the inequality doesn't give me any conclusion on the signal of , which complicates the calculations; On the other hand, we know that which implies that the supremum of is attained when ; If we assume that then the supremum of is also attained when , just from what I wrote on the last point; Now, if we keep assuming that , then the sumpremum of is attained when . Clearly, from the points I stated above it is impossible to reach any conclusion. So, I am looking for a new way of approaching this problem. Ideally, I am looking for a solution that doesn't assume anything about , but I strongly believe this is not possible, so a solution that assumes that will be good enough. Furthermore, if you have any other suggestion of assumptions (perhaps changing the initial inequalities to make the exercise easier) I am open to listen to them. Thanks for any help in advance.","0 < \lambda \leqslant n 1 \leqslant p < \infty \alpha,\beta > 0 \alpha < \frac{n-\lambda}{p} < \beta.  f(r) = r^{-\lambda}\left[ \frac{c(n)}{-\alpha p + n} + k(n)\left( \frac{r^{-\beta p + n}}{-\beta p + n} - \frac{1}{-\beta p + n}\right)\right] c(n) k(n)  r \geqslant 1  \alpha < \frac{n-\lambda}{p} -\alpha p + n > \lambda > 0, c(n)/(-\alpha p + n) r^{-\lambda}\frac{c(n)}{-\alpha p + n} r = 1 \frac{n-\lambda}{p} < \beta -\beta p + n -\beta p + n -\lambda < 0, r^{-\beta p + n - \lambda} r=1 -\beta p + n > 0, k(n)\frac{r^{-\beta p+n-\lambda}}{-\beta p+n} r=1 -\beta p + n>0 -k(n)\frac{r^{-\lambda}}{-\beta p + n} r \to \infty -\beta p + n -\beta p + n > 0","['real-analysis', 'functions', 'inequality', 'solution-verification', 'supremum-and-infimum']"
53,How to squeeze the logistic function obliquely?,How to squeeze the logistic function obliquely?,,"The original function: $f(x) = \frac{1}{1+e^{-10(x-0.5)}} $ . Its graph (blue line) is shown here : How can I squeeze this function obliquely along the $y=x$ line? The squeezed function $g$ needs to satisfy that $g(0.5) = 0.5$ , $g(0)$ is close to $0$ , and $g(1)$ is close to $1$ . The graph of this function $g$ that I have in mind is the black line in the image above.","The original function: . Its graph (blue line) is shown here : How can I squeeze this function obliquely along the line? The squeezed function needs to satisfy that , is close to , and is close to . The graph of this function that I have in mind is the black line in the image above.",f(x) = \frac{1}{1+e^{-10(x-0.5)}}  y=x g g(0.5) = 0.5 g(0) 0 g(1) 1 g,"['functions', 'graphing-functions', 'transformation', 'continuous-variables']"
54,Theorems about periodic functions,Theorems about periodic functions,,"I'm trying to prove something about periodic functions and I'd need someone to tell me if what I wrote is right! If $f$ is a periodic function with fundamental period $\tau$ . Then, all periods of $f$ are  in the form $k\tau$ , with $k$ in $\mathbb{Z}$ Obviously, if $\tau$ is the fundamental period of $f$ , $k\tau$ is too: \begin{equation*} 	f(x+k\tau)=f(x+\underbrace{\tau+\tau+\dots+\tau}_{k \text{ times}})=f(x+\underbrace{\tau+\tau+\dots+\tau}_{k-1 \text{ times}})=\dots=f(x+\tau)=f(x) \end{equation*} Viceversa, let's suppose that a period different from $k\tau$ exists, and let's call it $\beta>\tau$ . Hypothesis tell us that $\frac{\beta}{\tau}\neq k$ , and so $\frac{\beta}{\tau}$ is not an integer. We have  two possibilities: $\frac{\beta}{\tau}$ is rational, but not integer; $\frac{\beta}{\tau}$ is irrational. In the first case, it could be: $\beta$ and $\tau$ are two irrational numbers that gives a rational when divided: $\beta=s\tau$ with $s\in\mathbb{Q}\verb|\| \mathbb{Z} $ $\beta$ and $\tau$ are two integers without factors in common. Let's analyze case by case If $\beta=s\tau$ with $s$ like I said, $\beta$ is not a period. In fact, even if $\tau$ is a period of $f$ , $\beta=s\tau$ isn't anymore. We can consider $\sin(\pi+2\pi)=\sin(\pi)=0\neq\sin(\pi+\frac{1}{3}2\pi)$ for a counterexample. If $\beta$ and $\tau$ are two integers without factors in common, we cand divide $\beta$ by $\tau$ , finding the quotient $q$ and the remainder $r$ so that: \begin{equation*} 			\beta=q\cdot\tau+r 		\end{equation*} with $0<r<\tau$ . Now, for hypothesis $\beta$ is a period, and so: \begin{equation*} 		f(x)=f(x+\beta)=f(x+q\cdot\tau+r)=f(x+r) \end{equation*} That means that $r$ too is a period, but this is absurd because $\tau$ is the minimum  period and $r<\tau$ . If $\frac{\beta}{\tau}=t$ with $t$ irrational, $\beta=\tau t$ isn't a period anymore (it's possible to create a counterexample like done before). So, if $\beta\neq k\tau$ , $\beta$ isn't a period, therefore $\beta=k\tau$ , with $k\in\mathbb{Z}$ Now let's use this result to show that: If $f$ and $g$ are periodic functions with fundamental period $s$ and $t$ respectively, then if: $i)$ $\frac{s}{t}$ is a rational number $\neq1$ , $f+g$ , $fg$ , $f/g$ are periodic functions with period $mcm(s,t)$ . $ii)$ $s=t$ , $f+g$ , $fg$ , $f/g$ are periodic functions and their period is $\leq s=t$ ; $iii)$ $\frac{s}{t}$ is irrational, $f+g$ , $fg$ , $f/g$ are not periodic functions. Here we extend the notion of $mcm$ to real number as it follow: \begin{equation*} 		z=mcm(\alpha,\beta) \iff \exists m,n \in \mathbb{Z} : \begin{cases} 			\alpha=m\cdot z\\ 			\beta=n\cdot z 		\end{cases} 		\end{equation*} $i)$ If $\frac{s}{t}=k$ is rational,  we have $\frac{s}{t}=\frac{m}{n} \implies sn=mt$ , with $s$ and $m$ integers. $mcm(s,t)=sn=mt$ . Let's see if $sn$ is a period for $f+g$ , $fg$ e $f/g$ . We have: \begin{equation*} 	\begin{aligned} 		&(f+g)(x+m)=f(x+m)+g(x+m)=f(x+n\cdot kt)+g(x+l\cdot 	t)=f(x)+g(x)=(f+g)(x)\\ 		&(fg)(x+sn)=f(x+sn)g(x+sn)=f(x+sn)g(x+mt)=f(x)g(x) \\ 	    &\frac{f(x+sn)}{g(x+mt)}=\frac{f(x)}{g(x)} 	\end{aligned} \end{equation*} So $sn=mt$ is a period for $f+g$ , $fg$ , $f/g$ . We have to show that $sn=mt$ is the minimum of the positive periods of $f$ : suppose that $\alpha$ is the period of $f$ , so $\alpha\leq sn$ . By the precedent proposition, we know that $sn$ is in the form $\alpha k_1$ , and so: \begin{equation*} 				k_1=\frac{sn}{\alpha} 			\end{equation*} $k_1$ is an integer, so $\frac{sn}{\alpha}$ must be an  integer. That happens if $sn=mt=\alpha$ (in this case,we conclude), or $\frac{s}{\alpha}$ is integer: $s=k_2\cdot \alpha$ . But that means that $s$ is a period for $f+g, fg, f/g$ . We can repeat the same with $mt$ , and we would get that $t$ is a period for $f+g, fg, f/g$ . However, since $s=kt$ ; if $k$ is rational not integer, that isn't true (in fact $s$ wouldn't be a period for $g$ ), if $k$ is an integer, $t$ can't be a period for $f$ (otherwise it would be a positive period less than the fundamental period),and so it can't be a period for $f+g, fg, f/g$ too. That means that the only possibility is $sn=mt=\alpha$ . $ii)$ In this case it's obvious that $s=t$ is a period for  the functions $f+g$ , $fg$ , $f/g$ . However, we don't manage to say much on he period of these functions. The only thing we can say is that if $\alpha$ is \textbf{the} fundamental period, it is the minimum of the positive periods, and so it surely will be $\alpha \leq s=t$ $iii)$ If $\frac{s}{t}$ is irrational, then we can't find integers $m$ , $n$ so that $ms=nt$ . Anyway, suppose that $f+g$ $fg$ $f/g$ are periodics with fundamental period $c$ . $c$ can't be, at the same time, period of $f$ and period of $g$ , because such number doesn't exist. If $c$ was a period for $f$ ( $c=kt$ ), we would have: \begin{equation*} 	f(x+kt)+g(x+kt)=f(x)+g(x+kt)\neq f(x)+g(x) \end{equation*} And so $kt$ is not the period of $f+g$ ,same thing if $c$ was a period for $g$ . But that means that $\exists x\in X : f(x+c)\neq f(x)$ and $g(x+c)\neq g(x)$ and so $f(x)+g(x) \neq f(x+c)+g(x+c)$ . Therefore, $c$ is not a period for $f+g$ , contraddiction: $f+g$ is not periodic. This can be done in the same way for the function $fg$ $f/g$ , and we conclude.","I'm trying to prove something about periodic functions and I'd need someone to tell me if what I wrote is right! If is a periodic function with fundamental period . Then, all periods of are  in the form , with in Obviously, if is the fundamental period of , is too: Viceversa, let's suppose that a period different from exists, and let's call it . Hypothesis tell us that , and so is not an integer. We have  two possibilities: is rational, but not integer; is irrational. In the first case, it could be: and are two irrational numbers that gives a rational when divided: with and are two integers without factors in common. Let's analyze case by case If with like I said, is not a period. In fact, even if is a period of , isn't anymore. We can consider for a counterexample. If and are two integers without factors in common, we cand divide by , finding the quotient and the remainder so that: with . Now, for hypothesis is a period, and so: That means that too is a period, but this is absurd because is the minimum  period and . If with irrational, isn't a period anymore (it's possible to create a counterexample like done before). So, if , isn't a period, therefore , with Now let's use this result to show that: If and are periodic functions with fundamental period and respectively, then if: is a rational number , , , are periodic functions with period . , , , are periodic functions and their period is ; is irrational, , , are not periodic functions. Here we extend the notion of to real number as it follow: If is rational,  we have , with and integers. . Let's see if is a period for , e . We have: So is a period for , , . We have to show that is the minimum of the positive periods of : suppose that is the period of , so . By the precedent proposition, we know that is in the form , and so: is an integer, so must be an  integer. That happens if (in this case,we conclude), or is integer: . But that means that is a period for . We can repeat the same with , and we would get that is a period for . However, since ; if is rational not integer, that isn't true (in fact wouldn't be a period for ), if is an integer, can't be a period for (otherwise it would be a positive period less than the fundamental period),and so it can't be a period for too. That means that the only possibility is . In this case it's obvious that is a period for  the functions , , . However, we don't manage to say much on he period of these functions. The only thing we can say is that if is \textbf{the} fundamental period, it is the minimum of the positive periods, and so it surely will be If is irrational, then we can't find integers , so that . Anyway, suppose that are periodics with fundamental period . can't be, at the same time, period of and period of , because such number doesn't exist. If was a period for ( ), we would have: And so is not the period of ,same thing if was a period for . But that means that and and so . Therefore, is not a period for , contraddiction: is not periodic. This can be done in the same way for the function , and we conclude.","f \tau f k\tau k \mathbb{Z} \tau f k\tau \begin{equation*}
	f(x+k\tau)=f(x+\underbrace{\tau+\tau+\dots+\tau}_{k \text{ times}})=f(x+\underbrace{\tau+\tau+\dots+\tau}_{k-1 \text{ times}})=\dots=f(x+\tau)=f(x)
\end{equation*} k\tau \beta>\tau \frac{\beta}{\tau}\neq k \frac{\beta}{\tau} \frac{\beta}{\tau} \frac{\beta}{\tau} \beta \tau \beta=s\tau s\in\mathbb{Q}\verb|\| \mathbb{Z}  \beta \tau \beta=s\tau s \beta \tau f \beta=s\tau \sin(\pi+2\pi)=\sin(\pi)=0\neq\sin(\pi+\frac{1}{3}2\pi) \beta \tau \beta \tau q r \begin{equation*}
			\beta=q\cdot\tau+r
		\end{equation*} 0<r<\tau \beta \begin{equation*}
		f(x)=f(x+\beta)=f(x+q\cdot\tau+r)=f(x+r)
\end{equation*} r \tau r<\tau \frac{\beta}{\tau}=t t \beta=\tau t \beta\neq k\tau \beta \beta=k\tau k\in\mathbb{Z} f g s t i) \frac{s}{t} \neq1 f+g fg f/g mcm(s,t) ii) s=t f+g fg f/g \leq s=t iii) \frac{s}{t} f+g fg f/g mcm \begin{equation*}
		z=mcm(\alpha,\beta) \iff \exists m,n \in \mathbb{Z} : \begin{cases}
			\alpha=m\cdot z\\
			\beta=n\cdot z
		\end{cases}
		\end{equation*} i) \frac{s}{t}=k \frac{s}{t}=\frac{m}{n} \implies sn=mt s m mcm(s,t)=sn=mt sn f+g fg f/g \begin{equation*}
	\begin{aligned}
		&(f+g)(x+m)=f(x+m)+g(x+m)=f(x+n\cdot kt)+g(x+l\cdot 	t)=f(x)+g(x)=(f+g)(x)\\
		&(fg)(x+sn)=f(x+sn)g(x+sn)=f(x+sn)g(x+mt)=f(x)g(x) \\
	    &\frac{f(x+sn)}{g(x+mt)}=\frac{f(x)}{g(x)}
	\end{aligned}
\end{equation*} sn=mt f+g fg f/g sn=mt f \alpha f \alpha\leq sn sn \alpha k_1 \begin{equation*}
				k_1=\frac{sn}{\alpha}
			\end{equation*} k_1 \frac{sn}{\alpha} sn=mt=\alpha \frac{s}{\alpha} s=k_2\cdot \alpha s f+g, fg, f/g mt t f+g, fg, f/g s=kt k s g k t f f+g, fg, f/g sn=mt=\alpha ii) s=t f+g fg f/g \alpha \alpha \leq s=t iii) \frac{s}{t} m n ms=nt f+g fg f/g c c f g c f c=kt \begin{equation*}
	f(x+kt)+g(x+kt)=f(x)+g(x+kt)\neq f(x)+g(x)
\end{equation*} kt f+g c g \exists x\in X : f(x+c)\neq f(x) g(x+c)\neq g(x) f(x)+g(x) \neq f(x+c)+g(x+c) c f+g f+g fg f/g","['real-analysis', 'calculus', 'functions', 'solution-verification', 'periodic-functions']"
55,What functions describe themselves with degree n,What functions describe themselves with degree n,,"I'm interested in understanding functions that describe themselves in a certain degree $ n $ . Let me define what I mean by this: A function $ f(x) $ is said to describe itself in degree $ n $ if there exists a function $ g_{n,f} $ with an inverse such that $$ f = g^{-1} \circ f^n \circ g $$ Notably, every function describes itself in degree 1, since $ g(t) = t $ in that case. An example to illustrate this concept is the function $ f(x) = 2x $ , which describes itself in degree 2 with $ g(x) = a|x|x $ and its inverse $ g^{-1}(x) = \frac{\sqrt{|\frac{x}{a}|} \cdot |\frac{x}{a}|}{(\frac{x}{a})} $ for $ x \neq 0 $ and 0 when $ x = 0 $ , where $ a $ is a non-zero real number. Through this exploration, I've found that $ g(x) $ for n degree is related to $ a \cdot x^n $ , but I'm struggling to find a $ g(x) $ for $f(x) = x^2$ for any other degree other than the trivial case of degree equaling $ 1 $ . my main question is this What types of functions describe themselves with degree $ n $ ? My follow up questions that I think are important as well are as follows: How does this change if we restrict our functions to complex-to-complex, real-to-real, positive-to-positive, or integer-to-integer mappings? What are the constraints required for a function to describe itself in a specific degree $ n $ ? Are there functions that describe themselves in some $ n > 1 $ but not in all such $ n $ ? Does the function $ x^2 $ describe itself in any degree other than degree 1? I appreciate any insights or references that could help in understanding these types of functions and their properties.","I'm interested in understanding functions that describe themselves in a certain degree . Let me define what I mean by this: A function is said to describe itself in degree if there exists a function with an inverse such that Notably, every function describes itself in degree 1, since in that case. An example to illustrate this concept is the function , which describes itself in degree 2 with and its inverse for and 0 when , where is a non-zero real number. Through this exploration, I've found that for n degree is related to , but I'm struggling to find a for for any other degree other than the trivial case of degree equaling . my main question is this What types of functions describe themselves with degree ? My follow up questions that I think are important as well are as follows: How does this change if we restrict our functions to complex-to-complex, real-to-real, positive-to-positive, or integer-to-integer mappings? What are the constraints required for a function to describe itself in a specific degree ? Are there functions that describe themselves in some but not in all such ? Does the function describe itself in any degree other than degree 1? I appreciate any insights or references that could help in understanding these types of functions and their properties."," n   f(x)   n   g_{n,f}   f = g^{-1} \circ f^n \circ g   g(t) = t   f(x) = 2x   g(x) = a|x|x   g^{-1}(x) = \frac{\sqrt{|\frac{x}{a}|} \cdot |\frac{x}{a}|}{(\frac{x}{a})}   x \neq 0   x = 0   a   g(x)   a \cdot x^n   g(x)  f(x) = x^2  1   n   n   n > 1   n   x^2 ",['functions']
56,Distance between $e^x$ and $\ln x$ using tangent/normal method,Distance between  and  using tangent/normal method,e^x \ln x,"I have been trying to find the shortest distance between $f(x)=e^x$ and $g(x)=\ln(x)$ . All methods I have seen include taking the $y=x$ line as the mirror and find a point on both curves which have same slope as the mirror ( $1$ in this case). Now this method is working only because it is a very specific case as the functions are inverse of each other. The general method would be to find a common normal between the two curves and calculate the distance from where the normal intersects them. I am trying to apply this method for the given question but am getting unexpected results. First I found derivatives for both curves, took their reciprocals, and multiplied them by a minus sign to get the slope of the normal: $m_{f(x)normal}=-\frac{1}{e^x}$ $m_{g(x)normal}=-x$ Now, both these slopes must be equal in case of a common normal. But equating them yields: $xe^x=1$ This is far from the actual answer of $x=1$ and $x=0$ where the normal intersect the curves. Where am I going wrong?","I have been trying to find the shortest distance between and . All methods I have seen include taking the line as the mirror and find a point on both curves which have same slope as the mirror ( in this case). Now this method is working only because it is a very specific case as the functions are inverse of each other. The general method would be to find a common normal between the two curves and calculate the distance from where the normal intersects them. I am trying to apply this method for the given question but am getting unexpected results. First I found derivatives for both curves, took their reciprocals, and multiplied them by a minus sign to get the slope of the normal: Now, both these slopes must be equal in case of a common normal. But equating them yields: This is far from the actual answer of and where the normal intersect the curves. Where am I going wrong?",f(x)=e^x g(x)=\ln(x) y=x 1 m_{f(x)normal}=-\frac{1}{e^x} m_{g(x)normal}=-x xe^x=1 x=1 x=0,"['functions', 'exponential-function', 'graphing-functions', 'calculus-of-variations']"
57,Fixing a proof involving surjective and injective functions,Fixing a proof involving surjective and injective functions,,"I'm trying to prove that there exists an injective function $f: A \to B$ if and only if there exists a surjective function $g : B \to A$ . I'm fine with the [⇐] direction (which requires the Axiom of Choice), but stuck with part of the [⇒] direction. The theorem is discussed here There exists an injection from $X$ to $Y$ if and only if there exists a surjection from $Y$ to $X$. but the answers there do not touch upon the issue I have. Here is the start of my proof: [⇒] Let $f: A \to B$ be an injection. We need to prove there exists a surjective function $g: B \to A$ . Cases: $A \neq \emptyset = B$ . $A = \emptyset = B$ . $A \neq  \emptyset \neq  B$ . $A = \emptyset \neq B$ . In case 1 the implication follows because the antecedent is false (there cannot be a function from a non-empty set into the empty set). In Case(2), $f^T$ is trivially a surjective function. For Case 3 we take some arbitrary but fixed element $z \in A$ and then set $$g =_{df} f^T \cup (B \setminus \operatorname{range}(f) \times \{z\})$$ If $\operatorname{range}(f) = B$ then $g = f^T \cup (B \setminus \operatorname{range}(f) \times \{z\}) = f^T \cup (\emptyset \times \{z\}) = f^T$ . And $g$ is a surjective function. But now consider Case 4. In this case $f : \emptyset \to B$ is clearly an injective function. But since there can be no function from a non-empty set into the empty set, there cannot be a function from $B$ to $A$ , so there cannot be a surjective function. So how can I find a surjective function in Case 4?","I'm trying to prove that there exists an injective function if and only if there exists a surjective function . I'm fine with the [⇐] direction (which requires the Axiom of Choice), but stuck with part of the [⇒] direction. The theorem is discussed here There exists an injection from $X$ to $Y$ if and only if there exists a surjection from $Y$ to $X$. but the answers there do not touch upon the issue I have. Here is the start of my proof: [⇒] Let be an injection. We need to prove there exists a surjective function . Cases: . . . . In case 1 the implication follows because the antecedent is false (there cannot be a function from a non-empty set into the empty set). In Case(2), is trivially a surjective function. For Case 3 we take some arbitrary but fixed element and then set If then . And is a surjective function. But now consider Case 4. In this case is clearly an injective function. But since there can be no function from a non-empty set into the empty set, there cannot be a function from to , so there cannot be a surjective function. So how can I find a surjective function in Case 4?",f: A \to B g : B \to A f: A \to B g: B \to A A \neq \emptyset = B A = \emptyset = B A \neq  \emptyset \neq  B A = \emptyset \neq B f^T z \in A g =_{df} f^T \cup (B \setminus \operatorname{range}(f) \times \{z\}) \operatorname{range}(f) = B g = f^T \cup (B \setminus \operatorname{range}(f) \times \{z\}) = f^T \cup (\emptyset \times \{z\}) = f^T g f : \emptyset \to B B A,"['functions', 'elementary-set-theory', 'logic', 'axiom-of-choice']"
58,Prove that Gradient points to Steepest Ascent,Prove that Gradient points to Steepest Ascent,,"I’m following a course on Machine Learning at uni at the moment. It is the first mathematics course I’ve followed in a while, so I’ve had some difficulty getting back into the mathematics ‘way of thinking’ if you know what I mean. The exercise I’m having difficulty with at the moment is as follows: Let $f : \mathbb{R}^d \to \mathbb{R}$ be differentiable, show that the largest possible increase of the functions $$ \phi_v(t) = f(x+tv) : v \in \mathbb{R}^d, \|v\|_2 = 1$$ in $t=0$ is $\|\nabla f(x)\|_2$ and is assumed for $v = \nabla f(x) / \|\nabla f(x)\|_2$ . A hint was given of using Cauchy-Schwarz (recalling when this is an equality), but I have no idea how I would even start at solving this problem. Any help at all would be greatly appreciated! Thanks in advance!","I’m following a course on Machine Learning at uni at the moment. It is the first mathematics course I’ve followed in a while, so I’ve had some difficulty getting back into the mathematics ‘way of thinking’ if you know what I mean. The exercise I’m having difficulty with at the moment is as follows: Let be differentiable, show that the largest possible increase of the functions in is and is assumed for . A hint was given of using Cauchy-Schwarz (recalling when this is an equality), but I have no idea how I would even start at solving this problem. Any help at all would be greatly appreciated! Thanks in advance!","f : \mathbb{R}^d \to \mathbb{R}  \phi_v(t) = f(x+tv) : v \in \mathbb{R}^d, \|v\|_2 = 1 t=0 \|\nabla f(x)\|_2 v = \nabla f(x) / \|\nabla f(x)\|_2","['real-analysis', 'functions', 'optimization', 'vector-analysis']"
59,"Why can we produce a composition of two functions, if we know that the codomain of the inner function is equal to the domain of the outer function?","Why can we produce a composition of two functions, if we know that the codomain of the inner function is equal to the domain of the outer function?",,"I'm having some trouble understanding this. For example if we have functions $f:X \to Y$ and $g:Y\to Z$ it seems to me that the only possible way for $g \circ f$ to be defined is if $f(X)$ =Y so the range of f must equal it's codomain. For example if we construct $g(f(x))$ then that $f(x)$ is always some element in the range of f, but not necessarily in it's codomain, for example if $f$ isn't surjective. So lets say $f(x)$ is some $y\in Y$ (not random) then we have $g(y)$ , and since $g$ maps from $Y$ to $Z$ then by definition of a function all elements of Y must be mapped to it's codomain. But lets assume that f isn't surjective so then $g(y)$ can't map all of the elements in it's domain, and the function $g \circ f$ can't be defined. So then when we have this information of where these sets f and g map to and we try to make a composition of f and g, we always have to implicitly assume that f(X)=Y.","I'm having some trouble understanding this. For example if we have functions and it seems to me that the only possible way for to be defined is if =Y so the range of f must equal it's codomain. For example if we construct then that is always some element in the range of f, but not necessarily in it's codomain, for example if isn't surjective. So lets say is some (not random) then we have , and since maps from to then by definition of a function all elements of Y must be mapped to it's codomain. But lets assume that f isn't surjective so then can't map all of the elements in it's domain, and the function can't be defined. So then when we have this information of where these sets f and g map to and we try to make a composition of f and g, we always have to implicitly assume that f(X)=Y.",f:X \to Y g:Y\to Z g \circ f f(X) g(f(x)) f(x) f f(x) y\in Y g(y) g Y Z g(y) g \circ f,"['calculus', 'functions']"
60,Proof that the function $f(x)=x(\frac{3}{2}+\lfloor -x^2 \rfloor)$ is injective,Proof that the function  is injective,f(x)=x(\frac{3}{2}+\lfloor -x^2 \rfloor),"I've been stuck on this one for a while, what I've basically tried is showing that: $$ f(x) = f(y)\ \ \Longrightarrow\ \ x = y$$ Can anyone help?","I've been stuck on this one for a while, what I've basically tried is showing that: Can anyone help?", f(x) = f(y)\ \ \Longrightarrow\ \ x = y,"['functions', 'ceiling-and-floor-functions']"
61,"What is the max of $x+y+z$ where $(x,y,z)$ is a real solution of the system",What is the max of  where  is a real solution of the system,"x+y+z (x,y,z)","I am trying to calculate the maximum of $x +y +z$ and $(x_0 ,y_0,z_0)$ is a real solution of the system: $$2x=y+ \frac{2}{y}$$ $$2y=z+ \frac{2}{z}$$ $$2z=x+ \frac{2}{x}$$ I tried to sum them and got that $$x+y+z=2\left( \frac{1}{y} + \frac{1}{z} +\frac{1}{x} \right)$$ and with $$(x+y+z)\left(\frac{1}{y} + \frac{1}{z} +\frac{1}{x} \right) ≥9,$$ I got $$x+y+z≥3\sqrt{2}.$$ I am stuck here because they want the maximum of the sum. Any help will be appreciated.",I am trying to calculate the maximum of and is a real solution of the system: I tried to sum them and got that and with I got I am stuck here because they want the maximum of the sum. Any help will be appreciated.,"x +y +z (x_0 ,y_0,z_0) 2x=y+ \frac{2}{y} 2y=z+ \frac{2}{z} 2z=x+ \frac{2}{x} x+y+z=2\left( \frac{1}{y} + \frac{1}{z} +\frac{1}{x} \right) (x+y+z)\left(\frac{1}{y} + \frac{1}{z} +\frac{1}{x} \right) ≥9, x+y+z≥3\sqrt{2}.","['functions', 'systems-of-equations']"
62,How to deduce the monotonicity of a function from another function?,How to deduce the monotonicity of a function from another function?,,"I have the following task and I am a bit confused by the solution of it. In the official solution it's stated that only the first assumption is correct. But in my approach I am always coming to the end that the first and the third assumptions are correct. I would be happy if someone could verify if my solution is correct and there is a mistake in the solutions or to explain where I am thinking wrong. Task The function $f:\mathbb{R}\rightarrow\mathbb{R}\setminus\{0\}$ is a strict monotonic growing function. Let $g:\mathbb{R}\rightarrow\mathbb{R}$ , $g(x)=\frac{1}{f(x)}$ . Which of the following is correct? If $f$ doesn't take on positive function values, $g$ is strictly monotonically decreasing. If $f$ doesn't take on positive function values, $g$ is strictly monotonically increasing. If $f$ only takes on function values which are bigger than $-1$ , $g$ is strictly monotonically decreasing. If $f$ only takes on function values which are less than $1$ , $g$ is strictly monotonically increasing. My Solution First we check what happens when $f$ doesn't take on positive function values. That means that for every $x\in\mathbb{R}$ , $f(x)<0$ holds. We know that if we have $x,y\in\mathbb{R}$ with $x<y$ then $f(x)<f(y)$ . In this case the function $f$ looks like this $f:\mathbb{R}\rightarrow\mathbb(-\infty,0)$ . Where $(-\infty,0)$ is an interval. Then let $h$ be the following function $h:(-\infty,0)\rightarrow\mathbb{R}$ , $h(x)=\frac{1}{x}$ . We can see that $h$ is strictly monotonic decreasing. If we have $x,y\in(-\infty,0)$ with $x<y$ then we can see that $f(x)>f(y)$ holds. Now the following holds: $(h\circ f)(x)=h(f(x))=\frac{1}{f(x)}=g(x)$ . Because the function composition of one strictly monotonic increasing and one strictly decreasing function is strictly decreasing again, we can say that the first assumption is a correct one and the second one is wrong. From this reasoning we can also deduce that the fourth assumption is wrong. Now we are looking at the third assumption. Where we look at the case where $f(x)>0$ . Here our function $f$ looks like the following $f:\mathbb{R}\rightarrow(0,\infty)$ . Then we let $p$ be the following function $p:(0,\infty)\rightarrow\mathbb{R}$ , $p(x)=\frac{1}{x}$ . If we have $x,y\in(0,\infty)$ with $x<y$ we have $p(x)>p(y)$ and thus we have a monotonic decreasing function again. Now the following holds again $(p\circ f)(x)=p(f(x))=\frac{1}{f(x)}=g(x)$ . And because the function composition of one strictly monotonic increasing and one strictly decreasing function is strictly decreasing again. Thus the third assumption is correct as well. So where is my error, or is the solution incorrect?","I have the following task and I am a bit confused by the solution of it. In the official solution it's stated that only the first assumption is correct. But in my approach I am always coming to the end that the first and the third assumptions are correct. I would be happy if someone could verify if my solution is correct and there is a mistake in the solutions or to explain where I am thinking wrong. Task The function is a strict monotonic growing function. Let , . Which of the following is correct? If doesn't take on positive function values, is strictly monotonically decreasing. If doesn't take on positive function values, is strictly monotonically increasing. If only takes on function values which are bigger than , is strictly monotonically decreasing. If only takes on function values which are less than , is strictly monotonically increasing. My Solution First we check what happens when doesn't take on positive function values. That means that for every , holds. We know that if we have with then . In this case the function looks like this . Where is an interval. Then let be the following function , . We can see that is strictly monotonic decreasing. If we have with then we can see that holds. Now the following holds: . Because the function composition of one strictly monotonic increasing and one strictly decreasing function is strictly decreasing again, we can say that the first assumption is a correct one and the second one is wrong. From this reasoning we can also deduce that the fourth assumption is wrong. Now we are looking at the third assumption. Where we look at the case where . Here our function looks like the following . Then we let be the following function , . If we have with we have and thus we have a monotonic decreasing function again. Now the following holds again . And because the function composition of one strictly monotonic increasing and one strictly decreasing function is strictly decreasing again. Thus the third assumption is correct as well. So where is my error, or is the solution incorrect?","f:\mathbb{R}\rightarrow\mathbb{R}\setminus\{0\} g:\mathbb{R}\rightarrow\mathbb{R} g(x)=\frac{1}{f(x)} f g f g f -1 g f 1 g f x\in\mathbb{R} f(x)<0 x,y\in\mathbb{R} x<y f(x)<f(y) f f:\mathbb{R}\rightarrow\mathbb(-\infty,0) (-\infty,0) h h:(-\infty,0)\rightarrow\mathbb{R} h(x)=\frac{1}{x} h x,y\in(-\infty,0) x<y f(x)>f(y) (h\circ f)(x)=h(f(x))=\frac{1}{f(x)}=g(x) f(x)>0 f f:\mathbb{R}\rightarrow(0,\infty) p p:(0,\infty)\rightarrow\mathbb{R} p(x)=\frac{1}{x} x,y\in(0,\infty) x<y p(x)>p(y) (p\circ f)(x)=p(f(x))=\frac{1}{f(x)}=g(x)","['calculus', 'algebra-precalculus', 'functions', 'solution-verification']"
63,Calculator doesn't show the steps to finding the inverse of this function.,Calculator doesn't show the steps to finding the inverse of this function.,,"I was recently given the function $\sqrt{x}/(x-1)$ and was asked to evaluate $f^{-1}(1)$ find the inverse and draw the graph. Firstly, in order for a function to be invertible, it must be bijective, meaning it has a one-to-one mapping and its range is the same as its co-domain. So based on our definition, Should the inverse not be undefined as well at that point. When searching on a calculator, I either get the result $y=(1+2x^2\pm\sqrt{4x^2+1})/(2x^2)$ or an error telling me it is not possible Can someone please run me through on how one can achieve this inverse? My guess is that we must use the quadratic formula however I have already tried. The furthest I have gotten is $\sqrt{y}/(y-1) = x$ $y/(y-1)^2 = x^2$ $(y-1)^2/y = 1/x^2$ $(y^2-2y+1)/y = 1/x^2$ $y-2+1/y = 1/x^2$ $y+1/y = (1+2x^2)/x^2$ I can't seem to get any further than this for some reason. Also if someone could explain how our definition of an invertible function still holds this would be a literal contradiction of the properties of an invertible function. I can't seem to grasp why this is possible, unless my definition for an invertible function is wrong. Lastly I don't understand how $\pm$ is in the function, does this imply there is more than one output for each specific input, and if so I thought this was also contradictory to the definition of a function.","I was recently given the function and was asked to evaluate find the inverse and draw the graph. Firstly, in order for a function to be invertible, it must be bijective, meaning it has a one-to-one mapping and its range is the same as its co-domain. So based on our definition, Should the inverse not be undefined as well at that point. When searching on a calculator, I either get the result or an error telling me it is not possible Can someone please run me through on how one can achieve this inverse? My guess is that we must use the quadratic formula however I have already tried. The furthest I have gotten is I can't seem to get any further than this for some reason. Also if someone could explain how our definition of an invertible function still holds this would be a literal contradiction of the properties of an invertible function. I can't seem to grasp why this is possible, unless my definition for an invertible function is wrong. Lastly I don't understand how is in the function, does this imply there is more than one output for each specific input, and if so I thought this was also contradictory to the definition of a function.",\sqrt{x}/(x-1) f^{-1}(1) y=(1+2x^2\pm\sqrt{4x^2+1})/(2x^2) \sqrt{y}/(y-1) = x y/(y-1)^2 = x^2 (y-1)^2/y = 1/x^2 (y^2-2y+1)/y = 1/x^2 y-2+1/y = 1/x^2 y+1/y = (1+2x^2)/x^2 \pm,"['functions', 'inverse', 'inverse-function']"
64,"Let $f: A\rightarrow B, g: B\rightarrow C, and h: C\rightarrow D$. If $f$ and $g$ are both injective, then $g\circ f$ is injective.","Let . If  and  are both injective, then  is injective.","f: A\rightarrow B, g: B\rightarrow C, and h: C\rightarrow D f g g\circ f","Proof: Assume that $f$ and $g$ are injective. Let $a_1,a_2\in A$ and $b_1=f(a_1), b_2=f(a_2)$ . Suppose that $g(f(a_1))=g(f(a_2))\Rightarrow g(b_1)=g(b_2)\Rightarrow b_1=b_2$ ( $g$ is injective) $\Rightarrow f(a_1)=f(a_2)\Rightarrow a_1=a_2$ ( $f$ is injective). Therefore, $g\circ f$ is injective. $\blacksquare$","Proof: Assume that and are injective. Let and . Suppose that ( is injective) ( is injective). Therefore, is injective.","f g a_1,a_2\in A b_1=f(a_1), b_2=f(a_2) g(f(a_1))=g(f(a_2))\Rightarrow g(b_1)=g(b_2)\Rightarrow b_1=b_2 g \Rightarrow f(a_1)=f(a_2)\Rightarrow a_1=a_2 f g\circ f \blacksquare","['functions', 'solution-verification']"
65,Doubt about the power of $x$ of the function to find that $f(x) = 3$ is an even function,Doubt about the power of  of the function to find that  is an even function,x f(x) = 3,"Using the definition of even functions, $f(-x) = f(x) = 3$ , hence it is an even function. Also, it is being mentioned that if $f(x)$ is an even power of $x$ , then it is an even function of $x$ . Same for an odd function. We know that the equation of a horizontal line in slope-intercept form is $y = mx + b$ where $m$ is the slope and $b$ is the $y$ -intercept. That means, the equation of the horizontal line $y = 3$ can be written as, $y = 0x^1 + 3$ where $m = 0$ and b = 3 . Therefore, $y = f(x) = 0x^1 + 3 = 0x^1 + 3x^0$ Now, what is the power of the function above, $0$ or $1$ ? I want to apply the even power method to determine whether $f(x) = 3$ is an even function or let any function having multiple terms with $x^n$ to determine whether it is an even function (or an odd function let's say) just by using the power method.","Using the definition of even functions, , hence it is an even function. Also, it is being mentioned that if is an even power of , then it is an even function of . Same for an odd function. We know that the equation of a horizontal line in slope-intercept form is where is the slope and is the -intercept. That means, the equation of the horizontal line can be written as, where and b = 3 . Therefore, Now, what is the power of the function above, or ? I want to apply the even power method to determine whether is an even function or let any function having multiple terms with to determine whether it is an even function (or an odd function let's say) just by using the power method.",f(-x) = f(x) = 3 f(x) x x y = mx + b m b y y = 3 y = 0x^1 + 3 m = 0 y = f(x) = 0x^1 + 3 = 0x^1 + 3x^0 0 1 f(x) = 3 x^n,"['functions', 'even-and-odd-functions']"
66,Can $f([x])$ be continuous?,Can  be continuous?,f([x]),"There is a problem I encountered which has two functions $f(x)$ and $g(x)$ such that $g(f(x))=x$ and $f(\lfloor g(x) \rfloor)=x, \quad \forall x\geq 0$ . I am not giving any other details here, because what I want to know is how it is possible that $f(\lfloor x \rfloor)=x$ ? All I know by graphical transformation of $f(x)\to f(\lfloor x \rfloor)$ that the graph obtained is piecewise, not continuous. So how is this case possible? One situation I could think of is $f(x)=x, x \in \mathbf Z$ . But here, the domain is $\mathbf R$ . I would like to know other simple cases when it could be possible, so that it won't be hard for me to imagine such a function. Edit Here is the complete definition of function: $$f(x)=\begin{cases} \sqrt{1-x^2},& -1\leq x < 0\\ x^2+1,& 0\leq x < 1\\ \frac{(x-1)^2)}{4} +2, & x\geq 1 \end{cases} $$ $g(x)$ is defined such that $g(f(x))=x, x \geq -1$ and $f(\lfloor(g(x)\rfloor)= x, x\geq0$","There is a problem I encountered which has two functions and such that and . I am not giving any other details here, because what I want to know is how it is possible that ? All I know by graphical transformation of that the graph obtained is piecewise, not continuous. So how is this case possible? One situation I could think of is . But here, the domain is . I would like to know other simple cases when it could be possible, so that it won't be hard for me to imagine such a function. Edit Here is the complete definition of function: is defined such that and","f(x) g(x) g(f(x))=x f(\lfloor g(x) \rfloor)=x, \quad \forall x\geq 0 f(\lfloor x \rfloor)=x f(x)\to f(\lfloor x \rfloor) f(x)=x, x \in \mathbf Z \mathbf R f(x)=\begin{cases}
\sqrt{1-x^2},& -1\leq x < 0\\
x^2+1,& 0\leq x < 1\\
\frac{(x-1)^2)}{4} +2, & x\geq 1
\end{cases}
 g(x) g(f(x))=x, x \geq -1 f(\lfloor(g(x)\rfloor)= x, x\geq0","['functions', 'graphing-functions', 'ceiling-and-floor-functions']"
67,Showing $\log(f(z))-\log(z^n)$ is single-valued holomorphic.,Showing  is single-valued holomorphic.,\log(f(z))-\log(z^n),"For context, I am currently working through ""Dynamics in One Complex Variable"" by John Milnor, specifically, Lemma A.2 in Appendix A. The problem I'm facing is as follows: Let $f:\mathbb{D} \rightarrow \mathbb{C}$ be a holomorphic function that contains no zeros in the annulus region $\{z : r_0 < \vert z \vert < r_1 \}$ . Let $n$ denote the number of zeros in the disk $\mathbb{D}_r$ where $r<1$ . I want to show that if $r_0 < r < r_1$ , then we have that $\log(f(z)) - \log(z^n)$ is single valued and holomorphic on this annulus. I believe the idea would be to Taylor expand $f(z)$ and combine the logarithms somehow so that the imaginary part cancels out somehow.. but I can't seem to get it to work. Any help would be greatly appreciated.","For context, I am currently working through ""Dynamics in One Complex Variable"" by John Milnor, specifically, Lemma A.2 in Appendix A. The problem I'm facing is as follows: Let be a holomorphic function that contains no zeros in the annulus region . Let denote the number of zeros in the disk where . I want to show that if , then we have that is single valued and holomorphic on this annulus. I believe the idea would be to Taylor expand and combine the logarithms somehow so that the imaginary part cancels out somehow.. but I can't seem to get it to work. Any help would be greatly appreciated.",f:\mathbb{D} \rightarrow \mathbb{C} \{z : r_0 < \vert z \vert < r_1 \} n \mathbb{D}_r r<1 r_0 < r < r_1 \log(f(z)) - \log(z^n) f(z),"['complex-analysis', 'functions', 'complex-numbers']"
68,The range of a constraint for function to be surjective,The range of a constraint for function to be surjective,,"Consider the following function $f(x)=\dfrac{x^2+2x+a}{x^2+4x+3a}$ Now the question states for us to find the constraint that limits $a$ so that $f(x)$ becomes surjective. My Attempt This can be further written as $f(x)=\dfrac{(x+1)^2+a-1}{(x+2)^2+3a-4}$ Now to make the function surjective, we can ensure two cases:- CASE 1 The function on the top can have some $y$ $\in$ $\mathbb{Q}^{-}$ and for this $a-1<0$ and the function at bottom  can have some $y$ $\in$ $\mathbb{Q}^{+}$ and for this $3a-4>0$ . But there is no solution. CASE  2 The function on the top can have some $y$ $\in$ $\mathbb{Q}^{+}$ and for this $a-1>0$ and the function at bottom  can have some $y$ $\in$ $\mathbb{Q}^{-}$ and for this $3a-4<0$ . So $a\in(1,4/3)$ But this ans is wrong could someone point the mistake.","Consider the following function Now the question states for us to find the constraint that limits so that becomes surjective. My Attempt This can be further written as Now to make the function surjective, we can ensure two cases:- CASE 1 The function on the top can have some and for this and the function at bottom  can have some and for this . But there is no solution. CASE  2 The function on the top can have some and for this and the function at bottom  can have some and for this . So But this ans is wrong could someone point the mistake.","f(x)=\dfrac{x^2+2x+a}{x^2+4x+3a} a f(x) f(x)=\dfrac{(x+1)^2+a-1}{(x+2)^2+3a-4} y \in \mathbb{Q}^{-} a-1<0 y \in \mathbb{Q}^{+} 3a-4>0 y \in \mathbb{Q}^{+} a-1>0 y \in \mathbb{Q}^{-} 3a-4<0 a\in(1,4/3)",['functions']
69,"Let $T: \mathbb{Z}\rightarrow\{0\}\cup X, X$ is a finite set. Only a finite number of integers are not sent to $0$. The set of all $T$ is countable?",Let  is a finite set. Only a finite number of integers are not sent to . The set of all  is countable?,"T: \mathbb{Z}\rightarrow\{0\}\cup X, X 0 T","My tentative: For some $T$ , let $S$ be the finite set of numbers that are not sent to $0$ . Then we can write $T$ as: $$ T(x)=\begin{cases} T(x), & \text{ if } x \in S \newline 0,& \text{ otherwise}   \end{cases}$$ So counting the $T$ functions is the same that counting the $T_S$ functions ( $T$ restricted to $S$ ) for all $S$ Then exists a finite number of $T_S:S\rightarrow X$ for a fixed $S$ Since $S$ is a finite subset of $\mathbb{Z}$ , the set of all possible $S$ is countable. Then total number of $T$ is a series with infinite countable finite terms, so the number of $T$ is countable. Is this correct?","My tentative: For some , let be the finite set of numbers that are not sent to . Then we can write as: So counting the functions is the same that counting the functions ( restricted to ) for all Then exists a finite number of for a fixed Since is a finite subset of , the set of all possible is countable. Then total number of is a series with infinite countable finite terms, so the number of is countable. Is this correct?","T S 0 T  T(x)=\begin{cases}
T(x), & \text{ if } x \in S \newline
0,& \text{ otherwise}  
\end{cases} T T_S T S S T_S:S\rightarrow X S S \mathbb{Z} S T T","['analysis', 'functions', 'elementary-set-theory']"
70,Approximation of $ \frac{1 - a x^2} {1 - b x^2} $ for small $x$,Approximation of  for small, \frac{1 - a x^2} {1 - b x^2}  x,"I am working with the following function: $$\frac{1 - a x^2} {1 - b x^2} $$ I am studying it for small values of $x$ , which are between $0$ and $0.25$ and $b$ sligtly smaller (or slightly larger) than $a$ . Plotting this function, I see clearly that it can be approximated by a quadratic form that is dependent on $a - b$ . Is there a known approximation for such a function?","I am working with the following function: I am studying it for small values of , which are between and and sligtly smaller (or slightly larger) than . Plotting this function, I see clearly that it can be approximated by a quadratic form that is dependent on . Is there a known approximation for such a function?",\frac{1 - a x^2} {1 - b x^2}  x 0 0.25 b a a - b,"['functions', 'polynomials', 'taylor-expansion', 'approximation']"
71,"Given $f(x_1,x_2,x_3,...,x_n)=0$, does a $g$ exist such that $g(x_1,x_2,x_3,...,x_{n-1})=x_n$?","Given , does a  exist such that ?","f(x_1,x_2,x_3,...,x_n)=0 g g(x_1,x_2,x_3,...,x_{n-1})=x_n","Given $f(x_1,x_2,x_3,...,x_n)=0$ , is it true that there exists a function $g$ such that $g(x_1,x_2,x_3,...,x_{n-1})=x_n$ ? If so, how could I go about proving it for the general case? If not, what would be the broadest additional given that would make it true, i.e. the definition which would be true for the largest set of possible functions. For example, If I changed the statement to ""given a linear function $f(x_1,x_2,x_3,...,x_n)=0$ "" it is fairly straightforward to show that there exists a function $g$ such that $g(x_1,x_2,x_3,...,x_{n-1})=x_n$ , but restricting the given function to only linear functions would be a pretty exclusive given.","Given , is it true that there exists a function such that ? If so, how could I go about proving it for the general case? If not, what would be the broadest additional given that would make it true, i.e. the definition which would be true for the largest set of possible functions. For example, If I changed the statement to ""given a linear function "" it is fairly straightforward to show that there exists a function such that , but restricting the given function to only linear functions would be a pretty exclusive given.","f(x_1,x_2,x_3,...,x_n)=0 g g(x_1,x_2,x_3,...,x_{n-1})=x_n f(x_1,x_2,x_3,...,x_n)=0 g g(x_1,x_2,x_3,...,x_{n-1})=x_n","['real-analysis', 'analysis', 'functions', 'proof-writing', 'proof-explanation']"
72,Prove that $x^3$ is strictly increasing on the real numbers using inequality properties,Prove that  is strictly increasing on the real numbers using inequality properties,x^3,"I'm attempting to prove that $x^3$ is strictly increasing on $\mathbb{R}$ , but I'm encountering two issues. Firstly, I'm uncertain about the precise definition of a strictly increasing function. Definition: $f$ is said to be a strictly function on the interval $I$ if, and only if, $$\forall x_1,x_2\in I, x_1<x_2\rightarrow f(x_1)<f(x_2).$$ What is the specific form of argument used in this definition? Why? (I think b is correct) a. $p \wedge (q\rightarrow r)$ b. $(p \wedge q)\rightarrow r$ The second issue I face is determining how to prove the following statement using properties of inequalities. $$\forall a,b\in\mathbb{R},a>b\rightarrow a^3>b^3$$","I'm attempting to prove that is strictly increasing on , but I'm encountering two issues. Firstly, I'm uncertain about the precise definition of a strictly increasing function. Definition: is said to be a strictly function on the interval if, and only if, What is the specific form of argument used in this definition? Why? (I think b is correct) a. b. The second issue I face is determining how to prove the following statement using properties of inequalities.","x^3 \mathbb{R} f I \forall x_1,x_2\in I, x_1<x_2\rightarrow f(x_1)<f(x_2). p \wedge (q\rightarrow r) (p \wedge q)\rightarrow r \forall a,b\in\mathbb{R},a>b\rightarrow a^3>b^3","['functions', 'proof-explanation']"
73,"Prove: if $x^2 + y^2 < \frac{1}{2}$, then $\cos(x+y) > 0$","Prove: if , then",x^2 + y^2 < \frac{1}{2} \cos(x+y) > 0,"For an exercise about finding the minimum of a function I have to prove that $cos(x+y) > 0$ for $x^2 + y^2 < \frac{1}{2}$ . Which means that $-\frac{\pi}{2}< x + y < \frac{\pi}{2}$ . However, I am struggling with drawing any conclusions about $x + y$ from the expression with the squares. Does anyone have tips for that? only thing I have so far, is this: $-\frac{\pi}{2} < -\frac{1}{\sqrt{2}} < -\sqrt{x^2 + y^2} \leq \sqrt{x^2 + y^2} < \frac{1}{\sqrt{2}} < \frac{\pi}{2}$","For an exercise about finding the minimum of a function I have to prove that for . Which means that . However, I am struggling with drawing any conclusions about from the expression with the squares. Does anyone have tips for that? only thing I have so far, is this:",cos(x+y) > 0 x^2 + y^2 < \frac{1}{2} -\frac{\pi}{2}< x + y < \frac{\pi}{2} x + y -\frac{\pi}{2} < -\frac{1}{\sqrt{2}} < -\sqrt{x^2 + y^2} \leq \sqrt{x^2 + y^2} < \frac{1}{\sqrt{2}} < \frac{\pi}{2},"['analysis', 'functions', 'trigonometry', 'polar-coordinates', 'extreme-value-analysis']"
74,Why viewing sequences as functions allows to find the equivalent?,Why viewing sequences as functions allows to find the equivalent?,,"I want to know why this method works so well to find an equivalent of a sequence. The idea of this method is to consider the sequence like a function that can be derived. Here are a few examples : Let $u_0>0$ and $u_{n+1}:=\ln(1+u_n)$ : we have $(u_n)_n$ decreasing and positive $(0\le\ln(1+u_n)\le u_n)$ , so it converges to $0$ . Now, let's consider this way of thinking : $u'(n) \approx u(n+1) - u(n) =  \ln(1+u(n))-u(n) \approx -2^{-1}u^2(n)$ when $n$ approaches $+\infty$ . We get : $(u(n)^{-1})' \approx 2^{-1}$ . Using this information, let us look : $ (u(n)^{-1})' \approx u_{n+1}^{-1}-u_n^{-1}=\ln(1+u_n)^{-1}-u_n^{-1} = (u_n -2^{-1}u_n^2+o(u_n^2))^{-1}-u_n^{-1}$ So $u_{n+1}^{-1}-u_n^{-1} = u_n^{-1}(1+2^{-1}u_n+o(u_n))-u_n$ . We get by a telescoping sum: $u_n^{-1}\sim n/2$ and finally we have : $u_n\sim 2/n$ . Let $u_0>0$ and $u_{n+1}:=u_n+u_n^{-1}$ : We can show that it goes to $+\infty$ . We have : $u'(n)\approx u(n+1)-u(n) = u(n)^{-1}$ . We get : $(u(n)^2)'=2^{-1}$ . Now, let us look : $(u(n)^2)'\approx u_{n+1}^2-u_n^2=u_n^2(1+u_n^{-2})^2-u_n^2= u_n^2(1+2u_n^{-2}+o(u_n^{-2}))-u_n^2 \sim 2$ . We get : $u_n^{2}\sim 2n$ and finally we have : $u_n\sim \sqrt{2n}$ . Let $u_n >0$ and $\forall n\ge1, u_{n+1}:=u_n + (nu_n)^{-1}$ : We can show that it goes to $l$ where $l\in\mathbb R_*^+\cup\{+\infty\}$ . We have : $u'(n)\approx u(n+1)-u(n) = (nu(n))^{-1}$ . We get : $(u(n)^2)'=2n^{-1}$ . Now, let us look : $(u(n)^2)' \approx u_{n+1}^2-u_n^2=u_n^2(1+(\sqrt{n}u_n)^{-2})^2-u_n^2$ So $u_{n+1}^2-u_n^2 = u_n^2(1+2(\sqrt{n}u_n)^{-2}+o(\sqrt{n}u_n)^{-2})-u_n^2 \sim 2n^{-1}$ . We get : $u_n^{2}\sim 2\ln(n)$ and finally we have : $u_n\sim \sqrt{2\ln(n)}$ . Let $(u_n)_n\in \mathbb R^\mathbb {N_*}$ and $S_n:=\sum_{i=1}^n u_i^2$ such that $u_nS_n\to 1$ when $n$ goes to $\infty$ . We can show that $u_n\to0$ and $S_n\to+\infty$ . We have : $S'(n)\approx S(n+1)-S(n) = u(n+1)^2\approx (S(n+1))^{-2} \approx (S(n))^{-2}$ . We get : $(S(n)^3)'=3$ . Then : $(S(n)^3)'\approx S_{n+1}^3-S_n^3 = (S_{n+1}-S_n)(S_{n+1}^2+S_nS_{n+1}+S_n^2)$ . However : $S_{n+1}-S_n = u_{n+1}^2 \sim (S_n)^{-2}$ . So : $S_{n+1}^3-S_n^3 \sim (S_n)^{-2}(S_{n+1}^2+S_nS_{n+1}+S_n^2)\sim 1+(S_{n+1}/S_n)+(S_{n+1}/S_n)^2 \sim 3.$ Finally, we get : $S_n\sim (3n)^{1/3}$ . So : $a_n \sim S_n^{-1} \sim (3n)^{-1/3}$ In these examples, considering the sequence as a function derived allows us to determine a equivalent. Why does it work so well ?","I want to know why this method works so well to find an equivalent of a sequence. The idea of this method is to consider the sequence like a function that can be derived. Here are a few examples : Let and : we have decreasing and positive , so it converges to . Now, let's consider this way of thinking : when approaches . We get : . Using this information, let us look : So . We get by a telescoping sum: and finally we have : . Let and : We can show that it goes to . We have : . We get : . Now, let us look : . We get : and finally we have : . Let and : We can show that it goes to where . We have : . We get : . Now, let us look : So . We get : and finally we have : . Let and such that when goes to . We can show that and . We have : . We get : . Then : . However : . So : Finally, we get : . So : In these examples, considering the sequence as a function derived allows us to determine a equivalent. Why does it work so well ?","u_0>0 u_{n+1}:=\ln(1+u_n) (u_n)_n (0\le\ln(1+u_n)\le u_n) 0 u'(n) \approx u(n+1) - u(n) =  \ln(1+u(n))-u(n) \approx -2^{-1}u^2(n) n +\infty (u(n)^{-1})' \approx 2^{-1}  (u(n)^{-1})' \approx u_{n+1}^{-1}-u_n^{-1}=\ln(1+u_n)^{-1}-u_n^{-1} = (u_n -2^{-1}u_n^2+o(u_n^2))^{-1}-u_n^{-1} u_{n+1}^{-1}-u_n^{-1} = u_n^{-1}(1+2^{-1}u_n+o(u_n))-u_n u_n^{-1}\sim n/2 u_n\sim 2/n u_0>0 u_{n+1}:=u_n+u_n^{-1} +\infty u'(n)\approx u(n+1)-u(n) = u(n)^{-1} (u(n)^2)'=2^{-1} (u(n)^2)'\approx u_{n+1}^2-u_n^2=u_n^2(1+u_n^{-2})^2-u_n^2= u_n^2(1+2u_n^{-2}+o(u_n^{-2}))-u_n^2 \sim 2 u_n^{2}\sim 2n u_n\sim \sqrt{2n} u_n >0 \forall n\ge1, u_{n+1}:=u_n + (nu_n)^{-1} l l\in\mathbb R_*^+\cup\{+\infty\} u'(n)\approx u(n+1)-u(n) = (nu(n))^{-1} (u(n)^2)'=2n^{-1} (u(n)^2)' \approx u_{n+1}^2-u_n^2=u_n^2(1+(\sqrt{n}u_n)^{-2})^2-u_n^2 u_{n+1}^2-u_n^2 = u_n^2(1+2(\sqrt{n}u_n)^{-2}+o(\sqrt{n}u_n)^{-2})-u_n^2 \sim 2n^{-1} u_n^{2}\sim 2\ln(n) u_n\sim \sqrt{2\ln(n)} (u_n)_n\in \mathbb R^\mathbb {N_*} S_n:=\sum_{i=1}^n u_i^2 u_nS_n\to 1 n \infty u_n\to0 S_n\to+\infty S'(n)\approx S(n+1)-S(n) = u(n+1)^2\approx (S(n+1))^{-2} \approx (S(n))^{-2} (S(n)^3)'=3 (S(n)^3)'\approx S_{n+1}^3-S_n^3 = (S_{n+1}-S_n)(S_{n+1}^2+S_nS_{n+1}+S_n^2) S_{n+1}-S_n = u_{n+1}^2 \sim (S_n)^{-2} S_{n+1}^3-S_n^3 \sim (S_n)^{-2}(S_{n+1}^2+S_nS_{n+1}+S_n^2)\sim 1+(S_{n+1}/S_n)+(S_{n+1}/S_n)^2 \sim 3. S_n\sim (3n)^{1/3} a_n \sim S_n^{-1} \sim (3n)^{-1/3}","['sequences-and-series', 'limits', 'functions']"
75,"I'm searching for a monotonically increasing function, defined for all reals, that is concave down and a ""gentle curve"" (no aymptotes).","I'm searching for a monotonically increasing function, defined for all reals, that is concave down and a ""gentle curve"" (no aymptotes).",,"I'm searching for a monotonically increasing function, defined for all reals, that is concave down and a ""gentle curve"" (no aymptotes). The link below provides an image: example of gentle concave down curve This post has some examples of near misses: Is there a bijective, monotonically increasing, strictly concave function from the reals, to the reals? For instance: y = -e^(-x) However, this is not by any means a gentle curve, outside of the domain (-3,3). The rest of the graph looks essentially like a right angle.","I'm searching for a monotonically increasing function, defined for all reals, that is concave down and a ""gentle curve"" (no aymptotes). The link below provides an image: example of gentle concave down curve This post has some examples of near misses: Is there a bijective, monotonically increasing, strictly concave function from the reals, to the reals? For instance: y = -e^(-x) However, this is not by any means a gentle curve, outside of the domain (-3,3). The rest of the graph looks essentially like a right angle.",,['functions']
76,"When raising a bracket (of a function like $\ln$) to a power, is the power applied before the ln operation?","When raising a bracket (of a function like ) to a power, is the power applied before the ln operation?",\ln,I've seen sources that apply the $\ln$ function before the power in $\ln(x-1)^2$ for example and others where it is applied after the power. Which is correct?,I've seen sources that apply the function before the power in for example and others where it is applied after the power. Which is correct?,\ln \ln(x-1)^2,['functions']
77,"Rewriting $||x-y|-z|$, for non-negative $x$, $y$, $z$, in a way that does not involve nested absolutes","Rewriting , for non-negative , , , in a way that does not involve nested absolutes",||x-y|-z| x y z,"Is there an idea that resolves nested value expressions into several separate expressions each using a single absolute value? Something similar like resolving the max function using the absolute value. More concretely, I am looking for a way to rewrite the expression $$||x-y|-z|$$ in a way that does not use expressions of nested absolutes. I already did a case study, and this is what I've got so far For $x<y$ and $(y-x) < z$ , we have: $||x-y|-z| = x - y + z$ For $x<y$ and $(y-x) > z$ , we have: $||x-y|-z| = -x + y - z$ For $x>y$ and $(x-y) < z$ , we have: $||x-y|-z| = -x + y + z$ For $x>y$ and $(x-y) > z$ , we have: $||x-y|-z| = x - y - z$ But I can't seem to find a pattern to rewrite it. If it helps, we can assume that all variables $x$ , $y$ and $z$ are non-negative.","Is there an idea that resolves nested value expressions into several separate expressions each using a single absolute value? Something similar like resolving the max function using the absolute value. More concretely, I am looking for a way to rewrite the expression in a way that does not use expressions of nested absolutes. I already did a case study, and this is what I've got so far For and , we have: For and , we have: For and , we have: For and , we have: But I can't seem to find a pattern to rewrite it. If it helps, we can assume that all variables , and are non-negative.",||x-y|-z| x<y (y-x) < z ||x-y|-z| = x - y + z x<y (y-x) > z ||x-y|-z| = -x + y - z x>y (x-y) < z ||x-y|-z| = -x + y + z x>y (x-y) > z ||x-y|-z| = x - y - z x y z,"['algebra-precalculus', 'functions', 'absolute-value', 'nonnegative-matrices', 'algebraic-equations']"
78,Looking for prototype for ease-in function,Looking for prototype for ease-in function,,"I'm looking for some kind of ease-in function. Within the range of $0 < x < 1$ , $0 < y < 1$ and depending on a parameter $0 < g < 1$ it should have the following properties: $$ f(0) = 0, f(1) = 1, f'(0) = 0, f'(1) = \infty $$ $$ f(x, g = 0) = x, f(x, g = 1) = 0$$ $$ f\left(\frac{1}{2} + g\right) = \frac12 - g, f'\left(\frac{1}{2} + g\right) = 1$$ So basically it is symmetric about y = 1 - x and crosses that line perpendicularly. I tried to stitch it together from two 3rd degree polynomials, which almos does the job, but not exactly. Graph Biggest issue is that it becomes negative as the parameter gets larger. I'm not quite sure what to look for, so any help would be appreciated!","I'm looking for some kind of ease-in function. Within the range of , and depending on a parameter it should have the following properties: So basically it is symmetric about y = 1 - x and crosses that line perpendicularly. I tried to stitch it together from two 3rd degree polynomials, which almos does the job, but not exactly. Graph Biggest issue is that it becomes negative as the parameter gets larger. I'm not quite sure what to look for, so any help would be appreciated!","0 < x < 1 0 < y < 1 0 < g < 1  f(0) = 0, f(1) = 1, f'(0) = 0, f'(1) = \infty   f(x, g = 0) = x, f(x, g = 1) = 0  f\left(\frac{1}{2} + g\right) = \frac12 - g, f'\left(\frac{1}{2} + g\right) = 1","['functions', 'graphing-functions']"
79,Will this function always have a fixed point?,Will this function always have a fixed point?,,"$f:[0,\infty) \to [0,\infty)$ where $|f(x)-f(y)| \le \frac{1}{2}|x-y|$ Does this function always have a fixed point? My attempt: The function is continuous. If it becomes differentiable then it will have a fixed point. So I was looking for some non differentiable continuous function which doesn't have a fixed point. What I could think of is example of the form $|x-a|/2$ but I am unable to construct one. Some hints please.",where Does this function always have a fixed point? My attempt: The function is continuous. If it becomes differentiable then it will have a fixed point. So I was looking for some non differentiable continuous function which doesn't have a fixed point. What I could think of is example of the form but I am unable to construct one. Some hints please.,"f:[0,\infty) \to [0,\infty) |f(x)-f(y)| \le \frac{1}{2}|x-y| |x-a|/2","['real-analysis', 'functions', 'fixed-point-theorems']"
80,Does finding slope of the tangent line to $y=x^2 +2x$ constitute division by zero when differentiating from first principles?,Does finding slope of the tangent line to  constitute division by zero when differentiating from first principles?,y=x^2 +2x,"When we consider a limit as $h \rightarrow 0$ when finding the slope of the tangent to a function at a particular point, we sometimes find ourselves in a form where the function may lead to a division by $0$ error. However, since this is a limit, I'm unsure whether or not this actually does lead to this particular problem. To illustrate the above problem, let's say that one wishes to find the slope of the tangent line at the point $(-1,-1)$ in the function $y=x^2 +2x$ We are told that $y=x^2 +2x$ and so we look for the slope at $(-1,-1)$ . We consider $f(-1+h)=(-1+h)^2+2(-1+h)=h^2 -1$ where $h \rightarrow 0$ ; so the closest point is $((-1+h),(h^2-1))$ . Finding the slope, we have $\frac{h^{2}-1-(-1)}{h-1-(-1)}=\frac{h^2}{h}=h$ . When $h$ approches $0$ , the slope is $0$ . I am wondering if when $h^2/h$ is simplified to $h$ , this would preclude us from taking the limit as $h$ approaches zero, as the expression has been divided by $h$ at one point. To take the limit when $h$ approaches zero, we plug in zero for $h$ - doesn't this constitute a zero division error? Thanks for any clarification.","When we consider a limit as when finding the slope of the tangent to a function at a particular point, we sometimes find ourselves in a form where the function may lead to a division by error. However, since this is a limit, I'm unsure whether or not this actually does lead to this particular problem. To illustrate the above problem, let's say that one wishes to find the slope of the tangent line at the point in the function We are told that and so we look for the slope at . We consider where ; so the closest point is . Finding the slope, we have . When approches , the slope is . I am wondering if when is simplified to , this would preclude us from taking the limit as approaches zero, as the expression has been divided by at one point. To take the limit when approaches zero, we plug in zero for - doesn't this constitute a zero division error? Thanks for any clarification.","h \rightarrow 0 0 (-1,-1) y=x^2 +2x y=x^2 +2x (-1,-1) f(-1+h)=(-1+h)^2+2(-1+h)=h^2 -1 h \rightarrow 0 ((-1+h),(h^2-1)) \frac{h^{2}-1-(-1)}{h-1-(-1)}=\frac{h^2}{h}=h h 0 0 h^2/h h h h h h","['calculus', 'limits', 'functions', 'derivatives', 'tangent-line']"
81,onto functions disproving method,onto functions disproving method,,"Let $f: \mathbb R^* \to \mathbb R$ with $f(x) = \frac{x+1}x,$ where $\mathbb R^*$ is the set of all real numbers different from zero. Determine whether or not $f$ is an onto function. I know that this is not onto. But how do I go about disproving it in a formal way. I know the range does not contain the element $1$ whilst the codomain does. And since the codomain is not equal to the range the function is not onto. But like I said how do I formally disprove it??",Let with where is the set of all real numbers different from zero. Determine whether or not is an onto function. I know that this is not onto. But how do I go about disproving it in a formal way. I know the range does not contain the element whilst the codomain does. And since the codomain is not equal to the range the function is not onto. But like I said how do I formally disprove it??,"f: \mathbb R^* \to \mathbb R f(x) = \frac{x+1}x, \mathbb R^* f 1",['functions']
82,Solving $x=\frac{2^{1+y}}{\left(y+1\right)\left(y+2\right)}$ for $y$,Solving  for,x=\frac{2^{1+y}}{\left(y+1\right)\left(y+2\right)} y,Do you know how to solve the following equation to make $y$ the subject: $$x=\frac{2^{1+y}}{\left(y+1\right)\left(y+2\right)}$$ My attempts: I multiplied both sides by $\ln(2)(y+1)^2$ to get $$x\ln\left(2\right)\left(y+1\right)^{2}\left(y+2\right)=\ln\left(2\right)\left(y+1\right)e^{\ln\left(2\right)\left(y+1\right)}$$ The reasoning behind this was to get an expression of the form $xe^x$ to use the Lambert W function. However I was unable to make it work. I also tried considering the more general function $$x=\frac{z^{1+y}}{\left(y+1\right)\left(y+2\right)}$$ Differentiating both sides with respect to z cancels the $(y+1)$ term in the denominator which I thought could make it easier to work with. However again I was unable to find a solution. Any help is appreciated. Thanks,Do you know how to solve the following equation to make the subject: My attempts: I multiplied both sides by to get The reasoning behind this was to get an expression of the form to use the Lambert W function. However I was unable to make it work. I also tried considering the more general function Differentiating both sides with respect to z cancels the term in the denominator which I thought could make it easier to work with. However again I was unable to find a solution. Any help is appreciated. Thanks,y x=\frac{2^{1+y}}{\left(y+1\right)\left(y+2\right)} \ln(2)(y+1)^2 x\ln\left(2\right)\left(y+1\right)^{2}\left(y+2\right)=\ln\left(2\right)\left(y+1\right)e^{\ln\left(2\right)\left(y+1\right)} xe^x x=\frac{z^{1+y}}{\left(y+1\right)\left(y+2\right)} (y+1),['functions']
83,How to linearize a base-10 exponential function,How to linearize a base-10 exponential function,,"I have a base-10 exponential function with the equation: $$y = 0.000346 \cdot 10^{0.00676x} + 0.148$$ I am trying to linearize this equation but unable to do so. I tried taking $\log(y)$ in the $y$ -axis and $\log(x)$ in the $x$ -axis but I am never getting a straight line. In fact, taking $\log(y)$ gives me negative $y$ -values. Any help would be appreciated. I have attached an imgur link to my graph below since I am unable to embed it here. Thank you so much.","I have a base-10 exponential function with the equation: I am trying to linearize this equation but unable to do so. I tried taking in the -axis and in the -axis but I am never getting a straight line. In fact, taking gives me negative -values. Any help would be appreciated. I have attached an imgur link to my graph below since I am unable to embed it here. Thank you so much.",y = 0.000346 \cdot 10^{0.00676x} + 0.148 \log(y) y \log(x) x \log(y) y,"['functions', 'logarithms', 'exponential-function', 'graphing-functions', 'linearization']"
84,"Formula for the $n$-th term of the sequence $1, 2, 4, 6, 12, 16, 24, 30, 60, 72, 96, 112, \ldots$, where $f_n := \frac{1}{n} (f_{2n} - f_n)$","Formula for the -th term of the sequence , where","n 1, 2, 4, 6, 12, 16, 24, 30, 60, 72, 96, 112, \ldots f_n := \frac{1}{n} (f_{2n} - f_n)","I'm struggling with this sequence. $$1, 2, 4, 6, 12, 16, 24, 30, 60, 72, 96, 112, \ldots$$ Where, $f_n := \frac{1}{n} (f_{2n} - f_n)$ You can also work it out for negative powers of 2, $$f_\frac{1}{2} = \frac{2}{3}$$ $$f_\frac{1}{4} = \frac{8}{15}$$ $$f_{2^{-n}} = \prod_{k=1}^{n} (\frac{2^k}{2^k +1})$$ I wanted to know if it possible to find a formula for $f_n$ , and to generalize it to all real numbers? Can generating functions help here? (I don't know much about them.) (And sorry if I had made some mistake)","I'm struggling with this sequence. Where, You can also work it out for negative powers of 2, I wanted to know if it possible to find a formula for , and to generalize it to all real numbers? Can generating functions help here? (I don't know much about them.) (And sorry if I had made some mistake)","1, 2, 4, 6, 12, 16, 24, 30, 60, 72, 96, 112, \ldots f_n := \frac{1}{n} (f_{2n} - f_n) f_\frac{1}{2} = \frac{2}{3} f_\frac{1}{4} = \frac{8}{15} f_{2^{-n}} = \prod_{k=1}^{n} (\frac{2^k}{2^k +1}) f_n","['sequences-and-series', 'functions', 'real-numbers', 'generating-functions']"
85,"Most efficient way to find the ""solution intervals"" / ""case conditions""? (problem regarding a function with absolute value notation):","Most efficient way to find the ""solution intervals"" / ""case conditions""? (problem regarding a function with absolute value notation):",,"I am trying to write the function $f(x) = |x^2-1|+|x|-1$ without the notation for the absolute value. ""||"" It makes logical sense to consider four cases, because each term in the absolute value notation can either be positive or negative. Therefore, we get: Case 1 (positive, positive): $f(x) = x^2-1+x-1 = (x-1)(x+2)$ Case 2 (positive, negative): $f(x) = x^2-1-x-1 = (x+1)(x-2)$ Case 3 (negative, positive): $f(x) = -x^2+1+x-1 = -x(x-1)$ Case 4 (negative, negative): $f(x) = -x^2+1-x-1 = -x(x+1)$ To use the piecewise function notation, I need the intervals for which each term is correct. $$   f(x) = \cases{        term       & $condition\ $ \cr                  term       & $condition\ $ \cr                         term       & $condition\ $ \cr term       & $condition\ $ \cr} $$ What is the most efficient way to find the case conditions (in this particular example, and generally speaking)? (I have tried putting the term of each case equal to zero to find the roots. However, doing this, I get $5$ roots. Our expression is of order $3$ , therefore something has to be wrong/I overlooked something while trying this.) I am thankful for any input/ideas! Thank you!","I am trying to write the function without the notation for the absolute value. ""||"" It makes logical sense to consider four cases, because each term in the absolute value notation can either be positive or negative. Therefore, we get: Case 1 (positive, positive): Case 2 (positive, negative): Case 3 (negative, positive): Case 4 (negative, negative): To use the piecewise function notation, I need the intervals for which each term is correct. What is the most efficient way to find the case conditions (in this particular example, and generally speaking)? (I have tried putting the term of each case equal to zero to find the roots. However, doing this, I get roots. Our expression is of order , therefore something has to be wrong/I overlooked something while trying this.) I am thankful for any input/ideas! Thank you!","f(x) = |x^2-1|+|x|-1 f(x) = x^2-1+x-1 = (x-1)(x+2) f(x) = x^2-1-x-1 = (x+1)(x-2) f(x) = -x^2+1+x-1 = -x(x-1) f(x) = -x^2+1-x-1 = -x(x+1) 
  f(x) = \cases{        term       & condition\  \cr
                 term       & condition\  \cr
                        term       & condition\  \cr
term       & condition\  \cr}
 5 3","['calculus', 'algebra-precalculus', 'functions', 'absolute-value', 'piecewise-continuity']"
86,How do I find the inverse of $y=2x^2+2x+2$ [closed],How do I find the inverse of  [closed],y=2x^2+2x+2,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I'm supposed to find the inverse of $$y=2x^2+2x+2 $$ I know that the inverse isn't a function, as it isn't injective, but we're supposed to find it in domain $[0, 1]$ . So far, I've switched x for y, and tried to solve for y, and gotten so far: $$ x=2y^2+2y+2$$ $$ 2y^2 + 2y = x-2$$ $$ y(y+1)=1/2 (x-2)$$ WolframAlpha tells me the inverse is supposed to be $$ y= 1/2 (\pm\sqrt{2x-3}-1 ) $$ But I have no idea how to get so far","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I'm supposed to find the inverse of I know that the inverse isn't a function, as it isn't injective, but we're supposed to find it in domain . So far, I've switched x for y, and tried to solve for y, and gotten so far: WolframAlpha tells me the inverse is supposed to be But I have no idea how to get so far","y=2x^2+2x+2  [0, 1]  x=2y^2+2y+2  2y^2 + 2y = x-2  y(y+1)=1/2 (x-2)  y= 1/2 (\pm\sqrt{2x-3}-1 ) ","['calculus', 'functions', 'inverse-function']"
87,Find for what values of a and b in R the limit exists (No De L'Hopital),Find for what values of a and b in R the limit exists (No De L'Hopital),,"I was given this exercise in my math course at university. The question is to find, without using De l'Hopitals and other methods which may use derivates and similars, for what values of $a$ and $b$ in $\mathbb{R}$ the following statement is true. $$ f(x)= \left\{\begin{matrix}  \dfrac{\sin x}{x} & x > 0  \\  ax + b & x \leq 0  \\ \end{matrix}\right. $$ $$ \lim_{x \to 0^+} \dfrac{f(x) - ax - b}{x} = 0$$ I started by writing it as: $$ \lim_{x \to 0^+} \dfrac{\dfrac{\sin x}{x} -ax - b}{x} = 0$$ because, due to the fact that we are approaching from $x > 0, \, f(x) = \dfrac{\sin x}{x}$ Then I multiplied $\frac{\sin x}{x}$ by $\frac{\sin x}{\sin x}$ in order to get: $$ \lim_{x \to 0^+} \dfrac{\dfrac{\sin^2x}{x\sin x} -ax - b}{x} = 0$$ From there: $$ \lim_{x \to 0^+} \dfrac{\dfrac{\sin^2x}{x\sin x} -ax - b}{x} = 0$$ $$ \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos^2x}{x\sin x}-ax-b}{x} = 0 $$ $$ \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos x}{x} \times \dfrac{1+\cos x}{\sin x}-ax-b}{x} = 0$$ $$ \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos x}{x} \times \dfrac{1+\cos x}{x} \times \dfrac{x}{\sin x} - ax - b}{x} = 0$$ $$ \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1 - \cos x}{x} \times \dfrac{1}{x} \times \left(1 + \cos x\right) \times \dfrac{x}{\sin x} -ax - b}{x} = 0$$ $$ \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos x}{x^2} \times \left(1+ \cos x\right) \times \dfrac{x}{\sin x} -ax - b}{x} = 0$$ Which, substituting the value of $x$ to the value it is approaching, results in: $$ \dfrac{\dfrac{1}{2}\times\left(1+1\right)\times 1 - a \times 0 - b}{x} = 0 $$ $$ \Longleftrightarrow \dfrac{1 - b}{x} = 0 $$ Which should resolve to the I.F. $$\dfrac{0}{0}$$ when $b=1$ So to me it seems like, with the calculations I've done, I can't reach an answer about which value of $a$ and $b$ make the statement true","I was given this exercise in my math course at university. The question is to find, without using De l'Hopitals and other methods which may use derivates and similars, for what values of and in the following statement is true. I started by writing it as: because, due to the fact that we are approaching from Then I multiplied by in order to get: From there: Which, substituting the value of to the value it is approaching, results in: Which should resolve to the I.F. when So to me it seems like, with the calculations I've done, I can't reach an answer about which value of and make the statement true","a b \mathbb{R} 
f(x)= \left\{\begin{matrix}  \dfrac{\sin x}{x} & x > 0  \\  ax + b & x \leq 0  \\ \end{matrix}\right.   \lim_{x \to 0^+} \dfrac{f(x) - ax - b}{x} = 0  \lim_{x \to 0^+} \dfrac{\dfrac{\sin x}{x} -ax - b}{x} = 0 x > 0, \, f(x) = \dfrac{\sin x}{x} \frac{\sin x}{x} \frac{\sin x}{\sin x}  \lim_{x \to 0^+} \dfrac{\dfrac{\sin^2x}{x\sin x} -ax - b}{x} = 0  \lim_{x \to 0^+} \dfrac{\dfrac{\sin^2x}{x\sin x} -ax - b}{x} = 0  \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos^2x}{x\sin x}-ax-b}{x} = 0   \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos x}{x} \times \dfrac{1+\cos x}{\sin x}-ax-b}{x} = 0  \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos x}{x} \times \dfrac{1+\cos x}{x} \times \dfrac{x}{\sin x} - ax - b}{x} = 0  \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1 - \cos x}{x} \times \dfrac{1}{x} \times \left(1 + \cos x\right) \times \dfrac{x}{\sin x} -ax - b}{x} = 0  \Longleftrightarrow \lim_{x \to 0^+} \dfrac{\dfrac{1-\cos x}{x^2} \times \left(1+ \cos x\right) \times \dfrac{x}{\sin x} -ax - b}{x} = 0 x  \dfrac{\dfrac{1}{2}\times\left(1+1\right)\times 1 - a \times 0 - b}{x} = 0   \Longleftrightarrow \dfrac{1 - b}{x} = 0  \dfrac{0}{0} b=1 a b","['real-analysis', 'limits', 'analysis', 'functions', 'limits-without-lhopital']"
88,Totally bounded set in the space of continuous functions,Totally bounded set in the space of continuous functions,,"I have a set $$S  = \{ f \in C^2 [0,1] : \| f\|_c + \|f''\| = 1\}$$ in space $(C^2 [0,1], \| \cdot \|)$ , where $\| f(x) \|_c = \max\limits_{x \in [0,1]} |f(x)|$ . So to check that this space in totally bounded, I want to use Arzelà–Ascoli theorem, for that I need boundness, which is obvious because $\|f\|_c \le \|f\|_c + \|f'' \| = 1$ , but I have problem with uniformly equicontinuous. I have to check follow condition $$ \forall \varepsilon > 0 ~ \exists \delta > 0 : \forall f \in S ~ \forall x_1, x_2 :|x_1 - x_2| < \delta \hookrightarrow | f(x_1) - f(x_2)| < \varepsilon. $$ I tried to use mean value and Weierstrass theorems, but I from these I got $$|f(x_1) - f(x_2)| = |f'(\xi)||x_1 - x_2| < \varepsilon$$ with $\delta = \frac{\varepsilon}{ \max\limits_{x \in [0,1]} |f'(x)|} $ depends on function, which I don't want. So what I'm missing when trying to pick up the value of $\delta$ not depending on function?","I have a set in space , where . So to check that this space in totally bounded, I want to use Arzelà–Ascoli theorem, for that I need boundness, which is obvious because , but I have problem with uniformly equicontinuous. I have to check follow condition I tried to use mean value and Weierstrass theorems, but I from these I got with depends on function, which I don't want. So what I'm missing when trying to pick up the value of not depending on function?","S  = \{ f \in C^2 [0,1] : \| f\|_c + \|f''\| = 1\} (C^2 [0,1], \| \cdot \|) \| f(x) \|_c = \max\limits_{x \in [0,1]} |f(x)| \|f\|_c \le \|f\|_c + \|f'' \| = 1  \forall \varepsilon > 0 ~ \exists \delta > 0 : \forall f \in S ~ \forall x_1, x_2 :|x_1 - x_2| < \delta \hookrightarrow | f(x_1) - f(x_2)| < \varepsilon.  |f(x_1) - f(x_2)| = |f'(\xi)||x_1 - x_2| < \varepsilon \delta = \frac{\varepsilon}{ \max\limits_{x \in [0,1]} |f'(x)|}  \delta","['real-analysis', 'functional-analysis', 'functions']"
89,"Find all analytic functions such that $z^{2} f^{\prime \prime}(z)+f^{\prime}(z)-6 f(z)=0, \quad z \in \mathbb{C}$",Find all analytic functions such that,"z^{2} f^{\prime \prime}(z)+f^{\prime}(z)-6 f(z)=0, \quad z \in \mathbb{C}","This is a question I got in a homework sheet for one of my modules (MSc Mathematics, complex analysis module). We've been doing Taylor Series and Laurent series in class, and I tried to find the Taylor series for $f(z)$ about 0, and then differentiated that to get $f'(z)$ and $f''(z)$ . Then I substituted these into the given equation, and for the first few terms I got: $$-6f(0) + (2-6z)f'(0) + (z^2+2z)f''(0) + ...$$ I hit a dead end after that. I don't know if what I've done is helpful, or if I'm completely on the wrong track. If anyone could advise me on whether this is going in the right direction or not, that would be very helpful. Thank you!","This is a question I got in a homework sheet for one of my modules (MSc Mathematics, complex analysis module). We've been doing Taylor Series and Laurent series in class, and I tried to find the Taylor series for about 0, and then differentiated that to get and . Then I substituted these into the given equation, and for the first few terms I got: I hit a dead end after that. I don't know if what I've done is helpful, or if I'm completely on the wrong track. If anyone could advise me on whether this is going in the right direction or not, that would be very helpful. Thank you!",f(z) f'(z) f''(z) -6f(0) + (2-6z)f'(0) + (z^2+2z)f''(0) + ...,"['complex-analysis', 'functions', 'complex-numbers', 'taylor-expansion']"
90,Find all functions satisfying $f\left((1-xy)f(x)\right)+x^2f(y)=f(x)$,Find all functions satisfying,f\left((1-xy)f(x)\right)+x^2f(y)=f(x),"To find all functions $f:\mathbb{R} \to \mathbb{R}$ satisfying $$f((1-x y) f(x))+x^2 f(y)=f(x) \label1\tag1$$ When $x=y=1$ we have $f(0)=0$ . Case I: If $f(x)$ is a constant function, say $f(x)=\lambda$ , we have $$\lambda+x^2\lambda=\lambda$$ which makes sense only when $\lambda=0$ . Thus the only constant function satisfying the functional equation is $$f(x)=0$$ Case II: If $f(x)$ is a non constant function, we have for $y=0$ in \eqref{1} $$f(f(x))=f(x)$$ Any help from here?","To find all functions satisfying When we have . Case I: If is a constant function, say , we have which makes sense only when . Thus the only constant function satisfying the functional equation is Case II: If is a non constant function, we have for in \eqref{1} Any help from here?",f:\mathbb{R} \to \mathbb{R} f((1-x y) f(x))+x^2 f(y)=f(x) \label1\tag1 x=y=1 f(0)=0 f(x) f(x)=\lambda \lambda+x^2\lambda=\lambda \lambda=0 f(x)=0 f(x) y=0 f(f(x))=f(x),"['calculus', 'algebra-precalculus', 'functions', 'functional-equations']"
91,Doubt regarding notation of functions and relations,Doubt regarding notation of functions and relations,,"In the notation $f : A \rightarrow B$ , $A$ is the domain of $f$ and $B$ is the codomain. What actually is the codomain? Defining it as the set into which all outputs of the function are constrained to doesn't seem very solid to me. Is it wrong to say that for the function $x \mapsto x+1, x \in \mathbb{Z}$ , one may say that the codomain is $\mathbb{R}$ or $\mathbb{Z}$ or any other superset of $\mathbb{Z}$ ? Let's say I define sets $A = \{1,2,3,4,5\}$ and $B =  \{2,4,6,8,10\} $ , and a relation, $R:A \to B$ (which means domain is $A$ and codomain is $B$ ), such that $R = \{(1,2),(2,4),(3,6),(4,8)\} $ . In this case, $R$ is a subset of $A \times B$ , and I've always thought that this means $R$ is a relation from A to $B$ . But if $A$ is the domain, then that means $A$ should be the set of all first elements of all ordered pairs in $R$ . But clearly in this case, the element $5$ is in $A$ but it is not the first element of any ordered pair in $R$ . So my question is, is it valid to say that $R$ is a relation from $A \to B$ , purely from the fact that $R \subset A \times B$ ? Does this not contradict the fact that the $R:A \to B$ notation says that $A$ is the domain ?","In the notation , is the domain of and is the codomain. What actually is the codomain? Defining it as the set into which all outputs of the function are constrained to doesn't seem very solid to me. Is it wrong to say that for the function , one may say that the codomain is or or any other superset of ? Let's say I define sets and , and a relation, (which means domain is and codomain is ), such that . In this case, is a subset of , and I've always thought that this means is a relation from A to . But if is the domain, then that means should be the set of all first elements of all ordered pairs in . But clearly in this case, the element is in but it is not the first element of any ordered pair in . So my question is, is it valid to say that is a relation from , purely from the fact that ? Does this not contradict the fact that the notation says that is the domain ?","f : A \rightarrow B A f B x \mapsto x+1, x \in \mathbb{Z} \mathbb{R} \mathbb{Z} \mathbb{Z} A = \{1,2,3,4,5\} B =  \{2,4,6,8,10\}  R:A \to B A B R = \{(1,2),(2,4),(3,6),(4,8)\}  R A \times B R B A A R 5 A R R A \to B R \subset A \times B R:A \to B A",['functions']
92,A question related to the inverse image of a set,A question related to the inverse image of a set,,"This may seem like (... or, may be it is) a very trivial question. Consider a function $f\colon X\to Y$ (Assume that both $X$ and $Y$ are non-empty). Consider the inverse image of $Y$ under $f$ , defined by $\:f^{-1}(Y):=\{x\in X:f(x)\in Y\}$ . Then is it necessarily true that $f^{-1}(Y)=X$ ? My thoughts: Cleary, $f^{-1}(Y)\subset X$ (follows from the definition). Now given $x\in X$ , $f(x)\in Y$ , so $x\in f^{-1}(Y)$ . Hence $X\subset f^{-1}(Y)$ , so $X=f^{-1}(Y)$ . Is this reasoning correct? I feel like I am missing something.","This may seem like (... or, may be it is) a very trivial question. Consider a function (Assume that both and are non-empty). Consider the inverse image of under , defined by . Then is it necessarily true that ? My thoughts: Cleary, (follows from the definition). Now given , , so . Hence , so . Is this reasoning correct? I feel like I am missing something.",f\colon X\to Y X Y Y f \:f^{-1}(Y):=\{x\in X:f(x)\in Y\} f^{-1}(Y)=X f^{-1}(Y)\subset X x\in X f(x)\in Y x\in f^{-1}(Y) X\subset f^{-1}(Y) X=f^{-1}(Y),['functions']
93,"Skew a value in the range [0.0, 1.0].","Skew a value in the range [0.0, 1.0].",,"I have a variable v that can take a value from 0.0 to 1.0 . I want a function to left-skew the value, producing w . By ""left skew"" I mean that any value of v will be increased, but more so for lower values and less so for higher values, so that there will be more values in w ""bunched together"" the nearer you get to 1.0 . (My math is a but rusty so I apologize if I'm not asking this using the correct terminology.) For an intuitive example (not to scale; these are arbitrary values to explain the idea ), a value v of 0.4 might yield a value w of 0.5 , while a value v of 0.91 might only yield a value w of 0.92 . (Ideally there would be some other variable that controlled the amount of skew, and perhaps another variable that controlled the weight or slope of the skew. But I want to start simple!) However an input v of 0 or 1 would still yield an output w of 0 , and 1 , respectively (i.e. the bounds of the range are fixed). Another way to look at this is to assume that the values in v are right-skewed, and we want to ""unskew"" them to make a uniform distribution. This is probably Math 101 or Trigonometry 101, and there's probably some simple sin/cos function or something like that. Thank you in advance for helping my brain get oriented to review these elementary concepts.","I have a variable v that can take a value from 0.0 to 1.0 . I want a function to left-skew the value, producing w . By ""left skew"" I mean that any value of v will be increased, but more so for lower values and less so for higher values, so that there will be more values in w ""bunched together"" the nearer you get to 1.0 . (My math is a but rusty so I apologize if I'm not asking this using the correct terminology.) For an intuitive example (not to scale; these are arbitrary values to explain the idea ), a value v of 0.4 might yield a value w of 0.5 , while a value v of 0.91 might only yield a value w of 0.92 . (Ideally there would be some other variable that controlled the amount of skew, and perhaps another variable that controlled the weight or slope of the skew. But I want to start simple!) However an input v of 0 or 1 would still yield an output w of 0 , and 1 , respectively (i.e. the bounds of the range are fixed). Another way to look at this is to assume that the values in v are right-skewed, and we want to ""unskew"" them to make a uniform distribution. This is probably Math 101 or Trigonometry 101, and there's probably some simple sin/cos function or something like that. Thank you in advance for helping my brain get oriented to review these elementary concepts.",,"['functions', 'uniform-distribution']"
94,Proof Surjective function with no ''given'' function,Proof Surjective function with no ''given'' function,,"$f_1 : \mathbb{R}^2 \longrightarrow \mathbb{R}$ and $f_2 : \mathbb{R}^2 \longrightarrow \mathbb{R}$ and define $f: \mathbb{R}^2 \longrightarrow \mathbb{R}^2$ as $f(x,y) = (f_1(x,y),f_2(x,y))$ . Question: If $f$ is surjective. Proof that $f_1$ and $f_2$ are also surjective. So what I thought was that if $f$ is surjective, this means that for all $b$ (element of $\mathbb{R}^2$ ) there exists an $a$ (element of $\mathbb{R}^2$ ) so that $f(a)=b$ . However, I don't know how to continue this proof without having a function as I can't find an inverse function. I would like some help. Thanks !","and and define as . Question: If is surjective. Proof that and are also surjective. So what I thought was that if is surjective, this means that for all (element of ) there exists an (element of ) so that . However, I don't know how to continue this proof without having a function as I can't find an inverse function. I would like some help. Thanks !","f_1 : \mathbb{R}^2 \longrightarrow \mathbb{R} f_2 : \mathbb{R}^2 \longrightarrow \mathbb{R} f: \mathbb{R}^2 \longrightarrow \mathbb{R}^2 f(x,y) = (f_1(x,y),f_2(x,y)) f f_1 f_2 f b \mathbb{R}^2 a \mathbb{R}^2 f(a)=b","['functions', 'real-numbers']"
95,Find f(32) given f(x) = f(x-1) + 2^(f(x-1)+1) and f(0) = 5 [closed],Find f(32) given f(x) = f(x-1) + 2^(f(x-1)+1) and f(0) = 5 [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I would like to find f(32) given: f(x) = f(x-1) + 2^(f(x-1)+1) f(0) = 5 I figured that this function grows tetrationally (if that is a word) but I don't really know Where I got this equation from: In the collectable trading card game Magic: The Gathering, there are these cards: Miirym, sentinel wyrm , Astral Dragon , Parallel Lives If Astral Dragon where to come into play with Miirym and Parallel Lives already on the battlefield and all of the tokens Astral Dragon created where copies of Parallel Lives, you would end up with f(32) Parallel Lives in play. Edit: I am not looking for a specific answer, just a rough estimate of how large that number is. I know it is larger than 2^^32 bit is it Larger than 2^^33? 2^^34?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question I would like to find f(32) given: f(x) = f(x-1) + 2^(f(x-1)+1) f(0) = 5 I figured that this function grows tetrationally (if that is a word) but I don't really know Where I got this equation from: In the collectable trading card game Magic: The Gathering, there are these cards: Miirym, sentinel wyrm , Astral Dragon , Parallel Lives If Astral Dragon where to come into play with Miirym and Parallel Lives already on the battlefield and all of the tokens Astral Dragon created where copies of Parallel Lives, you would end up with f(32) Parallel Lives in play. Edit: I am not looking for a specific answer, just a rough estimate of how large that number is. I know it is larger than 2^^32 bit is it Larger than 2^^33? 2^^34?",,"['functions', 'recursion', 'tetration']"
96,"For the function $y=\frac{\sqrt{x}}{x-e^x}$, prove that there is one horizontal asymptote at $y=0$","For the function , prove that there is one horizontal asymptote at",y=\frac{\sqrt{x}}{x-e^x} y=0,"$$y=\frac{\sqrt{x}}{x-e^x}$$ Proving vertical asymptotes are easy but when it comes to proving horizontal or oblique ones, I often get stuck. This function seems to intersect its asymptote at the origin so substituting in $0$ to show an error does not work. So how does one prove these kinds of things, is there a common way that people use? Right now, I am suspecting something to do with limits(correct me if I am wrong) but have no idea how to progress with that way.","Proving vertical asymptotes are easy but when it comes to proving horizontal or oblique ones, I often get stuck. This function seems to intersect its asymptote at the origin so substituting in to show an error does not work. So how does one prove these kinds of things, is there a common way that people use? Right now, I am suspecting something to do with limits(correct me if I am wrong) but have no idea how to progress with that way.",y=\frac{\sqrt{x}}{x-e^x} 0,"['algebra-precalculus', 'limits', 'functions']"
97,Solve inequality $\sinh (3x-x^2) > 0$,Solve inequality,\sinh (3x-x^2) > 0,"Solve inequality $\sinh (3x-x^2) \ > 0$ To solve this, we can say that $\sinh y$ is always increasing on real numbers. It’s domain and range its from negative to positive infinity. Why can we can say that $(3x-x^2) > 0$ , ? Solving for $x$ gives $x>3$ but $x>3$ means it will not satisfy the inequality as the function will be negative.","Solve inequality To solve this, we can say that is always increasing on real numbers. It’s domain and range its from negative to positive infinity. Why can we can say that , ? Solving for gives but means it will not satisfy the inequality as the function will be negative.",\sinh (3x-x^2) \ > 0 \sinh y (3x-x^2) > 0 x x>3 x>3,"['functions', 'inequality']"
98,"Am I getting this right about equations, functions and logic?","Am I getting this right about equations, functions and logic?",,"When I square the equation $ x=2 $ I get the equation $ x^2=4 $ and I would write $$ x=2 \Rightarrow x^2=4. $$ This implication is true for all $x$ in $\mathbb R$ . In other words, the sentence $$\forall x \in \mathbb R: (x=2 \Rightarrow x^2=4)$$ is true. Of course I could also think of this predicate $$ x^2=4 \Rightarrow x=2 , $$ let's call it $A(x)$ . There are numbers which turn $A(x)$ into a true sentence but also numbers which turn $A(x)$ into a false sentence, for example $A(-2)$ is a false sentence . So the sentence $$\forall x \in \mathbb R: (x^2=4 \Rightarrow x=2)$$ is false. The squaring of the equation $ x=2 $ is actually me using the function $h:t\mapsto t^2$ on both sides of $x=2$ . And I know that $x=2 \Rightarrow x^2=4$ is true for all $x$ in $\mathbb R$ because $t_1=t_2 \Rightarrow f(t_1)=f(t_2)$ is true for all $t_1$ and $t_2$ . This $$t_1=t_2 \Rightarrow f(t_1)=f(t_2)$$ is true for all $t_1,t_2$ because that's just what functions do; taking an input and giving out an output. For this $$t_1=t_2 \iff f(t_1)=f(t_2)$$ to be true for all $t_1,t_2$ , the function $f$ has to be injective. So when I'm doing my operations on my equations, I can only use the $ \iff $ arrow when I am applying an injective function on both sides of the equations. A simple example would be $$ x=2 \iff x+x=2+x. $$ Here I used the injective function $f:t\mapsto t+x$ on both sides of the equation. And because I used this injective function on both sides of the equation I know that the sentence $$ \forall x \in \mathbb R: (x=2 \iff x+x=2+x) $$ is true. Are all these thoughts correct?","When I square the equation I get the equation and I would write This implication is true for all in . In other words, the sentence is true. Of course I could also think of this predicate let's call it . There are numbers which turn into a true sentence but also numbers which turn into a false sentence, for example is a false sentence . So the sentence is false. The squaring of the equation is actually me using the function on both sides of . And I know that is true for all in because is true for all and . This is true for all because that's just what functions do; taking an input and giving out an output. For this to be true for all , the function has to be injective. So when I'm doing my operations on my equations, I can only use the arrow when I am applying an injective function on both sides of the equations. A simple example would be Here I used the injective function on both sides of the equation. And because I used this injective function on both sides of the equation I know that the sentence is true. Are all these thoughts correct?"," x=2   x^2=4  
x=2 \Rightarrow x^2=4.
 x \mathbb R \forall x \in \mathbb R: (x=2 \Rightarrow x^2=4) 
x^2=4 \Rightarrow x=2 ,
 A(x) A(x) A(x) A(-2) \forall x \in \mathbb R: (x^2=4 \Rightarrow x=2)  x=2  h:t\mapsto t^2 x=2 x=2 \Rightarrow x^2=4 x \mathbb R t_1=t_2 \Rightarrow f(t_1)=f(t_2) t_1 t_2 t_1=t_2 \Rightarrow f(t_1)=f(t_2) t_1,t_2 t_1=t_2 \iff f(t_1)=f(t_2) t_1,t_2 f  \iff  
x=2 \iff x+x=2+x.
 f:t\mapsto t+x 
\forall x \in \mathbb R: (x=2 \iff x+x=2+x)
","['functions', 'logic', 'propositional-calculus']"
99,Find the maximum value of the integral $\int_{-1}^1|x-a|e^xdx$ where $|a|\le1$,Find the maximum value of the integral  where,\int_{-1}^1|x-a|e^xdx |a|\le1,"Question: Find the maximum value of the integral $\int_{-1}^1|x-a|e^xdx$ where $|a|\le1$ My Attempt: Let $f(a)=\int_{-1}^a(a-x)e^xdx+\int_{a}^1(x-a)e^xdx$ $f'(a)=\int_{-1}^ae^xdx+\int_{a}^1-e^xdx$ $f'(a)=e^a-e^{-1}-(e-e^a)$ For maximum, $f'(a)=0$ So, $2e^a-e-e^{-1}=0\implies 2e^a=e+\frac1e$ So, $e^a=\frac{e^2+1}{2e}\implies a=\ln\left(\frac{e^2+1}{2e}\right)$ But the answer given is: Max value $e+e^{-1}$ when $a=-1$ What's wrong in my approach? Edit: For derivative, I have used Leibniz Integral Rule","Question: Find the maximum value of the integral where My Attempt: Let For maximum, So, So, But the answer given is: Max value when What's wrong in my approach? Edit: For derivative, I have used Leibniz Integral Rule",\int_{-1}^1|x-a|e^xdx |a|\le1 f(a)=\int_{-1}^a(a-x)e^xdx+\int_{a}^1(x-a)e^xdx f'(a)=\int_{-1}^ae^xdx+\int_{a}^1-e^xdx f'(a)=e^a-e^{-1}-(e-e^a) f'(a)=0 2e^a-e-e^{-1}=0\implies 2e^a=e+\frac1e e^a=\frac{e^2+1}{2e}\implies a=\ln\left(\frac{e^2+1}{2e}\right) e+e^{-1} a=-1,"['calculus', 'integration', 'functions', 'definite-integrals', 'maxima-minima']"
