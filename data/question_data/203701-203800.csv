,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,On the generalisation of the Fubini theorem,On the generalisation of the Fubini theorem,,"Consider a smooth function $g(x) \colon \mathbb{R}^n \to \mathbb{R}$ such that $\nabla g > 0$ entrywise. Let $M_t = \{ x \mid g(x) = t \}$. Assume that $\{M_t\}$ don't intersect pairwise and their union gives $\mathbb{R}^n$. Let $dg \wedge \omega = dx_1 \wedge ... \wedge dx_n \equiv dx.$ How to show than that $$   \int\limits_{\mathbb{R}^n} f(g(x),x) dx = \int\limits_{\mathbb{R}} dt \int\limits_{M_t}f(t,x)\omega $$","Consider a smooth function $g(x) \colon \mathbb{R}^n \to \mathbb{R}$ such that $\nabla g > 0$ entrywise. Let $M_t = \{ x \mid g(x) = t \}$. Assume that $\{M_t\}$ don't intersect pairwise and their union gives $\mathbb{R}^n$. Let $dg \wedge \omega = dx_1 \wedge ... \wedge dx_n \equiv dx.$ How to show than that $$   \int\limits_{\mathbb{R}^n} f(g(x),x) dx = \int\limits_{\mathbb{R}} dt \int\limits_{M_t}f(t,x)\omega $$",,"['integration', 'differential-geometry']"
1,How to work with Connections,How to work with Connections,,"I am currently reading a book which deals with complex manifolds. Since I am fairly new to the topic I don't know exactly the meaning of the followinig: Suppose we have a holomorphic vector bundle $V$ over the manifold $M$ with frames $s_\alpha$ over each trivialization $U_\alpha \subset M$ We can construct a Hermitian metric $h$ on $V$, and the author says this is given locally as $h_\alpha = (s_\alpha,s_\alpha) $. Then a connection 1 - form is defined locally by \begin{equation} \omega_\alpha = \partial h_\alpha h_\alpha^{-1} \end{equation}  where  \begin{equation} d = \partial + \bar{\partial} \end{equation} and  \begin{equation} \partial(f) = \sum_j \frac{\partial f}{\partial z^j}dz^j \end{equation} (more generally $\partial \colon C^\infty(\Lambda^{p,q}) \to C^\infty(\Lambda^{p+1,q}) $.  It is then shown in the book that these 1-forms patch together to form a connection $\triangledown_h$. Now comes the bit where I am struggeling with, to the extend that I can't read on without a bad feeling: From the definition, one should see that \begin{align} (\triangledown_h s_\alpha, s_\alpha) + (s_\alpha, \triangledown_h s_\alpha) &= \omega_\alpha h_\alpha + h_\alpha \omega^*_\alpha \\  &= \partial h _\alpha + \bar{\partial}h _\alpha = dh _\alpha \end{align} I am afraind I don't know enough about connections yet, in particular I don't really understand how to get from the first expression to the second. If anyone could fill in a little more details into the lines above that would be very helpful!","I am currently reading a book which deals with complex manifolds. Since I am fairly new to the topic I don't know exactly the meaning of the followinig: Suppose we have a holomorphic vector bundle $V$ over the manifold $M$ with frames $s_\alpha$ over each trivialization $U_\alpha \subset M$ We can construct a Hermitian metric $h$ on $V$, and the author says this is given locally as $h_\alpha = (s_\alpha,s_\alpha) $. Then a connection 1 - form is defined locally by \begin{equation} \omega_\alpha = \partial h_\alpha h_\alpha^{-1} \end{equation}  where  \begin{equation} d = \partial + \bar{\partial} \end{equation} and  \begin{equation} \partial(f) = \sum_j \frac{\partial f}{\partial z^j}dz^j \end{equation} (more generally $\partial \colon C^\infty(\Lambda^{p,q}) \to C^\infty(\Lambda^{p+1,q}) $.  It is then shown in the book that these 1-forms patch together to form a connection $\triangledown_h$. Now comes the bit where I am struggeling with, to the extend that I can't read on without a bad feeling: From the definition, one should see that \begin{align} (\triangledown_h s_\alpha, s_\alpha) + (s_\alpha, \triangledown_h s_\alpha) &= \omega_\alpha h_\alpha + h_\alpha \omega^*_\alpha \\  &= \partial h _\alpha + \bar{\partial}h _\alpha = dh _\alpha \end{align} I am afraind I don't know enough about connections yet, in particular I don't really understand how to get from the first expression to the second. If anyone could fill in a little more details into the lines above that would be very helpful!",,['differential-geometry']
2,Solution of a differential equation that would be a generalized mean?,Solution of a differential equation that would be a generalized mean?,,"I am trying to solve this differential equation on which I've been stuck for several days now. $$\frac{d X}{d t}=\frac{\int_{-\infty}^{\infty}\frac{\partial f}{\partial t}\frac{\partial f}{\partial x}dx}{\int_{-\infty}^{\infty}\left(\frac{\partial f}{\partial x}\right)^{2}dx} $$ where $f(x,t)$ is as smooth and integrable as you want it to be. Hey, I'm a physicist :) I have also the normalisation $\int f(x,t)dx=\int f^{2}(x,t)dx=1 $ If for all $t$, $x_0(t)$ is a center of symmetry relative to x then $X(t)=x_0(t)$ is a solution of my equation. This lets me think that in the general, non-symmetric case, a solution of this equation might be related to a generalized mean of $f$. It does make sense when I do some simulations. Rewriting this in the Fourier plane using Parseval identities leads to interesting formulas but I can't interpret them either. I also tried to think of it as $L^2$ inner products without any result. That would be great if anyone had an idea on how to give some sense to this equation, particularily if a solution of it could be interpreted as a generalized mean of $f$. Or obviously to solve it if that proved to be possible. The original problem is actually in dimension $N$ with gradients instead of derivatives relative to $x$ but any idea in dimension $1$ would be extremely welcome. Thanks to whoever takes time considering this problem, Olivier","I am trying to solve this differential equation on which I've been stuck for several days now. $$\frac{d X}{d t}=\frac{\int_{-\infty}^{\infty}\frac{\partial f}{\partial t}\frac{\partial f}{\partial x}dx}{\int_{-\infty}^{\infty}\left(\frac{\partial f}{\partial x}\right)^{2}dx} $$ where $f(x,t)$ is as smooth and integrable as you want it to be. Hey, I'm a physicist :) I have also the normalisation $\int f(x,t)dx=\int f^{2}(x,t)dx=1 $ If for all $t$, $x_0(t)$ is a center of symmetry relative to x then $X(t)=x_0(t)$ is a solution of my equation. This lets me think that in the general, non-symmetric case, a solution of this equation might be related to a generalized mean of $f$. It does make sense when I do some simulations. Rewriting this in the Fourier plane using Parseval identities leads to interesting formulas but I can't interpret them either. I also tried to think of it as $L^2$ inner products without any result. That would be great if anyone had an idea on how to give some sense to this equation, particularily if a solution of it could be interpreted as a generalized mean of $f$. Or obviously to solve it if that proved to be possible. The original problem is actually in dimension $N$ with gradients instead of derivatives relative to $x$ but any idea in dimension $1$ would be extremely welcome. Thanks to whoever takes time considering this problem, Olivier",,"['calculus', 'differential-geometry', 'partial-differential-equations']"
3,exercise on surfaces and geodesics,exercise on surfaces and geodesics,,"Maybe someone can verify my answers. The problem is as follows: Consider a line $l$ in $\mathbb{R}^3$ and rotate it around the $Oz$ axis. Denote by $A$ the set of all such obtained surfaces. Question 1: Write their parametrizations. My answer: Let $S \in A$. Then there exists a line $$\phi:\mathbb{R}\rightarrow\mathbb{R}^3:t\mapsto \phi(t)=p_0+tv$$ and a matrix $R(\theta)$  corresponding to the rotation around the $Oz$ axis by an angle $0\leq \theta <2\pi$ such that $S$ is parametrized as $$\psi: [0,\theta]\times \mathbb{R}\rightarrow S:(\alpha,t)\mapsto R(\alpha)\phi(t).$$ Queston 2: Describe as many geodesics as you can for each surface. My partial answer: I started with taking an $S$ as above and defining $\gamma(t)=\psi(\alpha,t)/||v||$, where the vector $v$ is a ""direction"" of the line $l$. Since $\gamma''(t)=(0,0,0)$, $\gamma$ is a geodesic on $S$. How can I find many others?","Maybe someone can verify my answers. The problem is as follows: Consider a line $l$ in $\mathbb{R}^3$ and rotate it around the $Oz$ axis. Denote by $A$ the set of all such obtained surfaces. Question 1: Write their parametrizations. My answer: Let $S \in A$. Then there exists a line $$\phi:\mathbb{R}\rightarrow\mathbb{R}^3:t\mapsto \phi(t)=p_0+tv$$ and a matrix $R(\theta)$  corresponding to the rotation around the $Oz$ axis by an angle $0\leq \theta <2\pi$ such that $S$ is parametrized as $$\psi: [0,\theta]\times \mathbb{R}\rightarrow S:(\alpha,t)\mapsto R(\alpha)\phi(t).$$ Queston 2: Describe as many geodesics as you can for each surface. My partial answer: I started with taking an $S$ as above and defining $\gamma(t)=\psi(\alpha,t)/||v||$, where the vector $v$ is a ""direction"" of the line $l$. Since $\gamma''(t)=(0,0,0)$, $\gamma$ is a geodesic on $S$. How can I find many others?",,['differential-geometry']
4,Is the $n$-th order derivative the derivative of the $n-1$-th order one?,Is the -th order derivative the derivative of the -th order one?,n n-1,"From Wikipedia : The natural analog of second, third, and higher-order total derivatives is not a linear transformation, is not a function on the   tangent bundle, and is not built by repeatedly taking the total   derivative . I think the $n$-th order (total) derivative of a mapping is the derivative of its $n-1$-th order derivative. In other words, derivative can be defined recursively. So I was wondering how to understand that ""the natural analog of second, third, and higher-order total derivatives ... is not built by repeatedly taking the total derivative""? Thanks and regards!","From Wikipedia : The natural analog of second, third, and higher-order total derivatives is not a linear transformation, is not a function on the   tangent bundle, and is not built by repeatedly taking the total   derivative . I think the $n$-th order (total) derivative of a mapping is the derivative of its $n-1$-th order derivative. In other words, derivative can be defined recursively. So I was wondering how to understand that ""the natural analog of second, third, and higher-order total derivatives ... is not built by repeatedly taking the total derivative""? Thanks and regards!",,"['real-analysis', 'differential-geometry']"
5,Do the maximum and minimum values of a Laplacian eigenfunction have the same magnitude?,Do the maximum and minimum values of a Laplacian eigenfunction have the same magnitude?,,"Let $\Delta$ be the scalar Laplace-Beltrami operator on a compact, connected, orientable 2-manifold without boundary smoothly embedded in $\mathbb{R}^3$ and let $\phi$ be one of its eigenfunctions, i.e., $$ \Delta \phi = \lambda \phi $$ for some constant $\lambda \in \mathbb{R}$.  Is there any reason to believe that the maximum and minimum pointwise values of $\phi$ have the same magnitude?  This statement certainly holds for simple domains like $S^1$ (where the eigenfunctions are just $\cos(nx)$ and $\sin(nx)$, $n \in \mathbb{Z}$) and also appears to be true empirically (e.g., if you numerically compute eigenfunctions of triangulated surfaces).  But I have trouble seeing why it would be true in general. One thing to note is that the eigenfunctions of $\Delta$ are orthogonal with respect to the $L^2$ inner product.  In particular, the constant function is always an eigenfunction of $\Delta$, which means all other eigenfunctions will have zero mean.  Unfortunately zero mean does not guarantee that the max and min have equal magnitude.","Let $\Delta$ be the scalar Laplace-Beltrami operator on a compact, connected, orientable 2-manifold without boundary smoothly embedded in $\mathbb{R}^3$ and let $\phi$ be one of its eigenfunctions, i.e., $$ \Delta \phi = \lambda \phi $$ for some constant $\lambda \in \mathbb{R}$.  Is there any reason to believe that the maximum and minimum pointwise values of $\phi$ have the same magnitude?  This statement certainly holds for simple domains like $S^1$ (where the eigenfunctions are just $\cos(nx)$ and $\sin(nx)$, $n \in \mathbb{Z}$) and also appears to be true empirically (e.g., if you numerically compute eigenfunctions of triangulated surfaces).  But I have trouble seeing why it would be true in general. One thing to note is that the eigenfunctions of $\Delta$ are orthogonal with respect to the $L^2$ inner product.  In particular, the constant function is always an eigenfunction of $\Delta$, which means all other eigenfunctions will have zero mean.  Unfortunately zero mean does not guarantee that the max and min have equal magnitude.",,"['differential-geometry', 'functional-analysis', 'spectral-theory']"
6,After Whitney embedding,After Whitney embedding,,Let $M$ be a $d$-dimensional compact manifold and $f:M\to M$ be a diffeomorphism on $M$. Whitney embedding theorem says that we can embed $M$ into $\mathbb{R}^{2d+1}$. Let $T$ be a tubular neighborhood of $M$ with respect to the embedding. In some papers they say that there exists a diffeomorphism $F:T\to F(T)\Subset T$ with $F|_M=f$. Is there a theorem about this? Any reference will be great!,Let $M$ be a $d$-dimensional compact manifold and $f:M\to M$ be a diffeomorphism on $M$. Whitney embedding theorem says that we can embed $M$ into $\mathbb{R}^{2d+1}$. Let $T$ be a tubular neighborhood of $M$ with respect to the embedding. In some papers they say that there exists a diffeomorphism $F:T\to F(T)\Subset T$ with $F|_M=f$. Is there a theorem about this? Any reference will be great!,,"['differential-geometry', 'manifolds']"
7,Motivation for product structure,Motivation for product structure,,"I guess I understand some reasons why we should care for complex structure on manifolds, but what is the reason why product structure is studied? Does it arise naturally somewhere? The product structure on a smooth manifold $M$ is given by a (1,1)-tensor $E$ such that $E \neq \pm1$ and $E^2 = 1$ and the following integrability condition holds: $$E[X,Y] = [EX,Y] + [X,EY] - E[EX,EY]$$ Compare it to a complex structure $J$ such that $J^2 = -1$ and $$J[X,Y] = [JX,Y] + [X,JY] + J[JX,JY]$$ I'm still studying basic literature, one thing I do know is that on a Lie group it $E$ induces a double algebra structure on a correspoinding Lie algebra, and thus two foliations on the group, if I remember correctly; I guess it is generalized for an arbitrary manifold, so this 'splitting' of the tangent bundle and how it's compatible with other structures (complex, Hermitian, Kähler etc., e.g. a complex product structure is defined by the two respective structures such that $JE = -EJ$) is probably one of the reasons to study it, but I'm not sure this reason is good enough on its own.","I guess I understand some reasons why we should care for complex structure on manifolds, but what is the reason why product structure is studied? Does it arise naturally somewhere? The product structure on a smooth manifold $M$ is given by a (1,1)-tensor $E$ such that $E \neq \pm1$ and $E^2 = 1$ and the following integrability condition holds: $$E[X,Y] = [EX,Y] + [X,EY] - E[EX,EY]$$ Compare it to a complex structure $J$ such that $J^2 = -1$ and $$J[X,Y] = [JX,Y] + [X,JY] + J[JX,JY]$$ I'm still studying basic literature, one thing I do know is that on a Lie group it $E$ induces a double algebra structure on a correspoinding Lie algebra, and thus two foliations on the group, if I remember correctly; I guess it is generalized for an arbitrary manifold, so this 'splitting' of the tangent bundle and how it's compatible with other structures (complex, Hermitian, Kähler etc., e.g. a complex product structure is defined by the two respective structures such that $JE = -EJ$) is probably one of the reasons to study it, but I'm not sure this reason is good enough on its own.",,"['soft-question', 'differential-geometry']"
8,Commutivity of two derivatives for exponential map,Commutivity of two derivatives for exponential map,,"I'm reading the book Hörmander Operators by Marco Bramanti and Luca Brandolini World Scientific, 2023 . I had a problem when reading the proof of the following theorem: Theorem 1.9 Let $X$ and $Y$ be smooth vector fields in a domain $\Omega$ such that $[X, Y] \equiv 0$ . Let $x_{0} \in \Omega$ . There exist $\varepsilon>0$ such that for every $|t|<\varepsilon $ \begin{array}{l} \exp (t X) \exp (t Y)\left(x_{0}\right)=\exp  (t(X+Y))\left(x_{0}\right) ; \\ \exp (-t X) \exp (-t Y) \exp (t X) \exp (t Y)\left(x_{0}\right)=x_{0} \end{array} Proof . The second identity easily follows from the first one. To prove the first identity, let $\varphi(t)=\exp (t X) \exp (t  Y)\left(x_{0}\right)$ . Clearly $\varphi(0)=x_{0}$ . We will show that $$\varphi^{\prime}(t)=X_{\varphi(t)}+Y_{\varphi(t)}\tag{1.8}$$ and therefore $\varphi(t)=\exp (t(X+Y))\left(x_{0}\right) $ . Let now $$F(u, v)=\exp (u X) \exp (v Y)\left(x_{0}\right),$$ it follows that $\varphi^{\prime}(t)=\frac{\partial F}{\partial u}(t,t)+\frac{\partial F}{\partial v}(t, t) $ . For the first term we have $$\frac{\partial F}{\partial u}(t, t)=X_{\exp (t X) \exp (tY)\left(x_{0}\right)}=X_{\varphi(t)}$$ In order to evaluate $\frac{\partial F}{\partial v}(t, t)$ we set $G_{v}(u)=\frac{\partial F}{\partial v}(u, v)$ , we observe that $G_{v}(0)=   Y_{\exp (v Y)\left(x_{0}\right)}$ and that \begin{align} G_{v}^{\prime}(u) & =\frac{\partial^{2} F}{\partial v \partial u}(u, v)=\frac{\partial}{\partial v}\left(X_{\exp (u X) \exp (v Y)\left(x_{0}\right)}\right) \\ & =J_{X}\left(\exp (u X) \exp (v Y)\left(x_{0}\right)\right) \frac{\partial}{\partial v}\left(\exp (u X) \exp (v Y)\left(x_{0}\right)\right) \\ & =J_{X}\left(\exp (u X) \exp (v Y)\left(x_{0}\right)\right) G_{v}(u) \end{align} Let now $H_{v}(u)=Y_{\exp (u X) \exp (v Y)\left(x_{0}\right)}$ , observe that $H_{v}(0)=Y_{\exp (v Y)\left(x_{0}\right)}$ and that \begin{aligned} H_{v}^{\prime}(u) & =J_{Y}\left(\exp (u X)\exp (v Y) x_{0}\right) \frac{\partial}{\partial u}\left(\exp (u X) \exp (v Y) x_{0}\right) \\ & =J_{Y}\left(\exp (u X) \exp (v Y) x_{0}\right) X_{\exp (u X) \exp (v Y) (x_{0})}  \end{aligned} Since the vector fields $X$ and $Y$ commute, by (1.7), $J_{X}(x)Y_{x}=J_{Y}(x) X_{x}$ and therefore \begin{aligned} H_{v}^{\prime}(u) & =J_{X}\left(\exp (u X) \exp (v Y) x_{0}\right) Y_{\exp (u X) \exp (v Y) x_{0}} \\ & =J_{X}\left(\exp (u  X) \exp (v Y) x_{0}\right) H_{v}(u) \end{aligned} It follows that $H_{v}$ and $G_{v}$ satisfies the same Cauchy problem so that $$\frac{\partial F}{\partial v}(u, v)=G_{v}(u)=H_{v}(u)=Y_{\exp (u X)  \exp (v Y)\left(x_{0}\right)} .$$ Hence $\frac{\partial F}{\partial v}(t, t)=Y_{\varphi(t)} $ and (1.8) follows. where (1.7) is $$[X,Y]_x=J_Y(x)X_x-J_X(x)Y_x$$ $J_X$ is the Jacobian of the map $x\mapsto X_x$ . My main questions is at \begin{align} G_{v}^{\prime}(u) & =\frac{\partial^{2} F}{\partial v \partial u}(u, v)=\frac{\partial}{\partial v}\left(X_{\exp (u X) \exp (v Y)\left(x_{0}\right)}\right) \\ & =J_{X}\left(\exp (u X) \exp (v Y)\left(x_{0}\right)\right) \frac{\partial}{\partial v}\left(\exp (u X) \exp (v Y)\left(x_{0}\right)\right) \\ & =J_{X}\left(\exp (u X) \exp (v Y)\left(x_{0}\right)\right) G_{v}(u) \end{align} There should be $$G_{v}^{\prime}(u)=\frac{\partial^2 F}{\partial u\partial v}(u,v),$$ why they can commute? It's not obviously for me, and there taking derivative for vector field and Jacobian make me confuse, it can be rewritten more strictly? Any anwser and comment are appreciate! I have recognized this theorem can be corollary of Baker-Campbell-Hausdorff formula, but I wonder is it reasonable for the original proof. Thanks for comment, it's necessary to give some definition. So $\Omega$ is a domain in some Lie group, and Lie bracket $[X,Y]$ as standard definition, where $exp(tX)(x_0)$ defined as a $C^1$ integral curve $\varphi(t)$ , is the solution as Cauchy problem \begin{align} \begin{cases} \varphi'(t)=X_{\varphi(t)}\\ \varphi(0)=x_0 \end{cases} \end{align}","I'm reading the book Hörmander Operators by Marco Bramanti and Luca Brandolini World Scientific, 2023 . I had a problem when reading the proof of the following theorem: Theorem 1.9 Let and be smooth vector fields in a domain such that . Let . There exist such that for every Proof . The second identity easily follows from the first one. To prove the first identity, let . Clearly . We will show that and therefore . Let now it follows that . For the first term we have In order to evaluate we set , we observe that and that Let now , observe that and that Since the vector fields and commute, by (1.7), and therefore It follows that and satisfies the same Cauchy problem so that Hence and (1.8) follows. where (1.7) is is the Jacobian of the map . My main questions is at There should be why they can commute? It's not obviously for me, and there taking derivative for vector field and Jacobian make me confuse, it can be rewritten more strictly? Any anwser and comment are appreciate! I have recognized this theorem can be corollary of Baker-Campbell-Hausdorff formula, but I wonder is it reasonable for the original proof. Thanks for comment, it's necessary to give some definition. So is a domain in some Lie group, and Lie bracket as standard definition, where defined as a integral curve , is the solution as Cauchy problem","X Y \Omega [X, Y] \equiv 0 x_{0} \in \Omega \varepsilon>0 |t|<\varepsilon  \begin{array}{l} \exp (t X) \exp (t Y)\left(x_{0}\right)=\exp
 (t(X+Y))\left(x_{0}\right) ; \\ \exp (-t X) \exp (-t Y) \exp (t X)
\exp (t Y)\left(x_{0}\right)=x_{0} \end{array} \varphi(t)=\exp (t X) \exp (t
 Y)\left(x_{0}\right) \varphi(0)=x_{0} \varphi^{\prime}(t)=X_{\varphi(t)}+Y_{\varphi(t)}\tag{1.8} \varphi(t)=\exp (t(X+Y))\left(x_{0}\right)  F(u, v)=\exp (u X) \exp (v Y)\left(x_{0}\right), \varphi^{\prime}(t)=\frac{\partial F}{\partial u}(t,t)+\frac{\partial F}{\partial v}(t, t)  \frac{\partial F}{\partial u}(t, t)=X_{\exp (t X) \exp (tY)\left(x_{0}\right)}=X_{\varphi(t)} \frac{\partial F}{\partial v}(t, t) G_{v}(u)=\frac{\partial F}{\partial v}(u, v) G_{v}(0)=   Y_{\exp (v Y)\left(x_{0}\right)} \begin{align} G_{v}^{\prime}(u) & =\frac{\partial^{2} F}{\partial v
\partial u}(u, v)=\frac{\partial}{\partial v}\left(X_{\exp (u X) \exp
(v Y)\left(x_{0}\right)}\right) \\ & =J_{X}\left(\exp (u X) \exp (v
Y)\left(x_{0}\right)\right) \frac{\partial}{\partial v}\left(\exp (u
X) \exp (v Y)\left(x_{0}\right)\right) \\ & =J_{X}\left(\exp (u X)
\exp (v Y)\left(x_{0}\right)\right) G_{v}(u) \end{align} H_{v}(u)=Y_{\exp (u X) \exp (v Y)\left(x_{0}\right)} H_{v}(0)=Y_{\exp (v Y)\left(x_{0}\right)} \begin{aligned} H_{v}^{\prime}(u) & =J_{Y}\left(\exp (u X)\exp (v Y)
x_{0}\right) \frac{\partial}{\partial u}\left(\exp (u X) \exp (v Y)
x_{0}\right) \\ & =J_{Y}\left(\exp (u X) \exp (v Y) x_{0}\right)
X_{\exp (u X) \exp (v Y) (x_{0})} 
\end{aligned} X Y J_{X}(x)Y_{x}=J_{Y}(x) X_{x} \begin{aligned} H_{v}^{\prime}(u) & =J_{X}\left(\exp (u X) \exp (v Y)
x_{0}\right) Y_{\exp (u X) \exp (v Y) x_{0}} \\ & =J_{X}\left(\exp (u
 X) \exp (v Y) x_{0}\right) H_{v}(u) \end{aligned} H_{v} G_{v} \frac{\partial F}{\partial v}(u, v)=G_{v}(u)=H_{v}(u)=Y_{\exp (u X)
 \exp (v Y)\left(x_{0}\right)} . \frac{\partial F}{\partial v}(t, t)=Y_{\varphi(t)}  [X,Y]_x=J_Y(x)X_x-J_X(x)Y_x J_X x\mapsto X_x \begin{align} G_{v}^{\prime}(u) & =\frac{\partial^{2} F}{\partial v
\partial u}(u, v)=\frac{\partial}{\partial v}\left(X_{\exp (u X) \exp
(v Y)\left(x_{0}\right)}\right) \\ & =J_{X}\left(\exp (u X) \exp (v
Y)\left(x_{0}\right)\right) \frac{\partial}{\partial v}\left(\exp (u
X) \exp (v Y)\left(x_{0}\right)\right) \\ & =J_{X}\left(\exp (u X)
\exp (v Y)\left(x_{0}\right)\right) G_{v}(u) \end{align} G_{v}^{\prime}(u)=\frac{\partial^2 F}{\partial u\partial v}(u,v), \Omega [X,Y] exp(tX)(x_0) C^1 \varphi(t) \begin{align}
\begin{cases}
\varphi'(t)=X_{\varphi(t)}\\
\varphi(0)=x_0
\end{cases}
\end{align}","['differential-geometry', 'vector-fields']"
9,Vector field with almost non-periodic orbits,Vector field with almost non-periodic orbits,,"Let $M$ be an n-dimensional smooth manifold (Open or compact). I want to know if it is possible to construct an smooth vector field with exactly one singularity, such that the set of periodic integral curves has null n-dimensional Lebesgue measure. Any reference/idea is appreciate.","Let be an n-dimensional smooth manifold (Open or compact). I want to know if it is possible to construct an smooth vector field with exactly one singularity, such that the set of periodic integral curves has null n-dimensional Lebesgue measure. Any reference/idea is appreciate.",M,"['differential-geometry', 'differential-topology', 'dynamical-systems', 'vector-fields']"
10,A graph with radius of curvature $≥1$ can't have more than 2 distinct real intersection points with a circle of radius 1,A graph with radius of curvature  can't have more than 2 distinct real intersection points with a circle of radius 1,≥1,"Is the following true? If the graph of a continuously twice differentiable function $y(x)$ and the radius of curvature $|\frac1\kappa |$ is $\gt 1$ at all points on the graph (e.g. $y=\sin(x),x\in(0,\frac\pi2)$ ), then it can't have more than $2$ distinct real intersection points with a circle of radius $1$ . Related: How the curvature of a curve affects its behavior relative to a circle What is the largest circle that fits in $\sin(x)?$ how to prove that the curvature of sin x is greatest at its extremum? I have a rough idea: From curvature formula for a graph: $$\kappa =\frac{y''}{\left(1+y'^{\,2}\right)^{\frac {3}{2}}}$$ so $$\int\kappa~\mathrm{d}s =\int\frac{y''(x)}{\left(1+y'(x)^2\right)^{\frac {3}{2}}}~\mathrm{d}s=\int\frac{y''(x)}{\left(1+y'(x)^2\right)}~\mathrm{d}x=\arctan y'(x)$$ so, if $s$ is arc-length parameter and there is smooth function $\phi$ such that $(\cos\phi(s),\sin\phi(s))$ is the unit tangent vector, then $\int_{s_0}^{s_1}\kappa~\mathrm{d}s=\phi(s_1)-\phi(s_0)$ If the graph intersects a circle of radius $1$ at three points $A,B,C$ , and the graph is lower than the circle between $A,B$ and the graph is higher than the circle between $B,C$ , then $\phi$ of the graph at $A$ is less than $\phi$ of the circle at $A$ , but $\phi$ of the graph at $B$ is greater than $\phi$ of the circle at $B$ , so $\phi(s_B)-\phi(s_A)$ is greater than that of the circle, so the integral of $κ$ from $A$ to $B$ is greater than that of the circle, but $κ$ of the graph is assumed to be less than than curvature $1$ of the circle, contradiction.","Is the following true? If the graph of a continuously twice differentiable function and the radius of curvature is at all points on the graph (e.g. ), then it can't have more than distinct real intersection points with a circle of radius . Related: How the curvature of a curve affects its behavior relative to a circle What is the largest circle that fits in $\sin(x)?$ how to prove that the curvature of sin x is greatest at its extremum? I have a rough idea: From curvature formula for a graph: so so, if is arc-length parameter and there is smooth function such that is the unit tangent vector, then If the graph intersects a circle of radius at three points , and the graph is lower than the circle between and the graph is higher than the circle between , then of the graph at is less than of the circle at , but of the graph at is greater than of the circle at , so is greater than that of the circle, so the integral of from to is greater than that of the circle, but of the graph is assumed to be less than than curvature of the circle, contradiction.","y(x) |\frac1\kappa | \gt 1 y=\sin(x),x\in(0,\frac\pi2) 2 1 \kappa =\frac{y''}{\left(1+y'^{\,2}\right)^{\frac {3}{2}}} \int\kappa~\mathrm{d}s =\int\frac{y''(x)}{\left(1+y'(x)^2\right)^{\frac {3}{2}}}~\mathrm{d}s=\int\frac{y''(x)}{\left(1+y'(x)^2\right)}~\mathrm{d}x=\arctan y'(x) s \phi (\cos\phi(s),\sin\phi(s)) \int_{s_0}^{s_1}\kappa~\mathrm{d}s=\phi(s_1)-\phi(s_0) 1 A,B,C A,B B,C \phi A \phi A \phi B \phi B \phi(s_B)-\phi(s_A) κ A B κ 1","['differential-geometry', 'curvature', 'plane-curves']"
11,Computing the connection form $\omega_1^2$ for $ds^2 = dt^2 + f(t)^2d\theta^2$,Computing the connection form  for,\omega_1^2 ds^2 = dt^2 + f(t)^2d\theta^2,"For $S^1 \times I$ where $I \subset \mathbb{R}$ consider the following metric $$ds^2 = dt^2 + f(t)^2d\theta^2.$$ I want to compute $\omega_1^2$ , the connection form. I let $\theta^1 = dt$ and $\theta^2 = f(t)d\theta$ . By the compatibility with the metric and the first structure equations we have the system \begin{align*}d\theta^1 + \omega_1^1\wedge \theta^1 + \omega^1_2 \wedge \theta^2 & = 0,\\ d\theta^2 + \omega_1^2 \wedge \theta^1 + \omega_2^2 \wedge \theta^2 & = 0. \end{align*} Write $\omega_i^j = a_i^j\theta^1 + \overline{a_i^j}\theta^2$ . From the previous system we get \begin{align*} a_1^2 & = -\overline{a_1^1},\\ \frac{f'(t)}{f(t)} & = \overline{a_1^2} + a_2^2. \end{align*} I can't fully describe $\omega_1^2$ with this information. Is there something more that I am forgetting and can help me conclude? I thought about using the second structural equation $$\Omega_1^2 = d\omega_1^2 + \omega_1^1 \wedge \omega^1_2 + \omega_2^1 \wedge \omega^2_2,$$ knowing that $\Omega_1^2 = K = -f''(t)/f(t)$ but it doesn't seem helpful. Question: Is it true that $\omega_1^1 = \omega_2^2 = 0$ ? Why is it? Because then we get $\omega_1^2 = -f'(t)d\theta$ which agrees (up to a minus sign?) with the expression that on wikipedia $$\omega_i^j = \sum_k \Gamma_{ki}^j\theta^k.$$ Thanks!","For where consider the following metric I want to compute , the connection form. I let and . By the compatibility with the metric and the first structure equations we have the system Write . From the previous system we get I can't fully describe with this information. Is there something more that I am forgetting and can help me conclude? I thought about using the second structural equation knowing that but it doesn't seem helpful. Question: Is it true that ? Why is it? Because then we get which agrees (up to a minus sign?) with the expression that on wikipedia Thanks!","S^1 \times I I \subset \mathbb{R} ds^2 = dt^2 + f(t)^2d\theta^2. \omega_1^2 \theta^1 = dt \theta^2 = f(t)d\theta \begin{align*}d\theta^1 + \omega_1^1\wedge \theta^1 + \omega^1_2 \wedge \theta^2 & = 0,\\
d\theta^2 + \omega_1^2 \wedge \theta^1 + \omega_2^2 \wedge \theta^2 & = 0.
\end{align*} \omega_i^j = a_i^j\theta^1 + \overline{a_i^j}\theta^2 \begin{align*}
a_1^2 & = -\overline{a_1^1},\\
\frac{f'(t)}{f(t)} & = \overline{a_1^2} + a_2^2.
\end{align*} \omega_1^2 \Omega_1^2 = d\omega_1^2 + \omega_1^1 \wedge \omega^1_2 + \omega_2^1 \wedge \omega^2_2, \Omega_1^2 = K = -f''(t)/f(t) \omega_1^1 = \omega_2^2 = 0 \omega_1^2 = -f'(t)d\theta \omega_i^j = \sum_k \Gamma_{ki}^j\theta^k.","['differential-geometry', 'riemannian-geometry', 'connections']"
12,Is this Proof on 1-Form with Compact Support Correct?,Is this Proof on 1-Form with Compact Support Correct?,,"Question Let $\alpha=\sum_{i=1}^m\alpha_i(x)dx^i\in\Omega^1(\mathbb{R}^m)$ be a closed 1-form on $\mathbb{R}^m$ , and $f(x)=\sum_{i=1}^mx^i\int_0^1\alpha^i(ux)du$ define a smooth function satisfying $df=\alpha$ . Show that if $\alpha$ has compact support and $m>1$ , then there exists a smooth function $g$ with compact support such that $dg=\alpha$ . Show that this doesn't need to hold for $m=1$ . Attempt Since $\alpha$ has a compact support in $\mathbb{R}^m$ with $m>1$ , by the Poincaré lemma, there exists a function $g$ such that $dg=\alpha$ . Let’s construct $g$ so that it has compact support. Consider a bump function $\beta$ that is 1 on the support of $\alpha$ , and smoothly decreases to zero outside a slightly larger compact set. Then $\beta g$ will have compact support and still satisfy: $d(\beta g)=\beta dg=\beta \alpha=\alpha$ . (because $\alpha=0$ outside the support of $\alpha$ , so is $d\alpha$ ). Now, suppose $m=1$ , then $\mathbb{R}$ is not simply connected on any bounded interval. So, the Poincaré lemma does not apply. For example, if $\alpha=dx$ on $\mathbb{R}$ , then the function $g(x)=x$ is such that $dg=dx=\alpha$ , but $g$ does not have compact support. In other words, if there is a function with compact support on $\mathbb{R}$ whose derivative is $dx$ everywhere, the integral of such function will have to be constant outside its support, which would contradict the fact that the derivative is $dx$ . Note I am not sure I attempted this the right way, or at least there are a couple of things I left out in this proof. Your help will be appreciated.","Question Let be a closed 1-form on , and define a smooth function satisfying . Show that if has compact support and , then there exists a smooth function with compact support such that . Show that this doesn't need to hold for . Attempt Since has a compact support in with , by the Poincaré lemma, there exists a function such that . Let’s construct so that it has compact support. Consider a bump function that is 1 on the support of , and smoothly decreases to zero outside a slightly larger compact set. Then will have compact support and still satisfy: . (because outside the support of , so is ). Now, suppose , then is not simply connected on any bounded interval. So, the Poincaré lemma does not apply. For example, if on , then the function is such that , but does not have compact support. In other words, if there is a function with compact support on whose derivative is everywhere, the integral of such function will have to be constant outside its support, which would contradict the fact that the derivative is . Note I am not sure I attempted this the right way, or at least there are a couple of things I left out in this proof. Your help will be appreciated.",\alpha=\sum_{i=1}^m\alpha_i(x)dx^i\in\Omega^1(\mathbb{R}^m) \mathbb{R}^m f(x)=\sum_{i=1}^mx^i\int_0^1\alpha^i(ux)du df=\alpha \alpha m>1 g dg=\alpha m=1 \alpha \mathbb{R}^m m>1 g dg=\alpha g \beta \alpha \beta g d(\beta g)=\beta dg=\beta \alpha=\alpha \alpha=0 \alpha d\alpha m=1 \mathbb{R} \alpha=dx \mathbb{R} g(x)=x dg=dx=\alpha g \mathbb{R} dx dx,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'differential-forms']"
13,Geodesics in Hyperbolic Disk,Geodesics in Hyperbolic Disk,,"Let $\Gamma \le \operatorname{PSL}(2,\mathbb{R})$ be a discrete subgroup and $\Sigma:=\mathbb{D}^2/\Gamma$ be the quotient. Then $\Sigma$ is a hyperbolic surface whose universal cover is $\mathbb{D}^2$ and the fundamental group $\pi_1(\Sigma,x)$ ( $x\in\Sigma$ ) is isomorphic to $\Gamma$ . Fix a point $\tilde{x}\in\mathbb{D}^2$ over $x$ . For two closed geodesics $\alpha, \beta:S^1(\cong \mathbb{R}/\mathbb{Z})\rightarrow \Sigma$ , which are elements of $\pi_1(\Sigma,x)$ (so $\alpha(0)=\alpha(1)=\beta(0)=\beta(1)=x$ ), let $\tilde{\alpha}_0, \tilde{\beta}_0:\mathbb{R}\rightarrow\mathbb{D}^2$ be the liftings of $\alpha, \beta$ , respectively, with $\tilde{\alpha}_0(0)=\tilde{\beta}_0(0)=\tilde{x}$ . Then let $\tilde{\alpha}_1:\mathbb{R}\rightarrow \mathbb{D}^2$ be the lifting of $\alpha$ with $\tilde{\alpha}_1(0)=\tilde{\beta}_0(1)$ , and $\tilde{\beta}_1:\mathbb{R}\rightarrow \mathbb{D}^2$ the lifting of $\beta$ with $\tilde{\beta}_1(0)=\tilde{\alpha}_0(1)$ . My claim is that $\tilde{\alpha}_0$ , $\tilde{\beta}_0$ , $ \tilde{\alpha}_1$ and $\tilde{\beta}_1$ do not make an embedded quadrangle in $\mathbb{D}^2$ . In the case the loops are not assumed to be geodesics, I already know that there are counterexamples, see Paths in the hyperbolic disk . I tried prove the claim with geodesics (or minimally meeting curves) with Gauss-Bonnet theorem, but it gave me only a restriction between angles. Can I show this using another techniques in hyperbolic geometry or find some counterexamples? Any help or hint will be appreciated.","Let be a discrete subgroup and be the quotient. Then is a hyperbolic surface whose universal cover is and the fundamental group ( ) is isomorphic to . Fix a point over . For two closed geodesics , which are elements of (so ), let be the liftings of , respectively, with . Then let be the lifting of with , and the lifting of with . My claim is that , , and do not make an embedded quadrangle in . In the case the loops are not assumed to be geodesics, I already know that there are counterexamples, see Paths in the hyperbolic disk . I tried prove the claim with geodesics (or minimally meeting curves) with Gauss-Bonnet theorem, but it gave me only a restriction between angles. Can I show this using another techniques in hyperbolic geometry or find some counterexamples? Any help or hint will be appreciated.","\Gamma \le \operatorname{PSL}(2,\mathbb{R}) \Sigma:=\mathbb{D}^2/\Gamma \Sigma \mathbb{D}^2 \pi_1(\Sigma,x) x\in\Sigma \Gamma \tilde{x}\in\mathbb{D}^2 x \alpha, \beta:S^1(\cong \mathbb{R}/\mathbb{Z})\rightarrow \Sigma \pi_1(\Sigma,x) \alpha(0)=\alpha(1)=\beta(0)=\beta(1)=x \tilde{\alpha}_0, \tilde{\beta}_0:\mathbb{R}\rightarrow\mathbb{D}^2 \alpha, \beta \tilde{\alpha}_0(0)=\tilde{\beta}_0(0)=\tilde{x} \tilde{\alpha}_1:\mathbb{R}\rightarrow \mathbb{D}^2 \alpha \tilde{\alpha}_1(0)=\tilde{\beta}_0(1) \tilde{\beta}_1:\mathbb{R}\rightarrow \mathbb{D}^2 \beta \tilde{\beta}_1(0)=\tilde{\alpha}_0(1) \tilde{\alpha}_0 \tilde{\beta}_0 
\tilde{\alpha}_1 \tilde{\beta}_1 \mathbb{D}^2","['differential-geometry', 'hyperbolic-geometry', 'geometric-group-theory']"
14,Hodge decomposition on vector bundle-valued differential forms,Hodge decomposition on vector bundle-valued differential forms,,"Let $M$ be a compact Reimannian manifold and let $(E,h)$ be a Hermitian vector bundle over $M$ . Let $A^k(M,E)$ denote the space of $E$ -valued $k$ -forms, i.e. smooth section of the bundle $\bigwedge^kT^*M\otimes E$ . Let $D$ be a flat Hermitian connection on $(E,h)$ (where 'Hermitian' means $D$ is compatible with the metric $h$ : $dh(s,t)=h(Ds,t)+h(s,Dt)$ , $\forall s,t\in A^0(M,E)$ ), and let $D^*$ denote its formal adjoint (i.e. $(D\alpha,\beta)=(\alpha,D^*\beta)$ where $(-,-)$ is the $L^2$ -inner product of $A^*(M,E)=\bigoplus_kA^k(M,E)$ induced by $h$ ). Then one can define the Laplacian w.r.t. to $D$ : $\Delta_D=-D^*D-DD^*$ . A Hodge decomposition theorem on $A^*(M,E)$ : $$A^*(M,E)=ker\Delta_D\oplus im D\oplus im D^*$$ is demonstrated in Demailly's $L^2$ Hodge Theory and Vanishing Theorems (the first chapter of the book 'Introduction to Hodge Theory'), Section 4. The proof is actually the same as the proof in the case without $E$ : to show the formally self-adjoint operator $\Delta_D$ is elliptic and to use linear elliptic PDE theory. Now I wonder wether the condition that $D$ is Hermitian can be removed. It seems to me that the only place where this condition is used is to calculate $D^*=(-1)^{...}\star D \star$ . This formula implies the principal symbol $\sigma_{D^*}(\xi)=-\xi_{\sharp}\lrcorner$ , then it follows that $\sigma_{\Delta_D}(\xi)=|\xi|^2$ : the differential operator $\Delta_D$ is elliptic. But using antilinear Hodge operators $\bar\star:A^{p,q}(M,E)\leftrightarrow A^{n-p,n-q}(M,E^*):\bar\star$ , we have $D^*=(-1)^{...}\bar\star D_{E^*}\bar\star$ even $D$ is not Hermitian. Then the same consequences still follow.","Let be a compact Reimannian manifold and let be a Hermitian vector bundle over . Let denote the space of -valued -forms, i.e. smooth section of the bundle . Let be a flat Hermitian connection on (where 'Hermitian' means is compatible with the metric : , ), and let denote its formal adjoint (i.e. where is the -inner product of induced by ). Then one can define the Laplacian w.r.t. to : . A Hodge decomposition theorem on : is demonstrated in Demailly's Hodge Theory and Vanishing Theorems (the first chapter of the book 'Introduction to Hodge Theory'), Section 4. The proof is actually the same as the proof in the case without : to show the formally self-adjoint operator is elliptic and to use linear elliptic PDE theory. Now I wonder wether the condition that is Hermitian can be removed. It seems to me that the only place where this condition is used is to calculate . This formula implies the principal symbol , then it follows that : the differential operator is elliptic. But using antilinear Hodge operators , we have even is not Hermitian. Then the same consequences still follow.","M (E,h) M A^k(M,E) E k \bigwedge^kT^*M\otimes E D (E,h) D h dh(s,t)=h(Ds,t)+h(s,Dt) \forall s,t\in A^0(M,E) D^* (D\alpha,\beta)=(\alpha,D^*\beta) (-,-) L^2 A^*(M,E)=\bigoplus_kA^k(M,E) h D \Delta_D=-D^*D-DD^* A^*(M,E) A^*(M,E)=ker\Delta_D\oplus im D\oplus im D^* L^2 E \Delta_D D D^*=(-1)^{...}\star D \star \sigma_{D^*}(\xi)=-\xi_{\sharp}\lrcorner \sigma_{\Delta_D}(\xi)=|\xi|^2 \Delta_D \bar\star:A^{p,q}(M,E)\leftrightarrow A^{n-p,n-q}(M,E^*):\bar\star D^*=(-1)^{...}\bar\star D_{E^*}\bar\star D","['differential-geometry', 'vector-bundles', 'hodge-theory']"
15,Strongly convex sets are totally normal,Strongly convex sets are totally normal,,"Let $(\mathcal{M},g)$ be a smooth Riemannian manifold. We say that an (open) subset $U \subset \mathcal{M}$ is strongly convex if and only if every pair $p$ , $q \in U$ has a unique geodesic of minimum length connecting them, and this geodesic lies completely in $U$ . Note that besides the unique minimizing geodesic, there may be other geodesics between $p$ and $q$ which do not minimize length. I have seen multiple posts which claim that any strongly convex set is totally normal, i.e. for every $p \in U$ we have that $\exp_p: \exp_p^{-1}(U) \subset T_p\mathcal{M} \to U$ is a diffeomorphism, see for example here and here . However, I can't find a reference where this is shown and failed to prove it myself. I am aware that it suffices to show the injectivity of $\exp_p$ on $\exp_p^{-1}(U)$ for every $p \in U$ . In fact, assuming we already know that $\exp_p$ is locally injective $^1$ , we can deduce that any geodesic $\gamma : \lbrack 0, b \rbrack \to \mathcal{M}$ lying in $U$ cannot seize to be minimizing: Otherwise, there would exist a cut time $0 < c < b$ such that $\gamma$ is no longer minimizing past $\lbrack 0, c\rbrack$ and one can construct at least two distinct minimizing geodesics connecting $p$ with $\gamma(c)$ . $^2$ Therefore, all geodesics lying in $U$ must be minimizing and an argument similar to this answer then yields the claim. In summary : I am looking for an argument as to why $\exp_p$ is (locally) injective on the preimage $\exp_p^{-1}(U)$ if $U$ is a strongly convex set containing $p$ . $$ $$ $\small{^1 : \text{I.e. for every} \ v \in \exp_p^{-1}(U) \ \text{there exists an open neighborhood} \ V \subset \exp_p^{-1}(U) \ \text{of} \ v \ \text{such that} \ \ \\exp_p\vert_V \ \text{is injective}.}$ $\small{^2 : \text{C.f. Proposition} \ 10.32 \ \text{b)} \ \text{in Jack Lee's }}$ Introduction to Riemannian Manifolds","Let be a smooth Riemannian manifold. We say that an (open) subset is strongly convex if and only if every pair , has a unique geodesic of minimum length connecting them, and this geodesic lies completely in . Note that besides the unique minimizing geodesic, there may be other geodesics between and which do not minimize length. I have seen multiple posts which claim that any strongly convex set is totally normal, i.e. for every we have that is a diffeomorphism, see for example here and here . However, I can't find a reference where this is shown and failed to prove it myself. I am aware that it suffices to show the injectivity of on for every . In fact, assuming we already know that is locally injective , we can deduce that any geodesic lying in cannot seize to be minimizing: Otherwise, there would exist a cut time such that is no longer minimizing past and one can construct at least two distinct minimizing geodesics connecting with . Therefore, all geodesics lying in must be minimizing and an argument similar to this answer then yields the claim. In summary : I am looking for an argument as to why is (locally) injective on the preimage if is a strongly convex set containing . Introduction to Riemannian Manifolds","(\mathcal{M},g) U \subset \mathcal{M} p q \in U U p q p \in U \exp_p: \exp_p^{-1}(U) \subset T_p\mathcal{M} \to U \exp_p \exp_p^{-1}(U) p \in U \exp_p ^1 \gamma : \lbrack 0, b \rbrack \to \mathcal{M} U 0 < c < b \gamma \lbrack 0, c\rbrack p \gamma(c) ^2 U \exp_p \exp_p^{-1}(U) U p   \small{^1 : \text{I.e. for every} \ v \in \exp_p^{-1}(U) \ \text{there exists an open neighborhood} \ V \subset \exp_p^{-1}(U) \ \text{of} \ v \ \text{such that} \ \ \\exp_p\vert_V \ \text{is injective}.} \small{^2 : \text{C.f. Proposition} \ 10.32 \ \text{b)} \ \text{in Jack Lee's }}","['differential-geometry', 'riemannian-geometry', 'geodesic']"
16,De Rham isomorphism for relative and compactly supported cohomology,De Rham isomorphism for relative and compactly supported cohomology,,"I am currently reading up on cohomology with compact supports, and am looking for a reference as to whether the De Rham isomorphism $H_\textrm{DR}^*(M)\simeq H^*(M;\mathbb R)$ exists for the compactly supported cohomologies $H_\textrm{DR,c}^*(M)$ and $H_c^*(M;\mathbb R)$ as well. I think it probably does, because I suspect two more things to be true as well: that $H_\textrm{DR,c}^*(M)$ is the direct limit of relative cohomology groups $H_\textrm{DR}^*(M,M\setminus K)$ in the same way that $H_c^*(M;\mathbb R)$ is the direct limit of $H^*(M,M\setminus K;\mathbb R)$ , and that the De Rham isomorphism $H_\textrm{DR}^*(M)\simeq H^*(M;\mathbb R)$ exists for the relative cohomology groups $H_\textrm{DR}^*(M,M\setminus K)$ and $H^*(M,M\setminus K;\mathbb R)$ too. I have however not been able to find a source for that at all, neither for the De Rham isomorphism on compactly supported cohomology nor for the two weaker statements that together would imply it. The only thing I was able to find is this answer on MathOverflow, which refers to a similar-looking theorem in a book on sheaf theory that I don't really understand. Can anyone maybe point me to a more elementary proof, or outline one here?","I am currently reading up on cohomology with compact supports, and am looking for a reference as to whether the De Rham isomorphism exists for the compactly supported cohomologies and as well. I think it probably does, because I suspect two more things to be true as well: that is the direct limit of relative cohomology groups in the same way that is the direct limit of , and that the De Rham isomorphism exists for the relative cohomology groups and too. I have however not been able to find a source for that at all, neither for the De Rham isomorphism on compactly supported cohomology nor for the two weaker statements that together would imply it. The only thing I was able to find is this answer on MathOverflow, which refers to a similar-looking theorem in a book on sheaf theory that I don't really understand. Can anyone maybe point me to a more elementary proof, or outline one here?","H_\textrm{DR}^*(M)\simeq H^*(M;\mathbb R) H_\textrm{DR,c}^*(M) H_c^*(M;\mathbb R) H_\textrm{DR,c}^*(M) H_\textrm{DR}^*(M,M\setminus K) H_c^*(M;\mathbb R) H^*(M,M\setminus K;\mathbb R) H_\textrm{DR}^*(M)\simeq H^*(M;\mathbb R) H_\textrm{DR}^*(M,M\setminus K) H^*(M,M\setminus K;\mathbb R)","['differential-geometry', 'algebraic-topology', 'reference-request', 'homology-cohomology', 'de-rham-cohomology']"
17,Derivative between topological vector spaces - equivalence in definition of tangent to $0$,Derivative between topological vector spaces - equivalence in definition of tangent to,0,"In Serge Lang's Differential and Riemannian manifold, he defined derivative between two topological vector spaces with the concept tangent to $0$ : Let $\mathbf{E}, \mathbf{F}$ be two topological vector spaces, and $\varphi$ a mapping of a neighborhood of $0$ in $\mathbf{E}$ into $\mathbf{F}$ . We say that $\varphi$ is tangent to 0 if, given a neighborhood $W$ of 0 in $\mathbf{F}$ , there exists a neighborhood $V$ of 0 in $\mathbf{E}$ such that $$ \varphi(t V) \subset o(t) W $$ for some function $o(t)$ . If both $\mathbf{E}, \mathbf{F}$ are normed, then this amounts to the usual condition $$ |\varphi(x)| \leqq|x| \psi(x) $$ with $\lim \psi(x)=0$ as $|x| \rightarrow 0$ . Let $\mathbf{E}, \mathbf{F}$ be two topological vector spaces and $U$ open in $\mathbf{E}$ . Let $f: U \rightarrow \mathbf{F}$ be a continuous map. We shall say that $f$ is differentiable at a point $x_0 \in U$ if there exists a continuous linear map $\lambda$ of $\mathbf{E}$ into $\mathbf{F}$ such that, if we let $$ f\left(x_0+y\right)=f\left(x_0\right)+\lambda y+\varphi(y) $$ for small $y$ , then $\varphi$ is tangent to 0 . It then follows trivially that $\lambda$ is uniquely determined, and we say that it is the derivative of $f$ at $x_0$ . We denote the derivative by $D f\left(x_0\right)$ or $f^{\prime}\left(x_0\right)$ . It is an element of $L(\mathbf{E}, \mathbf{F})$ I think I might understand the intuition of this tangent to 0 concept. However, why is this definition equivalent to the definition stated in the normed space case? I don't really see how to write a proof to show these definitions are equivalent. $\|\varphi(x)\|_{F}\leq \|x\|_{E} \psi(x)$ is the definition I know before, but I'm having trouble to relate to the general definition, where it specifically refers to ""given a neighborhood $W$ "". So why are these two definitions equivalent?","In Serge Lang's Differential and Riemannian manifold, he defined derivative between two topological vector spaces with the concept tangent to : Let be two topological vector spaces, and a mapping of a neighborhood of in into . We say that is tangent to 0 if, given a neighborhood of 0 in , there exists a neighborhood of 0 in such that for some function . If both are normed, then this amounts to the usual condition with as . Let be two topological vector spaces and open in . Let be a continuous map. We shall say that is differentiable at a point if there exists a continuous linear map of into such that, if we let for small , then is tangent to 0 . It then follows trivially that is uniquely determined, and we say that it is the derivative of at . We denote the derivative by or . It is an element of I think I might understand the intuition of this tangent to 0 concept. However, why is this definition equivalent to the definition stated in the normed space case? I don't really see how to write a proof to show these definitions are equivalent. is the definition I know before, but I'm having trouble to relate to the general definition, where it specifically refers to ""given a neighborhood "". So why are these two definitions equivalent?","0 \mathbf{E}, \mathbf{F} \varphi 0 \mathbf{E} \mathbf{F} \varphi W \mathbf{F} V \mathbf{E} 
\varphi(t V) \subset o(t) W
 o(t) \mathbf{E}, \mathbf{F} 
|\varphi(x)| \leqq|x| \psi(x)
 \lim \psi(x)=0 |x| \rightarrow 0 \mathbf{E}, \mathbf{F} U \mathbf{E} f: U \rightarrow \mathbf{F} f x_0 \in U \lambda \mathbf{E} \mathbf{F} 
f\left(x_0+y\right)=f\left(x_0\right)+\lambda y+\varphi(y)
 y \varphi \lambda f x_0 D f\left(x_0\right) f^{\prime}\left(x_0\right) L(\mathbf{E}, \mathbf{F}) \|\varphi(x)\|_{F}\leq \|x\|_{E} \psi(x) W","['functional-analysis', 'differential-geometry', 'manifolds', 'riemannian-geometry', 'differential-topology']"
18,Commutator formula between Hessian and Laplacian of a scalar function,Commutator formula between Hessian and Laplacian of a scalar function,,"I am looking to derive an identity I found which commutes the Hessian and the Laplacian of a scalar function $f \in C^4(M)$ on a Riemannian manifold $(M,g).$ $$\Delta \nabla_i \nabla_j f = \nabla_i \nabla_j \Delta f + (R_{jp}g_{ik} + R_{ip} g_{jk} - 2R_{kipj}) \nabla_k \nabla_p f + (\nabla_i R_{jp} + \nabla_j R_{pi} - \nabla_p R_{ij}) \nabla^p f. $$ One can note you have the Laplacian of the Hessian on the LHS of the equality, and the Hessian of the Laplacian on the RHS + some extra terms. This formula It can be found in page 28 of these Lecture Notes: https://www.math.uci.edu/~jviaclov/courses/865_F07.html The problem with understanding the derivation he does there is the notation, as I am more familiar with index notation, so that the Laplacian of a scalar function for example is expressed as $\Delta f = g^{ik}u_{,ik}$ and the Hessian is $u_{,ij}.$ First, $\Delta \nabla_i \nabla_j f$ is the Laplacian of the Hessian, so that in index notation it would be $g^{kl}(f_{,ij})_{,kl},$ whilst he writes $g^{kl}\nabla_k \nabla_l \nabla_i \nabla_j f.$ From this I understand that he is doing $g^{kl}\nabla_k \nabla_l (\nabla_i \nabla_j f)$ and he operates from the left. But then he does $g^{kl}\nabla_k \nabla_l \nabla_i \nabla_j f = g^{kl} \nabla_k (\nabla_l \nabla_i \nabla_j f),$ which would mean $g^{kl}(f_{,lij})_{,k}$ but this does not seem to work well in index notation and I can no longer follow through his steps. The following question helps me but I would need two covariant derivatives instead of one: Commutator of laplacian and covariant derivative of a tensor","I am looking to derive an identity I found which commutes the Hessian and the Laplacian of a scalar function on a Riemannian manifold One can note you have the Laplacian of the Hessian on the LHS of the equality, and the Hessian of the Laplacian on the RHS + some extra terms. This formula It can be found in page 28 of these Lecture Notes: https://www.math.uci.edu/~jviaclov/courses/865_F07.html The problem with understanding the derivation he does there is the notation, as I am more familiar with index notation, so that the Laplacian of a scalar function for example is expressed as and the Hessian is First, is the Laplacian of the Hessian, so that in index notation it would be whilst he writes From this I understand that he is doing and he operates from the left. But then he does which would mean but this does not seem to work well in index notation and I can no longer follow through his steps. The following question helps me but I would need two covariant derivatives instead of one: Commutator of laplacian and covariant derivative of a tensor","f \in C^4(M) (M,g). \Delta \nabla_i \nabla_j f = \nabla_i \nabla_j \Delta f + (R_{jp}g_{ik} + R_{ip} g_{jk} - 2R_{kipj}) \nabla_k \nabla_p f + (\nabla_i R_{jp} + \nabla_j R_{pi} - \nabla_p R_{ij}) \nabla^p f.
 \Delta f = g^{ik}u_{,ik} u_{,ij}. \Delta \nabla_i \nabla_j f g^{kl}(f_{,ij})_{,kl}, g^{kl}\nabla_k \nabla_l \nabla_i \nabla_j f. g^{kl}\nabla_k \nabla_l (\nabla_i \nabla_j f) g^{kl}\nabla_k \nabla_l \nabla_i \nabla_j f = g^{kl} \nabla_k (\nabla_l \nabla_i \nabla_j f), g^{kl}(f_{,lij})_{,k}","['differential-geometry', 'riemannian-geometry', 'index-notation']"
19,Who named the first fundamental form?,Who named the first fundamental form?,,"This is a historic question for which I couldn't find an answer on google or on the math history books I have at hand. The first fundamental form $I$ of a surface $S$ embedded in $\mathbb{R}^3$ is, indeed, a differential form: a choice of bilinear map $I_x\colon T_xS \times T_xS \to \mathbb{R}$ for the tangent space of $x \in S$ that is ""differentiable"" in $x$ in the suitable sense. However, since metric considerations about surfaces goes way earlier than the language of differential forms (say, Gauss' Theorema Egregium dates from 1827, Cartan's paper on differential forms is from 1899), I assume either the first fundamental form didn't have a name, or was called differently, or ""form"" meant something else back then. In the 1902 Princeton translation of Gauss 1827 paper, what we now understand as the first fundamental form is referred to as the ""line element"", as Gauss manipulates the expression $\sqrt{Edp^2 + 2Fdpdq + Gdq^2}$ in the notation therein. Who first named the first fundamental form?","This is a historic question for which I couldn't find an answer on google or on the math history books I have at hand. The first fundamental form of a surface embedded in is, indeed, a differential form: a choice of bilinear map for the tangent space of that is ""differentiable"" in in the suitable sense. However, since metric considerations about surfaces goes way earlier than the language of differential forms (say, Gauss' Theorema Egregium dates from 1827, Cartan's paper on differential forms is from 1899), I assume either the first fundamental form didn't have a name, or was called differently, or ""form"" meant something else back then. In the 1902 Princeton translation of Gauss 1827 paper, what we now understand as the first fundamental form is referred to as the ""line element"", as Gauss manipulates the expression in the notation therein. Who first named the first fundamental form?",I S \mathbb{R}^3 I_x\colon T_xS \times T_xS \to \mathbb{R} x \in S x \sqrt{Edp^2 + 2Fdpdq + Gdq^2},"['differential-geometry', 'terminology', 'math-history']"
20,Is every smooth manifold the solution set of finitely many equations?,Is every smooth manifold the solution set of finitely many equations?,,In the case of affine varieties we have finitely many (polynomial) equations defining the variety. It is a (smooth) manifold iff it satisfies the Jacobian criterion. I wonder whether this can be generalized in the following sense: Is it possible for every smooth submanifold $M\subseteq \mathbb{R}^n$ to find a smooth map $f: \mathbb{R}^k \rightarrow \mathbb{R}^l$ and a regular value $q\in \mathbb{R}^l$ of $f$ such that $M=f^{-1}(q)$?,In the case of affine varieties we have finitely many (polynomial) equations defining the variety. It is a (smooth) manifold iff it satisfies the Jacobian criterion. I wonder whether this can be generalized in the following sense: Is it possible for every smooth submanifold $M\subseteq \mathbb{R}^n$ to find a smooth map $f: \mathbb{R}^k \rightarrow \mathbb{R}^l$ and a regular value $q\in \mathbb{R}^l$ of $f$ such that $M=f^{-1}(q)$?,,['smooth-manifolds']
21,Relation between square root of matrix representation of Riemannian metric and Christoffel symbols,Relation between square root of matrix representation of Riemannian metric and Christoffel symbols,,"Let $(M,g)$ be a Riemannian manifold of dimension $n$ and let $g_{ij}$ be the matrix of the components of $g$ in coordinates. Since $g_{ij}$ is symmetric and positive-definite, it can diagonalized by $g_{ij} = PDP^{T}$ , with $D = \text{diag}(\lambda_1, \ldots, \lambda_n)$ diagonal and $P$ orthogonal. For $s \in \mathbb{R}$ , define the matrix power $g_{ij}^s := PD^sP^T$ , where $D^s = \text{diag}(\lambda_1^s, \ldots, \lambda_n^s)$ . Is there a link between the matrix $g_{ij}^{-1/2}$ and the Christoffel symbols $\Gamma^i_{jk}$ ? For instance, denoting the matrix by $G := g_{ij}$ , if I consider the derivative: \begin{equation}    \frac{\partial G^{-1/2}}{\partial x^k} = -\frac{1}{2} G^{-1}\frac{\partial G}{\partial x^k}G^{-1/2}, \end{equation} several ""ingredients"" of the Christoffel symbols appear. I know that the following holds when the Christoffel are contracted: \begin{equation}    \Gamma^i_{ij} = \frac{1}{2}g_{ik}^{-1}\frac{\partial g_{ik}}{\partial x^j}, \end{equation} but I'd be interested to know if a relation involving $g_{ij}^{-1/2}$ exists before contraction. On another note, I derived the expression of the derivative of $G^{-1/2}$ using the usual approach when taking derivatives of matrices (i.e., taking the derivative of the identity $G^{-1/2}GG^{-1/2} = I$ ), but from I read in this paper https://epubs.siam.org/doi/10.1137/S089547989528274X (Theorem 3.5 with $\alpha = -1/2$ ), there might be additional terms... I try to interpret the following ""symmetry"" relation on the matrix components of a metric: \begin{equation} g_{ti}^{-1/2}\frac{\partial g_{kj}^{-1/2}}{\partial x^t} = g_{tj}^{-1/2}\frac{\partial g_{ki}^{-1/2}}{\partial x^t} \end{equation} Could this be a relation between Christoffel symbols? For context, I am trying to reinterpret some approaches in numerical geometry in engineering using differential geometry, and I need to reverse-engineer some results to try and make sense of them on manifolds. For the first question, I consider an isometry $F:U \to M$ between $(U \subseteq \mathbb{R}^2, \bar{g})$ and $(M,g)$ , where $\bar{g}$ is the Euclidean metric. If $y^j$ are coordinates on $U$ , it is my understanding that in coordinates, the components of the differential map $dF$ satisfy: \begin{equation} \frac{\partial F^i}{\partial y^j} = g_{ik}^{-1/2}O_{kj} \end{equation} for some orthogonal matrix $O$ , since $F$ pulls back the metric $g$ to the Euclidean metric, that is: \begin{equation} \bar{g}_{ij} = \delta_{ij} = \left(\frac{\partial F^k}{\partial y^i}\right)^T g_{kl} \frac{\partial F^l}{\partial y^j}, \end{equation} which is satisfied if the Jacobian matrix has the form written above. Thus, the square root matrix of 1. originates from this. The symmetry relation of 2. is obtained as follows: I consider a map $F:U \to M$ that is not necessarily an isometry or even smooth, and I suppose that I can write its Jacobian matrix in coordinates as: \begin{equation} \frac{\partial F^i}{\partial y^j} = g_{ik}^{-1/2}R_{kj}, \end{equation} with $R$ a rotation matrix. Then I consider what kind of constraints there should be on the components of the metric to have at least a $C^2$ map. The symmetry relation is obtained by imposing that the second derivatives of $F^i$ are equal, to ensure $C^2$ continuity. Please feel free to correct any nonsense in what I said, I am learning DG on my own using Lee's Introduction to smooth and Riemannian manifolds. Thanks for your help!","Let be a Riemannian manifold of dimension and let be the matrix of the components of in coordinates. Since is symmetric and positive-definite, it can diagonalized by , with diagonal and orthogonal. For , define the matrix power , where . Is there a link between the matrix and the Christoffel symbols ? For instance, denoting the matrix by , if I consider the derivative: several ""ingredients"" of the Christoffel symbols appear. I know that the following holds when the Christoffel are contracted: but I'd be interested to know if a relation involving exists before contraction. On another note, I derived the expression of the derivative of using the usual approach when taking derivatives of matrices (i.e., taking the derivative of the identity ), but from I read in this paper https://epubs.siam.org/doi/10.1137/S089547989528274X (Theorem 3.5 with ), there might be additional terms... I try to interpret the following ""symmetry"" relation on the matrix components of a metric: Could this be a relation between Christoffel symbols? For context, I am trying to reinterpret some approaches in numerical geometry in engineering using differential geometry, and I need to reverse-engineer some results to try and make sense of them on manifolds. For the first question, I consider an isometry between and , where is the Euclidean metric. If are coordinates on , it is my understanding that in coordinates, the components of the differential map satisfy: for some orthogonal matrix , since pulls back the metric to the Euclidean metric, that is: which is satisfied if the Jacobian matrix has the form written above. Thus, the square root matrix of 1. originates from this. The symmetry relation of 2. is obtained as follows: I consider a map that is not necessarily an isometry or even smooth, and I suppose that I can write its Jacobian matrix in coordinates as: with a rotation matrix. Then I consider what kind of constraints there should be on the components of the metric to have at least a map. The symmetry relation is obtained by imposing that the second derivatives of are equal, to ensure continuity. Please feel free to correct any nonsense in what I said, I am learning DG on my own using Lee's Introduction to smooth and Riemannian manifolds. Thanks for your help!","(M,g) n g_{ij} g g_{ij} g_{ij} = PDP^{T} D = \text{diag}(\lambda_1, \ldots, \lambda_n) P s \in \mathbb{R} g_{ij}^s := PD^sP^T D^s = \text{diag}(\lambda_1^s, \ldots, \lambda_n^s) g_{ij}^{-1/2} \Gamma^i_{jk} G := g_{ij} \begin{equation}
   \frac{\partial G^{-1/2}}{\partial x^k} = -\frac{1}{2} G^{-1}\frac{\partial G}{\partial x^k}G^{-1/2},
\end{equation} \begin{equation}
   \Gamma^i_{ij} = \frac{1}{2}g_{ik}^{-1}\frac{\partial g_{ik}}{\partial x^j},
\end{equation} g_{ij}^{-1/2} G^{-1/2} G^{-1/2}GG^{-1/2} = I \alpha = -1/2 \begin{equation}
g_{ti}^{-1/2}\frac{\partial g_{kj}^{-1/2}}{\partial x^t} = g_{tj}^{-1/2}\frac{\partial g_{ki}^{-1/2}}{\partial x^t}
\end{equation} F:U \to M (U \subseteq \mathbb{R}^2, \bar{g}) (M,g) \bar{g} y^j U dF \begin{equation}
\frac{\partial F^i}{\partial y^j} = g_{ik}^{-1/2}O_{kj}
\end{equation} O F g \begin{equation}
\bar{g}_{ij} = \delta_{ij} = \left(\frac{\partial F^k}{\partial y^i}\right)^T g_{kl} \frac{\partial F^l}{\partial y^j},
\end{equation} F:U \to M \begin{equation}
\frac{\partial F^i}{\partial y^j} = g_{ik}^{-1/2}R_{kj},
\end{equation} R C^2 F^i C^2","['differential-geometry', 'riemannian-geometry']"
22,Constructing Smooth and Analytic Maps for a Given Trace $y=|x|$,Constructing Smooth and Analytic Maps for a Given Trace,y=|x|,"As we know, a curve in $2$ -dim Euclidean space is defined as a map $\alpha: I \rightarrow \mathbb{R}^2$ , where $I$ is an open interval. The set $\alpha(I) \subset \mathbb{R}^2$ represents the trace or image of the curve. The property of being smooth or analytic for a curve depends on whether the map $\alpha$ is smooth or analytic, respectively. Interestingly, the smoothness of a curve does not necessarily correlate with the smoothness of its image. For instance, the function $y = \sqrt[3]{x^2}$ is not differentiable at $x=0$ . However, we can identify an analytic map $x = t^3$ , $y = t^2$ with same trace. My question focuses on how to construct a smooth, or even an analytic, map that corresponds to the trace $y=|x|$ . For a smooth map, I have managed to construct $x = t e^{-1/t^2}$ , $y = |t| e^{-1/t^2}$ . It is verifiable that the $n$ -th derivative at $t=0$ is $0$ . How would one go about constructing an analytic map for this trace? Alternatively, is it possible to prove that no such analytic map exists for this trace?","As we know, a curve in -dim Euclidean space is defined as a map , where is an open interval. The set represents the trace or image of the curve. The property of being smooth or analytic for a curve depends on whether the map is smooth or analytic, respectively. Interestingly, the smoothness of a curve does not necessarily correlate with the smoothness of its image. For instance, the function is not differentiable at . However, we can identify an analytic map , with same trace. My question focuses on how to construct a smooth, or even an analytic, map that corresponds to the trace . For a smooth map, I have managed to construct , . It is verifiable that the -th derivative at is . How would one go about constructing an analytic map for this trace? Alternatively, is it possible to prove that no such analytic map exists for this trace?",2 \alpha: I \rightarrow \mathbb{R}^2 I \alpha(I) \subset \mathbb{R}^2 \alpha y = \sqrt[3]{x^2} x=0 x = t^3 y = t^2 y=|x| x = t e^{-1/t^2} y = |t| e^{-1/t^2} n t=0 0,"['calculus', 'differential-geometry', 'analytic-geometry']"
23,Filling a Klein bottle with four-dimensional water,Filling a Klein bottle with four-dimensional water,,"Can you fill a Klein bottle $K \subseteq \mathbb R^4$ , embedded in four dimensional Euclidean space $\mathbb R^4$ , with hyperraindroplets (hyperballs $B_\varepsilon$ ) from the outside? Will it enclose a four-dimensional region, similar to how the three-dimenaional torus $T^2 \subseteq \mathbb R^3$ partitions three-dimensional space $\mathbb R^3$ into an inside and an outside? In the case of the three-dimensional torus embedded into three-dimensional space, three-dimensional droplets cannot ""fill"" the inside from the outside without intersecting with the torus itself (there is no path for a ball which does not also lead to crossing the torus). Or will it be analogous to the Möbius band, which doesn't enclose an inside? ""Filling"" a Möbius strip with water doesn't really make sense since it's just a surface and doesn't enclose any three-dimensional volume. What throws me off is that it seems unreasonable to think that a surface can enclose a  four-dimensional volume, since analogously a curve in three dimensional space cannot enclose a three-dimensional volume. I have no real intuition behind this. I asked this somewhere else and it turns out that if $\mathcal N$ is a closed submanifold of connected $\mathcal M$ with dimension $\dim\left(\mathcal N\right) < \dim\left(\mathcal M\right) - 1$ , then $\mathcal M\setminus \mathcal N$ is (path) connected . Does this also mean that a Klein bottle does not partition $\mathbb R^4$ into an inside and an outside, since $\mathcal M\setminus \mathcal N$ is path-connected? Here: we take $K = \mathcal N \subseteq \mathcal M = \mathbb R^4$ . Even if it is path-connnected, can a hyperraindroplet freely pass through $\mathcal M\setminus \mathcal N$ ? That is, can you reach every point of $\mathcal M\setminus \mathcal N$ by translated balls $B_\varepsilon(x)$ if you squeeze $\varepsilon$ small enough?","Can you fill a Klein bottle , embedded in four dimensional Euclidean space , with hyperraindroplets (hyperballs ) from the outside? Will it enclose a four-dimensional region, similar to how the three-dimenaional torus partitions three-dimensional space into an inside and an outside? In the case of the three-dimensional torus embedded into three-dimensional space, three-dimensional droplets cannot ""fill"" the inside from the outside without intersecting with the torus itself (there is no path for a ball which does not also lead to crossing the torus). Or will it be analogous to the Möbius band, which doesn't enclose an inside? ""Filling"" a Möbius strip with water doesn't really make sense since it's just a surface and doesn't enclose any three-dimensional volume. What throws me off is that it seems unreasonable to think that a surface can enclose a  four-dimensional volume, since analogously a curve in three dimensional space cannot enclose a three-dimensional volume. I have no real intuition behind this. I asked this somewhere else and it turns out that if is a closed submanifold of connected with dimension , then is (path) connected . Does this also mean that a Klein bottle does not partition into an inside and an outside, since is path-connected? Here: we take . Even if it is path-connnected, can a hyperraindroplet freely pass through ? That is, can you reach every point of by translated balls if you squeeze small enough?",K \subseteq \mathbb R^4 \mathbb R^4 B_\varepsilon T^2 \subseteq \mathbb R^3 \mathbb R^3 \mathcal N \mathcal M \dim\left(\mathcal N\right) < \dim\left(\mathcal M\right) - 1 \mathcal M\setminus \mathcal N \mathbb R^4 \mathcal M\setminus \mathcal N K = \mathcal N \subseteq \mathcal M = \mathbb R^4 \mathcal M\setminus \mathcal N \mathcal M\setminus \mathcal N B_\varepsilon(x) \varepsilon,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'submanifold', 'klein-bottle']"
24,Properties of tangent functor,Properties of tangent functor,,"When I was learning differential geometry, I was told that differential of a function can be viewed as a functor, i.e. sending manifold into tangent space and function into its differential. Unfortunately, I believe that it's simply abstract nonsense, since I cannot find any references on the properties of tangent functor, for example, when it's exact, when it keeps injective ( a bit wired, since there are piles of injection, immersed or embedded for example ), or whether it keeps the limit or colimit. ( for finite product, it's evident ) So is there any reference for the properties of tangent functor? Thanks!","When I was learning differential geometry, I was told that differential of a function can be viewed as a functor, i.e. sending manifold into tangent space and function into its differential. Unfortunately, I believe that it's simply abstract nonsense, since I cannot find any references on the properties of tangent functor, for example, when it's exact, when it keeps injective ( a bit wired, since there are piles of injection, immersed or embedded for example ), or whether it keeps the limit or colimit. ( for finite product, it's evident ) So is there any reference for the properties of tangent functor? Thanks!",,"['differential-geometry', 'category-theory', 'tangent-spaces']"
25,Flat Maurer-Cartan connection iff flat Berry connection,Flat Maurer-Cartan connection iff flat Berry connection,,"I am studying two connections on induced representation spaces $\text{Ind}_{H}^{G} \Gamma$ , where $H \subseteq G$ are groups, and $\Gamma$ is an irrep of $H$ . The first is the canonical or $H$ -connection, which is the projection of $G$ 's Maurer-Cartan form into $H$ 's Lie algebra. A paper by Milnor classifies all such flat connections in terms of monodromy groups $\pi_1(G/H)/\ker \rho$ , induced by $\pi_1$ -irreps $\rho$ . These irreps determine the monodromy after a non-contractible closed path in the coset space. The second is the Berry connection (see here and here for mathematican description), $\langle a,\mu |\partial a,\nu\rangle$ , for ""position states"" $|a,\mu\rangle$ of a particle on the induced-rep space, where $a \in G/H$ , and $\mu,\nu$ index the irrep space of $\Gamma$ . Here a position state moves in the coset space $G/H$ , and obtains a holonomy (in physics: Berry phase or matrix) after a closed path that acts on the $\mu$ factor. The possible monodromies (physics: topological Berry phases or matrices) for non-contractible closed paths are classified by the monodromy group $H/\ker \Gamma$ . The two connections are related but not generally equal [ Eq. (4.2) here or here] . For all examples I'm aware of, the connections are zero iff the two monodromy groups match . In other words, I see that both connections are flat for a given inducing $H$ -irrep $\Gamma$ if there exists a $\pi_1$ -irrep $\rho$ such that $$ \frac{H}{\ker \Gamma} = \frac{\pi_1(G/H)}{\ker \rho}~. $$ I was hoping someone could either prove this or provide a counterexample. Here are some examples: Both connections are flat and the monodromy is trivial for the sphere, $\text{Ind}_{U(1)}^{SU(2)} 0$ , where $0$ is the trivial irrep of $U(1)$ . The above equation holds since $H/\ker\Gamma = U(1)/U(1)$ , $\pi_1$ is trivial, and its only (trivial) irrep can be picked to be $\rho$ . Both connections are not flat and the monodromy is trivial for the sphere with a monopole of nonzero strength $\lambda$ , $\text{Ind}_{U(1)}^{SU(2)} \lambda$ , where $\lambda$ is a non-trivial irrep of $U(1)$ . Conjecture holds since $H/\ker \Gamma = U(1)/\mathbb{Z}_{|\lambda|} = U(1)$ , $\pi_1$ is the same (i.e., trivial), and so it's impossible to find a $\rho$ that can fill in the above equation. Both connections are flat and the monodromy is nontrivial for the Poincare homology sphere with some inducing $A_5$ -irrep $\Gamma$ , $\text{Ind}^{SO(3)}_{A_5} \Gamma$ . The above equation holds since $\pi_1 = 2A_5$ , and so one can pick the $\pi_1$ -irrep corresponding to $\Gamma$ under the double cover to be $\rho$ .","I am studying two connections on induced representation spaces , where are groups, and is an irrep of . The first is the canonical or -connection, which is the projection of 's Maurer-Cartan form into 's Lie algebra. A paper by Milnor classifies all such flat connections in terms of monodromy groups , induced by -irreps . These irreps determine the monodromy after a non-contractible closed path in the coset space. The second is the Berry connection (see here and here for mathematican description), , for ""position states"" of a particle on the induced-rep space, where , and index the irrep space of . Here a position state moves in the coset space , and obtains a holonomy (in physics: Berry phase or matrix) after a closed path that acts on the factor. The possible monodromies (physics: topological Berry phases or matrices) for non-contractible closed paths are classified by the monodromy group . The two connections are related but not generally equal [ Eq. (4.2) here or here] . For all examples I'm aware of, the connections are zero iff the two monodromy groups match . In other words, I see that both connections are flat for a given inducing -irrep if there exists a -irrep such that I was hoping someone could either prove this or provide a counterexample. Here are some examples: Both connections are flat and the monodromy is trivial for the sphere, , where is the trivial irrep of . The above equation holds since , is trivial, and its only (trivial) irrep can be picked to be . Both connections are not flat and the monodromy is trivial for the sphere with a monopole of nonzero strength , , where is a non-trivial irrep of . Conjecture holds since , is the same (i.e., trivial), and so it's impossible to find a that can fill in the above equation. Both connections are flat and the monodromy is nontrivial for the Poincare homology sphere with some inducing -irrep , . The above equation holds since , and so one can pick the -irrep corresponding to under the double cover to be .","\text{Ind}_{H}^{G} \Gamma H \subseteq G \Gamma H H G H \pi_1(G/H)/\ker \rho \pi_1 \rho \langle a,\mu |\partial a,\nu\rangle |a,\mu\rangle a \in G/H \mu,\nu \Gamma G/H \mu H/\ker \Gamma H \Gamma \pi_1 \rho 
\frac{H}{\ker \Gamma} = \frac{\pi_1(G/H)}{\ker \rho}~.
 \text{Ind}_{U(1)}^{SU(2)} 0 0 U(1) H/\ker\Gamma = U(1)/U(1) \pi_1 \rho \lambda \text{Ind}_{U(1)}^{SU(2)} \lambda \lambda U(1) H/\ker \Gamma = U(1)/\mathbb{Z}_{|\lambda|} = U(1) \pi_1 \rho A_5 \Gamma \text{Ind}^{SO(3)}_{A_5} \Gamma \pi_1 = 2A_5 \pi_1 \Gamma \rho","['differential-geometry', 'mathematical-physics', 'vector-bundles', 'fiber-bundles', 'connections']"
26,The Stratonovich operator application,The Stratonovich operator application,,"I am self-studying https://sayanmuk.github.io/StochasticAnalysisManifolds.pdf and I am struggling with the proof of the following proposition: Proposition 2.4.2: Let $\theta$ be a 1-form on $M$ and $X$ the solution of the equation $dX_t = V_\alpha(X_t) \circ dZ_\alpha$ . Then, $$ \int_{X[0,t]} \theta = \int_{0}^{t} \theta(V_\alpha)(X_s) \circ dZ_\alpha $$ Proof: From Lemma 2.3.8, we have $dW_t = U_t^{-1} V_{\alpha}(X_t) \circ dZ_{\alpha}$ . Hence, the differential of the line integral is: $$\widetilde{\theta}(U_t) \circ dW_t = \left\langle \widetilde{\theta}(U_t), U_t^{-1} V_{\alpha}(X_t) \right\rangle \circ dZ_{\alpha} = \theta(V_{\alpha})(X_t) \circ dZ_{\alpha} $$ My problem is understanding how the Stratonovich integral was applied, or more specifically the operator $\circ$ . By definition, the Stratonovich integral relates with the Ito integral in the following way: $X_t = X_0 + \int_{0}^{t} V_\alpha(X_s) \, dZ_\alpha(s) + \frac{1}{2} \int_{0}^{t} \nabla_{V_\beta} V_\alpha(X_s) \, d\langle Z_\alpha \, dZ_\beta\rangle_s$ . I could see the second term with the covariation is very similar apart from the differential to $\langle\tilde{\theta} (U_t), U^{-1}_t V_\alpha(X_t) \rangle$ , but even so it needs to be differentiated. The first component I do not know how it would disappear. This is just a summary of my handwritten attempts. Question : Can someone explain me this first step in the proof?","I am self-studying https://sayanmuk.github.io/StochasticAnalysisManifolds.pdf and I am struggling with the proof of the following proposition: Proposition 2.4.2: Let be a 1-form on and the solution of the equation . Then, Proof: From Lemma 2.3.8, we have . Hence, the differential of the line integral is: My problem is understanding how the Stratonovich integral was applied, or more specifically the operator . By definition, the Stratonovich integral relates with the Ito integral in the following way: . I could see the second term with the covariation is very similar apart from the differential to , but even so it needs to be differentiated. The first component I do not know how it would disappear. This is just a summary of my handwritten attempts. Question : Can someone explain me this first step in the proof?","\theta M X dX_t = V_\alpha(X_t) \circ dZ_\alpha 
\int_{X[0,t]} \theta = \int_{0}^{t} \theta(V_\alpha)(X_s) \circ dZ_\alpha
 dW_t = U_t^{-1} V_{\alpha}(X_t) \circ dZ_{\alpha} \widetilde{\theta}(U_t) \circ dW_t = \left\langle \widetilde{\theta}(U_t), U_t^{-1} V_{\alpha}(X_t) \right\rangle \circ dZ_{\alpha} = \theta(V_{\alpha})(X_t) \circ dZ_{\alpha}
 \circ X_t = X_0 + \int_{0}^{t} V_\alpha(X_s) \, dZ_\alpha(s) + \frac{1}{2} \int_{0}^{t} \nabla_{V_\beta} V_\alpha(X_s) \, d\langle Z_\alpha \, dZ_\beta\rangle_s \langle\tilde{\theta} (U_t), U^{-1}_t V_\alpha(X_t) \rangle","['differential-geometry', 'stochastic-analysis']"
27,A lemma to the escape lemma (Lee' Intro to smooth manifolds Lemma 9.19),A lemma to the escape lemma (Lee' Intro to smooth manifolds Lemma 9.19),,"I am trying to prove the following lemma, that is used to prove the escape lemma (Lee's Intro to smooth manifolds  Lemma 9.19) Lemma Suppose $X$ is a smooth vector field on a smooth manifold $M$ . Let $\gamma : J \to M$ a maximum integral curve of $X$ such that $b := $ sup $(J)$ is finite. Let $t_0 \in J$ , and $K \subseteq M$ compact. Suppose $\gamma([t_0, b)) \subseteq K$ . Suppose $U$ and $V$ are relatively compact open subsets of $M$ such that $K \subseteq U$ and $\bar U \subseteq V$ . Let $\psi \in C^\infty(M )$ such that $\psi|_ \bar U \equiv 1$ and supp $(\psi) ⊂ V$ . Prove that there is a $\varepsilon > 0$ such that $(t_0 − \varepsilon, b) \subseteq J$ and $\gamma|_{(t_0−\varepsilon,b)}$ an is an integral curve of $\psi X$ . So I have no idea how to start, how can I prove this ? The following proposition can be used Proposition Let $X$ be a smooth vector field on a smooth manifold $M$ . Let $p \in M$ , and $\gamma_p : J_p \to M$ the maximum integral curve of $X$ with $\gamma_p(0) = p$ . Let $\gamma : J \to M$ be another integral curve of $X$ with $\gamma(0) = p$ . Then $J \subseteq J_p$ and $\gamma = \gamma_p|_J$ .","I am trying to prove the following lemma, that is used to prove the escape lemma (Lee's Intro to smooth manifolds  Lemma 9.19) Lemma Suppose is a smooth vector field on a smooth manifold . Let a maximum integral curve of such that sup is finite. Let , and compact. Suppose . Suppose and are relatively compact open subsets of such that and . Let such that and supp . Prove that there is a such that and an is an integral curve of . So I have no idea how to start, how can I prove this ? The following proposition can be used Proposition Let be a smooth vector field on a smooth manifold . Let , and the maximum integral curve of with . Let be another integral curve of with . Then and .","X M \gamma : J \to M X b :=  (J) t_0 \in J K \subseteq M \gamma([t_0, b)) \subseteq K U V M K \subseteq
U \bar U \subseteq V \psi \in C^\infty(M ) \psi|_ \bar U \equiv 1 (\psi) ⊂ V \varepsilon > 0 (t_0 − \varepsilon, b) \subseteq J \gamma|_{(t_0−\varepsilon,b)} \psi X X M p \in M \gamma_p : J_p \to M X \gamma_p(0) = p \gamma : J \to M X \gamma(0) = p J \subseteq J_p \gamma = \gamma_p|_J","['general-topology', 'differential-geometry', 'differential-topology', 'smooth-manifolds', 'vector-fields']"
28,Does there exist research about equation like $u_{tt}=\det(D_{x}^{2}u)+\cdots$?,Does there exist research about equation like ?,u_{tt}=\det(D_{x}^{2}u)+\cdots,"Does there exist research about equation like $$u_{tt}=\det(D_{x}^{2}u)+\cdots$$ ? That is to say, it contains second order time term $u_{tt}$ and the determination of Hessian of solution $\det(D_{x}^{2}u)$ . Recently, I have read some papers concerning Hyperbolic meaning curvature flow like the paper""The hyperbolic mean curvature flow"" by K.Smoczyk and philippe G.Lefloch on JMPA. But does there exist some research like the above question, if yes, can you offer me some paper? Thank advance.","Does there exist research about equation like ? That is to say, it contains second order time term and the determination of Hessian of solution . Recently, I have read some papers concerning Hyperbolic meaning curvature flow like the paper""The hyperbolic mean curvature flow"" by K.Smoczyk and philippe G.Lefloch on JMPA. But does there exist some research like the above question, if yes, can you offer me some paper? Thank advance.",u_{tt}=\det(D_{x}^{2}u)+\cdots u_{tt} \det(D_{x}^{2}u),"['differential-geometry', 'partial-differential-equations', 'reference-request']"
29,Growth of distance function near singularity of riemannian metric,Growth of distance function near singularity of riemannian metric,,"Let $\overline{M}$ be a projective manifold, $D$ is smooth divisor in $\overline{M}$ . Suppose $S$ is the defining section of $D$ , that is $S$ is a nontrivial meromorphic section of the line bundle $[D]$ such that $D=\{S=0\}$ . If we further suppose that $[D]$ is an ample line bundle, then it's direct to compute that $\omega_g=\frac{\sqrt{-1}}{2\pi}\partial\overline{\partial}(-\log\vert|S\vert|^2)^{\frac{n+1}{n}}$ is a Kahler metric on $M=\overline{M}\backslash D$ . The problem is that if we fix a point $x_0\in M$ , then when $x$ is sufficiently close to $D$ , the distance function $r(x)=d(x,x_0)$ is of order $O((-\log\vert|S\vert|^2)^{\frac{n+1}{2n}})$ , where $\vert|\cdot\vert|$ is some Hermitian metric on line bundle $[D]$ . This claim comes from the paper ""Complete Kahler Manifolds with Zero Ricci Curvature"", and I'm confused with this. Although the setting is complex, the problem is essentially Riemannian geometry. As far as I'm concerned, a standard process of caculating the distance function involves finding a geodesic $\gamma(t)$ connecting $x$ and $x_0$ , then use $d(x,x_0)=\int_0^1\vert|\gamma'(t)\vert|dt$ . However, in our setting, it's too complicated to carry out this process since finding a geodesic explicitly is already horrifying. Still the claim does not require a precise formula of distance function, so this may rather be a simple question where I got stuck at some stupid point. Any solution or hint is highly appreciated!","Let be a projective manifold, is smooth divisor in . Suppose is the defining section of , that is is a nontrivial meromorphic section of the line bundle such that . If we further suppose that is an ample line bundle, then it's direct to compute that is a Kahler metric on . The problem is that if we fix a point , then when is sufficiently close to , the distance function is of order , where is some Hermitian metric on line bundle . This claim comes from the paper ""Complete Kahler Manifolds with Zero Ricci Curvature"", and I'm confused with this. Although the setting is complex, the problem is essentially Riemannian geometry. As far as I'm concerned, a standard process of caculating the distance function involves finding a geodesic connecting and , then use . However, in our setting, it's too complicated to carry out this process since finding a geodesic explicitly is already horrifying. Still the claim does not require a precise formula of distance function, so this may rather be a simple question where I got stuck at some stupid point. Any solution or hint is highly appreciated!","\overline{M} D \overline{M} S D S [D] D=\{S=0\} [D] \omega_g=\frac{\sqrt{-1}}{2\pi}\partial\overline{\partial}(-\log\vert|S\vert|^2)^{\frac{n+1}{n}} M=\overline{M}\backslash D x_0\in M x D r(x)=d(x,x_0) O((-\log\vert|S\vert|^2)^{\frac{n+1}{2n}}) \vert|\cdot\vert| [D] \gamma(t) x x_0 d(x,x_0)=\int_0^1\vert|\gamma'(t)\vert|dt","['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
30,Total curvature is area of image of Gauss map,Total curvature is area of image of Gauss map,,"I am trying to solve the following exercise from the book Differential Geometry by Loring W. Tu: 5.4 Total curvature The total curvature of a smooth oriented surface $M$ in $\mathbb{R}^3$ is defined to be the integral $\int_M K$ if it exists, of the Gaussian curvature $K$ . Prove that the total curvature of $M$ is, up to sign, the area of the image of the Gauss map: $$\int_M K = \text{Area of} \ \nu(M).$$ I'm pretty sure that surfaces are assumed to be connected, otherwise this theorem is clearly false. (Consider two disjoint spheres in $\mathbb{R}^3$ with outward unit normal.) Even then I am not sure that this is true as stated. I know how to prove it in the case when $\nu$ is injective on the set of points where $K$ is non-zero. In this case the restriction of $\nu$ to this set is actually a diffeomorphism onto its image and if $dV_g$ and $dV$ are the volume forms of $M$ and $\mathbb{S}^2$ respectively, then the pullback of $dV$ with $\nu$ is just $KdV_g$ . My idea to solve the general case was to introduce a partition of unity with respect to an open cover such that on each element of the cover $\nu$ is a diffeomorphism onto its image, but I run into trouble with this approach because of the possible non-injectivity of $\nu$ . In fact when I brought this up with one of my professors, we also didn't know how to proceed and in turn tried to consider some examples. This discussion culminated in what we think is a counterexample which I will now describe. Consider the following subsets of $\mathbb{R}^3$ : $A=$ { $(x,y,z)\in \mathbb{R}^3 \vert x^2+y^2 \geq 2, z=0$ } and $B=$ { $(x,y,z)\in \mathbb{R}^3 \vert x^2+y^2+(z-1)^2 = 1, z \geq 1$ }. So $A$ is the plane $z=0$ with the open disk of radius $2$ removed and $B$ is the upper hemisphere of a unit sphere around the point $(0,0,1)$ . We can then imagine connecting these two in such a way that we get a smooth surface embedded in $\mathbb{R}^3$ . The image of the Gauss map of this surface clearly has positive volume no matter what unit normal vector field we pick, since it either contains the whole upper hemisphere or the whole lower hemisphere of $\mathbb{S}^2$ . Now consider the circle with radius $2$ in the plane $z=0$ parameterized anti-clockwise with unit speed such that it winds around only once and denote this parameterization with $\gamma$ . If we denote with $\Omega$ the surface it encloses and denote with $\kappa_N$ it's curvature with respect to the inward pointing normal relative to the plane $z=0$ then the Gauss-Bonnet formula (John M. Lee - Introduction to Riemannian Manifolds theorem 9.3) yields: $$\int_{\Omega}KdA + \int_{\gamma} \kappa_{N} ds = 2\pi.$$ And since the second integral is equal to $2\pi$ we get $\int_{\Omega}KdA=0$ , so this integral can't be equal (up to sign) to the area of the image of the Gauss map which is positive. This result is also independent on how we connected $A$ and $B$ to a smooth connected surface in $\mathbb{R}^3$ . I think the problem is that no matter how we connect $A$ and $B$ we won't be able to do it in a way that would make the Gauss map injective. The only answer on here that asks a similar question is this , but as I said, I understand this case. I want to know if the counterexample works and if it does are there even easier counterxamples? If the claim is actually true as stated, then I would like to see an argument why it is true. EDIT: It has been confirmed in the comments that this exercise is wrong as written and I have also located an errata for Tu's book on his website which adds that the Gauss map should be injective on points where $K\neq 0$ and that $K$ should be either non-negative or non-positive everywhere. This is so that the Gauss map is either orientation-preserving or orientation-reversing on the set where $K\neq 0$ . @TedShifrin also provided an easier counterexample: the torus in $\mathbb{R}^3$ .","I am trying to solve the following exercise from the book Differential Geometry by Loring W. Tu: 5.4 Total curvature The total curvature of a smooth oriented surface in is defined to be the integral if it exists, of the Gaussian curvature . Prove that the total curvature of is, up to sign, the area of the image of the Gauss map: I'm pretty sure that surfaces are assumed to be connected, otherwise this theorem is clearly false. (Consider two disjoint spheres in with outward unit normal.) Even then I am not sure that this is true as stated. I know how to prove it in the case when is injective on the set of points where is non-zero. In this case the restriction of to this set is actually a diffeomorphism onto its image and if and are the volume forms of and respectively, then the pullback of with is just . My idea to solve the general case was to introduce a partition of unity with respect to an open cover such that on each element of the cover is a diffeomorphism onto its image, but I run into trouble with this approach because of the possible non-injectivity of . In fact when I brought this up with one of my professors, we also didn't know how to proceed and in turn tried to consider some examples. This discussion culminated in what we think is a counterexample which I will now describe. Consider the following subsets of : { } and { }. So is the plane with the open disk of radius removed and is the upper hemisphere of a unit sphere around the point . We can then imagine connecting these two in such a way that we get a smooth surface embedded in . The image of the Gauss map of this surface clearly has positive volume no matter what unit normal vector field we pick, since it either contains the whole upper hemisphere or the whole lower hemisphere of . Now consider the circle with radius in the plane parameterized anti-clockwise with unit speed such that it winds around only once and denote this parameterization with . If we denote with the surface it encloses and denote with it's curvature with respect to the inward pointing normal relative to the plane then the Gauss-Bonnet formula (John M. Lee - Introduction to Riemannian Manifolds theorem 9.3) yields: And since the second integral is equal to we get , so this integral can't be equal (up to sign) to the area of the image of the Gauss map which is positive. This result is also independent on how we connected and to a smooth connected surface in . I think the problem is that no matter how we connect and we won't be able to do it in a way that would make the Gauss map injective. The only answer on here that asks a similar question is this , but as I said, I understand this case. I want to know if the counterexample works and if it does are there even easier counterxamples? If the claim is actually true as stated, then I would like to see an argument why it is true. EDIT: It has been confirmed in the comments that this exercise is wrong as written and I have also located an errata for Tu's book on his website which adds that the Gauss map should be injective on points where and that should be either non-negative or non-positive everywhere. This is so that the Gauss map is either orientation-preserving or orientation-reversing on the set where . @TedShifrin also provided an easier counterexample: the torus in .","M \mathbb{R}^3 \int_M K K M \int_M K = \text{Area of} \ \nu(M). \mathbb{R}^3 \nu K \nu dV_g dV M \mathbb{S}^2 dV \nu KdV_g \nu \nu \mathbb{R}^3 A= (x,y,z)\in \mathbb{R}^3 \vert x^2+y^2 \geq 2, z=0 B= (x,y,z)\in \mathbb{R}^3 \vert x^2+y^2+(z-1)^2 = 1, z \geq 1 A z=0 2 B (0,0,1) \mathbb{R}^3 \mathbb{S}^2 2 z=0 \gamma \Omega \kappa_N z=0 \int_{\Omega}KdA + \int_{\gamma} \kappa_{N} ds = 2\pi. 2\pi \int_{\Omega}KdA=0 A B \mathbb{R}^3 A B K\neq 0 K K\neq 0 \mathbb{R}^3","['geometry', 'differential-geometry', 'riemannian-geometry', 'surfaces', 'curvature']"
31,Does the metric derivative have a weak formulation?,Does the metric derivative have a weak formulation?,,"Given a metric space $(X, d)$ and a function $f:I:=(a,b)\subseteq \mathbb{R} \rightarrow X$ , we can define the metric derivative of $f$ at $t\in I$ as $$ f'(t) := |\frac{d}{dt}|f(t) := \lim_{\delta\rightarrow 0} \frac{d(f(t+\delta),f(t))}{|\delta|} \in \mathbb{R} $$ Of course, the limit in $t$ exists only for those $f$ such that the function $g_t(\delta) := d(f(t+\delta),f(t)) $ is differentiable at $\delta=0$ (since $f'(t) = g_t'(0)$ ). My question is : if the functions $g_t$ are not differentiable, but just weakly differentiable, can we provide a notion of weak metric derivative ? I tried to have a look around and I didn't find this. Is it sufficient to require that ""the $g_t$ are weakly differentiable at $0$ ""? Could someone hint whether there are some subtleties one should pay attention to?","Given a metric space and a function , we can define the metric derivative of at as Of course, the limit in exists only for those such that the function is differentiable at (since ). My question is : if the functions are not differentiable, but just weakly differentiable, can we provide a notion of weak metric derivative ? I tried to have a look around and I didn't find this. Is it sufficient to require that ""the are weakly differentiable at ""? Could someone hint whether there are some subtleties one should pay attention to?","(X, d) f:I:=(a,b)\subseteq \mathbb{R} \rightarrow X f t\in I  f'(t) := |\frac{d}{dt}|f(t) := \lim_{\delta\rightarrow 0} \frac{d(f(t+\delta),f(t))}{|\delta|} \in \mathbb{R}  t f g_t(\delta) := d(f(t+\delta),f(t))  \delta=0 f'(t) = g_t'(0) g_t g_t 0","['functional-analysis', 'differential-geometry', 'metric-spaces']"
32,Differential densities of rank $k<n$.,Differential densities of rank .,k<n,"Motivation In "" Gelfand Transforms and Crofton formulas "" the authors state that ""Roughly speaking, densities are the most general objects that can be integrated over submanifolds independently of parameterization and orientation"". So I wanted to understand these concepts better. There was a very good answer about densities (of rank $n$ ) here , and I was wondering how this extends to densities of rank $k$ . Density of rank $k$ In "" Gelfand Transforms and Crofton formulas "" the authors define a $k$ -density (a density of rank $k$ , not to be confused with the weight) over a vector space $V$ as a continuous function $\phi:\underbrace{V\times\ldots\times V}_k\to\mathbb{R}$ such that for any set of $k$ linearly independent vectors $\{v_j\}_{j=1}^k$ and $A\in GL(k,\mathbb{R})$ we have $$\phi(Av) = |\det A|\phi(v).$$ If I understood it correctly, the notation $Av$ means $(\sum_j A_{j1} v_j, \ldots, \sum_j A_{jk} v_j)$ . It is clear that for $k=n=\dim V$ this is just a usual (volume) density. For $k<n$ , $\phi$ behaves like a density when restricted to any $k$ -dimensional subspace of $V$ . In fact it is less constrained than an $n$ -density on the full space. Did I understand this correctly? Examples of $k$ -densities: $|\alpha|$ , $\langle \alpha, \beta\rangle$ ? Let $\alpha = \alpha_{i_1\ldots i_n} \, e^1\wedge\ldots \wedge e^n$ be a $n$ -covector for an $n$ -dimensional space. Then from $\alpha(Av) = (\det A) \,\alpha(v)$ , and thus $|\alpha(Av)| = |\det A| \, |\alpha(v)|$ is a density. That is, it is enough to take the absolute value of an $n$ -covector to get an $n$ -density. If $V$ is a space over the complex numbers then $|z| = z^*z$ . It's also clear that I can get a density of weight $s$ from $|\alpha|^s$ . Now let $\beta = \beta_{i_1\ldots i_n} \,e^1\wedge\ldots \wedge e^n$ then I believe the following object is an $n$ -density of weight $2$ : $$\langle\alpha,\beta\rangle = \alpha^*_{i_1\ldots i_n}G_{i_1\ldots i_n}\beta_{i_1\ldots i_n} (e^1\wedge\ldots\wedge e^n)^*(e^1\wedge\ldots\wedge e^n) = \alpha^*_{i_1\ldots i_n}G_{i_1\ldots i_n}\beta_{i_1\ldots i_n}|e^1\wedge\ldots\wedge e^n|^2.$$ This should hold because $$|(e^1\wedge\ldots \wedge e^n)(Av)|^2 = |\det A|^2\, |(e^1\wedge\ldots \wedge e^n)(v)|^2.$$ So if I want to consider $k<n$ I can try to see whether the above approaches work for $k$ -densities. Proof that $|\alpha|$ is a $k$ -density Let $\alpha = \sum_{|I|=k} \alpha_I \, (e^{i_1}\wedge\ldots\wedge e^{i_k})$ . I want to show that $|\alpha(Av)| = |\det A| |\alpha(v)|$ . I will show $\alpha(Av) = (\det A) \alpha(v)$ from which the former will follow. Let $\{e_j\}_{j=1}^n$ be the basis of $V$ that is biorthogonal to the basis $\{e^i\}_{i=1}^n$ for $V^*$ , biorthogonal meaning $e^i(e_j) = \delta^i_j$ . Now let $\{v_r\}_{r=1}^k$ be $k$ vectors from $V$ , then their coordinates with respect to $\{e_i\}_{i=1}^n$ are given as the $n\times k$ matrix $C_{ij} = e^i(v_j)$ . Then it follows that: \begin{equation} \begin{aligned} \alpha(Av) &= \sum_{|I|=k}\alpha_I \,(e^{i_1}\wedge\ldots\wedge e^{i_k})(Av)  \\ &=\sum_{|I|=k}\alpha_I \, \det C_IA \\ &= \sum_{|I|=k}\alpha_I \, \det C_I \det A \\ &= (\det A)\, \alpha(v). \end{aligned} \end{equation} Here $C_I$ was the $k\times k$ submatrix of $C$ with rows from $I$ (in ascending order). Taking powers $|\alpha|^s$ results in a $k$ -density of weight $s$ . Proof that $\langle \alpha, \beta \rangle$ is a $k$ -density Let $\alpha = \sum_{|I|=k} \alpha_I\, (e^{i_1}\wedge\ldots\wedge e^{i_k})$ and $\beta = \sum_{|J|=k} \beta_J\, (e^{j_1}\wedge\ldots\wedge e^{j_k})$ . I define their ""inner product"" by distributing the terms: \begin{equation} \begin{aligned} \langle \alpha, \beta\rangle &= \left(\sum_{|I|=k}\alpha_I\,(e^{i_1}\wedge\ldots\wedge e^{i_k})\right)^*G \left(\sum_{|J|=k}\beta_J\,(e^{j_1}\wedge\ldots\wedge e^{j_k})\right)\\ &= \sum_{|I|=k}\sum_{|J|=k} \alpha_I^*G_{I,J}\beta_J \, (e^{i_1}\wedge\ldots\wedge e^{i_k})^*(e^{j_1}\wedge\ldots\wedge e^{j_k}), \end{aligned} \end{equation} where $^*$ is complex conjugation. The product is to be understood pointwise and not as a wedge or something else, i.e. $$\bigl((e^{i_1}\wedge\ldots\wedge e^{i_k})^*(e^{j_1}\wedge\ldots\wedge e^{j_k})\bigr)(v) = \bigl((e^{i_1}\wedge\ldots\wedge e^{i_k})(v)\bigr)^*\cdot\bigl((e^{j_1}\wedge\ldots\wedge e^{j_k})(v)\bigr),$$ where $\cdot$ is multiplication of complex numbers. Now let $C_{ij} = e^i(v_j)$ , then I can write: \begin{equation} \begin{aligned} \langle \alpha, \beta \rangle(Av) &= \left(\sum_{|I|=k}\alpha_I \,(e^{i_1}\wedge\ldots\wedge e^{i_k})(Av)\right)^*G\left(\sum_{|J|=k}\beta_J \,(e^{j_1}\wedge\ldots\wedge e^{j_k})(Av)\right) \\ &= \left(\sum_{|I|=k}\det \alpha_I \,\det C_IA\right)^*G\left(\sum_{|J|=k}\det \beta_J \,\det C_JA\right) \\ &= \left(\sum_{|I|=k}\alpha_I \,\det C_I \det A\right)^*G\left(\sum_{|J|=k}\det \beta_J \,\det C_J \det A\right) \\ &= (\det A)^*(\det A)  \left(\sum_{|I|=k}\alpha_I \,(e^{i_1}\wedge\ldots\wedge e^{i_k})(v)\right)^*G\left(\sum_{|J|=k}\beta_J \,(e^{j_1}\wedge\ldots\wedge e^{j_k})(v)\right)  \\ &= |\det A|^2 \langle \alpha, \beta\rangle (v). \end{aligned} \end{equation} I can take powers $\langle \alpha,\beta\rangle^{s/2}$ to get densities with weight $s$ . I should also be able to formulate a similar operation such as $\langle \alpha_1,\ldots,\alpha_r\rangle$ by expanding things in a similar manner, which should yield a $k$ -density of weight $r$ (provided $r$ is even). Interpretation If $|\omega|$ is indeed a density for $k<n$ , then what would be the physical/geometrical meaning of it in an integration problem? For instance a $2$ -form in 3D $\omega = \star (f_1dx + f_2 dy + f_3 dz)$ can be used to integrate surface flux given a vector field $f$ . It results in $f\cdot \hat{n} dS$ . The corresponding $2$ -density $|\omega|$ then integrates $|f\cdot \hat{n}|dS$ , which is some kind of quantity that ""doesn't care"" about whether $f$ is in the positive or negative halfspace w.r.t. $n$ - it always takes the normal that would produce a positive result. Are there physical examples of something that would integrate like this over a surface? Some kind of non-oriented flux? Densities of the form $\|\omega\|_2 = \sqrt{\langle \omega, \omega\rangle}$ should represent $k$ -volume measure I believe. As an example for $k=1$ and $G_{ij} = \delta_{ij}$ I have $vol_1 = \sqrt{\sum_i (e^i)^2}$ . So $G_{ij}$ here plays the role of metric tensor coefficients I guess, and the variants with more slots are some kinds of generalizations of this. I have no idea what $\langle \alpha, \beta\rangle$ for $\alpha\ne \beta$ is though. Double Cover and Densities Finally, if I were to integrate a $2$ -form $\omega$ over the double cover of a non-orientable surface, e.g. a Mobius strip in $\mathbb{R}^3$ , is it equivalent to twice the integral of $|\omega|$ or $\|\omega\|_2$ or some other $2$ -density? Or is it something else? Is there a theorem about this anywhere? More generally, is the correspondence: form $\to$ oriented manifold, pseudoform $\to$ potentially non-oriented but orientable manifold, density $\to$ potentially non-orientable manifold.","Motivation In "" Gelfand Transforms and Crofton formulas "" the authors state that ""Roughly speaking, densities are the most general objects that can be integrated over submanifolds independently of parameterization and orientation"". So I wanted to understand these concepts better. There was a very good answer about densities (of rank ) here , and I was wondering how this extends to densities of rank . Density of rank In "" Gelfand Transforms and Crofton formulas "" the authors define a -density (a density of rank , not to be confused with the weight) over a vector space as a continuous function such that for any set of linearly independent vectors and we have If I understood it correctly, the notation means . It is clear that for this is just a usual (volume) density. For , behaves like a density when restricted to any -dimensional subspace of . In fact it is less constrained than an -density on the full space. Did I understand this correctly? Examples of -densities: , ? Let be a -covector for an -dimensional space. Then from , and thus is a density. That is, it is enough to take the absolute value of an -covector to get an -density. If is a space over the complex numbers then . It's also clear that I can get a density of weight from . Now let then I believe the following object is an -density of weight : This should hold because So if I want to consider I can try to see whether the above approaches work for -densities. Proof that is a -density Let . I want to show that . I will show from which the former will follow. Let be the basis of that is biorthogonal to the basis for , biorthogonal meaning . Now let be vectors from , then their coordinates with respect to are given as the matrix . Then it follows that: Here was the submatrix of with rows from (in ascending order). Taking powers results in a -density of weight . Proof that is a -density Let and . I define their ""inner product"" by distributing the terms: where is complex conjugation. The product is to be understood pointwise and not as a wedge or something else, i.e. where is multiplication of complex numbers. Now let , then I can write: I can take powers to get densities with weight . I should also be able to formulate a similar operation such as by expanding things in a similar manner, which should yield a -density of weight (provided is even). Interpretation If is indeed a density for , then what would be the physical/geometrical meaning of it in an integration problem? For instance a -form in 3D can be used to integrate surface flux given a vector field . It results in . The corresponding -density then integrates , which is some kind of quantity that ""doesn't care"" about whether is in the positive or negative halfspace w.r.t. - it always takes the normal that would produce a positive result. Are there physical examples of something that would integrate like this over a surface? Some kind of non-oriented flux? Densities of the form should represent -volume measure I believe. As an example for and I have . So here plays the role of metric tensor coefficients I guess, and the variants with more slots are some kinds of generalizations of this. I have no idea what for is though. Double Cover and Densities Finally, if I were to integrate a -form over the double cover of a non-orientable surface, e.g. a Mobius strip in , is it equivalent to twice the integral of or or some other -density? Or is it something else? Is there a theorem about this anywhere? More generally, is the correspondence: form oriented manifold, pseudoform potentially non-oriented but orientable manifold, density potentially non-orientable manifold.","n k k k k V \phi:\underbrace{V\times\ldots\times V}_k\to\mathbb{R} k \{v_j\}_{j=1}^k A\in GL(k,\mathbb{R}) \phi(Av) = |\det A|\phi(v). Av (\sum_j A_{j1} v_j, \ldots, \sum_j A_{jk} v_j) k=n=\dim V k<n \phi k V n k |\alpha| \langle \alpha, \beta\rangle \alpha = \alpha_{i_1\ldots i_n} \, e^1\wedge\ldots \wedge e^n n n \alpha(Av) = (\det A) \,\alpha(v) |\alpha(Av)| = |\det A| \, |\alpha(v)| n n V |z| = z^*z s |\alpha|^s \beta = \beta_{i_1\ldots i_n} \,e^1\wedge\ldots \wedge e^n n 2 \langle\alpha,\beta\rangle = \alpha^*_{i_1\ldots i_n}G_{i_1\ldots i_n}\beta_{i_1\ldots i_n} (e^1\wedge\ldots\wedge e^n)^*(e^1\wedge\ldots\wedge e^n) = \alpha^*_{i_1\ldots i_n}G_{i_1\ldots i_n}\beta_{i_1\ldots i_n}|e^1\wedge\ldots\wedge e^n|^2. |(e^1\wedge\ldots \wedge e^n)(Av)|^2 = |\det A|^2\, |(e^1\wedge\ldots \wedge e^n)(v)|^2. k<n k |\alpha| k \alpha = \sum_{|I|=k} \alpha_I \, (e^{i_1}\wedge\ldots\wedge e^{i_k}) |\alpha(Av)| = |\det A| |\alpha(v)| \alpha(Av) = (\det A) \alpha(v) \{e_j\}_{j=1}^n V \{e^i\}_{i=1}^n V^* e^i(e_j) = \delta^i_j \{v_r\}_{r=1}^k k V \{e_i\}_{i=1}^n n\times k C_{ij} = e^i(v_j) \begin{equation}
\begin{aligned}
\alpha(Av) &= \sum_{|I|=k}\alpha_I \,(e^{i_1}\wedge\ldots\wedge e^{i_k})(Av)  \\
&=\sum_{|I|=k}\alpha_I \, \det C_IA \\
&= \sum_{|I|=k}\alpha_I \, \det C_I \det A \\
&= (\det A)\, \alpha(v).
\end{aligned}
\end{equation} C_I k\times k C I |\alpha|^s k s \langle \alpha, \beta \rangle k \alpha = \sum_{|I|=k} \alpha_I\, (e^{i_1}\wedge\ldots\wedge e^{i_k}) \beta = \sum_{|J|=k} \beta_J\, (e^{j_1}\wedge\ldots\wedge e^{j_k}) \begin{equation}
\begin{aligned}
\langle \alpha, \beta\rangle
&= \left(\sum_{|I|=k}\alpha_I\,(e^{i_1}\wedge\ldots\wedge e^{i_k})\right)^*G
\left(\sum_{|J|=k}\beta_J\,(e^{j_1}\wedge\ldots\wedge e^{j_k})\right)\\
&= \sum_{|I|=k}\sum_{|J|=k} \alpha_I^*G_{I,J}\beta_J \, (e^{i_1}\wedge\ldots\wedge e^{i_k})^*(e^{j_1}\wedge\ldots\wedge e^{j_k}),
\end{aligned}
\end{equation} ^* \bigl((e^{i_1}\wedge\ldots\wedge e^{i_k})^*(e^{j_1}\wedge\ldots\wedge e^{j_k})\bigr)(v) = \bigl((e^{i_1}\wedge\ldots\wedge e^{i_k})(v)\bigr)^*\cdot\bigl((e^{j_1}\wedge\ldots\wedge e^{j_k})(v)\bigr), \cdot C_{ij} = e^i(v_j) \begin{equation}
\begin{aligned}
\langle \alpha, \beta \rangle(Av)
&= \left(\sum_{|I|=k}\alpha_I \,(e^{i_1}\wedge\ldots\wedge e^{i_k})(Av)\right)^*G\left(\sum_{|J|=k}\beta_J \,(e^{j_1}\wedge\ldots\wedge e^{j_k})(Av)\right) \\
&= \left(\sum_{|I|=k}\det \alpha_I \,\det C_IA\right)^*G\left(\sum_{|J|=k}\det \beta_J \,\det C_JA\right) \\
&= \left(\sum_{|I|=k}\alpha_I \,\det C_I \det A\right)^*G\left(\sum_{|J|=k}\det \beta_J \,\det C_J \det A\right) \\
&= (\det A)^*(\det A)  \left(\sum_{|I|=k}\alpha_I \,(e^{i_1}\wedge\ldots\wedge e^{i_k})(v)\right)^*G\left(\sum_{|J|=k}\beta_J \,(e^{j_1}\wedge\ldots\wedge e^{j_k})(v)\right)  \\
&= |\det A|^2 \langle \alpha, \beta\rangle (v).
\end{aligned}
\end{equation} \langle \alpha,\beta\rangle^{s/2} s \langle \alpha_1,\ldots,\alpha_r\rangle k r r |\omega| k<n 2 \omega = \star (f_1dx + f_2 dy + f_3 dz) f f\cdot \hat{n} dS 2 |\omega| |f\cdot \hat{n}|dS f n \|\omega\|_2 = \sqrt{\langle \omega, \omega\rangle} k k=1 G_{ij} = \delta_{ij} vol_1 = \sqrt{\sum_i (e^i)^2} G_{ij} \langle \alpha, \beta\rangle \alpha\ne \beta 2 \omega \mathbb{R}^3 |\omega| \|\omega\|_2 2 \to \to \to","['differential-geometry', 'smooth-manifolds', 'differential-forms']"
33,Formula for gaussian curvature of a holomorphic curve in complex 2-space,Formula for gaussian curvature of a holomorphic curve in complex 2-space,,"Define h : ℂ → ℂ 2 via h(z)  =  (f(z), g(z)), where f, g : ℂ → ℂ are analytic functions such that the complex velocity h'(z) = (f'(z), g'(z)) ∈ ℂ 2 is never equal to (0,0). Suppose further that h is an embedding of ℂ into ℂ 2 . Then the image h(ℂ) is a smooth (C ∞ ) real surface at each of its points h(z), deriving its metric in the standard way as a submanifold of ℂ 2 = ℝ 4 .  As such it has a well-defined gaussian curvature K(z) at each point h(z) ∈ ℂ 2 . After finding a formula for K(z) in no book or paper that I was able to access, I calculated such a formula as K(z) =  -2 |h''(z) ^ h'(z)| 2 / |h'(z)| 6 , where h''(z) ^ h'(z) is shorthand for f''(z) g'(z) - g''(z) f'(z). Question : Is this formula well known?  Can anyone give a reference for where it can be found? (Note: I am not looking for formulas from which this one can be derived.) Remark : We could have replaced the domain by a nonempty open subset of ℂ and asked only that h be an immersion, but those refinements seemed to obscure the main point.","Define h : ℂ → ℂ 2 via h(z)  =  (f(z), g(z)), where f, g : ℂ → ℂ are analytic functions such that the complex velocity h'(z) = (f'(z), g'(z)) ∈ ℂ 2 is never equal to (0,0). Suppose further that h is an embedding of ℂ into ℂ 2 . Then the image h(ℂ) is a smooth (C ∞ ) real surface at each of its points h(z), deriving its metric in the standard way as a submanifold of ℂ 2 = ℝ 4 .  As such it has a well-defined gaussian curvature K(z) at each point h(z) ∈ ℂ 2 . After finding a formula for K(z) in no book or paper that I was able to access, I calculated such a formula as K(z) =  -2 |h''(z) ^ h'(z)| 2 / |h'(z)| 6 , where h''(z) ^ h'(z) is shorthand for f''(z) g'(z) - g''(z) f'(z). Question : Is this formula well known?  Can anyone give a reference for where it can be found? (Note: I am not looking for formulas from which this one can be derived.) Remark : We could have replaced the domain by a nonempty open subset of ℂ and asked only that h be an immersion, but those refinements seemed to obscure the main point.",,"['differential-geometry', 'riemann-surfaces']"
34,Is there a good reason why continuity assumed in the definition of differentiability in do Carmo?,Is there a good reason why continuity assumed in the definition of differentiability in do Carmo?,,"I am reading Do Carmo's Differential Geometry of Curves and Surfaces. He defines differentiability as follows: A continuous map [emphasis mine] $\varphi: V_1 \subset S_1 \to S_2$ of an open set $V_1$ of a regular surface to a regular surface $S_2$ is said to be differentiable at $p \in V_1$ if, given parametrizations $$x_1 : U_1 \subset \mathbb{R}^2 \to S_1 \quad x_2 : U_2 \subset \mathbb{R}^2 \to S_2 $$ with $p \in x_1(U_1)$ and $\varphi(x_1(U_1)) \subset x_2(U_2),$ the map $$x_2^{-1} \circ \varphi \circ x_1:U_1 \to U_2$$ is differentiable at $q = x_1^{-1}(p)$ . I believe that when he says continuous, and when he says that $V_1$ is open, he is referring to the topologies inherited from $\mathbb{R}^3$ . I was wondering why he assumes $\varphi$ to be continuous in the definition. I thought that it must be an easy consequence that $\varphi$ is continuous, if you know that all maps of the form $x_2^{-1} \circ \varphi \circ x_1$ are differentiable (hence continuous). However, I am starting to think that the continuity requirement is not superfluous. I think that for the definition to be correct, we must do one of two things. Either Assume $\varphi$ is continuous. In the definition, change ""given parametrizations"" to ""there exist parametrizations"". If we do neither, then I think there can be very badly behaved, discontinuous functions $\varphi$ where it is impossible to find parametrizations $x_1, x_2$ with $\varphi(x_1(U_1)) \subset x_2(U_2)$ . Hence, $\varphi$ would vaccuously be a diffeomorphism, even though it is discontinuous. However, if we do drop continuity but make change in $2$ , I think we can prove that $\varphi$ is continuous, and we get an equivalent definition to do Carmo's. Is my analysis above correct? EDIT: Proposition: Let $\varphi$ be any function from $S_1$ to $S_2$ . If for each point $p \in S_1$ there exist parametrizations $$x_1 : U_1 \subset \mathbb{R}^2 \to S_1 \quad x_2 : U_2 \subset \mathbb{R}^2 \to S_2 $$ with $p \in x_1(U_1)$ and $\varphi(x_1(U_1)) \subset x_2(U_2)$ such that the map $$x_2^{-1} \circ \varphi \circ x_1:U_1 \to U_2$$ is differentiable at $q = x_1^{-1}(p),$ then $\varphi$ is a continuous map from $S_1 \to S_2$ (with the topologies inherited from $\mathbb{R}^3$ ). $\textit{Proof: }$ Fix $p \in S_1$ and take parametrizations $x_1, x_2,$ and the point $q$ , as given in the claim. We will show that $\varphi$ is continuous at $p$ . Let $O_{S_2}$ be any open subset of $S_2$ containing $\varphi(p)$ , and let $O_{U_2} = x_2^{-1}(O_{S_2})$ , which is open because (by definition of parametrization) $x_2$ is a homeomorphism. Now $x_2 ^{-1} \circ \varphi \circ x_1$ is differentiable at $q$ , so it is continuous at $q$ . Since $O_{U_2}$ contains $x_2 ^{-1} \circ \varphi \circ x_1(q)$ , there exists an open subset $O_{U_1}$ of $U_1$ , containing $q$ , such that $x_2 ^{-1} \circ \varphi \circ x_1 (O_{U_1}) \subseteq O_{U_2}.$ Applying $x_2$ to both sides, we get $\varphi \circ x_1 (O_{U_1}) \subseteq x_2(O_{U_2}) = O_{S_2}.$ Finally, let $O_{S_1} = x_1(U_1)$ , which is open because $x_1$ is a homeomorphism. Substituting above, we have $\varphi(O_{S_1}) \subseteq O_{S_2}$ , which shows that $\varphi$ is continuous at $p$ . Since $p$ was arbitrary, $\varphi$ is continuous on $S_1.$","I am reading Do Carmo's Differential Geometry of Curves and Surfaces. He defines differentiability as follows: A continuous map [emphasis mine] of an open set of a regular surface to a regular surface is said to be differentiable at if, given parametrizations with and the map is differentiable at . I believe that when he says continuous, and when he says that is open, he is referring to the topologies inherited from . I was wondering why he assumes to be continuous in the definition. I thought that it must be an easy consequence that is continuous, if you know that all maps of the form are differentiable (hence continuous). However, I am starting to think that the continuity requirement is not superfluous. I think that for the definition to be correct, we must do one of two things. Either Assume is continuous. In the definition, change ""given parametrizations"" to ""there exist parametrizations"". If we do neither, then I think there can be very badly behaved, discontinuous functions where it is impossible to find parametrizations with . Hence, would vaccuously be a diffeomorphism, even though it is discontinuous. However, if we do drop continuity but make change in , I think we can prove that is continuous, and we get an equivalent definition to do Carmo's. Is my analysis above correct? EDIT: Proposition: Let be any function from to . If for each point there exist parametrizations with and such that the map is differentiable at then is a continuous map from (with the topologies inherited from ). Fix and take parametrizations and the point , as given in the claim. We will show that is continuous at . Let be any open subset of containing , and let , which is open because (by definition of parametrization) is a homeomorphism. Now is differentiable at , so it is continuous at . Since contains , there exists an open subset of , containing , such that Applying to both sides, we get Finally, let , which is open because is a homeomorphism. Substituting above, we have , which shows that is continuous at . Since was arbitrary, is continuous on","\varphi: V_1 \subset S_1 \to S_2 V_1 S_2 p \in V_1 x_1 : U_1 \subset \mathbb{R}^2 \to S_1 \quad x_2 : U_2 \subset \mathbb{R}^2 \to S_2  p \in x_1(U_1) \varphi(x_1(U_1)) \subset x_2(U_2), x_2^{-1} \circ \varphi \circ x_1:U_1 \to U_2 q = x_1^{-1}(p) V_1 \mathbb{R}^3 \varphi \varphi x_2^{-1} \circ \varphi \circ x_1 \varphi \varphi x_1, x_2 \varphi(x_1(U_1)) \subset x_2(U_2) \varphi 2 \varphi \varphi S_1 S_2 p \in S_1 x_1 : U_1 \subset \mathbb{R}^2 \to S_1 \quad x_2 : U_2 \subset \mathbb{R}^2 \to S_2  p \in x_1(U_1) \varphi(x_1(U_1)) \subset x_2(U_2) x_2^{-1} \circ \varphi \circ x_1:U_1 \to U_2 q = x_1^{-1}(p), \varphi S_1 \to S_2 \mathbb{R}^3 \textit{Proof: } p \in S_1 x_1, x_2, q \varphi p O_{S_2} S_2 \varphi(p) O_{U_2} = x_2^{-1}(O_{S_2}) x_2 x_2 ^{-1} \circ \varphi \circ x_1 q q O_{U_2} x_2 ^{-1} \circ \varphi \circ x_1(q) O_{U_1} U_1 q x_2 ^{-1} \circ \varphi \circ x_1 (O_{U_1}) \subseteq O_{U_2}. x_2 \varphi \circ x_1 (O_{U_1}) \subseteq x_2(O_{U_2}) = O_{S_2}. O_{S_1} = x_1(U_1) x_1 \varphi(O_{S_1}) \subseteq O_{S_2} \varphi p p \varphi S_1.","['differential-geometry', 'manifolds', 'differential-topology']"
35,"Proving that in Spherical geometry, Interior angles of triangles don't add up to $180^{\circ}$. [closed]","Proving that in Spherical geometry, Interior angles of triangles don't add up to . [closed]",180^{\circ},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 9 months ago . Improve this question I've gotten a germ of the proof, which involves using the standard metric on the two sphere $ds^2=d\theta^2 + \sin^2{\theta}d\phi^2$ . Thing is, how do I continue from here? How do I use this metric to calculate those interior angles regardless of the lengths of the legs of the triangle?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 9 months ago . Improve this question I've gotten a germ of the proof, which involves using the standard metric on the two sphere . Thing is, how do I continue from here? How do I use this metric to calculate those interior angles regardless of the lengths of the legs of the triangle?",ds^2=d\theta^2 + \sin^2{\theta}d\phi^2,['differential-geometry']
36,If a closed curve has no antipodal points it must be contained in some open hemisphere,If a closed curve has no antipodal points it must be contained in some open hemisphere,,"Whilst doing an exercise, on bounds on total absolute curvature I encountered the following obstacle: Let $ \mathit c$ be a closed curve, whose trace is contained in $\mathbb S^2$ , if c has no antipodal points, does this imply, that c is contained in some open hemisphere? Intuitively I would argue, that if $ \pmb P, Q$ are the points on the curve that are the furthest apart, one takes the great circle parallel to the line connecting the two points, and then the curve should be contained, in one of the open hemispheres whose equator is formed by this great circle. I'm not sure if the claim is even true, and if yes how to make it rigorous. Any help would be greatly appreciated.","Whilst doing an exercise, on bounds on total absolute curvature I encountered the following obstacle: Let be a closed curve, whose trace is contained in , if c has no antipodal points, does this imply, that c is contained in some open hemisphere? Intuitively I would argue, that if are the points on the curve that are the furthest apart, one takes the great circle parallel to the line connecting the two points, and then the curve should be contained, in one of the open hemispheres whose equator is formed by this great circle. I'm not sure if the claim is even true, and if yes how to make it rigorous. Any help would be greatly appreciated."," \mathit c \mathbb S^2  \pmb P, Q","['geometry', 'differential-geometry', 'curves']"
37,Does parallel transport apply to points or vectors?,Does parallel transport apply to points or vectors?,,"My current understanding of parallel transport is the following: Let $P \xrightarrow{\pi} M$ be a principal $G$ -bundle and $\gamma: [a,b] \rightarrow M$ a curve in $M$ . For a given connection $A$ , we may define a map $$\Pi_\gamma^A: P_{\gamma(a)} \rightarrow P_{\gamma(b)}\\ p \mapsto \gamma_p^*(b)$$ where $\gamma^*_p$ is the horizontal lift of $\gamma$ such that $\gamma^*_p(a) = p$ . Thus we see that parallel transport is a way to map a point in one fiber to another, hence it maps points in $P$ to points in $P$ . What has been confusing me is that many resources, such as Wikipedia or Wolfram MathWorld , instead describe parallel transport as transporting vectors. I do not see how the above definition of parallel transport has anything to do with vectors unless we consider $(\Pi_\gamma^A)_*$ , the pushforward of the parallel transport map, but this is never mentioned. What is the connection between these two viewpoints?","My current understanding of parallel transport is the following: Let be a principal -bundle and a curve in . For a given connection , we may define a map where is the horizontal lift of such that . Thus we see that parallel transport is a way to map a point in one fiber to another, hence it maps points in to points in . What has been confusing me is that many resources, such as Wikipedia or Wolfram MathWorld , instead describe parallel transport as transporting vectors. I do not see how the above definition of parallel transport has anything to do with vectors unless we consider , the pushforward of the parallel transport map, but this is never mentioned. What is the connection between these two viewpoints?","P \xrightarrow{\pi} M G \gamma: [a,b] \rightarrow M M A \Pi_\gamma^A: P_{\gamma(a)} \rightarrow P_{\gamma(b)}\\
p \mapsto \gamma_p^*(b) \gamma^*_p \gamma \gamma^*_p(a) = p P P (\Pi_\gamma^A)_*","['differential-geometry', 'connections', 'principal-bundles']"
38,Definition of the $\hat{A}$-genus,Definition of the -genus,\hat{A},"From page $50$ of Heat Kernels and Dirac Operators : If $E$ is a real vector bundle with covariant derivative $\nabla$ and curvature $F$ , we associate to it its $\hat{A}$ -genus form \begin{equation}     \hat{A}(\nabla):=\mathrm{det}^{1/2}\bigg(\frac{F/2}{\sinh{F/2}}\bigg)\in\Gamma(M,\Lambda(TM^*)). \end{equation} I feel a bit betrayed, because the $\hat{A}$ -genus form seems to be defined in terms of another undefined expression. Am I right in assuming that the definition is meant as follows: Fix $x\in M$ and choose a basis $e_1,\ldots,e_n$ of $E_x$ , consider the matrix $\Omega\in \Lambda(T_pM^*)^{n\times n}$ with $\Omega^{i}{}_{j}\in \Lambda^2(T_pM^*)\subset\Lambda(T_pM^*)$ given by $$\Omega^{i}{}_{j}(X,Y)=e^iF(X,Y)e_j$$ and set $$\hat{A}(\nabla)_x:=\mathrm{det}^{1/2}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)$$ (of course we have to check that the definition is independent of the basis). But even the definition of the last expression is not entirely clear: First of all, note that the entries of $\Omega$ are in the even subalgebra of $\Lambda(T_pM^*)$ , i.e. the determinant makes sense. I would have expected that $$\mathrm{det}^{1/2}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg):=\bigg(\mathrm{det}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)\bigg)^{1/2}$$ but the determinant is an element of $\Lambda(T_pM^*)$ and defining the square root is a subtle issue. Setting $$\hat{A}(\nabla)_x:=\mathrm{det}\bigg(\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)^{1/2}\bigg)$$ seems much more reasonable, as this solves the issue: On the one hand, the function \begin{align} \mathbb R&\to\mathbb R\\ x&\mapsto\sqrt{\frac{x}{\sinh{x}}} \end{align} has a nice taylor series and the other hand we dont even have to worry about convergence as $\Omega$ is nilpotent. (To do: Check consistency with $(1.36)$ for $8$ -dim. manifolds.)","From page of Heat Kernels and Dirac Operators : If is a real vector bundle with covariant derivative and curvature , we associate to it its -genus form I feel a bit betrayed, because the -genus form seems to be defined in terms of another undefined expression. Am I right in assuming that the definition is meant as follows: Fix and choose a basis of , consider the matrix with given by and set (of course we have to check that the definition is independent of the basis). But even the definition of the last expression is not entirely clear: First of all, note that the entries of are in the even subalgebra of , i.e. the determinant makes sense. I would have expected that but the determinant is an element of and defining the square root is a subtle issue. Setting seems much more reasonable, as this solves the issue: On the one hand, the function has a nice taylor series and the other hand we dont even have to worry about convergence as is nilpotent. (To do: Check consistency with for -dim. manifolds.)","50 E \nabla F \hat{A} \begin{equation}
    \hat{A}(\nabla):=\mathrm{det}^{1/2}\bigg(\frac{F/2}{\sinh{F/2}}\bigg)\in\Gamma(M,\Lambda(TM^*)).
\end{equation} \hat{A} x\in M e_1,\ldots,e_n E_x \Omega\in \Lambda(T_pM^*)^{n\times n} \Omega^{i}{}_{j}\in \Lambda^2(T_pM^*)\subset\Lambda(T_pM^*) \Omega^{i}{}_{j}(X,Y)=e^iF(X,Y)e_j \hat{A}(\nabla)_x:=\mathrm{det}^{1/2}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg) \Omega \Lambda(T_pM^*) \mathrm{det}^{1/2}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg):=\bigg(\mathrm{det}\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)\bigg)^{1/2} \Lambda(T_pM^*) \hat{A}(\nabla)_x:=\mathrm{det}\bigg(\bigg(\frac{\Omega/2}{\sinh{\Omega/2}}\bigg)^{1/2}\bigg) \begin{align}
\mathbb R&\to\mathbb R\\
x&\mapsto\sqrt{\frac{x}{\sinh{x}}}
\end{align} \Omega (1.36) 8",['differential-geometry']
39,Smooth manifold with finite atlas,Smooth manifold with finite atlas,,"There is already quite a bit of discussion about this online, but I feel like a lot of this discussion is very confused so please help me understand the following questions: Does every connected manifold have a finite atlas with connected charts? There is a book by Werner Greub called ""Connections, Curvature and Cohomology - Volume 1"" which, on page 20 contains the corollary that every topological manifold has a finite atlas of at most $n+1$ charts, where $n$ is the dimension of the manifold. Of course, these charts could well be disconnected, so I wonder if we can also find a finite atlas consisting of charts whose domains are each connected. How does this change if we are working with smooth manifolds? I assume the proof by Werner Greub still works if we impose the additional requirement that charts be compatible in the sense that the transition maps are $C^{\infty}$ , leading to the implication that every smooth manifold has a finite atlas consisting of at most $n+1$ charts. Finally, I came across the dubious paper A. Solecki. ""Finite atlases on manifolds"", Annales Societatis Mathematicae Polonae. Series I: Commentationes Mathematicae XVII (1974), which I call dubious because it doesn't have a single citation as far as I can tell. Without having fully verified the proof myself, the paper claims that for every smooth connected manifold $M$ of dimension $n$ there exists a finite atlas consisting of at most $2\cdot3^{2n}$ full charts, where a full chart is one that maps onto $\mathbb{R}^n$ . Since each chart is a homeomorphism and $\mathbb{R}^n$ is connected, this would mean that the domains of each of these charts is also connected. Any clarification is much appreciated.","There is already quite a bit of discussion about this online, but I feel like a lot of this discussion is very confused so please help me understand the following questions: Does every connected manifold have a finite atlas with connected charts? There is a book by Werner Greub called ""Connections, Curvature and Cohomology - Volume 1"" which, on page 20 contains the corollary that every topological manifold has a finite atlas of at most charts, where is the dimension of the manifold. Of course, these charts could well be disconnected, so I wonder if we can also find a finite atlas consisting of charts whose domains are each connected. How does this change if we are working with smooth manifolds? I assume the proof by Werner Greub still works if we impose the additional requirement that charts be compatible in the sense that the transition maps are , leading to the implication that every smooth manifold has a finite atlas consisting of at most charts. Finally, I came across the dubious paper A. Solecki. ""Finite atlases on manifolds"", Annales Societatis Mathematicae Polonae. Series I: Commentationes Mathematicae XVII (1974), which I call dubious because it doesn't have a single citation as far as I can tell. Without having fully verified the proof myself, the paper claims that for every smooth connected manifold of dimension there exists a finite atlas consisting of at most full charts, where a full chart is one that maps onto . Since each chart is a homeomorphism and is connected, this would mean that the domains of each of these charts is also connected. Any clarification is much appreciated.",n+1 n C^{\infty} n+1 M n 2\cdot3^{2n} \mathbb{R}^n \mathbb{R}^n,"['general-topology', 'differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
40,"Exponential map of flow, does it locally look like a power series/matrix exponential?","Exponential map of flow, does it locally look like a power series/matrix exponential?",,"Let $g_t : M \rightarrow M$ be the flow of a vector field, that is a family of diffeomorphisms such that $g_t \circ g_s = g_{t+s}$ to $t,s > 0$ and $g_0 = \operatorname{id}$ . One can interpret the diffeomorphism group as an infinite dimensional Lie group, up to some technicalities I am not interested in, with its Lie algebra given by vector fields. This group admits an exponential map that sometimes coincides with the Riemannian exponential map, namely there is an $\exp: \mathfrak{X}(M) \rightarrow Diff(M)$ such that: $$\exp(tX) = g_t$$ Where $X : M \rightarrow TM$ is a vector field satisfying $$\frac{d}{dt}g_t(x) = X(g_t(x))$$ My question is, using a coordinate chart a diffeomorphism can be represented locally as just a collection of mappings $g = (g_t^i)_{i=1}^n$ with $g^i_t = F^i(x,t) : \mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^n$ . Similarly, a vector field can be identified as a first order differential operator that has components with respect to a basis induced by the same chart. Can we say, that in a small neighbourhood we have: $$\exp(tX) = \sum \frac{1}{k!}X^k$$ Where the RHS is some sort of operator/matrix exponential instead of some abstract time 1 geodesic map?","Let be the flow of a vector field, that is a family of diffeomorphisms such that to and . One can interpret the diffeomorphism group as an infinite dimensional Lie group, up to some technicalities I am not interested in, with its Lie algebra given by vector fields. This group admits an exponential map that sometimes coincides with the Riemannian exponential map, namely there is an such that: Where is a vector field satisfying My question is, using a coordinate chart a diffeomorphism can be represented locally as just a collection of mappings with . Similarly, a vector field can be identified as a first order differential operator that has components with respect to a basis induced by the same chart. Can we say, that in a small neighbourhood we have: Where the RHS is some sort of operator/matrix exponential instead of some abstract time 1 geodesic map?","g_t : M \rightarrow M g_t \circ g_s = g_{t+s} t,s > 0 g_0 = \operatorname{id} \exp: \mathfrak{X}(M) \rightarrow Diff(M) \exp(tX) = g_t X : M \rightarrow TM \frac{d}{dt}g_t(x) = X(g_t(x)) g = (g_t^i)_{i=1}^n g^i_t = F^i(x,t) : \mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^n \exp(tX) = \sum \frac{1}{k!}X^k","['differential-geometry', 'lie-groups', 'lie-algebras', 'matrix-exponential']"
41,Differentiating a pullback along a family of curves,Differentiating a pullback along a family of curves,,"Say I have a family of curves $x_s : [0,1] \longrightarrow M$ where $s \in (-\epsilon, \epsilon)$ is my family's parameter, and $M$ is a manifold (which, for all purposes being, we can assume to be $\mathbb{R}^n$ ). Additionally, let $\zeta := \dfrac{\mathrm{d}}{\mathrm{d}s}x_s|_{s = 0}$ , which ends up being a vector field along the curve $x$ . (More precisely, it is a function $[0,1] \longrightarrow x^*TM$ with appropriate regularity that I care about, but I don't believe it is necessary to go into such details). I am trying to calculate: $\dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0}\displaystyle\int_{0}^1 x_s^{*}\lambda$ Where $\lambda$ is an arbitrary (integrable) $1$ -form defined on my manifold $M$ (which we assume to be $\mathbb{R}^n$ ). The source I am reading makes the following claim: $\boxed{\dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0}\displaystyle\int_{0}^1 x_s^{*}\lambda = \displaystyle\int_0^1 x^{*}\mathcal{L}_\zeta\lambda}$ where $\mathcal{L}_\zeta$ denotes the Lie derivative with respect to the vector $\zeta$ defined above. But I'm not entirely sure how to prove it. Here is where my head is at so far: \begin{align} \dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0}\displaystyle\int_{0}^1 x_s^{*}\lambda &= \displaystyle\int_{0}^1 \dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0} \, x_s^{*}\lambda \\ &= \displaystyle\int_0^1 \lim\limits_{\varepsilon \to 0} \frac{1}{\varepsilon}(x_\varepsilon^{*}\lambda - x^{*}\lambda) \textit{     (cause } x_0 = x) \end{align} However, I'm not sure how to formally identify $\lim\limits_{\varepsilon \to 0} \dfrac{1}{\varepsilon}(x_\varepsilon^{*}\lambda - x^{*}\lambda)$ with $x^{*}\mathcal{L}_\zeta \lambda$ . I can see ""philosophically"" why these should be the same ( $\zeta$ is a vector field along the curve $x$ , and it is generated by the ""curve of curves"" $x_s$ . So intuitively, the expression on the left sort of corresponds to a derivative along the flow of $\zeta$ , which is exactly what the Lie derivative is). But then, I'm not sure how to prove it formally because the vector field $\zeta$ is only defined along $x$ , so what does it even mean to take $\mathcal{L}_\zeta \lambda$ ? Do we somehow extend $\zeta$ beyond $x$ in an arbitrary way? And then, since we don't care about this extension,  maybe that's the reason we take the pullback along $x$ , and end up with the expression $x^{*}\mathcal{L}_\zeta\lambda$ ? Any help or progress on the question would be much appreciated. Thank you :)","Say I have a family of curves where is my family's parameter, and is a manifold (which, for all purposes being, we can assume to be ). Additionally, let , which ends up being a vector field along the curve . (More precisely, it is a function with appropriate regularity that I care about, but I don't believe it is necessary to go into such details). I am trying to calculate: Where is an arbitrary (integrable) -form defined on my manifold (which we assume to be ). The source I am reading makes the following claim: where denotes the Lie derivative with respect to the vector defined above. But I'm not entirely sure how to prove it. Here is where my head is at so far: However, I'm not sure how to formally identify with . I can see ""philosophically"" why these should be the same ( is a vector field along the curve , and it is generated by the ""curve of curves"" . So intuitively, the expression on the left sort of corresponds to a derivative along the flow of , which is exactly what the Lie derivative is). But then, I'm not sure how to prove it formally because the vector field is only defined along , so what does it even mean to take ? Do we somehow extend beyond in an arbitrary way? And then, since we don't care about this extension,  maybe that's the reason we take the pullback along , and end up with the expression ? Any help or progress on the question would be much appreciated. Thank you :)","x_s : [0,1] \longrightarrow M s \in (-\epsilon, \epsilon) M \mathbb{R}^n \zeta := \dfrac{\mathrm{d}}{\mathrm{d}s}x_s|_{s = 0} x [0,1] \longrightarrow x^*TM \dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0}\displaystyle\int_{0}^1 x_s^{*}\lambda \lambda 1 M \mathbb{R}^n \boxed{\dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0}\displaystyle\int_{0}^1 x_s^{*}\lambda = \displaystyle\int_0^1 x^{*}\mathcal{L}_\zeta\lambda} \mathcal{L}_\zeta \zeta \begin{align}
\dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0}\displaystyle\int_{0}^1 x_s^{*}\lambda &= \displaystyle\int_{0}^1 \dfrac{\mathrm{d}}{\mathrm{d}s}|_{s = 0} \, x_s^{*}\lambda \\
&= \displaystyle\int_0^1 \lim\limits_{\varepsilon \to 0} \frac{1}{\varepsilon}(x_\varepsilon^{*}\lambda - x^{*}\lambda) \textit{     (cause } x_0 = x)
\end{align} \lim\limits_{\varepsilon \to 0} \dfrac{1}{\varepsilon}(x_\varepsilon^{*}\lambda - x^{*}\lambda) x^{*}\mathcal{L}_\zeta \lambda \zeta x x_s \zeta \zeta x \mathcal{L}_\zeta \lambda \zeta x x x^{*}\mathcal{L}_\zeta\lambda","['functional-analysis', 'differential-geometry', 'differential-forms', 'lie-derivative']"
42,Dimension of the manifold of symmetric rank $r$ $n\times n$ matrices,Dimension of the manifold of symmetric rank   matrices,r n\times n,"I'm currently reading through the paper ""Low-rank matrix completion by Riemannian optimization—extended version"" by Vandereycken, and in this paper the author states that the set $\mathcal{M}_k = \{X\in\mathbb{R}^{n\times n}\vert \text{rank}(X) = k\}$ is a smooth manifold of dimension $k(2n-k)$ . For the proof, the author cites Example 5.30 on page 117 of ""Introduction to Smooth Manifolds"" by Lee, which uses a fairly standard submersion proof to show that $\mathcal{M}_k$ is a submanifold with the dimension given above. My question is twofold: First, is the set $\mathcal{M}_k^{sym} = \{X\in\mathbb{R}^{n\times n}\vert X = X^T, \text{rank}(X) = k\}$ a manifold as well? If one assumes positive semi-definiteness, the answer to this post ( Is the set of symmetric positive semi-definite matrices a smooth manifold with boundary ) indicates that this is a manifold. I'm wondering if the relaxation away from positive semi-definite breaks this. Second, if this is in fact a manifold (which I think it is), what is the embedded dimension of said manifold? The proof in Lee shows that the codimension of $\mathcal{M}_k$ is $(n-k)^2$ , and I thought the proof should generalize to symmetric matrices, but the codimension would have to change as the dimension of symmetric $n\times n$ matrices is $\frac{n(n+1)}{2}$ , which is for small $k$ is smaller than $(n-k)^2$ . I'd appreciate any input on this question/pointers in the right direction.","I'm currently reading through the paper ""Low-rank matrix completion by Riemannian optimization—extended version"" by Vandereycken, and in this paper the author states that the set is a smooth manifold of dimension . For the proof, the author cites Example 5.30 on page 117 of ""Introduction to Smooth Manifolds"" by Lee, which uses a fairly standard submersion proof to show that is a submanifold with the dimension given above. My question is twofold: First, is the set a manifold as well? If one assumes positive semi-definiteness, the answer to this post ( Is the set of symmetric positive semi-definite matrices a smooth manifold with boundary ) indicates that this is a manifold. I'm wondering if the relaxation away from positive semi-definite breaks this. Second, if this is in fact a manifold (which I think it is), what is the embedded dimension of said manifold? The proof in Lee shows that the codimension of is , and I thought the proof should generalize to symmetric matrices, but the codimension would have to change as the dimension of symmetric matrices is , which is for small is smaller than . I'd appreciate any input on this question/pointers in the right direction.","\mathcal{M}_k = \{X\in\mathbb{R}^{n\times n}\vert \text{rank}(X) = k\} k(2n-k) \mathcal{M}_k \mathcal{M}_k^{sym} = \{X\in\mathbb{R}^{n\times n}\vert X = X^T, \text{rank}(X) = k\} \mathcal{M}_k (n-k)^2 n\times n \frac{n(n+1)}{2} k (n-k)^2","['differential-geometry', 'differential-topology', 'non-convex-optimization', 'matrix-analysis']"
43,Effects of perturbation on level set.,Effects of perturbation on level set.,,"Consider the function $f:\mathbb{R}^n\rightarrow \mathbb{R}$ , defined as $f:x\mapsto \|x\|^2_2$ . It's evident that the pre-image $f^{-1}(1)$ becomes $(n-1)$ -sphere $S^{n-1}$ . Consider a smooth $\epsilon$ -perturbation $g$ of $f$ in the uniform sense: $$\|f-g\|_{\operatorname{sup}}<\epsilon$$ I want to prove that $g^{-1}(1)$ can not be embedded in $\mathbb{R}^{n-1}$ if $\epsilon$ is a sufficiently small value. If $g^{-1}(1)$ is a manifold, it is clear because a compact $(n-1)$ -manifold can not be embedded in $\mathbb{R}^{n-1}$ . However, I am not sure that $g^{-1}(1)$ is a manifold because $1$ is not necessarily the regular value of $g$ . But it should be something very similar to $S^{n-1}$ because it divides the entire Euclidean space $\mathbb{R}^n$ into (at least) two components, $g^{-1}([0,1))\supset B_{1-\epsilon}(0) $ and $g^{-1}((1,\infty))\supset \mathbb{R}^n - B_{1+\epsilon}(0) $ . Any assistance you can offer would be greatly appreciated.","Consider the function , defined as . It's evident that the pre-image becomes -sphere . Consider a smooth -perturbation of in the uniform sense: I want to prove that can not be embedded in if is a sufficiently small value. If is a manifold, it is clear because a compact -manifold can not be embedded in . However, I am not sure that is a manifold because is not necessarily the regular value of . But it should be something very similar to because it divides the entire Euclidean space into (at least) two components, and . Any assistance you can offer would be greatly appreciated.","f:\mathbb{R}^n\rightarrow \mathbb{R} f:x\mapsto \|x\|^2_2 f^{-1}(1) (n-1) S^{n-1} \epsilon g f \|f-g\|_{\operatorname{sup}}<\epsilon g^{-1}(1) \mathbb{R}^{n-1} \epsilon g^{-1}(1) (n-1) \mathbb{R}^{n-1} g^{-1}(1) 1 g S^{n-1} \mathbb{R}^n g^{-1}([0,1))\supset B_{1-\epsilon}(0)  g^{-1}((1,\infty))\supset \mathbb{R}^n - B_{1+\epsilon}(0) ","['general-topology', 'differential-geometry', 'algebraic-topology', 'differential-topology', 'geometric-topology']"
44,Preserving the symplectic 2-form vs phase space volume,Preserving the symplectic 2-form vs phase space volume,,"Say I have a Hamiltonian system of $N$ particles in 3D-3V phase space. I'm using some sort of update scheme taking the system from $t^{n-1}$ to $t^{n}$ to $t^{n+1}$ . I want to know if the update scheme is symplectic, volume preserving, or neither, but I want to test this in an experimental way.* If it's symplectic, then the 2-form $\omega = dq \wedge dp = \sum_{i}^{N}{dq_i \wedge dp_i}$ is preserved over time (minor question here, are $dq$ and $dp$ vectors or scalars? I'm assuming vectors representing individual particles in phase space, but I could see an argument made for simply iterating over $3N$ $q,p$ pairs rather than $N$ vectors), which in turn implies phase space volume is preserved. My question is, how do I test this computationally? My current thought: Compute $dq_i^n = q_i^{n}-q_i^{n-1}, dp_i^{n} = p_i^{n}-p_i^{n-1}$ , which are vectors with three components. Taking the 2-form is, in the case of vectors in $\mathbb{R}^3$ , just the cross product (from what I understand it's a bit more complicated than ""just the cross product"" in that the result is a two-vector or something to that effect, but I'm only concerned in having something to compare over the simulation, so as long as I'm on the right track here I'm content). Sum up all $dq_i^n \wedge dp_i^n$ . Do the same for $dq_i^{n+1} \wedge dp_i^{n+1}$ . If the scheme is symplectic, then the difference between these two values should be bound over the simulation (unsure if I'm comparing individual components or the norms of those values). For phase space volume preservation, simply compute $dV_i^n = dq_{1i}^ndq_{2i}^ndq_{3i}^ndp_{2i}^ndp_{1i}^ndp_{3i}^n$ , take the product $\Pi_i^N{dV_i^n}$ up over all $i$ , do the same for $dV_i^{n+1}$ , compare over timesteps, the difference should be bound over the simulation. Frustratingly, I cannot find any resources to confirm or deny this.** So I suppose my question is in two parts, first am I right/where am I wrong, second is what are some good resources for looking more into this? Incidentally, symplecticity $\implies$ phase space volume preservation, but whenever I try to prove that the above follows that rule I very quickly get lost in about a million cross terms, which either means I need to get back to it or I'm on the wrong track. *I know if $\Omega$ is my update matrix, then $\Omega^TJ\Omega = J$ implies symplecticity and $det(\Omega)=1$ implies volume preservation. This is great, but I'd like to have a practical test for my code. I've been using the Hamiltonian as my litmus test, making sure it's bound over time, but from what I understand this doesn't necessarily track phase space volume preservation or symplecticity, just total energy in the system. **Every paper, website, and youtube video I've seen has shown the same picture of a box or a smiley face or whatever in phase space being stretched with the area/volume being preserved over time, which is helpful in getting an intuitive idea, not helpful in actually solving the problem.","Say I have a Hamiltonian system of particles in 3D-3V phase space. I'm using some sort of update scheme taking the system from to to . I want to know if the update scheme is symplectic, volume preserving, or neither, but I want to test this in an experimental way.* If it's symplectic, then the 2-form is preserved over time (minor question here, are and vectors or scalars? I'm assuming vectors representing individual particles in phase space, but I could see an argument made for simply iterating over pairs rather than vectors), which in turn implies phase space volume is preserved. My question is, how do I test this computationally? My current thought: Compute , which are vectors with three components. Taking the 2-form is, in the case of vectors in , just the cross product (from what I understand it's a bit more complicated than ""just the cross product"" in that the result is a two-vector or something to that effect, but I'm only concerned in having something to compare over the simulation, so as long as I'm on the right track here I'm content). Sum up all . Do the same for . If the scheme is symplectic, then the difference between these two values should be bound over the simulation (unsure if I'm comparing individual components or the norms of those values). For phase space volume preservation, simply compute , take the product up over all , do the same for , compare over timesteps, the difference should be bound over the simulation. Frustratingly, I cannot find any resources to confirm or deny this.** So I suppose my question is in two parts, first am I right/where am I wrong, second is what are some good resources for looking more into this? Incidentally, symplecticity phase space volume preservation, but whenever I try to prove that the above follows that rule I very quickly get lost in about a million cross terms, which either means I need to get back to it or I'm on the wrong track. *I know if is my update matrix, then implies symplecticity and implies volume preservation. This is great, but I'd like to have a practical test for my code. I've been using the Hamiltonian as my litmus test, making sure it's bound over time, but from what I understand this doesn't necessarily track phase space volume preservation or symplecticity, just total energy in the system. **Every paper, website, and youtube video I've seen has shown the same picture of a box or a smiley face or whatever in phase space being stretched with the area/volume being preserved over time, which is helpful in getting an intuitive idea, not helpful in actually solving the problem.","N t^{n-1} t^{n} t^{n+1} \omega = dq \wedge dp = \sum_{i}^{N}{dq_i \wedge dp_i} dq dp 3N q,p N dq_i^n = q_i^{n}-q_i^{n-1}, dp_i^{n} = p_i^{n}-p_i^{n-1} \mathbb{R}^3 dq_i^n \wedge dp_i^n dq_i^{n+1} \wedge dp_i^{n+1} dV_i^n = dq_{1i}^ndq_{2i}^ndq_{3i}^ndp_{2i}^ndp_{1i}^ndp_{3i}^n \Pi_i^N{dV_i^n} i dV_i^{n+1} \implies \Omega \Omega^TJ\Omega = J det(\Omega)=1","['differential-geometry', 'differential-forms', 'classical-mechanics', 'symplectic-geometry', 'symplectic-linear-algebra']"
45,reference and full statement for the fundamental group of $\Bbb{P}_n^k-Y$ is $\Bbb{Z}/(d)$?,reference and full statement for the fundamental group of  is ?,\Bbb{P}_n^k-Y \Bbb{Z}/(d),"In Vakil’s FOAG, exercise 15.4.M, there is a remark: 15.4.M. EXERCISE: A TORSION PICARD GROUP. Suppose that $Y$ is a hypersurface in $\Bbb{P}^n_k$ corresponding to an irreducible degree d polynomial. Show that $Pic(\Bbb{P}^n_k-Y) = Z/(d)$ . (For differential geometers: this is related to the fact that $π_1(\Bbb{P}^n_k - Y)= Z/(d)$ .) Is there any reference for the related differential geometry fact? and what is the full statement for it? Is the topology still using the Zariski topology? If not, should the field $k$ be the $\Bbb{C}$ ? Thank you in advance.","In Vakil’s FOAG, exercise 15.4.M, there is a remark: 15.4.M. EXERCISE: A TORSION PICARD GROUP. Suppose that is a hypersurface in corresponding to an irreducible degree d polynomial. Show that . (For differential geometers: this is related to the fact that .) Is there any reference for the related differential geometry fact? and what is the full statement for it? Is the topology still using the Zariski topology? If not, should the field be the ? Thank you in advance.",Y \Bbb{P}^n_k Pic(\Bbb{P}^n_k-Y) = Z/(d) π_1(\Bbb{P}^n_k - Y)= Z/(d) k \Bbb{C},"['differential-geometry', 'algebraic-geometry', 'reference-request', 'fundamental-groups', 'picard-group']"
46,"“Simple” formula, besides Cartan’s equation, for exterior covariant derivative of vector-valued forms on principal bundle","“Simple” formula, besides Cartan’s equation, for exterior covariant derivative of vector-valued forms on principal bundle",,"Let $P$ be a principal bundle with structure group $G$ , equipped with a principal connection, whose connection $1$ -form we denote $\omega$ . Suppose we also have a linear representation $\rho:G\to GL(V)$ (which then gives rise to a right-action $(g,v)\mapsto\rho(g^{-1})(v)$ and by taking the tangent at the identity gives us $\rho_*:\mathfrak{g}\to\text{End}(V)$ , which can be thought of as a bilinear map $\rho’:\mathfrak{g}\times V\to V$ ). Finally, let $\alpha$ be a $V$ -valued $k$ -form on $P$ . My question is if there is any “nice” formula for the exterior covariant derivative $D\alpha$ in general? I know some special cases: if $\alpha=\omega$ is the connection 1-form itself, then we get Cartan’s structure equation for the curvature. if $k\geq 2$ and $\alpha$ is vertical then $D\alpha=0$ (a useful remark when proving Bianchi’s identity $D\Omega=0$ ). if $\alpha$ is horizontal and $G$ -equivariant (for the naturally induced right action of $G$ on the $k^{th}$ exterior power of $TR$ , and the right action of $G$ on $V$ described above), i.e a “tensorial form on $P$ of type $(V,\rho)$ ”, then we have $D\alpha=d\alpha+\omega\wedge_{\rho’}\alpha$ . Is there a more general formula which addresses other cases as well? My guess is not because the definition of $D\alpha$ involves the various horizontal projections, so if we make no further assumptions on $\alpha$ , then it’s going to be hard to simplify (and annihilate many of the terms when unwinding definitions). In fact, even for $k=1$ and assuming $\alpha$ is vertical I run into trouble trying to obtain a “nice” formula, because unlike the connection 1-form, we don’t have the nice property that $\omega(X_{\xi})=\xi$ (where $X_{\xi}$ is the “fundamental” vertical vector field on $P$ induced by $\xi\in\mathfrak{g}$ ) so the proof of Cartan’s structure equation doesn’t really go through here (unless I’m missing something). Note I’m also fine with accepting there isn’t really a general formula (though an accompanying (heuristic even) explanation would be nice), but just curious if there exists one.","Let be a principal bundle with structure group , equipped with a principal connection, whose connection -form we denote . Suppose we also have a linear representation (which then gives rise to a right-action and by taking the tangent at the identity gives us , which can be thought of as a bilinear map ). Finally, let be a -valued -form on . My question is if there is any “nice” formula for the exterior covariant derivative in general? I know some special cases: if is the connection 1-form itself, then we get Cartan’s structure equation for the curvature. if and is vertical then (a useful remark when proving Bianchi’s identity ). if is horizontal and -equivariant (for the naturally induced right action of on the exterior power of , and the right action of on described above), i.e a “tensorial form on of type ”, then we have . Is there a more general formula which addresses other cases as well? My guess is not because the definition of involves the various horizontal projections, so if we make no further assumptions on , then it’s going to be hard to simplify (and annihilate many of the terms when unwinding definitions). In fact, even for and assuming is vertical I run into trouble trying to obtain a “nice” formula, because unlike the connection 1-form, we don’t have the nice property that (where is the “fundamental” vertical vector field on induced by ) so the proof of Cartan’s structure equation doesn’t really go through here (unless I’m missing something). Note I’m also fine with accepting there isn’t really a general formula (though an accompanying (heuristic even) explanation would be nice), but just curious if there exists one.","P G 1 \omega \rho:G\to GL(V) (g,v)\mapsto\rho(g^{-1})(v) \rho_*:\mathfrak{g}\to\text{End}(V) \rho’:\mathfrak{g}\times V\to V \alpha V k P D\alpha \alpha=\omega k\geq 2 \alpha D\alpha=0 D\Omega=0 \alpha G G k^{th} TR G V P (V,\rho) D\alpha=d\alpha+\omega\wedge_{\rho’}\alpha D\alpha \alpha k=1 \alpha \omega(X_{\xi})=\xi X_{\xi} P \xi\in\mathfrak{g}","['differential-geometry', 'connections', 'principal-bundles']"
47,Are there harmonic 1-forms which induce harmonic circle-valued maps?,Are there harmonic 1-forms which induce harmonic circle-valued maps?,,"I was reading this question and it got me thinking more about harmonic maps. A smooth circle-valued map $\varphi : M \to S^1$ from a Riemannian manifold is harmonic if $\varphi^*(d \theta)$ is in the kernel of Hodge Laplace operator $\Delta^1 : \Omega^1(M) \to \Omega^1(M)$ . It seems to me that, given a nice enough harmonic $\omega \in \Omega^1(M)$ , one might be able to induce a harmonic map. Suppose that $\omega$ is harmonic, and in addition, that $$\int_\gamma \omega \in \mathbb{Z}$$ for all $[\gamma] \in \pi_1(M)$ . Since $\omega$ is closed, this doesn't depend on the homotopy class of $\gamma$ . One should be able to define a map $\varphi_\omega : M \to S^1 = \mathbb{R}/\mathbb{Z}$ by mapping a base-point $x$ of $M$ to $1$ and defining the rest of the map via $$\varphi_\omega(x') \mapsto exp(2 \pi i \int_\gamma \omega)$$ for any path $\gamma$ from $x$ to $x'$ . My question: is it possible that $$ \varphi_\omega^*(d \theta) = \omega$$ thus recovering the original harmonic and generating a harmonic map? The example in my head is a harmonic on $S^1 \times S^1$ which 'wraps' around the first coordinate.","I was reading this question and it got me thinking more about harmonic maps. A smooth circle-valued map from a Riemannian manifold is harmonic if is in the kernel of Hodge Laplace operator . It seems to me that, given a nice enough harmonic , one might be able to induce a harmonic map. Suppose that is harmonic, and in addition, that for all . Since is closed, this doesn't depend on the homotopy class of . One should be able to define a map by mapping a base-point of to and defining the rest of the map via for any path from to . My question: is it possible that thus recovering the original harmonic and generating a harmonic map? The example in my head is a harmonic on which 'wraps' around the first coordinate.",\varphi : M \to S^1 \varphi^*(d \theta) \Delta^1 : \Omega^1(M) \to \Omega^1(M) \omega \in \Omega^1(M) \omega \int_\gamma \omega \in \mathbb{Z} [\gamma] \in \pi_1(M) \omega \gamma \varphi_\omega : M \to S^1 = \mathbb{R}/\mathbb{Z} x M 1 \varphi_\omega(x') \mapsto exp(2 \pi i \int_\gamma \omega) \gamma x x'  \varphi_\omega^*(d \theta) = \omega S^1 \times S^1,"['differential-geometry', 'differential-forms', 'harmonic-functions', 'laplacian']"
48,Reference request: Lorentzian Ricci flow,Reference request: Lorentzian Ricci flow,,"I have been studying some aspects of Ricci flow, namely existence, uniqueness, finite time extinction, the preservation of curvature bounds via the maximum principle, and the modifications of Ricci flow that lead to long time solutions with limiting geometries of interest like constant curvature metrics. As a physicist, I naturally wanted to see what the analogue of Ricci flow is for Lorentzian manifolds. A couple of problems arise: (1) globally hyperbolic spacetimes are not closed, (2) non compact manifolds without further conditions may render the flow ill-defined for existence of solutions, and (3) the Laplacian in this case is not elliptic given the metric is not positive. Does anyone have any good references where progress is made on some of these problems in the Lorentzian setting? I would also appreciate any insight from the community here, as I am a bit out of my depth.","I have been studying some aspects of Ricci flow, namely existence, uniqueness, finite time extinction, the preservation of curvature bounds via the maximum principle, and the modifications of Ricci flow that lead to long time solutions with limiting geometries of interest like constant curvature metrics. As a physicist, I naturally wanted to see what the analogue of Ricci flow is for Lorentzian manifolds. A couple of problems arise: (1) globally hyperbolic spacetimes are not closed, (2) non compact manifolds without further conditions may render the flow ill-defined for existence of solutions, and (3) the Laplacian in this case is not elliptic given the metric is not positive. Does anyone have any good references where progress is made on some of these problems in the Lorentzian setting? I would also appreciate any insight from the community here, as I am a bit out of my depth.",,"['differential-geometry', 'reference-request', 'semi-riemannian-geometry', 'ricci-flow']"
49,First order elliptic operator with compact resolvent.,First order elliptic operator with compact resolvent.,,"I am working on Omar Mohsen's article Witten deformation using Lie groupoids and having trouble with Proposition 2.1, which says Let $W$ be a complete Riemannian manifold, $\sharp : T^*W\to TW$ the musical isomorphism given by the Riemannian metric, $\alpha$ a 1-form on $W$ such that the form $\mathrm{d}\alpha$ is bounded, the section of $\mathrm{End}(\Lambda_{\mathbb{C}}T^*W)$ given by $\mathcal{L}_{\alpha^\sharp}+\mathcal{L}^*_{\alpha^\sharp}$ is bounded, $\lVert\alpha\rVert$ is a proper function, then the operator $d+d^*+c(\alpha)$ on $L^2(\Lambda_{\mathbb{C}}T^*W)$ is a self-adjoint elliptic operator with compact resolvent, where $L^2(\Lambda_{\mathbb{C}}T^*W)$ is the Hilbert space of $L^2$ sections on $\Lambda_{\mathbb{C}}T^*W$ , $d$ is the exterior derivative and $d^*$ its formal adjoint, $c(\alpha)=\alpha\wedge\cdot+i_{\alpha^\sharp}(\cdot)$ is the Clifford action. I can prove that it is self-adjoint and elliptic, but I have no idea of the compactness of its resolvent. Any help would be grateful!","I am working on Omar Mohsen's article Witten deformation using Lie groupoids and having trouble with Proposition 2.1, which says Let be a complete Riemannian manifold, the musical isomorphism given by the Riemannian metric, a 1-form on such that the form is bounded, the section of given by is bounded, is a proper function, then the operator on is a self-adjoint elliptic operator with compact resolvent, where is the Hilbert space of sections on , is the exterior derivative and its formal adjoint, is the Clifford action. I can prove that it is self-adjoint and elliptic, but I have no idea of the compactness of its resolvent. Any help would be grateful!",W \sharp : T^*W\to TW \alpha W \mathrm{d}\alpha \mathrm{End}(\Lambda_{\mathbb{C}}T^*W) \mathcal{L}_{\alpha^\sharp}+\mathcal{L}^*_{\alpha^\sharp} \lVert\alpha\rVert d+d^*+c(\alpha) L^2(\Lambda_{\mathbb{C}}T^*W) L^2(\Lambda_{\mathbb{C}}T^*W) L^2 \Lambda_{\mathbb{C}}T^*W d d^* c(\alpha)=\alpha\wedge\cdot+i_{\alpha^\sharp}(\cdot),"['functional-analysis', 'differential-geometry', 'operator-theory']"
50,Gaussian curvature of a two-dimensional manifold with $C^1$ metric,Gaussian curvature of a two-dimensional manifold with  metric,C^1,"I am working on a problem in geometric analysis and I arrived at the following question: what would be the minimum of regularity I could require from a metric in order to define a first fundamental form on an abstract surface (two-dimensional manifold) with Gaussian curvature ${\cal K}=-1$ ? More precisely, let us consider the following: assume the existence of $C^1$ functions $f_{ij}=f_{ij}(x,t),\,\,1\leq i\leq 3,\,\,1\leq j\leq 2$ , defined on an open set $U\subseteq{\mathbb R}^2$ (non-empty, of course) such that the one-forms $\omega_i=f_{i1}dx+f_{i2}dt,\quad 1\leq i\leq 3$ , satisfy the equations \begin{equation} d\omega_1=\omega_3\wedge\omega_2,\quad d\omega_2=\omega_1\wedge\omega_3,\quad d\omega_3=\omega_1\wedge\omega_2.\quad\quad (1) \end{equation} The equations above make sense with the required regularity and, as a result, $I=\omega_1^2+\omega_2^2$ would define a $C^1$ first fundamental form ( $C^1$ -metric) for a manifold with Gaussian curvature ${\cal K}=-1$ . The problem is that, usually, in differential geometry one requires the metric as being a tensor with $C^2$ components, e.g, see Theorem 4.24, page 153, in [W. Kühnel, Differential Geometry, 3nd Ed., AMS, (2015)]. Actually, most of the books I studied consider $C^\infty$ metrics. This one by Künhel is one of the few I found requiring finite regularity, but being $C^2$ would contradict what I wrote above. On the other hand, on page 760 of the paper [P. Hartman and A. Wintner, On the fundamental equations of differential geometry, Amer. J. Math., vol. 72, 757--774, (1950)], the authors consider $C^1$ metrics, but in conjunction with a $C^0$ second fundamental form. My questions is: Would it be possible to require $C^1$ regularity for the metric (or the forms satisfying (1))  and still have a well defined Gaussian curvature? The paper by Hartman and Wintner apparently supports a positive answer, but the fact that usually books on differential geometry require higher regularity makes me worry about if I could or not have it.","I am working on a problem in geometric analysis and I arrived at the following question: what would be the minimum of regularity I could require from a metric in order to define a first fundamental form on an abstract surface (two-dimensional manifold) with Gaussian curvature ? More precisely, let us consider the following: assume the existence of functions , defined on an open set (non-empty, of course) such that the one-forms , satisfy the equations The equations above make sense with the required regularity and, as a result, would define a first fundamental form ( -metric) for a manifold with Gaussian curvature . The problem is that, usually, in differential geometry one requires the metric as being a tensor with components, e.g, see Theorem 4.24, page 153, in [W. Kühnel, Differential Geometry, 3nd Ed., AMS, (2015)]. Actually, most of the books I studied consider metrics. This one by Künhel is one of the few I found requiring finite regularity, but being would contradict what I wrote above. On the other hand, on page 760 of the paper [P. Hartman and A. Wintner, On the fundamental equations of differential geometry, Amer. J. Math., vol. 72, 757--774, (1950)], the authors consider metrics, but in conjunction with a second fundamental form. My questions is: Would it be possible to require regularity for the metric (or the forms satisfying (1))  and still have a well defined Gaussian curvature? The paper by Hartman and Wintner apparently supports a positive answer, but the fact that usually books on differential geometry require higher regularity makes me worry about if I could or not have it.","{\cal K}=-1 C^1 f_{ij}=f_{ij}(x,t),\,\,1\leq i\leq 3,\,\,1\leq j\leq 2 U\subseteq{\mathbb R}^2 \omega_i=f_{i1}dx+f_{i2}dt,\quad 1\leq i\leq 3 \begin{equation}
d\omega_1=\omega_3\wedge\omega_2,\quad d\omega_2=\omega_1\wedge\omega_3,\quad d\omega_3=\omega_1\wedge\omega_2.\quad\quad (1)
\end{equation} I=\omega_1^2+\omega_2^2 C^1 C^1 {\cal K}=-1 C^2 C^\infty C^2 C^1 C^0 C^1","['differential-geometry', 'differential-forms', 'curvature']"
51,How to define Brownian motion for constraint matrix manifold?,How to define Brownian motion for constraint matrix manifold?,,"My problem at hand is the construction of a Brownian motion on a constraint matrix manifold $^\color{magenta}\star$ denoted by $\mathcal{M}$ , which is represented as follows: $$ \mathcal{M} = \left\{ P\in \mathbb{R}^{n\times d} \mid \operatorname{Tr} \left( P^T A_k P \right) = b_k, k = 1, 2, \dots, m \right\} $$ where $A_k \in \mathbb{R}^{n\times n}$ are given symmetric matrices and $b_k \in \mathbb{R}$ are given scalars. My initial thought is to construct this Brownian motion based on the tangent space of the manifold. The tangent space at a point $P$ on the manifold, denoted by $T_{P}\mathcal{M}$ , is defined as follows: $$ T_{P}\mathcal{M} = \left\{ Z \in \mathbb{R}^{n\times d} \mid \operatorname{Tr} \left( P^T A_k Z \right) = 0, k = 1, 2, \dots, m \right\} $$ However, obtaining the basis of this tangent space poses a challenge for me as I didn't find explicit forms of those bases. Does anyone have an idea about constructing a Brownian motion for this particular manifold? Another thought is to project the Brownian motion from space of all matrices $\mathbb{R}^{n\times d}$ to this manifold. As the normal space w.r.t. Frobenius inner product is $$ N_{P}\mathcal{M} = \left\{\sum_{k=1}^m \alpha_k A_k P, \alpha_k \in \mathbb{R}\right\}, $$ the orthogonal projection to $T_P \mathcal{M}$ is $\pi_P(X)= X - \sum_{k=1}^m \alpha_k A_k P$ and these $\alpha_k$ can be solved by equations $\operatorname{Tr} \left( P^T A_k X \right) = 0, k = 1, 2, \dots, m$ . However, I cannot connect the relationship between the projected Brownian motion and the Brownian motion on this manifold as they are not the same in general. $\color{magenta}\star$ Michel Journée, Francis Bach, Pierre-Antoine Absil, Rodolphe Sepulchre, Low-rank optimization on the cone of positive semidefinite matrices , SIAM Journal on Optimization, Volume 20, Issue 5, 2010.","My problem at hand is the construction of a Brownian motion on a constraint matrix manifold denoted by , which is represented as follows: where are given symmetric matrices and are given scalars. My initial thought is to construct this Brownian motion based on the tangent space of the manifold. The tangent space at a point on the manifold, denoted by , is defined as follows: However, obtaining the basis of this tangent space poses a challenge for me as I didn't find explicit forms of those bases. Does anyone have an idea about constructing a Brownian motion for this particular manifold? Another thought is to project the Brownian motion from space of all matrices to this manifold. As the normal space w.r.t. Frobenius inner product is the orthogonal projection to is and these can be solved by equations . However, I cannot connect the relationship between the projected Brownian motion and the Brownian motion on this manifold as they are not the same in general. Michel Journée, Francis Bach, Pierre-Antoine Absil, Rodolphe Sepulchre, Low-rank optimization on the cone of positive semidefinite matrices , SIAM Journal on Optimization, Volume 20, Issue 5, 2010.","^\color{magenta}\star \mathcal{M}  \mathcal{M} = \left\{ P\in \mathbb{R}^{n\times d} \mid \operatorname{Tr} \left( P^T A_k P \right) = b_k, k = 1, 2, \dots, m \right\}  A_k \in \mathbb{R}^{n\times n} b_k \in \mathbb{R} P T_{P}\mathcal{M}  T_{P}\mathcal{M} = \left\{ Z \in \mathbb{R}^{n\times d} \mid \operatorname{Tr} \left( P^T A_k Z \right) = 0, k = 1, 2, \dots, m \right\}  \mathbb{R}^{n\times d} 
N_{P}\mathcal{M} = \left\{\sum_{k=1}^m \alpha_k A_k P, \alpha_k \in \mathbb{R}\right\},
 T_P \mathcal{M} \pi_P(X)= X - \sum_{k=1}^m \alpha_k A_k P \alpha_k \operatorname{Tr} \left( P^T A_k X \right) = 0, k = 1, 2, \dots, m \color{magenta}\star","['probability', 'matrices', 'differential-geometry', 'stochastic-processes', 'riemannian-geometry']"
52,Relation between Ricci and Kähler forms on a cscK surface,Relation between Ricci and Kähler forms on a cscK surface,,"I'm studying the paper https://arxiv.org/abs/dg-ga/9506002 from LeBrun and I'm stuck on the the last part of the proof of Theorem 2. The author claims that on a Kähler surface $(M,g,J)$ with constant scalar curvature $s$ , the Ricci and the Kähler form are related by $$ \rho^+ = \frac{s}{4}\omega $$ where $\rho^+$ is the self-dual component of the Ricci form. I suppose it could be a consequence of some property of cscK surfaces but I haven't found any reference for this fact. Can someone gently help to enlight on this? Thank you for any advice or just for your time","I'm studying the paper https://arxiv.org/abs/dg-ga/9506002 from LeBrun and I'm stuck on the the last part of the proof of Theorem 2. The author claims that on a Kähler surface with constant scalar curvature , the Ricci and the Kähler form are related by where is the self-dual component of the Ricci form. I suppose it could be a consequence of some property of cscK surfaces but I haven't found any reference for this fact. Can someone gently help to enlight on this? Thank you for any advice or just for your time","(M,g,J) s 
\rho^+ = \frac{s}{4}\omega
 \rho^+","['differential-geometry', 'complex-geometry', 'kahler-manifolds']"
53,Is every Euclidean tensor an affine tensor?,Is every Euclidean tensor an affine tensor?,,"Let $F(M)$ be the first order frame bundle on a $C^\infty$ smooth real manifold $M$ of dimension $m$ , and $O(M)$ the bundle of all orthonormal frames. $F(M)$ is a $GL(m)$ -principal bundle, and $O(M)$ is an $O(m)$ -principal bundle. In the following, I use $G$ to denote either $GL(m)$ or $O(m)$ and $P$ to denote the total space $F(M)$ or $O(M)$ respectively, of the principal fibre bundle $(F(M),p,M,GL(m))$ or $(O(M),p,M,O(m))$ , respectively. So the general notation of the PFB is $(P,p,M,G)$ . Let $V$ be a real vector space and $\rho: G \to GL(V)$ a linear representation of $G$ on $V$ . A smooth map $f: P \to V$ is called a "" $G$ -tensor of type $(V,\rho)$ on $M$ ,"" if $\forall g \in G, u \in P: f(u.g) = \rho(g^{-1})(f(u))$ Now for my question : Does every $O(m)$ -tensor of type $(V,\rho)$ on $M$ lift to a $GL(m)$ -tensor of type $(V\!\uparrow_{O(m)}^{GL(m)}\, , \rho\!\uparrow_{O(m)}^{GL(m)}\, )$ for the induced representation $\rho\!\uparrow_{O(m)}^{GL(m)}$ of the group $GL(m)$ on $V$ ? In other words, does every Cartensian (Euclidean) tensor field on $M$ lift to an affine tensor field on $M$ ? My guess is: Yes. Somehow, because $O(m)$ is the maximal compact subgroup of $GL(m)$ . But is there an ""easy"" proof, or a reference to the literature? Thank you very much! Remark: Maybe just consider the associated bundles, instead of sections, and use an extension of structure group: Let $E$ be the associated vector bundle to $(O(M),p,M,O(m))$ with typical fibre $V$ obtained from the action $\rho$ of $O(m)$ on $V$ . Given the group homomorphism (embedding) $\iota: O(m) \hookrightarrow GL(m)$ , apply the ""extension of structure groups functor"" $GL(M) \times_{M,\iota, O(m)} \, (.) $ to the bundle $E$ , and then prove that $GL(M) \times_{M,\iota, O(m)} E $ is isomorphic, as real vector bundles over $M$ , to $E$ ? ========= Edit 1, one day later, due to some findings: The following theorem can be found in a compilatory master thesis by Sandon : So, if the left action $\rho: O(m) \to Aut(V)$ on $V$ is the restriction to $O(m)$ of a left action $GL(m) \to Aut(V)$ on the same vector space $V$ , then, indeed, the (associated) vector bundles (over $M$ ) $F(M) \times_{GL(m)} V$ and $O(M) \times_{O(m)} V$ are isomorphic (as vector bundles over $M$ ), and have corresponding smooth sections. Therefore, for such $O(m)$ -actions $(\rho\downarrow^{Gl(m)}_{O(m)} \, ,V)$ , which are a restriction of a $GL(m)$ action $\rho$ , every $O(m)$ -tensor of type $(\rho\downarrow^{Gl(m)}_{O(m)},V)$ indeed stems from a $GL(m)$ -tensor of type $(\rho,V)$ , Cartensian and affine tensors are the same. I guess, the general case can now be settled by using Frobenius reciprocity, universal property of the induced action, and/or Mackey machinery. Because a given left $O(m)$ action can be considered the restriction to $O(m)$ of its $GL(m)$ -induction.","Let be the first order frame bundle on a smooth real manifold of dimension , and the bundle of all orthonormal frames. is a -principal bundle, and is an -principal bundle. In the following, I use to denote either or and to denote the total space or respectively, of the principal fibre bundle or , respectively. So the general notation of the PFB is . Let be a real vector space and a linear representation of on . A smooth map is called a "" -tensor of type on ,"" if Now for my question : Does every -tensor of type on lift to a -tensor of type for the induced representation of the group on ? In other words, does every Cartensian (Euclidean) tensor field on lift to an affine tensor field on ? My guess is: Yes. Somehow, because is the maximal compact subgroup of . But is there an ""easy"" proof, or a reference to the literature? Thank you very much! Remark: Maybe just consider the associated bundles, instead of sections, and use an extension of structure group: Let be the associated vector bundle to with typical fibre obtained from the action of on . Given the group homomorphism (embedding) , apply the ""extension of structure groups functor"" to the bundle , and then prove that is isomorphic, as real vector bundles over , to ? ========= Edit 1, one day later, due to some findings: The following theorem can be found in a compilatory master thesis by Sandon : So, if the left action on is the restriction to of a left action on the same vector space , then, indeed, the (associated) vector bundles (over ) and are isomorphic (as vector bundles over ), and have corresponding smooth sections. Therefore, for such -actions , which are a restriction of a action , every -tensor of type indeed stems from a -tensor of type , Cartensian and affine tensors are the same. I guess, the general case can now be settled by using Frobenius reciprocity, universal property of the induced action, and/or Mackey machinery. Because a given left action can be considered the restriction to of its -induction.","F(M) C^\infty M m O(M) F(M) GL(m) O(M) O(m) G GL(m) O(m) P F(M) O(M) (F(M),p,M,GL(m)) (O(M),p,M,O(m)) (P,p,M,G) V \rho: G \to GL(V) G V f: P \to V G (V,\rho) M \forall g \in G, u \in P: f(u.g) = \rho(g^{-1})(f(u)) O(m) (V,\rho) M GL(m) (V\!\uparrow_{O(m)}^{GL(m)}\, , \rho\!\uparrow_{O(m)}^{GL(m)}\, ) \rho\!\uparrow_{O(m)}^{GL(m)} GL(m) V M M O(m) GL(m) E (O(M),p,M,O(m)) V \rho O(m) V \iota: O(m) \hookrightarrow GL(m) GL(M) \times_{M,\iota, O(m)} \, (.)  E GL(M) \times_{M,\iota, O(m)} E  M E \rho: O(m) \to Aut(V) V O(m) GL(m) \to Aut(V) V M F(M) \times_{GL(m)} V O(M) \times_{O(m)} V M O(m) (\rho\downarrow^{Gl(m)}_{O(m)} \, ,V) GL(m) \rho O(m) (\rho\downarrow^{Gl(m)}_{O(m)},V) GL(m) (\rho,V) O(m) O(m) GL(m)","['differential-geometry', 'tensors', 'principal-bundles']"
54,Gluing two disks to get an exotic sphere,Gluing two disks to get an exotic sphere,,"I have found interest in the subject of exotic spheres. Particularly, the 7-sphere. To create such a sphere, you glue two copies $\mathbb{D}^4\times \mathbb{S}^3$ along the boundary identifying $(u,v)$ with $(u,u^hvu^j)$ such that $h+j=\pm1$ . Now my question is, the fact that I am trying to construct such a sphere by gluing two 7-disks along the boundary via a diffeomorphism. However, it seems I cannot find such a diffeomorphism explicitly. By diffeomorphism I mean the map $h:\partial \mathbb{S}^6\to\partial \mathbb{S}^6$ . Any help is appreciated.","I have found interest in the subject of exotic spheres. Particularly, the 7-sphere. To create such a sphere, you glue two copies along the boundary identifying with such that . Now my question is, the fact that I am trying to construct such a sphere by gluing two 7-disks along the boundary via a diffeomorphism. However, it seems I cannot find such a diffeomorphism explicitly. By diffeomorphism I mean the map . Any help is appreciated.","\mathbb{D}^4\times \mathbb{S}^3 (u,v) (u,u^hvu^j) h+j=\pm1 h:\partial \mathbb{S}^6\to\partial \mathbb{S}^6","['differential-geometry', 'spheres', 'manifolds-with-boundary']"
55,"How to understand Cartan formula $[L_X,i_Y]=i_{[X,Y]}$ geometrically?",How to understand Cartan formula  geometrically?,"[L_X,i_Y]=i_{[X,Y]}","Let $M$ be a smooth manifold, $X,Y$ be the vector field over $M$ , the Lie derivative $L_X$ is defined by $L_X=d\circ i_X+i_X\circ d$ , where $i_X$ means contraction operation of $X$ , then by a complicated computation, we can prove the Cartan formula $[L_X,i_Y]=i_{[X,Y]}$ algebraically, but does anyone have a geometric intuition about why it should be true?","Let be a smooth manifold, be the vector field over , the Lie derivative is defined by , where means contraction operation of , then by a complicated computation, we can prove the Cartan formula algebraically, but does anyone have a geometric intuition about why it should be true?","M X,Y M L_X L_X=d\circ i_X+i_X\circ d i_X X [L_X,i_Y]=i_{[X,Y]}",['differential-geometry']
56,When does a distribution admit a closed top-dimensional differential form?,When does a distribution admit a closed top-dimensional differential form?,,"Let $M^n$ be a smooth manifold. Let $\mathcal{D}$ be a $k$ -dimensional integrable distribution on $M$ . Denote by $\mathcal{D}^\bot\to M$ the vector bundle which is spanned by the differentials of the set of first integrals of $\mathcal{D}$ . That is, at a point $p$ we have $\mathcal{D}^\bot|_p = \left<\mathrm{d}f\ \Big|\ \forall\xi\in\mathcal{D}|_p\colon\xi(f) = 0\right>$ . Then for any point $p\in M$ there are functions $f^1_p, \ldots, f^{n - k}_p$ such that in a neighbourhood of $p$ the differential $(n - k)$ -form $\omega_{(p)} := \mathrm{d}f^1_p\wedge\ldots\wedge\mathrm{d}f^{n - k}_p$ is nowhere vanishing and the vector bundle $\mathcal{D}^\bot$ equals $\left<\mathrm{d}f^1_p, \ldots, \mathrm{d}f^{n - k}_p\right>$ , so $\omega_{(p)}$ is ""top-dimensional"". Clearly, we have $\mathrm{d}\omega_{(p)} = 0$ . Also, each differential $(n - k)$ -form $\tau\in\bigwedge^{n - k}\mathcal{D}^\bot|_p$ is proportional to $\omega_{(p)}$ . As one can see, the existence of such $\omega_{(p)}$ for each $p\in M$ is a local condition. What I wonder is when a similar condition is met globally. To be precise, the question is the following. When does there exist a nowhere vanishing $(n - k)$ -dimensional differential form $\omega$ such that $\mathrm{d}\omega = 0$ and at each point $p\in M$ the form $\omega$ is proportional to $\omega_{(p)}$ (or, equivalently, $\mathrm{d}\omega = 0$ and $\forall p\in M\colon\omega|_p\in\bigwedge^{n - k}\mathcal{D}^\bot|_p$ )? This obviously always holds for $k = 0, n$ (a constant function and a volume form will suffice). However, I have not been able to think of (and prove) a criterion even for $k = 1$ . In particular, I have tried using a partition of unity but have not succeeded.","Let be a smooth manifold. Let be a -dimensional integrable distribution on . Denote by the vector bundle which is spanned by the differentials of the set of first integrals of . That is, at a point we have . Then for any point there are functions such that in a neighbourhood of the differential -form is nowhere vanishing and the vector bundle equals , so is ""top-dimensional"". Clearly, we have . Also, each differential -form is proportional to . As one can see, the existence of such for each is a local condition. What I wonder is when a similar condition is met globally. To be precise, the question is the following. When does there exist a nowhere vanishing -dimensional differential form such that and at each point the form is proportional to (or, equivalently, and )? This obviously always holds for (a constant function and a volume form will suffice). However, I have not been able to think of (and prove) a criterion even for . In particular, I have tried using a partition of unity but have not succeeded.","M^n \mathcal{D} k M \mathcal{D}^\bot\to M \mathcal{D} p \mathcal{D}^\bot|_p = \left<\mathrm{d}f\ \Big|\ \forall\xi\in\mathcal{D}|_p\colon\xi(f) = 0\right> p\in M f^1_p, \ldots, f^{n - k}_p p (n - k) \omega_{(p)} := \mathrm{d}f^1_p\wedge\ldots\wedge\mathrm{d}f^{n - k}_p \mathcal{D}^\bot \left<\mathrm{d}f^1_p, \ldots, \mathrm{d}f^{n - k}_p\right> \omega_{(p)} \mathrm{d}\omega_{(p)} = 0 (n - k) \tau\in\bigwedge^{n - k}\mathcal{D}^\bot|_p \omega_{(p)} \omega_{(p)} p\in M (n - k) \omega \mathrm{d}\omega = 0 p\in M \omega \omega_{(p)} \mathrm{d}\omega = 0 \forall p\in M\colon\omega|_p\in\bigwedge^{n - k}\mathcal{D}^\bot|_p k = 0, n k = 1","['differential-geometry', 'differential-forms', 'vector-bundles']"
57,de Rham cohomology of the Grassmannian bundle,de Rham cohomology of the Grassmannian bundle,,"Let $X$ be a smooth $n+m$ dimensional manifold and $\pi:Y\rightarrow X$ the bundle whose fibre over any $x\in X$ is the Grassmann manifold of all $m$ dimensional subspaces of $T_xX$ . This is equivalent to the manifold $J^1(X,m)$ of all first order contact elements of dimension $m$ , also called the space of order $1$ jets of $m$ dimensional submanifolds in $X$ . I am interested in knowing the de Rham cohomology $H^\ast_{\mathrm{dR}}(Y)$ of the total space of this bundle in terms of the de Rham cohomology $H^\ast_{\mathrm{dR}}(X)$ of $X$ . I assume this is computable and have been computed, but I cannot find it anywhere and I am not familiar enough with algebraic topology to compute it myself.","Let be a smooth dimensional manifold and the bundle whose fibre over any is the Grassmann manifold of all dimensional subspaces of . This is equivalent to the manifold of all first order contact elements of dimension , also called the space of order jets of dimensional submanifolds in . I am interested in knowing the de Rham cohomology of the total space of this bundle in terms of the de Rham cohomology of . I assume this is computable and have been computed, but I cannot find it anywhere and I am not familiar enough with algebraic topology to compute it myself.","X n+m \pi:Y\rightarrow X x\in X m T_xX J^1(X,m) m 1 m X H^\ast_{\mathrm{dR}}(Y) H^\ast_{\mathrm{dR}}(X) X","['differential-geometry', 'algebraic-topology', 'differential-topology', 'grassmannian', 'jet-bundles']"
58,"How does $H^{1,1}(X,\mathbb Z)$ look like in $H^{1,1}(X,\mathbb R)$?",How does  look like in ?,"H^{1,1}(X,\mathbb Z) H^{1,1}(X,\mathbb R)","Let $X$ be a compact Kahler manifold. Let $c_1:Pic(X)\rightarrow H^2(X,\mathbb Z)$ and $NS(X) = Im(c_1)$ and $H^{1,1}(X,\mathbb Z) = Im(H^2(X,\mathbb Z)\rightarrow H^2(X,\mathbb C))\cap H^{1,1}(X)$ . My question is: Intuitively, how does $H^{1,1}(X,\mathbb Z)$ look like in $H^{1,1}(X,\mathbb R)$ ? Is it a complete lattice? In Demailly's 'Analytic Methods of Algebraic Geometry', he defines the algebraic class of Kahler form as $\mathcal K_{NS} = \mathcal K\cap NS_\mathbb R(X)$ when $X$ is projective. But Lefschetz (1,1)-theorem tells us $Pic(X)\rightarrow H^{1,1}(X,\mathbb Z)$ is surjective. So, why don't we have $\mathcal K\subseteq NS_{\mathbb R}(X)$ ?","Let be a compact Kahler manifold. Let and and . My question is: Intuitively, how does look like in ? Is it a complete lattice? In Demailly's 'Analytic Methods of Algebraic Geometry', he defines the algebraic class of Kahler form as when is projective. But Lefschetz (1,1)-theorem tells us is surjective. So, why don't we have ?","X c_1:Pic(X)\rightarrow H^2(X,\mathbb Z) NS(X) = Im(c_1) H^{1,1}(X,\mathbb Z) = Im(H^2(X,\mathbb Z)\rightarrow H^2(X,\mathbb C))\cap H^{1,1}(X) H^{1,1}(X,\mathbb Z) H^{1,1}(X,\mathbb R) \mathcal K_{NS} = \mathcal K\cap NS_\mathbb R(X) X Pic(X)\rightarrow H^{1,1}(X,\mathbb Z) \mathcal K\subseteq NS_{\mathbb R}(X)","['differential-geometry', 'algebraic-geometry', 'complex-geometry']"
59,Lie derivative of a coordinate form into its coordinate direction,Lie derivative of a coordinate form into its coordinate direction,,"I have to calculate the Lie derivative of $\alpha = d x_1$ with respect to the vector field $X = \partial_1$ , but I cannot use Cartan's magic formula (which would immediatly show that $L_X\alpha= 0$ ). So the flow is given by $\phi_X^t(x) = (x_1+t,x_2,...,x_n)$ , and thus $D\phi_X^t(x) = id_n$ , right? Then it follows that $$\left.\frac{d}{dt}\right|_{t=0}(\phi_X^t(x))^*\alpha = \left.\frac{d}{dt}\right|_{t=0} \alpha\circ id_n = 0,$$ which should be the right answer... but I am not really sure if my linerarization of the flow is actually correct.","I have to calculate the Lie derivative of with respect to the vector field , but I cannot use Cartan's magic formula (which would immediatly show that ). So the flow is given by , and thus , right? Then it follows that which should be the right answer... but I am not really sure if my linerarization of the flow is actually correct.","\alpha = d x_1 X = \partial_1 L_X\alpha= 0 \phi_X^t(x) = (x_1+t,x_2,...,x_n) D\phi_X^t(x) = id_n \left.\frac{d}{dt}\right|_{t=0}(\phi_X^t(x))^*\alpha = \left.\frac{d}{dt}\right|_{t=0} \alpha\circ id_n = 0,","['differential-geometry', 'differential', 'lie-derivative']"
60,regularity condition for a solution of a parabolic PDE on a manifold,regularity condition for a solution of a parabolic PDE on a manifold,,"Given a Riemannian manifold $(M,g)$ (can be taken parallelizable if needed) a second order differential operator $\mathcal{L}$ can be expressed in a local chart as $$ \mathcal{L}f(x)= \left(a^{ij}(x) \partial_i \partial_j+ b^j(x) \partial_j +c(x)\right)f(x) $$ The operator is said uniformly elliptic (w.r. to $g$ ) if, given an atlas $\{(U_\alpha,(x^i)_\alpha)\}$ exists a constant $C>0$ such that in any chart $$ a^{ij}(x) \xi_i\xi_j \ge C g^{ij}(x) \xi_i\xi_j $$ It is immediate that a uniformly elliptic operator is elliptic. Let now $u(t,x)$ a classical solution of the Cauchy problem \begin{align}  \label{parabolic}(\partial_t -\mathcal{L}) u(t,x)&=0\\ u(0,x)&=f(x) \end{align} Where $f: M \rightarrow \mathbb{R}$ Is a smooth function. If we assume the coefficients to be smooth functions  it is true that $\mathcal{L}u(t,x)$ is a solution for the Cauchy problem? i.e has $\mathcal{L}u(t,x)$ the same regularity of $u(t,x)$ ? EDIT: If the manifold is compact the result should follow. Indeed it is possible to prove that for compact manifolds any elliptic operator is the generator of a Feller semi-group.  For a dense classe of functions the semigroup can be written as $e^{tA}$ . By the Kolmogorov backward formula.  for any such function $e^{tA}f$ is a solution of the PDE. If the function is taken to be smooth of course $u(t,x):=e^{tA}f(x)$ is smooth in $t$ and in $x$ . I am not abke to characterize in any useful way the set of functions for which this works.","Given a Riemannian manifold (can be taken parallelizable if needed) a second order differential operator can be expressed in a local chart as The operator is said uniformly elliptic (w.r. to ) if, given an atlas exists a constant such that in any chart It is immediate that a uniformly elliptic operator is elliptic. Let now a classical solution of the Cauchy problem Where Is a smooth function. If we assume the coefficients to be smooth functions  it is true that is a solution for the Cauchy problem? i.e has the same regularity of ? EDIT: If the manifold is compact the result should follow. Indeed it is possible to prove that for compact manifolds any elliptic operator is the generator of a Feller semi-group.  For a dense classe of functions the semigroup can be written as . By the Kolmogorov backward formula.  for any such function is a solution of the PDE. If the function is taken to be smooth of course is smooth in and in . I am not abke to characterize in any useful way the set of functions for which this works.","(M,g) \mathcal{L} 
\mathcal{L}f(x)= \left(a^{ij}(x) \partial_i \partial_j+ b^j(x) \partial_j +c(x)\right)f(x)
 g \{(U_\alpha,(x^i)_\alpha)\} C>0 
a^{ij}(x) \xi_i\xi_j \ge C g^{ij}(x) \xi_i\xi_j
 u(t,x) \begin{align} 
\label{parabolic}(\partial_t -\mathcal{L}) u(t,x)&=0\\
u(0,x)&=f(x)
\end{align} f: M \rightarrow \mathbb{R} \mathcal{L}u(t,x) \mathcal{L}u(t,x) u(t,x) e^{tA} e^{tA}f u(t,x):=e^{tA}f(x) t x","['differential-geometry', 'partial-differential-equations', 'operator-theory', 'elliptic-equations', 'parabolic-pde']"
61,Tensorial Ito formula for the tangent space of a manifold,Tensorial Ito formula for the tangent space of a manifold,,"Consider a compact Riemannian manifold $M$ with Riemannian structure given by a metric $g$ . Given a chart $(U, (x^i))$ and two vector fields $G_{\alpha}, G_{\beta} \in \Gamma(TM)$ it is possible to define the SDE $dX_t=G_\alpha(X_s) dt + G_\beta(X_s) dW_t$ where $W_t$ is a standard Brownian motion on the tangent space and $X_t \in TM$ . All the references that i looked at use the Stratonovich stochastic integral in which the Ito formula doesn't contains the diffusion term. Is it true that for the Ito integral the ito formula is $f(X_t)=f(X_0)+ \int_0^t \left(G_\alpha+ \frac{1}{2} \nabla_{G_\beta}G_\beta \right) f(X_s) ds + \int_0^t G_\beta dW_t  $ If this is correct, given a frame $\left(\frac{\partial}{\partial x^i}\right)$ and in $U$ the formula above became $df(X_t)= \left(G_{\alpha}^i \frac{\partial}{\partial x^i} + G_{\beta}^iG_{\beta}^i\frac{\partial^2}{\partial x^i \partial x^i}\right)f(X_t)dt + G_{\beta}^i\frac{\partial}{\partial x^i}f(X_t) dW_t $ is there a way to make this formula tensorial while preserving the martigale property?","Consider a compact Riemannian manifold with Riemannian structure given by a metric . Given a chart and two vector fields it is possible to define the SDE where is a standard Brownian motion on the tangent space and . All the references that i looked at use the Stratonovich stochastic integral in which the Ito formula doesn't contains the diffusion term. Is it true that for the Ito integral the ito formula is If this is correct, given a frame and in the formula above became is there a way to make this formula tensorial while preserving the martigale property?","M g (U, (x^i)) G_{\alpha}, G_{\beta} \in \Gamma(TM) dX_t=G_\alpha(X_s) dt + G_\beta(X_s) dW_t W_t X_t \in TM f(X_t)=f(X_0)+ \int_0^t \left(G_\alpha+ \frac{1}{2} \nabla_{G_\beta}G_\beta \right) f(X_s) ds + \int_0^t G_\beta dW_t   \left(\frac{\partial}{\partial x^i}\right) U df(X_t)= \left(G_{\alpha}^i \frac{\partial}{\partial x^i} + G_{\beta}^iG_{\beta}^i\frac{\partial^2}{\partial x^i \partial x^i}\right)f(X_t)dt + G_{\beta}^i\frac{\partial}{\partial x^i}f(X_t) dW_t ","['differential-geometry', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals', 'stochastic-differential-equations']"
62,First chern class of canonical line bundle on $CP^n$,First chern class of canonical line bundle on,CP^n,"I am trying to calculate the first chern class $c_1(K)$ of the canonical bundle $K = \Lambda^n(T^*\mathbb{CP}^n)^{1,0}$ , where my definition of the first chern class is $c_1(K)=\frac{i}{2\pi}[F(A)] \in H^2_{dR}(\mathbb{CP}^n)$ for any connection $A$ and its curvature $F(A)$ . First, we know $K = O(-n-1)$ . Cover $X=\mathbb{CP}^n$ by $U_i$ , the affine patch with nonzero $i$ 'th coordinate. We define $h_i = (1+\sum_{j \neq i} |z_j/z_i|^2)^{-n-1}$ , which patch together to give a fibrewise Hermitian inner product on $O(-n-1)$ . i.e., under the trivialization $U_i$ , if $e_i$ is the section corresponding to $1 \in \mathbb{C}$ , and $h=|e_i|^2$ , then by direct calculation $|s_ie_i|^2=|s_je_j|^2$ for all sections $s_i$ , where $s_j = (z_j/z_i)^{n+1} s_i$ are the transition functions of $O(-n-1)$ . Then we know that $A = \partial \log h$ patches together to give a connection, and hence $\frac{i}{2\pi}F(A) = \frac{i}{2\pi}\bar{\partial}\partial \log h \in \Lambda^{1,1}T^*X$ gives a representative of $c_1$ . Note that the Fubini-study form is $\omega|_{U_i} = \frac{i}{2\pi} \partial \bar{\partial} \log (1+\sum_{j\neq i} |z_j/z_i|^2)$ , so we see that $\frac{i}{2\pi}F(A) = (n+1) \omega$ (using $\partial \bar{\partial} = -\bar{\partial}\partial$ ). Hence, $c_1(K)$ can be represented by a positive (1,1)-form, since $\omega$ is a positive (1,1)-form. However, I was expecting that $c_1(X) = -c_1(K)$ can be represented by a positive $(1,1)$ form (i.e., $\mathbb{CP}^n$ is a Fano manifold) instead, which contradicts the above. (A real (1,1) form $\omega$ is a positive if $-i\omega(a,\bar{a}) >0$ for all nonzero $a \in T^{1,0}X$ .) What's the mistake in this argument?","I am trying to calculate the first chern class of the canonical bundle , where my definition of the first chern class is for any connection and its curvature . First, we know . Cover by , the affine patch with nonzero 'th coordinate. We define , which patch together to give a fibrewise Hermitian inner product on . i.e., under the trivialization , if is the section corresponding to , and , then by direct calculation for all sections , where are the transition functions of . Then we know that patches together to give a connection, and hence gives a representative of . Note that the Fubini-study form is , so we see that (using ). Hence, can be represented by a positive (1,1)-form, since is a positive (1,1)-form. However, I was expecting that can be represented by a positive form (i.e., is a Fano manifold) instead, which contradicts the above. (A real (1,1) form is a positive if for all nonzero .) What's the mistake in this argument?","c_1(K) K = \Lambda^n(T^*\mathbb{CP}^n)^{1,0} c_1(K)=\frac{i}{2\pi}[F(A)] \in H^2_{dR}(\mathbb{CP}^n) A F(A) K = O(-n-1) X=\mathbb{CP}^n U_i i h_i = (1+\sum_{j \neq i} |z_j/z_i|^2)^{-n-1} O(-n-1) U_i e_i 1 \in \mathbb{C} h=|e_i|^2 |s_ie_i|^2=|s_je_j|^2 s_i s_j = (z_j/z_i)^{n+1} s_i O(-n-1) A = \partial \log h \frac{i}{2\pi}F(A) = \frac{i}{2\pi}\bar{\partial}\partial \log h \in \Lambda^{1,1}T^*X c_1 \omega|_{U_i} = \frac{i}{2\pi} \partial \bar{\partial} \log (1+\sum_{j\neq i} |z_j/z_i|^2) \frac{i}{2\pi}F(A) = (n+1) \omega \partial \bar{\partial} = -\bar{\partial}\partial c_1(K) \omega c_1(X) = -c_1(K) (1,1) \mathbb{CP}^n \omega -i\omega(a,\bar{a}) >0 a \in T^{1,0}X","['differential-geometry', 'complex-geometry', 'kahler-manifolds']"
63,Prove that Kahler form induced by Fubini-Study metric on $\Bbb{P}^n$ is the generator of the $\Bbb{Z}$ coefficient cohomology,Prove that Kahler form induced by Fubini-Study metric on  is the generator of the  coefficient cohomology,\Bbb{P}^n \Bbb{Z},"I try to prove that the Kahler metric induced from the Fubini-Study metric on $\Bbb{P}^n$ is a generator of the cohomology $H^2(\Bbb{P}^n,\Bbb{Z})$ My attempt first by the Poincare duality we know that integral induce an isomorphic between $$H^2(X,\Bbb{R}) \to \Bbb{R}$$ while the integral $\int \omega_{\text{FS}} = 1$ it will be the generator for the $\Bbb{R}$ coefficient cohomology. Secondly,I claim that $[\omega_{\text{FS}}] \in H^2(\Bbb{P}^n,\Bbb{Z})$ ,   since the image of the line bundle $\mathcal{O}(1)$ under the first Chern class is $$c_1(\mathcal{O}(1)) = [\omega_{\text{FS}}]$$ it has to lie in $H^2(\Bbb{P}^n,\Bbb{Z}) \cong \Bbb{Z}$ (which is torsion-free). Is it possible to deduce that it's the generator of $H^2(\Bbb{P}^n,\Bbb{Z})$ without involving results from algebraic topology, only based on the observations above?","I try to prove that the Kahler metric induced from the Fubini-Study metric on is a generator of the cohomology My attempt first by the Poincare duality we know that integral induce an isomorphic between while the integral it will be the generator for the coefficient cohomology. Secondly,I claim that ,   since the image of the line bundle under the first Chern class is it has to lie in (which is torsion-free). Is it possible to deduce that it's the generator of without involving results from algebraic topology, only based on the observations above?","\Bbb{P}^n H^2(\Bbb{P}^n,\Bbb{Z}) H^2(X,\Bbb{R}) \to \Bbb{R} \int \omega_{\text{FS}} = 1 \Bbb{R} [\omega_{\text{FS}}] \in H^2(\Bbb{P}^n,\Bbb{Z}) \mathcal{O}(1) c_1(\mathcal{O}(1)) = [\omega_{\text{FS}}] H^2(\Bbb{P}^n,\Bbb{Z}) \cong \Bbb{Z} H^2(\Bbb{P}^n,\Bbb{Z})","['complex-analysis', 'differential-geometry', 'algebraic-topology']"
64,Schauder estimates on a punctured disk.,Schauder estimates on a punctured disk.,,"The following is related to my previous question [1], which I think can be resolved if this question is resolved. Is it true for $u\in C^{1,\alpha}(B-p)$ where $B=B_p(r)$ a function satisfying the spacetime Laplacian $\Delta u+K|\nabla u|=0,$ that the following estimate holds, $$r^2|\nabla\nabla u|\leq C r^{1+\alpha}?$$ Here, $K$ is the trace of some prescribed symmetric $(0,2)$ tensor $k$ . For simplicity, let us assume $K=0$ , so that $u$ is harmonic. Classical Schauder estimates from Gilbarg-Trudinger tell us that the following bound holds, $$r^2|\nabla\nabla u|\leq C |u|_{C^0(B-p)}.$$ Does it follow that for harmonic $u$ , we have $|u|_{0;B-p}\leq C r^{1+\alpha}$ ? References: [1]: PDE inequalities to show a gradient is integrable","The following is related to my previous question [1], which I think can be resolved if this question is resolved. Is it true for where a function satisfying the spacetime Laplacian that the following estimate holds, Here, is the trace of some prescribed symmetric tensor . For simplicity, let us assume , so that is harmonic. Classical Schauder estimates from Gilbarg-Trudinger tell us that the following bound holds, Does it follow that for harmonic , we have ? References: [1]: PDE inequalities to show a gradient is integrable","u\in C^{1,\alpha}(B-p) B=B_p(r) \Delta u+K|\nabla u|=0, r^2|\nabla\nabla u|\leq C r^{1+\alpha}? K (0,2) k K=0 u r^2|\nabla\nabla u|\leq C |u|_{C^0(B-p)}. u |u|_{0;B-p}\leq C r^{1+\alpha}","['differential-geometry', 'partial-differential-equations', 'general-relativity']"
65,"Classify $U(1)$ bundle over $\mathbf{P}^3$, and its topological invariants [closed]","Classify  bundle over , and its topological invariants [closed]",U(1) \mathbf{P}^3,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I am interested in knowing the classification of the $U(1)$ bundle over the complex projective space $\mathbf{P}^3$ . This is effectively a $U(1)$ bundle over the $6$ -manifold $M^6$ . What are the possible values of the $$c_1 p_1$$ for that $6$ -manifold $M^6$ with $U(1)$ bundle over $\mathbf{P}^3$ ? Here $c_1$ is the first Chern class of $U(1)$ bundle, and the $p_1$ is the first Pontryagin class of the tangent bundle of the $6$ -manifold? Can you give a configuration where $\int_{M^6} c_1 p_1=1$ or $\int_{M^6} c_1 p_1=4$ ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I am interested in knowing the classification of the bundle over the complex projective space . This is effectively a bundle over the -manifold . What are the possible values of the for that -manifold with bundle over ? Here is the first Chern class of bundle, and the is the first Pontryagin class of the tangent bundle of the -manifold? Can you give a configuration where or ?",U(1) \mathbf{P}^3 U(1) 6 M^6 c_1 p_1 6 M^6 U(1) \mathbf{P}^3 c_1 U(1) p_1 6 \int_{M^6} c_1 p_1=1 \int_{M^6} c_1 p_1=4,"['differential-geometry', 'algebraic-geometry', 'algebraic-topology', 'homology-cohomology', 'characteristic-classes']"
66,Does $\partial\bar{\partial}+\bar{\partial}\partial=0$ imply integrability of the almost complex structure?,Does  imply integrability of the almost complex structure?,\partial\bar{\partial}+\bar{\partial}\partial=0,"Let $X$ be an almost complex manifold. A well-known result says that $\bar{\partial}^{2}=0$ implies the integrability of the almost complex structure. My question is what about $\partial\bar{\partial}+\bar{\partial}\partial=0$ ? Does it imply the integrability? I have proved that $\partial\bar{\partial} f+\bar{\partial}\partial f=0$ always holds for any function $f$ , but does it hold for any form?","Let be an almost complex manifold. A well-known result says that implies the integrability of the almost complex structure. My question is what about ? Does it imply the integrability? I have proved that always holds for any function , but does it hold for any form?",X \bar{\partial}^{2}=0 \partial\bar{\partial}+\bar{\partial}\partial=0 \partial\bar{\partial} f+\bar{\partial}\partial f=0 f,"['differential-geometry', 'complex-geometry']"
67,PDE inequalities to show a gradient is integrable,PDE inequalities to show a gradient is integrable,,"I'm having trouble understanding the two inequalities in page 9 , quoted below. From the fact that $u\in C^{0,\alpha}(M)$ , apply $W^{2,p}$ estimate followed by Sobolev embedding onto $w_r(x)$ , where $r>0$ fixed, in a (conic) annulus $A(1)$ around $p$ , we have $$|\nabla u|_{C^0(A(r))}\leq |\nabla\nabla u|_{L^p(A(r))}\leq Cr^{\alpha-1}.$$ $|\nabla u|$ is therefore integrable on $\partial M$ and also on $M$ . Unless I missed it, I don't think the author defines $w_r(x)$ , which is one minor area of confusion. In any case, we're estimating on the boundary of $M$ , and $\dim\partial M=2$ . Note that we can't immediately get an $L^1$ bound on $\nabla u$ by GNS since $$|\nabla u|_{L^1}\leq |\nabla\nabla u|_{L^p}\implies 1=\frac{2p}{2-p}\implies p=2/3.$$ I'm not sure what the author means by ""apply $W^{2,p}$ estimate followed by Sobolev embedding"", which I assume gives the first inequality. I record a few thoughts below. I assume the domains are $A(r)$ , which I will omit from the notation. We can use GNS inequality for $1\leq p<2$ , to relate $\nabla u$ to its derviative. For $n=2$ , we get $$|\nabla u|_{L^{\frac{2p}{2-p}}}\leq |\nabla\nabla u|_{L^p}.$$ I am unsure how to proceed from here. I definitely don't think it's true that $$|\nabla u|_{C^0}\leq C|u|_{L^\frac{2p}{2-p}}.$$ We want to apply one of the following argument to $v=\nabla u$ , and this is possible if $u\in W^{3,2}$ . But $u\in W^{3,p}$ on the interior (see Lemma 1.1, page 3 ), not boundary, of $M$ . By the general Sobolev inequalities , for $n=2$ , we know that $v\in W^{2,p}$ with $p=2,3,4,...$ , then for any $\alpha\in (0,1)$ , we have $$|v|_{C^{0,\alpha}}\leq C|v|_{W^{2,i}}.$$ Alternatively, for $1\leq p< 2$ , for $\alpha=2-2/p$ , we get $$|v|_{C^{0,\alpha}}\leq C|v|_{W^{2,p}}.$$ Alternatively, for $p>2$ not an integer, we have for $\alpha=1-2/p$ , $$|v|_{C^{0,\alpha}}\leq C|v|_{W^{2,p}}.$$ For the second inequality, I'm assuming this comes from the domain being a conic annulus, and somehow $u\in C^{0,\alpha}$ should enter. But I'm not clear how this is done.","I'm having trouble understanding the two inequalities in page 9 , quoted below. From the fact that , apply estimate followed by Sobolev embedding onto , where fixed, in a (conic) annulus around , we have is therefore integrable on and also on . Unless I missed it, I don't think the author defines , which is one minor area of confusion. In any case, we're estimating on the boundary of , and . Note that we can't immediately get an bound on by GNS since I'm not sure what the author means by ""apply estimate followed by Sobolev embedding"", which I assume gives the first inequality. I record a few thoughts below. I assume the domains are , which I will omit from the notation. We can use GNS inequality for , to relate to its derviative. For , we get I am unsure how to proceed from here. I definitely don't think it's true that We want to apply one of the following argument to , and this is possible if . But on the interior (see Lemma 1.1, page 3 ), not boundary, of . By the general Sobolev inequalities , for , we know that with , then for any , we have Alternatively, for , for , we get Alternatively, for not an integer, we have for , For the second inequality, I'm assuming this comes from the domain being a conic annulus, and somehow should enter. But I'm not clear how this is done.","u\in C^{0,\alpha}(M) W^{2,p} w_r(x) r>0 A(1) p |\nabla u|_{C^0(A(r))}\leq |\nabla\nabla u|_{L^p(A(r))}\leq Cr^{\alpha-1}. |\nabla u| \partial M M w_r(x) M \dim\partial M=2 L^1 \nabla u |\nabla u|_{L^1}\leq |\nabla\nabla u|_{L^p}\implies 1=\frac{2p}{2-p}\implies p=2/3. W^{2,p} A(r) 1\leq p<2 \nabla u n=2 |\nabla u|_{L^{\frac{2p}{2-p}}}\leq |\nabla\nabla u|_{L^p}. |\nabla u|_{C^0}\leq C|u|_{L^\frac{2p}{2-p}}. v=\nabla u u\in W^{3,2} u\in W^{3,p} M n=2 v\in W^{2,p} p=2,3,4,... \alpha\in (0,1) |v|_{C^{0,\alpha}}\leq C|v|_{W^{2,i}}. 1\leq p< 2 \alpha=2-2/p |v|_{C^{0,\alpha}}\leq C|v|_{W^{2,p}}. p>2 \alpha=1-2/p |v|_{C^{0,\alpha}}\leq C|v|_{W^{2,p}}. u\in C^{0,\alpha}","['differential-geometry', 'partial-differential-equations']"
68,Reference request: relationship between c-convexity and geodesic convexity on manifolds,Reference request: relationship between c-convexity and geodesic convexity on manifolds,,"I am interested in a characterization of c-convex/c-concave functions (as in Definition 5.2 and Definition 5.7 in Cédric Villani's book, 'Optimal transport, old and new' ) on manifolds in the case when the cost function is the half squared distance, $c(x, y) = \frac{1}{2} \text{dist}^2(x, y)$ . In particular, in this comment it is mentioned that on a manifold of nonnegative sectional curvature, a c-convex function $f$ is 1-convex, i.e. $ g(t) = f(\gamma(t)) + \frac{t^2}{2} $ is convex, where $ \gamma $ is a unit speed geodesic. Does anyone know of a reference where this property is explored? Thank you!","I am interested in a characterization of c-convex/c-concave functions (as in Definition 5.2 and Definition 5.7 in Cédric Villani's book, 'Optimal transport, old and new' ) on manifolds in the case when the cost function is the half squared distance, . In particular, in this comment it is mentioned that on a manifold of nonnegative sectional curvature, a c-convex function is 1-convex, i.e. is convex, where is a unit speed geodesic. Does anyone know of a reference where this property is explored? Thank you!","c(x, y) = \frac{1}{2} \text{dist}^2(x, y) f  g(t) = f(\gamma(t)) + \frac{t^2}{2}   \gamma ","['differential-geometry', 'convex-analysis', 'riemannian-geometry', 'optimal-transport']"
69,Computing derivative of pullback of time-dependent metric,Computing derivative of pullback of time-dependent metric,,"$\qquad$ Following Topping's book on Ricci flow, $X(t)$ be a time-dependent collection of vector fields with associated collection of diffeomorphisms $\psi_t$ defined on a compact, closed manifold $M$ . Given $g=g(t)$ a family of metrics on $M$ , why is it that if we define $\hat{g}(t)=\sigma(t)\psi_t^*(g(t))$ ( $\sigma$ a smooth, real valued function) that $$\frac{\partial \hat{g}}{\partial t}=\sigma'(t)\psi_t^*(g(t))+\sigma(t)\psi_t^*\left(\frac{\partial g}{\partial t}\right)+\sigma(t)\psi_t^*(\mathcal{L}_Xg)?$$ One definition of the Lie derivative I know is $\mathcal{L}_Xg=\left(\frac{\partial}{\partial t}\big|_{t=0}\psi_t^*\right)g$ , so directly using the product rule and this definition I get $$\frac{\partial \hat{g}}{\partial t}=\sigma'(t)\psi_t^*(g(t))+\sigma(t)\psi_t^*\left(\frac{\partial g}{\partial t}\right)+\sigma(t)\mathcal{L}_Xg.$$ Where is my mistake, or how do I see the first equation holds? I've looked at How to show $\partial_t \hat g = \sigma'(t)\psi_t^* (g) + \sigma(t) \psi_t^*(\partial_t g) + \sigma(t) \psi_t^*(L_Xg)$? but there's not a clear answer.","Following Topping's book on Ricci flow, be a time-dependent collection of vector fields with associated collection of diffeomorphisms defined on a compact, closed manifold . Given a family of metrics on , why is it that if we define ( a smooth, real valued function) that One definition of the Lie derivative I know is , so directly using the product rule and this definition I get Where is my mistake, or how do I see the first equation holds? I've looked at How to show $\partial_t \hat g = \sigma'(t)\psi_t^* (g) + \sigma(t) \psi_t^*(\partial_t g) + \sigma(t) \psi_t^*(L_Xg)$? but there's not a clear answer.",\qquad X(t) \psi_t M g=g(t) M \hat{g}(t)=\sigma(t)\psi_t^*(g(t)) \sigma \frac{\partial \hat{g}}{\partial t}=\sigma'(t)\psi_t^*(g(t))+\sigma(t)\psi_t^*\left(\frac{\partial g}{\partial t}\right)+\sigma(t)\psi_t^*(\mathcal{L}_Xg)? \mathcal{L}_Xg=\left(\frac{\partial}{\partial t}\big|_{t=0}\psi_t^*\right)g \frac{\partial \hat{g}}{\partial t}=\sigma'(t)\psi_t^*(g(t))+\sigma(t)\psi_t^*\left(\frac{\partial g}{\partial t}\right)+\sigma(t)\mathcal{L}_Xg.,"['differential-geometry', 'tensors', 'lie-derivative', 'ricci-flow']"
70,Are there theorems in fiber bundle land and differential geometry land that make calculations in electromagnetism easier?,Are there theorems in fiber bundle land and differential geometry land that make calculations in electromagnetism easier?,,"Some time ago while thinking about life and such, I thought to myself does recasting electromagnetism in bundle theory make certain calculations easier? To be precise are there theorems in differential geometry and fiber bundle theory that will make some calculations in electromagnetism easier? Motivation: A few days ago I realized that a theorem in algebraic topology helped me calculate a homotopy group by calculating a homology. I am still not sure how I could have directly calculated the homotopy group but the theorem made the calculation easier, simpler and doable. This got me thinking maybe I have been ignoring modern mathematics theorems at my own peril. There are some simpler theorems in calculus that have applications in electromagnetism like Stokes's and Gauss's theorem, but I was wondering if some ideas grew out of differential geometry and fiber bundle language that made calculating things significantly easier in electromagnetism. I am thinking of things like the scalar potential, vector potential, electric field, and magnetic field. I am just wondering. I'm inclined to believe that people who go out of their way to define everything in this language are probably using some new and exciting theorems to calculate things. At this stage in my life I am marginally competent with some electromagnetism I guess some U(1) theory as well but I am probably not well versed with broader gauge theories but I am wondering again are there theorems that make calculations easier in this language? I know very very basic fiber language. In fact, probably just the definitions of base space, projection map, fiber, section etc, but I have not had the pleasure of delving deep to see the theorems and such so I don't know.","Some time ago while thinking about life and such, I thought to myself does recasting electromagnetism in bundle theory make certain calculations easier? To be precise are there theorems in differential geometry and fiber bundle theory that will make some calculations in electromagnetism easier? Motivation: A few days ago I realized that a theorem in algebraic topology helped me calculate a homotopy group by calculating a homology. I am still not sure how I could have directly calculated the homotopy group but the theorem made the calculation easier, simpler and doable. This got me thinking maybe I have been ignoring modern mathematics theorems at my own peril. There are some simpler theorems in calculus that have applications in electromagnetism like Stokes's and Gauss's theorem, but I was wondering if some ideas grew out of differential geometry and fiber bundle language that made calculating things significantly easier in electromagnetism. I am thinking of things like the scalar potential, vector potential, electric field, and magnetic field. I am just wondering. I'm inclined to believe that people who go out of their way to define everything in this language are probably using some new and exciting theorems to calculate things. At this stage in my life I am marginally competent with some electromagnetism I guess some U(1) theory as well but I am probably not well versed with broader gauge theories but I am wondering again are there theorems that make calculations easier in this language? I know very very basic fiber language. In fact, probably just the definitions of base space, projection map, fiber, section etc, but I have not had the pleasure of delving deep to see the theorems and such so I don't know.",,"['differential-geometry', 'fiber-bundles', 'electromagnetism']"
71,Path integral of the connection $1$-form of the Hopf bundle,Path integral of the connection -form of the Hopf bundle,1,"Let $\mathcal H$ be a complex Hilbert space with scalar product $\langle \cdot,\cdot\rangle$ . Let us consider on $\mathcal H$ the $1$ -form defined for any $\psi\in \mathcal H$ by $$ \widetilde \omega_\psi\colon [\gamma]_\psi \in T_\psi \mathcal H\mapsto \Im\langle \psi,\gamma'(0)\rangle\in \mathbb R\,. $$ Let's $\omega=\iota^\ast \widetilde \omega$ , where $\iota\colon \mathcal S\mathcal H\hookrightarrow \mathcal H$ is the canonical inclusion of the Hilbert sphere $\mathcal S\mathcal H=\{\psi\in \mathcal H\mid \langle \psi,\psi\rangle=1\}$ . Thus, $\omega$ is a $1$ -form on $\mathcal S\mathcal H$ . Let $P\colon [0,1]\to \mathbb P\mathcal H$ be a closed curve on the complex Hilbert space $\mathbb P\mathcal H$ . Let us assume that $P([0,1])\subseteq U_{P(0)}$ , where for any $\psi\in \mathcal S\mathcal H$ , $U_\psi=\Pi(\mathcal S\mathcal H\setminus \psi^\perp)$ is the domain of the coordinate chart $$ u_\psi \colon \chi\in U_\psi\mapsto \frac{\chi}{\langle \psi,\chi\rangle}-\psi\in \psi^\perp\,. $$ Let $s$ be a local section of the projection $\Pi\colon \mathcal S\mathcal H\to \mathbb P\mathcal H$ defined on $U_\psi$ . Let us define $A=s^\ast \omega$ , so that $A$ is a $1$ -form on $U_\psi$ . Now I have trouble in calculating $$ \int_P A\,. $$ My attempt First, $$  \int_P A=\int_P s^\ast\iota^\ast \widetilde \omega=\int_0^1 P^\ast s^\ast \iota^\ast \widetilde \omega=\int_0^1 (\iota\circ s\circ P)^\ast \widetilde \omega\,. $$ Since $\widetilde \omega$ is not written in terms of differentials ( $\mathcal H$ can be infinite-dimensional), I don't know how to calculate the pullback, and so how to continue...","Let be a complex Hilbert space with scalar product . Let us consider on the -form defined for any by Let's , where is the canonical inclusion of the Hilbert sphere . Thus, is a -form on . Let be a closed curve on the complex Hilbert space . Let us assume that , where for any , is the domain of the coordinate chart Let be a local section of the projection defined on . Let us define , so that is a -form on . Now I have trouble in calculating My attempt First, Since is not written in terms of differentials ( can be infinite-dimensional), I don't know how to calculate the pullback, and so how to continue...","\mathcal H \langle \cdot,\cdot\rangle \mathcal H 1 \psi\in \mathcal H 
\widetilde \omega_\psi\colon [\gamma]_\psi \in T_\psi \mathcal H\mapsto \Im\langle \psi,\gamma'(0)\rangle\in \mathbb R\,.
 \omega=\iota^\ast \widetilde \omega \iota\colon \mathcal S\mathcal H\hookrightarrow \mathcal H \mathcal S\mathcal H=\{\psi\in \mathcal H\mid \langle \psi,\psi\rangle=1\} \omega 1 \mathcal S\mathcal H P\colon [0,1]\to \mathbb P\mathcal H \mathbb P\mathcal H P([0,1])\subseteq U_{P(0)} \psi\in \mathcal S\mathcal H U_\psi=\Pi(\mathcal S\mathcal H\setminus \psi^\perp) 
u_\psi \colon \chi\in U_\psi\mapsto \frac{\chi}{\langle \psi,\chi\rangle}-\psi\in \psi^\perp\,.
 s \Pi\colon \mathcal S\mathcal H\to \mathbb P\mathcal H U_\psi A=s^\ast \omega A 1 U_\psi 
\int_P A\,.
  
\int_P A=\int_P s^\ast\iota^\ast \widetilde \omega=\int_0^1 P^\ast s^\ast \iota^\ast \widetilde \omega=\int_0^1 (\iota\circ s\circ P)^\ast \widetilde \omega\,.
 \widetilde \omega \mathcal H","['differential-geometry', 'differential-forms', 'principal-bundles', 'hopf-fibration']"
72,Energy bound for a closed curve,Energy bound for a closed curve,,Let $\gamma : S^1 \rightarrow M$ be a smooth map from a circle of length 1 to a closed manifold $M$ with nonpositive curvature. Could we find a constant $C > 0$ depending only on $M$ such that $$\int_{S^1}||\nabla_{\dot{\gamma}}\nabla_{\dot{\gamma}}\dot{\gamma}||^2 \ge C\int_{S^1}||\nabla_{\dot{\gamma}}\dot{\gamma}||^2$$ for arbitrary $\gamma$ ? I have constructed counterexamples on the 2-sphere and a noncompact manifold with negative curvature; that's the reason for the assumption on $M$ .,Let be a smooth map from a circle of length 1 to a closed manifold with nonpositive curvature. Could we find a constant depending only on such that for arbitrary ? I have constructed counterexamples on the 2-sphere and a noncompact manifold with negative curvature; that's the reason for the assumption on .,\gamma : S^1 \rightarrow M M C > 0 M \int_{S^1}||\nabla_{\dot{\gamma}}\nabla_{\dot{\gamma}}\dot{\gamma}||^2 \ge C\int_{S^1}||\nabla_{\dot{\gamma}}\dot{\gamma}||^2 \gamma M,"['differential-geometry', 'curves', 'integral-inequality']"
73,"Classification of topologically constrained foliations on $X$ in low dimensions i.e. $2,3$",Classification of topologically constrained foliations on  in low dimensions i.e.,"X 2,3","Take $X=(0,1)^n.$ Fix points $p,q$ s.t. $\text{dist}_n(p,q)=\sqrt{n}.$ Problem: Classify analytic regular foliations of $X$ with $(n-1)-$ dim. leaves which are topologically $(0,\sqrt{n})\times S^{n-2} $ accumulating to $p,q.$ The problem is trivial until dim. $2,$ and I have found one (real analytic foliation) solution in $n=2$ dim. but have not completely classified for $n=2.$ I conjecture that there are no solutions for $n\gt2$ and I would be shocked if there was a solution. My solution for $n=2$ : Foliation $F_s=\big\{\log x \log y=s: s\in (0,\infty) \big\}$ which satisfies $\cup_s F_s=X,$ is clearly analytic and regular, and satisfies the topological constraint as well as the accumulation criterion. In this case, note that $p=(0,1)$ and $q=(1,0).$ I feel like there should be a more elegant approach here. My solution does not let one see the global classification picture and is only an isolated example that happens to work. Perhaps the problem is easier in the complex setting. Edit 3/19/2023: I will relax the conditions. Let $n=3.$ Take $X=(0,1)^n.$ Fix points $p,q$ s.t. $\text{dist}_n(p,q)=\sqrt{n}.$ Construct a smooth regular foliation of $X$ with $(n-1)-$ dim. leaves which are topologically $(0,\sqrt{n})\times S^{n-2} $ accumulating to $p,q.$ I think this is a much more tractable problem. I am only looking for a construction in dimension $3$ now, where I've replaced ""analytic"" with ""smooth."" I am including the following related question I posted $10$ months ago (link below), because it is an attempt at a solution (in the smooth case) for any dimension $n.$ This method leverages distribution theory and imagines the leaves as arising from integrating some continuous bivariate probability distribution. In this way a single leaf is precisely the distribution when all the parameters are fixed. What's interesting about this method is that you get the topological condition for sufficient constraints on the probability distribution. Since the definition in the linked post below includes $p,q$ in the leafs, then deleting $p,q$ would match up with my definition in this post. Understanding a subspace of $S^n$ for a given distribution .","Take Fix points s.t. Problem: Classify analytic regular foliations of with dim. leaves which are topologically accumulating to The problem is trivial until dim. and I have found one (real analytic foliation) solution in dim. but have not completely classified for I conjecture that there are no solutions for and I would be shocked if there was a solution. My solution for : Foliation which satisfies is clearly analytic and regular, and satisfies the topological constraint as well as the accumulation criterion. In this case, note that and I feel like there should be a more elegant approach here. My solution does not let one see the global classification picture and is only an isolated example that happens to work. Perhaps the problem is easier in the complex setting. Edit 3/19/2023: I will relax the conditions. Let Take Fix points s.t. Construct a smooth regular foliation of with dim. leaves which are topologically accumulating to I think this is a much more tractable problem. I am only looking for a construction in dimension now, where I've replaced ""analytic"" with ""smooth."" I am including the following related question I posted months ago (link below), because it is an attempt at a solution (in the smooth case) for any dimension This method leverages distribution theory and imagines the leaves as arising from integrating some continuous bivariate probability distribution. In this way a single leaf is precisely the distribution when all the parameters are fixed. What's interesting about this method is that you get the topological condition for sufficient constraints on the probability distribution. Since the definition in the linked post below includes in the leafs, then deleting would match up with my definition in this post. Understanding a subspace of $S^n$ for a given distribution .","X=(0,1)^n. p,q \text{dist}_n(p,q)=\sqrt{n}. X (n-1)- (0,\sqrt{n})\times S^{n-2}  p,q. 2, n=2 n=2. n\gt2 n=2 F_s=\big\{\log x \log y=s: s\in (0,\infty) \big\} \cup_s F_s=X, p=(0,1) q=(1,0). n=3. X=(0,1)^n. p,q \text{dist}_n(p,q)=\sqrt{n}. X (n-1)- (0,\sqrt{n})\times S^{n-2}  p,q. 3 10 n. p,q p,q","['differential-geometry', 'manifolds', 'riemannian-geometry', 'differential-topology', 'geometric-topology']"
74,Calculating the derivative of the flow of a time-dependent family of vector fields,Calculating the derivative of the flow of a time-dependent family of vector fields,,"Suppose on a manifold $M$ I have a family of complete vector fields, $V(t) \in \Gamma(TM)$ for each $t \in \mathbb R$ with $V(0) = 0$ . Also assume that $[V(t_0), V(t_1)]=0$ for any $t_0, t_1 \in \mathbb R$ . Let $s \rightarrow \phi_s^X(p)$ be the integral curve of the vector field $X$ with initial condition $p \in M$ , parametrized by $s$ . My question is, is there any way to compute $$ \frac{d}{dt} \phi_s^{V(t)}(p) $$ for given fixed $s \neq 0$ and $p \in M$ ? For example, I am trying to compute $$ \frac{d}{dt}\rvert_{t=0} \phi_1^{V(t)}(p) $$ for such a family. I tried looking at the theorem for flows of time-dependent vector fields to obtain some chance of computation. There, an integral curve of $V$ with initial condition $(t_0, p) \in \mathbb R \times M$ is a curve $\psi^{(t_0,p)}: \mathbb R \rightarrow M$ such that $$ \frac{d}{dt} \psi^{(t_0,p)}(t) = V(t)_{\psi^{(t_0,p)}(t)} $$ According to Theorem 9.48 of Lee's ""Introduction to smooth manifolds"", such integral curves always exist and have good composition properties. However, I failed to see any relationship between these integral curves and the flows $\phi_t^{V(t)}(p)$ . Initially I had thought it reasonable that $$ \psi^{(t_0,p)}(t) = \phi_{t-t_0}^{V(t)}(p) $$ but I don't actually know how to prove that this is the case, and I feel like what I'm asking is equivalent to proving that this is the case; both computations seem to reduce to the question of how to differentiate the flow respect to $t$ when $V(t)$ changes.","Suppose on a manifold I have a family of complete vector fields, for each with . Also assume that for any . Let be the integral curve of the vector field with initial condition , parametrized by . My question is, is there any way to compute for given fixed and ? For example, I am trying to compute for such a family. I tried looking at the theorem for flows of time-dependent vector fields to obtain some chance of computation. There, an integral curve of with initial condition is a curve such that According to Theorem 9.48 of Lee's ""Introduction to smooth manifolds"", such integral curves always exist and have good composition properties. However, I failed to see any relationship between these integral curves and the flows . Initially I had thought it reasonable that but I don't actually know how to prove that this is the case, and I feel like what I'm asking is equivalent to proving that this is the case; both computations seem to reduce to the question of how to differentiate the flow respect to when changes.","M V(t) \in \Gamma(TM) t \in \mathbb R V(0) = 0 [V(t_0), V(t_1)]=0 t_0, t_1 \in \mathbb R s \rightarrow \phi_s^X(p) X p \in M s  \frac{d}{dt} \phi_s^{V(t)}(p)  s \neq 0 p \in M  \frac{d}{dt}\rvert_{t=0} \phi_1^{V(t)}(p)  V (t_0, p) \in \mathbb R \times M \psi^{(t_0,p)}: \mathbb R \rightarrow M  \frac{d}{dt} \psi^{(t_0,p)}(t) = V(t)_{\psi^{(t_0,p)}(t)}  \phi_t^{V(t)}(p)  \psi^{(t_0,p)}(t) = \phi_{t-t_0}^{V(t)}(p)  t V(t)","['differential-geometry', 'vector-fields']"
75,Smooth function motivation in Lee,Smooth function motivation in Lee,,"I was reading a bit in ""Introduction to Smooth Manifolds"" by John M. Lee for some motivations and came across the following section on page $11$ - $12$ . ""Each point in $M$ is in the domain of a coordinate map $\varphi:U \to \hat{U}.$ A plausible definition of a smooth function on $M$ would be to say that $f:M \to \mathbb{R}$ is smooth if and only if the composition $f \circ \varphi^{-1}:\hat{U} \to \mathbb{R}$ is smooth in the sense of ordinary calculus. But this will only make sense if this property is independent of the choice of coordinate chart."" Why is that the case? Wouldn't the definition "" $f$ is continuous iff at every point $p$ there is some chart $(U,\varphi)$ with $p \in U$ such that $f \circ \varphi^{-1}$ is smooth"" be a perfectly fine definition? Maybe I am overlooking something basic here, but I, at the moment, don't see why this wouldn't be well defined.","I was reading a bit in ""Introduction to Smooth Manifolds"" by John M. Lee for some motivations and came across the following section on page - . ""Each point in is in the domain of a coordinate map A plausible definition of a smooth function on would be to say that is smooth if and only if the composition is smooth in the sense of ordinary calculus. But this will only make sense if this property is independent of the choice of coordinate chart."" Why is that the case? Wouldn't the definition "" is continuous iff at every point there is some chart with such that is smooth"" be a perfectly fine definition? Maybe I am overlooking something basic here, but I, at the moment, don't see why this wouldn't be well defined.","11 12 M \varphi:U \to \hat{U}. M f:M \to \mathbb{R} f \circ \varphi^{-1}:\hat{U} \to \mathbb{R} f p (U,\varphi) p \in U f \circ \varphi^{-1}",['differential-geometry']
76,Decomposition of tensor field on hypersurface,Decomposition of tensor field on hypersurface,,"Lets consider the following situation: $(\mathcal{M},g)$ is a Lorentzian manifold, which is globally of the form $\mathcal{M}\cong I\times\Sigma$ , where $I\subset\mathbb{R}$ and $\Sigma$ is some $3$ -dimensional hypersurface. Furthermore, let $T$ be an arbitrary symmetric $2$ -tensor field on $\mathcal{M}$ . Then, in some coordinates, I can decompose $$T_{\mu\nu}\mathrm{d}x^{\mu}\otimes\mathrm{d}x^{\nu}=T_{00}\mathrm{d}x^{0}\otimes\mathrm{d}x^{0}+2T_{i0}\mathrm{d}x^{0}\otimes\mathrm{d}x^{i}+T_{ij}\mathrm{d}x^{i}\otimes\mathrm{d}x^{j}.$$ This essentially provides a decompisition of the form (in the sense of $C^{\infty}(\mathcal{M})$ -module isomorphisms) $$\Gamma^{\infty}(T^{\ast}\mathcal{M}^{\otimes_{s}2})\cong C^{\infty}(\mathcal{M})\oplus\Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma)\oplus\Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma^{\otimes_{s}2})$$ where $T_{00}$ is interpreted as a function in $C^{\infty}(\mathcal{M})$ , $T_{i0}$ of beeing the components in coordinates of an element in $\Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma)$ and similarely for $T_{ij}$ . Now, is it possible to establish isomorphisms $$C^{\infty}(\mathcal{M})\cong C^{\infty}(I,C^{\infty}(\Sigma))$$ $$\Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma)\cong C^{\infty}(I,\Gamma^{\infty}(T^{\ast}\Sigma))$$ $$\Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma^{\otimes_{s}2})\cong C^{\infty}(I,\Gamma^{\infty}(T^{\ast}\Sigma^{\otimes_{s}2}))$$ i.e. to interpret $T_{00}$ , $T_{i0}$ and $T_{ij}$ as ""smooth time-dependent functions, co-vector and tensor fields"", respectively? What I mean with smooth in the notation above is the following: If $X:I\to\Gamma^{\infty}(T^{\ast}\Sigma)$ is a map, for example, then $X_{p}(t)\in T_{p}^{\ast}\Sigma$ for all $p\in\mathcal{M}$ , $t\in I$ , and hence, it makes sense to define derivative with respect to $t$ in the usual way, i.e. $$\frac{\mathrm{d}}{\mathrm{d}t}X_{p}(t)=\lim_{h\to 0}\frac{X_{p}(t+h)-X_{p}(t)}{h}$$ where we choose an arbitrary norm on $T_{p}^{\ast}\Sigma$ , for example, the one induced by the metric $g$ (the choice does not matter, since on finite-dimensional spaces they are all equivalent). Similarely, the spaces are defined for the other two cases.","Lets consider the following situation: is a Lorentzian manifold, which is globally of the form , where and is some -dimensional hypersurface. Furthermore, let be an arbitrary symmetric -tensor field on . Then, in some coordinates, I can decompose This essentially provides a decompisition of the form (in the sense of -module isomorphisms) where is interpreted as a function in , of beeing the components in coordinates of an element in and similarely for . Now, is it possible to establish isomorphisms i.e. to interpret , and as ""smooth time-dependent functions, co-vector and tensor fields"", respectively? What I mean with smooth in the notation above is the following: If is a map, for example, then for all , , and hence, it makes sense to define derivative with respect to in the usual way, i.e. where we choose an arbitrary norm on , for example, the one induced by the metric (the choice does not matter, since on finite-dimensional spaces they are all equivalent). Similarely, the spaces are defined for the other two cases.","(\mathcal{M},g) \mathcal{M}\cong I\times\Sigma I\subset\mathbb{R} \Sigma 3 T 2 \mathcal{M} T_{\mu\nu}\mathrm{d}x^{\mu}\otimes\mathrm{d}x^{\nu}=T_{00}\mathrm{d}x^{0}\otimes\mathrm{d}x^{0}+2T_{i0}\mathrm{d}x^{0}\otimes\mathrm{d}x^{i}+T_{ij}\mathrm{d}x^{i}\otimes\mathrm{d}x^{j}. C^{\infty}(\mathcal{M}) \Gamma^{\infty}(T^{\ast}\mathcal{M}^{\otimes_{s}2})\cong C^{\infty}(\mathcal{M})\oplus\Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma)\oplus\Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma^{\otimes_{s}2}) T_{00} C^{\infty}(\mathcal{M}) T_{i0} \Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma) T_{ij} C^{\infty}(\mathcal{M})\cong C^{\infty}(I,C^{\infty}(\Sigma)) \Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma)\cong C^{\infty}(I,\Gamma^{\infty}(T^{\ast}\Sigma)) \Gamma^{\infty}(\mathcal{M},T^{\ast}\Sigma^{\otimes_{s}2})\cong C^{\infty}(I,\Gamma^{\infty}(T^{\ast}\Sigma^{\otimes_{s}2})) T_{00} T_{i0} T_{ij} X:I\to\Gamma^{\infty}(T^{\ast}\Sigma) X_{p}(t)\in T_{p}^{\ast}\Sigma p\in\mathcal{M} t\in I t \frac{\mathrm{d}}{\mathrm{d}t}X_{p}(t)=\lim_{h\to 0}\frac{X_{p}(t+h)-X_{p}(t)}{h} T_{p}^{\ast}\Sigma g","['limits', 'differential-geometry', 'manifolds', 'riemannian-geometry', 'tensors']"
77,Cohomology of submanifolds,Cohomology of submanifolds,,"Suppose I have a manifold $M$ and a submanifold or a boundary $N\subset M$ . By the natural inclusion $\iota:N\hookrightarrow M$ we can easily see that $$\omega\in\mathrm{H}^k(M) \quad\implies\quad \iota^*\omega\in\mathrm{H}^k(N).$$ On the other hand, obviously $$\iota^*\omega\in\mathrm{H}^k(N) \quad\not\kern{-0.5em}\implies\quad \omega\in\mathrm{H}^k(M).$$ Is there something to be said about those forms that are in the cohomology of $N$ but not in that of $M$ ? Precisely, does either the space $$\mathrm{Hmm}_{(1)}^k(N,M):=\left\lbrace\omega\in\mathrm{H}^k(N)\ \middle|\ \omega\neq\iota^*\eta,\quad \eta\in\mathrm{H}^k(M)\right\rbrace$$ or the space $$ \mathrm{Hmm}_{(2)}^k(N,M) := \mathrm{H}^k(N)\Big/\left\lbrace\omega\in\mathrm{H}^k(N)\ \middle|\ \omega=\iota^*\eta,\quad \eta\in\mathrm{H}^k(M)\right\rbrace$$ have a simple description? 1 I have a hunch that it should come from some relative cohomology but I wasn't able to make it precise. Even if there is no simple description, can we say something about its dimension? I am more interested in the case where $N=\partial M$ (so if there's something to be said there but not in the general case, I'm perfectly happy), but the general case seems interesting too. 1 I'm writing both spaces to maximize my chances, see the helpful comments of @Thorgott and @Osama Ghani","Suppose I have a manifold and a submanifold or a boundary . By the natural inclusion we can easily see that On the other hand, obviously Is there something to be said about those forms that are in the cohomology of but not in that of ? Precisely, does either the space or the space have a simple description? 1 I have a hunch that it should come from some relative cohomology but I wasn't able to make it precise. Even if there is no simple description, can we say something about its dimension? I am more interested in the case where (so if there's something to be said there but not in the general case, I'm perfectly happy), but the general case seems interesting too. 1 I'm writing both spaces to maximize my chances, see the helpful comments of @Thorgott and @Osama Ghani","M N\subset M \iota:N\hookrightarrow M \omega\in\mathrm{H}^k(M) \quad\implies\quad \iota^*\omega\in\mathrm{H}^k(N). \iota^*\omega\in\mathrm{H}^k(N) \quad\not\kern{-0.5em}\implies\quad \omega\in\mathrm{H}^k(M). N M \mathrm{Hmm}_{(1)}^k(N,M):=\left\lbrace\omega\in\mathrm{H}^k(N)\ \middle|\ \omega\neq\iota^*\eta,\quad \eta\in\mathrm{H}^k(M)\right\rbrace  \mathrm{Hmm}_{(2)}^k(N,M) := \mathrm{H}^k(N)\Big/\left\lbrace\omega\in\mathrm{H}^k(N)\ \middle|\ \omega=\iota^*\eta,\quad \eta\in\mathrm{H}^k(M)\right\rbrace N=\partial M","['differential-geometry', 'homology-cohomology', 'submanifold', 'manifolds-with-boundary', 'de-rham-cohomology']"
78,Integrate over geodesic ball on $n$-sphere,Integrate over geodesic ball on -sphere,n,"Let $e_1=(1,0,\dots,0)\in S^{n-1}\subset\mathbb{R}^n$ . The geodesic ball of radius $\epsilon$ centered at $e_1$ is \begin{align*} B_\epsilon(e_1) = \{\cos(t)e_1 + \sin(t)v : \lVert v\rVert=1, v_1=0, t\in[0,\epsilon)\}. \end{align*} Let $f:S^{n-1}\to\mathbb{R}$ be smooth. Is the following true? \begin{align*} \int_{B_\epsilon(e_1)}f(p)dp = \int_{S^{n-2}}\int_0^\epsilon f(\varphi(v,t))\sin^n(t)dtdv. \end{align*} Here $dp$ is the volume form on $S^{n-1}$ and $dv$ is the volume form on $S^{n-2}\simeq \{v\in S^{n-1}\subset\mathbb{R}^n : v_1=0\}$ (in what follows I identify $v=(v_1,\dots,v_{n-1})\in S^{n-2}\subset\mathbb{R}^{n-1}$ with $v=(0,v_1,\dots,v_{n-1})\in T_{e_1}S$ , the space of unit tangent vectors to $e_1$ ). I obtained this by considering the diffeomorphism $\varphi:S^{n-2}\times [0,\epsilon)\to B_\epsilon(e_1)$ given by $(v,t)\mapsto \cos(t)e_1+\sin(t)v$ and applying change of variables (see for example Proposition 9.8 here ). At the risk of being overly naive, the derivative of $\varphi$ is \begin{align*} D\varphi(v,t) = \begin{pmatrix} 0 & \cdots & 0 & -sin(t) \\  & \sin(t)I_{n-1} & & \vdots \end{pmatrix} \end{align*} which has determinant $-\sin^n(t)$ , hence the factor above.","Let . The geodesic ball of radius centered at is Let be smooth. Is the following true? Here is the volume form on and is the volume form on (in what follows I identify with , the space of unit tangent vectors to ). I obtained this by considering the diffeomorphism given by and applying change of variables (see for example Proposition 9.8 here ). At the risk of being overly naive, the derivative of is which has determinant , hence the factor above.","e_1=(1,0,\dots,0)\in S^{n-1}\subset\mathbb{R}^n \epsilon e_1 \begin{align*}
B_\epsilon(e_1) = \{\cos(t)e_1 + \sin(t)v : \lVert v\rVert=1, v_1=0, t\in[0,\epsilon)\}.
\end{align*} f:S^{n-1}\to\mathbb{R} \begin{align*}
\int_{B_\epsilon(e_1)}f(p)dp = \int_{S^{n-2}}\int_0^\epsilon f(\varphi(v,t))\sin^n(t)dtdv.
\end{align*} dp S^{n-1} dv S^{n-2}\simeq \{v\in S^{n-1}\subset\mathbb{R}^n : v_1=0\} v=(v_1,\dots,v_{n-1})\in S^{n-2}\subset\mathbb{R}^{n-1} v=(0,v_1,\dots,v_{n-1})\in T_{e_1}S e_1 \varphi:S^{n-2}\times [0,\epsilon)\to B_\epsilon(e_1) (v,t)\mapsto \cos(t)e_1+\sin(t)v \varphi \begin{align*}
D\varphi(v,t) = \begin{pmatrix} 0 & \cdots & 0 & -sin(t) \\ 
& \sin(t)I_{n-1} & & \vdots \end{pmatrix}
\end{align*} -\sin^n(t)","['integration', 'differential-geometry', 'riemannian-geometry']"
79,Existence of minimizing geodesic,Existence of minimizing geodesic,,"I have read in a post in Terence Tao's blog that in every connected smooth manifold, any two points can be joined by $C^1$ -piecewise minimising geodesic, but I am not so sure that this result is true in not necessarily complete manifolds, because otherwise we wouldn't need the completeness condition in the theorem of Hopf-Rinow. The classic counter-example is $\mathbb{R}^2\setminus\{0\}$ in which any point and its central inversion can't be joined by a minimising geodesic. So if anybody can confirm or invalidate Tao's statement, it would be appreciated.","I have read in a post in Terence Tao's blog that in every connected smooth manifold, any two points can be joined by -piecewise minimising geodesic, but I am not so sure that this result is true in not necessarily complete manifolds, because otherwise we wouldn't need the completeness condition in the theorem of Hopf-Rinow. The classic counter-example is in which any point and its central inversion can't be joined by a minimising geodesic. So if anybody can confirm or invalidate Tao's statement, it would be appreciated.",C^1 \mathbb{R}^2\setminus\{0\},"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
80,Lee Introduction to Smooth Manifolds Problem 8-15: Extension Lemma for Vector Fields on Submanifolds,Lee Introduction to Smooth Manifolds Problem 8-15: Extension Lemma for Vector Fields on Submanifolds,,"Three questions have been asked previously on this topic. First, there was Proving The Extension Lemma For Vector Fields On Submanifolds , asked over 10 years ago (!), which did not copy the problem statement exactly correctly. What was left out was that the embedded submanifold $S\subseteq M$ could actually be a submanifold with boundary. When I tried to work the first part of this problem, the solution given in the accepted answer to the referenced question seemed to not work when $S$ had a boundary. The second question asked previously on this topic was Lee book introduction to smooth manifold problem 8.15 , which correctly stated the problem as printed in the book. The OP of this question wrote that they ""could manage"" the first part of the problem. Unfortunately, the OP didn't share the proof they had. (Maybe the margin was too small to contain it.) The OP went on to say that they were asking for help with the reverse direction of the second part of the problem. Interestingly, the one answer given for this question did not address what the OP originally asked for, but rather gave a claimed proof for the first part. However, there seems to be a technical detail missing from the answer which has stymied me. The third question asked earlier was Better proof that vector fields on submanifolds extend globally iff submanifold is closed , which didn't go into the proof of the first part of the problem in either the question or the answer. Here's the technical detail in the answer to the second question that troubles me. (I'm paraphrasing the answer given): $n=\dim M$ , $k=\dim S$ , $X\in\mathfrak{X}(S)$ , $p\in S$ , $(U_p,\phi_p)$ is a smooth slice (or half-slice) chart centered at $p$ for $S$ in $M$ , $V_p=S\cap U_p$ , $\pi\colon\mathbb{R}^n\to\mathbb{R}^k$ is the projection on the first $k$ coordinates, $\psi_p=\pi\circ\phi_p|_{V_p}$ , $(V_p,\psi_p=(x^i))$ is a smooth chart centered at $p$ for $S$ , and $X$ is expanded as $$X|_{V_p}=X^i\frac{\partial}{\partial x^i},$$ where for $i=1,\dots,k$ , $X^i\colon V_p\to\mathbb{R}$ is a smooth function on $V_p$ as an open submanifold with or without boundary of $S$ . Due to the slice condition, $V_p$ is also a closed subset of $U_p$ . At this point the answer suggests that we can use the Extension Lemma for Smooth Functions (Lemma 2.26 in Lee ISM) to extend $X^i$ smoothly to $U_p$ . But I don't see how the hypotheses of that lemma are met in this case. Specifically, one needs to show that $X^i$ is smooth on $V_p$ , and I'm having a hard time doing that. All my attempts fail because given a point $q$ in $V_p$ (or even some subset of $V_p$ ), I can't seem to find a neighborhood of that point in $U_p$ on which a smooth function is defined which agrees with $X^i$ in the appropriate overlap set. So my question is, how do you fix (or get around) this problem? Note that I am not asking about a complete solution to Problem 8-15. I'm only requesting help with the first part, and only of the part before we bring in the smooth partition of unity. That is, I just want to be able to prove that there is a smooth extension of $X^i$ to $U_p$ . I also understand that it would not hurt to restrict $V_p$ first if necessary, so long as it still contains $p$ .","Three questions have been asked previously on this topic. First, there was Proving The Extension Lemma For Vector Fields On Submanifolds , asked over 10 years ago (!), which did not copy the problem statement exactly correctly. What was left out was that the embedded submanifold could actually be a submanifold with boundary. When I tried to work the first part of this problem, the solution given in the accepted answer to the referenced question seemed to not work when had a boundary. The second question asked previously on this topic was Lee book introduction to smooth manifold problem 8.15 , which correctly stated the problem as printed in the book. The OP of this question wrote that they ""could manage"" the first part of the problem. Unfortunately, the OP didn't share the proof they had. (Maybe the margin was too small to contain it.) The OP went on to say that they were asking for help with the reverse direction of the second part of the problem. Interestingly, the one answer given for this question did not address what the OP originally asked for, but rather gave a claimed proof for the first part. However, there seems to be a technical detail missing from the answer which has stymied me. The third question asked earlier was Better proof that vector fields on submanifolds extend globally iff submanifold is closed , which didn't go into the proof of the first part of the problem in either the question or the answer. Here's the technical detail in the answer to the second question that troubles me. (I'm paraphrasing the answer given): , , , , is a smooth slice (or half-slice) chart centered at for in , , is the projection on the first coordinates, , is a smooth chart centered at for , and is expanded as where for , is a smooth function on as an open submanifold with or without boundary of . Due to the slice condition, is also a closed subset of . At this point the answer suggests that we can use the Extension Lemma for Smooth Functions (Lemma 2.26 in Lee ISM) to extend smoothly to . But I don't see how the hypotheses of that lemma are met in this case. Specifically, one needs to show that is smooth on , and I'm having a hard time doing that. All my attempts fail because given a point in (or even some subset of ), I can't seem to find a neighborhood of that point in on which a smooth function is defined which agrees with in the appropriate overlap set. So my question is, how do you fix (or get around) this problem? Note that I am not asking about a complete solution to Problem 8-15. I'm only requesting help with the first part, and only of the part before we bring in the smooth partition of unity. That is, I just want to be able to prove that there is a smooth extension of to . I also understand that it would not hurt to restrict first if necessary, so long as it still contains .","S\subseteq M S n=\dim M k=\dim S X\in\mathfrak{X}(S) p\in S (U_p,\phi_p) p S M V_p=S\cap U_p \pi\colon\mathbb{R}^n\to\mathbb{R}^k k \psi_p=\pi\circ\phi_p|_{V_p} (V_p,\psi_p=(x^i)) p S X X|_{V_p}=X^i\frac{\partial}{\partial x^i}, i=1,\dots,k X^i\colon V_p\to\mathbb{R} V_p S V_p U_p X^i U_p X^i V_p q V_p V_p U_p X^i X^i U_p V_p p","['differential-geometry', 'smooth-manifolds', 'vector-fields', 'submanifold']"
81,Structure on moduli space of topological/smooth vector bundles,Structure on moduli space of topological/smooth vector bundles,,"If $M$ is paracompact (let us assume smooth manifold of dimension $d$ ), then one has that the set of isomorphism classes of vector bundles of rank $n$ over $M$ is isomorphic to the set of homotopy classes $V_n:=[M,G_n\left(\mathbb{R}^{n+d}\right)]$ from $M$ to a Grassmannian. This holds both in the topological and the smooth category over $M$ . I was wondering if there is any ""nice"" topological/smooth structure on $V_n$ ? Does it carry a well-behaved and non-trivial topology? Are there results on how ""many"" elements $V_n$ usually has? Finitely many, Countably many? This is really not my area, so these questions may have simple, well-known answers.","If is paracompact (let us assume smooth manifold of dimension ), then one has that the set of isomorphism classes of vector bundles of rank over is isomorphic to the set of homotopy classes from to a Grassmannian. This holds both in the topological and the smooth category over . I was wondering if there is any ""nice"" topological/smooth structure on ? Does it carry a well-behaved and non-trivial topology? Are there results on how ""many"" elements usually has? Finitely many, Countably many? This is really not my area, so these questions may have simple, well-known answers.","M d n M V_n:=[M,G_n\left(\mathbb{R}^{n+d}\right)] M M V_n V_n","['general-topology', 'differential-geometry', 'manifolds', 'smooth-manifolds', 'vector-bundles']"
82,Derive the Lemma of Christoffel symbol,Derive the Lemma of Christoffel symbol,,"Derive the Lemma of Christoffel symbol, $$\frac{\partial^2x^\rho}{\partial\bar x^\mu\partial\bar x^\nu}=\Gamma_{\mu\nu}^\gamma\frac{\partial x^\rho}{\partial\bar x^\gamma}-\frac{\partial x^\alpha}{\partial\bar x^\mu}\frac{\partial x^\beta}{\partial\bar x^\nu}\Gamma_{\alpha\beta}^\rho$$ We know that, $$\bar g_{ij}=\frac{\partial x^\alpha}{\partial \bar x^i}\frac{\partial x^\beta}{\partial\bar x^j}g_{\alpha\beta}\tag 1$$ Now, the process my book followed, differentiate $(1)$ with respect to different co-ordinate $\bar x^i$ , interchange several variable and use the definition of Christoffel symbol of first kind and multiplying conjugate metric $\bar g^{rk}$ . The complete computation was so tedious and it took 5 pages. Now, I can't just memorize that and copy in my exam sheet. Is there any other approach where things were flowing a sequence or I can easily memorize or understand those steps intuitively. Any solution or external redirect will be appreciated. Thanks in advance.","Derive the Lemma of Christoffel symbol, We know that, Now, the process my book followed, differentiate with respect to different co-ordinate , interchange several variable and use the definition of Christoffel symbol of first kind and multiplying conjugate metric . The complete computation was so tedious and it took 5 pages. Now, I can't just memorize that and copy in my exam sheet. Is there any other approach where things were flowing a sequence or I can easily memorize or understand those steps intuitively. Any solution or external redirect will be appreciated. Thanks in advance.",\frac{\partial^2x^\rho}{\partial\bar x^\mu\partial\bar x^\nu}=\Gamma_{\mu\nu}^\gamma\frac{\partial x^\rho}{\partial\bar x^\gamma}-\frac{\partial x^\alpha}{\partial\bar x^\mu}\frac{\partial x^\beta}{\partial\bar x^\nu}\Gamma_{\alpha\beta}^\rho \bar g_{ij}=\frac{\partial x^\alpha}{\partial \bar x^i}\frac{\partial x^\beta}{\partial\bar x^j}g_{\alpha\beta}\tag 1 (1) \bar x^i \bar g^{rk},"['differential-geometry', 'tensors', 'general-relativity', 'special-relativity']"
83,The angle between corresponding tangent lines on two Bertrand curves is constant,The angle between corresponding tangent lines on two Bertrand curves is constant,,"The angle between corresponding tangent lines on two Bertrand curves is constant and torsions of the two associate Bertrand curves have the same sign and their product is constant Two distinct parametrized curves $\boldsymbol{x}$ and $\boldsymbol{y}$ are called Bertrand mates if for each $t$ , the normal line to $\boldsymbol{x}$ at $\boldsymbol{x}(t)$ equals the normal line to $\boldsymbol{y}$ at $\boldsymbol{y}(t)$ . So, we have $$\boldsymbol{y}(s_1)=\boldsymbol{x}(s)+a(s)\boldsymbol{n}(s)$$ Now we have to calculate $\boldsymbol T_x$ and $\boldsymbol T_y$ : $$ \begin{align} \boldsymbol T_y&=\boldsymbol y'(s_1)\\ &=\boldsymbol x'(s)+a'(s)\boldsymbol n(s)+a(s)\boldsymbol n'(s)\\ &= \boldsymbol x'(s)+a'(s)\boldsymbol n(s)+a(s)(-\kappa \boldsymbol  t(s)+\tau\boldsymbol  b(s))\\ &=\boldsymbol  x'(s)-\kappa a(s)\boldsymbol  t(s)+a'(s)\boldsymbol n(s)+\tau a(s)\boldsymbol  b(s)\\\\ \boldsymbol T_x&=\boldsymbol x'(s) \end{align} $$ Now, consider, $\boldsymbol T_x . \boldsymbol T_y=\|\boldsymbol T_x\|\|\boldsymbol T_y\|\cos\theta$ . But from this, I couldn't see the angle $\theta$ is constant. Any help will be appreciated.","The angle between corresponding tangent lines on two Bertrand curves is constant and torsions of the two associate Bertrand curves have the same sign and their product is constant Two distinct parametrized curves and are called Bertrand mates if for each , the normal line to at equals the normal line to at . So, we have Now we have to calculate and : Now, consider, . But from this, I couldn't see the angle is constant. Any help will be appreciated.","\boldsymbol{x} \boldsymbol{y} t \boldsymbol{x} \boldsymbol{x}(t) \boldsymbol{y} \boldsymbol{y}(t) \boldsymbol{y}(s_1)=\boldsymbol{x}(s)+a(s)\boldsymbol{n}(s) \boldsymbol T_x \boldsymbol T_y 
\begin{align}
\boldsymbol T_y&=\boldsymbol y'(s_1)\\
&=\boldsymbol x'(s)+a'(s)\boldsymbol n(s)+a(s)\boldsymbol n'(s)\\
&= \boldsymbol x'(s)+a'(s)\boldsymbol n(s)+a(s)(-\kappa \boldsymbol  t(s)+\tau\boldsymbol  b(s))\\
&=\boldsymbol  x'(s)-\kappa a(s)\boldsymbol  t(s)+a'(s)\boldsymbol n(s)+\tau a(s)\boldsymbol  b(s)\\\\
\boldsymbol T_x&=\boldsymbol x'(s)
\end{align}
 \boldsymbol T_x . \boldsymbol T_y=\|\boldsymbol T_x\|\|\boldsymbol T_y\|\cos\theta \theta","['differential-geometry', 'curves', 'frenet-frame']"
84,Existence of integrating factor for a complex 1-form,Existence of integrating factor for a complex 1-form,,"Let $M$ be a smooth $n$ -manifold and $\theta\in\Omega^1(M)$ a (smooth) $1$ -form. A clear consequence of Frobenius' theorem is that the necessary and sufficient condition for the local existence of functions $\phi,\psi$ such that $\theta=\psi d\phi$ is $d\theta\wedge\theta=0$ . In particular this implies that every $1$ -form on a $2$ -manifold has an integrating factor. Suppose now that $\theta=\theta_1+i\theta_2$ is a complex-valued differential $1$ -form on $M$ . What is the necessary and sufficient condition for the existence of a pair $\phi,\psi$ of complex-valued functions such that $$ \theta=\psi d\phi? $$ The real Frobenius theorem does not seem to help here. The context of this question is the existence of isothermal coordinates on two dimensional Riemannian manifolds. When $(M,g)$ is a two dimensional Lorentzian manifold, the Frobenius theorem provides an easy proof since we may write $ds^2=\theta_1^2-\theta_0^2$ for some orthonormal coframe $\theta_0,\theta_1$ , which can be factored as $\theta_1^2-\theta_0^2=(\theta_1+\theta_0)(\theta_1-\theta_0)=\theta_+\theta_-$ and since each $1$ -form has an integrating factor, this gives $ds^2=\psi_+\psi_- d\phi_+d\phi_-=\psi_+\psi_-(dx^2-dt^2)$ where $\phi_+=x+t$ and $\phi_-=x-t$ . The same proof does not work for positive definite metrics since then we have $ds^2=\theta_1^2+\theta_2^2$ and this can be factored as $ds^2=(\theta_1+i\theta_2)(\theta_1-i\theta_2)=\omega\bar\omega$ . If it is also true that on a two dimensional space every complex $1$ -form has an integrating factor, we are done. There is a proof of the existence of isothermal coordinates this way in a paper by Chern , however it seems to me Chern wants to prove this theorem under minimal regularity assumptions and there are lots of analytical ""nonsense"" in the proof which makes it quite difficult for me to understand. What I am hoping if one is satisfied with a proof in the $C^r$ ( $r\ge 1$ ) or even $C^\infty$ category, there is a proof that is similar to the Frobenius theorem in that it does not rely on any heavy-duty analytic or PDE-theoretic results.","Let be a smooth -manifold and a (smooth) -form. A clear consequence of Frobenius' theorem is that the necessary and sufficient condition for the local existence of functions such that is . In particular this implies that every -form on a -manifold has an integrating factor. Suppose now that is a complex-valued differential -form on . What is the necessary and sufficient condition for the existence of a pair of complex-valued functions such that The real Frobenius theorem does not seem to help here. The context of this question is the existence of isothermal coordinates on two dimensional Riemannian manifolds. When is a two dimensional Lorentzian manifold, the Frobenius theorem provides an easy proof since we may write for some orthonormal coframe , which can be factored as and since each -form has an integrating factor, this gives where and . The same proof does not work for positive definite metrics since then we have and this can be factored as . If it is also true that on a two dimensional space every complex -form has an integrating factor, we are done. There is a proof of the existence of isothermal coordinates this way in a paper by Chern , however it seems to me Chern wants to prove this theorem under minimal regularity assumptions and there are lots of analytical ""nonsense"" in the proof which makes it quite difficult for me to understand. What I am hoping if one is satisfied with a proof in the ( ) or even category, there is a proof that is similar to the Frobenius theorem in that it does not rely on any heavy-duty analytic or PDE-theoretic results.","M n \theta\in\Omega^1(M) 1 \phi,\psi \theta=\psi d\phi d\theta\wedge\theta=0 1 2 \theta=\theta_1+i\theta_2 1 M \phi,\psi  \theta=\psi d\phi?  (M,g) ds^2=\theta_1^2-\theta_0^2 \theta_0,\theta_1 \theta_1^2-\theta_0^2=(\theta_1+\theta_0)(\theta_1-\theta_0)=\theta_+\theta_- 1 ds^2=\psi_+\psi_- d\phi_+d\phi_-=\psi_+\psi_-(dx^2-dt^2) \phi_+=x+t \phi_-=x-t ds^2=\theta_1^2+\theta_2^2 ds^2=(\theta_1+i\theta_2)(\theta_1-i\theta_2)=\omega\bar\omega 1 C^r r\ge 1 C^\infty","['differential-geometry', 'partial-differential-equations']"
85,Existence of A Smooth Function Under a Positive Continuous Function,Existence of A Smooth Function Under a Positive Continuous Function,,"Let $M$ be a smooth manifold. Let $f : M \to \mathbb{R}$ be a positive continuous function. Then is it true that there exists a positive smooth function $g : M \to \mathbb{R}$ such that $0 < g \le f$ ? This seems obvious, but I do not know how to approach. Thank you. (Edit) I think I proved it. If $M$ is compact, then $f$ has minimum, say $m > 0$ , so we can consider the constant function $g = m$ . If $M$ is noncompact, then consider some nice partition $\{ K_i \}_i$ of $M$ by compact sets, and let $m_i > 0$ be the minimum of $f|_{K_i}$ . Now we may take some nice smooth function $g$ such that $g \le m_i$ on each $K_i$ .","Let be a smooth manifold. Let be a positive continuous function. Then is it true that there exists a positive smooth function such that ? This seems obvious, but I do not know how to approach. Thank you. (Edit) I think I proved it. If is compact, then has minimum, say , so we can consider the constant function . If is noncompact, then consider some nice partition of by compact sets, and let be the minimum of . Now we may take some nice smooth function such that on each .",M f : M \to \mathbb{R} g : M \to \mathbb{R} 0 < g \le f M f m > 0 g = m M \{ K_i \}_i M m_i > 0 f|_{K_i} g g \le m_i K_i,"['real-analysis', 'differential-geometry', 'continuity', 'smooth-functions']"
86,Intrinsic curvature of transverse metric,Intrinsic curvature of transverse metric,,"Suppose we have a hypersurface $f(x^\mu)=0$ (with $\mu=0,1,...,d-1$ ) in a manifold with metric tensor $g_{\mu\nu}$ . The transverse metric is defined as $$h_{\mu\nu}=g_{\mu\nu}-n_\mu n_\nu,$$ with $$n_\mu=\frac{\partial_\mu f}{\sqrt{|\partial_\nu f \partial^\nu f|}}.$$ It is used to define the extrinsic curvature of the hypersurface: $$K_{\mu\nu}=h^\alpha_{~~\mu} h^\beta_{~~\nu}\nabla_\alpha n_\beta$$ Does it have any sense computing the Riemann (intrinsic) curvature tensor for $h_{\mu\nu}$ ? What would it mean? Would it be related to the extrinsic curvature?",Suppose we have a hypersurface (with ) in a manifold with metric tensor . The transverse metric is defined as with It is used to define the extrinsic curvature of the hypersurface: Does it have any sense computing the Riemann (intrinsic) curvature tensor for ? What would it mean? Would it be related to the extrinsic curvature?,"f(x^\mu)=0 \mu=0,1,...,d-1 g_{\mu\nu} h_{\mu\nu}=g_{\mu\nu}-n_\mu n_\nu, n_\mu=\frac{\partial_\mu f}{\sqrt{|\partial_\nu f \partial^\nu f|}}. K_{\mu\nu}=h^\alpha_{~~\mu} h^\beta_{~~\nu}\nabla_\alpha n_\beta h_{\mu\nu}","['differential-geometry', 'tensors', 'curvature', 'general-relativity']"
87,Does there exist a tangent field of normal vectors along a curve that covers all points near the curve?,Does there exist a tangent field of normal vectors along a curve that covers all points near the curve?,,"Let $\gamma: [0,1] \to \mathbb R^2$ be a parameterized curve, where $\gamma(t) = (x(t),y(t))$ is continuously differentiable with $(x' (t), y'(t)) \ne (0,0)$ for all $t \in [0,1]$ . Let $N(t) = (-y'(t),x'(t))$ be the normal vector to the tangent vector $\gamma' (t)$ . Is it true that for all $t \in (0,1)$ , there exists an open ball $B_r (t)$ with radius $r > 0$ such that for all $(x,y) \in B_r (t)$ , there exists $s \in (0,1)$ and $\alpha \in \mathbb R$ with $\gamma (s) + \alpha N(s) = (x,y)$ ? If we assume that $\gamma'$ also is continuously differentiable, we can use the Inverse Function Theorem: Define $f: \mathbb R^2 \to \mathbb R^2$ by $f( s, \alpha ) = \gamma (s) + \alpha N(s)$ . Then the Jacobian matrix of $f$ is: $\left[ \begin{array}   ,x'(s) - \alpha y''(s) & y'(s)+ \alpha x''(s) \\ -y'(s) & x'(s) \end{array} \right]$ The determinant of the Jacobian evaluated at $t$ is: $x'(t)^2 + y'(t)^2 \ne 0$ which shows that the matrix is invertible. It follows from the Inverse Function Theorem that $f$ is invertible in an open ball with center $t$ , which proves the claim. However, when $\gamma'$ is not differentiable, I am unsure how to create the proof. My attempt would be to fix $t_0,t_1 \in (0,1)$ with $t_0 < t < t_1$ and $K > 0$ such that the curve with image: $\{ f( t_0, \alpha) : \alpha \in [-K,K] \} \cup \{ f( t_1, \alpha) : \alpha \in [-K,K] \} \cup \{ f( s, K ) : s \in [t_0,t_1] \} \cup \{ f( s, -K ) : s \in [t_0,t_1] \}$ has positive distance $d$ from $\gamma(t)$ . Then we take the limit $t_0,t_1 \to t$ and $K \to 0$ , so the curve contracts continuously to $\gamma(t)$ . Then we can use tools from algebraic topology to show that for all $(x,y) \in B_d (t)$ , the contraction must pass through the point $(x,y)$ . Is such an approach viable?","Let be a parameterized curve, where is continuously differentiable with for all . Let be the normal vector to the tangent vector . Is it true that for all , there exists an open ball with radius such that for all , there exists and with ? If we assume that also is continuously differentiable, we can use the Inverse Function Theorem: Define by . Then the Jacobian matrix of is: The determinant of the Jacobian evaluated at is: which shows that the matrix is invertible. It follows from the Inverse Function Theorem that is invertible in an open ball with center , which proves the claim. However, when is not differentiable, I am unsure how to create the proof. My attempt would be to fix with and such that the curve with image: has positive distance from . Then we take the limit and , so the curve contracts continuously to . Then we can use tools from algebraic topology to show that for all , the contraction must pass through the point . Is such an approach viable?","\gamma: [0,1] \to \mathbb R^2 \gamma(t) = (x(t),y(t)) (x' (t), y'(t)) \ne (0,0) t \in [0,1] N(t) = (-y'(t),x'(t)) \gamma' (t) t \in (0,1) B_r (t) r > 0 (x,y) \in B_r (t) s \in (0,1) \alpha \in \mathbb R \gamma (s) + \alpha N(s) = (x,y) \gamma' f: \mathbb R^2 \to \mathbb R^2 f( s, \alpha ) = \gamma (s) + \alpha N(s) f \left[ \begin{array} 
 ,x'(s) - \alpha y''(s) & y'(s)+ \alpha x''(s) \\
-y'(s) & x'(s) \end{array} \right] t x'(t)^2 + y'(t)^2 \ne 0 f t \gamma' t_0,t_1 \in (0,1) t_0 < t < t_1 K > 0 \{ f( t_0, \alpha) : \alpha \in [-K,K] \} \cup \{ f( t_1, \alpha) : \alpha \in [-K,K] \} \cup \{ f( s, K ) : s \in [t_0,t_1] \} \cup \{ f( s, -K ) : s \in [t_0,t_1] \} d \gamma(t) t_0,t_1 \to t K \to 0 \gamma(t) (x,y) \in B_d (t) (x,y)","['differential-geometry', 'curves']"
88,Difficulty in proving $i_{\alpha} (\vartheta \wedge \zeta) = i_{\alpha} \vartheta \wedge \zeta + (-1)^k \vartheta \wedge i_{\alpha} \zeta.$,Difficulty in proving,i_{\alpha} (\vartheta \wedge \zeta) = i_{\alpha} \vartheta \wedge \zeta + (-1)^k \vartheta \wedge i_{\alpha} \zeta.,"Let $M$ be a smooth manifold. Let $\mathcal \vartheta \in \mathfrak X^k (M)$ be a $k$ -vector field and $\alpha \in \Omega^1 (M)$ be a $1$ -form on $M.$ Then we define $i_{\alpha} \vartheta \in \mathfrak X^{k-1} (M)$ (the interior product of $\vartheta$ by $\alpha$ ) as follows $:$ $$i_{\alpha} \vartheta\ (\alpha_1, \cdots, \alpha_{k-1}) : = \vartheta\ (\alpha, \alpha_1, \cdots, \alpha_{k-1})$$ where $\alpha_1, \cdots, \alpha_{k - 1} \in \Omega^1 (M).$ With this definition in mind we have to show that given $\vartheta \in \mathfrak X^k (M)$ and $\zeta \in \mathfrak X^s (M)$ the following equality holds $:$ $$i_{\alpha} (\vartheta \wedge  \zeta) = i_{\alpha} \vartheta \wedge \zeta + (-1)^k \vartheta \wedge i_{\alpha} \zeta.$$ Which I could not able to prove. Any help would be greatly appreciated. Thanks for your time.",Let be a smooth manifold. Let be a -vector field and be a -form on Then we define (the interior product of by ) as follows where With this definition in mind we have to show that given and the following equality holds Which I could not able to prove. Any help would be greatly appreciated. Thanks for your time.,"M \mathcal \vartheta \in \mathfrak X^k (M) k \alpha \in \Omega^1 (M) 1 M. i_{\alpha} \vartheta \in \mathfrak X^{k-1} (M) \vartheta \alpha : i_{\alpha} \vartheta\ (\alpha_1, \cdots, \alpha_{k-1}) : = \vartheta\ (\alpha, \alpha_1, \cdots, \alpha_{k-1}) \alpha_1, \cdots, \alpha_{k - 1} \in \Omega^1 (M). \vartheta \in \mathfrak X^k (M) \zeta \in \mathfrak X^s (M) : i_{\alpha} (\vartheta \wedge  \zeta) = i_{\alpha} \vartheta \wedge \zeta + (-1)^k \vartheta \wedge i_{\alpha} \zeta.","['differential-geometry', 'smooth-manifolds', 'differential-forms', 'vector-fields', 'exterior-algebra']"
89,Computing sectional curvature on flat torus,Computing sectional curvature on flat torus,,"There have been several questions similar to mine, but none of them fleshed out to a complete answer. I would like someone to look over this proof (I am NOT looking for alternative solutions), as it's the first time I've seriously computed with second fundamental form, Gauss equation, etc. Also, I can never read classical DG notation, so I'll stick to modern notation throughout. I want to show the sectional curvature of the Clifford torus, that is the image of the map $F:\mathbb{R}^2\to \mathbb{R}^4$ given by $$F(\theta,\phi)=\frac{1}{\sqrt{2}}(\cos\theta,\sin\theta,\cos\phi,\sin\phi),$$ has zero sectional curvature. Let us denote the image of $F$ by $T^2$ . Splitting $\mathbb{R}^4=\mathbb{R}^2_{r,\theta}\times \mathbb{R}^2_{s,\phi}$ into two copies of the plane with polar coordinates, let us take an orthonormal frame on $T^2$ as $e_1=\frac{1}{r}\partial_\theta$ and $e_2=\frac{1}{s}\partial_\phi$ . Now, we compute $$sec_{(\theta,\phi)}(T^2)=R^{T^2}(e_1,e_2,e_2,e_1)=R(e_1,e_2,e_2,e_1)+g(\Pi(e_1,e_1),\Pi(e_2,e_2))-g(\Pi(e_1,e_2),\Pi(e_1,e_2))$$ where the last equality follows by Gauss equation. Since R is the curvature tensor of Euclidean space, the first term vanishes. Therefore, it remains to compute the second fundamental forms. We compute $$\Pi(e_1,e_2)=-(\nabla_{\frac{1}{r}\partial_\theta}\frac{1}{s}\partial_\phi)^\perp=-(\frac{1}{sr}\Gamma^i_{\theta\phi}\partial_i)^\perp=0,$$ where the last equality is by consideration of $g_{\mathbb{R}^4}=dr^2+r^2d\theta^2+ds^2+s^2d\phi^2$ . Similarly $$\Pi(e_1,e_1)=-(\nabla_{\frac{1}{r}\partial_\theta}\frac{1}{r}\partial_\theta)^\perp=\left(\frac{\partial_r}{r}\right)^\perp=\frac{\partial_r}{r},$$ since $\partial_r$ is already perpendicular to the torus; similarly $\Pi(e_2,e_2)=\frac{\partial_s}{s}.$ But $\partial_r,\partial_s$ are orthogonal as we have a direct-sum decomposition, so all second fundamental form terms must vanish. Thus, the sectional curvature on the torus vanishes.","There have been several questions similar to mine, but none of them fleshed out to a complete answer. I would like someone to look over this proof (I am NOT looking for alternative solutions), as it's the first time I've seriously computed with second fundamental form, Gauss equation, etc. Also, I can never read classical DG notation, so I'll stick to modern notation throughout. I want to show the sectional curvature of the Clifford torus, that is the image of the map given by has zero sectional curvature. Let us denote the image of by . Splitting into two copies of the plane with polar coordinates, let us take an orthonormal frame on as and . Now, we compute where the last equality follows by Gauss equation. Since R is the curvature tensor of Euclidean space, the first term vanishes. Therefore, it remains to compute the second fundamental forms. We compute where the last equality is by consideration of . Similarly since is already perpendicular to the torus; similarly But are orthogonal as we have a direct-sum decomposition, so all second fundamental form terms must vanish. Thus, the sectional curvature on the torus vanishes.","F:\mathbb{R}^2\to \mathbb{R}^4 F(\theta,\phi)=\frac{1}{\sqrt{2}}(\cos\theta,\sin\theta,\cos\phi,\sin\phi), F T^2 \mathbb{R}^4=\mathbb{R}^2_{r,\theta}\times \mathbb{R}^2_{s,\phi} T^2 e_1=\frac{1}{r}\partial_\theta e_2=\frac{1}{s}\partial_\phi sec_{(\theta,\phi)}(T^2)=R^{T^2}(e_1,e_2,e_2,e_1)=R(e_1,e_2,e_2,e_1)+g(\Pi(e_1,e_1),\Pi(e_2,e_2))-g(\Pi(e_1,e_2),\Pi(e_1,e_2)) \Pi(e_1,e_2)=-(\nabla_{\frac{1}{r}\partial_\theta}\frac{1}{s}\partial_\phi)^\perp=-(\frac{1}{sr}\Gamma^i_{\theta\phi}\partial_i)^\perp=0, g_{\mathbb{R}^4}=dr^2+r^2d\theta^2+ds^2+s^2d\phi^2 \Pi(e_1,e_1)=-(\nabla_{\frac{1}{r}\partial_\theta}\frac{1}{r}\partial_\theta)^\perp=\left(\frac{\partial_r}{r}\right)^\perp=\frac{\partial_r}{r}, \partial_r \Pi(e_2,e_2)=\frac{\partial_s}{s}. \partial_r,\partial_s","['differential-geometry', 'solution-verification', 'riemannian-geometry', 'curvature']"
90,Tubular neighborhood of a surface in a 3-manifold,Tubular neighborhood of a surface in a 3-manifold,,"Consider a smooth $3$ -manifold $M$ , a submanifold $P$ of dimension $2$ and a non-vanishing vector field $V$ transverse to $P$ . Does there exist a neighborhood of $P$ diffeomorphic to $P\times (-\varepsilon, \varepsilon)$ , such that $V$ is pushed forward to $\partial z$ ? Here $\partial z$ is vector field corresponding to $(-\varepsilon, \varepsilon)$ direction. If that is not the case, what would be necessary conditions for that? I am not sure if this helps but this question is motivated by trying to think about convex surfaces for Reeb vector field in contact geometry.","Consider a smooth -manifold , a submanifold of dimension and a non-vanishing vector field transverse to . Does there exist a neighborhood of diffeomorphic to , such that is pushed forward to ? Here is vector field corresponding to direction. If that is not the case, what would be necessary conditions for that? I am not sure if this helps but this question is motivated by trying to think about convex surfaces for Reeb vector field in contact geometry.","3 M P 2 V P P P\times (-\varepsilon, \varepsilon) V \partial z \partial z (-\varepsilon, \varepsilon)","['differential-geometry', 'smooth-manifolds', 'submanifold', 'contact-geometry']"
91,Why can't we define the directional derivative of vector fields on a manifold in the same way as in $\mathbb{R}^n$.,Why can't we define the directional derivative of vector fields on a manifold in the same way as in .,\mathbb{R}^n,"First of all I apologize for my english, it is not my first language. I am reading the book ""Differential Geometry"" by Loring W. Tu. In subsection 4 of chapter 1, Tu defines the directional derivative at $p$ of a $C^\infty$ vector field $Y=\sum b^i \frac{\partial}{\partial x^i} \Bigr\rvert_{p}$ on $\mathbb{R}^n$ in the direction $X_p$ as \begin{align} D_{X_p}Y=\sum (X_p b^i)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}. \end{align} When $X$ is a $C^\infty$ vector field on $\mathbb{R}^n$ , not just a vector at $p$ , we define the vector field $D_XY$ on $\mathbb{R}^n$ by \begin{align*} (D_xY)_p=D_{X_p}Y  \end{align*} for all $p\in \mathbb{R}^n$ . Later, in subsection 6, which deals with affine connections, Tu writes: ""Consider a smooth vector field $Y$ on a manifold $M$ and a tangent vector $X_p \in T_pM$ at a point $p$ in $M$ . To define the directional derivative of $Y$ in the direction $X_p$ , it is necessary to compare the values of $Y$ in a neighborhood of $p$ . If $q$ is a point near $p$ , in general it is not possible to compare the vectors $Y_q$ and $Y_p$ by taking the difference $Y_q-Y_p$ , since they are in distinct tangent spaces. For this reason, the directional derivative of a vector field on an arbitrary manifold $M$ cannot be defined in the same way as in Section 4"". My problem is that I don't see in the definition of directional derivative where the values ​​of $Y_p$ and $Y_q$ are compared. In $\mathbb{R}^n$ , we have that to compute the directional derivative of $f$ at $p$ in the direction $X_p$ , we first write down a set of parametric equations for the line through $p$ in the direction $X_p$ : \begin{align*} x^i=p^i+ta^i \end{align*} with $i=1,...,n$ . Let $a=(a^1,...,a^n)$ . Then $D_{X_p}f$ is \begin{align*} D_{X_p}f&=\lim_{t \to 0} \frac{f(p+ta)-f(p)}{t}=\frac{d}{dt}\Bigr\rvert_{t=0} f(p+ta)\\ &=\sum \frac{\partial f}{\partial x^i}\Bigr\rvert_{p} \frac{dx^i}{dt}\Bigr\rvert_{0} =\sum \frac{\partial f}{\partial x^i}\Bigr\rvert_{p} a^i\\&=\big(\sum a^i \frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)f=X_p f. \end{align*} When $X$ and $Y$ are $C^\infty$ vector field on $\mathbb{R}^n$ , then \begin{align*} (D_xY)_p=D_{X_p}Y=\sum (X_p b^i)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}&=\sum \big(\lim_{t \to 0} \frac{b^i(p+ta)-b^i(p)}{t}\big)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\\ &=\sum \lim_{t \to 0} \frac{\big(b^i(p+ta)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)-\big(b^i(p)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)}{t} \tag{1} \end{align*} is this last line right?, I mean, is (1) right? or should I write \begin{align} =\sum \lim_{t \to 0} \frac{\big(b^i(p+ta)\frac{\partial}{\partial x^i} \Bigr\rvert_{p+ta}\big)-\big(b^i(p)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)}{t}. \tag{2} \end{align} If (2) is the right way, then I see why is not possible to compare $Y_q$ and $Y_p$ , and the reason is because they are in distinct tangent spaces. In $\mathbb{R}^n$ we do not have this problem, because there are a canonical basis for all the tangent spaces, and that is why we can compare tangent vectors in distinct tangent spaces. But if (1) is right then I do not see why we can not define the directional derivative of vector fields on a manifold in the same way is done in $\mathbb{R}^n$ . What am I not understanding correctly? Thanks for your help.","First of all I apologize for my english, it is not my first language. I am reading the book ""Differential Geometry"" by Loring W. Tu. In subsection 4 of chapter 1, Tu defines the directional derivative at of a vector field on in the direction as When is a vector field on , not just a vector at , we define the vector field on by for all . Later, in subsection 6, which deals with affine connections, Tu writes: ""Consider a smooth vector field on a manifold and a tangent vector at a point in . To define the directional derivative of in the direction , it is necessary to compare the values of in a neighborhood of . If is a point near , in general it is not possible to compare the vectors and by taking the difference , since they are in distinct tangent spaces. For this reason, the directional derivative of a vector field on an arbitrary manifold cannot be defined in the same way as in Section 4"". My problem is that I don't see in the definition of directional derivative where the values ​​of and are compared. In , we have that to compute the directional derivative of at in the direction , we first write down a set of parametric equations for the line through in the direction : with . Let . Then is When and are vector field on , then is this last line right?, I mean, is (1) right? or should I write If (2) is the right way, then I see why is not possible to compare and , and the reason is because they are in distinct tangent spaces. In we do not have this problem, because there are a canonical basis for all the tangent spaces, and that is why we can compare tangent vectors in distinct tangent spaces. But if (1) is right then I do not see why we can not define the directional derivative of vector fields on a manifold in the same way is done in . What am I not understanding correctly? Thanks for your help.","p C^\infty Y=\sum b^i \frac{\partial}{\partial x^i} \Bigr\rvert_{p} \mathbb{R}^n X_p \begin{align}
D_{X_p}Y=\sum (X_p b^i)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}.
\end{align} X C^\infty \mathbb{R}^n p D_XY \mathbb{R}^n \begin{align*}
(D_xY)_p=D_{X_p}Y 
\end{align*} p\in \mathbb{R}^n Y M X_p \in T_pM p M Y X_p Y p q p Y_q Y_p Y_q-Y_p M Y_p Y_q \mathbb{R}^n f p X_p p X_p \begin{align*}
x^i=p^i+ta^i
\end{align*} i=1,...,n a=(a^1,...,a^n) D_{X_p}f \begin{align*}
D_{X_p}f&=\lim_{t \to 0} \frac{f(p+ta)-f(p)}{t}=\frac{d}{dt}\Bigr\rvert_{t=0} f(p+ta)\\
&=\sum \frac{\partial f}{\partial x^i}\Bigr\rvert_{p} \frac{dx^i}{dt}\Bigr\rvert_{0} =\sum \frac{\partial f}{\partial x^i}\Bigr\rvert_{p} a^i\\&=\big(\sum a^i \frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)f=X_p f.
\end{align*} X Y C^\infty \mathbb{R}^n \begin{align*}
(D_xY)_p=D_{X_p}Y=\sum (X_p b^i)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}&=\sum \big(\lim_{t \to 0} \frac{b^i(p+ta)-b^i(p)}{t}\big)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\\
&=\sum \lim_{t \to 0} \frac{\big(b^i(p+ta)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)-\big(b^i(p)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)}{t} \tag{1}
\end{align*} \begin{align}
=\sum \lim_{t \to 0} \frac{\big(b^i(p+ta)\frac{\partial}{\partial x^i} \Bigr\rvert_{p+ta}\big)-\big(b^i(p)\frac{\partial}{\partial x^i} \Bigr\rvert_{p}\big)}{t}. \tag{2}
\end{align} Y_q Y_p \mathbb{R}^n \mathbb{R}^n","['differential-geometry', 'manifolds', 'riemannian-geometry', 'smooth-manifolds']"
92,Does the zero locus of a real analytic function have a smooth point?,Does the zero locus of a real analytic function have a smooth point?,,"Let $F \colon \mathbb{R}^m \to \mathbb{R}^n$ be a real analytic function (i.e., each of its component functions is real analytic).  Does the set $$Z = \{x \in \mathbb{R}^m : F(x) = 0\}$$ have a smooth point?  If not, what is an explicit example of such a set with no smooth points?  Assume $Z$ is not empty. By $x \in Z$ is a smooth point, I mean there is an open set $U \subset \mathbb{R}^m$ containing $x$ such that $Z \cap U$ is a smooth manifold. [Comments: I know this is true if $F$ is a polynomial map (and so $Z$ is an affine variety).]","Let be a real analytic function (i.e., each of its component functions is real analytic).  Does the set have a smooth point?  If not, what is an explicit example of such a set with no smooth points?  Assume is not empty. By is a smooth point, I mean there is an open set containing such that is a smooth manifold. [Comments: I know this is true if is a polynomial map (and so is an affine variety).]",F \colon \mathbb{R}^m \to \mathbb{R}^n Z = \{x \in \mathbb{R}^m : F(x) = 0\} Z x \in Z U \subset \mathbb{R}^m x Z \cap U F Z,"['differential-geometry', 'algebraic-geometry', 'systems-of-equations', 'analyticity']"
93,correspondence between locally free sheaf of finite rank equipped with flat connection and the local system,correspondence between locally free sheaf of finite rank equipped with flat connection and the local system,,"The $(X,C^\infty)$ is a smooth manifold then we have the following theorem which says the category of locally free sheaves of finite rank with flat connection is equivalent to the category of $\Bbb{R}$ -local system. The functor between the category of locally free sheaves with flat connection and the category of the local system as shown in this post , takes the kernel of the connection and gives $\mathcal{L} = \ker \nabla$ . I try to prove that $\mathcal{L}$ is a local system. In the language of a vector bundle, the kernel of the connection is some parallel section of bundle, if the connection is flat we can parallel transport along the coordinate axis, since the commutation relation $$[\nabla_{\partial_i},\nabla_{\partial_j}] = 0$$ we can prove that this process really produces a section such that $\nabla s = 0$ that independent order of translation. (See for example Lee's Riemannian manifold book Lemma 7.8). However, I don't know how to prove it is a local system after that. (That is I want to show $\mathcal{L}|_U \cong \underline{\Bbb{R}}^k$ )","The is a smooth manifold then we have the following theorem which says the category of locally free sheaves of finite rank with flat connection is equivalent to the category of -local system. The functor between the category of locally free sheaves with flat connection and the category of the local system as shown in this post , takes the kernel of the connection and gives . I try to prove that is a local system. In the language of a vector bundle, the kernel of the connection is some parallel section of bundle, if the connection is flat we can parallel transport along the coordinate axis, since the commutation relation we can prove that this process really produces a section such that that independent order of translation. (See for example Lee's Riemannian manifold book Lemma 7.8). However, I don't know how to prove it is a local system after that. (That is I want to show )","(X,C^\infty) \Bbb{R} \mathcal{L} = \ker \nabla \mathcal{L} [\nabla_{\partial_i},\nabla_{\partial_j}] = 0 \nabla s = 0 \mathcal{L}|_U \cong \underline{\Bbb{R}}^k","['differential-geometry', 'algebraic-geometry', 'smooth-manifolds', 'complex-geometry']"
94,Radius of curvature at a point on a Lorentzian manifold,Radius of curvature at a point on a Lorentzian manifold,,"I recently asked this question on the physics stack exchange. After some discussion in the comments, I didn't really arrive at a satisfactory conclusion, so I thought it might be worth it to ask it here as well. I'm new to posting questions here, so if it goes against guidelines, then apologies and a mod can close this. Anyway, here is the question. For context, I am reading this paper. The authors speak of the radius of curvature of a spacetime at a particular point. However, they don't give an explicit definition of this term. So more precisely, let $(M,g)$ be a $D$ -dimensional Lorentzian manifold with Riemann tensor $R$ , which is non-vanishing, and consider an arbitrary point $p\in M$ . Then how is the radius of curvature at $p$ defined? In the comments to my original post, user Prahar provided the following definition: \begin{equation} \tag{1} r^2(x)=\frac{D(D-1)}{R(x)} \end{equation} where $r(x)$ is the radius of curvature at $x$ and $R(x)$ is the Ricci scalar at $x$ . The problem is, the authors of the article mentioned above, have to be using a definition where the radius of curvature is finite, even in a Ricci-flat region of $M$ . This is clearly not the case for this definition, since the Ricci scalar would be identically zero in a Ricci flat region and hence $r$ would diverge. My question can thus be summarized: Is there a definition of the radius of curvature at a point on a Lorentzian manifold such that the radius of curvature is finite even in a Ricci-flat region of the manifold? One candidate I could think of would be to replace $R(x)$ with the square-root of the Kretschmann scalar in $(1)$ . However I don't know if this even makes sense as a definition of radius of curvature. Any answers or reference suggestions are greatly appreciated.","I recently asked this question on the physics stack exchange. After some discussion in the comments, I didn't really arrive at a satisfactory conclusion, so I thought it might be worth it to ask it here as well. I'm new to posting questions here, so if it goes against guidelines, then apologies and a mod can close this. Anyway, here is the question. For context, I am reading this paper. The authors speak of the radius of curvature of a spacetime at a particular point. However, they don't give an explicit definition of this term. So more precisely, let be a -dimensional Lorentzian manifold with Riemann tensor , which is non-vanishing, and consider an arbitrary point . Then how is the radius of curvature at defined? In the comments to my original post, user Prahar provided the following definition: where is the radius of curvature at and is the Ricci scalar at . The problem is, the authors of the article mentioned above, have to be using a definition where the radius of curvature is finite, even in a Ricci-flat region of . This is clearly not the case for this definition, since the Ricci scalar would be identically zero in a Ricci flat region and hence would diverge. My question can thus be summarized: Is there a definition of the radius of curvature at a point on a Lorentzian manifold such that the radius of curvature is finite even in a Ricci-flat region of the manifold? One candidate I could think of would be to replace with the square-root of the Kretschmann scalar in . However I don't know if this even makes sense as a definition of radius of curvature. Any answers or reference suggestions are greatly appreciated.","(M,g) D R p\in M p \begin{equation}
\tag{1}
r^2(x)=\frac{D(D-1)}{R(x)}
\end{equation} r(x) x R(x) x M r R(x) (1)","['differential-geometry', 'definition', 'general-relativity']"
95,Volume comparison for scalar curvature,Volume comparison for scalar curvature,,"I'm reading Gromov's article "" Four lectures on scalar curvature "". On the page 7, he states a volume comparison theorem for small balls without proof. I want to know how to prove it or where I can find its proof. The article can be found on arXiv:1908.10612v6. I would like to restate this theorem here: If the scalar curvature of $n$ -dimensional manifolds $X$ and $X'$ at some points $x\in X$ and $x'\in X'$ are related by the strict inequality $$Sc(X)(x)<Sc(X')(x')$$ then the Riemannian volumes of the $\varepsilon$ -balls around these points satisfy $$vol(B_x(X,\varepsilon))>vol(B_{x'}(X',\varepsilon))$$ for all sufficiently small $\varepsilon>0.$","I'm reading Gromov's article "" Four lectures on scalar curvature "". On the page 7, he states a volume comparison theorem for small balls without proof. I want to know how to prove it or where I can find its proof. The article can be found on arXiv:1908.10612v6. I would like to restate this theorem here: If the scalar curvature of -dimensional manifolds and at some points and are related by the strict inequality then the Riemannian volumes of the -balls around these points satisfy for all sufficiently small","n X X' x\in X x'\in X' Sc(X)(x)<Sc(X')(x') \varepsilon vol(B_x(X,\varepsilon))>vol(B_{x'}(X',\varepsilon)) \varepsilon>0.","['differential-geometry', 'reference-request', 'riemannian-geometry', 'differential-topology']"
96,A question on warped product Riemannian metric,A question on warped product Riemannian metric,,"I am studying a text of Riemannian geometry where the author says: Let the product manifold $M=I\times \tilde{M}$ where $I$ is an interval of $\mathbb{R}$ and $\tilde{M}$ is an $(n-1)-$ dimensional manifold equipped with a Riemannian metric $\tilde{g}$ . A warped product Riemannian metric on $M$ can be written as $$g= dr\otimes dr + w(r) \tilde{g}$$ where $r$ is the standard coordinate on $I$ and $w(r)$ is a positive function. If $F$ and $\tilde F$ denote norms induced by the Riemannian inner products on $M$ and $\tilde M$ respectively, we get $$F(v)=\sqrt{v^1v^1+w(r)\tilde{F}^2(\tilde{v})},$$ where $\tilde{v}$ is projection of v on $\tilde{M}$ . We generalize it to the form $$F=\sqrt{w(v^1, r, \tilde{F})}. $$ Since F is positive homogeneous of degree one,  we have $$F = \tilde F.  \sqrt{w(\frac{v^1}{\tilde{F}}, r, 1)}, $$ for $\tilde{F} \neq 0$ . Since $\{v\in T_x M \mid \tilde{F}=0\}$ is a one dimensional subspace of $T_x M$ ( $x\in M$ ), the norm $F$ can be determined by its values on the open subset $\{v\in T_x M \mid \tilde{F} \neq 0\}$ by the continuity. I don't know which theorem is used that this result came up? Can someone explain it for me?","I am studying a text of Riemannian geometry where the author says: Let the product manifold where is an interval of and is an dimensional manifold equipped with a Riemannian metric . A warped product Riemannian metric on can be written as where is the standard coordinate on and is a positive function. If and denote norms induced by the Riemannian inner products on and respectively, we get where is projection of v on . We generalize it to the form Since F is positive homogeneous of degree one,  we have for . Since is a one dimensional subspace of ( ), the norm can be determined by its values on the open subset by the continuity. I don't know which theorem is used that this result came up? Can someone explain it for me?","M=I\times \tilde{M} I \mathbb{R} \tilde{M} (n-1)- \tilde{g} M g= dr\otimes dr + w(r) \tilde{g} r I w(r) F \tilde F M \tilde M F(v)=\sqrt{v^1v^1+w(r)\tilde{F}^2(\tilde{v})}, \tilde{v} \tilde{M} F=\sqrt{w(v^1, r, \tilde{F})}.  F = \tilde F.  \sqrt{w(\frac{v^1}{\tilde{F}}, r, 1)},  \tilde{F} \neq 0 \{v\in T_x M \mid \tilde{F}=0\} T_x M x\in M F \{v\in T_x M \mid \tilde{F} \neq 0\}","['differential-geometry', 'normed-spaces', 'riemannian-geometry']"
97,An oriented compact smooth manifold with boundary does not have a retraction onto its boundary,An oriented compact smooth manifold with boundary does not have a retraction onto its boundary,,"The following is Problem 16-4 of Lee's Introduction to Smooth manifolds. Suppose $M$ is an oriented compact smooth manifold with nonempty boundary. Show that there does not exist a retraction of $M$ onto its boundary. [Hint: if the retraction is smooth, consider an orientation form on $\partial M$ .] Suppose there is a smooth retraction $r:M\to\partial M$ and let $\iota: \partial M\hookrightarrow M$ be an inclusion so that $r\circ\iota = 1$ . Let $\omega$ be an orientation form of $\partial M$ . Then by Stoke's theorem, \begin{align*} \int_{\partial M} r^*\omega = \int_M d(r^*\omega) = \int_M r^*(d\omega) = 0. \end{align*} where the last equality follows from the fact that $d\omega = 0$ . Since $r\circ\iota = 1$ , we have \begin{align*} \int_{\partial M}r^*\omega = \int_{\partial M}\iota^*r^*\omega = \int_{\partial M}(r\circ\iota)^*\omega = \int_{\partial M}\omega.\end{align*} Hence, we get $$\int_{\partial M}\omega = 0.$$ which is a contradiction as $\omega$ is an orientation form of $\partial M$ . Now, suppose $\tilde{r}:M\to\partial M$ is just continuous. Then by Smooth approximation theorem, $\tilde{r}\simeq r$ where $r:M\to\partial M$ is smooth. Then $\tilde{r}\circ\iota = 1\simeq r\circ\iota$ . Since $1$ and $r\circ\iota$ are smooth, we can choose a smooth homotopy $H:M\times I\to \partial M$ such that $H(x,0) = x$ and $H(x,1) = r\circ\iota(x)$ . Now, $$\int_{\partial (M\times I)}H^*\omega = \int_{M\times I}d(H^*\omega) = \int_{M\times I}H^*(d\omega) = 0.$$ I'm stuck in here. I need to express $\partial (M\times I)$ as a finite union of manifolds with boundary but can't see.","The following is Problem 16-4 of Lee's Introduction to Smooth manifolds. Suppose is an oriented compact smooth manifold with nonempty boundary. Show that there does not exist a retraction of onto its boundary. [Hint: if the retraction is smooth, consider an orientation form on .] Suppose there is a smooth retraction and let be an inclusion so that . Let be an orientation form of . Then by Stoke's theorem, where the last equality follows from the fact that . Since , we have Hence, we get which is a contradiction as is an orientation form of . Now, suppose is just continuous. Then by Smooth approximation theorem, where is smooth. Then . Since and are smooth, we can choose a smooth homotopy such that and . Now, I'm stuck in here. I need to express as a finite union of manifolds with boundary but can't see.","M M \partial M r:M\to\partial M \iota: \partial M\hookrightarrow M r\circ\iota = 1 \omega \partial M \begin{align*}
\int_{\partial M} r^*\omega = \int_M d(r^*\omega) = \int_M r^*(d\omega) = 0.
\end{align*} d\omega = 0 r\circ\iota = 1 \begin{align*}
\int_{\partial M}r^*\omega = \int_{\partial M}\iota^*r^*\omega = \int_{\partial M}(r\circ\iota)^*\omega = \int_{\partial M}\omega.\end{align*} \int_{\partial M}\omega = 0. \omega \partial M \tilde{r}:M\to\partial M \tilde{r}\simeq r r:M\to\partial M \tilde{r}\circ\iota = 1\simeq r\circ\iota 1 r\circ\iota H:M\times I\to \partial M H(x,0) = x H(x,1) = r\circ\iota(x) \int_{\partial (M\times I)}H^*\omega = \int_{M\times I}d(H^*\omega) = \int_{M\times I}H^*(d\omega) = 0. \partial (M\times I)","['differential-geometry', 'smooth-manifolds']"
98,Are initial submanifolds cofibrations?,Are initial submanifolds cofibrations?,,"In Natural Operations in Differential Geometry by Kolar, Michor, & Slovak, they define an initial submanifold as follows: They can be shown to satisfy the following universal property: I am aware that the inclusion of an embedded submanifold is a cofibration, and I am wondering if the same holds for the more general class of initial submanifolds?","In Natural Operations in Differential Geometry by Kolar, Michor, & Slovak, they define an initial submanifold as follows: They can be shown to satisfy the following universal property: I am aware that the inclusion of an embedded submanifold is a cofibration, and I am wondering if the same holds for the more general class of initial submanifolds?",,"['general-topology', 'differential-geometry', 'algebraic-topology', 'differential-topology']"
99,Smooth family of diffeomorphisms gives a complete vector field?,Smooth family of diffeomorphisms gives a complete vector field?,,"Let $M$ be a manifold and $U\subseteq \mathbb R$ an open interval containing $0$ . Consider a smooth map $\Phi:U \times M\rightarrow M$ such that $\Phi(t,-):M\rightarrow M$ is a diffeomorphism, for every $t\in U$ $\Phi(0,-)$ is the identity morphism. Then, for every $x\in M$ , we have a path $\Phi(-,x):(U,0)\rightarrow (M,x)$ representing a tangent vector $v_x=\Phi(-,x)_*(\frac{d}{dt})\in T_xM$ and so we get a vector field $v:M\rightarrow TM$ . This vector field has itself a maximal flow $\Psi:V\rightarrow M$ (defined on some open $V\subseteq \mathbb R\times M$ containing $\{0\}\times M$ ) and so I define the following $$\mathcal D=\{t\in\mathbb R|(t,x)\in V\forall x\in M\}$$ so $\mathcal D$ is the maximal domain on which every maximal integral curve is defined. My question is In the context of this question, is $\mathcal D$ an open neighborhood of $0$ ? For those interested, here is where this question comes from: I'm reading about the internal tangent space to a diffeological space . I'm particularly interested in the tangent space at the identity of the diffeological space $\text{Diff}(M)$ . The construction of the internal tangent space (ITS, for short) is here and here . In general, the ITS at some point $x$ of the diffeological space $X$ is linearly generated by pairs $(p,u)$ , with $p: (W,0)\rightarrow(X,x)$ a plot for $X$ (with $W$ open neighborhood of $0\in\mathbb R$ ) and $u\in T_0W$ . For every smooth $f:(W',0)\rightarrow (W,0)$ we identify $(pf,u)$ with $(p,f_*(u))$ . In here , the author proves that if $G$ is a diffeological group, then every tangent vector $v\in T_gG$ ( $g$ any point $\in G$ ) can be represented by a single pair $(p,u)$ like above. In particular, this applies to $\text{Diff}(M)$ , so every $v\in T_\text{id}\text{Diff}(M)$ is represented by some plot $p:U\rightarrow \text{Diff}(M)$ sending $0$ to $\text{id}$ and a tangent vector $u\in T_0U$ . Now, a plot $p$ is like above a smooth family $U\times M\rightarrow M$ of diffeomorphisms, in particular given the pair $(p,u)$ we can associate a vector field as $$x\mapsto p(-,x)_*(u)\in T_xM$$ so that we have a map $$\gamma:T_\text{id}\text{Diff}(M)\rightarrow \mathfrak X(M)$$ If $M$ is compact, then $\gamma$ is an isomorphism (proved in the articles above). In general, I want to understand the image of $\gamma$ for a non-necessarily compact manifold. For now, my guess is that the image of $\gamma$ are those vector fields for which $\mathcal D$ (defined as above) is an open neighborhood of $0$ .","Let be a manifold and an open interval containing . Consider a smooth map such that is a diffeomorphism, for every is the identity morphism. Then, for every , we have a path representing a tangent vector and so we get a vector field . This vector field has itself a maximal flow (defined on some open containing ) and so I define the following so is the maximal domain on which every maximal integral curve is defined. My question is In the context of this question, is an open neighborhood of ? For those interested, here is where this question comes from: I'm reading about the internal tangent space to a diffeological space . I'm particularly interested in the tangent space at the identity of the diffeological space . The construction of the internal tangent space (ITS, for short) is here and here . In general, the ITS at some point of the diffeological space is linearly generated by pairs , with a plot for (with open neighborhood of ) and . For every smooth we identify with . In here , the author proves that if is a diffeological group, then every tangent vector ( any point ) can be represented by a single pair like above. In particular, this applies to , so every is represented by some plot sending to and a tangent vector . Now, a plot is like above a smooth family of diffeomorphisms, in particular given the pair we can associate a vector field as so that we have a map If is compact, then is an isomorphism (proved in the articles above). In general, I want to understand the image of for a non-necessarily compact manifold. For now, my guess is that the image of are those vector fields for which (defined as above) is an open neighborhood of .","M U\subseteq \mathbb R 0 \Phi:U \times M\rightarrow M \Phi(t,-):M\rightarrow M t\in U \Phi(0,-) x\in M \Phi(-,x):(U,0)\rightarrow (M,x) v_x=\Phi(-,x)_*(\frac{d}{dt})\in T_xM v:M\rightarrow TM \Psi:V\rightarrow M V\subseteq \mathbb R\times M \{0\}\times M \mathcal D=\{t\in\mathbb R|(t,x)\in V\forall x\in M\} \mathcal D \mathcal D 0 \text{Diff}(M) x X (p,u) p: (W,0)\rightarrow(X,x) X W 0\in\mathbb R u\in T_0W f:(W',0)\rightarrow (W,0) (pf,u) (p,f_*(u)) G v\in T_gG g \in G (p,u) \text{Diff}(M) v\in T_\text{id}\text{Diff}(M) p:U\rightarrow \text{Diff}(M) 0 \text{id} u\in T_0U p U\times M\rightarrow M (p,u) x\mapsto p(-,x)_*(u)\in T_xM \gamma:T_\text{id}\text{Diff}(M)\rightarrow \mathfrak X(M) M \gamma \gamma \gamma \mathcal D 0","['differential-geometry', 'vector-fields']"
