,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,component and dimension in Gaussian mixture model,component and dimension in Gaussian mixture model,,"What is the relation between a dimension and a component in a Gaussian Mixture Model? And what is the meaning of dimension and component? Thank you. Please correct me if I'm wrong: my understanding is the observed data have many dimensions. Each dimension represents a feature/aspect of the collected data and has its own Gaussian distribution. I don't know where ""component"" fits into this picture and what it means.","What is the relation between a dimension and a component in a Gaussian Mixture Model? And what is the meaning of dimension and component? Thank you. Please correct me if I'm wrong: my understanding is the observed data have many dimensions. Each dimension represents a feature/aspect of the collected data and has its own Gaussian distribution. I don't know where ""component"" fits into this picture and what it means.",,"['statistics', 'terminology', 'probability-distributions']"
1,How to measure if a sequence has a bimodal distribution,How to measure if a sequence has a bimodal distribution,,"Inspired by the recent incident in which a professor was able to [detect that students in his class were cheating][1], I'm curious if there is a standard way to detect if a distribution is bimodal, or a standard measure of the 'bimodality' of a distribution. Does such a test exist? What are caveats that I should be aware of in such a test?","Inspired by the recent incident in which a professor was able to [detect that students in his class were cheating][1], I'm curious if there is a standard way to detect if a distribution is bimodal, or a standard measure of the 'bimodality' of a distribution. Does such a test exist? What are caveats that I should be aware of in such a test?",,"['probability', 'statistics']"
2,binomial-Poisson/beta hierarchy,binomial-Poisson/beta hierarchy,,"X|N,P ~ Binomial(N, P) N ~ Poisson(11) P ~ Beta(2,3) What is the moment generating function for X?","X|N,P ~ Binomial(N, P) N ~ Poisson(11) P ~ Beta(2,3) What is the moment generating function for X?",,['probability']
3,How do I determine if my variance is significant?,How do I determine if my variance is significant?,,"For a given group of data, I have both a mean and variance (already calculated). Looking over the raw spread of data, and its numerous outliers, I expect that variance will be high. My question is -- now that I have my variance calculated, what do I need to compare it to to determine if the variance is significant (i.e., indicative of highly skewed data)?","For a given group of data, I have both a mean and variance (already calculated). Looking over the raw spread of data, and its numerous outliers, I expect that variance will be high. My question is -- now that I have my variance calculated, what do I need to compare it to to determine if the variance is significant (i.e., indicative of highly skewed data)?",,['statistics']
4,How to do hypothesis testing on Gaussian mixture model?,How to do hypothesis testing on Gaussian mixture model?,,"I am CS major, please be patient if my question is not well-stated. The dataset is quantitative mass spectrometry (MS) data. By labeling proteins of two different samples A and B, we get the relative abundance of 100 to thousands of proteins in A/B. Alongside with this ratio, we can estimate its variance based on the signal intensities. Wanted: A list of proteins significantly different from the set of all protein ratios. Most proteins remain unchanged between A and B. The population of log-ratios distributes around 1. The histogram shows a bell shape with fat tails. Two-term Gaussian mixture model has been found to provide a good fit to experimental noise. I suppose it would work good for this data - think of experimental and biological noise. How to test for significantly different ratios on such a two-term Gaussian mixture model? Thanks for your responses!","I am CS major, please be patient if my question is not well-stated. The dataset is quantitative mass spectrometry (MS) data. By labeling proteins of two different samples A and B, we get the relative abundance of 100 to thousands of proteins in A/B. Alongside with this ratio, we can estimate its variance based on the signal intensities. Wanted: A list of proteins significantly different from the set of all protein ratios. Most proteins remain unchanged between A and B. The population of log-ratios distributes around 1. The histogram shows a bell shape with fat tails. Two-term Gaussian mixture model has been found to provide a good fit to experimental noise. I suppose it would work good for this data - think of experimental and biological noise. How to test for significantly different ratios on such a two-term Gaussian mixture model? Thanks for your responses!",,['statistics']
5,Logistic function passing through two points AND the origin?,Logistic function passing through two points AND the origin?,,"I had recently asked the question: Logistic function passing through two points? which received a very helpful answer. However, I'd like to ask your help again as the formulation of the problem has slightly changed and i'm lost... Problem: Given two points: $(x_l, y_l)$ and $(x_u, y_u)$ with: $x_l < x_u$ and $y_l < y_u$, and given that the higher asymptote is one ($\lim_{x\to+\infty}f(x)=1$) what's the logistic function that passes through the two points and the origin $(0, 0)$ ? Thanks!","I had recently asked the question: Logistic function passing through two points? which received a very helpful answer. However, I'd like to ask your help again as the formulation of the problem has slightly changed and i'm lost... Problem: Given two points: $(x_l, y_l)$ and $(x_u, y_u)$ with: $x_l < x_u$ and $y_l < y_u$, and given that the higher asymptote is one ($\lim_{x\to+\infty}f(x)=1$) what's the logistic function that passes through the two points and the origin $(0, 0)$ ? Thanks!",,"['statistics', 'exponential-function']"
6,How can I calculate this expected rate?,How can I calculate this expected rate?,,"In DotA, there is a character called "" Axe "". Every time he is attacked, he has a chance to spin ($17\%$) his blade and deal damage based on what level the skill is, $100 / 125 / 150 / 175$ damage for levels $1, 2, 3$, and $4$. When the spin activates, it triggers the cooldown of $0.7 / 0.65 / 0.6 / 0.55$ seconds, so that attacking Axe does not generate a chance to spin. I was trying to calculate an average damage per second that this skill generates, given that most of the time you will find Axe taking around $5$ attacks per second (average $1.667$ attacks per second from creeps, $3$ creeps per camp), so I figured that would mean the probability of him spinning in any second is $1 - 0.83^5$, so given the damage from earlier, we should expect him to deal $60.61 / 75.76 / 90.91 / 106.07$ damage per second? I got this calculation, but then I realized that I have to factor in the cooldown somewhere, but I have no idea where to start.","In DotA, there is a character called "" Axe "". Every time he is attacked, he has a chance to spin ($17\%$) his blade and deal damage based on what level the skill is, $100 / 125 / 150 / 175$ damage for levels $1, 2, 3$, and $4$. When the spin activates, it triggers the cooldown of $0.7 / 0.65 / 0.6 / 0.55$ seconds, so that attacking Axe does not generate a chance to spin. I was trying to calculate an average damage per second that this skill generates, given that most of the time you will find Axe taking around $5$ attacks per second (average $1.667$ attacks per second from creeps, $3$ creeps per camp), so I figured that would mean the probability of him spinning in any second is $1 - 0.83^5$, so given the damage from earlier, we should expect him to deal $60.61 / 75.76 / 90.91 / 106.07$ damage per second? I got this calculation, but then I realized that I have to factor in the cooldown somewhere, but I have no idea where to start.",,['statistics']
7,"Bounds of Pearson correlation coefficients for (X,Z) knowing those for (X,Y) and (Y,Z)","Bounds of Pearson correlation coefficients for (X,Z) knowing those for (X,Y) and (Y,Z)",,"Assume $X,Y,Z$ are three variables over a set of data (say, a finite set of data to avoid discussions of convergence).  Suppose we know the Pearson correlation coefficient $r_{X,Y}$ and $r_{Y,Z}$ : given these data, what bounds (ideally sharp) can we put on $r_{X,Z}$ ? If I am not mistaken, the question is equivalent to the following: for a positive semidefinite matrix with a diagonal of $1$ , if we know the coefficients $(i,j)$ and $(j,k)$ in the matrix, what (ideally sharp) bounds can we put on the coefficient $(i,k)$ ? Surely this is a classical problem and has been considered before, but I don't know what terms to search for.","Assume are three variables over a set of data (say, a finite set of data to avoid discussions of convergence).  Suppose we know the Pearson correlation coefficient and : given these data, what bounds (ideally sharp) can we put on ? If I am not mistaken, the question is equivalent to the following: for a positive semidefinite matrix with a diagonal of , if we know the coefficients and in the matrix, what (ideally sharp) bounds can we put on the coefficient ? Surely this is a classical problem and has been considered before, but I don't know what terms to search for.","X,Y,Z r_{X,Y} r_{Y,Z} r_{X,Z} 1 (i,j) (j,k) (i,k)","['statistics', 'inequality', 'semidefinite-programming']"
8,Invariant Semi-Bounded Distributions under Hierarchical Transformation,Invariant Semi-Bounded Distributions under Hierarchical Transformation,,"I am interested in determining the set of semi-bounded distributions that remain invariant when they are part of a hierarchical model. For example, let \begin{align}  X\overset{iid}{\sim} p(x; \alpha)\\  \alpha\overset{iid}{\sim} p(\alpha; \beta)\\ \end{align} then \begin{equation}  X\overset{iid}{\sim} p(x; \beta)\\ \end{equation} The formulation of this is: \begin{equation}    p(x, \beta) = \int_0^\infty p(x, \alpha) p(\alpha, \beta) d\alpha \end{equation} I have not found a general way of solving this, but I have found a specific solution: a variation of the log-normal distribution with median $m$ on the natural scale and standard deviation $\sigma$ , specifically when the median has a hierarchical distribution. \begin{equation}    p(x; m, \sigma) = \frac{1}{x \sigma \sqrt{2 \pi}} \exp\left(-\frac{\ln^2\left(\frac{x}{m}\right)}{2\sigma^2}\right) \end{equation} So, this solution provides evidence that indeed such distributions do exist but it irks me that I cannot solve this problem more generally. If the community can assist me in understanding how to solve these types of functional problems, I would really appreciate it. UPDATE 1: Certain RV transformations also exhibit this behavior, namely those \begin{align}  Y &= \alpha X ^ \beta \\  X &\sim LN(m,\sigma) \end{align} which provides the following pdf: \begin{equation} q(y; m, \sigma, \alpha, \beta) = \frac{1}{\sigma |\beta|y\sqrt{2\pi}}\exp\left(-\frac{\left(\ln \alpha + \beta \ln m - \ln y\right)^2}{2\beta^2\sigma^2}\right) \end{equation} which is still lognormal. Finally, the mixture distribution of lognormal PDFs also meet the criteria, so \begin{equation}  r = \sum_{j=1}^J w_jq_j(y; m_j, \sigma_j, \alpha_j, \beta_j) \end{equation} where $0\le w_j \le 1$ and \begin{equation} \sum_{j=1}^J w_j=1 \end{equation} However, these are only expansions from the original insight that a special case of the lognormal distribution is invariant under hierarchical transformation. If it does not show that the lognormal is the only solution. That remains an open question for me. UPDATE 2: (Under Construction) If we assume the following relationship, we can begin to construct a subset of solutions: \begin{equation}  p(x;a) = q(x) r(a) \end{equation} This implies that a parameter $a$ can be factored out of the PDF. Note: this is not an ideal solution as it makes a pretty significant assumption about the structure of a solution, but it is arguably incremental progress. From this, we obtain: \begin{align}  p(x; \beta) &= \int_0^\infty p(x;\alpha)p(\alpha; \beta) d\alpha\\  &= \int_0^\infty q(x) r(\alpha) q(\alpha) r(\beta) d\alpha\\  &= q(x) r(\beta) \int_0^\infty q(\alpha) r(\alpha) d\alpha\\ 1 &= \int_0^\infty q(\alpha) r(\alpha) d\alpha\\ 1 &= \int_0^\infty p(\alpha; \alpha) d\alpha\\ \end{align} The way I interpret this is that the parameter within the PDF must be interchangeable with the independent variable of the PDF. One example of this is when \begin{align}   q(x) &= 2 x e^{-x^2}\\   r(\lambda) &= 2 \lambda e^{-\lambda^2}\\   &\therefore\\   p(x; \lambda) &= 4 x \lambda e^{-x^2-\lambda^2} \end{align} Update 3 (Under Construction): If we build a hierarchical distribution of Pareto distributions where the location parameter is hierarchically distributed, we begin to see a similar pattern to the last hierarchical distribution. Generalizing this, we obtain: \begin{equation}   p(x; \alpha, \beta) = \frac{1}{N}\sum_{n=1}^N \frac{1}{n!}\alpha^{1+n} \beta^\alpha x^{-1-\alpha} \ln^n \left(\frac{x}{\beta}\right) \text{I}_{(\beta, \infty)}(x) \end{equation}","I am interested in determining the set of semi-bounded distributions that remain invariant when they are part of a hierarchical model. For example, let then The formulation of this is: I have not found a general way of solving this, but I have found a specific solution: a variation of the log-normal distribution with median on the natural scale and standard deviation , specifically when the median has a hierarchical distribution. So, this solution provides evidence that indeed such distributions do exist but it irks me that I cannot solve this problem more generally. If the community can assist me in understanding how to solve these types of functional problems, I would really appreciate it. UPDATE 1: Certain RV transformations also exhibit this behavior, namely those which provides the following pdf: which is still lognormal. Finally, the mixture distribution of lognormal PDFs also meet the criteria, so where and However, these are only expansions from the original insight that a special case of the lognormal distribution is invariant under hierarchical transformation. If it does not show that the lognormal is the only solution. That remains an open question for me. UPDATE 2: (Under Construction) If we assume the following relationship, we can begin to construct a subset of solutions: This implies that a parameter can be factored out of the PDF. Note: this is not an ideal solution as it makes a pretty significant assumption about the structure of a solution, but it is arguably incremental progress. From this, we obtain: The way I interpret this is that the parameter within the PDF must be interchangeable with the independent variable of the PDF. One example of this is when Update 3 (Under Construction): If we build a hierarchical distribution of Pareto distributions where the location parameter is hierarchically distributed, we begin to see a similar pattern to the last hierarchical distribution. Generalizing this, we obtain:","\begin{align}
 X\overset{iid}{\sim} p(x; \alpha)\\
 \alpha\overset{iid}{\sim} p(\alpha; \beta)\\
\end{align} \begin{equation}
 X\overset{iid}{\sim} p(x; \beta)\\
\end{equation} \begin{equation}
   p(x, \beta) = \int_0^\infty p(x, \alpha) p(\alpha, \beta) d\alpha
\end{equation} m \sigma \begin{equation}
   p(x; m, \sigma) = \frac{1}{x \sigma \sqrt{2 \pi}} \exp\left(-\frac{\ln^2\left(\frac{x}{m}\right)}{2\sigma^2}\right)
\end{equation} \begin{align}
 Y &= \alpha X ^ \beta \\
 X &\sim LN(m,\sigma)
\end{align} \begin{equation}
q(y; m, \sigma, \alpha, \beta) = \frac{1}{\sigma |\beta|y\sqrt{2\pi}}\exp\left(-\frac{\left(\ln \alpha + \beta \ln m - \ln y\right)^2}{2\beta^2\sigma^2}\right)
\end{equation} \begin{equation}
 r = \sum_{j=1}^J w_jq_j(y; m_j, \sigma_j, \alpha_j, \beta_j)
\end{equation} 0\le w_j \le 1 \begin{equation}
\sum_{j=1}^J w_j=1
\end{equation} \begin{equation}
 p(x;a) = q(x) r(a)
\end{equation} a \begin{align}
 p(x; \beta) &= \int_0^\infty p(x;\alpha)p(\alpha; \beta) d\alpha\\
 &= \int_0^\infty q(x) r(\alpha) q(\alpha) r(\beta) d\alpha\\
 &= q(x) r(\beta) \int_0^\infty q(\alpha) r(\alpha) d\alpha\\
1 &= \int_0^\infty q(\alpha) r(\alpha) d\alpha\\
1 &= \int_0^\infty p(\alpha; \alpha) d\alpha\\
\end{align} \begin{align}
  q(x) &= 2 x e^{-x^2}\\
  r(\lambda) &= 2 \lambda e^{-\lambda^2}\\
  &\therefore\\
  p(x; \lambda) &= 4 x \lambda e^{-x^2-\lambda^2}
\end{align} \begin{equation}
  p(x; \alpha, \beta) = \frac{1}{N}\sum_{n=1}^N \frac{1}{n!}\alpha^{1+n} \beta^\alpha x^{-1-\alpha} \ln^n \left(\frac{x}{\beta}\right) \text{I}_{(\beta, \infty)}(x)
\end{equation}","['statistics', 'probability-distributions']"
9,Sequence of non-extreme digits of power sequence must be uniformely distributed,Sequence of non-extreme digits of power sequence must be uniformely distributed,,"Let $a>1$ be an integer. I wish to analyze the digits of the power sequence $(a^n)_n$ . The behave of extreme digits can be settle to the following: The last $k$ digits of $a^n$ are given by $a^n\pmod{10^k}$ , therefore the sequence of the $k$ last digits is eventually periodic and does not depend on subsequent digits. The first $k$ digits of $a^n$ are given by the number $s = \overline{(s_1s_2\dots s_k)}_{10}$ if, and only if, there is an integer $t$ such that $$\begin{alignat}{3} &10^t(s+1)& &>a^n& & &\ge 10^ts\\\iff &t+\log_{10}(s+1)& &>n\log_{10}(a)& & &\ge t+\log_{10}(s)\\\iff &\log_{10}(s+1)& &>\{n\log_{10}(a)\}~& & &\ge \log_{10}(s) \end{alignat}$$ Now the Equidistribution Theorem says that $(\{n\log_{10}(a)\})_n$ is equidistributed over $[0, 1]$ as long as $\log_{10}(a)$ is irrational (i.e., as long as $a$ is not a power of $10$ ), therefore $s$ occurs as the first set of digits of $a^n$ with probability $\log_{10}(s+1)-\log_{10}(s)$ , or $\displaystyle\log_{10}\left(1+\frac1s\right)$ . This not only says every string of digits occur as the first set of digits of $a^n$ for some $n$ but also says power sequences follows Benford's Law . But what about the digits in between? The study of first and last digits require very specific tools which seem not easy to adapt or combine to adresse this particular case. More precisely, I want to know the limit distribution of the digits which are not a fixed number of positions from the right or from the left of a power sequence. Is the sequence it periodic? Must every digit appear in it? What is the frequency of these digits? In an attempt to develop intuition I recurred to this Python script, which plots the frequency of each digit of $2^n$ in positions $\left\lfloor\dfrac 15m\right\rfloor, \left\lfloor\dfrac 25m\right\rfloor, \left\lfloor\dfrac 35m\right\rfloor, \left\lfloor\dfrac 45m\right\rfloor$ , where $m$ is the total number of digits. import numpy as np import matplotlib.pyplot as plt import sys  # increases limit for integer-string conversion sys.set_int_max_str_digits(0)  freq1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] freq2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] freq3 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] freq4 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  a = 2 # power basis for n in range(10000):     p = str(a**n) # power     m = len(p)    # number of digits     freq1[int(p[int(0.2*m)])]+=1     freq2[int(p[int(0.4*m)])]+=1     freq3[int(p[int(0.6*m)])]+=1     freq4[int(p[int(0.8*m)])]+=1 The code produces the following graphs. The distribution seems to be approaching uniformity. The same behavior was observed for several other basis. This is my conjecture: Conjecture. Given an integer $a>1$ not divisible by $10$ , a digit $d$ and $\lambda\in(0,1)$ , we have $$\lim\frac{\#(\{n:\text{ the }\lfloor\lambda m(a^n)\rfloor\text{th digit of }a^n\text{ is }d\}\cap[1, N])}{N} = \frac1{10}.$$ where $m(x)\equiv\lfloor\log_{10} x\rfloor$ is the amount of digits of $x$ . Of course, I have no reason to believe this only applies to base $10$ .","Let be an integer. I wish to analyze the digits of the power sequence . The behave of extreme digits can be settle to the following: The last digits of are given by , therefore the sequence of the last digits is eventually periodic and does not depend on subsequent digits. The first digits of are given by the number if, and only if, there is an integer such that Now the Equidistribution Theorem says that is equidistributed over as long as is irrational (i.e., as long as is not a power of ), therefore occurs as the first set of digits of with probability , or . This not only says every string of digits occur as the first set of digits of for some but also says power sequences follows Benford's Law . But what about the digits in between? The study of first and last digits require very specific tools which seem not easy to adapt or combine to adresse this particular case. More precisely, I want to know the limit distribution of the digits which are not a fixed number of positions from the right or from the left of a power sequence. Is the sequence it periodic? Must every digit appear in it? What is the frequency of these digits? In an attempt to develop intuition I recurred to this Python script, which plots the frequency of each digit of in positions , where is the total number of digits. import numpy as np import matplotlib.pyplot as plt import sys  # increases limit for integer-string conversion sys.set_int_max_str_digits(0)  freq1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] freq2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] freq3 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] freq4 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  a = 2 # power basis for n in range(10000):     p = str(a**n) # power     m = len(p)    # number of digits     freq1[int(p[int(0.2*m)])]+=1     freq2[int(p[int(0.4*m)])]+=1     freq3[int(p[int(0.6*m)])]+=1     freq4[int(p[int(0.8*m)])]+=1 The code produces the following graphs. The distribution seems to be approaching uniformity. The same behavior was observed for several other basis. This is my conjecture: Conjecture. Given an integer not divisible by , a digit and , we have where is the amount of digits of . Of course, I have no reason to believe this only applies to base .","a>1 (a^n)_n k a^n a^n\pmod{10^k} k k a^n s = \overline{(s_1s_2\dots s_k)}_{10} t \begin{alignat}{3}
&10^t(s+1)& &>a^n& & &\ge 10^ts\\\iff
&t+\log_{10}(s+1)& &>n\log_{10}(a)& & &\ge t+\log_{10}(s)\\\iff
&\log_{10}(s+1)& &>\{n\log_{10}(a)\}~& & &\ge \log_{10}(s)
\end{alignat} (\{n\log_{10}(a)\})_n [0, 1] \log_{10}(a) a 10 s a^n \log_{10}(s+1)-\log_{10}(s) \displaystyle\log_{10}\left(1+\frac1s\right) a^n n 2^n \left\lfloor\dfrac 15m\right\rfloor, \left\lfloor\dfrac 25m\right\rfloor, \left\lfloor\dfrac 35m\right\rfloor, \left\lfloor\dfrac 45m\right\rfloor m a>1 10 d \lambda\in(0,1) \lim\frac{\#(\{n:\text{ the }\lfloor\lambda m(a^n)\rfloor\text{th digit of }a^n\text{ is }d\}\cap[1, N])}{N} = \frac1{10}. m(x)\equiv\lfloor\log_{10} x\rfloor x 10","['number-theory', 'statistics', 'probability-distributions', 'analytic-number-theory']"
10,Trying to adapt an Elo-ranking system for an asymetric multiplayer game,Trying to adapt an Elo-ranking system for an asymetric multiplayer game,,"My friends and I have used an Elo-Ranking system to track our relative strength in the social deduction game ""Secret Hitler"". So far, the formula we used was a very basic adaptation of the original Elo-formula that uses a lot of assumptions and thus gives unfair results. First, I will describe the relevant features of the game to those unfamiliar with it. Second, I will show our old formula and describe its shortcomings. Third and last, I will show the draft for our new formula. I will outline some potential problems with it that we have noticed and ask for your help in spotting any that we have overlooked. The game is played with 5 to 10 people, seperated into 2 teams. The teams are of unequal, but predetermined size. (An 8-player game will always have teams of 3 vs 5 for example.) The smaller team (""red"") has a smaller chance of winning than the larger team (""blue""). (In our data it's ~40%/60%.) We record wins (1) and losses (0) for each player and can infer the team they were on from that (3 wins and 5 losses in a game must mean team red won). Old formula: https://i.sstatic.net/tIxrP.png $E_n$ is your new Elo. $E_a$ is your old Elo. $k$ is a constant that is the max. delta between $E_n$ and $E_a$ per game. $Er$ is your personal result (1 or 0, draws are impossible in this game). $E_G$ is the opposite team's average Elo. $E_T$ is your own team's average Elo (including your personal Elo). $S$ is the stepsize. (A value of 40 means that if your Elo is 40 points higher than the opponent's it means that your expected value is one order of magnitude higher than your opponents.) This makes a lot of assumptions, here are a few: Your likelihood of being on either team matches the theoretical distribution. You are just as good at playing on team red than you are at playing on team blue. We also combine your own Elo and the overall team average with a 50/50 distribution, without considering cases like a pro playing with a team of noobs, where the pro's actions are more responsible for overall team performance (in our experience). To eliminate some of these shortcomings, here is our new formula: https://i.sstatic.net/ZXHUQ.png (I am sorry for the links, this is my first question.) $F$ is the general winrate of the team you were on (red or blue). $A_E$ is your own contribution to the outcome relative to the rest of your team. $A_T$ is your teams contribution to the outcome relative to you. All of these values are extracted from the raw results with some very inefficient and 'hacky' excel-code, but that is the topic of another post in another forum. Some thoughts on the new formula: For some of these values, we can go two different routes, the comparative and the personal. For your faction's winrate for example we can either use the overall average (about 40/60) or take your own results into consideration: Maybe you are really good at playing on team red, bringing your average closer to 50/50. Shouldn't you then be rewarded for showing personal progress when you ""unexpectedly"" win a blue-team game? The latter has two drawbacks: While it gives you an Elo that more accurately tracks your personal progress, comparing these values between players is not fair. It also means that you need to have played a large number of games for your own values to become statistically relevant. In general, we 'officially' give players a ranking after their 10th game and gradually fade out the overall averages from the first to the 10th game, but that value was chosen arbitrarily without being rooted in data. Our current solution is to calculate two Elo values for each player: A personal Elo that is a (weak) indicator of potential and a comparable Elo that determines the ranking. Something that we are not able to consider at all, due to the too-small number of games played in total, is whether a player is better at playing games of a certain size, i.e. 7-player games. Have we overlooked something in our calculation, maybe another asymetry in the game that we are not aware of? Have we made a mistake in transfering our thoughts to a formula? Do you have a good idea how to incorporate some of our considerations that have not been implemented yet?","My friends and I have used an Elo-Ranking system to track our relative strength in the social deduction game ""Secret Hitler"". So far, the formula we used was a very basic adaptation of the original Elo-formula that uses a lot of assumptions and thus gives unfair results. First, I will describe the relevant features of the game to those unfamiliar with it. Second, I will show our old formula and describe its shortcomings. Third and last, I will show the draft for our new formula. I will outline some potential problems with it that we have noticed and ask for your help in spotting any that we have overlooked. The game is played with 5 to 10 people, seperated into 2 teams. The teams are of unequal, but predetermined size. (An 8-player game will always have teams of 3 vs 5 for example.) The smaller team (""red"") has a smaller chance of winning than the larger team (""blue""). (In our data it's ~40%/60%.) We record wins (1) and losses (0) for each player and can infer the team they were on from that (3 wins and 5 losses in a game must mean team red won). Old formula: https://i.sstatic.net/tIxrP.png is your new Elo. is your old Elo. is a constant that is the max. delta between and per game. is your personal result (1 or 0, draws are impossible in this game). is the opposite team's average Elo. is your own team's average Elo (including your personal Elo). is the stepsize. (A value of 40 means that if your Elo is 40 points higher than the opponent's it means that your expected value is one order of magnitude higher than your opponents.) This makes a lot of assumptions, here are a few: Your likelihood of being on either team matches the theoretical distribution. You are just as good at playing on team red than you are at playing on team blue. We also combine your own Elo and the overall team average with a 50/50 distribution, without considering cases like a pro playing with a team of noobs, where the pro's actions are more responsible for overall team performance (in our experience). To eliminate some of these shortcomings, here is our new formula: https://i.sstatic.net/ZXHUQ.png (I am sorry for the links, this is my first question.) is the general winrate of the team you were on (red or blue). is your own contribution to the outcome relative to the rest of your team. is your teams contribution to the outcome relative to you. All of these values are extracted from the raw results with some very inefficient and 'hacky' excel-code, but that is the topic of another post in another forum. Some thoughts on the new formula: For some of these values, we can go two different routes, the comparative and the personal. For your faction's winrate for example we can either use the overall average (about 40/60) or take your own results into consideration: Maybe you are really good at playing on team red, bringing your average closer to 50/50. Shouldn't you then be rewarded for showing personal progress when you ""unexpectedly"" win a blue-team game? The latter has two drawbacks: While it gives you an Elo that more accurately tracks your personal progress, comparing these values between players is not fair. It also means that you need to have played a large number of games for your own values to become statistically relevant. In general, we 'officially' give players a ranking after their 10th game and gradually fade out the overall averages from the first to the 10th game, but that value was chosen arbitrarily without being rooted in data. Our current solution is to calculate two Elo values for each player: A personal Elo that is a (weak) indicator of potential and a comparable Elo that determines the ranking. Something that we are not able to consider at all, due to the too-small number of games played in total, is whether a player is better at playing games of a certain size, i.e. 7-player games. Have we overlooked something in our calculation, maybe another asymetry in the game that we are not aware of? Have we made a mistake in transfering our thoughts to a formula? Do you have a good idea how to incorporate some of our considerations that have not been implemented yet?",E_n E_a k E_n E_a Er E_G E_T S F A_E A_T,"['probability', 'statistics']"
11,A self-proof of Vapnik - Chervonenkis theorem,A self-proof of Vapnik - Chervonenkis theorem,,"Theorem : For every $\varepsilon >0$ , with the probability greater than $1-\varepsilon$ \begin{align*}     R_p(\hat{g}_{n,\mathcal{G}}) - R_{p}(g^*_{p,\mathcal{G}}) \le 2 \sqrt{\dfrac{2V_{\mathcal{G}}(2n) \ln(4(2n+1)\varepsilon^{-1}) }{n}} \end{align*} where $V_{\mathcal{G}}(N) = \sup_{\mathbb{X_N} \in \mathcal{X}^N} V_{\mathcal{G}} (\mathbb{X_N})$ with $\mathbb{X_N} = \left\{x_1,x_2,\ldots x_N\right\}$ . The notation $V_{\mathcal{G}}$ denotes for the VC-dimension of $\mathcal{G}$ . My proof : (This proof was confirmed to be wrong by my lecturer. He pointed out the mistake was at the union bound after (1.1). I wonder if you could help me fix this point by using Rademacher complexity) Before going to the proof, let us recall some definitions, and lemmas we are going to use. Lemma (Sauer). For all $S = \left\{x_1,\ldots,x_N\right\} = \mathbb{X_N}$ , we have \begin{align*}     \vert T_{\mathcal{G}}(S)\vert &\le \sum_{k=0}^{V_{\mathcal{G}}(\mathbb{X_N})} C^k_N\\     & \le \begin{cases}         (N+1)^{V_{\mathcal{G}}(\mathbb{X_N})} & \text{, if } N> V_{\mathcal{G}}(\mathbb{X_N})\\         2^N & \text{, if } N \le V_{\mathcal{G}}(\mathbb{X}_N)     \end{cases} \end{align*} Lemma: (Symmetrization). Let $l$ be the loss function that \begin{align*}     a \le l(y,y') \le a+1,\ \forall y,y' \in \mathcal{Y}. \end{align*} Let $\mathcal{D'}_n = (x'_i,y'_i),\ i=\overline{1,n}$ be a sample independent of $\mathcal{D}_n$ with the same law. Then for all $t \ge \sqrt{\dfrac{2}{n}}$ \begin{align*}     \mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t\right) \le 2\mathbb{P}\left(\sup_{g \in \mathcal{G}}\left\{\hat{R}_n(g) - \hat{R}'_n(g)\right\} > \dfrac{t}{2}\right), \end{align*} where $\hat{R}_n(g):=\dfrac{1}{n}\sum_{i=1}^n l(y_i,g(x_i))$ , $\hat{R}'_n(g):=\dfrac{1}{n}\sum_{i=1}^n l(y'_i,g(x'_i))$ . Back to the main proof. Let $nt^2 = 2V_{\mathcal{G}}(2n)\ln\left(4(2n+1)\varepsilon^{-1}\right)$ . Then, we would like to prove that \begin{align*} \mathbb{P}\left(R_p(\hat{g}_{n,\mathcal{G}}) - R_p(g^*_{p,\mathcal{G}}) > 2t \right) \le \varepsilon. \tag{*} \end{align*} Firstly, we use the following fact \begin{align*} R_p(\hat{g}_{n,\mathcal{G}}) - R_p(g^*_{p,\mathcal{G}}) \le 2\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert, \end{align*} and obtain that \begin{align*} \mathbb{P}\left(R_p(\hat{g}_{n,\mathcal{G}}) - R_p(g^*_{p,\mathcal{G}}) > 2t \right) \le \mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t \right). \end{align*} Next, by using the symmetrization lemma, we have \begin{align*} \mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t \right) \le 2 \mathbb{P}\left(\sup_{g \in \mathcal{G}}\left\vert \hat{R}_n(g) - \hat{R}'_n(g)\right\vert > \dfrac{t}{2} \right). \tag{1.1} \end{align*} Let us consider the trace of $\mathcal{G}$ on $(\mathbb{X}_n,\mathbb{X}'_n)$ , denotes $T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n)$ . Each element of $T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n)$ is a sample $\left\{x_{j_1},x_{j_2},\ldots,x_{j_K}\right\}$ with $K \le 2n$ . To each of these elements, we can associate a prediction $g \in \mathcal{G}$ such that $g(x_{j_k})$ = 1, $\forall k \in [K]$ . We just built a bijection between $T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n)$ and a subset of $\mathcal{G}$ , denotes $\hat{\mathcal{G}}_n$ . With this notation, we have $$\vert \hat{\mathcal{G}}_n\vert = T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n) \le (2n+1)^{V_{\mathcal{G}}(2n)   }.$$ Therefore, we can derive from (1.1) that \begin{align*} \mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t \right) &\le 2 \mathbb{P}\left(\sup_{g \in \mathcal{G}}\left\vert \hat{R}_n(g) - \hat{R}'_n(g)\right\vert > \dfrac{t}{2} \right)\\ &=2\mathbb{P}\left(\sup_{g \in \hat{\mathcal{G}}_n}\left\{\hat{R}_n(g) - \hat{R}'_n(g)\right\}> t/2\right)\\ &\le 2 \sum_{g \in \hat{\mathcal{G}}_n} \mathbb{P}\left(\hat{R}_n(g) - \hat{R}'_n(g)> t/2   \right) \tag{union bound}\\ &\le 2\vert \hat{\mathcal{G}_n}\vert \max_{g \in \mathcal{G}} \mathbb{P}\left(\hat{R}_n(g) - \hat{R}'_n(g) > t/2 \right)\\ & \le 2(2n+1)^{V_\mathcal{G}(2n)} \max_{g \in \mathcal{G}} \mathbb{P}\left(\hat{R}_n(g) - \hat{R}'_n(g) > t/2 \right) \end{align*} By substituting $\hat{R}_n(g) = \dfrac{1}{n}\mathbb{1}_{g(X_i)\neq Y_i}$ and using the Hoeffding inequality, we obtain the result in theorem.","Theorem : For every , with the probability greater than where with . The notation denotes for the VC-dimension of . My proof : (This proof was confirmed to be wrong by my lecturer. He pointed out the mistake was at the union bound after (1.1). I wonder if you could help me fix this point by using Rademacher complexity) Before going to the proof, let us recall some definitions, and lemmas we are going to use. Lemma (Sauer). For all , we have Lemma: (Symmetrization). Let be the loss function that Let be a sample independent of with the same law. Then for all where , . Back to the main proof. Let . Then, we would like to prove that Firstly, we use the following fact and obtain that Next, by using the symmetrization lemma, we have Let us consider the trace of on , denotes . Each element of is a sample with . To each of these elements, we can associate a prediction such that = 1, . We just built a bijection between and a subset of , denotes . With this notation, we have Therefore, we can derive from (1.1) that By substituting and using the Hoeffding inequality, we obtain the result in theorem.","\varepsilon >0 1-\varepsilon \begin{align*}
    R_p(\hat{g}_{n,\mathcal{G}}) - R_{p}(g^*_{p,\mathcal{G}}) \le 2 \sqrt{\dfrac{2V_{\mathcal{G}}(2n) \ln(4(2n+1)\varepsilon^{-1}) }{n}}
\end{align*} V_{\mathcal{G}}(N) = \sup_{\mathbb{X_N} \in \mathcal{X}^N} V_{\mathcal{G}} (\mathbb{X_N}) \mathbb{X_N} = \left\{x_1,x_2,\ldots x_N\right\} V_{\mathcal{G}} \mathcal{G} S = \left\{x_1,\ldots,x_N\right\} = \mathbb{X_N} \begin{align*}
    \vert T_{\mathcal{G}}(S)\vert &\le \sum_{k=0}^{V_{\mathcal{G}}(\mathbb{X_N})} C^k_N\\
    & \le \begin{cases}
        (N+1)^{V_{\mathcal{G}}(\mathbb{X_N})} & \text{, if } N> V_{\mathcal{G}}(\mathbb{X_N})\\
        2^N & \text{, if } N \le V_{\mathcal{G}}(\mathbb{X}_N)
    \end{cases}
\end{align*} l \begin{align*}
    a \le l(y,y') \le a+1,\ \forall y,y' \in \mathcal{Y}.
\end{align*} \mathcal{D'}_n = (x'_i,y'_i),\ i=\overline{1,n} \mathcal{D}_n t \ge \sqrt{\dfrac{2}{n}} \begin{align*}
    \mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t\right) \le 2\mathbb{P}\left(\sup_{g \in \mathcal{G}}\left\{\hat{R}_n(g) - \hat{R}'_n(g)\right\} > \dfrac{t}{2}\right),
\end{align*} \hat{R}_n(g):=\dfrac{1}{n}\sum_{i=1}^n l(y_i,g(x_i)) \hat{R}'_n(g):=\dfrac{1}{n}\sum_{i=1}^n l(y'_i,g(x'_i)) nt^2 = 2V_{\mathcal{G}}(2n)\ln\left(4(2n+1)\varepsilon^{-1}\right) \begin{align*}
\mathbb{P}\left(R_p(\hat{g}_{n,\mathcal{G}}) - R_p(g^*_{p,\mathcal{G}}) > 2t \right) \le \varepsilon. \tag{*}
\end{align*} \begin{align*}
R_p(\hat{g}_{n,\mathcal{G}}) - R_p(g^*_{p,\mathcal{G}}) \le 2\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert,
\end{align*} \begin{align*}
\mathbb{P}\left(R_p(\hat{g}_{n,\mathcal{G}}) - R_p(g^*_{p,\mathcal{G}}) > 2t \right) \le \mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t \right).
\end{align*} \begin{align*}
\mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t \right) \le 2 \mathbb{P}\left(\sup_{g \in \mathcal{G}}\left\vert \hat{R}_n(g) - \hat{R}'_n(g)\right\vert > \dfrac{t}{2} \right). \tag{1.1}
\end{align*} \mathcal{G} (\mathbb{X}_n,\mathbb{X}'_n) T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n) T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n) \left\{x_{j_1},x_{j_2},\ldots,x_{j_K}\right\} K \le 2n g \in \mathcal{G} g(x_{j_k}) \forall k \in [K] T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n) \mathcal{G} \hat{\mathcal{G}}_n \vert \hat{\mathcal{G}}_n\vert = T_{\mathcal{G}}(\mathbb{X}_n,\mathbb{X}'_n) \le (2n+1)^{V_{\mathcal{G}}(2n) 
 }. \begin{align*}
\mathbb{P}\left(\sup_{g \in \mathcal{G}}\vert \hat{R}_n(g) - R_p(g)\vert > t \right) &\le 2 \mathbb{P}\left(\sup_{g \in \mathcal{G}}\left\vert \hat{R}_n(g) - \hat{R}'_n(g)\right\vert > \dfrac{t}{2} \right)\\
&=2\mathbb{P}\left(\sup_{g \in \hat{\mathcal{G}}_n}\left\{\hat{R}_n(g) - \hat{R}'_n(g)\right\}> t/2\right)\\
&\le 2 \sum_{g \in \hat{\mathcal{G}}_n} \mathbb{P}\left(\hat{R}_n(g) - \hat{R}'_n(g)> t/2   \right) \tag{union bound}\\
&\le 2\vert \hat{\mathcal{G}_n}\vert \max_{g \in \mathcal{G}} \mathbb{P}\left(\hat{R}_n(g) - \hat{R}'_n(g) > t/2 \right)\\
& \le 2(2n+1)^{V_\mathcal{G}(2n)} \max_{g \in \mathcal{G}} \mathbb{P}\left(\hat{R}_n(g) - \hat{R}'_n(g) > t/2 \right)
\end{align*} \hat{R}_n(g) = \dfrac{1}{n}\mathbb{1}_{g(X_i)\neq Y_i}","['probability', 'statistics', 'inequality', 'probability-distributions', 'machine-learning']"
12,Sqrt LASSO vs LASSO,Sqrt LASSO vs LASSO,,"In the paper Square Root Lasso: Pivotal Recovery of Sparse Signals via Conic Programming they talk about Sqrt-LASSO which is simply just trying to minimize $\|Ax-b\|_2 + \lambda\|x\|_1$ rather than the regular LASSO $\|Ax-b\|_2^2 + \lambda\|x\|_1$ . Can anyone point out the theoretical differences between the two in terms of whether one is more robust to outliers, do we still have sparsity, etc? What about in practice, do these implementations have much of a difference?","In the paper Square Root Lasso: Pivotal Recovery of Sparse Signals via Conic Programming they talk about Sqrt-LASSO which is simply just trying to minimize rather than the regular LASSO . Can anyone point out the theoretical differences between the two in terms of whether one is more robust to outliers, do we still have sparsity, etc? What about in practice, do these implementations have much of a difference?",\|Ax-b\|_2 + \lambda\|x\|_1 \|Ax-b\|_2^2 + \lambda\|x\|_1,"['statistics', 'optimization', 'regression', 'linear-regression', 'regression-analysis']"
13,What is the intuition behind medians (and quartiles) being defined as the value of the $(n+1)/p$ th observation?,What is the intuition behind medians (and quartiles) being defined as the value of the  th observation?,(n+1)/p,"When calculating the median of an un-grouped distribution, we take the $(n+1)/2$ the value. For quartiles it's $\text{I} \cdot (n+1)/4$ . For deciles it's $\text{I} \cdot (n+1)/10$ . What is the intuition behind the $1$ added to $n$ ? More generally, why do we find the midpoint of numbers $1$ to $n$ at $(n+1)/2$ ?","When calculating the median of an un-grouped distribution, we take the the value. For quartiles it's . For deciles it's . What is the intuition behind the added to ? More generally, why do we find the midpoint of numbers to at ?",(n+1)/2 \text{I} \cdot (n+1)/4 \text{I} \cdot (n+1)/10 1 n 1 n (n+1)/2,"['statistics', 'median']"
14,"Explanation for standard deviation rule-of-thumb, $s\approx \text{range}/4$","Explanation for standard deviation rule-of-thumb,",s\approx \text{range}/4,"In several introductory statistics books, for a list of data $X = \{x_1,\ldots,x_n\}$ , I have frequently seen the following rule-of-thumb: $$ s \approx \frac{\text{range}(X)}{4} = \frac{\max(X)-\min(X)}{4} $$ I have thought about this a little and can offer my heuristics, but I am curious if this (obviously very crass) rule-of-thumb can be put on slightly more stable mathematical footing. Suppose the data are normally distributed. Then approximately $95\%$ of the data should be within two standard deviations of the mean, in which case $4s \approx \text{range}(X)$ is plausible. For a continuous uniform distribution on $(a,b)$ , the exact value is $s = (b-a)/\sqrt{12}$ , compared to the approximation $(b-a)/4$ . Since $1/\sqrt{12}\approx 0.2887$ , the relative error is about $15.47\%$ ; not great, not terrible. This value is in the same ballpark for the discrete normal distribution. Looking at another distribution, the Poisson distribution with mean $\mu>0$ and standard deviation $\sqrt{\mu}$ , this amounts to summing over values $k$ with $|\mu-k|\le 2 \sqrt{\mu}$ ; this becomes weird because of rounding since $k$ can only take integer values, but a plot produced about $0.92$ as a minimum value for this sum. The book did use this rule-of-thumb as a way to approximate the range of a population given a sample (of which the range and standard deviation can be calculated), but I think the reason for the heuristic in the first place is to provide an alternative to students who do not have the tech or computational skills to find the exact value of $s$ in the first place. Any further justification of this heuristic would be appreciated.","In several introductory statistics books, for a list of data , I have frequently seen the following rule-of-thumb: I have thought about this a little and can offer my heuristics, but I am curious if this (obviously very crass) rule-of-thumb can be put on slightly more stable mathematical footing. Suppose the data are normally distributed. Then approximately of the data should be within two standard deviations of the mean, in which case is plausible. For a continuous uniform distribution on , the exact value is , compared to the approximation . Since , the relative error is about ; not great, not terrible. This value is in the same ballpark for the discrete normal distribution. Looking at another distribution, the Poisson distribution with mean and standard deviation , this amounts to summing over values with ; this becomes weird because of rounding since can only take integer values, but a plot produced about as a minimum value for this sum. The book did use this rule-of-thumb as a way to approximate the range of a population given a sample (of which the range and standard deviation can be calculated), but I think the reason for the heuristic in the first place is to provide an alternative to students who do not have the tech or computational skills to find the exact value of in the first place. Any further justification of this heuristic would be appreciated.","X = \{x_1,\ldots,x_n\} 
s \approx \frac{\text{range}(X)}{4} = \frac{\max(X)-\min(X)}{4}
 95\% 4s \approx \text{range}(X) (a,b) s = (b-a)/\sqrt{12} (b-a)/4 1/\sqrt{12}\approx 0.2887 15.47\% \mu>0 \sqrt{\mu} k |\mu-k|\le 2 \sqrt{\mu} k 0.92 s","['statistics', 'approximation', 'standard-deviation']"
15,Turning a Sum Into an Integral,Turning a Sum Into an Integral,,"I came up with a measure of dispersion for a sequence of $n$ numbers $(x_i)$ , namely $\sqrt{\sum^n_{i=1}x^2_i - \sum^n_{j=2}\sum^{j-1}_{i=1}\frac{2x_i x_j}{n-1}}$ .  Is there a way to generalize this sum by turning it into an integral for probability distribution functions?","I came up with a measure of dispersion for a sequence of numbers , namely .  Is there a way to generalize this sum by turning it into an integral for probability distribution functions?",n (x_i) \sqrt{\sum^n_{i=1}x^2_i - \sum^n_{j=2}\sum^{j-1}_{i=1}\frac{2x_i x_j}{n-1}},"['real-analysis', 'statistics', 'probability-distributions', 'random-variables', 'probability-limit-theorems']"
16,Show that the least square estimator $\hat \beta$ for $\beta$ can be written as $\hat \beta=V D^{−1}U^TY$.,Show that the least square estimator  for  can be written as .,\hat \beta \beta \hat \beta=V D^{−1}U^TY,"Consider a linear model $Y=X\beta+\varepsilon$ , where $Y,\varepsilon \in \Bbb R^n,\beta\in \Bbb R^p$ and with model matrix $X \in \Bbb R^{n×p}$ of full rank, $n, p\in  \Bbb N$ with $1\lt p\le n$ . Moreover consider the singular value decomposition of the model matrix X, i.e. $$\DeclareMathOperator{\diag}{diag} X=UDV^T, $$ where $U$ and $D$ is $n\times p$ and a $p\times p$ diagonal matrices and $V$ is a $p\times p$ matrix. Notes The diagonal elements of $D=\diag(\lambda_1,\lambda_2,\dots,\lambda_p)$ are the positive square roots of the eigenvalues of $X^TX$ or $XX^T$ and $U$ and $V$ contain normalized eigenvectors of $XX^T$ and $X^TX$ respectively, i.e. $ U^TU=I,V^TV=I.$ We moreover we assume that $\lambda_1\ge\lambda_2\ge \ldots\ge\lambda_p$ . Problem . Show that the least square estimator $\hat \beta$ for $\beta$ can be written as $\hat \beta=V D^{−1}U^TY$ . An alternative estimator for $\beta$ is given by $\widetilde\beta:=V D^{−1}_* U^TY$ , where $D^{−1}_*=\diag(\lambda^{-1}_1,\lambda^{-1}_2,\ldots,\lambda^{-1}_k,0,\ldots,0)$ for some $1\le k \lt p$ . ( Note :  such an estimator can e.g. be useful if some covariates are highly correlated and $X^TX$ is close to singular.) Answer : to show that the least square estimator $\hat \beta$ equals $V D^{−1}U^TY$ , we start with the linear model $Y=X\beta+\varepsilon$ Using the singular value decomposition (SVD) of the model matrix $X$ , $X=UDV^T$ we can rewrite the model as $$ Y=(UDV^T)\beta+\varepsilon. $$ Multiplying both sides by the transpose of $U$ , we get, $$ U^TY=(U^TUDV^T)\beta+U^T\varepsilon. $$ Since $U^TU = I$ i.e. it is the identity matrix, the term $(U^TUDV^T)$ simplifies to $DV^T\beta$ . Therefore, the equation becomes $$ U^TY=(DV^T)\beta+U^T\varepsilon $$ To solve for $\beta$ , we multiply both sides by $V$ and get $$ VU^TY = V(DV^T)\beta+ VU^T\varepsilon. $$ Simplifying further, since $V^TV = I$ , we have $$ VU^TY = D \beta+ VU^T\varepsilon. $$ Subtracting $VU^T\varepsilon$ from both sides, we get $$ VU^TY - VU^T\varepsilon = D\beta. $$ Combining the terms on the left side, we have $$ V(U^TY - U^T\varepsilon) = D\beta. $$ Since $E$ is the vector of errors, $U^T\varepsilon = 0$ , so the equation simplifies to $VU^TY = D\beta$ . Therefore, the least squares estimator $\beta$ equals $VD^{-1}U^TY$ . My question . Am I doing it correctly? I just need a solution verification.","Consider a linear model , where and with model matrix of full rank, with . Moreover consider the singular value decomposition of the model matrix X, i.e. where and is and a diagonal matrices and is a matrix. Notes The diagonal elements of are the positive square roots of the eigenvalues of or and and contain normalized eigenvectors of and respectively, i.e. We moreover we assume that . Problem . Show that the least square estimator for can be written as . An alternative estimator for is given by , where for some . ( Note :  such an estimator can e.g. be useful if some covariates are highly correlated and is close to singular.) Answer : to show that the least square estimator equals , we start with the linear model Using the singular value decomposition (SVD) of the model matrix , we can rewrite the model as Multiplying both sides by the transpose of , we get, Since i.e. it is the identity matrix, the term simplifies to . Therefore, the equation becomes To solve for , we multiply both sides by and get Simplifying further, since , we have Subtracting from both sides, we get Combining the terms on the left side, we have Since is the vector of errors, , so the equation simplifies to . Therefore, the least squares estimator equals . My question . Am I doing it correctly? I just need a solution verification.","Y=X\beta+\varepsilon Y,\varepsilon \in \Bbb R^n,\beta\in \Bbb R^p X \in \Bbb R^{n×p} n, p\in 
\Bbb N 1\lt p\le n \DeclareMathOperator{\diag}{diag}
X=UDV^T,
 U D n\times p p\times p V p\times p D=\diag(\lambda_1,\lambda_2,\dots,\lambda_p) X^TX XX^T U V XX^T X^TX  U^TU=I,V^TV=I. \lambda_1\ge\lambda_2\ge \ldots\ge\lambda_p \hat \beta \beta \hat \beta=V D^{−1}U^TY \beta \widetilde\beta:=V D^{−1}_* U^TY D^{−1}_*=\diag(\lambda^{-1}_1,\lambda^{-1}_2,\ldots,\lambda^{-1}_k,0,\ldots,0) 1\le k \lt p X^TX \hat \beta V D^{−1}U^TY Y=X\beta+\varepsilon X X=UDV^T 
Y=(UDV^T)\beta+\varepsilon.
 U 
U^TY=(U^TUDV^T)\beta+U^T\varepsilon.
 U^TU = I (U^TUDV^T) DV^T\beta 
U^TY=(DV^T)\beta+U^T\varepsilon
 \beta V 
VU^TY = V(DV^T)\beta+ VU^T\varepsilon.
 V^TV = I 
VU^TY = D \beta+ VU^T\varepsilon.
 VU^T\varepsilon 
VU^TY - VU^T\varepsilon = D\beta.
 
V(U^TY - U^T\varepsilon) = D\beta.
 E U^T\varepsilon = 0 VU^TY = D\beta \beta VD^{-1}U^TY","['statistics', 'solution-verification', 'linear-regression']"
17,Why is an online poker article claiming that Straights happen more often than Three of a Kinds in a short deck?,Why is an online poker article claiming that Straights happen more often than Three of a Kinds in a short deck?,,"Six Plus Hold'em is a variant of Texas Hold'em in which a short deck is used. A short deck is a deck in which all cards from 2 to 5 are removed from a standard 52-card deck, leaving only 36 cards. Due to the change in deck composition the frequency in which hands appear are also different, which is why hand rankings are different from standard poker. An official World Series of Poker event held a few months ago swapped Full House and Flush from their usual hierarchy, leaving the others untouched. However a Wikipedia article about the variant claims the follwing about hand rankings: Flush ranks higher than full house. In theory, three-of-a-kind ranks higher than a straight as the probability of achieving three-of-a-kind is lower than a straight in short-deck, however recent games have been ranking straight higher than three-of-a-kind which has become standard. I was unconvinced that tournaments were arbitrarily defying mathematics so I decided to do the numbers myself. Standard Deck A. Flush - Pick $5$ out of the $13$ ranks: $\binom{13}{5}=1287$ .   - Pick a suit: $4$ .   - Total: $1287\times 4=5148$ .   - This figure includes Straight Flushes. B. Straight - Pick $1$ of $10$ rank combinations that constitute a Straight: A-5, 2-6, 3-7, ..., 10-A.   - Assign a suit to each card: $4^{5}=1024$ .   - Total: $10\times 1024=10240$ .   - This figure includes $10\times 4=40$ Straight Flushes. C. Three of a Kind 1) Only a Three of a Kind and nothing higher       - Pick one rank to be the Three of a Kind: $13$ .       - Pick two other suits: $\binom{12}{2}=66$ .       - Pick three out of four suits for the Three of a Kind: $\binom{4}{3}=4$ .       - Assign a suit to the other two cards: $4^{2}=16$ .       - Total: $13\times 66\times 4\times 16=54912$ .   2) Full House       - Pick the rank to be the Three of a Kind: $13$ .       - Pick another rank to be the Pair: $12$ .       - Pick three out of four suits for the Three of a Kind: $4$ .       - Pick two out of four suits for the Pair: $\binom{4}{2}=6$ .       - Total: $13\times 12\times 4\times 6=3744$ .   3) Four of a Kind       - Pick the rank to be the Four of a Kind: $13$ .       - Pick another rank to be the lone card: $12$ .       - Pick a suit for the lone card: $4$ .       -Total: $13\times 12\times 4=624$ . Short Deck A. Flush - Pick $5$ out of $9$ ranks: $\binom{9}{5}=126$ .   - Pick a suit: $4$ .   - Total: $126\times 4=504$ .   - Includes Straight Flushes. B. Straight - Pick $1$ of $6$ combinations: A-9, 6-10, 7-J, ..., 10-A.   - Assign a suit to each card: $4^{5}=1024$ .   - Total: $6\times 1024=6144$ .   - This figure includes $6\times 4=24$ Straight Flushes. C. Three of a Kind 1) Only a Three of a Kind and nothing higher       - Pick one rank to be the Three of a Kind: $9$ .       - Pick two other suits: $\binom{8}{2}=28$ .       - Pick three out of four suits for the Three of a Kind: $\binom{4}{3}=4$ .       - Assign a suit to the other two cards: $4^{2}=16$ .       - Total: $9\times 28\times 4\times 16=16128$ .   2) Full House       - Pick the rank to be the Three of a Kind: $9$ .       - Pick another rank to be the Pair: $8$ .       - Pick three out of four suits for the Three of a Kind: $4$ .       - Pick two out of four suits for the Pair: $\binom{4}{2}=6$ .       - Total: $9\times 8\times 4\times 6=1728$ .   3) Four of a Kind       - Pick the rank to be the Four of a Kind: $9$ .       - Pick another rank to be the lone card: $8$ .       - Pick a suit for the lone card: $4$ .       - Total: $9\times 8\times 4=288$ . To summarize: Full House vs Flush(Straight Flush) Standard Deck 3744 < 5148(40) Short Deck 1728 > 504(24) Straight(Straight Flush) vs Three of a Kind(Full House/Quads) Standard Deck 10240(40) < 59280(3744/624) Short Deck 6144(24) < 18144(1728/288) As you can see the frequency of Full Houses compared to Flushes flips but Straights compared to Three of a Kinds does not, regardless of whether hands that also belong to a higher rank are deducted or not. Thus the hand ranking that WSOP used is mathematically correct. I read the reference of the Wikipedia article which claimed as follows: In Six Plus straights appear in abundance, so much so, that they rank lower than three-of-a-kind (but still higher than two pair). The article does not dive into the numbers so I have no idea about their reasoning. What method of measuring frequency could have led to this claim? Are there any errors in my logic or calculations?","Six Plus Hold'em is a variant of Texas Hold'em in which a short deck is used. A short deck is a deck in which all cards from 2 to 5 are removed from a standard 52-card deck, leaving only 36 cards. Due to the change in deck composition the frequency in which hands appear are also different, which is why hand rankings are different from standard poker. An official World Series of Poker event held a few months ago swapped Full House and Flush from their usual hierarchy, leaving the others untouched. However a Wikipedia article about the variant claims the follwing about hand rankings: Flush ranks higher than full house. In theory, three-of-a-kind ranks higher than a straight as the probability of achieving three-of-a-kind is lower than a straight in short-deck, however recent games have been ranking straight higher than three-of-a-kind which has become standard. I was unconvinced that tournaments were arbitrarily defying mathematics so I decided to do the numbers myself. Standard Deck A. Flush - Pick out of the ranks: .   - Pick a suit: .   - Total: .   - This figure includes Straight Flushes. B. Straight - Pick of rank combinations that constitute a Straight: A-5, 2-6, 3-7, ..., 10-A.   - Assign a suit to each card: .   - Total: .   - This figure includes Straight Flushes. C. Three of a Kind 1) Only a Three of a Kind and nothing higher       - Pick one rank to be the Three of a Kind: .       - Pick two other suits: .       - Pick three out of four suits for the Three of a Kind: .       - Assign a suit to the other two cards: .       - Total: .   2) Full House       - Pick the rank to be the Three of a Kind: .       - Pick another rank to be the Pair: .       - Pick three out of four suits for the Three of a Kind: .       - Pick two out of four suits for the Pair: .       - Total: .   3) Four of a Kind       - Pick the rank to be the Four of a Kind: .       - Pick another rank to be the lone card: .       - Pick a suit for the lone card: .       -Total: . Short Deck A. Flush - Pick out of ranks: .   - Pick a suit: .   - Total: .   - Includes Straight Flushes. B. Straight - Pick of combinations: A-9, 6-10, 7-J, ..., 10-A.   - Assign a suit to each card: .   - Total: .   - This figure includes Straight Flushes. C. Three of a Kind 1) Only a Three of a Kind and nothing higher       - Pick one rank to be the Three of a Kind: .       - Pick two other suits: .       - Pick three out of four suits for the Three of a Kind: .       - Assign a suit to the other two cards: .       - Total: .   2) Full House       - Pick the rank to be the Three of a Kind: .       - Pick another rank to be the Pair: .       - Pick three out of four suits for the Three of a Kind: .       - Pick two out of four suits for the Pair: .       - Total: .   3) Four of a Kind       - Pick the rank to be the Four of a Kind: .       - Pick another rank to be the lone card: .       - Pick a suit for the lone card: .       - Total: . To summarize: Full House vs Flush(Straight Flush) Standard Deck 3744 < 5148(40) Short Deck 1728 > 504(24) Straight(Straight Flush) vs Three of a Kind(Full House/Quads) Standard Deck 10240(40) < 59280(3744/624) Short Deck 6144(24) < 18144(1728/288) As you can see the frequency of Full Houses compared to Flushes flips but Straights compared to Three of a Kinds does not, regardless of whether hands that also belong to a higher rank are deducted or not. Thus the hand ranking that WSOP used is mathematically correct. I read the reference of the Wikipedia article which claimed as follows: In Six Plus straights appear in abundance, so much so, that they rank lower than three-of-a-kind (but still higher than two pair). The article does not dive into the numbers so I have no idea about their reasoning. What method of measuring frequency could have led to this claim? Are there any errors in my logic or calculations?",5 13 \binom{13}{5}=1287 4 1287\times 4=5148 1 10 4^{5}=1024 10\times 1024=10240 10\times 4=40 13 \binom{12}{2}=66 \binom{4}{3}=4 4^{2}=16 13\times 66\times 4\times 16=54912 13 12 4 \binom{4}{2}=6 13\times 12\times 4\times 6=3744 13 12 4 13\times 12\times 4=624 5 9 \binom{9}{5}=126 4 126\times 4=504 1 6 4^{5}=1024 6\times 1024=6144 6\times 4=24 9 \binom{8}{2}=28 \binom{4}{3}=4 4^{2}=16 9\times 28\times 4\times 16=16128 9 8 4 \binom{4}{2}=6 9\times 8\times 4\times 6=1728 9 8 4 9\times 8\times 4=288,"['probability', 'statistics', 'card-games', 'poker']"
18,Bounding a Certain Derivative,Bounding a Certain Derivative,,"I'm self-studying the $2^{\mathrm{nd}}$ edition of Casella and Berger's Statistical Inference and I'm having trouble following a derivation they give (on pp. 72-73). Suppose we want to find a function $g(x,t)$ such that \begin{equation*} \left[\frac{\partial}{\partial t}e^{tx}e^{-(x-\mu)^{2}/2}\right]_{t=t'} \leq g(x,t) \end{equation*} for all $|t'-t|\leq \delta_{0}$ (where $\delta_{0}>0$ ) and such that \begin{equation*} \int_{-\infty}^{\infty}{g(x,t)\,\mathrm{d}x} < \infty. \end{equation*} It is easy to determine that \begin{equation*} \left|\frac{\partial}{\partial t}e^{tx}e^{-(x-\mu)^{2}/2}\right| = \left|x\right|e^{tx}e^{-(x-\mu)^{2}/2}. \end{equation*} They go on to define $g$ as \begin{equation*} g(x,t) = \begin{cases} \left|x\right|e^{(t-\delta_{0})x}e^{-(x-\mu)^{2}/2}\,&\mbox{ for }x<0\mbox{ and}\\ \left|x\right|e^{(t+\delta_{0})x}e^{-(x-\mu)^{2}/2}\,&\mbox{ for }x\geq 0. \end{cases} \end{equation*} Defining the function $g$ as they do, the integral over the negative real numbers involves $e^{-\delta_{0}x}$ in which $-\delta_{0}x>0$ , and the integral over the non-negative real numbers involves $e^{\delta_{0}x}$ in which $\delta_{0}x\geq 0$ , but either way it seems like $e^{-(x-\mu)^{2}/2}$ will ensure the integral is finite. It's not clear to me why it is necessary to define the function differently depending on the sign of $x$ . Is this done to ensure the inequality? Or is it done to ensure that $g(x,\cdot)$ has finite integral over $\mathbb{R}$ ? Edit : I don't think it has to do with integrability. For $x\geq 0$ , they show that one can write \begin{equation*} g(x,t) = xe^{-\left[x-(\mu+t+\delta_{0})\right]^{2}/2}e^{-\left[\mu^{2}-(\mu+t+\delta_{0})^{2}\right]/2} \end{equation*} so that integrating this function over $[0,\infty)$ amounts to calculating the (surely finite) mean of a normal distribution over half of its support. They do the same for $x<0$ : \begin{equation*} g(x,t) = |x|e^{-\left[x-(\mu+t-\delta_{0})\right]^{2}/2}e^{-\left[\mu^{2}-(\mu+t-\delta_{0})^{2}\right]/2}. \end{equation*} But the reasoning seems to hold equally well using $t-\delta_{0}$ or $t+\delta_{0}$ in either case, the difference amounting to a shift in the mean of the normal distribution.","I'm self-studying the edition of Casella and Berger's Statistical Inference and I'm having trouble following a derivation they give (on pp. 72-73). Suppose we want to find a function such that for all (where ) and such that It is easy to determine that They go on to define as Defining the function as they do, the integral over the negative real numbers involves in which , and the integral over the non-negative real numbers involves in which , but either way it seems like will ensure the integral is finite. It's not clear to me why it is necessary to define the function differently depending on the sign of . Is this done to ensure the inequality? Or is it done to ensure that has finite integral over ? Edit : I don't think it has to do with integrability. For , they show that one can write so that integrating this function over amounts to calculating the (surely finite) mean of a normal distribution over half of its support. They do the same for : But the reasoning seems to hold equally well using or in either case, the difference amounting to a shift in the mean of the normal distribution.","2^{\mathrm{nd}} g(x,t) \begin{equation*}
\left[\frac{\partial}{\partial t}e^{tx}e^{-(x-\mu)^{2}/2}\right]_{t=t'} \leq g(x,t)
\end{equation*} |t'-t|\leq \delta_{0} \delta_{0}>0 \begin{equation*}
\int_{-\infty}^{\infty}{g(x,t)\,\mathrm{d}x} < \infty.
\end{equation*} \begin{equation*}
\left|\frac{\partial}{\partial t}e^{tx}e^{-(x-\mu)^{2}/2}\right| = \left|x\right|e^{tx}e^{-(x-\mu)^{2}/2}.
\end{equation*} g \begin{equation*}
g(x,t) = \begin{cases}
\left|x\right|e^{(t-\delta_{0})x}e^{-(x-\mu)^{2}/2}\,&\mbox{ for }x<0\mbox{ and}\\
\left|x\right|e^{(t+\delta_{0})x}e^{-(x-\mu)^{2}/2}\,&\mbox{ for }x\geq 0.
\end{cases}
\end{equation*} g e^{-\delta_{0}x} -\delta_{0}x>0 e^{\delta_{0}x} \delta_{0}x\geq 0 e^{-(x-\mu)^{2}/2} x g(x,\cdot) \mathbb{R} x\geq 0 \begin{equation*}
g(x,t) = xe^{-\left[x-(\mu+t+\delta_{0})\right]^{2}/2}e^{-\left[\mu^{2}-(\mu+t+\delta_{0})^{2}\right]/2}
\end{equation*} [0,\infty) x<0 \begin{equation*}
g(x,t) = |x|e^{-\left[x-(\mu+t-\delta_{0})\right]^{2}/2}e^{-\left[\mu^{2}-(\mu+t-\delta_{0})^{2}\right]/2}.
\end{equation*} t-\delta_{0} t+\delta_{0}","['real-analysis', 'statistics', 'derivatives']"
19,How large does a sample need to be in order to be very representative with high probability?,How large does a sample need to be in order to be very representative with high probability?,,"Suppose we have a set $X$ of $n$ objects that we want to sample uniformly at random. Let $\ell \colon X \rightarrow Y$ be a total, surjective function assigning a label to each object. For a subset $X'$ of $X$ and a label $y \in Y$ let $f_{X'}(y)$ denote the relative frequency of $y$ in $X'$ , i.e. $\frac{|\{ x \in X' \mid \ell(x) = y  \}|}{|X'|}$ . Given a subset $X'$ of $X$ , there are two simple ways to measure how representative it is: $$r_0(X') := \min \left\{ r \geq 0 \mid \forall y \in Y \colon (1-r)\cdot f_X(y) \leq f_{X'}(y) \leq (1+r)\cdot f_X(y) \right\}  $$ $$r_1(X') := \min \left\{ r  \geq 0 \mid \forall y \in Y \colon f_X(y) - r \leq f_{X'}(y) \leq f_X(y) + r \right\}  $$ If $r_0(X') = r$ , this means the relative frequencies in $X'$ differ by at most $(100\cdot r)$ % from their counterparts in $X$ . The function $r_1$ refers to the absolute difference. In both cases 0 denotes the highest degree of representativity, i.e. all relative frequencies in $X'$ coincide with their respective ones in $X$ . Assume we only know the number of objects $n$ , the number of labels $l =|Y|$ and the least amount of times a certain label occurs $k = \min \left\{ |\ell^{-1}(y)| \mid y \in Y \right\}$ . I would like to know the smallest sample size $m=|X'|$ such that the probability that $r_i(X') \leq r$ is at least $p$ for some given $r \geq 0$ , $p \in [0,1]$ and $i \in \{1,2\}$ . Stated differently, I'm looking for (bounds on) the function $f_i(n,l,k,r,p)=m$ .","Suppose we have a set of objects that we want to sample uniformly at random. Let be a total, surjective function assigning a label to each object. For a subset of and a label let denote the relative frequency of in , i.e. . Given a subset of , there are two simple ways to measure how representative it is: If , this means the relative frequencies in differ by at most % from their counterparts in . The function refers to the absolute difference. In both cases 0 denotes the highest degree of representativity, i.e. all relative frequencies in coincide with their respective ones in . Assume we only know the number of objects , the number of labels and the least amount of times a certain label occurs . I would like to know the smallest sample size such that the probability that is at least for some given , and . Stated differently, I'm looking for (bounds on) the function .","X n \ell \colon X \rightarrow Y X' X y \in Y f_{X'}(y) y X' \frac{|\{ x \in X' \mid \ell(x) = y  \}|}{|X'|} X' X r_0(X') := \min \left\{ r \geq 0 \mid \forall y \in Y \colon (1-r)\cdot f_X(y) \leq f_{X'}(y) \leq (1+r)\cdot f_X(y) \right\}   r_1(X') := \min \left\{ r  \geq 0 \mid \forall y \in Y \colon f_X(y) - r \leq f_{X'}(y) \leq f_X(y) + r \right\}   r_0(X') = r X' (100\cdot r) X r_1 X' X n l =|Y| k = \min \left\{ |\ell^{-1}(y)| \mid y \in Y \right\} m=|X'| r_i(X') \leq r p r \geq 0 p \in [0,1] i \in \{1,2\} f_i(n,l,k,r,p)=m","['probability', 'statistics']"
20,Best estimator of a matrix signal with binary entries,Best estimator of a matrix signal with binary entries,,"Setup: Given that we have a noisy matrix signal $\breve{B}\in\mathbb{R}^{p\times L}$ of the true signal $B\in\mathbb{R}^{p\times L}$ , where the empirical distribution of the rows of $B$ converge to $\bar{B}\in\mathbb{R}^L$ where $\bar{B}\sim\text{Categorical}(\pi)$ , $\pi\in\mathbb{R}^L$ , and $\sum_{l=1}^L\pi_l=1$ (i.e., $\pi$ is a probability vector). The rows of $B$ are generated by sampling independently from the distribution $\text{Categorical}(\pi)$ . So the rows of $B$ are independent one-hot vectors. The goal is to estimate $B$ from $\breve{B}$ . We have additional statistical information about $\breve{B}$ , namely: The empirical distribution of the rows of $\breve{B}$ converges to $M\bar{B}+G$ , where: $M\in\mathbb{R}^{L\times L}$ is a non-random component; $G\sim \mathcal{N}(0,\Sigma)$ , where $\Sigma\in\mathbb{R}^{L\times L}$ , is the random noise component. Note that we have access to $\pi$ , $M$ , and $\Sigma$ . To be more precise, the convergence of rows means $$ \frac{1}{p}\sum_{j=1}^p\breve{B}_j \rightarrow \mathbb{E}\big[M\bar{B}+G\big], $$ where $\breve{B}_j$ denotes the $j$ th row of $\breve{B}$ . Question: What is the best estimator $\widehat{B}_j=f(\breve{B}_j)$ ? Note that here, estimation is done row wise with $j\in\{1,\dots,p\}$ . The best that I can think of is $$ f(\breve{B}_j)=\mathbb{E}\Big[\bar{B}\,\Big|\,M\bar{B}+G=\breve{B}_j\Big]. $$ Can we do better than this since we know that rows of $B$ are one-hot vectors (and we also know the prior distribution of the signal $B$ )? Thanks.","Setup: Given that we have a noisy matrix signal of the true signal , where the empirical distribution of the rows of converge to where , , and (i.e., is a probability vector). The rows of are generated by sampling independently from the distribution . So the rows of are independent one-hot vectors. The goal is to estimate from . We have additional statistical information about , namely: The empirical distribution of the rows of converges to , where: is a non-random component; , where , is the random noise component. Note that we have access to , , and . To be more precise, the convergence of rows means where denotes the th row of . Question: What is the best estimator ? Note that here, estimation is done row wise with . The best that I can think of is Can we do better than this since we know that rows of are one-hot vectors (and we also know the prior distribution of the signal )? Thanks.","\breve{B}\in\mathbb{R}^{p\times L} B\in\mathbb{R}^{p\times L} B \bar{B}\in\mathbb{R}^L \bar{B}\sim\text{Categorical}(\pi) \pi\in\mathbb{R}^L \sum_{l=1}^L\pi_l=1 \pi B \text{Categorical}(\pi) B B \breve{B} \breve{B} \breve{B} M\bar{B}+G M\in\mathbb{R}^{L\times L} G\sim \mathcal{N}(0,\Sigma) \Sigma\in\mathbb{R}^{L\times L} \pi M \Sigma 
\frac{1}{p}\sum_{j=1}^p\breve{B}_j
\rightarrow
\mathbb{E}\big[M\bar{B}+G\big],
 \breve{B}_j j \breve{B} \widehat{B}_j=f(\breve{B}_j) j\in\{1,\dots,p\} 
f(\breve{B}_j)=\mathbb{E}\Big[\bar{B}\,\Big|\,M\bar{B}+G=\breve{B}_j\Big].
 B B","['probability', 'statistics', 'statistical-inference', 'signal-processing', 'estimation']"
21,Intuitive difference between optimal transport distance and Fisher information distance,Intuitive difference between optimal transport distance and Fisher information distance,,"Let me start by saying I'm not a mathematician but a biologist with an interest in mathematics. I have a set of covariance matrices and I am interested in studying their geometry in the Symmetric Positive Definite Matrices (SPDM) manifold. I'm particularly interested in relating the geometry to statistical properties of the centered Gaussians defined by those matrices (e.g. how 'discriminable' the data generated by the different Gaussians is). There exist a plethora of metrics that are used with this manifold. Two of these metrics (at least) are related to probabilistic/statistics concepts. One is the Affine Invariant (AI) distance, which according to this source *Up to a constant, it is known as the Fisher information metric"". The other one is the Wasserstein distance , which is the optimal transport distance. The AI distance between $A$ and $B$ is given by: $$d(A,B) = ||log(A^{-1/2} B A^{-1/2})||_F$$ The Wasserstein distance is given by: $$d(A,B) = tr(A) + tr(B) - 2tr((A^{1/2} B A^{1/2})^{1/2})$$ These two metrics behave very differently. For one, it is my understanding that the AI manifold has negative curvature, while the Wasserstein manifold has non-negative curvature. But I'm still not clear on the differences between the two from a probability/statistical conceptually point of view. What do the two distances tell me with regards to the statistical problem of discriminating between classes that generate data according to the Gaussians of those SPDM? What complementary information about this problem do the two metrics give? This gives some intuition of the difference between KL divergence and Optimal transport distance, but I'm not sure how much translates to the AI/Fisher information metric.","Let me start by saying I'm not a mathematician but a biologist with an interest in mathematics. I have a set of covariance matrices and I am interested in studying their geometry in the Symmetric Positive Definite Matrices (SPDM) manifold. I'm particularly interested in relating the geometry to statistical properties of the centered Gaussians defined by those matrices (e.g. how 'discriminable' the data generated by the different Gaussians is). There exist a plethora of metrics that are used with this manifold. Two of these metrics (at least) are related to probabilistic/statistics concepts. One is the Affine Invariant (AI) distance, which according to this source *Up to a constant, it is known as the Fisher information metric"". The other one is the Wasserstein distance , which is the optimal transport distance. The AI distance between and is given by: The Wasserstein distance is given by: These two metrics behave very differently. For one, it is my understanding that the AI manifold has negative curvature, while the Wasserstein manifold has non-negative curvature. But I'm still not clear on the differences between the two from a probability/statistical conceptually point of view. What do the two distances tell me with regards to the statistical problem of discriminating between classes that generate data according to the Gaussians of those SPDM? What complementary information about this problem do the two metrics give? This gives some intuition of the difference between KL divergence and Optimal transport distance, but I'm not sure how much translates to the AI/Fisher information metric.","A B d(A,B) = ||log(A^{-1/2} B A^{-1/2})||_F d(A,B) = tr(A) + tr(B) - 2tr((A^{1/2} B A^{1/2})^{1/2})","['statistics', 'differential-geometry', 'symmetric-matrices', 'positive-definite', 'information-geometry']"
22,Finding the PMF of a discrete ordered statistic,Finding the PMF of a discrete ordered statistic,,"Question Let $X_0,X_1,X_2 \dots$ be independent and identically distributed continuous random variables with density $f(x)$ . Let $N$ be the first index $k$ such that $X_k > X_0$ . For example, $N = 2$ if $X_2 > X_0$ and $X_1 \leq X_0$ . Determine the PMF of $N$ and its expectation. Also, explain how your answer would change if the random variables $X_0,X_1,X_2 \dots$ were discrete rather than continuous. I came across this post , where the question is the same as mine except for the second part where the random variables $X_0,X_1,X_2 \dots$ change to discrete. My thoughts for the second part $$\begin{aligned} \mathbb{P}(N= n | X_0 = x) &= \mathbb{P}(X_1 \leq x,X_2 \leq x,\dots, X_{n-1}\leq x, X_n>x)\\ & = F(x)^{n-1}[1-F(x)]\\ \implies \mathbb{P}(N=n) & = \sum_{x}\mathbb{P}(N = n |X_0=x)\mathbb{P}(X_0 = x)\\ &= \sum_{x}F(x)^{n-1}[1-F(x)]p_X(x) \end{aligned}$$ Am I on the right track? Also, my professor said that he is looking more for a qualitative answer rather than a quantitative one for this part, but I am unable to come up with anything, so any intuitive explanation will be greatly appreciated!","Question Let be independent and identically distributed continuous random variables with density . Let be the first index such that . For example, if and . Determine the PMF of and its expectation. Also, explain how your answer would change if the random variables were discrete rather than continuous. I came across this post , where the question is the same as mine except for the second part where the random variables change to discrete. My thoughts for the second part Am I on the right track? Also, my professor said that he is looking more for a qualitative answer rather than a quantitative one for this part, but I am unable to come up with anything, so any intuitive explanation will be greatly appreciated!","X_0,X_1,X_2 \dots f(x) N k X_k > X_0 N = 2 X_2 > X_0 X_1 \leq X_0 N X_0,X_1,X_2 \dots X_0,X_1,X_2 \dots \begin{aligned}
\mathbb{P}(N= n | X_0 = x) &= \mathbb{P}(X_1 \leq x,X_2 \leq x,\dots, X_{n-1}\leq x, X_n>x)\\
& = F(x)^{n-1}[1-F(x)]\\
\implies \mathbb{P}(N=n) & = \sum_{x}\mathbb{P}(N = n |X_0=x)\mathbb{P}(X_0 = x)\\
&= \sum_{x}F(x)^{n-1}[1-F(x)]p_X(x)
\end{aligned}","['probability', 'statistics', 'probability-distributions', 'independence']"
23,Recommendation on probability and statistic books.,Recommendation on probability and statistic books.,,"I'm currently starting to self study probability and statistic, a friend recommend me to use a book he has but his book does not go deep in the theorem and formula, instead it just state the equation and when to use it along with some properties but not the proof for the equation (for example: the chapter about the Poisson random variable just tells you how to use it and when, but lacks the proof of how mathematicians arrive at that complex equation ). I would like a book that is rigorous and proof-based for every problem in it ( like Tom M. Apostol's calculus books for example), im a colleague student and has good calculus and linear algebra background so an more advance than regular books is ok with me. Do you have any recommendation ?","I'm currently starting to self study probability and statistic, a friend recommend me to use a book he has but his book does not go deep in the theorem and formula, instead it just state the equation and when to use it along with some properties but not the proof for the equation (for example: the chapter about the Poisson random variable just tells you how to use it and when, but lacks the proof of how mathematicians arrive at that complex equation ). I would like a book that is rigorous and proof-based for every problem in it ( like Tom M. Apostol's calculus books for example), im a colleague student and has good calculus and linear algebra background so an more advance than regular books is ok with me. Do you have any recommendation ?",,"['probability', 'statistics', 'self-learning', 'book-recommendation']"
24,"Show that $\bar{Y} - \min(Y_{1}, \dots, Y_{n})$ is independent of $\min(Y_{1}, \dots, Y_{n})$",Show that  is independent of,"\bar{Y} - \min(Y_{1}, \dots, Y_{n}) \min(Y_{1}, \dots, Y_{n})","Suppose that $Y_1, \dots, Y_n$ are i.i.d observations from the density $f(y, \theta, \beta) = \beta e^{-\beta(y - \theta)}I_{[y \geq\theta]}$ where $\beta \gt 0$ , $\theta \in \mathbb{R}$ are unknown parameters. Let $(T_1, T_2) = (\min(Y_1, \dots, Y_n), \bar{Y})$ . I want to show that $T_2 - T_1$ is independent of $T_1$ for all values of $(\theta, \beta)$ . I already proved that $T_1$ is complete sufficient for $\theta$ when $\beta$ is fixed and known, and that $T_2$ is complete sufficient for $\beta$ when $\theta$ is fixed and known. Clearly, $T_2 - T_1$ is an ancillary statistic of $\theta$ . Since $T_1$ is complete sufficient for $\theta$ when $\beta$ is fixed and known, can we just use Basu's theorem to conclude that $T_2 - T_1$ is independent of $T_1$ for all values of $(\theta, \beta)$ ?","Suppose that are i.i.d observations from the density where , are unknown parameters. Let . I want to show that is independent of for all values of . I already proved that is complete sufficient for when is fixed and known, and that is complete sufficient for when is fixed and known. Clearly, is an ancillary statistic of . Since is complete sufficient for when is fixed and known, can we just use Basu's theorem to conclude that is independent of for all values of ?","Y_1, \dots, Y_n f(y, \theta, \beta) = \beta e^{-\beta(y - \theta)}I_{[y \geq\theta]} \beta \gt 0 \theta \in \mathbb{R} (T_1, T_2) = (\min(Y_1, \dots, Y_n), \bar{Y}) T_2 - T_1 T_1 (\theta, \beta) T_1 \theta \beta T_2 \beta \theta T_2 - T_1 \theta T_1 \theta \beta T_2 - T_1 T_1 (\theta, \beta)","['statistics', 'statistical-inference', 'order-statistics', 'sufficient-statistics']"
25,How do I calculate the probability of getting a 5 card straight in 7 card poker?,How do I calculate the probability of getting a 5 card straight in 7 card poker?,,"So here's my progress on this problem. The first straight to examine is $\begin{pmatrix} A & 2 & 3 & 4 & 5 & n & m\end{pmatrix}$ . If we start with all one suit, there are $\binom{47}{2}$ ways to obtain this hand. Next, we iterate through the suit of one card, say, the Ace, and we have $\binom{46}{2}$ , then $\binom{45}{2}$ , then $\binom{44}{2}$ ways to obtain this hand without repeating previous hands. To iterate through all suits of all cards, take the sum \begin{equation} \sum_{k,l,m,n,p=0}^{3}\binom{47-k-l-m-n-p}{2} \end{equation} and subtract $4\binom{47}{2}$ to discount straight flushes. Next, to count the hands of $\begin{pmatrix} 2 & 3 & 4 & 5 & 6 & p & q\end{pmatrix}$ , $\begin{pmatrix} 3 & 4 & 5 & 6 & 7 & r & s\end{pmatrix}$ , etc., we start with $\binom{43}{2}$ to obtain the first hand, so as not to double count hands of the form $\begin{pmatrix} A & 2 & 3 & 4 & 5 & 6 & m\end{pmatrix}$ . Therefore we add 9 hands of the following form, subtracting the possible straight flushes. \begin{equation} 9 \left( \sum_{k,l,m,n,p=0}^{3}\binom{43-k-l-m-n-p}{2}\right) - 9\binom{46}{2} \end{equation} These sums may be reduced to one dimension by observing that the weight of each possible sum, r, for $k+l+m+n+p=r$ is equivalent to the coefficient of each term $x^r$ in the expansion $(x^0+x^1+x^2+x^3)^5$ . The problem is that these equations describe 6412688 possible straight hands while there should be 6180020 possible hands (according to Wikipedia). I can not for the life of me figure out what hands I am double counting here. Any help is appreciated.","So here's my progress on this problem. The first straight to examine is . If we start with all one suit, there are ways to obtain this hand. Next, we iterate through the suit of one card, say, the Ace, and we have , then , then ways to obtain this hand without repeating previous hands. To iterate through all suits of all cards, take the sum and subtract to discount straight flushes. Next, to count the hands of , , etc., we start with to obtain the first hand, so as not to double count hands of the form . Therefore we add 9 hands of the following form, subtracting the possible straight flushes. These sums may be reduced to one dimension by observing that the weight of each possible sum, r, for is equivalent to the coefficient of each term in the expansion . The problem is that these equations describe 6412688 possible straight hands while there should be 6180020 possible hands (according to Wikipedia). I can not for the life of me figure out what hands I am double counting here. Any help is appreciated.","\begin{pmatrix} A & 2 & 3 & 4 & 5 & n & m\end{pmatrix} \binom{47}{2} \binom{46}{2} \binom{45}{2} \binom{44}{2} \begin{equation}
\sum_{k,l,m,n,p=0}^{3}\binom{47-k-l-m-n-p}{2}
\end{equation} 4\binom{47}{2} \begin{pmatrix} 2 & 3 & 4 & 5 & 6 & p & q\end{pmatrix} \begin{pmatrix} 3 & 4 & 5 & 6 & 7 & r & s\end{pmatrix} \binom{43}{2} \begin{pmatrix} A & 2 & 3 & 4 & 5 & 6 & m\end{pmatrix} \begin{equation}
9 \left( \sum_{k,l,m,n,p=0}^{3}\binom{43-k-l-m-n-p}{2}\right) - 9\binom{46}{2}
\end{equation} k+l+m+n+p=r x^r (x^0+x^1+x^2+x^3)^5","['probability', 'combinatorics', 'statistics', 'permutations', 'poker']"
26,Sum of two difference sequences for consecutive numbers,Sum of two difference sequences for consecutive numbers,,"Problem Setting: If there are two difference sequences for consective integers $\{a_i \}_{i=1}^{n}$ and $\{b_i \}_{i=1}^{n}$ and they have a relationship that for any $i = 1,2,...,n$ , $$\delta = a_i - b_i, $$ and $\delta \in R$ , how can we prove that $$ \left[ \sum_{i=1}^{n}a_i y_i \right] \left[ \sum_{i=1}^{n}a_i \right] - \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}a_i^2 \right] \neq \left[ \sum_{i=1}^{n}b_i y_i \right] \left[ \sum_{i=1}^{n}b_i \right] - \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}b_i^2 \right], $$ where $y_i \in R$ . Solved Attempt: I tried to use proof by contradiction. Assuming that the above inequality is not hold so LHS = RHS, and plug in their relationship $\delta = a_i - b_i$ , I can obtain $$ \left[ \sum_{i=1}^{n}a_i y_i \right] \left[ \sum_{i=1}^{n}a_i \right] - \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}a_i^2 \right] - \left[ \sum_{i=1}^{n}b_i y_i \right] \left[ \sum_{i=1}^{n}b_i \right] + \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}b_i^2 \right] = 0, $$ after some calculation, $$ \sum_{i=1}^{n}\left[-(n-1)n\delta^2 - \delta(2n-1)\left(\sum_{i=1}^{n}b_i\right) + n \delta b_i \right]y_i = 0. $$ However, I didn't know how to continue this process. I am wondering how I can continue the proof or if I make any mistakes.","Problem Setting: If there are two difference sequences for consective integers and and they have a relationship that for any , and , how can we prove that where . Solved Attempt: I tried to use proof by contradiction. Assuming that the above inequality is not hold so LHS = RHS, and plug in their relationship , I can obtain after some calculation, However, I didn't know how to continue this process. I am wondering how I can continue the proof or if I make any mistakes.","\{a_i \}_{i=1}^{n} \{b_i \}_{i=1}^{n} i = 1,2,...,n \delta = a_i - b_i,  \delta \in R 
\left[ \sum_{i=1}^{n}a_i y_i \right] \left[ \sum_{i=1}^{n}a_i \right] - \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}a_i^2 \right] \neq \left[ \sum_{i=1}^{n}b_i y_i \right] \left[ \sum_{i=1}^{n}b_i \right] - \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}b_i^2 \right],
 y_i \in R \delta = a_i - b_i 
\left[ \sum_{i=1}^{n}a_i y_i \right] \left[ \sum_{i=1}^{n}a_i \right] - \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}a_i^2 \right] - \left[ \sum_{i=1}^{n}b_i y_i \right] \left[ \sum_{i=1}^{n}b_i \right] + \left[ \sum_{i=1}^{n}y_i \right]\left[ \sum_{i=1}^{n}b_i^2 \right] = 0,
 
\sum_{i=1}^{n}\left[-(n-1)n\delta^2 - \delta(2n-1)\left(\sum_{i=1}^{n}b_i\right) + n \delta b_i \right]y_i = 0.
","['real-analysis', 'sequences-and-series', 'statistics', 'summation']"
27,Elo/Glicko based rating system for team games and with margin of victory multiplier,Elo/Glicko based rating system for team games and with margin of victory multiplier,,"Can someone suggest a rating formula for individuals playing a team game where pairings are made up from a pool of individual players? I have a game which is always played in doubles. The pairings can be made up of any two players in the pool of players and will change every match. Pairings are random and not affected by previous pairings or skill/ability. I want a rating system that tracks individual ratings based upon all the games they play in paired matches. Assumptions The simple win probability of a pairing against another pairing is based upon their average rating, nothing more complicated than this. Each match provides only two pieces of data - the team that won and the margin of victory (there is no indication of how each player in the team performed, only the team as a whole). There are no ""cyclic"" relationships between pairings or players as in rock, paper scissors. Requirements Accurately tracks the probability of win/loss for a given matchup. Not prone to rapid inflation or deflation Doesn't encourage players to ""protect"" their rating Doesn't allow manipulation of pairings to create  beneficial match ups Preferably includes a margin of victory multiplier to encourage teams to continue to play to the best of their ability even when very far behind in a game. This would imply that it can predict the margin of victory as well as the probability of win/loss. Low computation requirements and easy to implement in a spreadsheet Options Elo is perhaps the best-known rating system made popular from its use by FIDE but has many well-known flaws . It also needs to be adapted to allow tracking individual ratings when only team results are known. Perhaps it can be altered to take into account margin of victory by scaling the scores from 0-1 instead of 0 for a loss, 1 for a win and 1/2 for a draw? Another system is the KGS rank system . A frequently-used improvement upon Elo's work is the Glicko-2 system . It introduced concepts such as rating volatility, improves prediction reliability and has replaced the use of Elo on many rating leagues. However, it also doesn't account for teams made of of pairings from a pool. Rating systems that do account for this include Microsoft's TrueSkill2 but this is a licensed system.  Another method would be to use Glicko-2 treating each 2v2 match it as 4 individual simultaneous matches. Nate Silver also apparently uses some sort of algorithm for team sports . There are some similar questions but, as far as I can see, none take into account both the margin of victory and individual ratings in team matches. Does anyone have any suggestions for a simple rating algorithm to use?","Can someone suggest a rating formula for individuals playing a team game where pairings are made up from a pool of individual players? I have a game which is always played in doubles. The pairings can be made up of any two players in the pool of players and will change every match. Pairings are random and not affected by previous pairings or skill/ability. I want a rating system that tracks individual ratings based upon all the games they play in paired matches. Assumptions The simple win probability of a pairing against another pairing is based upon their average rating, nothing more complicated than this. Each match provides only two pieces of data - the team that won and the margin of victory (there is no indication of how each player in the team performed, only the team as a whole). There are no ""cyclic"" relationships between pairings or players as in rock, paper scissors. Requirements Accurately tracks the probability of win/loss for a given matchup. Not prone to rapid inflation or deflation Doesn't encourage players to ""protect"" their rating Doesn't allow manipulation of pairings to create  beneficial match ups Preferably includes a margin of victory multiplier to encourage teams to continue to play to the best of their ability even when very far behind in a game. This would imply that it can predict the margin of victory as well as the probability of win/loss. Low computation requirements and easy to implement in a spreadsheet Options Elo is perhaps the best-known rating system made popular from its use by FIDE but has many well-known flaws . It also needs to be adapted to allow tracking individual ratings when only team results are known. Perhaps it can be altered to take into account margin of victory by scaling the scores from 0-1 instead of 0 for a loss, 1 for a win and 1/2 for a draw? Another system is the KGS rank system . A frequently-used improvement upon Elo's work is the Glicko-2 system . It introduced concepts such as rating volatility, improves prediction reliability and has replaced the use of Elo on many rating leagues. However, it also doesn't account for teams made of of pairings from a pool. Rating systems that do account for this include Microsoft's TrueSkill2 but this is a licensed system.  Another method would be to use Glicko-2 treating each 2v2 match it as 4 individual simultaneous matches. Nate Silver also apparently uses some sort of algorithm for team sports . There are some similar questions but, as far as I can see, none take into account both the margin of victory and individual ratings in team matches. Does anyone have any suggestions for a simple rating algorithm to use?",,"['probability', 'statistics', 'algorithms']"
28,Bias be larger than variance in ERM,Bias be larger than variance in ERM,,"Given a convex set $S\subset \mathbb{R}^n$ and some $\theta\in S$ , consider the observation $y=\theta+\epsilon$ where $\epsilon\sim \mathcal{N}(0,I)$ , the ERM estimator is $$\hat{\theta}=\arg \min_{x\in S}\|x-y\|_2.$$ Consider the usual bias-variance decomposition $$\mathbb{E}\|\hat\theta-\theta\|^2=\|\mathbb{E}\hat\theta-\theta\|^2+var(\hat\theta)=bias^2+variance.$$ Does there exists some $S$ and $\theta$ , such that the bias term is much larger than the variance term? For example, for 1D linear regression on $x_1,...,x_n\in\mathbb{R}$ , the $S$ here is $S=\{(y_1,...,y_n):y_i=kx_i+b, k,b\in\mathbb{R}\}$ is a hyperplane in $\mathbb{R}^n$ , so the estimator is unbiased.","Given a convex set and some , consider the observation where , the ERM estimator is Consider the usual bias-variance decomposition Does there exists some and , such that the bias term is much larger than the variance term? For example, for 1D linear regression on , the here is is a hyperplane in , so the estimator is unbiased.","S\subset \mathbb{R}^n \theta\in S y=\theta+\epsilon \epsilon\sim \mathcal{N}(0,I) \hat{\theta}=\arg \min_{x\in S}\|x-y\|_2. \mathbb{E}\|\hat\theta-\theta\|^2=\|\mathbb{E}\hat\theta-\theta\|^2+var(\hat\theta)=bias^2+variance. S \theta x_1,...,x_n\in\mathbb{R} S S=\{(y_1,...,y_n):y_i=kx_i+b, k,b\in\mathbb{R}\} \mathbb{R}^n","['statistics', 'statistical-inference', 'estimation']"
29,Name for this type of Markov process?,Name for this type of Markov process?,,"I'm experimenting with this type of stochastic process and I'm wondering if there is a specific name for it. So far I've described it as a discrete-time continuous-state Markov process but curious to see if there's a special name. I have random variables $X_t$ where $t \in \mathbb{N}$ on the state-space $\mathbb{R}$ , given by: $X_{t+1}=     \begin{cases}       0, & \text{with prob.}\ \alpha \\       X_t +\mu, & \text{with prob.}\ 1-\alpha     \end{cases}$ where $\mu \in \mathbb{R}$ . Thanks in advance!","I'm experimenting with this type of stochastic process and I'm wondering if there is a specific name for it. So far I've described it as a discrete-time continuous-state Markov process but curious to see if there's a special name. I have random variables where on the state-space , given by: where . Thanks in advance!","X_t t \in \mathbb{N} \mathbb{R} X_{t+1}=
    \begin{cases}
      0, & \text{with prob.}\ \alpha \\
      X_t +\mu, & \text{with prob.}\ 1-\alpha
    \end{cases} \mu \in \mathbb{R}","['probability', 'statistics', 'stochastic-processes', 'definition']"
30,Show that the MLE of $\alpha$ is consistent by definition.,Show that the MLE of  is consistent by definition.,\alpha,"Suppose that $(X_1,\dots, X_n)$ is an iid random sample from $X\sim f(x;\alpha, \beta)$ and $$ f(x;\alpha, \beta)=\frac{\alpha x^{\alpha-1}}{\beta^{\alpha}}, \, 0<x\le \beta, \alpha>0, \beta>0, $$ Show that the MLE of $\alpha$ is consistent by definition. My work: Note that the log-likelihood: $$ \ell(\alpha, \beta)=n\log\alpha-n\alpha\log\beta+\sum_{i=1}^n \log x_i^{\alpha-1} I[1<X_{(1)}<X_{(n)}\le \beta] $$ where $X_{(1)}\le X_{(2)}\le \dots \le X_{(n)}$ . Then the MLE of $\beta$ is $$ \hat{\beta}=X_{(n)}. $$ By the invariant of MLE and solving $\frac{\partial \ell(\alpha, X_{(n)})}{\partial \alpha}=0$ , the MLE of $\alpha$ is $$ \hat{\alpha}=\frac{1}{\log X_{(n)}-\frac{1}{n}\sum \log X_i} $$ By Weak law of large number, we have $$ \frac{1}{n}\sum \log X_i \to E[\log X_1]=\log \beta-\frac{1}{\alpha}. $$ Note that for every $\epsilon>0$ , $$ P(|X_{(n)}-\beta|>\epsilon)=P(\beta-X_{(n)}>\epsilon)=\frac{(\beta-\epsilon)^{n\alpha}}{\beta^{n\alpha}}\to 0 $$ as $n\to \infty$ . (Because $\frac{\beta-\epsilon}{\beta}<1$ ) Hence, $\hat{\beta}=X_{(n)}\to \beta$ in probability. Hence, by continuous mapping theorem $$ \hat{\alpha}=\frac{1}{\log X_{(n)}-\frac{1}{n}\sum \log X_i}\to \alpha $$ Is my proof right?","Suppose that is an iid random sample from and Show that the MLE of is consistent by definition. My work: Note that the log-likelihood: where . Then the MLE of is By the invariant of MLE and solving , the MLE of is By Weak law of large number, we have Note that for every , as . (Because ) Hence, in probability. Hence, by continuous mapping theorem Is my proof right?","(X_1,\dots, X_n) X\sim f(x;\alpha, \beta) 
f(x;\alpha, \beta)=\frac{\alpha x^{\alpha-1}}{\beta^{\alpha}}, \, 0<x\le \beta, \alpha>0, \beta>0,
 \alpha 
\ell(\alpha, \beta)=n\log\alpha-n\alpha\log\beta+\sum_{i=1}^n \log x_i^{\alpha-1} I[1<X_{(1)}<X_{(n)}\le \beta]
 X_{(1)}\le X_{(2)}\le \dots \le X_{(n)} \beta 
\hat{\beta}=X_{(n)}.
 \frac{\partial \ell(\alpha, X_{(n)})}{\partial \alpha}=0 \alpha 
\hat{\alpha}=\frac{1}{\log X_{(n)}-\frac{1}{n}\sum \log X_i}
 
\frac{1}{n}\sum \log X_i \to E[\log X_1]=\log \beta-\frac{1}{\alpha}.
 \epsilon>0 
P(|X_{(n)}-\beta|>\epsilon)=P(\beta-X_{(n)}>\epsilon)=\frac{(\beta-\epsilon)^{n\alpha}}{\beta^{n\alpha}}\to 0
 n\to \infty \frac{\beta-\epsilon}{\beta}<1 \hat{\beta}=X_{(n)}\to \beta 
\hat{\alpha}=\frac{1}{\log X_{(n)}-\frac{1}{n}\sum \log X_i}\to \alpha
","['probability', 'statistics']"
31,Unbiased estimator of a complex function,Unbiased estimator of a complex function,,"Let $X_1, X_2 \cdots X_N$ be random variables, which follow a Gaussian distribution. \begin{equation} X \sim N(\mu, \sigma^2) \end{equation} Let the parameters $\mu$ and $\sigma^2$ be unknown. I know that the unbiased estimator of $\mu$ is \begin{equation} \bar{X}=\frac{1}{N}(X_1+X_2 \cdots X_N) \end{equation} and that of $\sigma^2$ is \begin{equation} U = \frac{1}{N-1}\left((X_1 -\bar{X})^2 \cdots (X_N -\bar{X})^2\right) \end{equation} Here, a new parameter $f$ is defined as \begin{equation} f = \frac{1}{\sigma^2 + \sigma_t^2}  \exp\left(-\frac{1}{2}(\mu -\mu_t)^2(\sigma^2 + \sigma_t^2)^{-1}\right) \end{equation} , where $\mu_t$ and $\sigma_t^2$ are known parameters. I'm not sure how to obtain the unbiased estimator of $f$ . The simplest case is when $\mu$ is a known parameter and $\mu = \mu_t$ . In this case, \begin{equation} f = \frac{1}{\sigma^2 + \sigma_t^2} \end{equation} and I'd like to calculate the mean value of $\tilde{F}=\frac{1}{U + \sigma_t^2}$ \begin{equation} \begin{split} E\left[\tilde{F} \right]&= E\left[\frac{1}{U + \sigma_t^2}\right] \\ &=  E\left[\frac{N-1}{\sigma^2 Y +  (N-1)\sigma_t^2}\right] \quad (Y \sim \chi_{N-1}^2) \\ &= (N-1) \int_0^{\infty} \frac{1}{\sigma^2 y + (N-1)\sigma_t^2} \frac{y^{\frac{N-1}{2}-1}e^{-\frac{y}{2}}} {2^{\frac{N-1}{2}} \Gamma(\frac{N-1}{2})} dy \end{split} \end{equation} How can I calculate this value? So, my question is how to obtain the unbiased estimator of $f$ how to calculate $E[\tilde{F}]$ Either one or the other answer is fine. I faced this problem when I was studying quantum mechanics. Gaussian quantum states can be represented by Gaussian distributions of operators of $\hat{x}$ and $\hat{p}$ . A vector of the mean values of these operators can be defined as $\boldsymbol{m} = (\left<\hat{x}\right>, \left< \hat{p}\right>)^{\top}$ and the covariance matrix can be defined as \begin{equation} V =  \begin{pmatrix} (\Delta \hat{x})^2 & \Delta \hat{x} \Delta \hat{p} \\ \Delta \hat{p} \Delta \hat{x} & (\Delta \hat{p})^2 \end{pmatrix} \end{equation} Fidelity $f$ , which is a measure of closeness between two quantum states, can be written as \begin{equation} \begin{split} f&= \frac{\hbar}{\sqrt{\operatorname{det}\left(V_1+V_2\right)}} \exp \left[-\frac{1}{2}\left(\boldsymbol{m}_1-\boldsymbol{m}_2\right)^\top\left(V_1+V_2\right)^{-1}\left(\boldsymbol{m}_1-\boldsymbol{m}_2\right)\right] \\ &0 \le f \le 1 \end{split} \end{equation} If the two states are the same ( $\boldsymbol{m}_1 = \boldsymbol{m}_2$ , $V_1 = V_2$ ), the fidelity is 1 since $\operatorname{det} V=(\frac{\hbar}{2})^2$ . The Gaussian states can be defined using two parameters $\hat{x}$ and $\hat{p}$ , but the question is changed to one parameter in order to make the problem simpler.","Let be random variables, which follow a Gaussian distribution. Let the parameters and be unknown. I know that the unbiased estimator of is and that of is Here, a new parameter is defined as , where and are known parameters. I'm not sure how to obtain the unbiased estimator of . The simplest case is when is a known parameter and . In this case, and I'd like to calculate the mean value of How can I calculate this value? So, my question is how to obtain the unbiased estimator of how to calculate Either one or the other answer is fine. I faced this problem when I was studying quantum mechanics. Gaussian quantum states can be represented by Gaussian distributions of operators of and . A vector of the mean values of these operators can be defined as and the covariance matrix can be defined as Fidelity , which is a measure of closeness between two quantum states, can be written as If the two states are the same ( , ), the fidelity is 1 since . The Gaussian states can be defined using two parameters and , but the question is changed to one parameter in order to make the problem simpler.","X_1, X_2 \cdots X_N \begin{equation}
X \sim N(\mu, \sigma^2)
\end{equation} \mu \sigma^2 \mu \begin{equation}
\bar{X}=\frac{1}{N}(X_1+X_2 \cdots X_N)
\end{equation} \sigma^2 \begin{equation}
U = \frac{1}{N-1}\left((X_1 -\bar{X})^2 \cdots (X_N -\bar{X})^2\right)
\end{equation} f \begin{equation}
f = \frac{1}{\sigma^2 + \sigma_t^2} 
\exp\left(-\frac{1}{2}(\mu -\mu_t)^2(\sigma^2 + \sigma_t^2)^{-1}\right)
\end{equation} \mu_t \sigma_t^2 f \mu \mu = \mu_t \begin{equation}
f = \frac{1}{\sigma^2 + \sigma_t^2}
\end{equation} \tilde{F}=\frac{1}{U + \sigma_t^2} \begin{equation}
\begin{split}
E\left[\tilde{F} \right]&= E\left[\frac{1}{U + \sigma_t^2}\right] \\
&=  E\left[\frac{N-1}{\sigma^2 Y +  (N-1)\sigma_t^2}\right] \quad (Y \sim \chi_{N-1}^2) \\
&= (N-1) \int_0^{\infty}
\frac{1}{\sigma^2 y + (N-1)\sigma_t^2}
\frac{y^{\frac{N-1}{2}-1}e^{-\frac{y}{2}}}
{2^{\frac{N-1}{2}} \Gamma(\frac{N-1}{2})} dy
\end{split}
\end{equation} f E[\tilde{F}] \hat{x} \hat{p} \boldsymbol{m} = (\left<\hat{x}\right>, \left< \hat{p}\right>)^{\top} \begin{equation}
V = 
\begin{pmatrix}
(\Delta \hat{x})^2 & \Delta \hat{x} \Delta \hat{p} \\
\Delta \hat{p} \Delta \hat{x} & (\Delta \hat{p})^2
\end{pmatrix}
\end{equation} f \begin{equation}
\begin{split}
f&=
\frac{\hbar}{\sqrt{\operatorname{det}\left(V_1+V_2\right)}} \exp \left[-\frac{1}{2}\left(\boldsymbol{m}_1-\boldsymbol{m}_2\right)^\top\left(V_1+V_2\right)^{-1}\left(\boldsymbol{m}_1-\boldsymbol{m}_2\right)\right] \\
&0 \le f \le 1
\end{split}
\end{equation} \boldsymbol{m}_1 = \boldsymbol{m}_2 V_1 = V_2 \operatorname{det} V=(\frac{\hbar}{2})^2 \hat{x} \hat{p}","['statistics', 'parameter-estimation']"
32,Family of transformations can I find a density function?,Family of transformations can I find a density function?,,"Let's consider the family of transformations given by $$g_a(Y)=\begin{cases} \frac{e^{aY}-1}{a} & \text{ for } a\neq 0 \\ Y & \text{ for } a=0  \end{cases}$$ for $Y\in\mathbb{R}$ . Analogous to the estimation of the Box-Cox parameter $\lambda$ , the parameter $a\in\mathbb{R}$ can be estimated using a profile likelihood approach. Let $Y_1,...,Y_n\in\mathbb{R}$ be independent responses together with corresponding predictors $\mathbf{x}_1,...,\mathbf{x}_n\in\mathbb{R}^n$ . We assume for $a$ that there exist $\textbf{b}\in\mathbb{R}^p$ and $\sigma^2>0$ such that $g_a(Y_i)\sim N(\textbf{x}_i^T \textbf{b},\sigma^2)$ for $i=1,...,n$ . Here is my questions: Can we derive such a density function $f_Y$ of the untransformed observations $Y_i$ . If so, would it be $$f_{Y_i}(\textbf{x})=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{1}{2}\cdot \frac{(\textbf{x}-\textbf{x}_i^T\textbf{b})^2}{\sigma^2}}$$ How would we find the log-likelihood function $\ell(a,b,\sigma^2;y_1,...,y_n)$ ? I know that $\sum_{i=1}^n \log(f_{Y_i}(y_i))$ . Thanks in advance.","Let's consider the family of transformations given by for . Analogous to the estimation of the Box-Cox parameter , the parameter can be estimated using a profile likelihood approach. Let be independent responses together with corresponding predictors . We assume for that there exist and such that for . Here is my questions: Can we derive such a density function of the untransformed observations . If so, would it be How would we find the log-likelihood function ? I know that . Thanks in advance.","g_a(Y)=\begin{cases}
\frac{e^{aY}-1}{a} & \text{ for } a\neq 0 \\
Y & \text{ for } a=0 
\end{cases} Y\in\mathbb{R} \lambda a\in\mathbb{R} Y_1,...,Y_n\in\mathbb{R} \mathbf{x}_1,...,\mathbf{x}_n\in\mathbb{R}^n a \textbf{b}\in\mathbb{R}^p \sigma^2>0 g_a(Y_i)\sim N(\textbf{x}_i^T \textbf{b},\sigma^2) i=1,...,n f_Y Y_i f_{Y_i}(\textbf{x})=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{1}{2}\cdot \frac{(\textbf{x}-\textbf{x}_i^T\textbf{b})^2}{\sigma^2}} \ell(a,b,\sigma^2;y_1,...,y_n) \sum_{i=1}^n \log(f_{Y_i}(y_i))","['statistics', 'normal-distribution', 'transformation', 'log-likelihood']"
33,Derivation of the exponential distribution from a process with instantaneous probabilities,Derivation of the exponential distribution from a process with instantaneous probabilities,,"Assume we have a process $X$ with two states: $x_1$ and $x_0$ . The process itself is a Markov Process, so its behaviour depends only on the current state, and thus, it can be described by a transition matrix containing the instantaneous probabilities of transition between states. This matrix is usually written as: $$Q_X = \begin{pmatrix}-q_{x_0} & q_{x_0x_1}\\ q_{x_1x_0} & -q_{x_1}\end{pmatrix},$$ where the elements $q_{x_ix_j}$ stand for the probability of transition from state $x_i$ to state $x_j$ provided a transition from the $x_i$ state, and the elements in the diagonal describe the probability on remaining in a state, and are computed such that each row sums up to zero. I know that, in theory, the probability distribution of remaining in a certain state is an exponential. This can be proved by taking the instant probability of transition from $x_i$ to $x_j$ , $p_{x_ix_j}$ which is the probability of transition in $\delta t$ as $\delta t \rightarrow 0$ . In an interval of time $[0,T]$ and with $X(t=0)=x_i$ , the probability of remaining in the same state up to $t=T$ can be expressed as an infinite product of the probability of not transitioning in infinitely many smaller intervals: $$P(\textrm{not transitioning from }X(0)=x_i\textrm{ to }X(T)=x_i) = \lim_{n \rightarrow \infty}\prod_{i=0}^n(1-p_{x_ix_j}\frac{T}{n})=\lim_{n \rightarrow \infty}(1-p_{x_ix_j}\frac{T}{n})^n.$$ The last limit is the definition of the exponential, so, finally: $$P(\textrm{not transitioning from }X(0)=x_i\textrm{ to }X(T)=x_i)=e^{-p{x_ix_j}T}.$$ So far so good, but I can't figure out why the following reasoning is wrong: Instead of taking the instantaneousprobability of transitioning, let's try to get the same result from the instantaneous probability of remaining in the same state, $p_{x_i}$ , which should be $p_{x_i} = 1-p_{x_ix_j}$ (as there are only two states in this scenario). Clearly we can follow the same strategy again: $$P(\textrm{not transitioning from }X(0)=x_i\textrm{ to }X(T)=x_i) = \lim_{n \rightarrow \infty}\prod_{i=0}^n(p_{x_i}\frac{T}{n})=\lim_{n \rightarrow \infty}(p_{x_i}\frac{T}{n})^n,$$ but this time it is clear that the limit approaches $0$ as $n \rightarrow \infty$ , and even if we substitute $p_{x_i} = 1-p_{x_ix_j}$ , the limit vanishes as well. I know there's something phishy about $p_{x_i} = 1-p_{x_ix_j}$ , since it would be fixed in the case that this relation only held when multiplying the instantaneous probabilities by $\delta t = \frac{T}{n}$ , the infinitesimally small interval of time in which they are applied, but on the other hand this would mean that the instantaneous probabilities don't sum up to one, which bugs me as well. I will appreciate any information on the subject, even as sources to check. Thank you in advance.","Assume we have a process with two states: and . The process itself is a Markov Process, so its behaviour depends only on the current state, and thus, it can be described by a transition matrix containing the instantaneous probabilities of transition between states. This matrix is usually written as: where the elements stand for the probability of transition from state to state provided a transition from the state, and the elements in the diagonal describe the probability on remaining in a state, and are computed such that each row sums up to zero. I know that, in theory, the probability distribution of remaining in a certain state is an exponential. This can be proved by taking the instant probability of transition from to , which is the probability of transition in as . In an interval of time and with , the probability of remaining in the same state up to can be expressed as an infinite product of the probability of not transitioning in infinitely many smaller intervals: The last limit is the definition of the exponential, so, finally: So far so good, but I can't figure out why the following reasoning is wrong: Instead of taking the instantaneousprobability of transitioning, let's try to get the same result from the instantaneous probability of remaining in the same state, , which should be (as there are only two states in this scenario). Clearly we can follow the same strategy again: but this time it is clear that the limit approaches as , and even if we substitute , the limit vanishes as well. I know there's something phishy about , since it would be fixed in the case that this relation only held when multiplying the instantaneous probabilities by , the infinitesimally small interval of time in which they are applied, but on the other hand this would mean that the instantaneous probabilities don't sum up to one, which bugs me as well. I will appreciate any information on the subject, even as sources to check. Thank you in advance.","X x_1 x_0 Q_X = \begin{pmatrix}-q_{x_0} & q_{x_0x_1}\\
q_{x_1x_0} & -q_{x_1}\end{pmatrix}, q_{x_ix_j} x_i x_j x_i x_i x_j p_{x_ix_j} \delta t \delta t \rightarrow 0 [0,T] X(t=0)=x_i t=T P(\textrm{not transitioning from }X(0)=x_i\textrm{ to }X(T)=x_i) = \lim_{n \rightarrow \infty}\prod_{i=0}^n(1-p_{x_ix_j}\frac{T}{n})=\lim_{n \rightarrow \infty}(1-p_{x_ix_j}\frac{T}{n})^n. P(\textrm{not transitioning from }X(0)=x_i\textrm{ to }X(T)=x_i)=e^{-p{x_ix_j}T}. p_{x_i} p_{x_i} = 1-p_{x_ix_j} P(\textrm{not transitioning from }X(0)=x_i\textrm{ to }X(T)=x_i) = \lim_{n \rightarrow \infty}\prod_{i=0}^n(p_{x_i}\frac{T}{n})=\lim_{n \rightarrow \infty}(p_{x_i}\frac{T}{n})^n, 0 n \rightarrow \infty p_{x_i} = 1-p_{x_ix_j} p_{x_i} = 1-p_{x_ix_j} \delta t = \frac{T}{n}","['probability', 'statistics', 'markov-process', 'exponential-distribution']"
34,Distance distribution in different dimensions,Distance distribution in different dimensions,,"This is a crosspost from this question on stackoverflow. It received no answers because ""it is a math question"". I don't know how to move so I crosspost. There are so many questions about distance distributions and the curse of dimensionality I did not read them all. But those that I did read, did not answer my question. I want to create the distance distribution of uniformly distributed points in different dimensions, to ultimately visualize the curse of dimensionality. My understanding is that the distribution goes from a flatter curve in low dimensions to a spike curve in higher dimensions. They look like this: Mean increases, variance decreases. Don't mind numbers, this is just a sketch (with gaussian distribution) I have seen corresponding figures in papers. (Would be able to show and cite, but not sure about copyrights.) I want to recreate those figures. But when I create random points calculate the distances and put them in to a histgram it looks like this: The first one is the plain histogram of distances. The second one, the bin are scaled to the max distance of the repective dimensions. In the third one I overlayed them by subtracting the value of the lowest non-empty bin. The first one obviously has the means, but neither increasing height nor decreasing variance. In the second you can see the concentration of the distances, but not height or means. This is not what I saw in those papers. The third indicates that the curves have all the same shape. Again, not what I expected. This is the code I used to create the second figure. import math import numpy as np import matplotlib.pyplot as plt from scipy.spatial import distance  if __name__ == '__main__':     records = 1000     binwidth = 0.01     precision = 10     fig, ((ax1), (ax2), (ax3)) = plt.subplots(3, 1)     fig.set_size_inches(6, 10)     for dimensions in [2, 10, 100, 1000]:         data = np.random.uniform(low=0, high=1, size=(records, dimensions))         data = np.around(data, decimals=precision)         distlist = distance.pdist(data)          variance = np.var(distlist)         print('dim {dim}: var={var}'.format(dim=dimensions, var=variance))          maxdist = math.pow(dimensions, 1 / 2)         bins = [round(x * binwidth, 2) for x in range(round(maxdist / binwidth) + 2)]         histo = np.histogram(distlist, bins)          harr = np.stack((histo[1][1:], histo[0]), axis=-1)         mask = harr[:, 1] > 0          masked = harr[mask]         ax1.plot(masked[:, 0], masked[:, 1], label='dim {dim}'.format(dim=dimensions))         ax2.plot(masked[:, 0] / maxdist, masked[:, 1], label='dim {dim}'.format(dim=dimensions))         min = np.min(masked[:, 0])         ax3.plot(masked[:, 0] - min, masked[:, 1], label='dim {dim}'.format(dim=dimensions))     ax1.set_title('histogram')     ax1.legend()      ax2.set_title('histogram, bins divided by max distance')     ax2.legend()      ax3.set_title('histogram, bin subtracted by minimum bin')     ax3.legend()     plt.show() I see two points where I may be wrong. My understanding of distance distributions the code does not what it's intended to do How do I draw a histogram with bins of width 0.01 showing the number of distances between pairs of uniformly distributed points in the unit cube? EDIT Ok, thanks to @Henry it seems what I did was correct but not what I should have done to produce the results I wanted. What I want is the to produce the following figures myself. The image is taken from Pestov, Vladimir (2007): Intrinsic dimension of a dataset: what  properties does one expect? In : 2007 IEEE International Joint Conference on Neural Networks Proceedings. International Joint Conference on Neural Networks. Fig. 14 of Chávez, Edgar; Navarro, Gonzalo; Baeza-Yates, Ricardo; Marroqu\’ın, José Luis (2001): Searching in metric spaces. In ACM Computing Surveys 33 (3), pp. 273–321. DOI: 10.1145/502807.502808. is a similar one. The text does not describe how to create them. How can I do this?","This is a crosspost from this question on stackoverflow. It received no answers because ""it is a math question"". I don't know how to move so I crosspost. There are so many questions about distance distributions and the curse of dimensionality I did not read them all. But those that I did read, did not answer my question. I want to create the distance distribution of uniformly distributed points in different dimensions, to ultimately visualize the curse of dimensionality. My understanding is that the distribution goes from a flatter curve in low dimensions to a spike curve in higher dimensions. They look like this: Mean increases, variance decreases. Don't mind numbers, this is just a sketch (with gaussian distribution) I have seen corresponding figures in papers. (Would be able to show and cite, but not sure about copyrights.) I want to recreate those figures. But when I create random points calculate the distances and put them in to a histgram it looks like this: The first one is the plain histogram of distances. The second one, the bin are scaled to the max distance of the repective dimensions. In the third one I overlayed them by subtracting the value of the lowest non-empty bin. The first one obviously has the means, but neither increasing height nor decreasing variance. In the second you can see the concentration of the distances, but not height or means. This is not what I saw in those papers. The third indicates that the curves have all the same shape. Again, not what I expected. This is the code I used to create the second figure. import math import numpy as np import matplotlib.pyplot as plt from scipy.spatial import distance  if __name__ == '__main__':     records = 1000     binwidth = 0.01     precision = 10     fig, ((ax1), (ax2), (ax3)) = plt.subplots(3, 1)     fig.set_size_inches(6, 10)     for dimensions in [2, 10, 100, 1000]:         data = np.random.uniform(low=0, high=1, size=(records, dimensions))         data = np.around(data, decimals=precision)         distlist = distance.pdist(data)          variance = np.var(distlist)         print('dim {dim}: var={var}'.format(dim=dimensions, var=variance))          maxdist = math.pow(dimensions, 1 / 2)         bins = [round(x * binwidth, 2) for x in range(round(maxdist / binwidth) + 2)]         histo = np.histogram(distlist, bins)          harr = np.stack((histo[1][1:], histo[0]), axis=-1)         mask = harr[:, 1] > 0          masked = harr[mask]         ax1.plot(masked[:, 0], masked[:, 1], label='dim {dim}'.format(dim=dimensions))         ax2.plot(masked[:, 0] / maxdist, masked[:, 1], label='dim {dim}'.format(dim=dimensions))         min = np.min(masked[:, 0])         ax3.plot(masked[:, 0] - min, masked[:, 1], label='dim {dim}'.format(dim=dimensions))     ax1.set_title('histogram')     ax1.legend()      ax2.set_title('histogram, bins divided by max distance')     ax2.legend()      ax3.set_title('histogram, bin subtracted by minimum bin')     ax3.legend()     plt.show() I see two points where I may be wrong. My understanding of distance distributions the code does not what it's intended to do How do I draw a histogram with bins of width 0.01 showing the number of distances between pairs of uniformly distributed points in the unit cube? EDIT Ok, thanks to @Henry it seems what I did was correct but not what I should have done to produce the results I wanted. What I want is the to produce the following figures myself. The image is taken from Pestov, Vladimir (2007): Intrinsic dimension of a dataset: what  properties does one expect? In : 2007 IEEE International Joint Conference on Neural Networks Proceedings. International Joint Conference on Neural Networks. Fig. 14 of Chávez, Edgar; Navarro, Gonzalo; Baeza-Yates, Ricardo; Marroqu\’ın, José Luis (2001): Searching in metric spaces. In ACM Computing Surveys 33 (3), pp. 273–321. DOI: 10.1145/502807.502808. is a similar one. The text does not describe how to create them. How can I do this?",,['statistics']
35,Bayesian posterior probability and conditional probability,Bayesian posterior probability and conditional probability,,"This is a homework exercise but I am stuck, and I believe there is something basic that is still confusing me. This is the problem: There is a test for a new illness. The lab who developed did the following: To determine the false positive rate they tested 3000 known negative samples and got 15 positive results. To determine the false negative rate they tested 200 known positive samples and got 30 negative results. Then they tested 4000 people and got 60 positive results. Determine the posterior distribution on the true incidence, marginalizing over false positive and false negative rates. Assume flat priors on all parameters. My work From point (1) I can easily get a posterior distribution on the false positive rate, $p_{fp}$ : $$ f(p_{fp}|\text{data}) = \frac{P(\text{data}|p_{fp})}{\int_0^\infty P(\text{data}|p_{fp})} $$ where $P(\text{data}|p_{fp})$ is just a binomial distribution with 15 successes, 3000 trials, and probability of success $p_{fp}$ . I can then do exactly the same and get a posterior distribution for the false negative rate. My problem is that I don't know how to move forward )use this information) to get the posterior on the true incidence. Is this what I am supposed to compute? $$ P(N \text{ positive}|\text{60 positive out of 4000}) = \frac{P(\text{outcome}|\text{incidence})}{\sum_{n=0}^{4000}P(\text{outcome}|\text{incidence})} $$ If this is truly what I need to calculate, how do my posterior distributions on false-positive and false-negative used here? I think I am a bit confused on how to proceed, but hopefully I am not too lost.","This is a homework exercise but I am stuck, and I believe there is something basic that is still confusing me. This is the problem: There is a test for a new illness. The lab who developed did the following: To determine the false positive rate they tested 3000 known negative samples and got 15 positive results. To determine the false negative rate they tested 200 known positive samples and got 30 negative results. Then they tested 4000 people and got 60 positive results. Determine the posterior distribution on the true incidence, marginalizing over false positive and false negative rates. Assume flat priors on all parameters. My work From point (1) I can easily get a posterior distribution on the false positive rate, : where is just a binomial distribution with 15 successes, 3000 trials, and probability of success . I can then do exactly the same and get a posterior distribution for the false negative rate. My problem is that I don't know how to move forward )use this information) to get the posterior on the true incidence. Is this what I am supposed to compute? If this is truly what I need to calculate, how do my posterior distributions on false-positive and false-negative used here? I think I am a bit confused on how to proceed, but hopefully I am not too lost.","p_{fp} 
f(p_{fp}|\text{data}) = \frac{P(\text{data}|p_{fp})}{\int_0^\infty P(\text{data}|p_{fp})}
 P(\text{data}|p_{fp}) p_{fp} 
P(N \text{ positive}|\text{60 positive out of 4000}) = \frac{P(\text{outcome}|\text{incidence})}{\sum_{n=0}^{4000}P(\text{outcome}|\text{incidence})}
","['statistics', 'conditional-probability', 'bayesian', 'bayes-theorem']"
36,How to show that sampling from correlated fraction PDFs does not reproduce correlations?,How to show that sampling from correlated fraction PDFs does not reproduce correlations?,,"Let's assume that we have $N$ layers over which a quantity X is distributed, i.e. $X = \sum_{i=1}^{N} X_i$ for each 'data point'. Now, we know how the Probability Density Function $f(X)$ of the overall quantity as well as the Probability Denity Function of the fraction in each layer $g(X_i^{\mathrm{frac}})$ with $X_i^{\mathrm{frac}}=\frac{X_i}{X}$ look. We also know that the correlations of $X_i$ are not zero, i.e. $\rho(X_i, X_j) \neq 0$ . How can I concisely show that if I would just sample data from the fraction PDFs $g(X_i^{\mathrm{frac}})$ and the total PDF $f(X)$ with the constrain of the fractions always summing up to $X$ , it would not be possible to reproduce the original correlations. Hope this was clear!","Let's assume that we have layers over which a quantity X is distributed, i.e. for each 'data point'. Now, we know how the Probability Density Function of the overall quantity as well as the Probability Denity Function of the fraction in each layer with look. We also know that the correlations of are not zero, i.e. . How can I concisely show that if I would just sample data from the fraction PDFs and the total PDF with the constrain of the fractions always summing up to , it would not be possible to reproduce the original correlations. Hope this was clear!","N X = \sum_{i=1}^{N} X_i f(X) g(X_i^{\mathrm{frac}}) X_i^{\mathrm{frac}}=\frac{X_i}{X} X_i \rho(X_i, X_j) \neq 0 g(X_i^{\mathrm{frac}}) f(X) X","['probability', 'statistics', 'probability-distributions', 'correlation']"
37,Normalizing Flow Penalization,Normalizing Flow Penalization,,"I am looking to fit a normalizing flow, specifically a Masked Autoregressive Flow model. However, this model leads to high variance on lower dimensional, less complex data. I am using a neural network to parameterize the scale and shift components of the MAF. I think we need to smooth the loss surface, i.e., the log likelihood of the normalizing flow. Is there any literature outlining good ideas or what would be a good starting point? More generally, are there any papers that have a solid theoretical foundation to defining a penalty that can smooth something like a normalizing flow?","I am looking to fit a normalizing flow, specifically a Masked Autoregressive Flow model. However, this model leads to high variance on lower dimensional, less complex data. I am using a neural network to parameterize the scale and shift components of the MAF. I think we need to smooth the loss surface, i.e., the log likelihood of the normalizing flow. Is there any literature outlining good ideas or what would be a good starting point? More generally, are there any papers that have a solid theoretical foundation to defining a penalty that can smooth something like a normalizing flow?",,"['statistics', 'optimization', 'machine-learning']"
38,"$n$ voters ranks $m$ candidates, what is the probability of the Smith set having cardinality $k$?","voters ranks  candidates, what is the probability of the Smith set having cardinality ?",n m k,"Let’s say there are $n$ voters who vote on $m$ candidates. Each voter creates a list where they rank the candidates from most favorite to least favorite. There are $m!$ different possible lists each of them could have made, so there are $m!^n$ possible events. From each event you can define a unique Smith set . Let $f(n,m,k)$ be the amount of events with $n$ voters and $m$ candidates where the Smith set has cardinality $k$ , how can I define this function? Some additional info: $f(n,m,1) + f(n,m,2) + \ldots + f(n,m,m) = m!^n$ $f(n,m,a)=0$ when $a>m$ or $a<1$ The motivation behind the question is that $f(n,m,k)/m!^n$ is the probability of ending up with $k$ winners in a ranked choice vote where you consider the candidates in the Smith set as winners. I want to choose an $n$ and $m$ and plot $f(n,m,k)/m!^n$ where $k$ varies from 1 to $m$ to see the probability of getting different amount of winners depending on the $n$ and $m$ I choose.","Let’s say there are voters who vote on candidates. Each voter creates a list where they rank the candidates from most favorite to least favorite. There are different possible lists each of them could have made, so there are possible events. From each event you can define a unique Smith set . Let be the amount of events with voters and candidates where the Smith set has cardinality , how can I define this function? Some additional info: when or The motivation behind the question is that is the probability of ending up with winners in a ranked choice vote where you consider the candidates in the Smith set as winners. I want to choose an and and plot where varies from 1 to to see the probability of getting different amount of winners depending on the and I choose.","n m m! m!^n f(n,m,k) n m k f(n,m,1) + f(n,m,2) + \ldots + f(n,m,m) = m!^n f(n,m,a)=0 a>m a<1 f(n,m,k)/m!^n k n m f(n,m,k)/m!^n k m n m","['combinatorics', 'statistics', 'voting-theory']"
39,"HMM, reverse engineering the transition matrix","HMM, reverse engineering the transition matrix",,"I fitted a 2-states-HMM model last week, and generate a bunch of 1s and 0s, but I forgot to store its parameters (transition matrix). Now, I only got these 1s and 0s, how do I backward/reverse-engineering to estimates these transition matrix? Things that I have : the input data the outputed 0s and 1s from a fitted 2-states-HMM What I want : The transition matrix of the two-states HMM model. Please see the exact input and output data here: https://colab.research.google.com/drive/1N-PKaeHMVI4S1VU7fgcgDqRT5L3h8R0L?usp=sharing And go to the bottom which it says Input_data and Output_data","I fitted a 2-states-HMM model last week, and generate a bunch of 1s and 0s, but I forgot to store its parameters (transition matrix). Now, I only got these 1s and 0s, how do I backward/reverse-engineering to estimates these transition matrix? Things that I have : the input data the outputed 0s and 1s from a fitted 2-states-HMM What I want : The transition matrix of the two-states HMM model. Please see the exact input and output data here: https://colab.research.google.com/drive/1N-PKaeHMVI4S1VU7fgcgDqRT5L3h8R0L?usp=sharing And go to the bottom which it says Input_data and Output_data",,"['statistics', 'statistical-inference', 'parameter-estimation', 'hidden-markov-models']"
40,Conditional joint density based on the sum,Conditional joint density based on the sum,,"Let $X$ , $Y$ , $Z$ be independent random variables that have a (positive) joint density $f_{XYZ}$ with respect to the Lebesgue measure on $\mathbb{R}^3$ , with positive marginals $f_X$ , $f_Y$ , $f_Z$ . How do we obtain the density $(X,Y,Z)$ conditional on $X+Y+Z$ ? The joint density of $(X,Y)$ conditional on $X+Y+Z$ seems to be doable based on the strategy in this question: Conditional density of Sum of two independent and continuous random variables but in this question, the change of variables and the explicit calculation of the Jacobian seems to be important, and I don't know how to apply this here. Example using e.g. Gaussian random variable would be much appreciated.","Let , , be independent random variables that have a (positive) joint density with respect to the Lebesgue measure on , with positive marginals , , . How do we obtain the density conditional on ? The joint density of conditional on seems to be doable based on the strategy in this question: Conditional density of Sum of two independent and continuous random variables but in this question, the change of variables and the explicit calculation of the Jacobian seems to be important, and I don't know how to apply this here. Example using e.g. Gaussian random variable would be much appreciated.","X Y Z f_{XYZ} \mathbb{R}^3 f_X f_Y f_Z (X,Y,Z) X+Y+Z (X,Y) X+Y+Z","['statistics', 'random-variables', 'conditional-probability']"
41,Different Types of Markov Chains?,Different Types of Markov Chains?,,"I have been trying to learn more about different types of Markov Chains. So far, here is my basic understanding of them: Discrete Time Markov Chain: Characterized by a constant transition probability matrix ""P"" Continuous Time Markov Chain: Characterized by a time dependent transition probability matrix ""P(t)"" and a constant infinitesimal generator matrix ""Q"". The Continuous Time Markov Chain is based on the Exponential Distribution and thereby must obey the Memoryless Property. Non Homogenous Continuous Time Markov Chain: Characterized by a time dependent transition probability matrix ""P(t)"" and a time dependent infinitesimal generator matrix ""Q(t)"". Non Homogenous Continuous Time Markov Chains are not necessarily based on the Exponential Distribution and thereby do not need to obey the Memoryless Property. This brings me to my question - given the above information, I am having difficulty understanding the difference between these Markov Chains and a Semi-Markov Process. Based on some readings that I have done, it seems like a Semi Markov Process is characterized by its ""Sojourn Time"" - that is, the amount of time that is spent in some state. Since the probability distribution of this ""Sojourn Time"" does not necessarily need to be Exponentially Distributed, a Semi Markov Process does not need to obey the Memoryless Property. If this is the case, then how exactly is the Semi-Markov Process different from a Non Homogenous Continuous Time Markov Chain? Can someone please help me understand this? Perhaps some example could illustrate in which conditions it might be more advantageous to use a Semi-Markov Process compared to a Continuous Markov Process and vice versa? Thanks! Note: I am currently reading this reference : Difference between non-homogeneous Markov and Semi-Markov? Note 1: I understand that as the name suggests, ""Semi-Markov"" does not need to obey the ""Markov Property"" . That is, in Semi-Markov, the future states that the process can go to does not only depend on the current state, and can also depend on the history of the process. This is in contrast to a Continuous Markov Process in which the Markov Property must be obeyed , and the future state of a Continuous Markov Process can only depend on the current state. Note 2: I am told that one of the differences between Semi-Markov and Markov is how the notion of time is recorded. In a Continuous Markov Process, time is recorded in the ""clock forward"" format - this means that all time transitions are recorded from some initial time. In a Semi Markov Process, time is recorded in the ""clock reset"" format - this means that the clock is restarted every time a transition is recorded. Supposedly, ""clock forward"" is not able to take into consideration the history of the Markov Process - whereas ""clock reset"" is able to take into consideration the history of the Markov Process. However, I do not understand this point - I am not sure as to why recording time using different formats ""magically"" allows the Markov Process to consider the history or not to consider the history of the process. Note 3: It seems to me like a Semi Markov Process is closer to a ""Discrete Markov Chain"" : If my understanding is correct, a Semi Markov Process does not have a P(t) matrix or any type of Q matrix - a Semi Markov Process only has a time independent P matrix. Is this correct? Note 4: Again, if my understanding is correct, it seems as though a Semi Markov Process might not be as useful for modelling real world phenomena compared to a Continuous Markov Process (i.e. when modelling a person transitioning between medical condition, it will likely be useful to know the history of how long he has been healthy or sick) - with this being said, in what kinds of situations is it useful to use  Semi Markov Processes?","I have been trying to learn more about different types of Markov Chains. So far, here is my basic understanding of them: Discrete Time Markov Chain: Characterized by a constant transition probability matrix ""P"" Continuous Time Markov Chain: Characterized by a time dependent transition probability matrix ""P(t)"" and a constant infinitesimal generator matrix ""Q"". The Continuous Time Markov Chain is based on the Exponential Distribution and thereby must obey the Memoryless Property. Non Homogenous Continuous Time Markov Chain: Characterized by a time dependent transition probability matrix ""P(t)"" and a time dependent infinitesimal generator matrix ""Q(t)"". Non Homogenous Continuous Time Markov Chains are not necessarily based on the Exponential Distribution and thereby do not need to obey the Memoryless Property. This brings me to my question - given the above information, I am having difficulty understanding the difference between these Markov Chains and a Semi-Markov Process. Based on some readings that I have done, it seems like a Semi Markov Process is characterized by its ""Sojourn Time"" - that is, the amount of time that is spent in some state. Since the probability distribution of this ""Sojourn Time"" does not necessarily need to be Exponentially Distributed, a Semi Markov Process does not need to obey the Memoryless Property. If this is the case, then how exactly is the Semi-Markov Process different from a Non Homogenous Continuous Time Markov Chain? Can someone please help me understand this? Perhaps some example could illustrate in which conditions it might be more advantageous to use a Semi-Markov Process compared to a Continuous Markov Process and vice versa? Thanks! Note: I am currently reading this reference : Difference between non-homogeneous Markov and Semi-Markov? Note 1: I understand that as the name suggests, ""Semi-Markov"" does not need to obey the ""Markov Property"" . That is, in Semi-Markov, the future states that the process can go to does not only depend on the current state, and can also depend on the history of the process. This is in contrast to a Continuous Markov Process in which the Markov Property must be obeyed , and the future state of a Continuous Markov Process can only depend on the current state. Note 2: I am told that one of the differences between Semi-Markov and Markov is how the notion of time is recorded. In a Continuous Markov Process, time is recorded in the ""clock forward"" format - this means that all time transitions are recorded from some initial time. In a Semi Markov Process, time is recorded in the ""clock reset"" format - this means that the clock is restarted every time a transition is recorded. Supposedly, ""clock forward"" is not able to take into consideration the history of the Markov Process - whereas ""clock reset"" is able to take into consideration the history of the Markov Process. However, I do not understand this point - I am not sure as to why recording time using different formats ""magically"" allows the Markov Process to consider the history or not to consider the history of the process. Note 3: It seems to me like a Semi Markov Process is closer to a ""Discrete Markov Chain"" : If my understanding is correct, a Semi Markov Process does not have a P(t) matrix or any type of Q matrix - a Semi Markov Process only has a time independent P matrix. Is this correct? Note 4: Again, if my understanding is correct, it seems as though a Semi Markov Process might not be as useful for modelling real world phenomena compared to a Continuous Markov Process (i.e. when modelling a person transitioning between medical condition, it will likely be useful to know the history of how long he has been healthy or sick) - with this being said, in what kinds of situations is it useful to use  Semi Markov Processes?",,"['probability', 'statistics', 'markov-chains', 'markov-process']"
42,Quadratic Approximation for Log-Likelihood Ratio Processes,Quadratic Approximation for Log-Likelihood Ratio Processes,,"I'm trying to understand why the quadratic equation can approximate the log likelihood ratio , and how it is derived: $$\mathrm{Log}(\mathrm{LR})=\frac{1}{2}\left(\frac{\mathrm{MLE}-\theta}{S}\right)^2$$ Is this approximated using Taylor's series or normal distribution equation or anything else? Using Taylor's expansion, I get $ -\frac{1}{2}(MLE-\theta)^2 (\frac{1}{\theta^2}+\frac{1}{MLE^2})$ , instead of $ -\frac{1}{2}(\frac{MLE-\theta}{S})^2$ This was brought up in book 'Essential Medical statistics' Chapter $28$ , the main goal was to derive a supported range (similar to the $95\%$ CI) for the likelihood ratio. It was mentioned in the book that the log of the likelihood ratio (LR) is used instead of the likelihood itself, because the $\log(\mathrm{LR})$ can be approximated by a quadratic equation (the one shown above), for easier calculation. It is also said that this equation is chosen so as to meet the curve of and to have the same curvature as the $\log(\mathrm{LR})$ at the MLE .","I'm trying to understand why the quadratic equation can approximate the log likelihood ratio , and how it is derived: Is this approximated using Taylor's series or normal distribution equation or anything else? Using Taylor's expansion, I get , instead of This was brought up in book 'Essential Medical statistics' Chapter , the main goal was to derive a supported range (similar to the CI) for the likelihood ratio. It was mentioned in the book that the log of the likelihood ratio (LR) is used instead of the likelihood itself, because the can be approximated by a quadratic equation (the one shown above), for easier calculation. It is also said that this equation is chosen so as to meet the curve of and to have the same curvature as the at the MLE .",\mathrm{Log}(\mathrm{LR})=\frac{1}{2}\left(\frac{\mathrm{MLE}-\theta}{S}\right)^2  -\frac{1}{2}(MLE-\theta)^2 (\frac{1}{\theta^2}+\frac{1}{MLE^2})  -\frac{1}{2}(\frac{MLE-\theta}{S})^2 28 95\% \log(\mathrm{LR}) \log(\mathrm{LR}),"['statistics', 'quadratics', 'log-likelihood']"
43,What is the intuition behind using the harmonic mean?,What is the intuition behind using the harmonic mean?,,Why do we sometimes prefer the harmonic mean to the arithmetic mean? When is it more relevant to use the former than the latter?,Why do we sometimes prefer the harmonic mean to the arithmetic mean? When is it more relevant to use the former than the latter?,,"['statistics', 'average', 'means']"
44,Inverse of the transform in the Box-Muller transform,Inverse of the transform in the Box-Muller transform,,"I am following this writeup of the Box-Muller method but I am confused how they derived the inverse. In this method, they write Box-Muller Algorithm is a classic method to generate identical and independent standard normal random variables. Box-Muller Algorithm Generate $U_{1} \sim$ uniform $(0,1)$ and $U_{2} \sim$ uniform $(0,1)$ where $U_{1} \perp U_{2}$ Set $R=\sqrt{-2 \log \left(U_{1}\right)}$ and $\theta=2 \pi U_{2}$ Set $X=R \cos (\theta)$ and $Y=R \sin (\theta)$ Overall, $$ \begin{aligned} &X=\sqrt{-2 \log U_{1}} \cos \left(2 \pi U_{2}\right) \ &Y=\sqrt{-2 \log U_{1}} \sin \left(2 \pi U_{2}\right) \end{aligned} This can be verified by solving $U_{1}$ and $U_{2}$, \begin{aligned} &U_{1}=e^{-\left(X^{2}+Y^{2}\right) / 2} \ &U_{2}=\frac{1}{2 \pi} \arctan \left(\frac{X}{Y}\right) \end{aligned} I am trying to understand how exactly the inverse of $X=\sqrt{-2 \log U_{1}} \cos \left(2 \pi U_{2}\right)$ and $Y=\sqrt{-2 \log U_{1}} \sin \left(2 \pi U_{2}\right)$ was computed, i.e. $$ \begin{aligned} &U_{1}=e^{-\left(X^{2}+Y^{2}\right) / 2} \\ &U_{2}=\frac{1}{2 \pi} \arctan \left(\frac{X}{Y}\right) \end{aligned} $$ Looking at these formulas, I can't directly compute it so I'm not sure how they came up with their result.","I am following this writeup of the Box-Muller method but I am confused how they derived the inverse. In this method, they write Box-Muller Algorithm is a classic method to generate identical and independent standard normal random variables. Box-Muller Algorithm Generate uniform and uniform where Set and Set and Overall, $$ \begin{aligned} &X=\sqrt{-2 \log U_{1}} \cos \left(2 \pi U_{2}\right) \ &Y=\sqrt{-2 \log U_{1}} \sin \left(2 \pi U_{2}\right) \end{aligned} This can be verified by solving $U_{1}$ and $U_{2}$, \begin{aligned} &U_{1}=e^{-\left(X^{2}+Y^{2}\right) / 2} \ &U_{2}=\frac{1}{2 \pi} \arctan \left(\frac{X}{Y}\right) \end{aligned} I am trying to understand how exactly the inverse of and was computed, i.e. Looking at these formulas, I can't directly compute it so I'm not sure how they came up with their result.","U_{1} \sim (0,1) U_{2} \sim (0,1) U_{1} \perp U_{2} R=\sqrt{-2 \log \left(U_{1}\right)} \theta=2 \pi U_{2} X=R \cos (\theta) Y=R \sin (\theta) X=\sqrt{-2 \log U_{1}} \cos \left(2 \pi U_{2}\right) Y=\sqrt{-2 \log U_{1}} \sin \left(2 \pi U_{2}\right) 
\begin{aligned}
&U_{1}=e^{-\left(X^{2}+Y^{2}\right) / 2} \\
&U_{2}=\frac{1}{2 \pi} \arctan \left(\frac{X}{Y}\right)
\end{aligned}
","['real-analysis', 'calculus', 'probability', 'statistics', 'statistical-inference']"
45,"If Z is regularly varying with index $\alpha$, then $zP(Z>z)$ is decreasing [closed]","If Z is regularly varying with index , then  is decreasing [closed]",\alpha zP(Z>z),"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question i want to show: if $Z\geq0$ is regularly varying with index $\alpha$ , that the function $zP(Z>z)$ is decreasing. Def: A randomvariable $Z$ is regularly varying with index $\alpha>1$ if for all $t>0$ $\lim_{x\longrightarrow\infty}\frac{P(Z>tx)}{P(Z>x)}=t^{-\alpha}$ I tried to use the definition of an increasing function, but got stuck because i dont know where i can use the assumption, that $Z$ is reg.varying.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question i want to show: if is regularly varying with index , that the function is decreasing. Def: A randomvariable is regularly varying with index if for all I tried to use the definition of an increasing function, but got stuck because i dont know where i can use the assumption, that is reg.varying.",Z\geq0 \alpha zP(Z>z) Z \alpha>1 t>0 \lim_{x\longrightarrow\infty}\frac{P(Z>tx)}{P(Z>x)}=t^{-\alpha} Z,"['probability', 'statistics', 'probability-distributions']"
46,How can I find the probability of getting a Yahtzee using probability generating functions for each roll?,How can I find the probability of getting a Yahtzee using probability generating functions for each roll?,,"I was recently taught the concept of Probability Generating Functions (PGFs) and while revising said concept, I came across a question about the game Yahtzee. The question was as follows: Find the probability of achieving a Yahtzee made entirely of the number $k$ on five 6-sided dice after 3 rolls. You may assume the player achieving the Yahtzee removes all of the dice which rolled $k$ after each of the 3 rolls. Most of the answers I googled after attempting to solve this consisted of combinatorics and/or simply doing it manually or by using other ways I don't understand; however, while attempting to solve this using PGFs, I came across a curious problem in my method which I was unsure could be worked with, leading me to ask this question, this problem is explained below: Let $X$ be the number of 6-sided dice in a game of Yahtzee that land on the number $k$ in one roll. $X$ can be modelled binomially as $X \sim B(n,\frac{1}{6})$ for each throw where $n$ is the number of dice in each throw. The probability generating function for $X$ is $G_X(t) = (\frac{5}{6}+\frac{1}{6}t)^n$ Thus, for the first roll, the PGF is as follows: $G_{X_1}(t)=(\frac{5}{6}+\frac{1}{6}t)^5$ However, given the second roll is dependent on the amount of successes of the first roll, I would have to implement the first roll's outcome into the second roll's PGF: $G_{X_2}(t)=(\frac{5}{6}+\frac{1}{6}t)^{5-X_1}$ And the third roll would implement the same concept: $G_{X_3}(t)=(\frac{5}{6}+\frac{1}{6}t)^{5-X_1-X_2}$ This is not the answer I'm looking for since I would like $G_{X_3}(t)$ and $G_{X_2}(t)$ to be solely in terms of $t$ to then solve the question by finding the coefficient of $t^5$ . I would like to have the skill to manipulate embedded random variables in PGFs, thus my question is: If possible, how can I implement the PGF of a random variable into the PGF of another random variable? (A method which I can use to solve the above question for example)","I was recently taught the concept of Probability Generating Functions (PGFs) and while revising said concept, I came across a question about the game Yahtzee. The question was as follows: Find the probability of achieving a Yahtzee made entirely of the number on five 6-sided dice after 3 rolls. You may assume the player achieving the Yahtzee removes all of the dice which rolled after each of the 3 rolls. Most of the answers I googled after attempting to solve this consisted of combinatorics and/or simply doing it manually or by using other ways I don't understand; however, while attempting to solve this using PGFs, I came across a curious problem in my method which I was unsure could be worked with, leading me to ask this question, this problem is explained below: Let be the number of 6-sided dice in a game of Yahtzee that land on the number in one roll. can be modelled binomially as for each throw where is the number of dice in each throw. The probability generating function for is Thus, for the first roll, the PGF is as follows: However, given the second roll is dependent on the amount of successes of the first roll, I would have to implement the first roll's outcome into the second roll's PGF: And the third roll would implement the same concept: This is not the answer I'm looking for since I would like and to be solely in terms of to then solve the question by finding the coefficient of . I would like to have the skill to manipulate embedded random variables in PGFs, thus my question is: If possible, how can I implement the PGF of a random variable into the PGF of another random variable? (A method which I can use to solve the above question for example)","k k X k X X \sim B(n,\frac{1}{6}) n X G_X(t) = (\frac{5}{6}+\frac{1}{6}t)^n G_{X_1}(t)=(\frac{5}{6}+\frac{1}{6}t)^5 G_{X_2}(t)=(\frac{5}{6}+\frac{1}{6}t)^{5-X_1} G_{X_3}(t)=(\frac{5}{6}+\frac{1}{6}t)^{5-X_1-X_2} G_{X_3}(t) G_{X_2}(t) t t^5","['probability', 'statistics', 'probability-distributions']"
47,Integral of the deconvolution kernel density estimator,Integral of the deconvolution kernel density estimator,,"let $Y_i = m(X_i) + \eta_i$ , $W_j = X_j + U_j$ , $E[\eta_i | X_i] = 0$ with $X_i \sim f_X$ , $U_i \sim f_U$ be an errors-in-variable problem and $K_{U}(x) = \dfrac{1}{2 \pi} \int \mathrm{e}^{-itx} \dfrac{\phi_K(t)}{\phi_{U}(t/h)} \, dt$ with $\phi_K$ characteristic function of a Kernel and $U$ the characteristic function of the error-variable $U$ . I already solved the integral \begin{align} E \left[ \dfrac{1}{h} K_{U} \left(\dfrac{w - W_i}{h} \right)\right] &= \int E \left[ \mathrm{e}^{-it(w - W)/h}\right] \dfrac{\phi_K(t)}{\phi_{U}(t/h)} \,dt \\ &=\dfrac{1}{2 \pi} \int E \left[\mathrm{e}^{-iz(w - W)} \right] \dfrac{\phi_K(hz)}{\phi_{U}(z)} \, dz \\ &= \dfrac{1}{2 \pi} \int \phi_X(z) \phi_U(z) \mathrm{e}^{-izw} \dfrac{\phi_K(hz)}{\phi_{U}(z)} \, dz \\ &= \dfrac{1}{h} \int K\left( \dfrac{u - x}{h} \right) f_X(u) \, du \\ &= \int K(v) f_X(x + hv) \, dv \end{align} I substituted in the second line with $t = hz$ , $dt = h \, dz$ and used Plancherels theorem in the fourth line. Now I want to show that $$ E \left[ \dfrac{1}{h} K_{U} \left( \dfrac{x - W_i}{h} \right) \, (Y_i - m(x))  \right] = \int (m(x + hv) - m(x)) \, K(v) f_X(x + hv) \, dv,$$ which is nearly the same as above. Unfortunately I don't know how to handle the $Y_i$ .","let , , with , be an errors-in-variable problem and with characteristic function of a Kernel and the characteristic function of the error-variable . I already solved the integral I substituted in the second line with , and used Plancherels theorem in the fourth line. Now I want to show that which is nearly the same as above. Unfortunately I don't know how to handle the .","Y_i = m(X_i) + \eta_i W_j = X_j + U_j E[\eta_i | X_i] = 0 X_i \sim f_X U_i \sim f_U K_{U}(x) = \dfrac{1}{2 \pi} \int \mathrm{e}^{-itx} \dfrac{\phi_K(t)}{\phi_{U}(t/h)} \, dt \phi_K U U \begin{align}
E \left[ \dfrac{1}{h} K_{U} \left(\dfrac{w - W_i}{h} \right)\right] &= \int E \left[ \mathrm{e}^{-it(w - W)/h}\right] \dfrac{\phi_K(t)}{\phi_{U}(t/h)} \,dt \\
&=\dfrac{1}{2 \pi} \int E \left[\mathrm{e}^{-iz(w - W)} \right] \dfrac{\phi_K(hz)}{\phi_{U}(z)} \, dz \\
&= \dfrac{1}{2 \pi} \int \phi_X(z) \phi_U(z) \mathrm{e}^{-izw} \dfrac{\phi_K(hz)}{\phi_{U}(z)} \, dz \\
&= \dfrac{1}{h} \int K\left( \dfrac{u - x}{h} \right) f_X(u) \, du \\
&= \int K(v) f_X(x + hv) \, dv
\end{align} t = hz dt = h \, dz  E \left[ \dfrac{1}{h} K_{U} \left( \dfrac{x - W_i}{h} \right) \, (Y_i - m(x))  \right] = \int (m(x + hv) - m(x)) \, K(v) f_X(x + hv) \, dv, Y_i","['probability', 'integration', 'statistics', 'regression', 'characteristic-functions']"
48,Gap between two consecutive order statistics under arbitrary distribution.,Gap between two consecutive order statistics under arbitrary distribution.,,"Consider an arbitrary distribution $\mathcal{D}$ supported on $[a,b]$ with density function $\phi(x)\in[\gamma, \Gamma]$ where $\Gamma\geq \gamma>0$ . M i.i.d samples $\{d_i\}_{i=1}^M$ are drawn from $\mathcal{D}$ . Denote $\{d_{k_j}\}_{j=1}^M$ be the ordered sequence: $d_{k_1}\leq d_{k_2}\leq\ldots\leq d_{k_M}$ . I wonder whether we have some gap bound on $\max_{j\in [M]}|d_{k_j}-d_{k_{j-1}}|$ ? Specifically, I wonder what is the bound on $Pr(\max_{j\in [M]}|d_{k_j}-d_{k_{j-1}}|\geq \epsilon)$ . Thanks!","Consider an arbitrary distribution supported on with density function where . M i.i.d samples are drawn from . Denote be the ordered sequence: . I wonder whether we have some gap bound on ? Specifically, I wonder what is the bound on . Thanks!","\mathcal{D} [a,b] \phi(x)\in[\gamma, \Gamma] \Gamma\geq \gamma>0 \{d_i\}_{i=1}^M \mathcal{D} \{d_{k_j}\}_{j=1}^M d_{k_1}\leq d_{k_2}\leq\ldots\leq d_{k_M} \max_{j\in [M]}|d_{k_j}-d_{k_{j-1}}| Pr(\max_{j\in [M]}|d_{k_j}-d_{k_{j-1}}|\geq \epsilon)","['probability', 'statistics', 'law-of-large-numbers', 'concentration-of-measure']"
49,Random Walk 'Snake Problem',Random Walk 'Snake Problem',,"Introduction A snake is traveling around the infinite Cartesian grid. It starts at (0,0) and takes the first step to the left to (-1,0). It continues spiralling counterclockwise, so it visits (-1,-1) next. Then, as the snake arrives at (0,-1), it cannot continue to (0,0) since this place has already been visitted. In such situation the snake chooses a random direction and continues its journey. Question How many steps will the snake take on average before biting its own body? Simulation I wrote some python code to check the answer numerically and is seems to be about 56.261616. Is there a way to estimate the answer mathematically? The histogram after 10mln runs: An example journey: import numpy as np import matplotlib.pyplot as plt import random as rd start=[0,0] right=[1,0] up=[0,1] left=[-1,0] down=[0,-1]  directions={0:right, 1:up, 2:left, 3:down} facing=0 hist_data=[] for jj in range(10000):     pos=start     visits=[start]     step_num=0     while True:         new_pos=[sum(x) for x in zip(pos,directions[facing])]         if new_pos not in visits:             pos=new_pos             visits.append(pos)             step_num+=1             facing=(facing+1)%4         else:              facing=(facing+rd.randint(1,3))%4             new_pos_right=[sum(x) for x in zip(pos,directions[0])]             new_pos_up=[sum(x) for x in zip(pos,directions[1])]             new_pos_left=[sum(x) for x in zip(pos,directions[2])]             new_pos_down=[sum(x) for x in zip(pos,directions[3])]             if (new_pos_right in visits) and (new_pos_up in visits) and (new_pos_left in visits) and (new_pos_down in visits):                 hist_data.append(step_num)                 break  plt.figure() for ii in range(len(visits)-1):     plt.plot([visits[ii+1][0],visits[ii][0]],[visits[ii+1][1],visits[ii][1]],'b-')  plt.plot(0,0,'g.',markersize=25) plt.plot(visits[-1][0],visits[-1][1],'r.',markersize=25) plt.title('Snake got stuck after '+str(step_num)+' steps')  plt.figure() w=1 plt.hist(hist_data,bins=np.arange(min(hist_data), max(hist_data) + w, w)) print(np.average(hist_data)) plt.show()","Introduction A snake is traveling around the infinite Cartesian grid. It starts at (0,0) and takes the first step to the left to (-1,0). It continues spiralling counterclockwise, so it visits (-1,-1) next. Then, as the snake arrives at (0,-1), it cannot continue to (0,0) since this place has already been visitted. In such situation the snake chooses a random direction and continues its journey. Question How many steps will the snake take on average before biting its own body? Simulation I wrote some python code to check the answer numerically and is seems to be about 56.261616. Is there a way to estimate the answer mathematically? The histogram after 10mln runs: An example journey: import numpy as np import matplotlib.pyplot as plt import random as rd start=[0,0] right=[1,0] up=[0,1] left=[-1,0] down=[0,-1]  directions={0:right, 1:up, 2:left, 3:down} facing=0 hist_data=[] for jj in range(10000):     pos=start     visits=[start]     step_num=0     while True:         new_pos=[sum(x) for x in zip(pos,directions[facing])]         if new_pos not in visits:             pos=new_pos             visits.append(pos)             step_num+=1             facing=(facing+1)%4         else:              facing=(facing+rd.randint(1,3))%4             new_pos_right=[sum(x) for x in zip(pos,directions[0])]             new_pos_up=[sum(x) for x in zip(pos,directions[1])]             new_pos_left=[sum(x) for x in zip(pos,directions[2])]             new_pos_down=[sum(x) for x in zip(pos,directions[3])]             if (new_pos_right in visits) and (new_pos_up in visits) and (new_pos_left in visits) and (new_pos_down in visits):                 hist_data.append(step_num)                 break  plt.figure() for ii in range(len(visits)-1):     plt.plot([visits[ii+1][0],visits[ii][0]],[visits[ii+1][1],visits[ii][1]],'b-')  plt.plot(0,0,'g.',markersize=25) plt.plot(visits[-1][0],visits[-1][1],'r.',markersize=25) plt.title('Snake got stuck after '+str(step_num)+' steps')  plt.figure() w=1 plt.hist(hist_data,bins=np.arange(min(hist_data), max(hist_data) + w, w)) print(np.average(hist_data)) plt.show()",,"['statistics', 'recreational-mathematics', 'random-walk']"
50,Fisher Information and Cramér-Rao lower bound problem,Fisher Information and Cramér-Rao lower bound problem,,"Suppose $X_1,...,X_n$ are random samples from $N(\mu, \sigma^2)$ , where both $\mu$ and $\sigma \gt 0$ are unknown, and let $\theta = \sigma^p$ for some $p \gt 0$ . I want to find the Fisher Information of $\theta$ , and the Cramér-Rao lower bound for the variance of any unbiased estimator for $\theta$ . I am kind of confused of this assumption $\theta = \sigma^p$ , and I don't quite know how to deal with it. Any help is welcome","Suppose are random samples from , where both and are unknown, and let for some . I want to find the Fisher Information of , and the Cramér-Rao lower bound for the variance of any unbiased estimator for . I am kind of confused of this assumption , and I don't quite know how to deal with it. Any help is welcome","X_1,...,X_n N(\mu, \sigma^2) \mu \sigma \gt 0 \theta = \sigma^p p \gt 0 \theta \theta \theta = \sigma^p","['statistics', 'statistical-inference', 'sampling', 'parameter-estimation']"
51,"Showing that max of uniform laws on $[0,\theta]$ is sufficient statistic with definition",Showing that max of uniform laws on  is sufficient statistic with definition,"[0,\theta]","Let $X_1, \cdots, X_n$ be i.i.d. $Unif(0,\theta)$ and $T = \max\{X_1,X_2,···,X_n\}$ . Show that T is a sufficient statistic using the definition. So I need to show that for $t>0$ , $\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)$ does not depend on $\theta$ . Here are my computations : $$\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n , T \leq t)}{\Bbb P( T \leq t)}$$ $$=\frac{\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n , T \leq t)}{\Bbb P( T \leq t)}=\frac{ \Bbb P(X_1 \leq \min(x_1,t), \cdots, X_n \leq \min(x_n,t))}{\Bbb P(X_1 \leq t, \cdots, X_n \leq t)}$$ $$=\frac{ \Bbb P(X_1 \leq \min(x_1,t), \cdots, X_n \leq \min(x_n,t))}{\Pi_{i=1}^n \Bbb P(X_i \leq t)}=\frac{\Pi_{i=1}^n \int_{-\infty}^{\min(x_i,t)}\Bbb 1_{[0,\theta]}dx}{\bigg(\int_{-\infty}^{t}\Bbb 1_{[0,\theta]}dx\bigg)^n}$$ It is very technical but we can finally write it as $$\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{\Pi_{i=1}^n \min(x_i,t,\theta)}{(\min(t,\theta))^n}$$ Let us suppose for example that $t\geq \theta$ and all $x_i$ are also bigger than $\theta$ then $\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{\theta^n}{\theta^n}=1$ which does not depend on $\theta$ . The big issue is starting to be clear : if $t \geq \theta$ and (at least) one of $x_i$ is smaller than $\theta$ then we have that $\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{x_i \theta^{n-1}}{\theta^n}=\frac{x_i}{\theta}$ that depends on $\theta$ ! If maths are never wrong, then I am but where ? I was told there must be a mistake in my computations but they seem ok. Can anyone see what's not right ? (I know I can use the equivalent factorisation but I really want to do it by definition).","Let be i.i.d. and . Show that T is a sufficient statistic using the definition. So I need to show that for , does not depend on . Here are my computations : It is very technical but we can finally write it as Let us suppose for example that and all are also bigger than then which does not depend on . The big issue is starting to be clear : if and (at least) one of is smaller than then we have that that depends on ! If maths are never wrong, then I am but where ? I was told there must be a mistake in my computations but they seem ok. Can anyone see what's not right ? (I know I can use the equivalent factorisation but I really want to do it by definition).","X_1, \cdots, X_n Unif(0,\theta) T = \max\{X_1,X_2,···,X_n\} t>0 \Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t) \theta \Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n , T \leq t)}{\Bbb P( T \leq t)} =\frac{\Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n , T \leq t)}{\Bbb P( T \leq t)}=\frac{ \Bbb P(X_1 \leq \min(x_1,t), \cdots, X_n \leq \min(x_n,t))}{\Bbb P(X_1 \leq t, \cdots, X_n \leq t)} =\frac{ \Bbb P(X_1 \leq \min(x_1,t), \cdots, X_n \leq \min(x_n,t))}{\Pi_{i=1}^n \Bbb P(X_i \leq t)}=\frac{\Pi_{i=1}^n \int_{-\infty}^{\min(x_i,t)}\Bbb 1_{[0,\theta]}dx}{\bigg(\int_{-\infty}^{t}\Bbb 1_{[0,\theta]}dx\bigg)^n} \Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{\Pi_{i=1}^n \min(x_i,t,\theta)}{(\min(t,\theta))^n} t\geq \theta x_i \theta \Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{\theta^n}{\theta^n}=1 \theta t \geq \theta x_i \theta \Bbb P(X_1 \leq x_1, \cdots, X_n \leq x_n \lvert T \leq t)=\frac{x_i \theta^{n-1}}{\theta^n}=\frac{x_i}{\theta} \theta","['probability', 'statistics', 'solution-verification', 'uniform-distribution', 'sufficient-statistics']"
52,inverse proportional probabilities,inverse proportional probabilities,,"Imagine that we have a series of $n$ positive real numbers $x_1 ,\ldots, x_n$ . We want to assign a probability $p_i \in [0,1]$ to each number $x_i$ proportional to its magnitude so that all the probabilities add up to 1 ( $\sum_{i=1}^{n}p_i=1$ ). One way to do this is to use the expression: $p_i= x_i/\sum_{j=1}^{n}x_j$ The question is: if we want to assign to each number $x_i$ a probability $p_i$ inversely proportional to its magnitude maintaining $\sum_{i=1}^{n}p_i=1$ , how can we do it?","Imagine that we have a series of positive real numbers . We want to assign a probability to each number proportional to its magnitude so that all the probabilities add up to 1 ( ). One way to do this is to use the expression: The question is: if we want to assign to each number a probability inversely proportional to its magnitude maintaining , how can we do it?","n x_1 ,\ldots, x_n p_i \in [0,1] x_i \sum_{i=1}^{n}p_i=1 p_i= x_i/\sum_{j=1}^{n}x_j x_i p_i \sum_{i=1}^{n}p_i=1","['probability', 'statistics', 'functions', 'probability-distributions', 'random-variables']"
53,"X,Y independent and normally distributed. What is the expected length and angle of the vector (X,Y)?","X,Y independent and normally distributed. What is the expected length and angle of the vector (X,Y)?",,"Let $X, Y$ be independent, normally distributed random variables with equal variances and means $\mu_X, \mu_Y$ . What is the expected length of the vector $(X,Y)$ and what is the expected angle with respect to the $x$ -axis? If the means are $0$ , then the length is Rayleigh distributed and the angle is uniformly distributed. But what if the means are not $0$ ? Is there a way to calculate the integrals to get their mean and variance (or other properties)?","Let be independent, normally distributed random variables with equal variances and means . What is the expected length of the vector and what is the expected angle with respect to the -axis? If the means are , then the length is Rayleigh distributed and the angle is uniformly distributed. But what if the means are not ? Is there a way to calculate the integrals to get their mean and variance (or other properties)?","X, Y \mu_X, \mu_Y (X,Y) x 0 0","['probability', 'statistics', 'probability-distributions']"
54,(Conditional) coin flips mean and variance,(Conditional) coin flips mean and variance,,"Roll a fair die to obtain a random number $1 ≤ n ≤ 6$ , then flip a fair coin $n$ times. Let $X$ be the random variable that expresses the number of heads in the coin flips. Find the mean and variance of $X$ . Since the coin flips are Bernoulli trials, the expected number for heads ( $H$ ) and tails ( $T$ ) are $\mathbb{E}[H]=\mathbb{E}[T]=n/2$ . Furthermore, $H$ (and $T$ ) is distributed as per the binomial distribution, which has mean $n/2$ and variance $n/4$ ,  ( $n\in\{1,2,3,4,5,6\}$ ). I don't know how to combine this with the outcome of the die roll. I have very elementary knowledge with probability and statistics, but I know, at least, that the coin tosses are independent of any other event. (This is a problem I found in a Facebook group - not homework or anything). Thank you!","Roll a fair die to obtain a random number , then flip a fair coin times. Let be the random variable that expresses the number of heads in the coin flips. Find the mean and variance of . Since the coin flips are Bernoulli trials, the expected number for heads ( ) and tails ( ) are . Furthermore, (and ) is distributed as per the binomial distribution, which has mean and variance ,  ( ). I don't know how to combine this with the outcome of the die roll. I have very elementary knowledge with probability and statistics, but I know, at least, that the coin tosses are independent of any other event. (This is a problem I found in a Facebook group - not homework or anything). Thank you!","1 ≤ n ≤ 6 n X X H T \mathbb{E}[H]=\mathbb{E}[T]=n/2 H T n/2 n/4 n\in\{1,2,3,4,5,6\}","['probability', 'statistics']"
55,Exponential regression GLM,Exponential regression GLM,,"Consider some positive random variables $X^1, X^2$ and $Y\sim Exp(p)$ where $p=\beta_0+\beta_1X^1 + \beta_2X^2$ . We have a random sample $\{X^1_i, X^2_i, Y_i\}$ . Now, estimate $\beta_1, \beta_2$ is not hard, e.g. using GLM. Now let's say that we do not observe $X^2$ . Is it still possible to consistently estimate $\beta_1$ (i.e. using only a statistic consisting of $\{X^1_i, Y_i\}$ )? If not, is there some assumption (normality etc...) for $X^i$ under which we can consistently estimate $\beta_1$ ? And some confidence intervals for $\beta_1$ ? A nice method is shown by @TomChen here Beta regression , but it doesn't work for a linear $p$ .","Consider some positive random variables and where . We have a random sample . Now, estimate is not hard, e.g. using GLM. Now let's say that we do not observe . Is it still possible to consistently estimate (i.e. using only a statistic consisting of )? If not, is there some assumption (normality etc...) for under which we can consistently estimate ? And some confidence intervals for ? A nice method is shown by @TomChen here Beta regression , but it doesn't work for a linear .","X^1, X^2 Y\sim Exp(p) p=\beta_0+\beta_1X^1 + \beta_2X^2 \{X^1_i, X^2_i, Y_i\} \beta_1, \beta_2 X^2 \beta_1 \{X^1_i, Y_i\} X^i \beta_1 \beta_1 p","['statistics', 'regression', 'exponential-distribution', 'maximum-likelihood']"
56,Are finite state irreducible continuous Markov chains identifiable in general?,Are finite state irreducible continuous Markov chains identifiable in general?,,"Let $S=\{1,...,h\}$ be a finite state space and $X(t)$ an irreducible Markov chain fully described by a generator matrix $Q$ with a transition probability matrix $P(t)=e^{Qt}$ on time horizon $[0,T]$ . I have noticed in literature that identifiability of $Q$ is always assumed; however, I can hardly imagine that this cannot be proven. Unfortunately, I get stuck on where to look using the definition of identifiability \begin{equation} P_{Q_{1}}=P_{Q_{2}}\implies Q_{1}=Q_{2} \end{equation} and the MLE \begin{equation} q_{ij}=\frac{N_{ij}(T)}{R_{i}(T)} \end{equation} with $N_{ij}(t)$ the number of $i\rightarrow j$ transition up to time and $R_{i}(t)=\int_{0}^{t}1_{\{X(u)=i\}}du$ for $t\in[0,T]$ and any $i,j\in S$ with $j\neq i$ and \begin{equation} q_{ii}=-\sum_{j=1,j\neq i}q_{ij} \end{equation} Does anyone have some tips on where to start on or literature proving identifiability?","Let be a finite state space and an irreducible Markov chain fully described by a generator matrix with a transition probability matrix on time horizon . I have noticed in literature that identifiability of is always assumed; however, I can hardly imagine that this cannot be proven. Unfortunately, I get stuck on where to look using the definition of identifiability and the MLE with the number of transition up to time and for and any with and Does anyone have some tips on where to start on or literature proving identifiability?","S=\{1,...,h\} X(t) Q P(t)=e^{Qt} [0,T] Q \begin{equation}
P_{Q_{1}}=P_{Q_{2}}\implies Q_{1}=Q_{2}
\end{equation} \begin{equation}
q_{ij}=\frac{N_{ij}(T)}{R_{i}(T)}
\end{equation} N_{ij}(t) i\rightarrow j R_{i}(t)=\int_{0}^{t}1_{\{X(u)=i\}}du t\in[0,T] i,j\in S j\neq i \begin{equation}
q_{ii}=-\sum_{j=1,j\neq i}q_{ij}
\end{equation}","['statistics', 'markov-chains']"
57,"""Statistical Inference"" telephone question, follow-up","""Statistical Inference"" telephone question, follow-up",,"I ran across the following problem in Casella and Berger's Statistical Inference (Q1.20, 2nd ed): My telephone rings 12 times each week, the calls being randomly distributed among the 7 days. What is the probability that I get at least one call each day? (Answer: .2285) This seems to be equivalent to putting 12 balls into 7 boxes so that there is at least 1 ball in each box. In that case, this should be a fairly straightforward selection-with-repetition problem: since we have at least 1 ball in each box, that means we must actually count the number of ways to put 5 balls into 7 boxes, and divide by the number of ways to put 12 balls into 7 boxes, which would give [(11 choose 6)/(18 choose 6)] or about 0.0249. I see an answer given here: Statistical Inference Question which approaches it from the bottom up rather than the top down. This method seems reasonable, and I've verified that it gives the authors' desired answer, but what's different about my approach? In both cases, the calls are unordered and identical, the days are ordered and distinct, and repetition is allowed.","I ran across the following problem in Casella and Berger's Statistical Inference (Q1.20, 2nd ed): My telephone rings 12 times each week, the calls being randomly distributed among the 7 days. What is the probability that I get at least one call each day? (Answer: .2285) This seems to be equivalent to putting 12 balls into 7 boxes so that there is at least 1 ball in each box. In that case, this should be a fairly straightforward selection-with-repetition problem: since we have at least 1 ball in each box, that means we must actually count the number of ways to put 5 balls into 7 boxes, and divide by the number of ways to put 12 balls into 7 boxes, which would give [(11 choose 6)/(18 choose 6)] or about 0.0249. I see an answer given here: Statistical Inference Question which approaches it from the bottom up rather than the top down. This method seems reasonable, and I've verified that it gives the authors' desired answer, but what's different about my approach? In both cases, the calls are unordered and identical, the days are ordered and distinct, and repetition is allowed.",,"['probability', 'statistics']"
58,Transformation of an exponential distribution,Transformation of an exponential distribution,,"Suppose that $X\sim Exp(p)$ is exponentially distributed with expectation $1/p$ . Does there exist transformation $f:\mathbb{R}\to\mathbb{R}$ such that $f(X)$ will be some (ideally ""nice"") distribution with expectation $\mathbb{E}f(X)=p$ ? Here, $f$ can not depend on $p$ . Context: In GLM models (generalized linear models) we usually deal with a random variables $Y\sim exp(p)$ where $p=\beta_0+\beta_1X_1$ . So $\mathbb{E}Y=\frac{1}{\beta_0+\beta_1X_1}$ which is kind of ugly. It would be nice if we can change Y in such a way that $f(Y)$ will have nice linear expectation. Is it possible?","Suppose that is exponentially distributed with expectation . Does there exist transformation such that will be some (ideally ""nice"") distribution with expectation ? Here, can not depend on . Context: In GLM models (generalized linear models) we usually deal with a random variables where . So which is kind of ugly. It would be nice if we can change Y in such a way that will have nice linear expectation. Is it possible?",X\sim Exp(p) 1/p f:\mathbb{R}\to\mathbb{R} f(X) \mathbb{E}f(X)=p f p Y\sim exp(p) p=\beta_0+\beta_1X_1 \mathbb{E}Y=\frac{1}{\beta_0+\beta_1X_1} f(Y),"['statistics', 'probability-distributions', 'exponential-distribution']"
59,Demonstration of inequality between 2 variances expressions,Demonstration of inequality between 2 variances expressions,,"Just to remind, $C_\ell$ is the variance of random variables $a_{\ell m}$ following a centered Gaussian PDF (in spherical harmonics of Legendre) : $$C_{\ell}=\left\langle a_{l m}^{2}\right\rangle=\frac{1}{2 \ell+1} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}=\operatorname{Var}\left(a_{l m}\right)$$ Second observable : $$ \sigma_{D, 2}^{2}=\dfrac{2 \sum_{\ell_{\min }}^{\ell_{\max }}(2 \ell+1)}{\left(f_{s k y} N_{p}^{2}\right)} $$ so : $$ \sigma_{o, 2}^{2}=\dfrac{\sigma_{D, 2}^{2}}{\left(\sum_{\ell_{\min }}^{\ell_{\max }}(2 \ell+1) C_{\ell}\right)^{2}} $$ First observable : $$ \sigma_{D, 1}^{2}=\sum_{\ell_{\min }}^{\ell_{\max }} \dfrac{2}{(2 \ell+1)\left(f_{s k y} N_{p}^{2}\right)} $$ so : $$ \sigma_{o, 1}^{2}=\dfrac{\sigma_{D, 1}^{2}}{\left(\sum_{\ell_{\min }}^{\ell_{\max }} C_{\ell}\right)^{2}} $$ Goal : I would like to prove than $\sigma_{o, 1}^{2}<\sigma_{o, 2}^{2}$ but I have difficulties to derive this inequality. UPDATE : from the preliminary results of a colleague, it may show the contrary, i.e that the inequality is rather : $\sigma_{o, 2}^{2}<\sigma_{o, 1}^{2}$ But I have to double check, there should be an error since numerically, I find that $\sigma_{o, 1}^{2}<\sigma_{o, 2}^{2}$ . Any help is welcome","Just to remind, is the variance of random variables following a centered Gaussian PDF (in spherical harmonics of Legendre) : Second observable : so : First observable : so : Goal : I would like to prove than but I have difficulties to derive this inequality. UPDATE : from the preliminary results of a colleague, it may show the contrary, i.e that the inequality is rather : But I have to double check, there should be an error since numerically, I find that . Any help is welcome","C_\ell a_{\ell m} C_{\ell}=\left\langle a_{l m}^{2}\right\rangle=\frac{1}{2 \ell+1} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}=\operatorname{Var}\left(a_{l m}\right) 
\sigma_{D, 2}^{2}=\dfrac{2 \sum_{\ell_{\min }}^{\ell_{\max }}(2 \ell+1)}{\left(f_{s k y} N_{p}^{2}\right)}
 
\sigma_{o, 2}^{2}=\dfrac{\sigma_{D, 2}^{2}}{\left(\sum_{\ell_{\min }}^{\ell_{\max }}(2 \ell+1) C_{\ell}\right)^{2}}
 
\sigma_{D, 1}^{2}=\sum_{\ell_{\min }}^{\ell_{\max }} \dfrac{2}{(2 \ell+1)\left(f_{s k y} N_{p}^{2}\right)}
 
\sigma_{o, 1}^{2}=\dfrac{\sigma_{D, 1}^{2}}{\left(\sum_{\ell_{\min }}^{\ell_{\max }} C_{\ell}\right)^{2}}
 \sigma_{o, 1}^{2}<\sigma_{o, 2}^{2} \sigma_{o, 2}^{2}<\sigma_{o, 1}^{2} \sigma_{o, 1}^{2}<\sigma_{o, 2}^{2}","['probability', 'statistics']"
60,Calculate the binomial probability for $N$ events,Calculate the binomial probability for  events,N,"Background I have a question that I've been thinking about a lots and haven't been sure about the answer. Here is the question. Bob and Alice play a game called ""Change and Guess"". Basically, Alice has an array including $800000$ numbers that Bob has to guess. Since there are a lot of numbers to guess so Alice decides to give Bob all the numbers ( $800000$ ) in the array. However, Alice will first change $512$ numbers at random in the array then give the array to Bob. Bob's also aware of that every time he asks there will be $512$ numbers that are changed in the array. Bob can ask as many times as he wants and will have to guess the numbers after that. Bob takes the strategy that counting the appearances for each number in the array and take the majority one to find out the original value for each number. He'll do that process for $800000$ numbers and bring them back to Alice. How many times that Bob as least has to ask in order to have $99.9999999\%$ chance of guessing all the numbers right using the mentioned strategy above** Here is an example: Since the length of the array is big and to keep everything simple, the example below is just a simplified version of the question demonstrates how the Bob/Alice game works. The length of the array is just 5 numbers and Alice changes only 1 number each time in the example but It will be 800000 numbers and Alice can change 512 numbers in the array for real question. Alice has an array $X = [1,2,3,4,5]$ Bob asks Alice for $3$ times. Alice then will change some numbers in the array and then give them to Bob each time. The $3$ arrays can look like: $$X_1 = [1,2,3,4,6]$$ $$X_2 = [1,2,3,10,5]$$ $$X_3 = [100,2,3,4,5]$$ Now Bob can look at those arrays and start guessing the values. So for each position for $3$ arrays, Bob counts the appearance and picks the highest one with the hope that the majority one will be the original one. First position : $1$ appears $2$ times, $100$ appears $1$ times. Bob picks $1$ . Second position : $2$ appears $3$ times. Bob picks $2$ . Third position: $3$ appears $2$ times, $2$ appears $1$ times. Bob picks $3$ . .. .. Then at the end, Bob's guessing array will be $X = [1,2,3,4,5]$ My Attempt So this is what I thought so far: The probability of picking one number from an array is $512/800000 = 0.00064$ . So for $N$ times, in order for this strategy to be failed, there must be at least one number that is picked at least $(N/2) + 1   times (\gt50\%)$ so the changed valued will get picked based on majority vote. Based on the binomial probability formula. The probability of an event happens exactly $K$ times out of $N$ times is: Binomial probability formula In this case, we need to calculate the probability for $K$ from $(N/2) +1$ to $N$ . This will be calculated by the sum of applying the formula for $K$ from $(N/2) + 1$ to $N$ . I'll call that $$P(k\ge (N/2) +1 )$$ I ran $N$ from $2$ to $100$ : $$N=2, P(k\ge (N/2) +1 ) = 4.0960000000000007e^{-7}$$ $$N=3, P(k\ge (N/2) +1 ) = 1.2282757120000002e^{-6}$$ $$N =4, P(k\ge (N/2) +1 ) =  1.0480726835200003e^{-9}$$ $$N =5, P(k\ge (N/2) +1 ) = 2.6189240618450956e^{-9}$$ $$N=6, P(k\ge (N/2) +1 ) = 2.5140061068171685e^{-12}$$ $$\vdots$$ So on it keeps getting closer to $0$ . So in order to have $99.9999999\%$ success, Bob probably need $4$ iterations at least. I'm wondering that whether there was any approach other than mine for this question or not. Is there anything else I haven't considered yet. Any help would be appreciated.","Background I have a question that I've been thinking about a lots and haven't been sure about the answer. Here is the question. Bob and Alice play a game called ""Change and Guess"". Basically, Alice has an array including numbers that Bob has to guess. Since there are a lot of numbers to guess so Alice decides to give Bob all the numbers ( ) in the array. However, Alice will first change numbers at random in the array then give the array to Bob. Bob's also aware of that every time he asks there will be numbers that are changed in the array. Bob can ask as many times as he wants and will have to guess the numbers after that. Bob takes the strategy that counting the appearances for each number in the array and take the majority one to find out the original value for each number. He'll do that process for numbers and bring them back to Alice. How many times that Bob as least has to ask in order to have chance of guessing all the numbers right using the mentioned strategy above** Here is an example: Since the length of the array is big and to keep everything simple, the example below is just a simplified version of the question demonstrates how the Bob/Alice game works. The length of the array is just 5 numbers and Alice changes only 1 number each time in the example but It will be 800000 numbers and Alice can change 512 numbers in the array for real question. Alice has an array Bob asks Alice for times. Alice then will change some numbers in the array and then give them to Bob each time. The arrays can look like: Now Bob can look at those arrays and start guessing the values. So for each position for arrays, Bob counts the appearance and picks the highest one with the hope that the majority one will be the original one. First position : appears times, appears times. Bob picks . Second position : appears times. Bob picks . Third position: appears times, appears times. Bob picks . .. .. Then at the end, Bob's guessing array will be My Attempt So this is what I thought so far: The probability of picking one number from an array is . So for times, in order for this strategy to be failed, there must be at least one number that is picked at least so the changed valued will get picked based on majority vote. Based on the binomial probability formula. The probability of an event happens exactly times out of times is: Binomial probability formula In this case, we need to calculate the probability for from to . This will be calculated by the sum of applying the formula for from to . I'll call that I ran from to : So on it keeps getting closer to . So in order to have success, Bob probably need iterations at least. I'm wondering that whether there was any approach other than mine for this question or not. Is there anything else I haven't considered yet. Any help would be appreciated.","800000 800000 512 512 800000 99.9999999\% X = [1,2,3,4,5] 3 3 X_1 = [1,2,3,4,6] X_2 = [1,2,3,10,5] X_3 = [100,2,3,4,5] 3 1 2 100 1 1 2 3 2 3 2 2 1 3 X = [1,2,3,4,5] 512/800000 = 0.00064 N (N/2) + 1   times (\gt50\%) K N K (N/2) +1 N K (N/2) + 1 N P(k\ge (N/2) +1 ) N 2 100 N=2, P(k\ge (N/2) +1 ) = 4.0960000000000007e^{-7} N=3, P(k\ge (N/2) +1 ) = 1.2282757120000002e^{-6} N =4, P(k\ge (N/2) +1 ) =  1.0480726835200003e^{-9} N =5, P(k\ge (N/2) +1 ) = 2.6189240618450956e^{-9} N=6, P(k\ge (N/2) +1 ) = 2.5140061068171685e^{-12} \vdots 0 99.9999999\% 4","['probability', 'statistics']"
61,What is this lognormal-like distribution?,What is this lognormal-like distribution?,,"I have a distribution, marked with the blue line, which looks remarkably like a lognormal distribution. . I used the median and mod values to get the mu and sigma values to estimate its lognormal counterpart. The resultant lognormal distribution is given with the orange line. Note that it is shifted slightly to the right to fit best to the distribution. The distribution given by the blue line has the formula: $$ dist(x)=\frac{\mathrm{d}}{\mathrm{d}x}\left(1-\sum_{i=-\infty}^\infty(-1)^{i+1}\left[\Phi\left(\frac{(2i+1)c}{\sqrt{x}}\right)-\Phi\left(\frac{(2i-1)c}{\sqrt{x}}\right)\right]\right), $$ where $\Phi()$ is the CDF of the standard normal distribution and $c=50$ for this particular case. The above equation is the probability of first incidence happening at $x=i$ to the boundaries $\{-c,c\}$ for a brownian motion starting at $0$ . My questions are: Is this a lognormal distribution? Would I get a better approximation if I use some other measures to get mu and sigma values, i.e., if I use variance and mean? If it is not a lognormal distribution, what it could be? I think I need something slightly more skewed. Thanks in advance! Appendix: Here is a python snippet to obtain the above formula. #Performs the summation of the above CDF upto ss from scipy.stats import norm def cdf_of_dist(c,m,ss):     aa=c/(m)**0.5     P1=lambda s: ((-1)**(s+1))*(norm.cdf((2*s+1)*aa)-norm.cdf((2*s-1)*aa))     res=1     for i in range(ss):         res+=P1(i)+P1(-i)     return res-P1(0) #Takes derivative of the CDF def dist(c,ss):     derivative_array=[0]     for i in range(m-1):         derivative_array.append(cdf_of_dist(c,i+1,ss)-cdf_of_dist(c,i,ss))     return derivative_array","I have a distribution, marked with the blue line, which looks remarkably like a lognormal distribution. . I used the median and mod values to get the mu and sigma values to estimate its lognormal counterpart. The resultant lognormal distribution is given with the orange line. Note that it is shifted slightly to the right to fit best to the distribution. The distribution given by the blue line has the formula: where is the CDF of the standard normal distribution and for this particular case. The above equation is the probability of first incidence happening at to the boundaries for a brownian motion starting at . My questions are: Is this a lognormal distribution? Would I get a better approximation if I use some other measures to get mu and sigma values, i.e., if I use variance and mean? If it is not a lognormal distribution, what it could be? I think I need something slightly more skewed. Thanks in advance! Appendix: Here is a python snippet to obtain the above formula. #Performs the summation of the above CDF upto ss from scipy.stats import norm def cdf_of_dist(c,m,ss):     aa=c/(m)**0.5     P1=lambda s: ((-1)**(s+1))*(norm.cdf((2*s+1)*aa)-norm.cdf((2*s-1)*aa))     res=1     for i in range(ss):         res+=P1(i)+P1(-i)     return res-P1(0) #Takes derivative of the CDF def dist(c,ss):     derivative_array=[0]     for i in range(m-1):         derivative_array.append(cdf_of_dist(c,i+1,ss)-cdf_of_dist(c,i,ss))     return derivative_array","
dist(x)=\frac{\mathrm{d}}{\mathrm{d}x}\left(1-\sum_{i=-\infty}^\infty(-1)^{i+1}\left[\Phi\left(\frac{(2i+1)c}{\sqrt{x}}\right)-\Phi\left(\frac{(2i-1)c}{\sqrt{x}}\right)\right]\right),
 \Phi() c=50 x=i \{-c,c\} 0","['statistics', 'probability-distributions']"
62,Spherical harmonics - Computing the variance of Poisson noise integrated over $\ell$ on a defined quantity?,Spherical harmonics - Computing the variance of Poisson noise integrated over  on a defined quantity?,\ell,"It is an astrophysics context but actually, it is mostly a mathematics issue. From spherical harmonics with Legendre deccomposition, I have the following definition of the standard deviation of a $C_\ell$ noised with a Poisson Noise $N_p$ : \begin{equation} \sigma({C_\ell})(\ell)=\sqrt{\frac{2}{(2 \ell+1) f_{sky}}}\left[C_\ell(\ell)+\dfrac{1}{N_{p}}\right]\label{1}\tag{1} \end{equation} Now I consider the quantity : $$\sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}$$ I want to estimate the variance expression of Poisson Noise of this qantity. For that, I take the definition of $a_{lm}$ following a normal distribution with mean equal to zero and take also the definition of a $C_\ell=\langle a_{lm}^2 \rangle=\dfrac{1}{2\ell+1}\sum_{m=-\ell}^{\ell}\,a_{\ell m}^2 = \text{Var}(a_{lm})$ . I use $\stackrel{d}{=}$ to denote equality in distribution : $$ \begin{split} Z & \equiv \sum_{\ell=\ell_{\min }}^{\ell_{\max }} \sum_{m=-\ell}^{\ell} a_{\ell, m}^{2} \\ & =\sum_{\ell=\ell_{\min }}^{\ell_{\max }} \sum_{m=-\ell}^{\ell} C_{\ell} \cdot\left(\frac{a_{\ell, m}}{\sqrt{C_{\ell}}}\right)^{2} \\ & \sim \sum_{\ell=\ell_{\min }}^{\ell_{\max }} \sum_{m=-\ell}^{\ell} C_{\ell} \cdot \mathrm{ChiSq}(1) \\ &=\sum_{\ell=\ell_{\min }}^{\ell_{\max }} C_{\ell} \cdot \mathrm{ChiSq}(2 \ell+1). \end{split} $$ So Finally we have : $$ \sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}  \stackrel{d}{=} \sum_{\ell=1}^{N}\,C_\ell \chi^{2}(2\ell+1). $$ To compute the Poisson Noise of each $a_{\ell m}^2$ , a colleague suggests me that for getting an optimal variance expression, I must use the Inverse-variance_weighting , to take only the quantity below: $$ \dfrac{2}{f_{sky}\,N_p^2},\label{2}\tag{2} $$ and to do the summation to get the variance of Poisson Noise (to make the link with formula \eqref{1} and be consistent with it) : $$ \text{Var}(N_{p,int})=\sum_{\ell=1}^{N} \dfrac{2}{f_{sky}\,N_p^2}. \label{3}\tag{3} $$ But I have difficulties to understand the Inverse-variance_weighting applied in my case : I don't understand where are implied the weights regarding the formula \eqref{3}. I wrote above $\text{Var}(N_{p,int})$ , make caution, this is just to express the ""integrated Poisson variance"" over $\ell$ in the quantity $$ \sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}. $$ Unfortunately, when I do numerical computation with this variance formula \eqref{3}, I don't get the same variance than with another valid method. Correct results are got by introducing a factor $\sqrt{2\ell+1}$ into formula \eqref{3}. But I don't know how to justify it, it is just fine-tuned from my part for the moment and it is not rigorous I admit. QUESTION : Is formula \eqref{2} that expresses the variance of Shot Noise on the quantity $\sum_{\ell=\ell_{min}}^{\ell_{max}} \sum_{m=-\ell}^\ell a_{\ell,m}^2$ correct ? If yes, how could integrate it correctly by summing it on multipole $\ell$ and to remain consistent with the standard deviation formula \eqref{1} ? (I talk about the pre-factor $\sqrt{\frac{2}{(2 \ell+1) f_{sky}}}$ that disturbs me in the expression of integrated Poisson Noise) Finally, from all given informations above, how to correctly compute analytically the variance of $$\sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}\:?$$","It is an astrophysics context but actually, it is mostly a mathematics issue. From spherical harmonics with Legendre deccomposition, I have the following definition of the standard deviation of a noised with a Poisson Noise : Now I consider the quantity : I want to estimate the variance expression of Poisson Noise of this qantity. For that, I take the definition of following a normal distribution with mean equal to zero and take also the definition of a . I use to denote equality in distribution : So Finally we have : To compute the Poisson Noise of each , a colleague suggests me that for getting an optimal variance expression, I must use the Inverse-variance_weighting , to take only the quantity below: and to do the summation to get the variance of Poisson Noise (to make the link with formula \eqref{1} and be consistent with it) : But I have difficulties to understand the Inverse-variance_weighting applied in my case : I don't understand where are implied the weights regarding the formula \eqref{3}. I wrote above , make caution, this is just to express the ""integrated Poisson variance"" over in the quantity Unfortunately, when I do numerical computation with this variance formula \eqref{3}, I don't get the same variance than with another valid method. Correct results are got by introducing a factor into formula \eqref{3}. But I don't know how to justify it, it is just fine-tuned from my part for the moment and it is not rigorous I admit. QUESTION : Is formula \eqref{2} that expresses the variance of Shot Noise on the quantity correct ? If yes, how could integrate it correctly by summing it on multipole and to remain consistent with the standard deviation formula \eqref{1} ? (I talk about the pre-factor that disturbs me in the expression of integrated Poisson Noise) Finally, from all given informations above, how to correctly compute analytically the variance of","C_\ell N_p \begin{equation}
\sigma({C_\ell})(\ell)=\sqrt{\frac{2}{(2 \ell+1) f_{sky}}}\left[C_\ell(\ell)+\dfrac{1}{N_{p}}\right]\label{1}\tag{1}
\end{equation} \sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2} a_{lm} C_\ell=\langle a_{lm}^2 \rangle=\dfrac{1}{2\ell+1}\sum_{m=-\ell}^{\ell}\,a_{\ell m}^2 = \text{Var}(a_{lm}) \stackrel{d}{=} 
\begin{split}
Z & \equiv \sum_{\ell=\ell_{\min }}^{\ell_{\max }} \sum_{m=-\ell}^{\ell} a_{\ell, m}^{2} \\
& =\sum_{\ell=\ell_{\min }}^{\ell_{\max }} \sum_{m=-\ell}^{\ell} C_{\ell} \cdot\left(\frac{a_{\ell, m}}{\sqrt{C_{\ell}}}\right)^{2} \\
& \sim \sum_{\ell=\ell_{\min }}^{\ell_{\max }} \sum_{m=-\ell}^{\ell} C_{\ell} \cdot \mathrm{ChiSq}(1) \\
&=\sum_{\ell=\ell_{\min }}^{\ell_{\max }} C_{\ell} \cdot \mathrm{ChiSq}(2 \ell+1).
\end{split}
 
\sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}  \stackrel{d}{=} \sum_{\ell=1}^{N}\,C_\ell \chi^{2}(2\ell+1).
 a_{\ell m}^2 
\dfrac{2}{f_{sky}\,N_p^2},\label{2}\tag{2}
 
\text{Var}(N_{p,int})=\sum_{\ell=1}^{N} \dfrac{2}{f_{sky}\,N_p^2}. \label{3}\tag{3}
 \text{Var}(N_{p,int}) \ell 
\sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}.
 \sqrt{2\ell+1} \sum_{\ell=\ell_{min}}^{\ell_{max}} \sum_{m=-\ell}^\ell a_{\ell,m}^2 \ell \sqrt{\frac{2}{(2 \ell+1) f_{sky}}} \sum_{\ell=1}^{N} \sum_{m=-\ell}^{\ell} a_{\ell m}^{2}\:?","['statistics', 'variance']"
63,Problem when calculating vaccine effectiveness,Problem when calculating vaccine effectiveness,,"When calculating vaccine effectiveness against hospitalization from publicly available data, I came across a strange (mathematical) problem, which I do not know how to interpret. The problem occurs on real-world data, though for this question I hand-crafted the data to better illustrate the problem. I calculate the vaccine effectiveness against hospitalization by comparing numbers of hospitalized in the group of positive. Here are my data: Note that while the effectiveness of the vaccine for the whole population is negative, for individual age ranges it is positive. Mathematically it is clear - young people are often positive but rarely hospitalized, while old people are rarely positive (because they are more vaccinated) however they are hospitalized more often. Question 1: How to interpret the fact that the effectiveness for the whole is negative, while for parts it is positive? When I perform the categorization differently than by age range, I can get completely different effectiveness for the parts: Note that the total numbers are the same as before, only the distribution of hospitalized among positive is different. My impression is that by carefully choosing the category, I can get any results I want. Question 2: I am sure this phenomenon is well known and studied in statistics. Can you point me to the right topic I can look at? Question 3: As shown above, the calculated vaccine effectiveness depends substantially (and can give completely different results) on the division into categories chosen. Why is categorization by age considered better (and correct) than categorization e.g. by colour (as in my example)? IMO, it's just a wishful thinking. For instance, how can we be sure that if we sub-divide the age ranges more finely (either by individual years or by another criteria, e.g. type of vaccine, factory where it was made, region where the patients live etc.), the effectiveness won't be negative again?","When calculating vaccine effectiveness against hospitalization from publicly available data, I came across a strange (mathematical) problem, which I do not know how to interpret. The problem occurs on real-world data, though for this question I hand-crafted the data to better illustrate the problem. I calculate the vaccine effectiveness against hospitalization by comparing numbers of hospitalized in the group of positive. Here are my data: Note that while the effectiveness of the vaccine for the whole population is negative, for individual age ranges it is positive. Mathematically it is clear - young people are often positive but rarely hospitalized, while old people are rarely positive (because they are more vaccinated) however they are hospitalized more often. Question 1: How to interpret the fact that the effectiveness for the whole is negative, while for parts it is positive? When I perform the categorization differently than by age range, I can get completely different effectiveness for the parts: Note that the total numbers are the same as before, only the distribution of hospitalized among positive is different. My impression is that by carefully choosing the category, I can get any results I want. Question 2: I am sure this phenomenon is well known and studied in statistics. Can you point me to the right topic I can look at? Question 3: As shown above, the calculated vaccine effectiveness depends substantially (and can give completely different results) on the division into categories chosen. Why is categorization by age considered better (and correct) than categorization e.g. by colour (as in my example)? IMO, it's just a wishful thinking. For instance, how can we be sure that if we sub-divide the age ranges more finely (either by individual years or by another criteria, e.g. type of vaccine, factory where it was made, region where the patients live etc.), the effectiveness won't be negative again?",,['statistics']
64,Average expected number of throws,Average expected number of throws,,"Rene throws the ball into the river, then retrieves it, turns it randomly and throws it again. With each throw, exactly half of the ball gets wet (the lower hemisphere). How many times, on average, does Rene need to throw a ball to get it completely wet (each point of its surface at least once was in the lower hemisphere)? I found an article by Kevin Brown that talks about a simple formula for the probability that $n$ random points on a sphere lie in the same hemisphere. In our case, this formula $p_{n}=\frac{(n-2)(n-3)}{2^{n}}$ valid for all $n\geq 2$ gives the probability that we will need $n$ throws to completely wet the ball. From this probability, the average number of throws needed to completely wet the sphere is $7$ . I suppose it will also be possible to run a Monte Carlo simulation to verify this. Am I on the right track?","Rene throws the ball into the river, then retrieves it, turns it randomly and throws it again. With each throw, exactly half of the ball gets wet (the lower hemisphere). How many times, on average, does Rene need to throw a ball to get it completely wet (each point of its surface at least once was in the lower hemisphere)? I found an article by Kevin Brown that talks about a simple formula for the probability that random points on a sphere lie in the same hemisphere. In our case, this formula valid for all gives the probability that we will need throws to completely wet the ball. From this probability, the average number of throws needed to completely wet the sphere is . I suppose it will also be possible to run a Monte Carlo simulation to verify this. Am I on the right track?",n p_{n}=\frac{(n-2)(n-3)}{2^{n}} n\geq 2 n 7,"['probability', 'statistics']"
65,What is the orthogonal projection with expectation?,What is the orthogonal projection with expectation?,,"I am reading an advanced econometrics textbook. When it talks about least squares, it says that the orthogonal projection of A onto Z is $P_Z(A)=Z^\prime E[ZZ^\prime]^{-1}E[ZA_k]$ and when A is a vector $A=(A_1,...,A_k)^\prime$ , $P_Z(A)$ is defined as $$ P_Z(A)=(Z^\prime E[ZZ^\prime]^{-1}E[ZA_1],...,Z^\prime  E[ZZ^\prime]^{-1}E[ZA_k])^\prime. $$ Although I know the basic projection matrix is $P=A(A^\prime A)^{-1}A^\prime$ , I can't interpret the expectation in this formula. Could you help me? And I think this is some basic statistic and matrix knowledge, so to pass the econometric course, could you give me some resources or advice to learn it?","I am reading an advanced econometrics textbook. When it talks about least squares, it says that the orthogonal projection of A onto Z is and when A is a vector , is defined as Although I know the basic projection matrix is , I can't interpret the expectation in this formula. Could you help me? And I think this is some basic statistic and matrix knowledge, so to pass the econometric course, could you give me some resources or advice to learn it?","P_Z(A)=Z^\prime E[ZZ^\prime]^{-1}E[ZA_k] A=(A_1,...,A_k)^\prime P_Z(A) 
P_Z(A)=(Z^\prime E[ZZ^\prime]^{-1}E[ZA_1],...,Z^\prime  E[ZZ^\prime]^{-1}E[ZA_k])^\prime.
 P=A(A^\prime A)^{-1}A^\prime","['matrices', 'statistics', 'economics', 'projection-matrices']"
66,Upper Bound on Probability of Maximum Statistic from Exponential Distribution,Upper Bound on Probability of Maximum Statistic from Exponential Distribution,,"Let $X_1,\cdots,X_n$ be I.I.D. Exponential $(\lambda)$ . Let $X_{(n)}$ denote the maximum ordered statistic. Prove that $$P\left(X_{(n)}\geq \frac{2\log(n)}{\lambda}\right)\leq\frac{1}{n}.$$ Work so far: $$ \begin{align}  P\left(X_{(n)}\geq\frac{2\log(n)}{\lambda}\right)&=1-F_{X_{(n)}}\left(\frac{2\log(n)}{\lambda}\right)\\&=1-\left[F_X\left(\frac{2\log(n)}{\lambda}\right)\right]^n\\&=1-\left[1-\text{exp}\{-2\log(n)\}\right]^n\\&=1-\left[1-\frac{1}{n^2}\right]^n \end{align}  $$ From here, I can't think of a clever way to change the RHS to be less than or equal to $\frac{1}{n}$ . Any hints or tips would be much appreciated!","Let be I.I.D. Exponential . Let denote the maximum ordered statistic. Prove that Work so far: From here, I can't think of a clever way to change the RHS to be less than or equal to . Any hints or tips would be much appreciated!","X_1,\cdots,X_n (\lambda) X_{(n)} P\left(X_{(n)}\geq \frac{2\log(n)}{\lambda}\right)\leq\frac{1}{n}. 
\begin{align} 
P\left(X_{(n)}\geq\frac{2\log(n)}{\lambda}\right)&=1-F_{X_{(n)}}\left(\frac{2\log(n)}{\lambda}\right)\\&=1-\left[F_X\left(\frac{2\log(n)}{\lambda}\right)\right]^n\\&=1-\left[1-\text{exp}\{-2\log(n)\}\right]^n\\&=1-\left[1-\frac{1}{n^2}\right]^n
\end{align} 
 \frac{1}{n}","['probability', 'statistics', 'order-statistics']"
67,Quantile function of two-term gaussian,Quantile function of two-term gaussian,,"I'm trying to find the quantile function of the two-term gaussian. From https://statproofbook.github.io/P/norm-qf.html , I've got that I can take the inverse of the CDF of the two-term gaussian.  I've got the two-term CDF as $${1\over2}\left[2+erf\left({(x-\mu_1)\over\sqrt2\sigma_1}\right)+erf\left({(x-\mu_2)\over\sqrt2\sigma_2}\right)\right]$$ Sadly, $erf\left({x-\mu_1\over\sqrt2\sigma_1}\right)+erf\left({x-\mu_2\over\sqrt2\sigma_2}\right)$ is not equal to $erf\left({x-\mu_1\over\sqrt2\sigma_1}+{x-\mu_2\over\sqrt2\sigma_2}\right)$ . (I examined it numerically.) I tried to make a sum function $$erf\_sum(x,\mu_1,\sigma_1,\mu_2,\sigma_2) = {2\over\sqrt\pi}\left[\int_{0}^{x-\mu_1\over\sqrt{2}\sigma_1}e^{-t_1^2}dt_1+\int_{0}^{x-\mu_2\over\sqrt{2}\sigma_2}e^{-t_2^2}dt_2\right]$$ with the hope I could do some change-of-variables trickery to bring the two integrals together into an $erf$ -like form so I could still express the result using $erfinv$ , but I wasn't able to get very far.  The domains of the integrals look like they'll forever be different.  So, I'm stuck here.  Any help is appreciated.","I'm trying to find the quantile function of the two-term gaussian. From https://statproofbook.github.io/P/norm-qf.html , I've got that I can take the inverse of the CDF of the two-term gaussian.  I've got the two-term CDF as Sadly, is not equal to . (I examined it numerically.) I tried to make a sum function with the hope I could do some change-of-variables trickery to bring the two integrals together into an -like form so I could still express the result using , but I wasn't able to get very far.  The domains of the integrals look like they'll forever be different.  So, I'm stuck here.  Any help is appreciated.","{1\over2}\left[2+erf\left({(x-\mu_1)\over\sqrt2\sigma_1}\right)+erf\left({(x-\mu_2)\over\sqrt2\sigma_2}\right)\right] erf\left({x-\mu_1\over\sqrt2\sigma_1}\right)+erf\left({x-\mu_2\over\sqrt2\sigma_2}\right) erf\left({x-\mu_1\over\sqrt2\sigma_1}+{x-\mu_2\over\sqrt2\sigma_2}\right) erf\_sum(x,\mu_1,\sigma_1,\mu_2,\sigma_2) = {2\over\sqrt\pi}\left[\int_{0}^{x-\mu_1\over\sqrt{2}\sigma_1}e^{-t_1^2}dt_1+\int_{0}^{x-\mu_2\over\sqrt{2}\sigma_2}e^{-t_2^2}dt_2\right] erf erfinv","['calculus', 'statistics', 'normal-distribution', 'error-function', 'quantile-function']"
68,Proving that the Sample Mean is BLUE (Best Linear Unbiased Estimator),Proving that the Sample Mean is BLUE (Best Linear Unbiased Estimator),,"For a pupil, i, selected at random from a school, the number of years of education of their parents, $X_i$ , is given by: $$ X_{i}=\mu+\varepsilon_{i} $$ $\varepsilon_{i} \sim i i d\left(0, \sigma^{2}\right)$ . Here $\mu$ is the mean number of years of education completed by parents. For a sample of N students selected independently from the population: (e) Is the sample mean BLUE? Either way, prove it. Answer: First part of proof proves conditions for linear estimator to be unbiased. The second part proves that if the estimator is unbiased, the variance of a linear estimator cannot better it. Define linear estimator $\tilde{X}=\frac{1}{N} \sum_{i=1}^{N} w_{i} X_{i}$ with weights made up: $w_{i}=1+\delta_{i}$ . The 1 here is what the sample mean weight are, so we are saying our new estimator weights differ from that of the sample mean by the amount $\delta_{i}$ . $$ \mathbb{E}(\tilde{X})=\mathbb{E}\left(\frac{1}{N} \sum_{i=1}^{N}\left(1+\delta_{i}\right) X_{i}\right)=\mu+\frac{\mu}{N} \sum_{i=1}^{N} \delta_{i} $$ Hence we must have $\sum_{i=1}^{N} \delta_{i}=0$ for our new linear estimator to be unbiased. Now we derive variance: $$ \operatorname{Var}(\tilde{X})=\frac{1}{N^{2}} \sum_{i=1}^{N}\left(1+\delta_{i}\right)^{2} \sigma^{2}=\frac{\sigma^{2}}{N}+\frac{\sigma^{2}}{N^{2}} \sum_{i=1}^{N}\left(2 \delta_{i}+\delta_{i}^{2}\right)=\operatorname{Var}(\bar{X})+\frac{\sigma^{2}}{N^{2}} \sum_{i=1}^{N} \delta_{i}^{2} $$ Finally, note that for non-zero weights the expression $\sum_{i=1}^{N} \delta_{i}^{2}=\eta>0$ , hence we have that the variance of the new estimator is greater than that of the sample mean. Hence this has proved that any other linear estimator apart from the sample mean has a greater sampling variance. $$ \operatorname{Var}(\tilde{X})=\operatorname{Var}(\bar{X})+\eta $$ Q: The expected value expression makes sense, but where does the variance expression come from and how does he get that?","For a pupil, i, selected at random from a school, the number of years of education of their parents, , is given by: . Here is the mean number of years of education completed by parents. For a sample of N students selected independently from the population: (e) Is the sample mean BLUE? Either way, prove it. Answer: First part of proof proves conditions for linear estimator to be unbiased. The second part proves that if the estimator is unbiased, the variance of a linear estimator cannot better it. Define linear estimator with weights made up: . The 1 here is what the sample mean weight are, so we are saying our new estimator weights differ from that of the sample mean by the amount . Hence we must have for our new linear estimator to be unbiased. Now we derive variance: Finally, note that for non-zero weights the expression , hence we have that the variance of the new estimator is greater than that of the sample mean. Hence this has proved that any other linear estimator apart from the sample mean has a greater sampling variance. Q: The expected value expression makes sense, but where does the variance expression come from and how does he get that?","X_i 
X_{i}=\mu+\varepsilon_{i}
 \varepsilon_{i} \sim i i d\left(0, \sigma^{2}\right) \mu \tilde{X}=\frac{1}{N} \sum_{i=1}^{N} w_{i} X_{i} w_{i}=1+\delta_{i} \delta_{i} 
\mathbb{E}(\tilde{X})=\mathbb{E}\left(\frac{1}{N} \sum_{i=1}^{N}\left(1+\delta_{i}\right) X_{i}\right)=\mu+\frac{\mu}{N} \sum_{i=1}^{N} \delta_{i}
 \sum_{i=1}^{N} \delta_{i}=0 
\operatorname{Var}(\tilde{X})=\frac{1}{N^{2}} \sum_{i=1}^{N}\left(1+\delta_{i}\right)^{2} \sigma^{2}=\frac{\sigma^{2}}{N}+\frac{\sigma^{2}}{N^{2}} \sum_{i=1}^{N}\left(2 \delta_{i}+\delta_{i}^{2}\right)=\operatorname{Var}(\bar{X})+\frac{\sigma^{2}}{N^{2}} \sum_{i=1}^{N} \delta_{i}^{2}
 \sum_{i=1}^{N} \delta_{i}^{2}=\eta>0 
\operatorname{Var}(\tilde{X})=\operatorname{Var}(\bar{X})+\eta
","['statistics', 'regression']"
69,Optimal rate of convergence of nonparametric density estimators,Optimal rate of convergence of nonparametric density estimators,,"Suppose that $X_1, X_2, \dots, X_n$ forms an independent and identically distributed sample from some $d$ -dimensional probability distribution with unknown probability density function $f$ . Let $x$ be some point in the interior of $f$ 's support. The goal is to estimate $f$ based on the observed sample using some nonparametric estimator $\hat f$ . Nonparametric estimators suffer from the curse of dimensionality; Stone [1] is often given as a reference to the claim that the optimal rate of convergence for any nonparametric estimator is $\mathcal O\big(n^{-\frac{p}{2p+d}}\big)$ , where $p$ is the degree of smoothness. I don't understand how Stone's setting applies to a general class of nonparametric estimators. The setting stated in his paper appears very artificial. I would be glad if someone could shed some light on this. [1] https://projecteuclid.org/journals/annals-of-statistics/volume-8/issue-6/Optimal-Rates-of-Convergence-for-Nonparametric-Estimators/10.1214/aos/1176345206.full","Suppose that forms an independent and identically distributed sample from some -dimensional probability distribution with unknown probability density function . Let be some point in the interior of 's support. The goal is to estimate based on the observed sample using some nonparametric estimator . Nonparametric estimators suffer from the curse of dimensionality; Stone [1] is often given as a reference to the claim that the optimal rate of convergence for any nonparametric estimator is , where is the degree of smoothness. I don't understand how Stone's setting applies to a general class of nonparametric estimators. The setting stated in his paper appears very artificial. I would be glad if someone could shed some light on this. [1] https://projecteuclid.org/journals/annals-of-statistics/volume-8/issue-6/Optimal-Rates-of-Convergence-for-Nonparametric-Estimators/10.1214/aos/1176345206.full","X_1, X_2, \dots, X_n d f x f f \hat f \mathcal O\big(n^{-\frac{p}{2p+d}}\big) p","['statistics', 'asymptotics']"
70,What are books/notes on coordinate-free statistics?,What are books/notes on coordinate-free statistics?,,"There are some books here , but all focus on linear models. Do we have books/notes with broader coverages? In case of linear models, “coordinate-free” basically means “matrix-free” and uses the theory of vector space, and the viewpoint is geometric. (Outside of linearity, would we go into something like Information Geometry?) Edit : It seems Information Geometry and Topological Data Analysis are related to this question. But books on IG and TDA tend to collect recent research results, and the problems solved are specialized. Rather, I’d like to see coordinate-free reconstructions of main stream statistical methods (maybe also advanced ones), and this would also help to learn IG and TDA, proper.","There are some books here , but all focus on linear models. Do we have books/notes with broader coverages? In case of linear models, “coordinate-free” basically means “matrix-free” and uses the theory of vector space, and the viewpoint is geometric. (Outside of linearity, would we go into something like Information Geometry?) Edit : It seems Information Geometry and Topological Data Analysis are related to this question. But books on IG and TDA tend to collect recent research results, and the problems solved are specialized. Rather, I’d like to see coordinate-free reconstructions of main stream statistical methods (maybe also advanced ones), and this would also help to learn IG and TDA, proper.",,"['statistics', 'reference-request', 'soft-question', 'statistical-inference', 'book-recommendation']"
71,"Is the second, third, and nth standard deviation an established concept?","Is the second, third, and nth standard deviation an established concept?",,"Of course the first standard deviation is a measure that shows the level of variation among a set of values, and is of course derived by taking the sqrt of mean squared differences of the values to their mean. But what if you needed to know the level of variation OF the variation of the set of values. This would be the second standard deviation, and would be derived by taking the sqrt of mean squared differences of the residuals to their standard deviation. And in the same way: the third, fourth, and nth standard deviation.","Of course the first standard deviation is a measure that shows the level of variation among a set of values, and is of course derived by taking the sqrt of mean squared differences of the values to their mean. But what if you needed to know the level of variation OF the variation of the set of values. This would be the second standard deviation, and would be derived by taking the sqrt of mean squared differences of the residuals to their standard deviation. And in the same way: the third, fourth, and nth standard deviation.",,"['statistics', 'standard-deviation']"
72,Maximizing expected reward for inhomogenous exponential process,Maximizing expected reward for inhomogenous exponential process,,"Consider an inhomogenous exponential process $t \sim \lambda(p(t)) e^{-\int_{0}^{t} \lambda(p(s)) ds}$ where $\lambda > 0$ and monotonically decreases on the reals. Now define the reward function $\pi(p(t), t) = \begin{cases} 0 &\text{ if } t > T\\ p(t) &\text{ else } \end{cases}$ The expected reward is then $E[\pi] = \int_{0}^{T} \lambda(p(t)) e^{-\int_{0}^{t} \lambda(p(s)) ds} p(t)dt$ Directly applying the calculus of variations, I get the Euler-Lagrange conditions for extremizing this $0 = \exp\big(- \int_{0}^{t} (\lambda \circ p)(t) ds\big) \big((\lambda' \circ p)(t) \times p(t) + (\lambda \circ p)(t) - (\lambda \circ p)(t) \times p(t) \times \int_{0}^{t} (\lambda' \circ p)(s) ds\big)$ $0 = (\lambda' \circ p)(t) \times p(t) + (\lambda \circ p)(t) - (\lambda \circ p)(t) \times p(t) \times \int_{0}^{t} (\lambda' \circ p)(s) ds$ This seems like an absurd result to me. How can the result be independent of the boundary conditions $t = T$ ? Putting this into concrete terms, say I'm choosing to set the price for a single good that expires at time $t = T$ . The sale time is inhomogenous exponential with a demand-curve like rate parameter $\lambda(p)$ , and I'm trying to choose the price trajectory through time that maximizes my expected revenue. This result tells me that my revenue maximizing price trajectory doesn't depend on how much time I have to sell the good? Alternatively, I can discretize the same problem with an equivalent sequence of poisson processes. I'll spare you the tedious details, but rescaling $\lambda$ for the timestep length, letting $\pi^{*}_{t}$ be the optimum price for a discrete time step and $\pi^{*}_{T+1} = 0$ , the inductive discrete solution is $0 = 1 + \exp(-\lambda(p_{t})) \big(\lambda'(p_{t}) (p_{t} - \pi^*_{t+1}) - 1\big)$ which is obviously completely different, and doesn't converge in the limit to the continuous solution. I'm pretty sure I did something wrong here, but for the life of me I can't think of what. EDIT: I've figured out my error. I can't naively apply the Euler-Lagrange result because my action here depends on both $p(t)$ and $\int_{0}^{t} \lambda(p(s))ds$ . Taking the rigorous functional derivative of the action, with perturbation $p + \epsilon \phi$ , wrt $\epsilon$ evaluated at $\epsilon = 0$ , I get the first order condition $$0 = \int_{0}^{T} \exp\bigg(- \int_{0}^{t} \lambda p ds\bigg) \bigg(\lambda' p \phi - \lambda p \int_{0}^{t} \phi \lambda' ds + \lambda \phi \bigg) dt$$ $$\forall \phi: \mathbb{R} \rightarrow \mathbb{R} \mid \phi(0) = \phi(T) = 0$$ Because $\phi$ can't be easily factored out of the inner integral, this is not as straightforward as the usual calculus of variations problem. But at least things are making sense now.","Consider an inhomogenous exponential process where and monotonically decreases on the reals. Now define the reward function The expected reward is then Directly applying the calculus of variations, I get the Euler-Lagrange conditions for extremizing this This seems like an absurd result to me. How can the result be independent of the boundary conditions ? Putting this into concrete terms, say I'm choosing to set the price for a single good that expires at time . The sale time is inhomogenous exponential with a demand-curve like rate parameter , and I'm trying to choose the price trajectory through time that maximizes my expected revenue. This result tells me that my revenue maximizing price trajectory doesn't depend on how much time I have to sell the good? Alternatively, I can discretize the same problem with an equivalent sequence of poisson processes. I'll spare you the tedious details, but rescaling for the timestep length, letting be the optimum price for a discrete time step and , the inductive discrete solution is which is obviously completely different, and doesn't converge in the limit to the continuous solution. I'm pretty sure I did something wrong here, but for the life of me I can't think of what. EDIT: I've figured out my error. I can't naively apply the Euler-Lagrange result because my action here depends on both and . Taking the rigorous functional derivative of the action, with perturbation , wrt evaluated at , I get the first order condition Because can't be easily factored out of the inner integral, this is not as straightforward as the usual calculus of variations problem. But at least things are making sense now.","t \sim \lambda(p(t)) e^{-\int_{0}^{t} \lambda(p(s)) ds} \lambda > 0 \pi(p(t), t) = \begin{cases}
0 &\text{ if } t > T\\
p(t) &\text{ else }
\end{cases} E[\pi] = \int_{0}^{T} \lambda(p(t)) e^{-\int_{0}^{t} \lambda(p(s)) ds} p(t)dt 0 = \exp\big(- \int_{0}^{t} (\lambda \circ p)(t) ds\big) \big((\lambda' \circ p)(t) \times p(t) + (\lambda \circ p)(t) - (\lambda \circ p)(t) \times p(t) \times \int_{0}^{t} (\lambda' \circ p)(s) ds\big) 0 = (\lambda' \circ p)(t) \times p(t) + (\lambda \circ p)(t) - (\lambda \circ p)(t) \times p(t) \times \int_{0}^{t} (\lambda' \circ p)(s) ds t = T t = T \lambda(p) \lambda \pi^{*}_{t} \pi^{*}_{T+1} = 0 0 = 1 + \exp(-\lambda(p_{t})) \big(\lambda'(p_{t}) (p_{t} - \pi^*_{t+1}) - 1\big) p(t) \int_{0}^{t} \lambda(p(s))ds p + \epsilon \phi \epsilon \epsilon = 0 0 = \int_{0}^{T} \exp\bigg(- \int_{0}^{t} \lambda p ds\bigg) \bigg(\lambda' p \phi - \lambda p \int_{0}^{t} \phi \lambda' ds + \lambda \phi \bigg) dt \forall \phi: \mathbb{R} \rightarrow \mathbb{R} \mid \phi(0) = \phi(T) = 0 \phi","['probability', 'statistics', 'stochastic-processes', 'calculus-of-variations', 'economics']"
73,How can I find the uncertainty of derivatives?,How can I find the uncertainty of derivatives?,,"Suppose I have a quadratic (weighted) least-square fit result obtained from a given set of data: $$ f(x) = \underbrace{-0.243(\pm0.3324)}_{\text{quad}_a}x^2\underbrace{{}-0.921(\pm0.061)}_{\text{quad}_b}x \underbrace{{}-2.12(\pm0.0223)}_{\text{quad}_c} $$ If I'm taking the derivative of $f(x)$ to have $f'(x) = Ax+B$ , I wonder how can I figure out the uncertainties on $A$ and $B$ ? I also have the correlations C(quad_a, quad_c) = -0.422 C(quad_a, quad_b) = -0.278 Thanks!","Suppose I have a quadratic (weighted) least-square fit result obtained from a given set of data: If I'm taking the derivative of to have , I wonder how can I figure out the uncertainties on and ? I also have the correlations C(quad_a, quad_c) = -0.422 C(quad_a, quad_b) = -0.278 Thanks!","
f(x) = \underbrace{-0.243(\pm0.3324)}_{\text{quad}_a}x^2\underbrace{{}-0.921(\pm0.061)}_{\text{quad}_b}x \underbrace{{}-2.12(\pm0.0223)}_{\text{quad}_c}
 f(x) f'(x) = Ax+B A B","['statistics', 'regression', 'linear-regression', 'confidence-interval', 'error-propagation']"
74,Circular mean of equal mixture of two distributions?,Circular mean of equal mixture of two distributions?,,"Problem Suppose I have two ""probability"" vectors $\mathbf{x}, \mathbf{y}$ each of whose elements corresponds to the weight of an evenly discretized circular space ""support"" $\Theta = [1 \cdot (2\pi/n), 2 \cdot (2\pi/n), \cdots, n \cdot (2\pi/n) ]^T$ : $$ \begin{aligned} \mathbf{x} &= [x_1, x_2, \cdots, x_n]^T \\ \mathbf{y} &= [y_1, y_2, \cdots, y_n]^T \\ \end{aligned} $$ Note that the sums of their elements, $\sum x_i \equiv \sum y_i = 1$ . We can calculate the ""circular mean"" $\bar{\mathbf{X}}$ and ""circular precision"" $\mathrm{prec}({\mathbf{X}})$ as follows: $$ \begin{aligned} \bar{\mathbf{X}} &= \mathrm{atan2} \left( \mathbf{x}^T \sin \Theta, \mathbf{x}^T \cos \Theta \right) \\  \mathrm{prec}({\mathbf{X}}) &= \sqrt{ \left( \mathbf{x}^T \sin \Theta \right)^2 + \left( \mathbf{x}^T \cos \Theta \right)^2 } \end{aligned} $$ where $\sin \Theta := [\sin \left(1 \cdot (2\pi/n)\right), \sin \left( 2 \cdot (2\pi/n) \right), \cdots, \sin \left( n \cdot (2\pi/n)\right) ]^T$ , and cosine alike. Now let $\mathbf{z} = (\mathbf{x} + \mathbf{y})/2$ , the equal mixture distribution of $\mathbf{x}$ , $\mathbf{y}$ . Now I would like to clarify the following question: Question: Can we simplify circular mean $\bar{\mathbf{Z}}$ , using $\bar{\mathbf{X}}$ , $\bar{\mathbf{Y}}$ , $\mathrm{prec}({\mathbf{X}})$ , $\mathrm{prec}({\mathbf{Y}})$ ? Expectation $\bar{\mathbf{Z}}$ may look somewhat like $\bar{\mathbf{X}} \cdot \mathrm{prec}(\mathbf{X}) + \bar{\mathbf{Y}} \cdot \mathrm{prec}(\mathbf{Y})$ . Try Thanks to the invariance of $\mathrm{atan2}$ to constant multiplication, i.e. , $\mathrm{atan2}(cx,cy) = \mathrm{atan2}(x,y)$ for $\forall c>0$ , we have $$ \begin{aligned} \bar{\mathbf{Z}} &= \mathrm{atan2} \left( \mathbf{z}^T \sin \Theta, \mathbf{z}^T \cos \Theta \right) \\ &= \mathrm{atan2} \left( (\mathbf{x}+\mathbf{y})^T \sin \Theta, (\mathbf{x}+\mathbf{y})^T \cos \Theta \right) \\ &= \mathrm{tan}^{-1} \left( \frac{\mathbf{x}^T \sin \Theta + \mathbf{y}^T \sin \Theta}{\mathbf{x}^T \cos \Theta + \mathbf{y}^T \cos \Theta} \right) \end{aligned} $$ where $\mathbf{z}^T\cos\Theta >0$ assumed for the third equality for the sake of simplicity. Letting $\mathbf{S}(\Theta) = \sin \Theta \sin \Theta^T$ , $\mathbf{C}(\Theta) = \cos \Theta \cos \Theta^T$ , $\mathbf{J}(\Theta) = \sin \Theta \cos \Theta^T$ , we have $$ \mathrm{prec} (\mathbf{X}) = \sqrt{ \mathbf{x}^T \left[\mathbf{S}(\Theta) + \mathbf{C} (\Theta) \right] \mathbf{x} } $$ Moreover, using $\mathrm{tan}^{-1} (a/b) + \mathrm{tan}^{-1} (x/y) = \mathrm{tan}^{-1} \left( \frac{bx + ay}{by - ax} \right) $ , $$ \begin{aligned} \mathrm{tan}^{-1} \left( \frac{\mathbf{x}^T \sin \Theta}{\mathbf{x}^T \cos \Theta} \right) + \mathrm{tan}^{-1} \left( \frac{ \mathbf{y}^T \sin \Theta}{\mathbf{y}^T \cos \Theta} \right) &= \mathrm{tan}^{-1} \left( \frac{\mathbf{x}^T \left[ \mathbf{J} (\Theta) - \mathbf{J} (\Theta)^T \right] \mathbf{y} }{\mathbf{x}^T \left[ \mathbf{C} (\Theta) - \mathbf{S} (\Theta) \right] \mathbf{y}} \right) \end{aligned} $$ From here, I did believe it was simple algebra, but I cannot proceed. Any help will be appreciated. Thanks!","Problem Suppose I have two ""probability"" vectors each of whose elements corresponds to the weight of an evenly discretized circular space ""support"" : Note that the sums of their elements, . We can calculate the ""circular mean"" and ""circular precision"" as follows: where , and cosine alike. Now let , the equal mixture distribution of , . Now I would like to clarify the following question: Question: Can we simplify circular mean , using , , , ? Expectation may look somewhat like . Try Thanks to the invariance of to constant multiplication, i.e. , for , we have where assumed for the third equality for the sake of simplicity. Letting , , , we have Moreover, using , From here, I did believe it was simple algebra, but I cannot proceed. Any help will be appreciated. Thanks!","\mathbf{x}, \mathbf{y} \Theta = [1 \cdot (2\pi/n), 2 \cdot (2\pi/n), \cdots, n \cdot (2\pi/n) ]^T 
\begin{aligned}
\mathbf{x} &= [x_1, x_2, \cdots, x_n]^T \\
\mathbf{y} &= [y_1, y_2, \cdots, y_n]^T \\
\end{aligned}
 \sum x_i \equiv \sum y_i = 1 \bar{\mathbf{X}} \mathrm{prec}({\mathbf{X}}) 
\begin{aligned}
\bar{\mathbf{X}} &= \mathrm{atan2} \left( \mathbf{x}^T \sin \Theta, \mathbf{x}^T \cos \Theta \right) \\ 
\mathrm{prec}({\mathbf{X}}) &= \sqrt{ \left( \mathbf{x}^T \sin \Theta \right)^2 + \left( \mathbf{x}^T \cos \Theta \right)^2 }
\end{aligned}
 \sin \Theta := [\sin \left(1 \cdot (2\pi/n)\right), \sin \left( 2 \cdot (2\pi/n) \right), \cdots, \sin \left( n \cdot (2\pi/n)\right) ]^T \mathbf{z} = (\mathbf{x} + \mathbf{y})/2 \mathbf{x} \mathbf{y} \bar{\mathbf{Z}} \bar{\mathbf{X}} \bar{\mathbf{Y}} \mathrm{prec}({\mathbf{X}}) \mathrm{prec}({\mathbf{Y}}) \bar{\mathbf{Z}} \bar{\mathbf{X}} \cdot \mathrm{prec}(\mathbf{X}) + \bar{\mathbf{Y}} \cdot \mathrm{prec}(\mathbf{Y}) \mathrm{atan2} \mathrm{atan2}(cx,cy) = \mathrm{atan2}(x,y) \forall c>0 
\begin{aligned}
\bar{\mathbf{Z}} &= \mathrm{atan2} \left( \mathbf{z}^T \sin \Theta, \mathbf{z}^T \cos \Theta \right) \\
&= \mathrm{atan2} \left( (\mathbf{x}+\mathbf{y})^T \sin \Theta, (\mathbf{x}+\mathbf{y})^T \cos \Theta \right) \\
&= \mathrm{tan}^{-1} \left( \frac{\mathbf{x}^T \sin \Theta + \mathbf{y}^T \sin \Theta}{\mathbf{x}^T \cos \Theta + \mathbf{y}^T \cos \Theta} \right)
\end{aligned}
 \mathbf{z}^T\cos\Theta >0 \mathbf{S}(\Theta) = \sin \Theta \sin \Theta^T \mathbf{C}(\Theta) = \cos \Theta \cos \Theta^T \mathbf{J}(\Theta) = \sin \Theta \cos \Theta^T 
\mathrm{prec} (\mathbf{X}) = \sqrt{ \mathbf{x}^T \left[\mathbf{S}(\Theta) + \mathbf{C} (\Theta) \right] \mathbf{x} }
 \mathrm{tan}^{-1} (a/b) + \mathrm{tan}^{-1} (x/y) = \mathrm{tan}^{-1} \left( \frac{bx + ay}{by - ax} \right)  
\begin{aligned}
\mathrm{tan}^{-1} \left( \frac{\mathbf{x}^T \sin \Theta}{\mathbf{x}^T \cos \Theta} \right) + \mathrm{tan}^{-1} \left( \frac{ \mathbf{y}^T \sin \Theta}{\mathbf{y}^T \cos \Theta} \right) &= \mathrm{tan}^{-1} \left( \frac{\mathbf{x}^T \left[ \mathbf{J} (\Theta) - \mathbf{J} (\Theta)^T \right] \mathbf{y} }{\mathbf{x}^T \left[ \mathbf{C} (\Theta) - \mathbf{S} (\Theta) \right] \mathbf{y}} \right)
\end{aligned}
","['probability', 'statistics', 'probability-distributions']"
75,What would be the probability density function for a Monte Carlo sampling strategy which only samples a single value?,What would be the probability density function for a Monte Carlo sampling strategy which only samples a single value?,,"Please see my edit for a more concise description of my question Ever since I started looking into the mathematics behind path-tracing algorithms, there has been one question that I haven't been able to find an answer to: How are deterministic samples weighted in an importance sampled Monte Carlo estimation? By deterministic samples, I mean values that will ALWAYS be sampled, as opposed to values which are sampled probabilistically. In importance sampling, non-uniform sampling can be achieved without introducing any bias, by dividing the value of a sample by it's probability of being chosen from a given distribution function. Deterministic samples can't be represented in a probability distribution function, since they are inherently non-probabilistic. My question is: if a specific value or range of values are always sampled, how are they weighted in order to not introduce statistical bias? This is a core mathematical principal behind path-tracing, as samples which connect vertices of a path, which is probabilistically drawn, to light sources are always sampled, in order to reduce variance. This is somehow done without introducing statistical bias, yet I cannot find any information on how this is achieved. EDIT: I have done some more research, and gotten closer to the answer, yet some question still remain. After reading this paper on Multiple Importance Sampling , I have discovered the combined sample density function : here ""n"" represents the number of sampling strategies used, "" "" the fraction of samples taken with strategy k, and "" "" being the probability distribution function of strategy k. MY REMAINING QUESTION IS: What would be the probability density function ( ) for a sampling strategy which only samples a single value? It can't be infinite, otherwise path-tracing algorithms could not handle point, or purely directional light sources, as directly sampling them would contribute an infinitely small amount towards the final estimation of radiance.","Please see my edit for a more concise description of my question Ever since I started looking into the mathematics behind path-tracing algorithms, there has been one question that I haven't been able to find an answer to: How are deterministic samples weighted in an importance sampled Monte Carlo estimation? By deterministic samples, I mean values that will ALWAYS be sampled, as opposed to values which are sampled probabilistically. In importance sampling, non-uniform sampling can be achieved without introducing any bias, by dividing the value of a sample by it's probability of being chosen from a given distribution function. Deterministic samples can't be represented in a probability distribution function, since they are inherently non-probabilistic. My question is: if a specific value or range of values are always sampled, how are they weighted in order to not introduce statistical bias? This is a core mathematical principal behind path-tracing, as samples which connect vertices of a path, which is probabilistically drawn, to light sources are always sampled, in order to reduce variance. This is somehow done without introducing statistical bias, yet I cannot find any information on how this is achieved. EDIT: I have done some more research, and gotten closer to the answer, yet some question still remain. After reading this paper on Multiple Importance Sampling , I have discovered the combined sample density function : here ""n"" represents the number of sampling strategies used, "" "" the fraction of samples taken with strategy k, and "" "" being the probability distribution function of strategy k. MY REMAINING QUESTION IS: What would be the probability density function ( ) for a sampling strategy which only samples a single value? It can't be infinite, otherwise path-tracing algorithms could not handle point, or purely directional light sources, as directly sampling them would contribute an infinitely small amount towards the final estimation of radiance.",,"['statistics', 'computer-science', 'monte-carlo']"
76,How to find the product distribution of two independent random variable with own distribution,How to find the product distribution of two independent random variable with own distribution,,"How to find the distribution function of $G$ given as $f_G(g)$ , where $G = XY$ where $X$ and $Y$ are independent random variable with given pdf as $f_X(x) = \frac{2x^{-\left(\frac{n +4}{n+2}\right)}}{(n + 2) r^2}$ , $x \in [\left(l^2 + r^2\right)^{-\frac{n +2}{2}}, l^{-(n+ 2)}]$ , Assuming $x_{min} = \left(l^2 + r^2\right)^{-\frac{n +2}{2}}$ and $x_{max}= l^{-(n+ 2)}$ . Furhter, $f_Y(y) = \frac{1}{\pi \sqrt{1 - y^2}}$ , $y \in [-1, 1]$ . Here $n, r, l$ are some parameter constant. To find pdf of $G$ I have followed Product distribution As $-1 < y < 1$ and $\frac{z}{x_{max}} < y < \frac{z}{x_{min}}$ . Also, $z \in \left[-x_{max}, x_{max}\right]$ Hence employing Product distribution $f_G(g) = \int_{max\left\{-1,\frac{z}{x_{max}}\right\}}^{min\left\{1,\frac{z}{x_{min}}\right\}} f_Y(y)f_X(\frac{z}{y})\frac{1}{y}\,dy$ . Then after solving I found $f_G(g)$ as $f_G(g) = \frac{2g^{-\left(\frac{n + 4}{n+2}\right)}\left[\beta\left\{\left(1 + \frac{r^2}{l^2}\right)^{(n +2)}, \frac{n+4}{n +2},\frac{1}{2}\right\}-\beta\left\{\frac{n+4}{n +2},\frac{1}{2}\right\}\right]}{\pi(n +2)r^2}$ with $g \in [-l^{-(n+2)}, l^{-(n +2)}]$ . However, problem is when integrating the pdf of $G$ over its range it is not coming as $1$ . Can anyone please provide where I have gone wrong? I guess the limit in the integration of integrant $y$ is wrong can anyone please correct me.","How to find the distribution function of given as , where where and are independent random variable with given pdf as , , Assuming and . Furhter, , . Here are some parameter constant. To find pdf of I have followed Product distribution As and . Also, Hence employing Product distribution . Then after solving I found as with . However, problem is when integrating the pdf of over its range it is not coming as . Can anyone please provide where I have gone wrong? I guess the limit in the integration of integrant is wrong can anyone please correct me.","G f_G(g) G = XY X Y f_X(x) = \frac{2x^{-\left(\frac{n +4}{n+2}\right)}}{(n + 2) r^2} x \in [\left(l^2 + r^2\right)^{-\frac{n +2}{2}}, l^{-(n+ 2)}] x_{min} = \left(l^2 + r^2\right)^{-\frac{n +2}{2}} x_{max}= l^{-(n+ 2)} f_Y(y) = \frac{1}{\pi \sqrt{1 - y^2}} y \in [-1, 1] n, r, l G -1 < y < 1 \frac{z}{x_{max}} < y < \frac{z}{x_{min}} z \in \left[-x_{max}, x_{max}\right] f_G(g) = \int_{max\left\{-1,\frac{z}{x_{max}}\right\}}^{min\left\{1,\frac{z}{x_{min}}\right\}} f_Y(y)f_X(\frac{z}{y})\frac{1}{y}\,dy f_G(g) f_G(g) = \frac{2g^{-\left(\frac{n + 4}{n+2}\right)}\left[\beta\left\{\left(1 + \frac{r^2}{l^2}\right)^{(n +2)}, \frac{n+4}{n +2},\frac{1}{2}\right\}-\beta\left\{\frac{n+4}{n +2},\frac{1}{2}\right\}\right]}{\pi(n +2)r^2} g \in [-l^{-(n+2)}, l^{-(n +2)}] G 1 y","['statistics', 'probability-distributions', 'random-variables']"
77,How to correctly use an integral to model the density?,How to correctly use an integral to model the density?,,"I have a density function $p_X(x)$ of an image $X \in \mathbb{R}^2$ over a set of points $x_i \in X$ . If two points $x_i$ and $x_j$ are within a fixed distance of $\epsilon$ from each other, I want to connect them with an edge. We can find the euclidean distance of every two values BUT this is too slow so i want to create a continuous model to speed it up. Firstly, define the density as $$\rho_0 = \frac{1}{N} \sum_{i=1}^N\delta(X - x_i).$$ Convolve it with a scaled Gaussian Kernel, to get $$\rho_X = \psi \circledast \rho_0 = \frac{1}{2N\epsilon^2 \pi} \sum_{i=1}^N e^{-\frac{(X-x_i)^2}{2\epsilon^2}}$$ My idea is then to integrate $p_X$ over a ball of size $\epsilon$ and centered at the point $x_i$ , i.e. the probability $x_j$ is a distance of $\epsilon$ from $x_i$ : $$ \int_{D(\epsilon,x_i)} p_X dX=  \frac{1}{2N\pi \epsilon^2} \int_{D(\epsilon,x_i)} \sum_{i=1}^N e^{-\frac{(x_1 - x_i)^2 + (x_2 - x_i)^2}{2\epsilon^2}} dx_1dx_2 \approx 0.39$$ If, $ \int_D p_X \ge C\epsilon^2$ , then we join an edge between $x_i$ and any $x_j$ in this ball, since the probability they are close is high enough. However, the result gives a constant so it would always be the same and hence useless to model. Should I integrate a different region and include $x_j$ somehow? But, say if I integrate each $x_i$ at a ball of size $x_j$ , I do NOT want to compute the distance between every $x_i$ and $x_j$ as it defeats the purpose of why I'm doing this!","I have a density function of an image over a set of points . If two points and are within a fixed distance of from each other, I want to connect them with an edge. We can find the euclidean distance of every two values BUT this is too slow so i want to create a continuous model to speed it up. Firstly, define the density as Convolve it with a scaled Gaussian Kernel, to get My idea is then to integrate over a ball of size and centered at the point , i.e. the probability is a distance of from : If, , then we join an edge between and any in this ball, since the probability they are close is high enough. However, the result gives a constant so it would always be the same and hence useless to model. Should I integrate a different region and include somehow? But, say if I integrate each at a ball of size , I do NOT want to compute the distance between every and as it defeats the purpose of why I'm doing this!","p_X(x) X \in \mathbb{R}^2 x_i \in X x_i x_j \epsilon \rho_0 = \frac{1}{N} \sum_{i=1}^N\delta(X - x_i). \rho_X = \psi \circledast \rho_0 = \frac{1}{2N\epsilon^2 \pi} \sum_{i=1}^N e^{-\frac{(X-x_i)^2}{2\epsilon^2}} p_X \epsilon x_i x_j \epsilon x_i  \int_{D(\epsilon,x_i)} p_X dX=  \frac{1}{2N\pi \epsilon^2} \int_{D(\epsilon,x_i)} \sum_{i=1}^N e^{-\frac{(x_1 - x_i)^2 + (x_2 - x_i)^2}{2\epsilon^2}} dx_1dx_2 \approx 0.39  \int_D p_X \ge C\epsilon^2 x_i x_j x_j x_i x_j x_i x_j","['integration', 'statistics', 'mathematical-modeling', 'density-function']"
78,Find the probability that one card is king and the other is heart.,Find the probability that one card is king and the other is heart.,,Two cards are dealt from an ordinary deck of 52 cards (the sampling is without replacement). Find the probability that one card is king and the other is heart. I'm having trouble figure out how to deal with the case where you pick up a king of hearts. Normally I would just multiple the separate probabilities together but as they are not independent? I'm not entirely sure how to proceed.,Two cards are dealt from an ordinary deck of 52 cards (the sampling is without replacement). Find the probability that one card is king and the other is heart. I'm having trouble figure out how to deal with the case where you pick up a king of hearts. Normally I would just multiple the separate probabilities together but as they are not independent? I'm not entirely sure how to proceed.,,"['probability', 'statistics', 'card-games']"
79,What is the reasoning used here to determine the UMVUE?,What is the reasoning used here to determine the UMVUE?,,"Let $X_1, \dots, X_n$ denote a random sample from the PDF $$f_{\varphi}(x)= \begin{cases}  \varphi x^{\varphi - 1} &\text{if}\, 0 < x < 1, \varphi > 0\\       0 &\text{otherwise} \end{cases}$$ This density function is a member of the one-parameter exponential family. Let $A_i = - \log(X_i)$ , where $A_i$ has an exponential distribution. This means that $2\varphi \sum_{i = 1}^n A_i$ has a $\chi^2$ distribution with $2n$ degrees of freedom. Furthermore, I have that $$ E\left[ \left( 2\varphi \sum_{i = 1}^n A_i \right)^{-1} \right] = \dfrac{1}{2n - 2} $$ and $$\text{Var} \left( \dfrac{1}{2 \varphi \sum_{i = 1}^n A_i} \right) = \dfrac{1}{4(n - 1)^2(n - 2)}$$ Apparently, using this information, we can conclude that $\dfrac{n - 1}{\sum_{i = 1}^n A_i} = \dfrac{n - 1}{- \sum_{i = 1}^n \log(X_i)}$ is a UMVUE for $\varphi$ . However, I am not able to follow this reasoning for how they calculated the UMVUE (nor for how they concluded that this is a UMVUE). If I had to guess, it seems to me that they might have done some kind of bias correction at $\dfrac{n - 1}{\sum_{i = 1}^n A_i} = \dfrac{n - 1}{- \sum_{i = 1}^n \log(X_i)}$ , but I'm honestly not sure. What is the reasoning used here for why $\dfrac{n - 1}{\sum_{i = 1}^n A_i} = \dfrac{n - 1}{- \sum_{i = 1}^n \log(X_i)}$ is a UMVUE for $\varphi$ ? I'd greatly appreciate it if someone would please take the time to fill in the gaps and explain this reasoning so that I may understand it.","Let denote a random sample from the PDF This density function is a member of the one-parameter exponential family. Let , where has an exponential distribution. This means that has a distribution with degrees of freedom. Furthermore, I have that and Apparently, using this information, we can conclude that is a UMVUE for . However, I am not able to follow this reasoning for how they calculated the UMVUE (nor for how they concluded that this is a UMVUE). If I had to guess, it seems to me that they might have done some kind of bias correction at , but I'm honestly not sure. What is the reasoning used here for why is a UMVUE for ? I'd greatly appreciate it if someone would please take the time to fill in the gaps and explain this reasoning so that I may understand it.","X_1, \dots, X_n f_{\varphi}(x)=
\begin{cases}
 \varphi x^{\varphi - 1} &\text{if}\, 0 < x < 1, \varphi > 0\\
      0 &\text{otherwise}
\end{cases} A_i = - \log(X_i) A_i 2\varphi \sum_{i = 1}^n A_i \chi^2 2n  E\left[ \left( 2\varphi \sum_{i = 1}^n A_i \right)^{-1} \right] = \dfrac{1}{2n - 2}  \text{Var} \left( \dfrac{1}{2 \varphi \sum_{i = 1}^n A_i} \right) = \dfrac{1}{4(n - 1)^2(n - 2)} \dfrac{n - 1}{\sum_{i = 1}^n A_i} = \dfrac{n - 1}{- \sum_{i = 1}^n \log(X_i)} \varphi \dfrac{n - 1}{\sum_{i = 1}^n A_i} = \dfrac{n - 1}{- \sum_{i = 1}^n \log(X_i)} \dfrac{n - 1}{\sum_{i = 1}^n A_i} = \dfrac{n - 1}{- \sum_{i = 1}^n \log(X_i)} \varphi","['statistics', 'exponential-distribution', 'gamma-distribution', 'chi-squared']"
80,Uncertainty quantification Frequentist vs Bayesian,Uncertainty quantification Frequentist vs Bayesian,,"Is it actually possible to quantify the uncertainty in a frequentist setting? (e.g. using Maximum Likelihood Estimator). Say that we have a dataset $\mathcal{D} = \{(x_i,y_i)\}_{i=1}^n$ and assume that $y_i$ are i.i.d given some parameter $\theta$ . if I have a regression problem it is common to assume the likelihood function $p(\mathcal{D}|\theta)$ being Gaussian. Then since observations are indipendent and identically distributed we have $$p(\mathcal{D}|\theta) = \prod_{i=1}^n p(y_i|x_i,\theta) $$ where each $p(y_i|x_i,\theta) \sim \mathcal{N}(y_i|\mu,\sigma^2)$ Using maximum likelihood estimator we find \begin{align} &\mu_{ML} = \frac{1}{n}\sum_{i=1}^n y_i\\ & \sigma^2_{ML} = \frac{1}{n}\sum_{i=1}^n (y_i-\mu_{ML})^2  \end{align} Based on this procedure, the uncertainty I get does not depend on $x$ but it is just a fixed quantity (i.e. the $\bf{spread}$ of the distribution remains fixed once computed). Instead, using a Bayesian inference approach and putting a gaussian conjugate prior dist. on the parameters we end up having a predictive distribution that looks like this $$p(y_{new}|x_{new}) = \mathcal{N}(y_{new}|\mu(x),\sigma^2(x))$$ which takes specifically into account the input. So, is it true that a Bayesian approach is more suitable to $\bf{quantify}$ uncertainty? Or we can do something similar even with a classical inference approach using MLE? EDIT: This is a plot of Bayesian linear regression. As you can see, according to the notation I've used above, the red line corresponds to $\mu(x)$ while the light red-shaded region is the uncertainty associated to each input (\sigma^2(x)), that clearly depends on it. So my question is, while Bayesian inference clearly quantifies input-depending uncertainty, can we do a similar thing under a classical inference setting? Thanks, James","Is it actually possible to quantify the uncertainty in a frequentist setting? (e.g. using Maximum Likelihood Estimator). Say that we have a dataset and assume that are i.i.d given some parameter . if I have a regression problem it is common to assume the likelihood function being Gaussian. Then since observations are indipendent and identically distributed we have where each Using maximum likelihood estimator we find Based on this procedure, the uncertainty I get does not depend on but it is just a fixed quantity (i.e. the of the distribution remains fixed once computed). Instead, using a Bayesian inference approach and putting a gaussian conjugate prior dist. on the parameters we end up having a predictive distribution that looks like this which takes specifically into account the input. So, is it true that a Bayesian approach is more suitable to uncertainty? Or we can do something similar even with a classical inference approach using MLE? EDIT: This is a plot of Bayesian linear regression. As you can see, according to the notation I've used above, the red line corresponds to while the light red-shaded region is the uncertainty associated to each input (\sigma^2(x)), that clearly depends on it. So my question is, while Bayesian inference clearly quantifies input-depending uncertainty, can we do a similar thing under a classical inference setting? Thanks, James","\mathcal{D} = \{(x_i,y_i)\}_{i=1}^n y_i \theta p(\mathcal{D}|\theta) p(\mathcal{D}|\theta) = \prod_{i=1}^n p(y_i|x_i,\theta)  p(y_i|x_i,\theta) \sim \mathcal{N}(y_i|\mu,\sigma^2) \begin{align}
&\mu_{ML} = \frac{1}{n}\sum_{i=1}^n y_i\\
& \sigma^2_{ML} = \frac{1}{n}\sum_{i=1}^n (y_i-\mu_{ML})^2 
\end{align} x \bf{spread} p(y_{new}|x_{new}) = \mathcal{N}(y_{new}|\mu(x),\sigma^2(x)) \bf{quantify} \mu(x)","['statistics', 'statistical-inference', 'bayesian']"
81,"Gaussian with prior $p(\mu, \Sigma) \propto |\Sigma|^{-(d+1)/2}$. Why is the posterior $\Sigma \mid y \sim \text{Inv-Wishart}(S^{-1})$?",Gaussian with prior . Why is the posterior ?,"p(\mu, \Sigma) \propto |\Sigma|^{-(d+1)/2} \Sigma \mid y \sim \text{Inv-Wishart}(S^{-1})","According to Gelman et al book , page 73, if $p(\mu, \Sigma) \propto |\Sigma|^{-(d+1)/2}$ then $\Sigma \mid y \sim \text{Inv-Wishart}(S^{-1})$ with $n-1$ degrees of freedom for $$S = \sum_i (y_i - \bar{y})(y_i - \bar{y})^T$$ I cannot get the inverse, $S^{-1}$ , am I missing something please? Here is how I do it: By construction any matrix $\sum_i X_i X_i^T$ will have the Wishart distribution if $X$ is drawn from the multivariate normal distribution (with known covariance matrix). Hence $S$ will follow the Wishart with $n-1$ degrees of freedom (conditional on $\Sigma$ ): $$S \sim W_{n-1}(\Sigma)$$ with density: $$ \operatorname{p}(S \mid \Sigma) =  \frac{  |S|^{  \frac{1}{2}(n-d-2)  } \exp\Big[ -\frac{1}{2} \operatorname{Tr}(\Sigma^{-1} S) \Big]  }{  2^{\frac{1}{2}(n-1)d }  |\Sigma|^{(n-1)/2} \Gamma_d(\frac{n-1}{2})    } $$ From Bayes theorem: $p(\Sigma \mid S) \,\, p(S) = p(S \mid \Sigma) \,\, p(\Sigma)$ and since $S\sim W_{n-1}(\Sigma)$ we get: \begin{align}  \operatorname{p}(\Sigma \mid S, \text{data})  	& \propto\operatorname{p}(S \mid \Sigma) \cdot |\Sigma|^{-(d+1)/2}  \nonumber \\ 			& \propto |\Sigma|^{-(n+d)/2} \exp\big[ -\frac{1}{2} \operatorname{Tr}(\Sigma^{-1} \, S)\big] \nonumber \end{align} Isnt the last one the density (up to a scalar) of the Inv-Wishart( $S$ )? According to the book, it should have been the Inv-Wishart( $S^{-1}$ ) instead. What am i doing wrong please?","According to Gelman et al book , page 73, if then with degrees of freedom for I cannot get the inverse, , am I missing something please? Here is how I do it: By construction any matrix will have the Wishart distribution if is drawn from the multivariate normal distribution (with known covariance matrix). Hence will follow the Wishart with degrees of freedom (conditional on ): with density: From Bayes theorem: and since we get: Isnt the last one the density (up to a scalar) of the Inv-Wishart( )? According to the book, it should have been the Inv-Wishart( ) instead. What am i doing wrong please?","p(\mu, \Sigma) \propto |\Sigma|^{-(d+1)/2} \Sigma \mid y \sim \text{Inv-Wishart}(S^{-1}) n-1 S = \sum_i (y_i - \bar{y})(y_i - \bar{y})^T S^{-1} \sum_i X_i X_i^T X S n-1 \Sigma S \sim W_{n-1}(\Sigma) 
\operatorname{p}(S \mid \Sigma) =  \frac{  |S|^{  \frac{1}{2}(n-d-2)  } \exp\Big[ -\frac{1}{2} \operatorname{Tr}(\Sigma^{-1} S) \Big]  }{  2^{\frac{1}{2}(n-1)d }  |\Sigma|^{(n-1)/2} \Gamma_d(\frac{n-1}{2})    }
 p(\Sigma \mid S) \,\, p(S) = p(S \mid \Sigma) \,\, p(\Sigma) S\sim W_{n-1}(\Sigma) \begin{align}
 \operatorname{p}(\Sigma \mid S, \text{data})  	& \propto\operatorname{p}(S \mid \Sigma) \cdot |\Sigma|^{-(d+1)/2}  \nonumber \\
			& \propto |\Sigma|^{-(n+d)/2} \exp\big[ -\frac{1}{2} \operatorname{Tr}(\Sigma^{-1} \, S)\big] \nonumber
\end{align} S S^{-1}","['statistics', 'normal-distribution', 'bayesian', 'gaussian']"
82,Little help understanding the wikipedia derivation of the Chi-Squared with k degrees of freedom,Little help understanding the wikipedia derivation of the Chi-Squared with k degrees of freedom,,"It seems something simple but I still haven’t totally grasped. While reading this wikipedia’s derivation of of Chi-Squared distribution with k-degrees of freedom : Consider the $k$ samples $x_i$ to represent a single point in a $k$ -dimensional space. The chi square distribution for $k$ -degrees of freedom will then be given by: $$ P(Q) \, dQ = \int_\mathcal{V} \prod_{i=1}^k (N(x_i)\,dx_i) = \int_\mathcal{V} \frac{e^{-(x_1^2 + x_2^2 + \cdots +x_k^2)/2}}{(2\pi)^{k/2}}\,dx_1\,dx_2 \cdots dx_k $$ where $N(x)$ is the standard normal distribution and $\mathcal{V}$ is that elemental shell volume at $Q(x)$ which is proportional to the $(k-1)$ -dimensional surface in $k$ -space for which $Q=\sum_{i=1}^k x_i^2$ The derivation continues, but I have a question concerning the term $dQ$ in the above equation for $P(Q)dQ$ . What I understand of the probability of $P(Q)$ is that it is a composition of the function $Q: \mathbb{R}^k \to \mathbb{R}$ with the probability function $P$ . So the probability of the event $P(Q = q)$ is the probability of the event that is a surface of the $k$ -sphere which is the level surface of $w = Q$ at $q$ (which is, the surface $Q(x) = q$ ). So the probability of $P(Q = q)$ should be the integral over this spherical surface of the density function (this density function being $k$ -independent joint normal distributions multiplied). However I don’t quite get de $dQ$ term. Shouldn’t it be just $P(Q)$ ?","It seems something simple but I still haven’t totally grasped. While reading this wikipedia’s derivation of of Chi-Squared distribution with k-degrees of freedom : Consider the samples to represent a single point in a -dimensional space. The chi square distribution for -degrees of freedom will then be given by: where is the standard normal distribution and is that elemental shell volume at which is proportional to the -dimensional surface in -space for which The derivation continues, but I have a question concerning the term in the above equation for . What I understand of the probability of is that it is a composition of the function with the probability function . So the probability of the event is the probability of the event that is a surface of the -sphere which is the level surface of at (which is, the surface ). So the probability of should be the integral over this spherical surface of the density function (this density function being -independent joint normal distributions multiplied). However I don’t quite get de term. Shouldn’t it be just ?","k x_i k k 
P(Q) \, dQ = \int_\mathcal{V} \prod_{i=1}^k (N(x_i)\,dx_i) = \int_\mathcal{V} \frac{e^{-(x_1^2 + x_2^2 + \cdots +x_k^2)/2}}{(2\pi)^{k/2}}\,dx_1\,dx_2 \cdots dx_k
 N(x) \mathcal{V} Q(x) (k-1) k Q=\sum_{i=1}^k x_i^2 dQ P(Q)dQ P(Q) Q: \mathbb{R}^k \to \mathbb{R} P P(Q = q) k w = Q q Q(x) = q P(Q = q) k dQ P(Q)","['real-analysis', 'probability', 'statistics', 'normal-distribution', 'chi-squared']"
83,UMVUE for some function $\tau(\theta)$ when $f(x;\theta)=\frac{\ln(\theta)}{\theta -1} \theta^x$,UMVUE for some function  when,\tau(\theta) f(x;\theta)=\frac{\ln(\theta)}{\theta -1} \theta^x,"I need to find an UMVUE for some function $\tau(\theta)$ for $X_1, \dots, X_n$ random variables with $f(x;\theta)=\frac{\ln(\theta)}{\theta -1}  \theta^x$ where $x\in (0,1)$ . I know that $\sum_{i=1}^{n}X_i$ is a Sufficient and complete statistic, but I don't know which function to choose such that it turns out to be an unbiased estimator. Any hint?","I need to find an UMVUE for some function for random variables with where . I know that is a Sufficient and complete statistic, but I don't know which function to choose such that it turns out to be an unbiased estimator. Any hint?","\tau(\theta) X_1, \dots, X_n f(x;\theta)=\frac{\ln(\theta)}{\theta -1}  \theta^x x\in (0,1) \sum_{i=1}^{n}X_i","['statistics', 'random-variables', 'parameter-estimation']"
84,Why does a right-tailed distribution have a positive third moment?,Why does a right-tailed distribution have a positive third moment?,,"So a right-tailed distribution (or a left-leaning one) has positive skewness, which means a positive third moment. I was trying to convince myself why this is always the case. I am considering a compactly supported discrete distribution for simplicity. Now a typical right-tailed distribution will have its mode and most of the frequency concentrated towards the left, dragging the mean to a bit left of where it would have been for a uniform distribution. So that there are more positive terms in the sum $$\sum_i(x_i-\bar x)^3f_i$$ than negative terms. But the median is to the left of $\bar x$ , which means there is more frequency associated with the negative terms than the positive ones. Why is  it always the case then, that this sum ends up positive? I am guessing that the third powers of the higher magnitude terms end up on top but I am not very convinced.","So a right-tailed distribution (or a left-leaning one) has positive skewness, which means a positive third moment. I was trying to convince myself why this is always the case. I am considering a compactly supported discrete distribution for simplicity. Now a typical right-tailed distribution will have its mode and most of the frequency concentrated towards the left, dragging the mean to a bit left of where it would have been for a uniform distribution. So that there are more positive terms in the sum than negative terms. But the median is to the left of , which means there is more frequency associated with the negative terms than the positive ones. Why is  it always the case then, that this sum ends up positive? I am guessing that the third powers of the higher magnitude terms end up on top but I am not very convinced.",\sum_i(x_i-\bar x)^3f_i \bar x,"['probability', 'statistics']"
85,"Is $\max\{-X_{(1)},X_{(n)}\}$ a one dimensional or two dimensional statistic?",Is  a one dimensional or two dimensional statistic?,"\max\{-X_{(1)},X_{(n)}\}","Is statistic $\max\{-X_{(1)},X_{(n)}\}$ one dimension or two dimension? I was trying to find the minimal sufficient statistic for $U(-\theta,\theta)$ from $n$ $i.i.d$ random variables $X_i$ . The result is that $\theta\ge \max\{-X_{(1)},X_{(n)}\}$ thus the minimal sufficient statistic is $\max\{-X_{(1)},X_{(n)}\}$ . However, the problem actually states that ""Find a two dimensional minimal sufficient statistic for $U(-\theta,\theta)$ "". Is $\max\{-X_{(1)},X_{(n)}\}$ a two dimensional statistic? Here $X_{(i)}$ is the $i^{th}$ smallest value of $X_1,\cdots,X_n$ .","Is statistic one dimension or two dimension? I was trying to find the minimal sufficient statistic for from random variables . The result is that thus the minimal sufficient statistic is . However, the problem actually states that ""Find a two dimensional minimal sufficient statistic for "". Is a two dimensional statistic? Here is the smallest value of .","\max\{-X_{(1)},X_{(n)}\} U(-\theta,\theta) n i.i.d X_i \theta\ge \max\{-X_{(1)},X_{(n)}\} \max\{-X_{(1)},X_{(n)}\} U(-\theta,\theta) \max\{-X_{(1)},X_{(n)}\} X_{(i)} i^{th} X_1,\cdots,X_n","['statistics', 'sufficient-statistics']"
86,How many LinkedIn connections would I need to be 2nd degree with everyone,How many LinkedIn connections would I need to be 2nd degree with everyone,,"A mental experiment, If I would want to be a 2nd degree connection (only 1 person in between me and another one) with everyone on LinkedIn, how many connections would I need to have? I found these number: 722 million users in total ( https://news.linkedin.com/about-us#Statistics ) Every user has 400 connections on average ( https://techjury.net/blog/linkedin-statistics/ ) My reasoning, if all these people would have a unique network (all 400 connections are different), it would be like this: 722 000 000 / 400 = 1.8 million connections Now, I guess majority of users will have a good amount of overlap, so in reality the number would be higher.","A mental experiment, If I would want to be a 2nd degree connection (only 1 person in between me and another one) with everyone on LinkedIn, how many connections would I need to have? I found these number: 722 million users in total ( https://news.linkedin.com/about-us#Statistics ) Every user has 400 connections on average ( https://techjury.net/blog/linkedin-statistics/ ) My reasoning, if all these people would have a unique network (all 400 connections are different), it would be like this: 722 000 000 / 400 = 1.8 million connections Now, I guess majority of users will have a good amount of overlap, so in reality the number would be higher.",,['statistics']
87,Derivation of mutual information's closed-form analytical solution,Derivation of mutual information's closed-form analytical solution,,"$$I(X;Y) = -\frac{1}{2} \ln(1-\rho^2)$$ is the mutual information between two Gaussian random variables. What source derived this formula? Could we have the full derivation here as an answer. First Attempt Given $f(x)$ is the Gaussian p.d.f. of variable $X$ and $f(y)$ is the Gaussian p.d.f. of variable $Y$ , and \begin{align} f(x,y)&=\frac{1}{\left( (2\pi)^{n}\det{(\boldsymbol \Sigma)}\right)^\frac{1}{2}  }\exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})% \right)\\ & = \frac{1}{2 \pi \sigma_X \sigma_Y \sqrt{1-\rho^2}}  \exp \left\{ -\frac{1}{2\left(1-\rho^2\right)} \left[ \left(\frac{x-\mu_{X}}{\sigma_{X}}\right)^2 + \left(\frac{y-\mu_{Y}}{\sigma_{Y}}\right)^2 -2\rho \left(\frac{x-\mu_{X}}{\sigma_{X}}\right) \left(\frac{y-\mu_{X}}{\sigma_{Y}}\right) \right] \right\} \end{align} is the joint distribution where $\boldsymbol{x}, \boldsymbol{\mu}$ and $\boldsymbol{\Sigma}$ are the data observations, means and covariance matrix of the joint distribution, \begin{align} I(X;Y) &= \int \int f(x,y) \ln \frac{f(x,y)}{f(x)f(y)} dx dy\\ &= \int \int f(x,y) \ln \frac{f(x,y)}{\left(2\pi \sigma_X^2\right)^{-\frac{1}{2}} e^{-(x-\mu_X)^2 / 2\sigma_X^2} \cdot \left(2\pi \sigma_Y^2\right)^{-\frac{1}{2}} e^{-(y-\mu_Y)^2 / 2\sigma_Y^2}} dx dy\\ &= ? \end{align}","is the mutual information between two Gaussian random variables. What source derived this formula? Could we have the full derivation here as an answer. First Attempt Given is the Gaussian p.d.f. of variable and is the Gaussian p.d.f. of variable , and is the joint distribution where and are the data observations, means and covariance matrix of the joint distribution,","I(X;Y) = -\frac{1}{2} \ln(1-\rho^2) f(x) X f(y) Y \begin{align}
f(x,y)&=\frac{1}{\left( (2\pi)^{n}\det{(\boldsymbol
\Sigma)}\right)^\frac{1}{2}  }\exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^\top\boldsymbol{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})%
\right)\\
& = \frac{1}{2 \pi \sigma_X \sigma_Y \sqrt{1-\rho^2}} 
\exp \left\{ -\frac{1}{2\left(1-\rho^2\right)} \left[ \left(\frac{x-\mu_{X}}{\sigma_{X}}\right)^2
+ \left(\frac{y-\mu_{Y}}{\sigma_{Y}}\right)^2 -2\rho \left(\frac{x-\mu_{X}}{\sigma_{X}}\right) \left(\frac{y-\mu_{X}}{\sigma_{Y}}\right) \right] \right\}
\end{align} \boldsymbol{x}, \boldsymbol{\mu} \boldsymbol{\Sigma} \begin{align}
I(X;Y) &= \int \int f(x,y) \ln \frac{f(x,y)}{f(x)f(y)} dx dy\\
&= \int \int f(x,y) \ln \frac{f(x,y)}{\left(2\pi \sigma_X^2\right)^{-\frac{1}{2}} e^{-(x-\mu_X)^2 / 2\sigma_X^2} \cdot \left(2\pi \sigma_Y^2\right)^{-\frac{1}{2}} e^{-(y-\mu_Y)^2 / 2\sigma_Y^2}} dx dy\\
&= ?
\end{align}","['statistics', 'logarithms', 'information-theory', 'entropy', 'gaussian']"
88,Question about connection between Poisson and Gamma distributions,Question about connection between Poisson and Gamma distributions,,"Assuming $X\sim\mathcal{P}(\lambda)$ and $Y\sim\Gamma(w,1)$ prove that $P(X\ge w)=P(Y\le \lambda)$. How this fact is lead from the connection between the poisson and exponential distributions? I don't know from where to start. poisson is defined only for discrete situations but the exponential is only for continious situation. How can I prove the fact ? EDIT : for gamma distribution I wrote that $f_Y(y)=\frac{y^{w-1}e^{-y}}{\Gamma(w)}$, but I have problem with integrating it. About Poisson: its function is $\displaystyle \sum _{w_i=0}^w P(X=w_i)$ which I don't know how to sum into a final expression. How can I continue?","Assuming $X\sim\mathcal{P}(\lambda)$ and $Y\sim\Gamma(w,1)$ prove that $P(X\ge w)=P(Y\le \lambda)$. How this fact is lead from the connection between the poisson and exponential distributions? I don't know from where to start. poisson is defined only for discrete situations but the exponential is only for continious situation. How can I prove the fact ? EDIT : for gamma distribution I wrote that $f_Y(y)=\frac{y^{w-1}e^{-y}}{\Gamma(w)}$, but I have problem with integrating it. About Poisson: its function is $\displaystyle \sum _{w_i=0}^w P(X=w_i)$ which I don't know how to sum into a final expression. How can I continue?",,['probability']
89,How do people know that their experiment follows a gamma distribution?,How do people know that their experiment follows a gamma distribution?,,"I am currently taking a Probability and Statistics course and learning the gamma function. Problems are usually phrased like ""A group of scientists did x experiment and it followed a gamma distribution (...)"" but I am wondering how do they know? Especially since the gamma function shape varies a lot depending on the values.","I am currently taking a Probability and Statistics course and learning the gamma function. Problems are usually phrased like ""A group of scientists did x experiment and it followed a gamma distribution (...)"" but I am wondering how do they know? Especially since the gamma function shape varies a lot depending on the values.",,"['statistics', 'probability-distributions', 'gamma-distribution']"
90,Variance of a bootstrap estimator,Variance of a bootstrap estimator,,"Suppose we have a sample $X_1,X_2,...,X_n \sim F$ , where the distribution $F$ is unknown.  Let $T_n = g(X_1,X_2,...,X_n) = \bar{X}^2$ , $\mu = \mathbb{E}[X_1]$ , and define the following: $$\alpha_k = \int \left | x - \mu \right | ^k dF(x) \ \ \ \  \text{and} \ \ \ \ \hat{\alpha}_k = \frac{1}{n}\sum_{i=1}^{n}\left | X_i - \bar{X_n} \right |^k.$$ We can see that $\hat{\alpha}_k$ is the plug-in estimator for $\alpha_k$ . Now suppose we take $B$ bootstrap samples $X_1^*, X_2^* , ..., X_n^*$ and compute $T_n^*$ .  I want to show that the variance of $T_n^*$ , that is, the variance of our bootstrap estimate, is $$v_{\text{bootstrap}}(T_n^*) = \frac{4\bar{X_n}^2 \hat{\alpha}_2}{n} + \frac{4\bar{X_n} \hat{\alpha}_3}{n^2}+\frac{\hat{\alpha}_4}{n^3}.$$ In general, the variance of a bootstrap estimator $S_n^*$ with $B$ bootstrap samples is $$v_{\text{bootstrap}} = \frac{1}{B}\sum_{b=1}^{B}\left ( S_{n,b}^* - \frac{1}{B}\sum_{r=1}^{n}S_{n,r}^* \right )^2,$$ where $S_{n,b}^*$ is the statistic computed from the $b^{\text{th}}$ bootstrap sample.  If I use this definition and apply it to the original problem, I obtain something like \begin{equation} \begin{split} v_{\text{bootstrap}} &=  \frac{1}{B}\sum_{b=1}^{B}\left ( \bar{X}_{n,b}^{*2} - \frac{1}{B}\sum_{r=1}^{n}\bar{X}_{n,r}^{*2} \right )^2 \\ &= \frac{1}{B}\sum_{b=1}^{B}\left [ \bar{X}_{n,b}^{*4} - 2\bar{X}_{n,b}^{*2}\frac{1}{B}\sum_{r=1}^{B}\bar{X}_{n,r}^{*2} + \frac{1}{B^2}\sum_{r=1}^{B}\bar{X}_{n,r}^{*2}\right  ] .\\ \end{split} \end{equation} From here, I don't see anything I can do to get a nicer form.  So although this should simplify to $v_{\text{bootstrap}}(T_n^*),$ I am thinking this is probably not the best approach.  Another approach that I thought of was conditioning.  We have $$\mathrm{Var}[\bar{X}^{*2}] = \mathbb{E}[\mathrm{Var}[\bar{X}^{*2} | X_1, X_2, ... , X_n]] +\mathrm{Var}[\mathbb{E}[\bar{X}^{*2} | X_1, X_2, ... , X_n]].$$ This seems more computable.  The bootstrap distribution is as follows. \begin{array}{|c|c|c|c|} \hline x & \mathbb{P} (X^* = x )\\ \hline X_1 & 1/n \\ \hline X_2 & 1/n \\ \hline \vdots & \vdots  \\ \hline X_n & 1/n \\ \hline \end{array} From this, the expected value and variance of $\bar{X}^*$ come easily, but the squared term in $\bar{X}^{*2}$ is what is tripping me up. Does anyone have any ideas or possible solutions?  Thanks.","Suppose we have a sample , where the distribution is unknown.  Let , , and define the following: We can see that is the plug-in estimator for . Now suppose we take bootstrap samples and compute .  I want to show that the variance of , that is, the variance of our bootstrap estimate, is In general, the variance of a bootstrap estimator with bootstrap samples is where is the statistic computed from the bootstrap sample.  If I use this definition and apply it to the original problem, I obtain something like From here, I don't see anything I can do to get a nicer form.  So although this should simplify to I am thinking this is probably not the best approach.  Another approach that I thought of was conditioning.  We have This seems more computable.  The bootstrap distribution is as follows. From this, the expected value and variance of come easily, but the squared term in is what is tripping me up. Does anyone have any ideas or possible solutions?  Thanks.","X_1,X_2,...,X_n \sim F F T_n = g(X_1,X_2,...,X_n) = \bar{X}^2 \mu = \mathbb{E}[X_1] \alpha_k = \int \left | x - \mu \right | ^k dF(x) \ \ \ \  \text{and} \ \ \ \ \hat{\alpha}_k = \frac{1}{n}\sum_{i=1}^{n}\left | X_i - \bar{X_n} \right |^k. \hat{\alpha}_k \alpha_k B X_1^*, X_2^* , ..., X_n^* T_n^* T_n^* v_{\text{bootstrap}}(T_n^*) = \frac{4\bar{X_n}^2 \hat{\alpha}_2}{n} + \frac{4\bar{X_n} \hat{\alpha}_3}{n^2}+\frac{\hat{\alpha}_4}{n^3}. S_n^* B v_{\text{bootstrap}} = \frac{1}{B}\sum_{b=1}^{B}\left ( S_{n,b}^* - \frac{1}{B}\sum_{r=1}^{n}S_{n,r}^* \right )^2, S_{n,b}^* b^{\text{th}} \begin{equation}
\begin{split}
v_{\text{bootstrap}} &= 
\frac{1}{B}\sum_{b=1}^{B}\left ( \bar{X}_{n,b}^{*2} - \frac{1}{B}\sum_{r=1}^{n}\bar{X}_{n,r}^{*2} \right )^2 \\ &=
\frac{1}{B}\sum_{b=1}^{B}\left [ \bar{X}_{n,b}^{*4} - 2\bar{X}_{n,b}^{*2}\frac{1}{B}\sum_{r=1}^{B}\bar{X}_{n,r}^{*2} + \frac{1}{B^2}\sum_{r=1}^{B}\bar{X}_{n,r}^{*2}\right  ] .\\
\end{split}
\end{equation} v_{\text{bootstrap}}(T_n^*), \mathrm{Var}[\bar{X}^{*2}] = \mathbb{E}[\mathrm{Var}[\bar{X}^{*2} | X_1, X_2, ... , X_n]] +\mathrm{Var}[\mathbb{E}[\bar{X}^{*2} | X_1, X_2, ... , X_n]]. \begin{array}{|c|c|c|c|}
\hline
x & \mathbb{P} (X^* = x )\\ \hline
X_1 & 1/n \\ \hline
X_2 & 1/n \\ \hline
\vdots & \vdots  \\ \hline
X_n & 1/n \\ \hline
\end{array} \bar{X}^* \bar{X}^{*2}","['statistics', 'variance']"
91,"In what interval must the percentage of black squares fall in order to capture 95%, 99%, and 99.9% of possible QR codes?","In what interval must the percentage of black squares fall in order to capture 95%, 99%, and 99.9% of possible QR codes?",,"Generally speaking most QR codes look as though they have about 50% of their cells black. If a putative QR code had 90% or 10% of its cells black, we would reasonably conclude that it didn't look like a QR code. Centred on the mean, which may possibly not be 50%, in what interval must the percentage of black squares fall in order to capture 95%, 99%, and 99.9% of possible QR codes ? I intend ""possible"" to mean ""appearing for normal purposes"", which I realise is open-ended. If it is necessary to assume a certain size, please use version 1, which defines a 21 x 21 cell array.","Generally speaking most QR codes look as though they have about 50% of their cells black. If a putative QR code had 90% or 10% of its cells black, we would reasonably conclude that it didn't look like a QR code. Centred on the mean, which may possibly not be 50%, in what interval must the percentage of black squares fall in order to capture 95%, 99%, and 99.9% of possible QR codes ? I intend ""possible"" to mean ""appearing for normal purposes"", which I realise is open-ended. If it is necessary to assume a certain size, please use version 1, which defines a 21 x 21 cell array.",,[]
92,Under what conditions is this product greater than 1?,Under what conditions is this product greater than 1?,,"I have the following product: $$ \frac{x^T(X^TX)^{-1}x}{x^Tx} $$ Where x $\in$ R $^{N}$ and X $\in$ R $^{M\times N}$ . In my application, $X$ is a design matrix for linear regression. $x$ is a vector of inputs. Under what conditions is this product greater than $\frac{1}{x^Tx}$ ? I few ideas: This looks like Rayleigh quotient $X^TX$ is positive semi-definite See the ""Special case of covariance matrices"" here I think $(X^TX)^{-1}$ yields a Hermatian matrix","I have the following product: Where x R and X R . In my application, is a design matrix for linear regression. is a vector of inputs. Under what conditions is this product greater than ? I few ideas: This looks like Rayleigh quotient is positive semi-definite See the ""Special case of covariance matrices"" here I think yields a Hermatian matrix","
\frac{x^T(X^TX)^{-1}x}{x^Tx}
 \in ^{N} \in ^{M\times N} X x \frac{1}{x^Tx} X^TX (X^TX)^{-1}","['real-analysis', 'linear-algebra', 'statistics', 'eigenvalues-eigenvectors']"
93,Voting intention poll,Voting intention poll,,"In a voting intention polling, we use a a random sample of 400 people and the two candidates, party A and party B get 32% and 28% respectively. Check whether party A will win against party B with probability 99%. I assume that, by ""probability"" they mean ""confidence"". So the question is, if with the given sample size, we can secure a 99% confidence interval that A will win. All I managed to find is critical value *z for 99% confidence, $z = 2.58$ . Then we calculate $β = \frac {32}{100}$ . How do we continue? Thank you very much.","In a voting intention polling, we use a a random sample of 400 people and the two candidates, party A and party B get 32% and 28% respectively. Check whether party A will win against party B with probability 99%. I assume that, by ""probability"" they mean ""confidence"". So the question is, if with the given sample size, we can secure a 99% confidence interval that A will win. All I managed to find is critical value *z for 99% confidence, . Then we calculate . How do we continue? Thank you very much.",z = 2.58 β = \frac {32}{100},['statistics']
94,"Simplify $\mathbb{E}\left[ -\log c(u,v)\right] $, the expected logarithm of the copula density","Simplify , the expected logarithm of the copula density","\mathbb{E}\left[ -\log c(u,v)\right] ","2020 11.26: I finished the derivation but haven't posted it here. I leave this open so that those willing to try their own version can if they want Question How can we derive a closed-form analytical solution for $\mathbb{E}\left[ -\log c(u,v)\right] $ ? $c(u,v)$ is the bivariate copula density for Student's $t$ -copula, whose degrees of freedom is $\nu$ and dependence parameter is $\rho\in (-1,1)$ : \begin{aligned} c(u,v) &= \frac{1}{2\pi \sqrt{1-\rho^2}} \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} \Bigg(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \Bigg)^{-\frac{\nu +2}{2}} \end{aligned} where $$dt(x_i; \nu) = \frac{\Gamma \bigg(\frac{\nu+1}{2}\bigg) }{\Gamma (\frac{\nu}{2}) \sqrt{\pi\nu}} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} } \enspace, i=1,2 $$ or equivalently, $$\displaystyle dt(x_i;\nu) = \frac{1}{\sqrt{\nu}B \left(\frac{1}{2}, \frac{\nu}{2} \right)} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} }, i=1,2 $$ where $\Gamma(\cdot)$ is the gamma function, and $B(\cdot)$ is the beta function. First Attempt \begin{align} h(c(u,v)) &= -\int_{[0,1]^2} c(u,v) \ln c(u,v) \hspace{1mm} du \hspace{1mm} dv \\ &= \mathbb{E}\left[ -\log c(u,v)\right] \\ &= \mathbb{E}\left[ -\log \frac{1}{2\pi \sqrt{1-\rho^2}} \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)^{-\frac{\nu +2}{2}}\right] \\ &=  -\mathbb{E}\left[\log \frac{1}{2\pi \sqrt{1-\rho^2}} + \log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} +\log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)^{-\frac{\nu +2}{2}}\right] \\ &=  -\mathbb{E}\left[-\log \left(2\pi \sqrt{1-\rho^2}\right) + \log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} -\left(\frac{\nu +2}{2}\right) \log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)\right] \\ &=  \log \left(2\pi \sqrt{1-\rho^2}\right) -\mathbb{E}\left[\log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} -\left(\frac{\nu +2}{2}\right) \log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)\right] \\ & = \dots ? \end{align} Hint Why do I think an analytical solution of copula entropy can be found? Because there is one for the entropy of the Normal distribution's pdf , which I copy and paste now from its derivation here : \begin{align}\label{equation:hN} h(X_\mathrm{Gauss}) = &-\int_{-\infty}^{\infty} \left(2\pi \sigma^2\right)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \ln\left[ \left(2\pi \sigma^2\right)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \right] \mathrm{d} x\\ = &\frac{1}{2} \ln(2\pi \sigma^2) \int_{-\infty}^{\infty} (2\pi \sigma^2)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \mathrm{d} x\\ &+ \frac{1}{2\sigma^2} \left(2\pi \sigma^2\right)^{-\frac{1}{2}} (x-\mu)^2 e^{-(x-\mu)^2 / 2\sigma^2} \mathrm{d} x\\ =& \frac{1}{2} \ln (2\pi\sigma^2) + \frac{1}{2}\\ =& \frac12\ln(2\pi\sigma^2) + \frac12\ln e\\ =& \frac12\left(\ln(2\pi\sigma^2) + \ln e\right)\\ =& \frac{1}{2} \ln (2\pi e \sigma^2) \end{align} Link to someone's attempt at the Clayton copula entropy","2020 11.26: I finished the derivation but haven't posted it here. I leave this open so that those willing to try their own version can if they want Question How can we derive a closed-form analytical solution for ? is the bivariate copula density for Student's -copula, whose degrees of freedom is and dependence parameter is : where or equivalently, where is the gamma function, and is the beta function. First Attempt Hint Why do I think an analytical solution of copula entropy can be found? Because there is one for the entropy of the Normal distribution's pdf , which I copy and paste now from its derivation here : Link to someone's attempt at the Clayton copula entropy","\mathbb{E}\left[ -\log c(u,v)\right]  c(u,v) t \nu \rho\in (-1,1) \begin{aligned}
c(u,v) &= \frac{1}{2\pi \sqrt{1-\rho^2}} \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} \Bigg(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \Bigg)^{-\frac{\nu +2}{2}}
\end{aligned} dt(x_i; \nu) = \frac{\Gamma \bigg(\frac{\nu+1}{2}\bigg) }{\Gamma (\frac{\nu}{2}) \sqrt{\pi\nu}} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} } \enspace, i=1,2  \displaystyle dt(x_i;\nu) = \frac{1}{\sqrt{\nu}B \left(\frac{1}{2}, \frac{\nu}{2} \right)} \Bigg( 1+\frac{x_i^2}{\nu} \Bigg)^{-\frac{\nu+1}{2} }, i=1,2  \Gamma(\cdot) B(\cdot) \begin{align}
h(c(u,v)) &= -\int_{[0,1]^2} c(u,v) \ln c(u,v) \hspace{1mm} du \hspace{1mm} dv \\
&= \mathbb{E}\left[ -\log c(u,v)\right] \\
&= \mathbb{E}\left[ -\log \frac{1}{2\pi \sqrt{1-\rho^2}} \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)^{-\frac{\nu +2}{2}}\right] \\
&=  -\mathbb{E}\left[\log \frac{1}{2\pi \sqrt{1-\rho^2}} + \log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} +\log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)^{-\frac{\nu +2}{2}}\right] \\
&=  -\mathbb{E}\left[-\log \left(2\pi \sqrt{1-\rho^2}\right) + \log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} -\left(\frac{\nu +2}{2}\right) \log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)\right] \\
&=  \log \left(2\pi \sqrt{1-\rho^2}\right) -\mathbb{E}\left[\log \frac{1}{dt(x_1; \nu) dt(x_2; \nu)} -\left(\frac{\nu +2}{2}\right) \log  \left(1+\frac{x_1^2 + x_2^2 -2\rho x_1 x_2}{\nu (1-\rho^2)} \right)\right] \\
& = \dots ?
\end{align} \begin{align}\label{equation:hN}
h(X_\mathrm{Gauss}) = &-\int_{-\infty}^{\infty} \left(2\pi \sigma^2\right)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \ln\left[ \left(2\pi \sigma^2\right)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \right] \mathrm{d} x\\
= &\frac{1}{2} \ln(2\pi \sigma^2) \int_{-\infty}^{\infty} (2\pi \sigma^2)^{-\frac{1}{2}} e^{-(x-\mu)^2 / 2\sigma^2} \mathrm{d} x\\
&+ \frac{1}{2\sigma^2} \left(2\pi \sigma^2\right)^{-\frac{1}{2}} (x-\mu)^2 e^{-(x-\mu)^2 / 2\sigma^2} \mathrm{d} x\\
=& \frac{1}{2} \ln (2\pi\sigma^2) + \frac{1}{2}\\
=& \frac12\ln(2\pi\sigma^2) + \frac12\ln e\\
=& \frac12\left(\ln(2\pi\sigma^2) + \ln e\right)\\
=& \frac{1}{2} \ln (2\pi e \sigma^2)
\end{align}","['integration', 'statistics', 'information-theory', 'entropy', 'copula']"
95,How to check if a distribution is subgaussian using a finite sample?,How to check if a distribution is subgaussian using a finite sample?,,"Let $X_1, X_2... X_n$ be a iid sample of size $n$ from some distribution. How can I check if the distribution of these $X_i$ is subgaussian? Is there some statistical test I can apply? My thought is that a distribution is subgaussian if it's tails are bounded by some gaussian, but in practice I can always find some gaussian distribution whose tails dominate those of my finite sample of size $n$ .","Let be a iid sample of size from some distribution. How can I check if the distribution of these is subgaussian? Is there some statistical test I can apply? My thought is that a distribution is subgaussian if it's tails are bounded by some gaussian, but in practice I can always find some gaussian distribution whose tails dominate those of my finite sample of size .","X_1, X_2... X_n n X_i n","['probability', 'statistics', 'hypothesis-testing']"
96,"How to create a high dimensional Gaussian that isn't ""spiky""?","How to create a high dimensional Gaussian that isn't ""spiky""?",,"When sampling from a high dimensional Gaussian distribution the results are similar to sampling from a uniform distribution on a unit sphere. Upon searching, I was able to find this mentioned in [1]. This phenomenon already begins in 3D, see [2]. My objective is to construct a distribution in high dimensions such that the property of Gaussians in 1D and 2D holds, mainly that when given a random sample from such a desired distribution, the best guess as to the mean of that distribution is that given sample. And so that there would be a ""falloff"" from the mean. How can this be achieved? Can it be done? [1] https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/ [2] https://en.wikipedia.org/wiki/Proof_of_Stein%27s_example Edit: After some more keyword googling, I was able to find this very recent Twitter thread which further expands on the problem: https://twitter.com/johncarlosbaez/status/1298274201682325509","When sampling from a high dimensional Gaussian distribution the results are similar to sampling from a uniform distribution on a unit sphere. Upon searching, I was able to find this mentioned in [1]. This phenomenon already begins in 3D, see [2]. My objective is to construct a distribution in high dimensions such that the property of Gaussians in 1D and 2D holds, mainly that when given a random sample from such a desired distribution, the best guess as to the mean of that distribution is that given sample. And so that there would be a ""falloff"" from the mean. How can this be achieved? Can it be done? [1] https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/ [2] https://en.wikipedia.org/wiki/Proof_of_Stein%27s_example Edit: After some more keyword googling, I was able to find this very recent Twitter thread which further expands on the problem: https://twitter.com/johncarlosbaez/status/1298274201682325509",,"['statistics', 'normal-distribution', 'gaussian']"
97,Chernoff bound for binary cross entropy loss with finite bracketing entropy,Chernoff bound for binary cross entropy loss with finite bracketing entropy,,"Consider the binary cross entropy loss of the posterior $\eta(x) = \mathbb{P}(Y=1 | X=x)$ : $$\mathcal{L}_n(\eta) = \frac{1}{n} \sum_{i=1}^n Y_i\log(\eta(X_i)) + (1-Y_i)\log(1-\eta(X_i))$$ Assume that $\eta$ has finite bracketing entropy. Specifically, assume that for every $\eta$ there exists $\eta_L \leq \eta \leq \eta_U$ with $\eta_L, \eta_U \in \mathcal{F_\delta}$ where $\mathcal{F_\delta}$ is a finite class of functions and $\eta_L, \eta_U$ are close in the sense that: $\mathbb{E}|\eta_L- \eta_U| \leq \delta$ . Show the following upper bound on the deviation of the empirical likelihood from the expectation for all $\varepsilon < \varepsilon_0$ where $\varepsilon_0$ is some positive constant that may depend on the $\eta$ being considered: $$\mathbb{P}(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n] > \varepsilon) \leq e^{-n\varepsilon^2/16}$$ I expect I should be able to apply a Chernoff bound here but I am having trouble evaluating or bounding the moment generating function of $\mathcal{L}_n$ : $$\mathbb{P}(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n] > \varepsilon) \leq \inf_t \frac{\mathbb{E}\exp{t\mathcal{L}_n}}{\exp{t\epsilon}}$$ In this case I don't know anything about $\eta$ other than it's range. In particular, $\eta(x)$ can be $0$ for some values of $x$ , in which case $\log(\eta(x))$ is unbounded. How do I deal with this? If it's not possible to show such a bound, what additional assumptions do I need to make so that such a bound is possible? EDIT: I've tried to apply a symmetrization argument, but I am still missing a bound on the deviation of each term in the summation. As described in the question, we will use a chernoff bound: $$\mathbb{P}(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n] > \varepsilon) \leq \inf_t \frac{\mathbb{E}\exp{t(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n])}}{\exp{t\epsilon}}$$ Let's focus on the numerator. By Jensen's: $$\mathbb{E}\exp{t(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n])} \leq \mathbb{E}\exp{t(\mathcal{L}_n - \mathcal{L}_n')}$$ where $\mathcal{L}_n'$ is an independent sample that is identically distributed to $\mathcal{L}_n$ . Now, since $\mathcal{L}_n - \mathcal{L}_n'$ is distributed as $\sigma(\mathcal{L}_n - \mathcal{L}_n')$ where $\sigma$ is a rademacher random variable we can take the expectation conditonal on $\sigma$ and apply the fact that $\sigma$ is subgaussian: $$\leq \Pi_i \mathbb{E}\exp{(t/n)^2(Z_i - Z_i')^2/8}$$ where $Z_i, Z_i'$ are individual terms in the summation forming $\mathcal{L}_n, \mathcal{L}_n'$ respectively. All that remains to do is to upperbound $(Z_i - Z_i')$ and then optimize $t$ to get the upper bound. However, it's not clear to me that I can bound this difference. EDIT 2: It should also be possible to apply Theorem 2 from https://terrytao.wordpress.com/2010/01/03/254a-notes-1-concentration-of-measure/ by showing that each term in the likelihood has bounded variance. EDIT 3: I'm pretty sure we need additional conditions on the class of bracketing functions (either bounded second moment or bounded a.s.) but I am not sure how to show that those conditions are required. For example, for the weak law of large numbers we use the condition of finite variance and arrive at a similar subgaussian convergence rate (we could also arrive at the same rate with absolute integrability condition by applying the truncation method). Although in this case, the convergence is subexponential since we only need to specify some $\epsilon_0$ where the condition holds. This question is from problem 15.4 in [1]. References [1] Devroye, Luc, László Györfi, and Gábor Lugosi. A probabilistic theory of pattern recognition. Vol. 31. Springer Science & Business Media, 2013","Consider the binary cross entropy loss of the posterior : Assume that has finite bracketing entropy. Specifically, assume that for every there exists with where is a finite class of functions and are close in the sense that: . Show the following upper bound on the deviation of the empirical likelihood from the expectation for all where is some positive constant that may depend on the being considered: I expect I should be able to apply a Chernoff bound here but I am having trouble evaluating or bounding the moment generating function of : In this case I don't know anything about other than it's range. In particular, can be for some values of , in which case is unbounded. How do I deal with this? If it's not possible to show such a bound, what additional assumptions do I need to make so that such a bound is possible? EDIT: I've tried to apply a symmetrization argument, but I am still missing a bound on the deviation of each term in the summation. As described in the question, we will use a chernoff bound: Let's focus on the numerator. By Jensen's: where is an independent sample that is identically distributed to . Now, since is distributed as where is a rademacher random variable we can take the expectation conditonal on and apply the fact that is subgaussian: where are individual terms in the summation forming respectively. All that remains to do is to upperbound and then optimize to get the upper bound. However, it's not clear to me that I can bound this difference. EDIT 2: It should also be possible to apply Theorem 2 from https://terrytao.wordpress.com/2010/01/03/254a-notes-1-concentration-of-measure/ by showing that each term in the likelihood has bounded variance. EDIT 3: I'm pretty sure we need additional conditions on the class of bracketing functions (either bounded second moment or bounded a.s.) but I am not sure how to show that those conditions are required. For example, for the weak law of large numbers we use the condition of finite variance and arrive at a similar subgaussian convergence rate (we could also arrive at the same rate with absolute integrability condition by applying the truncation method). Although in this case, the convergence is subexponential since we only need to specify some where the condition holds. This question is from problem 15.4 in [1]. References [1] Devroye, Luc, László Györfi, and Gábor Lugosi. A probabilistic theory of pattern recognition. Vol. 31. Springer Science & Business Media, 2013","\eta(x) = \mathbb{P}(Y=1 | X=x) \mathcal{L}_n(\eta) = \frac{1}{n} \sum_{i=1}^n Y_i\log(\eta(X_i)) + (1-Y_i)\log(1-\eta(X_i)) \eta \eta \eta_L \leq \eta \leq \eta_U \eta_L, \eta_U \in \mathcal{F_\delta} \mathcal{F_\delta} \eta_L, \eta_U \mathbb{E}|\eta_L- \eta_U| \leq \delta \varepsilon < \varepsilon_0 \varepsilon_0 \eta \mathbb{P}(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n] > \varepsilon) \leq e^{-n\varepsilon^2/16} \mathcal{L}_n \mathbb{P}(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n] > \varepsilon) \leq \inf_t \frac{\mathbb{E}\exp{t\mathcal{L}_n}}{\exp{t\epsilon}} \eta \eta(x) 0 x \log(\eta(x)) \mathbb{P}(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n] > \varepsilon) \leq \inf_t \frac{\mathbb{E}\exp{t(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n])}}{\exp{t\epsilon}} \mathbb{E}\exp{t(\mathcal{L}_n - \mathbb{E}[\mathcal{L}_n])} \leq \mathbb{E}\exp{t(\mathcal{L}_n - \mathcal{L}_n')} \mathcal{L}_n' \mathcal{L}_n \mathcal{L}_n - \mathcal{L}_n' \sigma(\mathcal{L}_n - \mathcal{L}_n') \sigma \sigma \sigma \leq \Pi_i \mathbb{E}\exp{(t/n)^2(Z_i - Z_i')^2/8} Z_i, Z_i' \mathcal{L}_n, \mathcal{L}_n' (Z_i - Z_i') t \epsilon_0","['probability', 'statistics', 'concentration-of-measure']"
98,"Looking for the proof of theorem 5.2.11 of Casella, Berger, Statistical Inference","Looking for the proof of theorem 5.2.11 of Casella, Berger, Statistical Inference",,"Theorem 5.2.11 Suppose $X_1,\dots, X_n$ is a random sample from a pdf or pmf $f(x\mid \theta)=h(x)c(\theta)\exp(\sum_{i=1}^kw_i(\theta)T_i(x))$ is in exponential family. Define statistics $T_i=\sum_it_i(X_j)$ where $i=1,\dots, k$ . If the set $\{(w_1(\theta),\dots,w_k(\theta))\}$ contains some open subset of $\mathbb{R}^k$ , then the distribution of $(T_1,\dots, T_k)$ is an exponential family of the form $g(u_1,\dots, u_k\mid\theta)=H(u_1,\dots, u_k)c(\theta)^n \exp(\sum_iw_i(\theta)u_i)$ Q: I am looking for a proof of the theorem or reference of proof. How is containing open set for $(w_1(\theta),\dots,w_k(\theta))$ used to derive transformation? All I could see is that somehow Jacobian between $(T_i)$ 's and $(X_i)$ 's is accounted by part of $H$ but this may not be 1-1.","Theorem 5.2.11 Suppose is a random sample from a pdf or pmf is in exponential family. Define statistics where . If the set contains some open subset of , then the distribution of is an exponential family of the form Q: I am looking for a proof of the theorem or reference of proof. How is containing open set for used to derive transformation? All I could see is that somehow Jacobian between 's and 's is accounted by part of but this may not be 1-1.","X_1,\dots, X_n f(x\mid \theta)=h(x)c(\theta)\exp(\sum_{i=1}^kw_i(\theta)T_i(x)) T_i=\sum_it_i(X_j) i=1,\dots, k \{(w_1(\theta),\dots,w_k(\theta))\} \mathbb{R}^k (T_1,\dots, T_k) g(u_1,\dots, u_k\mid\theta)=H(u_1,\dots, u_k)c(\theta)^n \exp(\sum_iw_i(\theta)u_i) (w_1(\theta),\dots,w_k(\theta)) (T_i) (X_i) H","['probability', 'statistics', 'statistical-inference']"
99,Normalizing constant of an exponential family of distributions with spherical harmonics,Normalizing constant of an exponential family of distributions with spherical harmonics,,"I am interested in modeling a distribution on a sphere with a series expansion in terms of the spherical harmonics $Y_l^m (x)$ where $x \in \mathbb{S}^2$ is a point on the unit sphere. From the paper Harmonic analysis and distribution-free inference for spherical distributions by Jammalamadaka and Terdik I learned that there are multiple ways of achieving this. The following formulation appears to be suitable in my setting: An exponential family of distributions for directional data was introduced in [4] and on p. 82 of [36]. Apart from the normalizing constant, the density has the form $$f_e(x) \propto \exp \sum_{l=0}^{\infty} \sum_{m=-l}^{l} c_l^m Y_l^m (x) $$ where $c_l^{m \ast} = (− 1)^m c_l^{−m}$ . The normalizing constant corresponds to $c_0^0$ and depends on the rest of the parameters $c_l^m$ as well since the integral of $f_e$ must be 1. I am interested in this normalization constant $c_0^0$ . Following the references in the paper, I could not find an expression for $c_0^0$ . Can anybody point me to a paper or book in which an analytical form (or approximation) is given?","I am interested in modeling a distribution on a sphere with a series expansion in terms of the spherical harmonics where is a point on the unit sphere. From the paper Harmonic analysis and distribution-free inference for spherical distributions by Jammalamadaka and Terdik I learned that there are multiple ways of achieving this. The following formulation appears to be suitable in my setting: An exponential family of distributions for directional data was introduced in [4] and on p. 82 of [36]. Apart from the normalizing constant, the density has the form where . The normalizing constant corresponds to and depends on the rest of the parameters as well since the integral of must be 1. I am interested in this normalization constant . Following the references in the paper, I could not find an expression for . Can anybody point me to a paper or book in which an analytical form (or approximation) is given?",Y_l^m (x) x \in \mathbb{S}^2 f_e(x) \propto \exp \sum_{l=0}^{\infty} \sum_{m=-l}^{l} c_l^m Y_l^m (x)  c_l^{m \ast} = (− 1)^m c_l^{−m} c_0^0 c_l^m f_e c_0^0 c_0^0,"['integration', 'statistics', 'spherical-harmonics']"
