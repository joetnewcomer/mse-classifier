,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Finding $\sum\limits_{i=1}^m \frac{i(n-i)! }{ n!}$,Finding,\sum\limits_{i=1}^m \frac{i(n-i)! }{ n!},What will be the value of the following summation? $$\sum_{i=1}^{m}{ \frac{i(n-i)!}{ n!} }$$ Is it $\frac{m}{2}$ ? Can anybody show the derivation?,What will be the value of the following summation? $$\sum_{i=1}^{m}{ \frac{i(n-i)!}{ n!} }$$ Is it $\frac{m}{2}$ ? Can anybody show the derivation?,,"['real-analysis', 'combinatorics', 'sequences-and-series']"
1,Is there a closed form to this expression?,Is there a closed form to this expression?,,"Consider  $$2^{n-1} + 2^{n-2}\dfrac{(n - 1)!}{1!(n - 2)!} + 2^{n-3}\dfrac{(n - 2)!}{2!(n - 2 \cdot 2)!} + 2^{n-4}\dfrac{(n - 3)!}{3!(n - 2 \cdot 3)!} + 2^{n-5} \dfrac{(n - 4)!}{4!(n - 2 \cdot 4)!} + \ldots $$ Until $(n - 2 \cdot k)$ equals to either $0$ or $1$ (even/odd). In other words: $$k = \lfloor \dfrac{n}{2} \rfloor$$ This expression comes from a programming puzzle, and it runs extremely slow when $n$ is large, so I try to find its closed form. Any idea or suggestion would be greatly appreciated.","Consider  $$2^{n-1} + 2^{n-2}\dfrac{(n - 1)!}{1!(n - 2)!} + 2^{n-3}\dfrac{(n - 2)!}{2!(n - 2 \cdot 2)!} + 2^{n-4}\dfrac{(n - 3)!}{3!(n - 2 \cdot 3)!} + 2^{n-5} \dfrac{(n - 4)!}{4!(n - 2 \cdot 4)!} + \ldots $$ Until $(n - 2 \cdot k)$ equals to either $0$ or $1$ (even/odd). In other words: $$k = \lfloor \dfrac{n}{2} \rfloor$$ This expression comes from a programming puzzle, and it runs extremely slow when $n$ is large, so I try to find its closed form. Any idea or suggestion would be greatly appreciated.",,"['sequences-and-series', 'elementary-number-theory']"
2,Every Cauchy sequence in $\mathbb{C}$ is bounded,Every Cauchy sequence in  is bounded,\mathbb{C},"Prove that every Cauchy sequence in $\mathbb{C}$ is bounded. In $\mathbb{R}$, this is a sketch of the proof that I recall: Let {${a_k}$} be Cauchy in $\mathbb{R}$, since $1\in\mathbb{R}$, $\exists N$ s.t. $\forall m,n>N$, $|a_n-A_N|<1\rightarrow$$|a_n|-|A_N|<|a_n-A_N|<1\iff|a_n|<1+|a_N|,\forall n>N-1$. Let $M = \max{|a_1|,|a_2|,\ldots,|a_N-1|,1+|a_N|}$. Then, $M$, $-M$ bound {$a_k$}. A sequence is bounded in $\mathbb{C}$ if $\exists R\in\mathbb{R}$ and an integer $N$ s.t. $|z_n|<R$ $\forall, n>N$. Here's my attempt at the proof at hand then: Let {${z_n}$} be Cauchy in $\mathbb{C}$. I want to show that there exists an R s.t. that definition above is satisfied. Is this R just the $M$ from the proof in $\mathbb{R}$?","Prove that every Cauchy sequence in $\mathbb{C}$ is bounded. In $\mathbb{R}$, this is a sketch of the proof that I recall: Let {${a_k}$} be Cauchy in $\mathbb{R}$, since $1\in\mathbb{R}$, $\exists N$ s.t. $\forall m,n>N$, $|a_n-A_N|<1\rightarrow$$|a_n|-|A_N|<|a_n-A_N|<1\iff|a_n|<1+|a_N|,\forall n>N-1$. Let $M = \max{|a_1|,|a_2|,\ldots,|a_N-1|,1+|a_N|}$. Then, $M$, $-M$ bound {$a_k$}. A sequence is bounded in $\mathbb{C}$ if $\exists R\in\mathbb{R}$ and an integer $N$ s.t. $|z_n|<R$ $\forall, n>N$. Here's my attempt at the proof at hand then: Let {${z_n}$} be Cauchy in $\mathbb{C}$. I want to show that there exists an R s.t. that definition above is satisfied. Is this R just the $M$ from the proof in $\mathbb{R}$?",,"['sequences-and-series', 'complex-analysis', 'convergence-divergence']"
3,limit superior of a sequence proof,limit superior of a sequence proof,,"Let $(x_{n})\in\mathbb{R}^{+}$ be bounded and let $x_{0}=\lim\sup_{n\rightarrow\infty}x_{n}$. $\forall\epsilon>0$, prove that there are infinitely many elements less than $x_{0}+\epsilon$ and finitely many terms greater than $x_{0}+\epsilon$. My attempt: By definition of limit superior, $\forall\epsilon>0$, $\exists N_{\epsilon}\in\mathbb{N}$  s.t. $\forall n>N_{\epsilon}$, $x_{n}<r+\epsilon$ . Since $\{x_{n}\}$ is a bounded sequence, there are only $N_{\epsilon}$  values of $\{x_{n}\}$  s.t. $x_{n}>r+\epsilon$.  However, since for all $n>N_{\epsilon}$,  $x_{n}<r+\epsilon$,  there are infinitely such $x_{n}<r+\epsilon$. I think my proof is probably incomplete/too informal. What do you think?","Let $(x_{n})\in\mathbb{R}^{+}$ be bounded and let $x_{0}=\lim\sup_{n\rightarrow\infty}x_{n}$. $\forall\epsilon>0$, prove that there are infinitely many elements less than $x_{0}+\epsilon$ and finitely many terms greater than $x_{0}+\epsilon$. My attempt: By definition of limit superior, $\forall\epsilon>0$, $\exists N_{\epsilon}\in\mathbb{N}$  s.t. $\forall n>N_{\epsilon}$, $x_{n}<r+\epsilon$ . Since $\{x_{n}\}$ is a bounded sequence, there are only $N_{\epsilon}$  values of $\{x_{n}\}$  s.t. $x_{n}>r+\epsilon$.  However, since for all $n>N_{\epsilon}$,  $x_{n}<r+\epsilon$,  there are infinitely such $x_{n}<r+\epsilon$. I think my proof is probably incomplete/too informal. What do you think?",,"['sequences-and-series', 'limits', 'proof-writing', 'limsup-and-liminf']"
4,Convergence of Sum over Integer Lattice,Convergence of Sum over Integer Lattice,,"Does the sum  $$\sum_{z \in \mathbb{Z}^3\setminus \{(0,0,0)\}} \left( \frac{1}{|{\bf x} - {\bf z}|^2} - \frac{1}{|{\bf z}|^2} \right)$$ converge pointwise or even uniformly for $\varepsilon < |{\bf x}| < 1-\varepsilon$?","Does the sum  $$\sum_{z \in \mathbb{Z}^3\setminus \{(0,0,0)\}} \left( \frac{1}{|{\bf x} - {\bf z}|^2} - \frac{1}{|{\bf z}|^2} \right)$$ converge pointwise or even uniformly for $\varepsilon < |{\bf x}| < 1-\varepsilon$?",,"['sequences-and-series', 'integer-lattices']"
5,Decimal representation series,Decimal representation series,,"Given the following sequence $d(n) = x \cdot n - \lfloor x \cdot n \rfloor$ with $n \in \mathbb{N}$, $x \in \mathbb{R} \backslash \mathbb{Q}$ . I want to show that for every $z \in [0,1)$ there is a subsequence of $d(n)$ that converges against $z$. Notes: I am having serious problems of finding such a subsequence, first I see what the sequence does. If you take for example the subsequence $a(n) = d(10^n)$ you see that it gives you the decimal representation of $x$ starting with the $n'th$ digit. Example: let $x=\pi$, then we get $a(0)=0.141592..., a(1)=0.41592..., a(2)=0.1592...$ and so on. Also this is a plot of $d(n)$ for $x=\pi$: You see that for irrational x the height of the function at integers is not constant, nor periodic. Also this question I asked several weeks ago seems to be related: Proving that an equation is solvable, Floor function","Given the following sequence $d(n) = x \cdot n - \lfloor x \cdot n \rfloor$ with $n \in \mathbb{N}$, $x \in \mathbb{R} \backslash \mathbb{Q}$ . I want to show that for every $z \in [0,1)$ there is a subsequence of $d(n)$ that converges against $z$. Notes: I am having serious problems of finding such a subsequence, first I see what the sequence does. If you take for example the subsequence $a(n) = d(10^n)$ you see that it gives you the decimal representation of $x$ starting with the $n'th$ digit. Example: let $x=\pi$, then we get $a(0)=0.141592..., a(1)=0.41592..., a(2)=0.1592...$ and so on. Also this is a plot of $d(n)$ for $x=\pi$: You see that for irrational x the height of the function at integers is not constant, nor periodic. Also this question I asked several weeks ago seems to be related: Proving that an equation is solvable, Floor function",,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
6,trajectories in ListPlot[the maximal prime factor of average of twin prime pair],trajectories in ListPlot[the maximal prime factor of average of twin prime pair],,"another sequence on twin primes The maximal prime factor of average of twin prime pair: n = 100000; averageList = Select[Prime[Range[n]], PrimeQ[# + 2] &] + 1; mpfList = FactorInteger[#][[-1, 1]] & /@ averageList; ListPlot[%] Why does this diagram look like a series of trajectories?","another sequence on twin primes The maximal prime factor of average of twin prime pair: n = 100000; averageList = Select[Prime[Range[n]], PrimeQ[# + 2] &] + 1; mpfList = FactorInteger[#][[-1, 1]] & /@ averageList; ListPlot[%] Why does this diagram look like a series of trajectories?",,"['sequences-and-series', 'prime-numbers']"
7,"Limit of a trigonometric integral: $\lim\limits_{x \to \infty} \int_{0}^{\pi} \frac{\sin (t)}{1+\cos^{2}(xt)} \, \mathrm dt$",Limit of a trigonometric integral:,"\lim\limits_{x \to \infty} \int_{0}^{\pi} \frac{\sin (t)}{1+\cos^{2}(xt)} \, \mathrm dt","For all $x \in \mathbb{R}$, let  $$ {\rm f}\left(x\right) =\int_{0}^{\pi}\frac{\sin\left(t\right)}{1 + \cos^{2}\left(xt\right)}\,{\rm d}t $$ Compute the limit when $x\rightarrow +\infty$. My attempt : I tried the substitution $u=\sin(t)$ (and $u=\cos^2(xt)$) but it seems worse: $$ \int _{0}^{1}\!{\frac {u}{ \left( 1+ \left( \cos \left( x\arcsin  \left( u \right)  \right)  \right) ^{2} \right) \sqrt {1-{u}^{2}}}}{du} $$ I tried to use a subsequence $(x_n)$ which is tends to $+\infty$ and use the dominated convergence theorem but it didn't work either. Sorry if my attempt doesn't make much sense. Thank you in advance.","For all $x \in \mathbb{R}$, let  $$ {\rm f}\left(x\right) =\int_{0}^{\pi}\frac{\sin\left(t\right)}{1 + \cos^{2}\left(xt\right)}\,{\rm d}t $$ Compute the limit when $x\rightarrow +\infty$. My attempt : I tried the substitution $u=\sin(t)$ (and $u=\cos^2(xt)$) but it seems worse: $$ \int _{0}^{1}\!{\frac {u}{ \left( 1+ \left( \cos \left( x\arcsin  \left( u \right)  \right)  \right) ^{2} \right) \sqrt {1-{u}^{2}}}}{du} $$ I tried to use a subsequence $(x_n)$ which is tends to $+\infty$ and use the dominated convergence theorem but it didn't work either. Sorry if my attempt doesn't make much sense. Thank you in advance.",,"['calculus', 'real-analysis']"
8,Convergence of subsequence defined by geometric sequence,Convergence of subsequence defined by geometric sequence,,"Let $\{x_n\}$ be a real sequence. Suppose that for any geometric sequence $\{a_n\}$ with $a_1>1$ and the common ratio greater than $1$ , $\lim\limits_{n\rightarrow+\infty}x_{[a_n]}=l$ , where $[\cdot]$ is the floor function. Show that $\{x_n\}$ converges to $l$ . Here, floor function $[x]$ is the greatest integer less than or equal to $x$ . If the condition “geometric sequence” is replaced by ""arithmetic sequence"", then the problem is easy to solve because finite many arithmetic sequences will cover all indices; for example, we may take $a_1$ and the common difference $d$ to be arbitrary positive integers, and then $d$ subsequences will cover the whole sequence. An typical example is the even subsequence and the odd subsequence. However, is this idea still applied to “geometric sequence”? If we only consider all index sequences $\{a_n\}$ within integers, it will certainly fail because any prime integer must be the first term of some sequence. Hence, we have to consider the case when the first term $a_1$ or the common ratio is not an integer. Maybe it is related to elementary number theory, isn't it?","Let be a real sequence. Suppose that for any geometric sequence with and the common ratio greater than , , where is the floor function. Show that converges to . Here, floor function is the greatest integer less than or equal to . If the condition “geometric sequence” is replaced by ""arithmetic sequence"", then the problem is easy to solve because finite many arithmetic sequences will cover all indices; for example, we may take and the common difference to be arbitrary positive integers, and then subsequences will cover the whole sequence. An typical example is the even subsequence and the odd subsequence. However, is this idea still applied to “geometric sequence”? If we only consider all index sequences within integers, it will certainly fail because any prime integer must be the first term of some sequence. Hence, we have to consider the case when the first term or the common ratio is not an integer. Maybe it is related to elementary number theory, isn't it?",\{x_n\} \{a_n\} a_1>1 1 \lim\limits_{n\rightarrow+\infty}x_{[a_n]}=l [\cdot] \{x_n\} l [x] x a_1 d d \{a_n\} a_1,"['real-analysis', 'calculus', 'sequences-and-series', 'analysis', 'elementary-number-theory']"
9,The alternating Abel Plana formula and Riemann $\xi\left(\frac12\right)$,The alternating Abel Plana formula and Riemann,\xi\left(\frac12\right),"Starting from the alternating Abel Plana summation formula ( presented here ): $$\sum_{n=0}^\infty (-1)^nf(n) = \frac{f(0)}{2} + i\int_0^\infty\frac{f(iy)−f(−iy)}{2\sinh(πy)} dy \tag{1}$$ and putting $f(t)=\xi\left(\frac12+it\right)$ , where $\xi(s)$ is the Riemann $\xi-$ function . Since $\xi(s) = \xi(1-s)$ the integral part reduces to zero and we obtain: $$2\,\sum_{n=0}^\infty (-1)^n\,\xi\left(\frac12+in\right) = \xi\left(\frac12\right) \tag{2}$$ Questions: Numerically this appears to work fine, but is it formally allowed in terms of the required growth conditions for the Abel Plana formula? This is rather philosophical, but the series on the LHS ""samples"" its values at the integer imaginary parts on the critical line. We know that $\xi\left(\frac12+it\right)$ oscillates around $0$ and has its sign changes at the non-trivial zeros. Given the unpredictable nature of these zeros, the signs of the integer samples are expected to fluctuate rather randomly as well. Does this imply that the complexity of the distribution of the non-trivial zeros is fully ""encoded"" in $\xi\left(\frac12\right)$ ADDED 1: Numerical evidence strongly suggests that the above could be generalised as follows: $$\xi(s) = \sum_{n=1}^\infty (-1)^{n+1}\,\big(\xi\left(s+in\right)+\xi\left(1-s+in\right)\big) \qquad s \in \mathbb{C} \tag{3}$$ or after expanding to the $d$ -th derivative: $$\xi^{(d)}(s) = \sum_{n=1}^\infty (-1)^{n+1}\,\big(\xi^{(d)}\left(s+in\right)+(-1)^d\,\xi^{(d)}\left(1-s+in\right)\big) \qquad s \in \mathbb{C} \tag{4}$$ ADDED 2: Numerical evidence also strongly supports the alternating series with multiplication of $\xi(s)$ : $$\frac12\,\xi(s)^2 = \sum_{n=1}^\infty (-1)^{n+1}\,\xi\left(s+in\right)\,\xi\left(1-s+in\right) \qquad s \in \mathbb{C} \tag{5}$$","Starting from the alternating Abel Plana summation formula ( presented here ): and putting , where is the Riemann function . Since the integral part reduces to zero and we obtain: Questions: Numerically this appears to work fine, but is it formally allowed in terms of the required growth conditions for the Abel Plana formula? This is rather philosophical, but the series on the LHS ""samples"" its values at the integer imaginary parts on the critical line. We know that oscillates around and has its sign changes at the non-trivial zeros. Given the unpredictable nature of these zeros, the signs of the integer samples are expected to fluctuate rather randomly as well. Does this imply that the complexity of the distribution of the non-trivial zeros is fully ""encoded"" in ADDED 1: Numerical evidence strongly suggests that the above could be generalised as follows: or after expanding to the -th derivative: ADDED 2: Numerical evidence also strongly supports the alternating series with multiplication of :","\sum_{n=0}^\infty (-1)^nf(n) = \frac{f(0)}{2} + i\int_0^\infty\frac{f(iy)−f(−iy)}{2\sinh(πy)} dy \tag{1} f(t)=\xi\left(\frac12+it\right) \xi(s) \xi- \xi(s) = \xi(1-s) 2\,\sum_{n=0}^\infty (-1)^n\,\xi\left(\frac12+in\right) = \xi\left(\frac12\right) \tag{2} \xi\left(\frac12+it\right) 0 \xi\left(\frac12\right) \xi(s) = \sum_{n=1}^\infty (-1)^{n+1}\,\big(\xi\left(s+in\right)+\xi\left(1-s+in\right)\big) \qquad s \in \mathbb{C} \tag{3} d \xi^{(d)}(s) = \sum_{n=1}^\infty (-1)^{n+1}\,\big(\xi^{(d)}\left(s+in\right)+(-1)^d\,\xi^{(d)}\left(1-s+in\right)\big) \qquad s \in \mathbb{C} \tag{4} \xi(s) \frac12\,\xi(s)^2 = \sum_{n=1}^\infty (-1)^{n+1}\,\xi\left(s+in\right)\,\xi\left(1-s+in\right) \qquad s \in \mathbb{C} \tag{5}","['sequences-and-series', 'number-theory', 'riemann-zeta']"
10,"Summing a nonstandard sequence, closed form of $S_n(x) = \sum_{i=1}^n x^{c^{i-1}}$","Summing a nonstandard sequence, closed form of",S_n(x) = \sum_{i=1}^n x^{c^{i-1}},"Arithmetic sequences have a common difference, where you add a constant to each term to get the next. Geometric sequences have a common ratio, where you multiply a constant to each term to get the next. Each one of these sort of sequences have a summation formula where you can sum the first $n$ terms without generating them. For an arithmetic sequence $(a_i)_{i=1}^n$ , we have $$\begin{align} a+(a+d)+(a+2d)+\cdots+(a+(n-1)d) &= na+(1+2+\cdots+(n-1))d \\ &=na+\frac{(n-1)(n)}{2}d. \end{align}$$ For a geometric sequence $(a_i)_{i=1}^n$ , we have $$\begin{align} a+ra+r^2a+\cdots+r^{n-1}a &= s \\ ra+r^2a+r^3a+\cdots+r^{n}a &= rs\\ \phantom{d}&\\ \mbox{subtracting line 2 from line 1 gives us:}&\\ \\ r^na -a&= rs-s\\ (r^n-1)a &= (r-1)s\\ \\ \mbox{so, we get:}\\ \\ s &= \frac{r^n-1}{r-1}a \end{align}$$ What if we take this to the next natural step. Instead of adding a constant to get the next term, as in an arithmetic sequence, or multiplying a constant to get the next term, as in a geometric sequence, you instead raise each term to a constant power to get the next term. So, you would have $$a,a^e,(a^e)^e,((a^e)^e)^e,\dots$$ or, more elegantly, $$a,a^e,a^{e^2},a^{e^3},\dots,a^{e^n}$$ for some constant $e$ . I feel like this would be called an exponential sequence, but that seems to be another name for a geometric sequence from google searches. I was playing with trying to make a summation formula for the first $n$ terms of such a sequence, and quickly realized I was stuck. I am sure others have played with such a sequence before, but I couldn't find anything online for similar sequences. Does anyone have any ideas for how to proceed with generating a summation formula? Note that I am not asking what the formula is - I want to derive it myself (this is just for fun), but I cannot find a good starting point. Thanks for any thoughts you all may have! -Andrew Edit: A user named Doug supplied a useful starting point on a comment that has since been deleted, suggesting an approach using partial sums. I wasn't able to look at it until late last night, and I spent a few hours working on it before I had to go to bed. Unfortunately, I got stuck in the weeds of the calculus on their approach, and since it is now gone I can't continue working on it. But, the starting point is sound I think. Note that I will be using $c$ as the constant power, instead of $e$ , because as users have pointed out, $e$ was a bad choice (Euler's constant). If we think of the sum as a finite power series $S_n(x) = \sum_{i=1}^n x^{c^{i-1}}$ , the question becomes finding a closed form of that finite power series. We notice that $$S_n(x^c)-S_n(x)=x^{c^n}-x$$ This gives us a starting point similar to that in finding the summation formula of a geometric series. Unfortunately, the left-hand side doesn't lend itself well to being written as a multiple of $S_n(x)$ . I have tried some tricks, seeing if I could take derivatives and end up with a solvable ODE, but I haven't had much luck. I am going to keep thinking about this, but if anyone browsing the forum has any ideas, please feel free to share!","Arithmetic sequences have a common difference, where you add a constant to each term to get the next. Geometric sequences have a common ratio, where you multiply a constant to each term to get the next. Each one of these sort of sequences have a summation formula where you can sum the first terms without generating them. For an arithmetic sequence , we have For a geometric sequence , we have What if we take this to the next natural step. Instead of adding a constant to get the next term, as in an arithmetic sequence, or multiplying a constant to get the next term, as in a geometric sequence, you instead raise each term to a constant power to get the next term. So, you would have or, more elegantly, for some constant . I feel like this would be called an exponential sequence, but that seems to be another name for a geometric sequence from google searches. I was playing with trying to make a summation formula for the first terms of such a sequence, and quickly realized I was stuck. I am sure others have played with such a sequence before, but I couldn't find anything online for similar sequences. Does anyone have any ideas for how to proceed with generating a summation formula? Note that I am not asking what the formula is - I want to derive it myself (this is just for fun), but I cannot find a good starting point. Thanks for any thoughts you all may have! -Andrew Edit: A user named Doug supplied a useful starting point on a comment that has since been deleted, suggesting an approach using partial sums. I wasn't able to look at it until late last night, and I spent a few hours working on it before I had to go to bed. Unfortunately, I got stuck in the weeds of the calculus on their approach, and since it is now gone I can't continue working on it. But, the starting point is sound I think. Note that I will be using as the constant power, instead of , because as users have pointed out, was a bad choice (Euler's constant). If we think of the sum as a finite power series , the question becomes finding a closed form of that finite power series. We notice that This gives us a starting point similar to that in finding the summation formula of a geometric series. Unfortunately, the left-hand side doesn't lend itself well to being written as a multiple of . I have tried some tricks, seeing if I could take derivatives and end up with a solvable ODE, but I haven't had much luck. I am going to keep thinking about this, but if anyone browsing the forum has any ideas, please feel free to share!","n (a_i)_{i=1}^n \begin{align}
a+(a+d)+(a+2d)+\cdots+(a+(n-1)d) &= na+(1+2+\cdots+(n-1))d \\
&=na+\frac{(n-1)(n)}{2}d.
\end{align} (a_i)_{i=1}^n \begin{align}
a+ra+r^2a+\cdots+r^{n-1}a &= s \\
ra+r^2a+r^3a+\cdots+r^{n}a &= rs\\
\phantom{d}&\\
\mbox{subtracting line 2 from line 1 gives us:}&\\
\\
r^na -a&= rs-s\\
(r^n-1)a &= (r-1)s\\
\\
\mbox{so, we get:}\\
\\
s &= \frac{r^n-1}{r-1}a
\end{align} a,a^e,(a^e)^e,((a^e)^e)^e,\dots a,a^e,a^{e^2},a^{e^3},\dots,a^{e^n} e n c e e S_n(x) = \sum_{i=1}^n x^{c^{i-1}} S_n(x^c)-S_n(x)=x^{c^n}-x S_n(x)","['sequences-and-series', 'summation', 'power-series']"
11,An identity related to the series $\sum_{n\geq 0}p(5n+4)x^n$ in Ramanujan's lost notebook,An identity related to the series  in Ramanujan's lost notebook,\sum_{n\geq 0}p(5n+4)x^n,"While browsing through Ramanujan's original manuscript titled ""The Lost Notebook"" (the link is a PDF file with 379 scanned pages, so instead of a click it is preferable to download) I found this identity (numbered (4.5))  on page 139 $$x\cdot\frac{\left\{(1-x^5)(1-x^{10})(1-x^{15})\dots\right\} ^5} {(1-x)(1-x^2)(1-x^3)\dots} =\frac{x} {(1-x)^2}-\frac{x^2}{(1-x^2)^2}-\frac{x^3}{(1-x^3)^2}+\frac{x^4}{(1-x^4)^2}+\frac{x^6}{(1-x^6)^2}-\frac{x^7}{(1-x^7)^2}-\dots\tag{1}$$ which can be more compactly written as $$x\prod_{n\geq 1}\frac{(1-x^{5n})^5}{1-x^n}=\sum_{n\geq 1}\left(\frac{n}{5}\right)\frac{x^n}{(1-x^n)^2}$$ Next Ramanujan says ""it follows from $(1)$ that $$\{(1-x)(1-x^2)(1-x^3)\dots \} ^5\{p(4)x+p(9)x^2+p(14)x^3+\dots\}=5\left\{\frac{x} {(1-x)^2}-\frac{x^2}{(1-x^2)^2}-\frac{x^3}{(1-x^3)^2}+\frac{x^4}{(1-x^4)^2}+\frac{x^6}{(1-x^6)^2}-\dots\right\}\tag{2}$$ and hence that $$p(4)+p(9)x+p(14)x^2+p(19)x^3+\dots=5\cdot\frac{\{(1-x^5)(1-x^{10})(1-x^{15})\dots\}^5 } {\{(1-x)(1-x^2)(1-x^3)\dots\}^6}\tag{3} $$ Here $p(n) $ denotes the number of unrestricted partitions of a positive integer $n $ and $\left(\dfrac{a}{p} \right) $ denotes the Legendre symbol . The identity $(3)$ mentioned above is famous and is used to derive many partition congruences with $$p(5n+4)\equiv 0\pmod{5}$$ as an immediate consequence. A complete proof of $(3)$ based on different ideas is available in this answer . It took me sometime to figure out as to how $(2)$ follows from $(1)$ . The technique Ramanujan uses here is to expand both sides in powers of $x$ and then pick only the terms with $x^{5n}$ and replace $x^5$ by $x$ . In this process we also make use of the fact that $$1+\sum_{n\geq 1}p(n)x^n=\frac{1}{(1-x)(1-x^2)(1-x^3)\dots}\tag{4}$$ What is really mysterious is the origin of the identity $(1)$ and I am trying to find a proof. I did check the nearby pages of the Lost Notebook and did not find any proofs or hint. However on the same page 139 of the notebook there is another identity (numbered (4.6)) $$\frac{\left\{(1-x)(1-x^2)(1-x^3)\dots\right\} ^5} {(1-x^5)(1-x^{10})(1-x^{15})\dots} =1-5\left(\frac{x} {1-x}-\frac{2x^2}{1-x^2}-\frac{3x^3}{1-x^3}+\frac{4x^4}{1-x^4}+\frac{6x^6}{1-x^6}-\frac{7x^7}{1-x^7}-\dots\right) \tag{5}$$ The identities $(1),(5)$ appear intimately tied to each other and seem to come out of nowhere. Any proofs or references regarding proofs of the identities $(1),(5)$ are desired.","While browsing through Ramanujan's original manuscript titled ""The Lost Notebook"" (the link is a PDF file with 379 scanned pages, so instead of a click it is preferable to download) I found this identity (numbered (4.5))  on page 139 which can be more compactly written as Next Ramanujan says ""it follows from that and hence that Here denotes the number of unrestricted partitions of a positive integer and denotes the Legendre symbol . The identity mentioned above is famous and is used to derive many partition congruences with as an immediate consequence. A complete proof of based on different ideas is available in this answer . It took me sometime to figure out as to how follows from . The technique Ramanujan uses here is to expand both sides in powers of and then pick only the terms with and replace by . In this process we also make use of the fact that What is really mysterious is the origin of the identity and I am trying to find a proof. I did check the nearby pages of the Lost Notebook and did not find any proofs or hint. However on the same page 139 of the notebook there is another identity (numbered (4.6)) The identities appear intimately tied to each other and seem to come out of nowhere. Any proofs or references regarding proofs of the identities are desired.","x\cdot\frac{\left\{(1-x^5)(1-x^{10})(1-x^{15})\dots\right\} ^5} {(1-x)(1-x^2)(1-x^3)\dots} =\frac{x} {(1-x)^2}-\frac{x^2}{(1-x^2)^2}-\frac{x^3}{(1-x^3)^2}+\frac{x^4}{(1-x^4)^2}+\frac{x^6}{(1-x^6)^2}-\frac{x^7}{(1-x^7)^2}-\dots\tag{1} x\prod_{n\geq 1}\frac{(1-x^{5n})^5}{1-x^n}=\sum_{n\geq 1}\left(\frac{n}{5}\right)\frac{x^n}{(1-x^n)^2} (1) \{(1-x)(1-x^2)(1-x^3)\dots \} ^5\{p(4)x+p(9)x^2+p(14)x^3+\dots\}=5\left\{\frac{x} {(1-x)^2}-\frac{x^2}{(1-x^2)^2}-\frac{x^3}{(1-x^3)^2}+\frac{x^4}{(1-x^4)^2}+\frac{x^6}{(1-x^6)^2}-\dots\right\}\tag{2} p(4)+p(9)x+p(14)x^2+p(19)x^3+\dots=5\cdot\frac{\{(1-x^5)(1-x^{10})(1-x^{15})\dots\}^5 } {\{(1-x)(1-x^2)(1-x^3)\dots\}^6}\tag{3}  p(n)  n  \left(\dfrac{a}{p} \right)  (3) p(5n+4)\equiv 0\pmod{5} (3) (2) (1) x x^{5n} x^5 x 1+\sum_{n\geq 1}p(n)x^n=\frac{1}{(1-x)(1-x^2)(1-x^3)\dots}\tag{4} (1) \frac{\left\{(1-x)(1-x^2)(1-x^3)\dots\right\} ^5} {(1-x^5)(1-x^{10})(1-x^{15})\dots} =1-5\left(\frac{x} {1-x}-\frac{2x^2}{1-x^2}-\frac{3x^3}{1-x^3}+\frac{4x^4}{1-x^4}+\frac{6x^6}{1-x^6}-\frac{7x^7}{1-x^7}-\dots\right) \tag{5} (1),(5) (1),(5)","['sequences-and-series', 'integer-partitions', 'q-series']"
12,Unconditional convergence implies convergence of sum of norm squares in hilbert space,Unconditional convergence implies convergence of sum of norm squares in hilbert space,,"Let $(H, (.,.))$ be a Hilbertspace and consider the definition of unconditional convergence, i.e. for a set $I \neq \emptyset$ and a family of vectors $(x_i)_{i \in I}$ in $H$ the series $$ \sum_{i \in I}x_i$$ is said to be unconditional convergent to a value $x \in H$ , if for any $\epsilon > 0$ there is a finite $I_0 \subseteq I$ such that $$ \left\lVert \sum_{i \in \tilde{I}}x_i - x\right\rVert<\epsilon$$ for all finite $\tilde{I} \supseteq I_0$ . Using this definition I wanted to prove that the unconditional convergence of a series $ \sum_{n \in \mathbb{N}} x_n$ in $H$ implies the convergence of $\sum_{n=1}^{\infty} \lVert x_n \rVert^2$ . Using unconditional convergence of $ \sum_{n \in \mathbb{N}} x_n =\colon y$ and the fact that the inner product is linear and continuous in each argument we deduce that $$(y,y) = (\sum_{n \in \mathbb{N}}x_n, \sum_{m \in \mathbb{N}}x_m) = \sum_{n \in \mathbb{N}}\sum_{m \in \mathbb{N}}(x_n, x_m)$$ and analogously for the sums interchanged. Here, the sums on the right side converge unconditionally. From there I want to infer, and I don't know how to do that step, that $$ \sum_{(n,m) \in \mathbb{N} \times \mathbb{N}}(x_n,x_m)$$ converges unconditionally, which would then lead me to the unconditional convergence of $$ \sum_{(n,m) \in \mathbb{N} \times \mathbb{N}}\lvert (x_n,x_m) \rvert.$$ Hence we get $$\sum_{n=1}^{\infty} \lVert x_n \rVert^2 = \sum_{n \in \mathbb{N}}(x_n, x_n) \leq \sum_{(n,m) \in \mathbb{N} \times \mathbb{N}}\lvert (x_n,x_m) \rvert.$$ Thus my question is if is this is correct and if so, how can the step which I highlighted with ""I don't know how to do"" be justified? Thanks in advance.","Let be a Hilbertspace and consider the definition of unconditional convergence, i.e. for a set and a family of vectors in the series is said to be unconditional convergent to a value , if for any there is a finite such that for all finite . Using this definition I wanted to prove that the unconditional convergence of a series in implies the convergence of . Using unconditional convergence of and the fact that the inner product is linear and continuous in each argument we deduce that and analogously for the sums interchanged. Here, the sums on the right side converge unconditionally. From there I want to infer, and I don't know how to do that step, that converges unconditionally, which would then lead me to the unconditional convergence of Hence we get Thus my question is if is this is correct and if so, how can the step which I highlighted with ""I don't know how to do"" be justified? Thanks in advance.","(H, (.,.)) I \neq \emptyset (x_i)_{i \in I} H  \sum_{i \in I}x_i x \in H \epsilon > 0 I_0 \subseteq I  \left\lVert \sum_{i \in \tilde{I}}x_i - x\right\rVert<\epsilon \tilde{I} \supseteq I_0  \sum_{n \in \mathbb{N}} x_n H \sum_{n=1}^{\infty} \lVert x_n \rVert^2  \sum_{n \in \mathbb{N}} x_n =\colon y (y,y) = (\sum_{n \in \mathbb{N}}x_n, \sum_{m \in \mathbb{N}}x_m) = \sum_{n \in \mathbb{N}}\sum_{m \in \mathbb{N}}(x_n, x_m)  \sum_{(n,m) \in \mathbb{N} \times \mathbb{N}}(x_n,x_m)  \sum_{(n,m) \in \mathbb{N} \times \mathbb{N}}\lvert (x_n,x_m) \rvert. \sum_{n=1}^{\infty} \lVert x_n \rVert^2 = \sum_{n \in \mathbb{N}}(x_n, x_n) \leq \sum_{(n,m) \in \mathbb{N} \times \mathbb{N}}\lvert (x_n,x_m) \rvert.","['sequences-and-series', 'functional-analysis', 'hilbert-spaces']"
13,Show that a convergent sequence exists within any uncountable set of reals,Show that a convergent sequence exists within any uncountable set of reals,,"Assume $A$ is an uncountable set of reals, show there exists a convergent sequence $a_n$ such that $(\forall n \ a_n\in A) \land (\forall n,m \ n\neq m\implies a_n\neq a_m)$ Please check the validity of my proof: The equistence of such a sequence implies that there is a point $a$ in $A$ such that in any neighbour-hood around $a$ , there is infinitely many points within it. Assume for a contradiction, the contrary, that is assume: for every point in $a$ there is a neighbour-hood around $a$ in which only finitely many points lie within. Now we will develop a method to count the elements of $A$ via the above assumption, finishing our proof by contradiction. Chose any element say $v_0$ , by the assumption choose a neighbourbood which contains finitely many other points (such that $v_0$ is not the smallest or largest element of this neighbourhood.). Call this set $V_0$ . Define $v_{-1}:=\text{min}(V_0)$ and $v_{1}:=\text{max}(V_0)$ , find a suitable neighbourhood for points $v_1$ and $v_2$ and inductively continue. The countably many finite sets $\cdots,V_{-2},V_{-1},V_0,V_1,V_2,\cdots$ union to make another countable set $V$ . It is easy to prove $A=V$ . $\square$ NEW CLEANER PROOF TO CHECK: Notice that if there exists a neighbourhood with infinitely many elements from $A$ , then the desired sequence exists by Bolzano-Weierstrass. Assume that such a neighbourhood does not exist, chose any $v\in A$ , notice the amount of $a\in A$ and $a\in V_1=(v-1,v+1)$ is finite, $V_2=(v-2,v+2)/V_1$ is finite, and generally $V_n=(v-n,v+n)/V_{n-1}$ is finite. The union of countably many finite $V_n$ is countable, the obvious bijection between $A$ and $V=V_1\cup V_2\cup\cdots$ proves $A$ is countable, we have our contradiction.","Assume is an uncountable set of reals, show there exists a convergent sequence such that Please check the validity of my proof: The equistence of such a sequence implies that there is a point in such that in any neighbour-hood around , there is infinitely many points within it. Assume for a contradiction, the contrary, that is assume: for every point in there is a neighbour-hood around in which only finitely many points lie within. Now we will develop a method to count the elements of via the above assumption, finishing our proof by contradiction. Chose any element say , by the assumption choose a neighbourbood which contains finitely many other points (such that is not the smallest or largest element of this neighbourhood.). Call this set . Define and , find a suitable neighbourhood for points and and inductively continue. The countably many finite sets union to make another countable set . It is easy to prove . NEW CLEANER PROOF TO CHECK: Notice that if there exists a neighbourhood with infinitely many elements from , then the desired sequence exists by Bolzano-Weierstrass. Assume that such a neighbourhood does not exist, chose any , notice the amount of and is finite, is finite, and generally is finite. The union of countably many finite is countable, the obvious bijection between and proves is countable, we have our contradiction.","A a_n (\forall n \ a_n\in A) \land (\forall n,m \ n\neq m\implies a_n\neq a_m) a A a a a A v_0 v_0 V_0 v_{-1}:=\text{min}(V_0) v_{1}:=\text{max}(V_0) v_1 v_2 \cdots,V_{-2},V_{-1},V_0,V_1,V_2,\cdots V A=V \square A v\in A a\in A a\in V_1=(v-1,v+1) V_2=(v-2,v+2)/V_1 V_n=(v-n,v+n)/V_{n-1} V_n A V=V_1\cup V_2\cup\cdots A","['real-analysis', 'sequences-and-series', 'analysis', 'solution-verification', 'proof-writing']"
14,what's the fastest growing series such that it is bounded in $\ell^2$?,what's the fastest growing series such that it is bounded in ?,\ell^2,"How fast a sequence can grow in $\ell_1$ norm before it diverges in $\ell_2$ ? Let $\{a_n\} \in \ell_2(\mathbb{R})$ , i.e. such that $\sum_{n=1}^\infty a_n^2 < \infty$ , we want to find $\sum_{n=1}^N |a_n| = \Theta(N^{\varepsilon})$ (as $N \to \infty$ ) and $\varepsilon$ be the largest possible, what is the value of $\varepsilon$ ? Some remarks: By Hölder inequality, we have a necessary condition that definetely, $$ cN^\varepsilon \le \sum_{k=1}^N |a_n| \le N^{1/2} \left(\sum_{k=1}^N a_n^2 \right)^{1/2} $$ that is $c^2 N^{-(1-2\varepsilon)} \le \sum_{n=1}^N a^2_n$ , because the series in $\ell^2$ must converges, we have that $\varepsilon \le 1/2$ . The sequence $a_n := (n+1)^{\varepsilon} - n^{\varepsilon}$ grows as $N^\varepsilon$ for $0 < \varepsilon < 1/4$ , and it satisfies the conditions: $$ \sum_{n=1}^\infty |a_n| = +\infty$$ and $$\sum_{n=1}^\infty a^2_n \le \varepsilon^2 \sum_{n=1}^\infty ((n+1)^{2\varepsilon-2}) \le \zeta(2-2\varepsilon) < \infty$$ where we used Taylor approximation and the fact that the $\zeta(\beta)$ converges as $\beta = 2 - 2\varepsilon > 1$ . Finally, polynomial ''growth'' is the fastest growth possible or exponential (for very low parameters) is possible? (I conjecture that a growth of $\Theta(N^\varepsilon (\ln N)^\gamma)$ is possible by just adding some harmonic sequence to an already polynomial growing sequence, i.e. $\frac{(n+1)^{\varepsilon + \gamma} - n^{\varepsilon + \gamma}}{n^\eta}$ but I'm not so sure).","How fast a sequence can grow in norm before it diverges in ? Let , i.e. such that , we want to find (as ) and be the largest possible, what is the value of ? Some remarks: By Hölder inequality, we have a necessary condition that definetely, that is , because the series in must converges, we have that . The sequence grows as for , and it satisfies the conditions: and where we used Taylor approximation and the fact that the converges as . Finally, polynomial ''growth'' is the fastest growth possible or exponential (for very low parameters) is possible? (I conjecture that a growth of is possible by just adding some harmonic sequence to an already polynomial growing sequence, i.e. but I'm not so sure).","\ell_1 \ell_2 \{a_n\} \in \ell_2(\mathbb{R}) \sum_{n=1}^\infty a_n^2 < \infty \sum_{n=1}^N |a_n| = \Theta(N^{\varepsilon}) N \to \infty \varepsilon \varepsilon 
cN^\varepsilon \le \sum_{k=1}^N |a_n| \le N^{1/2} \left(\sum_{k=1}^N a_n^2 \right)^{1/2}
 c^2 N^{-(1-2\varepsilon)} \le \sum_{n=1}^N a^2_n \ell^2 \varepsilon \le 1/2 a_n := (n+1)^{\varepsilon} - n^{\varepsilon} N^\varepsilon 0 < \varepsilon < 1/4  \sum_{n=1}^\infty |a_n| = +\infty \sum_{n=1}^\infty a^2_n \le \varepsilon^2 \sum_{n=1}^\infty ((n+1)^{2\varepsilon-2}) \le \zeta(2-2\varepsilon) < \infty \zeta(\beta) \beta = 2 - 2\varepsilon > 1 \Theta(N^\varepsilon (\ln N)^\gamma) \frac{(n+1)^{\varepsilon + \gamma} - n^{\varepsilon + \gamma}}{n^\eta}","['real-analysis', 'sequences-and-series', 'analysis']"
15,Evaluate $\sqrt{x+\sqrt{{x^2}+\sqrt{{x^3}+\sqrt{{x^4}...}}}}$,Evaluate,\sqrt{x+\sqrt{{x^2}+\sqrt{{x^3}+\sqrt{{x^4}...}}}},"I recently became fascinated by infinite nested radicals, first drawn attention to me from a question in my textbook about the value of $\sqrt{1+\sqrt{{1}+\sqrt{{1}+\sqrt{{1}...}}}}$ which turned out to be $\phi$ when I worked it out, a rather beautiful result. I then tried to find a formula to evaluate the general case $$\sqrt{x+\sqrt{{x}+\sqrt{{x}+\sqrt{{x}...}}}}$$ which I succeeded in; it can be evaluated as $$\frac{1+\sqrt{1+4x}}{2}$$ Multiplying the nested radical which was equal to $\phi$ by $x$ produces the following nested radical: $$\sqrt{{x^2}+\sqrt{{x^4}+\sqrt{{x^8}+\sqrt{{x^{16}}...}}}}$$ so this is equal to $x\left(\frac{1+\sqrt5}{2}\right)$ . However, I have tried and failed to find the value of the following infinite square root: $$\sqrt{x+\sqrt{{x^2}+\sqrt{{x^3}+\sqrt{{x^4}...}}}}$$","I recently became fascinated by infinite nested radicals, first drawn attention to me from a question in my textbook about the value of which turned out to be when I worked it out, a rather beautiful result. I then tried to find a formula to evaluate the general case which I succeeded in; it can be evaluated as Multiplying the nested radical which was equal to by produces the following nested radical: so this is equal to . However, I have tried and failed to find the value of the following infinite square root:",\sqrt{1+\sqrt{{1}+\sqrt{{1}+\sqrt{{1}...}}}} \phi \sqrt{x+\sqrt{{x}+\sqrt{{x}+\sqrt{{x}...}}}} \frac{1+\sqrt{1+4x}}{2} \phi x \sqrt{{x^2}+\sqrt{{x^4}+\sqrt{{x^8}+\sqrt{{x^{16}}...}}}} x\left(\frac{1+\sqrt5}{2}\right) \sqrt{x+\sqrt{{x^2}+\sqrt{{x^3}+\sqrt{{x^4}...}}}},"['sequences-and-series', 'convergence-divergence', 'radicals', 'nested-radicals']"
16,"(Complex Stieltjes Integral) If $f$ is integrable wrt $\alpha$, is $\overline{f}$ also integrable wrt $\alpha$?","(Complex Stieltjes Integral) If  is integrable wrt , is  also integrable wrt ?",f \alpha \overline{f} \alpha,"Let $f,\alpha$ be two bounded complex functions on $[0,1]$ . We say that $f$ is integrable w.r.t. $\alpha$ iff the Riemann sum $$\sum f(t_i)(\alpha(x_i)-\alpha(x_{i-1}))$$ converges to a fixed number $I\in\mathbb{C}$ as the partition $P=\left\{0=x_0<x_1<\cdots<x_n=1\right\}$ gets finer. When this is the case, we write $f\in\mathcal{R}(\alpha)$ and that $\int f\,d\alpha=I$ . It is known that when $\alpha$ is of bounded variation, $\mathcal{R}(\alpha)$ contains all continuous functions. I have two questions related to this. Q1. If $f\in\mathcal{R}(\alpha)$ , do we have $\overline{f}\in\mathcal{R}(\alpha)$ too? Q2. Does the answer change if we further assume that $\alpha$ is of bounded variation? There is an example of a pair of sequences $(a_n)$ and $(b_n)$ such that $\sum a_n b_n$ converges while $\sum \overline{a_n} b_n$ diverges. From this I get a feeling that the answers to my questions are both negative, but I could not find counterexamples by myself.","Let be two bounded complex functions on . We say that is integrable w.r.t. iff the Riemann sum converges to a fixed number as the partition gets finer. When this is the case, we write and that . It is known that when is of bounded variation, contains all continuous functions. I have two questions related to this. Q1. If , do we have too? Q2. Does the answer change if we further assume that is of bounded variation? There is an example of a pair of sequences and such that converges while diverges. From this I get a feeling that the answers to my questions are both negative, but I could not find counterexamples by myself.","f,\alpha [0,1] f \alpha \sum f(t_i)(\alpha(x_i)-\alpha(x_{i-1})) I\in\mathbb{C} P=\left\{0=x_0<x_1<\cdots<x_n=1\right\} f\in\mathcal{R}(\alpha) \int f\,d\alpha=I \alpha \mathcal{R}(\alpha) f\in\mathcal{R}(\alpha) \overline{f}\in\mathcal{R}(\alpha) \alpha (a_n) (b_n) \sum a_n b_n \sum \overline{a_n} b_n","['real-analysis', 'sequences-and-series', 'measure-theory', 'riemann-integration', 'stieltjes-integral']"
17,Is it a double coincidence $\sum_{n\ge 2}\frac{1}{n^2}\frac{\log(n!)^{\frac{1}{n}}}{\log n} \approx\lim_{n\to\infty}\frac{(n!)^{\frac{1}{n}}}{n}$?,Is it a double coincidence ?,\sum_{n\ge 2}\frac{1}{n^2}\frac{\log(n!)^{\frac{1}{n}}}{\log n} \approx\lim_{n\to\infty}\frac{(n!)^{\frac{1}{n}}}{n},Is this a double co-incidence or is there a reason why $$ \sum_{n = 2}^{\infty}\frac{\log n!}{n^3 \log n}  = \sum_{n = 2}^{\infty}\frac{1}{n^2}\frac{\log (n!)^{\frac{1}{n}}}{\log n} \approx \lim_{n \to  \infty}\frac{(n!)^{\frac{1}{n}}}{n} = \frac{1}{e} $$ This this could be a coincidence because the difference between the sum and the limit is $< 0.0000523$ which is not earth shatering-ly small lets say as in case of the famous $e^{\pi \sqrt{163}}$ . However there is some similarity in the form of the sum and the limit so this could be a double co-incidence i.e. not just in value but also on the form of the expression. Or is there an explanation why?,Is this a double co-incidence or is there a reason why This this could be a coincidence because the difference between the sum and the limit is which is not earth shatering-ly small lets say as in case of the famous . However there is some similarity in the form of the sum and the limit so this could be a double co-incidence i.e. not just in value but also on the form of the expression. Or is there an explanation why?,"
\sum_{n = 2}^{\infty}\frac{\log n!}{n^3 \log n} 
= \sum_{n = 2}^{\infty}\frac{1}{n^2}\frac{\log (n!)^{\frac{1}{n}}}{\log n} \approx \lim_{n \to  \infty}\frac{(n!)^{\frac{1}{n}}}{n} = \frac{1}{e}
 < 0.0000523 e^{\pi \sqrt{163}}","['sequences-and-series', 'limits', 'analysis', 'number-theory', 'summation']"
18,Closed form for $\sum_{n=1}^\infty x^{-\frac{2\pi}{n}} e^{-2\pi n}$,Closed form for,\sum_{n=1}^\infty x^{-\frac{2\pi}{n}} e^{-2\pi n},"I need a closed form for $$ \sum_{n=1}^\infty x^{-\frac{2\pi}{n}} e^{-2\pi n}$$ where $x\in[1,\infty)$ For $x=1$ we have the sum as $$ \sum_{n=1}^\infty e^{-2\pi n}=\frac{1}{e^{2\pi}-1}$$ For $1<x<\infty$ we can write the sum as $$ \sum_{n=1}^\infty (x^{\frac{1}{n}} e^n)^{-2 \pi} $$ Any help would be appreciated. Thanks.",I need a closed form for where For we have the sum as For we can write the sum as Any help would be appreciated. Thanks.," \sum_{n=1}^\infty x^{-\frac{2\pi}{n}} e^{-2\pi n} x\in[1,\infty) x=1  \sum_{n=1}^\infty e^{-2\pi n}=\frac{1}{e^{2\pi}-1} 1<x<\infty  \sum_{n=1}^\infty (x^{\frac{1}{n}} e^n)^{-2 \pi} ","['real-analysis', 'sequences-and-series', 'summation', 'exponential-sum']"
19,Proving some rational numbers are integers,Proving some rational numbers are integers,,"Let $r_1$ , $\ldots$ , $r_k$ distinct (non-zero) rational numbers, $P_1$ , $\ldots$ , $P_k \in \mathbb{Q}[x]$ non-zero polynomials, such that for every integer $n\ge 0$ the number $$\sum_{s=1}^k P_s(n) r_s^n$$ is an integer. Show that all of the numbers $r_1$ , $\ldots$ , $r_k$ are integers. $\bf{Notes:}$ This is a particular case of a question I posted  before. The solution I managed to come up with of the general case could be  understood here, even by people not familiar with the rudiments of algebraic number theory. Thus the posting.  I would like to see whether there are any other distinct solutions in this case.  Thank you for your attention!  Any feedback would be appreciated!","Let , , distinct (non-zero) rational numbers, , , non-zero polynomials, such that for every integer the number is an integer. Show that all of the numbers , , are integers. This is a particular case of a question I posted  before. The solution I managed to come up with of the general case could be  understood here, even by people not familiar with the rudiments of algebraic number theory. Thus the posting.  I would like to see whether there are any other distinct solutions in this case.  Thank you for your attention!  Any feedback would be appreciated!",r_1 \ldots r_k P_1 \ldots P_k \in \mathbb{Q}[x] n\ge 0 \sum_{s=1}^k P_s(n) r_s^n r_1 \ldots r_k \bf{Notes:},"['sequences-and-series', 'elementary-number-theory', 'divisibility']"
20,"Suppose $(x_n)_n$ is a non-decreasing sequence of natural numbers. Then, $\sum\frac{1}{x_{x_n}-x_n}$ diverges $\iff\sum\frac{1}{x_n}$ diverges.","Suppose  is a non-decreasing sequence of natural numbers. Then,  diverges  diverges.",(x_n)_n \sum\frac{1}{x_{x_n}-x_n} \iff\sum\frac{1}{x_n},"Is the following proposition true, and if so, how can it be proven? I cannot find a counter-example. Proposition: Suppose $\ (x_n)_n\ $ is a non-decreasing sequence of natural numbers, and $\ x_{x_n} \neq x_n\ \forall  n\in\mathbb{N}.\ $ Then, $\ \displaystyle\sum_n \frac{1}{x_{x_n} -  x_n}\ $ diverges $\ \iff \displaystyle\sum_n \frac{1}{x_n}\ $ diverges. Note: if we did not require $\ (x_n)_n\ $ to be non-decreasing, then $\ 2, 10, 4, 100, 6, 1000, 8, 10000, 12, 100000,\ldots\ $ would be a counterexample.","Is the following proposition true, and if so, how can it be proven? I cannot find a counter-example. Proposition: Suppose is a non-decreasing sequence of natural numbers, and Then, diverges diverges. Note: if we did not require to be non-decreasing, then would be a counterexample.","\ (x_n)_n\  \ x_{x_n} \neq x_n\ \forall
 n\in\mathbb{N}.\  \ \displaystyle\sum_n \frac{1}{x_{x_n} -
 x_n}\  \ \iff \displaystyle\sum_n \frac{1}{x_n}\  \ (x_n)_n\  \ 2, 10, 4, 100, 6, 1000, 8, 10000, 12, 100000,\ldots\ ","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'recreational-mathematics', 'problem-solving']"
21,How to bound $\sum_{n=1}^\infty \frac{n^{4k-1}}{e^{2\pi n}-1}$ where $k\in\mathbb{N}$,How to bound  where,\sum_{n=1}^\infty \frac{n^{4k-1}}{e^{2\pi n}-1} k\in\mathbb{N},"By using this answer ( On proving that $\sum\limits_{n=1}^\infty \frac{n^{13}}{e^{2\pi n}-1}=\frac 1{24}$ ), I found that $$2\frac{1-2^{-4k-2}}{1-2^{-4k-1}}\frac{(4k+2)!}{(2\pi)^{4k+2}(8k+4)}\lt \sum_{n=1}^\infty \frac{n^{4k+1}}{e^{2\pi n}-1}\lt \frac{2}{1-2^{-4k-1}}\frac{(4k+2)!}{(2\pi)^{4k+2}(8k+4)}$$ where $k\in\mathbb{N}$ . Are there some known bounds (useful for approximations) for the similar series $$\sum_{n=1}^\infty \frac{n^{4k-1}}{e^{2\pi n}-1}$$ where $k\in\mathbb{N}$ ?","By using this answer ( On proving that $\sum\limits_{n=1}^\infty \frac{n^{13}}{e^{2\pi n}-1}=\frac 1{24}$ ), I found that where . Are there some known bounds (useful for approximations) for the similar series where ?",2\frac{1-2^{-4k-2}}{1-2^{-4k-1}}\frac{(4k+2)!}{(2\pi)^{4k+2}(8k+4)}\lt \sum_{n=1}^\infty \frac{n^{4k+1}}{e^{2\pi n}-1}\lt \frac{2}{1-2^{-4k-1}}\frac{(4k+2)!}{(2\pi)^{4k+2}(8k+4)} k\in\mathbb{N} \sum_{n=1}^\infty \frac{n^{4k-1}}{e^{2\pi n}-1} k\in\mathbb{N},"['real-analysis', 'sequences-and-series', 'inequality']"
22,Verification of proof of convergence of the series $\displaystyle \sum_{n \in \mathbb{N}} (-1)^n \dfrac{n!}{n^n}$,Verification of proof of convergence of the series,\displaystyle \sum_{n \in \mathbb{N}} (-1)^n \dfrac{n!}{n^n},"Could someone please verify my solution to the following question? Question: Does $\sum_{n \in \mathbb{N}} (-1)^n \dfrac{n!}{n^n}$ converge? Answer: I have verified with WolframAlpha that it does converge. I wish to know if my proof is correct: Define $a_n = \dfrac{(-1)^n n!}{n^n}$ . Then $$\left|\dfrac{a_{n+1}}{a_n}\right|= \dfrac{(n+1)!n^n}{(n+1)^{n+1} n!} = (1+1/n)^{-n}.$$ Hence, we see that $\lim\limits_{n\rightarrow\infty} \left|\dfrac{a_{n+1}}{a_n}\right|= \dfrac{1}{e}<1$ from which we deduce that the series is absolutely convergent by the ratio test. Hence the series in question converges.","Could someone please verify my solution to the following question? Question: Does converge? Answer: I have verified with WolframAlpha that it does converge. I wish to know if my proof is correct: Define . Then Hence, we see that from which we deduce that the series is absolutely convergent by the ratio test. Hence the series in question converges.",\sum_{n \in \mathbb{N}} (-1)^n \dfrac{n!}{n^n} a_n = \dfrac{(-1)^n n!}{n^n} \left|\dfrac{a_{n+1}}{a_n}\right|= \dfrac{(n+1)!n^n}{(n+1)^{n+1} n!} = (1+1/n)^{-n}. \lim\limits_{n\rightarrow\infty} \left|\dfrac{a_{n+1}}{a_n}\right|= \dfrac{1}{e}<1,"['real-analysis', 'sequences-and-series', 'solution-verification', 'ratio']"
23,Can you generalize this alternating series for $\log(2)$ to any logarithm series of a similar form?,Can you generalize this alternating series for  to any logarithm series of a similar form?,\log(2),"Look at the decimal expansion for the alternating sum for $\log(2)$ summed upto $n=100000$ and subtract it with the decimal expansion for the actual value for $\log(2)$ : $$\log 2=\sum_{n=1}^{100000}\frac{(-1)^{n-1}}n$$ (* Mathematica start*) digits=100; N[Sum[(-1)^(n + 1)/n, {n, 1, 100000}], digits] N[Log[2], digits] %% - % (*end*) Decimal expansion for the alternating sum for $\log(2)$ truncated at $n=100000$ : 0.69314218058494530941598212145842656807539388436033275412059363449353\ 01469694042252941638997436445553 Decimal expansion of actual value for $\log(2)$ 0.69314718055994530941723212145817656807550013436025525412068000949339\ 36219696947156058633269964186875 The difference between the truncated series and actual value for $\log(2)$ : -4.9999750000000012499999997500000001062499999225000000863749998634750\ 00290490311699427252774132*10^-6 Notice how it is correct at many decimal places beyond the first error. I find that strange. It is like it suggests that there is a series acceleration that would correct this. By guessing and adding fractions that I looked up in the OEIS, it suggests that the alternating sum together with the correcting part for parameters $p = 4$ and $r = 10$ is: $$\log(2)=\sum _{n=1}^{6\ 10 p r} \frac{2 (-1)^n \left(\left(1-2^{-2 n}\right) \zeta (2 n) \Gamma (2 n)\right)}{\pi ^{2 n} \left(r^{2 p}\right)^n}+\sum _{n=1}^{r^p} \frac{(-1)^{n+1}}{n}+\frac{r^{-p}}{2} \;\;\;\;\;\;\;\;(\ast)$$ For $r^p=10^4=10000$ , this gives the decimal expansion of $\log(2)$ to $6004$ correct digits, as shown by this Mathematica program: (*start*) p = 4; r = 10; digits = r^p; N[Sum[(-1)^(n + 1)/n, {n, 1, r^p}] + 1/2*r^(-p) +     Sum[(-1)^(n)*2*(Gamma[2 n]*(1 - 2^(-2 n))*Zeta[2 n])/        Pi^(2 n)/(r^(2*p))^n, {n, 1, 6*10*r*p}], digits]; N[Log[2], digits]; %% - % (*end*) If this is a known result I apologize. What I really would like to know is how does this generalizes to series of similar form for $\log(3),\log(4),\log(5)$ and so on. Also, the requirement that $r=10$ is not optimal, and I don't know how to generalize it away so that $r^p$ can be any integer. For $\log(3)$ with Mathematica: I found the following repeating decimal expansion for the difference between the decimal expansion from the series: $$\text{log3}=\sum _{n=0}^{333333} \left(\frac{1}{(3 n+1)}+\frac{1}{(3 n+2)}-\frac{2}{(3 n+3)}\right) \;\;\;\;\; (\ast\ast)$$ truncated at $n=333333$ and the actual decimal expansion for $\log(3)$ : (*start*) nn = 333333; s = 1; N[Sum[1/(3*n + 1)^s + 1/(3*n + 2)^s - 2/(3*n + 3)^s, {n, 0, nn}], 100] N[Log[3], 100] %% - % (*end*) Truncated series for $\log(3)$ : 1.09861128867077635139526057022385909953625944698030440640216033343750\ 3992932594561746334595530692166 Decimal expansion for the actual value of $\log(3)$ : 1.09861228866810969139524523692252570464749055782274945173469433363749\ 4293218608966873615754813732089 Difference between decimal expansions for truncated series and actual $\log(3)$ : -9.9999733333999998466669866660511123111084244504533253400019999030028\ 6014405127281159283039922*10^-7 Here again we could try to guess the fractions that are found inbetween the repeating digits: (*Mathematica start*) -9.9999733333999998466669866660511123111084244504533253400019999030028\ 6014405127281159283039922419278832912630462820405230189615775`93.\ 65812459130527*^-7 (%*3) - 4/5*10^(-6 - 5) % + 1/5*10^(-16) % - (1 - 54/100)*10^(-22) % + (1 - 5/100)*10^(-28) (*end*)  {-4/5*10^(-6 - 5), +1/    5*10^(-16), -(1 - 54/100)*10^(-22), +(1 - 5/100)*10^(-28)} The guess simplifies to the first few fractions: $$\left\{-\frac{1}{125000000000},\frac{1}{50000000000000000},-\frac{23}{500000000000000000000000},\frac{19}{200000000000000000000000000000}\right\}$$ An OEIS search . Question: Can you generalize the formula in $(\ast)$ for $\log(2)$ to apply to the formula for $\log(3)$ in $(\ast\ast)$ ? That is can you generalize this formula: $$\log(2)=\sum _{n=1}^{6\ 10 p r} \frac{2 (-1)^n \left(\left(1-2^{-2 n}\right) \zeta (2 n) \Gamma (2 n)\right)}{\pi ^{2 n} \left(r^{2 p}\right)^n}+\sum _{n=1}^{r^p} \frac{(-1)^{n+1}}{n}+\frac{r^{-p}}{2} \;\;\;\;\;\;\;\;(\ast)$$ to apply to this formula: $$\log(3)=\sum _{n=0}^{\infty} \left(\frac{1}{(3 n+1)}+\frac{1}{(3 n+2)}-\frac{2}{(3 n+3)}\right) \;\;\;\;\; (\ast\ast)$$ Or even: $$\log(4)=\sum _{n=0}^{n=\infty} \left(\frac{1}{(4 n+1)}+\frac{1}{(4 n+2)}+\frac{1}{(4 n+3)}-\frac{3}{(4 n+4)}\right)$$ and so on .","Look at the decimal expansion for the alternating sum for summed upto and subtract it with the decimal expansion for the actual value for : (* Mathematica start*) digits=100; N[Sum[(-1)^(n + 1)/n, {n, 1, 100000}], digits] N[Log[2], digits] %% - % (*end*) Decimal expansion for the alternating sum for truncated at : 0.69314218058494530941598212145842656807539388436033275412059363449353\ 01469694042252941638997436445553 Decimal expansion of actual value for 0.69314718055994530941723212145817656807550013436025525412068000949339\ 36219696947156058633269964186875 The difference between the truncated series and actual value for : -4.9999750000000012499999997500000001062499999225000000863749998634750\ 00290490311699427252774132*10^-6 Notice how it is correct at many decimal places beyond the first error. I find that strange. It is like it suggests that there is a series acceleration that would correct this. By guessing and adding fractions that I looked up in the OEIS, it suggests that the alternating sum together with the correcting part for parameters and is: For , this gives the decimal expansion of to correct digits, as shown by this Mathematica program: (*start*) p = 4; r = 10; digits = r^p; N[Sum[(-1)^(n + 1)/n, {n, 1, r^p}] + 1/2*r^(-p) +     Sum[(-1)^(n)*2*(Gamma[2 n]*(1 - 2^(-2 n))*Zeta[2 n])/        Pi^(2 n)/(r^(2*p))^n, {n, 1, 6*10*r*p}], digits]; N[Log[2], digits]; %% - % (*end*) If this is a known result I apologize. What I really would like to know is how does this generalizes to series of similar form for and so on. Also, the requirement that is not optimal, and I don't know how to generalize it away so that can be any integer. For with Mathematica: I found the following repeating decimal expansion for the difference between the decimal expansion from the series: truncated at and the actual decimal expansion for : (*start*) nn = 333333; s = 1; N[Sum[1/(3*n + 1)^s + 1/(3*n + 2)^s - 2/(3*n + 3)^s, {n, 0, nn}], 100] N[Log[3], 100] %% - % (*end*) Truncated series for : 1.09861128867077635139526057022385909953625944698030440640216033343750\ 3992932594561746334595530692166 Decimal expansion for the actual value of : 1.09861228866810969139524523692252570464749055782274945173469433363749\ 4293218608966873615754813732089 Difference between decimal expansions for truncated series and actual : -9.9999733333999998466669866660511123111084244504533253400019999030028\ 6014405127281159283039922*10^-7 Here again we could try to guess the fractions that are found inbetween the repeating digits: (*Mathematica start*) -9.9999733333999998466669866660511123111084244504533253400019999030028\ 6014405127281159283039922419278832912630462820405230189615775`93.\ 65812459130527*^-7 (%*3) - 4/5*10^(-6 - 5) % + 1/5*10^(-16) % - (1 - 54/100)*10^(-22) % + (1 - 5/100)*10^(-28) (*end*)  {-4/5*10^(-6 - 5), +1/    5*10^(-16), -(1 - 54/100)*10^(-22), +(1 - 5/100)*10^(-28)} The guess simplifies to the first few fractions: An OEIS search . Question: Can you generalize the formula in for to apply to the formula for in ? That is can you generalize this formula: to apply to this formula: Or even: and so on .","\log(2) n=100000 \log(2) \log 2=\sum_{n=1}^{100000}\frac{(-1)^{n-1}}n \log(2) n=100000 \log(2) \log(2) p = 4 r = 10 \log(2)=\sum _{n=1}^{6\ 10 p r} \frac{2 (-1)^n \left(\left(1-2^{-2 n}\right) \zeta (2 n) \Gamma (2 n)\right)}{\pi ^{2 n} \left(r^{2 p}\right)^n}+\sum _{n=1}^{r^p} \frac{(-1)^{n+1}}{n}+\frac{r^{-p}}{2} \;\;\;\;\;\;\;\;(\ast) r^p=10^4=10000 \log(2) 6004 \log(3),\log(4),\log(5) r=10 r^p \log(3) \text{log3}=\sum _{n=0}^{333333} \left(\frac{1}{(3 n+1)}+\frac{1}{(3 n+2)}-\frac{2}{(3 n+3)}\right) \;\;\;\;\; (\ast\ast) n=333333 \log(3) \log(3) \log(3) \log(3) \left\{-\frac{1}{125000000000},\frac{1}{50000000000000000},-\frac{23}{500000000000000000000000},\frac{19}{200000000000000000000000000000}\right\} (\ast) \log(2) \log(3) (\ast\ast) \log(2)=\sum _{n=1}^{6\ 10 p r} \frac{2 (-1)^n \left(\left(1-2^{-2 n}\right) \zeta (2 n) \Gamma (2 n)\right)}{\pi ^{2 n} \left(r^{2 p}\right)^n}+\sum _{n=1}^{r^p} \frac{(-1)^{n+1}}{n}+\frac{r^{-p}}{2} \;\;\;\;\;\;\;\;(\ast) \log(3)=\sum _{n=0}^{\infty} \left(\frac{1}{(3 n+1)}+\frac{1}{(3 n+2)}-\frac{2}{(3 n+3)}\right) \;\;\;\;\; (\ast\ast) \log(4)=\sum _{n=0}^{n=\infty} \left(\frac{1}{(4 n+1)}+\frac{1}{(4 n+2)}+\frac{1}{(4 n+3)}-\frac{3}{(4 n+4)}\right)","['sequences-and-series', 'logarithms']"
24,determine whether it is possible that $a_n$ is composite only finitely many times,determine whether it is possible that  is composite only finitely many times,a_n,"Form a sequence $(a_n)$ as follows: Let $a_1$ be any positive integer. Let $a_{n+1}$ be formed from $a_n$ by appending any decimal digit to the end of $a_1$ . Determine, with proof, whether it is possible that $a_n$ is composite only finitely often (i.e. if there exists a value of $a_1$ that makes $a_n$ composite only finitely often). The digits $0, 2, 4, 5, 6, 8$ can only be used finitely many times as otherwise one would get infinitely many composites. The digits $1, 7$ can only be used finitely many times as, after we stop using $2, 5$ and $8$ , they are the only ones to change the remainder modulo $3$ and both add $1$ to it (otherwise there would be infinitely many multiples of $3$ ). Both $3$ and $9$ must be used infinitely many times because, if at some point a prime $p$ is reached, adding at most $p$ of the same digit yields another multiple of $p$ . Even with these restrictions the question seems very hard. For instance, the following are primes of length $9$ : $1979339333, 1979339339$ .","Form a sequence as follows: Let be any positive integer. Let be formed from by appending any decimal digit to the end of . Determine, with proof, whether it is possible that is composite only finitely often (i.e. if there exists a value of that makes composite only finitely often). The digits can only be used finitely many times as otherwise one would get infinitely many composites. The digits can only be used finitely many times as, after we stop using and , they are the only ones to change the remainder modulo and both add to it (otherwise there would be infinitely many multiples of ). Both and must be used infinitely many times because, if at some point a prime is reached, adding at most of the same digit yields another multiple of . Even with these restrictions the question seems very hard. For instance, the following are primes of length : .","(a_n) a_1 a_{n+1} a_n a_1 a_n a_1 a_n 0, 2, 4, 5, 6, 8 1, 7 2, 5 8 3 1 3 3 9 p p p 9 1979339333, 1979339339","['sequences-and-series', 'elementary-number-theory', 'discrete-mathematics', 'contest-math', 'divisibility']"
25,A weighted count of Egyptian fraction representations,A weighted count of Egyptian fraction representations,,"Given a positive rational $\alpha$ and a natural number $k$ , let $N_k(\alpha)$ be the number of Egyptian fraction representations of $\alpha$ with smallest element ${1\over k}$ (see e.g. the survey ""Paul Erdős and Egyptian Fractions"" by Graham) . For $s>0$ let $$S_s(\alpha):=\sum_{k\in\mathbb{N}}{N_k(\alpha)\over k^s}$$ and let $$t(\alpha)=\inf\{s: S_s(\alpha)<\infty\}.$$ My first question is what the above ""threshold"" value is, in at least one particular natural case: Q1 : What is $t(1)$ ? Or, failing that, can we compute any concrete examples of $t(\alpha)$ ? Tentatively, I suspect that $t(\alpha)=1$ for every positive rational $\alpha$ , but I don't see how to prove that. Basically, I need an appropriate bound on the number of Egyptian fraction representations of a given rational with a given smallest term, but I don't see how to get a bound which is good enough for this question. My second question is about what happens, specifically, at $s=2$ : Q2 : What is $S_2(1)$ ?","Given a positive rational and a natural number , let be the number of Egyptian fraction representations of with smallest element (see e.g. the survey ""Paul Erdős and Egyptian Fractions"" by Graham) . For let and let My first question is what the above ""threshold"" value is, in at least one particular natural case: Q1 : What is ? Or, failing that, can we compute any concrete examples of ? Tentatively, I suspect that for every positive rational , but I don't see how to prove that. Basically, I need an appropriate bound on the number of Egyptian fraction representations of a given rational with a given smallest term, but I don't see how to get a bound which is good enough for this question. My second question is about what happens, specifically, at : Q2 : What is ?",\alpha k N_k(\alpha) \alpha {1\over k} s>0 S_s(\alpha):=\sum_{k\in\mathbb{N}}{N_k(\alpha)\over k^s} t(\alpha)=\inf\{s: S_s(\alpha)<\infty\}. t(1) t(\alpha) t(\alpha)=1 \alpha s=2 S_2(1),"['sequences-and-series', 'number-theory', 'recreational-mathematics', 'egyptian-fractions']"
26,Proof that the series $\sum_{n=2}^{\infty}\frac{[\Omega(n)]^\alpha}{n^2}$ converges,Proof that the series  converges,\sum_{n=2}^{\infty}\frac{[\Omega(n)]^\alpha}{n^2},"Let's consider the series $$f(\alpha)=\sum_{n\gt1}\frac{[\,\Omega(n)\,]^\alpha}{n^2}$$ where $\Omega(n)$ denotes the number of prime factors of $n$ counted with their multiplicity and $\alpha\ge0$ is a real parameter. It is known that $$f(0)=\frac{\pi^2}{6}-1$$ and by computational experiments results that $$f\Big(\frac 1 2\Big)=0.74587577\dots$$ $$f(1)=0.90748082\dots$$ $$f(2)=1.62036452\dots$$ How to prove that $f(\alpha)$ is finite (that is the given series converges) for any value of $\alpha$ ? The trend of the function $\log f(\alpha)$ is shown in the following graph: One could conjecture that $$f(\alpha)\sim e^{C\alpha}$$ with $C=\frac 5 2$ approximately. How to prove this estimate?",Let's consider the series where denotes the number of prime factors of counted with their multiplicity and is a real parameter. It is known that and by computational experiments results that How to prove that is finite (that is the given series converges) for any value of ? The trend of the function is shown in the following graph: One could conjecture that with approximately. How to prove this estimate?,"f(\alpha)=\sum_{n\gt1}\frac{[\,\Omega(n)\,]^\alpha}{n^2} \Omega(n) n \alpha\ge0 f(0)=\frac{\pi^2}{6}-1 f\Big(\frac 1 2\Big)=0.74587577\dots f(1)=0.90748082\dots f(2)=1.62036452\dots f(\alpha) \alpha \log f(\alpha) f(\alpha)\sim e^{C\alpha} C=\frac 5 2","['sequences-and-series', 'number-theory', 'dirichlet-series']"
27,Convergence and divergence of a Complex Series,Convergence and divergence of a Complex Series,,"I've been given the following series: $$\frac{z}{1-z^2} + \frac{z^2}{1-z^4} + \frac{z^4}{1-z^8} + ...$$ and been told to investigate the convergence. Clearly this diverges if $z=1$ (possibly if $\vert{z}\vert = 1$ ?), but other than that I am at a loss as to how to proceed. Wolfram Alpha tells me that this converges to $\frac{z}{1-z}$ if $\vert{z}\vert<1$ and to $\frac{1}{1-z}$ if $\vert{z}\vert>1$ but how would one go about showing this?","I've been given the following series: and been told to investigate the convergence. Clearly this diverges if (possibly if ?), but other than that I am at a loss as to how to proceed. Wolfram Alpha tells me that this converges to if and to if but how would one go about showing this?",\frac{z}{1-z^2} + \frac{z^2}{1-z^4} + \frac{z^4}{1-z^8} + ... z=1 \vert{z}\vert = 1 \frac{z}{1-z} \vert{z}\vert<1 \frac{1}{1-z} \vert{z}\vert>1,"['sequences-and-series', 'convergence-divergence']"
28,Initial conditions for which these two recursive sequences converge,Initial conditions for which these two recursive sequences converge,,"The following problem is a generalization of an exercise that the professor give me and that I have already solved. In the initial statement $\alpha=0$ and given $0<a_0<1$ , the limit of the first sequence  is $\dfrac{a_0}{1-a_0}$ . I was wondering what happen if I change a bit the exercise, with $\alpha>1$ it seems to me that the sequence diverges, but what happens if $0<\alpha<1$ ? Given $N\in\mathbb{N}$ and $0<\alpha<1$ , we define for each $0\leq n \leq N-1$ $$a_{n+1,N}=a_{n,N}+\dfrac{1}{N}a_{n,N}^2\left(\dfrac{2}{b_{n,N}}\right)^\alpha\\ b_{n+1,N}=b_{n,N}-\dfrac{1}{N}a_{n,N}^2\left(\dfrac{2}{b_{n,N}}\right)^\alpha.$$ There exist any values of $a_0=a_{0,N}$ and $b_0=b_{0,N}$ such that the sequences $\{a_{N,N}\}$ and $\{b_{N,N}\}$ converge to positive numbers? Attempt: I have realized that $a_N+b_N=a_0+b_0$ for every $N$ , so it suffices to see that $\{b_{N,N}\}$ is bounded below or $\{a_{N,N}\}$ is bounded above. I don't know how to make rigorous calculations, but I have found out by using the software Mathematica that apparently  with $\alpha=1/2$ there is convergence for some pairs $(a_0,b_0)$ like $a_0=0.004; b_0=0.003$ $a_0=0.008 ; b_0=0.004$ $a_0=0.003 ; b_0=0.001$ $a_0=0.32 ; b_0=0.24$ $a_0=0.021 ; b_0=0.017$ Thanks.","The following problem is a generalization of an exercise that the professor give me and that I have already solved. In the initial statement and given , the limit of the first sequence  is . I was wondering what happen if I change a bit the exercise, with it seems to me that the sequence diverges, but what happens if ? Given and , we define for each There exist any values of and such that the sequences and converge to positive numbers? Attempt: I have realized that for every , so it suffices to see that is bounded below or is bounded above. I don't know how to make rigorous calculations, but I have found out by using the software Mathematica that apparently  with there is convergence for some pairs like Thanks.","\alpha=0 0<a_0<1 \dfrac{a_0}{1-a_0} \alpha>1 0<\alpha<1 N\in\mathbb{N} 0<\alpha<1 0\leq n \leq N-1 a_{n+1,N}=a_{n,N}+\dfrac{1}{N}a_{n,N}^2\left(\dfrac{2}{b_{n,N}}\right)^\alpha\\
b_{n+1,N}=b_{n,N}-\dfrac{1}{N}a_{n,N}^2\left(\dfrac{2}{b_{n,N}}\right)^\alpha. a_0=a_{0,N} b_0=b_{0,N} \{a_{N,N}\} \{b_{N,N}\} a_N+b_N=a_0+b_0 N \{b_{N,N}\} \{a_{N,N}\} \alpha=1/2 (a_0,b_0) a_0=0.004; b_0=0.003 a_0=0.008 ; b_0=0.004 a_0=0.003 ; b_0=0.001 a_0=0.32 ; b_0=0.24 a_0=0.021 ; b_0=0.017","['real-analysis', 'calculus', 'sequences-and-series', 'convergence-divergence', 'numerical-methods']"
29,Conditions of uniform convergence of arithmetic mean,Conditions of uniform convergence of arithmetic mean,,"Under what conditions on sequence $(a_i)_{i=1}^{\infty}$ , where $a_i \in \mathbb R^n$ can we have $$ m^{-1}\sum_{i=1}^{m} \|x_1-a_i\|\|x_2-a_i\| $$ converges as $m \rightarrow \infty$ uniformly for all $x_1$ and $x_2$ in a compact set $\mathcal X$ . For example, if $m^{-1}\sum_{i=1}^{m} \|a_i\|^2$ and $m^{-1}\sum_{i=1}^{m} a_i$ converges as $m \rightarrow \infty$ , then $m^{-1}\sum_{i=1}^{m} \|x-a_i\|^2$ converges uniformly for all $x$ in $\mathcal X$ . But I cannot derive the similar conditions for the uniform convergence of $m^{-1}\sum_{i=1}^{m} \|x_1-a_i\|\|x_2-a_i\|$ . Can anyone give me some ideas. Thanks~","Under what conditions on sequence , where can we have converges as uniformly for all and in a compact set . For example, if and converges as , then converges uniformly for all in . But I cannot derive the similar conditions for the uniform convergence of . Can anyone give me some ideas. Thanks~","(a_i)_{i=1}^{\infty} a_i \in \mathbb R^n 
m^{-1}\sum_{i=1}^{m} \|x_1-a_i\|\|x_2-a_i\|
 m \rightarrow \infty x_1 x_2 \mathcal X m^{-1}\sum_{i=1}^{m} \|a_i\|^2 m^{-1}\sum_{i=1}^{m} a_i m \rightarrow \infty m^{-1}\sum_{i=1}^{m} \|x-a_i\|^2 x \mathcal X m^{-1}\sum_{i=1}^{m} \|x_1-a_i\|\|x_2-a_i\|","['real-analysis', 'sequences-and-series', 'cauchy-sequences']"
30,"Intersection of the Domain of the Logarithm of the Product of a Sequence of Sine Functions and $[0,1]$",Intersection of the Domain of the Logarithm of the Product of a Sequence of Sine Functions and,"[0,1]","Good afternoon.  I have a couple of questions regarding a problem on the 2010 AMC 12A/AHSME.  it's more on the reasoning of something I was using to try and solve the problem (turned out not to be fruitful).  Here's the question. Let $f(x)=\log_{10}\left(\sin{\pi x}\cdot\sin{2\pi x}\cdot ...\cdot \sin{8\pi x}\right)$ .  The intersection of the domain of $f$ with the interval $[0,1]$ is a union of disjoint open intervals.  What is $n$ ? I already answered the question ( $n=12$ ).  But the strategy for accomplishing this task on my end was very tedious and got me thinking that there was a better.  I literally graphed and highlighted the domains of the individual sine functions above.  Then, since the argument of the logarithm is a product, the intervals in the domain generated would mean that the product would be positive in a particular open interval $(a,b)\in[0,1]$ when there exists an even number of indexed sine functions where, for a particular $c\in[a,b]$ , $\sin{ck\pi}<0$ .  This made it easy to generate the sets, albeit as i mentioned, quite tedious.  But also, what happens if $k$ is large?  It becomes a massive problem. One of the solutions I was thinking of was to look at the derivative of $f$ and see how many maxes or mins occur.  Since there are swathes of sine functions and each of those functions is composite, and that huge product is in itself the inner function of the broader logarithm, this seemed impossible without a CAS like Mathematica (which I haven't tried yet but will).  So then I thought to transform the function based upon rules of logarithms.  So $$f(x)=\log_{10}\left(\sin{\pi x}\cdot\sin{2\pi x}\cdot ...\cdot \sin{8\pi x}\right)=\sum_{k=1}^{8}\log_{10}\sin{k\pi x}$$ But this approach doesn't seem to work (and it seems that the rules of logarithms doesn't take into account for the product since the domains of both functions appear to be different).  So outside of a CAS, this again seems like a black hole of problems. My questions are this: 1.  Are there any mathematical papers that can handle the analysis of this type of problem or any generalized function similar to this one?  2.  Are there patterns that emerge for increasing $k$ ?  The number of intervals for the problem in question has the following sequence for $k=1...20$ $$1,1,2,4,6,6,9,12,16,16,21,26,30,32,36,44,54,51,60,68,...$$ I checked the OEIS and there was nothing.  I basically plotted the function in desmos and counted intervals where the function existed and went with that.  I am not 100% convinced that this is the sequence, but if it's not, I don't know where i made my error. Any insight, papers, references, etc are welcome and super helpful.  Thank you in advance. Here is a simple PARI/GP program to calculate the number of intervals in $[0, 1]$ where $\prod_{j=2}^n \sin(j \pi x)$ is positive. It collects the zeros of all factors in a list, sorts them in increasing order and then counts the number of non-degenerate intervals on which the product is positive. P(n) = {     my (zeros = List());     for (j=2, n, for (k=1,j-1, listput(zeros, k/j)));     listput(zeros, 1);     my (xcoords = vecsort(Vec(zeros)), x = 0, sign = -1, count = 0);     for(i=1, #xcoords,         sign = -sign;         if (xcoords[i] > x && sign == 1, count += 1);         x = xcoords[i];     );     count };  vector(30, n, P(n)) (You can run it in the PARI/GP online calculator ). Output: %2 = [1, 1, 2, 4, 6, 6, 9, 12, 16, 16, 21, 26, 30, 32, 36, 44, 54, 51, 60, 68, 74, 75, 86, 98, 104, 106, 115, 128, 144, 139]","Good afternoon.  I have a couple of questions regarding a problem on the 2010 AMC 12A/AHSME.  it's more on the reasoning of something I was using to try and solve the problem (turned out not to be fruitful).  Here's the question. Let .  The intersection of the domain of with the interval is a union of disjoint open intervals.  What is ? I already answered the question ( ).  But the strategy for accomplishing this task on my end was very tedious and got me thinking that there was a better.  I literally graphed and highlighted the domains of the individual sine functions above.  Then, since the argument of the logarithm is a product, the intervals in the domain generated would mean that the product would be positive in a particular open interval when there exists an even number of indexed sine functions where, for a particular , .  This made it easy to generate the sets, albeit as i mentioned, quite tedious.  But also, what happens if is large?  It becomes a massive problem. One of the solutions I was thinking of was to look at the derivative of and see how many maxes or mins occur.  Since there are swathes of sine functions and each of those functions is composite, and that huge product is in itself the inner function of the broader logarithm, this seemed impossible without a CAS like Mathematica (which I haven't tried yet but will).  So then I thought to transform the function based upon rules of logarithms.  So But this approach doesn't seem to work (and it seems that the rules of logarithms doesn't take into account for the product since the domains of both functions appear to be different).  So outside of a CAS, this again seems like a black hole of problems. My questions are this: 1.  Are there any mathematical papers that can handle the analysis of this type of problem or any generalized function similar to this one?  2.  Are there patterns that emerge for increasing ?  The number of intervals for the problem in question has the following sequence for I checked the OEIS and there was nothing.  I basically plotted the function in desmos and counted intervals where the function existed and went with that.  I am not 100% convinced that this is the sequence, but if it's not, I don't know where i made my error. Any insight, papers, references, etc are welcome and super helpful.  Thank you in advance. Here is a simple PARI/GP program to calculate the number of intervals in where is positive. It collects the zeros of all factors in a list, sorts them in increasing order and then counts the number of non-degenerate intervals on which the product is positive. P(n) = {     my (zeros = List());     for (j=2, n, for (k=1,j-1, listput(zeros, k/j)));     listput(zeros, 1);     my (xcoords = vecsort(Vec(zeros)), x = 0, sign = -1, count = 0);     for(i=1, #xcoords,         sign = -sign;         if (xcoords[i] > x && sign == 1, count += 1);         x = xcoords[i];     );     count };  vector(30, n, P(n)) (You can run it in the PARI/GP online calculator ). Output: %2 = [1, 1, 2, 4, 6, 6, 9, 12, 16, 16, 21, 26, 30, 32, 36, 44, 54, 51, 60, 68, 74, 75, 86, 98, 104, 106, 115, 128, 144, 139]","f(x)=\log_{10}\left(\sin{\pi x}\cdot\sin{2\pi x}\cdot ...\cdot \sin{8\pi x}\right) f [0,1] n n=12 (a,b)\in[0,1] c\in[a,b] \sin{ck\pi}<0 k f f(x)=\log_{10}\left(\sin{\pi x}\cdot\sin{2\pi x}\cdot ...\cdot \sin{8\pi x}\right)=\sum_{k=1}^{8}\log_{10}\sin{k\pi x} k k=1...20 1,1,2,4,6,6,9,12,16,16,21,26,30,32,36,44,54,51,60,68,... [0, 1] \prod_{j=2}^n \sin(j \pi x)","['calculus', 'sequences-and-series', 'reference-request', 'logarithms', 'interval-arithmetic']"
31,Properties of integers squareness function,Properties of integers squareness function,,"Consider the map $$ \begin{array}{rccc} s: &\mathbb{N}_{\geq1} & \longrightarrow & \left(0,1\right]\cap\mathbb{Q}\\    & n & \longmapsto & \frac{\max\{d|n:\ d\ \leq\ \sqrt{n}\}}{\min\{d|n:\ d\ \geq\ \sqrt{n}\}} \end{array} $$ which gives the ""squareness"" of $n$ . The two following properties should be clear: $n$ is a square number $\Leftrightarrow$ $s(n)=1$ $n$ is a prime number $\Leftrightarrow$ $s(n)=\frac{1}{n}$ One nice pattern to display the integer numbers so that the end of each row is a square number is the following: $$ \begin{array}{cccccc} 1 \\ 2 & 3 & 4 \\ 5 & 6 & 7 & 8 & 9 \\ 10 & 11 & 12 & 13 & 14 & 15 & 16 \\ \cdots \end{array} $$ If we write the values of $s$ applied to this pattern we get: $$ \begin{array}{cccccc} 1 \\ \color{red}{1/2} & \color{blue}{1/3} & 1 \\ 1/5 & \color{red}{2/3} & 1/7 & \color{blue}{1/2} & 1 \\ 2/5 & 1/11 & \color{red}{3/4} & 1/13 & 2/7 & \color{blue}{3/5} & 1 \\ \cdots \end{array} $$ The diagonal highlighted in red (formed by taking the $(k-1)$ -th value in each row) is given by the relation $s(n)=\frac{k-1}{k}$ , i.e. $n=k(k-1)$ . These are the oblong numbers . We can see that after the 1 corresponding to perfect squares, on each row the oblong number attains the maximum value of $s$ (in the end ""oblong"" can be understood as ""quasi-square""). The diagonal highlighted in blue (formed by taking the number before the last in each row) is given by the relation $s(n)=\frac{k-1}{k+1}$ , i.e. $n=(k-1)(k+1)=k^2-1$ , as we already knew. These are the 3rd-most largest values for $s$ in each row. (very open-ended) QUESTION: What other nice properties, derived from the pattern or not, does the squareness function $s$ have?","Consider the map which gives the ""squareness"" of . The two following properties should be clear: is a square number is a prime number One nice pattern to display the integer numbers so that the end of each row is a square number is the following: If we write the values of applied to this pattern we get: The diagonal highlighted in red (formed by taking the -th value in each row) is given by the relation , i.e. . These are the oblong numbers . We can see that after the 1 corresponding to perfect squares, on each row the oblong number attains the maximum value of (in the end ""oblong"" can be understood as ""quasi-square""). The diagonal highlighted in blue (formed by taking the number before the last in each row) is given by the relation , i.e. , as we already knew. These are the 3rd-most largest values for in each row. (very open-ended) QUESTION: What other nice properties, derived from the pattern or not, does the squareness function have?","
\begin{array}{rccc}
s: &\mathbb{N}_{\geq1} & \longrightarrow & \left(0,1\right]\cap\mathbb{Q}\\
   & n & \longmapsto & \frac{\max\{d|n:\ d\ \leq\ \sqrt{n}\}}{\min\{d|n:\ d\ \geq\ \sqrt{n}\}}
\end{array}
 n n \Leftrightarrow s(n)=1 n \Leftrightarrow s(n)=\frac{1}{n} 
\begin{array}{cccccc}
1 \\
2 & 3 & 4 \\
5 & 6 & 7 & 8 & 9 \\
10 & 11 & 12 & 13 & 14 & 15 & 16 \\
\cdots
\end{array}
 s 
\begin{array}{cccccc}
1 \\
\color{red}{1/2} & \color{blue}{1/3} & 1 \\
1/5 & \color{red}{2/3} & 1/7 & \color{blue}{1/2} & 1 \\
2/5 & 1/11 & \color{red}{3/4} & 1/13 & 2/7 & \color{blue}{3/5} & 1 \\
\cdots
\end{array}
 (k-1) s(n)=\frac{k-1}{k} n=k(k-1) s s(n)=\frac{k-1}{k+1} n=(k-1)(k+1)=k^2-1 s s","['sequences-and-series', 'integers']"
32,"Validity of $\ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))}$",Validity of,"\ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))}","Definitions For the definitions of $\operatorname{AGP}$ and $\operatorname{AGO}$ , see here or here . $\theta_2(z)$ and $\theta_3(z)$ are defined as follows: $$\theta_2(z)=\sum_{n=-\infty}^\infty z^{(n+1/2)^2},$$ $$\theta_3(z)=\sum_{n=-\infty}^\infty z^{n^2}$$ where $z\in\mathbb{C}$ and $|z|\lt 1$ . Problem Due to Brent (pages 38 and 48), we have the following ""formula"": $$\ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))}$$ where $z\in\mathbb{C}\setminus (-\infty ,0]$ and $|z|\gt 1$ . It is based on Sasaki and Kanada's formula which is essentially the same, but less general: $$\ln x=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/x),\theta_3^2(1/x))}$$ where $x\in\mathbb{R}$ and $x\gt 1$ . Sasaki and Kanada's formula is fine, but Brent's formula turns out to be very problematic. For example, it works for $z=-1-2i$ , but doesn't seem to work for $z=-0.4+i$ and $z=0.4+i$ . All these complex numbers are greater than $1$ in absolute value and they don't lie on $(-\infty ,0]$ . To be specific, on page 48 Brent writes The theory that we outlined for the $\operatorname{AGM}$ iteration and $\operatorname{AGM}$ algorithms for $\log (z)$ can be extended without problems to complex $z\setminus (-\infty ,0]$ provided we always choose the square root with positive real part. Note that he is describing the $\operatorname{AGP}$ . Apparently there are some problems, though. It is not clear what he means: can it be extended to some complex $z\setminus (-\infty ,0]$ or all complex $z\setminus (-\infty ,0]$ ? Nevertheless, on page 28, he is referencing Borwein & Borwein: Given $(a_0,b_0)$ , the $\operatorname{AGM}$ iteration is defined by $$(a_{n+1},b_{n+1})=\left(\frac{a_n+b_n}{2},\sqrt{a_nb_n}\right).$$ For simplicity we'll only consider real, positive starting values $(a_0,b_0)$ for the moment, but the results can be extended to complex starting values (see Borwein & Borwein, Pi and the AGM , pp. 15–16) and we'll use that later. However, in their book on page 15 and 16, Borwein & Borwein write: All of the algorithms and functional relations extend naturally to the complex domain. In fact, all the algorithms and functional equations of this section hold at least for $k\in\{\operatorname{re}(z)\gt 0\}-[1,\infty )$ . The interested reader may readily establish the exact domains of validity for the various relations. The analysis of the $\operatorname{AGM}$ iteration for complex starting values is reasonably complicated (See Cox [85].) The problem is to decide which root is appropriate in the computation of $b_{n+1}=\sqrt{a_nb_n}$ . The right choice is made to ensure $|a_{n+1}-b_{n+1}|\le |a_{n+1}+b_{n+1}|$ [with $\operatorname{im}(b_{n+1}/a_{n+1})\gt 0$ in the case of equality]. As you can see, Borwein & Borwein are describing $\operatorname{AGO}$ , not $\operatorname{AGP}$ . I was thinking that Brent just erroneously assumed $\operatorname{AGP}$ instead of $\operatorname{AGO}$ , but even if we replace $\operatorname{AGP}$ with $\operatorname{AGO}$ in Brent's formula, the computation of $\ln z$ for both $z=-0.4+i$ and $z=0.4+i$ still gives wrong results. Quite curiously, $$\operatorname{AGP}\left(\theta_2^2 \left(\frac{1}{0.4+i}\right),\theta_3^2\left(\frac{1}{0.4+i}\right)\right)\ne \operatorname{AGO}\left(\theta_2^2 \left(\frac{1}{0.4+i}\right),\theta_3^2\left(\frac{1}{0.4+i}\right)\right),$$ but $$\operatorname{AGP}\left(\theta_2^2 \left(\frac{1}{-0.4+i}\right),\theta_3^2\left(\frac{1}{-0.4+i}\right)\right)=\operatorname{AGO}\left(\theta_2^2 \left(\frac{1}{-0.4+i}\right),\theta_3^2\left(\frac{1}{-0.4+i}\right)\right).$$ Question Brent's formula is apparently wrong, but what is the largest subset of $\mathbb{C}$ such that his formula holds true? Motivation Sasaki and Kanada's formula provides one of the fastest algorithms for the computation of the real natural logarithm and the real inverse hyperbolic functions. Newton's method can be used to compute the real exponential function and the real hyperbolic functions by means of a fast inversion. However, it is harder to compute the real trigonometric and the real inverse trigonometric functions this way. Namely, one has to extend Sasaki and Kanada's formula to the complex plane. But still, according to Brent, the convergence in the complex plane should be very fast and the algorithm should be even faster than the one based on Landen's transformations . An empirical result $$\ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))}$$ should be valid everywhere outside the square with vertices at $-2.1-1.6i$ , $1.1-1.6i$ , $1.1+1.6i$ , $-2.1+1.6i$ . Complex plots The horizontal axis represents $\operatorname{Re}z$ and the vertical axis represents $\operatorname{Im}z$ . Note $\ln$ denotes the principal branch of the complex natural logarithm. This question was also asked on MathOverflow .","Definitions For the definitions of and , see here or here . and are defined as follows: where and . Problem Due to Brent (pages 38 and 48), we have the following ""formula"": where and . It is based on Sasaki and Kanada's formula which is essentially the same, but less general: where and . Sasaki and Kanada's formula is fine, but Brent's formula turns out to be very problematic. For example, it works for , but doesn't seem to work for and . All these complex numbers are greater than in absolute value and they don't lie on . To be specific, on page 48 Brent writes The theory that we outlined for the iteration and algorithms for can be extended without problems to complex provided we always choose the square root with positive real part. Note that he is describing the . Apparently there are some problems, though. It is not clear what he means: can it be extended to some complex or all complex ? Nevertheless, on page 28, he is referencing Borwein & Borwein: Given , the iteration is defined by For simplicity we'll only consider real, positive starting values for the moment, but the results can be extended to complex starting values (see Borwein & Borwein, Pi and the AGM , pp. 15–16) and we'll use that later. However, in their book on page 15 and 16, Borwein & Borwein write: All of the algorithms and functional relations extend naturally to the complex domain. In fact, all the algorithms and functional equations of this section hold at least for . The interested reader may readily establish the exact domains of validity for the various relations. The analysis of the iteration for complex starting values is reasonably complicated (See Cox [85].) The problem is to decide which root is appropriate in the computation of . The right choice is made to ensure [with in the case of equality]. As you can see, Borwein & Borwein are describing , not . I was thinking that Brent just erroneously assumed instead of , but even if we replace with in Brent's formula, the computation of for both and still gives wrong results. Quite curiously, but Question Brent's formula is apparently wrong, but what is the largest subset of such that his formula holds true? Motivation Sasaki and Kanada's formula provides one of the fastest algorithms for the computation of the real natural logarithm and the real inverse hyperbolic functions. Newton's method can be used to compute the real exponential function and the real hyperbolic functions by means of a fast inversion. However, it is harder to compute the real trigonometric and the real inverse trigonometric functions this way. Namely, one has to extend Sasaki and Kanada's formula to the complex plane. But still, according to Brent, the convergence in the complex plane should be very fast and the algorithm should be even faster than the one based on Landen's transformations . An empirical result should be valid everywhere outside the square with vertices at , , , . Complex plots The horizontal axis represents and the vertical axis represents . Note denotes the principal branch of the complex natural logarithm. This question was also asked on MathOverflow .","\operatorname{AGP} \operatorname{AGO} \theta_2(z) \theta_3(z) \theta_2(z)=\sum_{n=-\infty}^\infty z^{(n+1/2)^2}, \theta_3(z)=\sum_{n=-\infty}^\infty z^{n^2} z\in\mathbb{C} |z|\lt 1 \ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))} z\in\mathbb{C}\setminus (-\infty ,0] |z|\gt 1 \ln x=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/x),\theta_3^2(1/x))} x\in\mathbb{R} x\gt 1 z=-1-2i z=-0.4+i z=0.4+i 1 (-\infty ,0] \operatorname{AGM} \operatorname{AGM} \log (z) z\setminus (-\infty ,0] \operatorname{AGP} z\setminus (-\infty ,0] z\setminus (-\infty ,0] (a_0,b_0) \operatorname{AGM} (a_{n+1},b_{n+1})=\left(\frac{a_n+b_n}{2},\sqrt{a_nb_n}\right). (a_0,b_0) k\in\{\operatorname{re}(z)\gt 0\}-[1,\infty ) \operatorname{AGM} b_{n+1}=\sqrt{a_nb_n} |a_{n+1}-b_{n+1}|\le |a_{n+1}+b_{n+1}| \operatorname{im}(b_{n+1}/a_{n+1})\gt 0 \operatorname{AGO} \operatorname{AGP} \operatorname{AGP} \operatorname{AGO} \operatorname{AGP} \operatorname{AGO} \ln z z=-0.4+i z=0.4+i \operatorname{AGP}\left(\theta_2^2 \left(\frac{1}{0.4+i}\right),\theta_3^2\left(\frac{1}{0.4+i}\right)\right)\ne \operatorname{AGO}\left(\theta_2^2 \left(\frac{1}{0.4+i}\right),\theta_3^2\left(\frac{1}{0.4+i}\right)\right), \operatorname{AGP}\left(\theta_2^2 \left(\frac{1}{-0.4+i}\right),\theta_3^2\left(\frac{1}{-0.4+i}\right)\right)=\operatorname{AGO}\left(\theta_2^2 \left(\frac{1}{-0.4+i}\right),\theta_3^2\left(\frac{1}{-0.4+i}\right)\right). \mathbb{C} \ln z=\frac{\pi}{\operatorname{AGP}(\theta_2^2(1/z),\theta_3^2(1/z))} -2.1-1.6i 1.1-1.6i 1.1+1.6i -2.1+1.6i \operatorname{Re}z \operatorname{Im}z \ln","['sequences-and-series', 'complex-analysis', 'algorithms', 'special-functions', 'theta-functions']"
33,"Proving that for any 3 infinite sequences $\{a_n\},\{b_n\},\{c_n\}$ in $\Bbb N,\exists p,q\in\Bbb N$ s. t. $a_p\ge a_q,b_p\ge b_q,c_p\ge c_q.$",Proving that for any 3 infinite sequences  in  s. t.,"\{a_n\},\{b_n\},\{c_n\} \Bbb N,\exists p,q\in\Bbb N a_p\ge a_q,b_p\ge b_q,c_p\ge c_q.","Prove that for any three infinite sequences $\{a_n\},\{b_n\},\{c_n\}$ in $\Bbb N$ , there are distinct $p,q\in\Bbb N$ s. t. $$a_p\ge a_q\space\land\space b_p\ge b_q\space\land\space c_p\ge c_q.$$ The task appeared on the $1961$ All Soviet Union Olympiad . My attempt: I tried to use the following lemma: Every sequence in $\{x_n\}$ in $\Bbb R$ has a monotonic subsequence. and its corollary: For finitely many sequences $a^{(1)},a^{(2)},\ldots,a^{(k)}$ there is a strictly increasing subsequence $p:\Bbb N\to\Bbb N$ s. t. all of the subsequences $a^{(1)}\circ p,a^{(2)}\circ p,\ldots,a^{(k)}\circ p$ are monotonic. and the proof of the corollary is: From the lemma, we know there a strictly increasing sequence $q^{(1)}:\Bbb N\to\Bbb N$ s. t. $a^{(1)}\circ q^{(1)}$ is a monotonic subsequence of $a^{(1)}$ . We now look at the subsequences $a^{(1)}\circ q^{(1)},a^{(2)}\circ q^{(1)},\ldots,a^{(k)}\circ q^{(1)}$ where the first one is monotonic, while others don't have to be. Again, from the lemma, there is a strictly increasing sequence $q^{(2)}:\Bbb N\to\Bbb N$ s. t. $a^{(2)}\circ q^{(1)}\circ q^{(2)}$ is a monotonic subsequence of $a^{(2)}\circ q^{(1)}$ . Since a subsequence of a monotonic sequence is also monotonic, among the subsequences $a^{(1)}\circ q^{(1)}\circ q^{(2)},a^{(2)}\circ q^{(1)}\circ q^{(2)},\ldots,a^{(k)}\circ q^{(1)}\circ q^{(2)}$ , the first two are monotonic, while others don't have to be. We repeat the process $(k-2)$ more times and obtain the subsequences $a^{(1)}\circ p,a^{(2)}\circ p,\ldots,a^{(k)}\circ p$ , where $p=q^{(1)}\circ q^{(2)}\circ\cdots\circ q^{(k)}$ . To avoid confusion, let $d:\Bbb N\to\Bbb N$ take the role of the strictly increasing sequence $p:\Bbb N\to\Bbb N$ from the corollary of the lemma. Now, every sequence in $\Bbb N$ has a minimum element, so, if some of the sequences $a\circ d,b\circ d,c\circ d$ happen to be decreasing , at some point they should become constant and hence monotonically increasing so, e.g., if $a'=a\circ d$ is decreasing $$\space m_a=\min\{m\in\Bbb N\mid\space a'_l\ge a'_m,l> m\},$$ and if we similarly define $m_b,m_c$ (if necessary), $p=\max\{m_a,m_b,m_c\}$ , and any $q\ge p$ should work as we end up with three monotonically increasing sequences $a\circ d,b\circ d,c\circ d$ starting from the index $p$ . May I ask if this argument is valid and if there is anything wrong? Thank you in advance!","Prove that for any three infinite sequences in , there are distinct s. t. The task appeared on the All Soviet Union Olympiad . My attempt: I tried to use the following lemma: Every sequence in in has a monotonic subsequence. and its corollary: For finitely many sequences there is a strictly increasing subsequence s. t. all of the subsequences are monotonic. and the proof of the corollary is: From the lemma, we know there a strictly increasing sequence s. t. is a monotonic subsequence of . We now look at the subsequences where the first one is monotonic, while others don't have to be. Again, from the lemma, there is a strictly increasing sequence s. t. is a monotonic subsequence of . Since a subsequence of a monotonic sequence is also monotonic, among the subsequences , the first two are monotonic, while others don't have to be. We repeat the process more times and obtain the subsequences , where . To avoid confusion, let take the role of the strictly increasing sequence from the corollary of the lemma. Now, every sequence in has a minimum element, so, if some of the sequences happen to be decreasing , at some point they should become constant and hence monotonically increasing so, e.g., if is decreasing and if we similarly define (if necessary), , and any should work as we end up with three monotonically increasing sequences starting from the index . May I ask if this argument is valid and if there is anything wrong? Thank you in advance!","\{a_n\},\{b_n\},\{c_n\} \Bbb N p,q\in\Bbb N a_p\ge a_q\space\land\space b_p\ge b_q\space\land\space c_p\ge c_q. 1961 \{x_n\} \Bbb R a^{(1)},a^{(2)},\ldots,a^{(k)} p:\Bbb N\to\Bbb N a^{(1)}\circ p,a^{(2)}\circ p,\ldots,a^{(k)}\circ p q^{(1)}:\Bbb N\to\Bbb N a^{(1)}\circ q^{(1)} a^{(1)} a^{(1)}\circ q^{(1)},a^{(2)}\circ q^{(1)},\ldots,a^{(k)}\circ q^{(1)} q^{(2)}:\Bbb N\to\Bbb N a^{(2)}\circ q^{(1)}\circ q^{(2)} a^{(2)}\circ q^{(1)} a^{(1)}\circ q^{(1)}\circ q^{(2)},a^{(2)}\circ q^{(1)}\circ q^{(2)},\ldots,a^{(k)}\circ q^{(1)}\circ q^{(2)} (k-2) a^{(1)}\circ p,a^{(2)}\circ p,\ldots,a^{(k)}\circ p p=q^{(1)}\circ q^{(2)}\circ\cdots\circ q^{(k)} d:\Bbb N\to\Bbb N p:\Bbb N\to\Bbb N \Bbb N a\circ d,b\circ d,c\circ d a'=a\circ d \space m_a=\min\{m\in\Bbb N\mid\space a'_l\ge a'_m,l> m\}, m_b,m_c p=\max\{m_a,m_b,m_c\} q\ge p a\circ d,b\circ d,c\circ d p","['real-analysis', 'sequences-and-series', 'solution-verification', 'contest-math']"
34,Sequence such that $x_{n+m} \leq x_n+x_m$,Sequence such that,x_{n+m} \leq x_n+x_m,"I have a couple of questions about the following type of sequences : Let $(x_n)$ be a sequence such that $x_n \geq  0$ $\forall n \in \mathbb N$ and that $$x_{n+m} \leq x_n+x_m \quad \forall n,m \in \mathbb N $$ In order to show that the sequence $(\frac{x_n}{n})$ converges, all proofs ""guess"" the limit that is $\inf(\frac{x_n}{n})$ and then use Euclidean division. What if I cannot guess it by myself (which actually happened) and do not think of using Euclidean division ? What happens if the sequence's property is $$x_{n+m} \geq x_n+x_m \quad \forall n,m \in \mathbb N $$ I feel like that here the sequence $(\frac{n}{x_n})$ will converge (tried with $x_n=e^n$ ), but I am not really sure...","I have a couple of questions about the following type of sequences : Let be a sequence such that and that In order to show that the sequence converges, all proofs ""guess"" the limit that is and then use Euclidean division. What if I cannot guess it by myself (which actually happened) and do not think of using Euclidean division ? What happens if the sequence's property is I feel like that here the sequence will converge (tried with ), but I am not really sure...","(x_n) x_n \geq  0 \forall n \in \mathbb N x_{n+m} \leq x_n+x_m \quad \forall n,m \in \mathbb N  (\frac{x_n}{n}) \inf(\frac{x_n}{n}) x_{n+m} \geq x_n+x_m \quad \forall n,m \in \mathbb N  (\frac{n}{x_n}) x_n=e^n","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'cauchy-sequences']"
35,Evaluating $\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}$,Evaluating,\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)},"I am trying to evaluate the following series: $$\sum_{n=1}^\infty\frac{1}{n^3\sin\left(\sqrt{2}\pi n \right)}\tag{a} $$ where, using the well-known result: $$\frac{1}{\sin\left(\pi x\right)}=\frac{2x}{\pi}\sum_{k=1}^\infty\frac{(-1)^{k-1}}{k^2-x^2}+\frac{1}{\pi x}\tag{1} $$ connecting $(1)$ in $(a)$ and $x\to \sqrt{2}n$ got the step: $$\sum_{n=1}^\infty\frac{1}{n^3\sin\left(\sqrt{2}\pi n \right)}=\frac{2\sqrt{2}}{\pi}\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}+\frac{1}{\sqrt{2}\pi}\zeta(4)\tag{b} $$ I tried to apply partial fractions in the double series above, then i found that: $$\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}=\frac54\zeta(4)+2\sum_{k=1}^\infty\sum_{n=1}^\infty\frac{(-1)^{k-1}}{k^2\left(k^2-2n^2\right)}\tag{2} $$ To conclude, I do not know to what extent this last step can help to solve the Double Series. Maybe I'm not seeing the obvious. It will be interesting to see some approach to resolve it. At Wolfram , she is: $$\therefore\ \sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}=-\frac{17}{16}\zeta(4).  $$","I am trying to evaluate the following series: where, using the well-known result: connecting in and got the step: I tried to apply partial fractions in the double series above, then i found that: To conclude, I do not know to what extent this last step can help to solve the Double Series. Maybe I'm not seeing the obvious. It will be interesting to see some approach to resolve it. At Wolfram , she is:",\sum_{n=1}^\infty\frac{1}{n^3\sin\left(\sqrt{2}\pi n \right)}\tag{a}  \frac{1}{\sin\left(\pi x\right)}=\frac{2x}{\pi}\sum_{k=1}^\infty\frac{(-1)^{k-1}}{k^2-x^2}+\frac{1}{\pi x}\tag{1}  (1) (a) x\to \sqrt{2}n \sum_{n=1}^\infty\frac{1}{n^3\sin\left(\sqrt{2}\pi n \right)}=\frac{2\sqrt{2}}{\pi}\sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}+\frac{1}{\sqrt{2}\pi}\zeta(4)\tag{b}  \sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}=\frac54\zeta(4)+2\sum_{k=1}^\infty\sum_{n=1}^\infty\frac{(-1)^{k-1}}{k^2\left(k^2-2n^2\right)}\tag{2}  \therefore\ \sum_{n=1}^\infty\sum_{k=1}^\infty\frac{(-1)^{k-1}}{n^2\left(k^2-2n^2 \right)}=-\frac{17}{16}\zeta(4).  ,"['sequences-and-series', 'summation', 'closed-form']"
36,Compute the series $\sum_{n=1}^{+\infty} \frac{1}{n^3\sin(n\pi\sqrt{2})}.$,Compute the series,\sum_{n=1}^{+\infty} \frac{1}{n^3\sin(n\pi\sqrt{2})}.,"I need to compute $$\sum_{n=1}^{+\infty} \frac{1}{n^3\sin(n\pi\sqrt{2})}.$$ This an exercice of ""Amar and Matheron, complex analysis"". I proved the convergence and now to compute the sum, I follow the hint of the book which is : Consider integrals of the form $$\int_{\gamma}\frac{dz}{z^3[\sin(\pi z)\sin(\sqrt{2}-1)\pi z]}$$ for a well-chosen $\gamma.$ I know this a residue theorem application but it seems a bit hard to have the good idea. I also tried with a summation factor. Any help will be greatly appreciated.","I need to compute $$\sum_{n=1}^{+\infty} \frac{1}{n^3\sin(n\pi\sqrt{2})}.$$ This an exercice of ""Amar and Matheron, complex analysis"". I proved the convergence and now to compute the sum, I follow the hint of the book which is : Consider integrals of the form $$\int_{\gamma}\frac{dz}{z^3[\sin(\pi z)\sin(\sqrt{2}-1)\pi z]}$$ for a well-chosen $\gamma.$ I know this a residue theorem application but it seems a bit hard to have the good idea. I also tried with a summation factor. Any help will be greatly appreciated.",,"['sequences-and-series', 'complex-analysis', 'contour-integration', 'residue-calculus']"
37,Proof of Toeplitz Transformation.,Proof of Toeplitz Transformation.,,"Toeplitz Transformation: Let $\{c_{n,k}:1\leq k\leq n, n\geq 1\}$ be an array of real numbers such that: i) $c_{n,k}\longrightarrow 0$ as $n\rightarrow{\infty}$ for  each $k\in \mathbb{N}$ . ii) $\sum\limits_{k=1}^{n} c_{n,k} \longrightarrow 1$ iii) There exists $C>0$ such that for all positive integers n: $$\sum_{k=1}^{n}|c_{n,k}| \leq C.$$ Then for any convergent sequence $\{a_n\}$ the transformed sequence $\{b_n\}$ given by $$b_n= \sum_{k=1}^{n}c_{n,k}a_k,\ \ n\geq 1$$ is also convergent and $(b_n) \rightarrow a \leftarrow (a_n)$ Proof: Let $a_n=a$ then $$\underset{n\rightarrow \infty}{\lim} b_n= a\underset{n\rightarrow \infty}{\lim} \sum\limits_{k=1}^{n} c_{n,k} =a.\ \ \ [by (ii)]$$ Now assuming [ $(a_n) \rightarrow 0 \implies (b_n) \rightarrow 0$ ] we can show that [ $(a_n) \rightarrow a \implies (b_n) \rightarrow a$ ] where $a\neq 0$ . Let $d_n:=(a_n-a) \implies (d_n) \rightarrow 0$ . Then from the assumption: $$ e_n:= \sum_{k=1}^{n}c_{n,k}d_k \longrightarrow 0 \\    \implies \sum_{k=1}^{n}c_{n,k}(a_k-a) \longrightarrow 0 \\    \implies \sum_{k=1}^{n}c_{n,k}(a_k) - \sum_{k=1}^{n}c_{n,k}a \longrightarrow 0 \\    \implies b_n - \sum_{k=1}^{n}c_{n,k}a \longrightarrow 0 \\    \implies b_n - a \longrightarrow 0\ \ \text{as n} \rightarrow \infty                               \ \ \                \textbf{USING (ii)}\\    \implies \underset{n\rightarrow \infty}{\lim} b_n=a.$$ All that remains to show is: If $\underset{n\rightarrow \infty}{\lim} a_n=0$ then $\underset{n\rightarrow \infty}{\lim} b_n=0$ . $|b_n - 0|=|\sum\limits_{k=1}^{n}c_{n,k}a_k|\leq \sum\limits_{k=1}^{n}|c_{n,k}||a_k|\ \ \ \ \ \ \ (1)$ Now USING (iii) we have $\sum\limits_{k=1}^{n}|c_{n,k}| \leq C$ , and for any $\epsilon>0$ there exists $n_1 \in \mathbb{N}$ such that for all $n \geq n_1$ , $|a_n| \leq \frac{\epsilon}{2C} \ \ \ \ \ (2)$ From (2) & (1) [ USING (iii) ] we obtain: For all $n\geq n_1$ we have $|b_n| \leq \sum\limits_{k=1}^{n_1-1}|c_{n,k}||a_k|+ \sum\limits_{k=n_1}^{n}|c_{n,k}||a_k| \leq \sum\limits_{k=1}^{n_1}|c_{n,k}||a_k|+C.\frac{\epsilon}{2C}(=\frac{\epsilon}{2}) \ \ \ \ \ (3)$ To get control over this $\sum\limits_{k=1}^{n_1-1}|c_{n,k}||a_k|$ one can USE (i) . As for each $k$ , $(c_{n,k}) \longrightarrow 0$ as $n \rightarrow \infty$ ( $1\leq k < n_1).\ \ \ \ \ \  (4)$ Also since $(a_n)$ is convergent, hence $(a_n)$ is bounded by D(say),  i.e $|a_k|<D \ \ \ \text{for all} \ \ k \in \mathbb{N}$ $\ \ \ \ \  (5)$ Let $\epsilon > 0$ then there exists $n_{2,k} \in \mathbb{N}, 1\leq k < n_1$ such that $$|c_{n,k}|< \frac{\epsilon}{2(n_1-1)D} \text{for all}\ n \geq n_2:=max\{n_{2,1},n_{2,2},...,n_{2,n_1-1}\}\\   \implies \sum\limits_{k=1}^{n_1-1} |c_{n,k}| < \frac{\epsilon}{2D}\ \ \ \ \ \ \  \text{for all}\ \ n\geq n_2 \ \ \ \ \  (6)$$ Using (5) & (6) we have: $$ \sum\limits_{k=1}^{n_1-1} |c_{n,k}||a_k| < \frac{\epsilon}{2D}.D=\frac{\epsilon}{2}\ \ \text{for all}\ \  n \geq n_2\ \ \ \ \ (7)$$ from (3) & (7) we have: for any $\epsilon > 0$ there exist $N:=\text{max}\{n_1,n_2\} \in \mathbb{N}$ such that for all $n \geq N$ we have $$|b_n - 0| \leq \sum\limits_{k=1}^{n_1}|c_{n,k}||a_k|+ \sum\limits_{k=n_1}^{n}|c_{n,k}||a_k| \leq \frac{\epsilon}{2D}.D + C.\frac{\epsilon}{2C}=\epsilon \\ \implies \underset{n\rightarrow \infty}{\lim} b_n=a.$$ Please tell me if my argument is correct. Observation: If $a=0$ then condition (ii) $\sum\limits_{k=1}^{n} c_{n,k} \longrightarrow 1$ can be removed. Am I correct?","Toeplitz Transformation: Let be an array of real numbers such that: i) as for  each . ii) iii) There exists such that for all positive integers n: Then for any convergent sequence the transformed sequence given by is also convergent and Proof: Let then Now assuming [ ] we can show that [ ] where . Let . Then from the assumption: All that remains to show is: If then . Now USING (iii) we have , and for any there exists such that for all , From (2) & (1) [ USING (iii) ] we obtain: For all we have To get control over this one can USE (i) . As for each , as ( Also since is convergent, hence is bounded by D(say),  i.e Let then there exists such that Using (5) & (6) we have: from (3) & (7) we have: for any there exist such that for all we have Please tell me if my argument is correct. Observation: If then condition (ii) can be removed. Am I correct?","\{c_{n,k}:1\leq k\leq n, n\geq 1\} c_{n,k}\longrightarrow 0 n\rightarrow{\infty} k\in \mathbb{N} \sum\limits_{k=1}^{n} c_{n,k} \longrightarrow 1 C>0 \sum_{k=1}^{n}|c_{n,k}| \leq C. \{a_n\} \{b_n\} b_n= \sum_{k=1}^{n}c_{n,k}a_k,\ \ n\geq 1 (b_n) \rightarrow a \leftarrow (a_n) a_n=a \underset{n\rightarrow \infty}{\lim} b_n= a\underset{n\rightarrow \infty}{\lim} \sum\limits_{k=1}^{n} c_{n,k} =a.\ \ \ [by (ii)] (a_n) \rightarrow 0 \implies (b_n) \rightarrow 0 (a_n) \rightarrow a \implies (b_n) \rightarrow a a\neq 0 d_n:=(a_n-a) \implies (d_n) \rightarrow 0  e_n:= \sum_{k=1}^{n}c_{n,k}d_k \longrightarrow 0 \\
   \implies \sum_{k=1}^{n}c_{n,k}(a_k-a) \longrightarrow 0 \\
   \implies \sum_{k=1}^{n}c_{n,k}(a_k) - \sum_{k=1}^{n}c_{n,k}a \longrightarrow 0 \\
   \implies b_n - \sum_{k=1}^{n}c_{n,k}a \longrightarrow 0 \\
   \implies b_n - a \longrightarrow 0\ \ \text{as n} \rightarrow \infty 
                             \ \ \                \textbf{USING (ii)}\\
   \implies \underset{n\rightarrow \infty}{\lim} b_n=a. \underset{n\rightarrow \infty}{\lim} a_n=0 \underset{n\rightarrow \infty}{\lim} b_n=0 |b_n - 0|=|\sum\limits_{k=1}^{n}c_{n,k}a_k|\leq \sum\limits_{k=1}^{n}|c_{n,k}||a_k|\ \ \ \ \ \ \ (1) \sum\limits_{k=1}^{n}|c_{n,k}| \leq C \epsilon>0 n_1 \in \mathbb{N} n \geq n_1 |a_n| \leq \frac{\epsilon}{2C} \ \ \ \ \ (2) n\geq n_1 |b_n| \leq \sum\limits_{k=1}^{n_1-1}|c_{n,k}||a_k|+ \sum\limits_{k=n_1}^{n}|c_{n,k}||a_k| \leq \sum\limits_{k=1}^{n_1}|c_{n,k}||a_k|+C.\frac{\epsilon}{2C}(=\frac{\epsilon}{2}) \ \ \ \ \ (3) \sum\limits_{k=1}^{n_1-1}|c_{n,k}||a_k| k (c_{n,k}) \longrightarrow 0 n \rightarrow \infty 1\leq k < n_1).\ \ \ \ \ \  (4) (a_n) (a_n) |a_k|<D \ \ \ \text{for all} \ \ k \in \mathbb{N} \ \ \ \ \  (5) \epsilon > 0 n_{2,k} \in \mathbb{N}, 1\leq k < n_1 |c_{n,k}|< \frac{\epsilon}{2(n_1-1)D} \text{for all}\ n \geq n_2:=max\{n_{2,1},n_{2,2},...,n_{2,n_1-1}\}\\
  \implies \sum\limits_{k=1}^{n_1-1} |c_{n,k}| < \frac{\epsilon}{2D}\ \ \ \ \ \ \  \text{for all}\ \ n\geq n_2 \ \ \ \ \  (6)  \sum\limits_{k=1}^{n_1-1} |c_{n,k}||a_k| < \frac{\epsilon}{2D}.D=\frac{\epsilon}{2}\ \ \text{for all}\ \  n \geq n_2\ \ \ \ \ (7) \epsilon > 0 N:=\text{max}\{n_1,n_2\} \in \mathbb{N} n \geq N |b_n - 0| \leq \sum\limits_{k=1}^{n_1}|c_{n,k}||a_k|+ \sum\limits_{k=n_1}^{n}|c_{n,k}||a_k| \leq \frac{\epsilon}{2D}.D + C.\frac{\epsilon}{2C}=\epsilon \\
\implies \underset{n\rightarrow \infty}{\lim} b_n=a. a=0 \sum\limits_{k=1}^{n} c_{n,k} \longrightarrow 1","['real-analysis', 'sequences-and-series', 'limits', 'epsilon-delta']"
38,Generating (almost?) all odd numbers for the 3n + 1 problem [closed],Generating (almost?) all odd numbers for the 3n + 1 problem [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed last year . Improve this question The 3n + 1 problem The $3n + 1$ problem can be described as a set of simple rules. For any positive integer apply the following two rules: If the number is even: divide by 2 If the number is odd: multiply by 3 and add 1 Here is an example: 7 -> 22 -> 11 -> 34 -> 17 -> 52 -> 26 -> 13 -> 40 -> 20 -> 10 -> 5 -> 16 -> 8 -> 4 -> 2 -> 1 -> 4 ... Collatz conjecture One thing to notice in the example above is that the pattern ends in a 1 -> 4 -> 2 -> 1 cycle. Collatz has conjectured this will always happen, for each positive starting integer. Proving/disproving Collatz To prove or disprove this conjecture someone will need to: Find a counter example: a number grows forever or another cycle. Prove that a cycle can't exist. Prove that all odd numbers can be generated by other numbers working backwards. People have been using super computers to crunch numbers to find a counter example to the Collatz conjecture. As of 2020 people have checked up to $2^{68}$ , and all examples end up in the same 1 -> 4 -> 2 -> 1 cycle. We could state that, for a second cycle to exist, there has to be some specific properties of the numbers inside the cycle. For example, every cycle has one lowest number in it; and for any repeating cycle it can't have $6n + 3$ numbers in it (more on that later). This lowest number in a cycle might have some very specific properties that only $1$ has, thus making a second cycle impossible. Generating numbers (working backwards) A final way to prove the Collatz conjecture is to show that all other numbers can be created by starting at $1$ . Lets take a closer look at all the numbers involved. Even numbers can easily be ignored, they will (in a cycle) always get divided down to an odd number. Because every even number is an odd number multiplied by a power of two. For example $80$ comes down to 80 -> 40 -> 20 -> 10 -> 5 . Because of this we can just focus on the odd numbers in the $3n + 1$ problem. Splitting the odd numbers The numbers that we need to focus on are: $$2n + 1$$ These are all the odd numbers. Let's split these numbers into three equal groups: $$a = 6n + 1$$ $$b = 6n + 3$$ $$c = 6n + 5$$ We can show that these groups all uniquely contain the odd numbers: $$a [1, 7,  13, 19, 27...]$$ $$b [3, 9,  15, 21, 29...]$$ $$c [5, 11, 17, 23, 31...]$$ Going a single ""Collatz"" step back from an odd number means multiplying by 2, this creates new even numbers: $$a_1 = 12n + 2$$ $$b_1 = 12n + 6$$ $$c_1 = 12n + 10$$ $a_1 - 1$ and $b_1 - 1$ are not divisible by three and have no odd predecessor at this depth. $c_1 - 1$ is divisible by three and it creates a pattern: $4n + 3$ This implies that from every number in the form $6n + 5$ , going one step back in the Collatz sequence, we can generate all $4n + 3$ formed numbers. When multiplying $a_1$ , $b_1$ and $c_1$ again by two (going a deeper step back) we get: $$a_2 = 24n + 4$$ $$b_2 = 24n + 12$$ $$c_2 = 24n + 20$$ $b_2 - 1$ and $c_2 - 1$ are not divisible by three thus have no odd predecessor at this depth. $a_2 - 1$ is divisible, and reveals pattern: $8n + 1$ Special case: 6n + 3 Because b is in the form $6n + 3$ , multiplying by two will never result in a number that minus one is divisible by three. This means that odd numbers of form $6n + 3$ have no odd numbers preceding them. This allows us to focus completely on $6n + 1$ and $6n + 5$ form numbers. Pattern equations For a and c we can come up with the following equations: $$a = \frac{2^{2k} (6n + 1) - 1}{3}$$ $$c = \frac{2^{2 k + 1} (6 n + 5) - 1}{3}$$ Depth $k$ determines how deep we travel backwards (multiplying by two). The values for $k$ from the equations are: \begin{array}{|c|c|c|} \hline     k & a & c \\ \hline     1 & 8n + 1 & 4n + 3 \\ \hline     2 & 32n + 5 & 16n + 13 \\ \hline     3 & 128n + 21 & 64n + 53 \\ \hline     4 & 512n + 85 & 256n + 213 \\ \hline     5 & ... & ... \\ \hline \end{array} All the odd numbers that could be in a repeating cycle now have a method to calculate all their preceding odd numbers at different depths of $k$ . At a depth of $k=1$ we get the following information as mentioned above: $6n + 1$ and $6n + 5$ numbers will generate patterns: $8n + 1$ and $4n + 3$ This means all numbers in the forms: $8n + 1$ , $8n + 3$ and $8n + 7$ can be generated. After $k=1$ we just miss the numbers in the form $8n + 5$ . Next we look at $k=2$ , the new additions are: $32n + 5$ and $16n + 13$ . Scaling everything to $32n$ we can see that we can now form all odd numbers except in the form $32n + 21$ . One level deeper again and the patterns added are: $128n + 21$ and $64n + 53$ . This means that we can now form all odd numbers except those in the form $128n + 85$ . If this process is repeated, we can see that all odd numbers can be generated starting from just $6n + 1$ and $6n + 5$ . Density The amount of odd numbers that can be calculated are: $$\frac{4^k-1}{4^k}$$ The largest number that, at depth $k$ , can't yet be created is equal to: $$ 2 \cdot 4^{k+1}n + \frac{4^{k+2}-1}{3}$$ This results in the following table for small values of $k$ : \begin{array}{|l|l|l|l|} \hline         k & Missing & Density & Percentage \\ \hline         1 & 8n + 5 & \frac{3}{4} & 0.75 \\ \hline         2 & 32n + 21 & \frac{15}{16} & 0.9375 \\ \hline         3 & 128n + 85 & \frac{63}{64} & 0.984375 \\ \hline         4 & 512n + 341 & \frac{255}{256} & 0.99609375 \\ \hline         5 & 2048n + 1365 & \frac{1023}{1024} & 0.9990234375 \\ \hline         6 & 2 \cdot 4^6n + 5461 & \frac{4095}{4096} & 0.9997.. \\ \hline         7 & 2 \cdot 4^7n + 21845 & \frac{16383}{16384} & 0.99993.. \\ \hline         8 & 2 \cdot 4^8n + 87381 & \frac{65535}{65536} & 0.99998.. \\ \hline         9 & 2 \cdot 4^9n + 349.525 & \frac{262143}{262144} & 0.999996.. \\ \hline         10 & 2 \cdot 4^{10} n + 1398101 & \frac{1048575}{1048576} & 0.99999904... \\ \hline         .. &  &  &  \\ \hline         100 & 2 \cdot 4^{100} n + 214..... &  & 0.9999999999... \\ \hline          & 2 \cdot 4^{k+1}n + \frac{4^{k+2}-1}{3} & \frac{4^k-1}{4^k} &  \\ \hline \end{array} After just $k=10$ steps we can generate $\frac{1048575}{1048576}$ of all existing odd numbers from the starting values $6n + 1$ and $6n + 5$ . The lowest number we can't create is $2 \cdot 4^{10}n + 1398101$ . And after $k=100$ steps we're up to: $$0.9999999999999999999999999999999999999999999999999999999999993777$$ Update : Does this ""prove"" the Collatz conjecture? Sadly: No. There is one problem: We did show that each odd number can be made from $6n+1$ and $6n+5$ . We haven't shown that this all happens from the number 1. Update 2 : Suppose a second cycle exists. That cycle will have to have a lowest number, that is larger than 1 (obviously). Can we prove this cycle doesn't exist? We can try. First of all, we can still rule out any numbers in the form $6n+3$ , these numbers have no preceding odd numbers and can therefor never be created in a cycle. Now we have two options left, $6n+1$ ( a ) or $6n+5$ ( c ). Let's look at the numbers in c . They are in the form $6n+5$ , and have smaller predecessors in the form $4n+3$ . These are the only numbers that can make a cycle grow exist and odd numbers grow larger when running Collatz forward: \begin{array}{|l|l|l|} \hline         n & 4n + 3 \\ \hline         0 & 6 \cdot 0 + 3 \\ \hline         1 & 6 \cdot 1 + 1 \\ \hline         2 & 6 \cdot 1 + 5 \\ \hline         3 & 6 \cdot 2 + 3 \\ \hline         4 & 6 \cdot 3 + 1 \\ \hline         5 & 6 \cdot 3 + 5 \\ \hline         6 & 6 \cdot 4 + 3 \\ \hline         7 & 6 \cdot 5 + 1 \\ \hline         8 & 6 \cdot 5 + 5 \\ \hline         9 & 6 \cdot 6 + 3 \\ \hline         10 & 6 \cdot 7 + 1 \\ \hline         11 & 6 \cdot 7 + 5 \\ \hline \end{array} From this we can conclude that we either: The smaller odd number before $4n+3$ is a smaller $6n+1$ The smaller odd number before $4n+3$ has the form $6n+3$ , a dead end The smaller odd number before $4n+3$ is a smaller $6n+5$ , continue until (1) or (2) are reached (will happen by deduction). This means that the only possible smallest odd number in a cycle can be in the form $6n+1$ , a number from group a . Suppose we again split a into two groups a1 and a2 : $$a1 = 12n + 1$$ $$a2 = 12n + 7$$ These groups contain all $6n+1$ numbers, split equally. If we now follow the sequence forward from our hypothetical lowest number in the cycle we get: $$((12n + 1) * 3)+1 = 36n + 4$$ $$((12n + 7) * 3)+1 = 36n + 22$$ Next we divide the even numbers by two (according to the $3n+1$ rule) and get: $$(36n + 4)/2/2 = 9n + 1$$ $$(36n + 22)/2 = 18n + 11$$ This shows that a number in form a1 ( $12n + 1$ ) is not the lowest number of the hypothetical Collatz cycle because $9n + 1$ follows and is smaller. So the lowest number in an hypothetical cycle must be $12n + 7$ . What next? One could dive deeper into these $4n+3$ numbers; those are very special and allow a number to grow before going down to 1. One could try to come up with a set of finite sub-trees that create the fractal like pattern the $3n+1$ problem has? I'm giving up (for now) :)","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed last year . Improve this question The 3n + 1 problem The problem can be described as a set of simple rules. For any positive integer apply the following two rules: If the number is even: divide by 2 If the number is odd: multiply by 3 and add 1 Here is an example: 7 -> 22 -> 11 -> 34 -> 17 -> 52 -> 26 -> 13 -> 40 -> 20 -> 10 -> 5 -> 16 -> 8 -> 4 -> 2 -> 1 -> 4 ... Collatz conjecture One thing to notice in the example above is that the pattern ends in a 1 -> 4 -> 2 -> 1 cycle. Collatz has conjectured this will always happen, for each positive starting integer. Proving/disproving Collatz To prove or disprove this conjecture someone will need to: Find a counter example: a number grows forever or another cycle. Prove that a cycle can't exist. Prove that all odd numbers can be generated by other numbers working backwards. People have been using super computers to crunch numbers to find a counter example to the Collatz conjecture. As of 2020 people have checked up to , and all examples end up in the same 1 -> 4 -> 2 -> 1 cycle. We could state that, for a second cycle to exist, there has to be some specific properties of the numbers inside the cycle. For example, every cycle has one lowest number in it; and for any repeating cycle it can't have numbers in it (more on that later). This lowest number in a cycle might have some very specific properties that only has, thus making a second cycle impossible. Generating numbers (working backwards) A final way to prove the Collatz conjecture is to show that all other numbers can be created by starting at . Lets take a closer look at all the numbers involved. Even numbers can easily be ignored, they will (in a cycle) always get divided down to an odd number. Because every even number is an odd number multiplied by a power of two. For example comes down to 80 -> 40 -> 20 -> 10 -> 5 . Because of this we can just focus on the odd numbers in the problem. Splitting the odd numbers The numbers that we need to focus on are: These are all the odd numbers. Let's split these numbers into three equal groups: We can show that these groups all uniquely contain the odd numbers: Going a single ""Collatz"" step back from an odd number means multiplying by 2, this creates new even numbers: and are not divisible by three and have no odd predecessor at this depth. is divisible by three and it creates a pattern: This implies that from every number in the form , going one step back in the Collatz sequence, we can generate all formed numbers. When multiplying , and again by two (going a deeper step back) we get: and are not divisible by three thus have no odd predecessor at this depth. is divisible, and reveals pattern: Special case: 6n + 3 Because b is in the form , multiplying by two will never result in a number that minus one is divisible by three. This means that odd numbers of form have no odd numbers preceding them. This allows us to focus completely on and form numbers. Pattern equations For a and c we can come up with the following equations: Depth determines how deep we travel backwards (multiplying by two). The values for from the equations are: All the odd numbers that could be in a repeating cycle now have a method to calculate all their preceding odd numbers at different depths of . At a depth of we get the following information as mentioned above: and numbers will generate patterns: and This means all numbers in the forms: , and can be generated. After we just miss the numbers in the form . Next we look at , the new additions are: and . Scaling everything to we can see that we can now form all odd numbers except in the form . One level deeper again and the patterns added are: and . This means that we can now form all odd numbers except those in the form . If this process is repeated, we can see that all odd numbers can be generated starting from just and . Density The amount of odd numbers that can be calculated are: The largest number that, at depth , can't yet be created is equal to: This results in the following table for small values of : After just steps we can generate of all existing odd numbers from the starting values and . The lowest number we can't create is . And after steps we're up to: Update : Does this ""prove"" the Collatz conjecture? Sadly: No. There is one problem: We did show that each odd number can be made from and . We haven't shown that this all happens from the number 1. Update 2 : Suppose a second cycle exists. That cycle will have to have a lowest number, that is larger than 1 (obviously). Can we prove this cycle doesn't exist? We can try. First of all, we can still rule out any numbers in the form , these numbers have no preceding odd numbers and can therefor never be created in a cycle. Now we have two options left, ( a ) or ( c ). Let's look at the numbers in c . They are in the form , and have smaller predecessors in the form . These are the only numbers that can make a cycle grow exist and odd numbers grow larger when running Collatz forward: From this we can conclude that we either: The smaller odd number before is a smaller The smaller odd number before has the form , a dead end The smaller odd number before is a smaller , continue until (1) or (2) are reached (will happen by deduction). This means that the only possible smallest odd number in a cycle can be in the form , a number from group a . Suppose we again split a into two groups a1 and a2 : These groups contain all numbers, split equally. If we now follow the sequence forward from our hypothetical lowest number in the cycle we get: Next we divide the even numbers by two (according to the rule) and get: This shows that a number in form a1 ( ) is not the lowest number of the hypothetical Collatz cycle because follows and is smaller. So the lowest number in an hypothetical cycle must be . What next? One could dive deeper into these numbers; those are very special and allow a number to grow before going down to 1. One could try to come up with a set of finite sub-trees that create the fractal like pattern the problem has? I'm giving up (for now) :)","3n + 1 2^{68} 6n + 3 1 1 80 3n + 1 2n + 1 a = 6n + 1 b = 6n + 3 c = 6n + 5 a [1, 7,  13, 19, 27...] b [3, 9,  15, 21, 29...] c [5, 11, 17, 23, 31...] a_1 = 12n + 2 b_1 = 12n + 6 c_1 = 12n + 10 a_1 - 1 b_1 - 1 c_1 - 1 4n + 3 6n + 5 4n + 3 a_1 b_1 c_1 a_2 = 24n + 4 b_2 = 24n + 12 c_2 = 24n + 20 b_2 - 1 c_2 - 1 a_2 - 1 8n + 1 6n + 3 6n + 3 6n + 1 6n + 5 a = \frac{2^{2k} (6n + 1) - 1}{3} c = \frac{2^{2 k + 1} (6 n + 5) - 1}{3} k k \begin{array}{|c|c|c|}
\hline
    k & a & c \\ \hline
    1 & 8n + 1 & 4n + 3 \\ \hline
    2 & 32n + 5 & 16n + 13 \\ \hline
    3 & 128n + 21 & 64n + 53 \\ \hline
    4 & 512n + 85 & 256n + 213 \\ \hline
    5 & ... & ... \\ \hline
\end{array} k k=1 6n + 1 6n + 5 8n + 1 4n + 3 8n + 1 8n + 3 8n + 7 k=1 8n + 5 k=2 32n + 5 16n + 13 32n 32n + 21 128n + 21 64n + 53 128n + 85 6n + 1 6n + 5 \frac{4^k-1}{4^k} k  2 \cdot 4^{k+1}n + \frac{4^{k+2}-1}{3} k \begin{array}{|l|l|l|l|}
\hline
        k & Missing & Density & Percentage \\ \hline
        1 & 8n + 5 & \frac{3}{4} & 0.75 \\ \hline
        2 & 32n + 21 & \frac{15}{16} & 0.9375 \\ \hline
        3 & 128n + 85 & \frac{63}{64} & 0.984375 \\ \hline
        4 & 512n + 341 & \frac{255}{256} & 0.99609375 \\ \hline
        5 & 2048n + 1365 & \frac{1023}{1024} & 0.9990234375 \\ \hline
        6 & 2 \cdot 4^6n + 5461 & \frac{4095}{4096} & 0.9997.. \\ \hline
        7 & 2 \cdot 4^7n + 21845 & \frac{16383}{16384} & 0.99993.. \\ \hline
        8 & 2 \cdot 4^8n + 87381 & \frac{65535}{65536} & 0.99998.. \\ \hline
        9 & 2 \cdot 4^9n + 349.525 & \frac{262143}{262144} & 0.999996.. \\ \hline
        10 & 2 \cdot 4^{10} n + 1398101 & \frac{1048575}{1048576} & 0.99999904... \\ \hline
        .. &  &  &  \\ \hline
        100 & 2 \cdot 4^{100} n + 214..... &  & 0.9999999999... \\ \hline
         & 2 \cdot 4^{k+1}n + \frac{4^{k+2}-1}{3} & \frac{4^k-1}{4^k} &  \\ \hline
\end{array} k=10 \frac{1048575}{1048576} 6n + 1 6n + 5 2 \cdot 4^{10}n + 1398101 k=100 0.9999999999999999999999999999999999999999999999999999999999993777 6n+1 6n+5 6n+3 6n+1 6n+5 6n+5 4n+3 \begin{array}{|l|l|l|}
\hline
        n & 4n + 3 \\ \hline
        0 & 6 \cdot 0 + 3 \\ \hline
        1 & 6 \cdot 1 + 1 \\ \hline
        2 & 6 \cdot 1 + 5 \\ \hline
        3 & 6 \cdot 2 + 3 \\ \hline
        4 & 6 \cdot 3 + 1 \\ \hline
        5 & 6 \cdot 3 + 5 \\ \hline
        6 & 6 \cdot 4 + 3 \\ \hline
        7 & 6 \cdot 5 + 1 \\ \hline
        8 & 6 \cdot 5 + 5 \\ \hline
        9 & 6 \cdot 6 + 3 \\ \hline
        10 & 6 \cdot 7 + 1 \\ \hline
        11 & 6 \cdot 7 + 5 \\ \hline
\end{array} 4n+3 6n+1 4n+3 6n+3 4n+3 6n+5 6n+1 a1 = 12n + 1 a2 = 12n + 7 6n+1 ((12n + 1) * 3)+1 = 36n + 4 ((12n + 7) * 3)+1 = 36n + 22 3n+1 (36n + 4)/2/2 = 9n + 1 (36n + 22)/2 = 18n + 11 12n + 1 9n + 1 12n + 7 4n+3 3n+1","['sequences-and-series', 'solution-verification', 'recreational-mathematics', 'collatz-conjecture']"
39,Abel's summation formula and approximating an integral of Jacobi theta functions,Abel's summation formula and approximating an integral of Jacobi theta functions,,"As my previous post remains unanswered, I thought I would post a more complete form of the problem in case it would be more practical to work on/ solve. I am trying to compute the following integral \begin{align} I_{\pm\pm} (x,y) = \int_0^1 dz \int_0^\infty ds \, \frac{e^{-\alpha/s}}{s} \,\partial_s \left[ \theta_3 \left( \frac{\pi(x \pm z)}{2},e^{-s} \right) \,\theta_3 \left( \frac{\pi(y \pm z)}{2},e^{-s} \right) \right] \end{align} where $x,y \in (0,1)$ and $\alpha > 0$ . To give a bit of context, I have come across this in a setting of heat propagation with Neumann boundary conditions and it does not seem to be something that can be calculated analytically. I have indeed looked at the numerical results for various values of $x$ and $y$ , but I still like to have an expression that approximates $I(x,y)$ (or various expression for different regimes). Any suggestions are therefore appreciated. My own (hopeless) attempt is based on approximating the $\theta_3$ functions first, for exmaple using Abel's summation formula following this post . Let's define \begin{align} f (z,s) = \sum_{n=0}^\infty e^{-n^2 \pi^2 s} \cos (n \pi z) \end{align} which in terms of Jacobi theta function could be represented as $ f (z,s) = ( \theta_3 ( \pi z/2 , e^{-\pi^2 s}) + 1 )/2. $ To use Abel's formula, we can define $ \phi (h) = e^{-h^2 \pi^2 s} \cos(h \pi z) $ and write \begin{align} \sum_{n=0}^\infty \phi(n) = \lim_{h \to \infty} \left( \lfloor h+1 \rfloor \phi(h) \right) - \int_0^\infty \lfloor h+1 \rfloor \phi'(h) \, dh \end{align} The first term on the r.h.s vanishes because of the exponential factor. We have \begin{align} \phi'(h) = -\pi e^{-h^2 \pi^2 s} \left( 2\pi h s \cos(h\pi z) + z \sin(h\pi z) \right) \end{align} and $\lfloor h+1 \rfloor = h+1 -\{h+1\} = 1 + h - \{h\}$ . Moreover, we can use the integral results \begin{align} \int_0^\infty dh \, 2 h \pi^2 s \, e^{-h^2 \pi^2 s} \, h \, \cos(h \pi z) &= 1 - \frac{z}{\sqrt{s}} D_+(\frac{z}{2\sqrt{s}}) \\ % \int_0^\infty dh \,  2 h^2 \pi^2 s \, e^{-h^2 \pi^2 s} \, \cos(h \pi z) &=  \frac{ e^{-\frac{z^2}{4s}}}{\sqrt{4\pi s}} \left( 1 - \frac{z^2}{2 s} \right) \\ % \int_0^\infty dh \, z \pi \, e^{-h^2 \pi^2 s}  \, \sin(h \pi z) &=  \frac{z}{\sqrt{s}} D_+(\frac{z}{2\sqrt{s}})\\ % \int_0^\infty dh \,  z \pi h \, e^{-h^2 \pi^2 s} \, \sin(h \pi z) &=  \frac{ e^{-\frac{z^2}{4s}}}{\sqrt{4\pi s}} \, \frac{z^2}{2 s} \end{align} where $D_+(z)$ is the Dawson function . Then we'll have (ps: possibly easier to get this just using integrations by part...) \begin{align} \sum_{n=0}^\infty \phi(n) = 1 + \frac{e^{-\frac{z^2}{4s}}}{\sqrt{4\pi s}} + \int_0^\infty \{h\} \phi'(h) dh \end{align} I have no idea how to estimate/find bounds of the remaining integral. In case that integral is something that could be neglected (I doubt), then we can just take the rest of the r.h.s and plug it into the expression for $I$ , compute the $s$ derivative and perform the integrations (which I think will give some error functions etc). Update We can work out the following bounds: as $ 0 \leq \{h\} <1 $ we have \begin{align}  \int_0^\infty \{h\} \phi'(h) \, dh &\leq \int_0^\infty \{h\} |\phi'(h)| \, dh \\ & \leq \int_0^\infty |\phi'(h)| dh \\ &\leq \int_0^\infty \pi e^{-h^2 \pi^2 s}\sqrt{4\pi^2h^2s^2+z^2} dh\\ &= \frac{ z^2 e^{\frac{z^2}{8s}}}{8s} \left( K_0(\frac{z^2}{8s}) + K_1 (\frac{z^2}{8s} ) \right), \end{align} where $K_\alpha$ is the modified Bessel function of the second kind . I am not sure if this bound is actually useful.","As my previous post remains unanswered, I thought I would post a more complete form of the problem in case it would be more practical to work on/ solve. I am trying to compute the following integral where and . To give a bit of context, I have come across this in a setting of heat propagation with Neumann boundary conditions and it does not seem to be something that can be calculated analytically. I have indeed looked at the numerical results for various values of and , but I still like to have an expression that approximates (or various expression for different regimes). Any suggestions are therefore appreciated. My own (hopeless) attempt is based on approximating the functions first, for exmaple using Abel's summation formula following this post . Let's define which in terms of Jacobi theta function could be represented as To use Abel's formula, we can define and write The first term on the r.h.s vanishes because of the exponential factor. We have and . Moreover, we can use the integral results where is the Dawson function . Then we'll have (ps: possibly easier to get this just using integrations by part...) I have no idea how to estimate/find bounds of the remaining integral. In case that integral is something that could be neglected (I doubt), then we can just take the rest of the r.h.s and plug it into the expression for , compute the derivative and perform the integrations (which I think will give some error functions etc). Update We can work out the following bounds: as we have where is the modified Bessel function of the second kind . I am not sure if this bound is actually useful.","\begin{align}
I_{\pm\pm} (x,y) = \int_0^1 dz \int_0^\infty ds \, \frac{e^{-\alpha/s}}{s} \,\partial_s \left[ \theta_3 \left( \frac{\pi(x \pm z)}{2},e^{-s} \right) \,\theta_3 \left( \frac{\pi(y \pm z)}{2},e^{-s} \right) \right]
\end{align} x,y \in (0,1) \alpha > 0 x y I(x,y) \theta_3 \begin{align}
f (z,s) = \sum_{n=0}^\infty e^{-n^2 \pi^2 s} \cos (n \pi z)
\end{align} 
f (z,s) = ( \theta_3 ( \pi z/2 , e^{-\pi^2 s}) + 1 )/2.
  \phi (h) = e^{-h^2 \pi^2 s} \cos(h \pi z)  \begin{align}
\sum_{n=0}^\infty \phi(n) = \lim_{h \to \infty} \left( \lfloor h+1 \rfloor \phi(h) \right) - \int_0^\infty \lfloor h+1 \rfloor \phi'(h) \, dh
\end{align} \begin{align}
\phi'(h) = -\pi e^{-h^2 \pi^2 s} \left( 2\pi h s \cos(h\pi z) + z \sin(h\pi z) \right)
\end{align} \lfloor h+1 \rfloor = h+1 -\{h+1\} = 1 + h - \{h\} \begin{align}
\int_0^\infty dh \, 2 h \pi^2 s \, e^{-h^2 \pi^2 s} \, h \, \cos(h \pi z) &= 1 - \frac{z}{\sqrt{s}} D_+(\frac{z}{2\sqrt{s}}) \\
%
\int_0^\infty dh \,  2 h^2 \pi^2 s \, e^{-h^2 \pi^2 s} \, \cos(h \pi z) &=  \frac{ e^{-\frac{z^2}{4s}}}{\sqrt{4\pi s}} \left( 1 - \frac{z^2}{2 s} \right) \\
%
\int_0^\infty dh \, z \pi \, e^{-h^2 \pi^2 s}  \, \sin(h \pi z) &=  \frac{z}{\sqrt{s}} D_+(\frac{z}{2\sqrt{s}})\\
%
\int_0^\infty dh \,  z \pi h \, e^{-h^2 \pi^2 s} \, \sin(h \pi z) &=  \frac{ e^{-\frac{z^2}{4s}}}{\sqrt{4\pi s}} \, \frac{z^2}{2 s}
\end{align} D_+(z) \begin{align}
\sum_{n=0}^\infty \phi(n) = 1 + \frac{e^{-\frac{z^2}{4s}}}{\sqrt{4\pi s}} + \int_0^\infty \{h\} \phi'(h) dh
\end{align} I s  0 \leq \{h\} <1  \begin{align}
 \int_0^\infty \{h\} \phi'(h) \, dh &\leq \int_0^\infty \{h\} |\phi'(h)| \, dh \\
& \leq \int_0^\infty |\phi'(h)| dh \\
&\leq \int_0^\infty \pi e^{-h^2 \pi^2 s}\sqrt{4\pi^2h^2s^2+z^2} dh\\
&= \frac{ z^2 e^{\frac{z^2}{8s}}}{8s} \left( K_0(\frac{z^2}{8s}) + K_1 (\frac{z^2}{8s} ) \right),
\end{align} K_\alpha","['sequences-and-series', 'approximation', 'theta-functions']"
40,Quaternionic and octonionic analogues of the Basel problem,Quaternionic and octonionic analogues of the Basel problem,,"It is a well-known fact that $$\sum_{0\neq n\in\mathbb{Z}} \frac{1}{n^k} = r_k (2\pi)^k$$ for any integer $k>1$ , where $r_k$ are rational numbers which can be given explicitly in terms of Bernoulli numbers. For example, for $k=2$ the sum equals $\pi^2/3$ (this is essentially the Basel problem ), and for $k=4$ it equals $\pi^4/45$ . Note that for odd $k$ the sum vanishes. The theory of elliptic curves with complex multiplication allows us to extend this result to systems of complex integers such as the Gaussian integers , or more generally the ring of integers in an imaginary quadratic number field of class number 1. Namely, for $k>2$ we have $$\sum_{0\neq \lambda\in\mathbb{Z[\omega]}} \frac{1}{\lambda^k} = r_k \varpi^k,$$ where again $r_k$ are rational constants and $\varpi \in \mathbb{R}$ (the ""complex $2\pi$ "") depends only on the ring $\mathcal{O}=\mathbb{Z[\omega]}$ and is an algebraic multiple of a so-called Chowla–Selberg period , given by a product of powers of certain gamma factors (note that the sum is always a real number since it is invariant under conjugation). For example, for the Eisenstein ( $\omega = (1+\sqrt{3} i)/2$ ), Gaussian ( $\omega = i$ ) and Kleinian ( $\omega = (1+\sqrt{7} i)/2$ ) integers, we have respectively $$\varpi_3 = 3^{-1/4} \sqrt{2\pi} \left(\frac{\Gamma(1/3)}{\Gamma(2/3)}\right)^{3/2}, \quad \varpi_4 = 4^{-1/4} \sqrt{2\pi} \left(\frac{\Gamma(1/4)}{\Gamma(3/4)}\right), \quad \varpi_7 = 7^{-1/4} \sqrt{2\pi} \left(\frac{\Gamma(1/7)\Gamma(2/7)\Gamma(4/7)}{\Gamma(3/7)\Gamma(5/7)\Gamma(6/7)}\right)^{1/2}.$$ For higher class numbers there is a similar formula, though in that case $r_k$ will in general not be rational but algebraic. A nice exposition of this result can be found in Section 6.3 of these notes . My question is whether this is still true for hypercomplex number systems, such as the Hurwitz integers or the octonionic integers .  Define $$S_k[\mathcal{O}] = \sum_{0\neq \lambda\in\mathcal{O}} \frac{1}{\lambda^k}$$ for $k>\operatorname{dim} \mathcal{O}$ , where $\mathcal{O}$ is now an order in a totally definite rational quaternion/octonion algebra of class number 1. The restriction on $k$ is so that the sum converges absolutely. Subquestion 1: Do we have $S_k[\mathcal{O}] = r_k \varpi^k$ for some rational sequence $r_k$ and some real number $\varpi$ depending only on $\mathcal{O}$ (a ""quaternionic/octonionic $2\pi$ "")? Obviously $\varpi$ will only be defined up to a nonzero rational factor. An equivalent question is whether $(S_m[\mathcal{O}])^n/(S_n[\mathcal{O}])^m$ is rational for any $m, n$ such that $S_n[\mathcal{O}]\neq 0$ . Subquestion 2: If so, can (some fixed choice of) $\varpi$ be expressed in terms of known constants such as $\zeta'(-1)$ or $\zeta'(-3)$ ? The reason I'm mentioning these particular constants is that in the previous cases (real and complex) the period $\varpi$ turns out to be equal to $e^{-\zeta'(\mathcal{O},0)/\zeta(\mathcal{O},0)}$ up to an algebraic factor, where the zeta function attached to the ring of integers $\mathcal{O}=\mathbb{Z}$ or $\mathbb{Z[\omega]}$ is defined as $$\zeta(\mathcal{O},s) = \sum_{0\neq \lambda\in\mathcal{O}} |\lambda|^{-s}.$$ (This is in general not the same as the previous sums, note the absolute value). In the case that $\mathcal{O}$ is instead a quaternionic or octonionic order, the logarithmic derivative of this zeta function at $s=0$ can be expressed in terms of $\zeta'(-1)$ or $\zeta'(-3)$ respectively, where $\zeta(s)$ is the ordinary Riemann zeta function. Update: I have calculated a few sums numerically for the ring of Hurwitz quaternions. The result is $$S_6[\mathcal{O}] \approx 10.76,\quad S_8[\mathcal{O}] \approx 1.196,\quad S_{12}[\mathcal{O}] \approx 23.9905.$$ Unfortunately the calculations take a lot of time, and right now the precision is not senough to determine whether e.g. $S_{12}[\mathcal{O}]/(S_6[\mathcal{O}])^2$ is rational to any degree of confidence.","It is a well-known fact that for any integer , where are rational numbers which can be given explicitly in terms of Bernoulli numbers. For example, for the sum equals (this is essentially the Basel problem ), and for it equals . Note that for odd the sum vanishes. The theory of elliptic curves with complex multiplication allows us to extend this result to systems of complex integers such as the Gaussian integers , or more generally the ring of integers in an imaginary quadratic number field of class number 1. Namely, for we have where again are rational constants and (the ""complex "") depends only on the ring and is an algebraic multiple of a so-called Chowla–Selberg period , given by a product of powers of certain gamma factors (note that the sum is always a real number since it is invariant under conjugation). For example, for the Eisenstein ( ), Gaussian ( ) and Kleinian ( ) integers, we have respectively For higher class numbers there is a similar formula, though in that case will in general not be rational but algebraic. A nice exposition of this result can be found in Section 6.3 of these notes . My question is whether this is still true for hypercomplex number systems, such as the Hurwitz integers or the octonionic integers .  Define for , where is now an order in a totally definite rational quaternion/octonion algebra of class number 1. The restriction on is so that the sum converges absolutely. Subquestion 1: Do we have for some rational sequence and some real number depending only on (a ""quaternionic/octonionic "")? Obviously will only be defined up to a nonzero rational factor. An equivalent question is whether is rational for any such that . Subquestion 2: If so, can (some fixed choice of) be expressed in terms of known constants such as or ? The reason I'm mentioning these particular constants is that in the previous cases (real and complex) the period turns out to be equal to up to an algebraic factor, where the zeta function attached to the ring of integers or is defined as (This is in general not the same as the previous sums, note the absolute value). In the case that is instead a quaternionic or octonionic order, the logarithmic derivative of this zeta function at can be expressed in terms of or respectively, where is the ordinary Riemann zeta function. Update: I have calculated a few sums numerically for the ring of Hurwitz quaternions. The result is Unfortunately the calculations take a lot of time, and right now the precision is not senough to determine whether e.g. is rational to any degree of confidence.","\sum_{0\neq n\in\mathbb{Z}} \frac{1}{n^k} = r_k (2\pi)^k k>1 r_k k=2 \pi^2/3 k=4 \pi^4/45 k k>2 \sum_{0\neq \lambda\in\mathbb{Z[\omega]}} \frac{1}{\lambda^k} = r_k \varpi^k, r_k \varpi \in \mathbb{R} 2\pi \mathcal{O}=\mathbb{Z[\omega]} \omega = (1+\sqrt{3} i)/2 \omega = i \omega = (1+\sqrt{7} i)/2 \varpi_3 = 3^{-1/4} \sqrt{2\pi} \left(\frac{\Gamma(1/3)}{\Gamma(2/3)}\right)^{3/2}, \quad \varpi_4 = 4^{-1/4} \sqrt{2\pi} \left(\frac{\Gamma(1/4)}{\Gamma(3/4)}\right), \quad \varpi_7 = 7^{-1/4} \sqrt{2\pi} \left(\frac{\Gamma(1/7)\Gamma(2/7)\Gamma(4/7)}{\Gamma(3/7)\Gamma(5/7)\Gamma(6/7)}\right)^{1/2}. r_k S_k[\mathcal{O}] = \sum_{0\neq \lambda\in\mathcal{O}} \frac{1}{\lambda^k} k>\operatorname{dim} \mathcal{O} \mathcal{O} k S_k[\mathcal{O}] = r_k \varpi^k r_k \varpi \mathcal{O} 2\pi \varpi (S_m[\mathcal{O}])^n/(S_n[\mathcal{O}])^m m, n S_n[\mathcal{O}]\neq 0 \varpi \zeta'(-1) \zeta'(-3) \varpi e^{-\zeta'(\mathcal{O},0)/\zeta(\mathcal{O},0)} \mathcal{O}=\mathbb{Z} \mathbb{Z[\omega]} \zeta(\mathcal{O},s) = \sum_{0\neq \lambda\in\mathcal{O}} |\lambda|^{-s}. \mathcal{O} s=0 \zeta'(-1) \zeta'(-3) \zeta(s) S_6[\mathcal{O}] \approx 10.76,\quad S_8[\mathcal{O}] \approx 1.196,\quad S_{12}[\mathcal{O}] \approx 23.9905. S_{12}[\mathcal{O}]/(S_6[\mathcal{O}])^2","['sequences-and-series', 'analytic-number-theory', 'quaternions', 'octonions', 'complex-multiplication']"
41,Existence of infinitely many sequences of this kind that are prime-free,Existence of infinitely many sequences of this kind that are prime-free,,"Prove that there exists infinitely many positive integers, $x$ , such that the sequence $(a_n)$ : $$a_0=1, a_1=x+1, a_{n+2}=xa_{n+1}-a_n$$ is prime-free (i.e. all terms are composite). Note: observe that $a_{4n}\equiv a_{4n+1}\equiv 1  ~(mod ~p)$ and $a_{4n+2}\equiv a_{4n+3}\equiv x-1  ~(mod ~p)$ , I guess terms in this sequence that share a common prime factor of $x\pm1$ have their positions repeat in a periodic pattern.","Prove that there exists infinitely many positive integers, , such that the sequence : is prime-free (i.e. all terms are composite). Note: observe that and , I guess terms in this sequence that share a common prime factor of have their positions repeat in a periodic pattern.","x (a_n) a_0=1, a_1=x+1, a_{n+2}=xa_{n+1}-a_n a_{4n}\equiv a_{4n+1}\equiv 1  ~(mod ~p) a_{4n+2}\equiv a_{4n+3}\equiv x-1  ~(mod ~p) x\pm1","['sequences-and-series', 'number-theory', 'elementary-number-theory', 'prime-numbers']"
42,Binomial Euler sums: Evaluate $\sum_{n=1}^\infty\frac1{4^n}\binom{2n}n\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s}$,Binomial Euler sums: Evaluate,\sum_{n=1}^\infty\frac1{4^n}\binom{2n}n\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s},"Denote $$f(s;s_1,s_2,\ldots,s_k)=\sum_{n=1}^\infty\frac1{4^n}\binom{2n}n\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s}$$ Can $f(\cdots)$ always be represented as $\mathbb Q$ -linear combination of alternating Euler sum of weight $W$ ? Here $s$ and $s_i$ are positive integers and $W=s+\sum_i s_i$ . Alternating Euler sums are defined as $$\sum_{n=1}^\infty (-1)^{l(n-1)}\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s},$$ where $l=0,1$ and $s,s_i\in\mathbb Z^+$ . By Editor: Examples and related things: Here , here , here , here , here , here , here . By Editor again: Harder examples and generalizations: Here , here , here , here . Numerical Evidence and Motivation I did some calculation of this binomial sum of small $n$ 's. The table in the appendix is a part of that. I also did some research on alternating Euler sum. The constants involved in the alt. Euler sums are exactly the same when $n\le4$ . I randomly chose and evaluated some sums of weight $5$ and found that their constants are again same. Possible Conversion Although I noticed $\frac1{4^n}\binom{2n}n=\frac2\pi\int_0^1(4x-4x^2)^{n-1/2}dx$ , I'm unsure about how to convert it into the whole sum into an integral and then (possibly making some substitution?) convert it into the form of alternating Euler sum. Appendix The number in the blanks are the coefficients. \begin{array}{|c|c|} \hline &\ln2\\\hline f(1)&2\\\hline \end{array} \begin{array}{|c|c|c|}\hline &\zeta(2)&\ln^22\\\hline f(2)&1&-2\\\hline f(1;1)&2&0\\\hline \end{array} \begin{array}{|c|c|c|c|} \hline &\zeta(3)&\zeta(2)\ln2&\ln^32\\\hline f(3)&2&-2&\frac43\\\hline f(2;1)&\frac92&-4&0\\\hline f(1;2)&\frac32&0&0\\\hline f(1;1^2)&\frac{21}2&0&0\\\hline \end{array} \begin{array}{|c|c|c|c|c|c|} \hline &\zeta(4)&\zeta(3)\ln2&\zeta(2)\ln^22&\ln^42&\operatorname{Li}_4(1/2)\\\hline f(4)&\frac94&-4&2&-\frac23&0\\\hline f(3;1)&-\frac{13}4&-2&2&\frac13&8\\\hline f(2;2)&3&-3&0&0&0\\\hline f(2;1^2)&-14&7&-8&\frac43&32\\\hline f(1;3)&\frac{37}4&-7&2&-\frac13&-8\\\hline f(1;2,1)&\frac{49}4&-7&2&-\frac13&-8\\\hline f(1;1^3)&\frac{115}4&35&-10&\frac53&40\\\hline \end{array}","Denote Can always be represented as -linear combination of alternating Euler sum of weight ? Here and are positive integers and . Alternating Euler sums are defined as where and . By Editor: Examples and related things: Here , here , here , here , here , here , here . By Editor again: Harder examples and generalizations: Here , here , here , here . Numerical Evidence and Motivation I did some calculation of this binomial sum of small 's. The table in the appendix is a part of that. I also did some research on alternating Euler sum. The constants involved in the alt. Euler sums are exactly the same when . I randomly chose and evaluated some sums of weight and found that their constants are again same. Possible Conversion Although I noticed , I'm unsure about how to convert it into the whole sum into an integral and then (possibly making some substitution?) convert it into the form of alternating Euler sum. Appendix The number in the blanks are the coefficients.","f(s;s_1,s_2,\ldots,s_k)=\sum_{n=1}^\infty\frac1{4^n}\binom{2n}n\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s} f(\cdots) \mathbb Q W s s_i W=s+\sum_i s_i \sum_{n=1}^\infty (-1)^{l(n-1)}\frac{H_n^{(s_1)}\cdots H_n^{(s_k)}}{n^s}, l=0,1 s,s_i\in\mathbb Z^+ n n\le4 5 \frac1{4^n}\binom{2n}n=\frac2\pi\int_0^1(4x-4x^2)^{n-1/2}dx \begin{array}{|c|c|} \hline
&\ln2\\\hline
f(1)&2\\\hline
\end{array} \begin{array}{|c|c|c|}\hline
&\zeta(2)&\ln^22\\\hline
f(2)&1&-2\\\hline
f(1;1)&2&0\\\hline
\end{array} \begin{array}{|c|c|c|c|} \hline
&\zeta(3)&\zeta(2)\ln2&\ln^32\\\hline
f(3)&2&-2&\frac43\\\hline
f(2;1)&\frac92&-4&0\\\hline
f(1;2)&\frac32&0&0\\\hline
f(1;1^2)&\frac{21}2&0&0\\\hline
\end{array} \begin{array}{|c|c|c|c|c|c|} \hline
&\zeta(4)&\zeta(3)\ln2&\zeta(2)\ln^22&\ln^42&\operatorname{Li}_4(1/2)\\\hline
f(4)&\frac94&-4&2&-\frac23&0\\\hline
f(3;1)&-\frac{13}4&-2&2&\frac13&8\\\hline
f(2;2)&3&-3&0&0&0\\\hline
f(2;1^2)&-14&7&-8&\frac43&32\\\hline
f(1;3)&\frac{37}4&-7&2&-\frac13&-8\\\hline
f(1;2,1)&\frac{49}4&-7&2&-\frac13&-8\\\hline
f(1;1^3)&\frac{115}4&35&-10&\frac53&40\\\hline
\end{array}","['sequences-and-series', 'definite-integrals', 'closed-form', 'harmonic-numbers', 'euler-sums']"
43,How to determine bounds on one variable in a system of inequalities?,How to determine bounds on one variable in a system of inequalities?,,"I came across this problem whilst exploring the asymptotic behaviour (or not) of different generalised harmonic numbers. I am interested in the point of 'cross-over' between a generalised harmonic number where the denominator of the summand is raised to a power, and a non-exponential harmonic sum operating on some subset of the natural numbers. For example, take the generalised harmonic number $H_x^{(k)}=\sum_{n=1}^x \frac{1}{n^k}$ , and a harmonic number operating only on odd denominators $G_x=\sum_{n=1}^x \frac{1}{2 n-1}$ . Clearly, there exist values of $x,k$ such that $G_x<H_x^{(k)}$ and values such that $H_x^{(k)}<G_x$ . Thus there exists a value $c=G_{x_0}$ such that $$G_{x_0}=c<H_{x_0}^{(k)}=\sum_{n=1}^x \frac{1}{n^k}$$ and $$H_{{x_0}+2}^{(k)}<G_{{x_0}+2}=c+\frac{1}{2x_0+1}+\frac{1}{2x_0+3}$$ or $$H_{{x_0}+2}^{(k)}-c<\frac{1}{2x_0+1}+\frac{1}{2x_0+3}$$ The values of $c,x_0,k$ are obviously co-dependent. I am searching for a way to solve for $x_0$ or at least put bounds on it. I am interested in how to approach this algebraically rather than numerically. This is a single simple example of $G$ and I want to be able to explore how to solve such problems generally , for whatever pattern of $G$ I choose (provided it's formulable!). Algebraically, how do I put bounds on $x_0$ in terms of $c,k$ ? (I am an amateur, so I need a fair amount of hand-holding, hence the bounty.)","I came across this problem whilst exploring the asymptotic behaviour (or not) of different generalised harmonic numbers. I am interested in the point of 'cross-over' between a generalised harmonic number where the denominator of the summand is raised to a power, and a non-exponential harmonic sum operating on some subset of the natural numbers. For example, take the generalised harmonic number , and a harmonic number operating only on odd denominators . Clearly, there exist values of such that and values such that . Thus there exists a value such that and or The values of are obviously co-dependent. I am searching for a way to solve for or at least put bounds on it. I am interested in how to approach this algebraically rather than numerically. This is a single simple example of and I want to be able to explore how to solve such problems generally , for whatever pattern of I choose (provided it's formulable!). Algebraically, how do I put bounds on in terms of ? (I am an amateur, so I need a fair amount of hand-holding, hence the bounty.)","H_x^{(k)}=\sum_{n=1}^x \frac{1}{n^k} G_x=\sum_{n=1}^x \frac{1}{2 n-1} x,k G_x<H_x^{(k)} H_x^{(k)}<G_x c=G_{x_0} G_{x_0}=c<H_{x_0}^{(k)}=\sum_{n=1}^x \frac{1}{n^k} H_{{x_0}+2}^{(k)}<G_{{x_0}+2}=c+\frac{1}{2x_0+1}+\frac{1}{2x_0+3} H_{{x_0}+2}^{(k)}-c<\frac{1}{2x_0+1}+\frac{1}{2x_0+3} c,x_0,k x_0 G G x_0 c,k","['sequences-and-series', 'inequality', 'upper-lower-bounds', 'harmonic-numbers']"
44,Proof verification : A weird identity involving sums,Proof verification : A weird identity involving sums,,"I recently managed to solve a question that I asked a few days ago, but that was unfortunately closed, probably because it wasn't clear enough. Here is the question : Let $ n $ be a positive integer, prove the following identity : $$ \sum_{k=0}^{n}{\frac{1}{2k+1}\binom{n}{k}}=\left(\sum_{k=0}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\right)\left(\sum_{k=0}^{n}{\frac{\left(-1\right)^{k}}{2k+1}\binom{n}{k}}\right) $$ What I'm asking you for is to verify the following solution for me. First of all : $$ \sum_{k=0}^{n}{\frac{1}{2k+1}\binom{n}{k}}=\sum_{k=0}^{n}{\binom{n}{k}\int_{0}^{1}{x^{2k}\,\mathrm{d}x}}=\int_{0}^{1}{\left(1+x^{2}\right)^{n}\,\mathrm{d}x}\overset{\mathrm{denoted}}{=}I_{n}$$ Then : \begin{aligned} I_{n}=\int_{0}^{1}{\left(1+x^{2}\right)^{n}\,\mathrm{d}x}&=\left[x\left(1+x^{2}\right)^{n}\right]_{0}^{1}-2n\int_{0}^{1}{x^{2}\left(1+x^{2}\right)^{n}\,\mathrm{d}x}\\ &=2^{n}-2n\int_{0}^{1}{\left(\left(1+x^{2}\right)^{n}-\left(1+x^{2}\right)^{n-1}\right)\mathrm{d}x} \\ I_{n}&=2^{n}-2n\left(I_{n}-I_{n-1}\right)\\ \iff I_{n}&=\frac{2^{n}}{2n+1}+\frac{2n}{2n+1}I_{n-1}\end{aligned} In order to solve this recurrence relation, we'll multiply everything by $ \prod\limits_{k=1}^{n}{\frac{2k+1}{2k}} $ , so that we could have telescopic cancelling between the consecutive terms. Meaning, $$ \prod_{k=1}^{n}{\frac{2k+1}{2k}}I_{n}=\frac{2^{n}}{2n+1}\prod_{k=1}^{n}{\frac{2k+1}{2k}}+\prod_{k=1}^{n-1}{\frac{2k+1}{2k}}I_{n-1} $$ Since : $$ \frac{2^{n}}{2n+1}\prod_{k=1}^{n}{\frac{2k+1}{2k}}=\frac{2^{n}\prod\limits_{k=0}^{n-1}{\left(2k+1\right)}}{\prod\limits_{k=1}^{n}{\left(2k\right)}}=\frac{\left(2n\right)!}{2^{n}\left(n!\right)^{2}}=\frac{1}{2^{n}}\binom{2n}{n} $$ We get that for any $ k\geq 1 $ : \begin{aligned} \prod_{j=1}^{k}{\frac{2j+1}{2j}}I_{k}-\prod_{j=1}^{k-1}{\frac{2j+1}{2j}}I_{k-1}&=\frac{1}{2^{k}}\binom{2k}{k}\\ \Longrightarrow\sum_{k=1}^{n}{\left(\prod_{j=1}^{k}{\frac{2j+1}{2j}}I_{k}-\prod_{j=1}^{k-1}{\frac{2j+1}{2j}}I_{k-1}\right)}&=\sum_{k=1}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\\ \iff \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \prod_{k=1}^{n}{\frac{2k+1}{2k}}I_{n}-1&=\sum_{k=1}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\\ \iff \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ I_{n}&=\left(\prod_{k=1}^{n}{\frac{2k}{2k+1}}\right)\left(\sum_{k=0}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\right)\end{aligned} Secondly : $$ \sum_{k=0}^{n}{\frac{\left(-1\right)^{k}}{2k+1}\binom{n}{k}}=\sum_{k=0}^{n}{\left(-1\right)^{k}\binom{n}{k}\int_{0}^{1}{x^{2k}\,\mathrm{d}x}}=\int_{0}^{1}{\left(1-x^{2}\right)^{n}\,\mathrm{d}x}\overset{\mathrm{denoted}}{=}J_{n} $$ Then : \begin{aligned} J_{n}=\int_{0}^{1}{\left(1-x^{2}\right)^{n}\,\mathrm{d}x}&=\left[x\left(1-x^{2}\right)^{n}\right]_{0}^{1}+2n\int_{0}^{1}{x^{2}\left(1-x^{2}\right)^{n}\,\mathrm{d}x}\\&=2n\int_{0}^{1}{\left(\left(1-x^{2}\right)^{n-1}-\left(1-x^{2}\right)^{n}\right)\mathrm{d}x} \\ J_{n}&=2n\left(J_{n-1}-J_{n}\right)\\ \iff \ \ \ \ \ \ \ \ \ J_{n}&=\frac{2n}{2n+1}J_{n-1}\\ \Longrightarrow \prod_{k=1}^{n}{\frac{J_{k}}{J_{k-1}}}&=\prod_{k=1}^{n}{\frac{2k}{2k+1}}\\ \iff \ \ \ \ \ \ \ \ \ J_{n}&=\prod_{k=1}^{n}{\frac{2k}{2k+1}}\end{aligned} Thus, $$ \sum_{k=0}^{n}{\frac{1}{2k+1}\binom{n}{k}}=\left(\sum_{k=0}^{n}{\frac{\left(-1\right)^{k}}{2k+1}\binom{n}{k}}\right)\left(\sum_{k=0}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\right) $$ What do you guys think ?","I recently managed to solve a question that I asked a few days ago, but that was unfortunately closed, probably because it wasn't clear enough. Here is the question : Let be a positive integer, prove the following identity : What I'm asking you for is to verify the following solution for me. First of all : Then : In order to solve this recurrence relation, we'll multiply everything by , so that we could have telescopic cancelling between the consecutive terms. Meaning, Since : We get that for any : Secondly : Then : Thus, What do you guys think ?"," n   \sum_{k=0}^{n}{\frac{1}{2k+1}\binom{n}{k}}=\left(\sum_{k=0}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\right)\left(\sum_{k=0}^{n}{\frac{\left(-1\right)^{k}}{2k+1}\binom{n}{k}}\right)   \sum_{k=0}^{n}{\frac{1}{2k+1}\binom{n}{k}}=\sum_{k=0}^{n}{\binom{n}{k}\int_{0}^{1}{x^{2k}\,\mathrm{d}x}}=\int_{0}^{1}{\left(1+x^{2}\right)^{n}\,\mathrm{d}x}\overset{\mathrm{denoted}}{=}I_{n} \begin{aligned} I_{n}=\int_{0}^{1}{\left(1+x^{2}\right)^{n}\,\mathrm{d}x}&=\left[x\left(1+x^{2}\right)^{n}\right]_{0}^{1}-2n\int_{0}^{1}{x^{2}\left(1+x^{2}\right)^{n}\,\mathrm{d}x}\\ &=2^{n}-2n\int_{0}^{1}{\left(\left(1+x^{2}\right)^{n}-\left(1+x^{2}\right)^{n-1}\right)\mathrm{d}x} \\ I_{n}&=2^{n}-2n\left(I_{n}-I_{n-1}\right)\\ \iff I_{n}&=\frac{2^{n}}{2n+1}+\frac{2n}{2n+1}I_{n-1}\end{aligned}  \prod\limits_{k=1}^{n}{\frac{2k+1}{2k}}   \prod_{k=1}^{n}{\frac{2k+1}{2k}}I_{n}=\frac{2^{n}}{2n+1}\prod_{k=1}^{n}{\frac{2k+1}{2k}}+\prod_{k=1}^{n-1}{\frac{2k+1}{2k}}I_{n-1}   \frac{2^{n}}{2n+1}\prod_{k=1}^{n}{\frac{2k+1}{2k}}=\frac{2^{n}\prod\limits_{k=0}^{n-1}{\left(2k+1\right)}}{\prod\limits_{k=1}^{n}{\left(2k\right)}}=\frac{\left(2n\right)!}{2^{n}\left(n!\right)^{2}}=\frac{1}{2^{n}}\binom{2n}{n}   k\geq 1  \begin{aligned} \prod_{j=1}^{k}{\frac{2j+1}{2j}}I_{k}-\prod_{j=1}^{k-1}{\frac{2j+1}{2j}}I_{k-1}&=\frac{1}{2^{k}}\binom{2k}{k}\\ \Longrightarrow\sum_{k=1}^{n}{\left(\prod_{j=1}^{k}{\frac{2j+1}{2j}}I_{k}-\prod_{j=1}^{k-1}{\frac{2j+1}{2j}}I_{k-1}\right)}&=\sum_{k=1}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\\ \iff \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \prod_{k=1}^{n}{\frac{2k+1}{2k}}I_{n}-1&=\sum_{k=1}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\\ \iff \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ I_{n}&=\left(\prod_{k=1}^{n}{\frac{2k}{2k+1}}\right)\left(\sum_{k=0}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\right)\end{aligned}  \sum_{k=0}^{n}{\frac{\left(-1\right)^{k}}{2k+1}\binom{n}{k}}=\sum_{k=0}^{n}{\left(-1\right)^{k}\binom{n}{k}\int_{0}^{1}{x^{2k}\,\mathrm{d}x}}=\int_{0}^{1}{\left(1-x^{2}\right)^{n}\,\mathrm{d}x}\overset{\mathrm{denoted}}{=}J_{n}  \begin{aligned} J_{n}=\int_{0}^{1}{\left(1-x^{2}\right)^{n}\,\mathrm{d}x}&=\left[x\left(1-x^{2}\right)^{n}\right]_{0}^{1}+2n\int_{0}^{1}{x^{2}\left(1-x^{2}\right)^{n}\,\mathrm{d}x}\\&=2n\int_{0}^{1}{\left(\left(1-x^{2}\right)^{n-1}-\left(1-x^{2}\right)^{n}\right)\mathrm{d}x} \\ J_{n}&=2n\left(J_{n-1}-J_{n}\right)\\ \iff \ \ \ \ \ \ \ \ \ J_{n}&=\frac{2n}{2n+1}J_{n-1}\\ \Longrightarrow \prod_{k=1}^{n}{\frac{J_{k}}{J_{k-1}}}&=\prod_{k=1}^{n}{\frac{2k}{2k+1}}\\ \iff \ \ \ \ \ \ \ \ \ J_{n}&=\prod_{k=1}^{n}{\frac{2k}{2k+1}}\end{aligned}  \sum_{k=0}^{n}{\frac{1}{2k+1}\binom{n}{k}}=\left(\sum_{k=0}^{n}{\frac{\left(-1\right)^{k}}{2k+1}\binom{n}{k}}\right)\left(\sum_{k=0}^{n}{\frac{1}{2^{k}}\binom{2k}{k}}\right) ","['sequences-and-series', 'summation', 'binomial-coefficients', 'solution-verification']"
45,A peculiar series involving $\pi$,A peculiar series involving,\pi,"A mathematical Facebook group posted a picture with the following claimed identity: $$ \sum_{n=0}^{\infty} \frac{1+14 n+76 n^{2}+168 n^{3}}{2^{20 n}}\binom{2n}{n}^{7}=\frac{32}{\pi^{3}}. $$ they didn't provide any source for this claim, but it appears that it might be a conjecture. Is this a familiar series? If so, what are its origins?","A mathematical Facebook group posted a picture with the following claimed identity: they didn't provide any source for this claim, but it appears that it might be a conjecture. Is this a familiar series? If so, what are its origins?","
\sum_{n=0}^{\infty} \frac{1+14 n+76 n^{2}+168 n^{3}}{2^{20 n}}\binom{2n}{n}^{7}=\frac{32}{\pi^{3}}.
","['sequences-and-series', 'analysis', 'pi']"
46,Prove that the sequence $b_n=b_{n-1}+b_{\left[\frac{n}{2}\right]}$ ($b_1=1$) contains infinitely many elements that are divisible by $7$,Prove that the sequence  () contains infinitely many elements that are divisible by,b_n=b_{n-1}+b_{\left[\frac{n}{2}\right]} b_1=1 7,"Let the sequence $b_n$ such that $$b_1=1, \; b_n=b_{n-1}+b_{\left[\frac{n}{2}\right]} \;\; \text{for all}\;\; n \ge 2,$$ where $\left[\frac{n}{2}\right]$ is an integer part of a real number $\frac{n}{2}$ ( $\left[\frac{n}{2}\right]$ is a largest integer not exceeding $\frac{n}{2}$ ).    Prove that the sequence $b_n$ contains infinitely many elements that are divisible by $7$ . My work . The sequence $b_n$ is $1, 2, 3, 5, \fbox{7},  10, 13, 18, 23, 30, 37, 47, 57, \fbox{70},  83, 101, \fbox{119},  142, 165, 195, 225, 262, 299, 346, 393, 450, 507, 577, 647, 730, 813, 914, \fbox{1015},  \fbox{1134},  \fbox{1253},  1395, 1537, 1702, 1867, 2062, 2257, 2482, 2707, 2969, 3231, 3530, \fbox{3829},  4175, 4521, \fbox{4914},  5307, 5757, 6207, 6714, 7221, \fbox{7798},  8375, 9022, 9669, 10399, 11129, \fbox{11942},  12755, 13669, 14583, 15598, 16613, 17747, 18881, 20134, 21387, 22782, 24177, 25714, \fbox{27251},  28953, 30655, \fbox{32522},  34389, 36451, 38513, 40770, 43027, 45509, 47991, 50698, 53405, 56374, 59343, 62574, 65805, \fbox{69335},  72865, 76694, 80523, 84698, 88873, \fbox{93394},  97915.$ It is not easy to see what is the pattern here.",Let the sequence such that where is an integer part of a real number ( is a largest integer not exceeding ).    Prove that the sequence contains infinitely many elements that are divisible by . My work . The sequence is It is not easy to see what is the pattern here.,"b_n b_1=1, \; b_n=b_{n-1}+b_{\left[\frac{n}{2}\right]} \;\; \text{for all}\;\; n \ge 2, \left[\frac{n}{2}\right] \frac{n}{2} \left[\frac{n}{2}\right] \frac{n}{2} b_n 7 b_n 1, 2, 3, 5, \fbox{7}, 
10, 13, 18, 23, 30, 37, 47, 57, \fbox{70}, 
83, 101, \fbox{119}, 
142, 165, 195, 225, 262, 299, 346, 393, 450, 507, 577, 647, 730, 813, 914, \fbox{1015}, 
\fbox{1134}, 
\fbox{1253}, 
1395, 1537, 1702, 1867, 2062, 2257, 2482, 2707, 2969, 3231, 3530, \fbox{3829}, 
4175, 4521, \fbox{4914}, 
5307, 5757, 6207, 6714, 7221, \fbox{7798}, 
8375, 9022, 9669, 10399, 11129, \fbox{11942}, 
12755, 13669, 14583, 15598, 16613, 17747, 18881, 20134, 21387, 22782, 24177, 25714, \fbox{27251}, 
28953, 30655, \fbox{32522}, 
34389, 36451, 38513, 40770, 43027, 45509, 47991, 50698, 53405, 56374, 59343, 62574, 65805, \fbox{69335}, 
72865, 76694, 80523, 84698, 88873, \fbox{93394}, 
97915.","['sequences-and-series', 'number-theory', 'contest-math', 'divisibility']"
47,Almost surely convergence for independent random variables and bounded real sequence,Almost surely convergence for independent random variables and bounded real sequence,,"Stumbled upon an exercise in my probability course which was given a couple of years ago as an assignment problem and was trying to solve it. However, I am struggling a bit with probability theory (especially the convergence part and characteristic functions part of the course) and thus I have no idea how to solve this. Problem. Suppose we have $X_{2}, X_{3}, \ldots$ independent random variables and $E[X_{1}] = 1$ . Let $y_{n}$ be a bounded sequence of real numbers. Show that we have $\frac{1}{n} \sum^{n}_{j = 1} y_{j} \longrightarrow{} 1$ if and only if $\frac{1}{n} \sum^{n}_{j = 2} y_{j} X_{j} \longrightarrow 1,$ a.s.","Stumbled upon an exercise in my probability course which was given a couple of years ago as an assignment problem and was trying to solve it. However, I am struggling a bit with probability theory (especially the convergence part and characteristic functions part of the course) and thus I have no idea how to solve this. Problem. Suppose we have independent random variables and . Let be a bounded sequence of real numbers. Show that we have if and only if a.s.","X_{2}, X_{3}, \ldots E[X_{1}] = 1 y_{n} \frac{1}{n} \sum^{n}_{j = 1} y_{j} \longrightarrow{} 1 \frac{1}{n} \sum^{n}_{j = 2} y_{j} X_{j} \longrightarrow 1,","['sequences-and-series', 'probability-theory', 'convergence-divergence']"
48,What's the Maclaurin series of $\frac{\ln(1-x)\ln(1+x)}{1+x^2}$?,What's the Maclaurin series of ?,\frac{\ln(1-x)\ln(1+x)}{1+x^2},"I am trying to find a closed-form for the Maclaurin series of $\frac{\ln(1-x)\ln(1+x)}{1+x^2}$ . I am not sure if it's possible but here is what I did: We know that: $$\ln(1-x)\ln(1+x)=\sum_{n=1}^\infty\left(\frac{H_n-H_{2n}}{n}-\frac{1}{2n^2}\right)x^{2n}\tag1$$ $$\frac1{1+x^2}=\sum_{n=1}^\infty (-1)^{n-1}x^{2n-2}$$ And by the Cauchy product of power series $$\left(\sum_{n=1}^\infty a_nx^n\right)\left(\sum_{n=1}^\infty b_nx^n\right)=\sum_{n=1}^\infty x^{n+1}\left(\sum_{k=1}^n a_k\ b_{n-k+1}\right)$$ we have $$\frac{\ln(1-x)\ln(1+x)}{1+x^2}=\sum_{n=1}^\infty(-1)^nx^{2n}\color{blue}{\left(\sum_{k=1}^n(-1)^k\left(\frac{H_k-H_{2k}}{k}-\frac1{2k^2}\right)\right)},$$ and I have no idea how to deal with the blue sum, any idea? Or maybe a different approach? The identity of $(1)$ can be found in the book Almost Impossible Integrals, Sums and Series .","I am trying to find a closed-form for the Maclaurin series of . I am not sure if it's possible but here is what I did: We know that: And by the Cauchy product of power series we have and I have no idea how to deal with the blue sum, any idea? Or maybe a different approach? The identity of can be found in the book Almost Impossible Integrals, Sums and Series .","\frac{\ln(1-x)\ln(1+x)}{1+x^2} \ln(1-x)\ln(1+x)=\sum_{n=1}^\infty\left(\frac{H_n-H_{2n}}{n}-\frac{1}{2n^2}\right)x^{2n}\tag1 \frac1{1+x^2}=\sum_{n=1}^\infty (-1)^{n-1}x^{2n-2} \left(\sum_{n=1}^\infty a_nx^n\right)\left(\sum_{n=1}^\infty b_nx^n\right)=\sum_{n=1}^\infty x^{n+1}\left(\sum_{k=1}^n a_k\ b_{n-k+1}\right) \frac{\ln(1-x)\ln(1+x)}{1+x^2}=\sum_{n=1}^\infty(-1)^nx^{2n}\color{blue}{\left(\sum_{k=1}^n(-1)^k\left(\frac{H_k-H_{2k}}{k}-\frac1{2k^2}\right)\right)}, (1)","['sequences-and-series', 'power-series', 'taylor-expansion', 'generating-functions', 'harmonic-numbers']"
49,Is it possible to give an elementary evaluation for this sum: $ \sum_{n=0}^{\infty}(x^{(2^{-n})}-1)$,Is it possible to give an elementary evaluation for this sum:, \sum_{n=0}^{\infty}(x^{(2^{-n})}-1),"I've been thinking about this sum for a little while. I came up with it based on the observation that the  product: $$\prod_{n=0}^{\infty}x^{(2^{-n})}$$ converges to $x^2$ , and if we take the natural log of this product then we get: $$\sum_{n=0}^{\infty}\ln(x^{2^{-n}})$$ which converges to $2\ln(x)$ . The sum of interest comes by using the linear approximation $ln (x) \approx x-1$ . Intuition says that since the linear approximation becomes very good as $x \rightarrow 1$ , then the sum: $$f(x) = \sum_{n=0}^{\infty}(x^{(2^{-n})}-1)$$ should also converge. This can be confirmed rigorously using the ratio test. This observation lead me to ask whether there was any way to give an elementary evaluation of this sum for any value other than one, where all there terms are clearly zero. Using Taylor expansion at one, I showed that over the open interval from 0 to 2, this is equal to the sum: $$\sum_{n=0}^{\infty}(x-1)^n \sum_{j=0}^{\infty} \prod_{i=0}^{n-1}(2^{-j}-i)$$ which though more complicated, has the advantage that the internal product and sum can be evaluated for a given value of $n$ by expanding the product, then breaking the sum into several geometric series and using the summation formula for geometric series to evaluate the individual geometric series. This altogether means that it is possible with only finitely much work to find rational estimates for $f(x)$ when $x$ is rational, which might lead to useful conjectures.","I've been thinking about this sum for a little while. I came up with it based on the observation that the  product: converges to , and if we take the natural log of this product then we get: which converges to . The sum of interest comes by using the linear approximation . Intuition says that since the linear approximation becomes very good as , then the sum: should also converge. This can be confirmed rigorously using the ratio test. This observation lead me to ask whether there was any way to give an elementary evaluation of this sum for any value other than one, where all there terms are clearly zero. Using Taylor expansion at one, I showed that over the open interval from 0 to 2, this is equal to the sum: which though more complicated, has the advantage that the internal product and sum can be evaluated for a given value of by expanding the product, then breaking the sum into several geometric series and using the summation formula for geometric series to evaluate the individual geometric series. This altogether means that it is possible with only finitely much work to find rational estimates for when is rational, which might lead to useful conjectures.","\prod_{n=0}^{\infty}x^{(2^{-n})} x^2 \sum_{n=0}^{\infty}\ln(x^{2^{-n}}) 2\ln(x) ln (x) \approx x-1 x \rightarrow 1 f(x) = \sum_{n=0}^{\infty}(x^{(2^{-n})}-1) \sum_{n=0}^{\infty}(x-1)^n \sum_{j=0}^{\infty}
\prod_{i=0}^{n-1}(2^{-j}-i) n f(x) x",['sequences-and-series']
50,"Prove that $\sum_{i=1}^\infty (a_i-b_i)^p,$ where $a_i,b_i\in\mathbb{R},$ converges for $p\ge 2.$",Prove that  where  converges for,"\sum_{i=1}^\infty (a_i-b_i)^p, a_i,b_i\in\mathbb{R}, p\ge 2.","Let $a_i,b_i\in\mathbb{R}$ . If $\displaystyle\sum_{i=1}^\infty a_i^2$ and $\displaystyle\sum_{i=1}^\infty b_i^2$ both converge, prove that $\displaystyle\sum_{i=1}^\infty (a_i-b_i)^p,$ where $a_i,b_i\in\mathbb{R},$ converges for $p\ge 2.$ Here's my work: Notice that it is sufficient to prove the result for $p=2.$ Hence for sufficiently large $i,|a_i-b_i|<1,$ and hence $|a_i-b_i|^p\le|a_i-b_i|^2.$ So $\displaystyle\sum_{i=1}^\infty(a_i-b_i)^p$ is absolutely convergent and hence convergent. $(a_i-b_i)^2 = a_i^2-2a_ib_i+b_i^2.$ Notice that $0\le (a_i-b_i)^2=2a_i^2+2b_i^2-(a_i+b_i)^2\le 2a_i^2+2b_i^2.$ Since $\displaystyle\sum_{i=1}^\infty a_i^2$ and $\displaystyle\sum_{i=1}^\infty b_i^2$ are convergent, $\displaystyle\sum_{i=1}^\infty (a_i-b_i)^2$ is convergent. $\;{\square}$","Let . If and both converge, prove that where converges for Here's my work: Notice that it is sufficient to prove the result for Hence for sufficiently large and hence So is absolutely convergent and hence convergent. Notice that Since and are convergent, is convergent.","a_i,b_i\in\mathbb{R} \displaystyle\sum_{i=1}^\infty a_i^2 \displaystyle\sum_{i=1}^\infty b_i^2 \displaystyle\sum_{i=1}^\infty (a_i-b_i)^p, a_i,b_i\in\mathbb{R}, p\ge 2. p=2. i,|a_i-b_i|<1, |a_i-b_i|^p\le|a_i-b_i|^2. \displaystyle\sum_{i=1}^\infty(a_i-b_i)^p (a_i-b_i)^2 = a_i^2-2a_ib_i+b_i^2. 0\le (a_i-b_i)^2=2a_i^2+2b_i^2-(a_i+b_i)^2\le 2a_i^2+2b_i^2. \displaystyle\sum_{i=1}^\infty a_i^2 \displaystyle\sum_{i=1}^\infty b_i^2 \displaystyle\sum_{i=1}^\infty (a_i-b_i)^2 \;{\square}",['calculus']
51,What is the sum of the reciprocal of the hypotenuse of Pythagorean triangles?,What is the sum of the reciprocal of the hypotenuse of Pythagorean triangles?,,"A primitive Pythagorean triplet is a triplet $a^2 + b^2 = c^2$ be where $a,b,c$ have no common factors and is generated by $a = x^2 - y^2, b = 2xy, c = x^2 + y^2$ where $x > y, \gcd(x,y) = 1$ . My experimental data suggests that $$ \frac{1}{5} + \frac{1}{13} + \frac{1}{17} + \frac{1}{25} + \frac{1}{29} + \frac{1}{37} + \cdots + \frac{1}{x^2 + y^2} \sim \frac{\pi}{6}\log x$$ where the summation is taken over the hypotenuse of all primitive right triangles  such that $y < x$ . Can this be proved or disproved? Related question : What is the sum of the reciprocal of the square of hypotenuse of Pythagorean triangles?",A primitive Pythagorean triplet is a triplet be where have no common factors and is generated by where . My experimental data suggests that where the summation is taken over the hypotenuse of all primitive right triangles  such that . Can this be proved or disproved? Related question : What is the sum of the reciprocal of the square of hypotenuse of Pythagorean triangles?,"a^2 + b^2 = c^2 a,b,c a = x^2 - y^2, b = 2xy, c = x^2 + y^2 x > y, \gcd(x,y) = 1  \frac{1}{5} + \frac{1}{13} + \frac{1}{17} +
\frac{1}{25} + \frac{1}{29} + \frac{1}{37} + \cdots + \frac{1}{x^2 + y^2} \sim \frac{\pi}{6}\log x y < x","['real-analysis', 'sequences-and-series', 'geometry', 'number-theory', 'summation']"
52,Necklace infinte sum,Necklace infinte sum,,"Consider the function: $$S(n)=\sum_{j=1}^{\infty}\frac{j^n}{2^j}=\frac1 2+\frac{2^n}{4}+\frac{3^n}{8}+\frac{4^n}{16}+\frac{5^n}{32}+...$$ Euler found the sum of the first few of these as: $S(0)=1$ ; (as per the usual geometric series.) $S(1)=2$ ; etc.  This creates a series of sums as follows: 1, 2, 6, 26, 150, 1082, 9366, 94586, … , which is the OEIS sequence A000629, “Number of necklaces of partitions of $n+1$ labelled beads”. My question is - what connection is there between this infinite series and necklace combinatorics?  Or is the connection accidental or illusory?","Consider the function: Euler found the sum of the first few of these as: ; (as per the usual geometric series.) ; etc.  This creates a series of sums as follows: 1, 2, 6, 26, 150, 1082, 9366, 94586, … , which is the OEIS sequence A000629, “Number of necklaces of partitions of labelled beads”. My question is - what connection is there between this infinite series and necklace combinatorics?  Or is the connection accidental or illusory?",S(n)=\sum_{j=1}^{\infty}\frac{j^n}{2^j}=\frac1 2+\frac{2^n}{4}+\frac{3^n}{8}+\frac{4^n}{16}+\frac{5^n}{32}+... S(0)=1 S(1)=2 n+1,"['sequences-and-series', 'necklace-and-bracelets']"
53,Evaluate the sum : $\frac{1}{1+x_{1}}+\frac{1}{1+x_{2}}+\frac{1}{1+x_{3}}+...+\frac{1}{1+x_{n}}$,Evaluate the sum :,\frac{1}{1+x_{1}}+\frac{1}{1+x_{2}}+\frac{1}{1+x_{3}}+...+\frac{1}{1+x_{n}},"Question : Let the real  number $x≥1$ : $x_{1}=x$ and $x_{n+1}=x_{n}(1+x_{n})$ for $n=1,2,3...$ Then find the sum : $S=\displaystyle \sum_{k=1}^{n}\frac{1}{1+x_{k}}$ My try : Note that : $\frac{1}{1+x_{1}}=\frac{1}{x_{1}}-\frac{1}{x_{2}}$ Also : $\frac{1}{1+x_{k}}=\frac{1}{x_{k}}-\frac{1}{x_{k+1}}$ So if we take sum rights-left  we get : $S=\frac{1}{x_{1}}-\frac{1}{x_{k+1}}$ I need see other method ? And it's possible to find the term of $x_{n}$ ?",Question : Let the real  number : and for Then find the sum : My try : Note that : Also : So if we take sum rights-left  we get : I need see other method ? And it's possible to find the term of ?,"x≥1 x_{1}=x x_{n+1}=x_{n}(1+x_{n}) n=1,2,3... S=\displaystyle \sum_{k=1}^{n}\frac{1}{1+x_{k}} \frac{1}{1+x_{1}}=\frac{1}{x_{1}}-\frac{1}{x_{2}} \frac{1}{1+x_{k}}=\frac{1}{x_{k}}-\frac{1}{x_{k+1}} S=\frac{1}{x_{1}}-\frac{1}{x_{k+1}} x_{n}","['calculus', 'sequences-and-series', 'summation']"
54,Can the result of $\sum\limits_{n=1}^{\infty}\dfrac{1}{3^n-2^n}$ be expressed as a closed form?,Can the result of  be expressed as a closed form?,\sum\limits_{n=1}^{\infty}\dfrac{1}{3^n-2^n},"Notice that, for any $a>b>0$ and $n=1,2,\cdots$ , it holds that \begin{align*} a^n-b^n&=(a-b)(a^{n-1}+a^{n-2}b+\cdots+ab^{n-2}+b^{n-1})\\ &\geq (a-b)(b^{n-1}+b^{n-2}b+\cdots+bb^{n-2}+b^{n-1})\\ &=n(a-b)b^{n-1}\\ &\geq(a-b)b^{n-1}. \end{align*} Thus $$\frac{1}{3^n-2^n}\leq\frac{1}{2^{n-1}}.$$ Since $\sum\limits_{n=1}^{\infty}\dfrac{1}{2^{n-1}}$ is convergent,by the comparison test, $\sum\limits_{n=1}^{\infty}\dfrac{1}{3^n-2^n}$ is also convergent. But where does it converge to? WA gives a numerical approximation: $$\sum_{n=1}^{\infty}\frac{1}{3^n-2^n}\approx 1.27498.$$ I wonder whether it can be a closed form or not.","Notice that, for any and , it holds that Thus Since is convergent,by the comparison test, is also convergent. But where does it converge to? WA gives a numerical approximation: I wonder whether it can be a closed form or not.","a>b>0 n=1,2,\cdots \begin{align*}
a^n-b^n&=(a-b)(a^{n-1}+a^{n-2}b+\cdots+ab^{n-2}+b^{n-1})\\
&\geq (a-b)(b^{n-1}+b^{n-2}b+\cdots+bb^{n-2}+b^{n-1})\\
&=n(a-b)b^{n-1}\\
&\geq(a-b)b^{n-1}.
\end{align*} \frac{1}{3^n-2^n}\leq\frac{1}{2^{n-1}}. \sum\limits_{n=1}^{\infty}\dfrac{1}{2^{n-1}} \sum\limits_{n=1}^{\infty}\dfrac{1}{3^n-2^n} \sum_{n=1}^{\infty}\frac{1}{3^n-2^n}\approx 1.27498.",['sequences-and-series']
55,Proof that $(1+\frac{1}{n})^n$ can't converge to a rational number,Proof that  can't converge to a rational number,(1+\frac{1}{n})^n,"One of my colleagues challenged me (and his students) with the following: ""Assume you don't know that $\lim_{n\to +\infty}(1+\frac{1}{n})^n=e$ . Prove the sequence $u_n=(1+\frac{1}{n})^n$ converges to a real non rational value."" I know how to do part of this. Actually, the proof of $u_n$ convergence is quite familiar (using the monotonic and bounded real sequences theorem). However, I can't prove the non rationality of the limit. Considering that $\lim_{n\to +\infty}(1+\frac{1}{n})^n=\ell$ , I tried to assume that $\ell$ can be written by $\frac{p}{q}, p,q\in \mathbb N$ with $p$ and $q$ being co-prime, but I reached a point I can't proceed. Here's my calculations: Let $u_n:\mathbb N\to \mathbb R, n\mapsto (1+\frac{1}{n})^n$ . STEP 1: Prove $u_n$ is monotonic If $u_n=(1+\frac{1}{n})^n$ then $u_{n+1}=(1+\frac{1}{n-1})^{n+1}$ . So $\frac{u_{n+1}}{u_n}=\frac{\left(1+\frac{1}{n+1}\right)^{n+1}}{\left(1+\frac{1}{n}\right)^n}=\left(1-\frac{1}{(n+1)^2}\right)^n\left(1+\frac{1}{n+1}\right)$ . By Bernoulli's inequality, as $-\frac{1}{(n+1)^2}>-1$ , $\left(1-\frac{1}{(n+1)^2}\right)^n\geq 1-\frac{n}{(n+1)^2}$ . So $\left(1-\frac{1}{(n+1)^2}\right)^n\left(1+\frac{1}{n+1}\right)\geq \left(1-\frac{n}{(n+1)^2}\right) \left(1+\frac{1}{n+1}\right)=1+\frac{1}{(n+1)^3}$ . As $1+\frac{1}{(n+1)^3}>1$ , $\frac{u_{n+1}}{u_n}>1$ , so $u_n$ is monotonically increasing. QED STEP 2: Prove $u_n$ is bounded As $u_n$ is monotonically increasing, by Step 1, $u_1=2$ is a lower bound for the set of $u_n$ terms. On the other side, as $n(n-1)...(n-k+1)\leq n^3$ and $\frac{1}{k\,!}\leq \frac{1}{2^{k-1}}$ , for all $k\in \mathbb N$ , then as $u_n = \sum_{k=0}^n \frac{\binom{n}{k}}{n^k}=1+\sum_{k=1}^n \frac{n(n-1)...(n-k+1)}{k\,!\,n^k}$ , $u_n\leq 1+\sum_{k=1}^n \frac{1}{2^{k-1}}=3-(\frac{1}{2})^{n-1}<3$ . So $3$ is an upper bound for the set of $u_n$ terms. Once bounded from below and bounded from above, the sequence $u_n$ is bounded. QED STEP 3: Prove $u_n$ is convergent Once monotonic (Step 1) and bounded (Step 2), by the monotonic and bounded real sequences theorem, the sequence $u_n$ is convergent, i.e. $\exists\,\ell\in\mathbb R:\lim_{n\to +\infty}(1+\frac{1}{n})^n=\ell$ . By Step 1 and Step 2, we also conclude that $2<\ell<3$ . QED STEP 4: Prove $\ell$ can't be rational As we saw in Step 2, $u_n =\sum_{k=0}^n \frac{n(n-1)...(n-k+1)}{k\,!\,n^k}$ . Then $\ell=\lim_{n\to +\infty}\sum_{k=0}^n \frac{n(n-1)...(n-k+1)}{k\,!\,n^k}$ . As $\lim_{n\to +\infty}\sum_{k=0}^n \frac{n(n-1)...(n-k+1)}{n^k}=1$ , then $\ell=\sum_{n=0}^\infty \frac{1}{n\,!}$ (*). Let's now suppose $\sum_{n=0}^\infty \frac{1}{n\,!}$ can be written by $\frac{p}{q}, p,q\in \mathbb N$ with $p$ and $q$ being co-prime... (and I can't proceed from here). (*) Please note that I obviously know that $e=\sum_{n=0}^\infty \frac{1}{n\,!}$ . However, the challenge asks to assume we don't know that $\lim_{n\to +\infty}(1+\frac{1}{n})^n=e$ . Also, I just wrote all the steps, because it could be useful to complete the proof. I did some research and one suggestion I saw somewhere is to assume, for some $x\in\mathbb R$ , let $x=q\,!\left(\frac{p}{q}-\sum_{n=0}^q \frac{1}{n\,!}\right)$ . Then $x=p(q-1)\,!-\sum_{n=0}^q q(q-1)...(q-n+1)$ . What's the next step? Is this the right approach? Thanks","One of my colleagues challenged me (and his students) with the following: ""Assume you don't know that . Prove the sequence converges to a real non rational value."" I know how to do part of this. Actually, the proof of convergence is quite familiar (using the monotonic and bounded real sequences theorem). However, I can't prove the non rationality of the limit. Considering that , I tried to assume that can be written by with and being co-prime, but I reached a point I can't proceed. Here's my calculations: Let . STEP 1: Prove is monotonic If then . So . By Bernoulli's inequality, as , . So . As , , so is monotonically increasing. QED STEP 2: Prove is bounded As is monotonically increasing, by Step 1, is a lower bound for the set of terms. On the other side, as and , for all , then as , . So is an upper bound for the set of terms. Once bounded from below and bounded from above, the sequence is bounded. QED STEP 3: Prove is convergent Once monotonic (Step 1) and bounded (Step 2), by the monotonic and bounded real sequences theorem, the sequence is convergent, i.e. . By Step 1 and Step 2, we also conclude that . QED STEP 4: Prove can't be rational As we saw in Step 2, . Then . As , then (*). Let's now suppose can be written by with and being co-prime... (and I can't proceed from here). (*) Please note that I obviously know that . However, the challenge asks to assume we don't know that . Also, I just wrote all the steps, because it could be useful to complete the proof. I did some research and one suggestion I saw somewhere is to assume, for some , let . Then . What's the next step? Is this the right approach? Thanks","\lim_{n\to +\infty}(1+\frac{1}{n})^n=e u_n=(1+\frac{1}{n})^n u_n \lim_{n\to +\infty}(1+\frac{1}{n})^n=\ell \ell \frac{p}{q}, p,q\in \mathbb N p q u_n:\mathbb N\to \mathbb R, n\mapsto (1+\frac{1}{n})^n u_n u_n=(1+\frac{1}{n})^n u_{n+1}=(1+\frac{1}{n-1})^{n+1} \frac{u_{n+1}}{u_n}=\frac{\left(1+\frac{1}{n+1}\right)^{n+1}}{\left(1+\frac{1}{n}\right)^n}=\left(1-\frac{1}{(n+1)^2}\right)^n\left(1+\frac{1}{n+1}\right) -\frac{1}{(n+1)^2}>-1 \left(1-\frac{1}{(n+1)^2}\right)^n\geq 1-\frac{n}{(n+1)^2} \left(1-\frac{1}{(n+1)^2}\right)^n\left(1+\frac{1}{n+1}\right)\geq \left(1-\frac{n}{(n+1)^2}\right) \left(1+\frac{1}{n+1}\right)=1+\frac{1}{(n+1)^3} 1+\frac{1}{(n+1)^3}>1 \frac{u_{n+1}}{u_n}>1 u_n u_n u_n u_1=2 u_n n(n-1)...(n-k+1)\leq n^3 \frac{1}{k\,!}\leq \frac{1}{2^{k-1}} k\in \mathbb N u_n = \sum_{k=0}^n \frac{\binom{n}{k}}{n^k}=1+\sum_{k=1}^n \frac{n(n-1)...(n-k+1)}{k\,!\,n^k} u_n\leq 1+\sum_{k=1}^n \frac{1}{2^{k-1}}=3-(\frac{1}{2})^{n-1}<3 3 u_n u_n u_n u_n \exists\,\ell\in\mathbb R:\lim_{n\to +\infty}(1+\frac{1}{n})^n=\ell 2<\ell<3 \ell u_n =\sum_{k=0}^n \frac{n(n-1)...(n-k+1)}{k\,!\,n^k} \ell=\lim_{n\to +\infty}\sum_{k=0}^n \frac{n(n-1)...(n-k+1)}{k\,!\,n^k} \lim_{n\to +\infty}\sum_{k=0}^n \frac{n(n-1)...(n-k+1)}{n^k}=1 \ell=\sum_{n=0}^\infty \frac{1}{n\,!} \sum_{n=0}^\infty \frac{1}{n\,!} \frac{p}{q}, p,q\in \mathbb N p q e=\sum_{n=0}^\infty \frac{1}{n\,!} \lim_{n\to +\infty}(1+\frac{1}{n})^n=e x\in\mathbb R x=q\,!\left(\frac{p}{q}-\sum_{n=0}^q \frac{1}{n\,!}\right) x=p(q-1)\,!-\sum_{n=0}^q q(q-1)...(q-n+1)","['sequences-and-series', 'convergence-divergence', 'rational-numbers']"
56,Find $ \lim _{n\to \infty} \frac{n^1+\dots+n^n}{1^n+\dots+n^n}$,Find, \lim _{n\to \infty} \frac{n^1+\dots+n^n}{1^n+\dots+n^n},"What is the limit of: $$\lim_{n\to \infty} \frac{n^1+\dots+n^n}{1^n+\dots+n^n} = ?$$ I did some computation with big numbers, I guess it is in the interval $\left(\frac{1}{2},1\right)$.","What is the limit of: $$\lim_{n\to \infty} \frac{n^1+\dots+n^n}{1^n+\dots+n^n} = ?$$ I did some computation with big numbers, I guess it is in the interval $\left(\frac{1}{2},1\right)$.",,['real-analysis']
57,How do I evaluate the antiderivative of $e^{cos(x)}$?,How do I evaluate the antiderivative of ?,e^{cos(x)},"Functions that do not have an elementary antiderivative can be evaluated by generating a Taylor series, provided the function is infinitely differentiable and uniformly convergent in its domain. However, some functions do not have a simple general form for its Taylor series. For example, take the following integral: $$ \int e^{cos(x)} dx $$ As the integral has no elementary antiderivative, we need to use a Taylor series to evaluate it. The Maclaurin series for $ cos(x) $ is: $$ cos(x) = \sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!} $$ Since $ cos(0) = 1 $ , we need to use the Taylor series of $ e^{x} $ centered at $ a = 1 $ . $$ e^{x} = \sum_{n=0}^{\infty} \frac {e (x-1)^{n}} {n!} $$ Utilizing the property of substation in Taylor series, we can generate one for $ e^{cos(x)} $ : $$ e^{cos(x)} = \sum_{n=0}^{\infty} \frac {e (cos(x)-1)^{n}} {n!} $$ Thus, the Taylor series of $ e^{cos(x)} $ is: $$ e^{cos(x)} = \sum_{n=0}^{\infty} \frac {e ((\sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!})-1)^{n}} {n!} $$ Clearly, this Taylor series is complex, with a series nested within in a series. I am confused as to how to compute the following integral: $$ \int e^{cos(x)} dx = \int \sum_{n=0}^{\infty} \frac {e ((\sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!})-1)^{n}} {n!} dx $$ The series can be simplified as such: $$ \int e^{cos(x)} dx = \int \sum_{n=0}^{\infty} \frac {e} {n!} ((\sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!})-1)^{n} dx $$ $$ \int e^{cos(x)} dx = \sum_{n=0}^{\infty} \frac {e} {n!} \int (- \frac{x^{2}}{2!} + \frac{x^{4}}{4!} - \frac{x^{6}}{6!} + \: ...)^{n} dx $$ Although a Taylor series can be integrated term-by-term, how does one integrate an infinite sum raised to a power? Is there a different approach to take, such as finding a general Maclaurin series for the function $ e^{cos(x)} $ by taking the derivatives and deciphering the pattern? EDIT:  I decided to approach the antiderivative in a different way.  Since the Maclaurin series for $ e^{x} $ is: $$ e^{x} = \sum_{n=0}^{\infty} \frac {x^{n}} {n!} $$ The series for $ e^{cos(x)} $ can be expressed as: $$ e^{cos(x)} = \sum_{n=0}^{\infty} \frac {(cos(x))^{n}} {n!} $$ $$ e^{cos(x)} = \sum_{n=0}^{\infty} \frac {{cos}^{n}(x)} {n!} $$ Thus the antiderivative of $ e^{cos(x)} $ can be evaluated: $$ \int e^{cos(x)} dx = \sum_{n=0}^{\infty} \frac {1} {n!} \int {cos}^{n}(x) $$ We can apply the reduction formula for $ \int {cos}^{n}(x) dx $ : $$ \int e^{cos(x)} dx = \sum_{n=0}^{\infty} (\frac {1} {n!}) (\frac {1} {n} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n} \int {cos}^{n-2}(x) dx) $$ Hence, the antiderivative of $ e^{cos(x)} $ is as follows: $$ \int e^{cos(x)} dx = \sum_{n=0}^{\infty} \frac {1} {n \cdot n!} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n \cdot n!} \int {cos}^{n-2}(x) dx $$ The reduction formula is not valid for the initial term, so it must be evaluated separately. $$ \int e^{cos(x)} dx = \int {cos}^{0}(x) dx + \sum_{n=1}^{\infty} \frac {1} {n \cdot n!} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n \cdot n!} \int {cos}^{n-2}(x) dx $$ $$ \int e^{cos(x)} dx = c + x + \sum_{n=1}^{\infty} \frac {1} {n \cdot n!} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n \cdot n!} \int {cos}^{n-2}(x) dx $$ I still have run into a roadblock though. My answer is not a Taylor series, as it is written as a summation of a string of trigonometric terms. Thus, I do not know how to determine the interval of convergence. If I evaluate the first few derivatives of $ e^{cos(x)} $ at the center point $ a=0 $ , I can generate the following Maclaurin series: $$ e^{cos(x)} = e- \frac {e} {2} x^2 + \frac {e} {6} x^4 - \frac {31e} {720} x^6 + \ldots \: $$ Thus, the antiderivative of $ e^{cos(x)} $ can be expressed as an infinite sum: $$ \int e^{cos(x)} dx = c + ex - \frac {e} {6} x^3 + \frac {e} {30} x^5 - \frac {31e} {5040} x^7 + \ldots \: $$ Is there a general pattern to the following Maclaurin series? If so, can a convergence test be applied to determine the interval of convergence? If there series is not convergent across all real numbers, the Taylor series is not valid. When this is the case, are there other methods to evaluate antiderivatives that do not require generating a Taylor series?","Functions that do not have an elementary antiderivative can be evaluated by generating a Taylor series, provided the function is infinitely differentiable and uniformly convergent in its domain. However, some functions do not have a simple general form for its Taylor series. For example, take the following integral: As the integral has no elementary antiderivative, we need to use a Taylor series to evaluate it. The Maclaurin series for is: Since , we need to use the Taylor series of centered at . Utilizing the property of substation in Taylor series, we can generate one for : Thus, the Taylor series of is: Clearly, this Taylor series is complex, with a series nested within in a series. I am confused as to how to compute the following integral: The series can be simplified as such: Although a Taylor series can be integrated term-by-term, how does one integrate an infinite sum raised to a power? Is there a different approach to take, such as finding a general Maclaurin series for the function by taking the derivatives and deciphering the pattern? EDIT:  I decided to approach the antiderivative in a different way.  Since the Maclaurin series for is: The series for can be expressed as: Thus the antiderivative of can be evaluated: We can apply the reduction formula for : Hence, the antiderivative of is as follows: The reduction formula is not valid for the initial term, so it must be evaluated separately. I still have run into a roadblock though. My answer is not a Taylor series, as it is written as a summation of a string of trigonometric terms. Thus, I do not know how to determine the interval of convergence. If I evaluate the first few derivatives of at the center point , I can generate the following Maclaurin series: Thus, the antiderivative of can be expressed as an infinite sum: Is there a general pattern to the following Maclaurin series? If so, can a convergence test be applied to determine the interval of convergence? If there series is not convergent across all real numbers, the Taylor series is not valid. When this is the case, are there other methods to evaluate antiderivatives that do not require generating a Taylor series?", \int e^{cos(x)} dx   cos(x)   cos(x) = \sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!}   cos(0) = 1   e^{x}   a = 1   e^{x} = \sum_{n=0}^{\infty} \frac {e (x-1)^{n}} {n!}   e^{cos(x)}   e^{cos(x)} = \sum_{n=0}^{\infty} \frac {e (cos(x)-1)^{n}} {n!}   e^{cos(x)}   e^{cos(x)} = \sum_{n=0}^{\infty} \frac {e ((\sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!})-1)^{n}} {n!}   \int e^{cos(x)} dx = \int \sum_{n=0}^{\infty} \frac {e ((\sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!})-1)^{n}} {n!} dx   \int e^{cos(x)} dx = \int \sum_{n=0}^{\infty} \frac {e} {n!} ((\sum_{n=0}^{\infty} \frac {(-1)^n x^{2n}} {(2n)!})-1)^{n} dx   \int e^{cos(x)} dx = \sum_{n=0}^{\infty} \frac {e} {n!} \int (- \frac{x^{2}}{2!} + \frac{x^{4}}{4!} - \frac{x^{6}}{6!} + \: ...)^{n} dx   e^{cos(x)}   e^{x}   e^{x} = \sum_{n=0}^{\infty} \frac {x^{n}} {n!}   e^{cos(x)}   e^{cos(x)} = \sum_{n=0}^{\infty} \frac {(cos(x))^{n}} {n!}   e^{cos(x)} = \sum_{n=0}^{\infty} \frac {{cos}^{n}(x)} {n!}   e^{cos(x)}   \int e^{cos(x)} dx = \sum_{n=0}^{\infty} \frac {1} {n!} \int {cos}^{n}(x)   \int {cos}^{n}(x) dx   \int e^{cos(x)} dx = \sum_{n=0}^{\infty} (\frac {1} {n!}) (\frac {1} {n} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n} \int {cos}^{n-2}(x) dx)   e^{cos(x)}   \int e^{cos(x)} dx = \sum_{n=0}^{\infty} \frac {1} {n \cdot n!} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n \cdot n!} \int {cos}^{n-2}(x) dx   \int e^{cos(x)} dx = \int {cos}^{0}(x) dx + \sum_{n=1}^{\infty} \frac {1} {n \cdot n!} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n \cdot n!} \int {cos}^{n-2}(x) dx   \int e^{cos(x)} dx = c + x + \sum_{n=1}^{\infty} \frac {1} {n \cdot n!} {cos}^{n-1}(x) sin(x) + \frac {n-1} {n \cdot n!} \int {cos}^{n-2}(x) dx   e^{cos(x)}   a=0   e^{cos(x)} = e- \frac {e} {2} x^2 + \frac {e} {6} x^4 - \frac {31e} {720} x^6 + \ldots \:   e^{cos(x)}   \int e^{cos(x)} dx = c + ex - \frac {e} {6} x^3 + \frac {e} {30} x^5 - \frac {31e} {5040} x^7 + \ldots \: ,"['sequences-and-series', 'taylor-expansion', 'indefinite-integrals', 'special-functions']"
58,Weighted mean of a function with binomial coefficients as weights,Weighted mean of a function with binomial coefficients as weights,,"Is the following true? Let $a$ be a positive integer and let $t_n$ be a sequence of numbers. We define the binomial mean of $t_n$ $$ \beta_{t_n,a} =  \frac{1}{2^n t_n}\sum_{r^a \le n} \binom{n}{r^a}t_r $$ Claim : If the binomial mean $\beta_{t_n,a}$ approaches a finite positive constant and $f$ is continious on the interval $[0,1]$ then, $$ \frac{1}{2^n}\sum_{r^a \le n} \binom{n}{r^a}f\Big(\frac{t_r}{t_n}\Big)  \sim f(\beta_{t_n,a}) $$ Note : The case $a = 1, t_n = n$ is true and is a special case of the approximation of $f$ using Bernstein polynomials as mentioned in the answer to the related question Binomial analogue of Riemann sum for definite integral Example : Let $a = 2, t_n = p_n$ be the $n$ -th prime and $f(x) = \log(x)$ for $n = 10^6$ , LHS = $-0.7426766$ , RHS = $-0.7426760$ , and the error is $< 5.65 \times 10^{-7}$","Is the following true? Let be a positive integer and let be a sequence of numbers. We define the binomial mean of Claim : If the binomial mean approaches a finite positive constant and is continious on the interval then, Note : The case is true and is a special case of the approximation of using Bernstein polynomials as mentioned in the answer to the related question Binomial analogue of Riemann sum for definite integral Example : Let be the -th prime and for , LHS = , RHS = , and the error is","a t_n t_n 
\beta_{t_n,a} =  \frac{1}{2^n t_n}\sum_{r^a \le n} \binom{n}{r^a}t_r
 \beta_{t_n,a} f [0,1] 
\frac{1}{2^n}\sum_{r^a \le n} \binom{n}{r^a}f\Big(\frac{t_r}{t_n}\Big) 
\sim f(\beta_{t_n,a})  a = 1, t_n = n f a = 2, t_n = p_n n f(x) = \log(x) n = 10^6 -0.7426766 -0.7426760 < 5.65 \times 10^{-7}","['real-analysis', 'sequences-and-series', 'number-theory', 'limits', 'binomial-coefficients']"
59,Evaluating series $\sum_{n=2}^\infty \left(n^{1/n}-1-\frac{\log n}{n} \right)$,Evaluating series,\sum_{n=2}^\infty \left(n^{1/n}-1-\frac{\log n}{n} \right),"This is similar to my recent question, but probably more interesting. What can we say about this slowly converging series: $$S=\sum_{n=2}^\infty \left(n^{1/n}-1-\frac{\log n}{n} \right)$$ We can rewrite it as a double sum: $$S=\sum_{n=2}^\infty \sum_{k=2}^\infty \frac{\log^k n}{k!~n^k}$$ Or express through zeta derivatives at integer points: $$S=\sum_{k=2}^\infty \frac{| \zeta^{(k)}(k) |}{k!}$$ Using the integral expression for zeta derivatives I obtained yesterday* and exchanging integration and summation, we can claim: $$S=\sum_{k=2}^\infty \frac{1}{(k-1)^{k+1}}+$$ $$+ \frac{1}{i} \int_0^{\infty } \frac{dt}{\exp (2 \pi  t)-1} \left((1-i t)^{\frac{1}{1-i t}}-(1+i t)^{\frac{1}{1+i t}}-\frac{\log (1-i t)}{1-i t}+\frac{\log (1+i t)}{1+i t}  \right)$$ This gives us the following numerical value: $$S=1.0613654466259454755053404842148725835597350221360 \ldots$$ Directly evaluating the series in Mathematica is hard, but it gives an approximately the same value $1.06136544662594547550535127514661 \ldots$ . Questions: Is my numerical value correct? What other methods can we use to check? Euler-Maclaurin doesn't seem to work well, mostly because the integral is not nice eihter. (The original version of this question contained a mistake, the corrected integral expression gives the same value as numerical summation for the first several digits, but I would still like to know more correct digits). Is there a way to obtain a nicer integral expression for the series? $*$ $$\zeta^{(n)}(s)=\frac{(-1)^n n!}{(s-1)^{n+1}}- \\ +\frac{1}{i} \int_0^{\infty } \frac{dt}{e^{2 \pi  t}-1} \left(\frac{(1+i t)^s}{\left(1+t^2\right)^s} \log ^n\left(\frac{1+i t}{1+t^2}\right)-\frac{(1-i t)^s }{\left(1+t^2\right)^s}\log ^n\left(\frac{1-i t}{1+t^2}\right) \right)$$","This is similar to my recent question, but probably more interesting. What can we say about this slowly converging series: We can rewrite it as a double sum: Or express through zeta derivatives at integer points: Using the integral expression for zeta derivatives I obtained yesterday* and exchanging integration and summation, we can claim: This gives us the following numerical value: Directly evaluating the series in Mathematica is hard, but it gives an approximately the same value . Questions: Is my numerical value correct? What other methods can we use to check? Euler-Maclaurin doesn't seem to work well, mostly because the integral is not nice eihter. (The original version of this question contained a mistake, the corrected integral expression gives the same value as numerical summation for the first several digits, but I would still like to know more correct digits). Is there a way to obtain a nicer integral expression for the series?",S=\sum_{n=2}^\infty \left(n^{1/n}-1-\frac{\log n}{n} \right) S=\sum_{n=2}^\infty \sum_{k=2}^\infty \frac{\log^k n}{k!~n^k} S=\sum_{k=2}^\infty \frac{| \zeta^{(k)}(k) |}{k!} S=\sum_{k=2}^\infty \frac{1}{(k-1)^{k+1}}+ + \frac{1}{i} \int_0^{\infty } \frac{dt}{\exp (2 \pi  t)-1} \left((1-i t)^{\frac{1}{1-i t}}-(1+i t)^{\frac{1}{1+i t}}-\frac{\log (1-i t)}{1-i t}+\frac{\log (1+i t)}{1+i t}  \right) S=1.0613654466259454755053404842148725835597350221360 \ldots 1.06136544662594547550535127514661 \ldots * \zeta^{(n)}(s)=\frac{(-1)^n n!}{(s-1)^{n+1}}- \\ +\frac{1}{i} \int_0^{\infty } \frac{dt}{e^{2 \pi  t}-1} \left(\frac{(1+i t)^s}{\left(1+t^2\right)^s} \log ^n\left(\frac{1+i t}{1+t^2}\right)-\frac{(1-i t)^s }{\left(1+t^2\right)^s}\log ^n\left(\frac{1-i t}{1+t^2}\right) \right),"['sequences-and-series', 'numerical-methods', 'riemann-zeta']"
60,Are there visual proofs for the sums of reciprocals of square and triangular numbers?,Are there visual proofs for the sums of reciprocals of square and triangular numbers?,,This is a visual proof for the sum of the reciprocals of powers of 2 - Are there a similar proofs for reciprocals of square and triangular numbers? I couldn't find any. I don't know if I used the right terms; maybe it's: infinite series sum. So correct this question if it's wrong.,This is a visual proof for the sum of the reciprocals of powers of 2 - Are there a similar proofs for reciprocals of square and triangular numbers? I couldn't find any. I don't know if I used the right terms; maybe it's: infinite series sum. So correct this question if it's wrong.,,['sequences-and-series']
61,Sequence of positive integers $n$ such that $n^2+n+1$ divides $4^n+2^n+1$ and $n$ is not power two,Sequence of positive integers  such that  divides  and  is not power two,n n^2+n+1 4^n+2^n+1 n,"If positive integer $n$ is not power two and $n^2+n+1 \mid 4^n+2^n+1$ , then what sequence of $n$ ? Source problem from Prove that there are infinitely many integers $n>0$ such that $n^2+n+1$ divides $4^n+2^n+1$ . We have two first term of sequence: 215,3692374808 . Let $m=n^2+n+1$ . For both first terms $m$ is prime. Question 1: can be $m$ is not prime for next terms? Suppose 1: $m$ is prime $\overset{FLT}{\implies} 2^{n(n+1)}\equiv 1 \pmod{m} \implies 2^{3n}\equiv 1 \pmod{m}$ . Question 2: how prove if $m$ is prime then $n\equiv2\pmod{3}$ ? Note: from post Modular arithmetic with Legendre symbol implies $n\not\equiv1\pmod3$ . Suppose 2: $n\equiv2\pmod{3} \implies 2^{\frac{n(n+1)}{3}}\equiv3^{\frac{n(n+1)}{3}}\equiv n^x\pmod{m}$ , where some integer $x\ge0$ . Question 3: what other conditions for $n$ we can seen for speedup find next terms?","If positive integer is not power two and , then what sequence of ? Source problem from Prove that there are infinitely many integers such that divides . We have two first term of sequence: 215,3692374808 . Let . For both first terms is prime. Question 1: can be is not prime for next terms? Suppose 1: is prime . Question 2: how prove if is prime then ? Note: from post Modular arithmetic with Legendre symbol implies . Suppose 2: , where some integer . Question 3: what other conditions for we can seen for speedup find next terms?",n n^2+n+1 \mid 4^n+2^n+1 n n>0 n^2+n+1 4^n+2^n+1 m=n^2+n+1 m m m \overset{FLT}{\implies} 2^{n(n+1)}\equiv 1 \pmod{m} \implies 2^{3n}\equiv 1 \pmod{m} m n\equiv2\pmod{3} n\not\equiv1\pmod3 n\equiv2\pmod{3} \implies 2^{\frac{n(n+1)}{3}}\equiv3^{\frac{n(n+1)}{3}}\equiv n^x\pmod{m} x\ge0 n,"['sequences-and-series', 'number-theory', 'modular-arithmetic']"
62,"How to evaluate $\sum\limits_{n=0}^\infty\frac{1}{x^n+y^n}$ for $x,y>1$?",How to evaluate  for ?,"\sum\limits_{n=0}^\infty\frac{1}{x^n+y^n} x,y>1","Is there an analytical expression for $\sum\limits_{n=0}^\infty\frac{1}{x^n+y^n}$ when $x,y>1$ ? If so, how do you solve it?","Is there an analytical expression for when ? If so, how do you solve it?","\sum\limits_{n=0}^\infty\frac{1}{x^n+y^n} x,y>1","['sequences-and-series', 'convergence-divergence', 'taylor-expansion']"
63,Convex Combination Generalized to Infinite Sums,Convex Combination Generalized to Infinite Sums,,"I'm independently studying Boyd & Vandenberghe's Convex Optimization and came across the following statement discussing convex combinations of infinite terms. The idea of a convex combination can be generalized to include   infinite sums, integrals, and, in the most general form, probability   distributions. Suppose $\theta_1, \theta_2, \dots$ satisfy $$\begin{align} \theta_i &\geq 0 \\ i &= 1, 2, \dots \\ \sum_{i=1}^{\infty} \theta_i &= 1 \end{align}$$ and $x_1, x_2, \dots \in C$ , where $C \subseteq \mathbb{R}^n$ is convex. Then $$\sum_{i=1}^{\infty} \theta_i x_i \in C$$ if the series converges. My first question is $\dots$ what mathematical concept or proof enables us to generalize the definition of convex combination from a finite $k$ to $k = \infty$ ? Previously in the book, the definition of convex combination was simply introduced as A point of the form $\theta_1 x_1 + \dots + \theta_k x_k$ , where $\theta_1 + \dots + \theta_k = 1$ and $\theta_i \geq 0$ , $i = 1, \dots, k$ is a convex combination of the points $x_1, \dots, x_k$ . My second question is $\dots$ why is it necessary that the series converge? Shouldn't the fact that $C$ is convex guarantee that the infinite sum $\sum_{i=1}^{\infty} \theta_i x_i \in C$ since $C$ is a convex set and convex sets are closed under convex combination? Thank you for taking the time to read this lengthy question!","I'm independently studying Boyd & Vandenberghe's Convex Optimization and came across the following statement discussing convex combinations of infinite terms. The idea of a convex combination can be generalized to include   infinite sums, integrals, and, in the most general form, probability   distributions. Suppose satisfy and , where is convex. Then if the series converges. My first question is what mathematical concept or proof enables us to generalize the definition of convex combination from a finite to ? Previously in the book, the definition of convex combination was simply introduced as A point of the form , where and , is a convex combination of the points . My second question is why is it necessary that the series converge? Shouldn't the fact that is convex guarantee that the infinite sum since is a convex set and convex sets are closed under convex combination? Thank you for taking the time to read this lengthy question!","\theta_1, \theta_2, \dots \begin{align} \theta_i &\geq 0 \\ i &= 1, 2, \dots \\
\sum_{i=1}^{\infty} \theta_i &= 1 \end{align} x_1, x_2, \dots \in C C \subseteq \mathbb{R}^n \sum_{i=1}^{\infty} \theta_i x_i \in C \dots k k = \infty \theta_1 x_1 + \dots + \theta_k x_k \theta_1 + \dots + \theta_k = 1 \theta_i \geq 0 i = 1, \dots, k x_1, \dots, x_k \dots C \sum_{i=1}^{\infty} \theta_i x_i \in C C","['sequences-and-series', 'convex-analysis', 'convex-optimization']"
64,Every nonempty closed subset $M\subset \mathbb C$ is the spectrum of a closed operator,Every nonempty closed subset  is the spectrum of a closed operator,M\subset \mathbb C,"Several questions on this cite concern themselves with the operator $T:\ell^2(\mathbb N)\to\ell^2(\mathbb N)$ where $T(x_n)_{n=1}^\infty=(r_nx_n)_{n=1}^\infty$ . Here the sequence $\{r_n:n\in\mathbb N\}\subset M\subset\mathbb C$ is dense in the closed and bounded set $M$ . These questions concern themselves with the continuous nature of the operator $T$ as well as the fact that $\sigma(T)=M$ . Some of these questions include the following: Show that $A:\ell^2(\mathbb N)\to\ell^2(\mathbb N)$ where $A(e_n)=\lambda_ne_n$ is bounded. Prove $\forall$ compact $M:\ M \subset C\quad \exists A:l_2\rightarrow l_2, \sigma(A)=M$ Operator whose spectrum is given compact set One will note that rather than having $T(x_n)_{n=1}^\infty=(r_nx_n)_{n=1}^\infty$ , we could also have our operator defined by $T(e_n)_{n=1}^\infty=(r_ne_n)_{n=1}^\infty$ , where $\{e_n\}_{n=1}^\infty$ is the usual basis for $\ell^2(\mathbb N)$ . I am interested in this example for the case when $T:\mathcal D(T)\subseteq \ell^2(\mathbb N)\to\ell^2(\mathbb N)$ is potentially unbounded but at least closed . The following is an excerpt from Unbounded Self-adjoint Operators on Hilbert Space by Konrad Schmüdgen. The example contained within the excerpt details that an arbitrary nonempty closed subset $M\subset\mathbb C$ is the spectrum for some closed operator. In trying to tackle the closed analogue to the hitherto often discussed bounded case, I am finding it hard to grasp and show the following points: What difference is there - if any - in requiring that $\mathcal D(T)=\{(x_n)\in\ell^2(\mathbb N):(r_nx_n)\in\ell^2(\mathbb N)\}$ over stipulating that $M\subset\mathbb C$ be compact? As noted in the opening, we often encounter the requirement that $M\subset\mathbb C$ be compact when $T$ is bounded. Interestingly, requiring that $\mathcal D(T)=\{(x_n)\in\ell^2(\mathbb N):(r_nx_n)\in\ell^2(\mathbb N)\}$ just ensures that $T$ is bounded - so are both stipulations equivalent? How does one use the fact that $(r_nx_n)\in\ell^2(\mathbb N)$ in the definition of $\mathcal D(T)$ to show that $T:\mathcal D(T)\subseteq \ell^2(\mathbb N)\to\ell^2(\mathbb N)$ is closed? I feel that this is obvious since $T$ acts on all of $\ell^2(\mathbb N)$ , but how do I demonstrate that the limit, $x=(x_m)_{m=1}^\infty\in\ell^2(\mathbb N)$ , of any convergent sequence $(x_n)_{n=1}^\infty\subset\mathcal D(T)$ satisfies that ' $(r_mx_m)\in\ell^2(\mathbb N)$ '? What is the difference between defining $Tx_n=r_nx_n$ and defining $Te_n=r_ne_n$ , as has been propositioned in similar questions? In particular, I feel that this point is best considered when taken with the next question ... How, exactly, do we see that $\{r_n:n\in\mathbb N\}\subset M$ is contained within $\sigma(T)$ ? In particular, I don't see how $Tx_n=(r_nx_n)=(r_1x_1, r_2x_2, r_3x_3,\dots)$ has anything to do with the eigenvalue problem; in particular, if we were interested in showing that this was included in the spectrum why don't we look at $Tx=\lambda x=(\lambda x_1, \lambda x_2, \lambda x_3, \dots)$ ? It just seems to me that regarding $Tx_n=(r_nx_n)=(r_1x_1, r_2x_2, r_3x_3,\dots)$ seems to say that this whole sequence $(r_n)_{n=1}^\infty$ is an eigenvalue, rather than that each of its components is an eigenvalue. Is this where it makes more sense to look at the operator $Te_n=(r_ne_n)?$","Several questions on this cite concern themselves with the operator where . Here the sequence is dense in the closed and bounded set . These questions concern themselves with the continuous nature of the operator as well as the fact that . Some of these questions include the following: Show that $A:\ell^2(\mathbb N)\to\ell^2(\mathbb N)$ where $A(e_n)=\lambda_ne_n$ is bounded. Prove $\forall$ compact $M:\ M \subset C\quad \exists A:l_2\rightarrow l_2, \sigma(A)=M$ Operator whose spectrum is given compact set One will note that rather than having , we could also have our operator defined by , where is the usual basis for . I am interested in this example for the case when is potentially unbounded but at least closed . The following is an excerpt from Unbounded Self-adjoint Operators on Hilbert Space by Konrad Schmüdgen. The example contained within the excerpt details that an arbitrary nonempty closed subset is the spectrum for some closed operator. In trying to tackle the closed analogue to the hitherto often discussed bounded case, I am finding it hard to grasp and show the following points: What difference is there - if any - in requiring that over stipulating that be compact? As noted in the opening, we often encounter the requirement that be compact when is bounded. Interestingly, requiring that just ensures that is bounded - so are both stipulations equivalent? How does one use the fact that in the definition of to show that is closed? I feel that this is obvious since acts on all of , but how do I demonstrate that the limit, , of any convergent sequence satisfies that ' '? What is the difference between defining and defining , as has been propositioned in similar questions? In particular, I feel that this point is best considered when taken with the next question ... How, exactly, do we see that is contained within ? In particular, I don't see how has anything to do with the eigenvalue problem; in particular, if we were interested in showing that this was included in the spectrum why don't we look at ? It just seems to me that regarding seems to say that this whole sequence is an eigenvalue, rather than that each of its components is an eigenvalue. Is this where it makes more sense to look at the operator","T:\ell^2(\mathbb N)\to\ell^2(\mathbb N) T(x_n)_{n=1}^\infty=(r_nx_n)_{n=1}^\infty \{r_n:n\in\mathbb N\}\subset M\subset\mathbb C M T \sigma(T)=M T(x_n)_{n=1}^\infty=(r_nx_n)_{n=1}^\infty T(e_n)_{n=1}^\infty=(r_ne_n)_{n=1}^\infty \{e_n\}_{n=1}^\infty \ell^2(\mathbb N) T:\mathcal D(T)\subseteq \ell^2(\mathbb N)\to\ell^2(\mathbb N) M\subset\mathbb C \mathcal D(T)=\{(x_n)\in\ell^2(\mathbb N):(r_nx_n)\in\ell^2(\mathbb N)\} M\subset\mathbb C M\subset\mathbb C T \mathcal D(T)=\{(x_n)\in\ell^2(\mathbb N):(r_nx_n)\in\ell^2(\mathbb N)\} T (r_nx_n)\in\ell^2(\mathbb N) \mathcal D(T) T:\mathcal D(T)\subseteq \ell^2(\mathbb N)\to\ell^2(\mathbb N) T \ell^2(\mathbb N) x=(x_m)_{m=1}^\infty\in\ell^2(\mathbb N) (x_n)_{n=1}^\infty\subset\mathcal D(T) (r_mx_m)\in\ell^2(\mathbb N) Tx_n=r_nx_n Te_n=r_ne_n \{r_n:n\in\mathbb N\}\subset M \sigma(T) Tx_n=(r_nx_n)=(r_1x_1, r_2x_2, r_3x_3,\dots) Tx=\lambda x=(\lambda x_1, \lambda x_2, \lambda x_3, \dots) Tx_n=(r_nx_n)=(r_1x_1, r_2x_2, r_3x_3,\dots) (r_n)_{n=1}^\infty Te_n=(r_ne_n)?","['sequences-and-series', 'functional-analysis', 'operator-theory', 'hilbert-spaces', 'unbounded-operators']"
65,What's the value of $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$?,What's the value of ?,\sum\limits_{k=1}^{\infty}\frac{k^2}{k!},"For some series, it is easy to say whether it is convergent or not by the ""convergence test"", e.g., ratio test. However, it is nontrivial to calculate the value of the sum when the series converges. The question is motivated from the simple exercise to determining whether the series $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$ is convergent. One may immediately get that it is convergent by the ratio test. So here is my question: What's the value of $$\sum_{k=1}^{\infty}\frac{k^2}{k!}?$$","For some series, it is easy to say whether it is convergent or not by the ""convergence test"", e.g., ratio test. However, it is nontrivial to calculate the value of the sum when the series converges. The question is motivated from the simple exercise to determining whether the series $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$ is convergent. One may immediately get that it is convergent by the ratio test. So here is my question: What's the value of $$\sum_{k=1}^{\infty}\frac{k^2}{k!}?$$",,"['calculus', 'real-analysis']"
66,Is $(\sum_{k=0}^n \sin(k!))_{n \in \mathbb{N}} $ bounded?,Is  bounded?,(\sum_{k=0}^n \sin(k!))_{n \in \mathbb{N}} ,"It is a relatively easy exercice to show that $(\sum_{k=0}^n \sin(k))_{n \in \mathbb{N}} $ is bounded by considering complex exponentials $e^{ik}$ (that form a geometric sum) and then taking the imaginary part. But what happens when we replace $k$ by $k!$ ? I think that it is bounded by analogy. The terms somehow compensate one another... But I was unsucessfull at proving it. One of my attempts : I tried to prove that $n!$ is an equidistributed sequence mod $2 \pi$ (I'm not sure that's true), but even with that I struggle to conclude.","It is a relatively easy exercice to show that is bounded by considering complex exponentials (that form a geometric sum) and then taking the imaginary part. But what happens when we replace by ? I think that it is bounded by analogy. The terms somehow compensate one another... But I was unsucessfull at proving it. One of my attempts : I tried to prove that is an equidistributed sequence mod (I'm not sure that's true), but even with that I struggle to conclude.",(\sum_{k=0}^n \sin(k))_{n \in \mathbb{N}}  e^{ik} k k! n! 2 \pi,"['real-analysis', 'sequences-and-series']"
67,For what $k\in \mathbb{C}$ do we have $\lim_{x\to\infty}\frac{1}{x^{k+1}}\sum_{n=1}^x \sigma_k(n)=\frac{\zeta(k+1)}{k+1}$?,For what  do we have ?,k\in \mathbb{C} \lim_{x\to\infty}\frac{1}{x^{k+1}}\sum_{n=1}^x \sigma_k(n)=\frac{\zeta(k+1)}{k+1},"Can the following claim be extended for some complex $k$ . Perhaps: all $k$ with real part greater than or equal to $1$ ? Do the arguments below fall apart for complex $k$ for some reason? Claim. For any real $k\ge1$ $$\lim_{x\to\infty}\frac{1}{x^{k+1}}\sum_{n=1}^x \sigma_k(n)=\frac{\zeta(k+1)}{k+1}$$ Where $\sigma_k(n)=\sum_{d|n}d^k$ and $\zeta(s)=\sum_{n=1}^\infty{\frac{1}{n^s}}$ . The case for $k=1$ is shown here and the two lemmata below will extend the claim for $k>1$ . I really just copied the arguments from the linked post and added in this symbol $k$ . Lemma 1. For $k>1$ we have $$\sum_{n=1}^x \frac{\sigma_k(n)}{n^k}\in\zeta(k+1)x+O(1)$$ Aside I should comment that I have some feelings about big O notation. I think we should not obfuscate the 'is' of identity and the 'is' of predication. This has caused problems in the past... We should really say $f\in O(x^3)$ and not $f=O(x^3)$ . This opinion is not unique to me. And I don't want to start a discussion of notation here. But I am explaining why we see $\in$ and not the more commonly seen $=$ in my presentation of the lemma. It's because of my notation feelings. Proof $$\begin{align} &\sum_{n=1}^x\frac{\sigma_k(n)}{n^k} \\ &=\sum_{n=1}^x \frac{1}{n^k}\sum_{d|n} (\frac{n}{d})^k \\ &=\sum_{n=1}^x \sum_{d|n} (\frac{1}{d})^k \\ &=\sum_{n=1}^x \sum_{A\le \frac{x}{d}} (\frac{1}{d})^k \\ &=\sum_{d=1}^x (\frac{1}{d})^k \sum_{A\le \frac{x}{d}}1  \\ &=\sum_{d=1}^x (\frac{1}{d})^k \bigg \lfloor \frac{x}{d} \bigg \rfloor \\ & \text{And since} \bigg \lfloor \frac{x}{d} \bigg \rfloor \in \frac{x}{d}+O(1) \text{we can substitute into the expression above to arrive at} \\ &\sum_{n=1}^x \frac{\sigma_k(n)}{n^k} \in \sum_{n=1}^x{\frac{1}{d^k}}{\bigg(\frac{x}{d}+O(1) \bigg)} \\ &\subseteq x\sum_{d=1}^x\frac{1}{d^{k+1}}+O\bigg( \sum_{d=1}^x\frac{1}{d^k} \bigg) \\ &\subseteq x\bigg(\zeta(k+1)+O\big(\frac{1}{x}\big) \bigg)+O(x^{1-k})\\ &\subseteq x\zeta(k+1)+O(1)  \end{align} $$ This is justified because for $k \geq 1$ we have $O(x^{1-k}) \subseteq O(1)$ . This concludes the first lemma. $\square$ Lemma 2. For $k>1$ , $$\sum_{n=1}^x\sigma_{k}(n) \in \frac{\zeta(k+1)}{k+1}x^{k+1}+O(x^k)$$ Proof We will use Abel's Summation: $$\sum_{n=1}^x a_nf(n)= A(x)f(x) +\int_1^x A(t)f'(t) dt $$ where $A(x)=\sum_{n=1}^x a_n $ . We will take $a_n=\frac{\sigma_k(n)}{n^k}$ and $f(x)=x^k \implies f'(x)=kx^{k-1}$ . Substituting we have $$\sum_{n=1}^x \sigma_k(n)= \sum_{n=1}^x \bigg(\frac{\sigma_k(n)}{n^k} \bigg){n^k}=x^k \sum_{n=1}^x \frac{\sigma_k(n)}{n^k}-k\int_1^x{t^{k-1}\sum_{n=1}^t{\frac{\sigma_k(n)}{n^k}}dt}$$ But in view of Lemma 1 we can see that this means $$\begin{align} &\sum_{n=1}^x \sigma_k(n) \\ &\in x^k[\zeta(k+1)x+O(1)]-k\int_1^xt^{k-1}[\zeta(k+1)t+O(1)]dt\\ &\subseteq\zeta(k+1)x^{k+1}+O(1)-k\zeta(k+1) \int_1^x{t^k}dt+O\bigg(\int_1^x{t^{k-1}dt}\bigg) \\ &\subseteq \zeta(k+1)x^{k+1}+O(1)-k\zeta(k+1)\bigg[\frac{x^{k+1}-1}{k+1}\bigg]+O\bigg(\frac{x^k-1}{k}\bigg) \\ & \subseteq \zeta(k+1) \bigg[ \frac{(k+1)x^{k+1}-kx^{k+1}}{k+1} \bigg]+O(x^k) \\ & \subseteq \frac{\zeta(k+1}{k+1}x^{k+1}+O(x^k) \end{align} $$ This concludes the second lemma. $\square$ The claim above follows from these lemmata.","Can the following claim be extended for some complex . Perhaps: all with real part greater than or equal to ? Do the arguments below fall apart for complex for some reason? Claim. For any real Where and . The case for is shown here and the two lemmata below will extend the claim for . I really just copied the arguments from the linked post and added in this symbol . Lemma 1. For we have Aside I should comment that I have some feelings about big O notation. I think we should not obfuscate the 'is' of identity and the 'is' of predication. This has caused problems in the past... We should really say and not . This opinion is not unique to me. And I don't want to start a discussion of notation here. But I am explaining why we see and not the more commonly seen in my presentation of the lemma. It's because of my notation feelings. Proof This is justified because for we have . This concludes the first lemma. Lemma 2. For , Proof We will use Abel's Summation: where . We will take and . Substituting we have But in view of Lemma 1 we can see that this means This concludes the second lemma. The claim above follows from these lemmata.","k k 1 k k\ge1 \lim_{x\to\infty}\frac{1}{x^{k+1}}\sum_{n=1}^x \sigma_k(n)=\frac{\zeta(k+1)}{k+1} \sigma_k(n)=\sum_{d|n}d^k \zeta(s)=\sum_{n=1}^\infty{\frac{1}{n^s}} k=1 k>1 k k>1 \sum_{n=1}^x \frac{\sigma_k(n)}{n^k}\in\zeta(k+1)x+O(1) f\in O(x^3) f=O(x^3) \in = \begin{align}
&\sum_{n=1}^x\frac{\sigma_k(n)}{n^k} \\
&=\sum_{n=1}^x \frac{1}{n^k}\sum_{d|n} (\frac{n}{d})^k \\
&=\sum_{n=1}^x \sum_{d|n} (\frac{1}{d})^k \\
&=\sum_{n=1}^x \sum_{A\le \frac{x}{d}} (\frac{1}{d})^k \\
&=\sum_{d=1}^x (\frac{1}{d})^k \sum_{A\le \frac{x}{d}}1  \\
&=\sum_{d=1}^x (\frac{1}{d})^k \bigg \lfloor \frac{x}{d} \bigg \rfloor \\
& \text{And since} \bigg \lfloor \frac{x}{d} \bigg \rfloor \in \frac{x}{d}+O(1) \text{we can substitute into the expression above to arrive at} \\
&\sum_{n=1}^x \frac{\sigma_k(n)}{n^k} \in \sum_{n=1}^x{\frac{1}{d^k}}{\bigg(\frac{x}{d}+O(1) \bigg)} \\
&\subseteq x\sum_{d=1}^x\frac{1}{d^{k+1}}+O\bigg( \sum_{d=1}^x\frac{1}{d^k} \bigg) \\
&\subseteq x\bigg(\zeta(k+1)+O\big(\frac{1}{x}\big) \bigg)+O(x^{1-k})\\
&\subseteq x\zeta(k+1)+O(1) 
\end{align}
 k \geq 1 O(x^{1-k}) \subseteq O(1) \square k>1 \sum_{n=1}^x\sigma_{k}(n) \in \frac{\zeta(k+1)}{k+1}x^{k+1}+O(x^k) \sum_{n=1}^x a_nf(n)= A(x)f(x) +\int_1^x A(t)f'(t) dt  A(x)=\sum_{n=1}^x a_n  a_n=\frac{\sigma_k(n)}{n^k} f(x)=x^k \implies f'(x)=kx^{k-1} \sum_{n=1}^x \sigma_k(n)= \sum_{n=1}^x \bigg(\frac{\sigma_k(n)}{n^k} \bigg){n^k}=x^k \sum_{n=1}^x \frac{\sigma_k(n)}{n^k}-k\int_1^x{t^{k-1}\sum_{n=1}^t{\frac{\sigma_k(n)}{n^k}}dt} \begin{align}
&\sum_{n=1}^x \sigma_k(n) \\
&\in x^k[\zeta(k+1)x+O(1)]-k\int_1^xt^{k-1}[\zeta(k+1)t+O(1)]dt\\
&\subseteq\zeta(k+1)x^{k+1}+O(1)-k\zeta(k+1) \int_1^x{t^k}dt+O\bigg(\int_1^x{t^{k-1}dt}\bigg) \\
&\subseteq \zeta(k+1)x^{k+1}+O(1)-k\zeta(k+1)\bigg[\frac{x^{k+1}-1}{k+1}\bigg]+O\bigg(\frac{x^k-1}{k}\bigg) \\
& \subseteq \zeta(k+1) \bigg[ \frac{(k+1)x^{k+1}-kx^{k+1}}{k+1} \bigg]+O(x^k) \\
& \subseteq \frac{\zeta(k+1}{k+1}x^{k+1}+O(x^k)
\end{align}
 \square","['sequences-and-series', 'asymptotics', 'analytic-number-theory', 'riemann-zeta', 'divisor-sum']"
68,Exact value of Elliptic Integrals.,Exact value of Elliptic Integrals.,,"I was taking currently in a elementary calculus course where i found how to find arc lengths of a smooth continuous curve. so here is how i started : $$\frac{x^2}{a^2}+\frac{y^2}{b^2}=1\Rightarrow y=\pm \frac{b}{a}\sqrt{a^2-x^2}$$ By applying the formula of the arc length of a function, we get: $$L=4\int_0^a\sqrt{1+\frac{b^2x^2}{a^2(a^2-x^2)}}dx=4\int_0^a\sqrt{\frac{a^4+(b^2-a^2)x^2}{a^2(a^2-x^2)}}dx$$ Now I made a little subsitution recalling trigonometry: $$x=a\sin(u)\\dx=a\cos(u)du$$ So the Integral now can be expressed as: $$L=4\int_0^{\frac{\pi}{2}}a\cos(u)\sqrt{\frac{a^4+(b^2-a^2)a^2\sin^2(u)}{a^2(a^2-a^2\sin^2(u))}}du=\\4\int_0^{\frac{\pi}{2}}a\cos(u)\sqrt{\frac{a^4+(b^2-a^2)a^2\sin^2(u)}{a^2(a^2\cos^2(u)+a^2\sin^2(u)-a^2\sin^2(u))}}du=\\4\int_0^{\frac{\pi}{2}}\sqrt{a^2+(b^2-a^2)\sin^2(u)}du$$ So we have: $$L=4a\int_0^{\frac{\pi}{2}}\sqrt{1+\frac{(b^2-a^2)}{a^2}\sin^2(u)}du$$ Letting $m=\frac{(b^2-a^2)}{a^2}$ we finally get: $$L=4a\int_0^{\frac{\pi}{2}}\sqrt{1+m\sin^2(u)}du$$ BUT later i found these type of integrals are known as elliptic integrals and can not be given in terms of elementary functions. say elliptic integral of another type $$u( k)=\int_{0}^{\frac{\pi}{2}} \frac{1}{\sqrt{1-k^2\sin(\theta)}} \, d\theta  $$ expanding by binomial theorem or mclaurian expansion will lead to : $$u(k)=\frac{\pi}{2}\Biggl[{1+\Biggl(\frac{1}{2}\Biggl)^2k^2+\Biggl(\frac{1.3}{2.4}\Biggl)^2k^4+\Biggl(\frac{1.3.5}{2.4.6}\Biggl)^2k^6+....}\Biggl]$$ Now I am very much interested in finding the values of these series rather than the arc length of ellipse. I just found on wikipedia where AGM method is used as : $$u(k)=\frac{\pi}{2M(1,\sqrt{1-k^2})}$$ But At first glance it is easy to see the following as a hypergeometric series : i.e. $$_2F_1\bigg[\frac{1}{2},\frac{1}{2};1;k^2\bigg]=\frac{1}{2}u(k)$$ $$LHS=\sum_{n=0}^{\infty}\frac{\bigg[(\frac{1}{2})_n\bigg]^2 k^{2n}}{(1)_n n!}$$ where $(a)_n=\frac{\Gamma_{a+n}}{\Gamma_a}$ simplify a bit $$=\frac{1}{\pi}\sum_{n=0}^{\infty} \bigg(\frac{\Gamma_{\frac{1}{2}+n}}{n!}\bigg)^2 k^{2n}$$ But i really do not know how the values of hypergeometric series are evaluated.I have seen(of course in a basic way) some special cases of $_3F_2$ and $_7F_6$ but do not know what to do with those generated by ellptic integral. Being unexperienced i will admire any suggestion from anyone. please tell me how these elliptic integrals and hypergeometric series are evaluated. THANK YOU FOR GIVING YOUR TIME.","I was taking currently in a elementary calculus course where i found how to find arc lengths of a smooth continuous curve. so here is how i started : By applying the formula of the arc length of a function, we get: Now I made a little subsitution recalling trigonometry: So the Integral now can be expressed as: So we have: Letting we finally get: BUT later i found these type of integrals are known as elliptic integrals and can not be given in terms of elementary functions. say elliptic integral of another type expanding by binomial theorem or mclaurian expansion will lead to : Now I am very much interested in finding the values of these series rather than the arc length of ellipse. I just found on wikipedia where AGM method is used as : But At first glance it is easy to see the following as a hypergeometric series : i.e. where simplify a bit But i really do not know how the values of hypergeometric series are evaluated.I have seen(of course in a basic way) some special cases of and but do not know what to do with those generated by ellptic integral. Being unexperienced i will admire any suggestion from anyone. please tell me how these elliptic integrals and hypergeometric series are evaluated. THANK YOU FOR GIVING YOUR TIME.","\frac{x^2}{a^2}+\frac{y^2}{b^2}=1\Rightarrow y=\pm \frac{b}{a}\sqrt{a^2-x^2} L=4\int_0^a\sqrt{1+\frac{b^2x^2}{a^2(a^2-x^2)}}dx=4\int_0^a\sqrt{\frac{a^4+(b^2-a^2)x^2}{a^2(a^2-x^2)}}dx x=a\sin(u)\\dx=a\cos(u)du L=4\int_0^{\frac{\pi}{2}}a\cos(u)\sqrt{\frac{a^4+(b^2-a^2)a^2\sin^2(u)}{a^2(a^2-a^2\sin^2(u))}}du=\\4\int_0^{\frac{\pi}{2}}a\cos(u)\sqrt{\frac{a^4+(b^2-a^2)a^2\sin^2(u)}{a^2(a^2\cos^2(u)+a^2\sin^2(u)-a^2\sin^2(u))}}du=\\4\int_0^{\frac{\pi}{2}}\sqrt{a^2+(b^2-a^2)\sin^2(u)}du L=4a\int_0^{\frac{\pi}{2}}\sqrt{1+\frac{(b^2-a^2)}{a^2}\sin^2(u)}du m=\frac{(b^2-a^2)}{a^2} L=4a\int_0^{\frac{\pi}{2}}\sqrt{1+m\sin^2(u)}du u( k)=\int_{0}^{\frac{\pi}{2}} \frac{1}{\sqrt{1-k^2\sin(\theta)}} \, d\theta   u(k)=\frac{\pi}{2}\Biggl[{1+\Biggl(\frac{1}{2}\Biggl)^2k^2+\Biggl(\frac{1.3}{2.4}\Biggl)^2k^4+\Biggl(\frac{1.3.5}{2.4.6}\Biggl)^2k^6+....}\Biggl] u(k)=\frac{\pi}{2M(1,\sqrt{1-k^2})} _2F_1\bigg[\frac{1}{2},\frac{1}{2};1;k^2\bigg]=\frac{1}{2}u(k) LHS=\sum_{n=0}^{\infty}\frac{\bigg[(\frac{1}{2})_n\bigg]^2 k^{2n}}{(1)_n n!} (a)_n=\frac{\Gamma_{a+n}}{\Gamma_a} =\frac{1}{\pi}\sum_{n=0}^{\infty} \bigg(\frac{\Gamma_{\frac{1}{2}+n}}{n!}\bigg)^2 k^{2n} _3F_2 _7F_6","['sequences-and-series', 'special-functions', 'hypergeometric-function', 'elliptic-integrals', 'elliptic-functions']"
69,What is the closed form for $ \sum\limits_{n=0}^{\infty}\frac{1}{(n!)^2}$?,What is the closed form for ?, \sum\limits_{n=0}^{\infty}\frac{1}{(n!)^2},"What is the closed form for $\sum_{n=0}^{\infty}\frac{1}{(n!)^2}$ ? And is there a closed form for $\displaystyle \sum_{n=0}^{\infty}\frac{1}{(n!)^k}$ ? Edit: If there are no closed forms for the two series, how should I convert them into integrals? Now I know that $\displaystyle I_0(2)=\sum_{n=0}^{\infty}\frac{1}{(n!)^2} = \frac{1}{\pi}\int_{0}^{\pi}e^{2\cos\theta}d\theta$ , but is there an integral representation for $\displaystyle \sum_{n=0}^{\infty}\frac{1}{(n!)^k}$ ?","What is the closed form for ? And is there a closed form for ? Edit: If there are no closed forms for the two series, how should I convert them into integrals? Now I know that , but is there an integral representation for ?",\sum_{n=0}^{\infty}\frac{1}{(n!)^2} \displaystyle \sum_{n=0}^{\infty}\frac{1}{(n!)^k} \displaystyle I_0(2)=\sum_{n=0}^{\infty}\frac{1}{(n!)^2} = \frac{1}{\pi}\int_{0}^{\pi}e^{2\cos\theta}d\theta \displaystyle \sum_{n=0}^{\infty}\frac{1}{(n!)^k},['sequences-and-series']
70,Find the sum : $\displaystyle\sum_{i=0}^n \frac{2^i}{1+x^{2^{i}}}$,Find the sum :,\displaystyle\sum_{i=0}^n \frac{2^i}{1+x^{2^{i}}},$\displaystyle\sum_{i=0}^n \frac{2^i}{1+x^{2^{i}}}$ What technique is applicable here? I can't find a way to manipulate this sum to make it telescope. Just guide me.,$\displaystyle\sum_{i=0}^n \frac{2^i}{1+x^{2^{i}}}$ What technique is applicable here? I can't find a way to manipulate this sum to make it telescope. Just guide me.,,['summation']
71,Approximations to series of Ramanujan-type,Approximations to series of Ramanujan-type,,"Recently I have been playing around with series of the form $$\sum_{k=1}^{\infty}\frac{k^{s}}{e^{kz}-1} =  \sum_{k=1}^{\infty}\sigma_{s}(k)e^{-kz}$$ for $s \in \mathbb{Z}$ and where $\sigma_s(k)$ is the sum of divisors function of order $s$.  These series have generated quite a bit of interest over the years, due in large part to some beautiful modular identities of Ramanujan.  The most famous example being $$\alpha^{-n}\left(\frac{1}{2}\zeta(2n+1)+\sum_{k=1}^{\infty}\frac{k^{2n-1}}{e^{2\alpha k}-1}\right) = \\ (-\beta)^n\left(\frac{1}{2}\zeta(2n+1)+\sum_{k=1}^{\infty}\frac{k^{2n-1}}{e^{2\beta k}-1}\right) - 2^{2n}\sum_{k=0}^{n+1}(-1)^k\frac{B_{2k}}{(2k)!}\frac{B_{2n+2-2k}}{(2n+2-2k)!}\alpha^{n+1-k}\beta^k$$ where $\alpha,\beta > 0, \alpha\beta=\pi^2$ and $B_k$ are the Bernoulli numbers and $\zeta(k)$ is the Riemann zeta function.  As far as I know there aren't any similar relations or closed forms when $s \in 2\mathbb{Z}$. In my investigations I was able to find some approximation formula for general $s > 0$ but which unfortunately perform poorer and poorer as $s \rightarrow \infty$. For instance, at $s=2$ we have $$\sum_{k=1}^{\infty}\frac{k^2z}{e^{kz}-1} \approx \frac{2\zeta(3)}{z^2} - \frac{1}{2}-\frac{z}{24} -\sum_{j=0}^{N}B^{(2)}_{j+2}B_{j}\frac{z^{j}}{(j+2)!}$$ where $B^{(k)}_n$ are the Norlund polynomials. I was excited to find this, but then unfortunately realized that since  the sum on the right hand side diverges as $N \rightarrow \infty$ we can only achieve a finite number of accurate digits as the RHS approaches the left from below then surpasses it, growing without bound. For instance letting $N=37$ we have $$\sum_{k=1}^{\infty}\frac{k^2}{e^{k}-1} \approx 2 \zeta (3)-\frac{707928034947324016593079681811720894660110227517}{8567110474102926210628918330759216889856000000000}$$ with the right hand side being correct to the 14-th decimal place.  This is about the best we can do with the above formula. I am curious as to whether someone would be able to provide a better approximation. I am not very familiar with sort of thing... so maybe there is a standard way of achieving approximations like the one above?","Recently I have been playing around with series of the form $$\sum_{k=1}^{\infty}\frac{k^{s}}{e^{kz}-1} =  \sum_{k=1}^{\infty}\sigma_{s}(k)e^{-kz}$$ for $s \in \mathbb{Z}$ and where $\sigma_s(k)$ is the sum of divisors function of order $s$.  These series have generated quite a bit of interest over the years, due in large part to some beautiful modular identities of Ramanujan.  The most famous example being $$\alpha^{-n}\left(\frac{1}{2}\zeta(2n+1)+\sum_{k=1}^{\infty}\frac{k^{2n-1}}{e^{2\alpha k}-1}\right) = \\ (-\beta)^n\left(\frac{1}{2}\zeta(2n+1)+\sum_{k=1}^{\infty}\frac{k^{2n-1}}{e^{2\beta k}-1}\right) - 2^{2n}\sum_{k=0}^{n+1}(-1)^k\frac{B_{2k}}{(2k)!}\frac{B_{2n+2-2k}}{(2n+2-2k)!}\alpha^{n+1-k}\beta^k$$ where $\alpha,\beta > 0, \alpha\beta=\pi^2$ and $B_k$ are the Bernoulli numbers and $\zeta(k)$ is the Riemann zeta function.  As far as I know there aren't any similar relations or closed forms when $s \in 2\mathbb{Z}$. In my investigations I was able to find some approximation formula for general $s > 0$ but which unfortunately perform poorer and poorer as $s \rightarrow \infty$. For instance, at $s=2$ we have $$\sum_{k=1}^{\infty}\frac{k^2z}{e^{kz}-1} \approx \frac{2\zeta(3)}{z^2} - \frac{1}{2}-\frac{z}{24} -\sum_{j=0}^{N}B^{(2)}_{j+2}B_{j}\frac{z^{j}}{(j+2)!}$$ where $B^{(k)}_n$ are the Norlund polynomials. I was excited to find this, but then unfortunately realized that since  the sum on the right hand side diverges as $N \rightarrow \infty$ we can only achieve a finite number of accurate digits as the RHS approaches the left from below then surpasses it, growing without bound. For instance letting $N=37$ we have $$\sum_{k=1}^{\infty}\frac{k^2}{e^{k}-1} \approx 2 \zeta (3)-\frac{707928034947324016593079681811720894660110227517}{8567110474102926210628918330759216889856000000000}$$ with the right hand side being correct to the 14-th decimal place.  This is about the best we can do with the above formula. I am curious as to whether someone would be able to provide a better approximation. I am not very familiar with sort of thing... so maybe there is a standard way of achieving approximations like the one above?",,"['real-analysis', 'sequences-and-series', 'approximation', 'divergent-series']"
72,Concerning the existence of a divergent monotone sequence with a Cauchy subsequence.,Concerning the existence of a divergent monotone sequence with a Cauchy subsequence.,,"Is my argument correct? Proposition. There is no divergent monotone sequence with a Cauchy subsequence. Proof. Assume that we have a divergent monotone sequence $(a_n)$ with a Cauchy sequence $(a_{n_k})$, from theorem $\textbf{2.6.3}$ we know that there exists an $M>0$ such that $|a_{n_k}|<M,\forall k\in\mathbf{N}$. We now examine the case where $(a_n)$ is increasing, the case where $(a_n)$ is decreasing will be handled similarly. Let $r\in\mathbf{N}$, evidently $r\leq n_r$ but then $a_r\leq a_{n_r}$ and since $a_{n_r}\leq |a_{n_r}|\leq M$ consequently $a_r\leq M$, implying that $(a_n)$ is bounded, but $(a_n)$ cannot be bounded since this together with $(a_n)$ being increasing would imply $(a_n)$ is convergent by theorem $\textbf{2.4.1}$. $\blacksquare$ Note: $\textbf{2.6.3}$ All Cauchy sequences are bounded. $\textbf{2.4.1}$ All bounded monotone sequeces are convergent.","Is my argument correct? Proposition. There is no divergent monotone sequence with a Cauchy subsequence. Proof. Assume that we have a divergent monotone sequence $(a_n)$ with a Cauchy sequence $(a_{n_k})$, from theorem $\textbf{2.6.3}$ we know that there exists an $M>0$ such that $|a_{n_k}|<M,\forall k\in\mathbf{N}$. We now examine the case where $(a_n)$ is increasing, the case where $(a_n)$ is decreasing will be handled similarly. Let $r\in\mathbf{N}$, evidently $r\leq n_r$ but then $a_r\leq a_{n_r}$ and since $a_{n_r}\leq |a_{n_r}|\leq M$ consequently $a_r\leq M$, implying that $(a_n)$ is bounded, but $(a_n)$ cannot be bounded since this together with $(a_n)$ being increasing would imply $(a_n)$ is convergent by theorem $\textbf{2.4.1}$. $\blacksquare$ Note: $\textbf{2.6.3}$ All Cauchy sequences are bounded. $\textbf{2.4.1}$ All bounded monotone sequeces are convergent.",,"['real-analysis', 'sequences-and-series', 'proof-verification', 'cauchy-sequences']"
73,"Finding a general formula for the sequence {$0, 1, 3, 5, 6, 7, 9, 15$}.",Finding a general formula for the sequence {}.,"0, 1, 3, 5, 6, 7, 9, 15","I'm working on a mathematical model which requires me to generalize the elements of an infinite set. The element n is the nth finite sequence of the set. For: n = 1: {0}  n = 2: {0, 1, 3, 5, 6, 7, 9, 15}  n = 3: {0, 1, 2, 5, 26, 29, 32, 81, 83, 87, 107, 112, 113, 116, 135, 140, 141, 142, 143, 161, 162, 194, 224, 351, 353, 356, 364, 365, 377, 647, 728, 1514, 1536, 1538, 1595, 1601, 1617, 1619, 1862, 2271, 2273, 2300, 2460, 2462, 2541, 2543, 2561, 3028, 3029, 3168, 3280, 3281, 3289, 3293, 3785, 3806, 3968, 4001, 4009, 4017, 4018, 4019, 4022, 4037, 4046, 4048, 4049, 4069, 4100, 4130, 4289, 4373, 5975, 6056, 6209, 6317, 6336, 6479, 6560, 6673, 6674, 7381, 8180, 9104, 9113, 9833, 9840, 9841, 9842, 9854, 10598, 10609, 10610, 11453, 12301, 13121, 13265, 13346, 14001, 14741, 15227, 15665, 16402, 17141, 17222, 17411, 18146, 18914, 19115, 19331, 19520, 19601, 19682} OEIS doesn't have the sequence n = 2 or n = 3 , let alone a master sequence, so I'm kinda stuck. Does anyone know any math magic to help me generalize the set of sequences. I can provide sequences for n > 3 if necessary. I can also provide the algorithm (c-code) and/or system of equations I'm using to generate these finite sequences. Weird, right? I have an indirect method for generating these sequences, but no direct function. If you don't have an answer, that's understandable, but any advice for a plan of attack would surely help. Thanks for your time, assuming you take the time to read this. Update as requested: Origin of the family of sequences: Generate an ordered, finite set $T_n:  T_n = \{A_1,...,A_\mu...,A_n\} $ , and an operator $\circ: A_p \circ A_q ∈ T_n$ . For $A_\mu ∈ T_n,\ P(A_\mu)$ is the position of $A_\mu$ in set $T_n$ . Further, let: $1. \ \ \ Q_k := (A_X \circ A_Y)_k$ $2.\ \ \ P(Q_k) = \left \lfloor{k\cdot n^{n*P(A_X)+P(A_Y)+1-{n^2}}} \right \rfloor\mod n:0\le k\lt n^{n^2}$ Then associativity of $\circ$ on the set $T_n$ requires that: $ \bigl((A_X \circ A_Y)_k \circ A_Z\bigr)_k = \bigl(A_X \circ (A_Y \circ A_Z)_k\bigr)_k$ . Once you select a given $n$ , we seek the instances $k$ for which the set $T_n$ is associative. There is typically more than one solution, $k$ . The solutions of k for a given n generate the sequences written above. Hence my dilemma: I have an algorithm for generating the numbers, but can't see through the math in order to find a general function that generates all of the finite sequences, and I'm hoping for a fresh perspective, maybe a technique or something, to hopefully find said function. Again, thanks for your input. I can do the work, but I'll appreciate a nudge in the right direction. :)","I'm working on a mathematical model which requires me to generalize the elements of an infinite set. The element n is the nth finite sequence of the set. For: n = 1: {0}  n = 2: {0, 1, 3, 5, 6, 7, 9, 15}  n = 3: {0, 1, 2, 5, 26, 29, 32, 81, 83, 87, 107, 112, 113, 116, 135, 140, 141, 142, 143, 161, 162, 194, 224, 351, 353, 356, 364, 365, 377, 647, 728, 1514, 1536, 1538, 1595, 1601, 1617, 1619, 1862, 2271, 2273, 2300, 2460, 2462, 2541, 2543, 2561, 3028, 3029, 3168, 3280, 3281, 3289, 3293, 3785, 3806, 3968, 4001, 4009, 4017, 4018, 4019, 4022, 4037, 4046, 4048, 4049, 4069, 4100, 4130, 4289, 4373, 5975, 6056, 6209, 6317, 6336, 6479, 6560, 6673, 6674, 7381, 8180, 9104, 9113, 9833, 9840, 9841, 9842, 9854, 10598, 10609, 10610, 11453, 12301, 13121, 13265, 13346, 14001, 14741, 15227, 15665, 16402, 17141, 17222, 17411, 18146, 18914, 19115, 19331, 19520, 19601, 19682} OEIS doesn't have the sequence n = 2 or n = 3 , let alone a master sequence, so I'm kinda stuck. Does anyone know any math magic to help me generalize the set of sequences. I can provide sequences for n > 3 if necessary. I can also provide the algorithm (c-code) and/or system of equations I'm using to generate these finite sequences. Weird, right? I have an indirect method for generating these sequences, but no direct function. If you don't have an answer, that's understandable, but any advice for a plan of attack would surely help. Thanks for your time, assuming you take the time to read this. Update as requested: Origin of the family of sequences: Generate an ordered, finite set , and an operator . For is the position of in set . Further, let: Then associativity of on the set requires that: . Once you select a given , we seek the instances for which the set is associative. There is typically more than one solution, . The solutions of k for a given n generate the sequences written above. Hence my dilemma: I have an algorithm for generating the numbers, but can't see through the math in order to find a general function that generates all of the finite sequences, and I'm hoping for a fresh perspective, maybe a technique or something, to hopefully find said function. Again, thanks for your input. I can do the work, but I'll appreciate a nudge in the right direction. :)","T_n:  T_n = \{A_1,...,A_\mu...,A_n\}  \circ: A_p \circ A_q ∈ T_n A_\mu ∈ T_n,\ P(A_\mu) A_\mu T_n 1. \ \ \ Q_k := (A_X \circ A_Y)_k 2.\ \ \ P(Q_k) = \left \lfloor{k\cdot n^{n*P(A_X)+P(A_Y)+1-{n^2}}} \right \rfloor\mod n:0\le k\lt n^{n^2} \circ T_n  \bigl((A_X \circ A_Y)_k \circ A_Z\bigr)_k = \bigl(A_X \circ (A_Y \circ A_Z)_k\bigr)_k n k T_n k",['sequences-and-series']
74,Sum of 2 raised to the power of every element in a line of Pascal’s triangle,Sum of 2 raised to the power of every element in a line of Pascal’s triangle,,"I know that the elements of a line in Pascal’s triangle add up to $2^n$ . What about: $$\sum_{k=0}^n 2^{\binom{n}{k}}$$ For example, line $n = 2$ adds up to $8$. $n = 3$ adds up to $20$. Is there any formula?","I know that the elements of a line in Pascal’s triangle add up to $2^n$ . What about: $$\sum_{k=0}^n 2^{\binom{n}{k}}$$ For example, line $n = 2$ adds up to $8$. $n = 3$ adds up to $20$. Is there any formula?",,"['sequences-and-series', 'summation', 'binomial-coefficients']"
75,$\sum\limits_{n=1}^{\infty} \frac{\tan^{-1} n}{n}$ diverges.,diverges.,\sum\limits_{n=1}^{\infty} \frac{\tan^{-1} n}{n},"I've come up with what I think are two alternate, valid ways to show that the series $\sum\limits_{n=1}^{\infty} \frac{\tan^{-1}{n}}{n}$ diverges. Hopefully someone can let me know if these hold. (1) Direct Comparison Test: For $x$ greater than about $1.557$ or so (an approximation, based on plotting), $\frac{\tan^{-1}{x}}{x} \geq \frac{1}{x}$. So, taking $N = 1$, for $n > N$, we have $\frac{\tan^{-1}{x}}{x} \geq \frac{1}{x} \geq 0$, where the harmonic series diverges. Thus, $\sum\limits_{n=1}^{\infty} \frac{\tan^{-1}{n}}{n}$ also diverges by direct comparison. (2) Limit-Comparison Test: Again take our series of comparison to be the harmonic series. We get: \begin{align*} \lim\limits_{n \to \infty} \frac{\frac{\tan^{-1}{n}}{n}}{\frac{1}{n}} & = \lim\limits_{n \to \infty} \tan^{-1} n \\ & = \frac{\pi}{2} \end{align*} Since this ratio is a finite number $\neq 0$, we can conclude that either both series converge or both diverge. Since the harmonic series diverges, $\sum\limits_{n=1}^{\infty} \frac{\tan^{-1} n}{n}$ also diverges. How do these look? Thanks in advance.","I've come up with what I think are two alternate, valid ways to show that the series $\sum\limits_{n=1}^{\infty} \frac{\tan^{-1}{n}}{n}$ diverges. Hopefully someone can let me know if these hold. (1) Direct Comparison Test: For $x$ greater than about $1.557$ or so (an approximation, based on plotting), $\frac{\tan^{-1}{x}}{x} \geq \frac{1}{x}$. So, taking $N = 1$, for $n > N$, we have $\frac{\tan^{-1}{x}}{x} \geq \frac{1}{x} \geq 0$, where the harmonic series diverges. Thus, $\sum\limits_{n=1}^{\infty} \frac{\tan^{-1}{n}}{n}$ also diverges by direct comparison. (2) Limit-Comparison Test: Again take our series of comparison to be the harmonic series. We get: \begin{align*} \lim\limits_{n \to \infty} \frac{\frac{\tan^{-1}{n}}{n}}{\frac{1}{n}} & = \lim\limits_{n \to \infty} \tan^{-1} n \\ & = \frac{\pi}{2} \end{align*} Since this ratio is a finite number $\neq 0$, we can conclude that either both series converge or both diverge. Since the harmonic series diverges, $\sum\limits_{n=1}^{\infty} \frac{\tan^{-1} n}{n}$ also diverges. How do these look? Thanks in advance.",,['sequences-and-series']
76,Series of Reciprocal of Iterated Functions,Series of Reciprocal of Iterated Functions,,"Have infinite series of the form $$I(f;z)=\sum_{n=1}^{\infty}\frac{1}{f^n(z)}$$ where $$f^n=\underbrace{f\circ f\circ\dots\circ f}_{n\text{ times}}$$ been studied? One interesting example of this that spurred my interest in these series is Sylvester's sequence . One way to define Sylvester's sequence is $s_0=2$ and $s_n=s_{n-1}^2-s_{n-1}+1$, and it has the known property that $$\sum_{n=0}^{\infty}\frac{1}{s_n}=1$$ This corresponds to the fact that $I(z^2-z+1; \varphi)=1$ where $\varphi$ is the golden ratio. In fact, we have the more general fact that $$I(z^2-z+1; z)=\frac{1}{z(z-1)}$$ In studying these series I have classified all rational $f$ such that $I(f;z)$ is rational in $z$, one such example being the one above. Does anyone know any way this could be used? Or know any literature that makes use of these series? One thing I have considered with this series is that when $f$ is rational, $I(f;z)$ converges on the escaping set minus points whose orbit contains zero. Thus for those such rational $f$ for which $I(f;z)$ has a known closed form the Julia set could maybe be described by looking at where this series (or its partial sums) strays ""too far"" from the value it ought to converge to.","Have infinite series of the form $$I(f;z)=\sum_{n=1}^{\infty}\frac{1}{f^n(z)}$$ where $$f^n=\underbrace{f\circ f\circ\dots\circ f}_{n\text{ times}}$$ been studied? One interesting example of this that spurred my interest in these series is Sylvester's sequence . One way to define Sylvester's sequence is $s_0=2$ and $s_n=s_{n-1}^2-s_{n-1}+1$, and it has the known property that $$\sum_{n=0}^{\infty}\frac{1}{s_n}=1$$ This corresponds to the fact that $I(z^2-z+1; \varphi)=1$ where $\varphi$ is the golden ratio. In fact, we have the more general fact that $$I(z^2-z+1; z)=\frac{1}{z(z-1)}$$ In studying these series I have classified all rational $f$ such that $I(f;z)$ is rational in $z$, one such example being the one above. Does anyone know any way this could be used? Or know any literature that makes use of these series? One thing I have considered with this series is that when $f$ is rational, $I(f;z)$ converges on the escaping set minus points whose orbit contains zero. Thus for those such rational $f$ for which $I(f;z)$ has a known closed form the Julia set could maybe be described by looking at where this series (or its partial sums) strays ""too far"" from the value it ought to converge to.",,"['sequences-and-series', 'reference-request', 'recreational-mathematics']"
77,Deriving values for the Riemann zeta function on even natural numbers through recurrence,Deriving values for the Riemann zeta function on even natural numbers through recurrence,,"In this paper, Yaglom shows an elementary derivation of the solution to the Basel problem by considering polynomials of the form $$\sum_{k=0}^m(-1)^k\binom{2m+1}{2k+1}x^{m-k}$$ which has roots $$\displaystyle \cot^2\frac{k\pi}{2m+1},\,k=1,2,\ldots,m$$ For convenience of notation let $n=2m+1$ . Using Vieta's relations, Yaglom shows that $$\sum_{k=1}^m\cot^2\frac{k\pi}{n}=\frac{\binom{n}{3}}{\binom{n}{1}}=\frac{(n-1)(n-2)}{6}$$ Using the trig identity $1+\cot^2\theta=\csc^2\theta$ , we get $$\sum_{k=1}^m\csc^2\frac{k\pi}{n}=\frac{(n-1)(n-2)}{6}+\frac{n-1}{2}=\frac{(n-1)(n+1)}{6}$$ Finally, using $\displaystyle\cot^2\theta<\frac{1}{\theta^2}<\csc^2\theta\,$ for $\theta\in (0,\pi/2)$ , we get $$\left(1-\frac{1}{n}\right)\left(1-\frac{2}{n}\right)\frac{\pi^2}{6}<\sum_{k=1}^m\frac{1}{k^2}<\left(1-\frac{1}{n}\right)\left(1+\frac{1}{n}\right)\frac{\pi^2}{6}$$ which gives us the desired solution. Yaglom suggests that this method can be extended via Newton's identities to produce values for the Riemann Zeta function on even natural numbers. If we call $$p_j=\sum_{k=1}^m\cot^{2j}\frac{k\pi}{n}$$ then by Newton's identities we get the recurrence relation $$k\binom{n}{2k+1}=\sum_{j=1}^k(-1)^{j-1}\binom{n}{2(k-j)+1}p_j$$ Unfortunately I don't have much experience with recurrence relations, and I have no idea how to proceed. Any help would be very much appreciated. My goal is to find and alternate expression for $p_j$ , just as Yaglom found that $$p_1=\frac{\binom{n}{3}}{\binom{n}{1}}$$ Edit: I'm specifically looking for a way to derive $$\zeta(2k)=\frac{(-1)^{k+1}B_{2k}(2\pi)^{2k}}{2(2k)!}$$ using this method.","In this paper, Yaglom shows an elementary derivation of the solution to the Basel problem by considering polynomials of the form which has roots For convenience of notation let . Using Vieta's relations, Yaglom shows that Using the trig identity , we get Finally, using for , we get which gives us the desired solution. Yaglom suggests that this method can be extended via Newton's identities to produce values for the Riemann Zeta function on even natural numbers. If we call then by Newton's identities we get the recurrence relation Unfortunately I don't have much experience with recurrence relations, and I have no idea how to proceed. Any help would be very much appreciated. My goal is to find and alternate expression for , just as Yaglom found that Edit: I'm specifically looking for a way to derive using this method.","\sum_{k=0}^m(-1)^k\binom{2m+1}{2k+1}x^{m-k} \displaystyle \cot^2\frac{k\pi}{2m+1},\,k=1,2,\ldots,m n=2m+1 \sum_{k=1}^m\cot^2\frac{k\pi}{n}=\frac{\binom{n}{3}}{\binom{n}{1}}=\frac{(n-1)(n-2)}{6} 1+\cot^2\theta=\csc^2\theta \sum_{k=1}^m\csc^2\frac{k\pi}{n}=\frac{(n-1)(n-2)}{6}+\frac{n-1}{2}=\frac{(n-1)(n+1)}{6} \displaystyle\cot^2\theta<\frac{1}{\theta^2}<\csc^2\theta\, \theta\in (0,\pi/2) \left(1-\frac{1}{n}\right)\left(1-\frac{2}{n}\right)\frac{\pi^2}{6}<\sum_{k=1}^m\frac{1}{k^2}<\left(1-\frac{1}{n}\right)\left(1+\frac{1}{n}\right)\frac{\pi^2}{6} p_j=\sum_{k=1}^m\cot^{2j}\frac{k\pi}{n} k\binom{n}{2k+1}=\sum_{j=1}^k(-1)^{j-1}\binom{n}{2(k-j)+1}p_j p_j p_1=\frac{\binom{n}{3}}{\binom{n}{1}} \zeta(2k)=\frac{(-1)^{k+1}B_{2k}(2\pi)^{2k}}{2(2k)!}","['sequences-and-series', 'recurrence-relations', 'riemann-zeta']"
78,"$a_1 = 1, a_{n+1} = \sin (a_n)$ Does the series $\sum a_n$ converge?",Does the series  converge?,"a_1 = 1, a_{n+1} = \sin (a_n) \sum a_n","Suppose $a_1 = 1, a_{n+1} = \sin (a_n).$ Does the series $$\sum_{n=1}^\infty a_n$$ converge? First of all I got that $\lim_{n \to \infty} a_n = 0$ it's easy. Then I tried using all tests I know (The Cauchy root test, The Ratio test, etc.) and I failed to prove either convergence or divergence. Some of my results: $$\lim_{n \to \infty} \frac{a_{n+1}}{a_n} = 1$$ $$\lim_{n \to \infty} \sqrt[n]{a_n} = 1$$ $$a_{n+1} < a_n$$ So, I don't know what to do. Could you please give me any hints about this problem? Thanks in advance!","Suppose $a_1 = 1, a_{n+1} = \sin (a_n).$ Does the series $$\sum_{n=1}^\infty a_n$$ converge? First of all I got that $\lim_{n \to \infty} a_n = 0$ it's easy. Then I tried using all tests I know (The Cauchy root test, The Ratio test, etc.) and I failed to prove either convergence or divergence. Some of my results: $$\lim_{n \to \infty} \frac{a_{n+1}}{a_n} = 1$$ $$\lim_{n \to \infty} \sqrt[n]{a_n} = 1$$ $$a_{n+1} < a_n$$ So, I don't know what to do. Could you please give me any hints about this problem? Thanks in advance!",,"['sequences-and-series', 'recurrence-relations']"
79,Show that: $\lim \limits_{n\to\infty}\frac{x_n-x_{n-1}}{n}=0 $,Show that:,\lim \limits_{n\to\infty}\frac{x_n-x_{n-1}}{n}=0 ,Here is an exercise: Suppose that $\{x_n\}$ is a sequence such that $\lim \limits_{n\to\infty}(x_n-x_{n-2})=0$.  Show that: $$\lim \limits_{n\to\infty}\frac{x_n-x_{n-1}}{n}=0 $$ Thanks.,Here is an exercise: Suppose that $\{x_n\}$ is a sequence such that $\lim \limits_{n\to\infty}(x_n-x_{n-2})=0$.  Show that: $$\lim \limits_{n\to\infty}\frac{x_n-x_{n-1}}{n}=0 $$ Thanks.,,[]
80,Show $\lim_{n\to \infty}{|A_{n}|+|A_{n-2}| \above 1.5pt |A_{n-1}|}=2$,Show,\lim_{n\to \infty}{|A_{n}|+|A_{n-2}| \above 1.5pt |A_{n-1}|}=2,"Question: Let $A(n)$ be a finite square $n \times n$ matrix with entries   $a_{ij}=1$ if $i+j$ is a  prime; otherwise equals to $0$. I write $|A(n)|$ to count the number of $1$'s in $A(n)$. Is it true, possibly trivially, and how can we show that $$\lim_{n\to \infty}{|A_{n}|+|A_{n-2}| \above 1.5pt |A_{n-1}|}=2$$ The sequence of $A(n)$'s can be found here in Sloan. The graph below illustrates the limit. I believe I have shown the question is true, conditionally using a parity argument along with Bertrand's Postulate. Solution: It is easy to verify that $A(n)$ has exactly $2n-1$ skew   diagonal . Two small lemmas. $\underline{\text{lemma 1}}:$  Observe $a_{ii}=1$ if and only if   $i=1$. Consequently $a_{11}$ is the only entry on the main diagonal of   $A(n)$ equal to $1$. Note $A(n)$ is symmetric since addition is commutative. So the count of $1$'s below the main diagonal equals the counts of $1$'s above the main diagonal and the two counts combined form an even number. If we remember to add the sole $1$ for the entry $a_{11}$ then there are an odd number of entries in $A(n)$. In particular $|A(n)|$ is always odd. $\underline{\text{lemma 2}}:$ As mentioned earlier every matrix $A(n)$   has $2n-1$ skew diagonals. Let $S_n$ be the $n$-th skew diagonal of $A(n)$. A skew analogue of Bertrand's   Postulate shows   that at least one of the skews between $S_n$ and $S_{2n-2}$ has all of its entries equal to $1$. Consequently for $n>2$ we have that there is always a  skew diagonal with entries equal to $1$ below the main skew diagonal. In particular $\{A(n)\}_{n=1}^\infty$ is a monotonically increasing sequence of odd integers. Lemma's 1 and 2 control the growth of $A(n)$ as $n \to \infty.$ By   parity check alone as $A(n)$ grows to $A(n+1)$ the count of new $1$'s   must be an nonzero even number. Because of this we have that   $|A_n|=|A_{n-1}|+2j$ for some $j\in\mathbb{N}$, $j\neq0$. So we have the   following from direct substitution \begin{align} {|A_{n}|+|A_{n-2}| \above 1.5pt|A_{n-1}|}&={\left(|A_{n-1}|+2j\right)+\left(|A_{n-1}|-2k\right)\above 1.5pt |A_{n-1}|}\\  &=2\cdot{|A_{n-1}|+j-k\above 1.5pt |A_{n-1}|}\\  &=2\cdot\left(1+{j-k\above 1.5pt |A_{n-1}|}\right)\\ \end{align} Taking limits we have   \begin{align} \lim_{n\to \infty}2\cdot\left(1+{j-k\above 1.5pt |A_{n-1}|}\right)&=2+\lim_{n\to \infty}\left({j-k\above 1.5pt |A_{n-1}|}\right)\\ &=2+0\\ &=2 \end{align} This completes the proof.","Question: Let $A(n)$ be a finite square $n \times n$ matrix with entries   $a_{ij}=1$ if $i+j$ is a  prime; otherwise equals to $0$. I write $|A(n)|$ to count the number of $1$'s in $A(n)$. Is it true, possibly trivially, and how can we show that $$\lim_{n\to \infty}{|A_{n}|+|A_{n-2}| \above 1.5pt |A_{n-1}|}=2$$ The sequence of $A(n)$'s can be found here in Sloan. The graph below illustrates the limit. I believe I have shown the question is true, conditionally using a parity argument along with Bertrand's Postulate. Solution: It is easy to verify that $A(n)$ has exactly $2n-1$ skew   diagonal . Two small lemmas. $\underline{\text{lemma 1}}:$  Observe $a_{ii}=1$ if and only if   $i=1$. Consequently $a_{11}$ is the only entry on the main diagonal of   $A(n)$ equal to $1$. Note $A(n)$ is symmetric since addition is commutative. So the count of $1$'s below the main diagonal equals the counts of $1$'s above the main diagonal and the two counts combined form an even number. If we remember to add the sole $1$ for the entry $a_{11}$ then there are an odd number of entries in $A(n)$. In particular $|A(n)|$ is always odd. $\underline{\text{lemma 2}}:$ As mentioned earlier every matrix $A(n)$   has $2n-1$ skew diagonals. Let $S_n$ be the $n$-th skew diagonal of $A(n)$. A skew analogue of Bertrand's   Postulate shows   that at least one of the skews between $S_n$ and $S_{2n-2}$ has all of its entries equal to $1$. Consequently for $n>2$ we have that there is always a  skew diagonal with entries equal to $1$ below the main skew diagonal. In particular $\{A(n)\}_{n=1}^\infty$ is a monotonically increasing sequence of odd integers. Lemma's 1 and 2 control the growth of $A(n)$ as $n \to \infty.$ By   parity check alone as $A(n)$ grows to $A(n+1)$ the count of new $1$'s   must be an nonzero even number. Because of this we have that   $|A_n|=|A_{n-1}|+2j$ for some $j\in\mathbb{N}$, $j\neq0$. So we have the   following from direct substitution \begin{align} {|A_{n}|+|A_{n-2}| \above 1.5pt|A_{n-1}|}&={\left(|A_{n-1}|+2j\right)+\left(|A_{n-1}|-2k\right)\above 1.5pt |A_{n-1}|}\\  &=2\cdot{|A_{n-1}|+j-k\above 1.5pt |A_{n-1}|}\\  &=2\cdot\left(1+{j-k\above 1.5pt |A_{n-1}|}\right)\\ \end{align} Taking limits we have   \begin{align} \lim_{n\to \infty}2\cdot\left(1+{j-k\above 1.5pt |A_{n-1}|}\right)&=2+\lim_{n\to \infty}\left({j-k\above 1.5pt |A_{n-1}|}\right)\\ &=2+0\\ &=2 \end{align} This completes the proof.",,"['sequences-and-series', 'algebra-precalculus', 'elementary-number-theory', 'conjectures']"
81,Can this closed form for $\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}$ be proved directly by contour integration?,Can this closed form for  be proved directly by contour integration?,\sum_{n=1}^\infty \arctan \frac{a^2}{n^2},"The general closed form for $$\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}= \arctan \left( \frac{\tan \frac{\pi a}{\sqrt{2}}-\tanh \frac{\pi a}{\sqrt{2}}}{\tan \frac{\pi a}{\sqrt{2}}+\tanh \frac{\pi a}{\sqrt{2}}} \right)$$ is shown here and here by referring to the infinite product for the sine. However, by using the series for the arctangent and the integral form of the zeta function, we can write the integral form for the series: $$\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}=2 \int_0^\infty \sin \frac{a x}{\sqrt{2}} ~\sinh \frac{a x}{\sqrt{2}} ~\frac{dx}{x(e^x-1)}$$ This integral is quite complicated, but I believe contour integration can be used to evaluate it directly, without getting back to the series. Can the closed form for the integral be proved with the use of contour integration (or some other integration methods, without using the series and the sine product)? I am still bad with contour integration, so this problem is beyond my level. I would be grateful for an outline of the solution.","The general closed form for $$\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}= \arctan \left( \frac{\tan \frac{\pi a}{\sqrt{2}}-\tanh \frac{\pi a}{\sqrt{2}}}{\tan \frac{\pi a}{\sqrt{2}}+\tanh \frac{\pi a}{\sqrt{2}}} \right)$$ is shown here and here by referring to the infinite product for the sine. However, by using the series for the arctangent and the integral form of the zeta function, we can write the integral form for the series: $$\sum_{n=1}^\infty \arctan \frac{a^2}{n^2}=2 \int_0^\infty \sin \frac{a x}{\sqrt{2}} ~\sinh \frac{a x}{\sqrt{2}} ~\frac{dx}{x(e^x-1)}$$ This integral is quite complicated, but I believe contour integration can be used to evaluate it directly, without getting back to the series. Can the closed form for the integral be proved with the use of contour integration (or some other integration methods, without using the series and the sine product)? I am still bad with contour integration, so this problem is beyond my level. I would be grateful for an outline of the solution.",,"['sequences-and-series', 'definite-integrals', 'contour-integration']"
82,Limit of a sequence given by recurrence relation and convergence rate,Limit of a sequence given by recurrence relation and convergence rate,,"Suppose we have a sequence $\{a_n\}_{n=0}^{\infty}$ which is generated by \begin{align*} a_{n+1} - \left(q+ \frac{A} {n+1} \right) a_n - \frac B n a_{n-1} = C, \end{align*} for $n \ge 1$, where $q, A, B, C$ are fixed positive constants and $0 < q < 1$. Suppose the initial condition is $a_{0} = a_{1} = 1$. It is easy to see the sequence $\{a_n\}_{n=2}^{\infty}$ generated is positive and lower bounded by $C$. I want to argue the limit of the sequence exits and come up with the limit. If we know there is a limit for the sequence, then by taking limits, it seems like $\lim_{n \to \infty} a_n = C/(1-q)$ and also this limit is not a fixed point of the recurrence. I guess the sequence will approximate this limit. But I cannot see how to argue the limit is guaranteed to exist. Any comments will be helpful. Thanks. Update: I guess one way is to write the relation recursively, i.e., \begin{align*} a_{n+1} &= C + \left( q+\frac{A}{n+1} \right) a_n + \frac{B}{n} a_{n-1} \\ &= C + \left( q+\frac{A}{n+1} \right) \left( C + \left( q+\frac{A}{n} \right) a_{n-1} + \frac{B}{n-1} a_{n-2} \right) + \frac{B} {n} a_{n-1}, \end{align*} Since we want the limiting behavior, any term with $n$ in the denominator will vanish. Then if we keep expanding, we get \begin{align*} a_{n+1} = C + Cq + Cq^2 + \dots + C q^{n+1} + o(n). \end{align*} It seems right except it seems a bit too messy. If anyone has a neat proof, please point me out. Another question is whether we can estimate the convergence rate of $\{a_k\}$ to $C/(1-q)$. From the expansion the slowest mode seems to $AC/(n+1)$ and thus the rate is determined by this term. Is this correct? Thanks.","Suppose we have a sequence $\{a_n\}_{n=0}^{\infty}$ which is generated by \begin{align*} a_{n+1} - \left(q+ \frac{A} {n+1} \right) a_n - \frac B n a_{n-1} = C, \end{align*} for $n \ge 1$, where $q, A, B, C$ are fixed positive constants and $0 < q < 1$. Suppose the initial condition is $a_{0} = a_{1} = 1$. It is easy to see the sequence $\{a_n\}_{n=2}^{\infty}$ generated is positive and lower bounded by $C$. I want to argue the limit of the sequence exits and come up with the limit. If we know there is a limit for the sequence, then by taking limits, it seems like $\lim_{n \to \infty} a_n = C/(1-q)$ and also this limit is not a fixed point of the recurrence. I guess the sequence will approximate this limit. But I cannot see how to argue the limit is guaranteed to exist. Any comments will be helpful. Thanks. Update: I guess one way is to write the relation recursively, i.e., \begin{align*} a_{n+1} &= C + \left( q+\frac{A}{n+1} \right) a_n + \frac{B}{n} a_{n-1} \\ &= C + \left( q+\frac{A}{n+1} \right) \left( C + \left( q+\frac{A}{n} \right) a_{n-1} + \frac{B}{n-1} a_{n-2} \right) + \frac{B} {n} a_{n-1}, \end{align*} Since we want the limiting behavior, any term with $n$ in the denominator will vanish. Then if we keep expanding, we get \begin{align*} a_{n+1} = C + Cq + Cq^2 + \dots + C q^{n+1} + o(n). \end{align*} It seems right except it seems a bit too messy. If anyone has a neat proof, please point me out. Another question is whether we can estimate the convergence rate of $\{a_k\}$ to $C/(1-q)$. From the expansion the slowest mode seems to $AC/(n+1)$ and thus the rate is determined by this term. Is this correct? Thanks.",,"['sequences-and-series', 'limits', 'convergence-divergence', 'asymptotics', 'rate-of-convergence']"
83,Nasty logarithmic infinite sums arising from a tan integral,Nasty logarithmic infinite sums arising from a tan integral,,"While trying to work on an old post , I managed after some manipulations to show that the nasty improper tan integral $$ I=\int_0^{\pi} \left( \frac{\pi}{2} - x \right) \frac{\tan x}{x} \, {\rm d}x\approx 2.138967 $$ could be represented as $$ I=\sum_{k=1}^\infty\frac{\ln \left(\frac{2 k+1}{2 k-1}\right)}{2 k-1}- \sum_{k=1}^\infty\frac{\ln \left(\frac{2 k-1}{2 k+1}\right)}{2 k+1}\ .\qquad(\star) $$ The purpose of the original post was to find a closed-form solution for $I$. Clearly the problem would be solved if closed-form solutions for the (equally nasty) logarithmic sums in $(\star)$ could be found. I have worked a bit on those, but didn't achieve much. My question is: can the sums in $(\star)$ be evaluated in closed form? Many thanks, folks.","While trying to work on an old post , I managed after some manipulations to show that the nasty improper tan integral $$ I=\int_0^{\pi} \left( \frac{\pi}{2} - x \right) \frac{\tan x}{x} \, {\rm d}x\approx 2.138967 $$ could be represented as $$ I=\sum_{k=1}^\infty\frac{\ln \left(\frac{2 k+1}{2 k-1}\right)}{2 k-1}- \sum_{k=1}^\infty\frac{\ln \left(\frac{2 k-1}{2 k+1}\right)}{2 k+1}\ .\qquad(\star) $$ The purpose of the original post was to find a closed-form solution for $I$. Clearly the problem would be solved if closed-form solutions for the (equally nasty) logarithmic sums in $(\star)$ could be found. I have worked a bit on those, but didn't achieve much. My question is: can the sums in $(\star)$ be evaluated in closed form? Many thanks, folks.",,"['sequences-and-series', 'definite-integrals', 'logarithms', 'trigonometric-integrals']"
84,On a base 10 Infinite Series,On a base 10 Infinite Series,,"What is the sum of the reciprocals of numbers with only $0$ 's and $1$ 's in their base $10$ expansion? $$x=\frac{1}{1}+\frac{1}{10}+\frac{1}{11}+\frac{1}{100}+\frac{1}{101}+\frac{1}{110}+\frac{1}{111}+\cdots.$$ Is the result transcendental, and does it have a closed form? I have figured out that $1.238405615301<x<1.238405615306$ , but do not know where to go from there.","What is the sum of the reciprocals of numbers with only 's and 's in their base expansion? Is the result transcendental, and does it have a closed form? I have figured out that , but do not know where to go from there.",0 1 10 x=\frac{1}{1}+\frac{1}{10}+\frac{1}{11}+\frac{1}{100}+\frac{1}{101}+\frac{1}{110}+\frac{1}{111}+\cdots. 1.238405615301<x<1.238405615306,"['sequences-and-series', 'number-theory', 'closed-form', 'transcendental-numbers']"
85,Finding a sequence $a_n$ such that $\sum a_n$ converges but $\sum a_n^3$ diverges. [duplicate],Finding a sequence  such that  converges but  diverges. [duplicate],a_n \sum a_n \sum a_n^3,"This question already has answers here : General infinite series convergence or divergence. [duplicate] (3 answers) Closed 6 years ago . This is an exercise that was given to me, and I would like to emphasize that I am not looking for an answer, but rather a pointer or a hint in the right direction, since it appears I've reached a bit of a dead end. We are looking at sequences over the real numbers (at least that's my assumption, and that's where I've been looking). I've come with various results to help me try such a sequence: The ratio test has to be inconclusive, as does the root test. Since $a_n$ converges to $0$, so does $a_n^3$ The sequences $|a_n|$ cannot be monotone decreasing, otherwise $\sum a_n^3$ will converge. Other various things I've noticed: It's very easy to find $a_n$ such that $a_n$ converges but $a_n^2$ diverges. Is it possible to use that fact? Let $u_n$ be such a sequence. I tried to construct a sum of two sequences so that when we take the third power, $u_n^2$ appears in the binomial expansion. That ""naive"" approach didn't get me too far however. We can make the following observation:  \begin{align} \sum a_n^3 &= a_1^3 + a_2^3+a_3^3+a_4^3\cdots \\ & = (a_1+a_2)((a_1-a_2)^2 + a_1a_2) + (a_3+a_4)((a_3-a_4)^2 + a_3a_4) +\cdots \end{align} This hasn't taken me anywhere. Other things I've thought about: I think a natural form for the sequence would be the product of two functions, $f$ and $g$, such that one converges to $0$ much faster than the other. By using the comparison test, we could try to require that $(fg)^3 > k_n$ for all n for some sequence $k_n$ whose associated series is divergent. I think it is unlikely we could find such a product though, since if $fg$ plummets fast enough, then $(fg)^3$ will plummet even faster. I've tried a few things for lack of better options, using exp, trig functions, polynomials, none of my tries have worked so far, almost always as a product of two functions. If someone could suggest a possible step forward, I would be very grateful!","This question already has answers here : General infinite series convergence or divergence. [duplicate] (3 answers) Closed 6 years ago . This is an exercise that was given to me, and I would like to emphasize that I am not looking for an answer, but rather a pointer or a hint in the right direction, since it appears I've reached a bit of a dead end. We are looking at sequences over the real numbers (at least that's my assumption, and that's where I've been looking). I've come with various results to help me try such a sequence: The ratio test has to be inconclusive, as does the root test. Since $a_n$ converges to $0$, so does $a_n^3$ The sequences $|a_n|$ cannot be monotone decreasing, otherwise $\sum a_n^3$ will converge. Other various things I've noticed: It's very easy to find $a_n$ such that $a_n$ converges but $a_n^2$ diverges. Is it possible to use that fact? Let $u_n$ be such a sequence. I tried to construct a sum of two sequences so that when we take the third power, $u_n^2$ appears in the binomial expansion. That ""naive"" approach didn't get me too far however. We can make the following observation:  \begin{align} \sum a_n^3 &= a_1^3 + a_2^3+a_3^3+a_4^3\cdots \\ & = (a_1+a_2)((a_1-a_2)^2 + a_1a_2) + (a_3+a_4)((a_3-a_4)^2 + a_3a_4) +\cdots \end{align} This hasn't taken me anywhere. Other things I've thought about: I think a natural form for the sequence would be the product of two functions, $f$ and $g$, such that one converges to $0$ much faster than the other. By using the comparison test, we could try to require that $(fg)^3 > k_n$ for all n for some sequence $k_n$ whose associated series is divergent. I think it is unlikely we could find such a product though, since if $fg$ plummets fast enough, then $(fg)^3$ will plummet even faster. I've tried a few things for lack of better options, using exp, trig functions, polynomials, none of my tries have worked so far, almost always as a product of two functions. If someone could suggest a possible step forward, I would be very grateful!",,"['sequences-and-series', 'analysis']"
86,Is $63\times63$ the largest matrix with no rectangles that have an even number of each $0-9$ digit?,Is  the largest matrix with no rectangles that have an even number of each  digit?,63\times63 0-9,"I'm working on an algorithm that finds the largest rectangle with an even number of all 10 digits within a square matrix, e.g. for the 4×4 square on the left that would be this 3×2 rectangle: 4 8 6 5    - - - - 3 4 1 2    3 4 1 - 1 3 4 5    1 3 4 - 7 4 0 9    - - - - because it has two of the digits 1, 3 and 4. Now, if you run the algorithm on large squares with random values, the average number of rectangles you have to check before finding one with an even number of all digits is around C(10,0) + C(10,2) + C(10,4) + C(10,6) + C(10,8) + C(10,0) = 512 (because a large rectangle with random values will have a probability of around 1/2 of having an even number of any digit, but only an even number of digits can be present an even number of times in a rectangle with an even number of cells). The worst case, where you'd have to check all rectangles with an even number of cells, because none has an even number of each digit, quickly becomes huge: size            rectangles     2 x    2                  5    4 x    4                 64    8 x    8                896   16 x   16             13,312   32 x   32            204,800   64 x   64          3,211,264  128 x  128         50,855,936  256 x  256        809,500,672  512 x  512     12,918,456,320 1024 x 1024    206,426,865,664 However, when running tests on random data, the highest number of rectangles I ever had to check for any size input was 13,862 for a 64×64 square, even after running the test 10 million times. So I started wondering whether a large square with no valid rectangles was actually possible, or whether there is a maximum size. When trying to construct worst-case input, I automatically ended up using the sequence: 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 ... which is made by taking the sequence so far, repeating it, and adding 1 to the last number ( OEIS A007814 ). The squares it produces (by copying the previous size square four times and then adding 1 to the right-most column and the bottom row) are: 0,1 1,2 0,1,0,2 1,2,1,3 0,1,0,2 2,3,2,4 0,1,0,2,0,1,0,3 1,2,1,3,1,2,1,4 0,1,0,2,0,1,0,3 2,3,2,4,2,3,2,5 0,1,0,2,0,1,0,3 1,2,1,3,1,2,1,4 0,1,0,2,0,1,0,3 3,4,3,5,3,4,3,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8 At his point, if you repeat the 16×16 matrix to create a 32×32 matrix and add 1 to the right-most column and bottom row, the bottom-right cell would have the value 10; we can replace this with a 1 (but that's the only value that works): 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,1 Then, when going from 32×32 to 64×64, there are several cells in the right-most column and bottom row for which every value creates a rectangle with an even number of each digit. So the maximum-sized square without rectangles with an even number of all digits that you can construct with this method seems to be this 63×63 matrix: 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,1,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 Of course, I don't know whether this is the best or only way to construct squares with no rectangles with an even number of each digit, and I also don't know whether there could be non-systematic, more random solutions. So my question is: Can it be proven that 63×63 is the largest square which has no rectangles with an even number of each digit 0-9? And if not, is there a maximum size? And is there a way to construct larger squares? As Peter Taylor pointed out in a comment, a rectangle with height 1 is limited to width 1023, because there are only 2 10 = 1024 different even-ness signatures with 10 digits, so either one of them will be 0 (meaning there is a rectangle with an even number of all digits up to that point), or two will be the same (meaning there is a rectangle with an even number of all digits between them) . Using the same logic, you can prove that a rectangle with height 2 is limited to width 511. Trying this out with the sequence explained above gave these maximum widths: 1: 1023   2 -    3:  511   4 -   15:  255  16 -   63:   63  64 -  255:   15 256 -  511:    3 512 - 1023:    1 The 1×1023 and 2×511 limit are certain. The other limits may just be limits of the method I'm using to create the examples. (Please feel free to change the tags; I was unsure which ones to use.)","I'm working on an algorithm that finds the largest rectangle with an even number of all 10 digits within a square matrix, e.g. for the 4×4 square on the left that would be this 3×2 rectangle: 4 8 6 5    - - - - 3 4 1 2    3 4 1 - 1 3 4 5    1 3 4 - 7 4 0 9    - - - - because it has two of the digits 1, 3 and 4. Now, if you run the algorithm on large squares with random values, the average number of rectangles you have to check before finding one with an even number of all digits is around C(10,0) + C(10,2) + C(10,4) + C(10,6) + C(10,8) + C(10,0) = 512 (because a large rectangle with random values will have a probability of around 1/2 of having an even number of any digit, but only an even number of digits can be present an even number of times in a rectangle with an even number of cells). The worst case, where you'd have to check all rectangles with an even number of cells, because none has an even number of each digit, quickly becomes huge: size            rectangles     2 x    2                  5    4 x    4                 64    8 x    8                896   16 x   16             13,312   32 x   32            204,800   64 x   64          3,211,264  128 x  128         50,855,936  256 x  256        809,500,672  512 x  512     12,918,456,320 1024 x 1024    206,426,865,664 However, when running tests on random data, the highest number of rectangles I ever had to check for any size input was 13,862 for a 64×64 square, even after running the test 10 million times. So I started wondering whether a large square with no valid rectangles was actually possible, or whether there is a maximum size. When trying to construct worst-case input, I automatically ended up using the sequence: 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 ... which is made by taking the sequence so far, repeating it, and adding 1 to the last number ( OEIS A007814 ). The squares it produces (by copying the previous size square four times and then adding 1 to the right-most column and the bottom row) are: 0,1 1,2 0,1,0,2 1,2,1,3 0,1,0,2 2,3,2,4 0,1,0,2,0,1,0,3 1,2,1,3,1,2,1,4 0,1,0,2,0,1,0,3 2,3,2,4,2,3,2,5 0,1,0,2,0,1,0,3 1,2,1,3,1,2,1,4 0,1,0,2,0,1,0,3 3,4,3,5,3,4,3,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8 At his point, if you repeat the 16×16 matrix to create a 32×32 matrix and add 1 to the right-most column and bottom row, the bottom-right cell would have the value 10; we can replace this with a 1 (but that's the only value that works): 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5 5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,1 Then, when going from 32×32 to 64×64, there are several cells in the right-most column and bottom row for which every value creates a rectangle with an even number of each digit. So the maximum-sized square without rectangles with an even number of all digits that you can construct with this method seems to be this 63×63 matrix: 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,1,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5,9,5,6,5,7,5,6,5,8,5,6,5,7,5,6,5 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,9,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4,8,4,5,4,6,4,5,4,7,4,5,4,6,4,5,4 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,8,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3,7,3,4,3,5,3,4,3,6,3,4,3,5,3,4,3 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,7,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2,6,2,3,2,4,2,3,2,5,2,3,2,4,2,3,2 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,6,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1,5,1,2,1,3,1,2,1,4,1,2,1,3,1,2,1 0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0 Of course, I don't know whether this is the best or only way to construct squares with no rectangles with an even number of each digit, and I also don't know whether there could be non-systematic, more random solutions. So my question is: Can it be proven that 63×63 is the largest square which has no rectangles with an even number of each digit 0-9? And if not, is there a maximum size? And is there a way to construct larger squares? As Peter Taylor pointed out in a comment, a rectangle with height 1 is limited to width 1023, because there are only 2 10 = 1024 different even-ness signatures with 10 digits, so either one of them will be 0 (meaning there is a rectangle with an even number of all digits up to that point), or two will be the same (meaning there is a rectangle with an even number of all digits between them) . Using the same logic, you can prove that a rectangle with height 2 is limited to width 511. Trying this out with the sequence explained above gave these maximum widths: 1: 1023   2 -    3:  511   4 -   15:  255  16 -   63:   63  64 -  255:   15 256 -  511:    3 512 - 1023:    1 The 1×1023 and 2×511 limit are certain. The other limits may just be limits of the method I'm using to create the examples. (Please feel free to change the tags; I was unsure which ones to use.)",,"['sequences-and-series', 'combinatorics', 'elementary-number-theory', 'discrete-mathematics', 'integers']"
87,Convergence of an infinite product,Convergence of an infinite product,,"For which $a \in \mathbb{R^+}$ does the sequence $$\gamma_n=(1+a)(1+2a^2)\cdots(1+na^n)$$ converge? Give a brief explanation. My attempt : Is easy to see that $a=0 \implies \gamma_n \equiv1$; $a \ge 1 \implies$ $\gamma_n$ diverges. Convergence: if $0<a<1$, $\gamma_n$ converges $\iff$ $\sum_{k=0}^{\infty}\ln(1+ka^k)$ converges. $$\sum_{k=0}^\infty \ln(1+ka^k) \le \sum_{k=0}^\infty ka^k=\frac{a}{(1-a)^2}<+\infty$$ so $\gamma_n(a)$ converges in $[0,1) \space \blacksquare$ Is the solution correct? If yes, Is there a briefer explanation?","For which $a \in \mathbb{R^+}$ does the sequence $$\gamma_n=(1+a)(1+2a^2)\cdots(1+na^n)$$ converge? Give a brief explanation. My attempt : Is easy to see that $a=0 \implies \gamma_n \equiv1$; $a \ge 1 \implies$ $\gamma_n$ diverges. Convergence: if $0<a<1$, $\gamma_n$ converges $\iff$ $\sum_{k=0}^{\infty}\ln(1+ka^k)$ converges. $$\sum_{k=0}^\infty \ln(1+ka^k) \le \sum_{k=0}^\infty ka^k=\frac{a}{(1-a)^2}<+\infty$$ so $\gamma_n(a)$ converges in $[0,1) \space \blacksquare$ Is the solution correct? If yes, Is there a briefer explanation?",,"['sequences-and-series', 'infinite-product']"
88,Understanding part of a proof for Stolz-Cesaro Theorem,Understanding part of a proof for Stolz-Cesaro Theorem,,"I'm trying to understand a step from a proof of the Stolz-Cesaro Theorem. Let ${\left\{ {{b_n}} \right\}_{n \in {\Bbb N}}}$ is a positively strictly increasing unbounded sequence. If ${\left\{ {{a_n}} \right\}_{n \in {\Bbb N}}}$ is another sequence and $$\mathop {\lim }\limits_{n \to \infty } \frac{{{a_{n + 1}} - {a_n}}}{{{b_{n + 1}} - {b_n}}} = l $$ then $$\mathop {\lim }\limits_{n \to \infty } \frac{{{a_n}}}{{{b_n}}} = l$$ The proof I'm trying to understand is here . I can't seem to understand the last step, i.e. why: $$(l-\epsilon)(1-\frac{b_{N(\epsilon)}}{b_{k+1}})+\frac{a_{N(\epsilon)}}{b_{k+1}} < \frac{a_{k+1}}{b_{k+1}}<(l+\epsilon)(1-\frac{b_{N(\epsilon)}}{b_{k+1}})+\frac{a_{N(\epsilon)}}{b_{k+1}} \implies\\ \implies l-\epsilon<\frac{a_{k+1}}{b_{k+1}} < l + \epsilon$$ How is that true and how can one write that more formally and detailed? Thanks in advance!","I'm trying to understand a step from a proof of the Stolz-Cesaro Theorem. Let is a positively strictly increasing unbounded sequence. If is another sequence and then The proof I'm trying to understand is here . I can't seem to understand the last step, i.e. why: How is that true and how can one write that more formally and detailed? Thanks in advance!",{\left\{ {{b_n}} \right\}_{n \in {\Bbb N}}} {\left\{ {{a_n}} \right\}_{n \in {\Bbb N}}} \mathop {\lim }\limits_{n \to \infty } \frac{{{a_{n + 1}} - {a_n}}}{{{b_{n + 1}} - {b_n}}} = l  \mathop {\lim }\limits_{n \to \infty } \frac{{{a_n}}}{{{b_n}}} = l (l-\epsilon)(1-\frac{b_{N(\epsilon)}}{b_{k+1}})+\frac{a_{N(\epsilon)}}{b_{k+1}} < \frac{a_{k+1}}{b_{k+1}}<(l+\epsilon)(1-\frac{b_{N(\epsilon)}}{b_{k+1}})+\frac{a_{N(\epsilon)}}{b_{k+1}} \implies\\ \implies l-\epsilon<\frac{a_{k+1}}{b_{k+1}} < l + \epsilon,"['real-analysis', 'sequences-and-series', 'limits', 'cesaro-summable']"
89,"Convergence of series alternating at varying ""rates""","Convergence of series alternating at varying ""rates""",,"Motivation : We all know the alternating harmonic series $$\sum (-1)^{n+1} \frac 1n = 1 - \frac 12 + \frac 13  - \frac 14 \cdots$$ is convergent. This is a basic consequence of the alternating series test. Here, it's quite clear how the ""plus"" and ""minus"" signs are behaving. Each term, they switch. Half of the terms, loosely speaking, have $+1$, and the other half have $-1$. Well, then one may ask, what if we relax this condition, and allow the $-1$ and $+1$ factors to ""vary"" in the series in an arbitrary manner? Is convergence still a possibility? Definitions : Let $\alpha:\mathbb{N} \to S \subset \mathbb{R}$ be a real sequence. Define $\alpha^{-1}[x,n] \stackrel{\text{def}}{=} \{k : 1 \leq k \leq n \ \text{and}\ \alpha(k) = x\}$. In other words, $\alpha^{-1}[x,n]$ is the set of naturals at most $n$ which $\alpha$ maps to $x$. (Obviously, $x \in S$.) Define the density of $x$ in $\alpha$ as the quantity $$D(\alpha,x) \stackrel{\text{def}}{=} \lim_{n \to +\infty} \frac{|\alpha^{-1}[x,n]|}{n} $$ if the limit exists. Conjecture: For any $\epsilon \in [0, 1]$, there is always a mapping $s_{\epsilon}:\mathbb{N} \to \{-1,1\}$ such that $$\sum_{n \geq 1} \frac{s_{\epsilon}(n)}{n}$$ is convergent and $D(s_{\epsilon}, 1) = \epsilon$. Note that there is a sort of ""symmetry"" with the $+1$ and $-1$, which is why we can work with $D(s_{\epsilon}, 1)$ without loss of generality. Generalization: Consider the above conjecture with $\sum s_{\epsilon}(n)a_n$ where $\{a_n\}$ is such that $\sum a_n$ is conditionally convergent.","Motivation : We all know the alternating harmonic series $$\sum (-1)^{n+1} \frac 1n = 1 - \frac 12 + \frac 13  - \frac 14 \cdots$$ is convergent. This is a basic consequence of the alternating series test. Here, it's quite clear how the ""plus"" and ""minus"" signs are behaving. Each term, they switch. Half of the terms, loosely speaking, have $+1$, and the other half have $-1$. Well, then one may ask, what if we relax this condition, and allow the $-1$ and $+1$ factors to ""vary"" in the series in an arbitrary manner? Is convergence still a possibility? Definitions : Let $\alpha:\mathbb{N} \to S \subset \mathbb{R}$ be a real sequence. Define $\alpha^{-1}[x,n] \stackrel{\text{def}}{=} \{k : 1 \leq k \leq n \ \text{and}\ \alpha(k) = x\}$. In other words, $\alpha^{-1}[x,n]$ is the set of naturals at most $n$ which $\alpha$ maps to $x$. (Obviously, $x \in S$.) Define the density of $x$ in $\alpha$ as the quantity $$D(\alpha,x) \stackrel{\text{def}}{=} \lim_{n \to +\infty} \frac{|\alpha^{-1}[x,n]|}{n} $$ if the limit exists. Conjecture: For any $\epsilon \in [0, 1]$, there is always a mapping $s_{\epsilon}:\mathbb{N} \to \{-1,1\}$ such that $$\sum_{n \geq 1} \frac{s_{\epsilon}(n)}{n}$$ is convergent and $D(s_{\epsilon}, 1) = \epsilon$. Note that there is a sort of ""symmetry"" with the $+1$ and $-1$, which is why we can work with $D(s_{\epsilon}, 1)$ without loss of generality. Generalization: Consider the above conjecture with $\sum s_{\epsilon}(n)a_n$ where $\{a_n\}$ is such that $\sum a_n$ is conditionally convergent.",,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
90,How does rounding affect Fibonacci-ish sequences?,How does rounding affect Fibonacci-ish sequences?,,"I'm curious how one might account for rounding in simple recurrence relations. $\textbf{Explanation}$ For a specific problem, suppose we have a sequence of positive integers $a_1, a_2, a_3,...$ with where each $a_i$ obeys the following rule $$a_n=a_{n-1}+\text{floor}\Big[\frac{a_{n-4}}{2}\Big]$$ Where ""floor"" here just means round down. For example if $a_1=5$ and $a_4=7$ then $$a_5=7+\text{floor}\Big[\frac{5}{2}\Big]=9$$ And if we start with $a_1=a_2=a_3=a_4=6$ and continue the sequence we get $$6\rightarrow6\rightarrow6\rightarrow6\rightarrow9\rightarrow12\rightarrow15\rightarrow18\rightarrow22\rightarrow28\rightarrow35\rightarrow44\rightarrow55\rightarrow...$$ What is $a_{100}$? And more importantly, can $a_n$ in general be exactly calculated without calculating all the previous terms in the sequence? Here's what's been tried so far $\textbf{Linear Algebra Approximation}$ The update rule for the previous sequence can be approximated with a linear transformation $$ A =  \begin{bmatrix} 1 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ \frac{1}{2} & 0 & 0 & 0 \\ \end{bmatrix} \quad \quad \text{with} \quad \quad A \cdot \begin{bmatrix} a_n \\ b_n \\ c_n \\ d_n \\ \end{bmatrix} = \begin{bmatrix} a_{n+1} \\ b_{n+1} \\ c_{n+1} \\ d_{n+1} \\ \end{bmatrix} $$ where the $a_n$ in each vector corresponds to the same $a_n$ of the previous sequence example. This matrix has only one all-positive eigenvector with an eigenvalue $\lambda=1.254...$ which is the growth rate approached by the sequence. One could predict the value of $a_n$ by calculating $$A^n \cdot \begin{bmatrix} a_1 \\ a_1 \\ a_1 \\ a_1 \\ \end{bmatrix}$$ The problem with using a linear transformation is that rounding isn't taken into account. So the predictions one gets inevitably overshoot. And some starting sequences don't even increase when rounding is taken into account. Consider $a_1=a_2=a_3=a_4=1$ $$1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow...$$ $\textbf{Error Estimation}$ For initial values of the sequence that highly divisible by $2$, the rounding down won't affect the sequence for a longer time. More specifically if we start with $$a_1=a_2=a_3=a_4=k2^m \text{ where } k \text{ is odd}$$ Then $a_{4m+5}$ will be the first term affected by the rounding. One could introduce a rounding error function. Something of the form $$f(k, m) = \text{% error approached by the initial value } k2^m$$ It was suggested to use linear dynamical discrete systems to derive an exact formula for $a_n$. How exactly that is done is still unknown. Are there any good example problems similar to this one?","I'm curious how one might account for rounding in simple recurrence relations. $\textbf{Explanation}$ For a specific problem, suppose we have a sequence of positive integers $a_1, a_2, a_3,...$ with where each $a_i$ obeys the following rule $$a_n=a_{n-1}+\text{floor}\Big[\frac{a_{n-4}}{2}\Big]$$ Where ""floor"" here just means round down. For example if $a_1=5$ and $a_4=7$ then $$a_5=7+\text{floor}\Big[\frac{5}{2}\Big]=9$$ And if we start with $a_1=a_2=a_3=a_4=6$ and continue the sequence we get $$6\rightarrow6\rightarrow6\rightarrow6\rightarrow9\rightarrow12\rightarrow15\rightarrow18\rightarrow22\rightarrow28\rightarrow35\rightarrow44\rightarrow55\rightarrow...$$ What is $a_{100}$? And more importantly, can $a_n$ in general be exactly calculated without calculating all the previous terms in the sequence? Here's what's been tried so far $\textbf{Linear Algebra Approximation}$ The update rule for the previous sequence can be approximated with a linear transformation $$ A =  \begin{bmatrix} 1 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ \frac{1}{2} & 0 & 0 & 0 \\ \end{bmatrix} \quad \quad \text{with} \quad \quad A \cdot \begin{bmatrix} a_n \\ b_n \\ c_n \\ d_n \\ \end{bmatrix} = \begin{bmatrix} a_{n+1} \\ b_{n+1} \\ c_{n+1} \\ d_{n+1} \\ \end{bmatrix} $$ where the $a_n$ in each vector corresponds to the same $a_n$ of the previous sequence example. This matrix has only one all-positive eigenvector with an eigenvalue $\lambda=1.254...$ which is the growth rate approached by the sequence. One could predict the value of $a_n$ by calculating $$A^n \cdot \begin{bmatrix} a_1 \\ a_1 \\ a_1 \\ a_1 \\ \end{bmatrix}$$ The problem with using a linear transformation is that rounding isn't taken into account. So the predictions one gets inevitably overshoot. And some starting sequences don't even increase when rounding is taken into account. Consider $a_1=a_2=a_3=a_4=1$ $$1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow1\rightarrow...$$ $\textbf{Error Estimation}$ For initial values of the sequence that highly divisible by $2$, the rounding down won't affect the sequence for a longer time. More specifically if we start with $$a_1=a_2=a_3=a_4=k2^m \text{ where } k \text{ is odd}$$ Then $a_{4m+5}$ will be the first term affected by the rounding. One could introduce a rounding error function. Something of the form $$f(k, m) = \text{% error approached by the initial value } k2^m$$ It was suggested to use linear dynamical discrete systems to derive an exact formula for $a_n$. How exactly that is done is still unknown. Are there any good example problems similar to this one?",,"['sequences-and-series', 'linear-transformations']"
91,$\frac {\pi} {1+\frac {\pi} {2+\frac {\pi} {3+\frac {\pi} {4+\frac {\pi} {\ddots}}}}}$,,\frac {\pi} {1+\frac {\pi} {2+\frac {\pi} {3+\frac {\pi} {4+\frac {\pi} {\ddots}}}}},"$$\cfrac \pi {1+\cfrac \pi {2+\cfrac \pi {3+\cfrac \pi {4+\cfrac {\pi} {\ddots}}}}}$$ I don't want a solution to this. I just want to know to begin ! I've been trying for almost an hour now. Thanks for the help EDIT 1 : Here is what I tried : $f(n) = n + \frac {\pi} {f(n+1)}$ $f(n+1)(f(n)-n) = \pi$ $f(1)f(0)=\pi$ since, $\pi$ is the factor of two numbers. So one must be 1 and other must be $\pi.$ $f(2)(f(1)-1)=\pi$ If $f(1)=1$, then, $f(2)(1-1)=\pi$ which is impossible. $So, f(0) = 1$ must be True! Hence the answer is 1 Can someone please verify ? Thanks :)","$$\cfrac \pi {1+\cfrac \pi {2+\cfrac \pi {3+\cfrac \pi {4+\cfrac {\pi} {\ddots}}}}}$$ I don't want a solution to this. I just want to know to begin ! I've been trying for almost an hour now. Thanks for the help EDIT 1 : Here is what I tried : $f(n) = n + \frac {\pi} {f(n+1)}$ $f(n+1)(f(n)-n) = \pi$ $f(1)f(0)=\pi$ since, $\pi$ is the factor of two numbers. So one must be 1 and other must be $\pi.$ $f(2)(f(1)-1)=\pi$ If $f(1)=1$, then, $f(2)(1-1)=\pi$ which is impossible. $So, f(0) = 1$ must be True! Hence the answer is 1 Can someone please verify ? Thanks :)",,"['sequences-and-series', 'continued-fractions']"
92,One step in the proof that the series of $1/{n^2}$ equals ${\pi^2}/6$ that I don't understand,One step in the proof that the series of  equals  that I don't understand,1/{n^2} {\pi^2}/6,"I know questions about the specific series $$\sum_{n=1}^{\infty} {1 \over {n^2}} = {{\pi^2} \over 6}$$ have been posted before, but there is one specific step in the proof that I don't understand I have yet to find a sufficient answer. I had already started working out the exercise and was getting the same results as in the following link: http://empslocal.ex.ac.uk/people/staff/rjchapma/etc/zeta2.pdf We want to first show $$\int_{(0,1)^2} {1 \over {1-xy}} d{\lambda^2}(x,y) = \sum_{n=1}^{\infty} {1 \over {n^2}}$$ by using a geometric series. I defined $${f_m}(x,y) :\doteq \lim_{m\to\infty} \sum_{n=0}^{m} {1 \over {(xy)^2}} = \lim_{m\to\infty} {{1 - {(xy)^{m+1}}} \over {1 - xy}}$$ This is a monotone increasing sequence of nonnegative functions that converges to $1 \over {1 - xy}$. Thus, we can use the monotone convergence theorem to exchange the sum and integral; further, by using an appropriate index shift, Tonelli's theorem, and the linearity of integrals, we get: $$\int_{(0,1)^2} {1 \over {1-xy}} d{\lambda^2}(x,y) = \lim_{m\to\infty} \sum_{n=1}^{m+1} \int_{0}^{1} \int_{0}^{1} {1 \over {(xy)^{n-1}}} dx dy$$ I can easily show that if $n = 1$ then the above double integral is equal to $1$, and if $n \geq 3$, the double integral is equal to $1 \over {n^2}$. My problem arises by $n=2$. In this case we have $$\int_{0}^{1} \int_{0}^{1} {1 \over xy} dx dy$$ which clearly does not exist. Am I just seeing incorrectly? Is there something obvious that I'm missing?  How can I justify this? I appreciate any help!","I know questions about the specific series $$\sum_{n=1}^{\infty} {1 \over {n^2}} = {{\pi^2} \over 6}$$ have been posted before, but there is one specific step in the proof that I don't understand I have yet to find a sufficient answer. I had already started working out the exercise and was getting the same results as in the following link: http://empslocal.ex.ac.uk/people/staff/rjchapma/etc/zeta2.pdf We want to first show $$\int_{(0,1)^2} {1 \over {1-xy}} d{\lambda^2}(x,y) = \sum_{n=1}^{\infty} {1 \over {n^2}}$$ by using a geometric series. I defined $${f_m}(x,y) :\doteq \lim_{m\to\infty} \sum_{n=0}^{m} {1 \over {(xy)^2}} = \lim_{m\to\infty} {{1 - {(xy)^{m+1}}} \over {1 - xy}}$$ This is a monotone increasing sequence of nonnegative functions that converges to $1 \over {1 - xy}$. Thus, we can use the monotone convergence theorem to exchange the sum and integral; further, by using an appropriate index shift, Tonelli's theorem, and the linearity of integrals, we get: $$\int_{(0,1)^2} {1 \over {1-xy}} d{\lambda^2}(x,y) = \lim_{m\to\infty} \sum_{n=1}^{m+1} \int_{0}^{1} \int_{0}^{1} {1 \over {(xy)^{n-1}}} dx dy$$ I can easily show that if $n = 1$ then the above double integral is equal to $1$, and if $n \geq 3$, the double integral is equal to $1 \over {n^2}$. My problem arises by $n=2$. In this case we have $$\int_{0}^{1} \int_{0}^{1} {1 \over xy} dx dy$$ which clearly does not exist. Am I just seeing incorrectly? Is there something obvious that I'm missing?  How can I justify this? I appreciate any help!",,"['sequences-and-series', 'lebesgue-integral']"
93,Characterisation of uniformly continuous function,Characterisation of uniformly continuous function,,"I have the following exercise: Let $(X,d)$, $(Y,e)$ be metric spaces. This is the definition of distance of sets used in the exercise: $d(A,B)=inf\{d(a,b)\colon a \in A, b \in B\}$ $d(f(A),f(B))=inf\{e(f(a),f(b))\colon f(a) \in A, f(b) \in B\}$ The exercise is: Prove that $f\colon X \rightarrow Y$ is uniformly continuous if and only if, for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$. If we suppose that $f$ is uniformly continuous, the implication is easy. But the converse is very hard for me. Let me show you what I have tried: Suppose that for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$, and for the sake of a contradiction suppose also that $f$ is not uniformly continuous. Then there exist $\epsilon_0>0$ such that for all $\delta>0$, exist $x_\delta$, $y_\delta$ in $X$ such that $d(x_\delta, y_\delta)<\delta$ but $e(f(x),f(y)) \geq \epsilon_0$. In particular, for all $\delta=\frac{1}{n}>0$ there exist $x_n,y_n$ in $X$ such that $d(x_n,y_n)<\frac{1}{n}$ but $e(f(x_n),f(y_n)) \geq \epsilon_0$ Then $A=\{x_n \colon n \in \mathbb{N}\}$ and $B=\{y_n \colon n \in \mathbb{N}\}$ are such that $d(A,B)=0$. Then by hypotheses, we have that $d(f(A),f(B))=0$. Then, in particular for $\epsilon_0>0$, there exist $x_n,y_m$ in $X$ such that $e(f(x_n),f(y_m))<\epsilon_0$. But I get a contradiction if $n=m$ but I don't know how to proceed in case that $n\neq m$. Any help would be appreciated.","I have the following exercise: Let $(X,d)$, $(Y,e)$ be metric spaces. This is the definition of distance of sets used in the exercise: $d(A,B)=inf\{d(a,b)\colon a \in A, b \in B\}$ $d(f(A),f(B))=inf\{e(f(a),f(b))\colon f(a) \in A, f(b) \in B\}$ The exercise is: Prove that $f\colon X \rightarrow Y$ is uniformly continuous if and only if, for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$. If we suppose that $f$ is uniformly continuous, the implication is easy. But the converse is very hard for me. Let me show you what I have tried: Suppose that for all non empty sets $A$,$B$ in $X$ such that $d(A,B)=0$ we always have that $d(f(A),f(B))=0$, and for the sake of a contradiction suppose also that $f$ is not uniformly continuous. Then there exist $\epsilon_0>0$ such that for all $\delta>0$, exist $x_\delta$, $y_\delta$ in $X$ such that $d(x_\delta, y_\delta)<\delta$ but $e(f(x),f(y)) \geq \epsilon_0$. In particular, for all $\delta=\frac{1}{n}>0$ there exist $x_n,y_n$ in $X$ such that $d(x_n,y_n)<\frac{1}{n}$ but $e(f(x_n),f(y_n)) \geq \epsilon_0$ Then $A=\{x_n \colon n \in \mathbb{N}\}$ and $B=\{y_n \colon n \in \mathbb{N}\}$ are such that $d(A,B)=0$. Then by hypotheses, we have that $d(f(A),f(B))=0$. Then, in particular for $\epsilon_0>0$, there exist $x_n,y_m$ in $X$ such that $e(f(x_n),f(y_m))<\epsilon_0$. But I get a contradiction if $n=m$ but I don't know how to proceed in case that $n\neq m$. Any help would be appreciated.",,"['general-topology', 'metric-spaces', 'uniform-continuity']"
94,Proving Riemann's Theorem through Casorati- Weierstrass,Proving Riemann's Theorem through Casorati- Weierstrass,,"The title is pretty much self-explanatory; I'd like to know if there is a proof of Riemann's rearrangement theorem that uses the Casorati-Weierstrass theorem. Even if you're not familiar with such a proof but can come up with one, I'd like to have a look. To be specific: Riemann's Rearrangement Theorem Let $(a_n)\subset\mathbb{R}$ be a real valued sequence such that the series $\displaystyle{\sum_{n=1}^{\infty}a_n}$ converges, but not absolutely, meaning that $\displaystyle{\sum_{n=1}^{\infty}|a_n|=+\infty}$. Then, for every $c \in \overline{\mathbb{R}}$ there exists a rearrangement $k:\mathbb{N}\to\mathbb{N}$ such that $\displaystyle{\sum_{n=1}^{\infty}a_{k(n)} = c}$. Comment: A rearrangement is just a bijection of the positive integers. Casorati-Weierstrass Theorem Let $z_0 \in \Omega$, with $\Omega$ being an open set and $f:\Omega\setminus\{z_0\}\to\mathbb{C}$ be a holomorphic function, such that $z_0$ is an essential singularity of $f$. Then, for each $\delta>0$ that satisfies $D(z_0,\delta)\subset\Omega$, the set$f(D(z_0,\delta)\setminus\{z_0\})$ is dense in $\mathbb{C}$. I'm familiar with the proofs of both theorems, but I can't seem to make a connection. I'm not even sure there is one; but both of the theorems flirt with the density of the limit points and I strongly believe that they're connected.","The title is pretty much self-explanatory; I'd like to know if there is a proof of Riemann's rearrangement theorem that uses the Casorati-Weierstrass theorem. Even if you're not familiar with such a proof but can come up with one, I'd like to have a look. To be specific: Riemann's Rearrangement Theorem Let $(a_n)\subset\mathbb{R}$ be a real valued sequence such that the series $\displaystyle{\sum_{n=1}^{\infty}a_n}$ converges, but not absolutely, meaning that $\displaystyle{\sum_{n=1}^{\infty}|a_n|=+\infty}$. Then, for every $c \in \overline{\mathbb{R}}$ there exists a rearrangement $k:\mathbb{N}\to\mathbb{N}$ such that $\displaystyle{\sum_{n=1}^{\infty}a_{k(n)} = c}$. Comment: A rearrangement is just a bijection of the positive integers. Casorati-Weierstrass Theorem Let $z_0 \in \Omega$, with $\Omega$ being an open set and $f:\Omega\setminus\{z_0\}\to\mathbb{C}$ be a holomorphic function, such that $z_0$ is an essential singularity of $f$. Then, for each $\delta>0$ that satisfies $D(z_0,\delta)\subset\Omega$, the set$f(D(z_0,\delta)\setminus\{z_0\})$ is dense in $\mathbb{C}$. I'm familiar with the proofs of both theorems, but I can't seem to make a connection. I'm not even sure there is one; but both of the theorems flirt with the density of the limit points and I strongly believe that they're connected.",,"['real-analysis', 'sequences-and-series', 'complex-analysis', 'holomorphic-functions']"
95,How can we evaluate $S_{N}=\sum_{k=1}^{N}\sin^2\left({x\over 2k}\right)?$,How can we evaluate,S_{N}=\sum_{k=1}^{N}\sin^2\left({x\over 2k}\right)?,I am interested in evaluating the sum of: $$S_{N}=\sum_{k=1}^{N}\sin^2\left({x\over 2k}\right)\tag1$$ Expanded $(1)$ $$\sin^2\left({x\over 2}\right)+\sin^2\left({x\over 4}\right)+\sin^2\left({x\over 6}\right)+\cdots+\sin^2\left({x\over 2N}\right)\tag2$$ Using $$\sin^2(x)+\cos^2(x)=1$$ $$S_{N}=N-\sum_{k=1}^{N}\cos^2\left({x\over 2k}\right)\tag3$$ Using $$\cos^2(x)-\sin^2(x)=\cos(2x)$$ $(1)$+$(3)\implies$ $$2S_{N}=N-\sum_{k=1}^{N}\cos\left({x\over k}\right)\tag4$$ Recall $${1\over 2}+\sum_{k=1}^{N}\cos(kx)={\sin(N+1/2)x\over 2\sin(x/2)}\tag5$$ $$\cos(A)-\cos(B)=2\sin\left({A+B\over 2}\right)\sin\left({A-B\over 2}\right)\tag6$$ $$\cos(kx)-\cos\left({x\over k}\right)=2\sin\left[x\left({k^2+1\over 2k}\right)\right]\sin\left[x\left({k^2-1\over 2k}\right)\right]\tag7$$ $(4)$+$(5)\implies$ $$2S_{N}+{\sin(N+1/2)x\over 2\sin(x/2)}=N+{1\over 2}+2\sum_{k=1}^{N}\sin\left[x\left({k^2+1\over 2k}\right)\right]\sin\left[x\left({k^2-1\over 2k}\right)\right]\tag8$$ How can we evaluate $(1)?$,I am interested in evaluating the sum of: $$S_{N}=\sum_{k=1}^{N}\sin^2\left({x\over 2k}\right)\tag1$$ Expanded $(1)$ $$\sin^2\left({x\over 2}\right)+\sin^2\left({x\over 4}\right)+\sin^2\left({x\over 6}\right)+\cdots+\sin^2\left({x\over 2N}\right)\tag2$$ Using $$\sin^2(x)+\cos^2(x)=1$$ $$S_{N}=N-\sum_{k=1}^{N}\cos^2\left({x\over 2k}\right)\tag3$$ Using $$\cos^2(x)-\sin^2(x)=\cos(2x)$$ $(1)$+$(3)\implies$ $$2S_{N}=N-\sum_{k=1}^{N}\cos\left({x\over k}\right)\tag4$$ Recall $${1\over 2}+\sum_{k=1}^{N}\cos(kx)={\sin(N+1/2)x\over 2\sin(x/2)}\tag5$$ $$\cos(A)-\cos(B)=2\sin\left({A+B\over 2}\right)\sin\left({A-B\over 2}\right)\tag6$$ $$\cos(kx)-\cos\left({x\over k}\right)=2\sin\left[x\left({k^2+1\over 2k}\right)\right]\sin\left[x\left({k^2-1\over 2k}\right)\right]\tag7$$ $(4)$+$(5)\implies$ $$2S_{N}+{\sin(N+1/2)x\over 2\sin(x/2)}=N+{1\over 2}+2\sum_{k=1}^{N}\sin\left[x\left({k^2+1\over 2k}\right)\right]\sin\left[x\left({k^2-1\over 2k}\right)\right]\tag8$$ How can we evaluate $(1)?$,,['sequences-and-series']
96,Convergence of $\sum\limits_{k=0}^\infty {\binom{z}{k}} $ for complex $z$,Convergence of  for complex,\sum\limits_{k=0}^\infty {\binom{z}{k}}  z,"For what complex values of $z$ does the following sum converge? $$\sum_{k=0}^\infty {\frac{z(z-1)\cdots(z-k+1)}{k!}} $$ And how would you prove it? Mathematica seems to suggest the sum converges as long as $\Re(z) \ge 0$ , regardless of the imaginary part.  Is that right?","For what complex values of does the following sum converge? And how would you prove it? Mathematica seems to suggest the sum converges as long as , regardless of the imaginary part.  Is that right?",z \sum_{k=0}^\infty {\frac{z(z-1)\cdots(z-k+1)}{k!}}  \Re(z) \ge 0,"['sequences-and-series', 'complex-analysis', 'convergence-divergence', 'binomial-coefficients']"
97,Definition of the $l_2$ space,Definition of the  space,l_2,"Why do we define $l_{2}$ to be the space of real sequences $(x_{k})$ such that $\sum_{k=1}^\infty\vert x_{k} \vert^{2}$ converges instead of the space of sequences such that $\sum_{k=1}^\infty x_{k}{}^{2}$ converges? $\vert x_{k}\vert^{2}=x_{k}^{2}$ after all... This question may be silly, but I want to be sure there's nothing mysterious going on here.","Why do we define $l_{2}$ to be the space of real sequences $(x_{k})$ such that $\sum_{k=1}^\infty\vert x_{k} \vert^{2}$ converges instead of the space of sequences such that $\sum_{k=1}^\infty x_{k}{}^{2}$ converges? $\vert x_{k}\vert^{2}=x_{k}^{2}$ after all... This question may be silly, but I want to be sure there's nothing mysterious going on here.",,"['sequences-and-series', 'functional-analysis']"
98,Help find closed form: $\sum_{n=1}^{\infty}\sum_{k=0}^{m}(-1)^k{m\choose k}{n-ka\over (n+m-k)^m}$,Help find closed form:,\sum_{n=1}^{\infty}\sum_{k=0}^{m}(-1)^k{m\choose k}{n-ka\over (n+m-k)^m},"We observe the double sum: $$\sum_{n=1}^{\infty}\sum_{k=0}^{m}(-1)^k{m\choose k}{n-ka\over (n+m-k)^m}=f(m,a),m\ge2\tag1$$   $a$ is not restricted We are trying to determine the closed form for $(1)$ Let expanded $(1)$ for $m=2,3$ and $4$ $$\sum_{n=1}^{\infty}{n\over (n+2)^2}-2\cdot{n-a\over (n+2)^2}+{n-2a\over n^2}=f(2,a)$$ $$\sum_{n=1}^{\infty}{n\over (n+3)^3}-3\cdot{n-a\over (n+2)^3}+3\cdot{n-2a\over (n+2)^3}-{n-3a\over n^3}=f(3,a)$$ $$\sum_{n=1}^{\infty}{n\over (n+4)^4}-4\cdot{n-a\over (n+3)^4}+6\cdot{n-2a\over (n+2)^4}-4\cdot{n-3a\over (n+1)^4}+{n-4a\over n^4}=f(4,a)$$ We was able to determine the closed form for $$f(2,a)=1-2a$$ $$f(3,a)={7\over8}(3a-1)$$ $$f(4,a)={575\over 648}(1-4a)$$ By the look of it, we can assume the general closed form $(1)$ might take the form of $$f(m,a)=(-1)^m(1-ma)g(m)$$ How can we find the general closed form for $(1)$?","We observe the double sum: $$\sum_{n=1}^{\infty}\sum_{k=0}^{m}(-1)^k{m\choose k}{n-ka\over (n+m-k)^m}=f(m,a),m\ge2\tag1$$   $a$ is not restricted We are trying to determine the closed form for $(1)$ Let expanded $(1)$ for $m=2,3$ and $4$ $$\sum_{n=1}^{\infty}{n\over (n+2)^2}-2\cdot{n-a\over (n+2)^2}+{n-2a\over n^2}=f(2,a)$$ $$\sum_{n=1}^{\infty}{n\over (n+3)^3}-3\cdot{n-a\over (n+2)^3}+3\cdot{n-2a\over (n+2)^3}-{n-3a\over n^3}=f(3,a)$$ $$\sum_{n=1}^{\infty}{n\over (n+4)^4}-4\cdot{n-a\over (n+3)^4}+6\cdot{n-2a\over (n+2)^4}-4\cdot{n-3a\over (n+1)^4}+{n-4a\over n^4}=f(4,a)$$ We was able to determine the closed form for $$f(2,a)=1-2a$$ $$f(3,a)={7\over8}(3a-1)$$ $$f(4,a)={575\over 648}(1-4a)$$ By the look of it, we can assume the general closed form $(1)$ might take the form of $$f(m,a)=(-1)^m(1-ma)g(m)$$ How can we find the general closed form for $(1)$?",,['sequences-and-series']
99,Is $\sum_{k=1}^{n} \sin(k^2)$ bounded by a constant $M$?,Is  bounded by a constant ?,\sum_{k=1}^{n} \sin(k^2) M,I know $\sum_{k=1}^{n} \sin(k)$ is bounded by a constant . How about $\sum_{k=1}^{n} \sin(k^2)$?,I know $\sum_{k=1}^{n} \sin(k)$ is bounded by a constant . How about $\sum_{k=1}^{n} \sin(k^2)$?,,"['calculus', 'sequences-and-series']"
