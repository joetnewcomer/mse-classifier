,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Proving that a function has a maximizer,Proving that a function has a maximizer,,"I am trying to prove this: Let $X$ be a nonempty, convex, and compact subset of $\mathbb{R}^n$ and $f:X \rightarrow \mathbb{R}$ a concave function. Then $f$ has a maximizer. Now this is trivial (somewhat) if f is continuous because of Weistrass' theorem. But f isn't necessarily continuous here. I have been stuck on this for a couple of days now. I can sort of imagine why this would be true if $f:\mathbb{R} \rightarrow \mathbb{R}$ . But I haven't gotten any idea further than that yet. Any help would be great!","I am trying to prove this: Let be a nonempty, convex, and compact subset of and a concave function. Then has a maximizer. Now this is trivial (somewhat) if f is continuous because of Weistrass' theorem. But f isn't necessarily continuous here. I have been stuck on this for a couple of days now. I can sort of imagine why this would be true if . But I haven't gotten any idea further than that yet. Any help would be great!",X \mathbb{R}^n f:X \rightarrow \mathbb{R} f f:\mathbb{R} \rightarrow \mathbb{R},"['functional-analysis', 'optimization']"
1,"Is the set of normal, positive, faithful, linear functionals on a W*-algebra open?","Is the set of normal, positive, faithful, linear functionals on a W*-algebra open?",,"Let $\mathcal{A}$ be an infinite-dimensional W*-algebra, that is, an infinite-dimensional $C^{*}$ -algebra which is the Banach dual of a Banach space $\mathcal{A}_{*}$ (equivalently, $\mathcal{A}$ is an abstract von Neumann algebra). Consider the so-called normal positive, linear functionals on $\mathcal{A}$ . According to the general theory of W*-algebras, these are all those positive linear functionals in the dual space $\mathcal{A}^{*}$ that are in the image $i(\mathcal{A}_{*})\subset\mathcal{A}^{*}$ of $\mathcal{A}_{*}$ in its bidual $(\mathcal{A}_{*})^{**}=\mathcal{A}^{*}$ . Now, consider the set $\mathcal{P}$ composed of all those normal,positive, linear functionals on $\mathcal{A}$ that are faithful (assuming, of course, that $\mathcal{A}$ admits normal, positive, linear functionals that are normal), that is, $\omega\in\mathcal{P}$ is such that $\omega(\mathbf{a}\mathbf{a}^{\dagger})=0$ for some $\mathbf{a}\in\mathcal{A}$ implies $\mathbf{a}=\mathbf{0}$ . Is the set $\mathcal{P}$ open in $\mathcal{A}^{*}$ and/or $\mathcal{A}_{*}$ ?","Let be an infinite-dimensional W*-algebra, that is, an infinite-dimensional -algebra which is the Banach dual of a Banach space (equivalently, is an abstract von Neumann algebra). Consider the so-called normal positive, linear functionals on . According to the general theory of W*-algebras, these are all those positive linear functionals in the dual space that are in the image of in its bidual . Now, consider the set composed of all those normal,positive, linear functionals on that are faithful (assuming, of course, that admits normal, positive, linear functionals that are normal), that is, is such that for some implies . Is the set open in and/or ?",\mathcal{A} C^{*} \mathcal{A}_{*} \mathcal{A} \mathcal{A} \mathcal{A}^{*} i(\mathcal{A}_{*})\subset\mathcal{A}^{*} \mathcal{A}_{*} (\mathcal{A}_{*})^{**}=\mathcal{A}^{*} \mathcal{P} \mathcal{A} \mathcal{A} \omega\in\mathcal{P} \omega(\mathbf{a}\mathbf{a}^{\dagger})=0 \mathbf{a}\in\mathcal{A} \mathbf{a}=\mathbf{0} \mathcal{P} \mathcal{A}^{*} \mathcal{A}_{*},"['functional-analysis', 'c-star-algebras']"
2,"Question about a ""w.l.o.g."" statement in proof of Uncertainty Principle?","Question about a ""w.l.o.g."" statement in proof of Uncertainty Principle?",,"I read a proof on the Uncertainty Principle (see below) and although the technical part itself is relatively straight forward I still do not understand a certain ""w.l.o.g."" statement in the proof. Uncertainty Principle : For $f\in L^2(\mathbb R)$ and $a,b\in\mathbb R$ we have $$\|(x-a)f(x)\|_2\cdot\|(x-b)\hat f(x)\|_2\geq\frac12\|f\|_2^2,$$ where $$\hat f(x):=\frac1{\sqrt{2\pi}}\int_{\mathbb R}f(\xi)e^{-i\xi x}d\xi$$ denotes the Fourier transform of $f$ . The proof asserts that it suffices to show the statement for $a=b=0$ . But why? I don't see how to substitute $f$ in $$\|xf(x)\|_2\cdot\|x\hat f(x)\|_2\geq\frac12\|f\|_2^2$$ such that the inequality becomes $$\|(x-a)f(x)\|_2\cdot\|(x-b)\hat f(x)\|_2\geq\frac12\|f\|_2^2$$ The norm $\|\cdot\|_2$ might be invariant under translation, so that I get $$   \begin{align*}     \|xf(x)\|_2&=\|(x-a)f(x-a)\|_2=\|(x-a)g(x)\|_2,&&g:=T_af\text{ and} \\     \|x\hat f(x)\|_2&=\|(x-b)\hat f(x-b)\|_2=\|(x-b)T_b\hat f(x)\|_2=\|(x-b)\hat h(x)\|_2,&&h:=M_bf,   \end{align*} $$ where $T_af(x):=f(x-a)$ is the translation operator and $M_bf(x):=f(x)e^{ibx}$ is the modulation operator, but surely $g$ and $h$ aren't equal. How do I get from $a=b=0$ to the general case?","I read a proof on the Uncertainty Principle (see below) and although the technical part itself is relatively straight forward I still do not understand a certain ""w.l.o.g."" statement in the proof. Uncertainty Principle : For and we have where denotes the Fourier transform of . The proof asserts that it suffices to show the statement for . But why? I don't see how to substitute in such that the inequality becomes The norm might be invariant under translation, so that I get where is the translation operator and is the modulation operator, but surely and aren't equal. How do I get from to the general case?","f\in L^2(\mathbb R) a,b\in\mathbb R \|(x-a)f(x)\|_2\cdot\|(x-b)\hat f(x)\|_2\geq\frac12\|f\|_2^2, \hat f(x):=\frac1{\sqrt{2\pi}}\int_{\mathbb R}f(\xi)e^{-i\xi x}d\xi f a=b=0 f \|xf(x)\|_2\cdot\|x\hat f(x)\|_2\geq\frac12\|f\|_2^2 \|(x-a)f(x)\|_2\cdot\|(x-b)\hat f(x)\|_2\geq\frac12\|f\|_2^2 \|\cdot\|_2 
  \begin{align*}
    \|xf(x)\|_2&=\|(x-a)f(x-a)\|_2=\|(x-a)g(x)\|_2,&&g:=T_af\text{ and} \\
    \|x\hat f(x)\|_2&=\|(x-b)\hat f(x-b)\|_2=\|(x-b)T_b\hat f(x)\|_2=\|(x-b)\hat h(x)\|_2,&&h:=M_bf,
  \end{align*}
 T_af(x):=f(x-a) M_bf(x):=f(x)e^{ibx} g h a=b=0",['functional-analysis']
3,Deforming a linear map a little preserves surjectivity,Deforming a linear map a little preserves surjectivity,,"Let $X$ be a Banach space, and $A: X\to X$ be a surjective linear map. Define $$\eta(A) = \{\lambda\in \mathbb{C}: A - \lambda I \text{ is surjective}\}$$ where $I: X\to X$ is the identity. Show that $\eta(A)$ is an open subset of $\mathbb{C}$ . This is a problem from a graduate qualifying exam and I'm a bit stuck on it—it suffices to show that a neighborhood of $0$ in $\mathbb{C}$ is contained in $\eta(A)$ . My initial idea was something like ""given $Ax \in X$ , consider $y\in A^{-1}(Ax + \lambda x)$ . This $y$ should under $A - \lambda I$ map to someone close to $Ax$ , if $\lambda$ is small. Then we use the difference between $Ay - \lambda y$ and $Ax$ to adjust $y$ . We repeat and hope we get convergence"". And that's about all I've got so far, but it requires the open mapping theorem, which requires $A$ to be continuous. Can the problem even be done without the continuity of $A$ ? Any help is appreciated, regarding whether the problem is possible without the continuity of $A$ and how actually to prove the result. Edit: this is Problem 6 of UCLA’s analysis qual from Spring 2007.","Let be a Banach space, and be a surjective linear map. Define where is the identity. Show that is an open subset of . This is a problem from a graduate qualifying exam and I'm a bit stuck on it—it suffices to show that a neighborhood of in is contained in . My initial idea was something like ""given , consider . This should under map to someone close to , if is small. Then we use the difference between and to adjust . We repeat and hope we get convergence"". And that's about all I've got so far, but it requires the open mapping theorem, which requires to be continuous. Can the problem even be done without the continuity of ? Any help is appreciated, regarding whether the problem is possible without the continuity of and how actually to prove the result. Edit: this is Problem 6 of UCLA’s analysis qual from Spring 2007.",X A: X\to X \eta(A) = \{\lambda\in \mathbb{C}: A - \lambda I \text{ is surjective}\} I: X\to X \eta(A) \mathbb{C} 0 \mathbb{C} \eta(A) Ax \in X y\in A^{-1}(Ax + \lambda x) y A - \lambda I Ax \lambda Ay - \lambda y Ax y A A A,['functional-analysis']
4,$G$ has Kazhdan's property (T) $\iff$ $G$ has a Kazhdan pair,has Kazhdan's property (T)   has a Kazhdan pair,G \iff G,"A locally compact group $G$ is said to be Kazhdan or have Property (T)  if for any unitary representation $\rho$ that has almost invariant vectors (a.i.v) it has an invariant vector. Meaning of a.i.v - for all $K \subseteq G$ compact and $\epsilon > 0$ there exists a $(K, \epsilon)$ invariant vector - $\left\lVert v \right\rVert =1$ such that $$\left\lVert\rho (g)v-v \right\rVert < \epsilon$$ $(K, \epsilon)$ is said to be a Kazhdan pair if for all unitary representations of $G$ that has a $(K, \epsilon)$ invariant vector it has an invariant vector. Apparently $G$ is Kazhdan if and only if it has a Kazhdan pair. It's easy to see that existence of Kazhdan pair implies Kazhdan, but I did not manage to prove the opposite direction. I know that $G$ is compactly generated and that if I can show that $G$ has a $(K,\epsilon)$ invariant vector for all $\epsilon>0$ and for the generating set $K$ then I'm finished, but I don't know haw to choose my $\epsilon$ . I hope I was clear, thank you in advance.","A locally compact group is said to be Kazhdan or have Property (T)  if for any unitary representation that has almost invariant vectors (a.i.v) it has an invariant vector. Meaning of a.i.v - for all compact and there exists a invariant vector - such that is said to be a Kazhdan pair if for all unitary representations of that has a invariant vector it has an invariant vector. Apparently is Kazhdan if and only if it has a Kazhdan pair. It's easy to see that existence of Kazhdan pair implies Kazhdan, but I did not manage to prove the opposite direction. I know that is compactly generated and that if I can show that has a invariant vector for all and for the generating set then I'm finished, but I don't know haw to choose my . I hope I was clear, thank you in advance.","G \rho K \subseteq G \epsilon > 0 (K, \epsilon) \left\lVert v \right\rVert =1 \left\lVert\rho (g)v-v \right\rVert < \epsilon (K, \epsilon) G (K, \epsilon) G G G (K,\epsilon) \epsilon>0 K \epsilon","['group-theory', 'functional-analysis']"
5,"An optimization problem in $L^1(0,1)$",An optimization problem in,"L^1(0,1)","Is there any non-negative function $f(t)$ that minimizes $\int_0^1e^{\int_0^tf(s)ds}dt$ and satisfies $\int_0^1sf(s)ds =1$ ? I guess there is not, because the exponential is minimized if $\int_0^tf(s)ds$ is as small as possible. However, for such functions there can never be $\int_0^1sf(s)ds\neq 0$ .","Is there any non-negative function that minimizes and satisfies ? I guess there is not, because the exponential is minimized if is as small as possible. However, for such functions there can never be .",f(t) \int_0^1e^{\int_0^tf(s)ds}dt \int_0^1sf(s)ds =1 \int_0^tf(s)ds \int_0^1sf(s)ds\neq 0,"['real-analysis', 'functional-analysis', 'optimization', 'convex-analysis', 'convex-optimization']"
6,$T=AU \iff T $ is a normal operator on Hilbert space,is a normal operator on Hilbert space,T=AU \iff T ,"This is Exercise 16.(c) from Conway's Functional Analysis book. Suppose $H$ is a Hilbert space and $T$ is a compact operator on $H$ . Assuming the result that $\exists A$ positive operator and $U$ a bounded operator such that $T=UA$ (NOTE: here $A= \sqrt {T^* T} $ and $U$ is the operator defined as in the construction of the polar decomposition i.e. $\|Uh\|=\|h\|$ when $h \perp \ker(T)$ and $Uh=0$ when $h \in\ker(T)$ i.e. $U(Ah)=Th$ when $h \perp \ker(A)=\bar{Ran(A)}$ and $Uh=0$ when $h\in\ker(A)$ ) , I have to prove : $T=AU \iff T $ is normal I tried to compute products and tried to show the one direction that ( $T=AU \implies T $ is normal) , but since $U$ is just assumed to be bounded, not unitary, got stuck! EDIT : For $T$ Normal ,assuming $U$ to be unitary ( we can do that provided $T$ is normal), have been able to show that $AU=UA$ . But for the other direction, ( $T=AU=UA \implies T$ normal), got, $T^*T=AU^*UA$ and $TT^* = AU^*UA$ . So if U is at least normal, we are done! (as mentioned in an answer) . But , we have to be careful, because by construction of $U$ and $A$ , it is not clear to me how is $U$ normal. ( since we are trying to show that $T$ is normal, we cannot assume beforehand that $U$ is unitary, like the other direction) Please help!","This is Exercise 16.(c) from Conway's Functional Analysis book. Suppose is a Hilbert space and is a compact operator on . Assuming the result that positive operator and a bounded operator such that (NOTE: here and is the operator defined as in the construction of the polar decomposition i.e. when and when i.e. when and when ) , I have to prove : is normal I tried to compute products and tried to show the one direction that ( is normal) , but since is just assumed to be bounded, not unitary, got stuck! EDIT : For Normal ,assuming to be unitary ( we can do that provided is normal), have been able to show that . But for the other direction, ( normal), got, and . So if U is at least normal, we are done! (as mentioned in an answer) . But , we have to be careful, because by construction of and , it is not clear to me how is normal. ( since we are trying to show that is normal, we cannot assume beforehand that is unitary, like the other direction) Please help!",H T H \exists A U T=UA A= \sqrt {T^* T}  U \|Uh\|=\|h\| h \perp \ker(T) Uh=0 h \in\ker(T) U(Ah)=Th h \perp \ker(A)=\bar{Ran(A)} Uh=0 h\in\ker(A) T=AU \iff T  T=AU \implies T  U T U T AU=UA T=AU=UA \implies T T^*T=AU^*UA TT^* = AU^*UA U A U T U,['functional-analysis']
7,How to find infimum and supremum of an inequality?,How to find infimum and supremum of an inequality?,,"Given $A=\{x\in \mathbb{R}: (2x^2+x-21)(x^2+2x)<0\}$ , I want to find $\inf(A)$ and $\sup(A)$ and to if it admits minimum and/or maximum. First of all, I've solved the inequality, which gives me that for $]-2:-\frac{7}{2}[$ and $]0:3[$ is negative, whereas the other parts of the domain are positive. I think the maximum of the function, in this case, are indeed $-2;-\frac{7}{2};0;3$ , but I don't know how to find $\inf(A)$ . Moreover, how do I know if it admits minimum and/or maximum?","Given , I want to find and and to if it admits minimum and/or maximum. First of all, I've solved the inequality, which gives me that for and is negative, whereas the other parts of the domain are positive. I think the maximum of the function, in this case, are indeed , but I don't know how to find . Moreover, how do I know if it admits minimum and/or maximum?",A=\{x\in \mathbb{R}: (2x^2+x-21)(x^2+2x)<0\} \inf(A) \sup(A) ]-2:-\frac{7}{2}[ ]0:3[ -2;-\frac{7}{2};0;3 \inf(A),"['real-analysis', 'calculus', 'functional-analysis']"
8,Graded $*$-homomorphisms where are homotopic to $0$,Graded -homomorphisms where are homotopic to,* 0,"This is an Exercise 3.15, pg 42. Show that the map between $\Bbb Z/2 \Bbb Z$ - graded $C^*$ -algebras $$C_0(\Bbb R) \rightarrow M_2(\Bbb C)$$ $$ \varphi: f \mapsto \begin{pmatrix} f(0) & 0 \\  0 & f(0) \end{pmatrix} $$ is homotopic (through graded $*$ -homomoprhisms) to the $0$ homomoprhisms. Whereas the $*$ -homomorphism $$ \psi:f \mapsto \begin{pmatrix} f(0) & 0 \\ 0 & 0  \end{pmatrix} $$ is not null homotopic. By definition in page 41, the even of $M_2(\Bbb C)$ consists of diagonal elemnts, the odd are those of off diagonals. My questions would be: 1. How does one construction this homotopy? 2. How does one show the non-homotopy for second part?","This is an Exercise 3.15, pg 42. Show that the map between - graded -algebras is homotopic (through graded -homomoprhisms) to the homomoprhisms. Whereas the -homomorphism is not null homotopic. By definition in page 41, the even of consists of diagonal elemnts, the odd are those of off diagonals. My questions would be: 1. How does one construction this homotopy? 2. How does one show the non-homotopy for second part?","\Bbb Z/2 \Bbb Z C^* C_0(\Bbb R) \rightarrow M_2(\Bbb C)  \varphi: f \mapsto \begin{pmatrix}
f(0) & 0 \\ 
0 & f(0)
\end{pmatrix}
 * 0 * 
\psi:f \mapsto \begin{pmatrix}
f(0) & 0 \\
0 & 0 
\end{pmatrix}
 M_2(\Bbb C)","['functional-analysis', 'algebraic-topology', 'operator-theory', 'homotopy-theory', 'operator-algebras']"
9,Proving a Certain Functional is Coercive,Proving a Certain Functional is Coercive,,"Let $\Omega\subset \mathbb{R}^n$ be a domain in $\mathbb{R}^n$ with $C^1$ boundary and let $J:\mathscr{H}^{1}_0(\Omega) \to \mathbb{R}$ be given by: $$ J(v) = \int_\Omega |v(x)|^p\mathrm{d}x $$ where $p <\frac{2n}{n-2}$ I want to show that $J$ is coercive, i.e $\lim_{\|v\|_{\mathscr{H}^{1}_0(\Omega)} \to \infty} |J(v)| = \infty$ to set up a later maximization problem. I have tried using a host of inequalities (Sobolev, Holder interpolation) to show the above limit, but they have all failed. The main issue occurs when the $L^2$ norm of $\nabla u$ grows unboundedly, but the $L^2$ norm of $u$ does not. Of course, the $L^2$ norm of $u$ can be controlled above by the norm of its gradient (Poincare inequality), but this does not give us control of the norms from below, which is what I seek.","Let be a domain in with boundary and let be given by: where I want to show that is coercive, i.e to set up a later maximization problem. I have tried using a host of inequalities (Sobolev, Holder interpolation) to show the above limit, but they have all failed. The main issue occurs when the norm of grows unboundedly, but the norm of does not. Of course, the norm of can be controlled above by the norm of its gradient (Poincare inequality), but this does not give us control of the norms from below, which is what I seek.","\Omega\subset \mathbb{R}^n \mathbb{R}^n C^1 J:\mathscr{H}^{1}_0(\Omega) \to \mathbb{R} 
J(v) = \int_\Omega |v(x)|^p\mathrm{d}x
 p <\frac{2n}{n-2} J \lim_{\|v\|_{\mathscr{H}^{1}_0(\Omega)} \to \infty} |J(v)| = \infty L^2 \nabla u L^2 u L^2 u","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'calculus-of-variations']"
10,"$A(D) \subseteq Y$ is closed, if $X$ is reflexive, $Y$ is Banach and $D \subseteq X$ is closed, convex and bounded.","is closed, if  is reflexive,  is Banach and  is closed, convex and bounded.",A(D) \subseteq Y X Y D \subseteq X,"Exercise : Let $X$ be a reflexive Banach space and $Y$ a Banach space. Also, let $A \in \mathcal{L}(X,Y)$ and $D \subseteq X$ be a closed, convex and bounded space. Show that $A(D) \subseteq Y$ is closed. Discussion : I know that for $A(D)$ to be closed, theoritically one should show that every sequence in $A(D)$ converges in $A(D)$ . Also, since $Y$ is Banach, if $A(D)$ is closed it should also be Banach, so that may be a way of showing that it is closed. After doing some research, I came across some posts quoting the Banach-Alaoglu theorem, but this is something I haven't been taught, so I guess there should be a more elaborate way around. Any hints or elaborations will be greatly appreciated.","Exercise : Let be a reflexive Banach space and a Banach space. Also, let and be a closed, convex and bounded space. Show that is closed. Discussion : I know that for to be closed, theoritically one should show that every sequence in converges in . Also, since is Banach, if is closed it should also be Banach, so that may be a way of showing that it is closed. After doing some research, I came across some posts quoting the Banach-Alaoglu theorem, but this is something I haven't been taught, so I guess there should be a more elaborate way around. Any hints or elaborations will be greatly appreciated.","X Y A \in \mathcal{L}(X,Y) D \subseteq X A(D) \subseteq Y A(D) A(D) A(D) Y A(D)","['functional-analysis', 'operator-theory', 'banach-spaces', 'reflexive-space']"
11,A Continuous function $f: \overline{B_1(0)} \subset \ell^2\to \mathbb{R}$ which does not reach the maximum?,A Continuous function  which does not reach the maximum?,f: \overline{B_1(0)} \subset \ell^2\to \mathbb{R},"If necessary, recall that $$ \ell^2 = \{x=\{x_n\}_n\subset \mathbb{R} : \|x\|^2:=\sum_n |x|^2<\infty\} $$ and $ \overline{B_1(0)} $ is the closed unit ball with respect to that norm. Can we find an explicit example of a continuous function $f: \overline{B_1(0)} \subset \ell^2\to \mathbb{R}$ which does not attain its maximum? The point is that this ball is not a compact set. Thank you.","If necessary, recall that and is the closed unit ball with respect to that norm. Can we find an explicit example of a continuous function which does not attain its maximum? The point is that this ball is not a compact set. Thank you.","
\ell^2 = \{x=\{x_n\}_n\subset \mathbb{R} : \|x\|^2:=\sum_n |x|^2<\infty\}
  \overline{B_1(0)}  f: \overline{B_1(0)} \subset \ell^2\to \mathbb{R}","['real-analysis', 'functional-analysis', 'special-functions']"
12,How can I prove that the Hilbert transform on the 1-torus doesn't map $L^1(\mathbb{T})$ into itself?,How can I prove that the Hilbert transform on the 1-torus doesn't map  into itself?,L^1(\mathbb{T}),"Let $\mathbb{T}$ be the 1-torus. Then, it is well defined the Hilbert transform: $$\mathcal{H}:L^1(\mathbb{T})\to L^0(\mathbb{T}), \vartheta\mapsto\int_{-\pi}^\pi f(\vartheta-t)\cot\left(\frac{t}{2}\right) \frac{\operatorname{d}t}{2\pi}.$$ I know that $\mathcal{H}$ is weak-(1,1), i.e. that there exists a constant $C>0$ such that: $$\forall f\in L^1(\mathbb{T}), \forall \lambda>0, \left|\left\{\vartheta\in\mathbb{T} : |\mathcal{H}(f)(\vartheta)|>\lambda \right\}\right|\le C\frac{\|f\|_1}{\lambda}.$$ In my lecture notes it is stated without proof that $\mathcal H$ doesn't map $L^1(\mathbb{T})$ into itself. I'm thinking about how to prove this claim. I can prove that doesn't exist an operator $\mathcal{G}: L^1(\mathbb{T})\to L^1(\mathbb{T})$ such that $$\forall f\in L^1(\mathbb{T}), \forall n\in\mathbb{Z}, \mathcal{F}(\mathcal{G}(f))(n) = -i \operatorname{sgn}(n)\mathcal{F}(f)(n),$$ where $\mathcal{F}$ is the Fourier transform. Also, I know that $$\forall p\in(1,+\infty), \forall f\in L^p(\mathbb{T}), \left(\mathcal{H(f)}\in L^p(\mathbb{T})\right)\land \left(\mathcal{F}(\mathcal{H}(f))(n) = -i \operatorname{sgn}(n)\mathcal{F}(f)(n)\right).$$ Now, if I only could prove that "" $\mathcal{H}$ maps $L^1(\mathbb{T})$ into itself"" would imply "" $\mathcal{H}: L^1(\mathbb{T})\to L^1(\mathbb{T})$ with continuity"", then the claim that $\mathcal H$ doesn't map $L^1(\mathbb{T})$ in itself  would follows from a density and continuity argument. However I can't see how to prove that the only fact that $\mathcal{H}$ maps $L^1(\mathbb{T})$ into itselt would imply its continuity (I thought to use something like the closed graph theorem, but I can't see how it could apply here). Any help?","Let be the 1-torus. Then, it is well defined the Hilbert transform: I know that is weak-(1,1), i.e. that there exists a constant such that: In my lecture notes it is stated without proof that doesn't map into itself. I'm thinking about how to prove this claim. I can prove that doesn't exist an operator such that where is the Fourier transform. Also, I know that Now, if I only could prove that "" maps into itself"" would imply "" with continuity"", then the claim that doesn't map in itself  would follows from a density and continuity argument. However I can't see how to prove that the only fact that maps into itselt would imply its continuity (I thought to use something like the closed graph theorem, but I can't see how it could apply here). Any help?","\mathbb{T} \mathcal{H}:L^1(\mathbb{T})\to L^0(\mathbb{T}), \vartheta\mapsto\int_{-\pi}^\pi f(\vartheta-t)\cot\left(\frac{t}{2}\right) \frac{\operatorname{d}t}{2\pi}. \mathcal{H} C>0 \forall f\in L^1(\mathbb{T}), \forall \lambda>0, \left|\left\{\vartheta\in\mathbb{T} : |\mathcal{H}(f)(\vartheta)|>\lambda \right\}\right|\le C\frac{\|f\|_1}{\lambda}. \mathcal H L^1(\mathbb{T}) \mathcal{G}: L^1(\mathbb{T})\to L^1(\mathbb{T}) \forall f\in L^1(\mathbb{T}), \forall n\in\mathbb{Z}, \mathcal{F}(\mathcal{G}(f))(n) = -i \operatorname{sgn}(n)\mathcal{F}(f)(n), \mathcal{F} \forall p\in(1,+\infty), \forall f\in L^p(\mathbb{T}), \left(\mathcal{H(f)}\in L^p(\mathbb{T})\right)\land \left(\mathcal{F}(\mathcal{H}(f))(n) = -i \operatorname{sgn}(n)\mathcal{F}(f)(n)\right). \mathcal{H} L^1(\mathbb{T}) \mathcal{H}: L^1(\mathbb{T})\to L^1(\mathbb{T}) \mathcal H L^1(\mathbb{T}) \mathcal{H} L^1(\mathbb{T})","['functional-analysis', 'fourier-analysis', 'harmonic-analysis', 'integral-transforms', 'weak-lp-spaces']"
13,Orthogonal projection onto the closure of a subspace spanned by a set of orthonormal vectors,Orthogonal projection onto the closure of a subspace spanned by a set of orthonormal vectors,,"Suppose $H$ is a Hilbert space and $\{e_1,\cdots\}$ is a set of infinitely many orthonormal vectors. Then let $M$ be the closure of the subspace spanned by these orthonormal vectors. I know that for $f\in H$ , the orthogonal projection of $f$ onto $M$ is given by $$\sum_i \langle f,e_i \rangle e_i$$ However, How can I justify that the infinite sum converges? My way is to extend these orthonormal vectors to an orthonormal basis. So we have $\{e_i\} \cup \{h_j\}$ as an orthonormal basis. Then $f=\sum_i \langle f,e_i \rangle e_i + \sum_j \langle f,h_j \rangle h_j$ . So that the concerned infinite sum must converge. However, extending these vectors to an orthonormal basis will use Zorn's Lemma. Is there any other argument to justify the convergence of $\sum_i \langle f,e_i \rangle e_i$ ?","Suppose is a Hilbert space and is a set of infinitely many orthonormal vectors. Then let be the closure of the subspace spanned by these orthonormal vectors. I know that for , the orthogonal projection of onto is given by However, How can I justify that the infinite sum converges? My way is to extend these orthonormal vectors to an orthonormal basis. So we have as an orthonormal basis. Then . So that the concerned infinite sum must converge. However, extending these vectors to an orthonormal basis will use Zorn's Lemma. Is there any other argument to justify the convergence of ?","H \{e_1,\cdots\} M f\in H f M \sum_i \langle f,e_i \rangle e_i \{e_i\} \cup \{h_j\} f=\sum_i \langle f,e_i \rangle e_i + \sum_j \langle f,h_j \rangle h_j \sum_i \langle f,e_i \rangle e_i","['functional-analysis', 'hilbert-spaces']"
14,Fixed point existence for a function satisfying a certain condition,Fixed point existence for a function satisfying a certain condition,,"Let $T:\mathbb{R}\to\mathbb{R}$ satisfying $$ |Tx - Ty| \leq \frac{1+\max({|x|,|y|})}{2+\max({|x|,|y|})}|x-y| $$ for every $x,y\in\mathbb{R}$ . Show that it has a unique fixed point. The thing is that this function is a weak contraction. I tried to repeat the proof of Banach's Theorem, but I did not get anything from that. Any ideas?","Let satisfying for every . Show that it has a unique fixed point. The thing is that this function is a weak contraction. I tried to repeat the proof of Banach's Theorem, but I did not get anything from that. Any ideas?","T:\mathbb{R}\to\mathbb{R} 
|Tx - Ty| \leq \frac{1+\max({|x|,|y|})}{2+\max({|x|,|y|})}|x-y|
 x,y\in\mathbb{R}","['real-analysis', 'functional-analysis']"
15,Strong limit of operator to spectral projection,Strong limit of operator to spectral projection,,"here's a claim made in Reed & Simon which I do not know how to prove : Given $B$ a (positive) operator of some $L^2(M, d\nu)$ such that $\Vert B \Vert = 1$ and $1$ is an (non-degenerate) eigenvalue of $B$ (with stricly positive eigenvector). Then : $$  \Vert B^n - P_{\{1\}} \Vert \longrightarrow 0 $$ where $P_{\{1\}}$ is the orthogonal projection onto $Ker(B - Id)$ . This claim appears in some proof where some hypothesis are made on B (those indicated in parenthesis). Maybe those are useless, but I've put them anyway. According to authors, the claim follows from functional calculus . Any help is greatly appreciated.","here's a claim made in Reed & Simon which I do not know how to prove : Given a (positive) operator of some such that and is an (non-degenerate) eigenvalue of (with stricly positive eigenvector). Then : where is the orthogonal projection onto . This claim appears in some proof where some hypothesis are made on B (those indicated in parenthesis). Maybe those are useless, but I've put them anyway. According to authors, the claim follows from functional calculus . Any help is greatly appreciated.","B L^2(M, d\nu) \Vert B \Vert = 1 1 B 
 \Vert B^n - P_{\{1\}} \Vert \longrightarrow 0
 P_{\{1\}} Ker(B - Id)","['functional-analysis', 'operator-theory']"
16,Weak Convergence Lemma - Is Banach needed?,Weak Convergence Lemma - Is Banach needed?,,"Lemma. Let $X$ be a normed space. If $x_n \rightharpoonup x$ in $X$ and $x_n^* \to x^*$ in $X^*$ , then $\lim_{n \to \infty} x_n^*(x_n) = x^*(x)$ . If $X$ is even Banach, then $x_n \to x$ in $X$ and $x_n^* \overset{*}\rightharpoonup x^*$ in $X^*$ implies $\lim_{n \to \infty} x_n^*(x_n) = x^*(x)$ . The lecture notes I work with, had this wrong at first - it didn't include Banach for the second statement. (The proof uses boundedness of $(x_n^*)$ which relies on Banach-Steinhaus!) Is Banach really needed, though? Does anyone have a counterexample?","Lemma. Let be a normed space. If in and in , then . If is even Banach, then in and in implies . The lecture notes I work with, had this wrong at first - it didn't include Banach for the second statement. (The proof uses boundedness of which relies on Banach-Steinhaus!) Is Banach really needed, though? Does anyone have a counterexample?",X x_n \rightharpoonup x X x_n^* \to x^* X^* \lim_{n \to \infty} x_n^*(x_n) = x^*(x) X x_n \to x X x_n^* \overset{*}\rightharpoonup x^* X^* \lim_{n \to \infty} x_n^*(x_n) = x^*(x) (x_n^*),"['functional-analysis', 'banach-spaces', 'weak-convergence']"
17,Find the support of $T(\phi) = \sum_{j = 1}^{+\infty} \frac{1}{j}(\phi(\frac{1}{j}) - \phi(0))$,Find the support of,T(\phi) = \sum_{j = 1}^{+\infty} \frac{1}{j}(\phi(\frac{1}{j}) - \phi(0)),"the distribution not being defined through a locally integrable function then the support is the complement open set on which $T$ vanishes. if we consider test function with support not including $[0,1]$ then $T(\phi) = 0$ , intuitively the support then must be $[0,1]$ but I'm having difficulties to prove it formally, i.e is to prove that $]-\infty,0[ \cup]1,+\infty[$ is indeed the biggest open set on which $T$ vanishes. how to prove it ?","the distribution not being defined through a locally integrable function then the support is the complement open set on which vanishes. if we consider test function with support not including then , intuitively the support then must be but I'm having difficulties to prove it formally, i.e is to prove that is indeed the biggest open set on which vanishes. how to prove it ?","T [0,1] T(\phi) = 0 [0,1] ]-\infty,0[ \cup]1,+\infty[ T","['functional-analysis', 'distribution-theory']"
18,"Need Hint; Show that the Limit Exists when $f\in C^1(0,1)$ and...",Need Hint; Show that the Limit Exists when  and...,"f\in C^1(0,1)","The problem is as follows: Assume that $f\in C^1(0,1)$ and $$ \int_{(0,1)}x|f'|^p\,dx<+\infty\qquad\text{for some }p>2. $$ Show that $\lim_{x\rightarrow 0^+}f(x)$ exists. Note: $C^1(0,1)$ is the space of continuously differentiable functions on $(0,1)$ . What I've considered so far; I know that $x\in C^1(0,1)$ . I know that $f$ is differentiable. I know that the definition of the right-hand limit here will be important (which I have written down on my scratch work). However, I am having difficulty in figuring out where to continue off from here. I think I might be missing some important Theorem.","The problem is as follows: Assume that and Show that exists. Note: is the space of continuously differentiable functions on . What I've considered so far; I know that . I know that is differentiable. I know that the definition of the right-hand limit here will be important (which I have written down on my scratch work). However, I am having difficulty in figuring out where to continue off from here. I think I might be missing some important Theorem.","f\in C^1(0,1) 
\int_{(0,1)}x|f'|^p\,dx<+\infty\qquad\text{for some }p>2.
 \lim_{x\rightarrow 0^+}f(x) C^1(0,1) (0,1) x\in C^1(0,1) f","['real-analysis', 'functional-analysis']"
19,Extreme points and closure of a set in $l^2(\mathbb{N})$,Extreme points and closure of a set in,l^2(\mathbb{N}),"Consider the subset C of the banach space $l^2(\mathbb{N})$ defined by \begin{equation} C = \left\{ x \in l^2(\mathbb{N}) \,\Bigg|\, \sum_{n = 0}^{\infty} (n+1) x(n) = 1, \, \, x(n) \geq 0 \, \forall  n \in \mathbb{N} \right\} \end{equation} It is easy to prove this set is convex. If $x, y \in C$ then $\lambda x + (1-\lambda)y \in C$ for $\lambda \in [0,1]$ since \begin{align} \sum_{n = 0}^{\infty} (n+1)(\lambda x(n) + (1-\lambda)y(n)) &= \lambda \sum_{n = 0}^{\infty} (x+1)x(n) + (1-\lambda) \sum_{n = 0}^{\infty} (n+1)y(n) \\&= \lambda + (1- \lambda) = 1. \end{align} It is given that it's extreme points are the following elements \begin{equation} \delta_n: \mathbb{N} \to \mathbb{C}: m \mapsto \begin{cases} \frac{1}{n+1} \,\, &\text{for} \,\, m = n\\ 0 \,\, &\text{else}\end{cases} \end{equation} My question is: how does one prove these are the only extreme points of $C$ . And also what is the closure of $C$ ?",Consider the subset C of the banach space defined by It is easy to prove this set is convex. If then for since It is given that it's extreme points are the following elements My question is: how does one prove these are the only extreme points of . And also what is the closure of ?,"l^2(\mathbb{N}) \begin{equation}
C = \left\{ x \in l^2(\mathbb{N}) \,\Bigg|\, \sum_{n = 0}^{\infty} (n+1) x(n) = 1, \, \, x(n) \geq 0 \, \forall  n \in \mathbb{N} \right\}
\end{equation} x, y \in C \lambda x + (1-\lambda)y \in C \lambda \in [0,1] \begin{align}
\sum_{n = 0}^{\infty} (n+1)(\lambda x(n) + (1-\lambda)y(n)) &= \lambda \sum_{n = 0}^{\infty} (x+1)x(n) + (1-\lambda) \sum_{n = 0}^{\infty} (n+1)y(n) \\&= \lambda + (1- \lambda) = 1.
\end{align} \begin{equation}
\delta_n: \mathbb{N} \to \mathbb{C}: m \mapsto \begin{cases} \frac{1}{n+1} \,\, &\text{for} \,\, m = n\\
0 \,\, &\text{else}\end{cases}
\end{equation} C C",['functional-analysis']
20,"""Standard reference"" for $C_c^\infty(\mathbb R)$ is dense in $C_c(\mathbb R)$","""Standard reference"" for  is dense in",C_c^\infty(\mathbb R) C_c(\mathbb R),"$C_c^\infty(\mathbb R)$ is dense in $C_c(\mathbb R)$ . This can be shown by mollification. This is a well-known, widely used fact. However, I wasn't able to find any book which I could point in a reference to. Is there any kind of ""standard reference"" with a readable proof?","is dense in . This can be shown by mollification. This is a well-known, widely used fact. However, I wasn't able to find any book which I could point in a reference to. Is there any kind of ""standard reference"" with a readable proof?",C_c^\infty(\mathbb R) C_c(\mathbb R),"['functional-analysis', 'reference-request', 'smooth-functions']"
21,find adjoint operator of an operator A,find adjoint operator of an operator A,,"How to find adjoint operator of an operator A $$A \in B(C^1[0,1], C[0,1])$$ $$ (Ax)(t) = x'(t)?$$ In answer : for any functional $f_y$ originated by function $y \in BV_0[0,1]:A(f'_y) = g_z$ , where functional $g_z$ originated by couple of function $z(t) = y(t)$ and number zero. Have no idea how to find. Can you help me with this?","How to find adjoint operator of an operator A In answer : for any functional originated by function , where functional originated by couple of function and number zero. Have no idea how to find. Can you help me with this?","A \in B(C^1[0,1], C[0,1])  (Ax)(t) = x'(t)? f_y y \in BV_0[0,1]:A(f'_y) = g_z g_z z(t) = y(t)",['functional-analysis']
22,Compactness of a specific set in weak topology,Compactness of a specific set in weak topology,,"I have the following question: Let $E$ be a polish space (that is, a topological space, which is separable and metrizable, such that $E$ would be complete if equipped with this metric). Consider the space of probability measures on $E$ , denoted by $\mathcal M (E)$ equipped with the topology of weak convergence. The claim I am struggling with is the following: For every $\ell\in\Bbb N$ let $K_\ell$ be a compact set of $E$ . Then the set $$\bigcap_{\ell\in\Bbb N} \{ m \in \mathcal M (E): m(K^{\operatorname{c}}_\ell) \leq \frac 1 \ell \}$$ is compact.","I have the following question: Let be a polish space (that is, a topological space, which is separable and metrizable, such that would be complete if equipped with this metric). Consider the space of probability measures on , denoted by equipped with the topology of weak convergence. The claim I am struggling with is the following: For every let be a compact set of . Then the set is compact.",E E E \mathcal M (E) \ell\in\Bbb N K_\ell E \bigcap_{\ell\in\Bbb N} \{ m \in \mathcal M (E): m(K^{\operatorname{c}}_\ell) \leq \frac 1 \ell \},"['general-topology', 'functional-analysis', 'measure-theory', 'weak-convergence', 'topological-vector-spaces']"
23,Is the natural embedding from $X$ to $X^{**}$ a homeomorphism with respect to the weak topologies if $X$ is reflexive?,Is the natural embedding from  to  a homeomorphism with respect to the weak topologies if  is reflexive?,X X^{**} X,"If $X$ is a reflexive Banach space, is it true that the natural embedding $\Lambda$ of $X$ into its double dual is a homeomorphism? Here we equip $X$ with the weak topology, and $X^{**}$ with the weak-* topology, i.e. $\sigma(X^{**},X^*)$ . I think that this is true. To start with I have shown that it is at least continuous by using nets. I also wanted to show that the inverse is continuous (but I could not figure this out using nets), but here's how far I got: So assume that the net $f_a \rightarrow f$ weakly (here the $f_a$ lie in $X^{**}$ ). We want to show $\Lambda^{-1}(f_a) \rightarrow \Lambda^{-1}(f)$ weakly. Note that $f_a \rightarrow f$ weakly is equivalent to $f_a(x) \rightarrow f(x)$ for all $x \in X^{*}$ . And that the conclusion is equivalent to $x(\Lambda^{-1}(f_a)) \rightarrow x(\Lambda^{-1}(f))$ weakly for all $x \in X^*$ . This is where I'm getting a bit confused: Is $x(\Lambda^{-1}(f_a))=f_a(x)$ ?","If is a reflexive Banach space, is it true that the natural embedding of into its double dual is a homeomorphism? Here we equip with the weak topology, and with the weak-* topology, i.e. . I think that this is true. To start with I have shown that it is at least continuous by using nets. I also wanted to show that the inverse is continuous (but I could not figure this out using nets), but here's how far I got: So assume that the net weakly (here the lie in ). We want to show weakly. Note that weakly is equivalent to for all . And that the conclusion is equivalent to weakly for all . This is where I'm getting a bit confused: Is ?","X \Lambda X X X^{**} \sigma(X^{**},X^*) f_a \rightarrow f f_a X^{**} \Lambda^{-1}(f_a) \rightarrow \Lambda^{-1}(f) f_a \rightarrow f f_a(x) \rightarrow f(x) x \in X^{*} x(\Lambda^{-1}(f_a)) \rightarrow x(\Lambda^{-1}(f)) x \in X^* x(\Lambda^{-1}(f_a))=f_a(x)","['functional-analysis', 'banach-spaces']"
24,A question about the Residue of $h=fg$,A question about the Residue of,h=fg,"Let $f$ and $g$ be two functions (not necessarily analytic) of the complex variable $z$ such that for some $\varepsilon >0$ : 1) $f$ is continuous on $0<\left\vert z\right\vert <\varepsilon $ 2) $g$ is continuous on $\left\vert z\right\vert <\varepsilon $ and $% g\left( 0\right) \neq 0$ 3) $h=fg$ is analytic on $0<\left\vert z\right\vert <\varepsilon .$ Do we have \begin{equation*} Res\left( h,0\right) =\frac{g\left( 0\right) }{2\pi i}\oint_{\left\vert z\right\vert =\frac{\varepsilon }{2}}f\left( z\right) dz \end{equation*} Or perhaps some other equation ? Thank you !",Let and be two functions (not necessarily analytic) of the complex variable such that for some : 1) is continuous on 2) is continuous on and 3) is analytic on Do we have Or perhaps some other equation ? Thank you !,"f g z \varepsilon >0 f 0<\left\vert z\right\vert <\varepsilon  g \left\vert z\right\vert <\varepsilon  %
g\left( 0\right) \neq 0 h=fg 0<\left\vert z\right\vert <\varepsilon . \begin{equation*}
Res\left( h,0\right) =\frac{g\left( 0\right) }{2\pi i}\oint_{\left\vert
z\right\vert =\frac{\varepsilon }{2}}f\left( z\right) dz
\end{equation*}","['integration', 'complex-analysis', 'functional-analysis', 'contour-integration', 'residue-calculus']"
25,Arbitrary close and norm-bounded approximations to an element in a Banach space from a dense subset,Arbitrary close and norm-bounded approximations to an element in a Banach space from a dense subset,,"I have an element $e \in E$ , where $E$ is a Banach space, and $\lVert e\rVert=l$ . I also have a subset $Y$ which is dense in $E$ . Does this mean that we can find element $y\in Y$ s.t. $\lVert y - e\rVert \le \frac{l}{2}$ and $\lVert y\rVert \le l$ ? If so, why? I have the feeling that a Banach space is like the Euclidean space $\mathbf R^n$ so to speak continuous and we can find elements arbitrary close to an element. Thanks in advance!","I have an element , where is a Banach space, and . I also have a subset which is dense in . Does this mean that we can find element s.t. and ? If so, why? I have the feeling that a Banach space is like the Euclidean space so to speak continuous and we can find elements arbitrary close to an element. Thanks in advance!",e \in E E \lVert e\rVert=l Y E y\in Y \lVert y - e\rVert \le \frac{l}{2} \lVert y\rVert \le l \mathbf R^n,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
26,"$L(V,\mathbb{R})$ with $\|\cdot\|_1$ complete?",with  complete?,"L(V,\mathbb{R}) \|\cdot\|_1","Let $(V,\|\cdot\|_V)$ and $(W,\|\cdot\|_W)$ be normed vector spaces. By $L(V,W)$ we denote the space of bounded linear operators from $V$ to $W.$ If $W$ is complete, then $L(V,W)$ with the operator norm $\|T\| := \sup \left\{\|Tu\|_W : \|u\|_V \leq 1\right\}$ is a Banach space. Now assume in addition that $\gamma$ is probability measure on $V$ with $\mathrm{supp}\, \gamma = V$ and with existing first moment. My Question: Is $L(V,\mathbb{R})$ closed subspace in $(\mathrm{L}_1(V),\|\cdot\|_1)$ ? In this case $L(V,\mathbb{R})$ with $\|\cdot\|_1$ would also be a Banach space.","Let and be normed vector spaces. By we denote the space of bounded linear operators from to If is complete, then with the operator norm is a Banach space. Now assume in addition that is probability measure on with and with existing first moment. My Question: Is closed subspace in ? In this case with would also be a Banach space.","(V,\|\cdot\|_V) (W,\|\cdot\|_W) L(V,W) V W. W L(V,W) \|T\| := \sup \left\{\|Tu\|_W : \|u\|_V \leq 1\right\} \gamma V \mathrm{supp}\, \gamma = V L(V,\mathbb{R}) (\mathrm{L}_1(V),\|\cdot\|_1) L(V,\mathbb{R}) \|\cdot\|_1","['general-topology', 'functional-analysis', 'lp-spaces']"
27,Separating Hyperplanes and Hahn-Banach,Separating Hyperplanes and Hahn-Banach,,"Let $f:X \rightarrow \mathbb{R}$ be convex, $x \in X$ . Assume further that $f$ is continuous and finite in $x.$ Then it says that by Hahn-Banach there is $x^* \in X^*$ with \begin{equation} \langle y - x, x^* \rangle_{X \times X^*} + f(x) \leq f(y) \ \ \ \forall y \in X. \end{equation} I'm trying to understand why this is true. As far as I know, by Hahn-Banach we can separate the convex set given by the points above the graph of $f$ from the point $(x,f(x))$ by some hyperplane. More generally, for $A,B \subset X$ , $A\cap B= \emptyset$ convex sets with $A$ open there is $x^* \in X^*$ and $\gamma \in \mathbb{R}$ such that \begin{equation} \langle a,x^* \rangle _{X \times X^*} \leq \gamma \leq \langle b,x^* \rangle _{X \times X^*} \ \ \ \forall a\in A,\ b \in B. \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  (1)   \end{equation} Intuitively, the above estimate makes sense. The desired hyperplane is an affine function below the graph of $f$ which intersects with the graph in the point $(x,f(x))$ . But I would like to understand how this follows from the formal statement $(1)$ in the Hahn-Banach Theorem. Thank you for any help.","Let be convex, . Assume further that is continuous and finite in Then it says that by Hahn-Banach there is with I'm trying to understand why this is true. As far as I know, by Hahn-Banach we can separate the convex set given by the points above the graph of from the point by some hyperplane. More generally, for , convex sets with open there is and such that Intuitively, the above estimate makes sense. The desired hyperplane is an affine function below the graph of which intersects with the graph in the point . But I would like to understand how this follows from the formal statement in the Hahn-Banach Theorem. Thank you for any help.","f:X \rightarrow \mathbb{R} x \in X f x. x^* \in X^* \begin{equation}
\langle y - x, x^* \rangle_{X \times X^*} + f(x) \leq f(y) \ \ \ \forall y \in X.
\end{equation} f (x,f(x)) A,B \subset X A\cap B= \emptyset A x^* \in X^* \gamma \in \mathbb{R} \begin{equation}
\langle a,x^* \rangle _{X \times X^*} \leq \gamma \leq \langle b,x^* \rangle _{X \times X^*} \ \ \ \forall a\in A,\ b \in B. \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  (1)  
\end{equation} f (x,f(x)) (1)","['functional-analysis', 'convex-analysis']"
28,Eigenvalues and power of a operator,Eigenvalues and power of a operator,,"If $\lambda$ is an eigenvalue of $A^k$ , prove that at least one of the $k^{th}$ roots of $\lambda$ is an eigenvalue of $A$ . I know it is easy to prove when $A$ can be presented by a matrix, but $A$ is an operator on a complex inner product space, which may be infinite dimensional.","If is an eigenvalue of , prove that at least one of the roots of is an eigenvalue of . I know it is easy to prove when can be presented by a matrix, but is an operator on a complex inner product space, which may be infinite dimensional.",\lambda A^k k^{th} \lambda A A A,"['functional-analysis', 'operator-theory']"
29,"Showing that $\bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| \geq \bigg\|x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\|$",Showing that,"\bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| \geq \bigg\|x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\|","Exercise : Let $\{e_1,e_2,\dots, e_n\}$ be an orthonormal set over the Hilbert space $H$ . Show that : $$\bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| \geq \bigg\|x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\|$$ for every $\lambda_1,\lambda_2,\dots,\lambda_n \in \mathbb R$ . Attempt : Let $x \in H$ and $\varepsilon > 0$ . Then,  we can find $\lambda_1,\dots, \lambda_n \in \mathbb R$ such that : $$\bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| < \varepsilon$$ But the element $w = x-\sum_{k=1}^n\langle x,e_k\rangle e_k$ achieves the minimum distance of $x$ from the finite dimensional space $ F = \langle e_1,\dots, e_n \rangle$ and then it will be $$\bigg\| x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\| \leq \bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| < \varepsilon$$ and thus the inequality which we were asked to show is proven. Question : Is my approach rigorous and legit enough ? If not, any recommendations, hints or elaborations will be greatly appreciated !","Exercise : Let be an orthonormal set over the Hilbert space . Show that : for every . Attempt : Let and . Then,  we can find such that : But the element achieves the minimum distance of from the finite dimensional space and then it will be and thus the inequality which we were asked to show is proven. Question : Is my approach rigorous and legit enough ? If not, any recommendations, hints or elaborations will be greatly appreciated !","\{e_1,e_2,\dots, e_n\} H \bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| \geq \bigg\|x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\| \lambda_1,\lambda_2,\dots,\lambda_n \in \mathbb R x \in H \varepsilon > 0 \lambda_1,\dots, \lambda_n \in \mathbb R \bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| < \varepsilon w = x-\sum_{k=1}^n\langle x,e_k\rangle e_k x  F = \langle e_1,\dots, e_n \rangle \bigg\| x-\sum_{k=1}^n\langle x,e_k\rangle e_k \bigg\| \leq \bigg\| x - \sum_{k=1}^n \lambda_ke_k\bigg\| < \varepsilon","['real-analysis', 'functional-analysis', 'hilbert-spaces', 'normed-spaces', 'inner-products']"
30,Proving that $\|T\|=\max\{\sqrt{\lambda};\;\lambda\in \sigma(T^*T)\}$.,Proving that .,\|T\|=\max\{\sqrt{\lambda};\;\lambda\in \sigma(T^*T)\},"Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on an infinite-dimensional complex Hilbert space $F$ . It is well known that if $T\in \mathcal{B}(F)$ , then $$\|T\|=\displaystyle\sup_{\|x\|=1}\|Tx\|.$$ I want to prove that for $T\in \mathcal{B}(F)$ , we have $$\|T\|=\max\{\sqrt{\lambda};\;\lambda\in \sigma(T^*T)=\sigma(TT^*)\},$$ where $\sigma(A)$ denotes the spectrum of an operator $A$ .","Let the algebra of all bounded linear operators on an infinite-dimensional complex Hilbert space . It is well known that if , then I want to prove that for , we have where denotes the spectrum of an operator .","\mathcal{B}(F) F T\in \mathcal{B}(F) \|T\|=\displaystyle\sup_{\|x\|=1}\|Tx\|. T\in \mathcal{B}(F) \|T\|=\max\{\sqrt{\lambda};\;\lambda\in \sigma(T^*T)=\sigma(TT^*)\}, \sigma(A) A","['functional-analysis', 'reference-request', 'operator-theory']"
31,What Are the Irreducible Representations of the Rational Rotation C$^{*}$-algebra?,What Are the Irreducible Representations of the Rational Rotation C-algebra?,^{*},"Let $m$ and $n$ be integers, with $n>0$ and $\gcd(m,n)=1$ . Let $\theta=m/n$ and let $A_{\theta}$ be the rational rotation C $^{*}$ -algebra generated by two unitaries $u$ and $v$ , satisfying the relation $vu=e^{2\pi i \theta}uv$ . I am working on an exercise in Davidson's C $^{*}$ -algebra and my goal is to Find all irreducible representations of $A_{\theta}$ and show that they lie in $M_{n}(\mathbb{C})$ . I was able to show that $u^{n}$ and $v^{n}$ lie in the center of $A_{\theta}$ . Thus, if $\pi\colon A_{\theta}\to B(H)$ is an irreducible representation of $A_{\theta}$ , it must be that $\pi(u^{n})$ and $\pi(v^{n})$ are scalar multiples of the identity. Using this I can show that the set $S=\{\pi(u)^{j}\pi(v)^{k}:0\leq j,k\leq n-1\}$ linearly spans $\pi(A_{\theta})$ . Thus, $\dim(\pi)\leq n$ . But I don't know how to rule out the case that $\dim(\pi)< n$ or how to go about finding all of the irreps.","Let and be integers, with and . Let and let be the rational rotation C -algebra generated by two unitaries and , satisfying the relation . I am working on an exercise in Davidson's C -algebra and my goal is to Find all irreducible representations of and show that they lie in . I was able to show that and lie in the center of . Thus, if is an irreducible representation of , it must be that and are scalar multiples of the identity. Using this I can show that the set linearly spans . Thus, . But I don't know how to rule out the case that or how to go about finding all of the irreps.","m n n>0 \gcd(m,n)=1 \theta=m/n A_{\theta} ^{*} u v vu=e^{2\pi i \theta}uv ^{*} A_{\theta} M_{n}(\mathbb{C}) u^{n} v^{n} A_{\theta} \pi\colon A_{\theta}\to B(H) A_{\theta} \pi(u^{n}) \pi(v^{n}) S=\{\pi(u)^{j}\pi(v)^{k}:0\leq j,k\leq n-1\} \pi(A_{\theta}) \dim(\pi)\leq n \dim(\pi)< n","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
32,Is weak derivative a bounded operator from $H^k(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$?,Is weak derivative a bounded operator from  to ?,H^k(\mathbb{R}^n) L^2(\mathbb{R}^n),"I'm struggling to become comfortable with the concept of the weak derivative and Sobolev space. In my textbook, it is proved that the Sobolev space $H^k(\mathbb{R}^n)$ is a Hilbert space, and it is also proved that the weak derivative $D$ is a closed operator from $H^k(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$ . Does this mean that $D$ is a bounded operator? I guess so because a closed operator defined everywhere in a Hilbert space is bounded. Is that also mean $D$ is bounded as an operator from $L^2(\mathbb{R}^n)$ to $L^2(\mathbb{R}^n)$ with domain $H^k(\mathbb{R}^n)$ ?","I'm struggling to become comfortable with the concept of the weak derivative and Sobolev space. In my textbook, it is proved that the Sobolev space is a Hilbert space, and it is also proved that the weak derivative is a closed operator from to . Does this mean that is a bounded operator? I guess so because a closed operator defined everywhere in a Hilbert space is bounded. Is that also mean is bounded as an operator from to with domain ?",H^k(\mathbb{R}^n) D H^k(\mathbb{R}^n) L^2(\mathbb{R}^n) D D L^2(\mathbb{R}^n) L^2(\mathbb{R}^n) H^k(\mathbb{R}^n),"['functional-analysis', 'sobolev-spaces', 'weak-derivatives']"
33,Paley-Wiener type integral: Conditions for the integrand $f$,Paley-Wiener type integral: Conditions for the integrand,f,"Let $(B_t)_{t \geq 0}$ be a Brownian Motion with $B_0=0$ . Then define the stochastic integral for $f \in C^1([0,1], \mathbb{R})$ ( $f$ does not have to be in $BV$ ) via an integration by parts formula, involving a ""normal"" Riemann-type integral: $$ \int_0^1 f(s)dB_s=f(1)B_1-\int_0^1f'(s)B_sds $$ For this type of stochastic integral, there is supposed to hold the isometry: $$ \mathbb{E}\ [\big(\int_0^1 f(s)dB_s)^2    ]=\int_0^1 f(s)^2ds $$ Using lenghty calculations, involving the identites $\mathbb{E}[B_r B_s]=\min(r,s)$ , Fubinis Theorem, splitting up integrals, finding a closed ""form"" for $\min(s,r)$ under the integral as well as $\frac{d}{ds}f(s)^2=2f'(s)f(s)$ and the integration by parts formula $\int_a^b f'(s)s=f(s)s|_a^b-\int_a^b f(s)$ , I could not get the desired result. Instead, I got stuck with terms involving $f(1)$ , not involving a square (the squares could have canceled out with $\mathbb{E}[B_1^2f(1)^2]=f(1)^2$ ). My question is: Is there any type of (boundary) conditions required for the functions that can be integrated via this stochastic integral? A condition like e.g. $f(1)=0$ would be the simplest way to provide a solution. I am aware that my condition mentioned above does not seem to be a necessary condition, as the constant case $f(s)=c \neq 0$ shows. Edit: For clarification, the leftover term had the form $f(1)\int_0^1 f′(s)sds$ , see the answer by zhoraster for more details.","Let be a Brownian Motion with . Then define the stochastic integral for ( does not have to be in ) via an integration by parts formula, involving a ""normal"" Riemann-type integral: For this type of stochastic integral, there is supposed to hold the isometry: Using lenghty calculations, involving the identites , Fubinis Theorem, splitting up integrals, finding a closed ""form"" for under the integral as well as and the integration by parts formula , I could not get the desired result. Instead, I got stuck with terms involving , not involving a square (the squares could have canceled out with ). My question is: Is there any type of (boundary) conditions required for the functions that can be integrated via this stochastic integral? A condition like e.g. would be the simplest way to provide a solution. I am aware that my condition mentioned above does not seem to be a necessary condition, as the constant case shows. Edit: For clarification, the leftover term had the form , see the answer by zhoraster for more details.","(B_t)_{t \geq 0} B_0=0 f \in C^1([0,1], \mathbb{R}) f BV 
\int_0^1 f(s)dB_s=f(1)B_1-\int_0^1f'(s)B_sds
 
\mathbb{E}\ [\big(\int_0^1 f(s)dB_s)^2    ]=\int_0^1 f(s)^2ds
 \mathbb{E}[B_r B_s]=\min(r,s) \min(s,r) \frac{d}{ds}f(s)^2=2f'(s)f(s) \int_a^b f'(s)s=f(s)s|_a^b-\int_a^b f(s) f(1) \mathbb{E}[B_1^2f(1)^2]=f(1)^2 f(1)=0 f(s)=c \neq 0 f(1)\int_0^1 f′(s)sds","['real-analysis', 'functional-analysis', 'stochastic-processes', 'stochastic-integrals']"
34,Differentiation Operator is not a bounded operator for polynomials,Differentiation Operator is not a bounded operator for polynomials,,"If you consider the space of all polynomials on [0,1] (defined as $P_{[0,1]}$ as subspace of $C_{[0,1]}$ ) then the differentiation operator is not a linear bounded operator on this space. Why is that? this doesn' t make any sense to me.","If you consider the space of all polynomials on [0,1] (defined as as subspace of ) then the differentiation operator is not a linear bounded operator on this space. Why is that? this doesn' t make any sense to me.","P_{[0,1]} C_{[0,1]}","['linear-algebra', 'functional-analysis', 'linear-transformations']"
35,"what is meant by ""the integral is interpreted in the weak sense""?","what is meant by ""the integral is interpreted in the weak sense""?",,"What is meant by the integral is interpreted in the weak sense in following corollary: on page 261 of the book ""An introduction to frame and Riesz bases"", second edition,  by Ole Christenson. There is no an explanation in the book.","What is meant by the integral is interpreted in the weak sense in following corollary: on page 261 of the book ""An introduction to frame and Riesz bases"", second edition,  by Ole Christenson. There is no an explanation in the book.",,"['real-analysis', 'functional-analysis', 'partial-differential-equations', 'terminology', 'lebesgue-integral']"
36,Extensions of amenable groups,Extensions of amenable groups,,"Let $1 \to N \to G \to Q \to 1$ be an extension of (discrete) groups, where $N$ and $Q$ are amenable. Using the fixed-point theorem, I know how to show that $G$ is amenable. However, I was wondering if there is a proof which only uses the Følner property, namely $G$ is amenable if and only if: for every finite $S \subset G$ and for every $\epsilon > 0$ there exists some finite $A \subset G$ such that $|SA \Delta A| < \epsilon |A|$ . I am asking this since in some texts this is used as the actual definition of an amenable group.","Let be an extension of (discrete) groups, where and are amenable. Using the fixed-point theorem, I know how to show that is amenable. However, I was wondering if there is a proof which only uses the Følner property, namely is amenable if and only if: for every finite and for every there exists some finite such that . I am asking this since in some texts this is used as the actual definition of an amenable group.",1 \to N \to G \to Q \to 1 N Q G G S \subset G \epsilon > 0 A \subset G |SA \Delta A| < \epsilon |A|,"['abstract-algebra', 'group-theory', 'functional-analysis', 'geometric-group-theory', 'amenability']"
37,characteristic function of a convolution of measures,characteristic function of a convolution of measures,,"Take the probability measures $\mu,\nu$ on $\mathbb{R}$ and denote $\varphi_{\mu}$ (the same for $\nu$) its characteristic function. Why holds $$\varphi_{\mu *\nu}(t)=\varphi_{\mu}(t)\cdot\varphi_{\nu}(t)$$ where $\mu*\nu$ denotes the convolution of $\mu$ and $\nu$?","Take the probability measures $\mu,\nu$ on $\mathbb{R}$ and denote $\varphi_{\mu}$ (the same for $\nu$) its characteristic function. Why holds $$\varphi_{\mu *\nu}(t)=\varphi_{\mu}(t)\cdot\varphi_{\nu}(t)$$ where $\mu*\nu$ denotes the convolution of $\mu$ and $\nu$?",,"['probability', 'functional-analysis', 'convolution', 'characteristic-functions']"
38,Exercise 3 of Lecture notes for 18.155 On concentration compactness and soliton solutions for the NLS equation,Exercise 3 of Lecture notes for 18.155 On concentration compactness and soliton solutions for the NLS equation,,"As picture below, I want to prove the Proposition 2.1. I want to use Poincare inequality, but fail. How should I do it ? Thanks for any answer or hint.","As picture below, I want to prove the Proposition 2.1. I want to use Poincare inequality, but fail. How should I do it ? Thanks for any answer or hint.",,"['functional-analysis', 'partial-differential-equations']"
39,"Proof attempt at ""Adjoint of compact operator is compact"" on Banach spaces","Proof attempt at ""Adjoint of compact operator is compact"" on Banach spaces",,"I was trying to prove this result and this is my attempt. Theorem [Schauder] Let $E,F$ be Banach spaces, and let $T:E\to F$ a compact operator. Then its adjoint   $T^*:F^*\to E^*$ is compact. Proof attempt. An operator between Banach spaces is compact iff the image of any bounded sequence has a Cauchy subsequence. So let $\left\{ v_n\right\}\subset F^*$ be a bounded sequence, with $\|v_n\|\leq C$. By the sequential Banach-Alaoglu's theorem, $\left\{ v_n\right\}$ has a weakly-star converging subsequence to some $\bar{v}\in F^*$, which we keep calling $\left\{ v_n\right\}$. Thus $$|\left\langle v_{n}-\bar{v},y\right\rangle| \to 0,\qquad \forall y\in F   $$ To prove the thesis, we need to show that $\left\{ A^*v_n\right\}$ has a Cauchy subsequence,  which we keep calling $\left\{ A^*v_n\right\}$. Let $B_E$ be the closed unit ball of $E$; we have \begin{align*}\|A^*v_n-A^*v_m\|_{E^*}&=\sup_{x\in B_E}|\left\langle A^*v_n-A^*v_m,x\right\rangle|=\sup_{x\in B_E}|\left\langle v_n-v_m,Ax\right\rangle|=\\  &=\sup_{y\in T(B_E)}|\left\langle v_n-v_m,y\right\rangle| \end{align*} so it suffices to show that the latter term converges to $0$ as $n,m\to +\infty$.\ To this purpose, since $T$ is compact, then $B':=\overline{T(B_E)}$ is compact in $F$. Thus, for all $n\in\mathbb{N}$ there is $y_n\in B'$ such that  $$\sup_{y\in T(E)}|\left\langle v_n-\bar{v},y\right\rangle|\leq \sup_{y\in B}|\left\langle v_n-\bar{v},y\right\rangle|= |\left\langle v_n-\bar{v},y_n\right\rangle|$$ Since $\left\{y_n\right\}\subset B'$ and $B'$ is compact, $\left\{y_n\right\}$ has a converging subsequence, which we keep calling $\left\{ y_n\right\}$, so that $y_n\to \bar{y}\in B'$. Thus  \begin{align*}|\left\langle v_n-\bar{v},y_n\right\rangle|&\leq |\left\langle v_n-\bar{v},y_n-\bar{y}\right\rangle|+|\left\langle v_n-\bar{v},\bar{y}\right\rangle|\leq\\   &\leq   2C\|y_n-\bar{y}\|+ |\left\langle v_n-\bar{v},\bar{y}\right\rangle|\to 0 \end{align*} And finally  $$\sup_{y\in T(E)}|\left\langle v_n-v_m,y\right\rangle|\leq \sup_{y\in T(E)}|\left\langle v_n-\bar{v},y\right\rangle|+ \sup_{y\in T(E)}|\left\langle \bar{v}-v_m,y\right\rangle|\to 0$$ and the thesis is proved. The problem is that the sequential Banach Alaoglu's theorem holds only when $E$ is separable. Is there a way I could adapt this proof to the general case? Maybe using nets instead of sequences?","I was trying to prove this result and this is my attempt. Theorem [Schauder] Let $E,F$ be Banach spaces, and let $T:E\to F$ a compact operator. Then its adjoint   $T^*:F^*\to E^*$ is compact. Proof attempt. An operator between Banach spaces is compact iff the image of any bounded sequence has a Cauchy subsequence. So let $\left\{ v_n\right\}\subset F^*$ be a bounded sequence, with $\|v_n\|\leq C$. By the sequential Banach-Alaoglu's theorem, $\left\{ v_n\right\}$ has a weakly-star converging subsequence to some $\bar{v}\in F^*$, which we keep calling $\left\{ v_n\right\}$. Thus $$|\left\langle v_{n}-\bar{v},y\right\rangle| \to 0,\qquad \forall y\in F   $$ To prove the thesis, we need to show that $\left\{ A^*v_n\right\}$ has a Cauchy subsequence,  which we keep calling $\left\{ A^*v_n\right\}$. Let $B_E$ be the closed unit ball of $E$; we have \begin{align*}\|A^*v_n-A^*v_m\|_{E^*}&=\sup_{x\in B_E}|\left\langle A^*v_n-A^*v_m,x\right\rangle|=\sup_{x\in B_E}|\left\langle v_n-v_m,Ax\right\rangle|=\\  &=\sup_{y\in T(B_E)}|\left\langle v_n-v_m,y\right\rangle| \end{align*} so it suffices to show that the latter term converges to $0$ as $n,m\to +\infty$.\ To this purpose, since $T$ is compact, then $B':=\overline{T(B_E)}$ is compact in $F$. Thus, for all $n\in\mathbb{N}$ there is $y_n\in B'$ such that  $$\sup_{y\in T(E)}|\left\langle v_n-\bar{v},y\right\rangle|\leq \sup_{y\in B}|\left\langle v_n-\bar{v},y\right\rangle|= |\left\langle v_n-\bar{v},y_n\right\rangle|$$ Since $\left\{y_n\right\}\subset B'$ and $B'$ is compact, $\left\{y_n\right\}$ has a converging subsequence, which we keep calling $\left\{ y_n\right\}$, so that $y_n\to \bar{y}\in B'$. Thus  \begin{align*}|\left\langle v_n-\bar{v},y_n\right\rangle|&\leq |\left\langle v_n-\bar{v},y_n-\bar{y}\right\rangle|+|\left\langle v_n-\bar{v},\bar{y}\right\rangle|\leq\\   &\leq   2C\|y_n-\bar{y}\|+ |\left\langle v_n-\bar{v},\bar{y}\right\rangle|\to 0 \end{align*} And finally  $$\sup_{y\in T(E)}|\left\langle v_n-v_m,y\right\rangle|\leq \sup_{y\in T(E)}|\left\langle v_n-\bar{v},y\right\rangle|+ \sup_{y\in T(E)}|\left\langle \bar{v}-v_m,y\right\rangle|\to 0$$ and the thesis is proved. The problem is that the sequential Banach Alaoglu's theorem holds only when $E$ is separable. Is there a way I could adapt this proof to the general case? Maybe using nets instead of sequences?",,"['functional-analysis', 'operator-theory', 'compactness']"
40,Why a spectral resolution should be left-continuous?,Why a spectral resolution should be left-continuous?,,"The usual definition I can find (almost) everywhere on the literature of a spectral resolution on a Hilbert space $\mathscr{H}$ is this: a family of orthogonal projections $(E_t)_{t \in \mathbb{R}}$ such that $t \leq s \implies E_t \leq E_s$ $\lim_{t \rightarrow -\infty} E_t = 0 \ , \quad \lim_{t \rightarrow +\infty} E_t$ $\lim_{t \searrow s} E_t = E_s$, where the limit is always taken in the strong topology sense. I wonder why one would ask the property 3 of a spectral resolution and not left-continuity. I've heard that right-continuity should actually be a better choice for a measure-theoretical reason: we can always take the limit of a measure of a sequence of increasing measurable sets and that doesn't work always if the sequence is decreasing, but I'm not convinced of that.","The usual definition I can find (almost) everywhere on the literature of a spectral resolution on a Hilbert space $\mathscr{H}$ is this: a family of orthogonal projections $(E_t)_{t \in \mathbb{R}}$ such that $t \leq s \implies E_t \leq E_s$ $\lim_{t \rightarrow -\infty} E_t = 0 \ , \quad \lim_{t \rightarrow +\infty} E_t$ $\lim_{t \searrow s} E_t = E_s$, where the limit is always taken in the strong topology sense. I wonder why one would ask the property 3 of a spectral resolution and not left-continuity. I've heard that right-continuity should actually be a better choice for a measure-theoretical reason: we can always take the limit of a measure of a sequence of increasing measurable sets and that doesn't work always if the sequence is decreasing, but I'm not convinced of that.",,"['functional-analysis', 'spectral-theory']"
41,Semi-inner product structure in complex Hilbert spaces,Semi-inner product structure in complex Hilbert spaces,,"Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on a complex Hilbert space $(F,\langle\cdot,\cdot\rangle)$. Any $M\in \mathcal{B}(F)^+$ (i.e. $\langle Mx\;, \;x\rangle\geq 0$ for all $x\in F$) induces a semi-inner product on $F$ defined as: $$\langle\cdot,\cdot\rangle_{M}:F\times F\longrightarrow\mathbb{C},\;(x,y)\longmapsto\langle Mx, y\rangle,$$ Now let    \begin{equation*} \mathbb{M}=\begin{pmatrix}A & B \\ C & D \end{pmatrix} \end{equation*}   be a positive operator on $F\oplus F$. Does $\mathbb{M}$ induces a semi-inner product on $F\oplus F$? Note that the inner product on $F\oplus F$ is defined as follows: If $x=\begin{pmatrix} x_1\\ x_2\end{pmatrix}\in F\oplus F$ with $x_1,x_2\in F$, and $x'=\begin{pmatrix}x_1'\\ x_2'\end{pmatrix}$ similarly, then $$\langle x,x'\rangle_{F\oplus F}:= \langle x_1,x_1'\rangle_F +\langle x_2,x_2'\rangle_F.$$","Let $\mathcal{B}(F)$ the algebra of all bounded linear operators on a complex Hilbert space $(F,\langle\cdot,\cdot\rangle)$. Any $M\in \mathcal{B}(F)^+$ (i.e. $\langle Mx\;, \;x\rangle\geq 0$ for all $x\in F$) induces a semi-inner product on $F$ defined as: $$\langle\cdot,\cdot\rangle_{M}:F\times F\longrightarrow\mathbb{C},\;(x,y)\longmapsto\langle Mx, y\rangle,$$ Now let    \begin{equation*} \mathbb{M}=\begin{pmatrix}A & B \\ C & D \end{pmatrix} \end{equation*}   be a positive operator on $F\oplus F$. Does $\mathbb{M}$ induces a semi-inner product on $F\oplus F$? Note that the inner product on $F\oplus F$ is defined as follows: If $x=\begin{pmatrix} x_1\\ x_2\end{pmatrix}\in F\oplus F$ with $x_1,x_2\in F$, and $x'=\begin{pmatrix}x_1'\\ x_2'\end{pmatrix}$ similarly, then $$\langle x,x'\rangle_{F\oplus F}:= \langle x_1,x_1'\rangle_F +\langle x_2,x_2'\rangle_F.$$",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'inner-products']"
42,A question about Bochner's theorem.,A question about Bochner's theorem.,,"I am studying Fourier analysis and finding two Bochner's theorem: Bochner's theorem VERSION  $1$ : In order that a function $f:\mathbb{R}^d\rightarrow \mathbb{R}$ be positive definite and continuous, it is necessary and sufficient that it be the Fourier transform of a nonnegative finite-valued Borel measure on $\mathbb{R}^d$. [In Cheney's book---A course in approximation theory] VERSION  $2$ :   Let $f:\mathbb{R}^d\to \mathbb{R}$ be a bounded and continuous function on $\mathbb{R}^d$. Then $f$ is a positive semi-definite function on $\mathbb{R}^d$ if and only if there is a probability measure $\mu$ on $\mathbb{R}^d$ such that $$ f(x) =f(0) \int_{\mathbb{R}^d} e^{2\pi i x\cdot \xi}\, d\mu(\xi),\   \ \forall x\in \mathbb{R}^d.$$ [In my course note] My question is in the necessary parts of version 1 and 2. I am wondering whether they are same? or is there a relationship between them? In my understanding, VERSION $1$ says if $f$ is a positive definite then it be the Fourier transform of a Borel measure. But in VERSION  $2$ , it says if $f$ is a positive semi-definite then it be the inverse Fourier transform of a Borel measure(i.e. the probability measure in version 2). Thanks in advance!","I am studying Fourier analysis and finding two Bochner's theorem: Bochner's theorem VERSION  $1$ : In order that a function $f:\mathbb{R}^d\rightarrow \mathbb{R}$ be positive definite and continuous, it is necessary and sufficient that it be the Fourier transform of a nonnegative finite-valued Borel measure on $\mathbb{R}^d$. [In Cheney's book---A course in approximation theory] VERSION  $2$ :   Let $f:\mathbb{R}^d\to \mathbb{R}$ be a bounded and continuous function on $\mathbb{R}^d$. Then $f$ is a positive semi-definite function on $\mathbb{R}^d$ if and only if there is a probability measure $\mu$ on $\mathbb{R}^d$ such that $$ f(x) =f(0) \int_{\mathbb{R}^d} e^{2\pi i x\cdot \xi}\, d\mu(\xi),\   \ \forall x\in \mathbb{R}^d.$$ [In my course note] My question is in the necessary parts of version 1 and 2. I am wondering whether they are same? or is there a relationship between them? In my understanding, VERSION $1$ says if $f$ is a positive definite then it be the Fourier transform of a Borel measure. But in VERSION  $2$ , it says if $f$ is a positive semi-definite then it be the inverse Fourier transform of a Borel measure(i.e. the probability measure in version 2). Thanks in advance!",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'positive-definite']"
43,Arzela-Ascoli Theorem for a specific family of functions on $\mathbb{R}$,Arzela-Ascoli Theorem for a specific family of functions on,\mathbb{R},"Let $f : \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function. Assume that $f(x) > 0$ for all $x \in \mathbb{R}$, but $f$ decays to $0$ at $\infty, -\infty.$ Let $\{f_n\}$ be a sequence of real-valued equicontinuous functions on $\mathbb{R}.$ Assume that $$|f_n(x)| \leq f(x)$$ for all $n$ and $x.$ Verify that $\{f_n\}$ has a uniformly convergent subsequence. $\textbf{Proof} \ $ Since $f$ decays at $\infty$ and $-\infty,$ there exists $M > 0$ such that $|f(x)| < 1$ for $|x|>M$. Since $[-M, M]$ is compact and $f$ is continuous, there is $K > 0$such that $|f(x)| \leq K$ with $x \in [-M,M].$ So $|f_n(x)| \leq |f(x)| \leq K+1$ for all $n, x.$ That is, $\{f_n\}$ is bounded under the infinity norm $||\cdot||_\infty.$ So $F = \{f_n : n \in \mathbb{N}\}$ is a bounded and equicontinuous family of function. Clearly, $F \subseteq C(\mathbb{R})$. The original proof of Arzela-Ascoli Theorem will apply only if the space is compact, but $\mathbb{R}$ is not compact. So I try to modify the proof of Arzela-Ascoli Theorem in Carothers book https://archive.org/details/CarothersN.L.RealAnalysisCambridge2000Isbn0521497566416S page 181. However, the proof relies on totally bounded to choose a finite points which their balls will cover the space. This is no where possible for the space that is not compact. I also try to restricted $F$ to $[-M,M]$ first and extract the subsequence. Then I try to extend it on $\mathbb{R}$ with decaying at $\infty, -\infty.$ But still not quite successful. Any help please ?","Let $f : \mathbb{R} \rightarrow \mathbb{R}$ be a continuous function. Assume that $f(x) > 0$ for all $x \in \mathbb{R}$, but $f$ decays to $0$ at $\infty, -\infty.$ Let $\{f_n\}$ be a sequence of real-valued equicontinuous functions on $\mathbb{R}.$ Assume that $$|f_n(x)| \leq f(x)$$ for all $n$ and $x.$ Verify that $\{f_n\}$ has a uniformly convergent subsequence. $\textbf{Proof} \ $ Since $f$ decays at $\infty$ and $-\infty,$ there exists $M > 0$ such that $|f(x)| < 1$ for $|x|>M$. Since $[-M, M]$ is compact and $f$ is continuous, there is $K > 0$such that $|f(x)| \leq K$ with $x \in [-M,M].$ So $|f_n(x)| \leq |f(x)| \leq K+1$ for all $n, x.$ That is, $\{f_n\}$ is bounded under the infinity norm $||\cdot||_\infty.$ So $F = \{f_n : n \in \mathbb{N}\}$ is a bounded and equicontinuous family of function. Clearly, $F \subseteq C(\mathbb{R})$. The original proof of Arzela-Ascoli Theorem will apply only if the space is compact, but $\mathbb{R}$ is not compact. So I try to modify the proof of Arzela-Ascoli Theorem in Carothers book https://archive.org/details/CarothersN.L.RealAnalysisCambridge2000Isbn0521497566416S page 181. However, the proof relies on totally bounded to choose a finite points which their balls will cover the space. This is no where possible for the space that is not compact. I also try to restricted $F$ to $[-M,M]$ first and extract the subsequence. Then I try to extend it on $\mathbb{R}$ with decaying at $\infty, -\infty.$ But still not quite successful. Any help please ?",,"['real-analysis', 'functional-analysis', 'compactness']"
44,Size of $L^{\infty}$,Size of,L^{\infty},"I am confused about the 'size' of $L^\infty$: One the one hand, when we consider $L^\infty(\Omega)$ and $\mu(\Omega)$ is finite (and $\mu$ some measure), then we have the inclusion $L^\infty \subset L^p$ for some $p \geq 1$. So $L^\infty$ is the 'smallest' of the $L^p$ spaces. On the other hand, we know for arbitrary open $\Omega \subset \mathbb{R^n}$ that $L^\infty$ is not separable, so it is in some sense 'too big' to be approximated by a countable subset, but $L^p$ for $1 \leq p < \infty$ are separable. I find this somewhat confusing. What am I missing or getting wrong? Thanks!","I am confused about the 'size' of $L^\infty$: One the one hand, when we consider $L^\infty(\Omega)$ and $\mu(\Omega)$ is finite (and $\mu$ some measure), then we have the inclusion $L^\infty \subset L^p$ for some $p \geq 1$. So $L^\infty$ is the 'smallest' of the $L^p$ spaces. On the other hand, we know for arbitrary open $\Omega \subset \mathbb{R^n}$ that $L^\infty$ is not separable, so it is in some sense 'too big' to be approximated by a countable subset, but $L^p$ for $1 \leq p < \infty$ are separable. I find this somewhat confusing. What am I missing or getting wrong? Thanks!",,"['functional-analysis', 'lebesgue-integral']"
45,"Prove that for $E$ of finite measure, $T(f) = \int_E\phi\circ f$ is continuous on $L^p(E)$ if $\phi(x)$ in continuous on $R$ and $\phi(x)<a+b|x|^p$.","Prove that for  of finite measure,  is continuous on  if  in continuous on  and .",E T(f) = \int_E\phi\circ f L^p(E) \phi(x) R \phi(x)<a+b|x|^p,"In Chapter 8 of Real analysis , 4th edition by Royden, a functional is continuous if $f_n \rightarrow f$ in $L^p$ implies $T(f_n)\rightarrow T(f)$. Royden had given a proof of this proposition in Collary 18 in that Chapter but there seems to be a mistake in it. Let $\{f_n\}$ be a sequence in $L^p$ that convergences strongly to $f$ in $L^p(E)$. By taking a subsequence if necessary and relabelling , we suppose $\{f_n\}$ is rapidly Cauchy. Therefore, according to Theorem 6 of Chapter 7, $\{f_n\}$ convergences pointwise a.e. on $E$ to $f$. Since $\phi$ is continuous, ${\phi\circ f_n}$ convergences pointwise a.e. on E to $\phi\circ f$. Moreover, by the completeness of $L^p(E)$, since ${f_n}$ is rapid Cauchy in $L^p(E)$, the function   $$g = |f_1| + \sum_{n=1}^{\infty} |{f_{n+1}-f_n}| $$   belongs to $L^p(E)$. It is clear that   $$ |f_n| \le g \text{ a.e. on E for all } n. $$   and hence, by the inequality (33),   $$ |\phi\circ f_n| \le a + b \cdot |f_n|^p \le a + b\cdot g^p \text{ a.e. on E for all }n.$$   We infer from the Dominated Convergence Theorem that   $$ \lim_{n\rightarrow \infty} \int_E \phi\circ f_n = \int_E\phi\circ f. $$   Therefore T is continuous on $L^p(E)$. But, why could one take a subsequence if necessary as in the boldface text above? If this was done, it occur to me that it is only proven that for the subsequence $T(f_{n_k})\rightarrow T(f)$ rather than for the original sequence $T(f_n)\rightarrow T(f)$.","In Chapter 8 of Real analysis , 4th edition by Royden, a functional is continuous if $f_n \rightarrow f$ in $L^p$ implies $T(f_n)\rightarrow T(f)$. Royden had given a proof of this proposition in Collary 18 in that Chapter but there seems to be a mistake in it. Let $\{f_n\}$ be a sequence in $L^p$ that convergences strongly to $f$ in $L^p(E)$. By taking a subsequence if necessary and relabelling , we suppose $\{f_n\}$ is rapidly Cauchy. Therefore, according to Theorem 6 of Chapter 7, $\{f_n\}$ convergences pointwise a.e. on $E$ to $f$. Since $\phi$ is continuous, ${\phi\circ f_n}$ convergences pointwise a.e. on E to $\phi\circ f$. Moreover, by the completeness of $L^p(E)$, since ${f_n}$ is rapid Cauchy in $L^p(E)$, the function   $$g = |f_1| + \sum_{n=1}^{\infty} |{f_{n+1}-f_n}| $$   belongs to $L^p(E)$. It is clear that   $$ |f_n| \le g \text{ a.e. on E for all } n. $$   and hence, by the inequality (33),   $$ |\phi\circ f_n| \le a + b \cdot |f_n|^p \le a + b\cdot g^p \text{ a.e. on E for all }n.$$   We infer from the Dominated Convergence Theorem that   $$ \lim_{n\rightarrow \infty} \int_E \phi\circ f_n = \int_E\phi\circ f. $$   Therefore T is continuous on $L^p(E)$. But, why could one take a subsequence if necessary as in the boldface text above? If this was done, it occur to me that it is only proven that for the subsequence $T(f_{n_k})\rightarrow T(f)$ rather than for the original sequence $T(f_n)\rightarrow T(f)$.",,"['real-analysis', 'functional-analysis', 'lp-spaces']"
46,Metrizability of a subset in the weak topology.,Metrizability of a subset in the weak topology.,,"Let $X$ be a Banach space (not reflexive). It is well-known that $(X,w)$, which is $X$ with its weak topology, is not metrizable if $X$ is infinite dimensional. I want to know under which condition can a subset $S\subset X$ be given a metric that is compatible with the weak topology $(S,w)$? If $X$ is reflexive then, if I recall correctly, the norm-boundedness of $S$ is enough. However, I am dealing with a non-reflexive space $X=W^{1,1}(\Omega)$ so the previous criterion is not applicable. What if I assume that $S$ is norm-compact? Would that be enough?","Let $X$ be a Banach space (not reflexive). It is well-known that $(X,w)$, which is $X$ with its weak topology, is not metrizable if $X$ is infinite dimensional. I want to know under which condition can a subset $S\subset X$ be given a metric that is compatible with the weak topology $(S,w)$? If $X$ is reflexive then, if I recall correctly, the norm-boundedness of $S$ is enough. However, I am dealing with a non-reflexive space $X=W^{1,1}(\Omega)$ so the previous criterion is not applicable. What if I assume that $S$ is norm-compact? Would that be enough?",,"['functional-analysis', 'partial-differential-equations', 'banach-spaces', 'sobolev-spaces']"
47,Unitarily equivalent operators have unitarily equivalent spectral measures,Unitarily equivalent operators have unitarily equivalent spectral measures,,"For every densely defined self-adjoint linear operator $ A : \mathcal D(A) \subset H \to H $ there is a unique spectral representation $$ A = \int t \, dE_A(t) $$ where $E_A$ is a spectral measure on $\mathbb R$. Now let $ B : \mathcal D(B) \subset H \to H $ be another densely defined self-adjoint operator on $H$ with spectral measure $E_B$ which is unitarly equivalent to $A$ with unitary map $U$: $$ AU=UB $$ This page is stating that the spectral measures are unitarily equivalent as well but I don't know how to prove it. Can someone give me a hint?","For every densely defined self-adjoint linear operator $ A : \mathcal D(A) \subset H \to H $ there is a unique spectral representation $$ A = \int t \, dE_A(t) $$ where $E_A$ is a spectral measure on $\mathbb R$. Now let $ B : \mathcal D(B) \subset H \to H $ be another densely defined self-adjoint operator on $H$ with spectral measure $E_B$ which is unitarly equivalent to $A$ with unitary map $U$: $$ AU=UB $$ This page is stating that the spectral measures are unitarily equivalent as well but I don't know how to prove it. Can someone give me a hint?",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
48,"If $f_m \rightarrow f$ in $L^p$, does $|f_m|^r \rightarrow |f|^r$ in $L^{\frac{p}{r}}$?","If  in , does  in ?",f_m \rightarrow f L^p |f_m|^r \rightarrow |f|^r L^{\frac{p}{r}},"Suppose that $(f_m)_m, f \subset L^p(\Omega)$ are nonnegative, such that $f_m \rightarrow f$ in $L^p$; that is: $$ \|f_m - f\|_p \rightarrow 0 $$ It is clear that $({f_m}^r)_m, f^r \subset L^{\frac{p}{r}}(\Omega)$, since $\int |f|^p = \int|f^r|^{\frac{p}{r}}$. Can we conclude that ${f_m}^r \rightarrow f^r$ in $L^{\frac{p}{r}}$? That is: $$ \left\| {f_m}^r - f^r \right\|_{\frac{p}{r}} \rightarrow 0 $$ Note: we assume $1<r<p<\infty$, and $\Omega \subset \mathbb{R}^n$ is measurable.","Suppose that $(f_m)_m, f \subset L^p(\Omega)$ are nonnegative, such that $f_m \rightarrow f$ in $L^p$; that is: $$ \|f_m - f\|_p \rightarrow 0 $$ It is clear that $({f_m}^r)_m, f^r \subset L^{\frac{p}{r}}(\Omega)$, since $\int |f|^p = \int|f^r|^{\frac{p}{r}}$. Can we conclude that ${f_m}^r \rightarrow f^r$ in $L^{\frac{p}{r}}$? That is: $$ \left\| {f_m}^r - f^r \right\|_{\frac{p}{r}} \rightarrow 0 $$ Note: we assume $1<r<p<\infty$, and $\Omega \subset \mathbb{R}^n$ is measurable.",,"['real-analysis', 'functional-analysis', 'convergence-divergence', 'lp-spaces', 'uniform-convergence']"
49,Optimal control problem (constant magnitude acceleration),Optimal control problem (constant magnitude acceleration),,"A particle in $\mathbb R^2$ begins at initial position $(x_0, y_0)$ and velocity $(u_0, v_0)$. It must eventually reach a target position $(x_1, y_1)$ and velocity $(u_1, v_1)$. The acceleration of the particle is a vector of constant magnitude $1$. The only control for this system is the direction of this acceleration, as a (not necessarily continuous) function of time. What path will bring the particle to the target position and velocity in the least amount of time ? I believe I already have a solution to this problem, but what I'm wondering is: does this problem already have a name? Does the curve? What work has already been done to solve and generalize this problem?","A particle in $\mathbb R^2$ begins at initial position $(x_0, y_0)$ and velocity $(u_0, v_0)$. It must eventually reach a target position $(x_1, y_1)$ and velocity $(u_1, v_1)$. The acceleration of the particle is a vector of constant magnitude $1$. The only control for this system is the direction of this acceleration, as a (not necessarily continuous) function of time. What path will bring the particle to the target position and velocity in the least amount of time ? I believe I already have a solution to this problem, but what I'm wondering is: does this problem already have a name? Does the curve? What work has already been done to solve and generalize this problem?",,"['functional-analysis', 'control-theory', 'optimal-control']"
50,Lipschitz constant of limit of functions part 2,Lipschitz constant of limit of functions part 2,,"This question follows from my other question Lipschitz constant of limit of functions . Consider two metric spaces $(X,d_X)$ and $(Y,d_Y)$ and define the lipschitz constant of every continuous function $f:X\rightarrow Y$ as $$Lip(f):=\sup\limits_{x\neq y}\frac{d_Y(f(x),f(y))}{d_X(x,y)}$$ Consider a sequence of continuous functions $f_n:X\rightarrow Y$ such that there is a $k>1$ such that for every $n\in \mathbb{N}$ it is $Lip(f_n)\le k$ $\{f_n\}$ has limit $f:X\rightarrow Y$ for the uniform convergence on  compact sets (this means that for every $K\subset X$ compact it results $\lim\limits_{n\rightarrow \infty}\sup\limits_{x\in K}d_Y(f(x),f_n(x))=0$) $Lip(f_n)\rightarrow 1$ User pcp showed that it is not true $Lip(f)=1$, but showed an example when it happens $Lip(f)=0$. It seems to me that his counter-example only works for proving $Lip(f)<1$, so my other question is the following. Question: Can it happen $Lip(f)>1$? Can you motivate your answer?","This question follows from my other question Lipschitz constant of limit of functions . Consider two metric spaces $(X,d_X)$ and $(Y,d_Y)$ and define the lipschitz constant of every continuous function $f:X\rightarrow Y$ as $$Lip(f):=\sup\limits_{x\neq y}\frac{d_Y(f(x),f(y))}{d_X(x,y)}$$ Consider a sequence of continuous functions $f_n:X\rightarrow Y$ such that there is a $k>1$ such that for every $n\in \mathbb{N}$ it is $Lip(f_n)\le k$ $\{f_n\}$ has limit $f:X\rightarrow Y$ for the uniform convergence on  compact sets (this means that for every $K\subset X$ compact it results $\lim\limits_{n\rightarrow \infty}\sup\limits_{x\in K}d_Y(f(x),f_n(x))=0$) $Lip(f_n)\rightarrow 1$ User pcp showed that it is not true $Lip(f)=1$, but showed an example when it happens $Lip(f)=0$. It seems to me that his counter-example only works for proving $Lip(f)<1$, so my other question is the following. Question: Can it happen $Lip(f)>1$? Can you motivate your answer?",,"['real-analysis', 'functional-analysis', 'analysis', 'lipschitz-functions']"
51,is function convex?,is function convex?,,"Suppose that $a_i$ has a normal distribution with mean $E(a_i)$ and variance $var(a_i)$ ,  we have for  $\sum_{i=1}^n a_i x_i $ , $$E (\sum_{i=1}^n a_i x_i) = \sum_{i=1}^n E(a_i) x_i,$$ and $$var (\sum_{i=1}^n a_i x_i)=\sum_{i=1}^n var(a_i) x_i ^2 +2\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} cov(a_i,a_j)x_ix_j,$$ where $cov(a_i,a_j)x_ix_j$  is a covariance. Is this function convex ? $$\sqrt{ \sum_i x_i ^2 var(a_i)+ 2 \sum_{i=1}^{n-1} \sum_{j=i+1}^{n}cov(a_i,a_j)x_ix_j  +  \sum_{i=1}^n E(a_i) x_i } $$","Suppose that $a_i$ has a normal distribution with mean $E(a_i)$ and variance $var(a_i)$ ,  we have for  $\sum_{i=1}^n a_i x_i $ , $$E (\sum_{i=1}^n a_i x_i) = \sum_{i=1}^n E(a_i) x_i,$$ and $$var (\sum_{i=1}^n a_i x_i)=\sum_{i=1}^n var(a_i) x_i ^2 +2\sum_{i=1}^{n-1} \sum_{j=i+1}^{n} cov(a_i,a_j)x_ix_j,$$ where $cov(a_i,a_j)x_ix_j$  is a covariance. Is this function convex ? $$\sqrt{ \sum_i x_i ^2 var(a_i)+ 2 \sum_{i=1}^{n-1} \sum_{j=i+1}^{n}cov(a_i,a_j)x_ix_j  +  \sum_{i=1}^n E(a_i) x_i } $$",,"['functional-analysis', 'optimization', 'convex-analysis', 'convex-optimization', 'nonlinear-optimization']"
52,Separating theorem,Separating theorem,,"I have convex the set $C:=C(x_1,\dots,x_n) \in \mathbb{R}^n$ of convex combinations of $x_i$'s. I know that there exists an $x_i$ such that $\Vert x_i \Vert > 0$ and $ 0 \notin \mathring{C}(x_1,\dots,x_n) = \{\sum_{i=1}^{n}\lambda_i x_i : \lambda_i \in (0,1) \text{ and sum up to 1}\}$. I also know that \begin{align*} \exists y \in C \>\forall c \in \mathring{C} : \> \langle y , c \rangle > 0. \end{align*}  Now I am supposed to show that $\langle y , x_i \rangle > 0$ holds. Can somebody give me a hint for this task?","I have convex the set $C:=C(x_1,\dots,x_n) \in \mathbb{R}^n$ of convex combinations of $x_i$'s. I know that there exists an $x_i$ such that $\Vert x_i \Vert > 0$ and $ 0 \notin \mathring{C}(x_1,\dots,x_n) = \{\sum_{i=1}^{n}\lambda_i x_i : \lambda_i \in (0,1) \text{ and sum up to 1}\}$. I also know that \begin{align*} \exists y \in C \>\forall c \in \mathring{C} : \> \langle y , c \rangle > 0. \end{align*}  Now I am supposed to show that $\langle y , x_i \rangle > 0$ holds. Can somebody give me a hint for this task?",,"['real-analysis', 'functional-analysis']"
53,$L^\infty (\Bbb R^n)$ bound for an inverse Fourier transform.,bound for an inverse Fourier transform.,L^\infty (\Bbb R^n),"Let $\phi:\Bbb R^n\to\Bbb R$ be a smooth and compactly supported function ($\phi\equiv1$ on some ball around $0$). I want to show that the function $f:\Bbb R^n\to\Bbb C$ defined by $$ f(x) := \int_{\Bbb R^n} \phi(\xi)\frac{\xi_j}{|\xi|^2}e^{2\pi i x\cdot\xi} \,d\xi $$ for a fixed $j\in\{1,\dots,n\}$is unformly bounded, i.e. $f\in L^\infty$. Here $|\xi|:=(\xi_1^2+\cdots+\xi_n^2)^{1/2}$. I get this expression from a lecture note on harmonic analysis but I don't know how to prove it. Could anyone please suggest how to show this?","Let $\phi:\Bbb R^n\to\Bbb R$ be a smooth and compactly supported function ($\phi\equiv1$ on some ball around $0$). I want to show that the function $f:\Bbb R^n\to\Bbb C$ defined by $$ f(x) := \int_{\Bbb R^n} \phi(\xi)\frac{\xi_j}{|\xi|^2}e^{2\pi i x\cdot\xi} \,d\xi $$ for a fixed $j\in\{1,\dots,n\}$is unformly bounded, i.e. $f\in L^\infty$. Here $|\xi|:=(\xi_1^2+\cdots+\xi_n^2)^{1/2}$. I get this expression from a lecture note on harmonic analysis but I don't know how to prove it. Could anyone please suggest how to show this?",,"['complex-analysis', 'functional-analysis', 'partial-differential-equations', 'fourier-analysis', 'harmonic-analysis']"
54,Are Lp norms equivalent on bounded functions with compact support?,Are Lp norms equivalent on bounded functions with compact support?,,"Are Lp norms equivalent on certain space of functions? Here, functions are of course infinite dimensional.  I know that if functions are allowed to have singularity and be non-zero everywhere, then Lp norms are certainly not equivlent. If functions have support and no singularity, will things change? If I have to go further, giving a strick upperbound to the functions would be enough right?","Are Lp norms equivalent on certain space of functions? Here, functions are of course infinite dimensional.  I know that if functions are allowed to have singularity and be non-zero everywhere, then Lp norms are certainly not equivlent. If functions have support and no singularity, will things change? If I have to go further, giving a strick upperbound to the functions would be enough right?",,"['functional-analysis', 'lp-spaces']"
55,Minor Detail in the Proof of the Spectral Radius Formula,Minor Detail in the Proof of the Spectral Radius Formula,,"Theorem : Let $A$ be a Banach Algebra then for $x\in A$ the spectral radius $r(x)$ of $x$ satisfies $$r(x)=\lim_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}.$$ The proofs that I have seen of this (I have mostly been using Murphy: C* algebras and operator theory, and a few sets of online lecture notes which follow his book) show that if $\lambda\in\mathbb{C}$ satisfies $r(x)<|\lambda^{-1}|$ then $\limsup_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}\leq|\lambda^{-1}|$, in fact I am quite happy with showing this inequality. However what I don't understand is why we then can conclude that $\limsup_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}\leq r(x)$, I mean it must be really trivial because everybody just concludes it without a second thought, but I just can't for the life of me see how it follows. Can anybody help me? I'm sorry that it's probably a very silly question.","Theorem : Let $A$ be a Banach Algebra then for $x\in A$ the spectral radius $r(x)$ of $x$ satisfies $$r(x)=\lim_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}.$$ The proofs that I have seen of this (I have mostly been using Murphy: C* algebras and operator theory, and a few sets of online lecture notes which follow his book) show that if $\lambda\in\mathbb{C}$ satisfies $r(x)<|\lambda^{-1}|$ then $\limsup_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}\leq|\lambda^{-1}|$, in fact I am quite happy with showing this inequality. However what I don't understand is why we then can conclude that $\limsup_{n\rightarrow\infty}\|x^n\|^\frac{1}{n}\leq r(x)$, I mean it must be really trivial because everybody just concludes it without a second thought, but I just can't for the life of me see how it follows. Can anybody help me? I'm sorry that it's probably a very silly question.",,"['functional-analysis', 'spectral-theory', 'banach-algebras']"
56,"If ${x_n}$ converges weakly to $x_0$, then for $T \in B(X,Y)$, $T(x_n)$ converges weakly to $T(x_0)$?","If  converges weakly to , then for ,  converges weakly to ?","{x_n} x_0 T \in B(X,Y) T(x_n) T(x_0)","Let $X,Y$ be normed spaces.  A bounded operator $T: X \to Y$ is arbitrary. $B(X,Y)$ denotes the set of bounded operators.  How to prove that if  ${x_n}$ converges weakly to $x_0$, then for $T \in B(X,Y)$, $T(x_n)$ converge weakly to $T(x_0)$? I know it has to be true in the case that weak convergence implies strong convergence. Also, when $T$ is not only bounded but also linear, Riesz representation theorem comes in and the proof becomes trivial. However, if $T$ is only bounded, I have no clue. This is an exercise from the book. I seem to find counter a example of this though. Can anyone at least show me an example of weak convergence where the limit is not 0?","Let $X,Y$ be normed spaces.  A bounded operator $T: X \to Y$ is arbitrary. $B(X,Y)$ denotes the set of bounded operators.  How to prove that if  ${x_n}$ converges weakly to $x_0$, then for $T \in B(X,Y)$, $T(x_n)$ converge weakly to $T(x_0)$? I know it has to be true in the case that weak convergence implies strong convergence. Also, when $T$ is not only bounded but also linear, Riesz representation theorem comes in and the proof becomes trivial. However, if $T$ is only bounded, I have no clue. This is an exercise from the book. I seem to find counter a example of this though. Can anyone at least show me an example of weak convergence where the limit is not 0?",,['functional-analysis']
57,The weak topology on locally convex spaces,The weak topology on locally convex spaces,,"Let $X$ be a non-zero real vector space endowed with a locally convex topology $τ$; its continuous dual, $X^*$, is the vector space of all the linear and continuous functions on $X$. Consider the topology on $X^*$ defined as the coarsest locally convex topology on $X^*$ which makes continuous all the mappings $$ T_x:X^*\rightarrow\mathbb{R},\quad T_x(g)=g(x),\quad g\in X^*, x\in X. $$ Is this topology the same as the weak$^*$-topology on $X^*$? In other words, is this the same as the coarsest ( not necessarily locally convex ) topology on $X^*$ which makes continuous all the mappings $T_x$ as described above?","Let $X$ be a non-zero real vector space endowed with a locally convex topology $τ$; its continuous dual, $X^*$, is the vector space of all the linear and continuous functions on $X$. Consider the topology on $X^*$ defined as the coarsest locally convex topology on $X^*$ which makes continuous all the mappings $$ T_x:X^*\rightarrow\mathbb{R},\quad T_x(g)=g(x),\quad g\in X^*, x\in X. $$ Is this topology the same as the weak$^*$-topology on $X^*$? In other words, is this the same as the coarsest ( not necessarily locally convex ) topology on $X^*$ which makes continuous all the mappings $T_x$ as described above?",,"['general-topology', 'functional-analysis']"
58,Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)?,Is the kernel of the adjoint operator equal to the kernel of the operator ()?,\ker (A)=\ker (A'),"I am in a middle of a proof where I asked myself about the following: Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)? Theorem :Let $X,Y$ be Banach spaces and $A$ an linear bounded operator. The closure of the image is $\overline{Im\: }A=\{y\in Y:f(y)=0,\forall f\in Y'$ such that $A'f=0$}. $(A'f)(x)=f(A(x))$ is the adjoint operator. $Im(A)=\ker(A')^\bot$ So I think that is straightforward the following identity: $\ker (A)=Im(A)^\bot=\ker(A')$ So $\ker (A)=\ker (A')$ Question: Are these moves valid? Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)?","I am in a middle of a proof where I asked myself about the following: Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)? Theorem :Let $X,Y$ be Banach spaces and $A$ an linear bounded operator. The closure of the image is $\overline{Im\: }A=\{y\in Y:f(y)=0,\forall f\in Y'$ such that $A'f=0$}. $(A'f)(x)=f(A(x))$ is the adjoint operator. $Im(A)=\ker(A')^\bot$ So I think that is straightforward the following identity: $\ker (A)=Im(A)^\bot=\ker(A')$ So $\ker (A)=\ker (A')$ Question: Are these moves valid? Is the kernel of the adjoint operator equal to the kernel of the operator ($\ker (A)=\ker (A')$)?",,"['functional-analysis', 'adjoint-operators']"
59,Continuous functional calculus of multiplication operator in $L_2$,Continuous functional calculus of multiplication operator in,L_2,"I would like to calculate the continuous calculus of the multiplication operator by an essentially bounded function $\varphi : X \rightarrow \mathbb{R}$ in $L_2 (X, \mu)$, where $\left( X, \mu \right)$ - finite measure space. But I have one problem. I know that $\sigma \left( M_{\varphi} \right) = \mathrm{ess.im} \left( \varphi \right)$, but to define $\gamma: C (\sigma) \rightarrow B \left( L_2 (X, \mu)\right)$ we need the domain of the function $f \in C (\sigma) $ to be $\mathrm{im} (\varphi)$. I know, that if $$\forall A \subset X \quad \varphi(A) \cap \mathrm{ess.im} \left( \varphi \right) = \varnothing \implies \mu(A)=0$$ but I don't know how to prove this. Thank's for the help!","I would like to calculate the continuous calculus of the multiplication operator by an essentially bounded function $\varphi : X \rightarrow \mathbb{R}$ in $L_2 (X, \mu)$, where $\left( X, \mu \right)$ - finite measure space. But I have one problem. I know that $\sigma \left( M_{\varphi} \right) = \mathrm{ess.im} \left( \varphi \right)$, but to define $\gamma: C (\sigma) \rightarrow B \left( L_2 (X, \mu)\right)$ we need the domain of the function $f \in C (\sigma) $ to be $\mathrm{im} (\varphi)$. I know, that if $$\forall A \subset X \quad \varphi(A) \cap \mathrm{ess.im} \left( \varphi \right) = \varnothing \implies \mu(A)=0$$ but I don't know how to prove this. Thank's for the help!",,"['functional-analysis', 'measure-theory', 'operator-theory', 'functional-calculus']"
60,Is it true that the convex hull of a finite union compact convex sets compact?,Is it true that the convex hull of a finite union compact convex sets compact?,,"Currently I am studying Behrend's $M$-structure and Banach-Stone Theorem .  He introduced the following notation. Notation : Consider a Banach space $X.$ Fix $x\in X$ and $r\geq 0.$ Consider the set  $$K(x,r)=\{(x^*,x^*(x)+r)\in X^*\times \mathbb{R}:x^*\in B_{X^*}\}.$$ It is not hard to show that $K(x,r)$ is a compact convex set. However, the author quoted the following at page $45.$ convex hull of $\bigcup_{i=1}^nK(x_i,r_i)$ is compact because convex hull of finite unions of compact convex sets is compact. I fail to prove the above statement.  Any hint is appreciated.","Currently I am studying Behrend's $M$-structure and Banach-Stone Theorem .  He introduced the following notation. Notation : Consider a Banach space $X.$ Fix $x\in X$ and $r\geq 0.$ Consider the set  $$K(x,r)=\{(x^*,x^*(x)+r)\in X^*\times \mathbb{R}:x^*\in B_{X^*}\}.$$ It is not hard to show that $K(x,r)$ is a compact convex set. However, the author quoted the following at page $45.$ convex hull of $\bigcup_{i=1}^nK(x_i,r_i)$ is compact because convex hull of finite unions of compact convex sets is compact. I fail to prove the above statement.  Any hint is appreciated.",,"['real-analysis', 'functional-analysis', 'convex-analysis', 'convex-hulls']"
61,Range of the Gelfand transform on a non-unital Banach algebra,Range of the Gelfand transform on a non-unital Banach algebra,,"Let $\mathcal{A}$ be a non-unital commutative Banach algebra. Consider the Gelfand transform \begin{align*}\Gamma_{\mathcal{A}}:\mathcal{A}&\to C(\sigma(\mathcal{A}))\\ x&\mapsto \hat{x} \end{align*} where \begin{align*}\hat{x}:\sigma(\mathcal{A})&\to \mathbb{C}\\ h&\mapsto \hat{x}(h)=h(x) \end{align*} In Folland's A course in Abstract Harmonic Analysis it is stated that in fact $\Gamma_{\mathcal{A}}(\mathcal{A})\subset C_0(\sigma(\mathcal{A}))$, i.e. if $x\in \mathcal{A}$ then for all $\varepsilon>0$ there is a compact $K\subset \sigma(\mathcal{A})$ such that $|\hat{x}(h)|\leq \varepsilon$ for all $h\in \sigma(\mathcal{A})\setminus K$. It is not well explained why this is true. The basic idea would be to try to get back to the unital case. We can consider the unital extension $\tilde{A}=\mathcal{A}\times \mathbb{C}$ of $\mathcal{A}$, where $\mathcal{A}\cong \mathcal{A}\times \left\{0\right\}\subset \tilde{A}$. We then have a homeomorphism (I think) \begin{align*}\sigma(\tilde{\mathcal{A}})&\cong \sigma(\mathcal{A})\cup \left\{0\right\}\\ 0&\mapsto \tilde{0}:(x,\lambda)\mapsto 0\\ \sigma(\mathcal{A})\ni h&\mapsto \tilde{h}:(x,\lambda)\mapsto h(x)+\lambda  \end{align*} both are compact Hausdorff spaces in the weak*-topology induced by $\mathcal{A}^*$ and $\mathcal{A}$ respectively, while $\sigma(\mathcal{A})$ is only locally compact in general. The above homeomorphism in turn induces a Banach algebra isomorphism $C(\sigma(\tilde{\mathcal{A}}))\cong C(\sigma(\mathcal{A})\cup\left\{0\right\})$. With this identification we have $\Gamma_{\mathcal{A}}=r\circ \left.\Gamma_{\tilde{\mathcal{A}}}\right|_{\mathcal{A}}$ where $r:C(\sigma(\mathcal{A})\cup\left\{0\right\})\to C(\sigma(\mathcal{A}))$ is the restriction map. Now I would like to use the topological/algebraic properties I know about $r$ and $\Gamma_{\tilde{\mathcal{A}}}$ to show that $\Gamma_{\mathcal{A}}(\mathcal{A})\subset C_0(\sigma(\mathcal{A}))$. I am aware that $\mathcal{A}$ is a closed maximal ideal of $\tilde{A}$ so since $\tilde{\mathcal{A}}$ is unital, $\Gamma_{\tilde{\mathcal{A}}}(\mathcal{A})$ is itself a closed non-trivial subalgebra of $C(\sigma(\mathcal{A})\cup\left\{0\right\})$.","Let $\mathcal{A}$ be a non-unital commutative Banach algebra. Consider the Gelfand transform \begin{align*}\Gamma_{\mathcal{A}}:\mathcal{A}&\to C(\sigma(\mathcal{A}))\\ x&\mapsto \hat{x} \end{align*} where \begin{align*}\hat{x}:\sigma(\mathcal{A})&\to \mathbb{C}\\ h&\mapsto \hat{x}(h)=h(x) \end{align*} In Folland's A course in Abstract Harmonic Analysis it is stated that in fact $\Gamma_{\mathcal{A}}(\mathcal{A})\subset C_0(\sigma(\mathcal{A}))$, i.e. if $x\in \mathcal{A}$ then for all $\varepsilon>0$ there is a compact $K\subset \sigma(\mathcal{A})$ such that $|\hat{x}(h)|\leq \varepsilon$ for all $h\in \sigma(\mathcal{A})\setminus K$. It is not well explained why this is true. The basic idea would be to try to get back to the unital case. We can consider the unital extension $\tilde{A}=\mathcal{A}\times \mathbb{C}$ of $\mathcal{A}$, where $\mathcal{A}\cong \mathcal{A}\times \left\{0\right\}\subset \tilde{A}$. We then have a homeomorphism (I think) \begin{align*}\sigma(\tilde{\mathcal{A}})&\cong \sigma(\mathcal{A})\cup \left\{0\right\}\\ 0&\mapsto \tilde{0}:(x,\lambda)\mapsto 0\\ \sigma(\mathcal{A})\ni h&\mapsto \tilde{h}:(x,\lambda)\mapsto h(x)+\lambda  \end{align*} both are compact Hausdorff spaces in the weak*-topology induced by $\mathcal{A}^*$ and $\mathcal{A}$ respectively, while $\sigma(\mathcal{A})$ is only locally compact in general. The above homeomorphism in turn induces a Banach algebra isomorphism $C(\sigma(\tilde{\mathcal{A}}))\cong C(\sigma(\mathcal{A})\cup\left\{0\right\})$. With this identification we have $\Gamma_{\mathcal{A}}=r\circ \left.\Gamma_{\tilde{\mathcal{A}}}\right|_{\mathcal{A}}$ where $r:C(\sigma(\mathcal{A})\cup\left\{0\right\})\to C(\sigma(\mathcal{A}))$ is the restriction map. Now I would like to use the topological/algebraic properties I know about $r$ and $\Gamma_{\tilde{\mathcal{A}}}$ to show that $\Gamma_{\mathcal{A}}(\mathcal{A})\subset C_0(\sigma(\mathcal{A}))$. I am aware that $\mathcal{A}$ is a closed maximal ideal of $\tilde{A}$ so since $\tilde{\mathcal{A}}$ is unital, $\Gamma_{\tilde{\mathcal{A}}}(\mathcal{A})$ is itself a closed non-trivial subalgebra of $C(\sigma(\mathcal{A})\cup\left\{0\right\})$.",,"['functional-analysis', 'banach-algebras', 'gelfand-representation']"
62,"Does all total sets have a ""stable"" property?","Does all total sets have a ""stable"" property?",,"In Kreyszig's Introductory Functional Analysis with Applications , a total set in a normed space $X$ is defined as a subset $M \subset X$ whose span is dense in $X$. That is, $\overline{\text{span } M} = X$. Let $X$ be a separable normed space, and $M = \{f_1, f_2, \dotsc\}$ be a countable total set in $X$. Prove or disprove the following: For each $x \in X$, there exist coefficients $c_1, c_2, \dotsc$, such that $\|x - \sum_{k=1}^n c_k f_k\| \to 0$ as $n \to \infty$. Note that $c_k$ does not change for each $n$, which is what I try to imply by ""stable"". Note: The question may be badly posed in the sense that there may still be assumptions I need to make, otherwise there will be a trivial answer. It's a personal question rather than a homework question.","In Kreyszig's Introductory Functional Analysis with Applications , a total set in a normed space $X$ is defined as a subset $M \subset X$ whose span is dense in $X$. That is, $\overline{\text{span } M} = X$. Let $X$ be a separable normed space, and $M = \{f_1, f_2, \dotsc\}$ be a countable total set in $X$. Prove or disprove the following: For each $x \in X$, there exist coefficients $c_1, c_2, \dotsc$, such that $\|x - \sum_{k=1}^n c_k f_k\| \to 0$ as $n \to \infty$. Note that $c_k$ does not change for each $n$, which is what I try to imply by ""stable"". Note: The question may be badly posed in the sense that there may still be assumptions I need to make, otherwise there will be a trivial answer. It's a personal question rather than a homework question.",,"['functional-analysis', 'normed-spaces']"
63,Inclusion of $C^*(S)$ in $W^*(S)$ is proper,Inclusion of  in  is proper,C^*(S) W^*(S),"I have a little question concerning operator algebras. Consider the unilateral shift $S\in \mathcal{B}(\ell^2)$ defined by $Se_n=e_{n+1}$, $e_i$ being the canonical orthonormal basis of $\ell^2$. Then take the $C^*$-algebra generated by $S$, that is the the completion of the algebra of all polynomials in $S$ and $S^*$ with respect to the operator norm, and the von-Neumann-Algebra $W^*(S)$ generated by $S$ which is the same but with respect to the strong operator topology. It is easy to see that $C^*(S) \subset W^*(S)$ and that $W^*(S)$ is actually the whole space $\mathcal{B}(\ell^2)$. But is this inclusion proper? What would be a linear Operator that is not in $C^*(S)$? I tried to think of a property that all elements in $C^*(S)$ fulfill and then find a linear operator that does not have this property but i can't seem to find something fitting. Does someone know an example? Thanks!","I have a little question concerning operator algebras. Consider the unilateral shift $S\in \mathcal{B}(\ell^2)$ defined by $Se_n=e_{n+1}$, $e_i$ being the canonical orthonormal basis of $\ell^2$. Then take the $C^*$-algebra generated by $S$, that is the the completion of the algebra of all polynomials in $S$ and $S^*$ with respect to the operator norm, and the von-Neumann-Algebra $W^*(S)$ generated by $S$ which is the same but with respect to the strong operator topology. It is easy to see that $C^*(S) \subset W^*(S)$ and that $W^*(S)$ is actually the whole space $\mathcal{B}(\ell^2)$. But is this inclusion proper? What would be a linear Operator that is not in $C^*(S)$? I tried to think of a property that all elements in $C^*(S)$ fulfill and then find a linear operator that does not have this property but i can't seem to find something fitting. Does someone know an example? Thanks!",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
64,A condition for an infinite matrix to represent a bounded operator on $\ell^2$,A condition for an infinite matrix to represent a bounded operator on,\ell^2,"Let $\ell^2=\ell^2(\mathbb{N})$ and let $e_1,e_2,\ldots$ be its usual basis. I have an infinite matrix $\{\alpha_{ij}\}_{i,j=1}^{\infty}$ such that $\alpha_{ij} \ge 0$ for all $i,j$ and such that there are scalars $p_i>0$ and $\beta,\gamma>0$ with $\sum_{i=1}^{\infty}\alpha_{ij}p_{i} \le \beta p_j \quad$ , $\quad \sum_{j=1}^{\infty}\alpha_{ij}p_{j} \le \gamma p_i \quad$ for all $i,j\ge 1$ Now I want to show that there is an operator $A$ on $\ell^{2}(\mathbb{N})$ with $\langle Ae_{j},e_{i}\rangle =\alpha_{ij}$. Do you know how I must represented this operator? I must use multiplication operator?","Let $\ell^2=\ell^2(\mathbb{N})$ and let $e_1,e_2,\ldots$ be its usual basis. I have an infinite matrix $\{\alpha_{ij}\}_{i,j=1}^{\infty}$ such that $\alpha_{ij} \ge 0$ for all $i,j$ and such that there are scalars $p_i>0$ and $\beta,\gamma>0$ with $\sum_{i=1}^{\infty}\alpha_{ij}p_{i} \le \beta p_j \quad$ , $\quad \sum_{j=1}^{\infty}\alpha_{ij}p_{j} \le \gamma p_i \quad$ for all $i,j\ge 1$ Now I want to show that there is an operator $A$ on $\ell^{2}(\mathbb{N})$ with $\langle Ae_{j},e_{i}\rangle =\alpha_{ij}$. Do you know how I must represented this operator? I must use multiplication operator?",,"['functional-analysis', 'operator-theory']"
65,"Prove $\|A\| \leq \|A\|_{HS}$, where $\|A\|$ is the operator norm of A","Prove , where  is the operator norm of A",\|A\| \leq \|A\|_{HS} \|A\|,"I Am trying to solve the following problem Let $H_1 ,H_ 2$ be  Hilbert  spaces.   Let $A \in B(H_1 ,H_2 )$  be  a  Hilbert-Schmidt  operator.   For  a  complete orthonormal sequence $( u_n )$ in $H_1$, define the Hilbert-Schmidt norm $\|.\|_{HS}$ by $\|A\|_{HS}=\left(\sum^\infty_{n=1}\|A(u_n)\|^2\right)^\frac{1}{2} $ Prove  $\|A\| \leq \|A\|_{HS}$, where $\|A\|$ is the operator norm of A. My current attempt is as follows: Let $x \in H_1$ such that $ x=\sum^\infty_{n=1} \langle x,u_n\rangle u_N$ and $\|x\|=\left(\sum^\infty_{n=1}|\langle x,u_n\rangle|^2\right)^\frac{1}{2} $. Then we have, $\|A(x)\|=\|A\left(\sum^\infty_{n=1} \langle x,u_n\rangle u_N\right)\| =\|\sum^\infty_{n=1}A\left( \langle x,u_n\rangle u_n\right)\| = \|\sum^\infty_{n=1} \langle x,u_n\rangle A\left(u_n\right)\| \leq \|\sum^\infty_{n=1}A(u_n)\|\ \|\sum^\infty_{n=1}\langle x,u_n\rangle\|$ I am unsure where to go from here and feel I have made a mistake? Thank you in advance.","I Am trying to solve the following problem Let $H_1 ,H_ 2$ be  Hilbert  spaces.   Let $A \in B(H_1 ,H_2 )$  be  a  Hilbert-Schmidt  operator.   For  a  complete orthonormal sequence $( u_n )$ in $H_1$, define the Hilbert-Schmidt norm $\|.\|_{HS}$ by $\|A\|_{HS}=\left(\sum^\infty_{n=1}\|A(u_n)\|^2\right)^\frac{1}{2} $ Prove  $\|A\| \leq \|A\|_{HS}$, where $\|A\|$ is the operator norm of A. My current attempt is as follows: Let $x \in H_1$ such that $ x=\sum^\infty_{n=1} \langle x,u_n\rangle u_N$ and $\|x\|=\left(\sum^\infty_{n=1}|\langle x,u_n\rangle|^2\right)^\frac{1}{2} $. Then we have, $\|A(x)\|=\|A\left(\sum^\infty_{n=1} \langle x,u_n\rangle u_N\right)\| =\|\sum^\infty_{n=1}A\left( \langle x,u_n\rangle u_n\right)\| = \|\sum^\infty_{n=1} \langle x,u_n\rangle A\left(u_n\right)\| \leq \|\sum^\infty_{n=1}A(u_n)\|\ \|\sum^\infty_{n=1}\langle x,u_n\rangle\|$ I am unsure where to go from here and feel I have made a mistake? Thank you in advance.",,"['functional-analysis', 'lebesgue-integral', 'normed-spaces', 'operator-algebras', 'spectral-theory']"
66,"$L^p(\mathbb R^n) \subset \mathcal S'(\mathbb R^n), 1 \le p < \infty$",,"L^p(\mathbb R^n) \subset \mathcal S'(\mathbb R^n), 1 \le p < \infty","For $p$ = 1, it's clear because for $f \in L^1(\mathbb R^n)$, one can define a tempered distribution by $T_{f}(\varphi) := \int_{\mathbb R^n} f(x) \varphi(x) dx$. Apparently, one can make the argument that $\mathcal S(\mathbb R^n) \subset L^p(\mathbb R^n)$ implies that the for the dual spaces the opposite inclusion holds. Why is that?","For $p$ = 1, it's clear because for $f \in L^1(\mathbb R^n)$, one can define a tempered distribution by $T_{f}(\varphi) := \int_{\mathbb R^n} f(x) \varphi(x) dx$. Apparently, one can make the argument that $\mathcal S(\mathbb R^n) \subset L^p(\mathbb R^n)$ implies that the for the dual spaces the opposite inclusion holds. Why is that?",,"['functional-analysis', 'distribution-theory', 'schwartz-space']"
67,Can a weakly Cauchy sequence in a non-complete inner product space be unbounded?,Can a weakly Cauchy sequence in a non-complete inner product space be unbounded?,,"Let $V$ be a non-complete inner product space, and let $x_n$ be a weakly Cauchy sequence, i.e suppose $\langle x_n, y\rangle$ converges for every $y \in V$. Is it true $x_n$ is bounded? I know this is true when $V$ is complete (Hilbert), but this uses Bair theorem. So, I guess there should be a counter-example when completeness is not assumed.","Let $V$ be a non-complete inner product space, and let $x_n$ be a weakly Cauchy sequence, i.e suppose $\langle x_n, y\rangle$ converges for every $y \in V$. Is it true $x_n$ is bounded? I know this is true when $V$ is complete (Hilbert), but this uses Bair theorem. So, I guess there should be a counter-example when completeness is not assumed.",,"['functional-analysis', 'inner-products', 'weak-convergence', 'weak-topology']"
68,Showing that the Differential Operator is continuous in a topological vector space,Showing that the Differential Operator is continuous in a topological vector space,,"Earlier this day, I asked a question , on how to prove continuity of scalar multiplication and addition in a specific topological vector space. To repeat it here, I was talking about this space: Let $\mathcal{D}_K$ be the space of all on $K\subseteq \mathbb{R}$   compactly supported, infinitely differentiable functions. I have shown for $N \in \mathbb{N}$, $\epsilon > 0$ and   $U_{N,\epsilon} := \{f \in \mathcal{D}_K: \max_{0\leq i \leq N} > ||f^{(i)}||_\infty < \epsilon\}$, that the sets $f + U_{N,\epsilon}$   with $f\in \mathcal{D}_K$ form a basis of a topology on our space. I do now indeed understand how to prove that this space is a topological vector space. However, I also want to show that the differentiation operator $D_i: \mathcal{D}_K \rightarrow \mathcal{D}_K , f \mapsto f^{(i)}$ is continuous under this topology. As far as I have understood, this topology is induced by the norms $$||g||_N := \max_{i \leq N} ||g^{(i)}|| $$ so essentially my open sets are just unions of balls $B_N(g,\epsilon)$, with some norm $||\cdot||_N$ I now tried to use this to prove the continuity of $D_i$, by showing that its preimage of such an open ball $$D_i^{-1}(B_N(f,\epsilon)) = \{g \in \mathcal{D}_K : \max_{k\leq N} ||g^{(i+k)}-f^{(k)}||_\infty  < \epsilon \} $$ is contained in a union of other open balls containing $f$. This is where I get stuck. I always end up with derivatives of different order on each of my functions, so I do not know how I can find such a union. Any help would be greatly appreciated!","Earlier this day, I asked a question , on how to prove continuity of scalar multiplication and addition in a specific topological vector space. To repeat it here, I was talking about this space: Let $\mathcal{D}_K$ be the space of all on $K\subseteq \mathbb{R}$   compactly supported, infinitely differentiable functions. I have shown for $N \in \mathbb{N}$, $\epsilon > 0$ and   $U_{N,\epsilon} := \{f \in \mathcal{D}_K: \max_{0\leq i \leq N} > ||f^{(i)}||_\infty < \epsilon\}$, that the sets $f + U_{N,\epsilon}$   with $f\in \mathcal{D}_K$ form a basis of a topology on our space. I do now indeed understand how to prove that this space is a topological vector space. However, I also want to show that the differentiation operator $D_i: \mathcal{D}_K \rightarrow \mathcal{D}_K , f \mapsto f^{(i)}$ is continuous under this topology. As far as I have understood, this topology is induced by the norms $$||g||_N := \max_{i \leq N} ||g^{(i)}|| $$ so essentially my open sets are just unions of balls $B_N(g,\epsilon)$, with some norm $||\cdot||_N$ I now tried to use this to prove the continuity of $D_i$, by showing that its preimage of such an open ball $$D_i^{-1}(B_N(f,\epsilon)) = \{g \in \mathcal{D}_K : \max_{k\leq N} ||g^{(i+k)}-f^{(k)}||_\infty  < \epsilon \} $$ is contained in a union of other open balls containing $f$. This is where I get stuck. I always end up with derivatives of different order on each of my functions, so I do not know how I can find such a union. Any help would be greatly appreciated!",,"['functional-analysis', 'topological-vector-spaces']"
69,A solution of the Laplace equation that is compactly supported or vanishes at $\infty$ or near the boundary,A solution of the Laplace equation that is compactly supported or vanishes at  or near the boundary,\infty,Consider the Laplace equation  \begin{equation}\label{1} \Delta u =0  \end{equation}  on a bounded smooth domain (or the whole space). Does there exist a solution for the Laplace equation that is compactly supported  or vanishes near the boundary (or at $\infty$) ?,Consider the Laplace equation  \begin{equation}\label{1} \Delta u =0  \end{equation}  on a bounded smooth domain (or the whole space). Does there exist a solution for the Laplace equation that is compactly supported  or vanishes near the boundary (or at $\infty$) ?,,"['real-analysis', 'complex-analysis', 'functional-analysis', 'analysis', 'partial-differential-equations']"
70,Moving limit into sup norm,Moving limit into sup norm,,"I need help understanding where I'm going wrong with this line of thought: Assume $f_n$ converges pointwise to $f$, so $\lim \limits_{n \rightarrow \infty}f_n(x) = f(x) \forall x \in X$, then since the suprumum norm is a norm therefore continuous we can move a limit inside, like this: $\lim \limits_{n \rightarrow \infty}\|f_n-f\|_\infty = \|\lim \limits_{n \rightarrow \infty}(f_n-f)\|_\infty = \|0\|_\infty = 0$ So all pointwise convergent sequences are also uniform convergent. This is clearly not the case so where am I going wrong?","I need help understanding where I'm going wrong with this line of thought: Assume $f_n$ converges pointwise to $f$, so $\lim \limits_{n \rightarrow \infty}f_n(x) = f(x) \forall x \in X$, then since the suprumum norm is a norm therefore continuous we can move a limit inside, like this: $\lim \limits_{n \rightarrow \infty}\|f_n-f\|_\infty = \|\lim \limits_{n \rightarrow \infty}(f_n-f)\|_\infty = \|0\|_\infty = 0$ So all pointwise convergent sequences are also uniform convergent. This is clearly not the case so where am I going wrong?",,"['real-analysis', 'functional-analysis', 'limits', 'normed-spaces', 'uniform-convergence']"
71,Closed and bounded but not compact subset of $\ell^1$,Closed and bounded but not compact subset of,\ell^1,"I need to prove that $$A=\{a\in \ell^1:\sum_{i=1}^{\infty}|a_n| \le 1\}$$ is closed, bounded and not a compact subset in $\ell^1$. Boundedness is trivial, but I get stuck in the other two. Proving subsets of $l^1$ are not closed seems easy, because one sequence whose limit is not in the subsets does it, but I’m stuck in proving that any sequence converges to a point in $A$. Thanks in advance!","I need to prove that $$A=\{a\in \ell^1:\sum_{i=1}^{\infty}|a_n| \le 1\}$$ is closed, bounded and not a compact subset in $\ell^1$. Boundedness is trivial, but I get stuck in the other two. Proving subsets of $l^1$ are not closed seems easy, because one sequence whose limit is not in the subsets does it, but I’m stuck in proving that any sequence converges to a point in $A$. Thanks in advance!",,"['real-analysis', 'functional-analysis', 'metric-spaces', 'compactness', 'lp-spaces']"
72,Commutant of two bounded linear operators,Commutant of two bounded linear operators,,"Let $E$ be an infinite-dimensional complex Hilbert space and $A,B\in  \mathcal{L}(E)$. Why it is impossible to find $c\in \mathbb{C}^*$ such that $[A,B]=cI$?","Let $E$ be an infinite-dimensional complex Hilbert space and $A,B\in  \mathcal{L}(E)$. Why it is impossible to find $c\in \mathbb{C}^*$ such that $[A,B]=cI$?",,['functional-analysis']
73,Convex conjugate of a function?,Convex conjugate of a function?,,"The conjugate of a function $f$ is $$f^*(y)=\sup_{x\in \mathop{\rm dom} f} (\left< y,x\right> - f(x)).$$ Let $f(x)=\frac{1}{2}\left< Ax,x\right>+\left< b,x\right>+c$ on open set $\Omega$ of $\mathbb R^n$, where $A$ is a definite positif symmetric matrix. I showed that $f$ is convex function. Now, I would like compute the conjugate function $f^*(y)$ of $f$? For this, I will calculate the derivative of the function $$g(x)=\left< y,x\right> - f(x) = \left< y,x\right> -\frac{1}{2}\left< Ax,x\right>-\left< b,x\right>-c$$ with respect to $x$, for find its maximum.  So, the derivative of $\left< y,x\right>$ is $y$ and the derivative of $-\left< b,x\right>-c$ is $-b$, but what it the derivative of $\left< Ax,x\right>$ ? Remark: In a pdf I found that: $f^*(y)= \frac{1}{2} \left< y-b, A^{-1}(y-b)\right>-c$. Thank you in advance","The conjugate of a function $f$ is $$f^*(y)=\sup_{x\in \mathop{\rm dom} f} (\left< y,x\right> - f(x)).$$ Let $f(x)=\frac{1}{2}\left< Ax,x\right>+\left< b,x\right>+c$ on open set $\Omega$ of $\mathbb R^n$, where $A$ is a definite positif symmetric matrix. I showed that $f$ is convex function. Now, I would like compute the conjugate function $f^*(y)$ of $f$? For this, I will calculate the derivative of the function $$g(x)=\left< y,x\right> - f(x) = \left< y,x\right> -\frac{1}{2}\left< Ax,x\right>-\left< b,x\right>-c$$ with respect to $x$, for find its maximum.  So, the derivative of $\left< y,x\right>$ is $y$ and the derivative of $-\left< b,x\right>-c$ is $-b$, but what it the derivative of $\left< Ax,x\right>$ ? Remark: In a pdf I found that: $f^*(y)= \frac{1}{2} \left< y-b, A^{-1}(y-b)\right>-c$. Thank you in advance",,"['real-analysis', 'functional-analysis', 'convex-analysis']"
74,Convolution operator,Convolution operator,,"I'm trying to find the spectrum of the convolution operator and understand $$T : L_2 \left[ -\pi, \pi \right] \longrightarrow L_2\left[ -\pi, \pi \right],$$ $$ f(t) \longmapsto \int_{-\pi}^\pi \sin^2(t-s)f(s) \, \mathrm{d}s. $$ I think the best option would be to go over to the Fourier transform $F$ due to this answer enter link description here . But the Fourier transformation is defined in space $L_2 (\mathbb{R}) $ (as a limit on the Schwarz class) ($F : L_2 (\mathbb{R}) \longrightarrow L_2 (\mathbb{R}) $). Then we know that $L_2\left[ -\pi, \pi \right] \subset L_2 (\mathbb{R}) $ and $F \circ T \circ F^{-1} : F \left( L_2\left[ -\pi, \pi \right] \right) \longrightarrow F \left( L_2\left[ -\pi, \pi \right] \right)$. In this case we get that the operator $F \circ T \circ F^{-1} $ is the multiplication operator $F \circ T \circ F^{-1} = M_{g}$, where  $$g(x) = \int_{-\pi}^\pi \sin^2 (t) e^{-ixt } \, \mathrm{d}t$$ We know also that $\sigma(M_g) = \sigma \left(F \circ T \circ F^{-1} \right) =\sigma(T)$. But then we want to define spectrum of $T$. We know that in $ B \left(L_2 \left( \mathbb{R} \right) \right)$ spectrum of $M_g$ is essential range of $g$ (in this case is simply range). But our space is not all $L_2\left( \mathbb{R} \right)$, we only have a part $ \operatorname{Im}(F) = F \left( L_2\left[ -\pi, \pi \right] \right) $ and i don't know how to show that in $B(\operatorname{Im}(F))$ operator $M_g$ has the same spectrum. Sorry for my english and thank you very much!","I'm trying to find the spectrum of the convolution operator and understand $$T : L_2 \left[ -\pi, \pi \right] \longrightarrow L_2\left[ -\pi, \pi \right],$$ $$ f(t) \longmapsto \int_{-\pi}^\pi \sin^2(t-s)f(s) \, \mathrm{d}s. $$ I think the best option would be to go over to the Fourier transform $F$ due to this answer enter link description here . But the Fourier transformation is defined in space $L_2 (\mathbb{R}) $ (as a limit on the Schwarz class) ($F : L_2 (\mathbb{R}) \longrightarrow L_2 (\mathbb{R}) $). Then we know that $L_2\left[ -\pi, \pi \right] \subset L_2 (\mathbb{R}) $ and $F \circ T \circ F^{-1} : F \left( L_2\left[ -\pi, \pi \right] \right) \longrightarrow F \left( L_2\left[ -\pi, \pi \right] \right)$. In this case we get that the operator $F \circ T \circ F^{-1} $ is the multiplication operator $F \circ T \circ F^{-1} = M_{g}$, where  $$g(x) = \int_{-\pi}^\pi \sin^2 (t) e^{-ixt } \, \mathrm{d}t$$ We know also that $\sigma(M_g) = \sigma \left(F \circ T \circ F^{-1} \right) =\sigma(T)$. But then we want to define spectrum of $T$. We know that in $ B \left(L_2 \left( \mathbb{R} \right) \right)$ spectrum of $M_g$ is essential range of $g$ (in this case is simply range). But our space is not all $L_2\left( \mathbb{R} \right)$, we only have a part $ \operatorname{Im}(F) = F \left( L_2\left[ -\pi, \pi \right] \right) $ and i don't know how to show that in $B(\operatorname{Im}(F))$ operator $M_g$ has the same spectrum. Sorry for my english and thank you very much!",,"['functional-analysis', 'operator-theory', 'spectral-theory', 'banach-algebras', 'compact-operators']"
75,Orthogonality of eigenvectors of a positive operator in the polar decomposition,Orthogonality of eigenvectors of a positive operator in the polar decomposition,,"Let $T : H \rightarrow H$ be a compact operator ($H$: complex Hilbert space). Then $|T| = (T^* T)^{1/2}$ is a compact self-adjoint operator. If $\{x_j\}$ is an orthonormal basis of $(\ker |T|)^{\perp}$, is it true that $\langle Tx_i, x_j \rangle = 0$ for $i\neq j$? I tried to check this by using the polar decomposition of $T$, that is, $T = U|T|$ where $U$ is a partial isometry. One can obtain that $\langle Tx_i x_j \rangle = \lambda_i \langle Ux_i, x_j\rangle = \lambda_i \langle Ux_i, U^*Ux_j \rangle  = \lambda_i \langle U^2 x_i, Ux_j\rangle .$ From this, is it possible to deduce that $\langle Tx_i, x_j\rangle = 0$ for $i\neq j$? Any help will be appreciated!","Let $T : H \rightarrow H$ be a compact operator ($H$: complex Hilbert space). Then $|T| = (T^* T)^{1/2}$ is a compact self-adjoint operator. If $\{x_j\}$ is an orthonormal basis of $(\ker |T|)^{\perp}$, is it true that $\langle Tx_i, x_j \rangle = 0$ for $i\neq j$? I tried to check this by using the polar decomposition of $T$, that is, $T = U|T|$ where $U$ is a partial isometry. One can obtain that $\langle Tx_i x_j \rangle = \lambda_i \langle Ux_i, x_j\rangle = \lambda_i \langle Ux_i, U^*Ux_j \rangle  = \lambda_i \langle U^2 x_i, Ux_j\rangle .$ From this, is it possible to deduce that $\langle Tx_i, x_j\rangle = 0$ for $i\neq j$? Any help will be appreciated!",,"['functional-analysis', 'eigenvalues-eigenvectors', 'hilbert-spaces', 'orthogonality']"
76,Prove that $||(\sum^k_{i=1}|f_i|)^{\frac{1}{2}}||_p \leq (\sum^k_i ||f_i||^2_p)^{\frac{1}{2}}$,Prove that,||(\sum^k_{i=1}|f_i|)^{\frac{1}{2}}||_p \leq (\sum^k_i ||f_i||^2_p)^{\frac{1}{2}},"In one popular Chinese Real Analysis textbook, I met a problem stated as the title: Prove the following inequality \begin{equation} \left|\left|\left(\sum^k_{i=1}|f_i|\right)^{\frac{1}{2}}\right|\right|_p \leq \left(\sum^k_i \left|\left|f_i\right|\right|^2_p\right)^{\frac{1}{2}}, \end{equation} given the condition: $2\leq p < \infty, f_i \in L^p(E) (i=1,2,...,k)$. Here is the snapshot . My attempts are as follows: It suffices to consider $k=2$. Without loss of generality, assume all $f_i>0$. Put the $\frac{1}{2}$ on LHS out of the norm, and cancel it with the $\frac{1}{2}$ on RHS. Put the $2$ on RHS into the p-norm. It becomes: \begin{equation} ||\sum^k_{i=1}f_i ||_{\frac{p}{2}} \leq \sum^k_i \left|\left| f_i^2 \right|\right|_{\frac{p}{2}}, \end{equation} The condition $2\leq p < \infty$ reminds me the Clarkson inequalities , and in fact they appeared slightly before this problem. Yet the book didn't provide any hint. Then I'm stucked. Can anyone help me? Thank you for the comments! Though the book has rare typos, the original inequality may have square $2$ outside the LHS p-norm? That is, \begin{equation} \left|\left|\left(\sum^k_{i=1}|f_i|\right)^{\frac{1}{2}}\right|\right|_p^2 \leq \left(\sum^k_i \left|\left|f_i\right|\right|^2_p\right)^{\frac{1}{2}}, \end{equation} such that the simplified one is \begin{equation} ||\sum^k_{i=1}f_i ||_{\frac{p}{2}}^2 \leq \sum^k_i \left|\left| f_i^2 \right|\right|_{\frac{p}{2}}, \end{equation} The reason is that, similar to Cauchy, Minkowski, Holder inequalities, both sides now have the same ""order""/""power"". No matther which case is true, this kind of inequality is elegant. Hope we can achieve the right one. @Calvin Khor I think your comment is correct. In this way, the question is to show: \begin{equation} \left|\left|\left(\sum^k_{i=1}|f_i|^2\right)^{\frac{1}{2}}\right|\right|_p \leq \left(\sum^k_i \left|\left|f_i\right|\right|^2_p\right)^{\frac{1}{2}}, \end{equation} Then the proof is obvious!","In one popular Chinese Real Analysis textbook, I met a problem stated as the title: Prove the following inequality \begin{equation} \left|\left|\left(\sum^k_{i=1}|f_i|\right)^{\frac{1}{2}}\right|\right|_p \leq \left(\sum^k_i \left|\left|f_i\right|\right|^2_p\right)^{\frac{1}{2}}, \end{equation} given the condition: $2\leq p < \infty, f_i \in L^p(E) (i=1,2,...,k)$. Here is the snapshot . My attempts are as follows: It suffices to consider $k=2$. Without loss of generality, assume all $f_i>0$. Put the $\frac{1}{2}$ on LHS out of the norm, and cancel it with the $\frac{1}{2}$ on RHS. Put the $2$ on RHS into the p-norm. It becomes: \begin{equation} ||\sum^k_{i=1}f_i ||_{\frac{p}{2}} \leq \sum^k_i \left|\left| f_i^2 \right|\right|_{\frac{p}{2}}, \end{equation} The condition $2\leq p < \infty$ reminds me the Clarkson inequalities , and in fact they appeared slightly before this problem. Yet the book didn't provide any hint. Then I'm stucked. Can anyone help me? Thank you for the comments! Though the book has rare typos, the original inequality may have square $2$ outside the LHS p-norm? That is, \begin{equation} \left|\left|\left(\sum^k_{i=1}|f_i|\right)^{\frac{1}{2}}\right|\right|_p^2 \leq \left(\sum^k_i \left|\left|f_i\right|\right|^2_p\right)^{\frac{1}{2}}, \end{equation} such that the simplified one is \begin{equation} ||\sum^k_{i=1}f_i ||_{\frac{p}{2}}^2 \leq \sum^k_i \left|\left| f_i^2 \right|\right|_{\frac{p}{2}}, \end{equation} The reason is that, similar to Cauchy, Minkowski, Holder inequalities, both sides now have the same ""order""/""power"". No matther which case is true, this kind of inequality is elegant. Hope we can achieve the right one. @Calvin Khor I think your comment is correct. In this way, the question is to show: \begin{equation} \left|\left|\left(\sum^k_{i=1}|f_i|^2\right)^{\frac{1}{2}}\right|\right|_p \leq \left(\sum^k_i \left|\left|f_i\right|\right|^2_p\right)^{\frac{1}{2}}, \end{equation} Then the proof is obvious!",,"['real-analysis', 'functional-analysis', 'measure-theory']"
77,Why denote the spectral decomposition of a bounded operator as an integral?,Why denote the spectral decomposition of a bounded operator as an integral?,,"In the spectral theorem for bounded self-adjoint operators we get, for each self-adjoint (bounded) operator $A$ in a Hilbert space $\mathcal{H}$, and each bounded Borel-measurable function $f \in \mathcal{B}_0(\sigma(A))$ (where I denote by $\mathcal{B}_0(\sigma (A))$ the set of all Borel-measurable functions in the spectrum $\sigma(A)$ of $A$) a bounded operator $f(A)$ defined as $$\langle \psi, f(A) \psi \rangle = \int_{\sigma(A)} f(\lambda) d\mu_{\psi}(\lambda) \ ,$$ where $\mu_{\psi}$ is a measure defined by a family of ""projection-valued measures"" $(P_B)_{B \in \mathcal{B}(\sigma(A))}$ which are just $\chi_B(A)$ in the sense of the functional calculus, for each Borel subset $B$ of $\sigma(A)$.  Given all this information, the operator $A$ is denoted as $$ A = \int_{\sigma(A)} \lambda dP_\lambda \ ,$$ and this decomposition is unique in the sense that any other projection-valued measure satisfying this equality should be equal to the first.  My questions are: Is there some other reason for this notation for the operator $A$? How this integral should be interpreted, as it isn't actually constructed as a Lebesgue integral? The only way I know to obtain the operator in this case is to use the somewhat more general expression above, and use the polarization identity + Riesz lemma, as usual. Sorry for the long question, my doubt is quite simple but there was a lot of context before I could express it.","In the spectral theorem for bounded self-adjoint operators we get, for each self-adjoint (bounded) operator $A$ in a Hilbert space $\mathcal{H}$, and each bounded Borel-measurable function $f \in \mathcal{B}_0(\sigma(A))$ (where I denote by $\mathcal{B}_0(\sigma (A))$ the set of all Borel-measurable functions in the spectrum $\sigma(A)$ of $A$) a bounded operator $f(A)$ defined as $$\langle \psi, f(A) \psi \rangle = \int_{\sigma(A)} f(\lambda) d\mu_{\psi}(\lambda) \ ,$$ where $\mu_{\psi}$ is a measure defined by a family of ""projection-valued measures"" $(P_B)_{B \in \mathcal{B}(\sigma(A))}$ which are just $\chi_B(A)$ in the sense of the functional calculus, for each Borel subset $B$ of $\sigma(A)$.  Given all this information, the operator $A$ is denoted as $$ A = \int_{\sigma(A)} \lambda dP_\lambda \ ,$$ and this decomposition is unique in the sense that any other projection-valued measure satisfying this equality should be equal to the first.  My questions are: Is there some other reason for this notation for the operator $A$? How this integral should be interpreted, as it isn't actually constructed as a Lebesgue integral? The only way I know to obtain the operator in this case is to use the somewhat more general expression above, and use the polarization identity + Riesz lemma, as usual. Sorry for the long question, my doubt is quite simple but there was a lot of context before I could express it.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
78,Dense subspaces of $L^\infty(\Omega\times\Omega)$,Dense subspaces of,L^\infty(\Omega\times\Omega),"Let $\Omega\subset\mathbb R$ be open and bounded.  For continuous functions $C(\Omega\times\Omega)$, the Stone-Weierstrass theorem shows that the products $a(x)b(y)$ of univariate continuous functions in $C(\Omega)$ span a dense subspace.  However, for bounded functions in $L^\infty(\Omega\times\Omega)$, the only subspace I can think of is spanned by the indicator functions $\chi_A(x,y)$, where $A\subset\Omega\times\Omega$ is measurable. My question: is there a more convenient dense subspace of $L^\infty(\Omega\times\Omega)$?  In particular, do the products $a(x)b(y)$ of $L^\infty(\Omega)$ functions span a dense subspace? Motivation: I am considering the $L^2$ continuity of pseudo-differential operators with $L^\infty$ symbols $a$: $$ Au(x)=\int e^{i(x-y)\cdot\xi}a(x,y,\xi)u(y)dyd\xi. $$ If $a(x,y,\xi)\sim \sum a(x)b(y)c(\xi)$, such as if $a(x,y,\xi)$ is bounded and continuous, then $L^2$ continuity follows immediately from the properties of $L^\infty$ multiplier operators.  But without this product structure, I am not sure where to go.","Let $\Omega\subset\mathbb R$ be open and bounded.  For continuous functions $C(\Omega\times\Omega)$, the Stone-Weierstrass theorem shows that the products $a(x)b(y)$ of univariate continuous functions in $C(\Omega)$ span a dense subspace.  However, for bounded functions in $L^\infty(\Omega\times\Omega)$, the only subspace I can think of is spanned by the indicator functions $\chi_A(x,y)$, where $A\subset\Omega\times\Omega$ is measurable. My question: is there a more convenient dense subspace of $L^\infty(\Omega\times\Omega)$?  In particular, do the products $a(x)b(y)$ of $L^\infty(\Omega)$ functions span a dense subspace? Motivation: I am considering the $L^2$ continuity of pseudo-differential operators with $L^\infty$ symbols $a$: $$ Au(x)=\int e^{i(x-y)\cdot\xi}a(x,y,\xi)u(y)dyd\xi. $$ If $a(x,y,\xi)\sim \sum a(x)b(y)c(\xi)$, such as if $a(x,y,\xi)$ is bounded and continuous, then $L^2$ continuity follows immediately from the properties of $L^\infty$ multiplier operators.  But without this product structure, I am not sure where to go.",,"['real-analysis', 'functional-analysis', 'lp-spaces', 'product-space', 'pseudo-differential-operators']"
79,Calculate convolution (integral),Calculate convolution (integral),,"We will define the convolution (slightly unconventionally to match Rudin's proof) of $f$ and $g$ as follows:   $$(f\star g)(x)=\int_{-1}^1f(x+t)g(t)\,dt\qquad(0\le x\le1)$$ Let $\delta_n(x)$ be defined as $\frac n2$ for $-\frac1n<x<\frac1n$ and 0 for all other $x$. Let $f(x)$ be defined as $x$ for $.4<x<.7$ and let $f(x)=0$ for all other $x$. Find a piecewise algebraic expression for $f\star\delta_{10}$ and graph $f\star\delta_{10}$. Repeat the exercise for $f\star\delta_{20}$. In what sense does $f\star\delta_n$ converge on $[0,1]$ and to what function does it converge? Hello everyone, I just need help finding a piecewise algebraic expression for $f* \delta_{  10}$. I think I should be able to figure out everything else in the question once I know how to do this. Thoughts/things I know (how to do): Delta 10 is defined as $5$ for $-1/10<x<1/10$ and $0$ otherwise.  $f(x)=x$ for $0.4<x<0.7$ and $0$ otherwise.  I know how both graphs look like visually.  I guess you could say there is a jump in the graph of f(x) at 0.4 and 0.7 and a jump in the graph of $\delta_{10}$ at $-1/10$ and $1/10$. Now confusions: I believe that perhaps I will have to split up the problem into several cases/integrals as both f(x) and delta are piecewise.  The main problem in this question is I don't understand what the t represents so I don't know how to set up my bounds as my bounds are in terms of t (as we integrate with respects to $dt$).  I believe that the integral seemingly from the definition is only valid for $0\leq x<\leq1$ inclusive. Also if I'm doing $f* \delta_{10}$, lets say for x between $0.4<x<0.7$ then wouldn't $f(x+t)=x+t$ and $g(t)=0$? Overall, I think I'm confused so I could really use some guidance on this problem for the first case $f*\delta_{10}$, then I believe I could figure out the rest. Thank you!","We will define the convolution (slightly unconventionally to match Rudin's proof) of $f$ and $g$ as follows:   $$(f\star g)(x)=\int_{-1}^1f(x+t)g(t)\,dt\qquad(0\le x\le1)$$ Let $\delta_n(x)$ be defined as $\frac n2$ for $-\frac1n<x<\frac1n$ and 0 for all other $x$. Let $f(x)$ be defined as $x$ for $.4<x<.7$ and let $f(x)=0$ for all other $x$. Find a piecewise algebraic expression for $f\star\delta_{10}$ and graph $f\star\delta_{10}$. Repeat the exercise for $f\star\delta_{20}$. In what sense does $f\star\delta_n$ converge on $[0,1]$ and to what function does it converge? Hello everyone, I just need help finding a piecewise algebraic expression for $f* \delta_{  10}$. I think I should be able to figure out everything else in the question once I know how to do this. Thoughts/things I know (how to do): Delta 10 is defined as $5$ for $-1/10<x<1/10$ and $0$ otherwise.  $f(x)=x$ for $0.4<x<0.7$ and $0$ otherwise.  I know how both graphs look like visually.  I guess you could say there is a jump in the graph of f(x) at 0.4 and 0.7 and a jump in the graph of $\delta_{10}$ at $-1/10$ and $1/10$. Now confusions: I believe that perhaps I will have to split up the problem into several cases/integrals as both f(x) and delta are piecewise.  The main problem in this question is I don't understand what the t represents so I don't know how to set up my bounds as my bounds are in terms of t (as we integrate with respects to $dt$).  I believe that the integral seemingly from the definition is only valid for $0\leq x<\leq1$ inclusive. Also if I'm doing $f* \delta_{10}$, lets say for x between $0.4<x<0.7$ then wouldn't $f(x+t)=x+t$ and $g(t)=0$? Overall, I think I'm confused so I could really use some guidance on this problem for the first case $f*\delta_{10}$, then I believe I could figure out the rest. Thank you!",,"['real-analysis', 'integration']"
80,Assume $f=g~~a.e$ with respect to a Lebesgue measure what is $L_g?$,Assume  with respect to a Lebesgue measure what is,f=g~~a.e L_g?,"Suppose $f$ and $g$ are in $L^1(\mathbb{R}^n,m)$ where $m$ is a Lebesgue measure. And suppose that $f=g$ almost everywhere with respect to $m$ . We denote by $$L_f=\left\{x: \frac{1}{m(B(r,x))}\int_{B(r,x)}|f(x)-f(y)| \; dm(y) = 0\right\}$$ where $m$ is a Lebesgue measure. Can $L_f$ be described in term of $L_g$ ? Thanks for your help",Suppose and are in where is a Lebesgue measure. And suppose that almost everywhere with respect to . We denote by where is a Lebesgue measure. Can be described in term of ? Thanks for your help,"f g L^1(\mathbb{R}^n,m) m f=g m L_f=\left\{x: \frac{1}{m(B(r,x))}\int_{B(r,x)}|f(x)-f(y)| \; dm(y) = 0\right\} m L_f L_g","['real-analysis', 'integration', 'functional-analysis', 'measure-theory']"
81,(Conway's Functional Analysis) Why can we assume that $\bigcap_{j\neq k}ker(f_j) \neq \bigcap_{j=1}^n ker(f_j).$,(Conway's Functional Analysis) Why can we assume that,\bigcap_{j\neq k}ker(f_j) \neq \bigcap_{j=1}^n ker(f_j).,"In Conway's A Course in Functional Analysis , the author stated the following Proposition $1.4$ at page $377.$ Let $X$ be a vector space over $\mathbb{R}.$   Given $f,f_1,f_2,...,f_n$ are linear functionals on $X.$   If    $$\bigcap_{j=1}^n ker(f_j) \subseteq ker(f),$$   then there exist scalars $a_1,...,a_n$ such that    $$f(x) = \sum_{j=1}^n a_j f_j.$$ The proof starts as follows: It may be assumed that without loss of generality that for $1\leq k\leq n,$ $$\bigcap_{j\neq k}ker(f_j) \neq \bigcap_{j=1}^n ker(f_j).$$ Question: Why can we assume above?    In general, we have    $$\bigcap_{j\neq k} ker(f_j) \supseteq \bigcap_{j=1}^n ker(f_j).$$   So in the proof, we can safely assume that the inclusion is strict.    If the inclusion is not strict, meaning the two intersections are equal, then    kernel of $f_j$ is a subset of kernel of $f_i$ for some $i.$","In Conway's A Course in Functional Analysis , the author stated the following Proposition $1.4$ at page $377.$ Let $X$ be a vector space over $\mathbb{R}.$   Given $f,f_1,f_2,...,f_n$ are linear functionals on $X.$   If    $$\bigcap_{j=1}^n ker(f_j) \subseteq ker(f),$$   then there exist scalars $a_1,...,a_n$ such that    $$f(x) = \sum_{j=1}^n a_j f_j.$$ The proof starts as follows: It may be assumed that without loss of generality that for $1\leq k\leq n,$ $$\bigcap_{j\neq k}ker(f_j) \neq \bigcap_{j=1}^n ker(f_j).$$ Question: Why can we assume above?    In general, we have    $$\bigcap_{j\neq k} ker(f_j) \supseteq \bigcap_{j=1}^n ker(f_j).$$   So in the proof, we can safely assume that the inclusion is strict.    If the inclusion is not strict, meaning the two intersections are equal, then    kernel of $f_j$ is a subset of kernel of $f_i$ for some $i.$",,"['functional-analysis', 'proof-explanation']"
82,"Proving that the injection $L^q(0,1)\to L^p(0,1) $ is not compact:",Proving that the injection  is not compact:,"L^q(0,1)\to L^p(0,1) ","I came across the following problem Let $1\le p\le q\le\infty$ then show that the canonical injection from $L^q(0,1)$ to $L^p(0,1) $ is continuous but not compact. The continuity here is straightforward since by Holder inequality one can easily show that $$\|u\|_p\le \|u\|_q.$$ How to show that this injection is not compact. Note this injection is weakly compact as well see here: Canonical inclusion $L^q(0,1) \to L^p(0,1)$ is compact?","I came across the following problem Let $1\le p\le q\le\infty$ then show that the canonical injection from $L^q(0,1)$ to $L^p(0,1) $ is continuous but not compact. The continuity here is straightforward since by Holder inequality one can easily show that $$\|u\|_p\le \|u\|_q.$$ How to show that this injection is not compact. Note this injection is weakly compact as well see here: Canonical inclusion $L^q(0,1) \to L^p(0,1)$ is compact?",,"['real-analysis', 'functional-analysis', 'analysis', 'lp-spaces', 'compact-operators']"
83,Weak convergence in separable Hilbert spaces,Weak convergence in separable Hilbert spaces,,"Let $H$ be a Hilbert space with ONB $\{b_1, b_2, \cdots \}$. I want to prove that the sequence $x_n = \frac{1}{n}\sum_{i=1}^{n^2}  b_i$ converges weakly to $0$. Notice also that $\|x_n\|=1$. The claim is easily verified on the basis elements, i.e. for large $n$ $$\langle x_n, b_i \rangle= \frac{1}{n}\to 0$$ but I fail to see why it is true for an arbitrary element $y = \sum_i \langle y, b_i \rangle b_i$. Why does $$\langle x_n, y\rangle = \frac{1}{n} \sum_{i=1}^{n^2} \langle y, b_i \rangle$$ converge to $0$?","Let $H$ be a Hilbert space with ONB $\{b_1, b_2, \cdots \}$. I want to prove that the sequence $x_n = \frac{1}{n}\sum_{i=1}^{n^2}  b_i$ converges weakly to $0$. Notice also that $\|x_n\|=1$. The claim is easily verified on the basis elements, i.e. for large $n$ $$\langle x_n, b_i \rangle= \frac{1}{n}\to 0$$ but I fail to see why it is true for an arbitrary element $y = \sum_i \langle y, b_i \rangle b_i$. Why does $$\langle x_n, y\rangle = \frac{1}{n} \sum_{i=1}^{n^2} \langle y, b_i \rangle$$ converge to $0$?",,"['functional-analysis', 'hilbert-spaces', 'weak-convergence']"
84,How to prove the following assertion for bounded linear functionals?,How to prove the following assertion for bounded linear functionals?,,"let $e_i$ be vector with $1$ at the $i^{th}$ pl ace and $0$ elsewhere for $i = 1, 2, \ldots$. Then how to prove that $\{f(e_i)\}$ converges for every bounded linear functional on $l^2$. I start with $$|f(e_m)-f(e_n)| = |f(e_m-e_n)| \leq \|f\| \|e_n-e_m\|$$ Using $f$ bounded, we get $$|f(e_m)-f(e_n)| \leq K \sqrt{2}$$. But how to prove the convergence?","let $e_i$ be vector with $1$ at the $i^{th}$ pl ace and $0$ elsewhere for $i = 1, 2, \ldots$. Then how to prove that $\{f(e_i)\}$ converges for every bounded linear functional on $l^2$. I start with $$|f(e_m)-f(e_n)| = |f(e_m-e_n)| \leq \|f\| \|e_n-e_m\|$$ Using $f$ bounded, we get $$|f(e_m)-f(e_n)| \leq K \sqrt{2}$$. But how to prove the convergence?",,"['functional-analysis', 'continuity', 'linear-transformations', 'lp-spaces']"
85,a range of an operator from $l^p$ to $l^p$,a range of an operator from  to,l^p l^p,"Let T be an operator $T:l^2→l^2$ defined by $T(x_n )=x_n/(n^2+1)$ , then the range of this operator is not closed .. Iam trying to find a sequence in $l^2$  under $T$ which its limit is not in $l^2$ .. My attempt is as the following: Let $(x_n )=(1,1,1,…,1,0,0,0,..)$ then $(x_n)$ in $l^2$ because $∑|x_n |^2=0<+∞$  But $T(x_n )=(1,1/5,1/10,…,0,0,0,..)$ in $l^2$ for the same previous reason  Now Iam not sure about the next steps : The limit of this sequence is $(1,1/5,1/10,1/17,…)$ which is not in $l^2$  is that right?","Let T be an operator $T:l^2→l^2$ defined by $T(x_n )=x_n/(n^2+1)$ , then the range of this operator is not closed .. Iam trying to find a sequence in $l^2$  under $T$ which its limit is not in $l^2$ .. My attempt is as the following: Let $(x_n )=(1,1,1,…,1,0,0,0,..)$ then $(x_n)$ in $l^2$ because $∑|x_n |^2=0<+∞$  But $T(x_n )=(1,1/5,1/10,…,0,0,0,..)$ in $l^2$ for the same previous reason  Now Iam not sure about the next steps : The limit of this sequence is $(1,1/5,1/10,1/17,…)$ which is not in $l^2$  is that right?",,"['functional-analysis', 'operator-theory']"
86,Every open set in a locally compact Hausdorff space contains an open set whose closure is compact and contained in the open set,Every open set in a locally compact Hausdorff space contains an open set whose closure is compact and contained in the open set,,"I know that if X is locally compact and Hausdorff, then any non-empty open set $S$ contains a non-empty closed set. I know this to be the case because a locally compact space is a regular space, in which the claim holds. But why does any open $S$ contain a non-empty open set whose closure is compact and contained in $S$ ? Context: a version of this is claimed at the beginning of the proof of the Baire category theorem in Rudin's Functional Analysis text. Edit: the definition of local compactness that I'm familiar with: $X$ is locally compact if for all $x \in X$ there exists an open set containing $x$ whose closure is compact in $X$.","I know that if X is locally compact and Hausdorff, then any non-empty open set $S$ contains a non-empty closed set. I know this to be the case because a locally compact space is a regular space, in which the claim holds. But why does any open $S$ contain a non-empty open set whose closure is compact and contained in $S$ ? Context: a version of this is claimed at the beginning of the proof of the Baire category theorem in Rudin's Functional Analysis text. Edit: the definition of local compactness that I'm familiar with: $X$ is locally compact if for all $x \in X$ there exists an open set containing $x$ whose closure is compact in $X$.",,"['general-topology', 'functional-analysis', 'compactness', 'baire-category']"
87,A question about the uniqueness in a version of Riesz representation theorem,A question about the uniqueness in a version of Riesz representation theorem,,"In my notes, I have this version of the Riesz representation theorem: Let $X$ be a separable Hilbert space, and let $\{\phi_n\}_n\subset X$ a countable orthonormal set. Let $\{c_k\}_k\in l^2$ a sequence. There exist an element $x\in X$ such that $\forall k\in\mathbb{N},\ (x\mid\phi_k)=c_k$. My question is: with these hypothesis, is there a unique $x\in X?$. I think that with the additional hypothesis that $\{\phi_n\}_n$ is complete, then I have the uniqueness: as a matter of fact if there were two elements $x,y\in X$ that verify the theorem, then I would have $$(x-y\mid \phi_k)=0\ \forall k,$$ Which would imply $$x-y\in clos(\{Span(\{\phi_k\}_k\})^\perp=X^\perp,$$ and then $$(x-y\mid x-y)=0\Rightarrow x-y=0.$$ Is this right?","In my notes, I have this version of the Riesz representation theorem: Let $X$ be a separable Hilbert space, and let $\{\phi_n\}_n\subset X$ a countable orthonormal set. Let $\{c_k\}_k\in l^2$ a sequence. There exist an element $x\in X$ such that $\forall k\in\mathbb{N},\ (x\mid\phi_k)=c_k$. My question is: with these hypothesis, is there a unique $x\in X?$. I think that with the additional hypothesis that $\{\phi_n\}_n$ is complete, then I have the uniqueness: as a matter of fact if there were two elements $x,y\in X$ that verify the theorem, then I would have $$(x-y\mid \phi_k)=0\ \forall k,$$ Which would imply $$x-y\in clos(\{Span(\{\phi_k\}_k\})^\perp=X^\perp,$$ and then $$(x-y\mid x-y)=0\Rightarrow x-y=0.$$ Is this right?",,[]
88,Need a help in finding the inverse of an operator .,Need a help in finding the inverse of an operator .,,"The question and part of its answer is given as follows: 13. Let $K$ be an operator of a finite rank on a Hilbert space $H$. For $\varphi \in H$,   $$ K\varphi = \sum_{j=1}^{n} \langle \varphi, \varphi_j\rangle\psi_j. $$   Suppose $\psi_j \in \operatorname{sp}\{ \varphi_1, \cdots, \varphi_n\}^{\perp}$ for $j = 1, \cdots, n$. Prove that $\mathrm{I} + \alpha K$ is invertible for any $\alpha$ and find its inverse. Solution. Let $\alpha \in \mathbb{C}$, $K'\varphi = \sum_{j=1}^{n} \langle \varphi, \varphi_j\rangle (-\alpha \psi_j)$. By Theorem 7.1,   \begin{align*} \text{$\mathrm{I} + \alpha K$ is invertible} &\quad \Leftrightarrow \quad \text{$\mathrm{I}-K'$ is invertible} \\ &\quad \Leftrightarrow \quad \det(\delta_{ij}-\langle(-\alpha\psi_j),\varphi_i\rangle)_{i,j=1}^{n}\neq 0. \end{align*}   But   $$\det(\delta_{ij}-\langle(-\alpha\psi_j),\varphi_i\rangle)_{i,j=1}^{n} = \det(\delta_{ij}+\alpha\langle\psi_j,\varphi_i\rangle)_{i,j=1}^{n} = 1 \neq 0$$   (because $\psi_j \in \operatorname{sp}\{ \varphi_1, \cdots, \varphi_n\}^{\perp}$ for $j = 1, \cdots, n$). Thus $\mathrm{I}+\alpha K$ is invertible. A part of the theorem is given as follows: 7.1. Theorem. Suppose $K \in L(H)$ is of finite rank, say   $$ Kx = \sum_{j=1}^{n} \langle x, \varphi_j\rangle\psi_j. $$   The operator $I-K$ is invertible if and only if   $$\det(\delta_{ij}-\langle\psi_j,\varphi_i\rangle)_{i,j=1}^{n} \neq 0. $$   In this case, for every $y \in H$,   $$ (I-K)^{-1}y = y - \frac{1}{\det(a_{ij})}\det\begin{pmatrix} a_{11} & a_{12} & \cdots & a_{1n} & \langle y, \varphi_1\rangle \\ a_{21} & a_{22} & \cdots & a_{2n} & \langle y, \varphi_2\rangle \\ \vdots & \vdots & & \vdots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} & \langle y, \varphi_n\rangle \\ \psi_1 & \psi_2 & \cdots & \psi_n & 0 \end{pmatrix} $$ Then the action of the inverse of the operator on $y$ is $y-I$, but how can this tell me what is the inverse of the operator $K$, could anyone clarify this for me please? Thanks!","The question and part of its answer is given as follows: 13. Let $K$ be an operator of a finite rank on a Hilbert space $H$. For $\varphi \in H$,   $$ K\varphi = \sum_{j=1}^{n} \langle \varphi, \varphi_j\rangle\psi_j. $$   Suppose $\psi_j \in \operatorname{sp}\{ \varphi_1, \cdots, \varphi_n\}^{\perp}$ for $j = 1, \cdots, n$. Prove that $\mathrm{I} + \alpha K$ is invertible for any $\alpha$ and find its inverse. Solution. Let $\alpha \in \mathbb{C}$, $K'\varphi = \sum_{j=1}^{n} \langle \varphi, \varphi_j\rangle (-\alpha \psi_j)$. By Theorem 7.1,   \begin{align*} \text{$\mathrm{I} + \alpha K$ is invertible} &\quad \Leftrightarrow \quad \text{$\mathrm{I}-K'$ is invertible} \\ &\quad \Leftrightarrow \quad \det(\delta_{ij}-\langle(-\alpha\psi_j),\varphi_i\rangle)_{i,j=1}^{n}\neq 0. \end{align*}   But   $$\det(\delta_{ij}-\langle(-\alpha\psi_j),\varphi_i\rangle)_{i,j=1}^{n} = \det(\delta_{ij}+\alpha\langle\psi_j,\varphi_i\rangle)_{i,j=1}^{n} = 1 \neq 0$$   (because $\psi_j \in \operatorname{sp}\{ \varphi_1, \cdots, \varphi_n\}^{\perp}$ for $j = 1, \cdots, n$). Thus $\mathrm{I}+\alpha K$ is invertible. A part of the theorem is given as follows: 7.1. Theorem. Suppose $K \in L(H)$ is of finite rank, say   $$ Kx = \sum_{j=1}^{n} \langle x, \varphi_j\rangle\psi_j. $$   The operator $I-K$ is invertible if and only if   $$\det(\delta_{ij}-\langle\psi_j,\varphi_i\rangle)_{i,j=1}^{n} \neq 0. $$   In this case, for every $y \in H$,   $$ (I-K)^{-1}y = y - \frac{1}{\det(a_{ij})}\det\begin{pmatrix} a_{11} & a_{12} & \cdots & a_{1n} & \langle y, \varphi_1\rangle \\ a_{21} & a_{22} & \cdots & a_{2n} & \langle y, \varphi_2\rangle \\ \vdots & \vdots & & \vdots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} & \langle y, \varphi_n\rangle \\ \psi_1 & \psi_2 & \cdots & \psi_n & 0 \end{pmatrix} $$ Then the action of the inverse of the operator on $y$ is $y-I$, but how can this tell me what is the inverse of the operator $K$, could anyone clarify this for me please? Thanks!",,"['functional-analysis', 'analysis']"
89,"Is the mapping $T : x \mapsto \int_{0}^{\bullet} \tau^{-1/2}x(\tau)\,d\tau$ uniformly continuous?",Is the mapping  uniformly continuous?,"T : x \mapsto \int_{0}^{\bullet} \tau^{-1/2}x(\tau)\,d\tau","Consider $X = C([0,1])$ with its natural metric induced by  $\| \cdot \|_{\sup}$ and $Y = C([0,1])$ with the metric $d_1(x,y) = \int^1_0 |x(t)-y(t)| \, dt$. Let $$T: X\to Y : x(t) \mapsto y(t) = \int_0^t \frac{1}{\sqrt \tau} \ x(\tau) \, d\tau$$ Is the mapping T uniformly continuous? Definition. $T:(X,d_x) \to (Y,d_y)$ is uniformly continuous if $\forall \epsilon$, $\exists \delta = \delta(\epsilon)$ : $$ \quad T(B(a,\delta)) \subset B(T_a,\epsilon), \qquad \forall a \in X$$ Usage of $\delta$ in the definition confuses me how can I prove this?","Consider $X = C([0,1])$ with its natural metric induced by  $\| \cdot \|_{\sup}$ and $Y = C([0,1])$ with the metric $d_1(x,y) = \int^1_0 |x(t)-y(t)| \, dt$. Let $$T: X\to Y : x(t) \mapsto y(t) = \int_0^t \frac{1}{\sqrt \tau} \ x(\tau) \, d\tau$$ Is the mapping T uniformly continuous? Definition. $T:(X,d_x) \to (Y,d_y)$ is uniformly continuous if $\forall \epsilon$, $\exists \delta = \delta(\epsilon)$ : $$ \quad T(B(a,\delta)) \subset B(T_a,\epsilon), \qquad \forall a \in X$$ Usage of $\delta$ in the definition confuses me how can I prove this?",,"['functional-analysis', 'uniform-continuity']"
90,Spectrum and Point-spectrum of an operator,Spectrum and Point-spectrum of an operator,,"Let $(\lambda_n)_{n\in\mathbb{R}}$ be a bounded sequence. $T:l^p\rightarrow l^p, (Tx)_i:=\lambda_ix_i\forall i\in\mathbb{N}$. Find the spectrum $\sigma(T)$ and point-spectrum $\sigma_p(T)$.   The definitions are:   $$\sigma(T):=\mathbb{R}/\{\lambda\in \mathbb{R}|ker(\lambda*Id-T)=\{0\}\cap Im(\lambda*Id-T)=l^p\}$$   $$\sigma_p(T):=\{\lambda\in\sigma(T)|ker(\lambda*Id-T)\neq\{0\}\}$$ I guess the spectrum consists of all $\lambda$, so that $(T-\lambda*Id)$ is not invertable. The point-spectrum consists of all $a$ so there is a $i\in\mathbb{N}$ with $a_i=\lambda_i$. Is that correct? How can I show that? Is there a simple way to proof that?","Let $(\lambda_n)_{n\in\mathbb{R}}$ be a bounded sequence. $T:l^p\rightarrow l^p, (Tx)_i:=\lambda_ix_i\forall i\in\mathbb{N}$. Find the spectrum $\sigma(T)$ and point-spectrum $\sigma_p(T)$.   The definitions are:   $$\sigma(T):=\mathbb{R}/\{\lambda\in \mathbb{R}|ker(\lambda*Id-T)=\{0\}\cap Im(\lambda*Id-T)=l^p\}$$   $$\sigma_p(T):=\{\lambda\in\sigma(T)|ker(\lambda*Id-T)\neq\{0\}\}$$ I guess the spectrum consists of all $\lambda$, so that $(T-\lambda*Id)$ is not invertable. The point-spectrum consists of all $a$ so there is a $i\in\mathbb{N}$ with $a_i=\lambda_i$. Is that correct? How can I show that? Is there a simple way to proof that?",,['functional-analysis']
91,"If $f(x)+g(x)$ is strictly concave, then is $x+(g \circ f^{-1})(x)$ also strictly concave?","If  is strictly concave, then is  also strictly concave?",f(x)+g(x) x+(g \circ f^{-1})(x),"Suppose I have continuous, single variable functions $f$ and $g$ : $\mathbb{R\rightarrow}\mathbb{R}$ (both are twice continuously differentiable). Define $H$ as follows $$H(x)=f(x)+g(x)$$ I know that $H(x)$ is strictly concave. Now suppose that $f$ is invertible and its inverse $f^{-1}$ is twice cont. differentiable everywhere. Define a new $\hat{H}$ as follows $$\hat{H}(x)=x+(g \circ f^{-1})(x)$$ Is $\hat{H}$ concave in $x$? Since both $g$ and $f^{-1}$ are twice continuously differentiable, so too then is $(g \circ f^{-1})(x)$. Hence we may inspect the sign of $\hat{H}''$. $\hat{H}''$ is  given by $$\hat{H}''=\frac{g'' \circ f^{-1}}{f'(f^{-1}(x))}-\bigg(\frac{(g' \circ f^{-1})(f''(x))}{\big(f'(f^{-1}(x))\big)^3}\bigg)$$ which is concave if $$\frac{g'' \circ f^{-1}}{g' \circ f^{-1}}<\frac{f''(x)}{\big[f'(f^{-1}(x))\big]^2}$$ Is there some insight that would simplify the checking of the sign, or is the answer only accessible through laborious computing?","Suppose I have continuous, single variable functions $f$ and $g$ : $\mathbb{R\rightarrow}\mathbb{R}$ (both are twice continuously differentiable). Define $H$ as follows $$H(x)=f(x)+g(x)$$ I know that $H(x)$ is strictly concave. Now suppose that $f$ is invertible and its inverse $f^{-1}$ is twice cont. differentiable everywhere. Define a new $\hat{H}$ as follows $$\hat{H}(x)=x+(g \circ f^{-1})(x)$$ Is $\hat{H}$ concave in $x$? Since both $g$ and $f^{-1}$ are twice continuously differentiable, so too then is $(g \circ f^{-1})(x)$. Hence we may inspect the sign of $\hat{H}''$. $\hat{H}''$ is  given by $$\hat{H}''=\frac{g'' \circ f^{-1}}{f'(f^{-1}(x))}-\bigg(\frac{(g' \circ f^{-1})(f''(x))}{\big(f'(f^{-1}(x))\big)^3}\bigg)$$ which is concave if $$\frac{g'' \circ f^{-1}}{g' \circ f^{-1}}<\frac{f''(x)}{\big[f'(f^{-1}(x))\big]^2}$$ Is there some insight that would simplify the checking of the sign, or is the answer only accessible through laborious computing?",,"['real-analysis', 'functional-analysis', 'functions', 'derivatives']"
92,"If a non-linear map preserves inner product, does it necessarily preserve distance?","If a non-linear map preserves inner product, does it necessarily preserve distance?",,"Let $(S, \langle\, , \rangle)$ be a prehilbertian space. I know that if a map $f: S \rightarrow S$ preserves norm but is not linear then it need not preserve metric. For instance, consider $f : (r\cos (\theta ), r\sin (\theta )) \mapsto$ $(r\cos (r\theta ), r\sin (r\theta )) $. We have $d(f(0,1),f(0,2))=||f(0,1)-f(0,2)||=||(0,1)-f(0,2)|| > 1=d((0,1),(0,2))$ Now I'm trying to find a counterexample for a map that preserves inner-product but, as above, doesn't preserve metric, but I've got a feeling this doesn't exist, am I right ?","Let $(S, \langle\, , \rangle)$ be a prehilbertian space. I know that if a map $f: S \rightarrow S$ preserves norm but is not linear then it need not preserve metric. For instance, consider $f : (r\cos (\theta ), r\sin (\theta )) \mapsto$ $(r\cos (r\theta ), r\sin (r\theta )) $. We have $d(f(0,1),f(0,2))=||f(0,1)-f(0,2)||=||(0,1)-f(0,2)|| > 1=d((0,1),(0,2))$ Now I'm trying to find a counterexample for a map that preserves inner-product but, as above, doesn't preserve metric, but I've got a feeling this doesn't exist, am I right ?",,"['real-analysis', 'functional-analysis', 'normed-spaces', 'inner-products', 'isometry']"
93,Characterization of continuous functionals on Fréchet spaces in terms of a seminorm,Characterization of continuous functionals on Fréchet spaces in terms of a seminorm,,"I've recently encountered Fréchet spaces for the first time, and I was wondering if it remains true that a functional $T \rightarrow \mathbb{R}$ with $S$ a Fréchet space, is continuous if for all $\phi \in S$  we have $$|T\phi| \leq c\|\phi\|_S$$ where $\|\cdot\|_S$ denotes a semi-norm on the $S$ space. The reason I'm asking is that I have only ever seen the above result formulated for Banach spaces, and I was curious if it extends naturally?","I've recently encountered Fréchet spaces for the first time, and I was wondering if it remains true that a functional $T \rightarrow \mathbb{R}$ with $S$ a Fréchet space, is continuous if for all $\phi \in S$  we have $$|T\phi| \leq c\|\phi\|_S$$ where $\|\cdot\|_S$ denotes a semi-norm on the $S$ space. The reason I'm asking is that I have only ever seen the above result formulated for Banach spaces, and I was curious if it extends naturally?",,"['functional-analysis', 'topological-vector-spaces']"
94,Subset of Banach space is bounded,Subset of Banach space is bounded,,"I am currently having problems understanding the following problem: Let X be a Banach space and M be a subset of X such that  $$\forall l \in X' \exists c \gt 0: \sup_{m\in M}l(m) \le c$$ Show that M is bounded. (X' is the dual space of X) My approach would have simply been to assume M is not bounded. Then, we can find a sequence $(x_n)\subseteq M$ with $\Vert x_n\Vert \ge n$. Now, let $l:X\to \mathbb{R}, l(x)=\Vert x\Vert$. Then, $l(x_n)\ge n$. Thus, $\sup_{m\in M}l(m) = \infty$. But this solution seems to be too easy. Also, I did not even use the fact that X is a Banach space. Where did I make a mistake? How should I approach this problem correctly?","I am currently having problems understanding the following problem: Let X be a Banach space and M be a subset of X such that  $$\forall l \in X' \exists c \gt 0: \sup_{m\in M}l(m) \le c$$ Show that M is bounded. (X' is the dual space of X) My approach would have simply been to assume M is not bounded. Then, we can find a sequence $(x_n)\subseteq M$ with $\Vert x_n\Vert \ge n$. Now, let $l:X\to \mathbb{R}, l(x)=\Vert x\Vert$. Then, $l(x_n)\ge n$. Thus, $\sup_{m\in M}l(m) = \infty$. But this solution seems to be too easy. Also, I did not even use the fact that X is a Banach space. Where did I make a mistake? How should I approach this problem correctly?",,"['functional-analysis', 'banach-spaces', 'dual-spaces']"
95,Injectiveness of an infinite triangular matrix,Injectiveness of an infinite triangular matrix,,"Let $A$ be an infinite upper triangular matrix with complex entries and all diagonal entries nonzero, i.e., \begin{align} A=\left(\begin{matrix} a_{11}&a_{12}&a_{13}&\cdots\\ a_{21}&a_{22}&a_{23}&\cdots\\ a_{31}&a_{32}&a_{33}&\cdots\\ \vdots&\vdots&\vdots&\ddots \end{matrix}\right) \end{align} where $a_{ij}=0(j<i)$ and $a_{ii}\neq 0(\forall i)$. Moreover, assume that $A$ represents a bounded linear operator on an $\ell^p$-space, and for convenience, say, from $\ell^2(\mathbb N)$ to itself. Though any finite triangular matrix with nonzero diagonal entries must be invertible because of its nonvanishing determinant, it seems that for such an infinite matrix $A$, only its range can be easily seen. What I am wondering are: Is $A$ always injective (and if not is there any counterexample, and is there any condition under which $A$ is injective)? If $A$ is not necessarily injective, is there any example that $A$ is injective and there are infinitely many subdiagonals of $A$ that are not eventually zero? Any help is greatly appreciated.","Let $A$ be an infinite upper triangular matrix with complex entries and all diagonal entries nonzero, i.e., \begin{align} A=\left(\begin{matrix} a_{11}&a_{12}&a_{13}&\cdots\\ a_{21}&a_{22}&a_{23}&\cdots\\ a_{31}&a_{32}&a_{33}&\cdots\\ \vdots&\vdots&\vdots&\ddots \end{matrix}\right) \end{align} where $a_{ij}=0(j<i)$ and $a_{ii}\neq 0(\forall i)$. Moreover, assume that $A$ represents a bounded linear operator on an $\ell^p$-space, and for convenience, say, from $\ell^2(\mathbb N)$ to itself. Though any finite triangular matrix with nonzero diagonal entries must be invertible because of its nonvanishing determinant, it seems that for such an infinite matrix $A$, only its range can be easily seen. What I am wondering are: Is $A$ always injective (and if not is there any counterexample, and is there any condition under which $A$ is injective)? If $A$ is not necessarily injective, is there any example that $A$ is injective and there are infinitely many subdiagonals of $A$ that are not eventually zero? Any help is greatly appreciated.",,"['linear-algebra', 'functional-analysis', 'operator-theory', 'hilbert-spaces']"
96,The elliptic regularity theorem for differential operators with variable coefficients,The elliptic regularity theorem for differential operators with variable coefficients,,"I'm following the book ""Introduction to the theory of distributions"" by Friedlander and Joshi. There is the following result p. 109 $Theorem (8.6.1)$. Let $X \subset \mathbb{R}^n$ be an open set, and let $P$ be an elliptic operator with constant coefficients. Then $$\mathrm{singsupp}(u)=\mathrm{singsupp}(Pu)$$ As an observation after the demonstration says: ""This principle, applied to Schwartz kernels and backed by an apropriate construction, gives the elliptic regularity theorem for differential operators with variable coefficients."" Would you give me references for this more general case? Is necessary the theory of pseudo-differential operators? Thank you for any reply.","I'm following the book ""Introduction to the theory of distributions"" by Friedlander and Joshi. There is the following result p. 109 $Theorem (8.6.1)$. Let $X \subset \mathbb{R}^n$ be an open set, and let $P$ be an elliptic operator with constant coefficients. Then $$\mathrm{singsupp}(u)=\mathrm{singsupp}(Pu)$$ As an observation after the demonstration says: ""This principle, applied to Schwartz kernels and backed by an apropriate construction, gives the elliptic regularity theorem for differential operators with variable coefficients."" Would you give me references for this more general case? Is necessary the theory of pseudo-differential operators? Thank you for any reply.",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'distribution-theory', 'regularity-theory-of-pdes']"
97,$\ell^\infty(\mathbb{N})$ is not separable,is not separable,\ell^\infty(\mathbb{N}),"Show, that $\ell^\infty(\mathbb{N})$ is not separable. Use, that $\mathcal{P}(\mathbb{N})$ is uncountable and observe the set $\{1_A\colon A\in\mathcal{P}(\mathbb{N})\}\subseteq\ell^\infty(\mathbb{N})$. Suppose $\ell^\infty(\mathbb{N})$ is separable. Then it exists a countable, dense set $D=\{d_n\colon n\in\mathbb{N}\}\subseteq\ell^\infty(\mathbb{N})$. Since $D$ is dense in $\ell^\infty(\mathbb{N})$ exists for every $a_k\in\ell^\infty(\mathbb{N})$ and $\varepsilon>0$ a sequence $(d_k^{(n)})\subseteq D$ with $\|d_k^{(n)}-a_k\|_{\infty}=\|d_k(n)-a_k(n)\|_{\infty}<\varepsilon$ Now I want to construct an $(a_k)$ such that it can not be the limit of any $d_k\in D$. I am trying to follow the hint in the task: $a_k=\begin{cases} 0,~~ \text{if}~~ |d_k(k)|>1\\ 1,~~ \text{else}\end{cases}$ Now we have: $\vert|d_k(n)-a_k(n)\|_\infty=\sup_{n\in\mathbb{N}} |d_k(n)-a_k(n)|\geq 1$ for all $n\in\mathbb{N}$ This is a contradiction. Hence $\ell^\infty(\mathbb{N})$ is separable. Is this correct? Thanks in advance for your help.","Show, that $\ell^\infty(\mathbb{N})$ is not separable. Use, that $\mathcal{P}(\mathbb{N})$ is uncountable and observe the set $\{1_A\colon A\in\mathcal{P}(\mathbb{N})\}\subseteq\ell^\infty(\mathbb{N})$. Suppose $\ell^\infty(\mathbb{N})$ is separable. Then it exists a countable, dense set $D=\{d_n\colon n\in\mathbb{N}\}\subseteq\ell^\infty(\mathbb{N})$. Since $D$ is dense in $\ell^\infty(\mathbb{N})$ exists for every $a_k\in\ell^\infty(\mathbb{N})$ and $\varepsilon>0$ a sequence $(d_k^{(n)})\subseteq D$ with $\|d_k^{(n)}-a_k\|_{\infty}=\|d_k(n)-a_k(n)\|_{\infty}<\varepsilon$ Now I want to construct an $(a_k)$ such that it can not be the limit of any $d_k\in D$. I am trying to follow the hint in the task: $a_k=\begin{cases} 0,~~ \text{if}~~ |d_k(k)|>1\\ 1,~~ \text{else}\end{cases}$ Now we have: $\vert|d_k(n)-a_k(n)\|_\infty=\sup_{n\in\mathbb{N}} |d_k(n)-a_k(n)|\geq 1$ for all $n\in\mathbb{N}$ This is a contradiction. Hence $\ell^\infty(\mathbb{N})$ is separable. Is this correct? Thanks in advance for your help.",,"['functional-analysis', 'separable-spaces']"
98,What is the period of $f(2x)$ if $f(2x+6) = f(2x)$ and that of $f(x)$?,What is the period of  if  and that of ?,f(2x) f(2x+6) = f(2x) f(x),"The question is in the title. Also note that $f(x)$ is non-constant function . This is not same as other question asked from similar title. I understand that if I put $x+3$ in place of $x$ in $f(2x)$, I get the same function. So the period must be $3$. And that the period of $f(x)$ must be $6$. But 'The book' says period of $f(2x)$ is $6$ and of $f(x)$ is $12$. I cannot understand this.","The question is in the title. Also note that $f(x)$ is non-constant function . This is not same as other question asked from similar title. I understand that if I put $x+3$ in place of $x$ in $f(2x)$, I get the same function. So the period must be $3$. And that the period of $f(x)$ must be $6$. But 'The book' says period of $f(2x)$ is $6$ and of $f(x)$ is $12$. I cannot understand this.",,"['algebra-precalculus', 'functional-analysis', 'functions', 'periodic-functions']"
99,Banach Steinhaus Theorem: Necessity of Completeness,Banach Steinhaus Theorem: Necessity of Completeness,,I came across this proof of the Banach-Steinhaus theorem in my textbook: I was wondering where exactly the author of the proof used the completeness of $V$. Does this have to do with the initial construction of $U \subset V$?,I came across this proof of the Banach-Steinhaus theorem in my textbook: I was wondering where exactly the author of the proof used the completeness of $V$. Does this have to do with the initial construction of $U \subset V$?,,"['real-analysis', 'functional-analysis', 'metric-spaces', 'linear-transformations', 'banach-spaces']"
