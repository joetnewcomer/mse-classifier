,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Subtle difference between convergence in measure and almost uniform convergence?,Subtle difference between convergence in measure and almost uniform convergence?,,"I am reading Terence Tao's post on convergence types . Consider the following two types: We say a sequence $f_n : \mathbb R \to \mathbb R$ converges in measure   to a function $f$ if and only if for every $\varepsilon > 0$ $$\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \})\to 0$$ as $n \to \infty$. On the other hand, $f_n $ converges to $f$ almost uniformly if for every $\varepsilon >  0$ there is a set $E$ such that $\mu(E) \le \varepsilon$ and outside   $E$, $f_n\to f$ uniformly. To me these seem very similar. Concretely, the expression $\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \})\to 0$ could be rewritten to say that given any $\delta > 0$ then $\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \}) \le \delta$. Then the set $\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \}$ would be the set $E$ outside of which $|f_n - f |<\varepsilon$ that is, outside of which $f_n \to f$ uniformly. Question Please could someone elaborate on the difference of these two   definitions? Perhaps with an example? I need some help gaining   intuition.","I am reading Terence Tao's post on convergence types . Consider the following two types: We say a sequence $f_n : \mathbb R \to \mathbb R$ converges in measure   to a function $f$ if and only if for every $\varepsilon > 0$ $$\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \})\to 0$$ as $n \to \infty$. On the other hand, $f_n $ converges to $f$ almost uniformly if for every $\varepsilon >  0$ there is a set $E$ such that $\mu(E) \le \varepsilon$ and outside   $E$, $f_n\to f$ uniformly. To me these seem very similar. Concretely, the expression $\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \})\to 0$ could be rewritten to say that given any $\delta > 0$ then $\mu(\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \}) \le \delta$. Then the set $\{x \in \mathbb R \mid |f_n(x) - f(x)|\ge \varepsilon \}$ would be the set $E$ outside of which $|f_n - f |<\varepsilon$ that is, outside of which $f_n \to f$ uniformly. Question Please could someone elaborate on the difference of these two   definitions? Perhaps with an example? I need some help gaining   intuition.",,"['real-analysis', 'measure-theory', 'intuition']"
1,What is so good about the $L^2$-norm of the second derivative being small?,What is so good about the -norm of the second derivative being small?,L^2,"One of the main properties of cubic splines is the minimality property which basically means that if $s$ (cubic spline) and $g$ (some other function) interpolate $f$ in a certain way then $$\Vert s'' \Vert_2 \leq \Vert g'' \Vert_2.$$ First of all, I am somewhat surprised to encounter a stand-alone function under a norm, most of the time we care about a difference, e.g. $\Vert s - f \Vert$. How do we interpret $\Vert s'' \Vert_2$? What is so good about the $L^2$-norm of the second derivative being small?","One of the main properties of cubic splines is the minimality property which basically means that if $s$ (cubic spline) and $g$ (some other function) interpolate $f$ in a certain way then $$\Vert s'' \Vert_2 \leq \Vert g'' \Vert_2.$$ First of all, I am somewhat surprised to encounter a stand-alone function under a norm, most of the time we care about a difference, e.g. $\Vert s - f \Vert$. How do we interpret $\Vert s'' \Vert_2$? What is so good about the $L^2$-norm of the second derivative being small?",,"['real-analysis', 'measure-theory', 'derivatives', 'numerical-methods', 'lebesgue-integral']"
2,Examples of predictable processes,Examples of predictable processes,,"I am asked to prove that the following processes are predictable. I am used to looking at stochastic processes as sequences of random variables (by fixing time) or as a collection of paths (by fixing $\omega$) but I find it hard to picture the two varying together. For this reason the notions of predictability and progressive measurability somewhat escape me. Anyway, here are the processes I am interested in. (a) Suppose $h : \mathbf{R}_+ \rightarrow \mathbf{R}$ is a Borel measurable function. Show that $X(t,\omega) = h(t)$ is predictable. Here is my attempt. First I fix an arbitrary Borel set $B\in\mathbf{R}$. Then I say $\{(t,\omega): X(t,\omega)\in B\} = \{(t,\Omega): h(t)\in B\} = (\bar{B},\Omega)$ for some $\bar{B}\in \mathcal{B}_{\mathbf{R}_+}$. The first equality is due to the deterministic nature of $h$ and the second one is due to the fact it is Borel measurable. Since I can generate $(\bar{B},\Omega)$ by using sets of the form $((a,b],\Omega)$, which are all in the predictable $\sigma$-algebra, $(\bar{B},\Omega)$ is also in the predictable $\sigma$-algebra. Does this sound right? (b): $X$ is a predictable process. $g :\mathbf{R} \rightarrow \mathbf{R}$ is a Borel function. Then, $Z_t = g(X_t)$ is also predictable. The intuitive answer that I would give is that Borel functions preserve measurability. Hence, if $X$ is measurable with respect to a sigma algebra, then $g(X)$ is also measurable with respect to that sigma algebra. But this doesn't constitute a rigorous answer so I write the following. $$\{(t,\omega): g(X(t,\omega)) \in B\} = \{(t,\omega): X(t,\omega) \in \bar{B}\}$$ The RHS is in the predictable sigma algebra since $X$ is predictable so this is it I guess. (c): $X$ is a predictable process. $g :\mathbf{R}_+\times\mathbf{R} \rightarrow \mathbf{R}$ is a Borel function. $Z_t = g(t,X_t)$ is predictable. There is a hint which suggests that I start with functions of the form $h(t)g(X_t)$ and apply the $\pi-\lambda$ lemma. I know that the product of two measurable functions is again measurable. So $h(t)g(X_t)$ is predictable. But I don't see how one could apply the $\pi-\lambda$ lemma to extend the result to arbitrary functions of the form $g(t,X_t)$?","I am asked to prove that the following processes are predictable. I am used to looking at stochastic processes as sequences of random variables (by fixing time) or as a collection of paths (by fixing $\omega$) but I find it hard to picture the two varying together. For this reason the notions of predictability and progressive measurability somewhat escape me. Anyway, here are the processes I am interested in. (a) Suppose $h : \mathbf{R}_+ \rightarrow \mathbf{R}$ is a Borel measurable function. Show that $X(t,\omega) = h(t)$ is predictable. Here is my attempt. First I fix an arbitrary Borel set $B\in\mathbf{R}$. Then I say $\{(t,\omega): X(t,\omega)\in B\} = \{(t,\Omega): h(t)\in B\} = (\bar{B},\Omega)$ for some $\bar{B}\in \mathcal{B}_{\mathbf{R}_+}$. The first equality is due to the deterministic nature of $h$ and the second one is due to the fact it is Borel measurable. Since I can generate $(\bar{B},\Omega)$ by using sets of the form $((a,b],\Omega)$, which are all in the predictable $\sigma$-algebra, $(\bar{B},\Omega)$ is also in the predictable $\sigma$-algebra. Does this sound right? (b): $X$ is a predictable process. $g :\mathbf{R} \rightarrow \mathbf{R}$ is a Borel function. Then, $Z_t = g(X_t)$ is also predictable. The intuitive answer that I would give is that Borel functions preserve measurability. Hence, if $X$ is measurable with respect to a sigma algebra, then $g(X)$ is also measurable with respect to that sigma algebra. But this doesn't constitute a rigorous answer so I write the following. $$\{(t,\omega): g(X(t,\omega)) \in B\} = \{(t,\omega): X(t,\omega) \in \bar{B}\}$$ The RHS is in the predictable sigma algebra since $X$ is predictable so this is it I guess. (c): $X$ is a predictable process. $g :\mathbf{R}_+\times\mathbf{R} \rightarrow \mathbf{R}$ is a Borel function. $Z_t = g(t,X_t)$ is predictable. There is a hint which suggests that I start with functions of the form $h(t)g(X_t)$ and apply the $\pi-\lambda$ lemma. I know that the product of two measurable functions is again measurable. So $h(t)g(X_t)$ is predictable. But I don't see how one could apply the $\pi-\lambda$ lemma to extend the result to arbitrary functions of the form $g(t,X_t)$?",,"['measure-theory', 'stochastic-processes', 'stochastic-analysis']"
3,Lebesgue measure without choice,Lebesgue measure without choice,,"From this question and this question (and their answers) I gather that it is consistent with ZF without The Axiom of Choice to assume that there exist countable sets $A_n$, $n\in \mathbb N$, such that $\mathbb R=\bigcup_{n\in \mathbb N} A_n$. Given any positive measure $\mu$ on the Borel $\sigma$-algebra of $\mathbb R$ which satisfies $\mu(\{x\})=0$ for all singletons $\{x\}$, this implies $$ \mu(\mathbb R)=\sum_{n\in \mathbb N} \mu(A_n)=0. $$ In particular Lebesgue measure cannot exist. However, when I looked through a construction of Lebesgue measure, I was not able to pinpoint any particular argument that (could not be refined to an argument that) required any choice. This has left me a bit puzzled My question is if I have misunderstood the situation, or if indeed some amount of choice is necessary to construct Lebesgue measure on $\mathbb R$. In the second case, I would be very interested in knowing 'how much' choice is needed.","From this question and this question (and their answers) I gather that it is consistent with ZF without The Axiom of Choice to assume that there exist countable sets $A_n$, $n\in \mathbb N$, such that $\mathbb R=\bigcup_{n\in \mathbb N} A_n$. Given any positive measure $\mu$ on the Borel $\sigma$-algebra of $\mathbb R$ which satisfies $\mu(\{x\})=0$ for all singletons $\{x\}$, this implies $$ \mu(\mathbb R)=\sum_{n\in \mathbb N} \mu(A_n)=0. $$ In particular Lebesgue measure cannot exist. However, when I looked through a construction of Lebesgue measure, I was not able to pinpoint any particular argument that (could not be refined to an argument that) required any choice. This has left me a bit puzzled My question is if I have misunderstood the situation, or if indeed some amount of choice is necessary to construct Lebesgue measure on $\mathbb R$. In the second case, I would be very interested in knowing 'how much' choice is needed.",,"['measure-theory', 'lebesgue-measure', 'axiom-of-choice']"
4,Prove that $\int_{\Omega}|f_n-f_0|d\mu\rightarrow 0$ (by weaker assumption on Scheffé's lemma: $f_n\xrightarrow{\mu} f_0$),Prove that  (by weaker assumption on Scheffé's lemma: ),\int_{\Omega}|f_n-f_0|d\mu\rightarrow 0 f_n\xrightarrow{\mu} f_0,"I'm dealing with this problem. Let $(\Omega,\mathcal{F},\mu)$ be a measure space and $\{f_n\}$ a sequence of nonnegative integrable functions. Suppose $f_n\xrightarrow{\mu} f_0$ and $\displaystyle\int_\Omega f_nd\mu\xrightarrow{n\rightarrow\infty}\int_\Omega f_0d\mu<\infty$. Prove that $\displaystyle\int_{\Omega}|f_n-f_0|d\mu\xrightarrow{n\rightarrow\infty} 0$. If the convergence of $\{f_n\}$s to $f_0$ were almost everywhere , then the problem would become Scheffé's lemma . By convergence in measure, for each $\epsilon>0$ and natural $n$, define : $\displaystyle E^\epsilon_n:=\{\omega\in\Omega\;;\;|f_n-f_0|(\omega)\geq\epsilon\} \;\wedge\;F_n^\epsilon:=\Omega-E^\epsilon_n$ $$\int_\Omega |f_n-f_0|d\mu=I_1+I_2\quad;\quad I_1=\int_{E^\epsilon_n} |f_n-f_0|d\mu\;\wedge\;I_2=\int_{F^\epsilon_n} |f_n-f_0|d\mu$$ We have $\mu(E_n^\epsilon)\rightarrow 0$ and $|f_n-f_0|<\epsilon$ over $F_n^\epsilon$. But I can't control the terms $|f_n-f_0|$ in $I_1$ and $\mu(F_n^\epsilon)$ in $I_2$ when the measure of space is not finite ! EDIT My book has never mentioned ""Scheffé's lemma"".","I'm dealing with this problem. Let $(\Omega,\mathcal{F},\mu)$ be a measure space and $\{f_n\}$ a sequence of nonnegative integrable functions. Suppose $f_n\xrightarrow{\mu} f_0$ and $\displaystyle\int_\Omega f_nd\mu\xrightarrow{n\rightarrow\infty}\int_\Omega f_0d\mu<\infty$. Prove that $\displaystyle\int_{\Omega}|f_n-f_0|d\mu\xrightarrow{n\rightarrow\infty} 0$. If the convergence of $\{f_n\}$s to $f_0$ were almost everywhere , then the problem would become Scheffé's lemma . By convergence in measure, for each $\epsilon>0$ and natural $n$, define : $\displaystyle E^\epsilon_n:=\{\omega\in\Omega\;;\;|f_n-f_0|(\omega)\geq\epsilon\} \;\wedge\;F_n^\epsilon:=\Omega-E^\epsilon_n$ $$\int_\Omega |f_n-f_0|d\mu=I_1+I_2\quad;\quad I_1=\int_{E^\epsilon_n} |f_n-f_0|d\mu\;\wedge\;I_2=\int_{F^\epsilon_n} |f_n-f_0|d\mu$$ We have $\mu(E_n^\epsilon)\rightarrow 0$ and $|f_n-f_0|<\epsilon$ over $F_n^\epsilon$. But I can't control the terms $|f_n-f_0|$ in $I_1$ and $\mu(F_n^\epsilon)$ in $I_2$ when the measure of space is not finite ! EDIT My book has never mentioned ""Scheffé's lemma"".",,"['measure-theory', 'convergence-divergence', 'lebesgue-integral']"
5,On the good set principle and sigma fields.,On the good set principle and sigma fields.,,"Following Probability and measure Theory by Ash (2000). let $\Omega$ be a set, let $C$ be a class of subsets of $\Omega$ and $A \subset \Omega$, we denote by $C \cap A$ the class $\{ B \cap A : B \in C \} $. And the minimal sigma field over $C$ is denoted by $\sigma(C) = F$. Ash wants to show that $B \cap A \in \sigma_A (C \cap A)$. Let $L$ consist of those sets $B \in F$ s.t. $B \cap A \in \sigma_A (C \cap A)$. Now Ash states that $C \subset L$. Why is this true? Edit with original text:","Following Probability and measure Theory by Ash (2000). let $\Omega$ be a set, let $C$ be a class of subsets of $\Omega$ and $A \subset \Omega$, we denote by $C \cap A$ the class $\{ B \cap A : B \in C \} $. And the minimal sigma field over $C$ is denoted by $\sigma(C) = F$. Ash wants to show that $B \cap A \in \sigma_A (C \cap A)$. Let $L$ consist of those sets $B \in F$ s.t. $B \cap A \in \sigma_A (C \cap A)$. Now Ash states that $C \subset L$. Why is this true? Edit with original text:",,"['measure-theory', 'elementary-set-theory', 'self-learning']"
6,Series representation of measurable functions,Series representation of measurable functions,,"I need to show that if a positive function $f$ on $E$, where $(E,\mathcal{E})$ is a measurable space, is $\mathcal{E}$-measurable then it has the form $$f=\sum_{n=1}^{\infty}a_n1_{A_n},$$ for some sequence $(a_n)\subset \bar{\mathbb{R}}_{+}$ and some sequence $(A_n)\subset \mathcal{E}$ (not necessarily disjoint). Since $f$ is measurable and positive it is a pointwise limit of an increasing sequence of positive simple functions, that is $$f(x)=\lim_{k\to\infty}\sum_{n=1}^ka_{n,k}1_{B_{n,k}}(x),\ \forall x\in E,$$ where for all $k$ we can assume $(B_{n,k})_{1\leq n\leq k}\subset \mathcal{E}$ are pairwise disjoint. I'm having trouble understanding what $a_n$'s and $A_n$'s should be since I think that $\lim_{k\to\infty}a_{n,k}$ need not exist (the sets $B_{n,k}$ and $B_{n,k+1}$ can be disjoint).","I need to show that if a positive function $f$ on $E$, where $(E,\mathcal{E})$ is a measurable space, is $\mathcal{E}$-measurable then it has the form $$f=\sum_{n=1}^{\infty}a_n1_{A_n},$$ for some sequence $(a_n)\subset \bar{\mathbb{R}}_{+}$ and some sequence $(A_n)\subset \mathcal{E}$ (not necessarily disjoint). Since $f$ is measurable and positive it is a pointwise limit of an increasing sequence of positive simple functions, that is $$f(x)=\lim_{k\to\infty}\sum_{n=1}^ka_{n,k}1_{B_{n,k}}(x),\ \forall x\in E,$$ where for all $k$ we can assume $(B_{n,k})_{1\leq n\leq k}\subset \mathcal{E}$ are pairwise disjoint. I'm having trouble understanding what $a_n$'s and $A_n$'s should be since I think that $\lim_{k\to\infty}a_{n,k}$ need not exist (the sets $B_{n,k}$ and $B_{n,k+1}$ can be disjoint).",,"['real-analysis', 'measure-theory']"
7,Comparing lebesgue measure and counting measure,Comparing lebesgue measure and counting measure,,"I have the following problem from Folland: Let $X = [0, 1]$, $\mathcal{M} = \mathcal{B}_{[0, 1]}$, $m = $ Lebesgue measure and $\mu = $ counting measure. $m \ll \mu$ but $dm \neq f \, d\mu$ for any $f$. $\mu$ has no Lebesgue decomposition with respect to $m$. I think I might be understanding counting measure incorrectly, because it seems to me that $m \ll \mu$ is not true, because any Borel subset of the open interval $(0, 1)$ would have counting measure zero because it does not contain any integers, but clearly could have positive Lebesgue measure.","I have the following problem from Folland: Let $X = [0, 1]$, $\mathcal{M} = \mathcal{B}_{[0, 1]}$, $m = $ Lebesgue measure and $\mu = $ counting measure. $m \ll \mu$ but $dm \neq f \, d\mu$ for any $f$. $\mu$ has no Lebesgue decomposition with respect to $m$. I think I might be understanding counting measure incorrectly, because it seems to me that $m \ll \mu$ is not true, because any Borel subset of the open interval $(0, 1)$ would have counting measure zero because it does not contain any integers, but clearly could have positive Lebesgue measure.",,"['real-analysis', 'measure-theory']"
8,Hausdorff dimension of $\mathrm{R}^d$,Hausdorff dimension of,\mathrm{R}^d,"I assume the Hausdorff Dimension of $\mathrm{R}^d$ is $d$ . To prove this I guess one has to prove these two statements: the $\alpha$ -dimensional Hausdorff measure of $\mathrm{R}^d$ is $0$ for $\alpha \gt d$ . the $\alpha$ -dimensional Hausdorff measure of $\mathrm{R}^d$ is $\infty$ for $\alpha \lt d$ . Unfortunately I am unable to prove anything here. I guess the trick is to use a clever partition of $\mathrm{R}^d$ , but I don't come up with one. How can I prove this statement?","I assume the Hausdorff Dimension of is . To prove this I guess one has to prove these two statements: the -dimensional Hausdorff measure of is for . the -dimensional Hausdorff measure of is for . Unfortunately I am unable to prove anything here. I guess the trick is to use a clever partition of , but I don't come up with one. How can I prove this statement?",\mathrm{R}^d d \alpha \mathrm{R}^d 0 \alpha \gt d \alpha \mathrm{R}^d \infty \alpha \lt d \mathrm{R}^d,"['measure-theory', 'dimension-theory-analysis']"
9,Uniform convergence and convergence of integrals,Uniform convergence and convergence of integrals,,"Question: $(X,\mathcal{M},\mu)$ measure space. Suppose that $\{f_n\}\subset L^1$ and $f_n\rightarrow f$ uniformly.  Show that if $\mu(X) <\infty$, then $\int f_n\rightarrow \int f$. Proof: I exploit uniform convergence and $\{f_n\}\subset L^1$ to say that $\forall x$  $\exists N$ s.t. $n\geq N \Rightarrow |f_n|\leq M$ where M is finite, then I build the dominating function $g:=M \chi_{[X]}$ and apply the DCT to the sequence $\{f_n\}_{n\geq N}$ and then claim that $\lim_{n\geq N\rightarrow\infty}\int f_n=\lim_{n\rightarrow\infty}\int f_n$. Makes sense? (I am new to math, please show mercy)","Question: $(X,\mathcal{M},\mu)$ measure space. Suppose that $\{f_n\}\subset L^1$ and $f_n\rightarrow f$ uniformly.  Show that if $\mu(X) <\infty$, then $\int f_n\rightarrow \int f$. Proof: I exploit uniform convergence and $\{f_n\}\subset L^1$ to say that $\forall x$  $\exists N$ s.t. $n\geq N \Rightarrow |f_n|\leq M$ where M is finite, then I build the dominating function $g:=M \chi_{[X]}$ and apply the DCT to the sequence $\{f_n\}_{n\geq N}$ and then claim that $\lim_{n\geq N\rightarrow\infty}\int f_n=\lim_{n\rightarrow\infty}\int f_n$. Makes sense? (I am new to math, please show mercy)",,"['measure-theory', 'convergence-divergence', 'lebesgue-integral', 'uniform-convergence', 'solution-verification']"
10,Borel sets and metric exterior measure (abstract measure spaces),Borel sets and metric exterior measure (abstract measure spaces),,"An exterior measure $\mu_*$ on $X$ is called a metric exterior measure if it satisfies $\mu_* (A\cup B)=\mu_*(A) + \mu_*(B)$ whenever the distance between $A$ and $B$ is positive. Now this theorem says that if $\mu_*$ is a metric exterior measure on a metric space $X$, then the Borel sets in $X$ are measurable. The proof proceeds by mentioning that it suffices to prove that closed sets in $X$ are Caratheodory measurable in view of the definition of a Borel set. I am not quite sure why the last statement is true. I know that if we can show that a closed set $F$ is Caratheodory measurable then so it it's complement (i.e. an open set). But a Borel set is an element of the Borel sigma algebra that is the intersection of all sigma algebras that contain the open sets. Certainly, Borel sets are not necessarily open so how will I use the fact that a closed set is Caratheodory measurable? Thanks - help appreciated!","An exterior measure $\mu_*$ on $X$ is called a metric exterior measure if it satisfies $\mu_* (A\cup B)=\mu_*(A) + \mu_*(B)$ whenever the distance between $A$ and $B$ is positive. Now this theorem says that if $\mu_*$ is a metric exterior measure on a metric space $X$, then the Borel sets in $X$ are measurable. The proof proceeds by mentioning that it suffices to prove that closed sets in $X$ are Caratheodory measurable in view of the definition of a Borel set. I am not quite sure why the last statement is true. I know that if we can show that a closed set $F$ is Caratheodory measurable then so it it's complement (i.e. an open set). But a Borel set is an element of the Borel sigma algebra that is the intersection of all sigma algebras that contain the open sets. Certainly, Borel sets are not necessarily open so how will I use the fact that a closed set is Caratheodory measurable? Thanks - help appreciated!",,"['real-analysis', 'measure-theory']"
11,Possible typo in Bogachev's Measure Theory,Possible typo in Bogachev's Measure Theory,,"I've a problem with the definition of a measure space in Bogachev's Measure Theory . The author (Definition 1.3.2, p. 9) assumes a measure to be a countably additive set function defined on an algebra of sets (Definition 1.2.1, p. 3), and let a countable additive set function be a real-valued set function (for which the usual conditions hold). But (see the top of p. 9) a real-valued function means, in the terminology of Bogachev, a function with values in the open interval $(-\infty, +\infty)$, so in particular a measure is not allowed to take the value $+\infty$. This looks like a typo to me, so I'd like to know (i) if I am missing something obvious and (ii) if there is an errata corrige for the book somewhere. Edit. I'm all the more convinced that it is a typo because later on, in Example 4.7.89 (p. 311), the author mentions the counting measure, which he defines, as usual, as the cardinality of the measured set. But I'd really like to hear from somebody else. Thanks.","I've a problem with the definition of a measure space in Bogachev's Measure Theory . The author (Definition 1.3.2, p. 9) assumes a measure to be a countably additive set function defined on an algebra of sets (Definition 1.2.1, p. 3), and let a countable additive set function be a real-valued set function (for which the usual conditions hold). But (see the top of p. 9) a real-valued function means, in the terminology of Bogachev, a function with values in the open interval $(-\infty, +\infty)$, so in particular a measure is not allowed to take the value $+\infty$. This looks like a typo to me, so I'd like to know (i) if I am missing something obvious and (ii) if there is an errata corrige for the book somewhere. Edit. I'm all the more convinced that it is a typo because later on, in Example 4.7.89 (p. 311), the author mentions the counting measure, which he defines, as usual, as the cardinality of the measured set. But I'd really like to hear from somebody else. Thanks.",,"['measure-theory', 'reference-request']"
12,"Real valued function of two variables defined on a square with area one, Partial derivatives exist and bounded by an Lebesgue intergrable function","Real valued function of two variables defined on a square with area one, Partial derivatives exist and bounded by an Lebesgue intergrable function",,"This problem in my real analysis textbook has been, let's just say, troubling me. Here is the problem: Let $f$ be a real-valued function of two variables $(x,y)$ that is defined on the square $D=\{(x,y): 0\le x \le 1, 0 \le y \le 1\}$ and $f$ is a measurable function of $x$ for each fixed value of $y$. For each $(x,y) \in D$ let the partial derivative $\frac {\partial f} {\partial y}$ exist. Also Suppose there is a function $g$ that is integrable over $[0,1]$ such that $\frac {\partial f} {\partial y}(x,y) \le g(x)$ for all $(x,y) \in D$. Prove that:   $$ \frac d {dy} \bigg[ \int_0^1 f(x,y)dx \bigg]= \int_0^1 \frac {\partial f} {\partial y}(x,y)dx \ \ \ \ \forall y \in [0,1] $$ What I'm really having trouble with is wrapping my head around what is going on. I will list what I know: Each $f$ is measurable on all of the $x$ values when $ y$ is fixed. The partial derivative of $f$ w.r.t. $y$ exists for each point i.e. $\ \ \exists \frac {\partial f} {\partial y}(x,y)$ The partial derivatives are bounded by an integrable function $g$ of $x$, integrable implies $\int_{[0,1]} g < \infty$ So essentially what I'm trying to show is that the derivative of the area w.r.t. $y$ can be rewritten as the area of a partial derivative of $f$ w.r.t. $y$. Honestly, I just have no idea where to begin. Some tips, hints, or proofs would be greatly appreciated!","This problem in my real analysis textbook has been, let's just say, troubling me. Here is the problem: Let $f$ be a real-valued function of two variables $(x,y)$ that is defined on the square $D=\{(x,y): 0\le x \le 1, 0 \le y \le 1\}$ and $f$ is a measurable function of $x$ for each fixed value of $y$. For each $(x,y) \in D$ let the partial derivative $\frac {\partial f} {\partial y}$ exist. Also Suppose there is a function $g$ that is integrable over $[0,1]$ such that $\frac {\partial f} {\partial y}(x,y) \le g(x)$ for all $(x,y) \in D$. Prove that:   $$ \frac d {dy} \bigg[ \int_0^1 f(x,y)dx \bigg]= \int_0^1 \frac {\partial f} {\partial y}(x,y)dx \ \ \ \ \forall y \in [0,1] $$ What I'm really having trouble with is wrapping my head around what is going on. I will list what I know: Each $f$ is measurable on all of the $x$ values when $ y$ is fixed. The partial derivative of $f$ w.r.t. $y$ exists for each point i.e. $\ \ \exists \frac {\partial f} {\partial y}(x,y)$ The partial derivatives are bounded by an integrable function $g$ of $x$, integrable implies $\int_{[0,1]} g < \infty$ So essentially what I'm trying to show is that the derivative of the area w.r.t. $y$ can be rewritten as the area of a partial derivative of $f$ w.r.t. $y$. Honestly, I just have no idea where to begin. Some tips, hints, or proofs would be greatly appreciated!",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
13,Integrals and Dirac delta measures,Integrals and Dirac delta measures,,Why is it the case that in general $\int X d\delta_k(w) = X(k) $??  I can't seem to work it out but it seems like a useful fact?,Why is it the case that in general $\int X d\delta_k(w) = X(k) $??  I can't seem to work it out but it seems like a useful fact?,,['measure-theory']
14,Derivative of the measure of the set where $f > t$,Derivative of the measure of the set where,f > t,"Let $f$ be a continuous function on a topological measure space $(X,\mu)$. Define $g(t) = \mu\{f \geq t\}$ for $t\in \mathbb R$. I am interested in the derivative of $g$. Is there a simple expression for it? What conditions on $f$ will ensure that it exists almost everywhere? What about everywhere?","Let $f$ be a continuous function on a topological measure space $(X,\mu)$. Define $g(t) = \mu\{f \geq t\}$ for $t\in \mathbb R$. I am interested in the derivative of $g$. Is there a simple expression for it? What conditions on $f$ will ensure that it exists almost everywhere? What about everywhere?",,['measure-theory']
15,An equivalent definition of uniform integrability,An equivalent definition of uniform integrability,,"Let $(X,\mathcal{M},\mu)$ be a measure space and $\{f\}$ be a sequence of functions on $X$, each of which is integrable over $X$. Show that $\{f_n\}$ is uniformly integrable if and only if for each $\varepsilon \gt 0$, there is a $\delta \gt 0$ such that for any natural number $n$ and measurable subset $E$ of $X$, if $\mu(E) \lt \delta$, $$ \left|\int_E f_n~d\mu\right| \lt \epsilon.$$ I think one direction $(\Rightarrow)$ is clear. Since $f_n$ being uniformly integrable imply that for every $\varepsilon\gt 0,~\exists \delta \gt 0$ such that for any $E\in \mathcal{M},~\mu(E)\lt \delta$, $\int_E |f_n|~d\mu$ for every natural $n$. But then $$ \left|\int_E f_n~d\mu\right|\le \int_E|f_n|~d\mu \lt \varepsilon.$$ Any suggestions for the other direction? Edit: Following Davide's suggestions, I have $$ \begin{align*} \int_E |f_n|~d\mu & \le \int_{E\cap [f_n \ge 0]} f_n~d\mu + \int_{E\cap [f_n \lt 0]} (-f_n)~d\mu\\ & = \left| \int_{E\cap [f_n \ge 0]} f_n~d\mu \right| + \left| \int_{E\cap [f_n \lt 0]}f_n~d\mu \right| \\ & \lt \varepsilon + \varepsilon = 2\varepsilon. \end{align*} $$","Let $(X,\mathcal{M},\mu)$ be a measure space and $\{f\}$ be a sequence of functions on $X$, each of which is integrable over $X$. Show that $\{f_n\}$ is uniformly integrable if and only if for each $\varepsilon \gt 0$, there is a $\delta \gt 0$ such that for any natural number $n$ and measurable subset $E$ of $X$, if $\mu(E) \lt \delta$, $$ \left|\int_E f_n~d\mu\right| \lt \epsilon.$$ I think one direction $(\Rightarrow)$ is clear. Since $f_n$ being uniformly integrable imply that for every $\varepsilon\gt 0,~\exists \delta \gt 0$ such that for any $E\in \mathcal{M},~\mu(E)\lt \delta$, $\int_E |f_n|~d\mu$ for every natural $n$. But then $$ \left|\int_E f_n~d\mu\right|\le \int_E|f_n|~d\mu \lt \varepsilon.$$ Any suggestions for the other direction? Edit: Following Davide's suggestions, I have $$ \begin{align*} \int_E |f_n|~d\mu & \le \int_{E\cap [f_n \ge 0]} f_n~d\mu + \int_{E\cap [f_n \lt 0]} (-f_n)~d\mu\\ & = \left| \int_{E\cap [f_n \ge 0]} f_n~d\mu \right| + \left| \int_{E\cap [f_n \lt 0]}f_n~d\mu \right| \\ & \lt \varepsilon + \varepsilon = 2\varepsilon. \end{align*} $$",,"['real-analysis', 'measure-theory', 'uniform-integrability']"
16,"Lebesgue outer measure of $[0,1]\cap\mathbb{Q}$",Lebesgue outer measure of,"[0,1]\cap\mathbb{Q}","Consider the Lebesgue outer measure  $$ \bar{m}(X) = \inf_{A \supset X}\bigg\{\sup_{P\subset A}\quad m(P)\bigg\} $$ where $X = [0,1]\cap \mathbb{Q}$ and $P = \bigcup [a_i,b_i]$  is a suitable union of intervals. My question is: suppose that $\bar{m}(X)=0$: can you exhibit one of those $A$'s? Thanks","Consider the Lebesgue outer measure  $$ \bar{m}(X) = \inf_{A \supset X}\bigg\{\sup_{P\subset A}\quad m(P)\bigg\} $$ where $X = [0,1]\cap \mathbb{Q}$ and $P = \bigcup [a_i,b_i]$  is a suitable union of intervals. My question is: suppose that $\bar{m}(X)=0$: can you exhibit one of those $A$'s? Thanks",,[]
17,Lebesgue's Theorem on Differentiation of measures?,Lebesgue's Theorem on Differentiation of measures?,,"I'm currently going through Ahlfors's ""Lectures of Quasiconformal Mappings,"" and there is a part that I would like more a bit more detail on. Let $f$ be a orientation preserving homeomorphism on the plane, and we define a measure $A(E)$ as the area of $f(E)$. On page 18, it says that ""This defines a locally finite additive measure, and according to a theorem of Lebesgue such a measure has a symmetric derivative a.e., that is, $$J(z) = \lim \frac{A(Q)}{m(Q)}$$ when $Q$ is a square of center $z$ whose side tends to zero. Moreover, $$\int_E J(z) dxdy \le A(E)$$ (we cannot yet guarantee equality)."" I think this statement is related to the Lebesgue differentiation theorem , but I haven't had luck finding actual the statement of the theorem Ahlfors is supposedly quoting. Could someone point me to a reference? Thank you!","I'm currently going through Ahlfors's ""Lectures of Quasiconformal Mappings,"" and there is a part that I would like more a bit more detail on. Let $f$ be a orientation preserving homeomorphism on the plane, and we define a measure $A(E)$ as the area of $f(E)$. On page 18, it says that ""This defines a locally finite additive measure, and according to a theorem of Lebesgue such a measure has a symmetric derivative a.e., that is, $$J(z) = \lim \frac{A(Q)}{m(Q)}$$ when $Q$ is a square of center $z$ whose side tends to zero. Moreover, $$\int_E J(z) dxdy \le A(E)$$ (we cannot yet guarantee equality)."" I think this statement is related to the Lebesgue differentiation theorem , but I haven't had luck finding actual the statement of the theorem Ahlfors is supposedly quoting. Could someone point me to a reference? Thank you!",,"['real-analysis', 'measure-theory']"
18,More Cantor-like constructions,More Cantor-like constructions,,"Two questions: (1.) Construct a subset of $[0,1]$ in the same manner as the Cantor set, except that at the $k$-th stage, each interval removed has length $\delta 3^{-k}$, $0<\delta <1$. Show that the resulting set is perfect, has measure $1-\delta$, and contains no intervals. Showing that it's perfect is not difficult. The resulting set is an intersection of closed intervals, so is closed. Any point in the set is a limit point of endpoints of intervals (obviously I have more details in my written solution, but that's the idea.) But I don't see how the measure is $1-\delta$... At stage $k$, we remove $2^{k-1}$ intervals of length $\delta 3^{-k}$, so the measure of the resulting set is $$1-\sum\limits_{k=0}^{\infty}{2^{k}\cdot\dfrac{\delta}{3^{k+1}}} = 1-\dfrac{\delta}{3}\cdot\sum\limits_{k=0}^{\infty}{\dfrac{2^k}{3^k}} = 1-\dfrac{2\delta}{3} .$$ Thoughts? (2.) Construct a Cantor-type set subset of $[0,1]$ by removing from each interval remaining at the $k$-th stage a subinterval of relative length $\theta_k$, $0<\theta_k<1$. Show that the remainder has measure zero if and only if $\sum{\theta_k}=\infty$. (Use the fact that for $a_k>0$, $\prod\limits_{k=1}^{\infty}{a_k}$ converges, in the sense that $\lim\limits_{N\to\infty}{\prod\limits_{k=1}^N{a_k}}$ exists and is not zero, if only if $\sum\limits_{k=1}^{\infty}{\log{a_k}}$ converges. ) I don't really understand the construction. Suppose we have our $\theta_1$ and we remove an interval of that length. So then we choose $\theta_2$ so that $\theta_2 < \dfrac{1-\theta_1}{2}$, or something like that? Or... ? The phrasing is weird to me. Secondly, the hint does not help at all; it is complete opaque to me, so any insight you can offer would be great.","Two questions: (1.) Construct a subset of $[0,1]$ in the same manner as the Cantor set, except that at the $k$-th stage, each interval removed has length $\delta 3^{-k}$, $0<\delta <1$. Show that the resulting set is perfect, has measure $1-\delta$, and contains no intervals. Showing that it's perfect is not difficult. The resulting set is an intersection of closed intervals, so is closed. Any point in the set is a limit point of endpoints of intervals (obviously I have more details in my written solution, but that's the idea.) But I don't see how the measure is $1-\delta$... At stage $k$, we remove $2^{k-1}$ intervals of length $\delta 3^{-k}$, so the measure of the resulting set is $$1-\sum\limits_{k=0}^{\infty}{2^{k}\cdot\dfrac{\delta}{3^{k+1}}} = 1-\dfrac{\delta}{3}\cdot\sum\limits_{k=0}^{\infty}{\dfrac{2^k}{3^k}} = 1-\dfrac{2\delta}{3} .$$ Thoughts? (2.) Construct a Cantor-type set subset of $[0,1]$ by removing from each interval remaining at the $k$-th stage a subinterval of relative length $\theta_k$, $0<\theta_k<1$. Show that the remainder has measure zero if and only if $\sum{\theta_k}=\infty$. (Use the fact that for $a_k>0$, $\prod\limits_{k=1}^{\infty}{a_k}$ converges, in the sense that $\lim\limits_{N\to\infty}{\prod\limits_{k=1}^N{a_k}}$ exists and is not zero, if only if $\sum\limits_{k=1}^{\infty}{\log{a_k}}$ converges. ) I don't really understand the construction. Suppose we have our $\theta_1$ and we remove an interval of that length. So then we choose $\theta_2$ so that $\theta_2 < \dfrac{1-\theta_1}{2}$, or something like that? Or... ? The phrasing is weird to me. Secondly, the hint does not help at all; it is complete opaque to me, so any insight you can offer would be great.",,"['real-analysis', 'measure-theory']"
19,Girsanov-type Theorem that alters the variance of a Wiener process,Girsanov-type Theorem that alters the variance of a Wiener process,,"Consider a general probability space $(\Omega, \mathcal{F}, \mathbb{S})$ , on which two or more other probability measures, $\mathbb{P}_1$ , $\mathbb{P}_2$ ,..., $\mathbb{P}_j$ ,..., $\mathbb{P}_n$ are defined that are absolutely continuous with respect to one another. Consider a normally distributed random variable $X\sim N(0, \sigma)$ with its density function denoted $f_{X}$ . Consider a probability measure $\mathbb{P_1}$ defined by the cumulative density function (CDF) of $X$ : \begin{equation} \label{eq1} \mathbb{P}_1(A):=\int_{-\infty}^{h=a}\frac{1}{\sigma \sqrt{ 2\pi}}e^{\frac{-(h)^2}{2\sigma^2}}dh \tag{1} \end{equation} (to be clear, $X$ is defined on Borel-measuruable sets on $\mathbb{R}$ , above $a \in \mathbb{R}$ and $A$ is defined as the event: $\{A \in \mathcal{F} : X \leq a\}$ ). Next consider the following function of $X$ : \begin{equation} \label{eq2} g(X):=\frac{1}{k}e^{\frac{(k^2-1)X^2}{2k^2\sigma^2}} \tag{2} \end{equation} Using the ""law of the unconscious statistician"", we have that: \begin{equation} \label{eq3} \mathbb{E}^{\mathbb{P_1}}\left[g(X)\right]=\int_{-\infty}^{\infty}g(h)f_{X}(h)dh=\int_{-\infty}^{\infty}\frac{1}{k\sigma\sqrt{ 2\pi}}e^{\frac{-(h)^2}{2\sigma^2 k^2}}dh \tag{3} \end{equation} Since in the last expression in \ref{eq3} we recognize a PDF of a normally distributed random variable with mean zero and variance $\sigma^2k^2$ , we have that $\mathbb{E}^{\mathbb{P_1}}\left[g(X)\right]=1$ . Furthermore, restricting $k>0$ results in $g(X)>0$ , and under this restriction, $g(X)$ is a valid Radon-Nikodym derivative. We can define a new measure $\mathbb{P}_2$ as follows (below $\mathbb{I}_{\{.\}}$ is an indicator function): \begin{equation} \label{eq4} \mathbb{P}_2(A):=\mathbb{E}^{\mathbb{P}_1}\left[g(X)\mathbb{I}_{\{A\}}\right] \tag{4} \end{equation} We can say that under the measure $\mathbb{P}_2$ : $X^{\mathbb{P}_2}\sim N(0, k^2\sigma^2)$ . Consider now a different probability space $(\Omega, \mathcal{F_t}, \mathbb{S})$ and assume that $\mathbb{S}$ is a probability measure induced by the standard Wiener process $W_t$ . Define $\mathbb{P}_1$ as: \begin{equation} \label{eq5} \mathbb{P_1}(A):=\mathbb{P_1}(W_t\leq a: a \in\mathbb{R})=\int_{-\infty}^{h=a}\frac{1}{\sqrt{ 2\pi t}}e^{\frac{-(h)^2}{2t}}dh=\int_{-\infty}^{h=a}f_{W_t}(h)dh \tag{5} \end{equation} Consider the following function of $W_t$ : \begin{equation} \label{eq6} g(W_t):=\frac{1}{k}\exp{\left(\frac{W_t^2\left(k^2-1\right)}{2tk^2}\right)} \tag{6} \end{equation} Above, $k>0$ is some constant. Repeating the same argument, we can conclude that $g(W_t)$ is a valid Radon-Nikodym derivative (i.e. integrates to 1 and is positive). We can write $\mathbb{P}_2(A):=\mathbb{E}^{\mathbb{P}_1}\left[g(W_t)\mathbb{I}_{\{A\}}\right]$ and conclude that: \begin{equation} \label{eq7} W(t)^{\mathbb{P}_2}\sim N(0,k^2t) \tag{7} \end{equation} Question : in the text-book "" Stochastic Calculus and Financial Application "" by J.M. Steele, in the first paragraph on page 221, the author states (without proof) that given two processes $\sigma_1 W_t$ and $\sigma_2 W_t$ , the measures $\mathbb{P}_{\sigma_1}$ and $\mathbb{P}_{\sigma_2}$ are singular whenever $\sigma_1 \neq \sigma_2$ . Setting $\sigma_1=1$ and $\sigma_2=k$ , I am unable to prove / explain why the construction above wouldn't produce two equivalent probability measures.","Consider a general probability space , on which two or more other probability measures, , ,..., ,..., are defined that are absolutely continuous with respect to one another. Consider a normally distributed random variable with its density function denoted . Consider a probability measure defined by the cumulative density function (CDF) of : (to be clear, is defined on Borel-measuruable sets on , above and is defined as the event: ). Next consider the following function of : Using the ""law of the unconscious statistician"", we have that: Since in the last expression in \ref{eq3} we recognize a PDF of a normally distributed random variable with mean zero and variance , we have that . Furthermore, restricting results in , and under this restriction, is a valid Radon-Nikodym derivative. We can define a new measure as follows (below is an indicator function): We can say that under the measure : . Consider now a different probability space and assume that is a probability measure induced by the standard Wiener process . Define as: Consider the following function of : Above, is some constant. Repeating the same argument, we can conclude that is a valid Radon-Nikodym derivative (i.e. integrates to 1 and is positive). We can write and conclude that: Question : in the text-book "" Stochastic Calculus and Financial Application "" by J.M. Steele, in the first paragraph on page 221, the author states (without proof) that given two processes and , the measures and are singular whenever . Setting and , I am unable to prove / explain why the construction above wouldn't produce two equivalent probability measures.","(\Omega, \mathcal{F}, \mathbb{S}) \mathbb{P}_1 \mathbb{P}_2 \mathbb{P}_j \mathbb{P}_n X\sim N(0, \sigma) f_{X} \mathbb{P_1} X \begin{equation}
\label{eq1}
\mathbb{P}_1(A):=\int_{-\infty}^{h=a}\frac{1}{\sigma \sqrt{ 2\pi}}e^{\frac{-(h)^2}{2\sigma^2}}dh
\tag{1}
\end{equation} X \mathbb{R} a \in \mathbb{R} A \{A \in \mathcal{F} : X \leq a\} X \begin{equation}
\label{eq2}
g(X):=\frac{1}{k}e^{\frac{(k^2-1)X^2}{2k^2\sigma^2}}
\tag{2}
\end{equation} \begin{equation}
\label{eq3}
\mathbb{E}^{\mathbb{P_1}}\left[g(X)\right]=\int_{-\infty}^{\infty}g(h)f_{X}(h)dh=\int_{-\infty}^{\infty}\frac{1}{k\sigma\sqrt{ 2\pi}}e^{\frac{-(h)^2}{2\sigma^2 k^2}}dh
\tag{3}
\end{equation} \sigma^2k^2 \mathbb{E}^{\mathbb{P_1}}\left[g(X)\right]=1 k>0 g(X)>0 g(X) \mathbb{P}_2 \mathbb{I}_{\{.\}} \begin{equation}
\label{eq4}
\mathbb{P}_2(A):=\mathbb{E}^{\mathbb{P}_1}\left[g(X)\mathbb{I}_{\{A\}}\right]
\tag{4}
\end{equation} \mathbb{P}_2 X^{\mathbb{P}_2}\sim N(0, k^2\sigma^2) (\Omega, \mathcal{F_t}, \mathbb{S}) \mathbb{S} W_t \mathbb{P}_1 \begin{equation}
\label{eq5}
\mathbb{P_1}(A):=\mathbb{P_1}(W_t\leq a: a \in\mathbb{R})=\int_{-\infty}^{h=a}\frac{1}{\sqrt{ 2\pi t}}e^{\frac{-(h)^2}{2t}}dh=\int_{-\infty}^{h=a}f_{W_t}(h)dh
\tag{5}
\end{equation} W_t \begin{equation}
\label{eq6}
g(W_t):=\frac{1}{k}\exp{\left(\frac{W_t^2\left(k^2-1\right)}{2tk^2}\right)}
\tag{6}
\end{equation} k>0 g(W_t) \mathbb{P}_2(A):=\mathbb{E}^{\mathbb{P}_1}\left[g(W_t)\mathbb{I}_{\{A\}}\right] \begin{equation}
\label{eq7}
W(t)^{\mathbb{P}_2}\sim N(0,k^2t)
\tag{7}
\end{equation} \sigma_1 W_t \sigma_2 W_t \mathbb{P}_{\sigma_1} \mathbb{P}_{\sigma_2} \sigma_1 \neq \sigma_2 \sigma_1=1 \sigma_2=k","['measure-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis', 'girsanov-theorem']"
20,Bounding $L^1$ norm of the difference between a function $f:\mathbb R^n\to\mathbb R$ of bounded variation and a piecewise constant approximation,Bounding  norm of the difference between a function  of bounded variation and a piecewise constant approximation,L^1 f:\mathbb R^n\to\mathbb R,"As a follow up to this question, which deals with univariate functions, I assume that we are given a function $f:\mathbb R^n\to\mathbb R$ which is of bounded variation on bounded sets, meaning, according to Wikipedia , that for $\Omega\subset\mathbb R^n$ open and bounded $$V(f,\Omega)=\sup\left\{\int_\Omega f(x)\mathrm{div}\phi(x)\ \mathrm dx:\phi\in C_c^1(\Omega,\mathbb R^n),\|\phi\|_{L^\infty(\Omega)}\leq1\right\}$$ is finite. I want to take some bounded set $A\subset\mathbb R^n$ ; I'm willing to assume that $A$ is an hyperrectangle, i.e. $A$ is of the form $A=\prod_{i=1}^n[a_i,b_i)$ . Then we partition $A$ into $d$ hyperrectangles $A_1^d,\ldots,A_d^d$ , and we denote this partition by $\mathcal P^d$ . We define its mesh by the largest Lebesgue measure (EDIT: it seems that we need to define the mesh as the largest diameter , see @dsh's comment and second update to their answer) among the elements from this partition. Then the piecewise constant function $f^d$ is obtained by averaging over the elements of the partition, i.e. with $|A_i^d|$ the Lebesgue measure of $A_i^d$ $$f^d|_{A_i^d}=\frac1{|A_i^d|}\int_{A_i^d}f(x)\ \mathrm dx.$$ Similarly to the univariate case, I was wondering whether we can prove that $$\|f^d-f\|_{L^1(A)}\leq V(f,A)\cdot \mathrm{mesh}(\mathcal P^d).$$ Since my multivariate calculus is not that strong, I'm having some difficulty proving this. I'm wondering whether this can be done similarly as in the univariate case, as done by Alex Ravsky in the linked question. Intuitively, the answer should definitely be yes, but I was wondering how to bound $\Delta_i:=\sup_{x\in A_i^d}f(x)-\inf_{x\in A_i^d}f(x)$ by the integrand involving the divergence operator. More specifically, ignoring the fact that we should deal with equivalence classes for the moment, some easy bounding gives \begin{align*} \|f^d-f\|_{L^1(A)}&=\int_A|f^d(x)-f(x)|\ \mathrm dx=\sum_{i=1}^d\int_{A_i}|f^d(x)-f(x)|\ \mathrm dx\leq\sum_{i=1}^d\int_{A_i}\Delta_i\ \mathrm dx\\ &\leq\mathrm{mesh}(\mathcal P^d)\sum_{i=1}^d\Delta_i, \end{align*} so that it suffices to prove that for any partition $\mathcal P^d$ of (the hyperrectangle) $A$ into $d$ subsets (hyperrectangles) $A_i$ it holds that $$\sum_{i=1}^d\Delta_i\leq V(f,A).$$ Any help is much appreciated.","As a follow up to this question, which deals with univariate functions, I assume that we are given a function which is of bounded variation on bounded sets, meaning, according to Wikipedia , that for open and bounded is finite. I want to take some bounded set ; I'm willing to assume that is an hyperrectangle, i.e. is of the form . Then we partition into hyperrectangles , and we denote this partition by . We define its mesh by the largest Lebesgue measure (EDIT: it seems that we need to define the mesh as the largest diameter , see @dsh's comment and second update to their answer) among the elements from this partition. Then the piecewise constant function is obtained by averaging over the elements of the partition, i.e. with the Lebesgue measure of Similarly to the univariate case, I was wondering whether we can prove that Since my multivariate calculus is not that strong, I'm having some difficulty proving this. I'm wondering whether this can be done similarly as in the univariate case, as done by Alex Ravsky in the linked question. Intuitively, the answer should definitely be yes, but I was wondering how to bound by the integrand involving the divergence operator. More specifically, ignoring the fact that we should deal with equivalence classes for the moment, some easy bounding gives so that it suffices to prove that for any partition of (the hyperrectangle) into subsets (hyperrectangles) it holds that Any help is much appreciated.","f:\mathbb R^n\to\mathbb R \Omega\subset\mathbb R^n V(f,\Omega)=\sup\left\{\int_\Omega f(x)\mathrm{div}\phi(x)\ \mathrm dx:\phi\in C_c^1(\Omega,\mathbb R^n),\|\phi\|_{L^\infty(\Omega)}\leq1\right\} A\subset\mathbb R^n A A A=\prod_{i=1}^n[a_i,b_i) A d A_1^d,\ldots,A_d^d \mathcal P^d f^d |A_i^d| A_i^d f^d|_{A_i^d}=\frac1{|A_i^d|}\int_{A_i^d}f(x)\ \mathrm dx. \|f^d-f\|_{L^1(A)}\leq V(f,A)\cdot \mathrm{mesh}(\mathcal P^d). \Delta_i:=\sup_{x\in A_i^d}f(x)-\inf_{x\in A_i^d}f(x) \begin{align*}
\|f^d-f\|_{L^1(A)}&=\int_A|f^d(x)-f(x)|\ \mathrm dx=\sum_{i=1}^d\int_{A_i}|f^d(x)-f(x)|\ \mathrm dx\leq\sum_{i=1}^d\int_{A_i}\Delta_i\ \mathrm dx\\
&\leq\mathrm{mesh}(\mathcal P^d)\sum_{i=1}^d\Delta_i,
\end{align*} \mathcal P^d A d A_i \sum_{i=1}^d\Delta_i\leq V(f,A).","['real-analysis', 'measure-theory', 'multivariable-calculus', 'geometric-measure-theory', 'bounded-variation']"
21,Convergence in $L^p(\lambda)$ of mean of backward shifted integrable functions,Convergence in  of mean of backward shifted integrable functions,L^p(\lambda),"Let $(\Omega, \mathcal{A}, \mu)$ be a $\sigma$ -finite measure space. I want to prove the following (Exercise 7.1.2 in Klenke's Probability book): Let $p \in (1, \infty), f \in \mathcal{L}^p(\lambda)$ , where $\lambda$ is the Lebesgue measure on $\mathbb{R}$ . Let $T: \mathbb{R} \to \mathbb{R}, x \to x + 1$ . Show that, \begin{align} \frac{1}{n}\sum_{k = 0}^{n - 1}f\circ T^k \to 0 \hspace{0.2cm} \text{as} \hspace{0.2cm} n \to \infty \hspace{0.2cm} \text{in} \hspace{0.2cm} L^p(\lambda). \end{align} I am lost on how to prove this. I think I am at least able to prove that the sequence is a Cauchy sequence and thus converges, but even there I am not sure. Here is my attempt: Let $S_n = \frac{1}{n}\sum_{k = 0}^{n - 1}f\circ T^k$ . Then \begin{align} \|S_n - S_{n - 1}\|_p &= \|\frac{1}{n} f \circ T^{n-1} - \frac{1}{n(n-1)}\sum_{k = 0}^{n -2}f \circ T^k \|_p \\ & \leq \frac{1}{n} \|f \circ T^{n - 1}\|_p + \frac{1}{n(n - 1)}\sum_{k = 0}^{n -2} \|f \circ T^k \|_p\\ &= \frac{2M}{n} \to 0, \end{align} where $M = \|f\circ T^k\|_p$ . Here I am obviously assuming $\|f\circ T^i\|_p = \|f\circ T^j\|_p$ for all $i, j \in \{0, \ldots, n- 1\}$ , which I think is true, but can only provide intuitive (as opposed to formal) justification (Since $f \in \mathcal{L}^p (\lambda)$ , then the integral of the function should not change by shifting it around horizontally. I guess the idea would be to invoke the translation invariance of the Lebesgue measure?). I have two questions then: (1) Is my proof that the sequence converges in $L^p(\lambda)$ correct? Is my above assumption correct? If yes, what would be the formal justification? (2) How would one prove that the limit is $0$ ? Thanks much in advance!","Let be a -finite measure space. I want to prove the following (Exercise 7.1.2 in Klenke's Probability book): Let , where is the Lebesgue measure on . Let . Show that, I am lost on how to prove this. I think I am at least able to prove that the sequence is a Cauchy sequence and thus converges, but even there I am not sure. Here is my attempt: Let . Then where . Here I am obviously assuming for all , which I think is true, but can only provide intuitive (as opposed to formal) justification (Since , then the integral of the function should not change by shifting it around horizontally. I guess the idea would be to invoke the translation invariance of the Lebesgue measure?). I have two questions then: (1) Is my proof that the sequence converges in correct? Is my above assumption correct? If yes, what would be the formal justification? (2) How would one prove that the limit is ? Thanks much in advance!","(\Omega, \mathcal{A}, \mu) \sigma p \in (1, \infty), f \in \mathcal{L}^p(\lambda) \lambda \mathbb{R} T: \mathbb{R} \to \mathbb{R}, x \to x + 1 \begin{align}
\frac{1}{n}\sum_{k = 0}^{n - 1}f\circ T^k \to 0 \hspace{0.2cm} \text{as} \hspace{0.2cm} n \to \infty \hspace{0.2cm} \text{in} \hspace{0.2cm} L^p(\lambda).
\end{align} S_n = \frac{1}{n}\sum_{k = 0}^{n - 1}f\circ T^k \begin{align}
\|S_n - S_{n - 1}\|_p &= \|\frac{1}{n} f \circ T^{n-1} - \frac{1}{n(n-1)}\sum_{k = 0}^{n -2}f \circ T^k \|_p \\
& \leq \frac{1}{n} \|f \circ T^{n - 1}\|_p + \frac{1}{n(n - 1)}\sum_{k = 0}^{n -2} \|f \circ T^k \|_p\\
&= \frac{2M}{n} \to 0,
\end{align} M = \|f\circ T^k\|_p \|f\circ T^i\|_p = \|f\circ T^j\|_p i, j \in \{0, \ldots, n- 1\} f \in \mathcal{L}^p (\lambda) L^p(\lambda) 0","['measure-theory', 'convergence-divergence', 'lebesgue-integral', 'lebesgue-measure']"
22,How to see Ky Fan metric satisfies the triangle inequality?,How to see Ky Fan metric satisfies the triangle inequality?,,"Let $X$ and $Y$ be random variables. The Ky Fan metric is defined as: $$d(X,Y):= \min \{\epsilon>0 :P(|X-Y|>\epsilon)\le\epsilon\} $$ I want to show it is indeed a metric, for which I need to show that it satisfies triangle inequality. Set $d(X,Y)=\epsilon_1, d(Y,Z)=\epsilon_2$ ,and $d(Z,X)=\epsilon_3$ . I approached this by trying to show that $ (\epsilon_1+\epsilon_2)  \in \{\epsilon>0 :P(|X-Z|>\epsilon)\le\epsilon\} $ . But to show that, I had to show $P(|X-Y|>\epsilon_1)+P(|Y-Z|>\epsilon_2) \ge P(|X-Z|>\epsilon_1+\epsilon_2)$ , which I could not. Can you help in showing this?","Let and be random variables. The Ky Fan metric is defined as: I want to show it is indeed a metric, for which I need to show that it satisfies triangle inequality. Set ,and . I approached this by trying to show that . But to show that, I had to show , which I could not. Can you help in showing this?","X Y d(X,Y):= \min \{\epsilon>0 :P(|X-Y|>\epsilon)\le\epsilon\}  d(X,Y)=\epsilon_1, d(Y,Z)=\epsilon_2 d(Z,X)=\epsilon_3  (\epsilon_1+\epsilon_2)  \in \{\epsilon>0 :P(|X-Z|>\epsilon)\le\epsilon\}  P(|X-Y|>\epsilon_1)+P(|Y-Z|>\epsilon_2) \ge P(|X-Z|>\epsilon_1+\epsilon_2)","['real-analysis', 'measure-theory', 'metric-spaces']"
23,Variation of exercise $1.1.1$ from Tao’s measure theory book,Variation of exercise  from Tao’s measure theory book,1.1.1,"Let $R$ and $S$ be $n-$ dimensional boxes. That is $R = I_1 \times I_2 \cdots \times I_n$ and $S = J_1 \times J_2 \cdots \times J_n$ .  Show that the difference $R \setminus S$ is a finite union of $n$ -dimensional boxes. This is a slight modification of from Tao’s measure theory book from exercise $1.1.1$ where instead of the elementary set we’re looking at the elements of it. I cannot find any properties for the difference of the products $\prod_k I_k \setminus \prod_k J_k$ . The only one I found was ( https://proofwiki.org/wiki/Set_Difference_of_Cartesian_Products ), which isn’t of much help. Is there a way to manipulate $\prod_k I_k \setminus \prod_k J_k$ somehow?","Let and be dimensional boxes. That is and .  Show that the difference is a finite union of -dimensional boxes. This is a slight modification of from Tao’s measure theory book from exercise where instead of the elementary set we’re looking at the elements of it. I cannot find any properties for the difference of the products . The only one I found was ( https://proofwiki.org/wiki/Set_Difference_of_Cartesian_Products ), which isn’t of much help. Is there a way to manipulate somehow?",R S n- R = I_1 \times I_2 \cdots \times I_n S = J_1 \times J_2 \cdots \times J_n R \setminus S n 1.1.1 \prod_k I_k \setminus \prod_k J_k \prod_k I_k \setminus \prod_k J_k,"['real-analysis', 'measure-theory']"
24,$L^p$ convergence and interchange of limit and integral,convergence and interchange of limit and integral,L^p,"The question goes as follows: ""Let $f_{n}$ be sequences in $L^{2}$ function, with domain $(a,b)$ and Lebesgue measure. Now, there is $f$ in $L^{2}(a,b)$ such that $\lim ||f_{n} - f||_{2}$ tends to $0$ as $n$ goes to infinity. If $a$ and $b$ are each finite and $a \leq t \leq  b$ , then show: $$\int_{a}^{t}f(x) dx = \lim_{n \to \infty} \int_{a}^{t}f_{n}(x)dx$$ My Thoughts: My first thought was that the switching of integral and limit would involve use of DCT. However, the $L^2$ convergence does not satisfy the condition for DCT (which requires convergence in a.e.). Therefore, I thought about "" $L^{2}$ implies $L^{1}$ convergence"" and reverse triangle inequality to get: $$||f_{n}||_{1} - ||f||_{1} \leq ||f_{n}-f||_{1}$$ and that $$\lim_{n \to \infty} \int_{a}^{t}|f_{n}|d\mu = \int_{a}^{t}|f(x)| d\mu$$ However, I think the way I approached is not what the question intended. Thank you in advance!","The question goes as follows: ""Let be sequences in function, with domain and Lebesgue measure. Now, there is in such that tends to as goes to infinity. If and are each finite and , then show: My Thoughts: My first thought was that the switching of integral and limit would involve use of DCT. However, the convergence does not satisfy the condition for DCT (which requires convergence in a.e.). Therefore, I thought about "" implies convergence"" and reverse triangle inequality to get: and that However, I think the way I approached is not what the question intended. Thank you in advance!","f_{n} L^{2} (a,b) f L^{2}(a,b) \lim ||f_{n} - f||_{2} 0 n a b a \leq t \leq  b \int_{a}^{t}f(x) dx = \lim_{n \to \infty} \int_{a}^{t}f_{n}(x)dx L^2 L^{2} L^{1} ||f_{n}||_{1} - ||f||_{1} \leq ||f_{n}-f||_{1} \lim_{n \to \infty} \int_{a}^{t}|f_{n}|d\mu = \int_{a}^{t}|f(x)| d\mu","['real-analysis', 'measure-theory']"
25,Why Not To Define the Lebesgue Integral Using the Upper Lebesgue Sum.,Why Not To Define the Lebesgue Integral Using the Upper Lebesgue Sum.,,"I am trying to understand why the Lebesgue integral is defined using the lower Lebesgue sum rather than the upper Lebesgue sum. I am trying to prove the following inter-related propositions: (a) Suppose $(X, \mathcal S, \mu)$ is a measure space with $\mu(X)<\infty$ . Suppose that $f\colon X\to[0, \infty)$ is a bounded $\mathcal S$ -measurable function. Prove that \begin{align*} \int f \; d\mu = \inf\left\{\sum_{j=1}^m \mu(A_j) \sup_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\} \end{align*} The author of my text calls the expression on the right hand side of the equation above the upper Lebesgue sum. My textbook describes the Lebesgue integral as: $\int f \; d\mu = \sup\left\{\sum_{j=1}^m \mu(A_j) \inf_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\}$ , so I know that I have to show that $$\sup\left\{\sum_{j=1}^m \mu(A_j) \inf_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\} = \inf\left\{\sum_{j=1}^m \mu(A_j) \sup_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\}$$ I'd really appreciate it if someone can show me how this can be done. (b) Show that the conclusion of part (a) can fail if the condition that $\mu(X)< \infty$ is deleted. I have no clue how to approach this one. Can someone give me some examples of sets whose Lebesgue measure is infinite? I'll try to complete the solution from there. Any help on one or both of these questions would be greatly appreciated!","I am trying to understand why the Lebesgue integral is defined using the lower Lebesgue sum rather than the upper Lebesgue sum. I am trying to prove the following inter-related propositions: (a) Suppose is a measure space with . Suppose that is a bounded -measurable function. Prove that The author of my text calls the expression on the right hand side of the equation above the upper Lebesgue sum. My textbook describes the Lebesgue integral as: , so I know that I have to show that I'd really appreciate it if someone can show me how this can be done. (b) Show that the conclusion of part (a) can fail if the condition that is deleted. I have no clue how to approach this one. Can someone give me some examples of sets whose Lebesgue measure is infinite? I'll try to complete the solution from there. Any help on one or both of these questions would be greatly appreciated!","(X, \mathcal S, \mu) \mu(X)<\infty f\colon X\to[0, \infty) \mathcal S \begin{align*}
\int f \; d\mu = \inf\left\{\sum_{j=1}^m \mu(A_j) \sup_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\}
\end{align*} \int f \; d\mu = \sup\left\{\sum_{j=1}^m \mu(A_j) \inf_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\} \sup\left\{\sum_{j=1}^m \mu(A_j) \inf_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\} = \inf\left\{\sum_{j=1}^m \mu(A_j) \sup_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\} \mu(X)< \infty","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
26,"If $E$ has positive measure, then prove that there exists $h \in \mathbb{R}$ such that $|(E+h) \cap E| > 0$.","If  has positive measure, then prove that there exists  such that .",E h \in \mathbb{R} |(E+h) \cap E| > 0,"If $E$ has positive measure, then prove that there exists $h \in \mathbb{R}$ such that $|(E+h) \cap E| > 0$ . I tried doing this by contradiction but cannot seem to find my way about the argument. Any hints or help would be appreciated. Thanks.","If has positive measure, then prove that there exists such that . I tried doing this by contradiction but cannot seem to find my way about the argument. Any hints or help would be appreciated. Thanks.",E h \in \mathbb{R} |(E+h) \cap E| > 0,"['real-analysis', 'measure-theory']"
27,Atoms in a measure space and Sierpinski theorem for non-atomic measures,Atoms in a measure space and Sierpinski theorem for non-atomic measures,,"I have two questions concerning atoms in a measure space. My first question is about two different definitions I've encountered and I'm not sure if they are equivalent. Definition 1: Given a measure space $(\Omega, \Sigma, \mu)$ we say that an element $A \in \Sigma$ is an atom of $\mu$ if it satisfies that $\mu(A) >0$ and for every $B \in \Sigma$ such that $B \subset A$ either $\mu(B)=0$ or $\mu(A \setminus B)=0$ . Definition 2: Given a measure space $(\Omega, \Sigma, \mu)$ we say that an element $A \in \Sigma$ is an atom of $\mu$ if it satisfies that $\mu(A) >0$ and for every $B \in \Sigma$ such that $B \subset A$ either $\mu(B)=0$ or $\mu(B)=\mu(A)$ . So I know that if $\mu(\Omega)$ is finite then both definitions are indeed equivalent but, are they still equivalent if the measure is not finite? Now, concerning atoms of a measure I'm trying to prove the following theorem, apparently due to Sierpinski: Theorem: If $(\Omega, \Sigma, \mu)$ is a measure space with no atoms, then for every $t \in [0, \mu(\Omega)]$ there exists an $A \in \Sigma$ such that $\mu(A)=t$ . Following Wikipedia's article on atoms , I'm trying to fully proof the sketch of the proof at the end of the page. So I want to prove there is a funciton $S:[0, \mu(\Omega)] \longrightarrow \Sigma$ satisfying: $S$ is monotone, that is, if $t \leq t'$ then $S(t) \subset S(t')$ $\mu(S(t))=t$ for every $t \in [0, \mu(\Omega)]$ because this would directly imply the theorem. To this end, we define $$\Gamma= \left\{  S:D \longrightarrow \Sigma: D \subset [0, \mu(\Omega)], S \textrm{ is monotone}, \mu(S(t))=t, \forall t \in D \right\}$$ Then $\Gamma$ is not empty beacause we can define $S_0:\{0\} \longrightarrow \Sigma$ given by $S(0)=\emptyset$ and is clearly in $\Gamma$ , and we can make it a partially ordered set by establishing that $S_1 \leq S_2$ if, and only if, $\operatorname{graph}(S_1) \subset \operatorname{graph}(S_2)$ . Now, if $\Gamma_c$ is a chain in $\Gamma$ then we define $S_c: D_c \longrightarrow \Sigma$ where $$D_c=\bigcup_{S \in \Gamma_c} \operatorname{dom}(S)$$ and given $t \in D_c$ , we choose any $S \in \Gamma_c$ such that $t \in \operatorname{dom}(S)$ , and define $S_c(t)=S(t)$ . First, $S_c$ is well defined because if we have that given $t \in D_c$ , there are $S_1, S_2 \in \Gamma_c$ such that $t \in \operatorname{dom}(S_1) \cap \operatorname{dom}(S_2)$ , then as $\Gamma_c$ is a chain, we can assume wlog that $S_1 \leq S_2$ and then, $(t,S_1(t)) \in \operatorname{graph}(S_2)$ so $S_2(t)=S_1(t)$ as we wanted to show. Now, we will prove that $S_c \in \Gamma$ . First, observe that given $t_1, t_2 \in D_c$ there exists $S_1, S_2 \in \Gamma_c$ such that $t_i \in \operatorname{dom}(S_i)$ , so as $\Gamma_c$ is a chain, we may assume $S_1 \leq S_2$ and so $\operatorname{dom}(S_1) \subset \operatorname{dom}(S_2)$ , getting that $t_1, t_2 \in \operatorname{dom}(S_2)$ . So, if $t_1 \leq t_2$ as $S_2 \in \Gamma$ we will have that $$S_c(t_1)=S_2(t_1) \subset S_2(t_2) = S_c (t_2$$ so $S_c$ is monotone. On the other hand, it is clear that given $t \in D_c$ if it is $S \in \Gamma_c$ such that $t \in \operatorname{dom}(S)$ , then $$\mu(S_c(t))=\mu(S(t))=t$$ So we have proven that $S_c \in \Gamma$ and it is clear by its construction that it is an upper bound of $\Gamma_c$ . By Zorn's lemma, there exits then some $S: D \longrightarrow \Sigma$ maximal in $\Gamma$ , and the claim is that this function is the one we are looking for, and it suffices to prove that $D=[0, \mu(\Omega)]$ . This last part is the one I cannot prove, and if everything I've done is correct I suppose here is where you should use that $\mu$ is non-atomic. If tried to prove that $D$ is closed and open in $[0, \mu(\Omega)]$ , and as it is conected, we'll have that $D=[0, \mu(\Omega)]$ as we want. First, I've shown by using the maximality of $S$ that $\{0, \mu(\Omega)\} \subset D$ , for example if we suppose $0 \not \in D$ (the other case is analogue), then defining $\bar S: D \cup \{0\} \longrightarrow \Sigma$ as $\bar S(t)=S(t)$ if $t \in D$ and $\bar S(0)=\emptyset$ , it is clear that $\bar S \in \Gamma$ and $S < \bar S$ contradiction with its maximality. Now, to show it is closed, I've taken a sequence $\{t_n\} \subset D$ converging to some $t_0 \in [0, \mu(\Omega)]$ and I've supposed that $t \not \in D$ . Then, we have that $t_0 \in (0, \mu(\Omega))$ so in particular is finite, and we know then there must exists a monotone subsequence of $\{t_n\}$ converging to $t_0$ , so we can suppose that $\{t_n\}$ is monotone. If it is increasing, defining $A_n=S(t_n)$ and $\bar S: D \cup \{t_0\} \longrightarrow \Sigma$ as $\bar S(t)= S(t)$ if $t \in D$ and $\bar S(t_0)= \cup A_n$ we have: If $t <t_0$ then there exists some natural number $n$ such that $t \leq t_n$ and so $$\bar S(t)=s(t) \subset S(t_n) = A_n \subset \bar S(t_0)$$ If $t_0 < t$ then $t_n < t$ for every $n \geq 1$ so $$A_n=S(t_n) \subset S(t), \forall n \geq 1$$ and then $$\bar S(t_0) \subset S(t)$$ Since $\{t_n\}$ is increasing, by the monotonity of $S$ , $\{S(t_n)\}$ is also increasing and we then have $$\mu\left(\bar S(t_0)\right)=\mu\left( \bigcup_{n=1}^\infty S(t_n) \right)=\lim_{n \rightarrow \infty} \mu\left( S(t_n)\right) = \lim_{n \rightarrow \infty} t_n = t_0$$ So, this three facts imply that $\bar S \in \Gamma$ but $S < \bar S$ so we have a contradiction with the maximality. Now, if $\{t_n\}$ is decreasing, we do the same thing but taking $\bar S(t_0)=\cap A_n$ and, as $t$ is finite, we can assume that $\mu(A_1)=\mu(S(t_1))=t_1$ is finite, so we can argue as before arriving at the same contradiction. If everything I've write here is correct, then to show $D$ is open I must use the fact that $\mu$ is non-atomic because I haven't used it yet, so my doubt concerging this part are: If the definitions I gave at the beggining are not equivalent, can this last part be shown with both definitions? In case it is two difficult to show $D$ is open, is there a simple proof that $D=[0,\mu(\Omega)]$ ? And, in that case, can it be shown with both definitions of atoms if they are not equivalent?","I have two questions concerning atoms in a measure space. My first question is about two different definitions I've encountered and I'm not sure if they are equivalent. Definition 1: Given a measure space we say that an element is an atom of if it satisfies that and for every such that either or . Definition 2: Given a measure space we say that an element is an atom of if it satisfies that and for every such that either or . So I know that if is finite then both definitions are indeed equivalent but, are they still equivalent if the measure is not finite? Now, concerning atoms of a measure I'm trying to prove the following theorem, apparently due to Sierpinski: Theorem: If is a measure space with no atoms, then for every there exists an such that . Following Wikipedia's article on atoms , I'm trying to fully proof the sketch of the proof at the end of the page. So I want to prove there is a funciton satisfying: is monotone, that is, if then for every because this would directly imply the theorem. To this end, we define Then is not empty beacause we can define given by and is clearly in , and we can make it a partially ordered set by establishing that if, and only if, . Now, if is a chain in then we define where and given , we choose any such that , and define . First, is well defined because if we have that given , there are such that , then as is a chain, we can assume wlog that and then, so as we wanted to show. Now, we will prove that . First, observe that given there exists such that , so as is a chain, we may assume and so , getting that . So, if as we will have that so is monotone. On the other hand, it is clear that given if it is such that , then So we have proven that and it is clear by its construction that it is an upper bound of . By Zorn's lemma, there exits then some maximal in , and the claim is that this function is the one we are looking for, and it suffices to prove that . This last part is the one I cannot prove, and if everything I've done is correct I suppose here is where you should use that is non-atomic. If tried to prove that is closed and open in , and as it is conected, we'll have that as we want. First, I've shown by using the maximality of that , for example if we suppose (the other case is analogue), then defining as if and , it is clear that and contradiction with its maximality. Now, to show it is closed, I've taken a sequence converging to some and I've supposed that . Then, we have that so in particular is finite, and we know then there must exists a monotone subsequence of converging to , so we can suppose that is monotone. If it is increasing, defining and as if and we have: If then there exists some natural number such that and so If then for every so and then Since is increasing, by the monotonity of , is also increasing and we then have So, this three facts imply that but so we have a contradiction with the maximality. Now, if is decreasing, we do the same thing but taking and, as is finite, we can assume that is finite, so we can argue as before arriving at the same contradiction. If everything I've write here is correct, then to show is open I must use the fact that is non-atomic because I haven't used it yet, so my doubt concerging this part are: If the definitions I gave at the beggining are not equivalent, can this last part be shown with both definitions? In case it is two difficult to show is open, is there a simple proof that ? And, in that case, can it be shown with both definitions of atoms if they are not equivalent?","(\Omega, \Sigma, \mu) A \in \Sigma \mu \mu(A) >0 B \in \Sigma B \subset A \mu(B)=0 \mu(A \setminus B)=0 (\Omega, \Sigma, \mu) A \in \Sigma \mu \mu(A) >0 B \in \Sigma B \subset A \mu(B)=0 \mu(B)=\mu(A) \mu(\Omega) (\Omega, \Sigma, \mu) t \in [0, \mu(\Omega)] A \in \Sigma \mu(A)=t S:[0, \mu(\Omega)] \longrightarrow \Sigma S t \leq t' S(t) \subset S(t') \mu(S(t))=t t \in [0, \mu(\Omega)] \Gamma= \left\{  S:D \longrightarrow \Sigma: D \subset [0, \mu(\Omega)], S \textrm{ is monotone}, \mu(S(t))=t, \forall t \in D \right\} \Gamma S_0:\{0\} \longrightarrow \Sigma S(0)=\emptyset \Gamma S_1 \leq S_2 \operatorname{graph}(S_1) \subset \operatorname{graph}(S_2) \Gamma_c \Gamma S_c: D_c \longrightarrow \Sigma D_c=\bigcup_{S \in \Gamma_c} \operatorname{dom}(S) t \in D_c S \in \Gamma_c t \in \operatorname{dom}(S) S_c(t)=S(t) S_c t \in D_c S_1, S_2 \in \Gamma_c t \in \operatorname{dom}(S_1) \cap \operatorname{dom}(S_2) \Gamma_c S_1 \leq S_2 (t,S_1(t)) \in \operatorname{graph}(S_2) S_2(t)=S_1(t) S_c \in \Gamma t_1, t_2 \in D_c S_1, S_2 \in \Gamma_c t_i \in \operatorname{dom}(S_i) \Gamma_c S_1 \leq S_2 \operatorname{dom}(S_1) \subset \operatorname{dom}(S_2) t_1, t_2 \in \operatorname{dom}(S_2) t_1 \leq t_2 S_2 \in \Gamma S_c(t_1)=S_2(t_1) \subset S_2(t_2) = S_c (t_2 S_c t \in D_c S \in \Gamma_c t \in \operatorname{dom}(S) \mu(S_c(t))=\mu(S(t))=t S_c \in \Gamma \Gamma_c S: D \longrightarrow \Sigma \Gamma D=[0, \mu(\Omega)] \mu D [0, \mu(\Omega)] D=[0, \mu(\Omega)] S \{0, \mu(\Omega)\} \subset D 0 \not \in D \bar S: D \cup \{0\} \longrightarrow \Sigma \bar S(t)=S(t) t \in D \bar S(0)=\emptyset \bar S \in \Gamma S < \bar S \{t_n\} \subset D t_0 \in [0, \mu(\Omega)] t \not \in D t_0 \in (0, \mu(\Omega)) \{t_n\} t_0 \{t_n\} A_n=S(t_n) \bar S: D \cup \{t_0\} \longrightarrow \Sigma \bar S(t)= S(t) t \in D \bar S(t_0)= \cup A_n t <t_0 n t \leq t_n \bar S(t)=s(t) \subset S(t_n) = A_n \subset \bar S(t_0) t_0 < t t_n < t n \geq 1 A_n=S(t_n) \subset S(t), \forall n \geq 1 \bar S(t_0) \subset S(t) \{t_n\} S \{S(t_n)\} \mu\left(\bar S(t_0)\right)=\mu\left( \bigcup_{n=1}^\infty S(t_n) \right)=\lim_{n \rightarrow \infty} \mu\left( S(t_n)\right) = \lim_{n \rightarrow \infty} t_n = t_0 \bar S \in \Gamma S < \bar S \{t_n\} \bar S(t_0)=\cap A_n t \mu(A_1)=\mu(S(t_1))=t_1 D \mu D D=[0,\mu(\Omega)]",['measure-theory']
28,Show that $f\in \mathcal{L}^p$ and $||f||_p \leqslant M.$,Show that  and,f\in \mathcal{L}^p ||f||_p \leqslant M.,"Let $(X, \mathcal{B}, \mu)$ be a measured space, $1<p<\infty$ , and $q$ the conjugate exponent of $p$ : $\left(\dfrac{1}{p}+\dfrac{1}{q}=1\right)$ . Show that $f \in \mathcal{L}^p \implies$ $\displaystyle{||f||_p=\sup\left\{ \left|\int_X f(x)g(x)d\mu(x) \right| ; ||g||_q \leqslant1\right\}}$ . We assume here that the measure $\mu$ is $\sigma$ -finite. Let $f : X\to \mathbb{C}$ a mesurable function. we assume that there exists $M\geqslant0$ such that $\displaystyle{\left|\int_X f(x)g(x)d\mu(x) \right| \leqslant M}$ for all $g \in \mathcal{L}^p$ with $||g||_q\leqslant 1$ . Show that $f\in \mathcal{L}^p$ and $||f||_p \leqslant M.$ My attempt: on the one hand \begin{align*} \left|\int_X f(x)g(x)d\mu(x) \right| & \leqslant \int_X|f(x)g(x)|d\mu(x)  \\ &  \leqslant  \left(\int_X|f(x)|^pd\mu(x) \right)^{\frac{1}{p}} \left(\int_X|g(x)|^q d\mu(x) \right)^{\frac{1}{q}}\\ & =||f||_p||g||_q  \\& \leqslant ||f||_p \end{align*} on the other hand Let $g_0(x)= \dfrac{|f(x)|^p}{|f(x)|}$ if $f(x)\not=0$ , $g_0(x)=0$ if $f(x)=0$ . so $g_0(x)f(x)=|f(x)|^p$ , for all $x\in X$ , then $|g_0|^q= |f|^{(p-1)q}=|f|^p$ , so $g_0 \in \mathcal{L}^q$ , since $f\in \mathcal{L}^p$ . let's pose now $g=\dfrac{g_0}{||g_0||_q}$ , we notice that $||g||^q=1$ , and $$\int_Xf(x)g(x)d\mu(x) =\int_X f(x)\dfrac{g_0(x)}{||g_0||_q^q}d\mu(x)=\int_X\dfrac{|f(x)|^p}{||g_0||_q^q}= \dfrac{||f||_p^p}{||f||_p^{\frac{p}{q}}} = ||f||_p.$$ 2. I got stuck here ! Any help is highly appreciated.","Let be a measured space, , and the conjugate exponent of : . Show that . We assume here that the measure is -finite. Let a mesurable function. we assume that there exists such that for all with . Show that and My attempt: on the one hand on the other hand Let if , if . so , for all , then , so , since . let's pose now , we notice that , and 2. I got stuck here ! Any help is highly appreciated.","(X, \mathcal{B}, \mu) 1<p<\infty q p \left(\dfrac{1}{p}+\dfrac{1}{q}=1\right) f \in \mathcal{L}^p \implies \displaystyle{||f||_p=\sup\left\{ \left|\int_X f(x)g(x)d\mu(x) \right| ; ||g||_q \leqslant1\right\}} \mu \sigma f : X\to \mathbb{C} M\geqslant0 \displaystyle{\left|\int_X f(x)g(x)d\mu(x) \right| \leqslant M} g \in \mathcal{L}^p ||g||_q\leqslant 1 f\in \mathcal{L}^p ||f||_p \leqslant M. \begin{align*}
\left|\int_X f(x)g(x)d\mu(x) \right| & \leqslant \int_X|f(x)g(x)|d\mu(x) 
\\ & 
\leqslant  \left(\int_X|f(x)|^pd\mu(x) \right)^{\frac{1}{p}} \left(\int_X|g(x)|^q d\mu(x) \right)^{\frac{1}{q}}\\ & =||f||_p||g||_q  \\& \leqslant ||f||_p
\end{align*} g_0(x)= \dfrac{|f(x)|^p}{|f(x)|} f(x)\not=0 g_0(x)=0 f(x)=0 g_0(x)f(x)=|f(x)|^p x\in X |g_0|^q= |f|^{(p-1)q}=|f|^p g_0 \in \mathcal{L}^q f\in \mathcal{L}^p g=\dfrac{g_0}{||g_0||_q} ||g||^q=1 \int_Xf(x)g(x)d\mu(x) =\int_X f(x)\dfrac{g_0(x)}{||g_0||_q^q}d\mu(x)=\int_X\dfrac{|f(x)|^p}{||g_0||_q^q}= \dfrac{||f||_p^p}{||f||_p^{\frac{p}{q}}} = ||f||_p.","['measure-theory', 'lebesgue-integral']"
29,Does $\lim\int f_n=\int f$ imply $\lim\int|f_n|=\int|f|$?,Does  imply ?,\lim\int f_n=\int f \lim\int|f_n|=\int|f|,"Suppose that $\{f_n\}$ is a sequence complex measurable functions on a measurable space $(X,\Omega,\mu)$ . Let $f$ be the pointwise limit of $f_n$ . Does (1) implies (2)? where $$\lim_{n\to\infty}\int_Xf_n\,d\mu=\int_Xf\,d\mu.\tag{1}$$ $$\lim_{n\to\infty}\int_X|f_n|\,d\mu=\int_X|f|\,d\mu.\tag{2}$$ [EDIT] I don't know if the above statement is valid or not. So please give me a counterexample if it is false. My trial: (1) implies $$\lim_{n\to\infty}\int_X(f_n-f)\,d\mu=0.\tag{3}$$ $$\lim_{n\to\infty}\int_X|f_n-f|\,d\mu=0.\tag{4}$$ $$\lim_{n\to\infty}\int_X\Big||f_n|-|f|\Big|\,d\mu=0.\tag{5}$$ $$\lim_{n\to\infty}\int_X|f_n|-|f|\,d\mu=0.\tag{6}$$ So (2) follows. I'm not certain whether (3) implies (4). That is to say that (7) implies (8) where $g_n\to0$ and $$\lim_{n\to\infty}\int_Xg_n\,d\mu=0.\tag{7}$$ $$\lim_{n\to\infty}\int_X|g_n|\,d\mu=0.\tag{8}$$ Let $A_n=\{x\in X:|u_n(x)|\ge |v_n(x)|\}$ and $B_n=X\setminus A_n$ . Then $$\int_X|g_n|\,d\mu =\int_X\sqrt{(u_n(x))^2+(v_n(x))^2}\,d\mu \le\int_{A_n}\sqrt2|u_n|\,d\mu+\int_{B_n}\sqrt2|v_n|\,d\mu \le\sqrt2\int_X|u_n|\,d\mu+\sqrt2\int_X|v_n|\,d\mu$$ So, it is enough to consider ""(7) implies (8)"" for real $g_n$ .","Suppose that is a sequence complex measurable functions on a measurable space . Let be the pointwise limit of . Does (1) implies (2)? where [EDIT] I don't know if the above statement is valid or not. So please give me a counterexample if it is false. My trial: (1) implies So (2) follows. I'm not certain whether (3) implies (4). That is to say that (7) implies (8) where and Let and . Then So, it is enough to consider ""(7) implies (8)"" for real .","\{f_n\} (X,\Omega,\mu) f f_n \lim_{n\to\infty}\int_Xf_n\,d\mu=\int_Xf\,d\mu.\tag{1} \lim_{n\to\infty}\int_X|f_n|\,d\mu=\int_X|f|\,d\mu.\tag{2} \lim_{n\to\infty}\int_X(f_n-f)\,d\mu=0.\tag{3} \lim_{n\to\infty}\int_X|f_n-f|\,d\mu=0.\tag{4} \lim_{n\to\infty}\int_X\Big||f_n|-|f|\Big|\,d\mu=0.\tag{5} \lim_{n\to\infty}\int_X|f_n|-|f|\,d\mu=0.\tag{6} g_n\to0 \lim_{n\to\infty}\int_Xg_n\,d\mu=0.\tag{7} \lim_{n\to\infty}\int_X|g_n|\,d\mu=0.\tag{8} A_n=\{x\in X:|u_n(x)|\ge |v_n(x)|\} B_n=X\setminus A_n \int_X|g_n|\,d\mu
=\int_X\sqrt{(u_n(x))^2+(v_n(x))^2}\,d\mu
\le\int_{A_n}\sqrt2|u_n|\,d\mu+\int_{B_n}\sqrt2|v_n|\,d\mu
\le\sqrt2\int_X|u_n|\,d\mu+\sqrt2\int_X|v_n|\,d\mu g_n","['measure-theory', 'lebesgue-integral']"
30,Looking for a problem and answer book for measure theory,Looking for a problem and answer book for measure theory,,"Looking supplementary self-study texts for measure theory, including a good problem and solutions companion while studying Royden and Stein's Real Analysis .  Instructors solutions for either would work as well .","Looking supplementary self-study texts for measure theory, including a good problem and solutions companion while studying Royden and Stein's Real Analysis .  Instructors solutions for either would work as well .",,"['real-analysis', 'measure-theory', 'reference-request']"
31,Understanding proof when equality holds in Minkowski's inequality,Understanding proof when equality holds in Minkowski's inequality,,"I have a simple question about a fact that is constantly mentioned when we have $\|f+g\|_p = \|f\|_p + \|g\|_p$ in $L^p(\mu)$ space for $1<p<\infty$ (I hope someone find this useful). I read the arguments given here , and here and a proof almost related here . In all of these proofs it's mentioned that when the two Hölder's inequalities below that result on the steps of Minkowski's inequality: $$\int |f| \cdot |f+g|^{p-1} \, d\mu \leq \|f\|_p \cdot \|f+g\|_p^{p-1}$$ $$\int |g| \cdot |f+g|^{p-1} \, d\mu \leq \|g\|_p \cdot \|f+g\|_p^{p-1}$$ These two holds with equality thanks to the given hypothesis, and that's clear to me. However, then comes a fact that is not as clear to me as it should be (since I found no justification for this) that is: these two equalities implies that there is $\alpha,\beta \geq 0$ such that $|f|^p = \alpha |f+g|^p$ and $|g|^p = \beta |f+g|^p$ almost everywhere. Any hint or reference is appreciated. Thanks!","I have a simple question about a fact that is constantly mentioned when we have in space for (I hope someone find this useful). I read the arguments given here , and here and a proof almost related here . In all of these proofs it's mentioned that when the two Hölder's inequalities below that result on the steps of Minkowski's inequality: These two holds with equality thanks to the given hypothesis, and that's clear to me. However, then comes a fact that is not as clear to me as it should be (since I found no justification for this) that is: these two equalities implies that there is such that and almost everywhere. Any hint or reference is appreciated. Thanks!","\|f+g\|_p = \|f\|_p + \|g\|_p L^p(\mu) 1<p<\infty \int |f| \cdot |f+g|^{p-1} \, d\mu \leq \|f\|_p \cdot \|f+g\|_p^{p-1} \int |g| \cdot |f+g|^{p-1} \, d\mu \leq \|g\|_p \cdot \|f+g\|_p^{p-1} \alpha,\beta \geq 0 |f|^p = \alpha |f+g|^p |g|^p = \beta |f+g|^p","['measure-theory', 'inequality', 'lebesgue-integral', 'lp-spaces', 'holder-inequality']"
32,"Doubt about Exercise 5, Chapter 1, Shakarchi [RA]","Doubt about Exercise 5, Chapter 1, Shakarchi [RA]",,"So, I need to find an example of $E$ an open and bounded set, such that if $\mathcal{O}_n:=\{x \in E: d(x,E) < \frac {1}{n}\}$ Then $\lim_{n \to \infty} m(\mathcal{O}_n) \neq m(E)$ . Where $m$ is the Lebesgue measure. My problem is the following, if all the $\mathcal{O}_n$ are measurable sets (Lebesgue measurable), you can apply Corolary 3.3 from the book, in other words, if $\mathcal{O}_n$ are all measurable, then the equality holds. Because we are taking the limit of $m(\mathcal{O}_n)$ , we need infinite many $\mathcal{O}_n$ to be not measurable, the only example of a non-measurable set is a Vitali set. So, how can a Vitali be the $\mathcal{O}_n$ of a set? Any help would be appreciated.","So, I need to find an example of an open and bounded set, such that if Then . Where is the Lebesgue measure. My problem is the following, if all the are measurable sets (Lebesgue measurable), you can apply Corolary 3.3 from the book, in other words, if are all measurable, then the equality holds. Because we are taking the limit of , we need infinite many to be not measurable, the only example of a non-measurable set is a Vitali set. So, how can a Vitali be the of a set? Any help would be appreciated.","E \mathcal{O}_n:=\{x \in E: d(x,E) < \frac
{1}{n}\} \lim_{n \to \infty} m(\mathcal{O}_n) \neq m(E) m \mathcal{O}_n \mathcal{O}_n m(\mathcal{O}_n) \mathcal{O}_n \mathcal{O}_n","['real-analysis', 'measure-theory', 'lebesgue-measure']"
33,Is Schilling's Corollary 8.9 really a corollary?,Is Schilling's Corollary 8.9 really a corollary?,,"I am reading René Schilling's Measures, Integrals and Martingales and am confused as to why he considers Corollary 8.9 a corollary of Theorem 8.8, rather than a completely separate theorem (which it appears to be). Theorem 8.8: Let $X$ be a measurable space. Every $\mathcal{A}/\bar{\mathcal{B}}$ -measurable numerical function $u:  X \to\bar{\mathbb{R}}$ is the pointwise limit of simple functions: $u(x) = \lim_{j\to\infty} f_j(x), f_j\in\mathcal{E}(\mathcal{A})$ and $|f_j|\leqslant|u|$ . If $u\geqslant 0$ , all $f_j$ can be chosen to be positive and increasing towards $u$ so that $u = \sup_{j\in\mathbb{N}} f_j$ . Corollary 8.9: Let $X$ be a measurable space. If $u_j: X \to \bar{\mathbb{R}}, j\in\mathbb{N},$ are measurable functions, then so are $$\sup_{j\in\mathbb{N}} u_j,\qquad \inf_{j\in\mathbb{N}} u_j,\qquad \limsup_{j\to\infty} u_j,\qquad \liminf_{j\to\infty} u_j,\qquad $$ and, whenever it exists, $\lim_{j\to\infty} u_j$ . From what I can tell, it seems that 8.9 doesn't follow from 8.8 at all. Schilling offers a proof of 8.9, which I'll insert below, but it doesn't reference anything relating to 8.8. Am I missing a key point here, or is calling this a ""corollary"" just a mistake? Also for completeness, here are Eqs. 8.10–8.12 referenced in the proof: $$\inf_{j\in\mathbb{N}} u_j(x) = -\sup_{j\in\mathbb{N}} u_j(-x), \tag{8.10}$$ $$\liminf_{j\to\infty} u_j(x) := \sup_{k\in\mathbb{N}} \Big( \inf_{j\geqslant k}u_j(x) \Big) = \lim_{k\to\infty} \Big( \inf_{j\geqslant k}u_j(x) \Big), \tag{8.11}$$ $$\limsup_{j\to\infty} u_j(x) := \inf_{k\in\mathbb{N}} \Big( \sup_{j\geqslant k}u_j(x) \Big) = \lim_{k\to\infty} \Big( \sup_{j\geqslant k}u_j(x) \Big), \tag{8.12}$$","I am reading René Schilling's Measures, Integrals and Martingales and am confused as to why he considers Corollary 8.9 a corollary of Theorem 8.8, rather than a completely separate theorem (which it appears to be). Theorem 8.8: Let be a measurable space. Every -measurable numerical function is the pointwise limit of simple functions: and . If , all can be chosen to be positive and increasing towards so that . Corollary 8.9: Let be a measurable space. If are measurable functions, then so are and, whenever it exists, . From what I can tell, it seems that 8.9 doesn't follow from 8.8 at all. Schilling offers a proof of 8.9, which I'll insert below, but it doesn't reference anything relating to 8.8. Am I missing a key point here, or is calling this a ""corollary"" just a mistake? Also for completeness, here are Eqs. 8.10–8.12 referenced in the proof:","X \mathcal{A}/\bar{\mathcal{B}} u:  X \to\bar{\mathbb{R}} u(x) = \lim_{j\to\infty} f_j(x), f_j\in\mathcal{E}(\mathcal{A}) |f_j|\leqslant|u| u\geqslant 0 f_j u u = \sup_{j\in\mathbb{N}} f_j X u_j: X \to \bar{\mathbb{R}}, j\in\mathbb{N}, \sup_{j\in\mathbb{N}} u_j,\qquad \inf_{j\in\mathbb{N}} u_j,\qquad \limsup_{j\to\infty} u_j,\qquad \liminf_{j\to\infty} u_j,\qquad  \lim_{j\to\infty} u_j \inf_{j\in\mathbb{N}} u_j(x) = -\sup_{j\in\mathbb{N}} u_j(-x), \tag{8.10} \liminf_{j\to\infty} u_j(x) := \sup_{k\in\mathbb{N}} \Big( \inf_{j\geqslant k}u_j(x) \Big) = \lim_{k\to\infty} \Big( \inf_{j\geqslant k}u_j(x) \Big), \tag{8.11} \limsup_{j\to\infty} u_j(x) := \inf_{k\in\mathbb{N}} \Big( \sup_{j\geqslant k}u_j(x) \Big) = \lim_{k\to\infty} \Big( \sup_{j\geqslant k}u_j(x) \Big), \tag{8.12}","['measure-theory', 'proof-verification']"
34,Is a set of measure zero in $\mathbb{R}$ totally disconnected?,Is a set of measure zero in  totally disconnected?,\mathbb{R},"Let $M \subset \mathbb{R}$ be a nonempty set of Lebesgue measure zero. Does it follow that $M$ is totally disconnected in the sense that for any $x<y$ , with $x,y\in M,$ there exists $z\notin M$ such that $x<z<y$ ? I think the answer to the questions is yes, since otherwise one could argue by contradiction and say that then there is an interval contained in $M$ and hence it cannot have measure zero. Is the reasoning above sound? Also just as side question, connectedness of nonempty sets does not imply positive measure in $\mathbb{R}^n$ , since a line in $\mathbb{R}^2$ is connected and has measure zero, right? Thank you for your time and appreciate any feedback.","Let be a nonempty set of Lebesgue measure zero. Does it follow that is totally disconnected in the sense that for any , with there exists such that ? I think the answer to the questions is yes, since otherwise one could argue by contradiction and say that then there is an interval contained in and hence it cannot have measure zero. Is the reasoning above sound? Also just as side question, connectedness of nonempty sets does not imply positive measure in , since a line in is connected and has measure zero, right? Thank you for your time and appreciate any feedback.","M \subset \mathbb{R} M x<y x,y\in M, z\notin M x<z<y M \mathbb{R}^n \mathbb{R}^2","['real-analysis', 'measure-theory', 'proof-verification', 'lebesgue-measure']"
35,Integration on manifolds?,Integration on manifolds?,,"To integrate we need a measure . A measure is a set function, $\mu$ , which takes sets as arguments and spits out elements of $\mathbb{R}^*$ (positive real number with infinity included as a point). We write $\int f d\mu$ for the integral of a function $f$ -approximated by step functions- to mean $\sum \alpha_i \mu(A_i)$ ; where $\alpha_i$ are the values the step function assumes, and $A_i=f^{-1}\{(\alpha_i)\}$ the set of all $x$ that get mapped to that fixed value. How do we reconcile this picture with the fact that we can integrate differential forms, $\int A_\mu dx^\mu$ . The coordinate function $x^\mu$ is obviously not a set function, hence not a measure. What is even the meaning of $\int A_\mu dx^\mu$ ? Do we break up $A_\mu$ into a sequence of step functions? How do we define the measure?","To integrate we need a measure . A measure is a set function, , which takes sets as arguments and spits out elements of (positive real number with infinity included as a point). We write for the integral of a function -approximated by step functions- to mean ; where are the values the step function assumes, and the set of all that get mapped to that fixed value. How do we reconcile this picture with the fact that we can integrate differential forms, . The coordinate function is obviously not a set function, hence not a measure. What is even the meaning of ? Do we break up into a sequence of step functions? How do we define the measure?",\mu \mathbb{R}^* \int f d\mu f \sum \alpha_i \mu(A_i) \alpha_i A_i=f^{-1}\{(\alpha_i)\} x \int A_\mu dx^\mu x^\mu \int A_\mu dx^\mu A_\mu,"['measure-theory', 'manifolds']"
36,A measure zero uncountable set for the Lebesgue-Stieltjes measure $\mu_F$.,A measure zero uncountable set for the Lebesgue-Stieltjes measure .,\mu_F,"Let $\mu_F$ be the Lebesgue-Stieltjes measure on $\Bbb R$ associated with the increasing function $F:\Bbb R\to \Bbb R$ . Construct an uncountable set of measure 0 for $\mu_F$ . When $F(x)=x$ and we get the Lebesgue measure on $\Bbb R$ and the Cantor set in the interval $[0,1]$ is an example. My guess is that the same argument can be repeated for $\mu_F$ , if there is an interval $[a,b]$ where $F$ is continuous (hence making sure that any singleton set has measure 0), and construct a ""Cantor set"" there. But an increasing function can have a dense set of discontinuities as shown in here . What can one do in this case?","Let be the Lebesgue-Stieltjes measure on associated with the increasing function . Construct an uncountable set of measure 0 for . When and we get the Lebesgue measure on and the Cantor set in the interval is an example. My guess is that the same argument can be repeated for , if there is an interval where is continuous (hence making sure that any singleton set has measure 0), and construct a ""Cantor set"" there. But an increasing function can have a dense set of discontinuities as shown in here . What can one do in this case?","\mu_F \Bbb R F:\Bbb R\to \Bbb R \mu_F F(x)=x \Bbb R [0,1] \mu_F [a,b] F",['measure-theory']
37,When does Brunn-Minkowski inequatily $(m(A+B))^{1/d} \geqslant (m(A))^{1/d} + (m(B))^{1/d}$ become equality?,When does Brunn-Minkowski inequatily  become equality?,(m(A+B))^{1/d} \geqslant (m(A))^{1/d} + (m(B))^{1/d},"Let $A$ and $B$ be two non-empty compact subsets of $\mathbb{R}^d$ , $m$ means Lebesgue measure. Brunn-Minkowski inequality gives $(m(A+B))^{1/d} \geqslant (m(A))^{1/d} + (m(B))^{1/d}$ . But how to prove the following? $(m(A+B))^{1/d} = (m(A))^{1/d} + (m(B))^{1/d} \implies$ $A$ and $B$ are convex and $\exists$ $\delta＞0$ , $h\in \mathbb{R}^d$ s.t. $A = \delta B + h$ (It's Problem $8$ of Chapter $1$ , Page $48$ in E.M.Stein's Real Analysis , though this problem doen't have much to do with real analysis.) Thanks in advance.","Let and be two non-empty compact subsets of , means Lebesgue measure. Brunn-Minkowski inequality gives . But how to prove the following? and are convex and , s.t. (It's Problem of Chapter , Page in E.M.Stein's Real Analysis , though this problem doen't have much to do with real analysis.) Thanks in advance.",A B \mathbb{R}^d m (m(A+B))^{1/d} \geqslant (m(A))^{1/d} + (m(B))^{1/d} (m(A+B))^{1/d} = (m(A))^{1/d} + (m(B))^{1/d} \implies A B \exists \delta＞0 h\in \mathbb{R}^d A = \delta B + h 8 1 48,"['real-analysis', 'measure-theory', 'convex-analysis', 'lebesgue-measure', 'geometric-measure-theory']"
38,Entropy of a Measure Preserving Transformation,Entropy of a Measure Preserving Transformation,,"I am reading the concept of entropy from Peter Walters' An Introduction to Ergodic Theory and I am having trouble understanding the notion of the entropy of a measure preserving transformation. Definitions: Let $(X, \mathcal{F}, \mu)$ be a probability space. For a partition $\xi=\{A_1 , \ldots, A_m\}$ of $X$ (where each $A_i$ is measurable) the entropy of $\xi$ is defined as: $$ H(\xi) = -\sum_{i=1}^m \mu(A_i)\log(\mu(A_i)) $$ If $T:X\to X$ is a measure preserving transformation, we write $T^{-1}\xi$ to denote the set $\set{T^{-1}(A_i):\ 1\leq i\leq m}$ . Thus $H(T^{-1}\xi)=H(\xi)$ . Now the entropy of a measure preserving transformation $T:X\to X$ with respect to $\xi$ is defined as (see Def. 4.9 in the aforementioned text) $$ h(T, \xi) = \lim_{n\to \infty} \frac{1}{n} H\left(\bigvee_{i=0}^{n-1} T^{-i}\xi\right), $$ where $\bigvee_{i=0}^{n-1} T^{-1}\xi$ is the coarsest common refinement of the partitions $T^{-i}\xi$ . The Problem: Just after giving the definition, the author writes This means that if we think of an application of $T$ as a passage of one day of time, then $\bigvee_{i=1}^{n-1}T^{-i}\xi$ represents the combined experiment of performing the original experiment, represented by $\xi$ , on $n$ consecutive days. Then $h(T, \xi)$ is the average information per day that one gets from performing the original experiment. I do not entirely follows this. If the application of $T$ is the passage of one day, that is, it takes us one day into the future, why is the expression $\bigvee_{i=1}^{n-1} T^{-i}\xi$ is the combined experiment (wait, what is intuitive meaning of 'combined experiment'?) for the next $n$ -days. We are taking backward images of $T$ in this expression, not the forward images. At any rate, I do not have any intuition for the last definition presented above. Can someone please try to give some insight. Thanks.","I am reading the concept of entropy from Peter Walters' An Introduction to Ergodic Theory and I am having trouble understanding the notion of the entropy of a measure preserving transformation. Definitions: Let be a probability space. For a partition of (where each is measurable) the entropy of is defined as: If is a measure preserving transformation, we write to denote the set . Thus . Now the entropy of a measure preserving transformation with respect to is defined as (see Def. 4.9 in the aforementioned text) where is the coarsest common refinement of the partitions . The Problem: Just after giving the definition, the author writes This means that if we think of an application of as a passage of one day of time, then represents the combined experiment of performing the original experiment, represented by , on consecutive days. Then is the average information per day that one gets from performing the original experiment. I do not entirely follows this. If the application of is the passage of one day, that is, it takes us one day into the future, why is the expression is the combined experiment (wait, what is intuitive meaning of 'combined experiment'?) for the next -days. We are taking backward images of in this expression, not the forward images. At any rate, I do not have any intuition for the last definition presented above. Can someone please try to give some insight. Thanks.","(X, \mathcal{F}, \mu) \xi=\{A_1 , \ldots, A_m\} X A_i \xi 
H(\xi) = -\sum_{i=1}^m \mu(A_i)\log(\mu(A_i))
 T:X\to X T^{-1}\xi \set{T^{-1}(A_i):\ 1\leq i\leq m} H(T^{-1}\xi)=H(\xi) T:X\to X \xi 
h(T, \xi) = \lim_{n\to \infty} \frac{1}{n} H\left(\bigvee_{i=0}^{n-1} T^{-i}\xi\right),
 \bigvee_{i=0}^{n-1} T^{-1}\xi T^{-i}\xi T \bigvee_{i=1}^{n-1}T^{-i}\xi \xi n h(T, \xi) T \bigvee_{i=1}^{n-1} T^{-i}\xi n T","['measure-theory', 'intuition', 'information-theory', 'ergodic-theory', 'entropy']"
39,Ratio limit of volumes,Ratio limit of volumes,,"Let $f:U\to \mathbb{R}^{m}$ be a $C^{1}$ function defined on an open subset $U\subset \mathbb{R}^{m}$. Prove that if $f'(a)$ is not an isomorphism then  $$\lim_{r\to 0} \frac{\mathrm{vol}~ f(\bar{B}_{r}(a))}{\mathrm{vol}~\bar{B}_{r}(a)}=0.$$ It seems to be necessary to use Sard theorem, but I was not able to do it. I appreciate any help. Edit: Since $f'(a)$ is a linear transformation which is not an isomorphism, $f'(\bar{B}_{r}(a))$ is contained in $\mathrm{Im}~ f'(a)$, which is an hipersurface of $\mathbb{R}^{m}$ such it dimension is smaller than $m$.   Therefore, $f'(\bar{B}_{r}(a))$ has empty interior and thus, $\mathrm{vol}~ f'(\bar{B}_{r}(a))= 0$. Does this imply the thesis?","Let $f:U\to \mathbb{R}^{m}$ be a $C^{1}$ function defined on an open subset $U\subset \mathbb{R}^{m}$. Prove that if $f'(a)$ is not an isomorphism then  $$\lim_{r\to 0} \frac{\mathrm{vol}~ f(\bar{B}_{r}(a))}{\mathrm{vol}~\bar{B}_{r}(a)}=0.$$ It seems to be necessary to use Sard theorem, but I was not able to do it. I appreciate any help. Edit: Since $f'(a)$ is a linear transformation which is not an isomorphism, $f'(\bar{B}_{r}(a))$ is contained in $\mathrm{Im}~ f'(a)$, which is an hipersurface of $\mathbb{R}^{m}$ such it dimension is smaller than $m$.   Therefore, $f'(\bar{B}_{r}(a))$ has empty interior and thus, $\mathrm{vol}~ f'(\bar{B}_{r}(a))= 0$. Does this imply the thesis?",,"['measure-theory', 'multivariable-calculus']"
40,Integration by parts on set $\{u>0\}$,Integration by parts on set,\{u>0\},"Consider a $C^\infty$ function satisfying $\Delta u=f$ in $\Bbb R^n$. Suppose that the super-level set $\{u>0\}$ is bounded, so $\partial\{u>0\}$ is compact. Can one integrate by parts on this? Namely, if $\partial\{u>0\}$ were smooth, then  $$\int_{\{u>0\}} |Du|^2=\int_{\partial\{u>0\}}u \frac{\partial u}{\partial n}-\int_{\{u>0\}}fu=-\int_{\{u>0\}}fu.$$ But $\partial\{u>0\}$ could be something strange. Is this kind of thing ok because $u=0$ on $\partial\{u>0\}$ anyway? I tried showing that $\{u>0\}$ is a set of finite perimeter, but no luck. The literature only seems to have results of this type for when $u$ is harmonic.","Consider a $C^\infty$ function satisfying $\Delta u=f$ in $\Bbb R^n$. Suppose that the super-level set $\{u>0\}$ is bounded, so $\partial\{u>0\}$ is compact. Can one integrate by parts on this? Namely, if $\partial\{u>0\}$ were smooth, then  $$\int_{\{u>0\}} |Du|^2=\int_{\partial\{u>0\}}u \frac{\partial u}{\partial n}-\int_{\{u>0\}}fu=-\int_{\{u>0\}}fu.$$ But $\partial\{u>0\}$ could be something strange. Is this kind of thing ok because $u=0$ on $\partial\{u>0\}$ anyway? I tried showing that $\{u>0\}$ is a set of finite perimeter, but no luck. The literature only seems to have results of this type for when $u$ is harmonic.",,"['real-analysis', 'measure-theory', 'partial-differential-equations', 'riemannian-geometry', 'geometric-measure-theory']"
41,Radon Nikodym derivative $\frac{\mathrm d(fλ)}{\mathrm d(gλ)}$,Radon Nikodym derivative,\frac{\mathrm d(fλ)}{\mathrm d(gλ)},"Here is the question: Consider the space $X = [0,1]$ with Lebesgue measure $\lambda$. Let $\mu = f\lambda$ and $\nu = g\lambda$ with functions $f$ and $g$ nonnegative, be finite measures. Find a condition characterising the absolute continuity $\nu \ll \mu$ and find the Radon Nikodym derivative $\dfrac{\mathrm{d}\nu}{\mathrm{d}\mu}$. On the first task, $\forall A \in \mathcal L [0,1]$, we have: $$[\mu(A) = 0 \implies \nu(A) = 0] \iff \\ \big[\int_Afd\lambda = 0 \implies \int_Ag d\lambda = 0 \big] \iff\\ \big[f \chi_A = 0\ (\lambda.a.e)\implies g \chi_A = 0\ (\lambda.a.e) \big].$$ So on whichever sets $f$ is $0$ almost everywhere, g is also $0$ almost everywhere (w.r.t. $\lambda$). Is this a good characterisation? Can you see a better one? On the second task: I can guess that we have $\dfrac{\mathrm{d}\nu}{\mathrm{d}\mu} = \dfrac gf$. We have established in lectures the chain rule$$ \frac{\mathrm{d}\nu}{\mathrm{d}\mu} = \frac{\mathrm{d}\nu}{\mathrm{d}\lambda} \frac{\mathrm{d}\lambda}{\mathrm{d}\mu} = g\frac{\mathrm{d}\lambda}{\mathrm{d}\mu}. $$ Now I need an argument that justifies $\dfrac{d\lambda}{d\mu} = f^{-1}\ (\lambda. a.e.)$ ""wherever $g \neq 0$"". Not sure how to argue in this way.","Here is the question: Consider the space $X = [0,1]$ with Lebesgue measure $\lambda$. Let $\mu = f\lambda$ and $\nu = g\lambda$ with functions $f$ and $g$ nonnegative, be finite measures. Find a condition characterising the absolute continuity $\nu \ll \mu$ and find the Radon Nikodym derivative $\dfrac{\mathrm{d}\nu}{\mathrm{d}\mu}$. On the first task, $\forall A \in \mathcal L [0,1]$, we have: $$[\mu(A) = 0 \implies \nu(A) = 0] \iff \\ \big[\int_Afd\lambda = 0 \implies \int_Ag d\lambda = 0 \big] \iff\\ \big[f \chi_A = 0\ (\lambda.a.e)\implies g \chi_A = 0\ (\lambda.a.e) \big].$$ So on whichever sets $f$ is $0$ almost everywhere, g is also $0$ almost everywhere (w.r.t. $\lambda$). Is this a good characterisation? Can you see a better one? On the second task: I can guess that we have $\dfrac{\mathrm{d}\nu}{\mathrm{d}\mu} = \dfrac gf$. We have established in lectures the chain rule$$ \frac{\mathrm{d}\nu}{\mathrm{d}\mu} = \frac{\mathrm{d}\nu}{\mathrm{d}\lambda} \frac{\mathrm{d}\lambda}{\mathrm{d}\mu} = g\frac{\mathrm{d}\lambda}{\mathrm{d}\mu}. $$ Now I need an argument that justifies $\dfrac{d\lambda}{d\mu} = f^{-1}\ (\lambda. a.e.)$ ""wherever $g \neq 0$"". Not sure how to argue in this way.",,"['measure-theory', 'radon-nikodym']"
42,"Existence of ""smallest"" non-empty measurable set","Existence of ""smallest"" non-empty measurable set",,"I am wondering if, for any $\sigma$-algebra $F$, there always exists some set $s\in F$ that satisfies the following properties, $s\ne \emptyset$. Except for $\emptyset$ and $s$ itself, there does not exist another set $t\in F$ that $t\subset s$. It is easy to see that this is true if the $\sigma$-algebra is induced by the topology induced by some metric because a set consisting of a single point satisfies this. But does it hold in general?","I am wondering if, for any $\sigma$-algebra $F$, there always exists some set $s\in F$ that satisfies the following properties, $s\ne \emptyset$. Except for $\emptyset$ and $s$ itself, there does not exist another set $t\in F$ that $t\subset s$. It is easy to see that this is true if the $\sigma$-algebra is induced by the topology induced by some metric because a set consisting of a single point satisfies this. But does it hold in general?",,['measure-theory']
43,Question about definition of signed measures [Stein and Shakarchi],Question about definition of signed measures [Stein and Shakarchi],,"In Stein and Shakarchi's Real Analysis , p. 285-6, they define a signed measure $\nu$ on a $\sigma$-algebra $\mathcal M$ of subsets of a set $X$ as a function that Is extended, in the sense that $\nu$ is a function $\mathcal M\to(-\infty,+\infty]$. If $\{E_j\}_{j=1}^\infty$ are disjoint subsets of $\mathcal M$, then $$\nu\bigg(\bigcup_{j=1}^\infty E_j\bigg) = \sum_{j=1}^\infty \nu(E_j).$$ Then they say, ""Note that for this to hold the sum $\sum \nu(E_j)$ must be independent of the rearrangement of terms, so that if $\nu(\bigcup_{j=1}^\infty E_j)$ is finite, it implies that the sum converges absolutely."" This definition seems off to me. I understand that for $\nu(\bigcup_{j=1}^\infty E_j)$ to be well-defined, the right-hand side must be independent of rearrangement, but it doesn't make sense to me to say ""if $\nu(\bigcup_{j=1}^\infty E_j)$ is finite, it implies that the sum converges absolutely"" because we could take $E_j$ to be disjoint sets of measure $(-1)^{j+1}/j$ for $j=1,2,3,\dots,$ and then we would have $$ \nu(E_1\cup E_2\cup E_3\dotsb) = 1-\frac{1}{2}+\frac{1}{3}-\dotsb = \ln(2), $$ so the sum is finite, but the series does not converge absolutely. So what is the correct way to state this definition? Or where am I misinterpreting the definition?","In Stein and Shakarchi's Real Analysis , p. 285-6, they define a signed measure $\nu$ on a $\sigma$-algebra $\mathcal M$ of subsets of a set $X$ as a function that Is extended, in the sense that $\nu$ is a function $\mathcal M\to(-\infty,+\infty]$. If $\{E_j\}_{j=1}^\infty$ are disjoint subsets of $\mathcal M$, then $$\nu\bigg(\bigcup_{j=1}^\infty E_j\bigg) = \sum_{j=1}^\infty \nu(E_j).$$ Then they say, ""Note that for this to hold the sum $\sum \nu(E_j)$ must be independent of the rearrangement of terms, so that if $\nu(\bigcup_{j=1}^\infty E_j)$ is finite, it implies that the sum converges absolutely."" This definition seems off to me. I understand that for $\nu(\bigcup_{j=1}^\infty E_j)$ to be well-defined, the right-hand side must be independent of rearrangement, but it doesn't make sense to me to say ""if $\nu(\bigcup_{j=1}^\infty E_j)$ is finite, it implies that the sum converges absolutely"" because we could take $E_j$ to be disjoint sets of measure $(-1)^{j+1}/j$ for $j=1,2,3,\dots,$ and then we would have $$ \nu(E_1\cup E_2\cup E_3\dotsb) = 1-\frac{1}{2}+\frac{1}{3}-\dotsb = \ln(2), $$ so the sum is finite, but the series does not converge absolutely. So what is the correct way to state this definition? Or where am I misinterpreting the definition?",,"['real-analysis', 'measure-theory']"
44,Show that $f:\mathbb{R}\to\mathbb{R}$ is Borel measurable if $f$ is either right continuous or left continuous.,Show that  is Borel measurable if  is either right continuous or left continuous.,f:\mathbb{R}\to\mathbb{R} f,"$f$ is Borel measurable if $\forall c\in\mathbb{R}$ the set $\{w\in\mathbb{R}:f(w) < c\}\in \mathcal{B}$ Suppose the function is left continuous. Then we have that $$\lim_{x \nearrow a} f(x) = f(a)$$ From this we get that the set $\{w\in\mathbb{R}:f(w) < c\}$ is in fact a union of intervals in $\mathbb{R}$ and therefore in $\mathcal{B}$. Same argument can be used for right continuous functions if you use the set $\{w\in\mathbb{R}:f(w) > c\}$ instead. Does this make sense? I'm not sure if it is rigorous enough, especially the part where I say it's a union of internals. Maybe I could construct that somehow?","$f$ is Borel measurable if $\forall c\in\mathbb{R}$ the set $\{w\in\mathbb{R}:f(w) < c\}\in \mathcal{B}$ Suppose the function is left continuous. Then we have that $$\lim_{x \nearrow a} f(x) = f(a)$$ From this we get that the set $\{w\in\mathbb{R}:f(w) < c\}$ is in fact a union of intervals in $\mathbb{R}$ and therefore in $\mathcal{B}$. Same argument can be used for right continuous functions if you use the set $\{w\in\mathbb{R}:f(w) > c\}$ instead. Does this make sense? I'm not sure if it is rigorous enough, especially the part where I say it's a union of internals. Maybe I could construct that somehow?",,"['measure-theory', 'proof-verification', 'borel-sets', 'borel-measures']"
45,Existence of Lebesgue measurable set with the same outer measure of the given set,Existence of Lebesgue measurable set with the same outer measure of the given set,,Let $A\subset \mathbb R^n$ be an arbitrary subset(not necessarily Lebesgue measurable). Denote the Lebesgue outer measure of $A$ by $m^{\ast}(A)$. Show that there exists a Lebesgue measurable set $B\subset \mathbb R^n$ such that $A\subset B$ and $m(B)=m^{\ast}(A)$. How should I deal with this problem? What I know is just the definition of outer measure $\mu^{\ast}(A)= \mathrm{inf}\{\sum_{i=1}^\infty l(U_i): A\subset\cup_i U_i\}$ where $U_i$'s are open sets in $\mathbb R^n$. I have no idea how to proceed. What should I do? Thank you for your help!,Let $A\subset \mathbb R^n$ be an arbitrary subset(not necessarily Lebesgue measurable). Denote the Lebesgue outer measure of $A$ by $m^{\ast}(A)$. Show that there exists a Lebesgue measurable set $B\subset \mathbb R^n$ such that $A\subset B$ and $m(B)=m^{\ast}(A)$. How should I deal with this problem? What I know is just the definition of outer measure $\mu^{\ast}(A)= \mathrm{inf}\{\sum_{i=1}^\infty l(U_i): A\subset\cup_i U_i\}$ where $U_i$'s are open sets in $\mathbb R^n$. I have no idea how to proceed. What should I do? Thank you for your help!,,"['measure-theory', 'lebesgue-measure', 'outer-measure']"
46,"If every open set of a metric space $(X, \rho)$ is $\mu^*$-measurable, then $\mu^*$ is a metric outer measure.","If every open set of a metric space  is -measurable, then  is a metric outer measure.","(X, \rho) \mu^* \mu^*","Let $(X, \rho)$ be a metric space and $\mu^*$ and outer measure on $X$. Then, if every open subset of $X$ is $\mu^*$-measurable, $\mu^*$ is a metric outer measure. I'm stuck with this problem. I'm supposed to prove that for every $A$, $B$ subsets of $X$ with $d(A, B) = \inf\{d(a,b) \mid a \in A, b \in B \} > 0$,  $$\mu^*(A \cup B) = \mu^*(A) + \mu^*(B)$$ and the hypothesis says that if $U \subset X$ is open, then  $$\mu^*(E) = \mu^*(E\cap U) + \mu^*(E\cap U^c)$$ for every set $E$ but I don't know how to do it. I thought of letting $E = A \cup B$ and then try to find some choice of $U$. With that choice of $E$, we have that  $$ \begin{align*} \mu^*(A\cup B) &= \mu^*((A\cup B) \cap U)+\mu^*((A\cup B)\cap A^c)\\ & =\mu^*((A\cap U) \cup (B \cap U))+ \mu^*((a \cap U^c)\cap (B\cap U^c)) \end{align*}$$  So at first sight, it looks like the open set $U$ we seek for has to be of one of the following two forms, $U \subset A$ and $B \subset U^c$ or the inverse, $U \subset B$ and $A \subset U^c$. The problem is that, even though the existence of an open set $U \subset A$ is always guaranteed, I don't know why it should also satisfy the property that $B \subset  U^c$ as well. My guess is that there is some property of metric spaces that I'm not aware off (or maybe I am really off the track here). Any help would be appreciated. Thank you!","Let $(X, \rho)$ be a metric space and $\mu^*$ and outer measure on $X$. Then, if every open subset of $X$ is $\mu^*$-measurable, $\mu^*$ is a metric outer measure. I'm stuck with this problem. I'm supposed to prove that for every $A$, $B$ subsets of $X$ with $d(A, B) = \inf\{d(a,b) \mid a \in A, b \in B \} > 0$,  $$\mu^*(A \cup B) = \mu^*(A) + \mu^*(B)$$ and the hypothesis says that if $U \subset X$ is open, then  $$\mu^*(E) = \mu^*(E\cap U) + \mu^*(E\cap U^c)$$ for every set $E$ but I don't know how to do it. I thought of letting $E = A \cup B$ and then try to find some choice of $U$. With that choice of $E$, we have that  $$ \begin{align*} \mu^*(A\cup B) &= \mu^*((A\cup B) \cap U)+\mu^*((A\cup B)\cap A^c)\\ & =\mu^*((A\cap U) \cup (B \cap U))+ \mu^*((a \cap U^c)\cap (B\cap U^c)) \end{align*}$$  So at first sight, it looks like the open set $U$ we seek for has to be of one of the following two forms, $U \subset A$ and $B \subset U^c$ or the inverse, $U \subset B$ and $A \subset U^c$. The problem is that, even though the existence of an open set $U \subset A$ is always guaranteed, I don't know why it should also satisfy the property that $B \subset  U^c$ as well. My guess is that there is some property of metric spaces that I'm not aware off (or maybe I am really off the track here). Any help would be appreciated. Thank you!",,"['measure-theory', 'metric-spaces', 'outer-measure']"
47,Showing that the Fatou's lemma inequality can be strict.,Showing that the Fatou's lemma inequality can be strict.,,"Let $X = \mathbb{R}$ and $M$ denote the $\sigma$-algebra of Lebesgue measurable subsets of $\mathbb{R}$, while $m$ denotes the outer Lebesgue measure restricted to $M$. Consider $f_n = \chi_{(1,2]}$ (characteristic function of $(1,2])$ when $n$ is even and $f_n = \chi _{[0,1]}$ when $n$ is odd. Since both $(1,2]$ and $[0,1]$ are Lebesgue measurable, we have that for each $n$, $f_n$ is a measurable function. Now when $n$ is odd, $\int_X f_n dm = m(1,2] = 1$ and $m[0,1] = 1$ for even $n$. Hence for each $n$ the integral is $1$. Hence,  $\lim \inf \int_X f_n dm = 1$. However clearly, $\lim\inf f_n = 0$. So $\int_X \lim \inf f_n dm = 0$. Hence the inequality in Fatou's lemma can be strict. Is this a correct argument, or have I made a mistake somewhere?","Let $X = \mathbb{R}$ and $M$ denote the $\sigma$-algebra of Lebesgue measurable subsets of $\mathbb{R}$, while $m$ denotes the outer Lebesgue measure restricted to $M$. Consider $f_n = \chi_{(1,2]}$ (characteristic function of $(1,2])$ when $n$ is even and $f_n = \chi _{[0,1]}$ when $n$ is odd. Since both $(1,2]$ and $[0,1]$ are Lebesgue measurable, we have that for each $n$, $f_n$ is a measurable function. Now when $n$ is odd, $\int_X f_n dm = m(1,2] = 1$ and $m[0,1] = 1$ for even $n$. Hence for each $n$ the integral is $1$. Hence,  $\lim \inf \int_X f_n dm = 1$. However clearly, $\lim\inf f_n = 0$. So $\int_X \lim \inf f_n dm = 0$. Hence the inequality in Fatou's lemma can be strict. Is this a correct argument, or have I made a mistake somewhere?",,"['real-analysis', 'measure-theory', 'proof-verification', 'limsup-and-liminf']"
48,Can the identity function be expressed as a countable-linear combination of indicator functions?,Can the identity function be expressed as a countable-linear combination of indicator functions?,,"Question. Can the function $$\mathrm{id} : \mathbb{R} \rightarrow \mathbb{R}, \qquad \mathrm{id}_\mathbb{R}(x) = x$$ be expressed as a countable-linear combination of indicator functions of subsets of $\mathbb{R}$ ? Remark. One idea for constructing such a thing is to try to find a function $a : \mathbb{Q} \rightarrow \mathbb{R}$ such that $$(\forall x \in \mathbb{R}) \qquad x = \sum_{q \in \mathbb{Q}}a_q[x<q],$$ where the square brackets connote the Iverson bracket . But it's not really clear how to choose the $a_q$ 's. Honestly, I think the answer is probably ""no."" Ideas, anyone? I'm also interested in the (simpler?) problem where $\mathbb{R}$ is replaced by $\mathbb{R}_{\geq 0}$ .","Question. Can the function be expressed as a countable-linear combination of indicator functions of subsets of ? Remark. One idea for constructing such a thing is to try to find a function such that where the square brackets connote the Iverson bracket . But it's not really clear how to choose the 's. Honestly, I think the answer is probably ""no."" Ideas, anyone? I'm also interested in the (simpler?) problem where is replaced by .","\mathrm{id} : \mathbb{R} \rightarrow \mathbb{R}, \qquad \mathrm{id}_\mathbb{R}(x) = x \mathbb{R} a : \mathbb{Q} \rightarrow \mathbb{R} (\forall x \in \mathbb{R}) \qquad x = \sum_{q \in \mathbb{Q}}a_q[x<q], a_q \mathbb{R} \mathbb{R}_{\geq 0}","['real-analysis', 'measure-theory']"
49,Equivalence of definitions for $L_\infty$ norm via essential range and essential supremum,Equivalence of definitions for  norm via essential range and essential supremum,L_\infty,"I have the following two norms for mesurable complex valued functions $f \colon X\to \mathbb{C}$: $$\|f \|_1 := \inf \big\{ c \geq 0 \colon \mu (\{ x \in X \colon |f(x)| > c \}) = 0 \big\}$$ and $$\|f\|_2 := \sup \big\{ |\lambda| \colon \lambda \in r_{\mathrm{ess}}(f)\big\},$$ where $$ r_{\mathrm{ess}}(f) := \big\{\lambda \in \mathbb{C} \colon \forall \varepsilon > 0: \mu(f^{-1}(B_\varepsilon(\lambda)) > 0 \big\},$$ where $B_\varepsilon(\lambda)$ denotes the open ball with radius $\varepsilon$ centered at $\lambda$. It is easy to show, that $\|f\|_2 \leq \|f\|_1$ but I have not been able to prove the converse. Any suggestions? I think the problem boils down to showing that $\mu\big(\;f^{-1}(\mathbb{C} \setminus r_{\mathrm{ess}}(f))\big) = 0$. EDIT One possible proof could be like this: We exhaust the set $S := \mathbb{C}  \setminus \overline{ B_{\|f\|_2}(0)}$ in two steps:  First for all $m \in \mathbb{N}$ by annuli $$ S_{m,n} := S_{\|f\|_2 + \frac{1}{m}, \|f\|_2 + n} := \bigg\{ \lambda \in \mathbb{C} \colon \|f\|_2 + \frac{1}{m} \leq |\lambda | \leq \|f\|_2 + n\bigg\} $$ with $\mu(f^{-1}(S_{m,n})) = 0$, i.e. for $$ S_m := \bigcup_{n \in \mathbb{N}} S_{m,n} $$ we get  $\mu(f^{-1}(S_{m}))  = 0$. Secondly, by considering $$ S = \bigcup_{m \in \mathbb{N}} S_{m} $$ we show the claim. Proof . Let $m,n$ be given.  Then, for all $\lambda \in S_{m,n}$ there exists $\varepsilon_\lambda > 0$ such that  $$\mu\bigg(\big\{f^{-1}\big(B_{\varepsilon_\lambda}(\lambda)\big)\big\}\bigg) = 0.$$ But $S_{m,n}$ is compact, i.e. we get $\lambda_1,\dots,\lambda_k$ such that $$ S_{m,n} \subseteq \bigcup_{i = 1,\dots,k} B_{\varepsilon_{\lambda_i}} (\lambda_i). $$ Hence (assuming completeness of $\mu$) we have that $f^{-1}(S_{m,n})$ is a set of measure zero, as well as the countable union of all $S_{m,n}$ for $n \in \mathbb{N}$. So, for all $m \in \mathbb{N}$ the sets $f^{-1}(S_m)$ are of measure zero and the fact that $S = \bigcup_{m \in \mathbb{N}}$ gives the claim: We have $$\mu (\{ x \in X \colon |f(x)| > \|f\|_2 \}) = 0$$ i.e. $\|f\|_2 \geq \|f\|_1$. $\square$ What do you think?","I have the following two norms for mesurable complex valued functions $f \colon X\to \mathbb{C}$: $$\|f \|_1 := \inf \big\{ c \geq 0 \colon \mu (\{ x \in X \colon |f(x)| > c \}) = 0 \big\}$$ and $$\|f\|_2 := \sup \big\{ |\lambda| \colon \lambda \in r_{\mathrm{ess}}(f)\big\},$$ where $$ r_{\mathrm{ess}}(f) := \big\{\lambda \in \mathbb{C} \colon \forall \varepsilon > 0: \mu(f^{-1}(B_\varepsilon(\lambda)) > 0 \big\},$$ where $B_\varepsilon(\lambda)$ denotes the open ball with radius $\varepsilon$ centered at $\lambda$. It is easy to show, that $\|f\|_2 \leq \|f\|_1$ but I have not been able to prove the converse. Any suggestions? I think the problem boils down to showing that $\mu\big(\;f^{-1}(\mathbb{C} \setminus r_{\mathrm{ess}}(f))\big) = 0$. EDIT One possible proof could be like this: We exhaust the set $S := \mathbb{C}  \setminus \overline{ B_{\|f\|_2}(0)}$ in two steps:  First for all $m \in \mathbb{N}$ by annuli $$ S_{m,n} := S_{\|f\|_2 + \frac{1}{m}, \|f\|_2 + n} := \bigg\{ \lambda \in \mathbb{C} \colon \|f\|_2 + \frac{1}{m} \leq |\lambda | \leq \|f\|_2 + n\bigg\} $$ with $\mu(f^{-1}(S_{m,n})) = 0$, i.e. for $$ S_m := \bigcup_{n \in \mathbb{N}} S_{m,n} $$ we get  $\mu(f^{-1}(S_{m}))  = 0$. Secondly, by considering $$ S = \bigcup_{m \in \mathbb{N}} S_{m} $$ we show the claim. Proof . Let $m,n$ be given.  Then, for all $\lambda \in S_{m,n}$ there exists $\varepsilon_\lambda > 0$ such that  $$\mu\bigg(\big\{f^{-1}\big(B_{\varepsilon_\lambda}(\lambda)\big)\big\}\bigg) = 0.$$ But $S_{m,n}$ is compact, i.e. we get $\lambda_1,\dots,\lambda_k$ such that $$ S_{m,n} \subseteq \bigcup_{i = 1,\dots,k} B_{\varepsilon_{\lambda_i}} (\lambda_i). $$ Hence (assuming completeness of $\mu$) we have that $f^{-1}(S_{m,n})$ is a set of measure zero, as well as the countable union of all $S_{m,n}$ for $n \in \mathbb{N}$. So, for all $m \in \mathbb{N}$ the sets $f^{-1}(S_m)$ are of measure zero and the fact that $S = \bigcup_{m \in \mathbb{N}}$ gives the claim: We have $$\mu (\{ x \in X \colon |f(x)| > \|f\|_2 \}) = 0$$ i.e. $\|f\|_2 \geq \|f\|_1$. $\square$ What do you think?",,"['real-analysis', 'measure-theory', 'proof-verification']"
50,Struggling to understand proof in introductory measure theory from Rudin,Struggling to understand proof in introductory measure theory from Rudin,,"So below is an excerpt from Rudin's book on ""Real and Complex Analysis"". The proof just confuses me quite a lot perhaps because of the fact that there's quite a few variables floating around. I've tried to highlight specific points which I believe are stopping me from understanding this. First why does he define function (1) like this? Second, why is it a Borel function, or on what basis is that true? P.S. I'm not asking for complete explanation per se, but some idea of what is going on would be good, thanks a lot!","So below is an excerpt from Rudin's book on ""Real and Complex Analysis"". The proof just confuses me quite a lot perhaps because of the fact that there's quite a few variables floating around. I've tried to highlight specific points which I believe are stopping me from understanding this. First why does he define function (1) like this? Second, why is it a Borel function, or on what basis is that true? P.S. I'm not asking for complete explanation per se, but some idea of what is going on would be good, thanks a lot!",,['measure-theory']
51,Stieltjes measure function to Lebesgue Measure?,Stieltjes measure function to Lebesgue Measure?,,"I have started reading Rick Durrett's ""Probability: Theory and Examples"" Edition 4.1. There is a section quite at the beginning that I do not understand. it starts OK but then at the last line ""When F ( x ) = x the resulting measure is called Lebesgue measure"" Does this imply that when the domain and co-domain has the same value the Stieltjes measure function becomes a Lebesgue Measure? What i have understood so far about Lebesgue Measure doesn't include this definition. Quote: ""Associated with each Stieltjes measure function F there is a unique measure μ on ( $\mathbb{R}$, $\mathcal{R}$) with μ (( a,b ]) = F ( b ) − F ( a ) When F ( x ) = x the resulting measure is called Lebesgue measure.""","I have started reading Rick Durrett's ""Probability: Theory and Examples"" Edition 4.1. There is a section quite at the beginning that I do not understand. it starts OK but then at the last line ""When F ( x ) = x the resulting measure is called Lebesgue measure"" Does this imply that when the domain and co-domain has the same value the Stieltjes measure function becomes a Lebesgue Measure? What i have understood so far about Lebesgue Measure doesn't include this definition. Quote: ""Associated with each Stieltjes measure function F there is a unique measure μ on ( $\mathbb{R}$, $\mathcal{R}$) with μ (( a,b ]) = F ( b ) − F ( a ) When F ( x ) = x the resulting measure is called Lebesgue measure.""",,['measure-theory']
52,"$f$ Lebesgue integrable, showing $f$ is constant almost everywhere","Lebesgue integrable, showing  is constant almost everywhere",f f,"$f\in L^1([a,b])$ satisfies $\lim_{h\rightarrow 0}\frac{1}{h}\int_{a}^{h}|f(t+h)-f(t)|dt = 0$ then $f$ is constant almost everywhere. I tried using the mean value theorem, to somehow get that $f'=0$ almost everywhere, but can't seem to prove it is.","$f\in L^1([a,b])$ satisfies $\lim_{h\rightarrow 0}\frac{1}{h}\int_{a}^{h}|f(t+h)-f(t)|dt = 0$ then $f$ is constant almost everywhere. I tried using the mean value theorem, to somehow get that $f'=0$ almost everywhere, but can't seem to prove it is.",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
53,Hausdorff measure vs Lebesgue measure for a hypersurface in $\mathbb{R}^n$,Hausdorff measure vs Lebesgue measure for a hypersurface in,\mathbb{R}^n,"Let $H$ be a compact smooth hypersurface with boundary in $\mathbb{R}^n$. We can compute the Lebesgue measure $\mathcal{L}(H)$ with respect to the induced Lebesgue measure coming from $\mathbb{R}^n$, and also separately the Hausdorff measure $\mathcal{H}^{n - 1}(H)$. My question is, how do they compare? Does one always have $\mathcal{L}(H) \leq \mathcal{H}^{n - 1}(H)$?","Let $H$ be a compact smooth hypersurface with boundary in $\mathbb{R}^n$. We can compute the Lebesgue measure $\mathcal{L}(H)$ with respect to the induced Lebesgue measure coming from $\mathbb{R}^n$, and also separately the Hausdorff measure $\mathcal{H}^{n - 1}(H)$. My question is, how do they compare? Does one always have $\mathcal{L}(H) \leq \mathcal{H}^{n - 1}(H)$?",,"['measure-theory', 'reference-request', 'lebesgue-measure', 'hausdorff-measure']"
54,"Real Analysis, Folland problem 2.2.16 Integration of Nonnegative functions","Real Analysis, Folland problem 2.2.16 Integration of Nonnegative functions",,"If $f\in L^+$ and $\int f < \infty$, for every $\epsilon > 0$ there exists $E\in M$ such that $\mu(E) < \infty$ and $\int_E f > (\int f) - \epsilon$. Attempted proof - Let $f\in L^+$ and $\int f < \infty$. Let $\epsilon > 0$, by definition of $\int f$, there exists a simple function $\phi = \sum_{n}a_n \chi_{E_n}$ such that $0\leq \phi \leq f$ and $$\int f - \epsilon < \int \phi$$ Note, we have a finite family of disjoint measurable sets $\{E_n\}_{n}$. Let $E = \bigcup_{n}E_n$ then $E\in M$ and for each $n$ $\mu(E_n) < \infty$ this $\mu(E) < \infty$. Note also we have that $\int \phi \leq \int f < \infty$ thus $$\int f - \epsilon < \int_{E}\phi \leq \int_{E}f$$ I am not sure if this is correct any suggestions is greatly appreciated.","If $f\in L^+$ and $\int f < \infty$, for every $\epsilon > 0$ there exists $E\in M$ such that $\mu(E) < \infty$ and $\int_E f > (\int f) - \epsilon$. Attempted proof - Let $f\in L^+$ and $\int f < \infty$. Let $\epsilon > 0$, by definition of $\int f$, there exists a simple function $\phi = \sum_{n}a_n \chi_{E_n}$ such that $0\leq \phi \leq f$ and $$\int f - \epsilon < \int \phi$$ Note, we have a finite family of disjoint measurable sets $\{E_n\}_{n}$. Let $E = \bigcup_{n}E_n$ then $E\in M$ and for each $n$ $\mu(E_n) < \infty$ this $\mu(E) < \infty$. Note also we have that $\int \phi \leq \int f < \infty$ thus $$\int f - \epsilon < \int_{E}\phi \leq \int_{E}f$$ I am not sure if this is correct any suggestions is greatly appreciated.",,"['real-analysis', 'measure-theory']"
55,"Real Analysis, 2.18 (Fatou's Lemma) Integration of Nonnegative functions","Real Analysis, 2.18 (Fatou's Lemma) Integration of Nonnegative functions",,"2.18 Fatou's Lemma - If $\{f_n\}$ is any sequence in $L^+$, then $$\int \left(\lim_{n\rightarrow \infty}\inf f_n\right) \leq \lim_{n\rightarrow \infty}\inf\int f_n$$ Attempted proof - We know that $$\int \left(\lim_{n\rightarrow \infty}\inf f_n\right) = \int \sup_{k\geq 1}\left(\inf_{n\geq k}f_n\right) = \int \lim_{k\rightarrow \infty}\inf_{n\geq k}f_n$$ Then by the Monotone Convergence theorem $$\int \lim_{k\rightarrow \infty}\inf_{n\geq k}f_n = \lim_{k\rightarrow \infty}\int \inf_{n\geq k}f_n$$ Note that the Monotone Convergence theorem can be applied because $$\inf_{n\geq k} f_n \leq \inf_{n\geq k+1} f_n$$ We see that $\inf_{n\geq k}f_n \leq f_k$ for all $n\geq k$. So, \begin{align*} \int \inf_{n\geq k}f_n &\leq \int f_k \ \forall n\geq k\\ &\leq\inf_{n\geq k}\int f_n\\ &\leq \lim_{k\rightarrow \infty}\inf_{n\geq k}\int f_n \end{align*} I may have some indexing mistakes but I think this is a sufficient proof. Any suggestions is greatly appreciated.","2.18 Fatou's Lemma - If $\{f_n\}$ is any sequence in $L^+$, then $$\int \left(\lim_{n\rightarrow \infty}\inf f_n\right) \leq \lim_{n\rightarrow \infty}\inf\int f_n$$ Attempted proof - We know that $$\int \left(\lim_{n\rightarrow \infty}\inf f_n\right) = \int \sup_{k\geq 1}\left(\inf_{n\geq k}f_n\right) = \int \lim_{k\rightarrow \infty}\inf_{n\geq k}f_n$$ Then by the Monotone Convergence theorem $$\int \lim_{k\rightarrow \infty}\inf_{n\geq k}f_n = \lim_{k\rightarrow \infty}\int \inf_{n\geq k}f_n$$ Note that the Monotone Convergence theorem can be applied because $$\inf_{n\geq k} f_n \leq \inf_{n\geq k+1} f_n$$ We see that $\inf_{n\geq k}f_n \leq f_k$ for all $n\geq k$. So, \begin{align*} \int \inf_{n\geq k}f_n &\leq \int f_k \ \forall n\geq k\\ &\leq\inf_{n\geq k}\int f_n\\ &\leq \lim_{k\rightarrow \infty}\inf_{n\geq k}\int f_n \end{align*} I may have some indexing mistakes but I think this is a sufficient proof. Any suggestions is greatly appreciated.",,"['real-analysis', 'measure-theory', 'proof-verification']"
56,"Show that $f$ defined on the interval $(a,b)$ is not differentiable for every point in $E$ with $m(E)=0$",Show that  defined on the interval  is not differentiable for every point in  with,"f (a,b) E m(E)=0","Let $E$ have measure zero contained in the open interval $(a,b)$. In a previous problem I showed that there is a countable collection of open intervals, $\{(c_k,d_k)\}_k$, contained in $(a,b)$ for which each point in $E$ is contained in infinitely many intervals of the collection and $\sum_k |(c_k,d_k)|=\sum_kd_k-c_k<\infty.$ Define $f(x)=\sum_k|(c_k,d_k)\cap(-\infty,x)|$ for $x \in (a,b)$. Show $f$ is increasing and fails to be differentiable for every point in $E$. The absolute value bars mean measure of the interval. I have already shown $f$ was increasing by showing that if $a \le u <v \le b$ then $$\begin{align} f(v)-f(u) &=\sum_k |(c_k,d_k)\cap [(-\infty,u)\cup[u,v)] |-\sum_k|(c_k,d_k)\cap (-\infty,u)|\\&=\sum_k|(c_k,d_k)\cap [u,v)] |\ge 0 \end{align}$$ Let $D^+f(x)=\lim_{h\rightarrow 0}\left[\sup_{0<|t|\le h}\dfrac{f(x+t)-f(x)}{t} \right]$ and $D^-f(x)=\lim_{h\rightarrow 0}\left[\inf_{0<|t|\le h}\dfrac{f(x+t)-f(x)}{t} \right]$ To show f is not differentiable at any point in $E$ then I need to show that $D^+f(x) \not= D^-f(x)$ for every $x \in E$. This is where I am having trouble. First from using what I did above to show that $f$ is increasing I found that for $t>0$ $$ A_t(f(x))= \dfrac{f(x+t)-f(x)}{t}=\dfrac{1}{t}\sum_{k=1}^{\infty}|(c_k,d_k)\cap[x,x+t)| $$ So at this point what we know is that if $x\in E$ then $x$ belongs to $(c_k,d_k)$ for infinitely many $k$ and $\sum_{k=1}^{\infty}|(c_k,d_k)\cap[x,x+t)|$ converges since $\sum_{k=1}^{\infty}|(c_k,d_k)|<\infty$. But Im not sure how to find the $\sup_{0<|t|\le h}$ and $\inf_{0<|t|\le h}$ of $A_t(f(x))$ I think that $\inf_{0<|t|\le h}A_t(f(x))=0$ and $\sup_{0<|t|\le h}A_t(f(x))>0$ but I dont know how to show it. Any help is appreciated, thanks","Let $E$ have measure zero contained in the open interval $(a,b)$. In a previous problem I showed that there is a countable collection of open intervals, $\{(c_k,d_k)\}_k$, contained in $(a,b)$ for which each point in $E$ is contained in infinitely many intervals of the collection and $\sum_k |(c_k,d_k)|=\sum_kd_k-c_k<\infty.$ Define $f(x)=\sum_k|(c_k,d_k)\cap(-\infty,x)|$ for $x \in (a,b)$. Show $f$ is increasing and fails to be differentiable for every point in $E$. The absolute value bars mean measure of the interval. I have already shown $f$ was increasing by showing that if $a \le u <v \le b$ then $$\begin{align} f(v)-f(u) &=\sum_k |(c_k,d_k)\cap [(-\infty,u)\cup[u,v)] |-\sum_k|(c_k,d_k)\cap (-\infty,u)|\\&=\sum_k|(c_k,d_k)\cap [u,v)] |\ge 0 \end{align}$$ Let $D^+f(x)=\lim_{h\rightarrow 0}\left[\sup_{0<|t|\le h}\dfrac{f(x+t)-f(x)}{t} \right]$ and $D^-f(x)=\lim_{h\rightarrow 0}\left[\inf_{0<|t|\le h}\dfrac{f(x+t)-f(x)}{t} \right]$ To show f is not differentiable at any point in $E$ then I need to show that $D^+f(x) \not= D^-f(x)$ for every $x \in E$. This is where I am having trouble. First from using what I did above to show that $f$ is increasing I found that for $t>0$ $$ A_t(f(x))= \dfrac{f(x+t)-f(x)}{t}=\dfrac{1}{t}\sum_{k=1}^{\infty}|(c_k,d_k)\cap[x,x+t)| $$ So at this point what we know is that if $x\in E$ then $x$ belongs to $(c_k,d_k)$ for infinitely many $k$ and $\sum_{k=1}^{\infty}|(c_k,d_k)\cap[x,x+t)|$ converges since $\sum_{k=1}^{\infty}|(c_k,d_k)|<\infty$. But Im not sure how to find the $\sup_{0<|t|\le h}$ and $\inf_{0<|t|\le h}$ of $A_t(f(x))$ I think that $\inf_{0<|t|\le h}A_t(f(x))=0$ and $\sup_{0<|t|\le h}A_t(f(x))>0$ but I dont know how to show it. Any help is appreciated, thanks",,"['real-analysis', 'measure-theory', 'derivatives', 'limsup-and-liminf']"
57,Completeness of product measure,Completeness of product measure,,"Given two measure spaces $(X,\mathcal{A},\mu)$ and $(Y,\mathcal{B},\nu)$, we can define the product measure $\mu\times\nu$ on the algebra $\mathcal{A}\times\mathcal{B}$ defined as the $\sigma$-algebra generated by all measurable rectangles in $X\times Y$. Assuming $\mu$ and $\nu$ are complete, $\mu\times\nu$ need not be. For example, consider $A\in\mathcal{A}$ with $A\ne \emptyset$ but $\mu(A)=0$, and $B\in\mathcal{P}(Y)-\mathcal{B}$ (if $\mathcal{P}(Y)-\mathcal{B}\ne\emptyset$). Then $A\times B\notin \mathcal{A}\times\mathcal{B}$, but $A\times Y\supset A\times B$ is a null set. How can we prove that $A\times B\notin \mathcal{A}\times\mathcal{B}$? It is not obvious to me that we cannot generate $A\times B$ from the measurable rectangles. I cannot think of a way to have $A\times B\in \mathcal{A}\times\mathcal{B}$, however I do not know how I would prove that it is impossible?","Given two measure spaces $(X,\mathcal{A},\mu)$ and $(Y,\mathcal{B},\nu)$, we can define the product measure $\mu\times\nu$ on the algebra $\mathcal{A}\times\mathcal{B}$ defined as the $\sigma$-algebra generated by all measurable rectangles in $X\times Y$. Assuming $\mu$ and $\nu$ are complete, $\mu\times\nu$ need not be. For example, consider $A\in\mathcal{A}$ with $A\ne \emptyset$ but $\mu(A)=0$, and $B\in\mathcal{P}(Y)-\mathcal{B}$ (if $\mathcal{P}(Y)-\mathcal{B}\ne\emptyset$). Then $A\times B\notin \mathcal{A}\times\mathcal{B}$, but $A\times Y\supset A\times B$ is a null set. How can we prove that $A\times B\notin \mathcal{A}\times\mathcal{B}$? It is not obvious to me that we cannot generate $A\times B$ from the measurable rectangles. I cannot think of a way to have $A\times B\in \mathcal{A}\times\mathcal{B}$, however I do not know how I would prove that it is impossible?",,"['measure-theory', 'product-measure']"
58,If a set has infinite measure is it NOT lebesgue measurable? If so why?,If a set has infinite measure is it NOT lebesgue measurable? If so why?,,"The definition I have been given for Lebsgue measureable sets is the following: The sets E for which $\mu E $ is defined, that is for which $\theta A = \theta(AnE) +  \theta (A|E) $ for every A contained the reals are called Lebesgue measurable set. (I assume this definition is following Catheradorys Method) From this I thought if E had infinite measure than it would be hard to define $\ \theta(A|E) $. Can somebody please explain this definition to me as I don't think I fully understand it. How does one know when a set is measurable/Lebesgue measureable? Thanks!","The definition I have been given for Lebsgue measureable sets is the following: The sets E for which $\mu E $ is defined, that is for which $\theta A = \theta(AnE) +  \theta (A|E) $ for every A contained the reals are called Lebesgue measurable set. (I assume this definition is following Catheradorys Method) From this I thought if E had infinite measure than it would be hard to define $\ \theta(A|E) $. Can somebody please explain this definition to me as I don't think I fully understand it. How does one know when a set is measurable/Lebesgue measureable? Thanks!",,['measure-theory']
59,"Real Analysis, Folland problem 2.13. Integration of Nonnegative functions [duplicate]","Real Analysis, Folland problem 2.13. Integration of Nonnegative functions [duplicate]",,"This question already has an answer here : Prove that $\int_{E}f =\lim \int_{E}f_{n}$ (1 answer) Closed 3 years ago . Suppose $\{f_n \}\subset L^{+}$, $f_n\rightarrow f$ pointwise, and $\int f = \lim\int f_n < \infty$. Then $\int_{E}f = \lim\int_{E}f_n$ for all $E\in M$. However, this need not be true if $\int f = \lim\int f_n = \infty$ Proof: Let $E\in M$, by Fatou's Lemma $$\int_{E}f = \int f 1_{E} = \int\lim_{n\rightarrow \infty}\inf f_n 1_{E} \leq \lim_{n\rightarrow \infty}\inf\int f_n 1_{E} = \lim_{n\rightarrow \infty} \inf\int_{E}f_n$$ Similarly, $$\int_{E^{c}}f\leq \lim_{n\rightarrow \infty}\inf\int_{E^{c}}f_n$$ Note, $f = \int f 1_{E} + f 1_{E^{c}}$ and $f_n = f_n 1_{E} + f_n 1_{E^c}$ for all $n\in\mathbb{N}$. This implies, $\int f_{E^c} = \int f - \int_{E} f$ and (for $n$ large) $\int_{E^c}f_n = \int f_n - \int_{E} f_n$. Therefore, $$\int f - \int_{E}f = \int_{E^c}f\leq \lim_{n\rightarrow \infty}\int_{E^c}f_n = \lim_{n\rightarrow\infty}\left(\int f_n - \int_{E} f_n\right) = \int f - \lim_{n\rightarrow \infty}\int_{E}f_n$$ Cancelling $\int f$ from both sides (which is allowed since $\int f = \lim\int f_n < \infty$)   we get $$\int_{E} f = \lim_{n\rightarrow \infty}\int_{E}f_n$$ I have not completed the second part yet, I just wanted to make sure this is correct, any suggestions is greatly appreciated especially for the second part.","This question already has an answer here : Prove that $\int_{E}f =\lim \int_{E}f_{n}$ (1 answer) Closed 3 years ago . Suppose $\{f_n \}\subset L^{+}$, $f_n\rightarrow f$ pointwise, and $\int f = \lim\int f_n < \infty$. Then $\int_{E}f = \lim\int_{E}f_n$ for all $E\in M$. However, this need not be true if $\int f = \lim\int f_n = \infty$ Proof: Let $E\in M$, by Fatou's Lemma $$\int_{E}f = \int f 1_{E} = \int\lim_{n\rightarrow \infty}\inf f_n 1_{E} \leq \lim_{n\rightarrow \infty}\inf\int f_n 1_{E} = \lim_{n\rightarrow \infty} \inf\int_{E}f_n$$ Similarly, $$\int_{E^{c}}f\leq \lim_{n\rightarrow \infty}\inf\int_{E^{c}}f_n$$ Note, $f = \int f 1_{E} + f 1_{E^{c}}$ and $f_n = f_n 1_{E} + f_n 1_{E^c}$ for all $n\in\mathbb{N}$. This implies, $\int f_{E^c} = \int f - \int_{E} f$ and (for $n$ large) $\int_{E^c}f_n = \int f_n - \int_{E} f_n$. Therefore, $$\int f - \int_{E}f = \int_{E^c}f\leq \lim_{n\rightarrow \infty}\int_{E^c}f_n = \lim_{n\rightarrow\infty}\left(\int f_n - \int_{E} f_n\right) = \int f - \lim_{n\rightarrow \infty}\int_{E}f_n$$ Cancelling $\int f$ from both sides (which is allowed since $\int f = \lim\int f_n < \infty$)   we get $$\int_{E} f = \lim_{n\rightarrow \infty}\int_{E}f_n$$ I have not completed the second part yet, I just wanted to make sure this is correct, any suggestions is greatly appreciated especially for the second part.",,"['real-analysis', 'measure-theory', 'proof-verification']"
60,Minimum Number of Sets Needed to Generate the Power Set,Minimum Number of Sets Needed to Generate the Power Set,,"Take a finite set $A$ with $|A|=n.$ Let $\mathscr{F}$ be the power set of $A$. What is the smallest number of sets needed to generate $\mathscr{F}$? That is, if $\mathscr{C}$ is a set of subsets of $A$, what is the minimum size of $\mathscr{C}$ such that $\sigma (\mathscr{C})=\mathscr{F},$ where $\sigma (\mathscr{C})$ denotes the sigma-field generated by $\mathscr{C}.$ My approach to this is to look at $\mathscr{C}$ being able to generate all the singletons of $A$. So we have an upper bound on the size of $\mathscr{C}$ at $n$, this comes from just letting $\mathscr{C}$ be the set of singletons. However, looking at the example of $A=\{ 1,2,3\},$ I can get a set that $\mathscr{C}=\{\{1,2\},\{2,3\}\}$ generates $\mathscr{F}$. So I know that $n$ is not the minimal size, but I am unsure how to go about finding the minimal size. Thanks for any help!","Take a finite set $A$ with $|A|=n.$ Let $\mathscr{F}$ be the power set of $A$. What is the smallest number of sets needed to generate $\mathscr{F}$? That is, if $\mathscr{C}$ is a set of subsets of $A$, what is the minimum size of $\mathscr{C}$ such that $\sigma (\mathscr{C})=\mathscr{F},$ where $\sigma (\mathscr{C})$ denotes the sigma-field generated by $\mathscr{C}.$ My approach to this is to look at $\mathscr{C}$ being able to generate all the singletons of $A$. So we have an upper bound on the size of $\mathscr{C}$ at $n$, this comes from just letting $\mathscr{C}$ be the set of singletons. However, looking at the example of $A=\{ 1,2,3\},$ I can get a set that $\mathscr{C}=\{\{1,2\},\{2,3\}\}$ generates $\mathscr{F}$. So I know that $n$ is not the minimal size, but I am unsure how to go about finding the minimal size. Thanks for any help!",,"['real-analysis', 'measure-theory']"
61,"Explicit construction of a nonmeasurable set, where only the proof of correctness uses choice?","Explicit construction of a nonmeasurable set, where only the proof of correctness uses choice?",,"By Solovay's theorem, assuming the existence of an inaccessible cardinal, the axiom of choice is necessary to prove the existence of nonmeasurable sets. In the past, I've thought that one consequence of this theorem is that if I construct a set without using choice (or even merely using dependent choice), then I don't have to worry about it being nonmeasurable. But now I realize that I was making an unjustified assumption. I'm not sure what the appropriate way to precisely phrase this question is, but I'm wondering: is there a non Lebesgue measurable set $E \subseteq \mathbb{R}$ which can be explicitly defined? I'm imagining that perhaps $E$ can be defined without invoking choice (unlike Vitali sets or their cousins), but then proving that $E$ is nonmeasurable requires choice. Is this possibility also ruled out by Solovay's theorem somehow?","By Solovay's theorem, assuming the existence of an inaccessible cardinal, the axiom of choice is necessary to prove the existence of nonmeasurable sets. In the past, I've thought that one consequence of this theorem is that if I construct a set without using choice (or even merely using dependent choice), then I don't have to worry about it being nonmeasurable. But now I realize that I was making an unjustified assumption. I'm not sure what the appropriate way to precisely phrase this question is, but I'm wondering: is there a non Lebesgue measurable set $E \subseteq \mathbb{R}$ which can be explicitly defined? I'm imagining that perhaps $E$ can be defined without invoking choice (unlike Vitali sets or their cousins), but then proving that $E$ is nonmeasurable requires choice. Is this possibility also ruled out by Solovay's theorem somehow?",,"['measure-theory', 'logic', 'lebesgue-measure', 'axiom-of-choice']"
62,When does the diagonal have zero measure?,When does the diagonal have zero measure?,,Let $\mu$ be a Radon measure on a space $X$ and consider the product measure $\mu \otimes \mu$ on $X \times X$. Is there some necessary and/or sufficient condition on $\mu$ to guarantee that the diagonal $\Delta \subset X \times X$ has zero $\mu \otimes \mu$-measure?,Let $\mu$ be a Radon measure on a space $X$ and consider the product measure $\mu \otimes \mu$ on $X \times X$. Is there some necessary and/or sufficient condition on $\mu$ to guarantee that the diagonal $\Delta \subset X \times X$ has zero $\mu \otimes \mu$-measure?,,['measure-theory']
63,Class of Lebesgue-Lebesgue measurable functions?,Class of Lebesgue-Lebesgue measurable functions?,,"A function $f:\mathbb{R}^n\to\mathbb{R}^m$ is Lebesgue-Lebesgue measurable iff inverse images of Lebesgue measurable sets are Lebesgue measurable. Seems to me that since projections* and arithmetic operations are Lebesgue-Lebesgue measurable surjective linear transformations have to be Lebesgue-Lebesgue. Is it possible to generalize and say that all surjective multivariable polynomials (rational/analytic functions) are Lebesgue-Lebesgue? For surjective rational functions in one variable I had the following idea:  Let $f:\mathbb{R}\to\mathbb{R}$ be a rational function, dissect $\mathbb{R}$ to a finite number of intervals s.t. at any interval $I_k$, $f:I_k \to f(I_k)$ is a diffeomorphism. Then glue them together to get a function that preserves measurability in both directions. (maybe i can extend that to the case where $f$ had countable number of zeros and singularities?) *By which i don't mean to include ""projections"" like $f:x \mapsto (x,0)$","A function $f:\mathbb{R}^n\to\mathbb{R}^m$ is Lebesgue-Lebesgue measurable iff inverse images of Lebesgue measurable sets are Lebesgue measurable. Seems to me that since projections* and arithmetic operations are Lebesgue-Lebesgue measurable surjective linear transformations have to be Lebesgue-Lebesgue. Is it possible to generalize and say that all surjective multivariable polynomials (rational/analytic functions) are Lebesgue-Lebesgue? For surjective rational functions in one variable I had the following idea:  Let $f:\mathbb{R}\to\mathbb{R}$ be a rational function, dissect $\mathbb{R}$ to a finite number of intervals s.t. at any interval $I_k$, $f:I_k \to f(I_k)$ is a diffeomorphism. Then glue them together to get a function that preserves measurability in both directions. (maybe i can extend that to the case where $f$ had countable number of zeros and singularities?) *By which i don't mean to include ""projections"" like $f:x \mapsto (x,0)$",,['measure-theory']
64,Show a function is Lebesgue integrable,Show a function is Lebesgue integrable,,"Hi I am struggling with a question but really I am struggling more with the concepts behind it so any help would be appreciated. Q/ Let $$f(x)=\begin{cases}  x^{-\frac{1}{2}} & ,x\in(0,1) \\  0 & , \text{otherwise}  \end{cases}$$ Let $r_k$ , k={1,2,3...} be an enumeration of all rationals and set $$ g(x)=\sum_{k=1}^{\infty}2^{-k}f(x-r_k) $$ Prove g is lebesgue integrable. So if we say $\lambda$ is the lebesgue measure, the question is asking us to show that $\int g \;d\lambda$ is defined. It is clear g is not a simple function so I am thinking the first step is to show that g is a measurable function but then the question seems ambiguous, what sigma algebra do I use on $\mathbb{R}$ ? Is the standard to use the Borel sets? or maybe I should use the set of all Lebesgue measurable functions? Then since g is non negative the definition of the integral says $\int g \;d\lambda=sup\{\int f \;d\lambda\; :0\leq f\leq g\}$ where f is simple and measurable, so then I show this supremum exists and I am done? Thanks","Hi I am struggling with a question but really I am struggling more with the concepts behind it so any help would be appreciated. Q/ Let Let , k={1,2,3...} be an enumeration of all rationals and set Prove g is lebesgue integrable. So if we say is the lebesgue measure, the question is asking us to show that is defined. It is clear g is not a simple function so I am thinking the first step is to show that g is a measurable function but then the question seems ambiguous, what sigma algebra do I use on ? Is the standard to use the Borel sets? or maybe I should use the set of all Lebesgue measurable functions? Then since g is non negative the definition of the integral says where f is simple and measurable, so then I show this supremum exists and I am done? Thanks","f(x)=\begin{cases} 
x^{-\frac{1}{2}} & ,x\in(0,1) \\ 
0 & , \text{otherwise} 
\end{cases} r_k 
g(x)=\sum_{k=1}^{\infty}2^{-k}f(x-r_k)
 \lambda \int g \;d\lambda \mathbb{R} \int g \;d\lambda=sup\{\int f \;d\lambda\; :0\leq f\leq g\}","['real-analysis', 'measure-theory', 'lebesgue-integral']"
65,Inducing a surface area measure on $S^2$ from the Haar measure on $SO(3)$,Inducing a surface area measure on  from the Haar measure on,S^2 SO(3),"I'm reading the book ""Random Matrices: High Dimensional Phenomena"" by G. Blower. There is an example that I've been struggled for a long time. For those who have access to the book, it's the Example 1.2.1 (iii) on p.11. From my understanding, the author is trying to derive a surface area measure on $S^2$ by a pushforward map. It starts with the fact that every compact group has a unique probability Haar measure on it. So is $\operatorname{SO}(3)=\{U\in M_3(\mathbb{R}):U^TU=I, \det U=1 \}$ . It then says that the map $\varphi:SO(3)\rightarrow S^2$ given by $\varphi(U)=Ue_3$ , where $e_3=(0,0,1)^T$ is the third canonical basis, induces a measure $\sigma_2$ on $S^2$ , normalized to be a probability measure, from the Haar measure on $\operatorname{SO}(3)$ . Also, it mentions that since $\varphi$ is not bijective: $Ve_3=Ue_3$ i.f.f. $V^{-1}U\in\operatorname{SO}(2)\subset\operatorname{SO}(3)$ . Thus we have that $\operatorname{SO}(3)/\operatorname{SO}(2)\cong S^2$ . Anyway, it gives the formula for the measure in terms of colatitude $\theta$ and longtitude $\phi$ : $\mathrm{d}\sigma_2=\frac{1}{4\pi}\sin\theta\mathrm{d}\theta\mathrm{d}\phi$ , which coincides with what I learned from advanced calculus course. Can anyone tell me how he obtain this area measure? I want to know the procedure (as clear as possible) for computing this $d\sigma$ . Thanks!","I'm reading the book ""Random Matrices: High Dimensional Phenomena"" by G. Blower. There is an example that I've been struggled for a long time. For those who have access to the book, it's the Example 1.2.1 (iii) on p.11. From my understanding, the author is trying to derive a surface area measure on by a pushforward map. It starts with the fact that every compact group has a unique probability Haar measure on it. So is . It then says that the map given by , where is the third canonical basis, induces a measure on , normalized to be a probability measure, from the Haar measure on . Also, it mentions that since is not bijective: i.f.f. . Thus we have that . Anyway, it gives the formula for the measure in terms of colatitude and longtitude : , which coincides with what I learned from advanced calculus course. Can anyone tell me how he obtain this area measure? I want to know the procedure (as clear as possible) for computing this . Thanks!","S^2 \operatorname{SO}(3)=\{U\in M_3(\mathbb{R}):U^TU=I, \det U=1 \} \varphi:SO(3)\rightarrow S^2 \varphi(U)=Ue_3 e_3=(0,0,1)^T \sigma_2 S^2 \operatorname{SO}(3) \varphi Ve_3=Ue_3 V^{-1}U\in\operatorname{SO}(2)\subset\operatorname{SO}(3) \operatorname{SO}(3)/\operatorname{SO}(2)\cong S^2 \theta \phi \mathrm{d}\sigma_2=\frac{1}{4\pi}\sin\theta\mathrm{d}\theta\mathrm{d}\phi d\sigma","['measure-theory', 'lie-groups', 'topological-groups']"
66,Completely stumped on exercise cooncerning the characterisation of Jordan measure - would anyone be willing to give a hint?,Completely stumped on exercise cooncerning the characterisation of Jordan measure - would anyone be willing to give a hint?,,"In Terry Tao's notes on measure theory he has the following exercise, I have no idea how to deal with the last statement, I would really appreciate it if someone could give a hint for the final case. Show that the following are equivalent: $E$ is Jordan Measurable For all $\epsilon > 0$ there exists elementary sets $A$ and $B$ satisfying $A \subset E \subset B$ such that $m(B/A) \leq \epsilon$ For all $\epsilon >0$ there exists an elementary set $A$ such that $m^{*}(A\Delta E) \leq \epsilon,$ where $m^*(\cdot)$ is the Jordan outer measure. Here is my attempt so far: $1. \Rightarrow 2.$ Since $E$ is measureable, we have $m(E) = m^*(E) = m_*(E)$ where $m_*(\cdot)$ is the Jordan inner measure. By assumption we can find elementary sets $B$ and $A$ where  $A \subset E \subset B$ such that $m(B) - m(E) \leq \epsilon$ and $m(E) - m(A) \leq \epsilon.$ It thus follows that $m(B) - m(A) \leq 2\epsilon.$ Since $A$ and $B$ are elementary we have that $m(B) = m(B/A) + m(A).$ combined with the inequality above this gives $m(B/A) \leq 2\epsilon$ $2. \Rightarrow 1.$ Choose $A \subset E \subset B$ with $m(B/A) \leq \epsilon$ then $\epsilon \geq m(B/A) = m(B) - m(A) \geq m(B) - m_*(E) \geq m^*(E) - m_*(E) = |m^*(E) - m_*(E)|$ Since $\epsilon$ was arbitrary the result follows.","In Terry Tao's notes on measure theory he has the following exercise, I have no idea how to deal with the last statement, I would really appreciate it if someone could give a hint for the final case. Show that the following are equivalent: $E$ is Jordan Measurable For all $\epsilon > 0$ there exists elementary sets $A$ and $B$ satisfying $A \subset E \subset B$ such that $m(B/A) \leq \epsilon$ For all $\epsilon >0$ there exists an elementary set $A$ such that $m^{*}(A\Delta E) \leq \epsilon,$ where $m^*(\cdot)$ is the Jordan outer measure. Here is my attempt so far: $1. \Rightarrow 2.$ Since $E$ is measureable, we have $m(E) = m^*(E) = m_*(E)$ where $m_*(\cdot)$ is the Jordan inner measure. By assumption we can find elementary sets $B$ and $A$ where  $A \subset E \subset B$ such that $m(B) - m(E) \leq \epsilon$ and $m(E) - m(A) \leq \epsilon.$ It thus follows that $m(B) - m(A) \leq 2\epsilon.$ Since $A$ and $B$ are elementary we have that $m(B) = m(B/A) + m(A).$ combined with the inequality above this gives $m(B/A) \leq 2\epsilon$ $2. \Rightarrow 1.$ Choose $A \subset E \subset B$ with $m(B/A) \leq \epsilon$ then $\epsilon \geq m(B/A) = m(B) - m(A) \geq m(B) - m_*(E) \geq m^*(E) - m_*(E) = |m^*(E) - m_*(E)|$ Since $\epsilon$ was arbitrary the result follows.",,['measure-theory']
67,"Where is ""countability"" used in this proposition about product $\sigma$-algebra?","Where is ""countability"" used in this proposition about product -algebra?",\sigma,"The following is a proposition about product sigma algebra from Folland's Real Analysis : Proposition. If $A$ is countable, then $\otimes_{\alpha\in A}M_{\alpha}$ is is the $\sigma$ -algebra generated by $\{\Pi_{\alpha\in A}E_\alpha:E_\alpha\in M_\alpha\}$ . Proof. If $E_{\alpha}\in M_{\alpha}$ , then $\pi_\alpha^{-1}(E_\alpha)=\Pi_{\beta\in A}E_\beta$ where $E_\beta=X_\beta$ for $\beta\not=\alpha$ ; on the other hand, $\Pi_{\alpha\in A}E_\alpha=\cap_{\alpha\in A}\pi^{-1}_\alpha(E_\alpha)$ . The result therefore follows from Lemma 1.1. [Added]Lemma 1.1: If $\mathcal{E}\subset M(\mathcal{F})$ then $M(\mathcal{E})\subset M(\mathcal{F})$ where $M(\mathcal{E})$ denotes the sigma algebra generated by $\mathcal{E}$ . Where is the assumption "" $A$ is countable"" used in the proof?","The following is a proposition about product sigma algebra from Folland's Real Analysis : Proposition. If is countable, then is is the -algebra generated by . Proof. If , then where for ; on the other hand, . The result therefore follows from Lemma 1.1. [Added]Lemma 1.1: If then where denotes the sigma algebra generated by . Where is the assumption "" is countable"" used in the proof?",A \otimes_{\alpha\in A}M_{\alpha} \sigma \{\Pi_{\alpha\in A}E_\alpha:E_\alpha\in M_\alpha\} E_{\alpha}\in M_{\alpha} \pi_\alpha^{-1}(E_\alpha)=\Pi_{\beta\in A}E_\beta E_\beta=X_\beta \beta\not=\alpha \Pi_{\alpha\in A}E_\alpha=\cap_{\alpha\in A}\pi^{-1}_\alpha(E_\alpha) \mathcal{E}\subset M(\mathcal{F}) M(\mathcal{E})\subset M(\mathcal{F}) M(\mathcal{E}) \mathcal{E} A,['real-analysis']
68,Definition of strong mixing and definition of measure-preserving,Definition of strong mixing and definition of measure-preserving,,"I have a few questions regarding measure-preserving dynamical systems $(X,\mathcal{A},\mu,T)$. 1) The definition of measure preserving is always stated as $$\mu(T^{-1}B)=\mu(B),$$ for all $B$. I believe this neither implies nor is implied by the similar statement $$\mu(TB)=\mu(B).$$ Is this correct? The problem lies in the fact that  $TT^{-1}B \subseteq B \subseteq T^{-1}TB$ may be strict inclusions, so the following implications may not hold: $$\mu(T^{-1} TB) = \mu(TB) \implies \mu(B)=\mu(TB)$$ and $$\mu(TT^{-1}B)= \mu(T^{-1}B) \implies \mu(B)=\mu(T^{-1}B).$$ 2) Is there some ""reason"" why the above definition involves $T^{-1}$ rather than $T$? 3) The definition of strong mixing is $$\lim_{n \to \infty} \mu(A \cap T^{-n}B) = \mu(A) \mu(B)$$ for all $A$ and $B$. Again, the exponent of $T$ is negative. However, in the wine-water example below the definition, they have $T^n$. Is this an issue? Thank you in advance","I have a few questions regarding measure-preserving dynamical systems $(X,\mathcal{A},\mu,T)$. 1) The definition of measure preserving is always stated as $$\mu(T^{-1}B)=\mu(B),$$ for all $B$. I believe this neither implies nor is implied by the similar statement $$\mu(TB)=\mu(B).$$ Is this correct? The problem lies in the fact that  $TT^{-1}B \subseteq B \subseteq T^{-1}TB$ may be strict inclusions, so the following implications may not hold: $$\mu(T^{-1} TB) = \mu(TB) \implies \mu(B)=\mu(TB)$$ and $$\mu(TT^{-1}B)= \mu(T^{-1}B) \implies \mu(B)=\mu(T^{-1}B).$$ 2) Is there some ""reason"" why the above definition involves $T^{-1}$ rather than $T$? 3) The definition of strong mixing is $$\lim_{n \to \infty} \mu(A \cap T^{-n}B) = \mu(A) \mu(B)$$ for all $A$ and $B$. Again, the exponent of $T$ is negative. However, in the wine-water example below the definition, they have $T^n$. Is this an issue? Thank you in advance",,"['measure-theory', 'dynamical-systems', 'ergodic-theory', 'mixing']"
69,Find $\delta >0$ such that $\int_E |f| d\mu < \epsilon$ whenever $\mu(E)<\delta$,Find  such that  whenever,\delta >0 \int_E |f| d\mu < \epsilon \mu(E)<\delta,"I am studying for a qualifying exam, and I am struggling with this problem since $f$ is not necessarily integrable. Let $(X,\Sigma, \mu)$ be a measure space and let $$\mathcal{L}(\mu) = \{ \text{ measurable } f \quad| \quad  \chi_Ef \in L^1(\mu) \text{ whenever } \mu(E)<\infty\}.$$ Show that for any $f\in \mathcal{L}(\mu)$ and any $\epsilon >0$ there is $\delta >0$ such that $\int_E|f| d\mu < \epsilon$ whenever $\mu(E)< \delta$. A technique I've used in other similar problems is to define $A_n = \{ x\in X \, | \, 1/n \leq |f(x)| \leq n \}$ and let $A = \displaystyle \bigcup_{n=1}^\infty A_n$. We can also define $A_0 = \{ x\in X \,|\, f(x) = 0\}$ and $A_\infty= \{x\in X\, | \, |f(x)| = \infty\}$. The part where I'm stuck is now that  $$\int_X|f|d\mu = \int_{A_0} |f|d\mu + \int_{A} |f| d\mu + \int_{A_\infty} |f|d\mu$$ where the first term on the right is zero, and I want the last term on the right to be zero. Is there another way to go about this problem? Explanations are helpful to me since I'm studying and I don't want to confuse myself further. Thanks!","I am studying for a qualifying exam, and I am struggling with this problem since $f$ is not necessarily integrable. Let $(X,\Sigma, \mu)$ be a measure space and let $$\mathcal{L}(\mu) = \{ \text{ measurable } f \quad| \quad  \chi_Ef \in L^1(\mu) \text{ whenever } \mu(E)<\infty\}.$$ Show that for any $f\in \mathcal{L}(\mu)$ and any $\epsilon >0$ there is $\delta >0$ such that $\int_E|f| d\mu < \epsilon$ whenever $\mu(E)< \delta$. A technique I've used in other similar problems is to define $A_n = \{ x\in X \, | \, 1/n \leq |f(x)| \leq n \}$ and let $A = \displaystyle \bigcup_{n=1}^\infty A_n$. We can also define $A_0 = \{ x\in X \,|\, f(x) = 0\}$ and $A_\infty= \{x\in X\, | \, |f(x)| = \infty\}$. The part where I'm stuck is now that  $$\int_X|f|d\mu = \int_{A_0} |f|d\mu + \int_{A} |f| d\mu + \int_{A_\infty} |f|d\mu$$ where the first term on the right is zero, and I want the last term on the right to be zero. Is there another way to go about this problem? Explanations are helpful to me since I'm studying and I don't want to confuse myself further. Thanks!",,"['real-analysis', 'measure-theory']"
70,"Find an example of Lebesgue measurable subsets of $[0,1]$ these conditions:",Find an example of Lebesgue measurable subsets of  these conditions:,"[0,1]","Let $m$ be Lebesgue measure. Find an example of Lebesgue measurable subsets $A_1, A_2, \dots$ of $[0,1]$ such that $m(A_n) > 0$ for each $n$, $m(A_n \Delta A_m) >0$ if $m \neq n$, and $m(A_n \cap A_m) = m(A_n)m(A_m)$ if $m\neq n$. I've spent some time trying to come up with examples of sets that satisfy these conditions and here's what I've come up with so far: These sets can't be properly nested since this would not satisfy the multiplicative property. Each set must intersect every other set in order to satisfy the multiplicative property. I've tried many variations of shifting shrinking closed intervals through the interval $[0,1]$. Any nudges in the right direction would be appreciated.","Let $m$ be Lebesgue measure. Find an example of Lebesgue measurable subsets $A_1, A_2, \dots$ of $[0,1]$ such that $m(A_n) > 0$ for each $n$, $m(A_n \Delta A_m) >0$ if $m \neq n$, and $m(A_n \cap A_m) = m(A_n)m(A_m)$ if $m\neq n$. I've spent some time trying to come up with examples of sets that satisfy these conditions and here's what I've come up with so far: These sets can't be properly nested since this would not satisfy the multiplicative property. Each set must intersect every other set in order to satisfy the multiplicative property. I've tried many variations of shifting shrinking closed intervals through the interval $[0,1]$. Any nudges in the right direction would be appreciated.",,"['measure-theory', 'lebesgue-measure']"
71,Qual problem in Analysis,Qual problem in Analysis,,"I am having trouble with the following qual problem.  Some help would be awesome.  Thanks. Let $f$ be a measurable function on $(0, ∞).$ Let $p > 1/2$ and define $g(x) = (x^p + x^{−p})f(x).$ Show that if $g ∈ L_2(0,∞)$ then $f ∈ L_1(0,∞).$","I am having trouble with the following qual problem.  Some help would be awesome.  Thanks. Let $f$ be a measurable function on $(0, ∞).$ Let $p > 1/2$ and define $g(x) = (x^p + x^{−p})f(x).$ Show that if $g ∈ L_2(0,∞)$ then $f ∈ L_1(0,∞).$",,"['real-analysis', 'measure-theory']"
72,Constructively generating a sigma algebra,Constructively generating a sigma algebra,,We have a collection $\mathcal{C}$ of sets (includes $\Omega)$ and would like to constructively generate the sigma algebra $\sigma(\mathcal{C})$. Would the following process work? Let $\mathcal{S}=\mathcal{C}$ 1.Take the complement of each set in $\mathcal{S}$ and add it to $\mathcal{S}$ 2.Take all possible finite and countably infinite unions of sets in $\mathcal{S}$ and add them to $\mathcal{S}$. 3. goto step 1. I have seen it claimed that taking countable unions and intersections of open intervals can only give you a proper subset of the Borel sets. This would seem to imply that the above process would not work because any resulting set could only have arisen from countable unions and intersections.,We have a collection $\mathcal{C}$ of sets (includes $\Omega)$ and would like to constructively generate the sigma algebra $\sigma(\mathcal{C})$. Would the following process work? Let $\mathcal{S}=\mathcal{C}$ 1.Take the complement of each set in $\mathcal{S}$ and add it to $\mathcal{S}$ 2.Take all possible finite and countably infinite unions of sets in $\mathcal{S}$ and add them to $\mathcal{S}$. 3. goto step 1. I have seen it claimed that taking countable unions and intersections of open intervals can only give you a proper subset of the Borel sets. This would seem to imply that the above process would not work because any resulting set could only have arisen from countable unions and intersections.,,"['measure-theory', 'set-theory']"
73,Show that $\mathfrak{S}=\bigcup_{N=1}^{\infty}\mathfrak{Z}_N\cup\left\{\emptyset\right\}$ is a semi-ring,Show that  is a semi-ring,\mathfrak{S}=\bigcup_{N=1}^{\infty}\mathfrak{Z}_N\cup\left\{\emptyset\right\},"Let $\Gamma$ be a finite set, $\Omega=\Gamma^{\mathbb{N}}=\left\{(x_1,x_2,\ldots):~\forall i\in\mathbb{N} x_i\in\Gamma\right\}$. For $a_1,\ldots,a_N\in\Gamma$ let     $$ [a_1,\ldots,a_N]:=\left\{(x_1,x_2,\ldots)\in\Gamma^{\mathbb{N}}: i=1,\ldots,N x_i=a_i\right\} $$     be the $N$-cylinder which is determined by $a_1,\ldots,a_N$. Define     $$ \mathfrak{Z}_N:=\left\{[a_1,\ldots,a_N]: a_1,\ldots,a_N\in\Gamma\right\}. $$     Show, that then     $$ \mathfrak{S}:=\bigcup_{N=1}^{\infty}\mathfrak{Z}_N\cup\left\{\emptyset\right\} $$     is a semi-ring for $\Omega$. Hello! Three things are to show: (1) $\emptyset\in\mathfrak{S}$ (2) $A,B\in\mathfrak{S}\implies A\cap B\in\mathfrak{S}$ (3) $A,B\in\mathfrak{S}$ and $A\subset B\implies~\exists A_1,\ldots,A_n\in\mathfrak{S}$ pairwise disjoint, so that $B\setminus A=A_1\cup\cdots\cup A_n$. Proof. (1) is clear by definition of $\mathfrak{S}$. (2) $A\in\mathfrak{S}$, i.e. $A=[a_1,\ldots,a_N]$ for a $N\in\mathbb{N}$ and $a_1,\ldots,a_N\in\Gamma$. $B\in\mathfrak{S}$, i.e. $B=[b_1,\ldots,b_M]$ for a $M\in\mathbb{N}$ and $b_1,\ldots,b_M\in\Gamma$. To my opinion then $$ A\cap B=\begin{cases}A, & N\leq M\wedge a_i=b_i, i=1,\ldots,N\\B, & M\leq N\wedge b_i=a_i, i=1,\ldots,M\\\emptyset, & \text{otherwise}\end{cases} $$ and $A,B,\emptyset\in\mathfrak{S}$. (3) $A,B\in\mathfrak{S}, A\subset B$. If $A\subset B$, this means for $A=[a_1,\ldots a_N]$ and $B=[b_1,\ldots,b_M]$ that $N\leq M$ and $a_i=b_i, i=1,\ldots,N$. I am not sure, but to my opinion then $B\setminus A=\emptyset$. And so $B\setminus A$ can be writte as disjoint union of ONE set, namely the emptyset. Would be great to know if my proof is ok. Miro","Let $\Gamma$ be a finite set, $\Omega=\Gamma^{\mathbb{N}}=\left\{(x_1,x_2,\ldots):~\forall i\in\mathbb{N} x_i\in\Gamma\right\}$. For $a_1,\ldots,a_N\in\Gamma$ let     $$ [a_1,\ldots,a_N]:=\left\{(x_1,x_2,\ldots)\in\Gamma^{\mathbb{N}}: i=1,\ldots,N x_i=a_i\right\} $$     be the $N$-cylinder which is determined by $a_1,\ldots,a_N$. Define     $$ \mathfrak{Z}_N:=\left\{[a_1,\ldots,a_N]: a_1,\ldots,a_N\in\Gamma\right\}. $$     Show, that then     $$ \mathfrak{S}:=\bigcup_{N=1}^{\infty}\mathfrak{Z}_N\cup\left\{\emptyset\right\} $$     is a semi-ring for $\Omega$. Hello! Three things are to show: (1) $\emptyset\in\mathfrak{S}$ (2) $A,B\in\mathfrak{S}\implies A\cap B\in\mathfrak{S}$ (3) $A,B\in\mathfrak{S}$ and $A\subset B\implies~\exists A_1,\ldots,A_n\in\mathfrak{S}$ pairwise disjoint, so that $B\setminus A=A_1\cup\cdots\cup A_n$. Proof. (1) is clear by definition of $\mathfrak{S}$. (2) $A\in\mathfrak{S}$, i.e. $A=[a_1,\ldots,a_N]$ for a $N\in\mathbb{N}$ and $a_1,\ldots,a_N\in\Gamma$. $B\in\mathfrak{S}$, i.e. $B=[b_1,\ldots,b_M]$ for a $M\in\mathbb{N}$ and $b_1,\ldots,b_M\in\Gamma$. To my opinion then $$ A\cap B=\begin{cases}A, & N\leq M\wedge a_i=b_i, i=1,\ldots,N\\B, & M\leq N\wedge b_i=a_i, i=1,\ldots,M\\\emptyset, & \text{otherwise}\end{cases} $$ and $A,B,\emptyset\in\mathfrak{S}$. (3) $A,B\in\mathfrak{S}, A\subset B$. If $A\subset B$, this means for $A=[a_1,\ldots a_N]$ and $B=[b_1,\ldots,b_M]$ that $N\leq M$ and $a_i=b_i, i=1,\ldots,N$. I am not sure, but to my opinion then $B\setminus A=\emptyset$. And so $B\setminus A$ can be writte as disjoint union of ONE set, namely the emptyset. Would be great to know if my proof is ok. Miro",,"['measure-theory', 'proof-verification']"
74,"Show: $\sum_{k=1}^{\infty}\mu(\left\{f\geq k\right\})\leq\int f\, d\mu\leq\sum_{k=0}^{\infty}\mu(\left\{f>k\right\})$",Show:,"\sum_{k=1}^{\infty}\mu(\left\{f\geq k\right\})\leq\int f\, d\mu\leq\sum_{k=0}^{\infty}\mu(\left\{f>k\right\})","Show that für $f\colon (\Omega,\mathcal{A})\to\mathbb{R}_{\geq 0}$ measurable, it is     $$ \sum_{k=1}^{\infty}\mu(\left\{f\geq k\right\})\leq\int f\, d\mu\leq\sum_{k=0}^{\infty}\mu(\left\{f>k\right\}). $$ I do not know if one needs it here, but we defined the integral of a non-negative measurable function $f\colon (\Omega,\mathcal{A})\to (\overline{\mathbb{R}},\overline{\mathcal{B}})$ by $$ \int_{\Omega}f\, d\mu=\sup\left\{\sum_{k=1}^{n}(\inf\left\{f(x): x\in A_k\right\})\mu(A_k): n\in\mathbb{N}, A_1,\ldots,A_n\in\mathcal{A}\mbox{ disjoint },\Omega=\bigcup_{k=1}^{n}A_k\right\}. $$ My first idea was to use this definition, but I did not come along with it... Maybe you can help me to show that? (I think, maybe it has something to do with monotone convergence theorem or majorated convergence?)","Show that für $f\colon (\Omega,\mathcal{A})\to\mathbb{R}_{\geq 0}$ measurable, it is     $$ \sum_{k=1}^{\infty}\mu(\left\{f\geq k\right\})\leq\int f\, d\mu\leq\sum_{k=0}^{\infty}\mu(\left\{f>k\right\}). $$ I do not know if one needs it here, but we defined the integral of a non-negative measurable function $f\colon (\Omega,\mathcal{A})\to (\overline{\mathbb{R}},\overline{\mathcal{B}})$ by $$ \int_{\Omega}f\, d\mu=\sup\left\{\sum_{k=1}^{n}(\inf\left\{f(x): x\in A_k\right\})\mu(A_k): n\in\mathbb{N}, A_1,\ldots,A_n\in\mathcal{A}\mbox{ disjoint },\Omega=\bigcup_{k=1}^{n}A_k\right\}. $$ My first idea was to use this definition, but I did not come along with it... Maybe you can help me to show that? (I think, maybe it has something to do with monotone convergence theorem or majorated convergence?)",,[]
75,Find a Borel subset satisfying the condition,Find a Borel subset satisfying the condition,,"Let $\alpha \in (0,1)$. Find a fixed Borel subset $E$ of $[-1,1]$ such that  $$ \lim_{r \rightarrow 0^+} \frac{m(E \cap [-r,r])}{2r} = \alpha $$ I think it is the trickiest problem for studying Lebesgue measure Differentiability. Firstly, I came up with setting $E = [-\alpha r, \alpha r]$, but it does not meet the condition of ''fixed'' subset. It is so tricky that even my TA said this problem is ""hard as hell"". Anybody can suggest any idea? Thanks in advance.","Let $\alpha \in (0,1)$. Find a fixed Borel subset $E$ of $[-1,1]$ such that  $$ \lim_{r \rightarrow 0^+} \frac{m(E \cap [-r,r])}{2r} = \alpha $$ I think it is the trickiest problem for studying Lebesgue measure Differentiability. Firstly, I came up with setting $E = [-\alpha r, \alpha r]$, but it does not meet the condition of ''fixed'' subset. It is so tricky that even my TA said this problem is ""hard as hell"". Anybody can suggest any idea? Thanks in advance.",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
76,continuity of norms with respect to $p$,continuity of norms with respect to,p,"Let $f\in L^{\infty}(\Omega,\Sigma,\mu)\cap L^{1}(\Omega,\Sigma,\mu)$. Then $w(p)=||f||_p$ is continuous function of $p$ for any $p\in [1,\infty)$. How to prove this? I have obtained the proof that $\lim\limits_{p\to\infty}{||f||_p}=||f||_\infty$. But I do not know how to prove for an arbitrary real number in $[1,\infty)$.","Let $f\in L^{\infty}(\Omega,\Sigma,\mu)\cap L^{1}(\Omega,\Sigma,\mu)$. Then $w(p)=||f||_p$ is continuous function of $p$ for any $p\in [1,\infty)$. How to prove this? I have obtained the proof that $\lim\limits_{p\to\infty}{||f||_p}=||f||_\infty$. But I do not know how to prove for an arbitrary real number in $[1,\infty)$.",,"['measure-theory', 'normed-spaces', 'integral-inequality']"
77,"Example of Converge in measure, but not converge point-wise a.e.?","Example of Converge in measure, but not converge point-wise a.e.?",,"Can anyone give an exam of Converge in measure, but not converge point-wise a.e.? And also for the converse part, professor asks us to prove ""pointwise a.e. implies converge in measure"", but think about this function: $$f_n(x)= \chi_{[n,\infty)}$$ It converge to $f(x)=0$ pointwise, but it seems that the difference measure between $f(x)$ and $f_n(x)$ is always infinity.","Can anyone give an exam of Converge in measure, but not converge point-wise a.e.? And also for the converse part, professor asks us to prove ""pointwise a.e. implies converge in measure"", but think about this function: $$f_n(x)= \chi_{[n,\infty)}$$ It converge to $f(x)=0$ pointwise, but it seems that the difference measure between $f(x)$ and $f_n(x)$ is always infinity.",,"['real-analysis', 'measure-theory', 'convergence-divergence', 'examples-counterexamples']"
78,A question about the Hardy-Littlewood maximal function.,A question about the Hardy-Littlewood maximal function.,,"Somebody can to help me in the following question? Let $f$ be measurable in $\mathbb{R}^n$ and different from zero in some set of positive measure. Show that there is a positive constant с such that $f^*(x) \geq c |x|^{-n}$ for $|x| \geq 1$ Note: $f^*(x)$ is the Hardy-Littlewood maximal function, i.e., $\displaystyle{f^*(x) = \sup_{r>0} \; \frac{1}{|B_{r}(x)|}\; \int_{B_{r}(x)} \;|f(y)|\;dy}.$","Somebody can to help me in the following question? Let $f$ be measurable in $\mathbb{R}^n$ and different from zero in some set of positive measure. Show that there is a positive constant с such that $f^*(x) \geq c |x|^{-n}$ for $|x| \geq 1$ Note: $f^*(x)$ is the Hardy-Littlewood maximal function, i.e., $\displaystyle{f^*(x) = \sup_{r>0} \; \frac{1}{|B_{r}(x)|}\; \int_{B_{r}(x)} \;|f(y)|\;dy}.$",,"['real-analysis', 'measure-theory']"
79,Which definition of Haar measure is correct?,Which definition of Haar measure is correct?,,"I have encountered several different definitions of left Haar measure that don't all seem to agree. The setting I care about is Locally Compact Groups. The first seems to completely disagree with the other two with the regularity dispute. $\bf{\text{Which definition is correct? or are they all correct in different contexts?}}$ Let $G$ be a locally compact group, and by a measure I mean a Borel measure. $\bf{\text{Definition 1:}}$ On Wikipedia: http://en.wikipedia.org/wiki/Haar_measure A left Haar measure is a non-zero measure $\mu$ on $G$ such that (i) $\mu(K) < \infty$ for compact $K$ (ii) $\mu$ is left $G$-invariant (iii) $\mu$ is outer regular on Borel sets (iv) $\mu$ is inner regular on open Borel sets (And then an example is given to show that $\mu$ need not be inner regular on all Borel sets!) $\bf{\text{Definition 2:}}$ Supplied in an answer: Why are Haar measures finite on compact sets? A left Haar measure is a non-zero measure $\mu$ on $G$ such that (i) $\mu$ is regular (ii) $\mu > 0$ on open sets. (iii) $\mu < \infty$ on compact sets. (iv) $\mu$ is left $G$-invariant $\bf{\text{Definition 3:}}$ Given in an appendix to a book. A left Haar measure is a non-zero measure $\mu$ on $G$ such that (i) $\mu$ is regular (ii) $\mu$ is left $G$-invariant.","I have encountered several different definitions of left Haar measure that don't all seem to agree. The setting I care about is Locally Compact Groups. The first seems to completely disagree with the other two with the regularity dispute. $\bf{\text{Which definition is correct? or are they all correct in different contexts?}}$ Let $G$ be a locally compact group, and by a measure I mean a Borel measure. $\bf{\text{Definition 1:}}$ On Wikipedia: http://en.wikipedia.org/wiki/Haar_measure A left Haar measure is a non-zero measure $\mu$ on $G$ such that (i) $\mu(K) < \infty$ for compact $K$ (ii) $\mu$ is left $G$-invariant (iii) $\mu$ is outer regular on Borel sets (iv) $\mu$ is inner regular on open Borel sets (And then an example is given to show that $\mu$ need not be inner regular on all Borel sets!) $\bf{\text{Definition 2:}}$ Supplied in an answer: Why are Haar measures finite on compact sets? A left Haar measure is a non-zero measure $\mu$ on $G$ such that (i) $\mu$ is regular (ii) $\mu > 0$ on open sets. (iii) $\mu < \infty$ on compact sets. (iv) $\mu$ is left $G$-invariant $\bf{\text{Definition 3:}}$ Given in an appendix to a book. A left Haar measure is a non-zero measure $\mu$ on $G$ such that (i) $\mu$ is regular (ii) $\mu$ is left $G$-invariant.",,"['measure-theory', 'topological-groups']"
80,Calculate an integral in a measurable space,Calculate an integral in a measurable space,,"Let $(X,\mathcal{M})$ a measurable set with measure  $\mu$. Let $f$ be an integrable non negative function, such that $K:=\int_{E}f \mathrm d\mu<\infty$, where $E\in(X,\mathcal M)$. Let $\alpha>0$. Calculate the following integral $\displaystyle \lim_{n\rightarrow\infty}\int_{E} n \ln\left(1+\left(\frac{f}{n}\right)^{\alpha}\right)\mathrm{d}\mu$ I prove that for $\alpha=1$ the previous integral is $K$, and $\forall \alpha>1$ is zero. It follows by the identity $(1+x^{\alpha})\leq\alpha x$, $\forall x\geq0$ $\forall \alpha\geq1$. And the Dominated Convergence Theorem. But I don´t know how to take the case $0<\alpha<1$.     Thanks in advance! Suppose that $\alpha>1$. We take the sequece  $\{f_{n}\}_{n\in\mathbb N}$ of measurable functions, $f_{n}:=n\ln(1+(f/n)^{\alpha})$.  Moreover by the identity, for $\alpha>1$,   we have the following $|f_{n}|=\left|n\log\left(  1+\left(\frac{f}{n}\right)^{\alpha}\right) \right|\leq n \alpha\frac{f}{n}=\alpha f$,   $\alpha f$ is measurable. We need only to prove that$\{f_{n}\}_{n\in\mathbb N}$ converges pointwise to a function. In this case $f\equiv 0$    $\forall x\in Dom(f)$, $\displaystyle\lim_{n\rightarrow \infty}n\log\left(\left(\frac{f}{n}\right)^{\alpha}+1\right)=   \lim_{t\rightarrow 0}\frac{\log((ft)^{\alpha}+1)}{t}$.   Making the change of variables $t=\frac{1}{n}$. And by L'Hopital, it arises   $\lim_{t\rightarrow 0}\alpha f^{\alpha}    \frac{t^{\alpha-1}}{(ft)^{\alpha}+1}=0$. ($\alpha-1>0$). Finally, using the Dominated Convergence Theorem, it leads to $  \displaystyle\lim_{n\rightarrow \infty} \int f_{n}  \mathrm d \mu=\int 0 \mathrm d\mu =0$","Let $(X,\mathcal{M})$ a measurable set with measure  $\mu$. Let $f$ be an integrable non negative function, such that $K:=\int_{E}f \mathrm d\mu<\infty$, where $E\in(X,\mathcal M)$. Let $\alpha>0$. Calculate the following integral $\displaystyle \lim_{n\rightarrow\infty}\int_{E} n \ln\left(1+\left(\frac{f}{n}\right)^{\alpha}\right)\mathrm{d}\mu$ I prove that for $\alpha=1$ the previous integral is $K$, and $\forall \alpha>1$ is zero. It follows by the identity $(1+x^{\alpha})\leq\alpha x$, $\forall x\geq0$ $\forall \alpha\geq1$. And the Dominated Convergence Theorem. But I don´t know how to take the case $0<\alpha<1$.     Thanks in advance! Suppose that $\alpha>1$. We take the sequece  $\{f_{n}\}_{n\in\mathbb N}$ of measurable functions, $f_{n}:=n\ln(1+(f/n)^{\alpha})$.  Moreover by the identity, for $\alpha>1$,   we have the following $|f_{n}|=\left|n\log\left(  1+\left(\frac{f}{n}\right)^{\alpha}\right) \right|\leq n \alpha\frac{f}{n}=\alpha f$,   $\alpha f$ is measurable. We need only to prove that$\{f_{n}\}_{n\in\mathbb N}$ converges pointwise to a function. In this case $f\equiv 0$    $\forall x\in Dom(f)$, $\displaystyle\lim_{n\rightarrow \infty}n\log\left(\left(\frac{f}{n}\right)^{\alpha}+1\right)=   \lim_{t\rightarrow 0}\frac{\log((ft)^{\alpha}+1)}{t}$.   Making the change of variables $t=\frac{1}{n}$. And by L'Hopital, it arises   $\lim_{t\rightarrow 0}\alpha f^{\alpha}    \frac{t^{\alpha-1}}{(ft)^{\alpha}+1}=0$. ($\alpha-1>0$). Finally, using the Dominated Convergence Theorem, it leads to $  \displaystyle\lim_{n\rightarrow \infty} \int f_{n}  \mathrm d \mu=\int 0 \mathrm d\mu =0$",,['measure-theory']
81,Outer measure defined with rectangles,Outer measure defined with rectangles,,"I'm studying Measure Theory by myself and I would appreciate some guidance about my proof. My textbook constructs an outer measure as following: $$m_*(E)=\inf\sum_{k=1}^{\infty}|Q_k|$$ where the infimum is taken over all coverings of $E $ with closed cubes . In an exercise it asks to prove that the above definion, only with rectangles instead of cubes, will give rise to the same measure, i.e. I need to prove that: $$m_*(E)=\inf\sum_{k=1}^{\infty}|Q_k|=\inf\sum_{k=1}^{\infty}|R_k|=m_*^R(E)$$ where on the left the infimum is taken over covering with cubes, and on the right is taken over covering with rectangles. The fact that $m_*(E)\geq m_*^R(E)$ is obious. STEP 1 : When the infimum is taken only over ""rational"" rectangles, i.e. rectangles in which the ratio between all edges is rational, then each of these rectangles can be devided into a finitely many cubes and it follows that the infimum must be equal . STEP 2 : This is the step that I'm not sure about. What is left to prove that coverings with rational rectangles give rise to the same measure as covering with general rectangles. Let $\{R_j\}$ be a covering of $E$ with rectangles and let $\{R_j^*\}$ be the subseries of not rational rectangles in $\{R_j\}$. Then each $R_j^*$ can be extended to a rational rectangle $R_j^{**}$ so that  $|R_j^{**}|=|R_j^{*}|+\epsilon/2^j$. We remain with a covering of $E$ and thus: $$\inf \sum_{j=1}^{\infty}|R_j|=\inf\left(\sum_{rational\ rect.}|R_j|+\sum_{irrational\ rect.}|R_j^{*}|\right) = \inf\left(\sum_{rational\ rect.}|R_j|-\sum_{j=1^\ }^\infty\frac{\epsilon}{2^j}\right)$$ $$=\inf\left(\sum_{rational\ rect.}|R_j|\right)-\epsilon$$ And since $\epsilon$ is arbitrary the claim is proven. Is it correct? Thanks!","I'm studying Measure Theory by myself and I would appreciate some guidance about my proof. My textbook constructs an outer measure as following: $$m_*(E)=\inf\sum_{k=1}^{\infty}|Q_k|$$ where the infimum is taken over all coverings of $E $ with closed cubes . In an exercise it asks to prove that the above definion, only with rectangles instead of cubes, will give rise to the same measure, i.e. I need to prove that: $$m_*(E)=\inf\sum_{k=1}^{\infty}|Q_k|=\inf\sum_{k=1}^{\infty}|R_k|=m_*^R(E)$$ where on the left the infimum is taken over covering with cubes, and on the right is taken over covering with rectangles. The fact that $m_*(E)\geq m_*^R(E)$ is obious. STEP 1 : When the infimum is taken only over ""rational"" rectangles, i.e. rectangles in which the ratio between all edges is rational, then each of these rectangles can be devided into a finitely many cubes and it follows that the infimum must be equal . STEP 2 : This is the step that I'm not sure about. What is left to prove that coverings with rational rectangles give rise to the same measure as covering with general rectangles. Let $\{R_j\}$ be a covering of $E$ with rectangles and let $\{R_j^*\}$ be the subseries of not rational rectangles in $\{R_j\}$. Then each $R_j^*$ can be extended to a rational rectangle $R_j^{**}$ so that  $|R_j^{**}|=|R_j^{*}|+\epsilon/2^j$. We remain with a covering of $E$ and thus: $$\inf \sum_{j=1}^{\infty}|R_j|=\inf\left(\sum_{rational\ rect.}|R_j|+\sum_{irrational\ rect.}|R_j^{*}|\right) = \inf\left(\sum_{rational\ rect.}|R_j|-\sum_{j=1^\ }^\infty\frac{\epsilon}{2^j}\right)$$ $$=\inf\left(\sum_{rational\ rect.}|R_j|\right)-\epsilon$$ And since $\epsilon$ is arbitrary the claim is proven. Is it correct? Thanks!",,['measure-theory']
82,"Find f ae-differentiable with $f´\in L^1(0,1)$ but not in $BV$...",Find f ae-differentiable with  but not in ...,"f´\in L^1(0,1) BV","Here is a natural question which I didn't find in Measure Theory books: Construct a continuous function $f(x)$ in $[0,1]$ with derivative at ae $x\in(0,1)$, and so that $f'(x)\in L^1(0,1)$, but such that $f$ is not of bounded variation. The motivation would be the following: A well-known sufficient condition for absolute continuity asserts that if $f$ is continuous, $f'(x)$ exists for all $x\in(0,1)$ except a countable set, and $f'(x)\in L^1(0,1)$, then $f$ is absolutely continuous (hence $f\in BV$). In this theorem, ""countable set"" cannot be replaced by ""null set"", as the Cantor staircase shows. Is this also the case if we just want $f\in BV(0,1)$? Some observations about temptative constructions: (i) Cantor staicases alone would not work, since they are increasing, hence $BV$... (ii) Volterra type constructions, which fill the complement of a Cantor set with  blocks $x^a \sin(x^{-b})$ are not good either. For the derivatives of these blocks to be in $L^1$ one needs $a>b$, but then blocks are in $BV$, and probably also the resulting function... Are there other natural examples to test with?","Here is a natural question which I didn't find in Measure Theory books: Construct a continuous function $f(x)$ in $[0,1]$ with derivative at ae $x\in(0,1)$, and so that $f'(x)\in L^1(0,1)$, but such that $f$ is not of bounded variation. The motivation would be the following: A well-known sufficient condition for absolute continuity asserts that if $f$ is continuous, $f'(x)$ exists for all $x\in(0,1)$ except a countable set, and $f'(x)\in L^1(0,1)$, then $f$ is absolutely continuous (hence $f\in BV$). In this theorem, ""countable set"" cannot be replaced by ""null set"", as the Cantor staircase shows. Is this also the case if we just want $f\in BV(0,1)$? Some observations about temptative constructions: (i) Cantor staicases alone would not work, since they are increasing, hence $BV$... (ii) Volterra type constructions, which fill the complement of a Cantor set with  blocks $x^a \sin(x^{-b})$ are not good either. For the derivatives of these blocks to be in $L^1$ one needs $a>b$, but then blocks are in $BV$, and probably also the resulting function... Are there other natural examples to test with?",,"['real-analysis', 'measure-theory', 'bounded-variation']"
83,Differentiability of convolution,Differentiability of convolution,,"First let me say that I have used the search bar and looked through all the ""differentiability of convolution"" questions that I saw, but none of them seem to cover this case. (If one of them did and I missed it, of course please post the link and I will look more closely). Suppose $h\in L^\infty(\mathbb{R})$. How nice does $g$ have to be in order to guarantee that $h * g \in C^1(\mathbb{R})$? In my particular situation $g$ is a Schwartz function, infinitely differentiable and all of its derivatives decay faster than any polynomial, and $h$ is continuous and bounded. I know that if $h \in L^p$ for $p<\infty$ then $f *g \in C^\infty$, and I know it works if $g$ is compactly supported, but in my case neither of these two hold. All I have is that $h$ is continuous and bounded, and $g$ is Schwartz. EDIT: $h*g$ being differentiable almost everywhere would actually suffice for my purposes. EDIT2: More specifically,  $g(x) = e^{-x^2}$.","First let me say that I have used the search bar and looked through all the ""differentiability of convolution"" questions that I saw, but none of them seem to cover this case. (If one of them did and I missed it, of course please post the link and I will look more closely). Suppose $h\in L^\infty(\mathbb{R})$. How nice does $g$ have to be in order to guarantee that $h * g \in C^1(\mathbb{R})$? In my particular situation $g$ is a Schwartz function, infinitely differentiable and all of its derivatives decay faster than any polynomial, and $h$ is continuous and bounded. I know that if $h \in L^p$ for $p<\infty$ then $f *g \in C^\infty$, and I know it works if $g$ is compactly supported, but in my case neither of these two hold. All I have is that $h$ is continuous and bounded, and $g$ is Schwartz. EDIT: $h*g$ being differentiable almost everywhere would actually suffice for my purposes. EDIT2: More specifically,  $g(x) = e^{-x^2}$.",,"['measure-theory', 'convolution']"
84,Sard's theorem for absolutely continuous function,Sard's theorem for absolutely continuous function,,"Can anyone help me proving Sard's theorem where $ f $ is a real valued absolutely continuous function on $ [a,b] $ that is to prove $ f(A) $ is measure zero where $$ A = \{x\in [a,b]\ |\ f'(x) = 0 \}$$  I need to use the definition of absolute continuity of real functions using estimates on sum and possibly properties like $f$ being differentiable a.e , $ f' \in L^1 $ and validity of fundamental theorem of calculus. I can't figure out ways to replicate or generalize the proof for continuously differentiable functions.","Can anyone help me proving Sard's theorem where $ f $ is a real valued absolutely continuous function on $ [a,b] $ that is to prove $ f(A) $ is measure zero where $$ A = \{x\in [a,b]\ |\ f'(x) = 0 \}$$  I need to use the definition of absolute continuity of real functions using estimates on sum and possibly properties like $f$ being differentiable a.e , $ f' \in L^1 $ and validity of fundamental theorem of calculus. I can't figure out ways to replicate or generalize the proof for continuously differentiable functions.",,"['calculus', 'real-analysis', 'measure-theory']"
85,What does it mean $\int_a^b f(G(x)) dG(x)$? - An exercise question on measure theory,What does it mean ? - An exercise question on measure theory,\int_a^b f(G(x)) dG(x),"I am reading Folland's book and definitions are as follows (p. 108). Let $G$ be a continuous increasing function on $[a,b]$ and let $G(a) = c, G(b) = d$. What is asked in the question is: If $f$ is a Borel measurable and integrable function on $[c,d]$, then $\int_c^d f(y)dy = \int_a^b f(G(x))dG(x)$. In particular, $\int_c^d f(y) dy = \int_a^b f(G(x))G'(x)dx$ if $G$ is absolutely continuous. As you can see from the title, I did not understand what does it mean $\int_a^b f(G(x))dG(x)$. Also, I am stuck on the whole exercise. If one can help, I will be very happy! Thanks.","I am reading Folland's book and definitions are as follows (p. 108). Let $G$ be a continuous increasing function on $[a,b]$ and let $G(a) = c, G(b) = d$. What is asked in the question is: If $f$ is a Borel measurable and integrable function on $[c,d]$, then $\int_c^d f(y)dy = \int_a^b f(G(x))dG(x)$. In particular, $\int_c^d f(y) dy = \int_a^b f(G(x))G'(x)dx$ if $G$ is absolutely continuous. As you can see from the title, I did not understand what does it mean $\int_a^b f(G(x))dG(x)$. Also, I am stuck on the whole exercise. If one can help, I will be very happy! Thanks.",,['real-analysis']
86,Do the Baire Sets of $\mathbb{R}$ contain the Borel Sets of $\mathbb{R}$?,Do the Baire Sets of  contain the Borel Sets of ?,\mathbb{R} \mathbb{R},"I'm trying to gain some intuitive characterization of the Baire subsets of $\mathbb{R}$.  I've seen different definitions of Baire subsets (which I presume are equivalent) but here is a characterization from Royden: The Baire subsets of $X$ (denoted $\mathcal{B}$) are equivalent to the smallest $\sigma$-algebra generated by $\{G_\delta\}$ where $G_\delta$ is a countable intersection of open subsets of $X$. If $X = \mathbb{R}$, wouldn't then $\mathcal{B}$ contain the Borel subsets of $\mathbb{R}$ since any open set $O \subseteq \mathbb{R}$ is also a $G_\delta$ so that since the open sets of $\mathbb{R}$ generate the Borel Sets of $\mathbb{R}$, then $\mathcal{B}$ would at least contain the Borel subsets of $\mathbb{R}$?","I'm trying to gain some intuitive characterization of the Baire subsets of $\mathbb{R}$.  I've seen different definitions of Baire subsets (which I presume are equivalent) but here is a characterization from Royden: The Baire subsets of $X$ (denoted $\mathcal{B}$) are equivalent to the smallest $\sigma$-algebra generated by $\{G_\delta\}$ where $G_\delta$ is a countable intersection of open subsets of $X$. If $X = \mathbb{R}$, wouldn't then $\mathcal{B}$ contain the Borel subsets of $\mathbb{R}$ since any open set $O \subseteq \mathbb{R}$ is also a $G_\delta$ so that since the open sets of $\mathbb{R}$ generate the Borel Sets of $\mathbb{R}$, then $\mathcal{B}$ would at least contain the Borel subsets of $\mathbb{R}$?",,"['real-analysis', 'measure-theory', 'descriptive-set-theory']"
87,Product of Borel $\sigma$-algebras?,Product of Borel -algebras?,\sigma,"I just have a quick question about the Borel sigma algebra $B$ . $B$ is, of course, a sigma algebra, and we also know that $B$ contains all open sets, and that it is as small as possible. I am wondering if the space $B \times B$ has the same properties? I am not sure if this is the case, but I am starting to think not.","I just have a quick question about the Borel sigma algebra . is, of course, a sigma algebra, and we also know that contains all open sets, and that it is as small as possible. I am wondering if the space has the same properties? I am not sure if this is the case, but I am starting to think not.",B B B B \times B,['measure-theory']
88,Poincaré Inequality - Product Of Measures,Poincaré Inequality - Product Of Measures,,"I'm given two euclidean spaces $ \mathbb{R}_1 , \mathbb{R}_2 $ , with probability measures on them , that satisfy the Poincaré's inequality: $ \lambda^2 \int_{\mathbb{R}^k} |f - \int_{\mathbb{R}^k} f d\mu | ^2 d\mu \leq \int_{\mathbb{R}^k} | \nabla f | ^2 d\mu $ for some constants $C_1 , C_2 $ respectively. How can I prove that the space $ (\mathbb{R}_1 \times \mathbb{R}_2 , \mu_1 \otimes \mu_2 )$ also satisfies the Poincaré inequality? Thanks in advance ! My attempt: denote: $ g(x) = \int_{\mathbb{R}_2 } f(x,y) d\mu_2  $ . We can then apply the inequality in order to get that: $$ C_1 ^2 \cdot \int_{\mathbb{R}_1 } \left| \int_{\mathbb{R}_2} f(x,y) d\mu_2 - \int_{\mathbb{R}_1} \int_{\mathbb{R}_2} f(x,y) d\mu_2 d\mu_1 \right| ^2 d\mu_1  \leq \int_{\mathbb{R_1}} \left| \nabla \int_{\mathbb{R}_2} f(x,y) d\mu_2 \right|^2 d\mu_1 $$ and we can even say that the RHS is  $ \leq \int_{\mathbb{R}_1 }  \int_{\mathbb{R}_2 } | \nabla f | ^2 d\mu_1 d\mu_2$ where our function is nice enough...But how can I finish the proof?","I'm given two euclidean spaces $ \mathbb{R}_1 , \mathbb{R}_2 $ , with probability measures on them , that satisfy the Poincaré's inequality: $ \lambda^2 \int_{\mathbb{R}^k} |f - \int_{\mathbb{R}^k} f d\mu | ^2 d\mu \leq \int_{\mathbb{R}^k} | \nabla f | ^2 d\mu $ for some constants $C_1 , C_2 $ respectively. How can I prove that the space $ (\mathbb{R}_1 \times \mathbb{R}_2 , \mu_1 \otimes \mu_2 )$ also satisfies the Poincaré inequality? Thanks in advance ! My attempt: denote: $ g(x) = \int_{\mathbb{R}_2 } f(x,y) d\mu_2  $ . We can then apply the inequality in order to get that: $$ C_1 ^2 \cdot \int_{\mathbb{R}_1 } \left| \int_{\mathbb{R}_2} f(x,y) d\mu_2 - \int_{\mathbb{R}_1} \int_{\mathbb{R}_2} f(x,y) d\mu_2 d\mu_1 \right| ^2 d\mu_1  \leq \int_{\mathbb{R_1}} \left| \nabla \int_{\mathbb{R}_2} f(x,y) d\mu_2 \right|^2 d\mu_1 $$ and we can even say that the RHS is  $ \leq \int_{\mathbb{R}_1 }  \int_{\mathbb{R}_2 } | \nabla f | ^2 d\mu_1 d\mu_2$ where our function is nice enough...But how can I finish the proof?",,"['measure-theory', 'inequality', 'sobolev-spaces']"
89,A Question on Convergence In $L^p$ [duplicate],A Question on Convergence In  [duplicate],L^p,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Convergence of integrals in $L^p$ Let $\{f_n\}$ be sequence of functions in $L^p$, $1\lt p \lt \infty$, which converge a.e. to a function $f\in L^p$. Suppose that there is a $M$ such that $\|f_n\| \leq M$ for all $n$. Then I would like to show that for each function $g\in L^q$ we have $$ \int fg = \lim \int f_ng.$$ Would the result hold true if $p =1$? My Attempt: I want to show $\left|\int (f_ng-fg)\right|\lt \varepsilon.$  I observe that $$\left|\int (f_ng-fg)\right| \lt \int \left| f_n-f\right||g| \leq \|f_n-f\|_p \|g\|_q,$$ and $$\|f_n-f\|_{L^p(E)}\leq M + \|f\|_{L^p(E)}.$$ Since $g\in L^q$,for every $\varepsilon \gt 0,\exists \delta \gt 0$ such if $\mu(E)\lt \delta$, $$ \|g\| = \left(\int _E |g|^q\right)^{1/q} \lt \frac{\varepsilon}{2\left(M + \|f\|_{L^p(E)}\right)}.$$ I can also call on Egoroff, to find a set $E$ of measure less that $\varepsilon$ such $f_n$ converges uniformly on $E^c$. Thus for some $n\gt N$, $$|f_n-f| \lt \frac{\varepsilon}{2(\mu(E^c))^{1/p}\|g\|_{L^q(E)}},$$ so that $$\|f_n-f\|_{L^p(E^c)} \lt \frac{\varepsilon}{2\|g\|_{L^q(E^c)}}.$$ Thus, $$ \begin{align*} \|f_n-f\|_p \|g\|_q & = \|f_n-f\|_{L^p(E)}\|g\|_{L^q(E)} + \|f_n-f\|_{L^p(E^c)}\|g\|_{L^q(E^c)}  \\ & \leq  \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon. \end{align*} $$ Please, is what I've done okay. I welcome criticisms and corrections. Thanks. I also need help with the case $p=1$. PS: This is not homework. It's a question in Royden's third edition, Chapter six.","This question already has answers here : Closed 12 years ago . Possible Duplicate: Convergence of integrals in $L^p$ Let $\{f_n\}$ be sequence of functions in $L^p$, $1\lt p \lt \infty$, which converge a.e. to a function $f\in L^p$. Suppose that there is a $M$ such that $\|f_n\| \leq M$ for all $n$. Then I would like to show that for each function $g\in L^q$ we have $$ \int fg = \lim \int f_ng.$$ Would the result hold true if $p =1$? My Attempt: I want to show $\left|\int (f_ng-fg)\right|\lt \varepsilon.$  I observe that $$\left|\int (f_ng-fg)\right| \lt \int \left| f_n-f\right||g| \leq \|f_n-f\|_p \|g\|_q,$$ and $$\|f_n-f\|_{L^p(E)}\leq M + \|f\|_{L^p(E)}.$$ Since $g\in L^q$,for every $\varepsilon \gt 0,\exists \delta \gt 0$ such if $\mu(E)\lt \delta$, $$ \|g\| = \left(\int _E |g|^q\right)^{1/q} \lt \frac{\varepsilon}{2\left(M + \|f\|_{L^p(E)}\right)}.$$ I can also call on Egoroff, to find a set $E$ of measure less that $\varepsilon$ such $f_n$ converges uniformly on $E^c$. Thus for some $n\gt N$, $$|f_n-f| \lt \frac{\varepsilon}{2(\mu(E^c))^{1/p}\|g\|_{L^q(E)}},$$ so that $$\|f_n-f\|_{L^p(E^c)} \lt \frac{\varepsilon}{2\|g\|_{L^q(E^c)}}.$$ Thus, $$ \begin{align*} \|f_n-f\|_p \|g\|_q & = \|f_n-f\|_{L^p(E)}\|g\|_{L^q(E)} + \|f_n-f\|_{L^p(E^c)}\|g\|_{L^q(E^c)}  \\ & \leq  \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon. \end{align*} $$ Please, is what I've done okay. I welcome criticisms and corrections. Thanks. I also need help with the case $p=1$. PS: This is not homework. It's a question in Royden's third edition, Chapter six.",,"['real-analysis', 'measure-theory']"
90,Signed Measures,Signed Measures,,"Let $\mu$ be a positive measure, $f$ be an extended $\mu$-integrable function. Define the set function $\nu$ on $\mathcal{M}$ by $$ \nu(E):=\int_E f~\text{d}\mu\qquad E\in \mathcal{M}.$$  I need assistance in showing that $\nu$ is signed measure.","Let $\mu$ be a positive measure, $f$ be an extended $\mu$-integrable function. Define the set function $\nu$ on $\mathcal{M}$ by $$ \nu(E):=\int_E f~\text{d}\mu\qquad E\in \mathcal{M}.$$  I need assistance in showing that $\nu$ is signed measure.",,['measure-theory']
91,On atomic and atomless subsets,On atomic and atomless subsets,,"In a measure space, let's call a measurable subset atomless wrt the measure, if it does not have an atomic subset . In particular a measurable subset with zero measure is atomless. There may be measurable subsets that are neither atomic nor atomless, for instance, the union of atomic subset(s) and atomless subset(s) with positive measure(s). I was wondering if the converse is true, i.e. if a measurable subset is neither atomic nor atomless, then must it be the union of atomic subset(s) and atomless subset(s) with positive measure(s)? I think the previous question is equivalent to whether any measurable subset can be partitioned into atomic subset(s) and atomless subset(s)? Thanks and regards!","In a measure space, let's call a measurable subset atomless wrt the measure, if it does not have an atomic subset . In particular a measurable subset with zero measure is atomless. There may be measurable subsets that are neither atomic nor atomless, for instance, the union of atomic subset(s) and atomless subset(s) with positive measure(s). I was wondering if the converse is true, i.e. if a measurable subset is neither atomic nor atomless, then must it be the union of atomic subset(s) and atomless subset(s) with positive measure(s)? I think the previous question is equivalent to whether any measurable subset can be partitioned into atomic subset(s) and atomless subset(s)? Thanks and regards!",,['measure-theory']
92,A differentiation almost everywhere problem,A differentiation almost everywhere problem,,"Let $f: \mathbb R \to \mathbb R$ be a continuous function, and there exists a $k>0$ such that for each $y \in \mathbb R$, there are at most $k$ distinct $x$ with $f(x)=y$. Prove that $f$ is differentiable a.e. My approach is trying to show $f$ is absolutly continuous, but need a hint to make a start. Thanks.","Let $f: \mathbb R \to \mathbb R$ be a continuous function, and there exists a $k>0$ such that for each $y \in \mathbb R$, there are at most $k$ distinct $x$ with $f(x)=y$. Prove that $f$ is differentiable a.e. My approach is trying to show $f$ is absolutly continuous, but need a hint to make a start. Thanks.",,"['real-analysis', 'measure-theory']"
93,Integrable function $f$ on $\mathbb R$ does not imply that limit $f(x)$ is zero,Integrable function  on  does not imply that limit  is zero,f \mathbb R f(x),"1) Construct a continuous function $f$ on $\mathbb{R}$ that is integrable on $\mathbb{R}$ but $\displaystyle\limsup_{x \to \infty} f(x)  = \infty$. I took the function that is equal to $n$ on $[n, n + 1/n^{3})$ and made it continuous by saying that $f$ is the line segment joining $n$ and $n+1$ on $[n + 1/n^{3}, n+1)$. But I am failing to prove this integrable. For this, $\lim f(x) = \infty$ but how do you prove in general, if limit does not exist that $\limsup$ is infinity? 2) Prove that if $f$ is uniformly continuous and integrable on $\mathbb{R}$ we have $\displaystyle\lim_{|x| \to \infty} f(x) = 0$. Any help is appreciated. Thanks","1) Construct a continuous function $f$ on $\mathbb{R}$ that is integrable on $\mathbb{R}$ but $\displaystyle\limsup_{x \to \infty} f(x)  = \infty$. I took the function that is equal to $n$ on $[n, n + 1/n^{3})$ and made it continuous by saying that $f$ is the line segment joining $n$ and $n+1$ on $[n + 1/n^{3}, n+1)$. But I am failing to prove this integrable. For this, $\lim f(x) = \infty$ but how do you prove in general, if limit does not exist that $\limsup$ is infinity? 2) Prove that if $f$ is uniformly continuous and integrable on $\mathbb{R}$ we have $\displaystyle\lim_{|x| \to \infty} f(x) = 0$. Any help is appreciated. Thanks",,"['real-analysis', 'measure-theory']"
94,"$\lim\int_{E_i}f = \int_{E}f$ when $\lim d(E_i , E) = 0$",when,"\lim\int_{E_i}f = \int_{E}f \lim d(E_i , E) = 0","Another question in my studies (of Lebesgue integration): I'm given a continuous function $f:\mathbb{R}\to\mathbb{R}$, a nonempty compact set $E\subseteq\mathbb{R}$, and a sequence of nonempty compact sets $E_i$ such that $$\lim d(E_i , E) = 0$$where this $d$ is Hausdorff distance . I am asked to prove that $$\lim \int_{E_i} f=\int_E f$$ Visually, this seems pretty straightforward, the $E_i$ are being forced to look more and more like $E$, and the continuity of $f$ ensures that the farther along the $E_i$ we pick, $f$ has to vary less and less where $E_i$ and $E$ don't coincide. I've been at this for a while and seem to be stuck.  For a while though I hadn't noticed the compactness assumed of $E$ and the $E_i$.  Putting the continuity and convergence in Hausdorff distance together, I see that for any $x\in E$, $\varepsilon>0$, and $\delta > 0$, there is eventually some $E_i$ for which I can find a $y\in E_i$ within $\delta$ of $x$ and with $|f(x)-f(y)|<\varepsilon$.  I guess using compactness, I can make this uniform over all $x\in E$ (so that my picture described above is actually as nicely behaved as I was probably picturing it to begin with). At this point though I'm not sure how to proceed.  Should I try to bound the integral over the symmetric difference of $E_i$ and $E$ or something like that?  I'm not sure how I would control it, despite knowing it would be constrained somehow by ""nearby"" values of $f$.  Should I cut up $E$ somehow, or select some dense subset of $E$ to use representative values of $f$ on?  Is there some subtlety my visual intuition is overlooking? Added It seems like there is a counterexample to this theorem as stated: Let $E=[0,1]$ and let $E_i = \{ k 2^{-i} : k=0,1,\dots,2^i \}$ so that $$\array{ E_1 & = & \{0,\frac{1}{2}, 1\} \\ E_2 & = & \{0,\frac{1}{4}, \frac{2}{4}, \frac{3}{4}, 1\} \\ & \vdots }$$ Then, for example, with $f$ taken to be the constant $1$ function on $[0,1]$, we have $\int_{E_i} f = 0$ for all $i$, yet $\int_{E} f = 1$.","Another question in my studies (of Lebesgue integration): I'm given a continuous function $f:\mathbb{R}\to\mathbb{R}$, a nonempty compact set $E\subseteq\mathbb{R}$, and a sequence of nonempty compact sets $E_i$ such that $$\lim d(E_i , E) = 0$$where this $d$ is Hausdorff distance . I am asked to prove that $$\lim \int_{E_i} f=\int_E f$$ Visually, this seems pretty straightforward, the $E_i$ are being forced to look more and more like $E$, and the continuity of $f$ ensures that the farther along the $E_i$ we pick, $f$ has to vary less and less where $E_i$ and $E$ don't coincide. I've been at this for a while and seem to be stuck.  For a while though I hadn't noticed the compactness assumed of $E$ and the $E_i$.  Putting the continuity and convergence in Hausdorff distance together, I see that for any $x\in E$, $\varepsilon>0$, and $\delta > 0$, there is eventually some $E_i$ for which I can find a $y\in E_i$ within $\delta$ of $x$ and with $|f(x)-f(y)|<\varepsilon$.  I guess using compactness, I can make this uniform over all $x\in E$ (so that my picture described above is actually as nicely behaved as I was probably picturing it to begin with). At this point though I'm not sure how to proceed.  Should I try to bound the integral over the symmetric difference of $E_i$ and $E$ or something like that?  I'm not sure how I would control it, despite knowing it would be constrained somehow by ""nearby"" values of $f$.  Should I cut up $E$ somehow, or select some dense subset of $E$ to use representative values of $f$ on?  Is there some subtlety my visual intuition is overlooking? Added It seems like there is a counterexample to this theorem as stated: Let $E=[0,1]$ and let $E_i = \{ k 2^{-i} : k=0,1,\dots,2^i \}$ so that $$\array{ E_1 & = & \{0,\frac{1}{2}, 1\} \\ E_2 & = & \{0,\frac{1}{4}, \frac{2}{4}, \frac{3}{4}, 1\} \\ & \vdots }$$ Then, for example, with $f$ taken to be the constant $1$ function on $[0,1]$, we have $\int_{E_i} f = 0$ for all $i$, yet $\int_{E} f = 1$.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
95,About the integrability of function,About the integrability of function,,"Let $f$ is integrable function on $[0,1]$. Define $g(x)=\int_x^b\frac{f(t)}{t}dt$ for $0<x\leq 1$ and $g(0)=0$. How can I show that $g(x)$ is integrable?","Let $f$ is integrable function on $[0,1]$. Define $g(x)=\int_x^b\frac{f(t)}{t}dt$ for $0<x\leq 1$ and $g(0)=0$. How can I show that $g(x)$ is integrable?",,['measure-theory']
96,Existence of a measure that preserves a given mapping,Existence of a measure that preserves a given mapping,,"Let $(X, d)$ be a compact metric space and let $T:X \to X$ be a continuous mapping. Now, does there exist a probability measure $\nu$ such that $T_* \nu = \nu$ (the first thing is the image measure)? Now I want to do this using a fixed-point theorem. So I start like this: Define the operator $\psi_T$ from $C(X)$ into itself by $\psi_T f = f \circ T$. Now we also know that $C(X)^* = P(X)$ where $P(X)$ are the Borel probability measures on $X$. So we have a mapping $\psi_T^* : P(X) \to P(X)$. Further we have that: $$\langle f, \underbrace{\psi_T^* \mu}_{= \nu} \rangle = \langle \psi_T f, \mu \rangle = \int f \circ T \, d\mu.$$ And $\nu$ is completely determined by $$\int f \, d\nu = \int f \circ T \, d\mu$$ Further, since $X$ is compact I know that $P(X)$ is compact (hence complete) with respect to the Bounded Lipschitz metric. This one is given by $$d_\text{BL}(\mu, \nu) := \sup \left \{ \left | \int f \, d\mu - \int f \, d\nu \right | : f \in \text{BL}(X,d), \|f\|_\text{BL} \leq 1 \right \}.$$ So everything is fine for the Banach fixed point theorem except one thing: is $d_\text{BL}$ a contraction? I don't think so. Does someone have an idea if I'm on the right track or does someone have a suggestion how to continue? By the way, this is homework.","Let $(X, d)$ be a compact metric space and let $T:X \to X$ be a continuous mapping. Now, does there exist a probability measure $\nu$ such that $T_* \nu = \nu$ (the first thing is the image measure)? Now I want to do this using a fixed-point theorem. So I start like this: Define the operator $\psi_T$ from $C(X)$ into itself by $\psi_T f = f \circ T$. Now we also know that $C(X)^* = P(X)$ where $P(X)$ are the Borel probability measures on $X$. So we have a mapping $\psi_T^* : P(X) \to P(X)$. Further we have that: $$\langle f, \underbrace{\psi_T^* \mu}_{= \nu} \rangle = \langle \psi_T f, \mu \rangle = \int f \circ T \, d\mu.$$ And $\nu$ is completely determined by $$\int f \, d\nu = \int f \circ T \, d\mu$$ Further, since $X$ is compact I know that $P(X)$ is compact (hence complete) with respect to the Bounded Lipschitz metric. This one is given by $$d_\text{BL}(\mu, \nu) := \sup \left \{ \left | \int f \, d\mu - \int f \, d\nu \right | : f \in \text{BL}(X,d), \|f\|_\text{BL} \leq 1 \right \}.$$ So everything is fine for the Banach fixed point theorem except one thing: is $d_\text{BL}$ a contraction? I don't think so. Does someone have an idea if I'm on the right track or does someone have a suggestion how to continue? By the way, this is homework.",,['measure-theory']
97,Nonmeasurable set with positive outer measure,Nonmeasurable set with positive outer measure,,"It is well-known that any set $E \subseteq \mathbb{R}$ with positive outer measure contains a nonmeasurable subset $V$. I know that $0 < m^*(V) \le m^*(E)$. Nevertheless, my question is the following: given $r \in \mathbb{R}$ such that $r>0$, is there a nonmeasurable subset of $\mathbb{R}$ whose outer measure is exactly $r$? Thank you in advance.","It is well-known that any set $E \subseteq \mathbb{R}$ with positive outer measure contains a nonmeasurable subset $V$. I know that $0 < m^*(V) \le m^*(E)$. Nevertheless, my question is the following: given $r \in \mathbb{R}$ such that $r>0$, is there a nonmeasurable subset of $\mathbb{R}$ whose outer measure is exactly $r$? Thank you in advance.",,"['measure-theory', 'examples-counterexamples']"
98,Question in the proof of the Riesz Representation theorem of non-negative functionals in geometric measure theory written by Leon Simon,Question in the proof of the Riesz Representation theorem of non-negative functionals in geometric measure theory written by Leon Simon,,"The problem is from the proof of Theorem 1.5.12 in Leon Simon's book: Geometric Measure Theory Suppose $X$ is a locally compact Hausdorff space, $\mathcal{K}^{+}$ is the set of all non-negative continuous functions on $X$ with compact support, $\lambda:\mathcal{K}^{+}\to [0,\infty)$ is linear. $U$ open in $X$ , $K$ compact in $X$ , $A\subset X$ . we define $$\mu(U)=\sup\{\lambda(f):f\in\mathcal{K}^{+},f\leq 1,supp(f)\subset U\}$$ $$\mu(A)=\inf\{\mu(U):U\mbox{ open},U\supset A\}$$ Prove that $\mu(U) = \sup\{\mu(K):K\mbox{ compact}$ , $K\subset U\}$ . In Leon Simon's book, the proof of this statement is too short to understand, so I was looking for clearer and more rigorous proof. Obviously LHS $\geq$ RHS, however I cannot prove the equality. Any help will be appreciated.","The problem is from the proof of Theorem 1.5.12 in Leon Simon's book: Geometric Measure Theory Suppose is a locally compact Hausdorff space, is the set of all non-negative continuous functions on with compact support, is linear. open in , compact in , . we define Prove that , . In Leon Simon's book, the proof of this statement is too short to understand, so I was looking for clearer and more rigorous proof. Obviously LHS RHS, however I cannot prove the equality. Any help will be appreciated.","X \mathcal{K}^{+} X \lambda:\mathcal{K}^{+}\to [0,\infty) U X K X A\subset X \mu(U)=\sup\{\lambda(f):f\in\mathcal{K}^{+},f\leq 1,supp(f)\subset U\} \mu(A)=\inf\{\mu(U):U\mbox{ open},U\supset A\} \mu(U) = \sup\{\mu(K):K\mbox{ compact} K\subset U\} \geq","['real-analysis', 'measure-theory', 'geometric-measure-theory', 'riesz-representation-theorem']"
99,Revisited question Lebesgue Measure of Symmetric Difference is 0,Revisited question Lebesgue Measure of Symmetric Difference is 0,,"Following this question: Dudley Section 3.4, Problem 1: Lebesgue Measure of Symmetric Difference is 0 Let E be a Lebesgue measurable set, such that for all $x$ in a dense subset of $\mathbb{R}$ , $m(E\Delta (E+x)) =0$ . Show that either $m (E)$ or $m(\mathbb{R}/E) =0$ . I did not understand the first answer in this question. Can anyone add some details for that answer? Or another approach.. Proof: I try to use the contradiction by following two results from For a set of positive measure there is an interval in which its density is high, $\mu(E\cap I)> \rho \mu(I)$ : Let $E$ be Lebesgue measurable, with $\mu(E)>0$ (here $\mu$ denotes the Lebesgue measure). Then: for any $0<\rho<1$ , there exists an open interval $I$ such that $\mu(E \cap I)> \rho \cdot \mu(I)$ . the set $E-E = \{x-y : x, y \in E\}$ contains an (open) interval centered at $0$ (in particular, if $\rho > 3/4$ , the text I am using suggests that $(-\frac{1}{2} \mu(I), \frac{1}{2}\mu(I)) \subseteq E-E$ ). Now, suppose that $m(E)>0$ and $m(E^c)>0$ . Then for $\rho=\frac{3}{4}$ so that there is $I_1$ with $$ \mu(E\cap I_1)>\frac{3}{4}\mu(I_1) $$ and apply the result to $E^c$ to get there is a interval $I_2$ so that $$ \mu(E\cap I_2)<\frac{1}{4}\mu(I_2) $$ Then by the second result, we have there is an open interval so that $$ (-0.5m(I_1), 0.5m(I_2))\subset E-E $$ and $$ (-0.5m(I_2), 0.5m(I_2))\subset E^c-E^c. $$ Since $m(E\Delta (E+q))=0$ (i.e., $E=E^c$ a.e.), then for $E\cap (I_1\cup I_2)$ we have $$ E\cap (I_1\cup I_2)=(E+q)\cap (I_1\cup I_2) a.e. $$ Thus, $m(E\cap (I_1\cup I_2))=m((E+q)\cap (I_1\cup I_2))$ Then for $x\in (-0.5m(I_1), 0.5m(I_2))$ , we have $x=a-b$ for some $a, b\in E$ , and for $y\in (-0.5m(I_2), 0.5m(I_2))$ , we have $y=c-d$ for some $c,d \in E^c$ .","Following this question: Dudley Section 3.4, Problem 1: Lebesgue Measure of Symmetric Difference is 0 Let E be a Lebesgue measurable set, such that for all in a dense subset of , . Show that either or . I did not understand the first answer in this question. Can anyone add some details for that answer? Or another approach.. Proof: I try to use the contradiction by following two results from For a set of positive measure there is an interval in which its density is high, $\mu(E\cap I)> \rho \mu(I)$ : Let be Lebesgue measurable, with (here denotes the Lebesgue measure). Then: for any , there exists an open interval such that . the set contains an (open) interval centered at (in particular, if , the text I am using suggests that ). Now, suppose that and . Then for so that there is with and apply the result to to get there is a interval so that Then by the second result, we have there is an open interval so that and Since (i.e., a.e.), then for we have Thus, Then for , we have for some , and for , we have for some .","x \mathbb{R} m(E\Delta (E+x)) =0 m (E) m(\mathbb{R}/E) =0 E \mu(E)>0 \mu 0<\rho<1 I \mu(E \cap I)> \rho \cdot \mu(I) E-E = \{x-y : x, y \in E\} 0 \rho > 3/4 (-\frac{1}{2} \mu(I), \frac{1}{2}\mu(I)) \subseteq E-E m(E)>0 m(E^c)>0 \rho=\frac{3}{4} I_1 
\mu(E\cap I_1)>\frac{3}{4}\mu(I_1)
 E^c I_2 
\mu(E\cap I_2)<\frac{1}{4}\mu(I_2)
 
(-0.5m(I_1), 0.5m(I_2))\subset E-E
 
(-0.5m(I_2), 0.5m(I_2))\subset E^c-E^c.
 m(E\Delta (E+q))=0 E=E^c E\cap (I_1\cup I_2) 
E\cap (I_1\cup I_2)=(E+q)\cap (I_1\cup I_2) a.e.
 m(E\cap (I_1\cup I_2))=m((E+q)\cap (I_1\cup I_2)) x\in (-0.5m(I_1), 0.5m(I_2)) x=a-b a, b\in E y\in (-0.5m(I_2), 0.5m(I_2)) y=c-d c,d \in E^c","['real-analysis', 'measure-theory']"
