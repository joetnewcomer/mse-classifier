,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,A Neat Identity Involving Zeta Zeroes,A Neat Identity Involving Zeta Zeroes,,"While playing around, I encountered the following very curious and cool identity. Consider the exponential integral $\text{Ei}(x)$ and the $n$th nontrivial zero of the Riemann Zeta function $p_n$. Now, look at the first few imaginary parts of the following function: $$f(x)=\sum_{n=1}^x \text{Ei}(p_n)$$ $$\Im \ \ f(1)=3.13732$$ $$\Im \ \ f(10)=31.3169$$ $$\Im \ \ f(100)=314.097$$  $$\Im \ \ f(1000)=3141.54$$ $$\Im \ \ f(10000)=31415.9$$ As you can see, it is each time adding a digit of pi. Question: Is this a known result that can be proved easily? Does this pattern even continue?","While playing around, I encountered the following very curious and cool identity. Consider the exponential integral $\text{Ei}(x)$ and the $n$th nontrivial zero of the Riemann Zeta function $p_n$. Now, look at the first few imaginary parts of the following function: $$f(x)=\sum_{n=1}^x \text{Ei}(p_n)$$ $$\Im \ \ f(1)=3.13732$$ $$\Im \ \ f(10)=31.3169$$ $$\Im \ \ f(100)=314.097$$  $$\Im \ \ f(1000)=3141.54$$ $$\Im \ \ f(10000)=31415.9$$ As you can see, it is each time adding a digit of pi. Question: Is this a known result that can be proved easily? Does this pattern even continue?",,"['calculus', 'summation', 'riemann-zeta', 'pi', 'riemann-hypothesis']"
1,Integration analog of automatic differentiation,Integration analog of automatic differentiation,,I was recently looking at automatic differentiation. Does something like automatic differentiation exist for integration? Would the integral be equivalent to something like Euler's method? (or am I thinking about it wrong?) edit: I am looking at some inherited code that includes https://projects.coin-or.org/ADOL-C as a black box.,I was recently looking at automatic differentiation. Does something like automatic differentiation exist for integration? Would the integral be equivalent to something like Euler's method? (or am I thinking about it wrong?) edit: I am looking at some inherited code that includes https://projects.coin-or.org/ADOL-C as a black box.,,"['calculus', 'integration']"
2,"What is minimum of the integral function $I(x)= \int_0^\infty \frac{1}{(1+t^x)^x} \,dt$",What is minimum of the integral function,"I(x)= \int_0^\infty \frac{1}{(1+t^x)^x} \,dt","A while ago I stumbled on a YT movie with regards the integral $$\int_0^\infty \frac1{(1+x^\phi)^\phi} dx = 1 .$$ Here $\phi=1.6180\ldots$ is the Golden Ratio. But then I thought, what will happen if you take $\phi$ as the variable and increase or decrease its value? You'll get the following function: $$I(x) =\int_0^\infty\frac{1}{(1+t^x)^x}dt .$$ with $I(\phi) = 1$ . So making $x$ smaller I noticed at $1$ there is a pole which goes to $+\infty$ . But much nicer is letting $x$ get much larger. What I did not expect is that if $x$ gets very large the value of $I(x)$ seems to go ""back"" to 1 again. I can not check that further than $708$ because after (at $709$ ) Wolfram times out and gives an error. But this means that there's a minimum between phi and infinity. I found that minimum (using public wolfram) to be around $x = 3.542$ . BUT, all values between $3.539$ and $3.546$ give the same lowest answer and that is $0,66568$ And then at $3.538$ or $3.547$ Wolfram gives $0,665681$ . So the question is: What is the exact minimum value and at what $x$ is that? And how can that be derived?","A while ago I stumbled on a YT movie with regards the integral Here is the Golden Ratio. But then I thought, what will happen if you take as the variable and increase or decrease its value? You'll get the following function: with . So making smaller I noticed at there is a pole which goes to . But much nicer is letting get much larger. What I did not expect is that if gets very large the value of seems to go ""back"" to 1 again. I can not check that further than because after (at ) Wolfram times out and gives an error. But this means that there's a minimum between phi and infinity. I found that minimum (using public wolfram) to be around . BUT, all values between and give the same lowest answer and that is And then at or Wolfram gives . So the question is: What is the exact minimum value and at what is that? And how can that be derived?","\int_0^\infty \frac1{(1+x^\phi)^\phi} dx = 1 . \phi=1.6180\ldots \phi I(x) =\int_0^\infty\frac{1}{(1+t^x)^x}dt . I(\phi) = 1 x 1 +\infty x x I(x) 708 709 x = 3.542 3.539 3.546 0,66568 3.538 3.547 0,665681 x","['calculus', 'integration', 'optimization', 'definite-integrals', 'improper-integrals']"
3,Evaluate $\lim_{n \to \infty} \int_{0}^1 [x^n + (1-x)^n ]^{1/n} \ \mathrm{d}x$,Evaluate,\lim_{n \to \infty} \int_{0}^1 [x^n + (1-x)^n ]^{1/n} \ \mathrm{d}x,"Evaluate $$\lim_{n \to \infty} \int_{0}^1 [x^n + (1-x)^n ]^{1/n} \ \mathrm{d}x$$ I simplified the limit to $$\dfrac{1}{2}\lim_{n \to \infty} \int_{0}^{1/2} \left[\left(\frac{1}{2}+x\right)^n + \left(\frac{1}{2}-x\right)^n \right]^{1/n} \ \mathrm{d}x$$ using properties of definite integrals, but I can't solve further. Any help will be appreciated. Thanks.","Evaluate I simplified the limit to using properties of definite integrals, but I can't solve further. Any help will be appreciated. Thanks.",\lim_{n \to \infty} \int_{0}^1 [x^n + (1-x)^n ]^{1/n} \ \mathrm{d}x \dfrac{1}{2}\lim_{n \to \infty} \int_{0}^{1/2} \left[\left(\frac{1}{2}+x\right)^n + \left(\frac{1}{2}-x\right)^n \right]^{1/n} \ \mathrm{d}x,"['calculus', 'integration', 'limits', 'definite-integrals']"
4,Integral ${\large\int}_0^1\frac{\ln^2\ln\left(\frac1x\right)}{1+x+x^2}dx$,Integral,{\large\int}_0^1\frac{\ln^2\ln\left(\frac1x\right)}{1+x+x^2}dx,"Gradshteyn & Ryzhik, 7th ed. , p. 570, formula 4.325(5) give the following definite integral: $$\begin{align*}{\large\int}_0^1\frac{\ln\ln\left(\frac1x\right)}{1+x+x^2}dx&=\frac\pi{\sqrt3}\ln\frac{\sqrt[3]{2\pi}\,\Gamma\left(\frac23\right)}{\Gamma\left(\frac13\right)}\\&=\frac\pi{\sqrt3}\left(\frac{4\ln2\pi}3-\frac{\ln3}2-2\ln\Gamma\left(\tfrac13\right)\right)\end{align*}$$ This and other similar integrals are discussed in several papers: Vardi, Integrals, an introduction to analytic number theory. Am. Math. Mon. 95, 308–315 (1988) Adamchik, A class of logarithmic integrals . Proceedings ISSAC, 1–8, 1997 Medina, Moll, A class of logarithmic integrals , Ramanujan J. 20 (2009), no. 1, 91–126 Blagouchine, Rediscovery of Malmsten's integrals, their evaluation by contour integration methods and some related results , Ramanujan J. 2014; 35: 21 Is it possible to find a closed form for a similar integral having the square of the logarithm in the numerator? $${\large\int}_0^1\frac{\ln^2\ln\left(\frac1x\right)}{1+x+x^2}dx$$","Gradshteyn & Ryzhik, 7th ed. , p. 570, formula 4.325(5) give the following definite integral: $$\begin{align*}{\large\int}_0^1\frac{\ln\ln\left(\frac1x\right)}{1+x+x^2}dx&=\frac\pi{\sqrt3}\ln\frac{\sqrt[3]{2\pi}\,\Gamma\left(\frac23\right)}{\Gamma\left(\frac13\right)}\\&=\frac\pi{\sqrt3}\left(\frac{4\ln2\pi}3-\frac{\ln3}2-2\ln\Gamma\left(\tfrac13\right)\right)\end{align*}$$ This and other similar integrals are discussed in several papers: Vardi, Integrals, an introduction to analytic number theory. Am. Math. Mon. 95, 308–315 (1988) Adamchik, A class of logarithmic integrals . Proceedings ISSAC, 1–8, 1997 Medina, Moll, A class of logarithmic integrals , Ramanujan J. 20 (2009), no. 1, 91–126 Blagouchine, Rediscovery of Malmsten's integrals, their evaluation by contour integration methods and some related results , Ramanujan J. 2014; 35: 21 Is it possible to find a closed form for a similar integral having the square of the logarithm in the numerator? $${\large\int}_0^1\frac{\ln^2\ln\left(\frac1x\right)}{1+x+x^2}dx$$",,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'closed-form']"
5,Set of zeroes of the derivative of a pathological function,Set of zeroes of the derivative of a pathological function,,"For a continuous function $f : [0,1] \to {\mathbb R}$, let us set $$ X_f=\lbrace x \in [0,1] \bigg| f'(x)=0 \rbrace $$ (for a $x\not\in X_f$, $f'(x)$ may be a nonzero value or undefined). There are well-known ""Cantor staircase"" examples where $X_f$ is a dense open set in $[0,1]$. Is there a continuous $f$ with $X_f={\mathbb Q}\cap [0,1]\,$ ? Is there a continuous $f$ with $X_f=[0,1] \setminus {\mathbb Q}$ ? UPDATE 06/02/2012 Since $X_f$ is dense in $[0,1]$, the continuity set of $f'$ is included in $X_f$. Since $X_f$ has empty interior, the continuity set of $f'$ cannot be a $G_{\delta}$ in any subinterval of $[0,1]$, so $f$ cannot be everywhere differentiable on any subinterval of $[0,1]$. All the links proposed so far in the comments are about everywhere differentiable functions, so they do not suffice to answer my question. An interesting sub-question is obtained if, in addition, we also require $f$ to be increasing (so that $f$ will be a homeomorphism from $[0,1]$ onto some other interval). It is easy enough to construct a $f$ and control the behaviour $f'$ on a countable set, by the usual step-by-step procedure. But it seems very hard to say anything at all on the behaviour of $f'$ on the other points of $[0,1]$. SECOND UPDATE 06/02/2012 As noted in the link provided in a comment below, it follows from Cousin's lemma that if $f$ is a continuous function such that $f'=0$ everywhere except  for a countable set, then $f$ is constant. So there is no $f$ such that $X_f=[0,1] \setminus {\mathbb Q}$ : the answer to my second question is NO. My first question remains open however.","For a continuous function $f : [0,1] \to {\mathbb R}$, let us set $$ X_f=\lbrace x \in [0,1] \bigg| f'(x)=0 \rbrace $$ (for a $x\not\in X_f$, $f'(x)$ may be a nonzero value or undefined). There are well-known ""Cantor staircase"" examples where $X_f$ is a dense open set in $[0,1]$. Is there a continuous $f$ with $X_f={\mathbb Q}\cap [0,1]\,$ ? Is there a continuous $f$ with $X_f=[0,1] \setminus {\mathbb Q}$ ? UPDATE 06/02/2012 Since $X_f$ is dense in $[0,1]$, the continuity set of $f'$ is included in $X_f$. Since $X_f$ has empty interior, the continuity set of $f'$ cannot be a $G_{\delta}$ in any subinterval of $[0,1]$, so $f$ cannot be everywhere differentiable on any subinterval of $[0,1]$. All the links proposed so far in the comments are about everywhere differentiable functions, so they do not suffice to answer my question. An interesting sub-question is obtained if, in addition, we also require $f$ to be increasing (so that $f$ will be a homeomorphism from $[0,1]$ onto some other interval). It is easy enough to construct a $f$ and control the behaviour $f'$ on a countable set, by the usual step-by-step procedure. But it seems very hard to say anything at all on the behaviour of $f'$ on the other points of $[0,1]$. SECOND UPDATE 06/02/2012 As noted in the link provided in a comment below, it follows from Cousin's lemma that if $f$ is a continuous function such that $f'=0$ everywhere except  for a countable set, then $f$ is constant. So there is no $f$ such that $X_f=[0,1] \setminus {\mathbb Q}$ : the answer to my second question is NO. My first question remains open however.",,"['calculus', 'examples-counterexamples']"
6,A Challenging Integral: $\int_{0}^{1} \frac{x \arcsin(x/2) \log(x)}{x^2-1} \ dx=\frac{5 \pi^3}{1296}$,A Challenging Integral:,\int_{0}^{1} \frac{x \arcsin(x/2) \log(x)}{x^2-1} \ dx=\frac{5 \pi^3}{1296},"I wish to evaluate the integral $$I=\int_{0}^{1} \frac{x \arcsin(x/2) \log(x)}{x^2-1} \ dx.$$ I used Mathematica's Rationalize command to see that it is equal to $5 \pi^3/1296,$ but I do not know how to prove it analytically. Context The integral appears as part of an alternative expression for the triple integral $$J=\int_{0}^{1} \int_{0}^{1}\int_{0}^{1} \frac{x^2y}{\sqrt{4-x^2}{\sqrt{4-x^2y^2} \sqrt{4-x^2y^2z^2}}} \ dz \ dy \ dx.$$ It is easy to evaluate $J$ directly and show it is $\frac{\pi^3}{1296}.$ However, if we reverse the order of integration and integrate with respect to $y$ first, we get $$J=- \int_{0}^{1} \int_{0}^{1} \frac{\log \left(\frac{\sqrt{4-x^2 z^2}+\sqrt{4-x^2} z}{2 z+2}\right)}{\sqrt{4-x^2} z} \ dz \ dx.$$ The integral can be expanded into the triple integral $$- \int_{0}^{1} \int_{0}^{1} \int_{0}^{z}\frac{x^2}{z \left(x^2 \left(t^2 \sqrt{4-x^2}+\sqrt{4-t^2 x^2}\right)-4    \left(\sqrt{4-t^2 x^2}+\sqrt{4-x^2}\right)\right)} \ dt \ dz \ dx.$$ Reversing the order of integration and integrating with respect to $x$ first, we can deduce \begin{align*} J &= \int_{0}^{1} \int_{t}^{1}\frac{\frac{\pi }{6} t-\sin ^{-1}\left(\frac{t}{2}\right)}{\left(t-t^3\right) z} \ dz \ dt  \\ &= -\int_{0}^{1}\frac{\frac{\pi}{6} t \log(t) -\sin ^{-1}\left(\frac{t}{2}\right) \log(t)}{t-t^3} \ dt  \\ &=\frac{\pi}{6} \int_{0}^{1}\frac{\log(t)}{t^2-1} \ dt + \int_{0}^{1} \frac{\sin ^{-1}\left(\frac{t}{2}\right) \log(t)}{t-t^3} \ dt \\ &= \frac{\pi^3}{48} + \int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt - \int_{0}^{1} \frac{t \log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t^2-1} \ dt, \end{align*} in which we used the well-known result $$\int_{0}^{1} \frac{\log(t)}{t^2-1} \ dt = \frac{\pi^2}{8}$$ and partial fractions on the second integral term in the second to last equality. Recalling $J=\pi^3/1296,$ rearranging gives $$ \begin{align*} -\frac{13 \pi ^3}{648} &=\int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt - \int_{0}^{1} \frac{t \log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t^2-1} \ dt \\ &=\int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt - I. \end{align*}$$ Question Upon using integrating by parts, it turns out $$\int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt= -\int_{0}^{1} \frac{\log^2(t)}{2\sqrt{4-t^2}} \ dt.$$ Further substituting $t=2 \sin(\theta)$ and using the answers in either Interesting log sine integrals $\int_0^{\pi/3} \log^2 \left(2\sin \frac{x}{2} \right)dx= \frac{7\pi^3}{108}$ or Finding $\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{4-x^2}}dx$ , we can deduce $$\int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt = -\frac{7 \pi^3}{432}.$$ Hence, assuming this, we can get $$I= \frac{5 \pi^3}{1296}.$$ Can we evaluate $I$ without knowing the value of the integral $\int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt$ ? Can $I$ be evaluated with real methods ?","I wish to evaluate the integral I used Mathematica's Rationalize command to see that it is equal to but I do not know how to prove it analytically. Context The integral appears as part of an alternative expression for the triple integral It is easy to evaluate directly and show it is However, if we reverse the order of integration and integrate with respect to first, we get The integral can be expanded into the triple integral Reversing the order of integration and integrating with respect to first, we can deduce in which we used the well-known result and partial fractions on the second integral term in the second to last equality. Recalling rearranging gives Question Upon using integrating by parts, it turns out Further substituting and using the answers in either Interesting log sine integrals $\int_0^{\pi/3} \log^2 \left(2\sin \frac{x}{2} \right)dx= \frac{7\pi^3}{108}$ or Finding $\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{4-x^2}}dx$ , we can deduce Hence, assuming this, we can get Can we evaluate without knowing the value of the integral ? Can be evaluated with real methods ?","I=\int_{0}^{1} \frac{x \arcsin(x/2) \log(x)}{x^2-1} \ dx. 5 \pi^3/1296, J=\int_{0}^{1} \int_{0}^{1}\int_{0}^{1} \frac{x^2y}{\sqrt{4-x^2}{\sqrt{4-x^2y^2} \sqrt{4-x^2y^2z^2}}} \ dz \ dy \ dx. J \frac{\pi^3}{1296}. y J=- \int_{0}^{1} \int_{0}^{1} \frac{\log \left(\frac{\sqrt{4-x^2 z^2}+\sqrt{4-x^2} z}{2 z+2}\right)}{\sqrt{4-x^2} z} \ dz \ dx. - \int_{0}^{1} \int_{0}^{1} \int_{0}^{z}\frac{x^2}{z \left(x^2 \left(t^2 \sqrt{4-x^2}+\sqrt{4-t^2 x^2}\right)-4
   \left(\sqrt{4-t^2 x^2}+\sqrt{4-x^2}\right)\right)} \ dt \ dz \ dx. x \begin{align*}
J &= \int_{0}^{1} \int_{t}^{1}\frac{\frac{\pi }{6} t-\sin ^{-1}\left(\frac{t}{2}\right)}{\left(t-t^3\right) z} \ dz \ dt  \\
&= -\int_{0}^{1}\frac{\frac{\pi}{6} t \log(t) -\sin ^{-1}\left(\frac{t}{2}\right) \log(t)}{t-t^3} \ dt  \\
&=\frac{\pi}{6} \int_{0}^{1}\frac{\log(t)}{t^2-1} \ dt + \int_{0}^{1} \frac{\sin ^{-1}\left(\frac{t}{2}\right) \log(t)}{t-t^3} \ dt \\
&= \frac{\pi^3}{48} + \int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt - \int_{0}^{1} \frac{t \log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t^2-1} \ dt,
\end{align*} \int_{0}^{1} \frac{\log(t)}{t^2-1} \ dt = \frac{\pi^2}{8} J=\pi^3/1296, 
\begin{align*}
-\frac{13 \pi ^3}{648} &=\int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt - \int_{0}^{1} \frac{t \log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t^2-1} \ dt \\
&=\int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt - I.
\end{align*} \int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt= -\int_{0}^{1} \frac{\log^2(t)}{2\sqrt{4-t^2}} \ dt. t=2 \sin(\theta) \int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt = -\frac{7 \pi^3}{432}. I= \frac{5 \pi^3}{1296}. I \int_{0}^{1} \frac{\log (t) \sin ^{-1}\left(\frac{t}{2}\right)}{t} \ dt I","['calculus', 'integration']"
7,What is minimum speed needed to jump over sphere object that has radius R and at distance d?,What is minimum speed needed to jump over sphere object that has radius R and at distance d?,,"(I am not expert in English. I will write as well as I can.) To understand this question easier, lets see this picture. From this picture, what is minimum initial speed that this grasshopper need to jump over this log? The grasshopper movement path can touch the log but can't cross through inside of the log. d and R can be any positive real number which d>R. g is a gravitational acceleration(approximately 9.80665 $m/s^2$). This is a mathematical-physics question but mainly in maths. I can do physics part but have problem in maths part. Physics Part : Let red ball is grasshopper and at origin point and y is height The relation between x and y for projectile motion is $y(x) = xtan\theta - \frac{gx^2}{2u^2cos^2\theta}$ , $0 < \theta < \frac{\pi}{2}$ Upper curve of sphere can de describe in function : $y_s(x) = R + \sqrt{R^2-(x-d)^2}$ , for $ d-R \leq x \leq d+R$ Condition of the sphere is $y(x) \geq y_s(x)$ , for $ d-R \leq x \leq d+R$ or $xtan\theta - \frac{gx^2}{2u^2cos^2\theta} \geq R + \sqrt{R^2-(x-d)^2}$ , for $ d-R \leq x \leq d+R$ At this point, I don't how to find $u_{min}(d,R)$ from this. (If you give value of d and h (for example, d = 2m and R = 1m), it is possible to find $\theta$ that minimize u.) I know only that y(x) (parabola curve) for $u_{min}(d,R)$ look like. Case : d = cR (c is a constant. There is a ratio that make y(x) have maximun point at the top of the sphere.) Case : d > cR Case : d < cR Please help me.","(I am not expert in English. I will write as well as I can.) To understand this question easier, lets see this picture. From this picture, what is minimum initial speed that this grasshopper need to jump over this log? The grasshopper movement path can touch the log but can't cross through inside of the log. d and R can be any positive real number which d>R. g is a gravitational acceleration(approximately 9.80665 $m/s^2$). This is a mathematical-physics question but mainly in maths. I can do physics part but have problem in maths part. Physics Part : Let red ball is grasshopper and at origin point and y is height The relation between x and y for projectile motion is $y(x) = xtan\theta - \frac{gx^2}{2u^2cos^2\theta}$ , $0 < \theta < \frac{\pi}{2}$ Upper curve of sphere can de describe in function : $y_s(x) = R + \sqrt{R^2-(x-d)^2}$ , for $ d-R \leq x \leq d+R$ Condition of the sphere is $y(x) \geq y_s(x)$ , for $ d-R \leq x \leq d+R$ or $xtan\theta - \frac{gx^2}{2u^2cos^2\theta} \geq R + \sqrt{R^2-(x-d)^2}$ , for $ d-R \leq x \leq d+R$ At this point, I don't how to find $u_{min}(d,R)$ from this. (If you give value of d and h (for example, d = 2m and R = 1m), it is possible to find $\theta$ that minimize u.) I know only that y(x) (parabola curve) for $u_{min}(d,R)$ look like. Case : d = cR (c is a constant. There is a ratio that make y(x) have maximun point at the top of the sphere.) Case : d > cR Case : d < cR Please help me.",,"['calculus', 'multivariable-calculus', 'trigonometry', 'classical-mechanics', 'projectile-motion']"
8,When is LIATE simply wrong?,When is LIATE simply wrong?,,"I'm currently teaching Calculus II, and yesterday I covered integration by parts and mentioned the LIATE rule. I also gave the usual ""it works 99% of the time"", but started wondering whether there are any cases where LIATE simply gets the choice of $u$ and $v'$ wrong. (For those of you who don't know what LIATE is, check out https://en.wikipedia.org/wiki/Integration_by_parts#LIATE_rule ) I don't consider the example listed at the link above to be what I'm looking for, because I don't consider $e^{x^2}$ to be an exponential function here (only $a^{bx}$). (I don't consider $\tan x$ to be a ""trig"" function, either, in this context.) Does anyone have a ""pet"" example that they show?","I'm currently teaching Calculus II, and yesterday I covered integration by parts and mentioned the LIATE rule. I also gave the usual ""it works 99% of the time"", but started wondering whether there are any cases where LIATE simply gets the choice of $u$ and $v'$ wrong. (For those of you who don't know what LIATE is, check out https://en.wikipedia.org/wiki/Integration_by_parts#LIATE_rule ) I don't consider the example listed at the link above to be what I'm looking for, because I don't consider $e^{x^2}$ to be an exponential function here (only $a^{bx}$). (I don't consider $\tan x$ to be a ""trig"" function, either, in this context.) Does anyone have a ""pet"" example that they show?",,"['calculus', 'integration']"
9,"Integral with arithmetic-geometric mean ${\large\int}_0^1\frac{x^z}{\operatorname{agm}(1,\,x)}dx$",Integral with arithmetic-geometric mean,"{\large\int}_0^1\frac{x^z}{\operatorname{agm}(1,\,x)}dx","The arithmetic-geometric mean $^{[1]}$ $\!^{[2]}$ of positive numbers $a$ and $b$ is denoted $\operatorname{agm}(a,b)$ and defined as follows:  $$\text{Let}\quad a_0=a,\quad b_0=b,\quad a_{n+1}=\frac{a_n+b_n}2,\quad b_{n+1}=\sqrt{a_n b_n}.$$ $$\text{Then}\quad\operatorname{agm}(a,\,b)=\lim_{n\to\infty}a_n=\lim_{n\to\infty}b_n.\tag1$$ It can be expressed $^{[3]}$ in terms of the complete elliptic integral of the $1^{\text{st}}$ kind $^{[4]}$ $\!^{[5]}$ : $$\operatorname{agm}(a,\,b)=\frac\pi4\cdot\frac{a+b}{{\bf K}\!\left(\frac{a+b}{a-b}\right)}.\tag2$$ It appears that $$\int_0^1\frac{x^z}{\operatorname{agm}(1,\,x)}dx\stackrel{\color{gray}?}=\frac{\Gamma\!\left(\frac z2+\frac12\right)}{2\,\Gamma\!\left(\frac z2+1\right)},\quad\forall z\in\mathbb C,\,\Re(z)>-1.\tag3$$ How can we prove it?","The arithmetic-geometric mean $^{[1]}$ $\!^{[2]}$ of positive numbers $a$ and $b$ is denoted $\operatorname{agm}(a,b)$ and defined as follows:  $$\text{Let}\quad a_0=a,\quad b_0=b,\quad a_{n+1}=\frac{a_n+b_n}2,\quad b_{n+1}=\sqrt{a_n b_n}.$$ $$\text{Then}\quad\operatorname{agm}(a,\,b)=\lim_{n\to\infty}a_n=\lim_{n\to\infty}b_n.\tag1$$ It can be expressed $^{[3]}$ in terms of the complete elliptic integral of the $1^{\text{st}}$ kind $^{[4]}$ $\!^{[5]}$ : $$\operatorname{agm}(a,\,b)=\frac\pi4\cdot\frac{a+b}{{\bf K}\!\left(\frac{a+b}{a-b}\right)}.\tag2$$ It appears that $$\int_0^1\frac{x^z}{\operatorname{agm}(1,\,x)}dx\stackrel{\color{gray}?}=\frac{\Gamma\!\left(\frac z2+\frac12\right)}{2\,\Gamma\!\left(\frac z2+1\right)},\quad\forall z\in\mathbb C,\,\Re(z)>-1.\tag3$$ How can we prove it?",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'elliptic-integrals']"
10,A closed form for $\int_{0}^{\pi/2}\frac{\ln\cos x}{x}\mathrm{d}x$?,A closed form for ?,\int_{0}^{\pi/2}\frac{\ln\cos x}{x}\mathrm{d}x,"The following integrals are classic, initiated by L. Euler. \begin{align}  \displaystyle \int_{0}^{\pi/2} x^3 \ln\cos x\:\mathrm{d}x & = -\frac{\pi^4}{64} \ln 2-\frac{3\pi^2}{16} \zeta(3)+\frac{93}{128} \zeta(5),  \\ \int_{0}^{\pi/2}  x^2 \ln\cos x\:\mathrm{d}x & = -\frac{\pi^3}{24} \ln 2-\frac{\pi}{4} \zeta(3),   \\  \int_{0}^{\pi/2}  x^1 \ln\cos x\:\mathrm{d}x  & = -\frac{\pi^2}{8} \ln 2-\frac{7}{16} \zeta(3),   \\  \int_{0}^{\pi/2}  x^0 \ln\cos x\:\mathrm{d}x  & = -\frac{\pi}{2}\ln 2.   \end{align} We may logically consider the case when the first factor of the integrand is $\displaystyle x^{-1} = \frac 1x $ leading to the following non classic convergent integral. $$ \int_{0}^{\pi/2}  \frac{\ln\cos x}{x}\:\mathrm{d}x \qquad  (*)$$ I do not have a closed form for this integral. My question is does someone have some references/results about $(*)$?","The following integrals are classic, initiated by L. Euler. \begin{align}  \displaystyle \int_{0}^{\pi/2} x^3 \ln\cos x\:\mathrm{d}x & = -\frac{\pi^4}{64} \ln 2-\frac{3\pi^2}{16} \zeta(3)+\frac{93}{128} \zeta(5),  \\ \int_{0}^{\pi/2}  x^2 \ln\cos x\:\mathrm{d}x & = -\frac{\pi^3}{24} \ln 2-\frac{\pi}{4} \zeta(3),   \\  \int_{0}^{\pi/2}  x^1 \ln\cos x\:\mathrm{d}x  & = -\frac{\pi^2}{8} \ln 2-\frac{7}{16} \zeta(3),   \\  \int_{0}^{\pi/2}  x^0 \ln\cos x\:\mathrm{d}x  & = -\frac{\pi}{2}\ln 2.   \end{align} We may logically consider the case when the first factor of the integrand is $\displaystyle x^{-1} = \frac 1x $ leading to the following non classic convergent integral. $$ \int_{0}^{\pi/2}  \frac{\ln\cos x}{x}\:\mathrm{d}x \qquad  (*)$$ I do not have a closed form for this integral. My question is does someone have some references/results about $(*)$?",,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'logarithms']"
11,Prove $\int_0^{\pi/2}x^2\sqrt{\cot x} \ dx=\frac{\sqrt2}{8}\left( \frac{5\pi^{3}}{12}-\pi^2\ln2-\pi \ln^22 \right)$,Prove,\int_0^{\pi/2}x^2\sqrt{\cot x} \ dx=\frac{\sqrt2}{8}\left( \frac{5\pi^{3}}{12}-\pi^2\ln2-\pi \ln^22 \right),"I came across the follwing integral: $$\int_0^{\pi/2}x^2\sqrt{\cot x} \ dx=\frac{\sqrt2}{8}\left( \frac{5\pi^{3}}{12}-\pi^2\ln2-\pi \ln^22 \right)$$ I try to do it like the following: Consider $$I(a,b)=\int_0^{\pi} \frac{\cos ax}{\sin^b x}\ dx=2\int_0^{\pi/2} \frac{\cos 2ax}{\sin^b 2x}\ dx$$ Then $$I''(a,b)=-8\int_0^{\pi/2}x^2 \frac{\cos 2ax}{\sin^b 2x}\ dx$$ Let $a=1/2,b=1/2$ $$I''(1/2,1/2)=-8\int_0^{\pi/2}x^2 \frac{\cos x}{\sqrt{\sin 2x}}\ dx=-\frac{8}{\sqrt2}\int_0^{\pi/2}x^2\sqrt{\cot x} \ dx $$ Back to $I(a,b),\quad I(a,b) $ can be expressed by beta fuction by Wolfram Mathematica. $$I(a,b)=\int_0^{\pi} \frac{\cos ax}{\sin^b x}\ dx=\frac{\pi \cdot 2^b\cdot\cos (\pi a/2)\cdot \Gamma(1-b) }{\Gamma(a/2-b/2+1) \cdot \Gamma(-a/2-b/2+1)} $$ Then we can get $I''(a,b)$ approach from other way. Finally,we can get $\int_0^{\pi/2}x^2\sqrt{\cot x} \ dx$ ,but it seems a little complex. For a similar integral: $$\int_0^{\pi/2}x\cdot\tan^p x \ dx=\frac{\pi}{4\sin (p\pi/2)}\left(\Psi\left(\frac{1}{2}\right)-\Psi\left(\frac{1-p}{2}\right) \right)$$ The above integral can be solved by method of parametric development.Let $p=-\frac{1}{2}$ ,We can get $$\int_0^{\pi/2}x\sqrt{\cot x} \ dx=\frac{\pi\left(\pi-2\ln 2\right)}{4\sqrt2}$$ But to this one, it seems to be difficult with method of parametric development.  Could you suggest any ideas how to prove this?","I came across the follwing integral: I try to do it like the following: Consider Then Let Back to can be expressed by beta fuction by Wolfram Mathematica. Then we can get approach from other way. Finally,we can get ,but it seems a little complex. For a similar integral: The above integral can be solved by method of parametric development.Let ,We can get But to this one, it seems to be difficult with method of parametric development.  Could you suggest any ideas how to prove this?","\int_0^{\pi/2}x^2\sqrt{\cot x} \ dx=\frac{\sqrt2}{8}\left( \frac{5\pi^{3}}{12}-\pi^2\ln2-\pi \ln^22 \right) I(a,b)=\int_0^{\pi} \frac{\cos ax}{\sin^b x}\ dx=2\int_0^{\pi/2} \frac{\cos 2ax}{\sin^b 2x}\ dx I''(a,b)=-8\int_0^{\pi/2}x^2 \frac{\cos 2ax}{\sin^b 2x}\ dx a=1/2,b=1/2 I''(1/2,1/2)=-8\int_0^{\pi/2}x^2 \frac{\cos x}{\sqrt{\sin 2x}}\ dx=-\frac{8}{\sqrt2}\int_0^{\pi/2}x^2\sqrt{\cot x} \ dx  I(a,b),\quad I(a,b)  I(a,b)=\int_0^{\pi} \frac{\cos ax}{\sin^b x}\ dx=\frac{\pi \cdot 2^b\cdot\cos (\pi a/2)\cdot \Gamma(1-b) }{\Gamma(a/2-b/2+1) \cdot \Gamma(-a/2-b/2+1)}  I''(a,b) \int_0^{\pi/2}x^2\sqrt{\cot x} \ dx \int_0^{\pi/2}x\cdot\tan^p x \ dx=\frac{\pi}{4\sin (p\pi/2)}\left(\Psi\left(\frac{1}{2}\right)-\Psi\left(\frac{1-p}{2}\right) \right) p=-\frac{1}{2} \int_0^{\pi/2}x\sqrt{\cot x} \ dx=\frac{\pi\left(\pi-2\ln 2\right)}{4\sqrt2}","['calculus', 'integration', 'definite-integrals']"
12,Limit of an inverse function,Limit of an inverse function,,"Let $f:\mathbb R\to \mathbb  R$ be an invertible function such that $$\lim_{x\to a} f(x)=b$$ for some $a,b\in \mathbb R$ . Does it follow that $$\lim_{x\to b}f^{-1}(x)= a,$$ where $f^{-1}$ denotes the inverse function of $f$ ? Edit: When I consider the $\epsilon,\delta$ -definition of the limit, I feel that there should be an example that $\lim_{x\to b}f^{-1}(x)\neq a$ due to the fact that $\epsilon,\delta$ -definition is not symmetric (for a given $\epsilon>0$ , we find $\delta>0$ such that ....). However, if we further assume that $f$ is cont., $$b=\lim_{x\to b}x=\lim_{x\to b}f\circ f^{-1}(x)=f(\lim_{x\to b}  f^{-1}(x)).$$ It follows that $\lim_{x\to b}  f^{-1}(x)=f^{-1}(b)=a$ . Thus, one needs a discontinuous function to have a counter example. I wonder whether there is any simple function with this property. @Floris Claassens'a answer shows that there are some ""ugly functions"" with this property.","Let be an invertible function such that for some . Does it follow that where denotes the inverse function of ? Edit: When I consider the -definition of the limit, I feel that there should be an example that due to the fact that -definition is not symmetric (for a given , we find such that ....). However, if we further assume that is cont., It follows that . Thus, one needs a discontinuous function to have a counter example. I wonder whether there is any simple function with this property. @Floris Claassens'a answer shows that there are some ""ugly functions"" with this property.","f:\mathbb R\to \mathbb  R \lim_{x\to a} f(x)=b a,b\in \mathbb R \lim_{x\to b}f^{-1}(x)= a, f^{-1} f \epsilon,\delta \lim_{x\to b}f^{-1}(x)\neq a \epsilon,\delta \epsilon>0 \delta>0 f b=\lim_{x\to b}x=\lim_{x\to b}f\circ f^{-1}(x)=f(\lim_{x\to b}  f^{-1}(x)). \lim_{x\to b}  f^{-1}(x)=f^{-1}(b)=a","['calculus', 'limits']"
13,An integral of a rational function of logarithm and nonlinear arguments,An integral of a rational function of logarithm and nonlinear arguments,,"This problem was posted in I&S $$ \int_{0}^{1} \dfrac{\log x \log (1+x) \log (1+x+x^{2})}{(1-x)(1+x^{2})}\,\mathrm{d}x \approx -0.223434.$$ I am not sure if there exists a closed form but it seems worth trying. I am completely clueless on how to start with this beast. It is worth saying that$$1-x^3= (1-x)(1+x+x^2).$$ That seems to go no where. I think the integral can be represented as the derivative of the integral representation of the Hypergeometric function but I am not comfortable with that. Any ideas ?","This problem was posted in I&S $$ \int_{0}^{1} \dfrac{\log x \log (1+x) \log (1+x+x^{2})}{(1-x)(1+x^{2})}\,\mathrm{d}x \approx -0.223434.$$ I am not sure if there exists a closed form but it seems worth trying. I am completely clueless on how to start with this beast. It is worth saying that$$1-x^3= (1-x)(1+x+x^2).$$ That seems to go no where. I think the integral can be represented as the derivative of the integral representation of the Hypergeometric function but I am not comfortable with that. Any ideas ?",,"['calculus', 'integration', 'definite-integrals']"
14,What is the best way to learn Differential forms?,What is the best way to learn Differential forms?,,"I'm taking a Multivariable Calculus class and my teacher has just started Differential forms. It is not making a lot of sense, though. I have tried reading ""Geometric Approach to Differential forms"" by David Bachman and I have understood a bit, but I would like to get more feel of it. I just want an introduction to the subject, not too much detail. I want to know if there are any online lectures I can see or a better book I can read from.","I'm taking a Multivariable Calculus class and my teacher has just started Differential forms. It is not making a lot of sense, though. I have tried reading ""Geometric Approach to Differential forms"" by David Bachman and I have understood a bit, but I would like to get more feel of it. I just want an introduction to the subject, not too much detail. I want to know if there are any online lectures I can see or a better book I can read from.",,"['calculus', 'multivariable-calculus', 'reference-request', 'differential-forms']"
15,Evaluting $\int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} \operatorname dx$,Evaluting,\int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} \operatorname dx,$$\int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} dx$$ My try:: $\displaystyle  \int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} dx = \int_{1}^{2}\frac{\tan^{-1}x}{\tan^{-1}(x-1)-\tan^{-1}(x-2)}dx$ Now How can i solve after that. plz help me Thanks,$$\int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} dx$$ My try:: $\displaystyle  \int_{1}^{2} \frac{\tan^{-1} x}{\tan^{-1} \frac {1}{x^2-3x+3}} dx = \int_{1}^{2}\frac{\tan^{-1}x}{\tan^{-1}(x-1)-\tan^{-1}(x-2)}dx$ Now How can i solve after that. plz help me Thanks,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
16,Which universities teach true infinitesimal calculus?,Which universities teach true infinitesimal calculus?,,"My colleague and I are currently teaching ""true infinitesimal calculus"" (TIC), in the sense of calculus with infinitesimals, to a class of about 120 freshmen at our university, based on the book by Keisler .  Two of my colleagues in Belgium are similarly teaching TIC at two universities there. I am also aware of such teaching going on in France in the Strasbourg area, based on Edward Nelson's approach, though I don't have any details on that. Which universities teach true infinitesimal calculus? Anyone with any additional information in this direction is requested to provide it. This is cross-posted here . A colleague in Italy has recently told me about a conference on using infinitesimals in teaching in Italian highschools. This NSA (nonstandard analysis) conference was apparently well attended (over 100 teachers showed up). Anybody with more information about this (who to contact, what the current status of the proposal is, etc.) is hereby requested to provide such information here. Our experiences teaching calculus with infinitesimals were detailed in this 2017 publication in Humanistic Mathematics .","My colleague and I are currently teaching ""true infinitesimal calculus"" (TIC), in the sense of calculus with infinitesimals, to a class of about 120 freshmen at our university, based on the book by Keisler .  Two of my colleagues in Belgium are similarly teaching TIC at two universities there. I am also aware of such teaching going on in France in the Strasbourg area, based on Edward Nelson's approach, though I don't have any details on that. Which universities teach true infinitesimal calculus? Anyone with any additional information in this direction is requested to provide it. This is cross-posted here . A colleague in Italy has recently told me about a conference on using infinitesimals in teaching in Italian highschools. This NSA (nonstandard analysis) conference was apparently well attended (over 100 teachers showed up). Anybody with more information about this (who to contact, what the current status of the proposal is, etc.) is hereby requested to provide such information here. Our experiences teaching calculus with infinitesimals were detailed in this 2017 publication in Humanistic Mathematics .",,"['calculus', 'reference-request', 'education', 'infinitesimals']"
17,Geometric approach to $\lim_{n\to\infty}\left(\frac{x_{n+1}}{x_n}\right)^n$ where $x_1=1$ and $x_{n+1}=\sqrt{1+x^2_n}$?,Geometric approach to  where  and ?,\lim_{n\to\infty}\left(\frac{x_{n+1}}{x_n}\right)^n x_1=1 x_{n+1}=\sqrt{1+x^2_n},"I was solving a question : Let $x_1=1$ and $x_{n+1} = \sqrt{1+x^2_n } \ \ \forall \ \ n\in \mathbb{N}$ Then evaluate $$\lim_{n \to \infty} \left( \frac{x_{n+1}}{x_n} \right)^n$$ The way I did it was : $$x_1^2=1$$ $$x_2^2=2$$ $$x_3^2=3$$ $$x_4^2=4$$ $$x_{n+1}^2=(n+1)$$ $$\therefore \lim_{n \to \infty} \left( \frac{x_{n+1}^2}{x_n^2} \right)^\frac{n}{2}$$ $$A = \lim_{n \to \infty} \left( \frac{n+1}{n} \right)^{\frac{n}{2}}$$ $$\ln(A) = \lim_{n \to \infty} \frac{1}{2} \frac{\ln\left( 1+ \frac{1}{n} \right)}{\frac{1}{n}} $$ Applying L'Hopital's rule : $$\ln(A) = \frac{1}{2}$$ $$A = \sqrt{e}$$ But what I think is that this could also be solved using a geometric approach. I believe so because the recurrence relation given is similar to the Pythagoras Theorem. $$x_{n+1}^2 = 1^2 + x_n^2$$ I tried to draw the diagram for something like this : However all I could conclude was the indeterminate form the was forming : For the the limit is of the secant of the base angle of the triangle ( $(\sec \alpha)^n$ ) with $x_n$ as the base. i.e. the limit becomes : $$\lim_{n \to \infty} \sec^n (\alpha_n)$$ which I can see that as $n$ approaches $\infty$ , $\alpha_n$ will keep decreasing until we can say $x_n \approx x_{n+1}$ , so it is a $(1)^\infty$ form. So my question is : How would one prove the above question using geometry?","I was solving a question : Let and Then evaluate The way I did it was : Applying L'Hopital's rule : But what I think is that this could also be solved using a geometric approach. I believe so because the recurrence relation given is similar to the Pythagoras Theorem. I tried to draw the diagram for something like this : However all I could conclude was the indeterminate form the was forming : For the the limit is of the secant of the base angle of the triangle ( ) with as the base. i.e. the limit becomes : which I can see that as approaches , will keep decreasing until we can say , so it is a form. So my question is : How would one prove the above question using geometry?",x_1=1 x_{n+1} = \sqrt{1+x^2_n } \ \ \forall \ \ n\in \mathbb{N} \lim_{n \to \infty} \left( \frac{x_{n+1}}{x_n} \right)^n x_1^2=1 x_2^2=2 x_3^2=3 x_4^2=4 x_{n+1}^2=(n+1) \therefore \lim_{n \to \infty} \left( \frac{x_{n+1}^2}{x_n^2} \right)^\frac{n}{2} A = \lim_{n \to \infty} \left( \frac{n+1}{n} \right)^{\frac{n}{2}} \ln(A) = \lim_{n \to \infty} \frac{1}{2} \frac{\ln\left( 1+ \frac{1}{n} \right)}{\frac{1}{n}}  \ln(A) = \frac{1}{2} A = \sqrt{e} x_{n+1}^2 = 1^2 + x_n^2 (\sec \alpha)^n x_n \lim_{n \to \infty} \sec^n (\alpha_n) n \infty \alpha_n x_n \approx x_{n+1} (1)^\infty,"['calculus', 'geometry', 'limits']"
18,Proving a trigonometric identity: $\frac{\cos x}{1-\sin x} -\tan x = \sec x$,Proving a trigonometric identity:,\frac{\cos x}{1-\sin x} -\tan x = \sec x,I am trying to prove a trig identity that is confusing me. The identity is  $$\frac{\cos(x)}{(1-\sin(x))}-\tan(x)=\sec(x)$$ Here is my attempt. I did $$\frac{\cos(x)}{(1-\sin^2(x))}=\frac{\cos(x)}{\cos^2(x)}=\frac{1}{\cos(x)}=\sec(x)=(\sec(x)+\tan(x))(1+\sin(x))\\\sec(x)=\sec(x)+\sec(x)\sin(x)+\tan(x)+\tan(x)\sin(x)\\0=\tan(x)+\tan(x)+\tan(x)\sin(x)$$ but this does not make sense to me. Can somebody please help me with this thing?,I am trying to prove a trig identity that is confusing me. The identity is  $$\frac{\cos(x)}{(1-\sin(x))}-\tan(x)=\sec(x)$$ Here is my attempt. I did $$\frac{\cos(x)}{(1-\sin^2(x))}=\frac{\cos(x)}{\cos^2(x)}=\frac{1}{\cos(x)}=\sec(x)=(\sec(x)+\tan(x))(1+\sin(x))\\\sec(x)=\sec(x)+\sec(x)\sin(x)+\tan(x)+\tan(x)\sin(x)\\0=\tan(x)+\tan(x)+\tan(x)\sin(x)$$ but this does not make sense to me. Can somebody please help me with this thing?,,"['calculus', 'trigonometry']"
19,Integration of secant [duplicate],Integration of secant [duplicate],,"This question already has answers here : Ways to evaluate $\int \sec \theta \, \mathrm d \theta$ (15 answers) Closed 3 years ago . $$\begin{align} \int \sec x \, dx  &= \int \cos x \left(  \frac{1}{\cos^2x} \right)  \, dx \\ &= \int \cos x \left(  \frac{1}{1-\sin^2x} \right) \, dx \\ & = \int\cos x\cdot\frac{1}{1-\frac{1-\cos2x}{2}} \, dx \\ &= \int \cos x \cdot\frac{2}{1+\cos2x} \, dx  \end{align}$$ I am stuck in here. Any help to integrate secant?","This question already has answers here : Ways to evaluate $\int \sec \theta \, \mathrm d \theta$ (15 answers) Closed 3 years ago . $$\begin{align} \int \sec x \, dx  &= \int \cos x \left(  \frac{1}{\cos^2x} \right)  \, dx \\ &= \int \cos x \left(  \frac{1}{1-\sin^2x} \right) \, dx \\ & = \int\cos x\cdot\frac{1}{1-\frac{1-\cos2x}{2}} \, dx \\ &= \int \cos x \cdot\frac{2}{1+\cos2x} \, dx  \end{align}$$ I am stuck in here. Any help to integrate secant?",,"['calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
20,Evaluate $\int_{0}^{\frac{\pi}{2}}\frac{x^2}{ \sin x}dx$,Evaluate,\int_{0}^{\frac{\pi}{2}}\frac{x^2}{ \sin x}dx,"I want to evaluate $$\int_{0}^{\frac{\pi}{2}}\frac{x^2}{ \sin x}dx$$ First,I tried to evaluate like this: $$\int_{0}^{\frac{\pi}{2}}\frac{x^2}{ \sin x}dx=\int_{0}^{\frac{\pi}{2}}x^2\left(\frac{1+\cos x}{\sin x}\right)\frac{dx}{1+\cos x}=\int_{0}^{\frac{\pi}{2}}x^2\left(\frac{1+\cos x}{\sin x}\right)d\left(\frac{\sin x}{1+\cos x}\right)$$ $$=\int_{0}^{\frac{\pi}{2}}x^2d\log\left(\frac{\sin x}{1+\cos x}\right)=x^2\log\left(\frac{\sin x}{1+\cos x}\right)|_{0}^{\frac{\pi}{2}}-2\int_{0}^{\frac{\pi}{2}}x\log\left(\frac{\sin x}{1+\cos x}\right)dx$$ $$=0+2\int_{0}^{\frac{\pi}{2}}x\log\left(\frac{1+\cos x}{\sin x}\right)dx=2\int_{0}^{\frac{\pi}{2}}x\log\left(1+\cos x\right)dx-2\int_{0}^{\frac{\pi}{2}}x\log\left(\sin x\right)dx$$ $$=2\int_{0}^{\frac{\pi}{2}}x\log\cot \left(\frac{x}{2}\right)dx=8\int_{0}^{\frac{\pi}{4}}x\log\cot xdx$$ but I can't proceed next step,help me,thanks.","I want to evaluate $$\int_{0}^{\frac{\pi}{2}}\frac{x^2}{ \sin x}dx$$ First,I tried to evaluate like this: $$\int_{0}^{\frac{\pi}{2}}\frac{x^2}{ \sin x}dx=\int_{0}^{\frac{\pi}{2}}x^2\left(\frac{1+\cos x}{\sin x}\right)\frac{dx}{1+\cos x}=\int_{0}^{\frac{\pi}{2}}x^2\left(\frac{1+\cos x}{\sin x}\right)d\left(\frac{\sin x}{1+\cos x}\right)$$ $$=\int_{0}^{\frac{\pi}{2}}x^2d\log\left(\frac{\sin x}{1+\cos x}\right)=x^2\log\left(\frac{\sin x}{1+\cos x}\right)|_{0}^{\frac{\pi}{2}}-2\int_{0}^{\frac{\pi}{2}}x\log\left(\frac{\sin x}{1+\cos x}\right)dx$$ $$=0+2\int_{0}^{\frac{\pi}{2}}x\log\left(\frac{1+\cos x}{\sin x}\right)dx=2\int_{0}^{\frac{\pi}{2}}x\log\left(1+\cos x\right)dx-2\int_{0}^{\frac{\pi}{2}}x\log\left(\sin x\right)dx$$ $$=2\int_{0}^{\frac{\pi}{2}}x\log\cot \left(\frac{x}{2}\right)dx=8\int_{0}^{\frac{\pi}{4}}x\log\cot xdx$$ but I can't proceed next step,help me,thanks.",,"['calculus', 'integration', 'analysis']"
21,Find the value of a function whose derivative is zero,Find the value of a function whose derivative is zero,,The initial function is $$h(x)=\arcsin  x + \arccos x$$ The derivative of this function is $0$ since $$h'(x)=\frac{1}{\sqrt{1-x^2}}-\frac{1}{\sqrt{1-x^2}}\equiv0$$ This means that $h(x)$ is a constant function; how can I find the value of $h(x)$? Could anyone please explain?,The initial function is $$h(x)=\arcsin  x + \arccos x$$ The derivative of this function is $0$ since $$h'(x)=\frac{1}{\sqrt{1-x^2}}-\frac{1}{\sqrt{1-x^2}}\equiv0$$ This means that $h(x)$ is a constant function; how can I find the value of $h(x)$? Could anyone please explain?,,"['calculus', 'trigonometry', 'derivatives']"
22,How does calculus without Euler's number (e) look? [closed],How does calculus without Euler's number (e) look? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'm starting to study calculus and I've become very interested in Euler's number ($e$). I understand that the property of being its own derivative makes it the ""natural"" base to work on for studying rates of change. However, I was wondering what would happen if we pretended not to know about the existence of $e$. Would trying to find the derivative of something like $a^x$ lead us into finding the definition of $e$ or is it possible to avoid $e$ altogether? In this video it says that not using $e$ in calculus leads to some pretty crazy math. What does that math look like?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'm starting to study calculus and I've become very interested in Euler's number ($e$). I understand that the property of being its own derivative makes it the ""natural"" base to work on for studying rates of change. However, I was wondering what would happen if we pretended not to know about the existence of $e$. Would trying to find the derivative of something like $a^x$ lead us into finding the definition of $e$ or is it possible to avoid $e$ altogether? In this video it says that not using $e$ in calculus leads to some pretty crazy math. What does that math look like?",,"['calculus', 'exponential-function']"
23,Limit of $\frac{\log(n!)}{n\log(n)}$ as $n\to\infty$.,Limit of  as .,\frac{\log(n!)}{n\log(n)} n\to\infty,"I can't seem to find a good way to solve this. I tried using L'Hopitals, but the derivative of $\log(n!)$ is really ugly. I know that the answer is 1, but I do not know why the answer is one. Any simple way to go about this?","I can't seem to find a good way to solve this. I tried using L'Hopitals, but the derivative of $\log(n!)$ is really ugly. I know that the answer is 1, but I do not know why the answer is one. Any simple way to go about this?",,"['calculus', 'limits', 'logarithms', 'asymptotics', 'factorial']"
24,Integral $ \dfrac { \int_0^{\pi/2} (\sin x)^{\sqrt 2 + 1} dx} { \int_0^{\pi/2} (\sin x)^{\sqrt 2 - 1} dx} $,Integral, \dfrac { \int_0^{\pi/2} (\sin x)^{\sqrt 2 + 1} dx} { \int_0^{\pi/2} (\sin x)^{\sqrt 2 - 1} dx} ,"I have this difficult integral to solve. $$ \dfrac { \int_0^{\pi/2} (\sin x)^{\sqrt 2 + 1} dx} { \int_0^{\pi/2} (\sin x)^{\sqrt 2 - 1} dx} $$ Now my approach is this: split $(\sin x)^{\sqrt 2 + 1}$ and $(\sin x)^{\sqrt 2 - 1}$ as $(\sin x)^{\sqrt 2}.(\sin x)$ and $(\sin x)^{\sqrt 2 - 2}.(\sin x)$ respectively, and then apply parts. But that doesn't seem to lead anywhere. Hints please! Edit : This is what I did (showing just for the numerator) $$ \int_0^{\pi/2} (\sin x)^{\sqrt 2 + 1} dx $$ $$ = \int_0^{\pi/2} (\sin x)^{\sqrt 2}.(\sin x) dx  $$ $$ = (-\cos x)(\sin x)^{\sqrt 2}\Bigg|_0^{\pi/2} + \int_0^{\pi/2}(\sin x)^{ \sqrt 2 - 1 }(\cos^2 x) dx  $$ (taking $ v = \sin x $ and $ u = (\sin x)^{\sqrt 2} $ in the $ \int uv $ formula) $$ = \int_0^{\pi/2}\left( (\sin x)^{ \sqrt 2 - 1 } - (\sin x)^{ \sqrt 2 + 1 } \right) dx  $$ Similarly for the denominator. This does give a reduction formula but then I don't see how to really use it for finding the answer.","I have this difficult integral to solve. $$ \dfrac { \int_0^{\pi/2} (\sin x)^{\sqrt 2 + 1} dx} { \int_0^{\pi/2} (\sin x)^{\sqrt 2 - 1} dx} $$ Now my approach is this: split $(\sin x)^{\sqrt 2 + 1}$ and $(\sin x)^{\sqrt 2 - 1}$ as $(\sin x)^{\sqrt 2}.(\sin x)$ and $(\sin x)^{\sqrt 2 - 2}.(\sin x)$ respectively, and then apply parts. But that doesn't seem to lead anywhere. Hints please! Edit : This is what I did (showing just for the numerator) $$ \int_0^{\pi/2} (\sin x)^{\sqrt 2 + 1} dx $$ $$ = \int_0^{\pi/2} (\sin x)^{\sqrt 2}.(\sin x) dx  $$ $$ = (-\cos x)(\sin x)^{\sqrt 2}\Bigg|_0^{\pi/2} + \int_0^{\pi/2}(\sin x)^{ \sqrt 2 - 1 }(\cos^2 x) dx  $$ (taking $ v = \sin x $ and $ u = (\sin x)^{\sqrt 2} $ in the $ \int uv $ formula) $$ = \int_0^{\pi/2}\left( (\sin x)^{ \sqrt 2 - 1 } - (\sin x)^{ \sqrt 2 + 1 } \right) dx  $$ Similarly for the denominator. This does give a reduction formula but then I don't see how to really use it for finding the answer.",,"['calculus', 'integration', 'definite-integrals']"
25,Why am I getting a finite integral for infinite area?,Why am I getting a finite integral for infinite area?,,"The following is the graph of the $\tan(x)$ function: We can clearly see there how it’s undefined at $\frac \pi 2$ . Now, what if we wanted to find the area between the tangent function and the x-axis  in the interval $[0, 2]$ ? The following happens: $$\int \tan(x) dx = -\ln|\sec(x)| + c, \quad c\in\mathbb{R}$$ $$\implies \int_{0}^{2} \tan(x) = (-\ln|\sec(2)|) - (-\ln|\sec(0)|)$$ $$\implies (-\ln|\sec(2)|) - (-\ln(1)) = (-\ln|\sec(2)|) + \ln(1)$$ $$ |\sec(2)| = 2.40299796…$$ So what we end up getting is something in the form $$\int_{0}^{2} \tan(x) dx = -\ln(2.40299..) + \ln(1)$$ Which ends up giving us $$-0.87671710853 + 0$$ Which is definitely a finite value! However, when you look at the above graph, you clearly see that there should be infinite area there, as the tangent is asymptotic one unit before there. What’s going on here?","The following is the graph of the function: We can clearly see there how it’s undefined at . Now, what if we wanted to find the area between the tangent function and the x-axis  in the interval ? The following happens: So what we end up getting is something in the form Which ends up giving us Which is definitely a finite value! However, when you look at the above graph, you clearly see that there should be infinite area there, as the tangent is asymptotic one unit before there. What’s going on here?","\tan(x) \frac \pi 2 [0, 2] \int \tan(x) dx = -\ln|\sec(x)| + c, \quad c\in\mathbb{R} \implies \int_{0}^{2} \tan(x) = (-\ln|\sec(2)|) - (-\ln|\sec(0)|) \implies (-\ln|\sec(2)|) - (-\ln(1)) = (-\ln|\sec(2)|) + \ln(1)  |\sec(2)| = 2.40299796… \int_{0}^{2} \tan(x) dx = -\ln(2.40299..) + \ln(1) -0.87671710853 + 0",['calculus']
26,What is the intuition behind the unit normal vector being the derivative of the unit tangent vector?,What is the intuition behind the unit normal vector being the derivative of the unit tangent vector?,,"I've seen the math, but... It just doesn't make sense to me. How is the slope going to point perpendicular to the vector that is clearly a straight line not going in that direction?","I've seen the math, but... It just doesn't make sense to me. How is the slope going to point perpendicular to the vector that is clearly a straight line not going in that direction?",,"['calculus', 'multivariable-calculus', 'vector-analysis']"
27,Are some indefinite integrals impossible to compute or just don't exist? [duplicate],Are some indefinite integrals impossible to compute or just don't exist? [duplicate],,"This question already has answers here : How can you prove that a function has no closed form integral? (7 answers) Closed 4 years ago . I've just started working with integrals relatively recently and I am so surprised how much harder they are to compute than derivatives. For example, for something as seemingly simple as $\int e^{ \cos x} dx $ is impossible right? I can't use u-sub since there is no $-\sin(x)$ multiplying the function, also integration by parts seems like it wouldn't work, correct? So does this mean this integral is impossible to compute?","This question already has answers here : How can you prove that a function has no closed form integral? (7 answers) Closed 4 years ago . I've just started working with integrals relatively recently and I am so surprised how much harder they are to compute than derivatives. For example, for something as seemingly simple as is impossible right? I can't use u-sub since there is no multiplying the function, also integration by parts seems like it wouldn't work, correct? So does this mean this integral is impossible to compute?",\int e^{ \cos x} dx  -\sin(x),"['calculus', 'integration']"
28,How to get more creative in Calculus,How to get more creative in Calculus,,"I'm currently doing Calculus I (one variable and some max- min problems with two variables as well), and I can follow most proofs and understand most of all chapters in the book. It seems tough that when solving problems you really need to be creative, and it is this creativity that I lack at the moment. For instance, limits is of course a good example where it is not enough with just knowing the theory but you also need to be creative to find a solution. It seems like I have to manipulate expressions all the time before actually solving problems (now I'm speaking of calculation problems, not ""show that.."" problems). Is it just me or is there some ""creative structure"" I can follow when solving Calculus problems? There are so many different things to have in mind, and it feels like this course is almost going more on to memorizing formulas rather than actually understand them, which is frustrating. It just seems that knowing the theory really good is not just enough?","I'm currently doing Calculus I (one variable and some max- min problems with two variables as well), and I can follow most proofs and understand most of all chapters in the book. It seems tough that when solving problems you really need to be creative, and it is this creativity that I lack at the moment. For instance, limits is of course a good example where it is not enough with just knowing the theory but you also need to be creative to find a solution. It seems like I have to manipulate expressions all the time before actually solving problems (now I'm speaking of calculation problems, not ""show that.."" problems). Is it just me or is there some ""creative structure"" I can follow when solving Calculus problems? There are so many different things to have in mind, and it feels like this course is almost going more on to memorizing formulas rather than actually understand them, which is frustrating. It just seems that knowing the theory really good is not just enough?",,"['calculus', 'learning']"
29,If $f(x)=f'(x)+f''(x)$ then show that $f(x)=0$,If  then show that,f(x)=f'(x)+f''(x) f(x)=0,"A real-valued function $f$ which is infinitely differentiable on $[a.b]$ has the following properties: $f(a)=f(b)=0$ $f(x)=f'(x)+f''(x)$ $\forall x \in [a,b]$ Show that $f(x)=0$ $\forall x\in [a.b]$ I tried using the Rolle's Theorem , but it only tells me that there exists a $c \in [a.b]$ for which $f'(c)=0$. All I get is: $f'(a)=-f''(a)$ $f'(b)=-f''(b)$ $f(c)=f''(c)$ Somehow none of these direct me to the solution.","A real-valued function $f$ which is infinitely differentiable on $[a.b]$ has the following properties: $f(a)=f(b)=0$ $f(x)=f'(x)+f''(x)$ $\forall x \in [a,b]$ Show that $f(x)=0$ $\forall x\in [a.b]$ I tried using the Rolle's Theorem , but it only tells me that there exists a $c \in [a.b]$ for which $f'(c)=0$. All I get is: $f'(a)=-f''(a)$ $f'(b)=-f''(b)$ $f(c)=f''(c)$ Somehow none of these direct me to the solution.",,"['calculus', 'ordinary-differential-equations']"
30,Infinitely differentiable,Infinitely differentiable,,How can one find if a function $f$ is infinitely differentiable?,How can one find if a function $f$ is infinitely differentiable?,,['calculus']
31,Prove that $\int_0^\pi\frac{\cos x \cos 4x}{(2-\cos x)^2}dx=\frac{\pi}{9} (2160 - 1247\sqrt{3})$,Prove that,\int_0^\pi\frac{\cos x \cos 4x}{(2-\cos x)^2}dx=\frac{\pi}{9} (2160 - 1247\sqrt{3}),Prove that $$\int_0^\pi\frac{\cos x \cos 4x}{(2-\cos x)^2}dx=\frac{\pi}{9} (2160 - 1247\sqrt{3})$$ I tried to use Weierstrass substitution but the term $\cos 4x$ made horrible algebraic-forms since $\cos 4x = \sin^4 x + \cos^4 x - 6\sin^2 x \cos^2 x$. My friend suggests me use a contour integration method but I am not familiar with that method. Any idea? Any help would be appreciated. Thanks in advance.,Prove that $$\int_0^\pi\frac{\cos x \cos 4x}{(2-\cos x)^2}dx=\frac{\pi}{9} (2160 - 1247\sqrt{3})$$ I tried to use Weierstrass substitution but the term $\cos 4x$ made horrible algebraic-forms since $\cos 4x = \sin^4 x + \cos^4 x - 6\sin^2 x \cos^2 x$. My friend suggests me use a contour integration method but I am not familiar with that method. Any idea? Any help would be appreciated. Thanks in advance.,,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'proof-writing']"
32,"Is there a relationship between $\sum _{n=1}^{\infty }\left({\frac {1}{2}}\right)^{n} = 1$ and $\int_{1}^{\infty} \frac{1}{x^2} \,dx = 1$?",Is there a relationship between  and ?,"\sum _{n=1}^{\infty }\left({\frac {1}{2}}\right)^{n} = 1 \int_{1}^{\infty} \frac{1}{x^2} \,dx = 1","A classic example of an infinite series that converges is: ${\displaystyle {\frac {1}{2}}+{\frac {1}{4}}+{\frac {1}{8}}+{\frac {1}{16}}+\cdots =\sum _{n=1}^{\infty }\left({\frac {1}{2}}\right)^{n}=1.}$ A classic example of an infinite integral that converges is: $\displaystyle\int_{1}^{\infty} \frac{1}{x^2} \,dx = 1.$ They feel very similar! But not quite the same. Is there a way to think about one in terms of the other? I ask partly because I want to borrow the nice geometric illustrations that the former converges (like this , or similarly for other geometric series ) to show the latter converging. ( Related question about illustrating the geometry of $\frac{1}{x}$ vs. $\frac{1}{x^2}$ .)","A classic example of an infinite series that converges is: A classic example of an infinite integral that converges is: They feel very similar! But not quite the same. Is there a way to think about one in terms of the other? I ask partly because I want to borrow the nice geometric illustrations that the former converges (like this , or similarly for other geometric series ) to show the latter converging. ( Related question about illustrating the geometry of vs. .)","{\displaystyle {\frac {1}{2}}+{\frac {1}{4}}+{\frac {1}{8}}+{\frac {1}{16}}+\cdots =\sum _{n=1}^{\infty }\left({\frac {1}{2}}\right)^{n}=1.} \displaystyle\int_{1}^{\infty} \frac{1}{x^2} \,dx = 1. \frac{1}{x} \frac{1}{x^2}","['calculus', 'integration', 'convergence-divergence', 'visualization', 'geometric-series']"
33,"Finding $\int_0^{\pi/2} \sin x\,dx$",Finding,"\int_0^{\pi/2} \sin x\,dx","I'm interested in why $$\int_0^{\pi/2} \sin x\,dx = 1.$$ I know how to do the integral the conventional way but am more interested in what makes radians special for this problem. If we instead compute $$\int_{0}^{90} \sin x^\circ\,dx,$$ we won't get $1$ as the answer. What about the definition of radians makes this integral evaluate to $1$? I'm looking for an intuitive (presumably geometric) explanation.","I'm interested in why $$\int_0^{\pi/2} \sin x\,dx = 1.$$ I know how to do the integral the conventional way but am more interested in what makes radians special for this problem. If we instead compute $$\int_{0}^{90} \sin x^\circ\,dx,$$ we won't get $1$ as the answer. What about the definition of radians makes this integral evaluate to $1$? I'm looking for an intuitive (presumably geometric) explanation.",,"['calculus', 'integration', 'trigonometry', 'definite-integrals']"
34,Evaluating the improper integral $\int_0^\infty \frac{x\cos x-\sin x}{x^3} \cos(\frac{x}{2}) \mathrm dx $,Evaluating the improper integral,\int_0^\infty \frac{x\cos x-\sin x}{x^3} \cos(\frac{x}{2}) \mathrm dx ,"I've been working through the following integral and am stumped: $$\int_0^\infty \frac{x\cos x-\sin x}{x^3}\cos\left(\frac{x}{2}\right)\mathrm dx$$ Given the questions in my class that have proceeded and followed this integral, I believe that this is some form of Fourier transform/integral. However, it doesn't look like any of the content surrounding it. That is, there is no $e^{-ikx}$ or $g(k)$ or anything else that I'm familiar with. I know that it's an even function, but that's about as far as I can get. If I try to split it over the subtraction, I get two non-converging integrals, so that wasn't much help either. I've been throwing lots of trig identities at it but nothing familiar has appeared yet. Any help would be greatly appreciated. Thank you.","I've been working through the following integral and am stumped: Given the questions in my class that have proceeded and followed this integral, I believe that this is some form of Fourier transform/integral. However, it doesn't look like any of the content surrounding it. That is, there is no or or anything else that I'm familiar with. I know that it's an even function, but that's about as far as I can get. If I try to split it over the subtraction, I get two non-converging integrals, so that wasn't much help either. I've been throwing lots of trig identities at it but nothing familiar has appeared yet. Any help would be greatly appreciated. Thank you.",\int_0^\infty \frac{x\cos x-\sin x}{x^3}\cos\left(\frac{x}{2}\right)\mathrm dx e^{-ikx} g(k),"['calculus', 'integration', 'fourier-analysis', 'improper-integrals', 'fourier-transform']"
35,Show that $\int_0^\infty \frac{x\log(1+x^2)}{e^{2\pi x}+1}dx=\frac{19}{24} - \frac{23}{24}\log 2 - \frac12\log A$,Show that,\int_0^\infty \frac{x\log(1+x^2)}{e^{2\pi x}+1}dx=\frac{19}{24} - \frac{23}{24}\log 2 - \frac12\log A,"Any idea on how to prove the following integral $$\int_{0}^{\infty} {x\log(1+x^2)\over e^{2\pi x}+1}dx =\require{cancel} \cancel{\frac{17}{24} - \frac{23}{24}\log 2 + \frac{1}{2}\log A}={\frac{19}{24} - \frac{23}{24}\log 2 - \frac{1}{2}\log A }$$ Where $A$ is the Glaisher–Kinkelin constant. We define $$A= \lim_{n \to \infty}\frac{H(n)}{n^{n^2/2+n/2+1/12}e^{-n^2/4}}$$ Where $$H(n) = \prod^{n}_{k=1} k^k $$ I would start by $$F(z) = \int^\infty_0 \frac{2xz}{(x^2+z^2)(e^{2\pi x}+1)} \, dx$$ I know that $$\frac{2t}{e^{2\pi t}-1} =\frac{1}{\pi}-t+\frac{2t^2}{\pi}\sum_{k=1}^\infty\frac{1}{k^2+t^2} $$ But I can't find a similar one for $$\frac{1}{e^{2\pi t}+1}$$","Any idea on how to prove the following integral $$\int_{0}^{\infty} {x\log(1+x^2)\over e^{2\pi x}+1}dx =\require{cancel} \cancel{\frac{17}{24} - \frac{23}{24}\log 2 + \frac{1}{2}\log A}={\frac{19}{24} - \frac{23}{24}\log 2 - \frac{1}{2}\log A }$$ Where $A$ is the Glaisher–Kinkelin constant. We define $$A= \lim_{n \to \infty}\frac{H(n)}{n^{n^2/2+n/2+1/12}e^{-n^2/4}}$$ Where $$H(n) = \prod^{n}_{k=1} k^k $$ I would start by $$F(z) = \int^\infty_0 \frac{2xz}{(x^2+z^2)(e^{2\pi x}+1)} \, dx$$ I know that $$\frac{2t}{e^{2\pi t}-1} =\frac{1}{\pi}-t+\frac{2t^2}{\pi}\sum_{k=1}^\infty\frac{1}{k^2+t^2} $$ But I can't find a similar one for $$\frac{1}{e^{2\pi t}+1}$$",,"['calculus', 'integration', 'definite-integrals']"
36,How to evaluate $\int_0^1 (\arctan x)^2 \ln(\frac{1+x^2}{2x^2}) dx$,How to evaluate,\int_0^1 (\arctan x)^2 \ln(\frac{1+x^2}{2x^2}) dx,"Evaluate $$ \int_{0}^{1} \arctan^{2}\left(\, x\,\right) \ln\left(\, 1 + x^{2} \over 2x^{2}\,\right)\,{\rm d}x $$ I substituted $x \equiv \tan\left(\,\theta\,\right)$ and got $$ -\int^{\pi/4}_{0}\theta^{2}\,{\ln\left(\, 2\sin^{2}\left(\,\theta\,\right)\,\right) \over \cos^{2}\left(\,\theta\,\right)}\,{\rm d}\theta $$ After this, I thought of using the Taylor Expansion of $\ln\left(\, 2\sin^{2}\left(\,\theta\,\right)\,\right)$ near zero but that didn't do any good. Please Help!","Evaluate $$ \int_{0}^{1} \arctan^{2}\left(\, x\,\right) \ln\left(\, 1 + x^{2} \over 2x^{2}\,\right)\,{\rm d}x $$ I substituted $x \equiv \tan\left(\,\theta\,\right)$ and got $$ -\int^{\pi/4}_{0}\theta^{2}\,{\ln\left(\, 2\sin^{2}\left(\,\theta\,\right)\,\right) \over \cos^{2}\left(\,\theta\,\right)}\,{\rm d}\theta $$ After this, I thought of using the Taylor Expansion of $\ln\left(\, 2\sin^{2}\left(\,\theta\,\right)\,\right)$ near zero but that didn't do any good. Please Help!",,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'harmonic-numbers']"
37,Taylor series leads to two different functions - why?,Taylor series leads to two different functions - why?,,"Suppose, I want to find a function such that its Taylor series expansion is $$f(x) = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n}$$ I could start with $$\frac{1}{1-x}=\sum_{n=0}^{\infty}x^n$$ Integrate it, substitute $x\rightarrow  \frac{x}{a}$ , multiply by $a$ and get $$F(x) = -\ln|x-1| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{n+1}$$ $$a F\left(\frac{x}{a}\right) = -a \ln\left|\frac{x}{a}-1\right| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n}$$ On the other hand, I could start with subtituting $x \rightarrow \frac{x}{a}$ before integration to get $$\frac{a}{a-x} = \sum_{n=0}^{\infty}\frac{x^n}{a^n}$$ and then integrate it to get $$-a\ln|x-a| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n}$$ As you can see, arguments of $\ln$ are not equal. Where did it go wrong?","Suppose, I want to find a function such that its Taylor series expansion is I could start with Integrate it, substitute , multiply by and get On the other hand, I could start with subtituting before integration to get and then integrate it to get As you can see, arguments of are not equal. Where did it go wrong?",f(x) = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n} \frac{1}{1-x}=\sum_{n=0}^{\infty}x^n x\rightarrow  \frac{x}{a} a F(x) = -\ln|x-1| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{n+1} a F\left(\frac{x}{a}\right) = -a \ln\left|\frac{x}{a}-1\right| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n} x \rightarrow \frac{x}{a} \frac{a}{a-x} = \sum_{n=0}^{\infty}\frac{x^n}{a^n} -a\ln|x-a| = \sum_{n=0}^{\infty}\frac{x^{n+1}}{(n+1)a^n} \ln,"['calculus', 'taylor-expansion']"
38,Putnam definite integral evaluation $\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx$,Putnam definite integral evaluation,\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx,"Evaluate $$\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx$$ Source : Putnam By the property $\displaystyle \int_0^af(x)\,dx=\int_0^af(a-x)\,dx$: $$=\int_0^{\pi/2}\frac{(\pi/2-x)\sin x\cos x}{\sin^4 x+\cos^4 x}dx=\frac{\pi}{2}\int_0^{\pi/2}\frac{\sin x\cos x}{\sin^4 x+\cos^4 x}dx-\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx$$ $$\Longleftrightarrow\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx=\frac{\pi}{4}\int_0^{\pi/2}\frac{\sin x\cos x}{\sin^4x+\cos^4x}dx$$ Now I'm stuck. WolframAlpha says the indefinite integral of $\dfrac{\sin x\cos x}{\sin^4 x+\cos^4x}$ evaluates nicely to $-\frac12\arctan(\cos(2x))$. I already factored $\sin^4 x+\cos^4 x$ into $1-\left(\frac{\sin(2x)}{\sqrt{2}}\right)^2$, but I don't know how to continue.. I suggest a substitution $u=\frac{\sin(2x)}{\sqrt{2}}$? Could someone provide me a hint , or maybe an easier method I can refer to in the future?","Evaluate $$\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx$$ Source : Putnam By the property $\displaystyle \int_0^af(x)\,dx=\int_0^af(a-x)\,dx$: $$=\int_0^{\pi/2}\frac{(\pi/2-x)\sin x\cos x}{\sin^4 x+\cos^4 x}dx=\frac{\pi}{2}\int_0^{\pi/2}\frac{\sin x\cos x}{\sin^4 x+\cos^4 x}dx-\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx$$ $$\Longleftrightarrow\int_0^{\pi/2}\frac{x\sin x\cos x}{\sin^4 x+\cos^4 x}dx=\frac{\pi}{4}\int_0^{\pi/2}\frac{\sin x\cos x}{\sin^4x+\cos^4x}dx$$ Now I'm stuck. WolframAlpha says the indefinite integral of $\dfrac{\sin x\cos x}{\sin^4 x+\cos^4x}$ evaluates nicely to $-\frac12\arctan(\cos(2x))$. I already factored $\sin^4 x+\cos^4 x$ into $1-\left(\frac{\sin(2x)}{\sqrt{2}}\right)^2$, but I don't know how to continue.. I suggest a substitution $u=\frac{\sin(2x)}{\sqrt{2}}$? Could someone provide me a hint , or maybe an easier method I can refer to in the future?",,"['calculus', 'integration', 'trigonometry', 'definite-integrals']"
39,"A Putnam Integral $\int_2^4 \frac{\sqrt{\ln(9-x)}\,dx}{\sqrt{\ln(9-x)} + \sqrt{\ln(x+3)}}.$",A Putnam Integral,"\int_2^4 \frac{\sqrt{\ln(9-x)}\,dx}{\sqrt{\ln(9-x)} + \sqrt{\ln(x+3)}}.","This is a Putnam Problem that I have been trying to solve (on and off) for two years, but I have failed. I am in Calculus BC. This problem comes from the book ""Calculus Eighth Edition by Larson, Hostetler, and Edwards"". This problem is at the end of the first section of the chapter 8 exercises. Here's the problem: Evaluate $$\int_2^4 \frac{\sqrt{\ln(9-x)}\,dx}{\sqrt{\ln(9-x)} + \sqrt{\ln(x+3)}}.$$ Please. Any help is very much appreciated. So are solutions. Thank you! Edit : I like the solution given, but I was interested to see if there is any other way of doing the problem? I'm excited to see the results.","This is a Putnam Problem that I have been trying to solve (on and off) for two years, but I have failed. I am in Calculus BC. This problem comes from the book ""Calculus Eighth Edition by Larson, Hostetler, and Edwards"". This problem is at the end of the first section of the chapter 8 exercises. Here's the problem: Evaluate $$\int_2^4 \frac{\sqrt{\ln(9-x)}\,dx}{\sqrt{\ln(9-x)} + \sqrt{\ln(x+3)}}.$$ Please. Any help is very much appreciated. So are solutions. Thank you! Edit : I like the solution given, but I was interested to see if there is any other way of doing the problem? I'm excited to see the results.",,"['calculus', 'integration', 'contest-math']"
40,Show that $\int_{0}^{\infty }\frac {\ln x}{x^4+1}\ dx =-\frac{\pi^2 \sqrt{2}}{16}$,Show that,\int_{0}^{\infty }\frac {\ln x}{x^4+1}\ dx =-\frac{\pi^2 \sqrt{2}}{16},"I could prove it using the residues but I'm interested to have it in a different way (for example using Gamma/Beta or any other functions) to show that $$ \int_{0}^{\infty}\frac{\ln\left(x\right)}{x^{4} + 1}\,{\rm d}x =-\frac{\,\pi^{2}\,\sqrt{\,2\,}\,}{16}. $$ Thanks in advance.","I could prove it using the residues but I'm interested to have it in a different way (for example using Gamma/Beta or any other functions) to show that $$ \int_{0}^{\infty}\frac{\ln\left(x\right)}{x^{4} + 1}\,{\rm d}x =-\frac{\,\pi^{2}\,\sqrt{\,2\,}\,}{16}. $$ Thanks in advance.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'gamma-function']"
41,Proving $\int_{0}^{\infty}\frac{x}{(x^2+1)(e^{2\pi x}+1)} dx=1-\frac{\gamma}{2}-\ln2$,Proving,\int_{0}^{\infty}\frac{x}{(x^2+1)(e^{2\pi x}+1)} dx=1-\frac{\gamma}{2}-\ln2,Nowadays I encounter  an integral which is difficult for me to evaluate it. Please help me to evaluate it. Thank you. $$\int_{0}^{\infty}\frac{x}{(x^2+1)(e^{2\pi x}+1)} dx=1-\frac{\gamma}{2}-\ln2$$ where $\gamma$ is The Euler–Mascheroni constant .,Nowadays I encounter  an integral which is difficult for me to evaluate it. Please help me to evaluate it. Thank you. $$\int_{0}^{\infty}\frac{x}{(x^2+1)(e^{2\pi x}+1)} dx=1-\frac{\gamma}{2}-\ln2$$ where $\gamma$ is The Euler–Mascheroni constant .,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
42,Can we find a closed form for $ \int\nolimits_{- \infty}^{\infty} \frac{\exp\left(-(a+bx)^2\right)}{1+\exp(x)}\mathrm dx$?,Can we find a closed form for ?, \int\nolimits_{- \infty}^{\infty} \frac{\exp\left(-(a+bx)^2\right)}{1+\exp(x)}\mathrm dx,Can we find a closed form for this definite integral: $ \int\nolimits_{- \infty}^{\infty} \frac{\exp\left(-(a+bx)^2\right)}{1+\exp(x)}\mathrm dx$ ?,Can we find a closed form for this definite integral: ?, \int\nolimits_{- \infty}^{\infty} \frac{\exp\left(-(a+bx)^2\right)}{1+\exp(x)}\mathrm dx,"['calculus', 'integration', 'definite-integrals']"
43,Differential equations: how does separation of variables really work?,Differential equations: how does separation of variables really work?,,"I'm trying to brush up my differential equations knowledge for an upcoming exam. I watched a set of videos and read few articles on how to solve differential equations via some different methods. One of them was variable separable. It includes separation of all y & x terms on each side of equals and then solving them by integrating both sides. However I remembered what I was taught in my high-school, that $dy/dx$ doesn't act like fraction, instead it is a combination of d/dx * y where y = f(x) None of the videos explained it properly, or should I say - never even brought it up. So I tried to find an explanation via google and stumbled upon a very good one here . The way author has written this article is perfect for my case, however problem is that equations don't render well which doesn't help me to understand it. There are missing operators, signs and other stuff which is making it quite difficult to understand. I would like to ask for a better or equal explanation for my question , even same article explained with proper equations would help.","I'm trying to brush up my differential equations knowledge for an upcoming exam. I watched a set of videos and read few articles on how to solve differential equations via some different methods. One of them was variable separable. It includes separation of all y & x terms on each side of equals and then solving them by integrating both sides. However I remembered what I was taught in my high-school, that $dy/dx$ doesn't act like fraction, instead it is a combination of d/dx * y where y = f(x) None of the videos explained it properly, or should I say - never even brought it up. So I tried to find an explanation via google and stumbled upon a very good one here . The way author has written this article is perfect for my case, however problem is that equations don't render well which doesn't help me to understand it. There are missing operators, signs and other stuff which is making it quite difficult to understand. I would like to ask for a better or equal explanation for my question , even same article explained with proper equations would help.",,"['calculus', 'ordinary-differential-equations']"
44,What is a point?,What is a point?,,"In geometry, what is a point? I have seen Euclid's definition and definitions in some text books. Nowhere have I found a complete notion. And then I made a definition out from everything that I know regarding maths. Now, I need to know what I know is correct or not. One book said, if we make a dot on a paper, it is a model for a point. Another said it has no size. Another said, everybody knows what it is.Another said, if placed one after another makes a straight line.Another said, dimensionless.Another said, can not be seen by any means.","In geometry, what is a point? I have seen Euclid's definition and definitions in some text books. Nowhere have I found a complete notion. And then I made a definition out from everything that I know regarding maths. Now, I need to know what I know is correct or not. One book said, if we make a dot on a paper, it is a model for a point. Another said it has no size. Another said, everybody knows what it is.Another said, if placed one after another makes a straight line.Another said, dimensionless.Another said, can not be seen by any means.",,"['calculus', 'geometry', 'definition', 'euclidean-geometry', 'analytic-geometry']"
45,Evaluating $\int_{0}^{1}\frac{\arcsin{\sqrt{x}}}{x^4-2x^3+2x^2-x+1}\operatorname d\!x$,Evaluating,\int_{0}^{1}\frac{\arcsin{\sqrt{x}}}{x^4-2x^3+2x^2-x+1}\operatorname d\!x,"Find this integral $$\operatorname I=\int\limits_{0}^{1}\dfrac{\arcsin{\sqrt{x}}}{x^4-2x^3+2x^2-x+1}\operatorname d\!x$$ My try: let $$f(x)=x^4-2x^3+2x^2-x+1$$ I found  $$f(1-x)=(1-x)^4-2(1-x)^3+2(1-x)^2-x+1=x^4-2x^3+2x^2-x+1=f(x)$$ so $$I=\int_{0}^{1}\dfrac{\arcsin{\sqrt{(1-x)}}}{x^4-2x^3+2x^2-x+1}dx$$ so $$2I=\int_{0}^{1}\dfrac{\arcsin{\sqrt{x}}+\arcsin{\sqrt{(1-x)}}}{x^4-2x^3+2x^2-x+1}dx$$ then I can't,Thank you very much","Find this integral $$\operatorname I=\int\limits_{0}^{1}\dfrac{\arcsin{\sqrt{x}}}{x^4-2x^3+2x^2-x+1}\operatorname d\!x$$ My try: let $$f(x)=x^4-2x^3+2x^2-x+1$$ I found  $$f(1-x)=(1-x)^4-2(1-x)^3+2(1-x)^2-x+1=x^4-2x^3+2x^2-x+1=f(x)$$ so $$I=\int_{0}^{1}\dfrac{\arcsin{\sqrt{(1-x)}}}{x^4-2x^3+2x^2-x+1}dx$$ so $$2I=\int_{0}^{1}\dfrac{\arcsin{\sqrt{x}}+\arcsin{\sqrt{(1-x)}}}{x^4-2x^3+2x^2-x+1}dx$$ then I can't,Thank you very much",,"['calculus', 'integration']"
46,How to prove that continuous functions are Riemann-integrable?,How to prove that continuous functions are Riemann-integrable?,,"In other words, how to prove A continuous function over a closed interval is Riemann-integrable. That is, if a function $f$ is continuous on an interval $[a, b]$ , then its definite integral over $[a, b]$ exists. Edit: The Definite Integral as a Limit of Riemann Sums : Let $f(x)$ be a function defined on a closed interval $[a, b]$ . We say that a number $I$ is the definite integral of $f$ over $[a, b]$ and that $I$ is the limit of the Riemann sums $\sum \limits_{k=1}^n f(c_k)\Delta x_k$ if the following condition is satisfied: Given any number $\epsilon \gt 0$ , there is a corresponding number $\delta \gt 0$ such that for every partition $P = \{x_0, x_1, ... , x_n\}$ of $[a, b]$ with $\|P \| < \delta$ and any choice of $c_k$ in $[x_{k-1}, x_k]$ , we have $$ \left| \sum_{k=1}^n f(c_k) \Delta x_k - I \ \right| \lt \epsilon .$$","In other words, how to prove A continuous function over a closed interval is Riemann-integrable. That is, if a function is continuous on an interval , then its definite integral over exists. Edit: The Definite Integral as a Limit of Riemann Sums : Let be a function defined on a closed interval . We say that a number is the definite integral of over and that is the limit of the Riemann sums if the following condition is satisfied: Given any number , there is a corresponding number such that for every partition of with and any choice of in , we have","f [a, b] [a, b] f(x) [a, b] I f [a, b] I \sum \limits_{k=1}^n f(c_k)\Delta x_k \epsilon \gt 0 \delta \gt 0 P = \{x_0, x_1, ... , x_n\} [a, b] \|P \| < \delta c_k [x_{k-1}, x_k]  \left| \sum_{k=1}^n f(c_k) \Delta x_k - I \ \right| \lt \epsilon .",['calculus']
47,"Prove that if $\int f^2$ and $\int( f'')^2$ converge, so does $\int (f')^2$","Prove that if  and  converge, so does",\int f^2 \int( f'')^2 \int (f')^2,"Question: Let $f: [a,\infty) \to \Bbb R \in C^2$ and the two following integrals converge:   $$\int _a^\infty (f''(x))^2\,dx ,~~~~~~~~~ \int _a^\infty (f(x))^2\,dx$$ Prove that $\int _a^\infty (f'(x)^2)\,dx$ converges as well. What we tried: Taylor expansion, Lagrange mean value theorem, integration by parts, comparison test, limit comparison test, none really helped us get there...","Question: Let $f: [a,\infty) \to \Bbb R \in C^2$ and the two following integrals converge:   $$\int _a^\infty (f''(x))^2\,dx ,~~~~~~~~~ \int _a^\infty (f(x))^2\,dx$$ Prove that $\int _a^\infty (f'(x)^2)\,dx$ converges as well. What we tried: Taylor expansion, Lagrange mean value theorem, integration by parts, comparison test, limit comparison test, none really helped us get there...",,"['calculus', 'integration', 'improper-integrals']"
48,"Prove that $g(x)=\frac{\ln(S_n (x))}{\ln(S_{n-1}(x))}$ is increasing in $x$, where $S_{n}(x)=\sum_{m=0}^{n}\frac{x^m}{m!}$","Prove that  is increasing in , where",g(x)=\frac{\ln(S_n (x))}{\ln(S_{n-1}(x))} x S_{n}(x)=\sum_{m=0}^{n}\frac{x^m}{m!},"I want to prove that the function  $$g(x)=\frac{\ln(S_n (x))}{\ln(S_{n-1}(x))},\,x >0$$ is increasing in $x$ for all $n$, where  $ S_n(x)= \sum_{m=0}^{n}\frac{x^m}{m!}$. Differentiating gives something messy that I have not been able to prove it is non-negative. I have also been trying to find an appropriate $h(x)$ increasing and proving that $  h(g(x))$ is increasing $\ln(\cdot)$ seems a good candidate. By plotting I am almost convinced the statement is true.","I want to prove that the function  $$g(x)=\frac{\ln(S_n (x))}{\ln(S_{n-1}(x))},\,x >0$$ is increasing in $x$ for all $n$, where  $ S_n(x)= \sum_{m=0}^{n}\frac{x^m}{m!}$. Differentiating gives something messy that I have not been able to prove it is non-negative. I have also been trying to find an appropriate $h(x)$ increasing and proving that $  h(g(x))$ is increasing $\ln(\cdot)$ seems a good candidate. By plotting I am almost convinced the statement is true.",,['calculus']
49,Equation $a^a=b^b$,Equation,a^a=b^b,"Here's the problem: Find all pairs of rational numbers $(a,b)$ such that $0<a<b$ with $a^a=b^b$ . Using some calculus, I was able to find that $0<a<\frac{1}{e}<b<1$ , and I also found one solution $(a,b) = (\frac{1}{4}, \frac{1}{2})$ . I thought it would be the only solution, but I couldn't prove it. How can I go further and solve this problem?","Here's the problem: Find all pairs of rational numbers such that with . Using some calculus, I was able to find that , and I also found one solution . I thought it would be the only solution, but I couldn't prove it. How can I go further and solve this problem?","(a,b) 0<a<b a^a=b^b 0<a<\frac{1}{e}<b<1 (a,b) = (\frac{1}{4}, \frac{1}{2})","['calculus', 'algebra-precalculus']"
50,The notation for partial derivatives,The notation for partial derivatives,,"Today, in my lesson, I was introduced to partial derivatives. One of the things that confuses me is the notation. I hope that I am wrong and hope the community can contribute to my learning. In single-variable calculus, we know that, given a function $y =f(x)$, the derivative of $y$ is denoted as $\frac {dy}{dx}$. I understand this as the relative change in $y$, $\delta y$ given a small change in $x$, $\delta x$. However, in today's lesson on partial derivative, my professor constantly used this notation. Given a function $z = f(x,y)$, the first derivative with respected to $x$ is written as $$ \frac{\partial z}{\partial x} $$ So, for example $$ z = 5x+3y\\ \frac{\partial z}{\partial x} = 5 $$ Why can't I just write it as $$ z = 5x+3y\\ \frac{d z}{d x} = 5 $$ Is it some convention or am I not understanding something in the notation?","Today, in my lesson, I was introduced to partial derivatives. One of the things that confuses me is the notation. I hope that I am wrong and hope the community can contribute to my learning. In single-variable calculus, we know that, given a function $y =f(x)$, the derivative of $y$ is denoted as $\frac {dy}{dx}$. I understand this as the relative change in $y$, $\delta y$ given a small change in $x$, $\delta x$. However, in today's lesson on partial derivative, my professor constantly used this notation. Given a function $z = f(x,y)$, the first derivative with respected to $x$ is written as $$ \frac{\partial z}{\partial x} $$ So, for example $$ z = 5x+3y\\ \frac{\partial z}{\partial x} = 5 $$ Why can't I just write it as $$ z = 5x+3y\\ \frac{d z}{d x} = 5 $$ Is it some convention or am I not understanding something in the notation?",,"['calculus', 'notation', 'partial-derivative']"
51,Change of Variables in Limits (Part 1),Change of Variables in Limits (Part 1),,"After answering this question , I was wondering if the following generalization holds true: Claim: If $\lim \limits_{x\to a}g(x)=b$, then $\lim \limits_{x\to a}f(g(x))=\lim \limits_{y\to b}f(y)$. I've seen some people use this change of variables before when evaluating difficult limits, but I haven't seen this presented as a theorem in a textbook. Is this claim true? If not, is the claim salvageable with additional hypotheses? For example, must $f$ be continuous for the claim to hold?","After answering this question , I was wondering if the following generalization holds true: Claim: If $\lim \limits_{x\to a}g(x)=b$, then $\lim \limits_{x\to a}f(g(x))=\lim \limits_{y\to b}f(y)$. I've seen some people use this change of variables before when evaluating difficult limits, but I haven't seen this presented as a theorem in a textbook. Is this claim true? If not, is the claim salvageable with additional hypotheses? For example, must $f$ be continuous for the claim to hold?",,"['calculus', 'limits']"
52,Maclaurin series of $1- \cos^{2/3} x$ has all coefficients positive,Maclaurin series of  has all coefficients positive,1- \cos^{2/3} x,"Experimenting with WA I noticed that the function $1- \cos^{\frac{2}{3}}x$ has the Maclaurin expansion with all coefficients positive ( works for any exponent in $[0, \frac{2}{3}]$ ). A trivial conclusion from this is $|\cos x|\le 1$ , but it implies more than that, for instance see this .  Maybe   some ''natural'' proofs are available.  Thank you for your interest! Note: an attempt  used a differential equation satisfied by the function. But the answer by @metamorphy just solved it the right way. $\bf{Added:}$ Some comments about series with positive coefficients. By $P$ we denote a series with positive coefficients ( no free term), If $a>0$ then $\frac{1}{(1-P)^a} = 1+P$ (moreover, the positive expression on RHS is a polynomial in $a$ with positive coefficients If $0<a < 1$ then $(1-P)^a = 1-P$ . Similarly the expressions for $a = \frac{t}{t+1}$ are positive in $t$ . 2'. If $1-f= P$ then $1- f^{a} =P$ for any $0 < a < 1$ , and similar with above. $\bf{Added:}$ It turns out that the function $\cos^{2/3} x$ has a continued fraction (an $S$ -fraction, from Stieltjes) that is ""positive"" ( similar to the continued fraction for $\tan x$ ). This is a stronger statement than the one before. Maybe there is some approach  using hypergeometric functions.","Experimenting with WA I noticed that the function has the Maclaurin expansion with all coefficients positive ( works for any exponent in ). A trivial conclusion from this is , but it implies more than that, for instance see this .  Maybe   some ''natural'' proofs are available.  Thank you for your interest! Note: an attempt  used a differential equation satisfied by the function. But the answer by @metamorphy just solved it the right way. Some comments about series with positive coefficients. By we denote a series with positive coefficients ( no free term), If then (moreover, the positive expression on RHS is a polynomial in with positive coefficients If then . Similarly the expressions for are positive in . 2'. If then for any , and similar with above. It turns out that the function has a continued fraction (an -fraction, from Stieltjes) that is ""positive"" ( similar to the continued fraction for ). This is a stronger statement than the one before. Maybe there is some approach  using hypergeometric functions.","1- \cos^{\frac{2}{3}}x [0, \frac{2}{3}] |\cos x|\le 1 \bf{Added:} P a>0 \frac{1}{(1-P)^a} = 1+P a 0<a < 1 (1-P)^a = 1-P a = \frac{t}{t+1} t 1-f= P 1- f^{a} =P 0 < a < 1 \bf{Added:} \cos^{2/3} x S \tan x","['calculus', 'taylor-expansion']"
53,Why is surface area not simply $2 \pi \int_{a}^{b} (y) dx$ instead of $2 \pi \int_a^b (y \cdot \sqrt{1 + y'^2}) dx$?,Why is surface area not simply  instead of ?,2 \pi \int_{a}^{b} (y) dx 2 \pi \int_a^b (y \cdot \sqrt{1 + y'^2}) dx,"Geometrically speaking, it seems to me that if you have for example $y^2=8x$ revolved around the x-axis, taking the limit of the sum of $n$ surfaces of cylinders as $n$ approaches infinity should give you the surface area of that surface of revolution. This is how the author initially derives the formula for finding the volume of solids of revolution. Take a rectangle under the curve over $\Delta x$ and revolve it around the axis to get an approximation of the volume of the solid over that interval. Add up those rectangles over $n$ changes in $x$ and take the limit as $n$ approaches infinity, which is the integral of the function that gives you the $y$ value (radius of that approximating cylinder) for each $x$ value. Following the same principle, why wouldn't we be able to take those same cylinders, but instead of taking their volume, taking their surface area and take the limit as the number of those cylinders approaches zero? In other words, in this case each $y$ value is given by $y = \sqrt{8x}$, which is the radius of that cylinder of height $\Delta x$ and an approximation of the surface area over that interval. Why doesn't that work? Why do we need to deal with arc length? I don't understand why it doesn't work in this case, it seems to me that you're still getting a better and better approximation of surface area as those cylinders get smaller and smaller, eventually getting the exact surface area with the limit as their number goes to infinity. PS: I saw this Surface area of a solid of revolution: Why does not $ \int_{b}^{a} 2\pi \,f(x) \,dx $ work? but it's still not making sense visually/geometrically.","Geometrically speaking, it seems to me that if you have for example $y^2=8x$ revolved around the x-axis, taking the limit of the sum of $n$ surfaces of cylinders as $n$ approaches infinity should give you the surface area of that surface of revolution. This is how the author initially derives the formula for finding the volume of solids of revolution. Take a rectangle under the curve over $\Delta x$ and revolve it around the axis to get an approximation of the volume of the solid over that interval. Add up those rectangles over $n$ changes in $x$ and take the limit as $n$ approaches infinity, which is the integral of the function that gives you the $y$ value (radius of that approximating cylinder) for each $x$ value. Following the same principle, why wouldn't we be able to take those same cylinders, but instead of taking their volume, taking their surface area and take the limit as the number of those cylinders approaches zero? In other words, in this case each $y$ value is given by $y = \sqrt{8x}$, which is the radius of that cylinder of height $\Delta x$ and an approximation of the surface area over that interval. Why doesn't that work? Why do we need to deal with arc length? I don't understand why it doesn't work in this case, it seems to me that you're still getting a better and better approximation of surface area as those cylinders get smaller and smaller, eventually getting the exact surface area with the limit as their number goes to infinity. PS: I saw this Surface area of a solid of revolution: Why does not $ \int_{b}^{a} 2\pi \,f(x) \,dx $ work? but it's still not making sense visually/geometrically.",,"['calculus', 'integration']"
54,A triple integral dancing in the unit cube,A triple integral dancing in the unit cube,,"Straight integration seems pretty tedious and difficult, and I guess the symmetry may open some new ways of which I'm not aware. What would your idea be? Calculate $$\int_0^1 \int_0^1 \int_0^1 \frac{x^2}{\sqrt{x^2+1} \left(x^2-y^2\right) \left(x^2-z^2\right)}+\frac{y^2}{\sqrt{y^2+1} \left(y^2-x^2\right) \left(y^2-z^2\right)}+\frac{z^2}{\sqrt{z^2+1} \left(z^2-x^2\right) \left(z^2-y^2\right)} \, dx \ dy \ dz.$$ A 300 points bounty moment: After 2 years and 10 months since the problem was posed no full solution was provided yet. Is it possible to find a slick solution (like a bolt of lightning)? Good luck!","Straight integration seems pretty tedious and difficult, and I guess the symmetry may open some new ways of which I'm not aware. What would your idea be? Calculate $$\int_0^1 \int_0^1 \int_0^1 \frac{x^2}{\sqrt{x^2+1} \left(x^2-y^2\right) \left(x^2-z^2\right)}+\frac{y^2}{\sqrt{y^2+1} \left(y^2-x^2\right) \left(y^2-z^2\right)}+\frac{z^2}{\sqrt{z^2+1} \left(z^2-x^2\right) \left(z^2-y^2\right)} \, dx \ dy \ dz.$$ A 300 points bounty moment: After 2 years and 10 months since the problem was posed no full solution was provided yet. Is it possible to find a slick solution (like a bolt of lightning)? Good luck!",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'special-functions']"
55,How to integrate $\int_{0}^{\infty }{\frac{\sin x}{\cosh x+\cos x}\cdot \frac{{{x}^{n}}}{n!}\ \text{d}x} $?,How to integrate ?,\int_{0}^{\infty }{\frac{\sin x}{\cosh x+\cos x}\cdot \frac{{{x}^{n}}}{n!}\ \text{d}x} ,"I have done one with $\displaystyle\int_0^{\infty}\frac{x-\sin x}{x^3}\ \text{d}x$, but I have no ideas with these: $$\begin{align*} I&=\int_{0}^{\infty }{\frac{\sin x}{\cosh x+\cos x}\cdot \frac{{{x}^{n}}}{n!}\ \text{d}x}\tag1 \\   J&= \int_{0}^{\infty }{\frac{x-\sin x}{\left( {{\pi }^{2}}+{{x}^{2}} \right){{x}^{3}}}\ \text{d}x}\tag2 \\  \end{align*}$$","I have done one with $\displaystyle\int_0^{\infty}\frac{x-\sin x}{x^3}\ \text{d}x$, but I have no ideas with these: $$\begin{align*} I&=\int_{0}^{\infty }{\frac{\sin x}{\cosh x+\cos x}\cdot \frac{{{x}^{n}}}{n!}\ \text{d}x}\tag1 \\   J&= \int_{0}^{\infty }{\frac{x-\sin x}{\left( {{\pi }^{2}}+{{x}^{2}} \right){{x}^{3}}}\ \text{d}x}\tag2 \\  \end{align*}$$",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
56,Some horrid integrals I am confused with,Some horrid integrals I am confused with,,"$$(1) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x} + 1}{x^3 + 1}}~~dx$$ Speaking as an example on (1). The only thing I could do from here is only to do a u-sub: $$ u = \ln(x) + 1 \\ x = e^{u-1} \\ du = \frac{1}{x} dx \\ dx = x (du) \Rightarrow dx = e^{u-1} (du) $$ And so this becomes: $$ \int \sqrt{ \frac{u}{e^{3u-3} + 1} } ~~ du \\ $$ And from here it's basically a deadend.. I would appreciate if you could give some insights.. Interestingly, these similar integrals have interesting solutions: $$(2) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x} +1}{x^3}}~~dx =  \sqrt{2 e \pi}$$ $$(3) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x}}{x^3 + 1}}~~dx = \text{a complex number ?!}$$ (2) - where and why does the pi comes into play? this looks like an interesting solution.. (3) - why is the solution a complex number if the area is right infront my eyes, and it is real just like every other areas? What is happening here? Mystery solved about the complex number - the lower bound should be $1$ and not $1/e$ my bad! But this is not the main mystery ;) Thank you :-)","Speaking as an example on (1). The only thing I could do from here is only to do a u-sub: And so this becomes: And from here it's basically a deadend.. I would appreciate if you could give some insights.. Interestingly, these similar integrals have interesting solutions: (2) - where and why does the pi comes into play? this looks like an interesting solution.. (3) - why is the solution a complex number if the area is right infront my eyes, and it is real just like every other areas? What is happening here? Mystery solved about the complex number - the lower bound should be and not my bad! But this is not the main mystery ;) Thank you :-)",(1) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x} + 1}{x^3 + 1}}~~dx  u = \ln(x) + 1 \\ x = e^{u-1} \\ du = \frac{1}{x} dx \\ dx = x (du) \Rightarrow dx = e^{u-1} (du)   \int \sqrt{ \frac{u}{e^{3u-3} + 1} } ~~ du \\  (2) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x} +1}{x^3}}~~dx =  \sqrt{2 e \pi} (3) ~~~~ \int_{1/e}^{\infty} \sqrt{\frac{\ln{x}}{x^3 + 1}}~~dx = \text{a complex number ?!} 1 1/e,['calculus']
57,"How can we show that $\int_{-\infty}^{+\infty}{ke^x\pm1\over \pi^2+(e^x-x+1)^2}\cdot{(e^x+1)^2\over \pi^2+(e^x+x+1)^2}\cdot 2x \,\mathrm dx=k?$",How can we show that,"\int_{-\infty}^{+\infty}{ke^x\pm1\over \pi^2+(e^x-x+1)^2}\cdot{(e^x+1)^2\over \pi^2+(e^x+x+1)^2}\cdot 2x \,\mathrm dx=k?","Motivated by this paper . Conjecture: $$\int_{-\infty}^{+\infty}{ke^x\pm1\over \pi^2+(e^x-x+1)^2}\cdot{(e^x+1)^2\over \pi^2+(e^x+x+1)^2}\cdot 2x \,\mathrm dx=k,\tag1$$   where $k$ is a real number. Making an attempt: $u=e^x+1\implies \,\mathrm du=e^x\,\mathrm dx$ and let $k=1$ for simplification, then (1) becomes $$\int_{1}^{\infty}{u^3\over \pi^2+(u-x)^2}\cdot{\ln(u-1)\over \pi^2+(u+x)^2}\cdot{2\mathrm du\over u-1}.\tag2$$ I have no idea where to go from here! I don't think substitution work here, probably using contour integration. How can we prove (1)?","Motivated by this paper . Conjecture: $$\int_{-\infty}^{+\infty}{ke^x\pm1\over \pi^2+(e^x-x+1)^2}\cdot{(e^x+1)^2\over \pi^2+(e^x+x+1)^2}\cdot 2x \,\mathrm dx=k,\tag1$$   where $k$ is a real number. Making an attempt: $u=e^x+1\implies \,\mathrm du=e^x\,\mathrm dx$ and let $k=1$ for simplification, then (1) becomes $$\int_{1}^{\infty}{u^3\over \pi^2+(u-x)^2}\cdot{\ln(u-1)\over \pi^2+(u+x)^2}\cdot{2\mathrm du\over u-1}.\tag2$$ I have no idea where to go from here! I don't think substitution work here, probably using contour integration. How can we prove (1)?",,"['calculus', 'integration', 'definite-integrals', 'contour-integration']"
58,Closed form for n-th anti-derivative of $\log x$,Closed form for n-th anti-derivative of,\log x,"Is it possible to write a closed-form expression with free variables $x, n$ representing the n-th anti-derivative of $\log x$?","Is it possible to write a closed-form expression with free variables $x, n$ representing the n-th anti-derivative of $\log x$?",,"['calculus', 'integration', 'logarithms', 'closed-form']"
59,Proof for exact differential equations shortcut?,Proof for exact differential equations shortcut?,,"Today in my math class, we learned about exact differential equations . During class, our teacher first taught us the accepted way to solve exact equations, but then, told us of a shortcut that one of her students had apparently discovered several years ago, where you integrate both components, and ""merge"" the common terms. For example, if I have the following equation: $(x^2 + y^2)dx +  (2xy + \cos{y})dy = 0$, then the shortcut would be the following: $$\begin{align} \int(x^2 + y^2)dx \;\;\;\;\; & and\;\;\;\;\;\; \int (2xy + \cos{y})dy \\ \frac{1}{3}x^3 + xy^2  \;\;\;\;\; & and\;\;\;\;\;\; xy^2 + \sin{y} \end{align}$$ Because $xy^2$ is a term common to both expressions, I would ""merge"" the equation into the following to get the final solution: $$\frac{1}{3}x^3 + xy^2 + \sin{y} = c$$ Our teacher then told us that neither her nor the student was able to formally prove why this works, and so cautioned us against relying on this (specifically, she told us we were only allowed to use this method to double-check our work in our upcoming quiz). Given that my teacher had difficulties figuring out how this works, I feel ill-equipped to try and prove how and why this works on my own. Can somebody help me understand or prove (or disprove) the validity of this shortcut? Edit: I corrected the final equation from $\frac{1}{3} + xy^2 + \sin{y} = c$ to $\frac{1}{3}x^3 + xy^2 + \sin{y} = c$","Today in my math class, we learned about exact differential equations . During class, our teacher first taught us the accepted way to solve exact equations, but then, told us of a shortcut that one of her students had apparently discovered several years ago, where you integrate both components, and ""merge"" the common terms. For example, if I have the following equation: $(x^2 + y^2)dx +  (2xy + \cos{y})dy = 0$, then the shortcut would be the following: $$\begin{align} \int(x^2 + y^2)dx \;\;\;\;\; & and\;\;\;\;\;\; \int (2xy + \cos{y})dy \\ \frac{1}{3}x^3 + xy^2  \;\;\;\;\; & and\;\;\;\;\;\; xy^2 + \sin{y} \end{align}$$ Because $xy^2$ is a term common to both expressions, I would ""merge"" the equation into the following to get the final solution: $$\frac{1}{3}x^3 + xy^2 + \sin{y} = c$$ Our teacher then told us that neither her nor the student was able to formally prove why this works, and so cautioned us against relying on this (specifically, she told us we were only allowed to use this method to double-check our work in our upcoming quiz). Given that my teacher had difficulties figuring out how this works, I feel ill-equipped to try and prove how and why this works on my own. Can somebody help me understand or prove (or disprove) the validity of this shortcut? Edit: I corrected the final equation from $\frac{1}{3} + xy^2 + \sin{y} = c$ to $\frac{1}{3}x^3 + xy^2 + \sin{y} = c$",,"['calculus', 'ordinary-differential-equations']"
60,Justification of algebraic manipulation of infinitesimals,Justification of algebraic manipulation of infinitesimals,,"As an engineering student, I regularly see people making arguments like this: Consider a rectangle of dimensions $x\times 4x$. If we make $x$ bigger by a small quantity $dx$ then this will make $4x$ bigger by $4\cdot dx$ so the area of that $x \times 4x$ rectangle will change from $4x^2$ to $$(x+dx)(4x+4dx)=4(x^2+2x\cdot dx+(dx)^2)\approx4x^2+8x\cdot dx$$ with the final step justified because $dx$ is a 'small' quantity so $(dx)^2$ will be so small as to be ignorable in some mathematically rigorous way. Thus the change in area $dA$ would be $8x\cdot dx$. Arguments like this are very common. Another random example would be in Wikipedia's proof of the brachistochrone problem which starts with the statement $$ds^2=dx^2+dy^2$$ and proceeds to manipulate these infinitesimals as if they were ordinary constants or variables. I'm wondering if there's a simple, analytically rigorous justification for all of this manipulation. While I feel perfectly comfortable with the idea of the derivative of a function (considered as a limit), I've never seen a similar, rigorous justification for the algebraic manipulation of infinitesimals and the cancellation of 'small' terms (like $(dx)^2$). Any thoughts or help would be appreciated. Thankyou","As an engineering student, I regularly see people making arguments like this: Consider a rectangle of dimensions $x\times 4x$. If we make $x$ bigger by a small quantity $dx$ then this will make $4x$ bigger by $4\cdot dx$ so the area of that $x \times 4x$ rectangle will change from $4x^2$ to $$(x+dx)(4x+4dx)=4(x^2+2x\cdot dx+(dx)^2)\approx4x^2+8x\cdot dx$$ with the final step justified because $dx$ is a 'small' quantity so $(dx)^2$ will be so small as to be ignorable in some mathematically rigorous way. Thus the change in area $dA$ would be $8x\cdot dx$. Arguments like this are very common. Another random example would be in Wikipedia's proof of the brachistochrone problem which starts with the statement $$ds^2=dx^2+dy^2$$ and proceeds to manipulate these infinitesimals as if they were ordinary constants or variables. I'm wondering if there's a simple, analytically rigorous justification for all of this manipulation. While I feel perfectly comfortable with the idea of the derivative of a function (considered as a limit), I've never seen a similar, rigorous justification for the algebraic manipulation of infinitesimals and the cancellation of 'small' terms (like $(dx)^2$). Any thoughts or help would be appreciated. Thankyou",,"['calculus', 'infinitesimals']"
61,Why can partial derivatives be exchanged?,Why can partial derivatives be exchanged?,,"In the Equality of mixed partial derivatives post in this stack exchange, one of the answers to the questions of do partial derivatives commute is: Second order partial derivatives commute if f is $C^2$ (i.e. all the second partial derivatives exist and are continuous). This is sometimes called Schwarz's Theorem or Clairaut's Theorem. This theorem is in my textbooks, yet I cannot seem to find the proof in them. I have tried proving the theorem yet I have gotten stuck. So, what is the proof of Clairaut's Theorem, or why do partial derivatives commute? If the proof is too long, a link to the proof with an intuitive explanation will be sufficient.","In the Equality of mixed partial derivatives post in this stack exchange, one of the answers to the questions of do partial derivatives commute is: Second order partial derivatives commute if f is $C^2$ (i.e. all the second partial derivatives exist and are continuous). This is sometimes called Schwarz's Theorem or Clairaut's Theorem. This theorem is in my textbooks, yet I cannot seem to find the proof in them. I have tried proving the theorem yet I have gotten stuck. So, what is the proof of Clairaut's Theorem, or why do partial derivatives commute? If the proof is too long, a link to the proof with an intuitive explanation will be sufficient.",,['calculus']
62,Is there any method other than Feynman’s trick which can deal further with powers higher than 2?,Is there any method other than Feynman’s trick which can deal further with powers higher than 2?,,"Background When I met the integral $$\int_0^1 \frac{\left(x^\phi-1\right)^2}{\ln ^2 x} d x\\$$ where $\phi$ is the golden ratio: $\phi^2= \phi+1, $ I was surprised by its simple and decent  value  though it is hard to tackle. I had tried some methods such as  substitutions, integration by parts etc. and failed. Then I tried Feynman’s trick by introducing the integral parametrized by $t$ $$I(t)= \int_0^1 \frac{\left(x^t-1\right)^2}{\ln ^2 x} d x\\ $$ As usual differentiating $I(t) $ w.r.t. $t$ once and twice yields $$ I^{\prime}(t)=\int_0^1 \frac{2\left(x^t-1\right) x^t}{\ln x}dx $$ and $$ \begin{aligned} I^{\prime \prime}(t) & =\int_0^1 \left(4x^{2 t}-2x^t\right) d x \\ & =\frac{4}{2 t+1}-\frac{2}{t+1} \end{aligned} $$ Noticing that $I(0)=I^{\prime}(0)=0$ , we can easily integrating back to $I(t)$ in two steps. $$ I^{\prime}(t)-I^{\prime}(0)=\int_0^t I^{\prime \prime}(u) d u=\int_0^t\left(\frac{4}{2 u+1}-\frac{2}{u+1}\right) du $$ $$ I^{\prime}(t)=2\ln (2 t+1)-2 \ln (t+1) $$ Similarly, $$ \begin{aligned} I(t)-I(0) & =\int_0^t I^{\prime}(u) d u =\int_0^t[2\ln (2 u+1)-2 \ln (u+1)] d u \end{aligned} $$ Using the result $\int \ln x d x=x \ln x-x+C$ , we have $$ \boxed{\int_0^1 \frac{\left(x^t-1\right)^2}{\ln ^2 x} d x =(2 t+1) \ln (2 t+1)-2(t+1) \ln (t+1)} $$ Using $\phi^2= \phi+1 $ gives $$I=I(\phi)= (2 \phi+1) \ln \left(\phi^3\right)-2(\phi+1) \ln \left(\phi^2\right)= (2 \phi-1) \ln \phi =(2 \phi-1) \ln \phi =\boxed{\sqrt 5 \ln \phi }$$ My Questions: Is there any method other than Feynman’s trick ? Can we go further with the powers higher than 2?","Background When I met the integral where is the golden ratio: I was surprised by its simple and decent  value  though it is hard to tackle. I had tried some methods such as  substitutions, integration by parts etc. and failed. Then I tried Feynman’s trick by introducing the integral parametrized by As usual differentiating w.r.t. once and twice yields and Noticing that , we can easily integrating back to in two steps. Similarly, Using the result , we have Using gives My Questions: Is there any method other than Feynman’s trick ? Can we go further with the powers higher than 2?","\int_0^1 \frac{\left(x^\phi-1\right)^2}{\ln ^2 x} d x\\ \phi \phi^2= \phi+1,  t I(t)=
\int_0^1 \frac{\left(x^t-1\right)^2}{\ln ^2 x} d x\\
 I(t)  t 
I^{\prime}(t)=\int_0^1 \frac{2\left(x^t-1\right) x^t}{\ln x}dx
 
\begin{aligned}
I^{\prime \prime}(t) & =\int_0^1 \left(4x^{2 t}-2x^t\right) d x \\
& =\frac{4}{2 t+1}-\frac{2}{t+1}
\end{aligned}
 I(0)=I^{\prime}(0)=0 I(t) 
I^{\prime}(t)-I^{\prime}(0)=\int_0^t I^{\prime \prime}(u) d u=\int_0^t\left(\frac{4}{2 u+1}-\frac{2}{u+1}\right) du
 
I^{\prime}(t)=2\ln (2 t+1)-2 \ln (t+1)
 
\begin{aligned}
I(t)-I(0) & =\int_0^t I^{\prime}(u) d u =\int_0^t[2\ln (2 u+1)-2 \ln (u+1)] d u
\end{aligned}
 \int \ln x d x=x \ln x-x+C 
\boxed{\int_0^1 \frac{\left(x^t-1\right)^2}{\ln ^2 x} d x =(2 t+1) \ln (2 t+1)-2(t+1) \ln (t+1)}
 \phi^2= \phi+1  I=I(\phi)= (2 \phi+1) \ln \left(\phi^3\right)-2(\phi+1) \ln \left(\phi^2\right)= (2 \phi-1) \ln \phi =(2 \phi-1) \ln \phi =\boxed{\sqrt 5 \ln \phi }","['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'golden-ratio']"
63,Did Feynman mentally compute $\sqrt[3]{1729.03}$ by linear approximation?,Did Feynman mentally compute  by linear approximation?,\sqrt[3]{1729.03},"In the biopic "" infinity "" about Richard Feynman. (12:54) He computes $\sqrt[3]{1729.03}$ by mental calculation. I guess that he uses linear approximation. That is,  he observe that $1728=12^3$. Let $f(x)=\sqrt[3]{x}$. Then $f'(x)=\frac{1}{3\sqrt[3]{x^2}}$ and $f'(1728)=\frac{1}{3\sqrt[3]{1728^2}}=\frac{1}{3\cdot 12^2}$. Therefore,  $$\sqrt[3]{1729.03}=f(1729.03)\approx f(1728)+f'(1728)(1729.03-1728)=12+\frac{1.03}{3\cdot 12^2}=12.002384\overline{259}.$$ Question 1. If he used the linear approximation,  how did he compute $\frac{1.03}{3\cdot 12^2}=0.002384\overline{259}$ by a mental calculation? Question 2. If he didn't use the linear approximation,  what is another method he might have used?","In the biopic "" infinity "" about Richard Feynman. (12:54) He computes $\sqrt[3]{1729.03}$ by mental calculation. I guess that he uses linear approximation. That is,  he observe that $1728=12^3$. Let $f(x)=\sqrt[3]{x}$. Then $f'(x)=\frac{1}{3\sqrt[3]{x^2}}$ and $f'(1728)=\frac{1}{3\sqrt[3]{1728^2}}=\frac{1}{3\cdot 12^2}$. Therefore,  $$\sqrt[3]{1729.03}=f(1729.03)\approx f(1728)+f'(1728)(1729.03-1728)=12+\frac{1.03}{3\cdot 12^2}=12.002384\overline{259}.$$ Question 1. If he used the linear approximation,  how did he compute $\frac{1.03}{3\cdot 12^2}=0.002384\overline{259}$ by a mental calculation? Question 2. If he didn't use the linear approximation,  what is another method he might have used?",,"['calculus', 'numerical-methods', 'power-series', 'popular-math', 'mental-arithmetic']"
64,When is the limit of a sum equal to the sum of limits?,When is the limit of a sum equal to the sum of limits?,,"I was trying to solve a problem and got stuck at the following step: Suppose ${n \to \infty}$ . $$\lim \limits_{n \to \infty} \frac{n^3}{n^3} = 1$$ Let us rewrite $n^3=n \cdot n^2$ as $n^2 + n^2 + n^2 + n^2 \dots +n^2$,$\space$ n times. Now we have $$\lim \limits_{n \to \infty} \frac{n^3}{n^3} = \frac {n^2 + n^2 + n^2 + n^2 + n^2 \dots +n^2}{n^3} $$ As far as I understand, we can always rewrite the limit of a sum as the sum of limits ... $$\dots = \lim \limits_{n \to \infty} \left(\frac{n^2}{n^3} + \frac{n^2}{n^3} + \dots + \frac{n^2}{n^3}\right)$$ ...but we can only let ${n \to \infty}$ and calculate the limit if all of the individual limits are of defined form ( is this correct? ). That would be the case here, so we have: $= \dots \lim \limits_{n \to \infty} \left(\frac{1}{n} + \frac{1}{n} + \dots + \frac{1}{n}\right) =$[ letting ${n \to \infty}]$ $= 0 + 0 + \dots + 0 = 0$ and the results we get are not the same. Where did I go wrong?","I was trying to solve a problem and got stuck at the following step: Suppose ${n \to \infty}$ . $$\lim \limits_{n \to \infty} \frac{n^3}{n^3} = 1$$ Let us rewrite $n^3=n \cdot n^2$ as $n^2 + n^2 + n^2 + n^2 \dots +n^2$,$\space$ n times. Now we have $$\lim \limits_{n \to \infty} \frac{n^3}{n^3} = \frac {n^2 + n^2 + n^2 + n^2 + n^2 \dots +n^2}{n^3} $$ As far as I understand, we can always rewrite the limit of a sum as the sum of limits ... $$\dots = \lim \limits_{n \to \infty} \left(\frac{n^2}{n^3} + \frac{n^2}{n^3} + \dots + \frac{n^2}{n^3}\right)$$ ...but we can only let ${n \to \infty}$ and calculate the limit if all of the individual limits are of defined form ( is this correct? ). That would be the case here, so we have: $= \dots \lim \limits_{n \to \infty} \left(\frac{1}{n} + \frac{1}{n} + \dots + \frac{1}{n}\right) =$[ letting ${n \to \infty}]$ $= 0 + 0 + \dots + 0 = 0$ and the results we get are not the same. Where did I go wrong?",,"['calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
65,$f(f(\sqrt{2}))=\sqrt{2}$ then f has a fixed point,then f has a fixed point,f(f(\sqrt{2}))=\sqrt{2},$f(x)$  is continuous $f:\mathbb{R}\rightarrow\mathbb{R}$ $f(f(\sqrt{2}))=\sqrt{2}$ Prove that $f$ has a fixed point in other words prove the there is $x_1$ such that $f(x_1)=x_1$ I tried using $g(x)=f(x)-x$ and tried to use the Intermediate value theorem but did not succeed. and it's obvious that $x=\sqrt{2}$ is the answer,$f(x)$  is continuous $f:\mathbb{R}\rightarrow\mathbb{R}$ $f(f(\sqrt{2}))=\sqrt{2}$ Prove that $f$ has a fixed point in other words prove the there is $x_1$ such that $f(x_1)=x_1$ I tried using $g(x)=f(x)-x$ and tried to use the Intermediate value theorem but did not succeed. and it's obvious that $x=\sqrt{2}$ is the answer,,"['calculus', 'continuity']"
66,$\int_{-\infty}^{+\infty}\frac1{1+x^2}\left(\frac{\mathrm d^n}{\mathrm dx^n}e^{-x^2}\right)\mathrm dx$ Evaluate,Evaluate,\int_{-\infty}^{+\infty}\frac1{1+x^2}\left(\frac{\mathrm d^n}{\mathrm dx^n}e^{-x^2}\right)\mathrm dx,"How can I solve this problem? $$ \int_{-\infty}^{+\infty}\frac1{1+x^2}\left(\frac{\mathrm d^n}{\mathrm dx^n}e^{-x^2}\right)\mathrm dx $$","How can I solve this problem? $$ \int_{-\infty}^{+\infty}\frac1{1+x^2}\left(\frac{\mathrm d^n}{\mathrm dx^n}e^{-x^2}\right)\mathrm dx $$",,"['calculus', 'integration', 'definite-integrals']"
67,Exponential of a function times derivative,Exponential of a function times derivative,,"Exponential of a derivative $e^{a\partial}$ is simply a shift operator, i.e. \begin{equation} e^{a\partial}f(x)=f(a+x) \end{equation} This can be easily verified from a Taylor series \begin{equation} e^{a\partial}=\sum_{n=0}^\infty \frac{(a\partial)^n}{n!} \end{equation} and \begin{equation} f(x)=\sum_{n=0}^\infty c_n\frac{x^n}{n!} \end{equation} and applying one on another by using $\partial^mx^n=\frac{n!}{(n-m)!}x^{n-m}$ for $n\ge m$ and zero otherwise. What if, instead of constant $a$, there is a function $g(x)$? In other words, I'm looking for $e^{g(x)\partial}f(x)$. Now, the derivative operator also acts on $g(x)$, which makes things very complicated and and seemingly intractable. For example, $[g(x)\partial]^2=g(x)[g'(x)+g(x)\partial]\partial$ and it gets worse for higher orders. Also, where can I find the list of identities such as $e^{a\partial}f(x)=f(a+x)$? Searching for function (or exponential or logarithm) of a derivative gets clogged with results about derivative of a function (or exponential or logarithm).","Exponential of a derivative $e^{a\partial}$ is simply a shift operator, i.e. \begin{equation} e^{a\partial}f(x)=f(a+x) \end{equation} This can be easily verified from a Taylor series \begin{equation} e^{a\partial}=\sum_{n=0}^\infty \frac{(a\partial)^n}{n!} \end{equation} and \begin{equation} f(x)=\sum_{n=0}^\infty c_n\frac{x^n}{n!} \end{equation} and applying one on another by using $\partial^mx^n=\frac{n!}{(n-m)!}x^{n-m}$ for $n\ge m$ and zero otherwise. What if, instead of constant $a$, there is a function $g(x)$? In other words, I'm looking for $e^{g(x)\partial}f(x)$. Now, the derivative operator also acts on $g(x)$, which makes things very complicated and and seemingly intractable. For example, $[g(x)\partial]^2=g(x)[g'(x)+g(x)\partial]\partial$ and it gets worse for higher orders. Also, where can I find the list of identities such as $e^{a\partial}f(x)=f(a+x)$? Searching for function (or exponential or logarithm) of a derivative gets clogged with results about derivative of a function (or exponential or logarithm).",,"['calculus', 'derivatives', 'operator-theory', 'exponentiation']"
68,How to show that $\int_0^\pi \arcsin{\left(\frac{\sin{x}}{\sqrt{5/4-\cos{x}}}\right)}dx=\frac{\pi^2}{4}$?,How to show that ?,\int_0^\pi \arcsin{\left(\frac{\sin{x}}{\sqrt{5/4-\cos{x}}}\right)}dx=\frac{\pi^2}{4},"I am trying to show that $$\int_0^\pi \arcsin{\left(\frac{\sin{x}}{\sqrt{5/4-\cos{x}}}\right)}dx=\frac{\pi^2}{4}$$ Context: I was working on another question (""Attempt $2$ "") and miscopied an integral, so I was trying to evaluate the integral in my question here. Anyway, now I'm intrigued by this integral, because my computer strongly suggests that it has a closed form, $\frac{\pi^2}{4}$ . My attempt: I have tried substituting $u=\cos{x}$ or $u=\frac{\sin{x}}{\sqrt{5/4-\cos{x}}}$ , and the half-angle tangent substitution , but they do not seem to work. (Ideally, there is an elementary solution, but any solution would be appreciated.)","I am trying to show that Context: I was working on another question (""Attempt "") and miscopied an integral, so I was trying to evaluate the integral in my question here. Anyway, now I'm intrigued by this integral, because my computer strongly suggests that it has a closed form, . My attempt: I have tried substituting or , and the half-angle tangent substitution , but they do not seem to work. (Ideally, there is an elementary solution, but any solution would be appreciated.)",\int_0^\pi \arcsin{\left(\frac{\sin{x}}{\sqrt{5/4-\cos{x}}}\right)}dx=\frac{\pi^2}{4} 2 \frac{\pi^2}{4} u=\cos{x} u=\frac{\sin{x}}{\sqrt{5/4-\cos{x}}},"['calculus', 'trigonometry', 'definite-integrals', 'closed-form']"
69,"Toward ""integrals of rational functions along an algebraic curve""","Toward ""integrals of rational functions along an algebraic curve""",,"In a talk by V.I. Arnold , this is said: When I was a first-year student at the Faculty of Mechanics and Mathematics of the Moscow State University, the lectures on calculus were read by the set-theoretic topologist L.A. Tumarkin, who conscientiously retold the old classical calculus course of French type in the Goursat version. He told us that integrals of rational functions along an algebraic curve can be taken if the corresponding Riemann surface is a sphere and, generally speaking, cannot be taken if its genus is higher, and that for the sphericity it is enough to have a sufficiently large number of double points on the curve of a given degree (which forces the curve to be unicursal: it is possible to draw its real points on the projective plane with one stroke of a pen). I would like to understand the mathematical part of this. What do I need to know to see why this makes sense? Where can I get enough of the background to understand it fully?","In a talk by V.I. Arnold , this is said: When I was a first-year student at the Faculty of Mechanics and Mathematics of the Moscow State University, the lectures on calculus were read by the set-theoretic topologist L.A. Tumarkin, who conscientiously retold the old classical calculus course of French type in the Goursat version. He told us that integrals of rational functions along an algebraic curve can be taken if the corresponding Riemann surface is a sphere and, generally speaking, cannot be taken if its genus is higher, and that for the sphericity it is enough to have a sufficiently large number of double points on the curve of a given degree (which forces the curve to be unicursal: it is possible to draw its real points on the projective plane with one stroke of a pen). I would like to understand the mathematical part of this. What do I need to know to see why this makes sense? Where can I get enough of the background to understand it fully?",,['calculus']
70,Can this definite integral involving series be solved without a calculator?,Can this definite integral involving series be solved without a calculator?,,"I got this question today but I can't see if there is any good way to solve it by hand. Evaluate the definite integral $$\int_2^{12}\frac{\sqrt{x+\sqrt{x+\sqrt{x+...}}}}{\sqrt{x\sqrt{x\sqrt{x}...}}}\,\mathrm{d}x$$ where the series in the numerator and denominator continue infinitely. If you let $y=\sqrt{x+\sqrt{x+\sqrt{x+...}}}=\sqrt{x+y}$ , solving for $y$ we get $y=\frac{1\pm\sqrt{1+4x}}{2}$ . And similarly for the denominator we have $z=\sqrt{xz}$ . So $z=x$ . So the integral simplifies to $$\int_2^{12}\frac{1\pm\sqrt{1+4x}}{2x}\,\mathrm{d}x\,.$$ Now my problems are I don't know what to with the $\pm$ . I tried to solve the integral by separating it as a sum of two fractions. But I can't solve $$\int_2^{12}\frac{\sqrt{1+4x}}{2x}\,\mathrm{d}x\,.$$","I got this question today but I can't see if there is any good way to solve it by hand. Evaluate the definite integral where the series in the numerator and denominator continue infinitely. If you let , solving for we get . And similarly for the denominator we have . So . So the integral simplifies to Now my problems are I don't know what to with the . I tried to solve the integral by separating it as a sum of two fractions. But I can't solve","\int_2^{12}\frac{\sqrt{x+\sqrt{x+\sqrt{x+...}}}}{\sqrt{x\sqrt{x\sqrt{x}...}}}\,\mathrm{d}x y=\sqrt{x+\sqrt{x+\sqrt{x+...}}}=\sqrt{x+y} y y=\frac{1\pm\sqrt{1+4x}}{2} z=\sqrt{xz} z=x \int_2^{12}\frac{1\pm\sqrt{1+4x}}{2x}\,\mathrm{d}x\,. \pm \int_2^{12}\frac{\sqrt{1+4x}}{2x}\,\mathrm{d}x\,.","['calculus', 'integration', 'definite-integrals']"
71,Prove $\pi^2\int_0^\infty\frac{x\sin^4\pi x}{\cos\pi x+\cosh\pi x}dx=e^2\int_0^\infty\frac{x\sin^4ex}{\cos ex+\cosh ex}dx=\frac{176}{225}$,Prove,\pi^2\int_0^\infty\frac{x\sin^4\pi x}{\cos\pi x+\cosh\pi x}dx=e^2\int_0^\infty\frac{x\sin^4ex}{\cos ex+\cosh ex}dx=\frac{176}{225},Marco Cantarini and Jack D'Aurizio proved hard-looking integrals (see Marco and Jack ) in my recent two posts. This is our final hard-looking integral that yield a rational answer: $$\pi^2\int_{0}^{\infty}\frac{x\sin^4(x\pi)}{\cos(x\pi)+\cosh(x\pi)}dx=e^2\int_{0}^{\infty}\frac{x\sin^4(xe)}{\cos(xe)+\cosh(xe)}dx=\frac{176}{225}\tag1$$ Can anyone provide us a prove of $(1)$?,Marco Cantarini and Jack D'Aurizio proved hard-looking integrals (see Marco and Jack ) in my recent two posts. This is our final hard-looking integral that yield a rational answer: $$\pi^2\int_{0}^{\infty}\frac{x\sin^4(x\pi)}{\cos(x\pi)+\cosh(x\pi)}dx=e^2\int_{0}^{\infty}\frac{x\sin^4(xe)}{\cos(xe)+\cosh(xe)}dx=\frac{176}{225}\tag1$$ Can anyone provide us a prove of $(1)$?,,"['calculus', 'integration']"
72,What does smooth curve mean?,What does smooth curve mean?,,"In this problem, I know that the hypothesis of Green's theorem must ensure that the simple closed curve is smooth, but what is smooth? Could you give a definition and an intuitive explanation?","In this problem, I know that the hypothesis of Green's theorem must ensure that the simple closed curve is smooth, but what is smooth? Could you give a definition and an intuitive explanation?",,['calculus']
73,What is the optimum angle of projection when throwing a stone off a cliff?,What is the optimum angle of projection when throwing a stone off a cliff?,,"You are standing on a cliff at a height $h$ above the sea. You are capable of throwing a stone with velocity $v$ at any angle $a$ between horizontal and vertical. What is the value of $a$ when the horizontal distance travelled $d$ is at a maximum? On level ground, when $h$ is zero, it's easy to show that $a$ needs to be midway between horizontal and vertical, and thus $\large\frac{\pi}{4}$ or $45°$. As $h$ increases, however, we can see by heuristic reasoning that $a$ decreases to zero, because you can put more of the velocity into the horizontal component as the height of the cliff begins to make up for the loss in the vertical component. For small negative values of $h$ (throwing up onto a platform), $a$ will actually be greater than $45°$. Is there a fully-solved, closed-form expression for the value of $a$ when $h$ is not zero?","You are standing on a cliff at a height $h$ above the sea. You are capable of throwing a stone with velocity $v$ at any angle $a$ between horizontal and vertical. What is the value of $a$ when the horizontal distance travelled $d$ is at a maximum? On level ground, when $h$ is zero, it's easy to show that $a$ needs to be midway between horizontal and vertical, and thus $\large\frac{\pi}{4}$ or $45°$. As $h$ increases, however, we can see by heuristic reasoning that $a$ decreases to zero, because you can put more of the velocity into the horizontal component as the height of the cliff begins to make up for the loss in the vertical component. For small negative values of $h$ (throwing up onto a platform), $a$ will actually be greater than $45°$. Is there a fully-solved, closed-form expression for the value of $a$ when $h$ is not zero?",,"['calculus', 'trigonometry', 'physics']"
74,Find a number $x$ such that $\sum_{n=1}^\infty\frac{n^x}{2^n n!} = \frac{1539}{64}e^{1/2}$,Find a number  such that,x \sum_{n=1}^\infty\frac{n^x}{2^n n!} = \frac{1539}{64}e^{1/2},I need to find a number $x$ such that $$\sum_{n=1}^\infty\frac{n^x}{2^n n!} = \frac{1539}{64}e^{1/2}.$$ What is the best approach to this problem?,I need to find a number $x$ such that $$\sum_{n=1}^\infty\frac{n^x}{2^n n!} = \frac{1539}{64}e^{1/2}.$$ What is the best approach to this problem?,,"['calculus', 'sequences-and-series', 'transcendental-equations']"
75,Fourier transform of $\operatorname{erfc}^3\left|x\right|$,Fourier transform of,\operatorname{erfc}^3\left|x\right|,"(this is a follow-up on my another question ) Could you please help me to find the Fourier transform of $$f(x)=\operatorname{erfc}^3\left|x\right|,$$ where $\operatorname{erfc}z$ denotes the the complementary error function .","(this is a follow-up on my another question ) Could you please help me to find the Fourier transform of $$f(x)=\operatorname{erfc}^3\left|x\right|,$$ where $\operatorname{erfc}z$ denotes the the complementary error function .",,"['calculus', 'integration', 'fourier-analysis', 'special-functions', 'error-function']"
76,Show that $\int_a^b \sin\left(x+\frac{1}{x}\right) dx <3.$,Show that,\int_a^b \sin\left(x+\frac{1}{x}\right) dx <3.,"Show that $$\int_a^b \sin\left(x+\frac{1}{x}\right) dx <3$$ for all $a,b \in \mathbb{R}.$ Here is my solution: \begin{align*} \int_a^b \sin\left(x+\frac{1}{x}\right) dx&=\int_a^b \left(\sin x\cos \frac{1}{x}+\cos x\sin \frac{1}{x}\right) dx\\ &\le \int_a^b( \sin x+\cos x )dx\\ &=\sqrt{2}\int_a^b \sin \left(x+\frac{\pi}{4}\right)d\left(x+\frac{\pi}{4}\right)\\ &\le2\sqrt{2}<3. \end{align*} But this seems to be incorrect, since we can not guarantee $\sin x,\cos x\ge 0$ in the first line.","Show that for all Here is my solution: But this seems to be incorrect, since we can not guarantee in the first line.","\int_a^b \sin\left(x+\frac{1}{x}\right) dx <3 a,b \in \mathbb{R}. \begin{align*}
\int_a^b \sin\left(x+\frac{1}{x}\right) dx&=\int_a^b \left(\sin x\cos \frac{1}{x}+\cos x\sin \frac{1}{x}\right) dx\\
&\le \int_a^b( \sin x+\cos x )dx\\
&=\sqrt{2}\int_a^b \sin \left(x+\frac{\pi}{4}\right)d\left(x+\frac{\pi}{4}\right)\\
&\le2\sqrt{2}<3.
\end{align*} \sin x,\cos x\ge 0","['calculus', 'integration', 'inequality', 'definite-integrals']"
77,What exactly IS a line integral?,What exactly IS a line integral?,,"As what happens in many math courses, a topic is learned without truly learning what one is doing. For me, this is line integrals. I can do them well, I just never truly learned what exactly I was doing. Can anyone give me (in layman's terms, something extremely basic) a good definition and example of what line integrals are truly evaluating and why we do it? Thank you","As what happens in many math courses, a topic is learned without truly learning what one is doing. For me, this is line integrals. I can do them well, I just never truly learned what exactly I was doing. Can anyone give me (in layman's terms, something extremely basic) a good definition and example of what line integrals are truly evaluating and why we do it? Thank you",,"['calculus', 'integration']"
78,"How to show an infinite number of algebraic numbers $\alpha$ and $\beta$ for $_2F_1\left(\frac13,\frac13;\frac56;-\alpha\right)=\beta\,$?",How to show an infinite number of algebraic numbers  and  for ?,"\alpha \beta _2F_1\left(\frac13,\frac13;\frac56;-\alpha\right)=\beta\,","( Note : This is the case $a=\frac13$ of ${_2F_1\left(a ,a ;a +\tfrac12;-u\right)}=2^{a}\frac{\Gamma\big(a+\tfrac12\big)}{\sqrt\pi\,\Gamma(a)}\int_0^\infty\frac{dx}{(1+2u+\cosh x)^a}.\,$ There is also $a=\frac14$ and $a=\frac16$ .) In a post , Reshetnikov considered some integrals and the surprising evaluations, $$ \frac{1}{48^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[3]{x^2+\color{blue}{4}x^3}}=\,_2F_1\big(\tfrac{1}{3},\tfrac{1}{3};\tfrac{5}{6};-\color{blue}{4}\big)= \frac3{5^{5/6}}\tag1$$ $$ \frac{1}{48^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[3]{x^2+\color{blue}{27}x^3}}=\,_2F_1\big(\tfrac{1}{3},\tfrac{1}{3};\tfrac{5}{6};-\color{blue}{27}\big)=\frac{4}{7}\tag2$$ We postulate these are just the first of an infinite family of algebraic numbers $\alpha$ and $\beta$ such that, $$_2F_1\left(\frac13,\frac13;\frac56;-\alpha\right)=\beta\tag3$$ $$\begin{array}{|c|c|c|c|c|} \hline p&\tau&\alpha&\beta&\text{Deg}\\ \hline 3&\frac{1+3\sqrt{-3}}2& \large \frac13& \large \frac{2}{3^{2/3}}&1\\ 5&\frac{1+5\sqrt{-3}}2&\color{blue}{4}& \large\frac3{5^{5/6}}  &1\\ 7&\frac{1+7\sqrt{-3}}2&\color{blue}{27}&\large\frac47&1\\ 11&\frac{1+11\sqrt{-3}}2& \sqrt{11}\big(2\sqrt3 + \sqrt{11}\big)^3& \large\frac6{11^{11/12}} \frac1{U_{33}^{1/4}} &2 \\ 13&\frac{1+13\sqrt{-3}}2& 4\sqrt{13}\big(4 + \sqrt{13}\big)^3&\large\frac7{13}\frac1{U_{13}}&2\\ 17&\frac{1+17\sqrt{-3}}2& \frac4{729}\left[(1 + \sqrt[3]{17})^2 + 6\right]^6& \large\frac9{17^{5/6}}\left(\frac{18}{17^{1/3}}-7\right)^{1/3}&3\\ 19&\frac{1+19\sqrt{-3}}2& \frac1{27}\left[(1 + \sqrt[3]{19})^2 + 5\right]^6 &\large \frac{10}{19} \Big(1-\frac{(1-19^{1/3})^2}{3}\Big)&3\\ 29&\frac{1+29\sqrt{-3}}2& 4(u_1)^6&\frac{15}{29^{5/6}}(u_2)^{1/3}  &5\\ 31&\frac{1+31\sqrt{-3}}2& \frac1{27}( v_1)^6 &\frac{16}{31} (v_2)&5\\ \hline \end{array}$$ and so on, where $U_{13} = \frac{3+\sqrt{13}}2$ , $U_{33} = 23+4\sqrt{33}\,$ are fundamental units , while $u_i$ and $v_i$ are roots of quintics, etc. (While the quintics were solvable in radicals, unfortunately they don't have the simple form as the others. The original forms for $p=17,19$ were found by yours truly while alternative ones were suggested by Reshetnikov.) And $\text{Deg}$ is degree of $\alpha(\tau)$ and $\beta^6(\tau)$ . Conjecture 1: Let $\tau = \frac{1+p\sqrt{-3}}{2}$ . Using the Dedekind eta function quotient $\lambda=\frac{\eta\big(\tfrac{\tau+1}{3}\big)}{\eta(\tau)}$ , then $\alpha$ is just a quadratic, $$16\cdot27\,\alpha(1+\alpha)=\left( \lambda^6 -27\, \lambda^{-6} \right)^2$$ or more simply, $$\alpha = \frac1{4\sqrt{27}}\big(\lambda^3-\sqrt{27}\,\lambda^{-3}\big)^2\tag4$$ And if $p=6k\pm1$ is a prime, then $\alpha$ and $\beta^6$ of $(3)$ are algebraic numbers of degree $k$ . Alternatively, one can use the well-known j-function $j(\tau)$ , $$j(\tau) = {1 \over q} + 744 + 196884 q + 21493760 q^2 + 864299970 q^3+\dots$$ which is easily calculated in Mathematica as 12^3KleinInvariantJ[tau]. Conjecture 2: Let $\tau = \frac{1+p\sqrt{-3}}{2}$ . Then $\alpha$ is an appropriate root of, $$j(\tau) = \frac{432}{1+f}\left(\frac{5+4f}{1 - f}\right)^3,\quad \text{where}\quad f = \frac{2\alpha+1}{2\sqrt{\alpha(1+\alpha)}}$$ P.S. Conjecture 2 is indebted to the answer by Noam Elkies , though the nature of $\tau$ which should provide the correct $\alpha(\tau)$ seems to have been left out.","( Note : This is the case of There is also and .) In a post , Reshetnikov considered some integrals and the surprising evaluations, We postulate these are just the first of an infinite family of algebraic numbers and such that, and so on, where , are fundamental units , while and are roots of quintics, etc. (While the quintics were solvable in radicals, unfortunately they don't have the simple form as the others. The original forms for were found by yours truly while alternative ones were suggested by Reshetnikov.) And is degree of and . Conjecture 1: Let . Using the Dedekind eta function quotient , then is just a quadratic, or more simply, And if is a prime, then and of are algebraic numbers of degree . Alternatively, one can use the well-known j-function , which is easily calculated in Mathematica as 12^3KleinInvariantJ[tau]. Conjecture 2: Let . Then is an appropriate root of, P.S. Conjecture 2 is indebted to the answer by Noam Elkies , though the nature of which should provide the correct seems to have been left out.","a=\frac13 {_2F_1\left(a ,a ;a +\tfrac12;-u\right)}=2^{a}\frac{\Gamma\big(a+\tfrac12\big)}{\sqrt\pi\,\Gamma(a)}\int_0^\infty\frac{dx}{(1+2u+\cosh x)^a}.\, a=\frac14 a=\frac16  \frac{1}{48^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[3]{x^2+\color{blue}{4}x^3}}=\,_2F_1\big(\tfrac{1}{3},\tfrac{1}{3};\tfrac{5}{6};-\color{blue}{4}\big)= \frac3{5^{5/6}}\tag1  \frac{1}{48^{1/4}\,K(k_3)}\,\int_0^1 \frac{dx}{\sqrt{1-x}\,\sqrt[3]{x^2+\color{blue}{27}x^3}}=\,_2F_1\big(\tfrac{1}{3},\tfrac{1}{3};\tfrac{5}{6};-\color{blue}{27}\big)=\frac{4}{7}\tag2 \alpha \beta _2F_1\left(\frac13,\frac13;\frac56;-\alpha\right)=\beta\tag3 \begin{array}{|c|c|c|c|c|}
\hline
p&\tau&\alpha&\beta&\text{Deg}\\
\hline
3&\frac{1+3\sqrt{-3}}2& \large \frac13& \large \frac{2}{3^{2/3}}&1\\
5&\frac{1+5\sqrt{-3}}2&\color{blue}{4}& \large\frac3{5^{5/6}}  &1\\
7&\frac{1+7\sqrt{-3}}2&\color{blue}{27}&\large\frac47&1\\
11&\frac{1+11\sqrt{-3}}2& \sqrt{11}\big(2\sqrt3 + \sqrt{11}\big)^3& \large\frac6{11^{11/12}} \frac1{U_{33}^{1/4}} &2 \\
13&\frac{1+13\sqrt{-3}}2& 4\sqrt{13}\big(4 + \sqrt{13}\big)^3&\large\frac7{13}\frac1{U_{13}}&2\\
17&\frac{1+17\sqrt{-3}}2& \frac4{729}\left[(1 + \sqrt[3]{17})^2 + 6\right]^6& \large\frac9{17^{5/6}}\left(\frac{18}{17^{1/3}}-7\right)^{1/3}&3\\
19&\frac{1+19\sqrt{-3}}2& \frac1{27}\left[(1 + \sqrt[3]{19})^2 + 5\right]^6 &\large \frac{10}{19} \Big(1-\frac{(1-19^{1/3})^2}{3}\Big)&3\\
29&\frac{1+29\sqrt{-3}}2& 4(u_1)^6&\frac{15}{29^{5/6}}(u_2)^{1/3}  &5\\
31&\frac{1+31\sqrt{-3}}2& \frac1{27}( v_1)^6 &\frac{16}{31} (v_2)&5\\
\hline
\end{array} U_{13} = \frac{3+\sqrt{13}}2 U_{33} = 23+4\sqrt{33}\, u_i v_i p=17,19 \text{Deg} \alpha(\tau) \beta^6(\tau) \tau = \frac{1+p\sqrt{-3}}{2} \lambda=\frac{\eta\big(\tfrac{\tau+1}{3}\big)}{\eta(\tau)} \alpha 16\cdot27\,\alpha(1+\alpha)=\left( \lambda^6 -27\, \lambda^{-6} \right)^2 \alpha = \frac1{4\sqrt{27}}\big(\lambda^3-\sqrt{27}\,\lambda^{-3}\big)^2\tag4 p=6k\pm1 \alpha \beta^6 (3) k j(\tau) j(\tau) = {1 \over q} + 744 + 196884 q + 21493760 q^2 + 864299970 q^3+\dots \tau = \frac{1+p\sqrt{-3}}{2} \alpha j(\tau) = \frac{432}{1+f}\left(\frac{5+4f}{1 - f}\right)^3,\quad \text{where}\quad f = \frac{2\alpha+1}{2\sqrt{\alpha(1+\alpha)}} \tau \alpha(\tau)","['calculus', 'radicals', 'modular-forms', 'hypergeometric-function', 'conjectures']"
79,Relation between function discontinuities and Fourier transform at infinity,Relation between function discontinuities and Fourier transform at infinity,,"I have made the following assertion a few times in this space without ever having provided a proof: Let $m$ be the smallest number such that a function $f \in L^2(\mathbb{R})$ has a discontinuity in its $m$th derivative.  (That is, the $(m-1)$th and lower derivatives of $f$ are continuous.)  Then $\hat{f}(k) \sim A k^{-(m+1)}$ as $k \rightarrow \infty$, where $$\hat{f}(k) = \int_{-\infty}^{\infty} dx \: f(x) e^{i k x}$$ is the Fourier transform of $f$, and $A$ is a constant. I have looked for a proof of this statement without success.  Does anyone know of such a proof, or if it is not true, a counterexample?","I have made the following assertion a few times in this space without ever having provided a proof: Let $m$ be the smallest number such that a function $f \in L^2(\mathbb{R})$ has a discontinuity in its $m$th derivative.  (That is, the $(m-1)$th and lower derivatives of $f$ are continuous.)  Then $\hat{f}(k) \sim A k^{-(m+1)}$ as $k \rightarrow \infty$, where $$\hat{f}(k) = \int_{-\infty}^{\infty} dx \: f(x) e^{i k x}$$ is the Fourier transform of $f$, and $A$ is a constant. I have looked for a proof of this statement without success.  Does anyone know of such a proof, or if it is not true, a counterexample?",,"['calculus', 'fourier-analysis']"
80,How to evaluate $\int_{0}^{1}{\frac{{{\ln }^{2}}\left( 1-x \right){{\ln }^{2}}\left( 1+x \right)}{1+x}dx}$,How to evaluate,\int_{0}^{1}{\frac{{{\ln }^{2}}\left( 1-x \right){{\ln }^{2}}\left( 1+x \right)}{1+x}dx},"I want to evaluate $$\int_{0}^{1}{\frac{{{\ln }^{2}}\left( 1-x \right){{\ln }^{2}}\left( 1+x \right)}{1+x}dx}$$ I run this integral on Maple, It does converge. How we get a closed form? Is that related to polylogs? $\operatorname{Li}_{5}\left(\frac{1}{2}\right)$","I want to evaluate $$\int_{0}^{1}{\frac{{{\ln }^{2}}\left( 1-x \right){{\ln }^{2}}\left( 1+x \right)}{1+x}dx}$$ I run this integral on Maple, It does converge. How we get a closed form? Is that related to polylogs? $\operatorname{Li}_{5}\left(\frac{1}{2}\right)$",,"['calculus', 'sequences-and-series', 'integration', 'summation']"
81,How to compute the following integral in $n$ variables?,How to compute the following integral in  variables?,n,"How can the following integral be calculated: $$ I_n=\int_0^1\int_0^1\cdots\int_0^1\frac{\prod_{k=1}^{n}\left(\frac{1-x_k}{1+x_k}\right)}{1-\prod_{k=1}^{n}x_k}dx_1\cdots dx_{n-1}dx_n $$ There should be $n$ integral signs, but I didn't know how to write that. It is easy to show that $I_1=\ln(2)$. After partial fractioning and the help of Wolfram Alpha, I managed to show that $I_2=4\ln(2)-2\ln^2(2)-\frac{\pi^2}{6}$. But how to derive a general result? Any help would be highly appreciated! Edit: As a supplementary question, how to calculate this slightly modified integral: $$ J_n=\int_0^1\int_0^1\cdots\int_0^1\frac{\prod_{k=1}^{n}\left(\frac{1-x_k}{1+x_k}\right)}{1+\prod_{k=1}^{n}x_k}dx_1\cdots dx_{n-1}dx_n $$ Again, it can be shown easily, that $J_1=1-\ln(2)$.","How can the following integral be calculated: $$ I_n=\int_0^1\int_0^1\cdots\int_0^1\frac{\prod_{k=1}^{n}\left(\frac{1-x_k}{1+x_k}\right)}{1-\prod_{k=1}^{n}x_k}dx_1\cdots dx_{n-1}dx_n $$ There should be $n$ integral signs, but I didn't know how to write that. It is easy to show that $I_1=\ln(2)$. After partial fractioning and the help of Wolfram Alpha, I managed to show that $I_2=4\ln(2)-2\ln^2(2)-\frac{\pi^2}{6}$. But how to derive a general result? Any help would be highly appreciated! Edit: As a supplementary question, how to calculate this slightly modified integral: $$ J_n=\int_0^1\int_0^1\cdots\int_0^1\frac{\prod_{k=1}^{n}\left(\frac{1-x_k}{1+x_k}\right)}{1+\prod_{k=1}^{n}x_k}dx_1\cdots dx_{n-1}dx_n $$ Again, it can be shown easily, that $J_1=1-\ln(2)$.",,"['calculus', 'products']"
82,"""Continuized"" Taylor Series? $\sin(x)=\sum \frac{(-1)^nx^{2n+1}}{(2n+1)!}=\int_{-1}^\infty \frac{\cos(\pi n) x^{2n+1}}{G(2n+1)}dn$?","""Continuized"" Taylor Series? ?",\sin(x)=\sum \frac{(-1)^nx^{2n+1}}{(2n+1)!}=\int_{-1}^\infty \frac{\cos(\pi n) x^{2n+1}}{G(2n+1)}dn,"~~not trying to reinvent the Laplace transform, but just an exploration into these particular series and integrals~~ Current answers don't fully address the 5 questions, so any new ideas or suggestions would be much appreciated. Thanks for the help! The Taylor Series for $e^x$ is $$\sum \frac{x^n}{n!}$$ Now isn’t this just a discrete sum of functions? What if I use integrals to make a ""continuous"" version of the Taylor series? Following that motivation, I came up with $$E(x)=\int_{-\infty}^\infty \frac{x^n}{G(n)}dn$$ where $G(n)=\Gamma(n+1)=n!$ . Since $\frac{x^n}{G(n)}$ goes to zero as $n\to -1$ , the integral just becomes $$E(x)=\int_{-1}^\infty \frac{x^n}{G(n)}dn$$ I graphed it on Desmos and it looked like this, with the green dotted line being $E(x)$ : After that, I was like ""wow, nice! I wonder if other functions work too”. Naturally, I moved on to $\sin(x)$ , which has power series $$\sum \frac{(-1)^nx^{2n+1}}{(2n+1)!}$$ Unfortunately, this power series is more complicated because of the $(-1)^n$ term. The first thought I came up with is that $\cos(\pi n)$ could be the continuous version of that term. So, one such “continuized” version of the Taylor series for $\sin x$ would be $$S(x)=\int_{-1}^\infty \frac{\cos(\pi n) x^{2n+1}}{G(2n+1)}dn$$ Of course, that's kind of arbitrary, so I did use two other functions: $$c_1(x)=\cos^6\left(\frac{\pi x}{2}\right)-\sin^6\left(\frac{\pi x}{2}\right)$$ which is more ""triangular"", and $$c_2(x)=2\left(1-\sin^6\left(\frac{\pi x}{2}\right)\right)^6-1$$ which is more ""square"". You can see all three of these functions in orange. I made three integrals with each of the three functions, with the dotted green line with the one with $\cos(\pi x)$ . I had to multiply it by a factor of $2$ to get it right, interestingly enough. In both integrals, I made the lower bound a bit higher to avoid crashing my computer and the higher bound low enough to make little to no difference. (accessible here: https://www.desmos.com/calculator/eesis3ykai , though it may take a while to load) The first one has already been addressed here: The function $f(x) = \int_0^\infty \frac{x^t}{\Gamma(t+1)} \, dt$ , so my only contribution is the nice graph. However, the $\sin x$ and $\cos x$ ones I found far more fascinating. Hence, I have a few questions: (1) does $S(x)$ actually converge to $\sin(x)$ ? (2) can we expect this ""integral-Taylor series"" to work on a lot of other functions? Is there some general result? (3) why does $\cos(\pi x)$ work the best compared to the triangle and square waves? Why did the rectangular wave fail so badly? (4) why does the integral have to be stretched by a factor of two, when the $e^x$ integral didn’t have to be? (5) is this approximation for these functions useful? Can this method be applied elsewhere? Is there any use to this outside just ""ooh look at this neat graph""? More cool stuff: I did the same thing with $\cos x$ , and I got similar results (the bounds get shifted a bit though): $$C(x)=\int_{-0.5}^\infty \frac{\cos(\pi n) x^{2n}}{G(2n)}dn$$ (which is accessible here: https://www.desmos.com/calculator/ctjqdxuw0h ) which also has the strange multiplicative factor of $2$ , and the peculiar favorability to $(-1)^n \approx \cos(\pi n)$ . So my above 5 questions still stand.","~~not trying to reinvent the Laplace transform, but just an exploration into these particular series and integrals~~ Current answers don't fully address the 5 questions, so any new ideas or suggestions would be much appreciated. Thanks for the help! The Taylor Series for is Now isn’t this just a discrete sum of functions? What if I use integrals to make a ""continuous"" version of the Taylor series? Following that motivation, I came up with where . Since goes to zero as , the integral just becomes I graphed it on Desmos and it looked like this, with the green dotted line being : After that, I was like ""wow, nice! I wonder if other functions work too”. Naturally, I moved on to , which has power series Unfortunately, this power series is more complicated because of the term. The first thought I came up with is that could be the continuous version of that term. So, one such “continuized” version of the Taylor series for would be Of course, that's kind of arbitrary, so I did use two other functions: which is more ""triangular"", and which is more ""square"". You can see all three of these functions in orange. I made three integrals with each of the three functions, with the dotted green line with the one with . I had to multiply it by a factor of to get it right, interestingly enough. In both integrals, I made the lower bound a bit higher to avoid crashing my computer and the higher bound low enough to make little to no difference. (accessible here: https://www.desmos.com/calculator/eesis3ykai , though it may take a while to load) The first one has already been addressed here: The function $f(x) = \int_0^\infty \frac{x^t}{\Gamma(t+1)} \, dt$ , so my only contribution is the nice graph. However, the and ones I found far more fascinating. Hence, I have a few questions: (1) does actually converge to ? (2) can we expect this ""integral-Taylor series"" to work on a lot of other functions? Is there some general result? (3) why does work the best compared to the triangle and square waves? Why did the rectangular wave fail so badly? (4) why does the integral have to be stretched by a factor of two, when the integral didn’t have to be? (5) is this approximation for these functions useful? Can this method be applied elsewhere? Is there any use to this outside just ""ooh look at this neat graph""? More cool stuff: I did the same thing with , and I got similar results (the bounds get shifted a bit though): (which is accessible here: https://www.desmos.com/calculator/ctjqdxuw0h ) which also has the strange multiplicative factor of , and the peculiar favorability to . So my above 5 questions still stand.",e^x \sum \frac{x^n}{n!} E(x)=\int_{-\infty}^\infty \frac{x^n}{G(n)}dn G(n)=\Gamma(n+1)=n! \frac{x^n}{G(n)} n\to -1 E(x)=\int_{-1}^\infty \frac{x^n}{G(n)}dn E(x) \sin(x) \sum \frac{(-1)^nx^{2n+1}}{(2n+1)!} (-1)^n \cos(\pi n) \sin x S(x)=\int_{-1}^\infty \frac{\cos(\pi n) x^{2n+1}}{G(2n+1)}dn c_1(x)=\cos^6\left(\frac{\pi x}{2}\right)-\sin^6\left(\frac{\pi x}{2}\right) c_2(x)=2\left(1-\sin^6\left(\frac{\pi x}{2}\right)\right)^6-1 \cos(\pi x) 2 \sin x \cos x S(x) \sin(x) \cos(\pi x) e^x \cos x C(x)=\int_{-0.5}^\infty \frac{\cos(\pi n) x^{2n}}{G(2n)}dn 2 (-1)^n \approx \cos(\pi n),"['calculus', 'integration', 'analysis', 'special-functions', 'laplace-transform']"
83,What is the difference between vector-valued functions and parametric equations?,What is the difference between vector-valued functions and parametric equations?,,"So as it is, I'm now starting to cover vector-valued functions in my Calculus III class. While studying the topic, I noticed that it seemed to be the exact same thing as parametric equations. I know that I am probably missing an important difference between the two topics, but I can't seem to figure it out. So the question is: What is the difference between a set of parametric equations and a vector-valued function?","So as it is, I'm now starting to cover vector-valued functions in my Calculus III class. While studying the topic, I noticed that it seemed to be the exact same thing as parametric equations. I know that I am probably missing an important difference between the two topics, but I can't seem to figure it out. So the question is: What is the difference between a set of parametric equations and a vector-valued function?",,"['calculus', 'multivariable-calculus', 'vectors']"
84,Do you know of any Calculus text defining the exponential and logarithm functions in an alternative way?,Do you know of any Calculus text defining the exponential and logarithm functions in an alternative way?,,"The story in nearly every introductory Calculus book is well known by everybody: you don't have the ""right"" to raise a number to an irrational power, so forget exponents for now and let's take a look at $y=x^{-1}$. How odd, the innocent formula for a power function's antiderivative breaks down but gee, it must have an antiderivative, it's smooth! Let's examine its properties... ...and in the end, Rosebud was his sled, no, wait, the mysterious antiderivative turns out to have an inverse that corresponds exactly to the elementary school concept of exponents, only it works for irrational exponents too! The hero wins! The End. But what if we start from the opposite end? Start with the innocent, only-defined-for-rationals (so far) exponential function $y=k^x$, $k>0$, and if $x_0$ is irrational, prove that, as $x$ (while staying rational) approaches $x_0$, $k^x$ approaches some specific real number. Define that such number is $k^{x_0}$. And from there, prove that our New! Improved! $k^x$ is continuous, has a derivative that's also an exponential, that there is some $k=e$ for which the exponential is its own derivative, that the inverse of $e^x$ has $x^{-1}$ as its derivative etc etc... Do you know of any Calculus text that takes that approach?","The story in nearly every introductory Calculus book is well known by everybody: you don't have the ""right"" to raise a number to an irrational power, so forget exponents for now and let's take a look at $y=x^{-1}$. How odd, the innocent formula for a power function's antiderivative breaks down but gee, it must have an antiderivative, it's smooth! Let's examine its properties... ...and in the end, Rosebud was his sled, no, wait, the mysterious antiderivative turns out to have an inverse that corresponds exactly to the elementary school concept of exponents, only it works for irrational exponents too! The hero wins! The End. But what if we start from the opposite end? Start with the innocent, only-defined-for-rationals (so far) exponential function $y=k^x$, $k>0$, and if $x_0$ is irrational, prove that, as $x$ (while staying rational) approaches $x_0$, $k^x$ approaches some specific real number. Define that such number is $k^{x_0}$. And from there, prove that our New! Improved! $k^x$ is continuous, has a derivative that's also an exponential, that there is some $k=e$ for which the exponential is its own derivative, that the inverse of $e^x$ has $x^{-1}$ as its derivative etc etc... Do you know of any Calculus text that takes that approach?",,"['calculus', 'logarithms', 'definition']"
85,Interpretation of $\epsilon$-$\delta$ limit definition,Interpretation of - limit definition,\epsilon \delta,"The epsilon-delta definition for limits states that (from Wikipedia ) for all real $\epsilon > 0$ there exists a real $\delta > 0$ such that for all $x$ with $ 0 < |x − c  | < \delta$, we have $|f(x) − L| < \epsilon$ - however, the definition of the limit requires only the existence of some $\delta>0$ for any $\epsilon>0$. The part I am having trouble understanding is why there are no details as to the ""intuitive"" decrease of the δ as ε grows smaller. I realize that saying that as ε approaches zero δ also approaches zero would use the non-rigorous intuition of a limit in a definition meant to make the limit a rigorous part of mathematics, but why is it unnecessary to show the relationship between epsilon and delta besides the proof of existence? Is there some other implication of a function that I am missing that is the reason only the proof of existence is in this definition? EDIT: If we consider the dependence of on an epsilon on a decreasing delta, can the limit exist if epsilon is increasing as delta decreases? If so, why?","The epsilon-delta definition for limits states that (from Wikipedia ) for all real $\epsilon > 0$ there exists a real $\delta > 0$ such that for all $x$ with $ 0 < |x − c  | < \delta$, we have $|f(x) − L| < \epsilon$ - however, the definition of the limit requires only the existence of some $\delta>0$ for any $\epsilon>0$. The part I am having trouble understanding is why there are no details as to the ""intuitive"" decrease of the δ as ε grows smaller. I realize that saying that as ε approaches zero δ also approaches zero would use the non-rigorous intuition of a limit in a definition meant to make the limit a rigorous part of mathematics, but why is it unnecessary to show the relationship between epsilon and delta besides the proof of existence? Is there some other implication of a function that I am missing that is the reason only the proof of existence is in this definition? EDIT: If we consider the dependence of on an epsilon on a decreasing delta, can the limit exist if epsilon is increasing as delta decreases? If so, why?",,"['calculus', 'limits']"
86,A generalized (MacLaurin's) average for functions,A generalized (MacLaurin's) average for functions,,"The average value of a function $y=f(x)$,  on an interval $[a,b]$, is ${1\over {b-a}}\int_a^b f(t)dt$. This of course relates to the arithmetic average. It is easy to see that a corresponding formula for the geometric average is $\exp\left({1\over {b-a}}\int_a^b \ln(f(t))dt\right)$. There are many other types of averages. In particular the ones motivated by the elementary symmetric polynomials are interesting as they ""mix"" the function values. My question is: How can we evaluate those averages? To be specific, consider a real positive continuous function $y=f(x)$ on $[a,b]$. Create a partition of $n$ sub-intervals of width $\Delta x$. Let $Y=(y_1,y_2,\cdots, y_n)$ be the values of the function $f$ at some point in  those intervals. Define the elementary symmetric polynomials $e_k=e_k(Y)$, for $1\le k \le n$, through $$ \prod_{i=1}^n (t+y_i)= t^n+e_1t^{n-1}+\cdots+e_n. $$  Define the average  $$ a_k(Y)={\root k \of {{e_k} \over {\left (n \atop k \right )}}}. $$ Define $A_\alpha(f)$, the $\alpha$-average of $f$ over $[a,b]$, as the limit of $a_k(Y)$ as $n \to \infty$, $\Delta x \to 0$, and $k/n \to \alpha$. Note $\alpha=0$ corresponds to the arithmetic average and $\alpha=1$ is the geometric average. What do we know about $A_\alpha$ for $0<\alpha <1$? How can we compute it? For example if $f(x)=x$, $[a,b]=[1,2]$, and $\alpha=1/2$ what is $A_\alpha$? Edit 1: Some related inequalities are Maclaurin's and Newton's . Edit 2: I guess the requirement of continuity can be relaxed to piecewise continuity and still have a unique limit.  Finding $A_\alpha$ for the following function, for a given $m>0$, will also be of interest: $$f(x)= \cases { 1  & if  $ \quad 0 \le x \le 1/2$  \cr m & if $ \quad 1/2 < x \le 1$ }.$$","The average value of a function $y=f(x)$,  on an interval $[a,b]$, is ${1\over {b-a}}\int_a^b f(t)dt$. This of course relates to the arithmetic average. It is easy to see that a corresponding formula for the geometric average is $\exp\left({1\over {b-a}}\int_a^b \ln(f(t))dt\right)$. There are many other types of averages. In particular the ones motivated by the elementary symmetric polynomials are interesting as they ""mix"" the function values. My question is: How can we evaluate those averages? To be specific, consider a real positive continuous function $y=f(x)$ on $[a,b]$. Create a partition of $n$ sub-intervals of width $\Delta x$. Let $Y=(y_1,y_2,\cdots, y_n)$ be the values of the function $f$ at some point in  those intervals. Define the elementary symmetric polynomials $e_k=e_k(Y)$, for $1\le k \le n$, through $$ \prod_{i=1}^n (t+y_i)= t^n+e_1t^{n-1}+\cdots+e_n. $$  Define the average  $$ a_k(Y)={\root k \of {{e_k} \over {\left (n \atop k \right )}}}. $$ Define $A_\alpha(f)$, the $\alpha$-average of $f$ over $[a,b]$, as the limit of $a_k(Y)$ as $n \to \infty$, $\Delta x \to 0$, and $k/n \to \alpha$. Note $\alpha=0$ corresponds to the arithmetic average and $\alpha=1$ is the geometric average. What do we know about $A_\alpha$ for $0<\alpha <1$? How can we compute it? For example if $f(x)=x$, $[a,b]=[1,2]$, and $\alpha=1/2$ what is $A_\alpha$? Edit 1: Some related inequalities are Maclaurin's and Newton's . Edit 2: I guess the requirement of continuity can be relaxed to piecewise continuity and still have a unique limit.  Finding $A_\alpha$ for the following function, for a given $m>0$, will also be of interest: $$f(x)= \cases { 1  & if  $ \quad 0 \le x \le 1/2$  \cr m & if $ \quad 1/2 < x \le 1$ }.$$",,"['calculus', 'integration', 'symmetric-polynomials']"
87,Further our knowledge of a certain class of integral involving logarithms.,Further our knowledge of a certain class of integral involving logarithms.,,"$\newcommand{\limitp}{\alpha}\newcommand{\innerp}{\beta}$I  am fascinated by definite integrals. Exploring math.stackexchange, I have found many interesting integrals of the form  $$ \mathcal{J}(b,c,d;\innerp,\limitp) = \int_0^{\limitp} \, \frac{\log{(1+\innerp x^b)}}{(1+x^c)^d}   \ \mathrm{d}x, \qquad \alpha,b,c,d\ge0, $$ the solutions to which have taught me a great deal. Many special cases have been evaluated, some with great difficulty and skill. Here is an attempt to collate and admire some of that work, and perhaps build upon it. Some of the techniques involved include series expansion, contour integration, differentiation with respect to $\innerp$ or maybe even $b$, and the answers often involve the evaluation of Euler sums and Hypergeometric functions, although sometimes it seems these difficulties can be bypassed. My question then, is ""can we build upon the work done in these answers, and develop a more general, complete theory for integrals of this type, or even extend our collection of specific cases?"" If you think you can evaluate a special case in a closed form, or even an interesting conjecture , answer here. Bounty goes to the best or most unique answer. I am particularly interested in larger values of $b,c$ and $d$, although feel free to make any contribution. An easy one to start with, answers use substitution and differentiation with respect to a parameter, $\limitp=1$, $\innerp=1$, $b=1$, $c=2$, $d=1$ An attempt at a more general case, $\limitp=1$, $\innerp=1$, $c=1$, $d=1$ A slightly less general case, $\limitp=\infty$, $\innerp=1$, $b=4n$, $c=2$, $d=1$ Three integrals in one question, with contour integration featuring prominently, $\limitp=\infty$, $\innerp=1$, $b=\left\{2,3,4\right\}$, $c=2$, $d=2$ Involves the golden ratio as a coefficient, $\limitp=1$, $\innerp=\phi$, $b=2$, $c=1$, $d=2$ This one is truly amazing, involves an irrational exponent and fairly heavy number theoretic ideas, $\limitp=1$, $\innerp=1$, $b=2+\sqrt{3}$, $c=1$, $d=1$ Related but slightly more general integrals, some with interesting solutions can be found here and here and here and here and here . In particular, the case when $\limitp=\infty$, $\innerp=1$, $c=2$, $d=2$ seems interesting. Can we evaluate any cases for $b>4$? One case stands out as quite simple, when Mathematica evaluates the case $b=6$, we generate the result $$ \mathcal{J}(6,2,2,1,\infty) = \frac{\pi}{4}\left(2\log 6 - 3\right). $$","$\newcommand{\limitp}{\alpha}\newcommand{\innerp}{\beta}$I  am fascinated by definite integrals. Exploring math.stackexchange, I have found many interesting integrals of the form  $$ \mathcal{J}(b,c,d;\innerp,\limitp) = \int_0^{\limitp} \, \frac{\log{(1+\innerp x^b)}}{(1+x^c)^d}   \ \mathrm{d}x, \qquad \alpha,b,c,d\ge0, $$ the solutions to which have taught me a great deal. Many special cases have been evaluated, some with great difficulty and skill. Here is an attempt to collate and admire some of that work, and perhaps build upon it. Some of the techniques involved include series expansion, contour integration, differentiation with respect to $\innerp$ or maybe even $b$, and the answers often involve the evaluation of Euler sums and Hypergeometric functions, although sometimes it seems these difficulties can be bypassed. My question then, is ""can we build upon the work done in these answers, and develop a more general, complete theory for integrals of this type, or even extend our collection of specific cases?"" If you think you can evaluate a special case in a closed form, or even an interesting conjecture , answer here. Bounty goes to the best or most unique answer. I am particularly interested in larger values of $b,c$ and $d$, although feel free to make any contribution. An easy one to start with, answers use substitution and differentiation with respect to a parameter, $\limitp=1$, $\innerp=1$, $b=1$, $c=2$, $d=1$ An attempt at a more general case, $\limitp=1$, $\innerp=1$, $c=1$, $d=1$ A slightly less general case, $\limitp=\infty$, $\innerp=1$, $b=4n$, $c=2$, $d=1$ Three integrals in one question, with contour integration featuring prominently, $\limitp=\infty$, $\innerp=1$, $b=\left\{2,3,4\right\}$, $c=2$, $d=2$ Involves the golden ratio as a coefficient, $\limitp=1$, $\innerp=\phi$, $b=2$, $c=1$, $d=2$ This one is truly amazing, involves an irrational exponent and fairly heavy number theoretic ideas, $\limitp=1$, $\innerp=1$, $b=2+\sqrt{3}$, $c=1$, $d=1$ Related but slightly more general integrals, some with interesting solutions can be found here and here and here and here and here . In particular, the case when $\limitp=\infty$, $\innerp=1$, $c=2$, $d=2$ seems interesting. Can we evaluate any cases for $b>4$? One case stands out as quite simple, when Mathematica evaluates the case $b=6$, we generate the result $$ \mathcal{J}(6,2,2,1,\infty) = \frac{\pi}{4}\left(2\log 6 - 3\right). $$",,"['calculus', 'integration', 'definite-integrals', 'contour-integration', 'closed-form']"
88,Prove $\int_0^1 \frac{\ln x\ +\ \ln(\sqrt x\ +\sqrt {1+x})}{\sqrt {1-x^2}} dx=0$,Prove,\int_0^1 \frac{\ln x\ +\ \ln(\sqrt x\ +\sqrt {1+x})}{\sqrt {1-x^2}} dx=0,"If a simple way exists , I am looking to show that $$\boxed{K=\int_0^1 \frac{\ln(x)+\ln(\sqrt x+\sqrt {1+x})}{\sqrt {1-x^2}} dx=0}$$ say, with  symmetry, a clever change of  variables, or  integrations by parts, without evaluating  integrals separately. It is similar to @Zacky question , of proving $$\boxed{\int_0^\frac{\pi}{2}\left(\frac{\pi}{3}-x\right)\frac{\ln(1-\sin x)}{\sin x}dx=0}$$ without calculating separately integrals. If we  take separately $$I=\int_0^1 \frac{\ln(x)}{\sqrt {1-x^2}}dx,\>\>\>\>J=\int_0^1 \frac{\ln(\sqrt x+\sqrt {1+x})}{\sqrt {1-x^2}}dx$$ the integrals $I$ and $J$ define the same series to a sign (two series of opposite sums) $$ I=-\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}},\>\>\>\>\>J=\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}}$$ Explanation By Fourier series $\ln\left(\sqrt{1+\sin x}+\sqrt{\sin x}\right)=\sum_{k=0}^\infty\frac{(2k)!}{4^k(2k+1)(k!)^2}\sin((2k+1)x)$ then $J=\int_0^{\frac{\pi}{2}} \ln\left(\sqrt{\sin t}+\sqrt{1+\sin t}\right)dt=\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}}$ $ I=\int_{0}^{1}\frac{\log(t)}{\sqrt{1-t^{2}}}dt$ We know that $\frac{1}{\sqrt{1-t^{2}}}=\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}}t^{2n} $ and $ \int_{0}^{1}\log(t)t^{2n}dt=-\frac{1}{(2n+1)^{2}}$ then $I=-\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}} $ We can write K as $$K=\int_0^{\dfrac{\pi}{2}} \Big(\ln(\sin t )+\ln\left(\sqrt{\sin t}+\sqrt{1+\sin t}\right)\Big)dt=0 $$ Remark : Wolframalpha can calculate K , but do not know how to calculate $$\int_0^1 \frac{\ln(\sqrt x+\sqrt {1+x})}{\sqrt {1-x^2}} dx$$ I believe that Wolframe uses a simple way to see that $K$ is zero . same observation for the Zacky’s integral","If a simple way exists , I am looking to show that say, with  symmetry, a clever change of  variables, or  integrations by parts, without evaluating  integrals separately. It is similar to @Zacky question , of proving without calculating separately integrals. If we  take separately the integrals and define the same series to a sign (two series of opposite sums) Explanation By Fourier series then We know that and then We can write K as Remark : Wolframalpha can calculate K , but do not know how to calculate I believe that Wolframe uses a simple way to see that is zero . same observation for the Zacky’s integral","\boxed{K=\int_0^1 \frac{\ln(x)+\ln(\sqrt x+\sqrt {1+x})}{\sqrt {1-x^2}} dx=0} \boxed{\int_0^\frac{\pi}{2}\left(\frac{\pi}{3}-x\right)\frac{\ln(1-\sin x)}{\sin x}dx=0} I=\int_0^1 \frac{\ln(x)}{\sqrt {1-x^2}}dx,\>\>\>\>J=\int_0^1 \frac{\ln(\sqrt x+\sqrt {1+x})}{\sqrt {1-x^2}}dx I J  I=-\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}},\>\>\>\>\>J=\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}} \ln\left(\sqrt{1+\sin x}+\sqrt{\sin x}\right)=\sum_{k=0}^\infty\frac{(2k)!}{4^k(2k+1)(k!)^2}\sin((2k+1)x) J=\int_0^{\frac{\pi}{2}} \ln\left(\sqrt{\sin t}+\sqrt{1+\sin t}\right)dt=\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}}  I=\int_{0}^{1}\frac{\log(t)}{\sqrt{1-t^{2}}}dt \frac{1}{\sqrt{1-t^{2}}}=\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}}t^{2n}   \int_{0}^{1}\log(t)t^{2n}dt=-\frac{1}{(2n+1)^{2}} I=-\sum_{n=0}^{\infty}\frac{{2n \choose n}}{4^{n}(2n+1)^{2}}  K=\int_0^{\dfrac{\pi}{2}} \Big(\ln(\sin t )+\ln\left(\sqrt{\sin t}+\sqrt{1+\sin t}\right)\Big)dt=0  \int_0^1 \frac{\ln(\sqrt x+\sqrt {1+x})}{\sqrt {1-x^2}} dx K","['calculus', 'integration', 'definite-integrals', 'alternative-proof']"
89,Closed form of integral using contour integration,Closed form of integral using contour integration,,"Here is the integral I am interested in evaluating using contour integration: Prove that: $$\int_0^\infty \frac{{\rm d}x}{(1+x^2)(1+x^r)}=\frac{\pi}{4}$$ That is that the above integral is independant of $r$ which is assumed to be a positive real number. I have a couple of approaches using real analysis. For instance, $$\begin{align*} \int_{0}^{\infty}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} &=\int_{0}^{1}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )}+ \int_{1}^{\infty}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} \\   &\overset{u=1/x}{=\! =\! =\!}\int_{0}^{1}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} +\int_{0}^{1}\frac{x^r}{\left ( x^2+1 \right )\left ( 1+x^r \right )}\, {\rm d}x \\   &= \require{cancel} \int_{0}^{1}\frac{\cancel{x^r+1}}{\left ( x^2+1 \right )\cancel{\left ( x^r+1 \right )}}\, {\rm d}x \\  &= \int_{0}^{1}\frac{{\rm d}x}{x^2+1}\\  &= \arctan 1 = \frac{\pi}{4} \end{align*}$$ or by applying the sub $x=\tan u$ we have that: $$\begin{align*} \int_{0}^{\infty}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} &\overset{x=\tan u}{=\! =\! =\! =\!}\int_{0}^{\pi/2}\frac{\sec^2 u}{\left ( 1+\tan^2 u \right )\left ( 1+\tan^r u \right )}\, {\rm d}u \\   &=\int_{0}^{\pi/2}\frac{{\rm d}u}{1+\tan^r u} \\   &= \int_{0}^{\pi/2}\frac{{\rm d}u}{1+\cot^r u} \end{align*}$$ Since $\cot u = 1/\tan u$ the last integral is evaluated easily again at $\pi/4$. A third approach would be to kill it directly with the sub $u=1/x$ which leads to, if we name the initial integral $I$, $$I= \frac{\pi}{2}-I$$ and the result follows. Now, what I am interested in here is to evaluate this using contour integration. I have a feeling that the contour will be a wedge shaped contour with some angle, let me call that $\omega$, but that $r$ cause some problems. Therefore I don't know how to integrate it using complex analysis. Any help appreciated.","Here is the integral I am interested in evaluating using contour integration: Prove that: $$\int_0^\infty \frac{{\rm d}x}{(1+x^2)(1+x^r)}=\frac{\pi}{4}$$ That is that the above integral is independant of $r$ which is assumed to be a positive real number. I have a couple of approaches using real analysis. For instance, $$\begin{align*} \int_{0}^{\infty}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} &=\int_{0}^{1}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )}+ \int_{1}^{\infty}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} \\   &\overset{u=1/x}{=\! =\! =\!}\int_{0}^{1}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} +\int_{0}^{1}\frac{x^r}{\left ( x^2+1 \right )\left ( 1+x^r \right )}\, {\rm d}x \\   &= \require{cancel} \int_{0}^{1}\frac{\cancel{x^r+1}}{\left ( x^2+1 \right )\cancel{\left ( x^r+1 \right )}}\, {\rm d}x \\  &= \int_{0}^{1}\frac{{\rm d}x}{x^2+1}\\  &= \arctan 1 = \frac{\pi}{4} \end{align*}$$ or by applying the sub $x=\tan u$ we have that: $$\begin{align*} \int_{0}^{\infty}\frac{{\rm d}x}{\left ( 1+x^2 \right )\left ( 1+x^r \right )} &\overset{x=\tan u}{=\! =\! =\! =\!}\int_{0}^{\pi/2}\frac{\sec^2 u}{\left ( 1+\tan^2 u \right )\left ( 1+\tan^r u \right )}\, {\rm d}u \\   &=\int_{0}^{\pi/2}\frac{{\rm d}u}{1+\tan^r u} \\   &= \int_{0}^{\pi/2}\frac{{\rm d}u}{1+\cot^r u} \end{align*}$$ Since $\cot u = 1/\tan u$ the last integral is evaluated easily again at $\pi/4$. A third approach would be to kill it directly with the sub $u=1/x$ which leads to, if we name the initial integral $I$, $$I= \frac{\pi}{2}-I$$ and the result follows. Now, what I am interested in here is to evaluate this using contour integration. I have a feeling that the contour will be a wedge shaped contour with some angle, let me call that $\omega$, but that $r$ cause some problems. Therefore I don't know how to integrate it using complex analysis. Any help appreciated.",,"['calculus', 'improper-integrals', 'contour-integration']"
90,Evaluation of $\int\frac{(1+x^2)(2+x^2)}{(x\cos x+\sin x)^4}dx$,Evaluation of,\int\frac{(1+x^2)(2+x^2)}{(x\cos x+\sin x)^4}dx,"Evaluation of $$\int\frac{(1+x^2)(2+x^2)}{(x\cos x+\sin x)^4}dx$$ $\bf{My\; Try::}$ We can write $$x\cos x+\sin x= \sqrt{1+x^2}\left\{\frac{x}{\sqrt{1+x^2}}\cdot \cos x+\frac{1}{\sqrt{1+x^2}}\cdot \sin x\right\}$$ So we get $$(x\cos x+\sin x) = \sqrt{1+x^2}\cos(x-\alpha)\;,$$ Where $\displaystyle \alpha = \tan^{-1}\left(\frac{1}{x}\right)$ So Integral $$I = \int\frac{(1+x^2)(2+x^2)}{(1+x^2)^2\cdot \cos^4 (x-\alpha)}dx = \int\frac{(2+x^2)}{(1+x^2)}\cdot \sec^4 (x-\alpha)dx$$ Now how can i solve after that,Help me Thanks","Evaluation of $$\int\frac{(1+x^2)(2+x^2)}{(x\cos x+\sin x)^4}dx$$ $\bf{My\; Try::}$ We can write $$x\cos x+\sin x= \sqrt{1+x^2}\left\{\frac{x}{\sqrt{1+x^2}}\cdot \cos x+\frac{1}{\sqrt{1+x^2}}\cdot \sin x\right\}$$ So we get $$(x\cos x+\sin x) = \sqrt{1+x^2}\cos(x-\alpha)\;,$$ Where $\displaystyle \alpha = \tan^{-1}\left(\frac{1}{x}\right)$ So Integral $$I = \int\frac{(1+x^2)(2+x^2)}{(1+x^2)^2\cdot \cos^4 (x-\alpha)}dx = \int\frac{(2+x^2)}{(1+x^2)}\cdot \sec^4 (x-\alpha)dx$$ Now how can i solve after that,Help me Thanks",,['calculus']
91,Evaluating $\int_0^\infty \frac {\cos {\pi x}} {e^{2\pi \sqrt x} - 1} \mathrm d x$,Evaluating,\int_0^\infty \frac {\cos {\pi x}} {e^{2\pi \sqrt x} - 1} \mathrm d x,"I am trying to show that$$\displaystyle \int_0^\infty \frac {\cos {\pi x}} {e^{2\pi \sqrt x} - 1} \mathrm d x = \dfrac {2 - \sqrt 2} {8}$$ I have verified this numerically on Mathematica. I have tried substituting $u=2\pi\sqrt x$ then using the cosine Maclaurin series and then the $\zeta \left({s}\right) \Gamma \left({s}\right)$ integral formula but this doesn't work because interchanging the sum and the integral isn't valid, and results in a divergent series. I am guessing it is easy with complex analysis, but I am looking for an elementary way if possible.","I am trying to show that$$\displaystyle \int_0^\infty \frac {\cos {\pi x}} {e^{2\pi \sqrt x} - 1} \mathrm d x = \dfrac {2 - \sqrt 2} {8}$$ I have verified this numerically on Mathematica. I have tried substituting $u=2\pi\sqrt x$ then using the cosine Maclaurin series and then the $\zeta \left({s}\right) \Gamma \left({s}\right)$ integral formula but this doesn't work because interchanging the sum and the integral isn't valid, and results in a divergent series. I am guessing it is easy with complex analysis, but I am looking for an elementary way if possible.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
92,How is Laplace transform more efficient?,How is Laplace transform more efficient?,,"I wrote an answer on Laplace Transform , following a series of lectures by Prof.Ali Hajimiri (kindly take a look at the answer, my question is entirely based on that answer). In this answer, though I was able to arrive at the Laplace transform with operational calculus, I had a hard time figuring out what ""applying Laplace Transform on both sides"" meant, from the standpoint of this answer . I mapped out the steps involved in solving a differential equation, $y'(t)=x(t)$ with the operator-method and using the Laplace transform. Operator Method The Operator method: Assuming the inputs $x(t)$ and $y(t)$ are the impulse responses of a system with system operators $X(D)$ and $Y(D)$ , will imply, $Y(D)=H(D)X(D)$ , and then we can find $y(t)$ by reverse mapping. So a convolution in time domain $y(t)=h(t) * x(t)$ ( $h(t)$ is the impulse response of the system) becomes multiplication in ""operator"" domain $Y(D)=H(D)X(D)$ Using Laplace Transform Laplace Transform method : While taking laplace transform on both sides of a differential equation, $y'(t)=x(t)$ in this example, we are assuming y(t), is the impulse response of a system say sys1 and x(t) is the impulse response of another system say sys2 . $Y(D)$ be the system operator of sys1 . Now we need $y'(t)$ , so the system operator becomes $DY(D)$ to produce $y'(t)$ . And $X(D)$ be the system operator of sys2 . Since $y'=x$ the two machines $DY(D)$ and $X(D)$ must be the same. Now if we give an input $e^{st}$ to sys1 and sys2 , we know the system operator for sys1 becomes $sY(s)$ and for sys2 it's $X(s)$ . Now as these two systems are equal, $sY(s)=X(s)$ which implies that $Y(s)=\dfrac{X(s)}{s}$ . Now reverse map $Y(s)$ to obtain $y(t)$ . Is my interpretation correct? As far as I can see, Laplace transform has just complicated things. How does it simplify the process. Why do we use Laplace transform? I understand that this question is highly specific. But if someone can help, it would be highly helpful. Thanks in advance. Example: Consider a differential equation, $y'' + 3y' + 2y = e^{-3t}u(t)$ , with zero initial conditions, where $y$ is function of $t$ and $u(t)$ is the step function, $i)$ Operator Method: $$(D^2+3D + 2)y = e^{-3t}u(t)$$ $$y=\left( \dfrac{1}{D^2+3D + 2}\right) e^{-3t}u(t)$$ Expressing $y$ and $e^{-3t}$ in terms of $\delta(t)$ $$Y(D)\delta(t) = \left( \dfrac{1}{D^2+3D + 2}\right) \left( \dfrac{1}{D+3} \right) \delta(x)$$ $$\implies Y(D) = \dfrac{1}{(D+1)(D+2)(D+3)}$$ $$Y(D) = \dfrac{1/2}{D+1} - \dfrac{1}{D+2}+\dfrac{1/2}{D+3} \tag*{...(1)}$$ Reverse mapping, $$y(t)= \left(\dfrac{e^{-t}}{2} - e^{-2t} + \dfrac{e^{-3t}}{2}\right)u(t)$$ $ii)$ Using Laplace transform: Taking Laplace transform on both sides, $$s^2Y(s) + 3sY(s) + 2Y(s) = \dfrac{1}{s+3}$$ $$Y(s) = \dfrac{1/2}{s+1} - \dfrac{1}{s+2}+\dfrac{1/2}{s+3}$$ We could've replaced $D$ by $s$ , in $(1)$ since the input is of the form $e^{st}$ Now, taking inverse Laplace transform on both sides, $$y(t)= \left(\dfrac{e^{-t}}{2} - e^{-2t} + \dfrac{e^{-3t}}{2}\right)u(t)$$ Note, if the input contained any of the natural frequencies ( $e^-t$ or $e^-2t$ ), we can't use the Laplace transform to obtain the response, but we can still use the operator method . And we can obtain only the forced response with the Laplace, but the operator method also  gives us the natural repsonse. Which again leads me to the question, why is Laplace transform more efficient? In-short, give me an example where, an ODE is unsolvable with the operator-method, but becomes a piece of cake with the Laplace transform. I don't exactly intend to prove that the operator method is superior or something, but I want to know why Laplace is preferred over the operators? In what way, does that work around simplify the journey? When I look at it, we actually need not even take Laplace on both sides to get H(s) we just have to find H(D) and replace D by s, which seems to be relatively easy, isn't it? Edit: Following are the thing(s), I could see, When we use Laplace transform, we have a way to analyse the system's response to various frequencies, just by looking at the transfer function(D replaced by s in system function), as it's a function of input frequency $s$ . That's the only advantage as far as I can see, but I guess I'm not experienced enough to appreciate its significance. The function $e^{st}$ is an Eigen function for the differential operator and the Laplace Transform performs a change of basis in disguise. I don't know how to relate this linear algebra interpretation to this map of operations. Does this mapping of the operations shed some light on how the change of basis takes place, or is it completely unrelated(it can't be)? Someone shared a link, Operator Calculus . That article really gave some insight as to why Laplace overtook Operators, from an historical perspective . Primarily because(as far as I can see) Heaviside really thought it was contemptuous to ""prove"" his methods. But is there no mathematical convenience at all? Sub-question: What actually allows us to use the operator like a variable? Specifics on operator-method: What is the operator method? How to handle time delays? How to handle initial conditions?","I wrote an answer on Laplace Transform , following a series of lectures by Prof.Ali Hajimiri (kindly take a look at the answer, my question is entirely based on that answer). In this answer, though I was able to arrive at the Laplace transform with operational calculus, I had a hard time figuring out what ""applying Laplace Transform on both sides"" meant, from the standpoint of this answer . I mapped out the steps involved in solving a differential equation, with the operator-method and using the Laplace transform. Operator Method The Operator method: Assuming the inputs and are the impulse responses of a system with system operators and , will imply, , and then we can find by reverse mapping. So a convolution in time domain ( is the impulse response of the system) becomes multiplication in ""operator"" domain Using Laplace Transform Laplace Transform method : While taking laplace transform on both sides of a differential equation, in this example, we are assuming y(t), is the impulse response of a system say sys1 and x(t) is the impulse response of another system say sys2 . be the system operator of sys1 . Now we need , so the system operator becomes to produce . And be the system operator of sys2 . Since the two machines and must be the same. Now if we give an input to sys1 and sys2 , we know the system operator for sys1 becomes and for sys2 it's . Now as these two systems are equal, which implies that . Now reverse map to obtain . Is my interpretation correct? As far as I can see, Laplace transform has just complicated things. How does it simplify the process. Why do we use Laplace transform? I understand that this question is highly specific. But if someone can help, it would be highly helpful. Thanks in advance. Example: Consider a differential equation, , with zero initial conditions, where is function of and is the step function, Operator Method: Expressing and in terms of Reverse mapping, Using Laplace transform: Taking Laplace transform on both sides, We could've replaced by , in since the input is of the form Now, taking inverse Laplace transform on both sides, Note, if the input contained any of the natural frequencies ( or ), we can't use the Laplace transform to obtain the response, but we can still use the operator method . And we can obtain only the forced response with the Laplace, but the operator method also  gives us the natural repsonse. Which again leads me to the question, why is Laplace transform more efficient? In-short, give me an example where, an ODE is unsolvable with the operator-method, but becomes a piece of cake with the Laplace transform. I don't exactly intend to prove that the operator method is superior or something, but I want to know why Laplace is preferred over the operators? In what way, does that work around simplify the journey? When I look at it, we actually need not even take Laplace on both sides to get H(s) we just have to find H(D) and replace D by s, which seems to be relatively easy, isn't it? Edit: Following are the thing(s), I could see, When we use Laplace transform, we have a way to analyse the system's response to various frequencies, just by looking at the transfer function(D replaced by s in system function), as it's a function of input frequency . That's the only advantage as far as I can see, but I guess I'm not experienced enough to appreciate its significance. The function is an Eigen function for the differential operator and the Laplace Transform performs a change of basis in disguise. I don't know how to relate this linear algebra interpretation to this map of operations. Does this mapping of the operations shed some light on how the change of basis takes place, or is it completely unrelated(it can't be)? Someone shared a link, Operator Calculus . That article really gave some insight as to why Laplace overtook Operators, from an historical perspective . Primarily because(as far as I can see) Heaviside really thought it was contemptuous to ""prove"" his methods. But is there no mathematical convenience at all? Sub-question: What actually allows us to use the operator like a variable? Specifics on operator-method: What is the operator method? How to handle time delays? How to handle initial conditions?",y'(t)=x(t) x(t) y(t) X(D) Y(D) Y(D)=H(D)X(D) y(t) y(t)=h(t) * x(t) h(t) Y(D)=H(D)X(D) y'(t)=x(t) Y(D) y'(t) DY(D) y'(t) X(D) y'=x DY(D) X(D) e^{st} sY(s) X(s) sY(s)=X(s) Y(s)=\dfrac{X(s)}{s} Y(s) y(t) y'' + 3y' + 2y = e^{-3t}u(t) y t u(t) i) (D^2+3D + 2)y = e^{-3t}u(t) y=\left( \dfrac{1}{D^2+3D + 2}\right) e^{-3t}u(t) y e^{-3t} \delta(t) Y(D)\delta(t) = \left( \dfrac{1}{D^2+3D + 2}\right) \left( \dfrac{1}{D+3} \right) \delta(x) \implies Y(D) = \dfrac{1}{(D+1)(D+2)(D+3)} Y(D) = \dfrac{1/2}{D+1} - \dfrac{1}{D+2}+\dfrac{1/2}{D+3} \tag*{...(1)} y(t)= \left(\dfrac{e^{-t}}{2} - e^{-2t} + \dfrac{e^{-3t}}{2}\right)u(t) ii) s^2Y(s) + 3sY(s) + 2Y(s) = \dfrac{1}{s+3} Y(s) = \dfrac{1/2}{s+1} - \dfrac{1}{s+2}+\dfrac{1/2}{s+3} D s (1) e^{st} y(t)= \left(\dfrac{e^{-t}}{2} - e^{-2t} + \dfrac{e^{-3t}}{2}\right)u(t) e^-t e^-2t s e^{st},"['calculus', 'linear-algebra', 'ordinary-differential-equations', 'operator-theory', 'laplace-transform']"
93,"If any differential equation is given by $f''(x)+f'(x)+f^2(x) = x^2\;,$ Then $f(x)=$",If any differential equation is given by  Then,"f''(x)+f'(x)+f^2(x) = x^2\;, f(x)=","If any differential equation is given by $f''(x)+f'(x)+f^2(x) = x^2\;,$ Then $f(x)=$ $\bf{My\; Try:}$ We can write the above differential  equation as $$e^xf''(x)+e^xf'(x)+e^x\cdot (f(x))^2 = e^x\cdot x^2$$ So $$\frac{d}{dx}\left[e^x\cdot f'(x)\right] = e^x\cdot x^2-e^x(f(x))^2$$ Now How can I proceed after that, help me Thanks.","If any differential equation is given by $f''(x)+f'(x)+f^2(x) = x^2\;,$ Then $f(x)=$ $\bf{My\; Try:}$ We can write the above differential  equation as $$e^xf''(x)+e^xf'(x)+e^x\cdot (f(x))^2 = e^x\cdot x^2$$ So $$\frac{d}{dx}\left[e^x\cdot f'(x)\right] = e^x\cdot x^2-e^x(f(x))^2$$ Now How can I proceed after that, help me Thanks.",,"['calculus', 'integration', 'ordinary-differential-equations']"
94,"Integrate $\int_0^1 \frac{\ln(1+x^a)}{1+x}\, dx$",Integrate,"\int_0^1 \frac{\ln(1+x^a)}{1+x}\, dx","I have recently met with this integral: $$\int_0^1 \frac{\ln(1+x^a)}{1+x}\, dx$$ I want to evaluate it in a closed form, if possible. 1st functional equation: $\displaystyle f(a)=\ln^2 2-f\left ( \frac{1}{a} \right )$ since: $$\begin{aligned} f(a)=\int_{0}^{1}\frac{\ln (1+x^a)}{1+x}\,dx &= \int_{0}^{1}\ln \left ( 1+x^a \right )\left ( \ln (1+x) \right )'\,dx\\ &= \ln^2 2 - \int_{0}^{1}\frac{ax^{a-1}\ln (1+x)}{1+x^a}\,dx\\ &\overset{y=x^a}{=\! =\! =\!}\ln^2 2 - \int_{0}^{1}\frac{a y^{(a-1)/a}\ln \left ( 1+y^{1/a} \right )}{1+y}\frac{1}{a}y^{(1-a)/a}\,dy \\ &= \ln^2 2 -f\left ( \frac{1}{a} \right ) \end{aligned}$$ 2nd functional equation: $\displaystyle f(a)=-\frac{a\pi^2}{12}+f(-a)$ since: $$\begin{aligned} f(a)=\int_{0}^{1}\frac{\ln (1+x^a)}{1+x}\,dx &=\int_{0}^{1}\frac{\ln \left ( x^a\left ( 1+x^{-a} \right ) \right )}{1+x}\,dx \\ &= a\int_{0}^{1}\frac{\ln x}{1+x}\,dx+\int_{0}^{1}\frac{\ln (1+x^{-a})}{1+x}\,dx\\ &= a\int_{0}^{1}\frac{\ln x}{1+x}\,dx+f(-a)\\ &= a\int_{0}^{1}\ln x \sum_{n=0}^{\infty}(-1)^n x^n \,dx +f(-a)\\ &= a\sum_{n=0}^{\infty}(-1)^n \int_{0}^{1}\ln x \cdot x^n \,dx +f(-a)\\  &=\cdots\\ &=-\frac{a\pi^2}{12}+f(-a) \end{aligned}$$ What I did try was: 1st way $$\begin{aligned} \int_{0}^{1}\frac{\log(1+x^a)}{1+x}\,dx &=\int_{0}^{1}\log(1+x^a)\sum_{n=0}^{\infty}(-1)^n x^n\,dx \\ &= \sum_{n=0}^{\infty}(-1)^n \int_{0}^{1}\log(1+x^a)x^n\,dx\\ &= \sum_{n=0}^{\infty}(-1)^n  \{ \left[ \frac{x^{n+1}\log(1+x^a)}{n+1} \right]_0^1- \\ & \quad \quad \quad \quad \quad \frac{a}{n+1}\int_{0}^{1}\frac{x^{n+1}x^{a-1}}{1+x^a}\,dx  \} \end{aligned}$$ 2nd way I tried IBP but I get to an unpleasant integral of the form $\displaystyle \int_{0}^{1}\frac{\ln(1+x)x^{a-1}}{1+x^a}\,dx$. 3nd way It was just an idea ... expand the nominator into Taylor Series , swip integration and summation and get into a digamma form . This way suggests that a closed form is far away ... since we are dealing with digammas here. The result I got was: $$\begin{aligned} \int_{0}^{1}\frac{1}{1+x}\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k}x^{ak} &=\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k}\int_{0}^{1}\frac{x^{ak}}{1+x}dx  \\   &= 1/2\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k}\left[\psi\left(\frac{ak}{2}+1\right)-\psi\left(\frac{ak}{2}+1/2\right)\right] \\  \end{aligned}$$ and I can't go on.","I have recently met with this integral: $$\int_0^1 \frac{\ln(1+x^a)}{1+x}\, dx$$ I want to evaluate it in a closed form, if possible. 1st functional equation: $\displaystyle f(a)=\ln^2 2-f\left ( \frac{1}{a} \right )$ since: $$\begin{aligned} f(a)=\int_{0}^{1}\frac{\ln (1+x^a)}{1+x}\,dx &= \int_{0}^{1}\ln \left ( 1+x^a \right )\left ( \ln (1+x) \right )'\,dx\\ &= \ln^2 2 - \int_{0}^{1}\frac{ax^{a-1}\ln (1+x)}{1+x^a}\,dx\\ &\overset{y=x^a}{=\! =\! =\!}\ln^2 2 - \int_{0}^{1}\frac{a y^{(a-1)/a}\ln \left ( 1+y^{1/a} \right )}{1+y}\frac{1}{a}y^{(1-a)/a}\,dy \\ &= \ln^2 2 -f\left ( \frac{1}{a} \right ) \end{aligned}$$ 2nd functional equation: $\displaystyle f(a)=-\frac{a\pi^2}{12}+f(-a)$ since: $$\begin{aligned} f(a)=\int_{0}^{1}\frac{\ln (1+x^a)}{1+x}\,dx &=\int_{0}^{1}\frac{\ln \left ( x^a\left ( 1+x^{-a} \right ) \right )}{1+x}\,dx \\ &= a\int_{0}^{1}\frac{\ln x}{1+x}\,dx+\int_{0}^{1}\frac{\ln (1+x^{-a})}{1+x}\,dx\\ &= a\int_{0}^{1}\frac{\ln x}{1+x}\,dx+f(-a)\\ &= a\int_{0}^{1}\ln x \sum_{n=0}^{\infty}(-1)^n x^n \,dx +f(-a)\\ &= a\sum_{n=0}^{\infty}(-1)^n \int_{0}^{1}\ln x \cdot x^n \,dx +f(-a)\\  &=\cdots\\ &=-\frac{a\pi^2}{12}+f(-a) \end{aligned}$$ What I did try was: 1st way $$\begin{aligned} \int_{0}^{1}\frac{\log(1+x^a)}{1+x}\,dx &=\int_{0}^{1}\log(1+x^a)\sum_{n=0}^{\infty}(-1)^n x^n\,dx \\ &= \sum_{n=0}^{\infty}(-1)^n \int_{0}^{1}\log(1+x^a)x^n\,dx\\ &= \sum_{n=0}^{\infty}(-1)^n  \{ \left[ \frac{x^{n+1}\log(1+x^a)}{n+1} \right]_0^1- \\ & \quad \quad \quad \quad \quad \frac{a}{n+1}\int_{0}^{1}\frac{x^{n+1}x^{a-1}}{1+x^a}\,dx  \} \end{aligned}$$ 2nd way I tried IBP but I get to an unpleasant integral of the form $\displaystyle \int_{0}^{1}\frac{\ln(1+x)x^{a-1}}{1+x^a}\,dx$. 3nd way It was just an idea ... expand the nominator into Taylor Series , swip integration and summation and get into a digamma form . This way suggests that a closed form is far away ... since we are dealing with digammas here. The result I got was: $$\begin{aligned} \int_{0}^{1}\frac{1}{1+x}\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k}x^{ak} &=\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k}\int_{0}^{1}\frac{x^{ak}}{1+x}dx  \\   &= 1/2\sum_{k=1}^{\infty}\frac{(-1)^{k-1}}{k}\left[\psi\left(\frac{ak}{2}+1\right)-\psi\left(\frac{ak}{2}+1/2\right)\right] \\  \end{aligned}$$ and I can't go on.",,"['calculus', 'sequences-and-series', 'analysis', 'special-functions']"
95,Math Subject GRE 1268 Question 55,Math Subject GRE 1268 Question 55,,"If $a$ and $b$ are positive numbers, what is the value of $\displaystyle \int_0^\infty \frac{e^{ax}-e^{bx}}{(1+e^{ax})(1+e^{bx})}dx$. A: $0$ B: $1$ C: $a-b$ D: $(a-b)\log 2$ E: $\frac{a-b}{ab}\log 2$ I really don't see how to start this one, I'm not so great with integrals.","If $a$ and $b$ are positive numbers, what is the value of $\displaystyle \int_0^\infty \frac{e^{ax}-e^{bx}}{(1+e^{ax})(1+e^{bx})}dx$. A: $0$ B: $1$ C: $a-b$ D: $(a-b)\log 2$ E: $\frac{a-b}{ab}\log 2$ I really don't see how to start this one, I'm not so great with integrals.",,"['calculus', 'integration', 'gre-exam']"
96,How to prove by arithmetical means that $\sum\limits_{k=1}^\infty \frac{((k-1)!)^2}{(2k)!} =\frac{1}{3}\sum\limits_{k=1}^{\infty}\frac{1}{k^{2}}$,How to prove by arithmetical means that,\sum\limits_{k=1}^\infty \frac{((k-1)!)^2}{(2k)!} =\frac{1}{3}\sum\limits_{k=1}^{\infty}\frac{1}{k^{2}},"I've been trying to prove, by arithmetical means, that $$\sum_{k=1}^\infty \frac{((k-1)!)^2}{(2k)!} =\frac{1}{3}\sum_{k=1}^{\infty}\frac{1}{k^{2}}$$ without success. When I say ""by arithmetical means"" I mean to say, go from the left to the right expression just by symbolic manipulation. Can anyone devise a way of doing this?","I've been trying to prove, by arithmetical means, that $$\sum_{k=1}^\infty \frac{((k-1)!)^2}{(2k)!} =\frac{1}{3}\sum_{k=1}^{\infty}\frac{1}{k^{2}}$$ without success. When I say ""by arithmetical means"" I mean to say, go from the left to the right expression just by symbolic manipulation. Can anyone devise a way of doing this?",,"['calculus', 'sequences-and-series']"
97,"Evaluate $ \int_{0}^{1} \ln(x)\ln(1-x)\,dx $",Evaluate," \int_{0}^{1} \ln(x)\ln(1-x)\,dx ","Evaluate the integral, $$ \int_{0}^{1} \ln(x)\ln(1-x)\,dx$$ I solved this problem, by writing power series and then calculating the series and found the answer to be $ 2 -\zeta(2) $, but I don't think that it is best solution to this problem. I want to know if it can be solved by any other nice/elegant method.","Evaluate the integral, $$ \int_{0}^{1} \ln(x)\ln(1-x)\,dx$$ I solved this problem, by writing power series and then calculating the series and found the answer to be $ 2 -\zeta(2) $, but I don't think that it is best solution to this problem. I want to know if it can be solved by any other nice/elegant method.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'problem-solving']"
98,Evaluating this integral $ \small\int \frac {x^2 dx} {(x\sin x+\cos x)^2} $,Evaluating this integral, \small\int \frac {x^2 dx} {(x\sin x+\cos x)^2} ,"The question: Compute$$ \int \frac {x^2 \, \operatorname{d}\!x} {(x\sin x+\cos x)^2} $$ Tried integration by parts. That didn't work. How do I proceed?","The question: Compute$$ \int \frac {x^2 \, \operatorname{d}\!x} {(x\sin x+\cos x)^2} $$ Tried integration by parts. That didn't work. How do I proceed?",,"['calculus', 'integration', 'indefinite-integrals']"
99,Prove that $\int_{0}^{\infty}{1\over x^4+x^2+1}dx=\int_{0}^{\infty}{1\over x^8+x^4+1}dx$,Prove that,\int_{0}^{\infty}{1\over x^4+x^2+1}dx=\int_{0}^{\infty}{1\over x^8+x^4+1}dx,"Let $$I=\int_{0}^{\infty}{1\over x^4+x^2+1}dx\tag1$$   $$J=\int_{0}^{\infty}{1\over x^8+x^4+1}dx\tag2$$ Prove that $I=J={\pi \over 2\sqrt3}$ Sub: $x=\tan{u}\rightarrow dx=\sec^2{u}du$ $x=\infty \rightarrow u={\pi\over 2}$, $x=0\rightarrow u=0$ Rewrite $(1)$ as $$I=\int_{0}^{\infty}{1\over (1+x^2)^2-x^2}dx$$ then $$\int_{0}^{\pi/2}{\sec^2{u}\over \sec^4{u}-\tan^2{u}}du\tag3$$ Simplified to $$I=\int_{0}^{\pi/2}{1\over \sec^2{u}-\sin^2{u}}du\tag4$$ Then to $$I=2\int_{0}^{\pi/2}{1+\cos{2u}\over (2+\sin{2u})(2-\sin{2u})}du\tag5$$ Any hints on what to do next? Re-edit (Hint from Marco) $${1\over x^8+x^4+1}={1\over 2}\left({x^2+1\over x^4+x^2+1}-{x^2-1\over x^4-x^2+1}\right)$$ $$M=\int_{0}^{\infty}{x^2+1\over x^4+x^2+1}dx=\int_{0}^{\infty}{x^2\over x^4+x^2+1}dx+\int_{0}^{\infty}{1\over x^4+x^2+1}dx={\pi\over \sqrt3}$$ $$N=\int_{0}^{\infty}{x^2-1\over x^4-x^2+1}dx=0$$ $$J=\int_{0}^{\infty}{1\over x^8+x^4+1}dx={1\over 2}\left({\pi\over \sqrt3}-0\right)={\pi\over 2\sqrt3}.$$","Let $$I=\int_{0}^{\infty}{1\over x^4+x^2+1}dx\tag1$$   $$J=\int_{0}^{\infty}{1\over x^8+x^4+1}dx\tag2$$ Prove that $I=J={\pi \over 2\sqrt3}$ Sub: $x=\tan{u}\rightarrow dx=\sec^2{u}du$ $x=\infty \rightarrow u={\pi\over 2}$, $x=0\rightarrow u=0$ Rewrite $(1)$ as $$I=\int_{0}^{\infty}{1\over (1+x^2)^2-x^2}dx$$ then $$\int_{0}^{\pi/2}{\sec^2{u}\over \sec^4{u}-\tan^2{u}}du\tag3$$ Simplified to $$I=\int_{0}^{\pi/2}{1\over \sec^2{u}-\sin^2{u}}du\tag4$$ Then to $$I=2\int_{0}^{\pi/2}{1+\cos{2u}\over (2+\sin{2u})(2-\sin{2u})}du\tag5$$ Any hints on what to do next? Re-edit (Hint from Marco) $${1\over x^8+x^4+1}={1\over 2}\left({x^2+1\over x^4+x^2+1}-{x^2-1\over x^4-x^2+1}\right)$$ $$M=\int_{0}^{\infty}{x^2+1\over x^4+x^2+1}dx=\int_{0}^{\infty}{x^2\over x^4+x^2+1}dx+\int_{0}^{\infty}{1\over x^4+x^2+1}dx={\pi\over \sqrt3}$$ $$N=\int_{0}^{\infty}{x^2-1\over x^4-x^2+1}dx=0$$ $$J=\int_{0}^{\infty}{1\over x^8+x^4+1}dx={1\over 2}\left({\pi\over \sqrt3}-0\right)={\pi\over 2\sqrt3}.$$",,"['calculus', 'integration', 'proof-verification', 'definite-integrals', 'improper-integrals']"
