,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability of getting $5$ heads on $10$ (fair) coin flips?,Probability of getting  heads on  (fair) coin flips?,5 10,"Even before attempting the problem, I immediately defaulted to an answer: $\frac{1}{2}$. I thought that this was a possible answer since the probability of flipping a head on one flip is definitely $\frac{1}{2}$. I then worked through the problem: Let E be the event in the problem statement. The total number of possible outcomes of $10$ coin flips: $N = 2^{10}$ The total number of ways in which E can result:for $n=10,r=5, nCr= 252$ $P(E) =\frac{n}{N} = .246$ How do I correct my intuition?","Even before attempting the problem, I immediately defaulted to an answer: $\frac{1}{2}$. I thought that this was a possible answer since the probability of flipping a head on one flip is definitely $\frac{1}{2}$. I then worked through the problem: Let E be the event in the problem statement. The total number of possible outcomes of $10$ coin flips: $N = 2^{10}$ The total number of ways in which E can result:for $n=10,r=5, nCr= 252$ $P(E) =\frac{n}{N} = .246$ How do I correct my intuition?",,"['probability', 'combinatorics', 'statistics']"
1,Mode ~ mean in binomial distribution,Mode ~ mean in binomial distribution,,"We toss a regular dice $60$ times. Denote $X$ the number of trials when the dice fell on one. The expected value of $X$ and the most probable value of $X$ are both equal to $10$, which is very intuitive. Is there some easy way to see that they are both equal (except calculating it)? In general is there some characterization of distributions that have this property?","We toss a regular dice $60$ times. Denote $X$ the number of trials when the dice fell on one. The expected value of $X$ and the most probable value of $X$ are both equal to $10$, which is very intuitive. Is there some easy way to see that they are both equal (except calculating it)? In general is there some characterization of distributions that have this property?",,"['probability', 'statistics']"
2,"If $Y_1, Y_2$ are exponential random variables, how can I find $P(Y_1 <Y_2)$?","If  are exponential random variables, how can I find ?","Y_1, Y_2 P(Y_1 <Y_2)","If I have that $Y_1, Y_2$ are independent exponential random variables with rate parameter $\lambda_1, \lambda_2$ respectively, how can I find $P(Y_1<Y_2)$? I know that I am supposed to use the integral but cannot get the joint distribution. Thanks.","If I have that $Y_1, Y_2$ are independent exponential random variables with rate parameter $\lambda_1, \lambda_2$ respectively, how can I find $P(Y_1<Y_2)$? I know that I am supposed to use the integral but cannot get the joint distribution. Thanks.",,"['probability', 'statistics']"
3,On normalized error measures,On normalized error measures,,"I have function values $f_1,\ldots,f_n$ that are approximated by data $y_1,\ldots,y_n$. I am looking for a measure that describes the error in the data $y_1,\ldots,y_n$ and I want the measure to take values between $0$ and $1$. I am familiar with the Root Mean Squared Error (RMSE) or RMSD (D for deviation): $$\mathrm{RMSE}=\sqrt{\frac{1}{n}\sum_{i=1}^n{\left(f_i-y_i\right)^2}} $$ Since this not normalized, I started searching for a normalized version, on which Wikipedia says: Normalizing the RMSE facilitates the comparison between datasets or models with different scales. Though there is no consistent means of normalization in the literature, the range of the measured data defined as the maximum value minus the minimum value is a common choice:   $$\mathrm{NRMSE}=\frac{\mathrm{RMSE}}{y_{\mathrm{max}}-y_{\mathrm{min}}}$$ Not that I consider Wikipedia a trustworthy source, but seems to me this isn't normalizing, since this could even blow up the error measure (if $y_{\mathrm{max}}-y_{\mathrm{min}}$ is small). Another approach would be to not consider the absolute error, but the error as a percentage. Something of the form $$\frac{1}{n}\sum_{i=1}^n{\left|\frac{f_i-y_i}{f_i}\right|}\ \ \ \mbox{ or } \ \ \ \frac{1}{n}\sqrt{\sum_{i=1}^n{\left(\frac{f_i-y_i}{f_i}\right)^2}}.$$ But this again does not necessarily take values between $0$ and $1$. Now my question is: are there other (perhaps better) measures to describe a normalized error. In other words, given values $f_1,\ldots,f_n$ and approximations $y_1,\ldots,y_n$, is there a measure to describe the error in these approximations that always takes values between $0$ and $1$?","I have function values $f_1,\ldots,f_n$ that are approximated by data $y_1,\ldots,y_n$. I am looking for a measure that describes the error in the data $y_1,\ldots,y_n$ and I want the measure to take values between $0$ and $1$. I am familiar with the Root Mean Squared Error (RMSE) or RMSD (D for deviation): $$\mathrm{RMSE}=\sqrt{\frac{1}{n}\sum_{i=1}^n{\left(f_i-y_i\right)^2}} $$ Since this not normalized, I started searching for a normalized version, on which Wikipedia says: Normalizing the RMSE facilitates the comparison between datasets or models with different scales. Though there is no consistent means of normalization in the literature, the range of the measured data defined as the maximum value minus the minimum value is a common choice:   $$\mathrm{NRMSE}=\frac{\mathrm{RMSE}}{y_{\mathrm{max}}-y_{\mathrm{min}}}$$ Not that I consider Wikipedia a trustworthy source, but seems to me this isn't normalizing, since this could even blow up the error measure (if $y_{\mathrm{max}}-y_{\mathrm{min}}$ is small). Another approach would be to not consider the absolute error, but the error as a percentage. Something of the form $$\frac{1}{n}\sum_{i=1}^n{\left|\frac{f_i-y_i}{f_i}\right|}\ \ \ \mbox{ or } \ \ \ \frac{1}{n}\sqrt{\sum_{i=1}^n{\left(\frac{f_i-y_i}{f_i}\right)^2}}.$$ But this again does not necessarily take values between $0$ and $1$. Now my question is: are there other (perhaps better) measures to describe a normalized error. In other words, given values $f_1,\ldots,f_n$ and approximations $y_1,\ldots,y_n$, is there a measure to describe the error in these approximations that always takes values between $0$ and $1$?",,"['statistics', 'data-analysis', 'mean-square-error']"
4,Distribution of sum of 2 circular uniform random variables,Distribution of sum of 2 circular uniform random variables,,"I hope you can help me resolve the following problem: Let $\Phi_1$ and $\Phi_2$ circular uniform random variables such that $0\leq\Phi_i\leq 2\pi$ (with $i=1,2$). Then the probability density function (pdf) and the cumulative distribution function (cdf) are given by \begin{align} f_{\Phi_i}(\phi_i) &= \frac{1}{2\pi} \\ F_{\Phi_i}(\phi_i) &= \frac{\phi_i}{2\pi}. \end{align} I'd like to find the distribution of sum $\Phi=\Phi_1+\Phi_2$ so that I've calculated the cdf of $\Phi$ as follows: \begin{align} F_{\Phi}(\phi) = Pr\{\Phi_1+\Phi_2\leq\phi\}  &= \int_0^{2\pi} Pr\{\Phi_1\leq\phi-\phi_2\bigl|\Phi_2=\phi_2\bigr.\} f_{\Phi_2}(\phi_2) d\phi_2 \\ &= \int_0^{2\pi} F_{\Phi_1}\left(\Phi_1\leq\phi-\phi_2\right) f_{\Phi_2}(\phi_2) d\phi_2 \\ &= \int_0^{2\pi} \frac{(\phi-\phi_2)}{2\pi} \frac{1}{2\pi} d\phi_2 \\ &= \frac{\phi}{2\pi} - \frac{1}{2}. \end{align} Due to $\Phi=\Phi_1+\Phi_2$, then $0\leq\Phi\leq 4\pi$. Unfortunately, we have \begin{align} F_{\Phi}(4\pi) = \frac{4\pi}{2\pi} - \frac{1}{2} = \frac{3}{2} > 1. \end{align} This is really unreasonable! Can anyone help me find the exact distribution of $\Phi$, please?","I hope you can help me resolve the following problem: Let $\Phi_1$ and $\Phi_2$ circular uniform random variables such that $0\leq\Phi_i\leq 2\pi$ (with $i=1,2$). Then the probability density function (pdf) and the cumulative distribution function (cdf) are given by \begin{align} f_{\Phi_i}(\phi_i) &= \frac{1}{2\pi} \\ F_{\Phi_i}(\phi_i) &= \frac{\phi_i}{2\pi}. \end{align} I'd like to find the distribution of sum $\Phi=\Phi_1+\Phi_2$ so that I've calculated the cdf of $\Phi$ as follows: \begin{align} F_{\Phi}(\phi) = Pr\{\Phi_1+\Phi_2\leq\phi\}  &= \int_0^{2\pi} Pr\{\Phi_1\leq\phi-\phi_2\bigl|\Phi_2=\phi_2\bigr.\} f_{\Phi_2}(\phi_2) d\phi_2 \\ &= \int_0^{2\pi} F_{\Phi_1}\left(\Phi_1\leq\phi-\phi_2\right) f_{\Phi_2}(\phi_2) d\phi_2 \\ &= \int_0^{2\pi} \frac{(\phi-\phi_2)}{2\pi} \frac{1}{2\pi} d\phi_2 \\ &= \frac{\phi}{2\pi} - \frac{1}{2}. \end{align} Due to $\Phi=\Phi_1+\Phi_2$, then $0\leq\Phi\leq 4\pi$. Unfortunately, we have \begin{align} F_{\Phi}(4\pi) = \frac{4\pi}{2\pi} - \frac{1}{2} = \frac{3}{2} > 1. \end{align} This is really unreasonable! Can anyone help me find the exact distribution of $\Phi$, please?",,"['probability', 'statistics']"
5,2 restaurants located randomly,2 restaurants located randomly,,"any help on following question will be much appreciated. Q. Suppose that $2$ restaurants are going to be located at a street that is $10$ km long. The location of each restaurant is chosen randomly. What is the probability that they will be located less than $5$ km apart? Ans: $\frac 34$ Also, can we generalize this to ""probability of $2$ entities located randomly over $y$ km stretch such that they are $x$ km apart""??","any help on following question will be much appreciated. Q. Suppose that $2$ restaurants are going to be located at a street that is $10$ km long. The location of each restaurant is chosen randomly. What is the probability that they will be located less than $5$ km apart? Ans: $\frac 34$ Also, can we generalize this to ""probability of $2$ entities located randomly over $y$ km stretch such that they are $x$ km apart""??",,"['probability', 'statistics']"
6,Probability of something happening exactly x times given y tries,Probability of something happening exactly x times given y tries,,"I'm working on my stats homework, and I completely forgot how to do this. Also, we were only taught how to do it on a calculator (TI84) and I want to know how to do it without one. The problem is pretty much ""what is the problem of it happening exactly twice given we try it ten times?"" and the probability of it happening each time is .17.","I'm working on my stats homework, and I completely forgot how to do this. Also, we were only taught how to do it on a calculator (TI84) and I want to know how to do it without one. The problem is pretty much ""what is the problem of it happening exactly twice given we try it ten times?"" and the probability of it happening each time is .17.",,"['probability', 'statistics']"
7,Why the mean value of a Gaussian process is usually set to zero?,Why the mean value of a Gaussian process is usually set to zero?,,"In most textbooks (e.g. Rasmussen's book on Gaussian Processes for Machine Learning) the mean value of a gaussian process is set to zero. Of course, this does not mean that all the values are expected to be zero since we are looking for the Maximum a Posteriori estimate of these variables, which do not have any more a zero mean. Is there a mathematically robust proof or at least an explanation based on mathematics that the assumption of the zero mean value is not too prohibitive for the a posteriori estimate? To make things a bit more clear, assume that we have the following model where the noise $e$ is uncorrelated with $f(x)$: $y= f(x) +e $, $f(x) \sim \mathcal{N} (m, K)$, $e \sim \mathcal{N} (0, \sigma^2)$. Then the a posteriori (which is actually the MAP estimate) is given by $\mathbb{E} (f | y) = m + K (\sigma^2 I + K)^{-1} (y-m)$ The way I see it, by setting the mean equal to zero we usually reduce the number of hyperparameters that have to be estimated, because most of the times the mean is also unknown, so it has to be parametrized by some hyperparameters and then these hyperparameters have to be estimated by a non-convex optimization routine, thus increasing the computational burden. However, this does not explain mathematically if the assumption that the mean is zero does not restrict too much the a posteriori estimate. Any help would be appreciated!","In most textbooks (e.g. Rasmussen's book on Gaussian Processes for Machine Learning) the mean value of a gaussian process is set to zero. Of course, this does not mean that all the values are expected to be zero since we are looking for the Maximum a Posteriori estimate of these variables, which do not have any more a zero mean. Is there a mathematically robust proof or at least an explanation based on mathematics that the assumption of the zero mean value is not too prohibitive for the a posteriori estimate? To make things a bit more clear, assume that we have the following model where the noise $e$ is uncorrelated with $f(x)$: $y= f(x) +e $, $f(x) \sim \mathcal{N} (m, K)$, $e \sim \mathcal{N} (0, \sigma^2)$. Then the a posteriori (which is actually the MAP estimate) is given by $\mathbb{E} (f | y) = m + K (\sigma^2 I + K)^{-1} (y-m)$ The way I see it, by setting the mean equal to zero we usually reduce the number of hyperparameters that have to be estimated, because most of the times the mean is also unknown, so it has to be parametrized by some hyperparameters and then these hyperparameters have to be estimated by a non-convex optimization routine, thus increasing the computational burden. However, this does not explain mathematically if the assumption that the mean is zero does not restrict too much the a posteriori estimate. Any help would be appreciated!",,"['statistics', 'random-variables', 'statistical-inference']"
8,Probability that P people will have N distinct birthdays,Probability that P people will have N distinct birthdays,,"This question is rather difficult to describe clearly, so I will begin with an example. Suppose I have a 365 people in a room. The odds are very low that all these people have different birthdays.  In fact, ignoring leap years and assuming that every birthday is equally likely , I estimated (using a program) that the most likely scenario is 231 distinct birthdays (with a probability of ~6.69%). More abstractly, out of P people, what are the odds that there are exactly N distinct birthdays amongst them (ignoring leap years and assuming that every birthday is equally likely)? In my above example I used P=365 and I estimated the answer for N=231. I am curious if there is a general solution to the problem which could give an exact answer for all N and P. For those who are interested, the program I created tries random combinations of birthdays and counts the number of unused birthdays. With it, I created a table of estimated probabilities for all N for P=365. Here is the most interesting part of the table: 242 - 1.1837375% 241 - 1.5966975% 240 - 2.0933325% 239 - 2.6695062% 238 - 3.3059700% 237 - 3.9824950% 236 - 4.6610425% 235 - 5.2969675% 234 - 5.8606362% 233 - 6.2995763% 232 - 6.5841737% 231 - 6.6932175% 230 - 6.6143263% 229 - 6.3563137% 228 - 5.9308837% 227 - 5.3896263% 226 - 4.7588988% 225 - 4.0879863% 224 - 3.4110800% 223 - 2.7697687% 222 - 2.1889950% 221 - 1.6793675% 220 - 1.2546263%","This question is rather difficult to describe clearly, so I will begin with an example. Suppose I have a 365 people in a room. The odds are very low that all these people have different birthdays.  In fact, ignoring leap years and assuming that every birthday is equally likely , I estimated (using a program) that the most likely scenario is 231 distinct birthdays (with a probability of ~6.69%). More abstractly, out of P people, what are the odds that there are exactly N distinct birthdays amongst them (ignoring leap years and assuming that every birthday is equally likely)? In my above example I used P=365 and I estimated the answer for N=231. I am curious if there is a general solution to the problem which could give an exact answer for all N and P. For those who are interested, the program I created tries random combinations of birthdays and counts the number of unused birthdays. With it, I created a table of estimated probabilities for all N for P=365. Here is the most interesting part of the table: 242 - 1.1837375% 241 - 1.5966975% 240 - 2.0933325% 239 - 2.6695062% 238 - 3.3059700% 237 - 3.9824950% 236 - 4.6610425% 235 - 5.2969675% 234 - 5.8606362% 233 - 6.2995763% 232 - 6.5841737% 231 - 6.6932175% 230 - 6.6143263% 229 - 6.3563137% 228 - 5.9308837% 227 - 5.3896263% 226 - 4.7588988% 225 - 4.0879863% 224 - 3.4110800% 223 - 2.7697687% 222 - 2.1889950% 221 - 1.6793675% 220 - 1.2546263%",,"['probability', 'statistics', 'balls-in-bins']"
9,Question about sum of chi-squared distribution,Question about sum of chi-squared distribution,,"I want to prove that the sum of two independent chi-squared random variables is a chi-squared random variable. I am supposed to only use the fact that if $Q$ has a chi-squared distribution with parameter k then Q = $Z_1^2$ + $Z_2^2$ + ... + $Z_k^2$ where each $Z_i$ is a standard normally distributed random variable and {$Z_1$,...,$Z_k$} is independent. My attempt at a proof: Let $Q_1$ and $Q_2$ be independent random variables with chi-squared distributions, with parameters a and b, respectively. Let {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$} be a set of independent random variables with standard normal distributions. Then we can write $Q_1$ = $X_1^2$ + $X_2^2$ + ... + $X_a^2$ $Q_2$ = $Y_1^2$ + $Y_2^2$ + ... + $Y_b^2$  , and $Q_1$ and $Q_2$ are independent because {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$} is independent. so $Q_2$ + $Q_2$ = $X_1^2$ + $X_2^2$ + ... + $X_a^2$ + $Y_1^2$ + $Y_2^2$ + ... + $Y_b^2$. Since {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$} is independent, $Q_2$ + $Q_2$ is a chi-squared random variable with parameter a+b. I don't think my proof is correct. I think the problem is that if we are given $Q_1$ and $Q_2$ that are independent, we can't just write them in terms of {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$}. But I am not really sure. Please tell me why my proof is incorrect (or maybe it is correct). Any help is appreciated.","I want to prove that the sum of two independent chi-squared random variables is a chi-squared random variable. I am supposed to only use the fact that if $Q$ has a chi-squared distribution with parameter k then Q = $Z_1^2$ + $Z_2^2$ + ... + $Z_k^2$ where each $Z_i$ is a standard normally distributed random variable and {$Z_1$,...,$Z_k$} is independent. My attempt at a proof: Let $Q_1$ and $Q_2$ be independent random variables with chi-squared distributions, with parameters a and b, respectively. Let {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$} be a set of independent random variables with standard normal distributions. Then we can write $Q_1$ = $X_1^2$ + $X_2^2$ + ... + $X_a^2$ $Q_2$ = $Y_1^2$ + $Y_2^2$ + ... + $Y_b^2$  , and $Q_1$ and $Q_2$ are independent because {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$} is independent. so $Q_2$ + $Q_2$ = $X_1^2$ + $X_2^2$ + ... + $X_a^2$ + $Y_1^2$ + $Y_2^2$ + ... + $Y_b^2$. Since {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$} is independent, $Q_2$ + $Q_2$ is a chi-squared random variable with parameter a+b. I don't think my proof is correct. I think the problem is that if we are given $Q_1$ and $Q_2$ that are independent, we can't just write them in terms of {$X_1$,...,$X_a$,$Y_1$,...,$Y_b$}. But I am not really sure. Please tell me why my proof is incorrect (or maybe it is correct). Any help is appreciated.",,"['statistics', 'probability-distributions']"
10,Sum over product of two binomial distributions,Sum over product of two binomial distributions,,"The problem is that of a two-stage ""binomial experiment"", where first a number $k$ out of $n$ is drawn (each element with probability $p_1$) and later a number $m$ out of those $k$ is drawn (each element with probability $p_2$). As shown here https://stats.stackexchange.com/questions/68800/stochastic-inequality-with-product-of-binomial-distributions , it turns out that $m$ ~ $Bin(n,p_1p_2)$. This is shown by this equation/theorem: \begin{equation} \sum _{k=m}^n {p_1}^k {p_2}^m \binom{k}{m} \binom{n}{k} (1-{p_2})^{k-m} (1-{p_1})^{n-k} = \binom{n}{m} ({p_1} {p_2})^m (1-{p_1} {p_2})^{n-m} \end{equation} Can anybody help me / tell me how to proof this formally? It looks a bit magical for me.","The problem is that of a two-stage ""binomial experiment"", where first a number $k$ out of $n$ is drawn (each element with probability $p_1$) and later a number $m$ out of those $k$ is drawn (each element with probability $p_2$). As shown here https://stats.stackexchange.com/questions/68800/stochastic-inequality-with-product-of-binomial-distributions , it turns out that $m$ ~ $Bin(n,p_1p_2)$. This is shown by this equation/theorem: \begin{equation} \sum _{k=m}^n {p_1}^k {p_2}^m \binom{k}{m} \binom{n}{k} (1-{p_2})^{k-m} (1-{p_1})^{n-k} = \binom{n}{m} ({p_1} {p_2})^m (1-{p_1} {p_2})^{n-m} \end{equation} Can anybody help me / tell me how to proof this formally? It looks a bit magical for me.",,"['real-analysis', 'probability', 'combinatorics', 'statistics', 'random-variables']"
11,What is the correct statistical language to conclude using type II error?,What is the correct statistical language to conclude using type II error?,,"Update: This question arises when I read a neuroscience paper. In the natural science community, people are generally less careful about the correctness of statistical language. I am clearly aware of the definitions of Type I error and Type II error. In statistics classes, we were taught that we should say either ""reject the null"" or ""fail to reject the null"" at a given significance level regarding Type I error rate. But we were rarely taught about the language used to describe Type II error. The author hypothesized that two samples are from the same distribution. The statistical test was performed using the following hypotheses. The null hypothesis: the two samples are from the same distribution. The alternative hypothesis: the two samples are from different distributions. The author got a p-value=0.83. Here the p-value is the same as the type I error rate. At significance level=0.05, we fail to reject the null hypothesis. That is, there is 83% chance that they are from different distributions when we say they are not. When the neuroscientists see something like this, they are more or less convinced that the two samples are from the same distribution. Of course, as a mathematician, this is far from rigorous. I am wondering if calculating the Type II error will strengthen the argument.  If my type II error rate is very small, say 0.03. What would be the correct statistical language to draw conclusion? Basically, I want to know the implication of the null/alternative given a high type I error and a low type II error and the rigorous statistical language to describe it .","Update: This question arises when I read a neuroscience paper. In the natural science community, people are generally less careful about the correctness of statistical language. I am clearly aware of the definitions of Type I error and Type II error. In statistics classes, we were taught that we should say either ""reject the null"" or ""fail to reject the null"" at a given significance level regarding Type I error rate. But we were rarely taught about the language used to describe Type II error. The author hypothesized that two samples are from the same distribution. The statistical test was performed using the following hypotheses. The null hypothesis: the two samples are from the same distribution. The alternative hypothesis: the two samples are from different distributions. The author got a p-value=0.83. Here the p-value is the same as the type I error rate. At significance level=0.05, we fail to reject the null hypothesis. That is, there is 83% chance that they are from different distributions when we say they are not. When the neuroscientists see something like this, they are more or less convinced that the two samples are from the same distribution. Of course, as a mathematician, this is far from rigorous. I am wondering if calculating the Type II error will strengthen the argument.  If my type II error rate is very small, say 0.03. What would be the correct statistical language to draw conclusion? Basically, I want to know the implication of the null/alternative given a high type I error and a low type II error and the rigorous statistical language to describe it .",,"['statistics', 'hypothesis-testing']"
12,World Cup Group prediction probability,World Cup Group prediction probability,,"We have an office world cup bet where each person guesses the team that finishes 1st and 2nd from their qualifying group. E.g. A1: Brazil A2: Mexico B1: Netherlands etc... You get a point for every correct guess. The person with the most points wins. My question is, if you selected each guess at random what is the expected number of points you would get? There are 8 groups, each with 4 teams; 2 guesses per team -> so the maximum points is 16. You can't guess the same team for 2 guesses. I.e. you couldn't guess Brazil to come 1st and 2nd in their group.","We have an office world cup bet where each person guesses the team that finishes 1st and 2nd from their qualifying group. E.g. A1: Brazil A2: Mexico B1: Netherlands etc... You get a point for every correct guess. The person with the most points wins. My question is, if you selected each guess at random what is the expected number of points you would get? There are 8 groups, each with 4 teams; 2 guesses per team -> so the maximum points is 16. You can't guess the same team for 2 guesses. I.e. you couldn't guess Brazil to come 1st and 2nd in their group.",,['statistics']
13,Find an unbiased estimator function (Poisson)?,Find an unbiased estimator function (Poisson)?,,"I think it is pretty easy to find an unbiased estimator for a regular distribution, whether it be Poisson or Gamma or something else.  For example, the unbiased estimator (Poisson from a random sample of size $n$) for $\lambda$ would be $\overline{Y}$. However, now suppose you have a function to find the number of failings of a computer system, and it is $C=2Y+Y^2$. We can easily see that $E(C)=E(2Y + Y^2) = 3\lambda + \lambda^2$.  But now if we want to find a function of $\overline{Y}$ that is an unbiased estimator of $E(C)$, how would you go about that? I would think that you need to find $\hat{\theta}$, such that $E(\hat{\theta})=3\lambda + \lambda^2$, but I am a little confused as to whether or not that is accurate. Any help on this problem would be greatly appreciated!  Thank you very much.","I think it is pretty easy to find an unbiased estimator for a regular distribution, whether it be Poisson or Gamma or something else.  For example, the unbiased estimator (Poisson from a random sample of size $n$) for $\lambda$ would be $\overline{Y}$. However, now suppose you have a function to find the number of failings of a computer system, and it is $C=2Y+Y^2$. We can easily see that $E(C)=E(2Y + Y^2) = 3\lambda + \lambda^2$.  But now if we want to find a function of $\overline{Y}$ that is an unbiased estimator of $E(C)$, how would you go about that? I would think that you need to find $\hat{\theta}$, such that $E(\hat{\theta})=3\lambda + \lambda^2$, but I am a little confused as to whether or not that is accurate. Any help on this problem would be greatly appreciated!  Thank you very much.",,"['probability', 'statistics', 'parameter-estimation']"
14,Health Insurance question,Health Insurance question,,"An insurance company issued health insurance policies to individuals. The company determined that Y, the number of claims filed by an insured in a year, is a random variable with the following probability function. $$P(Y=y)=0.45(0.55)^{y},\;\;\; y=0,1,2,3,\ldots$$ The number of claims filed by one insured individual is independent of the number of claims filed by any other insured individual. An actuary studied three randomly selected insured individuals from this group of individuals who purchased health policies from this company. What is the probability that these three insured individuals will file more than 6 claims in a year? My thinking was $$1-P(Y=0)-P(Y=1)-P(Y=2)-\dotsb-P(Y=6)$$ and than raising to the third power but this doesn't give me the answer. What am I missing?","An insurance company issued health insurance policies to individuals. The company determined that Y, the number of claims filed by an insured in a year, is a random variable with the following probability function. $$P(Y=y)=0.45(0.55)^{y},\;\;\; y=0,1,2,3,\ldots$$ The number of claims filed by one insured individual is independent of the number of claims filed by any other insured individual. An actuary studied three randomly selected insured individuals from this group of individuals who purchased health policies from this company. What is the probability that these three insured individuals will file more than 6 claims in a year? My thinking was $$1-P(Y=0)-P(Y=1)-P(Y=2)-\dotsb-P(Y=6)$$ and than raising to the third power but this doesn't give me the answer. What am I missing?",,"['probability', 'statistics']"
15,PDF of $Y = \cos(\pi X)$,PDF of,Y = \cos(\pi X),"I've run into a practice problem where $Y = \cos(\pi X)$, and $X$ is uniform on $[0, 1]$, and I'm supposed to prove that the PDF of $Y$ is $1/(\pi\sqrt{1 - y^2})$. I know that for derived distributions, you plug in the the equation for $Y$ in terms of $X$ into the PDF of $X$, integrate up to $y$, and then differentiate with respect to $y$. However, when I do this, I get the PDF of $Y = -1/(\pi\sqrt{1 - y^2})$. I'm sure that the problem here is that there's some property of the cosine and its inverse that I don't know, so if someone could point out how to do this, that would be great, thanks!","I've run into a practice problem where $Y = \cos(\pi X)$, and $X$ is uniform on $[0, 1]$, and I'm supposed to prove that the PDF of $Y$ is $1/(\pi\sqrt{1 - y^2})$. I know that for derived distributions, you plug in the the equation for $Y$ in terms of $X$ into the PDF of $X$, integrate up to $y$, and then differentiate with respect to $y$. However, when I do this, I get the PDF of $Y = -1/(\pi\sqrt{1 - y^2})$. I'm sure that the problem here is that there's some property of the cosine and its inverse that I don't know, so if someone could point out how to do this, that would be great, thanks!",,"['probability', 'statistics', 'probability-distributions']"
16,K Nearest Neighbor Density Estimation,K Nearest Neighbor Density Estimation,,"An intuitive way to estimate the pdf of a distribution $f$ is described here . Given a set of points you find the distance to the $k$th nearest neighbor for a point $x$ that we want to know the value of $f$ at. This allows us to calculate the volume of the sphere containing $k$ points. Approximating the probability mass within this sphere as $k$/(number of points in set), we can estimate $\hat{f}(x)$ as the probability mass over the volume. This is fine, but there is a problem in more than dimension when the variance of the marginals  differs greatly. In this case, the volume of the sphere will depend very heavily on points in the dimension of greatest variance. For example consider distribution $f(X)$ s.t $X \sim N(0,1)$. The estimation above should perform well given we have enough points. However now consider $$g(x,y) = \left\{ \begin{array}{ll}          f(x) & \mbox{if $y = 0$}\\         0 & \mbox{otherwise} \end{array} \right.$$ In this case we will be estimating the 'volume' by a circle, when in reality the distribution $g$ is only 1 dimensional which  ends up giving a very different answer to the estimation of $f$. What is the most common way around this? Maybe perform the $k$ nearest neighbor in 2(+) dimensions and approximate the volume using ellipses?","An intuitive way to estimate the pdf of a distribution $f$ is described here . Given a set of points you find the distance to the $k$th nearest neighbor for a point $x$ that we want to know the value of $f$ at. This allows us to calculate the volume of the sphere containing $k$ points. Approximating the probability mass within this sphere as $k$/(number of points in set), we can estimate $\hat{f}(x)$ as the probability mass over the volume. This is fine, but there is a problem in more than dimension when the variance of the marginals  differs greatly. In this case, the volume of the sphere will depend very heavily on points in the dimension of greatest variance. For example consider distribution $f(X)$ s.t $X \sim N(0,1)$. The estimation above should perform well given we have enough points. However now consider $$g(x,y) = \left\{ \begin{array}{ll}          f(x) & \mbox{if $y = 0$}\\         0 & \mbox{otherwise} \end{array} \right.$$ In this case we will be estimating the 'volume' by a circle, when in reality the distribution $g$ is only 1 dimensional which  ends up giving a very different answer to the estimation of $f$. What is the most common way around this? Maybe perform the $k$ nearest neighbor in 2(+) dimensions and approximate the volume using ellipses?",,"['statistics', 'probability-distributions']"
17,CDF from generating function,CDF from generating function,,Is there a way to obtain the CDF of a discrete random variable directly from one of its generating functions?,Is there a way to obtain the CDF of a discrete random variable directly from one of its generating functions?,,"['probability', 'statistics', 'generating-functions']"
18,The game of hand cricket.,The game of hand cricket.,,"(If you could add a more suitable title, I'd be very grateful to you) My friend gave me this question: In the game of hand-cricket (hand baseball, if you like it :D) two players $X$ - the batsman and $Y$ - the bowler, randomly choose numbers from $1$ to $6$ (simultaneously). Now, if both put the same number, then player $X$ is declared out and the game ends (for $X$). If both put different numbers, then the score of $X$ is incremented by the number he chose. Before starting, the score of $X$ is $0$. If the game goes on like this, what is the most probable score of $X$? For example, if $X$ and $Y$ start by choosing $1$ and $6$, then the score of $X$ is 1. If $X$ puts $3$ and $Y$ puts $1$, then the score of $X$ becomes $4$. If $X$ and $Y$ both put $5$, then $X$ is out and the final score is $4$. The question was just to write a program to find the average score - nothing big at all. But I wondered if there should be an expected score. The Question : Now, my question is why should there be a 'most probable score' at all? To investigate this, I just wrote a small program and it turns out that the average score is about $12$. Then, I changed the parameter $6$ to various numbers and I got various answers. If the parameter is increased, I get a greater average score and on reducing it, I get a lower average score. This seems quite sensible as by increasing the parameter, we are effectively reducing the chances of 'collision'. But is there any mathematical way to estimate the average score given a parameter $K$ such that the numbers chosen are between $1$ and $K$? Please note that I am not familiar with 'advanced' probability and such stuff, so if possible, give the answer in an intuitive way! Maybe I am asking too much. In that case, you may just tell that it is way above my current 'level'.","(If you could add a more suitable title, I'd be very grateful to you) My friend gave me this question: In the game of hand-cricket (hand baseball, if you like it :D) two players $X$ - the batsman and $Y$ - the bowler, randomly choose numbers from $1$ to $6$ (simultaneously). Now, if both put the same number, then player $X$ is declared out and the game ends (for $X$). If both put different numbers, then the score of $X$ is incremented by the number he chose. Before starting, the score of $X$ is $0$. If the game goes on like this, what is the most probable score of $X$? For example, if $X$ and $Y$ start by choosing $1$ and $6$, then the score of $X$ is 1. If $X$ puts $3$ and $Y$ puts $1$, then the score of $X$ becomes $4$. If $X$ and $Y$ both put $5$, then $X$ is out and the final score is $4$. The question was just to write a program to find the average score - nothing big at all. But I wondered if there should be an expected score. The Question : Now, my question is why should there be a 'most probable score' at all? To investigate this, I just wrote a small program and it turns out that the average score is about $12$. Then, I changed the parameter $6$ to various numbers and I got various answers. If the parameter is increased, I get a greater average score and on reducing it, I get a lower average score. This seems quite sensible as by increasing the parameter, we are effectively reducing the chances of 'collision'. But is there any mathematical way to estimate the average score given a parameter $K$ such that the numbers chosen are between $1$ and $K$? Please note that I am not familiar with 'advanced' probability and such stuff, so if possible, give the answer in an intuitive way! Maybe I am asking too much. In that case, you may just tell that it is way above my current 'level'.",,"['probability', 'statistics', 'recreational-mathematics']"
19,why is this Markov Chain aperiodic,why is this Markov Chain aperiodic,,"I have this Matrix: $$P=\begin{pmatrix}  0 & 1 \\ 0.3 & 0.7 \end{pmatrix}$$ this markov chain is said to be aperiodic, I dont understand how it comes to it. Period $\delta$ is the gcd of the set of all diagonal elements, right? if $\delta>1$, $P$ is periodic, if $\delta=1$, then aperiodic. but here it is not $\delta=1$, is it? or do i have to transit the matrix to some certain form?","I have this Matrix: $$P=\begin{pmatrix}  0 & 1 \\ 0.3 & 0.7 \end{pmatrix}$$ this markov chain is said to be aperiodic, I dont understand how it comes to it. Period $\delta$ is the gcd of the set of all diagonal elements, right? if $\delta>1$, $P$ is periodic, if $\delta=1$, then aperiodic. but here it is not $\delta=1$, is it? or do i have to transit the matrix to some certain form?",,"['probability', 'statistics', 'stochastic-processes', 'markov-chains']"
20,Cramer-Rao lower bound question. [closed],Cramer-Rao lower bound question. [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Suppose that $X_1,X_2,\ldots,X_n$ form a random sample from a normal distribution with mean $0$ and unknown standard deviation $\sigma > 0$. Find the Cramer-Rao Lower Bound for the variance of any unbiased estimator of $\log \sigma$.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question Suppose that $X_1,X_2,\ldots,X_n$ form a random sample from a normal distribution with mean $0$ and unknown standard deviation $\sigma > 0$. Find the Cramer-Rao Lower Bound for the variance of any unbiased estimator of $\log \sigma$.",,"['probability', 'statistics']"
21,Integration of function help,Integration of function help,,I'm having problems integrating this function $\displaystyle E(X)=\int^ \infty_0 x\lambda e^{-\lambda x} dx$. I did the integration by parts and had $-xe^{-\lambda x}- \lambda e^{-\lambda x}$. However the solution gives $-xe^{-\lambda x} - \dfrac{1}{\lambda}e^{-\lambda x}$. I can't find any mistakes. What am I doing wrong?,I'm having problems integrating this function $\displaystyle E(X)=\int^ \infty_0 x\lambda e^{-\lambda x} dx$. I did the integration by parts and had $-xe^{-\lambda x}- \lambda e^{-\lambda x}$. However the solution gives $-xe^{-\lambda x} - \dfrac{1}{\lambda}e^{-\lambda x}$. I can't find any mistakes. What am I doing wrong?,,"['statistics', 'integration']"
22,Likelihood function of a gamma distributed sample,Likelihood function of a gamma distributed sample,,"I missed the day of class where we went over likelihood functions, and I had a quick question. If $X_1,...X_n$ are i.i.d. $	{\Gamma}(\alpha,\beta)$ r.v.s, I'm trying to find the likelihood function for $\alpha$ and $\beta$. From what I can tell, the likelihood function is defined as $f(x_1;\alpha,\beta)*...*f(x_1;\alpha,\beta)$. If i'm not mistaking, $f(x_1;\alpha,\beta)$ should be the same as the pdf for the gamma distribution (although not a pdf, on account of x being a fixed value here?), so would the likelihood function in this case be ${(\text{pdf-of-}\Gamma)}^n$? Further, I'm a bit confused on what the support for this function should be; in this case x is fixed, am I correct in supposing that the support is then $\alpha>0, \beta>0$? I hope this makes sense - I get the feeling I might be very confused about the whole thing. Thank you for any help!","I missed the day of class where we went over likelihood functions, and I had a quick question. If $X_1,...X_n$ are i.i.d. $	{\Gamma}(\alpha,\beta)$ r.v.s, I'm trying to find the likelihood function for $\alpha$ and $\beta$. From what I can tell, the likelihood function is defined as $f(x_1;\alpha,\beta)*...*f(x_1;\alpha,\beta)$. If i'm not mistaking, $f(x_1;\alpha,\beta)$ should be the same as the pdf for the gamma distribution (although not a pdf, on account of x being a fixed value here?), so would the likelihood function in this case be ${(\text{pdf-of-}\Gamma)}^n$? Further, I'm a bit confused on what the support for this function should be; in this case x is fixed, am I correct in supposing that the support is then $\alpha>0, \beta>0$? I hope this makes sense - I get the feeling I might be very confused about the whole thing. Thank you for any help!",,"['statistics', 'probability-distributions']"
23,Poisson cdf and solving for $\lambda$,Poisson cdf and solving for,\lambda,"The Poisson cdf can be written as $F(k, \lambda) = e^{-\lambda} \sum\limits_{i = 0}^{k}\frac{\lambda^{i}}{i!}$. I was wondering if it was possible to solve this equation for $\lambda$? That is, I know $k$ and the value of $F$, but I want to know what value of $\lambda$ makes the equation equal $F$. Thanks.","The Poisson cdf can be written as $F(k, \lambda) = e^{-\lambda} \sum\limits_{i = 0}^{k}\frac{\lambda^{i}}{i!}$. I was wondering if it was possible to solve this equation for $\lambda$? That is, I know $k$ and the value of $F$, but I want to know what value of $\lambda$ makes the equation equal $F$. Thanks.",,"['statistics', 'probability-distributions']"
24,Transformations of Normal,Transformations of Normal,,"If we have $U$, $V$, and $W$ as i.i.d normal RV with mean $0$ and variance $\sigma^2$, then what are the following expressed as a transformation of a known distribution (if known): 1) $\frac{U}{V + W}$ I don't think this can expressed as a distribution. 2) $\frac{U^2}{V^2}$ Both $U^2$ and $V^2$ are $\chi^2$ and the quotient of $\chi^2$ is an F-distribution. I am just not sure what the degrees of freedom are... 3) $\frac{U^2 + V^2}{V^2}$ $U^2 + V^2$ is simply a $\chi^2$ with the sum of the degrees of freedom of $U$ and $V$. A $\chi^2$ divided by another $\chi^2$ is F. But I am wondering is this can be simiplified to $\frac{U^2}{V^2} + 1$ (are you allowed to do that?) in which case it would be $1 + F$... 4) $\frac{U^2 + V^2}{W^2}$ I think it is the same as the one above... just an F distribution. Please help me out with my reasoning! Thanks.","If we have $U$, $V$, and $W$ as i.i.d normal RV with mean $0$ and variance $\sigma^2$, then what are the following expressed as a transformation of a known distribution (if known): 1) $\frac{U}{V + W}$ I don't think this can expressed as a distribution. 2) $\frac{U^2}{V^2}$ Both $U^2$ and $V^2$ are $\chi^2$ and the quotient of $\chi^2$ is an F-distribution. I am just not sure what the degrees of freedom are... 3) $\frac{U^2 + V^2}{V^2}$ $U^2 + V^2$ is simply a $\chi^2$ with the sum of the degrees of freedom of $U$ and $V$. A $\chi^2$ divided by another $\chi^2$ is F. But I am wondering is this can be simiplified to $\frac{U^2}{V^2} + 1$ (are you allowed to do that?) in which case it would be $1 + F$... 4) $\frac{U^2 + V^2}{W^2}$ I think it is the same as the one above... just an F distribution. Please help me out with my reasoning! Thanks.",,"['probability', 'statistics']"
25,skew normal distribution,skew normal distribution,,"We have skew normal distribution with location $=0$, scale $=1$ and shape $=0$ then it is same as standard normal distribution with mean $0$ and variance $1$. But if we change the shape parameter say shape $=5$ then mean and variance also changes. How can we fix mean and variance with different values of shape parameter? If we have $3$ equation of mean, variance and skewness then how can we fix location, scale and shape parameter. Can you explain about it?","We have skew normal distribution with location $=0$, scale $=1$ and shape $=0$ then it is same as standard normal distribution with mean $0$ and variance $1$. But if we change the shape parameter say shape $=5$ then mean and variance also changes. How can we fix mean and variance with different values of shape parameter? If we have $3$ equation of mean, variance and skewness then how can we fix location, scale and shape parameter. Can you explain about it?",,[]
26,Probability concerning unfair dice with N sides,Probability concerning unfair dice with N sides,,"Fair warning: I am not a math expert (that's why I'm here). I would like to be able to calculate the probability of rolling a certain side on a die with n sides where any number of those sides has an unfair advantage over the others. For example: On a 6-sided die, we could assume that the 1 - 6 sides are longer than the other sides due to wear and tear (or someone shaved the 1 or 6) and, therefore, more likely to come face up on a roll. I know that, on a perfect die, the roll is uniformly random and each side has a 1/side chance of coming up. How do I calculate the probability of each side if sides 1 and 6 are longer? What if sides 1 and 6 are longest, 2 and 5 are second longest, and 3 and 4 are shortest? What if I'm using a 12-sided die? 10-sided? 20-sided? I'm looking for a formula that I can plug numbers into and I'd really, really like an explanation of how it all works, if possible. I found this link that talks about using Mathematica to calculate one side shaved on a 6-sided die, but I don't know how this changes when you increase the number of dice, or the syntax being used. I feel like the equation below (from the link) makes sense somewhat (in that σ represents the increase in probability of a 1 or 6, but I would like to know how to calculate σ. f = { 1/6 + σ, 1/6 - σ/6, 1/6 - σ/6, 1/6 - σ/6, 1/6 - σ/6, 1/6 + σ }; Could I use the same formula to represent a 20 sided die? f = {1/20 + σ, 1/20 - σ/20, ...  ... ... ..., 1/20 - σ/20, 1/20 + σ} Note: I took an intro to Statistics in college, but that's all the exposure I've had. I would like to understand more, but this is where I am now. I appreciate any help you can give me and any resources you can point me to.","Fair warning: I am not a math expert (that's why I'm here). I would like to be able to calculate the probability of rolling a certain side on a die with n sides where any number of those sides has an unfair advantage over the others. For example: On a 6-sided die, we could assume that the 1 - 6 sides are longer than the other sides due to wear and tear (or someone shaved the 1 or 6) and, therefore, more likely to come face up on a roll. I know that, on a perfect die, the roll is uniformly random and each side has a 1/side chance of coming up. How do I calculate the probability of each side if sides 1 and 6 are longer? What if sides 1 and 6 are longest, 2 and 5 are second longest, and 3 and 4 are shortest? What if I'm using a 12-sided die? 10-sided? 20-sided? I'm looking for a formula that I can plug numbers into and I'd really, really like an explanation of how it all works, if possible. I found this link that talks about using Mathematica to calculate one side shaved on a 6-sided die, but I don't know how this changes when you increase the number of dice, or the syntax being used. I feel like the equation below (from the link) makes sense somewhat (in that σ represents the increase in probability of a 1 or 6, but I would like to know how to calculate σ. f = { 1/6 + σ, 1/6 - σ/6, 1/6 - σ/6, 1/6 - σ/6, 1/6 - σ/6, 1/6 + σ }; Could I use the same formula to represent a 20 sided die? f = {1/20 + σ, 1/20 - σ/20, ...  ... ... ..., 1/20 - σ/20, 1/20 + σ} Note: I took an intro to Statistics in college, but that's all the exposure I've had. I would like to understand more, but this is where I am now. I appreciate any help you can give me and any resources you can point me to.",,"['probability', 'statistics', 'physics', 'applications']"
27,Is it possible to construct a positive random variable such that truncated means are always linear?,Is it possible to construct a positive random variable such that truncated means are always linear?,,"Let $X$ be a random variable that takes positive values. Let $\tau \in (0,\infty)$ be a truncation point. Is it possible to construct a distribution of $X$ such that both $u(\tau):=\mathbb{E}[X\mid X\ge \tau]$ and $l(\tau):=\mathbb{E}[X\mid X\le \tau]$ are linear in $\tau$ ? Intuitively, if the density of $X$ has a peak, then the rate of change in $u$ and $l$ cannot be constant, so I guess it should have a monotone density? For example, if $X$ follows the exponential distribution with scale $\beta$ , then $u(\tau)=\beta + \tau$ and $l(\tau)=\beta - \tau/(\exp(\beta^{-1}\tau - 1)$ . Thus, $u$ is linear but $l$ is not linear in $\tau$ . I tried to work from here by considering a weighted density or mixture of densities of exponential form, but I haven't gotten any results.","Let be a random variable that takes positive values. Let be a truncation point. Is it possible to construct a distribution of such that both and are linear in ? Intuitively, if the density of has a peak, then the rate of change in and cannot be constant, so I guess it should have a monotone density? For example, if follows the exponential distribution with scale , then and . Thus, is linear but is not linear in . I tried to work from here by considering a weighted density or mixture of densities of exponential form, but I haven't gotten any results.","X \tau \in (0,\infty) X u(\tau):=\mathbb{E}[X\mid X\ge \tau] l(\tau):=\mathbb{E}[X\mid X\le \tau] \tau X u l X \beta u(\tau)=\beta + \tau l(\tau)=\beta - \tau/(\exp(\beta^{-1}\tau - 1) u l \tau","['probability', 'statistics', 'probability-distributions']"
28,Why is average defined as sum of the data divided by the total number of data?,Why is average defined as sum of the data divided by the total number of data?,,"Wherever I search on the internet, the definition of average is more like just giving a formula for it- sum the values and then divide the result by the number of values, you get a number, that number is the average. Okay, but what does it represent? A central value? Okay but how did mathematicians know that this central value was sum of the values divided by the number of values? In a nutshell, I'm curious to know what led to the formula of average as sum of the data / number of data. I believe the answer lies in knowing the significance of the concept of average.","Wherever I search on the internet, the definition of average is more like just giving a formula for it- sum the values and then divide the result by the number of values, you get a number, that number is the average. Okay, but what does it represent? A central value? Okay but how did mathematicians know that this central value was sum of the values divided by the number of values? In a nutshell, I'm curious to know what led to the formula of average as sum of the data / number of data. I believe the answer lies in knowing the significance of the concept of average.",,"['probability', 'statistics', 'average']"
29,"Statistics, PDF and CDF pre-university (A level)","Statistics, PDF and CDF pre-university (A level)",,"This is a question from an A level textbook on continuous random variables. It states that the CRV $T$ has pdf $f(t)=0.5 ~for~ 1<t<3$ and then goes on to ask us to find the CDF (easy peasy $F(t)=\frac{1}{2} (t-1)$ and to show that the probability of selecting two independent observation less than 2.5 is $\frac{9}{16}$ (again, fine, $F(2.5)\times F(2.5)$ ). The third part, however, is a bit weird. I'll quote exactly "" $S$ is the larger of two independent observations of $T$ . By considering the CDF of $S$ show that $S$ has pdf $g(s)=\frac{s-1}{2}$ and then the details about the ranges it applied to"" I couldn't get anywhere with this and cheated looking up their worked solutions which amounted to $P(S=s)=P(T=s)\times P(T\leq S)\times 2=0.5\times \frac{s-1}{2}\times 2=\frac{s-1}{2}$ In other words, you pick a value of $T=s$ and the next one needs to be smaller than it ( $T\leq s$ ) but it could be the other way around (hence $\times 2$ ). Now, I'm really concerned about $P(T=s)$ , surely this is zero? Your help will be much appreciated.","This is a question from an A level textbook on continuous random variables. It states that the CRV has pdf and then goes on to ask us to find the CDF (easy peasy and to show that the probability of selecting two independent observation less than 2.5 is (again, fine, ). The third part, however, is a bit weird. I'll quote exactly "" is the larger of two independent observations of . By considering the CDF of show that has pdf and then the details about the ranges it applied to"" I couldn't get anywhere with this and cheated looking up their worked solutions which amounted to In other words, you pick a value of and the next one needs to be smaller than it ( ) but it could be the other way around (hence ). Now, I'm really concerned about , surely this is zero? Your help will be much appreciated.",T f(t)=0.5 ~for~ 1<t<3 F(t)=\frac{1}{2} (t-1) \frac{9}{16} F(2.5)\times F(2.5) S T S S g(s)=\frac{s-1}{2} P(S=s)=P(T=s)\times P(T\leq S)\times 2=0.5\times \frac{s-1}{2}\times 2=\frac{s-1}{2} T=s T\leq s \times 2 P(T=s),"['statistics', 'probability-distributions', 'random-variables', 'cumulative-distribution-functions', 'continuous-variables']"
30,Roll a pair of 6-sided dice. $S=$ total score. What is the expected number of pair-rolls to get the same value of $S$ consecutively?,Roll a pair of 6-sided dice.  total score. What is the expected number of pair-rolls to get the same value of  consecutively?,S= S,"Roll a pair of unbiased 6-sided dice. Let $S=$ total score. So the possible values of $S$ are 2, 3, 4, ..., 12. Let $X$ = number of pair-rolls up to and including the first time we get the same value of $S$ consecutively. For example, if the values of $S$ are {9, 7, 12, 3, 8, 5, 5} then $X=7$ . Question: What is the value of $E(X)$ ? What makes this question difficult for me is that the values of $S$ have different probabilities, so I cannot directly use a geometric distribution. And I have not been able to find a useful recurrence relation. I made a simulation on excel with 1000 trials, and $E(X)$ seems to be approximately $10$ . (Context: No special context; I've been looking at various questions involving dice n MSE, and I came up with this question.)","Roll a pair of unbiased 6-sided dice. Let total score. So the possible values of are 2, 3, 4, ..., 12. Let = number of pair-rolls up to and including the first time we get the same value of consecutively. For example, if the values of are {9, 7, 12, 3, 8, 5, 5} then . Question: What is the value of ? What makes this question difficult for me is that the values of have different probabilities, so I cannot directly use a geometric distribution. And I have not been able to find a useful recurrence relation. I made a simulation on excel with 1000 trials, and seems to be approximately . (Context: No special context; I've been looking at various questions involving dice n MSE, and I came up with this question.)",S= S X S S X=7 E(X) S E(X) 10,"['statistics', 'expected-value', 'dice']"
31,"Guess 2/3 of the Average - Is 0 More ""Powerful"" than 100?","Guess 2/3 of the Average - Is 0 More ""Powerful"" than 100?",,"I was reading about this game called ""Guess 2/3 of the Average"" ( https://en.wikipedia.org/wiki/Guess_2/3_of_the_average ). Players guess an integer between 0 and 100 - the winner is the player whose guess was closest to 2/3 of the average number guessed by all players. I read that if everyone knows how this game works, the best guess to make is 0. This is because guessing the number 0 will ""shrink"" the average of all guesses (and 2/3 of the average) closer to 0, thus making your guess closest to the average of 2/3rd's of all guesses and making you the winner. (However, this strategy is only valid if everyone knows how the game works - if players guess random numbers, then 0 is no longer the best guess) I tried to explain this game to my friend and explain why guessing the number 0 is the best guess. My friend argued that if guessing the number 0 has the ability to ""shrink"" 2/3rd's of the average guesses towards 0 - wouldn't guessing the number 100 have the equal ability to ""expand"" 2/3rd's of the average guess towards 100? I used this analogy: Suppose there are 3 exams - if you score 100/100 marks on two of the exams and score 0/100 on the third exam, your average grade is 66%. But if you score 0/100 on two exams and score 100/100 on the last exam, your average grade is only 33%. My informal reasoning was that the number 0 is much more powerful in pulling an average towards itself  compared to the number 100. But now, I beginning to doubt my own logic and reasoning. Can someone please explain the logic behind why guessing the number 0 is the best guess for this game (assuming that everyone knows how this game works)? Thank you!","I was reading about this game called ""Guess 2/3 of the Average"" ( https://en.wikipedia.org/wiki/Guess_2/3_of_the_average ). Players guess an integer between 0 and 100 - the winner is the player whose guess was closest to 2/3 of the average number guessed by all players. I read that if everyone knows how this game works, the best guess to make is 0. This is because guessing the number 0 will ""shrink"" the average of all guesses (and 2/3 of the average) closer to 0, thus making your guess closest to the average of 2/3rd's of all guesses and making you the winner. (However, this strategy is only valid if everyone knows how the game works - if players guess random numbers, then 0 is no longer the best guess) I tried to explain this game to my friend and explain why guessing the number 0 is the best guess. My friend argued that if guessing the number 0 has the ability to ""shrink"" 2/3rd's of the average guesses towards 0 - wouldn't guessing the number 100 have the equal ability to ""expand"" 2/3rd's of the average guess towards 100? I used this analogy: Suppose there are 3 exams - if you score 100/100 marks on two of the exams and score 0/100 on the third exam, your average grade is 66%. But if you score 0/100 on two exams and score 100/100 on the last exam, your average grade is only 33%. My informal reasoning was that the number 0 is much more powerful in pulling an average towards itself  compared to the number 100. But now, I beginning to doubt my own logic and reasoning. Can someone please explain the logic behind why guessing the number 0 is the best guess for this game (assuming that everyone knows how this game works)? Thank you!",,"['probability', 'statistics', 'game-theory', 'average', 'means']"
32,first step analysis-tossing two coins example,first step analysis-tossing two coins example,,"I am having trouble to understand this easy solution, why does only $A,B,C,D$ could partition the sample space? How come the $\mathbb{P}(B)=\mathbb{P}(C)=\frac{33}{36}$ ? Isn't that suppose to be $\frac{4}{36}$ and $\frac{2}{36}$ ,repectively. Thank you for any help and comments.","I am having trouble to understand this easy solution, why does only could partition the sample space? How come the ? Isn't that suppose to be and ,repectively. Thank you for any help and comments.","A,B,C,D \mathbb{P}(B)=\mathbb{P}(C)=\frac{33}{36} \frac{4}{36} \frac{2}{36}","['probability', 'statistics', 'solution-verification', 'conditional-probability']"
33,Is it possible that linear transform changes interval data to ratio?,Is it possible that linear transform changes interval data to ratio?,,"I'm going through a stats intro and got puzzled by the concept of interval and ratio data. Celsius temps is an example of interval data that can not be multiplied and divided, because there is no true 0. Yet, a simple linear transformation changes Celsius into Kelvin, where 0 is defined. Kelvin temps are divided and multiplied all over physics, so clearly a ratio data. To me it seems counterintuitive that a simple linear transformation allows for definition of a whole new mathematical operation. Is it just me and there is actually nothing strange about it, or am I missing something?","I'm going through a stats intro and got puzzled by the concept of interval and ratio data. Celsius temps is an example of interval data that can not be multiplied and divided, because there is no true 0. Yet, a simple linear transformation changes Celsius into Kelvin, where 0 is defined. Kelvin temps are divided and multiplied all over physics, so clearly a ratio data. To me it seems counterintuitive that a simple linear transformation allows for definition of a whole new mathematical operation. Is it just me and there is actually nothing strange about it, or am I missing something?",,"['linear-algebra', 'statistics', 'linear-transformations']"
34,Brownian Motion and Hitting Time expectation.,Brownian Motion and Hitting Time expectation.,,"The problem is as follows: Let $(W_t)$ be a Brownian Motion, $\alpha>0$ , and $\tau = \inf\{t>0 : W_t \geq \alpha\}$ be the First Exit Time. Compute $\mathbb{E}(\tau)$ . I am aware that the result is not finite, however I am having trouble showing that the integral does not converge. This problem has answers here . However they use results I haven't seen or understand, such as Wald's Identities. What I have done so far: $$ \mathbb{P}(\tau \leq t)  = \mathbb{P}(W_t^* \geq \alpha) = 2 \cdot \mathbb{P}(W_t \geq \alpha) = 2(1- \Phi(\alpha / \sqrt{t})) $$ Where $W_t^* = \underset{0\leq s \leq t}{\sup} W_s$ . $$ f(t)  = \frac{\partial}{\partial t} \mathbb{P}(\tau \leq t) = 2\phi\left(\frac{\alpha}{\sqrt{t}}\right)\left(\frac{\alpha}{2 \sqrt{t^3}}\right) = \frac{\alpha}{\sqrt{2\pi t^3}} e^{-\frac{1}{2t}\alpha^2} $$ I am stuck here: $$ \mathbb{E}(\tau) = \int_0^{\infty} t \cdot \frac{\alpha}{\sqrt{2\pi t^3}} e^{-\frac{1}{2t}\alpha^2} dt \overset{?}{=} \infty $$ Any help would be appreciated.","The problem is as follows: Let be a Brownian Motion, , and be the First Exit Time. Compute . I am aware that the result is not finite, however I am having trouble showing that the integral does not converge. This problem has answers here . However they use results I haven't seen or understand, such as Wald's Identities. What I have done so far: Where . I am stuck here: Any help would be appreciated.","(W_t) \alpha>0 \tau = \inf\{t>0 : W_t \geq \alpha\} \mathbb{E}(\tau) 
\mathbb{P}(\tau \leq t) 
= \mathbb{P}(W_t^* \geq \alpha)
= 2 \cdot \mathbb{P}(W_t \geq \alpha)
= 2(1- \Phi(\alpha / \sqrt{t}))
 W_t^* = \underset{0\leq s \leq t}{\sup} W_s 
f(t) 
= \frac{\partial}{\partial t} \mathbb{P}(\tau \leq t)
= 2\phi\left(\frac{\alpha}{\sqrt{t}}\right)\left(\frac{\alpha}{2 \sqrt{t^3}}\right)
= \frac{\alpha}{\sqrt{2\pi t^3}} e^{-\frac{1}{2t}\alpha^2}
 
\mathbb{E}(\tau)
= \int_0^{\infty} t \cdot \frac{\alpha}{\sqrt{2\pi t^3}} e^{-\frac{1}{2t}\alpha^2} dt
\overset{?}{=} \infty
","['probability', 'integration', 'statistics', 'normal-distribution', 'brownian-motion']"
35,Can non-convex optimization problems have closed form solutions?,Can non-convex optimization problems have closed form solutions?,,"In the realm of statistical modelling, creating a statistical model with respect to some data involves optimizing some mathematical function (e.g. Loss Function, OLS Equation, Maximum Likelihood Equation, etc. ) : Determining the final beta regression coefficients involves solving an optimization equation. From what I see: Sometimes, the equation to be optimized has a ""closed form solution"". For example, estimating the coefficients for a Linear Regression model involves optimizing an OLS or an MLE equation - but this optimization equation has a ""closed form solution"". This means that we can directly estimate the regression coefficients and do not require an iterative optimization algorithm. I have noticed that many of these instances where the optimization problem has a ""closed form solution"", the equation (i.e. the mathematical function being optimized) is usually ""Convex"". However, in most cases these optimization equations do not have ""closed form solutions"" (e.g. Neural Networks, Logistic Regression, etc.). In these cases, an iterative optimization algorithm (e.g. Gradient Descent) has to be used to estimate the model parameters (e.g.  weights of a Neural Network). I have also noticed that when this is the case, the optimization equation (i.e. the mathematical function being optimized) is usually ""Non-Convex"". I understand that optimizing some Convex Functions have ""closed form solutions"" while other Convex Functions do not have ""closed form solutions"". But: Can a mathematical problem that is Non-Convex (i.e. a Non-Convex Function) ever have a ""closed form solution""? Or is this never the case? Thank you!","In the realm of statistical modelling, creating a statistical model with respect to some data involves optimizing some mathematical function (e.g. Loss Function, OLS Equation, Maximum Likelihood Equation, etc. ) : Determining the final beta regression coefficients involves solving an optimization equation. From what I see: Sometimes, the equation to be optimized has a ""closed form solution"". For example, estimating the coefficients for a Linear Regression model involves optimizing an OLS or an MLE equation - but this optimization equation has a ""closed form solution"". This means that we can directly estimate the regression coefficients and do not require an iterative optimization algorithm. I have noticed that many of these instances where the optimization problem has a ""closed form solution"", the equation (i.e. the mathematical function being optimized) is usually ""Convex"". However, in most cases these optimization equations do not have ""closed form solutions"" (e.g. Neural Networks, Logistic Regression, etc.). In these cases, an iterative optimization algorithm (e.g. Gradient Descent) has to be used to estimate the model parameters (e.g.  weights of a Neural Network). I have also noticed that when this is the case, the optimization equation (i.e. the mathematical function being optimized) is usually ""Non-Convex"". I understand that optimizing some Convex Functions have ""closed form solutions"" while other Convex Functions do not have ""closed form solutions"". But: Can a mathematical problem that is Non-Convex (i.e. a Non-Convex Function) ever have a ""closed form solution""? Or is this never the case? Thank you!",,"['probability', 'statistics', 'optimization', 'maximum-likelihood', 'neural-networks']"
36,Show inequality using the Jensen inequality,Show inequality using the Jensen inequality,,"X is a non-negative random variable, with $\mathbb{E}(X) < \infty $ . My goal is to show this inequality: $$\sqrt{1+(\mathbb{E}(X))^2} \leq \mathbb{E}(\sqrt{1+X^2})$$ x² is a convex function, so with the Jensen inequality I get that: $$\sqrt{1+(\mathbb{E}(X))^2} \leq \sqrt{1+\mathbb{E}(X^2)} = \sqrt{\mathbb{E}(1+X^2)}$$ But when I use the Jensen inequality a second time, for the concave $\sqrt{ }$ function, I get that: $$\sqrt{1+(\mathbb{E}(X))^2} \leq \sqrt{1+\mathbb{E}(X^2)} = \sqrt{\mathbb{E}(1+X^2)}  \geq \mathbb{E}(\sqrt{1+X^2})   $$ where the inequality is in the wrong direction. Did I make a mistake? Or is more than the Jensen inequality needed to show this?","X is a non-negative random variable, with . My goal is to show this inequality: x² is a convex function, so with the Jensen inequality I get that: But when I use the Jensen inequality a second time, for the concave function, I get that: where the inequality is in the wrong direction. Did I make a mistake? Or is more than the Jensen inequality needed to show this?",\mathbb{E}(X) < \infty  \sqrt{1+(\mathbb{E}(X))^2} \leq \mathbb{E}(\sqrt{1+X^2}) \sqrt{1+(\mathbb{E}(X))^2} \leq \sqrt{1+\mathbb{E}(X^2)} = \sqrt{\mathbb{E}(1+X^2)} \sqrt{ } \sqrt{1+(\mathbb{E}(X))^2} \leq \sqrt{1+\mathbb{E}(X^2)} = \sqrt{\mathbb{E}(1+X^2)}  \geq \mathbb{E}(\sqrt{1+X^2})   ,"['statistics', 'inequality', 'expected-value', 'jensen-inequality']"
37,What minimizes mean absolute cubic error?,What minimizes mean absolute cubic error?,,"Given a family of real numbers $a_k$ , the median minimizes $\sum |x-a_k|$ and the mean minimizes $\sum |x-a_k|^2$ . Is there a known simple form of the value that minimizes $\sum |x-a_k|^3$ or any higher odd powers? Please see some context below. The focus is the cubic. I emphasize that I am asking this as a serious mathematical question looking for a simple formula or a proof that it does not exist. Or at least some other mathematical studies of this problem including work on the complexity of the problem. I am able to write naive brute force numerical code to determine the appropriate value in individual cases. So code to do this is not the interest here except perhaps if it represents a considerable reduction of complexity over the brute force naive method. The interest is in the mathematics - hence the posting in mathematics stack exchange. Where I got to ... The derivative of $|x-a_k|^{2n}$ is $2n(x-a_k)^{2n-1}$ because the absolute value is redundant in this case. The problem is then solved by finding the roots of a polynomial. It is as hard or easy as that task. But for odd powers, $|x-a_k|^{2n+1}$ , the derivative is $(2n+1)sgn(x-a_k)(x-a_k)^{2n}$ , where sgn is the signum (or sign) function. Hence, the derivative of the sum is $(2n+1)\sum_k sgn(x-a_k)(x-a_k)^{2n}$ , which is the negative sum of some of the terms and the positive sum of the rest. It is equal to zero when the balance point $m$ is found so that $\sum_{k=1}^m (x-a_k)^{2n} = \sum_{k=m+1}^n (x-a_k)^{2n}$ , assuming that the $a_k$ are ordered so that $s_k \le a_{k+1}$ . One could, of course, solve this numerically. For the cubic (and more generally) it would be a kind of median in the sense that is would be the point that balances $\sum (x-a_k)^2$ , so that there is equal weight of this on either side. This seems to be the more general concept - as the mean balances $\sum (x-a_k)^1$ and the median $\sum (x-a_k)^0$ . Notice that each $(x-a_k)^{2n}$ is positive definite with monotonic derivative. And so the sum of any of them is positive. If you partition it with nothing on the right then the left set is greater. Nothing on the left and the right set is greater. At some unique point they must flip over. That is there is a particular $k=m$ such that swapping this changes the balance. Now, if you put $x=a_m$ , then they will be imbalanced. If the left is bigger, then reduces $x$ so that some of $(x-a_k)^{2n}$ will be subtracted, or the other way if the left is smaller. From this it is apparent that there exists a unique such $x$ . It will be between $a_{m-1}$ and $a_{m+1}$ . Except in the case that there are less than 3 points, which can be handled separately. Can anyone give me references to other work on this problem?","Given a family of real numbers , the median minimizes and the mean minimizes . Is there a known simple form of the value that minimizes or any higher odd powers? Please see some context below. The focus is the cubic. I emphasize that I am asking this as a serious mathematical question looking for a simple formula or a proof that it does not exist. Or at least some other mathematical studies of this problem including work on the complexity of the problem. I am able to write naive brute force numerical code to determine the appropriate value in individual cases. So code to do this is not the interest here except perhaps if it represents a considerable reduction of complexity over the brute force naive method. The interest is in the mathematics - hence the posting in mathematics stack exchange. Where I got to ... The derivative of is because the absolute value is redundant in this case. The problem is then solved by finding the roots of a polynomial. It is as hard or easy as that task. But for odd powers, , the derivative is , where sgn is the signum (or sign) function. Hence, the derivative of the sum is , which is the negative sum of some of the terms and the positive sum of the rest. It is equal to zero when the balance point is found so that , assuming that the are ordered so that . One could, of course, solve this numerically. For the cubic (and more generally) it would be a kind of median in the sense that is would be the point that balances , so that there is equal weight of this on either side. This seems to be the more general concept - as the mean balances and the median . Notice that each is positive definite with monotonic derivative. And so the sum of any of them is positive. If you partition it with nothing on the right then the left set is greater. Nothing on the left and the right set is greater. At some unique point they must flip over. That is there is a particular such that swapping this changes the balance. Now, if you put , then they will be imbalanced. If the left is bigger, then reduces so that some of will be subtracted, or the other way if the left is smaller. From this it is apparent that there exists a unique such . It will be between and . Except in the case that there are less than 3 points, which can be handled separately. Can anyone give me references to other work on this problem?",a_k \sum |x-a_k| \sum |x-a_k|^2 \sum |x-a_k|^3 |x-a_k|^{2n} 2n(x-a_k)^{2n-1} |x-a_k|^{2n+1} (2n+1)sgn(x-a_k)(x-a_k)^{2n} (2n+1)\sum_k sgn(x-a_k)(x-a_k)^{2n} m \sum_{k=1}^m (x-a_k)^{2n} = \sum_{k=m+1}^n (x-a_k)^{2n} a_k s_k \le a_{k+1} \sum (x-a_k)^2 \sum (x-a_k)^1 \sum (x-a_k)^0 (x-a_k)^{2n} k=m x=a_m x (x-a_k)^{2n} x a_{m-1} a_{m+1},"['statistics', 'optimization']"
38,Expectation Value of Sample Mean,Expectation Value of Sample Mean,,"When deriving the expectation value of the sample mean, I am uncertain about the following step: $E(x_i) = E(x)$ The context is the following: $ \frac{1}{n}\sum_{i}E(x_i) = \frac{1}{n}\sum_{i}E(x) $ Why is that the expectation of a realized value of the random variable of x is equal to the expectation of x? Should I be looking at each $x_i$ as a random variable?","When deriving the expectation value of the sample mean, I am uncertain about the following step: The context is the following: Why is that the expectation of a realized value of the random variable of x is equal to the expectation of x? Should I be looking at each as a random variable?","E(x_i) = E(x) 
\frac{1}{n}\sum_{i}E(x_i) = \frac{1}{n}\sum_{i}E(x)
 x_i",['statistics']
39,Ask unbiased estimator of $\sigma ^2$ in normal distribution when either $\mu$ known or $\mu$ unknown？,Ask unbiased estimator of  in normal distribution when either  known or  unknown？,\sigma ^2 \mu \mu,"If $\mu$ is unknown, then $\frac{1}{n-1}  \sum_{i=1}^n (X_i - \overline X)^2$ is the unbiased estimator of $\sigma ^2$ . However, if $\mu$ is known, then $\frac{1}{n}  \sum_{i=1}^n (X_i - \mu)^2$ is the unbiased estimator of $\sigma ^2$ . I am very confused. From introductory statistics class, I know that given any random population, $E(S^2)$ is always equal to $\sigma ^2$ . Hence, for a normal distribution, I think the sample variance = $\frac{1}{n-1}  \sum_{i=1}^n (X_i - \overline X)^2$ should always be unbiased.","If is unknown, then is the unbiased estimator of . However, if is known, then is the unbiased estimator of . I am very confused. From introductory statistics class, I know that given any random population, is always equal to . Hence, for a normal distribution, I think the sample variance = should always be unbiased.",\mu \frac{1}{n-1}  \sum_{i=1}^n (X_i - \overline X)^2 \sigma ^2 \mu \frac{1}{n}  \sum_{i=1}^n (X_i - \mu)^2 \sigma ^2 E(S^2) \sigma ^2 \frac{1}{n-1}  \sum_{i=1}^n (X_i - \overline X)^2,"['probability', 'statistics', 'probability-distributions']"
40,Probability interpretation,Probability interpretation,,"Supose we have a mouse on a labyrinth and we associate $p$ as the probability of the mouse escaping this labyrinth this turn, and $(1-p)$ for the probability of him not escaping that turn. Call $X$ the random variable associated with the number of turns that the mouse takes in order to escape. If I want him to take, at best, $4$ turns to escape the labyrinth then I would consider the possibilities of: $$P(X \leq 4)= P(X = 4)+P(X = 3)+P(X = 2)+P(X = 1)$$ After some calculations I arrive at the probability: $$ P(X \leq 4)= 1-(1-p)^4 $$ On the other hand: $$ P(X \leq 4)=1-P(X > 4)$$ Which leads to: $$ P(X > 4) = (1-p)^4$$ This gives us the probability of him failling more then $4$ times, given that it is the sum: $$ P(X > 4) = P(X=5)+P(X = 6)+...=p(1-p)^4+p(1-p)^5+...=p \sum_{i=4}^n(1-p)^{i}=(1-p)^4$$ Can someone give me a intuitive interpretation for this? It seems a little odd that the summation would tend to $(1-p)^4$ when starting at $4$ .","Supose we have a mouse on a labyrinth and we associate as the probability of the mouse escaping this labyrinth this turn, and for the probability of him not escaping that turn. Call the random variable associated with the number of turns that the mouse takes in order to escape. If I want him to take, at best, turns to escape the labyrinth then I would consider the possibilities of: After some calculations I arrive at the probability: On the other hand: Which leads to: This gives us the probability of him failling more then times, given that it is the sum: Can someone give me a intuitive interpretation for this? It seems a little odd that the summation would tend to when starting at .",p (1-p) X 4 P(X \leq 4)= P(X = 4)+P(X = 3)+P(X = 2)+P(X = 1)  P(X \leq 4)= 1-(1-p)^4   P(X \leq 4)=1-P(X > 4)  P(X > 4) = (1-p)^4 4  P(X > 4) = P(X=5)+P(X = 6)+...=p(1-p)^4+p(1-p)^5+...=p \sum_{i=4}^n(1-p)^{i}=(1-p)^4 (1-p)^4 4,"['probability', 'statistics', 'conditional-probability']"
41,Distribution of the ratio of two Normal variables,Distribution of the ratio of two Normal variables,,"Considering a sample of size $n$ from a $N(\mu,\sigma^2)$ distribution: $X_1, \ldots , X_n$ , I need to find the ratio of \begin{equation}  R = \frac{\tilde{\mu} - \mu}{\hat{\mu} -\mu}, \end{equation} where $\tilde{\mu} = X_1 $ one observation, and $\hat{\mu} = \bar{X}$ , the sample mean. I know that $ \frac{\tilde{\mu} - \mu}{\sigma} \sim N(0,1)$ , $ \frac{\sqrt{n}(\hat{\mu} - \mu)}{\sigma} \sim N(0,1)$ , and the ratio of two normally distributed variables is Cauchy - for this to happen do we need for the variables to be independent? Also, there is a $\sqrt{n}$ coming in the picture when simplifying the ratio that I am not sure how to handle.","Considering a sample of size from a distribution: , I need to find the ratio of where one observation, and , the sample mean. I know that , , and the ratio of two normally distributed variables is Cauchy - for this to happen do we need for the variables to be independent? Also, there is a coming in the picture when simplifying the ratio that I am not sure how to handle.","n N(\mu,\sigma^2) X_1, \ldots , X_n \begin{equation}
 R = \frac{\tilde{\mu} - \mu}{\hat{\mu} -\mu},
\end{equation} \tilde{\mu} = X_1  \hat{\mu} = \bar{X}  \frac{\tilde{\mu} - \mu}{\sigma} \sim N(0,1)  \frac{\sqrt{n}(\hat{\mu} - \mu)}{\sigma} \sim N(0,1) \sqrt{n}","['statistics', 'probability-distributions', 'normal-distribution']"
42,Showing a sufficient statistic is not complete,Showing a sufficient statistic is not complete,,"Let $X_1.....X_n$ be independent Normal( $\theta, \theta^2$ ) for $\theta >0$ . Find a minimal sufficient statistic. Is it complete? I have a minimal sufficient statistic, $T=(\sum_{1}^{n}X_i,\sum_{1}^{n}X_i^2$ ), but cannot show it is complete.  I suspect I can find a counterexample to the completeness condition, but I have no intelligent strategy other than guessing random functions with expectation $0$ . A sketch or even starting point would be helpful. Edit: Duplicate of Not complete but minimal sufficient statistic But I would still like some intuition as to how one would come up with such a function.","Let be independent Normal( ) for . Find a minimal sufficient statistic. Is it complete? I have a minimal sufficient statistic, ), but cannot show it is complete.  I suspect I can find a counterexample to the completeness condition, but I have no intelligent strategy other than guessing random functions with expectation . A sketch or even starting point would be helpful. Edit: Duplicate of Not complete but minimal sufficient statistic But I would still like some intuition as to how one would come up with such a function.","X_1.....X_n \theta, \theta^2 \theta >0 T=(\sum_{1}^{n}X_i,\sum_{1}^{n}X_i^2 0","['statistics', 'statistical-inference']"
43,One-sided heavy tailed distribution,One-sided heavy tailed distribution,,"I seek a univariate distribution with analytically expressible density function that approximates (a vertically scaled version of) the standard normal distribution around the origin, but with a heavy tail extending in the positive direction (only). The distribution should be smooth and unimodal, with at least one parameter for specifying the heaviness of the one tail. My first thought is to mix a standard normal distribution with an exponential distribution (which decays slower than a normal distribution), but this causes a step change at the origin, making the distribution unsmooth. Trying to replace the exponential distribution with other positive distributions (such as Chi-squared, Beta prime, Chi, Dagum, F-distribution, Gamma, Erlang), it is possible to preserve smoothness, but this potentially introduces bimodality, depending on the parameters chosen. Can you suggest any idea for a distribution that: has analytically expressible PDF approximates (a vertically scaled version of) the standard normal distribution for $x<0$ is unimodal is smooth has a heavy tail in the $+x$ direction (with at least one parameter for specifying heaviness of the tail)","I seek a univariate distribution with analytically expressible density function that approximates (a vertically scaled version of) the standard normal distribution around the origin, but with a heavy tail extending in the positive direction (only). The distribution should be smooth and unimodal, with at least one parameter for specifying the heaviness of the one tail. My first thought is to mix a standard normal distribution with an exponential distribution (which decays slower than a normal distribution), but this causes a step change at the origin, making the distribution unsmooth. Trying to replace the exponential distribution with other positive distributions (such as Chi-squared, Beta prime, Chi, Dagum, F-distribution, Gamma, Erlang), it is possible to preserve smoothness, but this potentially introduces bimodality, depending on the parameters chosen. Can you suggest any idea for a distribution that: has analytically expressible PDF approximates (a vertically scaled version of) the standard normal distribution for is unimodal is smooth has a heavy tail in the direction (with at least one parameter for specifying heaviness of the tail)",x<0 +x,"['statistics', 'probability-distributions', 'normal-distribution', 'distribution-tails']"
44,Is there any way to calculate harmonic or geometric mean having probability density function?,Is there any way to calculate harmonic or geometric mean having probability density function?,,"I have probability density of function of some data (it's triangular.) How can I calculate harmonic or geometric mean of the data? I know for calculating arithmetic mean of a variable like $K$ , I have to calculate $\int_{0}^\infty K.P(K)dK$ but I don't have any ideas for other types of averaging methods (Harmonic and geometric).","I have probability density of function of some data (it's triangular.) How can I calculate harmonic or geometric mean of the data? I know for calculating arithmetic mean of a variable like , I have to calculate but I don't have any ideas for other types of averaging methods (Harmonic and geometric).",K \int_{0}^\infty K.P(K)dK,"['probability', 'statistics', 'probability-distributions', 'harmonic-functions', 'density-function']"
45,Probability of Multiple Weighted Coin Flips,Probability of Multiple Weighted Coin Flips,,"I would like to calculate the probabilities of the outcomes of three weighted coins being flipped. I believe what I am looking for is a Poisson Binomial Distribution . I am having trouble verifying/interpreting the results that I am finding on an online calculator . Edit: Order does not matter in this question - the below is a table of the sums of outcomes. +---------+---------+-------------+ | Outcome | Heads P | Probability | +---------+---------+-------------+ | 3 heads |     .75 | .421875??   | | 2 heads |     .75 | ??          | | 1 heads |     .75 | ??          | | 0 heads |     .75 | ??          | |         |         |  (Sum = 1)  | +---------+---------+-------------+ The .42 is calcualted for X>=3, but since there are only 3 flips it cannot be any greater. An alternate calculator provides a much lower answer, .03, which seems too low. Is a Poisson binomial distribution the correct calculation for this answer? (X=3 trials, .75 success) How would I find the probability of 2 out of 3 heads, 1 out of 3 heads, and no heads? Thank you for taking the time to explain what I might be missing here.","I would like to calculate the probabilities of the outcomes of three weighted coins being flipped. I believe what I am looking for is a Poisson Binomial Distribution . I am having trouble verifying/interpreting the results that I am finding on an online calculator . Edit: Order does not matter in this question - the below is a table of the sums of outcomes. +---------+---------+-------------+ | Outcome | Heads P | Probability | +---------+---------+-------------+ | 3 heads |     .75 | .421875??   | | 2 heads |     .75 | ??          | | 1 heads |     .75 | ??          | | 0 heads |     .75 | ??          | |         |         |  (Sum = 1)  | +---------+---------+-------------+ The .42 is calcualted for X>=3, but since there are only 3 flips it cannot be any greater. An alternate calculator provides a much lower answer, .03, which seems too low. Is a Poisson binomial distribution the correct calculation for this answer? (X=3 trials, .75 success) How would I find the probability of 2 out of 3 heads, 1 out of 3 heads, and no heads? Thank you for taking the time to explain what I might be missing here.",,"['probability', 'statistics', 'poisson-distribution']"
46,Binomial Calculating Probability of Airline Tickets,Binomial Calculating Probability of Airline Tickets,,"Because not all airline passengers show up for their reserved seat, an airline sells 125 tickets for a flight that holds only 115 passengers. The probability that a passenger does not show up is 0.05, and the passengers behave independently. Round your answers to four decimal places (e.g. 98.7654). a) What is the probability that every passenger who shows up can take the flight? b) What is the probability that the flight departs with at least one empty seat? I am not using a statistics program to calculate my answers like I have seen many answers on here use, but by using a formula: For example: P(115) = 125 C 115 * (.95)^115 * (.05)^10 = .0475 Similarly I have: P(116) = .0778 P(117) = .1137 P(118) = .1465 P(119) = .1637 P(120) = .1556 P(121) = .1221 P(122) = .0761 P(123) = .0353 P(124) = .0108 P(125) = .0016 So for part a) I did: 1 - P(X > 115) = 1 - .9032 = .0968 and for part b) I did: 1 - P(x >= 115) = 1 - .9507 = .0493 These numbers just do not seem correct to me. And I am confused as to why the probabilites are increasing from P(115) to P(119), (I would expect them to decrease, however I guess if they are on the rising part of the binomial distribution and then go to the falling part of the distribution at P(120) Edit: I know understand these values are correct and fall around the most probable value P(119) which is the mean. Thank you for help in clarifying.","Because not all airline passengers show up for their reserved seat, an airline sells 125 tickets for a flight that holds only 115 passengers. The probability that a passenger does not show up is 0.05, and the passengers behave independently. Round your answers to four decimal places (e.g. 98.7654). a) What is the probability that every passenger who shows up can take the flight? b) What is the probability that the flight departs with at least one empty seat? I am not using a statistics program to calculate my answers like I have seen many answers on here use, but by using a formula: For example: P(115) = 125 C 115 * (.95)^115 * (.05)^10 = .0475 Similarly I have: P(116) = .0778 P(117) = .1137 P(118) = .1465 P(119) = .1637 P(120) = .1556 P(121) = .1221 P(122) = .0761 P(123) = .0353 P(124) = .0108 P(125) = .0016 So for part a) I did: 1 - P(X > 115) = 1 - .9032 = .0968 and for part b) I did: 1 - P(x >= 115) = 1 - .9507 = .0493 These numbers just do not seem correct to me. And I am confused as to why the probabilites are increasing from P(115) to P(119), (I would expect them to decrease, however I guess if they are on the rising part of the binomial distribution and then go to the falling part of the distribution at P(120) Edit: I know understand these values are correct and fall around the most probable value P(119) which is the mean. Thank you for help in clarifying.",,"['statistics', 'binomial-distribution']"
47,Tricky coin probability,Tricky coin probability,,"Can someone please help, I am getting the wrong answer. Consider four coins labelled as 1, 2, 3 and 4. Suppose that the probability of obtaining a ‘head’ in a single toss of the 𝑖-𝑡h coin is $𝑖/4,\, 𝑖 = 1, 2, 3, 4.$ A coin is chosen uniformly at random and flipped. Given that the flip resulted in a ‘head’, the conditional probability that the coin was labelled either 1 or 2 equals. I tried doing this P(coin 1 or 2 | tails) =  P(coin 1 or 2 And Tails)/P(tails) \  =(1/4)(3/4)+(1/4)(2/4)   /  1/4(3/4)+(1/4)(2/4)+(1/4)(1/4) =5/6 In improved notation: $$P(C_1 \cup C_2 | T) = P((C_1 \cup C_2)T)/P(T) \\ = \frac{(1/4)(3/4) + (1/4)(2/4)} {(1/4)(3/4) + (1/4)(2/4) + (1/4)(1/4)} = 5/6.$$ But this is the wrong answer as the answer is one of 1/10,2/10,3/10,4/10. How to do this?","Can someone please help, I am getting the wrong answer. Consider four coins labelled as 1, 2, 3 and 4. Suppose that the probability of obtaining a ‘head’ in a single toss of the 𝑖-𝑡h coin is $𝑖/4,\, 𝑖 = 1, 2, 3, 4.$ A coin is chosen uniformly at random and flipped. Given that the flip resulted in a ‘head’, the conditional probability that the coin was labelled either 1 or 2 equals. I tried doing this P(coin 1 or 2 | tails) =  P(coin 1 or 2 And Tails)/P(tails) \  =(1/4)(3/4)+(1/4)(2/4)   /  1/4(3/4)+(1/4)(2/4)+(1/4)(1/4) =5/6 In improved notation: $$P(C_1 \cup C_2 | T) = P((C_1 \cup C_2)T)/P(T) \\ = \frac{(1/4)(3/4) + (1/4)(2/4)} {(1/4)(3/4) + (1/4)(2/4) + (1/4)(1/4)} = 5/6.$$ But this is the wrong answer as the answer is one of 1/10,2/10,3/10,4/10. How to do this?",,"['probability', 'statistics', 'statistical-inference']"
48,In Geometric distribution what does it mean to include first success,In Geometric distribution what does it mean to include first success,,"I was watching the harvard stat110 course on Geometric distribution and the PMF is $P(X = k) = pq^k$ where $p$ is the probability of success and $q = 1-p$. later he mentions another r.v $Y$ which he defined as the 1st success distribution and he mentions that this distribution, unlike the Geometric Distribution, includes the first success. I got a bit confused as to the meaning of including the first success, in the PMF of $Geo(p)$ there is a $p$, isn't this including the first success already?","I was watching the harvard stat110 course on Geometric distribution and the PMF is $P(X = k) = pq^k$ where $p$ is the probability of success and $q = 1-p$. later he mentions another r.v $Y$ which he defined as the 1st success distribution and he mentions that this distribution, unlike the Geometric Distribution, includes the first success. I got a bit confused as to the meaning of including the first success, in the PMF of $Geo(p)$ there is a $p$, isn't this including the first success already?",,"['statistics', 'probability-distributions']"
49,"Uniform distribution of $Z$ given $Y\sim U(2, 5)$",Uniform distribution of  given,"Z Y\sim U(2, 5)","Given that $Y \sim U(2, 5)$ and $Z = 3Y - 4$, what is the distribution for $Z$? I've worked out that for $Y \sim N(2, 5)$, $Z \sim N(2, 45)$ since $$\mu=3\cdot2 - 4 = 2$$ and $$\sigma^2=3^2 \cdot 5 = 45$$ I'm wondering how the working differs when we have a uniform distribution, rather than a normal distribution? Sorry if a similar question has been asked before - I could not find anything on my search! Thanks!","Given that $Y \sim U(2, 5)$ and $Z = 3Y - 4$, what is the distribution for $Z$? I've worked out that for $Y \sim N(2, 5)$, $Z \sim N(2, 45)$ since $$\mu=3\cdot2 - 4 = 2$$ and $$\sigma^2=3^2 \cdot 5 = 45$$ I'm wondering how the working differs when we have a uniform distribution, rather than a normal distribution? Sorry if a similar question has been asked before - I could not find anything on my search! Thanks!",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'uniform-distribution']"
50,Find a pivotal quantity and use it to approximate a 95% confidence interval,Find a pivotal quantity and use it to approximate a 95% confidence interval,,"Suppose $Y_1, Y_2, ... , Y_n$ denotes a random sample from a uniform distribution on the interval $(-\theta, 4\theta)$, where $\theta \gt 0$ us an unknown parameter. Assume that n is sufficiently large, find a pivotal quantity in terms of $\overline{Y}$and $\theta$. Use this pivotal quantity to derive a formula of: (i) an approximate 95% confidence interval for $\theta$. (ii) an approximate 95% confidence interval for $\theta^2$. What I have tried so far: (i) We know that $Y$ ~ $Unif(-\theta, 4\theta)$, so $\mu = 1.5\theta$ and $\sigma^2 = \frac{25\theta^2}{12}$. However, we also know that n is sufficiently large to apply the central limit theorem, so $Y$ ~ $N(1.5\theta, \frac{25\theta^2}{12})$ From that, we can create the pivotal quantity: $$\frac{\overline{Y} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{\overline{Y} - 1.5\theta}{\frac{5\theta}{\sqrt{12n}}} $$ So now we can set the problem up as $P(Z_{0.025} \le \frac{(\overline{Y} - 1.5\theta)\sqrt{12n}}{5\theta} \le Z_{0.975})$ After going through the math, I ended up with $P((\frac{-\sqrt{12n}}{9.8} + \frac{2}{3})\overline{Y} \ge \theta \ge (\frac{\sqrt{12n}}{9.8} + \frac{2}{3})\overline{Y})$ as my interval. I'm not really sure if that is correct. It seems a bit messy. (ii) For this part, I was having difficulty getting started. I'm not really sure how to go about finding a pivotal quantity for $\theta^2$, or if I'm just supposed to use the above pivotal quantity, which wouldn't make sense to me. I know that to be a pivotal quantity, it has to be a function of my random variable Y and my parameter $\theta$. And I also know that the distribution of my pivotal quantity has to be parameter free. But I'm otherwise stuck at this point. Any help or direction would be greatly appreciated.","Suppose $Y_1, Y_2, ... , Y_n$ denotes a random sample from a uniform distribution on the interval $(-\theta, 4\theta)$, where $\theta \gt 0$ us an unknown parameter. Assume that n is sufficiently large, find a pivotal quantity in terms of $\overline{Y}$and $\theta$. Use this pivotal quantity to derive a formula of: (i) an approximate 95% confidence interval for $\theta$. (ii) an approximate 95% confidence interval for $\theta^2$. What I have tried so far: (i) We know that $Y$ ~ $Unif(-\theta, 4\theta)$, so $\mu = 1.5\theta$ and $\sigma^2 = \frac{25\theta^2}{12}$. However, we also know that n is sufficiently large to apply the central limit theorem, so $Y$ ~ $N(1.5\theta, \frac{25\theta^2}{12})$ From that, we can create the pivotal quantity: $$\frac{\overline{Y} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{\overline{Y} - 1.5\theta}{\frac{5\theta}{\sqrt{12n}}} $$ So now we can set the problem up as $P(Z_{0.025} \le \frac{(\overline{Y} - 1.5\theta)\sqrt{12n}}{5\theta} \le Z_{0.975})$ After going through the math, I ended up with $P((\frac{-\sqrt{12n}}{9.8} + \frac{2}{3})\overline{Y} \ge \theta \ge (\frac{\sqrt{12n}}{9.8} + \frac{2}{3})\overline{Y})$ as my interval. I'm not really sure if that is correct. It seems a bit messy. (ii) For this part, I was having difficulty getting started. I'm not really sure how to go about finding a pivotal quantity for $\theta^2$, or if I'm just supposed to use the above pivotal quantity, which wouldn't make sense to me. I know that to be a pivotal quantity, it has to be a function of my random variable Y and my parameter $\theta$. And I also know that the distribution of my pivotal quantity has to be parameter free. But I'm otherwise stuck at this point. Any help or direction would be greatly appreciated.",,"['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'confidence-interval']"
51,How Does Probability Recursion Work?,How Does Probability Recursion Work?,,"I don't undstand how the textbook come up with recursive forumulas. For example, Consider the following gambling game for two players, Black and White. Black puts $b$ black balls and White puts $w$ white balls in a box. Black and White take turns at drawing at random from the box, with replacement between draws until either Black wins by drawing a black ball or White wins by drawing a white ball. Supposed black draws first. Calculate $P($ Black wins $)$ Textbook Answer: I'm not sure how they knew their equation encompasses all ways Black could win. I going to assume this is their reasoning: The first draw could only be be Black or White. $P($ Black wins $)$ $= P($ Black wins $|B)P(B) + P($ Black wins $|W)P(W)$ , obviously this encompasses all ways Black could win. $= P($ Black wins $|B)P(B) + ( P($ Black wins $|WW)P(WW) + P($ Black wins $|WB)P(WB) )$ $= P($ Black wins $|B)P(B)$ + ( 0 + $P($ Black wins $|WB)P(WB) )$ $= P($ Black wins $|B)P(B)$ + $P($ Black wins $|WB)P(WB)$ ? And how to set-up recursive probability equations in general + when to use them? Edit 1: I used everyone's feedback and came up with an in-depth solution. I think the logic is sound. For anyone that need it:","I don't undstand how the textbook come up with recursive forumulas. For example, Consider the following gambling game for two players, Black and White. Black puts black balls and White puts white balls in a box. Black and White take turns at drawing at random from the box, with replacement between draws until either Black wins by drawing a black ball or White wins by drawing a white ball. Supposed black draws first. Calculate Black wins Textbook Answer: I'm not sure how they knew their equation encompasses all ways Black could win. I going to assume this is their reasoning: The first draw could only be be Black or White. Black wins Black wins Black wins , obviously this encompasses all ways Black could win. Black wins Black wins Black wins Black wins + ( 0 + Black wins Black wins + Black wins ? And how to set-up recursive probability equations in general + when to use them? Edit 1: I used everyone's feedback and came up with an in-depth solution. I think the logic is sound. For anyone that need it:",b w P( ) P( ) = P( |B)P(B) + P( |W)P(W) = P( |B)P(B) + ( P( |WW)P(WW) + P( |WB)P(WB) ) = P( |B)P(B) P( |WB)P(WB) ) = P( |B)P(B) P( |WB)P(WB),['statistics']
52,What's the point of variance?,What's the point of variance?,,"The big question: Why should I use variance over standard deviation? In what contexts should variance be used (on its own, not with SD)? I'm failing to understand the point of variance - anything I found on the internet about variance can easily be explained with SD.","The big question: Why should I use variance over standard deviation? In what contexts should variance be used (on its own, not with SD)? I'm failing to understand the point of variance - anything I found on the internet about variance can easily be explained with SD.",,"['statistics', 'soft-question', 'standard-deviation', 'variance']"
53,Test whether we can infer that the population means differ,Test whether we can infer that the population means differ,,"Naturally, this is very insignificant and we fail to reject the null hypothesis. Is this the right calculation?","Naturally, this is very insignificant and we fail to reject the null hypothesis. Is this the right calculation?",,"['statistics', 'hypothesis-testing']"
54,Median of discrete and continuous random variables.,Median of discrete and continuous random variables.,,"If case of continuous random variables, we define median 'm' as a value such that the $P(X\ge m)=0.5$ and $P(X\le m)=0.5$ . This link also mentions the same https://www.google.co.in/url?sa=t&source=web&rct=j&url=https://www.wiley.com/legacy/Australia/Landing_Pages/c12ContinuousProbabilityDistributions_web.pdf&ved=0ahUKEwiCvLm0va3YAhUBro8KHUaYA-sQFgg6MAI&usg=AOvVaw1qTWw5kE9ZsgWJ6RtMjngD For discrete random variables, $P(X\ge m)\ge0.5$ and $P(X\le m)\ge0.5$ Why is the cumulative probability required to be greater than or equal to $0.5$ in case of discrete random variables and only equals to $0.5$ in case of continuous random variable?","If case of continuous random variables, we define median 'm' as a value such that the and . This link also mentions the same https://www.google.co.in/url?sa=t&source=web&rct=j&url=https://www.wiley.com/legacy/Australia/Landing_Pages/c12ContinuousProbabilityDistributions_web.pdf&ved=0ahUKEwiCvLm0va3YAhUBro8KHUaYA-sQFgg6MAI&usg=AOvVaw1qTWw5kE9ZsgWJ6RtMjngD For discrete random variables, and Why is the cumulative probability required to be greater than or equal to in case of discrete random variables and only equals to in case of continuous random variable?",P(X\ge m)=0.5 P(X\le m)=0.5 P(X\ge m)\ge0.5 P(X\le m)\ge0.5 0.5 0.5,"['probability', 'statistics', 'probability-distributions', 'random-variables', 'median']"
55,Error in calculation of $\pi$ using Monte Carlo method.,Error in calculation of  using Monte Carlo method.,\pi,"So lets say we are trying to calculate value of $\pi$ using MonteCarlo method. By picking random points in a square and measuring their distance from the center and if $k$ points lie inside the circle using the ratio $\frac{k}N$ to calculate the value of $\pi$. How do I derive the formula for variance of the calculated value of $\pi$? This is what I have got so far. Say the probability that the point lies inside the circle is $p$. Say we have N random points in the square, of which k lie inside the circle. The probability that k points lie inside the circle is $\binom{N}{k}p^k(1-p)^{N-k}$. The error in estimate of $\pi$ is $e=||c\pi-\frac{N}k||$. So the expected value of error $E(e) = \sum_{k=0}^{k=N}\left\|c\pi-\frac{N}k\right\|\binom{N}{k}p^k(1-p)^{N-k}$? Is the expectation value of error that I have written correct, how do I evaluate it?","So lets say we are trying to calculate value of $\pi$ using MonteCarlo method. By picking random points in a square and measuring their distance from the center and if $k$ points lie inside the circle using the ratio $\frac{k}N$ to calculate the value of $\pi$. How do I derive the formula for variance of the calculated value of $\pi$? This is what I have got so far. Say the probability that the point lies inside the circle is $p$. Say we have N random points in the square, of which k lie inside the circle. The probability that k points lie inside the circle is $\binom{N}{k}p^k(1-p)^{N-k}$. The error in estimate of $\pi$ is $e=||c\pi-\frac{N}k||$. So the expected value of error $E(e) = \sum_{k=0}^{k=N}\left\|c\pi-\frac{N}k\right\|\binom{N}{k}p^k(1-p)^{N-k}$? Is the expectation value of error that I have written correct, how do I evaluate it?",,"['probability', 'statistics', 'monte-carlo', 'simulation']"
56,Can Statistics be made Rigorous,Can Statistics be made Rigorous,,"I am taking a statistics class this term, and this is really my first taste of the subject. We were given the following definition: Let $f_n(A)$ be the relative frequency of some random event $A$ occurring over $n$ trials. Then if $A$ occurred $0\leq m \leq n$ times: $f_n(A) = \frac{m}{n}$. After repeated trials we will find that each time $f_n(A) \approx p$ for some number $p\in[0,1]$. We call this the frequentest definition of probability, and really it says that the odds of a random event $A$ occuring is that number $p$. So naturally I think well then we must have: $$ p = \lim_{n\rightarrow\infty} f_n(A) $$ However, after more careful thought this cannot be true. Since for a sequence $f_n$ to be convergent we would need for any $\epsilon > 0$ there to exist some $N\in\mathbb{N}$ such that if $n\geq N$ we have: $\left|f_n-p\right| \leq \epsilon$. But since $A$ is a random event we cannot conclude that after so many trials we won't get just a sequence of other events from the sample space that make it look like $p$ is a different value. So how do we come up with a rigorous definition of the probability of a random event? Any suggested readings would be greately appreciated.","I am taking a statistics class this term, and this is really my first taste of the subject. We were given the following definition: Let $f_n(A)$ be the relative frequency of some random event $A$ occurring over $n$ trials. Then if $A$ occurred $0\leq m \leq n$ times: $f_n(A) = \frac{m}{n}$. After repeated trials we will find that each time $f_n(A) \approx p$ for some number $p\in[0,1]$. We call this the frequentest definition of probability, and really it says that the odds of a random event $A$ occuring is that number $p$. So naturally I think well then we must have: $$ p = \lim_{n\rightarrow\infty} f_n(A) $$ However, after more careful thought this cannot be true. Since for a sequence $f_n$ to be convergent we would need for any $\epsilon > 0$ there to exist some $N\in\mathbb{N}$ such that if $n\geq N$ we have: $\left|f_n-p\right| \leq \epsilon$. But since $A$ is a random event we cannot conclude that after so many trials we won't get just a sequence of other events from the sample space that make it look like $p$ is a different value. So how do we come up with a rigorous definition of the probability of a random event? Any suggested readings would be greately appreciated.",,['statistics']
57,How to get PDF from moments?,How to get PDF from moments?,,"I want to make joint PDF in the case when I have the mean, the variance, the skewness and kurtosis of my solution. These four moments are spatial and time variables. mean(x,t), skewness(x,t)... Thanks","I want to make joint PDF in the case when I have the mean, the variance, the skewness and kurtosis of my solution. These four moments are spatial and time variables. mean(x,t), skewness(x,t)... Thanks",,"['statistics', 'probability-distributions']"
58,Express the generating function of $Y=aX+b$ as a function of $M_x(t)$,Express the generating function of  as a function of,Y=aX+b M_x(t),"I need to express the generating function of $Y=aX+b$ as a function of $M_x(t)$. For me, the generating function of a variable $Y$ is the expected value of $e^{ty}$, like this: $$M_y(t) = E[e^{ty}] = E[e^{t(ax+b)}] = E[e^{tax}e^{tb}]$$ how to express it in function of $M_x(t)$? I thing I should write it as something related to $E[e^{tx}]$ but I don't know how to do it. Should I use some expected value property?","I need to express the generating function of $Y=aX+b$ as a function of $M_x(t)$. For me, the generating function of a variable $Y$ is the expected value of $e^{ty}$, like this: $$M_y(t) = E[e^{ty}] = E[e^{t(ax+b)}] = E[e^{tax}e^{tb}]$$ how to express it in function of $M_x(t)$? I thing I should write it as something related to $E[e^{tx}]$ but I don't know how to do it. Should I use some expected value property?",,"['probability', 'statistics', 'moment-generating-functions']"
59,Finding distribution of $\frac{X_1+X_2 X_3}{\sqrt{1+X_3^2}}$,Finding distribution of,\frac{X_1+X_2 X_3}{\sqrt{1+X_3^2}},"I am trying to find distribution of random variable: $$\frac{X_1+X_2 X_3}{\sqrt{1+X_3^2}}$$ where $X_i \sim \mathcal{N}(0,1)$ and independent. My thinking so far is to use random variable algebra and to find distributions step by step. However, I don't know what to do with the variable: $\sqrt{1+X_3^2}$ (it seems like some variant of $\chi$-distribution). Moreover, I'm worried that my thinking is to complicated and that the solution should be more elegant.","I am trying to find distribution of random variable: $$\frac{X_1+X_2 X_3}{\sqrt{1+X_3^2}}$$ where $X_i \sim \mathcal{N}(0,1)$ and independent. My thinking so far is to use random variable algebra and to find distributions step by step. However, I don't know what to do with the variable: $\sqrt{1+X_3^2}$ (it seems like some variant of $\chi$-distribution). Moreover, I'm worried that my thinking is to complicated and that the solution should be more elegant.",,"['statistics', 'probability-distributions', 'normal-distribution']"
60,"For a continuous random variable, when can you use the PMF vs. the CDF?","For a continuous random variable, when can you use the PMF vs. the CDF?",,"I think I am missing a core concept in my (fairly basic) probability class.  I will try to explain my confusion as best I can... If I am given a continuous random variable (for instance, say that we have $X$ which follows an exponential distribution with expected value $E(X)=3$) and we want to to find the probability that the outcome is greater/less than a particular value (continuing with my example, say we are trying to find $P(x>5)$,) my intuition tells me that I would need to integrate the exponential PMF from 5 to infinity.  However, in looking at the solution for this particular problem, I can actually calculate the answer by simply plugging 5 into the exponential PMF. Can anybody explain to me when I would be able to simply plug the value into the PMF and when I would need to instead integrate the PMF? I apologize if this is unclear! My best guess here is that I am missing some key difference between the PMF and the CDF. If anybody could try and elucidate this for me I would be very grateful!  Thanks in advance.","I think I am missing a core concept in my (fairly basic) probability class.  I will try to explain my confusion as best I can... If I am given a continuous random variable (for instance, say that we have $X$ which follows an exponential distribution with expected value $E(X)=3$) and we want to to find the probability that the outcome is greater/less than a particular value (continuing with my example, say we are trying to find $P(x>5)$,) my intuition tells me that I would need to integrate the exponential PMF from 5 to infinity.  However, in looking at the solution for this particular problem, I can actually calculate the answer by simply plugging 5 into the exponential PMF. Can anybody explain to me when I would be able to simply plug the value into the PMF and when I would need to instead integrate the PMF? I apologize if this is unclear! My best guess here is that I am missing some key difference between the PMF and the CDF. If anybody could try and elucidate this for me I would be very grateful!  Thanks in advance.",,"['probability', 'statistics']"
61,Show that the largest obervation from a discrete uniform distribution is complete and sufficient,Show that the largest obervation from a discrete uniform distribution is complete and sufficient,,"Consider a random sample of size $n$ from a population with pmf $ P(X=x)=\frac{1}{\theta} $ for $x\in \{1,2,..., \theta\}$. I need to show that $Y=X_{(n)}$ is complete sufficient where $X_{(n)}$ is the largest order statistic. $ P(Y=y)=P(Y \le y)- P(Y \le y-1) = P(X \le y)^n - P(X \le y-1)^n  = \left( \frac{y}{\theta} \right)^n - \left( \frac{y-1}{\theta} \right)^n = \dfrac{y^n - (y-1)^n}{\theta ^n}$. Also the sample pmf is $ P(\mathbf X=\mathbf x) = \dfrac{1}{\theta ^n}  $ and since $ \frac{P(\mathbf X=\mathbf x) }{P(Y=y)}$ is independent of $\theta$ then this means that $Y$ is sufficient for $\theta$. Now to show that if $Y$ is complete then for any measurable function $g(y)$ such that $Eg(y)=0$ for any $\theta$ implys that $g=0$ almost surely. $0= Eg(y) = \sum_{y=1}^{\theta}g(y)\frac{1}{\theta ^n}(y^n - (y-1)^n )\Rightarrow \sum_{y=1}^{\theta}g(y)(y^n - (y-1)^n)=0$ . If we let $g(1)=1$ and $g(2)=-\frac{1}{2^n-1}$ and $ g(y)=0 $ for each $y\ge 3$ then the $Eg(y)=0$ but $g$ is not $0$ almost surely. So this would mean that $Y$ is not complete but Im assuming im doing something wrong here since the problem is telling me that $Y$ is complete and that I need to show that. Any help is appreciated","Consider a random sample of size $n$ from a population with pmf $ P(X=x)=\frac{1}{\theta} $ for $x\in \{1,2,..., \theta\}$. I need to show that $Y=X_{(n)}$ is complete sufficient where $X_{(n)}$ is the largest order statistic. $ P(Y=y)=P(Y \le y)- P(Y \le y-1) = P(X \le y)^n - P(X \le y-1)^n  = \left( \frac{y}{\theta} \right)^n - \left( \frac{y-1}{\theta} \right)^n = \dfrac{y^n - (y-1)^n}{\theta ^n}$. Also the sample pmf is $ P(\mathbf X=\mathbf x) = \dfrac{1}{\theta ^n}  $ and since $ \frac{P(\mathbf X=\mathbf x) }{P(Y=y)}$ is independent of $\theta$ then this means that $Y$ is sufficient for $\theta$. Now to show that if $Y$ is complete then for any measurable function $g(y)$ such that $Eg(y)=0$ for any $\theta$ implys that $g=0$ almost surely. $0= Eg(y) = \sum_{y=1}^{\theta}g(y)\frac{1}{\theta ^n}(y^n - (y-1)^n )\Rightarrow \sum_{y=1}^{\theta}g(y)(y^n - (y-1)^n)=0$ . If we let $g(1)=1$ and $g(2)=-\frac{1}{2^n-1}$ and $ g(y)=0 $ for each $y\ge 3$ then the $Eg(y)=0$ but $g$ is not $0$ almost surely. So this would mean that $Y$ is not complete but Im assuming im doing something wrong here since the problem is telling me that $Y$ is complete and that I need to show that. Any help is appreciated",,"['probability', 'statistics', 'expectation']"
62,Conditional probability and testing twice,Conditional probability and testing twice,,"I am struggling with an interview quiz question which starts with a standard conditional probability part: To detect genetic defects, you are in charge of    performing a test. You know that: 1% of people have a genetic defect 99.9% of tests for the gene detect the defect (true positives) 5% of the tests give a positive result even though there is no defect (false positives) Given that the condition of a patient is known, the results of multiple tests are independent a)   If a person gets a positive test result, what is the probability that he/she actually has the genetic defect? For a), I would argue that this is standard conditional probability and can be solved with Bayes Rule. Let's call the event ""$+$"" when a person tests positive, ""$d$"" when a person has the disease and ""$\bar{d}$"" when a person does not have the disease. Now we are looking for $P(d\mid+)$, so the conditional probability that someone actually has the disease when he tests positive. Given Bayes, that is \begin{align} P(d\mid+) & = \frac{P(+\mid d)}{P(+)}\cdot P(d) = \frac{0.999}{P(+\mid d)\cdot P(d) + P(+\mid\bar{d})\cdot P(\bar{d})}\cdot 0.01 \\[10pt] & = \frac{0.999}{0.999\cdot 0.01 + 0.05\cdot 0.99}\cdot 0.01 \approx 0.168. \end{align} So the probability is roughly 17%. What is more complicated for me is b): b) If a person gets a positive result in his/her first test, what is the probability of having a positive result in his/her second test? I would argue that we are looking for $P(++|+)$, i.e. the probability that someone tests positive the second time under the condition that he tested positive the first time. So we can apply Bayes again and get $\frac{P(+|++)}{P(+)}\cdot P(++)$. I'd argue that $P(+|++)$ is always 1 and that $P(++) = P(+)\cdot P(+)$. We can cancel out one $P(+)$ and this leaves us with $P(++|+) = P(+)$. On the one hand this looks reasonable given the independence proclaimed, on the other hand it feels counter-intuitive that the probability would only be 6% (on the third hand, we are talking about statistics here and that never went well together with common sense for me :-)). Thoughts?","I am struggling with an interview quiz question which starts with a standard conditional probability part: To detect genetic defects, you are in charge of    performing a test. You know that: 1% of people have a genetic defect 99.9% of tests for the gene detect the defect (true positives) 5% of the tests give a positive result even though there is no defect (false positives) Given that the condition of a patient is known, the results of multiple tests are independent a)   If a person gets a positive test result, what is the probability that he/she actually has the genetic defect? For a), I would argue that this is standard conditional probability and can be solved with Bayes Rule. Let's call the event ""$+$"" when a person tests positive, ""$d$"" when a person has the disease and ""$\bar{d}$"" when a person does not have the disease. Now we are looking for $P(d\mid+)$, so the conditional probability that someone actually has the disease when he tests positive. Given Bayes, that is \begin{align} P(d\mid+) & = \frac{P(+\mid d)}{P(+)}\cdot P(d) = \frac{0.999}{P(+\mid d)\cdot P(d) + P(+\mid\bar{d})\cdot P(\bar{d})}\cdot 0.01 \\[10pt] & = \frac{0.999}{0.999\cdot 0.01 + 0.05\cdot 0.99}\cdot 0.01 \approx 0.168. \end{align} So the probability is roughly 17%. What is more complicated for me is b): b) If a person gets a positive result in his/her first test, what is the probability of having a positive result in his/her second test? I would argue that we are looking for $P(++|+)$, i.e. the probability that someone tests positive the second time under the condition that he tested positive the first time. So we can apply Bayes again and get $\frac{P(+|++)}{P(+)}\cdot P(++)$. I'd argue that $P(+|++)$ is always 1 and that $P(++) = P(+)\cdot P(+)$. We can cancel out one $P(+)$ and this leaves us with $P(++|+) = P(+)$. On the one hand this looks reasonable given the independence proclaimed, on the other hand it feels counter-intuitive that the probability would only be 6% (on the third hand, we are talking about statistics here and that never went well together with common sense for me :-)). Thoughts?",,"['statistics', 'bayesian', 'bayes-theorem']"
63,Asymptotic behaviour of $\mathbb{E}[|\chi_n^2 - n|]$.,Asymptotic behaviour of .,\mathbb{E}[|\chi_n^2 - n|],"I want to know how $\mathbb{E}[|\chi_n^2 - n|]$ behaves as $n\to \infty$. Simulating this in R suggest that it grows at a rate of $\sqrt{n}$, but I am unable to prove it. Setting $\chi_n^2 =\sum_{i=1}^n Z_i^2$, where $Z_i$ are iid standard normal random variables, there is a trivial upper bound $$ \mathbb{E}[|\chi_n^2 - n]|]  = \mathbb{E}[|\sum_{i=1}^n (Z_i^2-1)|]\\ \leq \sum_{i=1}^n \mathbb{E}[|Z_i^2 - 1|], $$ which grows at a rate of $n$ as $n\to\infty$. However, this bound is clearly too high. What can we say about the limiting behaviour of $\mathbb{E}[|\chi_n^2 - n|]$, or is there even an explicit expression for it?","I want to know how $\mathbb{E}[|\chi_n^2 - n|]$ behaves as $n\to \infty$. Simulating this in R suggest that it grows at a rate of $\sqrt{n}$, but I am unable to prove it. Setting $\chi_n^2 =\sum_{i=1}^n Z_i^2$, where $Z_i$ are iid standard normal random variables, there is a trivial upper bound $$ \mathbb{E}[|\chi_n^2 - n]|]  = \mathbb{E}[|\sum_{i=1}^n (Z_i^2-1)|]\\ \leq \sum_{i=1}^n \mathbb{E}[|Z_i^2 - 1|], $$ which grows at a rate of $n$ as $n\to\infty$. However, this bound is clearly too high. What can we say about the limiting behaviour of $\mathbb{E}[|\chi_n^2 - n|]$, or is there even an explicit expression for it?",,"['probability', 'statistics', 'expectation', 'chi-squared']"
64,Can I bound the correlation of two random variables using the mutual information?,Can I bound the correlation of two random variables using the mutual information?,,"As correlation $\rho_{X,Y} := \frac{Cov(X,Y)}{\sigma_X \sigma_Y}$ sort of measures the linear dependence of two random variables, and mutual information $I(X; Y) := H(X) - H(X|Y)$ measures the general dependence of two random variables, I feel like it should be possible to get an upper bound on the correlation in terms of the mutual information. I expect that as the mutual information increases, correlation tends to 1, and as mutual information tends to 0, correlation also does. Can anyone help me formalise this?","As correlation $\rho_{X,Y} := \frac{Cov(X,Y)}{\sigma_X \sigma_Y}$ sort of measures the linear dependence of two random variables, and mutual information $I(X; Y) := H(X) - H(X|Y)$ measures the general dependence of two random variables, I feel like it should be possible to get an upper bound on the correlation in terms of the mutual information. I expect that as the mutual information increases, correlation tends to 1, and as mutual information tends to 0, correlation also does. Can anyone help me formalise this?",,"['probability', 'statistics', 'correlation', 'covariance']"
65,Probability and Conditional Probability,Probability and Conditional Probability,,"Could someone please provide a worked solution to this question? A box contains 5 amber, 7 blue and 9 green balls. Six of the balls are removed from the box at random and without replacement. Find the probability that (a) three out of the six balls are blue; (b) four of the balls are blue and two are green; (c) the second ball to be selected is amber, given that the final ball to be selected is blue. I was wondering if there is a combinatorial argument for these types of problems,  because multiplying fractions here seems a little time consuming and messy. My answers: (a) $\frac{7}{21}\times\frac{6}{20}\times\frac{5}{19}\times\frac{14}{18}\times\frac{13}{17}\times\frac{12}{16}\times\frac{6!}{(3!)^2}$ (b) $\frac{7}{21}\times\frac{6}{20}\times\frac{5}{19}\times\frac{4}{18}\times\frac{9}{17}\times\frac{8}{16}\times\frac{6!}{(4!)(2!)}$ Any help very much appreciated, as always.","Could someone please provide a worked solution to this question? A box contains 5 amber, 7 blue and 9 green balls. Six of the balls are removed from the box at random and without replacement. Find the probability that (a) three out of the six balls are blue; (b) four of the balls are blue and two are green; (c) the second ball to be selected is amber, given that the final ball to be selected is blue. I was wondering if there is a combinatorial argument for these types of problems,  because multiplying fractions here seems a little time consuming and messy. My answers: (a) $\frac{7}{21}\times\frac{6}{20}\times\frac{5}{19}\times\frac{14}{18}\times\frac{13}{17}\times\frac{12}{16}\times\frac{6!}{(3!)^2}$ (b) $\frac{7}{21}\times\frac{6}{20}\times\frac{5}{19}\times\frac{4}{18}\times\frac{9}{17}\times\frac{8}{16}\times\frac{6!}{(4!)(2!)}$ Any help very much appreciated, as always.",,"['probability', 'combinatorics', 'statistics']"
66,Prove that $\sum_{k=0}^x {n \choose k}p^k(1-p)^{n-k}=(n-x){n \choose x}\int_0^{1-p}t^{n-x-1}(1-t)^xdt $,Prove that,\sum_{k=0}^x {n \choose k}p^k(1-p)^{n-k}=(n-x){n \choose x}\int_0^{1-p}t^{n-x-1}(1-t)^xdt ,"For $0\le p \le 1$ and $x=0,1,2,...,n$, I need to prove that $\sum_{k=0}^x {n \choose k}p^k(1-p)^{n-k}=(n-x){n \choose x}\int_0^{1-p}t^{n-x-1}(1-t)^xdt  $ and the two hints are either differentiate both sides with respect to $p$ or integrate by parts. First since this is a finite sum $$\frac{d}{dp}\sum_{k=0}^x {n \choose k}p^k(1-p)^{n-k} =\sum_{k=0}^x \frac{d}{dp} {n \choose k}p^k(1-p)^{n-k} =\sum_{k=0}^x {n \choose k}\left(kp^{k-1}(1-p)^{n-k}-(n-k) p^{k}(1-p)^{n-k-1}\right)$$ and $$  \frac{d}{dp} \int_0^{1-p}t^{n-x-1}(1-t)^xdt = -(1-p)^{n-x-1}(p)^{x}   $$ and assuming I didn't make a mistake I don't see how this helps. I was also having trouble trying to make integration by parts to work. Could someone please help put me in the right direction?","For $0\le p \le 1$ and $x=0,1,2,...,n$, I need to prove that $\sum_{k=0}^x {n \choose k}p^k(1-p)^{n-k}=(n-x){n \choose x}\int_0^{1-p}t^{n-x-1}(1-t)^xdt  $ and the two hints are either differentiate both sides with respect to $p$ or integrate by parts. First since this is a finite sum $$\frac{d}{dp}\sum_{k=0}^x {n \choose k}p^k(1-p)^{n-k} =\sum_{k=0}^x \frac{d}{dp} {n \choose k}p^k(1-p)^{n-k} =\sum_{k=0}^x {n \choose k}\left(kp^{k-1}(1-p)^{n-k}-(n-k) p^{k}(1-p)^{n-k-1}\right)$$ and $$  \frac{d}{dp} \int_0^{1-p}t^{n-x-1}(1-t)^xdt = -(1-p)^{n-x-1}(p)^{x}   $$ and assuming I didn't make a mistake I don't see how this helps. I was also having trouble trying to make integration by parts to work. Could someone please help put me in the right direction?",,"['integration', 'combinatorics', 'statistics']"
67,Does a 'simple random sample' have to be drawn from a population of independent and identically distributed random variables?,Does a 'simple random sample' have to be drawn from a population of independent and identically distributed random variables?,,"I'm reading an Econometrics textbook and it talks about ""Simple Random Samples"" and ""IID draws"" (Independent, Identicaly Distributed variables). While it defines the two seperately, it also seems to imply that they are the same thing. From what I understand, a simple random sample is where n objects are selected from a population at random. While an IID draw is where n objects are randomly selected from a population of independent and identically distributed random variables. (by randomly selected I mean that each random variable is equally likely to be selected) So: Does is a 'simple random sample' the same thing as an 'iid draw' or are they not necessarily the same thing?","I'm reading an Econometrics textbook and it talks about ""Simple Random Samples"" and ""IID draws"" (Independent, Identicaly Distributed variables). While it defines the two seperately, it also seems to imply that they are the same thing. From what I understand, a simple random sample is where n objects are selected from a population at random. While an IID draw is where n objects are randomly selected from a population of independent and identically distributed random variables. (by randomly selected I mean that each random variable is equally likely to be selected) So: Does is a 'simple random sample' the same thing as an 'iid draw' or are they not necessarily the same thing?",,"['probability', 'statistics', 'economics', 'sampling']"
68,discretized Brownian motion,discretized Brownian motion,,"These are the definitions I'm working with: A (standard) Brownian motion in $\mathbb{R}$ is a stochastic process $W(t)$ $(t \geq 0)$ such that the following properties hold: $W(0) = 0$ almost certain $W(t) - W(s) \sim\mathcal{N}(0, t - s)$ (for 0 $\leq s \leq t$) For every $0 = t_0 < t_1 < ... < t_N$, $W(t_j) - W(t_{j-1})$ $(1 \leq j \leq N)$ are independent. For a certain natural number $N \geq 1$ and $j \in \left\{0, 1, 2, ..., N\right\}$, we define $\Delta t = T/N$ en $t_j = j \cdot \Delta t$. Further, let $W_j = \tilde{W(t_j)}$, the numerical approximation of $W(t_j)$. Now let $Z_j \sim \mathcal{N}(0, 1)$ independent vaiables for $j \in \left\{1, 2, ..., N\right\}$ and let $W_0 = 0$ and $W_j = W_{j-1} + \sqrt{\Delta t} \cdot Z_j$ for $j \in \left\{1, 2, ..., N\right\}$. We call $W_j$ $(j = 0, 1, 2, ..., N)$ a discretized Brownian motion. A discretized Brownian motion is considered a special case of the standard Brownian motion. It is clear that properties (1) (by definition of the discretized Brownian motion) and (3) hold since $W_j$ can be written as $\sqrt{\Delta t} \cdot \sum_{n = 1}^{j} Z_n$ and all $Z_n$'s are independent. However, it is not clear to me that $W_t - W_s$ is normally distributed with mean 0 and variance $t-s$. Since $W_t - W_s = \sqrt{\Delta t} \cdot \sum_{n = s + 1}^{t} Z_n$, shouldn't $W_t - W_s$ be normally distributed with mean 0 and variance $(t - s) \cdot \Delta t$?","These are the definitions I'm working with: A (standard) Brownian motion in $\mathbb{R}$ is a stochastic process $W(t)$ $(t \geq 0)$ such that the following properties hold: $W(0) = 0$ almost certain $W(t) - W(s) \sim\mathcal{N}(0, t - s)$ (for 0 $\leq s \leq t$) For every $0 = t_0 < t_1 < ... < t_N$, $W(t_j) - W(t_{j-1})$ $(1 \leq j \leq N)$ are independent. For a certain natural number $N \geq 1$ and $j \in \left\{0, 1, 2, ..., N\right\}$, we define $\Delta t = T/N$ en $t_j = j \cdot \Delta t$. Further, let $W_j = \tilde{W(t_j)}$, the numerical approximation of $W(t_j)$. Now let $Z_j \sim \mathcal{N}(0, 1)$ independent vaiables for $j \in \left\{1, 2, ..., N\right\}$ and let $W_0 = 0$ and $W_j = W_{j-1} + \sqrt{\Delta t} \cdot Z_j$ for $j \in \left\{1, 2, ..., N\right\}$. We call $W_j$ $(j = 0, 1, 2, ..., N)$ a discretized Brownian motion. A discretized Brownian motion is considered a special case of the standard Brownian motion. It is clear that properties (1) (by definition of the discretized Brownian motion) and (3) hold since $W_j$ can be written as $\sqrt{\Delta t} \cdot \sum_{n = 1}^{j} Z_n$ and all $Z_n$'s are independent. However, it is not clear to me that $W_t - W_s$ is normally distributed with mean 0 and variance $t-s$. Since $W_t - W_s = \sqrt{\Delta t} \cdot \sum_{n = s + 1}^{t} Z_n$, shouldn't $W_t - W_s$ be normally distributed with mean 0 and variance $(t - s) \cdot \Delta t$?",,"['statistics', 'stochastic-processes', 'stochastic-calculus', 'monte-carlo']"
69,Likelihood function for a distribution with both discrete and continuous components,Likelihood function for a distribution with both discrete and continuous components,,"Suppose $X_1, X_2, \ldots, X_n$ are $IID$ normal RVs with mean $\mu$ and variance $1$. However, we observe only $Y_i$'s where $Y_i = \max (0, X_i)$. I would like to know how to write likelihood function for $\mu$ given $Y_i$'s. Since, $Y_i$ has both discrete and continuous components, I tried to write it in the following way $$L(\mu \mid Y_1,Y_2,\ldots, Y_n) = \frac{1}{(2\pi)^\frac{m}{2}}\exp\left(-\frac{1}{2}\sum_1^m (Y_i-\mu)^2 \right) \left(\Phi(-\mu)\right)^{n-m}$$ where $Y_1, Y_2, \ldots, Y_m > 0$ and $Y_{m+1}=Y_{m+2}=\cdots=Y_n=0$ and $\Phi$ is CDF of standard normal. I am not sure if this is correct way of writing it. I would be thankful if anyone can direct me to any references on how to write likelihood functions when the distribution of data has both discrete and continuous components.","Suppose $X_1, X_2, \ldots, X_n$ are $IID$ normal RVs with mean $\mu$ and variance $1$. However, we observe only $Y_i$'s where $Y_i = \max (0, X_i)$. I would like to know how to write likelihood function for $\mu$ given $Y_i$'s. Since, $Y_i$ has both discrete and continuous components, I tried to write it in the following way $$L(\mu \mid Y_1,Y_2,\ldots, Y_n) = \frac{1}{(2\pi)^\frac{m}{2}}\exp\left(-\frac{1}{2}\sum_1^m (Y_i-\mu)^2 \right) \left(\Phi(-\mu)\right)^{n-m}$$ where $Y_1, Y_2, \ldots, Y_m > 0$ and $Y_{m+1}=Y_{m+2}=\cdots=Y_n=0$ and $\Phi$ is CDF of standard normal. I am not sure if this is correct way of writing it. I would be thankful if anyone can direct me to any references on how to write likelihood functions when the distribution of data has both discrete and continuous components.",,"['statistics', 'statistical-inference', 'maximum-likelihood']"
70,Find the moment generating function of $Y$ [duplicate],Find the moment generating function of  [duplicate],Y,"This question already has an answer here : Mgf of double exponential RV (1 answer) Closed 4 years ago . Let $Y$ denote a random variable with probability density function given by $$f(y) = \frac{1}{2}e^{-|{y}|}, \quad -\infty < y < \infty$$ Find the moment generating function of $Y$. \begin{align}M_y(t) = E(e^{ty})&=\frac{1}{2}\int^\infty_{0}e^{-y}e^{ty}dy +\frac12 \int^0_{-\infty}e^{y}e^{ty}dy\\&=\frac{1}{2}\int^\infty_{0}e^{y(t-1)}dy + \frac12\int^0_{-\infty}e^{y(t+1)}dy \\&=\frac{1}{2}\left(\frac{e^{\infty(t-1)}}{t-1}-\frac{1}{t-1}+\frac{1}{t+1}-\frac{e^{-\infty(t+1)}}{t+1}\right)\end{align} I am currently stuck here. The results will differ according to the value of $t$. I've heard from another source that we  can assume $t<1$. Is the claim valid? Am I missing another step?","This question already has an answer here : Mgf of double exponential RV (1 answer) Closed 4 years ago . Let $Y$ denote a random variable with probability density function given by $$f(y) = \frac{1}{2}e^{-|{y}|}, \quad -\infty < y < \infty$$ Find the moment generating function of $Y$. \begin{align}M_y(t) = E(e^{ty})&=\frac{1}{2}\int^\infty_{0}e^{-y}e^{ty}dy +\frac12 \int^0_{-\infty}e^{y}e^{ty}dy\\&=\frac{1}{2}\int^\infty_{0}e^{y(t-1)}dy + \frac12\int^0_{-\infty}e^{y(t+1)}dy \\&=\frac{1}{2}\left(\frac{e^{\infty(t-1)}}{t-1}-\frac{1}{t-1}+\frac{1}{t+1}-\frac{e^{-\infty(t+1)}}{t+1}\right)\end{align} I am currently stuck here. The results will differ according to the value of $t$. I've heard from another source that we  can assume $t<1$. Is the claim valid? Am I missing another step?",,"['integration', 'statistics', 'probability-distributions', 'moment-generating-functions']"
71,What does ${50}\choose{4}$ mean in statistics?,What does  mean in statistics?,{50}\choose{4},I have a test tomorrow in statistics and was wondering what the following means? $$\binom{50}{4}$$ My professor along with most of my classmates have a calculator they can just plug that into. The professor never went into depth on what it means and how to figure it out with a normal ti-30. Thanks for your time.,I have a test tomorrow in statistics and was wondering what the following means? $$\binom{50}{4}$$ My professor along with most of my classmates have a calculator they can just plug that into. The professor never went into depth on what it means and how to figure it out with a normal ti-30. Thanks for your time.,,"['elementary-number-theory', 'statistics', 'binomial-coefficients', 'combinations', 'factorial']"
72,Difference between fractions at group level have different sign than difference between fractions in aggregate,Difference between fractions at group level have different sign than difference between fractions in aggregate,,"I have obtained a result (perhaps incorrectly; we shall find out) that appears paradoxical. Suppose I am interested in comparing fractions between 'groups' (not in the strict mathematical sense) $\alpha$ and $\beta$.  Within these groups, there are two subgroups (which are present in both $\alpha$ and $\beta$), denoted $y$ and $z$. Without loss of generality and for sake of argument, suppose that we're interested in United States baseball batting averages , $AVG$, and have data on hits $H$ and at-bats $AB$. Specifically, $(H_{\alpha,y}, AB_{\alpha,y}) = (34836, 268206) \Rightarrow AVG_{\alpha,y} = \frac{34836}{268206} = 0.129885237 \ldots$ $(H_{\alpha,z}, AB_{\alpha,z}) = (81311, 366970) \Rightarrow AVG_{\alpha,z} = \frac{81311}{366970} = 0.221573970 \ldots$ $(H_{\beta,y}, AB_{\beta,y}) = (33463, 253042) \Rightarrow AVG_{\beta,y} = \frac{33463}{253042} = 0.132242868 \ldots$ $(H_{\beta,z}, AB_{\beta,z}) = (69498, 312624) \Rightarrow AVG_{\beta,z} = \frac{69498}{312624} = 0.222305389 \ldots$ Note the differences in $AVG$ between groups with the same subgroup, $d_{y} = AVG_{\alpha,y} - AVG_{\beta,y} = -0.0024 \ldots$ $d_{z} = AVG_{\alpha,z} - AVG_{\beta,z} = -0.0007 \ldots$ However, the difference in $AVG$ between groups, without regard for subgroup has a sign that is not intuitive for me, $d_{y+z} = AVG_{\alpha, y+z} - AVG_{\beta, y+z} = \frac{(H_{\alpha,y} + H_{\alpha,z})}{(AB_{\alpha,y} + AB_{\alpha,z})} - \frac{(H_{\beta,y} + H_{\beta,z})}{(AB_{\beta,y} + AB_{\beta,z})} =  +0.0008 \ldots$ My expectation is that $d_{y+z} \in [\min{(d_y, d_z)}, \max{(d_y, d_z)}]$ Why is the difference in $AVG$ between groups not bounded by the subgroup-level differences?","I have obtained a result (perhaps incorrectly; we shall find out) that appears paradoxical. Suppose I am interested in comparing fractions between 'groups' (not in the strict mathematical sense) $\alpha$ and $\beta$.  Within these groups, there are two subgroups (which are present in both $\alpha$ and $\beta$), denoted $y$ and $z$. Without loss of generality and for sake of argument, suppose that we're interested in United States baseball batting averages , $AVG$, and have data on hits $H$ and at-bats $AB$. Specifically, $(H_{\alpha,y}, AB_{\alpha,y}) = (34836, 268206) \Rightarrow AVG_{\alpha,y} = \frac{34836}{268206} = 0.129885237 \ldots$ $(H_{\alpha,z}, AB_{\alpha,z}) = (81311, 366970) \Rightarrow AVG_{\alpha,z} = \frac{81311}{366970} = 0.221573970 \ldots$ $(H_{\beta,y}, AB_{\beta,y}) = (33463, 253042) \Rightarrow AVG_{\beta,y} = \frac{33463}{253042} = 0.132242868 \ldots$ $(H_{\beta,z}, AB_{\beta,z}) = (69498, 312624) \Rightarrow AVG_{\beta,z} = \frac{69498}{312624} = 0.222305389 \ldots$ Note the differences in $AVG$ between groups with the same subgroup, $d_{y} = AVG_{\alpha,y} - AVG_{\beta,y} = -0.0024 \ldots$ $d_{z} = AVG_{\alpha,z} - AVG_{\beta,z} = -0.0007 \ldots$ However, the difference in $AVG$ between groups, without regard for subgroup has a sign that is not intuitive for me, $d_{y+z} = AVG_{\alpha, y+z} - AVG_{\beta, y+z} = \frac{(H_{\alpha,y} + H_{\alpha,z})}{(AB_{\alpha,y} + AB_{\alpha,z})} - \frac{(H_{\beta,y} + H_{\beta,z})}{(AB_{\beta,y} + AB_{\beta,z})} =  +0.0008 \ldots$ My expectation is that $d_{y+z} \in [\min{(d_y, d_z)}, \max{(d_y, d_z)}]$ Why is the difference in $AVG$ between groups not bounded by the subgroup-level differences?",,"['statistics', 'fractions', 'paradoxes']"
73,Joint density of first k order statistics,Joint density of first k order statistics,,"I need to compute the joint density of the first $k$($<n$) order statistics I was trying to do it by getting the marginal density function: $$\int \cdots \int f(x_1)\cdots f(x_n)n!dx_{k+1}\cdots dx_{n}$$ but I dont know my interval of integration; is it $(-\infty,\infty)$ for each integral? I would really appreciate if you can help me with this problem","I need to compute the joint density of the first $k$($<n$) order statistics I was trying to do it by getting the marginal density function: $$\int \cdots \int f(x_1)\cdots f(x_n)n!dx_{k+1}\cdots dx_{n}$$ but I dont know my interval of integration; is it $(-\infty,\infty)$ for each integral? I would really appreciate if you can help me with this problem",,"['probability', 'statistics', 'probability-distributions', 'order-statistics']"
74,Notation for probability distribution (capital P) and density function (lowercase p),Notation for probability distribution (capital P) and density function (lowercase p),,"I'm confused by the differences in the notation used to denote probability distribution and the density function. My understanding is that the probability distribution is usually denoted by the capital letter $P$, while the density function is denoted by lowercase $p$. From a text I'm reading, an application of Bayes's rule is as follows: $$p(\alpha,\beta\mid C)\propto P(C\mid \alpha,\beta)p(\alpha)p(\beta)$$ In this case, why is $P(C\mid\alpha,\beta)$ in capital $P$? Shouldn't it all be lowercase $p$ throughout the right-hand side since the term on the left-hand side is a density function?","I'm confused by the differences in the notation used to denote probability distribution and the density function. My understanding is that the probability distribution is usually denoted by the capital letter $P$, while the density function is denoted by lowercase $p$. From a text I'm reading, an application of Bayes's rule is as follows: $$p(\alpha,\beta\mid C)\propto P(C\mid \alpha,\beta)p(\alpha)p(\beta)$$ In this case, why is $P(C\mid\alpha,\beta)$ in capital $P$? Shouldn't it all be lowercase $p$ throughout the right-hand side since the term on the left-hand side is a density function?",,"['probability', 'statistics', 'notation', 'bayesian']"
75,Calculating the sample standard deviation,Calculating the sample standard deviation,,"I've been preparing for an exam tomorrow and was doing a past paper when it appears the mark scheme has an answer that I just cannot fathom. The exact question is to ""find a 95% confidence interval for the true mean time for the task"" . The only data I've been given are $n=80$, $Σx=555.20$, and $Σx^2=3863.9031$ I know I can calculate the sample mean using $\bar{x} = Σ\frac{x}{n}$, which gives me $6.94$. From my understanding, the sample mean is calculated by doing $\frac{Σx^2-(\bar{x})^2}{n-1}$, but this has given me a value of $6.94985611$ which is different from the answer given, stated as $s = 0.37$ (and $s^2 = 0.1369$). So, how do I arrive at an answer of $0.37$? (Paper reference: June 2013 MEI Statistics 3 Question 1 ii )","I've been preparing for an exam tomorrow and was doing a past paper when it appears the mark scheme has an answer that I just cannot fathom. The exact question is to ""find a 95% confidence interval for the true mean time for the task"" . The only data I've been given are $n=80$, $Σx=555.20$, and $Σx^2=3863.9031$ I know I can calculate the sample mean using $\bar{x} = Σ\frac{x}{n}$, which gives me $6.94$. From my understanding, the sample mean is calculated by doing $\frac{Σx^2-(\bar{x})^2}{n-1}$, but this has given me a value of $6.94985611$ which is different from the answer given, stated as $s = 0.37$ (and $s^2 = 0.1369$). So, how do I arrive at an answer of $0.37$? (Paper reference: June 2013 MEI Statistics 3 Question 1 ii )",,"['probability', 'statistics', 'standard-deviation']"
76,Finding a p-value based on the Poisson distribution,Finding a p-value based on the Poisson distribution,,"I'm having trouble understanding what I need to do to solve this problem for homework: Suppose a company which produces fire alarms has claimed that the fire alarms make only one false alarm per year, on average. Let $X$ denote the number of false alarms per year. Assume $X \sim Poisson(\lambda)$. Under the company's claim, the probability of observing $x$ fire alarms per year is $P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!} = \frac{e^{-1}}{x!}, x = 0,1,...$ A customer had a bad experience with the fire alarm he purchased before. He wants to conduct hypothesis testing $H_0: \lambda = 1$ versus $H_1: \lambda > 1$, and he purchased another fire alarm from the same company. He allows 1% chance for falsely rejecting $H_0$. After a year, he observed three false alarms. a. Find the p-value based on the single observation of three false alarms for the year. b. Draw a conclusion based on the p-value in part a. For part a, I'm very unsure how to do this. In class, we've only done hypothesis testing and p-values on normal distributions so I'm not sure if I can follow the same method where I use a test statistic, and find a value based on that value? I'm just very confused on what to do.","I'm having trouble understanding what I need to do to solve this problem for homework: Suppose a company which produces fire alarms has claimed that the fire alarms make only one false alarm per year, on average. Let $X$ denote the number of false alarms per year. Assume $X \sim Poisson(\lambda)$. Under the company's claim, the probability of observing $x$ fire alarms per year is $P(X = x) = \frac{e^{-\lambda}\lambda^x}{x!} = \frac{e^{-1}}{x!}, x = 0,1,...$ A customer had a bad experience with the fire alarm he purchased before. He wants to conduct hypothesis testing $H_0: \lambda = 1$ versus $H_1: \lambda > 1$, and he purchased another fire alarm from the same company. He allows 1% chance for falsely rejecting $H_0$. After a year, he observed three false alarms. a. Find the p-value based on the single observation of three false alarms for the year. b. Draw a conclusion based on the p-value in part a. For part a, I'm very unsure how to do this. In class, we've only done hypothesis testing and p-values on normal distributions so I'm not sure if I can follow the same method where I use a test statistic, and find a value based on that value? I'm just very confused on what to do.",,"['probability', 'statistics', 'poisson-distribution']"
77,How to prove that the maximum likelihood estimator of $\theta$ is asymptotically unbiased and consistent,How to prove that the maximum likelihood estimator of  is asymptotically unbiased and consistent,\theta,"In a class we looked at this example: Let $X_1,...,X_n\sim U(0,\theta)$. Then the maximum likelihood function is $\mathcal{L}(\theta) = \begin{cases} \dfrac{1}{\theta^{n}} & \text{if } \text{max}\{X_1,\dotsc,X_n\}\leq\theta \\ 0 & \text{otherwise} \end{cases}$ Only the fact that the maximum likelihood estimator $\hat{\theta}=\text{max}\{X_1,\dotsc,X_n\}$ is asymptotically unbiased and consistent was mentioned but I'm curious about why this is true. Could anyone help me to see how to prove this? Thanks.","In a class we looked at this example: Let $X_1,...,X_n\sim U(0,\theta)$. Then the maximum likelihood function is $\mathcal{L}(\theta) = \begin{cases} \dfrac{1}{\theta^{n}} & \text{if } \text{max}\{X_1,\dotsc,X_n\}\leq\theta \\ 0 & \text{otherwise} \end{cases}$ Only the fact that the maximum likelihood estimator $\hat{\theta}=\text{max}\{X_1,\dotsc,X_n\}$ is asymptotically unbiased and consistent was mentioned but I'm curious about why this is true. Could anyone help me to see how to prove this? Thanks.",,"['statistics', 'parameter-estimation']"
78,Logic behind the combo of cards in a hand that contain only clubs,Logic behind the combo of cards in a hand that contain only clubs,,"In looking at a stats problem where you want all combos of a 5-card hand that contain at least one club, the approach I have is to find the combos of 5-card hands that do not contain clubs, and then subtract it from the total number of 5-card hand combos, so this would be the following: $$\left(\begin{array}{c} 52 \\ 5 \end{array}\right) - \left(\begin{array}{c} 39 \\ 5 \end{array}\right)$$ I am pretty sure the above approach is correct. What I'm curious about is why the logic does not flow to the multiplication rule? Is it not that if we know all 5-card combinations of Hearts, Diamonds, and Spades, then we can multiply these together to get all possible 5-card combinations of these suits? By that logic, the following should be the same as the above, but its not. $$\left(\begin{array}{c} 52 \\ 5 \end{array}\right)-\left(\begin{array}{c} 13 \\ 5 \end{array}\right)\cdot \left(\begin{array}{c} 13 \\ 5 \end{array}\right)\cdot \left(\begin{array}{c} 13 \\ 5 \end{array}\right)$$ Perhaps I'm not seeing something obvious. Can anyone shed any light?","In looking at a stats problem where you want all combos of a 5-card hand that contain at least one club, the approach I have is to find the combos of 5-card hands that do not contain clubs, and then subtract it from the total number of 5-card hand combos, so this would be the following: $$\left(\begin{array}{c} 52 \\ 5 \end{array}\right) - \left(\begin{array}{c} 39 \\ 5 \end{array}\right)$$ I am pretty sure the above approach is correct. What I'm curious about is why the logic does not flow to the multiplication rule? Is it not that if we know all 5-card combinations of Hearts, Diamonds, and Spades, then we can multiply these together to get all possible 5-card combinations of these suits? By that logic, the following should be the same as the above, but its not. $$\left(\begin{array}{c} 52 \\ 5 \end{array}\right)-\left(\begin{array}{c} 13 \\ 5 \end{array}\right)\cdot \left(\begin{array}{c} 13 \\ 5 \end{array}\right)\cdot \left(\begin{array}{c} 13 \\ 5 \end{array}\right)$$ Perhaps I'm not seeing something obvious. Can anyone shed any light?",,"['probability', 'statistics', 'combinations']"
79,How to find the variance of this p.d.f?,How to find the variance of this p.d.f?,,"X is distributed so that: $$X=\begin{cases} \frac{ x-80}{400}&  80\le x \le 100\\ \frac{120-x}{400} &  100\le x\le 120\\  0 &\text{otherwise} \end{cases} $$ $Var(X)= E((X)^2)-(E(X))^2$ and $E(X)=100$ by symmetry, so what has me confused is how to go about finding $E((X)^2)$ because of the 'split' in the p.d.f. Thanks!","X is distributed so that: $$X=\begin{cases} \frac{ x-80}{400}&  80\le x \le 100\\ \frac{120-x}{400} &  100\le x\le 120\\  0 &\text{otherwise} \end{cases} $$ $Var(X)= E((X)^2)-(E(X))^2$ and $E(X)=100$ by symmetry, so what has me confused is how to go about finding $E((X)^2)$ because of the 'split' in the p.d.f. Thanks!",,"['statistics', 'expectation']"
80,"Difference among the same distribution , identical distribution and similar distribution.","Difference among the same distribution , identical distribution and similar distribution.",,"$X\sim N(\mu_1,\sigma)$ and $Y\sim N(\mu_2,\sigma)$ are similar but not identical. $X\sim N(\mu,\sigma)$ and $Y\sim N(\mu,\sigma)$ are  identical. But what is same distribution? Do same and identical exactly have the same meaning?","$X\sim N(\mu_1,\sigma)$ and $Y\sim N(\mu_2,\sigma)$ are similar but not identical. $X\sim N(\mu,\sigma)$ and $Y\sim N(\mu,\sigma)$ are  identical. But what is same distribution? Do same and identical exactly have the same meaning?",,"['statistics', 'self-learning', 'statistical-inference']"
81,Which voting method is the most fair? [closed],Which voting method is the most fair? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I have heard of Plurality Borda Count Instant Runoff Sequential Pairwise voting methods, where it mathematically can be proved which is the most fair and in which situations. From my understanding Sequential Pairwise does not seam fair at all, as the order in which you compare have a influence on the outcome. With Instant Runoff I would assume is not suited when there are few voting options and most of them have few votes. Question Does anyone know which is the most fair and when each of the methods should be used?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I have heard of Plurality Borda Count Instant Runoff Sequential Pairwise voting methods, where it mathematically can be proved which is the most fair and in which situations. From my understanding Sequential Pairwise does not seam fair at all, as the order in which you compare have a influence on the outcome. With Instant Runoff I would assume is not suited when there are few voting options and most of them have few votes. Question Does anyone know which is the most fair and when each of the methods should be used?",,"['statistics', 'voting-theory']"
82,Definition of Percentile (undefined notation)?,Definition of Percentile (undefined notation)?,,"From Loss Models , 4th ed., by Klugman et al.: Definition 3.6 The $100p^{\text{th}}$ percentile of a random variable is any value $\pi_p$ such that $F\left(\pi_{p^{-}}\right) \leq p \leq F\left(\pi_{p}\right)$. I have no idea what $\pi_{p^{-}}$ is, and cannot find it defined earlier in the text. Does anyone know what this notation is? Note : I would prefer a rigorous definition, if available.","From Loss Models , 4th ed., by Klugman et al.: Definition 3.6 The $100p^{\text{th}}$ percentile of a random variable is any value $\pi_p$ such that $F\left(\pi_{p^{-}}\right) \leq p \leq F\left(\pi_{p}\right)$. I have no idea what $\pi_{p^{-}}$ is, and cannot find it defined earlier in the text. Does anyone know what this notation is? Note : I would prefer a rigorous definition, if available.",,"['probability', 'statistics', 'actuarial-science']"
83,Calculating a Fisher expected information,Calculating a Fisher expected information,,"Let $X_1,..., X_n$ be a random sample from a distribution with probability density function $f(x;\theta) = (1/2\theta) exp(-|x|/\theta)$ for $-\infty<x<\infty$. (a) Find the maximum likelihood estimator of $\theta$ and calculate the Fisher (expected) information in the sample. I've calculated the MLE to be $\sum |X_i|/n$ and I know the definition of Fisher expectation, but I'm getting really stuck with calculating it. I think the $|X_i|$ terms are throwing me off. Any help in doing this problem would be much appreciated! Thanks","Let $X_1,..., X_n$ be a random sample from a distribution with probability density function $f(x;\theta) = (1/2\theta) exp(-|x|/\theta)$ for $-\infty<x<\infty$. (a) Find the maximum likelihood estimator of $\theta$ and calculate the Fisher (expected) information in the sample. I've calculated the MLE to be $\sum |X_i|/n$ and I know the definition of Fisher expectation, but I'm getting really stuck with calculating it. I think the $|X_i|$ terms are throwing me off. Any help in doing this problem would be much appreciated! Thanks",,['statistics']
84,What is the probability that $x_1+x_2+...+x_n \le n$?,What is the probability that ?,x_1+x_2+...+x_n \le n,"Given that $X_1, X_2...$ are mutually independent random variables. For each $i$ with $1\le i \le n$ the variable $X_i$ is equal to either $0$ or $n+1$ $E(X_i)$ = $1$ also.. if $X_i$ is equal to either $0$ or $n+1$, doesn't that mean that all $X_i$ need to be $0$? Thanks","Given that $X_1, X_2...$ are mutually independent random variables. For each $i$ with $1\le i \le n$ the variable $X_i$ is equal to either $0$ or $n+1$ $E(X_i)$ = $1$ also.. if $X_i$ is equal to either $0$ or $n+1$, doesn't that mean that all $X_i$ need to be $0$? Thanks",,"['probability', 'combinatorics', 'statistics', 'discrete-mathematics']"
85,The Probability of Catching Criminals,The Probability of Catching Criminals,,"I have been struggling with the following question and would greatly appreciate any help  :) Suppose we have information about the supermarket purchases of 100 million people. Each person goes to the supermarket 100 times in a year and buys 10 of the 1000 items that the supermarket sells. We believe that a pair of criminals will buy exactly the same set of 10 items at some time during the year. If we search for pairs of people who have bought the same set of items, would we expect that any such people found were truly criminals? Assume our hypothesis to be that a pair of criminals will surely buy a set of 10 items in common at some time during the year. This is meant to be an illustration of Bonferroni's principle. Suppose there are no criminals and that everyone behaves at random. Would we find any pairs of people who appear to be criminals? We must initially find the expected number of pairs who buy the same 10 items per year. I'm not sure whether I do this correctly... Here is how I've been going about solving it: Number of possible pairs of people: $\binom{10^6}{2} = \frac{10^{12}}{2} = 5 \times 10^{11}$, using the fact that $\binom{n}{2} \approx \frac{n^2}{2}$, when $n$ is large. Number of possible 10-item selections: $\binom{10^3}{10} \approx 2.6 \times 10^{23}$ Probability of a customer buying 10 particular items at a point in time: $\frac{1}{2.6 \times 10^{23}}$ Probability of a customer buying 10 particular items at least once over the course of 100 periods in time: $\frac{100}{2.6 \times 10^{23}}$ Probability of a pair buying exactly the same 10 items (both at least once) over the course of 100 periods in time: $(\frac{100}{2.6 \times 10^{23}})^2 = (\frac{1}{2.6 \times 10^{21}})^2 = \frac{1}{6.76 \times 10^{42}}$ The expected number of pairs who buy the same 10 items per year is thus: $ 5 \times 10^{11} \times \frac{1}{6.76 \times 10^{42}} = \frac{5}{6.75 \times 10^{31}}$ Because the above number is so low if we do find a pair buying the same 10 items then, under our hypothesis, they are likely to be criminals and not a false positive case. I am just wondering whether my solution to the above is correct?","I have been struggling with the following question and would greatly appreciate any help  :) Suppose we have information about the supermarket purchases of 100 million people. Each person goes to the supermarket 100 times in a year and buys 10 of the 1000 items that the supermarket sells. We believe that a pair of criminals will buy exactly the same set of 10 items at some time during the year. If we search for pairs of people who have bought the same set of items, would we expect that any such people found were truly criminals? Assume our hypothesis to be that a pair of criminals will surely buy a set of 10 items in common at some time during the year. This is meant to be an illustration of Bonferroni's principle. Suppose there are no criminals and that everyone behaves at random. Would we find any pairs of people who appear to be criminals? We must initially find the expected number of pairs who buy the same 10 items per year. I'm not sure whether I do this correctly... Here is how I've been going about solving it: Number of possible pairs of people: $\binom{10^6}{2} = \frac{10^{12}}{2} = 5 \times 10^{11}$, using the fact that $\binom{n}{2} \approx \frac{n^2}{2}$, when $n$ is large. Number of possible 10-item selections: $\binom{10^3}{10} \approx 2.6 \times 10^{23}$ Probability of a customer buying 10 particular items at a point in time: $\frac{1}{2.6 \times 10^{23}}$ Probability of a customer buying 10 particular items at least once over the course of 100 periods in time: $\frac{100}{2.6 \times 10^{23}}$ Probability of a pair buying exactly the same 10 items (both at least once) over the course of 100 periods in time: $(\frac{100}{2.6 \times 10^{23}})^2 = (\frac{1}{2.6 \times 10^{21}})^2 = \frac{1}{6.76 \times 10^{42}}$ The expected number of pairs who buy the same 10 items per year is thus: $ 5 \times 10^{11} \times \frac{1}{6.76 \times 10^{42}} = \frac{5}{6.75 \times 10^{31}}$ Because the above number is so low if we do find a pair buying the same 10 items then, under our hypothesis, they are likely to be criminals and not a false positive case. I am just wondering whether my solution to the above is correct?",,"['probability', 'statistics']"
86,Average number of tosses to reach a head with a biased coin,Average number of tosses to reach a head with a biased coin,,"Given a biased coin with probability P of flipping to head position, how can I compute N , the average number of tosses for reaching a head? I also need a formula for the reverse problem, computing P as a function of N (if I know the average number of tosses, how can I find the bias). Edit: This can apparently be rephrased as computing the average number of Bernoulli trials with probability P to get a success. The result is N = 1/p according to this article .","Given a biased coin with probability P of flipping to head position, how can I compute N , the average number of tosses for reaching a head? I also need a formula for the reverse problem, computing P as a function of N (if I know the average number of tosses, how can I find the bias). Edit: This can apparently be rephrased as computing the average number of Bernoulli trials with probability P to get a success. The result is N = 1/p according to this article .",,"['probability', 'statistics']"
87,Non-technical question about maximum likelihood estimation / intuition,Non-technical question about maximum likelihood estimation / intuition,,"Just a quick question on MLE, sorry if its too basic but I would love help on this issue! If we want to calculate the probability $P$ of the number of males in the United States and we knew the distribution $pmf$/$pdf$, why can't we just take the arithmetic mean and use $\bar{y}$. Why go through the trouble of using the MLE? For example, if we suppose that we are looking at a Bernoulli R.V. where $X_1=1$ is male and $X_2=0$ is a female and we want to estimate the parameter, which is $p$ in the case of Bernoulli, why would we go to great lengths to find the MLE when we could just see the $mean$ from our sample? I'm very confused on why MLE is useful in that way especially when we have the data. Thanks so much!","Just a quick question on MLE, sorry if its too basic but I would love help on this issue! If we want to calculate the probability $P$ of the number of males in the United States and we knew the distribution $pmf$/$pdf$, why can't we just take the arithmetic mean and use $\bar{y}$. Why go through the trouble of using the MLE? For example, if we suppose that we are looking at a Bernoulli R.V. where $X_1=1$ is male and $X_2=0$ is a female and we want to estimate the parameter, which is $p$ in the case of Bernoulli, why would we go to great lengths to find the MLE when we could just see the $mean$ from our sample? I'm very confused on why MLE is useful in that way especially when we have the data. Thanks so much!",,['statistics']
88,Finding a function which can describe a probability density function,Finding a function which can describe a probability density function,,"Let the function  $$ f(x) = \begin{cases} ax^2 & \text{for } x\in [ 0, 1], \\0 & \text{for } x\notin [0,1].\end{cases} $$ Find $a$, such that the function can describe a probability density function. (later I'm also to find CDF, standard deviation and such but I think that's the least problematic thing here) So first of all - it's not a homework, I'm trying to prepare for a test where it's said to appear but I was absent on the class so my only hopes are the notes I was able to obtain which are quite illegible for me. Thus, it's more important for me to be able to solve such class of problems rather than exactly this one and nothing else. So the notes I have seem to suggest I should take the integral from $-1$ to $1$ of the said function - but is that really all I need to say a function can describe a probability density function?","Let the function  $$ f(x) = \begin{cases} ax^2 & \text{for } x\in [ 0, 1], \\0 & \text{for } x\notin [0,1].\end{cases} $$ Find $a$, such that the function can describe a probability density function. (later I'm also to find CDF, standard deviation and such but I think that's the least problematic thing here) So first of all - it's not a homework, I'm trying to prepare for a test where it's said to appear but I was absent on the class so my only hopes are the notes I was able to obtain which are quite illegible for me. Thus, it's more important for me to be able to solve such class of problems rather than exactly this one and nothing else. So the notes I have seem to suggest I should take the integral from $-1$ to $1$ of the said function - but is that really all I need to say a function can describe a probability density function?",,"['probability', 'statistics']"
89,Expected value of number of cards drawn from a deck to get 5 spades.,Expected value of number of cards drawn from a deck to get 5 spades.,,The question: What is the expected number of cards required to be drawn in order to draw 5 spades. What I have: Let $X=X_1+\cdots+X_{43}$ (43 because we're examining the case when 4 spades have been drawn and we're waiting for the 5th) with $X_i=1$ iff card $i$ is drawn before the fifth spade.  Then $X=$ the number of cards drawn before the 5th spade.  Let $Y=X+1$.  Then $Y=$ the number of cards drawn before and including the 5th spade. $P\left\{X_i=1\right\}=$ the probability that card $i$ is drawn before the 5th spade $=\frac{9!}{10!}=\frac{1}{10}$ (because there are $9!$ ways of ordering the $i$th card at the front of 9 spades and $10$ ways of ordering 10 cards). Then $E\left[Y\right]=\frac{43}{10}+1=5.3$.  But this is far too small.  What went wrong? Thanks.,The question: What is the expected number of cards required to be drawn in order to draw 5 spades. What I have: Let $X=X_1+\cdots+X_{43}$ (43 because we're examining the case when 4 spades have been drawn and we're waiting for the 5th) with $X_i=1$ iff card $i$ is drawn before the fifth spade.  Then $X=$ the number of cards drawn before the 5th spade.  Let $Y=X+1$.  Then $Y=$ the number of cards drawn before and including the 5th spade. $P\left\{X_i=1\right\}=$ the probability that card $i$ is drawn before the 5th spade $=\frac{9!}{10!}=\frac{1}{10}$ (because there are $9!$ ways of ordering the $i$th card at the front of 9 spades and $10$ ways of ordering 10 cards). Then $E\left[Y\right]=\frac{43}{10}+1=5.3$.  But this is far too small.  What went wrong? Thanks.,,"['probability', 'statistics', 'random-variables', 'expectation']"
90,How is a sample from a Bernoulli distribution different from a binomial distribution? [duplicate],How is a sample from a Bernoulli distribution different from a binomial distribution? [duplicate],,"This question already has answers here : What is the difference and relationship between the binomial and Bernoulli distributions? (4 answers) Closed 7 years ago . The binomial distribution can be interpreted as $n$ independent and identically Bernoulli ""trials"". If $X_1, X_2, \dots, X_n$ is a sample from a Bernoulli distribution, how is that different from a binomial distribution?","This question already has answers here : What is the difference and relationship between the binomial and Bernoulli distributions? (4 answers) Closed 7 years ago . The binomial distribution can be interpreted as $n$ independent and identically Bernoulli ""trials"". If $X_1, X_2, \dots, X_n$ is a sample from a Bernoulli distribution, how is that different from a binomial distribution?",,"['statistics', 'statistical-inference', 'binomial-distribution']"
91,What is the probability that the student knew the answer to at least one of the two questions?,What is the probability that the student knew the answer to at least one of the two questions?,,A student takes a true-false examination containing 20 questions. On looking at the examination the student and that he knows the answer to 10 of the questions which he proceeds to answer correctly. He then randomly answers the remaining 10 questions. The instructor selects 2 of the questions at random and  that the students answered both questions correctly. What is the probability that the student knew the answer to at least one of the two questions?,A student takes a true-false examination containing 20 questions. On looking at the examination the student and that he knows the answer to 10 of the questions which he proceeds to answer correctly. He then randomly answers the remaining 10 questions. The instructor selects 2 of the questions at random and  that the students answered both questions correctly. What is the probability that the student knew the answer to at least one of the two questions?,,"['probability', 'statistics']"
92,Poisson Distribution - Questions about $\lambda$ parameter,Poisson Distribution - Questions about  parameter,\lambda,"Suppose that, on average, a bushel of 100 apples contain three apples with a worm.  Select a bushel of 100 apples at random.  Let $Worm$ be the random variable that represents the number of apples with a worm.  Assume that the number of apples that contain a worm can be modeled by a binomial random variable with parameters n=100, and p=0.03.  Find $\Pr(Worm=k)$ for $k=0,1,2,3,4,8$.  Compare these with the Poisson model. For the binomial model, I know that the equation is as follows: $\Pr(X=k)=\binom{100}{k}(0.03)^k(0.97)^{100-k}$ I was having a little trouble developing the equation with the Poisson model, specifically the lambda parameter.  I understand that lambda is the rate of occurrence.   For example, we might know that there are 500 misprints in a 250 page manuscript, which translates into an average rate of $\lambda=500/250=2$ misprints per page. In this problem, I thought $\lambda=3/100$ giving the following equation: $\Pr(Worm=k)=e^{-(3/100)} \cfrac{(-3/100)^k}{k!}$ but apparently $\lambda = 3 $.  Can someone please explain why?  I thought lambda is a rate so it should be 3 rotten apples per a bushel of 100 apples, not (3/100)*100 = 3....","Suppose that, on average, a bushel of 100 apples contain three apples with a worm.  Select a bushel of 100 apples at random.  Let $Worm$ be the random variable that represents the number of apples with a worm.  Assume that the number of apples that contain a worm can be modeled by a binomial random variable with parameters n=100, and p=0.03.  Find $\Pr(Worm=k)$ for $k=0,1,2,3,4,8$.  Compare these with the Poisson model. For the binomial model, I know that the equation is as follows: $\Pr(X=k)=\binom{100}{k}(0.03)^k(0.97)^{100-k}$ I was having a little trouble developing the equation with the Poisson model, specifically the lambda parameter.  I understand that lambda is the rate of occurrence.   For example, we might know that there are 500 misprints in a 250 page manuscript, which translates into an average rate of $\lambda=500/250=2$ misprints per page. In this problem, I thought $\lambda=3/100$ giving the following equation: $\Pr(Worm=k)=e^{-(3/100)} \cfrac{(-3/100)^k}{k!}$ but apparently $\lambda = 3 $.  Can someone please explain why?  I thought lambda is a rate so it should be 3 rotten apples per a bushel of 100 apples, not (3/100)*100 = 3....",,"['probability', 'statistics']"
93,Describe a sine wave of known frequency with only two points,Describe a sine wave of known frequency with only two points,,"This is my first post on math.stackexchange (sorry if meta people remove the Hello (sometimes we do that over on stackoverflow ;P)! I have a system wherein I know that the output is a sine wave, with a known frequency.  My objective is to find the approximate (x,y) of the first peak (i.e., find the phase shift of the signal).  An important point is that I do not need to know y, or the amplitude, of this peak.  Essentially, I can poll the system at a given angular shift (represented by x), and receive a y value in return.  I start with zero points, and want to poll the minimum number of x points in order to be able to know where to poll to receive a max y value. I believe that I can describe the sine wave with only two points, yet I do not know how to calculate this (it's on a motion controller, so I have quite limited functionality).  My thoughts so far:  phase = -sin^-1(y) - wt + 2*pi*n, but I don't know how to easily fit this with two points. Once I know the fitted sine wave, I will be able to determine which x should yield a max amplitude peak y, and then subsequently poll the x location. If this can be done, the final solution would account for noise in the system (i.e. each y point polled will be within a given tolerance... thus, the two or more points polled to fit the sine wave would cause additive errors...), but I'll cross that bridge when I come to it. Thanks!  I think it's a pretty interesting problem :)  Let me know if you need any further clarification! -Kadaj","This is my first post on math.stackexchange (sorry if meta people remove the Hello (sometimes we do that over on stackoverflow ;P)! I have a system wherein I know that the output is a sine wave, with a known frequency.  My objective is to find the approximate (x,y) of the first peak (i.e., find the phase shift of the signal).  An important point is that I do not need to know y, or the amplitude, of this peak.  Essentially, I can poll the system at a given angular shift (represented by x), and receive a y value in return.  I start with zero points, and want to poll the minimum number of x points in order to be able to know where to poll to receive a max y value. I believe that I can describe the sine wave with only two points, yet I do not know how to calculate this (it's on a motion controller, so I have quite limited functionality).  My thoughts so far:  phase = -sin^-1(y) - wt + 2*pi*n, but I don't know how to easily fit this with two points. Once I know the fitted sine wave, I will be able to determine which x should yield a max amplitude peak y, and then subsequently poll the x location. If this can be done, the final solution would account for noise in the system (i.e. each y point polled will be within a given tolerance... thus, the two or more points polled to fit the sine wave would cause additive errors...), but I'll cross that bridge when I come to it. Thanks!  I think it's a pretty interesting problem :)  Let me know if you need any further clarification! -Kadaj",,"['calculus', 'statistics', 'physics']"
94,Show that $(1-\frac{1}{n})^{\sum_{i=1}^n X_i}$ is an unbiased estimator of $\tau(\theta)=e^{-\lambda}$,Show that  is an unbiased estimator of,(1-\frac{1}{n})^{\sum_{i=1}^n X_i} \tau(\theta)=e^{-\lambda},"Let $S=\sum_{i=1}^n X_i$ than show that $T(X_1,\ldots,X_n)= \left(1-\frac{1}{n}\right)^{\sum_{i=1}^n X_i}$ is an unbiased estimator of $\tau(\theta)=e^{-\lambda}$ where $X_1,\ldots,X_n$ are IID from POI($\lambda$) with $n>1$.","Let $S=\sum_{i=1}^n X_i$ than show that $T(X_1,\ldots,X_n)= \left(1-\frac{1}{n}\right)^{\sum_{i=1}^n X_i}$ is an unbiased estimator of $\tau(\theta)=e^{-\lambda}$ where $X_1,\ldots,X_n$ are IID from POI($\lambda$) with $n>1$.",,"['statistics', 'statistical-inference']"
95,Help with calculating the variance?,Help with calculating the variance?,,"I'm reading a statistics book and I don't understand the following deduction: Let $X$ be uniformly distributed on the interval $[\mu - 0.05, \mu + 0.05]$. From here we get $E(X) = \mu$ and $Var(X) = (2\times0.05)^2/ 12 = 0.000833$. I don't understand how the variance was calculated... :/","I'm reading a statistics book and I don't understand the following deduction: Let $X$ be uniformly distributed on the interval $[\mu - 0.05, \mu + 0.05]$. From here we get $E(X) = \mu$ and $Var(X) = (2\times0.05)^2/ 12 = 0.000833$. I don't understand how the variance was calculated... :/",,"['probability', 'statistics']"
96,Can someone help me with this formula?,Can someone help me with this formula?,,"I'm writing a software algorithm at the moment which compares survey answers. Questions have $5$ possible answers, and a respondent could choose between 1 and 5 answers. What I'd like to do, for each respondent, for each question, is calculate how strongly they feel about their answer. I propose to do this by counting the number of answers they selected. For example, suppose the question was: Which of these colours do you like? And the possible answers were: a) Blue b) Red c) Green d) Orange e) Purple Then someone who answers only b), feels more strongly about their answer than someone who selected all 5. What I'm having trouble with, is how to account for the different numbers of possible answers.  If a question has a yes or no answer, and the respondent only chooses one answer, we want to consider this as being less significant than if they only choose one answer on a question with more possible options. So the more options to choose from, the higher the importance of each answer selected. So far, I've come up with this: $$i = \text{max} - (\frac{g}{n} * \text{max})$$ Where: $i$ (importance) max (maximum importance %) $= 100$ $p$ (possible answers) $g$ (given answers) Can anybody suggest how I could approach this problem differently or improve the formula? Thanks!","I'm writing a software algorithm at the moment which compares survey answers. Questions have possible answers, and a respondent could choose between 1 and 5 answers. What I'd like to do, for each respondent, for each question, is calculate how strongly they feel about their answer. I propose to do this by counting the number of answers they selected. For example, suppose the question was: Which of these colours do you like? And the possible answers were: a) Blue b) Red c) Green d) Orange e) Purple Then someone who answers only b), feels more strongly about their answer than someone who selected all 5. What I'm having trouble with, is how to account for the different numbers of possible answers.  If a question has a yes or no answer, and the respondent only chooses one answer, we want to consider this as being less significant than if they only choose one answer on a question with more possible options. So the more options to choose from, the higher the importance of each answer selected. So far, I've come up with this: Where: (importance) max (maximum importance %) (possible answers) (given answers) Can anybody suggest how I could approach this problem differently or improve the formula? Thanks!",5 i = \text{max} - (\frac{g}{n} * \text{max}) i = 100 p g,['statistics']
97,Question on the Condorcet Ranking (Schulze Method) Algorithm,Question on the Condorcet Ranking (Schulze Method) Algorithm,,"I've been doing some research on ranking algorithms, and I've read theresearch with interest. The aspects of the Schulze Algorithm that appeals to me is that respondents do not have to rank all options, the rank just has to be ordinal (rather than in order), and ties can be resolved. However, upon implementation, I'm having trouble showing that ties do not occur when using the algorithm. I've put together a below real-life example, in which the result looks to be a tie. I can't figure out what I'm doing wrong. Is the solution simply to randomly select a winner when there is a tie? Could you somoene please have a look and offer any advice? Thanks very much, David Who do you think are the best basketball players? _ Kevin Garnett _ Lebron James _ Josh Smith _ David Lee _ Tyson Chandler 5 users (let’s just call them User A, User B, User C, User D and User E) answer the question in the following way: User A : 1.Kevin Garnett 2.Tyson Chandler 3.Josh Smith 4.David Lee 5.Lebron James User B: 1.Kevin Garnett 2.David Lee 3.Lebron James 4.Tyson Chandler 5.Josh Smith User C: 1.David Lee 2.Josh Smith 3.Kevin Garnett 4.Lebron James 5.Tyson Chandler User D: 1.Lebron James 2.Josh Smith 3.Tyson Chandler 4.David Lee 5.Kevin Garnett User E: 1.Tyson Chandler 2.David Lee 3.Kevin Garnett 4.Lebron James 5.Josh Smith If you put together the matrix of pairwise preferences, it would look like: p[*Kevin Garnett] p[*Tyson Chandler] p[*David Lee] p[*Lebron James] p[*Josh Smith] p[*Kevin Garnett] - 3 2 4 3 p[*Tyson Chandler] 2 - 3 2 3 p[*David Lee] 3 2 - 4 3 p[*Lebron James] 1 3 1 - 3 p[*Josh Smith] 2 2 2 2 - To find the strongest paths, you can then construct the grid to look like: Now, the strongest paths are (weakest links in red): …to Kevin Garnett …to Tyson Chandler …to David Lee …to Lebron James …to Josh Smith From Kevin Garnett… - Tyson Chandler (3) Tyson Chandler (3) – David Lee (3) Lebron James (4) Josh Smith (3) From Tyson Chandler… David Lee (3) – Kevin Garnett (3) - David Lee (3) David Lee (3) – Lebron James (4) Josh Smith (3) From David Lee… Kevin Garnett (3) Kevin Garnett (3) – Tyson Chandler (3) - Lebron James (4) Josh Smith (3) From Lebron James… Tyson Chandler (4) – David Lee (3) – Kevin Garnett (3) Tyson Chandler (4) Tyson Chandler (4) – David Lee (3) - Josh Smith (3) From Josh Smith… 0 0 0 0 - So the new strongest paths grid is: p[*Kevin Garnett] p[*Tyson Chandler] p[*David Lee] p[*Lebron James] p[*Josh Smith] p[*Kevin Garnett] - 3 3 4 3 p[*Tyson Chandler] 3 - 3 3 3 p[*David Lee] 3 3 - 4 3 p[*Lebron James] 3 4 3 - 3 p[*Josh Smith] 0 0 0 0 - Kevin Garnett and David Lee would tie in this case.","I've been doing some research on ranking algorithms, and I've read theresearch with interest. The aspects of the Schulze Algorithm that appeals to me is that respondents do not have to rank all options, the rank just has to be ordinal (rather than in order), and ties can be resolved. However, upon implementation, I'm having trouble showing that ties do not occur when using the algorithm. I've put together a below real-life example, in which the result looks to be a tie. I can't figure out what I'm doing wrong. Is the solution simply to randomly select a winner when there is a tie? Could you somoene please have a look and offer any advice? Thanks very much, David Who do you think are the best basketball players? _ Kevin Garnett _ Lebron James _ Josh Smith _ David Lee _ Tyson Chandler 5 users (let’s just call them User A, User B, User C, User D and User E) answer the question in the following way: User A : 1.Kevin Garnett 2.Tyson Chandler 3.Josh Smith 4.David Lee 5.Lebron James User B: 1.Kevin Garnett 2.David Lee 3.Lebron James 4.Tyson Chandler 5.Josh Smith User C: 1.David Lee 2.Josh Smith 3.Kevin Garnett 4.Lebron James 5.Tyson Chandler User D: 1.Lebron James 2.Josh Smith 3.Tyson Chandler 4.David Lee 5.Kevin Garnett User E: 1.Tyson Chandler 2.David Lee 3.Kevin Garnett 4.Lebron James 5.Josh Smith If you put together the matrix of pairwise preferences, it would look like: p[*Kevin Garnett] p[*Tyson Chandler] p[*David Lee] p[*Lebron James] p[*Josh Smith] p[*Kevin Garnett] - 3 2 4 3 p[*Tyson Chandler] 2 - 3 2 3 p[*David Lee] 3 2 - 4 3 p[*Lebron James] 1 3 1 - 3 p[*Josh Smith] 2 2 2 2 - To find the strongest paths, you can then construct the grid to look like: Now, the strongest paths are (weakest links in red): …to Kevin Garnett …to Tyson Chandler …to David Lee …to Lebron James …to Josh Smith From Kevin Garnett… - Tyson Chandler (3) Tyson Chandler (3) – David Lee (3) Lebron James (4) Josh Smith (3) From Tyson Chandler… David Lee (3) – Kevin Garnett (3) - David Lee (3) David Lee (3) – Lebron James (4) Josh Smith (3) From David Lee… Kevin Garnett (3) Kevin Garnett (3) – Tyson Chandler (3) - Lebron James (4) Josh Smith (3) From Lebron James… Tyson Chandler (4) – David Lee (3) – Kevin Garnett (3) Tyson Chandler (4) Tyson Chandler (4) – David Lee (3) - Josh Smith (3) From Josh Smith… 0 0 0 0 - So the new strongest paths grid is: p[*Kevin Garnett] p[*Tyson Chandler] p[*David Lee] p[*Lebron James] p[*Josh Smith] p[*Kevin Garnett] - 3 3 4 3 p[*Tyson Chandler] 3 - 3 3 3 p[*David Lee] 3 3 - 4 3 p[*Lebron James] 3 4 3 - 3 p[*Josh Smith] 0 0 0 0 - Kevin Garnett and David Lee would tie in this case.",,"['statistics', 'order-statistics', 'voting-theory']"
98,Finding $E(|X_1|\ |\max |X_i| )$,Finding,E(|X_1|\ |\max |X_i| ),"Suppose $X_1,\ldots,X_n$ are a random sample of $U(-\theta,\theta)$ with $\theta>0$. How can find $$ E\left(|X_1|\ \big|\max |X_i| \right) $$ that $1\leq i\leq n$?","Suppose $X_1,\ldots,X_n$ are a random sample of $U(-\theta,\theta)$ with $\theta>0$. How can find $$ E\left(|X_1|\ \big|\max |X_i| \right) $$ that $1\leq i\leq n$?",,"['probability', 'statistics']"
99,Iteratively Updating a Normal Distribution,Iteratively Updating a Normal Distribution,,"Is there a way to update a normal distribution when given new data points without knowing the original data points? What is the minimum information that would need to be known? For example, if I know the mean, standard deviation, and the number of original data points, but not the values of those points themselves, is it possible?","Is there a way to update a normal distribution when given new data points without knowing the original data points? What is the minimum information that would need to be known? For example, if I know the mean, standard deviation, and the number of original data points, but not the values of those points themselves, is it possible?",,"['statistics', 'normal-distribution']"
