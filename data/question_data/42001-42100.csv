,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How is this subgroup normal?,How is this subgroup normal?,,"Let $G$ be a group, and let $U$ be a subset of $G$. Let $\hat{U}$ be the smallest subgroup of $G$ containing $U$. Then $\hat{U}$ is the intersection of the collection of all the subgroups of $G$ containing $U$. (Right?) This collection is obviously non-empty as $G$ itself is a subgroup of itself which contains $U$. Now my question is this: If $gug^{-1} \in U$ for all $g \in G$ and $u \in U$, then is the subgroup $\hat{U}$ a normal subgroup of $G$? If the answer is yes, then one way of proving this is to find a homomorphism $ \phi \colon G \to G$ with kernel equal to $\hat{U}$. If the answer is no, then what counter-example can we give?","Let $G$ be a group, and let $U$ be a subset of $G$. Let $\hat{U}$ be the smallest subgroup of $G$ containing $U$. Then $\hat{U}$ is the intersection of the collection of all the subgroups of $G$ containing $U$. (Right?) This collection is obviously non-empty as $G$ itself is a subgroup of itself which contains $U$. Now my question is this: If $gug^{-1} \in U$ for all $g \in G$ and $u \in U$, then is the subgroup $\hat{U}$ a normal subgroup of $G$? If the answer is yes, then one way of proving this is to find a homomorphism $ \phi \colon G \to G$ with kernel equal to $\hat{U}$. If the answer is no, then what counter-example can we give?",,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
1,Let $G$ be an Abelian group with odd order. Show that $\varphi : G \to G$ such that $\varphi(x)=x^2$ is an automorphism,Let  be an Abelian group with odd order. Show that  such that  is an automorphism,G \varphi : G \to G \varphi(x)=x^2,Let $G$ be an Abelian group with odd order. Show that $\varphi : G \to G$ such that $\varphi(x)=x^2$ is an automorphism. I was able to show that the $\varphi$ function is a homomorphism and one-to-one. But I wasn't able to show that it is onto.,Let $G$ be an Abelian group with odd order. Show that $\varphi : G \to G$ such that $\varphi(x)=x^2$ is an automorphism. I was able to show that the $\varphi$ function is a homomorphism and one-to-one. But I wasn't able to show that it is onto.,,"['abstract-algebra', 'group-theory', 'abelian-groups']"
2,Order of a product in an abelian group.,Order of a product in an abelian group.,,"Suppose $G$ is a finite abelian group and has two element $a$ and $b$, such that $\circ(a)=m$ and $\circ(b)=n$ and $lcm(m,n)\neq m,n$. Is it true that $\circ(ab)=lcm(m,n)$? Thanks in advance.","Suppose $G$ is a finite abelian group and has two element $a$ and $b$, such that $\circ(a)=m$ and $\circ(b)=n$ and $lcm(m,n)\neq m,n$. Is it true that $\circ(ab)=lcm(m,n)$? Thanks in advance.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
3,Is a left invertible element of a ring necessarily right invertible? [duplicate],Is a left invertible element of a ring necessarily right invertible? [duplicate],,"This question already has answers here : A ring element with a left inverse but no right inverse? (3 answers) Closed 10 years ago . Let $R$ be a unitary ring and let $a,b \in R$ such that $ab=1$.  Does it imply that $a$ is invertible? The definition of invertible element requires that $ab = ba = 1$, so I guess it doesn't imply that a is invertible, but I didn't manage to find a unitary ring in which this happens.","This question already has answers here : A ring element with a left inverse but no right inverse? (3 answers) Closed 10 years ago . Let $R$ be a unitary ring and let $a,b \in R$ such that $ab=1$.  Does it imply that $a$ is invertible? The definition of invertible element requires that $ab = ba = 1$, so I guess it doesn't imply that a is invertible, but I didn't manage to find a unitary ring in which this happens.",,"['abstract-algebra', 'ring-theory']"
4,Definition: finite type vs finitely generated,Definition: finite type vs finitely generated,,"The mathematical term ""finite type"" appears more and more in the modern articles nowadays. But it is still hard to be found in the standard textbooks. I learned the definition of it from Stacks Project http://stacks.math.columbia.edu/tag/00F2 , it is defining on the ring maps. What is the right point of view when we say ""ring of finite type"", ""group of finite type"", ""module of finite type""? Would the definition in each case be exactly equivalent to the definition of ""finitely generated""?","The mathematical term ""finite type"" appears more and more in the modern articles nowadays. But it is still hard to be found in the standard textbooks. I learned the definition of it from Stacks Project http://stacks.math.columbia.edu/tag/00F2 , it is defining on the ring maps. What is the right point of view when we say ""ring of finite type"", ""group of finite type"", ""module of finite type""? Would the definition in each case be exactly equivalent to the definition of ""finitely generated""?",,"['abstract-algebra', 'terminology', 'definition', 'math-history']"
5,"$\mathbb{Q}[X,Y]/(X,Y^{2}-1)$ is this a maximal ideal or a prime ideal?",is this a maximal ideal or a prime ideal?,"\mathbb{Q}[X,Y]/(X,Y^{2}-1)","$\mathbb{Q}[X,Y]/(X,Y^{2}-1)$ is this a maximal ideal or a prime ideal? So far i got: $\mathbb{Q}[X,Y]/(X,Y^{2}-1) = \left(\mathbb{Q}[Y]\right)X/(X,Y^{2}-1)$ is isomorphic to  $\mathbb{Q}[Y]/(Y^{2}-1)$ = $\mathbb{Q}[Y]/(Y+1)(Y-1)$. Because we now have zero divisors this can't be a domain, so its cant be a prime/maximal ideal. I don't trust my proof because i don't know why the second step would be valid. Please help :) Kees","$\mathbb{Q}[X,Y]/(X,Y^{2}-1)$ is this a maximal ideal or a prime ideal? So far i got: $\mathbb{Q}[X,Y]/(X,Y^{2}-1) = \left(\mathbb{Q}[Y]\right)X/(X,Y^{2}-1)$ is isomorphic to  $\mathbb{Q}[Y]/(Y^{2}-1)$ = $\mathbb{Q}[Y]/(Y+1)(Y-1)$. Because we now have zero divisors this can't be a domain, so its cant be a prime/maximal ideal. I don't trust my proof because i don't know why the second step would be valid. Please help :) Kees",,"['abstract-algebra', 'ring-theory']"
6,number of element in a principal ideal domain can be $25/36/35/15$?,number of element in a principal ideal domain can be ?,25/36/35/15,Could any one tell me number of element in a principal ideal domain can be $25/36/35/15$ ? I just know a principal ideal domain is generated by a single element. what the knowledge I need to find this result? Thank you,Could any one tell me number of element in a principal ideal domain can be $25/36/35/15$ ? I just know a principal ideal domain is generated by a single element. what the knowledge I need to find this result? Thank you,,"['abstract-algebra', 'ring-theory', 'principal-ideal-domains']"
7,Example of a variety that is not toric,Example of a variety that is not toric,,"My question is simple, but I haven't seen it to be addressed anywhere: What would be a simple example of an affine variety that is not a   toric variety? Toric varieties (the ones I have studied) are constructed by a fan using ""gluing"". (For some examples, see Example 2.2 in Page 20).  So to prove that some affine variety is not toric amounts to showing that there is no possible fan that gives rise to this variety. And I am not sure how could one exactly do that. An example of projective variety that is not a toric variety is also welcome. By the way, some authors require toric varieties to be normal varieties, but some do not. I am not looking for an example of such variety as an answer to this particular question. (So I really want something that's not ""toric"" in all senses of the word). I am especially interested in knowing how it is possible to prove that a variety cannot be obtained from a fan using gluing.","My question is simple, but I haven't seen it to be addressed anywhere: What would be a simple example of an affine variety that is not a   toric variety? Toric varieties (the ones I have studied) are constructed by a fan using ""gluing"". (For some examples, see Example 2.2 in Page 20).  So to prove that some affine variety is not toric amounts to showing that there is no possible fan that gives rise to this variety. And I am not sure how could one exactly do that. An example of projective variety that is not a toric variety is also welcome. By the way, some authors require toric varieties to be normal varieties, but some do not. I am not looking for an example of such variety as an answer to this particular question. (So I really want something that's not ""toric"" in all senses of the word). I am especially interested in knowing how it is possible to prove that a variety cannot be obtained from a fan using gluing.",,"['abstract-algebra', 'algebraic-geometry', 'toric-geometry']"
8,"Irreducible $f(x) \in F[x]$ of prime degree, $E/F$ finite extension, $p \mid [E:F]$.","Irreducible  of prime degree,  finite extension, .",f(x) \in F[x] E/F p \mid [E:F],"Let $F$ be a field and let $f(x) \in F[x]$ be irreducible of prime degree $p$. Let $E/F$ be a finite extension. Prove: If $f(x)$ is not irreducible in $E[x]$, then $p \mid [E:F]$. (Hint: Consider a field $L$ with $E \subseteq L$ and $L$ as a root of $\alpha$ of $f(x)$.) Proof : Let $F$ be a field and let $f(x) \in F[x]$ be irreducible of prime degree $p$. Let $E/F$ be a finite extension. By Proposition 20 there exists a field $L$ containing $F$ with $[L:F] = p$ in which $f(x)$ has a root $\alpha$. If $E \subseteq L$ then we can consider $p = [L : F] = [L : E][E : F]$. It must follow that $[E:F] = p$ since if $[L:E] = p$, then $[E:F]=1$ which would contradict $f(x)$ being irreducible in $F$. Hence $[E:F] = p$ and immediately $p \mid [E:F]$. Now if $L \subseteq E$ then we consider $[E:F] = [E:L][L:F] = [E:L]p$ and thus $p \mid [E:F]$. Proposition 20: Let $F$ be a field. Let $p(x) \in F[x]$ be irreducible of degree $n$. Then there exists a field $K$ containing $F$ with $[K:F] = n$ in which $p(x)$ has a root. Is this proof correct? If not, what is wrong and how would I fix it. If its right, alternate proofs/approaches welcomed.","Let $F$ be a field and let $f(x) \in F[x]$ be irreducible of prime degree $p$. Let $E/F$ be a finite extension. Prove: If $f(x)$ is not irreducible in $E[x]$, then $p \mid [E:F]$. (Hint: Consider a field $L$ with $E \subseteq L$ and $L$ as a root of $\alpha$ of $f(x)$.) Proof : Let $F$ be a field and let $f(x) \in F[x]$ be irreducible of prime degree $p$. Let $E/F$ be a finite extension. By Proposition 20 there exists a field $L$ containing $F$ with $[L:F] = p$ in which $f(x)$ has a root $\alpha$. If $E \subseteq L$ then we can consider $p = [L : F] = [L : E][E : F]$. It must follow that $[E:F] = p$ since if $[L:E] = p$, then $[E:F]=1$ which would contradict $f(x)$ being irreducible in $F$. Hence $[E:F] = p$ and immediately $p \mid [E:F]$. Now if $L \subseteq E$ then we consider $[E:F] = [E:L][L:F] = [E:L]p$ and thus $p \mid [E:F]$. Proposition 20: Let $F$ be a field. Let $p(x) \in F[x]$ be irreducible of degree $n$. Then there exists a field $K$ containing $F$ with $[K:F] = n$ in which $p(x)$ has a root. Is this proof correct? If not, what is wrong and how would I fix it. If its right, alternate proofs/approaches welcomed.",,"['abstract-algebra', 'field-theory', 'extension-field', 'irreducible-polynomials']"
9,"Ways of finding primitive element of separable extension $\Bbb{Q}(\sqrt[4]{2},i)$ over $\Bbb{Q}$.",Ways of finding primitive element of separable extension  over .,"\Bbb{Q}(\sqrt[4]{2},i) \Bbb{Q}","Consider the field extension $L=\mathbb Q (\sqrt[4] 2 ,i)$  over $\mathbb Q$. This extension is separable as we know over a field of characterstic $0$. Now according to the primitive element theorem there exist an element $\gamma$ such that $L=\mathbb Q(\gamma)$. What are the possible ways of finding $\sqrt[4]2, i$ in terms of $\gamma$. (I think we can take $\gamma$ simply as a sum.) Note that $L=\mathbb Q (\sqrt[4] 2 ,i)$ is a splitting field of $x^4-2$. Thanks.","Consider the field extension $L=\mathbb Q (\sqrt[4] 2 ,i)$  over $\mathbb Q$. This extension is separable as we know over a field of characterstic $0$. Now according to the primitive element theorem there exist an element $\gamma$ such that $L=\mathbb Q(\gamma)$. What are the possible ways of finding $\sqrt[4]2, i$ in terms of $\gamma$. (I think we can take $\gamma$ simply as a sum.) Note that $L=\mathbb Q (\sqrt[4] 2 ,i)$ is a splitting field of $x^4-2$. Thanks.",,"['abstract-algebra', 'galois-theory', 'splitting-field', 'galois-extensions', 'separable-extension']"
10,Epic implies Surjective,Epic implies Surjective,,"I'm starting to work through Algebra: Chapter 0, and I'm fumbling a bit.  One of the problems in the first chapter asks me to formulate a definition for epimorphism based on having seen the definition for monomorphism, and then to tie it to surjectivity as monomorphism is related to injectivity.  This is still early in the book, so I'm only hanging out in the world of sets and functions. Proposed definition:  A function $f:A\rightarrow B$ is epic if for all $Z$ and all $\alpha, \alpha ':B\rightarrow Z$, $\alpha \circ f=\alpha' \circ f\implies\alpha=\alpha'$. With this definition in mind I want the statement that $f$ is epic iff $f$ is surjective.  Showing surjectivity implies epic wasn't hard so long as I know surjective means $f$ has a right inverse.  But I'm getting stuck with the other direction.  I know I'm probably supposed to find some special $\alpha$'s to help my cause but I'm coming up short...","I'm starting to work through Algebra: Chapter 0, and I'm fumbling a bit.  One of the problems in the first chapter asks me to formulate a definition for epimorphism based on having seen the definition for monomorphism, and then to tie it to surjectivity as monomorphism is related to injectivity.  This is still early in the book, so I'm only hanging out in the world of sets and functions. Proposed definition:  A function $f:A\rightarrow B$ is epic if for all $Z$ and all $\alpha, \alpha ':B\rightarrow Z$, $\alpha \circ f=\alpha' \circ f\implies\alpha=\alpha'$. With this definition in mind I want the statement that $f$ is epic iff $f$ is surjective.  Showing surjectivity implies epic wasn't hard so long as I know surjective means $f$ has a right inverse.  But I'm getting stuck with the other direction.  I know I'm probably supposed to find some special $\alpha$'s to help my cause but I'm coming up short...",,"['abstract-algebra', 'elementary-set-theory', 'category-theory', 'epimorphisms']"
11,Characterize finite dimensional algebras without nilpotent elements,Characterize finite dimensional algebras without nilpotent elements,,"Characterize all finite dimensional algebras (may not be commutative) over a field $K$ without nilpotent elements. My condition: Let $A$ be any algebra (may not be finite dimensional), then it's easy to prove that $A$ has no nilpotent elements iff the equation $x^2=0$ has a unique solution (the trivial solution). But is there a more explicit characterization of these finite dimensional algebras?","Characterize all finite dimensional algebras (may not be commutative) over a field $K$ without nilpotent elements. My condition: Let $A$ be any algebra (may not be finite dimensional), then it's easy to prove that $A$ has no nilpotent elements iff the equation $x^2=0$ has a unique solution (the trivial solution). But is there a more explicit characterization of these finite dimensional algebras?",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
12,Any nonabelian group of order $6$ is isomorphic to $S_3$?,Any nonabelian group of order  is isomorphic to ?,6 S_3,"I've read a proof at the end of this document that any nonabelian group of order $6$ is isomorphic to $S_3$, but it feels clunky to me. I want to try the following instead: Let $G$ be a nonabelian group of order $6$. By Cauchy's theorem or the Sylow theorems, there is a element of order $2$, let it generate a subgroup $H$ of order $2$. Let $G$ act on the quotient set $G/H$ by conjugation. This induces a homomorphism $G\to S_3$. I want to show it's either injective or surjective to get the isomorphism. I know $n_3\equiv 1\pmod{3}$ and $n_3\mid 2$, so $n_3=1$, so there is a unique, normal Sylow $3$-subgroup. Also, $n_2\equiv 1\pmod{2}$, and $n_2\mid 3$, so $n_2=1$ or $3$. However, if $n_2=1$, then I know $G$ would be a direct product of its Sylow subgroups, but then $G\cong C_2\times C_3\cong C_6$, a contradiction since $G$ is nonabelian. So $n_2=3$. Can this info be used to show the homomorphism is either injective or surjective? Thanks.","I've read a proof at the end of this document that any nonabelian group of order $6$ is isomorphic to $S_3$, but it feels clunky to me. I want to try the following instead: Let $G$ be a nonabelian group of order $6$. By Cauchy's theorem or the Sylow theorems, there is a element of order $2$, let it generate a subgroup $H$ of order $2$. Let $G$ act on the quotient set $G/H$ by conjugation. This induces a homomorphism $G\to S_3$. I want to show it's either injective or surjective to get the isomorphism. I know $n_3\equiv 1\pmod{3}$ and $n_3\mid 2$, so $n_3=1$, so there is a unique, normal Sylow $3$-subgroup. Also, $n_2\equiv 1\pmod{2}$, and $n_2\mid 3$, so $n_2=1$ or $3$. However, if $n_2=1$, then I know $G$ would be a direct product of its Sylow subgroups, but then $G\cong C_2\times C_3\cong C_6$, a contradiction since $G$ is nonabelian. So $n_2=3$. Can this info be used to show the homomorphism is either injective or surjective? Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
13,Showing two field extensions are the same,Showing two field extensions are the same,,"Consider the finite extension $F/K$, [$F:K$]=15. Suppose for some $\gamma\in F$, $F=K(\gamma)$. I want to show that $F=K(\gamma^{2}+1)$. Since the extension is finite, in particular it is algebraic. Therefore I think as long as I show that both $\gamma$ and $\gamma^{2} +1$ satisfy the same minimal polynomial the conclusion will follow. Is this correct? Also, I do not see the significance that the degree of the extension is playing, I would appreciate a hint about this as well.","Consider the finite extension $F/K$, [$F:K$]=15. Suppose for some $\gamma\in F$, $F=K(\gamma)$. I want to show that $F=K(\gamma^{2}+1)$. Since the extension is finite, in particular it is algebraic. Therefore I think as long as I show that both $\gamma$ and $\gamma^{2} +1$ satisfy the same minimal polynomial the conclusion will follow. Is this correct? Also, I do not see the significance that the degree of the extension is playing, I would appreciate a hint about this as well.",,"['abstract-algebra', 'field-theory']"
14,"Are there cyclic, free modules where the generating element isn't a basis?","Are there cyclic, free modules where the generating element isn't a basis?",,"Let $R$ be a ring, and $M$ a nontrivial cyclic, free $R$-module. Let $m$ generate $M$, so that $M = Rm$. Is it then the case that $m$ forms a basis for $M$, so that $\mbox{ann}_{R}(m) = (0)$? I know that if $R$ is a domain or a commutative ring, it is easy to show that $m$ forms a basis. However, I am unsure as to whether or not it holds for general rings. Any insight would be appreciated. Thanks!","Let $R$ be a ring, and $M$ a nontrivial cyclic, free $R$-module. Let $m$ generate $M$, so that $M = Rm$. Is it then the case that $m$ forms a basis for $M$, so that $\mbox{ann}_{R}(m) = (0)$? I know that if $R$ is a domain or a commutative ring, it is easy to show that $m$ forms a basis. However, I am unsure as to whether or not it holds for general rings. Any insight would be appreciated. Thanks!",,['abstract-algebra']
15,Ring with 10 elements is isomorphic to $\mathbb{Z}/10 \mathbb{Z} $,Ring with 10 elements is isomorphic to,\mathbb{Z}/10 \mathbb{Z} ,"How do I prove that a finite ring $R$ of order 10 is isomorphic to the ring $\mathbb{Z}/10 \mathbb{Z}$? I know that as a group under addition, $(R,+)$ is isomorphic to the group $(\mathbb{Z}/10 \mathbb{Z}, + )$, but the multiplication is rather mysterious to me.","How do I prove that a finite ring $R$ of order 10 is isomorphic to the ring $\mathbb{Z}/10 \mathbb{Z}$? I know that as a group under addition, $(R,+)$ is isomorphic to the group $(\mathbb{Z}/10 \mathbb{Z}, + )$, but the multiplication is rather mysterious to me.",,"['abstract-algebra', 'ring-theory', 'finite-rings']"
16,Finding generators of an ideal / showing an ideal is prime,Finding generators of an ideal / showing an ideal is prime,,"Suppose I have an ideal like $\mathrm{rad}(\langle y - x^2, z - x^3 \rangle)$. How do I go about finding generators for the ideal? If I could show that $\langle y - x^2, z - x^3 \rangle$ is a prime ideal then obviously $y-x^2$ and $z-x^3$ would generate $\mathrm{rad}(\langle y - x^2, z - x^3 \rangle)$, but I don't see how to do this. Thanks.","Suppose I have an ideal like $\mathrm{rad}(\langle y - x^2, z - x^3 \rangle)$. How do I go about finding generators for the ideal? If I could show that $\langle y - x^2, z - x^3 \rangle$ is a prime ideal then obviously $y-x^2$ and $z-x^3$ would generate $\mathrm{rad}(\langle y - x^2, z - x^3 \rangle)$, but I don't see how to do this. Thanks.",,"['abstract-algebra', 'commutative-algebra']"
17,Nilpotent elements of a non-commutative ring with trivial automorphism group form an ideal,Nilpotent elements of a non-commutative ring with trivial automorphism group form an ideal,,Let $R$ be a non-commutative ring with identity such that the identity map is the only ring automorphism of $R$. Prove that the set $N$ of all nilpotent elements of $R$ is an ideal of $R$.,Let $R$ be a non-commutative ring with identity such that the identity map is the only ring automorphism of $R$. Prove that the set $N$ of all nilpotent elements of $R$ is an ideal of $R$.,,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
18,Multiples of 4 as sum or difference of 2 squares,Multiples of 4 as sum or difference of 2 squares,,"Is it true that for any $n \in \mathbb{N}$ we can have $4n = x^{2} + y^{2}$ or $4n = x^{2} - y^{2}$ , for $x,y \in \mathbb{N} \cup (0)$ ? I was just working out a proof and this turns out to be true from $n=1$ to $n=20$ . After that I didn't try, but I would like to see if a counterexample exists for a greater value of $n$ .","Is it true that for any we can have or , for ? I was just working out a proof and this turns out to be true from to . After that I didn't try, but I would like to see if a counterexample exists for a greater value of .","n \in \mathbb{N} 4n = x^{2} + y^{2} 4n = x^{2} - y^{2} x,y \in \mathbb{N} \cup (0) n=1 n=20 n",['number-theory']
19,Show a ring is commutative if $r^2 = r + r$,Show a ring is commutative if,r^2 = r + r,"The claim is that any ring $R$ in which for all $r \in R$ we have that $rr = r + r$ , must be commutative. No assumptions are made about $R$ having multiplicative identity or being commutative. I was told from a professor that it was true. So far, I've found that a ring with this property cannot have a $1$ element distinct from $0$ since $1^2 = 1 + 1 = 1$ , meaning $1 = 0$ . I also have that every element is nilpotent with a degree at most $3$ . This comes from \begin{equation*} (r+r)(r+r) = (r+r) +(r+r) \\ r^2 + r ^2 + r^2 + r^2 = r^2+r^2 \\ r^2 + r^2 = 0 \\ r^4 = 0. \end{equation*} Expanding $r^3$ then gives \begin{equation*} r^3 = r(r^2) \\ r^3 = r(r + r) \\ r^3 = r^2 + r^2 \\ r^3 = 0. \end{equation*} The other more notable result that I've managed to prove is that $ab = -ba$ for all $a, b \in R$ . This can be found from expanding \begin{equation*} a^2 + b^2 = (a + a) + (b + b) \\ a^2 + b^2 = (a + b) + (a + b) \\ a^2 + b^2 = (a + b)(a + b) \\ a^2 + b^2 = a^2 + ab + ba + b^2 \\ ab = -ba \end{equation*} It feels like I'm really close but I'm not really sure where to go from here. From the above, it seems like for R to commute you would need that $ab + ab = (ab)^2 = 0$ . I've continued to look at other expansions from the $r^2 = r + r$ identity and have been able to develop some other equations, but have had no success in proving commutativity yet.","The claim is that any ring in which for all we have that , must be commutative. No assumptions are made about having multiplicative identity or being commutative. I was told from a professor that it was true. So far, I've found that a ring with this property cannot have a element distinct from since , meaning . I also have that every element is nilpotent with a degree at most . This comes from Expanding then gives The other more notable result that I've managed to prove is that for all . This can be found from expanding It feels like I'm really close but I'm not really sure where to go from here. From the above, it seems like for R to commute you would need that . I've continued to look at other expansions from the identity and have been able to develop some other equations, but have had no success in proving commutativity yet.","R r \in R rr = r + r R 1 0 1^2 = 1 + 1 = 1 1 = 0 3 \begin{equation*}
(r+r)(r+r) = (r+r) +(r+r) \\
r^2 + r ^2 + r^2 + r^2 = r^2+r^2 \\
r^2 + r^2 = 0 \\
r^4 = 0.
\end{equation*} r^3 \begin{equation*}
r^3 = r(r^2) \\
r^3 = r(r + r) \\
r^3 = r^2 + r^2 \\
r^3 = 0.
\end{equation*} ab = -ba a, b \in R \begin{equation*}
a^2 + b^2 = (a + a) + (b + b) \\
a^2 + b^2 = (a + b) + (a + b) \\
a^2 + b^2 = (a + b)(a + b) \\
a^2 + b^2 = a^2 + ab + ba + b^2 \\
ab = -ba
\end{equation*} ab + ab = (ab)^2 = 0 r^2 = r + r","['abstract-algebra', 'ring-theory', 'noncommutative-algebra', 'rngs']"
20,"If the magnitude of a root of an irreducible polynomial can be expressed via radicals, can the root?","If the magnitude of a root of an irreducible polynomial can be expressed via radicals, can the root?",,"Let $f$ be an irreducible polynomial with coefficients in $\mathbb{Q}$ , with roots $c_1,...,c_n \in \mathbb{C}$ . I  have two related but slightly different questions: If $|c_1|$ lies in a radical extension of $\mathbb{Q}$ , does that imply that $c_1$ lies in a radical extension of $\mathbb{Q}$ ? If $|c_1|,...,|c_n|$ all lie in a radical extension of $\mathbb{Q}$ , does that imply that $c_1,...,c_n$ all lie in a radical extension of $\mathbb{Q}$ ? Obviously if the answer to the first question is yes, then so is the answer to the second question. However since I'm not sure of how to tackle either one, can someone with more expertise point me in the right direction?","Let be an irreducible polynomial with coefficients in , with roots . I  have two related but slightly different questions: If lies in a radical extension of , does that imply that lies in a radical extension of ? If all lie in a radical extension of , does that imply that all lie in a radical extension of ? Obviously if the answer to the first question is yes, then so is the answer to the second question. However since I'm not sure of how to tackle either one, can someone with more expertise point me in the right direction?","f \mathbb{Q} c_1,...,c_n \in \mathbb{C} |c_1| \mathbb{Q} c_1 \mathbb{Q} |c_1|,...,|c_n| \mathbb{Q} c_1,...,c_n \mathbb{Q}","['abstract-algebra', 'galois-theory', 'radicals']"
21,Which fields are closed with respect to roots of polynomial maps but not algebraically closed?,Which fields are closed with respect to roots of polynomial maps but not algebraically closed?,,"Before yesterday, I had heard of basically two examples of algebraically closed fields, the algebraic numbers $\overline{\mathbb{Q}}$ and $\mathbb{C}$ . I tried to come up with more examples and started thinking about $\mathbb{F}_2$ , the field with two elements. All the polynomial maps on $\mathbb{F}_2$ that are non-constant have a root because the domain consists of just $0$ and $1$ and thus any function without a root is constrained to be constantly 1. However, there are indeed polynomials in $\mathbb{F}_2[x]$ that are nonconstant and lack roots, such as $x^2 + x + 1$ . This question shows the construction for the algebraic closure of a finite field of prime order. Let's call the weaker property closure with respect to roots of polynomial maps . I'm wondering which fields are closed with respect to roots of polynomial maps but not algebraically closed besides $\mathbb{F}_2$ , if there are any . $\mathbb{F}_3$ does not have this property because $x^2 + 1 \mapsto \{0+1, 1+1, 1+1\} = \{1, 2\}$ has no roots. For the other finite fields of odd prime order, I think I can use the polynomial $x^{p - 1} + 1$ to witness the failure of the weaker property since the multiplicative group of $\mathbb{F}_p$ has order $p-1$ and this function is nonconstant since $p \ge 3$ . I think my question is distinct from this question about the distinction between polynomials and polynomial maps because I'm asking about consequences of using the ""wrong"" notion specifically when characterizing the algebraically closed fields, not what the difference is per se.","Before yesterday, I had heard of basically two examples of algebraically closed fields, the algebraic numbers and . I tried to come up with more examples and started thinking about , the field with two elements. All the polynomial maps on that are non-constant have a root because the domain consists of just and and thus any function without a root is constrained to be constantly 1. However, there are indeed polynomials in that are nonconstant and lack roots, such as . This question shows the construction for the algebraic closure of a finite field of prime order. Let's call the weaker property closure with respect to roots of polynomial maps . I'm wondering which fields are closed with respect to roots of polynomial maps but not algebraically closed besides , if there are any . does not have this property because has no roots. For the other finite fields of odd prime order, I think I can use the polynomial to witness the failure of the weaker property since the multiplicative group of has order and this function is nonconstant since . I think my question is distinct from this question about the distinction between polynomials and polynomial maps because I'm asking about consequences of using the ""wrong"" notion specifically when characterizing the algebraically closed fields, not what the difference is per se.","\overline{\mathbb{Q}} \mathbb{C} \mathbb{F}_2 \mathbb{F}_2 0 1 \mathbb{F}_2[x] x^2 + x + 1 \mathbb{F}_2 \mathbb{F}_3 x^2 + 1 \mapsto \{0+1, 1+1, 1+1\} = \{1, 2\} x^{p - 1} + 1 \mathbb{F}_p p-1 p \ge 3","['abstract-algebra', 'field-theory']"
22,Ideal of height $>1$ containing no non-zero prime ideals.,Ideal of height  containing no non-zero prime ideals.,>1,"Edit: Badam Baplan gives a remarkable example below, which answers the question completely. I would still appreciate any other examples that others may come up with; in particular, is an example still possible if we ask for $R$ to be Noetherian? Let $R$ be a (commutative, unital) ring and $I<R$ an ideal. Recall that we define $$\operatorname{ht}I=\min\{\operatorname{ht}P:P\in\operatorname{Spec}R,P\geqslant I\},$$ where $\operatorname{ht}P$ is defined in the usual way for a prime ideal $P$ . Is there a nice example of an integral domain $R$ and an ideal $I$ such that (i) $I$ contains no non-zero prime ideals, and (ii) $\operatorname{ht}I>1$ ? Note: by Krull's height theorem , if $R$ is Noetherian then $I$ cannot be principal. If we drop the condition that $R$ is an integral domain, then we can get examples where $\operatorname{ht}I$ is arbitrarily large. For instance, let $F$ be your favorite field, and define $A$ to be the polynomial ring $F[x_1,\dots,x_n]$ . Choose any non-zero ideal $M\leqslant A$ , with some $o\in M\setminus\{0\}$ of minimal degree. (For later, note that $o\notin x_1M+\dots+x_nM$ ; call this fact $(\star)$ .) Now, consider the ring structure on the product $R:=A\times M$ defined by $(a,m)+(b,n)=(a+b,m+n)$ $(a,m)\cdot(b,n)=(ab,an+bm)$ for all $a,b\in A$ and $m,n\in M$ . Note that every element $(0,m)$ is nilpotent, so any prime ideal of $R$ must contain $0\times M$ . Conversely, if $P$ is a prime ideal of $A$ , then $P\times M$ is a prime ideal of $R$ . With this in mind, consider the ideal $I<R$ generated by the elements $(x_i,0)$ for $1\leqslant i\leqslant n$ . First note that $I$ contains no prime ideals; indeed, one can explicitly compute $I$ to be the product $$(x_1A+\dots+x_nA)\times(x_1M+\dots +x_nM),$$ where both direct factors are considered as ideals of $A$ . In particular, by fact $(\star)$ , we have $(0,o)\notin I$ , and so (by the remark above, since $(0,o)$ is nilpotent), $I$ cannot contain any prime ideal. On the other hand, consider the prime ideal $P:=\langle x_1,\dots,x_n\rangle\times M>I$ . This is the unique minimal prime lying above $I$ , since $P=I+(0\times M)$ and every prime must contain $0\times M$ . However, we have $\operatorname{ht}P=n$ , since $$0\times M<\langle x_1\rangle\times M<\langle x_1,x_2\rangle\times M<\dots<P$$ is a strictly ascending chain of primes below $P$ . Thus, since $P$ is the unique minimal prime above $I$ , we have $\operatorname{ht}I=n$ . One can extend this example in the natural way to find an example where $\operatorname{ht}I=\infty$ . So this resolves the question completely if we do not require $R$ to be an integral domain. However, I'm struggling to find an example where $R$ is an integral domain. Can anyone think of a nice example? I tried attempting to consider the example above as a quotient of an appropriate polynomial ring, but didn't make any progress. My thinking was that we could perhaps find a desirable prime lying below the kernel of the projection map, and then quotient by that to find a domain with some similar behavior. However, this doesn't seem to work out very nicely. As a smaller follow-up question, what is the geometric significance (if any) of such a ring?","Edit: Badam Baplan gives a remarkable example below, which answers the question completely. I would still appreciate any other examples that others may come up with; in particular, is an example still possible if we ask for to be Noetherian? Let be a (commutative, unital) ring and an ideal. Recall that we define where is defined in the usual way for a prime ideal . Is there a nice example of an integral domain and an ideal such that (i) contains no non-zero prime ideals, and (ii) ? Note: by Krull's height theorem , if is Noetherian then cannot be principal. If we drop the condition that is an integral domain, then we can get examples where is arbitrarily large. For instance, let be your favorite field, and define to be the polynomial ring . Choose any non-zero ideal , with some of minimal degree. (For later, note that ; call this fact .) Now, consider the ring structure on the product defined by for all and . Note that every element is nilpotent, so any prime ideal of must contain . Conversely, if is a prime ideal of , then is a prime ideal of . With this in mind, consider the ideal generated by the elements for . First note that contains no prime ideals; indeed, one can explicitly compute to be the product where both direct factors are considered as ideals of . In particular, by fact , we have , and so (by the remark above, since is nilpotent), cannot contain any prime ideal. On the other hand, consider the prime ideal . This is the unique minimal prime lying above , since and every prime must contain . However, we have , since is a strictly ascending chain of primes below . Thus, since is the unique minimal prime above , we have . One can extend this example in the natural way to find an example where . So this resolves the question completely if we do not require to be an integral domain. However, I'm struggling to find an example where is an integral domain. Can anyone think of a nice example? I tried attempting to consider the example above as a quotient of an appropriate polynomial ring, but didn't make any progress. My thinking was that we could perhaps find a desirable prime lying below the kernel of the projection map, and then quotient by that to find a domain with some similar behavior. However, this doesn't seem to work out very nicely. As a smaller follow-up question, what is the geometric significance (if any) of such a ring?","R R I<R \operatorname{ht}I=\min\{\operatorname{ht}P:P\in\operatorname{Spec}R,P\geqslant I\}, \operatorname{ht}P P R I I \operatorname{ht}I>1 R I R \operatorname{ht}I F A F[x_1,\dots,x_n] M\leqslant A o\in M\setminus\{0\} o\notin x_1M+\dots+x_nM (\star) R:=A\times M (a,m)+(b,n)=(a+b,m+n) (a,m)\cdot(b,n)=(ab,an+bm) a,b\in A m,n\in M (0,m) R 0\times M P A P\times M R I<R (x_i,0) 1\leqslant i\leqslant n I I (x_1A+\dots+x_nA)\times(x_1M+\dots +x_nM), A (\star) (0,o)\notin I (0,o) I P:=\langle x_1,\dots,x_n\rangle\times M>I I P=I+(0\times M) 0\times M \operatorname{ht}P=n 0\times M<\langle x_1\rangle\times M<\langle x_1,x_2\rangle\times M<\dots<P P P I \operatorname{ht}I=n \operatorname{ht}I=\infty R R","['abstract-algebra', 'ring-theory', 'commutative-algebra']"
23,Classification of countably infinite Abelian groups?,Classification of countably infinite Abelian groups?,,"There’s a pretty simple classification of finitely generated Abelian groups, and there’s a relatively understandable classification of countably infinite Abelian $p$ -groups for any prime $p$ .  But my question is, what is the general classification upto isomorphism of countably infinite Abelian groups? How complicated is it to state?  Is there a sentence we can write, like “Two countably infinite Abelian groups are isomorphic if and only if ...”?","There’s a pretty simple classification of finitely generated Abelian groups, and there’s a relatively understandable classification of countably infinite Abelian -groups for any prime .  But my question is, what is the general classification upto isomorphism of countably infinite Abelian groups? How complicated is it to state?  Is there a sentence we can write, like “Two countably infinite Abelian groups are isomorphic if and only if ...”?",p p,"['abstract-algebra', 'group-theory', 'abelian-groups', 'group-isomorphism']"
24,Contravariant functor taking every finite group to an isomorphic group,Contravariant functor taking every finite group to an isomorphic group,,"Every finite abelian group $A$ is isomorphic to its dual group $A^*:=\operatorname{Hom}(A,\mathbb{C}^\times)$ . The isomorphism of $A$ with $A^*$ is non-canonical, and one way to make this precise is to say that the functor $A\mapsto A^*$ is contravariant, so this functor cannot be naturally isomorphic to the (covariant) identity functor. I wonder if there is an analogous construction that works for all finite groups. Specifically: Does there exist a contravariant functor $F$ from the category of finite groups to itself, such that $F(G)$ is isomorphic to $G$ for every group $G$ ? The imprecise question I have in mind is: for an arbitrary finite $G$ , can one construct a group $G'$ that is non-canonically isomorphic to $G$ ? The existence of a contravariant functor $F$ as above would be one precise way to answer the imprecise question.","Every finite abelian group is isomorphic to its dual group . The isomorphism of with is non-canonical, and one way to make this precise is to say that the functor is contravariant, so this functor cannot be naturally isomorphic to the (covariant) identity functor. I wonder if there is an analogous construction that works for all finite groups. Specifically: Does there exist a contravariant functor from the category of finite groups to itself, such that is isomorphic to for every group ? The imprecise question I have in mind is: for an arbitrary finite , can one construct a group that is non-canonically isomorphic to ? The existence of a contravariant functor as above would be one precise way to answer the imprecise question.","A A^*:=\operatorname{Hom}(A,\mathbb{C}^\times) A A^* A\mapsto A^* F F(G) G G G G' G F","['abstract-algebra', 'group-theory', 'category-theory']"
25,What is the difference between cyclic groups and periodic groups?,What is the difference between cyclic groups and periodic groups?,,"I have read that a cyclic group G is one that can be generated by a single element a called the generator , aϵG .  While looking up Wikipedia for Torsion Groups(periodic groups), I found: ""In group theory, a branch of mathematics, a torsion group or a periodic group is a group in which each element has finite order. All finite groups are periodic. The concept of a periodic group should not be confused with that of a cyclic group ."" I am confused, after this I couldn't find a satisfying difference between the two(periodic and cyclic groups). Thanks","I have read that a cyclic group G is one that can be generated by a single element a called the generator , aϵG .  While looking up Wikipedia for Torsion Groups(periodic groups), I found: ""In group theory, a branch of mathematics, a torsion group or a periodic group is a group in which each element has finite order. All finite groups are periodic. The concept of a periodic group should not be confused with that of a cyclic group ."" I am confused, after this I couldn't find a satisfying difference between the two(periodic and cyclic groups). Thanks",,"['abstract-algebra', 'group-theory', 'number-theory']"
26,Does Distributivity Imply Power Associativity?,Does Distributivity Imply Power Associativity?,,"Say we have an algebra $(A, +, \cdot)$ , where $(A, +)$ is an Abelian Group. All we know about $\cdot$ is that it is both left and right distributive over addition. So, $\forall a,b,c \in A, a \cdot (b+c) = (a \cdot b) + (a \cdot c)$ and $(b+c) \cdot a = (b \cdot a) + (c \cdot a)$ . We can't assume $ \cdot $ is associative, commutative, or anything else besides distributive. Do we know whether multiplication is power associative or not? That is, for all $a$ , powers of $a$ are associative (e.g $a \cdot (a \cdot a) = (a \cdot a) \cdot a$ ). If so, what would the proof look like? If not, is there a counterexample? I attempted this myself, but I couldn't find any hints of a proof, so I tried to produce a counterexample, similarly with no luck.","Say we have an algebra , where is an Abelian Group. All we know about is that it is both left and right distributive over addition. So, and . We can't assume is associative, commutative, or anything else besides distributive. Do we know whether multiplication is power associative or not? That is, for all , powers of are associative (e.g ). If so, what would the proof look like? If not, is there a counterexample? I attempted this myself, but I couldn't find any hints of a proof, so I tried to produce a counterexample, similarly with no luck.","(A, +, \cdot) (A, +) \cdot \forall a,b,c \in A, a \cdot (b+c) = (a \cdot b) + (a \cdot c) (b+c) \cdot a = (b \cdot a) + (c \cdot a)  \cdot  a a a \cdot (a \cdot a) = (a \cdot a) \cdot a","['abstract-algebra', 'nonassociative-algebras']"
27,What natural ways of partitioning a group $G$ are there?,What natural ways of partitioning a group  are there?,G,"What natural, or at least useful, ways are there to partition a finite group $G$ ? The two examples that come to mind are: Partitioning $G$ into all the left (or right) cosets of a subgroup $H$ of $G$ . Partitioning $G$ into all its conjugacy classes.","What natural, or at least useful, ways are there to partition a finite group ? The two examples that come to mind are: Partitioning into all the left (or right) cosets of a subgroup of . Partitioning into all its conjugacy classes.",G G H G G,"['abstract-algebra', 'group-theory', 'finite-groups', 'big-list', 'set-partition']"
28,Why do we want Dedekind rings to be integral closed?,Why do we want Dedekind rings to be integral closed?,,"As I understand, the idea of Dedekind domains is motivated by the wish to factorize ideals into prime ideals. Dedekind rings are supposed to: be noetherian, which makes sense because that ensures that the factorization is finite; have every prime ideal to be a maximal ideal, which makes sense because we want to factorize into prime ideals, so they need to be ""very"" big. integral closed. Can anybody give me an intuitive idea about why we need that property?","As I understand, the idea of Dedekind domains is motivated by the wish to factorize ideals into prime ideals. Dedekind rings are supposed to: be noetherian, which makes sense because that ensures that the factorization is finite; have every prime ideal to be a maximal ideal, which makes sense because we want to factorize into prime ideals, so they need to be ""very"" big. integral closed. Can anybody give me an intuitive idea about why we need that property?",,"['abstract-algebra', 'commutative-algebra', 'dedekind-domain']"
29,Difference between $G$-module homomorphisms and $G$-linear maps,Difference between -module homomorphisms and -linear maps,G G,"What is the difference between a $G$-module homomorphism and a $G$-linear map?  My understanding is that both are linear maps between vector spaces (say, from $V$ to $W$) and both preserve the action of the group $G$ (i.e., for all $g$ in $G$, $\rho(g*v)=g*\rho(v)$ for all $v$ in $V$).","What is the difference between a $G$-module homomorphism and a $G$-linear map?  My understanding is that both are linear maps between vector spaces (say, from $V$ to $W$) and both preserve the action of the group $G$ (i.e., for all $g$ in $G$, $\rho(g*v)=g*\rho(v)$ for all $v$ in $V$).",,"['abstract-algebra', 'group-theory', 'representation-theory']"
30,Prove that $R[x]$ is an integral domain if and only if $R$ is an integral domain. [duplicate],Prove that  is an integral domain if and only if  is an integral domain. [duplicate],R[x] R,"This question already has answers here : Prove that $R$ is an integral domain $\Leftrightarrow$ $R[x]$ is an integral domain (4 answers) Closed 5 years ago . I want to prove that for a ring $R$ , $R[x]$ is an integral domain if and only if $R$ is an integral domain. I have one direction of the proof ( $R$ an integral domain implies $R[x]$ ) an integral domain, but I am having trouble proving the other direction. Here is the first direction: Let $R$ be an integral domain, and suppose on the contrary that $R[x]$ is not an integral domain, meaning that it has zero divisors. In particular, let $f(x),g(x)\neq 0\in R[x]$ such that $\deg(f)=n$ and $\deg(g)=m$ and $f(x)g(x)=0$ . Specifically, $f(x)=a_nx^n+...a_1x+a_0$ and $g(x)=b_mx^m+...b_1x+b_0$ where $a_i,b_j\in R$ for all $0\leq i,j\leq n,m$ . Now, consider the polynomial term $a_nb_mx^{n+m}\in f(x)g(x)$ . Because $f(x)g(x)=0$ , this means that each polynomial coefficient must be zero, so in particular $a_nb_m=0$ . But, $R$ is an integral domain so either $a_n=0$ or $b_m=0$ , contradicting the degree of $f(x)$ or $g(x)$ . Thus, $R[x]$ is an integral domain. And here is what I have so far for the other direction, but I'm not sure if I have the right set-up. Any hints or comments are appreciated. Now, suppose conversely that $R[x]$ is an integral domain, and suppose on the contrary that $R$ is not, meaning that it has zero divisors. In particular, let $ab=0$ where $a\neq 0$ and $b\neq 0$ for $a_0,b_0\in R$ . Furthermore, consider the polynomial product $f(x)g(x)=0$ for $f(x),g(x)\in R[x]$ , where $f(x)$ and $g(x)$ are defined in the same way as above. Because $R[x]$ is an integral domain, either $f(x)=0$ or $g(x)=0$ .","This question already has answers here : Prove that $R$ is an integral domain $\Leftrightarrow$ $R[x]$ is an integral domain (4 answers) Closed 5 years ago . I want to prove that for a ring , is an integral domain if and only if is an integral domain. I have one direction of the proof ( an integral domain implies ) an integral domain, but I am having trouble proving the other direction. Here is the first direction: Let be an integral domain, and suppose on the contrary that is not an integral domain, meaning that it has zero divisors. In particular, let such that and and . Specifically, and where for all . Now, consider the polynomial term . Because , this means that each polynomial coefficient must be zero, so in particular . But, is an integral domain so either or , contradicting the degree of or . Thus, is an integral domain. And here is what I have so far for the other direction, but I'm not sure if I have the right set-up. Any hints or comments are appreciated. Now, suppose conversely that is an integral domain, and suppose on the contrary that is not, meaning that it has zero divisors. In particular, let where and for . Furthermore, consider the polynomial product for , where and are defined in the same way as above. Because is an integral domain, either or .","R R[x] R R R[x] R R[x] f(x),g(x)\neq 0\in R[x] \deg(f)=n \deg(g)=m f(x)g(x)=0 f(x)=a_nx^n+...a_1x+a_0 g(x)=b_mx^m+...b_1x+b_0 a_i,b_j\in R 0\leq i,j\leq n,m a_nb_mx^{n+m}\in f(x)g(x) f(x)g(x)=0 a_nb_m=0 R a_n=0 b_m=0 f(x) g(x) R[x] R[x] R ab=0 a\neq 0 b\neq 0 a_0,b_0\in R f(x)g(x)=0 f(x),g(x)\in R[x] f(x) g(x) R[x] f(x)=0 g(x)=0","['abstract-algebra', 'ring-theory', 'integral-domain', 'polynomial-rings']"
31,$v \otimes v' = v' \otimes v$ implies $v = av'$,implies,v \otimes v' = v' \otimes v v = av',"In Dummit and Foote problem 12 of section 10.4, I need to show that if $V$ is some vector space over a field $F$ and $v,v'$ are nonzero elements of $V$, supposing we have that $v \otimes v' = v' \otimes v$ then this implies that $v = av'$ for some $a \in F$. I was trying to consider some basis $\mathcal{B} = \{e_i\}_{i\in I}$ for the vector space $V$, show that we can write $v$ and $v'$ as linear combinations of this basis elements and then argue that since we have $v \otimes v' = \sum_{i \in I}r_i e_i \otimes \sum_{i\in I} s_i e_i = \sum_{i\in I} s_i e_i \otimes \sum_{i \in I}r_i e_i = v' \otimes v$ then if we look at a particular element of the sum on LHS and RHS, namely $r_ie_i \otimes s_je_j = s_je_j\otimes r_i e_i$ then we can send the $r_i$ to the other side or do some manipulation of that sort and obtain the desired result. I know this argument is not rigorous at all, so I am having a hard time doing it more rigorous (if this is a good approach) or actually attack this problem efficiently. I was wondering if this would be the right approach, like working with basis elements and so on or if there is some better way to look at this problem. Perhaps some use of universal property for modules would be helpful? Any help or suggestion with this problem is highly appreciated! Thanks so much!","In Dummit and Foote problem 12 of section 10.4, I need to show that if $V$ is some vector space over a field $F$ and $v,v'$ are nonzero elements of $V$, supposing we have that $v \otimes v' = v' \otimes v$ then this implies that $v = av'$ for some $a \in F$. I was trying to consider some basis $\mathcal{B} = \{e_i\}_{i\in I}$ for the vector space $V$, show that we can write $v$ and $v'$ as linear combinations of this basis elements and then argue that since we have $v \otimes v' = \sum_{i \in I}r_i e_i \otimes \sum_{i\in I} s_i e_i = \sum_{i\in I} s_i e_i \otimes \sum_{i \in I}r_i e_i = v' \otimes v$ then if we look at a particular element of the sum on LHS and RHS, namely $r_ie_i \otimes s_je_j = s_je_j\otimes r_i e_i$ then we can send the $r_i$ to the other side or do some manipulation of that sort and obtain the desired result. I know this argument is not rigorous at all, so I am having a hard time doing it more rigorous (if this is a good approach) or actually attack this problem efficiently. I was wondering if this would be the right approach, like working with basis elements and so on or if there is some better way to look at this problem. Perhaps some use of universal property for modules would be helpful? Any help or suggestion with this problem is highly appreciated! Thanks so much!",,"['abstract-algebra', 'modules', 'tensor-products']"
32,Quotient of a quotient ring,Quotient of a quotient ring,,"I'm trying to understand the quotient $\Bbb Z[\sqrt{47}]/(2, 1 +\sqrt{47})$, in order to find out whether or not $(2, 1 + \sqrt{47})$ is a prime ideal in $\Bbb Z[\sqrt{47}]$. I think it is but my calculations seem to be giving me something that doesn't agree with this, so either it isn't a prime ideal or I'm doing something very wrong. Since $\Bbb Z[\sqrt{47}] \cong \Bbb Z[X]/(X^2 - 47)$, I'm writing $$ (\Bbb Z[X]/(X^2 - 47))/(2, X^2 - 2X - 46) $$ where $X^2 - 2X - 46$ is a monic irreducible polynomial with $1 + \sqrt{47}$ as a root. Is this step correct? If so, then I think it follows that $$ (\Bbb F_2[X]/(X^2))/(\overline{X^2 - 2X - 46}) $$ where $\overline{.}$ denotes the reduction map. The problem is, this is the zero-ideal in $\Bbb F_2[X]/(X^2)$, and this finite ring is not an integral domain, so the conclusion is that $(2, 1 + \sqrt{47})$ is not a prime ideal. Which steps here (if any) are correct? Is any body able to show me how they might do it if it is not correct?","I'm trying to understand the quotient $\Bbb Z[\sqrt{47}]/(2, 1 +\sqrt{47})$, in order to find out whether or not $(2, 1 + \sqrt{47})$ is a prime ideal in $\Bbb Z[\sqrt{47}]$. I think it is but my calculations seem to be giving me something that doesn't agree with this, so either it isn't a prime ideal or I'm doing something very wrong. Since $\Bbb Z[\sqrt{47}] \cong \Bbb Z[X]/(X^2 - 47)$, I'm writing $$ (\Bbb Z[X]/(X^2 - 47))/(2, X^2 - 2X - 46) $$ where $X^2 - 2X - 46$ is a monic irreducible polynomial with $1 + \sqrt{47}$ as a root. Is this step correct? If so, then I think it follows that $$ (\Bbb F_2[X]/(X^2))/(\overline{X^2 - 2X - 46}) $$ where $\overline{.}$ denotes the reduction map. The problem is, this is the zero-ideal in $\Bbb F_2[X]/(X^2)$, and this finite ring is not an integral domain, so the conclusion is that $(2, 1 + \sqrt{47})$ is not a prime ideal. Which steps here (if any) are correct? Is any body able to show me how they might do it if it is not correct?",,"['abstract-algebra', 'polynomials', 'ring-theory', 'ideals']"
33,Middle Cancellation in Groups,Middle Cancellation in Groups,,"For a, b, c, d, x elements of a group G. If ab = cd does that mean that axb = cxd? What if ab = cd only in this one instance, does the equality still hold?","For a, b, c, d, x elements of a group G. If ab = cd does that mean that axb = cxd? What if ab = cd only in this one instance, does the equality still hold?",,['abstract-algebra']
34,How to derive this curious approximation to the cube root of $a + bi$?,How to derive this curious approximation to the cube root of ?,a + bi,"In this Wikipedia article in Portuguese is given the following approximation for the cube root of a complex number $ c = a + bi$: $$ \sqrt[3]{c} \approx k\left ( \frac{29z^3 + 261z^2 + 255z + 22}{7z^3 + 165z^2 +324z+71} \right ) $$ where $ \sqrt[3]{c} = \sqrt[3]{k^3z},\quad $ $ \forall k, z\in \mathbb{C}, z \neq  0 $ This gives an approximation, say $p_1$, and then you can use this approximation as a new value of $k$ to get another better approximation $p_2$, and so on. The question is: how this approximation can be derived? I think that it's an application of Newton's method or some truncated series, but I don't know the details. Also, what precise is the approximation? Does converges to the cube root for any initial values?","In this Wikipedia article in Portuguese is given the following approximation for the cube root of a complex number $ c = a + bi$: $$ \sqrt[3]{c} \approx k\left ( \frac{29z^3 + 261z^2 + 255z + 22}{7z^3 + 165z^2 +324z+71} \right ) $$ where $ \sqrt[3]{c} = \sqrt[3]{k^3z},\quad $ $ \forall k, z\in \mathbb{C}, z \neq  0 $ This gives an approximation, say $p_1$, and then you can use this approximation as a new value of $k$ to get another better approximation $p_2$, and so on. The question is: how this approximation can be derived? I think that it's an application of Newton's method or some truncated series, but I don't know the details. Also, what precise is the approximation? Does converges to the cube root for any initial values?",,"['abstract-algebra', 'complex-analysis']"
35,Why is the Skyscraper Sheaf defined as it is?,Why is the Skyscraper Sheaf defined as it is?,,"In Vakil's Foundations of Algebraic Geometry he defines the skyscraper sheaf as follows. Let $X$ be a topological space with $p\in X$.  Let $S$ be a set and $\{e\}$ any singleton set.  Let $i_p:p\to X$ be the inclusion then define: $$ i_{p,_{*}S}(U) = \begin{cases} S,& p\in U\\ \{e\},& p\not\in U \end{cases} $$ My question is, is there any reason why we use a single-element set $\{e\}$? As far as I can tell, we still get a sheaf if we use an arbitrary set  in place of $\{e\}$.  Why don't we use, say, the empty set instead?","In Vakil's Foundations of Algebraic Geometry he defines the skyscraper sheaf as follows. Let $X$ be a topological space with $p\in X$.  Let $S$ be a set and $\{e\}$ any singleton set.  Let $i_p:p\to X$ be the inclusion then define: $$ i_{p,_{*}S}(U) = \begin{cases} S,& p\in U\\ \{e\},& p\not\in U \end{cases} $$ My question is, is there any reason why we use a single-element set $\{e\}$? As far as I can tell, we still get a sheaf if we use an arbitrary set  in place of $\{e\}$.  Why don't we use, say, the empty set instead?",,"['abstract-algebra', 'sheaf-theory']"
36,How to show simply that a field is a vector space over any of its subfields?,How to show simply that a field is a vector space over any of its subfields?,,"I know that any field is a vector space over itself, see e.g. here -- Prove that the field F is a vector space over itself. Is there a correspondingly simple argument showing that this is the case for any subfield? For example, $\mathbb{C}$ can be thought of as a real vector space. The result in general is true, e.g. here https://cims.nyu.edu/~kiryl/Algebra/Section_5.1--Extension%20Fields.pdf To me the result is ""clear"" or ""obvious"", but when I go about trying to prove it, I cannot think of anything less clunky than to verify all of the scalar multiplication vector space axioms one by one (the additive axioms follow immediately from the fact that any field is an abelian group under addition), which means that I don't really gain anything from the observation. The example I have in mind is the field of rational functions over a projective curve $V(P) \subset \mathbb{CP}^2$; I want to argue that since all complex scalars $\lambda$ are polynomials hence rational functions on $V(P)$, that the field of rational functions is not only a vector space over itself, but also a complex vector space. Then given any divisor $D$, I can show that $L(D)$ is a complex vector space just by showing that it is closed under addition and scalar multiplication.","I know that any field is a vector space over itself, see e.g. here -- Prove that the field F is a vector space over itself. Is there a correspondingly simple argument showing that this is the case for any subfield? For example, $\mathbb{C}$ can be thought of as a real vector space. The result in general is true, e.g. here https://cims.nyu.edu/~kiryl/Algebra/Section_5.1--Extension%20Fields.pdf To me the result is ""clear"" or ""obvious"", but when I go about trying to prove it, I cannot think of anything less clunky than to verify all of the scalar multiplication vector space axioms one by one (the additive axioms follow immediately from the fact that any field is an abelian group under addition), which means that I don't really gain anything from the observation. The example I have in mind is the field of rational functions over a projective curve $V(P) \subset \mathbb{CP}^2$; I want to argue that since all complex scalars $\lambda$ are polynomials hence rational functions on $V(P)$, that the field of rational functions is not only a vector space over itself, but also a complex vector space. Then given any divisor $D$, I can show that $L(D)$ is a complex vector space just by showing that it is closed under addition and scalar multiplication.",,['abstract-algebra']
37,What exactly is the purpose of a coset?,What exactly is the purpose of a coset?,,"I'm having trouble understanding the motivation behind a coset. The book I'm using (A Book of Abstract Algebra) states: Let G be a group, and H a subgroup of G. For any element a in G, the symbol aH denotes the set of all products ah, as a remains fixed and h ranges over H. aH is called the left coset of H in G. It goes on to say the same about right cosets. I understand this definition (or I think I do), but what does this accomplish? Is it saying that given a subgroup H, you can generate a group G using cosets? Thank you in advance.","I'm having trouble understanding the motivation behind a coset. The book I'm using (A Book of Abstract Algebra) states: Let G be a group, and H a subgroup of G. For any element a in G, the symbol aH denotes the set of all products ah, as a remains fixed and h ranges over H. aH is called the left coset of H in G. It goes on to say the same about right cosets. I understand this definition (or I think I do), but what does this accomplish? Is it saying that given a subgroup H, you can generate a group G using cosets? Thank you in advance.",,"['abstract-algebra', 'group-theory', 'soft-question']"
38,"Coprime polynomials in $k[x,y]$ are also coprime in $k(y)[x]$",Coprime polynomials in  are also coprime in,"k[x,y] k(y)[x]","Let $f,g \in k[x,y]$ be polynomials with no common factor. Prove that when viewed as elements of $k(y)[x]$ they still do not have a common factor. Say we have $f=\sum a_{ij}x^iy^j,\ g=\sum b_{ij}x^i y^j$, and $h=\sum h_i(y) x^i \in k(y)[x]$ satisfies both $h \mid f$ and $h\mid g$. Hence $f = hp$ for $p = \sum p_{i}(y)x^i \in k(y)[x]$ and similarly for $g=hq$. The claim is noted here . However I don't understand the argument implied there, of multiplying by the lcm of the denominators of all terms in $h$ and all terms in the divisors $p,q$: we get a relation of the form $f \cdot \text{lcm(complicated polynomial w(y))}=hpw \in k[x,y]$, what is the common factor in $k[x,y]$ of $f,g $ here? (A concrete example will probably help.) Where do we use that $k(y)[x]=\mathbb{F}[x]$ is a euclidean domain and in particular a PID?","Let $f,g \in k[x,y]$ be polynomials with no common factor. Prove that when viewed as elements of $k(y)[x]$ they still do not have a common factor. Say we have $f=\sum a_{ij}x^iy^j,\ g=\sum b_{ij}x^i y^j$, and $h=\sum h_i(y) x^i \in k(y)[x]$ satisfies both $h \mid f$ and $h\mid g$. Hence $f = hp$ for $p = \sum p_{i}(y)x^i \in k(y)[x]$ and similarly for $g=hq$. The claim is noted here . However I don't understand the argument implied there, of multiplying by the lcm of the denominators of all terms in $h$ and all terms in the divisors $p,q$: we get a relation of the form $f \cdot \text{lcm(complicated polynomial w(y))}=hpw \in k[x,y]$, what is the common factor in $k[x,y]$ of $f,g $ here? (A concrete example will probably help.) Where do we use that $k(y)[x]=\mathbb{F}[x]$ is a euclidean domain and in particular a PID?",,"['abstract-algebra', 'polynomials', 'least-common-multiple']"
39,Show that $\Bbb R^{2n+1}$ is not a division algebra over $\Bbb R$ for $n>0$,Show that  is not a division algebra over  for,\Bbb R^{2n+1} \Bbb R n>0,"This is an exercise from Hatcher's Algebraic Topology (exercise 2.B.8). Here is the problem statement: Show that, for $n>0$ , $\Bbb R^{2n+1}$ is not a division algebra over $\Bbb R$ by showing that if it were, then for nonzero $a \in \Bbb R^{2n+1}$ the map $S^{2n} \to S^{2n}$ defined by $x \mapsto \dfrac{ax}{|ax|}$ would be homotopic to $x \mapsto -\dfrac{ax}{|ax|}$ , but these maps have different degrees. I found a duplicate of this question here where a suggestion was to find a path between $a$ and $-a$ that does not pass through $0$ . I am struggling to do this and I would appreciate if someone could give me some direction here. I don't have much experience with algebras or division algebras, so I may be missing something simple. I am also somewhat confused about how to find the degrees of the maps $x \mapsto {ax\over |ax|}$ and $x \mapsto {-ax\over |ax|}$ . As I understand it a map $S^{n} \to S^{n}$ induces a homomorphism $H_n(S^n) \to H_n(S^n)$ , and $H_n(S^n)$ is isomorphic to $\Bbb Z$ , so the induced homomorphism is of the form $x \mapsto nx$ for some $n \in \Bbb Z$ . Then that $n$ is the degree of the original map. I'm not sure how to actually find the induced maps on homology in this problem (or if there is another way to find the degree). Edit: As anomaly has pointed out, the second part of my question is simpler than I thought.","This is an exercise from Hatcher's Algebraic Topology (exercise 2.B.8). Here is the problem statement: Show that, for , is not a division algebra over by showing that if it were, then for nonzero the map defined by would be homotopic to , but these maps have different degrees. I found a duplicate of this question here where a suggestion was to find a path between and that does not pass through . I am struggling to do this and I would appreciate if someone could give me some direction here. I don't have much experience with algebras or division algebras, so I may be missing something simple. I am also somewhat confused about how to find the degrees of the maps and . As I understand it a map induces a homomorphism , and is isomorphic to , so the induced homomorphism is of the form for some . Then that is the degree of the original map. I'm not sure how to actually find the induced maps on homology in this problem (or if there is another way to find the degree). Edit: As anomaly has pointed out, the second part of my question is simpler than I thought.",n>0 \Bbb R^{2n+1} \Bbb R a \in \Bbb R^{2n+1} S^{2n} \to S^{2n} x \mapsto \dfrac{ax}{|ax|} x \mapsto -\dfrac{ax}{|ax|} a -a 0 x \mapsto {ax\over |ax|} x \mapsto {-ax\over |ax|} S^{n} \to S^{n} H_n(S^n) \to H_n(S^n) H_n(S^n) \Bbb Z x \mapsto nx n \in \Bbb Z n,"['abstract-algebra', 'algebraic-topology', 'algebras', 'division-algebras']"
40,Prove that $f(x)$ is irreducible iff its reciprocal polynomial $f^*(x)$ is irreducible.,Prove that  is irreducible iff its reciprocal polynomial  is irreducible.,f(x) f^*(x),"This is what I'm trying to prove: Let $f(x)\in\mathbb{Q}[x]$ and $\deg(f(x))>1$ . Prove that $f(x)$ is irreducible in $\mathbb{Q}[x]$ iff its reciprocal polynomial $f^*(x)$ is irreducible in $\mathbb{Q}[x]$ . Note: The reciprocal polynomial $f^*(x)=x^nf(1/x) \in \mathbb{Q}[x]$ , where $n=\deg f$ . So my thoughts are to prove the contrapositive, i.e. $f^*(x)$ is reducible iff $f(x)$ is reducible. So to prove the ( $\Rightarrow$ ) direction I assume that $f^*(x)=g(x)h(x)$ , so I get that $g(x)h(x)=x^nf(1/x)$ which implies $f(1/x)=(1/x^n)g(x)h(x)$ . I want to say this somehow makes $f(x)$ reducible but I am unable to proceed as $f(1/x)\notin \mathbb{Q}[x] $ . I thought about substituting $y=1/x$ , which gives $f(y)=y^ng(1/y)h(1/y)$ , but I am unable to show that this is irreducible in $\mathbb{Q}[y]$ . If I could, then it would be irreducible in $\mathbb{Q}[x]$ since $\mathbb{Q}[y]\cong \mathbb{Q}[x]$ Any suggestions or hints will be appreciated.","This is what I'm trying to prove: Let and . Prove that is irreducible in iff its reciprocal polynomial is irreducible in . Note: The reciprocal polynomial , where . So my thoughts are to prove the contrapositive, i.e. is reducible iff is reducible. So to prove the ( ) direction I assume that , so I get that which implies . I want to say this somehow makes reducible but I am unable to proceed as . I thought about substituting , which gives , but I am unable to show that this is irreducible in . If I could, then it would be irreducible in since Any suggestions or hints will be appreciated.",f(x)\in\mathbb{Q}[x] \deg(f(x))>1 f(x) \mathbb{Q}[x] f^*(x) \mathbb{Q}[x] f^*(x)=x^nf(1/x) \in \mathbb{Q}[x] n=\deg f f^*(x) f(x) \Rightarrow f^*(x)=g(x)h(x) g(x)h(x)=x^nf(1/x) f(1/x)=(1/x^n)g(x)h(x) f(x) f(1/x)\notin \mathbb{Q}[x]  y=1/x f(y)=y^ng(1/y)h(1/y) \mathbb{Q}[y] \mathbb{Q}[x] \mathbb{Q}[y]\cong \mathbb{Q}[x],"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
41,"$\Bbb Z_m \times \Bbb Z_n$ isomorphic to $\Bbb Z_{\operatorname{lcm}(m,n)}\times \Bbb Z_{\gcd(m,n)}$",isomorphic to,"\Bbb Z_m \times \Bbb Z_n \Bbb Z_{\operatorname{lcm}(m,n)}\times \Bbb Z_{\gcd(m,n)}","I want to show the title. Let $\Bbb Z_{\operatorname{lcm}(m,n)}=\langle x\rangle$, $\Bbb Z_{\gcd(m,n)}=\langle y\rangle$, $\Bbb Z_m=\langle z\rangle$, $\Bbb Z_n=\langle w\rangle$ and $d=\gcd(m,n)$. I use the function $f\colon \Bbb Z_{\operatorname{lcm}(m,n)}\times \Bbb Z_{\gcd(m,n)}\to \Bbb Z_m\times \Bbb Z_n$ such that $f(x,1)=(z,w)$ and $f(1,y)=(z^{m/d}, w^{n/d})$ This is homomorphism, but I can't show it is injective or surjective to show that it is bijective. Help me!","I want to show the title. Let $\Bbb Z_{\operatorname{lcm}(m,n)}=\langle x\rangle$, $\Bbb Z_{\gcd(m,n)}=\langle y\rangle$, $\Bbb Z_m=\langle z\rangle$, $\Bbb Z_n=\langle w\rangle$ and $d=\gcd(m,n)$. I use the function $f\colon \Bbb Z_{\operatorname{lcm}(m,n)}\times \Bbb Z_{\gcd(m,n)}\to \Bbb Z_m\times \Bbb Z_n$ such that $f(x,1)=(z,w)$ and $f(1,y)=(z^{m/d}, w^{n/d})$ This is homomorphism, but I can't show it is injective or surjective to show that it is bijective. Help me!",,"['abstract-algebra', 'group-theory', 'elementary-number-theory']"
42,$p(x)$ irreducible polynomial $\iff J=\langle p(x)\rangle$ is a maximal ideal in $K[x]$ $\iff K[x]/J$ is a field,irreducible polynomial  is a maximal ideal in   is a field,p(x) \iff J=\langle p(x)\rangle K[x] \iff K[x]/J,"Given a field $K$ and $p(x)\in K[x]$ . Then the following conditions are equivalent: a) $p(x)$ is irreducible over $K$ . b) $J = \langle p(x)\rangle$ is a maximal ideal in $K[x]$ . c) $K[x]/J$ is a field, where $J=\langle p(x)\rangle$ . My book proves $a\implies b$ as follows: Since the degree of $p(x)$ is greater than or equal to $1$ , we have that $J\neq K[x]$ (why the degree?). If $I=\langle h(x)\rangle$ is an ideal of $K[x]$ such that $I$ contains $J$ , let's prove that $J$ contains $I$ . For that look at the following: $$p(x)\in \langle p(x)\rangle \subseteq \langle h(x)\rangle \implies p(x) = g(x)h(x)$$ for some $g\in K[x]$ . Since $p(x)$ is irreducible, we must have: $$g(x) = a\in K - \{0\}$$ or $$h(x) = b\in K - \{0\}.$$ If $g(x)=a\neq 0$ we have $h(x) = a^{-1}\cdot p(x)\in J$ (because $h(x)$ is now $p(x)$ with some constant), and therefore $I$ is contained in $J$ , so we have $I=J$ , therefore $J$ is maximal ideal of $K[x]$ . Now, an unexpected proof of $a\implies c$ appears in the middle of this proof. If we consider the case $h(x)=b\neq 0$ we have ( and this part I didn't understand ) $I = \langle h(x)\rangle = K[x]$ and this proves $a\implies c$ . I think I didn't understand this part because I'm having trouble visualizing $K[x]/J$ where $J = \langle p(x)\rangle$ . In another example, the book actually computes the quotient $A/I$ where $A = \mathbb{R}[x]$ and $I = \langle x^2+1\rangle$ . It uses the theorem above to say that $L = A/I$ is a field since $x^2+1$ is irreducible over $K[x]$ (shouldn't it be $\mathbb{R}[x]$ ?). Then, it computes $L$ as follows: $$p(x) = q(x)(x^2+1)+r(x)$$ where $r(x) = bx+a$ . It then takes $p(x)\bmod I$ which gives the following: $p(x) = q(x)(x^2+1)+r(x)=r(x)= bx + a$ (everything above is with that bar at the top but I don't know how to write it in LaTeX). Then, the book simply says that $L = \{bx + a: a,b \in \mathbb{R}\}$ . Why is it that $L$ is the $p(x) \bmod I$ ? What am I missing about quotient rings? Can somebody clarify it for me?","Given a field and . Then the following conditions are equivalent: a) is irreducible over . b) is a maximal ideal in . c) is a field, where . My book proves as follows: Since the degree of is greater than or equal to , we have that (why the degree?). If is an ideal of such that contains , let's prove that contains . For that look at the following: for some . Since is irreducible, we must have: or If we have (because is now with some constant), and therefore is contained in , so we have , therefore is maximal ideal of . Now, an unexpected proof of appears in the middle of this proof. If we consider the case we have ( and this part I didn't understand ) and this proves . I think I didn't understand this part because I'm having trouble visualizing where . In another example, the book actually computes the quotient where and . It uses the theorem above to say that is a field since is irreducible over (shouldn't it be ?). Then, it computes as follows: where . It then takes which gives the following: (everything above is with that bar at the top but I don't know how to write it in LaTeX). Then, the book simply says that . Why is it that is the ? What am I missing about quotient rings? Can somebody clarify it for me?","K p(x)\in K[x] p(x) K J = \langle p(x)\rangle K[x] K[x]/J J=\langle p(x)\rangle a\implies b p(x) 1 J\neq K[x] I=\langle h(x)\rangle K[x] I J J I p(x)\in \langle p(x)\rangle \subseteq \langle h(x)\rangle \implies p(x) = g(x)h(x) g\in K[x] p(x) g(x) = a\in K - \{0\} h(x) = b\in K - \{0\}. g(x)=a\neq 0 h(x) = a^{-1}\cdot p(x)\in J h(x) p(x) I J I=J J K[x] a\implies c h(x)=b\neq 0 I = \langle h(x)\rangle = K[x] a\implies c K[x]/J J = \langle p(x)\rangle A/I A = \mathbb{R}[x] I = \langle x^2+1\rangle L = A/I x^2+1 K[x] \mathbb{R}[x] L p(x) = q(x)(x^2+1)+r(x) r(x) = bx+a p(x)\bmod I p(x) = q(x)(x^2+1)+r(x)=r(x)= bx + a L = \{bx + a: a,b \in \mathbb{R}\} L p(x) \bmod I","['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
43,"In $S_{4}$, find a Sylow 2-subgroup and a Sylow 3-subgroup.","In , find a Sylow 2-subgroup and a Sylow 3-subgroup.",S_{4},"In $S_{4}$ , find a Sylow 2-subgroup and a Sylow 3-subgroup. With everyone's comments and inputs, I have outlined the following answer: We have $|S_{4}|= 24 = 2^{3}3$ . If $P$ is a Sylow $2$ -subgroup then $|P| = 2^3$ , and if $K$ is a Sylow $3$ -subgroup then $|K|=3$ . So we need to find subgroups of $S_4$ of order $8$ and order $3$ . For the subgroup of order $3$ , since it is of prime order, it is cyclic, thus we need to find an element of $S_4$ of order $3$ .  So any $3$ -cycle of $S_4$ will suffice.  As a concrete example, we will call $K = \langle(1\ 2\ 3)\rangle$ . Now we must find $P$ . Since $|P| = 8$ , every element in $P$ must have order $1$ , $2$ or $4$ .  We can choose a dihedral subgroup $D_4$ to be $P$ . For example $$P= \lbrace e, (1234), (13)(24), (1432),(24) ,(14)(23), (13), (12)(34)\rbrace.$$","In , find a Sylow 2-subgroup and a Sylow 3-subgroup. With everyone's comments and inputs, I have outlined the following answer: We have . If is a Sylow -subgroup then , and if is a Sylow -subgroup then . So we need to find subgroups of of order and order . For the subgroup of order , since it is of prime order, it is cyclic, thus we need to find an element of of order .  So any -cycle of will suffice.  As a concrete example, we will call . Now we must find . Since , every element in must have order , or .  We can choose a dihedral subgroup to be . For example","S_{4} |S_{4}|= 24 = 2^{3}3 P 2 |P| = 2^3 K 3 |K|=3 S_4 8 3 3 S_4 3 3 S_4 K = \langle(1\ 2\ 3)\rangle P |P| = 8 P 1 2 4 D_4 P P= \lbrace e, (1234), (13)(24), (1432),(24) ,(14)(23), (13), (12)(34)\rbrace.","['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups', 'sylow-theory']"
44,Notation/definition problem for commutative binary operation,Notation/definition problem for commutative binary operation,,"I'm trying to describe/define the commutative binary operation on a three-element set which when the operands are the same, gives the same element and when they are different gives the element which is not an operand. So for $\{a,b,c\}$, if we denote the operation $\#$: $$a\#a=a\quad \text{and}  \quad a\#b=c \quad\text(etc.)$$ I suppose I could just define it case-by-case, but the notion of ""the one that's either both of these or neither of these"" is so intuitive and natural that that seems like a clunky solution. It also wouldn't be particularly useful to me. I want to describe it with a notation/definition which will lend itself to arguments regarding member-wise application of the operation on tuples i.e. $$(x_1,y_1,z_1...)\mathbf{\#}(x_2,y_2,z_2,...)=(x_1\#x_2,y_1\#y_2,z_1\#z_2,...)$$ In particular I want to discuss the properties of tuple-chains which, through repeated application of the member-wise operation, transform any given tuple into another. That is, I want to find out, given tuples $\mathbf {s}=(x_s,y_s,z_s,...)$ and $\mathbf{d}=(x_d,y_d,z_d,...)$, and considering $\mathbf{\#}$ to be right-associative, what can I say about the tuples in the sequence $\mathbf{C}=\mathbf{t_0},\mathbf{t_1},..\mathbf{t_n}$ if I know that$$\mathbf{t_0\#t_1\#}...\mathbf{\#t_n\#s}=\mathbf{d}$$ I'm not currently looking for help with that question, as I want to explore it myself for a while, and it's pretty open-ended anyway, but I have some ideas I'm setting out to prove, and I'm having trouble developing a formal definition of $\#$ that is useful in this context. Any Ideas?","I'm trying to describe/define the commutative binary operation on a three-element set which when the operands are the same, gives the same element and when they are different gives the element which is not an operand. So for $\{a,b,c\}$, if we denote the operation $\#$: $$a\#a=a\quad \text{and}  \quad a\#b=c \quad\text(etc.)$$ I suppose I could just define it case-by-case, but the notion of ""the one that's either both of these or neither of these"" is so intuitive and natural that that seems like a clunky solution. It also wouldn't be particularly useful to me. I want to describe it with a notation/definition which will lend itself to arguments regarding member-wise application of the operation on tuples i.e. $$(x_1,y_1,z_1...)\mathbf{\#}(x_2,y_2,z_2,...)=(x_1\#x_2,y_1\#y_2,z_1\#z_2,...)$$ In particular I want to discuss the properties of tuple-chains which, through repeated application of the member-wise operation, transform any given tuple into another. That is, I want to find out, given tuples $\mathbf {s}=(x_s,y_s,z_s,...)$ and $\mathbf{d}=(x_d,y_d,z_d,...)$, and considering $\mathbf{\#}$ to be right-associative, what can I say about the tuples in the sequence $\mathbf{C}=\mathbf{t_0},\mathbf{t_1},..\mathbf{t_n}$ if I know that$$\mathbf{t_0\#t_1\#}...\mathbf{\#t_n\#s}=\mathbf{d}$$ I'm not currently looking for help with that question, as I want to explore it myself for a while, and it's pretty open-ended anyway, but I have some ideas I'm setting out to prove, and I'm having trouble developing a formal definition of $\#$ that is useful in this context. Any Ideas?",,"['abstract-algebra', 'notation', 'definition']"
45,Are these quotient modules isomorphic?,Are these quotient modules isomorphic?,,"Let $K$ be an algebraic number field and $\mathcal{O}_K$ its ring of integers. For a non-zero ideal $\mathfrak{a}$ of $\mathcal{O}_K$ and an element $c \in \mathcal{O}_K \setminus \{0\}$ I wonder whether we always have an isomorphism    $$ \mathfrak{a} / c \mathfrak{a} \cong \mathcal{O}_K / (c) $$   as $\mathcal{O}_K$-modules. Using the inverse (fractional) ideal $\mathfrak{a}^{-1}$, one could naïvely ""calculate"" $$ \mathfrak{a} / (c) \mathfrak{a} \cong \mathfrak{a}\mathfrak{a}^{-1} / (c)\mathfrak{a}\mathfrak{a}^{-1} = \mathcal{O}_K / (c)\mathcal{O}_K = \mathcal{O}_K / (c). $$ But (again) I do not know how to justify the isomorphism. Additonal question Is it easier to somehow only show $ [\mathfrak{a} : c \mathfrak{a}] = [\mathcal{O}_K : (c)]$ ? This would help me, too :-).","Let $K$ be an algebraic number field and $\mathcal{O}_K$ its ring of integers. For a non-zero ideal $\mathfrak{a}$ of $\mathcal{O}_K$ and an element $c \in \mathcal{O}_K \setminus \{0\}$ I wonder whether we always have an isomorphism    $$ \mathfrak{a} / c \mathfrak{a} \cong \mathcal{O}_K / (c) $$   as $\mathcal{O}_K$-modules. Using the inverse (fractional) ideal $\mathfrak{a}^{-1}$, one could naïvely ""calculate"" $$ \mathfrak{a} / (c) \mathfrak{a} \cong \mathfrak{a}\mathfrak{a}^{-1} / (c)\mathfrak{a}\mathfrak{a}^{-1} = \mathcal{O}_K / (c)\mathcal{O}_K = \mathcal{O}_K / (c). $$ But (again) I do not know how to justify the isomorphism. Additonal question Is it easier to somehow only show $ [\mathfrak{a} : c \mathfrak{a}] = [\mathcal{O}_K : (c)]$ ? This would help me, too :-).",,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory', 'dedekind-domain']"
46,"Given $K(\alpha)/K$ and $K(\beta)/K$ abelian extensions, prove that $K(\alpha + \beta)/K$ is an abelian extension.","Given  and  abelian extensions, prove that  is an abelian extension.",K(\alpha)/K K(\beta)/K K(\alpha + \beta)/K,"Problem: Let $K(\alpha)/K$ and $K(\beta)/K$ algebraic field extensions so that their respective Galois groups are abelian. Prove that the Galois group of the field extension $K(\alpha + \beta)/K$ is also abelian. My attempt: I've tried considering the towers $$K(\alpha,\beta)/K(\alpha)/K \qquad K(\alpha,\beta)/K(\beta)/K$$ Are somehow related to $$K(\alpha,\beta)/K(\alpha+\beta)/K \qquad K(\alpha,\beta)/K(\alpha - \beta)/K$$ But I don't know how to relate this to the fact that the quotient is abelian or whether this statement is true or not.",Problem: Let and algebraic field extensions so that their respective Galois groups are abelian. Prove that the Galois group of the field extension is also abelian. My attempt: I've tried considering the towers Are somehow related to But I don't know how to relate this to the fact that the quotient is abelian or whether this statement is true or not.,"K(\alpha)/K K(\beta)/K K(\alpha + \beta)/K K(\alpha,\beta)/K(\alpha)/K \qquad K(\alpha,\beta)/K(\beta)/K K(\alpha,\beta)/K(\alpha+\beta)/K \qquad K(\alpha,\beta)/K(\alpha - \beta)/K","['abstract-algebra', 'field-theory', 'galois-theory', 'abelian-groups', 'extension-field']"
47,Showing these prime ideals are principal,Showing these prime ideals are principal,,"Let $K=\mathbb{Q}(\theta)$ be a number field where $\theta$ has minimal polynomial $x^3-9x-6$. I had to factorise the ideals $(2)$ and $(3)$ into prime ideals, for which I got $(2) = (2,\theta)(2,\theta +1)^2$ and $(3) = (3,\theta)^3$ by using Dedekind's criterion. Then I am to show these prime ideals are principal. I'm a bit stuck at this point. The best I can think to do is to choose some element I might believe generates the whole ideal and show that we can obtain the generators from it. I've had a few guesses for only $(2,\theta)$ and I can't manage to get there. I imagine there is a better way to do this than to simply strike it lucky with a good guess. Is there a better way to proceed in finding a generator, or maybe some other method of showing the ideals are principal?","Let $K=\mathbb{Q}(\theta)$ be a number field where $\theta$ has minimal polynomial $x^3-9x-6$. I had to factorise the ideals $(2)$ and $(3)$ into prime ideals, for which I got $(2) = (2,\theta)(2,\theta +1)^2$ and $(3) = (3,\theta)^3$ by using Dedekind's criterion. Then I am to show these prime ideals are principal. I'm a bit stuck at this point. The best I can think to do is to choose some element I might believe generates the whole ideal and show that we can obtain the generators from it. I've had a few guesses for only $(2,\theta)$ and I can't manage to get there. I imagine there is a better way to do this than to simply strike it lucky with a good guess. Is there a better way to proceed in finding a generator, or maybe some other method of showing the ideals are principal?",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
48,Characteristic of a ring: intuitive explanation,Characteristic of a ring: intuitive explanation,,"I know the following definition of characteristic of a ring: it is the smallest positive $n$ such that $$\underbrace{a+\cdots+a}_{n \text{ summands}} = 0$$ for every element a of the ring, if $n$ exists, otherwise it is zero. However, I don't understand what is the ""intuitive"" meaning of this. Could you give a physical analogy of anything that may help to see what it is.","I know the following definition of characteristic of a ring: it is the smallest positive $n$ such that $$\underbrace{a+\cdots+a}_{n \text{ summands}} = 0$$ for every element a of the ring, if $n$ exists, otherwise it is zero. However, I don't understand what is the ""intuitive"" meaning of this. Could you give a physical analogy of anything that may help to see what it is.",,"['abstract-algebra', 'ring-theory', 'soft-question', 'physics']"
49,Using the properites of normal subgroups to show that two elements commute,Using the properites of normal subgroups to show that two elements commute,,"$Question - $ Let $N, H$ be normal subgroups of a group $G$ such that $N\cap H = \{e_G\}$. Show that, for all $g\in N$ and $h\in H$, $gh=hg$. If $N, H$ are normal subgroups, I know that $aN = Na, aH = Ha$ for each $a\in G$. I tried to write $gh$ = $g.e_G.h$, but I don't think this can help me. I also know that for each $a\in G$ we have $a^{-1}Na = N, a^{-1}Ha = H$, so I wrote $gh = g.a.a^{-1}.g = g.a.e_G.a^{-1}.g$, but I think this can't help me as well. I'd appreciate if someone could help me!","$Question - $ Let $N, H$ be normal subgroups of a group $G$ such that $N\cap H = \{e_G\}$. Show that, for all $g\in N$ and $h\in H$, $gh=hg$. If $N, H$ are normal subgroups, I know that $aN = Na, aH = Ha$ for each $a\in G$. I tried to write $gh$ = $g.e_G.h$, but I don't think this can help me. I also know that for each $a\in G$ we have $a^{-1}Na = N, a^{-1}Ha = H$, so I wrote $gh = g.a.a^{-1}.g = g.a.e_G.a^{-1}.g$, but I think this can't help me as well. I'd appreciate if someone could help me!",,['abstract-algebra']
50,Describing integral closure of quadratic number fields,Describing integral closure of quadratic number fields,,I'm facing the following problem. Let $p$ be a prime and $ K=\mathbb{Q}(\sqrt{p}) $. I'm trying to find the integral closure of $ \mathbb{Z} $ in $ K $. I don't really know where to start. I've managed to prove that $ \mathbb{Z}[\sqrt{p}] $ is in the integral closure and I'm almost sure $ \mathbb{Q} $ is not. I can't think of a systematic way to approach this. I would appreciate any help.,I'm facing the following problem. Let $p$ be a prime and $ K=\mathbb{Q}(\sqrt{p}) $. I'm trying to find the integral closure of $ \mathbb{Z} $ in $ K $. I don't really know where to start. I've managed to prove that $ \mathbb{Z}[\sqrt{p}] $ is in the integral closure and I'm almost sure $ \mathbb{Q} $ is not. I can't think of a systematic way to approach this. I would appreciate any help.,,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory']"
51,Is {0} a free module?,Is {0} a free module?,,"Is $\{0\}$ a free module (over any ring $R$) ? A free module is isomorphic to $R^n$, but is $n=0$ allowed? Alternatively, a free module is defined to have a set of linearly independent generating sets, in this case it would be $0$ but I recall by definition in the case of vector spaces that $0$, by itself, is dependent. However $\{0\}$ is torsion free as the only torsion element is $0$. (I know torsion free does not imply free, but this fact seemed relevant to me). The thing is, there is a result I need to use which has free modules among the hypothesis and I am too lazy now to check if the proof of that result is ok for $\{0\}$.","Is $\{0\}$ a free module (over any ring $R$) ? A free module is isomorphic to $R^n$, but is $n=0$ allowed? Alternatively, a free module is defined to have a set of linearly independent generating sets, in this case it would be $0$ but I recall by definition in the case of vector spaces that $0$, by itself, is dependent. However $\{0\}$ is torsion free as the only torsion element is $0$. (I know torsion free does not imply free, but this fact seemed relevant to me). The thing is, there is a result I need to use which has free modules among the hypothesis and I am too lazy now to check if the proof of that result is ok for $\{0\}$.",,"['abstract-algebra', 'modules']"
52,Are varieties cocomplete?,Are varieties cocomplete?,,"Consider a variety $\mathcal{V}$ in a sense of universal algebra, i.e. algebras of some fixed signatures described by a set of identities. Then $\mathcal{V}$ can be thought of as a category with objects being the algebras and morphisms being algebra homomorphisms. The question is Is $\mathcal{V}$ cocomplete category, in general? Are there any (non-obvious) necessary/ sufficient condiions on $\mathcal{V}$ for this? This is probably something well-known, but I cannot find anything about it (maybe I am asking the question wrong somehow, possibly the different meanings of ""variety"" spoil the searches). And I honestly am not sure: It seems pretty obvious that it is complete (it is $\mathbb{HSP}$ of something, hence it has products and one can build the equalizers ""by hand"" from products and subalgebras) but I do not see any coproducts anywhere. I am also not so much familiar with ""weaker"" algebraic structures (semigroups, or even non-associative algebras) so that I could think of a counterexample. Thanks in advance for help. Additional question: What about injective objects/injective cogenerators in $\mathcal{V}$?","Consider a variety $\mathcal{V}$ in a sense of universal algebra, i.e. algebras of some fixed signatures described by a set of identities. Then $\mathcal{V}$ can be thought of as a category with objects being the algebras and morphisms being algebra homomorphisms. The question is Is $\mathcal{V}$ cocomplete category, in general? Are there any (non-obvious) necessary/ sufficient condiions on $\mathcal{V}$ for this? This is probably something well-known, but I cannot find anything about it (maybe I am asking the question wrong somehow, possibly the different meanings of ""variety"" spoil the searches). And I honestly am not sure: It seems pretty obvious that it is complete (it is $\mathbb{HSP}$ of something, hence it has products and one can build the equalizers ""by hand"" from products and subalgebras) but I do not see any coproducts anywhere. I am also not so much familiar with ""weaker"" algebraic structures (semigroups, or even non-associative algebras) so that I could think of a counterexample. Thanks in advance for help. Additional question: What about injective objects/injective cogenerators in $\mathcal{V}$?",,"['abstract-algebra', 'category-theory', 'universal-algebra']"
53,Subgroup of finitely generated abelian group is finitely generated,Subgroup of finitely generated abelian group is finitely generated,,"Call a group $G$ finitely generated if there is a finite subset $X \subseteq G$ with $G = \langle X \rangle$. Prove that every subgroup $S$ of a finitely generated abelian group $G$ is itself finitely generated. (This can be false if $G$ is not abelian.) Use induction on $n \geq 1$, where $X = \{a_1, \ldots ,a_n \}$. The inductive step should consider the quotient group $G/\langle  a_{n+1} \rangle$.","Call a group $G$ finitely generated if there is a finite subset $X \subseteq G$ with $G = \langle X \rangle$. Prove that every subgroup $S$ of a finitely generated abelian group $G$ is itself finitely generated. (This can be false if $G$ is not abelian.) Use induction on $n \geq 1$, where $X = \{a_1, \ldots ,a_n \}$. The inductive step should consider the quotient group $G/\langle  a_{n+1} \rangle$.",,"['abstract-algebra', 'group-theory', 'abelian-groups']"
54,"An infinite group $G$ and $\forall x\in G, x^n=e$",An infinite group  and,"G \forall x\in G, x^n=e","Let $G$ be an infinite group and $n\in \mathbb N$. If for any infinite subset $A$ of $G$ there is $a\in A$ such that $$a^n=e,~~~~(e=e_G)$$ then prove that for every element $x\in G$ we have $x^n=e$. This question was asked me and honestly I could not find any way to break it well. I worked on the order of an element $x$ to show that every element is of finite order but it seemed not to complete a solid approach. Thanks for the time!","Let $G$ be an infinite group and $n\in \mathbb N$. If for any infinite subset $A$ of $G$ there is $a\in A$ such that $$a^n=e,~~~~(e=e_G)$$ then prove that for every element $x\in G$ we have $x^n=e$. This question was asked me and honestly I could not find any way to break it well. I worked on the order of an element $x$ to show that every element is of finite order but it seemed not to complete a solid approach. Thanks for the time!",,"['abstract-algebra', 'group-theory']"
55,When is a power of an $m$-cycle also an $m$-cycle?,When is a power of an -cycle also an -cycle?,m m,"I have a question taken from Abstract Algebra by Dummit and Foote (pg. 33, q.11): Let $\sigma\in S_{n}$ be an $m$ -cycle. Show that $\sigma^{k}$ is   also an $m$ -cycle iff $\gcd(k,m)=1$ . My efforts: By considering a few examples I believe that $\sigma^{k}$ decomposition is a multiplication of cycles where each cycle is of length $\frac{m}{\gcd(k,m)}$ I have tried proving this by showing that $$ \frac{m}{\gcd(k,m)}+k\equiv_{m}1 $$ which shows that $\sigma^{k}$ maps $\frac{m}{\gcd(k,m)}$ back to $1$ hence is the cycle length (at least for the first cycle in the decomposition, but I imagine that proving similar claim for the other circles can be done analogy) . I have tried showing this by writing the equivalence as $$ m\mid\frac{m}{\gcd(k,m)}+k-1 $$ and trying to manipulate the above expression to see the divisibility, but I haven't managed to do so.","I have a question taken from Abstract Algebra by Dummit and Foote (pg. 33, q.11): Let be an -cycle. Show that is   also an -cycle iff . My efforts: By considering a few examples I believe that decomposition is a multiplication of cycles where each cycle is of length I have tried proving this by showing that which shows that maps back to hence is the cycle length (at least for the first cycle in the decomposition, but I imagine that proving similar claim for the other circles can be done analogy) . I have tried showing this by writing the equivalence as and trying to manipulate the above expression to see the divisibility, but I haven't managed to do so.","\sigma\in S_{n} m \sigma^{k} m \gcd(k,m)=1 \sigma^{k} \frac{m}{\gcd(k,m)} 
\frac{m}{\gcd(k,m)}+k\equiv_{m}1
 \sigma^{k} \frac{m}{\gcd(k,m)} 1 
m\mid\frac{m}{\gcd(k,m)}+k-1
","['abstract-algebra', 'group-theory', 'permutations', 'permutation-cycles']"
56,A field with characteristic $0$ contains $\mathbb Q$,A field with characteristic  contains,0 \mathbb Q,"To prove that a field $F$ with characteristic $0$ contains $\mathbb Q$ , the following lemma is used. Lemma: Let $R$ be a ring with unity. If the characteristic of $R$ is $0$ , then $R$ contains a subring isomorphic to $\mathbb Z$ . Solution: Let $S$ be a subring of $F$ that is $\approx \Bbb Z$ . Let $T = \{ab^{-1}~~|~~a,b \in S, b \neq 0\}$ . Then it is stated that $T \approx \mathbb Q$ . If we take a map $: ab^{-1} \rightarrow a/b$ . Then, clearly, $T \approx \mathbb Q$ under multiplication. Does isomorphism under addition need to be shown as well? My book further states that the intersection of the subfields of a field is a subfield (called the prime subfield), so there exists a subfield (EDIT: and a prime subfield) isomorphic to the rationals. I don't clearly understand this paragraph, did they just try to show that $T$ is a subfield of $F$ ? The subfield test says that a subset $A$ of a field $F$ forms a subfield iff $(i) ~~a-b \in A ~~\forall~~a,b \in A$ $(ii)~~ab^{-1} \in A ~~\forall~~a,b \in A$ But, we don't know if $ef^{-1}-gh^{-1} = e (f^{-1}-e^{-1}gh^{-1})\in T?~~|~~ e,f,g,h \in S?$ . I don't think $T$ should be a sub field. What is the book trying to say? Thank you for your help ..","To prove that a field with characteristic contains , the following lemma is used. Lemma: Let be a ring with unity. If the characteristic of is , then contains a subring isomorphic to . Solution: Let be a subring of that is . Let . Then it is stated that . If we take a map . Then, clearly, under multiplication. Does isomorphism under addition need to be shown as well? My book further states that the intersection of the subfields of a field is a subfield (called the prime subfield), so there exists a subfield (EDIT: and a prime subfield) isomorphic to the rationals. I don't clearly understand this paragraph, did they just try to show that is a subfield of ? The subfield test says that a subset of a field forms a subfield iff But, we don't know if . I don't think should be a sub field. What is the book trying to say? Thank you for your help ..","F 0 \mathbb Q R R 0 R \mathbb Z S F \approx \Bbb Z T = \{ab^{-1}~~|~~a,b \in S, b \neq 0\} T \approx \mathbb Q : ab^{-1} \rightarrow a/b T \approx \mathbb Q T F A F (i) ~~a-b \in A ~~\forall~~a,b \in A (ii)~~ab^{-1} \in A ~~\forall~~a,b \in A ef^{-1}-gh^{-1} = e (f^{-1}-e^{-1}gh^{-1})\in T?~~|~~ e,f,g,h \in S? T","['abstract-algebra', 'ring-theory']"
57,Is $\mathbb{Z}[\sqrt{2} + \sqrt{3}]$ integrally closed?,Is  integrally closed?,\mathbb{Z}[\sqrt{2} + \sqrt{3}],"Is $\mathbb{Z}[\sqrt{2} + \sqrt{3}]$ integrally closed? (Or could it have a relation to another domain like $\mathbb{Z}[\sqrt{-3}]$ does with $\mathbb{Z}[\omega]$?) Also, is it UFD? What are its units? I have never read about this domain in any book, though i did read try to read one book with very general techniques that could theoretically be applied here. reason I even known about this domain is because their was a question on this website last month asking if it was closed under multiplication. A lot of people fell into the trap of thinking that its quadratic but its not, myself included. Their was a whole bunch of snarky comments from people who know its quartic (is that the right term? not quadratic but only one person explained the difference -- he did a great job answering the question and explaining the misconception, and maybe from his answer one can derive the answers to the questions I'm asking today, but I'm not sure how if that's the case.","Is $\mathbb{Z}[\sqrt{2} + \sqrt{3}]$ integrally closed? (Or could it have a relation to another domain like $\mathbb{Z}[\sqrt{-3}]$ does with $\mathbb{Z}[\omega]$?) Also, is it UFD? What are its units? I have never read about this domain in any book, though i did read try to read one book with very general techniques that could theoretically be applied here. reason I even known about this domain is because their was a question on this website last month asking if it was closed under multiplication. A lot of people fell into the trap of thinking that its quadratic but its not, myself included. Their was a whole bunch of snarky comments from people who know its quartic (is that the right term? not quadratic but only one person explained the difference -- he did a great job answering the question and explaining the misconception, and maybe from his answer one can derive the answers to the questions I'm asking today, but I'm not sure how if that's the case.",,['abstract-algebra']
58,Quotient group $\mathbb Z^n/\ \text{im}(A)$ [duplicate],Quotient group  [duplicate],\mathbb Z^n/\ \text{im}(A),This question already has an answer here : Question on determinants of matrices changing between integer matrices [duplicate] (1 answer) Closed 5 years ago . Let $A$ be an $n \times n$ matrix with integer coefficients and nonzero determinant. Can we say something about $ \mathbb{Z}^n /\ \text{im}( \phi )$ (here $\phi : v \mapsto Av$ )? This problem has arised as I was solving some problem in homology theory.,This question already has an answer here : Question on determinants of matrices changing between integer matrices [duplicate] (1 answer) Closed 5 years ago . Let $A$ be an $n \times n$ matrix with integer coefficients and nonzero determinant. Can we say something about $ \mathbb{Z}^n /\ \text{im}( \phi )$ (here $\phi : v \mapsto Av$ )? This problem has arised as I was solving some problem in homology theory.,,"['abstract-algebra', 'matrices', 'group-theory', 'abelian-groups']"
59,How to think of quotients of polynomial rings,How to think of quotients of polynomial rings,,"I'm studying for an algebra midterm and I'm really just having a hard time wrapping my head around quotients of polynomial rings, especially ones where the ideal being quotiented by is something non-principle (i.e an ideal of the form $(x^2 - 2, 3$) in an appropriate polynomial ring). For example this question Set of Ideals of a Polynomial Ring makes use of the fact that $$\mathbb{Z}[x]/(2,x^3 + 1) \cong \mathbb{Z}_2[x]/(x^3 + 1)$$ to arrive at a solution, but this isomorphism doesn't at all seem obvious to me (hopefully because I'm just not thinking about the quotient in the correct way). Another example, also a question from dummit and foote ($\S 9.1, 13$), is ''Prove that the rings $F[x,y]/(y^2 - x)$ and $F[x,y](y^2 - x^2)$ are not isomorphic for any field $F$ ''. Really I don't even see an obvious direction to proceed, but I think, on a more fundamental level, I really just have no intuitive notion as to what those fields even look like. So I was hoping for some helpful way(s) of thinking about these spaces. Any insight would be much appreciated.","I'm studying for an algebra midterm and I'm really just having a hard time wrapping my head around quotients of polynomial rings, especially ones where the ideal being quotiented by is something non-principle (i.e an ideal of the form $(x^2 - 2, 3$) in an appropriate polynomial ring). For example this question Set of Ideals of a Polynomial Ring makes use of the fact that $$\mathbb{Z}[x]/(2,x^3 + 1) \cong \mathbb{Z}_2[x]/(x^3 + 1)$$ to arrive at a solution, but this isomorphism doesn't at all seem obvious to me (hopefully because I'm just not thinking about the quotient in the correct way). Another example, also a question from dummit and foote ($\S 9.1, 13$), is ''Prove that the rings $F[x,y]/(y^2 - x)$ and $F[x,y](y^2 - x^2)$ are not isomorphic for any field $F$ ''. Really I don't even see an obvious direction to proceed, but I think, on a more fundamental level, I really just have no intuitive notion as to what those fields even look like. So I was hoping for some helpful way(s) of thinking about these spaces. Any insight would be much appreciated.",,"['abstract-algebra', 'ring-theory']"
60,$S_6$ contains a subgroup $H$ that is isomorphic to $S_5$ but not conjugate to $S_5$,contains a subgroup  that is isomorphic to  but not conjugate to,S_6 H S_5 S_5,"$$H = \langle (1 2 3 4), (3 4 5 6)\rangle $$ I'm kind of lost. I see that $\\S_5$ is embedded in $\\S_6$ in the form of a pentad. Then the action of $H$ on the pentad induces a group homomorphism from $H$ into the permutations of the synthemes, which are isomorphic to $\\S_5$. But I'm not sure how to show that the homomorphism is an isomorphism, and that is not conjugate in $\\S_5$ Let me know if I need to clarify anything.","$$H = \langle (1 2 3 4), (3 4 5 6)\rangle $$ I'm kind of lost. I see that $\\S_5$ is embedded in $\\S_6$ in the form of a pentad. Then the action of $H$ on the pentad induces a group homomorphism from $H$ into the permutations of the synthemes, which are isomorphic to $\\S_5$. But I'm not sure how to show that the homomorphism is an isomorphism, and that is not conjugate in $\\S_5$ Let me know if I need to clarify anything.",,"['abstract-algebra', 'group-theory']"
61,Localization at a maximal ideal and quotients.,Localization at a maximal ideal and quotients.,,"If we have a commutative ring $R$ and a maximal ideal $m$, then is    $m/m^2$ isomorphic to $m_m/m^2_m$? Thx.","If we have a commutative ring $R$ and a maximal ideal $m$, then is    $m/m^2$ isomorphic to $m_m/m^2_m$? Thx.",,"['abstract-algebra', 'commutative-algebra', 'ideals']"
62,Why do we have to do the same things to both sides of an equation?,Why do we have to do the same things to both sides of an equation?,,"Forgive me in advanced if this is a trivial question. This convention makes perfect sense to me intuitively, but is there any rigorous underpinning to it? I'm beginning to read through an abstract algebra textbook, and soon after establishing what a ring is, it all of the sudden added to both sides of the equation to prove a(0)=(0)a=0. It seemed a little premature to me.","Forgive me in advanced if this is a trivial question. This convention makes perfect sense to me intuitively, but is there any rigorous underpinning to it? I'm beginning to read through an abstract algebra textbook, and soon after establishing what a ring is, it all of the sudden added to both sides of the equation to prove a(0)=(0)a=0. It seemed a little premature to me.",,"['abstract-algebra', 'algebra-precalculus']"
63,No constant polynomials are irreducible?,No constant polynomials are irreducible?,,No constant polynomials are irreducible? What does it mean? Is it because constant polynomials are units?,No constant polynomials are irreducible? What does it mean? Is it because constant polynomials are units?,,['abstract-algebra']
64,Show $\mathbb{Z}_2 \cong \mathbb{D}_2$,Show,\mathbb{Z}_2 \cong \mathbb{D}_2,"Hello once again everyone. A homework exercise I'm working on is asking me to show $\mathbb{Z}_2 \cong \mathbb{D}_2$ (the Dihedral group). I know that $\mathbb{Z}_2$ is cyclic and generated by $1$, but I've tried show that $\mathbb{D}_2$ with elements $(1,2)$ and $(2,1) $ is generated by $(1,2)$ or $(2,1)$ under addition or multiplication, but I can't find out how to show this in order to establish an isomorphism between the $\mathbb{Z}_2$ and $\mathbb{D}_2$. Can someone perhaps provide me a hint? As always, thank you so much for your support.","Hello once again everyone. A homework exercise I'm working on is asking me to show $\mathbb{Z}_2 \cong \mathbb{D}_2$ (the Dihedral group). I know that $\mathbb{Z}_2$ is cyclic and generated by $1$, but I've tried show that $\mathbb{D}_2$ with elements $(1,2)$ and $(2,1) $ is generated by $(1,2)$ or $(2,1)$ under addition or multiplication, but I can't find out how to show this in order to establish an isomorphism between the $\mathbb{Z}_2$ and $\mathbb{D}_2$. Can someone perhaps provide me a hint? As always, thank you so much for your support.",,"['abstract-algebra', 'group-theory']"
65,Number of Abelian Groups of Order 256,Number of Abelian Groups of Order 256,,"I am trying to find the number of abelian groups of order 256. Is the following correct? We may write $256=2^8$ we then know that this may be represented in the form: $C_{n_1}\times.....\times C_{n_s}$ where $n_i|n_{i+1}$ and $n_1.....n_s=|G|$ So this may be represented as: $C_2\times C_2\times C_2\times C_2\times C_2\times C_2\times C_2\times C_2, C_2\times C_2\times C_2\times C_2 \times C_2\times C_2 \times C_4.....$ Which I belive comes to 22 groups if you keep going in this way, is there a faster way? Cheers","I am trying to find the number of abelian groups of order 256. Is the following correct? We may write $256=2^8$ we then know that this may be represented in the form: $C_{n_1}\times.....\times C_{n_s}$ where $n_i|n_{i+1}$ and $n_1.....n_s=|G|$ So this may be represented as: $C_2\times C_2\times C_2\times C_2\times C_2\times C_2\times C_2\times C_2, C_2\times C_2\times C_2\times C_2 \times C_2\times C_2 \times C_4.....$ Which I belive comes to 22 groups if you keep going in this way, is there a faster way? Cheers",,"['abstract-algebra', 'group-theory', 'abelian-groups']"
66,"$G$ is a nonabelian finite group, then $|Z(G)|\leq \frac{1}{4}|G|$","is a nonabelian finite group, then",G |Z(G)|\leq \frac{1}{4}|G|,"If $G$ is a nonabelian finite group, then I have to show that $|Z(G)|\leq\frac{1}{4}|G|$, where $|Z(G)|$ denotes the center of group. I have got this question through random search on net. I am finding it difficult to solve. Moreover, I am not sure whether is it true or not. Thanks for help.","If $G$ is a nonabelian finite group, then I have to show that $|Z(G)|\leq\frac{1}{4}|G|$, where $|Z(G)|$ denotes the center of group. I have got this question through random search on net. I am finding it difficult to solve. Moreover, I am not sure whether is it true or not. Thanks for help.",,"['abstract-algebra', 'group-theory']"
67,"Finitely generated abelian groups: If $G \times K$ is isomorphic to $H \times K$, then $G$ is isomorphic to $H$.","Finitely generated abelian groups: If  is isomorphic to , then  is isomorphic to .",G \times K H \times K G H,"Let $G,H,K$ be finitely generated abelian groups.  If $G \times  K$ is isomorphic to $H \times K$, then $G$ is isomorphic to $H$. What I have thought is that fundamental theorem of abelian groups can be used, but I don't know how to do next.  Please help me.","Let $G,H,K$ be finitely generated abelian groups.  If $G \times  K$ is isomorphic to $H \times K$, then $G$ is isomorphic to $H$. What I have thought is that fundamental theorem of abelian groups can be used, but I don't know how to do next.  Please help me.",,"['abstract-algebra', 'group-theory', 'abelian-groups']"
68,Is $(R_S)_{\mathfrak{p}R_S}$ isomorphic to $R_{\mathfrak{p}}$?,Is  isomorphic to ?,(R_S)_{\mathfrak{p}R_S} R_{\mathfrak{p}},"Let $R$ be an integral domain, let $S$ be a multiplicative subset of $R$, not intersecting $\mathfrak{p}$, where $\mathfrak{p}$ is a prime ideal of $R$. Hence $\mathfrak{p}R_S$ (the ideal generated by $\mathfrak{p}$ in $R_S$) is a prime ideal of $R_S$, and we can take localization $(R_S)_{\mathfrak{p}R_S}$. I'm asking if these two rings: $(R_S)_{\mathfrak{p}R_S}$ and $R_{\mathfrak{p}}$ are isomorphic or not. I think there is something canonical here, hence i tried to show the existence of an iso only doing general considerations, not dealing with elements and their (possibly complicated) expressions. I used universal property of localization, in this sense: since $S\subseteq R - \mathfrak{p}$, then $R_S$ is contained in $R_{\mathfrak{p}}$ (both subrings of field of fractions of $R$), and let $i$ be the natural inclusion of $R_S$ in $R_{\mathfrak{p}}$. Clearly, $i$ sends elements of $S$ in invertible elements of $R_{\mathfrak{p}}$. Now, let $\phi$ be the canonical morphism from $R_S$ to its localization $(R_S)_{\mathfrak{p}R_S}$. By universal property, there is exactly one morphism of rings , say $h$, from $(R_S)_{\mathfrak{p}R_S}$ to $R_{\mathfrak{p}}$ such that $h\circ\phi=i$, which is obviously injective. Now, is $h$ also surjective?","Let $R$ be an integral domain, let $S$ be a multiplicative subset of $R$, not intersecting $\mathfrak{p}$, where $\mathfrak{p}$ is a prime ideal of $R$. Hence $\mathfrak{p}R_S$ (the ideal generated by $\mathfrak{p}$ in $R_S$) is a prime ideal of $R_S$, and we can take localization $(R_S)_{\mathfrak{p}R_S}$. I'm asking if these two rings: $(R_S)_{\mathfrak{p}R_S}$ and $R_{\mathfrak{p}}$ are isomorphic or not. I think there is something canonical here, hence i tried to show the existence of an iso only doing general considerations, not dealing with elements and their (possibly complicated) expressions. I used universal property of localization, in this sense: since $S\subseteq R - \mathfrak{p}$, then $R_S$ is contained in $R_{\mathfrak{p}}$ (both subrings of field of fractions of $R$), and let $i$ be the natural inclusion of $R_S$ in $R_{\mathfrak{p}}$. Clearly, $i$ sends elements of $S$ in invertible elements of $R_{\mathfrak{p}}$. Now, let $\phi$ be the canonical morphism from $R_S$ to its localization $(R_S)_{\mathfrak{p}R_S}$. By universal property, there is exactly one morphism of rings , say $h$, from $(R_S)_{\mathfrak{p}R_S}$ to $R_{\mathfrak{p}}$ such that $h\circ\phi=i$, which is obviously injective. Now, is $h$ also surjective?",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
69,Adjoint of forgetful functor between category of vector spaces and category of abelian groups,Adjoint of forgetful functor between category of vector spaces and category of abelian groups,,"I've just found out about the forgetful functor between the category of vector spaces and the category of abelian groups . It maps a vector space to it's additive abelian group. My question is, is there an adjoint of this forgetful functor, and if so what is it? If we considered the forgetful functor between the category of vector spaces and the category of sets that forgets all structure, I think the adjoint functor would take a set and create a generic free vector space generated by the elements of the set. However, when forgetting only to the level of an abelian group, there still retains some additional structure, so I don't think it's that simple. For example, just by looking at the additive group, you know $v$ and $v+v$ are related by the scalar multiplication $v+v=2v$. Similarly, one could deduce that rational combinations like $6v$ and $9v$ are related through multiplication, since there would exist an element $3v$ that can be added to itself several times to create both. On the other hand, just by looking at the additive structure, I think there is no way to tell that $v$ and $\pi v$ were once related since $\pi$ is irrational.","I've just found out about the forgetful functor between the category of vector spaces and the category of abelian groups . It maps a vector space to it's additive abelian group. My question is, is there an adjoint of this forgetful functor, and if so what is it? If we considered the forgetful functor between the category of vector spaces and the category of sets that forgets all structure, I think the adjoint functor would take a set and create a generic free vector space generated by the elements of the set. However, when forgetting only to the level of an abelian group, there still retains some additional structure, so I don't think it's that simple. For example, just by looking at the additive group, you know $v$ and $v+v$ are related by the scalar multiplication $v+v=2v$. Similarly, one could deduce that rational combinations like $6v$ and $9v$ are related through multiplication, since there would exist an element $3v$ that can be added to itself several times to create both. On the other hand, just by looking at the additive structure, I think there is no way to tell that $v$ and $\pi v$ were once related since $\pi$ is irrational.",,"['abstract-algebra', 'category-theory', 'vector-spaces', 'abelian-groups']"
70,A group of order $108$ has a proper normal subgroup of order $\geq 6$.,A group of order  has a proper normal subgroup of order .,108 \geq 6,"Problem : Let $G$ be a group of order $108 = 2^23^3$. Prove that $G$ has a proper normal subgroup of order $n \geq 6$. My attempt : From the Sylow theorems, if $n_3$ and $n_2$ denote the number of subgroups of order $27$ and $4$, respectively, in $G$, then $n_3 = 1$ or $4$, since $n_3 \equiv 1$ (mod $3$) and $n_3~|~2^2$, and $n_2 = 1, 3, 9$ or $27$, because $n_2~|~3^3$. Now, I don't know what else to do. I tried assuming $n_3 = 4$ and seeing if this leads to a contradiction, but I'm not even sure that this can't happen. I'm allowed to use only the basic results of group theory (the Sylow theorems being the most sophisticated tools). Any ideas are welcome; thanks!","Problem : Let $G$ be a group of order $108 = 2^23^3$. Prove that $G$ has a proper normal subgroup of order $n \geq 6$. My attempt : From the Sylow theorems, if $n_3$ and $n_2$ denote the number of subgroups of order $27$ and $4$, respectively, in $G$, then $n_3 = 1$ or $4$, since $n_3 \equiv 1$ (mod $3$) and $n_3~|~2^2$, and $n_2 = 1, 3, 9$ or $27$, because $n_2~|~3^3$. Now, I don't know what else to do. I tried assuming $n_3 = 4$ and seeing if this leads to a contradiction, but I'm not even sure that this can't happen. I'm allowed to use only the basic results of group theory (the Sylow theorems being the most sophisticated tools). Any ideas are welcome; thanks!",,"['abstract-algebra', 'group-theory']"
71,Derivations in a ring. What applications do they have outside algebra?,Derivations in a ring. What applications do they have outside algebra?,,"INTRODUCTION Let $R$ be any ring, possibly without unity. We call a function $d:R\longrightarrow R$ a derivation on $R$ if it satisfies the following conditions. $(1)$ It is an endomorphism of the additive abelian group of $R;$ $(2)$ For any $r,s\in R$ we have that $d(rs)=d(r)s+rd(s).$ I believe that when $R$ is an $A$-algebra for some commutative ring $A,$ we should also make the assumption that $d$ respects scalar multiplication, but I haven't seen the definition other than in the case of $R=K[x]$ and $A=K$ for a field $K.$ In this case, more specifically for $K=\mathbb C,$ it is standard knowledge that the standard derivative satisfies these conditions. Actually, we could just as well take the algebra of all holomorphic functions (instead of polynomials only) with the standard derivative. However, there are more such functions. It was a homework assignment in my field theory class to prove that for any $f\in K[x]$ there is exactly one derivation $d_f:K[x]\longrightarrow K[x]$ such that $d_f(x)=f.$ This is an easy exercise and one easily sees that in particular, for $K=\mathbb C,$ the standard derivative is just $d_1.$ QUESTION I understand that I will soon be shown how such derivations can be used in algebra, and I can't wait to see that. But since it's a field theory class, I'm quite sure that nothing will be said about their meaning outside algebra. This is why I'm writing this. I would like to know $(a)$ whether the derivations $d_f$ on $K[x]$ I wrote about above have any interpretation connected to actually differentiating something (which I understand involves taking limits in some metric space) and what the interpretation is. In particular, can we meaningfully assign a metric space to an arbitrary field? $(b)$ whether the general definition of a derivation on a ring or algebra has such an an interpretation.","INTRODUCTION Let $R$ be any ring, possibly without unity. We call a function $d:R\longrightarrow R$ a derivation on $R$ if it satisfies the following conditions. $(1)$ It is an endomorphism of the additive abelian group of $R;$ $(2)$ For any $r,s\in R$ we have that $d(rs)=d(r)s+rd(s).$ I believe that when $R$ is an $A$-algebra for some commutative ring $A,$ we should also make the assumption that $d$ respects scalar multiplication, but I haven't seen the definition other than in the case of $R=K[x]$ and $A=K$ for a field $K.$ In this case, more specifically for $K=\mathbb C,$ it is standard knowledge that the standard derivative satisfies these conditions. Actually, we could just as well take the algebra of all holomorphic functions (instead of polynomials only) with the standard derivative. However, there are more such functions. It was a homework assignment in my field theory class to prove that for any $f\in K[x]$ there is exactly one derivation $d_f:K[x]\longrightarrow K[x]$ such that $d_f(x)=f.$ This is an easy exercise and one easily sees that in particular, for $K=\mathbb C,$ the standard derivative is just $d_1.$ QUESTION I understand that I will soon be shown how such derivations can be used in algebra, and I can't wait to see that. But since it's a field theory class, I'm quite sure that nothing will be said about their meaning outside algebra. This is why I'm writing this. I would like to know $(a)$ whether the derivations $d_f$ on $K[x]$ I wrote about above have any interpretation connected to actually differentiating something (which I understand involves taking limits in some metric space) and what the interpretation is. In particular, can we meaningfully assign a metric space to an arbitrary field? $(b)$ whether the general definition of a derivation on a ring or algebra has such an an interpretation.",,"['abstract-algebra', 'soft-question']"
72,Show a rational function is transcendental over a field.,Show a rational function is transcendental over a field.,,"Let $u=\frac{x^3}{x+1}\in F(x)$, where $F(x)$ is the field of quotients of $F[x]$ ($F$ some field, $x$ an indeterminate over it). Show that $u$ is transcendental over $F$. This is an exercise in Hungerford. I'm having some trouble even grasping the concepts involved.  For instance, I know that if $v$ is transc. over $F$, then $F[v]\cong F[x]$. Or that if $v$ is transc. over $F$, then $F[v]\subsetneq F(v)$.  But I have no idea how to use this to my advantage. I'm also confused about what it even means for $u$ as above to be transc. over $F$.  Am I going to have to consider ""polynomials of polynomials""?","Let $u=\frac{x^3}{x+1}\in F(x)$, where $F(x)$ is the field of quotients of $F[x]$ ($F$ some field, $x$ an indeterminate over it). Show that $u$ is transcendental over $F$. This is an exercise in Hungerford. I'm having some trouble even grasping the concepts involved.  For instance, I know that if $v$ is transc. over $F$, then $F[v]\cong F[x]$. Or that if $v$ is transc. over $F$, then $F[v]\subsetneq F(v)$.  But I have no idea how to use this to my advantage. I'm also confused about what it even means for $u$ as above to be transc. over $F$.  Am I going to have to consider ""polynomials of polynomials""?",,['abstract-algebra']
73,Largest Normal subgroup,Largest Normal subgroup,,let $G$ be a finite group and $H$ any subgroup. $\psi_{H}$ be the left action of $G$ on $G/H$. It was asked to prove that the action is transitive and the kernel of $\psi_{H}$ is the 'largest normal subgroup'. It was easy to see that it is transitive. What does this 'largest normal subgroup' mean? Is it some thing anologous to maximal ideal definition? Or does it mean the normal subgroup with greatest cardinality? (note that $G$ need not be finite). Thanks Edit: By $G/H$ I mean the set of left cosets.,let $G$ be a finite group and $H$ any subgroup. $\psi_{H}$ be the left action of $G$ on $G/H$. It was asked to prove that the action is transitive and the kernel of $\psi_{H}$ is the 'largest normal subgroup'. It was easy to see that it is transitive. What does this 'largest normal subgroup' mean? Is it some thing anologous to maximal ideal definition? Or does it mean the normal subgroup with greatest cardinality? (note that $G$ need not be finite). Thanks Edit: By $G/H$ I mean the set of left cosets.,,"['abstract-algebra', 'group-theory']"
74,Bound for the rank of a nilpotent group,Bound for the rank of a nilpotent group,,Let $G$ be a nilpotent group generated by $d$ elements. Is there a function $r(d)$ such that every (necessarily finitely generated) subgroup $H$ of $G$ can be generated by at most $r(d)$ elements? Thanks in advance!,Let $G$ be a nilpotent group generated by $d$ elements. Is there a function $r(d)$ such that every (necessarily finitely generated) subgroup $H$ of $G$ can be generated by at most $r(d)$ elements? Thanks in advance!,,"['abstract-algebra', 'group-theory', 'finitely-generated', 'nilpotent-groups']"
75,Proving a relation is a mapping,Proving a relation is a mapping,,"In my abstract algebra book in the preliminary section there is a review of relations, mappings, etc. In the practice problems there are a few problems that check your understanding. Example 1: $$f(\frac{p}{q}) = \frac{3p}{3q}$$ This one is trivially a mapping because no matter what p, q you choose you will get a unique value from Q to Q. Example 2: $$f(\frac{p}{q}) = \frac{p + q}{q^2}$$ This one is not a mapping. A counter-example is $f(1/2) \neq f(2/4)$ . These both map to different values so this cannot be a mapping. But I am left kind of confused on the ""proof"" part. Showing a relation is not a mapping seems to be difficult because you have to search for a counter-example of a potentially hard problem. But proving something is a mapping seems extremely difficult. Is it possible to construct some kind of contradiction to prove it, or are you left sort of ""guessing and checking""? I am self learning at the moment so I don't really have a professor to ask this to.","In my abstract algebra book in the preliminary section there is a review of relations, mappings, etc. In the practice problems there are a few problems that check your understanding. Example 1: This one is trivially a mapping because no matter what p, q you choose you will get a unique value from Q to Q. Example 2: This one is not a mapping. A counter-example is . These both map to different values so this cannot be a mapping. But I am left kind of confused on the ""proof"" part. Showing a relation is not a mapping seems to be difficult because you have to search for a counter-example of a potentially hard problem. But proving something is a mapping seems extremely difficult. Is it possible to construct some kind of contradiction to prove it, or are you left sort of ""guessing and checking""? I am self learning at the moment so I don't really have a professor to ask this to.",f(\frac{p}{q}) = \frac{3p}{3q} f(\frac{p}{q}) = \frac{p + q}{q^2} f(1/2) \neq f(2/4),"['abstract-algebra', 'elementary-set-theory']"
76,Is there a reason the prime factors of $|M_{24}|$ are all one less than the factors of $24$?,Is there a reason the prime factors of  are all one less than the factors of ?,|M_{24}| 24,"Wikipedia says of the Mathieu group $M_{24}$ , a $5$ -transitive permutation group acting on $24$ points, $$ |M_{24}|= 2^{10}\cdot3^3\cdot5\cdot7\cdot11\cdot23. $$ The prime factors $2,3,5,7,11,23$ are all one less than one of the factors $3,4,6,8,12,24$ of $24$ . Am I crazy? Is this a coincidence, or does it admit an explanation? (I suppose it could be a combination of both: maybe the factors $11$ and $23$ for some $24$ -related reason and $2,3,5,7$ because of the law of small numbers, for example.)","Wikipedia says of the Mathieu group , a -transitive permutation group acting on points, The prime factors are all one less than one of the factors of . Am I crazy? Is this a coincidence, or does it admit an explanation? (I suppose it could be a combination of both: maybe the factors and for some -related reason and because of the law of small numbers, for example.)","M_{24} 5 24  |M_{24}|= 2^{10}\cdot3^3\cdot5\cdot7\cdot11\cdot23.  2,3,5,7,11,23 3,4,6,8,12,24 24 11 23 24 2,3,5,7","['abstract-algebra', 'group-theory', 'finite-groups']"
77,"If not associative, then what?","If not associative, then what?",,"Consider a binary operation $*$ acting from a set $X$ to itself. It's useful and standard to work with operations which are associative, such that $(a*b)*c = a*(b*c)$ . What about operations which are not associative? Is there any way to characterize all different possible types of such binary operations $*$ which are not associative? Eg. Can we say that if $*$ is not associative,  then it must instead satisfy one of set of other possible properties, depending on any other additional operations that we have on our set $X$ ? If we also add some additional structure to our set $X$ so that we can add elements together and multiply by scalars, it's standard to quantify the amount that two elements of $X$ commute with each other under $*$ by calculating the commutator $[a,b] = a*b - b*a$ . Is it ever useful to consider an 'associative commutator' $[abc] = (a*b)*c - a*(b*c)$ , for a given non-associative $*$ ? Finally, I know from Lie algebras that if $*$ anticommutes then it can be natural to consider a Jacobi identity $(a*b)*c = a*(b*c) - b*(a*c)$ Are there other natural extensions of associativity in different settings? Why do Lie algebras use this Jacobi identity and not for example $(a*b)*c = a*(b*c) + k b*(a*c)$ Where k is a scalar?","Consider a binary operation acting from a set to itself. It's useful and standard to work with operations which are associative, such that . What about operations which are not associative? Is there any way to characterize all different possible types of such binary operations which are not associative? Eg. Can we say that if is not associative,  then it must instead satisfy one of set of other possible properties, depending on any other additional operations that we have on our set ? If we also add some additional structure to our set so that we can add elements together and multiply by scalars, it's standard to quantify the amount that two elements of commute with each other under by calculating the commutator . Is it ever useful to consider an 'associative commutator' , for a given non-associative ? Finally, I know from Lie algebras that if anticommutes then it can be natural to consider a Jacobi identity Are there other natural extensions of associativity in different settings? Why do Lie algebras use this Jacobi identity and not for example Where k is a scalar?","* X (a*b)*c = a*(b*c) * * X X X * [a,b] = a*b - b*a [abc] = (a*b)*c - a*(b*c) * * (a*b)*c = a*(b*c) - b*(a*c) (a*b)*c = a*(b*c) + k b*(a*c)","['abstract-algebra', 'binary-operations', 'associativity', 'magma']"
78,Algebraic quaternion construction,Algebraic quaternion construction,,"Does there exist an algebraic construction of quaternion algebra such that the algebraic properties (such as associativity and distributivity) are immediately obvious? I am looking for something similar to how the complex numbers are constructed in Galois theory, as an extension of reals: $$\mathbb{C} \cong \mathbb{R}[x]/(x^2+1)$$ Apart from the algebraic properties, which are crystal clear in this construction, we also obtain that complex conjugation is an isomorphism without any explicit calculations. Is this possible for quaternions?","Does there exist an algebraic construction of quaternion algebra such that the algebraic properties (such as associativity and distributivity) are immediately obvious? I am looking for something similar to how the complex numbers are constructed in Galois theory, as an extension of reals: Apart from the algebraic properties, which are crystal clear in this construction, we also obtain that complex conjugation is an isomorphism without any explicit calculations. Is this possible for quaternions?",\mathbb{C} \cong \mathbb{R}[x]/(x^2+1),"['abstract-algebra', 'quaternions']"
79,Prove or disprove that $PQ = P + Q - I$ if $P$ and $Q$ are disjoint permutation matrices whose cycle lengths sum to $n.$,Prove or disprove that  if  and  are disjoint permutation matrices whose cycle lengths sum to,PQ = P + Q - I P Q n.,"Prove or disprove that if the matrices $P$ and $Q$ represent disjoint permutation cycles in $S_{n}$ with sum of cycle lengths equal to $n,$ then $PQ = P+Q-I$ . MY TRY: Let's start by an example. Let $P$ and $Q$ be the matrices corresponding to the respective permutations $p = (1 \, 2)$ and $q = (3 \, 4 \, 5)$ in cycle notation. We have that $$ P = \begin{pmatrix} 0 & 1 & 0 &  0 & 0 \\ 1 & 0 & 0 & 0 & 0 \\ 0 & 0 & 1 &  0 & 0\\  0 & 0 & 0 &  1 & 0\\ 0 & 0 & 0 &  0 & 1 \end{pmatrix} \text{ and } Q = \begin{pmatrix} 1 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0\\  0 & 0 & 0 & 0 & 1\\ 0 & 0 & 1 & 0 & 0 \end{pmatrix}. $$ It seems obvious that the matrix $PQ$ representing the permutation $pq = (1 \, 2)(3 \, 4 \, 5)$ will be $P+Q-I,$ as the ""untouched"" $1$ s in the matrices are simply canceled by $I$ and the touched $1$ s create the derangements. But isn't there some clear method to prove it? I am new to group theory. Please ask for clarifications in case of any discrepancies. Any hint will be a great help!","Prove or disprove that if the matrices and represent disjoint permutation cycles in with sum of cycle lengths equal to then . MY TRY: Let's start by an example. Let and be the matrices corresponding to the respective permutations and in cycle notation. We have that It seems obvious that the matrix representing the permutation will be as the ""untouched"" s in the matrices are simply canceled by and the touched s create the derangements. But isn't there some clear method to prove it? I am new to group theory. Please ask for clarifications in case of any discrepancies. Any hint will be a great help!","P Q S_{n} n, PQ = P+Q-I P Q p = (1 \, 2) q = (3 \, 4 \, 5) 
P =
\begin{pmatrix}
0 & 1 & 0 &  0 & 0 \\
1 & 0 & 0 & 0 & 0 \\
0 & 0 & 1 &  0 & 0\\ 
0 & 0 & 0 &  1 & 0\\
0 & 0 & 0 &  0 & 1
\end{pmatrix} \text{ and } Q = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 1 & 0\\ 
0 & 0 & 0 & 0 & 1\\
0 & 0 & 1 & 0 & 0
\end{pmatrix}.
 PQ pq = (1 \, 2)(3 \, 4 \, 5) P+Q-I, 1 I 1","['abstract-algebra', 'matrices', 'group-theory', 'permutations']"
80,How do I solve the quintic $n^5-m^4n+\frac{P}{2m}=0$ for $n$?,How do I solve the quintic  for ?,n^5-m^4n+\frac{P}{2m}=0 n,"I want to solve the following equation for $n$ in terms of $P$ and $m$ . $$n^5-m^4n+\frac{P}{2m}=0$$ I've bought and read many books, including ""Beyond The Quartic Equation"" but I've either missed something or do not have enough background or they said,  'such-and-such is used' but did not show how to use such-and-such to solve what I gather is a Bring-Jerrard quintic equation. I'm just a forklift mechanic 40 years removed from academia with a math hobby. I've been writing a math paper on Pythagorean triples for about $10$ years and, with help, I thought I was almost done with, ""On Finding Pythagorean Triples."" Then, I thought of a new way to find ""Triples On Demand"", i.e. how to find a Pythagorean triple, if it exists, given only the product $(P)$ of A,B,C. Using Euclid's formula: $$A=m^2-n^2\qquad B=2mn\qquad C=m^2+n^2$$ the product is $2m^5n-2mn^5=P$ . The best I've been able to understand is that the first equation above is in Bring-Jerrard form. The only thing I can add is that $P$ is a multiple of $60$ such as $60, 480, 780$ ,etc.  and $m$ will be one of a range of values to test where $\lfloor\sqrt[6]{P}\rfloor\le m\le \lceil\sqrt[5]{P}\space\rceil$ . How do I find the group and know if it is solvable? How does symmetry and/or permutations apply to this equation if at all? How does this equation correspond to an icosahedron? Is there a trig approach like the one here for a cubic equation? $$mn^3-m^3n+D=0$$ Almost any approach would be appreciated. I have so much to learn but none of the answers or comments have been useful so far – the approaches have been self-referential. How do I solve this quintic for $n$ if $P$ and $m$ are known? Update: I changed an $f$ in the OP to a $P$ so don't be confused by some of the comments. Also, I'm starting a bounty but not a large one for fear it will be wasted on the less-than-useful answers that have been upvoted already. Hurry, if you have an answer. I'd prefer to award the bounty rather than have it given away by an algorithm. A comment mentioned I should be more specific about what I want to do. I'm looking for inputs to Euclid's formula (shown above) and which we define here as $F(m,n)$ ––note capitol F. I want one-to-five functions $n_x=f_x(P,m )$ such that, given a number like $4200$ and, knowing $$\lfloor\sqrt[6]{4200}\rfloor=4\le m\le \lceil\sqrt[5]{4200}\space\rceil=6$$ I can discover $$f(4200,4)=3\Rightarrow F(4,3)=(7,24,25)\qquad f(4200,5)\notin\mathbb{N}\qquad f(4200,6)\notin\mathbb{N}$$ If an integer were not found for any of the $[5]$ solutions in the specified range of $m$ -values, then we would know that no Pythagorean triple exists for that value of $P=A\times B\times C$ . Now, I'm told, specific cases are needed before we can find a group. Here are the smallest sample equation values and the ""correct"" solution of $f(P,m)=n$ for each. $$n^5-16n+15=0\rightarrow f(60,2)=1\quad n^5-81n+80=0\rightarrow f(480,3)=1\quad n^5-81n+130=0\rightarrow f(780,3)=2\quad n^5-256n+255=0\rightarrow f(2040,4)=1\quad n^5-256n+480=0\rightarrow f(3840,4)=2\quad n^5-256n+525=0\rightarrow f(4200,4)=3\quad n^5-625n+624=0\rightarrow f(6240,5)=1\quad n^5-625n+1218=0\rightarrow f(12180,5)=2\quad n^5-625n+1476=0\rightarrow f(14760,5)=4\quad n^5-1296n+1295=0\rightarrow f(15540,6)=1\quad n^5-625n+1632=0\rightarrow f(16320,5)=3\quad n^5-1296n+2560=0\rightarrow f(30720,6)=2\quad n^5-2401n+2400=0\rightarrow f(33600,7)=1\quad n^5-1296n+3355=0\rightarrow f(40260,6)=5\quad n^5-1296n+3645=0\rightarrow f(43740,6)=3\quad n^5-1296n+4160=0\rightarrow f(49920,6)=4\quad n^5-4096n+4095=0\rightarrow f(65520,8)=1\quad$$ Are these sample equations enough to associate with a Galois group? Once we find the group, how do we proceed?","I want to solve the following equation for in terms of and . I've bought and read many books, including ""Beyond The Quartic Equation"" but I've either missed something or do not have enough background or they said,  'such-and-such is used' but did not show how to use such-and-such to solve what I gather is a Bring-Jerrard quintic equation. I'm just a forklift mechanic 40 years removed from academia with a math hobby. I've been writing a math paper on Pythagorean triples for about years and, with help, I thought I was almost done with, ""On Finding Pythagorean Triples."" Then, I thought of a new way to find ""Triples On Demand"", i.e. how to find a Pythagorean triple, if it exists, given only the product of A,B,C. Using Euclid's formula: the product is . The best I've been able to understand is that the first equation above is in Bring-Jerrard form. The only thing I can add is that is a multiple of such as ,etc.  and will be one of a range of values to test where . How do I find the group and know if it is solvable? How does symmetry and/or permutations apply to this equation if at all? How does this equation correspond to an icosahedron? Is there a trig approach like the one here for a cubic equation? Almost any approach would be appreciated. I have so much to learn but none of the answers or comments have been useful so far – the approaches have been self-referential. How do I solve this quintic for if and are known? Update: I changed an in the OP to a so don't be confused by some of the comments. Also, I'm starting a bounty but not a large one for fear it will be wasted on the less-than-useful answers that have been upvoted already. Hurry, if you have an answer. I'd prefer to award the bounty rather than have it given away by an algorithm. A comment mentioned I should be more specific about what I want to do. I'm looking for inputs to Euclid's formula (shown above) and which we define here as ––note capitol F. I want one-to-five functions such that, given a number like and, knowing I can discover If an integer were not found for any of the solutions in the specified range of -values, then we would know that no Pythagorean triple exists for that value of . Now, I'm told, specific cases are needed before we can find a group. Here are the smallest sample equation values and the ""correct"" solution of for each. Are these sample equations enough to associate with a Galois group? Once we find the group, how do we proceed?","n P m n^5-m^4n+\frac{P}{2m}=0 10 (P) A=m^2-n^2\qquad B=2mn\qquad C=m^2+n^2 2m^5n-2mn^5=P P 60 60, 480, 780 m \lfloor\sqrt[6]{P}\rfloor\le m\le \lceil\sqrt[5]{P}\space\rceil mn^3-m^3n+D=0 n P m f P F(m,n) n_x=f_x(P,m ) 4200 \lfloor\sqrt[6]{4200}\rfloor=4\le m\le \lceil\sqrt[5]{4200}\space\rceil=6 f(4200,4)=3\Rightarrow F(4,3)=(7,24,25)\qquad f(4200,5)\notin\mathbb{N}\qquad f(4200,6)\notin\mathbb{N} [5] m P=A\times B\times C f(P,m)=n n^5-16n+15=0\rightarrow f(60,2)=1\quad
n^5-81n+80=0\rightarrow f(480,3)=1\quad
n^5-81n+130=0\rightarrow f(780,3)=2\quad
n^5-256n+255=0\rightarrow f(2040,4)=1\quad
n^5-256n+480=0\rightarrow f(3840,4)=2\quad
n^5-256n+525=0\rightarrow f(4200,4)=3\quad
n^5-625n+624=0\rightarrow f(6240,5)=1\quad
n^5-625n+1218=0\rightarrow f(12180,5)=2\quad
n^5-625n+1476=0\rightarrow f(14760,5)=4\quad
n^5-1296n+1295=0\rightarrow f(15540,6)=1\quad
n^5-625n+1632=0\rightarrow f(16320,5)=3\quad
n^5-1296n+2560=0\rightarrow f(30720,6)=2\quad
n^5-2401n+2400=0\rightarrow f(33600,7)=1\quad
n^5-1296n+3355=0\rightarrow f(40260,6)=5\quad
n^5-1296n+3645=0\rightarrow f(43740,6)=3\quad
n^5-1296n+4160=0\rightarrow f(49920,6)=4\quad
n^5-4096n+4095=0\rightarrow f(65520,8)=1\quad","['abstract-algebra', 'trigonometry', 'galois-theory', 'solvable-groups', 'quintics']"
81,"Should the isomorphism theorems be seen as an ""interface"" between algebra and category theory?","Should the isomorphism theorems be seen as an ""interface"" between algebra and category theory?",,"My first instinct when I thought about algebra in category theory, was to try to ""generalize the isomorphism theorems in category theory"". So I tried to prove the generalization of ""the image of a group homomorphism is isomorphic to the quotient group generated by its kernel"". But then I found out that in category subobjects are actually defined in terms of monomorphisms, which for the category Grp is essentially implicitly using that isomorphism theorem. So is it correct that I shouldn't be trying to prove the isomorphism theorems in category theory? Is it correct that instead, the isomorphism theorems should be seen as justifying talking about algebraic structures (among other structuers) in terms of structure preserving morphisms? in that sense they are like the ""interface"" between category theoretical algebra (e.g. talking about groups in terms of group homomorphisms) and ""set-theoretic"" algebra (talking about groups in terms of the elements of the group, and cosets and so forth).","My first instinct when I thought about algebra in category theory, was to try to ""generalize the isomorphism theorems in category theory"". So I tried to prove the generalization of ""the image of a group homomorphism is isomorphic to the quotient group generated by its kernel"". But then I found out that in category subobjects are actually defined in terms of monomorphisms, which for the category Grp is essentially implicitly using that isomorphism theorem. So is it correct that I shouldn't be trying to prove the isomorphism theorems in category theory? Is it correct that instead, the isomorphism theorems should be seen as justifying talking about algebraic structures (among other structuers) in terms of structure preserving morphisms? in that sense they are like the ""interface"" between category theoretical algebra (e.g. talking about groups in terms of group homomorphisms) and ""set-theoretic"" algebra (talking about groups in terms of the elements of the group, and cosets and so forth).",,"['abstract-algebra', 'category-theory', 'group-isomorphism']"
82,"Can we invert these analogous ""Dirichlet"" series for GCD / LCM convolution?","Can we invert these analogous ""Dirichlet"" series for GCD / LCM convolution?",,"We know that $\sum_{ab = n} f(a) g(b)$ is multiplicative in $n$ if $f, g$ are but what about $\sum_{\text{lcm}(a,b) = n} f(a) g(b)$ .  It associates because of associativity of $\text{lcm}$ .   Thanks @darij grinberg who says that this preserves multiplicativity. Where does it show up? If the $a,b : \Bbb{N} \to \Bbb{C}$ is multiplicative then consider their natural map into infinite sums of the form $\sum_{i \in \Bbb{N}} c_i \chi_i(n)$ where $\chi_i = \begin{cases} 1, \text{ if } n \in (i) \\ 0, \text { if } n \notin (i)\end{cases}$ where $(i)$ is the ideal in $\Bbb{Z}$ , and $c_i \in \Bbb{C}$ . Then the $n$ th coefficient of $(a\cdot b)(n)\equiv a(n) b(n)$ is the second sum above i.e. the $m$ th coefficient of multiplication is $(a \star b)(m) = \sum_{\text{lcm}(i,j)=m} a(i)b(j)$ . Now take GCD sums: $$ \sum_{\text{gcd}(a,b) = n} f(a) g(b) $$ GCD basis functions: Whatever the ""basis functions"" are, they must satsify $\phi_k(n)^2 = \phi_{\gcd(k,k)}(n) = \phi_k(n)$ or can only give values in $\{0, 1\}$ meaning they too are probably ""characteristic functions"". $$\phi_k(n) = \begin{cases} 0, \text { if } (k,n) = 1 \\ 1, \text{ if } (k,n) \gt 1\end{cases}$$ works.  It can be expressed as the characteristic map of the set $\Bbb{Z} \setminus U_k$ where $U_k = $ the units $\pmod k$ . Question: When are the series $$\sum_{i\in \Bbb{N}} c_i \chi_i(x), \ \ \sum_{i \in \Bbb{N}} c_i \phi_i(x)$$ invertible with respect to pointwise multiplication? The first series always converges (it's always a finite sum), while the second series might not converge, so assume that it converges if you need to.","We know that is multiplicative in if are but what about .  It associates because of associativity of .   Thanks @darij grinberg who says that this preserves multiplicativity. Where does it show up? If the is multiplicative then consider their natural map into infinite sums of the form where where is the ideal in , and . Then the th coefficient of is the second sum above i.e. the th coefficient of multiplication is . Now take GCD sums: GCD basis functions: Whatever the ""basis functions"" are, they must satsify or can only give values in meaning they too are probably ""characteristic functions"". works.  It can be expressed as the characteristic map of the set where the units . Question: When are the series invertible with respect to pointwise multiplication? The first series always converges (it's always a finite sum), while the second series might not converge, so assume that it converges if you need to.","\sum_{ab = n} f(a) g(b) n f, g \sum_{\text{lcm}(a,b) = n} f(a) g(b) \text{lcm} a,b : \Bbb{N} \to \Bbb{C} \sum_{i \in \Bbb{N}} c_i \chi_i(n) \chi_i = \begin{cases} 1, \text{ if } n \in (i) \\ 0, \text { if } n \notin (i)\end{cases} (i) \Bbb{Z} c_i \in \Bbb{C} n (a\cdot b)(n)\equiv a(n) b(n) m (a \star b)(m) = \sum_{\text{lcm}(i,j)=m} a(i)b(j) 
\sum_{\text{gcd}(a,b) = n} f(a) g(b)
 \phi_k(n)^2 = \phi_{\gcd(k,k)}(n) = \phi_k(n) \{0, 1\} \phi_k(n) = \begin{cases} 0, \text { if } (k,n) = 1 \\ 1, \text{ if } (k,n) \gt 1\end{cases} \Bbb{Z} \setminus U_k U_k =  \pmod k \sum_{i\in \Bbb{N}} c_i \chi_i(x), \ \ \sum_{i \in \Bbb{N}} c_i \phi_i(x)","['abstract-algebra', 'elementary-number-theory', 'ring-theory', 'integers', 'least-common-multiple']"
83,When is every direct product of a ring also a free module?,When is every direct product of a ring also a free module?,,"Let $R$ be a non-zero commutative (unital) ring, such that the direct product $R^X$ is a free $R$-module, for any set $X$. What can be said on $R$ ?    For instance, does it have to be a field / artinian / local … ? What happens if we assume that $R$ is an integral domain ? Notice that I'm not imposing any condition on the rank of the free $R$-module $R^X$. (See here for the case where $R$ is a field).  When $R = \Bbb Z$, it is well-known that $R^{\Bbb N}$ is not a free $\Bbb Z$-module. Also, if any unital $R$-module is free, then $R$ is a field. I saw this question , which tells us that $R$ is a coherent ring.  The literature calls ""$F$-rings"" the rings I'm looking for, see this very relevant paper When a Ring Is an F-Ring by John D. O'Neill  and this other source . O'Neill's paper gives a complete characterization in Corollary 3.2, but the conditions are a bit complicated. Even the example 3.7 does not answer completely my question: if $R$ is an integral domain, then is $R$ necessarily a field? Otherwise, what would be some concrete (explicit) counter-examples? Thank you for your comments and remarks.","Let $R$ be a non-zero commutative (unital) ring, such that the direct product $R^X$ is a free $R$-module, for any set $X$. What can be said on $R$ ?    For instance, does it have to be a field / artinian / local … ? What happens if we assume that $R$ is an integral domain ? Notice that I'm not imposing any condition on the rank of the free $R$-module $R^X$. (See here for the case where $R$ is a field).  When $R = \Bbb Z$, it is well-known that $R^{\Bbb N}$ is not a free $\Bbb Z$-module. Also, if any unital $R$-module is free, then $R$ is a field. I saw this question , which tells us that $R$ is a coherent ring.  The literature calls ""$F$-rings"" the rings I'm looking for, see this very relevant paper When a Ring Is an F-Ring by John D. O'Neill  and this other source . O'Neill's paper gives a complete characterization in Corollary 3.2, but the conditions are a bit complicated. Even the example 3.7 does not answer completely my question: if $R$ is an integral domain, then is $R$ necessarily a field? Otherwise, what would be some concrete (explicit) counter-examples? Thank you for your comments and remarks.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'free-modules']"
84,"Show that if $\vert G\vert = pq$, then either $G$ is abelian or $Z(G) = \{ e\}$.","Show that if , then either  is abelian or .",\vert G\vert = pq G Z(G) = \{ e\},"The center of a group $G$ is defined as $Z(G):=\{ z\in G : gz = zg, \; \forall g \in G\}$. The goal is to show that if $\vert G\vert = pq$, where $p$ and $q$ are not necessarily distinct primes then either $G$ is abelian or $Z(G) = \{ e\}$. I want to suppose that $Z(G) \neq \{ e\}$ and then use the fact that $G/Z(G)$ is cyclic to imply that $G$ is abelian, which is something I have already proven. But how do I show that $G/Z(G)$ is cyclic when I am not certain what exactly $Z(G)$ looks like. I only know that it has at least one non-identity element in it, which will be of order $p$ WLOG, (the case where it is of order $pq$ is trivial). Any help is appreciated. Thank you.","The center of a group $G$ is defined as $Z(G):=\{ z\in G : gz = zg, \; \forall g \in G\}$. The goal is to show that if $\vert G\vert = pq$, where $p$ and $q$ are not necessarily distinct primes then either $G$ is abelian or $Z(G) = \{ e\}$. I want to suppose that $Z(G) \neq \{ e\}$ and then use the fact that $G/Z(G)$ is cyclic to imply that $G$ is abelian, which is something I have already proven. But how do I show that $G/Z(G)$ is cyclic when I am not certain what exactly $Z(G)$ looks like. I only know that it has at least one non-identity element in it, which will be of order $p$ WLOG, (the case where it is of order $pq$ is trivial). Any help is appreciated. Thank you.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
85,Find the degree of $\mathbb{Q}(\zeta_{37} + \zeta_{37}^{10} + \zeta_{37}^{26})$ over $\mathbb{Q}$,Find the degree of  over,\mathbb{Q}(\zeta_{37} + \zeta_{37}^{10} + \zeta_{37}^{26}) \mathbb{Q},"Apologies if this is a repeat question. First off, I notice that $1 + 10 + 26 = 37$. Hmmmmm! What could the significance of this possibly be? I have nothing more intelligent to add, except that I would try to see if I could find the degree of $\mathbb{Q}(\zeta_{37})$ over $\mathbb{Q}$ adjoin this $\alpha$ first, then use the tower argument. To that end, maybe I could try to see how many automorphisms in Gal$(\mathbb{Q}(\zeta_{37})/ \mathbb{Q})$ fix $\mathbb{Q}(\alpha)$.","Apologies if this is a repeat question. First off, I notice that $1 + 10 + 26 = 37$. Hmmmmm! What could the significance of this possibly be? I have nothing more intelligent to add, except that I would try to see if I could find the degree of $\mathbb{Q}(\zeta_{37})$ over $\mathbb{Q}$ adjoin this $\alpha$ first, then use the tower argument. To that end, maybe I could try to see how many automorphisms in Gal$(\mathbb{Q}(\zeta_{37})/ \mathbb{Q})$ fix $\mathbb{Q}(\alpha)$.",,"['abstract-algebra', 'galois-theory', 'extension-field']"
86,When is a quotient group abelian?,When is a quotient group abelian?,,"Every subgroup of an abelian group is normal, and every quotient of an abelian group is abelian. Also, a subgroup of a nonabelian group need not be normal, and a quotient of a nonabelian group need not be abelian. Is there a simple set of (sufficient, necessary) conditions for a quotient of a nonabelian group to be abelian? I found one here . Let $G$ be a group with commutator subgroup $G'$, let $N$ be a normal subgroup of $G$. Now $G/N$ is a abelian iff $G'$ is a subset of $N$. Are there others? Bonus question . A nonabelian group where every proper subgroup is normal is called Hamiltonian. What do you call a nonabelian group where every proper subgroup is abelian? What do you call a nonabelian group where every quotient group is abelian? (Then the commutator subgroup is a subset of every normal subgroup.)","Every subgroup of an abelian group is normal, and every quotient of an abelian group is abelian. Also, a subgroup of a nonabelian group need not be normal, and a quotient of a nonabelian group need not be abelian. Is there a simple set of (sufficient, necessary) conditions for a quotient of a nonabelian group to be abelian? I found one here . Let $G$ be a group with commutator subgroup $G'$, let $N$ be a normal subgroup of $G$. Now $G/N$ is a abelian iff $G'$ is a subset of $N$. Are there others? Bonus question . A nonabelian group where every proper subgroup is normal is called Hamiltonian. What do you call a nonabelian group where every proper subgroup is abelian? What do you call a nonabelian group where every quotient group is abelian? (Then the commutator subgroup is a subset of every normal subgroup.)",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'quotient-group']"
87,Is stabilizer subgroup Normal,Is stabilizer subgroup Normal,,"Let $G\le S_n$, and set $\Omega = \{1,2,3,\ldots,n\}$. Let $\Delta \subseteq \Omega$, Stabilizer subgroup of $\Delta$ is defined as $$Stab_{\Delta} = \{g \in G  \mid \Delta^g = \Delta \}$$ Is $Stab_{\Delta}$ Normal subgroup of $G$? My Attempt :  To prove normal we need to show that if any $h\in Stab_{\Delta} $ then $ghg^{-1} \in Stab_{\Delta}$ $$x_i^g = x_j$$ $$(x_i^g)^h = (x_j)^h $$ $$(x_i^{gh})^{g^{-1}} = (x_{l})^{g^{-1}}$$","Let $G\le S_n$, and set $\Omega = \{1,2,3,\ldots,n\}$. Let $\Delta \subseteq \Omega$, Stabilizer subgroup of $\Delta$ is defined as $$Stab_{\Delta} = \{g \in G  \mid \Delta^g = \Delta \}$$ Is $Stab_{\Delta}$ Normal subgroup of $G$? My Attempt :  To prove normal we need to show that if any $h\in Stab_{\Delta} $ then $ghg^{-1} \in Stab_{\Delta}$ $$x_i^g = x_j$$ $$(x_i^g)^h = (x_j)^h $$ $$(x_i^{gh})^{g^{-1}} = (x_{l})^{g^{-1}}$$",,['abstract-algebra']
88,Principal ideal property without being integral domain? [duplicate],Principal ideal property without being integral domain? [duplicate],,"This question already has an answer here : Principal ideal rings that are not integral domains (1 answer) Closed 7 years ago . In my algebra course (taught from Artin), a principal ideal domain is defined as an integral domain such that all ideals are principal. This got me wondering: Are there rings for which every ideal is principal, but the ring is not an integral domain?","This question already has an answer here : Principal ideal rings that are not integral domains (1 answer) Closed 7 years ago . In my algebra course (taught from Artin), a principal ideal domain is defined as an integral domain such that all ideals are principal. This got me wondering: Are there rings for which every ideal is principal, but the ring is not an integral domain?",,"['abstract-algebra', 'ring-theory']"
89,What are the self-normalizing subgroups of $S_n$?,What are the self-normalizing subgroups of ?,S_n,"The normalizer of $G < S_n$ in the group $S_n$ is defined as $$N_{S_n}(G) = \{\pi \in S_n \mid \pi G = G \pi \}.$$ The group $G$ is self-normalizing in $S_n$ iff $$N_{S_n}(G) = G.$$ What are the self-normalizing subgroups of $S_n$? This is equivalent to asking: Given a subgroup $G < S_n$, under what condition it is not a normal subgroup of any other $H \leq S_n, G\neq H$?","The normalizer of $G < S_n$ in the group $S_n$ is defined as $$N_{S_n}(G) = \{\pi \in S_n \mid \pi G = G \pi \}.$$ The group $G$ is self-normalizing in $S_n$ iff $$N_{S_n}(G) = G.$$ What are the self-normalizing subgroups of $S_n$? This is equivalent to asking: Given a subgroup $G < S_n$, under what condition it is not a normal subgroup of any other $H \leq S_n, G\neq H$?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups', 'normal-subgroups']"
90,Showing A Certain Subgroup of $\mathbb{Q}$ must actually be $\mathbb{Q}$,Showing A Certain Subgroup of  must actually be,\mathbb{Q} \mathbb{Q},"I asked to show that if $H$ is a subgroup of the additive group $\mathbb{Q}$ with the property that $\frac{1}{x} \in H$ if $0 \neq x \in H$, then $H=0$ or $H = \mathbb{Q}$>. I already ruled out the first case by supposing the $H$ only contained the identity. I am wondering if my proof of the second part is correct. Here it is: Suppose that $H$ has at least one other element besides $0$, call it $\frac{r}{s}$. By closure, we know $\frac{r}{s} + \dots + \frac{r}{s}$ (s-times is $r$, which is in $H$. Then $\frac{1}{r} \in H$. By closure, $\frac{1}{r} + \dots + \frac{1}{r}$ ($r$-times) is $1$. Since $H$ contains $1$, by $H$'s closure it must contain all integers. Now, let $y \in H$ be some arbitrary integer. Then $\frac{1}{y} \in H$, and so $\frac{1}{y} + \dots + \frac{1}{y}$ ($x$-times, where $x$ is some arbitary integer) is $\frac{x}{y}$, an arbitrary rational number which must be in $H$ by closure. Does this seem right?","I asked to show that if $H$ is a subgroup of the additive group $\mathbb{Q}$ with the property that $\frac{1}{x} \in H$ if $0 \neq x \in H$, then $H=0$ or $H = \mathbb{Q}$>. I already ruled out the first case by supposing the $H$ only contained the identity. I am wondering if my proof of the second part is correct. Here it is: Suppose that $H$ has at least one other element besides $0$, call it $\frac{r}{s}$. By closure, we know $\frac{r}{s} + \dots + \frac{r}{s}$ (s-times is $r$, which is in $H$. Then $\frac{1}{r} \in H$. By closure, $\frac{1}{r} + \dots + \frac{1}{r}$ ($r$-times) is $1$. Since $H$ contains $1$, by $H$'s closure it must contain all integers. Now, let $y \in H$ be some arbitrary integer. Then $\frac{1}{y} \in H$, and so $\frac{1}{y} + \dots + \frac{1}{y}$ ($x$-times, where $x$ is some arbitary integer) is $\frac{x}{y}$, an arbitrary rational number which must be in $H$ by closure. Does this seem right?",,"['abstract-algebra', 'group-theory', 'proof-verification', 'rational-numbers']"
91,Properties of a finite field extension of degree 2.,Properties of a finite field extension of degree 2.,,"I am bad (but trying to improve!) at very basic number theory and algebra. I'm quite sure this question is easy, but I do not know what fundamentals I am missing. This is from Ireland & Rosen's ""Classical Introduction to Modern Number Theory"" and is question 10 of Chapter 7. I have copied it exactly. Let $K\supset F$ be finite fields and $[K:F]=2$. For $\beta\in K$ show that $\beta^{1+q}\in F$ and moreover that every element in $F$ is of the form $\beta^{1+q}$ for some $\beta\in K$. The question uses the context of the previous one, in which $|F|=q$. What I've tried so far: For the first part, it seems there are two cases: i) $\beta\in F$ or ii) $\beta\in K\backslash F$. In i) it is easy, since $\beta^q=\beta$ and the extension is of degree $2$, $\beta^{q+1}=\beta^2\in F$. In ii), I suppose the minimal polynomial of $\beta$ in $K[x]$ is $x^2-\beta^2=x^2-\beta^{q+1}$... but where to go from here? And I can't even begin to see what to do with the second part of the problem. Is any of this right so far? What do I do next if so? Thanks so much, ya'll. I'll go try to answer a question I can help with in the meantime.","I am bad (but trying to improve!) at very basic number theory and algebra. I'm quite sure this question is easy, but I do not know what fundamentals I am missing. This is from Ireland & Rosen's ""Classical Introduction to Modern Number Theory"" and is question 10 of Chapter 7. I have copied it exactly. Let $K\supset F$ be finite fields and $[K:F]=2$. For $\beta\in K$ show that $\beta^{1+q}\in F$ and moreover that every element in $F$ is of the form $\beta^{1+q}$ for some $\beta\in K$. The question uses the context of the previous one, in which $|F|=q$. What I've tried so far: For the first part, it seems there are two cases: i) $\beta\in F$ or ii) $\beta\in K\backslash F$. In i) it is easy, since $\beta^q=\beta$ and the extension is of degree $2$, $\beta^{q+1}=\beta^2\in F$. In ii), I suppose the minimal polynomial of $\beta$ in $K[x]$ is $x^2-\beta^2=x^2-\beta^{q+1}$... but where to go from here? And I can't even begin to see what to do with the second part of the problem. Is any of this right so far? What do I do next if so? Thanks so much, ya'll. I'll go try to answer a question I can help with in the meantime.",,"['abstract-algebra', 'elementary-number-theory', 'finite-fields']"
92,The other $47$ roots of the minimal polynomial for $\cos 1 ^\circ$,The other  roots of the minimal polynomial for,47 \cos 1 ^\circ,"The minimal polynomial for $x=\cos 1 ^\circ=\cos \frac{\pi}{180}$ is: $$281474976710656 x^{48}-3377699720527872 x^{46}+18999560927969280 x^{44}- \\ -66568831992070144 x^{42}+162828875980603392 x^{40}-295364007592722432 x^{38}+ \\ +411985976135516160 x^{36}-452180272956309504 x^{34}+396366279591591936 x^{32}- \\ -280058255978266624 x^{30}+160303703377575936 x^{28}-74448984852135936 x^{26}+ \\ +28011510450094080 x^{24}-8500299631165440 x^{22}+2064791072931840 x^{20}- \\ -397107008634880 x^{18}+59570604933120 x^{16}-6832518856704 x^{14}+ \\ +583456329728 x^{12}-35782471680 x^{10}+1497954816 x^8- \\ -39625728 x^6+579456 x^4-3456 x^2+1$$ It obviously has $48$ roots, but since it's even we only need to consider $24$ positive roots. One is $x=\sin 1 ^\circ=\cos(\frac{\pi}{2}-\frac{\pi}{180})=\cos \frac{89\pi}{180}=\cos 89 ^\circ$. It seems that all the other roots are made using numbers of degrees $<90$, which share no common divisors with $180$: $$x=\cos \alpha ^\circ$$ $$\alpha=\{1,7,11,13,17,19,23,29,31,37,41,43,47,49,53,59,61,67,71,73,77,79,83,89 \}$$ What is the general algebrac reason for this? How does this rule work for other trigonometric functions of rational multiplies of $\pi$? If, in general, we find a polynomial for the following number: $$y=\text{trig} \frac{p}{q} \pi $$ Where $\text{trig}=\{ \sin, \cos, \tan  \}$, $p,q$ - integers, then what will the other solutions be?","The minimal polynomial for $x=\cos 1 ^\circ=\cos \frac{\pi}{180}$ is: $$281474976710656 x^{48}-3377699720527872 x^{46}+18999560927969280 x^{44}- \\ -66568831992070144 x^{42}+162828875980603392 x^{40}-295364007592722432 x^{38}+ \\ +411985976135516160 x^{36}-452180272956309504 x^{34}+396366279591591936 x^{32}- \\ -280058255978266624 x^{30}+160303703377575936 x^{28}-74448984852135936 x^{26}+ \\ +28011510450094080 x^{24}-8500299631165440 x^{22}+2064791072931840 x^{20}- \\ -397107008634880 x^{18}+59570604933120 x^{16}-6832518856704 x^{14}+ \\ +583456329728 x^{12}-35782471680 x^{10}+1497954816 x^8- \\ -39625728 x^6+579456 x^4-3456 x^2+1$$ It obviously has $48$ roots, but since it's even we only need to consider $24$ positive roots. One is $x=\sin 1 ^\circ=\cos(\frac{\pi}{2}-\frac{\pi}{180})=\cos \frac{89\pi}{180}=\cos 89 ^\circ$. It seems that all the other roots are made using numbers of degrees $<90$, which share no common divisors with $180$: $$x=\cos \alpha ^\circ$$ $$\alpha=\{1,7,11,13,17,19,23,29,31,37,41,43,47,49,53,59,61,67,71,73,77,79,83,89 \}$$ What is the general algebrac reason for this? How does this rule work for other trigonometric functions of rational multiplies of $\pi$? If, in general, we find a polynomial for the following number: $$y=\text{trig} \frac{p}{q} \pi $$ Where $\text{trig}=\{ \sin, \cos, \tan  \}$, $p,q$ - integers, then what will the other solutions be?",,"['abstract-algebra', 'trigonometry', 'polynomials', 'roots']"
93,Finding a given group in groups twice as large.,Finding a given group in groups twice as large.,,"Given a group $H$ with order $n$, can we determine how many groups $G$ of order $2n$ contain $H$ as a subgroup, and perhaps find these groups? For example, $\mathbb{Z}_4$ is contained in $\mathbb{Z}_8$, $\mathbb{Z}_4 \times \mathbb{Z}_2$, $D_4$, and $Q_8$. I'm curious if we can find a constant upper bound (or upper bound related to $n$) on the number of groups $G$ that satisfy my constraints for any $H$. I'm not very familiar with group theory, so methods to approach this might be over my head. I'm particularly interested in the case where we only consider cyclic $H$. Feel free to generalize! Thanks.","Given a group $H$ with order $n$, can we determine how many groups $G$ of order $2n$ contain $H$ as a subgroup, and perhaps find these groups? For example, $\mathbb{Z}_4$ is contained in $\mathbb{Z}_8$, $\mathbb{Z}_4 \times \mathbb{Z}_2$, $D_4$, and $Q_8$. I'm curious if we can find a constant upper bound (or upper bound related to $n$) on the number of groups $G$ that satisfy my constraints for any $H$. I'm not very familiar with group theory, so methods to approach this might be over my head. I'm particularly interested in the case where we only consider cyclic $H$. Feel free to generalize! Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
94,Show that $\beta $ is algebraic over $F(\alpha)$.,Show that  is algebraic over .,\beta  F(\alpha),"I have started reading field theory . Let $E$ be an extension field of $F$ and let $\alpha,\beta\in E$ .Suppose that $\alpha $ is transcendental over $F$ but algebraic over $F(\beta)$ . Show that $\beta$ is algebraic over $F(\alpha)$ . Since $\alpha$ is  algebraic over $F(\beta)\implies \exists p(x)\neq 0$ such that $p(\alpha)=0$ .So $p(x)$ must be a polynomial over $F(\beta)$ and not over $F$ . But these facts are taking me nowhere near the solution.Any help will be appreciated.",I have started reading field theory . Let be an extension field of and let .Suppose that is transcendental over but algebraic over . Show that is algebraic over . Since is  algebraic over such that .So must be a polynomial over and not over . But these facts are taking me nowhere near the solution.Any help will be appreciated.,"E F \alpha,\beta\in E \alpha  F F(\beta) \beta F(\alpha) \alpha F(\beta)\implies \exists p(x)\neq 0 p(\alpha)=0 p(x) F(\beta) F","['abstract-algebra', 'field-theory']"
95,Why is $\mathbb{Z}[1/p]$ the direct limit of $\mathbb{Z}\xrightarrow{p}\mathbb{Z}\xrightarrow{p}\mathbb{Z}\to...$?,Why is  the direct limit of ?,\mathbb{Z}[1/p] \mathbb{Z}\xrightarrow{p}\mathbb{Z}\xrightarrow{p}\mathbb{Z}\to...,"This is an example from Algebraic Topology, by Hatcher . As far as I understand, I have to take the direct sum of all the $G_i$s (in this case, $\mathbb{Z}\oplus\mathbb{Z}\oplus...$) and quotient out all elements of the form $(g_1,g_2-\alpha_1(g_1),...)$ with $\alpha_i$ as given in the definition on the same page. In this case, what are the elements I need to quotient out? Won't they be elements of the form $(z_1,z_2-pz_1,...)$? Because given that $z_2$ was obtained by taking an integer and multiplying it by $p$, $z_2-pz_1$ will be a multiple of $p$. I just don't see how setting these to $0$ is the same as $\mathbb{Z}[1/p]$.","This is an example from Algebraic Topology, by Hatcher . As far as I understand, I have to take the direct sum of all the $G_i$s (in this case, $\mathbb{Z}\oplus\mathbb{Z}\oplus...$) and quotient out all elements of the form $(g_1,g_2-\alpha_1(g_1),...)$ with $\alpha_i$ as given in the definition on the same page. In this case, what are the elements I need to quotient out? Won't they be elements of the form $(z_1,z_2-pz_1,...)$? Because given that $z_2$ was obtained by taking an integer and multiplying it by $p$, $z_2-pz_1$ will be a multiple of $p$. I just don't see how setting these to $0$ is the same as $\mathbb{Z}[1/p]$.",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'limits-colimits']"
96,"$A$ is a unitary ring with $xy=1$ implies $yx=1$, prove that if $a^2=3b^2$ and $3ab=1+4ba$, then $ab=ba$","is a unitary ring with  implies , prove that if  and , then",A xy=1 yx=1 a^2=3b^2 3ab=1+4ba ab=ba,"Let $(A,+, \cdot)$ be a unitary ring with the property that if $xy=1$ for $x,y \in A$, then $yx=1$. Let $a,b \in A$ with $a^2=3b^2$ and $3ab=1+4ba$. Prove that $ab=ba$. We easily get that $(a-2b)(2a+3b)=1$, so, by hypothesis, we have that $(2a+3b)(a-2b)=1$. From here we get that $3ba=1+4ab$. Then, $3ab-4ba=1=3ba-4ab$, and so $7ab=7ba$. Now, $9ab=3+12ba$ and $12ba=4+16ab$, so $9ab=3+4+16ab$, thus $7ab=-7$. Of course, we have $7ba=-7$ too. Next, from $3ab=1+4ba$ and $3ba=1+4ab$ we get that $1+ba=3ab-3ba=-1-ab$, so $ab+ba=-2$. We can go further and write that $aba+ba^2=-2a$ and $a^2b+aba=-2a$. We get that $a^2b=ba^2$ and, analogously $ab^2=b^2a$. Now, we can easily prove that $ab=6ba+5$, $ba=6ab+5$, $2ab=5ba+3$ and $2ba=5ab+3$. Here I'm stuck.","Let $(A,+, \cdot)$ be a unitary ring with the property that if $xy=1$ for $x,y \in A$, then $yx=1$. Let $a,b \in A$ with $a^2=3b^2$ and $3ab=1+4ba$. Prove that $ab=ba$. We easily get that $(a-2b)(2a+3b)=1$, so, by hypothesis, we have that $(2a+3b)(a-2b)=1$. From here we get that $3ba=1+4ab$. Then, $3ab-4ba=1=3ba-4ab$, and so $7ab=7ba$. Now, $9ab=3+12ba$ and $12ba=4+16ab$, so $9ab=3+4+16ab$, thus $7ab=-7$. Of course, we have $7ba=-7$ too. Next, from $3ab=1+4ba$ and $3ba=1+4ab$ we get that $1+ba=3ab-3ba=-1-ab$, so $ab+ba=-2$. We can go further and write that $aba+ba^2=-2a$ and $a^2b+aba=-2a$. We get that $a^2b=ba^2$ and, analogously $ab^2=b^2a$. Now, we can easily prove that $ab=6ba+5$, $ba=6ab+5$, $2ab=5ba+3$ and $2ba=5ab+3$. Here I'm stuck.",,"['abstract-algebra', 'ring-theory']"
97,Does orbit-stabilizer theorem holds for monoid action?,Does orbit-stabilizer theorem holds for monoid action?,,"For a group $G$ acting on some space $X$ we know there is a orbit-stabilizer theorem . My question is does this formula holds for monoid action? I think this formula may not hold, as inverse do not exist for all elements. Though I am not sure. My second question is what information do we get from monoid action? How it is useful?","For a group $G$ acting on some space $X$ we know there is a orbit-stabilizer theorem . My question is does this formula holds for monoid action? I think this formula may not hold, as inverse do not exist for all elements. Though I am not sure. My second question is what information do we get from monoid action? How it is useful?",,"['abstract-algebra', 'group-actions', 'monoid']"
98,About $R/I$ Where $I$ is a Prime Ideal,About  Where  is a Prime Ideal,R/I I,"A well known result in Commutative Algebra says: for a commutative ring $R$ with $1$, $R/I$ is an Integral Domain if and only if $I$ is a Prime Ideal of $R$. Can this result be generalised for non commutative rings?","A well known result in Commutative Algebra says: for a commutative ring $R$ with $1$, $R/I$ is an Integral Domain if and only if $I$ is a Prime Ideal of $R$. Can this result be generalised for non commutative rings?",,"['abstract-algebra', 'ring-theory', 'ideals', 'integral-domain', 'maximal-and-prime-ideals']"
99,Prove that a group of order $p^2q$ has a proper normal subgroup and is solvable.,Prove that a group of order  has a proper normal subgroup and is solvable.,p^2q,"So, going through my qual prep classes, there's a two part question:  For $p,q$ distinct primes, prove that a group of order $p^2q$ has a nontrivial proper normal subgroup,  then prove that it's solvable.  Part 2 is pretty trivial given the first, but I've been struggling with it. Thoughts so far:  Attacking with Sylow theorems, if $n_p=1$ or $n_q=1$ we'd be done,  so assume neither are one (either for contradiction or to find a group of order $pq$, since I'll show later that such a group would have to be normal) So,  given that we need $n_p=q$ and $n_q=p$ or $n_q=p^2$,  but since we also need $n_p>p$ and $n_q>q$,  we must have $p<q<p^2$, and $n_q=p^2$.  We also have $q=pk+1$ and $p^2=qj+1$ for some natural numbers $k,j$ due to congruency,  but I couldn't seem to find a contradiction out of here. Now, since $p$ is the smallest prime,  if I could find a subgroup of order $pq$, it would have index $p$ and thus be normal by the theorem that groups of the smallest prime index of a group are normal.  However, I can't seem to figure out why either that would have to be the case, or why the above statements are a contradiction to force a normal $p^2$ group or a normal $q$ group.","So, going through my qual prep classes, there's a two part question:  For $p,q$ distinct primes, prove that a group of order $p^2q$ has a nontrivial proper normal subgroup,  then prove that it's solvable.  Part 2 is pretty trivial given the first, but I've been struggling with it. Thoughts so far:  Attacking with Sylow theorems, if $n_p=1$ or $n_q=1$ we'd be done,  so assume neither are one (either for contradiction or to find a group of order $pq$, since I'll show later that such a group would have to be normal) So,  given that we need $n_p=q$ and $n_q=p$ or $n_q=p^2$,  but since we also need $n_p>p$ and $n_q>q$,  we must have $p<q<p^2$, and $n_q=p^2$.  We also have $q=pk+1$ and $p^2=qj+1$ for some natural numbers $k,j$ due to congruency,  but I couldn't seem to find a contradiction out of here. Now, since $p$ is the smallest prime,  if I could find a subgroup of order $pq$, it would have index $p$ and thus be normal by the theorem that groups of the smallest prime index of a group are normal.  However, I can't seem to figure out why either that would have to be the case, or why the above statements are a contradiction to force a normal $p^2$ group or a normal $q$ group.",,"['abstract-algebra', 'group-theory']"
