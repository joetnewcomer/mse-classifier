,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"If a fair die is thrown three times, what is the probability that the sum of the faces is 9?","If a fair die is thrown three times, what is the probability that the sum of the faces is 9?",,"If a fair die is thrown thrice, what is the probability that the sum of the faces is 9? I did like this. The total number of cases is $6^3=216$ Now,the number of solutions of the equation $x + y + z = 9$ with each of $x,y,z$ greater than equal to $1$ is ${8 \choose 2}$. But am not sure about my answer. Please help.","If a fair die is thrown thrice, what is the probability that the sum of the faces is 9? I did like this. The total number of cases is $6^3=216$ Now,the number of solutions of the equation $x + y + z = 9$ with each of $x,y,z$ greater than equal to $1$ is ${8 \choose 2}$. But am not sure about my answer. Please help.",,['probability']
1,What is the probability that four players who each receive ten cards together receive less than four aces?,What is the probability that four players who each receive ten cards together receive less than four aces?,,"A deck of cards contain 52 cards, including 4 aces. Suppose each player gets 10 cards and the other 12 cards are kept aside, what is the probability that the four players together have less than four aces? My answer: N = Total possibilities n = possibilities where the four players together have four aces p = probability that four players together have less than four aces = $\frac{N-n}{N}$ $$N = \frac{52!}{10!10!10!10!12!}=9.71*10^{32}$$ For n, I consider the possibilities of the distribution of the four aces among the four players: Each player gets 1 ace One player gets 2 aces, two players get 1 ace, one player gets 0 aces Two players get 2 aces, two players get 0 aces One player gets 3 aces, one player gets 1 ace, two players get 0 aces One player gets 4 aces, three players get 0 aces $$n = \frac{4!}{1!1!1!1!}*\frac{36!}{9!9!9!9!}+\frac{4!}{2!1!1!0!}*\frac{36!}{8!9!9!10!}+\frac{4!}{2!2!1!0!}*\frac{36!}{8!8!9!10!}+\frac{4!}{3!1!0!0!}*\frac{36!}{7!9!10!10!}+\frac{4!}{4!0!0!0!}*\frac{36!}{6!10!10!10!}$$ (36 is used because we are observing the set of cards excluding the 4 aces and the 12 cards kept aside) Using the values of N and n, p can be calculated. Is this correct? If so, is there a more efficient way to count the possibilities for n? Thanks!","A deck of cards contain 52 cards, including 4 aces. Suppose each player gets 10 cards and the other 12 cards are kept aside, what is the probability that the four players together have less than four aces? My answer: N = Total possibilities n = possibilities where the four players together have four aces p = probability that four players together have less than four aces = $\frac{N-n}{N}$ $$N = \frac{52!}{10!10!10!10!12!}=9.71*10^{32}$$ For n, I consider the possibilities of the distribution of the four aces among the four players: Each player gets 1 ace One player gets 2 aces, two players get 1 ace, one player gets 0 aces Two players get 2 aces, two players get 0 aces One player gets 3 aces, one player gets 1 ace, two players get 0 aces One player gets 4 aces, three players get 0 aces $$n = \frac{4!}{1!1!1!1!}*\frac{36!}{9!9!9!9!}+\frac{4!}{2!1!1!0!}*\frac{36!}{8!9!9!10!}+\frac{4!}{2!2!1!0!}*\frac{36!}{8!8!9!10!}+\frac{4!}{3!1!0!0!}*\frac{36!}{7!9!10!10!}+\frac{4!}{4!0!0!0!}*\frac{36!}{6!10!10!10!}$$ (36 is used because we are observing the set of cards excluding the 4 aces and the 12 cards kept aside) Using the values of N and n, p can be calculated. Is this correct? If so, is there a more efficient way to count the possibilities for n? Thanks!",,"['probability', 'combinatorics', 'combinations', 'multinomial-coefficients']"
2,How many unique ways are there to arrange the letters in the word HATTER?,How many unique ways are there to arrange the letters in the word HATTER?,,"How many unique ways are there to arrange the letters in the word HATTER? I can't wrap my head around the math to find the answer. I know that if they were all different letters the answer would be 6!. However, I know that these T's are going to overlap, so it won't be that. I am trying to give myself examples like AAA, it can only be written once but if it was 3 different letters it would be 6 times instead.  Somehow I need to get a 6/6, so that it can become 1. If I try it with AAC, half of the permutations disappear. So it must be divided by 2 I guess. 6/2. ABC AAC 1 ACB ACA 2 BCA ACA 2 BAC AAC 1 CAB CAA 3 CBA CAA 3 I kind of see a pattern here. Possible combinations if all letters were different factorial / Divide by the number of equal letters factorial, but still I am confused. Explanation is appreciated. The answer is 360.","How many unique ways are there to arrange the letters in the word HATTER? I can't wrap my head around the math to find the answer. I know that if they were all different letters the answer would be 6!. However, I know that these T's are going to overlap, so it won't be that. I am trying to give myself examples like AAA, it can only be written once but if it was 3 different letters it would be 6 times instead.  Somehow I need to get a 6/6, so that it can become 1. If I try it with AAC, half of the permutations disappear. So it must be divided by 2 I guess. 6/2. ABC AAC 1 ACB ACA 2 BCA ACA 2 BAC AAC 1 CAB CAA 3 CBA CAA 3 I kind of see a pattern here. Possible combinations if all letters were different factorial / Divide by the number of equal letters factorial, but still I am confused. Explanation is appreciated. The answer is 360.",,"['probability', 'combinatorics', 'statistics']"
3,Show that $\prod (1- P(A_n))=0$ iff $\sum P(A_n) = \infty$,Show that  iff,\prod (1- P(A_n))=0 \sum P(A_n) = \infty,Let $A_n$ be independent events with $P(A_n) \neq 1$. Show that $\prod_{n=1}^{\infty} (1- P(A_n))=0$ iff $\sum P(A_n) = \infty$ It kind of looks obvious but I really have no idea how to prove it. Can someone give me help?,Let $A_n$ be independent events with $P(A_n) \neq 1$. Show that $\prod_{n=1}^{\infty} (1- P(A_n))=0$ iff $\sum P(A_n) = \infty$ It kind of looks obvious but I really have no idea how to prove it. Can someone give me help?,,"['probability', 'probability-theory', 'infinite-product']"
4,How to uniformly sample multiple numbers whose product is within some bound,How to uniformly sample multiple numbers whose product is within some bound,,"Suppose I have 3 positive integers: $n_1$ , $n_2$ , and $n_3$ . How do I uniformly sample $(n_1, n_2, n_3)$ so that $50 < n_1 n_2 n_3 < 100$ . I could sample each number independently with bounds between 1 and 100, then keep re-sampling if their product is out of bound. I need to do this with a computer program with more numbers and larger bounds, so I prefer a way that's efficient both in space and time. Are there other ways to sample than what I described above? EDIT (regarding the accepted answer): At the time of this edit, there were 3 approaches answered so far: complete enumeration (addresses the example in the question, simple, but space and time bound for very large problems) rejection sampling (simple, but time bound for very large problems) weighted draw (""efficient"" in space and time compared to other approaches, but complex) All answers work best in different situations. I accepted weighted drawing since it seemed to be most complete in a sense that it addressed the ""efficient both in space and time"" part for larger problems the best.","Suppose I have 3 positive integers: , , and . How do I uniformly sample so that . I could sample each number independently with bounds between 1 and 100, then keep re-sampling if their product is out of bound. I need to do this with a computer program with more numbers and larger bounds, so I prefer a way that's efficient both in space and time. Are there other ways to sample than what I described above? EDIT (regarding the accepted answer): At the time of this edit, there were 3 approaches answered so far: complete enumeration (addresses the example in the question, simple, but space and time bound for very large problems) rejection sampling (simple, but time bound for very large problems) weighted draw (""efficient"" in space and time compared to other approaches, but complex) All answers work best in different situations. I accepted weighted drawing since it seemed to be most complete in a sense that it addressed the ""efficient both in space and time"" part for larger problems the best.","n_1 n_2 n_3 (n_1, n_2, n_3) 50 < n_1 n_2 n_3 < 100","['probability', 'statistics', 'sampling']"
5,"After $10$ minutes, what is the probability that the fly is back on $A$? [closed]","After  minutes, what is the probability that the fly is back on ? [closed]",10 A,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question A fly is walking on a hexagon, at random. The fly starts at vertex $A$. After a minute, it moves to one of the two adjacent vertices. After $10$ minutes, what is the probability that the fly in back on $A$?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question A fly is walking on a hexagon, at random. The fly starts at vertex $A$. After a minute, it moves to one of the two adjacent vertices. After $10$ minutes, what is the probability that the fly in back on $A$?",,['probability']
6,How many 32 digit binary number combinations are possible?,How many 32 digit binary number combinations are possible?,,"How many 32 digit binary number combinations are possible? For example: $$00000000-00000000-00000000-00000000$$ $$00000000-00000000-00000000-00000001$$ $$00000000-00000000-00000000-00000010$$ $$.$$ $$.$$ $$.$$ $$11111111-11111111-11111111-11111110$$ $$11111111-11111111-11111111-11111111$$ Well, we can easily convert the last number to decimal to get the number of combinations and the answer would be $2^{32}$ combinations. But I need a general explanation with respect to general concepts like probability, permutations or combinations, as to how we get $2^{32}$ combinations. P.S. I am not a mathematician. So, please try to explain in a simple way. Thanks a lot!","How many 32 digit binary number combinations are possible? For example: $$00000000-00000000-00000000-00000000$$ $$00000000-00000000-00000000-00000001$$ $$00000000-00000000-00000000-00000010$$ $$.$$ $$.$$ $$.$$ $$11111111-11111111-11111111-11111110$$ $$11111111-11111111-11111111-11111111$$ Well, we can easily convert the last number to decimal to get the number of combinations and the answer would be $2^{32}$ combinations. But I need a general explanation with respect to general concepts like probability, permutations or combinations, as to how we get $2^{32}$ combinations. P.S. I am not a mathematician. So, please try to explain in a simple way. Thanks a lot!",,"['probability', 'combinatorics', 'permutations', 'binary', 'combinations']"
7,Probability and uniform distribution,Probability and uniform distribution,,"How to calculate the probability that one random sample say $X_1$ will be greater than the other random sample say $X_2$ if they are from a uniform distribution with $[0,1]$ ? This is not a homework. I'm trying to solve some exercise problem and this is a part of the problem.","How to calculate the probability that one random sample say $X_1$ will be greater than the other random sample say $X_2$ if they are from a uniform distribution with $[0,1]$ ? This is not a homework. I'm trying to solve some exercise problem and this is a part of the problem.",,['probability']
8,Does $150$% chance exist?,Does % chance exist?,150,"I seen an internet meme that was titled ""Kids that did this sh&t in school have a 150% chance of being in jail right now."" My understanding is that we are dealing with probabilities here and probabilities are limited by $0 \le P \le 1$ or $0$% $\le P \le$ $100$%. Of course $100$% can exist in other areas of maths. For example $150$% of $100$ is $150$. But does the statement in the title make sense?","I seen an internet meme that was titled ""Kids that did this sh&t in school have a 150% chance of being in jail right now."" My understanding is that we are dealing with probabilities here and probabilities are limited by $0 \le P \le 1$ or $0$% $\le P \le$ $100$%. Of course $100$% can exist in other areas of maths. For example $150$% of $100$ is $150$. But does the statement in the title make sense?",,['probability']
9,"Probability of first actor winning a ""first to roll seven with two dice"" contest?","Probability of first actor winning a ""first to roll seven with two dice"" contest?",,"Two players P and Q take turns, in which they each roll two fair and independent dice. P rolls the dice first. The first player who gets a sum of seven wins the game. What is the probability that player P wins the game?","Two players P and Q take turns, in which they each roll two fair and independent dice. P rolls the dice first. The first player who gets a sum of seven wins the game. What is the probability that player P wins the game?",,['probability']
10,How do I tell if this function is a probability density function?,How do I tell if this function is a probability density function?,,If I have $$f(x)=\sin(x\pi/10)\qquad\text{for}\;0\leq x\leq10.$$ How do I tell if it is a probability density function? And if it isn't how do I normalize it?,If I have $$f(x)=\sin(x\pi/10)\qquad\text{for}\;0\leq x\leq10.$$ How do I tell if it is a probability density function? And if it isn't how do I normalize it?,,"['probability', 'probability-theory', 'probability-distributions']"
11,Probability of a Chord Passing Through Two Concentric Circles,Probability of a Chord Passing Through Two Concentric Circles,,"One of my friends gave me a problem that stumped me... You have two concentric circles, one with a radius of 1 and one with a radius of 2. What is the probability that a random chord will pass through the inner circle? Why?","One of my friends gave me a problem that stumped me... You have two concentric circles, one with a radius of 1 and one with a radius of 2. What is the probability that a random chord will pass through the inner circle? Why?",,['probability']
12,13 boys and 2 girls are to be placed next to each other. What is the probability that there are exactly 4 boys between the 2 girls?,13 boys and 2 girls are to be placed next to each other. What is the probability that there are exactly 4 boys between the 2 girls?,,"$13$ boys and $2$ girls are to be placed next to each. What is the probability that there are exactly $4$ boys between the $2$ girls? Arrangements possible: $GBBBBGBBBBBBBBB$ $BGBBBBGBBBBBBBB$ $BBGBBBBGBBBBBBB$ $BBBGBBBBGBBBBBB$ $BBBBGBBBBGBBBBB$ $BBBBBGBBBBGBBBB$ $BBBBBBGBBBBGBBB$ $BBBBBBBBGBBBBGB$ $BBBBBBBBBGBBBBG$ So the number of ways the arrangement can happen is $C(13,9) = 715$ I need help beyond this to frame the solution.",boys and girls are to be placed next to each. What is the probability that there are exactly boys between the girls? Arrangements possible: So the number of ways the arrangement can happen is I need help beyond this to frame the solution.,"13 2 4 2 GBBBBGBBBBBBBBB BGBBBBGBBBBBBBB BBGBBBBGBBBBBBB BBBGBBBBGBBBBBB BBBBGBBBBGBBBBB BBBBBGBBBBGBBBB BBBBBBGBBBBGBBB BBBBBBBBGBBBBGB BBBBBBBBBGBBBBG C(13,9) = 715","['probability', 'combinatorics']"
13,Probability of exactly two heads in four coin flips?,Probability of exactly two heads in four coin flips?,,"When you flip a coin four times, what is the probability that it will come up heads    exactly twice? My calculation: we have $2$ results for one flip : up or down so flip $4$ times, we have $4\cdot2 = 8$ results total Thus the probability is: $2/ 8 = 0.25 $ but the correct answer is $0.375$. Can anyone explain why I'm wrong?","When you flip a coin four times, what is the probability that it will come up heads    exactly twice? My calculation: we have $2$ results for one flip : up or down so flip $4$ times, we have $4\cdot2 = 8$ results total Thus the probability is: $2/ 8 = 0.25 $ but the correct answer is $0.375$. Can anyone explain why I'm wrong?",,['probability']
14,Why do non-Decreasing Functions have countable discontinuities [duplicate],Why do non-Decreasing Functions have countable discontinuities [duplicate],,"This question already has answers here : How to show that a set of discontinuous points of an increasing function is at most countable (4 answers) Closed 11 years ago . I was reading some notes and one of the results in it implicitly used a result which fell along the lines of ""non-decreasing functions have countable discontinuities"". I don't completely understand why. The notes were essentially describing the properties of a CDF of a ""weird"" random variable. They made the above statement and then concluded (after some more proofs) that the CDF is ""cadlag"".","This question already has answers here : How to show that a set of discontinuous points of an increasing function is at most countable (4 answers) Closed 11 years ago . I was reading some notes and one of the results in it implicitly used a result which fell along the lines of ""non-decreasing functions have countable discontinuities"". I don't completely understand why. The notes were essentially describing the properties of a CDF of a ""weird"" random variable. They made the above statement and then concluded (after some more proofs) that the CDF is ""cadlag"".",,"['real-analysis', 'probability']"
15,probability - 2 cards with same rank,probability - 2 cards with same rank,,"From a deck of 52 cards,What's the probability that he gets a combination of 2 cards with same rank. Eg: 3♥ 3♠","From a deck of 52 cards,What's the probability that he gets a combination of 2 cards with same rank. Eg: 3♥ 3♠",,"['probability', 'probability-theory', 'probability-distributions']"
16,"Choosing Colored Ball, probability of second choice not knowing first","Choosing Colored Ball, probability of second choice not knowing first",,"There are 50 balls in an urn, 30 are red and 20 are blue. If a single ball is taken and we don't look at its color, what is the probability that the second ball is red? I know that there is a 60% chance of choosing a red ball from the first choice, and 40% of not. That means for the second ball there is either (29 choose 1)/(49 choose 1) 60% of the time or (30 choose 1)/(49 choose 1) 40% of the time. I then multiplied the probabilities (60% and 40%) by each of the options and got a 60% chance of the second ball being red. Is this the correct way to approach this problem?","There are 50 balls in an urn, 30 are red and 20 are blue. If a single ball is taken and we don't look at its color, what is the probability that the second ball is red? I know that there is a 60% chance of choosing a red ball from the first choice, and 40% of not. That means for the second ball there is either (29 choose 1)/(49 choose 1) 60% of the time or (30 choose 1)/(49 choose 1) 40% of the time. I then multiplied the probabilities (60% and 40%) by each of the options and got a 60% chance of the second ball being red. Is this the correct way to approach this problem?",,"['probability', 'combinatorics', 'discrete-mathematics']"
17,What is the meaning of $X^{2}$?,What is the meaning of ?,X^{2},"Can you let me know the meaning of $X^{2}$ where X is a random variable? (Please, give me an example in real life and explain the meaning of $X^{2}$?)","Can you let me know the meaning of $X^{2}$ where X is a random variable? (Please, give me an example in real life and explain the meaning of $X^{2}$?)",,['probability']
18,What is the probability of choosing real numbers over two intervals and them being equal?,What is the probability of choosing real numbers over two intervals and them being equal?,,"You are given two intervals $[0,n_1]$ and $[0,n_2]$. What is the probability that real number chosen independently from both the intervals will be equal?","You are given two intervals $[0,n_1]$ and $[0,n_2]$. What is the probability that real number chosen independently from both the intervals will be equal?",,"['probability', 'combinatorics']"
19,"Drawing two cards from 52, what is the probability that the second card has a higher face value than the first?","Drawing two cards from 52, what is the probability that the second card has a higher face value than the first?",,"So if I draw two cards from 52, what is the probability that the second card has a higher face value than the first? The values of the cards are Ace = 1, Two = 2,..., King = 13. I got as far as $$\frac{13 \choose 1}{52 \choose 2}$$.. i.e. choosing the first card from 13 cards. But I don't how I am supposed to take account of choosing the second card.","So if I draw two cards from 52, what is the probability that the second card has a higher face value than the first? The values of the cards are Ace = 1, Two = 2,..., King = 13. I got as far as $$\frac{13 \choose 1}{52 \choose 2}$$.. i.e. choosing the first card from 13 cards. But I don't how I am supposed to take account of choosing the second card.",,"['probability', 'combinatorics']"
20,Can a vertical line be a valid PDF?,Can a vertical line be a valid PDF?,,"Consider a random variable X that always takes a single value, c. I would think that a valid PDF for X would be $$f(x) = \begin{cases} 1/c & x = c \\ 0 & \text{Otherwise}\end{cases}$$ However, I know the PDF is supposed to be the derivative of the CDF, and in this case derivative of F(x) would be 0, both when $x<c$ and when $x\geq c$ What am I missing ?","Consider a random variable X that always takes a single value, c. I would think that a valid PDF for X would be $$f(x) = \begin{cases} 1/c & x = c \\ 0 & \text{Otherwise}\end{cases}$$ However, I know the PDF is supposed to be the derivative of the CDF, and in this case derivative of F(x) would be 0, both when $x<c$ and when $x\geq c$ What am I missing ?",,"['probability', 'probability-distributions']"
21,What are the odd of a single coin toss after many consecutive ones?,What are the odd of a single coin toss after many consecutive ones?,,"I have little knowledge of probability and have recently been thinking of a math problem I am sure you guys could answer If for example I tossed a coin ten times and got all heads, would the odds of the next coin toss beeing heads be 50 50 or s very low as the odds of getting 11 in a row is tiny? Thanks","I have little knowledge of probability and have recently been thinking of a math problem I am sure you guys could answer If for example I tossed a coin ten times and got all heads, would the odds of the next coin toss beeing heads be 50 50 or s very low as the odds of getting 11 in a row is tiny? Thanks",,['probability']
22,Selfish Trolley Car Debate,Selfish Trolley Car Debate,,"So, I'm in disagreement with my boyfriend over the following scenario: given the trolley car problem (1 person on one track and 5 people on a second track, an out of control trolley car will kill the 5 unless you pull the lever to kill the 1), he knows that one of the people is me and the other 5 are strangers. Since I'm amazing, he selfishly wants to maximize the chance that I survive. His solution: he says he would pull the lever to save the five people. Since he doesn't know which one I am, he should save the most people to maximize the chance of saving me. My solution: I say I wish he would put more thought into saving me. Instead of assuming a uniform distribution on my position, he should assume a uniform distribution on all distributions. So, he should pull the lever with 5/6 probability and let it kill the 5 with 1/6 probability. So, what's the right answer? Is there even a right answer? Update People keep downvoting the correct answer, so I'll put it here. The correct answer is neither one of the suggestions. The assumption of no information about my placement means there is no prior information from which to draw a probability of survival. That means there is only one strategy where this probability is even defined: to pull the lever with probability $1/2$ . This trivially maximizes the survival probability ( $1/2$ ), since it is the only probability.","So, I'm in disagreement with my boyfriend over the following scenario: given the trolley car problem (1 person on one track and 5 people on a second track, an out of control trolley car will kill the 5 unless you pull the lever to kill the 1), he knows that one of the people is me and the other 5 are strangers. Since I'm amazing, he selfishly wants to maximize the chance that I survive. His solution: he says he would pull the lever to save the five people. Since he doesn't know which one I am, he should save the most people to maximize the chance of saving me. My solution: I say I wish he would put more thought into saving me. Instead of assuming a uniform distribution on my position, he should assume a uniform distribution on all distributions. So, he should pull the lever with 5/6 probability and let it kill the 5 with 1/6 probability. So, what's the right answer? Is there even a right answer? Update People keep downvoting the correct answer, so I'll put it here. The correct answer is neither one of the suggestions. The assumption of no information about my placement means there is no prior information from which to draw a probability of survival. That means there is only one strategy where this probability is even defined: to pull the lever with probability . This trivially maximizes the survival probability ( ), since it is the only probability.",1/2 1/2,[]
23,Quick evaluation of the Gamma function?,Quick evaluation of the Gamma function?,,"I am given an exercise about the beta distribution, with a solution: EXAMPLE 4.11 A gasoline wholesale distributor has bulk storage tanks that hold fixed supplies and are filled every Monday. Of interest to the wholesaler is the proportion of this supply that is sold during the week. Over many weeks of observation, the distributor found that this proportion could be modeled by a beta distribution with $\alpha = 4$ and $\beta = 2$. Find the probability that the wholesaler will sell at least $90\%$ of her stock in a given week. Solution If $Y$ denotes the proportion sold during the week, then   $$f(y) = \begin{cases} \frac{\Gamma(4 + 2)}{\Gamma(4)\Gamma(2)}y^3 (1 - y), & 0 \le y \le 1, \\ 0, & \text{elsewhere,} \end{cases}$$   and   $$P(Y \lt .9) = \int_.9^\infty f(y) dy = \int_.9^1 20(y^3 - y^4)dy \\ = 20 \left\{ \left. \frac{y^4}4 \right]_.9^1 - \left. \frac{y^5}5 \right]_.9^1 \right\} = 20(.004) = .08.$$   It is not very likely that $90\%$ of the stock will be sold in a given week. In this exercise they claim that $$\frac{\Gamma(4+2)}{\Gamma(4)\Gamma(2)}=20$$ without any explicit calculations of the integral. Moreover, it seems that the result is simply $(4+2-1)(4-1 + 2-1)=5*4=20$. What shortcut did they use to compute the gamma distribution without the need for explicit computation?","I am given an exercise about the beta distribution, with a solution: EXAMPLE 4.11 A gasoline wholesale distributor has bulk storage tanks that hold fixed supplies and are filled every Monday. Of interest to the wholesaler is the proportion of this supply that is sold during the week. Over many weeks of observation, the distributor found that this proportion could be modeled by a beta distribution with $\alpha = 4$ and $\beta = 2$. Find the probability that the wholesaler will sell at least $90\%$ of her stock in a given week. Solution If $Y$ denotes the proportion sold during the week, then   $$f(y) = \begin{cases} \frac{\Gamma(4 + 2)}{\Gamma(4)\Gamma(2)}y^3 (1 - y), & 0 \le y \le 1, \\ 0, & \text{elsewhere,} \end{cases}$$   and   $$P(Y \lt .9) = \int_.9^\infty f(y) dy = \int_.9^1 20(y^3 - y^4)dy \\ = 20 \left\{ \left. \frac{y^4}4 \right]_.9^1 - \left. \frac{y^5}5 \right]_.9^1 \right\} = 20(.004) = .08.$$   It is not very likely that $90\%$ of the stock will be sold in a given week. In this exercise they claim that $$\frac{\Gamma(4+2)}{\Gamma(4)\Gamma(2)}=20$$ without any explicit calculations of the integral. Moreover, it seems that the result is simply $(4+2-1)(4-1 + 2-1)=5*4=20$. What shortcut did they use to compute the gamma distribution without the need for explicit computation?",,"['calculus', 'probability', 'statistics', 'gamma-function', 'beta-function']"
24,Prove that $E((X-a)^2)$ is minimized when $a=E(X)$,Prove that  is minimized when,E((X-a)^2) a=E(X),$X$ is an arbitrary continuous random variable. I tried to do this by saying since $X-a$ is squared that means its lowest possible value is 0 and then I tried to solve for $a$ when the expression is $0$. $$ \begin{align} E((X-a)^2)&=0\\ E(X^2)-2aE(X) +a^2&=0\\ a^2-2aE(X)+E(X)^2&=E(X)^2-E(X^2)\\ (a-E(X))^2&=E(X)^2-E(X^2)\\ a-E(X)&=\sqrt{(E(X))^2-E(X^2)}\\ a&=E(X) \pm\sqrt{(E(X))^2-E(X^2)}\\ \end{align} $$ Now I don't know if there's some trick to say that $\sqrt{(E(X))^2-E(X^2)}=0$ or if I'm barking up the wrong tree with this approach.,$X$ is an arbitrary continuous random variable. I tried to do this by saying since $X-a$ is squared that means its lowest possible value is 0 and then I tried to solve for $a$ when the expression is $0$. $$ \begin{align} E((X-a)^2)&=0\\ E(X^2)-2aE(X) +a^2&=0\\ a^2-2aE(X)+E(X)^2&=E(X)^2-E(X^2)\\ (a-E(X))^2&=E(X)^2-E(X^2)\\ a-E(X)&=\sqrt{(E(X))^2-E(X^2)}\\ a&=E(X) \pm\sqrt{(E(X))^2-E(X^2)}\\ \end{align} $$ Now I don't know if there's some trick to say that $\sqrt{(E(X))^2-E(X^2)}=0$ or if I'm barking up the wrong tree with this approach.,,['probability']
25,Probability that the ball drawn from $n$th urn is white,Probability that the ball drawn from th urn is white,n,"There are $n$ urns each having $a$ white and $b$ black balls. One ball is taken from urn 1 and is transferred to urn 2. Then one ball is taken from urn 2 and transferred to urn 3 and so on. Find the probability that the ball drawn from $n$th urn is white. I get the intuition that the answer should be $\frac{a}{a+b}$, but I'm unable to prove it.","There are $n$ urns each having $a$ white and $b$ black balls. One ball is taken from urn 1 and is transferred to urn 2. Then one ball is taken from urn 2 and transferred to urn 3 and so on. Find the probability that the ball drawn from $n$th urn is white. I get the intuition that the answer should be $\frac{a}{a+b}$, but I'm unable to prove it.",,['probability']
26,"Probability measures, Integral","Probability measures, Integral",,"I had a test and was asked to prove that, with $\Omega = (0,1)$, $$ \mathbb{P}(B)= \frac32 \int_B \sqrt{x} \,dx, $$ is a probability measure, meaning it has to satisfy that $\mathbb{P}(\Omega)=1$, but had the condition $0 < x < 1$ (i.e. $B \subseteq \Omega$). I agree that $$\mathbb{P}(\Omega) = \left. x^{3/2}\right|_0^1 = 1,$$ but $x$ can’t take those values, so $\mathbb{P}(\Omega)$ cannot be equal to 1, which means that $\mathbb{P}(B)$ is not a probability measure. But my teacher insists that it is an integral, so taking away those points doesn’t affects the area, I don’t know which is the right answer because I don’t understand that argument, because an area is a group of “dots” joined together.","I had a test and was asked to prove that, with $\Omega = (0,1)$, $$ \mathbb{P}(B)= \frac32 \int_B \sqrt{x} \,dx, $$ is a probability measure, meaning it has to satisfy that $\mathbb{P}(\Omega)=1$, but had the condition $0 < x < 1$ (i.e. $B \subseteq \Omega$). I agree that $$\mathbb{P}(\Omega) = \left. x^{3/2}\right|_0^1 = 1,$$ but $x$ can’t take those values, so $\mathbb{P}(\Omega)$ cannot be equal to 1, which means that $\mathbb{P}(B)$ is not a probability measure. But my teacher insists that it is an integral, so taking away those points doesn’t affects the area, I don’t know which is the right answer because I don’t understand that argument, because an area is a group of “dots” joined together.",,"['calculus', 'probability', 'integration', 'definite-integrals']"
27,Probability Interview Question - Brain teaser,Probability Interview Question - Brain teaser,,"Player A has a thirty-sided and Player B has a twenty-sided die. They both roll the dies and whoever gets the higher roll wins. If they roll the same amount Player B wins. What is the probability that Player B win? So I have $$1 - \left(\frac{1}{3}+\frac{1}{2}\cdot\frac{2}{3}-\frac{1}{30}\right) = \frac{11}{30}.$$ There is $100\%$ chance of winning when A roll from 20 - 30 but for the rest $2/3$ there is only $50\%$ chance of winning, in addition, there is $1/30$ of chance that player A could roll the same number as B The answer for this question should be $0.35$, I am not sure where I did wrong. I just figured maybe I should do this instead $1 - (\frac{1}{3}+(\frac{1}{2}-\frac{1}{30})\cdot\frac{2}{3}) = \frac{16}{45}$ is this right ?","Player A has a thirty-sided and Player B has a twenty-sided die. They both roll the dies and whoever gets the higher roll wins. If they roll the same amount Player B wins. What is the probability that Player B win? So I have $$1 - \left(\frac{1}{3}+\frac{1}{2}\cdot\frac{2}{3}-\frac{1}{30}\right) = \frac{11}{30}.$$ There is $100\%$ chance of winning when A roll from 20 - 30 but for the rest $2/3$ there is only $50\%$ chance of winning, in addition, there is $1/30$ of chance that player A could roll the same number as B The answer for this question should be $0.35$, I am not sure where I did wrong. I just figured maybe I should do this instead $1 - (\frac{1}{3}+(\frac{1}{2}-\frac{1}{30})\cdot\frac{2}{3}) = \frac{16}{45}$ is this right ?",,['probability']
28,Rolling a die until obtaining the face 6. Whats the expected amout of the sum?,Rolling a die until obtaining the face 6. Whats the expected amout of the sum?,,"A game where you roll a fair die, repeatedly, adding up the faces that show up, until the face 6 appears. What is the expected sum (including the 6)? All I can think of is that the expected value of each roll is $7/2$. I'd appreciate your help!","A game where you roll a fair die, repeatedly, adding up the faces that show up, until the face 6 appears. What is the expected sum (including the 6)? All I can think of is that the expected value of each roll is $7/2$. I'd appreciate your help!",,['probability']
29,"Suppose $X, Y$ are random variables with the equal variance. Show that $X-Y$ and $X+Y$ are uncorrelated.",Suppose  are random variables with the equal variance. Show that  and  are uncorrelated.,"X, Y X-Y X+Y",Suppose that $X$ and $Y$ are random variables with the equal variance. Show that $X-Y$ and $X+Y$ are uncorrelated. I get I should use the equation  $$E[XY] = E[X]E[Y]$$ For the first part I get $$E[(X-Y)(X+Y)] = E[X^2-Y^2] = E[X^2] - E[Y^2]$$ And I don't know how to follow. Someone has any ideas? Thank you.,Suppose that $X$ and $Y$ are random variables with the equal variance. Show that $X-Y$ and $X+Y$ are uncorrelated. I get I should use the equation  $$E[XY] = E[X]E[Y]$$ For the first part I get $$E[(X-Y)(X+Y)] = E[X^2-Y^2] = E[X^2] - E[Y^2]$$ And I don't know how to follow. Someone has any ideas? Thank you.,,"['probability', 'random-variables', 'expectation', 'correlation']"
30,"Find the probability of $a>b+c$, where $a$, $b$, $c$ are $U(0,1)$","Find the probability of , where , ,  are","a>b+c a b c U(0,1)","What is the probability that $a > b + c$? $a, b, c$ are picked independently and uniformly at random from bounded interval [0,1] of $\mathbb{R}$.","What is the probability that $a > b + c$? $a, b, c$ are picked independently and uniformly at random from bounded interval [0,1] of $\mathbb{R}$.",,"['probability', 'uniform-distribution']"
31,Probability of an odd number in 10/20 lotto,Probability of an odd number in 10/20 lotto,,"Say you have a lotto game 10/20, which means that 10 balls are drawn from 20. How can I calculate what are the odds that the lowest drawn number is odd (and also how can I calculate the odds if it's even)? So a detailed explanation: we have numbers 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 and 20 and the drawn numbers were for example 3, 5, 8, 11, 12, 13, 14, 15, 18 and 19 so, we see now that lowest number is 3 and he is an odd number. So, as stated above, can you help me in finding out how to calculate such probability?","Say you have a lotto game 10/20, which means that 10 balls are drawn from 20. How can I calculate what are the odds that the lowest drawn number is odd (and also how can I calculate the odds if it's even)? So a detailed explanation: we have numbers 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19 and 20 and the drawn numbers were for example 3, 5, 8, 11, 12, 13, 14, 15, 18 and 19 so, we see now that lowest number is 3 and he is an odd number. So, as stated above, can you help me in finding out how to calculate such probability?",,['probability']
32,"Chance of generating two zeros in a row, compared to chance of generating a zero and a one in a row when generating random numbers between 0 and 5?? [closed]","Chance of generating two zeros in a row, compared to chance of generating a zero and a one in a row when generating random numbers between 0 and 5?? [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 months ago . Improve this question I tried to code a simple python program which does the following: it generates random numbers between 0 and 5 until a zero is generated twice in a row. it does this N times and calculates the average number of generated numbers needed to get two zeroes in a row. The second part of the program does exactly the same, except it stops when 1 is generated after a 0. I expected the average number of repetitions needed in both cases would be about the same, but there is a notable difference. I cannot find an error in my code, nor in my intuition. But there is certainly an error in one (or both). I tried to simplify my code as much as I could: import math  import random as rnd   def null_null():     ct=0     first=(math.floor(rnd.random()*6))     second=(math.floor(rnd.random()*6))       while (first!=0 or second!=0):         first=second         second=(math.floor(rnd.random()*6))         ct+=1     return ct  def null_one():     ct=0     first=(math.floor(rnd.random()*6))     second=(math.floor(rnd.random()*6))       while (first!=0 or second!=1):         first=second         second=(math.floor(rnd.random()*6))         ct+=1     return ct   res1=res2=0  N=1000 for i in range(N):          res1+=null_null()     res2+=null_one()   print(""Average for 0-0: "", res1/N) print(""Average for 0-1: "", res2/N)","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 months ago . Improve this question I tried to code a simple python program which does the following: it generates random numbers between 0 and 5 until a zero is generated twice in a row. it does this N times and calculates the average number of generated numbers needed to get two zeroes in a row. The second part of the program does exactly the same, except it stops when 1 is generated after a 0. I expected the average number of repetitions needed in both cases would be about the same, but there is a notable difference. I cannot find an error in my code, nor in my intuition. But there is certainly an error in one (or both). I tried to simplify my code as much as I could: import math  import random as rnd   def null_null():     ct=0     first=(math.floor(rnd.random()*6))     second=(math.floor(rnd.random()*6))       while (first!=0 or second!=0):         first=second         second=(math.floor(rnd.random()*6))         ct+=1     return ct  def null_one():     ct=0     first=(math.floor(rnd.random()*6))     second=(math.floor(rnd.random()*6))       while (first!=0 or second!=1):         first=second         second=(math.floor(rnd.random()*6))         ct+=1     return ct   res1=res2=0  N=1000 for i in range(N):          res1+=null_null()     res2+=null_one()   print(""Average for 0-0: "", res1/N) print(""Average for 0-1: "", res2/N)",,"['probability', 'statistics', 'computer-science', 'programming']"
33,What is the difference between a random variable and an event?,What is the difference between a random variable and an event?,,"In layman terms, what is the difference between a random variable and an event? To my understanding a random variable is a function outputting a real number. And an event is an outcome or a set of outcomes.","In layman terms, what is the difference between a random variable and an event? To my understanding a random variable is a function outputting a real number. And an event is an outcome or a set of outcomes.",,"['probability', 'statistics', 'random-variables']"
34,Probabilities in a binomial distribution not summing to one?,Probabilities in a binomial distribution not summing to one?,,"I am having an issue with what seems to me to be a quite simple binomial distribution problem: There are five members in my family, two of whom are male. My question is: what are the probabilities of choosing 0, 1 and 2 males if the number of trials ($n$) is three? My assumptions are as follows: Probability for success ($p$) is $0.4$ (two males divided by five total family members) The compliment for that probability is $0.6$ ($1 - p$) The number of trials per experiment ($n$) is $3$ (i.e. I am picking three members of the family at random each time) The formula I am using for the binomial distribution is this: $$P(x) = \frac{N!}{x!  (N-x)!}  p ^ x q^{(N-x)}$$ The issue I am coming across is that when I calculate the probabilities of the outcomes (0, 1, 2) I receive the following outputs respectively: $0.2160$ $0.4320$ $0.2880$ These outputs sum to only $0.9360$. However, when I include a third $x$ ($x = 3$), I receive a probability of $0.0640$. when this probability is included the sum of all probabilities is 1. My question is how can this be possible in a situation where there are only 2 males in the family of 5? Shouldn't the probability of picking 3 males be impossible (i.e. zero probability)? Am I misunderstanding the nature of my problem? Or the nature of the binomial distribution?","I am having an issue with what seems to me to be a quite simple binomial distribution problem: There are five members in my family, two of whom are male. My question is: what are the probabilities of choosing 0, 1 and 2 males if the number of trials ($n$) is three? My assumptions are as follows: Probability for success ($p$) is $0.4$ (two males divided by five total family members) The compliment for that probability is $0.6$ ($1 - p$) The number of trials per experiment ($n$) is $3$ (i.e. I am picking three members of the family at random each time) The formula I am using for the binomial distribution is this: $$P(x) = \frac{N!}{x!  (N-x)!}  p ^ x q^{(N-x)}$$ The issue I am coming across is that when I calculate the probabilities of the outcomes (0, 1, 2) I receive the following outputs respectively: $0.2160$ $0.4320$ $0.2880$ These outputs sum to only $0.9360$. However, when I include a third $x$ ($x = 3$), I receive a probability of $0.0640$. when this probability is included the sum of all probabilities is 1. My question is how can this be possible in a situation where there are only 2 males in the family of 5? Shouldn't the probability of picking 3 males be impossible (i.e. zero probability)? Am I misunderstanding the nature of my problem? Or the nature of the binomial distribution?",,"['probability', 'binomial-distribution']"
35,Expectation of Double Dice Throw,Expectation of Double Dice Throw,,"I was wondering about finding expected value of dice throw. I know that in case of single dice throw,the expected value is 3.5 = ((1+2+3+4+5+6)/6). So for purpose of betting the base price could be 3.5 to ensure no profit and no loss scenario. But how can I extend this logic for double dice throw or N dice throw. I though that for case of double dice out of the 36 cases, I could take the maximum value for each pair which would give 6 eleven times, 5 nine times, 4 seven times, 3 five times , 2 three times and 1 once. But this gave expected value to be 4.47, whereas the correct answer in book is 4.25. How can I determine the fair value in this case?","I was wondering about finding expected value of dice throw. I know that in case of single dice throw,the expected value is 3.5 = ((1+2+3+4+5+6)/6). So for purpose of betting the base price could be 3.5 to ensure no profit and no loss scenario. But how can I extend this logic for double dice throw or N dice throw. I though that for case of double dice out of the 36 cases, I could take the maximum value for each pair which would give 6 eleven times, 5 nine times, 4 seven times, 3 five times , 2 three times and 1 once. But this gave expected value to be 4.47, whereas the correct answer in book is 4.25. How can I determine the fair value in this case?",,"['probability', 'expectation']"
36,Are set differences in a sigma algebra?,Are set differences in a sigma algebra?,,"I am confused as to whether or not the difference of two sets (A\B...the elements in set A that aren't in set B). I think they are. We know that a $\sigma$-field is both a $\pi$ system and a $\lambda$ system. By the definition of a $\lambda$ system, if we have A in the system, then so too $A^c$. We get the same with B and $B^c$ We also get that the intersection of A and B are in the $\sigma$-field by the fact that it is a $\pi$ system. So, I believe that the set difference of A and B should be in the sigma field. However, I've never heard anyone speak about the set difference of two sets being in the sigma field, only the normal ""compliments and countable unions of sets"". This seems like a good thing to have on hand if you are asked to write out the sigma field of a small discrete$\Omega$ by hand. By using set differences, you could generate the singletons, and then build up from there.","I am confused as to whether or not the difference of two sets (A\B...the elements in set A that aren't in set B). I think they are. We know that a $\sigma$-field is both a $\pi$ system and a $\lambda$ system. By the definition of a $\lambda$ system, if we have A in the system, then so too $A^c$. We get the same with B and $B^c$ We also get that the intersection of A and B are in the $\sigma$-field by the fact that it is a $\pi$ system. So, I believe that the set difference of A and B should be in the sigma field. However, I've never heard anyone speak about the set difference of two sets being in the sigma field, only the normal ""compliments and countable unions of sets"". This seems like a good thing to have on hand if you are asked to write out the sigma field of a small discrete$\Omega$ by hand. By using set differences, you could generate the singletons, and then build up from there.",,"['probability', 'measure-theory', 'probability-theory']"
37,What's wrong with this 'proof' that probability of being $2$ m away is $1/9$?,What's wrong with this 'proof' that probability of being  m away is ?,2 1/9,"Suppose there is a chicken (which we will assume to simply be a point), which is encolsed in a circular barn of radius $6$ m. At the centre of the barn, there is a well, (which we will also assume to simply be a point). If the chicken was equally likely to be at any point within the barn, what is the probability that the chicken is exactly $2$ m away from the well? I know it should be zero , since this is a continuous distribution. However, I was wondering, what goes wrong in the following reasoning to obtain an answer which isn't zero. The only way for the chicken to be exactly $2$ m away from the well, is if it were confined to a concentric circle of radius $2$ m at the well. The length of the circumference can then be thought of as all the possible points the chicken could be at in order to be $2$ m away from the well, so that's $2\pi r' = 2\pi(2) = 4\pi$ . All the possible points in the barn is simply the area, so that's $\pi r^2 = \pi(6^2) = 36\pi$ . Hence, if we let $X$ be the random variable of how far the chicken is away from the well, then $$ \mathbb{P}(X = 2) = \dfrac{4\pi}{36\pi} = \dfrac{1}{9}. $$ So to be extra clear: Question: What goes wrong in the reasoning above? Thank you for any help.","Suppose there is a chicken (which we will assume to simply be a point), which is encolsed in a circular barn of radius m. At the centre of the barn, there is a well, (which we will also assume to simply be a point). If the chicken was equally likely to be at any point within the barn, what is the probability that the chicken is exactly m away from the well? I know it should be zero , since this is a continuous distribution. However, I was wondering, what goes wrong in the following reasoning to obtain an answer which isn't zero. The only way for the chicken to be exactly m away from the well, is if it were confined to a concentric circle of radius m at the well. The length of the circumference can then be thought of as all the possible points the chicken could be at in order to be m away from the well, so that's . All the possible points in the barn is simply the area, so that's . Hence, if we let be the random variable of how far the chicken is away from the well, then So to be extra clear: Question: What goes wrong in the reasoning above? Thank you for any help.",6 2 2 2 2 2\pi r' = 2\pi(2) = 4\pi \pi r^2 = \pi(6^2) = 36\pi X  \mathbb{P}(X = 2) = \dfrac{4\pi}{36\pi} = \dfrac{1}{9}. ,"['probability', 'fake-proofs']"
38,"$\sum_{A\in2^\Omega}P(A)=2^{|\Omega|-1}$ for probability space $(\Omega,2^\Omega,P)$ with finite $\Omega$",for probability space  with finite,"\sum_{A\in2^\Omega}P(A)=2^{|\Omega|-1} (\Omega,2^\Omega,P) \Omega","I'm looking for a combinatorial argument to complete a proof (below) of the following: Claim : If $(\Omega,2^\Omega,P)$ is a probability space with finite $\Omega,$ then $\sum_{A\in2^\Omega}P(A)=2^{|\Omega|-1}.$ In other words, if $\Omega$ is finite and every subset of $\Omega$ is considered an event, then the sum of all the event-probabilities must equal $2^{|\Omega|-1}.$ Proof: Let $\Omega=\{\omega_1,...,\omega_n\}$ and $p_i=P(\{\omega_i\}).$ Then, by summing over subsets of successively larger size, $$\begin{align*}&\sum_{A\in\cal 2^\Omega}P(A)\\ &=P(\emptyset)+\sum_{1\le i_1\le n}P\{\omega_{i_1}\}+\sum_{1\le i_1<i_2\le n}P(\{\omega_{i_1},\omega_{i_2}\})+...+\sum_{1\le i_1<...<i_t\le n}P(\{\omega_{i_1},...,\omega_{i_t}\})+...+P(\Omega)\\[3ex] &=\sum_{1\le i_1\le n}p_{i_1}+\sum_{1\le i_1<i_2\le n}(p_{i_1}+p_{i_2})+...+\sum_{1\le i_1<...<i_t\le n}(p_{i_1}+...+p_{i_t})+...+P(\Omega)\\[3ex] &\overset{(*)}{=}\binom{n-1}{1-1}+\binom{n-1}{2-1}+...+\binom{n-1}{t-1}+...+\binom{n-1}{n-1}\\[3ex] &=2^{n-1} \end{align*}$$ The step marked $\overset{(*)}{=}$ would be justified by showing that in every sum $\sum_{1\le i_1<...<i_t\le n}(p_{i_1}+...+p_{i_t}),$ for $t=1,...,n,$ each of the $p_i (i=1,...,n)$ appears exactly $\binom{n-1}{t-1}$ times (noting of course that the sum of the $p_i (i=1,...,n)$ is $1$ ). For example, if $n=4$ then for $t=2$ we have $\sum_{1\le i_1<i_2\le 4}(p_{i_1}+p_{i_2})=(p_1+p_2)+(p_1+p_3)+(p_1+p_4)+(p_2+p_3)+(p_2+p_4)+(p_3+p_4)=3,$ as we see that each $p_i$ appears $\binom{4-1}{2-1}=3$ times. Can anyone provide insight as to why this is generally the case? (Or perhaps give an alternative method of proof?) EDIT: As mentioned in comments, the accepted answer provides a method that proves the following much more general result: If $(\Omega,\mathcal F,P)$ is a probability space with finite $\sigma$ -field $\mathcal F$ , then $\sum_{A\in\mathcal F}P(A)={1\over 2}|\mathcal F|.$ I.e., ""the sum of all the event-probabilities must equal half the number of events"".","I'm looking for a combinatorial argument to complete a proof (below) of the following: Claim : If is a probability space with finite then In other words, if is finite and every subset of is considered an event, then the sum of all the event-probabilities must equal Proof: Let and Then, by summing over subsets of successively larger size, The step marked would be justified by showing that in every sum for each of the appears exactly times (noting of course that the sum of the is ). For example, if then for we have as we see that each appears times. Can anyone provide insight as to why this is generally the case? (Or perhaps give an alternative method of proof?) EDIT: As mentioned in comments, the accepted answer provides a method that proves the following much more general result: If is a probability space with finite -field , then I.e., ""the sum of all the event-probabilities must equal half the number of events"".","(\Omega,2^\Omega,P) \Omega, \sum_{A\in2^\Omega}P(A)=2^{|\Omega|-1}. \Omega \Omega 2^{|\Omega|-1}. \Omega=\{\omega_1,...,\omega_n\} p_i=P(\{\omega_i\}). \begin{align*}&\sum_{A\in\cal 2^\Omega}P(A)\\
&=P(\emptyset)+\sum_{1\le i_1\le n}P\{\omega_{i_1}\}+\sum_{1\le i_1<i_2\le n}P(\{\omega_{i_1},\omega_{i_2}\})+...+\sum_{1\le i_1<...<i_t\le n}P(\{\omega_{i_1},...,\omega_{i_t}\})+...+P(\Omega)\\[3ex]
&=\sum_{1\le i_1\le n}p_{i_1}+\sum_{1\le i_1<i_2\le n}(p_{i_1}+p_{i_2})+...+\sum_{1\le i_1<...<i_t\le n}(p_{i_1}+...+p_{i_t})+...+P(\Omega)\\[3ex]
&\overset{(*)}{=}\binom{n-1}{1-1}+\binom{n-1}{2-1}+...+\binom{n-1}{t-1}+...+\binom{n-1}{n-1}\\[3ex]
&=2^{n-1}
\end{align*} \overset{(*)}{=} \sum_{1\le i_1<...<i_t\le n}(p_{i_1}+...+p_{i_t}), t=1,...,n, p_i (i=1,...,n) \binom{n-1}{t-1} p_i (i=1,...,n) 1 n=4 t=2 \sum_{1\le i_1<i_2\le 4}(p_{i_1}+p_{i_2})=(p_1+p_2)+(p_1+p_3)+(p_1+p_4)+(p_2+p_3)+(p_2+p_4)+(p_3+p_4)=3, p_i \binom{4-1}{2-1}=3 (\Omega,\mathcal F,P) \sigma \mathcal F \sum_{A\in\mathcal F}P(A)={1\over 2}|\mathcal F|.","['probability', 'combinatorics', 'probability-theory', 'combinatorial-proofs']"
39,10 good and 3 bad batteries are mixed and then 5 are chosen. What is the probability of the fifth one being dead given that the first 4 aren't?,10 good and 3 bad batteries are mixed and then 5 are chosen. What is the probability of the fifth one being dead given that the first 4 aren't?,,"I approached this as follows: $A$ : First four are good, $B$ : Fifth one is bad. Then $$|A|={10\choose4}$$ because this is the number of ways we can choose 4 good batteries from the available 10. Then $$P(A)=\frac{10\choose4}{13\choose4}$$ I want to find $P(B|A)=\frac{P(A\cap B)}{P(A)}$ . For this I need: $A\cap B$ : First four are good and fifth one is dead. Then $|A\cap B|={10\choose4}{3\choose1}$ because this is the number of ways we can choose 4 good batteries from the available 10 followed by choosing 1 of the available 3 dead ones. Then $$P(A\cap B)=\frac{{10\choose4}\cdot{3\choose1}}{13\choose5}$$ However, once a substitute these values into the conitional probability expression I get $\frac53$ .","I approached this as follows: : First four are good, : Fifth one is bad. Then because this is the number of ways we can choose 4 good batteries from the available 10. Then I want to find . For this I need: : First four are good and fifth one is dead. Then because this is the number of ways we can choose 4 good batteries from the available 10 followed by choosing 1 of the available 3 dead ones. Then However, once a substitute these values into the conitional probability expression I get .",A B |A|={10\choose4} P(A)=\frac{10\choose4}{13\choose4} P(B|A)=\frac{P(A\cap B)}{P(A)} A\cap B |A\cap B|={10\choose4}{3\choose1} P(A\cap B)=\frac{{10\choose4}\cdot{3\choose1}}{13\choose5} \frac53,"['probability', 'combinatorics', 'conditional-probability']"
40,How are all possible poker hands of equal probability?,How are all possible poker hands of equal probability?,,"Please pardon the elementary question, for some reason I'm not grocking why all possible poker hand combinations are equally probable, as all textbooks and websites say. Just intuitively I would think getting 4 of a number is much more improbably than getting 1 of each number, if I were to draw 4 cards. For example, ignoring order, to get 4 of a single number there are only $4 \choose 4$ distinct possibilities, whereas for 1 of each number I would have ${4 \choose 1}^4$ distinct possibilities.","Please pardon the elementary question, for some reason I'm not grocking why all possible poker hand combinations are equally probable, as all textbooks and websites say. Just intuitively I would think getting 4 of a number is much more improbably than getting 1 of each number, if I were to draw 4 cards. For example, ignoring order, to get 4 of a single number there are only distinct possibilities, whereas for 1 of each number I would have distinct possibilities.",4 \choose 4 {4 \choose 1}^4,"['probability', 'poker']"
41,Suppose that $E[X^n] = 3n$. Find $E[e^X]$...,Suppose that . Find ...,E[X^n] = 3n E[e^X],"Suppose that $E[X^n] = 3n$. Find $E[e^X]$. Hint from my professor: $e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} +···$ Not quite sure how to solve this problem, wouldn't $e^x$ go on exponentially. Any help is really appreciated.","Suppose that $E[X^n] = 3n$. Find $E[e^X]$. Hint from my professor: $e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} +···$ Not quite sure how to solve this problem, wouldn't $e^x$ go on exponentially. Any help is really appreciated.",,"['probability', 'statistics', 'random-variables']"
42,Central Limit Theorem and Mean time between failures,Central Limit Theorem and Mean time between failures,,"I was reading up about RAID, and the text said: Suppose that the mean time to failure of a single disk is $100000$   hours. Then the mean time to failure of some disk in an array of 100   disks will be $\frac{100000}{100} = 1000$ hours, or $41.66$ days I don't understand this. Why should the average lifetime of a disk reduce if the number of disks increases? Let's say $X_i$ is a random variable that equals the life of $i^{\text{th}}$ disk. All $X_i$'s are identically distributed and independent. Then, by Central limit theorem: $$\hat{X} = \dfrac{X_1 + X_2 + \ldots + X_N} { N }$$ follows normal distribution as $N \to \infty $, with mean $E(X_i)$. What's wrong with this way of thinking?","I was reading up about RAID, and the text said: Suppose that the mean time to failure of a single disk is $100000$   hours. Then the mean time to failure of some disk in an array of 100   disks will be $\frac{100000}{100} = 1000$ hours, or $41.66$ days I don't understand this. Why should the average lifetime of a disk reduce if the number of disks increases? Let's say $X_i$ is a random variable that equals the life of $i^{\text{th}}$ disk. All $X_i$'s are identically distributed and independent. Then, by Central limit theorem: $$\hat{X} = \dfrac{X_1 + X_2 + \ldots + X_N} { N }$$ follows normal distribution as $N \to \infty $, with mean $E(X_i)$. What's wrong with this way of thinking?",,"['probability', 'probability-theory', 'probability-distributions', 'expectation']"
43,Confusion about the range of the sum of i.i.d. random variables,Confusion about the range of the sum of i.i.d. random variables,,"Let $X_1, X_2, ...X_n$ be independent and uniformly distributed random variables on the interval $[0,1]$. Now suppose I wanted to calculate the probability density function of $Z = X_1 + X_2 + ... + X_n$. I think this can be done by $n-1$ successive convolutions, but that's not too important for me right now. My confusion stems from the plot on the bottom which shows the resulting PDF's where $n = 2,3,4,5,6$. Obviously we no longer get a uniformly distributed random variable, but what's puzzling to me is the fact, that the new PDF has range $[0,n]$. This result only makes sense to me if we assume that the $X_i$ actually all have the same range (in this case $0 \leq X_i \leq 1$ for all $i$). Informally, what keeps $X_1$ from being the amount of fuel in a passing car and say $X_2$ the number of passengers in said car?","Let $X_1, X_2, ...X_n$ be independent and uniformly distributed random variables on the interval $[0,1]$. Now suppose I wanted to calculate the probability density function of $Z = X_1 + X_2 + ... + X_n$. I think this can be done by $n-1$ successive convolutions, but that's not too important for me right now. My confusion stems from the plot on the bottom which shows the resulting PDF's where $n = 2,3,4,5,6$. Obviously we no longer get a uniformly distributed random variable, but what's puzzling to me is the fact, that the new PDF has range $[0,n]$. This result only makes sense to me if we assume that the $X_i$ actually all have the same range (in this case $0 \leq X_i \leq 1$ for all $i$). Informally, what keeps $X_1$ from being the amount of fuel in a passing car and say $X_2$ the number of passengers in said car?",,"['probability', 'probability-distributions', 'random-variables']"
44,Is There A Way To Calculate Expected value From Variance And Vice Versa?,Is There A Way To Calculate Expected value From Variance And Vice Versa?,,"If I am given the value of one (just the value), can I calculate the value of the other?","If I am given the value of one (just the value), can I calculate the value of the other?",,['probability']
45,Probability that minimum of two numbers is less than 4,Probability that minimum of two numbers is less than 4,,"Suppose I have to choose two numbers from set $$S=\{1,2,3,4,5,6 \}$$ without a replacement , then what is the probability that minimum of two is less than $4$? I made two groups for this problem $A= \{1,2,3 \}$ and $B=\{4,5,6 \}$ .There are two possibilities , either both are from $A$ or one from $A$ and one from $B$ to satisfy our requirement. Hence $$P(E)=\frac{3}{6}.\frac{2}{5} + \frac{3}{6}.\frac{3}{5}$$ but answer is incorrect. Help?","Suppose I have to choose two numbers from set $$S=\{1,2,3,4,5,6 \}$$ without a replacement , then what is the probability that minimum of two is less than $4$? I made two groups for this problem $A= \{1,2,3 \}$ and $B=\{4,5,6 \}$ .There are two possibilities , either both are from $A$ or one from $A$ and one from $B$ to satisfy our requirement. Hence $$P(E)=\frac{3}{6}.\frac{2}{5} + \frac{3}{6}.\frac{3}{5}$$ but answer is incorrect. Help?",,['probability']
46,Why is Linearity of Expectation so important?,Why is Linearity of Expectation so important?,,"I understand what linearity of expectation is. In short: $E[\sum X_i] = \sum E[X_i] $ However I don't quite see its significance. That is, in what scenario does applying $E[\sum X_i]$ over $\sum E[X_i]$ (or vice versa) make a difference?","I understand what linearity of expectation is. In short: $E[\sum X_i] = \sum E[X_i] $ However I don't quite see its significance. That is, in what scenario does applying $E[\sum X_i]$ over $\sum E[X_i]$ (or vice versa) make a difference?",,"['probability', 'probability-theory']"
47,"Proof of, and requirements for, the reverse of Jensen's Inequality for concave functions","Proof of, and requirements for, the reverse of Jensen's Inequality for concave functions",,"As I understand it, Jensen's Inequality states $$\int_{U}f_{V}\left(h(u)g(u)\right)du\geq f_{V}\left(\int_{U}h(u)g(u)du\right)$$ For a convex function $f_{V}$, a probability distribution $g(u)$ on the space $U$, and a linear combination of some $u$-dependent probabilities $h(u)$. Which would give a lower bound as a function of some total probabilities where $u$ is unknown. (I realize that perhaps this is not the most general form but it is the one that is relevant to me.) My question then is what if the function $f$ is not convex but concave - $f_{C}$. My understanding now is that I use the above equation with the inequality reversed, that is $$\int_{U}f_{C}(h(u)g(u))du\leq f_{C}\left(\int_{U}h(u)g(u)du\right)$$ But this is based on nothing more than an intuition and single vague sentence on Wikipedia. Can anyone refer me to, or provide, a proof? Also, would there be any further requirements on the probability space $U$, measure $g$, or linear combination of inequalities $h$? Any help is greatly appreciated.","As I understand it, Jensen's Inequality states $$\int_{U}f_{V}\left(h(u)g(u)\right)du\geq f_{V}\left(\int_{U}h(u)g(u)du\right)$$ For a convex function $f_{V}$, a probability distribution $g(u)$ on the space $U$, and a linear combination of some $u$-dependent probabilities $h(u)$. Which would give a lower bound as a function of some total probabilities where $u$ is unknown. (I realize that perhaps this is not the most general form but it is the one that is relevant to me.) My question then is what if the function $f$ is not convex but concave - $f_{C}$. My understanding now is that I use the above equation with the inequality reversed, that is $$\int_{U}f_{C}(h(u)g(u))du\leq f_{C}\left(\int_{U}h(u)g(u)du\right)$$ But this is based on nothing more than an intuition and single vague sentence on Wikipedia. Can anyone refer me to, or provide, a proof? Also, would there be any further requirements on the probability space $U$, measure $g$, or linear combination of inequalities $h$? Any help is greatly appreciated.",,"['probability', 'probability-theory', 'probability-distributions']"
48,$\int_{0}^{\infty}xe^{-x^2/2}dx= 1$?,?,\int_{0}^{\infty}xe^{-x^2/2}dx= 1,"$X \sim N(0, 1)$ $$E(|X|) = \frac1{\sqrt{2\pi}}\int_{-\infty}^{\infty}|x|e^{-x^2/2}dx= \frac{2}{\sqrt{2\pi}}\int_{0}^{\infty}xe^{-x^2/2}dx=\sqrt{\frac{2}{\pi}}$$ I don't understand how the last equality was arrived at. Why is it seemingly obvious that $\int_{0}^{\infty}xe^{-x^2/2}dx= 1$? Is this some common identity?","$X \sim N(0, 1)$ $$E(|X|) = \frac1{\sqrt{2\pi}}\int_{-\infty}^{\infty}|x|e^{-x^2/2}dx= \frac{2}{\sqrt{2\pi}}\int_{0}^{\infty}xe^{-x^2/2}dx=\sqrt{\frac{2}{\pi}}$$ I don't understand how the last equality was arrived at. Why is it seemingly obvious that $\int_{0}^{\infty}xe^{-x^2/2}dx= 1$? Is this some common identity?",,"['probability', 'normal-distribution', 'expectation']"
49,Coin tosses and probability,Coin tosses and probability,,"A fair coin is flipped 5 times. What is the probability of getting more heads than tails? Note: Since this is a GRE practice question, I want a method that can help me solve this problem in the fastest way possible. Of course, I can compute this probability directly by considering the cases of getting 5, 4, or 3 heads separately. However, this approach would be very time-consuming.","A fair coin is flipped 5 times. What is the probability of getting more heads than tails? Note: Since this is a GRE practice question, I want a method that can help me solve this problem in the fastest way possible. Of course, I can compute this probability directly by considering the cases of getting 5, 4, or 3 heads separately. However, this approach would be very time-consuming.",,[]
50,why is $E[E[Y|X]] = E[Y]$,why is,E[E[Y|X]] = E[Y],"I have a derivation from my book, I have a problem with the very first line: $$ \begin{align} E[E(Y|X)] &= \int_{-\infty}^\infty E(Y|x)f_1(x)dx <- \text{why  dx}\\ &= \int_{-\infty}^\infty\int_{-\infty}^\infty yf(y|x)f_1(x)dydx\\ &=\int_{-\infty}^\infty y \int_{-\infty}^\infty f(x,y)dxdy\\ &=\int_{-\infty}^\infty yf_2(y)dy\\ &= E(Y) \end{align} $$ Now everything after the first integral I understand, thats just splitting the integral up and getting marginal/joint densities. But why do we choose $dx$ in the first integral? seems arbitrary, what is it based on?","I have a derivation from my book, I have a problem with the very first line: $$ \begin{align} E[E(Y|X)] &= \int_{-\infty}^\infty E(Y|x)f_1(x)dx <- \text{why  dx}\\ &= \int_{-\infty}^\infty\int_{-\infty}^\infty yf(y|x)f_1(x)dydx\\ &=\int_{-\infty}^\infty y \int_{-\infty}^\infty f(x,y)dxdy\\ &=\int_{-\infty}^\infty yf_2(y)dy\\ &= E(Y) \end{align} $$ Now everything after the first integral I understand, thats just splitting the integral up and getting marginal/joint densities. But why do we choose $dx$ in the first integral? seems arbitrary, what is it based on?",,"['probability', 'probability-theory', 'conditional-probability']"
51,What's the probability of a set of only three digits appearing in a random 9 digit set?,What's the probability of a set of only three digits appearing in a random 9 digit set?,,"I'd like to know the method for correctly calculating the probability of a random sequence of $9$ numbers only containing $3$ unique, different numbers. For the purpose of this question: there are 10 numbers $0,1,2,3,4,5,6,7,8,9$ i.e. the probability of this: $123123123$ - for all unique combinations of $3$ digits (e.g $071$ in $071717717$) My initial instinct is $(1/3)^9$ - is this correct?","I'd like to know the method for correctly calculating the probability of a random sequence of $9$ numbers only containing $3$ unique, different numbers. For the purpose of this question: there are 10 numbers $0,1,2,3,4,5,6,7,8,9$ i.e. the probability of this: $123123123$ - for all unique combinations of $3$ digits (e.g $071$ in $071717717$) My initial instinct is $(1/3)^9$ - is this correct?",,['probability']
52,Approximating Coins Flips Problem,Approximating Coins Flips Problem,,Approximate the probability of getting 500 heads out of a 1000 coin   flip of unbiased coins to be within 5% of its true value (without the use of a calculator). I know that an exact probability is $$\binom{1000}{500}(.5)^{1000} = .02522...$$ I am unsure how one could simplify this problem through estimation to get an approximate answer however. Thanks for any help.,Approximate the probability of getting 500 heads out of a 1000 coin   flip of unbiased coins to be within 5% of its true value (without the use of a calculator). I know that an exact probability is $$\binom{1000}{500}(.5)^{1000} = .02522...$$ I am unsure how one could simplify this problem through estimation to get an approximate answer however. Thanks for any help.,,"['probability', 'approximation', 'puzzle']"
53,"Find $ P(Z>X+Y)$ where $X,Y,Z \sim U(0,1)$ independently",Find  where  independently," P(Z>X+Y) X,Y,Z \sim U(0,1)","I'm trying to follow a line in a derivation for $P(Z>X+Y)$ where $X,Y,Z$ are independent continuous random variables distributed uniformly on $(0,1)$. I've already derived the pdf of $X+Y$ using the convolution theorem, but there's a line in the answer that says: $P(Z>X+Y) = \mathbb{E}[\ P(Z>X+Y\ |\  X+Y )\  ]$ where $\mathbb{E}$ is the expectation. I'm not familiar with this result. Could anyone give a pointer to a similar result if one exists? Thanks.","I'm trying to follow a line in a derivation for $P(Z>X+Y)$ where $X,Y,Z$ are independent continuous random variables distributed uniformly on $(0,1)$. I've already derived the pdf of $X+Y$ using the convolution theorem, but there's a line in the answer that says: $P(Z>X+Y) = \mathbb{E}[\ P(Z>X+Y\ |\  X+Y )\  ]$ where $\mathbb{E}$ is the expectation. I'm not familiar with this result. Could anyone give a pointer to a similar result if one exists? Thanks.",,"['probability', 'probability-distributions', 'volume', 'uniform-distribution']"
54,Equality of outcomes in two Poisson events,Equality of outcomes in two Poisson events,,"I have a Poisson process with a fixed (large) $\lambda$.  If I run the process twice, what is the probability that the two runs have the same outcome? That is, how can I approximate $$f(\lambda)=e^{-2\lambda}\sum_{k=0}^\infty\frac{\lambda^{2k}}{k!^2}$$ for $\lambda\gg1$?  If there's a simple expression about $+\infty$ that would be best, but I'm open to whatever can be suggested.","I have a Poisson process with a fixed (large) $\lambda$.  If I run the process twice, what is the probability that the two runs have the same outcome? That is, how can I approximate $$f(\lambda)=e^{-2\lambda}\sum_{k=0}^\infty\frac{\lambda^{2k}}{k!^2}$$ for $\lambda\gg1$?  If there's a simple expression about $+\infty$ that would be best, but I'm open to whatever can be suggested.",,"['probability', 'analysis', 'asymptotics']"
55,Average area of triangle formed ${1\over8}$ that of square,Average area of triangle formed  that of square,{1\over8},"Here's a question from my infamous probability textbook: A point is taken at random in each of the two adjacent sides of a square. Show that the average area of the triangle formed by joining them is one eighth of the area of the square. Intuitively, this makes sense since if I select the midpoints of two adjacent sides of the square, the triangle formed has ${1\over8}$ the area of the square. But I'm not sure how to go about averaging across all triangles i.e. what's the correct integral to setup. Any help would be well-appreciated. EDIT: Following Ninad Munshi's hint in the comments, I got the expression $${{\int_0^1 \int_0^1 {{xy}\over2}\,\text{d}x\,\text{d}y}\over{1^2}},$$ which indeed evaluates to ${1\over8}$ after a short calculation. But it feels like magic, can anyone explain in depth and conceptually why this integral gets us the desired probability? EDIT 2: Thanks to heropup for his answer. However, I am asking for an explanation that specifically addresses my concerns in my previous edit, which his answer unfortunately does not.","Here's a question from my infamous probability textbook: A point is taken at random in each of the two adjacent sides of a square. Show that the average area of the triangle formed by joining them is one eighth of the area of the square. Intuitively, this makes sense since if I select the midpoints of two adjacent sides of the square, the triangle formed has the area of the square. But I'm not sure how to go about averaging across all triangles i.e. what's the correct integral to setup. Any help would be well-appreciated. EDIT: Following Ninad Munshi's hint in the comments, I got the expression which indeed evaluates to after a short calculation. But it feels like magic, can anyone explain in depth and conceptually why this integral gets us the desired probability? EDIT 2: Thanks to heropup for his answer. However, I am asking for an explanation that specifically addresses my concerns in my previous edit, which his answer unfortunately does not.","{1\over8} {{\int_0^1 \int_0^1 {{xy}\over2}\,\text{d}x\,\text{d}y}\over{1^2}}, {1\over8}","['calculus', 'probability', 'integration', 'multivariable-calculus', 'geometric-probability']"
56,"Showing $P(X_1+X_2<1)=\frac12$ where $X_1,X_2$ are i.i.d $U(0,1)$ variables",Showing  where  are i.i.d  variables,"P(X_1+X_2<1)=\frac12 X_1,X_2 U(0,1)","I am given that $X_1$ and $X_2$ are iid $U(0,1)$ and want to show that $$Pr[X_1+X_2<1]=0.5$$ My approach is to evaluate $$\int_0^1\int_0^{1-x_1}1 \quad dx_2dx_1$$ but there seems to be a geometric approach to this that significantly simplifies the answer. May I have some assistance?",I am given that and are iid and want to show that My approach is to evaluate but there seems to be a geometric approach to this that significantly simplifies the answer. May I have some assistance?,"X_1 X_2 U(0,1) Pr[X_1+X_2<1]=0.5 \int_0^1\int_0^{1-x_1}1 \quad dx_2dx_1","['probability', 'probability-distributions', 'uniform-distribution']"
57,Determining probability of a rainy day,Determining probability of a rainy day,,"I have the following problem: If today is a sunny day, a probability that it will rain tomorrow is $0.2$ . If today is a rainy day, a probability that it will be sunny tomorrow is $0.4$ . I need to find the probability that if it's rainy on the third of May, it will also rain on the third of June. My initial idea was to write a program that will create the binary tree with all possible combinations and then I just traverse through all of them and sum the probabilities accordingly, but unfortunately, I have to do this by hand, so any help is very welcome.","I have the following problem: If today is a sunny day, a probability that it will rain tomorrow is . If today is a rainy day, a probability that it will be sunny tomorrow is . I need to find the probability that if it's rainy on the third of May, it will also rain on the third of June. My initial idea was to write a program that will create the binary tree with all possible combinations and then I just traverse through all of them and sum the probabilities accordingly, but unfortunately, I have to do this by hand, so any help is very welcome.",0.2 0.4,"['probability', 'probability-theory']"
58,Probability of 2 Dice Throws Equal to Sum,Probability of 2 Dice Throws Equal to Sum,,"I'm aware this is a very simple question, I must be missing something obvious. Given that the numbers coming out of two independent dice throws are different, find the probability that the sum of the numbers is 4. Apparently the correct answer is 1/15 . Though my answer is 1/18 : So you can roll either a $(1,3)$ or a $(3,1)$ . So then I do $\left(\frac{1}{6}\cdot\frac{1}{6}\right)$ + $\left(\frac{1}{6}\cdot\frac{1}{6}\right)$ = $\frac{1}{18}$","I'm aware this is a very simple question, I must be missing something obvious. Given that the numbers coming out of two independent dice throws are different, find the probability that the sum of the numbers is 4. Apparently the correct answer is 1/15 . Though my answer is 1/18 : So you can roll either a or a . So then I do + =","(1,3) (3,1) \left(\frac{1}{6}\cdot\frac{1}{6}\right) \left(\frac{1}{6}\cdot\frac{1}{6}\right) \frac{1}{18}","['probability', 'dice']"
59,Show that $(1+u) \log (1+u) - u \ge \frac{u^2}{2(1+u/3)} $,Show that,(1+u) \log (1+u) - u \ge \frac{u^2}{2(1+u/3)} ,"This is used to go from Bennett's inequality to Bernstein's inequality. Yet I don't understand how to prove the inequality. Assume that $u > 0$, define $$ h(u) = (1+u) \log (1+u) - u $$ show that $$ h(u) \ge \frac{u^2}{2(1+u/3)} $$ My research : Decomposing the function $h$ as a power series show that it is equivalent to $$ \sum_{n=1}^\infty (-1)^n \frac{u^n}{n+1} \frac{n-1}{n (n+2)} \ge 0 $$ Sadly, I see no reason for this series to be positive. SOLUTION The twice differenciation technique given below works. However, I don't agree with the calculus, only on small things that don't change the result. Define $$ g(u) = (1+u)\log (1+u) - u - \frac{3u^2}{2(3+u)} $$ $$ g'(u) = \log (1+u) + 1 - 1 - \frac{3}{2} \frac{2u (3+u) - u^2}{(3+u)^2}\\ $$ Simplifying, $$ g'(u) = \log (1+u) - \frac{3}{2} \frac{u(u+6 )}{(3+u)^2}   $$ $$ g''(u) = \frac{1}{1+u} - \frac{3}{2} \frac{(2u +6)(3+u)^2 -  2 (u+3)(u^2 + 6u) }{(3+u)^4}   $$ Simplifying, $$ g''(u) = \frac{1}{1+u} - \frac{3}{2} \frac{2u^2 +6u + 6u + 18 -  2u^2 - 12u }{(3+u)^3}   =  \frac{1}{1+u} - \frac{ 27  }{(3+u)^3}  $$ Simplifying again, $$ g''(u)= \frac{ u^3 + 3\times 3u^2 + 3 \times 9u + 27 - 27(1+u)}{(1+u)(3+u)^3}  = \frac{ u^2(u+9)}{(1+u)(3+u)^3} > 0 $$ And the result is given by the reasoning of Clement.","This is used to go from Bennett's inequality to Bernstein's inequality. Yet I don't understand how to prove the inequality. Assume that $u > 0$, define $$ h(u) = (1+u) \log (1+u) - u $$ show that $$ h(u) \ge \frac{u^2}{2(1+u/3)} $$ My research : Decomposing the function $h$ as a power series show that it is equivalent to $$ \sum_{n=1}^\infty (-1)^n \frac{u^n}{n+1} \frac{n-1}{n (n+2)} \ge 0 $$ Sadly, I see no reason for this series to be positive. SOLUTION The twice differenciation technique given below works. However, I don't agree with the calculus, only on small things that don't change the result. Define $$ g(u) = (1+u)\log (1+u) - u - \frac{3u^2}{2(3+u)} $$ $$ g'(u) = \log (1+u) + 1 - 1 - \frac{3}{2} \frac{2u (3+u) - u^2}{(3+u)^2}\\ $$ Simplifying, $$ g'(u) = \log (1+u) - \frac{3}{2} \frac{u(u+6 )}{(3+u)^2}   $$ $$ g''(u) = \frac{1}{1+u} - \frac{3}{2} \frac{(2u +6)(3+u)^2 -  2 (u+3)(u^2 + 6u) }{(3+u)^4}   $$ Simplifying, $$ g''(u) = \frac{1}{1+u} - \frac{3}{2} \frac{2u^2 +6u + 6u + 18 -  2u^2 - 12u }{(3+u)^3}   =  \frac{1}{1+u} - \frac{ 27  }{(3+u)^3}  $$ Simplifying again, $$ g''(u)= \frac{ u^3 + 3\times 3u^2 + 3 \times 9u + 27 - 27(1+u)}{(1+u)(3+u)^3}  = \frac{ u^2(u+9)}{(1+u)(3+u)^3} > 0 $$ And the result is given by the reasoning of Clement.",,"['real-analysis', 'probability', 'analysis']"
60,Approximation with a normal distribution,Approximation with a normal distribution,,"Every day Alice tries the stroke playing tennis until she reaches $50$ strokes. If each stroke is good with a probability of $0,4$, independently from others, approximately what is the probability that at least $100$ attemps are necessary to success? Let X be a binomial random variable with parameters $$n=100$$ and $$p=0,4$$ Since n is large we can approximate with a  normal distribution with parameters $$\mu=40$$ and $$\sigma=\sqrt{0,4*100*0,6}=\sqrt{24}$$ Appling the normal approximation \begin{align}P(X> 49,5)&=1-P(x<49,5)\\&=1-P((X-\mu )/\sigma  < (49,5-40 )/ \sqrt{24} )\\&=1-P((X-\mu )/\sigma  < 1,939 )\\&=1-\Phi (1,939)\\&=1-0,9737\\&=0,0263\end{align} But the solution on the book is $0,974$ (it could be $P(x<49,5)$).","Every day Alice tries the stroke playing tennis until she reaches $50$ strokes. If each stroke is good with a probability of $0,4$, independently from others, approximately what is the probability that at least $100$ attemps are necessary to success? Let X be a binomial random variable with parameters $$n=100$$ and $$p=0,4$$ Since n is large we can approximate with a  normal distribution with parameters $$\mu=40$$ and $$\sigma=\sqrt{0,4*100*0,6}=\sqrt{24}$$ Appling the normal approximation \begin{align}P(X> 49,5)&=1-P(x<49,5)\\&=1-P((X-\mu )/\sigma  < (49,5-40 )/ \sqrt{24} )\\&=1-P((X-\mu )/\sigma  < 1,939 )\\&=1-\Phi (1,939)\\&=1-0,9737\\&=0,0263\end{align} But the solution on the book is $0,974$ (it could be $P(x<49,5)$).",,"['probability', 'probability-distributions', 'normal-distribution']"
61,Finding the distribution law,Finding the distribution law,,"Throwing a cube twice, let $X$ be the sum of the two throws Find the distribution law My attempt $$ \begin{array}{c|lcr}  &2&3&4&5&6&7&8&9&10&11&12 \\ \hline \text{P}_\text{X}(x) & 1/12 & 1/12 & 1/12&1/12&1/12&1/12&1/12&1/12&1/12&1/12&1/12 \\ \end{array} $$ But shouldn't the sum be $1$? Currently the sum is $11/12$","Throwing a cube twice, let $X$ be the sum of the two throws Find the distribution law My attempt $$ \begin{array}{c|lcr}  &2&3&4&5&6&7&8&9&10&11&12 \\ \hline \text{P}_\text{X}(x) & 1/12 & 1/12 & 1/12&1/12&1/12&1/12&1/12&1/12&1/12&1/12&1/12 \\ \end{array} $$ But shouldn't the sum be $1$? Currently the sum is $11/12$",,"['probability', 'probability-distributions']"
62,What property does this binomial probability calculation use?,What property does this binomial probability calculation use?,,I have an equation $$\sum_{k=2}^7{7\choose k}{0.01^k}(1-0.01)^{7-k} = 1-(0.99)^7 - 7(0.01)(0.99)^6 \approx 0.002031$$ I don't know what property the teacher used to quickly transform the summation to two simple equations. Can someone please give me a hint? P.S. This formula is used to calculate binomial probability.,I have an equation $$\sum_{k=2}^7{7\choose k}{0.01^k}(1-0.01)^{7-k} = 1-(0.99)^7 - 7(0.01)(0.99)^6 \approx 0.002031$$ I don't know what property the teacher used to quickly transform the summation to two simple equations. Can someone please give me a hint? P.S. This formula is used to calculate binomial probability.,,"['probability', 'binomial-distribution', 'summation-method']"
63,Why is the number of ways to arrange n people in distinct ways around a circle $\frac{n!}{n}$,Why is the number of ways to arrange n people in distinct ways around a circle,\frac{n!}{n},"First off, this sounds like permutations, and I'm unable to squeeze  $\frac{n!}{n}$ out of the permutations formula. Could someone break down how to get to that solution from either the Combinations or Permutations standard formulas?","First off, this sounds like permutations, and I'm unable to squeeze  $\frac{n!}{n}$ out of the permutations formula. Could someone break down how to get to that solution from either the Combinations or Permutations standard formulas?",,['probability']
64,"Dice roll probability, at least 9 total?","Dice roll probability, at least 9 total?",,"If I have two dice with $6$ sides each, what is the probability of me rolling atleast $9$ total? I think I'm correct when thinking that the probability of rolling a $9$ is $\frac{4}{36}$, that is $11.1...\%$, but how do I go from here to calculate the ""at least"" part?","If I have two dice with $6$ sides each, what is the probability of me rolling atleast $9$ total? I think I'm correct when thinking that the probability of rolling a $9$ is $\frac{4}{36}$, that is $11.1...\%$, but how do I go from here to calculate the ""at least"" part?",,"['probability', 'dice']"
65,Expected number of coin tosses to land n heads,Expected number of coin tosses to land n heads,,"In reading about how to calculate the expected number of (fair) coin tosses to land n Heads in a row, using the equations produces the following: $$E(1|H) = 2$$ $$E(2|H) = 6$$ $$E(3|H) = 14,$$ and so on. What I also noticed is that given the following probabilities of landing N heads in a row (using $\frac1{2^n}$) we have: $$P(1|H) = \frac1{2}$$     $$P(2|H) = \frac1{4}$$    $$P(3|H) = \frac1{8},$$ and so on. From this it looks like we can calculate the expected number of tosses for a run of n heads by summing up the inverse of the probabilities for landing n head from 1 to n: For instance the expected number of tosses for $3$ heads is just $8 + 4 + 2 = 14.$ It is not clear to me from reading through the derivations and formulas of the expected values why this pattern emerges. Is this simply another way of stating the formulas using concrete values for P?","In reading about how to calculate the expected number of (fair) coin tosses to land n Heads in a row, using the equations produces the following: $$E(1|H) = 2$$ $$E(2|H) = 6$$ $$E(3|H) = 14,$$ and so on. What I also noticed is that given the following probabilities of landing N heads in a row (using $\frac1{2^n}$) we have: $$P(1|H) = \frac1{2}$$     $$P(2|H) = \frac1{4}$$    $$P(3|H) = \frac1{8},$$ and so on. From this it looks like we can calculate the expected number of tosses for a run of n heads by summing up the inverse of the probabilities for landing n head from 1 to n: For instance the expected number of tosses for $3$ heads is just $8 + 4 + 2 = 14.$ It is not clear to me from reading through the derivations and formulas of the expected values why this pattern emerges. Is this simply another way of stating the formulas using concrete values for P?",,"['probability', 'conditional-expectation']"
66,What is the probability that a randomly selected positive integer between 1 and 100 (inclusive) is square-free?,What is the probability that a randomly selected positive integer between 1 and 100 (inclusive) is square-free?,,"What is the probability that a randomly selected positive integer between $1$ and $100$ (inclusive) is square-free (i.e., has no square factor; for instance $15 = 3 \cdot 5$ is square-free, but $90$ is not, since it has a factor of $3^2$). I have no idea how to solve this problem. Any help on how to proceed?","What is the probability that a randomly selected positive integer between $1$ and $100$ (inclusive) is square-free (i.e., has no square factor; for instance $15 = 3 \cdot 5$ is square-free, but $90$ is not, since it has a factor of $3^2$). I have no idea how to solve this problem. Any help on how to proceed?",,['probability']
67,Help with monty hall problem,Help with monty hall problem,,"I'm having trouble understanding something about the monty hall problem. If monty opened one door before you arrives, then you would have a 50/50 chance, whichever door you picked, because there are only 2 doors to pick from - right? So, what about if you arrive, and monty said ""I assumed you would pick door 1, so I opened door 3""? In that case, picking door 2 would be the same as if you had picked door 1, and then switched, so you should have 2/3 odds on it. But if monty hadn't said anything and you just picked one of the two doors, then your chances would be 50/50... or would they? Does monty assuming that you would want to pick door 1, change the probabilities even if you don't know about his decision? What about if someone else picks a door and tells monty, who opens another one, and you then have the option to choose - without knowing which door the original person picked? What are the probabilities then? Does one of the doors secretly have a 2/3 probability? That doesn't make any sense to me. Can someone explain this? Because I'm really not getting it.","I'm having trouble understanding something about the monty hall problem. If monty opened one door before you arrives, then you would have a 50/50 chance, whichever door you picked, because there are only 2 doors to pick from - right? So, what about if you arrive, and monty said ""I assumed you would pick door 1, so I opened door 3""? In that case, picking door 2 would be the same as if you had picked door 1, and then switched, so you should have 2/3 odds on it. But if monty hadn't said anything and you just picked one of the two doors, then your chances would be 50/50... or would they? Does monty assuming that you would want to pick door 1, change the probabilities even if you don't know about his decision? What about if someone else picks a door and tells monty, who opens another one, and you then have the option to choose - without knowing which door the original person picked? What are the probabilities then? Does one of the doors secretly have a 2/3 probability? That doesn't make any sense to me. Can someone explain this? Because I'm really not getting it.",,"['probability', 'monty-hall']"
68,The probability that two vectors are linearly independent.,The probability that two vectors are linearly independent.,,"Given the set $R^{n}$, what is the probability that 2 vectors drawn are linearly independent? I know the answer is almost 1 but I am not able to reason. Could someone please help me out?","Given the set $R^{n}$, what is the probability that 2 vectors drawn are linearly independent? I know the answer is almost 1 but I am not able to reason. Could someone please help me out?",,"['linear-algebra', 'probability', 'probability-theory', 'vector-spaces']"
69,Probability of rolling at least one 6 while rerolling 1's,Probability of rolling at least one 6 while rerolling 1's,,"Scenario: You roll a number of 6-sided dice Success: Roll at least one 6 Conditions: You can re-roll any 1's you get on the first roll What are the odds of success for n dice? Example: 7 dice Roll:            (1, 1, 1, 4, 4, 4, 5) Re-roll:      (1, 2, 3) Final dice: (1, 2, 3, 4, 4, 4, 5) Result:        Failure My take on this was: For any number of rolled 1's, ""replace"" those rolls with rolling n+x dice (where x is the number of 1's rolled) and thus reducing the problem to simple combinatorics, but I didn't get very far. I suppose there is a simple ""trick"", so I'm looking for other angles into this problem. However, if it turns out not to be so simple, please try to be as verbose and layman-friendly as you can.","Scenario: You roll a number of 6-sided dice Success: Roll at least one 6 Conditions: You can re-roll any 1's you get on the first roll What are the odds of success for n dice? Example: 7 dice Roll:            (1, 1, 1, 4, 4, 4, 5) Re-roll:      (1, 2, 3) Final dice: (1, 2, 3, 4, 4, 4, 5) Result:        Failure My take on this was: For any number of rolled 1's, ""replace"" those rolls with rolling n+x dice (where x is the number of 1's rolled) and thus reducing the problem to simple combinatorics, but I didn't get very far. I suppose there is a simple ""trick"", so I'm looking for other angles into this problem. However, if it turns out not to be so simple, please try to be as verbose and layman-friendly as you can.",,"['probability', 'combinatorics', 'discrete-mathematics', 'dice']"
70,How to count permutations with restrictions on how items are grouped,How to count permutations with restrictions on how items are grouped,,"I am trying to solve the following problem: A town contains $4$ people who repair televisions. If $4$ sets break down, what is the probability that exactly $i$ of the repairers are called? Solve the problem for $i=1,2,3,4$. For $i=1$, there are ${}_4P_1$ ways to assign $1$ person to $4$ televisions, so the probability is $\frac{{}_4P_1}{4^4}=\frac{1}{64}$. For $i=4$, there are ${}_4P_4$ ways to assign $4$ people to $4$ televisions, so the probability is $\frac{{}_4P_4}{4^4}=\frac{3}{32}$. I am having trouble with $i=2,3$. How should I go about these cases?","I am trying to solve the following problem: A town contains $4$ people who repair televisions. If $4$ sets break down, what is the probability that exactly $i$ of the repairers are called? Solve the problem for $i=1,2,3,4$. For $i=1$, there are ${}_4P_1$ ways to assign $1$ person to $4$ televisions, so the probability is $\frac{{}_4P_1}{4^4}=\frac{1}{64}$. For $i=4$, there are ${}_4P_4$ ways to assign $4$ people to $4$ televisions, so the probability is $\frac{{}_4P_4}{4^4}=\frac{3}{32}$. I am having trouble with $i=2,3$. How should I go about these cases?",,"['probability', 'permutations']"
71,Roll six dice. Probability of at least one pair.,Roll six dice. Probability of at least one pair.,,I roll 6 fair dice. What is the probability that at least one pair shows up?,I roll 6 fair dice. What is the probability that at least one pair shows up?,,"['probability', 'dice']"
72,What are some martingales for asymmetric random walks?,What are some martingales for asymmetric random walks?,,Here are some examples for symmetric ones: https://mathoverflow.net/questions/55092/martingales-in-both-discrete-and-continuous-setting/55101#55101 Is there a similar list for asymmmetric random walks?,Here are some examples for symmetric ones: https://mathoverflow.net/questions/55092/martingales-in-both-discrete-and-continuous-setting/55101#55101 Is there a similar list for asymmmetric random walks?,,"['probability', 'probability-theory', 'random-walk', 'martingales']"
73,Is this a Delta Function? (and Delta as limit of Gaussian?),Is this a Delta Function? (and Delta as limit of Gaussian?),,"I have a set of users that generate calls.  If I assign the same probability to each user, they have identical call generation probability which can be defined as $\delta$. These callers are chosen uniformly among the set of users. At the end of the generation process, the representation of the probability density function of the call rates should be a delta function (hence the shape is similar to a bell, isn't it?) The probability i assigned to each user is:  $$p_u = \frac{\lambda}{\sum_{i \in N_u} \lambda}$$ where $\lambda = \frac{1}{N_u}$ and $N_u$ is the number of users. In this way they are equally partitioned between 0 and 1 and i can take a random number uniformly distributed in order to select a random user. My question is how can i demonstrate that this is really a Delta function? The information i wrote are enough to defined the Delta function (i don't know if it is possible to formalize the p.d.f.)? For example in figure we have 10000 that has the same generation probability: if I generate ca.  605000 calls the average is ca. 60.5 calls per user","I have a set of users that generate calls.  If I assign the same probability to each user, they have identical call generation probability which can be defined as $\delta$. These callers are chosen uniformly among the set of users. At the end of the generation process, the representation of the probability density function of the call rates should be a delta function (hence the shape is similar to a bell, isn't it?) The probability i assigned to each user is:  $$p_u = \frac{\lambda}{\sum_{i \in N_u} \lambda}$$ where $\lambda = \frac{1}{N_u}$ and $N_u$ is the number of users. In this way they are equally partitioned between 0 and 1 and i can take a random number uniformly distributed in order to select a random user. My question is how can i demonstrate that this is really a Delta function? The information i wrote are enough to defined the Delta function (i don't know if it is possible to formalize the p.d.f.)? For example in figure we have 10000 that has the same generation probability: if I generate ca.  605000 calls the average is ca. 60.5 calls per user",,"['probability', 'probability-theory', 'probability-distributions']"
74,"In the card game bridge, the 52 cards are dealt out equally to 4 players","In the card game bridge, the 52 cards are dealt out equally to 4 players",,"I misunderstand conditional probability as in this problem In the card game bridge, the 52 cards are dealt out equally to 4 players—called East, West, North, and South. If North and South have a total of 8 spades among them, what is the probability that East has 3 of the remaining 5 spades? My calculation is. Let  E denote:"" East has 3 of the remaining 5 spades"" and F:"" North and South have a total of 8 spades among them"". Since $  P(E|F)= \frac {P(EF)}  {P(F)} $ For $P(F)= \frac {{13 \choose 8}  * {39 \choose 18}} {{52 \choose 26}}$ =0,161 And $P(EF)= \frac {{13 \choose 8}*{39 \choose 18}*{5 \choose 3}*{18 \choose 10}}{{52\choose 26}*{26 \choose 13}}$ =0,32. But the answer is 0,339. What is wrong with my calculation?","I misunderstand conditional probability as in this problem In the card game bridge, the 52 cards are dealt out equally to 4 players—called East, West, North, and South. If North and South have a total of 8 spades among them, what is the probability that East has 3 of the remaining 5 spades? My calculation is. Let  E denote:"" East has 3 of the remaining 5 spades"" and F:"" North and South have a total of 8 spades among them"". Since For =0,161 And =0,32. But the answer is 0,339. What is wrong with my calculation?",  P(E|F)= \frac {P(EF)}  {P(F)}  P(F)= \frac {{13 \choose 8}  * {39 \choose 18}} {{52 \choose 26}} P(EF)= \frac {{13 \choose 8}*{39 \choose 18}*{5 \choose 3}*{18 \choose 10}}{{52\choose 26}*{26 \choose 13}},"['probability', 'combinatorics', 'card-games']"
75,The mice problem,The mice problem,,"Problem. You have $2$ mice, and $9$ bottles, exactly one of which is poisoned. Each mouse can taste any combination of bottles at once, and if it is poisoned it will die after exactly one minute. Once a mouse is dead, it can't taste any more bottles. How many minutes do you need to determine exactly which bottle is poisoned? This question has me in a complete bind. Anyone who can point me in the right direction as to how to get started with this problem would be greatly appreciated.","Problem. You have mice, and bottles, exactly one of which is poisoned. Each mouse can taste any combination of bottles at once, and if it is poisoned it will die after exactly one minute. Once a mouse is dead, it can't taste any more bottles. How many minutes do you need to determine exactly which bottle is poisoned? This question has me in a complete bind. Anyone who can point me in the right direction as to how to get started with this problem would be greatly appreciated.",2 9,"['probability', 'permutations', 'combinations']"
76,is transposed vector times transposed vector possible?,is transposed vector times transposed vector possible?,,I was wondering if it was indeed possible to perform a transposed vector multiplication with another transposed vector. And if so how I'm supposed to do so. Background: From https://en.wikipedia.org/wiki/Complex_normal_distribution I saw As you can see in the exponential there is a multiplication between two transposed vectors. I'm not sure if it's a typo or not.,I was wondering if it was indeed possible to perform a transposed vector multiplication with another transposed vector. And if so how I'm supposed to do so. Background: From https://en.wikipedia.org/wiki/Complex_normal_distribution I saw As you can see in the exponential there is a multiplication between two transposed vectors. I'm not sure if it's a typo or not.,,"['probability', 'matrices', 'multivariable-calculus', 'complex-numbers']"
77,Is a random subset of $\mathbb{R}^2$ connected?,Is a random subset of  connected?,\mathbb{R}^2,Create a set $S$ by adding each point of $\mathbb{R}^2$ with 50% probability (independently). What is the probability that $S$ is connected? (and is this even a valid thing to ask?),Create a set by adding each point of with 50% probability (independently). What is the probability that is connected? (and is this even a valid thing to ask?),S \mathbb{R}^2 S,"['probability', 'general-topology', 'measure-theory', 'connectedness', 'independence']"
78,Birthday problem: solving with permutations vs combinations,Birthday problem: solving with permutations vs combinations,,"I have a problem with an exercise: If k people are at a party, what is the probability that at least two of them have the same birthday? Suppose that there are n=365 days in a year and all days are equally likely to be the birthday of a specific person. What is the probability for k=23? And according to the solution sheet the right answer is: $Pr=1-\frac{P_{365,k}}{365^k}$ and $Pr_{k=23} \approx 0.5073$ I think I understand the way of thinking behind this solution but my way of thinking was quite different: Let's assume that $\#B$ is the number of pairs having the same birthday. The probability of NOT having the same birthday for a single pair is $p_b=1-\frac{1}{365}=\frac{364}{365}$ so for all the pairs we have: $P(\#B \ge 1)=1-P(\#B =0)=1-(\frac{364}{365})^{C_{k,2}}$ where $C_{k,2}$ is the number of possible pairs. This seems quite different than the solution from the solution sheet and the exact result for $k=23$ seems also to be a little bit different because (according to Wolfram alpha) I get: $Pr_{k=23} \approx 0.5004771$ What am I doing wrong? Or maybe the two solutions are equivalent and the difference in the results for $k=23$ is caused by some numerical approximations? Thank you in advance for your help.","I have a problem with an exercise: If k people are at a party, what is the probability that at least two of them have the same birthday? Suppose that there are n=365 days in a year and all days are equally likely to be the birthday of a specific person. What is the probability for k=23? And according to the solution sheet the right answer is: and I think I understand the way of thinking behind this solution but my way of thinking was quite different: Let's assume that is the number of pairs having the same birthday. The probability of NOT having the same birthday for a single pair is so for all the pairs we have: where is the number of possible pairs. This seems quite different than the solution from the solution sheet and the exact result for seems also to be a little bit different because (according to Wolfram alpha) I get: What am I doing wrong? Or maybe the two solutions are equivalent and the difference in the results for is caused by some numerical approximations? Thank you in advance for your help.","Pr=1-\frac{P_{365,k}}{365^k} Pr_{k=23} \approx 0.5073 \#B p_b=1-\frac{1}{365}=\frac{364}{365} P(\#B \ge 1)=1-P(\#B =0)=1-(\frac{364}{365})^{C_{k,2}} C_{k,2} k=23 Pr_{k=23} \approx 0.5004771 k=23","['probability', 'combinatorics', 'permutations', 'combinations', 'birthday']"
79,Expected value and Gambler's fallacy,Expected value and Gambler's fallacy,,"Betting on a fair coin has expected value 0 dollars. Suppose we win 1 dollar for each win and lose the same for each loss. Suppose we have lost 100 dollars so far. Then it's right to say that this loss has to be balanced out by the winnings somewhere in the future tosses of the coin? That's because the expected value is 0, so we can't remain at -100 dollars till infinity. But that also implies that the set of future tosses of the coin are overall biased towards winning, which is Gambler's fallacy. Please help.","Betting on a fair coin has expected value 0 dollars. Suppose we win 1 dollar for each win and lose the same for each loss. Suppose we have lost 100 dollars so far. Then it's right to say that this loss has to be balanced out by the winnings somewhere in the future tosses of the coin? That's because the expected value is 0, so we can't remain at -100 dollars till infinity. But that also implies that the set of future tosses of the coin are overall biased towards winning, which is Gambler's fallacy. Please help.",,"['probability', 'expected-value', 'gambling']"
80,How to calculate $\frac{100!}{(50!)^2 2^{100}}$ solely using mental arithmetic?,How to calculate  solely using mental arithmetic?,\frac{100!}{(50!)^2 2^{100}},"Question: When $100$ coins are tossed, what is the probability that exactly $50$ are heads? I mange to solve the question with answer $$\binom{100}{50} \left(\frac{1}{2}\right)^{100} = \frac{100!}{(50!)^2 2^{100}}.$$ But if I want to approximate the quantity above solely using mental arithmetic, how would one approach it?","Question: When coins are tossed, what is the probability that exactly are heads? I mange to solve the question with answer But if I want to approximate the quantity above solely using mental arithmetic, how would one approach it?",100 50 \binom{100}{50} \left(\frac{1}{2}\right)^{100} = \frac{100!}{(50!)^2 2^{100}}.,"['probability', 'combinatorics', 'algebra-precalculus']"
81,Proof of the union of two indicator functions,Proof of the union of two indicator functions,,How do I prove that $$1_{A∪B} = 1_A + 1_B - 1 _{A∩B}$$ ? For the proof of intersection I found on mathexchange that: \begin{align}1_A(x)1_B(x)&=\begin{cases} 1& x\in A\\ 0& x\in A^C \end{cases}\begin{cases} 1& x\in B\\ 0& x\in B^C \end{cases}\\&=\begin{cases} 1& x\in A \cap x\in B\\ 0\cdot 1& x\in A^C\cap B\\ 1\cdot 0& x\in A \cap B^C\\ 0\cdot 0& x\in A^C \cap B^C\\ \end{cases}\\&=\begin{cases} 1& x\in A \cap B\\ 0& x\in \underbrace{(A^C\cap B)\cup(A \cap B^C )\cup(A^C \cap B^C)}_{=(A\cap B)^C}\\ \end{cases}\\&=1_{A\cap B}(x)\end{align} I tried to do the same thing as in writing $ 1_A + 1_B - 1 _{A∩B}$ out like that but ended up getting really confused and can't seem to be able to prove this. \begin{align}1_A(x)+1_B(x)-1_A(x)1_B(x)&=\begin{cases}...+\begin{cases}...-\begin{cases} \end{cases}\end{cases}\end{cases}...\end{align},How do I prove that ? For the proof of intersection I found on mathexchange that: I tried to do the same thing as in writing out like that but ended up getting really confused and can't seem to be able to prove this.,"1_{A∪B} = 1_A + 1_B - 1 _{A∩B} \begin{align}1_A(x)1_B(x)&=\begin{cases}
1& x\in A\\
0& x\in A^C
\end{cases}\begin{cases}
1& x\in B\\
0& x\in B^C
\end{cases}\\&=\begin{cases}
1& x\in A \cap x\in B\\
0\cdot 1& x\in A^C\cap B\\
1\cdot 0& x\in A \cap B^C\\
0\cdot 0& x\in A^C \cap B^C\\
\end{cases}\\&=\begin{cases}
1& x\in A \cap B\\
0& x\in \underbrace{(A^C\cap B)\cup(A \cap B^C )\cup(A^C \cap B^C)}_{=(A\cap B)^C}\\
\end{cases}\\&=1_{A\cap B}(x)\end{align}  1_A + 1_B - 1 _{A∩B} \begin{align}1_A(x)+1_B(x)-1_A(x)1_B(x)&=\begin{cases}...+\begin{cases}...-\begin{cases}
\end{cases}\end{cases}\end{cases}...\end{align}","['real-analysis', 'probability', 'stochastic-calculus']"
82,Probability Dilemma,Probability Dilemma,,"The teacher gave us a question: We flip a coin. If it was Heads, we roll a die and if it was Tails, we flip three other coins. What's the probability of exactly having one coin as Heads? I first calculated $n(S)= 1  \cdot 6 + 1 \cdot 2 \cdot 2 \cdot 2$ , then $n(a) = 1 \cdot 6 + 1 \cdot 1 \cdot 1 \cdot 3$ . $P(a)=n(a)/n(S) = 9/14$ . For calculating $n(S)$ I first considered the case of the (first) coin being Heads and multiplied by $6$ (for the die), then calculated the case of the (first) coin being Tails and a $2 \cdot 2 \cdot 2$ for the coins. You'll get a sense of what I did for calculating $n(a)$ . The teacher told that my answer was incorrect and then wrote the answer as $6 \cdot (1/12) + 3 \cdot (1/16)=11/16$ and told me to find the problem of my answer for the next session. I don't think there's anything wrong with my answer and my teacher's wrong.","The teacher gave us a question: We flip a coin. If it was Heads, we roll a die and if it was Tails, we flip three other coins. What's the probability of exactly having one coin as Heads? I first calculated , then . . For calculating I first considered the case of the (first) coin being Heads and multiplied by (for the die), then calculated the case of the (first) coin being Tails and a for the coins. You'll get a sense of what I did for calculating . The teacher told that my answer was incorrect and then wrote the answer as and told me to find the problem of my answer for the next session. I don't think there's anything wrong with my answer and my teacher's wrong.","n(S)= 1 
\cdot 6 + 1 \cdot 2 \cdot 2 \cdot 2 n(a) = 1 \cdot 6 + 1 \cdot 1 \cdot 1 \cdot 3 P(a)=n(a)/n(S) = 9/14 n(S) 6 2 \cdot 2 \cdot 2 n(a) 6 \cdot (1/12) + 3 \cdot (1/16)=11/16",['probability']
83,Definition of conditional probability and a problem.,Definition of conditional probability and a problem.,,"The Problem: An urn contains 3 red and 4 black balls and another contains 4 red and 5 black. A random ball is chosen from the first urn and is inserted into the second urn. After this a random ball is chosen from the second urn. Consider the events: $A$ : ""first ball is red"", $B$ : ""second ball is red"". Find the Probability $P_A(B)$ where "" $P_A(B)$ "" means the probability that $B$ happens if $A$ has happened (i.e. the conditional probability of $B$ given $A$ ). This is a simple problem right? Why I'm confused: But I'm confused. We work in the probability space $(\Omega,\Sigma,P)$ (in this case $\Sigma=\mathcal P(\Omega)$ ), and $P$ is a probability that means is a function which respect kolmogorov axioms. $P_A(B)=1/2$ (because if $A$ happened then in the second urn we will have 5 red balls and 5 black balls) My question: Here is my question: If $P_A(B)=\frac{P(A \cap B)}{P(A)}$ by definition (and $P $ is a function, we don't know what function just this function respect Kolmogorov axioms). How we came to the conclusion $P_A(B)=1/2$ ? Using $$\frac{\text{Number of Favorable Outcomes}}{\text{Total Number of Possible Outcomes}}?$$ This doesn't make sense for me. $P$ is fixed from the beginning, then we must find $P_A(B)$ using definition to be rigorous. I need a rigourous proof.","The Problem: An urn contains 3 red and 4 black balls and another contains 4 red and 5 black. A random ball is chosen from the first urn and is inserted into the second urn. After this a random ball is chosen from the second urn. Consider the events: : ""first ball is red"", : ""second ball is red"". Find the Probability where "" "" means the probability that happens if has happened (i.e. the conditional probability of given ). This is a simple problem right? Why I'm confused: But I'm confused. We work in the probability space (in this case ), and is a probability that means is a function which respect kolmogorov axioms. (because if happened then in the second urn we will have 5 red balls and 5 black balls) My question: Here is my question: If by definition (and is a function, we don't know what function just this function respect Kolmogorov axioms). How we came to the conclusion ? Using This doesn't make sense for me. is fixed from the beginning, then we must find using definition to be rigorous. I need a rigourous proof.","A B P_A(B) P_A(B) B A B A (\Omega,\Sigma,P) \Sigma=\mathcal P(\Omega) P P_A(B)=1/2 A P_A(B)=\frac{P(A \cap B)}{P(A)} P  P_A(B)=1/2 \frac{\text{Number of Favorable Outcomes}}{\text{Total Number of Possible Outcomes}}? P P_A(B)",['probability']
84,Who has more probability of winning the game?,Who has more probability of winning the game?,,"Alice and Bob play a coin tossing game. A fair coin (that is, a coin with equal probability of landing heads and tails) is tossed repeatedly until one of the following happens. $1.$ The coin lands ""tails-tails"" (that is, a tails is immediately followed by a tails) for the first time. In this case Alice wins. $2.$ The coin lands ""tails-heads"" (that is, a tails is immediately followed by a heads) for the first time. In this case Bob wins. Who has more probability of winning the game? My attempt $:$ Let $X$ be the random variable which counts the number of tosses required to obtain ""tails-tails"" for the first time and $Y$ be the random variable which counts the number of tosses required to obtain ""tails-heads"" for the first time. It is quite clear that if $\Bbb E(X) < \Bbb E(Y)$ then Alice has more probability of winning the game than Bob $;$ otherwise Bob has more probability of winning the game than Alice. Let $X_1$ be the event which denotes ""the first toss yields heads"", $X_2$ be the event which denotes ""tails in the first toss followed by heads in the second toss"", $X_3$ be the event which denotes ""tails in the first toss followed by tails in the second toss"". Then $X_1,X_2$ and $X_3$ are mutually exclusive and exhaustive events. Let $\Bbb E(X) = r.$ So we have $$\begin{align} r & = \Bbb E(X \mid X_1) \cdot \Bbb P(X_1) + \Bbb E(X \mid X_2) \cdot \Bbb P(X_2) + \Bbb E(X \mid X_3) \cdot \Bbb P(X_3). \\ & = \frac {1} {2} \cdot (r+1) + \frac {1} {4} \cdot (r+2)+ 2 \cdot \frac {1} {4}. \\ & = \frac {3r} {4} + \frac {3} {2}. \end{align}$$ $\implies \frac {r} {4} = \frac {3} {2}.$ So $\Bbb E(X) = r = 6.$ But I find difficulty to find $\Bbb E(Y).$ Would anybody please help me finding this? Thank you very much for your valuable time.","Alice and Bob play a coin tossing game. A fair coin (that is, a coin with equal probability of landing heads and tails) is tossed repeatedly until one of the following happens. The coin lands ""tails-tails"" (that is, a tails is immediately followed by a tails) for the first time. In this case Alice wins. The coin lands ""tails-heads"" (that is, a tails is immediately followed by a heads) for the first time. In this case Bob wins. Who has more probability of winning the game? My attempt Let be the random variable which counts the number of tosses required to obtain ""tails-tails"" for the first time and be the random variable which counts the number of tosses required to obtain ""tails-heads"" for the first time. It is quite clear that if then Alice has more probability of winning the game than Bob otherwise Bob has more probability of winning the game than Alice. Let be the event which denotes ""the first toss yields heads"", be the event which denotes ""tails in the first toss followed by heads in the second toss"", be the event which denotes ""tails in the first toss followed by tails in the second toss"". Then and are mutually exclusive and exhaustive events. Let So we have So But I find difficulty to find Would anybody please help me finding this? Thank you very much for your valuable time.","1. 2. : X Y \Bbb E(X) < \Bbb E(Y) ; X_1 X_2 X_3 X_1,X_2 X_3 \Bbb E(X) = r. \begin{align} r & = \Bbb E(X \mid X_1) \cdot \Bbb P(X_1) + \Bbb E(X \mid X_2) \cdot \Bbb P(X_2) + \Bbb E(X \mid X_3) \cdot \Bbb P(X_3). \\ & = \frac {1} {2} \cdot (r+1) + \frac {1} {4} \cdot (r+2)+ 2 \cdot \frac {1} {4}. \\ & = \frac {3r} {4} + \frac {3} {2}. \end{align} \implies \frac {r} {4} = \frac {3} {2}. \Bbb E(X) = r = 6. \Bbb E(Y).",['probability']
85,What is the largest possible variance of a random variable on $[0; 1]$? [duplicate],What is the largest possible variance of a random variable on ? [duplicate],[0; 1],"This question already has answers here : Maximum of the Variance Function for Given Set of Bounded Numbers (2 answers) Closed 4 years ago . What is the largest possible variance of a random variable on $[0; 1]$ ? It is evident that it does not exceed $1$ , but I doubt, that $1$ is actually possible. The largest variance, for which I found the example is $\frac{1}{4}$ . That is the variance of a random variable $X$ , such that $P(X = 1) = P(X = 0) = \frac{1}{2}$ , but I doubt that  it is the largest possible one. Why is it interesting: Initially I wanted to find the largest possible second moment of $X - Y$ , where $X$ and $Y$ are i.i.d. random variables on $[0; 1]$ . Then I found: $$E(X - Y)^2 = E(X^2 - 2XY + Y^2) = EX^2 - 2EXY + EY^2 = 2(EX^2 - EXY + EXY - EXEY + Cov(X, Y)) = 2(EX^2 - {(EX)}^2) = 2VarX$$ And thats where I am now. This question is partially inspired by: Probability distribution to maximize the expected distance between two points","This question already has answers here : Maximum of the Variance Function for Given Set of Bounded Numbers (2 answers) Closed 4 years ago . What is the largest possible variance of a random variable on ? It is evident that it does not exceed , but I doubt, that is actually possible. The largest variance, for which I found the example is . That is the variance of a random variable , such that , but I doubt that  it is the largest possible one. Why is it interesting: Initially I wanted to find the largest possible second moment of , where and are i.i.d. random variables on . Then I found: And thats where I am now. This question is partially inspired by: Probability distribution to maximize the expected distance between two points","[0; 1] 1 1 \frac{1}{4} X P(X = 1) = P(X = 0) = \frac{1}{2} X - Y X Y [0; 1] E(X - Y)^2 = E(X^2 - 2XY + Y^2) = EX^2 - 2EXY + EY^2 = 2(EX^2 - EXY + EXY - EXEY + Cov(X, Y)) = 2(EX^2 - {(EX)}^2) = 2VarX","['probability', 'probability-theory', 'optimization', 'variance', 'expected-value']"
86,Choosing 10 cards randomly from a 52 card deck,Choosing 10 cards randomly from a 52 card deck,,"Given a 52-card deck, if we pick 10 cards, what's the probability of having all four aces among the 10 cards we picked? My attempt was defining $\Omega = \{(1,2,...,52)^{10}\}$. Now $|\Omega|=\binom{52}{10}$ Let $A$ be the event that we're looking for. $A=\{\{1,2,3,4\}\cup(5,6,...,52)^{6}\}$. $|A|=\binom{48}{6}$ Now $Pr(A)=\dfrac{|A|}{|\Omega|}=\dfrac{\binom{48}{6}}{\binom{52}{10}}$ I don't have the answer but I noticed I got a really small number ($0.07\%$), so I don't think I solved it right.","Given a 52-card deck, if we pick 10 cards, what's the probability of having all four aces among the 10 cards we picked? My attempt was defining $\Omega = \{(1,2,...,52)^{10}\}$. Now $|\Omega|=\binom{52}{10}$ Let $A$ be the event that we're looking for. $A=\{\{1,2,3,4\}\cup(5,6,...,52)^{6}\}$. $|A|=\binom{48}{6}$ Now $Pr(A)=\dfrac{|A|}{|\Omega|}=\dfrac{\binom{48}{6}}{\binom{52}{10}}$ I don't have the answer but I noticed I got a really small number ($0.07\%$), so I don't think I solved it right.",,['probability']
87,Probability that $z$ is EVEN satisfying the equation $x + y + z = 10$ is,Probability that  is EVEN satisfying the equation  is,z x + y + z = 10,"Question Three randomly chosen non negative integers $x, y  \text{  and  } z$ are found to satisfy the equation $x + y + z = 10$ . Then the probability that $z$ is even , is""? My Approach Calculating Sample space -: Number of possible solution for $x + y + z = 10$ $$=\binom{10+3-1}{10}=12 \times 3=66$$ Possible outcome for $z$ to be even = $6(0,2,4,6,8,10)$ Hence the required probability $$=\frac{6}{66}=\frac{1}{11}$$ But the answer is $\frac{6}{11}$ Am I missing something?","Question Three randomly chosen non negative integers are found to satisfy the equation . Then the probability that is even , is""? My Approach Calculating Sample space -: Number of possible solution for Possible outcome for to be even = Hence the required probability But the answer is Am I missing something?","x, y  \text{  and  } z x + y + z = 10 z x + y + z = 10 =\binom{10+3-1}{10}=12 \times 3=66 z 6(0,2,4,6,8,10) =\frac{6}{66}=\frac{1}{11} \frac{6}{11}","['probability', 'combinatorics']"
88,$Var(aX) = a^2Var(X)$ but $Var(X+Y) = Var(X) + Var(Y)$. How does this make any sense?,but . How does this make any sense?,Var(aX) = a^2Var(X) Var(X+Y) = Var(X) + Var(Y),"Apologies for the less than clear question, I wasn't quite sure how to phrase it. Say you have a random variable $X ~ N(5, 10^2)$. Say you have another random variable $Y ~ N(5, 10^2)$. Var(2X) = 4Var(X) = 4*10^2 But: $Var(X+Y) = Var(X) + Var(Y) = 2\times 10^2$ But now a question arises: what?! X = Y so Var(2X) = Var(X+X) = Var(X+Y) and yet two different answers are reached using the two distinct accepted formulas. How does this make any sense? What's going wrong? It shouldn't matter what we call the random variables, and yet it seems as if it does.","Apologies for the less than clear question, I wasn't quite sure how to phrase it. Say you have a random variable $X ~ N(5, 10^2)$. Say you have another random variable $Y ~ N(5, 10^2)$. Var(2X) = 4Var(X) = 4*10^2 But: $Var(X+Y) = Var(X) + Var(Y) = 2\times 10^2$ But now a question arises: what?! X = Y so Var(2X) = Var(X+X) = Var(X+Y) and yet two different answers are reached using the two distinct accepted formulas. How does this make any sense? What's going wrong? It shouldn't matter what we call the random variables, and yet it seems as if it does.",,"['probability', 'variance']"
89,"You cast a pair of dice. If you get a 6 and an 8 before 7 comes up twice, you win. What is the probability of winning?","You cast a pair of dice. If you get a 6 and an 8 before 7 comes up twice, you win. What is the probability of winning?",,"You cast a pair of dice. If you get a 6 and an 8 before 7 comes up twice, you win. What is the probability of winning? What I tried was  \begin{align*}  P(X=6) & = \frac{5}{36}\\  P(X=8) & = \frac{5}{36}\\  P(X=7) & = \frac{6}{36} = \frac{1}{6} \end{align*} I try finding the probability of getting $6$ and $8$ and not $7$ $$P(X=6)+P(X=8)+P(X \neq 7) = \frac{5}{26} + \frac{5}{36} + \frac{5}{6} = 1.11$$ I stick since I know that the probability cannot be greater than one. The solution key says the answer is $0.5456$.","You cast a pair of dice. If you get a 6 and an 8 before 7 comes up twice, you win. What is the probability of winning? What I tried was  \begin{align*}  P(X=6) & = \frac{5}{36}\\  P(X=8) & = \frac{5}{36}\\  P(X=7) & = \frac{6}{36} = \frac{1}{6} \end{align*} I try finding the probability of getting $6$ and $8$ and not $7$ $$P(X=6)+P(X=8)+P(X \neq 7) = \frac{5}{26} + \frac{5}{36} + \frac{5}{6} = 1.11$$ I stick since I know that the probability cannot be greater than one. The solution key says the answer is $0.5456$.",,"['probability', 'dice']"
90,Probability of sum to be divisible by 7,Probability of sum to be divisible by 7,,6 fair dice are thrown simultaneously. What is the probability that the sum of the numbers appeared on dice is divisible by 7 ?,6 fair dice are thrown simultaneously. What is the probability that the sum of the numbers appeared on dice is divisible by 7 ?,,['probability']
91,measure of irrational number,measure of irrational number,,"I've once read a proof about this and I'm trying to remember how it went. We want to show that if we randomly select a number $x$ from the set $[0,1],$ then $P[  \text {x is irrational} ] = 1$",I've once read a proof about this and I'm trying to remember how it went. We want to show that if we randomly select a number from the set then,"x [0,1], P[  \text {x is irrational} ] = 1","['probability', 'measure-theory', 'real-numbers']"
92,how do I prove standardizing a normally distributed random variable,how do I prove standardizing a normally distributed random variable,,Let X be a random variable of mean $\mu$ and variance $\sigma^2$. Use the properties of expectation to show that $$Z=\frac{X-\mu}{\sigma}$$ has mean 0 and variance 1. Let Z be a random variable of mean 0 and variance 1. Show that  $$X=\sigma Z+\mu$$ has mean $\mu$ and variance $\sigma^2$. I think I have to use $f_Z(z)=\frac{1}{\sqrt{2\pi}}e^{\frac{-z^2}{2}}$ to help me prove this but I have no idea where to start? I know what expectation is and how to calculate it but which properties specifically is the question talking about?,Let X be a random variable of mean $\mu$ and variance $\sigma^2$. Use the properties of expectation to show that $$Z=\frac{X-\mu}{\sigma}$$ has mean 0 and variance 1. Let Z be a random variable of mean 0 and variance 1. Show that  $$X=\sigma Z+\mu$$ has mean $\mu$ and variance $\sigma^2$. I think I have to use $f_Z(z)=\frac{1}{\sqrt{2\pi}}e^{\frac{-z^2}{2}}$ to help me prove this but I have no idea where to start? I know what expectation is and how to calculate it but which properties specifically is the question talking about?,,"['probability', 'random-variables']"
93,Expected flips for $n$ coins,Expected flips for  coins,n,"In the start, $n$ coins are flipped. Every round, if a coin lands   heads, it stops being flipped. What is the expected number of rounds it will   take to stop flipping completely? For $1$ coin, the answer is $2$. For $n$ coins, this is $E(1) + 2E(2) + ...$, with each $E(X)$ meaning one coin took $X$ tries and all the others took $\le X$ tries ($\max = X$). I am unsure of how to find a formula for this.","In the start, $n$ coins are flipped. Every round, if a coin lands   heads, it stops being flipped. What is the expected number of rounds it will   take to stop flipping completely? For $1$ coin, the answer is $2$. For $n$ coins, this is $E(1) + 2E(2) + ...$, with each $E(X)$ meaning one coin took $X$ tries and all the others took $\le X$ tries ($\max = X$). I am unsure of how to find a formula for this.",,['probability']
94,Chance on throwing last number of full house with two die,Chance on throwing last number of full house with two die,,I had a discussion with my family again while playing Yahtzee. Lets say I have 3 throws per round with 5 die. The first round I throw 3 - 3 - 2 - 2 -5 I need full house so I need 3 - 3 - 3 - 2 -2 or 2 - 2 - 2 -3 -3 After the first throw I need a 3rd 3 or a 3rd 2. So we had a discussion about the chance to throw the last needed number. So they asked me what is the chance? But I really don't know how I should calculate it while the problem looks fairly simple to me. Hopefully someone can help and can explain it in a way 'everyone'  can understand the way to calculate it.,I had a discussion with my family again while playing Yahtzee. Lets say I have 3 throws per round with 5 die. The first round I throw 3 - 3 - 2 - 2 -5 I need full house so I need 3 - 3 - 3 - 2 -2 or 2 - 2 - 2 -3 -3 After the first throw I need a 3rd 3 or a 3rd 2. So we had a discussion about the chance to throw the last needed number. So they asked me what is the chance? But I really don't know how I should calculate it while the problem looks fairly simple to me. Hopefully someone can help and can explain it in a way 'everyone'  can understand the way to calculate it.,,['probability']
95,Halting probability of random tree-generating algorithm,Halting probability of random tree-generating algorithm,,"Suppose I have a tree-generating algorithm as follows. Begin with one root vertex. With equal probability, create either three subvertices or none. Recurse and repeat for each of the subvertices (if any). What is the probability that this algorithm will halt?","Suppose I have a tree-generating algorithm as follows. Begin with one root vertex. With equal probability, create either three subvertices or none. Recurse and repeat for each of the subvertices (if any). What is the probability that this algorithm will halt?",,"['probability', 'graph-theory', 'trees']"
96,Sum of two Beta distributed random variables,Sum of two Beta distributed random variables,,"I want to establish (although  I am not certain that it is possible to do so) that, if X,Y  with $X \sim Beta(\alpha_1, 1- \alpha_1)$ $Y \sim Beta(\alpha_2, 1- \alpha_2)$ then $X+Y \sim Beta(\alpha_1+\alpha_2, 1-\alpha_1-\alpha_2)$ With the convolution I have: $ \int_0^1f_Y(z-x)f_X(x)dx $ $ =\int_0^1 \frac{1}{B(\alpha_1,1-\alpha_1)}\cdot(z-x)^{\alpha_1-1}\cdot(1-z+x)^{-\alpha_1}\frac{1}{B(\alpha_2,1-\alpha_2)}\cdot x^{\alpha_2-1}\cdot(1-x)^{-\alpha_2} $ $ =\frac{1}{\Gamma(\alpha_1)\Gamma(\alpha_2)\Gamma(1-\alpha_1)\Gamma(1-\alpha_2)}\int_0^1 \cdot(z-x)^{\alpha_1-1}\cdot(1-z+x)^{-\alpha_1}\cdot x^{\alpha_2-1}\cdot(1-x)^{-\alpha_2} $ I dont see how to continue here. Any ideas are appreciated! Kind Regards  Humboldt","I want to establish (although  I am not certain that it is possible to do so) that, if X,Y  with $X \sim Beta(\alpha_1, 1- \alpha_1)$ $Y \sim Beta(\alpha_2, 1- \alpha_2)$ then $X+Y \sim Beta(\alpha_1+\alpha_2, 1-\alpha_1-\alpha_2)$ With the convolution I have: $ \int_0^1f_Y(z-x)f_X(x)dx $ $ =\int_0^1 \frac{1}{B(\alpha_1,1-\alpha_1)}\cdot(z-x)^{\alpha_1-1}\cdot(1-z+x)^{-\alpha_1}\frac{1}{B(\alpha_2,1-\alpha_2)}\cdot x^{\alpha_2-1}\cdot(1-x)^{-\alpha_2} $ $ =\frac{1}{\Gamma(\alpha_1)\Gamma(\alpha_2)\Gamma(1-\alpha_1)\Gamma(1-\alpha_2)}\int_0^1 \cdot(z-x)^{\alpha_1-1}\cdot(1-z+x)^{-\alpha_1}\cdot x^{\alpha_2-1}\cdot(1-x)^{-\alpha_2} $ I dont see how to continue here. Any ideas are appreciated! Kind Regards  Humboldt",,['probability']
97,When does $P(A|B) = P(B|A)$?,When does ?,P(A|B) = P(B|A),"If A and B are events, when does $P(A|B) = P(B|A)$? If it is not always true, please provide a counter example as I cannot.","If A and B are events, when does $P(A|B) = P(B|A)$? If it is not always true, please provide a counter example as I cannot.",,['probability']
98,Probability of Winning a Contest,Probability of Winning a Contest,,"This is my first question so apologies if its unclear/vague. There exists a contest with me in it, and $5$ others, thus $6$ people in total, along with $5$ prizes. A person can only win one prize, and once they do, they're out of the contest. Winners are chosen at random. So, what is the chance of me winning at a prize? My initial thought was: $\frac16$ chance initially, then $\frac15$ if I don't win the first time, $\frac14$ if I don't win the second, ect. as people are removed once they win, resulting in $\frac16+\frac15+\frac14+\frac13+\frac12 = 1.45$ which is $145$%. This is greater than $100$%, and obviously I am not guaranteed to win as I can be the $1$ loser, so how do you find the correct probability? Thanks! Edit: All of you have been extremely helpful. Thank you!","This is my first question so apologies if its unclear/vague. There exists a contest with me in it, and $5$ others, thus $6$ people in total, along with $5$ prizes. A person can only win one prize, and once they do, they're out of the contest. Winners are chosen at random. So, what is the chance of me winning at a prize? My initial thought was: $\frac16$ chance initially, then $\frac15$ if I don't win the first time, $\frac14$ if I don't win the second, ect. as people are removed once they win, resulting in $\frac16+\frac15+\frac14+\frac13+\frac12 = 1.45$ which is $145$%. This is greater than $100$%, and obviously I am not guaranteed to win as I can be the $1$ loser, so how do you find the correct probability? Thanks! Edit: All of you have been extremely helpful. Thank you!",,['probability']
99,"Why is $E(\min(A, B)) < \min(E(A), E(B))$?",Why is ?,"E(\min(A, B)) < \min(E(A), E(B))","Let $A$ and $B$ be independent, positive random variables. Why must $E(\min(A, B)) < \min(E(A), E(B))$, where $\min(X, Y)$ is the minimum of $X$ and $Y$? I would think the opposite, that $E(A, B) > \min(E(A), E(B))$ because $E(\min(A, B))$ weights all possible values.","Let $A$ and $B$ be independent, positive random variables. Why must $E(\min(A, B)) < \min(E(A), E(B))$, where $\min(X, Y)$ is the minimum of $X$ and $Y$? I would think the opposite, that $E(A, B) > \min(E(A), E(B))$ because $E(\min(A, B))$ weights all possible values.",,['probability']
