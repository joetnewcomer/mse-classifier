,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to find an entire function $f(z)$ such that $f(n) = \sqrt {|n|}$ for every integer $n$?,How to find an entire function  such that  for every integer ?,f(z) f(n) = \sqrt {|n|} n,How to find an entire function $f(z)$ such that $f(n) = \sqrt {|n|}$ for every integer $n$? Now my thinking is to create a series $\displaystyle\sum_{k=-\infty}^\infty f_{k}(z)$ such that $f_{k}(z)=\sqrt{|k|}$ and the series is convergent for every $z$. Thanks for any help,How to find an entire function $f(z)$ such that $f(n) = \sqrt {|n|}$ for every integer $n$? Now my thinking is to create a series $\displaystyle\sum_{k=-\infty}^\infty f_{k}(z)$ such that $f_{k}(z)=\sqrt{|k|}$ and the series is convergent for every $z$. Thanks for any help,,"['complex-analysis', 'entire-functions']"
1,Please recommend good text on complex Fourier series/analysis,Please recommend good text on complex Fourier series/analysis,,"I am looking for some good text/reference on complex Fourier series resp. Fourier analysis for complex (in particular holomoprhic) functions (of one variable). The more it contains on this particular subject, the better. Background: For my diploma thesis, I need in particular to understand asymptotics of the Fourier coefficients for certain entire functions, so I need to study it fast, that is, more straightforward, well-structured theory without much ""bla-bla"", and less exercises... Nevertheless, I would like to learn the more general theory of Fourier analysis for complex/holomorphic functions as it has a great deal of applications in Analytic Number Theory, which is one of the subjects of interest to me. Thanks in advance!","I am looking for some good text/reference on complex Fourier series resp. Fourier analysis for complex (in particular holomoprhic) functions (of one variable). The more it contains on this particular subject, the better. Background: For my diploma thesis, I need in particular to understand asymptotics of the Fourier coefficients for certain entire functions, so I need to study it fast, that is, more straightforward, well-structured theory without much ""bla-bla"", and less exercises... Nevertheless, I would like to learn the more general theory of Fourier analysis for complex/holomorphic functions as it has a great deal of applications in Analytic Number Theory, which is one of the subjects of interest to me. Thanks in advance!",,"['complex-analysis', 'analysis', 'reference-request', 'soft-question', 'fourier-analysis']"
2,Average of one over sum of complex exponentials,Average of one over sum of complex exponentials,,"I need to compute a time-average which is of the form $$ \lim_\limits{T \to \infty} \frac{1}{T} \int_0^T \frac{\mathrm{d}t}{1+\sum_k c_k e^{i x_k t}} $$ where $x_k \in \mathbb{R}$ , $c_k \in \mathbb{C}$ and the sum in the denominator is finite, $k=1,\ldots,K$ . I tried substituting $z = e^{it}$ and using the residue theorem but in the end I didn't get far. Is there some way of getting a closed form expression for the limit? Alternatively, I don't mind if I have to use numerical techniques, but preferably I'd do it on a limit where the convergence is more controlled.","I need to compute a time-average which is of the form where , and the sum in the denominator is finite, . I tried substituting and using the residue theorem but in the end I didn't get far. Is there some way of getting a closed form expression for the limit? Alternatively, I don't mind if I have to use numerical techniques, but preferably I'd do it on a limit where the convergence is more controlled."," \lim_\limits{T \to \infty} \frac{1}{T} \int_0^T \frac{\mathrm{d}t}{1+\sum_k c_k e^{i x_k t}}  x_k \in \mathbb{R} c_k \in \mathbb{C} k=1,\ldots,K z = e^{it}",['complex-analysis']
3,Orbits of $z_{n+1} = z_n ^2 - 1$,Orbits of,z_{n+1} = z_n ^2 - 1,"Consider the sequence $z_{n+1} = z_n ^2 - 1$ defined for an arbitrary complex number $z_0$ . I am trying to determine all $z_0$ such that the sequence eventually becomes periodic. Here is my progress so far: If $|z_0|> \frac{1+\sqrt{5}}{2}$ the sequence is absolutely increasing since $$|z_{n+1}|=|z_n^2 - 1|\geq|z_n|^2-1 > |z_n| ,$$ which is true since $ |z_n| > \frac{1+\sqrt{5}}{2}$ holds inductively. If $z_0=\frac{1+\sqrt{5}}{2}$ the sequence would be the constant sequence of $\frac{1+\sqrt{5}}{2}$ and hence periodic. Similar to the first case if $|z_0|<\frac{1}{2}$ or more precisely if $|z_0|$ less than the root of $\alpha^3 +2\alpha -1 = 0,$ the sequence $\{z_{2i} \}$ becomes strictly decreasing since $$|z_{2i}| = |z_{2i-1}^2 - 1 |= |z_{2i-2}^4 - 2z_{2i-2}^2|<  |z_{2i-2}| \Leftrightarrow |z_{2i-2}^3 - 2z_{2i-2}| < 1.$$ Which holds true if $$ |z_{2i-2}^3 - 2z_{2i-2}| \leq  |z_{2i-2}^3|+| 2z_{2i-2}| <1.$$ And as a result $\{z_i\}$ cannot be periodic.",Consider the sequence defined for an arbitrary complex number . I am trying to determine all such that the sequence eventually becomes periodic. Here is my progress so far: If the sequence is absolutely increasing since which is true since holds inductively. If the sequence would be the constant sequence of and hence periodic. Similar to the first case if or more precisely if less than the root of the sequence becomes strictly decreasing since Which holds true if And as a result cannot be periodic.,"z_{n+1} = z_n ^2 - 1 z_0 z_0 |z_0|> \frac{1+\sqrt{5}}{2} |z_{n+1}|=|z_n^2 - 1|\geq|z_n|^2-1 > |z_n| ,  |z_n| > \frac{1+\sqrt{5}}{2} z_0=\frac{1+\sqrt{5}}{2} \frac{1+\sqrt{5}}{2} |z_0|<\frac{1}{2} |z_0| \alpha^3 +2\alpha -1 = 0, \{z_{2i} \} |z_{2i}| = |z_{2i-1}^2 - 1 |= |z_{2i-2}^4 - 2z_{2i-2}^2|<  |z_{2i-2}| \Leftrightarrow |z_{2i-2}^3 - 2z_{2i-2}| < 1.  |z_{2i-2}^3 - 2z_{2i-2}| \leq  |z_{2i-2}^3|+| 2z_{2i-2}| <1. \{z_i\}",['complex-analysis']
4,Evaluating a Lie Derivative of a Meromorphic Complex Form over a Holomorphic Vector Field.,Evaluating a Lie Derivative of a Meromorphic Complex Form over a Holomorphic Vector Field.,,"Given a meromorphic form $\omega : \Omega^{1, 0}$ , we can get the form $\; \mathrm{d}\omega = \partial \omega + \bar \partial \omega \;$ through the use of Dolbeault operators. I'm trying to find the lie derivative $\mathcal{L}_v \; \omega$ , where $v$ is a holomorphic vector field. How can I find this for non-holomorphic forms? For example, suppose we allow the following definitions: $$ \omega = \frac{z+4}{z-3i} \; \mathrm{d}z, \quad v = 2z-1.$$ What is the Lie derivative $\mathcal{L}_v \;\omega$ ?","Given a meromorphic form , we can get the form through the use of Dolbeault operators. I'm trying to find the lie derivative , where is a holomorphic vector field. How can I find this for non-holomorphic forms? For example, suppose we allow the following definitions: What is the Lie derivative ?","\omega : \Omega^{1, 0} \; \mathrm{d}\omega = \partial \omega + \bar \partial \omega \; \mathcal{L}_v \; \omega v  \omega = \frac{z+4}{z-3i} \; \mathrm{d}z, \quad v = 2z-1. \mathcal{L}_v \;\omega","['complex-analysis', 'multivariable-calculus', 'differential-geometry', 'differential-forms']"
5,Has there been any exploration on Cubic Power Series?,Has there been any exploration on Cubic Power Series?,,"I was interested in finding some identities/special values involving the function $$\gamma(z) = \sum_{i=0}^{\infty} z^{i^3} = 1 + z + z^8 + z^{27} + ... $$ which can be thought of as a ""cubic generalization of the famous $$\theta(z) = \sum_{i=0}^{\infty} z^{i^2} = 1 + z + z^4 + z^9 + ... $$ Which can be cooked up using jacobi theta functions. Unfortunately the term ""cubic theta function"" doesn't lead to any insight on this series since the ""cubic"" is reserved for a type of identity as opposed to the form of the series. Surely these have been looked at before does anyone have any links/intel about them?","I was interested in finding some identities/special values involving the function which can be thought of as a ""cubic generalization of the famous Which can be cooked up using jacobi theta functions. Unfortunately the term ""cubic theta function"" doesn't lead to any insight on this series since the ""cubic"" is reserved for a type of identity as opposed to the form of the series. Surely these have been looked at before does anyone have any links/intel about them?",\gamma(z) = \sum_{i=0}^{\infty} z^{i^3} = 1 + z + z^8 + z^{27} + ...  \theta(z) = \sum_{i=0}^{\infty} z^{i^2} = 1 + z + z^4 + z^9 + ... ,"['complex-analysis', 'reference-request', 'functional-equations', 'theta-functions', 'lacunary-series']"
6,Classification of holomorphic functions on the right half plane with certain conditions,Classification of holomorphic functions on the right half plane with certain conditions,,"The following problem comes from an old complex analysis prelim exam: Determine all analytic functions $f: H \rightarrow \mathbb{C}$ on the half-plane $H : = \{ z\in \mathbb{C} : \Re(z) > 0 \}$ that satisfy $f(\sqrt{n}) = n$ and $|f^{(n)}(1)| \leq 3$ for all positive integers $n$ . Clearly $f(z) = z^2$ satisfies this, and I wish to show that this is the only example. Note that $f(z) = z^2 + \epsilon \sin(\pi z^2)$ fail to satisfy the derivative bound for any $\epsilon > 0$ . Additionally, the derivative bound implies that any such $f$ is analytic and sub-exponential with order 1. I can apply Carlson's theorem to show that $h(z): =f(z) - z^2$ is exactly zero, but this seems like a very heavy hammer to use for a prelim problem. Any guidance on a more simple proof would be greatly appreciated!","The following problem comes from an old complex analysis prelim exam: Determine all analytic functions on the half-plane that satisfy and for all positive integers . Clearly satisfies this, and I wish to show that this is the only example. Note that fail to satisfy the derivative bound for any . Additionally, the derivative bound implies that any such is analytic and sub-exponential with order 1. I can apply Carlson's theorem to show that is exactly zero, but this seems like a very heavy hammer to use for a prelim problem. Any guidance on a more simple proof would be greatly appreciated!",f: H \rightarrow \mathbb{C} H : = \{ z\in \mathbb{C} : \Re(z) > 0 \} f(\sqrt{n}) = n |f^{(n)}(1)| \leq 3 n f(z) = z^2 f(z) = z^2 + \epsilon \sin(\pi z^2) \epsilon > 0 f h(z): =f(z) - z^2,['complex-analysis']
7,"Cusp form for $\text{SL}_2(\mathbb{Z})$ attaining a maximum on $\mathcal{D}=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac12,\|z\|\geq 1\}$",Cusp form for  attaining a maximum on,"\text{SL}_2(\mathbb{Z}) \mathcal{D}=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac12,\|z\|\geq 1\}","Let $f:\mathbb{H}\to\mathbb{C}$ , $z\mapsto\sum\limits_{i=1}^\infty a_i\exp(2\pi iz)$ be a non-zero weight- $0$ cusp form for $\text{SL}_2(\mathbb{Z})$ . Then $|f|$ attains a maximum on $\mathbb{H}$ . We can restrict to finding a bound on the fundamental domain $\mathcal{D}=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac{1}{2},\|z\|\geq 1\}$ , since $f$ has weight $0$ . Is is true that $f$ being a cusp form implies that $\lim\limits_{y\to\infty}f(x+iy)=0$ uniformly in $x$ for $|x|\leq\frac{1}{2}$ ? If it holds, I wanted to reason as follows. Pick some $z_0\in\mathcal{D}$ such that $f(z_0)\neq 0$ . Take $0<\epsilon<\frac{|f(z)|}{2}$ . Then there exists an $M\geq 0$ such that $|f(x+iy)|\leq\epsilon$ for all $x+iy\in\mathcal{D}$ with $y\geq M$ . Since the set $\mathcal{D}_M=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac{1}{2},\text{Im}(z)\leq M,\|z\|\geq 1\}$ is compact, $|f|$ takes a maximum on $\mathcal{D}_M$ . Now this maximum cannot be on the line $y=M$ , since $|f(x+iM)|\leq\frac{|f(z_0)|}{2}$ . Does, it follows that $f$ takes some maximum value on $\mathcal{D}_M^\circ=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac{1}{2},\text{Im}(z)<M,\|z\|\geq 1\}$ . Call this maximum $K$ . By constrution of $\mathcal{D}_M$ , we have that $|f(z)|<\frac{|f(z_0)|}{2}\leq K$ outside $\mathcal{D}_M$ , hereby proven that $|f|$ takes a maximum value on $\mathcal{D}$ .","Let , be a non-zero weight- cusp form for . Then attains a maximum on . We can restrict to finding a bound on the fundamental domain , since has weight . Is is true that being a cusp form implies that uniformly in for ? If it holds, I wanted to reason as follows. Pick some such that . Take . Then there exists an such that for all with . Since the set is compact, takes a maximum on . Now this maximum cannot be on the line , since . Does, it follows that takes some maximum value on . Call this maximum . By constrution of , we have that outside , hereby proven that takes a maximum value on .","f:\mathbb{H}\to\mathbb{C} z\mapsto\sum\limits_{i=1}^\infty a_i\exp(2\pi iz) 0 \text{SL}_2(\mathbb{Z}) |f| \mathbb{H} \mathcal{D}=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac{1}{2},\|z\|\geq 1\} f 0 f \lim\limits_{y\to\infty}f(x+iy)=0 x |x|\leq\frac{1}{2} z_0\in\mathcal{D} f(z_0)\neq 0 0<\epsilon<\frac{|f(z)|}{2} M\geq 0 |f(x+iy)|\leq\epsilon x+iy\in\mathcal{D} y\geq M \mathcal{D}_M=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac{1}{2},\text{Im}(z)\leq M,\|z\|\geq 1\} |f| \mathcal{D}_M y=M |f(x+iM)|\leq\frac{|f(z_0)|}{2} f \mathcal{D}_M^\circ=\{z\in\mathbb{H}\colon|\text{Re}(z)|\leq\frac{1}{2},\text{Im}(z)<M,\|z\|\geq 1\} K \mathcal{D}_M |f(z)|<\frac{|f(z_0)|}{2}\leq K \mathcal{D}_M |f| \mathcal{D}","['complex-analysis', 'fourier-analysis', 'maxima-minima', 'modular-forms']"
8,Help with the integral $\int_{0}^{\infty}\frac{x^{s}}{\Gamma(s)}s^{z-1}ds$,Help with the integral,\int_{0}^{\infty}\frac{x^{s}}{\Gamma(s)}s^{z-1}ds,"Consider the integral : $$\int_{0}^{\infty}\frac{x^{s}}{\Gamma(s)}s^{z-1}ds$$ Where $x\in \mathbb{R}^{+}$ , $z\in \mathbb{C}$ Using the Hankel contour representation of the reciprocal gamma function, we have: $$\int_{0}^{\infty}\frac{x^{s}}{\Gamma(s)}s^{z-1}ds=\frac{i}{2\pi}\oint \int_{0}^{\infty} \left(-\frac{x}{t}\right)^{s}s^{z-1}e^{-t}dsdt$$ $$=\Gamma(z)\frac{i}{2\pi}\oint \left(-\log\left(-\frac{x}{t}\right)\right)^{-z}e^{-t}dt$$ But i have no idea on how to do this integral. any help is highly appreciated","Consider the integral : Where , Using the Hankel contour representation of the reciprocal gamma function, we have: But i have no idea on how to do this integral. any help is highly appreciated",\int_{0}^{\infty}\frac{x^{s}}{\Gamma(s)}s^{z-1}ds x\in \mathbb{R}^{+} z\in \mathbb{C} \int_{0}^{\infty}\frac{x^{s}}{\Gamma(s)}s^{z-1}ds=\frac{i}{2\pi}\oint \int_{0}^{\infty} \left(-\frac{x}{t}\right)^{s}s^{z-1}e^{-t}dsdt =\Gamma(z)\frac{i}{2\pi}\oint \left(-\log\left(-\frac{x}{t}\right)\right)^{-z}e^{-t}dt,"['complex-analysis', 'definite-integrals']"
9,Show that these Kähler forms are $\sqrt{-1}\partial \overline{\partial}$-cohomologous,Show that these Kähler forms are -cohomologous,\sqrt{-1}\partial \overline{\partial},"I have decided to rewrite my question almost entirely: Let $Y$ be a compact (without boundary) Calabi-Yau manifold, i.e., $c_1(Y)=0$ in $H^2(Y, \mathbb{R})$ . Let $\omega$ be a Kähler form on $\mathbb{C}^m \times Y$ and let $\omega_P = \omega_{\mathbb{C}^m} + \omega_Y$ . It can be shown (see, e.g., the first statement of [1, Theorem A]) that $\zeta = \omega - \omega_P$ is an exact $(1,1)$ -form, i.e., $\zeta = d\xi$ for some real $1$ -form $\xi$ on $\mathbb{C}^m \times Y$ . My question concerns obtaining a more direct proof of Statement (ii) of [1, Theorem A]. That is, I am attempting to prove that there exists an automorphism $T$ of $\mathbb{C}^m$ such that $$\omega = T^{\ast} \omega_{\mathbb{C}^m} + \omega_Y + \sqrt{-1}\partial \overline{\partial} \varphi,$$ for some smooth $\mathbb{R}$ -valued function $\varphi$ . The proof given in [1, Proposition 3.1] is too abstract, and I would like a proof along the same lines as the Poincaré lemma and the Dolbeault lemma. In [2], the authors write $\omega$ can be expressed in local coordinates as \begin{eqnarray*} \omega &=& \hat{\omega}_{\mathbb{C}^m} + \omega_Y + \frac{1}{2} \sum_{i=1}^n dz^i \wedge \eta^i + \frac{1}{2} \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i, \end{eqnarray*} where $\eta^i = \left( \frac{\partial}{\partial z^i} \ \llcorner \ \omega \right) $ (here $\llcorner$ denotes the interior product), and $\hat{\omega}_{\mathbb{C}^m} = \frac{1}{2} \sum_{i,j=1}^m u_{i \overline{j}} dz^i \wedge d\overline{z}^j$ for some Hermitian matrix $(u_{i \overline{j}})$ . I might be able to make a lot of progress if $\sum_{i=1}^m dz^i \wedge \eta^i + \sum_{i=1}^m d\overline{z}^i \wedge \overline{\eta}^i$ could be written as $\partial \overline{\partial}\varphi$ for some smooth function $\varphi$ . References: [1] Hein, H.-J., A Liouville theorem for the complex Monge-Ampère equation on product manifolds , arxiv: 1701.05147. ( https://arxiv.org/abs/1701.05147 ) [2] Li, C., Li, J., Zhang, X., A mean value formula and a Liouville theorem for the complex Monge-Ampère equation , arxiv: 1709.05754. ( https://arxiv.org/abs/1709.05754 ) An attempt: Let $(z_1, ..., z_m, z_{m+1}, ..., z_{m+n})$ denote the local coordinates on $\mathbb{C}^m \times Y$ . Since the Kähler forms $\omega$ and $\omega_{\mathbb{C}^m} + \omega_Y$ are cohomologous, there exists a real $1$ -form $\xi$ such that $$\omega = \omega_{\mathbb{C}^m} + \omega_Y + d \xi.$$ Comparing the degrees of these forms, it is clear that if we decompose $\xi = \xi^{1,0} + \xi^{0,1}$ according the decompositon $\Lambda^1 = \Lambda^{1,0} \oplus \Lambda^{0,1}$ , then $\partial \xi^{1,0} = 0 = \overline{\partial} \xi^{0,1}$ . Hence, we see that \begin{eqnarray*} \omega &=& \omega_{\mathbb{C}^m} + \omega_Y + \partial \xi^{0,1} + \overline{\partial} \xi^{1,0}. \end{eqnarray*} Following [2], set $\eta^i = \left( \frac{\partial}{\partial z^i} \ \llcorner \ \omega \right) \Bigg \vert_{\{ z \} \times Y}$ . If we write $\omega = \frac{\sqrt{-1}}{2} \sum_{i,j=1}^{m+n} g_{i \overline{j}} dz^i \wedge d\overline{z}^j$ , then \begin{eqnarray*} \eta^i &=& \frac{\sqrt{-1}}{2} \sum_{j=m+1}^{m+n} g_{i \overline{j}} d\overline{z}^j. \end{eqnarray*} Hence, we see that \begin{eqnarray*} &&\sum_{i=1}^n dz^i \wedge \eta^i + \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i \\ &=& \frac{\sqrt{-1}}{2} \sum_{i=1}^n \sum_{j=m+1}^{m+n} g_{i \overline{j}} dz^i \wedge d\overline{z}^j+ \frac{\sqrt{-1}}{2} \sum_{i=1}^n \sum_{j=m+1}^{m+n} g_{j \overline{i}} dz^j \wedge d\overline{z}^i.  \end{eqnarray*} The claim from [2] is that there now exists a Hermitian matrix $(u_{i \overline{j}})$ such that $\omega = \hat{\omega}_{\mathbb{C}^m} + \omega_Y + \frac{1}{2} \sum_{i=1}^n dz^i \wedge \eta^i + \frac{1}{2} \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i$ .","I have decided to rewrite my question almost entirely: Let be a compact (without boundary) Calabi-Yau manifold, i.e., in . Let be a Kähler form on and let . It can be shown (see, e.g., the first statement of [1, Theorem A]) that is an exact -form, i.e., for some real -form on . My question concerns obtaining a more direct proof of Statement (ii) of [1, Theorem A]. That is, I am attempting to prove that there exists an automorphism of such that for some smooth -valued function . The proof given in [1, Proposition 3.1] is too abstract, and I would like a proof along the same lines as the Poincaré lemma and the Dolbeault lemma. In [2], the authors write can be expressed in local coordinates as where (here denotes the interior product), and for some Hermitian matrix . I might be able to make a lot of progress if could be written as for some smooth function . References: [1] Hein, H.-J., A Liouville theorem for the complex Monge-Ampère equation on product manifolds , arxiv: 1701.05147. ( https://arxiv.org/abs/1701.05147 ) [2] Li, C., Li, J., Zhang, X., A mean value formula and a Liouville theorem for the complex Monge-Ampère equation , arxiv: 1709.05754. ( https://arxiv.org/abs/1709.05754 ) An attempt: Let denote the local coordinates on . Since the Kähler forms and are cohomologous, there exists a real -form such that Comparing the degrees of these forms, it is clear that if we decompose according the decompositon , then . Hence, we see that Following [2], set . If we write , then Hence, we see that The claim from [2] is that there now exists a Hermitian matrix such that .","Y c_1(Y)=0 H^2(Y, \mathbb{R}) \omega \mathbb{C}^m \times Y \omega_P = \omega_{\mathbb{C}^m} + \omega_Y \zeta = \omega - \omega_P (1,1) \zeta = d\xi 1 \xi \mathbb{C}^m \times Y T \mathbb{C}^m \omega = T^{\ast} \omega_{\mathbb{C}^m} + \omega_Y + \sqrt{-1}\partial \overline{\partial} \varphi, \mathbb{R} \varphi \omega \begin{eqnarray*}
\omega &=& \hat{\omega}_{\mathbb{C}^m} + \omega_Y + \frac{1}{2} \sum_{i=1}^n dz^i \wedge \eta^i + \frac{1}{2} \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i,
\end{eqnarray*} \eta^i = \left( \frac{\partial}{\partial z^i} \ \llcorner \ \omega \right)  \llcorner \hat{\omega}_{\mathbb{C}^m} = \frac{1}{2} \sum_{i,j=1}^m u_{i \overline{j}} dz^i \wedge d\overline{z}^j (u_{i \overline{j}}) \sum_{i=1}^m dz^i \wedge \eta^i + \sum_{i=1}^m d\overline{z}^i \wedge \overline{\eta}^i \partial \overline{\partial}\varphi \varphi (z_1, ..., z_m, z_{m+1}, ..., z_{m+n}) \mathbb{C}^m \times Y \omega \omega_{\mathbb{C}^m} + \omega_Y 1 \xi \omega = \omega_{\mathbb{C}^m} + \omega_Y + d \xi. \xi = \xi^{1,0} + \xi^{0,1} \Lambda^1 = \Lambda^{1,0} \oplus \Lambda^{0,1} \partial \xi^{1,0} = 0 = \overline{\partial} \xi^{0,1} \begin{eqnarray*}
\omega &=& \omega_{\mathbb{C}^m} + \omega_Y + \partial \xi^{0,1} + \overline{\partial} \xi^{1,0}.
\end{eqnarray*} \eta^i = \left( \frac{\partial}{\partial z^i} \ \llcorner \ \omega \right) \Bigg \vert_{\{ z \} \times Y} \omega = \frac{\sqrt{-1}}{2} \sum_{i,j=1}^{m+n} g_{i \overline{j}} dz^i \wedge d\overline{z}^j \begin{eqnarray*}
\eta^i &=& \frac{\sqrt{-1}}{2} \sum_{j=m+1}^{m+n} g_{i \overline{j}} d\overline{z}^j.
\end{eqnarray*} \begin{eqnarray*}
&&\sum_{i=1}^n dz^i \wedge \eta^i + \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i \\
&=& \frac{\sqrt{-1}}{2} \sum_{i=1}^n \sum_{j=m+1}^{m+n} g_{i \overline{j}} dz^i \wedge d\overline{z}^j+ \frac{\sqrt{-1}}{2} \sum_{i=1}^n \sum_{j=m+1}^{m+n} g_{j \overline{i}} dz^j \wedge d\overline{z}^i. 
\end{eqnarray*} (u_{i \overline{j}}) \omega = \hat{\omega}_{\mathbb{C}^m} + \omega_Y + \frac{1}{2} \sum_{i=1}^n dz^i \wedge \eta^i + \frac{1}{2} \sum_{i=1}^n d\overline{z}^i \wedge \overline{\eta}^i","['complex-analysis', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds']"
10,Proving an analytic function $f$ is bounded on $|z|\le1/2$ independent of $f$ subject to certain conditions,Proving an analytic function  is bounded on  independent of  subject to certain conditions,f |z|\le1/2 f,"Let $f:D(0,1) \to \mathbb C$ be analytic. Show that there is a constant $C$ independent of $f$ such that if $f(0)=1$ and $f(z) \notin (-\infty,0]$ for all $z \in D(0,1)$, then $|f(z)| \le C$ whenever $|z| \le 1/2$. I have (finally) figured out how to prove this, and I ended up with $C=9$. I am curious what the “best” bound is though, and what the best approach would be for proving this. In other words, what is the supremum of all analytic functions $f$ on $|z|\le 1/2$, subject to the two conditions above?","Let $f:D(0,1) \to \mathbb C$ be analytic. Show that there is a constant $C$ independent of $f$ such that if $f(0)=1$ and $f(z) \notin (-\infty,0]$ for all $z \in D(0,1)$, then $|f(z)| \le C$ whenever $|z| \le 1/2$. I have (finally) figured out how to prove this, and I ended up with $C=9$. I am curious what the “best” bound is though, and what the best approach would be for proving this. In other words, what is the supremum of all analytic functions $f$ on $|z|\le 1/2$, subject to the two conditions above?",,[]
11,Evaluating a Path Integral in the Complex Plane,Evaluating a Path Integral in the Complex Plane,,"I am preparing for a final tomorrow and working through an old exam question that I got incorrect and since I cannot find an online contour integral calculator I was wondering if my (new) solution is correct. The question is Consider the contour $C$ given by $$ z(t)=\begin{cases} e^{it} & t \in [0,\pi] \\ 1 + 2e^{it} & t \in [\pi, 2 \pi] \end{cases}. $$   Evaluate the path integral $$\int_{C} \frac{(z + 1)^2}{z} \, dz .$$ For the first part of the contour, we may simplyify the integrand:  $$ \frac{(z+1)^2}{z} \cdot \frac{\overline{z}}{\overline{z}} = \frac{(z + 1)^2 \cdot \overline{z}}{|z|^2} $$ and we get  $$ \begin{eqnarray*} \int_{0}^\pi (e^{it} + 1)^2\cdot (e^{-it}) \cdot (i e^{it}) \, dt & = & i \cdot \int_{0}^\pi (e^{it} + 1)^2 \, dt \\ & = & i \left[ \frac{e^{2it}}{2i} + \frac{2e^{it}}{i} + t\right]_{t = 0}^{t = \pi} \\ & = & \pi i - 4.  \end{eqnarray*} $$ For the second part of the contour, we have  $$ \int_{\pi}^{2 \pi} \frac{(2 + 2e^{it})^2}{1 + 2e^{it}} \cdot 2ie^{it} \, dt. $$ If we let $u = 1 + 2e^{it}$, then $du = 2i e^{it}\,dt$ and the integral becomes  $$ \int_{-1}^3 \frac{(1 + u)^2}{u} \, du = \left[ \ln(u) + 2u + \frac{u^2}{2} \right]_{u = -1}^{u =3} = \ln(3) + 8. $$ So then  $$ \int_{C} \frac{(z + 1)^2}{z} \, dz= \ln(3) + 4 + i \pi. $$ Is this correct?","I am preparing for a final tomorrow and working through an old exam question that I got incorrect and since I cannot find an online contour integral calculator I was wondering if my (new) solution is correct. The question is Consider the contour $C$ given by $$ z(t)=\begin{cases} e^{it} & t \in [0,\pi] \\ 1 + 2e^{it} & t \in [\pi, 2 \pi] \end{cases}. $$   Evaluate the path integral $$\int_{C} \frac{(z + 1)^2}{z} \, dz .$$ For the first part of the contour, we may simplyify the integrand:  $$ \frac{(z+1)^2}{z} \cdot \frac{\overline{z}}{\overline{z}} = \frac{(z + 1)^2 \cdot \overline{z}}{|z|^2} $$ and we get  $$ \begin{eqnarray*} \int_{0}^\pi (e^{it} + 1)^2\cdot (e^{-it}) \cdot (i e^{it}) \, dt & = & i \cdot \int_{0}^\pi (e^{it} + 1)^2 \, dt \\ & = & i \left[ \frac{e^{2it}}{2i} + \frac{2e^{it}}{i} + t\right]_{t = 0}^{t = \pi} \\ & = & \pi i - 4.  \end{eqnarray*} $$ For the second part of the contour, we have  $$ \int_{\pi}^{2 \pi} \frac{(2 + 2e^{it})^2}{1 + 2e^{it}} \cdot 2ie^{it} \, dt. $$ If we let $u = 1 + 2e^{it}$, then $du = 2i e^{it}\,dt$ and the integral becomes  $$ \int_{-1}^3 \frac{(1 + u)^2}{u} \, du = \left[ \ln(u) + 2u + \frac{u^2}{2} \right]_{u = -1}^{u =3} = \ln(3) + 8. $$ So then  $$ \int_{C} \frac{(z + 1)^2}{z} \, dz= \ln(3) + 4 + i \pi. $$ Is this correct?",,"['complex-analysis', 'contour-integration']"
12,Why is the z =z' when using Milne-Thomson Method for determining a holomorphic function?,Why is the z =z' when using Milne-Thomson Method for determining a holomorphic function?,,"When we use Milne-Thomson method, we substitute $x$ and $y$ with $\frac{z+z^*}2$ and $\frac{z-z^*}{2i}$. This gives us... $f(z) = u(x,y) + iv(x,y) = u(\frac{z+z^*}2, \frac{z-z^*}{2i}) + i v(\frac{z+z^*}2, \frac{z-z^*}{2i})$ $z^*$ represents the conjugate of $z$. We then proceed to say that for the above relation $z=z^*$. Why did we we do that? And how can we say that? I mean, this seems like a massive over-simplification.","When we use Milne-Thomson method, we substitute $x$ and $y$ with $\frac{z+z^*}2$ and $\frac{z-z^*}{2i}$. This gives us... $f(z) = u(x,y) + iv(x,y) = u(\frac{z+z^*}2, \frac{z-z^*}{2i}) + i v(\frac{z+z^*}2, \frac{z-z^*}{2i})$ $z^*$ represents the conjugate of $z$. We then proceed to say that for the above relation $z=z^*$. Why did we we do that? And how can we say that? I mean, this seems like a massive over-simplification.",,"['complex-analysis', 'complex-numbers']"
13,What can be said about the convergence on $|z|=1$?,What can be said about the convergence on ?,|z|=1,I already found the radius of convergence of the power series $:$ $$\sum_{n=1}^{\infty} \frac {(-1)^n} {n} z^{n(n+1)}.$$ What happens at the boundary of disk of convergence? I found that the radius of convergence to be $1$ and hence the disk of convergence is $|z|<1$ . Now I found at $z=1$ the series converges. Now how can I proceed? Please help me. Thank you in advance.,I already found the radius of convergence of the power series What happens at the boundary of disk of convergence? I found that the radius of convergence to be and hence the disk of convergence is . Now I found at the series converges. Now how can I proceed? Please help me. Thank you in advance.,: \sum_{n=1}^{\infty} \frac {(-1)^n} {n} z^{n(n+1)}. 1 |z|<1 z=1,[]
14,Which real points are in the boundary of the Mandelbrot set?,Which real points are in the boundary of the Mandelbrot set?,,"Recall: the Mandelbrot set $M$ is defined to be the set of points $c\in \mathbb{C}$ such that the sequence of complex numbers $\{c, c^2+c, (c^2+c)^2 + c, \ldots  \}$ is bounded in magnitude. (Recursively, the sequence is defined by $z_1 = c$ and $z_{k+1} = z_k^2 + c$ .) The Wikipedia page on the Mandelbrot set states that the intersection of $M$ with the real axis is precisely the closed interval $[-2,1/4]$ . What if we instead intersect the boundary $\partial M$ of the Mandelbrot set with the real axis? The figure here seems to suggest this intersection may be a discrete set of points, and that this  is related to the logistic map. However I did not find the answer to this on either Wikipedia page, after browsing briefly. To summarize, I am wondering: Can we say exactly what real points are in the boundary $\partial M$ ? Is the intersection $\mathbb{R}\cap \partial M$ a discrete set of points? If it is not discrete, is it dense in any open interval of $\mathbb{R}$ ?","Recall: the Mandelbrot set is defined to be the set of points such that the sequence of complex numbers is bounded in magnitude. (Recursively, the sequence is defined by and .) The Wikipedia page on the Mandelbrot set states that the intersection of with the real axis is precisely the closed interval . What if we instead intersect the boundary of the Mandelbrot set with the real axis? The figure here seems to suggest this intersection may be a discrete set of points, and that this  is related to the logistic map. However I did not find the answer to this on either Wikipedia page, after browsing briefly. To summarize, I am wondering: Can we say exactly what real points are in the boundary ? Is the intersection a discrete set of points? If it is not discrete, is it dense in any open interval of ?","M c\in \mathbb{C} \{c, c^2+c, (c^2+c)^2 + c, \ldots  \} z_1 = c z_{k+1} = z_k^2 + c M [-2,1/4] \partial M \partial M \mathbb{R}\cap \partial M \mathbb{R}","['complex-analysis', 'dynamical-systems', 'complex-dynamics']"
15,Evaluate $\int_0^\infty \frac{\ln^2(z)}{1+z^2}$dz by contour integration [duplicate],Evaluate dz by contour integration [duplicate],\int_0^\infty \frac{\ln^2(z)}{1+z^2},"This question already has answers here : Evaluate $\int_0^\infty \frac{(\log x)^2}{1+x^2} dx$ using complex analysis (5 answers) Closed 7 years ago . Background: This is part b of problem 12.4.3 from Arfken, Weber, Harris Math Methods for Physicists to show that $\int_0^\infty \frac{\ln^2(z)}{1+z^2}$dz$=4(1-\frac{1}{3^3}+\frac{1}{5^3}-\frac{1}{7^3}+\dots)$. Part b of the question asks to show that this series evaluates to $\frac{\pi^3}{8}$ by contour integration. Where is my mistake: $\lim_{z \to 0}zf(z)=0$ and $\lim_{z \to \infty}zf(z)=0$ so the big and little circle equal 0.$ Drawing a branch cut along the positive x axis and integrating counterclockwise along the positive x-axis around a big circle the negative x-axis from infinity and the little circle: Assume $I=\int_0^\infty \frac{\ln^2(x)}{1+x^2}\text{dx}$ We can add the components of along the contour and set that equal to the value of $2\pi i \text{Res}[f(z),i]$ evaluated at the poles $\pm i$ $$\int_0^\infty \frac{\ln^2(z)}{1+z^2}\text{dz}+\int_{\infty}^0 \frac{\ln^2(z)}{1+z^2}\text{dz}=2\pi i \text{Res}[f(z),\pm i]\tag{1}$$ $$\int_0^\infty \frac{(\ln^2 \mid x\mid}{1+x^2}\text{dx}-\int_0^{\infty} \frac{(\ln\mid x\mid+2i\pi)^2}{1+x^2}\text{dx}=2\pi i \left (\lim_{z \to i}\frac{\ln^2(z)}{2z}+\lim_{z \to -i}\frac{\ln^2(z)}{2z}\right )\tag{2}$$ $$\int_0^\infty \frac{(\ln^2\mid x\mid}{1+x^2}\text{dx}-\int_0^{\infty} \frac{(\ln^2\mid x\mid+\color{red}{4\ln|x|i\pi}-4\pi^2)}{1+x^2}\text{dx}=2\pi i \left (\lim_{z \to i}\frac{\ln^2(z)}{2z}+\lim_{z \to -i}\frac{\ln^2(z)}{2z}\right )\tag{3}$$ $$0I+\color{red}{0}-\left[\tan^{-1}(x)\right]\mid^{\infty}_0(4\pi^2)\text{dx}=(2\pi i)  \left (\frac{-\pi^2/4+9\pi^2/4}{2i}\right )\tag{4}$$ $$0I+2\pi^3=\frac{8\pi^3}{4}\tag{5}$$ For explanation of the red integral see here , here or here . I found my error. It was a negative sign, and the two sides cancel to zero so you can't evaluate it this way, but I found an answer which evaluates it from negative to positive infinity so I'm marking the question as a duplicate. See dustin's answer at the link for the contour integration.","This question already has answers here : Evaluate $\int_0^\infty \frac{(\log x)^2}{1+x^2} dx$ using complex analysis (5 answers) Closed 7 years ago . Background: This is part b of problem 12.4.3 from Arfken, Weber, Harris Math Methods for Physicists to show that $\int_0^\infty \frac{\ln^2(z)}{1+z^2}$dz$=4(1-\frac{1}{3^3}+\frac{1}{5^3}-\frac{1}{7^3}+\dots)$. Part b of the question asks to show that this series evaluates to $\frac{\pi^3}{8}$ by contour integration. Where is my mistake: $\lim_{z \to 0}zf(z)=0$ and $\lim_{z \to \infty}zf(z)=0$ so the big and little circle equal 0.$ Drawing a branch cut along the positive x axis and integrating counterclockwise along the positive x-axis around a big circle the negative x-axis from infinity and the little circle: Assume $I=\int_0^\infty \frac{\ln^2(x)}{1+x^2}\text{dx}$ We can add the components of along the contour and set that equal to the value of $2\pi i \text{Res}[f(z),i]$ evaluated at the poles $\pm i$ $$\int_0^\infty \frac{\ln^2(z)}{1+z^2}\text{dz}+\int_{\infty}^0 \frac{\ln^2(z)}{1+z^2}\text{dz}=2\pi i \text{Res}[f(z),\pm i]\tag{1}$$ $$\int_0^\infty \frac{(\ln^2 \mid x\mid}{1+x^2}\text{dx}-\int_0^{\infty} \frac{(\ln\mid x\mid+2i\pi)^2}{1+x^2}\text{dx}=2\pi i \left (\lim_{z \to i}\frac{\ln^2(z)}{2z}+\lim_{z \to -i}\frac{\ln^2(z)}{2z}\right )\tag{2}$$ $$\int_0^\infty \frac{(\ln^2\mid x\mid}{1+x^2}\text{dx}-\int_0^{\infty} \frac{(\ln^2\mid x\mid+\color{red}{4\ln|x|i\pi}-4\pi^2)}{1+x^2}\text{dx}=2\pi i \left (\lim_{z \to i}\frac{\ln^2(z)}{2z}+\lim_{z \to -i}\frac{\ln^2(z)}{2z}\right )\tag{3}$$ $$0I+\color{red}{0}-\left[\tan^{-1}(x)\right]\mid^{\infty}_0(4\pi^2)\text{dx}=(2\pi i)  \left (\frac{-\pi^2/4+9\pi^2/4}{2i}\right )\tag{4}$$ $$0I+2\pi^3=\frac{8\pi^3}{4}\tag{5}$$ For explanation of the red integral see here , here or here . I found my error. It was a negative sign, and the two sides cancel to zero so you can't evaluate it this way, but I found an answer which evaluates it from negative to positive infinity so I'm marking the question as a duplicate. See dustin's answer at the link for the contour integration.",,['complex-analysis']
16,existence of a set of discs on the complex plane,existence of a set of discs on the complex plane,,"Given $z_1,\dots,z_n\in\mathbb{C}$ and $T>0$, prove that there exists a set of discs such that $\sum r_i\le 2T$ (where $r_i$ is the radius of $i$-th disc) and $\prod\limits_{i=1}^{n}|z-z_i| > \left(\frac{T}{e}\right)^n$ for all $z$ outside the union of these discs. It is somehow related with Cartan's lemma . I haven't studied complex analysis yet, can this problem be solved with not very advanced methods?","Given $z_1,\dots,z_n\in\mathbb{C}$ and $T>0$, prove that there exists a set of discs such that $\sum r_i\le 2T$ (where $r_i$ is the radius of $i$-th disc) and $\prod\limits_{i=1}^{n}|z-z_i| > \left(\frac{T}{e}\right)^n$ for all $z$ outside the union of these discs. It is somehow related with Cartan's lemma . I haven't studied complex analysis yet, can this problem be solved with not very advanced methods?",,"['complex-analysis', 'complex-numbers']"
17,How do you determine the angle of a branch cut in a composition of functions?,How do you determine the angle of a branch cut in a composition of functions?,,Given $\int\log{\frac{a^2+z^2}{z^2}}e^{ivz}$dz The integral along the branch cut from 0 to a and back: $$\int_0^a\log(\lvert\frac{a^2+z^2}{z^2}\rvert)+i\pi$$ $$\int_a^0\log(\lvert\frac{a^2+z^2}{z^2}\rvert)-i\pi$$ How were the angle's $\pm\pi$ determined? Was $\arg[1-(a/y)^2]$ calculated by picking an angle that was convenient to calculate or is there a unique value on the left and right for the branch cut? A second example:  Given $1/2\int\frac{e^{iwx}}{\sqrt{x^2+1}}$dz On the right side of the branch cut: $\int_R^1\frac{e^{-wy}}{(\sqrt{y^2-1})i}$ On the left side of the branch cut: $\int_1^R\frac{e^{-wy}}{-(\sqrt{y^2-1})i}$ How were the signs determined in the denominator? Here it could be $e^{i\pi/2+in\pi}$ measured from the origin in the figure but I don't think that's how it was determined because the same reasoning doesn't work in the first example.,Given $\int\log{\frac{a^2+z^2}{z^2}}e^{ivz}$dz The integral along the branch cut from 0 to a and back: $$\int_0^a\log(\lvert\frac{a^2+z^2}{z^2}\rvert)+i\pi$$ $$\int_a^0\log(\lvert\frac{a^2+z^2}{z^2}\rvert)-i\pi$$ How were the angle's $\pm\pi$ determined? Was $\arg[1-(a/y)^2]$ calculated by picking an angle that was convenient to calculate or is there a unique value on the left and right for the branch cut? A second example:  Given $1/2\int\frac{e^{iwx}}{\sqrt{x^2+1}}$dz On the right side of the branch cut: $\int_R^1\frac{e^{-wy}}{(\sqrt{y^2-1})i}$ On the left side of the branch cut: $\int_1^R\frac{e^{-wy}}{-(\sqrt{y^2-1})i}$ How were the signs determined in the denominator? Here it could be $e^{i\pi/2+in\pi}$ measured from the origin in the figure but I don't think that's how it was determined because the same reasoning doesn't work in the first example.,,['complex-analysis']
18,"Is there a ""nice"" function with zeros at lattice points in $\Bbb C$?","Is there a ""nice"" function with zeros at lattice points in ?",\Bbb C,"All functions will be considered on $\Bbb C$: The function $\sin(\pi z)$ has zeroes precisely at the lattice $\Lambda = \Bbb Z$ in the complex plane. Further, it is nice in the sense that: $$\frac{\sin(\pi z)}{\pi z} = \prod_{n\in \Lambda\backslash\{0\}}\bigg(1 - \frac{z^2}{n^2}\bigg).$$ Now, let us take $\Lambda = \Bbb Z[i] = \{m+ni : m,n\in \Bbb Z\}$. Is there a similarly nice function $f(z)$ satisfying: $$f(z) = z^k\prod_{n\in \Lambda\backslash\{0\}}\bigg(1 - \frac{z^4}{n^4}\bigg)$$ for some $k$? Note that I am raising $z$ to the power $4$ instead of $2$ now. Similarly, is there any nice function $g(z)$ for the lattice: $$\Lambda = \Bbb Z[\omega] = \{m + n\omega : m,n \in \Bbb Z\}$$ where $\omega$ is a primitive cube root of $1$. I expect this $g$ to satisfy: $$g(z) = z^k\prod_{n\in \Lambda\backslash\{0\}}\bigg(1 - \frac{z^6}{n^6}\bigg)$$ for some $k$? I would also like to know about the more general case of $\Lambda$ being the ring of integers in an arbitrary imaginary quadratic number field $K$. (Motivation: I would like to use this function to compute the zeta function of the number field $K$ at even integers mimicking Euler's Proof of $\zeta(2k)$.)","All functions will be considered on $\Bbb C$: The function $\sin(\pi z)$ has zeroes precisely at the lattice $\Lambda = \Bbb Z$ in the complex plane. Further, it is nice in the sense that: $$\frac{\sin(\pi z)}{\pi z} = \prod_{n\in \Lambda\backslash\{0\}}\bigg(1 - \frac{z^2}{n^2}\bigg).$$ Now, let us take $\Lambda = \Bbb Z[i] = \{m+ni : m,n\in \Bbb Z\}$. Is there a similarly nice function $f(z)$ satisfying: $$f(z) = z^k\prod_{n\in \Lambda\backslash\{0\}}\bigg(1 - \frac{z^4}{n^4}\bigg)$$ for some $k$? Note that I am raising $z$ to the power $4$ instead of $2$ now. Similarly, is there any nice function $g(z)$ for the lattice: $$\Lambda = \Bbb Z[\omega] = \{m + n\omega : m,n \in \Bbb Z\}$$ where $\omega$ is a primitive cube root of $1$. I expect this $g$ to satisfy: $$g(z) = z^k\prod_{n\in \Lambda\backslash\{0\}}\bigg(1 - \frac{z^6}{n^6}\bigg)$$ for some $k$? I would also like to know about the more general case of $\Lambda$ being the ring of integers in an arbitrary imaginary quadratic number field $K$. (Motivation: I would like to use this function to compute the zeta function of the number field $K$ at even integers mimicking Euler's Proof of $\zeta(2k)$.)",,"['complex-analysis', 'number-theory', 'algebraic-number-theory', 'integer-lattices', 'zeta-functions']"
19,Evaluate the integral $\int_0^{2\pi} \frac{d \theta}{5-3 \cos \theta}$,Evaluate the integral,\int_0^{2\pi} \frac{d \theta}{5-3 \cos \theta},"$$\int_0^{2\pi} \frac{d \theta}{5-3 \cos \theta}$$ My attempt: Let $z=e^{i\theta}$ which gives $d\theta = \frac{dz}{iz}$ Thus, $$\oint_C \frac{1}{5-3(\frac{z+z^{-1}}{2})}\frac{dz}{iz}$$ $$=\frac{1}{i}\oint_C \frac{dz}{(3z-1)(z-3)}$$ We can ignore the singularity at $z=3$ because it lies outside the unit circle and thus we don't need to account for it when computing the residues. $$=\frac{1}{i}\oint_C f(z) \, dz = 2\pi [\operatorname{Res}(f(z),\frac{1}{3})]$$ $$\operatorname{Res}(f(z),\frac{1}{3})=\frac{\lim_{z\to1/3} (3z-1)\cdot \frac{1}{(3z-1)(z-3)}}{0!}$$ $$=-\frac{9}{8}$$ Which yields: $$=\frac{1}{i}\oint_C f(z) \, dz = 2\pi [-\frac{9}{8}]$$ $$=-\frac{9\pi}{4}$$ But how can I have a negative answer for an integration??? Did I make a mistake somewhere??","$$\int_0^{2\pi} \frac{d \theta}{5-3 \cos \theta}$$ My attempt: Let $z=e^{i\theta}$ which gives $d\theta = \frac{dz}{iz}$ Thus, $$\oint_C \frac{1}{5-3(\frac{z+z^{-1}}{2})}\frac{dz}{iz}$$ $$=\frac{1}{i}\oint_C \frac{dz}{(3z-1)(z-3)}$$ We can ignore the singularity at $z=3$ because it lies outside the unit circle and thus we don't need to account for it when computing the residues. $$=\frac{1}{i}\oint_C f(z) \, dz = 2\pi [\operatorname{Res}(f(z),\frac{1}{3})]$$ $$\operatorname{Res}(f(z),\frac{1}{3})=\frac{\lim_{z\to1/3} (3z-1)\cdot \frac{1}{(3z-1)(z-3)}}{0!}$$ $$=-\frac{9}{8}$$ Which yields: $$=\frac{1}{i}\oint_C f(z) \, dz = 2\pi [-\frac{9}{8}]$$ $$=-\frac{9\pi}{4}$$ But how can I have a negative answer for an integration??? Did I make a mistake somewhere??",,"['complex-analysis', 'complex-numbers', 'contour-integration']"
20,What is a geometric meaning of $2\pi i$ for complex integration?,What is a geometric meaning of  for complex integration?,2\pi i,"Cauchy Integral formula Let $G$ be open in $\mathbb{C}$ and $f$ be holomorphic on $G$ . Let $\gamma$ be a closed rectifiable curve in $G$ such that $Wnd(\gamma,z)=0$ for all $z\in \mathbb{C}\setminus G$ . Then, $Wnd(\gamma,z) f(z)= \frac{1}{2\pi i}\int_\gamma \frac{f(w)}{w-z} dw$ I'm now reviewing complex analysis I have learned. Not only Cauchy integral formula, but all theorems relating line integral comes with the coefficient $\frac{1}{2\pi i}$ in basic complex analysis. I completely understand the proof for Cauchy integration formula and other theorems (such as Counting zeros, Residue theorem, Argument principle and etc) and I know how $2\pi i$ is derived. However, I cannot find why $2\pi i$ must be there geometrically or by any means. All I can say for now is that $2\pi i$ incidentally came out in proofs. I'm sure it has some meaning.. What is it? Thank you in advance.","Cauchy Integral formula Let be open in and be holomorphic on . Let be a closed rectifiable curve in such that for all . Then, I'm now reviewing complex analysis I have learned. Not only Cauchy integral formula, but all theorems relating line integral comes with the coefficient in basic complex analysis. I completely understand the proof for Cauchy integration formula and other theorems (such as Counting zeros, Residue theorem, Argument principle and etc) and I know how is derived. However, I cannot find why must be there geometrically or by any means. All I can say for now is that incidentally came out in proofs. I'm sure it has some meaning.. What is it? Thank you in advance.","G \mathbb{C} f G \gamma G Wnd(\gamma,z)=0 z\in \mathbb{C}\setminus G Wnd(\gamma,z) f(z)= \frac{1}{2\pi i}\int_\gamma \frac{f(w)}{w-z} dw \frac{1}{2\pi i} 2\pi i 2\pi i 2\pi i","['complex-analysis', 'line-integrals']"
21,Contour integral.,Contour integral.,,"Consider the function $y(x)$ defined by $$y(x)=e^{x^2}\int_{C_1'}\frac{e^{-u^2}}{(u-x)^{n+1}}du$$where $C_1'$ is as shown The Author makes following claims regarding the behavior of $y(x)$ in the limit of large $x$ (It is assumed that $n>-\frac{1}{2}$, but not integral). 1) As $x\rightarrow+\infty$, the whole path of integration $C_1'$ moves to infinity, and the integral in the above expression tends to zero as $e^{-x^2}$. 2) As $x\rightarrow-\infty$, however, the path of integration extends along the whole of real axis, and the integral in the expression does not tend $\boldsymbol{exponentially}$  to zero, so the function $y(x)$ becomes infinite essentially as $e^{x^2}$. In regard to the second claim, I can see that the integrals on the parts of the contour above and below the real axis will not cancel since $n+1$ is not integral. I understand these estimates are correct but have not been able to exactly see how. Any indication in the right direction would be very useful. Thanks.","Consider the function $y(x)$ defined by $$y(x)=e^{x^2}\int_{C_1'}\frac{e^{-u^2}}{(u-x)^{n+1}}du$$where $C_1'$ is as shown The Author makes following claims regarding the behavior of $y(x)$ in the limit of large $x$ (It is assumed that $n>-\frac{1}{2}$, but not integral). 1) As $x\rightarrow+\infty$, the whole path of integration $C_1'$ moves to infinity, and the integral in the above expression tends to zero as $e^{-x^2}$. 2) As $x\rightarrow-\infty$, however, the path of integration extends along the whole of real axis, and the integral in the expression does not tend $\boldsymbol{exponentially}$  to zero, so the function $y(x)$ becomes infinite essentially as $e^{x^2}$. In regard to the second claim, I can see that the integrals on the parts of the contour above and below the real axis will not cancel since $n+1$ is not integral. I understand these estimates are correct but have not been able to exactly see how. Any indication in the right direction would be very useful. Thanks.",,['complex-analysis']
22,If $|z|<1$ then $\prod_{k=0}^\infty (1+z^{2^k})$ = $(1-z)^{-1}$,If  then  =,|z|<1 \prod_{k=0}^\infty (1+z^{2^k}) (1-z)^{-1},Prove that if $|z|<1$ then $\prod_{k=0}^\infty (1+z^{2^k})$ converges and is equal to $(1-z)^{-1}$. My attempt: Note that \begin{equation} \begin{aligned}     (1-z)\prod_{k=0}^N (1+z^{2^k}) &= (1-z)(1+z)(1+z^2)(1+z^{2^2})\cdots(1+z^{2^N})\\     &= (1-z^2)(1+z^2)(1+z^{2^2})(1+z^{2^3})\cdots(1+z^{2^N})\\     &= (1-z^{2^2})(1+z^{2^2})(1+z^{2^3})(1+z^{2^4})\cdots(1+z^{2^N})\\     &= (1-z^{2^{N+1}}) \end{aligned} \end{equation} For |z|<1 \begin{equation}     \lim_{N\to\infty} (1-z)\prod_{k=0}^N (1+z^{2^k})= \lim_{N\to\infty}(1-z^{2^{N+1}}) =1. \end{equation} Is this enough to solve the problem?,Prove that if $|z|<1$ then $\prod_{k=0}^\infty (1+z^{2^k})$ converges and is equal to $(1-z)^{-1}$. My attempt: Note that \begin{equation} \begin{aligned}     (1-z)\prod_{k=0}^N (1+z^{2^k}) &= (1-z)(1+z)(1+z^2)(1+z^{2^2})\cdots(1+z^{2^N})\\     &= (1-z^2)(1+z^2)(1+z^{2^2})(1+z^{2^3})\cdots(1+z^{2^N})\\     &= (1-z^{2^2})(1+z^{2^2})(1+z^{2^3})(1+z^{2^4})\cdots(1+z^{2^N})\\     &= (1-z^{2^{N+1}}) \end{aligned} \end{equation} For |z|<1 \begin{equation}     \lim_{N\to\infty} (1-z)\prod_{k=0}^N (1+z^{2^k})= \lim_{N\to\infty}(1-z^{2^{N+1}}) =1. \end{equation} Is this enough to solve the problem?,,['complex-analysis']
23,Approximating $(1+\frac{1}{z})^z$ where $|z|$ is large,Approximating  where  is large,(1+\frac{1}{z})^z |z|,I know that $$\lim_{x\rightarrow \infty}\left(1+\frac{1}{x}\right)^x=e$$ Is there an equivalent in complex analysis for $$\lim_{|z|\rightarrow \infty}\left(1+\frac{1}{z}\right)^z=?$$,I know that $$\lim_{x\rightarrow \infty}\left(1+\frac{1}{x}\right)^x=e$$ Is there an equivalent in complex analysis for $$\lim_{|z|\rightarrow \infty}\left(1+\frac{1}{z}\right)^z=?$$,,"['complex-analysis', 'limits', 'complex-numbers']"
24,Question about Branch Cuts,Question about Branch Cuts,,"I'm starting to learn a little complex analysis, and I'm a little confused as to what the purpose of a branch cut is. Is it to make a function continuous, or single valued? For example, the $\sqrt{}$ function is multivalued: since $w(z)=z^2$ has $w(z)=w(-z)$, in order to make $\sqrt{}$ the inverse of $z^2$, we can choose one of two branches, $w\to\sqrt{w}$ or $w\to -\sqrt{w}$, the former being the principal branch. This function maps $\mathbb{C}\to$(right half plane), and the other maps to the left half plane. As far as I can tell, both functions are now well defined on $\mathbb{C}$, but are not continuous because for a point $-r$ on the negative real axis, the principal branch $w(z)\to i\sqrt{r}$ as $z\to r$ from above, but $w(z)\to -i\sqrt{r}$ as $z\to r$ from below. To make the principal branch continuous, we just cut out this section of the real line and define the principal branch $\sqrt{}_{+}:\mathbb{C}\setminus (-\infty,0]\to\mathbb{C}$. Is this the right idea? Also, I was assuming Arg$(z)\in[-\pi,\pi)$; is this the only branch cut you could make with Arg$(z)\in[-\pi,\pi)$? Where would the branch cut be if Arg$(z)\in[0,2\pi)$ instead?","I'm starting to learn a little complex analysis, and I'm a little confused as to what the purpose of a branch cut is. Is it to make a function continuous, or single valued? For example, the $\sqrt{}$ function is multivalued: since $w(z)=z^2$ has $w(z)=w(-z)$, in order to make $\sqrt{}$ the inverse of $z^2$, we can choose one of two branches, $w\to\sqrt{w}$ or $w\to -\sqrt{w}$, the former being the principal branch. This function maps $\mathbb{C}\to$(right half plane), and the other maps to the left half plane. As far as I can tell, both functions are now well defined on $\mathbb{C}$, but are not continuous because for a point $-r$ on the negative real axis, the principal branch $w(z)\to i\sqrt{r}$ as $z\to r$ from above, but $w(z)\to -i\sqrt{r}$ as $z\to r$ from below. To make the principal branch continuous, we just cut out this section of the real line and define the principal branch $\sqrt{}_{+}:\mathbb{C}\setminus (-\infty,0]\to\mathbb{C}$. Is this the right idea? Also, I was assuming Arg$(z)\in[-\pi,\pi)$; is this the only branch cut you could make with Arg$(z)\in[-\pi,\pi)$? Where would the branch cut be if Arg$(z)\in[0,2\pi)$ instead?",,"['complex-analysis', 'self-learning']"
25,"if $\operatorname{Res}_{z_0}f = 0$, then $f$ has a primitive in some deleted neighborhood of $z_0$","if , then  has a primitive in some deleted neighborhood of",\operatorname{Res}_{z_0}f = 0 f z_0,"Let $z_0$ be an isolated singularity of $f$. Prove that if $\operatorname{Res}_{z_0}f = 0$, then $f$ has a primitive in some deleted neighborhood of $z_0$ I know that if we assume $f$ has a primitive, then we can use Morera's theorem to prove that $\operatorname{Res}_{z_0}f = 0$. But, I don't know how to do the opposite side. Can someone please show me how can I do that ?","Let $z_0$ be an isolated singularity of $f$. Prove that if $\operatorname{Res}_{z_0}f = 0$, then $f$ has a primitive in some deleted neighborhood of $z_0$ I know that if we assume $f$ has a primitive, then we can use Morera's theorem to prove that $\operatorname{Res}_{z_0}f = 0$. But, I don't know how to do the opposite side. Can someone please show me how can I do that ?",,"['complex-analysis', 'analysis']"
26,Complex analysis: Prove a meromorphic function to be rational.,Complex analysis: Prove a meromorphic function to be rational.,,"I come across a problem about complex analysis: Show that a meromorphic function on the complex plane, which achieves any complex number no more than fixed given times, must be rational. The only way I know to prove a meromorphic function being rational is to show the infinity is not an essential singularity of the function (thus it can be controlled by polynomial). Following this, we can use Picard's Great Theorem to solve the problem. I wonder if anyone can help me think of another method. (Without using Picard's Great Theorem.)","I come across a problem about complex analysis: Show that a meromorphic function on the complex plane, which achieves any complex number no more than fixed given times, must be rational. The only way I know to prove a meromorphic function being rational is to show the infinity is not an essential singularity of the function (thus it can be controlled by polynomial). Following this, we can use Picard's Great Theorem to solve the problem. I wonder if anyone can help me think of another method. (Without using Picard's Great Theorem.)",,"['complex-analysis', 'rational-functions']"
27,Proving $\prod_k \sin \pi k / n = n / 2^{n-1}$,Proving,\prod_k \sin \pi k / n = n / 2^{n-1},"I am stuck trying to prove $$\prod_{k=1}^{n-1} \sin {\pi k \over n} = {n \over 2^{n-1}}$$ and I'd appreciate help. What I have done so far: $z^n - 1 = \prod_{k=1}^n (z - \xi^k)$ where $\xi = e^{2 \pi i k\over n}$. Dividing both sides by $z-1$ we get $$ {z^n - 1 \over z - 1} = \prod_{k=1}^{n-1} (z - \xi^k)$$ Taking the limit $z \to 1$ on both sides, $$ n = \prod_{k=1}^{n-1} (1 - \xi^k)$$ So I'm getting close to what I want to prove but unfortunately, this is where I am stuck! How to proceed form here?","I am stuck trying to prove $$\prod_{k=1}^{n-1} \sin {\pi k \over n} = {n \over 2^{n-1}}$$ and I'd appreciate help. What I have done so far: $z^n - 1 = \prod_{k=1}^n (z - \xi^k)$ where $\xi = e^{2 \pi i k\over n}$. Dividing both sides by $z-1$ we get $$ {z^n - 1 \over z - 1} = \prod_{k=1}^{n-1} (z - \xi^k)$$ Taking the limit $z \to 1$ on both sides, $$ n = \prod_{k=1}^{n-1} (1 - \xi^k)$$ So I'm getting close to what I want to prove but unfortunately, this is where I am stuck! How to proceed form here?",,['complex-analysis']
28,Determine the set of points $z$ that satisfy the condition $|2z|>|1+z^2|$,Determine the set of points  that satisfy the condition,z |2z|>|1+z^2|,"Determine the set of points $z$ that satisfy the condition $|2z|>|1+z^2|$ I tried to redo this problem and got to this point $|2z|>|1+z^2|$ $\Rightarrow$ $2|z|>1+|z^2|$ $\Rightarrow$ $2|z|>1+z\overline z$ Let $z=x+iy$ then $$2\sqrt{x^2+y^2}>1+(x+iy)(x-iy)$$ $$2\sqrt{x^2+y^2}>1+(x^2+y^2)$$ $$0>1-2\sqrt{x^2+y^2}+(x^2+y^2)$$ $$0>(1-\sqrt{x^2+y^2})^2$$ since $x,y$ are real number , so there is no solution for this inequality?","Determine the set of points $z$ that satisfy the condition $|2z|>|1+z^2|$ I tried to redo this problem and got to this point $|2z|>|1+z^2|$ $\Rightarrow$ $2|z|>1+|z^2|$ $\Rightarrow$ $2|z|>1+z\overline z$ Let $z=x+iy$ then $$2\sqrt{x^2+y^2}>1+(x+iy)(x-iy)$$ $$2\sqrt{x^2+y^2}>1+(x^2+y^2)$$ $$0>1-2\sqrt{x^2+y^2}+(x^2+y^2)$$ $$0>(1-\sqrt{x^2+y^2})^2$$ since $x,y$ are real number , so there is no solution for this inequality?",,"['complex-analysis', 'inequality', 'complex-numbers']"
29,"Complex analysis, showing a function is constant","Complex analysis, showing a function is constant",,"Let $\Omega$ be the right half plane excluding the imgainary axis and $f\in H(\Omega)$ such that $|f(z)|<1$ for all $z\in\Omega$. If there exists $\alpha\in(-\frac{\pi}{2},\frac{\pi}{2})$ such that $$\lim_{r\rightarrow\infty}\frac{\log|f(re^{i\alpha})|}{r}=-\infty$$ prove that $f=0$. The hint is define $g_n(z)=f(z)e^{nz}$, then by previous exericise $|g_n|<1$ for all $z\in\Omega$.","Let $\Omega$ be the right half plane excluding the imgainary axis and $f\in H(\Omega)$ such that $|f(z)|<1$ for all $z\in\Omega$. If there exists $\alpha\in(-\frac{\pi}{2},\frac{\pi}{2})$ such that $$\lim_{r\rightarrow\infty}\frac{\log|f(re^{i\alpha})|}{r}=-\infty$$ prove that $f=0$. The hint is define $g_n(z)=f(z)e^{nz}$, then by previous exericise $|g_n|<1$ for all $z\in\Omega$.",,"['complex-analysis', 'analysis', 'maximum-principle']"
30,Show that the set U is unbounded,Show that the set U is unbounded,,I am working on a practice qualifier problem: Let $f : \mathbb{C} → \mathbb{C}$ be an entire function with $f(z) \ne 0$ for all $z ∈ \mathbb{C}$. Define U = {z ∈ C : |f(z)| < 1}. Show that all connected component of U is unbounded. I know that $f$ is holomorphic on all of $\mathbb{C}$ I'm assuming that I have to use consider $\frac{1}{f(x)}$ since $f(z) \ne 0$ anywhere.  Any thoughts would be grealy appreciated.,I am working on a practice qualifier problem: Let $f : \mathbb{C} → \mathbb{C}$ be an entire function with $f(z) \ne 0$ for all $z ∈ \mathbb{C}$. Define U = {z ∈ C : |f(z)| < 1}. Show that all connected component of U is unbounded. I know that $f$ is holomorphic on all of $\mathbb{C}$ I'm assuming that I have to use consider $\frac{1}{f(x)}$ since $f(z) \ne 0$ anywhere.  Any thoughts would be grealy appreciated.,,"['complex-analysis', 'connectedness']"
31,Towards a formula for the Euler $\phi$ function?,Towards a formula for the Euler  function?,\phi,$\Phi_n(1)$ and $\Phi_n(-1)$ for the cyclotomic polynomials are well-known. I am now looking for $$\Phi_n(i)$$ and/or $$\Phi_n(-i)$$ with $i$ the complex unit. The reason is : I suppose it is true that $(1-i)^{\phi(n)}\Phi_n(i)$ is either zero or of the form $$(-1)^{f(n)}2^{g(n)}$$ for some rational valued functions.  Just now $f(n)$ and $g(n)$ are unknown to me. But if all calculations would succeed by taking logarithms $\phi(n)$ may perhaps be calculated. The ideas behind that rely on the polynomials defined by William E Heierman published   on his Web Site.,$\Phi_n(1)$ and $\Phi_n(-1)$ for the cyclotomic polynomials are well-known. I am now looking for $$\Phi_n(i)$$ and/or $$\Phi_n(-i)$$ with $i$ the complex unit. The reason is : I suppose it is true that $(1-i)^{\phi(n)}\Phi_n(i)$ is either zero or of the form $$(-1)^{f(n)}2^{g(n)}$$ for some rational valued functions.  Just now $f(n)$ and $g(n)$ are unknown to me. But if all calculations would succeed by taking logarithms $\phi(n)$ may perhaps be calculated. The ideas behind that rely on the polynomials defined by William E Heierman published   on his Web Site.,,"['complex-analysis', 'elementary-number-theory', 'complex-numbers', 'cyclotomic-polynomials']"
32,Complex Numbers - Finding Roots,Complex Numbers - Finding Roots,,"Hi there I was wondering if someone could help me? I am struggling to find the roots of the polynomial $z^4+2z+3=0$ It is not a quadratic so can't use the quadratic formula so am not quite sure what to do. What is normally a good way to tackle complex polynomials of this form? Thanks for your help. Edit: I needed its roots to answer the question 67(f), but looks like it would be very difficult to find the reisudes from those singularities. I am guessing there might have been a mistake in the question and that they meant $x^2$: So wanted a way to do it without using wolfram alpha","Hi there I was wondering if someone could help me? I am struggling to find the roots of the polynomial $z^4+2z+3=0$ It is not a quadratic so can't use the quadratic formula so am not quite sure what to do. What is normally a good way to tackle complex polynomials of this form? Thanks for your help. Edit: I needed its roots to answer the question 67(f), but looks like it would be very difficult to find the reisudes from those singularities. I am guessing there might have been a mistake in the question and that they meant $x^2$: So wanted a way to do it without using wolfram alpha",,"['complex-analysis', 'complex-numbers', 'contour-integration']"
33,"Independently analytic and continuous, but not jointly continuous?","Independently analytic and continuous, but not jointly continuous?",,"In Bak/Newman's ""Complex Analysis"", they write: 17.9 Theorem Suppose $\phi(z,t)$ is a continuous function of $t$, with $b \ge t \ge a$, for fixed $z$ and an analytic function of $z \in D$ for fixed $t$. Then $$ f(z) = \int _a ^b \phi(z,t) \ dt $$   is analytic in $D$, and ...etc... The proof starts off: Since $f$ is a continuous function of $z$, according to Morera's Theorem we need only prove that ...etc... I cannot seem to force $f$ to be continuous without requiring $\phi$ to be continuous in both variables together. I feel like it might be that analytic in the first variable and independently continuous in the second does not imply jointly continuous. Question: What, if there is one, is an example which is analytic in the first, continuous in the second, but not jointly continuous? Any reasonable $\text{(domain) }D \times [a,b]$ is OK. EDIT: Theorem 5.4 on p. 56 of Stein/Shakarchi's book here seems to be pretty much the same, except with the joint continuity assumption. (Their proof is neat, too, because it avoids blatantly using Fubini's theorem). Thank you!","In Bak/Newman's ""Complex Analysis"", they write: 17.9 Theorem Suppose $\phi(z,t)$ is a continuous function of $t$, with $b \ge t \ge a$, for fixed $z$ and an analytic function of $z \in D$ for fixed $t$. Then $$ f(z) = \int _a ^b \phi(z,t) \ dt $$   is analytic in $D$, and ...etc... The proof starts off: Since $f$ is a continuous function of $z$, according to Morera's Theorem we need only prove that ...etc... I cannot seem to force $f$ to be continuous without requiring $\phi$ to be continuous in both variables together. I feel like it might be that analytic in the first variable and independently continuous in the second does not imply jointly continuous. Question: What, if there is one, is an example which is analytic in the first, continuous in the second, but not jointly continuous? Any reasonable $\text{(domain) }D \times [a,b]$ is OK. EDIT: Theorem 5.4 on p. 56 of Stein/Shakarchi's book here seems to be pretty much the same, except with the joint continuity assumption. (Their proof is neat, too, because it avoids blatantly using Fubini's theorem). Thank you!",,['complex-analysis']
34,Is this analytic continuation possible?,Is this analytic continuation possible?,,"I'n new to complex analysis and am a little flustered by the following function. I would like help understanding whether or not it is possible to analytically continue it outside of the unit circle. $$f(z)=\prod\limits_{k=1}^{\infty}(1+z^k)$$ Using Maple, it seems to converge to $0$, at $z=(\exp(\frac{2\pi i}{2}),\exp(\frac{2\pi i}{4}),\exp(\frac{2\pi i}{6}),\dots)$ and diverge to infinity at $z=(\exp(\frac{2\pi i}{1}),\exp(\frac{2\pi i}{3}),\exp(\frac{2\pi i}{5}),\dots)$. This makes sense as when any of the first set of roots of unity are plugged into the function, you end up multiplying by 0 whereas with the other roots you just end up multiplying infinitely many numbers all greater than 1. Furthermore $f$ should converge to $0$ for any $even$ root of unity, $z=\exp(\frac{2\pi ik}{2n})$, and diverge for any odd root, $z=\exp\left(\frac{2\pi ik}{2n+1}\right)$. This means that at any singularity, there are points infinitely close to it with $f(z)=0$, and for every point such that $f(z)=0$, there are infinitely many singularities near it. Is it possible (In theory or practice) to analytically continue $f$ outside the unit circle? Edit: I am reading as we speak, a Wikipedia article that states that if a function has a set of singularities on its circle of convergence, and this set is $dense$, then every point on the circle must be a singularity. Except this function seems to contradict that as all of our $even$ roots are not singularities (unless secretly they are!).","I'n new to complex analysis and am a little flustered by the following function. I would like help understanding whether or not it is possible to analytically continue it outside of the unit circle. $$f(z)=\prod\limits_{k=1}^{\infty}(1+z^k)$$ Using Maple, it seems to converge to $0$, at $z=(\exp(\frac{2\pi i}{2}),\exp(\frac{2\pi i}{4}),\exp(\frac{2\pi i}{6}),\dots)$ and diverge to infinity at $z=(\exp(\frac{2\pi i}{1}),\exp(\frac{2\pi i}{3}),\exp(\frac{2\pi i}{5}),\dots)$. This makes sense as when any of the first set of roots of unity are plugged into the function, you end up multiplying by 0 whereas with the other roots you just end up multiplying infinitely many numbers all greater than 1. Furthermore $f$ should converge to $0$ for any $even$ root of unity, $z=\exp(\frac{2\pi ik}{2n})$, and diverge for any odd root, $z=\exp\left(\frac{2\pi ik}{2n+1}\right)$. This means that at any singularity, there are points infinitely close to it with $f(z)=0$, and for every point such that $f(z)=0$, there are infinitely many singularities near it. Is it possible (In theory or practice) to analytically continue $f$ outside the unit circle? Edit: I am reading as we speak, a Wikipedia article that states that if a function has a set of singularities on its circle of convergence, and this set is $dense$, then every point on the circle must be a singularity. Except this function seems to contradict that as all of our $even$ roots are not singularities (unless secretly they are!).",,"['complex-analysis', 'functions']"
35,Residue at infinity,Residue at infinity,,This is an old qualifying exam problem: Suppose $f$ is entire and $a < b$.  Show that the residue of $$ f(z) \log \frac{z-b}{z-a} $$ at infinity is $\int_a^b f(x)dx$.,This is an old qualifying exam problem: Suppose $f$ is entire and $a < b$.  Show that the residue of $$ f(z) \log \frac{z-b}{z-a} $$ at infinity is $\int_a^b f(x)dx$.,,['complex-analysis']
36,"How fast does the function $f(x)=\lim_{\epsilon\to0}\int_\epsilon^{\infty} \frac{e^{xt}}{t^t} \, dt$ grow?",How fast does the function  grow?,"f(x)=\lim_{\epsilon\to0}\int_\epsilon^{\infty} \frac{e^{xt}}{t^t} \, dt","Let $x$ be a positive real number and $f(x):=\lim_{\epsilon\to0}\int_\epsilon^{\infty} \dfrac{e^{xt}}{t^t} \, dt $ . How fast does this function grow ? In other words can we find a good asymptote for $f(x)$ as $x$ goes to $+\infty$ ? Can we show one of these two limits converges to a constant : A) $\lim_{x\to+\infty} \dfrac{\ln(f(x))}{P(x)} $ B) $\lim_{x\to+\infty} \dfrac{f(x)}{P(x)} $ For some polynomial $P(x)$ ? I know $f(z)$ is an entire function , so I tried using Taylor series. However the derivatives of $f$ are similar looking and Hence I do not know their growth rate either !? $$\frac{d f(x)}{d x^k} = \lim_{\epsilon\to0}\int_\epsilon^\infty \frac{e^{xt}}{t^{t-k}}\,dt.$$ Since by Taylor's theorem I need the derivatives of $f(x)$ , so I am stuck on how to prove any growth rate or limit. I considered replacing the integral with an infinite sum but that did not work for me. I assume one way is to use contour integrals but I'm not sure how that would work.","Let be a positive real number and . How fast does this function grow ? In other words can we find a good asymptote for as goes to ? Can we show one of these two limits converges to a constant : A) B) For some polynomial ? I know is an entire function , so I tried using Taylor series. However the derivatives of are similar looking and Hence I do not know their growth rate either !? Since by Taylor's theorem I need the derivatives of , so I am stuck on how to prove any growth rate or limit. I considered replacing the integral with an infinite sum but that did not work for me. I assume one way is to use contour integrals but I'm not sure how that would work.","x f(x):=\lim_{\epsilon\to0}\int_\epsilon^{\infty} \dfrac{e^{xt}}{t^t} \, dt  f(x) x +\infty \lim_{x\to+\infty} \dfrac{\ln(f(x))}{P(x)}  \lim_{x\to+\infty} \dfrac{f(x)}{P(x)}  P(x) f(z) f \frac{d f(x)}{d x^k} = \lim_{\epsilon\to0}\int_\epsilon^\infty \frac{e^{xt}}{t^{t-k}}\,dt. f(x)","['complex-analysis', 'limits', 'asymptotics', 'integral-transforms']"
37,Proof of the three-point characterization of holomorphy,Proof of the three-point characterization of holomorphy,,"This post on Math Overflow is looking for the source of the following theorem: Let $D = \{ z \in \mathbb{C} : |z| < 1 \}$ denote the open unit disk. A function $f : D \to D$ is holomorphic iff it has the following property: for any three points in $D$, there exists a holomorphic function $g : D \to D$ that agrees with $f$ at the three points. I'm interested in the proof. One direction is trivial, and for the other direction, the post says that there is an ""easy"" but clever proof using only Schwarz's lemma and Montel's theorem. So I suppose the general idea is to look at the family of functions $g$ that are holomorphic and agree with $f$ at three or more points, and to find, within this family, a sequence that converges to $f$. At first I thought this might require an enumeration of a countable dense subset of $D$, but now I think maybe it's possible to show that $f$ is differentiable at $0$, and use a Möbius transformations such that $z_0 \mapsto 0$ to show differentiability at $z_0 \neq 0$. The only other information I've been able to find online is a post on this blog, ""Calculus VII"", which explains why the theorem does not hold with fewer than three points nor with the codomain being all of $\mathbb{C}$. Please do not post a full solution. This is tagged as homework.","This post on Math Overflow is looking for the source of the following theorem: Let $D = \{ z \in \mathbb{C} : |z| < 1 \}$ denote the open unit disk. A function $f : D \to D$ is holomorphic iff it has the following property: for any three points in $D$, there exists a holomorphic function $g : D \to D$ that agrees with $f$ at the three points. I'm interested in the proof. One direction is trivial, and for the other direction, the post says that there is an ""easy"" but clever proof using only Schwarz's lemma and Montel's theorem. So I suppose the general idea is to look at the family of functions $g$ that are holomorphic and agree with $f$ at three or more points, and to find, within this family, a sequence that converges to $f$. At first I thought this might require an enumeration of a countable dense subset of $D$, but now I think maybe it's possible to show that $f$ is differentiable at $0$, and use a Möbius transformations such that $z_0 \mapsto 0$ to show differentiability at $z_0 \neq 0$. The only other information I've been able to find online is a post on this blog, ""Calculus VII"", which explains why the theorem does not hold with fewer than three points nor with the codomain being all of $\mathbb{C}$. Please do not post a full solution. This is tagged as homework.",,"['complex-analysis', 'analyticity', 'normal-families']"
38,"Proof of $\Gamma(z) e^{i \pi z/2} = \int_0^\infty t^{z-1} e^{it}\, dt$",Proof of,"\Gamma(z) e^{i \pi z/2} = \int_0^\infty t^{z-1} e^{it}\, dt","I am trying to prove the identity $$\Gamma(z) e^{i \pi z/2} = \int_0^\infty t^{z-1} e^{it}\, dt$$ for $0 < \Re(z) < 1$, starting from the integral definition of the gamma function $$\Gamma(z) = \int_0^\infty t^{z-1} e^{-t}\, dt.$$  I've been trying things for a while and don't really know how to proceed.  I've tried a couple of tricks involving taking complex conjugates of both sides of the identity, and trying to relate those back to the original gamma function in some enlightening way.  I've also tried thinking of a clever variable substitution for $z$, or even arguing by power series, though I don't know how I would handle the difficulties of convergence.  Any helpful pointers would be appreciated.","I am trying to prove the identity $$\Gamma(z) e^{i \pi z/2} = \int_0^\infty t^{z-1} e^{it}\, dt$$ for $0 < \Re(z) < 1$, starting from the integral definition of the gamma function $$\Gamma(z) = \int_0^\infty t^{z-1} e^{-t}\, dt.$$  I've been trying things for a while and don't really know how to proceed.  I've tried a couple of tricks involving taking complex conjugates of both sides of the identity, and trying to relate those back to the original gamma function in some enlightening way.  I've also tried thinking of a clever variable substitution for $z$, or even arguing by power series, though I don't know how I would handle the difficulties of convergence.  Any helpful pointers would be appreciated.",,"['complex-analysis', 'gamma-function']"
39,Prove or disprove that $f$ is Möbius transformation.,Prove or disprove that  is Möbius transformation.,f,"The value of analytic function $f(z)$ is defined to be the value of $f(1/t)$ at $t=0$ as an element of $\Bbb C\cup \{\infty\}$. We can consider a meromorphic function as a function from $\Bbb C\cup \{\infty\}$ to $\Bbb C\cup \{\infty\}$ Suppose that the Laurent expansion at the original of such a meromorphic function is of the form $$\frac{b_N}{z^N}+\dots\frac{b_1}{z}+a_0+a_1z+\dots$$ where $b_n\not=0$ and the series converges for $0\lt \vert z\vert \lt \infty$. Also, assume that $f:\Bbb C\cup \{\infty\}\to \Bbb C\cup \{\infty\}$ is one to one. Prove or disprove that $f$ is Möbius transformation. Thank you for helping. Best regards..","The value of analytic function $f(z)$ is defined to be the value of $f(1/t)$ at $t=0$ as an element of $\Bbb C\cup \{\infty\}$. We can consider a meromorphic function as a function from $\Bbb C\cup \{\infty\}$ to $\Bbb C\cup \{\infty\}$ Suppose that the Laurent expansion at the original of such a meromorphic function is of the form $$\frac{b_N}{z^N}+\dots\frac{b_1}{z}+a_0+a_1z+\dots$$ where $b_n\not=0$ and the series converges for $0\lt \vert z\vert \lt \infty$. Also, assume that $f:\Bbb C\cup \{\infty\}\to \Bbb C\cup \{\infty\}$ is one to one. Prove or disprove that $f$ is Möbius transformation. Thank you for helping. Best regards..",,"['complex-analysis', 'analysis', 'conformal-geometry']"
40,One-to-one mapping of $z^2+z$ in disk,One-to-one mapping of  in disk,z^2+z,"Find the largest disk in which the mapping $f(z)=z^2+z$ is a one-to-one mapping. If $f(z)$ is not one-to-one on a region $S$, we can find points $a\neq b\in S$ such that $a^2+a=b^2+b$. This means $a^2-b^2=b-a$, so that $a+b=-1$. Now, I think the question is asking for the largest disk centered at the origin; otherwise we can pick any disk inside the region $\{z:\Re z>2\}$. So assume the disk is centered at the origin. If the radius is strictly greater than $1/2$, then clearly we can pick two distinct negative real numbers that sum to $-1$. So consider the disk $|z|\leq 1/2$. For any two points $a,b$ in the disk, we have $|a+b|\leq |a|+|b|\leq 1$. The only chance that $a+b=-1$ is if $a=b=-1/2$, but here we have $a=b$. So $|z|\leq 1/2$ is the largest possible disk. Is this reasoning correct? I was first confused because of the ambiguous problem statement.","Find the largest disk in which the mapping $f(z)=z^2+z$ is a one-to-one mapping. If $f(z)$ is not one-to-one on a region $S$, we can find points $a\neq b\in S$ such that $a^2+a=b^2+b$. This means $a^2-b^2=b-a$, so that $a+b=-1$. Now, I think the question is asking for the largest disk centered at the origin; otherwise we can pick any disk inside the region $\{z:\Re z>2\}$. So assume the disk is centered at the origin. If the radius is strictly greater than $1/2$, then clearly we can pick two distinct negative real numbers that sum to $-1$. So consider the disk $|z|\leq 1/2$. For any two points $a,b$ in the disk, we have $|a+b|\leq |a|+|b|\leq 1$. The only chance that $a+b=-1$ is if $a=b=-1/2$, but here we have $a=b$. So $|z|\leq 1/2$ is the largest possible disk. Is this reasoning correct? I was first confused because of the ambiguous problem statement.",,['complex-analysis']
41,Is there a completion of Laurent series w.r.t. integration?,Is there a completion of Laurent series w.r.t. integration?,,"Given a Laurent series $$f(z) = \sum_{k=-\infty}^\infty a_k(z-z_0)^k,$$ its derivative is obviously also a Laurent series. However, upon integration, the $\frac1{z-z_0}$ term introduces a $\ln(z-z_0)$ term and therewith an essential singularity turning the integral of a Laurent series into something that generally is not a Laurent series again. So one could define a new kind of series including that $\ln$ term, and upon integration obtain another new term due to $\int\ln z\,dz = z(\ln z-1)$, or more generally, $$\int z^k\ln z\,dz = \frac{z^{k+1}[(k+1)\ln z -1]}{(k+1)^2}$$ for $k\neq-1$. So the series $$f(z) := \sum_{k=-\infty}^\infty [a_k+b_k\ln(z-z_0)](z-z_0)^k$$ with $b_{-1}=0$ is complete under both derivation and integration at the expense of introducing a branch cut and an essential singularity at $z_0$. But does such a series definition make sense? How would one obtain the coefficients $b_k$ now? For $b_{-1}\neq0$, one obtains $\int\frac{\ln z}z\,dz = \frac12\ln^2 z$, the inclusion of which requires the inclusion of $\int\ln^2z\,dz = z(\ln^2z -2\ln z+2)$ and therewith of $z^m\ln^2z$ for $m\neq-1$. And should the extended series include a $\frac{\ln^2z}z$ term, its integration would require a $\ln^3z$ term and so on, so in an even more general sense we'd have $$f(z) := \sum_{k=-\infty}^\infty \sum_{l=0}^\infty c_{kl} \ln^l(z-z_0)\cdot (z-z_0)^k.$$ Now you could go on and include $l<0$ terms, but their integrals would require the inclusion of the logarithmic integral $\operatorname{li}(z-z_0)$, and integrating that would include $\operatorname{Ei}(z-z_0)$ and hypergeometric functions etc. - so, does this ever stop at a (up to powers) finite set of base functions?","Given a Laurent series $$f(z) = \sum_{k=-\infty}^\infty a_k(z-z_0)^k,$$ its derivative is obviously also a Laurent series. However, upon integration, the $\frac1{z-z_0}$ term introduces a $\ln(z-z_0)$ term and therewith an essential singularity turning the integral of a Laurent series into something that generally is not a Laurent series again. So one could define a new kind of series including that $\ln$ term, and upon integration obtain another new term due to $\int\ln z\,dz = z(\ln z-1)$, or more generally, $$\int z^k\ln z\,dz = \frac{z^{k+1}[(k+1)\ln z -1]}{(k+1)^2}$$ for $k\neq-1$. So the series $$f(z) := \sum_{k=-\infty}^\infty [a_k+b_k\ln(z-z_0)](z-z_0)^k$$ with $b_{-1}=0$ is complete under both derivation and integration at the expense of introducing a branch cut and an essential singularity at $z_0$. But does such a series definition make sense? How would one obtain the coefficients $b_k$ now? For $b_{-1}\neq0$, one obtains $\int\frac{\ln z}z\,dz = \frac12\ln^2 z$, the inclusion of which requires the inclusion of $\int\ln^2z\,dz = z(\ln^2z -2\ln z+2)$ and therewith of $z^m\ln^2z$ for $m\neq-1$. And should the extended series include a $\frac{\ln^2z}z$ term, its integration would require a $\ln^3z$ term and so on, so in an even more general sense we'd have $$f(z) := \sum_{k=-\infty}^\infty \sum_{l=0}^\infty c_{kl} \ln^l(z-z_0)\cdot (z-z_0)^k.$$ Now you could go on and include $l<0$ terms, but their integrals would require the inclusion of the logarithmic integral $\operatorname{li}(z-z_0)$, and integrating that would include $\operatorname{Ei}(z-z_0)$ and hypergeometric functions etc. - so, does this ever stop at a (up to powers) finite set of base functions?",,"['complex-analysis', 'laurent-series']"
42,$f(z)$ and $f(z+z^2)$ have the same singularities at 0,and  have the same singularities at 0,f(z) f(z+z^2),"Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be an analytic function in a punctured neighborhood of 0 then $f(z)$ and $h(z)=f(z+z^2)$ have the same singularity at $z_0=0$. I was able to show that every removable singularity or pole of $f$ is also the same of $h$. However, I was unable to do so for the opposite direction or for an essential singularity (Casorati-Weierstrass theorem maybe?) Thanks in advance","Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be an analytic function in a punctured neighborhood of 0 then $f(z)$ and $h(z)=f(z+z^2)$ have the same singularity at $z_0=0$. I was able to show that every removable singularity or pole of $f$ is also the same of $h$. However, I was unable to do so for the opposite direction or for an essential singularity (Casorati-Weierstrass theorem maybe?) Thanks in advance",,['complex-analysis']
43,Book Searching in Complex Analysis,Book Searching in Complex Analysis,,"I'm searching for a problem book in complex analysis published by MIR. It was recommended by my professor (when I asked for a Demidovich equivalent in the field), but he did not remember the exact name (possibly "" Ejercicios de Analise Complexa "" - Exercises in Complex Analysis) nor the author. He said the book was quite difficult, it don't have applications and he mentioned a particular and hard problem involving a construction of a Riemannian surface. Edit: The problem of the construction of a Riemannian surface has a infinity product of functions.","I'm searching for a problem book in complex analysis published by MIR. It was recommended by my professor (when I asked for a Demidovich equivalent in the field), but he did not remember the exact name (possibly "" Ejercicios de Analise Complexa "" - Exercises in Complex Analysis) nor the author. He said the book was quite difficult, it don't have applications and he mentioned a particular and hard problem involving a construction of a Riemannian surface. Edit: The problem of the construction of a Riemannian surface has a infinity product of functions.",,"['complex-analysis', 'reference-request']"
44,A simple example related to Schwarz' lemma,A simple example related to Schwarz' lemma,,"Let $f$ be a holomorphic function on $B(0,R)$, where $R>0$.  Assume that there exists an $M>0$ such that $\forall z\in B(0,R): |f(z)| \le M$ and a natural number $n$ such that $$ 0 = f(0)=f'(0) = ... = f^{(n)}(0).$$ $1)$ Prove that $\forall z\in B(0,R) : |f(z)| \le M \left( \frac{|z|}{R} \right)^{n+1}$ with equality iff there exists an $\alpha \in \mathbb{C}$ such that $|\alpha|=1$ and $ f(z)=\alpha M \left( \frac{z}{R} \right)^{n+1}$. $2)$ Assume that either $ |f(z_0)|=M \left(\frac{|z_0|}{R}\right)^{n+1}$ for some $z_0 \in B(0,R) \setminus \{0\}$ or $ |f^{(n+1)}(0)|=(n+1)!M / R^{n+1}$. Then $ f(z)=\alpha M \left(\frac{z}{R}\right)^{n+1}$ for an $\alpha \in \mathbb{C}$ such that $|\alpha|=1$. Sorry for asking this problem, but I'd like to see some examples related to the Schwarz lemma. Thanks!","Let $f$ be a holomorphic function on $B(0,R)$, where $R>0$.  Assume that there exists an $M>0$ such that $\forall z\in B(0,R): |f(z)| \le M$ and a natural number $n$ such that $$ 0 = f(0)=f'(0) = ... = f^{(n)}(0).$$ $1)$ Prove that $\forall z\in B(0,R) : |f(z)| \le M \left( \frac{|z|}{R} \right)^{n+1}$ with equality iff there exists an $\alpha \in \mathbb{C}$ such that $|\alpha|=1$ and $ f(z)=\alpha M \left( \frac{z}{R} \right)^{n+1}$. $2)$ Assume that either $ |f(z_0)|=M \left(\frac{|z_0|}{R}\right)^{n+1}$ for some $z_0 \in B(0,R) \setminus \{0\}$ or $ |f^{(n+1)}(0)|=(n+1)!M / R^{n+1}$. Then $ f(z)=\alpha M \left(\frac{z}{R}\right)^{n+1}$ for an $\alpha \in \mathbb{C}$ such that $|\alpha|=1$. Sorry for asking this problem, but I'd like to see some examples related to the Schwarz lemma. Thanks!",,['complex-analysis']
45,"Is it possible to evaluate $ \int_0^1 x^n \, dx$ by contour integration?",Is it possible to evaluate  by contour integration?," \int_0^1 x^n \, dx","It's been quite a time since I had the complex analysis course. The thing is now I don't know the answer to the following simple question: Is it possible to find $$ \int_0^1 x^n \, dx$$ using the methods of contour integration? I've refreshed my knowledge with wikipedia , but I've no idea how to make integrals with no obvious singularities. Though there is a singularity at $\infty$, but how to connect it with $[0,1]$?","It's been quite a time since I had the complex analysis course. The thing is now I don't know the answer to the following simple question: Is it possible to find $$ \int_0^1 x^n \, dx$$ using the methods of contour integration? I've refreshed my knowledge with wikipedia , but I've no idea how to make integrals with no obvious singularities. Though there is a singularity at $\infty$, but how to connect it with $[0,1]$?",,"['complex-analysis', 'contour-integration']"
46,Cauchy-Goursat with triangle contour,Cauchy-Goursat with triangle contour,,"The Cauchy-Goursat theorem for a triangle contour states the following: Let $\triangle=\triangle(a,b,c)$ be a triangle in an open set $\Omega \subseteq \mathbb{C},p\in \Omega,f:\Omega\rightarrow \mathbb{C}$ continuous and f analytical on $\Omega \setminus \{p\}$. Then: $\int\limits_{\partial\triangle}f(z)dz=0$ , where $\partial\triangle$ means on and inside the triangle $\triangle$. The proof then distinguishes a few cases around $p$... but why?: 1) $p \notin \triangle$ 2) $p=a$ 3) $p \in \triangle$ randomly. I do understand the proof, but I don't understand what's the purposes of $p$. Why do we even mention it? What's the thought behind this? Some books don't mention it. Edit: Proof Case 1: $ p\not\subset\triangle$. Let $a',\ b',\ c'$ be the midpoints of the segments $[b,\ c],\ [c,\ a],\ [a,\ b]$. We denote with $\triangle^{j}(j=1,2,3,4)$ the triangles $(a,\ c',\ b'),\ (b,\ a',\ c'),\ (c,\ b',\ a'),\ (a',\ b',\ c')$. Let $I =\displaystyle \int_{\partial\triangle}f(z)dz$. We now have: $$ I\ =\sum_{j=1}^{4}\int_{\partial\triangle^{j}}f(z)\mathrm{d}z $$ There is a $j_{0}\in\{1,2,3,4\}$ so that $$ \left|\int_{\partial\triangle^{j_{0}}}f(z)\mathrm{d}z\right|\geq\frac{|I|}{4} $$ Let $\triangle_{1}:=\triangle^{j_{0}}$. The same construction with $\triangle_{1}$ instead of $\triangle$ yields a triangle $\triangle_{2}$, etc. By induction we get a sequence $(\triangle_{n})$ of triangles with $\triangle\supseteq\triangle_{1}\supseteq\triangle_{2}\supseteq\ldots$, so that $|I| \displaystyle \leq 4^{n}\left|\int_{\partial\triangle_{n}}f(z)\mathrm{d}z\right|,\ (n\in \mathbb{N})$ Further we have the length $L(\partial\triangle_{n})=2^{-n}L(\partial\triangle)$ and $\displaystyle \lim_{n\rightarrow\infty}$ diam $(\triangle_{n})=0$ because diam $(\triangle_{n})\leq L(\partial\triangle_{n})$. It follows that (Cantor) $$ \triangle \bigcap_{n=1}\triangle_{n}=\{z_{0}\}. $$ Because $f$  is in $z_{0}$  complex differentiable, there exists for $\varepsilon>0$ a $r>0$ with $$ |f(z)-f(z_{0})-f'(z_{0})(z-z_{0})|\leq \varepsilon|z-z_{0}|\ (z\in C(z_{0},\ r)\subseteq\Omega) $$ and there is a $n\in \mathbb{N}$ mit $\triangle_{n}\subseteq C(z_{0},\ r)$. For this $n$ we have: $$ |z-z_{0}|\leq 2^{-n}L(\partial\triangle)\ (z\in\triangle_{n}) $$ Furthermore: $$ \int_{\partial\triangle_{n}}f(z)\mathrm{d}z=\int_{\partial\triangle_{n}}f(z)-f(z_{0})-f'(z_{0})(z-z_{0})\mathrm{d}z $$ We have: $$ \left|\int_{\partial\triangle_{n}}f(z)\mathrm{d}z\right|\leq \varepsilon\cdot(2^{-n}L(\partial\triangle))^{2} $$ and thus $$ |I|\leq 4^{n}\left|\int_{\partial\triangle_{n}}f(z)\mathrm{d}z\right|\leq \varepsilon(L(\partial\triangle))^{2} $$ Because $\varepsilon>0$ was chosen arbitrarly,  $I =0$ follows. $\color{red}{\text{In my point of view, we are now completely done with the proof. But the proof continues, see below}}$ Case 2: Now, let $p$ be a vertex of $\triangle$, for instance let $p=a$. If  $a,\ b,\ c$ lie on the same line, then we have trivially $I=0$. If not, we choose $x\in[a,\ b],y\in[a,\ c]$ near $a$. Then we have: $$ \displaystyle \int_{\partial\triangle}f(z)\mathrm{d}z=\int_{\partial\triangle(a,x,y)}f(z)\mathrm{d}z+\int_{\partial\triangle(x,b,y)}f(z)\mathrm{d}z+\int_{\partial\triangle(b,c,y)}f(z)\mathrm{d}z $$ $$ =\int_{\partial\triangle(a,x,y)}f(z)dz. $$ Because we can make $L(\partial\triangle(a,x,\ y))$ arbitrarily small, $I =0$ follows. Case 3: If $ p\in\triangle$ arbitrarily, $I =0$ follows from case 2: $$ \displaystyle I\ =\int_{\partial\triangle(a,b,p)}f(z)\mathrm{d}z+\int_{\partial\triangle(b,c,p)}f(z)\mathrm{d}z+\int_{\partial\triangle(c,a,p)}f(z)\mathrm{d}z=0 $$ $\color{red}{\text{Why the hassle of introducing } p?}$","The Cauchy-Goursat theorem for a triangle contour states the following: Let $\triangle=\triangle(a,b,c)$ be a triangle in an open set $\Omega \subseteq \mathbb{C},p\in \Omega,f:\Omega\rightarrow \mathbb{C}$ continuous and f analytical on $\Omega \setminus \{p\}$. Then: $\int\limits_{\partial\triangle}f(z)dz=0$ , where $\partial\triangle$ means on and inside the triangle $\triangle$. The proof then distinguishes a few cases around $p$... but why?: 1) $p \notin \triangle$ 2) $p=a$ 3) $p \in \triangle$ randomly. I do understand the proof, but I don't understand what's the purposes of $p$. Why do we even mention it? What's the thought behind this? Some books don't mention it. Edit: Proof Case 1: $ p\not\subset\triangle$. Let $a',\ b',\ c'$ be the midpoints of the segments $[b,\ c],\ [c,\ a],\ [a,\ b]$. We denote with $\triangle^{j}(j=1,2,3,4)$ the triangles $(a,\ c',\ b'),\ (b,\ a',\ c'),\ (c,\ b',\ a'),\ (a',\ b',\ c')$. Let $I =\displaystyle \int_{\partial\triangle}f(z)dz$. We now have: $$ I\ =\sum_{j=1}^{4}\int_{\partial\triangle^{j}}f(z)\mathrm{d}z $$ There is a $j_{0}\in\{1,2,3,4\}$ so that $$ \left|\int_{\partial\triangle^{j_{0}}}f(z)\mathrm{d}z\right|\geq\frac{|I|}{4} $$ Let $\triangle_{1}:=\triangle^{j_{0}}$. The same construction with $\triangle_{1}$ instead of $\triangle$ yields a triangle $\triangle_{2}$, etc. By induction we get a sequence $(\triangle_{n})$ of triangles with $\triangle\supseteq\triangle_{1}\supseteq\triangle_{2}\supseteq\ldots$, so that $|I| \displaystyle \leq 4^{n}\left|\int_{\partial\triangle_{n}}f(z)\mathrm{d}z\right|,\ (n\in \mathbb{N})$ Further we have the length $L(\partial\triangle_{n})=2^{-n}L(\partial\triangle)$ and $\displaystyle \lim_{n\rightarrow\infty}$ diam $(\triangle_{n})=0$ because diam $(\triangle_{n})\leq L(\partial\triangle_{n})$. It follows that (Cantor) $$ \triangle \bigcap_{n=1}\triangle_{n}=\{z_{0}\}. $$ Because $f$  is in $z_{0}$  complex differentiable, there exists for $\varepsilon>0$ a $r>0$ with $$ |f(z)-f(z_{0})-f'(z_{0})(z-z_{0})|\leq \varepsilon|z-z_{0}|\ (z\in C(z_{0},\ r)\subseteq\Omega) $$ and there is a $n\in \mathbb{N}$ mit $\triangle_{n}\subseteq C(z_{0},\ r)$. For this $n$ we have: $$ |z-z_{0}|\leq 2^{-n}L(\partial\triangle)\ (z\in\triangle_{n}) $$ Furthermore: $$ \int_{\partial\triangle_{n}}f(z)\mathrm{d}z=\int_{\partial\triangle_{n}}f(z)-f(z_{0})-f'(z_{0})(z-z_{0})\mathrm{d}z $$ We have: $$ \left|\int_{\partial\triangle_{n}}f(z)\mathrm{d}z\right|\leq \varepsilon\cdot(2^{-n}L(\partial\triangle))^{2} $$ and thus $$ |I|\leq 4^{n}\left|\int_{\partial\triangle_{n}}f(z)\mathrm{d}z\right|\leq \varepsilon(L(\partial\triangle))^{2} $$ Because $\varepsilon>0$ was chosen arbitrarly,  $I =0$ follows. $\color{red}{\text{In my point of view, we are now completely done with the proof. But the proof continues, see below}}$ Case 2: Now, let $p$ be a vertex of $\triangle$, for instance let $p=a$. If  $a,\ b,\ c$ lie on the same line, then we have trivially $I=0$. If not, we choose $x\in[a,\ b],y\in[a,\ c]$ near $a$. Then we have: $$ \displaystyle \int_{\partial\triangle}f(z)\mathrm{d}z=\int_{\partial\triangle(a,x,y)}f(z)\mathrm{d}z+\int_{\partial\triangle(x,b,y)}f(z)\mathrm{d}z+\int_{\partial\triangle(b,c,y)}f(z)\mathrm{d}z $$ $$ =\int_{\partial\triangle(a,x,y)}f(z)dz. $$ Because we can make $L(\partial\triangle(a,x,\ y))$ arbitrarily small, $I =0$ follows. Case 3: If $ p\in\triangle$ arbitrarily, $I =0$ follows from case 2: $$ \displaystyle I\ =\int_{\partial\triangle(a,b,p)}f(z)\mathrm{d}z+\int_{\partial\triangle(b,c,p)}f(z)\mathrm{d}z+\int_{\partial\triangle(c,a,p)}f(z)\mathrm{d}z=0 $$ $\color{red}{\text{Why the hassle of introducing } p?}$",,['complex-analysis']
47,An obscure explanation in Conway's Complex analysis,An obscure explanation in Conway's Complex analysis,,"I don't understand a paragraph in Conway's complex analysis at the beginning of Chapter VI page 128 (Maximum Modulus Theorem). He says: ""Note that in Theorem 1.2 we did not assume that $G$ is connected as in Theorem 1.1. Do you understand how Theorem 1.1 puts the finishing touches on the proof of Theorem 1.2? Or could the assumption of connectedness in Theorem 1.1 be dropped?"" For reference I included both theorems here: 1.1 Maximum Modulus Theorem, First Version. If $f$ is analytic in a region $G$ and $a$ is a point in $G$ with $|f(a)| \geq |f(z)|$ for all $z$ in $G$, then $f$ must be constant. (it is proved with the open mapping theorem). 1.2 Maximum Modulus Theorem, Second Version. Let $G$ be a bounded open set in $\mathbb{C}$ and suppose $f$ is continuous on the closure of $G$ and analytic in $G$. Then the maximum is attained on $\partial G$. I was thinking that I understood the maximum modulus but since I can understand Conway's little paragraph I must be missing something important. If someone has the book, thanks for any help.","I don't understand a paragraph in Conway's complex analysis at the beginning of Chapter VI page 128 (Maximum Modulus Theorem). He says: ""Note that in Theorem 1.2 we did not assume that $G$ is connected as in Theorem 1.1. Do you understand how Theorem 1.1 puts the finishing touches on the proof of Theorem 1.2? Or could the assumption of connectedness in Theorem 1.1 be dropped?"" For reference I included both theorems here: 1.1 Maximum Modulus Theorem, First Version. If $f$ is analytic in a region $G$ and $a$ is a point in $G$ with $|f(a)| \geq |f(z)|$ for all $z$ in $G$, then $f$ must be constant. (it is proved with the open mapping theorem). 1.2 Maximum Modulus Theorem, Second Version. Let $G$ be a bounded open set in $\mathbb{C}$ and suppose $f$ is continuous on the closure of $G$ and analytic in $G$. Then the maximum is attained on $\partial G$. I was thinking that I understood the maximum modulus but since I can understand Conway's little paragraph I must be missing something important. If someone has the book, thanks for any help.",,['complex-analysis']
48,Removable sets for harmonic functions and Hardy spaces of general domains,Removable sets for harmonic functions and Hardy spaces of general domains,,"Let $\Omega$ be a domain of the complex plane. The Hardy space $H^p(\Omega)$ is defined, for $1 \leq p<\infty$, as the class of functions $f$ that are holomorphic on $\Omega$ such that $|f|^p$ has a harmonic majorant on $\Omega$, i.e. there is a function $u$ harmonic on $\Omega$ such that $$|f(z)|^p \leq u(z) $$ for all $z \in \Omega$. For $p=\infty$, $H^\infty(\Omega)$ is the class of bounded holomorphic functions on $\Omega$. I'm interested in cases when $H^p(\Omega)$ consist only of constant functions. For example, this is the case when $\Omega$ is the whole plane, because positive harmonic functions on $\mathbb{C}$ are constant. I came upon the following question : Let $E$ be a compact subset of the real line, and suppose that $E$ has zero length. Let $\Omega$ be the complement of $E$. Does $H^p(\Omega)$ consist only of the constant functions? For $p=\infty$, the answer is yes : one can use Cauchy's formula to extend any bounded holomorphic function on $\Omega$ to a bounded holomorphic function on $\mathbb{C}$, and that function is now constant by Liouville's theorem. For $1 \leq p<\infty$, I am pretty sure the answer is also yes. However, I can't seem to find a way to extend $f$ or the harmonic majorant of $|f|^p$ to the whole plane. Is there any way to do so? Thank you, Malik","Let $\Omega$ be a domain of the complex plane. The Hardy space $H^p(\Omega)$ is defined, for $1 \leq p<\infty$, as the class of functions $f$ that are holomorphic on $\Omega$ such that $|f|^p$ has a harmonic majorant on $\Omega$, i.e. there is a function $u$ harmonic on $\Omega$ such that $$|f(z)|^p \leq u(z) $$ for all $z \in \Omega$. For $p=\infty$, $H^\infty(\Omega)$ is the class of bounded holomorphic functions on $\Omega$. I'm interested in cases when $H^p(\Omega)$ consist only of constant functions. For example, this is the case when $\Omega$ is the whole plane, because positive harmonic functions on $\mathbb{C}$ are constant. I came upon the following question : Let $E$ be a compact subset of the real line, and suppose that $E$ has zero length. Let $\Omega$ be the complement of $E$. Does $H^p(\Omega)$ consist only of the constant functions? For $p=\infty$, the answer is yes : one can use Cauchy's formula to extend any bounded holomorphic function on $\Omega$ to a bounded holomorphic function on $\mathbb{C}$, and that function is now constant by Liouville's theorem. For $1 \leq p<\infty$, I am pretty sure the answer is also yes. However, I can't seem to find a way to extend $f$ or the harmonic majorant of $|f|^p$ to the whole plane. Is there any way to do so? Thank you, Malik",,"['complex-analysis', 'harmonic-analysis', 'hardy-spaces']"
49,Anything interesting known about this generalization of even and odd functions?,Anything interesting known about this generalization of even and odd functions?,,"Let $n \in \mathbb N$ . Let's say a complex function $f: U \rightarrow \mathbb C$ is ""of type $k \pmod n$ "" if for one (and hence every) primitive $n$ -th root of unity $\omega$ , $$f(\omega z) = \omega^k f(z)$$ for all $z\in U \subseteq \mathbb C$ . (Obviously the domain $U$ has to be closed under multiplying with $\omega$ .) For $f$ analytic around $0$ , this is equivalent to: In the Taylor expansion $f(z) = \sum a_m z^m$ , all $a_m$ except possibly those with $m \equiv k \pmod n$ are zero. The sum of two functions of type $k \pmod n$ is again of type $k \pmod n$ . The product of a function of type $k \pmod n$ and a function of type $l \pmod n$ is of type $(k+l) \pmod n$ . Also, the derivative of a differentiable function of type $k \pmod n$ is of type $k-1 \pmod n$ . For $n=2$ , this retrieves the classical ""even"" and ""odd functions"" taught to this day in high schools. I just stumbled upon these , or shifts of them, as rare exceptional solutions to functional identities which otherwise usually have no interesting solutions. I wondered if there is a better name for them, and if they are useful in some theory I have missed. (This seems to be at least one level of difficulty below modular forms of weight $k$ , but maybe somebody can take me by the hand and show a connection to those. Or to the seemingly very different generalization here , maybe bringing in representation theory of the cyclic group $\mathbb Z/n$ .)","Let . Let's say a complex function is ""of type "" if for one (and hence every) primitive -th root of unity , for all . (Obviously the domain has to be closed under multiplying with .) For analytic around , this is equivalent to: In the Taylor expansion , all except possibly those with are zero. The sum of two functions of type is again of type . The product of a function of type and a function of type is of type . Also, the derivative of a differentiable function of type is of type . For , this retrieves the classical ""even"" and ""odd functions"" taught to this day in high schools. I just stumbled upon these , or shifts of them, as rare exceptional solutions to functional identities which otherwise usually have no interesting solutions. I wondered if there is a better name for them, and if they are useful in some theory I have missed. (This seems to be at least one level of difficulty below modular forms of weight , but maybe somebody can take me by the hand and show a connection to those. Or to the seemingly very different generalization here , maybe bringing in representation theory of the cyclic group .)",n \in \mathbb N f: U \rightarrow \mathbb C k \pmod n n \omega f(\omega z) = \omega^k f(z) z\in U \subseteq \mathbb C U \omega f 0 f(z) = \sum a_m z^m a_m m \equiv k \pmod n k \pmod n k \pmod n k \pmod n l \pmod n (k+l) \pmod n k \pmod n k-1 \pmod n n=2 k \mathbb Z/n,"['complex-analysis', 'modular-forms', 'analytic-functions', 'roots-of-unity', 'even-and-odd-functions']"
50,Easiest argument for showing that a holomorphic map with finite fibres has no essential singularity,Easiest argument for showing that a holomorphic map with finite fibres has no essential singularity,,"Let $D$ be the open unit disc in $\mathbb{C}$ and let $D^* = D\setminus\{0\}$ . Now, Picard's Great Theorem implies the following fact. If $f\colon D^\ast \to \mathbb{C}$ is a holomorphic function with finite fibres, then $f$ does not have an essential singularity at $0$ . Here is the simple argument (using Picard's Great Theorem). The fibre $f^{-1}(0)$ is finite and so is the fibre $f^{-1}(1)$ . Thus, upon replacing $D$ by a disc of radius $r$ for some suitable $0<r<1$ and $D^*$ accordingly, we may assume that $f$ takes values in $\mathbb{C}\setminus \{0,1\}$ . Then Picard's Great Theorem says that $f$ has no essential singularity. QED Is there a proof of the above fact that does not use Picard's Great Theorem? I'm hoping to find  an argument which uses simpler results (e.g., Casorati-Weierstrass, existence of logarithm after shrinking $D^*$ , etc.)","Let be the open unit disc in and let . Now, Picard's Great Theorem implies the following fact. If is a holomorphic function with finite fibres, then does not have an essential singularity at . Here is the simple argument (using Picard's Great Theorem). The fibre is finite and so is the fibre . Thus, upon replacing by a disc of radius for some suitable and accordingly, we may assume that takes values in . Then Picard's Great Theorem says that has no essential singularity. QED Is there a proof of the above fact that does not use Picard's Great Theorem? I'm hoping to find  an argument which uses simpler results (e.g., Casorati-Weierstrass, existence of logarithm after shrinking , etc.)","D \mathbb{C} D^* = D\setminus\{0\} f\colon D^\ast \to \mathbb{C} f 0 f^{-1}(0) f^{-1}(1) D r 0<r<1 D^* f \mathbb{C}\setminus \{0,1\} f D^*",['complex-analysis']
51,Show that $e^z-1=z e^{\frac{z}{2}} \prod_{n=1}^{\infty}\left(1+\frac{z^2}{4 n^2 \pi^2}\right)$ using Residue Theorem,Show that  using Residue Theorem,e^z-1=z e^{\frac{z}{2}} \prod_{n=1}^{\infty}\left(1+\frac{z^2}{4 n^2 \pi^2}\right),"I was studying previous complex analysis exams and I came across the following question: Use a result obtained from the residue theorem to justify that following infinite product is representation is valid $$ e^z-1=z e^{\frac{z}{2}} \prod_{n=1}^{\infty}\left(1+\frac{z^2}{4 n^2 \pi^2}\right) $$ I saw some solutions using a product expansion for $\frac{\sin(\pi z)}{\pi z}$ that didn't use the residue theorem. Our instructor also presented the formula without proof $$ f(z)=f(0) e^{\frac{f^{\prime}(0)}{f(0)}}\prod_{k=1}^{\infty}\left(1-\frac{z}{a_k}\right) e^{\frac{z}{a_k}}. $$ Where $f(z)$ is an entire function with zeroes of order $1$ on $a_k$ . I would like to know a reference, or a proof, for the above formula and how it is related to the residue theorem.","I was studying previous complex analysis exams and I came across the following question: Use a result obtained from the residue theorem to justify that following infinite product is representation is valid I saw some solutions using a product expansion for that didn't use the residue theorem. Our instructor also presented the formula without proof Where is an entire function with zeroes of order on . I would like to know a reference, or a proof, for the above formula and how it is related to the residue theorem.","
e^z-1=z e^{\frac{z}{2}} \prod_{n=1}^{\infty}\left(1+\frac{z^2}{4 n^2 \pi^2}\right)
 \frac{\sin(\pi z)}{\pi z} 
f(z)=f(0) e^{\frac{f^{\prime}(0)}{f(0)}}\prod_{k=1}^{\infty}\left(1-\frac{z}{a_k}\right) e^{\frac{z}{a_k}}.
 f(z) 1 a_k","['complex-analysis', 'reference-request', 'residue-calculus', 'infinite-product']"
52,Using Rouche's theorem to prove injectivity,Using Rouche's theorem to prove injectivity,,"$\textbf{Problem setup}$ : Let $F : R_{\tau} \rightarrow R_{\tau}$ be a biholomorphism onto its image (i.e. $F : R_{\tau} \rightarrow V$ is a holomorphic function with holomorphic inverse, here $V = F(R_{\tau}) \subset R_{\tau}$ is open), $R_{\tau} = \{ w \in \mathbb{C} : \Re(w) > \tau \}$ where $\tau > 0$ is some fixed real number. Moreover assume that $F$ extends holomorphically to a slightly larger right half plane $R_{\tau’}$ with $\tau’ < \tau$ and is again a biholomorphism onto its image. Suppose $F(w) = w + 1 + \eta(w^{-\frac{1}{n}})$ (holds in $R_{\tau’}$ ), where $\eta(\zeta) = b_1 \zeta + b_2 \zeta^2 + ...$ , is some analytic function in a neighbourhood of $0$ , defined on $|\zeta| < r$ for some fixed $r > 0$ . Also assume $|\eta(\zeta)| \leq \frac{1}{2}$ for all $|\zeta| < r$ . Now suppose $\tau > \frac{1}{r^n} + 1$ is fixed, and let $x \geq \tau$ be a fixed real number. Define $E_{0,x} = \{ w \in \mathbb{C} : \Re(w) = x \}$ and $E_{1,x} = \{w \in \mathbb{C} : \Re(w) = x+1 \}$ . Then setting $H_x(w) = w$ if $w \in E_{0,x}$ and $H_{x}(w) = \Phi(w) = w + \eta((w-1)^{-\frac{1}{n}}) $ if $ w \in E_{1,x}$ we see that since $\Phi(w) = F(w-1)$ , $H_{x}(w)$ is injective on both $E_{0,x}$ and $E_{1,x}$ . Moreover since $\Re(H_{x}(w)) \geq \Re(w) - \frac{1}{2} = x+1 -\frac{1}{2} = x + \frac{1}{2}$ for $w \in E_{1,x}$ , the images of $E_{0,x}$ and $E_{1,x}$ under $H_{x}(w)$ do not intersect, thus $H_{x}(w)$ is injective. $\textbf{The problem}$ : Suppose we introduce a complex parameter $c \in \Delta$ where $\Delta = \mathbb{D}$ into $\eta(\zeta)$ as follows: Define $\eta(c,\zeta) = \eta(c r \zeta (x-1)^{\frac{1}{n}})$ for $|c| < 1$ and $|\zeta| \leq (x-1)^{-\frac{1}{n}}$ . Since $|c r \zeta (x-1)^{\frac{1}{n}}| < r$ , it follows that $\eta(c,\zeta)$ is a convergent power series and that $|\eta(c,\zeta)| \leq \frac{1}{2}$ for $|c| < 1$ and $|\zeta| \leq (x-1)^{-\frac{1}{n}}$ . Analogously to before, set $H_{x}(c,w) = w $ if $ (c,w) \in \Delta \times E_{0,x}$ and $H_{x}(c,w) =  \Phi(c,w) = w + \eta(c,(w-1)^{-\frac{1}{n}})$ if $ (c,w)  \in \Delta \times E_{1,x}$ Apparently now we can conclude by Rouche's theorem that for a $\textbf{fixed}$ $ |c| < 1$ , $H_{x}(c,.)$ is injective on $E_{0,x}$ and $E_{1,x}$ . I am lost as to how one is supposed to apply Rouche's theorem to see this.",": Let be a biholomorphism onto its image (i.e. is a holomorphic function with holomorphic inverse, here is open), where is some fixed real number. Moreover assume that extends holomorphically to a slightly larger right half plane with and is again a biholomorphism onto its image. Suppose (holds in ), where , is some analytic function in a neighbourhood of , defined on for some fixed . Also assume for all . Now suppose is fixed, and let be a fixed real number. Define and . Then setting if and if we see that since , is injective on both and . Moreover since for , the images of and under do not intersect, thus is injective. : Suppose we introduce a complex parameter where into as follows: Define for and . Since , it follows that is a convergent power series and that for and . Analogously to before, set if and if Apparently now we can conclude by Rouche's theorem that for a , is injective on and . I am lost as to how one is supposed to apply Rouche's theorem to see this.","\textbf{Problem setup} F : R_{\tau} \rightarrow R_{\tau} F : R_{\tau} \rightarrow V V = F(R_{\tau}) \subset R_{\tau} R_{\tau} = \{ w \in \mathbb{C} : \Re(w) > \tau \} \tau > 0 F R_{\tau’} \tau’ < \tau F(w) = w + 1 + \eta(w^{-\frac{1}{n}}) R_{\tau’} \eta(\zeta) = b_1 \zeta + b_2 \zeta^2 + ... 0 |\zeta| < r r > 0 |\eta(\zeta)| \leq \frac{1}{2} |\zeta| < r \tau > \frac{1}{r^n} + 1 x \geq \tau E_{0,x} = \{ w \in \mathbb{C} : \Re(w) = x \} E_{1,x} = \{w \in \mathbb{C} : \Re(w) = x+1 \} H_x(w) = w w \in E_{0,x} H_{x}(w) = \Phi(w) = w + \eta((w-1)^{-\frac{1}{n}})   w \in E_{1,x} \Phi(w) = F(w-1) H_{x}(w) E_{0,x} E_{1,x} \Re(H_{x}(w)) \geq \Re(w) - \frac{1}{2} = x+1 -\frac{1}{2} = x + \frac{1}{2} w \in E_{1,x} E_{0,x} E_{1,x} H_{x}(w) H_{x}(w) \textbf{The problem} c \in \Delta \Delta = \mathbb{D} \eta(\zeta) \eta(c,\zeta) = \eta(c r \zeta (x-1)^{\frac{1}{n}}) |c| < 1 |\zeta| \leq (x-1)^{-\frac{1}{n}} |c r \zeta (x-1)^{\frac{1}{n}}| < r \eta(c,\zeta) |\eta(c,\zeta)| \leq \frac{1}{2} |c| < 1 |\zeta| \leq (x-1)^{-\frac{1}{n}} H_{x}(c,w) = w   (c,w) \in \Delta \times E_{0,x} H_{x}(c,w) = 
\Phi(c,w) = w + \eta(c,(w-1)^{-\frac{1}{n}})  (c,w)  \in \Delta \times E_{1,x} \textbf{fixed}  |c| < 1 H_{x}(c,.) E_{0,x} E_{1,x}","['complex-analysis', 'analysis', 'complex-numbers', 'rouches-theorem']"
53,Integral of $\displaystyle\int_{|z| = 1} \frac{\sin(e^z)}{z^2} dz$,Integral of,\displaystyle\int_{|z| = 1} \frac{\sin(e^z)}{z^2} dz,"I'm required to solve the integral $\displaystyle\int_{|z| = 1} \frac{\sin(e^z)}{z^2} dz$ . For this, I'm using the Cauchy Integral Theorem which states that $$f^{(n)}(a) = \frac{n!}{2\pi i} \int_{\gamma} \frac{f(z)}{(z-a)^{n+1}} dz$$ under certain conditions that I'm omitting. Thus, $$f^{(1)}(0) = \frac{1}{2\pi i} \int_{\gamma} \frac{\sin(e^z)}{z^2} dz \Longrightarrow  2\pi i f'(0) = \int_{\gamma} \frac{\sin(e^z)}{z^2} dz$$ where $f'(z) = \frac{d}{dz} \sin(e^z) = e^z \cos(e^z)$ , where it follows that $f'(0) = \cos(1)$ . Therefore, $$\int_{|z| = 1} \frac{\sin(e^z)}{z^2} dz = 2\pi i\cos(1)$$ It looks correct to me, so I'm just looking for a solution-verification second opinion. Thanks!","I'm required to solve the integral . For this, I'm using the Cauchy Integral Theorem which states that under certain conditions that I'm omitting. Thus, where , where it follows that . Therefore, It looks correct to me, so I'm just looking for a solution-verification second opinion. Thanks!",\displaystyle\int_{|z| = 1} \frac{\sin(e^z)}{z^2} dz f^{(n)}(a) = \frac{n!}{2\pi i} \int_{\gamma} \frac{f(z)}{(z-a)^{n+1}} dz f^{(1)}(0) = \frac{1}{2\pi i} \int_{\gamma} \frac{\sin(e^z)}{z^2} dz \Longrightarrow  2\pi i f'(0) = \int_{\gamma} \frac{\sin(e^z)}{z^2} dz f'(z) = \frac{d}{dz} \sin(e^z) = e^z \cos(e^z) f'(0) = \cos(1) \int_{|z| = 1} \frac{\sin(e^z)}{z^2} dz = 2\pi i\cos(1),"['complex-analysis', 'solution-verification']"
54,"Constructing simply connected domains, starting from disks","Constructing simply connected domains, starting from disks",,"Let $\mathcal{G} $ be the collection of nonempty, open, connected subsets of $\mathbb{C} $ . For each $\mathcal{S}\subset\mathcal{G} $ , we may ask whether $\mathcal{S} $ is 'closed' under the following two 'operations'. If $D_1, D_2\in\mathcal{S} $ and $D_1\cap D_2 $ is nonempty and connected, then $D_1\cup D_2\in\mathcal{S} $ . If $D_1, D_2, D_3,\ldots\in\mathcal{S} $ and $D_n\subset D_{n+1} $ for all $n=1,2, 3,\ldots $ , then $\bigcup_{n=1}^\infty D_n\in\mathcal{S} $ . In page 87 of Complex Analysis by Freitag and Busam, the authors remark that the following can be proven in a non-trvial way: If $\mathcal{S}\subset\mathcal{G} $ contains all (nonempty open) disks and is closed under the above two operations, then $\mathcal{S} $ contains all simply connected domains in $\mathbb{C} $ So, how do we prove this statement? Can we generalize this to higher dimensions?","Let be the collection of nonempty, open, connected subsets of . For each , we may ask whether is 'closed' under the following two 'operations'. If and is nonempty and connected, then . If and for all , then . In page 87 of Complex Analysis by Freitag and Busam, the authors remark that the following can be proven in a non-trvial way: If contains all (nonempty open) disks and is closed under the above two operations, then contains all simply connected domains in So, how do we prove this statement? Can we generalize this to higher dimensions?","\mathcal{G}  \mathbb{C}  \mathcal{S}\subset\mathcal{G}  \mathcal{S}  D_1, D_2\in\mathcal{S}  D_1\cap D_2  D_1\cup D_2\in\mathcal{S}  D_1, D_2, D_3,\ldots\in\mathcal{S}  D_n\subset D_{n+1}  n=1,2, 3,\ldots  \bigcup_{n=1}^\infty D_n\in\mathcal{S}  \mathcal{S}\subset\mathcal{G}  \mathcal{S}  \mathbb{C} ","['complex-analysis', 'algebraic-topology', 'fundamental-groups']"
55,Is there a good way to estimate this double integral related to the Airy functions,Is there a good way to estimate this double integral related to the Airy functions,,"Let $\operatorname{Ai}(x,y)$ be the Airy kernel which is given by \begin{equation}\label{equ2.12} \operatorname{Ai}(x,y)=  \begin{cases}  \frac{\operatorname{Ai}(x)\operatorname{Ai}'(y)-\operatorname{Ai}(y)\operatorname{Ai}'(x)}{x-y}, & x\ne y, \\  \operatorname{Ai}'(x)^2-x\operatorname{Ai}(x)^2 & x=y. \\ \end{cases} \end{equation} Here $\operatorname{Ai}(x)$ denotes the standard Airy function \begin{align*} \operatorname{Ai}(x)=\frac{1}{2\pi i}\int_{\mathcal{C}}{e^{x\cdot t+t^3/3}\,\mathrm dt}, \end{align*} where $\mathcal{C}$ is a contour running from $\infty e^{- i \pi /3}$ to $\infty e^{ i \pi /3}$ , or any other contour which can be deform from this one such that $\operatorname{Re}(t^3) \to -\infty$ along the contour. Using the relation \begin{align}\label{equ2.13} \operatorname{Ai}(x,y)=\int_0^{\infty}{\operatorname{Ai}(t+x)\operatorname{Ai}(t+y)\,\mathrm dt}, \end{align} we have the following double integral representation of the Airy kernel \begin{align*} \operatorname{Ai}(x, y)=\frac{1}{(2\pi i)^2}\int_{-\mathcal{C}}\mathrm dt\int_{\mathcal{C}}\mathrm ds\, \frac{e^{x\cdot s+s^3/3}}{e^{y\cdot t+t^3/3}}\cdot\frac{1}{s-t}, \end{align*} Now let $\cdots<-\lambda_{k}<\cdots<-\lambda_1<0$ be the zeroes of the Airy function $\operatorname{Ai}(x)$ and let $\cdots<-\mu_{k}<\cdots<-\mu_1<0$ be the zeroes of $\operatorname{Ai}'(x)$ respectively. Choose large enough and close $\lambda_{k}$ , $\mu_{j}$ satisfying $$ |\lambda_k-\mu_j|\sim \frac{\lambda_k^{-\frac12}}{|k-j|}. $$ Then one can obtain $$ A(k, j)\triangleq\frac{|\operatorname{Ai}(-\lambda_k, -\mu_j)|}{\sqrt{\operatorname{Ai}(-\lambda_k, -\lambda_k)}\cdot \sqrt{\operatorname{Ai}(-\mu_j, -\mu_j)}}\approx \frac{1}{2|k-j|} $$ Now I need to deal with a more complicated form than the Airy kernel. More precisely, consider \begin{align*} I(x, y)=\frac{1}{(2\pi i)^2}\int_{-\mathcal{C}}\mathrm dt\int_{\mathcal{C}}\mathrm ds\, \frac{e^{x\cdot s+s^3/3}}{e^{y\cdot t+t^3/3}}\cdot\frac{1}{s-t}\cdot\frac{2e^{-2(s-t)}}{1-e^{-(s-t)}}. \end{align*} This can be seen as a ""perturbation"" of the Airy kernel. I hope to understand the asymptotic behavior of the form $$ T(k, j)\triangleq\frac{|I(-\lambda_k, -\mu_j)|}{\sqrt{\operatorname{Ai}(-\lambda_k, -\lambda_k)}\cdot \sqrt{\operatorname{Ai}(-\mu_j, -\mu_j)}}. $$ Question: Is there a good way to evaluate $T(k, j)$ and is there a similar estimate as $A(k, j)$ above? I think the key is to evaluate the double integral $I(-\lambda_k, -\mu_j)$ . Maybe some kind of saddle point argument is needed but I don't know how to deal with it. Thanks in advance.","Let be the Airy kernel which is given by Here denotes the standard Airy function where is a contour running from to , or any other contour which can be deform from this one such that along the contour. Using the relation we have the following double integral representation of the Airy kernel Now let be the zeroes of the Airy function and let be the zeroes of respectively. Choose large enough and close , satisfying Then one can obtain Now I need to deal with a more complicated form than the Airy kernel. More precisely, consider This can be seen as a ""perturbation"" of the Airy kernel. I hope to understand the asymptotic behavior of the form Question: Is there a good way to evaluate and is there a similar estimate as above? I think the key is to evaluate the double integral . Maybe some kind of saddle point argument is needed but I don't know how to deal with it. Thanks in advance.","\operatorname{Ai}(x,y) \begin{equation}\label{equ2.12}
\operatorname{Ai}(x,y)=
 \begin{cases}
 \frac{\operatorname{Ai}(x)\operatorname{Ai}'(y)-\operatorname{Ai}(y)\operatorname{Ai}'(x)}{x-y}, & x\ne y, \\
 \operatorname{Ai}'(x)^2-x\operatorname{Ai}(x)^2 & x=y. \\
\end{cases}
\end{equation} \operatorname{Ai}(x) \begin{align*}
\operatorname{Ai}(x)=\frac{1}{2\pi i}\int_{\mathcal{C}}{e^{x\cdot t+t^3/3}\,\mathrm dt},
\end{align*} \mathcal{C} \infty e^{- i \pi /3} \infty e^{ i \pi /3} \operatorname{Re}(t^3) \to -\infty \begin{align}\label{equ2.13}
\operatorname{Ai}(x,y)=\int_0^{\infty}{\operatorname{Ai}(t+x)\operatorname{Ai}(t+y)\,\mathrm dt},
\end{align} \begin{align*}
\operatorname{Ai}(x, y)=\frac{1}{(2\pi i)^2}\int_{-\mathcal{C}}\mathrm dt\int_{\mathcal{C}}\mathrm ds\, \frac{e^{x\cdot s+s^3/3}}{e^{y\cdot t+t^3/3}}\cdot\frac{1}{s-t},
\end{align*} \cdots<-\lambda_{k}<\cdots<-\lambda_1<0 \operatorname{Ai}(x) \cdots<-\mu_{k}<\cdots<-\mu_1<0 \operatorname{Ai}'(x) \lambda_{k} \mu_{j} 
|\lambda_k-\mu_j|\sim \frac{\lambda_k^{-\frac12}}{|k-j|}.
 
A(k, j)\triangleq\frac{|\operatorname{Ai}(-\lambda_k, -\mu_j)|}{\sqrt{\operatorname{Ai}(-\lambda_k, -\lambda_k)}\cdot \sqrt{\operatorname{Ai}(-\mu_j, -\mu_j)}}\approx \frac{1}{2|k-j|}
 \begin{align*}
I(x, y)=\frac{1}{(2\pi i)^2}\int_{-\mathcal{C}}\mathrm dt\int_{\mathcal{C}}\mathrm ds\, \frac{e^{x\cdot s+s^3/3}}{e^{y\cdot t+t^3/3}}\cdot\frac{1}{s-t}\cdot\frac{2e^{-2(s-t)}}{1-e^{-(s-t)}}.
\end{align*} 
T(k, j)\triangleq\frac{|I(-\lambda_k, -\mu_j)|}{\sqrt{\operatorname{Ai}(-\lambda_k, -\lambda_k)}\cdot \sqrt{\operatorname{Ai}(-\mu_j, -\mu_j)}}.
 T(k, j) A(k, j) I(-\lambda_k, -\mu_j)","['complex-analysis', 'asymptotics', 'special-functions']"
56,Is this Fourier series some combination of Eisenstein series?,Is this Fourier series some combination of Eisenstein series?,,"Consider the twisted Eisenstein series $$ \begin{align} 	E_{k \ge 1}\left[\begin{matrix} 		\phi \\ \theta 	\end{matrix}\right] := & \ - \frac{B_k(\lambda)}{k!} \\ 	& \ + \frac{1}{(k-1)!}\sum_{r \ge 0}' \frac{(r + \lambda)^{k - 1}\theta^{-1} q^{r + \lambda}}{1 - \theta^{-1}q^{r + \lambda}} 	+ \frac{(-1)^k}{(k-1)!}\sum_{r \ge 1} \frac{(r - \lambda)^{k - 1}\theta q^{r - \lambda}}{1 - \theta q^{r - \lambda}} \ , \end{align} $$ where $\phi = e^{2\pi i \lambda}, q = e^{2\pi i \tau}$ . We know that they all can be written in Fourier series, for example, $$ E_1 \begin{bmatrix} -1 \\ z \end{bmatrix}  = \frac{1}{2i}\sum_{n \in \mathbb{Z}, n \ne 0} \frac{1}{\sin n \pi \tau} e^{2\pi i n \mathfrak{z}} \ , \qquad E_2 \begin{bmatrix} 1 \\ z \end{bmatrix}  = - \frac{1}{12} -\frac{1}{4}\sum_{n \in \mathbb{Z}, n \ne 0} \frac{1}{\sin^2 n \pi \tau} e^{2\pi i n \mathfrak{z}} \ , $$ where $z = e^{2\pi i \mathfrak{z}}$ . Recently I run into the following series $$ \sum_{\substack{m,n \in \mathbb{Z}\\m,n,m+n \ne 0}}\frac{1}{\sin m \pi \tau\sin n \pi \tau \sin (m + n) \pi \tau}e^{2\pi i (m+n) \mathfrak{z}} \ . $$ I wonder if this can be rewritten in terms of Eisenstein series? Or is it known to be some other special functions? ============Update============ With some guess work and help from Mathematica, I think the answer is the following $$ \sum_{\substack{m,n \in \mathbb{Z}\\m,n,m+n \ne 0}}\frac{1}{\sin m \pi \tau\sin n \pi \tau \sin (m + n) \pi \tau}e^{2\pi i (m+n) \mathfrak{z}} \\ = - \frac{\vartheta'_1(\mathfrak{z})\vartheta''_1(\mathfrak{z})}{2\pi^3\vartheta_1(\mathfrak{z})^2} + \frac{\vartheta'''_1 (\mathfrak{z})}{6\pi^3\vartheta_1'(\mathfrak{z})} + 4 E_2(\tau) \frac{\vartheta_1'(\mathfrak{z})}{\pi\vartheta_1(\mathfrak{z})} \ , $$ where $E_2(\tau)$ is the standard quasi-modular Eisenstein series. In terms of twisted Eisenstein series, it reads $$ - 8 i \Bigg( E_3 \begin{bmatrix} 1 \\ z \end{bmatrix} + E_2 \begin{bmatrix} 1 \\ z \end{bmatrix} E_1 \begin{bmatrix} 1 \\ z \end{bmatrix} - E_2(\tau)E_1 \begin{bmatrix} 1 \\ z \end{bmatrix} \Bigg) $$ However, a proof is still lacking. The guessed result is a quasi-Jacobi form of modular weight-three . If  this were known beforehand, one can always make an anzatz in terms of the twisted Eisenstein series and work out the relative coefficients using Mathematica. So a relevant question would be: how to argue that the series gives rise to such a quasi-Jacobi form?","Consider the twisted Eisenstein series where . We know that they all can be written in Fourier series, for example, where . Recently I run into the following series I wonder if this can be rewritten in terms of Eisenstein series? Or is it known to be some other special functions? ============Update============ With some guess work and help from Mathematica, I think the answer is the following where is the standard quasi-modular Eisenstein series. In terms of twisted Eisenstein series, it reads However, a proof is still lacking. The guessed result is a quasi-Jacobi form of modular weight-three . If  this were known beforehand, one can always make an anzatz in terms of the twisted Eisenstein series and work out the relative coefficients using Mathematica. So a relevant question would be: how to argue that the series gives rise to such a quasi-Jacobi form?","
\begin{align}
	E_{k \ge 1}\left[\begin{matrix}
		\phi \\ \theta
	\end{matrix}\right] := & \ - \frac{B_k(\lambda)}{k!} \\
	& \ + \frac{1}{(k-1)!}\sum_{r \ge 0}' \frac{(r + \lambda)^{k - 1}\theta^{-1} q^{r + \lambda}}{1 - \theta^{-1}q^{r + \lambda}}
	+ \frac{(-1)^k}{(k-1)!}\sum_{r \ge 1} \frac{(r - \lambda)^{k - 1}\theta q^{r - \lambda}}{1 - \theta q^{r - \lambda}} \ ,
\end{align}
 \phi = e^{2\pi i \lambda}, q = e^{2\pi i \tau} 
E_1 \begin{bmatrix}
-1 \\ z
\end{bmatrix}
 = \frac{1}{2i}\sum_{n \in \mathbb{Z}, n \ne 0} \frac{1}{\sin n \pi \tau} e^{2\pi i n \mathfrak{z}} \ ,
\qquad
E_2 \begin{bmatrix}
1 \\ z
\end{bmatrix}
 = - \frac{1}{12} -\frac{1}{4}\sum_{n \in \mathbb{Z}, n \ne 0} \frac{1}{\sin^2 n \pi \tau} e^{2\pi i n \mathfrak{z}} \ ,
 z = e^{2\pi i \mathfrak{z}} 
\sum_{\substack{m,n \in \mathbb{Z}\\m,n,m+n \ne 0}}\frac{1}{\sin m \pi \tau\sin n \pi \tau \sin (m + n) \pi \tau}e^{2\pi i (m+n) \mathfrak{z}} \ .
 
\sum_{\substack{m,n \in \mathbb{Z}\\m,n,m+n \ne 0}}\frac{1}{\sin m \pi \tau\sin n \pi \tau \sin (m + n) \pi \tau}e^{2\pi i (m+n) \mathfrak{z}} \\
= - \frac{\vartheta'_1(\mathfrak{z})\vartheta''_1(\mathfrak{z})}{2\pi^3\vartheta_1(\mathfrak{z})^2}
+ \frac{\vartheta'''_1 (\mathfrak{z})}{6\pi^3\vartheta_1'(\mathfrak{z})}
+ 4 E_2(\tau) \frac{\vartheta_1'(\mathfrak{z})}{\pi\vartheta_1(\mathfrak{z})} \ ,
 E_2(\tau) 
- 8 i \Bigg(
E_3 \begin{bmatrix}
1 \\ z
\end{bmatrix}
+ E_2 \begin{bmatrix}
1 \\ z
\end{bmatrix}
E_1 \begin{bmatrix}
1 \\ z
\end{bmatrix}
- E_2(\tau)E_1 \begin{bmatrix}
1 \\ z
\end{bmatrix}
\Bigg)
","['complex-analysis', 'fourier-series', 'special-functions', 'modular-forms']"
57,Roots of $1+x+x^{2}/2!+...+x^{n}/n!$ are larger than $\frac{n}{2e}$,Roots of  are larger than,1+x+x^{2}/2!+...+x^{n}/n! \frac{n}{2e},"I wish to prove that the absolute values of the roots of the polynomial $p(x)=1+x+x^{2}/2!+...+x^{n}/n!$ are between $n/2e$ and $2n$ . I was able to prove the upper bound using the following: Claim: If $a_{n}x^{n}+\dots+a_{1}x+a_0$ is a polynomial, then its roots are bounded from above by $2\max\left\{\left(\frac{|a_i|}{|a_n|}\right)^{1/(n-i)}:\;0\leq i<n\right\}$ . It works perfectly, because $\frac{n!}{i!}<n^{n-i}$ , as one can see immediately by expanding the left hand side. To achieve the lower bound, I tried the following idea - if $x$ is a root of $p(x)$ , then $1/x$ is a root of $x^{n}p(1/x)$ . Thus I need to bound the roots of $q(x)=x^{n}+x^{n-1}+\dots+x/(n-1)!+1/n!$ from above by $2e/n$ . I tried to use the same claim, but now things are different, because now $\left(\frac{|a_i|}{|a_n|}\right)^{1/(n-i)}=\left(\frac{1}{(n-i)!}\right)^{\frac{1}{n-i}}$ , which equals $1$ when $i=n-1$ , which is certainly not smaller than $e/n$ . Am I missing something? I really can't think of any other idea, or in other words, I'm not sure how I would use Rouche's theorem here, so any hints or references towards this lower bound would be very useful, thank you very much!","I wish to prove that the absolute values of the roots of the polynomial are between and . I was able to prove the upper bound using the following: Claim: If is a polynomial, then its roots are bounded from above by . It works perfectly, because , as one can see immediately by expanding the left hand side. To achieve the lower bound, I tried the following idea - if is a root of , then is a root of . Thus I need to bound the roots of from above by . I tried to use the same claim, but now things are different, because now , which equals when , which is certainly not smaller than . Am I missing something? I really can't think of any other idea, or in other words, I'm not sure how I would use Rouche's theorem here, so any hints or references towards this lower bound would be very useful, thank you very much!",p(x)=1+x+x^{2}/2!+...+x^{n}/n! n/2e 2n a_{n}x^{n}+\dots+a_{1}x+a_0 2\max\left\{\left(\frac{|a_i|}{|a_n|}\right)^{1/(n-i)}:\;0\leq i<n\right\} \frac{n!}{i!}<n^{n-i} x p(x) 1/x x^{n}p(1/x) q(x)=x^{n}+x^{n-1}+\dots+x/(n-1)!+1/n! 2e/n \left(\frac{|a_i|}{|a_n|}\right)^{1/(n-i)}=\left(\frac{1}{(n-i)!}\right)^{\frac{1}{n-i}} 1 i=n-1 e/n,"['complex-analysis', 'polynomials', 'rouches-theorem']"
58,Contour Integral of $\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}dx$,Contour Integral of,\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}dx,"I had this question $\int_{0}^{\infty} \frac{\cos(x)}{(x^2+1)^2}dx$ on a introductory complex analysis final and really had a poor go of it. The poles are $\pm i$ both of order 2, so I replaced $cos(x)$ by $e^{iz}$ and then set $$H(z)=e^{iz}~~ \& ~~G(z)=(z^2+1)^2$$ and so $$G'(z)=4z(z^2+1)=4z((z+i)(z-i))$$ I then attempted to take $Res(\frac{H}{G'};i)$ $$\lim_{z\to i}\left((z-i)\frac{e^{iz}}{4z((z+i)(z-i))}\right)=\frac{e^{-1}}{4i(2i)}=-\frac{1}{8e}$$ But then multiplying by $2\pi i$ gave me an imaginary result which I clearly knew was wrong but due to time constraints I just couldn't afford to fix the problem. I am convinced that since $G'(i)=0$ that I was flawed from the start, could I have taken another derivative or slightly altered this approach? After a week of feeling poor about how I had fumbled this one, I decided to go back and redo it. I defined the same $H(z)=e^{iz}$ and $G(z)=(z^2+1)^2=(z+i)^2(z-i)^2$ . So define $$H_1(z)=\frac{e^{iz}}{(z+i)^2}$$ then $$H_1'(z)=\frac{ie^{iz}(z+i)^2-2(z+i)e^{iz}}{(z+i)^4}$$ To compute the residue I instead used the formula $Res(f;z_0)=\frac{H^{(m-1)}(z_0)}{(m-1)!}$ with $m=2$ , then $$Res(H_1;i)=\frac{H_1'(i)}{1!}=\frac{ie^{i\cdot i}(2i)^2-2(2i)e^{i\cdot i}}{2i^4}=\frac{-4ie^{-1}-4ie^{-1}}{16}=-\frac{i}{2e}$$ Then by the residue theorem; $2\pi i \cdot -\frac{i}{2e}= \frac{\pi}{e}$ . I chose to integrate over the contour of a semicircle in the upper half plane of radius $R$ , of which it can easily be shown that along upper arc $\gamma_R$ the integral will converge to 0 and so we are left with $\gamma_x$ which is the $\mathbb{R}$ -axis. Then $$\lim_{R\to\infty}\int_{-R}^{R}\frac{\cos(x)}{(x^2+1)^2}dx=\int_{-\infty}^{\infty}\frac{\cos(x)}{(x^2+1)^2}dx=2\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}=\frac{\pi}{e}$$ So $$\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}=\frac{\pi}{2e}$$ Could anybody confirm that this is the correct result and please point out any flaws in my method for both my first and second solutions?","I had this question on a introductory complex analysis final and really had a poor go of it. The poles are both of order 2, so I replaced by and then set and so I then attempted to take But then multiplying by gave me an imaginary result which I clearly knew was wrong but due to time constraints I just couldn't afford to fix the problem. I am convinced that since that I was flawed from the start, could I have taken another derivative or slightly altered this approach? After a week of feeling poor about how I had fumbled this one, I decided to go back and redo it. I defined the same and . So define then To compute the residue I instead used the formula with , then Then by the residue theorem; . I chose to integrate over the contour of a semicircle in the upper half plane of radius , of which it can easily be shown that along upper arc the integral will converge to 0 and so we are left with which is the -axis. Then So Could anybody confirm that this is the correct result and please point out any flaws in my method for both my first and second solutions?",\int_{0}^{\infty} \frac{\cos(x)}{(x^2+1)^2}dx \pm i cos(x) e^{iz} H(z)=e^{iz}~~ \& ~~G(z)=(z^2+1)^2 G'(z)=4z(z^2+1)=4z((z+i)(z-i)) Res(\frac{H}{G'};i) \lim_{z\to i}\left((z-i)\frac{e^{iz}}{4z((z+i)(z-i))}\right)=\frac{e^{-1}}{4i(2i)}=-\frac{1}{8e} 2\pi i G'(i)=0 H(z)=e^{iz} G(z)=(z^2+1)^2=(z+i)^2(z-i)^2 H_1(z)=\frac{e^{iz}}{(z+i)^2} H_1'(z)=\frac{ie^{iz}(z+i)^2-2(z+i)e^{iz}}{(z+i)^4} Res(f;z_0)=\frac{H^{(m-1)}(z_0)}{(m-1)!} m=2 Res(H_1;i)=\frac{H_1'(i)}{1!}=\frac{ie^{i\cdot i}(2i)^2-2(2i)e^{i\cdot i}}{2i^4}=\frac{-4ie^{-1}-4ie^{-1}}{16}=-\frac{i}{2e} 2\pi i \cdot -\frac{i}{2e}= \frac{\pi}{e} R \gamma_R \gamma_x \mathbb{R} \lim_{R\to\infty}\int_{-R}^{R}\frac{\cos(x)}{(x^2+1)^2}dx=\int_{-\infty}^{\infty}\frac{\cos(x)}{(x^2+1)^2}dx=2\int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}=\frac{\pi}{e} \int_{0}^{\infty}\frac{\cos(x)}{(x^2+1)^2}=\frac{\pi}{2e},"['complex-analysis', 'contour-integration', 'complex-integration', 'residue-calculus']"
59,Doubts in the solution of a Riemann Hilbert problem,Doubts in the solution of a Riemann Hilbert problem,,"Consider the following Riemann-Hilbert problem as given on Page 9 of this paper : $$\Phi^+(t)- \Phi^-(t) = 2u(t)$$ $$\Phi^+(t)+ \Phi^-(t) = \frac{P}{\pi i } \int_{t_1}^{t_2} \frac{d\zeta}{\zeta} u(\zeta) \frac{\zeta +t}{\zeta - t} = E(t - t^{-1})$$ where $E\in \mathbb{R}$ , $P$ denotes the principal value of the integral, and $\Phi^{\pm}(t)$ denote the values of the function $\Phi$ as the point $t$ on the counterclockwise arc $(t_1, t_2)$ is approached from the left and the right respectively. The function $u(t)$ takes the boundary values $u(t_1) = u(t_2) = 0$ . We have an additional constraint here as well: $$\Phi(\infty) = -1.$$ The author then proceeds to write down the solution of this problem which I am confused by. The first confusion is the claim is that ""the function $h(z) = \left[ (z-t_1)(z-t_2)\right]^{1/2}$ solves the problem $h^+ + h^- =0$ upto an entire function."" I am not able to see the same. The author then writes the ansatz for the function $\Phi(z) = h(z)H(z)$ . Using the Plemelj formula and calculating the residues, the author then obtains the expression for $H(z)$ as: $$H(z) = \frac{E}{2} \left[ \frac{z-z^{-1}}{\sqrt{(z-t_1)(z-t_2)}}+1 + \frac{1}{z}\right] $$ Is there an argument why the minus sign in the first term's numerator of the above equation gets converted into a plus sign in the following equation for $\Phi(z)$ ? $$\Phi(z) = \frac{E}{2} \left( z+ \frac{1}{z}\right) + \frac{E}{2} \left(\frac{1}{z} + 1\right) \sqrt{(z-t_1)(z-t_2)}$$ Using the above equation the author substitutes $\Phi(\infty) = -1$ to obtain: $$\frac{1-\cos \alpha}{2} = \frac{1}{E}$$ This follows if I set $z = e^{i\alpha}$ . However it does not seem reasonable to do so when $z=\infty$ . Is there some other way to see this?","Consider the following Riemann-Hilbert problem as given on Page 9 of this paper : where , denotes the principal value of the integral, and denote the values of the function as the point on the counterclockwise arc is approached from the left and the right respectively. The function takes the boundary values . We have an additional constraint here as well: The author then proceeds to write down the solution of this problem which I am confused by. The first confusion is the claim is that ""the function solves the problem upto an entire function."" I am not able to see the same. The author then writes the ansatz for the function . Using the Plemelj formula and calculating the residues, the author then obtains the expression for as: Is there an argument why the minus sign in the first term's numerator of the above equation gets converted into a plus sign in the following equation for ? Using the above equation the author substitutes to obtain: This follows if I set . However it does not seem reasonable to do so when . Is there some other way to see this?","\Phi^+(t)- \Phi^-(t) = 2u(t) \Phi^+(t)+ \Phi^-(t) = \frac{P}{\pi i } \int_{t_1}^{t_2} \frac{d\zeta}{\zeta} u(\zeta) \frac{\zeta +t}{\zeta - t} = E(t - t^{-1}) E\in \mathbb{R} P \Phi^{\pm}(t) \Phi t (t_1, t_2) u(t) u(t_1) = u(t_2) = 0 \Phi(\infty) = -1. h(z) = \left[ (z-t_1)(z-t_2)\right]^{1/2} h^+ + h^- =0 \Phi(z) = h(z)H(z) H(z) H(z) = \frac{E}{2} \left[ \frac{z-z^{-1}}{\sqrt{(z-t_1)(z-t_2)}}+1 + \frac{1}{z}\right]  \Phi(z) \Phi(z) = \frac{E}{2} \left( z+ \frac{1}{z}\right) + \frac{E}{2} \left(\frac{1}{z} + 1\right) \sqrt{(z-t_1)(z-t_2)} \Phi(\infty) = -1 \frac{1-\cos \alpha}{2} = \frac{1}{E} z = e^{i\alpha} z=\infty",['complex-analysis']
60,Existence of $R>0$ such that ${\int_{|z|=R}{f'(z)\over f(z)}dz}=0$,Existence of  such that,R>0 {\int_{|z|=R}{f'(z)\over f(z)}dz}=0,"I'm trying to solve the following problem: Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be a meromorphic function such that $f({1\over z})$ is analytic at $z=0$ and $\displaystyle{\lim_{z\rightarrow\infty}f(z)}=0$ . Show that there exists $R>0$ such that $\displaystyle{\int_{|z|=R}{f'(z)\over f(z)}dz}=0$ . If I find a $R>0$ such that $f(z)$ has the same finite number of zeros and poles in $B(0,R)$ , then by the Argument Theorem I would have that integral is zero, but how to know that such $R$ exists? I would appreciate any hint.","I'm trying to solve the following problem: Let be a meromorphic function such that is analytic at and . Show that there exists such that . If I find a such that has the same finite number of zeros and poles in , then by the Argument Theorem I would have that integral is zero, but how to know that such exists? I would appreciate any hint.","f:\mathbb{C}\rightarrow\mathbb{C} f({1\over z}) z=0 \displaystyle{\lim_{z\rightarrow\infty}f(z)}=0 R>0 \displaystyle{\int_{|z|=R}{f'(z)\over f(z)}dz}=0 R>0 f(z) B(0,R) R",['complex-analysis']
61,Understanding Complex Form of Green's Theorem,Understanding Complex Form of Green's Theorem,,"I'm reviewing complex analysis for the GRE. I've never taken a course in complex analysis before, but I do know vector calculus. I'm trying to understand the statement of the complex version of Green's theorem, which has a few symbols that I've never seen before. $$ \oint_C F(z,\overline{z}) dz = 2i \iint_{R} \frac{\partial F}{\partial \overline{z}} dA $$ For example, what is $F(z,\overline{z})?$ How is $\partial F/\partial \overline{z}?$ defined? Also, if there is an obvious connection to Green's theorem on a plane (the real version) I would appreciate an explanation!","I'm reviewing complex analysis for the GRE. I've never taken a course in complex analysis before, but I do know vector calculus. I'm trying to understand the statement of the complex version of Green's theorem, which has a few symbols that I've never seen before. For example, what is How is defined? Also, if there is an obvious connection to Green's theorem on a plane (the real version) I would appreciate an explanation!"," \oint_C F(z,\overline{z}) dz = 2i \iint_{R} \frac{\partial F}{\partial \overline{z}} dA  F(z,\overline{z})? \partial F/\partial \overline{z}?","['complex-analysis', 'vector-analysis', 'complex-integration', 'greens-theorem']"
62,Is $\pi (x)=\operatorname{R}(x)-\sum_{\rho}\operatorname{R}(x^{\rho})$ correct at all?,Is  correct at all?,\pi (x)=\operatorname{R}(x)-\sum_{\rho}\operatorname{R}(x^{\rho}),"It should be the case that, in some appropriate sense $$\pi (x)\sim \operatorname{Ri}(x)-\sum_{\rho}\operatorname{Ri}(x^{\rho}) \tag*{(4)}$$ with $\operatorname{Ri}$ denoting the Riemann function defined: $$\operatorname{Ri}(x)=\sum_{m=1}^\infty \frac{\mu (m)}{m}\operatorname{li}\left(x^{\frac{1}{m}}\right). \tag*{(5)}$$ This relation $(4)$ has been called ""exact"" [in Ribenboim's The New Book of Prime Number Records ], yet we could not locate a proof in the literature; such a proof should be nontrivial, as the conditionally convergent series involved are problematic. In any case relation $(4)$ is quite accurate, and furthermore the Riemann function $\operatorname{Ri}$ can be calculated efficiently (...) The sum in $(4)$ over critical zeros is not absolutely convergent, and furthermore the phases of the summands interact in a frightfully complicated way. —from Journal of Computational and Applied Mathematics by Borwein et al. Of profound importance, Bernhard Riemann proved that the prime-counting function is exactly $$\pi (x)=\operatorname{R}(x)-\sum_{\rho}\operatorname{R}(x^{\rho})$$ where $$\operatorname{R}(x)=\sum_{n=1}^\infty \frac{\mu (n)}{n}\operatorname{li}\left(x^{\frac{1}{n}}\right),$$ (...) $\rho$ indexes every zero of the Riemann zeta function, and $\operatorname{li}\left(x^{\frac{1}{n}}\right)$ is not evaluated with a branch cut but instead considered as $\operatorname{Ei}\left(\frac{\rho}{n}\ln x\right)$ . Equivalently, if the trivial zeros are collected and the sum is taken only over the non-trivial zeros $\rho$ of the Riemann zeta function, then $\pi (x)$ may be written $$\pi (x)=\operatorname{R}(x)-\sum_{\rho}\operatorname{R}(x^{\rho})-\frac{1}{\ln x}+\frac{1}{\pi}\arctan\frac{\pi}{\ln x}.$$ —from Wikipedia's Prime counting function article Questions: According to Borwein and Ribenboim, the index in $(4)$ should run only over non-trivial zeros . According to Wikipedia, the index in $(4)$ should run over all zeros . Wikipedia states that if the sum runs only over non-trivial zeros, then we add the $\ln$ and $\arctan$ terms, which is even more confusing. So what's true? I'm pretty sure that Riemann did not prove the formula $(4)$ . He only proposed a ""weaker"" form of it, namely $$\pi (x)=\sum_{m=1}^\infty \frac{\mu (m)}{m}J\left(x^{\frac{1}{m}}\right)$$ where $$J(x)=\operatorname{li}(x)-\sum_{\rho}\operatorname{li}\left(x^{\rho}\right)+\int_x^\infty \frac{dt}{t(t^2-1)\ln t}-\ln 2$$ and where $\rho$ runs over all non-trivial zeros. The formula was proven by Mangoldt, not Riemann. The Wikipedia article is wrong in that historical fact, isn't it? Even though the proof of $(4)$ is nowhere to be found in the literature, Raymond Manzoni provided a partial proof here: Two Representations of the Prime Counting Function . I call it partial because it is unknown whether the series converges at all: How could that be settled down? Note: When I refer to the formula $(4)$ in this question, I assume $=$ instead of $\sim$ .","It should be the case that, in some appropriate sense with denoting the Riemann function defined: This relation has been called ""exact"" [in Ribenboim's The New Book of Prime Number Records ], yet we could not locate a proof in the literature; such a proof should be nontrivial, as the conditionally convergent series involved are problematic. In any case relation is quite accurate, and furthermore the Riemann function can be calculated efficiently (...) The sum in over critical zeros is not absolutely convergent, and furthermore the phases of the summands interact in a frightfully complicated way. —from Journal of Computational and Applied Mathematics by Borwein et al. Of profound importance, Bernhard Riemann proved that the prime-counting function is exactly where (...) indexes every zero of the Riemann zeta function, and is not evaluated with a branch cut but instead considered as . Equivalently, if the trivial zeros are collected and the sum is taken only over the non-trivial zeros of the Riemann zeta function, then may be written —from Wikipedia's Prime counting function article Questions: According to Borwein and Ribenboim, the index in should run only over non-trivial zeros . According to Wikipedia, the index in should run over all zeros . Wikipedia states that if the sum runs only over non-trivial zeros, then we add the and terms, which is even more confusing. So what's true? I'm pretty sure that Riemann did not prove the formula . He only proposed a ""weaker"" form of it, namely where and where runs over all non-trivial zeros. The formula was proven by Mangoldt, not Riemann. The Wikipedia article is wrong in that historical fact, isn't it? Even though the proof of is nowhere to be found in the literature, Raymond Manzoni provided a partial proof here: Two Representations of the Prime Counting Function . I call it partial because it is unknown whether the series converges at all: How could that be settled down? Note: When I refer to the formula in this question, I assume instead of .","\pi (x)\sim \operatorname{Ri}(x)-\sum_{\rho}\operatorname{Ri}(x^{\rho}) \tag*{(4)} \operatorname{Ri} \operatorname{Ri}(x)=\sum_{m=1}^\infty \frac{\mu (m)}{m}\operatorname{li}\left(x^{\frac{1}{m}}\right). \tag*{(5)} (4) (4) \operatorname{Ri} (4) \pi (x)=\operatorname{R}(x)-\sum_{\rho}\operatorname{R}(x^{\rho}) \operatorname{R}(x)=\sum_{n=1}^\infty \frac{\mu (n)}{n}\operatorname{li}\left(x^{\frac{1}{n}}\right), \rho \operatorname{li}\left(x^{\frac{1}{n}}\right) \operatorname{Ei}\left(\frac{\rho}{n}\ln x\right) \rho \pi (x) \pi (x)=\operatorname{R}(x)-\sum_{\rho}\operatorname{R}(x^{\rho})-\frac{1}{\ln x}+\frac{1}{\pi}\arctan\frac{\pi}{\ln x}. (4) (4) \ln \arctan (4) \pi (x)=\sum_{m=1}^\infty \frac{\mu (m)}{m}J\left(x^{\frac{1}{m}}\right) J(x)=\operatorname{li}(x)-\sum_{\rho}\operatorname{li}\left(x^{\rho}\right)+\int_x^\infty \frac{dt}{t(t^2-1)\ln t}-\ln 2 \rho (4) (4) = \sim","['complex-analysis', 'convergence-divergence', 'prime-numbers', 'riemann-zeta']"
63,Sum of logarithm reciprocals,Sum of logarithm reciprocals,,"I am looking for an exact formula for the sum : $$\sum_{1<n\leq x}\frac{1}{\log n}$$ My attempt : Using the Perron's formula for partial Dirichlet series, we have : $$\sum_{1<n\leq x}\frac{1}{n^{s}}=\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}(\zeta(s+\omega)-1)\frac{x^{\omega}}{\omega}d\omega$$ $$=\frac{1}{2\pi i }\int_{c^{'}-i\infty}^{c^{'}+i\infty}(\zeta(z)-1)\frac{x^{z-s}}{z-s}dz$$ Now, we have : $$\sum_{1<n\leq x}\frac{1}{\log n}=\int_{0}^{\infty}\sum_{1<n\leq x}\frac{1}{n^{s}}ds=\frac{1}{2\pi i }\int_{c^{'}-i\infty}^{c^{'}+i\infty}\left(\zeta(z)-1\right)\text{Ei}(z\log x)dz$$ $\text{Ei}(\cdot)$ being the exponential integral function. By the residue theorem, the smooth part of this sum is given by : $$\text{Ei}(\log x)=\text{li}(x)$$ $\text{li}(\cdot)$ being the logarithmic integral function. My question is about the oscillatory part. How does one find an exact formula for this  oscillatory part ?","I am looking for an exact formula for the sum : My attempt : Using the Perron's formula for partial Dirichlet series, we have : Now, we have : being the exponential integral function. By the residue theorem, the smooth part of this sum is given by : being the logarithmic integral function. My question is about the oscillatory part. How does one find an exact formula for this  oscillatory part ?",\sum_{1<n\leq x}\frac{1}{\log n} \sum_{1<n\leq x}\frac{1}{n^{s}}=\frac{1}{2\pi i }\int_{c-i\infty}^{c+i\infty}(\zeta(s+\omega)-1)\frac{x^{\omega}}{\omega}d\omega =\frac{1}{2\pi i }\int_{c^{'}-i\infty}^{c^{'}+i\infty}(\zeta(z)-1)\frac{x^{z-s}}{z-s}dz \sum_{1<n\leq x}\frac{1}{\log n}=\int_{0}^{\infty}\sum_{1<n\leq x}\frac{1}{n^{s}}ds=\frac{1}{2\pi i }\int_{c^{'}-i\infty}^{c^{'}+i\infty}\left(\zeta(z)-1\right)\text{Ei}(z\log x)dz \text{Ei}(\cdot) \text{Ei}(\log x)=\text{li}(x) \text{li}(\cdot),"['complex-analysis', 'number-theory', 'analytic-number-theory']"
64,"A meromorphic function $f$ with poles of order $2$ at $\sqrt { n }$ ($n=1,2,3,...$),","A meromorphic function  with poles of order  at  (),","f 2 \sqrt { n } n=1,2,3,...","find a meromorphic function $f$ with poles of order 2 at $\sqrt { n }$ ( $n=1,2,3,...$ ), the Residue at each pole is $2$ , and $\lim _ { z \rightarrow \sqrt { n } } ( z - \sqrt { n } ) ^ { 2 } f ( z ) = 1$ for all $n \in \mathbb N$ . I tried with $f ( z ) = \frac { 1 } { \left( \sin \pi z^ { 2 } \right) ^ { 2 } }$ , but conditions are not fully conciding","find a meromorphic function with poles of order 2 at ( ), the Residue at each pole is , and for all . I tried with , but conditions are not fully conciding","f \sqrt { n } n=1,2,3,... 2 \lim _ { z \rightarrow \sqrt { n } } ( z - \sqrt { n } ) ^ { 2 } f ( z ) = 1 n \in \mathbb N f ( z ) = \frac { 1 } { \left( \sin \pi z^ { 2 } \right) ^ { 2 } }",['complex-analysis']
65,Looking for the software F(z) from lascaux graphics,Looking for the software F(z) from lascaux graphics,,I know this is not a typical math question. I also thought about asking on superUser or stackoverflow but I came to the conclusion that I have a higher chance of getting an answer here on the math stackexchange. I recently have read about the tool named f(z) from lascaux graphics which helps visualizing complex valued functions. This seems to be a very nice tool in complex analysis.  However it looks a little bit outdated and I cant find anything like a website or something.  Do you know this tool and/or have any idea where I can find additional information about it?,I know this is not a typical math question. I also thought about asking on superUser or stackoverflow but I came to the conclusion that I have a higher chance of getting an answer here on the math stackexchange. I recently have read about the tool named f(z) from lascaux graphics which helps visualizing complex valued functions. This seems to be a very nice tool in complex analysis.  However it looks a little bit outdated and I cant find anything like a website or something.  Do you know this tool and/or have any idea where I can find additional information about it?,,"['complex-analysis', 'math-software']"
66,Fubini Study Geodesics on $\Bbb {CP}^n$,Fubini Study Geodesics on,\Bbb {CP}^n,"I want to solve the geodesic equation on $\mathbb{CP}^n$ with the Fubini Study metric $$ g_{ij}=\frac{\left(1+{\mid z\mid}^2\right)\delta_{ij}-\bar{z}_iz_j}{\left(1+{\mid z\mid}^2\right)^2} $$ I have worked out the Christoffel symbols for the above metric. They are as follows $$ \Gamma^{k}_{ij}=-\frac{\delta^{k}_{j}\bar{z}_{i}+\delta^{k}_{i}\bar{z}_{j}}{\left(1+{\mid z\mid}^2\right)} $$ Thus the affinely parametrized geodesic equation becomes $$ \frac{d^2z^k(t)}{dt^2}-\frac{2\bar{z}_{j}(t)}{\left(1+{\mid z(t)\mid}^2\right)}\frac{dz^k(t)}{dt}\frac{dz^j(t)}{dt}=0 $$ I want to solve this equation for the case of $n=1,2$ . I have never solved an ODE with complex variables. Any suggestion or help is appreciated.",I want to solve the geodesic equation on with the Fubini Study metric I have worked out the Christoffel symbols for the above metric. They are as follows Thus the affinely parametrized geodesic equation becomes I want to solve this equation for the case of . I have never solved an ODE with complex variables. Any suggestion or help is appreciated.,"\mathbb{CP}^n 
g_{ij}=\frac{\left(1+{\mid z\mid}^2\right)\delta_{ij}-\bar{z}_iz_j}{\left(1+{\mid z\mid}^2\right)^2}
 
\Gamma^{k}_{ij}=-\frac{\delta^{k}_{j}\bar{z}_{i}+\delta^{k}_{i}\bar{z}_{j}}{\left(1+{\mid z\mid}^2\right)}
 
\frac{d^2z^k(t)}{dt^2}-\frac{2\bar{z}_{j}(t)}{\left(1+{\mid z(t)\mid}^2\right)}\frac{dz^k(t)}{dt}\frac{dz^j(t)}{dt}=0
 n=1,2","['complex-analysis', 'ordinary-differential-equations', 'differential-geometry', 'complex-geometry', 'geodesic']"
67,Principal Part of Laurent Series Converges in Punctured Disc,Principal Part of Laurent Series Converges in Punctured Disc,,"I'm trying to work through the following problem: Prove that if the holomorphic function $f$ has an isolated singularity at $z_{0}$ , then the principal part of the Laurent series of $f$ at $z_{0}$ converges in $\mathbb{C}\setminus\{z_{0}\}$ . My Thoughts: If $f$ has the Laurent series expansion $f(z)=\sum_{n=-\infty}^{\infty}a_{n}(z-z_{0})^{n}$ , then the principal part of the Laurent series is $\sum_{n=-\infty}^{-1}a_{n}(z-z_{0})^{n}$ . I'm assuming that I need to break this up to consider all possible types of singularities that could occur at $z_{0}$ (i.e., a removable singularity, a pole, or an essential singularity). If $z_{0}$ is a removable singularity, the principal part of the Laurent series is trivial ( $a_{n}=0$ for all $n<0$ ), so there is nothing to show. If $z_{0}$ is a pole (say of order $k$ ), then $a_{-k}\neq 0$ , but $a_{n}=0$ for all $n<-k$ . Then the principal part is $\sum_{n=-k}^{-1}a_{n}(z-z_{0})^{n}$ . If $z_{0}$ is an essential singularity, then the principal part of the Laurent series has infinitely many non-vanishing terms. Then the principal part is $\sum_{n=-\infty}^{-1}a_{n}(z-z_{0})^{n}$ . My Questions: Am I right in saying that the convergence is trivial in the case that $z_{0}$ is a removable singularity? Also, how would I go about the case where $z_{0}$ is a pole or an essential singularity? Is it some sort of Cauchy-Hadamard argument? Thanks in advance for any suggestions.","I'm trying to work through the following problem: Prove that if the holomorphic function has an isolated singularity at , then the principal part of the Laurent series of at converges in . My Thoughts: If has the Laurent series expansion , then the principal part of the Laurent series is . I'm assuming that I need to break this up to consider all possible types of singularities that could occur at (i.e., a removable singularity, a pole, or an essential singularity). If is a removable singularity, the principal part of the Laurent series is trivial ( for all ), so there is nothing to show. If is a pole (say of order ), then , but for all . Then the principal part is . If is an essential singularity, then the principal part of the Laurent series has infinitely many non-vanishing terms. Then the principal part is . My Questions: Am I right in saying that the convergence is trivial in the case that is a removable singularity? Also, how would I go about the case where is a pole or an essential singularity? Is it some sort of Cauchy-Hadamard argument? Thanks in advance for any suggestions.",f z_{0} f z_{0} \mathbb{C}\setminus\{z_{0}\} f f(z)=\sum_{n=-\infty}^{\infty}a_{n}(z-z_{0})^{n} \sum_{n=-\infty}^{-1}a_{n}(z-z_{0})^{n} z_{0} z_{0} a_{n}=0 n<0 z_{0} k a_{-k}\neq 0 a_{n}=0 n<-k \sum_{n=-k}^{-1}a_{n}(z-z_{0})^{n} z_{0} \sum_{n=-\infty}^{-1}a_{n}(z-z_{0})^{n} z_{0} z_{0},"['complex-analysis', 'laurent-series', 'holomorphic-functions', 'singularity']"
68,Prove the roots of $p(z)+z^n\bar{p}(\frac{1}{z})$ lie on the unit circle,Prove the roots of  lie on the unit circle,p(z)+z^n\bar{p}(\frac{1}{z}),"I have to prove the following question from ""A course in complex analysis and riemann surfaces"": Let $p(z)=\sum_{i=0}^na_iz^u$ be a polynomial with all roots inside the (open )unit disk. Denote by $\bar{p}(z)$ the polynomial $\sum_{i=0}^n\bar{a_i}z^i$. Prove that the roots of $p(z)+z^n\bar{p}(\frac{1}{z})$ lie on the unit circle. Now it's not hard to see that if $r$ is a root of $p(z)$, then $\frac{1}{\bar{r}}$ is a root of $z^n\bar{p}(\frac{1}{z})$. But that's about as far as I got. I would like a hint on how to prove this.","I have to prove the following question from ""A course in complex analysis and riemann surfaces"": Let $p(z)=\sum_{i=0}^na_iz^u$ be a polynomial with all roots inside the (open )unit disk. Denote by $\bar{p}(z)$ the polynomial $\sum_{i=0}^n\bar{a_i}z^i$. Prove that the roots of $p(z)+z^n\bar{p}(\frac{1}{z})$ lie on the unit circle. Now it's not hard to see that if $r$ is a root of $p(z)$, then $\frac{1}{\bar{r}}$ is a root of $z^n\bar{p}(\frac{1}{z})$. But that's about as far as I got. I would like a hint on how to prove this.",,['complex-analysis']
69,Complex power series on the circle of convergence,Complex power series on the circle of convergence,,"I'm trying to find examples of complex power series $\sum a_n z^n$ with radius of convergence $1$ and where: (1) The series converges everywhere on the circle $|z| = 1$ except one point;  (2) The series diverges everywhere on the circle $|z| = 1$ except one point. For (1) I found $\displaystyle \sum_{n=1}^\infty \frac{z^n}{n}$ which is a harmonic series when $|z| = 1$. It converges for $|z|=1, z \neq 1$ by Dirichlet test: $\sum_{n=1}^N e^{in\theta}$ bounded and $1/n$ decreasing Can anyone give an example for part (2)?","I'm trying to find examples of complex power series $\sum a_n z^n$ with radius of convergence $1$ and where: (1) The series converges everywhere on the circle $|z| = 1$ except one point;  (2) The series diverges everywhere on the circle $|z| = 1$ except one point. For (1) I found $\displaystyle \sum_{n=1}^\infty \frac{z^n}{n}$ which is a harmonic series when $|z| = 1$. It converges for $|z|=1, z \neq 1$ by Dirichlet test: $\sum_{n=1}^N e^{in\theta}$ bounded and $1/n$ decreasing Can anyone give an example for part (2)?",,"['complex-analysis', 'power-series']"
70,Does Cauchy Principal Value always exist?,Does Cauchy Principal Value always exist?,,"Is there any theorem that guarantees the existence of Cauchy Principal Value? I know that for many improper integrals, the Cauchy Principal Value exists but the improper integral might not exist, such as $$\int_{-\infty}^{\infty}x\,\mathrm{d}x.$$ So, I am wondering the reason that leads to such a result. Some says that it lies under the fact whether the limiting process is symmetric or non-symmetric. This seems to make sense. But why? Is there any more detailed explanation? Thank you!","Is there any theorem that guarantees the existence of Cauchy Principal Value? I know that for many improper integrals, the Cauchy Principal Value exists but the improper integral might not exist, such as So, I am wondering the reason that leads to such a result. Some says that it lies under the fact whether the limiting process is symmetric or non-symmetric. This seems to make sense. But why? Is there any more detailed explanation? Thank you!","\int_{-\infty}^{\infty}x\,\mathrm{d}x.","['complex-analysis', 'cauchy-principal-value']"
71,How to tell if a simply-connected curve is the complex plane or disk,How to tell if a simply-connected curve is the complex plane or disk,,"Suppose I have an analytic function $f: \mathbb{C}^2 \to \mathbb{C}$ whose zero locus $V=\{(z,w) \in \mathbb{C}^2 : f(z,w)=0\}$ is smooth and simply connected. By uniformization, $V$ is conformally equivalent to either $\mathbb{C}$ or the open unit disk $\Delta \subset \mathbb{C}$. But which one? Is this ""easily"" determined by some properties of the function $f$?","Suppose I have an analytic function $f: \mathbb{C}^2 \to \mathbb{C}$ whose zero locus $V=\{(z,w) \in \mathbb{C}^2 : f(z,w)=0\}$ is smooth and simply connected. By uniformization, $V$ is conformally equivalent to either $\mathbb{C}$ or the open unit disk $\Delta \subset \mathbb{C}$. But which one? Is this ""easily"" determined by some properties of the function $f$?",,"['complex-analysis', 'differential-geometry', 'complex-geometry', 'riemann-surfaces']"
72,Why the factor $e^{g(z)}$ in the Weierstrass factorization theorem?,Why the factor  in the Weierstrass factorization theorem?,e^{g(z)},"The Weierstrass factorization theorem is usually stated as such (quote from Wikipedia): Let $f$ be an entire function, and let $\{a_n\}$ be the non-zero zeros of $f$ repeated according to multiplicity; suppose also that $f$ has a zero at $z = 0$ of order $m ≥ 0$ (...). Then there exists an entire function $g$ and a sequence of integers $\{p_{n}\}$ such that $$f(z)=z^me^{g(z)}\prod_{n=1}^\infty E_{p_n}\left(\frac{z}{a_n}\right).$$ It seems to me that this combines two different theorems: that $f$ can be written as $$f(z)=z^mh(z)\prod_{n=1}^\infty E_{p_n}\left(\frac{z}{a_n}\right)$$ for some entire function $h$ with no zeros, and that any entire function $h$ with no zeros can be written as $h(z)=e^{g(z)}$ for some entire function $g$. The latter is an interesting nontrivial statement in its own right, and, as far as I can tell, its proof is not connected with the rest of the proof of the Weierstrass factorization theorem. So, what is the mathematical or historical reason for writing the theorem with $e^{g(z)}$ instead of $h(z)$?","The Weierstrass factorization theorem is usually stated as such (quote from Wikipedia): Let $f$ be an entire function, and let $\{a_n\}$ be the non-zero zeros of $f$ repeated according to multiplicity; suppose also that $f$ has a zero at $z = 0$ of order $m ≥ 0$ (...). Then there exists an entire function $g$ and a sequence of integers $\{p_{n}\}$ such that $$f(z)=z^me^{g(z)}\prod_{n=1}^\infty E_{p_n}\left(\frac{z}{a_n}\right).$$ It seems to me that this combines two different theorems: that $f$ can be written as $$f(z)=z^mh(z)\prod_{n=1}^\infty E_{p_n}\left(\frac{z}{a_n}\right)$$ for some entire function $h$ with no zeros, and that any entire function $h$ with no zeros can be written as $h(z)=e^{g(z)}$ for some entire function $g$. The latter is an interesting nontrivial statement in its own right, and, as far as I can tell, its proof is not connected with the rest of the proof of the Weierstrass factorization theorem. So, what is the mathematical or historical reason for writing the theorem with $e^{g(z)}$ instead of $h(z)$?",,['complex-analysis']
73,Computing: $\int_0^{\infty}\frac{dx}{(x+a)((\ln x)^2+\pi^2)}.$,Computing:,\int_0^{\infty}\frac{dx}{(x+a)((\ln x)^2+\pi^2)}.,"Assume $a>0$ and evaluate $$\int_0^{\infty}\frac{dx}{(x+a)((\ln x)^2+\pi^2)}.$$ My biggest issue when doing these problems is deciding which closed curve I should try, so if someone could point me in the right direction with at least that I would appreciate it!","Assume $a>0$ and evaluate $$\int_0^{\infty}\frac{dx}{(x+a)((\ln x)^2+\pi^2)}.$$ My biggest issue when doing these problems is deciding which closed curve I should try, so if someone could point me in the right direction with at least that I would appreciate it!",,"['complex-analysis', 'logarithms', 'complex-integration']"
74,Ring of rational-coefficient power series defining entire functions,Ring of rational-coefficient power series defining entire functions,,"I'm wondering if anyone has come across the following ring before. Let $R$ be the ring of complex power series $f=\sum_{n \ge 0} a_n t^n$ such that $a_n \in \mathbb{Q} \: \: \forall \: n$ The function $f: \mathbb{C} \rightarrow \mathbb{C}$ is entire Any information about it would be welcome but in order to keep the question specific, I'll list a few things I would like to know in particular. Is $R$ a unique factorisation domain? Are there any elements of $R$ which are known to be prime/irreducible but are not associates of polynomials? If an element $f \in R$ is prime/irreducible, must all its zeroes (in $\mathbb{C}$) be simple? Is every $\alpha \in \mathbb{C}$ a root of some nonzero $f \in R$ ?","I'm wondering if anyone has come across the following ring before. Let $R$ be the ring of complex power series $f=\sum_{n \ge 0} a_n t^n$ such that $a_n \in \mathbb{Q} \: \: \forall \: n$ The function $f: \mathbb{C} \rightarrow \mathbb{C}$ is entire Any information about it would be welcome but in order to keep the question specific, I'll list a few things I would like to know in particular. Is $R$ a unique factorisation domain? Are there any elements of $R$ which are known to be prime/irreducible but are not associates of polynomials? If an element $f \in R$ is prime/irreducible, must all its zeroes (in $\mathbb{C}$) be simple? Is every $\alpha \in \mathbb{C}$ a root of some nonzero $f \in R$ ?",,"['abstract-algebra', 'complex-analysis', 'ring-theory']"
75,Good video lectures on complex analysis?,Good video lectures on complex analysis?,,"I would like to find a complete series of video lectures on complex analysis, preferably with the following conditions: The videos are in English and clearly recorded. (Using English as a second language, I find it hard to understand spoken English when the sound is not clear.) The videos constitute a complete course and they are intended for students in mathematics who already have some familiarity with ""serious"" mathematics, i.e., they are decently fast paced and rigorous, and the content is deep enough. There are already several posts here about video lectures on complex analysis, but I don't know which one will be approapriate for me. For the background, I have studied mathematical analysis from the first seven chapters of Rudin's text. I hope the videos will be at the level of, say, Conway's book (or anything like that). I will clarify any vague points in the above description, just leave a comment. Thanks in advance!","I would like to find a complete series of video lectures on complex analysis, preferably with the following conditions: The videos are in English and clearly recorded. (Using English as a second language, I find it hard to understand spoken English when the sound is not clear.) The videos constitute a complete course and they are intended for students in mathematics who already have some familiarity with ""serious"" mathematics, i.e., they are decently fast paced and rigorous, and the content is deep enough. There are already several posts here about video lectures on complex analysis, but I don't know which one will be approapriate for me. For the background, I have studied mathematical analysis from the first seven chapters of Rudin's text. I hope the videos will be at the level of, say, Conway's book (or anything like that). I will clarify any vague points in the above description, just leave a comment. Thanks in advance!",,"['complex-analysis', 'reference-request', 'soft-question', 'online-resources']"
76,Using Residue Theorem to evaluate Trigonometric Integral $I=\frac{1}{\pi}\int_0^\pi\frac{F(x)}{a^2+b^2(\cos x-\cos y)^2}dx$,Using Residue Theorem to evaluate Trigonometric Integral,I=\frac{1}{\pi}\int_0^\pi\frac{F(x)}{a^2+b^2(\cos x-\cos y)^2}dx,"I'm trying to evaluate the following integral: $$I=\frac{1}{\pi}\int_0^\pi\frac{F(x)}{a^2+b^2(\cos x-\cos y)^2}dx ,\quad 0<y<\pi,$$ in the regime $a\ll b$, using Residue Theorem. I'm assuming that $F(x)$ is a well-behaved function with no singularities in the interval $[0,2\pi]$. I've tried the standard approach by defining $z=e^{ix}$ and $z_0=e^{iy}$ to convert the integral into the form $$I=-\frac{2i}{\pi}\oint_{|z|=1}\frac{z_0^2\,z\,F[-i \log (z)]}{4 a^2 \,z_0^2\,z^2+b^2 (z_0-z)^2 (z_0\,z-1)^2}dz.$$ In the regime considered, the first term in the denominator of the above expression can be neglected. The poles will be then $z=z_0$ and $z=\frac{1}{z_0}$, both of them with multiplicity 2. And here's my problem: both singularities relies on the unity circle $|z|=1.$ How can I proceed from here or what should be the best approach to deal with this integral? I was expecting to be able to find an answer that depends on $F(y)$ or $F^\prime(y)$. But that's only a guess. This is my very first question in stackexchange. I hope I had followed all the instructions properly.","I'm trying to evaluate the following integral: $$I=\frac{1}{\pi}\int_0^\pi\frac{F(x)}{a^2+b^2(\cos x-\cos y)^2}dx ,\quad 0<y<\pi,$$ in the regime $a\ll b$, using Residue Theorem. I'm assuming that $F(x)$ is a well-behaved function with no singularities in the interval $[0,2\pi]$. I've tried the standard approach by defining $z=e^{ix}$ and $z_0=e^{iy}$ to convert the integral into the form $$I=-\frac{2i}{\pi}\oint_{|z|=1}\frac{z_0^2\,z\,F[-i \log (z)]}{4 a^2 \,z_0^2\,z^2+b^2 (z_0-z)^2 (z_0\,z-1)^2}dz.$$ In the regime considered, the first term in the denominator of the above expression can be neglected. The poles will be then $z=z_0$ and $z=\frac{1}{z_0}$, both of them with multiplicity 2. And here's my problem: both singularities relies on the unity circle $|z|=1.$ How can I proceed from here or what should be the best approach to deal with this integral? I was expecting to be able to find an answer that depends on $F(y)$ or $F^\prime(y)$. But that's only a guess. This is my very first question in stackexchange. I hope I had followed all the instructions properly.",,"['complex-analysis', 'residue-calculus', 'trigonometric-integrals']"
77,Show that $f$ is univalent if in unit disk $|f'(z) - f'(0)|< |f'(0)|$.,Show that  is univalent if in unit disk .,f |f'(z) - f'(0)|< |f'(0)|,"Let $D = ${$z \in \mathbb{C}: |z|\leq 1$}, $f$ analytic on $D$ such that   $|f'(z) - f'(0)|< |f'(0)|$ for all $z\in D$. Show that for any $a \neq b$, $f(a) \neq f(b)$. I really need some hint or insight on how to start the proof. In all my attempt, I could not find a way to make use of the inequality given, thus I know I'm on the wrong track. Any help or insights is deeply appreciated. Edit: So turns out I have a solution, so do help to verify: Suppose not, that is $a\neq b$ but $f(a) = f(b)$ consider $L$ to be the line segment from $a$ to $b$. $|\int_L f'(z) - f'(0)dz| <|b-a||f'(0)|$ by M-L inequality and the conditions given. This means $|f(b) - f(a) -(b-a)f'(0)|<|b-a||f'(0)|$ but since we assume $f(b) = f(a)$ $|b-a||f'(0)| <|b-a||f'(0)|$ contradiction.","Let $D = ${$z \in \mathbb{C}: |z|\leq 1$}, $f$ analytic on $D$ such that   $|f'(z) - f'(0)|< |f'(0)|$ for all $z\in D$. Show that for any $a \neq b$, $f(a) \neq f(b)$. I really need some hint or insight on how to start the proof. In all my attempt, I could not find a way to make use of the inequality given, thus I know I'm on the wrong track. Any help or insights is deeply appreciated. Edit: So turns out I have a solution, so do help to verify: Suppose not, that is $a\neq b$ but $f(a) = f(b)$ consider $L$ to be the line segment from $a$ to $b$. $|\int_L f'(z) - f'(0)dz| <|b-a||f'(0)|$ by M-L inequality and the conditions given. This means $|f(b) - f(a) -(b-a)f'(0)|<|b-a||f'(0)|$ but since we assume $f(b) = f(a)$ $|b-a||f'(0)| <|b-a||f'(0)|$ contradiction.",,"['complex-analysis', 'proof-verification']"
78,Divisor Function Analytic Continuation,Divisor Function Analytic Continuation,,"I'm trying to define the divisor function $d(k)$ over a larger domain than the integers but the result I produce appears to converge nowhere, including the integer points i originally expected it to Here is my process: Consider: $$G(x) =  \sum_{k=1}^{\infty} \left[ \frac{1}{1-x^k} - 1 \right] = \sum_{i=1}^{\infty} d(i)x^i $$ Observe therefore that  $$ d(w) =\frac{1}{ \Gamma(w+1)}\frac{d^{(w)}G}{dx^{(w)}}[0]$$ Note: $$\frac{1}{1-x^k} = \frac{1}{k}\sum_{j=0}^{k-1} \frac{1}{1-e^{2i\pi(\frac{j}{k})}x}$$ $$ d(w) = \frac{1}{\Gamma(w+1)}\frac{d^{(w)}G}{dx^{(w)}} = \frac{1}{\Gamma(w+1)}\sum_{k=1}^{\infty} \left[ \frac{d^{(w)}}{dx^{(w)}} \left[ \frac{1}{k} \sum_{j=0}^{k-1} \frac{1}{1-e^{2i\pi(\frac{j}{k})}x} - 1  \right]\right][0]$$ If we let $w \in \mathbb{N}$ then this simplifies to $$ d(w) = \frac{1}{\Gamma(w+1)}\sum_{k=1}^{\infty} \left[ \frac{d^{(w)}}{dx^{(w)}} \left[ \frac{1}{k} \sum_{j=0}^{k-1} \frac{1}{1-e^{2i\pi(\frac{j}{k})}x}  \right]\right][0]= $$ $$\frac{1}{\Gamma(w+1)}\sum_{k=1}^{\infty} \left[  \frac{1}{k} \sum_{j=0}^{k-1} \frac{(-1)^w \Gamma(w+1)e^{2i\pi w(\frac{j}{k})}}{(1-e^{2i\pi(\frac{j}{k})}x)^w}  \right][0]$$ Cancelling out the gamma terms we have $$ d(w)= \sum_{k=1}^{\infty} \left[  \frac{1}{k} \sum_{j=0}^{k-1} \frac{(-1)^w e^{2i\pi w (\frac{j}{k})}}{(1-e^{2i\pi(\frac{j}{k})}x)^w}  \right][0]$$ Now setting $x=0$ yields $$ d(w) = \sum_{k=1}^{\infty} \left[  \frac{1}{k} \sum_{j=0}^{k-1} (-1)^w e^{2i\pi w (\frac{j}{k})} \right]$$ Factoring out common terms: $$ d(w) = \sum_{k=1}^{\infty} \left[ \frac{(-1)^w}{k} \sum_{j=0}^{k-1}   e^{2i\pi w (\frac{j}{k})} \right]$$ Applying Geometric Series formula: $$ d(w) = \sum_{k=1}^{\infty} \left[ \frac{(-1)^w}{k} \frac{1 - e^{2 i \pi w}}{1 - e^{\frac{2 wi\pi}{k}}} \right]$$ Which factors out nicely now as $$ d(w) = (-1)^w (1 - e^{2 wi \pi}) \sum_{k=1}^{\infty} \left[   \frac{1}{k- ke^{\frac{2 wi\pi}{k}}} \right]$$ But it's unclear that this is well defined as the denominator seems to tend to 0 as k tends to infinity qualitatively. Perhaps evaluating this as some type of limit is necessary","I'm trying to define the divisor function $d(k)$ over a larger domain than the integers but the result I produce appears to converge nowhere, including the integer points i originally expected it to Here is my process: Consider: $$G(x) =  \sum_{k=1}^{\infty} \left[ \frac{1}{1-x^k} - 1 \right] = \sum_{i=1}^{\infty} d(i)x^i $$ Observe therefore that  $$ d(w) =\frac{1}{ \Gamma(w+1)}\frac{d^{(w)}G}{dx^{(w)}}[0]$$ Note: $$\frac{1}{1-x^k} = \frac{1}{k}\sum_{j=0}^{k-1} \frac{1}{1-e^{2i\pi(\frac{j}{k})}x}$$ $$ d(w) = \frac{1}{\Gamma(w+1)}\frac{d^{(w)}G}{dx^{(w)}} = \frac{1}{\Gamma(w+1)}\sum_{k=1}^{\infty} \left[ \frac{d^{(w)}}{dx^{(w)}} \left[ \frac{1}{k} \sum_{j=0}^{k-1} \frac{1}{1-e^{2i\pi(\frac{j}{k})}x} - 1  \right]\right][0]$$ If we let $w \in \mathbb{N}$ then this simplifies to $$ d(w) = \frac{1}{\Gamma(w+1)}\sum_{k=1}^{\infty} \left[ \frac{d^{(w)}}{dx^{(w)}} \left[ \frac{1}{k} \sum_{j=0}^{k-1} \frac{1}{1-e^{2i\pi(\frac{j}{k})}x}  \right]\right][0]= $$ $$\frac{1}{\Gamma(w+1)}\sum_{k=1}^{\infty} \left[  \frac{1}{k} \sum_{j=0}^{k-1} \frac{(-1)^w \Gamma(w+1)e^{2i\pi w(\frac{j}{k})}}{(1-e^{2i\pi(\frac{j}{k})}x)^w}  \right][0]$$ Cancelling out the gamma terms we have $$ d(w)= \sum_{k=1}^{\infty} \left[  \frac{1}{k} \sum_{j=0}^{k-1} \frac{(-1)^w e^{2i\pi w (\frac{j}{k})}}{(1-e^{2i\pi(\frac{j}{k})}x)^w}  \right][0]$$ Now setting $x=0$ yields $$ d(w) = \sum_{k=1}^{\infty} \left[  \frac{1}{k} \sum_{j=0}^{k-1} (-1)^w e^{2i\pi w (\frac{j}{k})} \right]$$ Factoring out common terms: $$ d(w) = \sum_{k=1}^{\infty} \left[ \frac{(-1)^w}{k} \sum_{j=0}^{k-1}   e^{2i\pi w (\frac{j}{k})} \right]$$ Applying Geometric Series formula: $$ d(w) = \sum_{k=1}^{\infty} \left[ \frac{(-1)^w}{k} \frac{1 - e^{2 i \pi w}}{1 - e^{\frac{2 wi\pi}{k}}} \right]$$ Which factors out nicely now as $$ d(w) = (-1)^w (1 - e^{2 wi \pi}) \sum_{k=1}^{\infty} \left[   \frac{1}{k- ke^{\frac{2 wi\pi}{k}}} \right]$$ But it's unclear that this is well defined as the denominator seems to tend to 0 as k tends to infinity qualitatively. Perhaps evaluating this as some type of limit is necessary",,"['complex-analysis', 'number-theory', 'divisor-counting-function']"
79,Geometric meaning of complex integration,Geometric meaning of complex integration,,"In multivariable real calculus, if we want to calculate $\iint  (x^2 + y^2) dx dy $ over a region R, this is a number that represents the volume under the surface given by $ (x^2 + y^2) $ and the xy- plane only above the region R. So, the geometric meaning of this operation is a volume. If we wanna evalaute the intregral of a function $ f: \Bbb C \to \Bbb R $, over a path, for example, $f: \Bbb C\to \Bbb R$ with $ f(z) = Re(z^2) $ along a path I believe that, along that path, one is taking some alture and visualizing this we are making that operation to take the area between the path $\gamma $ in $\Bbb C$ and the ""image path"" of $\gamma$ in the ""alture coordinate"". But if we have that $f(z) = z^2$ and we integrate alonge the same $\gamma$ path, what kind of geometric element is that? And, what if we integrate the same function $f(z) = z^2$ but along the $\gamma $ path, indeed, what if we integrate $f(z) = z^2$ for example over all the closed unit circle region? What kind of geometric element is this?","In multivariable real calculus, if we want to calculate $\iint  (x^2 + y^2) dx dy $ over a region R, this is a number that represents the volume under the surface given by $ (x^2 + y^2) $ and the xy- plane only above the region R. So, the geometric meaning of this operation is a volume. If we wanna evalaute the intregral of a function $ f: \Bbb C \to \Bbb R $, over a path, for example, $f: \Bbb C\to \Bbb R$ with $ f(z) = Re(z^2) $ along a path I believe that, along that path, one is taking some alture and visualizing this we are making that operation to take the area between the path $\gamma $ in $\Bbb C$ and the ""image path"" of $\gamma$ in the ""alture coordinate"". But if we have that $f(z) = z^2$ and we integrate alonge the same $\gamma$ path, what kind of geometric element is that? And, what if we integrate the same function $f(z) = z^2$ but along the $\gamma $ path, indeed, what if we integrate $f(z) = z^2$ for example over all the closed unit circle region? What kind of geometric element is this?",,"['complex-analysis', 'complex-integration', 'geometric-construction']"
80,Compact Support of Fourier-like Differential Form $\sigma(\xi)$,Compact Support of Fourier-like Differential Form,\sigma(\xi),"Let $f\in$$L^1(\mathbb{R})$ and $g(y)=\int_{\mathbb{R}}f(x)e^{-iyx}dx.$ Then if $f$ has compact support, $g=\hat f(y)$ can not have compact support unless $f \equiv0$. Similarly, let $\Omega_c^{1}(X)$ denote the space of continuous one-forms with compact support on a Riemann surface $X.$ Is there a generalization of the above theorem for differential forms, whereby if $\omega\in\Omega_c^{1}(X)$ has compact support, and $$\sigma(\xi)=\int_{\partial X}e^{-i\xi z}\omega$$ for $\omega=f(z)dz,$ then $\sigma(\xi)=\hat \omega(\xi)$ can not (necessarily) have compact support unless $\omega\equiv0?$ Proposition/Attempted Proof: Let $\pi$ be a diffeomorphism $\pi:\mathbb{R} \to X,$ such that $$\sigma(\xi)=\int_{\partial X}e^{-i\xi z}f(z)dz\equiv\int_{\pi(\mathbb{R})}e^{-i\xi \pi(x)}f(\pi(x))\pi^{\prime}(x)dx,$$ where $\pi(x)=z,\pi(y)=\xi.$ Similarly, let $t=Re(\pi)(x)=\frac{\pi+\bar \pi}{2}$  be a change of variables, then $$\sigma(\xi)=\int_{\mathbb{R}}e^{-i\xi t}f(t)\frac{dt}{dx}dx=\int_{\mathbb{R}}e^{-i\xi t}f(t)dt,$$ where $\pi(\mathbb{R})$ is transformed into $\mathbb{R}$ under $t=Re(\pi)(x).$ This reduces the above case into the less general $g(y)=\int_{\mathbb{R}}f(x)e^{-iyx}dx.$ However, there seems to be a logical fallacy in this proof. Thanks in advance.","Let $f\in$$L^1(\mathbb{R})$ and $g(y)=\int_{\mathbb{R}}f(x)e^{-iyx}dx.$ Then if $f$ has compact support, $g=\hat f(y)$ can not have compact support unless $f \equiv0$. Similarly, let $\Omega_c^{1}(X)$ denote the space of continuous one-forms with compact support on a Riemann surface $X.$ Is there a generalization of the above theorem for differential forms, whereby if $\omega\in\Omega_c^{1}(X)$ has compact support, and $$\sigma(\xi)=\int_{\partial X}e^{-i\xi z}\omega$$ for $\omega=f(z)dz,$ then $\sigma(\xi)=\hat \omega(\xi)$ can not (necessarily) have compact support unless $\omega\equiv0?$ Proposition/Attempted Proof: Let $\pi$ be a diffeomorphism $\pi:\mathbb{R} \to X,$ such that $$\sigma(\xi)=\int_{\partial X}e^{-i\xi z}f(z)dz\equiv\int_{\pi(\mathbb{R})}e^{-i\xi \pi(x)}f(\pi(x))\pi^{\prime}(x)dx,$$ where $\pi(x)=z,\pi(y)=\xi.$ Similarly, let $t=Re(\pi)(x)=\frac{\pi+\bar \pi}{2}$  be a change of variables, then $$\sigma(\xi)=\int_{\mathbb{R}}e^{-i\xi t}f(t)\frac{dt}{dx}dx=\int_{\mathbb{R}}e^{-i\xi t}f(t)dt,$$ where $\pi(\mathbb{R})$ is transformed into $\mathbb{R}$ under $t=Re(\pi)(x).$ This reduces the above case into the less general $g(y)=\int_{\mathbb{R}}f(x)e^{-iyx}dx.$ However, there seems to be a logical fallacy in this proof. Thanks in advance.",,"['real-analysis', 'complex-analysis', 'fourier-analysis', 'differential-forms', 'complex-geometry']"
81,Does the Riemann map change smoothly with respect to smooth change of underlying domain?,Does the Riemann map change smoothly with respect to smooth change of underlying domain?,,"Let $\gamma:S^{1} \times [0,1] \to \mathbb{C}$ be in $C^1$ and suppose that $\gamma(.,t)$ is a Jordan curve for all $t\in [0,1]$. Call the domain bounded by $\gamma(.,t)$ as $\Omega(t)$. Assume that for all $t\in [0,1]$, $0 \in \Omega(t)$ and that there exists a $\delta>0$ such that $d(0,\partial \Omega(t) )\geq \delta$. For each fixed $t\in [0,1]$ consider the unique Riemann map $\Phi(.,t):\mathbb{D} \to \Omega(t)$ such that $\Phi (0,t) =0 $ and $\Phi_{z}(0,t) >0$. As $\partial \Omega(t)$ is a Jordan curve we know that $\Phi(,.t)$ extends continuously to $\mathbb{D}$ by Caratheodary's theorem. Question: Is $\Phi(z,t)$ differentiable in $t$? And if that is the case, is it true that for each fixed $t$, $\Phi_{t}(z,t)$ extends continuously to $\mathbb{D}$? I know that $\Phi(z,t)$ is continuous in $t$ by a theorem of Rado (Proof given in the book by Pommerenke: Boundary behaviour of Conformal maps). It seems that there is an unpublished paper (Lavrentiev curves and conformal mapping) by Coifman and Meyer on this problem where they show that the Riemann map depends analytically on the curve. However first of all I cannot find the paper anywhere and even with it I don't know how it solves the above question as the analytic dependence is with respect to the BMO norm associated with the chord arc curve (The problem is that all constants are killed by the BMO norm which corresponds to a rotation. So a lot of domains correspond to the same BMO function and hence you lose information. Also all possible Riemann maps from $\Omega$ to the upper half plane get assigned the same BMO function ) I would be very grateful if someone can answer this or give me a reference for it.","Let $\gamma:S^{1} \times [0,1] \to \mathbb{C}$ be in $C^1$ and suppose that $\gamma(.,t)$ is a Jordan curve for all $t\in [0,1]$. Call the domain bounded by $\gamma(.,t)$ as $\Omega(t)$. Assume that for all $t\in [0,1]$, $0 \in \Omega(t)$ and that there exists a $\delta>0$ such that $d(0,\partial \Omega(t) )\geq \delta$. For each fixed $t\in [0,1]$ consider the unique Riemann map $\Phi(.,t):\mathbb{D} \to \Omega(t)$ such that $\Phi (0,t) =0 $ and $\Phi_{z}(0,t) >0$. As $\partial \Omega(t)$ is a Jordan curve we know that $\Phi(,.t)$ extends continuously to $\mathbb{D}$ by Caratheodary's theorem. Question: Is $\Phi(z,t)$ differentiable in $t$? And if that is the case, is it true that for each fixed $t$, $\Phi_{t}(z,t)$ extends continuously to $\mathbb{D}$? I know that $\Phi(z,t)$ is continuous in $t$ by a theorem of Rado (Proof given in the book by Pommerenke: Boundary behaviour of Conformal maps). It seems that there is an unpublished paper (Lavrentiev curves and conformal mapping) by Coifman and Meyer on this problem where they show that the Riemann map depends analytically on the curve. However first of all I cannot find the paper anywhere and even with it I don't know how it solves the above question as the analytic dependence is with respect to the BMO norm associated with the chord arc curve (The problem is that all constants are killed by the BMO norm which corresponds to a rotation. So a lot of domains correspond to the same BMO function and hence you lose information. Also all possible Riemann maps from $\Omega$ to the upper half plane get assigned the same BMO function ) I would be very grateful if someone can answer this or give me a reference for it.",,"['complex-analysis', 'analysis', 'reference-request', 'harmonic-analysis']"
82,showing $-\eta(s) = \lim_{z \ \to \ -1} \sum_{n=1}^\infty z^{n} n^{-s}$,showing,-\eta(s) = \lim_{z \ \to \ -1} \sum_{n=1}^\infty z^{n} n^{-s},"For $Re(s) > 0$,  the Dirichlet eta function has the series representation $\eta(s) = \sum_{n=1}^\infty (-1)^{n+1} n^{-s}$. It extends analytically to the whole complex plane, and we have the following representation : $$\boxed{\forall s \in \mathbb{C}, \qquad -\eta(s) = \lim_{z \ \to \ -1, |z| < 1} \sum_{n=1}^\infty z^{n} n^{-s}}$$ Question : do you know other proofs, preferably more general ? Let $\displaystyle f(s,z ) = \sum_{n=1}^\infty z^{n} n^{-s} $ (the Polylogarithm ). Note it is analytic in $s$ and $z$ for $|z| < 1$. On $|z| = 1$, define $f(s,z) = \lim_{r \to 1^-}f(s,rz)$, we will prove it exists for $z \ne 1$ and that it stays analytic in $s$. Summing by parts, for $Re(s) > 1, |z| \le 1$ : $$f(s,z) =  \sum_{n=1}^\infty \frac{z^{n+1}-z}{z-1} (n^{-s}-(n+1)^{-s})= \frac{-z}{z-1} + \frac{z}{z-1}\sum_{n=1}^\infty z^n (n^{-s}-(n+1)^{-s})$$ using $n^{-s}-(n+1)^{-s} = s \int_n^{n+1} x^{-s-1}dx \sim s n^{-s-1}$ as $n \to \infty$, we get that $z\sum_{n=1}^\infty z^n (n^{-s}-(n+1)^{-s})$ is a representation of $(z-1)(f(s,z)+z)$ valid for $Re(s) > 0, |z| \le 1$. Then apply the same argument inductively : letting $a_n^0(s) = n^{-s}$, $a_n^{k+1}(s) = a_n^k(s)-a_{n+1}^k(s)$, $\ a_n^k(s) \sim s^k n^{-s-k}$ as $n \to \infty$. Define $$h_0(s,z) = f(s,z),\qquad h_{k+1}(s,z) = (z-1)(h_k(s,z)+z \, a_1^k(s))$$ so that $z^{k+1}\sum_{n=1}^\infty z^{n} (a_n^k(s)- a_{n+1}^k(s))$ is a representation of $h_{k+1}(s,z)$ valid for $Re(s) > -k, |z| \le 1$. Note that for all $m \ge 0$ : $$\frac{d^m}{d s^m} a_n^k(s) \sim \frac{d^m}{d s^m} s^k n^{-s-k} \qquad \text{as }n \to \infty$$ so that $ z^k\sum_{n=1}^\infty z^{n}\frac{d^m}{d s^m} a_n^k(s)$ is also a valid representation of $\frac{d^m}{d s^m} h_{k}(s,z)$, proving the analyticity for $Re(s) > 1-k, |z| \le 1$. Hence, defining $\tilde{h}_0(s) = -\eta(s),\ \tilde{h}_{k+1}(s) = 2 (\tilde{h}_{k}(s)- a_1^k(s))$ we get, for $Re(s) > 1-k$ : $$h_{k}(s,-1) = \tilde{h}_k(s)$$ And since $h_k(s,z)$ is clearly continuous in $z$ for $|z| \le 1, Re(s) > 1-k$ : $\tilde{h}_k(s) = \lim_{z \,\to\,  -1}h_{k}(s,z)$. Being true for every $k$, it means that  $$\forall s \in \mathbb{C}, \qquad\lim_{z \,\to\, -1} f(s,z) = -\eta(s)$$ Also, it should prove $f(s,e^{2i \pi x})$ is entire in $s$ whenever $x \in \mathbb{R}\setminus\mathbb{Z}$. Any ideas or references are welcome : extending $f(s,z)$ analytically beyond $|z| \le 1$, a functional equation for $f(s,z)$..","For $Re(s) > 0$,  the Dirichlet eta function has the series representation $\eta(s) = \sum_{n=1}^\infty (-1)^{n+1} n^{-s}$. It extends analytically to the whole complex plane, and we have the following representation : $$\boxed{\forall s \in \mathbb{C}, \qquad -\eta(s) = \lim_{z \ \to \ -1, |z| < 1} \sum_{n=1}^\infty z^{n} n^{-s}}$$ Question : do you know other proofs, preferably more general ? Let $\displaystyle f(s,z ) = \sum_{n=1}^\infty z^{n} n^{-s} $ (the Polylogarithm ). Note it is analytic in $s$ and $z$ for $|z| < 1$. On $|z| = 1$, define $f(s,z) = \lim_{r \to 1^-}f(s,rz)$, we will prove it exists for $z \ne 1$ and that it stays analytic in $s$. Summing by parts, for $Re(s) > 1, |z| \le 1$ : $$f(s,z) =  \sum_{n=1}^\infty \frac{z^{n+1}-z}{z-1} (n^{-s}-(n+1)^{-s})= \frac{-z}{z-1} + \frac{z}{z-1}\sum_{n=1}^\infty z^n (n^{-s}-(n+1)^{-s})$$ using $n^{-s}-(n+1)^{-s} = s \int_n^{n+1} x^{-s-1}dx \sim s n^{-s-1}$ as $n \to \infty$, we get that $z\sum_{n=1}^\infty z^n (n^{-s}-(n+1)^{-s})$ is a representation of $(z-1)(f(s,z)+z)$ valid for $Re(s) > 0, |z| \le 1$. Then apply the same argument inductively : letting $a_n^0(s) = n^{-s}$, $a_n^{k+1}(s) = a_n^k(s)-a_{n+1}^k(s)$, $\ a_n^k(s) \sim s^k n^{-s-k}$ as $n \to \infty$. Define $$h_0(s,z) = f(s,z),\qquad h_{k+1}(s,z) = (z-1)(h_k(s,z)+z \, a_1^k(s))$$ so that $z^{k+1}\sum_{n=1}^\infty z^{n} (a_n^k(s)- a_{n+1}^k(s))$ is a representation of $h_{k+1}(s,z)$ valid for $Re(s) > -k, |z| \le 1$. Note that for all $m \ge 0$ : $$\frac{d^m}{d s^m} a_n^k(s) \sim \frac{d^m}{d s^m} s^k n^{-s-k} \qquad \text{as }n \to \infty$$ so that $ z^k\sum_{n=1}^\infty z^{n}\frac{d^m}{d s^m} a_n^k(s)$ is also a valid representation of $\frac{d^m}{d s^m} h_{k}(s,z)$, proving the analyticity for $Re(s) > 1-k, |z| \le 1$. Hence, defining $\tilde{h}_0(s) = -\eta(s),\ \tilde{h}_{k+1}(s) = 2 (\tilde{h}_{k}(s)- a_1^k(s))$ we get, for $Re(s) > 1-k$ : $$h_{k}(s,-1) = \tilde{h}_k(s)$$ And since $h_k(s,z)$ is clearly continuous in $z$ for $|z| \le 1, Re(s) > 1-k$ : $\tilde{h}_k(s) = \lim_{z \,\to\,  -1}h_{k}(s,z)$. Being true for every $k$, it means that  $$\forall s \in \mathbb{C}, \qquad\lim_{z \,\to\, -1} f(s,z) = -\eta(s)$$ Also, it should prove $f(s,e^{2i \pi x})$ is entire in $s$ whenever $x \in \mathbb{R}\setminus\mathbb{Z}$. Any ideas or references are welcome : extending $f(s,z)$ analytically beyond $|z| \le 1$, a functional equation for $f(s,z)$..",,"['complex-analysis', 'reference-request', 'riemann-zeta']"
83,Laurent expansion of $\frac{1}{\sin z}$,Laurent expansion of,\frac{1}{\sin z},"Question is a fully solved exercise in Gamelin's complex analysis. Exercise : Consider the Laurent series expansion for $\frac{1}{\sin z}$ that converges on the circle $\{|z|=4\}$. Find the coefficients $a_0,a_{-1},a_{-2},a_{-3}$. Determine the largest open set on which the series converges. Solution :  The only zeros of $\sin z$ are at the integral multiples of $\pi$. These are then the only singularities of $\frac{1}{\sin z}$, and they are all simple poles. The largest open annular set containing the cirlce and to which $\frac{1}{\sin z}$ extends analytically is then the annulus $\{\pi <|z|<2\pi\}$. The annulus is then the largest open set on which the Laurent series converges. We have expansions  $$\sin z =z-\cdots \rm{near~~}z=0$$   $$\sin z =-(z-\pi)-\cdots \rm{near~~}z=\pi$$   $$\sin z =-(z+\pi)-\cdots \rm{near~~}z=-\pi$$ Just by considering inverses, long divisions, we see that $$\frac{1}{\sin z} =\frac{1}{z}+\rm{analytic}$$   $$\frac{1}{\sin z}=-\frac{1}{z-\pi}+\rm{analytic}$$   $$\frac{1}{\sin z} =-\frac{1}{z+\pi}+\rm{analytic}$$ We conclude that if $$f_1(z)=\frac{1}{z}-\frac{1}{z-\pi}-\frac{1}{z+\pi}$$ then $f_0(z)=1/\sin z-f_1(z)$ is analytic for $|z|>2\pi$. Thus, $$\frac{1}{\sin z}=f_0(z)+f_1(z)$$ is the Laurent decomposition of $1/\sin z$. I do not understand what ever is written in bold. I see that $f(z)$ is analytic for $|z|>\pi$.. could not figure out why $f_0(z)$ is analytic for $|z|<2\pi$.. We have $$f_3(z)=\frac{3}{\sin z}-f_1(z)=\left(\frac{1}{\sin z}-\frac{1}{z}\right)+\left(\frac{1}{\sin z}-\frac{1}{z-pi}\right)+\left(\frac{1}{\sin z}-\frac{1}{z+\pi}\right)$$ Each function in the brackets is analytic at $0,\pi,-\pi$ respectively.  does it imply sum is analytic?? That too in $|z|<2\pi$$?? $f_1(z)$ is just same as $f_3(z)$ except a constant.. so, if $f_3(z)$ is analytic then so would be $f_1(z)$.. Help me to fill the gaps..","Question is a fully solved exercise in Gamelin's complex analysis. Exercise : Consider the Laurent series expansion for $\frac{1}{\sin z}$ that converges on the circle $\{|z|=4\}$. Find the coefficients $a_0,a_{-1},a_{-2},a_{-3}$. Determine the largest open set on which the series converges. Solution :  The only zeros of $\sin z$ are at the integral multiples of $\pi$. These are then the only singularities of $\frac{1}{\sin z}$, and they are all simple poles. The largest open annular set containing the cirlce and to which $\frac{1}{\sin z}$ extends analytically is then the annulus $\{\pi <|z|<2\pi\}$. The annulus is then the largest open set on which the Laurent series converges. We have expansions  $$\sin z =z-\cdots \rm{near~~}z=0$$   $$\sin z =-(z-\pi)-\cdots \rm{near~~}z=\pi$$   $$\sin z =-(z+\pi)-\cdots \rm{near~~}z=-\pi$$ Just by considering inverses, long divisions, we see that $$\frac{1}{\sin z} =\frac{1}{z}+\rm{analytic}$$   $$\frac{1}{\sin z}=-\frac{1}{z-\pi}+\rm{analytic}$$   $$\frac{1}{\sin z} =-\frac{1}{z+\pi}+\rm{analytic}$$ We conclude that if $$f_1(z)=\frac{1}{z}-\frac{1}{z-\pi}-\frac{1}{z+\pi}$$ then $f_0(z)=1/\sin z-f_1(z)$ is analytic for $|z|>2\pi$. Thus, $$\frac{1}{\sin z}=f_0(z)+f_1(z)$$ is the Laurent decomposition of $1/\sin z$. I do not understand what ever is written in bold. I see that $f(z)$ is analytic for $|z|>\pi$.. could not figure out why $f_0(z)$ is analytic for $|z|<2\pi$.. We have $$f_3(z)=\frac{3}{\sin z}-f_1(z)=\left(\frac{1}{\sin z}-\frac{1}{z}\right)+\left(\frac{1}{\sin z}-\frac{1}{z-pi}\right)+\left(\frac{1}{\sin z}-\frac{1}{z+\pi}\right)$$ Each function in the brackets is analytic at $0,\pi,-\pi$ respectively.  does it imply sum is analytic?? That too in $|z|<2\pi$$?? $f_1(z)$ is just same as $f_3(z)$ except a constant.. so, if $f_3(z)$ is analytic then so would be $f_1(z)$.. Help me to fill the gaps..",,['complex-analysis']
84,Is there an analytic function $f$ in the open unit disc such that $|f(z)|=e^{|z|}$ therein?,Is there an analytic function  in the open unit disc such that  therein?,f |f(z)|=e^{|z|},Is there an analytic function $f$ in the open unit disc such that $|f(z)|=e^{|z|}$ therein? My try : Suppose such  a function exists .Then $|f(0)|=e^0=1$ Also $|f|\ge 0$. Now $e^{|z|}$ attains its minimum value i.e. $1$ at $0$. Thus $|f(z)|\ge 1$ I was trying to use the minimum modulus theorem which states that if $f$ is a non- constant analytic function such that $|f|$ attains  its minimum value in an interior point of the unit disc then $f$ is constant. Here $|f|$ attains its minimum value at $0$ which is an interior point  of the unit disc and thus  $f$ is constant which is false as $|f|=e^{|z|}$. Thus no such analytic function exists.,Is there an analytic function $f$ in the open unit disc such that $|f(z)|=e^{|z|}$ therein? My try : Suppose such  a function exists .Then $|f(0)|=e^0=1$ Also $|f|\ge 0$. Now $e^{|z|}$ attains its minimum value i.e. $1$ at $0$. Thus $|f(z)|\ge 1$ I was trying to use the minimum modulus theorem which states that if $f$ is a non- constant analytic function such that $|f|$ attains  its minimum value in an interior point of the unit disc then $f$ is constant. Here $|f|$ attains its minimum value at $0$ which is an interior point  of the unit disc and thus  $f$ is constant which is false as $|f|=e^{|z|}$. Thus no such analytic function exists.,,"['complex-analysis', 'analytic-functions']"
85,Prove this fact about holomorphic functions.,Prove this fact about holomorphic functions.,,"Suppose $f \colon \mathbb{D} → \mathbb{C}$ is holomorphic. Then I want to show that the diameter  $$d=\sup _{z, w∈\mathbb{D}} |f (z) − f (w)|$$ of the image of $f$ satisfies $2|f′(0)| ≤ d$ and that equality holds precisely when $f$ is linear, this is $f(z) = a_0 +a_1z$. Then I did the following: Using Cauchy's integral formula we get that, $$2|f′(0)|=\left|\frac{1}{2πi}∫_{|z|=r}\frac{f(z)−f(−z)}{z^2}\,dz\right|.$$ Then I parametrize the circle, so arrive at: $$\frac{1}{2πi}∫_{0}^{2 \pi}\frac{f(Re^{i \theta})−f(−Re^{i \theta})}{R^2e^{2i \theta}}iRe^{i \theta}\,d\theta.$$ So given that $R=1$ and that the length of the curve is $2 \pi$ we arrive to this inequality $$\left|\frac{1}{2πi}\int_{0}^{2 \pi}\frac{f(Re^{i \theta})−f(−Re^{i \theta})}{R^2e^{2i \theta}}iRe^{i \theta}\,d\theta\right|< \sup \left|f(e^{i \theta})−f(−e^{i \theta})\right|$$ and for the equality we see that if $f$ is linear then $2f'(0)=2a_0$ and $d=\sup|a_1(z-w)|=a_1$, but the thing there is no reason to have that $a_0=a_1.$ So Am I right in the first approach (or how can I fix it)? Also, how Can I get the equality? Thanks a lot in advance.","Suppose $f \colon \mathbb{D} → \mathbb{C}$ is holomorphic. Then I want to show that the diameter  $$d=\sup _{z, w∈\mathbb{D}} |f (z) − f (w)|$$ of the image of $f$ satisfies $2|f′(0)| ≤ d$ and that equality holds precisely when $f$ is linear, this is $f(z) = a_0 +a_1z$. Then I did the following: Using Cauchy's integral formula we get that, $$2|f′(0)|=\left|\frac{1}{2πi}∫_{|z|=r}\frac{f(z)−f(−z)}{z^2}\,dz\right|.$$ Then I parametrize the circle, so arrive at: $$\frac{1}{2πi}∫_{0}^{2 \pi}\frac{f(Re^{i \theta})−f(−Re^{i \theta})}{R^2e^{2i \theta}}iRe^{i \theta}\,d\theta.$$ So given that $R=1$ and that the length of the curve is $2 \pi$ we arrive to this inequality $$\left|\frac{1}{2πi}\int_{0}^{2 \pi}\frac{f(Re^{i \theta})−f(−Re^{i \theta})}{R^2e^{2i \theta}}iRe^{i \theta}\,d\theta\right|< \sup \left|f(e^{i \theta})−f(−e^{i \theta})\right|$$ and for the equality we see that if $f$ is linear then $2f'(0)=2a_0$ and $d=\sup|a_1(z-w)|=a_1$, but the thing there is no reason to have that $a_0=a_1.$ So Am I right in the first approach (or how can I fix it)? Also, how Can I get the equality? Thanks a lot in advance.",,['complex-analysis']
86,Understanding Complex Differentials (forms),Understanding Complex Differentials (forms),,"In the study of Riemann surfaces, many books bring in their discussions, the complex differentials or differential forms , and there my understanding gets stopped. I personally interacted with many people to understand the meaning of complex differentials or complex differentials form, but no one explained in intuitive or motivational way what that means . I tried to follow some books like - Calculus on manifolds- Spivak, Principles of Mathematical Analysis - Rudin, Analysis on Manifolds - Munkres, or even some specifically written books on differential forms like differential forms - Weintraub Everyone tried to explain it through algebraic meanings, but that is too abstract; I can not see its relations with analysis quickly. Question: Can one give an intuitive explanation of complex differential forms? What should we keep in mind when we came across it in some study? I would mostly welcome explanation through examples as well.","In the study of Riemann surfaces, many books bring in their discussions, the complex differentials or differential forms , and there my understanding gets stopped. I personally interacted with many people to understand the meaning of complex differentials or complex differentials form, but no one explained in intuitive or motivational way what that means . I tried to follow some books like - Calculus on manifolds- Spivak, Principles of Mathematical Analysis - Rudin, Analysis on Manifolds - Munkres, or even some specifically written books on differential forms like differential forms - Weintraub Everyone tried to explain it through algebraic meanings, but that is too abstract; I can not see its relations with analysis quickly. Question: Can one give an intuitive explanation of complex differential forms? What should we keep in mind when we came across it in some study? I would mostly welcome explanation through examples as well.",,"['complex-analysis', 'differential-geometry', 'complex-geometry', 'riemann-surfaces']"
87,Entire function assume real values for $z=x^2+ix$,Entire function assume real values for,z=x^2+ix,Let $f$ be an entire function such that $f(z)$ is real for $z=x^2+ix$. Is there exists such a function which is not constant? Previously I thought that  $\displaystyle\int_{0}^{z}\left(\sqrt{t-1/4}-i\right) dt \ $ would work but I realized that this function isn't continous so I cannot guarantee that this integral is entire.,Let $f$ be an entire function such that $f(z)$ is real for $z=x^2+ix$. Is there exists such a function which is not constant? Previously I thought that  $\displaystyle\int_{0}^{z}\left(\sqrt{t-1/4}-i\right) dt \ $ would work but I realized that this function isn't continous so I cannot guarantee that this integral is entire.,,"['complex-analysis', 'conic-sections']"
88,Radial limits of composition of functions,Radial limits of composition of functions,,"Is it true that if $f\in H(U)$ is a holomorphic function whose nontangential limits exist a.e and $g\in H^\infty(U)$ is a nonconstant holomorphic function whose range is in $U$ and whose radial limits exist everywhere, then the radial limits of $f\circ g$ exist a.e? I have been trying to show that g approaches its radial limits from nontangential regions, but I haven't been able to prove anything.","Is it true that if $f\in H(U)$ is a holomorphic function whose nontangential limits exist a.e and $g\in H^\infty(U)$ is a nonconstant holomorphic function whose range is in $U$ and whose radial limits exist everywhere, then the radial limits of $f\circ g$ exist a.e? I have been trying to show that g approaches its radial limits from nontangential regions, but I haven't been able to prove anything.",,['complex-analysis']
89,Prove there is no branch of arg $z$ on $0 < z < 1$.,Prove there is no branch of arg  on .,z 0 < z < 1,"If $G$ is an open connected subset of $\mathbb{C}$ that does not contain the origin, we call a continuous function $\alpha$ satisfying $\alpha(z) = \text{arg} z$ for all $z \in G$ a branch of arg $z$. Prove there is no branch of arg z (and consequently no continuous complex logarithm) in the region $D^* =0 < |z| < 1$. Attempt at a proof: Assume there is a branch of arg $z$, i.e., there exists $\alpha : D^* \to [a,b] \subset \mathbb{R}$ such that $\alpha(z) = \text{arg} z$. Consider the path $\gamma : [0,1] \to D^*$ defined by $\gamma(t) = \frac{1}{2} e^{2 \pi i t}$. Then, clearly $\gamma(0) = \gamma(1)$. Moreover, the function $t \mapsto \alpha(\gamma(t)) = \text{arg}(\gamma(t))$ is a strictly increasing function. Hence, $\alpha(\gamma(0)) < \alpha(\gamma(1))$ contradicting the fact that $\gamma(0) = \gamma(1)$. My concern with the outlined proof is that I don't know how to actually show that $t \mapsto \alpha(\gamma(t))$ is a strictly increasing function... other than the fact that intuitively this is so. Is it sufficient to say that arg($e^z$) = Im($z$)? Thanks! Alternative proof styles are also welcome!","If $G$ is an open connected subset of $\mathbb{C}$ that does not contain the origin, we call a continuous function $\alpha$ satisfying $\alpha(z) = \text{arg} z$ for all $z \in G$ a branch of arg $z$. Prove there is no branch of arg z (and consequently no continuous complex logarithm) in the region $D^* =0 < |z| < 1$. Attempt at a proof: Assume there is a branch of arg $z$, i.e., there exists $\alpha : D^* \to [a,b] \subset \mathbb{R}$ such that $\alpha(z) = \text{arg} z$. Consider the path $\gamma : [0,1] \to D^*$ defined by $\gamma(t) = \frac{1}{2} e^{2 \pi i t}$. Then, clearly $\gamma(0) = \gamma(1)$. Moreover, the function $t \mapsto \alpha(\gamma(t)) = \text{arg}(\gamma(t))$ is a strictly increasing function. Hence, $\alpha(\gamma(0)) < \alpha(\gamma(1))$ contradicting the fact that $\gamma(0) = \gamma(1)$. My concern with the outlined proof is that I don't know how to actually show that $t \mapsto \alpha(\gamma(t))$ is a strictly increasing function... other than the fact that intuitively this is so. Is it sufficient to say that arg($e^z$) = Im($z$)? Thanks! Alternative proof styles are also welcome!",,['complex-analysis']
90,estimating a particular analytic function on a bounded sector.,estimating a particular analytic function on a bounded sector.,,"Let $f(z)$ be an analytic function on $C^+=\{\Re z>0\}$, and we have the following (weaker) estimates $$ |f(re^{i\theta},a)|\leq C (r\cos\theta)^{-n}, ~~~r>0,-\frac{\pi}{2}<\theta<\frac{\pi}{2}, $$ for some constant $C$ and $n>0$. Furthermore, on the positive real line, and for any fixed $a>0$, we have the following (stronger) estimates $$ |f(r,a)|\leq C \frac{r}{a^{n+1}},~~~0<r\leq a, $$ where $C$ is a constant independent with $a$. My question is can we also get the following improved estimates of $f$ $$ |f(re^{i\theta},a)|\leq C \frac{r}{a^{n+1}},~~~0<r< a,~~-\frac{\pi}{2}<\theta<\frac{\pi}{2}? $$ If not, can you give a counterexample to this? The motivation of this question comes from estimating the Poisson semigroup $e^{-z\sqrt{-\Delta}}$ for small $|z|$ With  $\Re z>0$.To be more precise, if we let $K(z,x,y)$ be its kernel, then $K$ satisfies the estimates above with $a=|x-y|$. Although we can compute the kernel explicitly (for all $\Re z>0$ ) by using Fourier transform ($K(z,x,y)=\frac{z}{(z^2+a^2)^{n+1}}$,a=|x-y|), I think one may also obtain this by combining the kernel estimates on the positive real line (the second estimate above) with a weaker estimates on the right half plane (the first estimate above) and some analytic function theory. I don't know theorems like Hadamard's Three line lemma or its variants  would be useful here. Thanks in advance for any comment.","Let $f(z)$ be an analytic function on $C^+=\{\Re z>0\}$, and we have the following (weaker) estimates $$ |f(re^{i\theta},a)|\leq C (r\cos\theta)^{-n}, ~~~r>0,-\frac{\pi}{2}<\theta<\frac{\pi}{2}, $$ for some constant $C$ and $n>0$. Furthermore, on the positive real line, and for any fixed $a>0$, we have the following (stronger) estimates $$ |f(r,a)|\leq C \frac{r}{a^{n+1}},~~~0<r\leq a, $$ where $C$ is a constant independent with $a$. My question is can we also get the following improved estimates of $f$ $$ |f(re^{i\theta},a)|\leq C \frac{r}{a^{n+1}},~~~0<r< a,~~-\frac{\pi}{2}<\theta<\frac{\pi}{2}? $$ If not, can you give a counterexample to this? The motivation of this question comes from estimating the Poisson semigroup $e^{-z\sqrt{-\Delta}}$ for small $|z|$ With  $\Re z>0$.To be more precise, if we let $K(z,x,y)$ be its kernel, then $K$ satisfies the estimates above with $a=|x-y|$. Although we can compute the kernel explicitly (for all $\Re z>0$ ) by using Fourier transform ($K(z,x,y)=\frac{z}{(z^2+a^2)^{n+1}}$,a=|x-y|), I think one may also obtain this by combining the kernel estimates on the positive real line (the second estimate above) with a weaker estimates on the right half plane (the first estimate above) and some analytic function theory. I don't know theorems like Hadamard's Three line lemma or its variants  would be useful here. Thanks in advance for any comment.",,"['complex-analysis', 'analysis', 'interpolation']"
91,How can one derive Stokes lines of the Stokes phenomenon of asymptotics from a differential equation?,How can one derive Stokes lines of the Stokes phenomenon of asymptotics from a differential equation?,,"Is there a standard technique to calculate Stokes lines and anti-Stokes lines of the Stokes phenomenon of asymptotics for a function defined as the general solution to a differential equation without directly solving the differential equation? For example, consider the differential equation \begin{gather} \frac{dz}{d\phi} = \lambda e^{i \phi} z - 1 \end{gather} where $\lambda$ and $\phi$ are real, but $z$ is complex.  This has solution \begin{gather} z_A(\phi) = A e^{- i \lambda \exp(i \phi)} + i e^{- i \lambda \exp(i \phi)} \operatorname{Ei} \left( i \lambda e^{i \phi} \right) \end{gather} where $A$ is a constant and $\operatorname{Ei}$ is the exponential integral.  I therefore conclude that the general solution for $z$ in the above differential equation has Stokes lines that correspond to the Stokes lines for $\operatorname{Ei}(i \lambda e^{i \phi})$, viz., $\phi = \pi / 2$ and $\phi = - \pi / 2$. This is all very well, but consider that I now generalise the above differential equation in some way, e.g., write $\lambda = \lambda(z)$, add a term proportional to $z^2$, or do something even more exotic, such that I can no longer find a solution.  Can one nevertheless determine the Stokes lines and anti-Stokes lines that a general solution has?","Is there a standard technique to calculate Stokes lines and anti-Stokes lines of the Stokes phenomenon of asymptotics for a function defined as the general solution to a differential equation without directly solving the differential equation? For example, consider the differential equation \begin{gather} \frac{dz}{d\phi} = \lambda e^{i \phi} z - 1 \end{gather} where $\lambda$ and $\phi$ are real, but $z$ is complex.  This has solution \begin{gather} z_A(\phi) = A e^{- i \lambda \exp(i \phi)} + i e^{- i \lambda \exp(i \phi)} \operatorname{Ei} \left( i \lambda e^{i \phi} \right) \end{gather} where $A$ is a constant and $\operatorname{Ei}$ is the exponential integral.  I therefore conclude that the general solution for $z$ in the above differential equation has Stokes lines that correspond to the Stokes lines for $\operatorname{Ei}(i \lambda e^{i \phi})$, viz., $\phi = \pi / 2$ and $\phi = - \pi / 2$. This is all very well, but consider that I now generalise the above differential equation in some way, e.g., write $\lambda = \lambda(z)$, add a term proportional to $z^2$, or do something even more exotic, such that I can no longer find a solution.  Can one nevertheless determine the Stokes lines and anti-Stokes lines that a general solution has?",,"['complex-analysis', 'ordinary-differential-equations', 'asymptotics', 'special-functions']"
92,"Show that an entire function that is real only on the real axis has at most one zero, without the argument principle","Show that an entire function that is real only on the real axis has at most one zero, without the argument principle",,"Could someone advise me on how to approach this problem: Suppose an entire function $f$ is real if and only if $z$ is real. Prove that $f$ has at most $1$ zero. without the use of argument principle ? Here is my attempt: Suppose $f(z)$ has two zeroes at $z=a.$ Let $f(z) = \sum^{\infty}_{n=0}a_n(z-a)^n, \forall z. \ $ Then $f(z)=(z-a)^2 \left(\dfrac{a_{0}}{(z-a)^2} +\dfrac{a_1}{z-a}+a_2+a_3(z-a)+...\right)$ $\implies a_0=a_1=0.$ $\implies f(z)= (z-a)^2\left(a_2+a_3(z-a)+a_4(z-a)^2+...\right)$ $\implies .... ?$ Thank you.","Could someone advise me on how to approach this problem: Suppose an entire function $f$ is real if and only if $z$ is real. Prove that $f$ has at most $1$ zero. without the use of argument principle ? Here is my attempt: Suppose $f(z)$ has two zeroes at $z=a.$ Let $f(z) = \sum^{\infty}_{n=0}a_n(z-a)^n, \forall z. \ $ Then $f(z)=(z-a)^2 \left(\dfrac{a_{0}}{(z-a)^2} +\dfrac{a_1}{z-a}+a_2+a_3(z-a)+...\right)$ $\implies a_0=a_1=0.$ $\implies f(z)= (z-a)^2\left(a_2+a_3(z-a)+a_4(z-a)^2+...\right)$ $\implies .... ?$ Thank you.",,['complex-analysis']
93,"Infinitely many roots $z e^z = a, a\neq 0$",Infinitely many roots,"z e^z = a, a\neq 0","Spent some time trying to tackle this problem. It is supposed to use Rouche's Theorem, but not sure how. Show that $ze^z = a$ for $a \neq 0$ has infinitely many roots. Rouches: (1) $f$ and $g$ analytic in and on simple, closed $C$ (2) $|f|>|g|$ on $C$ (*) $f+g$ and $f$ have the same number of zeroes inside $C$","Spent some time trying to tackle this problem. It is supposed to use Rouche's Theorem, but not sure how. Show that $ze^z = a$ for $a \neq 0$ has infinitely many roots. Rouches: (1) $f$ and $g$ analytic in and on simple, closed $C$ (2) $|f|>|g|$ on $C$ (*) $f+g$ and $f$ have the same number of zeroes inside $C$",,['complex-analysis']
94,"For fixed $z_i$s inside the unit disc, can we always choose $a_i$s such that $\left|\sum_{i=1}^n a_iz_i\right|<\sqrt3$?","For fixed s inside the unit disc, can we always choose s such that ?",z_i a_i \left|\sum_{i=1}^n a_iz_i\right|<\sqrt3,"Let $z_1,z_2,\ldots,z_n$ be complex number such that $|z_i|<1$ for all $i=1,2,\ldots,n$. Show that we can choose $a_i \in\{-1,1\}$, $i=1,2,\ldots,n$ such that $$\left|\sum_{i=1}^n a_iz_i\right|<\sqrt3.$$","Let $z_1,z_2,\ldots,z_n$ be complex number such that $|z_i|<1$ for all $i=1,2,\ldots,n$. Show that we can choose $a_i \in\{-1,1\}$, $i=1,2,\ldots,n$ such that $$\left|\sum_{i=1}^n a_iz_i\right|<\sqrt3.$$",,['complex-analysis']
95,Show a Schwarz-Christoffel integral maps unit disk conformally onto the interior of a regular polygon,Show a Schwarz-Christoffel integral maps unit disk conformally onto the interior of a regular polygon,,"Show that $F(w)=\int_{0}^{w}(1-w^n)^{-\frac{2}{n}}dw$ maps $|w|<1$ conformally onto the interior of a regular polygon with $n$ sides. I know that the Schwarz-Christoffel Formula tells us any conformal map from the unit disk onto the interior of polygon has the following form: $F(w)=C_1\int_{0}^{w}(w-w_k)^{-\beta_k}dw + C_2$, where $C_1,C_2$ are some constants and $w_k$ is a point in the unit circle, $\beta_k$ is the exterior angle of the polygon. So my question is the anti-side of the above theorem. I think I can show $F$ maps the unit circle onto a polygon (boundary). But how to show $F$ maps $|w|<1$ conformally onto the interior. This is an exercise from 'Complex Analysis' by Ahlfors.","Show that $F(w)=\int_{0}^{w}(1-w^n)^{-\frac{2}{n}}dw$ maps $|w|<1$ conformally onto the interior of a regular polygon with $n$ sides. I know that the Schwarz-Christoffel Formula tells us any conformal map from the unit disk onto the interior of polygon has the following form: $F(w)=C_1\int_{0}^{w}(w-w_k)^{-\beta_k}dw + C_2$, where $C_1,C_2$ are some constants and $w_k$ is a point in the unit circle, $\beta_k$ is the exterior angle of the polygon. So my question is the anti-side of the above theorem. I think I can show $F$ maps the unit circle onto a polygon (boundary). But how to show $F$ maps $|w|<1$ conformally onto the interior. This is an exercise from 'Complex Analysis' by Ahlfors.",,['complex-analysis']
96,Historical context: The Fresnel integrals,Historical context: The Fresnel integrals,,"The evaluation of the Fresnel integrals has been done a plethora of  times both on this site, and numerous other places. The two main ways of  evalutating these integrals has either been with some algebraic manipulations.  $$ \int_{-\infty}^{\infty} \sin(x^2)\mathrm{d}x = \int_{0}^{\infty} \frac{\sin t}{\sqrt{t}}\mathrm{d}t =\frac{2}{\sqrt{\pi}}\int_0^\infty \int_0^\infty e^{-tx^2}\sin{t} \, \mathrm{d}x\,\mathrm{d}t =\frac{2}{\sqrt{\pi}}\int_0^{\infty} \frac{\mathrm{d}x}{1+x^4} =\sqrt{\frac{\pi}{8}} $$ Where it was amongst other things used that  $1/\sqrt{t} = \pi^{-1}\int_{-\infty}^{\infty}e^{-tx^2}\mathrm{d}x$  and $\int_0^{\infty}e^{-\alpha t}\sin \beta t \mathrm{d}t = \beta/(\alpha^2 + \beta^2)$. Or for an example http://www.jstor.org/stable/2320230 , http://www.math.binghamton.edu/loya/papers/LoyaMathMag.pdf Another path to take is complex analysis usually using  path in the figure below I have seen several proofs using the indented path, but the sources are few.  For a proof se p.32 here or for a proof on stack.exchange see here . My question is asking for refferences for these methods to evaluate the Fresnel integrals and in particular using complex analysis. What are the earliest occurrences of using complex analysis to evaluate the Fresnel integrals?","The evaluation of the Fresnel integrals has been done a plethora of  times both on this site, and numerous other places. The two main ways of  evalutating these integrals has either been with some algebraic manipulations.  $$ \int_{-\infty}^{\infty} \sin(x^2)\mathrm{d}x = \int_{0}^{\infty} \frac{\sin t}{\sqrt{t}}\mathrm{d}t =\frac{2}{\sqrt{\pi}}\int_0^\infty \int_0^\infty e^{-tx^2}\sin{t} \, \mathrm{d}x\,\mathrm{d}t =\frac{2}{\sqrt{\pi}}\int_0^{\infty} \frac{\mathrm{d}x}{1+x^4} =\sqrt{\frac{\pi}{8}} $$ Where it was amongst other things used that  $1/\sqrt{t} = \pi^{-1}\int_{-\infty}^{\infty}e^{-tx^2}\mathrm{d}x$  and $\int_0^{\infty}e^{-\alpha t}\sin \beta t \mathrm{d}t = \beta/(\alpha^2 + \beta^2)$. Or for an example http://www.jstor.org/stable/2320230 , http://www.math.binghamton.edu/loya/papers/LoyaMathMag.pdf Another path to take is complex analysis usually using  path in the figure below I have seen several proofs using the indented path, but the sources are few.  For a proof se p.32 here or for a proof on stack.exchange see here . My question is asking for refferences for these methods to evaluate the Fresnel integrals and in particular using complex analysis. What are the earliest occurrences of using complex analysis to evaluate the Fresnel integrals?",,"['complex-analysis', 'reference-request']"
97,A Curious Identity,A Curious Identity,,"I met the following equations when I was trying to solve a complex line integral (W.Rudin, RCA, p.228 ex.13). My question is how to prove them: We have to show that for $n>2$ even $$ 2^{n/2}\prod^{\left(n - 2\right)/2}_{k = 1} \left[1 - \cos\left(2k\pi \over n\right)\right] = n, $$ and for $n>1$ odd, $$ 2^{\left(n - 1\right)/2}\prod_{k = 1}^{\left(n - 1\right)/2} \left[1 - \cos\left(2k\pi \over n\right)\right] =n\text{ ?}$$ -This can be rewritten as a curious identity after the below hint of Greg Martin- Thx.","I met the following equations when I was trying to solve a complex line integral (W.Rudin, RCA, p.228 ex.13). My question is how to prove them: We have to show that for $n>2$ even $$ 2^{n/2}\prod^{\left(n - 2\right)/2}_{k = 1} \left[1 - \cos\left(2k\pi \over n\right)\right] = n, $$ and for $n>1$ odd, $$ 2^{\left(n - 1\right)/2}\prod_{k = 1}^{\left(n - 1\right)/2} \left[1 - \cos\left(2k\pi \over n\right)\right] =n\text{ ?}$$ -This can be rewritten as a curious identity after the below hint of Greg Martin- Thx.",,"['real-analysis', 'complex-analysis']"
98,"Show that the iterated $\ln^{[n]}$ of tetration(x,n) is nowhere analytic","Show that the iterated  of tetration(x,n) is nowhere analytic",\ln^{[n]},"$$f(x) = \lim_{n\to \infty} \ln^{[n]} x \uparrow\uparrow n$$ The conjecture is that $f(x)$ is monotonic and infinitely differentiable at the real axis, but nowhere analytic; because at each point on the real axis, the Taylor series has a zero radius of convergence.  The function is well defined at the real axis, but not as well behaved in the complex plane.  $f(x)$ is a useful function for comparing tetration for different bases, to see how much faster one base grows than another, where x can be thought of as the tetration base.  See my post, Comparison between two tetrations showing the evaulation of $f(\pi)$. How difficult would it be to show that $f(x)$ is infinitely differentiable, and nowhere analytic?  Below, is a graph of $f(x)$, showing the ""logarithmic singularity"" at the real axis near 1.805; for $x >\approx1.805$, $f(x)$ is real valued and converges nicely at the real axis. One simplification I found, also shows that $f(x)$ behaves somewhat like $\ln(x)+ \ln(\ln(x))$ as x increases.  The $x \uparrow \uparrow n$ term grows very rapidly, so that the $\ln(\ln(x))$ term becomes insignificant in the equation below, that can be used to evaluate $f(x)$.  At the same time as the $x \uparrow \uparrow n$ term in the denominator becomes insignificant at the real axis, it becomes less and less well behaved in the complex plane. $$f_n(x) = \ln^{[n]} x \uparrow\uparrow n$$ $$f_{n+1}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) ) $$ $$f_{n+2}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) + \ln(\ln(x))) $$ $$f_{n+2}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) \times (1+ \frac{\ln(\ln(x))}{(x \uparrow\uparrow n)\ln(x)}) $$ $$f_{n+2}(x) = \ln^{[n]}  ( \exp^{on}(f_{n+1}) \times (1+ \frac{\ln(\ln(x))}{ \exp^{on}(f_{n+1}) }) $$ After this, the algebra gets messy.... but here's the next step I took.  Eventually, you get to an equation of $f_{n+2}(x) \approx f_{n+1}(x) +$ reciprical of a superexponential product. $$f_{n+2}(x) \approx  f_{n+1} +  \frac{\ln(\ln(x))} { \exp^{on}(f_{n+1}) \times \exp^{on-1}(f_{n+1}) \times \exp^{on-2}(f_{n+1}) \times ... \exp(f_{n+1}) } + O\frac{1}{(\exp^{on}(f_{n+1}) )^2}$$ For this function, ""Nowhere analytic"" means the function has a well defined Taylor series at the real axis, but the Taylor series has a zero radius of convergence, so that that the function is not equal to its Taylor series. This is because the Taylor series terms eventually grow faster than any exponential series, so that for any value of r you pick, for n large enough, $|a_n|>r^n$, or equivalently, $\ln(|a_n|)>n\ln(r)$. I think the key to showing this is to look at the function $f_n(x)-f_{n-1}(x)$, as n increases. In the complex plane, $f_6(x)$ has a singularity near x=1.96219034541054 + 0.254713677298596i.  The $f_6$ singularities occur where $\exp^{4}(f_{5})  =-\ln(\ln(x))$.  As x gets larger, the singularities get closer to the real axis, and also, as n gets larger, the singularities get closer to the real axis.","$$f(x) = \lim_{n\to \infty} \ln^{[n]} x \uparrow\uparrow n$$ The conjecture is that $f(x)$ is monotonic and infinitely differentiable at the real axis, but nowhere analytic; because at each point on the real axis, the Taylor series has a zero radius of convergence.  The function is well defined at the real axis, but not as well behaved in the complex plane.  $f(x)$ is a useful function for comparing tetration for different bases, to see how much faster one base grows than another, where x can be thought of as the tetration base.  See my post, Comparison between two tetrations showing the evaulation of $f(\pi)$. How difficult would it be to show that $f(x)$ is infinitely differentiable, and nowhere analytic?  Below, is a graph of $f(x)$, showing the ""logarithmic singularity"" at the real axis near 1.805; for $x >\approx1.805$, $f(x)$ is real valued and converges nicely at the real axis. One simplification I found, also shows that $f(x)$ behaves somewhat like $\ln(x)+ \ln(\ln(x))$ as x increases.  The $x \uparrow \uparrow n$ term grows very rapidly, so that the $\ln(\ln(x))$ term becomes insignificant in the equation below, that can be used to evaluate $f(x)$.  At the same time as the $x \uparrow \uparrow n$ term in the denominator becomes insignificant at the real axis, it becomes less and less well behaved in the complex plane. $$f_n(x) = \ln^{[n]} x \uparrow\uparrow n$$ $$f_{n+1}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) ) $$ $$f_{n+2}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) + \ln(\ln(x))) $$ $$f_{n+2}(x) = \ln^{[n]} ((x \uparrow\uparrow n)\ln(x) \times (1+ \frac{\ln(\ln(x))}{(x \uparrow\uparrow n)\ln(x)}) $$ $$f_{n+2}(x) = \ln^{[n]}  ( \exp^{on}(f_{n+1}) \times (1+ \frac{\ln(\ln(x))}{ \exp^{on}(f_{n+1}) }) $$ After this, the algebra gets messy.... but here's the next step I took.  Eventually, you get to an equation of $f_{n+2}(x) \approx f_{n+1}(x) +$ reciprical of a superexponential product. $$f_{n+2}(x) \approx  f_{n+1} +  \frac{\ln(\ln(x))} { \exp^{on}(f_{n+1}) \times \exp^{on-1}(f_{n+1}) \times \exp^{on-2}(f_{n+1}) \times ... \exp(f_{n+1}) } + O\frac{1}{(\exp^{on}(f_{n+1}) )^2}$$ For this function, ""Nowhere analytic"" means the function has a well defined Taylor series at the real axis, but the Taylor series has a zero radius of convergence, so that that the function is not equal to its Taylor series. This is because the Taylor series terms eventually grow faster than any exponential series, so that for any value of r you pick, for n large enough, $|a_n|>r^n$, or equivalently, $\ln(|a_n|)>n\ln(r)$. I think the key to showing this is to look at the function $f_n(x)-f_{n-1}(x)$, as n increases. In the complex plane, $f_6(x)$ has a singularity near x=1.96219034541054 + 0.254713677298596i.  The $f_6$ singularities occur where $\exp^{4}(f_{5})  =-\ln(\ln(x))$.  As x gets larger, the singularities get closer to the real axis, and also, as n gets larger, the singularities get closer to the real axis.",,"['real-analysis', 'complex-analysis', 'analyticity', 'tetration', 'power-towers']"
99,Using the theorem of Rouché in order to show the fundamental theorem of algebra,Using the theorem of Rouché in order to show the fundamental theorem of algebra,,"Infer from the theorem of Rouché that every non-constant polynomial does have a zero point in $\mathbb{C}$ ( Fundamental Theorem of Algebra ). Consider the polynomial $$ p(z)=\sum_{i=0}^{n}a_iz^i, a_i,z\in\mathbb{C}, a_i\neq 0. $$ In order tu use Rouché, set $$ f(z):=a_nz^n,~~~~~~~~~~g(z):=\sum_{i=0}^{n-1}a_i z^i. $$ Because of the holomorphism of polyniomials, these functions are holomorphic and for each $r>0$ it is $$ f(z)\neq 0~\forall z\in\mbox{rg}(\gamma_r),\\ \gamma_r\colon [0,2\pi]\to\mathbb{C}, t\longmapsto r\exp(it). $$ Because of $$ \frac{\lvert z\rvert^i}{\lvert z\rvert^n}\to 0\mbox{ for }\lvert z\rvert\to\infty, i<n $$ it follows that $$ \lim\limits_{\lvert z\rvert\to\infty}\frac{\lvert g(z)\rvert}{\lvert f(z)\rvert}\leq\lim\limits_{\lvert z\rvert\to\infty}\frac{\sum_{i=0}^{n-1}\lvert a_i\rvert\cdot\lvert z^i\rvert}{\lvert a_n\rvert\cdot\lvert z^n\rvert}=\frac{1}{\lvert a_n\rvert}\lim\limits_{\lvert z\rvert\to\infty}\sum_{i=0}^{n-1}\lvert a_i\rvert\cdot\lvert z\rvert^{i-n}=0. $$ So there exists an $\varepsilon>0$ , so that $$ \frac{\lvert g(z)\rvert}{\lvert f(z)\rvert}<1~\forall z\in\mbox{rg}(\gamma_{\varepsilon}). $$ So let $\gamma_{\varepsilon}$ be the curve tracing the open circular disk with radius $\varepsilon$ . The theorem of Rouché then says that the number of zero points of $p$ within that circular disk is the same as the number of zero points of $f$ within that circular disk. And within that disk, it is $f(z)=0$ for $z=0$ (and nowhere else). So $p$ indeed has a zero point in $\mathbb{C}$ . Do you agree? Is my proof okay?","Infer from the theorem of Rouché that every non-constant polynomial does have a zero point in ( Fundamental Theorem of Algebra ). Consider the polynomial In order tu use Rouché, set Because of the holomorphism of polyniomials, these functions are holomorphic and for each it is Because of it follows that So there exists an , so that So let be the curve tracing the open circular disk with radius . The theorem of Rouché then says that the number of zero points of within that circular disk is the same as the number of zero points of within that circular disk. And within that disk, it is for (and nowhere else). So indeed has a zero point in . Do you agree? Is my proof okay?","\mathbb{C} 
p(z)=\sum_{i=0}^{n}a_iz^i, a_i,z\in\mathbb{C}, a_i\neq 0.
 
f(z):=a_nz^n,~~~~~~~~~~g(z):=\sum_{i=0}^{n-1}a_i z^i.
 r>0 
f(z)\neq 0~\forall z\in\mbox{rg}(\gamma_r),\\ \gamma_r\colon [0,2\pi]\to\mathbb{C}, t\longmapsto r\exp(it).
 
\frac{\lvert z\rvert^i}{\lvert z\rvert^n}\to 0\mbox{ for }\lvert z\rvert\to\infty, i<n
 
\lim\limits_{\lvert z\rvert\to\infty}\frac{\lvert g(z)\rvert}{\lvert f(z)\rvert}\leq\lim\limits_{\lvert z\rvert\to\infty}\frac{\sum_{i=0}^{n-1}\lvert a_i\rvert\cdot\lvert z^i\rvert}{\lvert a_n\rvert\cdot\lvert z^n\rvert}=\frac{1}{\lvert a_n\rvert}\lim\limits_{\lvert z\rvert\to\infty}\sum_{i=0}^{n-1}\lvert a_i\rvert\cdot\lvert z\rvert^{i-n}=0.
 \varepsilon>0 
\frac{\lvert g(z)\rvert}{\lvert f(z)\rvert}<1~\forall z\in\mbox{rg}(\gamma_{\varepsilon}).
 \gamma_{\varepsilon} \varepsilon p f f(z)=0 z=0 p \mathbb{C}",[]
