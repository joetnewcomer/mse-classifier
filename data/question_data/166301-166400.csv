,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Using CLT, Slutsky's theorem and delta method","Using CLT, Slutsky's theorem and delta method",,"Let $Y_n$ be a sequence of random variables with $\chi^2_n$ distribution. Using Slutsky' theorem or delta method prove that $$\sqrt{2Y_n}-\sqrt{2n-1}\stackrel{D}\to N(0,1)$$ In the first place I proved from CLT that $\frac{Y_n-n}{\sqrt{2n}}\stackrel{D}\to N(0,1)$ , but I have no idea how to prove this upper convergence using Slutsky's theorem or delta method. My attempt was to write it down as $\frac{2Y_n-(2n-1)}{\sqrt{2Y_n}+\sqrt{2n-1}}$ , but I can't see a point here.","Let be a sequence of random variables with distribution. Using Slutsky' theorem or delta method prove that In the first place I proved from CLT that , but I have no idea how to prove this upper convergence using Slutsky's theorem or delta method. My attempt was to write it down as , but I can't see a point here.","Y_n \chi^2_n \sqrt{2Y_n}-\sqrt{2n-1}\stackrel{D}\to N(0,1) \frac{Y_n-n}{\sqrt{2n}}\stackrel{D}\to N(0,1) \frac{2Y_n-(2n-1)}{\sqrt{2Y_n}+\sqrt{2n-1}}","['statistics', 'central-limit-theorem', 'delta-method']"
1,"How to find the median of three numbers, if one of them appears twice?","How to find the median of three numbers, if one of them appears twice?",,"How do you determine the median of three numbers where two of  the numbers are duplicated? For example, $(6,6,3)$.","How do you determine the median of three numbers where two of  the numbers are duplicated? For example, $(6,6,3)$.",,"['statistics', 'median']"
2,Adding and Subtracting Normal Distributions,Adding and Subtracting Normal Distributions,,"I think I know how to do this, but I'm not sure. I'm just hoping to check myself here before I do a bunch of work incorrectly. Suppose you have three independent normal distributions: Distribution $A$ : Mean = $30.48$ , SD = $8.15$ Distribution $B$ : Mean = $16.58$ , SD = $7.99$ Distribution $C$ : Mean = $10.51$ , SD = $4.43$ What is the probability that $B$ and $C$ will combine for a greater result than $A$ ? I believe the first step is to combine distributions $B$ and $C$ into one distribution through addition. So... Distribution $D$ : Mean = $27.09$ , SD = $9.135918$ Next I think I have to combine $D$ and $A$ through subtraction to get the final distribution. Distribution $E$ : Mean = $-3.39$ , SD = $12.24286$ Given these values, the $z$ -score using the standard normal distribution is $-.28$ , so the probability of distributions $B$ and $C$ combining for a value greater than distribution $A$ is $.3897$ I think. Any help is appreciated.","I think I know how to do this, but I'm not sure. I'm just hoping to check myself here before I do a bunch of work incorrectly. Suppose you have three independent normal distributions: Distribution : Mean = , SD = Distribution : Mean = , SD = Distribution : Mean = , SD = What is the probability that and will combine for a greater result than ? I believe the first step is to combine distributions and into one distribution through addition. So... Distribution : Mean = , SD = Next I think I have to combine and through subtraction to get the final distribution. Distribution : Mean = , SD = Given these values, the -score using the standard normal distribution is , so the probability of distributions and combining for a value greater than distribution is I think. Any help is appreciated.",A 30.48 8.15 B 16.58 7.99 C 10.51 4.43 B C A B C D 27.09 9.135918 D A E -3.39 12.24286 z -.28 B C A .3897,"['statistics', 'normal-distribution']"
3,What does it mean to divide by the standard deviation?,What does it mean to divide by the standard deviation?,,"I'm trying to ""variance-normalize"" an image. In order to do so, I subtract the mean from the pixel value (to have a $0$ mean), and divide by the standard deviation (to have a unit variance) right? But I've also seen division by the standard deviation, since it's obviously not the same, what does it do? I'm also a bit confused about the values I get after normalization: some values still more than $1.0$ or less than $-1.0$. I thought a unit variance means a variance from $-1.0$ to $1.0$.","I'm trying to ""variance-normalize"" an image. In order to do so, I subtract the mean from the pixel value (to have a $0$ mean), and divide by the standard deviation (to have a unit variance) right? But I've also seen division by the standard deviation, since it's obviously not the same, what does it do? I'm also a bit confused about the values I get after normalization: some values still more than $1.0$ or less than $-1.0$. I thought a unit variance means a variance from $-1.0$ to $1.0$.",,"['statistics', 'standard-deviation', 'image-processing']"
4,Derivation of standard error of mean,Derivation of standard error of mean,,"I was going through this wikipedia article on standard error . I could not understand the crucial step here. It goes like this: This formula may be derived from what we know about the variance of a sum of independent random variables. If $X_1, X_2 , \ldots, X_n$ are n independent observations from a population that has a mean $\mu$ and standard deviation $\sigma$ , then the variance of the total $T = (X_1 + X_2 + \cdots + X_n)$ is $n\sigma^2$. Understood. The variance of T/n must be $\frac{1}{n^2}n\sigma^2=\frac{\sigma^2}{n}$. Not understood. And the standard deviation of T/n must be $\sigma/{\sqrt{n}}$ . Of course, T/n is the sample mean $\bar{x}$ . I went to some basics: $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}({x_i-\mu})^2$ $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}({x_i^2+\mu^2-2x_i\mu})$ $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}x_i^2+\mu^2-\frac{2}{n}\sum_{i=1}^{n}x_i\mu$ As Sample mean is an unbiased estimate of population mean, we get $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}x_i^2-\mu^2$ $\displaystyle Var(X)=E(X^2)-(E(X))^2$ Nothing useful found from this. Why is there a $1/n^2$ in that step to get variance ?","I was going through this wikipedia article on standard error . I could not understand the crucial step here. It goes like this: This formula may be derived from what we know about the variance of a sum of independent random variables. If $X_1, X_2 , \ldots, X_n$ are n independent observations from a population that has a mean $\mu$ and standard deviation $\sigma$ , then the variance of the total $T = (X_1 + X_2 + \cdots + X_n)$ is $n\sigma^2$. Understood. The variance of T/n must be $\frac{1}{n^2}n\sigma^2=\frac{\sigma^2}{n}$. Not understood. And the standard deviation of T/n must be $\sigma/{\sqrt{n}}$ . Of course, T/n is the sample mean $\bar{x}$ . I went to some basics: $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}({x_i-\mu})^2$ $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}({x_i^2+\mu^2-2x_i\mu})$ $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}x_i^2+\mu^2-\frac{2}{n}\sum_{i=1}^{n}x_i\mu$ As Sample mean is an unbiased estimate of population mean, we get $\displaystyle Var(X)=\frac{1}{n}\sum_{i=1}^{n}x_i^2-\mu^2$ $\displaystyle Var(X)=E(X^2)-(E(X))^2$ Nothing useful found from this. Why is there a $1/n^2$ in that step to get variance ?",,"['statistics', 'statistical-inference']"
5,Order statistics and their CDF,Order statistics and their CDF,,"Here's a problem that seems rather peculiar to me. This time I have no initial idea about how to solve it. Let $X_1$, ..., $X_n$ be independent, real valued random variables with density $f$ and CDF $F$. Let $F_i$ denote the CDF of $X_{(i)}$. a) What is the distribution of $F(X_{(i)})$ and $F_i(X_{(i)})$? b) What is the variance of $F(X_{(i)})$? [edit: I have realised by now that my approach was flawed and furthermore that my question needs clarification. So here is my second try.] As I understand the question, we have real valued, i.i.d. random variables $X_1$, ..., $X_n$ with density $f$ and CDF $F$. $X_{(1)}< ... < X_{(n)}$ are the corresponding order statistics with CDF $F_i:=F_{X_{(i)}}$. I know the general formula for the CDF of order statistics. It is given by $$F_i(t)=\sum_{k=i}^n \binom{n}{k}F(t)^k(1-F(t))^{n-k}.$$ Now, the CDF of a random variable is a measurable function. Thus $F(X_{(i)})$ and $F_i(X_{(i)})$ are real valued random variables again. And a) asks for their distribution. Per definition, we have $$F(t)=\mathbb{P}(X_i\leq t).$$ Hence $$F(X_{(i)})=\mathbb{P}(X_i\leq X_{(i)}).$$ This is the probability of the event that any $X_i$ is less or equal $X_{(i)}$. By definition of order statistics, we have $$F(X_{(n)})=\mathbb{P}(X_i\leq X_{(n)})=1,$$ as $X_{(n)}$ is the maximum of the $X_i$. But how do I derive the distribution of $F(X_{(i)})$ for $i \in \{1, ..., n-1\}$? I think, if they were uniformly distributed, the answer would simply be $$F(X_{(i)})=i/n.$$ But their distribution ist unknown, so I'm stuck and have no idea how to proceed from here.","Here's a problem that seems rather peculiar to me. This time I have no initial idea about how to solve it. Let $X_1$, ..., $X_n$ be independent, real valued random variables with density $f$ and CDF $F$. Let $F_i$ denote the CDF of $X_{(i)}$. a) What is the distribution of $F(X_{(i)})$ and $F_i(X_{(i)})$? b) What is the variance of $F(X_{(i)})$? [edit: I have realised by now that my approach was flawed and furthermore that my question needs clarification. So here is my second try.] As I understand the question, we have real valued, i.i.d. random variables $X_1$, ..., $X_n$ with density $f$ and CDF $F$. $X_{(1)}< ... < X_{(n)}$ are the corresponding order statistics with CDF $F_i:=F_{X_{(i)}}$. I know the general formula for the CDF of order statistics. It is given by $$F_i(t)=\sum_{k=i}^n \binom{n}{k}F(t)^k(1-F(t))^{n-k}.$$ Now, the CDF of a random variable is a measurable function. Thus $F(X_{(i)})$ and $F_i(X_{(i)})$ are real valued random variables again. And a) asks for their distribution. Per definition, we have $$F(t)=\mathbb{P}(X_i\leq t).$$ Hence $$F(X_{(i)})=\mathbb{P}(X_i\leq X_{(i)}).$$ This is the probability of the event that any $X_i$ is less or equal $X_{(i)}$. By definition of order statistics, we have $$F(X_{(n)})=\mathbb{P}(X_i\leq X_{(n)})=1,$$ as $X_{(n)}$ is the maximum of the $X_i$. But how do I derive the distribution of $F(X_{(i)})$ for $i \in \{1, ..., n-1\}$? I think, if they were uniformly distributed, the answer would simply be $$F(X_{(i)})=i/n.$$ But their distribution ist unknown, so I'm stuck and have no idea how to proceed from here.",,"['statistics', 'order-statistics']"
6,Recommended Reading on Regression Analysis?,Recommended Reading on Regression Analysis?,,"For a university project, I am implementing an automated regression analysis tool. However, I have very little background in statistics. So what books / articles / material would you suggest I could use to brush up on this topic, based on your experiences? Thanks","For a university project, I am implementing an automated regression analysis tool. However, I have very little background in statistics. So what books / articles / material would you suggest I could use to brush up on this topic, based on your experiences? Thanks",,['statistics']
7,Sampling from the von-Mises Fisher distribution?,Sampling from the von-Mises Fisher distribution?,,"This topic has already been tackled on this website (here) .  But, unfortunately, no clear cut answers were given.  In (Wood,1994) , there is apparently a rejection algorithm for sampling from this distribution, but I can't find it on the web. I am thus looking for a pseudo-code (I have not much experience with sampling random variables). Many thanks!","This topic has already been tackled on this website (here) .  But, unfortunately, no clear cut answers were given.  In (Wood,1994) , there is apparently a rejection algorithm for sampling from this distribution, but I can't find it on the web. I am thus looking for a pseudo-code (I have not much experience with sampling random variables). Many thanks!",,"['statistics', 'probability-distributions', 'algorithms', 'sampling']"
8,How to calculate the lens distortion coefficients with a known displacement vector field?,How to calculate the lens distortion coefficients with a known displacement vector field?,,"I have this vector field full of displacement vectors, which indicates radial distortions by a lens system. ( Source ) I know where each of the displacement vectors starts $(x,y)$ and ends $(x',y')$ and I know the distortion equations look like $$ x' = (1 + k_1r^2 + k_2r^4)x\\ y' = (1 + k_1r^2 + k_2r^4)y $$ where $r^2 = x^2 + y^2$. Since each $(x',y')$ was measured, they are most likely biased. How can I estimate coefficients $k_1$ and $k_2$?","I have this vector field full of displacement vectors, which indicates radial distortions by a lens system. ( Source ) I know where each of the displacement vectors starts $(x,y)$ and ends $(x',y')$ and I know the distortion equations look like $$ x' = (1 + k_1r^2 + k_2r^4)x\\ y' = (1 + k_1r^2 + k_2r^4)y $$ where $r^2 = x^2 + y^2$. Since each $(x',y')$ was measured, they are most likely biased. How can I estimate coefficients $k_1$ and $k_2$?",,"['statistics', 'least-squares']"
9,Alternate definition of Entropy,Alternate definition of Entropy,,"I am going through the book Computational Optimal Transport by Peyré and Cuturi. In it (see Formula (4.1), P. 65/209) I came across the definition of the discrete entropy, which is not what I expected: $$ H(P) = - \sum_{i,j}P_{i,j}(\log(P_{i,j})-1), $$ with $P \in [0,1]^{n,m}$ being a coupling matrix, i.e. describing the transformation of discrete propability distributions. What confuses me is the $-1$ in the sum and I would like to know, why it is included. Since $\sum_{i,j} P_{i,j}=1$ it is shifting the result by $-1$ .  Still it confuses me.","I am going through the book Computational Optimal Transport by Peyré and Cuturi. In it (see Formula (4.1), P. 65/209) I came across the definition of the discrete entropy, which is not what I expected: with being a coupling matrix, i.e. describing the transformation of discrete propability distributions. What confuses me is the in the sum and I would like to know, why it is included. Since it is shifting the result by .  Still it confuses me.","
H(P) = - \sum_{i,j}P_{i,j}(\log(P_{i,j})-1),
 P \in [0,1]^{n,m} -1 \sum_{i,j} P_{i,j}=1 -1","['statistics', 'information-theory', 'entropy', 'optimal-transport']"
10,Is the usage of unbiased estimator appropriate?,Is the usage of unbiased estimator appropriate?,,"Sometimes I find the usage of unbiased estimator quite confusing. For example, the unbiased estimator of variance:$$S^2=\frac{\sum (X_i-\bar{X})^2}{n-1}\,.$$ True, it is the expectation of variance. But when should we use it? I mean, there are other ways to estimate $\sigma^2$, such as MLE. How can I know when I should use MLE and when I should use unbaised estimator? Secondly, some books(such as A-level and AP syllabus and textbooks) uses $S$ as an estimation of standard deviation. However, $S$ is NOT an unbiased estimation. This perplexes me a lot because I don't know what they are trying to do. Why don't they use an unbiased estimator of standard deviation instead? Here are some unbiased estimators of standard deviation. https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation#Background So I have two questions: When should we use unbiased estimator? How can I choose between Maximum Likelyhood Estimation and Unbiased Estimation? Why in some books, unbiased estimator are used in such a way that it end up with bias?","Sometimes I find the usage of unbiased estimator quite confusing. For example, the unbiased estimator of variance:$$S^2=\frac{\sum (X_i-\bar{X})^2}{n-1}\,.$$ True, it is the expectation of variance. But when should we use it? I mean, there are other ways to estimate $\sigma^2$, such as MLE. How can I know when I should use MLE and when I should use unbaised estimator? Secondly, some books(such as A-level and AP syllabus and textbooks) uses $S$ as an estimation of standard deviation. However, $S$ is NOT an unbiased estimation. This perplexes me a lot because I don't know what they are trying to do. Why don't they use an unbiased estimator of standard deviation instead? Here are some unbiased estimators of standard deviation. https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation#Background So I have two questions: When should we use unbiased estimator? How can I choose between Maximum Likelyhood Estimation and Unbiased Estimation? Why in some books, unbiased estimator are used in such a way that it end up with bias?",,"['statistics', 'estimation', 'standard-deviation', 'variance']"
11,Explanation for the Wilson Score Interval?,Explanation for the Wilson Score Interval?,,"I'm looking at this blog to try to understand the Wilson Score interval. I understand it somewhat, but I'm confused by the part under the title ""Excerpt"". In particular, I don't understand what he's calling the ""Interval equality principal"" and how he arrived at the below graph: Could someone elaborate on it, or really just explain how/why the Wilson Score Interval is arrived at from the basic Wald Interval (normal approximation)? Basically, what I'm trying to understand is why the Wilson Score Interval is more accurate than the Wald test / normal approximation interval?","I'm looking at this blog to try to understand the Wilson Score interval. I understand it somewhat, but I'm confused by the part under the title ""Excerpt"". In particular, I don't understand what he's calling the ""Interval equality principal"" and how he arrived at the below graph: Could someone elaborate on it, or really just explain how/why the Wilson Score Interval is arrived at from the basic Wald Interval (normal approximation)? Basically, what I'm trying to understand is why the Wilson Score Interval is more accurate than the Wald test / normal approximation interval?",,['statistics']
12,Mahalanobis distance invariant,Mahalanobis distance invariant,,"Is the Mahalanobis distance invariant with respect to arbitrary non-singular linear transformations? I mean if $C$ an arbitrary regular $(p × p)$ -matrix and $b$ in $R$ arbitrary and $ \tilde{x}_n= C\,x_n +b$ , is it then true that $d\left(x_n,x_m\right)=d\left(\tilde{x}_n,\tilde{x}_m\right)$ . And if so, why?","Is the Mahalanobis distance invariant with respect to arbitrary non-singular linear transformations? I mean if an arbitrary regular -matrix and in arbitrary and , is it then true that . And if so, why?","C (p × p) b R  \tilde{x}_n= C\,x_n +b d\left(x_n,x_m\right)=d\left(\tilde{x}_n,\tilde{x}_m\right)",['statistics']
13,Meaning of inverse temperature,Meaning of inverse temperature,,"I am not familiar with statistics, so when I read a book which covers statistical learning, I have a question. Here, a posteriori probability density function is defined as follows; $D_n=\{X_1,X_2,\cdots, X_n \}$ be a set of random variables and $\varphi(w)$ be a priori probability density function. Then for given statistical model $p(x|w)$, The ""a posteriori probability density function $p(w|D_n)$ with the inverse temperature $\beta>0$"" is defined by $$p(w|D_n)={1\over {Z_n}} \varphi(w) \prod_{i=1}^n p(X_i|w)^\beta,$$ where $Z_n$ is the normalizing factor. My question is what is the meaning of ""inverse temperature""? I want to know its meaning or role in this definition. Any reference would be helpful, thanks!","I am not familiar with statistics, so when I read a book which covers statistical learning, I have a question. Here, a posteriori probability density function is defined as follows; $D_n=\{X_1,X_2,\cdots, X_n \}$ be a set of random variables and $\varphi(w)$ be a priori probability density function. Then for given statistical model $p(x|w)$, The ""a posteriori probability density function $p(w|D_n)$ with the inverse temperature $\beta>0$"" is defined by $$p(w|D_n)={1\over {Z_n}} \varphi(w) \prod_{i=1}^n p(X_i|w)^\beta,$$ where $Z_n$ is the normalizing factor. My question is what is the meaning of ""inverse temperature""? I want to know its meaning or role in this definition. Any reference would be helpful, thanks!",,['statistics']
14,$\frac{\Gamma(\frac{n_T + n_C - 2}{2})}{\sqrt{\frac{n_T+n_C-2}{2}}\Gamma\left(\frac{n_T+n_C-3}{2}\right)} \approx 1 - \frac{3}{4(n_T+n_C+2)-1}$,,\frac{\Gamma(\frac{n_T + n_C - 2}{2})}{\sqrt{\frac{n_T+n_C-2}{2}}\Gamma\left(\frac{n_T+n_C-3}{2}\right)} \approx 1 - \frac{3}{4(n_T+n_C+2)-1},"In this answer to a question I asked (which derives the variance of Cohen's $d$), the approximation $$\frac{\Gamma\left(\frac{n_T + n_C - 2}{2}\right)}{\sqrt{\frac{n_T+n_C-2}{2}}\Gamma\left(\frac{n_T+n_C-3}{2}\right)} \approx 1 - \frac{3}{4(n_T+n_C+2)-1}$$ is used. We can reasonably assume that $n_T, n_C> 0$ are integers. How is this approximation derived? The answerer states: I pulled it from the Hedges paper -- don't know its derivation at the moment but will think about it some more. I wish I had more to contribute to this question than that, but the removal of the $\Gamma$ function I find completely baffling, and I wouldn't even know where to start. Edit : Currently trying out Stirling's approximation, seeing if that leads me anywhere. And so far, I'm quite lost as to how to deal with the division by $2$ in the $\Gamma$ functions.","In this answer to a question I asked (which derives the variance of Cohen's $d$), the approximation $$\frac{\Gamma\left(\frac{n_T + n_C - 2}{2}\right)}{\sqrt{\frac{n_T+n_C-2}{2}}\Gamma\left(\frac{n_T+n_C-3}{2}\right)} \approx 1 - \frac{3}{4(n_T+n_C+2)-1}$$ is used. We can reasonably assume that $n_T, n_C> 0$ are integers. How is this approximation derived? The answerer states: I pulled it from the Hedges paper -- don't know its derivation at the moment but will think about it some more. I wish I had more to contribute to this question than that, but the removal of the $\Gamma$ function I find completely baffling, and I wouldn't even know where to start. Edit : Currently trying out Stirling's approximation, seeing if that leads me anywhere. And so far, I'm quite lost as to how to deal with the division by $2$ in the $\Gamma$ functions.",,"['statistics', 'gamma-function']"
15,What is a confidence interval?,What is a confidence interval?,,What are the nature and purpose of confidence intervals?,What are the nature and purpose of confidence intervals?,,['statistics']
16,What can we conclude from correlation?,What can we conclude from correlation?,,"I just got my statistics test back and I am totally confused about one of the questions! A study was done that took a simple random sample of 40 people and measured whether   the subjects were right-handed or   left-handed, as well as their ages.   The study showed that the proportion   of left-handed people and the ages had   a strong negative correlation. What   can we conclude? Explain your answer. I know that we can't conclude that getting older causes people to become right-handed. Something else might be causing it, not the age. If two things are correlated, we can only conclude association, not causation. So I wrote: We can conclude that many people   become right-handed as they grow   older, but we cannot tell why. That's exactly what association means, but my teacher marked me wrong! What mistake did I make? Is 40 too small of a sample size to make any conclusions?","I just got my statistics test back and I am totally confused about one of the questions! A study was done that took a simple random sample of 40 people and measured whether   the subjects were right-handed or   left-handed, as well as their ages.   The study showed that the proportion   of left-handed people and the ages had   a strong negative correlation. What   can we conclude? Explain your answer. I know that we can't conclude that getting older causes people to become right-handed. Something else might be causing it, not the age. If two things are correlated, we can only conclude association, not causation. So I wrote: We can conclude that many people   become right-handed as they grow   older, but we cannot tell why. That's exactly what association means, but my teacher marked me wrong! What mistake did I make? Is 40 too small of a sample size to make any conclusions?",,['statistics']
17,Chi Squared for Goodness of Fit,Chi Squared for Goodness of Fit,,"Hi, any help is appreciated :) I am trying to teach myself statistics. I've watched the Khan Academy Series on Chi square statistic for hypothesis testing ( https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/chi-square-statistic ) After completing the multiple choice quizzes, I wanted to create an example of a usecase from my field and walk through the calculating chi square and determining goodness of fit. Here's the assignment I made for myself: 1. Description of scenario Education manager has historical enrollment data, showing the final student enrollment statuses on average are: 5% - transfer 10% - withdraw 20% - fail 65% - pass Over the past two years, there have been organizational changes, so the manager wants to see if the seemingly improved pass rates are better than what we might expect by random chance, given the known distribution. 2. Sample Size, Does it pass the large counts condition? Sample size will be 100, since that is the smallest sample that allows the expected count of 5 or higher. 3. Observed Counts (statistic) transfer - 1 (1.6) withdraw - 5 (2.5) fail - 10 (5) pass - 84 (5.55) 4. Chi Square Test Statistic $\chi ^{2} = 14.65$ 5. Test of Significance df = 3 $\alpha = 0.05$ critical value = 7.815 $\chi ^{2} = 14.65 > 7.815$ So, the difference between the observed and expected values is significant P-Value $H_0 =$ the sample is from the distribution $H_a =$ the sample is from a different distribution $P = 0.002 < P=0.05$ 6. Conclusion Reject the null hypothesis. The observed scores are not from the same distribution. In plain speak, the differences that I am seeing in enrollment trends are significant. Thank you","Hi, any help is appreciated :) I am trying to teach myself statistics. I've watched the Khan Academy Series on Chi square statistic for hypothesis testing ( https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/chi-square-statistic ) After completing the multiple choice quizzes, I wanted to create an example of a usecase from my field and walk through the calculating chi square and determining goodness of fit. Here's the assignment I made for myself: 1. Description of scenario Education manager has historical enrollment data, showing the final student enrollment statuses on average are: 5% - transfer 10% - withdraw 20% - fail 65% - pass Over the past two years, there have been organizational changes, so the manager wants to see if the seemingly improved pass rates are better than what we might expect by random chance, given the known distribution. 2. Sample Size, Does it pass the large counts condition? Sample size will be 100, since that is the smallest sample that allows the expected count of 5 or higher. 3. Observed Counts (statistic) transfer - 1 (1.6) withdraw - 5 (2.5) fail - 10 (5) pass - 84 (5.55) 4. Chi Square Test Statistic 5. Test of Significance df = 3 critical value = 7.815 So, the difference between the observed and expected values is significant P-Value the sample is from the distribution the sample is from a different distribution 6. Conclusion Reject the null hypothesis. The observed scores are not from the same distribution. In plain speak, the differences that I am seeing in enrollment trends are significant. Thank you",\chi ^{2} = 14.65 \alpha = 0.05 \chi ^{2} = 14.65 > 7.815 H_0 = H_a = P = 0.002 < P=0.05,"['statistics', 'statistical-inference', 'hypothesis-testing', 'chi-squared']"
18,Maximum Likelihood Estimation for Zero-inflated Poisson distribution,Maximum Likelihood Estimation for Zero-inflated Poisson distribution,,"I am trying to do exactly what the title says. What I have is the log-likelihood function as follows: Likelihood function , where $I_i = 1$ when $X_i = 0$, and $I_i = 0$ otherwise. Then I took the partial derivatives of that like this . I tried simplifying this expression to get an equation, but I keep getting nonsense. After searching the web, I found this book but I don't understand how the author arrived at ML equations just from looking at the PGF, can someone help explain that please? There is also this entry but they use a different model from mine (p = probability of Poisson, 1-p = probability of 0, whereas both the first book and my model use p = probability of 0, 1-p = probability of Poisson) and again they don't show the simplification steps so I can't really use that. Thanks for any help.","I am trying to do exactly what the title says. What I have is the log-likelihood function as follows: Likelihood function , where $I_i = 1$ when $X_i = 0$, and $I_i = 0$ otherwise. Then I took the partial derivatives of that like this . I tried simplifying this expression to get an equation, but I keep getting nonsense. After searching the web, I found this book but I don't understand how the author arrived at ML equations just from looking at the PGF, can someone help explain that please? There is also this entry but they use a different model from mine (p = probability of Poisson, 1-p = probability of 0, whereas both the first book and my model use p = probability of 0, 1-p = probability of Poisson) and again they don't show the simplification steps so I can't really use that. Thanks for any help.",,"['statistics', 'estimation', 'maximum-likelihood', 'parameter-estimation']"
19,How can the Central Limit Theorem apply to Finite Populations?,How can the Central Limit Theorem apply to Finite Populations?,,"In my statistics for beginners course we've just been introduced to the CLT, where it's been stated that a distribution of sample means tends to the normal dist. as your sample size $n$ increases to infinity. But what if your population is finite (i.e. of size $N$), so that your max sample size can only be of size $N \ll \infty$? Will such a distribution (which must be that of nearly all practical statistical surveys)not follow the CLT? My best attempt at thoughts on this so far go like this: If I were to take a random sample from my population of size N, each sample though containing just a single member of the pop, calculate and plot the 'mean' of each sample (which would just equal the single value) until I've sampled and plotted every member and done so for each only once, I would eventually of course replicate exactly the population distribution. Suppose then I repeat the experiment, increasing my sample size each repetition, until my sample is of size $N$. I take a single sample, plot its mean, then by definition this is the same as the population mean $\mu$. So here, as my sample size has increased, my distribution of sample means hasn't tended to the Normal - with an ever thinner distribution with flatter tails and a taller peak - but more like a hyper-idealised version of the Normal - a single value at the population mean. Clearly then, for finite populations - if I've understood the idea behind the CLT correctly, which is a big if -the CLT does not apply, rather in these practical cases, their sample mean distribution approaches something approximately Normal? Is it the case then that the CLT is more a theoretical concept, that applies to infinitely large populations, from which samples sizes can tend to infinity? Further to this, I've read for the CLT to apply, the random variables of your population have to be I.I.D - if I'm using SRS without replacement for a finite population, does that mean the variables aren't I.I.D anymore, and thus the CLT would also not apply because of this? If the population were infinite though and I used SRSWOR, would the r.v.'s then be I.I.D, thus meaning the CLT would apply? I appreciate all your insight on this; I'm very new to statistics, so I apologise if a lot of this is pretty basic and if my thoughts were way off. Thanks for any help you can lend, really appreciate it.","In my statistics for beginners course we've just been introduced to the CLT, where it's been stated that a distribution of sample means tends to the normal dist. as your sample size $n$ increases to infinity. But what if your population is finite (i.e. of size $N$), so that your max sample size can only be of size $N \ll \infty$? Will such a distribution (which must be that of nearly all practical statistical surveys)not follow the CLT? My best attempt at thoughts on this so far go like this: If I were to take a random sample from my population of size N, each sample though containing just a single member of the pop, calculate and plot the 'mean' of each sample (which would just equal the single value) until I've sampled and plotted every member and done so for each only once, I would eventually of course replicate exactly the population distribution. Suppose then I repeat the experiment, increasing my sample size each repetition, until my sample is of size $N$. I take a single sample, plot its mean, then by definition this is the same as the population mean $\mu$. So here, as my sample size has increased, my distribution of sample means hasn't tended to the Normal - with an ever thinner distribution with flatter tails and a taller peak - but more like a hyper-idealised version of the Normal - a single value at the population mean. Clearly then, for finite populations - if I've understood the idea behind the CLT correctly, which is a big if -the CLT does not apply, rather in these practical cases, their sample mean distribution approaches something approximately Normal? Is it the case then that the CLT is more a theoretical concept, that applies to infinitely large populations, from which samples sizes can tend to infinity? Further to this, I've read for the CLT to apply, the random variables of your population have to be I.I.D - if I'm using SRS without replacement for a finite population, does that mean the variables aren't I.I.D anymore, and thus the CLT would also not apply because of this? If the population were infinite though and I used SRSWOR, would the r.v.'s then be I.I.D, thus meaning the CLT would apply? I appreciate all your insight on this; I'm very new to statistics, so I apologise if a lot of this is pretty basic and if my thoughts were way off. Thanks for any help you can lend, really appreciate it.",,"['statistics', 'descriptive-statistics']"
20,How to calculate the autocorrelation of a markov chain?,How to calculate the autocorrelation of a markov chain?,,"i want to know how to calculate the autocorrelation of a markov chain (e.g for a simple random walk ). while i was searching online; i found a lecture with a two states {-1,1} markov chain with the following transition matrix  \begin{bmatrix}\alpha&1-\alpha\\1-\alpha&\alpha\end{bmatrix}  the lag-d autocorrelation was given as: $( 2\alpha-1)^d $. i was wandering how they got this answer? I was wandering how to calculate the autocorrelation in general for simple markov chains, or at least for just this simple example","i want to know how to calculate the autocorrelation of a markov chain (e.g for a simple random walk ). while i was searching online; i found a lecture with a two states {-1,1} markov chain with the following transition matrix  \begin{bmatrix}\alpha&1-\alpha\\1-\alpha&\alpha\end{bmatrix}  the lag-d autocorrelation was given as: $( 2\alpha-1)^d $. i was wandering how they got this answer? I was wandering how to calculate the autocorrelation in general for simple markov chains, or at least for just this simple example",,"['statistics', 'markov-chains', 'random-walk', 'correlation']"
21,Distribution of the sample mean of a exponential,Distribution of the sample mean of a exponential,,"I please ask someone to check if my calculations are right. I have $X_1, ..., X_n$ from a $\mathcal{E}(\lambda): f(x, \lambda) = \lambda e^{-\lambda x}$. I have to find the $k$ such that $P(\bar{X} \le k) = \alpha$, where $\bar{X}$ is the sample mean; i did: $$Y=\sum_{i = 1}^{n} X_i$$ $$Y \sim \Gamma (n, \lambda)$$  $$\bar{X} = \frac{1}{n} Y \sim \Gamma(n, \frac{\lambda}{n})$$ $$T = 2\frac{n}{\lambda} \bar{X} \sim \Gamma(\frac{2n}{2}, 2) \stackrel{d}{=}\chi^2 (2n) $$ $$P(\bar{X} \le k) = P(T \le k' = 2\frac{n}{\lambda} k) = \alpha $$ Then i can find the value of $k'$ from the table, and finally find $k$. I'm i missing something? (I can't reach the result stated by the book). Thank you very much.","I please ask someone to check if my calculations are right. I have $X_1, ..., X_n$ from a $\mathcal{E}(\lambda): f(x, \lambda) = \lambda e^{-\lambda x}$. I have to find the $k$ such that $P(\bar{X} \le k) = \alpha$, where $\bar{X}$ is the sample mean; i did: $$Y=\sum_{i = 1}^{n} X_i$$ $$Y \sim \Gamma (n, \lambda)$$  $$\bar{X} = \frac{1}{n} Y \sim \Gamma(n, \frac{\lambda}{n})$$ $$T = 2\frac{n}{\lambda} \bar{X} \sim \Gamma(\frac{2n}{2}, 2) \stackrel{d}{=}\chi^2 (2n) $$ $$P(\bar{X} \le k) = P(T \le k' = 2\frac{n}{\lambda} k) = \alpha $$ Then i can find the value of $k'$ from the table, and finally find $k$. I'm i missing something? (I can't reach the result stated by the book). Thank you very much.",,['statistics']
22,Correlation between two linear sums of random variables,Correlation between two linear sums of random variables,,"I understand how to create random variables with a prespecified correlational structure using a Cholsesky decomposition. But I would like to be able to solve the inverse problem: Given random variables $X_1, X_3, \dots X_n$ ,and two different linear sums of those variables $V_1=a_{11}X_1+a_{12}X_2+\dots a_{1n}X_n$, and  $V_2=a_{21}X_1 + a_{22}X_2 +\dots+a_{2n}X_n$, I wish to calculate the correlation between the $V_1$ and $V_2$. I have searched for terms like ""linear combination random variables correlation"" and have found plenty of material discussing how the correlation affects the variance of the sum of random variables. Unfortunately I have found nothing that seems to relate to the problem described. I would appreciate any information at all, including either an appropriate book chapter or web page reference.","I understand how to create random variables with a prespecified correlational structure using a Cholsesky decomposition. But I would like to be able to solve the inverse problem: Given random variables $X_1, X_3, \dots X_n$ ,and two different linear sums of those variables $V_1=a_{11}X_1+a_{12}X_2+\dots a_{1n}X_n$, and  $V_2=a_{21}X_1 + a_{22}X_2 +\dots+a_{2n}X_n$, I wish to calculate the correlation between the $V_1$ and $V_2$. I have searched for terms like ""linear combination random variables correlation"" and have found plenty of material discussing how the correlation affects the variance of the sum of random variables. Unfortunately I have found nothing that seems to relate to the problem described. I would appreciate any information at all, including either an appropriate book chapter or web page reference.",,"['statistics', 'correlation']"
23,"Find a minimal sufficient statistic for $U(\theta,\theta+c)$, where $(\theta,c)$ unknown.","Find a minimal sufficient statistic for , where  unknown.","U(\theta,\theta+c) (\theta,c)","Suppose $X_1,\cdots,X_n$ are $i.i.d$ from a distribution with p.d.f $$\delta_{(\theta,c)}(x)=\frac{1}{c}\mathbb{1}_{(x\in[\theta,\theta+c])},$$ where $\theta\in\mathbb{R}$ and $c\in\mathbb{R}^+$ unknown. Find a minimal sufficient statistic for $(\theta,c)$ . From the range of $x_i$ , i.e. $x_i\in[\theta,\theta+c]$ , we can determine that $\theta\leq x_i$ and $\theta+c\geq x_i$ , $\forall i\in\{1,\cdots,n\}$ . This implies $$\theta\leq x_{(1)}\text{ and }\theta+c\geq x_{(n)},$$ where $x_{(1)}=\underset{i\in\{1,\cdots,n\}}{\min}x_i$ and $x_{(n)}=\underset{i\in\{1,\cdots,n\}}{\max}x_i$ . The plots shows the area of $\theta\leq x_{(1)}\text{ and }\theta+c\geq x_{(n)}.$ It look like that $(x_{(1)},x_{(n)})$ is a minimal sufficient statistic for $(\theta,c)$ because $(x_{(1)},x_{(n)})$ uniquely determines the shape of the log-likelihood function. Is this correct?","Suppose are from a distribution with p.d.f where and unknown. Find a minimal sufficient statistic for . From the range of , i.e. , we can determine that and , . This implies where and . The plots shows the area of It look like that is a minimal sufficient statistic for because uniquely determines the shape of the log-likelihood function. Is this correct?","X_1,\cdots,X_n i.i.d \delta_{(\theta,c)}(x)=\frac{1}{c}\mathbb{1}_{(x\in[\theta,\theta+c])}, \theta\in\mathbb{R} c\in\mathbb{R}^+ (\theta,c) x_i x_i\in[\theta,\theta+c] \theta\leq x_i \theta+c\geq x_i \forall i\in\{1,\cdots,n\} \theta\leq x_{(1)}\text{ and }\theta+c\geq x_{(n)}, x_{(1)}=\underset{i\in\{1,\cdots,n\}}{\min}x_i x_{(n)}=\underset{i\in\{1,\cdots,n\}}{\max}x_i \theta\leq x_{(1)}\text{ and }\theta+c\geq x_{(n)}. (x_{(1)},x_{(n)}) (\theta,c) (x_{(1)},x_{(n)})","['statistics', 'statistical-inference', 'uniform-distribution']"
24,Finding $n$ using Chebyshev’s inequality,Finding  using Chebyshev’s inequality,n,"The height of a person is a random variable with variance $\leq 5$ square inches. According to Mr. Chebyshev, how many people do we need to sample to ensure that the sample mean is at most $1$ inch away from the distribution mean with probability $\geq 95$ %? According to Chebyshev’s inequality, $$P(|X-\mu| \leq \alpha) \geq \sigma^2/\alpha^2.$$ In my case I have $\alpha=1$ . But I am not able to understand how to apply this formula into the question.","The height of a person is a random variable with variance square inches. According to Mr. Chebyshev, how many people do we need to sample to ensure that the sample mean is at most inch away from the distribution mean with probability %? According to Chebyshev’s inequality, In my case I have . But I am not able to understand how to apply this formula into the question.",\leq 5 1 \geq 95 P(|X-\mu| \leq \alpha) \geq \sigma^2/\alpha^2. \alpha=1,['statistics']
25,What is a bi-affine classifier?,What is a bi-affine classifier?,,"Recently, doing research on NLP papers, I came across with affine classifiers and biaffine classifiers. What is meant by these terms? What are affine classifiers and what are not?","Recently, doing research on NLP papers, I came across with affine classifiers and biaffine classifiers. What is meant by these terms? What are affine classifiers and what are not?",,"['statistics', 'convex-optimization']"
26,Middle School Stats Book mess up?,Middle School Stats Book mess up?,,"I am curious what everyone's thoughts are on the following problem I found in a middle school textbook I am teaching out of. The chapter is on biased and unbiased data samples. Here is the question: To find how much money the average American family spends to cool their home, 100 Alaskan families are surveyed at random. Of these families, 85 said they spend less than 75 dollars per month on cooling. The researcher concluded that the average American family spends less than 75 dollars on cooling per month. Is the conclusion valid? The book states that it is valid because it is a simple, random sample. I would say otherwise considering they surveyed Alaskans and made a generalization about the whole nation. If you were given the options of unbiased simple, random sample, systematic unbiased sample, biased convenience sample, and biased voluntary sample, which would say is a better answer? I'm thinking a convenience sample.","I am curious what everyone's thoughts are on the following problem I found in a middle school textbook I am teaching out of. The chapter is on biased and unbiased data samples. Here is the question: To find how much money the average American family spends to cool their home, 100 Alaskan families are surveyed at random. Of these families, 85 said they spend less than 75 dollars per month on cooling. The researcher concluded that the average American family spends less than 75 dollars on cooling per month. Is the conclusion valid? The book states that it is valid because it is a simple, random sample. I would say otherwise considering they surveyed Alaskans and made a generalization about the whole nation. If you were given the options of unbiased simple, random sample, systematic unbiased sample, biased convenience sample, and biased voluntary sample, which would say is a better answer? I'm thinking a convenience sample.",,['statistics']
27,KL divergence between two multivariate Bernoulli distribution,KL divergence between two multivariate Bernoulli distribution,,"The KL divergence between two Bernoulli distributions is: $$ KL(p||q)_{Ber} = p\log\ \frac{p}{q}\ +\ (1-p)\log\ \frac{1-p}{1-q}   $$ According to my understanding, the KL divergence between two multivariate Bernoulli distributions $p$ and $q$ should be $$ KL(p||q)_{Ber} = \sum_{i=1}^{k} p_i\log\ \frac{p_i}{q_i}\ +\ (1-p_i)\log\ \frac{1-p_i}{1-q_i}   $$ where k is the number of possible outcome. Is this correct?","The KL divergence between two Bernoulli distributions is: $$ KL(p||q)_{Ber} = p\log\ \frac{p}{q}\ +\ (1-p)\log\ \frac{1-p}{1-q}   $$ According to my understanding, the KL divergence between two multivariate Bernoulli distributions $p$ and $q$ should be $$ KL(p||q)_{Ber} = \sum_{i=1}^{k} p_i\log\ \frac{p_i}{q_i}\ +\ (1-p_i)\log\ \frac{1-p_i}{1-q_i}   $$ where k is the number of possible outcome. Is this correct?",,"['statistics', 'probability-distributions', 'machine-learning', 'information-theory']"
28,Finding orthonormal basis within the Aitchison simplex geometry,Finding orthonormal basis within the Aitchison simplex geometry,,"Inside $\mathbb{R}^n$, consider the space $$S_\kappa = \{ x \in \mathbb{R}^n \ | \ \sum_{i=1}^n x_i = \kappa, \ \text{and} \ \ x_i \in (0,1)  \ \text{for all} \ i \in \{1,..,n\}\}.$$ On this simplex, one can define the Aitchison geometry with pertubation (addition), powering (multiplication), and a scalar product (-> norms, distances), which turns it into a ""vector space"". You probably need to know this geometry in order to answer this question. Anyways, within that geometry, how do I go about finding an orthonormal basis, i.e, if $\oplus$ and $\odot$ denote pertubation and powering, then we want to find $e_i$ such that for any $x$ in $S_\kappa$, $x = \bigoplus_{i=1}^n \left( \lambda_i \odot e_i \right)$, where $e_i$ are the basis vectors in $S_\kappa$ which have unit norm and are orthogonal (using the Aitchison scalar product), and $\lambda$s are real constants.","Inside $\mathbb{R}^n$, consider the space $$S_\kappa = \{ x \in \mathbb{R}^n \ | \ \sum_{i=1}^n x_i = \kappa, \ \text{and} \ \ x_i \in (0,1)  \ \text{for all} \ i \in \{1,..,n\}\}.$$ On this simplex, one can define the Aitchison geometry with pertubation (addition), powering (multiplication), and a scalar product (-> norms, distances), which turns it into a ""vector space"". You probably need to know this geometry in order to answer this question. Anyways, within that geometry, how do I go about finding an orthonormal basis, i.e, if $\oplus$ and $\odot$ denote pertubation and powering, then we want to find $e_i$ such that for any $x$ in $S_\kappa$, $x = \bigoplus_{i=1}^n \left( \lambda_i \odot e_i \right)$, where $e_i$ are the basis vectors in $S_\kappa$ which have unit norm and are orthogonal (using the Aitchison scalar product), and $\lambda$s are real constants.",,"['statistics', 'vector-spaces', 'inner-products', 'orthonormal']"
29,Can a reducible Markov chain have an unique stationary distribution? [closed],Can a reducible Markov chain have an unique stationary distribution? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question I know for irreducible and positive recurrent Markov Chain there exists an unique stationary distribution. For Markov Chain with several communication classes (example C1, C2) there exist stationary distributions (linear combination of $ \pi $1 and $ \pi $2). But how about this one, states {1,2,3} can communicate with each other while state {4} can access to other states. $$         \begin{matrix}         0.5 & 0.5 & 0 & 0 \\         0.3 & 0.3 & 0.4 &0 \\         0 & 0.5 & 0.5 & 0 \\         0 & 0 & 0.5 & 0.5 \\         \end{matrix} $$","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question I know for irreducible and positive recurrent Markov Chain there exists an unique stationary distribution. For Markov Chain with several communication classes (example C1, C2) there exist stationary distributions (linear combination of $ \pi $1 and $ \pi $2). But how about this one, states {1,2,3} can communicate with each other while state {4} can access to other states. $$         \begin{matrix}         0.5 & 0.5 & 0 & 0 \\         0.3 & 0.3 & 0.4 &0 \\         0 & 0.5 & 0.5 & 0 \\         0 & 0 & 0.5 & 0.5 \\         \end{matrix} $$",,"['statistics', 'markov-chains', 'stationary-processes']"
30,Update a regression on the fly?,Update a regression on the fly?,,"Say I have 100 people each with a height, weight, and age. I make a regression that predicts age based on height and weight. Now, I would like to update that model when I meet someone new. I don't want to just re-process 101 people though--I want to take the model that I already have and incorporate the new person into it. For example, say that I found from the first 100 that: age = .08*height + .06*weight + 7. Now, I meet someone with age 120 height 56 and weight 34. I do know the number of cases with which I originally made the regression. So, my initial idea was that I could just assume that they all fit the model age = .08*height + .06*weight + 7 and somehow weight the new case so that it takes the old into account (e.g., assume I have 100 people that fit the model, so create a regression equation based on the 100 identical data points and then just add the 101? That's almost just like running the regression again on the 101 data points, except that nothing needs to be stored then, because you could derive 100 from the equation. I would like to do something like this on a large scale, and I don't want to be creating an enormous database of cases, I just want to update the model with each new case.","Say I have 100 people each with a height, weight, and age. I make a regression that predicts age based on height and weight. Now, I would like to update that model when I meet someone new. I don't want to just re-process 101 people though--I want to take the model that I already have and incorporate the new person into it. For example, say that I found from the first 100 that: age = .08*height + .06*weight + 7. Now, I meet someone with age 120 height 56 and weight 34. I do know the number of cases with which I originally made the regression. So, my initial idea was that I could just assume that they all fit the model age = .08*height + .06*weight + 7 and somehow weight the new case so that it takes the old into account (e.g., assume I have 100 people that fit the model, so create a regression equation based on the 100 identical data points and then just add the 101? That's almost just like running the regression again on the 101 data points, except that nothing needs to be stored then, because you could derive 100 from the equation. I would like to do something like this on a large scale, and I don't want to be creating an enormous database of cases, I just want to update the model with each new case.",,"['statistics', 'regression', 'regression-analysis']"
31,Likelihood Ratio Test for Linear Regression,Likelihood Ratio Test for Linear Regression,,"I apologize for the image I am posting below. I am new to StackExchange and I am not yet familiar with the MathJaX equations, so I took a screenshot. Here is my question: Let the independent random variables $Y_1, \ldots , Y_n$ have the following joint pdf where $x_1, \ldots , x_n$ are not all equal. We have the null hypothesis specified below and we want to use a likelihood ratio test to test the null hypothesis against all possible alternative hypotheses.  $$ L(\alpha, \beta, \sigma ^ 2) = \left(\frac{1}{2 \pi \sigma ^ 2} \right) ^ {n / 2} \exp\left\{-\frac{1}{2 \sigma ^ 2} \sum_{i = 1}^n \left[y_i - \alpha - \beta (x_i - \bar x)\right] ^ 2 \right\} $$ $$ H_0: \beta = 0 \text{ ($\alpha$ and $\sigma^2$) unknown} $$ The question asks to find a the likelihood test statistic and check to see if it can be based on a familiar test statistics. So far, all I know is that I believe it will be based on a $T$-statistic, but I do not know how to show this.","I apologize for the image I am posting below. I am new to StackExchange and I am not yet familiar with the MathJaX equations, so I took a screenshot. Here is my question: Let the independent random variables $Y_1, \ldots , Y_n$ have the following joint pdf where $x_1, \ldots , x_n$ are not all equal. We have the null hypothesis specified below and we want to use a likelihood ratio test to test the null hypothesis against all possible alternative hypotheses.  $$ L(\alpha, \beta, \sigma ^ 2) = \left(\frac{1}{2 \pi \sigma ^ 2} \right) ^ {n / 2} \exp\left\{-\frac{1}{2 \sigma ^ 2} \sum_{i = 1}^n \left[y_i - \alpha - \beta (x_i - \bar x)\right] ^ 2 \right\} $$ $$ H_0: \beta = 0 \text{ ($\alpha$ and $\sigma^2$) unknown} $$ The question asks to find a the likelihood test statistic and check to see if it can be based on a familiar test statistics. So far, all I know is that I believe it will be based on a $T$-statistic, but I do not know how to show this.",,"['statistics', 'hypothesis-testing']"
32,Integrate the likelihood function,Integrate the likelihood function,,"We know that for a density function $f(x\mid\theta)$ we have  $$\int^{\infty}_{-\infty}f(x\mid\theta)\, dx=1$$ Do we also have for the likelihood function $L(\theta\mid x)$ that $$\int^{\infty}_{-\infty}L(\theta\mid x)\, d\theta=1?$$ My guess is yes, since $L(\theta\mid x)$ is some kind of ""possibility"" of the parameter that under different data. Thanks~","We know that for a density function $f(x\mid\theta)$ we have  $$\int^{\infty}_{-\infty}f(x\mid\theta)\, dx=1$$ Do we also have for the likelihood function $L(\theta\mid x)$ that $$\int^{\infty}_{-\infty}L(\theta\mid x)\, d\theta=1?$$ My guess is yes, since $L(\theta\mid x)$ is some kind of ""possibility"" of the parameter that under different data. Thanks~",,"['statistics', 'statistical-inference', 'density-function', 'maximum-likelihood']"
33,"""reverse birthday problem"" - inferring days in the year from collisions in sample [duplicate]","""reverse birthday problem"" - inferring days in the year from collisions in sample [duplicate]",,"This question already has an answer here : Magic 8 Ball Problem (1 answer) Closed 6 years ago . Say you have n randomly selected students from another planet whose birthdays are known. x of them have birthdays that collide with at least one other student. How do you estimate the number of days in their year? Alternatively, perhaps you can use the fact that you know these n students have $x_1$ birthday collision pairs, $x_2$ birthday collision triplets and so on. How could the number of days in their year be estimated from that? Edit for context : I am building a framework where teachers can build small programs to procedurally generate math questions and I would like to show them an estimation of how many actual questions they are generating. I can sample their program a bunch of times to get different questions and check if I have seen them before (birthday collisions). Of course immediately after giving up and posting here I realize that $x_1$, $x_2$ etc mentioned above would give me a binomial distribution where if I can get P, I beleive the ""population size"" should be 1/P. I am trying this approach right now and will sanity check and compare to wolfram alpha. Also please be gentle, I'm just a programmer, I don't really know what I am doing.","This question already has an answer here : Magic 8 Ball Problem (1 answer) Closed 6 years ago . Say you have n randomly selected students from another planet whose birthdays are known. x of them have birthdays that collide with at least one other student. How do you estimate the number of days in their year? Alternatively, perhaps you can use the fact that you know these n students have $x_1$ birthday collision pairs, $x_2$ birthday collision triplets and so on. How could the number of days in their year be estimated from that? Edit for context : I am building a framework where teachers can build small programs to procedurally generate math questions and I would like to show them an estimation of how many actual questions they are generating. I can sample their program a bunch of times to get different questions and check if I have seen them before (birthday collisions). Of course immediately after giving up and posting here I realize that $x_1$, $x_2$ etc mentioned above would give me a binomial distribution where if I can get P, I beleive the ""population size"" should be 1/P. I am trying this approach right now and will sanity check and compare to wolfram alpha. Also please be gentle, I'm just a programmer, I don't really know what I am doing.",,"['statistics', 'birthday']"
34,square root of covariance of two variables,square root of covariance of two variables,,"I know that if you calculate variance, you can square root it to get the standard deviation. What does it mean / what is it called if you square root a scalar value which is the covariance of two variables?","I know that if you calculate variance, you can square root it to get the standard deviation. What does it mean / what is it called if you square root a scalar value which is the covariance of two variables?",,['statistics']
35,Dropping a Lowest Score,Dropping a Lowest Score,,"I have a lab class, where I drop the lowest score students receive, easy enough. Except, all items are not weighted equally,  (lab A might be worth 10 points, while lab B might be worth 23 points, and so on). Right now, what I do in an excel file is calculate the total points earned and the maximum points, except in each instance I remove a different assignment from the calculation. Then compare the various percentages and drop the one that yields the highest overall percentage. TL;DR, here is the main question part ;) Is this a problem that can be solved more easily, or can I answer the question of which to drop with a formula? I'd love to include the calculation in my grade book so it happens automatically. Right now, I have to go in and drop an assignment manually for each student, since my only option is to drop ""lowest score"" which doesn't work since 5/10 has a different impact than 3/30. (I realize I could scale everything and make them all worth the same amount, but that complicates other parts of the grade for me, so isn't ideal) I've included a screen shot of what I do in excel for hopeful clarity. The bottom three rows are what I look at. Total Score w/o: Total earned points (from row 2) without the lab corresponding to that column Total Max w/o: Total maximum points possible (from row 3) without the lab corresponding to that column Combined Percent w/o: Just the values from $\displaystyle\frac{\text{Total Score w/o}}{\text{Max Score w/o}}$ for each column. I have conditional highlighting which shows me the highest percentage, so in this case, I would drop the student ""Hydrate"" lab assignment from their grade. *Note: I will confess I really wasn't sure what tags I should use. This stackexchange is way out of my comfort zone, so most terms were not familiar. Feel free to change them to whatever is most appropriate.","I have a lab class, where I drop the lowest score students receive, easy enough. Except, all items are not weighted equally,  (lab A might be worth 10 points, while lab B might be worth 23 points, and so on). Right now, what I do in an excel file is calculate the total points earned and the maximum points, except in each instance I remove a different assignment from the calculation. Then compare the various percentages and drop the one that yields the highest overall percentage. TL;DR, here is the main question part ;) Is this a problem that can be solved more easily, or can I answer the question of which to drop with a formula? I'd love to include the calculation in my grade book so it happens automatically. Right now, I have to go in and drop an assignment manually for each student, since my only option is to drop ""lowest score"" which doesn't work since 5/10 has a different impact than 3/30. (I realize I could scale everything and make them all worth the same amount, but that complicates other parts of the grade for me, so isn't ideal) I've included a screen shot of what I do in excel for hopeful clarity. The bottom three rows are what I look at. Total Score w/o: Total earned points (from row 2) without the lab corresponding to that column Total Max w/o: Total maximum points possible (from row 3) without the lab corresponding to that column Combined Percent w/o: Just the values from $\displaystyle\frac{\text{Total Score w/o}}{\text{Max Score w/o}}$ for each column. I have conditional highlighting which shows me the highest percentage, so in this case, I would drop the student ""Hydrate"" lab assignment from their grade. *Note: I will confess I really wasn't sure what tags I should use. This stackexchange is way out of my comfort zone, so most terms were not familiar. Feel free to change them to whatever is most appropriate.",,['statistics']
36,Variance of Coefficients in a Simple Linear Regression,Variance of Coefficients in a Simple Linear Regression,,"I have a linear regression model $\hat{y_i}=\hat{\beta_0}+\hat{\beta_1}x_i+\hat{\epsilon_i}$, where $\hat{\beta_0}$ and $\hat{\beta_1}$ are normally distributed unbiased estimators, and $\hat{\epsilon_i}$ is Normal with mean $0$ and variance $\sigma^2$.  I need to show that $$\operatorname{Var}\left(\hat{\beta_0}\right)=\frac{\sigma^2\sum_{i=1}^nx_i^2}{n\sum_{i=1}^n\left(x_i-\bar{x}\right)^2}$$ $$\operatorname{Var}\left(\hat{\beta_1}\right)=\frac{\sigma^2}{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2}$$ and $$\operatorname{cov}\left(\hat{\beta_0},\hat{\beta_1}\right)=\frac{-\sigma^2\sum_{i=1}^nx_i}{n\sum_{i=1}^n\left(x_i-\bar{x}\right)^2}$$ Can anyone help me out? Thanks.","I have a linear regression model $\hat{y_i}=\hat{\beta_0}+\hat{\beta_1}x_i+\hat{\epsilon_i}$, where $\hat{\beta_0}$ and $\hat{\beta_1}$ are normally distributed unbiased estimators, and $\hat{\epsilon_i}$ is Normal with mean $0$ and variance $\sigma^2$.  I need to show that $$\operatorname{Var}\left(\hat{\beta_0}\right)=\frac{\sigma^2\sum_{i=1}^nx_i^2}{n\sum_{i=1}^n\left(x_i-\bar{x}\right)^2}$$ $$\operatorname{Var}\left(\hat{\beta_1}\right)=\frac{\sigma^2}{\sum_{i=1}^n\left(x_i-\bar{x}\right)^2}$$ and $$\operatorname{cov}\left(\hat{\beta_0},\hat{\beta_1}\right)=\frac{-\sigma^2\sum_{i=1}^nx_i}{n\sum_{i=1}^n\left(x_i-\bar{x}\right)^2}$$ Can anyone help me out? Thanks.",,"['statistics', 'regression']"
37,Generously Feasible?,Generously Feasible?,,"In my machine learning class I have been provided a weight vector that has the property that it is generously feasible ? Formally, what does generously feasible mean?  I can't seem to find a definition?","In my machine learning class I have been provided a weight vector that has the property that it is generously feasible ? Formally, what does generously feasible mean?  I can't seem to find a definition?",,"['statistics', 'terminology']"
38,Why does sample standard deviation underestimate population standard deviation?,Why does sample standard deviation underestimate population standard deviation?,,"Refering to this wikipedia page Unbiased estimation of standard deviation , it says that ""it follows from Jensen's inequality that the square root of the sample variance is an underestimate"". I do know that for the concave square root function, Jensen's inequality says that the square root of the mean > mean of the square root. So, how do we conclude that the square root of the sample variance underestimates population standard deviation? Since we know from Jensen's inequality that square root of the mean > mean of the square root, does ""square root of sample variance"" somehow relate to ""mean of the square root"" while ""population standard deviation"" somehow relates to ""square root of the mean""? Added after joriki's response: Given joriki's response about using a single sampling of data, I am now left with why $s=\sqrt{\frac{1}{N-1}\sum_{i=1}^N{(x_i-\overline{x})^2}}$ will underestimate pop std dev.  In order to use Jensen's inequality (mean of the square root < square root of the mean).  I need to somehow relate the expression for $s$ to ""mean of square root"".  I do see the square root sign in the expression for $s$ but where is the ""mean"" of this square root quantity?","Refering to this wikipedia page Unbiased estimation of standard deviation , it says that ""it follows from Jensen's inequality that the square root of the sample variance is an underestimate"". I do know that for the concave square root function, Jensen's inequality says that the square root of the mean > mean of the square root. So, how do we conclude that the square root of the sample variance underestimates population standard deviation? Since we know from Jensen's inequality that square root of the mean > mean of the square root, does ""square root of sample variance"" somehow relate to ""mean of the square root"" while ""population standard deviation"" somehow relates to ""square root of the mean""? Added after joriki's response: Given joriki's response about using a single sampling of data, I am now left with why $s=\sqrt{\frac{1}{N-1}\sum_{i=1}^N{(x_i-\overline{x})^2}}$ will underestimate pop std dev.  In order to use Jensen's inequality (mean of the square root < square root of the mean).  I need to somehow relate the expression for $s$ to ""mean of square root"".  I do see the square root sign in the expression for $s$ but where is the ""mean"" of this square root quantity?",,['statistics']
39,"Complete statistic for Normal Distribution $\mathcal{N}(\mu, \mu^2)$",Complete statistic for Normal Distribution,"\mathcal{N}(\mu, \mu^2)","We call a ""curved"" normal if its distribution is $\mathcal{N}(\mu, \mu^2), \mu > 0$ . Then a ""curved"" normal has pdf $$       \left(\dfrac{1}{2\pi \mu^2}\right)^{\frac{1}{2}}e^{\frac{-1}{2\mu^2}(x - \mu)^2} $$ Here we can rewrite this pdf as $e^{t(x)^T \eta(\mu) - \epsilon(\mu)}h(x)$ where $t(x) = (x, x^2), \eta(\mu) = \left(\dfrac{1}{\mu}, \dfrac{-1}{2\mu^2}\right), \epsilon(\mu) = \dfrac{1}{2}[1 + \ln(2\pi \mu^2)]$ and $h(x) = 1$ . Hence, ""curved"" normal belongs to exponential distribution. This leads me to the conclusion that statistic $$        T(\mathbf{X}) = \left(\displaystyle\sum_{i = 1}^{n} X_i, \displaystyle\sum_{i = 1}^{n} X_i^2\right) $$ is complete sufficient statistic for parameter $\mu$ , given $\mathbf{X} = (X_1, X_2, \cdots, X_n)$ is a random sample of size $n$ draw from this distribution However , we have that $$        \mathbb{E}\left[\dfrac{1}{n}\displaystyle\sum_{i = 1}^{n} X_i^2 - 2S_n^2\right] = (\mu^2 + \mu^2) - 2\mu^2 = 0 $$ where $S_n^2$ is sample variance. Hence, $T(\mathbf{X})$ cannot be complete statistic (contradict to previous statement) So my question is what is wrong with my logic ? Any help is appreciated, thanks!","We call a ""curved"" normal if its distribution is . Then a ""curved"" normal has pdf Here we can rewrite this pdf as where and . Hence, ""curved"" normal belongs to exponential distribution. This leads me to the conclusion that statistic is complete sufficient statistic for parameter , given is a random sample of size draw from this distribution However , we have that where is sample variance. Hence, cannot be complete statistic (contradict to previous statement) So my question is what is wrong with my logic ? Any help is appreciated, thanks!","\mathcal{N}(\mu, \mu^2), \mu > 0 
      \left(\dfrac{1}{2\pi \mu^2}\right)^{\frac{1}{2}}e^{\frac{-1}{2\mu^2}(x - \mu)^2}
 e^{t(x)^T \eta(\mu) - \epsilon(\mu)}h(x) t(x) = (x, x^2), \eta(\mu) = \left(\dfrac{1}{\mu}, \dfrac{-1}{2\mu^2}\right), \epsilon(\mu) = \dfrac{1}{2}[1 + \ln(2\pi \mu^2)] h(x) = 1 
       T(\mathbf{X}) = \left(\displaystyle\sum_{i = 1}^{n} X_i, \displaystyle\sum_{i = 1}^{n} X_i^2\right)
 \mu \mathbf{X} = (X_1, X_2, \cdots, X_n) n 
       \mathbb{E}\left[\dfrac{1}{n}\displaystyle\sum_{i = 1}^{n} X_i^2 - 2S_n^2\right] = (\mu^2 + \mu^2) - 2\mu^2 = 0
 S_n^2 T(\mathbf{X})","['statistics', 'probability-distributions', 'normal-distribution']"
40,"Minimal Sufficient statistic for Uniform($\theta, \theta+1$)",Minimal Sufficient statistic for Uniform(),"\theta, \theta+1","We have that $\mathbf{X}$ is a random sample from Uniform$(\theta, \theta+1)$ and we want to find a sufficient statistic for $\theta$ and the determine whether it is minimal. The likelihood function is given by $$ L(\mathbf{x}| \theta) =  \prod \mathbf{1} [ \theta < x_i < \theta+1] = \mathbf{1} [\min (\mathbf{x}) > \theta] \mathbf{1} [\max (\mathbf{x}) < \theta+1]$$ so that by Neyman-Pearson factorization theorem, $T(\mathbf{X}) = (m,M)$ where $m := m (\mathbf{X})$ and $M := M(\mathbf{X})$ are the minimum and the maximum of $\mathbf{X}$, respectively. Now we want to determine whether the statistic is minimal. Despite the rule of thumb, (that if the dimension of the statistic is greater than the dimension of the parameter, then the statistic is not minimal), I have the hunch that the statistic is actually minimal. So we proceed by definition: A statistic $T$ is minimal sufficient if the ratio $f_θ(x)/f_θ(y)$ does not depend on $\theta$ if and only if $T(x) = T(y)$. In order to skirt any indeterminacy problems, we can take the first condition to be $f_\theta (x) = k(x,y) f_\theta (y)$. It is here that I get stuck.","We have that $\mathbf{X}$ is a random sample from Uniform$(\theta, \theta+1)$ and we want to find a sufficient statistic for $\theta$ and the determine whether it is minimal. The likelihood function is given by $$ L(\mathbf{x}| \theta) =  \prod \mathbf{1} [ \theta < x_i < \theta+1] = \mathbf{1} [\min (\mathbf{x}) > \theta] \mathbf{1} [\max (\mathbf{x}) < \theta+1]$$ so that by Neyman-Pearson factorization theorem, $T(\mathbf{X}) = (m,M)$ where $m := m (\mathbf{X})$ and $M := M(\mathbf{X})$ are the minimum and the maximum of $\mathbf{X}$, respectively. Now we want to determine whether the statistic is minimal. Despite the rule of thumb, (that if the dimension of the statistic is greater than the dimension of the parameter, then the statistic is not minimal), I have the hunch that the statistic is actually minimal. So we proceed by definition: A statistic $T$ is minimal sufficient if the ratio $f_θ(x)/f_θ(y)$ does not depend on $\theta$ if and only if $T(x) = T(y)$. In order to skirt any indeterminacy problems, we can take the first condition to be $f_\theta (x) = k(x,y) f_\theta (y)$. It is here that I get stuck.",,['statistics']
41,Uniformly Most Powerful Test for a Uniform Sample,Uniformly Most Powerful Test for a Uniform Sample,,"Let $X_{1}, \dots, X_{n}$ be a sample from $U(0,\theta), \theta > 0$ (uniform distribution). Show that the test: $\phi_{1}(x_{1},\dots,x_{n})=\begin{cases} 1 &\mbox{if } \max(x_{1},\dots,x_{n}) > \theta_{0} \quad or \quad \max(x_{1},\dots,x_{n}) \leq \alpha^{1/n}\theta_{0}\\  0 & \mbox{else } \end{cases}$ Is the UMP (uniformly most powerful test) of size $\alpha$ for testing $H_{0}:\theta = \theta_{0}$ against $H_{1}:\theta \neq \theta_{0}$ I know that the statistic $T$ given by $T(x_{1},\dots,x_{n})=\max(x_{1},\dots,x_{n})$ has the property that $U(0,\theta)$ has an MLR (monotone likelihood ratio) property in $T$. Then, by the Karlin-Rubin Theorem we get a test for $H_{0}: \theta \leq  \theta_{0}$ against $H_{1}: \theta > \theta_{0}$, of the form $\phi(x)=1$ if $x > x_{0}$ and $0$ if $x < x_{0}$, for $x_{0}$ chosen such that $E_{\theta_{0}}(\phi(x))=\alpha$ However, the Karlin-Rubin Theorem does not give an UMP of the form as specified in the problem. What would be a way to approach this problem? I'm completely lost. Thanks for the help!","Let $X_{1}, \dots, X_{n}$ be a sample from $U(0,\theta), \theta > 0$ (uniform distribution). Show that the test: $\phi_{1}(x_{1},\dots,x_{n})=\begin{cases} 1 &\mbox{if } \max(x_{1},\dots,x_{n}) > \theta_{0} \quad or \quad \max(x_{1},\dots,x_{n}) \leq \alpha^{1/n}\theta_{0}\\  0 & \mbox{else } \end{cases}$ Is the UMP (uniformly most powerful test) of size $\alpha$ for testing $H_{0}:\theta = \theta_{0}$ against $H_{1}:\theta \neq \theta_{0}$ I know that the statistic $T$ given by $T(x_{1},\dots,x_{n})=\max(x_{1},\dots,x_{n})$ has the property that $U(0,\theta)$ has an MLR (monotone likelihood ratio) property in $T$. Then, by the Karlin-Rubin Theorem we get a test for $H_{0}: \theta \leq  \theta_{0}$ against $H_{1}: \theta > \theta_{0}$, of the form $\phi(x)=1$ if $x > x_{0}$ and $0$ if $x < x_{0}$, for $x_{0}$ chosen such that $E_{\theta_{0}}(\phi(x))=\alpha$ However, the Karlin-Rubin Theorem does not give an UMP of the form as specified in the problem. What would be a way to approach this problem? I'm completely lost. Thanks for the help!",,"['statistics', 'probability-distributions', 'hypothesis-testing']"
42,How to estimate of coefficients of logistic model,How to estimate of coefficients of logistic model,,"Consider model $logit(p)=a+bx$. I would like to get a analytic formula of $a$ and $b$ like in linear regression. In linear regression, we can get a formula of estimates of $a$ and $b$. I tried using MLE to estimate it. But it is too complicated for me.","Consider model $logit(p)=a+bx$. I would like to get a analytic formula of $a$ and $b$ like in linear regression. In linear regression, we can get a formula of estimates of $a$ and $b$. I tried using MLE to estimate it. But it is too complicated for me.",,"['statistics', 'logistic-regression']"
43,Statistics: Why do we divide by $\sqrt{n}$ for sample standard deviation,Statistics: Why do we divide by  for sample standard deviation,\sqrt{n},"Can someone tell me if my explanations/understanding is on the right track? Suppose we have a set of variances, each of them identical, where $V_{1}(x) + V_{2}(x) + ...+ V_{j}(x) = \sigma^2$. If we wanted to take $\frac{1}{n}$-th ($n \leq j$) of the variances we would have $\frac{\sigma^2}{n}$, taking the square root this becomes $\frac{\sigma}{\sqrt{n}}$ My other idea is to let $V_{1}(x) = V_{2}(x) = ...=V_{j}(x) = \sigma^2$ so summing these all together we would get $j\sigma^2$ so the standard deviation is $\sqrt{j} \sigma$ and taking the average we would get $\frac{\sigma}{\sqrt{j}}$","Can someone tell me if my explanations/understanding is on the right track? Suppose we have a set of variances, each of them identical, where $V_{1}(x) + V_{2}(x) + ...+ V_{j}(x) = \sigma^2$. If we wanted to take $\frac{1}{n}$-th ($n \leq j$) of the variances we would have $\frac{\sigma^2}{n}$, taking the square root this becomes $\frac{\sigma}{\sqrt{n}}$ My other idea is to let $V_{1}(x) = V_{2}(x) = ...=V_{j}(x) = \sigma^2$ so summing these all together we would get $j\sigma^2$ so the standard deviation is $\sqrt{j} \sigma$ and taking the average we would get $\frac{\sigma}{\sqrt{j}}$",,['statistics']
44,A value has 'reduced by factor of 3'. Does this make mathematical sense?,A value has 'reduced by factor of 3'. Does this make mathematical sense?,,"I'm just reading some statistics. Last year there were 3000 observations, this year there are only 1000.  This is described as showing a ""fall by a factor of 3"". This phrase doesn't ring true.  If a factor of 3 is a 1/3, then a fall by a third would be down to 2000.  So the phrase is meant to represent a fall to a third. Am I right in thinking the phrase 'by a factor of' can only refer to an increase?","I'm just reading some statistics. Last year there were 3000 observations, this year there are only 1000.  This is described as showing a ""fall by a factor of 3"". This phrase doesn't ring true.  If a factor of 3 is a 1/3, then a fall by a third would be down to 2000.  So the phrase is meant to represent a fall to a third. Am I right in thinking the phrase 'by a factor of' can only refer to an increase?",,['statistics']
45,How many types of mathematical information are there?,How many types of mathematical information are there?,,"I am aware of at least two types of mathematical information: Shannon Information, which is the negative of entropy (i.e. a loss of entropy by $n$ bits is precisely a gain of Shannon information of $n$ bits). One also has mutual and conditional information of two random variables, and information theory is named for this type. Fisher information. This type is apparently very commonly used and considered in statistics, to the best of my limited knowledge. It is also supposed to be the source of the name for information geometry (since the Fisher information metric is the Riemannian metric). My question: Are there any other mathematical concepts of information which I am missing? How many types of mathematical information exist?","I am aware of at least two types of mathematical information: Shannon Information, which is the negative of entropy (i.e. a loss of entropy by $n$ bits is precisely a gain of Shannon information of $n$ bits). One also has mutual and conditional information of two random variables, and information theory is named for this type. Fisher information. This type is apparently very commonly used and considered in statistics, to the best of my limited knowledge. It is also supposed to be the source of the name for information geometry (since the Fisher information metric is the Riemannian metric). My question: Are there any other mathematical concepts of information which I am missing? How many types of mathematical information exist?",,"['statistics', 'terminology', 'information-theory', 'information-geometry', 'fisher-information']"
46,"Same mean, different standard deviation in data sets","Same mean, different standard deviation in data sets",,"How would a data set containing the values of a variable with a mean of 50 and a standard deviation of 3 compare with another data set containing the same variable, but a mean of 50 and a standard deviation of 12?","How would a data set containing the values of a variable with a mean of 50 and a standard deviation of 3 compare with another data set containing the same variable, but a mean of 50 and a standard deviation of 12?",,['statistics']
47,"Density function of $\max(X_1,\dots,X_n)$.",Density function of .,"\max(X_1,\dots,X_n)","I'm making this statistics exercise and I'm not sure about my solution. Find the density function of $Y=\max(X_1,\dots,X_n)$ if they are all i.i.d. This was my take on this question: $F_Y(a)=P(X_1 \leq a, \dots, X_n \leq a)$. Using that they are independent this gives $F_Y(a)=P(X_1 \leq a) \cdot P(X_2 \leq a) \dots P(X_n \leq a)= (P(X_1 \leq a))^n= (F_{X_1}(a))^n$. So the density function is $f_Y(x)= \frac{\partial F_Y(x)}{\partial x}= n\cdot f_{X_1}(x) \cdot F_{X_1}^{n-1}(x)$. What do you think of this argument? How would you calculate $E[Y]$? Thanks!","I'm making this statistics exercise and I'm not sure about my solution. Find the density function of $Y=\max(X_1,\dots,X_n)$ if they are all i.i.d. This was my take on this question: $F_Y(a)=P(X_1 \leq a, \dots, X_n \leq a)$. Using that they are independent this gives $F_Y(a)=P(X_1 \leq a) \cdot P(X_2 \leq a) \dots P(X_n \leq a)= (P(X_1 \leq a))^n= (F_{X_1}(a))^n$. So the density function is $f_Y(x)= \frac{\partial F_Y(x)}{\partial x}= n\cdot f_{X_1}(x) \cdot F_{X_1}^{n-1}(x)$. What do you think of this argument? How would you calculate $E[Y]$? Thanks!",,"['statistics', 'random-variables']"
48,"Minimal Sufficient Statistic for $f(x) = e^{-(x-\theta)}, \; \theta < x < \infty, \; x \in \mathbb{R}$",Minimal Sufficient Statistic for,"f(x) = e^{-(x-\theta)}, \; \theta < x < \infty, \; x \in \mathbb{R}","My question comes from Exercise 6.9(b) of Statistical Inference by Casella and Berger: 6.9: Find a minimal sufficient statistic for $\theta$ (b) $f(x|\theta) = e^{-(x-\theta)}, \quad \theta < x < \infty, \quad -\infty < \theta < \infty$ . This exercise appears to be a straighforward application of the following theorem: Theorem 6.2.13. Let $f(\mathbf{x}|\theta)$ be the pmf or pdf of a sample $\mathbf{X}$ . Suppose there exists a function $T(\mathbf{x})$ such that, for every two sample points $\mathbf{x}$ and $\mathbf{y}$ , the ratio $f(\mathbf{x}|\theta)/f(\mathbf{y}|\theta)$ is constant as a function of $\theta$ if and only if $T(\mathbf{x}) = T(\mathbf{y})$ . Then $T(\mathbf{X})$ is a minimal sufficient statistic for $\theta$ . A little algebra shows that $$\frac{f(\mathbf{x}|\theta)}{f(\mathbf{y}|\theta)} = \exp\left(\sum_{i=1}^{n} (y_i - x_i) \right) \frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})}$$ for all $\mathbf{x},\mathbf{y} \in (\theta,\infty)^n$ . Now it's clear that the desired implication "" $f(\mathbf{x}|\theta)/f(\mathbf{y}|\theta)$ is constant as a function of $\theta$ if and only if $T(\mathbf{x}) = T(\mathbf{y})$ "" depends solely upon the above ratio of indicator functions. If $\mathbf{x}_{(1)} = \mathbf{y}_{(1)}$ , then $\frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})} = 1$ for all $\theta \in (-\infty, \mathbf{y}_{(1)})$ (and undefined on $[\mathbf{y_{(1)}},\infty)$ ), so the ratio is constant in $\theta$ for all $\theta$ where it is defined. And if $\mathbf{x}_{(1)} < \mathbf{y}_{(1)}$ , then \begin{align*} 				\frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})} &= 				\begin{cases} 					1 & \text{ if } \theta \in (-\infty,\mathbf{x}_{(1)}) \\[2pt] 					0 & \text{ if } \theta \in [\mathbf{x}_{(1)},\mathbf{y}_{(1)}) 				\end{cases} 			\end{align*} (and is undefined for $\theta \geq \mathbf{y}_{(1)}$ ), so in this case the ratio clearly depends on $\theta$ .  But if $\mathbf{y}_{(1)} < \mathbf{x}_{(1)}$ , then $\frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})} = 1$ for all $\theta < \mathbf{y}_{(1)}$ (and undefined everywhere else). If the ratio is constant as a function of $\theta$ if and only if $\mathbf{x}_{(1)} = \mathbf{y}_{(1)}$ , then we can straightforwardly conclude that $T(\mathbf{X}_{(1)})$ is a minimal sufficient statistic. But in the case where $\mathbf{y}_{(1)} < \mathbf{x}_{(1)}$ , is the ratio of indicator functions considered to be constant as a function of $\theta$ ? Why or why not? Any feedback would be appreciated. Edit 2/23/22: As @Henry mentioned in the comments, the situation is clarified if we change the part of the theorem that says the ratio $f(\mathbf{x}|\theta)/f(\mathbf{y}|\theta)$ is constant as a function of $\theta$ to the new statement there exists some $k(\mathbf{x},\mathbf{y}) > 0$ (a strictly positive function which does not depend on $\theta$ ) such that $f(\mathbf{x}∣\theta)=k(\mathbf{x},\mathbf{y})f(\mathbf{y}∣\theta)$ for all $\mathbf{x}, \mathbf{y}$ in the sample space and all $\theta \in \Theta$ . I would just like some ""official"" confirmation of this in the form of a theorem in a textbook. Any relevant references would be greatly appreciated.","My question comes from Exercise 6.9(b) of Statistical Inference by Casella and Berger: 6.9: Find a minimal sufficient statistic for (b) . This exercise appears to be a straighforward application of the following theorem: Theorem 6.2.13. Let be the pmf or pdf of a sample . Suppose there exists a function such that, for every two sample points and , the ratio is constant as a function of if and only if . Then is a minimal sufficient statistic for . A little algebra shows that for all . Now it's clear that the desired implication "" is constant as a function of if and only if "" depends solely upon the above ratio of indicator functions. If , then for all (and undefined on ), so the ratio is constant in for all where it is defined. And if , then (and is undefined for ), so in this case the ratio clearly depends on .  But if , then for all (and undefined everywhere else). If the ratio is constant as a function of if and only if , then we can straightforwardly conclude that is a minimal sufficient statistic. But in the case where , is the ratio of indicator functions considered to be constant as a function of ? Why or why not? Any feedback would be appreciated. Edit 2/23/22: As @Henry mentioned in the comments, the situation is clarified if we change the part of the theorem that says the ratio is constant as a function of to the new statement there exists some (a strictly positive function which does not depend on ) such that for all in the sample space and all . I would just like some ""official"" confirmation of this in the form of a theorem in a textbook. Any relevant references would be greatly appreciated.","\theta f(x|\theta) = e^{-(x-\theta)}, \quad \theta < x < \infty, \quad -\infty < \theta < \infty f(\mathbf{x}|\theta) \mathbf{X} T(\mathbf{x}) \mathbf{x} \mathbf{y} f(\mathbf{x}|\theta)/f(\mathbf{y}|\theta) \theta T(\mathbf{x}) = T(\mathbf{y}) T(\mathbf{X}) \theta \frac{f(\mathbf{x}|\theta)}{f(\mathbf{y}|\theta)} = \exp\left(\sum_{i=1}^{n} (y_i - x_i) \right) \frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})} \mathbf{x},\mathbf{y} \in (\theta,\infty)^n f(\mathbf{x}|\theta)/f(\mathbf{y}|\theta) \theta T(\mathbf{x}) = T(\mathbf{y}) \mathbf{x}_{(1)} = \mathbf{y}_{(1)} \frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})} = 1 \theta \in (-\infty, \mathbf{y}_{(1)}) [\mathbf{y_{(1)}},\infty) \theta \theta \mathbf{x}_{(1)} < \mathbf{y}_{(1)} \begin{align*}
				\frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})} &=
				\begin{cases}
					1 & \text{ if } \theta \in (-\infty,\mathbf{x}_{(1)}) \\[2pt]
					0 & \text{ if } \theta \in [\mathbf{x}_{(1)},\mathbf{y}_{(1)})
				\end{cases}
			\end{align*} \theta \geq \mathbf{y}_{(1)} \theta \mathbf{y}_{(1)} < \mathbf{x}_{(1)} \frac{I_{(\theta,\infty)}(\mathbf{x}_{(1)})}{ I_{(\theta,\infty)}(\mathbf{y}_{(1)})} = 1 \theta < \mathbf{y}_{(1)} \theta \mathbf{x}_{(1)} = \mathbf{y}_{(1)} T(\mathbf{X}_{(1)}) \mathbf{y}_{(1)} < \mathbf{x}_{(1)} \theta f(\mathbf{x}|\theta)/f(\mathbf{y}|\theta) \theta k(\mathbf{x},\mathbf{y}) > 0 \theta f(\mathbf{x}∣\theta)=k(\mathbf{x},\mathbf{y})f(\mathbf{y}∣\theta) \mathbf{x}, \mathbf{y} \theta \in \Theta","['statistics', 'statistical-inference', 'sufficient-statistics']"
49,Seasonal adjustment and Fourier analysis,Seasonal adjustment and Fourier analysis,,"I've been reading up on seasonal adjustment (removing ""seasonal"" periodic components from a time series) recently and although I see a lot of fancy work around ARIMA models and fancy ways to detect the seasonality, I see comparatively little work on moving to the frequency domain and looking at series with Fourier transforms or wavelets or anything along those lines. There are some older papers on the topic but it looks like the mainstream approaches don't do anything directly in that space. Does anyone know why? Does naively applying the Fourier transform, removing undesired periodic components, and inverting it lead to bad results? Is there a survey of seasonal adjustment from the perspective of ""you might think to use XYZ, but this is why that doesn't work and how these mainstream techniques improve on that""?","I've been reading up on seasonal adjustment (removing ""seasonal"" periodic components from a time series) recently and although I see a lot of fancy work around ARIMA models and fancy ways to detect the seasonality, I see comparatively little work on moving to the frequency domain and looking at series with Fourier transforms or wavelets or anything along those lines. There are some older papers on the topic but it looks like the mainstream approaches don't do anything directly in that space. Does anyone know why? Does naively applying the Fourier transform, removing undesired periodic components, and inverting it lead to bad results? Is there a survey of seasonal adjustment from the perspective of ""you might think to use XYZ, but this is why that doesn't work and how these mainstream techniques improve on that""?",,"['statistics', 'fourier-analysis', 'time-series']"
50,How is Optimal Transport algorithmically related to the Assignment Problem?,How is Optimal Transport algorithmically related to the Assignment Problem?,,"In optimal transport , we calculate the distance between two probability measures $\mu$ and $\nu$ over the compact set $[a,b]\subset\mathbb R$ , using the Earth Movers distance which is a special case of the Wasserstein formula: $$W=\inf_\pi\int|x-y|\,{\rm d}\pi(x,y),$$ where $\pi$ is interpreted as a transport matrix satisfying $\int\pi(x,y)dy=\mu(x)$ and $\int\pi(y,x)dy=\nu(x)$ . It is said that the Earth Movers distance shown above is solved using the Hungarian algorithm by Munkres, which is also used for solving the Assignment Problem . Are optimal transport and the assignment problem related then, and how mathematically?","In optimal transport , we calculate the distance between two probability measures and over the compact set , using the Earth Movers distance which is a special case of the Wasserstein formula: where is interpreted as a transport matrix satisfying and . It is said that the Earth Movers distance shown above is solved using the Hungarian algorithm by Munkres, which is also used for solving the Assignment Problem . Are optimal transport and the assignment problem related then, and how mathematically?","\mu \nu [a,b]\subset\mathbb R W=\inf_\pi\int|x-y|\,{\rm d}\pi(x,y), \pi \int\pi(x,y)dy=\mu(x) \int\pi(y,x)dy=\nu(x)","['statistics', 'probability-distributions', 'optimization', 'optimal-transport']"
51,"Show that $Cov(\bar{y},\hat{\beta_1})=0$",Show that,"Cov(\bar{y},\hat{\beta_1})=0","Show that $Cov(\bar{y},\hat{\beta_1})=0$ For those unfamiliar with statistics, Cov(A,B) refers to the covariance function. $\bar{y}$ refers to the average of the response (dependent variable). $\hat{\beta_1}$ refers to the estimator of the slope. The solution goes as follows: $Cov(\bar{y},\hat{\beta_1}) = Cov(\frac{\sum{y_i}}{n},\sum{c_iy_i}) $ Where $c_i = \frac{(x_i-\bar{x})}{S_{xx}} $ And $S_{xx} = \sum{(x_i-\bar{x})^2}$ $Cov(\frac{\sum{y_i}}{n},\sum{c_iy_i}) = \frac{1}{n}Cov(\sum{y_i},\sum{c_iy_i}) $ Can we bring the $\sum{c_i}$ out of the covariance? If so, we would simply be left with $var(y_i)$.","Show that $Cov(\bar{y},\hat{\beta_1})=0$ For those unfamiliar with statistics, Cov(A,B) refers to the covariance function. $\bar{y}$ refers to the average of the response (dependent variable). $\hat{\beta_1}$ refers to the estimator of the slope. The solution goes as follows: $Cov(\bar{y},\hat{\beta_1}) = Cov(\frac{\sum{y_i}}{n},\sum{c_iy_i}) $ Where $c_i = \frac{(x_i-\bar{x})}{S_{xx}} $ And $S_{xx} = \sum{(x_i-\bar{x})^2}$ $Cov(\frac{\sum{y_i}}{n},\sum{c_iy_i}) = \frac{1}{n}Cov(\sum{y_i},\sum{c_iy_i}) $ Can we bring the $\sum{c_i}$ out of the covariance? If so, we would simply be left with $var(y_i)$.",,"['statistics', 'self-learning']"
52,Choosing H0 and Ha in hypothesis testing,Choosing H0 and Ha in hypothesis testing,,"There seems to be some ambiguity or contradiction in how to correctly choose the null and alternative hypotheses, both online and in my instructor's notes. I'm trying to figure out if this stems merely from my lack of understanding or if there actually is a disagreement in the scientific community at large. I've seen the following two ideas on choosing H0 and Ha The null hypothesis is the status quo, the state of things already accepted and/or shown to be true by previous data. We assume it to be true and need convincing evidence to reject it. The alternative hypothesis is the one being proposed based on data from the experiment in question, and is assumed to be false unless the data supporting it can convincingly show otherwise. The null hypothesis is always the one that includes the equality, and the alternative hypothesis is the complement to it. It doesn't matter whether the equality is the status quo or is being claimed by the researcher, it is always H0. An example I made up myself for demonstrative purposes, I'm not looking for an actual solution. Only interested in the hypotheses: A researcher believes that children in economically disadvantages areas are more likely to be raised in single-parent homes. He surveys 1000 children from such an area and finds that 317 of them are raised in a single-parent home. Can we conclude with 95% confidence that 30% or more of the children in economically disadvantages areas are raised in single-parent homes? What would be the H0 and Ha in this case and why? My professor provided the correct answer (for an equivalent question but with different numbers) to be H0 : p >= 0.3; Ha : p < 0.3 With the rationale that H0 must include the equality, which in this case is greater or equal to 30% . Her solution then failed to reject the null hypothesis and concluded that the researcher's claim is therefore correct. To me this seems like assuming the claim to be true to begin with and giving it the benefit of the doubt, which is the opposite of what I thought was the correct approach. A professor in this related question Difference between ""at least"" and ""more than"" in hypothesis testing? seemingly took the same approach. I wish I could talk to my professor about this, but unfortunately there's a significant language barrier.","There seems to be some ambiguity or contradiction in how to correctly choose the null and alternative hypotheses, both online and in my instructor's notes. I'm trying to figure out if this stems merely from my lack of understanding or if there actually is a disagreement in the scientific community at large. I've seen the following two ideas on choosing H0 and Ha The null hypothesis is the status quo, the state of things already accepted and/or shown to be true by previous data. We assume it to be true and need convincing evidence to reject it. The alternative hypothesis is the one being proposed based on data from the experiment in question, and is assumed to be false unless the data supporting it can convincingly show otherwise. The null hypothesis is always the one that includes the equality, and the alternative hypothesis is the complement to it. It doesn't matter whether the equality is the status quo or is being claimed by the researcher, it is always H0. An example I made up myself for demonstrative purposes, I'm not looking for an actual solution. Only interested in the hypotheses: A researcher believes that children in economically disadvantages areas are more likely to be raised in single-parent homes. He surveys 1000 children from such an area and finds that 317 of them are raised in a single-parent home. Can we conclude with 95% confidence that 30% or more of the children in economically disadvantages areas are raised in single-parent homes? What would be the H0 and Ha in this case and why? My professor provided the correct answer (for an equivalent question but with different numbers) to be H0 : p >= 0.3; Ha : p < 0.3 With the rationale that H0 must include the equality, which in this case is greater or equal to 30% . Her solution then failed to reject the null hypothesis and concluded that the researcher's claim is therefore correct. To me this seems like assuming the claim to be true to begin with and giving it the benefit of the doubt, which is the opposite of what I thought was the correct approach. A professor in this related question Difference between ""at least"" and ""more than"" in hypothesis testing? seemingly took the same approach. I wish I could talk to my professor about this, but unfortunately there's a significant language barrier.",,"['statistics', 'hypothesis-testing']"
53,Sum of best X dice in Y dice rolled (or roll X pick best Y) odds/calculation,Sum of best X dice in Y dice rolled (or roll X pick best Y) odds/calculation,,"Background: In many pen and paper RPGs there is often an option or bonus/penalty to rolls that incorporates rolling multiples of the required die and taking the best or worst of those rolls for your roll. Example: Advantage/Disadvantage in D&D 5e is best/worst die in 2 twenty-sided die rolls. This generally alters the average roll (of 1d20 or one twenty-sided die equaling 10.5) by 3.325 total (average of 13.825 with Advantage, 7.175 with Disadvantage). Example 2: Best two dice of three six-sided dice rolled. This usually improves the average roll (of 2d6 or two six-sided dice summed, 7) by 1.45833 (8.4583 3-repeating if best, 5.5416 6-repeating if worst) total. Example 3: Best two of four six-sided dice rolled. This usually improves the average roll (of 2d6 or two six-sided dice summed, 7) by about 2.344136 (9.344136 if best, 4.655864 if worst) total. Questions: I was wondering what the specific means of calculating certain total rolls (such as rolls totaling a specific number, or that number and higher) and averages would be? Or if that was more easy to calculate than simply finding all the possible combinations and totaling them. Part A: Given X best of Y dice with Z number of sides, is there a simple expression one can write to calculate this easier than just summing all the combinations? Part B: Given the above scenario, is there a simple expression one can write to calculate the number of rolls at/equaling a specific number? Part C: Given the above scenarios, is there a simple expression one can write to calculate the number of rolls at/equaling or above a specific number? Other notes: I imagine that this will include a lot of factorial math and the Permutation/Combination functions, but I'm not sure how to proceed.","Background: In many pen and paper RPGs there is often an option or bonus/penalty to rolls that incorporates rolling multiples of the required die and taking the best or worst of those rolls for your roll. Example: Advantage/Disadvantage in D&D 5e is best/worst die in 2 twenty-sided die rolls. This generally alters the average roll (of 1d20 or one twenty-sided die equaling 10.5) by 3.325 total (average of 13.825 with Advantage, 7.175 with Disadvantage). Example 2: Best two dice of three six-sided dice rolled. This usually improves the average roll (of 2d6 or two six-sided dice summed, 7) by 1.45833 (8.4583 3-repeating if best, 5.5416 6-repeating if worst) total. Example 3: Best two of four six-sided dice rolled. This usually improves the average roll (of 2d6 or two six-sided dice summed, 7) by about 2.344136 (9.344136 if best, 4.655864 if worst) total. Questions: I was wondering what the specific means of calculating certain total rolls (such as rolls totaling a specific number, or that number and higher) and averages would be? Or if that was more easy to calculate than simply finding all the possible combinations and totaling them. Part A: Given X best of Y dice with Z number of sides, is there a simple expression one can write to calculate this easier than just summing all the combinations? Part B: Given the above scenario, is there a simple expression one can write to calculate the number of rolls at/equaling a specific number? Part C: Given the above scenarios, is there a simple expression one can write to calculate the number of rolls at/equaling or above a specific number? Other notes: I imagine that this will include a lot of factorial math and the Permutation/Combination functions, but I'm not sure how to proceed.",,"['statistics', 'permutations', 'combinations', 'dice']"
54,Expectation of truncated log-normal,Expectation of truncated log-normal,,"Let's assume that $y=e^x$, where $x\sim N(\mu,\sigma^2)$, that is, $y$ follows a lognormal distribution. I'm interested in finding how $\mathbb{E}\left[y|y\geq a\right]$ varies with $\mu$ and $\sigma$. From https://en.wikipedia.org/wiki/Log-normal_distribution , it is to see that $$ \mathbb{E}\left[y|y\geq a\right]=\frac{\int_{a}^{\infty}yf\left(y\right)dy}{\int_{a}^{\infty}f\left(y\right)dy}=\underbrace{e^{\mu+\frac{1}{2}\sigma^{2}}}_{\mathbb{E}\left[y\right]}\frac{\Phi\left(\sigma-\frac{\ln a-\mu}{\sigma}\right)}{1-\Phi\left(\frac{\ln a-\mu}{\sigma}\right)} .$$ So formally, if we define $h(\mu,\sigma) = \mathbb{E}\left[y|y\geq a\right]$, I want to understand $\frac{\partial h}{\partial\mu}$ and $ \frac{\partial h}{\partial\sigma} $, for any value of $a$. I've tried to work out the derivatives, but I always find that both can take any sign. I'm not surprised that  $ \frac{\partial h}{\partial\sigma} $ can take any sign, but, shouldn't there be a way to prove that  $$ \frac{\partial h}{\partial\mu} >0 ?$$ Is there a counterexample otherwise?","Let's assume that $y=e^x$, where $x\sim N(\mu,\sigma^2)$, that is, $y$ follows a lognormal distribution. I'm interested in finding how $\mathbb{E}\left[y|y\geq a\right]$ varies with $\mu$ and $\sigma$. From https://en.wikipedia.org/wiki/Log-normal_distribution , it is to see that $$ \mathbb{E}\left[y|y\geq a\right]=\frac{\int_{a}^{\infty}yf\left(y\right)dy}{\int_{a}^{\infty}f\left(y\right)dy}=\underbrace{e^{\mu+\frac{1}{2}\sigma^{2}}}_{\mathbb{E}\left[y\right]}\frac{\Phi\left(\sigma-\frac{\ln a-\mu}{\sigma}\right)}{1-\Phi\left(\frac{\ln a-\mu}{\sigma}\right)} .$$ So formally, if we define $h(\mu,\sigma) = \mathbb{E}\left[y|y\geq a\right]$, I want to understand $\frac{\partial h}{\partial\mu}$ and $ \frac{\partial h}{\partial\sigma} $, for any value of $a$. I've tried to work out the derivatives, but I always find that both can take any sign. I'm not surprised that  $ \frac{\partial h}{\partial\sigma} $ can take any sign, but, shouldn't there be a way to prove that  $$ \frac{\partial h}{\partial\mu} >0 ?$$ Is there a counterexample otherwise?",,"['statistics', 'probability-distributions', 'normal-distribution']"
55,Find a function such that follows to normal in distribution,Find a function such that follows to normal in distribution,,"Suppose that $X_{n}\sim \text{Binomial}(n,\theta)$, where $n=1,2,\ldots$ and $0<\theta<1$. Find a function $g$ such that $\sqrt{n}(g(\frac{1}{n}X_n)-g(\theta))\xrightarrow{D} N(0,1)$ for each value of $\theta\in(0,1)$. Can someone give me hints by using Delta method? I was trying to prove $\sqrt{n}(X_{n}-\theta)\xrightarrow{D} N(0,\sigma^2)$. But I find I only know $\bar{X}_n$ has similar property. Delta Method Theorem Let $Y_n$ be sequence of random variables that satisfies $\sqrt{n}(Y_n-\theta)\xrightarrow{D}N(0,\sigma^2)$. For a given function $g$ and a specific value of $\theta$, suppose that $g'(\theta)$ exists and is not $0$. Then $$\sqrt{n}[g(Y_n)-g(\theta)]\xrightarrow{D}N(0,\sigma^2[g'(\theta)]^2).$$","Suppose that $X_{n}\sim \text{Binomial}(n,\theta)$, where $n=1,2,\ldots$ and $0<\theta<1$. Find a function $g$ such that $\sqrt{n}(g(\frac{1}{n}X_n)-g(\theta))\xrightarrow{D} N(0,1)$ for each value of $\theta\in(0,1)$. Can someone give me hints by using Delta method? I was trying to prove $\sqrt{n}(X_{n}-\theta)\xrightarrow{D} N(0,\sigma^2)$. But I find I only know $\bar{X}_n$ has similar property. Delta Method Theorem Let $Y_n$ be sequence of random variables that satisfies $\sqrt{n}(Y_n-\theta)\xrightarrow{D}N(0,\sigma^2)$. For a given function $g$ and a specific value of $\theta$, suppose that $g'(\theta)$ exists and is not $0$. Then $$\sqrt{n}[g(Y_n)-g(\theta)]\xrightarrow{D}N(0,\sigma^2[g'(\theta)]^2).$$",,"['statistics', 'statistical-inference']"
56,An estimator for the c.d.f $F$ at a point $x_0$?,An estimator for the c.d.f  at a point ?,F x_0,"Problem: Let $X_1,X_2,\ldots,X_n$ be independent identically distributed random variables (i.i.d's) with common CDF $F$. Fix $x_0\in\mathbb{R}$ and find an unbiased estimator for $F(x_0)$. Show that your estimator is an UMVUE for $F(x_0)$ (i.e. a uniformly minimum variance unbiased estimator ). So the problem is to find an unbiased estimator $\hat{F}(x_0)$ for $F(x_0)$ such that if $T$ is any unbiased estimator for $F(x_0)$, then $\operatorname{Var}(T)\geq \operatorname{Var}(\hat{F}(x_0))$. Attempt: I think I found what should be our unbiased estimator for $F(x_0)$. But after many, many attempts, I have no idea on how to show that it is an UMVUE. My estimator is $$\hat{F}(x_0)=\frac{1}{n}\sum_{i=1}^nI\{X_i\leq x_0\}$$ where $I\{X_i\leq x_0\}$ is the indicator function that equals $1$ when $X_i\leq x_0$ and $0$ otherwise. We have $$E[I\{X_i\leq x_0\}]=\int_{-\infty}^{x_0}f(x)dx=F(x_0),$$ so it is clear that $\hat{F}(x_0)$ is unbiased. But to show that it is UMVUE, the only tool that I have is the Cramer-Rao Inequality : $$\operatorname{Var}(T)\geq\frac{[g'(\theta)]^2}{n E[(\frac{\partial}{\partial \theta}\log f(X;\theta))^2]}\tag{1}$$ for any unbiased estimator $T$ of $g(\theta)$. But here if $\theta=F(x_0)$ how do we differentiate $f$ with respect to $\theta$? I got $$\operatorname{Var}(\hat{F}(x_0))=\frac{F(x_0)(1-F(x_0))}{n},\tag{2}$$ so I am trying to show that the r.h.s of $(1)$ is $(2)$ if $\theta=F(x_0)$ and $g(\theta)=\theta$. Edit: I looked it up and this estimator for $F(x_0)$ appears to be known as the empirical distribution function . However, there is no clue that this is an UMVUE...","Problem: Let $X_1,X_2,\ldots,X_n$ be independent identically distributed random variables (i.i.d's) with common CDF $F$. Fix $x_0\in\mathbb{R}$ and find an unbiased estimator for $F(x_0)$. Show that your estimator is an UMVUE for $F(x_0)$ (i.e. a uniformly minimum variance unbiased estimator ). So the problem is to find an unbiased estimator $\hat{F}(x_0)$ for $F(x_0)$ such that if $T$ is any unbiased estimator for $F(x_0)$, then $\operatorname{Var}(T)\geq \operatorname{Var}(\hat{F}(x_0))$. Attempt: I think I found what should be our unbiased estimator for $F(x_0)$. But after many, many attempts, I have no idea on how to show that it is an UMVUE. My estimator is $$\hat{F}(x_0)=\frac{1}{n}\sum_{i=1}^nI\{X_i\leq x_0\}$$ where $I\{X_i\leq x_0\}$ is the indicator function that equals $1$ when $X_i\leq x_0$ and $0$ otherwise. We have $$E[I\{X_i\leq x_0\}]=\int_{-\infty}^{x_0}f(x)dx=F(x_0),$$ so it is clear that $\hat{F}(x_0)$ is unbiased. But to show that it is UMVUE, the only tool that I have is the Cramer-Rao Inequality : $$\operatorname{Var}(T)\geq\frac{[g'(\theta)]^2}{n E[(\frac{\partial}{\partial \theta}\log f(X;\theta))^2]}\tag{1}$$ for any unbiased estimator $T$ of $g(\theta)$. But here if $\theta=F(x_0)$ how do we differentiate $f$ with respect to $\theta$? I got $$\operatorname{Var}(\hat{F}(x_0))=\frac{F(x_0)(1-F(x_0))}{n},\tag{2}$$ so I am trying to show that the r.h.s of $(1)$ is $(2)$ if $\theta=F(x_0)$ and $g(\theta)=\theta$. Edit: I looked it up and this estimator for $F(x_0)$ appears to be known as the empirical distribution function . However, there is no clue that this is an UMVUE...",,['statistics']
57,The distribution of the ith order statistic for discrete random variables,The distribution of the ith order statistic for discrete random variables,,"Assume $(X_i)_{i=1,...,n}$ are a sequence of real iid random variables with continuous density $p_x$. We know that $$Y:=\sum_{i=1}^n 1\{X_i\leq u\}\sim Bin(n,F_x(u)),$$ since $1\{X_i\leq u\}\sim Ber(F_x(u))$ with $F_x(u):=P(X_i\leq u)$. By $X_{[i]}$ we denote the ith order statistic. We know that  $$X_{[j]}\leq u\Leftrightarrow X_{[i]}\leq u ~(\forall i\leq j) \Leftrightarrow \sum_{i=1}^n 1\{X_i\leq u\} \geq j.$$ Consequently, it holds that $$P(X_{[j]}\leq u)=P(Y\geq j)=\sum_{k=j}^n \binom{n}{k}F_x^k(u)\left(1-F_x(u)\right)^{n-k}.$$ My question is the following: Why do I have to assume that $p_x$ is continuous? Don't I have the same binomial distribution if the $X_i$s are discrete random variables? My professor stated that the problem is that for discrete random variables there could occur ties, i.e., $P(X_i=X_j)\neq 0$ for $i\neq j$, making the proof above false; but I don't see the problem.","Assume $(X_i)_{i=1,...,n}$ are a sequence of real iid random variables with continuous density $p_x$. We know that $$Y:=\sum_{i=1}^n 1\{X_i\leq u\}\sim Bin(n,F_x(u)),$$ since $1\{X_i\leq u\}\sim Ber(F_x(u))$ with $F_x(u):=P(X_i\leq u)$. By $X_{[i]}$ we denote the ith order statistic. We know that  $$X_{[j]}\leq u\Leftrightarrow X_{[i]}\leq u ~(\forall i\leq j) \Leftrightarrow \sum_{i=1}^n 1\{X_i\leq u\} \geq j.$$ Consequently, it holds that $$P(X_{[j]}\leq u)=P(Y\geq j)=\sum_{k=j}^n \binom{n}{k}F_x^k(u)\left(1-F_x(u)\right)^{n-k}.$$ My question is the following: Why do I have to assume that $p_x$ is continuous? Don't I have the same binomial distribution if the $X_i$s are discrete random variables? My professor stated that the problem is that for discrete random variables there could occur ties, i.e., $P(X_i=X_j)\neq 0$ for $i\neq j$, making the proof above false; but I don't see the problem.",,"['statistics', 'statistical-inference', 'order-statistics']"
58,Decrease of entropy when iterating a random discrete function,Decrease of entropy when iterating a random discrete function,,"Let $m$ be a positive integer. Let $S$ be the set of non-negative integers $x$ less than $m$, with $|S|=m$. Let $X_0$ be the discrete uniform distribution over $S$, with $P(x)=\begin{cases} 1/m & \text{if } x\in S \\ 0   & \text{if } x\not\in S \end{cases}$ Let $F$ be any of the $m^m$ discrete functions from $S$ to $S$. For that particular $F$, let $X_{i+1}=F(X_i)$ be the discrete distribution of the output of $F$ for input distribution $X_i$ (or equivalently the discrete distribution of $F^i$ for input distribution $X_0$); and let $H_i=H(X_i)$ be the entropy of $X_i$. Question: How is the distribution of $H_i$ when $F$ is a uniformly random discrete function from $S$ to $S$? In particular, can we find a little-$\mathcal o$ expression of its mean (perhaps variance or standard deviation, skewness..) when $m\to\infty$? An heuristic approximation is proposed here , with $n=\log_2(m)$, in a cryptographic context. It holds that $H_0=\log_2(m)$; and $\forall i\in\mathbb N, H_{m-1}\le H_{i+1}\le H_i\le\log_2(m)$. $H_i$ for an individual $F$ depends only on $i$ and the structure of the Functional Graph of $F$, irrespective of its labeling. Here a graph showing a random $F$ (a truncated hash with $m=2^{10}$). Another example yielding a maximally high $i$ before $H_i$ no longer decreases is with $$F(x)=\begin{cases} x-1 & \text{if } 1\le x<m \\ 0   & \text{if } 0\le x\le1\text{ and }x<m \end{cases}$$ we have $$F^i(x)=\begin{cases} x-i & \text{if } i\le x<m \\ 0   & \text{if } 0\le x\le i\text{ and }x<m \end{cases}$$ and it comes $$H_i=\begin{cases} \log_2(m)                         & \text{if } i=0 \\ \log_2(m)-{i+1\over m}\log_2(1+i) & \text{if } 0\le i\le m-1 \\ 0                                 & \text{if } i\ge m-1 \end{cases}$$","Let $m$ be a positive integer. Let $S$ be the set of non-negative integers $x$ less than $m$, with $|S|=m$. Let $X_0$ be the discrete uniform distribution over $S$, with $P(x)=\begin{cases} 1/m & \text{if } x\in S \\ 0   & \text{if } x\not\in S \end{cases}$ Let $F$ be any of the $m^m$ discrete functions from $S$ to $S$. For that particular $F$, let $X_{i+1}=F(X_i)$ be the discrete distribution of the output of $F$ for input distribution $X_i$ (or equivalently the discrete distribution of $F^i$ for input distribution $X_0$); and let $H_i=H(X_i)$ be the entropy of $X_i$. Question: How is the distribution of $H_i$ when $F$ is a uniformly random discrete function from $S$ to $S$? In particular, can we find a little-$\mathcal o$ expression of its mean (perhaps variance or standard deviation, skewness..) when $m\to\infty$? An heuristic approximation is proposed here , with $n=\log_2(m)$, in a cryptographic context. It holds that $H_0=\log_2(m)$; and $\forall i\in\mathbb N, H_{m-1}\le H_{i+1}\le H_i\le\log_2(m)$. $H_i$ for an individual $F$ depends only on $i$ and the structure of the Functional Graph of $F$, irrespective of its labeling. Here a graph showing a random $F$ (a truncated hash with $m=2^{10}$). Another example yielding a maximally high $i$ before $H_i$ no longer decreases is with $$F(x)=\begin{cases} x-1 & \text{if } 1\le x<m \\ 0   & \text{if } 0\le x\le1\text{ and }x<m \end{cases}$$ we have $$F^i(x)=\begin{cases} x-i & \text{if } i\le x<m \\ 0   & \text{if } 0\le x\le i\text{ and }x<m \end{cases}$$ and it comes $$H_i=\begin{cases} \log_2(m)                         & \text{if } i=0 \\ \log_2(m)-{i+1\over m}\log_2(1+i) & \text{if } 0\le i\le m-1 \\ 0                                 & \text{if } i\ge m-1 \end{cases}$$",,"['statistics', 'discrete-mathematics', 'entropy', 'random-functions']"
59,Intuition on variance of linear combination of variables,Intuition on variance of linear combination of variables,,"I have the formulas for the variance of linear combintion of variables given as $$ \text{Var}\Bigl(\,\sum_{i=1}^n X_i\,\Bigr)=  \sum_{i=1}^n\text{Var}( X_i)+  2\sum_{i< j} \text{Cov}(X_i,X_j). $$ I know this is derived from variance of 2 variables and extrapolation. However, what is the intuition behind this formula? Can someone explain further on how I could  use this formula to understand covariance better?","I have the formulas for the variance of linear combintion of variables given as $$ \text{Var}\Bigl(\,\sum_{i=1}^n X_i\,\Bigr)=  \sum_{i=1}^n\text{Var}( X_i)+  2\sum_{i< j} \text{Cov}(X_i,X_j). $$ I know this is derived from variance of 2 variables and extrapolation. However, what is the intuition behind this formula? Can someone explain further on how I could  use this formula to understand covariance better?",,['statistics']
60,"Why does regression use least ""squares"" instead of least ""absolute values""? [duplicate]","Why does regression use least ""squares"" instead of least ""absolute values""? [duplicate]",,"This question already has answers here : Difference between least squares and minimum norm solution (3 answers) Closed 4 years ago . Linear regression uses summation of least squares to find the best fit. Why? I fully understand that we do not want to use actual residuals, otherwise, positive and negative numbers may cancel out each other. Then, why don't we use absolute values? Sorry if this sounds like a duplicate question. I did see many explanations but did not see an easy-to-understand answer. For example, some said that squares made calculation easier. How come? Your insight is highly appreciated!","This question already has answers here : Difference between least squares and minimum norm solution (3 answers) Closed 4 years ago . Linear regression uses summation of least squares to find the best fit. Why? I fully understand that we do not want to use actual residuals, otherwise, positive and negative numbers may cancel out each other. Then, why don't we use absolute values? Sorry if this sounds like a duplicate question. I did see many explanations but did not see an easy-to-understand answer. For example, some said that squares made calculation easier. How come? Your insight is highly appreciated!",,"['statistics', 'machine-learning', 'regression', 'least-squares']"
61,What is the purpose of the standard deviation?,What is the purpose of the standard deviation?,,"I don't have any knowledge of statistics beyond high school common sense. Why is the standard deviation usually seen in combinatorics textbooks, and why is the standard deviation defined intentionally? What is its purpose? Thanks in advance. I have checked in Wikipedia and many other websites to see what this is, but they are not very concise and clear.","I don't have any knowledge of statistics beyond high school common sense. Why is the standard deviation usually seen in combinatorics textbooks, and why is the standard deviation defined intentionally? What is its purpose? Thanks in advance. I have checked in Wikipedia and many other websites to see what this is, but they are not very concise and clear.",,"['statistics', 'soft-question', 'intuition']"
62,Percentage greater than 2 standard deviations from the mean,Percentage greater than 2 standard deviations from the mean,,"A question reads: ""The weights of $910$ young deer tagged and weighed in a research study are normally distributed with a mean of $86$ pounds and a standard deviation of $2.5$ pounds."" Approximately how many deer weigh more than $91$ pounds? Since $34.1$% fall within the first standard deviation and $13.6$% fall within the second standard deviation, then $2.3$% will be greater than two standard deviations. $2.3$% of $910$ equals $20.93$. Possible multiple choice answers are $21$ or $23$. I picked $21$. The test guide says $23$. I assume this is a typo. Anyone think I went awry?","A question reads: ""The weights of $910$ young deer tagged and weighed in a research study are normally distributed with a mean of $86$ pounds and a standard deviation of $2.5$ pounds."" Approximately how many deer weigh more than $91$ pounds? Since $34.1$% fall within the first standard deviation and $13.6$% fall within the second standard deviation, then $2.3$% will be greater than two standard deviations. $2.3$% of $910$ equals $20.93$. Possible multiple choice answers are $21$ or $23$. I picked $21$. The test guide says $23$. I assume this is a typo. Anyone think I went awry?",,['statistics']
63,Inverse of random variable,Inverse of random variable,,"Let's say we have a random variable $X$ of which the distribution is unknown. Now there are these general rules like $E[X + Y] = E[X] + E[Y]$ etc. But what if we would define $ \quad Y = \dfrac{1}{X} $ and we would be interested in the expected value $E[Y]$ and the variance $Var(Y) = E[(Y-\bar{Y})^2]$? Now, I do realize that $X$ might be zero and therefore it is undefined. But what if we would assume $X \neq 0$? My quick solution was to assume $X$ being a log-normal random variable. But I would prefer something more general. Maybe a power series expansion is possible?","Let's say we have a random variable $X$ of which the distribution is unknown. Now there are these general rules like $E[X + Y] = E[X] + E[Y]$ etc. But what if we would define $ \quad Y = \dfrac{1}{X} $ and we would be interested in the expected value $E[Y]$ and the variance $Var(Y) = E[(Y-\bar{Y})^2]$? Now, I do realize that $X$ might be zero and therefore it is undefined. But what if we would assume $X \neq 0$? My quick solution was to assume $X$ being a log-normal random variable. But I would prefer something more general. Maybe a power series expansion is possible?",,"['statistics', 'random-variables']"
64,Benford's law with random integers,Benford's law with random integers,,"I tried testing random integers for compliance with Benford's law, which they are apparently supposed to do . However, when I try doing this with Python, map(lambda x:str(x)[0], [random.randint(0, 10000) for a in range(100000)]).count('1') I get approximately equal frequencies for all leading digits. Why is this the case? Might it have something to do with how the pseudorandom number generator, the Mersenne twister, works?","I tried testing random integers for compliance with Benford's law, which they are apparently supposed to do . However, when I try doing this with Python, map(lambda x:str(x)[0], [random.randint(0, 10000) for a in range(100000)]).count('1') I get approximately equal frequencies for all leading digits. Why is this the case? Might it have something to do with how the pseudorandom number generator, the Mersenne twister, works?",,['statistics']
65,"What is meant by ""dot product between random variables?""","What is meant by ""dot product between random variables?""",,"I was having a discussion with a colleague today about correlation coefficients, and I was told that correlation coefficient between 2 random variables $X$ and $Y$ is proportional to the dot product of the two random variables. I asked him what he means by this, and I was told that you can view random variables as vectors. I don't think I agree with that, but I don't have a sufficient background to really argue my point, but now I want to revisit this. How can a random variable be viewed a vector? What is meant by dot product between 2 random variables -- is this actually formal terminology or something loosely used?","I was having a discussion with a colleague today about correlation coefficients, and I was told that correlation coefficient between 2 random variables and is proportional to the dot product of the two random variables. I asked him what he means by this, and I was told that you can view random variables as vectors. I don't think I agree with that, but I don't have a sufficient background to really argue my point, but now I want to revisit this. How can a random variable be viewed a vector? What is meant by dot product between 2 random variables -- is this actually formal terminology or something loosely used?",X Y,"['statistics', 'random-variables', 'inner-products', 'covariance', 'correlation']"
66,Logistic function passing through two points?,Logistic function passing through two points?,,"Quick formulation of the problem: Given two points: $(x_l, y_l)$ and $(x_u, y_u)$ with: $x_l < x_u$ and $y_l < y_u$ , and given lower asymptote=0 and higher asymptote=1, what's the logistic function that passes through the two points? Explanatory image: Other details: I'm given two points in the form of Pareto 90/10 (green in the example above) or 80/20 (blue in the example above), and I know that the upper bound is one and the lower bound is zero. How do I get the formula of a sigmoid function (such as the logistic function) that has a lower asymptote on the left and higher asymptote on the right and passes via the two points?","Quick formulation of the problem: Given two points: and with: and , and given lower asymptote=0 and higher asymptote=1, what's the logistic function that passes through the two points? Explanatory image: Other details: I'm given two points in the form of Pareto 90/10 (green in the example above) or 80/20 (blue in the example above), and I know that the upper bound is one and the lower bound is zero. How do I get the formula of a sigmoid function (such as the logistic function) that has a lower asymptote on the left and higher asymptote on the right and passes via the two points?","(x_l, y_l) (x_u, y_u) x_l < x_u y_l < y_u",['statistics']
67,Why does Bayes Theorem work?,Why does Bayes Theorem work?,,"I have always wondered about the math behind Bayes Theorem because it looks really simple and seems like there's probably a simple explanation behind it. I don't understand the relationship between P(A and B) over P(B) and why this means ""The probability of A given B.""","I have always wondered about the math behind Bayes Theorem because it looks really simple and seems like there's probably a simple explanation behind it. I don't understand the relationship between P(A and B) over P(B) and why this means ""The probability of A given B.""",,['statistics']
68,Can a discrete random variable be normally distributed?,Can a discrete random variable be normally distributed?,,"This question may seem quite strange, but I am wondering whether the above is true? In several russian books I saw the notion of ""somehow"" normally distributed discrete r.v. Can this even be possible? Thank you in advance!","This question may seem quite strange, but I am wondering whether the above is true? In several russian books I saw the notion of ""somehow"" normally distributed discrete r.v. Can this even be possible? Thank you in advance!",,"['statistics', 'probability-distributions', 'random-variables', 'normal-distribution']"
69,Method of Least Squares-Why is it preferred? [duplicate],Method of Least Squares-Why is it preferred? [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Why do we use a Least Squares fit? To find the normal equations for derivation of the regression line we use the method of least squares, We want to make the error smallest for each individual,so we may take summation of mod of the error term for each individual instead of taking the summation of the square of the errors of the individuals. Why is the former method used for regression and not the second one?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Why do we use a Least Squares fit? To find the normal equations for derivation of the regression line we use the method of least squares, We want to make the error smallest for each individual,so we may take summation of mod of the error term for each individual instead of taking the summation of the square of the errors of the individuals. Why is the former method used for regression and not the second one?",,"['statistics', 'regression']"
70,What is an example of a second-order markov chain? [closed],What is an example of a second-order markov chain? [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I'd like to see an example of a second-order markov chain. Haven't found one over google or in any of my textbooks.,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I'd like to see an example of a second-order markov chain. Haven't found one over google or in any of my textbooks.,,"['statistics', 'stochastic-processes', 'markov-chains', 'markov-process']"
71,Is it possible to calculate the mean and standard deviation from a median and quartiles?,Is it possible to calculate the mean and standard deviation from a median and quartiles?,,"Any advice would helpful. I understand that the reporting of median and quartiles for small samples is an indication of skewed data. If such is correct, then is it useless to try to work out the mean and standard deviation given the data below? Sample N=104; median number per subject (25–75 quartiles): 1.4 (0.0–2.0) I thought of using the following formula: $\sigma = \sqrt{n} \frac{\text{upper limit} - \text{lower limit}}{\text{number of standard errors between upper and lower limits}}$ Can I assume a normal distribution given that the data is based on quartiles? Can I assume that the 25th and 75th quartile are equivalent to the limits of a 50% confidence interval (CI)? Once I get the equivalent CI's, I could obtain the number of standard errors in a 50% CI based on a z-score for the normal distribution: $se = 0.674$ on a one tail and $1.348$ on a two tail So, replacing the values in the formula: $\sigma = \sqrt{104} \frac{0.0 - 2.0}{ 1.348} = -15.13$$ Is my work correct? How could I now obtain the mean?","Any advice would helpful. I understand that the reporting of median and quartiles for small samples is an indication of skewed data. If such is correct, then is it useless to try to work out the mean and standard deviation given the data below? Sample N=104; median number per subject (25–75 quartiles): 1.4 (0.0–2.0) I thought of using the following formula: $\sigma = \sqrt{n} \frac{\text{upper limit} - \text{lower limit}}{\text{number of standard errors between upper and lower limits}}$ Can I assume a normal distribution given that the data is based on quartiles? Can I assume that the 25th and 75th quartile are equivalent to the limits of a 50% confidence interval (CI)? Once I get the equivalent CI's, I could obtain the number of standard errors in a 50% CI based on a z-score for the normal distribution: $se = 0.674$ on a one tail and $1.348$ on a two tail So, replacing the values in the formula: $\sigma = \sqrt{104} \frac{0.0 - 2.0}{ 1.348} = -15.13$$ Is my work correct? How could I now obtain the mean?",,"['statistics', 'probability-distributions', 'standard-deviation', 'statistical-inference']"
72,Calculating expected value of sample standard deviation [closed],Calculating expected value of sample standard deviation [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How do we calculate $$ \begin{align}E[S]&=E\left[\sqrt{\frac{1}{n-1}\sum_i(x_i-\bar{x})^2}\right]\\&=E\left[\sqrt{\frac{1}{n-1}}   \sqrt{\sum_ix_i^2-n\bar{x}^2}\right]. \end{align}$$ I am asking this question out of curiosity mostly because it is easy to show that $E[S^2]=\sigma^2$ but not so easy to calculate this.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How do we calculate $$ \begin{align}E[S]&=E\left[\sqrt{\frac{1}{n-1}\sum_i(x_i-\bar{x})^2}\right]\\&=E\left[\sqrt{\frac{1}{n-1}}   \sqrt{\sum_ix_i^2-n\bar{x}^2}\right]. \end{align}$$ I am asking this question out of curiosity mostly because it is easy to show that $E[S^2]=\sigma^2$ but not so easy to calculate this.",,['statistics']
73,Expected value of a minimum?,Expected value of a minimum?,,"One of the problems of my Statistics assignment requires me to calculate the expected value of a minimum. Here's the situation: The following density function is given: $f(x) = \frac{\theta}{x^2}$ where $x\ge\theta$ and $\theta>0$ I have to calculate: E[min{$X_i$}] My initial guess was that the smallest possible value of $X$ is $\theta$ sense $x\ge\theta$ so the expected value of the minimum would be $\theta$, but then again, in an acquired sample, you can't be 100% certain that the smallest possible value of $X$ will be one of the observations. So what then?","One of the problems of my Statistics assignment requires me to calculate the expected value of a minimum. Here's the situation: The following density function is given: $f(x) = \frac{\theta}{x^2}$ where $x\ge\theta$ and $\theta>0$ I have to calculate: E[min{$X_i$}] My initial guess was that the smallest possible value of $X$ is $\theta$ sense $x\ge\theta$ so the expected value of the minimum would be $\theta$, but then again, in an acquired sample, you can't be 100% certain that the smallest possible value of $X$ will be one of the observations. So what then?",,['statistics']
74,"UMVUE of $\frac{\theta}{1+\theta}$ and $\frac{e^{\theta}}{\theta}$ from $U(-\theta,\theta)$ distribution",UMVUE of  and  from  distribution,"\frac{\theta}{1+\theta} \frac{e^{\theta}}{\theta} U(-\theta,\theta)","Let $X_1,X_2,\dots, X_n$ be rvs with pdf:   $$f(x\mid \theta)=\frac{1}{2\theta}I(-\theta<x<\theta)$$ Find UMVUE of $(i)\dfrac{\theta}{1+\theta}$ and $(ii)\dfrac{e^{\theta}}{\theta}$. Note that, $(X_{(1)},X_{(n)})$ is complete sufficient statistic. But now I have to find unbiased estimator of $(i),(ii)$ of the form $g(X_{(1)},X_{(n)})$, then $g$ will become UMVUE. But I could not find such $g$. Thanks for any help. I tried to find $E(X_{(1)}/X_{(n)})$, but it came out a total mess. Here $X_{(1)}=\min(X_1,X_2,\dots, X_n)$ and $X_{(n)}=\max(X_1,X_2,\dots, X_n)$.","Let $X_1,X_2,\dots, X_n$ be rvs with pdf:   $$f(x\mid \theta)=\frac{1}{2\theta}I(-\theta<x<\theta)$$ Find UMVUE of $(i)\dfrac{\theta}{1+\theta}$ and $(ii)\dfrac{e^{\theta}}{\theta}$. Note that, $(X_{(1)},X_{(n)})$ is complete sufficient statistic. But now I have to find unbiased estimator of $(i),(ii)$ of the form $g(X_{(1)},X_{(n)})$, then $g$ will become UMVUE. But I could not find such $g$. Thanks for any help. I tried to find $E(X_{(1)}/X_{(n)})$, but it came out a total mess. Here $X_{(1)}=\min(X_1,X_2,\dots, X_n)$ and $X_{(n)}=\max(X_1,X_2,\dots, X_n)$.",,"['statistics', 'probability-distributions', 'statistical-inference', 'order-statistics', 'parameter-estimation']"
75,Why is the denominator $N-p-1$ in estimation of variance?,Why is the denominator  in estimation of variance?,N-p-1,"I was recently going through the book Elements of Statistical Learning by Tibshirani et.al. In this book, while explaining the ordinary least squares model, the authors state that assume that $y_i \epsilon \mathbb{R}$ represents the observed variables, $\hat{y_i}$ represents the model output and $\mathbf{x_i} \epsilon \mathbf{R}^{p+1}$ represent the inputs. If the $y_i$s are assumed to be uncorrelated and have constant with variance $\sigma$, then the unbiased estimate of variance is $\hat{\sigma} = \frac{1}{\left (N-p-1 \right)}\sum\left( y_i - \hat{y_i} \right)^2$, summation being done from $i=1$ to $i=N$. Note that $p$ has been used here to denote the dimensionality of $\mathbf{x_i}$s. My question is why is the factor in the denominator $N-p-1$ while estimating the variance of $y_i$s i.e. $\hat{\sigma}$ ? From my understanding if the $y_s$s are real numbers that have constant variance, the factor should be equal to $N-1$.","I was recently going through the book Elements of Statistical Learning by Tibshirani et.al. In this book, while explaining the ordinary least squares model, the authors state that assume that $y_i \epsilon \mathbb{R}$ represents the observed variables, $\hat{y_i}$ represents the model output and $\mathbf{x_i} \epsilon \mathbf{R}^{p+1}$ represent the inputs. If the $y_i$s are assumed to be uncorrelated and have constant with variance $\sigma$, then the unbiased estimate of variance is $\hat{\sigma} = \frac{1}{\left (N-p-1 \right)}\sum\left( y_i - \hat{y_i} \right)^2$, summation being done from $i=1$ to $i=N$. Note that $p$ has been used here to denote the dimensionality of $\mathbf{x_i}$s. My question is why is the factor in the denominator $N-p-1$ while estimating the variance of $y_i$s i.e. $\hat{\sigma}$ ? From my understanding if the $y_s$s are real numbers that have constant variance, the factor should be equal to $N-1$.",,"['statistics', 'least-squares', 'variance']"
76,What is difference between standard deviation and Z-score?,What is difference between standard deviation and Z-score?,,"I have read several explanations of standard deviation and z-score, I know how to it calculate them but I am not sure what is differences betwen them. Can someone explain it to me? When is suitable to use stdev and when z-score?","I have read several explanations of standard deviation and z-score, I know how to it calculate them but I am not sure what is differences betwen them. Can someone explain it to me? When is suitable to use stdev and when z-score?",,"['statistics', 'standard-deviation']"
77,Why is the sample mean a random variable?,Why is the sample mean a random variable?,,"I know that a random variable is a measurable function from some measurable space $(\Omega, \mathscr{F})$ to some borel space $(R, \mathscr{B})$ . Suppose I am given some random sample $X_1, ..., X_n$ . From the definition of a random sample, each $X_i:\Omega \rightarrow R$ are a measurable function with common domain the sample space $\Omega$ . I know that the sample mean is a random variable. Hence it is a measurable function. So what type of function is the sample mean exactly? From which measurable space to where? And what exactly does the notation $\bar{X} = n^-1 \sum _i^n X_i$ mean given that it does not mean that $\bar{X} (s)= n^{-1} \sum _i^n X_i(s)$ ? I ask because usually defining a function $f$ by $f = v+g$ where $g:A \rightarrow R, v:A \rightarrow R$ implies that $f(x) = v(x) + g(x) \forall x \in A$ holds.","I know that a random variable is a measurable function from some measurable space to some borel space . Suppose I am given some random sample . From the definition of a random sample, each are a measurable function with common domain the sample space . I know that the sample mean is a random variable. Hence it is a measurable function. So what type of function is the sample mean exactly? From which measurable space to where? And what exactly does the notation mean given that it does not mean that ? I ask because usually defining a function by where implies that holds.","(\Omega, \mathscr{F}) (R, \mathscr{B}) X_1, ..., X_n X_i:\Omega \rightarrow R \Omega \bar{X} = n^-1 \sum _i^n X_i \bar{X} (s)= n^{-1} \sum _i^n X_i(s) f f = v+g g:A \rightarrow R, v:A \rightarrow R f(x) = v(x) + g(x) \forall x \in A","['statistics', 'statistical-inference']"
78,How to transform/shift the mean and standard deviation of a normal distribution?,How to transform/shift the mean and standard deviation of a normal distribution?,,"Given some Gaussian distribution with mean x and deviation s, how do I transform the distribution to have a new specific mean and specific deviation. Say the distribution has a mean, $\bar x = 4$ and deviation, $s = 10$, and needs to be transformed so that the new mean and deviation are $\bar x = 0.50$ and $s = 2$. My approach is to scale each element in the data set by $c = 0.20$, which will also scale the deviation to the desired $s = 2$, and will make the mean $\bar x = 0.80$. Finally I subtract 0.30 from each element to shift the mean to the desired $\bar x = 0.50$.","Given some Gaussian distribution with mean x and deviation s, how do I transform the distribution to have a new specific mean and specific deviation. Say the distribution has a mean, $\bar x = 4$ and deviation, $s = 10$, and needs to be transformed so that the new mean and deviation are $\bar x = 0.50$ and $s = 2$. My approach is to scale each element in the data set by $c = 0.20$, which will also scale the deviation to the desired $s = 2$, and will make the mean $\bar x = 0.80$. Finally I subtract 0.30 from each element to shift the mean to the desired $\bar x = 0.50$.",,"['statistics', 'normal-distribution', 'descriptive-statistics']"
79,Where do the values in a z-table come from?,Where do the values in a z-table come from?,,"I understand the purpose of a z-score and how you calculate $z_1$ and $z_2$ , given $x_1$ and $x_2$ for some normal random variable $X$ : $$Z = \frac{x-\mu}{\sigma}.$$ If $x-\mu = \sigma$ , then $Z = 1.00$ , which tells us that the sample point $x$ is precisely one standard deviation ( $\sigma$ ) to the right of its mean ( $\mu$ ). Likewise, if $x-\mu = -\sigma $ , then $Z = -1.00$ , which tells us that the sample point $x$ is precisely one standard deviation ( $\sigma$ ) to the left of its mean ( $\sigma$ ). However , what all sources I've come across fail to properly explain is where the values listed in a $z$ -table come from. I am interested in calculating: $$P(z_1<Z<z_2)$$ by hand. No matter what I've read online, everything tells me to just look up the value in a table.  Wwhere do those values come from? How is the above probability computed? And how is it any simpler than $P(x_1 < X < x_2)$ ?","I understand the purpose of a z-score and how you calculate and , given and for some normal random variable : If , then , which tells us that the sample point is precisely one standard deviation ( ) to the right of its mean ( ). Likewise, if , then , which tells us that the sample point is precisely one standard deviation ( ) to the left of its mean ( ). However , what all sources I've come across fail to properly explain is where the values listed in a -table come from. I am interested in calculating: by hand. No matter what I've read online, everything tells me to just look up the value in a table.  Wwhere do those values come from? How is the above probability computed? And how is it any simpler than ?",z_1 z_2 x_1 x_2 X Z = \frac{x-\mu}{\sigma}. x-\mu = \sigma Z = 1.00 x \sigma \mu x-\mu = -\sigma  Z = -1.00 x \sigma \sigma z P(z_1<Z<z_2) P(x_1 < X < x_2),"['statistics', 'normal-distribution']"
80,Proving MAE(mean absolute error) argmin is median using functionals?,Proving MAE(mean absolute error) argmin is median using functionals?,,"For example, I was able to find that, using functionals, the squared mean error argmin is $[y]$: $f^* = argmin_f E_{x,y \sim p*(x,y)}(y-f(x))^2$ gives us after deriving with respect to f: $\int_y(-2y + 2f(x))p(y|x) = 0$, and thus: $2E[Y] - 2f(x)*1 = 0$, which leads to $f^*(x) = E[Y]$. However, I can't use the same logic to find the functional for: $f^* = argmin_f E_{x,y \sim p*(x,y)}|y-f(x)|$ I know it's not differentiable at its minima, but is there any way to use functionals to motivate the minima as the median? Thanks.","For example, I was able to find that, using functionals, the squared mean error argmin is $[y]$: $f^* = argmin_f E_{x,y \sim p*(x,y)}(y-f(x))^2$ gives us after deriving with respect to f: $\int_y(-2y + 2f(x))p(y|x) = 0$, and thus: $2E[Y] - 2f(x)*1 = 0$, which leads to $f^*(x) = E[Y]$. However, I can't use the same logic to find the functional for: $f^* = argmin_f E_{x,y \sim p*(x,y)}|y-f(x)|$ I know it's not differentiable at its minima, but is there any way to use functionals to motivate the minima as the median? Thanks.",,"['statistics', 'machine-learning']"
81,How to quantify the differencen between 2/4 and 20/40?,How to quantify the differencen between 2/4 and 20/40?,,"Assume I have two methods to do prediction. The first method makes 4 predictions and 2 out of 4 are correct. The second method makes 40 predictions and 20 out of 40 are correct. The prediction precisions of both methods are the same, which is 2/4=20/40=0.5. But I think the second method is better than the first one, because it makes more correct predictions. Is there a measure to quantify this? Any suggestion may help:) Thanks in advance.","Assume I have two methods to do prediction. The first method makes 4 predictions and 2 out of 4 are correct. The second method makes 40 predictions and 20 out of 40 are correct. The prediction precisions of both methods are the same, which is 2/4=20/40=0.5. But I think the second method is better than the first one, because it makes more correct predictions. Is there a measure to quantify this? Any suggestion may help:) Thanks in advance.",,"['statistics', 'statistical-inference', 'machine-learning']"
82,Standard Deviation. Why do we take the square root of the entire equation?,Standard Deviation. Why do we take the square root of the entire equation?,,"Please forgive my lack of maths knowledge, It is my understanding that: Standard Deviation is the average distance from the mean in a data set of numbers. Therefore it stands to reason that working out the standard deviation of the data set $x_i = \{1,2,3,4,5\}$ would involve the following. First working out the mean $\mu(x_i) = 3$ and Then working out the sum of the distance from the average $\sum{|x_i-\mu|} = 6$ then we do $\frac{\sum{|x_i-\mu|}}{N} = \frac{6}{5} = 1.2$ This means that, according to my method/thinking, 1.2 is the standard deviation. However when using the formula $\sqrt{\frac{\sum{(x_i-\mu)}^2}{N}}$ I get $1.414$ Can someone explain why I'm wrong in layman terms. Thankyou","Please forgive my lack of maths knowledge, It is my understanding that: Standard Deviation is the average distance from the mean in a data set of numbers. Therefore it stands to reason that working out the standard deviation of the data set $x_i = \{1,2,3,4,5\}$ would involve the following. First working out the mean $\mu(x_i) = 3$ and Then working out the sum of the distance from the average $\sum{|x_i-\mu|} = 6$ then we do $\frac{\sum{|x_i-\mu|}}{N} = \frac{6}{5} = 1.2$ This means that, according to my method/thinking, 1.2 is the standard deviation. However when using the formula $\sqrt{\frac{\sum{(x_i-\mu)}^2}{N}}$ I get $1.414$ Can someone explain why I'm wrong in layman terms. Thankyou",,"['statistics', 'standard-deviation']"
83,"Variance is the squared difference - why not to the 3, or 4 instead?","Variance is the squared difference - why not to the 3, or 4 instead?",,"So there is this question about  why variance  is squared. And the answer seems to be "" because we get to do groovy maths when it is squared "". Ok, that's cool, I can dig. However, I'm sitting reading some financial maths stuff, and a lot of the equations on pricing and risk are based on variance. It doesn't seem to be the best basis for, you know, pricing exotic vehicles that are worth in the millions (or billions) that a formula for variance is used ""because the maths is better"". To make a point  then, why not have the variance be from the cubed , abs cubed, or the 4th power (or even a negative power)? eg (apologies, I don't know Latex) Sum 1/N * |(x - mean)^3| OR Sum 1/N * (x - mean)^4 Would using variance-to-a-different power measurably alter pricings/valuations if the equations still used variance as usual (but the variance was calculated with the different power)? Is there a reason why we stopped  at ""power of 2"", and are there any implications of using a variance concocted from a different (higher or lower) power?","So there is this question about  why variance  is squared. And the answer seems to be "" because we get to do groovy maths when it is squared "". Ok, that's cool, I can dig. However, I'm sitting reading some financial maths stuff, and a lot of the equations on pricing and risk are based on variance. It doesn't seem to be the best basis for, you know, pricing exotic vehicles that are worth in the millions (or billions) that a formula for variance is used ""because the maths is better"". To make a point  then, why not have the variance be from the cubed , abs cubed, or the 4th power (or even a negative power)? eg (apologies, I don't know Latex) Sum 1/N * |(x - mean)^3| OR Sum 1/N * (x - mean)^4 Would using variance-to-a-different power measurably alter pricings/valuations if the equations still used variance as usual (but the variance was calculated with the different power)? Is there a reason why we stopped  at ""power of 2"", and are there any implications of using a variance concocted from a different (higher or lower) power?",,"['statistics', 'standard-deviation']"
84,when to use which z score equation?,when to use which z score equation?,,in some exam past papers I have been doing I have come across the statistics equation z=(sample mean - mean)/standard deviation as well as the equation z = (sample mean - mean)/(standard deviation/sqrt n). could anyone please explain when to use which equation and what the difference is? thanks so much!,in some exam past papers I have been doing I have come across the statistics equation z=(sample mean - mean)/standard deviation as well as the equation z = (sample mean - mean)/(standard deviation/sqrt n). could anyone please explain when to use which equation and what the difference is? thanks so much!,,"['statistics', 'normal-distribution']"
85,Determinant of Fisher information,Determinant of Fisher information,,"In information geometry, the determinant of the Fisher information matrix is a natural volume form on a statistical manifold, so it has a nice geometrical interpretation. But what is it in statistics? Does it measure anything meaningful? (For example, I would say that if it is zero, then the parameters are not independent. Does this go any further?) Also, is there any closed form to compute it? Thanks. Update : I posted a similar question on stats.se .","In information geometry, the determinant of the Fisher information matrix is a natural volume form on a statistical manifold, so it has a nice geometrical interpretation. But what is it in statistics? Does it measure anything meaningful? (For example, I would say that if it is zero, then the parameters are not independent. Does this go any further?) Also, is there any closed form to compute it? Thanks. Update : I posted a similar question on stats.se .",,"['statistics', 'information-theory', 'information-geometry']"
86,Well known probability distributions defined on a $n$-dimensional simplex besides the Dirichlet distribution?,Well known probability distributions defined on a -dimensional simplex besides the Dirichlet distribution?,n,"Are there well known probability distributions defined on a n-dimensional simplex besides the Dirichlet distribution where the variation of of each component doesn't vary as much when the mean of the component changes as in the Dirichlet distribution? In the Dirichlet distribution , the variance changes too much when the mean changes between $(0, 1)$. I'm thinking of something more like a multivariate normal distribution but defined on the $n$-dimensional simplex.","Are there well known probability distributions defined on a n-dimensional simplex besides the Dirichlet distribution where the variation of of each component doesn't vary as much when the mean of the component changes as in the Dirichlet distribution? In the Dirichlet distribution , the variance changes too much when the mean changes between $(0, 1)$. I'm thinking of something more like a multivariate normal distribution but defined on the $n$-dimensional simplex.",,"['statistics', 'probability-distributions', 'reference-request', 'normal-distribution', 'simplex']"
87,Convergence in probability,Convergence in probability,,"If $X_1, X_2, \ldots$ converge in probability to a constant $c$, then does $1-X_1, 1-X_2, \ldots$ converge in probability to $1-c$? Is there a way to show this is true / is there an already existent theorem for this?","If $X_1, X_2, \ldots$ converge in probability to a constant $c$, then does $1-X_1, 1-X_2, \ldots$ converge in probability to $1-c$? Is there a way to show this is true / is there an already existent theorem for this?",,['statistics']
88,"How to find the sufficient statistics for the shifted exponential distribution $f_{\theta, k}(y) = \theta e^{-\theta (y - k)}, y \ge k, \theta \gt 0$?",How to find the sufficient statistics for the shifted exponential distribution ?,"f_{\theta, k}(y) = \theta e^{-\theta (y - k)}, y \ge k, \theta \gt 0","How to find the sufficient statistics for the shifted exponential distribution $f_{\theta, k}(y) = \theta e^{-\theta (y - k)}, y \ge k, \theta\gt 0$ ? If a) $k$ is known b) $k$ is unknown I believe we can use factorization theorem here. So the likelihood $$L(\theta, k; y) = \prod_{i = 1} \theta e^{-\theta (y_i - k)} = \mathbb{1}_{\min\{Y\} \ge k} \theta^n e^{-\theta \sum_{i=1}^n(y_i - k)} = \mathbb{1}_{\min\{Y\} \ge k} \theta^n e^{-\theta \sum_{i = 1}^n y_i + n \theta k}.$$ So here we have $\mathbb{1}_{\min{Y}\ge k} \theta^n e^{-\theta \sum_{i = 1}^n y_i + n \theta k}$ as $g(T(y), (\theta, k))$ and $h(y) = 1$ . But then I am confused what's the difference between we know $k$ and we do not know $k$ . Could someone please explain?",How to find the sufficient statistics for the shifted exponential distribution ? If a) is known b) is unknown I believe we can use factorization theorem here. So the likelihood So here we have as and . But then I am confused what's the difference between we know and we do not know . Could someone please explain?,"f_{\theta, k}(y) = \theta e^{-\theta (y - k)}, y \ge k, \theta\gt 0 k k L(\theta, k; y) = \prod_{i = 1} \theta e^{-\theta (y_i - k)} = \mathbb{1}_{\min\{Y\} \ge k} \theta^n e^{-\theta \sum_{i=1}^n(y_i - k)} = \mathbb{1}_{\min\{Y\} \ge k} \theta^n e^{-\theta \sum_{i = 1}^n y_i + n \theta k}. \mathbb{1}_{\min{Y}\ge k} \theta^n e^{-\theta \sum_{i = 1}^n y_i + n \theta k} g(T(y), (\theta, k)) h(y) = 1 k k","['statistics', 'statistical-inference', 'parameter-estimation', 'exponential-distribution']"
89,Analytic solution for matrix factorization using alternating least squares,Analytic solution for matrix factorization using alternating least squares,,"The standard form for ridge regression aims to minimize the following cost function. $$ \min\ \ \sum_i(y_i-x_i^T\beta)^2 + \lambda\sum_j\beta^2_j $$ As described here , it's possible to differentiate that function with respect to $\beta$ and derive the analytical solution as $$ \beta^{ridge}=(X^TX+\lambda I)^{-1}X^Ty $$ Collaborative Filtering for Implicit Feedback Datasets is a popular paper in the field of generating recommendations using matrix factorization. The authors proposed the use of alternating least squares to minimize a slightly different cost function. $$ \min_{x^*, y^*}\ \ \sum_{u,i}c_{ui}(p_{ui}-x_i^Ty_i)^2+\lambda(\sum_u\|x_u\|^2+\|y_u\|^2)  $$ The authors state the analytical solution as $$ x_u = (Y^TC^uY + \lambda I)^{-1}Y^TC^up(u) $$ $$ y_i = (X^TC^iX + \lambda I)^{-1}X^TC^ip(i) $$ where $C^u$ and $C^i$ are diagonal $n*n$ and $m*m$ matrices. Can somebody please show me how I can derive this? I have tried using the same procedure as the standard ridge regression but I am unable to see how/where the $C^u$ and $C^i$ show up. If you're interested, here's a python implementation of this algorithm. The code does not directly match the expression in the paper.","The standard form for ridge regression aims to minimize the following cost function. $$ \min\ \ \sum_i(y_i-x_i^T\beta)^2 + \lambda\sum_j\beta^2_j $$ As described here , it's possible to differentiate that function with respect to $\beta$ and derive the analytical solution as $$ \beta^{ridge}=(X^TX+\lambda I)^{-1}X^Ty $$ Collaborative Filtering for Implicit Feedback Datasets is a popular paper in the field of generating recommendations using matrix factorization. The authors proposed the use of alternating least squares to minimize a slightly different cost function. $$ \min_{x^*, y^*}\ \ \sum_{u,i}c_{ui}(p_{ui}-x_i^Ty_i)^2+\lambda(\sum_u\|x_u\|^2+\|y_u\|^2)  $$ The authors state the analytical solution as $$ x_u = (Y^TC^uY + \lambda I)^{-1}Y^TC^up(u) $$ $$ y_i = (X^TC^iX + \lambda I)^{-1}X^TC^ip(i) $$ where $C^u$ and $C^i$ are diagonal $n*n$ and $m*m$ matrices. Can somebody please show me how I can derive this? I have tried using the same procedure as the standard ridge regression but I am unable to see how/where the $C^u$ and $C^i$ show up. If you're interested, here's a python implementation of this algorithm. The code does not directly match the expression in the paper.",,"['statistics', 'regression', 'machine-learning', 'least-squares']"
90,Examples of sufficient statistics for non-exponential family distributions?,Examples of sufficient statistics for non-exponential family distributions?,,"I know that the Pitman-Koopman-Darmois theorem says that only exponential family distributions have sufficient statistics whose dimension stays constant as the sample size increases. I further know that the Fisher-Neyman factorization theorem says that any distribution with a sufficient statistic can be factorized as  $f(x;\theta) = h(x)\cdot g(T(x);\theta).$ Trivially, if $T(x)$ is a bijection, then $g$ could just invert $T$ and recover the whole original sample, and thus $T$ should be ""sufficient"". But the way the Pitman-Koopman-Darmois theorem is always stated raises what I think is an obvious question, but to which I can't seem to find a clear answer : Are there any distributions which have sufficient statistics which grow in dimension as the sample size grows, and which are ""lossy"" functions of their input data? In particular, I'm thinking that if there's some class of distributions where the dimension of $T$ grows sublinearly with the dataset size, then those distributions could be incredibly useful in distributed computational settings.","I know that the Pitman-Koopman-Darmois theorem says that only exponential family distributions have sufficient statistics whose dimension stays constant as the sample size increases. I further know that the Fisher-Neyman factorization theorem says that any distribution with a sufficient statistic can be factorized as  $f(x;\theta) = h(x)\cdot g(T(x);\theta).$ Trivially, if $T(x)$ is a bijection, then $g$ could just invert $T$ and recover the whole original sample, and thus $T$ should be ""sufficient"". But the way the Pitman-Koopman-Darmois theorem is always stated raises what I think is an obvious question, but to which I can't seem to find a clear answer : Are there any distributions which have sufficient statistics which grow in dimension as the sample size grows, and which are ""lossy"" functions of their input data? In particular, I'm thinking that if there's some class of distributions where the dimension of $T$ grows sublinearly with the dataset size, then those distributions could be incredibly useful in distributed computational settings.",,"['statistics', 'probability-distributions']"
91,"Rigorous book on bootstrapping, boosting, bagging, etc.","Rigorous book on bootstrapping, boosting, bagging, etc.",,"Is there a mathematically rigorous book giving an introduction to boosting, etc. A book that is rigorous like ""A Course in Probability Theory"" by Kai Lai Chung.","Is there a mathematically rigorous book giving an introduction to boosting, etc. A book that is rigorous like ""A Course in Probability Theory"" by Kai Lai Chung.",,"['reference-request', 'statistics']"
92,"Two envelope paradox, instead with amounts distributed uniformly.","Two envelope paradox, instead with amounts distributed uniformly.",,"There are two envelopes, each of which has a check for a Unif(0, 1) amount of money, measured in thousands of dollars. The amounts in the two envelopes are independent. You get to choose an envelope and open it, and then you can either keep that amount or switch to the other envelope and get whatever amount is in that envelope. Suppose that you use the following strategy: choose an envelope and open it. If you observe U, then stick with that envelope with probability U, and switch to the other envelope with probability 1 − U. (a) Find the probability that you get the larger of the two amounts. (b) Find the expected value of what you will receive.","There are two envelopes, each of which has a check for a Unif(0, 1) amount of money, measured in thousands of dollars. The amounts in the two envelopes are independent. You get to choose an envelope and open it, and then you can either keep that amount or switch to the other envelope and get whatever amount is in that envelope. Suppose that you use the following strategy: choose an envelope and open it. If you observe U, then stick with that envelope with probability U, and switch to the other envelope with probability 1 − U. (a) Find the probability that you get the larger of the two amounts. (b) Find the expected value of what you will receive.",,['statistics']
93,Asymptotic distribution for MLE of exponential distribution,Asymptotic distribution for MLE of exponential distribution,,"Let $X$ have an exponential distribution with parameter $\theta$ (pdf is $f(x, \theta) = \theta e^{-\theta x}$). I already found that the MLE for $\theta$ after $n$ observations is $$\hat{\theta}_{MLE} = \bar{X}^{-1} = \frac{n}{\sum_{i=1}^n{X_i}}$$ and that $\bar{X} \tilde{} \Gamma(n, n\theta)$. The question is to derive directly (i.e. without using the general theory for asymptotic behaviour of MLEs) the asymptotic distribution of $$\sqrt n (\hat{\theta}_{MLE} - \theta)$$ as $n \to \infty$. According to the general theory (which I should not be using), I am supposed to find that it is asymptotically $N(0, I(\theta)^{-1}) = N(0, \theta^2)$. However, I don't know where to start - for other distributions I was able to use CLT (if their MLE was the sample mean), but I can't think of a way to do it here.","Let $X$ have an exponential distribution with parameter $\theta$ (pdf is $f(x, \theta) = \theta e^{-\theta x}$). I already found that the MLE for $\theta$ after $n$ observations is $$\hat{\theta}_{MLE} = \bar{X}^{-1} = \frac{n}{\sum_{i=1}^n{X_i}}$$ and that $\bar{X} \tilde{} \Gamma(n, n\theta)$. The question is to derive directly (i.e. without using the general theory for asymptotic behaviour of MLEs) the asymptotic distribution of $$\sqrt n (\hat{\theta}_{MLE} - \theta)$$ as $n \to \infty$. According to the general theory (which I should not be using), I am supposed to find that it is asymptotically $N(0, I(\theta)^{-1}) = N(0, \theta^2)$. However, I don't know where to start - for other distributions I was able to use CLT (if their MLE was the sample mean), but I can't think of a way to do it here.",,"['statistics', 'parameter-estimation']"
94,"1/f ""Pink Noise"" for the Math-Disabled","1/f ""Pink Noise"" for the Math-Disabled",,"I have very little skill when it comes to math beyond all the elementary level operations (addition, subtraction, multiplication, division, mean, mode, etc) and a vague grasp of statistics, what a graph is, and algebra. I'm a writer at heart, and noticed a few discussions online about 1/f wave patterns or ""pink noise."" As much as I tried to comprehend the maths, the subject is over my head What I want to do is structure the beats of my text to produce a more pleasant experience that helps hold reader attention using natural mathematical rhythms as a guidelines. Would someone write up a set of steps, or pseudo-code explaining how the relations of intervals between points on a number line produce 1/f ""pink noise""?","I have very little skill when it comes to math beyond all the elementary level operations (addition, subtraction, multiplication, division, mean, mode, etc) and a vague grasp of statistics, what a graph is, and algebra. I'm a writer at heart, and noticed a few discussions online about 1/f wave patterns or ""pink noise."" As much as I tried to comprehend the maths, the subject is over my head What I want to do is structure the beats of my text to produce a more pleasant experience that helps hold reader attention using natural mathematical rhythms as a guidelines. Would someone write up a set of steps, or pseudo-code explaining how the relations of intervals between points on a number line produce 1/f ""pink noise""?",,"['statistics', 'algorithms', 'graphing-functions']"
95,Standard Deviation Annualized,Standard Deviation Annualized,,"Say I take the standard deviation of 730 data points, representing two years worth of data. How would I convert this standard deviation to an ""annualized"" one? Thanks for the help.","Say I take the standard deviation of 730 data points, representing two years worth of data. How would I convert this standard deviation to an ""annualized"" one? Thanks for the help.",,['statistics']
96,Fitting an exponential function to data,Fitting an exponential function to data,,"I have a noisy data set (the grey line in the graph below) that corresponds roughly to $y=m(1-2^{-x/k})$ where m and k are unknown constants. How can I determine the best-fit value of m and k ? I can get an approximate value for k by guessing m and then doing linear regression on $-\log_2(1-y/m)$... by this I estimate m =0.96 and k =1000 (see red and blue dotted lines above), but is there a more systematic way? Thanks in advance.","I have a noisy data set (the grey line in the graph below) that corresponds roughly to $y=m(1-2^{-x/k})$ where m and k are unknown constants. How can I determine the best-fit value of m and k ? I can get an approximate value for k by guessing m and then doing linear regression on $-\log_2(1-y/m)$... by this I estimate m =0.96 and k =1000 (see red and blue dotted lines above), but is there a more systematic way? Thanks in advance.",,"['statistics', 'matlab', 'regression']"
97,"What is the purpose of the contrast function in independent component analysis, specifically fast ICA?","What is the purpose of the contrast function in independent component analysis, specifically fast ICA?",,What exactly is meant by a contrast function in this context?  How does it differ from the objective function?  Why is it that several contrast functions can work here?,What exactly is meant by a contrast function in this context?  How does it differ from the objective function?  Why is it that several contrast functions can work here?,,"['statistics', 'optimization', 'nonlinear-optimization']"
98,How does research in math differ from research in statistics?,How does research in math differ from research in statistics?,,"I'm at a crossroads where I'm considering switching my major from electrical engineering to math, because quite frankly, I'm just not getting enough math to satisfy my passion from engineering. While my school doesn't offer a statistics bachelor's degree, it does offer statistics courses from the math department. Now, I would certainly like to combine a level of employability with a math degree. I'm very curious, though, about what I could do with statistics (I had never given it much thought before). So my questions are: How closely related are math and statistics? Can someone go from a math bachelor's degree (having taken some statistics courses) to a statistics graduate degree? Could someone who loves math also love statistics? Having asked all of the above, what are the differences between how university statistics professors and math professors approach research problems? How does the quantity and range of unsolved statistics problems compare to the ones in math? Note: I have had no exposure to statistics at all so far.","I'm at a crossroads where I'm considering switching my major from electrical engineering to math, because quite frankly, I'm just not getting enough math to satisfy my passion from engineering. While my school doesn't offer a statistics bachelor's degree, it does offer statistics courses from the math department. Now, I would certainly like to combine a level of employability with a math degree. I'm very curious, though, about what I could do with statistics (I had never given it much thought before). So my questions are: How closely related are math and statistics? Can someone go from a math bachelor's degree (having taken some statistics courses) to a statistics graduate degree? Could someone who loves math also love statistics? Having asked all of the above, what are the differences between how university statistics professors and math professors approach research problems? How does the quantity and range of unsolved statistics problems compare to the ones in math? Note: I have had no exposure to statistics at all so far.",,"['statistics', 'soft-question']"
99,Why does the central limit theorem imply that the standard deviation approaches $\frac{\sigma}{\sqrt{n}}$?,Why does the central limit theorem imply that the standard deviation approaches ?,\frac{\sigma}{\sqrt{n}},"According to the central limit theorem, if one takes random samples of size $n$ from a population of mean $\mu$ and standard deviation $\sigma$, then as $X$ gets large, $X$ approaches the normal distribution with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$. $\frac{\sigma}{\sqrt{n}}$ doesn't make sense to me. Lets look at the extreme case. Say my sample consists of the entire population. Then, shouldn't my standard deviation be just $ \sigma$ instead of $\sigma/\text{(population size)}$?","According to the central limit theorem, if one takes random samples of size $n$ from a population of mean $\mu$ and standard deviation $\sigma$, then as $X$ gets large, $X$ approaches the normal distribution with mean $\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$. $\frac{\sigma}{\sqrt{n}}$ doesn't make sense to me. Lets look at the extreme case. Say my sample consists of the entire population. Then, shouldn't my standard deviation be just $ \sigma$ instead of $\sigma/\text{(population size)}$?",,['statistics']
