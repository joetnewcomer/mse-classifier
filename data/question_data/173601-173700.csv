,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Normalizing multiple different features from unknown distributions,Normalizing multiple different features from unknown distributions,,"I'm doing some ""exploratory"" data analysis over a large set of classes/proteins, with a few hundred different features (I.E. Continuous variables) extracted from the data.  The features are calculated by different criteria (Letter frequency, letter group frequencies, physiochemical parameters, protein length, etc'), and there's no reason to assume that any feature has a normal distribution (but I don't know what sort of distribution it might have). My goal is to normalize the features, so I can use the features to discriminate between different classes, using machine learning/python/matlab most likely. (For that I need to normalize the features). So, what's the best way to normalize the features for the different groups?  (Standard normalization, i.e sample-mean/Var , doesn't seem appropriate, since the underlying distribution(s) may be non normal, and dividing into percentiles loses a lot of information). Thank you very much, and I apologize if this is trivial.","I'm doing some ""exploratory"" data analysis over a large set of classes/proteins, with a few hundred different features (I.E. Continuous variables) extracted from the data.  The features are calculated by different criteria (Letter frequency, letter group frequencies, physiochemical parameters, protein length, etc'), and there's no reason to assume that any feature has a normal distribution (but I don't know what sort of distribution it might have). My goal is to normalize the features, so I can use the features to discriminate between different classes, using machine learning/python/matlab most likely. (For that I need to normalize the features). So, what's the best way to normalize the features for the different groups?  (Standard normalization, i.e sample-mean/Var , doesn't seem appropriate, since the underlying distribution(s) may be non normal, and dividing into percentiles loses a lot of information). Thank you very much, and I apologize if this is trivial.",,"['statistics', 'normed-spaces', 'statistical-inference', 'machine-learning', 'biology']"
1,"Smallest set of Liner equations, which exactly fit a set of points","Smallest set of Liner equations, which exactly fit a set of points",,"I have a set of 2-d points,(it can be of any arbitrary dimension n). I want to find the minimum set of straight lines(linear equations) which exactly passes through the given 2-d points (unlike regression, I dont want any error here).","I have a set of 2-d points,(it can be of any arbitrary dimension n). I want to find the minimum set of straight lines(linear equations) which exactly passes through the given 2-d points (unlike regression, I dont want any error here).",,"['linear-algebra', 'statistics', 'numerical-linear-algebra', 'regression', 'interpolation']"
2,Model selection: geometric mean of the standard deviation.,Model selection: geometric mean of the standard deviation.,,"I have two models that represent a physical process. To determine which model is the best, I make some experiments and compare measured data with data predicted by each of the models. The model with the lowest root mean square error ($\sigma$) between measured and predicted data will be selected. If I make only one experiment, (i.e., I have only one sample) it is trivial to find the best $\sigma$. But I have two experiments, their data cannot be considered to come from the same sample, and both samples should have the same weight in the selection of the model. Then, I have two models: $a$ and $b$, two experiments: $1$ and $2$, and four $\sigma$: $\sigma_{a1}$, $\sigma_{a2}$, $\sigma_{b1}$ and $\sigma_{b2}$. I have derived that the best model will be the one with the minimum geometric mean of $\sigma$ for both experiments (i.e., the minimum between $\sqrt{\sigma_{a1} . \sigma_{a2}}$ and $\sqrt{\sigma_{b1} . \sigma_{b2}}$). Am I right? It would be very important for me to find a reference for this result, can you help me?","I have two models that represent a physical process. To determine which model is the best, I make some experiments and compare measured data with data predicted by each of the models. The model with the lowest root mean square error ($\sigma$) between measured and predicted data will be selected. If I make only one experiment, (i.e., I have only one sample) it is trivial to find the best $\sigma$. But I have two experiments, their data cannot be considered to come from the same sample, and both samples should have the same weight in the selection of the model. Then, I have two models: $a$ and $b$, two experiments: $1$ and $2$, and four $\sigma$: $\sigma_{a1}$, $\sigma_{a2}$, $\sigma_{b1}$ and $\sigma_{b2}$. I have derived that the best model will be the one with the minimum geometric mean of $\sigma$ for both experiments (i.e., the minimum between $\sqrt{\sigma_{a1} . \sigma_{a2}}$ and $\sqrt{\sigma_{b1} . \sigma_{b2}}$). Am I right? It would be very important for me to find a reference for this result, can you help me?",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'standard-deviation']"
3,Help understanding interaction and effect.,Help understanding interaction and effect.,,I am reading a research paper in which the authors designed three bots and wanted to determine what bot was most human-like (link is at the bottom). To do this they had subjects play against each bot and answer questions about each bots performance. The questions where answered on a scale of -2 to 2 where -2 was strongly disagree and 2 was strongly agree. Once all the subjects answered the questions the authors averaged all of the responses and plotted them on a graph. The graph shows the mean agreement and has error bars that show 95% confidence intervals around the mean. The authors then perform a 2-way analysis of variance on the bot type and question. The results are as follows: There is a difference between bots The effect of the question is not significant. There is a significant interaction between bot type and question. I have a weak background in statistics and I was hoping that someone could explain what these results mean in simple terms. http://ro.ecu.edu.au/cgi/viewcontent.cgi?article=1732&context=ecuworks,I am reading a research paper in which the authors designed three bots and wanted to determine what bot was most human-like (link is at the bottom). To do this they had subjects play against each bot and answer questions about each bots performance. The questions where answered on a scale of -2 to 2 where -2 was strongly disagree and 2 was strongly agree. Once all the subjects answered the questions the authors averaged all of the responses and plotted them on a graph. The graph shows the mean agreement and has error bars that show 95% confidence intervals around the mean. The authors then perform a 2-way analysis of variance on the bot type and question. The results are as follows: There is a difference between bots The effect of the question is not significant. There is a significant interaction between bot type and question. I have a weak background in statistics and I was hoping that someone could explain what these results mean in simple terms. http://ro.ecu.edu.au/cgi/viewcontent.cgi?article=1732&context=ecuworks,,['statistics']
4,Prove the relatinship between Beta Distribution and Bionomial Distribution,Prove the relatinship between Beta Distribution and Bionomial Distribution,,"Prove that  $$ \sum_{k=0}^{x}{n\choose k} p^k (a-p)^{n-k} = (n-x){n\choose x}\int_{0}^{1-p}t^{n-x-1}(1-t)^{x}dt $$ (Hint : Integrate by parts or differentiate both sides with respect to $p$) From the book ""Statistical Inference"" Until now, I figured out it is enough to show $$ P[\mathrm{Bin} (n,p) \leq x] = P[ \mathrm{Beta} (n-x,x+1) \leq 1-p] $$ But it is hard to develop the above equation. Can anybody help?","Prove that  $$ \sum_{k=0}^{x}{n\choose k} p^k (a-p)^{n-k} = (n-x){n\choose x}\int_{0}^{1-p}t^{n-x-1}(1-t)^{x}dt $$ (Hint : Integrate by parts or differentiate both sides with respect to $p$) From the book ""Statistical Inference"" Until now, I figured out it is enough to show $$ P[\mathrm{Bin} (n,p) \leq x] = P[ \mathrm{Beta} (n-x,x+1) \leq 1-p] $$ But it is hard to develop the above equation. Can anybody help?",,"['statistics', 'probability-distributions']"
5,Expectation of a Uniform PDF,Expectation of a Uniform PDF,,"How do I find the expectation of the following pdf? $f(x,y) = 1/\pi r^2$ , where $x^2+y^2 \leq r^2$ I've tried to integrate it on the bounds $-\sqrt{1-x^2}$ and $\sqrt{1-x^2}$ for $\int \frac{x}{\pi r^2} dx$. However once I apply the net change theorem I get 0. What am I doing wrong?","How do I find the expectation of the following pdf? $f(x,y) = 1/\pi r^2$ , where $x^2+y^2 \leq r^2$ I've tried to integrate it on the bounds $-\sqrt{1-x^2}$ and $\sqrt{1-x^2}$ for $\int \frac{x}{\pi r^2} dx$. However once I apply the net change theorem I get 0. What am I doing wrong?",,"['calculus', 'probability', 'statistics']"
6,Yule Walker equations,Yule Walker equations,,The Yule-Walker equations relate the auto covariance of a random signal to the autoregressive (AR) model parameters. They can be used to estimate AR models from data by first estimating the auto covariance sequence for the data and then using it to solve for the autoregressive parameters.Show that the Yule-Walker equations hold even when we do not assume c=0.?,The Yule-Walker equations relate the auto covariance of a random signal to the autoregressive (AR) model parameters. They can be used to estimate AR models from data by first estimating the auto covariance sequence for the data and then using it to solve for the autoregressive parameters.Show that the Yule-Walker equations hold even when we do not assume c=0.?,,"['statistics', 'time-series']"
7,Confidence Interval and margin of error,Confidence Interval and margin of error,,I had the following question on a study guide and was wondering if I did it correctly. I was confused because of the way the question is worded. Here is the question: And here is how I attempted it: Is this correct?? I was confused because I think the problem asked for confidence interval when it actually meant margin of error. Thanks for the help!,I had the following question on a study guide and was wondering if I did it correctly. I was confused because of the way the question is worded. Here is the question: And here is how I attempted it: Is this correct?? I was confused because I think the problem asked for confidence interval when it actually meant margin of error. Thanks for the help!,,[]
8,Derive a model for the variances $\sigma_i^2$ for which $b_1$ is the best linear unbiased estimator (BLUE) of $\beta$,Derive a model for the variances  for which  is the best linear unbiased estimator (BLUE) of,\sigma_i^2 b_1 \beta,"Consider the model $y_i=\beta x_i + \epsilon_i$ (without a constant term and with $k=1$ ), where $\mathbb{E}[\epsilon_i]=0, \mathbb{E}[\epsilon_i \epsilon_j]=0, \forall i \neq j$ , and $\mathbb{E}[\epsilon_i^2]=\sigma_i^2$ . Then consider following estimators of $\beta:$ $$b_1=\frac{\sum{x_iy_i}}{\sum{x_i^2}},$$ $$b_2=\frac{\sum y_i}{\sum x_i}$$ and derive a model for the variances $\sigma_i^2$ for which this estimator is the best linear unbiased estimator (BLUE) of $\beta$ My attempt so far: I thought I should write this model in the 'standard form' for which we know that the OLS estimator is BLUE. So I tried to deduce the variance of this estimator so that maybe this could be corrected by a certain factor (similarly to in Weighted Least Squares). The variance that I got is: $$\mathrm{Var}[b_1]=\frac{\sum x_i^2 \sigma_i^2}{\left(\sum x_i^2\right)^2}.$$ However, it doesn't seem that I can correct this variance by a factor to bring it to that of the standard model. Same problem for $b_2$ . Could anyone please help?","Consider the model (without a constant term and with ), where , and . Then consider following estimators of and derive a model for the variances for which this estimator is the best linear unbiased estimator (BLUE) of My attempt so far: I thought I should write this model in the 'standard form' for which we know that the OLS estimator is BLUE. So I tried to deduce the variance of this estimator so that maybe this could be corrected by a certain factor (similarly to in Weighted Least Squares). The variance that I got is: However, it doesn't seem that I can correct this variance by a factor to bring it to that of the standard model. Same problem for . Could anyone please help?","y_i=\beta x_i + \epsilon_i k=1 \mathbb{E}[\epsilon_i]=0, \mathbb{E}[\epsilon_i \epsilon_j]=0, \forall i \neq j \mathbb{E}[\epsilon_i^2]=\sigma_i^2 \beta: b_1=\frac{\sum{x_iy_i}}{\sum{x_i^2}}, b_2=\frac{\sum y_i}{\sum x_i} \sigma_i^2 \beta \mathrm{Var}[b_1]=\frac{\sum x_i^2 \sigma_i^2}{\left(\sum x_i^2\right)^2}. b_2","['statistics', 'probability-theory', 'probability-distributions', 'least-squares']"
9,Clarify my understanding for central limit theorem from a statement,Clarify my understanding for central limit theorem from a statement,,"Asked what the central limit theorem says, a student replies, ""as you take larger and larger samples from a population, the histogram of the sample values looks more and more Normal"". Is the student right? Explain your answer. My answer the student is wrong because the histogram of the sample values will look like the population distribution, whatever that distribution might look like as the sample size increases. The CLT says the sample mean follows a normal distribution with mean $u$ and variance $σ^2/n$ as the sample size goes to infinity. But CLT fails to population that has fat tails such as Cauchy Distribtion. Is this right? If so, do you think I could add a little more?","Asked what the central limit theorem says, a student replies, ""as you take larger and larger samples from a population, the histogram of the sample values looks more and more Normal"". Is the student right? Explain your answer. My answer the student is wrong because the histogram of the sample values will look like the population distribution, whatever that distribution might look like as the sample size increases. The CLT says the sample mean follows a normal distribution with mean $u$ and variance $σ^2/n$ as the sample size goes to infinity. But CLT fails to population that has fat tails such as Cauchy Distribtion. Is this right? If so, do you think I could add a little more?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
10,"Given $N$ coins, find a coin with minimal bias based on $N$ samples","Given  coins, find a coin with minimal bias based on  samples",N N,"General description: Given $N$ coins $Z_1,...,Z_N$ (Bernoulli RVs), where the $i$-th coin has probability $p_i$ for ""Head"", I'm trying to find  $\min\limits _{i\in[N]}p_{i}$. I'm interested in a ""probably accurate"" estimation: Given $\epsilon,\delta \in (0,1)$, my guess $\hat{i}$ has to hold: $\mathbb{P}(p_{\hat{i}}\leq \min\limits _{i\in[N]}p_{i} + \epsilon)\geq 1-\delta$ The parameter I'm trying to minimize here is $m$, the number of samples needed of each coin in order to comply with the probabilistic condition defined with  $\epsilon$ and $ \delta$. My objective: I must give an algorithm (or general method) which will need at most $m=\left\lceil \frac{1}{\epsilon^{2}}\cdot\frac{N}{\delta}\right\rceil $ samples. My try: The straightforward method is as follows: Given samples $\left(\left(z_{1}^{i},...,z_{m}^{i}\right)\right)_{i=1}^{N}$, compute $\hat{p}_{i}=\frac{1}{m}\sum\limits _{j=1}^{m}z_{j}^{i}$ for all $i \in [N]$ return $\hat{i}$ s.t. $\hat{p}_{\hat{i}}=\min\limits _{i\in [N]}\hat{p}_{i}$ The tricky part is to prove the bound on $m$. This is supposed to be rather simple, using basic tools such as Chebyshev's inequality or the union bound, but I threw everything I could think of at it without success. One of my tries was: if for all $i\in [N]$ it holds that $|\hat{p_i}-p_i|<\epsilon$, then the $\hat{i}$ we'll return is indeed $\epsilon$-close to  $\min\limits _{i\in[N]}p_{i}$, but using Chebyshev's inequality to compute that I get a much smaller probability than $1-\delta$ . Help will be very appreciated.","General description: Given $N$ coins $Z_1,...,Z_N$ (Bernoulli RVs), where the $i$-th coin has probability $p_i$ for ""Head"", I'm trying to find  $\min\limits _{i\in[N]}p_{i}$. I'm interested in a ""probably accurate"" estimation: Given $\epsilon,\delta \in (0,1)$, my guess $\hat{i}$ has to hold: $\mathbb{P}(p_{\hat{i}}\leq \min\limits _{i\in[N]}p_{i} + \epsilon)\geq 1-\delta$ The parameter I'm trying to minimize here is $m$, the number of samples needed of each coin in order to comply with the probabilistic condition defined with  $\epsilon$ and $ \delta$. My objective: I must give an algorithm (or general method) which will need at most $m=\left\lceil \frac{1}{\epsilon^{2}}\cdot\frac{N}{\delta}\right\rceil $ samples. My try: The straightforward method is as follows: Given samples $\left(\left(z_{1}^{i},...,z_{m}^{i}\right)\right)_{i=1}^{N}$, compute $\hat{p}_{i}=\frac{1}{m}\sum\limits _{j=1}^{m}z_{j}^{i}$ for all $i \in [N]$ return $\hat{i}$ s.t. $\hat{p}_{\hat{i}}=\min\limits _{i\in [N]}\hat{p}_{i}$ The tricky part is to prove the bound on $m$. This is supposed to be rather simple, using basic tools such as Chebyshev's inequality or the union bound, but I threw everything I could think of at it without success. One of my tries was: if for all $i\in [N]$ it holds that $|\hat{p_i}-p_i|<\epsilon$, then the $\hat{i}$ we'll return is indeed $\epsilon$-close to  $\min\limits _{i\in[N]}p_{i}$, but using Chebyshev's inequality to compute that I get a much smaller probability than $1-\delta$ . Help will be very appreciated.",,"['probability', 'statistics', 'machine-learning']"
11,How to rank a separate population using elo points/system,How to rank a separate population using elo points/system,,"Background: I have a website where students vote on the attractiveness of their peers: they are presented with two images, and they must pick one (the ""winner"")- then the elo score for each is updated. A user can choose to vote globally (i.e. cross population, i.e. between all schools), or a user can vote within a single school (i.e. separate population). All students start with 1200 points, there is a minimum of 1000 points. It's easy to rank students individually: for example the most attractive person within school ""x"" is simply the one with the highest elo points. Problem: I want to have a ranking for a group of students- in other words i want to say ""here are the most attractive schools"" My idea (which I think is bad): Take an average of the elo points for all students. My thought is that since ""every win also means there is a loss"" the distribution curve for all schools should be relatively similar- so the average elo points for every school will be relatively similar. A wider distribution curve would simply mean there are greater numbers of both more attractive and less attractive students (I think?). So does anyone have a (somewhat statistically significant) method of saying ""this group of students is more attractive than that group of students?"" I feel like I'm not collecting the proper metric- this would be easy if the users were ranking a single student on a 1-5 star scale, rather than my system where you're asked to pick between two students. Any advice much appreciated, thank you.","Background: I have a website where students vote on the attractiveness of their peers: they are presented with two images, and they must pick one (the ""winner"")- then the elo score for each is updated. A user can choose to vote globally (i.e. cross population, i.e. between all schools), or a user can vote within a single school (i.e. separate population). All students start with 1200 points, there is a minimum of 1000 points. It's easy to rank students individually: for example the most attractive person within school ""x"" is simply the one with the highest elo points. Problem: I want to have a ranking for a group of students- in other words i want to say ""here are the most attractive schools"" My idea (which I think is bad): Take an average of the elo points for all students. My thought is that since ""every win also means there is a loss"" the distribution curve for all schools should be relatively similar- so the average elo points for every school will be relatively similar. A wider distribution curve would simply mean there are greater numbers of both more attractive and less attractive students (I think?). So does anyone have a (somewhat statistically significant) method of saying ""this group of students is more attractive than that group of students?"" I feel like I'm not collecting the proper metric- this would be easy if the users were ranking a single student on a 1-5 star scale, rather than my system where you're asked to pick between two students. Any advice much appreciated, thank you.",,['statistics']
12,What's the proper graph representation for a category prices trends in time?,What's the proper graph representation for a category prices trends in time?,,"As I'm not a mathematician I thought I'd ask here for advice how to approach something I'm working on (probably a basic question for a lot of you guys, but it was a subject of a debate at my work earlier) We have this graph: and here we're trying to show the prices trend for products in ""Shoes"" category, for the last year. Every week we extracted the average discount for the ending week, for all the products available at that time in the ""shoes"" category, and now we put them in this graph. For example during the week ending on 30 June 2013 we had an average discount of 9%. This graph shows us very easily the price trends, the discounts periods, the discounts magnitude, for the last year, but it is also misleading because comparing the starting point with the ending point it states that overall we had a discount of almost 50%, which is not true all the time (because new products arrived with bigger prices, and the discounted ones have been sold). Is there any better graph representation, so we keep the price trending but not to mislead with the values? What We've tried In order to make it more understandable by the users I've generated a second graph to show the discounts level evolution (summed up for 4 continuous weeks, you can see it at http://vetements-et-chaussures.franceprix.fr/#evolution_prix , the second graph) but the discounts level graph doesn't actually really picture the big picture of the prices general trend (like in our first graph). Any suggestions how a problem like this could be approached? All ideas are more than welcome.","As I'm not a mathematician I thought I'd ask here for advice how to approach something I'm working on (probably a basic question for a lot of you guys, but it was a subject of a debate at my work earlier) We have this graph: and here we're trying to show the prices trend for products in ""Shoes"" category, for the last year. Every week we extracted the average discount for the ending week, for all the products available at that time in the ""shoes"" category, and now we put them in this graph. For example during the week ending on 30 June 2013 we had an average discount of 9%. This graph shows us very easily the price trends, the discounts periods, the discounts magnitude, for the last year, but it is also misleading because comparing the starting point with the ending point it states that overall we had a discount of almost 50%, which is not true all the time (because new products arrived with bigger prices, and the discounted ones have been sold). Is there any better graph representation, so we keep the price trending but not to mislead with the values? What We've tried In order to make it more understandable by the users I've generated a second graph to show the discounts level evolution (summed up for 4 continuous weeks, you can see it at http://vetements-et-chaussures.franceprix.fr/#evolution_prix , the second graph) but the discounts level graph doesn't actually really picture the big picture of the prices general trend (like in our first graph). Any suggestions how a problem like this could be approached? All ideas are more than welcome.",,['statistics']
13,On track Prerequisite for Statistics and Probability,On track Prerequisite for Statistics and Probability,,"I do not really have a solid mathematical background because of the range of courses i had back in high school/university that wasn't really scientific oriented. Presently i am doing an MSc in Computer Science which is going pretty well and almost completed but somehow, i have this nemesis course that deals with Poisson processes, Bernoulli, Markov chains and Branching process.The whole class(formulas) sounds Chinese to me although i am able to get the concepts. So i will like to ask : If you met this course today with no mathematical background, how will you approach it ? I have time to get back to the basics ! I just need to know a clear path before i start hitting the books. Thank you very much !","I do not really have a solid mathematical background because of the range of courses i had back in high school/university that wasn't really scientific oriented. Presently i am doing an MSc in Computer Science which is going pretty well and almost completed but somehow, i have this nemesis course that deals with Poisson processes, Bernoulli, Markov chains and Branching process.The whole class(formulas) sounds Chinese to me although i am able to get the concepts. So i will like to ask : If you met this course today with no mathematical background, how will you approach it ? I have time to get back to the basics ! I just need to know a clear path before i start hitting the books. Thank you very much !",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'markov-chains']"
14,Generalized Bayes Estimator,Generalized Bayes Estimator,,"Consider a decision problem in which the model parameter, $\theta$, is any integer, the distribution for the integer observation, y, given $\theta$ is $P(y|\theta) = 1/3$ if $y \in [\theta - 1, \theta + 1]$ and 0 otherwise. The action space is the integers, and the loss function is 0-1 loss function. The decision rule is $\delta(y) = y$. Find decision rules $\delta'$ and $\delta''$ such that $\delta'$ dominates $\delta$ and $\delta''$ dominates $\delta'$ and is admissible. I think that here we use the improper prior $f(\theta) = 1$ and so the posterior is the same as the prior (i.e. discrete uniform on $[\theta - 1, \theta + 1]$). Then with the 0-1 loss the associated Bayes estimator is the posterior mode, which in this case could be one of three values. Neither, however, seem to dominate $\delta(y) = y$. Then I tried randomized rules (for example with 1/2 prob. take $y+1$ and with 1/2 prob take $y-1$), but that also doesn't seem to work....","Consider a decision problem in which the model parameter, $\theta$, is any integer, the distribution for the integer observation, y, given $\theta$ is $P(y|\theta) = 1/3$ if $y \in [\theta - 1, \theta + 1]$ and 0 otherwise. The action space is the integers, and the loss function is 0-1 loss function. The decision rule is $\delta(y) = y$. Find decision rules $\delta'$ and $\delta''$ such that $\delta'$ dominates $\delta$ and $\delta''$ dominates $\delta'$ and is admissible. I think that here we use the improper prior $f(\theta) = 1$ and so the posterior is the same as the prior (i.e. discrete uniform on $[\theta - 1, \theta + 1]$). Then with the 0-1 loss the associated Bayes estimator is the posterior mode, which in this case could be one of three values. Neither, however, seem to dominate $\delta(y) = y$. Then I tried randomized rules (for example with 1/2 prob. take $y+1$ and with 1/2 prob take $y-1$), but that also doesn't seem to work....",,"['statistics', 'bayesian']"
15,Introductory Statistics/Probability Reference Request,Introductory Statistics/Probability Reference Request,,"I am a PhD student in mathematics with a background in Pure Mathematics. As such I have pretty much zero background in statistics or anything other than the most basic probability (i.e., what one learns in high school). Can anyone recommend good introductory texts for Statistics and Probability which would not be so elementary as to bore me to death?","I am a PhD student in mathematics with a background in Pure Mathematics. As such I have pretty much zero background in statistics or anything other than the most basic probability (i.e., what one learns in high school). Can anyone recommend good introductory texts for Statistics and Probability which would not be so elementary as to bore me to death?",,"['probability', 'statistics', 'reference-request']"
16,Statistics - Lost with this question,Statistics - Lost with this question,,"I'm having trouble doing this question because I don't know where to begin. Could someone walk me through this slowly so that I understand the thought process and how to approach questions like this? Let $X$ be the weight (in grams) of a nail of the type that is used for making decks. Assume that the distribution of X is Normal $X\sim N(\mu=8.78,\, \sigma^2=0.16)$. Let $\bar{X}$ be the mean of a random sample of the weights of $n = 9$ nails. (a) Sketch, on the same set of axes, the graphs of the probability density functions of X and of $\bar{X}$. (b) Let $S^2$ be the sample variance of the nine weights. Find constants $a$ and $b$ so that $P(a < S^2 < b) = 0.90$. (Please look for $a$ and $b$ such that $P(S^2 < a) = 0.05$ and $P(S^2 > b) = 0.05$.) Thank you.","I'm having trouble doing this question because I don't know where to begin. Could someone walk me through this slowly so that I understand the thought process and how to approach questions like this? Let $X$ be the weight (in grams) of a nail of the type that is used for making decks. Assume that the distribution of X is Normal $X\sim N(\mu=8.78,\, \sigma^2=0.16)$. Let $\bar{X}$ be the mean of a random sample of the weights of $n = 9$ nails. (a) Sketch, on the same set of axes, the graphs of the probability density functions of X and of $\bar{X}$. (b) Let $S^2$ be the sample variance of the nine weights. Find constants $a$ and $b$ so that $P(a < S^2 < b) = 0.90$. (Please look for $a$ and $b$ such that $P(S^2 < a) = 0.05$ and $P(S^2 > b) = 0.05$.) Thank you.",,"['statistics', 'normal-distribution', 'sampling']"
17,Why is the marginalized inverse-Wishart distribution not equal to the inverse-gamma distribution?,Why is the marginalized inverse-Wishart distribution not equal to the inverse-gamma distribution?,,"Given that the inverse-gamma distribution is the one-dimensional version of the inverse-Wishart distribution, why will (philosophically speaking) an inverse-Wishart distribution that originally has more than one dimension not become the inverse-gamma distribution when marginalized over all but one of the dimensions? I.e. if $\mathbf{\Psi}$ is a 2x2-matrix, and $\mathbf{X}\sim \mathcal{W}^{-1}(\mathbf{\Psi}, \nu)$, where $$ \mathcal{W}^{-1}(\mathbf{\Psi}, \nu) = \frac{|\mathbf{\Psi}|^{\nu/2}}{2^\nu\Gamma_p(\frac{\nu}{2})}|\mathbf{X}|^{-\frac{\nu+3}{2}}e^{-\frac{1}{2}tr({\mathbf{\Psi X}^{-1}})} $$ When marginalized over all but $\mathbf{X}_{11}$, you get $$ \mathbf{X}_{11} \sim \frac{\mathbf{\Psi}_{11}^{(\nu-1)/2}}{2^{\frac{\nu-1}{2}}\Gamma_1(\frac{\nu-1}{2})}\mathbf{X}_{11}^{-\frac{\nu+1}{2}}e^{-\frac{1}{2}{\mathbf{\Psi}_{11} \mathbf{X}_{11}^{-1}}} $$ whereas the inverse-gamma distribution for $\mathbf{X}_{11}$ with the corresponding parameters is $$ \mathbf{X}_{11} \sim \frac{\mathbf{\Psi}_{11}^{\nu/2}}{2^{\frac{\nu}{2}}\Gamma_1(\frac{\nu}{2})}\mathbf{X}_{11}^{-\frac{\nu+2}{2}}e^{-\frac{1}{2}{\mathbf{\Psi}_{11} \mathbf{X}_{11}^{-1}}}. $$ It seems to me that when you marginalize the 2x2 expression over all elements that are not $\mathbf{X}_{11}$, you should end up with a distribution that 'tells the same story': i.e., marginalizing over a parameter essentially means that we assume no knowledge of it - it might as well not exist. And that is the same assumption that gives rise to the inverse-gamma distribution, to my mind. So why do the two distributions not end up the same?","Given that the inverse-gamma distribution is the one-dimensional version of the inverse-Wishart distribution, why will (philosophically speaking) an inverse-Wishart distribution that originally has more than one dimension not become the inverse-gamma distribution when marginalized over all but one of the dimensions? I.e. if $\mathbf{\Psi}$ is a 2x2-matrix, and $\mathbf{X}\sim \mathcal{W}^{-1}(\mathbf{\Psi}, \nu)$, where $$ \mathcal{W}^{-1}(\mathbf{\Psi}, \nu) = \frac{|\mathbf{\Psi}|^{\nu/2}}{2^\nu\Gamma_p(\frac{\nu}{2})}|\mathbf{X}|^{-\frac{\nu+3}{2}}e^{-\frac{1}{2}tr({\mathbf{\Psi X}^{-1}})} $$ When marginalized over all but $\mathbf{X}_{11}$, you get $$ \mathbf{X}_{11} \sim \frac{\mathbf{\Psi}_{11}^{(\nu-1)/2}}{2^{\frac{\nu-1}{2}}\Gamma_1(\frac{\nu-1}{2})}\mathbf{X}_{11}^{-\frac{\nu+1}{2}}e^{-\frac{1}{2}{\mathbf{\Psi}_{11} \mathbf{X}_{11}^{-1}}} $$ whereas the inverse-gamma distribution for $\mathbf{X}_{11}$ with the corresponding parameters is $$ \mathbf{X}_{11} \sim \frac{\mathbf{\Psi}_{11}^{\nu/2}}{2^{\frac{\nu}{2}}\Gamma_1(\frac{\nu}{2})}\mathbf{X}_{11}^{-\frac{\nu+2}{2}}e^{-\frac{1}{2}{\mathbf{\Psi}_{11} \mathbf{X}_{11}^{-1}}}. $$ It seems to me that when you marginalize the 2x2 expression over all elements that are not $\mathbf{X}_{11}$, you should end up with a distribution that 'tells the same story': i.e., marginalizing over a parameter essentially means that we assume no knowledge of it - it might as well not exist. And that is the same assumption that gives rise to the inverse-gamma distribution, to my mind. So why do the two distributions not end up the same?",,"['statistics', 'statistical-inference', 'bayesian']"
18,"Have averages, need variance","Have averages, need variance",,"I have a large spreadsheet, generated by a colleague, that contains the results of $E$ experiments. For each experiment, he calculated the average of $M$ measurements. I need the calculate the average and variance of all measurements, but due to the complex structure of the spreadsheet, I cannot make the calculation directly in the spreadsheet, nor copy the data to another spreadsheet. How can use the current data, i.e., the averages per experiment and the number of measurements per experiment, to calculate the average and variance of all measurements? Here is what I did so far. Let $x_{ij}$ be measurement $j$ in experiment $i$. Let $a_i$ be the average of experiment $i$: $$a_i = \frac{1}{M} \sum_{j=1}^{M}{ x_{ij} } $$ Let $A$ be the total average: $$A = \frac{1}{EM} \sum_{i=1}^{E}{ \sum_{j=1}^{M}{ x_{ij} } } = \frac{1}{E} \sum_{i=1}^E {a_i}$$ So, I CAN calculate the total average by averaging the averages per experiment $a_i$. However, this trick doesn't seem to work for the variance. I need to calculate $V$: $$V = \frac{1}{EM} \sum_{i=1}^{E}{ \sum_{j=1}^{M}{ (x_{ij} - A)^2 } }$$ But if I calculate the variance of the $a_i$'s, I get: $$V' = \frac{1}{E} \sum_{i=1}^{E}{ (a_{i} - A)^2 }$$ These don't seem similar: $$V - V'    = \frac{1}{EM} \sum_{i=1}^{E}{     \sum_{j=1}^{M}{ [(x_{ij} - A)^2      - (a_{i} - A)^2]   } }$$ $$  = \frac{1}{EM} \sum_{i=1}^{E}{     \sum_{j=1}^{M}{ [(x_{ij} + a_{i} - 2A)\cdot(x_{ij}-a_{i})]   } } $$ Can I use the existing data to get, at least, an approximation to $V$?","I have a large spreadsheet, generated by a colleague, that contains the results of $E$ experiments. For each experiment, he calculated the average of $M$ measurements. I need the calculate the average and variance of all measurements, but due to the complex structure of the spreadsheet, I cannot make the calculation directly in the spreadsheet, nor copy the data to another spreadsheet. How can use the current data, i.e., the averages per experiment and the number of measurements per experiment, to calculate the average and variance of all measurements? Here is what I did so far. Let $x_{ij}$ be measurement $j$ in experiment $i$. Let $a_i$ be the average of experiment $i$: $$a_i = \frac{1}{M} \sum_{j=1}^{M}{ x_{ij} } $$ Let $A$ be the total average: $$A = \frac{1}{EM} \sum_{i=1}^{E}{ \sum_{j=1}^{M}{ x_{ij} } } = \frac{1}{E} \sum_{i=1}^E {a_i}$$ So, I CAN calculate the total average by averaging the averages per experiment $a_i$. However, this trick doesn't seem to work for the variance. I need to calculate $V$: $$V = \frac{1}{EM} \sum_{i=1}^{E}{ \sum_{j=1}^{M}{ (x_{ij} - A)^2 } }$$ But if I calculate the variance of the $a_i$'s, I get: $$V' = \frac{1}{E} \sum_{i=1}^{E}{ (a_{i} - A)^2 }$$ These don't seem similar: $$V - V'    = \frac{1}{EM} \sum_{i=1}^{E}{     \sum_{j=1}^{M}{ [(x_{ij} - A)^2      - (a_{i} - A)^2]   } }$$ $$  = \frac{1}{EM} \sum_{i=1}^{E}{     \sum_{j=1}^{M}{ [(x_{ij} + a_{i} - 2A)\cdot(x_{ij}-a_{i})]   } } $$ Can I use the existing data to get, at least, an approximation to $V$?",,"['statistics', 'average', 'standard-deviation']"
19,How I figure what (theoretical) dice are needed to achieve a certain curve?,How I figure what (theoretical) dice are needed to achieve a certain curve?,,"I am posting here by suggestion of RPG.se I want to make character stats that fit within certain bell curves depending on choices during character creation (for example race, gender, class, sprokets amount, whatever). And I am wondering how I figure how I calculate what dice I need to attain the curve I want, I will use for each stat a different way of rolling it, whatever one I find most appropriate... For example I might want a bell curve more accentuated (ie: everyone is almost certainly a the center), or one that is not only accentuated, but skewed to one side or another (for example, a random number between 1 and 100, but that most of the times rolls 70 instead of 50) Or maybe bowl shaped curves, or slopes, or senoidal (dunno what would be the use of that though :P) So, how I can learn more about this? (I suspect the subject is big enough that you cannot fit only in one answer here)","I am posting here by suggestion of RPG.se I want to make character stats that fit within certain bell curves depending on choices during character creation (for example race, gender, class, sprokets amount, whatever). And I am wondering how I figure how I calculate what dice I need to attain the curve I want, I will use for each stat a different way of rolling it, whatever one I find most appropriate... For example I might want a bell curve more accentuated (ie: everyone is almost certainly a the center), or one that is not only accentuated, but skewed to one side or another (for example, a random number between 1 and 100, but that most of the times rolls 70 instead of 50) Or maybe bowl shaped curves, or slopes, or senoidal (dunno what would be the use of that though :P) So, how I can learn more about this? (I suspect the subject is big enough that you cannot fit only in one answer here)",,['statistics']
20,How many different ways can 10 octupuses touch legs?,How many different ways can 10 octupuses touch legs?,,"There are 10 octopuses (octopi?). Each octopus has 8 legs. Legs on an octopus can only touch touch legs on other octupuses. Assuming each leg touches exactly 1 other leg, how many different combinations (and permutations) are possible? I have no idea how to go about solving this.","There are 10 octopuses (octopi?). Each octopus has 8 legs. Legs on an octopus can only touch touch legs on other octupuses. Assuming each leg touches exactly 1 other leg, how many different combinations (and permutations) are possible? I have no idea how to go about solving this.",,"['combinatorics', 'statistics', 'graph-theory', 'permutations']"
21,What is Lagrange's Identity in terms of Covariance and Variance?,What is Lagrange's Identity in terms of Covariance and Variance?,,"This is Lagrange's Identity What I've to put in the middle of this relation instead  $\color{red}{?}$, which led to find Lagrange's Identity in terms of variance and covariance ? $$\lvert \operatorname{Cov}(X,Y)|^2+\,\color{red}{?}=\operatorname{Var}(X)\operatorname{Var}(Y)$$ Do I need a new mathematical operator name for it? (base on matrix trace for example)","This is Lagrange's Identity What I've to put in the middle of this relation instead  $\color{red}{?}$, which led to find Lagrange's Identity in terms of variance and covariance ? $$\lvert \operatorname{Cov}(X,Y)|^2+\,\color{red}{?}=\operatorname{Var}(X)\operatorname{Var}(Y)$$ Do I need a new mathematical operator name for it? (base on matrix trace for example)",,"['calculus', 'statistics']"
22,Disagreement about rejection region for upper-tailed hypothesis test,Disagreement about rejection region for upper-tailed hypothesis test,,"If we look at the solutions for the first problem here and the first problem here , we see both problems are one-tailed tests for the upper-tail. However, in the first paper the rejection region is Z > 1.65, but in the second paper the rejection region is Z > 1.96. How can this be if both problems have a significance level of 0.05 and both are upper-tailed tests? Shouldn't they both have a rejection region of Z > 1.65? Is the second paper incorrect?","If we look at the solutions for the first problem here and the first problem here , we see both problems are one-tailed tests for the upper-tail. However, in the first paper the rejection region is Z > 1.65, but in the second paper the rejection region is Z > 1.96. How can this be if both problems have a significance level of 0.05 and both are upper-tailed tests? Shouldn't they both have a rejection region of Z > 1.65? Is the second paper incorrect?",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
23,Question about the logic behind hypothesis testing,Question about the logic behind hypothesis testing,,"Let us say that we have this following problem: ""A government agency claims that more than 50% of US tax returns were filed electronically last year. A random sample of 150 tax returns for last year contained 86 that were filed electronically. Test the claim at $\alpha = 0.05$ significance level."" In this problem our null hypothesis is: $H_0 : p \leq 0.50$ and $H_a : p > 0.50$. I've calculated the sample proportion : $\frac{x}{n} = \frac{86}{150} = 0.573$ and the standard error: $\sqrt{\frac{p(1-p)}{n}} = 0.0408$. Now my z-score is 1.79 which is greater than $z=1.64$, so I'm ""required to reject the null hypothesis."" But my question is how do I know that 86 out of 150 is not an unusual sampling to begin with? Why can't we reject the random sampling and support the claim given by $H_0$? My last question deals with what to do with $H_a$. Once $H_0$ has been rejected do we say that there is ""sufficient evidence for $H_a$"" or do we say that ""$H_a$ is true but under these conditions :""?","Let us say that we have this following problem: ""A government agency claims that more than 50% of US tax returns were filed electronically last year. A random sample of 150 tax returns for last year contained 86 that were filed electronically. Test the claim at $\alpha = 0.05$ significance level."" In this problem our null hypothesis is: $H_0 : p \leq 0.50$ and $H_a : p > 0.50$. I've calculated the sample proportion : $\frac{x}{n} = \frac{86}{150} = 0.573$ and the standard error: $\sqrt{\frac{p(1-p)}{n}} = 0.0408$. Now my z-score is 1.79 which is greater than $z=1.64$, so I'm ""required to reject the null hypothesis."" But my question is how do I know that 86 out of 150 is not an unusual sampling to begin with? Why can't we reject the random sampling and support the claim given by $H_0$? My last question deals with what to do with $H_a$. Once $H_0$ has been rejected do we say that there is ""sufficient evidence for $H_a$"" or do we say that ""$H_a$ is true but under these conditions :""?",,['statistics']
24,Expected Value of 10000 coin flips,Expected Value of 10000 coin flips,,"We toss a fair coin 10000 times and record the sequence of the results. Then we count the number of times that a sequence of 5 heads in a row followed immediately by 5 tails in a row has occurred among these results. (Of course, this number is a random variable.) What is the expected value of this number? Enter your answer as a decimal or a fraction, whichever you prefer. I have made some progress on it but granted I have one attempt left I didn't want to mess this up. I have determined that for 5 heads, and for 5 tails to occur in ten tries, the probability is 0.0009765625 with an expected value as well. My line of thinking was since we can't expect to get this sequence occur until the 10th try, the expected value of flipping 10,000 times would be 9990*0.0009765625  but this was wrong. I feel I'm very close since for any sequence of ten tries, the expected value will be 0.0009765625","We toss a fair coin 10000 times and record the sequence of the results. Then we count the number of times that a sequence of 5 heads in a row followed immediately by 5 tails in a row has occurred among these results. (Of course, this number is a random variable.) What is the expected value of this number? Enter your answer as a decimal or a fraction, whichever you prefer. I have made some progress on it but granted I have one attempt left I didn't want to mess this up. I have determined that for 5 heads, and for 5 tails to occur in ten tries, the probability is 0.0009765625 with an expected value as well. My line of thinking was since we can't expect to get this sequence occur until the 10th try, the expected value of flipping 10,000 times would be 9990*0.0009765625  but this was wrong. I feel I'm very close since for any sequence of ten tries, the expected value will be 0.0009765625",,"['probability', 'statistics']"
25,Solving an system of equations for the system,Solving an system of equations for the system,,"I'm trying to find a $n \times n$ matrix $A$, that satisfies $V_x = A V_y$, where $V_x$ and $V_y$ are both $n \times 1$ vectors of known quantities.  For what its worth, the sum of $V_x$ and the sum of $V_y$ will always equal 1, and each element in $V_x$ and $V_y$ will not be negative (probabilities...) Can $A$ be expressed in terms of $V_x$ and $V_y$? And I suspect $A$ has multiple possible solutions - is there a generalized equation which describes the possible solutions?  I'll take as much as you can tell me about the way $A, V_x$, and $V_y$ relate.  Thanks!","I'm trying to find a $n \times n$ matrix $A$, that satisfies $V_x = A V_y$, where $V_x$ and $V_y$ are both $n \times 1$ vectors of known quantities.  For what its worth, the sum of $V_x$ and the sum of $V_y$ will always equal 1, and each element in $V_x$ and $V_y$ will not be negative (probabilities...) Can $A$ be expressed in terms of $V_x$ and $V_y$? And I suspect $A$ has multiple possible solutions - is there a generalized equation which describes the possible solutions?  I'll take as much as you can tell me about the way $A, V_x$, and $V_y$ relate.  Thanks!",,"['linear-algebra', 'statistics', 'matrix-equations']"
26,Precision/std of points based on hitting an area target,Precision/std of points based on hitting an area target,,"I've have the following situation. I am scanning a circular area target with a known radius and location.  I receive back points that hit that target along with a location for the point.  However, because my scan is not perfectly precise the location of the points I get back do not necessarily fall within that target.  All I know is that they actual do come from hitting the target.  I'd like to know how to calculate the precision of a single point based on my returned points.  I can assume the the precision is the same in both x,y directions. My assumption is that I should do the following: a) Calculate the mean of the returned points b) Calculate a variance based of the distance of each point from the mean c) Subtract the variance of my actual points with the variance of points if they hit with equal probability on every point on the target.    d) The resulting variance will represent the variance of a single point. Is this correct, is there a better way to do this?","I've have the following situation. I am scanning a circular area target with a known radius and location.  I receive back points that hit that target along with a location for the point.  However, because my scan is not perfectly precise the location of the points I get back do not necessarily fall within that target.  All I know is that they actual do come from hitting the target.  I'd like to know how to calculate the precision of a single point based on my returned points.  I can assume the the precision is the same in both x,y directions. My assumption is that I should do the following: a) Calculate the mean of the returned points b) Calculate a variance based of the distance of each point from the mean c) Subtract the variance of my actual points with the variance of points if they hit with equal probability on every point on the target.    d) The resulting variance will represent the variance of a single point. Is this correct, is there a better way to do this?",,"['statistics', 'order-statistics']"
27,How much space probability should have in Statistics learning,How much space probability should have in Statistics learning,,"Of late I have started self-learning. I have bought a few well-advised Statistics books such as Statistics for Management by Levin and First Course on Probability by Ross. I observe that Ross' book has much more coverage than that of Levin's. I think Ross covers probability from Mathematical Statistics point of view rather than that of Business Statistics. Levin's does not have as much coverage on probability as Ross (In my humble opinion). And there I get confused. Given that I want pursue a career in Data Analysis, should I follow Ross book along with Levin's? Will Levin's book's coverage of Probability will suffice? Do you think following Ross' book First Course in Probability would be difficult and I should first start with Levi? Could you please give your guidance. Warm Regards Sabya","Of late I have started self-learning. I have bought a few well-advised Statistics books such as Statistics for Management by Levin and First Course on Probability by Ross. I observe that Ross' book has much more coverage than that of Levin's. I think Ross covers probability from Mathematical Statistics point of view rather than that of Business Statistics. Levin's does not have as much coverage on probability as Ross (In my humble opinion). And there I get confused. Given that I want pursue a career in Data Analysis, should I follow Ross book along with Levin's? Will Levin's book's coverage of Probability will suffice? Do you think following Ross' book First Course in Probability would be difficult and I should first start with Levi? Could you please give your guidance. Warm Regards Sabya",,"['probability', 'statistics']"
28,When can we write $f(v)dv=f(E)dE$?,When can we write ?,f(v)dv=f(E)dE,"In statistical thermodynamics we write  $$f(v)\,dv = f(E)\,dE$$ where $v$ is velocity and $E= \frac12mv^2$  is energy and $f$ refers to the distribution function Can someone explain the logic behind?","In statistical thermodynamics we write  $$f(v)\,dv = f(E)\,dE$$ where $v$ is velocity and $E= \frac12mv^2$  is energy and $f$ refers to the distribution function Can someone explain the logic behind?",,"['calculus', 'statistics', 'statistical-mechanics']"
29,Coin toss with unknown probability – Bayesian interpretation,Coin toss with unknown probability – Bayesian interpretation,,"I have observed a coin being tossed $n$ times. I do not know whether the coin is fair or not, but in every single toss I observed, the coin came up heads . What should my belief about $p$ (the probability that the coin shows heads ) be now? I cannot even say with certainty that $p>0$, since even an event with $p=0$ can occur. The frequency of heads is most compatible with $p=1$, but I doubt that is the best guess, especially if $n$ is low (it would be ridiculous to assume that $p=1$ after seeing a single heads only). How can this be handled in a Bayesian framework? What is my best guess for the true value of $p$?","I have observed a coin being tossed $n$ times. I do not know whether the coin is fair or not, but in every single toss I observed, the coin came up heads . What should my belief about $p$ (the probability that the coin shows heads ) be now? I cannot even say with certainty that $p>0$, since even an event with $p=0$ can occur. The frequency of heads is most compatible with $p=1$, but I doubt that is the best guess, especially if $n$ is low (it would be ridiculous to assume that $p=1$ after seeing a single heads only). How can this be handled in a Bayesian framework? What is my best guess for the true value of $p$?",,['statistics']
30,Sufficient Statistic Basics,Sufficient Statistic Basics,,"If I know the value of a sufficient statistic, but not the sample that generated it, am I right to suspect that the conditional distribution of any other statistic given the sufficient statistic will not depend on the parameter of interest? Formally speaking: Let $\theta$ be the parameter of interest. $T(x)$ is the known sufficient statistic. Now, for any other statistic $\tilde{T}(x)$, we (would; conjecturing) have: $$ f_{\tilde{T}\mid T}(\tilde{t}\mathbb\mid\theta,t)=f_{\tilde{T}\mid T}(\tilde{t}\mid t) $$ Thanks in advance. EDIT: just to add to my line of thought. I am thinking of the new statistic as equivalent to the sample points, since they differ just by a function. So if the if I have a sufficient statistic for the distribution, it will automatically be sufficient to any other statistic.","If I know the value of a sufficient statistic, but not the sample that generated it, am I right to suspect that the conditional distribution of any other statistic given the sufficient statistic will not depend on the parameter of interest? Formally speaking: Let $\theta$ be the parameter of interest. $T(x)$ is the known sufficient statistic. Now, for any other statistic $\tilde{T}(x)$, we (would; conjecturing) have: $$ f_{\tilde{T}\mid T}(\tilde{t}\mathbb\mid\theta,t)=f_{\tilde{T}\mid T}(\tilde{t}\mid t) $$ Thanks in advance. EDIT: just to add to my line of thought. I am thinking of the new statistic as equivalent to the sample points, since they differ just by a function. So if the if I have a sufficient statistic for the distribution, it will automatically be sufficient to any other statistic.",,"['statistics', 'statistical-inference']"
31,Simplifying the sample variance,Simplifying the sample variance,,"Let $Y_1$ and $Y_2$ be i.i.d. R.V.s sampled from a $N(\mu,\sigma^2)$, with $n=2$ it is shown that the sample variance: $$ S^2=\sum_{i=1}^n \frac{(Y_i- \overline Y)^2}{(n-1)} $$ simplifies to $$ S^2=\sum_{i=1}^n (\frac{(Y_1- Y_2)}{\sqrt2})^2 $$ I know this must be a simple question, but I do not understand how if $n=2$, the expression get simplified. Substituting $n=2$ for the first expression just gives: $$ S^2=\sum_{i=1}^n {(Y_i- \overline Y)^2}{} $$ so how do we go from here to the second equation? EDIT I expanded the first equation and now I have: ($Y_2^2-2\bar{Y}Y_2+\bar{Y^2})$ + ($Y_1^2-2\bar{Y}Y_1+\bar{Y_2}$) but I am unable to move forward, any hints or tips would be appreciated :)","Let $Y_1$ and $Y_2$ be i.i.d. R.V.s sampled from a $N(\mu,\sigma^2)$, with $n=2$ it is shown that the sample variance: $$ S^2=\sum_{i=1}^n \frac{(Y_i- \overline Y)^2}{(n-1)} $$ simplifies to $$ S^2=\sum_{i=1}^n (\frac{(Y_1- Y_2)}{\sqrt2})^2 $$ I know this must be a simple question, but I do not understand how if $n=2$, the expression get simplified. Substituting $n=2$ for the first expression just gives: $$ S^2=\sum_{i=1}^n {(Y_i- \overline Y)^2}{} $$ so how do we go from here to the second equation? EDIT I expanded the first equation and now I have: ($Y_2^2-2\bar{Y}Y_2+\bar{Y^2})$ + ($Y_1^2-2\bar{Y}Y_1+\bar{Y_2}$) but I am unable to move forward, any hints or tips would be appreciated :)",,"['probability', 'statistics']"
32,Prove or disprove an inequality involving statistics,Prove or disprove an inequality involving statistics,,"Do we have any result in statistics like this: $$|\overline x - \mu_e| \leq \sigma$$ Here $\overline x$ denotes the usual mean of some given discrete observations, $\mu_e$ their median and $\sigma$ the standard deviation of the variables. I got this feeling because I found the following problem: There are $2n+1$ numbers such that $x_1 \leq x_2 \leq x_3 \cdots \leq x_{2n} \leq x_{2n+1}$ and $\sum_{i=1}^{2n+1} x_i =0$. Show that, $$ x_{n+1}^{2} \leq \frac {1}{2n+1} \sum_{k=1}^{2n+1} x_{k}^{2}$$ plus, $\overline x$ and $\mu_e$ are supposed to be measures of central tendencies and $\sigma$ is supposed to find out how variables are scattered from the mean. It would be really strange if two such values be more far than the average scattering of all variables. Though here are two questions, my priority is the first one. But that does not mean I would not appreciate any other methods of solving the second one. Thank you in advance!","Do we have any result in statistics like this: $$|\overline x - \mu_e| \leq \sigma$$ Here $\overline x$ denotes the usual mean of some given discrete observations, $\mu_e$ their median and $\sigma$ the standard deviation of the variables. I got this feeling because I found the following problem: There are $2n+1$ numbers such that $x_1 \leq x_2 \leq x_3 \cdots \leq x_{2n} \leq x_{2n+1}$ and $\sum_{i=1}^{2n+1} x_i =0$. Show that, $$ x_{n+1}^{2} \leq \frac {1}{2n+1} \sum_{k=1}^{2n+1} x_{k}^{2}$$ plus, $\overline x$ and $\mu_e$ are supposed to be measures of central tendencies and $\sigma$ is supposed to find out how variables are scattered from the mean. It would be really strange if two such values be more far than the average scattering of all variables. Though here are two questions, my priority is the first one. But that does not mean I would not appreciate any other methods of solving the second one. Thank you in advance!",,"['probability', 'statistics', 'probability-theory', 'inequality']"
33,How to calculate $\sum(X_i-\bar{X})^2$ in R,How to calculate  in R,\sum(X_i-\bar{X})^2,"I'm trying to figure out how to calculate $\sum(X_i-\bar{X})^2$ in R, specifically identifying it in either the aov function or $\operatorname{lm}(y\sim x)$ function. I am trying to use it to calculate the s $\{\hat{Y}\}$ value in a regression confidence interval.","I'm trying to figure out how to calculate $\sum(X_i-\bar{X})^2$ in R, specifically identifying it in either the aov function or $\operatorname{lm}(y\sim x)$ function. I am trying to use it to calculate the s $\{\hat{Y}\}$ value in a regression confidence interval.",,"['statistics', 'regression']"
34,Checking random number generators,Checking random number generators,,"Given a function: $$ f(x) = \begin{cases} ax^2 & \text{for } x\in [ -1, 1], \\0 & \text{for } x\notin [-1,1].\end{cases} $$ I am to create a random number generator. I did this by finding the CDF and so I end up with $$X = \sqrt[3]{2F-1}$$ (F being some random variable generated in a spreadsheet, for example) The problem arises, however, with next tasks: a) How can we check that this generator generates numbers with a given distribution? b) Use the generator you found and the knowledge of central limit theorem to create a generator with $N(0,1)$ distribution and test it (One can use spreadsheet or programming language for the tasks) So as for the first, can I just generate a lot of data using the generator and then divide the $<max,min>$ into 10 intervals and see if the numbers that fall into them form a bell curve? As for the latter, If the distribution is to be $N(0,1)$ and the generator from point a) gives me $<-1,1>$, can I just take an absolute value of it and again - divide into intervals, try to see if a bell curve forms?","Given a function: $$ f(x) = \begin{cases} ax^2 & \text{for } x\in [ -1, 1], \\0 & \text{for } x\notin [-1,1].\end{cases} $$ I am to create a random number generator. I did this by finding the CDF and so I end up with $$X = \sqrt[3]{2F-1}$$ (F being some random variable generated in a spreadsheet, for example) The problem arises, however, with next tasks: a) How can we check that this generator generates numbers with a given distribution? b) Use the generator you found and the knowledge of central limit theorem to create a generator with $N(0,1)$ distribution and test it (One can use spreadsheet or programming language for the tasks) So as for the first, can I just generate a lot of data using the generator and then divide the $<max,min>$ into 10 intervals and see if the numbers that fall into them form a bell curve? As for the latter, If the distribution is to be $N(0,1)$ and the generator from point a) gives me $<-1,1>$, can I just take an absolute value of it and again - divide into intervals, try to see if a bell curve forms?",,['statistics']
35,Calculating the odds of winning a card game,Calculating the odds of winning a card game,,"So my friend made this game and I want to the odds of winning his game. So his game is basically I pay \$$1$ to draw $2$ cards from the deck and guess $2$ numbers and one suit. For each correct guess I get \$$1$. Doubled guesses still only count for one correct guess. So either I lose \$$1$ ($0$ correct guess), break even ($1$ correct guess), profit \$$1$ ($2$ correct guesses) or profit \$$2$ ($3$ correct guesses). To win, I have to profit at least \$$1$ so that means I need to be able to guess either both numbers, or one number and one suit. I was wondering what my odds of winning are or what the odds of all possibilities are.","So my friend made this game and I want to the odds of winning his game. So his game is basically I pay \$$1$ to draw $2$ cards from the deck and guess $2$ numbers and one suit. For each correct guess I get \$$1$. Doubled guesses still only count for one correct guess. So either I lose \$$1$ ($0$ correct guess), break even ($1$ correct guess), profit \$$1$ ($2$ correct guesses) or profit \$$2$ ($3$ correct guesses). To win, I have to profit at least \$$1$ so that means I need to be able to guess either both numbers, or one number and one suit. I was wondering what my odds of winning are or what the odds of all possibilities are.",,"['probability', 'analysis', 'statistics']"
36,Overall Probability for Multiple Independent Events on Single Trial,Overall Probability for Multiple Independent Events on Single Trial,,"Am working on a probability problem where a game is described using the hypergeometric distribution. The sample successes are $3...7$, the number of samples is $7$, population successes are $10$, and the number in population is $55$. Summing the probabilities gives $\sim0.1040683327$ or ""overall odds"" of about $1$ in $9.61$. Here's the tricky part. For each play, there are $3$ sets of $7$ numbers, and only one set may be chosen by the player (the other $2$ are chosen randomly). Basically, $3$ independent trials on a single slip. So how do you calculate the overall odds of winning per play for each level ($3...7$)? According to the operator it is $1$ in $3.6$. Using the Binomial distribution, taking the probability of at least one success and averaging it with the probability of exactly one success gives overall odds of exactly $1$ in $3.6$. However, this is not the closest approximation compared to using the Rule of Complements on the sum of probability from the hypergeometric distribution mentioned earlier. That result comes out to be $\sim 0.2808414272$ or about $1$ in $3.56$. The closest approximation seems to come from using a formula derived from the Poisson distribution...this gives overall odds of $1$ in $3.58$. Keep in mind I am trying to calculate the closest probability of each success level so that the overall odds come out to be nearest $1$ in $3.6$. Now, rounded to a couple decimal places both methods I tried come to the same results, but I just want to make sure I am doing this correctly. If this isn't clear, basically I want to calculate the actual probability of winning for each tier based on the fact that 3 trials occur in the same play. Obviously it isn't as simple as dividing each odds by 3 since there is the chance of winning more than once. Thanks","Am working on a probability problem where a game is described using the hypergeometric distribution. The sample successes are $3...7$, the number of samples is $7$, population successes are $10$, and the number in population is $55$. Summing the probabilities gives $\sim0.1040683327$ or ""overall odds"" of about $1$ in $9.61$. Here's the tricky part. For each play, there are $3$ sets of $7$ numbers, and only one set may be chosen by the player (the other $2$ are chosen randomly). Basically, $3$ independent trials on a single slip. So how do you calculate the overall odds of winning per play for each level ($3...7$)? According to the operator it is $1$ in $3.6$. Using the Binomial distribution, taking the probability of at least one success and averaging it with the probability of exactly one success gives overall odds of exactly $1$ in $3.6$. However, this is not the closest approximation compared to using the Rule of Complements on the sum of probability from the hypergeometric distribution mentioned earlier. That result comes out to be $\sim 0.2808414272$ or about $1$ in $3.56$. The closest approximation seems to come from using a formula derived from the Poisson distribution...this gives overall odds of $1$ in $3.58$. Keep in mind I am trying to calculate the closest probability of each success level so that the overall odds come out to be nearest $1$ in $3.6$. Now, rounded to a couple decimal places both methods I tried come to the same results, but I just want to make sure I am doing this correctly. If this isn't clear, basically I want to calculate the actual probability of winning for each tier based on the fact that 3 trials occur in the same play. Obviously it isn't as simple as dividing each odds by 3 since there is the chance of winning more than once. Thanks",,"['probability', 'statistics']"
37,Cauchy Schwarz inequality for random vectors,Cauchy Schwarz inequality for random vectors,,"If $X$ and $Y$ are random scalars, then Cauchy-Schwarz says that $$| \mathrm{Cov}(X,Y) | \le \mathrm{Var}(X)^{1/2}\mathrm{Var}(Y)^{1/2}.$$ If $X$ , $Y \in \mathrm{R}^n$ are random vectors, is there a way to bound the covariance matrix $\mathrm{Cov}(X,Y)$ in terms of the matrices $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$? (Note that, $\mathrm{Cov}(X,Y), \, \mathrm{Var}(X), \,\mathrm{Var}(Y) \in \mathrm{R}^{n\times n}$ and $\mathrm{Var}(X)_{ij} = \mathrm{Cov}(X_i,X_j)$ ) In particular, is it true that $$\mathrm{Cov}(X,Y) \preceq \mathrm{Var}(X)^{1/2}\left(\mathrm{Var}(Y)^{1/2}\right)'$$ where the square roots are Cholesky decompositions, and the inequality is read as meaning that the right hand side minus the left hand side is positive semidefinite? EDIT: I will put what i am trying to do, maybe it helps for an answer. I have $X$, $Y, \, Z \in \mathrm{R}^2$  such that $Z = X + Y$. I know $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$ and I need $\mathrm{Var}(Z)$. As i don't know $\mathrm{Cov}(X,Y)$ I intend to over-estimate  $\mathrm{Var}(Z)$ with a matrix $V$ such that $V-\mathrm{Var}(Z) \succeq 0$. That's why i want to know if Cauchy-Schwarz holds for random vectors. If it does, then: \begin{align*} \mathrm{Var}(Z) & = \mathrm{Var}(X)+\mathrm{Var}(Y)+\mathrm{Cov}(X,Y)+\mathrm{Cov}(Y,X) \\                 & \preceq \mathrm{Var}(X)+\mathrm{Var}(Y) + \mathrm{Var}(X)^{1/2}\left(\mathrm{Var}(Y)^{1/2}\right)' +\mathrm{Var}(Y)^{1/2}\left(\mathrm{Var}(X)^{1/2}\right)' \\     & =  \left( \mathrm{Var}(X)^{1/2} +\mathrm{Var}(Y)^{1/2}\right)\left(\mathrm{Var}(X)^{1/2} +\mathrm{Var}(Y)^{1/2}  \right)' \end{align*} For sure i know i could take $V = 2\left(\mathrm{Var}(X)+\mathrm{Var}(Y)\right)$  and it will work. But it seems to extreme and i am looking for a better bound.","If $X$ and $Y$ are random scalars, then Cauchy-Schwarz says that $$| \mathrm{Cov}(X,Y) | \le \mathrm{Var}(X)^{1/2}\mathrm{Var}(Y)^{1/2}.$$ If $X$ , $Y \in \mathrm{R}^n$ are random vectors, is there a way to bound the covariance matrix $\mathrm{Cov}(X,Y)$ in terms of the matrices $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$? (Note that, $\mathrm{Cov}(X,Y), \, \mathrm{Var}(X), \,\mathrm{Var}(Y) \in \mathrm{R}^{n\times n}$ and $\mathrm{Var}(X)_{ij} = \mathrm{Cov}(X_i,X_j)$ ) In particular, is it true that $$\mathrm{Cov}(X,Y) \preceq \mathrm{Var}(X)^{1/2}\left(\mathrm{Var}(Y)^{1/2}\right)'$$ where the square roots are Cholesky decompositions, and the inequality is read as meaning that the right hand side minus the left hand side is positive semidefinite? EDIT: I will put what i am trying to do, maybe it helps for an answer. I have $X$, $Y, \, Z \in \mathrm{R}^2$  such that $Z = X + Y$. I know $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$ and I need $\mathrm{Var}(Z)$. As i don't know $\mathrm{Cov}(X,Y)$ I intend to over-estimate  $\mathrm{Var}(Z)$ with a matrix $V$ such that $V-\mathrm{Var}(Z) \succeq 0$. That's why i want to know if Cauchy-Schwarz holds for random vectors. If it does, then: \begin{align*} \mathrm{Var}(Z) & = \mathrm{Var}(X)+\mathrm{Var}(Y)+\mathrm{Cov}(X,Y)+\mathrm{Cov}(Y,X) \\                 & \preceq \mathrm{Var}(X)+\mathrm{Var}(Y) + \mathrm{Var}(X)^{1/2}\left(\mathrm{Var}(Y)^{1/2}\right)' +\mathrm{Var}(Y)^{1/2}\left(\mathrm{Var}(X)^{1/2}\right)' \\     & =  \left( \mathrm{Var}(X)^{1/2} +\mathrm{Var}(Y)^{1/2}\right)\left(\mathrm{Var}(X)^{1/2} +\mathrm{Var}(Y)^{1/2}  \right)' \end{align*} For sure i know i could take $V = 2\left(\mathrm{Var}(X)+\mathrm{Var}(Y)\right)$  and it will work. But it seems to extreme and i am looking for a better bound.",,"['probability', 'matrices', 'statistics', 'inequality', 'bilinear-form']"
38,Rating System: Statistically significant with weighted entries,Rating System: Statistically significant with weighted entries,,"The title may be a bit confusing because I not exactly sure how to do/explain what I am after. I have judges rating an object on a score 1-100, where the majority of objects will in the range 85-95 most of the time (90% or so). 3 judges are needed for the system to be ""confident"" of the 1-100 rating, however 3 judges judging can take a very long time. To speed up the system, non-judges can also rate the object but their rating is weighted lower than a judge. Judges have a weight of 2500, and all non-members have their own weight based on a 0 to 2500 scale. The approval/deny cut off is at a score of 90. I am looking for a method to cut off ratings once a score of at least 90 has not only been reached but its unlikely that the # of judges it will take to reach 3 will not put it under 90. That is, if 1 judge has rated then a relatively low score from 2 judges will not put in under 90, vice versa if 2 judges have rated, a relatively low score from 1 judge will not put in under 90. As an example, if 2 judges give the object a score of 97 and 1 member with weight 1600 gives it a score of 99, that is a total of 2*97*2500+99*1600, which would trigger the system that it is very unlikely that the 3rd judge will give it a score low enough to make the average dip below 90, therefore rating should end early, and without the 3rd needed judge.","The title may be a bit confusing because I not exactly sure how to do/explain what I am after. I have judges rating an object on a score 1-100, where the majority of objects will in the range 85-95 most of the time (90% or so). 3 judges are needed for the system to be ""confident"" of the 1-100 rating, however 3 judges judging can take a very long time. To speed up the system, non-judges can also rate the object but their rating is weighted lower than a judge. Judges have a weight of 2500, and all non-members have their own weight based on a 0 to 2500 scale. The approval/deny cut off is at a score of 90. I am looking for a method to cut off ratings once a score of at least 90 has not only been reached but its unlikely that the # of judges it will take to reach 3 will not put it under 90. That is, if 1 judge has rated then a relatively low score from 2 judges will not put in under 90, vice versa if 2 judges have rated, a relatively low score from 1 judge will not put in under 90. As an example, if 2 judges give the object a score of 97 and 1 member with weight 1600 gives it a score of 99, that is a total of 2*97*2500+99*1600, which would trigger the system that it is very unlikely that the 3rd judge will give it a score low enough to make the average dip below 90, therefore rating should end early, and without the 3rd needed judge.",,"['statistics', 'average']"
39,Find the maximum of an integral function with respect to another function,Find the maximum of an integral function with respect to another function,,"I'm facing this statistical data analysis problem, where I have to maximize a certain statistic in order to find the optimal filtering function. I'm a little bit out of practice with the mathematics needed for solving it... Well, the statistic I got from the Neyman-Pearson Lemma is a function of the data set $\{s(t)\}$ and of some ($6$) unknown functions $S^{AB}(t)$ (symmetric under $A \leftrightarrow B$), with $A,B=1,2,3$, of the form: $$\Lambda\big(s(t)\big)=\sum_{A,B}\int_{-\infty}^{+\infty} \mathrm{d}t\ M^{AB}\big(s(t)\big)\,S^{AB}(t).$$ $M^{AB}\big(s(t)\big)$ is a known function of the data set. For the sake of simplicity of the notation, I considered continuous times and an infinite interval of integration. Of course this is not true in practice but I think it won't matter for this analysis problem. In order to evaluate the $6$ unknown functions $S^{AB}(f)$ through their maximum likelihood estimators , I'm asked to maximize $\Lambda$: $$\widehat{S^{AB}}:\qquad \max_{S^{AB}}\Lambda\big(s(t)\big).$$ Well, tese are my attempts: in order to find this maximum, I thought to find the derivative of $\Lambda\big(s(t)\big)$ with respect to $S^{AB}$ and impose it equals to zero for every $A,B$: $$ {\partial\over\partial S^{A'B'}}\Lambda\big(s(t)\big)=0.$$How could I perform this derivative? Can I consider the unknown function as an independent variable and put the derivative inside the integrand, writing: $$\sum_{A,B}\int_{-\infty}^{+\infty}\mathrm{d}t\,M^{AB}(t)\delta^{AA'}\delta^{BB'}=0$$ which does not depends on the filtering functions I'm looking for... Is it correct? How can I interpret this result? Also, I thought to try to solve the problem with this change of variables: $$ {\partial\over\partial S^{A'B'}}\Lambda\big(s(t)\big)= \left|{\partial S^{A'B'}\over\partial t}\right|^{-1}{\partial\over\partial t}\Lambda=\left|{\partial S^{A'B'}\over\partial t}\right|^{-1}\sum_{A,B}M^{AB}(t)\,S^{AB}(t)=0$$ where I need to ""guess"" some templates for the filtering functions $S^{AB}$ and calculate their derivatives. So, I'm stuck on this problem... Can someone suggest me a hint or correct what I did? Thank you, guys! PS: I'm thinking about moving (or copying) this question on dsp.stackexchange.com but since my problems are mostly related on mathematical aspects, I think it's best suited here. Make me know what should I do! Thanks!","I'm facing this statistical data analysis problem, where I have to maximize a certain statistic in order to find the optimal filtering function. I'm a little bit out of practice with the mathematics needed for solving it... Well, the statistic I got from the Neyman-Pearson Lemma is a function of the data set $\{s(t)\}$ and of some ($6$) unknown functions $S^{AB}(t)$ (symmetric under $A \leftrightarrow B$), with $A,B=1,2,3$, of the form: $$\Lambda\big(s(t)\big)=\sum_{A,B}\int_{-\infty}^{+\infty} \mathrm{d}t\ M^{AB}\big(s(t)\big)\,S^{AB}(t).$$ $M^{AB}\big(s(t)\big)$ is a known function of the data set. For the sake of simplicity of the notation, I considered continuous times and an infinite interval of integration. Of course this is not true in practice but I think it won't matter for this analysis problem. In order to evaluate the $6$ unknown functions $S^{AB}(f)$ through their maximum likelihood estimators , I'm asked to maximize $\Lambda$: $$\widehat{S^{AB}}:\qquad \max_{S^{AB}}\Lambda\big(s(t)\big).$$ Well, tese are my attempts: in order to find this maximum, I thought to find the derivative of $\Lambda\big(s(t)\big)$ with respect to $S^{AB}$ and impose it equals to zero for every $A,B$: $$ {\partial\over\partial S^{A'B'}}\Lambda\big(s(t)\big)=0.$$How could I perform this derivative? Can I consider the unknown function as an independent variable and put the derivative inside the integrand, writing: $$\sum_{A,B}\int_{-\infty}^{+\infty}\mathrm{d}t\,M^{AB}(t)\delta^{AA'}\delta^{BB'}=0$$ which does not depends on the filtering functions I'm looking for... Is it correct? How can I interpret this result? Also, I thought to try to solve the problem with this change of variables: $$ {\partial\over\partial S^{A'B'}}\Lambda\big(s(t)\big)= \left|{\partial S^{A'B'}\over\partial t}\right|^{-1}{\partial\over\partial t}\Lambda=\left|{\partial S^{A'B'}\over\partial t}\right|^{-1}\sum_{A,B}M^{AB}(t)\,S^{AB}(t)=0$$ where I need to ""guess"" some templates for the filtering functions $S^{AB}$ and calculate their derivatives. So, I'm stuck on this problem... Can someone suggest me a hint or correct what I did? Thank you, guys! PS: I'm thinking about moving (or copying) this question on dsp.stackexchange.com but since my problems are mostly related on mathematical aspects, I think it's best suited here. Make me know what should I do! Thanks!",,"['statistics', 'signal-processing', 'statistical-inference']"
40,What is the most relavant math for statistics students?,What is the most relavant math for statistics students?,,"As they say ""the more math you learn the better"". Unfortunately, I did not have a lot of mathematical training in my undergraduate. Now I am doing a master in mathematics, mainly to make up some necessary background knowledge in mathematics in order to do my statistics. So far I have done metric space analysis, group and ring, and two numerical computation courses. Now I am considering what subjects to take next semester. So far I have decided to do topological analysis, probability theory. I am not sure whether it is useful to take more algebra course like Galois Theory. Any suggestion, general or specific, would be appreciated. Thank you in advance!","As they say ""the more math you learn the better"". Unfortunately, I did not have a lot of mathematical training in my undergraduate. Now I am doing a master in mathematics, mainly to make up some necessary background knowledge in mathematics in order to do my statistics. So far I have done metric space analysis, group and ring, and two numerical computation courses. Now I am considering what subjects to take next semester. So far I have decided to do topological analysis, probability theory. I am not sure whether it is useful to take more algebra course like Galois Theory. Any suggestion, general or specific, would be appreciated. Thank you in advance!",,"['statistics', 'reference-request', 'soft-question', 'advice']"
41,Evaluate spatial variation of density-like scalar,Evaluate spatial variation of density-like scalar,,"Apologies if this has been asked previously, but I'm not totally sure of the best way to pose the question. Background I'm evaluating the variation of a spatially varying scalar field $p$ (specifically, the density of power) across a domain. As a first step, I simply integrated this field over several relevant subdomains, and divided by their volume to get the average density in those subdomains. For example, for a subdomain I'll call A: $$ p_A = \frac{\int_A p dV}{\int_A dV} $$ I then compared the differences of the average density between regions. Question As a better way of considering the overall 'spread' of the density values, not sensitive to my choice of regions, I would like to evaluate the variance of the power density $p$. Presently, I am evaluating this as: $$ \text{Var}(p) = \text{E}(p^2) - (\text{E}(p))^2                = \frac{\int_\Omega p^2 dV}{\int_\Omega dV} - \left( \frac{\int_\Omega p dV}{\int_\Omega dV} \right)^2 $$ where $\Omega$ represents the whole domain in question. I would like to know: Is this a correct representation of the variance of this scalar field? How can I relate this calculation with a more 'pure' statistical definition of variance, such as: $$ \text{Var}(X) = \int (x-\mu )^2 f(x) dx $$ I believe I have a conceptual understanding of what the probability density function $f(x)$ represents in this case, but am unsure how it can be written down as an equation. I considered writing it as an integral of $p$ over the domain, including a multiplicative factor such as the Dirac delta function in the integrand to 'knock out' desired values, but am uneasy about the rationale for doing so. Something like: $$ f(x) = \int_\Omega \delta (x - p) dV $$ Any input on to this problem would be greatly appreciated!","Apologies if this has been asked previously, but I'm not totally sure of the best way to pose the question. Background I'm evaluating the variation of a spatially varying scalar field $p$ (specifically, the density of power) across a domain. As a first step, I simply integrated this field over several relevant subdomains, and divided by their volume to get the average density in those subdomains. For example, for a subdomain I'll call A: $$ p_A = \frac{\int_A p dV}{\int_A dV} $$ I then compared the differences of the average density between regions. Question As a better way of considering the overall 'spread' of the density values, not sensitive to my choice of regions, I would like to evaluate the variance of the power density $p$. Presently, I am evaluating this as: $$ \text{Var}(p) = \text{E}(p^2) - (\text{E}(p))^2                = \frac{\int_\Omega p^2 dV}{\int_\Omega dV} - \left( \frac{\int_\Omega p dV}{\int_\Omega dV} \right)^2 $$ where $\Omega$ represents the whole domain in question. I would like to know: Is this a correct representation of the variance of this scalar field? How can I relate this calculation with a more 'pure' statistical definition of variance, such as: $$ \text{Var}(X) = \int (x-\mu )^2 f(x) dx $$ I believe I have a conceptual understanding of what the probability density function $f(x)$ represents in this case, but am unsure how it can be written down as an equation. I considered writing it as an integral of $p$ over the domain, including a multiplicative factor such as the Dirac delta function in the integrand to 'knock out' desired values, but am uneasy about the rationale for doing so. Something like: $$ f(x) = \int_\Omega \delta (x - p) dV $$ Any input on to this problem would be greatly appreciated!",,"['integration', 'statistics', 'random-variables']"
42,Convergence in Distribution which places mass of 1/2 at -1 and +1,Convergence in Distribution which places mass of 1/2 at -1 and +1,,"Let $\{X_{n}\}$ be i.i.d. with $P(X_{n}=1)=P(X_{n}=-1)=1/2$ and let $Y_{n}=\sum_{k=1}^{n}{\frac{1}{2^{k}}X_{k}}$. Then how do we show that $Y_{n}\rightarrow{U(-1,1)}$ in distribution. As a solution I tried the following I could not get it ultimately. I used convergence in distribution if and only if convergence in characteristic function. The characteristic function of $Y\sim{U(-1,1)}$ is $\phi_{Y}(t)=\frac{sin(t)}{t}$ and I found  $\phi_{Y_{n}}(t)=\prod_{k=1}^{n}{cos(\frac{t}{2^{k}})}$. But then I don't see that  $\phi_{Y_{n}}(t)\rightarrow{\phi_{Y}(t)}$ as $n\rightarrow{\infty}$ for all $t$.","Let $\{X_{n}\}$ be i.i.d. with $P(X_{n}=1)=P(X_{n}=-1)=1/2$ and let $Y_{n}=\sum_{k=1}^{n}{\frac{1}{2^{k}}X_{k}}$. Then how do we show that $Y_{n}\rightarrow{U(-1,1)}$ in distribution. As a solution I tried the following I could not get it ultimately. I used convergence in distribution if and only if convergence in characteristic function. The characteristic function of $Y\sim{U(-1,1)}$ is $\phi_{Y}(t)=\frac{sin(t)}{t}$ and I found  $\phi_{Y_{n}}(t)=\prod_{k=1}^{n}{cos(\frac{t}{2^{k}})}$. But then I don't see that  $\phi_{Y_{n}}(t)\rightarrow{\phi_{Y}(t)}$ as $n\rightarrow{\infty}$ for all $t$.",,['probability']
43,95 % confidence interval,95 % confidence interval,,"In a random sample of 41 cyclists two years ago, 18 tested positive for drugs. A random sample of 45 is conducted this year and 15 test positive. (a) Give a 95 percent confidence interval for the percentage who tested positive two years ago. (b) Can you conclude that drug use (or its detection rate) has fallen? Specifically i. What is the null hypothesis? ii. What is the value of the test statistic and what is its distribution? iii. What is the p value of the test statistic? Interpret what this means for the validity of the null hypothesis I dont understand how to get the Confidence Interval without any mean or standard error","In a random sample of 41 cyclists two years ago, 18 tested positive for drugs. A random sample of 45 is conducted this year and 15 test positive. (a) Give a 95 percent confidence interval for the percentage who tested positive two years ago. (b) Can you conclude that drug use (or its detection rate) has fallen? Specifically i. What is the null hypothesis? ii. What is the value of the test statistic and what is its distribution? iii. What is the p value of the test statistic? Interpret what this means for the validity of the null hypothesis I dont understand how to get the Confidence Interval without any mean or standard error",,['statistics']
44,Classification problem: admissible rule is a Bayes rule for some prior $\pi$,Classification problem: admissible rule is a Bayes rule for some prior,\pi,"I have a classification problem where I want to place an observation $X$ into a population described by a pdf equal to either $f_1$ or $f_2$. Given $P_{f_i}(\frac{f_1(X)}{f_2(X)}=j)=0$ for all $j\in [0,\infty]$, $i\in\{1,2\}$, I want to show that any admissible classification rule is a Bayes classification rule for some prior $\pi$. Any help doing this would be very much appreciated.","I have a classification problem where I want to place an observation $X$ into a population described by a pdf equal to either $f_1$ or $f_2$. Given $P_{f_i}(\frac{f_1(X)}{f_2(X)}=j)=0$ for all $j\in [0,\infty]$, $i\in\{1,2\}$, I want to show that any admissible classification rule is a Bayes classification rule for some prior $\pi$. Any help doing this would be very much appreciated.",,"['statistics', 'statistical-inference', 'decision-theory']"
45,Binomial and Variance (again),Binomial and Variance (again),,"$\newcommand{\Var}{\operatorname{Var}}$ I guess the answer is extremely easy, but I think I've missed something... When we have a set of $n$ independent identically distributed variables (with the binomial distribution), we can deduce the variance by :  $\Var\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \Var(X_i)$ Then $\Var(X_i)=pq \:\forall i$ (with standard notation), because of the identical distributed variables, hence :  $\Var\left(\sum_{i=1}^n X_i\right) = npq$.  But by using first the argument of identically distributed variables, we have : \begin{equation}\Var\left(\sum_{i=1}^{n} X_i\right) = \Var(nX_1)=n^2\Var(X_1)=\cdots\end{equation} Where is the error ?","$\newcommand{\Var}{\operatorname{Var}}$ I guess the answer is extremely easy, but I think I've missed something... When we have a set of $n$ independent identically distributed variables (with the binomial distribution), we can deduce the variance by :  $\Var\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \Var(X_i)$ Then $\Var(X_i)=pq \:\forall i$ (with standard notation), because of the identical distributed variables, hence :  $\Var\left(\sum_{i=1}^n X_i\right) = npq$.  But by using first the argument of identically distributed variables, we have : \begin{equation}\Var\left(\sum_{i=1}^{n} X_i\right) = \Var(nX_1)=n^2\Var(X_1)=\cdots\end{equation} Where is the error ?",,['statistics']
46,Bias of the Kernel density estimator without bounded support of the Kernel,Bias of the Kernel density estimator without bounded support of the Kernel,,"This is a standard result and should be easy to prove. Yet I cannot figure out the final step. Consider the Kernel density estimator: $\hat f_h=\frac{1}{nh}\sum K\left(\frac{X_i-x}{h}\right)$ where $X_i \sim iid$ with density $f$ K integrable with $\int K(u) du=1$, $K(u)=K(-u)$, To compute its expectation apply $E\left(\hat f_h\right) =\int \frac{1}{h}K\left(\frac{u-x}{h}\right)f(u)du \\  = \int K\left(u\right)f(uh+x)du\\ = \int K(u)(f(x)+f'(x)uh+\frac{1}{2}f''(\gamma(u))(uh)^2)du\\ = f(x)+\int K(u) \frac{1}{2}f''(x)(uh)^2 du + \int K(u) \frac{1}{2}(f''(\gamma(u))- f''(x)) (uh)^2 du$ where $\gamma$ is between x and $uh$, by the standard Taylor expansion argument. $\int K(u)u=0 $ by symmetry of $K$. It remains to show $\int K(u) \frac{1}{2}(f''(\gamma(u))- f''(x)) (uh)^2 du=o(h^2)$. Most sources prove it by assuming bounded support of $K$, but many kernels do not satisfy this. Other sources ignore the dependence of $\gamma$ on $u$ altogether. How do I prove it without assuming bounded support of K?","This is a standard result and should be easy to prove. Yet I cannot figure out the final step. Consider the Kernel density estimator: $\hat f_h=\frac{1}{nh}\sum K\left(\frac{X_i-x}{h}\right)$ where $X_i \sim iid$ with density $f$ K integrable with $\int K(u) du=1$, $K(u)=K(-u)$, To compute its expectation apply $E\left(\hat f_h\right) =\int \frac{1}{h}K\left(\frac{u-x}{h}\right)f(u)du \\  = \int K\left(u\right)f(uh+x)du\\ = \int K(u)(f(x)+f'(x)uh+\frac{1}{2}f''(\gamma(u))(uh)^2)du\\ = f(x)+\int K(u) \frac{1}{2}f''(x)(uh)^2 du + \int K(u) \frac{1}{2}(f''(\gamma(u))- f''(x)) (uh)^2 du$ where $\gamma$ is between x and $uh$, by the standard Taylor expansion argument. $\int K(u)u=0 $ by symmetry of $K$. It remains to show $\int K(u) \frac{1}{2}(f''(\gamma(u))- f''(x)) (uh)^2 du=o(h^2)$. Most sources prove it by assuming bounded support of $K$, but many kernels do not satisfy this. Other sources ignore the dependence of $\gamma$ on $u$ altogether. How do I prove it without assuming bounded support of K?",,['statistics']
47,Moment generating function using linearity of expectation,Moment generating function using linearity of expectation,,Bit of help required with moment generating function. If $X$ follows the distribution with moment generating function $M_X(t)$ and $Y = aX+b$. Show that $M_Y(t) = e^{bt} M_X(at)$ So I understand from reading using linearity of expectation Step 1:  $~M_Y(t) = E(e^{tY})$ Step 2:  $~E(e^{t(aX +b)})$ Step 3:  $~E(e^{atX} e^{tb})$ Step 4:  $~e^{tb} E(e^{atX})$ Step 5:  $~e^{bt} M_X(at)$ Step 3 -Why does $t$ go between $a$ and $X$ when multiplying out??? Step 4 - $e^{tb}$ moves out because it is constant?? Step 5 - How does this transition between step 4 and 5 happen? Thanks,Bit of help required with moment generating function. If $X$ follows the distribution with moment generating function $M_X(t)$ and $Y = aX+b$. Show that $M_Y(t) = e^{bt} M_X(at)$ So I understand from reading using linearity of expectation Step 1:  $~M_Y(t) = E(e^{tY})$ Step 2:  $~E(e^{t(aX +b)})$ Step 3:  $~E(e^{atX} e^{tb})$ Step 4:  $~e^{tb} E(e^{atX})$ Step 5:  $~e^{bt} M_X(at)$ Step 3 -Why does $t$ go between $a$ and $X$ when multiplying out??? Step 4 - $e^{tb}$ moves out because it is constant?? Step 5 - How does this transition between step 4 and 5 happen? Thanks,,"['statistics', 'moment-generating-functions']"
48,How to decompose a sum of Gaussian curves into its substituent addends?,How to decompose a sum of Gaussian curves into its substituent addends?,,"I have a radar that can scan its surrounding. If there is a new object in a previously empty environment, it will cause a bell curve in the amplitude of the light waves coming back. If there are two objects, they will produce two bell curves and if there are n objects, they will produce n bell curves, and because the objects are all roughly the same size, they should produce a corresponding bell curve with the same standard deviation, just a different mean. If I have the data from a radar (which theoretically looks like the sum of several bell curves), is there a way to algorithmically decompose the data and produce the points at which I think an object can be? Illustration: If I have the green curve (which is the sum of the yellow and blue curve), is it possible to solve for the component yellow and blue curves?","I have a radar that can scan its surrounding. If there is a new object in a previously empty environment, it will cause a bell curve in the amplitude of the light waves coming back. If there are two objects, they will produce two bell curves and if there are n objects, they will produce n bell curves, and because the objects are all roughly the same size, they should produce a corresponding bell curve with the same standard deviation, just a different mean. If I have the data from a radar (which theoretically looks like the sum of several bell curves), is there a way to algorithmically decompose the data and produce the points at which I think an object can be? Illustration: If I have the green curve (which is the sum of the yellow and blue curve), is it possible to solve for the component yellow and blue curves?",,"['statistics', 'statistical-inference']"
49,Resources for Teaching High School Statistics,Resources for Teaching High School Statistics,,"I am a student teacher looking for resources to teach high school Probability & Statistics (untracked). The second semester will be inferential statistics and will include these following topics: (1) Normal Distribution (2) z-Scores (3) Central Limit Theorem (4) Sampling Distributions (5) Confidence Interval (6) Margin of Error (7) Hypothesis Testing, including one tailed and two tailed tests (8) t-Scores and (9) Chi-Square Distribution I would like to know what kind of resources are there available for me to do an effective presentation while also incorporating the nationwide Common Core standards. Obviously, I cannot teach this class like a lectured-based college class. This class has to be student-oriented as in filled with activities and different checking points to assess their understanding. The challenge I feel is making this material accessible to all students. The minimum prerequisite to take this class is a C in Algebra II though there are a few who have taken AP Calculus AB along with the untracked Pre-Calculus and H Precalculus with at least a D. My big question is, should I teach this class based on a conceptual understanding of the terminology involved, its procedures and applications while ignoring the mathematical derivations? For example, if I were to talk to about the binomial distribution should I deliberately ignore discussing deriving the mean and variance? Is it wise for me to not even mention what a moment generating function is?","I am a student teacher looking for resources to teach high school Probability & Statistics (untracked). The second semester will be inferential statistics and will include these following topics: (1) Normal Distribution (2) z-Scores (3) Central Limit Theorem (4) Sampling Distributions (5) Confidence Interval (6) Margin of Error (7) Hypothesis Testing, including one tailed and two tailed tests (8) t-Scores and (9) Chi-Square Distribution I would like to know what kind of resources are there available for me to do an effective presentation while also incorporating the nationwide Common Core standards. Obviously, I cannot teach this class like a lectured-based college class. This class has to be student-oriented as in filled with activities and different checking points to assess their understanding. The challenge I feel is making this material accessible to all students. The minimum prerequisite to take this class is a C in Algebra II though there are a few who have taken AP Calculus AB along with the untracked Pre-Calculus and H Precalculus with at least a D. My big question is, should I teach this class based on a conceptual understanding of the terminology involved, its procedures and applications while ignoring the mathematical derivations? For example, if I were to talk to about the binomial distribution should I deliberately ignore discussing deriving the mean and variance? Is it wise for me to not even mention what a moment generating function is?",,"['statistics', 'education']"
50,Multivariate Distribution & Bayes Rule,Multivariate Distribution & Bayes Rule,,"Suppose I have that an unknown vector, x,  where x is drawn from the following distribution$ \bigl(\begin{smallmatrix} x_1 \\ x_2 \end{smallmatrix} \bigr)$ ~ $N\bigl(0, \bigl[\begin{matrix} \sigma^2_1 & \rho\sigma_1\sigma_2\\ & \sigma_2^2 \end{matrix} \bigr]\bigr) $ Further suppose that I am given a value $s$ such that: $s=x_2 + \epsilon$, where $\epsilon$~$N(0,v)$ I need to calculate $E[x_1 - x_2 | s]$ Here is my answer, but I don't know if it's correct: From standard Bayes rule, I have that $E[x_2 | s]=ws ; w=\frac{\sigma^2_2}{\sigma^2_2+v}$ (1) Furthermore, I also know that $E[x_1 | x_2]=\frac{\rho\sigma_1}{\sigma_2}x_2$ (2) Do equations (1) and (2) imply that: $E[x_1 - x_2 | s] = w(\frac{\rho\sigma_1}{\sigma_2}-1)s$?","Suppose I have that an unknown vector, x,  where x is drawn from the following distribution$ \bigl(\begin{smallmatrix} x_1 \\ x_2 \end{smallmatrix} \bigr)$ ~ $N\bigl(0, \bigl[\begin{matrix} \sigma^2_1 & \rho\sigma_1\sigma_2\\ & \sigma_2^2 \end{matrix} \bigr]\bigr) $ Further suppose that I am given a value $s$ such that: $s=x_2 + \epsilon$, where $\epsilon$~$N(0,v)$ I need to calculate $E[x_1 - x_2 | s]$ Here is my answer, but I don't know if it's correct: From standard Bayes rule, I have that $E[x_2 | s]=ws ; w=\frac{\sigma^2_2}{\sigma^2_2+v}$ (1) Furthermore, I also know that $E[x_1 | x_2]=\frac{\rho\sigma_1}{\sigma_2}x_2$ (2) Do equations (1) and (2) imply that: $E[x_1 - x_2 | s] = w(\frac{\rho\sigma_1}{\sigma_2}-1)s$?",,"['statistics', 'probability-theory', 'probability-distributions', 'normal-distribution', 'bayes-theorem']"
51,expectation of norm of orthogonal projector,expectation of norm of orthogonal projector,,"The question has to do with calculating the expected squared norm of a random projection. We have a 2D subspace $T := span\{U1, U2\}$ where $U1$ is a random vector uniformly distributed over unit vectors in $\mathbb{S}^{d-1}$ and $U2$ is a random vector uniformly distributed over unit vectors in $\mathbb{S}^{d-1}$ orthogonal to $U1$. We also have $X \sim \mathcal{N}(0, \Sigma)$, a vector in $\mathbb{R}^d$ where $\Sigma = v_1 v_1^T + v_2 v_2^T$ for orthogonal unit vectors $v_1, v_2 \in \mathbb{S}^{d-1}$. Then what is $\mathbb{E}\|\Pi_T X\|_2^2$, where $\Pi_T X$ is the orthogonal projection of X into $T$ (as a function of $d$)? I know that the plane $W$ which maximizes $\mathbb{E}\|\Pi_W X\|_2^2$ is given by $span\{\mu_1, \mu_2\}$, where $X \sim \mathcal{N}(\mu_, Covariance)$. I know that when you randomly project a d-dimensional point $x$ down to the subspace $T$, the squared norm is going to be something like $\|x\|_2^2/d$. I just don't quite know how to show that.","The question has to do with calculating the expected squared norm of a random projection. We have a 2D subspace $T := span\{U1, U2\}$ where $U1$ is a random vector uniformly distributed over unit vectors in $\mathbb{S}^{d-1}$ and $U2$ is a random vector uniformly distributed over unit vectors in $\mathbb{S}^{d-1}$ orthogonal to $U1$. We also have $X \sim \mathcal{N}(0, \Sigma)$, a vector in $\mathbb{R}^d$ where $\Sigma = v_1 v_1^T + v_2 v_2^T$ for orthogonal unit vectors $v_1, v_2 \in \mathbb{S}^{d-1}$. Then what is $\mathbb{E}\|\Pi_T X\|_2^2$, where $\Pi_T X$ is the orthogonal projection of X into $T$ (as a function of $d$)? I know that the plane $W$ which maximizes $\mathbb{E}\|\Pi_W X\|_2^2$ is given by $span\{\mu_1, \mu_2\}$, where $X \sim \mathcal{N}(\mu_, Covariance)$. I know that when you randomly project a d-dimensional point $x$ down to the subspace $T$, the squared norm is going to be something like $\|x\|_2^2/d$. I just don't quite know how to show that.",,"['linear-algebra', 'statistics', 'spectral-theory', 'machine-learning']"
52,Hypothesis test question,Hypothesis test question,,"Can anyone check my answer about the following hypothesis test? A company considers buying a machine to manufacture a certain item.   When tested, 28 out of 600 items produced by the machine were found   defective. Does the data support the hypothesis that the defect rate   of the machine is smaller than 3% at the 5% significance level. $H_0: p \ge 0.03$ $H_a: p < 0.03$ $\alpha = 0.05$ Critical value $z = -1.645$ Reject $H_0$ if $z < -1.645$ Test statistic $\Rightarrow Z_0 = \frac{\overline{X} - \mu_o}{\sigma/\sqrt{n}} = > \frac{0.0467-0.03}{0.03*0.97/\sqrt{600}} = 14.057$ Therefore, we fail to reject $H_0$. There isn't enough evidence to say   that defect rate of machine is smaller than 3%. Thanks!","Can anyone check my answer about the following hypothesis test? A company considers buying a machine to manufacture a certain item.   When tested, 28 out of 600 items produced by the machine were found   defective. Does the data support the hypothesis that the defect rate   of the machine is smaller than 3% at the 5% significance level. $H_0: p \ge 0.03$ $H_a: p < 0.03$ $\alpha = 0.05$ Critical value $z = -1.645$ Reject $H_0$ if $z < -1.645$ Test statistic $\Rightarrow Z_0 = \frac{\overline{X} - \mu_o}{\sigma/\sqrt{n}} = > \frac{0.0467-0.03}{0.03*0.97/\sqrt{600}} = 14.057$ Therefore, we fail to reject $H_0$. There isn't enough evidence to say   that defect rate of machine is smaller than 3%. Thanks!",,"['probability', 'statistics']"
53,estimation of a sample size for a pilot study,estimation of a sample size for a pilot study,,I am currently involved in a research project whilst being involved in a statistics programme and I can't quite understand what I have to do...so if anyone could help I would be so very grateful. OK so < need to look at diurnal variation in cortisol levels and I need to estimate my sample size for a pilot study. I have looked at several studies and currently have 6 standard deviation values. How do I then convert this into a formula that can give me a sample size? Probably a stupid question but can anyone help? Many thanks.,I am currently involved in a research project whilst being involved in a statistics programme and I can't quite understand what I have to do...so if anyone could help I would be so very grateful. OK so < need to look at diurnal variation in cortisol levels and I need to estimate my sample size for a pilot study. I have looked at several studies and currently have 6 standard deviation values. How do I then convert this into a formula that can give me a sample size? Probably a stupid question but can anyone help? Many thanks.,,['statistics']
54,Selection of Dirichlet parameters,Selection of Dirichlet parameters,,"Suppose that I have to draw from a Dirichlet distribution a multinomial distribution over three events: $$\theta \sim Dir(\alpha_1, \alpha_2, \alpha_3)$$ If $$\alpha_1 = \alpha_2 = \alpha_3 \land \alpha_1 + \alpha_2 + \alpha_3 >> 3$$ $\theta$ distribution is likely to be an uniform distributioin over the three events. On the contrary, if: $$\alpha_1 = \alpha_2 = \alpha_3 \land \alpha_1 + \alpha_2 + \alpha_3 < 3$$  $\theta$ is likely to be a multinomial distribution that puts the majority of its mass on one of those three events. My question is: how should I choose the $\alpha_1, \alpha_2, \alpha_3$ if I want $\theta$ to be a distribution that assigns high probability to two events and low probability to the third one? In other words, I would like that the three most probable values for $\theta$ are: $\theta_1 = 0.5, \theta_2=0.5, \theta_3=0$ $\theta_1 = 0.5, \theta_2=0, \theta_3=0.5$ $\theta_1 = 0, \theta_2=0.5, \theta_3=0.5$ Furthermore, is that easy to generalize this to the case in which we have $N>3$ events?","Suppose that I have to draw from a Dirichlet distribution a multinomial distribution over three events: $$\theta \sim Dir(\alpha_1, \alpha_2, \alpha_3)$$ If $$\alpha_1 = \alpha_2 = \alpha_3 \land \alpha_1 + \alpha_2 + \alpha_3 >> 3$$ $\theta$ distribution is likely to be an uniform distributioin over the three events. On the contrary, if: $$\alpha_1 = \alpha_2 = \alpha_3 \land \alpha_1 + \alpha_2 + \alpha_3 < 3$$  $\theta$ is likely to be a multinomial distribution that puts the majority of its mass on one of those three events. My question is: how should I choose the $\alpha_1, \alpha_2, \alpha_3$ if I want $\theta$ to be a distribution that assigns high probability to two events and low probability to the third one? In other words, I would like that the three most probable values for $\theta$ are: $\theta_1 = 0.5, \theta_2=0.5, \theta_3=0$ $\theta_1 = 0.5, \theta_2=0, \theta_3=0.5$ $\theta_1 = 0, \theta_2=0.5, \theta_3=0.5$ Furthermore, is that easy to generalize this to the case in which we have $N>3$ events?",,"['statistics', 'probability-theory', 'probability-distributions']"
55,Sampling data prior to nonlinear regression,Sampling data prior to nonlinear regression,,"As my question shows it, I am not a statistician. My problem is that I have too many data points to be used in a nonlinear fit (I have millions of them, automatically acquired). Is there a methodology for sampling the data in order to minimize the loss of information ?","As my question shows it, I am not a statistician. My problem is that I have too many data points to be used in a nonlinear fit (I have millions of them, automatically acquired). Is there a methodology for sampling the data in order to minimize the loss of information ?",,"['statistics', 'regression']"
56,Jacobian of the transformation from y to z,Jacobian of the transformation from y to z,,I'm stuck in this problem where I'm asked to verify that the Jacobian of the transformation from y to z (where z=ay+b) is what's the transformation from y to z in this case? is it y=z/a+b/a ? relation 1.10 is:,I'm stuck in this problem where I'm asked to verify that the Jacobian of the transformation from y to z (where z=ay+b) is what's the transformation from y to z in this case? is it y=z/a+b/a ? relation 1.10 is:,,"['linear-algebra', 'statistics']"
57,Finding $E(X^r\mid Y)$ of an exponential function,Finding  of an exponential function,E(X^r\mid Y),"Let $(X,Y)$ denote a two-dimensional random vector with an absolutely continuous distribution with density function $$p(x,y) = \frac{1}{y}\exp(-y), \qquad 0 < x < y < \infty.$$ Find $E(X^r\mid Y)$ for $r = 1,2,\ldots$ My solution: $$p_y(y) = \exp(-y)$$ $$p_{x\mid y}(x\mid y) = \frac{p(x,y)}{p_y(y)} = \frac{1}{y}$$ $$E(X\mid Y) = \int_0^y x p_{x\mid y}(x\mid y) \, dx = \frac{y^3}{2}$$ Not sure if I came out with the correct results, and not sure how to find the general rule.","Let $(X,Y)$ denote a two-dimensional random vector with an absolutely continuous distribution with density function $$p(x,y) = \frac{1}{y}\exp(-y), \qquad 0 < x < y < \infty.$$ Find $E(X^r\mid Y)$ for $r = 1,2,\ldots$ My solution: $$p_y(y) = \exp(-y)$$ $$p_{x\mid y}(x\mid y) = \frac{p(x,y)}{p_y(y)} = \frac{1}{y}$$ $$E(X\mid Y) = \int_0^y x p_{x\mid y}(x\mid y) \, dx = \frac{y^3}{2}$$ Not sure if I came out with the correct results, and not sure how to find the general rule.",,"['real-analysis', 'statistics', 'measure-theory', 'probability-theory', 'fourier-analysis']"
58,Exponential integral approximation,Exponential integral approximation,,"I have an equation that contain exponential integral of the form: $$ \begin{equation} E_k\left(\frac{a+b ~x}{c}\right) \end{equation} $$ Where $k\geq 0$ ($k=0,1,2,...$), $a$, $b$, and $c$ are constants, and $x>0$. How to get the approximation of the above expression?","I have an equation that contain exponential integral of the form: $$ \begin{equation} E_k\left(\frac{a+b ~x}{c}\right) \end{equation} $$ Where $k\geq 0$ ($k=0,1,2,...$), $a$, $b$, and $c$ are constants, and $x>0$. How to get the approximation of the above expression?",,"['integration', 'statistics', 'special-functions', 'exponential-function', 'statistical-inference']"
59,Random Variable with density and E(X),Random Variable with density and E(X),,"$X$ is a random variable with value $0,1,2$ and $E(X)=1$, $E(X^{2})=3/2$. Find $f(x)$=the density of $X$ and find $E(X^{7})$=? Here is what I did: $E(X) = 0*f(0)+1*f(1)+2*f(2)$ $E(X^{2}) = 0^{2}*f(0)+1^{2}*f(1)+2^{2}*f(2)$ Then I got: $f(1)+2*f(2)=1$ $f(1)+4f(2)=3/2$ Then I got: $2f(2)$ = ? I know this is suppose to help you get $f(2)$ My question is how do I get $2f(2)$ = ? to help me get $f(2)$=? from this.","$X$ is a random variable with value $0,1,2$ and $E(X)=1$, $E(X^{2})=3/2$. Find $f(x)$=the density of $X$ and find $E(X^{7})$=? Here is what I did: $E(X) = 0*f(0)+1*f(1)+2*f(2)$ $E(X^{2}) = 0^{2}*f(0)+1^{2}*f(1)+2^{2}*f(2)$ Then I got: $f(1)+2*f(2)=1$ $f(1)+4f(2)=3/2$ Then I got: $2f(2)$ = ? I know this is suppose to help you get $f(2)$ My question is how do I get $2f(2)$ = ? to help me get $f(2)$=? from this.",,"['probability', 'statistics', 'probability-distributions']"
60,Find the Moment Generating Function of $X'AX$,Find the Moment Generating Function of,X'AX,"(1) $X_i \sim iid$ $N(0,1)$ and $A$ is symmetric. Find the MGF of $X'AX$. (2) What if $A$ is idempotent and rank $m \le n$? Find MGF. First, we should make $X'AX \sim N(0,I)$. Since $A$ is symmetric, it can be decomposed as $C'DC$ where $C$ is orthogonal. $CX \sim N(0,I)$ I stuck here... Any suggestion or kind explanation will be thankful.","(1) $X_i \sim iid$ $N(0,1)$ and $A$ is symmetric. Find the MGF of $X'AX$. (2) What if $A$ is idempotent and rank $m \le n$? Find MGF. First, we should make $X'AX \sim N(0,I)$. Since $A$ is symmetric, it can be decomposed as $C'DC$ where $C$ is orthogonal. $CX \sim N(0,I)$ I stuck here... Any suggestion or kind explanation will be thankful.",,"['linear-algebra', 'statistics']"
61,L2-Regularized\Penalized Logistic Regression,L2-Regularized\Penalized Logistic Regression,,"Suppose you have an $n$ dimensional data vector $x = (x_1, \ldots, x_n)$ and two classes $y = 0$ or $y = 1$.  Assuming the dimensions of $x$ are conditionally independent given $y$, and that the conditional likelihood of each $x_i$ is Gaussian with $\mu_{i0}$ and $\mu_{i1}$ as the means of the two classes and $\sigma_i$ as their shared standard deviation. We can see that $p(y = 1 \mid x)$ takes the form of a logistic function $\sigma(wx + b)$ Now assume that a Gaussian prior is placed on each $w$ such that $p(w_i) \sim \mathrm{normal}(0, \sigma)$. My question is how do we find the posterior distribution $p(w,b\mid N)$ based on the prior and the likelihood function of logistic regression? ($N$ is our $N$-dimensional sample) At the end the log likelihood of this posterior $L(w, b)$ is supposed to take the form of an $L2$ regularized version of the likelihood function. I started with deriving an expression for the likelihood function.  I got $$- \sum_i \log(1 + e ^{b + xw}) + \sum_i y_i(b + xw).$$ Now I was thinking of using bayes rule to derive the posterior but then I don't know how to calculate the $p(N\mid b, w)$ term. A hint would be much appreciated. This question is basically the same as how we derive the expression for penalized logistic regression based on prior probabilities.","Suppose you have an $n$ dimensional data vector $x = (x_1, \ldots, x_n)$ and two classes $y = 0$ or $y = 1$.  Assuming the dimensions of $x$ are conditionally independent given $y$, and that the conditional likelihood of each $x_i$ is Gaussian with $\mu_{i0}$ and $\mu_{i1}$ as the means of the two classes and $\sigma_i$ as their shared standard deviation. We can see that $p(y = 1 \mid x)$ takes the form of a logistic function $\sigma(wx + b)$ Now assume that a Gaussian prior is placed on each $w$ such that $p(w_i) \sim \mathrm{normal}(0, \sigma)$. My question is how do we find the posterior distribution $p(w,b\mid N)$ based on the prior and the likelihood function of logistic regression? ($N$ is our $N$-dimensional sample) At the end the log likelihood of this posterior $L(w, b)$ is supposed to take the form of an $L2$ regularized version of the likelihood function. I started with deriving an expression for the likelihood function.  I got $$- \sum_i \log(1 + e ^{b + xw}) + \sum_i y_i(b + xw).$$ Now I was thinking of using bayes rule to derive the posterior but then I don't know how to calculate the $p(N\mid b, w)$ term. A hint would be much appreciated. This question is basically the same as how we derive the expression for penalized logistic regression based on prior probabilities.",,"['probability', 'statistics', 'machine-learning']"
62,distribution of spaced normal variables,distribution of spaced normal variables,,"If we have samples $x_1$, $x_2$, ...,$x_M$ in $R^N$ obtained as follows: 1) $x_1$ is drawn from a normal distribution $N(0,\Sigma)$ 2) $x_k$ ($k>1$) are also drawn from  $N(0,\Sigma)$, but only in the case that the distance between $x_k$ and any previous sample in $\{x_1, ..., x_{k-1}\}$ is larger than $d_0$, we will keep it. 3) We do 2) until we have $M$ samples. In this case, is it possible to write pdf for $x_1$, $x_2$, ...,$x_M$. If not, is there some way to approximate it? Thanks.","If we have samples $x_1$, $x_2$, ...,$x_M$ in $R^N$ obtained as follows: 1) $x_1$ is drawn from a normal distribution $N(0,\Sigma)$ 2) $x_k$ ($k>1$) are also drawn from  $N(0,\Sigma)$, but only in the case that the distance between $x_k$ and any previous sample in $\{x_1, ..., x_{k-1}\}$ is larger than $d_0$, we will keep it. 3) We do 2) until we have $M$ samples. In this case, is it possible to write pdf for $x_1$, $x_2$, ...,$x_M$. If not, is there some way to approximate it? Thanks.",,"['statistics', 'probability-distributions']"
63,Minimally Sufficient Statistic for Bivariate Distribution,Minimally Sufficient Statistic for Bivariate Distribution,,"Say you have: $f(x_i,y_i)=\lambda \mu \exp\{-\lambda x_i-\mu y_i\}$ However you only observe: $Z_i=\min (X_i,Y_i)~$ & $~U_i=\begin{cases}1~\text{if}~Z_i=X_i \\ 0~\text{if}~Z_i=Y_i\end{cases} $ We are asked to find a minimally sufficient statistic for this model. What I have done is to find the marginal distributions $Z_i\sim\exp(\lambda+\mu)$ and $U_i\sim\text{Bernoulli}(\frac{\lambda}{\lambda+\mu})$. Then using the ratio theorem I found the minimally sufficient statistic for each which are essentially just the sums. So I was wondering if together the two statistics that I found would be minimally sufficient for $(\lambda,\mu)$ or do I really have to use the joint distribution to find the statistic. Thanks","Say you have: $f(x_i,y_i)=\lambda \mu \exp\{-\lambda x_i-\mu y_i\}$ However you only observe: $Z_i=\min (X_i,Y_i)~$ & $~U_i=\begin{cases}1~\text{if}~Z_i=X_i \\ 0~\text{if}~Z_i=Y_i\end{cases} $ We are asked to find a minimally sufficient statistic for this model. What I have done is to find the marginal distributions $Z_i\sim\exp(\lambda+\mu)$ and $U_i\sim\text{Bernoulli}(\frac{\lambda}{\lambda+\mu})$. Then using the ratio theorem I found the minimally sufficient statistic for each which are essentially just the sums. So I was wondering if together the two statistics that I found would be minimally sufficient for $(\lambda,\mu)$ or do I really have to use the joint distribution to find the statistic. Thanks",,['statistics']
64,Central moments of the wrapped normal distribution?,Central moments of the wrapped normal distribution?,,"The wikipedia page defines the raw moments of the wrapped normal fairly succinctly: http://en.wikipedia.org/wiki/Wrapped_normal_distribution#Moments However, I'm struggling to find any literature on the equivalent of central moments for the wrapped normal (and circular distributions in general). Does the binomial transform still apply? If so, then I can derive the central moments using the raw moments.","The wikipedia page defines the raw moments of the wrapped normal fairly succinctly: http://en.wikipedia.org/wiki/Wrapped_normal_distribution#Moments However, I'm struggling to find any literature on the equivalent of central moments for the wrapped normal (and circular distributions in general). Does the binomial transform still apply? If so, then I can derive the central moments using the raw moments.",,"['probability', 'complex-analysis', 'statistics']"
65,Choosing the best estimator [closed],Choosing the best estimator [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 12 months ago . Improve this question Given yield measurements $X_1,X_2,X_3$ from three independent runs of an experiment with variance $\sigma^2$, which is the better of the two estimators: $\hat\theta_{1}$= $\frac{X_1+X_2+X_3}{3}$,                  $\hat\theta_{2}$=$\frac{X_1+2X_2+X_3}{4}$ I know that in order to find the best estimator if both are unbiased, we are supposed to choose the one with the smallest variance.  I need help just starting this problem.  Thank you.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 12 months ago . Improve this question Given yield measurements $X_1,X_2,X_3$ from three independent runs of an experiment with variance $\sigma^2$, which is the better of the two estimators: $\hat\theta_{1}$= $\frac{X_1+X_2+X_3}{3}$,                  $\hat\theta_{2}$=$\frac{X_1+2X_2+X_3}{4}$ I know that in order to find the best estimator if both are unbiased, we are supposed to choose the one with the smallest variance.  I need help just starting this problem.  Thank you.",,"['probability', 'statistics']"
66,Likelihood of a Uniform Distribution,Likelihood of a Uniform Distribution,,"I have been looking at this solution for two days and still can't understand the solution. The question is as follows: Given $w[i], i = 1, 2, \ldots, N$ are IID following a distribution of $U[0, \theta]$, show that the regularity condition does not hold and hence the Cramer Rao bound cannot be applied to the problem. My solution first states to let  $$w[i] = x[i]$$ Where $x[i] \sim U(0, \theta)$ and $i=1, 2, \ldots, N$ Now, I need to find the log-likelihood of the function so first, let $\textbf{A} = \begin{bmatrix} x[1]\space x[2]\space\ldots\space x[N] \end{bmatrix}^T $ The answer key stated that $$ p(x[i];\theta) = \frac 1 \theta (u(x[i]) - u(x[i] - \theta)) $$ where $u(x) = 1 $ when $x>0$ and $u(x)=0$ when $x<0$. Why is the last sentence so? Is it because I could express the Uniform distribution as a function of a Step function?","I have been looking at this solution for two days and still can't understand the solution. The question is as follows: Given $w[i], i = 1, 2, \ldots, N$ are IID following a distribution of $U[0, \theta]$, show that the regularity condition does not hold and hence the Cramer Rao bound cannot be applied to the problem. My solution first states to let  $$w[i] = x[i]$$ Where $x[i] \sim U(0, \theta)$ and $i=1, 2, \ldots, N$ Now, I need to find the log-likelihood of the function so first, let $\textbf{A} = \begin{bmatrix} x[1]\space x[2]\space\ldots\space x[N] \end{bmatrix}^T $ The answer key stated that $$ p(x[i];\theta) = \frac 1 \theta (u(x[i]) - u(x[i] - \theta)) $$ where $u(x) = 1 $ when $x>0$ and $u(x)=0$ when $x<0$. Why is the last sentence so? Is it because I could express the Uniform distribution as a function of a Step function?",,"['probability', 'statistics', 'estimation']"
67,Mathematical model building with dependent and independent variables,Mathematical model building with dependent and independent variables,,"I have been working with data and building models on data. I have developed models in regression using cubic and power series. It works fine for variables with one dependent and one independent variable. What kind of technique is to be adopted if I have to find an equation or model for say, D depends on C, C changes for a set of B, which changes for different A. I can carry our bi-variate correlation to find significance. But, that is not something I am interested in. I have data, but wondering as to how to fit a model in those lines. I have tried building models with regression, line fitting and get a relationship between D and C, or D and B. Good fits with varying constants, but no relationship between the others. Is there a way to combine and build a model altogether? What is that kind of analysis called? How to go about it? Any software that would help me do it? I have been using SPSS, Minitab, and R.","I have been working with data and building models on data. I have developed models in regression using cubic and power series. It works fine for variables with one dependent and one independent variable. What kind of technique is to be adopted if I have to find an equation or model for say, D depends on C, C changes for a set of B, which changes for different A. I can carry our bi-variate correlation to find significance. But, that is not something I am interested in. I have data, but wondering as to how to fit a model in those lines. I have tried building models with regression, line fitting and get a relationship between D and C, or D and B. Good fits with varying constants, but no relationship between the others. Is there a way to combine and build a model altogether? What is that kind of analysis called? How to go about it? Any software that would help me do it? I have been using SPSS, Minitab, and R.",,"['statistics', 'regression', 'mathematical-modeling', 'data-analysis']"
68,GLR Test for 2 samples from exponential distributions,GLR Test for 2 samples from exponential distributions,,"I am trying to solve this complicated Generalised Likelihood Ratio Test problem for 2 samples as part of my independent study course. However, the book that I am using does not talk about 2 samples at all; all the examples provided are 1 sample questions. The question: Assume that $X_1, ...,X_m$ is a random sample from $\theta_1e^{-\theta_1x}I_{(0,\infty)}(x)$ and $Y_1, ...,Y_n$ is a random sample from $\theta_2e^{-\theta_2y}I_{(0,\infty)}(y)$ . If we assume the samples are independent. What is the GLR for testing $H_0:\theta_1=\theta_2$ vs. $H_0:\theta_1\ne\theta_2$ ? So far I just got to $$\Lambda=\frac{L(\theta,\theta)}{L(\theta_1,\theta_2)}=\frac{\theta^{m+n}\exp[-\theta\sum x_i+\sum y_i]}{\theta_1^m\exp[-\theta_1\sum x_i]\theta_2^n \exp[-\theta_2\sum y_i]}$$ However, I don't know what I should do for the next step. They say it should be an F test but I just can't see it. I appreciate your time and help!","I am trying to solve this complicated Generalised Likelihood Ratio Test problem for 2 samples as part of my independent study course. However, the book that I am using does not talk about 2 samples at all; all the examples provided are 1 sample questions. The question: Assume that is a random sample from and is a random sample from . If we assume the samples are independent. What is the GLR for testing vs. ? So far I just got to However, I don't know what I should do for the next step. They say it should be an F test but I just can't see it. I appreciate your time and help!","X_1, ...,X_m \theta_1e^{-\theta_1x}I_{(0,\infty)}(x) Y_1, ...,Y_n \theta_2e^{-\theta_2y}I_{(0,\infty)}(y) H_0:\theta_1=\theta_2 H_0:\theta_1\ne\theta_2 \Lambda=\frac{L(\theta,\theta)}{L(\theta_1,\theta_2)}=\frac{\theta^{m+n}\exp[-\theta\sum x_i+\sum y_i]}{\theta_1^m\exp[-\theta_1\sum x_i]\theta_2^n \exp[-\theta_2\sum y_i]}","['statistics', 'probability-distributions', 'statistical-inference', 'hypothesis-testing']"
69,"$f_{\theta}(x)=\frac{2}{3\theta}(1-\frac{x}{3\theta}),\ 0<x<3\theta$ Is $\hat{\theta}=\bar{X}$ unbiased/consistent/sufficient estimator for $\theta$?",Is  unbiased/consistent/sufficient estimator for ?,"f_{\theta}(x)=\frac{2}{3\theta}(1-\frac{x}{3\theta}),\ 0<x<3\theta \hat{\theta}=\bar{X} \theta","For my statistics homework: Let $X_1 , \dots X_n$ be a sample of independent, identically distributed random variables, with density: $$ f_{\theta}(x)=  \left\{ \begin{array}{l} \frac{2}{3\theta}\left(  1- \frac{x}{3\theta} \right)\ \ \ \ \ \  \text{       if  }0 < x<3\theta  \\ 0\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \   \text{       else  } \end{array}  \right. $$ Let $\hat{\theta}=\bar{X}$ be an estimate of $\theta$. Question: (i) is $\hat{\theta}$ unbiased? (ii) is $\hat{\theta}$ consistent? (iii) is $\hat{\theta}$ sufficient? (iv) why doesn't the Cramer-Rao lower bound apply? Answer:  (i) To determine if $\hat{\theta}$ is unbiased we check that $E(\hat{\theta}) = \theta$ for all $\theta$: $$E(\hat{\theta})   =   \int\limits_{0}^{3\theta} x \frac{2}{3\theta}\left(  1- \frac{x}{3\theta} \right)dx  =    \int\limits_{0}^{3\theta}  \left(\frac{2x}{3\theta} - \frac{2x^2}{9\theta ^2} \right)dx  =  \left[   \frac{x ^2}{3\theta} - \frac{2x^3}{27 \theta^2}  \right]_{x=0}^{x=3\theta}    =  \left(     \frac{9\theta^2}{3\theta} - \frac{54\theta^3}{27\theta^2}   \right)=\theta  $$ Thus $\hat{\theta}$ is an unbiased estimator of $\theta$. (iv) The support (domain for which $f_{\theta}>0$ is dependent on $\theta$ thus the regularity conditions are not met and the Cramer-Rao lower bound on does not necessarily apply. For (ii) and (iii) I can't really get started. The definition of consistent and sufficient are not really clear enough to me so I get confused. if anyone could help me with a tip or a start in the right direction that would be great! Thanks!","For my statistics homework: Let $X_1 , \dots X_n$ be a sample of independent, identically distributed random variables, with density: $$ f_{\theta}(x)=  \left\{ \begin{array}{l} \frac{2}{3\theta}\left(  1- \frac{x}{3\theta} \right)\ \ \ \ \ \  \text{       if  }0 < x<3\theta  \\ 0\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \   \text{       else  } \end{array}  \right. $$ Let $\hat{\theta}=\bar{X}$ be an estimate of $\theta$. Question: (i) is $\hat{\theta}$ unbiased? (ii) is $\hat{\theta}$ consistent? (iii) is $\hat{\theta}$ sufficient? (iv) why doesn't the Cramer-Rao lower bound apply? Answer:  (i) To determine if $\hat{\theta}$ is unbiased we check that $E(\hat{\theta}) = \theta$ for all $\theta$: $$E(\hat{\theta})   =   \int\limits_{0}^{3\theta} x \frac{2}{3\theta}\left(  1- \frac{x}{3\theta} \right)dx  =    \int\limits_{0}^{3\theta}  \left(\frac{2x}{3\theta} - \frac{2x^2}{9\theta ^2} \right)dx  =  \left[   \frac{x ^2}{3\theta} - \frac{2x^3}{27 \theta^2}  \right]_{x=0}^{x=3\theta}    =  \left(     \frac{9\theta^2}{3\theta} - \frac{54\theta^3}{27\theta^2}   \right)=\theta  $$ Thus $\hat{\theta}$ is an unbiased estimator of $\theta$. (iv) The support (domain for which $f_{\theta}>0$ is dependent on $\theta$ thus the regularity conditions are not met and the Cramer-Rao lower bound on does not necessarily apply. For (ii) and (iii) I can't really get started. The definition of consistent and sufficient are not really clear enough to me so I get confused. if anyone could help me with a tip or a start in the right direction that would be great! Thanks!",,['statistics']
70,"When defining the probability generating function(pgf), why do we restrict ourselves to discrete random variable?","When defining the probability generating function(pgf), why do we restrict ourselves to discrete random variable?",,"When defining the probability generating function (pgf), why do we put the restriction of discreteness on our random variable? Replacing summation by integration, we could try to generalize it for continuous random variables as well, and derive the respective pdf. We don't do this! Why not?","When defining the probability generating function (pgf), why do we put the restriction of discreteness on our random variable? Replacing summation by integration, we could try to generalize it for continuous random variables as well, and derive the respective pdf. We don't do this! Why not?",,"['statistics', 'probability-distributions', 'random-variables']"
71,"If X is Geometric(p), show that $\displaystyle E\left[\frac{1}{1+X}\right]=\log\left( (1-p)^{\frac{p}{p-1}}\right)$","If X is Geometric(p), show that",\displaystyle E\left[\frac{1}{1+X}\right]=\log\left( (1-p)^{\frac{p}{p-1}}\right),"If X is Geometric(p), show that $\displaystyle E\left[\frac{1}{1+X}\right]=\log\left( (1-p)^{\frac{p}{p-1}}\right)$ I found that $E\left[\frac{1}{1+X}\right]=\log p^{\frac{p}{p-1}}$ instead using Taylor expansion of $log(1-x)=-\sum_{n=1}^{\infty}\frac{x^n}{n}$. $$E\left[\frac{1}{1+X}\right]=\sum_{x=0}^{\infty}\frac{1}{1+X}p(1-p)^x=\sum_{y=1}^{\infty}\frac{1}{y}p(1-p)^{y-1}=-\frac{p}{p-1}\sum_{y=1}^{\infty}\frac{(1-p)^y}{y}$$ and since $-\sum_{y=1}^{\infty}\frac{(1-p)^y}{y}=log(1-(1-p))=\log(p)$, then we get $$=\frac{p}{p-1}\log p$$ Did I go wrong somewhere with the $1-p$?","If X is Geometric(p), show that $\displaystyle E\left[\frac{1}{1+X}\right]=\log\left( (1-p)^{\frac{p}{p-1}}\right)$ I found that $E\left[\frac{1}{1+X}\right]=\log p^{\frac{p}{p-1}}$ instead using Taylor expansion of $log(1-x)=-\sum_{n=1}^{\infty}\frac{x^n}{n}$. $$E\left[\frac{1}{1+X}\right]=\sum_{x=0}^{\infty}\frac{1}{1+X}p(1-p)^x=\sum_{y=1}^{\infty}\frac{1}{y}p(1-p)^{y-1}=-\frac{p}{p-1}\sum_{y=1}^{\infty}\frac{(1-p)^y}{y}$$ and since $-\sum_{y=1}^{\infty}\frac{(1-p)^y}{y}=log(1-(1-p))=\log(p)$, then we get $$=\frac{p}{p-1}\log p$$ Did I go wrong somewhere with the $1-p$?",,"['probability', 'statistics']"
72,Sufficient statistics and isometries,Sufficient statistics and isometries,,"Let $(M,g)$ be an infinite dimensional statistical manifold with the Fisher information metric $g$. Is it true that any isometry on this manifold must correspond to a sufficient statistic?","Let $(M,g)$ be an infinite dimensional statistical manifold with the Fisher information metric $g$. Is it true that any isometry on this manifold must correspond to a sufficient statistic?",,"['statistics', 'differential-geometry', 'information-geometry']"
73,Interpreting the meaning of sampling distribution,Interpreting the meaning of sampling distribution,,"I have asked a couple of questions related to statistics recently as I just started to study the topic again (I ignored my university course on statistics and I now eat my fingers in anger). I asked this question recently, and even though I do appreciate all the answers that people made the effort to provide me with, I am still puzzled about the whole thing: Monte Carlo integration, expected value of the sample mean and expected value of f(x) I also studied this very good video and example from Khan Academy: http://www.khanacademy.org/math/probability/descriptive-statistics/variance_std_deviation/v/review-and-intuition-why-we-divide-by-n-1-for-the-unbiased-sample-variance I tried to interpret the data that are generated from the exercise (which you can see in the video). In short what the exercise does is generating a population (it creates groups of random size where each of the generated group holds a number between 1 to 20). The sum of the groups size gives the population size. From this population we can compute population mean and variance. All good. Then we sample the population X times where the sample size varies from 2 to 20. The sample mean and variance is computed for each sample, and then plotted (sample variance as a function of sample mean). Again this is all good. I would like to know if I interpret (intuitively) the data correctly: this exercise shows clearly to me the difference between ""estimation"" and ""approximation"". You can see that even with sample size whose size is small (say 2) we can get a good estimation of the population mean and variance. Of course this happens by ""chance"" but the probability that this happens exists. now the problem I am debating with a student friend of mine is this. I tell him that it is not because the ""size"" of the sample increases, that the probability of that the sample to give a ""better"" estimate (compared to a sample with a smaller size) increases accordingly! My argument is that, as the size of the sample increases, the results of the sample ""converge"" to the population's parameters due to the law of large numbers. But the probability that you get a value close to this population parameters because the sample size is either 2 or 20 doesn't really change. I feel I am be right and wrong at the same time. But I like this explanation because it seems to make it possible to explain 2 distinct phenomena from 1 single set of data. 1) that sample gives an estimate (and not an approximation) of the population's parameters. The less samples, the more likely the estimate is to be way off from the population parameters. That still suggests though that there's some relation between number of sample and probability of getting an estimate close to the population parameter. But I don't know which one I can establish and if it is accurate to say so? 2) however increasing the size of the samples, can't be seen as a guarantee of of getting a better estimate from a probability point of view. It gives us the guarantee though that we get an estimate that converges to the exact value because of the LLN (then this looks almost more like an approximation than an expectation to me). It would be great if someone could tell me if I am on the right path or not (and if not correct me). I would really like to understand 1) how to interpret the results 2) where is the line between estimators and the LLN. Thank you so much for your time and knowledge. EDIT: reading the Wikipedia page on the CLT. It says ""By the law of large numbers, the sample averages converge in probability and almost surely to the expected value µ as n → ∞."" So I assume this is where the relationship is. If it converges in probability it means the probability of getting the population parameters increases as n increases. Could someone please confirm this is right?","I have asked a couple of questions related to statistics recently as I just started to study the topic again (I ignored my university course on statistics and I now eat my fingers in anger). I asked this question recently, and even though I do appreciate all the answers that people made the effort to provide me with, I am still puzzled about the whole thing: Monte Carlo integration, expected value of the sample mean and expected value of f(x) I also studied this very good video and example from Khan Academy: http://www.khanacademy.org/math/probability/descriptive-statistics/variance_std_deviation/v/review-and-intuition-why-we-divide-by-n-1-for-the-unbiased-sample-variance I tried to interpret the data that are generated from the exercise (which you can see in the video). In short what the exercise does is generating a population (it creates groups of random size where each of the generated group holds a number between 1 to 20). The sum of the groups size gives the population size. From this population we can compute population mean and variance. All good. Then we sample the population X times where the sample size varies from 2 to 20. The sample mean and variance is computed for each sample, and then plotted (sample variance as a function of sample mean). Again this is all good. I would like to know if I interpret (intuitively) the data correctly: this exercise shows clearly to me the difference between ""estimation"" and ""approximation"". You can see that even with sample size whose size is small (say 2) we can get a good estimation of the population mean and variance. Of course this happens by ""chance"" but the probability that this happens exists. now the problem I am debating with a student friend of mine is this. I tell him that it is not because the ""size"" of the sample increases, that the probability of that the sample to give a ""better"" estimate (compared to a sample with a smaller size) increases accordingly! My argument is that, as the size of the sample increases, the results of the sample ""converge"" to the population's parameters due to the law of large numbers. But the probability that you get a value close to this population parameters because the sample size is either 2 or 20 doesn't really change. I feel I am be right and wrong at the same time. But I like this explanation because it seems to make it possible to explain 2 distinct phenomena from 1 single set of data. 1) that sample gives an estimate (and not an approximation) of the population's parameters. The less samples, the more likely the estimate is to be way off from the population parameters. That still suggests though that there's some relation between number of sample and probability of getting an estimate close to the population parameter. But I don't know which one I can establish and if it is accurate to say so? 2) however increasing the size of the samples, can't be seen as a guarantee of of getting a better estimate from a probability point of view. It gives us the guarantee though that we get an estimate that converges to the exact value because of the LLN (then this looks almost more like an approximation than an expectation to me). It would be great if someone could tell me if I am on the right path or not (and if not correct me). I would really like to understand 1) how to interpret the results 2) where is the line between estimators and the LLN. Thank you so much for your time and knowledge. EDIT: reading the Wikipedia page on the CLT. It says ""By the law of large numbers, the sample averages converge in probability and almost surely to the expected value µ as n → ∞."" So I assume this is where the relationship is. If it converges in probability it means the probability of getting the population parameters increases as n increases. Could someone please confirm this is right?",,"['statistics', 'sampling', 'law-of-large-numbers']"
74,most common subsets,most common subsets,,"Excuse the ignorance here. My background is not mathematics.  This is an IT problem that may  have a mathematical solution: I have a large amount of sets of variables. The variables belong to a distinct set of data (for example, each variable may be the age of a person in years, in which case, my potential range has about 100 values). Each set has an unspecified number of data points (for the sake of making things easier to understand, lets assume that each set is the ages of people in a restaurant table): set 1: {1, 100, 2, 3} set 2: {3, 4, 45,1 ,2 ,34, 65, 33, 59, 32} set 3: {40} etc. etc. I need to identify common subsets within the data. So ideally I would like to look at a few millions of sets and determine that in 20% of these sets you can find the subset (30, 45, 50) for example. Which would then suggest that if you see a 50 year old and a 45 year old, then there is a good chance that a 30 year old will join them - or something similar) Can anyone provide a few pointers? After going over some of the comments: @dls thanks for the link. I think that I found something relevant in the apriori algorithm. There is also (for the IT lot) useful ruby code at github and R code . I have also posted the same question at CrossValidated . The responses and comments have been very helpful so please have a look there too.","Excuse the ignorance here. My background is not mathematics.  This is an IT problem that may  have a mathematical solution: I have a large amount of sets of variables. The variables belong to a distinct set of data (for example, each variable may be the age of a person in years, in which case, my potential range has about 100 values). Each set has an unspecified number of data points (for the sake of making things easier to understand, lets assume that each set is the ages of people in a restaurant table): set 1: {1, 100, 2, 3} set 2: {3, 4, 45,1 ,2 ,34, 65, 33, 59, 32} set 3: {40} etc. etc. I need to identify common subsets within the data. So ideally I would like to look at a few millions of sets and determine that in 20% of these sets you can find the subset (30, 45, 50) for example. Which would then suggest that if you see a 50 year old and a 45 year old, then there is a good chance that a 30 year old will join them - or something similar) Can anyone provide a few pointers? After going over some of the comments: @dls thanks for the link. I think that I found something relevant in the apriori algorithm. There is also (for the IT lot) useful ruby code at github and R code . I have also posted the same question at CrossValidated . The responses and comments have been very helpful so please have a look there too.",,['statistics']
75,Almost sure convergence of a sum of random variables,Almost sure convergence of a sum of random variables,,"Suppose $(X_i)_{i=1}^{\infty}$ is an i.i.d. sequence of rv's, where $X_i$ can take countably many values $\{x_1,x_2,\dots\}$ with probabilities $\{p_1,p_2\dots\}$, respectively. Let $p_{n,k}:= 1/n\sum_{i=1}^n \mathrm{1}\{X_i=x_k\}$, for $k\in\mathbb{N}$. By the SLLN, we have $p_{n,k} \rightarrow p_k,\forall k$, almost surely, as $n\rightarrow \infty$. Here is my question: How do I show that $\sum_{k=1}^{\infty}|p_{n,k}-p_k|\rightarrow 0$, almost surely, as $n\rightarrow \infty$? I was thinking of using Borell-Cantelli, but could not make it work. Any help is much appreciated. many thanks!","Suppose $(X_i)_{i=1}^{\infty}$ is an i.i.d. sequence of rv's, where $X_i$ can take countably many values $\{x_1,x_2,\dots\}$ with probabilities $\{p_1,p_2\dots\}$, respectively. Let $p_{n,k}:= 1/n\sum_{i=1}^n \mathrm{1}\{X_i=x_k\}$, for $k\in\mathbb{N}$. By the SLLN, we have $p_{n,k} \rightarrow p_k,\forall k$, almost surely, as $n\rightarrow \infty$. Here is my question: How do I show that $\sum_{k=1}^{\infty}|p_{n,k}-p_k|\rightarrow 0$, almost surely, as $n\rightarrow \infty$? I was thinking of using Borell-Cantelli, but could not make it work. Any help is much appreciated. many thanks!",,"['probability', 'analysis', 'statistics', 'random-variables']"
76,Probability of a slot having exactly $K$ elements,Probability of a slot having exactly  elements,K,"From this question asked in an interview: Consider a hash table with $M$ slots. Suppose hash value is uniformly   distributed between $1$ to $M$. Suppose we put $N$ keys   into this $M$-slotted hash table, what is the probability that there   will be a slot with $K$ elements? $K$ could vary from $0$ to $N$. I'm not very good in statistics, that's why I'm asking for your help.  What is the probability and how to compute it? I could think of the following. Let $a_i$ be the number of elements in slot $i$. Then $P(a_i = K) = P(a_j = K) = P_K, \forall i, j$. And the answer is given by $P^* = 1 - (1 - P_K)^M$. But how to comupte $P_K$? PS. The only question I could answer is ""what is the expected value of the number of elements in a single slot?"". And the answer is $N/M$. Am I right?","From this question asked in an interview: Consider a hash table with $M$ slots. Suppose hash value is uniformly   distributed between $1$ to $M$. Suppose we put $N$ keys   into this $M$-slotted hash table, what is the probability that there   will be a slot with $K$ elements? $K$ could vary from $0$ to $N$. I'm not very good in statistics, that's why I'm asking for your help.  What is the probability and how to compute it? I could think of the following. Let $a_i$ be the number of elements in slot $i$. Then $P(a_i = K) = P(a_j = K) = P_K, \forall i, j$. And the answer is given by $P^* = 1 - (1 - P_K)^M$. But how to comupte $P_K$? PS. The only question I could answer is ""what is the expected value of the number of elements in a single slot?"". And the answer is $N/M$. Am I right?",,"['combinatorics', 'statistics', 'hash-function']"
77,hypothesis testing practice question,hypothesis testing practice question,,"This is a practice question for a final exam. Two types of cordless weed-trimmer batteries are tested. One group of 5 batteries averaged $1.4$ hours, while the other group consisting of 8 batteries, averaged $1.2$ hours. A) What null and alternative hypotheses would you establish to determine     whether or not the battery life differs between the two types? ANS: I think the answer to this is $H_0: \mu_1 = \mu_2$ $H_1: \mu_1 \neq \mu_2$ B) What test statistic is appropriate if ${σ_1}^2 = 6.7$ $   {σ_2}^2$ = 5.2.  (Please print out the appropriate  formula.) Ans: I think it is Z distribution. I have no idea why its just an intuition that it may be Z distribution. Could use some help or advice on how to identify the distribution. C) Construct the appropriate critical values, assuming $α =0.05$. Would you accept the null or  the alternative hypothesis? Ans. Definitely need help here. Completely lost. D) What p-value would you report if α is not specified?","This is a practice question for a final exam. Two types of cordless weed-trimmer batteries are tested. One group of 5 batteries averaged $1.4$ hours, while the other group consisting of 8 batteries, averaged $1.2$ hours. A) What null and alternative hypotheses would you establish to determine     whether or not the battery life differs between the two types? ANS: I think the answer to this is $H_0: \mu_1 = \mu_2$ $H_1: \mu_1 \neq \mu_2$ B) What test statistic is appropriate if ${σ_1}^2 = 6.7$ $   {σ_2}^2$ = 5.2.  (Please print out the appropriate  formula.) Ans: I think it is Z distribution. I have no idea why its just an intuition that it may be Z distribution. Could use some help or advice on how to identify the distribution. C) Construct the appropriate critical values, assuming $α =0.05$. Would you accept the null or  the alternative hypothesis? Ans. Definitely need help here. Completely lost. D) What p-value would you report if α is not specified?",,"['statistics', 'statistical-inference']"
78,Hermite rank of an $L^2$ function,Hermite rank of an  function,L^2,"Let $(H_k)_{k\in\mathbb{N}}$ be the sequence of hermite polynimials, $Z\sim N(0,1)$ and $G\in L^2(\mathbb{R},\phi)$ with $\operatorname{E}\left[Z\right]=0$. By $\phi$ we denote the density of the standard normal distribution. Than exists a unique representation \begin{align} G(Z)=\sum_{k=1}^{\infty}\frac{J(k)}{k!}H_k(Z) \end{align} in $L^2(\Omega)$ where \begin{align} J(k):=\operatorname{E}\left[G(Z)H_k(Z)\right]. \end{align} We call \begin{align} m:=\min_{k\in\mathbb{N}_{\geq1}}\operatorname{E}\left[G(Z)H_k(Z)\right]\neq 0\} \end{align} the hermite rank of $G$. Assume now that the hermite rank of $G$ is 1. Is the hermite rank of  \begin{align*} 1\{G(x)\leq u\} \text{   for fixed $u\in\mathbb{R}$} \end{align*} also 1? I.e. is $\operatorname{E}\left[1\{G(Z)\leq u\}H_1(Z)\right]= \operatorname{E}\left[1\{G(Z)\leq u\}Z\right]\neq 0$?","Let $(H_k)_{k\in\mathbb{N}}$ be the sequence of hermite polynimials, $Z\sim N(0,1)$ and $G\in L^2(\mathbb{R},\phi)$ with $\operatorname{E}\left[Z\right]=0$. By $\phi$ we denote the density of the standard normal distribution. Than exists a unique representation \begin{align} G(Z)=\sum_{k=1}^{\infty}\frac{J(k)}{k!}H_k(Z) \end{align} in $L^2(\Omega)$ where \begin{align} J(k):=\operatorname{E}\left[G(Z)H_k(Z)\right]. \end{align} We call \begin{align} m:=\min_{k\in\mathbb{N}_{\geq1}}\operatorname{E}\left[G(Z)H_k(Z)\right]\neq 0\} \end{align} the hermite rank of $G$. Assume now that the hermite rank of $G$ is 1. Is the hermite rank of  \begin{align*} 1\{G(x)\leq u\} \text{   for fixed $u\in\mathbb{R}$} \end{align*} also 1? I.e. is $\operatorname{E}\left[1\{G(Z)\leq u\}H_1(Z)\right]= \operatorname{E}\left[1\{G(Z)\leq u\}Z\right]\neq 0$?",,"['statistics', 'probability-theory', 'stochastic-processes', 'time-series']"
79,Distribution of the $l_2$-norm of gaussian vector,Distribution of the -norm of gaussian vector,l_2,"Let $Y_k \sim N(\mu_k, \sigma_k^2)$. For $\sigma_k = \sigma$ the squared norm of $Y = (Y_1, \ldots, Y_n)$ follows the noncentral chi square distribution . What is the distribution in the general case? The derivation of the pdf found on wikipedia doesn't generalize to our case.","Let $Y_k \sim N(\mu_k, \sigma_k^2)$. For $\sigma_k = \sigma$ the squared norm of $Y = (Y_1, \ldots, Y_n)$ follows the noncentral chi square distribution . What is the distribution in the general case? The derivation of the pdf found on wikipedia doesn't generalize to our case.",,"['statistics', 'probability-distributions', 'normal-distribution']"
80,Statistical Significance level - elementary level,Statistical Significance level - elementary level,,"Let's say one day my sister tells me she has psychic powers and can help me predict the winners in horse racing games and for whatever reason, we only have 2 horse racers in a game. She tells me that if she chooses 'blue', then the blue horse wins (painted blue okay?) and if she chooses 'red', then the red horse wins. She does this $8$ times and it turns out she was correct on all of them, making me very wealthy. Now is this a fluke or not? Let's test this at a significance level of $\alpha = 0.05$ Assuming my sister isn't really a psychic, then I expect she would be correct half the time. This yields $\mu = 4$. So my null hypothesis is $\mu = 4$ and my alternative would be $\mu = 8 > 4$. Let $X$ be the random variable denoting the ""number of correct predictions my sister makes"". So $X \sim Bin(8,1/2)$ and I did $P(X = 8| \mu = 4) = (1/2)^8 \approx 0 < 0.05$. This leads me to conclude I should reject my initial null hypthosis and conclude my sister may be a psychic. However this seems to go against any intuition since my sister is actually only 3 years old, and I probably made a Type I Error. Is this a correct analysis?","Let's say one day my sister tells me she has psychic powers and can help me predict the winners in horse racing games and for whatever reason, we only have 2 horse racers in a game. She tells me that if she chooses 'blue', then the blue horse wins (painted blue okay?) and if she chooses 'red', then the red horse wins. She does this $8$ times and it turns out she was correct on all of them, making me very wealthy. Now is this a fluke or not? Let's test this at a significance level of $\alpha = 0.05$ Assuming my sister isn't really a psychic, then I expect she would be correct half the time. This yields $\mu = 4$. So my null hypothesis is $\mu = 4$ and my alternative would be $\mu = 8 > 4$. Let $X$ be the random variable denoting the ""number of correct predictions my sister makes"". So $X \sim Bin(8,1/2)$ and I did $P(X = 8| \mu = 4) = (1/2)^8 \approx 0 < 0.05$. This leads me to conclude I should reject my initial null hypthosis and conclude my sister may be a psychic. However this seems to go against any intuition since my sister is actually only 3 years old, and I probably made a Type I Error. Is this a correct analysis?",,['statistics']
81,Gibbs / MCMC sampling for sum of parameters - how to improve slow mixing?,Gibbs / MCMC sampling for sum of parameters - how to improve slow mixing?,,"Suppose I have a hierarchical Bayesian model, where my observational prediction, $y'$, is calculated as the sum of other parameters, ${\alpha_i}$. My observation equation (the likelihood) is: $P(y | \{\alpha_i\}, \sigma) \sim N(\sum_i \alpha_i, \sigma^2)$. I want to perform inference on the $\{\alpha_i\}$ parameters. Using the usual notation, let $\{\alpha_{-j}\}$ be the subset of $\{\alpha_i\}$ not including $\alpha_j$. Considering $\alpha_j$, $P(\alpha_j | \{\alpha_{-j}\}, y, \sigma) \sim N(y - \sum_{i \neq j}\alpha_i, \sigma^2)\,P(\alpha_j)$, where $P(\alpha_j)$ is the prior. Now you can obviously implement a Gibbs sampler for this, sampling each $\alpha_i$ in turn, but the mixing will be slow if there area a lot of $\alpha$ parameters as each parameter depends on the other one. I am looking to see if there is a way of drawing from the joint distribution for this (which would eliminate this problem), but I can't see how to work out the joint distribution $P(\{\alpha_i\} | y, \sigma)$. Note 1: This is not a homework problem. Note 2: my actual problem is more complicated, because the observation equation actually depends on a weighted sum of the $\{\alpha_i\}$, and then I have to deal with priors etc. I think the problem will ultimately be tractable if I can understand how to do this bit. Many thanks! OK after I have written this I've realised that the full joint probability is $P(\{\alpha_i\} | y, \sigma) \sim P(y | \{\alpha_i\}, \sigma)\,P(\{\alpha_i\})$ - the answer is right in front of me. I guess my question relates to how to sample this well - can this expressed in a form where it is multivariate normal for instance? I don't think so due to the interdependence of parameters.  Does this mean that Metropolis or Metropolis-Hastings is the only way to go?","Suppose I have a hierarchical Bayesian model, where my observational prediction, $y'$, is calculated as the sum of other parameters, ${\alpha_i}$. My observation equation (the likelihood) is: $P(y | \{\alpha_i\}, \sigma) \sim N(\sum_i \alpha_i, \sigma^2)$. I want to perform inference on the $\{\alpha_i\}$ parameters. Using the usual notation, let $\{\alpha_{-j}\}$ be the subset of $\{\alpha_i\}$ not including $\alpha_j$. Considering $\alpha_j$, $P(\alpha_j | \{\alpha_{-j}\}, y, \sigma) \sim N(y - \sum_{i \neq j}\alpha_i, \sigma^2)\,P(\alpha_j)$, where $P(\alpha_j)$ is the prior. Now you can obviously implement a Gibbs sampler for this, sampling each $\alpha_i$ in turn, but the mixing will be slow if there area a lot of $\alpha$ parameters as each parameter depends on the other one. I am looking to see if there is a way of drawing from the joint distribution for this (which would eliminate this problem), but I can't see how to work out the joint distribution $P(\{\alpha_i\} | y, \sigma)$. Note 1: This is not a homework problem. Note 2: my actual problem is more complicated, because the observation equation actually depends on a weighted sum of the $\{\alpha_i\}$, and then I have to deal with priors etc. I think the problem will ultimately be tractable if I can understand how to do this bit. Many thanks! OK after I have written this I've realised that the full joint probability is $P(\{\alpha_i\} | y, \sigma) \sim P(y | \{\alpha_i\}, \sigma)\,P(\{\alpha_i\})$ - the answer is right in front of me. I guess my question relates to how to sample this well - can this expressed in a form where it is multivariate normal for instance? I don't think so due to the interdependence of parameters.  Does this mean that Metropolis or Metropolis-Hastings is the only way to go?",,"['statistics', 'markov-chains', 'sampling', 'monte-carlo']"
82,The correct probability distribution / way to analyze daily changes,The correct probability distribution / way to analyze daily changes,,"I am working on a report which is being sent through to end users that should flag to them any ""large changes"" in the day-to-day values for the past 30 days for something we would assume the day-to-day differences to have a mean of zero. So, assume we have the following data: Day:    Change from previous day: 1       -40 2       30 3       15 4       12 5       -34 6       -2 ... 30      12 And they don't care about the direction of the change, just to flag any day where the change is of a ""statistically significant"" magnitude. I'm curious as to how to calculate the statistics for this properly / what distribution would best be used to assign probability levels for this set of data. What has been proposed is to, firstly, look at the square of the changes (rather than the original values since all we care about is magnitude): To calculate the std dev as $\sqrt{ \dfrac{\sum \left( x_i - 0 \right)^2 }{29}}$ - In other words assume a zero expected value To Calculate the std dev as $\sqrt{ \dfrac{\sum \left( x_i - \bar{x} \right)^2 }{29}}$ - In other words, use the mean we would calculate for this sample And then to take each day's value and divide it by this std_dev to calculate it's magnitude. I have quite a few problems with a few things here, but especially idea #2 since I believe the mean SHOULD BE ZERO. Generally speaking, what is the correct way to analyze deltas with an expected value of zero and what distribution would you use for a 30-sample data-set to find statistically significant values? I hope this makes sense, but, if not, please let me know where I could clarify more. THANKS!!!","I am working on a report which is being sent through to end users that should flag to them any ""large changes"" in the day-to-day values for the past 30 days for something we would assume the day-to-day differences to have a mean of zero. So, assume we have the following data: Day:    Change from previous day: 1       -40 2       30 3       15 4       12 5       -34 6       -2 ... 30      12 And they don't care about the direction of the change, just to flag any day where the change is of a ""statistically significant"" magnitude. I'm curious as to how to calculate the statistics for this properly / what distribution would best be used to assign probability levels for this set of data. What has been proposed is to, firstly, look at the square of the changes (rather than the original values since all we care about is magnitude): To calculate the std dev as $\sqrt{ \dfrac{\sum \left( x_i - 0 \right)^2 }{29}}$ - In other words assume a zero expected value To Calculate the std dev as $\sqrt{ \dfrac{\sum \left( x_i - \bar{x} \right)^2 }{29}}$ - In other words, use the mean we would calculate for this sample And then to take each day's value and divide it by this std_dev to calculate it's magnitude. I have quite a few problems with a few things here, but especially idea #2 since I believe the mean SHOULD BE ZERO. Generally speaking, what is the correct way to analyze deltas with an expected value of zero and what distribution would you use for a 30-sample data-set to find statistically significant values? I hope this makes sense, but, if not, please let me know where I could clarify more. THANKS!!!",,"['probability', 'statistics', 'random-variables', 'data-analysis']"
83,Can someone explain the intuition behind this moment generating function identity?,Can someone explain the intuition behind this moment generating function identity?,,"If $X_i \sim N(\mu, \sigma^2) $, we know that: $\bar{X} \sim N(\mu, \sigma^2 /n)$. But why does: $$\exp\left({\sigma^{2}\over 2}\sum_{i=1}^{n}(t_{i}-\bar{t})^{2}\right)= M_{X_{1}-\bar{X},X_{2}-\bar{X},...,X_{n}-\bar{X}}(t_1,t_2,...,t_n)$$ Where $M$ is the moment generating function? I have three pages of scratch work but it would be incredibly tedious to post that here, and I already know it's true... Thanks!","If $X_i \sim N(\mu, \sigma^2) $, we know that: $\bar{X} \sim N(\mu, \sigma^2 /n)$. But why does: $$\exp\left({\sigma^{2}\over 2}\sum_{i=1}^{n}(t_{i}-\bar{t})^{2}\right)= M_{X_{1}-\bar{X},X_{2}-\bar{X},...,X_{n}-\bar{X}}(t_1,t_2,...,t_n)$$ Where $M$ is the moment generating function? I have three pages of scratch work but it would be incredibly tedious to post that here, and I already know it's true... Thanks!",,"['probability', 'statistics']"
84,Unbiased family of estimators and variance.,Unbiased family of estimators and variance.,,"Given $X_1, \dots, X_n$ simple random sample with distribution $F_X$ -unknown-, i have to estimate $\mu = \mathrm{E}(X)$. Now, given the famility of estimators $\tilde{T} = \bigg\{\displaystyle\sum_{i=1}^n \alpha_iX_i : \ \displaystyle\sum_{i=1}^n \alpha_i = 1\bigg\}$. I have to (1) Prove that if $\hat{\mu} \in \tilde{T},$ then $\hat{\mu}$ it's unbiased; and (2) Show that for every estimator $\beta \in \tilde{T}$, $\mathrm{Var}(\bar{X_n})<\mathrm{Var}\{\beta\}$. Here's my attempt: (1) $\hat{\mu} \in \tilde{T} \implies \hat{\mu} = \displaystyle\sum_{i=1}^n \alpha_iX_i \implies \mathrm{E}(\hat{\mu}) = \mathrm{E}\bigg(\displaystyle\sum_{i=1}^n \alpha_iX_i\bigg) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X_i)$. Now, since $X_1,\dots, X_n$ it's a sample mean, then all of them have the same distribution, let's say $X$. Follows $\mathrm{E}(\hat{\mu}) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X_i) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X) = \mathrm{E}(X)\displaystyle\sum_{i=1}^n \alpha_i = \mathrm{E}(X)$ and then follows $ \hat{\mu}$ unbiased ? (2) I know that $\mathrm{V}(\bar{X}) = \displaystyle\frac{\sigma^2}{n}$, if $\mathrm{V}(\beta) < \displaystyle\frac{\sigma^2}{n}$ and since $\beta \in \tilde{T}$ we have $\beta = \displaystyle\sum_{i=1}^n \beta_iX_i$ for $\beta_i$ scalars, then $\mathrm{V}(\beta) =\mathrm{V}\bigg(\displaystyle\sum_{i=1}^n \beta_iX_i\bigg) = \displaystyle\sum_{i=1}^n \beta_i^2\mathrm{V}(X_i) > \displaystyle\sum_{i=1}^n \mathrm{V}(X_i) = n\sigma ^2$ and should be $n\sigma ^2 < \displaystyle\frac{\sigma^2}{n}$. And follows that the assumption was wrong.","Given $X_1, \dots, X_n$ simple random sample with distribution $F_X$ -unknown-, i have to estimate $\mu = \mathrm{E}(X)$. Now, given the famility of estimators $\tilde{T} = \bigg\{\displaystyle\sum_{i=1}^n \alpha_iX_i : \ \displaystyle\sum_{i=1}^n \alpha_i = 1\bigg\}$. I have to (1) Prove that if $\hat{\mu} \in \tilde{T},$ then $\hat{\mu}$ it's unbiased; and (2) Show that for every estimator $\beta \in \tilde{T}$, $\mathrm{Var}(\bar{X_n})<\mathrm{Var}\{\beta\}$. Here's my attempt: (1) $\hat{\mu} \in \tilde{T} \implies \hat{\mu} = \displaystyle\sum_{i=1}^n \alpha_iX_i \implies \mathrm{E}(\hat{\mu}) = \mathrm{E}\bigg(\displaystyle\sum_{i=1}^n \alpha_iX_i\bigg) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X_i)$. Now, since $X_1,\dots, X_n$ it's a sample mean, then all of them have the same distribution, let's say $X$. Follows $\mathrm{E}(\hat{\mu}) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X_i) = \displaystyle\sum_{i=1}^n \alpha_i\mathrm{E}(X) = \mathrm{E}(X)\displaystyle\sum_{i=1}^n \alpha_i = \mathrm{E}(X)$ and then follows $ \hat{\mu}$ unbiased ? (2) I know that $\mathrm{V}(\bar{X}) = \displaystyle\frac{\sigma^2}{n}$, if $\mathrm{V}(\beta) < \displaystyle\frac{\sigma^2}{n}$ and since $\beta \in \tilde{T}$ we have $\beta = \displaystyle\sum_{i=1}^n \beta_iX_i$ for $\beta_i$ scalars, then $\mathrm{V}(\beta) =\mathrm{V}\bigg(\displaystyle\sum_{i=1}^n \beta_iX_i\bigg) = \displaystyle\sum_{i=1}^n \beta_i^2\mathrm{V}(X_i) > \displaystyle\sum_{i=1}^n \mathrm{V}(X_i) = n\sigma ^2$ and should be $n\sigma ^2 < \displaystyle\frac{\sigma^2}{n}$. And follows that the assumption was wrong.",,['statistics']
85,Max variance of uniform distribution?,Max variance of uniform distribution?,,"Suppose I roll a 20-sided die 1000 times and count the number of times a particular value comes up. This gives an array of 20 counts, and the expected value of each is 1000/20 = 50. I'd like to find an estimate for the maximum variation around this number. If I subtract 50 from each count and take the absolute value, what is the maximum I'm likely to find? This would be N where 50% of trials will have all counts within N of the expected value, and 50% will have one or more count beyond. (A specific example for clarity, I'm really looking for a general answer about uniform distributions.)","Suppose I roll a 20-sided die 1000 times and count the number of times a particular value comes up. This gives an array of 20 counts, and the expected value of each is 1000/20 = 50. I'd like to find an estimate for the maximum variation around this number. If I subtract 50 from each count and take the absolute value, what is the maximum I'm likely to find? This would be N where 50% of trials will have all counts within N of the expected value, and 50% will have one or more count beyond. (A specific example for clarity, I'm really looking for a general answer about uniform distributions.)",,"['statistics', 'uniform-distribution']"
86,hypothesis testing problem,hypothesis testing problem,,"I'm stuck at the following problem We have people picking one of A,B,C. According to a theoretical model people pick in the ratio $p^2:2p(1-p):(1-p)^2$ respectively. From a sample we have 42,52,22. Is the model correct? I know that I have to use chi-square test and since we know nothing about $p$ I should use MLE When I do  that I find $\hat{p}=\frac{1}{2}$ but according to the book it should be $\hat{p}=\frac{68}{116}$ I would like to know what I'm doing wrong?","I'm stuck at the following problem We have people picking one of A,B,C. According to a theoretical model people pick in the ratio $p^2:2p(1-p):(1-p)^2$ respectively. From a sample we have 42,52,22. Is the model correct? I know that I have to use chi-square test and since we know nothing about $p$ I should use MLE When I do  that I find $\hat{p}=\frac{1}{2}$ but according to the book it should be $\hat{p}=\frac{68}{116}$ I would like to know what I'm doing wrong?",,['statistics']
87,Convergence in distribution of a quadratic form,Convergence in distribution of a quadratic form,,"If $Q_n=X_nM_nX_n=\sum_{i,j=1}^n X_i m_{nij}X_j$, $X_n=(X_1,...,X_n)$ where $X_j$ are iid random variables and $M_n=(m_{nij})$ is a symmetric matrix with extending rownumber in $n\to\infty$. Iam looking for assertions to clarify in which cases there exists a limit-distribution for $Q_n$? E.g. there is a quadratic form which has the same trace for all n.","If $Q_n=X_nM_nX_n=\sum_{i,j=1}^n X_i m_{nij}X_j$, $X_n=(X_1,...,X_n)$ where $X_j$ are iid random variables and $M_n=(m_{nij})$ is a symmetric matrix with extending rownumber in $n\to\infty$. Iam looking for assertions to clarify in which cases there exists a limit-distribution for $Q_n$? E.g. there is a quadratic form which has the same trace for all n.",,"['probability', 'statistics', 'convergence-divergence', 'quadratic-forms']"
88,Random walk type problem with time increments,Random walk type problem with time increments,,Imagine you have $\$50$ and every $2$ minutes you either gain or lose $33$ cents. How would you model the evolution of the hypothetical bankroll for the next hour? My approach based on what i've read about about random walks: $\sigma=.33\cdot(\frac{60}{2})^.5$ $\mu=50.$ Plug these into a normal distribution to find the probability of having $x$ amount of money after an hour. Some sources say if $\frac{1}{2}$ then $\sigma$ would have to be divided by $2$. But others just use the square root.,Imagine you have $\$50$ and every $2$ minutes you either gain or lose $33$ cents. How would you model the evolution of the hypothetical bankroll for the next hour? My approach based on what i've read about about random walks: $\sigma=.33\cdot(\frac{60}{2})^.5$ $\mu=50.$ Plug these into a normal distribution to find the probability of having $x$ amount of money after an hour. Some sources say if $\frac{1}{2}$ then $\sigma$ would have to be divided by $2$. But others just use the square root.,,"['probability', 'statistics', 'random-walk']"
89,Stabilize Variance for Statistics (Transformation),Stabilize Variance for Statistics (Transformation),,"Problem: When $Y (> 0)$ has mean and variance equal to $\mu$ and $\mu/n$ respectively, it is shown in the textbook that the appropriate transformation of Y to stabilize variance is the square root transformation. Suppose that Y has mean equal to  respectively, it is shown on pages 76-77 of our textbook that the mu and variance equal to $\frac{\mu^4}{n}$ where $n$ is ""large"".  Find the appropriate transformation $Z = f(Y)$ of $Y$ that makes the variance of $Z$ equal to 1. My feedback: I know I am to use the equation $Var(f(Y)) \approx [f'E(Y))]^2 \times Var(Y)$. This is equivalent to $1 \approx [f'(\mu)]^2 \times (\frac{\mu^4}{n} )$. I am struggling to understand how to apply this derivative to solve this equation.","Problem: When $Y (> 0)$ has mean and variance equal to $\mu$ and $\mu/n$ respectively, it is shown in the textbook that the appropriate transformation of Y to stabilize variance is the square root transformation. Suppose that Y has mean equal to  respectively, it is shown on pages 76-77 of our textbook that the mu and variance equal to $\frac{\mu^4}{n}$ where $n$ is ""large"".  Find the appropriate transformation $Z = f(Y)$ of $Y$ that makes the variance of $Z$ equal to 1. My feedback: I know I am to use the equation $Var(f(Y)) \approx [f'E(Y))]^2 \times Var(Y)$. This is equivalent to $1 \approx [f'(\mu)]^2 \times (\frac{\mu^4}{n} )$. I am struggling to understand how to apply this derivative to solve this equation.",,"['calculus', 'statistics', 'transformation']"
90,Conditional Expected Value and distribution question,Conditional Expected Value and distribution question,,"The distribution of loss due to fire damage to a warehouse is: $$ \begin{array}{r|l} \text{Amount of Loss (X)} & \text{Probability}\\ \hline 0 & 0.900 \\ 500 & 0.060  \\ 1,000 & 0.030\\ 10,000 & 0.008 \\ 50,000 & 0.001\\ 100,000 & 0.001 \\ \end{array} $$ Given that a loss is greater than zero, calculate the expected amount of the loss. My approach is to apply the definition of expected value: $$E[X \mid X>0]=\sum\limits_{x_i}x_i \cdot p(x_i)=500 \cdot 0.060 + 1,000 \cdot 0.030 + \cdots + 100,000 \cdot 0.001=290$$ I am off by a factor of 10--The answer is 2,900.  I am following the definition of expected value, does anyone know why I am off by a factor of $1/10$? Should I be doing this instead??? $E[X \mid X>0] = \sum\limits_{x_i} (x_i \mid x_i > 0) \cdot \cfrac{\Pr[x_i \cap x_i>0]}{\Pr(x_i > 0)}$ Thanks.","The distribution of loss due to fire damage to a warehouse is: $$ \begin{array}{r|l} \text{Amount of Loss (X)} & \text{Probability}\\ \hline 0 & 0.900 \\ 500 & 0.060  \\ 1,000 & 0.030\\ 10,000 & 0.008 \\ 50,000 & 0.001\\ 100,000 & 0.001 \\ \end{array} $$ Given that a loss is greater than zero, calculate the expected amount of the loss. My approach is to apply the definition of expected value: $$E[X \mid X>0]=\sum\limits_{x_i}x_i \cdot p(x_i)=500 \cdot 0.060 + 1,000 \cdot 0.030 + \cdots + 100,000 \cdot 0.001=290$$ I am off by a factor of 10--The answer is 2,900.  I am following the definition of expected value, does anyone know why I am off by a factor of $1/10$? Should I be doing this instead??? $E[X \mid X>0] = \sum\limits_{x_i} (x_i \mid x_i > 0) \cdot \cfrac{\Pr[x_i \cap x_i>0]}{\Pr(x_i > 0)}$ Thanks.",,"['probability', 'statistics']"
91,rms signal given covariance matrix,rms signal given covariance matrix,,"Hi I have a fairly simple question Say I have a covariance matrix C that describes the noise in some data series D, including correlations between different data points (so just a general correlated gaussian). I thought that if i wanted to work out the theoretical RMS of the signal such a matrix describes i could just use the square root of the diagonal elements, however, if i generate 100000 realisations of noise described by my covariance matrix by taking the cholesky decomposition and using that to generate my data series, i get an rms of 1.23508e-07 however the square root of all the diagonal elements of the covariance matrix are 2.12019e-07 and i don't understand where the offset is coming from. How should i go about getting the theoretical rms from the covariance matrix? Cheers","Hi I have a fairly simple question Say I have a covariance matrix C that describes the noise in some data series D, including correlations between different data points (so just a general correlated gaussian). I thought that if i wanted to work out the theoretical RMS of the signal such a matrix describes i could just use the square root of the diagonal elements, however, if i generate 100000 realisations of noise described by my covariance matrix by taking the cholesky decomposition and using that to generate my data series, i get an rms of 1.23508e-07 however the square root of all the diagonal elements of the covariance matrix are 2.12019e-07 and i don't understand where the offset is coming from. How should i go about getting the theoretical rms from the covariance matrix? Cheers",,['statistics']
92,Broken Line Regression,Broken Line Regression,,"$X = $Lot & $Y = $Cost Give a broken line linear model with a breakpoint at $250$: $$Y = B_0 + B_1X_1 + B_2X_2 + B_3X_3 + e$$ where $X_2 = 0$ or $1$ depending on whether the lot size is $\geq 250$ or $< 250$ and $X_3 = X_1\cdot X_2.$ Which hypothesis statement is equivalent to the statement: The two regression lines have the same intercept term? $$H_0 : B_0 = 0\\ H_0 : B_1 = 0\\ H_0 : B_2 = 0\\ H_0 : B_3 = 0$$ $B_0$ is obviously the intercept for simple linear regression models, however, the broken line phrasing is causing me to be confused on this. My initial instinct was to assume $B_0$ hypothesis was appropriate, but now I'm wondering if $B_2 = 0$ makes more sense. Any assistance or starting point would be very beneficial as I need to explain through the reasoning algebraically too !","$X = $Lot & $Y = $Cost Give a broken line linear model with a breakpoint at $250$: $$Y = B_0 + B_1X_1 + B_2X_2 + B_3X_3 + e$$ where $X_2 = 0$ or $1$ depending on whether the lot size is $\geq 250$ or $< 250$ and $X_3 = X_1\cdot X_2.$ Which hypothesis statement is equivalent to the statement: The two regression lines have the same intercept term? $$H_0 : B_0 = 0\\ H_0 : B_1 = 0\\ H_0 : B_2 = 0\\ H_0 : B_3 = 0$$ $B_0$ is obviously the intercept for simple linear regression models, however, the broken line phrasing is causing me to be confused on this. My initial instinct was to assume $B_0$ hypothesis was appropriate, but now I'm wondering if $B_2 = 0$ makes more sense. Any assistance or starting point would be very beneficial as I need to explain through the reasoning algebraically too !",,"['statistics', 'regression']"
93,The distribution of the result of Monte-Carlo method,The distribution of the result of Monte-Carlo method,,"For example, if I want to determine the probability of getting tails when tossing a coin. By Monte-Carlo method, I toss the coin 1000 times and got 600 tails. As I know the distribution of the result is binomial, I can be confident to say the probability of getting tails is somewhere very near 60%. If I toss the coin another 1000 times it's likely that I get roughly 600 tails again. So what about the general case? If I go over some Monte-Carlo simulation over and over again, what distribution of results am I expected to see? A normal distribution? Or the answer depends on the Monte-Carlo simulation itself? EDIT: on the second thought this is a stupid question because clearly the distribution depends on the nature of the original problem. So I'm going to change my question to: why can I be confident when using Monte-Carlo method, and how to quantify my confidence?","For example, if I want to determine the probability of getting tails when tossing a coin. By Monte-Carlo method, I toss the coin 1000 times and got 600 tails. As I know the distribution of the result is binomial, I can be confident to say the probability of getting tails is somewhere very near 60%. If I toss the coin another 1000 times it's likely that I get roughly 600 tails again. So what about the general case? If I go over some Monte-Carlo simulation over and over again, what distribution of results am I expected to see? A normal distribution? Or the answer depends on the Monte-Carlo simulation itself? EDIT: on the second thought this is a stupid question because clearly the distribution depends on the nature of the original problem. So I'm going to change my question to: why can I be confident when using Monte-Carlo method, and how to quantify my confidence?",,"['statistics', 'probability-distributions', 'normal-distribution']"
94,"Conjugate prior where prior is normal, applying Bayes theorem","Conjugate prior where prior is normal, applying Bayes theorem",,"So $X_1,...,X_n$ forms a random sample from a normal dist with unknown mean $µ$ and variance $σ^2$ . So we have the prior distribution with mean $0$ and variance $σ^2$ .  We then need to show that if $n$ is large then the posterior distribution of $µ$ given that $X_i=x_i(i=1,…,n)$ will be approximately a normal distribution with mean $\bar{x_n}$ and variance $\sigma^2/n$ . I've found solutions from various places, but I don't understand some of them. I mean, from bayes' theorem, the posterior is proportional to product of prior and likelihood function, because the denominator in the formula just goes to constant with respect to mu, so we just look at the proportionality. Also, once you get the product, the constant at the front isn't important and also drops off. I found similar questions and solutions, but I'm not sure how to apply them here: http://lausanne.isb-sib.ch/~darlene/gda/add/BayesConjugateNormal.pdf Bayes Estimator of normal distribution and normal prior I wasn't sure why the $\tau$ notation for variance was introduced, and how to express the argument that what we get at the end is our $\bar{x_n}$ and variance $\sigma^2/n$ .","So forms a random sample from a normal dist with unknown mean and variance . So we have the prior distribution with mean and variance .  We then need to show that if is large then the posterior distribution of given that will be approximately a normal distribution with mean and variance . I've found solutions from various places, but I don't understand some of them. I mean, from bayes' theorem, the posterior is proportional to product of prior and likelihood function, because the denominator in the formula just goes to constant with respect to mu, so we just look at the proportionality. Also, once you get the product, the constant at the front isn't important and also drops off. I found similar questions and solutions, but I'm not sure how to apply them here: http://lausanne.isb-sib.ch/~darlene/gda/add/BayesConjugateNormal.pdf Bayes Estimator of normal distribution and normal prior I wasn't sure why the notation for variance was introduced, and how to express the argument that what we get at the end is our and variance .","X_1,...,X_n µ σ^2 0 σ^2 n µ X_i=x_i(i=1,…,n) \bar{x_n} \sigma^2/n \tau \bar{x_n} \sigma^2/n","['probability', 'statistics']"
95,T'wo level full factorial design question,T'wo level full factorial design question,,"I need to prove the following identities for a factorial design experiment of the form $2^k$. $\overline{Y}(AB+)-\overline{Y}(AB-)=0.5$[$A(B+)-A(B-)$] $A(B+)=A+AB$ $A(B-)=A-AB$ $A=\frac{[A(B+)+A(B-)]}{2}$ ($\overline{Y}(AB+)$ is the mean of all observations where A*B has a positive sign, A(B+) is the effect of A when B is positive +, and so on..) I know that for a  factorial design experiment of the form $2^3$ $AB=[A(B+)-A(B-)]/2$, but I'm not sure it's applicable for a $2^k$ factorial design experiment. We've mostly talked about the $2^2$ factorial design experiment and briefly mentioned the $2^k$ factorial design","I need to prove the following identities for a factorial design experiment of the form $2^k$. $\overline{Y}(AB+)-\overline{Y}(AB-)=0.5$[$A(B+)-A(B-)$] $A(B+)=A+AB$ $A(B-)=A-AB$ $A=\frac{[A(B+)+A(B-)]}{2}$ ($\overline{Y}(AB+)$ is the mean of all observations where A*B has a positive sign, A(B+) is the effect of A when B is positive +, and so on..) I know that for a  factorial design experiment of the form $2^3$ $AB=[A(B+)-A(B-)]/2$, but I'm not sure it's applicable for a $2^k$ factorial design experiment. We've mostly talked about the $2^2$ factorial design experiment and briefly mentioned the $2^k$ factorial design",,['statistics']
96,Distribution of $pX+(1-p) Y$,Distribution of,pX+(1-p) Y,"We have two independent, normally distributed RV's: $$X \sim N(\mu_1,\sigma^2_1), \quad Y \sim N(\mu_2,\sigma^2_2)$$ and we're interested in the distribution of $pX+(1-p) Y, \space p \in (0,1)$. I've tried to solve this via moment generating functions. Since $$X \perp Y \Rightarrow \Psi_X(t) \Psi_Y(t)$$ where for $ N(\mu,\sigma^2)$ we'll have the MGF $$\Psi(t) = \exp\{ \mu t + \frac12 \sigma^2 t^2 \}$$ After computation I've got the joint MGF as  $$\Psi_{pX+(1-p) Y}(t) = \exp\{ t(p \mu_1 +(1-p)\mu_2) + \frac{t^2}{2}(p^2 \sigma_1^2 +(1-p)^2 \sigma_2^2) \}$$ which would mean $$pX+(1-p) Y \sim N(p \mu_1 +(1-p)\mu_2, p^2 \sigma_1^2 +(1-p)^2 \sigma_2^2) $$ Is my approach correct? Intuitively it makes sense and the math also adds up.","We have two independent, normally distributed RV's: $$X \sim N(\mu_1,\sigma^2_1), \quad Y \sim N(\mu_2,\sigma^2_2)$$ and we're interested in the distribution of $pX+(1-p) Y, \space p \in (0,1)$. I've tried to solve this via moment generating functions. Since $$X \perp Y \Rightarrow \Psi_X(t) \Psi_Y(t)$$ where for $ N(\mu,\sigma^2)$ we'll have the MGF $$\Psi(t) = \exp\{ \mu t + \frac12 \sigma^2 t^2 \}$$ After computation I've got the joint MGF as  $$\Psi_{pX+(1-p) Y}(t) = \exp\{ t(p \mu_1 +(1-p)\mu_2) + \frac{t^2}{2}(p^2 \sigma_1^2 +(1-p)^2 \sigma_2^2) \}$$ which would mean $$pX+(1-p) Y \sim N(p \mu_1 +(1-p)\mu_2, p^2 \sigma_1^2 +(1-p)^2 \sigma_2^2) $$ Is my approach correct? Intuitively it makes sense and the math also adds up.",,"['probability', 'statistics', 'probability-distributions']"
97,Exponent p-value generated in Excel,Exponent p-value generated in Excel,,"Excel gave me a p-value of 1.44909E-09 Notice is does not say .09 but 09 This is confusing me, I am trying to analyze my data but am stuck at this point. If it were E-9 it could be 1.44909/1000000000 ? The rest of the data I have looks like this (blood pressure data): The mean SBP for control is 116.525 and experimental 119.125. The mean DBP for control is 67.575 and experimental 80.05. The standard deviation SBP for control is 15.076 and experimental is 20.613. The standard deviation DBP for control is 8.003 and experimental 11.856. The p-value for the control data-set is 39%. The p-value for the experimental data-set is ???? (also, since both data sets were close in range, is the data not significant?)","Excel gave me a p-value of 1.44909E-09 Notice is does not say .09 but 09 This is confusing me, I am trying to analyze my data but am stuck at this point. If it were E-9 it could be 1.44909/1000000000 ? The rest of the data I have looks like this (blood pressure data): The mean SBP for control is 116.525 and experimental 119.125. The mean DBP for control is 67.575 and experimental 80.05. The standard deviation SBP for control is 15.076 and experimental is 20.613. The standard deviation DBP for control is 8.003 and experimental 11.856. The p-value for the control data-set is 39%. The p-value for the experimental data-set is ???? (also, since both data sets were close in range, is the data not significant?)",,"['real-analysis', 'statistics', 'exponentiation', 'data-analysis', 'statistical-mechanics']"
98,This is regarding Chi square test,This is regarding Chi square test,,A chi square test is conducted to check whether a person's ability in Mathematics has an impact on his/her interest in Statistic. The test statistic is 13.277 under the tested null hypothesis. write a recommended null hypothesis and an alternative hypothesis. Briefly describe your conclusion on this test at the 0.01 significance level.,A chi square test is conducted to check whether a person's ability in Mathematics has an impact on his/her interest in Statistic. The test statistic is 13.277 under the tested null hypothesis. write a recommended null hypothesis and an alternative hypothesis. Briefly describe your conclusion on this test at the 0.01 significance level.,,['statistics']
99,Probability distribution for a digit of a number,Probability distribution for a digit of a number,,"If someone choose a digit $\alpha$ and a digit $\beta$ independently. Each one can be in $0,1, ...,9$. So $\mu = \alpha \beta$ (e.g. if $\alpha = 5$ and $\beta = 3$ then $\mu =53$). And I observe a sample: $\{10,12,45,50\}$. How can I attribute a likelihood distribution and a prior distribution to $\alpha$ and $\beta$ to test the hypothesis that $\alpha < \beta$? The sample for μ is {10,12,45,50},for α is {1,1,4,5} and for β is {0,2,5,0}. μ can any number between (0;99), α and β can be any number between (0;9). The person choosed only one time α and β, after this μ is fixed for a number of balls in an urn that can have (0;99) balls depending on the one's choice. Only after this, I observe the sample, with μ fixed. My estimative will depends on the sample that I observed. Here is my answer: $p(\alpha) = \frac{1}{10}$ For estimate $\alpha$, the most important digit of $\mu$ is the left one. So I call $a_{i}$ the left digit of the $n_{i}$ observation. And I call $a = max(a_{i}), i=1,...,n$. I don't know what is the pdf of $a = max(a_{i})$, but I know its cdf: $p(a \leq a_{i} |\alpha) = p(a_{1} \leq a |\alpha)p(a_{2} \leq |\alpha)...p(a_{n} \leq a |\alpha) = (\frac{max(a_{i})}{\alpha})^n = F(a|\alpha) $ To find the pdf: $\frac{dF(a|\alpha)}{da} = \frac{n*max(a_{i})^{n-1}}{\alpha^{n}}$ So the posterior of $\alpha$: $p(\alpha | a) \propto 1 \times \frac{n*max(a_{i})^{n-1}}{\alpha^{n}}$ The same for $\beta$: $p(\beta| b) \propto 1 \times \frac{n*max(b_{i})^{n-1}}{\beta^{n}}$ My only problem is how to test the hypothesis that $\alpha < \beta$? The Bayes Fator will be: $BF = \frac{\frac{n*max(a_{i})^{n-1}}{\alpha^{n}}}{\frac{n*max(b_{i})^{n-1}}{\beta^{n}}} = \frac{\alpha^{n}}{\beta^{n}} \times \frac{n*max(a_{i})^{n-1}}{n*max(b_{i})^{n-1}} $ That still depends on $\alpha$ and $\beta$, unknown","If someone choose a digit $\alpha$ and a digit $\beta$ independently. Each one can be in $0,1, ...,9$. So $\mu = \alpha \beta$ (e.g. if $\alpha = 5$ and $\beta = 3$ then $\mu =53$). And I observe a sample: $\{10,12,45,50\}$. How can I attribute a likelihood distribution and a prior distribution to $\alpha$ and $\beta$ to test the hypothesis that $\alpha < \beta$? The sample for μ is {10,12,45,50},for α is {1,1,4,5} and for β is {0,2,5,0}. μ can any number between (0;99), α and β can be any number between (0;9). The person choosed only one time α and β, after this μ is fixed for a number of balls in an urn that can have (0;99) balls depending on the one's choice. Only after this, I observe the sample, with μ fixed. My estimative will depends on the sample that I observed. Here is my answer: $p(\alpha) = \frac{1}{10}$ For estimate $\alpha$, the most important digit of $\mu$ is the left one. So I call $a_{i}$ the left digit of the $n_{i}$ observation. And I call $a = max(a_{i}), i=1,...,n$. I don't know what is the pdf of $a = max(a_{i})$, but I know its cdf: $p(a \leq a_{i} |\alpha) = p(a_{1} \leq a |\alpha)p(a_{2} \leq |\alpha)...p(a_{n} \leq a |\alpha) = (\frac{max(a_{i})}{\alpha})^n = F(a|\alpha) $ To find the pdf: $\frac{dF(a|\alpha)}{da} = \frac{n*max(a_{i})^{n-1}}{\alpha^{n}}$ So the posterior of $\alpha$: $p(\alpha | a) \propto 1 \times \frac{n*max(a_{i})^{n-1}}{\alpha^{n}}$ The same for $\beta$: $p(\beta| b) \propto 1 \times \frac{n*max(b_{i})^{n-1}}{\beta^{n}}$ My only problem is how to test the hypothesis that $\alpha < \beta$? The Bayes Fator will be: $BF = \frac{\frac{n*max(a_{i})^{n-1}}{\alpha^{n}}}{\frac{n*max(b_{i})^{n-1}}{\beta^{n}}} = \frac{\alpha^{n}}{\beta^{n}} \times \frac{n*max(a_{i})^{n-1}}{n*max(b_{i})^{n-1}} $ That still depends on $\alpha$ and $\beta$, unknown",,"['probability', 'statistics', 'bayesian', 'statistical-inference']"
