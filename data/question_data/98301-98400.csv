,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Prove there exists a real number $p$ such that $z_1 = p \overline z_2$.,Prove there exists a real number  such that .,p z_1 = p \overline z_2,"Suppose the product of two complex numbers $z_1$ and $z_2$ is real and not zero. Prove there exists a real number $p$ such that $$$$ $z_1 = p \overline z_2 $. $$$$ My solution thus far: Using the equivalence $z \in \Bbb R  \iff z = \overline z. $ Assuming $z_1 . z_2 \in \Bbb R$. Then $z_1 z_2 = \overline{ z_1z_2 }$. As $z_2 \ne 0$. Then $\frac{z_1}{\overline z_2}$ = $\frac{\overline z_1}{z_2}$ = $\overline (\frac{z_1}{\overline z_2})$, i.e. $\frac{z_1}{\overline z_2}$ equals its conjugate. It follows that $\frac{z_1}{\overline z_2} = p \in \Bbb R$. If I then rearrange would this proof suffice? Is this the right approach? I'm still getting to grips with the proofs needed for this course and would appreciate some feedback. (The $\overline (\frac{z_1}{\overline z_2})$ part is supposed to have a bar above but \overline seems to have cut part of it off).","Suppose the product of two complex numbers $z_1$ and $z_2$ is real and not zero. Prove there exists a real number $p$ such that $$$$ $z_1 = p \overline z_2 $. $$$$ My solution thus far: Using the equivalence $z \in \Bbb R  \iff z = \overline z. $ Assuming $z_1 . z_2 \in \Bbb R$. Then $z_1 z_2 = \overline{ z_1z_2 }$. As $z_2 \ne 0$. Then $\frac{z_1}{\overline z_2}$ = $\frac{\overline z_1}{z_2}$ = $\overline (\frac{z_1}{\overline z_2})$, i.e. $\frac{z_1}{\overline z_2}$ equals its conjugate. It follows that $\frac{z_1}{\overline z_2} = p \in \Bbb R$. If I then rearrange would this proof suffice? Is this the right approach? I'm still getting to grips with the proofs needed for this course and would appreciate some feedback. (The $\overline (\frac{z_1}{\overline z_2})$ part is supposed to have a bar above but \overline seems to have cut part of it off).",,"['complex-analysis', 'complex-numbers', 'real-numbers']"
1,"Show that $x$ is within the unit disk if $\overline{x} + xz_1z_2 = z_1 + z_2$ and $|z_1|,|z_2| < 1$.",Show that  is within the unit disk if  and .,"x \overline{x} + xz_1z_2 = z_1 + z_2 |z_1|,|z_2| < 1","Let $x \in \mathbb{C}$. Denote the complex conjugate of $x$ as $\overline{x}$. Fix $z_1, z_2 \in \mathbb{C}$ such that $|z_1| < 1$ and $|z_2| <1$.  The following equation is satisfied: $$\overline{x} + xz_1z_2 = z_1 + z_2$$ I want to show that $|x| < 1$. I tried a whole bunch of numerics and this seems to be true, but I have difficulty proving it. Any suggestions would be appreciated!","Let $x \in \mathbb{C}$. Denote the complex conjugate of $x$ as $\overline{x}$. Fix $z_1, z_2 \in \mathbb{C}$ such that $|z_1| < 1$ and $|z_2| <1$.  The following equation is satisfied: $$\overline{x} + xz_1z_2 = z_1 + z_2$$ I want to show that $|x| < 1$. I tried a whole bunch of numerics and this seems to be true, but I have difficulty proving it. Any suggestions would be appreciated!",,['complex-analysis']
2,Help needed on laurent series for a complex function,Help needed on laurent series for a complex function,,I'm struggling to understand the ways in which one could find the laurent series and there for the residuals for: Find the Laurent series expansion and residue at    $$ \left(\frac{z}{z-1}\right)^2 $$   for $z = 1$ Any help that could be provided as to where to start would be appreciated. I attempted differentiating the Laurent series expansion for $$ \frac{1}{z-1} $$ Aswell as trying to multiply out the coefficients of the Laurent expansion for $$ \frac{1}{z-1} $$ But have had no luck whatsoever and just get myself into a state.,I'm struggling to understand the ways in which one could find the laurent series and there for the residuals for: Find the Laurent series expansion and residue at    $$ \left(\frac{z}{z-1}\right)^2 $$   for $z = 1$ Any help that could be provided as to where to start would be appreciated. I attempted differentiating the Laurent series expansion for $$ \frac{1}{z-1} $$ Aswell as trying to multiply out the coefficients of the Laurent expansion for $$ \frac{1}{z-1} $$ But have had no luck whatsoever and just get myself into a state.,,"['sequences-and-series', 'complex-analysis', 'laurent-series']"
3,Show that there exists $g:D\rightarrow \mathbb{C}$ is analytic and one-to-one such that $(g(z))^2=f(z^2).$,Show that there exists  is analytic and one-to-one such that,g:D\rightarrow \mathbb{C} (g(z))^2=f(z^2).,"Let $D=\{z: |z|<1\}$ and suppose that $f:D\rightarrow \mathbb{C}$ is analytic, one-to-one and $f(0)=0, f'(0)=1.$ Show that there exists $g:D\rightarrow \mathbb{C}$ is analytic and one-to-one such that $(g(z))^2=f(z^2).$ I proved this statement is as follows: Since $f$ is analytic and $f(0)=0, f'(0)=1$, we have $f(z)=z+a_1z^2+a_2z^3+...$ Then, $f(z^2)=z^2(1+a_1z^2+a_2z^3+...)=z^2h(z).$ If there is $z_0\in D$ such that $h(z_0)=0$, we have $f({z_0}^2)=0$, which implies $z_0^2=0$ since $f$ is 1-1. Thus, $z_0=0.$ However, it is clear that $h(0)=1\neq 0.$ Hence, we proved that $h$ is nonzero on $D$. Now, since $h$ and $\frac{1}{h}$ are both analytic on $D$, there is an analytic function $g_1:D\rightarrow \mathbb{C}$ such that $g_1^2=h.$ (this result follows from the theorem 13.11 in Real and Complex analysis by W. Rudin) Therefore, we define $g(z)=zg_1(z)$, it is clear that $g$ is analytic and satisfies $g(z)^2=f(z^2).$ However, I have no good idea how to explain that $g$ is 1-1. Can anyone give me some ideas how to solve this part? Thanks.","Let $D=\{z: |z|<1\}$ and suppose that $f:D\rightarrow \mathbb{C}$ is analytic, one-to-one and $f(0)=0, f'(0)=1.$ Show that there exists $g:D\rightarrow \mathbb{C}$ is analytic and one-to-one such that $(g(z))^2=f(z^2).$ I proved this statement is as follows: Since $f$ is analytic and $f(0)=0, f'(0)=1$, we have $f(z)=z+a_1z^2+a_2z^3+...$ Then, $f(z^2)=z^2(1+a_1z^2+a_2z^3+...)=z^2h(z).$ If there is $z_0\in D$ such that $h(z_0)=0$, we have $f({z_0}^2)=0$, which implies $z_0^2=0$ since $f$ is 1-1. Thus, $z_0=0.$ However, it is clear that $h(0)=1\neq 0.$ Hence, we proved that $h$ is nonzero on $D$. Now, since $h$ and $\frac{1}{h}$ are both analytic on $D$, there is an analytic function $g_1:D\rightarrow \mathbb{C}$ such that $g_1^2=h.$ (this result follows from the theorem 13.11 in Real and Complex analysis by W. Rudin) Therefore, we define $g(z)=zg_1(z)$, it is clear that $g$ is analytic and satisfies $g(z)^2=f(z^2).$ However, I have no good idea how to explain that $g$ is 1-1. Can anyone give me some ideas how to solve this part? Thanks.",,['complex-analysis']
4,"If $f$ is holomorphic except for $z_0$, then $\lim_{n\to\infty} \frac{a_n}{a_{n+1}}=z_0$","If  is holomorphic except for , then",f z_0 \lim_{n\to\infty} \frac{a_n}{a_{n+1}}=z_0,"The question is from Stein & Shakarchi - Complex Analysis Chapter 2, Exercise 14. Suppose that $f$ is holomorphic in an open set $\Omega$ containing the closed unit disc, except for a pole at $z_0$ on the unit circle. Show that if $f$ is given by a power series expansion $$f(z)=\sum^\infty_{n=0}a_n z^n$$ in the unit disc $D_1(0)$ , then $$\lim_{n\to\infty} \frac{a_n}{a_{n+1}}=z_0.$$ I solved this problem by using the pole formula $$f(z)=(z-z_0)^{-m}g_0(z)\implies f^{(n)}(z)=(z-z_0)^{-m-n}g_n(z)$$ where $g_0$ and $g_n$ are holomorphic and not zero at $z_0$ , and $m$ is a positive integer. These are defined on $D_{1+\epsilon}(0)\subset\Omega$ , which contains $z_0$ and $\epsilon$ is sufficiently small. I've got below : $$\lim_{n\to\infty} \frac{a_{n+1}}{a_{n}}=\lim_{n\to\infty} \dfrac{\frac{f^{(n+1)}(0)}{(n+1)!}}{\frac{f^{(n)}(0)}{n!}}=\lim_{n\to\infty}\dfrac{1}{n+1}\left(\dfrac{-m-n}{0-z_0}+H(0)\right)=\dfrac{1}{z_0}.$$ where $H(z)$ is holomorphic in the disc. Actually, the pole formula I've used appears in Chapter 3 so I should not use this, but I think it is worth to try. Is there something wrong about this solution? Very thanks.","The question is from Stein & Shakarchi - Complex Analysis Chapter 2, Exercise 14. Suppose that is holomorphic in an open set containing the closed unit disc, except for a pole at on the unit circle. Show that if is given by a power series expansion in the unit disc , then I solved this problem by using the pole formula where and are holomorphic and not zero at , and is a positive integer. These are defined on , which contains and is sufficiently small. I've got below : where is holomorphic in the disc. Actually, the pole formula I've used appears in Chapter 3 so I should not use this, but I think it is worth to try. Is there something wrong about this solution? Very thanks.",f \Omega z_0 f f(z)=\sum^\infty_{n=0}a_n z^n D_1(0) \lim_{n\to\infty} \frac{a_n}{a_{n+1}}=z_0. f(z)=(z-z_0)^{-m}g_0(z)\implies f^{(n)}(z)=(z-z_0)^{-m-n}g_n(z) g_0 g_n z_0 m D_{1+\epsilon}(0)\subset\Omega z_0 \epsilon \lim_{n\to\infty} \frac{a_{n+1}}{a_{n}}=\lim_{n\to\infty} \dfrac{\frac{f^{(n+1)}(0)}{(n+1)!}}{\frac{f^{(n)}(0)}{n!}}=\lim_{n\to\infty}\dfrac{1}{n+1}\left(\dfrac{-m-n}{0-z_0}+H(0)\right)=\dfrac{1}{z_0}. H(z),"['complex-analysis', 'solution-verification']"
5,Integrate $\int _0^{\infty }\frac{\sqrt[3]{x}}{x^2+1\:}\:dx$,Integrate,\int _0^{\infty }\frac{\sqrt[3]{x}}{x^2+1\:}\:dx,"So I want to compute $ I = \int _0^{\infty }\frac{\sqrt[3]{x}}{x^2+1\:}\:dx$. First thing I thought of is that integrals from $0$ to $\infty$ usually take a nicer form when we apply the change $x = e^t$, so I did that: $$ I = \int _{-\infty }^{\infty }\frac{e^{\frac{4}{3}t}}{e^{2t}+1\:}\:dt $$ Now, I've seen some other integrals with a form like this one. For the other ones, I computed the contour integral of a rectangle of vertex $[-R, R, R+xi, -R+xi]$, choosing $x$ such that the integrand takes opposite values in $[-R, R]$ and $[-R+xi, R+xi]$. If I could choose such an $x$, then I would have succeeded, since I can prove that the lateral integrals go to $0$ as $R\to \infty$, and thus the desired integrals would be equal to half the value of the residues enclosed by the rectangle. But that requires solving the following system: $$ \begin{cases}  e^{\frac{4}{3}t} = -e^{\frac{4}{3}(t+xi)} \\  e^{2t} = e^{2(t+xi)}  \end{cases} \implies \begin{cases}  \frac{4}{3}xi+i\pi = 2ki\pi \\  2xi = 2ki\pi  \end{cases} \implies \begin{cases}  x = \frac{3}{4}(2k+1)\pi \\ x = k\pi \end{cases} $$ For $k\in \mathbb{Z}$. But this system does not have a solution! The first equation forces $x$ to be $q\pi$ for some $q\not\in\mathbb{Z}$, contradicting the second equation. From here I am stuck. Can I get a hint? EDIT: I followed @DanielFischer suggestion to use a keyhole contour. Let $C$ be the keyhole contour formed by a big circle $\Gamma_R$ of radii $R$, a small circle $\gamma_\epsilon$ of radii $\epsilon$ and two segments connecting the two circles surrounding the positive axis, separated by a $\delta$ margin. Then we have thanks to the estimation lemma that: $$ |\int_{\Gamma_R}|\le {\sup}_{z\in{\Gamma_R}}{\frac{\sqrt[3]{z}}{z^2+1\:}}\cdot long(\Gamma_R)\sim \frac{R^{1/3}}{R^2}\cdot 2\pi R \to 0 $$ On the other hand, when $\delta \to 0$: $$ \int_R^\epsilon\frac{\sqrt[3]{z}}{z^2+1\:} =  \int_R^\epsilon\frac{e^{\log{z}/3}}{z^2+1\:} =  \int_R^\epsilon\frac{e^{\frac{\log{|z| + i\arg{z}}}{3}}}{z^2+1\:} =  -e^{-2\pi i/3}\int_\epsilon^R\frac{e^{\frac{\log{|z| + i\arg{z}+2\pi i}}{3}}}{z^2+1\:} =  -e^{-2\pi i/3}\int_\epsilon^R $$ Thus in the limit: $$ \int_C = \int_\Gamma + \int_\gamma + \int_\epsilon^R + \int_R^\epsilon = \int_0^\infty -e^{-2\pi i/3}\int_0^\infty =\\ =(1 -e^{-2\pi i/3})\int_0^\infty = 2\pi i (Res(i)+Res(-i)) $$ The residues can be easily calculated as: $$ Res(i) = \frac{\sqrt[3]{i}}{2i\:}\\ Res(-i) = \frac{\sqrt[3]{-i}}{-2i\:} $$ Thus $\int_0^\infty = \frac{2\pi i (\frac{\sqrt[3]{i}}{2i\:}+\frac{\sqrt[3]{-i}}{-2i\:})}{(1-e^{-2\pi i/3})} = \frac{π}{2 \sqrt{3}} + \frac{i π}{2}$... which is not real as it should be. Along the way I've also assumed that $\int_{\gamma_\epsilon}\to 0$, which seems like the case but I cannot prove it. Therefore, I ask: How do I prove that $\int_{\gamma_\epsilon}\to 0$? Why is my result wrong? Turns out the minus sign on the exponent was wrong: $$I = \frac{i \left(e^{\frac{i \pi }{3}}-e^{-\frac{2 i \pi }{3}} \right) \pi }{1-e^{\frac{2    i \pi }{3}}} = -2\pi / \sqrt{3}$$ This result is still wrong according to the almighty Wolfram Alpha, but at least it has a similar form! I'll keep debugging.","So I want to compute $ I = \int _0^{\infty }\frac{\sqrt[3]{x}}{x^2+1\:}\:dx$. First thing I thought of is that integrals from $0$ to $\infty$ usually take a nicer form when we apply the change $x = e^t$, so I did that: $$ I = \int _{-\infty }^{\infty }\frac{e^{\frac{4}{3}t}}{e^{2t}+1\:}\:dt $$ Now, I've seen some other integrals with a form like this one. For the other ones, I computed the contour integral of a rectangle of vertex $[-R, R, R+xi, -R+xi]$, choosing $x$ such that the integrand takes opposite values in $[-R, R]$ and $[-R+xi, R+xi]$. If I could choose such an $x$, then I would have succeeded, since I can prove that the lateral integrals go to $0$ as $R\to \infty$, and thus the desired integrals would be equal to half the value of the residues enclosed by the rectangle. But that requires solving the following system: $$ \begin{cases}  e^{\frac{4}{3}t} = -e^{\frac{4}{3}(t+xi)} \\  e^{2t} = e^{2(t+xi)}  \end{cases} \implies \begin{cases}  \frac{4}{3}xi+i\pi = 2ki\pi \\  2xi = 2ki\pi  \end{cases} \implies \begin{cases}  x = \frac{3}{4}(2k+1)\pi \\ x = k\pi \end{cases} $$ For $k\in \mathbb{Z}$. But this system does not have a solution! The first equation forces $x$ to be $q\pi$ for some $q\not\in\mathbb{Z}$, contradicting the second equation. From here I am stuck. Can I get a hint? EDIT: I followed @DanielFischer suggestion to use a keyhole contour. Let $C$ be the keyhole contour formed by a big circle $\Gamma_R$ of radii $R$, a small circle $\gamma_\epsilon$ of radii $\epsilon$ and two segments connecting the two circles surrounding the positive axis, separated by a $\delta$ margin. Then we have thanks to the estimation lemma that: $$ |\int_{\Gamma_R}|\le {\sup}_{z\in{\Gamma_R}}{\frac{\sqrt[3]{z}}{z^2+1\:}}\cdot long(\Gamma_R)\sim \frac{R^{1/3}}{R^2}\cdot 2\pi R \to 0 $$ On the other hand, when $\delta \to 0$: $$ \int_R^\epsilon\frac{\sqrt[3]{z}}{z^2+1\:} =  \int_R^\epsilon\frac{e^{\log{z}/3}}{z^2+1\:} =  \int_R^\epsilon\frac{e^{\frac{\log{|z| + i\arg{z}}}{3}}}{z^2+1\:} =  -e^{-2\pi i/3}\int_\epsilon^R\frac{e^{\frac{\log{|z| + i\arg{z}+2\pi i}}{3}}}{z^2+1\:} =  -e^{-2\pi i/3}\int_\epsilon^R $$ Thus in the limit: $$ \int_C = \int_\Gamma + \int_\gamma + \int_\epsilon^R + \int_R^\epsilon = \int_0^\infty -e^{-2\pi i/3}\int_0^\infty =\\ =(1 -e^{-2\pi i/3})\int_0^\infty = 2\pi i (Res(i)+Res(-i)) $$ The residues can be easily calculated as: $$ Res(i) = \frac{\sqrt[3]{i}}{2i\:}\\ Res(-i) = \frac{\sqrt[3]{-i}}{-2i\:} $$ Thus $\int_0^\infty = \frac{2\pi i (\frac{\sqrt[3]{i}}{2i\:}+\frac{\sqrt[3]{-i}}{-2i\:})}{(1-e^{-2\pi i/3})} = \frac{π}{2 \sqrt{3}} + \frac{i π}{2}$... which is not real as it should be. Along the way I've also assumed that $\int_{\gamma_\epsilon}\to 0$, which seems like the case but I cannot prove it. Therefore, I ask: How do I prove that $\int_{\gamma_\epsilon}\to 0$? Why is my result wrong? Turns out the minus sign on the exponent was wrong: $$I = \frac{i \left(e^{\frac{i \pi }{3}}-e^{-\frac{2 i \pi }{3}} \right) \pi }{1-e^{\frac{2    i \pi }{3}}} = -2\pi / \sqrt{3}$$ This result is still wrong according to the almighty Wolfram Alpha, but at least it has a similar form! I'll keep debugging.",,"['complex-analysis', 'improper-integrals', 'contour-integration']"
6,Conditions for when a line in $\mathbb{C}$ is tangent to a point on a circle,Conditions for when a line in  is tangent to a point on a circle,\mathbb{C},"I am working on the following problem from Chapter 1, Section 5 of Conway's ""Functions of One Complex Variable"": Let $C$ be the circle {z:|z-c|=r}, r>0; let $a=c+r\text{ cis }\alpha$ and put    $$ L_\beta=\left\lbrace z:\text{Im}\left(\frac{z-a}{b}\right)=0\right\rbrace $$   where $b=\text{cis }\beta$. Find necessary and sufficient conditions in terms of $\beta$ that $L_\beta$ be tangent to $C$ at $a$. Here, Conway uses the notation $\text{cis }\alpha$ to denote $(\cos\alpha+i\sin\alpha)$; also, he shows in the section mentioned that $L_\beta$ is simply the line in $\mathbb{C}$ containing $a$ in the direction of $b$. I've been able to convince myself in pictures that the necessary and sufficient condition is that $\beta=\alpha\pm \pi/2$. One direction is: Define  $$ L_\alpha=\left\lbrace z:\text{Im}\left(\frac{z-c}{d}\right)=0\right\rbrace $$ where $d=\text{cis }\alpha$. Then $L_\alpha$ is the line containing $c$ in the direction of $a$. Assuming $\beta=\alpha\pm\pi/2$, define unit vectors $z_1=\text{cis }\alpha$ and $z_2=\text{cis }\beta$. If we were to add $a$ to each of these, then $z_1\in L_\alpha$ and $z_2\in L_\beta$. So, it suffices to show that $z_1$ and $z_2$ are perpendicular when considered as vectors in $\mathbb{R}^2$. Since $z_1=(\cos\alpha,\sin\alpha)$ and $z_2=(\cos\beta,\sin\beta)$, then $$z_1\cdot z_2=\cos\alpha\cos\beta+\sin\alpha\sin\beta=\cos\alpha-\beta=\cos(\pm \pi/2)=0.$$ My questions are: Is this enough to show one direction, or would I have to show something more to show that $L_\beta$ is tangent to $C$ at $a$? Or maybe I've missed the mark completely? How would I begin the other direction? Should I use the definition of ""tangent to $C$ at $a$"" that says $L_\beta$ contains only the point $a$ in the circle $C$? Or something else?","I am working on the following problem from Chapter 1, Section 5 of Conway's ""Functions of One Complex Variable"": Let $C$ be the circle {z:|z-c|=r}, r>0; let $a=c+r\text{ cis }\alpha$ and put    $$ L_\beta=\left\lbrace z:\text{Im}\left(\frac{z-a}{b}\right)=0\right\rbrace $$   where $b=\text{cis }\beta$. Find necessary and sufficient conditions in terms of $\beta$ that $L_\beta$ be tangent to $C$ at $a$. Here, Conway uses the notation $\text{cis }\alpha$ to denote $(\cos\alpha+i\sin\alpha)$; also, he shows in the section mentioned that $L_\beta$ is simply the line in $\mathbb{C}$ containing $a$ in the direction of $b$. I've been able to convince myself in pictures that the necessary and sufficient condition is that $\beta=\alpha\pm \pi/2$. One direction is: Define  $$ L_\alpha=\left\lbrace z:\text{Im}\left(\frac{z-c}{d}\right)=0\right\rbrace $$ where $d=\text{cis }\alpha$. Then $L_\alpha$ is the line containing $c$ in the direction of $a$. Assuming $\beta=\alpha\pm\pi/2$, define unit vectors $z_1=\text{cis }\alpha$ and $z_2=\text{cis }\beta$. If we were to add $a$ to each of these, then $z_1\in L_\alpha$ and $z_2\in L_\beta$. So, it suffices to show that $z_1$ and $z_2$ are perpendicular when considered as vectors in $\mathbb{R}^2$. Since $z_1=(\cos\alpha,\sin\alpha)$ and $z_2=(\cos\beta,\sin\beta)$, then $$z_1\cdot z_2=\cos\alpha\cos\beta+\sin\alpha\sin\beta=\cos\alpha-\beta=\cos(\pm \pi/2)=0.$$ My questions are: Is this enough to show one direction, or would I have to show something more to show that $L_\beta$ is tangent to $C$ at $a$? Or maybe I've missed the mark completely? How would I begin the other direction? Should I use the definition of ""tangent to $C$ at $a$"" that says $L_\beta$ contains only the point $a$ in the circle $C$? Or something else?",,['complex-analysis']
7,understanding holomorphic Functions,understanding holomorphic Functions,,I'm a bit unsure about how to know when a function is holomorphic or not for example: $$ f(z)= 2Re(z)-iz^2 $$ for what values of z is f holomorphic,I'm a bit unsure about how to know when a function is holomorphic or not for example: $$ f(z)= 2Re(z)-iz^2 $$ for what values of z is f holomorphic,,"['complex-analysis', 'holomorphic-functions']"
8,Continued fractions: convergence of fraction expansion,Continued fractions: convergence of fraction expansion,,"Using the notation $[a_0,a_1,a_2,...]$ for the continued fraction $$  a_0 + \dfrac{1}{a_1 + \dfrac{1}{a_2 + \dfrac{1}{...}}} $$ where $a_0 ∈ \mathbb Z$ and $a_i ∈ \mathbb N$ for all $i>0$ Question: Consider the continued fraction expansion $$ [1,0,1,1,2,1,1,4,1,1,6,1,...,1,2n,1,...] $$ and let $p_i$ and $q_i$ denote the numerators and denominators (respectively) of its convergents. Prove that $$ p_{3n} = p_{3n-1} + p_{3n-2},  q_{3n} = q_{3n-1}+q_{3n-2} $$ $$ p_{3n+1} = 2np_{3n} + p_{3n−1},  q_{3n+1} = 2nq_{3n} +q_{3n−1} $$ $$ p_{3n+2} = p_{3n+1} + p_{3n},  q_{3n+2} = q_{3n+1} +q_{3n} $$ for $n=1,2,....$ As I understand it, the numerators are $[1,0,1,1,2,1,1,4,1,1,6,1,...,1,2n,1,...]$ while the denominator's are $[1,1,...]$. But I do not know what exactly is meant with ""of its convergence"". I am also uncertain how to proceed with proving the above mentioned questions, but I do believe it relates to the ""fundamental recurrence formulas"" as I read a bit about in the following wikipedia article: https://en.wikipedia.org/wiki/Generalized_continued_fraction Merry Christmas and happy new year.","Using the notation $[a_0,a_1,a_2,...]$ for the continued fraction $$  a_0 + \dfrac{1}{a_1 + \dfrac{1}{a_2 + \dfrac{1}{...}}} $$ where $a_0 ∈ \mathbb Z$ and $a_i ∈ \mathbb N$ for all $i>0$ Question: Consider the continued fraction expansion $$ [1,0,1,1,2,1,1,4,1,1,6,1,...,1,2n,1,...] $$ and let $p_i$ and $q_i$ denote the numerators and denominators (respectively) of its convergents. Prove that $$ p_{3n} = p_{3n-1} + p_{3n-2},  q_{3n} = q_{3n-1}+q_{3n-2} $$ $$ p_{3n+1} = 2np_{3n} + p_{3n−1},  q_{3n+1} = 2nq_{3n} +q_{3n−1} $$ $$ p_{3n+2} = p_{3n+1} + p_{3n},  q_{3n+2} = q_{3n+1} +q_{3n} $$ for $n=1,2,....$ As I understand it, the numerators are $[1,0,1,1,2,1,1,4,1,1,6,1,...,1,2n,1,...]$ while the denominator's are $[1,1,...]$. But I do not know what exactly is meant with ""of its convergence"". I am also uncertain how to proceed with proving the above mentioned questions, but I do believe it relates to the ""fundamental recurrence formulas"" as I read a bit about in the following wikipedia article: https://en.wikipedia.org/wiki/Generalized_continued_fraction Merry Christmas and happy new year.",,"['complex-analysis', 'continued-fractions']"
9,Analytic function related,Analytic function related,,"The function  $f(z)=y+ix$ is (a) Differentiable  everywhere (b) Differentiable  no-where (c)Differentiable only when $y=x$ (d)Differentiable only at $0$ As $f(z)=y+ix$ Hence $u=y$ and $v=x$ According to C-R equation a function is analytic if $u_x=v_y$ and $u_y=-v_x$ But in this case $u_x=0,u_y=1,v_x=1,v_y=0$ Hence it does not satisfy C-R equation for any $x$ and $y$. So my answer is $b$ Please guide me whether I am correct or not?","The function  $f(z)=y+ix$ is (a) Differentiable  everywhere (b) Differentiable  no-where (c)Differentiable only when $y=x$ (d)Differentiable only at $0$ As $f(z)=y+ix$ Hence $u=y$ and $v=x$ According to C-R equation a function is analytic if $u_x=v_y$ and $u_y=-v_x$ But in this case $u_x=0,u_y=1,v_x=1,v_y=0$ Hence it does not satisfy C-R equation for any $x$ and $y$. So my answer is $b$ Please guide me whether I am correct or not?",,"['complex-analysis', 'analytic-functions']"
10,Evaluate $P.V. \int^{\infty}_{0} \frac{x^\alpha }{x(x+1)} dx $ where $0 < \alpha <1$ [duplicate],Evaluate  where  [duplicate],P.V. \int^{\infty}_{0} \frac{x^\alpha }{x(x+1)} dx  0 < \alpha <1,"This question already has answers here : Closed form for $ \int_0^\infty {\frac{{{x^n}}}{{1 + {x^m}}}dx }$ (11 answers) Closed 7 years ago . Evaluate $$P.V. \int^{\infty}_{0} \frac{x^\alpha }{x(x+1)} dx   $$ where $0 < \alpha <1$ Thm Let $P$ and $Q$ be polynomials of degree $m$ and $n$,respectively, where $n \geq m+2$. If $Q(x)\neq 0$. for $Q$ has a zero of order at most 1 at the origin and $f(z)= \frac{z^\alpha P(z)}{Q(z)}$, where $0 < \alpha <1$ then  $$P.V, \int^{\infty}_0 \frac{x^ \alpha  P(x)}{Q(x)} dx= \frac{2 \pi i}{1- e^{i \alpha 2 \pi }}  \sum^{k}_{j=1} Res [f,z_j] $$ where $z_1,z_2 ,\dots , z_k$ are the nonzero poles of $\frac{P}{Q}$ Attempt Got that $P(x)=1$ where its degree $m=1$ and $q(x)=x(x+1)$ its degree is $n=1$ so it is not the case that $n \geq  m+2$ because $2 \geq 1+2$","This question already has answers here : Closed form for $ \int_0^\infty {\frac{{{x^n}}}{{1 + {x^m}}}dx }$ (11 answers) Closed 7 years ago . Evaluate $$P.V. \int^{\infty}_{0} \frac{x^\alpha }{x(x+1)} dx   $$ where $0 < \alpha <1$ Thm Let $P$ and $Q$ be polynomials of degree $m$ and $n$,respectively, where $n \geq m+2$. If $Q(x)\neq 0$. for $Q$ has a zero of order at most 1 at the origin and $f(z)= \frac{z^\alpha P(z)}{Q(z)}$, where $0 < \alpha <1$ then  $$P.V, \int^{\infty}_0 \frac{x^ \alpha  P(x)}{Q(x)} dx= \frac{2 \pi i}{1- e^{i \alpha 2 \pi }}  \sum^{k}_{j=1} Res [f,z_j] $$ where $z_1,z_2 ,\dots , z_k$ are the nonzero poles of $\frac{P}{Q}$ Attempt Got that $P(x)=1$ where its degree $m=1$ and $q(x)=x(x+1)$ its degree is $n=1$ so it is not the case that $n \geq  m+2$ because $2 \geq 1+2$",,['complex-analysis']
11,Explicit relationship between the complex derivative and the Jacobian of the corresponding 2d real function?,Explicit relationship between the complex derivative and the Jacobian of the corresponding 2d real function?,,"As complex numbers can be represented in the complex plane $\mathbb{C} \cong \mathbb{R}^2$ there are two related notions of derivatives. For a real 2d function with continuous partial derivatives  $ f:\left(   \begin{array}{c}     x \\     y \\   \end{array} \right)  \mapsto \left(   \begin{array}{c}     u \\     v \\   \end{array} \right)  $ the derivative at a point $z_0 = \left(   \begin{array}{c}     x_0 \\     y_0 \\   \end{array} \right) $ is defined as $$ \lim_{h \to 0}\frac{\|f(z_0+h)-f(z_0)-Df(z_0)h \|}{\|h\|} = 0 $$ where $Df$ is the Jacobian $\left(   \begin{array}{cc}     u_x & u_y \\     v_x & v_y \\   \end{array}\right)$ and has due to the Cauchy-Riemann equations the structure  $\left(   \begin{array}{cc}     a & b \\     -b & a \\   \end{array}\right)$ For a complex differentiable function $f(x,y) = u(x,y) + iv(x,y)$ the complex derivative is defined as $$ \lim_{h \to 0}\frac{|f(z_0+h)-f(z_0)-f'(z_0)h |}{|h|}   = \lim_{h \to 0}\left|\frac{f(z_0+h)-f(z_0)}{h} -f'(z_0)\right| = 0 $$ where now $f'(z_0)\in \mathbb{C}$. Comparing the two we have $$ Df(z_0)h \cong f'(z_0)h = f'(z_0)(h_1 + ih_2) $$ On the right hand side, the complex derivative $f'(z_0)$ is just a complex number multiplying $h=h_1 + ih_2$. How can $f'(z_0)$ explicitely be calculated from the partial derivatives that appear in the Jacobian of the corresponding 2d function? From the structure of the Jacobian and interpreting it as the matrix representation of a complex number, my first guess would be that $$ f'(x_0) = a + ib = u_x(x_0) + iu_x(x_0) = v_y(x_0) - iv_x(x_0) $$","As complex numbers can be represented in the complex plane $\mathbb{C} \cong \mathbb{R}^2$ there are two related notions of derivatives. For a real 2d function with continuous partial derivatives  $ f:\left(   \begin{array}{c}     x \\     y \\   \end{array} \right)  \mapsto \left(   \begin{array}{c}     u \\     v \\   \end{array} \right)  $ the derivative at a point $z_0 = \left(   \begin{array}{c}     x_0 \\     y_0 \\   \end{array} \right) $ is defined as $$ \lim_{h \to 0}\frac{\|f(z_0+h)-f(z_0)-Df(z_0)h \|}{\|h\|} = 0 $$ where $Df$ is the Jacobian $\left(   \begin{array}{cc}     u_x & u_y \\     v_x & v_y \\   \end{array}\right)$ and has due to the Cauchy-Riemann equations the structure  $\left(   \begin{array}{cc}     a & b \\     -b & a \\   \end{array}\right)$ For a complex differentiable function $f(x,y) = u(x,y) + iv(x,y)$ the complex derivative is defined as $$ \lim_{h \to 0}\frac{|f(z_0+h)-f(z_0)-f'(z_0)h |}{|h|}   = \lim_{h \to 0}\left|\frac{f(z_0+h)-f(z_0)}{h} -f'(z_0)\right| = 0 $$ where now $f'(z_0)\in \mathbb{C}$. Comparing the two we have $$ Df(z_0)h \cong f'(z_0)h = f'(z_0)(h_1 + ih_2) $$ On the right hand side, the complex derivative $f'(z_0)$ is just a complex number multiplying $h=h_1 + ih_2$. How can $f'(z_0)$ explicitely be calculated from the partial derivatives that appear in the Jacobian of the corresponding 2d function? From the structure of the Jacobian and interpreting it as the matrix representation of a complex number, my first guess would be that $$ f'(x_0) = a + ib = u_x(x_0) + iu_x(x_0) = v_y(x_0) - iv_x(x_0) $$",,['complex-analysis']
12,Value of the integral $\int_0^{2\pi} \log|re^{it}-\zeta| dt$,Value of the integral,\int_0^{2\pi} \log|re^{it}-\zeta| dt,"I am trying to evaluate the integral $$ \frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}-\zeta| dt$$ for $\zeta\in\mathbb{C}$. My approach so far has been to first assume $r\leq\zeta$, since this implies the integrand is the real part of a holomorphic branch of the logarithm, hence harmonic, which gives $$ \frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}-\zeta| dt = \log|\zeta| $$ For the case $r > \zeta$ I would like to conclude $$\frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}-\zeta| dt = \frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}| dt = \log r $$ but I don't quite see why the first equality in this equation should be true. Any help and hints are appreciated! :)","I am trying to evaluate the integral $$ \frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}-\zeta| dt$$ for $\zeta\in\mathbb{C}$. My approach so far has been to first assume $r\leq\zeta$, since this implies the integrand is the real part of a holomorphic branch of the logarithm, hence harmonic, which gives $$ \frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}-\zeta| dt = \log|\zeta| $$ For the case $r > \zeta$ I would like to conclude $$\frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}-\zeta| dt = \frac{1}{2\pi}\int_0^{2\pi} \log|re^{it}| dt = \log r $$ but I don't quite see why the first equality in this equation should be true. Any help and hints are appreciated! :)",,"['integration', 'complex-analysis', 'logarithms']"
13,Spectral decomposition of $L^2(\Gamma \setminus \mathbb{H})$,Spectral decomposition of,L^2(\Gamma \setminus \mathbb{H}),"Let $\Gamma \leq SL(2,\mathbb{R})$ be a discrete subgoup such that the quotient $\Gamma \setminus \mathbb{H}$ is compact (i.e. $\Gamma$ has a compact fundamental domain in the upper half plane $\mathbb{H} \subset \mathbb{C})$. My question concerns the spectral decomposition of the hyperbolic Laplacian  $$\Delta=-y^2(\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2})$$ viewed as an operator in the Hilbert space $L^2=L^2(\Gamma \setminus \mathbb{H})$. I am studying some lecture notes about this topic and I found there a theorem which is confusing to me: $\textbf{Theorem.}$ If $\Gamma \setminus \mathbb{H}$ is compact, then there exists an orthonormal basis of $L^2$ consisting of eigenfunctions of $\Delta$. My problem is that $\Delta$ seems not to be defined on the whole space $L^2$ but only for functions in $L^2$ which are at least $C^2$. My question is whether it is a nontrivial part of the theorem that $L^2 \subset C^2$ or whether the formulation of the theorem is just a bit unprecise. (A more precise formulation I have in mind might be something like this: ... there exists a dense subspace of $L^2$ which has an orthonormal basis consisting of $\Delta$-eigenfunctions. I am not sure about a possible candidate for the dense subspace, but some other references I found on the web suggest it might be the space  $$\{f \in C^{\infty}(\Gamma \setminus \mathbb{H}):f\text{ bounded and }\Delta f\text{ bounded}\}$$  where ""bounded"" probably means ""bounded w.r.t. the $L^2$-norm"".) Any help is appreciated.","Let $\Gamma \leq SL(2,\mathbb{R})$ be a discrete subgoup such that the quotient $\Gamma \setminus \mathbb{H}$ is compact (i.e. $\Gamma$ has a compact fundamental domain in the upper half plane $\mathbb{H} \subset \mathbb{C})$. My question concerns the spectral decomposition of the hyperbolic Laplacian  $$\Delta=-y^2(\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2})$$ viewed as an operator in the Hilbert space $L^2=L^2(\Gamma \setminus \mathbb{H})$. I am studying some lecture notes about this topic and I found there a theorem which is confusing to me: $\textbf{Theorem.}$ If $\Gamma \setminus \mathbb{H}$ is compact, then there exists an orthonormal basis of $L^2$ consisting of eigenfunctions of $\Delta$. My problem is that $\Delta$ seems not to be defined on the whole space $L^2$ but only for functions in $L^2$ which are at least $C^2$. My question is whether it is a nontrivial part of the theorem that $L^2 \subset C^2$ or whether the formulation of the theorem is just a bit unprecise. (A more precise formulation I have in mind might be something like this: ... there exists a dense subspace of $L^2$ which has an orthonormal basis consisting of $\Delta$-eigenfunctions. I am not sure about a possible candidate for the dense subspace, but some other references I found on the web suggest it might be the space  $$\{f \in C^{\infty}(\Gamma \setminus \mathbb{H}):f\text{ bounded and }\Delta f\text{ bounded}\}$$  where ""bounded"" probably means ""bounded w.r.t. the $L^2$-norm"".) Any help is appreciated.",,"['complex-analysis', 'spectral-theory', 'hyperbolic-geometry', 'laplacian', 'automorphic-forms']"
14,Is logarithm the only analytic function such that Re[f(z)]=Re[f(|z|)]?,Is logarithm the only analytic function such that Re[f(z)]=Re[f(|z|)]?,,Complex logarithm has an amazing property: its real part is rotationally invariant in the complex plane: $$\Re\ln z=\Re\ln|z|.$$ But even squaring $\ln$ leads to a non-symmetric real part. So I wonder: is logarithm the only nonconstant analytic function with such property?,Complex logarithm has an amazing property: its real part is rotationally invariant in the complex plane: $$\Re\ln z=\Re\ln|z|.$$ But even squaring $\ln$ leads to a non-symmetric real part. So I wonder: is logarithm the only nonconstant analytic function with such property?,,['complex-analysis']
15,Show that the function $f(z)=\exp\left(\frac{z}{1-\cos z}\right)$ has essential singularity at $z=0$,Show that the function  has essential singularity at,f(z)=\exp\left(\frac{z}{1-\cos z}\right) z=0,At $z=0$ show that the function $f(z)=\exp (\dfrac{z}{1-\cos z})$ has essential singularity. I want to show that the limit does not exist at $z=0$. Put $z=x\to 0$ $\lim_{x\to 0}\exp(\dfrac{x}{1-\cos x})$. Let $y=\exp(\dfrac{x}{1-\cos x})\implies \ln y=\dfrac{x}{1-\cos x}$. Now $\dfrac{x}{1-\cos x}=(0/0)$.so we have $\dfrac{1}{\sin x}\to \infty as x\to 0.$ Hence $y=e^\infty \to \infty$ Put $z=ix\to 0$; $\exp(\dfrac{ix}{1-\cos ix})=\exp(\dfrac{ix}{1-{\dfrac{e^{ix}+e^{-ix}}{2}}})$. I think the above limit tends to $\infty $ as $x\to 0$. I am unable to prove the limit does not exist.,At $z=0$ show that the function $f(z)=\exp (\dfrac{z}{1-\cos z})$ has essential singularity. I want to show that the limit does not exist at $z=0$. Put $z=x\to 0$ $\lim_{x\to 0}\exp(\dfrac{x}{1-\cos x})$. Let $y=\exp(\dfrac{x}{1-\cos x})\implies \ln y=\dfrac{x}{1-\cos x}$. Now $\dfrac{x}{1-\cos x}=(0/0)$.so we have $\dfrac{1}{\sin x}\to \infty as x\to 0.$ Hence $y=e^\infty \to \infty$ Put $z=ix\to 0$; $\exp(\dfrac{ix}{1-\cos ix})=\exp(\dfrac{ix}{1-{\dfrac{e^{ix}+e^{-ix}}{2}}})$. I think the above limit tends to $\infty $ as $x\to 0$. I am unable to prove the limit does not exist.,,"['complex-analysis', 'proof-verification', 'singularity']"
16,how to show that $e^{\pi z}-1 = \pi z e^{\frac{\pi z}{2}}\prod_1^{\infty}(1+\frac{z^2}{4n^2})$?,how to show that ?,e^{\pi z}-1 = \pi z e^{\frac{\pi z}{2}}\prod_1^{\infty}(1+\frac{z^2}{4n^2}),"how to show that $e^{\pi z}-1 = \pi z e^{\frac{\pi z}{2}}\prod_1^{\infty}(1+\frac{z^2}{4n^2})$? I would want to show that $F := \frac{e^{\pi z}-1}{\pi z e^{\frac{\pi z}{2}}}= \prod_1^{\infty}(1+\frac{z^2}{4n^2}) : = G$. Then I want to show that $\frac{F'}{F}= \frac{G'}{G}$, but I do not have any information on $\frac{G'}{G}$","how to show that $e^{\pi z}-1 = \pi z e^{\frac{\pi z}{2}}\prod_1^{\infty}(1+\frac{z^2}{4n^2})$? I would want to show that $F := \frac{e^{\pi z}-1}{\pi z e^{\frac{\pi z}{2}}}= \prod_1^{\infty}(1+\frac{z^2}{4n^2}) : = G$. Then I want to show that $\frac{F'}{F}= \frac{G'}{G}$, but I do not have any information on $\frac{G'}{G}$",,['complex-analysis']
17,Finding the largest possible value of $|f(2)|$ and |f'(1)|?,Finding the largest possible value of  and |f'(1)|?,|f(2)|,"Hi I was doing the following problem: Let $f$ be analytic in the right half plane $\{z\in\mathbb{C}:\text{Re}(z)>0\}$ with $|f(z)|<1$ for all $z$. If $f(1)=0$, (a) What is he largest value of $|f(2)|$? (b) What is the largest possible value of $|f'(1)|$? I got so far the following The transformation $T(z)=\frac{z-1}{z+1}$ maps $P=\{z\in\mathbb{C}:\text{Re}(z)>0\}$ to unit disk and hence $f\circ T^{-1}$ maps the unit disk to itself and $$f\circ T^{-1}(0)=f(T^{-1}(0))=f(1)=0$$ Therefore Schwarz lemma can be applied and by Schwarz lemma we have $|f\circ T^{-1}(z)|\le|z|$ Then $$|f(2)|=|f\circ T^{-1}\circ T(2)|=\Bigl|\:f\circ T^{-1}\Big(\frac{1}{3}\Big)\Bigr|\le\frac{1}{3}$$ Hence the largest possible value will be $\frac{1}{3}$ But I couldn't do part (b). Anyone can help me with that. Any help would be highly appreciated. Thanks in advance.","Hi I was doing the following problem: Let $f$ be analytic in the right half plane $\{z\in\mathbb{C}:\text{Re}(z)>0\}$ with $|f(z)|<1$ for all $z$. If $f(1)=0$, (a) What is he largest value of $|f(2)|$? (b) What is the largest possible value of $|f'(1)|$? I got so far the following The transformation $T(z)=\frac{z-1}{z+1}$ maps $P=\{z\in\mathbb{C}:\text{Re}(z)>0\}$ to unit disk and hence $f\circ T^{-1}$ maps the unit disk to itself and $$f\circ T^{-1}(0)=f(T^{-1}(0))=f(1)=0$$ Therefore Schwarz lemma can be applied and by Schwarz lemma we have $|f\circ T^{-1}(z)|\le|z|$ Then $$|f(2)|=|f\circ T^{-1}\circ T(2)|=\Bigl|\:f\circ T^{-1}\Big(\frac{1}{3}\Big)\Bigr|\le\frac{1}{3}$$ Hence the largest possible value will be $\frac{1}{3}$ But I couldn't do part (b). Anyone can help me with that. Any help would be highly appreciated. Thanks in advance.",,['complex-analysis']
18,Proof of Ramanujan doubly exponential series identity,Proof of Ramanujan doubly exponential series identity,,"Apologies if this has been asked here already. On page 7 of this paper the following formula due to Ramanujan is presented: $$\alpha \sum_{k=0}^\infty e^{-n e^{k\alpha}}=\alpha\left(\frac{1}{2}+\sum_{k=1}^\infty\frac{(-1)^{k-1}n^k}{k!(e^{k\alpha}-1)}\right)-\gamma-\ln{n}+2\sum_{k=1}^\infty\varphi(k\beta)$$ where: $$\varphi(\beta)=\frac{1}{\beta}\Im\left(n^{-i\beta}\Gamma(i\beta+1)\right)$$ and $\alpha, n>0$ , for any $\beta>0$ such that $\alpha\beta=2\pi$ . No proof is presented there although it is mentioned that Poisson's formula can be used, with the note that the proof is 'intricate' (although it seems to imply that Ramanujan used properties of the theta function to prove it). The theorem is also mentioned in this answer , which mentions that the proof can be found here , but like the author of that answer I do not have access to this paper. I have tried to prove this myself, but I have not had luck using the Poisson summation formula directly since I do not know how to find the Fourier transform of $e^{a e^{bt}}$ (although using functions like $e^{t}e^{-e^t}$ I was able to formally find some vaguely similar summation identities involving imaginary parts of gamma functions ). I was wondering whether anyone knows how to prove this formula?","Apologies if this has been asked here already. On page 7 of this paper the following formula due to Ramanujan is presented: where: and , for any such that . No proof is presented there although it is mentioned that Poisson's formula can be used, with the note that the proof is 'intricate' (although it seems to imply that Ramanujan used properties of the theta function to prove it). The theorem is also mentioned in this answer , which mentions that the proof can be found here , but like the author of that answer I do not have access to this paper. I have tried to prove this myself, but I have not had luck using the Poisson summation formula directly since I do not know how to find the Fourier transform of (although using functions like I was able to formally find some vaguely similar summation identities involving imaginary parts of gamma functions ). I was wondering whether anyone knows how to prove this formula?","\alpha \sum_{k=0}^\infty e^{-n e^{k\alpha}}=\alpha\left(\frac{1}{2}+\sum_{k=1}^\infty\frac{(-1)^{k-1}n^k}{k!(e^{k\alpha}-1)}\right)-\gamma-\ln{n}+2\sum_{k=1}^\infty\varphi(k\beta) \varphi(\beta)=\frac{1}{\beta}\Im\left(n^{-i\beta}\Gamma(i\beta+1)\right) \alpha, n>0 \beta>0 \alpha\beta=2\pi e^{a e^{bt}} e^{t}e^{-e^t}","['sequences-and-series', 'complex-analysis', 'gamma-function', 'fourier-transform']"
19,How to choose contour for computing this particular real integral?,How to choose contour for computing this particular real integral?,,"I am trying to solve a exercise from my Complex Analysis book. The exercise says: Show that $\displaystyle\int_0^\infty \frac {\cos(x)}{x^a} \, dx=\Gamma(1-a) \sin \left(\frac{\pi a} 2 \right)$ where $0<a<1.$ I am having trouble in choosing proper contour for this integral. Could someone please explain me how should i choose contour for computing the same integral?","I am trying to solve a exercise from my Complex Analysis book. The exercise says: Show that $\displaystyle\int_0^\infty \frac {\cos(x)}{x^a} \, dx=\Gamma(1-a) \sin \left(\frac{\pi a} 2 \right)$ where $0<a<1.$ I am having trouble in choosing proper contour for this integral. Could someone please explain me how should i choose contour for computing the same integral?",,"['integration', 'complex-analysis', 'improper-integrals']"
20,Proof of continuously differentiable curve arc length,Proof of continuously differentiable curve arc length,,"I was reading Terence Tao's lecture on complex analysis .  This is a question regarding his ""continuity"" solution to the proposition: My question is: Why is $\Omega_{\varepsilon}$ closed? I have quoted the part of the proof. The (7) referred to is as follows.","I was reading Terence Tao's lecture on complex analysis .  This is a question regarding his ""continuity"" solution to the proposition: My question is: Why is $\Omega_{\varepsilon}$ closed? I have quoted the part of the proof. The (7) referred to is as follows.",,"['complex-analysis', 'proof-explanation', 'alternative-proof', 'curves', 'arc-length']"
21,"Polya's theorem on polynomials, ""Proofs from THE BOOK""""","Polya's theorem on polynomials, ""Proofs from THE BOOK""""",,"I have a small question about the proof of the following statement by Pólya from ""Proofs from THE BOOK, Springer 2014"" Let $$f(z) = z^n + b_{n-1}z^{n-1} + \cdots + b_0$$ be a complex polynomial, degree $n\geq 1$, leading coefficient $1$. Associate with $f(z)$ the set $$\mathcal{C} := \{ z\in \mathbb{C}: |f(z)| \leq 2 \}$$ Take any line $L$ in the complex plane and consider the orthogonal projection $\mathcal{C}_L$ of the set $\mathcal{C}$ onto $L$. Then the total length of any such projection never exceeds $4$. The proof says that we can take $L$ as the real axis of the complex plane, by rotation and translation of the plane. My professor wants that I show that the resulting (after the rotation / translation) $\mathcal{C}'$ is again of the form $\{z \in \mathbb{C} : |g(z)| \leq 2\}$ for some complex polynomial $g$ with degree $n\geq 1$ and leading coefficient $1$, in this way we can wlog assume that $L=$ real axis, $\mathcal{C}_L = \mathcal{R} = \{ x \in \mathbb{R} : x + iy \in \mathcal{C'}\text{ for some }y\in\mathbb{R} \}$, and continue the proof using another theorem: Theorem : Let $f(z)$ be a complex polynomial of degree $n\geq 1$, and leading coefficient $1$. Set $\mathcal{C}$ as above and let $\mathcal{R}$ be the orthogonal projection of $\mathcal{C}$ onto the real axis. Then there are intervals $I_1,\cdots,I_t$ on the real line which together cover $\mathcal{R}$ and satisfy $l(I_1) + \cdots + l(I_t)\leq 4$ How can I show this? Which form has it?","I have a small question about the proof of the following statement by Pólya from ""Proofs from THE BOOK, Springer 2014"" Let $$f(z) = z^n + b_{n-1}z^{n-1} + \cdots + b_0$$ be a complex polynomial, degree $n\geq 1$, leading coefficient $1$. Associate with $f(z)$ the set $$\mathcal{C} := \{ z\in \mathbb{C}: |f(z)| \leq 2 \}$$ Take any line $L$ in the complex plane and consider the orthogonal projection $\mathcal{C}_L$ of the set $\mathcal{C}$ onto $L$. Then the total length of any such projection never exceeds $4$. The proof says that we can take $L$ as the real axis of the complex plane, by rotation and translation of the plane. My professor wants that I show that the resulting (after the rotation / translation) $\mathcal{C}'$ is again of the form $\{z \in \mathbb{C} : |g(z)| \leq 2\}$ for some complex polynomial $g$ with degree $n\geq 1$ and leading coefficient $1$, in this way we can wlog assume that $L=$ real axis, $\mathcal{C}_L = \mathcal{R} = \{ x \in \mathbb{R} : x + iy \in \mathcal{C'}\text{ for some }y\in\mathbb{R} \}$, and continue the proof using another theorem: Theorem : Let $f(z)$ be a complex polynomial of degree $n\geq 1$, and leading coefficient $1$. Set $\mathcal{C}$ as above and let $\mathcal{R}$ be the orthogonal projection of $\mathcal{C}$ onto the real axis. Then there are intervals $I_1,\cdots,I_t$ on the real line which together cover $\mathcal{R}$ and satisfy $l(I_1) + \cdots + l(I_t)\leq 4$ How can I show this? Which form has it?",,"['complex-analysis', 'polynomials']"
22,Complex number (cube roots of unity),Complex number (cube roots of unity),,"If $w$ and $w^2$ are non real cube roots of unity, then what would be the value of $\frac{2015+2016w+2017w^2}{2017+2015w+2016w^2}$+$\frac{2015+2016w+2017w^2}{2016+2017w+2015w^2}$ All I know is --> $1+w+w^2=0$ and $w^3=1$ Any tips and suggestions regarding how to solve these kinds of problems would be great.","If $w$ and $w^2$ are non real cube roots of unity, then what would be the value of $\frac{2015+2016w+2017w^2}{2017+2015w+2016w^2}$+$\frac{2015+2016w+2017w^2}{2016+2017w+2015w^2}$ All I know is --> $1+w+w^2=0$ and $w^3=1$ Any tips and suggestions regarding how to solve these kinds of problems would be great.",,"['complex-analysis', 'complex-numbers']"
23,Entire function and injectivity [duplicate],Entire function and injectivity [duplicate],,"This question already has answers here : Proving that all entire and injective functions take the form $f = ax + b$? (3 answers) Closed 7 years ago . So if $f(z)=az+b$, is an entire injective map from $\Bbb C$ to $\Bbb C$, for both a and b are complex numbers and a is not equal to 0. I've proved that if f is an injective entire function, it cannot have an essential singularity at infinity, but then how to show that $f(z)$ has to be a polynomial? And why $f(z)$ has to satisfy that $f(z)=az+b$?","This question already has answers here : Proving that all entire and injective functions take the form $f = ax + b$? (3 answers) Closed 7 years ago . So if $f(z)=az+b$, is an entire injective map from $\Bbb C$ to $\Bbb C$, for both a and b are complex numbers and a is not equal to 0. I've proved that if f is an injective entire function, it cannot have an essential singularity at infinity, but then how to show that $f(z)$ has to be a polynomial? And why $f(z)$ has to satisfy that $f(z)=az+b$?",,"['complex-analysis', 'polynomials', 'laurent-series', 'entire-functions']"
24,Theorem 3.55 in Baby Rudin: How to make sense of the proof?,Theorem 3.55 in Baby Rudin: How to make sense of the proof?,,"Here's Theorem 3.55 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition. If $\sum a_n$ is a series of complex numbers which converges absolutely, then every rearrangement of $\sum a_n$ converges, and they all converge to the same sum. Now here's Rudin's proof. Let $\sum a_n^\prime$ be a rearrangement, with partial sums $s_n^\prime$. Given $\varepsilon > 0$, there exists an integer $N$ such that $m \geq n \geq N$ implies $$ \sum_{i =n}^m \left\vert a_i \right\vert \leq \varepsilon.$$ [This relation Rudin calls (26). ] Now choose $p$ such that the integers $1, 2, \ldots, N$ are all contained in the set $k_1, k_2, \ldots, k_p$ (we use the notation of Definition 3.52). Then if $n > p$, the numbers $a_1, \ldots, a_N$ will cancel in the difference $s_n - s_n^\prime$, so that $\left\vert s_n - s_n^\prime \right\vert \leq \varepsilon$, by (26). Hence $\left\{ s_n^\prime \right\}$ converges to the same sum as $\left\{ s_n \right\}$. And, finally, here's Rudin's Definition 3.52. Let $\left\{ k_n \right\}$, $n = 1, 2, 3, \ldots$, be a sequence in which every positive integer appears once and only once (that is, $\left\{ k_n \right\}$ is a 1-1 function from $J$ onto $J$, in the notation of Definition 2.2). Putting $$ a_n^\prime = a_n \ \ \ (n= 1, 2, 3, \ldots),$$    we say that $\sum a_n^\prime$ is a rearrangement of $\sum a_n$. And, for the sake of completeness, Rudin uses the symbol $J$ to denote the set of natural numbers. Now my question is, how does Rudin's relation (26) give the conclusion that $\left\vert s_n - s_n^\prime \right\vert \leq \varepsilon$ if $n > p$? Here's how I have been able to understand the proof. Given that $\sum \left\vert a_n \right\vert$ converges, we can conclude that $\sum a_n$ converges too. Let    $$s = \sum_{n =1 }^\infty a_n.$$   Let $s_n$, $(n = 1, 2, 3, \ldots)$, be the partial sums of $\sum a_n$. Then $$s = \lim_{n \to \infty} s_n.$$   Now let $\sum a_n^\prime$ be a rearrangement of $\sum a_n$, and let $s_n^\prime$, $(n = 1, 2, 3, \ldots)$, be the partial sums of $\sum a_n^\prime$. We show that $$\lim_{n \to \infty} s_n^\prime = s$$ as well. Now as $s_n \to s$ as $n \to \infty$, so, given $\varepsilon > 0$, we can find a natural number $N_1$ such that $$ \left\vert s_n - s \right\vert < \frac{\varepsilon}{2}$$ for all $n \in \mathbb{N}$ such that $n > N_1$. Now as $\sum \left\vert a_n \right\vert$ converges, so we can find a natural number $N_2$ such that $$ \sum_{i =n}^m \left\vert a_i \right\vert < \frac{\varepsilon}{2}$$ for all $m, n \in \mathbb{N}$ such that $m \geq n \geq N_2$. So we can conclude that $$\left\vert \sum_{i=n}^m a_i \right\vert < \frac{\varepsilon}{2}$$ for all $m, n \in \mathbb{N}$ such that $m \geq n \geq N_2$. Now let $N = \max \left\{ N_1, N_2 \right\}$. Then, for all $m, n \in \mathbb{N}$ such that $m \geq n > N$, we have $$ \left\vert s_n - s \right\vert < \frac{\varepsilon}{2}$$ and also $$\left\vert \sum_{i=n}^m a_i \right\vert < \frac{\varepsilon}{2}.$$ Now let $p$ be a natural number such that the integers $1, 2, \ldots, N$ are all contained in the set $\left\{ k_1, \ldots, k_p \right\}$. Then, for all $n \in \mathbb{N}$ such that $n > p$, we see that the difference $s_n - s_n^\prime$ is a sum of some finitely many terms of the sequence $\left(  a_{N+1}, a_{N+2}, a_{N+3}, \ldots\right)$, and therefore $$\left\vert s_n - s_n^\prime \right\vert < \frac{\varepsilon}{2}. $$ So if $n \in \mathbb{N}$ is such that $n > \max \{ N, p \}$, then we have $$ \left\vert s_n - s_n^\prime \right\vert < \frac{\varepsilon}{2}$$ and also $$\left\vert s_n - s \right\vert < \frac{\varepsilon}{2}.$$ Therefore, for all $n \in \mathbb{N}$ such that $n > \max \{ N, p \}$, we have    $$ \left\vert s_n^\prime - s \right\vert \leq \left\vert s_n^\prime - s_n \right\vert + \left\vert s_n - s \right\vert < \varepsilon,$$ from which it follows that $$ \lim_{n \to \infty} s_n^\prime = s$$ also. Is my understanding of the proof of Theorem 3.55 in Baby Rudin correct? If so, then is my version the same as Rudin's? If not, where have I erred? And, if my proof is also correct but differs from Rudin's, can anybody here please fill in the details in Rudin's original proof for me? Thanks.","Here's Theorem 3.55 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition. If $\sum a_n$ is a series of complex numbers which converges absolutely, then every rearrangement of $\sum a_n$ converges, and they all converge to the same sum. Now here's Rudin's proof. Let $\sum a_n^\prime$ be a rearrangement, with partial sums $s_n^\prime$. Given $\varepsilon > 0$, there exists an integer $N$ such that $m \geq n \geq N$ implies $$ \sum_{i =n}^m \left\vert a_i \right\vert \leq \varepsilon.$$ [This relation Rudin calls (26). ] Now choose $p$ such that the integers $1, 2, \ldots, N$ are all contained in the set $k_1, k_2, \ldots, k_p$ (we use the notation of Definition 3.52). Then if $n > p$, the numbers $a_1, \ldots, a_N$ will cancel in the difference $s_n - s_n^\prime$, so that $\left\vert s_n - s_n^\prime \right\vert \leq \varepsilon$, by (26). Hence $\left\{ s_n^\prime \right\}$ converges to the same sum as $\left\{ s_n \right\}$. And, finally, here's Rudin's Definition 3.52. Let $\left\{ k_n \right\}$, $n = 1, 2, 3, \ldots$, be a sequence in which every positive integer appears once and only once (that is, $\left\{ k_n \right\}$ is a 1-1 function from $J$ onto $J$, in the notation of Definition 2.2). Putting $$ a_n^\prime = a_n \ \ \ (n= 1, 2, 3, \ldots),$$    we say that $\sum a_n^\prime$ is a rearrangement of $\sum a_n$. And, for the sake of completeness, Rudin uses the symbol $J$ to denote the set of natural numbers. Now my question is, how does Rudin's relation (26) give the conclusion that $\left\vert s_n - s_n^\prime \right\vert \leq \varepsilon$ if $n > p$? Here's how I have been able to understand the proof. Given that $\sum \left\vert a_n \right\vert$ converges, we can conclude that $\sum a_n$ converges too. Let    $$s = \sum_{n =1 }^\infty a_n.$$   Let $s_n$, $(n = 1, 2, 3, \ldots)$, be the partial sums of $\sum a_n$. Then $$s = \lim_{n \to \infty} s_n.$$   Now let $\sum a_n^\prime$ be a rearrangement of $\sum a_n$, and let $s_n^\prime$, $(n = 1, 2, 3, \ldots)$, be the partial sums of $\sum a_n^\prime$. We show that $$\lim_{n \to \infty} s_n^\prime = s$$ as well. Now as $s_n \to s$ as $n \to \infty$, so, given $\varepsilon > 0$, we can find a natural number $N_1$ such that $$ \left\vert s_n - s \right\vert < \frac{\varepsilon}{2}$$ for all $n \in \mathbb{N}$ such that $n > N_1$. Now as $\sum \left\vert a_n \right\vert$ converges, so we can find a natural number $N_2$ such that $$ \sum_{i =n}^m \left\vert a_i \right\vert < \frac{\varepsilon}{2}$$ for all $m, n \in \mathbb{N}$ such that $m \geq n \geq N_2$. So we can conclude that $$\left\vert \sum_{i=n}^m a_i \right\vert < \frac{\varepsilon}{2}$$ for all $m, n \in \mathbb{N}$ such that $m \geq n \geq N_2$. Now let $N = \max \left\{ N_1, N_2 \right\}$. Then, for all $m, n \in \mathbb{N}$ such that $m \geq n > N$, we have $$ \left\vert s_n - s \right\vert < \frac{\varepsilon}{2}$$ and also $$\left\vert \sum_{i=n}^m a_i \right\vert < \frac{\varepsilon}{2}.$$ Now let $p$ be a natural number such that the integers $1, 2, \ldots, N$ are all contained in the set $\left\{ k_1, \ldots, k_p \right\}$. Then, for all $n \in \mathbb{N}$ such that $n > p$, we see that the difference $s_n - s_n^\prime$ is a sum of some finitely many terms of the sequence $\left(  a_{N+1}, a_{N+2}, a_{N+3}, \ldots\right)$, and therefore $$\left\vert s_n - s_n^\prime \right\vert < \frac{\varepsilon}{2}. $$ So if $n \in \mathbb{N}$ is such that $n > \max \{ N, p \}$, then we have $$ \left\vert s_n - s_n^\prime \right\vert < \frac{\varepsilon}{2}$$ and also $$\left\vert s_n - s \right\vert < \frac{\varepsilon}{2}.$$ Therefore, for all $n \in \mathbb{N}$ such that $n > \max \{ N, p \}$, we have    $$ \left\vert s_n^\prime - s \right\vert \leq \left\vert s_n^\prime - s_n \right\vert + \left\vert s_n - s \right\vert < \varepsilon,$$ from which it follows that $$ \lim_{n \to \infty} s_n^\prime = s$$ also. Is my understanding of the proof of Theorem 3.55 in Baby Rudin correct? If so, then is my version the same as Rudin's? If not, where have I erred? And, if my proof is also correct but differs from Rudin's, can anybody here please fill in the details in Rudin's original proof for me? Thanks.",,"['sequences-and-series', 'complex-analysis', 'analysis', 'convergence-divergence', 'absolute-convergence']"
25,How to efficiently solve this question? Possibly using Max Mod Principle,How to efficiently solve this question? Possibly using Max Mod Principle,,Let $f: {\mathbb{D}} \rightarrow {\mathbb{C}}$ be holomorphic and continuous on the closed unit disk $\bar {\mathbb{D}}$. Assume that $|f(z)| \leq 1$ whenever $|z| = 1$ and $Im(z) > 0$; and $|f(z)| \leq 9$ whenever  $|z| = 1$ and $Im(z) < 0$. Show that $|f(0)| \leq 3$. Is it possible to solve this using the Max Mod Principle?,Let $f: {\mathbb{D}} \rightarrow {\mathbb{C}}$ be holomorphic and continuous on the closed unit disk $\bar {\mathbb{D}}$. Assume that $|f(z)| \leq 1$ whenever $|z| = 1$ and $Im(z) > 0$; and $|f(z)| \leq 9$ whenever  $|z| = 1$ and $Im(z) < 0$. Show that $|f(0)| \leq 3$. Is it possible to solve this using the Max Mod Principle?,,"['complex-analysis', 'maximum-principle']"
26,The series of functions in the complex plane.,The series of functions in the complex plane.,,"This is closely related to another question that I asked here regarding series of functions in the complex plane . The $\sin(z)$ series in the complex plane is represented as $z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots$. In the real line with $\sin(x)$ we have Taylor's series and and the remainder and the convergence and such things. The question I have is---- how do we get this extension with the complex plane? In the question I have referred, people suggested that it was just a definiton, and that $\sin(z)=z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots$ was defined as such. But somehow that answer seems very unconvincing. It is like being told that the $\sin(x)$ series extension in the real plane is defined as such. It seems like it may have got something to  do with $\sin(z)$ extension in the complex plane having to satisfy the $\sin(x)$ component in the real line too (because real is a subset of complex) and since the coefficients in the real line is known to be $(1,0,\frac{1}{3},0,\frac{1}{5}......)$ the coefficients in the complex series expansion also have to be the same, although I dont know whether that line of approach is correct or whether it can be proven rigorously.","This is closely related to another question that I asked here regarding series of functions in the complex plane . The $\sin(z)$ series in the complex plane is represented as $z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots$. In the real line with $\sin(x)$ we have Taylor's series and and the remainder and the convergence and such things. The question I have is---- how do we get this extension with the complex plane? In the question I have referred, people suggested that it was just a definiton, and that $\sin(z)=z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots$ was defined as such. But somehow that answer seems very unconvincing. It is like being told that the $\sin(x)$ series extension in the real plane is defined as such. It seems like it may have got something to  do with $\sin(z)$ extension in the complex plane having to satisfy the $\sin(x)$ component in the real line too (because real is a subset of complex) and since the coefficients in the real line is known to be $(1,0,\frac{1}{3},0,\frac{1}{5}......)$ the coefficients in the complex series expansion also have to be the same, although I dont know whether that line of approach is correct or whether it can be proven rigorously.",,['complex-analysis']
27,"Radius of convergence of $\sum\, (a_0+a_1 + \cdots+ a_n)z^n.$",Radius of convergence of,"\sum\, (a_0+a_1 + \cdots+ a_n)z^n.","Consider a complex power series $$s(z) = \sum_{n\geq 0} a_nz^n$$ with radius of covergence of $\rho(s)=1$. Then, consider the following power series: $$t(z) = \sum_{n\geq 0} b_nz^n $$ where $b_n = a_0 + a_1 + ....+a_n$. Prove that: $\rho(t)=1$. My approach: Consider the partial sum of the absolute values: $$ P_k = \sum_{n\geq 0}^{k} |b_0| + |b_1z| + ...+|b_kz^k| = |a_0| + |(a_0+a_1)z|+...+|(a_0 + ... + a_k)|z^k $$ It follows: $$ P_k \leq |a_0| + |a_0z| + |a_1z| + ... + |a_0z^k| +...+|a_kz^k| = |a_0|(1 + |z| +...+|z^k|) + |a_1z|(1+...+|z^{k-1}|)+....|a_kz^k| \leq |a_0|(1 + |z| +...+|z^k|) + |a_1z|(1+...+|z^{k}|)+....|a_kz^k|(1+|z|+...|z^k|) = (|a_0|+|a_1z|+...+|a_kz^k|)(1+|z|+...|z^k|) $$ From that inequality I get $\rho(t)\geq 1$. My question is: how to continue? Is my thought process and conclusion ok? since I'm working with the absolute values power series and not the actual power series. Thanks","Consider a complex power series $$s(z) = \sum_{n\geq 0} a_nz^n$$ with radius of covergence of $\rho(s)=1$. Then, consider the following power series: $$t(z) = \sum_{n\geq 0} b_nz^n $$ where $b_n = a_0 + a_1 + ....+a_n$. Prove that: $\rho(t)=1$. My approach: Consider the partial sum of the absolute values: $$ P_k = \sum_{n\geq 0}^{k} |b_0| + |b_1z| + ...+|b_kz^k| = |a_0| + |(a_0+a_1)z|+...+|(a_0 + ... + a_k)|z^k $$ It follows: $$ P_k \leq |a_0| + |a_0z| + |a_1z| + ... + |a_0z^k| +...+|a_kz^k| = |a_0|(1 + |z| +...+|z^k|) + |a_1z|(1+...+|z^{k-1}|)+....|a_kz^k| \leq |a_0|(1 + |z| +...+|z^k|) + |a_1z|(1+...+|z^{k}|)+....|a_kz^k|(1+|z|+...|z^k|) = (|a_0|+|a_1z|+...+|a_kz^k|)(1+|z|+...|z^k|) $$ From that inequality I get $\rho(t)\geq 1$. My question is: how to continue? Is my thought process and conclusion ok? since I'm working with the absolute values power series and not the actual power series. Thanks",,['complex-analysis']
28,Biholomorphic function with bounded derivative,Biholomorphic function with bounded derivative,,"Let $U$ be an open subsets of $\mathbb{C}$ and $\psi:U\rightarrow U$ a biholomorphic function (a holomorphic function with holomorphic inverse). I want to prove the following statement: For every $\epsilon >0$ there exists $\delta>0$ such that if $\frac{1}{1+\delta}<|\psi'(z)|<1+\delta$ for every $z\in U$ then $|\psi''(z)|<\epsilon$ for every $z\in U$. This means that if $\psi$ is biholomorphic and the module of its derivative is everywhere close to 1 then $\psi$ is ""almost"" the identity. I've thought about it but I wasn't able to find anything that works. Using $\psi(\psi^{-1})=Id$ I just obtained that if $\frac{1}{1+\delta}<|\psi'(z)|<1+\delta$ then also $\frac{1}{1+\delta}<|(\psi^{-1})'(z)|<1+\delta$ and that $\frac{1}{(1+\delta)^3}<|\frac{\psi''(\psi^{-1})}{(\psi^{-1})''}|<(1+\delta)^3$ but this isn't enough to conclude. Can anyone help me? Thank you very much!","Let $U$ be an open subsets of $\mathbb{C}$ and $\psi:U\rightarrow U$ a biholomorphic function (a holomorphic function with holomorphic inverse). I want to prove the following statement: For every $\epsilon >0$ there exists $\delta>0$ such that if $\frac{1}{1+\delta}<|\psi'(z)|<1+\delta$ for every $z\in U$ then $|\psi''(z)|<\epsilon$ for every $z\in U$. This means that if $\psi$ is biholomorphic and the module of its derivative is everywhere close to 1 then $\psi$ is ""almost"" the identity. I've thought about it but I wasn't able to find anything that works. Using $\psi(\psi^{-1})=Id$ I just obtained that if $\frac{1}{1+\delta}<|\psi'(z)|<1+\delta$ then also $\frac{1}{1+\delta}<|(\psi^{-1})'(z)|<1+\delta$ and that $\frac{1}{(1+\delta)^3}<|\frac{\psi''(\psi^{-1})}{(\psi^{-1})''}|<(1+\delta)^3$ but this isn't enough to conclude. Can anyone help me? Thank you very much!",,"['complex-analysis', 'analysis']"
29,Radius of convergence of product of two absolutely convergent power series,Radius of convergence of product of two absolutely convergent power series,,"I need help with finding the radius of the Cauchy product of two aboslutely convergent series. Concretely, let $\sum a_k z^k $ have radius of convergence equal to $R_1$ and $\sum b_k z^k $ have radius of convergence equal to $R_2$. Let $\sum c_k z^k$ be the Cauchy product of the two series. I am stuck trying to calculate the radius of convergence of $\sum c_k z^k$. Please could someone show me how to calculate the radius of   convergence of the Cauchy product of two absolutely convergent series? The correct result is $R = \min (R_1, R_2)$ as the exercise asks to show that the Cauchy product converges for $|z|<\min(R_1, R_2)$.","I need help with finding the radius of the Cauchy product of two aboslutely convergent series. Concretely, let $\sum a_k z^k $ have radius of convergence equal to $R_1$ and $\sum b_k z^k $ have radius of convergence equal to $R_2$. Let $\sum c_k z^k$ be the Cauchy product of the two series. I am stuck trying to calculate the radius of convergence of $\sum c_k z^k$. Please could someone show me how to calculate the radius of   convergence of the Cauchy product of two absolutely convergent series? The correct result is $R = \min (R_1, R_2)$ as the exercise asks to show that the Cauchy product converges for $|z|<\min(R_1, R_2)$.",,['complex-analysis']
30,Laurent Series From Cracking the GRE (Mistake?),Laurent Series From Cracking the GRE (Mistake?),,"The problem asks to find the Laurent series for $f(z)=\frac{1}{z-3}$ in the annulus $|z-4|>1$. I found the answer to be $\sum\limits_{n=0}^{\infty}(-1)^n(z-4)^{-n-1}$. However, the book states that the answer is $\sum\limits_{n=1}^{\infty}(-1)^n(z-4)^{-n-1}$. I think this is wrong, since the first term in the expansion should be $\frac{1}{z-4}$. Is the book wrong, or did I do something incorrect?","The problem asks to find the Laurent series for $f(z)=\frac{1}{z-3}$ in the annulus $|z-4|>1$. I found the answer to be $\sum\limits_{n=0}^{\infty}(-1)^n(z-4)^{-n-1}$. However, the book states that the answer is $\sum\limits_{n=1}^{\infty}(-1)^n(z-4)^{-n-1}$. I think this is wrong, since the first term in the expansion should be $\frac{1}{z-4}$. Is the book wrong, or did I do something incorrect?",,"['sequences-and-series', 'complex-analysis', 'laurent-series', 'gre-exam']"
31,Writing Complex Numbers as a Vector in $\mathbb{R^2}$,Writing Complex Numbers as a Vector in,\mathbb{R^2},"Generally speaking is it mathematically correct to write a complex number $z = x +  iy \in \mathbb{C}$, as a vector in $\mathbb{R}^2$? $$z=\begin{bmatrix} x\\ y \end{bmatrix} \quad \text{with } x,y \in \mathbb{R}$$ With row 1 being the $Re(z)$ and row 2 being $Im(z)$, i.e.  $$Re: \mathbb R^2 \to \mathbb R, \begin{bmatrix} x\\ y \end{bmatrix}\mapsto x \quad \text{and} \quad Im: \mathbb R^2 \to \mathbb R, \begin{bmatrix} x\\ y \end{bmatrix}\mapsto y$$","Generally speaking is it mathematically correct to write a complex number $z = x +  iy \in \mathbb{C}$, as a vector in $\mathbb{R}^2$? $$z=\begin{bmatrix} x\\ y \end{bmatrix} \quad \text{with } x,y \in \mathbb{R}$$ With row 1 being the $Re(z)$ and row 2 being $Im(z)$, i.e.  $$Re: \mathbb R^2 \to \mathbb R, \begin{bmatrix} x\\ y \end{bmatrix}\mapsto x \quad \text{and} \quad Im: \mathbb R^2 \to \mathbb R, \begin{bmatrix} x\\ y \end{bmatrix}\mapsto y$$",,"['complex-analysis', 'vector-spaces', 'complex-numbers', 'vectors', 'real-numbers']"
32,"For a sequence $\{f_j\}$ of holomorphic functions, what can we say given $\sum_{j=1}^\infty |f_j(0)|$ converges.","For a sequence  of holomorphic functions, what can we say given  converges.",\{f_j\} \sum_{j=1}^\infty |f_j(0)|,"In particular, let $\{f_j\}$ a sequence of holomorphic functions from $D(0,1)$ to $D(0,1)$ \ $\{0\}$, where $D(0,1)$ denotes the unit disk. I want to show that if $\sum_{j=1}^\infty |f_j(0)|$ converges, then $\sum_{j=1}^\infty f_j(z)^2$ converges absolutely and uniformly on compact sets in $D(0,1/3)$. I need a hint to get started. I think there may be a theorem relating to this kind of thing of which I am not aware.","In particular, let $\{f_j\}$ a sequence of holomorphic functions from $D(0,1)$ to $D(0,1)$ \ $\{0\}$, where $D(0,1)$ denotes the unit disk. I want to show that if $\sum_{j=1}^\infty |f_j(0)|$ converges, then $\sum_{j=1}^\infty f_j(z)^2$ converges absolutely and uniformly on compact sets in $D(0,1/3)$. I need a hint to get started. I think there may be a theorem relating to this kind of thing of which I am not aware.",,['complex-analysis']
33,$f$ conformal $\implies$ $f$ ACL?,conformal   ACL?,f \implies f,"In An Introduction to Teichmüller Spaces , by Imayoshi and Taniguchi, we have the following definition for an absolutely continuous function : where, I suppose, a function $g:I\to \mathbb{C}$ , $I \subset \mathbb{R}$ interval, is said to be absolutely continuous if, $\forall \epsilon>0$ , $\exists \delta>0$ such that, $$[x_k,y_k]\subset I, k\in \{1,\dots,n\}\text{ pairwise disjoint intervals with }\sum_{k=1}^n|y_k-x_k|<\delta$$ $$\implies\sum_{k=1}^n|f(y_k)-f(x_k)|<\epsilon.$$ The authors want to define quasiconformal mappings which are, in particular, ACL. The very first example given for quasiconformal mappings is, of course, the conformal ones. But while giving this example in the book, it is not shown that the conformal map is ACL (it is only discussed the other requirements, which are indeed easier to see). So my question is: $f:D\to \mathbb{C}$ conformal $\implies$ $f$ ACL? Is this due to some classical result? Thank you very much!","In An Introduction to Teichmüller Spaces , by Imayoshi and Taniguchi, we have the following definition for an absolutely continuous function : where, I suppose, a function , interval, is said to be absolutely continuous if, , such that, The authors want to define quasiconformal mappings which are, in particular, ACL. The very first example given for quasiconformal mappings is, of course, the conformal ones. But while giving this example in the book, it is not shown that the conformal map is ACL (it is only discussed the other requirements, which are indeed easier to see). So my question is: conformal ACL? Is this due to some classical result? Thank you very much!","g:I\to \mathbb{C} I \subset \mathbb{R} \forall \epsilon>0 \exists \delta>0 [x_k,y_k]\subset I, k\in \{1,\dots,n\}\text{ pairwise disjoint intervals with }\sum_{k=1}^n|y_k-x_k|<\delta \implies\sum_{k=1}^n|f(y_k)-f(x_k)|<\epsilon. f:D\to \mathbb{C} \implies f","['complex-analysis', 'conformal-geometry', 'teichmueller-theory', 'quasiconformal-maps']"
34,Prove or refute that $\{p^{1/p}\}_{p\text{ prime}}$ to be equidistributed in $\mathbb{R}/\mathbb{Z}$,Prove or refute that  to be equidistributed in,\{p^{1/p}\}_{p\text{ prime}} \mathbb{R}/\mathbb{Z},"I've tried follow the Example 3 (see minute 30'40"" of the reference), where is required the related Theorem (stated at minute 21') combined with Serre's formalism for $\mathbb{R}/\mathbb{Z}$ (also explained in the video) from a  video in YouTube , from the official channel matsciencechannel , An Introduction to Analytic Number Theory Lecture 07 Equidistribution by Ram Murty to ask myself Question. Is the sequence $\{p^{1/p}\}$, as $p$ varies over all primes, equidistributed in $\mathbb{R}/\mathbb{Z}$? I need to check if $$\frac{1}{\pi(N)}\sum_{p\leq N}e^{2\pi i m p^{1/p}}$$ tends to zero as $N\to\infty$, $\forall m\neq 0$, where we are denoting the prime-counting function by $\pi(x)$ and $p$ the sequence of prime numbers in increasing order. I take the definition following the teacher in this video of the more high quality, to do the calculation $$L(s,\psi_m)=\prod_{p}\left(1-\frac{p^{\frac{2\pi i m}{p}}}{p^s}\right)^{-1}=\zeta(s-\frac{2\pi i m}{p}).$$ Now I believe that it is required to say that one has a pole at $s=1+\frac{2\pi i m}{p}$ (notice that I believe that I have a sequence of poles, Murty's example only depends on $m$), and say that I can use the theorem to show that our sum $\rightarrow 0$ as $N\to\infty$, thus our sequence is equidistributed in the (compact) group $\mathbb{R}/\mathbb{Z}$. Can you explain if it is feasible such calculations or do it? I don't understand well if it is possible to  apply the theorem for my example, if you can state in details how one can use the theorem, then it is the best, and this example will be here as a reference. Thanks in advance.","I've tried follow the Example 3 (see minute 30'40"" of the reference), where is required the related Theorem (stated at minute 21') combined with Serre's formalism for $\mathbb{R}/\mathbb{Z}$ (also explained in the video) from a  video in YouTube , from the official channel matsciencechannel , An Introduction to Analytic Number Theory Lecture 07 Equidistribution by Ram Murty to ask myself Question. Is the sequence $\{p^{1/p}\}$, as $p$ varies over all primes, equidistributed in $\mathbb{R}/\mathbb{Z}$? I need to check if $$\frac{1}{\pi(N)}\sum_{p\leq N}e^{2\pi i m p^{1/p}}$$ tends to zero as $N\to\infty$, $\forall m\neq 0$, where we are denoting the prime-counting function by $\pi(x)$ and $p$ the sequence of prime numbers in increasing order. I take the definition following the teacher in this video of the more high quality, to do the calculation $$L(s,\psi_m)=\prod_{p}\left(1-\frac{p^{\frac{2\pi i m}{p}}}{p^s}\right)^{-1}=\zeta(s-\frac{2\pi i m}{p}).$$ Now I believe that it is required to say that one has a pole at $s=1+\frac{2\pi i m}{p}$ (notice that I believe that I have a sequence of poles, Murty's example only depends on $m$), and say that I can use the theorem to show that our sum $\rightarrow 0$ as $N\to\infty$, thus our sequence is equidistributed in the (compact) group $\mathbb{R}/\mathbb{Z}$. Can you explain if it is feasible such calculations or do it? I don't understand well if it is possible to  apply the theorem for my example, if you can state in details how one can use the theorem, then it is the best, and this example will be here as a reference. Thanks in advance.",,"['complex-analysis', 'prime-numbers']"
35,Winding number of a polynomial,Winding number of a polynomial,,"Consider $f(z) = c_n z^n + ... + c_1 z + c_0$, where $c_n\ne 0$. Let $C_R$ be the circle of radius $R$ centred at the origin, oriented counterclockwise. Prove that the winding number of $f\circ C_R =n $ for $R$ sufficiently large. My approach: Parametrize $C_R$ as $\gamma(t) = Re^{it}$. Then $$\frac{1}{2\pi i}\int_{C_R} \frac{f'(z)}{f(z)}dz=\frac{1}{2\pi i}\int\limits_0^{2\pi} \frac{f'(\gamma(t))\gamma'(t)}{f(\gamma(t))}dt$$ $$=\frac{1}{2\pi }\int\limits_0^{2\pi} \frac{nc_n (Re^{it})^n + ... + c_1 Re^{it}}{c_n (Re^{it})^n+...+c_1Re^{it}+c_0}dt$$ I thought I got stuck here, but now I'm thinking: maybe I should take the limit as $R\to \infty$ of the integral above, take the limit in the integral (since the limit is not in terms of $t$), and then observe that the integrand becomes $ndt$, and so the integral comes to $\frac{2\pi n}{2\pi}=n$? Would this approach be correct? I think so, because $R$ should go to infinity in order to encompass all possibilities for all zeros of $f(z)$.","Consider $f(z) = c_n z^n + ... + c_1 z + c_0$, where $c_n\ne 0$. Let $C_R$ be the circle of radius $R$ centred at the origin, oriented counterclockwise. Prove that the winding number of $f\circ C_R =n $ for $R$ sufficiently large. My approach: Parametrize $C_R$ as $\gamma(t) = Re^{it}$. Then $$\frac{1}{2\pi i}\int_{C_R} \frac{f'(z)}{f(z)}dz=\frac{1}{2\pi i}\int\limits_0^{2\pi} \frac{f'(\gamma(t))\gamma'(t)}{f(\gamma(t))}dt$$ $$=\frac{1}{2\pi }\int\limits_0^{2\pi} \frac{nc_n (Re^{it})^n + ... + c_1 Re^{it}}{c_n (Re^{it})^n+...+c_1Re^{it}+c_0}dt$$ I thought I got stuck here, but now I'm thinking: maybe I should take the limit as $R\to \infty$ of the integral above, take the limit in the integral (since the limit is not in terms of $t$), and then observe that the integrand becomes $ndt$, and so the integral comes to $\frac{2\pi n}{2\pi}=n$? Would this approach be correct? I think so, because $R$ should go to infinity in order to encompass all possibilities for all zeros of $f(z)$.",,"['complex-analysis', 'contour-integration', 'winding-number']"
36,Theta series and Jacobi theta functions,Theta series and Jacobi theta functions,,"I have some difficulties with expressing the following series  $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{1 + 3 a + 3 a^2 - 3 b - 3 a b + 3 b^2}$ using standart theta functions. I've tried to get the degree for the sum of squares: $1 + 3 a + 3 a^2 - 3 b - 3 a b + 3 b^2=3t^2+(\frac{3b-1}{2})^2$, where $a=t+\frac{b-1}{2}$ so as that the initial sum splits in $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{1 + 3 a + 3 a^2 - 3 b - 3 a b + 3 b^2}$ with $b$ even  and $\sum\limits_{t=-\infty}^{+\infty}\sum\limits_{b=-\infty}^{+\infty}q^{3t^2+(\frac{3b-1}{2})^2}$ , where $b$ is odd and then I tried analyzing cases with $\frac{3b-1}{2}\equiv 1 (mod3)$ and $\frac{3b-1}{2}\equiv 2 (mod3)$, but I were unsucceded. It is also clear how to express $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{3 a^2 - 3 a b + 3 b^2}$, so that we may decide it as being standart. I will be really grateful for any suggestions. Some useful definitions: $\theta_2(z)=\sum\limits_{a=-\infty}^{+\infty}q^{(a+1/2)^2}$, where $q=e^{\pi i z}$; $\theta_3(z)=\sum\limits_{a=-\infty}^{+\infty}q^{a^2}$; $\theta_4(z)=\sum\limits_{a=-\infty}^{+\infty}(-q)^{a^2}$. Some extra comments: Let $\phi(z)=\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{a^2 - a b + b^2}$, and assume that $a^2 - a b + b^2=(a-\frac{b}{2})^2+\frac{3b^2}{4}$, then $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{(a-\frac{b}{2})^2+\frac{3b^2}{4}}=\sum\limits_{a=-\infty}^{+\infty}\sum\limits_{\substack{b=-\infty \\ \text{b even}}}^{+\infty}q^{(a-\frac{b}{2})^2+\frac{3b^2}{4}}+ \sum\limits_{a=-\infty}^{+\infty}\sum\limits_{\substack{b=-\infty \\ \text{b odd}}}^{+\infty}q^{(a-\frac{b}{2})^2+\frac{3b^2}{4}}= \sum\limits_{a=-\infty}^{+\infty}\sum\limits_{k=-\infty}^{+\infty}q^{(a-k)^2+3k^2} +\sum\limits_{a=-\infty}^{+\infty}\sum\limits_{k=-\infty}^{+\infty}q^{(a-k-1/2)^2+3(k+1/2)^2}= \sum\limits_{t=-\infty}^{+\infty}\sum\limits_{t=-\infty}^{+\infty}q^{t^2+3k^2}+ \sum\limits_{a=-\infty}^{+\infty}\sum\limits_{t=-\infty}^{+\infty}q^{(t+1/2)^2+3(k+1/2)^2}=\theta_2(z)\theta_2(3z)+\theta_3(z)\theta_3(3z)$. And then $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{3(a^2 - a b + b^2)}=\phi(3z)$.","I have some difficulties with expressing the following series  $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{1 + 3 a + 3 a^2 - 3 b - 3 a b + 3 b^2}$ using standart theta functions. I've tried to get the degree for the sum of squares: $1 + 3 a + 3 a^2 - 3 b - 3 a b + 3 b^2=3t^2+(\frac{3b-1}{2})^2$, where $a=t+\frac{b-1}{2}$ so as that the initial sum splits in $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{1 + 3 a + 3 a^2 - 3 b - 3 a b + 3 b^2}$ with $b$ even  and $\sum\limits_{t=-\infty}^{+\infty}\sum\limits_{b=-\infty}^{+\infty}q^{3t^2+(\frac{3b-1}{2})^2}$ , where $b$ is odd and then I tried analyzing cases with $\frac{3b-1}{2}\equiv 1 (mod3)$ and $\frac{3b-1}{2}\equiv 2 (mod3)$, but I were unsucceded. It is also clear how to express $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{3 a^2 - 3 a b + 3 b^2}$, so that we may decide it as being standart. I will be really grateful for any suggestions. Some useful definitions: $\theta_2(z)=\sum\limits_{a=-\infty}^{+\infty}q^{(a+1/2)^2}$, where $q=e^{\pi i z}$; $\theta_3(z)=\sum\limits_{a=-\infty}^{+\infty}q^{a^2}$; $\theta_4(z)=\sum\limits_{a=-\infty}^{+\infty}(-q)^{a^2}$. Some extra comments: Let $\phi(z)=\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{a^2 - a b + b^2}$, and assume that $a^2 - a b + b^2=(a-\frac{b}{2})^2+\frac{3b^2}{4}$, then $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{(a-\frac{b}{2})^2+\frac{3b^2}{4}}=\sum\limits_{a=-\infty}^{+\infty}\sum\limits_{\substack{b=-\infty \\ \text{b even}}}^{+\infty}q^{(a-\frac{b}{2})^2+\frac{3b^2}{4}}+ \sum\limits_{a=-\infty}^{+\infty}\sum\limits_{\substack{b=-\infty \\ \text{b odd}}}^{+\infty}q^{(a-\frac{b}{2})^2+\frac{3b^2}{4}}= \sum\limits_{a=-\infty}^{+\infty}\sum\limits_{k=-\infty}^{+\infty}q^{(a-k)^2+3k^2} +\sum\limits_{a=-\infty}^{+\infty}\sum\limits_{k=-\infty}^{+\infty}q^{(a-k-1/2)^2+3(k+1/2)^2}= \sum\limits_{t=-\infty}^{+\infty}\sum\limits_{t=-\infty}^{+\infty}q^{t^2+3k^2}+ \sum\limits_{a=-\infty}^{+\infty}\sum\limits_{t=-\infty}^{+\infty}q^{(t+1/2)^2+3(k+1/2)^2}=\theta_2(z)\theta_2(3z)+\theta_3(z)\theta_3(3z)$. And then $\sum\limits_{b=-\infty}^{+\infty}\sum\limits_{a=-\infty}^{+\infty}q^{3(a^2 - a b + b^2)}=\phi(3z)$.",,"['abstract-algebra', 'complex-analysis', 'special-functions', 'theta-functions']"
37,Invariance of subharmonicity under a holomorphic map,Invariance of subharmonicity under a holomorphic map,,"If $f:U_1\rightarrow U_2$ is holomorphic and $u$ is subharmonic on $U_2$, then prove that $u\circ f $ is subharmonic on $U_1$. I know how to prove the same argument with $f$ being conformal. In that proof I had to use $f^{-1}$. But here $f$ is just holomorphic and not necessarily invertible. So how could I prove the above statement? Any help is appreciated.","If $f:U_1\rightarrow U_2$ is holomorphic and $u$ is subharmonic on $U_2$, then prove that $u\circ f $ is subharmonic on $U_1$. I know how to prove the same argument with $f$ being conformal. In that proof I had to use $f^{-1}$. But here $f$ is just holomorphic and not necessarily invertible. So how could I prove the above statement? Any help is appreciated.",,['complex-analysis']
38,Real and imaginary part of an analytic function are harmonic?,Real and imaginary part of an analytic function are harmonic?,,"Let $f:\Bbb{C}\to\Bbb{C}$ be an analytic function. For $z = x+iy,$ let $u,v : \mathbb{R}^2  \rightarrow \mathbb{R}^2 $ be such that $u(x,y) = \operatorname{Re}f(z)$ and $v(x,y) = \operatorname{Im}f(z)$ . Then which of the following are correct, 1. $\dfrac{\partial ^2u}{\partial x^2} + \dfrac{\partial ^2u}{\partial y^2} = 0$ 2. $\dfrac{\partial ^2v}{\partial x^2} + \dfrac{\partial ^2v}{\partial y^2} = 0$ 3. $\dfrac{\partial ^2u}{\partial x \partial y} - \dfrac{\partial ^2u}{\partial y \partial x} = 0$ My try: Since $\operatorname{Re} f(z)$ and $\operatorname{Im}f(z)$ parts of an analytic function satisfies Cauchy Riemann Equation. We can conclude all the options holds. But it's displayed option $2$ is incorrect. Is that so?","Let be an analytic function. For let be such that and . Then which of the following are correct, 1. 2. 3. My try: Since and parts of an analytic function satisfies Cauchy Riemann Equation. We can conclude all the options holds. But it's displayed option is incorrect. Is that so?","f:\Bbb{C}\to\Bbb{C} z = x+iy, u,v : \mathbb{R}^2  \rightarrow \mathbb{R}^2  u(x,y) = \operatorname{Re}f(z) v(x,y) = \operatorname{Im}f(z) \dfrac{\partial ^2u}{\partial x^2} + \dfrac{\partial ^2u}{\partial y^2} = 0 \dfrac{\partial ^2v}{\partial x^2} + \dfrac{\partial ^2v}{\partial y^2} = 0 \dfrac{\partial ^2u}{\partial x \partial y} - \dfrac{\partial ^2u}{\partial y \partial x} = 0 \operatorname{Re} f(z) \operatorname{Im}f(z) 2","['complex-analysis', 'complex-numbers', 'analytic-functions']"
39,Nice exercise with Rouche theorem,Nice exercise with Rouche theorem,,"let $P_n(z) = 1 + z/1! + z^2/2! + ... + z^n/n!$ prove that for all $R>0$ sufficiently large, there exists $N\in \mathbb N$ such that for all $n \ge N$, all the roots of $P_n$ lie in $D(0,R)$ I know this has to do with Rouche's theorem. since $P_n$ converges uniformly to $e^z = f(z)$ for all $\epsilon > 0$  there exists $N$ such that for $n \ge N$: $\sup |P_n(z) - f(z)| < \epsilon$ I want the bound $|P_n(z) - f(z)| < |f(z)$ somewhere to deduce that $P_n$ has the same number of roots (=zero) as $f$ inside $D(0,R)$ I am not sure how to make an argument and i don't have a clear idea about how to proceed please help and try to give as much details as possible because I am having trouble doing arguments thanks","let $P_n(z) = 1 + z/1! + z^2/2! + ... + z^n/n!$ prove that for all $R>0$ sufficiently large, there exists $N\in \mathbb N$ such that for all $n \ge N$, all the roots of $P_n$ lie in $D(0,R)$ I know this has to do with Rouche's theorem. since $P_n$ converges uniformly to $e^z = f(z)$ for all $\epsilon > 0$  there exists $N$ such that for $n \ge N$: $\sup |P_n(z) - f(z)| < \epsilon$ I want the bound $|P_n(z) - f(z)| < |f(z)$ somewhere to deduce that $P_n$ has the same number of roots (=zero) as $f$ inside $D(0,R)$ I am not sure how to make an argument and i don't have a clear idea about how to proceed please help and try to give as much details as possible because I am having trouble doing arguments thanks",,['complex-analysis']
40,How to find the Laurent series expansion of an exp function.,How to find the Laurent series expansion of an exp function.,,"Question: How to find the Laurent series expansion in powers of z of a) $f(z)= \dfrac{e^{z^2}}{z^3}$ $\text{where} \left| z \right| > 0$ Attempt: I know that the main idea is to rearrange the equation in such a way that you can use standard Tylor series such as: $e^x$ which is given as $\displaystyle \sum \frac{x^n}{n!}$ But how do you do this, and what is the method to tackle L series questions? Edit: After looking at some of the comments, would this method be correct: $f(z)= \dfrac{e^{z^2}}{z^3}$ $f(z)= \dfrac{1}{z^3} e^{z^2}$ $f(z)= \dfrac{1}{z^3} \displaystyle \sum_{n=0}^\infty \frac{(z^2)^n}{n!}$ L.series? $f(z)= \dfrac{1}{z^3} \biggl(1+z^2+\dfrac{z^4}{2!}+\dfrac{z^6}{3!}+...\biggr)$","Question: How to find the Laurent series expansion in powers of z of a) Attempt: I know that the main idea is to rearrange the equation in such a way that you can use standard Tylor series such as: which is given as But how do you do this, and what is the method to tackle L series questions? Edit: After looking at some of the comments, would this method be correct: L.series?",f(z)= \dfrac{e^{z^2}}{z^3} \text{where} \left| z \right| > 0 e^x \displaystyle \sum \frac{x^n}{n!} f(z)= \dfrac{e^{z^2}}{z^3} f(z)= \dfrac{1}{z^3} e^{z^2} f(z)= \dfrac{1}{z^3} \displaystyle \sum_{n=0}^\infty \frac{(z^2)^n}{n!} f(z)= \dfrac{1}{z^3} \biggl(1+z^2+\dfrac{z^4}{2!}+\dfrac{z^6}{3!}+...\biggr),"['calculus', 'complex-analysis', 'laurent-series']"
41,"closed path, winding number, Jordan contour","closed path, winding number, Jordan contour",,"If $ D$ is a domain in $\Bbb C$ , $z_0\in \Bbb C\setminus D$ , and $\gamma$ is a closed, piecewise smooth path in $ D$ for which the winding number $n(\gamma, z_0)\ne0$ , show that there is a Jordan contour $\gamma_1$ in $D$ for which $n(\gamma_1, z_0)=1$ Here, Jordan contour: positively oriented, simple, closed, piecewise smooth path. Bruce P.Palka, An Introduction to Complex Function Theory, P183， The author leave as an exercise I think, $C\setminus \gamma$ is the disjoint union of domains, the components of $C\setminus \gamma$ , and $z_0$ in a bounded component $U$ of $C\setminus \gamma$ .  then,  the boundary of $ U$ is a Jordan contour. But I don't know  how to prove this(if correc).","If is a domain in , , and is a closed, piecewise smooth path in for which the winding number , show that there is a Jordan contour in for which Here, Jordan contour: positively oriented, simple, closed, piecewise smooth path. Bruce P.Palka, An Introduction to Complex Function Theory, P183， The author leave as an exercise I think, is the disjoint union of domains, the components of , and in a bounded component of .  then,  the boundary of is a Jordan contour. But I don't know  how to prove this(if correc)."," D \Bbb C z_0\in \Bbb C\setminus D \gamma  D n(\gamma, z_0)\ne0 \gamma_1 D n(\gamma_1, z_0)=1 C\setminus \gamma C\setminus \gamma z_0 U C\setminus \gamma  U",['complex-analysis']
42,Rouche's Theorem application for $z^6-5z^4+3z^2-1$ in $|z|\leq 1$,Rouche's Theorem application for  in,z^6-5z^4+3z^2-1 |z|\leq 1,"Find the number of roots of $f(z)=z^6-5z^4+3z^2-1$ in $|z|\leq 1$ Taking $g(z)=1$ would be the obvious choice, but it's not the right one. The next choice would be $z^6-1$ because we know the roots of unity, that doesn't work either. Am I missing something obvious? $g(z)=-5z^4$ would work, but then I'd have to expand this and I'm pretty sure the point of the theorem is to avoid Mathematica! Any insight is appreciated.","Find the number of roots of $f(z)=z^6-5z^4+3z^2-1$ in $|z|\leq 1$ Taking $g(z)=1$ would be the obvious choice, but it's not the right one. The next choice would be $z^6-1$ because we know the roots of unity, that doesn't work either. Am I missing something obvious? $g(z)=-5z^4$ would work, but then I'd have to expand this and I'm pretty sure the point of the theorem is to avoid Mathematica! Any insight is appreciated.",,"['complex-analysis', 'polynomials', 'roots']"
43,There is no 'nice' complex logarithm,There is no 'nice' complex logarithm,,"Two problems are meant to establish that no 'nice' logarithm function exists for complex numbers. The first is Let $U$ be an open set in $\mathfrak{C}\setminus\{0\}$. Suppose $h:U \to \mathfrak{C}$ is a continuous function, such that $$e^{h(z)}=z \ \ \ \text{for every} \ z\in U$$ Show that $h$ is holomorphic by computing the defining formula for the derivative. $$lim_{w \to z} \frac{h(w)-h(z)}{w-z}$$ While the second is to prove no such function can exist on $\mathfrak{C}\setminus\{0\}$. My attempt so far has been to write $h(z)=f(z)+ig(z)$  which then gives $f(z)=\ln|z|$ and $g(z)=\arg(z)$ which contradicts the assumption of continuity, proving the second part. This does not prove the first part, which is that if such an $h$ did exist then $h$ is holomorphic","Two problems are meant to establish that no 'nice' logarithm function exists for complex numbers. The first is Let $U$ be an open set in $\mathfrak{C}\setminus\{0\}$. Suppose $h:U \to \mathfrak{C}$ is a continuous function, such that $$e^{h(z)}=z \ \ \ \text{for every} \ z\in U$$ Show that $h$ is holomorphic by computing the defining formula for the derivative. $$lim_{w \to z} \frac{h(w)-h(z)}{w-z}$$ While the second is to prove no such function can exist on $\mathfrak{C}\setminus\{0\}$. My attempt so far has been to write $h(z)=f(z)+ig(z)$  which then gives $f(z)=\ln|z|$ and $g(z)=\arg(z)$ which contradicts the assumption of continuity, proving the second part. This does not prove the first part, which is that if such an $h$ did exist then $h$ is holomorphic",,"['complex-analysis', 'analysis', 'complex-numbers']"
44,Index of a Jordan curve,Index of a Jordan curve,,"Winding number theorem : If $J\subset \mathbb{C}$  is a Jordan curve and a point $z$ lies in its interior domain, then the winding number $n(J,z)=\pm 1$. Now suppose that $J$ is smooth and we have the Jordan curve theorem . Is there any simple complex analysis proof for winding number theorem? I have found only tedious (non-analytical) proofs for the case of continuous curves. EDIT : Possible proof should use the facts that in each component of $\mathbb{C}\setminus J$ the winding numer is constant, and winding number is zero in the unbounded component; Jordan curve theorem tells us that there are only two different components. But I have no idea how to analytically conclude that $|n(J,z_{\text{inside}})-n(J,z_{\text{outside}})|=1.$","Winding number theorem : If $J\subset \mathbb{C}$  is a Jordan curve and a point $z$ lies in its interior domain, then the winding number $n(J,z)=\pm 1$. Now suppose that $J$ is smooth and we have the Jordan curve theorem . Is there any simple complex analysis proof for winding number theorem? I have found only tedious (non-analytical) proofs for the case of continuous curves. EDIT : Possible proof should use the facts that in each component of $\mathbb{C}\setminus J$ the winding numer is constant, and winding number is zero in the unbounded component; Jordan curve theorem tells us that there are only two different components. But I have no idea how to analytically conclude that $|n(J,z_{\text{inside}})-n(J,z_{\text{outside}})|=1.$",,"['general-topology', 'complex-analysis', 'differential-topology', 'plane-curves', 'winding-number']"
45,Asymptotic analysis references,Asymptotic analysis references,,"I'm self studying asymptotic analysis with Bruijn (1981) - Asymptotic Methods in Analysis Bleistein and Handelsman (1986) - Asymptotic Expansions of Integrals but the texts are terse, without too many examples, and the exercises don't have solutions. Could you please recommend texts on the same topic that are perhaps a bit easier and/or come with solutions for exercises? I'm reading these so that I can understand better Laplace transforms and saddlepoint methods. I took real analysis, functional analysis and complex analysis as an undergrad and can fill in some gaps if necessary.","I'm self studying asymptotic analysis with Bruijn (1981) - Asymptotic Methods in Analysis Bleistein and Handelsman (1986) - Asymptotic Expansions of Integrals but the texts are terse, without too many examples, and the exercises don't have solutions. Could you please recommend texts on the same topic that are perhaps a bit easier and/or come with solutions for exercises? I'm reading these so that I can understand better Laplace transforms and saddlepoint methods. I took real analysis, functional analysis and complex analysis as an undergrad and can fill in some gaps if necessary.",,"['real-analysis', 'complex-analysis', 'reference-request', 'asymptotics']"
46,Holomorphic function $f\left(\frac{1}{2n}\right)=f\left(\frac{1}{2n-1} \right)=\frac{1}{n}$,Holomorphic function,f\left(\frac{1}{2n}\right)=f\left(\frac{1}{2n-1} \right)=\frac{1}{n},"Does there exists a holomorphic function $f:B_2(0)\to\mathbb C$ such that $$f\left(\frac{1}{2n}\right)=f\left(\frac{1}{2n-1}\right)=\frac{1}{n},\;\forall n\in\mathbb Z^+.$$ I do not have an idea?",Does there exists a holomorphic function such that I do not have an idea?,"f:B_2(0)\to\mathbb C f\left(\frac{1}{2n}\right)=f\left(\frac{1}{2n-1}\right)=\frac{1}{n},\;\forall n\in\mathbb Z^+.","['complex-analysis', 'functions']"
47,holomorphic funktion is a polynomial,holomorphic funktion is a polynomial,,"Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be holomorphic. If we have $|f(z)|\leq|z|^n$ for some $n\in\mathbb{N}$ and all $z\in\mathbb{C}$, then $f$ is a polynomial. I tried to apply Liouville's theorem but it does not help. Thanks for your help.","Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be holomorphic. If we have $|f(z)|\leq|z|^n$ for some $n\in\mathbb{N}$ and all $z\in\mathbb{C}$, then $f$ is a polynomial. I tried to apply Liouville's theorem but it does not help. Thanks for your help.",,['polynomials']
48,Applying the Schur algorithm to finite Blaschke products,Applying the Schur algorithm to finite Blaschke products,,"A Schur function is a function which is holomorphic in the unit disk $\mathbb{D}$ satisfying $|f(z)|\leq 1$. The Schur algorithm is a way of producing a sequence of Schur functions starting with a given Schur fanction $f(z)$ in the following way : $$ f_{n+1}(z)=\frac{1}{z} \frac{f_n(z)-\gamma_n}{1-\overline{\gamma_n}f_n(z)} \ \ \ \ (\star) \ \ \ \ \text{with} \ \ f_0(z)=f(z) \ \ \text{and} \ \ \ \gamma_n = f_n(0) $$ One continues this algorithm as long as $|\gamma_n|<1$, if $|\gamma_m|=1$ for some $m$, we set $f_j(z) \equiv0$ for $j>m$. I need to prove that the Schur algorithm stops ($|\gamma_m|=1$ for some $m>0$) if and only if the Schur function $f(z)=f_0(z)$ that we start with is a finite Blaschke product $\displaystyle e^{i\theta}\prod^{N}_{i=1}\frac{z-z_i}{1-\overline{z_i}z }$; $|z_i|<1$. This is how I approached this : ($\Leftarrow$) Proof by induction on the number of factors in the Blaschke product. Base of induction: for $N=1$ we have $$f(z)=e^{i\theta}\frac{z-z_1}{1-\overline{z_1}z } \ \ \ \ \ \ \ \ \ |z_1|<1 $$ We have that $$ f_1(z)= \frac{e^{i\theta}+\gamma_0\overline{z_1}}{1-|\gamma_0|^2-(\overline{z_1}+\overline{\gamma_0}e^{i\theta})z}  $$ so $$\gamma_1=\frac{e^{i\theta}+\gamma_0\overline{z_1}}{1-|\gamma_0|^2} \ \ \ \Rightarrow |\gamma_1|=|e^{-i\theta}\gamma_1|=1$$ To prove the inductive step, I need to prove that if we apply the Schur algorithm to a finite Blaschke product with $m+1$ factors, we will get another Blaschke product with $m$ factors, and then using the induction hypothesis we are done. but I had failed so far to prove this fact. My attempt for ($\Rightarrow$): Suppose for some $m$ we have that $f_m(0)=\gamma_m \in \mathbb{T}$, where $\mathbb{T}$ is the unit circle. By a simple calculation we can show that $$f_{m-1}(z)=\frac{\gamma_{m-1}+zf_m(z)}{1+\overline{\gamma_{m-1}}zf_m(z)} \ \ \ \  \ \ (\star \star) $$ from $(\star)$. However, by maximum modulus principle we have that $$f_m(z) \equiv \gamma_m$$ so by the above equation for $f_{m-1}(z)$ we will find that $$f_{m-1}(z)=\gamma_m \frac{z-(-\overline{\gamma_m}\gamma_{m-1})}{1-\overline{\left( \overline{\gamma_m}\gamma_{m-1} \right)}z}$$ which is a Blaschke product with one factor. however, to finish the proof , I need to show that if $f_j(z)$ is a Blaschke product $\displaystyle e^{i\theta}\prod^{k}_{i=1} \frac{z-z_i}{1-\overline{z_i}z}$ then $f_{j-1}(z)$ given by $(\star \star)$ is also a Blaschke product (with $k+1$ factors?); plugging into $(\star \star)$ gives us $$f_{j-1}(z)=\frac{\gamma_{j-1}\prod_{i=1}^{k}(1-\overline{z_i}z)+z\prod_{i=1}^{k}(z-z_i)}{\prod_{i=1}^{k}(1-\overline{z_i}z)+\overline{\gamma_{j-1}}z\prod_{i=1}^{k}(z-z_i)}$$  The numerator is a polynomial of degree $k+1$, so I can write it as $\displaystyle \prod^{k+1}_{i=1} (z-w_i)$; but this is not at all clear to me why I can write the denominator as $\displaystyle \prod^{k+1}_{i=1} (1-\overline{w_i}z)$ for the same $w_i$ appearing in the numerator; to get a Blaschke product. (somehow the same problem that I run into when I want to prove $(\Leftarrow)$) Any help, hints, or suggestion of alternative ways to approach this problem is very much appreciated, Thanks !","A Schur function is a function which is holomorphic in the unit disk $\mathbb{D}$ satisfying $|f(z)|\leq 1$. The Schur algorithm is a way of producing a sequence of Schur functions starting with a given Schur fanction $f(z)$ in the following way : $$ f_{n+1}(z)=\frac{1}{z} \frac{f_n(z)-\gamma_n}{1-\overline{\gamma_n}f_n(z)} \ \ \ \ (\star) \ \ \ \ \text{with} \ \ f_0(z)=f(z) \ \ \text{and} \ \ \ \gamma_n = f_n(0) $$ One continues this algorithm as long as $|\gamma_n|<1$, if $|\gamma_m|=1$ for some $m$, we set $f_j(z) \equiv0$ for $j>m$. I need to prove that the Schur algorithm stops ($|\gamma_m|=1$ for some $m>0$) if and only if the Schur function $f(z)=f_0(z)$ that we start with is a finite Blaschke product $\displaystyle e^{i\theta}\prod^{N}_{i=1}\frac{z-z_i}{1-\overline{z_i}z }$; $|z_i|<1$. This is how I approached this : ($\Leftarrow$) Proof by induction on the number of factors in the Blaschke product. Base of induction: for $N=1$ we have $$f(z)=e^{i\theta}\frac{z-z_1}{1-\overline{z_1}z } \ \ \ \ \ \ \ \ \ |z_1|<1 $$ We have that $$ f_1(z)= \frac{e^{i\theta}+\gamma_0\overline{z_1}}{1-|\gamma_0|^2-(\overline{z_1}+\overline{\gamma_0}e^{i\theta})z}  $$ so $$\gamma_1=\frac{e^{i\theta}+\gamma_0\overline{z_1}}{1-|\gamma_0|^2} \ \ \ \Rightarrow |\gamma_1|=|e^{-i\theta}\gamma_1|=1$$ To prove the inductive step, I need to prove that if we apply the Schur algorithm to a finite Blaschke product with $m+1$ factors, we will get another Blaschke product with $m$ factors, and then using the induction hypothesis we are done. but I had failed so far to prove this fact. My attempt for ($\Rightarrow$): Suppose for some $m$ we have that $f_m(0)=\gamma_m \in \mathbb{T}$, where $\mathbb{T}$ is the unit circle. By a simple calculation we can show that $$f_{m-1}(z)=\frac{\gamma_{m-1}+zf_m(z)}{1+\overline{\gamma_{m-1}}zf_m(z)} \ \ \ \  \ \ (\star \star) $$ from $(\star)$. However, by maximum modulus principle we have that $$f_m(z) \equiv \gamma_m$$ so by the above equation for $f_{m-1}(z)$ we will find that $$f_{m-1}(z)=\gamma_m \frac{z-(-\overline{\gamma_m}\gamma_{m-1})}{1-\overline{\left( \overline{\gamma_m}\gamma_{m-1} \right)}z}$$ which is a Blaschke product with one factor. however, to finish the proof , I need to show that if $f_j(z)$ is a Blaschke product $\displaystyle e^{i\theta}\prod^{k}_{i=1} \frac{z-z_i}{1-\overline{z_i}z}$ then $f_{j-1}(z)$ given by $(\star \star)$ is also a Blaschke product (with $k+1$ factors?); plugging into $(\star \star)$ gives us $$f_{j-1}(z)=\frac{\gamma_{j-1}\prod_{i=1}^{k}(1-\overline{z_i}z)+z\prod_{i=1}^{k}(z-z_i)}{\prod_{i=1}^{k}(1-\overline{z_i}z)+\overline{\gamma_{j-1}}z\prod_{i=1}^{k}(z-z_i)}$$  The numerator is a polynomial of degree $k+1$, so I can write it as $\displaystyle \prod^{k+1}_{i=1} (z-w_i)$; but this is not at all clear to me why I can write the denominator as $\displaystyle \prod^{k+1}_{i=1} (1-\overline{w_i}z)$ for the same $w_i$ appearing in the numerator; to get a Blaschke product. (somehow the same problem that I run into when I want to prove $(\Leftarrow)$) Any help, hints, or suggestion of alternative ways to approach this problem is very much appreciated, Thanks !",,['complex-analysis']
49,Singular point of $f(z)$ also a singular point of $1/f(z)$ and $f^{2}(z)$,Singular point of  also a singular point of  and,f(z) 1/f(z) f^{2}(z),"Suppose $z_{0} \in \mathbb{C}$ is an isolated singular point of the function $f$ of a given type (removable, pole of order $N$, essential). I need to show that $z_{0}$ is an isolated singular point of $g(z) = 1/f(z)$ (here, additionally, assume that $f(z)$ has no zeros in some deleted neighborhood of $z_{0}$). $h(z) = f^{2}(z)$ and find its type in each case. I've been struggling with this problem for a couple of days - I tried using the neighborhood definition of an isolated singular point with $\delta$'s, but that wasn't getting me anywhere. Could somebody please walk me through this problem? I'm extremely confused to the point of tearing my hair out. Maybe just a full solution for 1. and a hint for 2.? Thanks.","Suppose $z_{0} \in \mathbb{C}$ is an isolated singular point of the function $f$ of a given type (removable, pole of order $N$, essential). I need to show that $z_{0}$ is an isolated singular point of $g(z) = 1/f(z)$ (here, additionally, assume that $f(z)$ has no zeros in some deleted neighborhood of $z_{0}$). $h(z) = f^{2}(z)$ and find its type in each case. I've been struggling with this problem for a couple of days - I tried using the neighborhood definition of an isolated singular point with $\delta$'s, but that wasn't getting me anywhere. Could somebody please walk me through this problem? I'm extremely confused to the point of tearing my hair out. Maybe just a full solution for 1. and a hint for 2.? Thanks.",,['complex-analysis']
50,"Suppose $\triangle ABC$ is an equilateral triangle inscribed in the unit circle C(0,1).","Suppose  is an equilateral triangle inscribed in the unit circle C(0,1).",\triangle ABC,"Suppose $\triangle ABC$ is an equilateral triangle inscribed in the unit circle C(0,1). Find the maximum value of $$\overline{PA}\cdot\overline{PB}\cdot\overline{PC}$$ where $P$ is a variable point in $\bar{D}(0,2).$ I am trying to figure a proof for this problem out. I have it all drawn out so I could see conceptually what is going on but I am having trouble finding the answer. I believe the sides of the equilateral triangle are going to be $\sqrt{3}$ but I am not sure about the rest. this question is actually blowing my mind trying to find an answer.","Suppose $\triangle ABC$ is an equilateral triangle inscribed in the unit circle C(0,1). Find the maximum value of $$\overline{PA}\cdot\overline{PB}\cdot\overline{PC}$$ where $P$ is a variable point in $\bar{D}(0,2).$ I am trying to figure a proof for this problem out. I have it all drawn out so I could see conceptually what is going on but I am having trouble finding the answer. I believe the sides of the equilateral triangle are going to be $\sqrt{3}$ but I am not sure about the rest. this question is actually blowing my mind trying to find an answer.",,['complex-analysis']
51,How many roots does the polynomial $p(z) = z^8 + 3z^7 + 6z^2 + 1$ have inside the annulus $1 < |z| < 2$?,How many roots does the polynomial  have inside the annulus ?,p(z) = z^8 + 3z^7 + 6z^2 + 1 1 < |z| < 2,How many roots does the polynomial $p(z) = z^8 + 3z^7 + 6z^2 + 1$ have inside the annulus $1 < |z| < 2$? I know I can use Rouche's Theorem. I'm just not sure how. It states that $|f(z) − g(z)| < |f(z)|$ where $f(z)$ is the given polynomial and we choose $g(z)$. Any solutions or hints are greatly appreciated.,How many roots does the polynomial $p(z) = z^8 + 3z^7 + 6z^2 + 1$ have inside the annulus $1 < |z| < 2$? I know I can use Rouche's Theorem. I'm just not sure how. It states that $|f(z) − g(z)| < |f(z)|$ where $f(z)$ is the given polynomial and we choose $g(z)$. Any solutions or hints are greatly appreciated.,,"['real-analysis', 'abstract-algebra', 'complex-analysis', 'polynomials', 'roots']"
52,Show that a power series is analytic inside its radius of convergence,Show that a power series is analytic inside its radius of convergence,,Let $f(z)=\sum_{k=0}^\infty a_k(z-z_0)^k$ with radius of convergence $R$ then $f$ is analytic on the open disk around $z_0$ with radius $R$. What I was thinking about is an approach based on this sketch: I want to find a new power series based on a new disk with center $\widetilde{z_0}$ and variable $z$. Therefore I am using $z-z_0 = (\widetilde{z_0}-z_0)+(z-\widetilde{z_0})$ which yields $$ f(z) = \sum_{k=0}^\infty a_k\left( (\widetilde{z_0}-z_0)+(z-\widetilde{z_0}) \right)^k = \sum_{k=0}^\infty a_k\sum_{n=0}^k\binom{k}{n}(\widetilde{z_0}-z_0)^n(z-\widetilde{z_0})^{k-n}. $$ I am looking for power series of the form $\sum_{k=0}^\infty b_k(z-\widetilde{z_0})^k$ but haven't been able to come up with the next step. What is your suggestion based on the method of using the binomial formula (explicitly no derivatives of power series etc. if possible)?,Let $f(z)=\sum_{k=0}^\infty a_k(z-z_0)^k$ with radius of convergence $R$ then $f$ is analytic on the open disk around $z_0$ with radius $R$. What I was thinking about is an approach based on this sketch: I want to find a new power series based on a new disk with center $\widetilde{z_0}$ and variable $z$. Therefore I am using $z-z_0 = (\widetilde{z_0}-z_0)+(z-\widetilde{z_0})$ which yields $$ f(z) = \sum_{k=0}^\infty a_k\left( (\widetilde{z_0}-z_0)+(z-\widetilde{z_0}) \right)^k = \sum_{k=0}^\infty a_k\sum_{n=0}^k\binom{k}{n}(\widetilde{z_0}-z_0)^n(z-\widetilde{z_0})^{k-n}. $$ I am looking for power series of the form $\sum_{k=0}^\infty b_k(z-\widetilde{z_0})^k$ but haven't been able to come up with the next step. What is your suggestion based on the method of using the binomial formula (explicitly no derivatives of power series etc. if possible)?,,"['complex-analysis', 'proof-verification', 'convergence-divergence', 'power-series', 'binomial-theorem']"
53,$f(|z|)$ is not an analytic function,is not an analytic function,f(|z|),"Let $f: [0,\infty)\rightarrow \mathbb{C}$ is a non constant function. Define $g:\mathbb{C}\rightarrow\mathbb{C}$ by $g(z)=f(|z|)$. Prove that $g(z)$ is not holomorphic. So, I need to find a point $z_0$ where it is not analytic. Write $f(x)=u(x)+iv(x)$ then $f(|z|)=u(\sqrt{x^2+y^2})+iv(\sqrt{x^2+y^2})$. Set $p(x,y)=u(\sqrt{x^2+y^2})$ and $q(x,y)=v(\sqrt{x^2+y^2})$ Then, $$\partial p/\partial x=(\partial u/\partial x)(x/\sqrt{x^2+y^2}),\partial p/\partial y=(\partial u/\partial y)(y/\sqrt{x^2+y^2})$$ and  $$\partial q/\partial x=(\partial v/\partial x)(x/\sqrt{x^2+y^2}),\partial q/\partial y=(\partial v/\partial y)(y/\sqrt{x^2+y^2})$$ Suppose it is holomorphic then it has to satisfy cauchy riemann equations and so we should have $$x(\partial u/\partial x)=y(\partial v/\partial y),y(\partial u/\partial y)=-x(\partial v/\partial x)$$ After writing this then i realized that $u,v$ are functions of single variable.. It does not make sense in trying to differentiate with two variables... I am clueless at this stage.","Let $f: [0,\infty)\rightarrow \mathbb{C}$ is a non constant function. Define $g:\mathbb{C}\rightarrow\mathbb{C}$ by $g(z)=f(|z|)$. Prove that $g(z)$ is not holomorphic. So, I need to find a point $z_0$ where it is not analytic. Write $f(x)=u(x)+iv(x)$ then $f(|z|)=u(\sqrt{x^2+y^2})+iv(\sqrt{x^2+y^2})$. Set $p(x,y)=u(\sqrt{x^2+y^2})$ and $q(x,y)=v(\sqrt{x^2+y^2})$ Then, $$\partial p/\partial x=(\partial u/\partial x)(x/\sqrt{x^2+y^2}),\partial p/\partial y=(\partial u/\partial y)(y/\sqrt{x^2+y^2})$$ and  $$\partial q/\partial x=(\partial v/\partial x)(x/\sqrt{x^2+y^2}),\partial q/\partial y=(\partial v/\partial y)(y/\sqrt{x^2+y^2})$$ Suppose it is holomorphic then it has to satisfy cauchy riemann equations and so we should have $$x(\partial u/\partial x)=y(\partial v/\partial y),y(\partial u/\partial y)=-x(\partial v/\partial x)$$ After writing this then i realized that $u,v$ are functions of single variable.. It does not make sense in trying to differentiate with two variables... I am clueless at this stage.",,['complex-analysis']
54,Complex power series expansion of $\frac{e^z}{1+z}$,Complex power series expansion of,\frac{e^z}{1+z},"I'm trying to find complex power series expansion of $\frac{e^z}{1+z}$ centered at $z=0$ and its radius of convergence. Here is my attempt: Since $e^z = \sum_{n=0}^\infty \frac{z^n}{n!}$, we can divide both terms by $1+z$ to get $e^z = \sum_{n=0}^\infty \frac{z^n}{(1+z)n!}$. Then I can get radius of convergence using the usual Cauchy-Hadamard formula. Is this correct? Thanks for any help!","I'm trying to find complex power series expansion of $\frac{e^z}{1+z}$ centered at $z=0$ and its radius of convergence. Here is my attempt: Since $e^z = \sum_{n=0}^\infty \frac{z^n}{n!}$, we can divide both terms by $1+z$ to get $e^z = \sum_{n=0}^\infty \frac{z^n}{(1+z)n!}$. Then I can get radius of convergence using the usual Cauchy-Hadamard formula. Is this correct? Thanks for any help!",,"['complex-analysis', 'power-series']"
55,Prove if $f'(1)$ is Real then $f'(1)\ge 1$,Prove if  is Real then,f'(1) f'(1)\ge 1,"While Solving exams of previous years I encountered this problem which I cannot solve Prove if $f'(1)$ is Real then $f'(1)\ge 1$, Let $f$ be holomorphic(has a derivative) at $\Omega = \{|z|<1\}\cup\{|z-1|<r\}$ for some $r>0$. Assume: $f(0)=0$ $f(1)=1$ $\forall z\in\Omega \space(|z|<1 \implies |f(z)|<1)$ Anyway I try to look at it... I don't get anywhere :\ Thanks","While Solving exams of previous years I encountered this problem which I cannot solve Prove if $f'(1)$ is Real then $f'(1)\ge 1$, Let $f$ be holomorphic(has a derivative) at $\Omega = \{|z|<1\}\cup\{|z-1|<r\}$ for some $r>0$. Assume: $f(0)=0$ $f(1)=1$ $\forall z\in\Omega \space(|z|<1 \implies |f(z)|<1)$ Anyway I try to look at it... I don't get anywhere :\ Thanks",,['complex-analysis']
56,How can I make the function $\cot (z)$ holomorphic?,How can I make the function  holomorphic?,\cot (z),"How can I make the function $\cot (z)$ holomorphic? $\cot (z)$ clearly has a pole whenever $\tan (z)=0$. This happens when $z=n\pi$, including at $(0,0)$. Is it possible to define a branch such to make $\cot (z)$ holomorphic?  Is it possible to define the domain of holomorphicity? This function is used to derive identities such as $\sum 1/n^2$","How can I make the function $\cot (z)$ holomorphic? $\cot (z)$ clearly has a pole whenever $\tan (z)=0$. This happens when $z=n\pi$, including at $(0,0)$. Is it possible to define a branch such to make $\cot (z)$ holomorphic?  Is it possible to define the domain of holomorphicity? This function is used to derive identities such as $\sum 1/n^2$",,['complex-analysis']
57,Derivative of a logarithm and Dirac delta function,Derivative of a logarithm and Dirac delta function,,"I'm reading Polyakov's book, Gauge fields and strings. There is this formula (9.247) which I do not really understand how to get. The formula states that in two dimensions, taking $z$ as my holomorphic and $\bar{z}$ as my antiholomorphic variable, the following relation holds $$\partial_{\bar{z}}\frac{1}{z-w}=-\pi \delta(z-w)$$ How does one find this?","I'm reading Polyakov's book, Gauge fields and strings. There is this formula (9.247) which I do not really understand how to get. The formula states that in two dimensions, taking $z$ as my holomorphic and $\bar{z}$ as my antiholomorphic variable, the following relation holds $$\partial_{\bar{z}}\frac{1}{z-w}=-\pi \delta(z-w)$$ How does one find this?",,"['complex-analysis', 'dirac-delta']"
58,Radii of convergence for complex series,Radii of convergence for complex series,,"I need to find the radii of convergence for these series: $1. \sum_{n=1}^\infty (2+(-1)^n)^n z^{2n}$ $2. \sum_{n=1}^\infty (n+a^n)z^n, a \in C $ $3. \sum_{n=1}^\infty 2^n z^{n!}$ Starting with the first power series, I attempted this by claiming that $$a_n =(2+(-1)^k)^k$$ if $n = 2k, k\ge 1$, and $0$ otherwise. Then, $$|a_n|^{1/n} = ((2+(-1)^k)^k)^\frac{1}{2k}= \sqrt{(2+(-1)^k}$$ Therefore,  $$ \limsup|a_n|^{1/n} = \limsup = \sqrt{(2+(-1)^k} = \sqrt3$$ The radius of convergence is $\frac{1}{\sqrt3}$. I would just like to confirm if this approach is feasible, and if not, what I should change about it. As for the second series, my first idea was to split up the sum like this:  $$\sum_{n=1}^\infty (n+a^n)z^n = \sum_{n=1}^\infty nz^n + \sum_{n=1}^\infty (az)^n  $$ Is it acceptable to say that the radius of convergence for this one is the radii of convergences of the two series that were broken up? Lastly, for the third, I was considering using a ratio test for this one, but I fail to see how that would help me, nor do I see how any other option would be helpful. Any advice would be much appreciated. Thank you!","I need to find the radii of convergence for these series: $1. \sum_{n=1}^\infty (2+(-1)^n)^n z^{2n}$ $2. \sum_{n=1}^\infty (n+a^n)z^n, a \in C $ $3. \sum_{n=1}^\infty 2^n z^{n!}$ Starting with the first power series, I attempted this by claiming that $$a_n =(2+(-1)^k)^k$$ if $n = 2k, k\ge 1$, and $0$ otherwise. Then, $$|a_n|^{1/n} = ((2+(-1)^k)^k)^\frac{1}{2k}= \sqrt{(2+(-1)^k}$$ Therefore,  $$ \limsup|a_n|^{1/n} = \limsup = \sqrt{(2+(-1)^k} = \sqrt3$$ The radius of convergence is $\frac{1}{\sqrt3}$. I would just like to confirm if this approach is feasible, and if not, what I should change about it. As for the second series, my first idea was to split up the sum like this:  $$\sum_{n=1}^\infty (n+a^n)z^n = \sum_{n=1}^\infty nz^n + \sum_{n=1}^\infty (az)^n  $$ Is it acceptable to say that the radius of convergence for this one is the radii of convergences of the two series that were broken up? Lastly, for the third, I was considering using a ratio test for this one, but I fail to see how that would help me, nor do I see how any other option would be helpful. Any advice would be much appreciated. Thank you!",,"['complex-analysis', 'power-series']"
59,Integration of a polynomial about a cricle,Integration of a polynomial about a cricle,,"Let $p(z)=a_0+a_1z+a_2z^2+...+a_nz^n$ $(a_n \neq0)$. Show that for sufficiently large r, $$\frac{1}{2\pi i} \int_{C(0,r)}\frac{p'(z)}{p(z)}dz=n$$ What can be said about a small r? I am trying to manipulate Cauchy's formula to achieve what I need but I can not seem to reach the conclusion. Also wouldn't the answer be the same for any positive r no matter the size?","Let $p(z)=a_0+a_1z+a_2z^2+...+a_nz^n$ $(a_n \neq0)$. Show that for sufficiently large r, $$\frac{1}{2\pi i} \int_{C(0,r)}\frac{p'(z)}{p(z)}dz=n$$ What can be said about a small r? I am trying to manipulate Cauchy's formula to achieve what I need but I can not seem to reach the conclusion. Also wouldn't the answer be the same for any positive r no matter the size?",,"['real-analysis', 'complex-analysis']"
60,Prove that $|\sin z| \geq |\sin x|$ and $|\cos z| \geq |\cos x|$,Prove that  and,|\sin z| \geq |\sin x| |\cos z| \geq |\cos x|,"For any $z=x+iy$, prove the following: $$|\sin z| \geq |\sin x|$$  $$|\cos z| \geq |\cos x|$$  $\epsilon$-$\delta $ proof is not required. I don't really know how to proceed. I know in order to remove the absolute values I can square both sides and I have tried proving this statement using the hyperbolic forms and then the exponential forms but I keep running into circles and I am getting no where... So for the first one all I have is $$ |\sin z| \geq |\sin x|   $$ $$|\sin z|^2=\sin^2x +\sinh^2y \geq \sin^2x $$ or $${1\over4} |e^{iz}-e^{-iz} |^2≥{1\over4}|e^{ix}-e^{-ix}|^2$$And at this point I think I am beginning to overthink how to square absolute values.","For any $z=x+iy$, prove the following: $$|\sin z| \geq |\sin x|$$  $$|\cos z| \geq |\cos x|$$  $\epsilon$-$\delta $ proof is not required. I don't really know how to proceed. I know in order to remove the absolute values I can square both sides and I have tried proving this statement using the hyperbolic forms and then the exponential forms but I keep running into circles and I am getting no where... So for the first one all I have is $$ |\sin z| \geq |\sin x|   $$ $$|\sin z|^2=\sin^2x +\sinh^2y \geq \sin^2x $$ or $${1\over4} |e^{iz}-e^{-iz} |^2≥{1\over4}|e^{ix}-e^{-ix}|^2$$And at this point I think I am beginning to overthink how to square absolute values.",,"['complex-analysis', 'trigonometry', 'proof-verification', 'hyperbolic-functions']"
61,Cauchy's theorem for contour integration,Cauchy's theorem for contour integration,,"I have to compute $\int_C(z+\frac{1}{z})^{2n}\frac{1}{z}dz$, where $n \in \mathbb{N}$, and $C$ is the unit circle with positive orientation. So let $z(t)=\cos (t) + i \sin (t)$, with $-\pi \leq t < \pi$ $$\begin{align*}\int_C(z+\frac{1}{z})^{2n}\frac{1}{z}dz &= \int^{\pi}_{-\pi}\left(z(t)+\frac{1}{z(t)}\right)^{2n}\frac{1}{z(t)}dt \\ &= 4^n \left(\int^{\pi}_{-\pi} (\cos (t)) ^{2n+1})dt -i  \int^{\pi}_{-\pi} (\cos (t))^{2n} \sin (t) dt \right)\end{align*}$$ Is there a faster way to compute this integral? Does Cauchy's Theorem help here?","I have to compute $\int_C(z+\frac{1}{z})^{2n}\frac{1}{z}dz$, where $n \in \mathbb{N}$, and $C$ is the unit circle with positive orientation. So let $z(t)=\cos (t) + i \sin (t)$, with $-\pi \leq t < \pi$ $$\begin{align*}\int_C(z+\frac{1}{z})^{2n}\frac{1}{z}dz &= \int^{\pi}_{-\pi}\left(z(t)+\frac{1}{z(t)}\right)^{2n}\frac{1}{z(t)}dt \\ &= 4^n \left(\int^{\pi}_{-\pi} (\cos (t)) ^{2n+1})dt -i  \int^{\pi}_{-\pi} (\cos (t))^{2n} \sin (t) dt \right)\end{align*}$$ Is there a faster way to compute this integral? Does Cauchy's Theorem help here?",,"['integration', 'complex-analysis', 'contour-integration']"
62,Show that $\Gamma(z)\Gamma(1-z) \sin \pi z$ is bounded in the complex plane,Show that  is bounded in the complex plane,\Gamma(z)\Gamma(1-z) \sin \pi z,"Attempt I know that $\Gamma(z)=\int_0^\infty e^{-t}t^{z-1} \ dt$ so $$\lvert \Gamma(z) \rvert \leq \int_0^\infty e^{-t}|t^{z-1}| \ dt=\int_0^{\infty} \frac{e^{-t}}{t} t^{\Re(z)} dt .$$ After this, I'm not really sure what more I can do. Edit I am actually trying to show that $$\frac{\pi}{\sin \pi z} =\Gamma(z) \Gamma(1-z)$$ without resorting to contour integration. However I am beginning to think that showing that this function is bounded might be more work than just carrying out the integration. Sorry for the lack of background in the original question.","Attempt I know that $\Gamma(z)=\int_0^\infty e^{-t}t^{z-1} \ dt$ so $$\lvert \Gamma(z) \rvert \leq \int_0^\infty e^{-t}|t^{z-1}| \ dt=\int_0^{\infty} \frac{e^{-t}}{t} t^{\Re(z)} dt .$$ After this, I'm not really sure what more I can do. Edit I am actually trying to show that $$\frac{\pi}{\sin \pi z} =\Gamma(z) \Gamma(1-z)$$ without resorting to contour integration. However I am beginning to think that showing that this function is bounded might be more work than just carrying out the integration. Sorry for the lack of background in the original question.",,"['complex-analysis', 'gamma-function', 'beta-function']"
63,Branch of the cube root,Branch of the cube root,,"Let $f(z)=z^{1/3}$ be the branch of the cube root whose domain of definition is given by $0<\theta<2\pi$, $z\neq 0$ (i.e. the branch cut is along the ray $\theta=0$.) Find $f(-i)$. Could someone please help me understand the question? I'm not too clear on ""branches"" and ""branch cuts"".","Let $f(z)=z^{1/3}$ be the branch of the cube root whose domain of definition is given by $0<\theta<2\pi$, $z\neq 0$ (i.e. the branch cut is along the ray $\theta=0$.) Find $f(-i)$. Could someone please help me understand the question? I'm not too clear on ""branches"" and ""branch cuts"".",,"['complex-analysis', 'complex-numbers']"
64,Show that the complex function f is continuous at the given point,Show that the complex function f is continuous at the given point,,"Show that the function $f$ is continuous at the given point $$f(z) =\begin{cases} \dfrac{z^3 - 1}{z-1} & \text{if } |z| \neq 1  \\[6pt] 3 & \text{if } |z| = 1 \\ \end{cases}$$ $z_0 = 1$ I have the following definition for the Limit of a Complex Function: Suppose that a complex function $f$ is defined in a deleted neighborhood of $z_0$ and suppose that $L$ is a complex number. The limit of $f$ as $z$ tends to $z_0$ exists and is equal to $L$, written as $\lim\limits_{z \to z_0} f(z) = L$ if for every $\epsilon > 0$ there exists a $\delta > 0$ such that $\vert f(z) - L \vert < \epsilon $ whenever $0 < \vert z - z_0 \vert < \delta$. My intuition is to start with $\vert f(z) - L \vert < \epsilon$ and manipulate this until the expression on the left looks like $\vert z-z_0 \vert$. From there, I figured I would have identified an appropriate value for my $\delta$ and used it to work forward for my proof. However, I got a little stuck with the manipulation. I can see that for $z = z_0 = 1$ that $\vert z_0 \vert = 1$ and so $f(z_0) = 3$ immediately. When I work in the neighborhood of $z_0$ for $\vert z \vert \neq 1$ that I do approach $3$. I've decided to try an epsilon/delta proof for the condition that $vert z \vert \neq 1$. Here's what I've done so far: $$ \begin{align} f(z) & = \frac{z^3 - 1}{z-1}  \\[6pt]      & = \frac{z^3 - 1^3}{z-1} \\[6pt]      & = \frac{(z-1)(z^2 + z + 1^2)}{z-1} \\[6pt]      & = z^2 + z + 1         \end{align} $$ From here, I can plug this alternate form of $f(z)$ into $\vert f(z) - L \vert < \epsilon$ and continue to manipulate: $$ \begin{align} \varepsilon & > \vert (z^2 + z + 1) - (3) \vert  \\[6pt]      & = \vert z^2 + z - 2 \vert \\[6pt]      & = \vert (z-1)(z+2) \vert \end{align} $$ This is where I'm stuck. I don't think that I can just divide $\epsilon$ by $\vert z+2 \vert$ because that would make it depend on the variable $z$ which defeats setting a fixed value for $\delta$. What am I supposed to do here?","Show that the function $f$ is continuous at the given point $$f(z) =\begin{cases} \dfrac{z^3 - 1}{z-1} & \text{if } |z| \neq 1  \\[6pt] 3 & \text{if } |z| = 1 \\ \end{cases}$$ $z_0 = 1$ I have the following definition for the Limit of a Complex Function: Suppose that a complex function $f$ is defined in a deleted neighborhood of $z_0$ and suppose that $L$ is a complex number. The limit of $f$ as $z$ tends to $z_0$ exists and is equal to $L$, written as $\lim\limits_{z \to z_0} f(z) = L$ if for every $\epsilon > 0$ there exists a $\delta > 0$ such that $\vert f(z) - L \vert < \epsilon $ whenever $0 < \vert z - z_0 \vert < \delta$. My intuition is to start with $\vert f(z) - L \vert < \epsilon$ and manipulate this until the expression on the left looks like $\vert z-z_0 \vert$. From there, I figured I would have identified an appropriate value for my $\delta$ and used it to work forward for my proof. However, I got a little stuck with the manipulation. I can see that for $z = z_0 = 1$ that $\vert z_0 \vert = 1$ and so $f(z_0) = 3$ immediately. When I work in the neighborhood of $z_0$ for $\vert z \vert \neq 1$ that I do approach $3$. I've decided to try an epsilon/delta proof for the condition that $vert z \vert \neq 1$. Here's what I've done so far: $$ \begin{align} f(z) & = \frac{z^3 - 1}{z-1}  \\[6pt]      & = \frac{z^3 - 1^3}{z-1} \\[6pt]      & = \frac{(z-1)(z^2 + z + 1^2)}{z-1} \\[6pt]      & = z^2 + z + 1         \end{align} $$ From here, I can plug this alternate form of $f(z)$ into $\vert f(z) - L \vert < \epsilon$ and continue to manipulate: $$ \begin{align} \varepsilon & > \vert (z^2 + z + 1) - (3) \vert  \\[6pt]      & = \vert z^2 + z - 2 \vert \\[6pt]      & = \vert (z-1)(z+2) \vert \end{align} $$ This is where I'm stuck. I don't think that I can just divide $\epsilon$ by $\vert z+2 \vert$ because that would make it depend on the variable $z$ which defeats setting a fixed value for $\delta$. What am I supposed to do here?",,"['complex-analysis', 'continuity', 'epsilon-delta']"
65,Simple linear map question,Simple linear map question,,"I am struggling with a very simple question. I need to show that any linear map $\mathbb{C}\to\mathbb{C}$ has the form: $$f(z)=\alpha z+\beta\, \bar z,\quad \alpha,\beta\in\mathbb{C}$$ I thought of relating this to an arbitrary matrix but I can't see how to do it. Can someone nudge me in the right direction?","I am struggling with a very simple question. I need to show that any linear map $\mathbb{C}\to\mathbb{C}$ has the form: $$f(z)=\alpha z+\beta\, \bar z,\quad \alpha,\beta\in\mathbb{C}$$ I thought of relating this to an arbitrary matrix but I can't see how to do it. Can someone nudge me in the right direction?",,"['complex-analysis', 'linear-transformations']"
66,Bounded Holomorphic function on Right half plane.,Bounded Holomorphic function on Right half plane.,,Does there exist a Bounded Holomorphic function defined on Right half plane which have all $\sqrt{n}$ as root for all natural number $n$? I guess It is a just $0$ function. But How Could I approach this one? (I've been trying to use Blascke product.) Thanks!,Does there exist a Bounded Holomorphic function defined on Right half plane which have all $\sqrt{n}$ as root for all natural number $n$? I guess It is a just $0$ function. But How Could I approach this one? (I've been trying to use Blascke product.) Thanks!,,['complex-analysis']
67,Residue theorem with pole on integration path,Residue theorem with pole on integration path,,I have to calculate the inverse Laplace transform of $\dfrac{1}{s^2+1}$ (which I know is sin(x)) by residue theorem: $\int^{i \infty}_{-i \infty}exp(t\cdot s)\cdot \dfrac{1}{s^2+1}\mathrm{d}s$. Therefore I want to integrate over a vertical semicircle and show that the integral over the circular arc is zero. However I can only apply the theorem if the path goes around the poles i and -i. I haven't found something on this topic yet. Thanks for helping!,I have to calculate the inverse Laplace transform of $\dfrac{1}{s^2+1}$ (which I know is sin(x)) by residue theorem: $\int^{i \infty}_{-i \infty}exp(t\cdot s)\cdot \dfrac{1}{s^2+1}\mathrm{d}s$. Therefore I want to integrate over a vertical semicircle and show that the integral over the circular arc is zero. However I can only apply the theorem if the path goes around the poles i and -i. I haven't found something on this topic yet. Thanks for helping!,,"['complex-analysis', 'laplace-transform', 'residue-calculus']"
68,Violating Cauchy's Integral Theorem,Violating Cauchy's Integral Theorem,,"With regards to utilizing Cauchy's Integral Theorem for integration over closed contours: https://en.wikipedia.org/wiki/Cauchy%27s_integral_theorem In particular the result that $\int_\gamma f(z)\,dz = 0$ for closed paths $\gamma$ and holomorphic functions $f(z)$. It is stated (and shown algebraically) in numerous tutorials and texts that $f(z)=z^{-1}$ violates the conditions for the above result to hold. But in all elaborations given to this statement it has not been clear to me why this is not also true for $z^{-2}$ (or indeed any $z^{n}$ for integers $n$ smaller than -1). For example, in the Wikipedia article linked, it states: ""The Cauchy integral theorem does not apply here since $f(z)=\frac1 z$   is not defined (and certainly not holomorphic) at $z=0$."" Which I believe is also true for any other $f(z) = \frac 1 {z^n}$. Alternatively, a set of notes from the Columbia's Complex Analysis course state: $1/z$ is analytic in the region $\mathbb C − \{ 0 \} = \{z ∈ \mathbb C > : z \neq 0\}$, but this region is not simply connected. Again believe this also applies to other $f(z) = \frac 1 {z^n}$. Could someone please clarify what exact condition $\frac 1 z$ violates that $\frac 1 {z^n}$ does not? P.S. Some background - I am not a mathematician by training but trying to teach myself for applied research, so answers that favor intuition are greatly appreciated!","With regards to utilizing Cauchy's Integral Theorem for integration over closed contours: https://en.wikipedia.org/wiki/Cauchy%27s_integral_theorem In particular the result that $\int_\gamma f(z)\,dz = 0$ for closed paths $\gamma$ and holomorphic functions $f(z)$. It is stated (and shown algebraically) in numerous tutorials and texts that $f(z)=z^{-1}$ violates the conditions for the above result to hold. But in all elaborations given to this statement it has not been clear to me why this is not also true for $z^{-2}$ (or indeed any $z^{n}$ for integers $n$ smaller than -1). For example, in the Wikipedia article linked, it states: ""The Cauchy integral theorem does not apply here since $f(z)=\frac1 z$   is not defined (and certainly not holomorphic) at $z=0$."" Which I believe is also true for any other $f(z) = \frac 1 {z^n}$. Alternatively, a set of notes from the Columbia's Complex Analysis course state: $1/z$ is analytic in the region $\mathbb C − \{ 0 \} = \{z ∈ \mathbb C > : z \neq 0\}$, but this region is not simply connected. Again believe this also applies to other $f(z) = \frac 1 {z^n}$. Could someone please clarify what exact condition $\frac 1 z$ violates that $\frac 1 {z^n}$ does not? P.S. Some background - I am not a mathematician by training but trying to teach myself for applied research, so answers that favor intuition are greatly appreciated!",,"['complex-analysis', 'intuition', 'contour-integration']"
69,evaluate the path integral around a circle in complex plane,evaluate the path integral around a circle in complex plane,,"Let $a \in \mathbb{C}$ with $|a|>1$. I need to evaluate the path integral around the unit circle in $\mathbb{C}$: $$\int_{|z|=1}\frac{|dz|}{|az-1|^2}$$ where $|dz|$ represents integration with respect to arc-length. My solution is following: Since $z$ is the unit circle, we can rewrite it as $z=x+iy=e^{it}$ with $x=\cos t$ and $y=\sin t$. Hence, $|dz|=dt$ after the required transformations. Also, if $a=re^{i\varphi} (r>1)$, we have: $$\int_{|z|=1}\frac{|dz|}{|az-1|^2}=\int_{0}^{2\pi}\frac{dt}{|re^{i(t+\varphi)}-1|^2}=\int_{0}^{2\pi}\frac{dt}{(r\cos (t+\varphi)-1)^2+r^2\sin (t+\varphi)^2}=\int_{0}^{2\pi}\frac{dt}{r^2+1-2r\cos (t+\varphi)}$$ and then I can try to find out the integral, but it is a little bit challenging. So, my question is if I did everything right? and are there any easier ways to calculate this? Any hints are welcome! Thank you!","Let $a \in \mathbb{C}$ with $|a|>1$. I need to evaluate the path integral around the unit circle in $\mathbb{C}$: $$\int_{|z|=1}\frac{|dz|}{|az-1|^2}$$ where $|dz|$ represents integration with respect to arc-length. My solution is following: Since $z$ is the unit circle, we can rewrite it as $z=x+iy=e^{it}$ with $x=\cos t$ and $y=\sin t$. Hence, $|dz|=dt$ after the required transformations. Also, if $a=re^{i\varphi} (r>1)$, we have: $$\int_{|z|=1}\frac{|dz|}{|az-1|^2}=\int_{0}^{2\pi}\frac{dt}{|re^{i(t+\varphi)}-1|^2}=\int_{0}^{2\pi}\frac{dt}{(r\cos (t+\varphi)-1)^2+r^2\sin (t+\varphi)^2}=\int_{0}^{2\pi}\frac{dt}{r^2+1-2r\cos (t+\varphi)}$$ and then I can try to find out the integral, but it is a little bit challenging. So, my question is if I did everything right? and are there any easier ways to calculate this? Any hints are welcome! Thank you!",,"['complex-analysis', 'contour-integration']"
70,$J=\lambda M$ where $M \in SO(2)$ and $\lambda \in \mathbb{R}$ instead of Cauchy-Riemann,where  and  instead of Cauchy-Riemann,J=\lambda M M \in SO(2) \lambda \in \mathbb{R},"In ""visual complex analysis"" (Tristan Needham), the author explains that an application  $ f : \mathbb{C} \mapsto \mathbb{C} $ is complex differentiable on some domain if and only if it is everywhere locally an ""amplitwist"" [rotation+scaling] on this domain. Then he proceeds to explain the Cauchy-Riemann equations. I found Cauchy-Riemann to be a very poor capture of the above intuition. Indeed, lets start from the beginning: If $ f : \mathbb{R}^2 \mapsto \mathbb{R}^2$ is everywhere differentiable on some open domain $U$ then it can be locally approximated by its jacobian matrix: $$f(x) = f(x_0) + J_f(x_0) ( x - x_0 ) + o(\left\| x-x_0 \right\|) $$ Hence, when asking for complex differentiability: $$f'(z_0) = \lim_{z \rightarrow z_0} \frac{f(z) - f(z_0) }{z-z_0} $$ one asks for: $$f(z) = f(z_0) + f'(z_0) ( z - z_0 ) + o(\left\| z-z_0 \right\|) $$ So the question is in what case can we identify the jacobian with a $J_f(x_0)$ with a complex number $f'(z_0)$ ? The action of the multiplication by a complex $re^{i\theta}$ number can be represented by an ""amplitwist"" hence, the jacobian matrix must be of the form: $$ r  \left(   \begin{matrix}         cos(\theta) & -sin(\theta) \\         sin(\theta) & cos(\theta) \\   \end{matrix}  \right) $$ Indeed, for being well defined $f'(z_0)$ must not depend on the way we approached $z_0$, for example: $$f(z) = \overline{z}$$ has a well defined jacobian matrix $$ \left(   \begin{matrix}         1 & 0 \\         0 & -1 \\   \end{matrix}  \right) $$ but depending on direction the local action of the matrix cannot be identified by a single complex number: $$f'(z_0) = \lim_{h \rightarrow 0} \frac{f(z_0 + h) - f(z_0) }{h} = \frac{\overline{h}}{h} = \frac{re^{-i\theta}}{re^{i\theta} } = e^{-2i\theta}$$ Hence depending on the way you approach $z_0$ the local action of the jacobian is identified with some element of the unit circle. Now, the Cauchy-Riemann equations are always established the same way, by considering that two directional derivatives ( approaching either of the Cartesian axes ) must lead to the same complex number: \begin{equation} f'(z_0) = \lim_{x \rightarrow 0} \frac{f(z_0 + ix) - f(z_0) }{ix} = \lim_{x \rightarrow 0} \frac{f(z_0 + x) - f(z_0) }{x}, x \in \mathbb{R} \tag{1} \end{equation} this leads to the Cauchy-Riemann equations and force the jacobian matrix to be: $$ \left(   \begin{matrix}         a & -b \\         b & a \\   \end{matrix}  \right) $$ but does not enforce any relationship between $a$ and $b$, this matrix only captures the fact that the images of $\vec{x}$ and $\vec{y}$ will be orthogonal with direction preserved. Which is what we enforced by (1) but it does not force every angle to be preserved (conformality). It is easy to build a matrix $$ r  \left(   \begin{matrix}         cos(\theta) & -sin(\phi) \\         sin(\phi) & cos(\theta) \\   \end{matrix}  \right) $$ so that Cauchy-Riemann is respected but the application is not conformal. Then using $Im(z)$ and $Re(z)$ one can make the complex function matching the above jacobian. I beleive the three following are equivalent: $f$ is conformal $f$ has a jacobian matrix $J=\lambda M$ where $M \in SO(2)$ and $\lambda \in \mathbb{R}$ $f$ respects the Cauchy-Riemann equations and every of the four entries $\frac{\partial u}{\partial x}$, $\frac{\partial u}{\partial y}$, $\frac{\partial v}{\partial x}$, $\frac{\partial v}{\partial y}$ are continuous. QUESTIONS I'm not sure how to prove the equivalence between 2 and 3: why would continuity and and angle preservation of two vectors imply angle preservation in general ? the other way around is geometrically more intuitive, as the jacobian is itself the result of a limit, $\lambda$ and $\theta$ of ""nearby"" jacobians must tend to those of jacobian of $z_0$ but I'm not sure how to write it. How to prove above equivalence, and if it is correct, then why using Cauchy-Riemann at all, as it requires the same computations and provides less information than the jacobian characterization ?","In ""visual complex analysis"" (Tristan Needham), the author explains that an application  $ f : \mathbb{C} \mapsto \mathbb{C} $ is complex differentiable on some domain if and only if it is everywhere locally an ""amplitwist"" [rotation+scaling] on this domain. Then he proceeds to explain the Cauchy-Riemann equations. I found Cauchy-Riemann to be a very poor capture of the above intuition. Indeed, lets start from the beginning: If $ f : \mathbb{R}^2 \mapsto \mathbb{R}^2$ is everywhere differentiable on some open domain $U$ then it can be locally approximated by its jacobian matrix: $$f(x) = f(x_0) + J_f(x_0) ( x - x_0 ) + o(\left\| x-x_0 \right\|) $$ Hence, when asking for complex differentiability: $$f'(z_0) = \lim_{z \rightarrow z_0} \frac{f(z) - f(z_0) }{z-z_0} $$ one asks for: $$f(z) = f(z_0) + f'(z_0) ( z - z_0 ) + o(\left\| z-z_0 \right\|) $$ So the question is in what case can we identify the jacobian with a $J_f(x_0)$ with a complex number $f'(z_0)$ ? The action of the multiplication by a complex $re^{i\theta}$ number can be represented by an ""amplitwist"" hence, the jacobian matrix must be of the form: $$ r  \left(   \begin{matrix}         cos(\theta) & -sin(\theta) \\         sin(\theta) & cos(\theta) \\   \end{matrix}  \right) $$ Indeed, for being well defined $f'(z_0)$ must not depend on the way we approached $z_0$, for example: $$f(z) = \overline{z}$$ has a well defined jacobian matrix $$ \left(   \begin{matrix}         1 & 0 \\         0 & -1 \\   \end{matrix}  \right) $$ but depending on direction the local action of the matrix cannot be identified by a single complex number: $$f'(z_0) = \lim_{h \rightarrow 0} \frac{f(z_0 + h) - f(z_0) }{h} = \frac{\overline{h}}{h} = \frac{re^{-i\theta}}{re^{i\theta} } = e^{-2i\theta}$$ Hence depending on the way you approach $z_0$ the local action of the jacobian is identified with some element of the unit circle. Now, the Cauchy-Riemann equations are always established the same way, by considering that two directional derivatives ( approaching either of the Cartesian axes ) must lead to the same complex number: \begin{equation} f'(z_0) = \lim_{x \rightarrow 0} \frac{f(z_0 + ix) - f(z_0) }{ix} = \lim_{x \rightarrow 0} \frac{f(z_0 + x) - f(z_0) }{x}, x \in \mathbb{R} \tag{1} \end{equation} this leads to the Cauchy-Riemann equations and force the jacobian matrix to be: $$ \left(   \begin{matrix}         a & -b \\         b & a \\   \end{matrix}  \right) $$ but does not enforce any relationship between $a$ and $b$, this matrix only captures the fact that the images of $\vec{x}$ and $\vec{y}$ will be orthogonal with direction preserved. Which is what we enforced by (1) but it does not force every angle to be preserved (conformality). It is easy to build a matrix $$ r  \left(   \begin{matrix}         cos(\theta) & -sin(\phi) \\         sin(\phi) & cos(\theta) \\   \end{matrix}  \right) $$ so that Cauchy-Riemann is respected but the application is not conformal. Then using $Im(z)$ and $Re(z)$ one can make the complex function matching the above jacobian. I beleive the three following are equivalent: $f$ is conformal $f$ has a jacobian matrix $J=\lambda M$ where $M \in SO(2)$ and $\lambda \in \mathbb{R}$ $f$ respects the Cauchy-Riemann equations and every of the four entries $\frac{\partial u}{\partial x}$, $\frac{\partial u}{\partial y}$, $\frac{\partial v}{\partial x}$, $\frac{\partial v}{\partial y}$ are continuous. QUESTIONS I'm not sure how to prove the equivalence between 2 and 3: why would continuity and and angle preservation of two vectors imply angle preservation in general ? the other way around is geometrically more intuitive, as the jacobian is itself the result of a limit, $\lambda$ and $\theta$ of ""nearby"" jacobians must tend to those of jacobian of $z_0$ but I'm not sure how to write it. How to prove above equivalence, and if it is correct, then why using Cauchy-Riemann at all, as it requires the same computations and provides less information than the jacobian characterization ?",,['complex-analysis']
71,Sequence of analytic function with range in $\mathbb{H}$ converges locally uniformly,Sequence of analytic function with range in  converges locally uniformly,\mathbb{H},Let $G$ be a region and let $h_n :G\rightarrow \mathbb{C}$ be analyic maps such that $h_n (G) \subset \{\Im z >0\}$. Assume there is a $z_0 \in G$ such that $h_n (z_0) \rightarrow 0$. Prove that $h_n$ converges uniformly in compact subsets of $G$ to $0$. Any hint here is appreciated. I am not exactly sure how to use what we know about $z_0$. My guess is that the limit being $0$ and $0$ being on $\partial \mathbb{H}$ are related. Is this possibly a Schwarz reflection problem?,Let $G$ be a region and let $h_n :G\rightarrow \mathbb{C}$ be analyic maps such that $h_n (G) \subset \{\Im z >0\}$. Assume there is a $z_0 \in G$ such that $h_n (z_0) \rightarrow 0$. Prove that $h_n$ converges uniformly in compact subsets of $G$ to $0$. Any hint here is appreciated. I am not exactly sure how to use what we know about $z_0$. My guess is that the limit being $0$ and $0$ being on $\partial \mathbb{H}$ are related. Is this possibly a Schwarz reflection problem?,,['complex-analysis']
72,Mapping the region $\Gamma_{z}$ using the conformal map $ \omega=\frac{-2z}{z^{2}+1}$,Mapping the region  using the conformal map,\Gamma_{z}  \omega=\frac{-2z}{z^{2}+1},"Suppose we have an analytic function $$ \omega=\frac{-2z}{z^{2}+1}$$ and the region $\Gamma_{z}$ given by $$\Gamma_{z}:=\left \{ z \in \mathbb{C}| \Im \left ( z \right )\geq 0 \wedge \left | z \right |\geq 1\right \}$$ As with many other problems of this type I tried to break it down into several conformal mapping compositions. For example, it would be very elegant to algebraically manipulate the expression for $\omega$ in such a way that it only has  $z^{2}$, and then first map $z \mapsto \omega_{1}=z^{2}$, and at last do the map $\omega_{1} \mapsto \omega$, where $\omega$ is a Möbius transform, ideally. However, I wasn't able to do so, and perhaps someone can suggest a different approach here.","Suppose we have an analytic function $$ \omega=\frac{-2z}{z^{2}+1}$$ and the region $\Gamma_{z}$ given by $$\Gamma_{z}:=\left \{ z \in \mathbb{C}| \Im \left ( z \right )\geq 0 \wedge \left | z \right |\geq 1\right \}$$ As with many other problems of this type I tried to break it down into several conformal mapping compositions. For example, it would be very elegant to algebraically manipulate the expression for $\omega$ in such a way that it only has  $z^{2}$, and then first map $z \mapsto \omega_{1}=z^{2}$, and at last do the map $\omega_{1} \mapsto \omega$, where $\omega$ is a Möbius transform, ideally. However, I wasn't able to do so, and perhaps someone can suggest a different approach here.",,"['complex-analysis', 'analyticity', 'conformal-geometry']"
73,Elliptic Curve as Sphere with 4 Punctures?,Elliptic Curve as Sphere with 4 Punctures?,,"I saw an informal comment somewhere about taking a Riemann sphere with four punctures and generating all possible elliptic curves.  I was hoping someone could describe for me how this construction goes?  Or possibly point me to online literature? If I had to guess, I feel like given four points on the sphere, you could connect them pairwise with branch cuts, and glue these two cuts together to get the torus/elliptic curve.  I know that any two Riemann spheres with three punctures are biholomorphic, so is the idea that the fourth puncture treated as a moduli which turns into the modular parameter $\tau$ of the elliptic curve?  Kind of like a change of variables, or so?","I saw an informal comment somewhere about taking a Riemann sphere with four punctures and generating all possible elliptic curves.  I was hoping someone could describe for me how this construction goes?  Or possibly point me to online literature? If I had to guess, I feel like given four points on the sphere, you could connect them pairwise with branch cuts, and glue these two cuts together to get the torus/elliptic curve.  I know that any two Riemann spheres with three punctures are biholomorphic, so is the idea that the fourth puncture treated as a moduli which turns into the modular parameter $\tau$ of the elliptic curve?  Kind of like a change of variables, or so?",,"['complex-analysis', 'number-theory', 'algebraic-geometry']"
74,How can I justify that the partial sums of $\frac{(2n)^k}{k!}$ is less than the number $\frac{(2n)^n}{n!}$?,How can I justify that the partial sums of  is less than the number ?,\frac{(2n)^k}{k!} \frac{(2n)^n}{n!},"I am currently using Rouche's Theorem from complex analysis but am working on an upper bound and want to show $$\sum_{k=0}^{n-1}\frac{(2n)^k}{k!}< \frac{(2n)^n}{n!}$$ Any suggestions are welcome. Thanks,","I am currently using Rouche's Theorem from complex analysis but am working on an upper bound and want to show $$\sum_{k=0}^{n-1}\frac{(2n)^k}{k!}< \frac{(2n)^n}{n!}$$ Any suggestions are welcome. Thanks,",,"['calculus', 'sequences-and-series', 'complex-analysis', 'inequality', 'power-series']"
75,Calculating $Log(-e i)$,Calculating,Log(-e i),$$Log(-e i)$$ My try: $$=\ln|0+(-e)i|+i[\arg (0+(-e i))+2\pi k]$$ $$=\ln|e i|+i(-\frac{\pi}{2}+2\pi k)$$ My attempt is correct?,$$Log(-e i)$$ My try: $$=\ln|0+(-e)i|+i[\arg (0+(-e i))+2\pi k]$$ $$=\ln|e i|+i(-\frac{\pi}{2}+2\pi k)$$ My attempt is correct?,,['complex-analysis']
76,Show that $f(0) + f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)e^w}{w^2}dw$,Show that,f(0) + f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)e^w}{w^2}dw,"Let f be holomorphic on a region containing the closed unit disk $D(0, 1)$ and C be the unit circle traversed anticlockwise. Let n be a positive integer. Show that $$f(0) + f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)e^w}{w^2}dw$$ and that $$\frac{1}{2\pi i} \int_C\frac{f(w)+f(e^{2\pi i/n}w)+...+f(e^{2(n-1)\pi i/n}w)}{w^2}dw=0$$ I am not allowed to use the residue theorem. I know that $f(0)=\frac{1}{2\pi i} \int_C\frac{f(w)}{w}dw$ and $f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)}{w^2}dw$ but that only gets me to $f(0) + f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)(w+1)}{w^2}dw$. For the second part I tried writing every term within the integral as $\frac{f(e^{2(n-1)\pi i/n}w)}{w^2 {(e^{2(n-1)\pi i/n})}^2}*{(e^{2(n-1)\pi i/n})}^2$ but to no avail as I get to $f'(0) + ... + \frac{f'(0)}{{(e^{2(n-1)\pi i/n})^2}}$. Any hints/tips would be greatly appreciated. Thanks.","Let f be holomorphic on a region containing the closed unit disk $D(0, 1)$ and C be the unit circle traversed anticlockwise. Let n be a positive integer. Show that $$f(0) + f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)e^w}{w^2}dw$$ and that $$\frac{1}{2\pi i} \int_C\frac{f(w)+f(e^{2\pi i/n}w)+...+f(e^{2(n-1)\pi i/n}w)}{w^2}dw=0$$ I am not allowed to use the residue theorem. I know that $f(0)=\frac{1}{2\pi i} \int_C\frac{f(w)}{w}dw$ and $f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)}{w^2}dw$ but that only gets me to $f(0) + f'(0)=\frac{1}{2\pi i} \int_C\frac{f(w)(w+1)}{w^2}dw$. For the second part I tried writing every term within the integral as $\frac{f(e^{2(n-1)\pi i/n}w)}{w^2 {(e^{2(n-1)\pi i/n})}^2}*{(e^{2(n-1)\pi i/n})}^2$ but to no avail as I get to $f'(0) + ... + \frac{f'(0)}{{(e^{2(n-1)\pi i/n})^2}}$. Any hints/tips would be greatly appreciated. Thanks.",,"['complex-analysis', 'contour-integration', 'cauchy-integral-formula']"
77,"Showing that $\overline{\int_{\gamma}f(z)\,dz}=\int_{\overline{\gamma}}\overline{f\left(\overline{z}\right)}\,dz$",Showing that,"\overline{\int_{\gamma}f(z)\,dz}=\int_{\overline{\gamma}}\overline{f\left(\overline{z}\right)}\,dz","Let $\gamma$ be a piecewise- $C^1$ curve, and let $\overline{\gamma}$ be its image under the mapping $z\mapsto \overline{z}$ (symmetry in the real axis). I am trying to show that if $f(z)$ is continuous on $\gamma$ , then $z\mapsto \overline{f\left(\overline{z}\right)}$ is continuous on $\overline{\gamma}$ , and $$\overline{\int_{\gamma}f(z)\,dz}=\int_{\overline{\gamma}}\overline{f\left(\overline{z}\right)}\,dz$$ I think for the first part I just need to use the usual definition of continuity, but does this apply for continuity on the curve as well? I'm not sure how to approach the second part.","Let be a piecewise- curve, and let be its image under the mapping (symmetry in the real axis). I am trying to show that if is continuous on , then is continuous on , and I think for the first part I just need to use the usual definition of continuity, but does this apply for continuity on the curve as well? I'm not sure how to approach the second part.","\gamma C^1 \overline{\gamma} z\mapsto \overline{z} f(z) \gamma z\mapsto \overline{f\left(\overline{z}\right)} \overline{\gamma} \overline{\int_{\gamma}f(z)\,dz}=\int_{\overline{\gamma}}\overline{f\left(\overline{z}\right)}\,dz","['complex-analysis', 'complex-integration']"
78,Differentiating a contour integral,Differentiating a contour integral,,"Let $P(z, t)$ be a cubic with the parameter $t$, and consider $$\mathcal{I} = \int_{\gamma(t)} \frac{dz}{\sqrt{P(z, t)}}.$$ Here, $\gamma(t)$ is a contour in the complex plane that encloses any two of the three roots of $P(z, t)$ and does not go through the third. Since the roots are given in terms of $t$, the path $\gamma(t)$ is a function of $t$. I would like to differentiate $\mathcal{I}$ under the integral sign with respect to $t$. Is it permissible? Could someone point me to a theorem I could use or help me prove it directly?","Let $P(z, t)$ be a cubic with the parameter $t$, and consider $$\mathcal{I} = \int_{\gamma(t)} \frac{dz}{\sqrt{P(z, t)}}.$$ Here, $\gamma(t)$ is a contour in the complex plane that encloses any two of the three roots of $P(z, t)$ and does not go through the third. Since the roots are given in terms of $t$, the path $\gamma(t)$ is a function of $t$. I would like to differentiate $\mathcal{I}$ under the integral sign with respect to $t$. Is it permissible? Could someone point me to a theorem I could use or help me prove it directly?",,"['complex-analysis', 'derivatives', 'complex-integration']"
79,What are the entire functions that commute with the exponential function?,What are the entire functions that commute with the exponential function?,,"I am looking for entire functions $f(z)$ that satisfy $f(\exp(z))=\exp(f(z))$ on $\mathbb{C}$. I see that this is satisfied by $e^z$, $z$, and constant functions where the constant is a solution of $e^c=c$. Are there any other entire functions that commute with the exponential?","I am looking for entire functions $f(z)$ that satisfy $f(\exp(z))=\exp(f(z))$ on $\mathbb{C}$. I see that this is satisfied by $e^z$, $z$, and constant functions where the constant is a solution of $e^c=c$. Are there any other entire functions that commute with the exponential?",,['complex-analysis']
80,Analytic function on an open disc.,Analytic function on an open disc.,,Let $\mathbb{D}=\{ z\in\mathbb{C}:|z|<1\}$. Which of the following are correct? There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(0)=0$ and $f'(0)=2$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(3/4)=3/4$ and $f'(2/3)=3/4$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(3/4)=-3/4$ and $f'(3/4)=-3/4$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(1/2)=-1/2$ and $f'(1/4)=1.$ Option one is not true by Schwartz-lemma. But i don't know how to think about other options. I  don't know which theorem or result gives condition of existence of this type of holomorphic function. Please help me to solve this problem. If possible please solve this problem. Thanks in advance.,Let $\mathbb{D}=\{ z\in\mathbb{C}:|z|<1\}$. Which of the following are correct? There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(0)=0$ and $f'(0)=2$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(3/4)=3/4$ and $f'(2/3)=3/4$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(3/4)=-3/4$ and $f'(3/4)=-3/4$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(1/2)=-1/2$ and $f'(1/4)=1.$ Option one is not true by Schwartz-lemma. But i don't know how to think about other options. I  don't know which theorem or result gives condition of existence of this type of holomorphic function. Please help me to solve this problem. If possible please solve this problem. Thanks in advance.,,['complex-analysis']
81,How to interpret the plot of a function of a complex variable?,How to interpret the plot of a function of a complex variable?,,"I know what a complex number is: $a+bi$. But I have seen these functions that make no sense to me, something such as this: $$f(z)=z^2+1$$ where $z$ is a complex number. Does this have to do with that plane where the ""y""-axis is Real numbers and the ""x""-axis is Imaginary numbers? I typed it into this complex grapher http://davidbau.com/conformal/#z%5E2%2B1 and I am utterly confused. What's with all the colors? What's with that weird 8 shape?","I know what a complex number is: $a+bi$. But I have seen these functions that make no sense to me, something such as this: $$f(z)=z^2+1$$ where $z$ is a complex number. Does this have to do with that plane where the ""y""-axis is Real numbers and the ""x""-axis is Imaginary numbers? I typed it into this complex grapher http://davidbau.com/conformal/#z%5E2%2B1 and I am utterly confused. What's with all the colors? What's with that weird 8 shape?",,"['complex-analysis', 'complex-numbers', 'graphing-functions']"
82,Find : $\sqrt[6]{\frac{\sqrt{2}+(-\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^7}{(\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^{11}}}$ in its algebraic form.,Find :  in its algebraic form.,\sqrt[6]{\frac{\sqrt{2}+(-\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^7}{(\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^{11}}},"Find : $$\sqrt[6]{\frac{\sqrt{2}+(-\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^7}{(\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^{11}}}$$ in its algebraic form. Now, I kinda think it would not be wise to try to expand this, but rather apply de Moivre formula on the complex number in the numerator and denominator, then simplify that complex number within the root, and once again apply moivres formula. I have tried but then I get the expression:$\sqrt[6]{\frac{\sqrt{2}+\cos{\frac{21 \pi}{4}+i\sin{\frac{21 \pi }{4}}}}{\cos \frac{11\pi}{4}+i\sin\frac{11 \pi}{4}}}$ and don't know what to do with it.","Find : $$\sqrt[6]{\frac{\sqrt{2}+(-\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^7}{(\frac{\sqrt{2}}{2}+\frac{\sqrt{2}}{2}i)^{11}}}$$ in its algebraic form. Now, I kinda think it would not be wise to try to expand this, but rather apply de Moivre formula on the complex number in the numerator and denominator, then simplify that complex number within the root, and once again apply moivres formula. I have tried but then I get the expression:$\sqrt[6]{\frac{\sqrt{2}+\cos{\frac{21 \pi}{4}+i\sin{\frac{21 \pi }{4}}}}{\cos \frac{11\pi}{4}+i\sin\frac{11 \pi}{4}}}$ and don't know what to do with it.",,"['calculus', 'complex-analysis', 'complex-numbers']"
83,"Is it possible to prove $\int _\gamma f \, dz \ne 0$ with Green's Theorem",Is it possible to prove  with Green's Theorem,"\int _\gamma f \, dz \ne 0","Let $U$ be an open subset of $\Bbb C$, and let $f : U \to \Bbb C$ be an analytic function. Let $\gamma$ be a closed curve in $U$. Prove or disprove that $\int _\gamma f\, dz =0$. I started with Green's Theorem: Let $z=x+iy$ and let $\Omega$ be the interior of $\gamma$. We have, $$\int _\gamma f(z) \, dz = i \iint_\Omega \left ( \frac {\partial f}{\partial x} +  i \frac {\partial f}{\partial y}\right )$$ Suppose $U$ not simply connected such that there exists a subset of $\Omega$, $ \Omega'$, such that $\Omega'$ is not in $U$. In $\Omega'$, $f$ is not defined. This is where I am stuck. Since $f$ is not defined does it disprove the statement or can I just not use Green's Theorem?","Let $U$ be an open subset of $\Bbb C$, and let $f : U \to \Bbb C$ be an analytic function. Let $\gamma$ be a closed curve in $U$. Prove or disprove that $\int _\gamma f\, dz =0$. I started with Green's Theorem: Let $z=x+iy$ and let $\Omega$ be the interior of $\gamma$. We have, $$\int _\gamma f(z) \, dz = i \iint_\Omega \left ( \frac {\partial f}{\partial x} +  i \frac {\partial f}{\partial y}\right )$$ Suppose $U$ not simply connected such that there exists a subset of $\Omega$, $ \Omega'$, such that $\Omega'$ is not in $U$. In $\Omega'$, $f$ is not defined. This is where I am stuck. Since $f$ is not defined does it disprove the statement or can I just not use Green's Theorem?",,['complex-analysis']
84,Prove that $\forall z \in \Bbb C : \lvert \Re(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z)\rvert$,Prove that,\forall z \in \Bbb C : \lvert \Re(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z)\rvert,I'm having difficulties trying to prove these two complex inequalities : $\forall z \in \Bbb C :$ $$\lvert \Re(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z)\rvert$$ $$\lvert \Im(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z) \rvert$$ By the defintion of the modulus of a complex number we have : $$\lvert z \rvert = \lvert x+iy \rvert = \sqrt{x^2+y^2} = [(\Re(z))^2 + (\Im(z))^2]^{1/2}$$ If I square both side of the equality I get : $${\lvert z \rvert}^2 = (\Re(z))^2 + (\Im(z))^2$$ but I don't know how to continue from here.,I'm having difficulties trying to prove these two complex inequalities : $\forall z \in \Bbb C :$ $$\lvert \Re(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z)\rvert$$ $$\lvert \Im(z) \rvert \le \lvert z \rvert \le \lvert \Re(z) \rvert + \lvert \Im(z) \rvert$$ By the defintion of the modulus of a complex number we have : $$\lvert z \rvert = \lvert x+iy \rvert = \sqrt{x^2+y^2} = [(\Re(z))^2 + (\Im(z))^2]^{1/2}$$ If I square both side of the equality I get : $${\lvert z \rvert}^2 = (\Re(z))^2 + (\Im(z))^2$$ but I don't know how to continue from here.,,"['complex-analysis', 'inequality', 'complex-numbers']"
85,Is sudden appearance of poles possible?,Is sudden appearance of poles possible?,,"I was thinking about the following scenario: For $|\epsilon|<1$ let $f_\epsilon(z)$ be a meromorphic function such that $f_0(z)$ has a pole at the origin for $\epsilon \neq 0$, $f_\epsilon(z)$ is entire. Is this possible, if we assume the $f_\epsilon$ depends ""nicely"" on $\epsilon$ (e.g. continuously)? I want to say no, but I can't quite prove this. Thanks!","I was thinking about the following scenario: For $|\epsilon|<1$ let $f_\epsilon(z)$ be a meromorphic function such that $f_0(z)$ has a pole at the origin for $\epsilon \neq 0$, $f_\epsilon(z)$ is entire. Is this possible, if we assume the $f_\epsilon$ depends ""nicely"" on $\epsilon$ (e.g. continuously)? I want to say no, but I can't quite prove this. Thanks!",,"['complex-analysis', 'analyticity']"
86,Question about complex analysis in proof in Ingham,Question about complex analysis in proof in Ingham,,"This is a detail from a proof in Ingham's Distribution of Prime Numbers, p. 91-92. He forms a Dirichlet integral and assumes for contradiction that the numerator $c(x)\geq 0.$ Then he bounds $f(s)$ in order to find an inequality for a constant $k$ that is inherently contradictory. My question is about the details of the complex algebra in the penultimate step. Note, $k\neq K.$ Assume RH. $k$ is a positive constant. $$c(x) = \frac{\psi(x)- x + k x^{1/2}}{x},$$ then for $\sigma > 1$ we have $f(s)=\int_1^{\infty}\frac{c(x)}{x^s}dx$ in which $$f(s) = -\frac{1\zeta'}{s\zeta}(s)-\frac{1}{s-1}+\frac{k}{s-1/2}$$ For $\sigma > 1/2$ there are no singularities of $f$ on the real line, and so the abscissa of convergence is $1/2.$ Suppose (for contradiction) $c(x) \geq 0$ for all $x>X (>1).$ Leaving out some detail we get $ | f (\sigma+ t i) | \leq \int_1^X   \frac{ | c(x |)}{x^{\sigma}}dx +\int_X^{\infty} \frac{c(x)}{x^{\sigma}} dx = ...\leq K+ f(\sigma),$ with K independent of $\sigma, t.$ Take $t = \gamma_1,$ where $1/2 + \gamma_1 i$ is the zero with the least positive $\gamma,$ multiply both sides by $(\sigma -1/2),$ and let $\sigma \to (1/2 + 0);$ this gives $$ \frac{m_1}{|1/2 + \gamma_1|}\leq k$$ where $m_1$ is the multiplicity of the zero $1/2 + \gamma_1.$ The part in yellow is verbatim. Can someone explain the details of this step?","This is a detail from a proof in Ingham's Distribution of Prime Numbers, p. 91-92. He forms a Dirichlet integral and assumes for contradiction that the numerator Then he bounds in order to find an inequality for a constant that is inherently contradictory. My question is about the details of the complex algebra in the penultimate step. Note, Assume RH. is a positive constant. then for we have in which For there are no singularities of on the real line, and so the abscissa of convergence is Suppose (for contradiction) for all Leaving out some detail we get with K independent of Take where is the zero with the least positive multiply both sides by and let this gives where is the multiplicity of the zero The part in yellow is verbatim. Can someone explain the details of this step?","c(x)\geq 0. f(s) k k\neq K. k c(x) = \frac{\psi(x)- x + k x^{1/2}}{x}, \sigma > 1 f(s)=\int_1^{\infty}\frac{c(x)}{x^s}dx f(s) = -\frac{1\zeta'}{s\zeta}(s)-\frac{1}{s-1}+\frac{k}{s-1/2} \sigma > 1/2 f 1/2. c(x) \geq 0 x>X (>1).  | f (\sigma+ t i) | \leq \int_1^X   \frac{ | c(x |)}{x^{\sigma}}dx +\int_X^{\infty} \frac{c(x)}{x^{\sigma}} dx = ...\leq K+ f(\sigma), \sigma, t. t = \gamma_1, 1/2 + \gamma_1 i \gamma, (\sigma -1/2), \sigma \to (1/2 + 0);  \frac{m_1}{|1/2 + \gamma_1|}\leq k m_1 1/2 + \gamma_1.","['complex-analysis', 'analytic-number-theory', 'riemann-zeta']"
87,How can I map a wedge onto the unit disk?,How can I map a wedge onto the unit disk?,,"The wedge is given by $0< \arg(z) < \alpha \pi$, for $0 < \alpha <1$. If I use the complex logarithm, principal branch $-\pi < 0 \le \pi$, then $$z \mapsto w = \operatorname{Log}(z)$$ $$ = \ln|z|+ i\arg(z)$$ $$= u+iv$$ so that $0<v<\alpha\pi$, which shows that the wedge maps onto a semi-infinite, horizontal half-strip, with height ranging from $0$ to $\alpha \pi$. What can I do next?  Is the Logarithm mapping even a good start?  I usually like it, when I see a circular region that I have to start with, but not for very great reasons other than that I know what the mapping does to a circular region... Thanks,","The wedge is given by $0< \arg(z) < \alpha \pi$, for $0 < \alpha <1$. If I use the complex logarithm, principal branch $-\pi < 0 \le \pi$, then $$z \mapsto w = \operatorname{Log}(z)$$ $$ = \ln|z|+ i\arg(z)$$ $$= u+iv$$ so that $0<v<\alpha\pi$, which shows that the wedge maps onto a semi-infinite, horizontal half-strip, with height ranging from $0$ to $\alpha \pi$. What can I do next?  Is the Logarithm mapping even a good start?  I usually like it, when I see a circular region that I have to start with, but not for very great reasons other than that I know what the mapping does to a circular region... Thanks,",,"['complex-analysis', 'geometry', 'linear-transformations', 'conformal-geometry', 'mobius-transformation']"
88,isometry of the complex plane,isometry of the complex plane,,"Prove that any isometry is of one of the forms $$z \mapsto az+b, \ \ \ \ \  z \mapsto a\bar z +b$$ where $|a|=1$ How should one prove this for all possible isometries? My textbook, Algebra and Geometry, gives a proof that I cannot understand. Suppose $F$ is any isometry, and let $$F_1(z)={{F(z)-F(0)}\over {F(1)-F(0)}}$$ Then $|F(1)-F(0)|=1$ so that $F_1$ is an isometry with $F_1(0)=0$ and $F_1(1)=1$. This implies that $F_1(i)$ is $i$ or $-i$, and we deduce that either $F_1(z)=z$ or $F_1(z)=\bar z$ for all $z$ My problem with the above proof is, how could one deduce that $|F(1)-F(0)|=1$ and how can one deduce, then, that $F_1(i)=i \ \text{or} -1$??","Prove that any isometry is of one of the forms $$z \mapsto az+b, \ \ \ \ \  z \mapsto a\bar z +b$$ where $|a|=1$ How should one prove this for all possible isometries? My textbook, Algebra and Geometry, gives a proof that I cannot understand. Suppose $F$ is any isometry, and let $$F_1(z)={{F(z)-F(0)}\over {F(1)-F(0)}}$$ Then $|F(1)-F(0)|=1$ so that $F_1$ is an isometry with $F_1(0)=0$ and $F_1(1)=1$. This implies that $F_1(i)$ is $i$ or $-i$, and we deduce that either $F_1(z)=z$ or $F_1(z)=\bar z$ for all $z$ My problem with the above proof is, how could one deduce that $|F(1)-F(0)|=1$ and how can one deduce, then, that $F_1(i)=i \ \text{or} -1$??",,"['complex-analysis', 'isometry']"
89,"Laplacian of $|f|^p,$ where $f$ is holomorphic",Laplacian of  where  is holomorphic,"|f|^p, f","I have to prove that if $f$ is a homolorphic function that doesn´t vanish on its domain then $\triangle |f|^p=p^2 |f|^{p-2} |\frac{\partial f}{\partial z}|^2$ . My attempt: I take $|f|^p=(z \bar{z})^{p/2}$ to use the alternative form of the Laplacian $\triangle u=\frac{\partial}{\partial z} \frac{\partial}{\partial \bar{z}}u$. So I start computing as follows, using the chain rule: $\triangle |f|^p = 4 \frac{\partial}{\partial z} \frac{\partial}{\partial \bar{z}} (z \bar{z})^{p/2}=4 \frac{\partial}{\partial z} \frac{p}{2} (z \bar{z})^{p/2 -1} (z) = 4 \frac{p}{2}(\bar{z})^{p/2-1}(\frac{p}{2})z^{p/2-1}=p^2|f|^{p-2}$. So I´m clearly missing something, because the term $|\frac{\partial f}{\partial z}|^2$ doesn´t show off, I just don´t see what is it, as my differentiation skills are not quite good. Thanks.","I have to prove that if $f$ is a homolorphic function that doesn´t vanish on its domain then $\triangle |f|^p=p^2 |f|^{p-2} |\frac{\partial f}{\partial z}|^2$ . My attempt: I take $|f|^p=(z \bar{z})^{p/2}$ to use the alternative form of the Laplacian $\triangle u=\frac{\partial}{\partial z} \frac{\partial}{\partial \bar{z}}u$. So I start computing as follows, using the chain rule: $\triangle |f|^p = 4 \frac{\partial}{\partial z} \frac{\partial}{\partial \bar{z}} (z \bar{z})^{p/2}=4 \frac{\partial}{\partial z} \frac{p}{2} (z \bar{z})^{p/2 -1} (z) = 4 \frac{p}{2}(\bar{z})^{p/2-1}(\frac{p}{2})z^{p/2-1}=p^2|f|^{p-2}$. So I´m clearly missing something, because the term $|\frac{\partial f}{\partial z}|^2$ doesn´t show off, I just don´t see what is it, as my differentiation skills are not quite good. Thanks.",,"['complex-analysis', 'derivatives', 'laplacian']"
90,An analytic function $f$ bounded on the right half plane and $|f(z)|\leq 1$ on the imaginary axis,An analytic function  bounded on the right half plane and  on the imaginary axis,f |f(z)|\leq 1,"Assume that $f$ is an analytic function that $|f(z)|\leq 1$ on the imaginary axis and that $f$ is bounded in the right half plane. Prove that in fact $|f(z)|\leq 1$ in the right half plane. Hint: Consider the function $f_{\epsilon}(z)=f(z) e^{-\epsilon \sqrt{z}\,\,\,}$ for small positive $\epsilon$. Even though there is a hint I couldn't figure out how to approach to this question. If the function is conformal the statement is true but what we have otherwise? any help would be great.","Assume that $f$ is an analytic function that $|f(z)|\leq 1$ on the imaginary axis and that $f$ is bounded in the right half plane. Prove that in fact $|f(z)|\leq 1$ in the right half plane. Hint: Consider the function $f_{\epsilon}(z)=f(z) e^{-\epsilon \sqrt{z}\,\,\,}$ for small positive $\epsilon$. Even though there is a hint I couldn't figure out how to approach to this question. If the function is conformal the statement is true but what we have otherwise? any help would be great.",,['complex-analysis']
91,Existence of holomorphic function from unit disc to itself.,Existence of holomorphic function from unit disc to itself.,,"Does there exists a holomorphic function from open unit disc to itself s.t. $f(1/2)=-1/2$ and $f'(3/4)=1$? I think the answer is 'Yes' as $f(z)=z-1$ satisfies these conditions. Kindly correct me if I am wrong in interpretation of $f(z)$ which maps $D$ to $D$. Edit: If I use linear transformation f(z)=az+b ;|a|≦1 &|a|+|b|≦1 to seek the existence of such a function from unit disk to itself, I do not get f(z) due to voilation of |a|+|b|≦1.Does it mean that such function cannot exist? As I know a linear mapping completely characterizes any transformation from disc to disc.","Does there exists a holomorphic function from open unit disc to itself s.t. $f(1/2)=-1/2$ and $f'(3/4)=1$? I think the answer is 'Yes' as $f(z)=z-1$ satisfies these conditions. Kindly correct me if I am wrong in interpretation of $f(z)$ which maps $D$ to $D$. Edit: If I use linear transformation f(z)=az+b ;|a|≦1 &|a|+|b|≦1 to seek the existence of such a function from unit disk to itself, I do not get f(z) due to voilation of |a|+|b|≦1.Does it mean that such function cannot exist? As I know a linear mapping completely characterizes any transformation from disc to disc.",,['complex-analysis']
92,Residue theorem for line segment,Residue theorem for line segment,,"I am working through this problem:- Show that $\int_0^ \infty \frac{1}{1+x^n} dx= \frac{ \pi /n}{\sin(\pi /n)}$ , where $n$ is a positive integer. I follow it all, except for part (3) - I think this must a technique I haven't encountered yet, why does the integral on the incoming ray tend to $ -e^{\frac{2 \pi i}{n}} \int_{0}^{\infty}\frac{dx}{1+x^n} $ ? I tried - because the function is analytic, it is path independent - $ \lim_{{R}\to{\infty}}  \int_{R}^{0}f(z)dz = f(0) - f(R) $. Not promising. What I can sort of see, might be to paramerterize $ z= Re^{\frac{2 \pi i}{n}}, dz=e^{\frac{2 \pi i}{n}}dR $ and then find $ \lim_{{R}\to{\infty}} e^{\frac{2 \pi i}{n}} \int_{0}^{R}\frac{dR}{1+R^ne^{2 \pi i}}$ but thats no better than the original problem.  A hint on the approach would be very helpful, thanks","I am working through this problem:- Show that $\int_0^ \infty \frac{1}{1+x^n} dx= \frac{ \pi /n}{\sin(\pi /n)}$ , where $n$ is a positive integer. I follow it all, except for part (3) - I think this must a technique I haven't encountered yet, why does the integral on the incoming ray tend to $ -e^{\frac{2 \pi i}{n}} \int_{0}^{\infty}\frac{dx}{1+x^n} $ ? I tried - because the function is analytic, it is path independent - $ \lim_{{R}\to{\infty}}  \int_{R}^{0}f(z)dz = f(0) - f(R) $. Not promising. What I can sort of see, might be to paramerterize $ z= Re^{\frac{2 \pi i}{n}}, dz=e^{\frac{2 \pi i}{n}}dR $ and then find $ \lim_{{R}\to{\infty}} e^{\frac{2 \pi i}{n}} \int_{0}^{R}\frac{dR}{1+R^ne^{2 \pi i}}$ but thats no better than the original problem.  A hint on the approach would be very helpful, thanks",,['complex-analysis']
93,"Find a harmonic function in the interior of the disk, taking values +1 and -1","Find a harmonic function in the interior of the disk, taking values +1 and -1",,"Consider the Mobius transformation $$f(z) = \frac{1+z}{1-z}$$ Use this map to find a function $f(x,y)$ which is harmonic in $x^2+y^2<1$ and on the boundary $x^2+y^2=1$ takes values $+1$ when $y>0$ and $−1$ when $y<0$. My work: this is part (b) of a question that I am working on.  For part (a), I described the conformal mapping, showing that it maps the unit disk to the right half-plane. I know that $f$ harmonic means that for every $(x,y)$ in the interior of the disk, we need that $f_{xx}(x,y) + f_{yy}(x,y) = 0$. It also needs to take values +1 for $(x,y)$ on the upper semi-circle, and -1 on the lower semi-circle. I tried writing $f(z)$ as $$f(x,y) =\frac{(1+x)+iy}{(1-x)-iy}$$ How can I proceed? I tried setting $f(x,y) = 1$ and got the equation $2x = -2iy$.  So I made a  function $f(x,y)= 2x + i2y$, which happens to be harmonic.  But I don't know how to make it so that it takes the value $+1$ on the boundary $x^2+y^2=1$, $y>0$ (and similarly, $-1$ on the boundary $x^2+y^2=1$, $y<0$). Thanks,","Consider the Mobius transformation $$f(z) = \frac{1+z}{1-z}$$ Use this map to find a function $f(x,y)$ which is harmonic in $x^2+y^2<1$ and on the boundary $x^2+y^2=1$ takes values $+1$ when $y>0$ and $−1$ when $y<0$. My work: this is part (b) of a question that I am working on.  For part (a), I described the conformal mapping, showing that it maps the unit disk to the right half-plane. I know that $f$ harmonic means that for every $(x,y)$ in the interior of the disk, we need that $f_{xx}(x,y) + f_{yy}(x,y) = 0$. It also needs to take values +1 for $(x,y)$ on the upper semi-circle, and -1 on the lower semi-circle. I tried writing $f(z)$ as $$f(x,y) =\frac{(1+x)+iy}{(1-x)-iy}$$ How can I proceed? I tried setting $f(x,y) = 1$ and got the equation $2x = -2iy$.  So I made a  function $f(x,y)= 2x + i2y$, which happens to be harmonic.  But I don't know how to make it so that it takes the value $+1$ on the boundary $x^2+y^2=1$, $y>0$ (and similarly, $-1$ on the boundary $x^2+y^2=1$, $y<0$). Thanks,",,"['complex-analysis', 'harmonic-functions', 'conformal-geometry', 'mobius-transformation']"
94,"$f$ is an analytic function in the disk $D=\{z\in\mathbb{C}\,:\,|z|\leq 2\}$ such that $\iint_D=|f(z)|^2\,dx\,dy\leq 3\pi$. Maximize $|f''(0)|$",is an analytic function in the disk  such that . Maximize,"f D=\{z\in\mathbb{C}\,:\,|z|\leq 2\} \iint_D=|f(z)|^2\,dx\,dy\leq 3\pi |f''(0)|","Determine the largest possible value of $|f''(0)|$ when $f$ is an analytic function in the disk $D=\{z\in\mathbb{C}\,:\,|z|<2\}$ with the property that $\iint_{D}|f(z)|^2\,dx\,dy\leq 3\pi$. I don't really know what to do with the assumption that $\iint_D|f(z)|^2\,dx\,dy\leq 3\pi$. I believe you could use Stokes' theorem to rewrite this as a line integral on $\partial D$, but I'm really rusty with my usage, so I'm kind of stuck. If I could get a bound on $\int_{\partial D}|f(z)|^2\,dz$, I could probably use harnack's inequality for subharmonic functions to get a bound on $|f|$ then Cauchy's inequality, however I'm not very sure about my usage of green's theorem (if that's even the right way to go) any help is greatly appreciated. Thanks","Determine the largest possible value of $|f''(0)|$ when $f$ is an analytic function in the disk $D=\{z\in\mathbb{C}\,:\,|z|<2\}$ with the property that $\iint_{D}|f(z)|^2\,dx\,dy\leq 3\pi$. I don't really know what to do with the assumption that $\iint_D|f(z)|^2\,dx\,dy\leq 3\pi$. I believe you could use Stokes' theorem to rewrite this as a line integral on $\partial D$, but I'm really rusty with my usage, so I'm kind of stuck. If I could get a bound on $\int_{\partial D}|f(z)|^2\,dz$, I could probably use harnack's inequality for subharmonic functions to get a bound on $|f|$ then Cauchy's inequality, however I'm not very sure about my usage of green's theorem (if that's even the right way to go) any help is greatly appreciated. Thanks",,"['complex-analysis', 'greens-theorem']"
95,Describing the zero level set of a harmonic function,Describing the zero level set of a harmonic function,,"Let $p(k)$ be a complex polynomial of degree $n\in\mathbb{N}$. Let $A=\{k\in\mathbb{C}:\text{Re}\,p(k)=0\}$ The harmonic function $\text{Re}\,p(k)$ determines the behaviour of $A$. Fix $z\in A$. If atleast one of the partial derivatives $\partial_{\text{Re}\, k}\text{Re}\,p(z)$ or $\partial_{\text{Im}\, k}\text{Re}\,p(z)$ are not equal to zero, then the implicit function theorem gives that in every neighbourhood of such a point $z$, there exist a smooth curve such that $\text{Re}\,p=0$ on that curve in that neighbourhood. This only fails when both the partial derivatives are zero. But in the latter case due to Cauchy–Riemann equations $\frac{d}{dk}p(z)=0$ and this only occurs at a finite number of points. Can someone help me describe what happens at a neighborhood of a point $z\in A$ where $\frac{d}{dk}p(z)=0$? Also is there some flaws in the above argument?","Let $p(k)$ be a complex polynomial of degree $n\in\mathbb{N}$. Let $A=\{k\in\mathbb{C}:\text{Re}\,p(k)=0\}$ The harmonic function $\text{Re}\,p(k)$ determines the behaviour of $A$. Fix $z\in A$. If atleast one of the partial derivatives $\partial_{\text{Re}\, k}\text{Re}\,p(z)$ or $\partial_{\text{Im}\, k}\text{Re}\,p(z)$ are not equal to zero, then the implicit function theorem gives that in every neighbourhood of such a point $z$, there exist a smooth curve such that $\text{Re}\,p=0$ on that curve in that neighbourhood. This only fails when both the partial derivatives are zero. But in the latter case due to Cauchy–Riemann equations $\frac{d}{dk}p(z)=0$ and this only occurs at a finite number of points. Can someone help me describe what happens at a neighborhood of a point $z\in A$ where $\frac{d}{dk}p(z)=0$? Also is there some flaws in the above argument?",,"['complex-analysis', 'harmonic-functions']"
96,show that $f$ does not have a zero in the disc $\{z:|z|<|a|\}$.,show that  does not have a zero in the disc .,f \{z:|z|<|a|\},"Consider the unit disc $D$ and an analytic function $f:D\to D$. If $f(0)=a\not=0$ then show that $f$ does not have a zero in the disc $\{z:|z|<|a|\}$. My Try: Consider $g(z)=f(z)-a$. Then $g:D\to D$ is analytic and $g(0)=0$. Now apply Schwarz lemma on $g$ and we get , $|g(z)|<|z|\implies|f(z)-a|<|z|$. Now , when $|z|<|a|$ then $|f(z)|<2|a|$. From here how we can say that $f$ does not have zero in the given domain ? Or any other way ?","Consider the unit disc $D$ and an analytic function $f:D\to D$. If $f(0)=a\not=0$ then show that $f$ does not have a zero in the disc $\{z:|z|<|a|\}$. My Try: Consider $g(z)=f(z)-a$. Then $g:D\to D$ is analytic and $g(0)=0$. Now apply Schwarz lemma on $g$ and we get , $|g(z)|<|z|\implies|f(z)-a|<|z|$. Now , when $|z|<|a|$ then $|f(z)|<2|a|$. From here how we can say that $f$ does not have zero in the given domain ? Or any other way ?",,['complex-analysis']
97,Computing residues of $\cot(\pi z)/z(z+1)$ with symmetries,Computing residues of  with symmetries,\cot(\pi z)/z(z+1),"I would like to know if there is a quick way of computing the residues of $$f(z) = \frac{\cot \pi z}{z(z+1)}$$at the points $z = 0$ and $z = -1$. They are double poles. Expanding this in Laurent series I have: \begin{align} \frac{\cot \pi z}{z(z+1)} &= \frac{1}{z}\left(\frac{1}{\pi z}-\frac{\pi z}{3}-\frac{\pi^3z^3}{45}+\cdots\right)(1-z+z^2-z^3+z^4+\cdots) \\ &= \frac{1}{\pi z^2}-\frac{1}{\pi z}+\frac{1}{\pi}-\frac{\pi}{3}+\cdots\end{align} which gives: $${\rm Res}\left(\frac{\cot \pi z}{z(z+1)}, 0\right) = -\frac 1\pi.$$ My calculation above seemed quick, but computing Laurent series for $\cot$ is a pain. Also, Wolfram Alpha gives:  $${\rm Res}\left(\frac{\cot \pi z}{z(z+1)},-1\right) = -\frac 1\pi,$$too, which makes me think that there is some symmetry to be explored here. At first I thought about some symmetry around the $x = -1/2$ axis, and the following plot suggests that it might be the case. However, we don't have quite a straight line, so I don't know how to apply this.","I would like to know if there is a quick way of computing the residues of $$f(z) = \frac{\cot \pi z}{z(z+1)}$$at the points $z = 0$ and $z = -1$. They are double poles. Expanding this in Laurent series I have: \begin{align} \frac{\cot \pi z}{z(z+1)} &= \frac{1}{z}\left(\frac{1}{\pi z}-\frac{\pi z}{3}-\frac{\pi^3z^3}{45}+\cdots\right)(1-z+z^2-z^3+z^4+\cdots) \\ &= \frac{1}{\pi z^2}-\frac{1}{\pi z}+\frac{1}{\pi}-\frac{\pi}{3}+\cdots\end{align} which gives: $${\rm Res}\left(\frac{\cot \pi z}{z(z+1)}, 0\right) = -\frac 1\pi.$$ My calculation above seemed quick, but computing Laurent series for $\cot$ is a pain. Also, Wolfram Alpha gives:  $${\rm Res}\left(\frac{\cot \pi z}{z(z+1)},-1\right) = -\frac 1\pi,$$too, which makes me think that there is some symmetry to be explored here. At first I thought about some symmetry around the $x = -1/2$ axis, and the following plot suggests that it might be the case. However, we don't have quite a straight line, so I don't know how to apply this.",,"['complex-analysis', 'residue-calculus']"
98,Help evaluating residue with simple poles,Help evaluating residue with simple poles,,"I am having a bit of trouble evaluating $$\sum_{k=1}^3{ \rm Res}\left(\frac{\log(z)}{z^3+8};z_k\right)$$ where $z_1=2e^{i\pi}$, $z_2=2e^{i\pi/3}$ and $z_3=2e^{i5\pi/3}$. I know that each $z_k$ is a simple pole and, therefore, the residue should be equal to $$\sum_{k=1}^3\frac{\log(z_k)}{3z_k^{2}}$$ However, I can't seem to get the desired answer of $-\frac{\sqrt{3}\pi}{18}$. Help would be greatly appreciated! Note: The back of my textbook says $${\rm Res}\left(\frac{\log(z)}{z^3+8};z_k\right)=\frac{-z_k\log(z_k)}{24}$$ Still, I don't see where this comes from.","I am having a bit of trouble evaluating $$\sum_{k=1}^3{ \rm Res}\left(\frac{\log(z)}{z^3+8};z_k\right)$$ where $z_1=2e^{i\pi}$, $z_2=2e^{i\pi/3}$ and $z_3=2e^{i5\pi/3}$. I know that each $z_k$ is a simple pole and, therefore, the residue should be equal to $$\sum_{k=1}^3\frac{\log(z_k)}{3z_k^{2}}$$ However, I can't seem to get the desired answer of $-\frac{\sqrt{3}\pi}{18}$. Help would be greatly appreciated! Note: The back of my textbook says $${\rm Res}\left(\frac{\log(z)}{z^3+8};z_k\right)=\frac{-z_k\log(z_k)}{24}$$ Still, I don't see where this comes from.",,"['complex-analysis', 'residue-calculus']"
99,Why are rational numbers required in cusps of congruence subgroups?,Why are rational numbers required in cusps of congruence subgroups?,,"While we consider the action of congruence subgroups on $\mathbb{H}$ (the upper half plane), we compactify using an additional point at infinity, that is fine. But why do we add even all rational numbers? I am talking about how cusps are defined. And in particular, if $f$ is modular form, what does $f(q)$ (where $q \in \mathbb{Q}$) mean?","While we consider the action of congruence subgroups on $\mathbb{H}$ (the upper half plane), we compactify using an additional point at infinity, that is fine. But why do we add even all rational numbers? I am talking about how cusps are defined. And in particular, if $f$ is modular form, what does $f(q)$ (where $q \in \mathbb{Q}$) mean?",,"['complex-analysis', 'number-theory', 'analytic-number-theory', 'modular-forms']"
