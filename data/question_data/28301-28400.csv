,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Cut a number to a random integer between 0 and that number. Keep going until that number is 0. How many cuts do we need?,Cut a number to a random integer between 0 and that number. Keep going until that number is 0. How many cuts do we need?,,"Start with an integer like n = 100 and set it equal to a uniformaly random integer between [0,n] inclusive. Keep cutting it this way until n = 0 . What's the expected value of the number of cuts needed? For me, intuition gives an expected value of $\log_2 n ≈ 6.64$ , but empirical simulation in Python: import random   cuts = 0 expectedValue = 0 trials = 100000   for i in range(trials):   startingValue = 100   while startingValue > 0:     startingValue = random.randint(0, startingValue)     cuts += 1   expectedValue = cuts / trials print(expectedValue) results in $≈6.18$ . Does there exist an explicit solution for n = 100 or for any integer n ?","Start with an integer like n = 100 and set it equal to a uniformaly random integer between [0,n] inclusive. Keep cutting it this way until n = 0 . What's the expected value of the number of cuts needed? For me, intuition gives an expected value of , but empirical simulation in Python: import random   cuts = 0 expectedValue = 0 trials = 100000   for i in range(trials):   startingValue = 100   while startingValue > 0:     startingValue = random.randint(0, startingValue)     cuts += 1   expectedValue = cuts / trials print(expectedValue) results in . Does there exist an explicit solution for n = 100 or for any integer n ?",\log_2 n ≈ 6.64 ≈6.18,"['probability', 'combinatorics', 'number-theory', 'statistics', 'probability-distributions']"
1,Expected number of tosses for two coins to achieve the same outcome for five consecutive flips,Expected number of tosses for two coins to achieve the same outcome for five consecutive flips,,"Consider two unbiased coins. Toss both until last 5 sequence outcome are same. That means we stop when output of the sequence of both are as follows:  HTTHTHHTH , HHTTTHHTH. What is the expected number of trials?","Consider two unbiased coins. Toss both until last 5 sequence outcome are same. That means we stop when output of the sequence of both are as follows:  HTTHTHHTH , HHTTTHHTH. What is the expected number of trials?",,['probability']
2,What's the probability that a given permutation has exactly $k$ fixed points. [duplicate],What's the probability that a given permutation has exactly  fixed points. [duplicate],k,"This question already has an answer here : Number of permutations with a fixed point (1 answer) Closed 2 years ago . Given a random permutation $\sigma \in S_n$ from $[n] \to [n]$ in a uniform probability space, what is the probability that $\sigma $ has exactly $k$ fixed points for a given $k$ between $1$ and $n$ ? In other words: what is the probability that $\exists x_1 ,...,x_k \in [n] : \sigma (x_i) = x_i  $ for $\ i\in \{1,...,k\}$ and for every $y \notin \{x_1 , ... , x_k\}$ we get $\sigma(y) \neq y$ . I saw that $\lim_{n \to \infty } prob(A_0) = e^{-1}$ using Inclusion–exclusion principle and i belive that for a given k : $\lim_{n \to \infty} prob(A_k) = \frac{e^{-1}}{k!}$ but I am not sure how to show it. * $A_k$ stands for the event ""k"".","This question already has an answer here : Number of permutations with a fixed point (1 answer) Closed 2 years ago . Given a random permutation from in a uniform probability space, what is the probability that has exactly fixed points for a given between and ? In other words: what is the probability that for and for every we get . I saw that using Inclusion–exclusion principle and i belive that for a given k : but I am not sure how to show it. * stands for the event ""k"".","\sigma \in S_n [n] \to [n] \sigma  k k 1 n \exists x_1 ,...,x_k \in [n] : \sigma (x_i) = x_i   \ i\in \{1,...,k\} y \notin \{x_1 , ... , x_k\} \sigma(y) \neq y \lim_{n \to \infty } prob(A_0) = e^{-1} \lim_{n \to \infty} prob(A_k) = \frac{e^{-1}}{k!} A_k","['probability', 'combinatorics', 'permutations', 'derangements']"
3,probability and statistics: Does having little correlation imply independence?,probability and statistics: Does having little correlation imply independence?,,Suppose there are two correlated random variable and having very small correlation coefficient (order of 10 -1 ). Is it valid to approximate it as  independent random variables?,Suppose there are two correlated random variable and having very small correlation coefficient (order of 10 -1 ). Is it valid to approximate it as  independent random variables?,,"['probability-theory', 'statistics', 'probability']"
4,Expected number of rolls to get all sixes,Expected number of rolls to get all sixes,,"I'm struggling with the following problem: I have $N$ balanced 6-sided dice. I roll the dice simultaneously, and remove any sixes that occur. I roll the remaining dice again, and remove any more sixes. I repeat the process until there are no dice remaining. What is the expected number of rolls this will take? So far I have calculated that by the $n^{th}$ dice roll there will be $N\left(\frac56\right)^n$ dice remaining: If we start with $N$ dice, on the first roll we expect $\frac{N}{6}$ sixes. Therefore, on the second roll we expect to have $N-\frac{N}{6}$ dice and hence expect $\frac{5N}{36}$ sixes, meaning after the second roll there are $\frac{25}{36}N$ dice remaining.  Repeating this calculation gives the sequence $N, \frac{25}{36}N, \frac{125}{216}N...$ which is equal to $N\left(\frac56\right)^n$ where $n$ is the roll number. I'm struggling with the next part: My thinking is we must find the expected number of rolls $n$ such that $N\left(\frac56\right)^n\lt0.5$, and therefore $n>\frac{\ln(\frac{0.5}{N})}{\ln(\frac56)}$. Taking $N$ to be $8$, the expected number of rolls is then about $15.21$. I used MATLAB to run the experiment $200,000$ times, and it gave me an average number of rolls of $15.4$. I seem to be close to the right answer, but I'm not sure what I've done wrong. What is the solution?","I'm struggling with the following problem: I have $N$ balanced 6-sided dice. I roll the dice simultaneously, and remove any sixes that occur. I roll the remaining dice again, and remove any more sixes. I repeat the process until there are no dice remaining. What is the expected number of rolls this will take? So far I have calculated that by the $n^{th}$ dice roll there will be $N\left(\frac56\right)^n$ dice remaining: If we start with $N$ dice, on the first roll we expect $\frac{N}{6}$ sixes. Therefore, on the second roll we expect to have $N-\frac{N}{6}$ dice and hence expect $\frac{5N}{36}$ sixes, meaning after the second roll there are $\frac{25}{36}N$ dice remaining.  Repeating this calculation gives the sequence $N, \frac{25}{36}N, \frac{125}{216}N...$ which is equal to $N\left(\frac56\right)^n$ where $n$ is the roll number. I'm struggling with the next part: My thinking is we must find the expected number of rolls $n$ such that $N\left(\frac56\right)^n\lt0.5$, and therefore $n>\frac{\ln(\frac{0.5}{N})}{\ln(\frac56)}$. Taking $N$ to be $8$, the expected number of rolls is then about $15.21$. I used MATLAB to run the experiment $200,000$ times, and it gave me an average number of rolls of $15.4$. I seem to be close to the right answer, but I'm not sure what I've done wrong. What is the solution?",,"['probability', 'dice']"
5,Chance versus Skill,Chance versus Skill,,"Question. How does one mathematically analyze situations that involve chance and skill? Let's take the coin flip as a simple example. Assume that it possible to skillfully flip a coin to get the landing you want. Also assume zero cheating. FIRST SCENARIO The world's 5 most talented coin flippers gather to compete. The results: Person 1 Coin Flips : 100 Success Rate : 100% Person 2 Coin Flips : 10,000 Success Rate : 90% Person 3 Coin Flips : 1,000,000 Success Rate : 80% Person 4 Coin Flips : 100,000,000 Success Rate : 70% Person 5 Coin Flips : 10,000,000,000 Success Rate : 60% Each person claims he is the best coin flipper. How would you analyze the results? SECOND SCENARIO A man claims he is so skilled at coin flipping, he can always land heads. He flips one coin. Sure enough, heads. He flips again. Heads again. He flips 100 times. All heads. 1000 times. Still all heads. After 100,000,000,000,000 flips, every single one heads, he stops and says ""I told you so."" When do we go from thinking ""He's lucky !"" to ""He's good !""?","Question. How does one mathematically analyze situations that involve chance and skill? Let's take the coin flip as a simple example. Assume that it possible to skillfully flip a coin to get the landing you want. Also assume zero cheating. FIRST SCENARIO The world's 5 most talented coin flippers gather to compete. The results: Person 1 Coin Flips : 100 Success Rate : 100% Person 2 Coin Flips : 10,000 Success Rate : 90% Person 3 Coin Flips : 1,000,000 Success Rate : 80% Person 4 Coin Flips : 100,000,000 Success Rate : 70% Person 5 Coin Flips : 10,000,000,000 Success Rate : 60% Each person claims he is the best coin flipper. How would you analyze the results? SECOND SCENARIO A man claims he is so skilled at coin flipping, he can always land heads. He flips one coin. Sure enough, heads. He flips again. Heads again. He flips 100 times. All heads. 1000 times. Still all heads. After 100,000,000,000,000 flips, every single one heads, he stops and says ""I told you so."" When do we go from thinking ""He's lucky !"" to ""He's good !""?",,"['probability', 'statistics', 'soft-question', 'mathematical-modeling']"
6,Finding expected value with recursion,Finding expected value with recursion,,"We'll start off with an example of a question of finding expected value. What is the expected number of tries to get $6$ when rolling dice? $$ \mathbb{E}[x] =1/6*1 + 5/6 * (1+\mathbb{E}[x]) \implies \mathbb{E}(x)=6 $$ I understand the intuition, there is a 1/6 probability of getting 6 in one roll and 5/6 of not getting 6, so we roll again and add 1 to the counter since we have done one roll. I wonder what is the formal proof of such method?","We'll start off with an example of a question of finding expected value. What is the expected number of tries to get when rolling dice? I understand the intuition, there is a 1/6 probability of getting 6 in one roll and 5/6 of not getting 6, so we roll again and add 1 to the counter since we have done one roll. I wonder what is the formal proof of such method?","6 
\mathbb{E}[x] =1/6*1 + 5/6 * (1+\mathbb{E}[x]) \implies \mathbb{E}(x)=6
","['probability', 'expected-value', 'recursion']"
7,Sums of two probability density functions [closed],Sums of two probability density functions [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . This post was edited and submitted for review 2 years ago and failed to reopen the post: Original close reason(s) were not resolved Improve this question If the weighted sum of 2 probability density functions is also a probability density function, then what is the relationship between the random variables of these 3 probability density functions.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . This post was edited and submitted for review 2 years ago and failed to reopen the post: Original close reason(s) were not resolved Improve this question If the weighted sum of 2 probability density functions is also a probability density function, then what is the relationship between the random variables of these 3 probability density functions.",,['probability']
8,Different approaches to N balls and m boxes problem,Different approaches to N balls and m boxes problem,,"Suppose that you have N indistinguishable balls that are to be distributed in m boxes (the boxes are numbered from 1 to m). What is the probability of the i-th box being empty (where the i-th box is the box with the number i) given that the balls have equal chances of arriving at any box? I found two different approaches to solve this problem (which I post bellow). Since each of them leads to a different solution, I am having a hard time trying to find which one is incorrect. I am fairly sure that the first approach is correct since it follows the 'standard' way of solving problems involving indistinguishable balls, but I cannot find the error in the second one. I would greatly appreciate any help you could provide to solve this doubt. (1) First approach: (Bosons) The number of ways of distributing N indistinguishable balls into m boxes is equal to: $$\binom{N + m -1}{N}=\frac{(N + m - 1)!}{N!(m-1)!} $$ On the other hand, the number of ways to distribute the balls and leaving the i-th box empty can be obtained by leaving the i-th box empty and distributing the N balls into the remaining m - 1 boxes. This is equal to: $$\binom{N + m - 2}{N}=\frac{(N + m - 2)!}{N!(m-2)!}$$ Therefore the probability of the i-th box being empty is the quotient of the second number by the first: $$\frac{(N + m - 2)!}{N!(m-2)!}.\frac{N!(m-1)!}{(N + m - 1)!}=\frac{m-1}{N + m - 1}$$ (2) Second approach: (Counting functions) Suppose that before distributing the balls into the boxes we number them from 1 to N. Then for each ball, the number of ways of distributing that ball into the m boxes is m. So the number of ways to distribute N balls into m boxes is: $$m^N$$ If we want to distribute N numbered balls into m boxes leaving the i-th box empty, each ball can only go to the m-1 remaining boxes. Therefore the number of ways in which this can be done is: $$(m-1)^N$$ And the desired probability will be the quotient: $$\left(\frac{m-1}{m}\right)^N \neq \frac{m-1}{N + m - 1}$$ Thank you very much for your time.","Suppose that you have N indistinguishable balls that are to be distributed in m boxes (the boxes are numbered from 1 to m). What is the probability of the i-th box being empty (where the i-th box is the box with the number i) given that the balls have equal chances of arriving at any box? I found two different approaches to solve this problem (which I post bellow). Since each of them leads to a different solution, I am having a hard time trying to find which one is incorrect. I am fairly sure that the first approach is correct since it follows the 'standard' way of solving problems involving indistinguishable balls, but I cannot find the error in the second one. I would greatly appreciate any help you could provide to solve this doubt. (1) First approach: (Bosons) The number of ways of distributing N indistinguishable balls into m boxes is equal to: $$\binom{N + m -1}{N}=\frac{(N + m - 1)!}{N!(m-1)!} $$ On the other hand, the number of ways to distribute the balls and leaving the i-th box empty can be obtained by leaving the i-th box empty and distributing the N balls into the remaining m - 1 boxes. This is equal to: $$\binom{N + m - 2}{N}=\frac{(N + m - 2)!}{N!(m-2)!}$$ Therefore the probability of the i-th box being empty is the quotient of the second number by the first: $$\frac{(N + m - 2)!}{N!(m-2)!}.\frac{N!(m-1)!}{(N + m - 1)!}=\frac{m-1}{N + m - 1}$$ (2) Second approach: (Counting functions) Suppose that before distributing the balls into the boxes we number them from 1 to N. Then for each ball, the number of ways of distributing that ball into the m boxes is m. So the number of ways to distribute N balls into m boxes is: $$m^N$$ If we want to distribute N numbered balls into m boxes leaving the i-th box empty, each ball can only go to the m-1 remaining boxes. Therefore the number of ways in which this can be done is: $$(m-1)^N$$ And the desired probability will be the quotient: $$\left(\frac{m-1}{m}\right)^N \neq \frac{m-1}{N + m - 1}$$ Thank you very much for your time.",,"['probability', 'combinatorics']"
9,"What is the meaning of ""mean-field""?","What is the meaning of ""mean-field""?",,"In lots of Bayesian papers, people use variational approximation. In lots of them they call it  "" mean-field variational approximation"". Does anyone know what is the meaning of mean-field in this context?","In lots of Bayesian papers, people use variational approximation. In lots of them they call it  "" mean-field variational approximation"". Does anyone know what is the meaning of mean-field in this context?",,"['probability', 'approximation', 'bayesian']"
10,"In the card game Set, what's the probability of a Set existing in n cards?","In the card game Set, what's the probability of a Set existing in n cards?",,"Given $n$ randomly drawn Set cards on a table from a standard 81-card deck, how can I determine the probability of one or more Sets existing on the table? First, for those who may not be familiar with the game, here's a simple introduction to Set (see setgame.com ), which lends itself to some straightforward mathematics: there are four properties of the symbols on each card.  Each property has three states, resulting in $3^4$ or 81 possible symbols.  Each of the 81 cards is unique. The properties are as follows: Number , Shading , Color , and Shape . The three states of Number : One, Two, Three. The three states of Shading : Open, Lined, Solid. The three states of Color : Red, Green, Purple. The three states of Shape : Diamond, Oval, Squiggle. A Set is defined by three cards in which each property is either all the same across the three cards (e.g. Two, Two, Two), or all different across the three cards (e.g. Red, Green, Purple).  You must consider all four properties when determining the validity of a Set. Hence the following are Sets: One Lined Red Diamond, Two Lined Green Diamonds, and Three Lined Purple Diamonds One Solid Green Oval, One Solid Green Diamond, One Solid Green Squiggle One Lined Purple Squiggle, Two Solid Red Diamonds, Three Open Green Ovals. And, just for kicks, the following is not a Set: One Open Green Diamond, Two Lined Green Diamonds, and Two Solid Green Diamonds; the number property does not pass the test (1, 2, 2) The game is played by one or more players placing twelve cards (random, from a shuffled deck) face up on a flat area.  When a player sees a Set, s/he calls ""Set"" and indicates the three cards, collects them from the table, and the dealer replaces them.  When the deck runs out, and no more Sets are possible, whoever has the most Sets wins. Hopefully you have the gist of it now.  Here's the question again, in light of the rules: given a shuffled 81-card deck, when you lay out $n$ cards face up on a table, what is the probability of a Set existing on the table? I have been able to figure it out to five cards, but past that, I get lost.  I'll post what I have in an answer, because it's part of the answer, but what I really want to know is whether there's an easier way to do it.  Otherwise it could take me a long time, no kidding.","Given $n$ randomly drawn Set cards on a table from a standard 81-card deck, how can I determine the probability of one or more Sets existing on the table? First, for those who may not be familiar with the game, here's a simple introduction to Set (see setgame.com ), which lends itself to some straightforward mathematics: there are four properties of the symbols on each card.  Each property has three states, resulting in $3^4$ or 81 possible symbols.  Each of the 81 cards is unique. The properties are as follows: Number , Shading , Color , and Shape . The three states of Number : One, Two, Three. The three states of Shading : Open, Lined, Solid. The three states of Color : Red, Green, Purple. The three states of Shape : Diamond, Oval, Squiggle. A Set is defined by three cards in which each property is either all the same across the three cards (e.g. Two, Two, Two), or all different across the three cards (e.g. Red, Green, Purple).  You must consider all four properties when determining the validity of a Set. Hence the following are Sets: One Lined Red Diamond, Two Lined Green Diamonds, and Three Lined Purple Diamonds One Solid Green Oval, One Solid Green Diamond, One Solid Green Squiggle One Lined Purple Squiggle, Two Solid Red Diamonds, Three Open Green Ovals. And, just for kicks, the following is not a Set: One Open Green Diamond, Two Lined Green Diamonds, and Two Solid Green Diamonds; the number property does not pass the test (1, 2, 2) The game is played by one or more players placing twelve cards (random, from a shuffled deck) face up on a flat area.  When a player sees a Set, s/he calls ""Set"" and indicates the three cards, collects them from the table, and the dealer replaces them.  When the deck runs out, and no more Sets are possible, whoever has the most Sets wins. Hopefully you have the gist of it now.  Here's the question again, in light of the rules: given a shuffled 81-card deck, when you lay out $n$ cards face up on a table, what is the probability of a Set existing on the table? I have been able to figure it out to five cards, but past that, I get lost.  I'll post what I have in an answer, because it's part of the answer, but what I really want to know is whether there's an easier way to do it.  Otherwise it could take me a long time, no kidding.",,"['probability', 'combinatorics', 'card-games']"
11,Third Moment of Standard Normal Random Variable,Third Moment of Standard Normal Random Variable,,Let $X$ be a normal random variable with mean $\mu$ and standard deviation $\sigma^2$ . I am wondering how to calculate the third moment of a normal random variable without having a huge mess to integrate. Is there a quicker way to do this?,Let be a normal random variable with mean and standard deviation . I am wondering how to calculate the third moment of a normal random variable without having a huge mess to integrate. Is there a quicker way to do this?,X \mu \sigma^2,['probability']
12,A man who lies a fourth of the time throws a die and says it is a six. What is the probability it is actually a six?,A man who lies a fourth of the time throws a die and says it is a six. What is the probability it is actually a six?,,"First, I apologise for the vague title. I couldn't think of a short way to represent the problem. Also, I am aware that a similar question exists, but I have a little bit more insight. The problem is: A man is known to speak the truth three out of four times. He throws a   die and reports that it is a six. Find the probability that it   actually is a six. The answer in the book is $ \frac{3}{8} $, which sounds completely off to me, given the numbers, on first glance. I decided to try it on my own. After some contemplation, it indeed is true that $ \frac{3}{8} $ is correct. But, the question's vagueness makes it interesting. It's sort of a naive answer! First, here's the book's solution: Let $ E $ be the event that the man reports that a six occurs, $ S_1 $ be the event that six occurs and $ S_2 $ be the event that six does not occur. $ P(S_1) $ = Probability that six occurs = $ \frac{1}{6} $ $ P(S_2) $ = Probability that six does not occur = $ \frac{5}{6} $ $ P(E~|S_1) $ = Probability that the man reports that a six occurred when it has actually occurred (truth) = $ \frac{3}{4} $ $ P(E~|S_2) $ = Probability that the man reports that a six occurred when it hasn't actually occurred = $ \frac{1}{4} $ $ P(S_1|E) $ = Probability that a six has actually occurred when the man claims so = $$ \frac{P(S_1)~P(E~|S1)}{P(S_1)~P(E~|S_1)+P(S_2)~P(E~|S_2)} = \frac{3}{8} $$ Link to original: Page 25 of this (link updated 22/11/2015; tends to break often). Here's the first of my two solutions: The question is a little vague and it doesn't tell us what the man says when he doesn't get a six. Assuming he lies every time he doesn't get a six (which is not quite what the question says), would bring up $ P(E~|S_2) $ to $ 1 $, which skyrockets $ P(lie) $ to $ \frac{1}{6} + \frac{1}{6} + \frac{1}{6} + \frac{1}{6} + \frac{1}{6} + \frac{1}{6}.\frac{1}{4} = \frac{7}{8} $. Also, $ P(E~|S_1) = \frac{3}{4} $ and $ P(E) = \frac{5}{6} + \frac{1}{6}.\frac{3}{4} = \frac{23}{24} $. This brings us to, $$ P(S_1|E) = \frac{P(S_1)P(E~|S_1)}{P(E)} = \frac{3}{23} = 13.04\% $$ Please note that I don't care about the sixes rolled when he lies about it being a six, because that condition is not applicable to the question. I'm very skeptical about my calculations! I decided to whip up a simple program and see what the probability distribution is for $$ \frac{Number~of~sixes~rolled~while ~saying~it's~a~six}{Number~of~dice~rolls} $$ Here's the result: Considering the book says $ P(E~|S_2) = \frac{1}{4} $, which is in essence is contradictory to the question, let's also consider the other possibility: It's even more vague in this scenario! If the man lies after any given roll, there is a $ \frac{1}{5} $ probability that he will lie about it being any other number. This creates a new branch at each lie, which splits into five. In this case, $$ P(E) = \frac{1}{6}.\frac{1}{4}.\frac{1}{5}.\frac{5}{1}+\frac{1}{6}.\frac{3}{4} =  \frac{1}{6} $$ $ P(E~|S_1) $ still remains $ \frac{3}{4} $, but $ P(E~|S_2) = \frac{1}{4}.\frac{1}{5} = \frac{1}{20} $. $$ P(S_1|E) = \frac{P(S_1)P(E~|S_1)}{P(E)} = \frac{3}{4} = 75\% $$ This seems like the more intuitive answer, and it is why I doubted the original answer in the first place. Given a truth probability of $ \frac{3}{4} $, there was no way that the probability of a six was $ 37.5\% $! The ambiguity of the question is what makes $ \frac{3}{8} $ wrong to me. Entirely out of curiosity, which answer fits best with the question and are these calculations correct or baloney?","First, I apologise for the vague title. I couldn't think of a short way to represent the problem. Also, I am aware that a similar question exists, but I have a little bit more insight. The problem is: A man is known to speak the truth three out of four times. He throws a   die and reports that it is a six. Find the probability that it   actually is a six. The answer in the book is $ \frac{3}{8} $, which sounds completely off to me, given the numbers, on first glance. I decided to try it on my own. After some contemplation, it indeed is true that $ \frac{3}{8} $ is correct. But, the question's vagueness makes it interesting. It's sort of a naive answer! First, here's the book's solution: Let $ E $ be the event that the man reports that a six occurs, $ S_1 $ be the event that six occurs and $ S_2 $ be the event that six does not occur. $ P(S_1) $ = Probability that six occurs = $ \frac{1}{6} $ $ P(S_2) $ = Probability that six does not occur = $ \frac{5}{6} $ $ P(E~|S_1) $ = Probability that the man reports that a six occurred when it has actually occurred (truth) = $ \frac{3}{4} $ $ P(E~|S_2) $ = Probability that the man reports that a six occurred when it hasn't actually occurred = $ \frac{1}{4} $ $ P(S_1|E) $ = Probability that a six has actually occurred when the man claims so = $$ \frac{P(S_1)~P(E~|S1)}{P(S_1)~P(E~|S_1)+P(S_2)~P(E~|S_2)} = \frac{3}{8} $$ Link to original: Page 25 of this (link updated 22/11/2015; tends to break often). Here's the first of my two solutions: The question is a little vague and it doesn't tell us what the man says when he doesn't get a six. Assuming he lies every time he doesn't get a six (which is not quite what the question says), would bring up $ P(E~|S_2) $ to $ 1 $, which skyrockets $ P(lie) $ to $ \frac{1}{6} + \frac{1}{6} + \frac{1}{6} + \frac{1}{6} + \frac{1}{6} + \frac{1}{6}.\frac{1}{4} = \frac{7}{8} $. Also, $ P(E~|S_1) = \frac{3}{4} $ and $ P(E) = \frac{5}{6} + \frac{1}{6}.\frac{3}{4} = \frac{23}{24} $. This brings us to, $$ P(S_1|E) = \frac{P(S_1)P(E~|S_1)}{P(E)} = \frac{3}{23} = 13.04\% $$ Please note that I don't care about the sixes rolled when he lies about it being a six, because that condition is not applicable to the question. I'm very skeptical about my calculations! I decided to whip up a simple program and see what the probability distribution is for $$ \frac{Number~of~sixes~rolled~while ~saying~it's~a~six}{Number~of~dice~rolls} $$ Here's the result: Considering the book says $ P(E~|S_2) = \frac{1}{4} $, which is in essence is contradictory to the question, let's also consider the other possibility: It's even more vague in this scenario! If the man lies after any given roll, there is a $ \frac{1}{5} $ probability that he will lie about it being any other number. This creates a new branch at each lie, which splits into five. In this case, $$ P(E) = \frac{1}{6}.\frac{1}{4}.\frac{1}{5}.\frac{5}{1}+\frac{1}{6}.\frac{3}{4} =  \frac{1}{6} $$ $ P(E~|S_1) $ still remains $ \frac{3}{4} $, but $ P(E~|S_2) = \frac{1}{4}.\frac{1}{5} = \frac{1}{20} $. $$ P(S_1|E) = \frac{P(S_1)P(E~|S_1)}{P(E)} = \frac{3}{4} = 75\% $$ This seems like the more intuitive answer, and it is why I doubted the original answer in the first place. Given a truth probability of $ \frac{3}{4} $, there was no way that the probability of a six was $ 37.5\% $! The ambiguity of the question is what makes $ \frac{3}{8} $ wrong to me. Entirely out of curiosity, which answer fits best with the question and are these calculations correct or baloney?",,['probability']
13,Incredible Blackjack Hand,Incredible Blackjack Hand,,"Last Saturday night I played at Bally's in Atlantic City and got a hand I could not believe. Dealer had 9 and I was dealt 2 8s. I split the 8s and was given a third card. It was an 8 so I split them again. The next card I was dealt was a fourth 8. This has happened to me three other times in my life, so no big deal. The fifth card was again an 8 and the sixth consecutive 8 followed. No one at the table or the dealer or even the pit boss had ever seen that before. I do not even know how to start calculating what the odds are in getting 6 straight cards of the same denomination from an 8 deck shoe, which holds 416 cards. Can you help me?","Last Saturday night I played at Bally's in Atlantic City and got a hand I could not believe. Dealer had 9 and I was dealt 2 8s. I split the 8s and was given a third card. It was an 8 so I split them again. The next card I was dealt was a fourth 8. This has happened to me three other times in my life, so no big deal. The fifth card was again an 8 and the sixth consecutive 8 followed. No one at the table or the dealer or even the pit boss had ever seen that before. I do not even know how to start calculating what the odds are in getting 6 straight cards of the same denomination from an 8 deck shoe, which holds 416 cards. Can you help me?",,"['probability', 'combinatorics']"
14,Bayesian posterior with truncated normal prior,Bayesian posterior with truncated normal prior,,"Suppose we observe one draw from the random variable $X$, which is distributed with normal distribution $\mathcal{N}(\mu,\sigma^2)$. The variance $\sigma^2$ is known, $\mu$ isn't. We want to estimate $\mu$. Suppose further that the prior distribution is given by truncated normal distribution $\mathcal{N}(\mu_0,\sigma^2_0,t)$, i.e., density $f(\mu)=c/\sigma \phi((\mu-\mu_0)/\sigma_0)$ if $\mu<t$, and $f(\mu)=0$ otherwise, where $t>\mu$ and $c$ is a normalizing constant. (Interpretation: we get noisy signals about $\mu$, which are known to be normally distributed with known variance---this is the draw of $X$. But we have prior knowledge that values $\mu\ge t$ are not possible.) In this setup, is the resulting posterior a truncated normal distribution (truncated at $t$ like the prior)? I tried to adapt the derivation of the posterior for the well known conjugate normal pair (e.g., here and here ), and it seems to work. Do you see any mistake in this derivation? The likelihood function is given by  $$f(x|\mu)=\frac{1}{\sigma\sqrt{2\pi}} \exp\left\{-\frac{(x-\mu)^2}{2\sigma^2} \right\} $$ The prior density is ($\Phi(.)$ is the cdf of the standard normal distribution) $$f(\mu)=\begin{cases} \frac{1}{\sigma_0\sqrt{2\pi}\Phi((t-\mu_0)/\sigma_0)} \exp\left\{-\frac{(\mu-\mu_0)^2}{2\sigma_0^2} \right\} &\text{ if } \mu\le t \\ 0 & \text{else}. \end{cases}$$ The prior density can be rewritten as  $$f(\mu)=c \phi((\mu-\mu_0)/\sigma_0)\mathbf{1}\{\mu<t\},$$ where $c$ is the normalizing constant (independent of $\mu$, but dependent on $t$). Now, by Bayes' rule, \begin{equation} f(\mu|x)\propto f(x|\mu) f(\mu)\propto\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2} \right\} \exp\left\{-\frac{(\mu-\mu_0)^2}{2\sigma_0^2} \right\}\mathbf{1}\{\mu<t\} \\ =\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2} -\frac{(\mu-\mu_0)^2}{2\sigma_0^2} \right\}\mathbf{1}\{\mu<t\}\\ \propto \exp\left\{-\frac{1}{2\sigma^2\sigma_0^2/(\sigma^2+\sigma_0^2)} \left(\mu-\frac{\sigma^2\mu_0+\sigma_0^2 x}{\sigma^2+\sigma_0^2}\right)^2 \right\}\mathbf{1}\{\mu<t\}. \end{equation} This is the kernel of the normal distribution with the usual mean and variance (as if we had done the derivation for an untruncated prior), but truncated at $t$ and above. In other words, ignoring the truncation in the prior distribution, using the usual learning rule for the conjugate normal pair, and then applying the truncation gives the same result as the derivation above (assuming it is correct). Is it correct? All I do is add the indicator function (and adapt the normalizing constant), does that introduce problems somewhere?","Suppose we observe one draw from the random variable $X$, which is distributed with normal distribution $\mathcal{N}(\mu,\sigma^2)$. The variance $\sigma^2$ is known, $\mu$ isn't. We want to estimate $\mu$. Suppose further that the prior distribution is given by truncated normal distribution $\mathcal{N}(\mu_0,\sigma^2_0,t)$, i.e., density $f(\mu)=c/\sigma \phi((\mu-\mu_0)/\sigma_0)$ if $\mu<t$, and $f(\mu)=0$ otherwise, where $t>\mu$ and $c$ is a normalizing constant. (Interpretation: we get noisy signals about $\mu$, which are known to be normally distributed with known variance---this is the draw of $X$. But we have prior knowledge that values $\mu\ge t$ are not possible.) In this setup, is the resulting posterior a truncated normal distribution (truncated at $t$ like the prior)? I tried to adapt the derivation of the posterior for the well known conjugate normal pair (e.g., here and here ), and it seems to work. Do you see any mistake in this derivation? The likelihood function is given by  $$f(x|\mu)=\frac{1}{\sigma\sqrt{2\pi}} \exp\left\{-\frac{(x-\mu)^2}{2\sigma^2} \right\} $$ The prior density is ($\Phi(.)$ is the cdf of the standard normal distribution) $$f(\mu)=\begin{cases} \frac{1}{\sigma_0\sqrt{2\pi}\Phi((t-\mu_0)/\sigma_0)} \exp\left\{-\frac{(\mu-\mu_0)^2}{2\sigma_0^2} \right\} &\text{ if } \mu\le t \\ 0 & \text{else}. \end{cases}$$ The prior density can be rewritten as  $$f(\mu)=c \phi((\mu-\mu_0)/\sigma_0)\mathbf{1}\{\mu<t\},$$ where $c$ is the normalizing constant (independent of $\mu$, but dependent on $t$). Now, by Bayes' rule, \begin{equation} f(\mu|x)\propto f(x|\mu) f(\mu)\propto\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2} \right\} \exp\left\{-\frac{(\mu-\mu_0)^2}{2\sigma_0^2} \right\}\mathbf{1}\{\mu<t\} \\ =\exp\left\{-\frac{(x-\mu)^2}{2\sigma^2} -\frac{(\mu-\mu_0)^2}{2\sigma_0^2} \right\}\mathbf{1}\{\mu<t\}\\ \propto \exp\left\{-\frac{1}{2\sigma^2\sigma_0^2/(\sigma^2+\sigma_0^2)} \left(\mu-\frac{\sigma^2\mu_0+\sigma_0^2 x}{\sigma^2+\sigma_0^2}\right)^2 \right\}\mathbf{1}\{\mu<t\}. \end{equation} This is the kernel of the normal distribution with the usual mean and variance (as if we had done the derivation for an untruncated prior), but truncated at $t$ and above. In other words, ignoring the truncation in the prior distribution, using the usual learning rule for the conjugate normal pair, and then applying the truncation gives the same result as the derivation above (assuming it is correct). Is it correct? All I do is add the indicator function (and adapt the normalizing constant), does that introduce problems somewhere?",,"['probability', 'statistics', 'normal-distribution', 'bayesian', 'bayes-theorem']"
15,Who has the upper hand in a generalized game of Risk?,Who has the upper hand in a generalized game of Risk?,,"So, I played a game of Risk the other day for the first time since I was very little. I was frustrated to discover that I couldn't compute (at least not in my head) whether the attacker or the defender has the upper-hand in large battles. Based on how the game unfolded, I guessed that the attacker has the advantage, and later I verified this by calculating the expected number of casualties in a round of ""combat"". But, my approach was just to brute-force the computation in a spreadsheet. I'm curious whether there is a more elegant approach and also I thought it might be nice to ask a more general question. Let $A$ and $B$ be two players. Let $a,b,n,k$ be positive integers with $k \leq a,b$. The game is as follows. Person $A$ has $a$ dice. Person $B$ has $b$ dice. All dice have $n$ sides labelled $1,2,\ldots,n$. Both players roll all of their dice, extract their $k$ highest rolls (with repetition) and sort them in (weakly) decreasing order. Say $a_1,\ldots,a_k$ are $A$'s $k$ best rolls and $b_1,\ldots,b_k$ are $B$'s $k$ best rolls. $A$ suffers one ""casualty"" for each index $i \in \{1,2,\ldots,k\}$ with $a_i \leq b_i$. $B$ suffers one ""casualty"" for each index $i \in \{1,2,\ldots,k\}$ with $a_i > b_i$. Note that player $B$ wins when the rolls are tied. What are the expected number casulties that $A$ suffers in terms of $a,b,n,k$? Note by linearity of expectation, the expected number of casualties that $A$ suffers plus the expected number of casualties that $B$ suffers sum to $k$.","So, I played a game of Risk the other day for the first time since I was very little. I was frustrated to discover that I couldn't compute (at least not in my head) whether the attacker or the defender has the upper-hand in large battles. Based on how the game unfolded, I guessed that the attacker has the advantage, and later I verified this by calculating the expected number of casualties in a round of ""combat"". But, my approach was just to brute-force the computation in a spreadsheet. I'm curious whether there is a more elegant approach and also I thought it might be nice to ask a more general question. Let $A$ and $B$ be two players. Let $a,b,n,k$ be positive integers with $k \leq a,b$. The game is as follows. Person $A$ has $a$ dice. Person $B$ has $b$ dice. All dice have $n$ sides labelled $1,2,\ldots,n$. Both players roll all of their dice, extract their $k$ highest rolls (with repetition) and sort them in (weakly) decreasing order. Say $a_1,\ldots,a_k$ are $A$'s $k$ best rolls and $b_1,\ldots,b_k$ are $B$'s $k$ best rolls. $A$ suffers one ""casualty"" for each index $i \in \{1,2,\ldots,k\}$ with $a_i \leq b_i$. $B$ suffers one ""casualty"" for each index $i \in \{1,2,\ldots,k\}$ with $a_i > b_i$. Note that player $B$ wins when the rolls are tied. What are the expected number casulties that $A$ suffers in terms of $a,b,n,k$? Note by linearity of expectation, the expected number of casualties that $A$ suffers plus the expected number of casualties that $B$ suffers sum to $k$.",,"['probability', 'recreational-mathematics', 'closed-form']"
16,$52$ cards reciprocal sum probability,cards reciprocal sum probability,52,"Imagine a deck of $52$ cards but instead of having suits and ranks, they only have sequential (unique) integer ranks from $1$ to $52$. You could also imagine a standard deck of $52$ cards but convert the ranks and suits to an integer number from $1$ to $52$ so that all the cards have different numbers assigned to them. So the question is, what is the probability, if you randomly choose exactly $10$ cards from that deck without replacement, that the sum of the reciprocals of the cards ranks (from $1$ to $52$) totals exactly $1$?  For example, if you chose cards $5,10,15,20,25,30,35,40,45$ and $50$, the sum of the reciprocals would only be $0.58579$... so that is too small. As a hint, I believe if you sort the cards in ascending order, the first card (the lowest rank card) MUST be between a $2$ and $6$ (inclusive) to be a candidate solution.  This is because $1/1$ is already a sum of $1$ so any additional cards will make it too large a sum.  Also $7$ as a lowest card will not work cuz $1/7$ + $1/8$... + $1/16$ = $0.93$...  so the lowest card MUST be a $2,3,4,5$, or $6$.  I am re-running my modified simulation now with that added information to prune the state space it must check. Also I am seeing multiple solutions so there is not just $1$ solution but the probability is likely very low, only a small fraction of $1$% I would guesstimate. Also note than many solutions are very close to $1$ but not exactly $1$, thus making computer simulation of this type of problem more difficult.  An example of a ""close solution"" is $2,4,13,25,35,41,47,50,51,52$ which evaluates to $0.99999995750965$.  The closest sum not equal to $1$ happens with $3,4,8,14,17,22,26,29,46,47$ which evaluates to $1.00000000288991$.  That is $8$ zeros after the $1$. An interesting note...  That number very close to $1$ is gotten by summing only $10$ terms.  This is impressive since even summing negative powers of $2$ which converges to $1$, ($1/2$ + $1/4$ + $1/8$...), it takes $28$ terms to almost match that closeness to $1$ and $29$ terms to beat it.","Imagine a deck of $52$ cards but instead of having suits and ranks, they only have sequential (unique) integer ranks from $1$ to $52$. You could also imagine a standard deck of $52$ cards but convert the ranks and suits to an integer number from $1$ to $52$ so that all the cards have different numbers assigned to them. So the question is, what is the probability, if you randomly choose exactly $10$ cards from that deck without replacement, that the sum of the reciprocals of the cards ranks (from $1$ to $52$) totals exactly $1$?  For example, if you chose cards $5,10,15,20,25,30,35,40,45$ and $50$, the sum of the reciprocals would only be $0.58579$... so that is too small. As a hint, I believe if you sort the cards in ascending order, the first card (the lowest rank card) MUST be between a $2$ and $6$ (inclusive) to be a candidate solution.  This is because $1/1$ is already a sum of $1$ so any additional cards will make it too large a sum.  Also $7$ as a lowest card will not work cuz $1/7$ + $1/8$... + $1/16$ = $0.93$...  so the lowest card MUST be a $2,3,4,5$, or $6$.  I am re-running my modified simulation now with that added information to prune the state space it must check. Also I am seeing multiple solutions so there is not just $1$ solution but the probability is likely very low, only a small fraction of $1$% I would guesstimate. Also note than many solutions are very close to $1$ but not exactly $1$, thus making computer simulation of this type of problem more difficult.  An example of a ""close solution"" is $2,4,13,25,35,41,47,50,51,52$ which evaluates to $0.99999995750965$.  The closest sum not equal to $1$ happens with $3,4,8,14,17,22,26,29,46,47$ which evaluates to $1.00000000288991$.  That is $8$ zeros after the $1$. An interesting note...  That number very close to $1$ is gotten by summing only $10$ terms.  This is impressive since even summing negative powers of $2$ which converges to $1$, ($1/2$ + $1/4$ + $1/8$...), it takes $28$ terms to almost match that closeness to $1$ and $29$ terms to beat it.",,['probability']
17,Proving $\operatorname{Var}(X) = E[X^2] - (E[X])^2$,Proving,\operatorname{Var}(X) = E[X^2] - (E[X])^2,"I want to understand something about the derivation of $\text{Var}(X) = E[X^2] - (E[X])^2$ Variance is defined as the expected squared difference between a random variable and the mean (expected value): $\text{Var}(X) = E[(X - \mu)^2]$ Then: $\operatorname{Var}(X) = E[(X - \mu)^2]$ $\operatorname{Var}(X) = E[(X - E[X])^2]$ $\operatorname{Var}(X) = E[(X - E[X])(X - E[X])]$ $\operatorname{Var}(X) = E[X^2 - 2XE[X] + (E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2E[XE[X]] + E[(E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2E[E[X]E[X]] + E[(E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2(E[X])^2 + (E[X])^2$ $\operatorname{Var}(X) = E[X^2] - (E[X])^2$ What I don't quite understand is the steps that get us from $E[XE[X]]$ to $E[E[X]E[X]]$ to $(E[X])^2$, also $E[(E[X])^2]$ to $(E[X])^2$. While I'm sure these jumps are intuitive and obvious I would still like to understand how we can (more formally) make these jumps / consider them mathematically equivalent.","I want to understand something about the derivation of $\text{Var}(X) = E[X^2] - (E[X])^2$ Variance is defined as the expected squared difference between a random variable and the mean (expected value): $\text{Var}(X) = E[(X - \mu)^2]$ Then: $\operatorname{Var}(X) = E[(X - \mu)^2]$ $\operatorname{Var}(X) = E[(X - E[X])^2]$ $\operatorname{Var}(X) = E[(X - E[X])(X - E[X])]$ $\operatorname{Var}(X) = E[X^2 - 2XE[X] + (E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2E[XE[X]] + E[(E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2E[E[X]E[X]] + E[(E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2(E[X])^2 + (E[X])^2$ $\operatorname{Var}(X) = E[X^2] - (E[X])^2$ What I don't quite understand is the steps that get us from $E[XE[X]]$ to $E[E[X]E[X]]$ to $(E[X])^2$, also $E[(E[X])^2]$ to $(E[X])^2$. While I'm sure these jumps are intuitive and obvious I would still like to understand how we can (more formally) make these jumps / consider them mathematically equivalent.",,"['probability', 'proof-explanation', 'expected-value', 'variance']"
18,Banach Matchbox Problem,Banach Matchbox Problem,,"Banach Matchbox Problem: Suppose a mathematician carries two matchboxes at all times: one in   his left pocket and one in his right. Each time he needs a match, he   is equally likely to take it from either pocket. Suppose he reaches   into his pocket and discovers for the first time that the box picked   is empty. If it is assumed that each of the matchboxes originally   contained $n$ matches, what is the probability that there are exactly $k$   matches in the other box? I'm wondering whether the following reasoning is right, because it doesn't match up with the correct probability. But here goes my reasoning: Assuming there are $k$ matches left in the other box, we have had to take $2n-k+1$ matches to notice there are none left. The total number of ways in which we could have picked those is $2 {2n - k \choose n}$, for either the matchbox in the left or right pocket has $k$ matches left inside, and in the $(2n-k+1)$th pick we would have found an empty box. The total number of possibilities, taken over all possible sizes $k$, would then be $\sum_{m=0}^{n} 2{2n-m \choose n}$. So I'd assume the overall probability would be $\frac{2 {2n - k \choose n}}{\sum_{m=0}^{n} 2 {2n-m \choose n}} =\frac{{2n - k \choose n}}{\sum_{m=0}^{n} {2n-m \choose n}}$. However, the mentioned solution is ${2n - k \choose n} (\tfrac{1}{2})^{2n-k}$. Where is my reasoning wrong? Thanks in advance.","Banach Matchbox Problem: Suppose a mathematician carries two matchboxes at all times: one in   his left pocket and one in his right. Each time he needs a match, he   is equally likely to take it from either pocket. Suppose he reaches   into his pocket and discovers for the first time that the box picked   is empty. If it is assumed that each of the matchboxes originally   contained $n$ matches, what is the probability that there are exactly $k$   matches in the other box? I'm wondering whether the following reasoning is right, because it doesn't match up with the correct probability. But here goes my reasoning: Assuming there are $k$ matches left in the other box, we have had to take $2n-k+1$ matches to notice there are none left. The total number of ways in which we could have picked those is $2 {2n - k \choose n}$, for either the matchbox in the left or right pocket has $k$ matches left inside, and in the $(2n-k+1)$th pick we would have found an empty box. The total number of possibilities, taken over all possible sizes $k$, would then be $\sum_{m=0}^{n} 2{2n-m \choose n}$. So I'd assume the overall probability would be $\frac{2 {2n - k \choose n}}{\sum_{m=0}^{n} 2 {2n-m \choose n}} =\frac{{2n - k \choose n}}{\sum_{m=0}^{n} {2n-m \choose n}}$. However, the mentioned solution is ${2n - k \choose n} (\tfrac{1}{2})^{2n-k}$. Where is my reasoning wrong? Thanks in advance.",,['probability']
19,"Irreducible, finite Markov chains are positive recurrent","Irreducible, finite Markov chains are positive recurrent",,"I am under the impression that an irreducible, finite Markov chain is necessarily positive recurrent. How might I show this? Regards, Jon","I am under the impression that an irreducible, finite Markov chain is necessarily positive recurrent. How might I show this? Regards, Jon",,"['probability', 'markov-chains']"
20,Why does this strategy to pick the largest envelope work?,Why does this strategy to pick the largest envelope work?,,"Game: You have two envelopes. Each one contains a real number. Choose one envelope and you get to see the number on it. Now you have two choices: select the same envelope, or swap. At the end, if you have chosen the greater number, You win. Problem: Find a strategy that gives you a probability of winning that is more than $0.5$ Solution: Choose one real number $x$ . If envelope one contains $y>x$ , keep it, else swap. My Question: Why does the strategy work? Can we prove that probability-theoretically?","Game: You have two envelopes. Each one contains a real number. Choose one envelope and you get to see the number on it. Now you have two choices: select the same envelope, or swap. At the end, if you have chosen the greater number, You win. Problem: Find a strategy that gives you a probability of winning that is more than Solution: Choose one real number . If envelope one contains , keep it, else swap. My Question: Why does the strategy work? Can we prove that probability-theoretically?",0.5 x y>x,"['probability', 'probability-theory', 'probability-distributions']"
21,A random sphere containing the center of the unit cube,A random sphere containing the center of the unit cube,,"Inspired by a Putnam problem, I came up with the following question: A point in randomly chosen in the unit cube, a sphere is then created using the random point as the center such that the sphere must be contained inside the cube (In other words, the largest sphere that fits). What is the probability that the center of the cube is contained inside the sphere created? No real idea how to approach this one but thought some of you might find this interesting.","Inspired by a Putnam problem, I came up with the following question: A point in randomly chosen in the unit cube, a sphere is then created using the random point as the center such that the sphere must be contained inside the cube (In other words, the largest sphere that fits). What is the probability that the center of the cube is contained inside the sphere created? No real idea how to approach this one but thought some of you might find this interesting.",,"['probability', 'contest-math', 'recreational-mathematics', 'geometric-probability']"
22,Operator $T \colon L^p \to L^p$ is a conditional expectation,Operator  is a conditional expectation,T \colon L^p \to L^p,"I'm trying to solve this problem: Let $(X,\mathcal{B},\mu)$ a probability space and $T \colon L^p(\mu) \to L^p(\mu)$ a continuous linear operator ($1 \leq p < \infty$ ) with the following properties: 1) $||T||=1$. 2) $T(1) = 1$. 3) $\forall g \in L^\infty(\mu), f \in L^p(\mu) \colon \, T(gT(f))=T(f)T(g)$. Then exists a sub $\sigma$-algebra $\mathcal{G} \subseteq \mathcal{B}$ such that $$ \forall f \in L^p(\mu) \colon \, T(f) = \mathbb{E}(f | \mathcal{G})$$ My attempt: We can define $$\mathcal{C}= \{g \in L^\infty \colon T(g) = g\}, \ \mathcal{G} = \sigma(\mathcal{C})$$  By the monotone class theorem is not to difficult to see that if $g \in L^\infty$ is $\mathcal{G}$-measurable then $T(g) = g$. Then I want to prove that for every $f \in L^\infty$ $T(f) = \mathbb{E}(f|\mathcal{G})$. $T(f) \in \mathcal{C}$ by property 2) then $T(f)$ is $\sigma(\mathcal{C})=\mathcal{G}$-measurable. Let $g \in L^\infty$ and $\mathcal{G}$-measurable. Then $$\int_X T(f)g d\mu = \int_X T(fg) d\mu =\cdots $$ I don't know how to procede from here. Any help will be appreciated.","I'm trying to solve this problem: Let $(X,\mathcal{B},\mu)$ a probability space and $T \colon L^p(\mu) \to L^p(\mu)$ a continuous linear operator ($1 \leq p < \infty$ ) with the following properties: 1) $||T||=1$. 2) $T(1) = 1$. 3) $\forall g \in L^\infty(\mu), f \in L^p(\mu) \colon \, T(gT(f))=T(f)T(g)$. Then exists a sub $\sigma$-algebra $\mathcal{G} \subseteq \mathcal{B}$ such that $$ \forall f \in L^p(\mu) \colon \, T(f) = \mathbb{E}(f | \mathcal{G})$$ My attempt: We can define $$\mathcal{C}= \{g \in L^\infty \colon T(g) = g\}, \ \mathcal{G} = \sigma(\mathcal{C})$$  By the monotone class theorem is not to difficult to see that if $g \in L^\infty$ is $\mathcal{G}$-measurable then $T(g) = g$. Then I want to prove that for every $f \in L^\infty$ $T(f) = \mathbb{E}(f|\mathcal{G})$. $T(f) \in \mathcal{C}$ by property 2) then $T(f)$ is $\sigma(\mathcal{C})=\mathcal{G}$-measurable. Let $g \in L^\infty$ and $\mathcal{G}$-measurable. Then $$\int_X T(f)g d\mu = \int_X T(fg) d\mu =\cdots $$ I don't know how to procede from here. Any help will be appreciated.",,"['probability', 'measure-theory']"
23,If $X$ and $Y$ are independent then $f(X)$ and $g(Y)$ are also independent.,If  and  are independent then  and  are also independent.,X Y f(X) g(Y),"Knowing that if you have two independent $X$ and $Y$, and $ f $ and $ g $ measurable functions, how to show that then $ U = f (X) $ and $ V = g (Y) $ are still independent.","Knowing that if you have two independent $X$ and $Y$, and $ f $ and $ g $ measurable functions, how to show that then $ U = f (X) $ and $ V = g (Y) $ are still independent.",,"['probability', 'probability-distributions']"
24,How do I generate doubly-stochastic matrices uniform randomly?,How do I generate doubly-stochastic matrices uniform randomly?,,A doubly-stochastic matrix is an $n \times n$ matrix $P$ such that $$ \sum_{i=1}^n p_{ij} = \sum_{j=1}^n p_{ij} = 1 $$ where $p_{ij}\ge 0$ . Can someone please suggest an algorithm for generating these matrices uniform randomly?,A doubly-stochastic matrix is an matrix such that where . Can someone please suggest an algorithm for generating these matrices uniform randomly?,n \times n P  \sum_{i=1}^n p_{ij} = \sum_{j=1}^n p_{ij} = 1  p_{ij}\ge 0,"['probability', 'matrices', 'stochastic-matrices', 'birkhoff-polytopes']"
25,How often do we expect a random walk with decreasing step size to cross $0$?,How often do we expect a random walk with decreasing step size to cross ?,0,"Let $S_n = \sum_{i=1}^{n} X_i$ be a random walk where the steps $X_i$ are $+\frac{1}{i}$ or $-\frac{1}{i}$ with equal probability. How often do we expect such a walk to cross $0$ ?  By ""cross 0"", I mean that $S_i$ has the opposite sign as $S_{i-1}$ . I'll use the following notation for such a crossing: $S_i \updownarrow 0$","Let be a random walk where the steps are or with equal probability. How often do we expect such a walk to cross ?  By ""cross 0"", I mean that has the opposite sign as . I'll use the following notation for such a crossing:",S_n = \sum_{i=1}^{n} X_i X_i +\frac{1}{i} -\frac{1}{i} 0 S_i S_{i-1} S_i \updownarrow 0,"['probability', 'random-variables', 'random-walk']"
26,Doubling Money Game,Doubling Money Game,,"The casino offers a certain win-lose game, where you have $p$ chance of winning. You can bet any amount of money, and if you win you get twice your bet; otherwise, you lose your bet. If you use the optimal strategy, what is your chance of doubling your money, as a function of $p$? I came up with the following incorrect solution: You have a 100% chance of winning if $p>\frac{1}{2}$ and $p$ chance of winning if $p<\frac{1}{2}$. Suppose that $p>\frac{1}{2}$. Then each time you bet exactly half your money. If you have $x$ dollars, you end up with $\frac{3}{2}x$ if you win and $\frac{1}{2}x$ if you lose, hence your expected outcome is $\frac{3}{2} xp + \frac{1}{2}x(1-p)$ which equals $xp + \frac{1}{2}x$. So if $p>\frac{1}{2}$, then the total is greater than $x$. Given that each game on average gains you money and you can play an arbitrary number of games, of course you should have 100% chance of doubling your money. Similarly, if $p<\frac{1}{2}$, it can be shown that no matter how much we bet, we lose money on average. Then on average our money will tend to go toward zero, so we're better off just going all-in at the start, with $p$ chance of doubling our money. I do not understand the proper solution, but I think this solution is incorrect; however, I'm having trouble pinpointing where my proof falls apart. Thanks. Edit : for reference I've included a screenshot of the given solution.","The casino offers a certain win-lose game, where you have $p$ chance of winning. You can bet any amount of money, and if you win you get twice your bet; otherwise, you lose your bet. If you use the optimal strategy, what is your chance of doubling your money, as a function of $p$? I came up with the following incorrect solution: You have a 100% chance of winning if $p>\frac{1}{2}$ and $p$ chance of winning if $p<\frac{1}{2}$. Suppose that $p>\frac{1}{2}$. Then each time you bet exactly half your money. If you have $x$ dollars, you end up with $\frac{3}{2}x$ if you win and $\frac{1}{2}x$ if you lose, hence your expected outcome is $\frac{3}{2} xp + \frac{1}{2}x(1-p)$ which equals $xp + \frac{1}{2}x$. So if $p>\frac{1}{2}$, then the total is greater than $x$. Given that each game on average gains you money and you can play an arbitrary number of games, of course you should have 100% chance of doubling your money. Similarly, if $p<\frac{1}{2}$, it can be shown that no matter how much we bet, we lose money on average. Then on average our money will tend to go toward zero, so we're better off just going all-in at the start, with $p$ chance of doubling our money. I do not understand the proper solution, but I think this solution is incorrect; however, I'm having trouble pinpointing where my proof falls apart. Thanks. Edit : for reference I've included a screenshot of the given solution.",,['probability']
27,length of Gaussian Random Vector,length of Gaussian Random Vector,,"Suppose I have a random vector $x=[x_1,...,x_k]$ s.t. $x∼N(\mu,\sum)$. How is the length or magnitude of $x$ distributed? I know that if $k=2$ and $\sigma_1=\sigma_2$ and $\sigma_{12}=0$ ($x_1$ and $x_2$ are not correlated), it is Rayleigh distribution. I also know that $\sqrt{\sum_{i=1}^k(\frac{x_i-\mu_i}{\sigma_i})^2}$ is Chi distributed (no correlation). However, the random variables are normalized by its standard deviation, it is just the length of a zero-mean unit variance Gaussian vector. If it is not zero mean, we can have noncentral chi distribution. It is non-zero-mean but still unit variance Gaussian vector. So my question is: When $\sigma_i$ has different values for all $i=1,...,k$, what is the distribution of vector length/magnitude $|x|=\sqrt{\sum_{i=1}^k x_i^2}$? When the random variables are correlated, what is the distribution of the vector length/magnitude $|x|=\sqrt{\sum_{i=1}^k x_i^2}$?","Suppose I have a random vector $x=[x_1,...,x_k]$ s.t. $x∼N(\mu,\sum)$. How is the length or magnitude of $x$ distributed? I know that if $k=2$ and $\sigma_1=\sigma_2$ and $\sigma_{12}=0$ ($x_1$ and $x_2$ are not correlated), it is Rayleigh distribution. I also know that $\sqrt{\sum_{i=1}^k(\frac{x_i-\mu_i}{\sigma_i})^2}$ is Chi distributed (no correlation). However, the random variables are normalized by its standard deviation, it is just the length of a zero-mean unit variance Gaussian vector. If it is not zero mean, we can have noncentral chi distribution. It is non-zero-mean but still unit variance Gaussian vector. So my question is: When $\sigma_i$ has different values for all $i=1,...,k$, what is the distribution of vector length/magnitude $|x|=\sqrt{\sum_{i=1}^k x_i^2}$? When the random variables are correlated, what is the distribution of the vector length/magnitude $|x|=\sqrt{\sum_{i=1}^k x_i^2}$?",,"['probability', 'normal-distribution']"
28,Can I normalize KL-divergence to be $\leq 1$?,Can I normalize KL-divergence to be ?,\leq 1,"The Kullback-Leibler divergence has a strong relationship with mutual information, and mutual information has a number of normalized variants .  Is there some similar, entropy-like value that I can use to normalize KL-divergence such that the normalized KL-divergence is bounded above by 1 (and below by 0)?","The Kullback-Leibler divergence has a strong relationship with mutual information, and mutual information has a number of normalized variants .  Is there some similar, entropy-like value that I can use to normalize KL-divergence such that the normalized KL-divergence is bounded above by 1 (and below by 0)?",,"['probability', 'probability-theory', 'information-theory', 'entropy']"
29,Concentration inequality for sum of squares of i.i.d. sub-exponential random variables?,Concentration inequality for sum of squares of i.i.d. sub-exponential random variables?,,"Suppose $X_1, X_2, \ldots, X_n$ are independent and each has the same distribution with a sub-exponential random variable $X$ (for example, $X$ is the square of a standard normal Gaussian variable). Can I obtain a concentration inequality for the square of sub-exponential $X_i$ , say, $$\mathbb{P}\left( \frac{1}{n} \left( X_1^2+\cdots+X_n^2 \right) \ge \mathbb{E}\left[X^2\right] + t \right) \le C \exp\left( - n \cdot \min\left( C_1 t^2, C_2 t, C_3 \sqrt{t} \right) \right),$$ where $C, C_1, C_2, C_3$ are constants? This problem arises in my research. Remark: Actually, for i.i.d. sub-Gaussian random variables $Y_i\ (i=1,\ldots,n)$, I knew that $$\mathbb{P}\left( \frac{1}{n} \left(Y_1+\cdots+Y_n\right) \ge \mathbb{E}\left[Y\right] + t \right) \le \exp\left( - n\cdot C_1 t^2 \right).$$ Besides, since $Y_i^2\ (i=1,2,\ldots,n)$ are sub-exponential , I also knew that $$\mathbb{P}\left( \frac{1}{n} \left(Y_1^2+\cdots+Y_n^2\right)\ge \mathbb{E}\left[ Y^2 \right] + t \right) \le \exp\left( - n\cdot \min(C_1 t^2, C_2 t) \right).$$ These two inequalities can be proved by a Chernoff bound, since the moment generating functions of $Y$ (sub-Gaussian) and $Y^2$ (sub-exponential) both exist. However, I want to know whether there is an inequality like $$\mathbb{P}\left( \frac{1}{n} \left( Y_1^4+\cdots+Y_n^4 \right) \ge \mathbb{E}\left[Y^4\right] + t \right) \le C \exp\left( - n \cdot \min\left( C_1 t^2, C_2 t, C_3 \sqrt{t} \right) \right),$$ even though the moment generating function of $Y^4$ (square of sub-exponential) does not exist.","Suppose $X_1, X_2, \ldots, X_n$ are independent and each has the same distribution with a sub-exponential random variable $X$ (for example, $X$ is the square of a standard normal Gaussian variable). Can I obtain a concentration inequality for the square of sub-exponential $X_i$ , say, $$\mathbb{P}\left( \frac{1}{n} \left( X_1^2+\cdots+X_n^2 \right) \ge \mathbb{E}\left[X^2\right] + t \right) \le C \exp\left( - n \cdot \min\left( C_1 t^2, C_2 t, C_3 \sqrt{t} \right) \right),$$ where $C, C_1, C_2, C_3$ are constants? This problem arises in my research. Remark: Actually, for i.i.d. sub-Gaussian random variables $Y_i\ (i=1,\ldots,n)$, I knew that $$\mathbb{P}\left( \frac{1}{n} \left(Y_1+\cdots+Y_n\right) \ge \mathbb{E}\left[Y\right] + t \right) \le \exp\left( - n\cdot C_1 t^2 \right).$$ Besides, since $Y_i^2\ (i=1,2,\ldots,n)$ are sub-exponential , I also knew that $$\mathbb{P}\left( \frac{1}{n} \left(Y_1^2+\cdots+Y_n^2\right)\ge \mathbb{E}\left[ Y^2 \right] + t \right) \le \exp\left( - n\cdot \min(C_1 t^2, C_2 t) \right).$$ These two inequalities can be proved by a Chernoff bound, since the moment generating functions of $Y$ (sub-Gaussian) and $Y^2$ (sub-exponential) both exist. However, I want to know whether there is an inequality like $$\mathbb{P}\left( \frac{1}{n} \left( Y_1^4+\cdots+Y_n^4 \right) \ge \mathbb{E}\left[Y^4\right] + t \right) \le C \exp\left( - n \cdot \min\left( C_1 t^2, C_2 t, C_3 \sqrt{t} \right) \right),$$ even though the moment generating function of $Y^4$ (square of sub-exponential) does not exist.",,"['probability', 'probability-theory', 'statistics']"
30,Taxicab metric *with stoplights*; does it ever give the Euclidean metric?,Taxicab metric *with stoplights*; does it ever give the Euclidean metric?,,"This question is not terribly formal in nature, but please bear with me: what I’m looking for is a model of traveling via taxi on a grid of streets where the “metric” in some sense becomes the standard Euclidean metric in a limit, for non-trivial reasons. I’ll elaborate below: Recall the taxicab metric in the plane, where $d(x, y) = |x_1 - x_2| + |y_2 - y_2|$ . I'm interested in looking at restricting this to $\mathbb{Z}^2$ , and using that as a basis for a model in which we imagine taxis traveling on actual streets, where we then add complexity to the model (in ways that plausibly model car traffic, though it need not be actually realistic—extreme idealization is okay). For example, one could imagine that on each lattice point, for each direction there is a $50\%$ chance it is blocked by a red light for $1$ unit of time; perhaps we also let traveling cost $1$ unit of time between lattice points when not stopped by a light. In this model, the expected time to get to two points depends on more than just the taxicab metric; you’d rather be $10$ units north and $10$ units west of your destination than $20$ units north, since in the former case when one of your ways is stopped, you have the choice of making progress in the other direction rather than having to stop and wait. (In fact, even if both ways are open, you want to move in the way that keeps how far you have to move south vs east as “balanced” as possible—I’ve made choices in real life based on this). As a result of this, the “balls” around where you start are no longer diamond-shaped as in the taxicab metric (of course, we don't really have a metric, but a probabilistic model, where one can think in terms of expected times, and take approximate level sets of this and see the limiting shape: I’m intentionally informal here as I’m open to answers that take this in different directions). In fact, if I recall, I believe this forms an octagon, in some sense! What I would like is model in the spirit of the above, devised so that the “balls” in some expected sense form a Euclidean circle. That is, for larger $r$ , the expected time to move approximately $r$ in any given direction (not just north and south; just look at lattice points near $r$ in some direction) is the same as $r$ goes to infinity. One reason one might be hopeful such a model exists is because there are examples of things defined on a grid where in the limit, Euclidean symmetry is recovered (see Brownian motion defined as a limit of random walks on a grid as an example of this). I’m open to various creative things leading to this behavior, such as other cars, weird stoplight systems, etc, though ideally there is some degree of elegance to the model and it doesn’t immediately feel cooked up to give a Euclidean result.","This question is not terribly formal in nature, but please bear with me: what I’m looking for is a model of traveling via taxi on a grid of streets where the “metric” in some sense becomes the standard Euclidean metric in a limit, for non-trivial reasons. I’ll elaborate below: Recall the taxicab metric in the plane, where . I'm interested in looking at restricting this to , and using that as a basis for a model in which we imagine taxis traveling on actual streets, where we then add complexity to the model (in ways that plausibly model car traffic, though it need not be actually realistic—extreme idealization is okay). For example, one could imagine that on each lattice point, for each direction there is a chance it is blocked by a red light for unit of time; perhaps we also let traveling cost unit of time between lattice points when not stopped by a light. In this model, the expected time to get to two points depends on more than just the taxicab metric; you’d rather be units north and units west of your destination than units north, since in the former case when one of your ways is stopped, you have the choice of making progress in the other direction rather than having to stop and wait. (In fact, even if both ways are open, you want to move in the way that keeps how far you have to move south vs east as “balanced” as possible—I’ve made choices in real life based on this). As a result of this, the “balls” around where you start are no longer diamond-shaped as in the taxicab metric (of course, we don't really have a metric, but a probabilistic model, where one can think in terms of expected times, and take approximate level sets of this and see the limiting shape: I’m intentionally informal here as I’m open to answers that take this in different directions). In fact, if I recall, I believe this forms an octagon, in some sense! What I would like is model in the spirit of the above, devised so that the “balls” in some expected sense form a Euclidean circle. That is, for larger , the expected time to move approximately in any given direction (not just north and south; just look at lattice points near in some direction) is the same as goes to infinity. One reason one might be hopeful such a model exists is because there are examples of things defined on a grid where in the limit, Euclidean symmetry is recovered (see Brownian motion defined as a limit of random walks on a grid as an example of this). I’m open to various creative things leading to this behavior, such as other cars, weird stoplight systems, etc, though ideally there is some degree of elegance to the model and it doesn’t immediately feel cooked up to give a Euclidean result.","d(x, y) = |x_1 - x_2| + |y_2 - y_2| \mathbb{Z}^2 50\% 1 1 10 10 20 r r r r","['probability', 'metric-spaces', 'euclidean-geometry', 'mathematical-modeling', 'random-walk']"
31,Is this distribution already known and has a name?,Is this distribution already known and has a name?,,"My question is whether the distribution on $\Bbb R$ with probability density $$ f(x) := \frac 2 {\sqrt{2\pi}} e^{-\frac{x^2}{2}} - 2 \vert x\vert \int_{\vert x \vert}^\infty \frac 1{\sqrt{2\pi}} e^{-\frac{y^2} 2} \text d y$$ is already appearing in some context or even has a name or is part of a wider class of distributions. Here it is. I discovered the following. Let $U_n$ be uniformly distributed on $\{1, \ldots , n \}$ and $X_{n,k}$ normal distributed with mean $0$ and variance $k/n$ , independent. Then $$X_{n, U_n} \to Z$$ where $Z$ has the density above. Proof: The characteristic function of $X_{n, U_n}$ converges pointwise to $$t \mapsto \frac{1 - e^{- \frac 1 2 t^2 }}{\frac 1 2 t^2 }$$ By Levy's continuity theorem the laws of $X_{n, U_n}$ have a weak limit. By Fourier inversion one can derive the density of $Z$ .","My question is whether the distribution on with probability density is already appearing in some context or even has a name or is part of a wider class of distributions. Here it is. I discovered the following. Let be uniformly distributed on and normal distributed with mean and variance , independent. Then where has the density above. Proof: The characteristic function of converges pointwise to By Levy's continuity theorem the laws of have a weak limit. By Fourier inversion one can derive the density of .","\Bbb R  f(x) := \frac 2 {\sqrt{2\pi}} e^{-\frac{x^2}{2}} - 2 \vert x\vert \int_{\vert x \vert}^\infty \frac 1{\sqrt{2\pi}} e^{-\frac{y^2} 2} \text d y U_n \{1, \ldots , n \} X_{n,k} 0 k/n X_{n, U_n} \to Z Z X_{n, U_n} t \mapsto \frac{1 - e^{- \frac 1 2 t^2 }}{\frac 1 2 t^2 } X_{n, U_n} Z","['probability', 'probability-distributions', 'terminology', 'normal-distribution', 'density-function']"
32,Interpreting the Lindeberg's condition,Interpreting the Lindeberg's condition,,"I know the Lindeberg's CLT but I don't have a good grasp of the intuition behind the Lindeberg's condition. Could you please give some intuition behind said condition via an example (or, perhaps, via 2 related examples, one satisfying the condition and one not satisfying). For completeness and to fix notation, I reproduce the wiki's statement of the Lindeberg's CLT and condition below. Please note that wiki provides an intuition based on a consequence of the Lindeberg's condition. I don't this intuition helpful. Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space, and $X_k:\Omega\to\mathbb{R}, k\in\mathbb{N}$, be independent random variables defined on that space. Assume the expected values $E(X_k)=\mu_k$ and variances $\text{Var}(X_k)=\sigma_k^2$ exist and are finite. Also let $s_n^2\equiv\sum_{k=1}^n\sigma_k^2$. If this sequence of independent variables $X_k$ satisfies Lindeberg's condition :   $$ \lim_{n\to\infty}\frac{1}{s^2_n}\sum_{k=1}^nE[(X_k-\mu_k)^2\cdot1_{|X_k-\mu_k|>\epsilon s_n|}=0 $$   for all $\epsilon>0$, where $1_{\{\cdots\}}$ is the indicator function, then the central limit theorem holds:   $$ Z_n:=\frac{\sum_{k=1}^n(X_k-\mu_k)}{s_n}\overset{L}{\to}N(0,1). $$","I know the Lindeberg's CLT but I don't have a good grasp of the intuition behind the Lindeberg's condition. Could you please give some intuition behind said condition via an example (or, perhaps, via 2 related examples, one satisfying the condition and one not satisfying). For completeness and to fix notation, I reproduce the wiki's statement of the Lindeberg's CLT and condition below. Please note that wiki provides an intuition based on a consequence of the Lindeberg's condition. I don't this intuition helpful. Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space, and $X_k:\Omega\to\mathbb{R}, k\in\mathbb{N}$, be independent random variables defined on that space. Assume the expected values $E(X_k)=\mu_k$ and variances $\text{Var}(X_k)=\sigma_k^2$ exist and are finite. Also let $s_n^2\equiv\sum_{k=1}^n\sigma_k^2$. If this sequence of independent variables $X_k$ satisfies Lindeberg's condition :   $$ \lim_{n\to\infty}\frac{1}{s^2_n}\sum_{k=1}^nE[(X_k-\mu_k)^2\cdot1_{|X_k-\mu_k|>\epsilon s_n|}=0 $$   for all $\epsilon>0$, where $1_{\{\cdots\}}$ is the indicator function, then the central limit theorem holds:   $$ Z_n:=\frac{\sum_{k=1}^n(X_k-\mu_k)}{s_n}\overset{L}{\to}N(0,1). $$",,"['probability', 'probability-theory', 'statistics', 'asymptotics', 'central-limit-theorem']"
33,Constructing an $\epsilon$-net of $l_2$ unit ball,Constructing an -net of  unit ball,\epsilon l_2,"I am interested in probabilistic or explicit ways to construct an $\epsilon$ -net of the $l_2$ unit ball in $\mathbb{R}^{d}$ . I know that, for every $\epsilon > 0$ , there exists an $\epsilon$ -net $\mathcal{N}_{\epsilon}$ for the unit sphere in $d$ dimensions such that $$ M\triangleq\left|\mathcal{N}_{\epsilon}\right| \le \left( 1+\frac{2}{\epsilon}\right)^{d}. $$ (Lemma 5.2 in https://arxiv.org/abs/1011.3027 ) To my understanding, the aforementioned bound holds for an $\epsilon$ -net of the entire ball, not only the sphere. In the case of the sphere, we can construct an $\epsilon$ -net with high probability,  by drawing a sufficient number ( $O(M\log{M})$ ) of independent random vectors according to a Gaussian distribution $N(\mathbf{0}, \mathbf{I})$ , and normalizing the length to $1$ . I believe that one way to get an $\epsilon$ -net for the ball, would be to repeat the above procedure $O(1/\epsilon)$ times, for all spheres of radii $\epsilon, 2\epsilon,3\epsilon, \dots, 1$ . The union of the $\epsilon$ -nets, should be able to cover the ball. However, it would require $\tilde{O}\left((1+2/{\epsilon})^{d+1}\right)$ points (ignoring the logarithmic factor). Is there a simple way to construct an $\epsilon$ -net for the unit ball directly, $\textit{i.e.}$ , without constructing nets for multiple spheres? Is there way to achieve the bound on $\left|\mathcal{N}_{\epsilon}\right|$ (possibly up to logarithmic factors)? I would appreciate any pointers to either probabilistic or explicit methods.","I am interested in probabilistic or explicit ways to construct an -net of the unit ball in . I know that, for every , there exists an -net for the unit sphere in dimensions such that (Lemma 5.2 in https://arxiv.org/abs/1011.3027 ) To my understanding, the aforementioned bound holds for an -net of the entire ball, not only the sphere. In the case of the sphere, we can construct an -net with high probability,  by drawing a sufficient number ( ) of independent random vectors according to a Gaussian distribution , and normalizing the length to . I believe that one way to get an -net for the ball, would be to repeat the above procedure times, for all spheres of radii . The union of the -nets, should be able to cover the ball. However, it would require points (ignoring the logarithmic factor). Is there a simple way to construct an -net for the unit ball directly, , without constructing nets for multiple spheres? Is there way to achieve the bound on (possibly up to logarithmic factors)? I would appreciate any pointers to either probabilistic or explicit methods.","\epsilon l_2 \mathbb{R}^{d} \epsilon > 0 \epsilon \mathcal{N}_{\epsilon} d 
M\triangleq\left|\mathcal{N}_{\epsilon}\right|
\le \left( 1+\frac{2}{\epsilon}\right)^{d}.
 \epsilon \epsilon O(M\log{M}) N(\mathbf{0}, \mathbf{I}) 1 \epsilon O(1/\epsilon) \epsilon, 2\epsilon,3\epsilon, \dots, 1 \epsilon \tilde{O}\left((1+2/{\epsilon})^{d+1}\right) \epsilon \textit{i.e.} \left|\mathcal{N}_{\epsilon}\right|",['probability']
34,Problem on EU commission,Problem on EU commission,,"Consider the following problem. A collection of $n$ countries $C_1, \dots, C_n$ sit on an EU commission. Each country $C_i$ is assigned a voting weight $c_i$. A resolution passes if it has the support of a proportion of the panel of at least $A$, taking into account voting weights. Each country $C_i$ has a probability $p_i$ of voting for the resolution, and each country acts independently of the others. The problem is to assign the voting weights so as to maximize the probability that any given resolution will pass. I am interested in answering the question asymptotically under something like the following assumptions. The number of countries $n$ is very large. (Perhaps the EU's $n = 28$ is already not so far from this!) The proportion of votes held by any one country is bounded above by $M/n$, for some fixed reasonable number $M$. $p_i > A$ for all $i$. The probabilities $p_i$ are bounded away from $1$. Perhaps some of these conditions can be relaxed, or perhaps additional assumptions are needed, but these are the ones that seem to be needed for my arguments below. I have tried to answer the question in an approximate and non-rigorous way as follows. Let $X_i$ be the random variable equal to $1$ when country $C_i$ votes for the resolution, and $0$ otherwise. Now let $V = \sum c_i X_i$. By a suitably general version of the central limit theorem (the Berry-Esseen inequality?), $V$ follows approximately a normal distribution with mean $\sum c_i p_i$ and variance $\sum c_i^2 p_i(1-p_i)$. The probability that we would like to maximize is  $$P\left( V \geq A\sum c_i \right).$$ If we let $F(z)$ be the cumulative distribution function for the standard normal distribution, this probability can be approximated by $F(z)$ where $$z = \frac{\sum c_i(p_i - A)}{\left[\sum c_i^2 p_i (1-p_i) \right]^{1/2}}. $$ Considering the gradient of the function $z = z(c_1,\dots,c_n)$ shows that $z$ is maximal when the weights $c_i$ are proportional to the numbers $$\gamma_i = \frac{p_i - A}{p_i(1-p_i)}.$$ I conclude that it is plausible that the weights $c_i = \gamma_i$ are close to being optimal. My questions, in descending order of importance, are: Has anything significant been written on this problem, or an equivalent one? Is my ""theorem"" correct? What would a rigorous formulation of the ""theorem"" look like? EDIT: I've simulated the problem for $A = 0.5$ with 1867 countries with a 50.17% chance of voting in favour and 637 countries with a probability of 50.5%. I gave weight $1$ to each of the first group of countries and weight $c$ to the second. In the graph below, the horizontal axis is for $c$, and the vertical axis for the probability of passing the resolution. The blue curve represents the theoretical probability we would have if the normal approximation worked perfectly, and the red curve experimental data based on 5 million repetitions of the experiment. The maximum for the red graph is not too far from the conjectured optimal value of $\gamma = 2.94$. EDIT: In response to a comment, here are some additional details on the maximization of $z$ above. By homogeneity, it makes no difference whether or not we constrain the $c_i$'s to have sum $1$. But if we do, then a compactness argument shows that $z$ must attain a maximum at some point. Now return to unconstrained $c_i$'s. $\partial z/\partial c_i$ has the same sign as $$\frac{\sum c_j^2 p_j (1 - p_j)}{\sum c_j (p_j - A)} \gamma_i - c_i.$$ This shows that where the maximum occurs, all the $c_i$'s must be proportional to $\gamma_i$.","Consider the following problem. A collection of $n$ countries $C_1, \dots, C_n$ sit on an EU commission. Each country $C_i$ is assigned a voting weight $c_i$. A resolution passes if it has the support of a proportion of the panel of at least $A$, taking into account voting weights. Each country $C_i$ has a probability $p_i$ of voting for the resolution, and each country acts independently of the others. The problem is to assign the voting weights so as to maximize the probability that any given resolution will pass. I am interested in answering the question asymptotically under something like the following assumptions. The number of countries $n$ is very large. (Perhaps the EU's $n = 28$ is already not so far from this!) The proportion of votes held by any one country is bounded above by $M/n$, for some fixed reasonable number $M$. $p_i > A$ for all $i$. The probabilities $p_i$ are bounded away from $1$. Perhaps some of these conditions can be relaxed, or perhaps additional assumptions are needed, but these are the ones that seem to be needed for my arguments below. I have tried to answer the question in an approximate and non-rigorous way as follows. Let $X_i$ be the random variable equal to $1$ when country $C_i$ votes for the resolution, and $0$ otherwise. Now let $V = \sum c_i X_i$. By a suitably general version of the central limit theorem (the Berry-Esseen inequality?), $V$ follows approximately a normal distribution with mean $\sum c_i p_i$ and variance $\sum c_i^2 p_i(1-p_i)$. The probability that we would like to maximize is  $$P\left( V \geq A\sum c_i \right).$$ If we let $F(z)$ be the cumulative distribution function for the standard normal distribution, this probability can be approximated by $F(z)$ where $$z = \frac{\sum c_i(p_i - A)}{\left[\sum c_i^2 p_i (1-p_i) \right]^{1/2}}. $$ Considering the gradient of the function $z = z(c_1,\dots,c_n)$ shows that $z$ is maximal when the weights $c_i$ are proportional to the numbers $$\gamma_i = \frac{p_i - A}{p_i(1-p_i)}.$$ I conclude that it is plausible that the weights $c_i = \gamma_i$ are close to being optimal. My questions, in descending order of importance, are: Has anything significant been written on this problem, or an equivalent one? Is my ""theorem"" correct? What would a rigorous formulation of the ""theorem"" look like? EDIT: I've simulated the problem for $A = 0.5$ with 1867 countries with a 50.17% chance of voting in favour and 637 countries with a probability of 50.5%. I gave weight $1$ to each of the first group of countries and weight $c$ to the second. In the graph below, the horizontal axis is for $c$, and the vertical axis for the probability of passing the resolution. The blue curve represents the theoretical probability we would have if the normal approximation worked perfectly, and the red curve experimental data based on 5 million repetitions of the experiment. The maximum for the red graph is not too far from the conjectured optimal value of $\gamma = 2.94$. EDIT: In response to a comment, here are some additional details on the maximization of $z$ above. By homogeneity, it makes no difference whether or not we constrain the $c_i$'s to have sum $1$. But if we do, then a compactness argument shows that $z$ must attain a maximum at some point. Now return to unconstrained $c_i$'s. $\partial z/\partial c_i$ has the same sign as $$\frac{\sum c_j^2 p_j (1 - p_j)}{\sum c_j (p_j - A)} \gamma_i - c_i.$$ This shows that where the maximum occurs, all the $c_i$'s must be proportional to $\gamma_i$.",,"['probability', 'probability-theory', 'optimization']"
35,Density of odd numbers in a sequence relating base 2 and base 3 expansion,Density of odd numbers in a sequence relating base 2 and base 3 expansion,,"Define the function $$f(4n)=6n+1\\ f(4n+1)=6n+2\\ f(4n+2)=6n+3\\ f(4n+3)=6n+5$$ and the sequence $u_0=2$, $u_{k+1}=f(u_k)$. Let $d_1\le d_2$ be the lower and upper asymptotic density of odd numbers in $u_k$. Since $f(n)$ is odd for even $n$, no two consecutive terms can be even so obviously $d_1\ge 1/2$. Experimentally, it seems reasonable to conjecture $d=d_1=d_2=2/3$. Heuristically, when $n$ is odd, $f(n)$ has ""probability 1/2"" to be even, so we get this Markov chain: which is consistent with $d=2/3$. But can we prove rigorously that the heuristic works, that is that $u_k$ is ""random enough"" for this to be true? Failing that, a sharper lower bound on $d_1$ could still be an interesting result. (One approach could be to let $a_k=1$ if $u_k$ is even and $0$ otherwise, and examine the probabilities of the $p$-bit subwords $(a_k,\dots,a_{k+p-1})$. Unfortunately every Fibonacci word, that is one not containing the pattern 11, seems to appear infinitely frequently in $a_k$. This is consistent with the Markov chain model.) PS: If you're wondering, the problem arose from this question . Response to comments: Someone suggested to work modulo some larger number, such as 12. The problem with this approach is that if the input is considered mod $2^a 3^b$, the output will only be known mod $2^{a-1} 3^{b+1}$ so you're not going to be able to say much about the behavior of $f$ when iterating more than $a$ times. And it seems that $010101\dots$ can always appear as a subword of $a_k$, so you won't be able to prove anything non-trivial about the density by proving something about the density after $k$ iterations starting from an arbitrary state (that is, by examining $f^k$ for bounded $k$). The first few terms are 2, 3, 5, 8, 13, 20, 31, 47, 71, 107, 161, 242. The sequence grows as $\Theta((3/2)^n)$. Interestingly, notice how closely the first few terms match the Fibonacci sequence (which can be explained by how close $3/2$ is to the golden ratio and by the fact that modulo 2, neither sequence contains the pattern 00).","Define the function $$f(4n)=6n+1\\ f(4n+1)=6n+2\\ f(4n+2)=6n+3\\ f(4n+3)=6n+5$$ and the sequence $u_0=2$, $u_{k+1}=f(u_k)$. Let $d_1\le d_2$ be the lower and upper asymptotic density of odd numbers in $u_k$. Since $f(n)$ is odd for even $n$, no two consecutive terms can be even so obviously $d_1\ge 1/2$. Experimentally, it seems reasonable to conjecture $d=d_1=d_2=2/3$. Heuristically, when $n$ is odd, $f(n)$ has ""probability 1/2"" to be even, so we get this Markov chain: which is consistent with $d=2/3$. But can we prove rigorously that the heuristic works, that is that $u_k$ is ""random enough"" for this to be true? Failing that, a sharper lower bound on $d_1$ could still be an interesting result. (One approach could be to let $a_k=1$ if $u_k$ is even and $0$ otherwise, and examine the probabilities of the $p$-bit subwords $(a_k,\dots,a_{k+p-1})$. Unfortunately every Fibonacci word, that is one not containing the pattern 11, seems to appear infinitely frequently in $a_k$. This is consistent with the Markov chain model.) PS: If you're wondering, the problem arose from this question . Response to comments: Someone suggested to work modulo some larger number, such as 12. The problem with this approach is that if the input is considered mod $2^a 3^b$, the output will only be known mod $2^{a-1} 3^{b+1}$ so you're not going to be able to say much about the behavior of $f$ when iterating more than $a$ times. And it seems that $010101\dots$ can always appear as a subword of $a_k$, so you won't be able to prove anything non-trivial about the density by proving something about the density after $k$ iterations starting from an arbitrary state (that is, by examining $f^k$ for bounded $k$). The first few terms are 2, 3, 5, 8, 13, 20, 31, 47, 71, 107, 161, 242. The sequence grows as $\Theta((3/2)^n)$. Interestingly, notice how closely the first few terms match the Fibonacci sequence (which can be explained by how close $3/2$ is to the golden ratio and by the fact that modulo 2, neither sequence contains the pattern 00).",,"['probability', 'number-theory', 'sequences-and-series', 'conjectures']"
36,Expected number of coin flips until all cars move to end of array?,Expected number of coin flips until all cars move to end of array?,,"Imagine that we have an array of length $2n$ , where the first $n$ entries are a $C$ (representing a toy car) and the remaining $n$ entries are empty. Additionally, we have $n$ fair coins labeled $1$ through $n$ , where coin $i$ corresponds to car $C_i$ in the array. On each timestep, we flip all $n$ coins. If coin $i$ comes up as heads, then car $C_i$ moves forward in the array by one spot, but only if it is not blocked by another car directly in the slot in front of it. Else, if blocked or the coin comes up tails, car $C_i$ does nothing. The question has two parts: What is the expected number of timesteps until the $n$ - $th$ car reaches the end of the array (reaches slot $2n$ )? What is the expected number of timesteps until all of the $n$ cars have moved from the first $n$ slots of the array to the last $n$ slots? I have worked out part 1 as follows. The expected number of flips for one coin to land as heads is $2$ , and the $n$ - $th$ car has to move $n$ slots to get to the end (and is not blocked by anything ever), so the expected number of timesteps is $2n$ . However, I am lost on the approach to part 2. I reason that it should be on the order $O(n\log n$ ) but do not know how to proceed. I keep running into a long chain of conditional probabilities and wonder if there is a more elegant way I am missing.","Imagine that we have an array of length , where the first entries are a (representing a toy car) and the remaining entries are empty. Additionally, we have fair coins labeled through , where coin corresponds to car in the array. On each timestep, we flip all coins. If coin comes up as heads, then car moves forward in the array by one spot, but only if it is not blocked by another car directly in the slot in front of it. Else, if blocked or the coin comes up tails, car does nothing. The question has two parts: What is the expected number of timesteps until the - car reaches the end of the array (reaches slot )? What is the expected number of timesteps until all of the cars have moved from the first slots of the array to the last slots? I have worked out part 1 as follows. The expected number of flips for one coin to land as heads is , and the - car has to move slots to get to the end (and is not blocked by anything ever), so the expected number of timesteps is . However, I am lost on the approach to part 2. I reason that it should be on the order ) but do not know how to proceed. I keep running into a long chain of conditional probabilities and wonder if there is a more elegant way I am missing.",2n n C n n 1 n i C_i n i C_i C_i n th 2n n n n 2 n th n 2n O(n\log n,"['probability', 'random-variables', 'expected-value']"
37,Expected Value of the maximum of two exponentially distributed random variables,Expected Value of the maximum of two exponentially distributed random variables,,"I want to find the expected value of $\text{max}\{X,Y\}$ where $X$ ist $\text{exp}(\lambda)$-distributed and $Y$ ist $\text{exp}(\eta)$-distributed. X and Y are independent. I figured out how to do this for the minimum of $n$ variables, but i struggle with doing it for 2 with the maximum. (The context in which this was given is waiting for the later of two trains, with their arrival times being exp-distributed). Thanks!","I want to find the expected value of $\text{max}\{X,Y\}$ where $X$ ist $\text{exp}(\lambda)$-distributed and $Y$ ist $\text{exp}(\eta)$-distributed. X and Y are independent. I figured out how to do this for the minimum of $n$ variables, but i struggle with doing it for 2 with the maximum. (The context in which this was given is waiting for the later of two trains, with their arrival times being exp-distributed). Thanks!",,"['probability', 'statistics']"
38,Expected number of tosses to get 3 consecutive Heads [closed],Expected number of tosses to get 3 consecutive Heads [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I have a fair coin. What is the expected number of tosses to get three Heads in a row? I have looked at similar past questions such as Expected Number of Coin Tosses to Get Five Consecutive Heads but I find the proof there is at the intuitive, not at the rigorous level there: the use of the ""recursive"" element is not justified. The Expectation $\mathbb E[X]$ is a number, not a random variable, as it is treated there. Please make this clear.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I have a fair coin. What is the expected number of tosses to get three Heads in a row? I have looked at similar past questions such as Expected Number of Coin Tosses to Get Five Consecutive Heads but I find the proof there is at the intuitive, not at the rigorous level there: the use of the ""recursive"" element is not justified. The Expectation $\mathbb E[X]$ is a number, not a random variable, as it is treated there. Please make this clear.",,['probability']
39,Why is not the answer to all probability questions 1/2.,Why is not the answer to all probability questions 1/2.,,"Ok, I know this is wrong, but I want someone to tell me why. Let's take a normal heads tails example of a fair coin. The probability of getting head = 1/2. And I write this is because, either it will be heads, or not . Hence two cases that makes it 1/2. Now, I know I can't do this to all the cases. For example, the probability of getting a 2 when I roll a dice. I know the answer is 1/6 but why can't I do, either the outcome will be 2 or not . And in that case, my probability is 1/2.","Ok, I know this is wrong, but I want someone to tell me why. Let's take a normal heads tails example of a fair coin. The probability of getting head = 1/2. And I write this is because, either it will be heads, or not . Hence two cases that makes it 1/2. Now, I know I can't do this to all the cases. For example, the probability of getting a 2 when I roll a dice. I know the answer is 1/6 but why can't I do, either the outcome will be 2 or not . And in that case, my probability is 1/2.",,['probability']
40,Convergence in probability implies convergence in distribution,Convergence in probability implies convergence in distribution,,"A sequence of random variables $\{X_n\}$ converges to $X$ in probability if for any $\varepsilon > 0$, $$P(|X_n-X| \geq \varepsilon) \rightarrow 0$$ They converge in distribution if $$F_{X_n} \rightarrow F_X$$ at points where $F_X$ is continuous. (There is another equivalent definition of converge in distribution in terms of weak convergence.) It seems like a very simple result, but I cannot think of a clever proof.","A sequence of random variables $\{X_n\}$ converges to $X$ in probability if for any $\varepsilon > 0$, $$P(|X_n-X| \geq \varepsilon) \rightarrow 0$$ They converge in distribution if $$F_{X_n} \rightarrow F_X$$ at points where $F_X$ is continuous. (There is another equivalent definition of converge in distribution in terms of weak convergence.) It seems like a very simple result, but I cannot think of a clever proof.",,"['probability', 'probability-theory', 'convergence-divergence', 'random-variables', 'weak-convergence']"
41,Prove that random variables satisfy the inequality $E(XY)^2 \le E(X^2)E(Y^2)$?,Prove that random variables satisfy the inequality ?,E(XY)^2 \le E(X^2)E(Y^2),Given Random variables $X$ and $Y$ is it true always that; $$E(XY)^2 \le  E(X^2)E(Y^2)$$ Is it easy to prove?,Given Random variables $X$ and $Y$ is it true always that; $$E(XY)^2 \le  E(X^2)E(Y^2)$$ Is it easy to prove?,,"['probability', 'inequality']"
42,How to compute moments of log normal distribution?,How to compute moments of log normal distribution?,,The computed moments of log normal distribution can be found here . How to compute them?,The computed moments of log normal distribution can be found here . How to compute them?,,['probability']
43,"Proof that $x \Phi(x) + \Phi'(x) \geq 0$ $\forall x$, where $\Phi$ is the normal CDF","Proof that  , where  is the normal CDF",x \Phi(x) + \Phi'(x) \geq 0 \forall x \Phi,"As title. Can anyone supply a simple proof that $$x \Phi(x) + \Phi'(x) \geq 0 \quad \forall x\in\mathbb{R}$$ where $\Phi$ is the standard normal CDF, i.e. $$\Phi(x) = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}} e^{-y^2/2} {\rm d} y$$ I have so far: Defining $f(x) = x \Phi(x) + \Phi'(x)$ we get $$ \begin{align} f'(x) & = \Phi(x) + x \Phi'(x) + \Phi''(x) \\ & = \Phi(x) + x\Phi'(x) - x\Phi'(x) \\ & = \Phi(x) \\ & >0 \end{align}$$ so it seems that if we can show $$\lim_{x\to-\infty} f(x) = 0$$ then we have our proof - am I correct? Clearly $f$ is the sum of two terms which tend to zero, so maybe I have all the machinery I require, and I just need to connect the parts in the right way! Assistance will be gratefully received. In case anyone is interested in where this question comes from: Bachelier's formula for an option struck at $K$ with time $T$ until maturity, with volatility $\sigma>0$ and current asset price $S$ is given by $$V(S) = (S - K) \Phi\left( \frac{S-K}{\sigma S \sqrt{T}} \right) + \sigma S \sqrt{T} \Phi' \left( \frac{S-K}{\sigma S \sqrt{T}} \right) $$ Working in time units where $\sigma S\sqrt{T} = 1$ and letting $x=S-K$, we have $$V(x) = x \Phi(x) + \Phi'(x)$$ and I wanted a simple proof that $V(x)>0$ $\forall x$, i.e. an option always has positive value under Bachelier's model.","As title. Can anyone supply a simple proof that $$x \Phi(x) + \Phi'(x) \geq 0 \quad \forall x\in\mathbb{R}$$ where $\Phi$ is the standard normal CDF, i.e. $$\Phi(x) = \int_{-\infty}^x \frac{1}{\sqrt{2\pi}} e^{-y^2/2} {\rm d} y$$ I have so far: Defining $f(x) = x \Phi(x) + \Phi'(x)$ we get $$ \begin{align} f'(x) & = \Phi(x) + x \Phi'(x) + \Phi''(x) \\ & = \Phi(x) + x\Phi'(x) - x\Phi'(x) \\ & = \Phi(x) \\ & >0 \end{align}$$ so it seems that if we can show $$\lim_{x\to-\infty} f(x) = 0$$ then we have our proof - am I correct? Clearly $f$ is the sum of two terms which tend to zero, so maybe I have all the machinery I require, and I just need to connect the parts in the right way! Assistance will be gratefully received. In case anyone is interested in where this question comes from: Bachelier's formula for an option struck at $K$ with time $T$ until maturity, with volatility $\sigma>0$ and current asset price $S$ is given by $$V(S) = (S - K) \Phi\left( \frac{S-K}{\sigma S \sqrt{T}} \right) + \sigma S \sqrt{T} \Phi' \left( \frac{S-K}{\sigma S \sqrt{T}} \right) $$ Working in time units where $\sigma S\sqrt{T} = 1$ and letting $x=S-K$, we have $$V(x) = x \Phi(x) + \Phi'(x)$$ and I wanted a simple proof that $V(x)>0$ $\forall x$, i.e. an option always has positive value under Bachelier's model.",,"['probability', 'inequality', 'special-functions']"
44,"Probability that $b^2 - 4ac \geq 0$ where $a,b,c$ are normally distributed (numerical integration)",Probability that  where  are normally distributed (numerical integration),"b^2 - 4ac \geq 0 a,b,c","I would like to determine the probability that a random quadratic polynomial has positive discriminant, where the 3 coefficients $a, b, c$ are normally distributed and independent: That is, given $a,b,c \sim \operatorname{N}\left(0,1\right)$ , what is ( a numerical approximation to 5 digits of ) $\operatorname{Pr}\left(\,{b^2 - 4 a c \geq 0}\,\right)$ ? Thoughts : We have $$ \mathrm{Pr}\left(\,{b^2 - 4 a c \geq 0}\,\right) = \dfrac{1}{\left(\sqrt{\pi}\right)^3} \iiint_{\mathbb{R}^3} \mathbb{\large 1}_{b^{2}\ -\ 4ac\ \geq\ 0}\quad{\rm e}^{-a^2} {\rm e}^{-b^2}{\rm e}^{-c^2}\,\mathrm{d}a \,\mathrm{d}b \,\mathrm{d}c $$ This integral probably cannot be expressed explicitly, but even a numerical approximation is not so easy. Here is what I tried with SAGE , without success: var('a,b,c')  RR = RealField(100)   I = integrate(integrate(integrate(exp(-a^2), a, 0, b^2/(4*c)) * exp(-c^2),    c, 0, oo) * exp(-b^2),    b, 0, oo) print(RR(I)) #error... Expermenting with SAGE seems to give a probability between 0.64 and 0.65 (compare the values given below if $a,b,c$ are uniformly distributed): N = 0 T = 10^5 for _ in range(T):     a = gauss(0, 1)     b = gauss(0, 1)     c = gauss(0, 1)     if b^2 - 4*a*c >= 0:         N += 1  print(float(N/T)) Other comments : The idea to consider the normal distribution is that the vector $(a, b, c) / \sqrt{a^2 + b^2 + c^2}$ is uniformly distributed on the sphere, because the joint Gaussian distribution is spherically symmetric, and the property $b^2 - 4 a c \geq 0$ is invariant under rescaling. Note that when $a,b,c \sim \mathrm{Unif}(-N, N)$ for some $N > 0$ , the probability $\mathrm{Pr}(b^2 - 4 a c \geq 0)$ can be computed explicitly [1] : it is $$(41 + \log(64))/72 \approx 0.627207.$$ See also Probability that a quadratic polynomial with random coefficients has real roots for the case $a,b,c \sim \mathrm{Unif}(0, 1)$ .","I would like to determine the probability that a random quadratic polynomial has positive discriminant, where the 3 coefficients are normally distributed and independent: That is, given , what is ( a numerical approximation to 5 digits of ) ? Thoughts : We have This integral probably cannot be expressed explicitly, but even a numerical approximation is not so easy. Here is what I tried with SAGE , without success: var('a,b,c')  RR = RealField(100)   I = integrate(integrate(integrate(exp(-a^2), a, 0, b^2/(4*c)) * exp(-c^2),    c, 0, oo) * exp(-b^2),    b, 0, oo) print(RR(I)) #error... Expermenting with SAGE seems to give a probability between 0.64 and 0.65 (compare the values given below if are uniformly distributed): N = 0 T = 10^5 for _ in range(T):     a = gauss(0, 1)     b = gauss(0, 1)     c = gauss(0, 1)     if b^2 - 4*a*c >= 0:         N += 1  print(float(N/T)) Other comments : The idea to consider the normal distribution is that the vector is uniformly distributed on the sphere, because the joint Gaussian distribution is spherically symmetric, and the property is invariant under rescaling. Note that when for some , the probability can be computed explicitly [1] : it is See also Probability that a quadratic polynomial with random coefficients has real roots for the case .","a, b, c a,b,c \sim \operatorname{N}\left(0,1\right) \operatorname{Pr}\left(\,{b^2 - 4 a c \geq 0}\,\right) 
\mathrm{Pr}\left(\,{b^2 - 4 a c \geq 0}\,\right)
=
\dfrac{1}{\left(\sqrt{\pi}\right)^3} \iiint_{\mathbb{R}^3} \mathbb{\large 1}_{b^{2}\ -\ 4ac\ \geq\ 0}\quad{\rm e}^{-a^2}
{\rm e}^{-b^2}{\rm e}^{-c^2}\,\mathrm{d}a \,\mathrm{d}b \,\mathrm{d}c
 a,b,c (a, b, c) / \sqrt{a^2 + b^2 + c^2} b^2 - 4 a c \geq 0 a,b,c \sim \mathrm{Unif}(-N, N) N > 0 \mathrm{Pr}(b^2 - 4 a c \geq 0) (41 + \log(64))/72 \approx 0.627207. a,b,c \sim \mathrm{Unif}(0, 1)","['probability', 'integration', 'numerical-methods', 'normal-distribution', 'discriminant']"
45,"If I roll two fair dice, the probability that I would get at least one 6 would be....","If I roll two fair dice, the probability that I would get at least one 6 would be....",,"$11$ out of $36$ ? I got this by writing down the number of possible outcomes ( $36$ ) and then counting how many of the pairs had a $6$ in them: $(1,6)$ , $(2,6)$ , $(3,6)$ , $(4,6)$ , $(5,6)$ , $(6,6)$ , $(6,5)$ , $(6,4)$ , $(6,3)$ , $(6,2)$ , $(6,1)$ . Is this correct?","out of ? I got this by writing down the number of possible outcomes ( ) and then counting how many of the pairs had a in them: , , , , , , , , , , . Is this correct?","11 36 36 6 (1,6) (2,6) (3,6) (4,6) (5,6) (6,6) (6,5) (6,4) (6,3) (6,2) (6,1)","['probability', 'statistics', 'dice']"
46,Tail sum for expectation,Tail sum for expectation,,"In Pitman's Probability , the tail sum formula for expectation is introduced for a nonnegative (0,1,...) discrete random variable $X$: $$E(X) = \sum_{i=0}^\infty P(X > i).$$ I wonder if there is a similar formula for nonnegative continuous random variable $X$: $$E(X) = \int_0^\infty P(X > x) dx?$$ If no, are there some conditions for it to hold? And how can it be proved? Here is my thought: If the cdf $F$ of $X$ is bijective, then $X=F^{-1}(U)$ for some random variable $U$ uniformly distributed over $[0,1)$. So $$E(X) =     \int_0^1 F^{-1}(u) du.$$ To prove the tail sum formula, it suffices to prove $$\int_0^1     F^{-1}(u) du = \int_0^\infty P(X > x) dx.$$ But I am stuck here. What's more, is the condition that the cdf $F$ of $X$ is bijective really necessary for tail sum formula to hold? Can tail sum formula be generalized to a random variable that is not necessarily nonnegative? Thanks!","In Pitman's Probability , the tail sum formula for expectation is introduced for a nonnegative (0,1,...) discrete random variable $X$: $$E(X) = \sum_{i=0}^\infty P(X > i).$$ I wonder if there is a similar formula for nonnegative continuous random variable $X$: $$E(X) = \int_0^\infty P(X > x) dx?$$ If no, are there some conditions for it to hold? And how can it be proved? Here is my thought: If the cdf $F$ of $X$ is bijective, then $X=F^{-1}(U)$ for some random variable $U$ uniformly distributed over $[0,1)$. So $$E(X) =     \int_0^1 F^{-1}(u) du.$$ To prove the tail sum formula, it suffices to prove $$\int_0^1     F^{-1}(u) du = \int_0^\infty P(X > x) dx.$$ But I am stuck here. What's more, is the condition that the cdf $F$ of $X$ is bijective really necessary for tail sum formula to hold? Can tail sum formula be generalized to a random variable that is not necessarily nonnegative? Thanks!",,"['probability', 'integration']"
47,"What is the formal definition of ""probability distribution""?","What is the formal definition of ""probability distribution""?",,Can someone please provide a useful reference on the definition of probabilistic distribution. A very popular site (top of Google search) states: A probability distribution is a table or an equation that links each outcome of a statistical experiment with its probability of occurrence. https://stattrek.com/probability-distributions/probability-distribution.aspx I feel that this definition is very unsatisfactory. I need a better one with a reference. Thank you!,Can someone please provide a useful reference on the definition of probabilistic distribution. A very popular site (top of Google search) states: A probability distribution is a table or an equation that links each outcome of a statistical experiment with its probability of occurrence. https://stattrek.com/probability-distributions/probability-distribution.aspx I feel that this definition is very unsatisfactory. I need a better one with a reference. Thank you!,,"['probability', 'probability-theory', 'probability-distributions', 'reference-request', 'definition']"
48,Coin flipping probability?,Coin flipping probability?,,"Q: flip a coin - how many times should it be flipped until the prob of all tails is $< 0.005$? Intuitively, I want to just do $0.5\times 0.5\times 0.5...$ until I get an answer $< 0.005$. Would this be the best way to do it to find out how many times I should flip it?","Q: flip a coin - how many times should it be flipped until the prob of all tails is $< 0.005$? Intuitively, I want to just do $0.5\times 0.5\times 0.5...$ until I get an answer $< 0.005$. Would this be the best way to do it to find out how many times I should flip it?",,['probability']
49,What is the expected number of trials until x successes?,What is the expected number of trials until x successes?,,"This is barely a probability question, but I needed to check to make sure the solution is as simple as I believe it to be. What is the the expected number $n$ of independent trials needed to have $x$ success (not necessary to be consecutive) given probability $p$? I would assume since each trial is independent the solution would be $n = x/p$, but perhaps I am overlooking something here.","This is barely a probability question, but I needed to check to make sure the solution is as simple as I believe it to be. What is the the expected number $n$ of independent trials needed to have $x$ success (not necessary to be consecutive) given probability $p$? I would assume since each trial is independent the solution would be $n = x/p$, but perhaps I am overlooking something here.",,['probability']
50,Definition of Conditional Probability by Measure Theory,Definition of Conditional Probability by Measure Theory,,"I was reading a book on information theory and entropy by Robert Gray, when I saw the following definition of conditional probability: Given a probability space $(\Omega,\mathcal{B}, P)$ and a   sub-$\sigma$-field $\mathcal{G}$, for any event $H\in\mathcal{B}$ the   conditional probability $m(H\text{ }|\text{ }\mathcal{G})$ is defined   as any function , say $g$, which satisfies the two properties: (1) $g$ is measurable with respect to $\mathcal{G}$ (2) $\displaystyle\int_{G}ghdP=m(G\bigcap{}H)$; all $G\in\mathcal{G}$ I am quite confused with this definition since it is very different from the definition through joint probability of events. I understand what measurable function, sub-$\sigma$-field and probability space are, and I'm guessing that the author is trying to definie the measure $m$ through the measurable function $g$, but I don't quite understand what the second requirement is saying. Especially, what does that h in $\displaystyle\int_{G}ghdP$ refer to? it just jumped out of nowhere in the book, so I'm suspecting that it may have some conventional meaning? I'd appreciate it a lot if someone can help. Thank you!!","I was reading a book on information theory and entropy by Robert Gray, when I saw the following definition of conditional probability: Given a probability space $(\Omega,\mathcal{B}, P)$ and a   sub-$\sigma$-field $\mathcal{G}$, for any event $H\in\mathcal{B}$ the   conditional probability $m(H\text{ }|\text{ }\mathcal{G})$ is defined   as any function , say $g$, which satisfies the two properties: (1) $g$ is measurable with respect to $\mathcal{G}$ (2) $\displaystyle\int_{G}ghdP=m(G\bigcap{}H)$; all $G\in\mathcal{G}$ I am quite confused with this definition since it is very different from the definition through joint probability of events. I understand what measurable function, sub-$\sigma$-field and probability space are, and I'm guessing that the author is trying to definie the measure $m$ through the measurable function $g$, but I don't quite understand what the second requirement is saying. Especially, what does that h in $\displaystyle\int_{G}ghdP$ refer to? it just jumped out of nowhere in the book, so I'm suspecting that it may have some conventional meaning? I'd appreciate it a lot if someone can help. Thank you!!",,"['probability', 'measure-theory']"
51,Race of the wealthy gamblers: How do I get this closed form?,Race of the wealthy gamblers: How do I get this closed form?,,"UPDATE: If you can prove the following identity: $$\sum\limits_{t=0}^p \left(\frac{{2t+1 \choose t}}{2^{2t+1}}\right)^2 \frac{1}{t+2} = -1 + \frac{(2+p)}{2^{4p+4}}{2p+3 \choose p+1}^2$$ Then this is good enough to solve this question and get my gratitude as well as the 50 point bounty. I got this identity from Mathematica. See my answer below for details. My question relates to an infinite summation and it's very elegant closed form. The expression is the solution to a nice problem which I'll get into as well. Here is the summation: Let: $$a_t = \left({2t+1 \choose t} - {2t+1 \choose t-1}\right)\frac{1}{2^{2+2t}}$$ and, $$b_t = \left({2t+2 \choose t} - {2t+2 \choose t-1}\right)\frac{1}{2^{3+2t}}$$ For the very first terms of these sequences, ${n \choose -1} = 0$ for all $n$ . And the summation: $$S = \sum_{t=0}^{\infty} \left(1-\sum_{l=0}^{t-1}b_l\right) a_t = 1- \sum_{t=0}^{\infty} \left(\sum_{l=0}^{t-1}b_l\right) a_t =  7-\frac{20}{\pi} \tag{1}$$ I know the expression above is correct (verified with a python program), but have no idea how to prove this and would like to at least see how I might approach it. Now, why do I care about this summation? It is the solution to the following problem: Imagine two wealthy gamblers start tossing their own separate fair coins, winning 1\$ on heads and losing 1\$ on tails. Both start at 0\$ and have infinite bank balances. The first one wants to get to 2\$ and the second one wants to get to 3\$. What is the probability that the first one will reach his goal before the second one? One way to solve this is to consider the probability that a gambler reaches exactly $k$ dollars for the first time on toss $n$ . If he has $t$ tails, then he needs $t+k$ heads. So, $n=2t+k$ (note if k=2\$, he can only reach the target on even tosses and if k=3\$, he can only reach it on odd tosses). This probability turns out to be: $$\left({k+2t-1 \choose t} - {k+2t-1 \choose t-1}\right) \frac{1}{2^{k+t}} \frac{1}{2^t}$$ Now, let $A_n$ be the probability that the 2\$ targeting gambler wins on toss $n$ and $A$ be the probability that he wins. Then we have $A = \bigcup\limits_{n=1}^{\infty}A_n$ and so, $P(A) = \sum\limits_{n=0}^\infty P(A_n)$ . Now, for the 2\$ targeting gambler to win on the $n$ th toss, two things should happen: He should reach his target on the $n$ th toss for some even $n$ . His competitor, the 3\$ gambler should not reach his target on any toss upto $n-1$ (since he can only reach his target on odd tosses). Putting all of this together, you can see that the probability that the 2\$ gambler wins is given by equation (1) above. I have put together some python code that approximates $S$ by going upto a large number of tosses. A Reddit user pointed out the closed form for which he used a slightly different but related approach and Mathematica. Now, how do I prove that the summation above has the closed form mentioned $(7-\frac{20}{\pi})$ ? EDIT: Here is a short python snippet that demonstrates the summation in equation (1) above. a_t = np.array([(comb(2*t+1,t)-comb(2*t+1,t-1))/2**(2*t+2) for t in range(500)]) b_t = np.array([(comb(2*t+2,t)-comb(2*t+2,t-1))/2**(2*t+3) for t in range(500)]) b_sum = 1-np.concatenate(([0],np.cumsum(b_t))) s = sum(a_t*b_sum[:500]) print(7-20/np.pi-s) Also, here is the Mathematica snippet that shows the result (thanks to @SteveKass for helping with that):","UPDATE: If you can prove the following identity: Then this is good enough to solve this question and get my gratitude as well as the 50 point bounty. I got this identity from Mathematica. See my answer below for details. My question relates to an infinite summation and it's very elegant closed form. The expression is the solution to a nice problem which I'll get into as well. Here is the summation: Let: and, For the very first terms of these sequences, for all . And the summation: I know the expression above is correct (verified with a python program), but have no idea how to prove this and would like to at least see how I might approach it. Now, why do I care about this summation? It is the solution to the following problem: Imagine two wealthy gamblers start tossing their own separate fair coins, winning 1\$ on heads and losing 1\$ on tails. Both start at 0\$ and have infinite bank balances. The first one wants to get to 2\$ and the second one wants to get to 3\$. What is the probability that the first one will reach his goal before the second one? One way to solve this is to consider the probability that a gambler reaches exactly dollars for the first time on toss . If he has tails, then he needs heads. So, (note if k=2\$, he can only reach the target on even tosses and if k=3\$, he can only reach it on odd tosses). This probability turns out to be: Now, let be the probability that the 2\$ targeting gambler wins on toss and be the probability that he wins. Then we have and so, . Now, for the 2\$ targeting gambler to win on the th toss, two things should happen: He should reach his target on the th toss for some even . His competitor, the 3\$ gambler should not reach his target on any toss upto (since he can only reach his target on odd tosses). Putting all of this together, you can see that the probability that the 2\$ gambler wins is given by equation (1) above. I have put together some python code that approximates by going upto a large number of tosses. A Reddit user pointed out the closed form for which he used a slightly different but related approach and Mathematica. Now, how do I prove that the summation above has the closed form mentioned ? EDIT: Here is a short python snippet that demonstrates the summation in equation (1) above. a_t = np.array([(comb(2*t+1,t)-comb(2*t+1,t-1))/2**(2*t+2) for t in range(500)]) b_t = np.array([(comb(2*t+2,t)-comb(2*t+2,t-1))/2**(2*t+3) for t in range(500)]) b_sum = 1-np.concatenate(([0],np.cumsum(b_t))) s = sum(a_t*b_sum[:500]) print(7-20/np.pi-s) Also, here is the Mathematica snippet that shows the result (thanks to @SteveKass for helping with that):",\sum\limits_{t=0}^p \left(\frac{{2t+1 \choose t}}{2^{2t+1}}\right)^2 \frac{1}{t+2} = -1 + \frac{(2+p)}{2^{4p+4}}{2p+3 \choose p+1}^2 a_t = \left({2t+1 \choose t} - {2t+1 \choose t-1}\right)\frac{1}{2^{2+2t}} b_t = \left({2t+2 \choose t} - {2t+2 \choose t-1}\right)\frac{1}{2^{3+2t}} {n \choose -1} = 0 n S = \sum_{t=0}^{\infty} \left(1-\sum_{l=0}^{t-1}b_l\right) a_t = 1- \sum_{t=0}^{\infty} \left(\sum_{l=0}^{t-1}b_l\right) a_t =  7-\frac{20}{\pi} \tag{1} k n t t+k n=2t+k \left({k+2t-1 \choose t} - {k+2t-1 \choose t-1}\right) \frac{1}{2^{k+t}} \frac{1}{2^t} A_n n A A = \bigcup\limits_{n=1}^{\infty}A_n P(A) = \sum\limits_{n=0}^\infty P(A_n) n n n n-1 S (7-\frac{20}{\pi}),"['probability', 'sequences-and-series', 'summation', 'markov-chains']"
52,Proof of linearity for expectation given random variables are dependent,Proof of linearity for expectation given random variables are dependent,,"The proof of linearity for expectation given random variables are independent is intuitive. What is the proof given there they are dependent? Formally, $$ E(X+Y)=E(X)+E(Y)$$ where $X$ and $Y$ are dependent random variables. The proof below assumes that $X$ and $Y$ belong to the sample space. That is, they map from the sample space to a real number line. Is that also a condition for linearity of expectation? Proof: $$E\left(X+Y\right) =\sum\limits_{s}\left(X+Y\right)\left(s\right) P\left({s}\right)    $$ $$E\left(X+Y\right) =\sum\limits_{s}\left(X\left(s\right)+Y\left(s\right)\right) P\left({s}\right)    $$ $$E\left(X+Y\right) =\sum\limits_{s} X\left(s\right)P\left({s}\right) + \sum\limits_{s} Y\left(s\right)P\left({s}\right)     $$ $$E\left(X+Y\right) =E\left(X\right)+E\left(Y\right)$$ Here $S$ is the sample space and $s$ is an event in the sample space. Reference Lecture for proof. Also, more reasoning for step 2 would be helpful. I don't understand it completely.","The proof of linearity for expectation given random variables are independent is intuitive. What is the proof given there they are dependent? Formally, where and are dependent random variables. The proof below assumes that and belong to the sample space. That is, they map from the sample space to a real number line. Is that also a condition for linearity of expectation? Proof: Here is the sample space and is an event in the sample space. Reference Lecture for proof. Also, more reasoning for step 2 would be helpful. I don't understand it completely.", E(X+Y)=E(X)+E(Y) X Y X Y E\left(X+Y\right) =\sum\limits_{s}\left(X+Y\right)\left(s\right) P\left({s}\right)     E\left(X+Y\right) =\sum\limits_{s}\left(X\left(s\right)+Y\left(s\right)\right) P\left({s}\right)     E\left(X+Y\right) =\sum\limits_{s} X\left(s\right)P\left({s}\right) + \sum\limits_{s} Y\left(s\right)P\left({s}\right)      E\left(X+Y\right) =E\left(X\right)+E\left(Y\right) S s,"['probability', 'probability-theory', 'random-variables']"
53,100-sided die probability,100-sided die probability,,"The question is as follows: You are given a 100-sided die. After you roll once, you can choose to either get paid the dollar amount of that roll OR pay one dollar for one more roll. What is the expected value of the game? There is no limit on number of rolls. The EV for a 100-sided die roll is 50.5, but the fact that you can pay a dollar for an extra roll complicates things. Not quite sure how to proceed.","The question is as follows: You are given a 100-sided die. After you roll once, you can choose to either get paid the dollar amount of that roll OR pay one dollar for one more roll. What is the expected value of the game? There is no limit on number of rolls. The EV for a 100-sided die roll is 50.5, but the fact that you can pay a dollar for an extra roll complicates things. Not quite sure how to proceed.",,"['probability', 'puzzle', 'dice', 'gambling']"
54,Expectation of inverse of sum of random variables,Expectation of inverse of sum of random variables,,"Let $X_i$'s ($i=1,..,n$) be i.i.d. random variables with mean $\mu$ and variance $\sigma^2$. Is there a method that can be used to compute $\mathbb{E}[1/(X_1+...+X_n)]$?","Let $X_i$'s ($i=1,..,n$) be i.i.d. random variables with mean $\mu$ and variance $\sigma^2$. Is there a method that can be used to compute $\mathbb{E}[1/(X_1+...+X_n)]$?",,"['probability', 'random-variables']"
55,Simulating uniformly on $S^1=\{x \in \mathbb{R}^n \mid \|x\|_1=1\}$,Simulating uniformly on,S^1=\{x \in \mathbb{R}^n \mid \|x\|_1=1\},A scheme to generate random variates distributed uniformly in  $S^2=\{x\in \mathbb{R}^n \mid \|x\|_2=1\}$ is well known: generate a standard normal variate in $\mathbb{R}^n$ and normalize it to unit norm. Is there a similarly simple and clever procedure to simulate uniformly distributed variates on the $1$-ball $S^1=\{x \in \mathbb{R}^n \mid \|x\|_1=1\}$?,A scheme to generate random variates distributed uniformly in  $S^2=\{x\in \mathbb{R}^n \mid \|x\|_2=1\}$ is well known: generate a standard normal variate in $\mathbb{R}^n$ and normalize it to unit norm. Is there a similarly simple and clever procedure to simulate uniformly distributed variates on the $1$-ball $S^1=\{x \in \mathbb{R}^n \mid \|x\|_1=1\}$?,,"['probability', 'geometry', 'simulation', 'geometric-probability']"
56,What is the theory behind rigorous hypothesis testing?,What is the theory behind rigorous hypothesis testing?,,"I understand that hypothesis testing is essentially a statistical form of proof by contradiction. In proof by contradiction, you assume P, then show that it leads to a result Q, which you know to be false. Since we assume logical consistency, Q and ~Q cannot both be true, therefore ~P. In hypothesis testing, you start with a hypothesis H and you make an observation, O. If you find that P(O | H) << 1, then we can say that H is unlikely, in a similar way to proof by contradiction, but this reasoning is a heuristic one. What is the formal mechanism behind this result? How do you get from P(O | H) << 1 to P(H | O) << 1?","I understand that hypothesis testing is essentially a statistical form of proof by contradiction. In proof by contradiction, you assume P, then show that it leads to a result Q, which you know to be false. Since we assume logical consistency, Q and ~Q cannot both be true, therefore ~P. In hypothesis testing, you start with a hypothesis H and you make an observation, O. If you find that P(O | H) << 1, then we can say that H is unlikely, in a similar way to proof by contradiction, but this reasoning is a heuristic one. What is the formal mechanism behind this result? How do you get from P(O | H) << 1 to P(H | O) << 1?",,"['probability', 'probability-theory', 'statistics', 'hypothesis-testing']"
57,Conditional expectation equals random variable almost sure,Conditional expectation equals random variable almost sure,,"Let $X$ be in $\mathfrak{L}^1(\Omega,\mathfrak{F},P)$ and $\mathfrak{G}\subset \mathfrak{F}$. Prove that if $X$ and $E(X|\mathfrak{G})$ have same distribution, then they are equal almost surely. I know what I have to show, that $X$ is $\mathfrak{G}$ measurable, but I don't know how...","Let $X$ be in $\mathfrak{L}^1(\Omega,\mathfrak{F},P)$ and $\mathfrak{G}\subset \mathfrak{F}$. Prove that if $X$ and $E(X|\mathfrak{G})$ have same distribution, then they are equal almost surely. I know what I have to show, that $X$ is $\mathfrak{G}$ measurable, but I don't know how...",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'conditional-expectation']"
58,About problem A4 2022 of Putnam,About problem A4 2022 of Putnam,,"I'm not passing the William Lowell Putnam competition (I live in France) but I'm still fascinated by some of the problems. This year the A4 problem challenged me and I wanna know your thoughts about it : Suppose $X_1, X_2, \dots$ real numbers between $0$ and $1$ that are chosen independently and uniformly at random. Let $S = \displaystyle\sum\limits_{i=1}^k \frac{X_i}{2^i}$ where $k$ is the least positive integer such that $X_k < X_{k+1}$ or $k=\infty$ if there is no such integer. Find the expected value of $S$ . 1 - Is this a classic problem that Putnam competitors know ? 2 - What's the idea to solve this ? Instictively I would say that : $$\mathbb{E}[S] = \mathbb{E}\left[ \displaystyle\sum\limits_{i=1}^k \frac{X_i}{2^i} \right] = \displaystyle\sum\limits_{i=1}^k \frac{\mathbb{E}[X_i]}{2^i} = \displaystyle\frac{\mathbb{E}[X_1]}{2} + \displaystyle\frac{\mathbb{E}[X_2]}{4} + \dots + \displaystyle\frac{\mathbb{E}[X_k]}{2^k}$$ And then calculate $\mathbb{E}[X_k]$ for all $k \in \mathbb{N}^*$ but maybe that's not the right idea and the solution is far more exotic.",I'm not passing the William Lowell Putnam competition (I live in France) but I'm still fascinated by some of the problems. This year the A4 problem challenged me and I wanna know your thoughts about it : Suppose real numbers between and that are chosen independently and uniformly at random. Let where is the least positive integer such that or if there is no such integer. Find the expected value of . 1 - Is this a classic problem that Putnam competitors know ? 2 - What's the idea to solve this ? Instictively I would say that : And then calculate for all but maybe that's not the right idea and the solution is far more exotic.,"X_1, X_2, \dots 0 1 S = \displaystyle\sum\limits_{i=1}^k \frac{X_i}{2^i} k X_k < X_{k+1} k=\infty S \mathbb{E}[S] = \mathbb{E}\left[ \displaystyle\sum\limits_{i=1}^k \frac{X_i}{2^i} \right] = \displaystyle\sum\limits_{i=1}^k \frac{\mathbb{E}[X_i]}{2^i} = \displaystyle\frac{\mathbb{E}[X_1]}{2} + \displaystyle\frac{\mathbb{E}[X_2]}{4} + \dots + \displaystyle\frac{\mathbb{E}[X_k]}{2^k} \mathbb{E}[X_k] k \in \mathbb{N}^*","['probability', 'contest-math']"
59,Expected number of steps between states in a Markov Chain,Expected number of steps between states in a Markov Chain,,"Suppose I am given a state space $S=\{0,1,2,3\}$ with transition probability matrix $\mathbf{P}= \begin{bmatrix}     	\frac{2}{3} & \frac{1}{3} & 0 & 0       	\\[0.3em]     	\frac{2}{3} & 0       	& \frac{1}{3} & 0\\[0.3em]     	\frac{2}{3} & 0 & 0 & \frac{1}{3}\\[0.3em]     	0 & 0 & 0 & 1   	\end{bmatrix}$ and I want the expected number of steps from states $0 \rightarrow 3$ which I will denote $E_0(N(3))$. Attempt at solving: First I write the transient states $\{0,1,2\}$ and recurrent state $\{3\}$ which I got from drawing the chain. I now want to write $\mathbf{P}$ in canonical form, i.e. with state space $S=\{3,0,1,2\}$ as so: $\mathbf{P}=\begin{bmatrix}     	1 & 0 & 0 & 0\\[0.3em]     	0 & \frac{2}{3} & \frac{1}{3} & 0        	\\[0.3em]     	0 & \frac{2}{3} & 0 & \frac{1}{3}\\[0.3em]     	\frac{2}{3} & 0 & 0 & \frac{1}{3}   	\end{bmatrix}$ It's clear that the transient matrix is $\mathbf{Q}= \begin{bmatrix}     	\frac{2}{3} & \frac{1}{3} & 0        	\\[0.3em]     	\frac{2}{3} & 0 & \frac{1}{3}\\[0.3em]     	0 & 0 & \frac{1}{3}   	\end{bmatrix}$ Now I can get the matrix I want for computing expected steps (calculated with Mathematica): $\mathbf{M}=(\mathbf{I}-\mathbf{Q})^{-1}=\begin{bmatrix}     	9 & 3 & 3\\[0.3em]     	6 & 3 & 3\\[0.3em]     	0 & 0 & \frac{3}{2}   	\end{bmatrix}$ From this, we get $E_0(N(3))=9+3+3=15$. Is this correct? I am sort of weak in finding the ""canonical form"" of a matrix. Note: although this looks like a homework question, it's simply a preparation problem for an upcoming exam, so a complete solution/correction of my work is appreciated.","Suppose I am given a state space $S=\{0,1,2,3\}$ with transition probability matrix $\mathbf{P}= \begin{bmatrix}     	\frac{2}{3} & \frac{1}{3} & 0 & 0       	\\[0.3em]     	\frac{2}{3} & 0       	& \frac{1}{3} & 0\\[0.3em]     	\frac{2}{3} & 0 & 0 & \frac{1}{3}\\[0.3em]     	0 & 0 & 0 & 1   	\end{bmatrix}$ and I want the expected number of steps from states $0 \rightarrow 3$ which I will denote $E_0(N(3))$. Attempt at solving: First I write the transient states $\{0,1,2\}$ and recurrent state $\{3\}$ which I got from drawing the chain. I now want to write $\mathbf{P}$ in canonical form, i.e. with state space $S=\{3,0,1,2\}$ as so: $\mathbf{P}=\begin{bmatrix}     	1 & 0 & 0 & 0\\[0.3em]     	0 & \frac{2}{3} & \frac{1}{3} & 0        	\\[0.3em]     	0 & \frac{2}{3} & 0 & \frac{1}{3}\\[0.3em]     	\frac{2}{3} & 0 & 0 & \frac{1}{3}   	\end{bmatrix}$ It's clear that the transient matrix is $\mathbf{Q}= \begin{bmatrix}     	\frac{2}{3} & \frac{1}{3} & 0        	\\[0.3em]     	\frac{2}{3} & 0 & \frac{1}{3}\\[0.3em]     	0 & 0 & \frac{1}{3}   	\end{bmatrix}$ Now I can get the matrix I want for computing expected steps (calculated with Mathematica): $\mathbf{M}=(\mathbf{I}-\mathbf{Q})^{-1}=\begin{bmatrix}     	9 & 3 & 3\\[0.3em]     	6 & 3 & 3\\[0.3em]     	0 & 0 & \frac{3}{2}   	\end{bmatrix}$ From this, we get $E_0(N(3))=9+3+3=15$. Is this correct? I am sort of weak in finding the ""canonical form"" of a matrix. Note: although this looks like a homework question, it's simply a preparation problem for an upcoming exam, so a complete solution/correction of my work is appreciated.",,"['probability', 'matrices', 'probability-theory', 'markov-chains', 'markov-process']"
60,Why is the probability that a continuous random variable takes a specific value zero?,Why is the probability that a continuous random variable takes a specific value zero?,,"My understanding is that a random variable is actually a function $X: \Omega \to T$, where $\Omega$ is the sample space of some random experiment and $T$ is the set from which the possible values of the random variable are taken. Regarding the set of values that the random variable can actually take, it is the image of the function $X$. If the image is finite, then $X$ must be a discrete random variable. However, if it is an infinite set, then $X$ may or may not be a continuous random variable. Whether it is depends on whether the image is countable or not. If it is countable, then $X$ is a discrete random variable; whereas if it is not, then $X$ is  continuous. Assuming that my understanding is correct, why does the fact that the image is uncountable imply that $Pr(X = x) = 0$. I would have thought that the fact that the image is infinite, regardless of whether it is countable or not, would already imply that $Pr(X = x) = 0$ since if it is infinite, then the domain $\Omega$ must also be infinite, and therefore $$Pr(X = x) = \frac{\text{# favorable outcomes}}{\text{# possible outcomes}} = \frac{\text{# outcomes of the experiment where X = x}}{|\Omega|} = \frac{\text{# outcomes of the experiment where X = x}}{\infty} = 0$$ What is wrong with my argument? Why does the probability that a continuous random variable takes on a specific value actually equal zero?","My understanding is that a random variable is actually a function $X: \Omega \to T$, where $\Omega$ is the sample space of some random experiment and $T$ is the set from which the possible values of the random variable are taken. Regarding the set of values that the random variable can actually take, it is the image of the function $X$. If the image is finite, then $X$ must be a discrete random variable. However, if it is an infinite set, then $X$ may or may not be a continuous random variable. Whether it is depends on whether the image is countable or not. If it is countable, then $X$ is a discrete random variable; whereas if it is not, then $X$ is  continuous. Assuming that my understanding is correct, why does the fact that the image is uncountable imply that $Pr(X = x) = 0$. I would have thought that the fact that the image is infinite, regardless of whether it is countable or not, would already imply that $Pr(X = x) = 0$ since if it is infinite, then the domain $\Omega$ must also be infinite, and therefore $$Pr(X = x) = \frac{\text{# favorable outcomes}}{\text{# possible outcomes}} = \frac{\text{# outcomes of the experiment where X = x}}{|\Omega|} = \frac{\text{# outcomes of the experiment where X = x}}{\infty} = 0$$ What is wrong with my argument? Why does the probability that a continuous random variable takes on a specific value actually equal zero?",,['probability']
61,"When modelling a real world event by assuming it has probability p, what are we saying/assuming about how that event behaves?","When modelling a real world event by assuming it has probability p, what are we saying/assuming about how that event behaves?",,"There are countless books on statistics, and how to apply probability-theory to the real world. But I have never really understood what we are actually doing when we model a real world phenomenon with probability theory. If you have real world events, and say that you model the real world, and assign probabilities to those events, what are you actually saying then? If you say that the chance that the bus will be on time have probability 0.3, what are you actually saying then? Most books I read interpret this as a long term relative frequency, that is, if you observe many ""independent"" such situations then the limiting frequency will go to 0.3. But this is not the definition of probability, and probability theory only says that this will happen with probability 1, not that it will happen surely.(measure 0 events etc.) I guess what I am wondering is when we use probability in statistics and the real world, what does it mean when we say that an event have probability p. If we just are concerned with mathematics this is easy, then we are just saying that the measure of that event is p. So when we model a real world situation with probability in our abstract world, we give a real world event a measure p, but what are we actually saying about the real world then?","There are countless books on statistics, and how to apply probability-theory to the real world. But I have never really understood what we are actually doing when we model a real world phenomenon with probability theory. If you have real world events, and say that you model the real world, and assign probabilities to those events, what are you actually saying then? If you say that the chance that the bus will be on time have probability 0.3, what are you actually saying then? Most books I read interpret this as a long term relative frequency, that is, if you observe many ""independent"" such situations then the limiting frequency will go to 0.3. But this is not the definition of probability, and probability theory only says that this will happen with probability 1, not that it will happen surely.(measure 0 events etc.) I guess what I am wondering is when we use probability in statistics and the real world, what does it mean when we say that an event have probability p. If we just are concerned with mathematics this is easy, then we are just saying that the measure of that event is p. So when we model a real world situation with probability in our abstract world, we give a real world event a measure p, but what are we actually saying about the real world then?",,"['probability', 'probability-theory', 'mathematical-modeling']"
62,Addition of two Binomial Distribution,Addition of two Binomial Distribution,,"What is the distribution of the variable $X$ given $$ X = Y + Z, $$where $Y \sim $ Binomial($n$, $P_Y$) and $Z\sim$ Binomial($n$, $P_Z$)? For the special case, when $P_Y = P_Z = P$, I think that X~Binomial($2n$, $P$) is correct. If $P_A ≠ P_B$, the distribution might eventually just be Binomial$\left(2n, \frac{P_A + P_B}{2}\right)$ but I can't prove it. If the problem is more complicated than I expect and we can't derive the whole distribution, can we tell something about the mean and the variance of $X$?","What is the distribution of the variable $X$ given $$ X = Y + Z, $$where $Y \sim $ Binomial($n$, $P_Y$) and $Z\sim$ Binomial($n$, $P_Z$)? For the special case, when $P_Y = P_Z = P$, I think that X~Binomial($2n$, $P$) is correct. If $P_A ≠ P_B$, the distribution might eventually just be Binomial$\left(2n, \frac{P_A + P_B}{2}\right)$ but I can't prove it. If the problem is more complicated than I expect and we can't derive the whole distribution, can we tell something about the mean and the variance of $X$?",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
63,Convolution of two Gaussians is a Gaussian,Convolution of two Gaussians is a Gaussian,,"I know that the product of two Gaussians is a Gaussian, and I know that the convolution of two Gaussians is also a Gaussian. I guess I was just wondering if there's a proof out there to show that the convolution of two Gaussians is a Gaussian.","I know that the product of two Gaussians is a Gaussian, and I know that the convolution of two Gaussians is also a Gaussian. I guess I was just wondering if there's a proof out there to show that the convolution of two Gaussians is a Gaussian.",,"['probability', 'probability-distributions', 'normal-distribution']"
64,Algebra of Random Variables?,Algebra of Random Variables?,,"I've been looking online (and in teaching journals) for a good introduction to Algebras of Random Variables (on an undergraduate level) and their usage, and have come up short. I know I can find the probability distribution of $h(z)$ where: \begin{equation*} z = x + y. \end{equation*} If $x$ and $y$ are from known independent probability distributions (the solution is simply a convolution). Two other operations $z=xy$ and $z=y/x$ can be solved for quite easily as well. Does anyone know of any other, more complicated, uses for treating random variables as objects to be manipulated?","I've been looking online (and in teaching journals) for a good introduction to Algebras of Random Variables (on an undergraduate level) and their usage, and have come up short. I know I can find the probability distribution of $h(z)$ where: \begin{equation*} z = x + y. \end{equation*} If $x$ and $y$ are from known independent probability distributions (the solution is simply a convolution). Two other operations $z=xy$ and $z=y/x$ can be solved for quite easily as well. Does anyone know of any other, more complicated, uses for treating random variables as objects to be manipulated?",,"['probability-theory', 'probability']"
65,"Markov chains: is ""aperiodic + irreducible"" equivalent to ""regular""?","Markov chains: is ""aperiodic + irreducible"" equivalent to ""regular""?",,"I have two books on stochastic processes. In one book, it says that the limiting matrix is possible to find if the matrix is regular, that is, if for some $n$ $P^n$ has only positive values.  The other book says that the limiting values are possible to find if the Markov chain is recurrent, irreducible and aperiodic; it is then called ergodic. Does this then hold: aperiodic + irreducible $\Leftrightarrow$ ergodic $\Leftrightarrow$ regular ? And is there any difference whether it is a finite-state chain or not?","I have two books on stochastic processes. In one book, it says that the limiting matrix is possible to find if the matrix is regular, that is, if for some $n$ $P^n$ has only positive values.  The other book says that the limiting values are possible to find if the Markov chain is recurrent, irreducible and aperiodic; it is then called ergodic. Does this then hold: aperiodic + irreducible $\Leftrightarrow$ ergodic $\Leftrightarrow$ regular ? And is there any difference whether it is a finite-state chain or not?",,"['probability', 'stochastic-processes', 'markov-chains', 'markov-process']"
66,Does there exist an unfair coin such that the probability of an even number of heads in $n$ flips is $\frac{1}{2}$?,Does there exist an unfair coin such that the probability of an even number of heads in  flips is ?,n \frac{1}{2},"Question: Does there exist an unfair coin and an $n$ such that the probability of an even number of heads in $n$ flips is $\frac{1}{2}$ ? First attempt Let $p$ be the probability of our coin flipping heads. If we try $n=2 $ then we must have: $p^2+(1-p)^2 = \frac{1}{2}$ and the only root to this is $p = \frac{1}{2}$ so no bias coin works in only $2$ flips. Moving on to $n=3$ we must have: $p^3 + 3p(1-p^2) = \frac{1}{2} $ and again the only root is $p = \frac{1}{2}$ I then proceeded to check these up to $n=6$ and found that the only root was $p=\frac{1}{2}$ . This suggested to me that the answer was no but I wasnt able to go much further with this method for a general $n$ . I could have proceeded by proving $(p-\frac{1}{2})^n \propto $ ""the polynomials we were getting - 0.5 "" but this is cumbersome. Second attempt I then noticed that if we found such a $p$ and an $n$ then it would also be true for $n+1$ as the probability of an even number of heads in $n+1$ tosses = $\frac{p}{2}+\frac{1-p}{2} = \frac{1}{2} $ (conditioning on the first $n$ tosses ) I then wanted to do this in reverse i.e showing if its true for $n$ its true for $n-1$ Define $P_n^p$ as the probability of getting an even number of heads from a coin having bias $p$ in $n$ flips. Then we have $P_n^p = (1-p)\cdot P_{n-1}^p +  p \cdot (1-P_{n-1}^p)$ and if $P_{n}^p = \frac{1}{2}$ then $\frac{1}{2} = P_{n-1}^p -2pP_{n-1}^p +p   $ and so $\frac{1}{2} - p = P_{n-1}^p (1-2p)$ and then $P_{n-1}^p = \frac{1}{2}$ And so if it is true for $n$ it is true for $n-1$ but we know that for $n=2$ no bias coins work and so inductively there do not exist any coins with bias that work! (as true for $n$ implies $n-1 $ , implies $n-2$ , implies $n-3$ ,.... implies $2$ But we already showed $n=2$ is false. Something more streamline? I cannot help but think that due to the symmetry of this problem there must surely exist such a simple and elegant way of showing it is not true! Notice if $p$ works then so does $1-p$ .   Can someone find a very simple way of solving this problem ? :)","Question: Does there exist an unfair coin and an such that the probability of an even number of heads in flips is ? First attempt Let be the probability of our coin flipping heads. If we try then we must have: and the only root to this is so no bias coin works in only flips. Moving on to we must have: and again the only root is I then proceeded to check these up to and found that the only root was . This suggested to me that the answer was no but I wasnt able to go much further with this method for a general . I could have proceeded by proving ""the polynomials we were getting - 0.5 "" but this is cumbersome. Second attempt I then noticed that if we found such a and an then it would also be true for as the probability of an even number of heads in tosses = (conditioning on the first tosses ) I then wanted to do this in reverse i.e showing if its true for its true for Define as the probability of getting an even number of heads from a coin having bias in flips. Then we have and if then and so and then And so if it is true for it is true for but we know that for no bias coins work and so inductively there do not exist any coins with bias that work! (as true for implies , implies , implies ,.... implies But we already showed is false. Something more streamline? I cannot help but think that due to the symmetry of this problem there must surely exist such a simple and elegant way of showing it is not true! Notice if works then so does .   Can someone find a very simple way of solving this problem ? :)",n n \frac{1}{2} p n=2  p^2+(1-p)^2 = \frac{1}{2} p = \frac{1}{2} 2 n=3 p^3 + 3p(1-p^2) = \frac{1}{2}  p = \frac{1}{2} n=6 p=\frac{1}{2} n (p-\frac{1}{2})^n \propto  p n n+1 n+1 \frac{p}{2}+\frac{1-p}{2} = \frac{1}{2}  n n n-1 P_n^p p n P_n^p = (1-p)\cdot P_{n-1}^p +  p \cdot (1-P_{n-1}^p) P_{n}^p = \frac{1}{2} \frac{1}{2} = P_{n-1}^p -2pP_{n-1}^p +p    \frac{1}{2} - p = P_{n-1}^p (1-2p) P_{n-1}^p = \frac{1}{2} n n-1 n=2 n n-1  n-2 n-3 2 n=2 p 1-p,"['probability', 'statistics', 'puzzle']"
67,Approximating indicator function on open set continuous functions,Approximating indicator function on open set continuous functions,,"Given some polish space $X$ and a probability measure $P$ on $X$ is it true that for any open set $A$ in $X$ one can construct a sequence of bounded continuous functions $\{f_{n}(x)\}_{n}$ such that $f_{n}$ converges in probability to the indicator function on $A$, $I_{A}$?","Given some polish space $X$ and a probability measure $P$ on $X$ is it true that for any open set $A$ in $X$ one can construct a sequence of bounded continuous functions $\{f_{n}(x)\}_{n}$ such that $f_{n}$ converges in probability to the indicator function on $A$, $I_{A}$?",,"['probability', 'general-topology', 'analysis']"
68,The probability that ${x_1}^{1/k_1}+{x_2}^{1/k_2}+\dotsb+{x_n}^{1/k_n}$ is less than $1$ - combinatorial proof?,The probability that  is less than  - combinatorial proof?,{x_1}^{1/k_1}+{x_2}^{1/k_2}+\dotsb+{x_n}^{1/k_n} 1,"A friend and I were playing around with Beta integrals and we noticed the following fact. Choose some positive integers $k_1,k_2,\dots,k_n$ , and let $x_1,x_2,\dots,x_n$ be independent uniform random variables between $0$ and $1$ . Then the probability that ${x_1}^{1/k_1}+{x_2}^{1/k_2}+\dotsb+{x_n}^{1/k_n}\le1$ is $$\frac{k_1!k_2!\dotsm k_n!}{(k_1+k_2+\dotsb+k_n)!}.$$ (Sidenote: In fact, using the Gamma extension of the factorial, this works for noninteger $k_i$ as well. This has the nice corollary that the volume of a sphere is $2^3\frac{\frac12!^3}{\frac32!}r^3=\frac43\pi r^3$ . In fact, this yields the volume formulas for $n$ -balls in any dimension.) This result is particularly clean in that it can be expressed as a multinomial coefficient : it's $\dfrac1{\binom{k_1+k_2+\dotsb+k_n}{k_1,k_2,\dots,k_n}}$ . (The multinomial coefficient describes the number of ways of distributing $k_1+k_2+\dotsb+k_n$ objects into bins of sizes $k_1,k_2,\dots,k_n$ .) In particular, it is always the reciprocal of an integer. Given the combinatorial nature of the solution, we should expect a combinatorial proof. Is there one? (One can prove this using Beta integrals, as I noted above, but I wouldn't call this combinatorial.) In other words: is there an elementary proof of the identity $P({x_1}^{1/k_1}+{x_2}^{1/k_2}+\dotsb+{x_n}^{1/k_n}\le1)=\frac{k_1!k_2!\dotsm k_n!}{(k_1+k_2+\dotsb+k_n)!}$ ? (P.S. The case where $k_1=\dotsb=k_n=1$ is well-known.)","A friend and I were playing around with Beta integrals and we noticed the following fact. Choose some positive integers , and let be independent uniform random variables between and . Then the probability that is (Sidenote: In fact, using the Gamma extension of the factorial, this works for noninteger as well. This has the nice corollary that the volume of a sphere is . In fact, this yields the volume formulas for -balls in any dimension.) This result is particularly clean in that it can be expressed as a multinomial coefficient : it's . (The multinomial coefficient describes the number of ways of distributing objects into bins of sizes .) In particular, it is always the reciprocal of an integer. Given the combinatorial nature of the solution, we should expect a combinatorial proof. Is there one? (One can prove this using Beta integrals, as I noted above, but I wouldn't call this combinatorial.) In other words: is there an elementary proof of the identity ? (P.S. The case where is well-known.)","k_1,k_2,\dots,k_n x_1,x_2,\dots,x_n 0 1 {x_1}^{1/k_1}+{x_2}^{1/k_2}+\dotsb+{x_n}^{1/k_n}\le1 \frac{k_1!k_2!\dotsm k_n!}{(k_1+k_2+\dotsb+k_n)!}. k_i 2^3\frac{\frac12!^3}{\frac32!}r^3=\frac43\pi r^3 n \dfrac1{\binom{k_1+k_2+\dotsb+k_n}{k_1,k_2,\dots,k_n}} k_1+k_2+\dotsb+k_n k_1,k_2,\dots,k_n P({x_1}^{1/k_1}+{x_2}^{1/k_2}+\dotsb+{x_n}^{1/k_n}\le1)=\frac{k_1!k_2!\dotsm k_n!}{(k_1+k_2+\dotsb+k_n)!} k_1=\dotsb=k_n=1","['probability', 'multinomial-coefficients']"
69,Two tails in a row - what's the probability that the game started with a head?,Two tails in a row - what's the probability that the game started with a head?,,"We're tossing a coin until two heads or two tails in a row occur. The game ended with a tail. What's the probability that it started with a head? Let's say we denote the game as a sequence of heads and tails, e.g. $(T_1, H_2, T_3, H_5, H_6)$ is a game that started with a tail and ended with a head. In this notation, I need to find $P(H_1 | T_{n-1}T_{n})$. $$P(H_1 | T_{n-1}T_{n}) = \dfrac{P(H_1 \cap T_{n-1}T_{n})}{P(T_{n-1}T_{n})}$$ For a given $n$, there is exactly one sequence starting with a head and ending with two tails: $(H_1, T_2, H_3, ..., H_{n-2}, T_{n-1}, T_n)$ - this is the event mentioned in the numerator. Now, there are two options for the event in the denominator: either the game is $(H_1, T_2, H_3, ..., H_{n-2}, T_{n-1}, T_n)$, or $(T_1, H_2, T_3, ..., H_{n-2}, T_{n-1}, T_n)$ - they differ in length by 1, though. How do I calculate their probabilities? I was thinking of calculating discrete probabilities of sequences of length $n$, but since there are two options for the last event, I'm not sure how it'll work.","We're tossing a coin until two heads or two tails in a row occur. The game ended with a tail. What's the probability that it started with a head? Let's say we denote the game as a sequence of heads and tails, e.g. $(T_1, H_2, T_3, H_5, H_6)$ is a game that started with a tail and ended with a head. In this notation, I need to find $P(H_1 | T_{n-1}T_{n})$. $$P(H_1 | T_{n-1}T_{n}) = \dfrac{P(H_1 \cap T_{n-1}T_{n})}{P(T_{n-1}T_{n})}$$ For a given $n$, there is exactly one sequence starting with a head and ending with two tails: $(H_1, T_2, H_3, ..., H_{n-2}, T_{n-1}, T_n)$ - this is the event mentioned in the numerator. Now, there are two options for the event in the denominator: either the game is $(H_1, T_2, H_3, ..., H_{n-2}, T_{n-1}, T_n)$, or $(T_1, H_2, T_3, ..., H_{n-2}, T_{n-1}, T_n)$ - they differ in length by 1, though. How do I calculate their probabilities? I was thinking of calculating discrete probabilities of sequences of length $n$, but since there are two options for the last event, I'm not sure how it'll work.",,"['probability', 'probability-theory', 'independence']"
70,Asymmetric ruin probability,Asymmetric ruin probability,,"I have $50$ dollars and I’m gambling on a series of coin flips. For each head I win $2$ dollars and for each tail I lose $1$ dollar. What’s the probability that I will run out of money? Hint: Suppose we have $x$ dollars, then the probability of ruin satisfies the recursive equation $$p(x+2) - p(x) = p(x) - p(x-1)$$ Find function $p(x)$.","I have $50$ dollars and I’m gambling on a series of coin flips. For each head I win $2$ dollars and for each tail I lose $1$ dollar. What’s the probability that I will run out of money? Hint: Suppose we have $x$ dollars, then the probability of ruin satisfies the recursive equation $$p(x+2) - p(x) = p(x) - p(x-1)$$ Find function $p(x)$.",,"['probability', 'stochastic-processes', 'gambling']"
71,"If $(a,b,c)$ are the sides of a triangle and $x \ge 1$, what is the probability that $a+b > cx$?","If  are the sides of a triangle and , what is the probability that ?","(a,b,c) x \ge 1 a+b > cx","I am trying to generalize the triangle inequality in probabilistic terms. Assume that the vertices are uniformly distributed around the circumference of a fixed circle. In this question it was proved that if $(a,b,c)$ are the sides of a triangle than the probability that geometric mean of any two sides is greater than the third side i.e. $P\left(\sqrt{ab} > c\right) = \frac{2}{5}$ . Since $a+b > 2\sqrt{ab}$ , it implies that probability that $P(a+b > 2c) > \frac{2}{5}$ . In general, we can ask: Question : If $(a,b,c)$ are the sides of a triangle and $x \ge 1$ , what is the probability that $a+b > cx$ ? Equivalence with the Basel's Problem : The series in the accepted answer is actually the Lengendre Chi function $\chi_2\left(\frac1{x}\right)$ ; hence $$ P(a+b > cx) = \frac{8}{\pi^2}\chi_2\left(\frac1{x}\right) $$ Taking $x = 1$ and applying the fact that the sum of the reciprocal of odd squares is $3/4$ -th the sum over the reciprocal of the squares of natural numbers we find that the probability that the sum of any two sides of a triangle is greater than than the third side is $\displaystyle \frac{6\zeta(2)}{\pi^2}$ . Since this probability must be $1$ and the proof does not require the value of $\zeta(2)$ to be known in advance, it unexpectedly shows that: The triangle inequality equivalent to the Basel Problem $$ 1 + \frac{1}{2^2} + \frac{1}{3^2} + \cdots = \frac{\pi^2}{6} $$ I have changed the title to reflect this remarkable connection. Related question : If $(a,b,c)$ are the sides of a triangle, is it true that probability that $a+b > c^{\frac{3}{c}}$ is $\zeta(2)-1$ ?","I am trying to generalize the triangle inequality in probabilistic terms. Assume that the vertices are uniformly distributed around the circumference of a fixed circle. In this question it was proved that if are the sides of a triangle than the probability that geometric mean of any two sides is greater than the third side i.e. . Since , it implies that probability that . In general, we can ask: Question : If are the sides of a triangle and , what is the probability that ? Equivalence with the Basel's Problem : The series in the accepted answer is actually the Lengendre Chi function ; hence Taking and applying the fact that the sum of the reciprocal of odd squares is -th the sum over the reciprocal of the squares of natural numbers we find that the probability that the sum of any two sides of a triangle is greater than than the third side is . Since this probability must be and the proof does not require the value of to be known in advance, it unexpectedly shows that: The triangle inequality equivalent to the Basel Problem I have changed the title to reflect this remarkable connection. Related question : If are the sides of a triangle, is it true that probability that is ?","(a,b,c) P\left(\sqrt{ab} > c\right) = \frac{2}{5} a+b > 2\sqrt{ab} P(a+b > 2c) > \frac{2}{5} (a,b,c) x \ge 1 a+b > cx \chi_2\left(\frac1{x}\right) 
P(a+b > cx) = \frac{8}{\pi^2}\chi_2\left(\frac1{x}\right)
 x = 1 3/4 \displaystyle \frac{6\zeta(2)}{\pi^2} 1 \zeta(2)  1 + \frac{1}{2^2} +
\frac{1}{3^2} + \cdots = \frac{\pi^2}{6}  (a,b,c) a+b > c^{\frac{3}{c}} \zeta(2)-1","['probability', 'integration', 'geometry', 'probability-distributions', 'euclidean-geometry']"
72,"If two sets have a natural (asymptotic) density, does their union?","If two sets have a natural (asymptotic) density, does their union?",,"Let $\Omega=\mathbb{N}$ . For each $E\subset\Omega$ let $N_n(E)$ be the cardinality of the set $E\cap \{1,2,\ldots,n\}$ . Define $C=\left\{E: \lim_{n\rightarrow \infty} \frac{N_n(E)}{n} \text{ exists}\right\}$ . Show that $C$ isn't a field. I already know that it isn't closed to finite union of non-disjoint set but I can't see why. I saw a post that somebody said ""the set of natural numbers whose first digit is 1 doesn't have this limit"". I'm in trouble to see why this limit wouldn't exists in finite unions. Thanks in advance.","Let . For each let be the cardinality of the set . Define . Show that isn't a field. I already know that it isn't closed to finite union of non-disjoint set but I can't see why. I saw a post that somebody said ""the set of natural numbers whose first digit is 1 doesn't have this limit"". I'm in trouble to see why this limit wouldn't exists in finite unions. Thanks in advance.","\Omega=\mathbb{N} E\subset\Omega N_n(E) E\cap \{1,2,\ldots,n\} C=\left\{E: \lim_{n\rightarrow \infty} \frac{N_n(E)}{n} \text{ exists}\right\} C","['probability', 'number-theory']"
73,Probability measures on a Polish space,Probability measures on a Polish space,,"Let $X$ be a Polish space, that is a separable metric complete topological space. Is the space of Borel probability measures on $X$, equipped with its weak topology, is Polish too ? It is metric, but what about completeness and separability ?","Let $X$ be a Polish space, that is a separable metric complete topological space. Is the space of Borel probability measures on $X$, equipped with its weak topology, is Polish too ? It is metric, but what about completeness and separability ?",,"['probability', 'general-topology', 'probability-theory']"
74,"The vertices of a triangle are three random points on a unit circle. The side lengths are $a,b,c$. Show that $P(ab>c)=\frac12$.",The vertices of a triangle are three random points on a unit circle. The side lengths are . Show that .,"a,b,c P(ab>c)=\frac12","The vertices of a triangle are three uniformly random points on a unit circle. The side lengths are, in random order, $a,b,c$ . Show that $P(ab>c)=\frac12$ . The result is strongly suggested by simulations, and by my attempt shown below. The simplicity of the result suggests that there may be an intuitive explanation. I am hoping for an intuitive explanation, but if that's not possible then any answer is welcome. (Examples of intuitive explanations are here and here .) My attempt Assume that the circle is centred at the origin, and the vertices of the triangle are: $A(\cos(-2Y),\sin(-2Y))$ where $0\le Y\le\pi$ $B(\cos(2X),\sin(2X))$ where $0\le X\le\pi$ $C(1,0)$ Let: $a=BC=2\sin X$ $b=AC=2\sin Y$ $c=AB=\left|2\sin\left(\frac{2\pi-2X-2Y}{2}\right)\right|=|2\sin(X+Y)|$ $P\left[ab>c\right]=P\left[2(\sin X)(\sin Y)>|\sin(X+Y)|\right]$ This probability is the ratio of the area of the shaded region to the area of the square in the graph below. Rotate these regions $45^\circ$ clockwise about the origin and then shrink them by a factor of $\frac{1}{\sqrt2}$ , by letting $X=x-y$ and $Y=x+y$ . Using symmetry, we only need to consider the left half of the blue ""diamond"". Note that in the left half, $0<x<\pi/2$ , so $|\sin(2x)|=\sin(2x)$ . $P\left[2(\sin X)(\sin Y)>|\sin(X+Y)|\right]$ $=P\left[2(\sin (x-y))(\sin (x+y))>\sin(2x)\right]$ $=P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(\sin^2 y)>(\cos x)(\sin x)\right]$ $=P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(1-\cos^2 y)>(\cos x)(\sin x)\right]$ $=P\left[\cos^2 y>\cos^2 x+(\cos x)(\sin x)\right]$ $=P\left[ -f(x)<y<f(x)\right]$ where $\color{red}{f(x)=\arccos\left((\cos x)\sqrt{1+\tan x}\right)}$ . Noting that $f\left(\frac{\pi}{4}\right)=0$ , the probability is $$\dfrac{\int_{\pi/4}^{\pi/2}f(x)\mathrm dx}{\frac12\left(\frac{\pi}{2}\right)^2}$$ Numerical evidence suggests that $\int_{\pi/4}^{\pi/2}f(x)\mathrm dx=\frac{\pi^2}{16}$ , but I don't know how to prove this. If that's true, then the probability is indeed $1/2$ . Context This question was inspired by a question , ""If $(a,b,c)$ are the sides of a triangle, what is the probability that $ac>b^2$ ?"" Generalization I found a generalization, which may or may not help in finding an intuitive explanation. For $k\in\mathbb{R^+}$ , we have $$P(ab<kc)=\frac{2}{\pi}\arctan k$$ or equivalently, $$P\left(\frac{ab}{c}<k\right)=\frac{\arctan k}{\frac{\pi}{2}}$$ Proof : Using the set-up in the above ""My attempt"", we have $P[ab\color{red}{>}kc]$ $=P\left[2(\sin X)(\sin Y)>k|\sin(X+Y)|\right]$ $=P\left[2(\sin (x-y))(\sin (x+y))>k\sin(2x)\right]$ $=P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(\sin^2 y)>k(\cos x)(\sin x)\right]$ $=P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(1-\cos^2 y)>k(\cos x)(\sin x)\right]$ $=P\left[\cos^2 y>\cos^2 x+k(\cos x)(\sin x)\right]$ $=P\left[ -g(x)<y<g(x)\right]$ where $\color{red}{g(x)=\arccos\left((\cos x)\sqrt{1+k\tan x}\right)}$ . Noting that $g\left(\arctan k\right)=0$ , the probability is $$\dfrac{\int_{\arctan k}^{\pi/2}g(x)\mathrm dx}{\frac12\left(\frac{\pi}{2}\right)^2}$$ To evaluate the integral in the numerator, I copy the method in @Zacky's answer , adjusted for the presence of $k$ . $$I=\int_{\arctan k}^{\pi/2} \arccos\left(\cos x \sqrt{1+k\tan x}\right)dx\overset{\cot x\to x}=\int_0^{1/k} \frac{\arccos \sqrt{\frac{x(k+x)}{1+x^2}}}{1+x^2}dx$$ $$=\int_0^{1/k} \frac{\arctan \sqrt{\frac{1}{x}\frac{1-kx}{k+x}}}{1+x^2} dx\overset{\large \frac{1-kx}{k+x}\to x}=\int_0^{1/k} \frac{\operatorname{arccot} \sqrt{\frac{1}{x}\frac{1-kx}{k+x}}}{1+x^2}dx$$ $$\Rightarrow 2I=\frac{\pi}{2}\int_0^{1/k} \frac{1}{1+x^2}dx\Rightarrow \boxed{I=\frac{\pi}{4}\arctan \frac1k}$$ Above it was utilized that $\, \arccos x =\arctan \left(\frac{\sqrt{1-x^2}}{x}\right)$ and $\arctan x+\operatorname{arccot} x=\frac{\pi}{2}$ . $\therefore P(ab>kc)=\frac{2}{\pi}\arctan\frac1k$ $\therefore P(ab<kc)=1-\frac{2}{\pi}\arctan\frac1k=\frac{2}{\pi}\arctan k$","The vertices of a triangle are three uniformly random points on a unit circle. The side lengths are, in random order, . Show that . The result is strongly suggested by simulations, and by my attempt shown below. The simplicity of the result suggests that there may be an intuitive explanation. I am hoping for an intuitive explanation, but if that's not possible then any answer is welcome. (Examples of intuitive explanations are here and here .) My attempt Assume that the circle is centred at the origin, and the vertices of the triangle are: where where Let: This probability is the ratio of the area of the shaded region to the area of the square in the graph below. Rotate these regions clockwise about the origin and then shrink them by a factor of , by letting and . Using symmetry, we only need to consider the left half of the blue ""diamond"". Note that in the left half, , so . where . Noting that , the probability is Numerical evidence suggests that , but I don't know how to prove this. If that's true, then the probability is indeed . Context This question was inspired by a question , ""If are the sides of a triangle, what is the probability that ?"" Generalization I found a generalization, which may or may not help in finding an intuitive explanation. For , we have or equivalently, Proof : Using the set-up in the above ""My attempt"", we have where . Noting that , the probability is To evaluate the integral in the numerator, I copy the method in @Zacky's answer , adjusted for the presence of . Above it was utilized that and .","a,b,c P(ab>c)=\frac12 A(\cos(-2Y),\sin(-2Y)) 0\le Y\le\pi B(\cos(2X),\sin(2X)) 0\le X\le\pi C(1,0) a=BC=2\sin X b=AC=2\sin Y c=AB=\left|2\sin\left(\frac{2\pi-2X-2Y}{2}\right)\right|=|2\sin(X+Y)| P\left[ab>c\right]=P\left[2(\sin X)(\sin Y)>|\sin(X+Y)|\right] 45^\circ \frac{1}{\sqrt2} X=x-y Y=x+y 0<x<\pi/2 |\sin(2x)|=\sin(2x) P\left[2(\sin X)(\sin Y)>|\sin(X+Y)|\right] =P\left[2(\sin (x-y))(\sin (x+y))>\sin(2x)\right] =P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(\sin^2 y)>(\cos x)(\sin x)\right] =P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(1-\cos^2 y)>(\cos x)(\sin x)\right] =P\left[\cos^2 y>\cos^2 x+(\cos x)(\sin x)\right] =P\left[ -f(x)<y<f(x)\right] \color{red}{f(x)=\arccos\left((\cos x)\sqrt{1+\tan x}\right)} f\left(\frac{\pi}{4}\right)=0 \dfrac{\int_{\pi/4}^{\pi/2}f(x)\mathrm dx}{\frac12\left(\frac{\pi}{2}\right)^2} \int_{\pi/4}^{\pi/2}f(x)\mathrm dx=\frac{\pi^2}{16} 1/2 (a,b,c) ac>b^2 k\in\mathbb{R^+} P(ab<kc)=\frac{2}{\pi}\arctan k P\left(\frac{ab}{c}<k\right)=\frac{\arctan k}{\frac{\pi}{2}} P[ab\color{red}{>}kc] =P\left[2(\sin X)(\sin Y)>k|\sin(X+Y)|\right] =P\left[2(\sin (x-y))(\sin (x+y))>k\sin(2x)\right] =P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(\sin^2 y)>k(\cos x)(\sin x)\right] =P\left[(\sin^2x)(\cos^2y)-(\cos^2 x)(1-\cos^2 y)>k(\cos x)(\sin x)\right] =P\left[\cos^2 y>\cos^2 x+k(\cos x)(\sin x)\right] =P\left[ -g(x)<y<g(x)\right] \color{red}{g(x)=\arccos\left((\cos x)\sqrt{1+k\tan x}\right)} g\left(\arctan k\right)=0 \dfrac{\int_{\arctan k}^{\pi/2}g(x)\mathrm dx}{\frac12\left(\frac{\pi}{2}\right)^2} k I=\int_{\arctan k}^{\pi/2} \arccos\left(\cos x \sqrt{1+k\tan x}\right)dx\overset{\cot x\to x}=\int_0^{1/k} \frac{\arccos \sqrt{\frac{x(k+x)}{1+x^2}}}{1+x^2}dx =\int_0^{1/k} \frac{\arctan \sqrt{\frac{1}{x}\frac{1-kx}{k+x}}}{1+x^2} dx\overset{\large \frac{1-kx}{k+x}\to x}=\int_0^{1/k} \frac{\operatorname{arccot} \sqrt{\frac{1}{x}\frac{1-kx}{k+x}}}{1+x^2}dx \Rightarrow 2I=\frac{\pi}{2}\int_0^{1/k} \frac{1}{1+x^2}dx\Rightarrow \boxed{I=\frac{\pi}{4}\arctan \frac1k} \, \arccos x =\arctan \left(\frac{\sqrt{1-x^2}}{x}\right) \arctan x+\operatorname{arccot} x=\frac{\pi}{2} \therefore P(ab>kc)=\frac{2}{\pi}\arctan\frac1k \therefore P(ab<kc)=1-\frac{2}{\pi}\arctan\frac1k=\frac{2}{\pi}\arctan k","['probability', 'integration', 'definite-integrals', 'intuition', 'geometric-probability']"
75,Expected value of infinite sum,Expected value of infinite sum,,"$x_1, x_2,  \dots, x_n, \dots$ - independent random variables. Is it true that $$ \sum_{i = 1}^{\infty}Ex_i = E(\sum_{i = 1}^{\infty} x_i) $$ ?","$x_1, x_2,  \dots, x_n, \dots$ - independent random variables. Is it true that $$ \sum_{i = 1}^{\infty}Ex_i = E(\sum_{i = 1}^{\infty} x_i) $$ ?",,['probability']
76,Distribution of a maximum,Distribution of a maximum,,"Randomly select $n$ numbers from ${\{1,2,\dots,m\}}$ without replacement, and order the chosen elements increasingly: $X_1 < X_2 < \dots < X_n$ And we can view each $X_i$ as a random variable, and we can get $\mathbb{E}(X_i) = \frac{(m+1)i}{n+1}$ And we can define $Y_i=|X_i-\mathbb{E}(X_i)|$ which is the distance of each variable to its corresponding expectation. And we can also define $Z = \max_{1 \le i \le n} Y_i$ So what is the distribution of $Z$? [Updated] Any bound of $Z$ is helpful. [Updated] I have re-posted the question at Mathoverflow: https://mathoverflow.net/questions/78822/distribution-of-a-maximum People there gave some new ideas.","Randomly select $n$ numbers from ${\{1,2,\dots,m\}}$ without replacement, and order the chosen elements increasingly: $X_1 < X_2 < \dots < X_n$ And we can view each $X_i$ as a random variable, and we can get $\mathbb{E}(X_i) = \frac{(m+1)i}{n+1}$ And we can define $Y_i=|X_i-\mathbb{E}(X_i)|$ which is the distance of each variable to its corresponding expectation. And we can also define $Z = \max_{1 \le i \le n} Y_i$ So what is the distribution of $Z$? [Updated] Any bound of $Z$ is helpful. [Updated] I have re-posted the question at Mathoverflow: https://mathoverflow.net/questions/78822/distribution-of-a-maximum People there gave some new ideas.",,"['probability', 'combinatorics']"
77,Average Length of Longest Palindromic Subsequence,Average Length of Longest Palindromic Subsequence,,"Suppose there is a finite set $A$ containing $n$ elements. One can construct a sequence of  finite length: $$\{a_i\},\ a_i \in A,\  i\in \mathbb N,\ i\le N$$ This sequence contains $2^N$ subsequences of the form: $$\{ a_{i_k}\}, k\in \mathbb N,\ k\le M\le N,\ i_k>i_{k-1}$$ Such a subsequence is palindromic iff $a_{i_{M+1-k}} = a_{i_k}\ \forall k$ . The length of the longest such palindromic subsequence can thus be defined as: $$M_p\{a_i\} = \max\{|\{a_{i_k}\}|:a_{i_{M+1-k}} = a_{i_k}\ \forall k\}$$ The algorithm to find $M_p$ is a well known dynamic programming problem, but after implementing it I found an interesting behavior. The average proportional length of the longest palindromic subsequence can be written as: $$\pi(N) = \left\langle\frac{M_p\{a_i\}}{N}\right\rangle$$ where $\left\langle\right\rangle$ denotes an average over all $\{a_i\}$ of length $N$ . In principle, a random sampling should provide a good approximation. Numerically, it appears that $\lim_{N\to\infty}\pi(N)$ converges to a constant depending only on the $n$ , the number of elements from which the sequence is constructed. For binary sequences, this limit appears to be $\approx 0.8$ , while for $n=10$ , it appears to be $\approx 0.45$ . The fact that the limit converges to a constant other than $1$ or $0$ indicates that the longest palindrome scales linearly with the length of the sequence, and that the calculated values appear to be rational numbers quite curious. Here are some rough approximations of $\lim_{N\to\infty}\pi_n(N)$ , generated using 256 random sequences of length 256. $\sigma$ indicates the standard deviation of the distribution, not the sample mean. \begin{array}{c|lcr} n & \pi_n(N) & \sigma \\ \hline 2  & 0.80035 & 0.01647 \\ 3  & 0.70724 & 0.01615 \\ 4  & 0.64514 & 0.01544 \\ 5  & 0.59718 & 0.01697 \\ 6  & 0.56046 & 0.01617 \\ 7  & 0.53024 & 0.01627 \\ 8  & 0.50377 & 0.01527 \\ 9  & 0.48380 & 0.01520 \\ 10 & 0.46349 & 0.01489 \end{array} I would like to know if there is a way to derive the asymptotic behavior observed in these numerical results. The complexity of the algorithm for $M_p$ makes it difficult to derive a probability distribution, and the rational number results hint that there may be a simpler approach. Any input would be appreciated.","Suppose there is a finite set containing elements. One can construct a sequence of  finite length: This sequence contains subsequences of the form: Such a subsequence is palindromic iff . The length of the longest such palindromic subsequence can thus be defined as: The algorithm to find is a well known dynamic programming problem, but after implementing it I found an interesting behavior. The average proportional length of the longest palindromic subsequence can be written as: where denotes an average over all of length . In principle, a random sampling should provide a good approximation. Numerically, it appears that converges to a constant depending only on the , the number of elements from which the sequence is constructed. For binary sequences, this limit appears to be , while for , it appears to be . The fact that the limit converges to a constant other than or indicates that the longest palindrome scales linearly with the length of the sequence, and that the calculated values appear to be rational numbers quite curious. Here are some rough approximations of , generated using 256 random sequences of length 256. indicates the standard deviation of the distribution, not the sample mean. I would like to know if there is a way to derive the asymptotic behavior observed in these numerical results. The complexity of the algorithm for makes it difficult to derive a probability distribution, and the rational number results hint that there may be a simpler approach. Any input would be appreciated.","A n \{a_i\},\ a_i \in A,\  i\in \mathbb N,\ i\le N 2^N \{ a_{i_k}\}, k\in \mathbb N,\ k\le M\le N,\ i_k>i_{k-1} a_{i_{M+1-k}} = a_{i_k}\ \forall k M_p\{a_i\} = \max\{|\{a_{i_k}\}|:a_{i_{M+1-k}} = a_{i_k}\ \forall k\} M_p \pi(N) = \left\langle\frac{M_p\{a_i\}}{N}\right\rangle \left\langle\right\rangle \{a_i\} N \lim_{N\to\infty}\pi(N) n \approx 0.8 n=10 \approx 0.45 1 0 \lim_{N\to\infty}\pi_n(N) \sigma \begin{array}{c|lcr}
n & \pi_n(N) & \sigma \\
\hline
2  & 0.80035 & 0.01647 \\
3  & 0.70724 & 0.01615 \\
4  & 0.64514 & 0.01544 \\
5  & 0.59718 & 0.01697 \\
6  & 0.56046 & 0.01617 \\
7  & 0.53024 & 0.01627 \\
8  & 0.50377 & 0.01527 \\
9  & 0.48380 & 0.01520 \\
10 & 0.46349 & 0.01489
\end{array} M_p","['probability', 'combinatorics', 'palindrome']"
78,A probability involving areas in a random pentagram inscribed in a circle: Is it really just $\frac12$?,A probability involving areas in a random pentagram inscribed in a circle: Is it really just ?,\frac12,"The vertices of a pentagram are five uniformly random points on a circle. The areas of three consecutive triangular ""petals"" are $a,b,c$ . The petals are randomly chosen, but they must be consecutive, either clockwise or anticlockwise. A simulation of $10^7$ such random pentagrams yielded a proportion of $0.5000179$ satisfying $a^2<bc$ . Is the following conjecture true: $P(a^2<bc)=\frac{1}{2}$ Remarks Note that the three petals must be consecutive. Calling the areas of consecutive petals $a,b,c,d,e$ , simulations suggest that: $P(a^2<bd)\approx0.468$ $P(a^2<be)\approx0.505$ $P(a^2<cd)\approx0.460$ Curiously, the probability that seems to equal $\frac{1}{2}$ , i.e. $P(a^2<bc)$ , does not involve a symmetrical arrangement of three petals. As for other random star polygons $\{\frac{n}{2}\}$ inscribed in a circle, simulations suggest that Star polygon $\left\{\frac{6}{2}\right\}$ : $P(a^2<bc)\approx0.505$ . Star polygon $\{\frac{7}{2}\}$ : $P(a^2<bc)\approx0.504$ . I used the shoelace formula to calculate the areas of the triangular petals. One might expect that a probability of $\frac12$ should have an intuitive explanation, but sometimes probabilities of $\frac12$ are hard to explain . Underlying reason? Simulations suggest that the random pentagram/pentagon shape is teeming with probabilities of powers of $\frac12$ . In the following diagram, the letters represent areas of the regions. $P(g+b+h<a+f+c)\overset{?}{=}\color{red}{\frac{1}{2}}$ $P(g+h<f)\overset{?}{=}\color{red}{\frac{1}{4}}$ $P((g+a+k)(h+c+i)>(b+f+e+d+j)^2)\overset{?}{=}\color{red}{\frac{1}{8}}$ $P(\text{each region with area $g,b,f,l$ contains the centre of the circle})=\color{red}{\frac{1}{16}}$ ( proved ) $P(\text{areas of petals increase going around once, clockwise or anticlockwise})\overset{?}{=}\color{red}{\frac{1}{32}}$ I am not asking to prove these other probability claims. I am presenting them to suggest that there may be an underlying reason why the pentagram has probabilities of powers of $\frac12$ , which may be relevant to my conjecture. These simulations make me more inclined to believe that my conjecture is true, but I could be wrong .","The vertices of a pentagram are five uniformly random points on a circle. The areas of three consecutive triangular ""petals"" are . The petals are randomly chosen, but they must be consecutive, either clockwise or anticlockwise. A simulation of such random pentagrams yielded a proportion of satisfying . Is the following conjecture true: Remarks Note that the three petals must be consecutive. Calling the areas of consecutive petals , simulations suggest that: Curiously, the probability that seems to equal , i.e. , does not involve a symmetrical arrangement of three petals. As for other random star polygons inscribed in a circle, simulations suggest that Star polygon : . Star polygon : . I used the shoelace formula to calculate the areas of the triangular petals. One might expect that a probability of should have an intuitive explanation, but sometimes probabilities of are hard to explain . Underlying reason? Simulations suggest that the random pentagram/pentagon shape is teeming with probabilities of powers of . In the following diagram, the letters represent areas of the regions. ( proved ) I am not asking to prove these other probability claims. I am presenting them to suggest that there may be an underlying reason why the pentagram has probabilities of powers of , which may be relevant to my conjecture. These simulations make me more inclined to believe that my conjecture is true, but I could be wrong .","a,b,c 10^7 0.5000179 a^2<bc P(a^2<bc)=\frac{1}{2} a,b,c,d,e P(a^2<bd)\approx0.468 P(a^2<be)\approx0.505 P(a^2<cd)\approx0.460 \frac{1}{2} P(a^2<bc) \{\frac{n}{2}\} \left\{\frac{6}{2}\right\} P(a^2<bc)\approx0.505 \{\frac{7}{2}\} P(a^2<bc)\approx0.504 \frac12 \frac12 \frac12 P(g+b+h<a+f+c)\overset{?}{=}\color{red}{\frac{1}{2}} P(g+h<f)\overset{?}{=}\color{red}{\frac{1}{4}} P((g+a+k)(h+c+i)>(b+f+e+d+j)^2)\overset{?}{=}\color{red}{\frac{1}{8}} P(\text{each region with area g,b,f,l contains the centre of the circle})=\color{red}{\frac{1}{16}} P(\text{areas of petals increase going around once, clockwise or anticlockwise})\overset{?}{=}\color{red}{\frac{1}{32}} \frac12","['probability', 'integration', 'circles', 'conjectures', 'geometric-probability']"
79,"Take a random walk on a Christmas tree, starting at the top. What is the probability of returning to the top?","Take a random walk on a Christmas tree, starting at the top. What is the probability of returning to the top?",,"Consider a ""Christmas tree lattice"" composed of equilateral triangles, as shown. The lattice extends down infinitely. Start at the top vertex and take a random walk. At each step, move to a randomly chosen neighboring vertex, each with equal probability. Re-visiting vertices is allowed. What is the probability of returning to the top? Context I was reading about Polya's random walk constants , and with all the Christmas trees appearing these days, this question naturally arose. My thoughts Let $p(k)$ be the probability of returning to the top for the first time on the $k$ th step, and let $P(n)=\sum\limits_{k=2}^n p(k)$ . We are looking for $P(\infty)$ . According to my calculations, based on counting paths: $p(2)=\frac14$ $p(3)=\frac{1}{4^2}=\frac{1}{16}$ $p(4)=\frac{2}{4^3}+\frac{1}{4^2\cdot3}=\frac{5}{96}$ $p(5)=\frac{3}{4^4}+\frac{4}{4^3\cdot 3}=\frac{25}{768}$ $p(6)=\frac{6}{4^5}+\frac{21}{4^4 6}+\frac{12}{4^3 6^2}+\frac{4}{4^2 6^3}=\frac{179}{6912}$ Calculating gets progressively harder. $P(6)=\frac14+\frac{1}{16}+\frac{5}{96}+\frac{25}{768}+\frac{179}{6912}=\approx 0.423032$ . I guess $P(\infty)<1$ , because whenever the path touches the boundary of the tree, the probability of going down is double the probability of going up. If we have a triangular lattice (instead of a Christmas tree), the probability of returning to the origin is presumably $1$ . Edit In the comments, @user has provided values of $P(n)$ for $n=5,6,50,100, 150, 200, 250,300$ . (I got the same results for $n=5,6$ .) Here is a graph of $P(n)$ against $n$ , for $n=2,6,50,100,150,200,250,300$ .","Consider a ""Christmas tree lattice"" composed of equilateral triangles, as shown. The lattice extends down infinitely. Start at the top vertex and take a random walk. At each step, move to a randomly chosen neighboring vertex, each with equal probability. Re-visiting vertices is allowed. What is the probability of returning to the top? Context I was reading about Polya's random walk constants , and with all the Christmas trees appearing these days, this question naturally arose. My thoughts Let be the probability of returning to the top for the first time on the th step, and let . We are looking for . According to my calculations, based on counting paths: Calculating gets progressively harder. . I guess , because whenever the path touches the boundary of the tree, the probability of going down is double the probability of going up. If we have a triangular lattice (instead of a Christmas tree), the probability of returning to the origin is presumably . Edit In the comments, @user has provided values of for . (I got the same results for .) Here is a graph of against , for .","p(k) k P(n)=\sum\limits_{k=2}^n p(k) P(\infty) p(2)=\frac14 p(3)=\frac{1}{4^2}=\frac{1}{16} p(4)=\frac{2}{4^3}+\frac{1}{4^2\cdot3}=\frac{5}{96} p(5)=\frac{3}{4^4}+\frac{4}{4^3\cdot 3}=\frac{25}{768} p(6)=\frac{6}{4^5}+\frac{21}{4^4 6}+\frac{12}{4^3 6^2}+\frac{4}{4^2 6^3}=\frac{179}{6912} P(6)=\frac14+\frac{1}{16}+\frac{5}{96}+\frac{25}{768}+\frac{179}{6912}=\approx 0.423032 P(\infty)<1 1 P(n) n=5,6,50,100, 150, 200, 250,300 n=5,6 P(n) n n=2,6,50,100,150,200,250,300","['probability', 'sequences-and-series', 'limits', 'graph-theory', 'random-walk']"
80,Can the sample mean converge faster than $1/\sqrt{n}$?,Can the sample mean converge faster than ?,1/\sqrt{n},"Consider a IID sequence $X_1,...,X_n$ of random variables with $\mathbb{E}[X_i] = 0$ and $\mathbb{E}[X_i^2] = 1$ . The central limit theorem implies that the sample mean converges in $L_1$ to $0$ at a rate $O(1/\sqrt{n})$ . I am interested in an anti-concentration result showing that this is the fastest possible rate over all $X_i$ s. So far, using the Paley-Zygmund inequality, I have derived such a result assuming the $X_i$ 's have sufficiently small $4^{th}$ moments; specifically, for some universal constant $c_0$ , $$\mathbb{E} \left[ \left| \frac{1}{n} \sum_{i = 1}^n X_i \right| \right] \geq \frac{c_0}{\sqrt{n}} \frac{n}{\mathbb{E}[X_i^4] + n} \in \Omega \left( \frac{1}{\sqrt{n}} \right),$$ which implies my desired result as long as $\mathbb{E}[X_i^4] \in O(n)$ . Previously, using Berry-Esseen, I was also able to get a similar result assuming $(\mathbb{E}[X_i^3])^{4/3} \in O(\sqrt{n})$ . However, it seems counterintuitive to me that having a large $3^{rd}$ or $4^{th}$ moment would speed up the rate of convergence, and I'm wondering if these assumption can be relaxed. Actually, in my application, it would be ok to assume $\mathbb{E}[X_i^p] \in O(n^{p/2})$ for any $p \geq 1$ , although it would be simpler if I can avoid making any assumptions on $X_i$ . Question: Without any further assumptions on the $X_i$ s, do there exist universal constants $c_0, n_0 > 0$ such that, for all integers $n > n_0$ , $$\mathbb{E} \left[ \left| \frac{1}{n} \sum_{i = 1}^n X_i \right| \right]   \geq \frac{c_0}{\sqrt{n}}.$$ Alternatively, is there a counterexample, i.e., a sequence of IID sequences $\{\{X_{n,i}\}_{i = 1}^n\}_{n = 1}^\infty$ such that $$\lim_{n \to \infty} \mathbb{E} \left[ \left| \frac{1}{\sqrt{n}} \sum_{i = 1}^n X_{n,i} \right| \right] \to 0.$$","Consider a IID sequence of random variables with and . The central limit theorem implies that the sample mean converges in to at a rate . I am interested in an anti-concentration result showing that this is the fastest possible rate over all s. So far, using the Paley-Zygmund inequality, I have derived such a result assuming the 's have sufficiently small moments; specifically, for some universal constant , which implies my desired result as long as . Previously, using Berry-Esseen, I was also able to get a similar result assuming . However, it seems counterintuitive to me that having a large or moment would speed up the rate of convergence, and I'm wondering if these assumption can be relaxed. Actually, in my application, it would be ok to assume for any , although it would be simpler if I can avoid making any assumptions on . Question: Without any further assumptions on the s, do there exist universal constants such that, for all integers , Alternatively, is there a counterexample, i.e., a sequence of IID sequences such that","X_1,...,X_n \mathbb{E}[X_i] = 0 \mathbb{E}[X_i^2] = 1 L_1 0 O(1/\sqrt{n}) X_i X_i 4^{th} c_0 \mathbb{E} \left[ \left| \frac{1}{n} \sum_{i = 1}^n X_i \right| \right] \geq \frac{c_0}{\sqrt{n}} \frac{n}{\mathbb{E}[X_i^4] + n} \in \Omega \left( \frac{1}{\sqrt{n}} \right), \mathbb{E}[X_i^4] \in O(n) (\mathbb{E}[X_i^3])^{4/3} \in O(\sqrt{n}) 3^{rd} 4^{th} \mathbb{E}[X_i^p] \in O(n^{p/2}) p \geq 1 X_i X_i c_0, n_0 > 0 n > n_0 \mathbb{E} \left[ \left| \frac{1}{n} \sum_{i = 1}^n X_i \right| \right]
  \geq \frac{c_0}{\sqrt{n}}. \{\{X_{n,i}\}_{i = 1}^n\}_{n = 1}^\infty \lim_{n \to \infty} \mathbb{E} \left[ \left| \frac{1}{\sqrt{n}} \sum_{i = 1}^n X_{n,i} \right| \right] \to 0.","['probability', 'statistics', 'central-limit-theorem']"
81,Bayes Theorem Example in Nate Silver's The Signal and the Noise,Bayes Theorem Example in Nate Silver's The Signal and the Noise,,"In his book The Signal and the Noise , Nate Silver presents this example application of Bayes's Theorem on pp. 247-248: Consider a somber example: the September 11 attacks. Most of us would   have assigned almost no probability to terrorists crashing planes into   buildings in Manhattan when we woke up that morning. But we recognized   that a terror attack was an obvious possibility once the first plane hit   the World Trade Center. And we had no doubt we were being attacked   once the second tower was hit. Bayes's theorem can replicate this result. You can view the complete example in Amazon.com's previw, and I've made the two pages available here . Silver assumes the prior probability of a terrorist plane attack to be 1 in 20,000. After the first plane crash, using Bayes's Theorem he updates that to 38%. And after the second plane crash, he comes up with a 99.99% probability. However, I think he may be mistaken. I'll provide the details below. To be precise, let us define the following three events: $PC$ = Plane Crash: At least one plane crashes into a Manhattan skyscraper on a given day. $TPA$ = Terrorist Plane Attack: At least one plane is intentionally crashed into a Manhattan skyscraper on a given day. $APC$ = Accidental Plane Crash: At least one plane is accidentally crashed into a Manhattan skyscraper on a given day. We assume all plane crashes into buildings are either terrorist plane attacks or accidental (i.e. $PC = TPA \cup APC$). Using historical data, Silver estimates the prior probability of an accidental plane crash to be 1 in 12,500. In summary: $$P(TPA) = \frac{1}{20000},$$$$P(APC) = \frac{1}{12500}.$$ Furthermore, Silver assumes $P(APC) = P(PC|\overline{TPA})$ (which is true if $APC$ and $TPA$ are independent events). Applying Bayes's Theorem, he comes up with  $$\begin{align}P(TPA|PC) &= \frac{P(PC|TPA) \times P(TPA)}{P(PC|TPA) \times P(TPA) + P(PC|\overline{TPA})(1-P(TPA))} \\ &= \frac{1 \times \frac{1}{20000}}{1 \times \frac{1}{20000} +  \frac{1}{12500} \times (1 - \frac{1}{20000})} = 0.385\end{align}$$ Silver continues: The idea behind Bayes's theorem, however, is not that we update our    probability estimates just once. Instead, we do so continuously as new   evidence presents itself to us. Thus our posterior probability of a   terror attack after the first plane hit, 38 percent, becomes our prior probability before the second one did. And if you go through the calculation again, to  reflect the second plane hitting the World   Trade Center, the probability that we were under attack becomes a   near-certainty -- 99.99 percent. That is (this is Silver's calculation): $$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 +  \frac{1}{12500}(1-0.385)} = 99.99 \%$$ ""Cool!"" I thought, until I thought a bit more. The problem is that you can apply the same logic to calculate the conditional probability of an accidental crash, too. I'll spare you the math, but I come up with $P(APC|PC) = 0.615$ after the first crash, and $P(APC|PC) = 99.997\%$ after the second. So we can be almost certain the second plane crash is a terrorist attack, and we can be even more certain that it's accidental? I think the problem is that when Silver applies Bayes's Theorem after the second crash, he uses the updated probability of a terrorist plane attack as his prior, but fails to update the prior probability of an accidental plane crash (which should become 0.615). After the second crash, then, the correct formula is $$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 +  0.615(1-0.385)} = 0.504$$ Similarly, the probability that we're observing an accidental crash given that there have been two crashes is  $$P(APC|PC) = \frac{1 \times 0.615}{1 \times 0.615 +  0.385(1-0.615)} = 0.806$$ Question 1 : Am I correct that Nate Silver is doing it wrong? Question 2 : Am I doing it right?","In his book The Signal and the Noise , Nate Silver presents this example application of Bayes's Theorem on pp. 247-248: Consider a somber example: the September 11 attacks. Most of us would   have assigned almost no probability to terrorists crashing planes into   buildings in Manhattan when we woke up that morning. But we recognized   that a terror attack was an obvious possibility once the first plane hit   the World Trade Center. And we had no doubt we were being attacked   once the second tower was hit. Bayes's theorem can replicate this result. You can view the complete example in Amazon.com's previw, and I've made the two pages available here . Silver assumes the prior probability of a terrorist plane attack to be 1 in 20,000. After the first plane crash, using Bayes's Theorem he updates that to 38%. And after the second plane crash, he comes up with a 99.99% probability. However, I think he may be mistaken. I'll provide the details below. To be precise, let us define the following three events: $PC$ = Plane Crash: At least one plane crashes into a Manhattan skyscraper on a given day. $TPA$ = Terrorist Plane Attack: At least one plane is intentionally crashed into a Manhattan skyscraper on a given day. $APC$ = Accidental Plane Crash: At least one plane is accidentally crashed into a Manhattan skyscraper on a given day. We assume all plane crashes into buildings are either terrorist plane attacks or accidental (i.e. $PC = TPA \cup APC$). Using historical data, Silver estimates the prior probability of an accidental plane crash to be 1 in 12,500. In summary: $$P(TPA) = \frac{1}{20000},$$$$P(APC) = \frac{1}{12500}.$$ Furthermore, Silver assumes $P(APC) = P(PC|\overline{TPA})$ (which is true if $APC$ and $TPA$ are independent events). Applying Bayes's Theorem, he comes up with  $$\begin{align}P(TPA|PC) &= \frac{P(PC|TPA) \times P(TPA)}{P(PC|TPA) \times P(TPA) + P(PC|\overline{TPA})(1-P(TPA))} \\ &= \frac{1 \times \frac{1}{20000}}{1 \times \frac{1}{20000} +  \frac{1}{12500} \times (1 - \frac{1}{20000})} = 0.385\end{align}$$ Silver continues: The idea behind Bayes's theorem, however, is not that we update our    probability estimates just once. Instead, we do so continuously as new   evidence presents itself to us. Thus our posterior probability of a   terror attack after the first plane hit, 38 percent, becomes our prior probability before the second one did. And if you go through the calculation again, to  reflect the second plane hitting the World   Trade Center, the probability that we were under attack becomes a   near-certainty -- 99.99 percent. That is (this is Silver's calculation): $$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 +  \frac{1}{12500}(1-0.385)} = 99.99 \%$$ ""Cool!"" I thought, until I thought a bit more. The problem is that you can apply the same logic to calculate the conditional probability of an accidental crash, too. I'll spare you the math, but I come up with $P(APC|PC) = 0.615$ after the first crash, and $P(APC|PC) = 99.997\%$ after the second. So we can be almost certain the second plane crash is a terrorist attack, and we can be even more certain that it's accidental? I think the problem is that when Silver applies Bayes's Theorem after the second crash, he uses the updated probability of a terrorist plane attack as his prior, but fails to update the prior probability of an accidental plane crash (which should become 0.615). After the second crash, then, the correct formula is $$P(TPA|PC) = \frac{1 \times 0.385}{1 \times 0.385 +  0.615(1-0.385)} = 0.504$$ Similarly, the probability that we're observing an accidental crash given that there have been two crashes is  $$P(APC|PC) = \frac{1 \times 0.615}{1 \times 0.615 +  0.385(1-0.615)} = 0.806$$ Question 1 : Am I correct that Nate Silver is doing it wrong? Question 2 : Am I doing it right?",,"['probability', 'bayesian']"
82,Probability density function of the integral of a continuous stochastic process,Probability density function of the integral of a continuous stochastic process,,"I am interested in whether there is a general method to calculate the pdf of the integral of a stochastic process that is continuous in time. My specific example: I am studying a stochastic given process given by $X(t)=\int\limits_{0}^{t}\cos(B(s))\,\text{d}s$, where $B(t)$ is the Wiener process, which is normally distributed over an interval of length $\tau$ with zero mean and variance $\tau$: $B(t+\tau)-B(t)\sim\mathcal{N}(0, \tau)$. I am able to calculate the first and second moments of $X(t)$, see: Expectation value of a product of an Ito integral and a function of a Brownian motion A couple of thoughts on the matter: 1) Integrals of Gaussian continuous stochastic processes, such as the Wiener process can be considered as the limit of a sum of Gaussians and are hence themselves Gaussian.  Since $\cos(B(s))$ is not Gaussian, this doesn't seem to help here. 2) If we can derive an expression for the characteristic function of the process $X(t)$, then we can theoretically invert this to obtain the pdf.  The Feynman-Kac formula enables us to describe the characteristic function in terms of a PDE.  If this PDE has a unique analytic solution then we can make use of this.  In my specific example, this is not the case - the PDE obtained has no analytic solution.  I can provide more detail on this point if required. Many thanks for your thoughts.","I am interested in whether there is a general method to calculate the pdf of the integral of a stochastic process that is continuous in time. My specific example: I am studying a stochastic given process given by $X(t)=\int\limits_{0}^{t}\cos(B(s))\,\text{d}s$, where $B(t)$ is the Wiener process, which is normally distributed over an interval of length $\tau$ with zero mean and variance $\tau$: $B(t+\tau)-B(t)\sim\mathcal{N}(0, \tau)$. I am able to calculate the first and second moments of $X(t)$, see: Expectation value of a product of an Ito integral and a function of a Brownian motion A couple of thoughts on the matter: 1) Integrals of Gaussian continuous stochastic processes, such as the Wiener process can be considered as the limit of a sum of Gaussians and are hence themselves Gaussian.  Since $\cos(B(s))$ is not Gaussian, this doesn't seem to help here. 2) If we can derive an expression for the characteristic function of the process $X(t)$, then we can theoretically invert this to obtain the pdf.  The Feynman-Kac formula enables us to describe the characteristic function in terms of a PDE.  If this PDE has a unique analytic solution then we can make use of this.  In my specific example, this is not the case - the PDE obtained has no analytic solution.  I can provide more detail on this point if required. Many thanks for your thoughts.",,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'stochastic-integrals']"
83,Very simple dice game,Very simple dice game,,"Two players compete to reach a certain number N of points (for example 100) to win the game by throwing a each roll  two regular dice and noting the amount accumulated since their first roll. So, the first player reaching N points wins the game. Each game starts with a stake of S dollars. A fair coin is tossed to designate the first player. When a player to roll feels he has a sufficient advantage, he can choose , before he rolls the two dice,  to offer to double the stake of the game to 2S dollars. The opposing player can: -turn down the offer, but concedes the game by doing so and loses S dollars, OR -accept the offer: then the stake of the game doubles (to 2S). When a player accepts a double, he takes control of the right to (re)double the stake and he is the only player who can make the next offer of a new double (to 4S), etc. Assuming the player to roll reached s1 points (N-s1 to go to N) and his opponent has   s2 (N-s2 to go to N), how to compute if and when: -he must offer to double (redouble) -his opponent must accept","Two players compete to reach a certain number N of points (for example 100) to win the game by throwing a each roll  two regular dice and noting the amount accumulated since their first roll. So, the first player reaching N points wins the game. Each game starts with a stake of S dollars. A fair coin is tossed to designate the first player. When a player to roll feels he has a sufficient advantage, he can choose , before he rolls the two dice,  to offer to double the stake of the game to 2S dollars. The opposing player can: -turn down the offer, but concedes the game by doing so and loses S dollars, OR -accept the offer: then the stake of the game doubles (to 2S). When a player accepts a double, he takes control of the right to (re)double the stake and he is the only player who can make the next offer of a new double (to 4S), etc. Assuming the player to roll reached s1 points (N-s1 to go to N) and his opponent has   s2 (N-s2 to go to N), how to compute if and when: -he must offer to double (redouble) -his opponent must accept",,['probability']
84,How many possible 10-card hands can be dealt from super deck?,How many possible 10-card hands can be dealt from super deck?,,"I have the following problem from Introduction to Probability (2019 2 edn) by Joseph Blitzstein, p. 32, Chapter 1. A certain casino uses 10 standard decks of cards mixed together into one big deck, which we will call a superdeck . Thus, the superdeck has 52 · 10 = 520 cards, with 10 copies of each card. How many different 10-card hands can be dealt from the superdeck? The order of the cards does not matter, nor does it matter which of the original 10 decks the cards came from. Express your answer as a binomial coefficient. Hint: Bose-Einstein. Is my solution below correct? Because the number of cards of each type in the superdeck (10) is not less than the size of the hand (10), and thus not limiting, it's the same as sampling with replacement where the order does not matter, so the number of possible 10-card hands would be $\binom{52+10-1}{10}$ .","I have the following problem from Introduction to Probability (2019 2 edn) by Joseph Blitzstein, p. 32, Chapter 1. A certain casino uses 10 standard decks of cards mixed together into one big deck, which we will call a superdeck . Thus, the superdeck has 52 · 10 = 520 cards, with 10 copies of each card. How many different 10-card hands can be dealt from the superdeck? The order of the cards does not matter, nor does it matter which of the original 10 decks the cards came from. Express your answer as a binomial coefficient. Hint: Bose-Einstein. Is my solution below correct? Because the number of cards of each type in the superdeck (10) is not less than the size of the hand (10), and thus not limiting, it's the same as sampling with replacement where the order does not matter, so the number of possible 10-card hands would be .",\binom{52+10-1}{10},"['probability', 'combinatorics', 'card-games', 'multisets']"
85,Sum-Product of Random Variables,Sum-Product of Random Variables,,"Let $X_i$ be an iid sequence of random variables with support in $(0,1)$. I'm looking for references (even just a name) for the following infinite sum random variable: $$S:=X_1+X_1X_2+X_1X_2X_3+X_1X_2X_3X_4+\cdots.$$ This came up for a waiting-time problem. I can easily calculate the expected value and variance of the above sum, but I'm interested if other people have studied this in literature, specifically if there are asymptotics for limiting distribution. I presume there are also issues when $P(X>1-\epsilon)$ falls off too slowly with increasing $\epsilon$.","Let $X_i$ be an iid sequence of random variables with support in $(0,1)$. I'm looking for references (even just a name) for the following infinite sum random variable: $$S:=X_1+X_1X_2+X_1X_2X_3+X_1X_2X_3X_4+\cdots.$$ This came up for a waiting-time problem. I can easily calculate the expected value and variance of the above sum, but I'm interested if other people have studied this in literature, specifically if there are asymptotics for limiting distribution. I presume there are also issues when $P(X>1-\epsilon)$ falls off too slowly with increasing $\epsilon$.",,"['probability', 'probability-theory', 'probability-distributions']"
86,Is there a simple formula for $\binom{2n}{n} \pmod{n^3}$?,Is there a simple formula for ?,\binom{2n}{n} \pmod{n^3},"Is there a simple formula for the following? $$f(n) = \binom{2n}{n} \pmod{n^3}$$ I know $f(n) = 2$ iff $n$ is prime and greater than $3$ , but I don't know anything about composite numbers.","Is there a simple formula for the following? I know iff is prime and greater than , but I don't know anything about composite numbers.",f(n) = \binom{2n}{n} \pmod{n^3} f(n) = 2 n 3,"['probability', 'combinatorics', 'prime-numbers', 'modular-arithmetic', 'binomial-coefficients']"
87,Roll two dice. What is the probability that one die shows exactly two more than the other die? [closed],Roll two dice. What is the probability that one die shows exactly two more than the other die? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Two fair six-sided dice are rolled. What is the probability that one die shows exactly two more than the other die (for example, rolling a $1$ and $3$, or rolling a $6$ and a $4$)? I know how to calculate the probabilities of each event by itself, but I do not know how to proceed with this problem.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Two fair six-sided dice are rolled. What is the probability that one die shows exactly two more than the other die (for example, rolling a $1$ and $3$, or rolling a $6$ and a $4$)? I know how to calculate the probabilities of each event by itself, but I do not know how to proceed with this problem.",,"['probability', 'discrete-mathematics']"
88,"If two coins are flipped and one gets head, what is the probability that both get head?","If two coins are flipped and one gets head, what is the probability that both get head?",,"I have a doubt because I think that once the result of the first coin is obtained, just simply await the outcome of the second, which is completely independent of the previous one, and then we have a chance of $\frac12$ to get a head again. But someone else tells me that as the possible events are: Head - Head Head - Tail Tail - Head Tail - Tail then when we get a head we restrict ourselves to the first three cases, so the probability would be $\frac13$. What is the right way? I know there's a difference between saying ""first came head"" to say ""one of the two came head"", but if we have the first fact, aren't we supposed to know which one is that came head?","I have a doubt because I think that once the result of the first coin is obtained, just simply await the outcome of the second, which is completely independent of the previous one, and then we have a chance of $\frac12$ to get a head again. But someone else tells me that as the possible events are: Head - Head Head - Tail Tail - Head Tail - Tail then when we get a head we restrict ourselves to the first three cases, so the probability would be $\frac13$. What is the right way? I know there's a difference between saying ""first came head"" to say ""one of the two came head"", but if we have the first fact, aren't we supposed to know which one is that came head?",,"['probability', 'combinatorics', 'discrete-mathematics']"
89,Monty hall problem probability 2/6?,Monty hall problem probability 2/6?,,"For the Monty hall problem, with 3 doors, two of which have sheep and 1 has a car. I calculated the probability of getting the car if you swap being 2/6 instead of 2/3. I have drawn this tree diagram of how I calculated it: And from it I get that the probability of getting a car if you swap is 2/6 and if you stay it's 1/6, which is not the same as the actual answer 2/3 and 1/3. I have included the probabilities of getting sheep, as well as my overall probabilities, add up so I want to know what is wrong with my tree diagram, which resulted in this wrong answer. In my tree diagram I haven't included the host revealing a door, so could this be a factor as to why my answer is wrong?","For the Monty hall problem, with 3 doors, two of which have sheep and 1 has a car. I calculated the probability of getting the car if you swap being 2/6 instead of 2/3. I have drawn this tree diagram of how I calculated it: And from it I get that the probability of getting a car if you swap is 2/6 and if you stay it's 1/6, which is not the same as the actual answer 2/3 and 1/3. I have included the probabilities of getting sheep, as well as my overall probabilities, add up so I want to know what is wrong with my tree diagram, which resulted in this wrong answer. In my tree diagram I haven't included the host revealing a door, so could this be a factor as to why my answer is wrong?",,"['probability', 'monty-hall', 'decision-trees']"
90,Probability of getting all faces of a die an equal number of times,Probability of getting all faces of a die an equal number of times,,I have a question: A die is rolled 36 times. What is the probability of getting each number 6 times? I think the answer is: $6\cdot\left(\frac16\right)^6$ Am I wrong?,I have a question: A die is rolled 36 times. What is the probability of getting each number 6 times? I think the answer is: $6\cdot\left(\frac16\right)^6$ Am I wrong?,,"['probability', 'dice']"
91,Minimum number of flips to guarantee heads,Minimum number of flips to guarantee heads,,"This is a weird problem that popped into my head: given a fair coin, how many flips is required to guarantee heads? If I get a tails, then another tails, and another etc., the chance of getting a heads increases every time. But there is still a small chance that I will get another tails. This seems to imply that there is no finite number of flips to guarantee a heads. Does this mean that infinity is the correct answer (although infinity isn't a number as far as I understand) or is this question even answerable in the first place?","This is a weird problem that popped into my head: given a fair coin, how many flips is required to guarantee heads? If I get a tails, then another tails, and another etc., the chance of getting a heads increases every time. But there is still a small chance that I will get another tails. This seems to imply that there is no finite number of flips to guarantee a heads. Does this mean that infinity is the correct answer (although infinity isn't a number as far as I understand) or is this question even answerable in the first place?",,['probability']
92,Calculate expectation of a geometric random variable,Calculate expectation of a geometric random variable,,"When you download a file from a website, the file gets corrupted with probability 0.8. What is the expected number of downloads to get an uncorrupted file? I have no idea how to do this. I only know the probability that a file isn't corrupted should be 0.2, but how do I get the expectation? Can anyone help me?","When you download a file from a website, the file gets corrupted with probability 0.8. What is the expected number of downloads to get an uncorrupted file? I have no idea how to do this. I only know the probability that a file isn't corrupted should be 0.2, but how do I get the expectation? Can anyone help me?",,"['probability', 'expectation']"
93,Probability Discrepancy in drawing 2 cards from a Deck of 52,Probability Discrepancy in drawing 2 cards from a Deck of 52,,"A colleague and I are having a hard time figuring out this probability question and was wondering if anyone could provide an explanation / insight into it. The question is simple: what is the probability if you draw 2 cards at the same time (so without replacement) from a standard deck of 52, that one of those cards, or both, is a diamond? He mapped out all the possible outcomes and came to $\frac{7}{16}$, by writing out the following: DD DH DC DS HD HH HC HS SD SH SC SS CD CH CC CS Since 7 out of those 16 outcomes have a diamond in them, that is the probability. Trying mathematically though, the answer is not equivalent. We both believe that the formula is not right, but we can't figure out where the problem is. This is the formula we've tried: $\displaystyle\frac{{13\choose{1}}{39\choose1}}{52\choose{2}}+\frac{13\choose2}{52\choose2}$; the left term is for 1 diamond, another card different, and the right term is for 2 diamonds. This sum comes out to $\frac{15}{34}$ or approximately .44, which is close, but not exact to the answer we'd expect above. Which is correct - or where is the mistake? An explanation of the discrepancy would be much appreciated. Thanks a lot.","A colleague and I are having a hard time figuring out this probability question and was wondering if anyone could provide an explanation / insight into it. The question is simple: what is the probability if you draw 2 cards at the same time (so without replacement) from a standard deck of 52, that one of those cards, or both, is a diamond? He mapped out all the possible outcomes and came to $\frac{7}{16}$, by writing out the following: DD DH DC DS HD HH HC HS SD SH SC SS CD CH CC CS Since 7 out of those 16 outcomes have a diamond in them, that is the probability. Trying mathematically though, the answer is not equivalent. We both believe that the formula is not right, but we can't figure out where the problem is. This is the formula we've tried: $\displaystyle\frac{{13\choose{1}}{39\choose1}}{52\choose{2}}+\frac{13\choose2}{52\choose2}$; the left term is for 1 diamond, another card different, and the right term is for 2 diamonds. This sum comes out to $\frac{15}{34}$ or approximately .44, which is close, but not exact to the answer we'd expect above. Which is correct - or where is the mistake? An explanation of the discrepancy would be much appreciated. Thanks a lot.",,"['probability', 'card-games']"
94,Two players alternately flip a coin; what is the probability of winning by getting a head?,Two players alternately flip a coin; what is the probability of winning by getting a head?,,"Two players, $A$ and $B$, alternately and independently flip a coin and the first player to get a head wins. Assume player $A$ flips first.  If the coin is fair, what is the probability that $A$ wins? So $A$ only flips on odd tosses. So the probability of winning would be $$ P =\frac{1}{2}+\left(\frac{1}{2} \right)^{2} \frac{1}{2} + \cdots+ \left(\frac{1}{2} \right)^{2n} \frac{1}{2}$$ Is that right? It seems that if $A$ only flips on odd tosses, this shouldn't matter. Either $A$ can win on his first toss, his second toss, ...., or his $n^{th}$ toss. So the third flip of the coin is actually $A$'s second toss. So shouldn't it be $$P = \frac{1}{2} + \left(\frac{1}{2} \right)^{2} + \left(\frac{1}{2} \right)^{3} + \cdots$$","Two players, $A$ and $B$, alternately and independently flip a coin and the first player to get a head wins. Assume player $A$ flips first.  If the coin is fair, what is the probability that $A$ wins? So $A$ only flips on odd tosses. So the probability of winning would be $$ P =\frac{1}{2}+\left(\frac{1}{2} \right)^{2} \frac{1}{2} + \cdots+ \left(\frac{1}{2} \right)^{2n} \frac{1}{2}$$ Is that right? It seems that if $A$ only flips on odd tosses, this shouldn't matter. Either $A$ can win on his first toss, his second toss, ...., or his $n^{th}$ toss. So the third flip of the coin is actually $A$'s second toss. So shouldn't it be $$P = \frac{1}{2} + \left(\frac{1}{2} \right)^{2} + \left(\frac{1}{2} \right)^{3} + \cdots$$",,['probability']
95,Probability the three points on a circle will be on the same semi-circle [duplicate],Probability the three points on a circle will be on the same semi-circle [duplicate],,"This question already has answers here : Probability that n points on a circle are in one semicircle (6 answers) Closed 4 years ago . Three points are chosen at random on a circle. What is the probability that they are on the same semi circle? If I have two portions $x$ and $y$, then $x+y= \pi r$...if the projected angles are $c_1$ and $c_2$. then it will imply that $c_1+c_2=\pi$...I have assumed uniform distribtuion so that $f(c_1)=\frac{\pi}{2}$...to calculate $P(c_1+c_2= \pi)$ I have integrated $c_2$ from $0$ to $\pi-c_1$ and $c_1$ from $0$ to $\pi$..but not arriving at the answer of $\frac 3 4$","This question already has answers here : Probability that n points on a circle are in one semicircle (6 answers) Closed 4 years ago . Three points are chosen at random on a circle. What is the probability that they are on the same semi circle? If I have two portions $x$ and $y$, then $x+y= \pi r$...if the projected angles are $c_1$ and $c_2$. then it will imply that $c_1+c_2=\pi$...I have assumed uniform distribtuion so that $f(c_1)=\frac{\pi}{2}$...to calculate $P(c_1+c_2= \pi)$ I have integrated $c_2$ from $0$ to $\pi-c_1$ and $c_1$ from $0$ to $\pi$..but not arriving at the answer of $\frac 3 4$",,"['probability', 'uniform-distribution']"
96,Difference between Probability and Probability Density,Difference between Probability and Probability Density,,"This question is from DeGroot's ""Probability and Statistics"" : Unbounded p.d.f.’s. Since a value of a p.d.f.(probability density function) is a probability density, rather than a   probability, such a value can be larger than $1$. In fact, the values of the following   p.d.f. are unbounded in the neighborhood of $x = 0$:$$f(x) = \begin{cases} \frac{2}{3}x^{-\frac{1}{3}}  & \text{for 0<$x$<1,} \\ 0 & \text{otherwise.}  \\ \end{cases}$$ Now, I don't know how the p.d.f. can take value larger than $1$.Please let me know the difference between the probability and probability density.","This question is from DeGroot's ""Probability and Statistics"" : Unbounded p.d.f.’s. Since a value of a p.d.f.(probability density function) is a probability density, rather than a   probability, such a value can be larger than $1$. In fact, the values of the following   p.d.f. are unbounded in the neighborhood of $x = 0$:$$f(x) = \begin{cases} \frac{2}{3}x^{-\frac{1}{3}}  & \text{for 0<$x$<1,} \\ 0 & \text{otherwise.}  \\ \end{cases}$$ Now, I don't know how the p.d.f. can take value larger than $1$.Please let me know the difference between the probability and probability density.",,['probability']
97,Probability of the union of $3$ events?,Probability of the union of  events?,3,"I need some clarification for why the probability of the union of three events is equal to the right side in the following: $$P(E\cup F\cup G)=P(E)+P(F)+P(G)-P(E\cap F)-P(E\cap G)-P(F\cap G)+P(E\cap F\cap G)$$ What I don't understand is, why is the last term(intersection of all) added back just once, when it was subtracted three times as it appears from a Venn Diagram? Here on page 3, this is explained but not in enough details that I can understand it: http://www.math.dartmouth.edu/archive/m19w03/public_html/Section6-2.pdf","I need some clarification for why the probability of the union of three events is equal to the right side in the following: $$P(E\cup F\cup G)=P(E)+P(F)+P(G)-P(E\cap F)-P(E\cap G)-P(F\cap G)+P(E\cap F\cap G)$$ What I don't understand is, why is the last term(intersection of all) added back just once, when it was subtracted three times as it appears from a Venn Diagram? Here on page 3, this is explained but not in enough details that I can understand it: http://www.math.dartmouth.edu/archive/m19w03/public_html/Section6-2.pdf",,['probability']
98,Proof of the identity $2^n = \sum\limits_{k=0}^n 2^{-k} \binom{n+k}{k}$,Proof of the identity,2^n = \sum\limits_{k=0}^n 2^{-k} \binom{n+k}{k},"I just found this identity but without any proof, could you just give me an hint how I could prove it? $$2^n = \sum\limits_{k=0}^n 2^{-k} \cdot \binom{n+k}{k}$$ I know that $$2^n = \sum\limits_{k=0}^n \binom{n}{k}$$ but that didn't help me","I just found this identity but without any proof, could you just give me an hint how I could prove it? $$2^n = \sum\limits_{k=0}^n 2^{-k} \cdot \binom{n+k}{k}$$ I know that $$2^n = \sum\limits_{k=0}^n \binom{n}{k}$$ but that didn't help me",,"['probability', 'combinatorics', 'summation', 'binomial-coefficients']"
99,Why does the Cauchy distribution have no mean if it's symmetric around 0?,Why does the Cauchy distribution have no mean if it's symmetric around 0?,,"Something that didn't make intuitive sense to me when learning about the Cauchy distribution was that there was no defined mean for the function, even though the function was clearly centered at zero and equally valued in both directions. Is there any reason for this?","Something that didn't make intuitive sense to me when learning about the Cauchy distribution was that there was no defined mean for the function, even though the function was clearly centered at zero and equally valued in both directions. Is there any reason for this?",,"['probability', 'probability-distributions']"
