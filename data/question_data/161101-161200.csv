,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Examples of Calculations using Lebesgue Dominated Convergence,Examples of Calculations using Lebesgue Dominated Convergence,,"I came across the following problem in my self-study, and wanted to know how to use Lebesgue Dominated Convergence to compute any of the following limits: (a) $\lim\limits_{n \rightarrow \infty}$ $\int_0^\infty$ $(1+(x/n))^{-n} \sin (x/n)dx$ (b) $\lim\limits_{n \rightarrow \infty}$ $\int_0^1$ $(1+nx^{2})(1+x^2)^{-n}dx$ (c) $\lim\limits_{n \rightarrow \infty}$ $\int_0^\infty$ $n \sin (x/n) [x(1+x^2)]^{-1}dx$ Any help is greatly appreciated. Update: I think I have successfully worked out arguments for each of (a) and (b), so I am less concerned about answers/strategies to those parts. However, (c) seems more tricky than the others, so if anyone visiting today sees how to handle (c) (in particular, a nice-enough dominating function!), let me know as it would be greatly appreciated.","I came across the following problem in my self-study, and wanted to know how to use Lebesgue Dominated Convergence to compute any of the following limits: (a) $\lim\limits_{n \rightarrow \infty}$ $\int_0^\infty$ $(1+(x/n))^{-n} \sin (x/n)dx$ (b) $\lim\limits_{n \rightarrow \infty}$ $\int_0^1$ $(1+nx^{2})(1+x^2)^{-n}dx$ (c) $\lim\limits_{n \rightarrow \infty}$ $\int_0^\infty$ $n \sin (x/n) [x(1+x^2)]^{-1}dx$ Any help is greatly appreciated. Update: I think I have successfully worked out arguments for each of (a) and (b), so I am less concerned about answers/strategies to those parts. However, (c) seems more tricky than the others, so if anyone visiting today sees how to handle (c) (in particular, a nice-enough dominating function!), let me know as it would be greatly appreciated.",,['measure-theory']
1,$n^{2}\|f_n\|_2\le1$ implies $f_n\to0$ a.e.?,implies  a.e.?,n^{2}\|f_n\|_2\le1 f_n\to0,"Let $(X,\mathcal{M},\mu)$ be a $\sigma$ -finite measure space. Let $f_1, f_2, ... : X \to \mathbb{R}$ be measurable functions such that $n^{2}\|f_n\|_2\le1$ for every $n\ge1$ . Does it imply that $f_n\to0$ a.e. where $n\to\infty$ ? Since $f_n\to0$ in $L^2$ we know that there is a subsequence $\{f_{n_k}\}$ such that $f_{n_k}\to0$ a.e. Can't see how the fact that the measure is $\sigma$ -finite is helpful... So, I tried to disprove it using the ""typewriter sequence"": $X=[0,1]$ , $\mu=m$ Lebesgue measure. $f_n=\chi_{[j/2^{k},(j+1)/2^{k}]}$ where $n=2^{k}+ j$ with $0\le j<2^{k}$ . So $f_n\to0$ in $L^2$ and $\{f_n\}$ does not converge to $0$ for any point. But $k\approx\log_2{n}$ and $n^{2}\|f_n\|_2>1$ for every $n>1$ . I can choose a subsequence $\{f_{n_k}\}$ such that ${n_{k}}^{2}\|f_{n_k}\|_2\le1$ , but then this subsequence might converge to $0$ . Maybe some another variation of this sequence would work? Thanks!","Let be a -finite measure space. Let be measurable functions such that for every . Does it imply that a.e. where ? Since in we know that there is a subsequence such that a.e. Can't see how the fact that the measure is -finite is helpful... So, I tried to disprove it using the ""typewriter sequence"": , Lebesgue measure. where with . So in and does not converge to for any point. But and for every . I can choose a subsequence such that , but then this subsequence might converge to . Maybe some another variation of this sequence would work? Thanks!","(X,\mathcal{M},\mu) \sigma f_1, f_2, ... : X \to \mathbb{R} n^{2}\|f_n\|_2\le1 n\ge1 f_n\to0 n\to\infty f_n\to0 L^2 \{f_{n_k}\} f_{n_k}\to0 \sigma X=[0,1] \mu=m f_n=\chi_{[j/2^{k},(j+1)/2^{k}]} n=2^{k}+ j 0\le j<2^{k} f_n\to0 L^2 \{f_n\} 0 k\approx\log_2{n} n^{2}\|f_n\|_2>1 n>1 \{f_{n_k}\} {n_{k}}^{2}\|f_{n_k}\|_2\le1 0","['measure-theory', 'lp-spaces']"
2,Is a measure measurable?,Is a measure measurable?,,"This could totally be a stupid question but I'm unsure: is a measure (ie positive, countable additive on a $\sigma$ algebra, 0 for the empty set) actually a measurable function (wrt to the Borel-sigma algebra on $\mathbb{R}$ )?","This could totally be a stupid question but I'm unsure: is a measure (ie positive, countable additive on a algebra, 0 for the empty set) actually a measurable function (wrt to the Borel-sigma algebra on )?",\sigma \mathbb{R},"['measure-theory', 'borel-measures']"
3,"Do we need compactness hypothesis in Lemma 6.2 in Lee's ""Introduction to Smooth Manifolds""?","Do we need compactness hypothesis in Lemma 6.2 in Lee's ""Introduction to Smooth Manifolds""?",,"The following lemma is from Lee's "" Introduction to Smooth Manifolds ."" Lemma 6.2. Suppose $A\subseteq\mathbb R^n$ is a compact subset whose intersection with $\{c\}\times\mathbb R^{n-1}$ has $(n-1)$ -dimensional measure zero for every $c\in\mathbb R$ . Then $A$ has $n$ -dimensional measure zero. Do we need to hypothesize that $A$ is compact? I think the author included the compactness hypothesis so that the elementary proof (no measure theory) in the book will work. But if I prove the lemma using Tonelli's theorem, I think $A$ does not need to be compact: Let $\chi_A$ be the characteristic function of $A$ . We have to prove that $\int\chi_Adm^n=0$ . By Tonelli's theorem, $\int\chi_Adm^n=\int\left(\int(\chi_A)_cdm^{n-1}\right)dm(c)$ , where $(\chi_A)_c(x_2,\ldots,x_n)=(c,x_2,\ldots,x_n)$ . Since we are given that $\{c\}\times\mathbb R^{n-1}$ has $(n-1)$ -dimensional Lebesgue measure zero, it follows that $\int(\chi_A)_cdm^{n-1}=0$ for all $c\in\mathbb R$ . Thus $\int\chi_Adm^n=\int 0dm(c)=0$ . Am I right, or did I miss something?","The following lemma is from Lee's "" Introduction to Smooth Manifolds ."" Lemma 6.2. Suppose is a compact subset whose intersection with has -dimensional measure zero for every . Then has -dimensional measure zero. Do we need to hypothesize that is compact? I think the author included the compactness hypothesis so that the elementary proof (no measure theory) in the book will work. But if I prove the lemma using Tonelli's theorem, I think does not need to be compact: Let be the characteristic function of . We have to prove that . By Tonelli's theorem, , where . Since we are given that has -dimensional Lebesgue measure zero, it follows that for all . Thus . Am I right, or did I miss something?","A\subseteq\mathbb R^n \{c\}\times\mathbb R^{n-1} (n-1) c\in\mathbb R A n A A \chi_A A \int\chi_Adm^n=0 \int\chi_Adm^n=\int\left(\int(\chi_A)_cdm^{n-1}\right)dm(c) (\chi_A)_c(x_2,\ldots,x_n)=(c,x_2,\ldots,x_n) \{c\}\times\mathbb R^{n-1} (n-1) \int(\chi_A)_cdm^{n-1}=0 c\in\mathbb R \int\chi_Adm^n=\int 0dm(c)=0","['measure-theory', 'lebesgue-measure', 'smooth-manifolds', 'fubini-tonelli-theorems']"
4,Charcteristic function not in a fractional Sobolev space,Charcteristic function not in a fractional Sobolev space,,"I am trying to show that for any Lebesgue measurable set of finite positive measure $E$ , the characteristic function $\chi_E$ is not in $H^{\frac{1}{2}}(\mathbb{R}^n)$ . I found somewhere that it would be enough to show instead that $$ \int_{\mathbb{R}^n} \int_{\mathbb{R}^n} \frac{\vert \chi_E(x)-\chi_E(y) \vert^2}{\Vert x-y \Vert^{n+1}} dx dy $$ is infinite. I think that the numerator is simply the sum $$ \chi_{E\times E^c}(x,y)+\chi_{E^c\times E}(x,y) $$ which simplifies the problem to showing that $$ \int_{E} \int_{E^c} \frac{1}{\Vert x-y \Vert^{n+1}} dx dy + \int_{E^c} \int_{E} \frac{1}{\Vert x-y \Vert^{n+1}} dx dy $$ is infinite, and using Fubini, I think it is enough to show that the first term is infinite. However I am having trouble trying to simplify it further, and think that I should eventually use an integral of the form $\int_1^\infty \frac{1}{r^p}dr$ somehow. I would appreciate any hints or helpful remarks, including those telling me that this attempt is inherently flawed.","I am trying to show that for any Lebesgue measurable set of finite positive measure , the characteristic function is not in . I found somewhere that it would be enough to show instead that is infinite. I think that the numerator is simply the sum which simplifies the problem to showing that is infinite, and using Fubini, I think it is enough to show that the first term is infinite. However I am having trouble trying to simplify it further, and think that I should eventually use an integral of the form somehow. I would appreciate any hints or helpful remarks, including those telling me that this attempt is inherently flawed.","E \chi_E H^{\frac{1}{2}}(\mathbb{R}^n)  \int_{\mathbb{R}^n} \int_{\mathbb{R}^n} \frac{\vert \chi_E(x)-\chi_E(y) \vert^2}{\Vert x-y \Vert^{n+1}} dx dy   \chi_{E\times E^c}(x,y)+\chi_{E^c\times E}(x,y)   \int_{E} \int_{E^c} \frac{1}{\Vert x-y \Vert^{n+1}} dx dy + \int_{E^c} \int_{E} \frac{1}{\Vert x-y \Vert^{n+1}} dx dy  \int_1^\infty \frac{1}{r^p}dr","['measure-theory', 'change-of-variable', 'fractional-sobolev-spaces']"
5,Is Lebesgue outer measure continuous from above for sets with finite Lebesgue outer measure,Is Lebesgue outer measure continuous from above for sets with finite Lebesgue outer measure,,"Does there exist a decreasing sequence  of sets ($A_{n+1}\subseteq A_n$) ; $\{A_n\}$ of real numbers such that $m^*(A_n)<\infty , \forall n \in \mathbb N$ and $m^*(\cap_{n\in \mathbb N} A_n) < \lim_{n\to \infty} m^*(A_n)$ ? Here $m^*$ is the Lebesgue outer measure on real line","Does there exist a decreasing sequence  of sets ($A_{n+1}\subseteq A_n$) ; $\{A_n\}$ of real numbers such that $m^*(A_n)<\infty , \forall n \in \mathbb N$ and $m^*(\cap_{n\in \mathbb N} A_n) < \lim_{n\to \infty} m^*(A_n)$ ? Here $m^*$ is the Lebesgue outer measure on real line",,['measure-theory']
6,Show that the counting measure has no Lebesgue decomposition.,Show that the counting measure has no Lebesgue decomposition.,,"Let $m$ be the Lebesgue measure on $(0,1)$, and $\lambda$ the counting measure on $(0,1)$. I am trying to prove that there is no decomposition $$\lambda=\lambda_a+\lambda_s$$ where $\lambda_a$ is absolutely continuous with respect to $m$, and $\lambda_s$ is singular with respect to $m$. I am trying to show that the decomposition would give a contradiction, but I am stuck. Any idea? My attempt: We get $\lambda(E)=\lambda_s(E)$ for all countable sets $E$, so (maybe) this implies that $\lambda=\lambda_s$ and hence $\lambda\perp m$, which is false.","Let $m$ be the Lebesgue measure on $(0,1)$, and $\lambda$ the counting measure on $(0,1)$. I am trying to prove that there is no decomposition $$\lambda=\lambda_a+\lambda_s$$ where $\lambda_a$ is absolutely continuous with respect to $m$, and $\lambda_s$ is singular with respect to $m$. I am trying to show that the decomposition would give a contradiction, but I am stuck. Any idea? My attempt: We get $\lambda(E)=\lambda_s(E)$ for all countable sets $E$, so (maybe) this implies that $\lambda=\lambda_s$ and hence $\lambda\perp m$, which is false.",,['measure-theory']
7,Is the pull back of a generated $\sigma$-algebra itself a generated $\sigma$-algebra?,Is the pull back of a generated -algebra itself a generated -algebra?,\sigma \sigma,"Let $f : \Omega_{1} \rightarrow \Omega_{2}$ be a map from a measurable space $\Omega_{1}$ to another measurable spacce $(\Omega_{2},\mathcal{B})$, where $\mathcal{B}$ is the generated $\sigma$-algebra of some $\textbf{countable}$ collection of subsets of $\Omega_{2}$: $$\mathcal{B}=\sigma(\mathcal{C}),$$ where $\mathcal{C}$ is countable. Do we have that the pull-back $\sigma$-algebra on $\Omega_{1}$, $f^{-1}(\mathcal{B})$, also a generated-$\sigma$ algebra? I think that the answer should be yes and $f^{-1}(\mathcal{B})$ is generated by $f^{-1}(\mathcal{C})$ but I don't know how to prove this. Could anyone help on this? Thank you so much!","Let $f : \Omega_{1} \rightarrow \Omega_{2}$ be a map from a measurable space $\Omega_{1}$ to another measurable spacce $(\Omega_{2},\mathcal{B})$, where $\mathcal{B}$ is the generated $\sigma$-algebra of some $\textbf{countable}$ collection of subsets of $\Omega_{2}$: $$\mathcal{B}=\sigma(\mathcal{C}),$$ where $\mathcal{C}$ is countable. Do we have that the pull-back $\sigma$-algebra on $\Omega_{1}$, $f^{-1}(\mathcal{B})$, also a generated-$\sigma$ algebra? I think that the answer should be yes and $f^{-1}(\mathcal{B})$ is generated by $f^{-1}(\mathcal{C})$ but I don't know how to prove this. Could anyone help on this? Thank you so much!",,['measure-theory']
8,Smallest of sigma-algebra,Smallest of sigma-algebra,,"Can anyone show me how to solve this question extracted from Michael Taylor's book: If $\{\mathcal{F}_{\alpha} : \alpha \in A\}$ is the collection of all $\sigma$-algebras of subsets of $X$ that contain $\mathcal{C}$, show that $$\bigcap_{\alpha \in A} \mathcal{F}_{\alpha} = \mathcal{F}$$ is a $\sigma$-algebra of subsets of $X$, containing $\mathcal{C}$, and is in fact the smallest such $\sigma$-algebra. One says $\mathcal{F}$ is the $\sigma$-algebra generated by $\mathcal{C}$ and writes $\mathcal{F} = \sigma(\mathcal{C})$","Can anyone show me how to solve this question extracted from Michael Taylor's book: If $\{\mathcal{F}_{\alpha} : \alpha \in A\}$ is the collection of all $\sigma$-algebras of subsets of $X$ that contain $\mathcal{C}$, show that $$\bigcap_{\alpha \in A} \mathcal{F}_{\alpha} = \mathcal{F}$$ is a $\sigma$-algebra of subsets of $X$, containing $\mathcal{C}$, and is in fact the smallest such $\sigma$-algebra. One says $\mathcal{F}$ is the $\sigma$-algebra generated by $\mathcal{C}$ and writes $\mathcal{F} = \sigma(\mathcal{C})$",,['measure-theory']
9,"Revisiting a Lebesgue measure question involving a dense subset of R, translates of a measurable set, etc.","Revisiting a Lebesgue measure question involving a dense subset of R, translates of a measurable set, etc.",,"In a previous post I asked the following question: Let $\{b_n\}_{n=1}^\infty$ be a dense subset of $\mathbb{R}$ and let $D \subseteq \mathbb{R}$ be a measurable set such that $m(D \triangle (D + b_n))=0$ for all $n \in \mathbb{N}$ (here, the $\triangle$ denotes the symmetric difference of the two sets, $D+ b_n = \{d + b_n : d \in D\}$, and $m$ stands for the Lebesgue measure). Prove that $m(D)=0$ or $m(D^c)=0$ (here $D^c$ is the complement of $D$ in  $\mathbb{R}$). Robert Israel gave hints to one neat strategy for proving the above result. But now I want to see whether anyone visiting can prove the above result without using the Lebesgue density theorem. In particular, a fellow graduate student in my program suggested that the result follows via contradiction by making smart uses of an interesting result I asked about earlier today: Let $A$ be Lebesgue measurable, with $m(A)>0$ (here $m$ denotes the Lebesgue measure). Then for any $0<\rho<1$, there exists an open interval $I$ such that $m(A \cap I)> \rho \cdot m(I)$. While I am curious to see alternative strategies for proof, I would be particularly interested to see a proof using this last result, if anyone's game to try!","In a previous post I asked the following question: Let $\{b_n\}_{n=1}^\infty$ be a dense subset of $\mathbb{R}$ and let $D \subseteq \mathbb{R}$ be a measurable set such that $m(D \triangle (D + b_n))=0$ for all $n \in \mathbb{N}$ (here, the $\triangle$ denotes the symmetric difference of the two sets, $D+ b_n = \{d + b_n : d \in D\}$, and $m$ stands for the Lebesgue measure). Prove that $m(D)=0$ or $m(D^c)=0$ (here $D^c$ is the complement of $D$ in  $\mathbb{R}$). Robert Israel gave hints to one neat strategy for proving the above result. But now I want to see whether anyone visiting can prove the above result without using the Lebesgue density theorem. In particular, a fellow graduate student in my program suggested that the result follows via contradiction by making smart uses of an interesting result I asked about earlier today: Let $A$ be Lebesgue measurable, with $m(A)>0$ (here $m$ denotes the Lebesgue measure). Then for any $0<\rho<1$, there exists an open interval $I$ such that $m(A \cap I)> \rho \cdot m(I)$. While I am curious to see alternative strategies for proof, I would be particularly interested to see a proof using this last result, if anyone's game to try!",,['measure-theory']
10,Show that $\mu\left(\bigcup_{j=1}^{N}E_j\right) \geq \frac{1}{6}\sum_{j=1}^{N}\mu(E_j)$,Show that,\mu\left(\bigcup_{j=1}^{N}E_j\right) \geq \frac{1}{6}\sum_{j=1}^{N}\mu(E_j),"This came from an old qualification exam for measure theory: Suppose $(X,M,\mu)$ is a measure space and $E_1,\ldots, E_N\in M$ with $\mu(E_j\cap E_k)\leq \mu(E_j)/N$ for each $j\neq k$. Show that $$\mu\left(\bigcup_{j=1}^{N}E_j\right) \geq \frac{1}{6}\sum_{j=1}^{N}\mu(E_j)$$ Thoughts: I thought that for $E_1,\ldots,E_n\in M$ that $$\mu\left(\bigcup_{1}^{n}E_j\right)\leq \sum_{1}^{n}\mu(E_j)$$ when $E_j$'s are not disjoint. I know we can use the disjointification trick to get equality. I am not sure how to show the latter though. Any suggestions are greatly appreciated.","This came from an old qualification exam for measure theory: Suppose $(X,M,\mu)$ is a measure space and $E_1,\ldots, E_N\in M$ with $\mu(E_j\cap E_k)\leq \mu(E_j)/N$ for each $j\neq k$. Show that $$\mu\left(\bigcup_{j=1}^{N}E_j\right) \geq \frac{1}{6}\sum_{j=1}^{N}\mu(E_j)$$ Thoughts: I thought that for $E_1,\ldots,E_n\in M$ that $$\mu\left(\bigcup_{1}^{n}E_j\right)\leq \sum_{1}^{n}\mu(E_j)$$ when $E_j$'s are not disjoint. I know we can use the disjointification trick to get equality. I am not sure how to show the latter though. Any suggestions are greatly appreciated.",,['measure-theory']
11,The graph of every real function has inner measure zero,The graph of every real function has inner measure zero,,"I'm trying to understand the answer to this question : Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a (general) function. Is there an $N\subset \mathbb{R}^2$ with $\lambda^2(N)=0$ , such that $\{(x,f(x)):x\in \mathbb{R}\}$ $\subset N$ ? First line of the answer, found there : ""No function can have a graph with positive measure or even positive inner measure, since every function graph has uncountably many disjoint vertical translations, which cover the plane. "" I don't understand why the fact that ""every function graph has uncountably many disjoint vertical translations, which cover the plane"" (I agree with that) implies the desired result. Thank you for your help.","I'm trying to understand the answer to this question : Let be a (general) function. Is there an with , such that ? First line of the answer, found there : ""No function can have a graph with positive measure or even positive inner measure, since every function graph has uncountably many disjoint vertical translations, which cover the plane. "" I don't understand why the fact that ""every function graph has uncountably many disjoint vertical translations, which cover the plane"" (I agree with that) implies the desired result. Thank you for your help.","f:\mathbb{R} \rightarrow \mathbb{R} N\subset \mathbb{R}^2 \lambda^2(N)=0 \{(x,f(x)):x\in \mathbb{R}\} \subset N","['measure-theory', 'lebesgue-measure', 'proof-explanation']"
12,Proof outer measure satisfies monotonicity: $A \subseteq B \implies m^*(A) \leq m^*(B)$,Proof outer measure satisfies monotonicity:,A \subseteq B \implies m^*(A) \leq m^*(B),"Theorem: $$A \subseteq B \implies m^*(A) \leq m^*(B)$$ Proof Attempt: By definition, $m^*(B) = \inf\{\sum\limits_{k=1}^\infty |J_k||\{J_k\} \text{ is a cover of B }\}$, $m^*(A) = \inf\{\sum\limits_{k=1}^\infty |I_k||\{I_k\} \text{ is a cover of A }\}$ Then since $A \subset B \implies \bigcup_{k =1}^\infty I_k \subseteq \bigcup_{k=1}^\infty J_k$, then $\sum\limits_{k=1}^\infty |I_k| \leq \sum\limits_{k=1}^\infty |J_k|$, so we have $m^*(A) \leq m^*(B)$ Can someone check if everything checks out?","Theorem: $$A \subseteq B \implies m^*(A) \leq m^*(B)$$ Proof Attempt: By definition, $m^*(B) = \inf\{\sum\limits_{k=1}^\infty |J_k||\{J_k\} \text{ is a cover of B }\}$, $m^*(A) = \inf\{\sum\limits_{k=1}^\infty |I_k||\{I_k\} \text{ is a cover of A }\}$ Then since $A \subset B \implies \bigcup_{k =1}^\infty I_k \subseteq \bigcup_{k=1}^\infty J_k$, then $\sum\limits_{k=1}^\infty |I_k| \leq \sum\limits_{k=1}^\infty |J_k|$, so we have $m^*(A) \leq m^*(B)$ Can someone check if everything checks out?",,"['measure-theory', 'proof-verification', 'proof-writing', 'lebesgue-measure']"
13,question on equivalent ideas of absolute continuity of measures,question on equivalent ideas of absolute continuity of measures,,"The measure $\nu$ is absolute continuous with respect to $\mu$ if for each $A$, $\mu(A)=0$ implies $\nu(A)=0$ (indicated by $\nu \ll \mu$). There is an $\epsilon$-$\delta$ idea related to this definition: If $\nu$ is finite, then: $\nu \ll \mu$  $\iff$ for every $\epsilon$ there exist a $\delta$ satisfying $\nu(A)<\epsilon$, if $\mu(A)<\delta$ What is the necessity of finiteness of $\nu$? What happens if $\nu$ is not finite? Is there any example to show that $\epsilon$-$\delta$ definition does not hold if $\nu$ is infinite, even if $\nu\ll\mu$?","The measure $\nu$ is absolute continuous with respect to $\mu$ if for each $A$, $\mu(A)=0$ implies $\nu(A)=0$ (indicated by $\nu \ll \mu$). There is an $\epsilon$-$\delta$ idea related to this definition: If $\nu$ is finite, then: $\nu \ll \mu$  $\iff$ for every $\epsilon$ there exist a $\delta$ satisfying $\nu(A)<\epsilon$, if $\mu(A)<\delta$ What is the necessity of finiteness of $\nu$? What happens if $\nu$ is not finite? Is there any example to show that $\epsilon$-$\delta$ definition does not hold if $\nu$ is infinite, even if $\nu\ll\mu$?",,['measure-theory']
14,Product of measurable and integrable functions,Product of measurable and integrable functions,,"Let $(X,F,u)$ be a measure space and $f,g$ measurable functions. Show that if $f$ is integrable and $g$ is bounded and measurable, then $fg$ is integrable. $f$ is integrable (on a set $E$) means that $\int_E|f|d\mu<\infty$. And we want to show that $\int_E|fg|d\mu<\infty$. But if $|g(x)|<M$ for all $x$, then the function $|fg|$ is bounded from above by $M|f|$, so we have $$\int_E|fg|d\mu\leq\int_EM|f|=M\int_E|f|<\infty.$$ So we don't need the condition that $g$ is measurable, do we?","Let $(X,F,u)$ be a measure space and $f,g$ measurable functions. Show that if $f$ is integrable and $g$ is bounded and measurable, then $fg$ is integrable. $f$ is integrable (on a set $E$) means that $\int_E|f|d\mu<\infty$. And we want to show that $\int_E|fg|d\mu<\infty$. But if $|g(x)|<M$ for all $x$, then the function $|fg|$ is bounded from above by $M|f|$, so we have $$\int_E|fg|d\mu\leq\int_EM|f|=M\int_E|f|<\infty.$$ So we don't need the condition that $g$ is measurable, do we?",,"['measure-theory', 'lebesgue-integral']"
15,Limit of Lebesgue measure of interesection of a set $E$ with its translation,Limit of Lebesgue measure of interesection of a set  with its translation,E,Let $E$ be a Lebesgue measurable set in $\mathbb{R}$. Prove that $$\lim_{x\rightarrow 0} m(E\cap (E+x))=m(E).$$,Let $E$ be a Lebesgue measurable set in $\mathbb{R}$. Prove that $$\lim_{x\rightarrow 0} m(E\cap (E+x))=m(E).$$,,['measure-theory']
16,$\mu(E\setminus (E+x))=0$ for all $x\in\mathbb{R}$. Prove that $\mu(E)=0$ or $\mu(\mathbb{R}\setminus E)=0$,for all . Prove that  or,\mu(E\setminus (E+x))=0 x\in\mathbb{R} \mu(E)=0 \mu(\mathbb{R}\setminus E)=0,"I am preparing myself to the mini-exam in measure theory by solving problems from lecturer's notes and I have encountered some difficulties I cannot overcome. I would appreciate if you could solve the following (or if you could give me some huge hints at least): Let $\mu$ be the Lebesgue measure on $\mathbb{R}$ and let $E$ be a Borel subset of $\mathbb{R}$ such that $$\mu(E\setminus (E+x))=0$$ for any $x\in\mathbb{R}$, where $E+x=\{z+x\mid z\in E\}$. Prove that $\mu(E)=0$ or $\mu(\mathbb{R}\setminus E)=0$. I know that $\mu(E)=\mu(E+x)$ and I suppose I have to prove the statement by assuming the opposite, but I really do not know how. Thanks in advance!","I am preparing myself to the mini-exam in measure theory by solving problems from lecturer's notes and I have encountered some difficulties I cannot overcome. I would appreciate if you could solve the following (or if you could give me some huge hints at least): Let $\mu$ be the Lebesgue measure on $\mathbb{R}$ and let $E$ be a Borel subset of $\mathbb{R}$ such that $$\mu(E\setminus (E+x))=0$$ for any $x\in\mathbb{R}$, where $E+x=\{z+x\mid z\in E\}$. Prove that $\mu(E)=0$ or $\mu(\mathbb{R}\setminus E)=0$. I know that $\mu(E)=\mu(E+x)$ and I suppose I have to prove the statement by assuming the opposite, but I really do not know how. Thanks in advance!",,['measure-theory']
17,Is a probability measure on a compact space regular?,Is a probability measure on a compact space regular?,,"Let $X$ be a compact Hausdorff space. Let $\mu$ be a Borel, probability measure on $X$. Does it automatically follow that $\mu$ is regular? That is, for all Borel $E \subset X$, must we have $$\mu(E) = \inf \mu(U) = \sup \mu(K)$$ where the infimum is taken over open $U \supset E$ and the supremum is taken over compact $K \subset E$? I know this is true when $X$ is a metric space or, more generally, when every open subset of $X$ is $\sigma$-compact. I imagine this fails in general though. I have a proposed counterexample which is a long way from being complete, but I'll put it here anyway. Let $I$ be an uncountable index set. Denote the product of $I$ many copies of the discrete space $\{0,1\}$ by $2^I$ and give it the (compact) product topology. I would like to give $2^I$ it's ""product measure"" as well, but I don't understand products of infinite families of measure spaces. Luckily, $2^I$ is, in a natural way, a compact group, so we can use the Haar measure which does what I wanted the product measure to do. Let $E$ be the set of elements of $2^I$ with countable support. Issue 1: Is $E$ Borel? I don't see why it should be... Assuming $E$ is Borel, it must have measure zero. Consider the translates $$xE = \{ y \in 2^I : y_i = x_i \text{ for all but countably many } i \in I\}$$  of $E$. By choosing a sequence of points $x_1,x_2,x_3,\ldots \in X$ such that any two differ in uncountably many coordinates (this is possible), we see that the translates $x_1E,x_2E,x_3E,\ldots$ are disjoint. So, if $E$ had positive measure, we get that $\mu(x_1E \cup x_2E \cup \ldots) = \mu(E) + \mu(E) + \ldots = \infty$ by translation invariance of the measure. This contradicts $\mu(2^I) =1$. Now, I would like to use $E$ to contradict outer regularity. So how is it that one can find open $U \supset E$? For $F \subset I$ finite, let $U_F = \{x \in 2^I : x_i = 0 \text{ for all } i \in F\}$ (basic open set). I think essentially the only way to cover $E$ by an open set is to choose an uncountable family $F_j$ of disjoint finite subsets of $I$ and to consider $U = \bigcup_j U_{F_j}$. This covers $E$ since, if $x \in E$, then the support of $x$ is countable, so $x$ is nonzero on countably many of the $F_j$, so $x$ is zero on some particular $F_j$ and $x \in U$. Issue 2: Is it true that $U$ should have $\mu(U)=1$? For some reason I feel maybe it should. If both of the above issues are resolved, then $2^I$ is not regular since $\mu(E) = 0$ and $\inf \mu(U) = 1$.","Let $X$ be a compact Hausdorff space. Let $\mu$ be a Borel, probability measure on $X$. Does it automatically follow that $\mu$ is regular? That is, for all Borel $E \subset X$, must we have $$\mu(E) = \inf \mu(U) = \sup \mu(K)$$ where the infimum is taken over open $U \supset E$ and the supremum is taken over compact $K \subset E$? I know this is true when $X$ is a metric space or, more generally, when every open subset of $X$ is $\sigma$-compact. I imagine this fails in general though. I have a proposed counterexample which is a long way from being complete, but I'll put it here anyway. Let $I$ be an uncountable index set. Denote the product of $I$ many copies of the discrete space $\{0,1\}$ by $2^I$ and give it the (compact) product topology. I would like to give $2^I$ it's ""product measure"" as well, but I don't understand products of infinite families of measure spaces. Luckily, $2^I$ is, in a natural way, a compact group, so we can use the Haar measure which does what I wanted the product measure to do. Let $E$ be the set of elements of $2^I$ with countable support. Issue 1: Is $E$ Borel? I don't see why it should be... Assuming $E$ is Borel, it must have measure zero. Consider the translates $$xE = \{ y \in 2^I : y_i = x_i \text{ for all but countably many } i \in I\}$$  of $E$. By choosing a sequence of points $x_1,x_2,x_3,\ldots \in X$ such that any two differ in uncountably many coordinates (this is possible), we see that the translates $x_1E,x_2E,x_3E,\ldots$ are disjoint. So, if $E$ had positive measure, we get that $\mu(x_1E \cup x_2E \cup \ldots) = \mu(E) + \mu(E) + \ldots = \infty$ by translation invariance of the measure. This contradicts $\mu(2^I) =1$. Now, I would like to use $E$ to contradict outer regularity. So how is it that one can find open $U \supset E$? For $F \subset I$ finite, let $U_F = \{x \in 2^I : x_i = 0 \text{ for all } i \in F\}$ (basic open set). I think essentially the only way to cover $E$ by an open set is to choose an uncountable family $F_j$ of disjoint finite subsets of $I$ and to consider $U = \bigcup_j U_{F_j}$. This covers $E$ since, if $x \in E$, then the support of $x$ is countable, so $x$ is nonzero on countably many of the $F_j$, so $x$ is zero on some particular $F_j$ and $x \in U$. Issue 2: Is it true that $U$ should have $\mu(U)=1$? For some reason I feel maybe it should. If both of the above issues are resolved, then $2^I$ is not regular since $\mu(E) = 0$ and $\inf \mu(U) = 1$.",,['measure-theory']
18,"If A is a subset of R with Lebesgue measure > 0 then are there a,b such that the measure of $[a,b]\cap A$ is b-a?","If A is a subset of R with Lebesgue measure > 0 then are there a,b such that the measure of  is b-a?","[a,b]\cap A","If $A$ is a subset of $\mathbb{R}$ with Lebesgue measure strictly greater than $0$, does it follow then that are there $a$ and $b$ such that the measure of $[a,b]\cap A$ is $b-a$? Thank you.","If $A$ is a subset of $\mathbb{R}$ with Lebesgue measure strictly greater than $0$, does it follow then that are there $a$ and $b$ such that the measure of $[a,b]\cap A$ is $b-a$? Thank you.",,['measure-theory']
19,Defining a function without using Axiom of Choice,Defining a function without using Axiom of Choice,,"I have a situation where I do not know if I need the axiom of choice: Let $\mathcal{B}(\mathbb{R})$ be the collection of Borel measurable subsets of $\mathbb{R}$ . I have a (possibly non-Borel) subset $M \subseteq \mathbb{R}$ and a probability measure $P:\mathcal{B}(\mathbb{R})\rightarrow[0,1]$ with the property: $$ P(A)=P(B) \quad \forall A, B \in \mathcal{B}(\mathbb{R}) \mbox{ such that $M\cap A = M\cap B$}  \quad (Eq. 1)$$ So I can group all sets in $\mathcal{B}(\mathbb{R})$ into equivalence classes where $A$ and $B$ are equivalent if $M\cap A = M \cap B$ . I want to condense $P$ to a function $g$ on equivalence classes.  Specifically, define $$V = \{M\cap A: A \in \mathcal{B}(\mathbb{R})\}$$ Define $g:V\rightarrow[0,1]$ as follows:  For each $D \in V$ , I can choose an $A \in \mathbb{B}(\mathbb{R})$ such that $M \cap A = D$ , then I can define $g(D)=P(A)$ . Formally, using the axiom of choice , there is a choice function $c:V\rightarrow \mathcal{B}(\mathbb{R})$ such that $$c(D)\in \{A\in \mathcal{B}(\mathbb{R}):M\cap A=D\} \quad \forall D \in V$$ Then I define $g(D)=P(c(D))$ . Notice by (Eq. 1) that this leads to the same $g$ function regardless of my choice function $c(D)$ .  In particular: $$g(M\cap A) = P(A) \quad \forall A \in \mathcal{B}(\mathbb{R}) \quad (Eq. 2)$$ Question: Do I really need to use the Axiom of Choice when defining this g function? I think that, due to (Eq. 2), I do not formally need the axiom of choice here. Perhaps I can simply define objects $(A,P[A])$ for all $A \in \mathcal{B}(\mathbb{R})$ and then simply ""say"" that I condense these objects according to equivalence classes, so that my function $g$ somehow emerges. However, it is often hard to know if I am inadvertently using the axiom of choice. Edit: I guess I could just define the set $\{(M\cap A, P[A]) : A \in \mathcal{B}(\mathbb{R})\}$ and $g$ emerges...?","I have a situation where I do not know if I need the axiom of choice: Let be the collection of Borel measurable subsets of . I have a (possibly non-Borel) subset and a probability measure with the property: So I can group all sets in into equivalence classes where and are equivalent if . I want to condense to a function on equivalence classes.  Specifically, define Define as follows:  For each , I can choose an such that , then I can define . Formally, using the axiom of choice , there is a choice function such that Then I define . Notice by (Eq. 1) that this leads to the same function regardless of my choice function .  In particular: Question: Do I really need to use the Axiom of Choice when defining this g function? I think that, due to (Eq. 2), I do not formally need the axiom of choice here. Perhaps I can simply define objects for all and then simply ""say"" that I condense these objects according to equivalence classes, so that my function somehow emerges. However, it is often hard to know if I am inadvertently using the axiom of choice. Edit: I guess I could just define the set and emerges...?","\mathcal{B}(\mathbb{R}) \mathbb{R} M \subseteq \mathbb{R} P:\mathcal{B}(\mathbb{R})\rightarrow[0,1]  P(A)=P(B) \quad \forall A, B \in \mathcal{B}(\mathbb{R}) \mbox{ such that M\cap A = M\cap B}  \quad (Eq. 1) \mathcal{B}(\mathbb{R}) A B M\cap A = M \cap B P g V = \{M\cap A: A \in \mathcal{B}(\mathbb{R})\} g:V\rightarrow[0,1] D \in V A \in \mathbb{B}(\mathbb{R}) M \cap A = D g(D)=P(A) c:V\rightarrow \mathcal{B}(\mathbb{R}) c(D)\in \{A\in \mathcal{B}(\mathbb{R}):M\cap A=D\} \quad \forall D \in V g(D)=P(c(D)) g c(D) g(M\cap A) = P(A) \quad \forall A \in \mathcal{B}(\mathbb{R}) \quad (Eq. 2) (A,P[A]) A \in \mathcal{B}(\mathbb{R}) g \{(M\cap A, P[A]) : A \in \mathcal{B}(\mathbb{R})\} g","['measure-theory', 'set-theory', 'axiom-of-choice']"
20,Every compact subset of $\mathbb R^1$ is the support of a Borel measure,Every compact subset of  is the support of a Borel measure,\mathbb R^1,"I know this already has an answer here , though it is very cryptic. So, I'm making this post for solution/proof-verification (it is not a duplicate) - I've come up with a measure on Borel sets of $\mathbb R$ corresponding to a compact set. Please help me fill in the gaps, if any. Prove that every compact subset of $\mathbb R^1$ is the support of a Borel measure. Here's my work: Suppose $A \subset \mathbb R$ is compact. Compact metric spaces are separable, so there exists a set $B = (b_n)_{n\in\mathbb N} \subset A$ which is dense in $A$ (i.e. $\overline B = A$ w.r.t. the subspace topology on $A$ ). Define $\mu$ on Borel sets of $\mathbb R$ as follows, where $\delta_p$ is the dirac measure at point $p\in\mathbb R$ . Note that $\delta_p(X) = 1$ if $p\in X$ and $\delta_p(X) = 0$ if $p\not\in X$ , for every $X\subset\mathbb R$ . Also we know that the support of $\delta_p$ is $\{p\}$ , and the support of a finite sum of measures is the (finite) union of their supports. If $C$ is a Borel set in $\mathbb R$ , $$\mu(C) = \sum_{n=1}^\infty \frac{\delta_{b_n}(C)}{2^n}$$ To check that $\mu$ is a measure, we need to show that $\mu$ is countably sub-additive. I think it suffices to notice the countable sub-additivity of Dirac measures. Unfortunately, I'm unable to characterize the support of $\mu$ , because it is only in the finite case that we are allowed to union over the supports. However, I do feel that the above construction suffices. Could I please get some help in completing my proof? Thank you! Follow-up questions: What is special about Borel sets in this construction? Can we define $\mu$ over a larger $\sigma$ -algebra? There must be something special about Borel sets, otherwise, the statement would probably not be framed this way. How do we deal with the case when $K = \varnothing$ ? What's the corresponding measure? If $B$ is finite, I think we cannot work with the finite sum. Instead, if we have distinct $b_1,b_2,\ldots,b_N$ , we can define $b_n := b_N$ for $n > N$ ? (See this link ). Please clarify. The book gives questions 11 and 12 together (image below for reference) - so are we supposed to use the definition of support from Q11 in Q12? Hopefully, it is equivalent to the one here .","I know this already has an answer here , though it is very cryptic. So, I'm making this post for solution/proof-verification (it is not a duplicate) - I've come up with a measure on Borel sets of corresponding to a compact set. Please help me fill in the gaps, if any. Prove that every compact subset of is the support of a Borel measure. Here's my work: Suppose is compact. Compact metric spaces are separable, so there exists a set which is dense in (i.e. w.r.t. the subspace topology on ). Define on Borel sets of as follows, where is the dirac measure at point . Note that if and if , for every . Also we know that the support of is , and the support of a finite sum of measures is the (finite) union of their supports. If is a Borel set in , To check that is a measure, we need to show that is countably sub-additive. I think it suffices to notice the countable sub-additivity of Dirac measures. Unfortunately, I'm unable to characterize the support of , because it is only in the finite case that we are allowed to union over the supports. However, I do feel that the above construction suffices. Could I please get some help in completing my proof? Thank you! Follow-up questions: What is special about Borel sets in this construction? Can we define over a larger -algebra? There must be something special about Borel sets, otherwise, the statement would probably not be framed this way. How do we deal with the case when ? What's the corresponding measure? If is finite, I think we cannot work with the finite sum. Instead, if we have distinct , we can define for ? (See this link ). Please clarify. The book gives questions 11 and 12 together (image below for reference) - so are we supposed to use the definition of support from Q11 in Q12? Hopefully, it is equivalent to the one here .","\mathbb R \mathbb R^1 A \subset \mathbb R B = (b_n)_{n\in\mathbb N} \subset A A \overline B = A A \mu \mathbb R \delta_p p\in\mathbb R \delta_p(X) = 1 p\in X \delta_p(X) = 0 p\not\in X X\subset\mathbb R \delta_p \{p\} C \mathbb R \mu(C) = \sum_{n=1}^\infty \frac{\delta_{b_n}(C)}{2^n} \mu \mu \mu \mu \sigma K = \varnothing B b_1,b_2,\ldots,b_N b_n := b_N n > N","['measure-theory', 'solution-verification', 'compactness', 'borel-sets', 'borel-measures']"
21,Levy-Ito decomposition intuition,Levy-Ito decomposition intuition,,"So a Levy process $(X_t)_{t\geq0}$ can be decomposed into three parts $$X_t = \mu t + \sigma^2B_t + L_\nu(t)$$ where $L_\nu(t)$ is ""a compound Poisson process with Levy measure $\nu$ "". I know the Levy measure of a set $A$ is the expected number of steps of $X_t$ having step size in $A$ in a time interval t. I.e. $\nu(A) = \mathbb{E}[N(1,A)]$ where $N(t,A)$ is the Poisson random measure of a set of counts $A$ in a time interval $t$ . In the paper I'm looking at, $$L_\nu(t) = \int_{|h|>1} h N_\nu (t,dh) + \int_{|h|\leq 1} h \big(N_\nu(t,dh) - t\nu(dh)\big).$$ I understand the first two terms of the decomposition, linear drift and Brownian motion, but not the third. Roughly, the third component seems to contribute information about how fast the process is moving. But I don't understand the details -- like, why are we adding $L_\nu(t)$ rather than scaling somehow? And why are we integrating over $h$ in this way?","So a Levy process can be decomposed into three parts where is ""a compound Poisson process with Levy measure "". I know the Levy measure of a set is the expected number of steps of having step size in in a time interval t. I.e. where is the Poisson random measure of a set of counts in a time interval . In the paper I'm looking at, I understand the first two terms of the decomposition, linear drift and Brownian motion, but not the third. Roughly, the third component seems to contribute information about how fast the process is moving. But I don't understand the details -- like, why are we adding rather than scaling somehow? And why are we integrating over in this way?","(X_t)_{t\geq0} X_t = \mu t + \sigma^2B_t + L_\nu(t) L_\nu(t) \nu A X_t A \nu(A) = \mathbb{E}[N(1,A)] N(t,A) A t L_\nu(t) = \int_{|h|>1} h N_\nu (t,dh) + \int_{|h|\leq 1} h \big(N_\nu(t,dh) - t\nu(dh)\big). L_\nu(t) h","['measure-theory', 'stochastic-processes', 'brownian-motion', 'stochastic-integrals']"
22,Why the Fubini theorem fail??,Why the Fubini theorem fail??,,"Let $f(x,y)=\dfrac{x^2-y^2}{(x^2+y^2)^2}$ prove: $$\int_0^1\left(\int_0^1f(x,y)dy\right)dx=\frac{\pi}{4}\tag1$$ $$\int_0^1\left(\int_0^1f(x,y)dx\right)dy=\frac{-\pi}{4}\tag2$$ Why the Fubini theorem fail?? My attempt: For $(1)$ we have: $$\int_0^1\left(\int_0^1f(x,y)dy\right)dx=\int\int\frac{\partial}{\partial y}\left(\frac{y}{x^2+y^2}\right)=\int \frac{y}{x^2+y^2}\bigg|_{y = 0}^{y = 1}dx=\int\frac{1}{x^2+1}dx= \\ =\arctan(x)\bigg|_0^1=\frac{\pi}{4}$$ For $(2)$ we have: $$\int_0^1\left(\int_0^1f(x,y)dx\right)dy=\int\int\frac{\partial}{\partial x}\left(\frac{-x}{x^2+y^2}\right)dxdy=-\int_0^1\frac{1}{1+y^2}dy=-\frac{\pi}{4}$$ I don't have very clear why Fubini Theorem fail. Can someone help me? https://en.wikipedia.org/wiki/Fubini%27s_theorem (Fubini-Tonelli Theorem)",Let prove: Why the Fubini theorem fail?? My attempt: For we have: For we have: I don't have very clear why Fubini Theorem fail. Can someone help me? https://en.wikipedia.org/wiki/Fubini%27s_theorem (Fubini-Tonelli Theorem),"f(x,y)=\dfrac{x^2-y^2}{(x^2+y^2)^2} \int_0^1\left(\int_0^1f(x,y)dy\right)dx=\frac{\pi}{4}\tag1 \int_0^1\left(\int_0^1f(x,y)dx\right)dy=\frac{-\pi}{4}\tag2 (1) \int_0^1\left(\int_0^1f(x,y)dy\right)dx=\int\int\frac{\partial}{\partial y}\left(\frac{y}{x^2+y^2}\right)=\int \frac{y}{x^2+y^2}\bigg|_{y = 0}^{y = 1}dx=\int\frac{1}{x^2+1}dx= \\ =\arctan(x)\bigg|_0^1=\frac{\pi}{4} (2) \int_0^1\left(\int_0^1f(x,y)dx\right)dy=\int\int\frac{\partial}{\partial x}\left(\frac{-x}{x^2+y^2}\right)dxdy=-\int_0^1\frac{1}{1+y^2}dy=-\frac{\pi}{4}",['measure-theory']
23,How should I study measure theory?,How should I study measure theory?,,"Im about to start studying measure theory on my own but I dont know what order I should follow, plus I dont know which textbook I should use.  Any ideas? I've already had a course on measure theory but it was kinda limited on the Lebesgue measure on the real numbers, integrals, $L^p(\mathbb{R})$ spaces etc; I'd like to study the more general measure theory. Also, any tips or advice for the subject would be appreciated","Im about to start studying measure theory on my own but I dont know what order I should follow, plus I dont know which textbook I should use.  Any ideas? I've already had a course on measure theory but it was kinda limited on the Lebesgue measure on the real numbers, integrals, $L^p(\mathbb{R})$ spaces etc; I'd like to study the more general measure theory. Also, any tips or advice for the subject would be appreciated",,"['measure-theory', 'soft-question', 'book-recommendation']"
24,Is a family of disjoints atoms in $\sigma$-finite neasurable space at most countable?,Is a family of disjoints atoms in -finite neasurable space at most countable?,\sigma,"Let   $\mu$ be a positive measure on a $\sigma$-algebra $S$ in $X$. A subset $A\subset X$ is called an atom if $\mu(A)>0$ and  for each $E\subset A$ is $\mu(E)=0$ or $\mu(E)=\mu(A)$. Let's assume that $\mu$ is $\sigma$-finite and consider a family  $\cal F$ of pairwise disjoint atoms in $(X, S, \mu)$. Is $\cal F$ at most countable? Remarks. Is it not true without $\sigma$-finitness of a measure, for example if $X$ is uncountable, $S=2^X$, $\mu(A)=+\infty$ if $A\neq \emptyset$, $\mu(\emptyset)=0$ and ${\cal F}= \{ \{x\}: x\in X \} $. It is true if $\mu $ is finite; in this case for each $c>0$ the family ${\cal F}_c=\{A\in {\cal F}: \mu(A)>c \}$ is finite and consequently $\cal F=\bigcup_{n\in \mathbb N} {\cal F}_{\frac{1}{n}}$ is at most countable.","Let   $\mu$ be a positive measure on a $\sigma$-algebra $S$ in $X$. A subset $A\subset X$ is called an atom if $\mu(A)>0$ and  for each $E\subset A$ is $\mu(E)=0$ or $\mu(E)=\mu(A)$. Let's assume that $\mu$ is $\sigma$-finite and consider a family  $\cal F$ of pairwise disjoint atoms in $(X, S, \mu)$. Is $\cal F$ at most countable? Remarks. Is it not true without $\sigma$-finitness of a measure, for example if $X$ is uncountable, $S=2^X$, $\mu(A)=+\infty$ if $A\neq \emptyset$, $\mu(\emptyset)=0$ and ${\cal F}= \{ \{x\}: x\in X \} $. It is true if $\mu $ is finite; in this case for each $c>0$ the family ${\cal F}_c=\{A\in {\cal F}: \mu(A)>c \}$ is finite and consequently $\cal F=\bigcup_{n\in \mathbb N} {\cal F}_{\frac{1}{n}}$ is at most countable.",,['measure-theory']
25,Subset $A\subset\mathbb R$ such that for any interval $I$ of length $a$ the set $A\cap I$ has Lebesgue measure $a/2$,Subset  such that for any interval  of length  the set  has Lebesgue measure,A\subset\mathbb R I a A\cap I a/2,Is there a subset $A\subset\mathbb R$ such that for any interval $I$ of length $a$ the set $A\cap I$ has lebesgue measure $a/2$? Can it be constructed explicitly?,Is there a subset $A\subset\mathbb R$ such that for any interval $I$ of length $a$ the set $A\cap I$ has lebesgue measure $a/2$? Can it be constructed explicitly?,,"['measure-theory', 'lebesgue-measure']"
26,Weak convergence vs Convergence in Measure,Weak convergence vs Convergence in Measure,,"What is the difference between weak convergence and convergence in measure? example let  $\mu_{n}\Rightarrow \mu$ on $[0,1]$ (the space where all measures are defined is $[0,1]$.) How does this contrast with the statement that we have a sample space $\Omega$ on which are defined random variables $X_{1},\ldots,$ which map $\Omega $ to $[0,1]$ and $X_{n}$ converges in measure to some random variable $X$.","What is the difference between weak convergence and convergence in measure? example let  $\mu_{n}\Rightarrow \mu$ on $[0,1]$ (the space where all measures are defined is $[0,1]$.) How does this contrast with the statement that we have a sample space $\Omega$ on which are defined random variables $X_{1},\ldots,$ which map $\Omega $ to $[0,1]$ and $X_{n}$ converges in measure to some random variable $X$.",,"['measure-theory', 'convergence-divergence', 'weak-convergence']"
27,Lebesgue Integration and non-measurable Sets,Lebesgue Integration and non-measurable Sets,,"All: Say $f$ is a measurable (integrable, actually) function over the Lebesgue-measurable set $S$, with $m(S)>0$. Now, since $m(S)>0$, there exists a non-measurable subset $S'$ of $S$, and we can then write: $$S=S'\cup (S\setminus S').$$ How would we then go about dealing with this (sorry, I don't know how to Tex an integral) $$\int_S f\,d\mu=\int_{S'} f\,d\mu+ \int_{S\setminus S'}f\,d\mu?$$ (given that $S'$ and $S\setminus S'$ are clearly disjoint) Doesn't this imply that the integral over the non-measurable subset S' can be defined? It also seems , using inner- and outer- measure, that if $S'$ is non-measurable, i.e. $m^*<m_*$, neither is $S\setminus S'$. So I'm confused here. Thanks for any comments. Edit: what confuses me here is this: We start with a set equality $A=B$  (given as $S=S'\cup (S-S')$, so that $A=S$, $B=S-S'$, from which we cannot conclude: $\int_A f=\int_B f$ , it is as if we had $x=y+z$ , but we cannot then conclude, for any decomposition of $x$, that $f(x)=f(y+z)$.","All: Say $f$ is a measurable (integrable, actually) function over the Lebesgue-measurable set $S$, with $m(S)>0$. Now, since $m(S)>0$, there exists a non-measurable subset $S'$ of $S$, and we can then write: $$S=S'\cup (S\setminus S').$$ How would we then go about dealing with this (sorry, I don't know how to Tex an integral) $$\int_S f\,d\mu=\int_{S'} f\,d\mu+ \int_{S\setminus S'}f\,d\mu?$$ (given that $S'$ and $S\setminus S'$ are clearly disjoint) Doesn't this imply that the integral over the non-measurable subset S' can be defined? It also seems , using inner- and outer- measure, that if $S'$ is non-measurable, i.e. $m^*<m_*$, neither is $S\setminus S'$. So I'm confused here. Thanks for any comments. Edit: what confuses me here is this: We start with a set equality $A=B$  (given as $S=S'\cup (S-S')$, so that $A=S$, $B=S-S'$, from which we cannot conclude: $\int_A f=\int_B f$ , it is as if we had $x=y+z$ , but we cannot then conclude, for any decomposition of $x$, that $f(x)=f(y+z)$.",,['measure-theory']
28,"$\int |f+g|^p \leq \int |f|^p + \int |g|^p$ for $p>0$ and $f, g \in L^p$?",for  and ?,"\int |f+g|^p \leq \int |f|^p + \int |g|^p p>0 f, g \in L^p","$(\Omega, \mathcal{F}, u)$ is a measure space, and $L^p(\Omega, \mathcal{F}, u)$ is its $L^p$ space. Define $N_p(f) = \int_{\Omega} |f|^p\, d\mu$. $\forall f, g \in L^p(\Omega, \mathcal{F}, u)$, when $0<p<1$, $N_p(f+g) \leq     N_p(f)+N_p(g) $ is true according to Wikipedia . This can help to show that     $L^p(\Omega, \mathcal{F}, u)$ is a vector space. I was wondering how to prove the inequality is true? when $p \geq 1$, is the inequality $N_p(f+g) \leq N_p(f)+N_p(g) $ still true? If not, (1) can the inequality be modified to be true? Note I am not asking about the triangle inequality of $L^p$ norm. (2) how can one show that $L^p(\Omega, \mathcal{F}, u)$ is a vector space? Thanks and regards!","$(\Omega, \mathcal{F}, u)$ is a measure space, and $L^p(\Omega, \mathcal{F}, u)$ is its $L^p$ space. Define $N_p(f) = \int_{\Omega} |f|^p\, d\mu$. $\forall f, g \in L^p(\Omega, \mathcal{F}, u)$, when $0<p<1$, $N_p(f+g) \leq     N_p(f)+N_p(g) $ is true according to Wikipedia . This can help to show that     $L^p(\Omega, \mathcal{F}, u)$ is a vector space. I was wondering how to prove the inequality is true? when $p \geq 1$, is the inequality $N_p(f+g) \leq N_p(f)+N_p(g) $ still true? If not, (1) can the inequality be modified to be true? Note I am not asking about the triangle inequality of $L^p$ norm. (2) how can one show that $L^p(\Omega, \mathcal{F}, u)$ is a vector space? Thanks and regards!",,['measure-theory']
29,An Application of Baire Category In Measure Theory?,An Application of Baire Category In Measure Theory?,,"Im currently working on Ergodic Theory by Einsiedler and Ward, and Im stuck at Exercise 2.7.1: Let $(X,\mathcal{B},\mu)$ be a measure space with $\mu(X)<\infty$ , and $T:X\to X$ be a measure-preserving transformation, that is, $\mu(A)=\mu(T^{-1}A)$ for all $A\in \mathcal{B}$ . If for any $A,B\in \mathcal{B}$ there exists $N\in \mathbb{N}$ such that \begin{equation} \mu(A\cap T^{-n} B)=\mu(A)\mu(B) \end{equation} holds for all $n\geq N$ , then it is trivial in the sense that $\mu(A)=0$ or $\mu(A)=1$ for any $A\in \mathcal{B}$ . At first I took $B\in \mathcal{B}$ such that $0<\mu(B)<1$ and tried to construct $A$ that violates the equation by using $T^{-n}B$ s, but it didnt work. Looking at the hint page, it says that such a set $A$ is obtained by applying Baire Category Theorem, but I have no ideas where to apply it. Would you please give me an extra hint?","Im currently working on Ergodic Theory by Einsiedler and Ward, and Im stuck at Exercise 2.7.1: Let be a measure space with , and be a measure-preserving transformation, that is, for all . If for any there exists such that holds for all , then it is trivial in the sense that or for any . At first I took such that and tried to construct that violates the equation by using s, but it didnt work. Looking at the hint page, it says that such a set is obtained by applying Baire Category Theorem, but I have no ideas where to apply it. Would you please give me an extra hint?","(X,\mathcal{B},\mu) \mu(X)<\infty T:X\to X \mu(A)=\mu(T^{-1}A) A\in \mathcal{B} A,B\in \mathcal{B} N\in \mathbb{N} \begin{equation}
\mu(A\cap T^{-n} B)=\mu(A)\mu(B)
\end{equation} n\geq N \mu(A)=0 \mu(A)=1 A\in \mathcal{B} B\in \mathcal{B} 0<\mu(B)<1 A T^{-n}B A","['measure-theory', 'ergodic-theory']"
30,What is the best way to study graduate level mathematics?,What is the best way to study graduate level mathematics?,,"I am studying a 400/500 level measure theory math book on my own. Right now, when I read it I try to read the proposition then the following proof. And then try to do the exercises on my own.  I wonder if I should change it to:- 1. read the proposition 2. try to prove it on my own. 3. If I could not then proceed to read the proof from the book. 4. Do the exercises. Or should I stick with everything above minus step 2. It can save me some time but I wonder if that is what good mathematics students do? Any feedback from your experience would be appreciated. Best,","I am studying a 400/500 level measure theory math book on my own. Right now, when I read it I try to read the proposition then the following proof. And then try to do the exercises on my own.  I wonder if I should change it to:- 1. read the proposition 2. try to prove it on my own. 3. If I could not then proceed to read the proof from the book. 4. Do the exercises. Or should I stick with everything above minus step 2. It can save me some time but I wonder if that is what good mathematics students do? Any feedback from your experience would be appreciated. Best,",,"['measure-theory', 'soft-question', 'self-learning', 'advice']"
31,Invariance for translations of the Lebesgue measure,Invariance for translations of the Lebesgue measure,,"Let $T\colon\mathbb{R}\to\mathbb{R}$ a linear trasformation of $\mathbb{R}$ defined as $Tx:=ax+b$ , where $a,b\in\mathbb{R}$ , $a\ne 0.$ We want to show the invariance for translations of the Lebesgue measure using the following result. Theorem. For all $E\subseteq\mathbb{R}$ we have $\lambda^*(T(E))=|a|\lambda^*(E);$ Notation. $\lambda^*$ is the Lebesgue outer measure, that is $$\lambda^*(E):=\inf\bigg\{\sum_{n=1}^{+\infty}\lambda_0(I_k)\;\bigg|\;\{I_n\}\subseteq\mathcal{I},E\subseteq\bigcup_{n=1}^{+\infty}I_n\bigg\},$$ where $\mathcal{I}$ is the algebra of plurintervals and $\lambda_0\colon\mathcal{I}\to [0,+\infty]$ is a measure definited as following: let $$\mathcal{I}_0=\{(a,b]\;|\;-\infty\le a\le b<+\infty)\}\cup\{(a,+\infty)\;|a\in\mathbb{R}\},$$ the family $\mathcal{I}$ consists of the finite disjoint unions of elements of $\mathcal{I}_0,$ then \begin{cases} \lambda_0(\emptyset):=0 \\ \lambda_0((a,b]):=b-a & \text{if $-\infty<a\le b<+\infty$}\\ \lambda_0((a,+\infty)):=+\infty &\text{if $a\in\mathbb{R}.$} \end{cases} Moreover, if $E\in\mathcal{I}\setminus\mathcal{I}_0$ $$\lambda_0(E):=\sum_{k=1}^{n}\lambda_0(E_k)$$ where $\{E_k\}_{k=1}^{n}\subseteq\mathcal{I}_0$ and $E=\bigcup_{k=1}^{n}E_k.$ $\mathcal{L}$ is the Lebesgue's $\sigma-$ algebra. Proof. We consider the linear transformations on $\mathbb{R}$ : $$T_1x:=\frac{a}{|a|}x,\quad T_2x:=|a|x,\quad T_3x:=x+b.$$ We observe that $T$ is the composition of $T_1,T_2$ and $T_3$ . In fact let $x\in\mathbb{R}$ , $$T_3T_2T_1x=T_3T_2\bigg(\frac{a}{|a|}x\bigg)=T_3(ax)=ax+b.$$ We start to prove that $\lambda^*(T_3(E))=\lambda^*(E).$ $(a)$ Let $\lambda^*(E)<+\infty.$ Then for $\varepsilon>0$ exists $\{I_k\}_{k\in\mathbb{N}}$ such that $$E\subseteq\bigcup_{k=1}^{+\infty} I_k\quad\lambda^*(E)+\varepsilon > \sum_{k=1}^{+\infty}\lambda_0(I_k).$$ Then $$T_3(E)\subseteq T_3\big(\bigcup_{k=1}^{+\infty} I_k\big)=\bigcup_{k=1}^{+\infty} T_3(I_k).$$ Therefore, $$\lambda^*(T_3(E))\le\sum_{k=1}^{+\infty}\lambda_0(T_3(I_k))\color{RED}{=}\sum_{k=1}^{+\infty}\lambda_0(I_k)<\lambda^*(E)+\varepsilon.$$ In the red equality we used the fact that for definition $\lambda_0$ is invariant for trasformation of type $T_3$ . Then for the arbitrariness of $\varepsilon$ we have that $\lambda^*(T_3(E))\le\lambda^*(E).$ Question 1. How can I show that $\lambda^*(T_3(E))\ge\lambda^*(E)$ ? $(b)$ Let $\lambda^*(E)=+\infty$ . We suppose for absurd that $\lambda^*(T_3(E))<+\infty$ , then exists $\{I'_k\}_{k\in\mathbb{N}}\subseteq\mathcal{I}$ such that $$T_3(E)\subseteq\bigcup_{k=1}^{+\infty}I'_k,\quad\sum_{k=1}^{+\infty}\lambda_0(I'_k)<\lambda^*(T_3(E))+\varepsilon<+\infty.$$ Since $E\subseteq\bigcup_{k=1}^{+\infty}\big[T_3^{-1}(I'_k)\big]$ we have $$\lambda^*(E)\le\sum_{k=1}^{+\infty}\lambda_0(T_3^{-1}(I'_k))\color{GREEN}{=}\sum_{k=1}^{+\infty}\lambda_0(I'_k)<+\infty,$$ absurd. Question 2. Why is the equality in green is valid? $$$$ Question 3. How can I formally show that $\lambda_0$ is invariant for transformations of the type $T_1, T_2, T_3$ ? In the same way it is shown that $\lambda^*(T_2(E))=|a|\lambda^*(E)$ and $\lambda^*(T_1(E))=\lambda^*(E).$ Therefore \begin{equation} \begin{split} \lambda^*(T(E))=&\lambda^*(T_3(T_2(T_1(E))\\ =&\lambda^*(T_2(T_1(E))\\ =&\lambda^*(T_1(E))\\ =&|a|\lambda^*(E) \end{split} \end{equation} Question 4. Is it true or false that $\lambda^*(T^{-1}(E))=|a|\lambda^*(E)$ ? How can I show it? My answer is false, but $$\lambda^*(E)=\lambda^*\big(T\big[T^{-1}(E)\big]\big)=|a|\lambda^*\big(T^{-1}\big(E\big)\big).$$ Therefore $\lambda^*\big(T^{-1}\big(E\big)\big)=\frac{1}{|a|}\lambda^*(E).$ Correct? Clarifications on the answer Thanks for the ansewer @    , but some doubts remain to me.  My book says to proceed this way $\lambda^*(T_1(E))=\lambda^*(E)$ , $\lambda^*(T_2(E))=|a|\lambda^*(E)$ , $\lambda^*(T_3(E))=\lambda^*(E).$ You explained to me that if $I\in\mathcal{I}$ , then $T_3(I)\in\mathcal{I}$ , moreover $\lambda_0$ is invariant under $T_3$ , then it is proved that $\lambda^*(T_3(E))\le\lambda^*(E),$ how can I show that $$\lambda^*(T_3(E))\ge\lambda^*(E)?$$ The same procedure can lead to show that $\lambda^*(T_2(E))=|a|\lambda^*(E)$ , with the necessary changes about $\lambda_0.$ Since $T_1(I)\notin\mathcal{I}$ , how can I show that $\lambda^*(T_1(E))=\lambda^*(E)?$ And finally how do I paste everything to show that $\lambda^*(T(E))=\lambda^*(E)$ ? Thanks! Thanks!","Let a linear trasformation of defined as , where , We want to show the invariance for translations of the Lebesgue measure using the following result. Theorem. For all we have Notation. is the Lebesgue outer measure, that is where is the algebra of plurintervals and is a measure definited as following: let the family consists of the finite disjoint unions of elements of then Moreover, if where and is the Lebesgue's algebra. Proof. We consider the linear transformations on : We observe that is the composition of and . In fact let , We start to prove that Let Then for exists such that Then Therefore, In the red equality we used the fact that for definition is invariant for trasformation of type . Then for the arbitrariness of we have that Question 1. How can I show that ? Let . We suppose for absurd that , then exists such that Since we have absurd. Question 2. Why is the equality in green is valid? Question 3. How can I formally show that is invariant for transformations of the type ? In the same way it is shown that and Therefore Question 4. Is it true or false that ? How can I show it? My answer is false, but Therefore Correct? Clarifications on the answer Thanks for the ansewer @    , but some doubts remain to me.  My book says to proceed this way , , You explained to me that if , then , moreover is invariant under , then it is proved that how can I show that The same procedure can lead to show that , with the necessary changes about Since , how can I show that And finally how do I paste everything to show that ? Thanks! Thanks!","T\colon\mathbb{R}\to\mathbb{R} \mathbb{R} Tx:=ax+b a,b\in\mathbb{R} a\ne 0. E\subseteq\mathbb{R} \lambda^*(T(E))=|a|\lambda^*(E); \lambda^* \lambda^*(E):=\inf\bigg\{\sum_{n=1}^{+\infty}\lambda_0(I_k)\;\bigg|\;\{I_n\}\subseteq\mathcal{I},E\subseteq\bigcup_{n=1}^{+\infty}I_n\bigg\}, \mathcal{I} \lambda_0\colon\mathcal{I}\to [0,+\infty] \mathcal{I}_0=\{(a,b]\;|\;-\infty\le a\le b<+\infty)\}\cup\{(a,+\infty)\;|a\in\mathbb{R}\}, \mathcal{I} \mathcal{I}_0, \begin{cases}
\lambda_0(\emptyset):=0 \\
\lambda_0((a,b]):=b-a & \text{if -\infty<a\le b<+\infty}\\
\lambda_0((a,+\infty)):=+\infty &\text{if a\in\mathbb{R}.}
\end{cases} E\in\mathcal{I}\setminus\mathcal{I}_0 \lambda_0(E):=\sum_{k=1}^{n}\lambda_0(E_k) \{E_k\}_{k=1}^{n}\subseteq\mathcal{I}_0 E=\bigcup_{k=1}^{n}E_k. \mathcal{L} \sigma- \mathbb{R} T_1x:=\frac{a}{|a|}x,\quad T_2x:=|a|x,\quad T_3x:=x+b. T T_1,T_2 T_3 x\in\mathbb{R} T_3T_2T_1x=T_3T_2\bigg(\frac{a}{|a|}x\bigg)=T_3(ax)=ax+b. \lambda^*(T_3(E))=\lambda^*(E). (a) \lambda^*(E)<+\infty. \varepsilon>0 \{I_k\}_{k\in\mathbb{N}} E\subseteq\bigcup_{k=1}^{+\infty} I_k\quad\lambda^*(E)+\varepsilon > \sum_{k=1}^{+\infty}\lambda_0(I_k). T_3(E)\subseteq T_3\big(\bigcup_{k=1}^{+\infty} I_k\big)=\bigcup_{k=1}^{+\infty} T_3(I_k). \lambda^*(T_3(E))\le\sum_{k=1}^{+\infty}\lambda_0(T_3(I_k))\color{RED}{=}\sum_{k=1}^{+\infty}\lambda_0(I_k)<\lambda^*(E)+\varepsilon. \lambda_0 T_3 \varepsilon \lambda^*(T_3(E))\le\lambda^*(E). \lambda^*(T_3(E))\ge\lambda^*(E) (b) \lambda^*(E)=+\infty \lambda^*(T_3(E))<+\infty \{I'_k\}_{k\in\mathbb{N}}\subseteq\mathcal{I} T_3(E)\subseteq\bigcup_{k=1}^{+\infty}I'_k,\quad\sum_{k=1}^{+\infty}\lambda_0(I'_k)<\lambda^*(T_3(E))+\varepsilon<+\infty. E\subseteq\bigcup_{k=1}^{+\infty}\big[T_3^{-1}(I'_k)\big] \lambda^*(E)\le\sum_{k=1}^{+\infty}\lambda_0(T_3^{-1}(I'_k))\color{GREEN}{=}\sum_{k=1}^{+\infty}\lambda_0(I'_k)<+\infty,  \lambda_0 T_1, T_2, T_3 \lambda^*(T_2(E))=|a|\lambda^*(E) \lambda^*(T_1(E))=\lambda^*(E). \begin{equation}
\begin{split}
\lambda^*(T(E))=&\lambda^*(T_3(T_2(T_1(E))\\
=&\lambda^*(T_2(T_1(E))\\
=&\lambda^*(T_1(E))\\
=&|a|\lambda^*(E)
\end{split}
\end{equation} \lambda^*(T^{-1}(E))=|a|\lambda^*(E) \lambda^*(E)=\lambda^*\big(T\big[T^{-1}(E)\big]\big)=|a|\lambda^*\big(T^{-1}\big(E\big)\big). \lambda^*\big(T^{-1}\big(E\big)\big)=\frac{1}{|a|}\lambda^*(E). \lambda^*(T_1(E))=\lambda^*(E) \lambda^*(T_2(E))=|a|\lambda^*(E) \lambda^*(T_3(E))=\lambda^*(E). I\in\mathcal{I} T_3(I)\in\mathcal{I} \lambda_0 T_3 \lambda^*(T_3(E))\le\lambda^*(E), \lambda^*(T_3(E))\ge\lambda^*(E)? \lambda^*(T_2(E))=|a|\lambda^*(E) \lambda_0. T_1(I)\notin\mathcal{I} \lambda^*(T_1(E))=\lambda^*(E)? \lambda^*(T(E))=\lambda^*(E)","['measure-theory', 'proof-explanation', 'lebesgue-measure']"
32,No mid points implies measure $0$,No mid points implies measure,0,"Let $E$ be a Lebesgue measurable set in $\mathbb R$ such that $x \in E, y\in E, x\neq y$ implies $\frac {x+y} 2 \notin E$. Show that $m(E)=0$ where $m$ is the Lebesgue measure on $\mathbb R$ I believe this result is interesting enough to the MSE community so I am posting the question as well as the answer. The proof may also benefit those who are beginning to learn measure theory.","Let $E$ be a Lebesgue measurable set in $\mathbb R$ such that $x \in E, y\in E, x\neq y$ implies $\frac {x+y} 2 \notin E$. Show that $m(E)=0$ where $m$ is the Lebesgue measure on $\mathbb R$ I believe this result is interesting enough to the MSE community so I am posting the question as well as the answer. The proof may also benefit those who are beginning to learn measure theory.",,['measure-theory']
33,measure theory for dummies,measure theory for dummies,,"Is there a book with simplest examples one can ever imagine? For example: ""Lets say we have ""tree"" ""apple"" ""1"" . . ."" What is sigma algebra of this set, what is sigma algebra generated by something in this set, what is borel sigma algebra etc. It would be awesome if book covered main topics in measure theory that are important to probability and stochastic processes. Do such books exist? For Aduh: Books i have read on measure theory use notation like this below. I want author instead  to explain intuition in simple way.","Is there a book with simplest examples one can ever imagine? For example: ""Lets say we have ""tree"" ""apple"" ""1"" . . ."" What is sigma algebra of this set, what is sigma algebra generated by something in this set, what is borel sigma algebra etc. It would be awesome if book covered main topics in measure theory that are important to probability and stochastic processes. Do such books exist? For Aduh: Books i have read on measure theory use notation like this below. I want author instead  to explain intuition in simple way.",,"['measure-theory', 'reference-request']"
34,"Let $\nu$ be a signed measure, then E is $\nu$-null iff $|\nu|(E)=0$","Let  be a signed measure, then E is -null iff",\nu \nu |\nu|(E)=0,"I am having trouble with understanding the proof of the forward direction. In all the proofs I have seen it's always the case that the following fact is implied. Taking a Hahn Decomposition $X=P\cup N$. $\nu(E)=0 \Rightarrow \nu(E\cap P)=0$ since $E\cap P\subset E$. However why is this true? An example, proving $E$ is $\nu$-null iff $|\nu| (E)=0$ . I can only deduce $0=\nu(E)=\nu(E\cap P)+\nu (E\cap N)$ and $\nu(E\cap P)\geq 0$ since it is a subset of P, but $\nu (E\cap N)$ could still be negative. Alternatively, are there any other proofs?","I am having trouble with understanding the proof of the forward direction. In all the proofs I have seen it's always the case that the following fact is implied. Taking a Hahn Decomposition $X=P\cup N$. $\nu(E)=0 \Rightarrow \nu(E\cap P)=0$ since $E\cap P\subset E$. However why is this true? An example, proving $E$ is $\nu$-null iff $|\nu| (E)=0$ . I can only deduce $0=\nu(E)=\nu(E\cap P)+\nu (E\cap N)$ and $\nu(E\cap P)\geq 0$ since it is a subset of P, but $\nu (E\cap N)$ could still be negative. Alternatively, are there any other proofs?",,['measure-theory']
35,Non-measurable sets on $\mathbb{N}$,Non-measurable sets on,\mathbb{N},"I'm familiar with the ""construction"" of non-measurable sets on $\mathbb{R}$. But of interest to me is if there is a way to construct a countably additive probability measure $\mu$ on $\mathbb{N}$ such that we can't extend $\mu$ to $2^{\mathbb{N}}$. Apparently there's no way to do it when $\mu$ is defined on all singletons, as for any set $S \subseteq \mathbb{N}$, we have \begin{align*} \mu(S) & = \sum_{k \in S} \mu( \{k \}) \\ & = \sum_{k = 1}^{\infty} \chi_{S} \mu( \{k\} ) \end{align*} Clearly we have that $\mu(\mathbb{N}) = \sum_{k = 1}^{\infty} \mu ( \{k\}) = 1$, so we know that $\lim_{N \to \infty} \sum_{k = N + 1}^{\infty} \mu( \{ k \} ) = 0$. But then we use this to show that $\mu(S)$ is well-defined, as the sum converges. Let $\epsilon > 0$, and let $N$ be large enough that $\sum_{k = N + 1}^{\infty} \mu( \{k \}) < \epsilon$. \begin{align*} \left| \left( \sum_{k \in S} \mu( \{k\}) \right) - \left( \sum_{k = 1}^{N} \mu( \{ k \} ) \right) \right| & = \left| \sum_{k = N + 1}^{\infty} \chi_{S} \mu(\{k\}) \right| \\ & \leq \sum_{k = 1}^{\infty} \| \chi_{S} \mu(\{k\}) \| \\ & \leq \sum_{k = N + 1}^{\infty} \mu( \{k\} ) \\ & < \epsilon . \end{align*} So is there a way to define a measure on $\mathbb{N}$ that is finite, but cannot be extended to measure the singletons? Is it possible if we drop the assumption that $\mu$ be finite? Can we show instead that any countably additive measure will extend to all of $2^{\mathbb{N}}$?","I'm familiar with the ""construction"" of non-measurable sets on $\mathbb{R}$. But of interest to me is if there is a way to construct a countably additive probability measure $\mu$ on $\mathbb{N}$ such that we can't extend $\mu$ to $2^{\mathbb{N}}$. Apparently there's no way to do it when $\mu$ is defined on all singletons, as for any set $S \subseteq \mathbb{N}$, we have \begin{align*} \mu(S) & = \sum_{k \in S} \mu( \{k \}) \\ & = \sum_{k = 1}^{\infty} \chi_{S} \mu( \{k\} ) \end{align*} Clearly we have that $\mu(\mathbb{N}) = \sum_{k = 1}^{\infty} \mu ( \{k\}) = 1$, so we know that $\lim_{N \to \infty} \sum_{k = N + 1}^{\infty} \mu( \{ k \} ) = 0$. But then we use this to show that $\mu(S)$ is well-defined, as the sum converges. Let $\epsilon > 0$, and let $N$ be large enough that $\sum_{k = N + 1}^{\infty} \mu( \{k \}) < \epsilon$. \begin{align*} \left| \left( \sum_{k \in S} \mu( \{k\}) \right) - \left( \sum_{k = 1}^{N} \mu( \{ k \} ) \right) \right| & = \left| \sum_{k = N + 1}^{\infty} \chi_{S} \mu(\{k\}) \right| \\ & \leq \sum_{k = 1}^{\infty} \| \chi_{S} \mu(\{k\}) \| \\ & \leq \sum_{k = N + 1}^{\infty} \mu( \{k\} ) \\ & < \epsilon . \end{align*} So is there a way to define a measure on $\mathbb{N}$ that is finite, but cannot be extended to measure the singletons? Is it possible if we drop the assumption that $\mu$ be finite? Can we show instead that any countably additive measure will extend to all of $2^{\mathbb{N}}$?",,"['measure-theory', 'examples-counterexamples']"
36,Finite measure space & sigma-finite measure space,Finite measure space & sigma-finite measure space,,"A measure space $(X, \Sigma, \mu)$ is finite if $\mu(X)<\infty$ . It is equivalent to saying that $(X, \Sigma, \mu)$ is finite if $\mu(E)<\infty$ for all $E \in \Sigma$ A measure space $(X, \Sigma, \mu)$ is $\sigma$ -finite if X is a countable union of sets with finite measure. Does $\sigma$ -finiteness imply that $\mu(E)<\infty$ for all $E \in \Sigma$ ? If $\mu(E)<\infty$ for all $E \in \Sigma$ , dose it imply $\sigma$ -finiteness or finiteness of a measure space?","A measure space is finite if . It is equivalent to saying that is finite if for all A measure space is -finite if X is a countable union of sets with finite measure. Does -finiteness imply that for all ? If for all , dose it imply -finiteness or finiteness of a measure space?","(X, \Sigma, \mu) \mu(X)<\infty (X, \Sigma, \mu) \mu(E)<\infty E \in \Sigma (X, \Sigma, \mu) \sigma \sigma \mu(E)<\infty E \in \Sigma \mu(E)<\infty E \in \Sigma \sigma","['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
37,Is there non Lebesgue measurable set in $I^2$ that its every section has measure $0$?,Is there non Lebesgue measurable set in  that its every section has measure ?,I^2 0,"As topic says, more precisely, is there set $E \subseteq [0,1]^2$ such that for every $(x,y) \in [0,1]^2$ sets $$E \cap ([0,1]\times \{y\}),  \;E \cap (\{x\} \times [0,1])$$ have measure zero in $\mathbb{R}$ but $E$ is not measureable in $\mathbb{R}^2$? I tried some sets as $V^2$ but it's clearly has measure zero, so $E$ should be more chaotic as set of $(x,y)$ s.t. $\frac{x}{y}\in \mathbb{Q}$. I think set of like this is should be candidate for answer of my question.","As topic says, more precisely, is there set $E \subseteq [0,1]^2$ such that for every $(x,y) \in [0,1]^2$ sets $$E \cap ([0,1]\times \{y\}),  \;E \cap (\{x\} \times [0,1])$$ have measure zero in $\mathbb{R}$ but $E$ is not measureable in $\mathbb{R}^2$? I tried some sets as $V^2$ but it's clearly has measure zero, so $E$ should be more chaotic as set of $(x,y)$ s.t. $\frac{x}{y}\in \mathbb{Q}$. I think set of like this is should be candidate for answer of my question.",,"['measure-theory', 'lebesgue-measure']"
38,Existence of minimal $\sigma$-algebra and transfinite induction,Existence of minimal -algebra and transfinite induction,\sigma,"It is well-known that: Given a set $X$ and a collection $\cal S$ of subsets of $X$, there exists a $\sigma$-algebra $\cal B$ containing $\cal S$, such that $\cal B$ is the smallest $\sigma$-algebra satisfying this condition. Certain texts, Lieb and Loss, Analysis , for instance, state that the proof of this assertion requires transfinite induction. On the other hand, one can define $\mathcal B$ to be the intersection of all $\sigma$-algebras containing $\cal S$. Which statement is correct? Or, is there a hidden transfinite induction contained somewhere? I must confess here that I have only vague ideaos of the rigorous set-theoretic foundations of mathematics.","It is well-known that: Given a set $X$ and a collection $\cal S$ of subsets of $X$, there exists a $\sigma$-algebra $\cal B$ containing $\cal S$, such that $\cal B$ is the smallest $\sigma$-algebra satisfying this condition. Certain texts, Lieb and Loss, Analysis , for instance, state that the proof of this assertion requires transfinite induction. On the other hand, one can define $\mathcal B$ to be the intersection of all $\sigma$-algebras containing $\cal S$. Which statement is correct? Or, is there a hidden transfinite induction contained somewhere? I must confess here that I have only vague ideaos of the rigorous set-theoretic foundations of mathematics.",,"['measure-theory', 'set-theory']"
39,Filter of Lebesgue measure one sets,Filter of Lebesgue measure one sets,,"I am reading lecture notes I borrowed from friend. It defines the filter of subsets of $[0,1]$ with Lebesgue measure $1$. Then it defines sets $A$ to be called $F$-stationary iff $A \cap Y \neq \varnothing$ for all $Y$ in the filter. Then it writes the $F$-stationary sets are the sets of positive outer measure. Why is it outer measure and not Lebesgue measure? And why is it true? Does it hold  that all subsets of $[0,1]$ with cardinality equal the cardinality of $[0,1]$ must have positive (outer or Lebesgue) measure?","I am reading lecture notes I borrowed from friend. It defines the filter of subsets of $[0,1]$ with Lebesgue measure $1$. Then it defines sets $A$ to be called $F$-stationary iff $A \cap Y \neq \varnothing$ for all $Y$ in the filter. Then it writes the $F$-stationary sets are the sets of positive outer measure. Why is it outer measure and not Lebesgue measure? And why is it true? Does it hold  that all subsets of $[0,1]$ with cardinality equal the cardinality of $[0,1]$ must have positive (outer or Lebesgue) measure?",,"['measure-theory', 'filters']"
40,Sigma field generated by a random variable!,Sigma field generated by a random variable!,,"Consider $A = \text{the sets of the form {X $\le$ x}}$. The goal is to prove that $\sigma(A) = \sigma(X)$. The question seems obvious to me but I just don't know how to prove it. I also have difficulty understanding the definition of $\sigma(X)$. Is $\sigma(X)$ defined as the sigma field generated by the sets that the random variable X refers to? if So, isn't it obvious that $\sigma(A) = \sigma(X)$ should be equal? I appreciate your help.","Consider $A = \text{the sets of the form {X $\le$ x}}$. The goal is to prove that $\sigma(A) = \sigma(X)$. The question seems obvious to me but I just don't know how to prove it. I also have difficulty understanding the definition of $\sigma(X)$. Is $\sigma(X)$ defined as the sigma field generated by the sets that the random variable X refers to? if So, isn't it obvious that $\sigma(A) = \sigma(X)$ should be equal? I appreciate your help.",,"['measure-theory', 'field-theory']"
41,Distribution Functions of Measures and Countable Sets,Distribution Functions of Measures and Countable Sets,,"Let $\mu$ be a continuous probability measure on $[0,1]$. Then, the function $g:[0,1] \to [0,1]$ defined by $g(x) = \mu([0,x])$ is called the distribution function of $\mu$. I have proved that $g$ is continuous and increasing, with $g(0)=0$ and $g(1)=1$. Moreover, for every $x \in [0,1]$, $g^{-1}(\{x\})$ is an interval which may be just a point. Define $A := \{x \in [0,1] : g^{-1}(\{x\})$ contains more than one point $\}$. I'm trying to prove that $A$ is countable, but it is giving me a hard time. My approach is to show that if $A$ is uncountable, then $g$ is not increasing. Any other ideas? I'm sure there is an easier way to prove this.","Let $\mu$ be a continuous probability measure on $[0,1]$. Then, the function $g:[0,1] \to [0,1]$ defined by $g(x) = \mu([0,x])$ is called the distribution function of $\mu$. I have proved that $g$ is continuous and increasing, with $g(0)=0$ and $g(1)=1$. Moreover, for every $x \in [0,1]$, $g^{-1}(\{x\})$ is an interval which may be just a point. Define $A := \{x \in [0,1] : g^{-1}(\{x\})$ contains more than one point $\}$. I'm trying to prove that $A$ is countable, but it is giving me a hard time. My approach is to show that if $A$ is uncountable, then $g$ is not increasing. Any other ideas? I'm sure there is an easier way to prove this.",,"['measure-theory', 'set-theory']"
42,Defining a measure as a supremum,Defining a measure as a supremum,,"Let $\Sigma$ be a $\sigma$-algebra over a set $X$, and $\mu_1$ and $\mu_2$ measures in it. It can be shown that $$ \begin{align} \mu_\sup: &\Sigma \to [0,\infty]\\ &E \mapsto \sup_{F \in \Sigma}\, \{\mu_1 (E \cap F) + \mu_2 (E\setminus F)\} \end{align}$$ is a measure. How do I show that it's the smallest measure $\mu$ with domain $\Sigma$ such that $\mu\geq\max\{\mu_1, \mu_2\}$?","Let $\Sigma$ be a $\sigma$-algebra over a set $X$, and $\mu_1$ and $\mu_2$ measures in it. It can be shown that $$ \begin{align} \mu_\sup: &\Sigma \to [0,\infty]\\ &E \mapsto \sup_{F \in \Sigma}\, \{\mu_1 (E \cap F) + \mu_2 (E\setminus F)\} \end{align}$$ is a measure. How do I show that it's the smallest measure $\mu$ with domain $\Sigma$ such that $\mu\geq\max\{\mu_1, \mu_2\}$?",,['measure-theory']
43,Inverse images and $\sigma$-algebras,Inverse images and -algebras,\sigma,"Let $\Sigma$ be a $\sigma$-algebra over $\mathbb R$ and $\mathcal A \subset \mathcal P(\mathbb R)$. Let also $f: \mathbb R \to \mathbb R$ be any function. If $\mathcal A$ generates $\Sigma$, is it true that $\widetilde{f^{-1}}(\mathcal A)$ generates $\widetilde{f^{-1}}(\Sigma)$? That is, do these symbols commute: $$\sigma(\widetilde{f^{-1}}(\mathcal A)) = \widetilde{f^{-1}}(\sigma(\mathcal A))\quad?$$","Let $\Sigma$ be a $\sigma$-algebra over $\mathbb R$ and $\mathcal A \subset \mathcal P(\mathbb R)$. Let also $f: \mathbb R \to \mathbb R$ be any function. If $\mathcal A$ generates $\Sigma$, is it true that $\widetilde{f^{-1}}(\mathcal A)$ generates $\widetilde{f^{-1}}(\Sigma)$? That is, do these symbols commute: $$\sigma(\widetilde{f^{-1}}(\mathcal A)) = \widetilde{f^{-1}}(\sigma(\mathcal A))\quad?$$",,['measure-theory']
44,Is there a measurable set $A$ such that $m(A \cap B) = \frac12 m(B)$ for every open set $B$?,Is there a measurable set  such that  for every open set ?,A m(A \cap B) = \frac12 m(B) B,Is there a measurable set $A$ such that $m(A \cap B)= \frac12 m(B)$ for every open set $B$? Edit: (t.b.) See also A Lebesgue measure question for further answers.,Is there a measurable set $A$ such that $m(A \cap B)= \frac12 m(B)$ for every open set $B$? Edit: (t.b.) See also A Lebesgue measure question for further answers.,,['measure-theory']
45,"$\int_0^1 x^n f(x)\,\mathrm{d}x = 0$ for all $n$ implies $f=0$ almost everywhere",for all  implies  almost everywhere,"\int_0^1 x^n f(x)\,\mathrm{d}x = 0 n f=0","It has been shown that given $f \in \mathcal C[0,1]$ , we have that if $\int_0^1 x^nf(x)\,dx = 0$ for all $n \in \mathbb N$ , then $f = 0$ . I was thinking of generalizing this statement to $L^p$ spaces. For instance, if we have that $f \in L^\infty[0,1]$ instead, and $\int_0^1 x^nf(x)\,dx = 0$ for all $n \in \mathbb N$ . Can we say that $f = 0$ a.e on $[0,1]$ ? That is, if $f$ is measurable on $[0,1]$ , with $\|f\|_\infty = \inf\{a \geq 0 \mid \lambda(|f|^{-1}(a,\infty]) = 0\} < \infty$ given $|f|^{-1}(a,\infty] = \{x \in [0,1] \mid |f(x)| > a\}$ , can we show that $f = 0$ for all points in $[0,1]$ except some set $B$ where $\lambda(B) = 0$ ? In this case, we use $\lambda$ to denote the Lebesgue measure.","It has been shown that given , we have that if for all , then . I was thinking of generalizing this statement to spaces. For instance, if we have that instead, and for all . Can we say that a.e on ? That is, if is measurable on , with given , can we show that for all points in except some set where ? In this case, we use to denote the Lebesgue measure.","f \in \mathcal C[0,1] \int_0^1 x^nf(x)\,dx = 0 n \in \mathbb N f = 0 L^p f \in L^\infty[0,1] \int_0^1 x^nf(x)\,dx = 0 n \in \mathbb N f = 0 [0,1] f [0,1] \|f\|_\infty = \inf\{a \geq 0 \mid \lambda(|f|^{-1}(a,\infty]) = 0\} < \infty |f|^{-1}(a,\infty] = \{x \in [0,1] \mid |f(x)| > a\} f = 0 [0,1] B \lambda(B) = 0 \lambda","['measure-theory', 'lebesgue-measure', 'measurable-functions']"
46,Hoeffding's lemma: hard to prove,Hoeffding's lemma: hard to prove,,"This is a continuation of another post . Let $F$ be the joint distribution function and $F_X,F_Y$ the marginal distribution function of the random variables $X,Y$ respectively. Let $(X,Y), (X_2,Y_2)$ be independent and distributed according to $F$ . Assume $E\mid XY\mid, E\mid X \mid, E\mid Y \mid$ finite. Then \begin{align} &E\bigg\{\int\int\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]dxdy\bigg\}\\ &=2\int\int F_{X,Y}(x,y)-F_X(x)F_Y(y)dxdy \end{align} where $I$ is the indicator function. My attempt There are two challenging steps for me. Firstly, I think I have to show that I can put the expectation inside the integrals using Fubini-Tonelli's theorem. Unfortunately I'm struggling to deal with it. Well, I know that the integrand is a (measurable) function of the random variables $X,Y,X_2$ and $Y_2$ . So I saw the $L.H.S.$ of the above equality as $$\int_{\mathbb{R}^4}\int\int\Big[I(x_1\leq x)-I(x_2\leq x)\Big]\Big[I(y_1\leq y)-I(y_2\leq y)\Big]dxdy P_{X,Y,X_2,Y_2}(dx_1dy_1dx_2dy_2)$$ I don't know if this allows me to interchange the integrals to obtain \begin{align} &\int\int\ E\bigg\{\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]\bigg\}dxdy\\ \end{align} If everything is alright so far, then I need to show that $E\bigg\{\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]\bigg\}=2Cov(I(X\leq x),I(Y\leq y))$ , and the rest becomes straighforward to me. Thus I need to show (i) the independence of $I(X_2\leq x)\perp I(Y\leq y)$ and $I(X\leq x)\perp I(Y_2\leq y)$ given $X_2\perp Y$ and $X\perp Y_2$ ; and (ii) $E(I(Y\leq y))=E(I(Y_2\leq y))$ which is easy, and that $Cov(I(X\leq x),I(Y\leq y))=Cov(I(X_2\leq x),I(Y_2\leq y))$ . I wonder if you can help me with it. UPDATE Since $X$ is independent of $Y_2$ , by definition, $\sigma(X)=\{X^{-1}(B):B\in \mathcal{B}_\mathbb{R}\}$ and $\sigma(Y_2)$ are independent, meaning that $P(A\cap B)=P(A)P(B), \ \forall A\in \sigma(Y_2), B\in \sigma(X)$ . Since $f=I_{(-\infty,x]}$ and $g=I_{(-\infty,y]}$ are $(\mathbb{R},\mathcal{B}_\mathbb{R})-(\mathbb{R},\mathcal{B}_\mathbb{R})$ measurable functions, then $(f\circ X)^{-1}=X^{-1}(f^{-1}(A))\in \sigma(X), \forall A\in \mathcal{B}_\mathbb{R}$ . The same holds for $g\circ Y_2$ . It implies $\sigma(f\circ X)\subseteq \sigma(X)$ and $\sigma(g\circ Y_2)\subseteq \sigma(Y_2)$ . Hence $\sigma(f\circ X)$ and $\sigma(g\circ Y_2)$ are also independent. That is the indicator functions (measurable) preserve the independence of the random variables. Exploring one of the answers below, let $f,b:\mathbb{R}\rightarrow\mathbb{R}$ measurable functions (like the indicator functions I am interested in). Then $F_{f\circ X, g\circ Y}(x_1,y_1)=P\{f(X)\leq x_1, g(Y)\leq y_1\}=P(X\in f^{-1}(-\infty,x_1], Y\in g^{-1}(-\infty,y_1])=P_{XY}(f^{-1}(-\infty,x_1]\times g^{-1}(-\infty,y_1])=P_{X_2Y_2}(f^{-1}(-\infty,x_1]\times g^{-1}(-\infty,y_1])=F_{f\circ X_2, g\circ Y_2}(x_1,y_1)$ . This immediately implies $Cov(f\circ X_2, g\circ Y_2)=Cov(f\circ X, g\circ Y)$ . Just put $f=I_{(-\infty,x]}$ and $g=I_{(-\infty,y]}$ . Finally, it is clear that the marginal probability distributions must be the same ( $P_X=P_{X_2}$ ), by assumption. Therefore, $E(f\circ X)=\int_{\Omega} (f\circ X)(z) P(dz)=\int_{\mathbb{R}} f(w) P_X(dw)=\int_{\mathbb{R}} f(w) P_{X_2}(dw)=E(f\circ X_2)$ , since $f$ is nonnegative measurable function (the indicator function)[see the Corollary 5.5.1, Resnick, A probability path, p. 138].","This is a continuation of another post . Let be the joint distribution function and the marginal distribution function of the random variables respectively. Let be independent and distributed according to . Assume finite. Then where is the indicator function. My attempt There are two challenging steps for me. Firstly, I think I have to show that I can put the expectation inside the integrals using Fubini-Tonelli's theorem. Unfortunately I'm struggling to deal with it. Well, I know that the integrand is a (measurable) function of the random variables and . So I saw the of the above equality as I don't know if this allows me to interchange the integrals to obtain If everything is alright so far, then I need to show that , and the rest becomes straighforward to me. Thus I need to show (i) the independence of and given and ; and (ii) which is easy, and that . I wonder if you can help me with it. UPDATE Since is independent of , by definition, and are independent, meaning that . Since and are measurable functions, then . The same holds for . It implies and . Hence and are also independent. That is the indicator functions (measurable) preserve the independence of the random variables. Exploring one of the answers below, let measurable functions (like the indicator functions I am interested in). Then . This immediately implies . Just put and . Finally, it is clear that the marginal probability distributions must be the same ( ), by assumption. Therefore, , since is nonnegative measurable function (the indicator function)[see the Corollary 5.5.1, Resnick, A probability path, p. 138].","F F_X,F_Y X,Y (X,Y), (X_2,Y_2) F E\mid XY\mid, E\mid X \mid, E\mid Y \mid \begin{align}
&E\bigg\{\int\int\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]dxdy\bigg\}\\
&=2\int\int F_{X,Y}(x,y)-F_X(x)F_Y(y)dxdy
\end{align} I X,Y,X_2 Y_2 L.H.S. \int_{\mathbb{R}^4}\int\int\Big[I(x_1\leq x)-I(x_2\leq x)\Big]\Big[I(y_1\leq y)-I(y_2\leq y)\Big]dxdy P_{X,Y,X_2,Y_2}(dx_1dy_1dx_2dy_2) \begin{align}
&\int\int\ E\bigg\{\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]\bigg\}dxdy\\
\end{align} E\bigg\{\Big[I(X\leq x)-I(X_2\leq x)\Big]\Big[I(Y\leq y)-I(Y_2\leq y)\Big]\bigg\}=2Cov(I(X\leq x),I(Y\leq y)) I(X_2\leq x)\perp I(Y\leq y) I(X\leq x)\perp I(Y_2\leq y) X_2\perp Y X\perp Y_2 E(I(Y\leq y))=E(I(Y_2\leq y)) Cov(I(X\leq x),I(Y\leq y))=Cov(I(X_2\leq x),I(Y_2\leq y)) X Y_2 \sigma(X)=\{X^{-1}(B):B\in \mathcal{B}_\mathbb{R}\} \sigma(Y_2) P(A\cap B)=P(A)P(B), \ \forall A\in \sigma(Y_2), B\in \sigma(X) f=I_{(-\infty,x]} g=I_{(-\infty,y]} (\mathbb{R},\mathcal{B}_\mathbb{R})-(\mathbb{R},\mathcal{B}_\mathbb{R}) (f\circ X)^{-1}=X^{-1}(f^{-1}(A))\in \sigma(X), \forall A\in \mathcal{B}_\mathbb{R} g\circ Y_2 \sigma(f\circ X)\subseteq \sigma(X) \sigma(g\circ Y_2)\subseteq \sigma(Y_2) \sigma(f\circ X) \sigma(g\circ Y_2) f,b:\mathbb{R}\rightarrow\mathbb{R} F_{f\circ X, g\circ Y}(x_1,y_1)=P\{f(X)\leq x_1, g(Y)\leq y_1\}=P(X\in f^{-1}(-\infty,x_1], Y\in g^{-1}(-\infty,y_1])=P_{XY}(f^{-1}(-\infty,x_1]\times g^{-1}(-\infty,y_1])=P_{X_2Y_2}(f^{-1}(-\infty,x_1]\times g^{-1}(-\infty,y_1])=F_{f\circ X_2, g\circ Y_2}(x_1,y_1) Cov(f\circ X_2, g\circ Y_2)=Cov(f\circ X, g\circ Y) f=I_{(-\infty,x]} g=I_{(-\infty,y]} P_X=P_{X_2} E(f\circ X)=\int_{\Omega} (f\circ X)(z) P(dz)=\int_{\mathbb{R}} f(w) P_X(dw)=\int_{\mathbb{R}} f(w) P_{X_2}(dw)=E(f\circ X_2) f","['measure-theory', 'self-learning']"
47,"Define $ \mu_1 = \int_a^b xdx,$ and inductively: $\mu_k = \int_a^b x d \mu_{k-1}$. What will be $\mu_k?$",Define  and inductively: . What will be," \mu_1 = \int_a^b xdx, \mu_k = \int_a^b x d \mu_{k-1} \mu_k?","Define the following sequence of measures given by $\mu_0 = dx$ (Lebesgue measure), $\mu_1([a,b]) = \int_a^b x \;dx, \mu_k([a,b]) = \int_a^b x\; d\mu_{k-1}, [a,b] \subset [0,1].$ What will be $\mu_{k}?$ This problem was posted by our professor as a challenge, and at the moment we don't have Radon Nikodym theorem at disposition. Well, what I tried was to define a sequence of functions $\varphi_n$ which I know how to calcule the integral with respect to $\mu_1$ for each term and which converges monotically to $f = x$ . So by the monotone convergence theorem, it would follow that: $$\int_a^b x d\mu_1 = \lim_n \int_a^b \varphi_n d\mu_1$$ The sequence which I tried is given by: $$ \varphi_n = \sum_{j=0}^{2^n-1}(a+j\cdot \frac{b-a}{2^n})\chi_{[a+j\cdot \frac{b-a}{2^n},\, a+(j+1)\cdot \frac{b-a}{2^n}]}, $$ which basically is a step function defined on and constant at each $2^n$ intervals by the infimum of the function there. The problem, as you may notice, is to calculate this limit: $\lim_n \sum_{j=0}^{2^n-1} (a+j\cdot\frac{b-a}{2^n}) \mu_1\bigg ( \bigg [a+j\cdot \frac{b-a}{2^n}, a+(j+1)\cdot \frac{b-a}{2^n} \bigg ] \bigg).$ How to proceed with this? Any good suggestions? Edit Solution to the hint given in the answer: Let $f,g = x$ . Then exists an increasing sequence $(\varphi_n)$ of simple functions such that $\lim \varphi_n = g, x \in [a,b] =  A.$ Write for each $ \varphi_n = \sum_k a_{k,n}\chi_{E_{k,n}}$ for each $n$ . Since $(\varphi_n)$ is an increasing function, by the monotone convergence theorem we have that $$ \int_A g d\nu = \lim_n \int_A \varphi_n d\nu = \lim_n \sum_k  a_{k,n}\nu(E_{k,n}) = \lim_n\sum_k a_{k,n} \int_{E_{k,n}}f d\mu = $$ $$\lim_n \int_A \sum_k a_{k,n} f \cdot \chi_{E_{k,n}} d\mu = \lim_n \int_A \varphi_nf d\mu. $$ Now we note that $(\varphi_n f)$ is also an increasing sequence $(f$ is also positive) whose terms are also measurable and positive and such that $\lim_n \varphi_n f = gf $ (as $f$ is bounded on $A$ ). Hence, once more by the monotone convergence theorem we have $$ \int_A g d\nu = \lim_n \int_A  \varphi_n f d\mu = \int_A \lim_n \varphi_n f d\mu = \int_A gf d\mu.$$","Define the following sequence of measures given by (Lebesgue measure), What will be This problem was posted by our professor as a challenge, and at the moment we don't have Radon Nikodym theorem at disposition. Well, what I tried was to define a sequence of functions which I know how to calcule the integral with respect to for each term and which converges monotically to . So by the monotone convergence theorem, it would follow that: The sequence which I tried is given by: which basically is a step function defined on and constant at each intervals by the infimum of the function there. The problem, as you may notice, is to calculate this limit: How to proceed with this? Any good suggestions? Edit Solution to the hint given in the answer: Let . Then exists an increasing sequence of simple functions such that Write for each for each . Since is an increasing function, by the monotone convergence theorem we have that Now we note that is also an increasing sequence is also positive) whose terms are also measurable and positive and such that (as is bounded on ). Hence, once more by the monotone convergence theorem we have","\mu_0 = dx \mu_1([a,b]) = \int_a^b x \;dx, \mu_k([a,b]) = \int_a^b x\; d\mu_{k-1}, [a,b] \subset [0,1]. \mu_{k}? \varphi_n \mu_1 f = x \int_a^b x d\mu_1 = \lim_n \int_a^b \varphi_n d\mu_1  \varphi_n = \sum_{j=0}^{2^n-1}(a+j\cdot \frac{b-a}{2^n})\chi_{[a+j\cdot \frac{b-a}{2^n},\, a+(j+1)\cdot \frac{b-a}{2^n}]},  2^n \lim_n \sum_{j=0}^{2^n-1} (a+j\cdot\frac{b-a}{2^n}) \mu_1\bigg ( \bigg [a+j\cdot \frac{b-a}{2^n}, a+(j+1)\cdot \frac{b-a}{2^n} \bigg ] \bigg). f,g = x (\varphi_n) \lim \varphi_n = g, x \in [a,b] =  A.  \varphi_n = \sum_k a_{k,n}\chi_{E_{k,n}} n (\varphi_n)  \int_A g d\nu = \lim_n \int_A \varphi_n d\nu = \lim_n \sum_k  a_{k,n}\nu(E_{k,n}) = \lim_n\sum_k a_{k,n} \int_{E_{k,n}}f d\mu =  \lim_n \int_A \sum_k a_{k,n} f \cdot \chi_{E_{k,n}} d\mu = \lim_n \int_A \varphi_nf d\mu.  (\varphi_n f) (f \lim_n \varphi_n f = gf  f A  \int_A g d\nu = \lim_n \int_A  \varphi_n f d\mu = \int_A \lim_n \varphi_n f d\mu = \int_A gf d\mu.",['measure-theory']
48,Is there a Birkhoff's Ergodic Theorem for multivariate functions?,Is there a Birkhoff's Ergodic Theorem for multivariate functions?,,"I recently tackled a problem and I arrived at something of the following form, $$ \frac{1}{n^2} \sum_{i=0}^{n-1}\sum_{j=0}^{n-1} f(T^ix, T^jy), $$ where $T$ is a measure preserving transformation and I am interested in the limit as $n$ tends to infinity. In my case it  is the shift operator in a probability space. In the uni-variate case Birkhoff's ergodic theorem states that for a measure preserving transformation $T$ ,in a measurable space $(X, \mathscr{B})$ , with a $\sigma$ -finite measure $\mu$ $$\frac{1}{n} \sum_{i=0}^{n-1} f(T^ix)$$ converges a.e. to a function $f*\in L^1$ , with $f^* = \frac{1}{\mu(X)}\int fd\mu$ . Is there an equivalent result for the multivariate case? Will the first equation converge  to it's average?","I recently tackled a problem and I arrived at something of the following form, where is a measure preserving transformation and I am interested in the limit as tends to infinity. In my case it  is the shift operator in a probability space. In the uni-variate case Birkhoff's ergodic theorem states that for a measure preserving transformation ,in a measurable space , with a -finite measure converges a.e. to a function , with . Is there an equivalent result for the multivariate case? Will the first equation converge  to it's average?"," \frac{1}{n^2} \sum_{i=0}^{n-1}\sum_{j=0}^{n-1} f(T^ix, T^jy),  T n T (X, \mathscr{B}) \sigma \mu \frac{1}{n} \sum_{i=0}^{n-1} f(T^ix) f*\in L^1 f^* = \frac{1}{\mu(X)}\int fd\mu","['measure-theory', 'ergodic-theory']"
49,Are there products in the category of $\sigma$-algebras and (reversed) $\sigma$-homomorphisms?,Are there products in the category of -algebras and (reversed) -homomorphisms?,\sigma \sigma,"Let $\mathcal{A}$ be a $\sigma$ -algebra on a set $X$ , and $\mathcal{B}$ be a $\sigma$ -algebra on a set $Y$ . A map $h\colon\mathcal{B}\to\mathcal{A}$ is called a $\sigma$ -homomorphism if $h(\emptyset)=\emptyset$ , $h(Y\setminus B)=X\setminus h(B)$ for any $B\in\mathcal{B}$ , and $h\big(\bigcup B_n\big)=\bigcup h(B_n)$ for any sequence $\{B_n\}_{n\in\omega}$ in $\mathcal{B}$ . Let us consider a category where objects are pairs of the form $(X,\mathcal{A})$ , $\mathcal{A}$ being a $\sigma$ -algebra on $X$ , and morphisms $(X,\mathcal{A})\to(Y,\mathcal{B})$ are $\sigma$ -homomorphisms $h\colon\mathcal{B}\to\mathcal{A}$ . Note that the arrows are reversed. Question: Are there products in this category? Note: Original version of this question confusingly uses the term ""measurable space"" for the objects of the category in concern. The question is now rewrtitten to make clear the difference. There is a standard notion of ""the category of measurable spaces"" where objects are the same pairs as above and morphisms $(X,\mathcal{A})\to(Y,\mathcal{B})$ are measurable maps $f\colon X\to Y$ . Measurability means that $f^{-1}[B]\in\mathcal{A}$ for any set $B\in\mathcal{B}$ ; it is easy to check that then $f^{-1}\colon\mathcal{B}\to\mathcal{A}$ is $\sigma$ -homomorphism. However, not all $\sigma$ -homomorphisms are of this form; see here . So our category has the same objects but more morphisms than the standard category of measurable spaces. A natural candidate for a product of $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ in our category of $\sigma$ -algebras is $(X\times Y,\mathcal{A}\times\mathcal{B})$ , where $\mathcal{A}\times\mathcal{B}\,$ is the $\sigma$ -algebra generated by rectangles of the form $A\times B\,$ for $A\in\mathcal{A}$ and $B\in\mathcal{B}$ , together with $\sigma$ -homomorphisms $f_1\colon\mathcal{A}\to\mathcal{A}\times\mathcal{B}$ and $f_2\colon\mathcal{B}\to\mathcal{A}\times\mathcal{B}$ defined by $f_1(A)=A\times Y$ and $f_2(B)=X\times B$ . Taking another $\sigma$ -algebra $\mathcal{C}$ and $\sigma$ -homomorphisms $g_1\colon\mathcal{A}\to\mathcal{C}$ , $g_2\colon\mathcal{B}\to\mathcal{C}$ , we have to prove that there exists a unique $\sigma$ -homomorphism $h\colon\mathcal{A}\times\mathcal{B}\to\mathcal{C}$ such that $g_1=h\circ f_1$ and $g_2=h\circ f_2$ . We could define $h(A\times B)=g_1(A)\cap g_2(B)$ and then try to extend the definition of $h$ to the whole $\sigma$ -algebra $\mathcal{A}\times\mathcal{B}$ . Is this approach working? How one can prove the existence and the uniqueness of $h$ ?","Let be a -algebra on a set , and be a -algebra on a set . A map is called a -homomorphism if , for any , and for any sequence in . Let us consider a category where objects are pairs of the form , being a -algebra on , and morphisms are -homomorphisms . Note that the arrows are reversed. Question: Are there products in this category? Note: Original version of this question confusingly uses the term ""measurable space"" for the objects of the category in concern. The question is now rewrtitten to make clear the difference. There is a standard notion of ""the category of measurable spaces"" where objects are the same pairs as above and morphisms are measurable maps . Measurability means that for any set ; it is easy to check that then is -homomorphism. However, not all -homomorphisms are of this form; see here . So our category has the same objects but more morphisms than the standard category of measurable spaces. A natural candidate for a product of and in our category of -algebras is , where is the -algebra generated by rectangles of the form for and , together with -homomorphisms and defined by and . Taking another -algebra and -homomorphisms , , we have to prove that there exists a unique -homomorphism such that and . We could define and then try to extend the definition of to the whole -algebra . Is this approach working? How one can prove the existence and the uniqueness of ?","\mathcal{A} \sigma X \mathcal{B} \sigma Y h\colon\mathcal{B}\to\mathcal{A} \sigma h(\emptyset)=\emptyset h(Y\setminus B)=X\setminus h(B) B\in\mathcal{B} h\big(\bigcup B_n\big)=\bigcup h(B_n) \{B_n\}_{n\in\omega} \mathcal{B} (X,\mathcal{A}) \mathcal{A} \sigma X (X,\mathcal{A})\to(Y,\mathcal{B}) \sigma h\colon\mathcal{B}\to\mathcal{A} (X,\mathcal{A})\to(Y,\mathcal{B}) f\colon X\to Y f^{-1}[B]\in\mathcal{A} B\in\mathcal{B} f^{-1}\colon\mathcal{B}\to\mathcal{A} \sigma \sigma (X,\mathcal{A}) (Y,\mathcal{B}) \sigma (X\times Y,\mathcal{A}\times\mathcal{B}) \mathcal{A}\times\mathcal{B}\, \sigma A\times B\, A\in\mathcal{A} B\in\mathcal{B} \sigma f_1\colon\mathcal{A}\to\mathcal{A}\times\mathcal{B} f_2\colon\mathcal{B}\to\mathcal{A}\times\mathcal{B} f_1(A)=A\times Y f_2(B)=X\times B \sigma \mathcal{C} \sigma g_1\colon\mathcal{A}\to\mathcal{C} g_2\colon\mathcal{B}\to\mathcal{C} \sigma h\colon\mathcal{A}\times\mathcal{B}\to\mathcal{C} g_1=h\circ f_1 g_2=h\circ f_2 h(A\times B)=g_1(A)\cap g_2(B) h \sigma \mathcal{A}\times\mathcal{B} h","['measure-theory', 'category-theory', 'boolean-algebra']"
50,Measurable subset of Vitaly set has measure zero. Proof.,Measurable subset of Vitaly set has measure zero. Proof.,,"$E_x = \{y \in [0,1]: x-y \in \Bbb{Q}\}$, $ \varepsilon=\{A \subset [0,1]: \exists x \quad A=E_x\}  $ .We chose one element from each set of family $\varepsilon$. This is a Vitaly set $V$. Prove that if $E$ is measurable and $E \subset V$ then $E$ has measure $0$. $E_q = [0,1] \bigcap \Bbb{Q} $, $q \in \Bbb{Q} $ I don't know how $E$ looks. I know for example that every singleton is measurable and has measure zero. But I don't know how to explain that every measurable set of $V$ has measure zero.","$E_x = \{y \in [0,1]: x-y \in \Bbb{Q}\}$, $ \varepsilon=\{A \subset [0,1]: \exists x \quad A=E_x\}  $ .We chose one element from each set of family $\varepsilon$. This is a Vitaly set $V$. Prove that if $E$ is measurable and $E \subset V$ then $E$ has measure $0$. $E_q = [0,1] \bigcap \Bbb{Q} $, $q \in \Bbb{Q} $ I don't know how $E$ looks. I know for example that every singleton is measurable and has measure zero. But I don't know how to explain that every measurable set of $V$ has measure zero.",,"['measure-theory', 'lebesgue-measure']"
51,Cauchy sequence in mean,Cauchy sequence in mean,,"Suppose $\{f_n\}$ is a sequence of functions in $L_1$ . Show that $\{f_n\}$ is a Cauchy sequence in mean if and only if $\int_E f_n \, d\mu=x_n$ is a Cauchy sequence for real numbers for every measurable set $E,$ and $\{f_n\}$ is a Cauchy sequence in measure. I am able to prove the first part: ( $\Rightarrow$ ) Since Cauchy sequence in $p$ th mean implies Cauchy sequence in measure, we only need to prove that the sequence $\{x_n\}$ is a Cauchy sequence (We can assume that $E=\Omega$ is the entire space), but that is precisely the definition of being a Cauchy sequence in $L_1$ , so we are done I'm having trouble to proving the second part, since I cannot estimate $\int_E |f_n-f_m| \, d\mu$ using $|x_n-x_m|=|\int_E( f_n-f_m ) \, d\mu|$ . I was tying to use one Theorem, too: Theorem: Suppose $\{f_n\}$ is a sequence of functions is $L_p$ and let $\nu_n(E)$ = $\int_E |f_n|^p \, d\mu$ . Then $\{f_n\}$ is a Cauchy sequence in pth mean if an only if $\{f_n\}$ is a Cauchy sequence in measure and the family $\{\nu_n\}$ is equicontinuous at $\varnothing$ . Since $\nu_n(\Omega)<\infty$ , then we only need to show that the family is absolutely continuous with respect to $\mu$ , and is precisely here where I'm stuck.","Suppose is a sequence of functions in . Show that is a Cauchy sequence in mean if and only if is a Cauchy sequence for real numbers for every measurable set and is a Cauchy sequence in measure. I am able to prove the first part: ( ) Since Cauchy sequence in th mean implies Cauchy sequence in measure, we only need to prove that the sequence is a Cauchy sequence (We can assume that is the entire space), but that is precisely the definition of being a Cauchy sequence in , so we are done I'm having trouble to proving the second part, since I cannot estimate using . I was tying to use one Theorem, too: Theorem: Suppose is a sequence of functions is and let = . Then is a Cauchy sequence in pth mean if an only if is a Cauchy sequence in measure and the family is equicontinuous at . Since , then we only need to show that the family is absolutely continuous with respect to , and is precisely here where I'm stuck.","\{f_n\} L_1 \{f_n\} \int_E f_n \, d\mu=x_n E, \{f_n\} \Rightarrow p \{x_n\} E=\Omega L_1 \int_E |f_n-f_m| \, d\mu |x_n-x_m|=|\int_E( f_n-f_m ) \, d\mu| \{f_n\} L_p \nu_n(E) \int_E |f_n|^p \, d\mu \{f_n\} \{f_n\} \{\nu_n\} \varnothing \nu_n(\Omega)<\infty \mu",['measure-theory']
52,almost everywhere differentiable but not almost everywhere continuously differentiable,almost everywhere differentiable but not almost everywhere continuously differentiable,,"The common example for differentiable but not continuously differentiable is $x^2\sin \frac{1}{x}$. This still looks almost everywhere continuously differentiable to my not very trained eyes. Are there examples of almost everywhere differentiable but not almost everywhere continuously differentiable? If so, are there any straightforward conditions (possibly to do with one-sided derivatives) that can be combined with almost everywhere differentiable to give almost everywhere continuously differentiable? (I am trying to show that the Lipschitz continuous function I am working with is almost everywhere continuously differentiable. Rademacher's theorem says that a Lipschitz continuous function is almost everywhere differentiable. )","The common example for differentiable but not continuously differentiable is $x^2\sin \frac{1}{x}$. This still looks almost everywhere continuously differentiable to my not very trained eyes. Are there examples of almost everywhere differentiable but not almost everywhere continuously differentiable? If so, are there any straightforward conditions (possibly to do with one-sided derivatives) that can be combined with almost everywhere differentiable to give almost everywhere continuously differentiable? (I am trying to show that the Lipschitz continuous function I am working with is almost everywhere continuously differentiable. Rademacher's theorem says that a Lipschitz continuous function is almost everywhere differentiable. )",,"['measure-theory', 'derivatives', 'lipschitz-functions']"
53,Dirac Delta Function as a Measure,Dirac Delta Function as a Measure,,"I was always told in my college physics classes to not worry too much about the dirac delta function because it can be made rigorous using distributions or measure theory. I've just started learning some measure theory, and I'm trying to make the connection between the dirac measure $\delta_x$ on $(\mathbb{R},\scr B_{\mathbb{R}})$, and the dirac delta function. I know that for some fixed $x_0\in\mathbb{R}$, and some measurable function $f$, $\delta_{x_0}f=\int_{\mathbb{R}}\delta_{x_0}\{dx\}f(x)=f(x_0)$, so in the case of the dirac delta function, we just let $x_0=0$, and we get $\int_{-\infty}^{\infty}f(x)\delta(x)dx=f(0)$, and $\int_{-\infty}^{\infty}\delta(x)dx=1$, the latter taken as part of the definition of the dirac delta function. Here's my confusion: The dirac measure is defined (for $x_0=0$) as $\delta_{0}(A)=\begin{cases} 1, & 0\in A \\ 0, & 0\in A^c \end{cases}$, $A\in\scr B_{\mathbb{R}}$. $A$ can include a singleton $\{x\}$ since these are also Borel sets, and in this case we have $\delta_{0}(\{x\})=\begin{cases} 1, & x=0 \\ 0, & x\neq 0 \end{cases}$. But the dirac delta function is defined as $\delta(x)=\begin{cases} +\infty, & x=0 \\ 0, & x\neq 0 \end{cases}$. Why is $\delta_0(0)=1$ in the first case and $+\infty$ in the second?","I was always told in my college physics classes to not worry too much about the dirac delta function because it can be made rigorous using distributions or measure theory. I've just started learning some measure theory, and I'm trying to make the connection between the dirac measure $\delta_x$ on $(\mathbb{R},\scr B_{\mathbb{R}})$, and the dirac delta function. I know that for some fixed $x_0\in\mathbb{R}$, and some measurable function $f$, $\delta_{x_0}f=\int_{\mathbb{R}}\delta_{x_0}\{dx\}f(x)=f(x_0)$, so in the case of the dirac delta function, we just let $x_0=0$, and we get $\int_{-\infty}^{\infty}f(x)\delta(x)dx=f(0)$, and $\int_{-\infty}^{\infty}\delta(x)dx=1$, the latter taken as part of the definition of the dirac delta function. Here's my confusion: The dirac measure is defined (for $x_0=0$) as $\delta_{0}(A)=\begin{cases} 1, & 0\in A \\ 0, & 0\in A^c \end{cases}$, $A\in\scr B_{\mathbb{R}}$. $A$ can include a singleton $\{x\}$ since these are also Borel sets, and in this case we have $\delta_{0}(\{x\})=\begin{cases} 1, & x=0 \\ 0, & x\neq 0 \end{cases}$. But the dirac delta function is defined as $\delta(x)=\begin{cases} +\infty, & x=0 \\ 0, & x\neq 0 \end{cases}$. Why is $\delta_0(0)=1$ in the first case and $+\infty$ in the second?",,"['measure-theory', 'self-learning', 'dirac-delta']"
54,"Why is the relation ""$f=g $ almost everywhere"" transitive?","Why is the relation "" almost everywhere"" transitive?",f=g ,"In Rudin's Real and Complex Analysis, it says on pg 27 that If $\mu$ be a measure, define $f\sim g$ iff $\mu(\{x|f(x)g(x)\})=0$, where $f,g$ are measurable functions from $X$ to a topological space $Y$. Then, $f\sim g$ is an equivalence relation. But, I do not see why $f\sim g$ is transitive. If I assume $f\sim g$ and $g\sim h$, then by definition, $\{x|f(x)g(x)\}$ and $\{x|g(x)h(x)\}$ are measurable sets with measure zero. But then, how do I know that the set $\{x|f(x)h(x)\} \subset \{x|f(x)g(x)\} \cup  \{x|g(x)h(x)\} $ is measurable? Here $Y$ is a topological space, not necessarily $R$ or extended reals.","In Rudin's Real and Complex Analysis, it says on pg 27 that If $\mu$ be a measure, define $f\sim g$ iff $\mu(\{x|f(x)g(x)\})=0$, where $f,g$ are measurable functions from $X$ to a topological space $Y$. Then, $f\sim g$ is an equivalence relation. But, I do not see why $f\sim g$ is transitive. If I assume $f\sim g$ and $g\sim h$, then by definition, $\{x|f(x)g(x)\}$ and $\{x|g(x)h(x)\}$ are measurable sets with measure zero. But then, how do I know that the set $\{x|f(x)h(x)\} \subset \{x|f(x)g(x)\} \cup  \{x|g(x)h(x)\} $ is measurable? Here $Y$ is a topological space, not necessarily $R$ or extended reals.",,['measure-theory']
55,What is an intuitive explanation for Birkhoff's ergodic theorem?,What is an intuitive explanation for Birkhoff's ergodic theorem?,,"If I'm not familiar with measure theory, what is a good way to understand the idea behind the definitions involved, the interpretation of the theorem, and the proofs thereof? Particularly, it's not clear to me what is the significance of the map $T$ often referred to in the definitions, etc. Should it be thought of as a time shift? Even definitions of ergodicity don't mean much to me in terms of the notation. So, I'm looking for a tangible intuitive idea of what these quantities/sets/functions represent (maybe via an example?). A basic explanation with a concrete example or two explaining the definitions from scratch would be really helpful. Thank you!","If I'm not familiar with measure theory, what is a good way to understand the idea behind the definitions involved, the interpretation of the theorem, and the proofs thereof? Particularly, it's not clear to me what is the significance of the map $T$ often referred to in the definitions, etc. Should it be thought of as a time shift? Even definitions of ergodicity don't mean much to me in terms of the notation. So, I'm looking for a tangible intuitive idea of what these quantities/sets/functions represent (maybe via an example?). A basic explanation with a concrete example or two explaining the definitions from scratch would be really helpful. Thank you!",,"['measure-theory', 'stochastic-processes', 'intuition', 'information-theory', 'ergodic-theory']"
56,"""Lebesgue measure"" on metric spaces?","""Lebesgue measure"" on metric spaces?",,"Sry if my question is stupid, but I just wondered if is there is like a corresponding counterpart to the Lebesgue measure on $\mathbb{R}^n$ for (some?) metric spaces $(E,d)$? Since the natural way to measure distances in $(E,d)$ is given by $d$, shouldn't there be a ""natural"" way to measure sets as well? Sure I'm aware that the structure of $\mathbb{R}^n$ is very special but is there a theory out there about how to measure sets in metric spaces ""naturally""?","Sry if my question is stupid, but I just wondered if is there is like a corresponding counterpart to the Lebesgue measure on $\mathbb{R}^n$ for (some?) metric spaces $(E,d)$? Since the natural way to measure distances in $(E,d)$ is given by $d$, shouldn't there be a ""natural"" way to measure sets as well? Sure I'm aware that the structure of $\mathbb{R}^n$ is very special but is there a theory out there about how to measure sets in metric spaces ""naturally""?",,"['measure-theory', 'lebesgue-measure']"
57,"Exercise 30 from Chapter 1 (""Measure Theory"") of Stein and Shakarchi's ""Real Analysis""","Exercise 30 from Chapter 1 (""Measure Theory"") of Stein and Shakarchi's ""Real Analysis""",,"Consider the following exercise from [1] (p. 44): 30 If $E$ and $F$ are measurable, and $m(E) > 0$, $M(F) > 0$, prove that   $$ E + F = \{x + y : x \in E, x \in F\} $$   contains an interval. If $E = F$, this exercise reduces to exercise 29 (see below), which I am able to prove according to the hint. But I cant figure out how to modify exercise 29's proof to prove exercise 30's more general claim. Any help will be appreciated. 29 Suppose $E$ is a measurable subset of $\mathbb{R}$ with $m(E) > 0$. Prove that the difference set of $E$, which is defined by   $$ \{z \in \mathbb{R} : z = x - y \mbox{ for some } x, y \in E\} $$   contains an open interval centered at the origin. If $E$ contains an interval, then the conclusion is straightforward. In general, one may rely on Exercise 28. [Hint: Indeed, by Exercise 28, there exists an open interval $I$ so that $m(E \cap I) \geq (9/10)m(I)$. If we denote $E \cap I$ by $E_0$, and suppose that the difference set of $E_0$ does not contain an open interval around the origin, then for arbitrarily small $a$ the sets $E_0$ and $E_0 + a$ are disjoint. From the fact that $(E_0 \cup (E_0 + a)) \subseteq (I \cup (I + a))$ we get a contradiction, since the lift-hand side has measure $2m(E_0)$, while the right-hand side has measure only slightly larger than $m(I)$.] For completeness, here's exercise 28 mentioned in exercise 29: 28 Let $E$ be a subset of $\mathbb{R}$ with $m_*(E) > 0$. Prove that for each $0 < \alpha < 1$, there exists an open interval $I$ so that   $$ m_*(E\cap I) \geq \alpha m_*(I). $$   Loosely speaking, this estimate shows that $E$ contains almost a whole interval. [Hint: Choose an open set $\mathcal{O}$ that contains $E$, and such that $m_*(E) \geq \alpha m_*(\mathcal{O})$. Write $\mathcal{O}$ as the countable union of disjoint open intervals, and show that one of these intervals must satisfy the desired property.] References [1] Stein, Elias M. and Shakarchi, Rami. Real Analysis: Measure Theory, Integration, and Hilbert Spaces. Princeton University Press (2005)","Consider the following exercise from [1] (p. 44): 30 If $E$ and $F$ are measurable, and $m(E) > 0$, $M(F) > 0$, prove that   $$ E + F = \{x + y : x \in E, x \in F\} $$   contains an interval. If $E = F$, this exercise reduces to exercise 29 (see below), which I am able to prove according to the hint. But I cant figure out how to modify exercise 29's proof to prove exercise 30's more general claim. Any help will be appreciated. 29 Suppose $E$ is a measurable subset of $\mathbb{R}$ with $m(E) > 0$. Prove that the difference set of $E$, which is defined by   $$ \{z \in \mathbb{R} : z = x - y \mbox{ for some } x, y \in E\} $$   contains an open interval centered at the origin. If $E$ contains an interval, then the conclusion is straightforward. In general, one may rely on Exercise 28. [Hint: Indeed, by Exercise 28, there exists an open interval $I$ so that $m(E \cap I) \geq (9/10)m(I)$. If we denote $E \cap I$ by $E_0$, and suppose that the difference set of $E_0$ does not contain an open interval around the origin, then for arbitrarily small $a$ the sets $E_0$ and $E_0 + a$ are disjoint. From the fact that $(E_0 \cup (E_0 + a)) \subseteq (I \cup (I + a))$ we get a contradiction, since the lift-hand side has measure $2m(E_0)$, while the right-hand side has measure only slightly larger than $m(I)$.] For completeness, here's exercise 28 mentioned in exercise 29: 28 Let $E$ be a subset of $\mathbb{R}$ with $m_*(E) > 0$. Prove that for each $0 < \alpha < 1$, there exists an open interval $I$ so that   $$ m_*(E\cap I) \geq \alpha m_*(I). $$   Loosely speaking, this estimate shows that $E$ contains almost a whole interval. [Hint: Choose an open set $\mathcal{O}$ that contains $E$, and such that $m_*(E) \geq \alpha m_*(\mathcal{O})$. Write $\mathcal{O}$ as the countable union of disjoint open intervals, and show that one of these intervals must satisfy the desired property.] References [1] Stein, Elias M. and Shakarchi, Rami. Real Analysis: Measure Theory, Integration, and Hilbert Spaces. Princeton University Press (2005)",,['measure-theory']
58,Jordan Measure and Lebesgue Measure,Jordan Measure and Lebesgue Measure,,"The Jordan outer measure $J^*(E)$ of a set $E\subseteq \mathbb{R}$ is defined as infimum of $\sum_{i=1}^n (b_i-a_i)$ where $(a_i,b_i)$ are open intervals whose union contains $E$ . The Jordan inner measure $J_*(E)$ of a set $E\subseteq \mathbb{R}$ is defined as supremum of $\sum_{i=1}^n (b_i-a_i)$ where $(a_i,b_i)$ are open intervals, whose union is contained in $E$ . A set is $E$ Jordan measurable if $J^*(E)=J_*(E)$ . Lebesgue measure of a set $E\subseteq \mathbb{R}$ is defined in a similar way by defining Lebesgue outer measure and inner measure, where the sums/unions in above definition are allowed to be countable. Question: What properties of functions can be characterized by the Lebesgue measure but not the Jordan measure? (I want a motivation of Lebesgue measure with some drawback/disadvantages of Jordan measure. I didn't find theory of Jordan measure in many books of Measure theory, although it was a motivational point towards development of Lebesgue measure and Integration.)","The Jordan outer measure of a set is defined as infimum of where are open intervals whose union contains . The Jordan inner measure of a set is defined as supremum of where are open intervals, whose union is contained in . A set is Jordan measurable if . Lebesgue measure of a set is defined in a similar way by defining Lebesgue outer measure and inner measure, where the sums/unions in above definition are allowed to be countable. Question: What properties of functions can be characterized by the Lebesgue measure but not the Jordan measure? (I want a motivation of Lebesgue measure with some drawback/disadvantages of Jordan measure. I didn't find theory of Jordan measure in many books of Measure theory, although it was a motivational point towards development of Lebesgue measure and Integration.)","J^*(E) E\subseteq \mathbb{R} \sum_{i=1}^n (b_i-a_i) (a_i,b_i) E J_*(E) E\subseteq \mathbb{R} \sum_{i=1}^n (b_i-a_i) (a_i,b_i) E E J^*(E)=J_*(E) E\subseteq \mathbb{R}",['measure-theory']
59,Lebesgue integral with repect to counting measure,Lebesgue integral with repect to counting measure,,"Let $\Omega$ be a set, $\mathcal{A} = \mathcal{P}(\Omega)$ the power set, $\mu$ counting measure, $f$ a nonnegative function on $\Omega$, I want to show that $$ \int_\Omega f d\mu = \sum_{x \in \Omega} f(x) $$ where $\sum_{x \in \Omega} f(x) = \sup \{\sum_{x \in F} f(x): F \mbox{ finite },\, F \subset \Omega \}$. $\forall F \subset \Omega$, we have $$ \int_{\Omega} f d\mu \ge \int_F f d\mu = \sum_{x \in F} \int_{\{x\}} f d\mu = \sum_{x \in F} f(x) \mu(\{x\}) = \sum_{x \in F} f(x)$$ so $ \int_{\Omega} f d\mu \ge \sup_{F \subset \Omega} \{ \sum_{x \in F} f(x) \}$. How do I show the reverse inequality ?","Let $\Omega$ be a set, $\mathcal{A} = \mathcal{P}(\Omega)$ the power set, $\mu$ counting measure, $f$ a nonnegative function on $\Omega$, I want to show that $$ \int_\Omega f d\mu = \sum_{x \in \Omega} f(x) $$ where $\sum_{x \in \Omega} f(x) = \sup \{\sum_{x \in F} f(x): F \mbox{ finite },\, F \subset \Omega \}$. $\forall F \subset \Omega$, we have $$ \int_{\Omega} f d\mu \ge \int_F f d\mu = \sum_{x \in F} \int_{\{x\}} f d\mu = \sum_{x \in F} f(x) \mu(\{x\}) = \sum_{x \in F} f(x)$$ so $ \int_{\Omega} f d\mu \ge \sup_{F \subset \Omega} \{ \sum_{x \in F} f(x) \}$. How do I show the reverse inequality ?",,['measure-theory']
60,"Every open subset $O$ of $\Bbb R^d,d \geq 1$, can be written as a countable union of almost disjoint closed cubes.","Every open subset  of , can be written as a countable union of almost disjoint closed cubes.","O \Bbb R^d,d \geq 1","After the usual construction as explained in press.princeton.edu/chapters/s8008.pdf (page 8) I did not understand the argument why the union is all of $O$. ""We note that given $x \in O$ there exists a cube of side length $2^{-N}$ (obtained from successive bisections of the original grid) that contains $x$ and that is entirely contained in $O$"" (page 8 line 4). How can this cube be rejected ? it is entirely contained in $O$.  ","After the usual construction as explained in press.princeton.edu/chapters/s8008.pdf (page 8) I did not understand the argument why the union is all of $O$. ""We note that given $x \in O$ there exists a cube of side length $2^{-N}$ (obtained from successive bisections of the original grid) that contains $x$ and that is entirely contained in $O$"" (page 8 line 4). How can this cube be rejected ? it is entirely contained in $O$.  ",,['measure-theory']
61,Arithmetic sequence in a Lebesgue measurable set,Arithmetic sequence in a Lebesgue measurable set,,"Let $A\subseteq[a,b]$ be Lebesgue measurable, such that: $m(A)>\frac{2n-1}{2n}(b-a)$. I need to show that $A$ contains an arithmetic sequence with n numbers ($a_1,a_1+d,...,a_1+(n-1)*d$ for some d). I thought about dividing [a,b] into n equal parts, and show that if I put one part on top of the other, there must be at least one lapping point, that will occur in every part. but I haven't succeeded in showing that. Thank you.","Let $A\subseteq[a,b]$ be Lebesgue measurable, such that: $m(A)>\frac{2n-1}{2n}(b-a)$. I need to show that $A$ contains an arithmetic sequence with n numbers ($a_1,a_1+d,...,a_1+(n-1)*d$ for some d). I thought about dividing [a,b] into n equal parts, and show that if I put one part on top of the other, there must be at least one lapping point, that will occur in every part. but I haven't succeeded in showing that. Thank you.",,['measure-theory']
62,Pushforward/image outer measure,Pushforward/image outer measure,,"Let $X$ and $Y$ be two sets, $f:X\to Y$ and $\mu$ be an outer measure on $2^X$. Is that true that the image of $\mu$ under $f$ defined by $$   \nu(B):= \mu(f^{-1}(B)) $$ is an outer measure on $Y$? If I am not mistaken, the answer is yes as $f^{-1}$ preserves empty sets, set inclusions and commutes with the unions. At the same time, I have never seen such construction in use, so I would be happy if anybody knows any reference on a topic.","Let $X$ and $Y$ be two sets, $f:X\to Y$ and $\mu$ be an outer measure on $2^X$. Is that true that the image of $\mu$ under $f$ defined by $$   \nu(B):= \mu(f^{-1}(B)) $$ is an outer measure on $Y$? If I am not mistaken, the answer is yes as $f^{-1}$ preserves empty sets, set inclusions and commutes with the unions. At the same time, I have never seen such construction in use, so I would be happy if anybody knows any reference on a topic.",,['measure-theory']
63,Outer measure discontinuous from below,Outer measure discontinuous from below,,"I was trying to find an example of an outer Measure which is not continuous from below.  These are the definitions I use An outer measure on $X$ is a function $\mu^\ast: \mathcal{P}(X)\to [0,\infty]$ if    it fulfills $\mu^\ast(\emptyset)=0$ $\mu^\ast\Big( \bigcup_{j=1}^\infty A_j\Big) \leq \sum_{j=1}^\infty A_j$ And an outer measure is continuous from below when for the sequence $(A_j)_{j\in \mathbb{N}}$ with  $A_j\subset A_{j+1}$ for alle $j$  the equality  $$ \mu^\ast \Big( \bigcup_{j=1}^\infty A_j\Big)= \lim_{j\to \infty} \mu^\ast (A_j)$$ Some results which might be helpful All measures are continuous from below All metric outer measures are continuous from below So I search for an outer measure which isn't continuous from below.","I was trying to find an example of an outer Measure which is not continuous from below.  These are the definitions I use An outer measure on $X$ is a function $\mu^\ast: \mathcal{P}(X)\to [0,\infty]$ if    it fulfills $\mu^\ast(\emptyset)=0$ $\mu^\ast\Big( \bigcup_{j=1}^\infty A_j\Big) \leq \sum_{j=1}^\infty A_j$ And an outer measure is continuous from below when for the sequence $(A_j)_{j\in \mathbb{N}}$ with  $A_j\subset A_{j+1}$ for alle $j$  the equality  $$ \mu^\ast \Big( \bigcup_{j=1}^\infty A_j\Big)= \lim_{j\to \infty} \mu^\ast (A_j)$$ Some results which might be helpful All measures are continuous from below All metric outer measures are continuous from below So I search for an outer measure which isn't continuous from below.",,"['measure-theory', 'examples-counterexamples']"
64,What different ways are there to construct the Lebesgue measure?,What different ways are there to construct the Lebesgue measure?,,"I have recently learned of different approaches (which I've included below) to constructing the Lebesgue measure, and I'm somewhat startled by how much each approach can illuminate the theory as a whole. Are there still others approaches to defining the Lebesgue measure? If so, what are their benefits and disadvantages? Where may I read about them? $$\textbf{First Approach}$$ Starting with the premeasure $\mu$ defined only on boxes, and extending it into a measure through the follwing theorem: Carathodory's Extension Lemma: let $\mu_0:\Sigma_0\to [0,\infty]$ be a pre-measure on the algebra $\Sigma_0$ of $X$ . Then $\mu_0$ can be extended to a measure $$\mu:\Sigma\to[0,\infty]$$ where $\Sigma:=\sigma(\Sigma_0)$ and $\mu|_{\Sigma_0}=\mu_0$ . Furhermore, if $\mu_0$ is finite, then the extension $\mu$ is unique. This approach is used in Williams' Probability with Martingales (PWM). It is worth mentioning that -excluding the proof of the theorem above- this is the simplest construction I know of. However, both of the proofs I know of the theorem above (one found at the end of PWT, and the other one found here ) first use the pre-measure to construct an outer measure $\mu^*$ and then restrict the outer measure to Lebesgue measurable sets. $$\textbf{Second Approach}$$ Parting from the outer Lebesgue measure $\mu^*$ and restricting it through the following theorem: Carathodory's Restriction Lemma: let $\mu^*:2^X\to [0,\infty]$ be an outer measure on the power set $2^X$ of $X$ . Then $\mu^*$ can be restricted to a measure $$\mu:\Sigma\to[0,\infty]$$ where $\Sigma := \Big\{ C \in 2^X : C \text{ is Caratheodory measurable} \Big\}$ and $\mu := \mu^*|_{\Sigma}$ . (I've never seen the 'Restriction Lemma' named as such, but I find the name appropriate). The approach may be found in Tao's An Introduction to Measure Theory (IMT), as well as Hunter's Measure Theory (MT). This approach is, I believe, the most common one, though it left me puzzled as to why the restriction was made to Carathodory measurable sets specifically; some intuition may be found in this post or by studying equivalent (and more geometrically intuitive) definitions of Lebesgue measurable sets (as in Exercise 1.2.7 in IMT). $$\textbf{Third Approach}$$ Parting again from the Lebesgue outer measure $\mu^*$ , one defines Lebesgue measurable sets as those which can be 'approximated from above' by open sets arbitrarily well: Definition: a set $E\subseteq \mathbb{R}^d$ is Lebesgue measurable iff for every $\varepsilon>0$ there is some open set $U\subseteq \mathbb{R}^d$ containing $E$ such that $\mu^*(U\setminus E)<\varepsilon$ . Then the Lebesgue measure is characterized as the restriction of $\mu^*$ to Lebesgue measurable sets, and a bit of work shows that the collection of Lebesgue measurable sets is a $\sigma$ -algebra, as well as that $\mu$ is a measure. The approach is not as generalizable, although it is arguably more geometrically intuitive (specially when similarities and dissimlarities with the Jordan measure are made). It is also found in IMT.","I have recently learned of different approaches (which I've included below) to constructing the Lebesgue measure, and I'm somewhat startled by how much each approach can illuminate the theory as a whole. Are there still others approaches to defining the Lebesgue measure? If so, what are their benefits and disadvantages? Where may I read about them? Starting with the premeasure defined only on boxes, and extending it into a measure through the follwing theorem: Carathodory's Extension Lemma: let be a pre-measure on the algebra of . Then can be extended to a measure where and . Furhermore, if is finite, then the extension is unique. This approach is used in Williams' Probability with Martingales (PWM). It is worth mentioning that -excluding the proof of the theorem above- this is the simplest construction I know of. However, both of the proofs I know of the theorem above (one found at the end of PWT, and the other one found here ) first use the pre-measure to construct an outer measure and then restrict the outer measure to Lebesgue measurable sets. Parting from the outer Lebesgue measure and restricting it through the following theorem: Carathodory's Restriction Lemma: let be an outer measure on the power set of . Then can be restricted to a measure where and . (I've never seen the 'Restriction Lemma' named as such, but I find the name appropriate). The approach may be found in Tao's An Introduction to Measure Theory (IMT), as well as Hunter's Measure Theory (MT). This approach is, I believe, the most common one, though it left me puzzled as to why the restriction was made to Carathodory measurable sets specifically; some intuition may be found in this post or by studying equivalent (and more geometrically intuitive) definitions of Lebesgue measurable sets (as in Exercise 1.2.7 in IMT). Parting again from the Lebesgue outer measure , one defines Lebesgue measurable sets as those which can be 'approximated from above' by open sets arbitrarily well: Definition: a set is Lebesgue measurable iff for every there is some open set containing such that . Then the Lebesgue measure is characterized as the restriction of to Lebesgue measurable sets, and a bit of work shows that the collection of Lebesgue measurable sets is a -algebra, as well as that is a measure. The approach is not as generalizable, although it is arguably more geometrically intuitive (specially when similarities and dissimlarities with the Jordan measure are made). It is also found in IMT.","\textbf{First Approach} \mu \mu_0:\Sigma_0\to [0,\infty] \Sigma_0 X \mu_0 \mu:\Sigma\to[0,\infty] \Sigma:=\sigma(\Sigma_0) \mu|_{\Sigma_0}=\mu_0 \mu_0 \mu \mu^* \textbf{Second Approach} \mu^* \mu^*:2^X\to [0,\infty] 2^X X \mu^* \mu:\Sigma\to[0,\infty] \Sigma := \Big\{ C \in 2^X : C \text{ is Caratheodory measurable} \Big\} \mu := \mu^*|_{\Sigma} \textbf{Third Approach} \mu^* E\subseteq \mathbb{R}^d \varepsilon>0 U\subseteq \mathbb{R}^d E \mu^*(U\setminus E)<\varepsilon \mu^* \sigma \mu","['measure-theory', 'definition', 'lebesgue-measure', 'big-list']"
65,Paradoxical sums of non-integrable measurable functions,Paradoxical sums of non-integrable measurable functions,,"Are there reals $\alpha_1,\alpha_2$ and Lebesgue-measurable functions $f_1,f_2:\mathbb R/\mathbb Z\to\mathbb R$ such that $$f_1(x)+f_2(x)>f_1(x+\alpha_1)+f_2(x+\alpha_2)$$ for almost all $x\in\mathbb R/\mathbb Z$ ? Here $\mathbb R/\mathbb Z$ has its usual Lebesgue measure coming from the unit interval. This would be a functional relative of paradoxical decompositions, where moving sets around can make them bigger. The famous example is the Banach-Tarski decomposition of the 2-sphere, which can be achieved with Baire measurable pieces [1]. Feel free to use more functions if it helps with a positive answer, or to add $1$ to the right-hand-side if it helps with a negative answer. Neither of the offsets $\alpha_1,\alpha_2$ can be rational. If $\alpha_i$ is a rational $p/q,$ we can sum (*) over $x=z,z+\tfrac1q,\dots,z+\tfrac{p-1}q$ to eliminate $f_i.$ Then $\alpha_i$ is irrelevant, so we can replace it by any irrational and apply the following argument. Neither $f_1$ nor $f_2$ can be integrable. To show this it suffices to consider the case that $f_2$ is integrable and $\alpha_1\not\in\mathbb Q.$ We can then find an integrable function $g$ satisfying $\int g>0$ and $$f_1(x)+f_2(x)> g(x)+f_1(x+\alpha_1)+f_2(x+\alpha_2)$$ for almost all $x,$ for example $g(x)=\min(1,f_1(x)+f_2(x)-f_1(x+\alpha_1)-f_2(x+\alpha_2))/2.$ Averaging over $x=z,z+\alpha_1,\dots,z+(n-1)\alpha_1$ and cancelling and rearranging gives $$\frac1n (f_1(z)-f_1(z+n\alpha_1))>\frac1n \sum_{k=0}^{n-1}(g(z+k\alpha_1)+f_2(z+\alpha_2+k\alpha_1)-f_2(z+k\alpha_1)).\tag{*}$$ Pick $C$ such that $\{x:f_1(x)>C\}$ has positive measure. By the pointwise ergodic theorem $f_1(z+n\alpha_1)>C$ for infinitely many integers $n\geq 0,$ for almost all $z.$ So $$\liminf_{n\to\infty}\frac1n (f_1(z)-f_1(z+n\alpha_1))\leq 0$$ for almost all $z.$ By the pointwise ergodic theorem again, the right-hand-side of (*) tends to $\int g>0$ for almost all $z\in\mathbb R/\mathbb Z.$ This is a contradiction. [1] Marks, Andrew; Unger, Spencer , Baire measurable paradoxical decompositions via matchings , Adv. Math. 289, 397-410 (2016). ZBL1335.54035 .","Are there reals and Lebesgue-measurable functions such that for almost all ? Here has its usual Lebesgue measure coming from the unit interval. This would be a functional relative of paradoxical decompositions, where moving sets around can make them bigger. The famous example is the Banach-Tarski decomposition of the 2-sphere, which can be achieved with Baire measurable pieces [1]. Feel free to use more functions if it helps with a positive answer, or to add to the right-hand-side if it helps with a negative answer. Neither of the offsets can be rational. If is a rational we can sum (*) over to eliminate Then is irrelevant, so we can replace it by any irrational and apply the following argument. Neither nor can be integrable. To show this it suffices to consider the case that is integrable and We can then find an integrable function satisfying and for almost all for example Averaging over and cancelling and rearranging gives Pick such that has positive measure. By the pointwise ergodic theorem for infinitely many integers for almost all So for almost all By the pointwise ergodic theorem again, the right-hand-side of (*) tends to for almost all This is a contradiction. [1] Marks, Andrew; Unger, Spencer , Baire measurable paradoxical decompositions via matchings , Adv. Math. 289, 397-410 (2016). ZBL1335.54035 .","\alpha_1,\alpha_2 f_1,f_2:\mathbb R/\mathbb Z\to\mathbb R f_1(x)+f_2(x)>f_1(x+\alpha_1)+f_2(x+\alpha_2) x\in\mathbb R/\mathbb Z \mathbb R/\mathbb Z 1 \alpha_1,\alpha_2 \alpha_i p/q, x=z,z+\tfrac1q,\dots,z+\tfrac{p-1}q f_i. \alpha_i f_1 f_2 f_2 \alpha_1\not\in\mathbb Q. g \int g>0 f_1(x)+f_2(x)> g(x)+f_1(x+\alpha_1)+f_2(x+\alpha_2) x, g(x)=\min(1,f_1(x)+f_2(x)-f_1(x+\alpha_1)-f_2(x+\alpha_2))/2. x=z,z+\alpha_1,\dots,z+(n-1)\alpha_1 \frac1n (f_1(z)-f_1(z+n\alpha_1))>\frac1n \sum_{k=0}^{n-1}(g(z+k\alpha_1)+f_2(z+\alpha_2+k\alpha_1)-f_2(z+k\alpha_1)).\tag{*} C \{x:f_1(x)>C\} f_1(z+n\alpha_1)>C n\geq 0, z. \liminf_{n\to\infty}\frac1n (f_1(z)-f_1(z+n\alpha_1))\leq 0 z. \int g>0 z\in\mathbb R/\mathbb Z.","['measure-theory', 'ergodic-theory']"
66,Suspicious corollary of Lusins Theorem,Suspicious corollary of Lusins Theorem,,"Suppose $f : [0,1] \to \mathbb R$ is integrable. According to Lusins Theorem (as I understand it), for every $\epsilon > 0$ , there is a closed subset $C \subset [0,1]$ for which $f|_C : C \to \mathbb R$ is continuous and $\lambda([0,1] \setminus C) < \epsilon$ , where $\lambda$ is the Lebesgue measure on $[0,1]$ . Furthermore, if $B \subset [0,1]$ is open, then there is a closed $C \subset B$ for which $f_{C} : C \to \mathbb R$ is continuous and $\lambda(B \setminus C) < \epsilon$ . Playing with this, I arrived at the following corollary, which seems way too powerful to be true: Corollary: There is a subset $C \subset [0,1]$ of full measure, for which $f|_C : C \to \mathbb R$ is continuous (in the induced subspace topology on $C$ ). Proof. Let $C_1 \subset [0,1]$ be a closed set for which $f|_{C_1}$ is continuous, with $\lambda([0,1] \setminus C_1) < 2^{-1}$ , so $\lambda(C_1) > 2^{-1}$ . The existence of such a $C_1$ follows from Lusins Theorem. Now let $C_2 \subset [0,1] \setminus C_1$ be such that $f|_{C_2}$ is also continuous, and $\lambda\left(\left([0,1]\setminus C_1\right)\setminus C_2\right) < 2^{-2}$ , or $\lambda(C_1 \sqcup C_2) > 2^{-2}$ . The existence of $C_2$ also follows from Lusins theorem. Continuing in this way, we get a countable collection of disjoint closed sets $(C_n)_{n \geq 1}$ for which $f|_{C_n} : C_n \to \mathbb R$ is continuous for each $n$ , and for which $\lambda\left(C_1 \sqcup C_2 \sqcup \cdots \sqcup C_n\right) > 1-2^{-n}$ . By lower semicontinuity of $\lambda$ , denoting $C = \bigsqcup_{n\geq 1} C_n$ , we have $$ 1 \geq \lambda(C) = \lim_{n \to \infty} \lambda\left(\mathop{\bigsqcup}_{k=1}^n C_k\right) \geq \lim_{n \to \infty}(1-2^{-n}) = 1. $$ So $\lambda(C) = 1$ . and since $C$ is the countable disjoint union of closed sets, on each of which $f$ is continuous in the subspace topology, it follows that $f$ is continuous on $C$ in its subspace topology. QED. I dont see an obvious flaw with this proof, but I find this hard to believe. The only place I can see an issue possibly is with the existence of $C_n$ for $n \geq 2$ using Lusins Theorem, but Lusins Theorem should hold on any Radon measure space $(X, \mathcal A, \mu)$ in particular it should hold on any measurable subset of $[0,1]$ . Where is the flaw in this proof? Or is this really a corollary of Lusins Theorem? EDIT: See the answer below.","Suppose is integrable. According to Lusins Theorem (as I understand it), for every , there is a closed subset for which is continuous and , where is the Lebesgue measure on . Furthermore, if is open, then there is a closed for which is continuous and . Playing with this, I arrived at the following corollary, which seems way too powerful to be true: Corollary: There is a subset of full measure, for which is continuous (in the induced subspace topology on ). Proof. Let be a closed set for which is continuous, with , so . The existence of such a follows from Lusins Theorem. Now let be such that is also continuous, and , or . The existence of also follows from Lusins theorem. Continuing in this way, we get a countable collection of disjoint closed sets for which is continuous for each , and for which . By lower semicontinuity of , denoting , we have So . and since is the countable disjoint union of closed sets, on each of which is continuous in the subspace topology, it follows that is continuous on in its subspace topology. QED. I dont see an obvious flaw with this proof, but I find this hard to believe. The only place I can see an issue possibly is with the existence of for using Lusins Theorem, but Lusins Theorem should hold on any Radon measure space in particular it should hold on any measurable subset of . Where is the flaw in this proof? Or is this really a corollary of Lusins Theorem? EDIT: See the answer below.","f : [0,1] \to \mathbb R \epsilon > 0 C \subset [0,1] f|_C : C \to \mathbb R \lambda([0,1] \setminus C) < \epsilon \lambda [0,1] B \subset [0,1] C \subset B f_{C} : C \to \mathbb R \lambda(B \setminus C) < \epsilon C \subset [0,1] f|_C : C \to \mathbb R C C_1 \subset [0,1] f|_{C_1} \lambda([0,1] \setminus C_1) < 2^{-1} \lambda(C_1) > 2^{-1} C_1 C_2 \subset [0,1] \setminus C_1 f|_{C_2} \lambda\left(\left([0,1]\setminus C_1\right)\setminus C_2\right) < 2^{-2} \lambda(C_1 \sqcup C_2) > 2^{-2} C_2 (C_n)_{n \geq 1} f|_{C_n} : C_n \to \mathbb R n \lambda\left(C_1 \sqcup C_2 \sqcup \cdots \sqcup C_n\right) > 1-2^{-n} \lambda C = \bigsqcup_{n\geq 1} C_n 
1 \geq \lambda(C) = \lim_{n \to \infty} \lambda\left(\mathop{\bigsqcup}_{k=1}^n C_k\right) \geq \lim_{n \to \infty}(1-2^{-n}) = 1.
 \lambda(C) = 1 C f f C C_n n \geq 2 (X, \mathcal A, \mu) [0,1]","['measure-theory', 'lebesgue-measure']"
67,"Completitude of $L^1[0,1]\cap L^2[0,1]$ with the maximumm norm",Completitude of  with the maximumm norm,"L^1[0,1]\cap L^2[0,1]","I am trying to prove from scratch that the space $L^1[0,1]\cap L^2[0,1]$ equipped with the norm: $$\left \| f \right \|=\max\{\left \| f \right \|_1,\left \| f \right \|_2\}$$ defines a Banach space, but I am having trouble checking completitude. I have considered the Cauchy sequence $\{f_n\}$ , and found that by completitude of $L^1[0,1]$ and $L^2[0,1]$ , there must be $f_0^1, f_0^2$ such that: $$\left \| f_n -f_0^1\right \|_1\rightarrow 0$$ $$\left \| f_n -f_0^2\right \|_2\rightarrow 0$$ But I don't know how to prove that $\left \| f_0^1-f_0^2 \right \|=0$ . Any ideas?","I am trying to prove from scratch that the space equipped with the norm: defines a Banach space, but I am having trouble checking completitude. I have considered the Cauchy sequence , and found that by completitude of and , there must be such that: But I don't know how to prove that . Any ideas?","L^1[0,1]\cap L^2[0,1] \left \| f \right \|=\max\{\left \| f \right \|_1,\left \| f \right \|_2\} \{f_n\} L^1[0,1] L^2[0,1] f_0^1, f_0^2 \left \| f_n -f_0^1\right \|_1\rightarrow 0 \left \| f_n -f_0^2\right \|_2\rightarrow 0 \left \| f_0^1-f_0^2 \right \|=0","['measure-theory', 'banach-spaces', 'lp-spaces']"
68,Is the Carathodory measurability criterion optimal in some sense?,Is the Carathodory measurability criterion optimal in some sense?,,"If $m$ is an outer measure defined on a set $X$, we say that a subset $E$ of $X$ is Carathodory-measurable with respect to $m$ if for all subsets $A$ of $X$, we have $m(A)=m(A\cap E) + m(A\cap E^c)$.  And if $M$ is the set of all Carathodory-measurable sets with respect to $m$, then $M$ is a complete sigma algebra on $X$ and $m$ restricted to $M$ is a complete measure on $X$. My question is, is $M$ ""optimal"" in some way?  Is it the biggest or smallest subset of $P(X)$ such that $m$ restricted to that subset is a measure?  Is it the biggest or smallest subset of $P(X)$ such that $m$ restricted to that subset is a complete measure? To put it another way, what is it that makes the Carathodory measurability criterion the ""best"" criterion for measurability?  Or is it not the best, but just an arbitrary choice out of a sea of infinitely many equally good stronger and weaker measurability criteria?","If $m$ is an outer measure defined on a set $X$, we say that a subset $E$ of $X$ is Carathodory-measurable with respect to $m$ if for all subsets $A$ of $X$, we have $m(A)=m(A\cap E) + m(A\cap E^c)$.  And if $M$ is the set of all Carathodory-measurable sets with respect to $m$, then $M$ is a complete sigma algebra on $X$ and $m$ restricted to $M$ is a complete measure on $X$. My question is, is $M$ ""optimal"" in some way?  Is it the biggest or smallest subset of $P(X)$ such that $m$ restricted to that subset is a measure?  Is it the biggest or smallest subset of $P(X)$ such that $m$ restricted to that subset is a complete measure? To put it another way, what is it that makes the Carathodory measurability criterion the ""best"" criterion for measurability?  Or is it not the best, but just an arbitrary choice out of a sea of infinitely many equally good stronger and weaker measurability criteria?",,"['measure-theory', 'lebesgue-measure', 'outer-measure']"
69,Why does Dominated Convergence Theorem fail in this example?,Why does Dominated Convergence Theorem fail in this example?,,"Given a measure space, $(\Omega = [0,1], \mathcal{F} = \mathcal{B}[0,1], P)$, my professor said in class that the limit of the following expectation could not be evaluated using Dominating Convergence Theorem: for $n \ge 2$, $$\lim_{n \to \infty} E\left(\cfrac{n}{\log n} \mathbb{1}_{[0,\frac{1}{n}]}(w)\right). $$ But does $\cfrac{n}{\log n} \mathbb{1}_{[0, \frac{1}{n}]}(w) \to 0$ as $n \to \infty$? Then should it be bounded by some variable in $L_1(P)$ and so DCT is applicable? Or am I missing anything?","Given a measure space, $(\Omega = [0,1], \mathcal{F} = \mathcal{B}[0,1], P)$, my professor said in class that the limit of the following expectation could not be evaluated using Dominating Convergence Theorem: for $n \ge 2$, $$\lim_{n \to \infty} E\left(\cfrac{n}{\log n} \mathbb{1}_{[0,\frac{1}{n}]}(w)\right). $$ But does $\cfrac{n}{\log n} \mathbb{1}_{[0, \frac{1}{n}]}(w) \to 0$ as $n \to \infty$? Then should it be bounded by some variable in $L_1(P)$ and so DCT is applicable? Or am I missing anything?",,"['measure-theory', 'examples-counterexamples']"
70,Completion and outer-measure extension of sigma finite measure,Completion and outer-measure extension of sigma finite measure,,"I need some help with the proof of the following. Let $(X,\mathcal{A},\mu)$ be a measure space with $\mu$ being $\sigma$ -finite, $\mu^*$ be the outer measure given by the formula $\mu^*(E)=\inf\{\sum_{n}\mu(A_n): E\subset\bigcup A_n, (A_n)\subset\mathcal{A}\}$ and $\mathcal{M}$ the $\sigma$ -algebra of the $\mu^*$ -measurable sets. Also let $\mathcal{A}_{\mu}=\{A\subset X: \exists E,F\in\mathcal{A},$ with $E\subset A\subset F$ and $  \mu(F\setminus E)=0\}$ and $\overline{\mu}:\mathcal{A}_\mu\to [0,+\infty]$ given by $\overline{\mu}(E)=\sup\{\mu(B): B\in\mathcal{A}, B\subset E\}.$ Then $\mathcal{A}_\mu=\mathcal{M}$ and $\overline{\mu}=\mu^*\vert_{\mathcal{M}}$ . Okay, so it is known that the measure space $(X,\mathcal{A}_\mu, \overline\mu)$ is the completion of $(X,\mathcal{A},\mu)$ and by the facts that $\mu^*\vert_\mathcal{A}=\mu$ and $\mathcal{A}\subset\mathcal{M}$ , we have that $\mathcal{A}_\mu\subset\mathcal{M}$ and that $\mu^*\vert_{\mathcal{A}_\mu}=\overline\mu$ . So in order to prove the statement above, it would be enough to show that $\mathcal{M}\subset\mathcal{A}_\mu$ . I'm trying to prove that if $A\in\mathcal{M}$ and $\mu^*(A)<\infty$ then $A\in\mathcal{A}_{\mu}$ but I'm stuck. My progress is the following: For each $n\in\mathbb{N}$ there exists a sequence $(A_k^{(n)})\subset\mathcal{A}$ such that $\sum_{k}\mu(A_k^{(n)})<\mu^*(A)+\frac{1}{n}$ . Let $A_n=\bigcup_{k}A_k^{(n)}\in\mathcal{A}$ . We have that $\mu(A_n)\leq\sum_{k}\mu(A_k^{(n)})<\mu^*(A)+\frac{1}{n}$ . Finally let $F=\bigcap_{n} A_n$ . Then $\mu(F)\leq\mu(A_n)<\mu^*(A)+\frac{1}{n}$ for all $n$ . Taking limits we have that $\mu(F)\leq\mu^*(A)$ , but $A\subset F$ , so $\mu^*(A)\leq\mu^*(F)=\mu(F)$ so we found the first desirable set. But what about the other? I'm stuck here and I can't seem to be able to use the sigma-finiteness. Any help? EDIT: Maybe considering the fact that the sigma-algebra $\mathcal{A}_1=\{A\cup E: A\in\mathcal{A}, E\subset F,$ where $F\in\mathcal{A}, \mu(F)=0\}$ is equal to $\mathcal{A}_\mu$ helps. It is easy to show this equality.","I need some help with the proof of the following. Let be a measure space with being -finite, be the outer measure given by the formula and the -algebra of the -measurable sets. Also let with and and given by Then and . Okay, so it is known that the measure space is the completion of and by the facts that and , we have that and that . So in order to prove the statement above, it would be enough to show that . I'm trying to prove that if and then but I'm stuck. My progress is the following: For each there exists a sequence such that . Let . We have that . Finally let . Then for all . Taking limits we have that , but , so so we found the first desirable set. But what about the other? I'm stuck here and I can't seem to be able to use the sigma-finiteness. Any help? EDIT: Maybe considering the fact that the sigma-algebra where is equal to helps. It is easy to show this equality.","(X,\mathcal{A},\mu) \mu \sigma \mu^* \mu^*(E)=\inf\{\sum_{n}\mu(A_n): E\subset\bigcup A_n, (A_n)\subset\mathcal{A}\} \mathcal{M} \sigma \mu^* \mathcal{A}_{\mu}=\{A\subset X: \exists E,F\in\mathcal{A}, E\subset A\subset F   \mu(F\setminus E)=0\} \overline{\mu}:\mathcal{A}_\mu\to [0,+\infty] \overline{\mu}(E)=\sup\{\mu(B): B\in\mathcal{A}, B\subset E\}. \mathcal{A}_\mu=\mathcal{M} \overline{\mu}=\mu^*\vert_{\mathcal{M}} (X,\mathcal{A}_\mu, \overline\mu) (X,\mathcal{A},\mu) \mu^*\vert_\mathcal{A}=\mu \mathcal{A}\subset\mathcal{M} \mathcal{A}_\mu\subset\mathcal{M} \mu^*\vert_{\mathcal{A}_\mu}=\overline\mu \mathcal{M}\subset\mathcal{A}_\mu A\in\mathcal{M} \mu^*(A)<\infty A\in\mathcal{A}_{\mu} n\in\mathbb{N} (A_k^{(n)})\subset\mathcal{A} \sum_{k}\mu(A_k^{(n)})<\mu^*(A)+\frac{1}{n} A_n=\bigcup_{k}A_k^{(n)}\in\mathcal{A} \mu(A_n)\leq\sum_{k}\mu(A_k^{(n)})<\mu^*(A)+\frac{1}{n} F=\bigcap_{n} A_n \mu(F)\leq\mu(A_n)<\mu^*(A)+\frac{1}{n} n \mu(F)\leq\mu^*(A) A\subset F \mu^*(A)\leq\mu^*(F)=\mu(F) \mathcal{A}_1=\{A\cup E: A\in\mathcal{A}, E\subset F, F\in\mathcal{A}, \mu(F)=0\} \mathcal{A}_\mu","['measure-theory', 'outer-measure']"
71,Most Markov chain definitions are false,Most Markov chain definitions are false,,"When introducing discrete, time-homogenouos Markov chains $(X_n)_{n\geq 0}$, a lot of introductory lecture notes simply seem to assume the existence of a probability measure $\mathbb{P}$  on the common domain $\Omega$ of the $X_n$, given the  distribution of $X_0$ and the transition matrix $T$. (We need $\mathbb{P}$  to talk about things like $$\mathbb{P}(X_7=u \land X_{23}=v)$$ resp. $$\mathbb{P}((X_n)_{n\geq 0}=(s_n)_{n\geq 0}),$$for some $u,v$ from the state space $S$ resp.  a sequence of values $(s_n)_{n\geq 0}$ ins $S$, a measure $\mathbb{P}$ is required.) Only one set of lecture notes , out of many that I've consulted, have in passing mentioned that there is a thing such as the Ionescu-Tulcea theorem that shows that such probability measure $\mathbb{P}$ indeed exist (hence the title). This theorem is interestingly is not yet on Wikipedia - only on the german Wikipedia .The theorem is way above my head to understand it, as it is formulated. My questions are: Do we really need this theorem? If most lectures notes gloss over it, perhaps it is trivial that $\mathbb{P}$ exists? Since the Ionescu-Tulcea theorem seems to apply for general Markov chains, does its statement (which I don't fully understand currently) and proof perhaps simplify significantly for discrete, time-homogenuous Markov chains (perhaps if we additionally assume a finite state space)? I'd be very happy, if I could understand it's proof.","When introducing discrete, time-homogenouos Markov chains $(X_n)_{n\geq 0}$, a lot of introductory lecture notes simply seem to assume the existence of a probability measure $\mathbb{P}$  on the common domain $\Omega$ of the $X_n$, given the  distribution of $X_0$ and the transition matrix $T$. (We need $\mathbb{P}$  to talk about things like $$\mathbb{P}(X_7=u \land X_{23}=v)$$ resp. $$\mathbb{P}((X_n)_{n\geq 0}=(s_n)_{n\geq 0}),$$for some $u,v$ from the state space $S$ resp.  a sequence of values $(s_n)_{n\geq 0}$ ins $S$, a measure $\mathbb{P}$ is required.) Only one set of lecture notes , out of many that I've consulted, have in passing mentioned that there is a thing such as the Ionescu-Tulcea theorem that shows that such probability measure $\mathbb{P}$ indeed exist (hence the title). This theorem is interestingly is not yet on Wikipedia - only on the german Wikipedia .The theorem is way above my head to understand it, as it is formulated. My questions are: Do we really need this theorem? If most lectures notes gloss over it, perhaps it is trivial that $\mathbb{P}$ exists? Since the Ionescu-Tulcea theorem seems to apply for general Markov chains, does its statement (which I don't fully understand currently) and proof perhaps simplify significantly for discrete, time-homogenuous Markov chains (perhaps if we additionally assume a finite state space)? I'd be very happy, if I could understand it's proof.",,"['measure-theory', 'probability-distributions']"
72,"Using test functions to ""test"" whether functions vanish","Using test functions to ""test"" whether functions vanish",,"Let $U$ be an open subset of $\mathbb R^n$ and let $f \in L_{\text {loc}}^1(U)$ (i.e. $f$ is integrable on compact subsets of $U$). Suppose $\int_U f \phi = 0$ for all test functions $\phi \in C_c^\infty(U)$. Does this imply that $f = 0$ a.e.? If so, why? I ask this question because I'm learning about analysis of PDEs from Evans' textbook. This fact, or something similar to it, is used everywhere, but I can't think of a rigorous proof for it. One approach I tried is to approximate indicator functions on arbitrary measurable subsets of $U$ by their mollifications, but I haven't managed to get this to work. I wonder if there is a better method.","Let $U$ be an open subset of $\mathbb R^n$ and let $f \in L_{\text {loc}}^1(U)$ (i.e. $f$ is integrable on compact subsets of $U$). Suppose $\int_U f \phi = 0$ for all test functions $\phi \in C_c^\infty(U)$. Does this imply that $f = 0$ a.e.? If so, why? I ask this question because I'm learning about analysis of PDEs from Evans' textbook. This fact, or something similar to it, is used everywhere, but I can't think of a rigorous proof for it. One approach I tried is to approximate indicator functions on arbitrary measurable subsets of $U$ by their mollifications, but I haven't managed to get this to work. I wonder if there is a better method.",,"['measure-theory', 'partial-differential-equations']"
73,Is every measurable set a measure-independent limit of open sets,Is every measurable set a measure-independent limit of open sets,,"My main question is Q1. Let $B$ be a Borel-measurable subset of $\mathbb R$. Is   there a sequence of open sets $U_n$ independent of any measure such that for all Borel probability measures $\mu$ on $\mathbb R$, $\mu(B \Delta U_n) \to 0$? Any open set is trivially a measure-independent limit of open sets. Any closed set is an intersection of a nested sequence of open sets and hence is a measure-independent limit. I wonder if Q1 can be answered negatively by showing that $\mathbb Q$ is a counter example. Q1a. Is $\mathbb Q$ a counter example? If $B$ is a measure-independent limit of $U_n$ then $1_B$ is a pointwise-limit of the sequence $1_{U_n}$ because of Dirac delta measures. Maybe this can be used to show that $\mathbb Q$ is a counter example, but I don't know how. Motivation: last paragraph of the question in https://mathoverflow.net/questions/167823/the-borel-sigma-algebra-of-the-set-of-probability-measures?rq=1","My main question is Q1. Let $B$ be a Borel-measurable subset of $\mathbb R$. Is   there a sequence of open sets $U_n$ independent of any measure such that for all Borel probability measures $\mu$ on $\mathbb R$, $\mu(B \Delta U_n) \to 0$? Any open set is trivially a measure-independent limit of open sets. Any closed set is an intersection of a nested sequence of open sets and hence is a measure-independent limit. I wonder if Q1 can be answered negatively by showing that $\mathbb Q$ is a counter example. Q1a. Is $\mathbb Q$ a counter example? If $B$ is a measure-independent limit of $U_n$ then $1_B$ is a pointwise-limit of the sequence $1_{U_n}$ because of Dirac delta measures. Maybe this can be used to show that $\mathbb Q$ is a counter example, but I don't know how. Motivation: last paragraph of the question in https://mathoverflow.net/questions/167823/the-borel-sigma-algebra-of-the-set-of-probability-measures?rq=1",,"['measure-theory', 'descriptive-set-theory']"
74,Non-measurable set $A$ such that every measurable subset of $A$ or $A^c$ has measure zero,Non-measurable set  such that every measurable subset of  or  has measure zero,A A A^c,I want to show the following: There is $A \subset \mathbb{R}$ such that both are satisfied: if $E \subset A$ is a Lebesgue measurable set then $\lambda(E) = 0$ if $E \subset A^c$ is a Lebesgue measurable set then $\lambda(E) = 0$ where $\lambda$ is the Lebesgue measure on the real line. Do you know how to show that such a set exists? Also a reference would be appreciated. Thank you :) ps: if you find a better title feel free to modify it!,I want to show the following: There is $A \subset \mathbb{R}$ such that both are satisfied: if $E \subset A$ is a Lebesgue measurable set then $\lambda(E) = 0$ if $E \subset A^c$ is a Lebesgue measurable set then $\lambda(E) = 0$ where $\lambda$ is the Lebesgue measure on the real line. Do you know how to show that such a set exists? Also a reference would be appreciated. Thank you :) ps: if you find a better title feel free to modify it!,,['measure-theory']
75,Homogenous measure on the positive real halfline,Homogenous measure on the positive real halfline,,"Define a measure $\mu\not=0$ on positive real number $\Bbb R_{>0}$ such that for any measurable set $E\subset\Bbb R_{>0}$ and $a\in \Bbb R_{>0} $, we have $\mu(aE)= \mu(E)$, where $aE=[ax;x\in E]$. I am totally blank about this problem. I ponder on it several times but didn't get any idea. This exercise illustrates lebesgue measure's abstract and weird nature. Because if we assume E as a subset of real numbers or any interval, it totally disagrees to fulfill this translation.","Define a measure $\mu\not=0$ on positive real number $\Bbb R_{>0}$ such that for any measurable set $E\subset\Bbb R_{>0}$ and $a\in \Bbb R_{>0} $, we have $\mu(aE)= \mu(E)$, where $aE=[ax;x\in E]$. I am totally blank about this problem. I ponder on it several times but didn't get any idea. This exercise illustrates lebesgue measure's abstract and weird nature. Because if we assume E as a subset of real numbers or any interval, it totally disagrees to fulfill this translation.",,"['measure-theory', 'lebesgue-integral', 'geometric-measure-theory']"
76,Problem with the Lebesgue integral of Dirichlet function,Problem with the Lebesgue integral of Dirichlet function,,"According to all sources $\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=0$ (Lebesgue integral out of Dirichlet funtion). However, below I constructed a sequence of functions ${{f}_{n}}$ which converges to $\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=\Phi (x)$ and ${{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)=\Phi (x)$ $\underset{n\to \infty }{\mathop{\lim }}\,\int\limits_{[0,1]}{{{f}_{n}}(x)}dx=\int\limits_{[0,1]}{\Phi (x)}dx=p\in (0,1)$ so $p$ is an arbitrary number from the interval (0,1). This is a contradiction because $\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=0$. Maybe somebody will be able to find a problem in my reasoning ... The biggest problem in the method is the assumption that [\Phi (x)=0] for $x$ which is irrational number in the interval [0,1]. In my opinion I proved that it is true. Do you agree with my reasoning (see below for details). Let us consider characteristic function of the set $\mathbb{Q}\cap [0,1]$ (Dirichlet funtion) ${{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)=\left\{ \begin{align}   & 1\text{ for }x\in \mathbb{Q}\cap [0,1] \\   & 0\text{ for }x\notin \mathbb{Q}\cap [0,1] \\  \end{align} \right.$ Let $\left\{ {{a}_{i}} \right\}_{i=1}^{\infty }$ be a sequence which contains all rational numbers i.e. $\mathbb{Q}=\bigcup\limits_{i=1}^{\infty }{\left\{ {{a}_{i}} \right\}}$. Lets define the following function ${{f}_{n}}(x)=\left\{ \begin{align}   & 1\text{ if }\underset{i\in \{1,...,n\}}{\mathop{\exists }}\,x\in \left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right] \\   & 0\text{ otherwise} \\  \end{align} \right.$ where  $\delta _{i,n}^{+}-\delta _{i,n}^{-}={{\delta }_{n}}$ and $p=\sum\limits_{i=1}^{n}{{{\delta }_{n}}}=\sum\limits_{i=1}^{n}{\left( \delta _{i,n}^{+}-\delta _{i,n}^{-} \right)}$ and $p\in (0,1)$. For every sequence of rational numbers $\left\{ {{a}_{i}} \right\}_{i=1}^{\infty }$ and $1>p>0$ it is possible to construct the intervals $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]$ such that $p=\sum\limits_{i=1}^{n}{{{\delta }_{n}}}=\sum\limits_{i=1}^{n}{\left( \delta _{i,n}^{+}-\delta _{i,n}^{-} \right)}$ and $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]\cap \left[ {{a}_{j}}-\delta _{j,n}^{-},{{a}_{j}}+\delta _{j,n}^{+} \right]=\varnothing $. In order to do that first it is necessary to construct a sequence of intervals $\left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$ such that $1=\sum\limits_{i=1}^{n}{{{\varepsilon }_{n}}}=\sum\limits_{i=1}^{n}{\left( \varepsilon _{i,n}^{+}-\varepsilon _{i,n}^{-} \right)}$ and $\left( {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right)\cap \left( {{a}_{j}}-\varepsilon _{j,n}^{-},{{a}_{j}}+\varepsilon _{j,n}^{+} \right)=\varnothing $. For any fixed $n>1$ it is possible to order all $\{{{a}_{1}},...,{{a}_{n}}\}$ such that ${{a}_{{{\alpha }_{1}}}}<{{a}_{{{\alpha }_{2}}}}<...<{{a}_{{{\alpha }_{n}}}}$. Now we can define the following numbers $\varepsilon _{1}^{-}={{a}_{{{\alpha }_{1}}}}$ $\varepsilon _{1}^{+}=\frac{{{a}_{{{\alpha }_{1}}}}+{{a}_{{{\alpha }_{2}}}}}{2}$ ${{\varepsilon }_{1}}=\varepsilon _{1}^{-}+\varepsilon _{1}^{+}$ $\varepsilon _{2}^{-}=\frac{{{a}_{{{\alpha }_{1}}}}+{{a}_{{{\alpha }_{2}}}}}{2}$ $\varepsilon _{2}^{+}=\frac{{{a}_{{{\alpha }_{2}}}}+{{a}_{{{\alpha }_{3}}}}}{2}$ ${{\varepsilon }_{2}}=\varepsilon _{2}^{-}+\varepsilon _{2}^{+}$ ... $\varepsilon _{n-1}^{-}=\frac{{{a}_{{{\alpha }_{n-2}}}}+{{a}_{{{\alpha }_{n-1}}}}}{2}$ $\varepsilon _{n-1}^{+}=\frac{{{a}_{{{\alpha }_{n-1}}}}+{{a}_{{{\alpha }_{n}}}}}{2}$ ${{\varepsilon }_{n-1}}=\varepsilon _{n-1}^{-}+\varepsilon _{n-1}^{+}$ $\varepsilon _{n}^{-}=\frac{{{a}_{{{\alpha }_{n-1}}}}+{{a}_{{{\alpha }_{n}}}}}{2}$ $\varepsilon _{n}^{+}=1-{{a}_{{{\alpha }_{n}}}}$ ${{\varepsilon }_{n}}=\varepsilon _{n}^{-}+\varepsilon _{n}^{+}$ It is possible to see that $\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}=1$ $\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}={{\varepsilon }_{1}}+{{\varepsilon }_{2}}+...+{{\varepsilon }_{n-1}}+{{\varepsilon }_{n}}=(\varepsilon _{1}^{-}+\varepsilon _{1}^{+})+(\varepsilon _{2}^{-}+\varepsilon _{2}^{+})+...+(\varepsilon _{n-1}^{-}+\varepsilon _{n-1}^{+})+(\varepsilon _{n}^{-}+\varepsilon _{n}^{+})=$ $=\left( {{a}_{{{\alpha }_{1}}}}+\frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2} \right)+\left( \frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2} \right)+\left( \frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2} \right.+...+\left. \frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2} \right)+$ $+\left( \frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2} \right)+\left( \frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2}+1-{{a}_{{{\alpha }_{n}}}} \right)=$ $={{a}_{{{\alpha }_{1}}}}+\frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2}+...$ $+\frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2}+\frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2}$ $+\frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2}+1-{{a}_{{{\alpha }_{n}}}}=$ $={{a}_{{{\alpha }_{1}}}}-\frac{{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{2}}}}}{2}-\frac{{{a}_{{{\alpha }_{2}}}}}{2}+\frac{{{a}_{{{\alpha }_{1}}}}}{2}-\frac{{{a}_{{{\alpha }_{3}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}}{2}+...$ $+\frac{{{a}_{{{\alpha }_{n-2}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}+\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-2}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}+1-{{a}_{{{\alpha }_{n}}}}=$ $={{a}_{{{\alpha }_{1}}}}-{{a}_{{{\alpha }_{1}}}}+{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{2}}}}+...+{{a}_{{{\alpha }_{n}}-1}}-{{a}_{{{\alpha }_{n-1}}}}+{{a}_{{{\alpha }_{n}}}}+1-{{a}_{{{\alpha }_{n}}}}=1$ In every interval $\left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$ it is possible to find subintervals $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]$ such that $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]\subset \left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$ and $p=\sum\limits_{i=1}^{n}{l\left( \left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right] \right)}=\sum\limits_{i=1}^{n}{\left( \delta _{i,n}^{+}-\delta _{i,n}^{-} \right)}=\sum\limits_{i=1}^{n}{{{\delta }_{i,n}}}$. In order to do that it is enough to assume that ${{\delta }_{i,n}}=p{{\varepsilon }_{i,n}}$ or $\delta _{i,n}^{-}=p\varepsilon _{i,n}^{-},\delta _{i,n}^{+}=p\varepsilon _{i,n}^{+}$. Verification $\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}=1$ $\sum\limits_{i=1}^{n}{{{\delta }_{i}}}=\sum\limits_{i=1}^{n}{p{{\varepsilon }_{i}}}=p\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}=p1=p$ additionally because $p\varepsilon _{i,n}^{-}<\varepsilon _{i,n}^{-}$ and $p\varepsilon _{i,n}^{+}<\varepsilon _{i,n}^{+}$ then $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]=\left[ {{a}_{i}}-p\varepsilon _{i,n}^{-},{{a}_{i}}+p\varepsilon _{i,n}^{+} \right]\subset \left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$. Because of that for each $n$ $\int\limits_{[0,1]}{{{f}_{n}}(x)dx}=\sum\limits_{i=1}^{n}{{{\delta }_{n}}}=p$ then  $\underset{n\to \infty }{\mathop{\lim }}\,\int\limits_{[0,1]}{{{f}_{n}}(x)dx}=\underset{n\to \infty }{\mathop{\lim }}\,p=p\in (0,1)$ Because set $\mathbb{Q}\cap [0,1]$ is dense in [0,1] then $\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-}=0$, $\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{+}=0$. For every fixed ${{a}_{i}}$ we have $\underset{n\to \infty }{\mathop{\lim }}\,\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]=\left[ {{a}_{i}}-\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-},{{a}_{i}}+\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-} \right]=\left[ {{a}_{i}}-0,{{a}_{i}}+0 \right]=\{{{a}_{i}}\}$ $\underset{n\to \infty }{\mathop{\lim }}\,\bigcup\limits_{i=1}^{n}{\left[ {{a}_{i}}-{{\delta }_{n}},{{a}_{i}}+{{\delta }_{n}} \right]}=\{{{a}_{i}}\}_{i=1}^{\infty }=\mathbb{Q}\cap [0,1]$ Let $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)$ and x is a rational nuber in the interval [0,1] then $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=1$   for   $x\in \mathbb{Q}\cap [0,1]$ In limit case $\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-}=\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-}=0$ then function $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)$ is 1 only for rational numbers consequently $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=0$ for x which is an irrational number in the interval [0,1] i.e. $x\in R\backslash \left( \mathbb{Q}\cap [0,1] \right)$ then $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=0$ Because of that  $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)={{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)$ According to the definition of the Lebesgue integral we have $\underset{n\to \infty }{\mathop{\lim }}\,\int\limits_{[0,1]}{{{f}_{n}}(x)}dx=\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=p\in (0,1)$ which is a contradiction because $\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=0$.","According to all sources $\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=0$ (Lebesgue integral out of Dirichlet funtion). However, below I constructed a sequence of functions ${{f}_{n}}$ which converges to $\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=\Phi (x)$ and ${{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)=\Phi (x)$ $\underset{n\to \infty }{\mathop{\lim }}\,\int\limits_{[0,1]}{{{f}_{n}}(x)}dx=\int\limits_{[0,1]}{\Phi (x)}dx=p\in (0,1)$ so $p$ is an arbitrary number from the interval (0,1). This is a contradiction because $\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=0$. Maybe somebody will be able to find a problem in my reasoning ... The biggest problem in the method is the assumption that [\Phi (x)=0] for $x$ which is irrational number in the interval [0,1]. In my opinion I proved that it is true. Do you agree with my reasoning (see below for details). Let us consider characteristic function of the set $\mathbb{Q}\cap [0,1]$ (Dirichlet funtion) ${{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)=\left\{ \begin{align}   & 1\text{ for }x\in \mathbb{Q}\cap [0,1] \\   & 0\text{ for }x\notin \mathbb{Q}\cap [0,1] \\  \end{align} \right.$ Let $\left\{ {{a}_{i}} \right\}_{i=1}^{\infty }$ be a sequence which contains all rational numbers i.e. $\mathbb{Q}=\bigcup\limits_{i=1}^{\infty }{\left\{ {{a}_{i}} \right\}}$. Lets define the following function ${{f}_{n}}(x)=\left\{ \begin{align}   & 1\text{ if }\underset{i\in \{1,...,n\}}{\mathop{\exists }}\,x\in \left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right] \\   & 0\text{ otherwise} \\  \end{align} \right.$ where  $\delta _{i,n}^{+}-\delta _{i,n}^{-}={{\delta }_{n}}$ and $p=\sum\limits_{i=1}^{n}{{{\delta }_{n}}}=\sum\limits_{i=1}^{n}{\left( \delta _{i,n}^{+}-\delta _{i,n}^{-} \right)}$ and $p\in (0,1)$. For every sequence of rational numbers $\left\{ {{a}_{i}} \right\}_{i=1}^{\infty }$ and $1>p>0$ it is possible to construct the intervals $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]$ such that $p=\sum\limits_{i=1}^{n}{{{\delta }_{n}}}=\sum\limits_{i=1}^{n}{\left( \delta _{i,n}^{+}-\delta _{i,n}^{-} \right)}$ and $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]\cap \left[ {{a}_{j}}-\delta _{j,n}^{-},{{a}_{j}}+\delta _{j,n}^{+} \right]=\varnothing $. In order to do that first it is necessary to construct a sequence of intervals $\left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$ such that $1=\sum\limits_{i=1}^{n}{{{\varepsilon }_{n}}}=\sum\limits_{i=1}^{n}{\left( \varepsilon _{i,n}^{+}-\varepsilon _{i,n}^{-} \right)}$ and $\left( {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right)\cap \left( {{a}_{j}}-\varepsilon _{j,n}^{-},{{a}_{j}}+\varepsilon _{j,n}^{+} \right)=\varnothing $. For any fixed $n>1$ it is possible to order all $\{{{a}_{1}},...,{{a}_{n}}\}$ such that ${{a}_{{{\alpha }_{1}}}}<{{a}_{{{\alpha }_{2}}}}<...<{{a}_{{{\alpha }_{n}}}}$. Now we can define the following numbers $\varepsilon _{1}^{-}={{a}_{{{\alpha }_{1}}}}$ $\varepsilon _{1}^{+}=\frac{{{a}_{{{\alpha }_{1}}}}+{{a}_{{{\alpha }_{2}}}}}{2}$ ${{\varepsilon }_{1}}=\varepsilon _{1}^{-}+\varepsilon _{1}^{+}$ $\varepsilon _{2}^{-}=\frac{{{a}_{{{\alpha }_{1}}}}+{{a}_{{{\alpha }_{2}}}}}{2}$ $\varepsilon _{2}^{+}=\frac{{{a}_{{{\alpha }_{2}}}}+{{a}_{{{\alpha }_{3}}}}}{2}$ ${{\varepsilon }_{2}}=\varepsilon _{2}^{-}+\varepsilon _{2}^{+}$ ... $\varepsilon _{n-1}^{-}=\frac{{{a}_{{{\alpha }_{n-2}}}}+{{a}_{{{\alpha }_{n-1}}}}}{2}$ $\varepsilon _{n-1}^{+}=\frac{{{a}_{{{\alpha }_{n-1}}}}+{{a}_{{{\alpha }_{n}}}}}{2}$ ${{\varepsilon }_{n-1}}=\varepsilon _{n-1}^{-}+\varepsilon _{n-1}^{+}$ $\varepsilon _{n}^{-}=\frac{{{a}_{{{\alpha }_{n-1}}}}+{{a}_{{{\alpha }_{n}}}}}{2}$ $\varepsilon _{n}^{+}=1-{{a}_{{{\alpha }_{n}}}}$ ${{\varepsilon }_{n}}=\varepsilon _{n}^{-}+\varepsilon _{n}^{+}$ It is possible to see that $\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}=1$ $\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}={{\varepsilon }_{1}}+{{\varepsilon }_{2}}+...+{{\varepsilon }_{n-1}}+{{\varepsilon }_{n}}=(\varepsilon _{1}^{-}+\varepsilon _{1}^{+})+(\varepsilon _{2}^{-}+\varepsilon _{2}^{+})+...+(\varepsilon _{n-1}^{-}+\varepsilon _{n-1}^{+})+(\varepsilon _{n}^{-}+\varepsilon _{n}^{+})=$ $=\left( {{a}_{{{\alpha }_{1}}}}+\frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2} \right)+\left( \frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2} \right)+\left( \frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2} \right.+...+\left. \frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2} \right)+$ $+\left( \frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2} \right)+\left( \frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2}+1-{{a}_{{{\alpha }_{n}}}} \right)=$ $={{a}_{{{\alpha }_{1}}}}+\frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}-{{a}_{{{\alpha }_{2}}}}}{2}+...$ $+\frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2}+\frac{{{a}_{{{\alpha }_{n-1}}}}-{{a}_{{{\alpha }_{n-2}}}}}{2}$ $+\frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}-{{a}_{{{\alpha }_{n-1}}}}}{2}+1-{{a}_{{{\alpha }_{n}}}}=$ $={{a}_{{{\alpha }_{1}}}}-\frac{{{a}_{{{\alpha }_{1}}}}}{2}+\frac{{{a}_{{{\alpha }_{2}}}}}{2}-\frac{{{a}_{{{\alpha }_{2}}}}}{2}+\frac{{{a}_{{{\alpha }_{1}}}}}{2}-\frac{{{a}_{{{\alpha }_{3}}}}}{2}+\frac{{{a}_{{{\alpha }_{3}}}}}{2}+...$ $+\frac{{{a}_{{{\alpha }_{n-2}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}+\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-2}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}+\frac{{{a}_{{{\alpha }_{n}}}}}{2}-\frac{{{a}_{{{\alpha }_{n-1}}}}}{2}+1-{{a}_{{{\alpha }_{n}}}}=$ $={{a}_{{{\alpha }_{1}}}}-{{a}_{{{\alpha }_{1}}}}+{{a}_{{{\alpha }_{2}}}}-{{a}_{{{\alpha }_{2}}}}+...+{{a}_{{{\alpha }_{n}}-1}}-{{a}_{{{\alpha }_{n-1}}}}+{{a}_{{{\alpha }_{n}}}}+1-{{a}_{{{\alpha }_{n}}}}=1$ In every interval $\left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$ it is possible to find subintervals $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]$ such that $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]\subset \left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$ and $p=\sum\limits_{i=1}^{n}{l\left( \left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right] \right)}=\sum\limits_{i=1}^{n}{\left( \delta _{i,n}^{+}-\delta _{i,n}^{-} \right)}=\sum\limits_{i=1}^{n}{{{\delta }_{i,n}}}$. In order to do that it is enough to assume that ${{\delta }_{i,n}}=p{{\varepsilon }_{i,n}}$ or $\delta _{i,n}^{-}=p\varepsilon _{i,n}^{-},\delta _{i,n}^{+}=p\varepsilon _{i,n}^{+}$. Verification $\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}=1$ $\sum\limits_{i=1}^{n}{{{\delta }_{i}}}=\sum\limits_{i=1}^{n}{p{{\varepsilon }_{i}}}=p\sum\limits_{i=1}^{n}{{{\varepsilon }_{i}}}=p1=p$ additionally because $p\varepsilon _{i,n}^{-}<\varepsilon _{i,n}^{-}$ and $p\varepsilon _{i,n}^{+}<\varepsilon _{i,n}^{+}$ then $\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]=\left[ {{a}_{i}}-p\varepsilon _{i,n}^{-},{{a}_{i}}+p\varepsilon _{i,n}^{+} \right]\subset \left[ {{a}_{i}}-\varepsilon _{i,n}^{-},{{a}_{i}}+\varepsilon _{i,n}^{+} \right]$. Because of that for each $n$ $\int\limits_{[0,1]}{{{f}_{n}}(x)dx}=\sum\limits_{i=1}^{n}{{{\delta }_{n}}}=p$ then  $\underset{n\to \infty }{\mathop{\lim }}\,\int\limits_{[0,1]}{{{f}_{n}}(x)dx}=\underset{n\to \infty }{\mathop{\lim }}\,p=p\in (0,1)$ Because set $\mathbb{Q}\cap [0,1]$ is dense in [0,1] then $\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-}=0$, $\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{+}=0$. For every fixed ${{a}_{i}}$ we have $\underset{n\to \infty }{\mathop{\lim }}\,\left[ {{a}_{i}}-\delta _{i,n}^{-},{{a}_{i}}+\delta _{i,n}^{+} \right]=\left[ {{a}_{i}}-\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-},{{a}_{i}}+\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-} \right]=\left[ {{a}_{i}}-0,{{a}_{i}}+0 \right]=\{{{a}_{i}}\}$ $\underset{n\to \infty }{\mathop{\lim }}\,\bigcup\limits_{i=1}^{n}{\left[ {{a}_{i}}-{{\delta }_{n}},{{a}_{i}}+{{\delta }_{n}} \right]}=\{{{a}_{i}}\}_{i=1}^{\infty }=\mathbb{Q}\cap [0,1]$ Let $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)$ and x is a rational nuber in the interval [0,1] then $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=1$   for   $x\in \mathbb{Q}\cap [0,1]$ In limit case $\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-}=\underset{n\to \infty }{\mathop{\lim }}\,\delta _{i,n}^{-}=0$ then function $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)$ is 1 only for rational numbers consequently $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=0$ for x which is an irrational number in the interval [0,1] i.e. $x\in R\backslash \left( \mathbb{Q}\cap [0,1] \right)$ then $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)=0$ Because of that  $\Phi (x)=\underset{n\to \infty }{\mathop{\lim }}\,{{f}_{n}}(x)={{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)$ According to the definition of the Lebesgue integral we have $\underset{n\to \infty }{\mathop{\lim }}\,\int\limits_{[0,1]}{{{f}_{n}}(x)}dx=\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=p\in (0,1)$ which is a contradiction because $\int\limits_{[0,1]}{{{\chi }_{\mathbb{Q}\cap [0,1]}}\left( x \right)}dx=0$.",,['measure-theory']
77,"What are the $n$-th degree minimal polynomials for $L^p([-1,1])$?",What are the -th degree minimal polynomials for ?,"n L^p([-1,1])","It is known (even by me) that the Chebyshev polynomial of degree $n$ (of the first kind) is the minimal polynomial in the space $L^{\infty}([-1,1])$ for a fixed $n$ and leading coefficient $2^{n-1}$ . However, what are the minimal polynomials for the $p$ -norm in general for a fixed $n$ ? Does there exist a general answer? This is my first question here and I apologize if it is not up to par. Feel free to edit, migrate or close it if necessary.","It is known (even by me) that the Chebyshev polynomial of degree (of the first kind) is the minimal polynomial in the space for a fixed and leading coefficient . However, what are the minimal polynomials for the -norm in general for a fixed ? Does there exist a general answer? This is my first question here and I apologize if it is not up to par. Feel free to edit, migrate or close it if necessary.","n L^{\infty}([-1,1]) n 2^{n-1} p n","['measure-theory', 'polynomials', 'normed-spaces']"
78,Rotation $x \to x+a \pmod 1$ of the circle is Ergodic if and only if $a$ is irrational,Rotation  of the circle is Ergodic if and only if  is irrational,x \to x+a \pmod 1 a,"I have a book, Ergodic problems of classical mechanics by Arnold/Avez, and in it they prove that rotation $Tx = x+a \pmod 1$ of the circle $M=\{x \pmod 1\}$ is Ergodic if and only if a is irrational. In it they use an earlier corollary that a system is ergodic if and only if any invariant measurable absolutely integrable function is constant a.e. So the start proof goes like this: Suppose $a$ is rational, then write $a=p/q$, $p,q$ coprime. Since $e^{2\pi qx}$ is nonconstant and measurable, $T$ is not ergodic. This is fine, but then how come I can't make a similar argument for irrational $a$? As in: Suppose $a$ is irrational, then $e^{2\pi x/a}$ is nonconstant, and it seems to be measurable and absolutely integrable. What did I do wrong?","I have a book, Ergodic problems of classical mechanics by Arnold/Avez, and in it they prove that rotation $Tx = x+a \pmod 1$ of the circle $M=\{x \pmod 1\}$ is Ergodic if and only if a is irrational. In it they use an earlier corollary that a system is ergodic if and only if any invariant measurable absolutely integrable function is constant a.e. So the start proof goes like this: Suppose $a$ is rational, then write $a=p/q$, $p,q$ coprime. Since $e^{2\pi qx}$ is nonconstant and measurable, $T$ is not ergodic. This is fine, but then how come I can't make a similar argument for irrational $a$? As in: Suppose $a$ is irrational, then $e^{2\pi x/a}$ is nonconstant, and it seems to be measurable and absolutely integrable. What did I do wrong?",,"['measure-theory', 'modular-arithmetic', 'circles', 'irrational-numbers', 'ergodic-theory']"
79,Change of variable within an integral of the Hausdorff measure,Change of variable within an integral of the Hausdorff measure,,"Let $T \colon \mathbb{R}^n \to \mathbb{R}^n$ be a linear map, $H^{m}$ be a Hausdorff measure. Is it true that $$   \int\limits_{T(M)} f(x) H^{m}(dx) = |\det{T}| \int\limits_{M} f(T(x)) H^{m}(dx) $$ where $f(x)$ is some continuous function?","Let $T \colon \mathbb{R}^n \to \mathbb{R}^n$ be a linear map, $H^{m}$ be a Hausdorff measure. Is it true that $$   \int\limits_{T(M)} f(x) H^{m}(dx) = |\det{T}| \int\limits_{M} f(T(x)) H^{m}(dx) $$ where $f(x)$ is some continuous function?",,"['measure-theory', 'geometric-measure-theory']"
80,Lebesgue measurable subset of $\mathbb{R}$ with given metric density at zero,Lebesgue measurable subset of  with given metric density at zero,\mathbb{R},"Let $0 \leq \alpha < \beta \leq 1$. I'm looking for an example of a Lebesgue measurable subset $E$ of $\mathbb{R}$ such that $$\liminf_{\delta \rightarrow 0} \frac{m(E \cap (-\delta,\delta))}{2\delta} = \alpha$$ but $$\limsup_{\delta \rightarrow 0} \frac{m(E \cap (-\delta,\delta))}{2\delta} = \beta$$ where $m$ is the Lebesgue measure on $\mathbb{R}$. Can someone give an example? Thank you, Malik","Let $0 \leq \alpha < \beta \leq 1$. I'm looking for an example of a Lebesgue measurable subset $E$ of $\mathbb{R}$ such that $$\liminf_{\delta \rightarrow 0} \frac{m(E \cap (-\delta,\delta))}{2\delta} = \alpha$$ but $$\limsup_{\delta \rightarrow 0} \frac{m(E \cap (-\delta,\delta))}{2\delta} = \beta$$ where $m$ is the Lebesgue measure on $\mathbb{R}$. Can someone give an example? Thank you, Malik",,['measure-theory']
81,A $\sigma$-algebra that is complete as a Boolean algebra?,A -algebra that is complete as a Boolean algebra?,\sigma,"This MO thread has several examples of complete Boolean algebras that are not isomorphic to $\sigma$ -algebra of sets. But what is a non-trivial example of a complete Boolean algebra that is isomorphic to a $\sigma$ -algebra of set as Boolean algebras? Equivalently, is there a $\sigma$ -algebra of set that is complete as a Boolean algebra? A trivial example is the power set algebra $\mathcal{P}(X)$ , or any algebra of set that is atomic and complete as Boolean algebra. Also, from the above post it seems a non-trivial example is probably not ccc. I am wondering if the tree algebra on some tree such as $2^{<\aleph_1}$ can help, but the tree algebra itself doesn't seem complete, or even $\sigma$ . Maybe we can consider its completion? Clarification: By a complete Boolean algebra I mean a Boolean algebra whose any subset has supremum. An algebra of set (on $X$ ) is a nonempty subset of $\mathcal{P}(X)$ closed under union and complementation. An algebra of set can be viewed as a Boolean algebra in an obvious way. Edit: Now I have the feeling that the Boolean completion of the poset $(2^{<\aleph_1},\supseteq)$ should does it. This is the poset of partial map from $\aleph_1$ to $\{0,1\}$ with countable domain, under inverse inclusion (the largest element being the empty map). Every branch in $2^{<\aleph_1}$ , equivalently every element in $2^{\aleph_1}$ , determines an $\sigma$ -complete ultrafilter in the Boolean completion because the branch has uncountable cofinality. The Boolean completion seems to be the regular-open algebra on $2^{\aleph_1}$ with countable support product topology. I'm not sure if it is extremally disconnected; probably not.","This MO thread has several examples of complete Boolean algebras that are not isomorphic to -algebra of sets. But what is a non-trivial example of a complete Boolean algebra that is isomorphic to a -algebra of set as Boolean algebras? Equivalently, is there a -algebra of set that is complete as a Boolean algebra? A trivial example is the power set algebra , or any algebra of set that is atomic and complete as Boolean algebra. Also, from the above post it seems a non-trivial example is probably not ccc. I am wondering if the tree algebra on some tree such as can help, but the tree algebra itself doesn't seem complete, or even . Maybe we can consider its completion? Clarification: By a complete Boolean algebra I mean a Boolean algebra whose any subset has supremum. An algebra of set (on ) is a nonempty subset of closed under union and complementation. An algebra of set can be viewed as a Boolean algebra in an obvious way. Edit: Now I have the feeling that the Boolean completion of the poset should does it. This is the poset of partial map from to with countable domain, under inverse inclusion (the largest element being the empty map). Every branch in , equivalently every element in , determines an -complete ultrafilter in the Boolean completion because the branch has uncountable cofinality. The Boolean completion seems to be the regular-open algebra on with countable support product topology. I'm not sure if it is extremally disconnected; probably not.","\sigma \sigma \sigma \mathcal{P}(X) 2^{<\aleph_1} \sigma X \mathcal{P}(X) (2^{<\aleph_1},\supseteq) \aleph_1 \{0,1\} 2^{<\aleph_1} 2^{\aleph_1} \sigma 2^{\aleph_1}","['measure-theory', 'set-theory', 'boolean-algebra']"
82,Is the diagonal still measurable in this product measure?,Is the diagonal still measurable in this product measure?,,"Is the diagonal $\Delta=\{(x,x)|x \in[0,1]\}$ still measurable in $\mathcal{B}([0,1])\times\mathcal{F}$ where $\mathcal{F}$ is the $\sigma$ -algebra formed by all sets of Lebesgue measure $0$ or $1$ in $[0,1]$ ? This problem comes to me when I want to prove that the indicator of $A$ is measurable in this question: https://mathoverflow.net/questions/176622/progressively-measurable-vs-adapted",Is the diagonal still measurable in where is the -algebra formed by all sets of Lebesgue measure or in ? This problem comes to me when I want to prove that the indicator of is measurable in this question: https://mathoverflow.net/questions/176622/progressively-measurable-vs-adapted,"\Delta=\{(x,x)|x
\in[0,1]\} \mathcal{B}([0,1])\times\mathcal{F} \mathcal{F} \sigma 0 1 [0,1] A","['measure-theory', 'lebesgue-measure']"
83,"For $W=\cup_{U\in\mathcal U} U$ show that there exists $U_1,\dots,U_n: \ \sum_{i=1}^n \lambda(U_i) > \frac{1 - \epsilon}{3^d}\lambda(W)$",For  show that there exists,"W=\cup_{U\in\mathcal U} U U_1,\dots,U_n: \ \sum_{i=1}^n \lambda(U_i) > \frac{1 - \epsilon}{3^d}\lambda(W)","I'm trying to solve the following, which is Exercise 13.15 in the book Probability Theory by A. Klenke. Let $C \subset \mathbb R^d $ be an open, bounded and convex set and assume that $$ \mathcal{U} \subset \left \{ x+rC: x \in \mathbb R^d, r>0 \right \} $$ is such that $$ W:= \bigcup_{U \in \mathcal{U}}U  $$ has finite Lebesgue measure $\lambda(W)$ . Show that for any $\epsilon > 0$ there exists finitely many pairwise disjoint sets $U_1, \dots, U_n$ such that $$ \sum_{i=1}^n \lambda(U_i) > \frac{1 - \epsilon}{3^d}\lambda(W). \tag 1 $$ Show by a counterexample that the condition of similarity of the open sets in $\mathcal{U} $ is essential. This is my approach: Given that the Lebesgue measure $\lambda$ is inner regular, pick a compact set $K \subset W$ such that $$ \lambda(W) - \epsilon < \lambda(K). $$ Since the open sets\footnote{We take it as given that $C$ is open implies that $x + rC$ is open.} in $\mathcal{U}$ covers $K$ and $K$ is compact there exists a finite number $m$ of them such that $U_i, \dots, U_m$ covers $K$ . Order the $U_i$ :s such that, if $$ U_i = x_i + r_iC, \qquad i=1, \dots m $$ then $r_1 \ge r_1 \ge \dots \ge r_m$ . Now, I have seen a similar Lemma in Rudin's Real and complex analysis (Lemma 7.3) where the sets $U_i$ are open balls $U_i = B(x_i,r_i)$ . In that case one may do as follows: to get a disjoint collection of sets we let $i_1=1$ , and then we discard every $U_j$ that intersects $U_{i_1}$ . Let $U_{i_2}$ be the first remaining $U_j$ (if any exists) and discard the remaining $U_j$ that intersects $U_{i_2}$ . Continuing this process gives a a collection of $n$ disjoint sets. Then one may claim that, $$ \bigcup_{i=1}^m x_i+ r_iC \subset \bigcup_{k=1}^n x_{i_k} + 3r_{i_k}C. $$ The conclusion then follows (for that Lemma) from $$ \lambda \left(B(x, 3r)\right) =3^d \lambda \left(B(x, r)\right)  $$ and subadditivity. I don't think the exact same argument works here but is there a similar approach to get at least pairwise disjoint sets in the case of this exercise? And further such that (1) holds? Secondly, what is the meaning of the last sentence in the exercise, ""Show by a counterexample that the condition of similarity of the open sets in $\mathcal{U} $ is essential.""? Much grateful for any help provided!","I'm trying to solve the following, which is Exercise 13.15 in the book Probability Theory by A. Klenke. Let be an open, bounded and convex set and assume that is such that has finite Lebesgue measure . Show that for any there exists finitely many pairwise disjoint sets such that Show by a counterexample that the condition of similarity of the open sets in is essential. This is my approach: Given that the Lebesgue measure is inner regular, pick a compact set such that Since the open sets\footnote{We take it as given that is open implies that is open.} in covers and is compact there exists a finite number of them such that covers . Order the :s such that, if then . Now, I have seen a similar Lemma in Rudin's Real and complex analysis (Lemma 7.3) where the sets are open balls . In that case one may do as follows: to get a disjoint collection of sets we let , and then we discard every that intersects . Let be the first remaining (if any exists) and discard the remaining that intersects . Continuing this process gives a a collection of disjoint sets. Then one may claim that, The conclusion then follows (for that Lemma) from and subadditivity. I don't think the exact same argument works here but is there a similar approach to get at least pairwise disjoint sets in the case of this exercise? And further such that (1) holds? Secondly, what is the meaning of the last sentence in the exercise, ""Show by a counterexample that the condition of similarity of the open sets in is essential.""? Much grateful for any help provided!","C \subset \mathbb R^d  
\mathcal{U} \subset \left \{ x+rC: x \in \mathbb R^d, r>0 \right \}
 
W:= \bigcup_{U \in \mathcal{U}}U 
 \lambda(W) \epsilon > 0 U_1, \dots, U_n 
\sum_{i=1}^n \lambda(U_i) > \frac{1 - \epsilon}{3^d}\lambda(W). \tag 1
 \mathcal{U}  \lambda K \subset W 
\lambda(W) - \epsilon < \lambda(K).
 C x + rC \mathcal{U} K K m U_i, \dots, U_m K U_i 
U_i = x_i + r_iC, \qquad i=1, \dots m
 r_1 \ge r_1 \ge \dots \ge r_m U_i U_i = B(x_i,r_i) i_1=1 U_j U_{i_1} U_{i_2} U_j U_j U_{i_2} n 
\bigcup_{i=1}^m x_i+ r_iC \subset \bigcup_{k=1}^n x_{i_k} + 3r_{i_k}C.
 
\lambda \left(B(x, 3r)\right) =3^d \lambda \left(B(x, r)\right) 
 \mathcal{U} ","['measure-theory', 'convex-analysis', 'lebesgue-measure', 'convex-geometry', 'combinatorial-geometry']"
84,Lebesgue Measure and Isometries on the Unit Square,Lebesgue Measure and Isometries on the Unit Square,,"This is a question I had on an exam from awhile ago and was rather curious about. ""Let $m$ denote the Lebesgue measure on the unit square $I^2 = [0,1]^2$. Define two mappings $S,T: I^2 \to I^2$ as follows: $S(x,y) = (y,x)$ and $T(x,y) = (x,\bar{y})$ where $\bar{y} = y + \frac{1}{\sqrt{2}}$ if $y \leq 1 - \frac{1}{\sqrt{2}}$ and $\bar{y} = y + \frac{1}{\sqrt{2}} - 1$ otherwise. Now suppose that $A \subset I^2$ is a measurable subset such that $S(A) = A$ and $T(A)=A$. Show that either $m(A) = 0$ or $m(A)=1$."" My thoughts/attempt: $S$ is a reflection of $I^2$ along the diagonal and $T$ is a translation of the $y$ coordinate ""up"" by $\frac{1}{\sqrt{2}}$. But if it were to translate $y$ too far; i.e. leave $I^2$, it loops around so we can think of these isometries acting on a cylinder where we identify the top and bottom of the square. On the other hand, $STS(x,y) = ST(y,x) = (x + \frac{1}{\sqrt{2}},y)$ (or the other expression, depending on what $x$ is). So $STS$ is a horizonal translation which also loops around so now, it seems we should think of $S,T$ as isometries on the torus. Now, this set $A$ is invariant under both maps as is $m$ so it makes intuitive sense that it should be either measure-theoretic large or small. Since $\frac{1}{\sqrt{2}}$ is irrational, if we apply our horizontal or vertical translations to a point $p \in A$ and consider its orbit, I believe its orbit should be dense in $I^2$. So suppose that $0 < m(A)$. It seems like on the one hand, we can ""cover"" all of $I^2$ by translations of $A$ since $A$ has positive measure; i.e. its orbit should have full measure $1$. On the other hand, $A$ is invariant under $S,T$ so it equals its orbit. I'm just not clear on how to prove this rigorously. My hunch is to use something like Lebesgue density. The definition of the density of $A$ at a point $p$ is (when the limit exists) $$D_A(p) = \lim_{r \to 0}\frac{m(A \cap B(r,p))}{m(B(r,p))}.$$ The Lebesgue Density Theorem says that if $E \subset \mathbb{R}^n$ is any Borel set, then for almost every point $p \in E$, $D_E(p) = 1$ and for almost every $p \notin E$, $D_E(p) = 0$. We can assume $E$ to be Borel as there is a theorem which basically allows us to write $E$ as some $G_\delta$ set minus a null set and $G_\delta$ sets are Borel. So let $p \in A$ be such a point where $D_A(p) = 1$. Let $\mathcal{O}(p)$ be the orbit set of $p$ under $S,T$. It seems that for each $q \in \mathcal{O}(p)$, $D_A(q) =1$ because we may take a small ball around $p$ and intersect that with $A$. Now apply some finite combination of $S,T$ to this intersection set; it is moved about but will still end up in the set $A$ and since these are rigid transformations, the measure of this intersection set should be the same. Moreover, this should hold for every small ball so the density ought to still be 1 around $q \in \mathcal{O}(p)$. But $\mathcal{O}(p)$ is dense in $I^2$, topologically. So for each point in a dense set in $I^2$, the Lebesgue density at that point is 1. Question: Can we conclude that since $$D_A(p) = \lim_{r \to 0}\frac{m(A \cap B(r,p))}{\pi r^2} = 1,$$ for sufficiently small $r$, for every $q \in \mathcal{O}(p)$, $m(A \cap B(r,q)) \approx \pi r^2$, for the same $r$? If so, can we say that the since the measure of $A$ locally is positive in a dense set, then $m(A) = 1$? Problem: If $q \in \mathcal{O}(p)$ happens to be a corner or edge point in the square, then maybe the density should be $\frac{1}{2}$ or $\frac{1}{4}$.","This is a question I had on an exam from awhile ago and was rather curious about. ""Let $m$ denote the Lebesgue measure on the unit square $I^2 = [0,1]^2$. Define two mappings $S,T: I^2 \to I^2$ as follows: $S(x,y) = (y,x)$ and $T(x,y) = (x,\bar{y})$ where $\bar{y} = y + \frac{1}{\sqrt{2}}$ if $y \leq 1 - \frac{1}{\sqrt{2}}$ and $\bar{y} = y + \frac{1}{\sqrt{2}} - 1$ otherwise. Now suppose that $A \subset I^2$ is a measurable subset such that $S(A) = A$ and $T(A)=A$. Show that either $m(A) = 0$ or $m(A)=1$."" My thoughts/attempt: $S$ is a reflection of $I^2$ along the diagonal and $T$ is a translation of the $y$ coordinate ""up"" by $\frac{1}{\sqrt{2}}$. But if it were to translate $y$ too far; i.e. leave $I^2$, it loops around so we can think of these isometries acting on a cylinder where we identify the top and bottom of the square. On the other hand, $STS(x,y) = ST(y,x) = (x + \frac{1}{\sqrt{2}},y)$ (or the other expression, depending on what $x$ is). So $STS$ is a horizonal translation which also loops around so now, it seems we should think of $S,T$ as isometries on the torus. Now, this set $A$ is invariant under both maps as is $m$ so it makes intuitive sense that it should be either measure-theoretic large or small. Since $\frac{1}{\sqrt{2}}$ is irrational, if we apply our horizontal or vertical translations to a point $p \in A$ and consider its orbit, I believe its orbit should be dense in $I^2$. So suppose that $0 < m(A)$. It seems like on the one hand, we can ""cover"" all of $I^2$ by translations of $A$ since $A$ has positive measure; i.e. its orbit should have full measure $1$. On the other hand, $A$ is invariant under $S,T$ so it equals its orbit. I'm just not clear on how to prove this rigorously. My hunch is to use something like Lebesgue density. The definition of the density of $A$ at a point $p$ is (when the limit exists) $$D_A(p) = \lim_{r \to 0}\frac{m(A \cap B(r,p))}{m(B(r,p))}.$$ The Lebesgue Density Theorem says that if $E \subset \mathbb{R}^n$ is any Borel set, then for almost every point $p \in E$, $D_E(p) = 1$ and for almost every $p \notin E$, $D_E(p) = 0$. We can assume $E$ to be Borel as there is a theorem which basically allows us to write $E$ as some $G_\delta$ set minus a null set and $G_\delta$ sets are Borel. So let $p \in A$ be such a point where $D_A(p) = 1$. Let $\mathcal{O}(p)$ be the orbit set of $p$ under $S,T$. It seems that for each $q \in \mathcal{O}(p)$, $D_A(q) =1$ because we may take a small ball around $p$ and intersect that with $A$. Now apply some finite combination of $S,T$ to this intersection set; it is moved about but will still end up in the set $A$ and since these are rigid transformations, the measure of this intersection set should be the same. Moreover, this should hold for every small ball so the density ought to still be 1 around $q \in \mathcal{O}(p)$. But $\mathcal{O}(p)$ is dense in $I^2$, topologically. So for each point in a dense set in $I^2$, the Lebesgue density at that point is 1. Question: Can we conclude that since $$D_A(p) = \lim_{r \to 0}\frac{m(A \cap B(r,p))}{\pi r^2} = 1,$$ for sufficiently small $r$, for every $q \in \mathcal{O}(p)$, $m(A \cap B(r,q)) \approx \pi r^2$, for the same $r$? If so, can we say that the since the measure of $A$ locally is positive in a dense set, then $m(A) = 1$? Problem: If $q \in \mathcal{O}(p)$ happens to be a corner or edge point in the square, then maybe the density should be $\frac{1}{2}$ or $\frac{1}{4}$.",,"['measure-theory', 'lebesgue-measure']"
85,Lipshitz function and measurable sets,Lipshitz function and measurable sets,,"I apologize if that question has been asked already. I can't figure out this problem: Let a function $f:[a,b]\rightarrow \mathbb{R}$ which be a Lipshitz function with a constant c, prove that it maps a set of Lebesgue measure zero onto a set of Lebesgue measure zero and a Lebesgue measurable set onto a lebesgue measurable set. Now, I managed to do the first part, but the part about measurable sets is not as easy for me. If I take an open subset of $[a,b]$ it will be open and bounded hence lebesgue measurable, but its image won't necessarily be open, it may be closed, though still bounded... would it necessarily be measurable? can't go further from here. I studied baby Rudin and Royden&Fitzpatrick, these books define measurable sets in different ways, can't fidure out which one to apply here...","I apologize if that question has been asked already. I can't figure out this problem: Let a function $f:[a,b]\rightarrow \mathbb{R}$ which be a Lipshitz function with a constant c, prove that it maps a set of Lebesgue measure zero onto a set of Lebesgue measure zero and a Lebesgue measurable set onto a lebesgue measurable set. Now, I managed to do the first part, but the part about measurable sets is not as easy for me. If I take an open subset of $[a,b]$ it will be open and bounded hence lebesgue measurable, but its image won't necessarily be open, it may be closed, though still bounded... would it necessarily be measurable? can't go further from here. I studied baby Rudin and Royden&Fitzpatrick, these books define measurable sets in different ways, can't fidure out which one to apply here...",,"['measure-theory', 'lebesgue-measure', 'measurable-sets']"
86,Disintegration of Haar measures,Disintegration of Haar measures,,"Suppose I have a locally compact group $G$ and a quotient map $f:G\to G/N$. Is it true that for every Borel-measurable function $f : G  [0, +]$, $$\int_{G} f(g) \, \mathrm{d} \mu_G (g) = \int_{G/N} \int_{N}    f(gn) \, \mathrm{d} \mu_{N} (n) \mathrm{d} \mu_{G/N} (gN),$$ where $\mathrm{d} \mu_{G}$, $\mathrm{d} \mu_{N}$ and $\mathrm{d} \mu_{G/N}$ are the Haar measures on $G$, $N$ and $G/N$ respectively? In particular, is it true that if a subset $A\subseteq G$ is such that its intersection with $\mathrm{d}\mu_{G/N}$-almost every coset $gN$ is of full measure in $gN$ (w.r.t. to the measure on $gN$ obtained by shifting the measure of $N$, which is independent of the choice of $g$), then $A$ is of full measure in $G$? (This is implied from the equation above by taking $f$ to be the characteristic function of $A$). I wanted to use the disintegration theorem in Wikipedia, but I'm not sure if it applies here. I'm not sure I understand the definition of a Radon space and I don't know which locally compact groups satisfy it. I know of a more specific disintegration result, which appears in many/most introductions to Haar measures (e.g. Raghunthan's book), but it is only stated for continuous $f$ with compact support. I suppose it's not hard to get rid of the continuous part by using some Luzin argument (although I am not sure how to do it myself), but the compact support bothers me. In any case, if this is not true for general locally compact groups, for which groups it is true? I have a reference for second-countable compact groups (Halmos's book Measure Theory ; his definitions are a bit out-dated, but coincide with the modern ones for second-countable compact groups). I don't mind assuming separability. Compactness is not awful either, but I prefer not to assume metrisability. Thanks.","Suppose I have a locally compact group $G$ and a quotient map $f:G\to G/N$. Is it true that for every Borel-measurable function $f : G  [0, +]$, $$\int_{G} f(g) \, \mathrm{d} \mu_G (g) = \int_{G/N} \int_{N}    f(gn) \, \mathrm{d} \mu_{N} (n) \mathrm{d} \mu_{G/N} (gN),$$ where $\mathrm{d} \mu_{G}$, $\mathrm{d} \mu_{N}$ and $\mathrm{d} \mu_{G/N}$ are the Haar measures on $G$, $N$ and $G/N$ respectively? In particular, is it true that if a subset $A\subseteq G$ is such that its intersection with $\mathrm{d}\mu_{G/N}$-almost every coset $gN$ is of full measure in $gN$ (w.r.t. to the measure on $gN$ obtained by shifting the measure of $N$, which is independent of the choice of $g$), then $A$ is of full measure in $G$? (This is implied from the equation above by taking $f$ to be the characteristic function of $A$). I wanted to use the disintegration theorem in Wikipedia, but I'm not sure if it applies here. I'm not sure I understand the definition of a Radon space and I don't know which locally compact groups satisfy it. I know of a more specific disintegration result, which appears in many/most introductions to Haar measures (e.g. Raghunthan's book), but it is only stated for continuous $f$ with compact support. I suppose it's not hard to get rid of the continuous part by using some Luzin argument (although I am not sure how to do it myself), but the compact support bothers me. In any case, if this is not true for general locally compact groups, for which groups it is true? I have a reference for second-countable compact groups (Halmos's book Measure Theory ; his definitions are a bit out-dated, but coincide with the modern ones for second-countable compact groups). I don't mind assuming separability. Compactness is not awful either, but I prefer not to assume metrisability. Thanks.",,"['measure-theory', 'harmonic-analysis', 'topological-groups', 'locally-compact-groups', 'haar-measure']"
87,Is Fuzzy Set/Measure Theory an Active Area for Research?,Is Fuzzy Set/Measure Theory an Active Area for Research?,,"I came across the notion of a fuzzy set the other day and since then, I've been reading about fuzzy measures and the Sugeno/Choquet integrals. While I certainly do not claim to have fully wrapped my mind around it by any means, there is something that I find appealing about this area of study. This whole subject seems to be fairly obscure as Amazon has only a few books on the subject and none of them look like bestsellers (though I find these sorts of texts to be hidden gems more often than not). Basically, I am just interested in learning more about the direction that research in this subject is headed (if anywhere) and if it is perhaps a promising area to carve out a niche (admittedly in the distant future) one day. Any insight or reference would be very much appreciated. Also if Fuzzy Sets/Measure are thought to be a dead end or a ""rabbit hole"" of sorts, that knowledge would be equally valuable.","I came across the notion of a fuzzy set the other day and since then, I've been reading about fuzzy measures and the Sugeno/Choquet integrals. While I certainly do not claim to have fully wrapped my mind around it by any means, there is something that I find appealing about this area of study. This whole subject seems to be fairly obscure as Amazon has only a few books on the subject and none of them look like bestsellers (though I find these sorts of texts to be hidden gems more often than not). Basically, I am just interested in learning more about the direction that research in this subject is headed (if anywhere) and if it is perhaps a promising area to carve out a niche (admittedly in the distant future) one day. Any insight or reference would be very much appreciated. Also if Fuzzy Sets/Measure are thought to be a dead end or a ""rabbit hole"" of sorts, that knowledge would be equally valuable.",,"['measure-theory', 'fuzzy-logic', 'fuzzy-set']"
88,Atomless measure space without measure preserving isomorphisms,Atomless measure space without measure preserving isomorphisms,,"Question : Could somebody give an example of a nontrivial atomless measure space without measure preserving isomorphisms (except for the identity)? Background : A measure preserving isomorphism on a measure space $(X,\Sigma,\mu)$ is a bijection $\phi$ such that $$\forall A\in\Sigma:\mu(\phi^{-1}(A))=\mu(\phi(A))=\mu(A)$$ Edit: By ' except for the identity ' I obviously meant to exclude all $\phi$ such that $\mu(A\triangle\phi(A))=0$ for all $A\in\Sigma$.","Question : Could somebody give an example of a nontrivial atomless measure space without measure preserving isomorphisms (except for the identity)? Background : A measure preserving isomorphism on a measure space $(X,\Sigma,\mu)$ is a bijection $\phi$ such that $$\forall A\in\Sigma:\mu(\phi^{-1}(A))=\mu(\phi(A))=\mu(A)$$ Edit: By ' except for the identity ' I obviously meant to exclude all $\phi$ such that $\mu(A\triangle\phi(A))=0$ for all $A\in\Sigma$.",,['measure-theory']
89,Converse for Fubini-Tonelli's theorem,Converse for Fubini-Tonelli's theorem,,"By Fubini-Tonelli's theorem, we know that if $E\subset \mathbb{R^{n+m}}$ and $f: \mathbb{R^{n+m}}\to \mathbb{R_{>0}}$ are measurable and $f$ integrable, then the sections $E_x=\{y\in \mathbb{R^m}: (x,y)\in E\}$ and $E_y$ are measurable. I know that the converse is false, but I don't ""see"" an example where both sections are measurable but $E$ not (for lebesgue measure). Any idea? Thanks!","By Fubini-Tonelli's theorem, we know that if $E\subset \mathbb{R^{n+m}}$ and $f: \mathbb{R^{n+m}}\to \mathbb{R_{>0}}$ are measurable and $f$ integrable, then the sections $E_x=\{y\in \mathbb{R^m}: (x,y)\in E\}$ and $E_y$ are measurable. I know that the converse is false, but I don't ""see"" an example where both sections are measurable but $E$ not (for lebesgue measure). Any idea? Thanks!",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
90,"If the measure of union = sum of outer measures, then the sets are measurable","If the measure of union = sum of outer measures, then the sets are measurable",,"I am trying to show that for $A$, $B \; \subset \mathbb{R}$ $A \cup B$ is Lebesgue measurable such that \begin{align} \infty > \mu(A \cup B) = \mu^{*}(A) + \mu^{*}(B), \end{align} Then $A$ and $B$ are Lebesgue measurable. Thus far, I have tried reversing the directions in the proof of Caratheodory.  I seem to want to do the following: If $A \cup B$ is Lebesgue measurable, then, for any $E \subset \mathbb{R}$, \begin{align} \mu^{*}(E) \geq \mu^{*}(E \cap (A \cup B)) + \mu^{*}(E \cap (A \cup B)^{c}). \end{align} I want to use this and work backwards from here adding and subtracting sets to get \begin{align} \mu^{*}(E) \geq \mu^{*}(E \cap A) + \mu^{*}(E \cap A^{c}). \end{align} yet I am having trouble.","I am trying to show that for $A$, $B \; \subset \mathbb{R}$ $A \cup B$ is Lebesgue measurable such that \begin{align} \infty > \mu(A \cup B) = \mu^{*}(A) + \mu^{*}(B), \end{align} Then $A$ and $B$ are Lebesgue measurable. Thus far, I have tried reversing the directions in the proof of Caratheodory.  I seem to want to do the following: If $A \cup B$ is Lebesgue measurable, then, for any $E \subset \mathbb{R}$, \begin{align} \mu^{*}(E) \geq \mu^{*}(E \cap (A \cup B)) + \mu^{*}(E \cap (A \cup B)^{c}). \end{align} I want to use this and work backwards from here adding and subtracting sets to get \begin{align} \mu^{*}(E) \geq \mu^{*}(E \cap A) + \mu^{*}(E \cap A^{c}). \end{align} yet I am having trouble.",,"['measure-theory', 'outer-measure']"
91,Hlder's Inequality and the Pigeonhole Principle,Hlder's Inequality and the Pigeonhole Principle,,"I heard someone in my department claim that Hlder's inequality was just a continuous version of the pigeonhole principle.  It seemed reasonable, but I'm struggling to make their connection precise. Does anyone know of a precise connection between the two?  Are they related at all, or was my source confused? [Edit: Originally this post had ""Markov's inequality"" instead of Hlder's.  I suspect, given my answer below, that my source meant to say Hlder's inequality.]","I heard someone in my department claim that Hlder's inequality was just a continuous version of the pigeonhole principle.  It seemed reasonable, but I'm struggling to make their connection precise. Does anyone know of a precise connection between the two?  Are they related at all, or was my source confused? [Edit: Originally this post had ""Markov's inequality"" instead of Hlder's.  I suspect, given my answer below, that my source meant to say Hlder's inequality.]",,"['measure-theory', 'pigeonhole-principle']"
92,Sets of Divergence for Fourier Partial Integals,Sets of Divergence for Fourier Partial Integals,,"It is a consequence of Carleson's theorem together with a transference argument that (see Section 4.3.5 in L Grafakos, Classical Fourier Analysis for proof) that the Fourier partial integrals of a function $f\in L^{p}(\mathbb{R})$ , where $1<p\leq 2$ , converge pointwise almost everywhere (a.e.) to $f$ : $$\lim_{R\rightarrow\infty}\int_{\left|\xi\right|\leq R}\widehat{f}(\xi)e^{2\pi i\xi x}\mathrm{d}\xi=f(x)\quad \text{a.e.} \tag{1}$$ Kahane and Katznelson showed that given any subset of the torus $E$ of measure zero, there exists a continuous periodic complex-valued function $f\in C(\mathbb{T})$ such that the Fourier partial sums of $f$ diverge at every $x\in E$ (and possibly at other points too). My question is whether there is an analogoue of Kahane's and Katznelson's result for continuous, $p$ -integrable functions on the real line. A cursory search has been unable to find one. Question. Given a subset $E\subset\mathbb{R}$ of measure zero, does there exist a continuous function $f\in L^{p}$ with locally integrable (distributional) Fourier transform $\widehat{f}$ , such that $$S_{R}f(x):=\int_{\left|\xi\right|\leq R}\widehat{f}(\xi)e^{2\pi i\xi x}\mathrm{d}\xi \tag{2}$$ diverges for all $x\in E$ ? I think this question makes sense as its written. I know that, unlike in the setting of the torus, the Fourier transform of a function $f\in L^{p}(\mathbb{R})$ isn't necessarily a function, if $p>2$ . But I think I have taken care of that issue by requiring the Fourier transform to be locally integrable so the integral in (2) makes sense. My motivation for this question stems from the problem of inverting the Fourier transform $\widehat{f}$ using the cutoff function $\chi_{[-R,R]}$ (see this question ), when $f\in L^{1}(\mathbb{R})$ and $\widehat{f}$ is only assumed to be locally integrable. How badly can the equality in (2) fail if $\widehat{f}\notin L^{1}(\mathbb{R})$ ? Edit 1. I incorrectly stated Kahane and Katznelson's result in the original question. They only showed that given a measure zero subset $E\subset\mathbb{T}$ , the partial Fourier sums diverge on $E$ and possibly at other points as well. It's not necessarily the case that $S_{N}f(x)\rightarrow f(x)$ for all $x\notin E$ . In fact, characterizing the sets $E$ for which $S_{N}f$ diverges on $E$ and converges on $E^{c}$ appears to be an open problem . Also, it cannot be the case that $S_{N}f(x)\rightarrow a\in\mathbb{C}$ , where $a\neq f(x)$ . The Fejer means $\sigma_{N}f(x)$ of the partial sums converge to $f(x)$ at every point of continuity of $f$ , whence everywhere. So if the partial sums converge, then it must be to $f(x)$ .","It is a consequence of Carleson's theorem together with a transference argument that (see Section 4.3.5 in L Grafakos, Classical Fourier Analysis for proof) that the Fourier partial integrals of a function , where , converge pointwise almost everywhere (a.e.) to : Kahane and Katznelson showed that given any subset of the torus of measure zero, there exists a continuous periodic complex-valued function such that the Fourier partial sums of diverge at every (and possibly at other points too). My question is whether there is an analogoue of Kahane's and Katznelson's result for continuous, -integrable functions on the real line. A cursory search has been unable to find one. Question. Given a subset of measure zero, does there exist a continuous function with locally integrable (distributional) Fourier transform , such that diverges for all ? I think this question makes sense as its written. I know that, unlike in the setting of the torus, the Fourier transform of a function isn't necessarily a function, if . But I think I have taken care of that issue by requiring the Fourier transform to be locally integrable so the integral in (2) makes sense. My motivation for this question stems from the problem of inverting the Fourier transform using the cutoff function (see this question ), when and is only assumed to be locally integrable. How badly can the equality in (2) fail if ? Edit 1. I incorrectly stated Kahane and Katznelson's result in the original question. They only showed that given a measure zero subset , the partial Fourier sums diverge on and possibly at other points as well. It's not necessarily the case that for all . In fact, characterizing the sets for which diverges on and converges on appears to be an open problem . Also, it cannot be the case that , where . The Fejer means of the partial sums converge to at every point of continuity of , whence everywhere. So if the partial sums converge, then it must be to .","f\in L^{p}(\mathbb{R}) 1<p\leq 2 f \lim_{R\rightarrow\infty}\int_{\left|\xi\right|\leq R}\widehat{f}(\xi)e^{2\pi i\xi x}\mathrm{d}\xi=f(x)\quad \text{a.e.} \tag{1} E f\in C(\mathbb{T}) f x\in E p E\subset\mathbb{R} f\in L^{p} \widehat{f} S_{R}f(x):=\int_{\left|\xi\right|\leq R}\widehat{f}(\xi)e^{2\pi i\xi x}\mathrm{d}\xi \tag{2} x\in E f\in L^{p}(\mathbb{R}) p>2 \widehat{f} \chi_{[-R,R]} f\in L^{1}(\mathbb{R}) \widehat{f} \widehat{f}\notin L^{1}(\mathbb{R}) E\subset\mathbb{T} E S_{N}f(x)\rightarrow f(x) x\notin E E S_{N}f E E^{c} S_{N}f(x)\rightarrow a\in\mathbb{C} a\neq f(x) \sigma_{N}f(x) f(x) f f(x)","['measure-theory', 'fourier-analysis', 'fourier-series', 'harmonic-analysis']"
93,Proving measurability of a function only by checking generating sets,Proving measurability of a function only by checking generating sets,,"Theorem: Suppose that $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ are measurable spaces and $\mathcal{B}$ = $\sigma(\mathcal{G})$ is generated by a family $\mathcal{G}\subset\mathcal{P}(Y)$. Then $f : X \rightarrow Y$ is measurable if and only if $f^{-1}(G)\in \mathcal{A}$ for every $G \in \mathcal{G}$. The proof goes as follows: Set operations are natural under pull-backs, meaning that $f^{-1}(Y\setminus B) = X \setminus f^{-1}(B)$ and $\displaystyle f^{-1}\left(\bigcup_{i=1}^{\infty} B_i\right) = \bigcup_{i=1}^{\infty}f^{-1}(B_i)$, $\displaystyle f^{-1}\left(\bigcap_{i=1}^{\infty}B_{i}\right) = \bigcap_{i=1}^{\infty}f^{-1}(B_{i}).$ It follows that $\mathcal M = \{ B \subset Y : f^{-1}(B) \in \mathcal{A}\}$ is a $\sigma$-algebra on $Y$. By assumption, $\mathcal{M} \supset \mathcal{G}$ and therefore $\mathcal{M} \supset \sigma(\mathcal{G}) = \mathcal{B}$, which implies that $f$ is measurable. Now I got a few questions: 1) How do we know $\mathcal M$ is a $\sigma$-algebra on $Y$? 2) ""By assumption, $\mathcal{M} \supset \mathcal{G}$"" - why? $\mathcal M$ is just a sigma algebra on $Y$, one of many, it doesn't have to contain every subset of $Y$, so we don't know if it contains $\mathcal{G}$. 3) Why $\mathcal{M} \supset \sigma(\mathcal{G}) = \mathcal{B}$ implies that $f$ is measurable? Please explain as simple as possible.","Theorem: Suppose that $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ are measurable spaces and $\mathcal{B}$ = $\sigma(\mathcal{G})$ is generated by a family $\mathcal{G}\subset\mathcal{P}(Y)$. Then $f : X \rightarrow Y$ is measurable if and only if $f^{-1}(G)\in \mathcal{A}$ for every $G \in \mathcal{G}$. The proof goes as follows: Set operations are natural under pull-backs, meaning that $f^{-1}(Y\setminus B) = X \setminus f^{-1}(B)$ and $\displaystyle f^{-1}\left(\bigcup_{i=1}^{\infty} B_i\right) = \bigcup_{i=1}^{\infty}f^{-1}(B_i)$, $\displaystyle f^{-1}\left(\bigcap_{i=1}^{\infty}B_{i}\right) = \bigcap_{i=1}^{\infty}f^{-1}(B_{i}).$ It follows that $\mathcal M = \{ B \subset Y : f^{-1}(B) \in \mathcal{A}\}$ is a $\sigma$-algebra on $Y$. By assumption, $\mathcal{M} \supset \mathcal{G}$ and therefore $\mathcal{M} \supset \sigma(\mathcal{G}) = \mathcal{B}$, which implies that $f$ is measurable. Now I got a few questions: 1) How do we know $\mathcal M$ is a $\sigma$-algebra on $Y$? 2) ""By assumption, $\mathcal{M} \supset \mathcal{G}$"" - why? $\mathcal M$ is just a sigma algebra on $Y$, one of many, it doesn't have to contain every subset of $Y$, so we don't know if it contains $\mathcal{G}$. 3) Why $\mathcal{M} \supset \sigma(\mathcal{G}) = \mathcal{B}$ implies that $f$ is measurable? Please explain as simple as possible.",,['measure-theory']
94,Existence of a random variable satisfying a condition on its distribution,Existence of a random variable satisfying a condition on its distribution,,"Let $X, Y : [0,1] \to \mathcal{X}$ be two random variables. Here, $[0,1]$ is the interval with the Lebesgue $\sigma$-algebra and $\mathcal{X}$ is a topological space with the Borel $\sigma$-algebra. The distribution of $X$ is by definition a measure $\mu_X$ on $\mathcal{X}$ defined as $\mu_X(A) = \mathbf{P}(X^{-1}(A))$, where $\mathbf{P}$ is the Lebesgue measure on $[0,1]$. Are there results on the existence of a random variable $Z : [0,1] \to \mathcal{X}$, whose distribution $\mu_Z$ satisfies  $$\frac{1}{2} \mu_X + \frac{1}{2}\mu_Y = \mu_Z.$$ Or more generally. Given probability distributions of two random variables, is every convex combination of these distribution also a distribution of a random variable (with the same domain)?","Let $X, Y : [0,1] \to \mathcal{X}$ be two random variables. Here, $[0,1]$ is the interval with the Lebesgue $\sigma$-algebra and $\mathcal{X}$ is a topological space with the Borel $\sigma$-algebra. The distribution of $X$ is by definition a measure $\mu_X$ on $\mathcal{X}$ defined as $\mu_X(A) = \mathbf{P}(X^{-1}(A))$, where $\mathbf{P}$ is the Lebesgue measure on $[0,1]$. Are there results on the existence of a random variable $Z : [0,1] \to \mathcal{X}$, whose distribution $\mu_Z$ satisfies  $$\frac{1}{2} \mu_X + \frac{1}{2}\mu_Y = \mu_Z.$$ Or more generally. Given probability distributions of two random variables, is every convex combination of these distribution also a distribution of a random variable (with the same domain)?",,"['measure-theory', 'reference-request', 'lebesgue-measure']"
95,Continuity in the Krylov-Bogoliubov theorem,Continuity in the Krylov-Bogoliubov theorem,,"I have the following proof of the Krylov-Bogoliubov theorem, which asserts that given a compact metric space $X$ endowed with a continuous transformation $T \colon X \to X$ one can find a $T$-invariant Borel probability measure $\mu$: Let $$S_f^N(x) = \frac{1}{N} \sum_{n = 0}^{N-1} f(T^n(x))$$ and fix $x \in X$. Let $\mathcal{F}$ be a countable dense subset of $\mathcal{C}(X, \mathbb{R})$. Using a diagonalization argument and the fact that $f(X)$ is bounded, it's easy to prove that there exists a strictly increasing sequence $N_k$ such that $S_f^{N_k}(x)$ converges for every $f \in \mathcal{F}$. Because $\mathcal{F}$ is dense in the uniform topology, $S_g^{N_k}(x)$ also converges for every $g \in \mathcal{C}(X, \mathbb{R})$. Let $S_g(x) = \lim_{k \to \infty} S_g^{N_k}(x)$. Let $L_x(g) = S_g(x)$. Then $L_x \colon \mathcal{C}(X, \mathbb{R}) \to \mathcal{R}$ is a continuous positive linear functional. By the Riesz representation theorem, there is a regular measure $\mu$ on $\mathcal{B}(X)$ such that $$L_x(g) = \int_X g d\mu$$ for every $g \in \mathcal{C}(X, \mathbb{R})$. A simple computation shows that $L_x(g \circ T) = L_x(g)$ for every $g \in \mathcal{C}(X, \mathbb{R})$, so $$\int_X g d\nu = \int_X g \circ T d\mu = \int_X g d\mu$$ for every $g \in \mathcal{C}(X, \mathbb{R})$, where $\nu = \mu(T^{-1}(\cdot))$. Since $\nu$ is a finite measure and $X$ is compact and metrizable, it follows that $\nu$ is also regular. This proves that $\mu = \nu$, so $\mu$ is $T$-invariant. My problem is that this proof doesn't seem to need the continuity of $T$, whereas there are examples that show that measurability alone isn't enough for the proof. What am I missing? Thanks in advance.","I have the following proof of the Krylov-Bogoliubov theorem, which asserts that given a compact metric space $X$ endowed with a continuous transformation $T \colon X \to X$ one can find a $T$-invariant Borel probability measure $\mu$: Let $$S_f^N(x) = \frac{1}{N} \sum_{n = 0}^{N-1} f(T^n(x))$$ and fix $x \in X$. Let $\mathcal{F}$ be a countable dense subset of $\mathcal{C}(X, \mathbb{R})$. Using a diagonalization argument and the fact that $f(X)$ is bounded, it's easy to prove that there exists a strictly increasing sequence $N_k$ such that $S_f^{N_k}(x)$ converges for every $f \in \mathcal{F}$. Because $\mathcal{F}$ is dense in the uniform topology, $S_g^{N_k}(x)$ also converges for every $g \in \mathcal{C}(X, \mathbb{R})$. Let $S_g(x) = \lim_{k \to \infty} S_g^{N_k}(x)$. Let $L_x(g) = S_g(x)$. Then $L_x \colon \mathcal{C}(X, \mathbb{R}) \to \mathcal{R}$ is a continuous positive linear functional. By the Riesz representation theorem, there is a regular measure $\mu$ on $\mathcal{B}(X)$ such that $$L_x(g) = \int_X g d\mu$$ for every $g \in \mathcal{C}(X, \mathbb{R})$. A simple computation shows that $L_x(g \circ T) = L_x(g)$ for every $g \in \mathcal{C}(X, \mathbb{R})$, so $$\int_X g d\nu = \int_X g \circ T d\mu = \int_X g d\mu$$ for every $g \in \mathcal{C}(X, \mathbb{R})$, where $\nu = \mu(T^{-1}(\cdot))$. Since $\nu$ is a finite measure and $X$ is compact and metrizable, it follows that $\nu$ is also regular. This proves that $\mu = \nu$, so $\mu$ is $T$-invariant. My problem is that this proof doesn't seem to need the continuity of $T$, whereas there are examples that show that measurability alone isn't enough for the proof. What am I missing? Thanks in advance.",,"['measure-theory', 'continuity', 'ergodic-theory']"
96,Approximation of measurable function by simple functions,Approximation of measurable function by simple functions,,"This is from Tao Exercise 19.1.3. Let $\Omega \subseteq \mathbb R^n$ measurable and $f: \Omega \rightarrow \mathbb R$ be measurable. Assume $f \geq 0$ on $\Omega$ . Then there exists a sequence $\{f_n: \Omega \rightarrow \mathbb R\}_{n=1}^\infty$ s.t. all $f_n$ are simple, non-negative and increasing and $f_n \rightarrow f$ pointwise on $\Omega$ . Tao gives the hint to define $$f_n(x) := \sup \left \{\frac j {2^n} : j \in \mathbb Z, \frac j {2^n} \leq \min(f(x),2^n) \right \}$$ Can someone help me to prove why all $f_n$ are measurable ?!","This is from Tao Exercise 19.1.3. Let measurable and be measurable. Assume on . Then there exists a sequence s.t. all are simple, non-negative and increasing and pointwise on . Tao gives the hint to define Can someone help me to prove why all are measurable ?!","\Omega \subseteq \mathbb R^n f: \Omega \rightarrow \mathbb R f \geq 0 \Omega \{f_n: \Omega \rightarrow \mathbb R\}_{n=1}^\infty f_n f_n \rightarrow f \Omega f_n(x) := \sup \left \{\frac j {2^n} : j \in \mathbb Z, \frac j {2^n} \leq \min(f(x),2^n) \right \} f_n",[]
97,Absolute Continuity of Finite Borel Measure Characterized by Orthonormal Basis,Absolute Continuity of Finite Borel Measure Characterized by Orthonormal Basis,,"I've been working through Fundamentals of Stochastic Filtering (Bain, Crisan) and am a little perplexed by the following (initially) seemingly straightforward exercise and its given solution. We are given a certain finite Borel measure $\mu$ on $\mathbb{R}^d$ and we wish to determine whether or not it is absolutely continuous with respect to Lebesgue measure. The exercise purports the following: Let $\{\varphi_i\} _{i>0}$ be an orthonormal basis of $L^2(\mathbb{R}^d$ ) with the property that $\varphi_i$ is continuous and bounded for all $i$ . Let $\mu$ be a finite measure. If $$\sum_{i=1}^\infty \, \mu(\varphi_i)^2 <\infty $$ then $\mu$ is absolutely continuous with respect to Lebesgue measure. Moreover, if $g_\mu$ is the density of $\mu$ with respect to Lebesgue measure, then $g_\mu \in L^2(\mathbb{R}^d)$ . The solution in the book goes as follows: we construct a density function, use it to define a new measure (which is necessarily absolutely continuous with respect to Lebesgue measure) and then show that this new measure is indeed the one we were given. Defining our density function $\bar{g_\mu} = \sum_{i=1}^\infty \, \mu(\varphi_i) \varphi_i$ , it is easy to see that this is in $L^2$ . Defining $\bar{\mu}$ to be the finite measure given rise to by this density, we see that $\bar{\mu}(\varphi_i) = \mu(\varphi_i)$ for all i. All well so good. The problem is showing that our wavelet basis $\{\varphi_i\}_{i>0}$ is a separating set of functions with respect to Borel measures on $\mathbb{R^d}$ , which would show that $\bar{\mu} = \mu$ . The book simply says: [...] via an approximation argument $\bar{\mu}(A) = \mu(A) $ for any ball A of arbitrary center and radius. Hence $\bar{\mu} = \mu$ . The issue I have here is making this approximation argument or any similar one work. The most obvious idea is to show that $ \bar{\mu}(f) =\mu(f)$ for any continuous bounded function $f$ . If we approximate naively $f$ in $L^2$ by functions in the span of our wavelet basis, this will also approximate the left hand side since we have absolute continuity between Lebesgue measure and $\bar{\mu}$ . However, the same cannot be said a priori about the right hand side. I note that the proposition supposed continuity of the wavelet functions, but this was never explicitly referred to in the proof. In fact, continuity must be necessary here, because it's easy to construct a counter example to this if the wavelets are allowed to be discontinuous (take $\mu$ to be Dirac measure at the origin, with any wavelet basis whose basis functions are modified to be zero at the origin). Being able to approximate in $L^2$ alone is clearly not strong enough - we need some uniform or uniform-like strength. Unfortunately though I can't think of any specific properties (such as their span forming an algebra) of general wavelets that would let us infer this. As I type this, it occurs to me that for the way this result is applied in the book, it is enough for it to hold for one particular choice of basis. Using finiteness of $\mu$ , it would be enough to exhibit existence of a wavelet basis that can uniformly approximate any given continuous $f$ on $\mathbb{R}^d$ (or on any given compact interval/cube). I guess we could use truncated trigonometric base functions (truncation in the sense of domain) - allowing for uniform convergence on $...,[-1,0],[0,1],[1,2],...$ simultaneously (similarly for $\mathbb{R}^d$ . Now the wavelets are only piecewise continuous, but this is probably not a problem). For the time being I'll likely go with this makeshift approach, so I hope I haven't made any mistakes in my reasoning. For general continuous wavelets, is the original proposition true, I wonder. EDIT: It turns out that my above makeshift approach isn't going to work for proving the main result since I need the wavelets to have bounded partial derivatives up to second order.","I've been working through Fundamentals of Stochastic Filtering (Bain, Crisan) and am a little perplexed by the following (initially) seemingly straightforward exercise and its given solution. We are given a certain finite Borel measure on and we wish to determine whether or not it is absolutely continuous with respect to Lebesgue measure. The exercise purports the following: Let be an orthonormal basis of ) with the property that is continuous and bounded for all . Let be a finite measure. If then is absolutely continuous with respect to Lebesgue measure. Moreover, if is the density of with respect to Lebesgue measure, then . The solution in the book goes as follows: we construct a density function, use it to define a new measure (which is necessarily absolutely continuous with respect to Lebesgue measure) and then show that this new measure is indeed the one we were given. Defining our density function , it is easy to see that this is in . Defining to be the finite measure given rise to by this density, we see that for all i. All well so good. The problem is showing that our wavelet basis is a separating set of functions with respect to Borel measures on , which would show that . The book simply says: [...] via an approximation argument for any ball A of arbitrary center and radius. Hence . The issue I have here is making this approximation argument or any similar one work. The most obvious idea is to show that for any continuous bounded function . If we approximate naively in by functions in the span of our wavelet basis, this will also approximate the left hand side since we have absolute continuity between Lebesgue measure and . However, the same cannot be said a priori about the right hand side. I note that the proposition supposed continuity of the wavelet functions, but this was never explicitly referred to in the proof. In fact, continuity must be necessary here, because it's easy to construct a counter example to this if the wavelets are allowed to be discontinuous (take to be Dirac measure at the origin, with any wavelet basis whose basis functions are modified to be zero at the origin). Being able to approximate in alone is clearly not strong enough - we need some uniform or uniform-like strength. Unfortunately though I can't think of any specific properties (such as their span forming an algebra) of general wavelets that would let us infer this. As I type this, it occurs to me that for the way this result is applied in the book, it is enough for it to hold for one particular choice of basis. Using finiteness of , it would be enough to exhibit existence of a wavelet basis that can uniformly approximate any given continuous on (or on any given compact interval/cube). I guess we could use truncated trigonometric base functions (truncation in the sense of domain) - allowing for uniform convergence on simultaneously (similarly for . Now the wavelets are only piecewise continuous, but this is probably not a problem). For the time being I'll likely go with this makeshift approach, so I hope I haven't made any mistakes in my reasoning. For general continuous wavelets, is the original proposition true, I wonder. EDIT: It turns out that my above makeshift approach isn't going to work for proving the main result since I need the wavelets to have bounded partial derivatives up to second order.","\mu \mathbb{R}^d \{\varphi_i\} _{i>0} L^2(\mathbb{R}^d \varphi_i i \mu \sum_{i=1}^\infty \, \mu(\varphi_i)^2 <\infty  \mu g_\mu \mu g_\mu \in L^2(\mathbb{R}^d) \bar{g_\mu} = \sum_{i=1}^\infty \, \mu(\varphi_i) \varphi_i L^2 \bar{\mu} \bar{\mu}(\varphi_i) = \mu(\varphi_i) \{\varphi_i\}_{i>0} \mathbb{R^d} \bar{\mu} = \mu \bar{\mu}(A) = \mu(A)  \bar{\mu} = \mu  \bar{\mu}(f) =\mu(f) f f L^2 \bar{\mu} \mu L^2 \mu f \mathbb{R}^d ...,[-1,0],[0,1],[1,2],... \mathbb{R}^d","['measure-theory', 'hilbert-spaces', 'wavelets']"
98,The approximating Hausdorff measure is not Borel,The approximating Hausdorff measure is not Borel,,"This is an exercise taken from Mattila, Geometry of sets and measures in Euclidean space , chapter 4. Exercise . Let $U$ be an open ball in $\mathbb{R}^n$ ($n\ge 2$) such that $d(U)=\delta$ [here $d$ stands for ""diameter""]. Show that for $0\le s \le 1$,    $$\tag{1} \mathcal{H}^s_\delta(U)=\mathcal{H}^s_\delta\left(\overline{U}\right)=\mathcal{H}^s_\delta(\partial U).$$ Here $\mathcal{H}^s_\delta(A)$ is the infimum of the sums  $$\sum_{j=1}^\infty d^s(E_j), $$ where $\{E_j\}$ is a covering of $A$ such that $d(E_j)\le \delta$. As $\delta\downarrow 0$, $\mathcal{H}^s_\delta(A)$ tends to the Hausdorff measure $\mathcal{H}^s(A)$. The point of this exercise is to show that, even if $\mathcal{H}^s_\delta$ is a (outer) measure, it is not Borel since it fails to be additive on $\overline{U}=U\cup \partial U$. Can you help me with this exercise? Those things are new to me and I would use a hint to start with. Thank you!","This is an exercise taken from Mattila, Geometry of sets and measures in Euclidean space , chapter 4. Exercise . Let $U$ be an open ball in $\mathbb{R}^n$ ($n\ge 2$) such that $d(U)=\delta$ [here $d$ stands for ""diameter""]. Show that for $0\le s \le 1$,    $$\tag{1} \mathcal{H}^s_\delta(U)=\mathcal{H}^s_\delta\left(\overline{U}\right)=\mathcal{H}^s_\delta(\partial U).$$ Here $\mathcal{H}^s_\delta(A)$ is the infimum of the sums  $$\sum_{j=1}^\infty d^s(E_j), $$ where $\{E_j\}$ is a covering of $A$ such that $d(E_j)\le \delta$. As $\delta\downarrow 0$, $\mathcal{H}^s_\delta(A)$ tends to the Hausdorff measure $\mathcal{H}^s(A)$. The point of this exercise is to show that, even if $\mathcal{H}^s_\delta$ is a (outer) measure, it is not Borel since it fails to be additive on $\overline{U}=U\cup \partial U$. Can you help me with this exercise? Those things are new to me and I would use a hint to start with. Thank you!",,"['measure-theory', 'geometric-measure-theory']"
99,"Showing that $\nu \ll \mu$ implies $\forall \epsilon > 0$, $\exists \delta > 0$ s.t. $\mu(A) < \delta \implies \nu(A) < \epsilon$","Showing that  implies ,  s.t.",\nu \ll \mu \forall \epsilon > 0 \exists \delta > 0 \mu(A) < \delta \implies \nu(A) < \epsilon,"I am stuck on what I think may be the very last line of the proof I am seeking. Let $(X, \mathcal{B})$ be a measurable space which has associated with it the finite measures $\mu$ and $\nu$ s.t. $\nu \ll \mu$.  I aim to show that $\forall \epsilon > 0$, $\exists \delta > 0$ s.t. $\forall A \in \mathcal{B}$, $$\mu(A) < \delta \implies \nu(A) < \epsilon$$ Fix $\epsilon > 0$. For all $n \in \mathbb{N}$, let $\delta_n = \frac{1}{n^2}$. For all $n \in \mathbb{N}$, let $A_n \in \mathcal{B}$ s.t. if $\exists E \in \mathcal{B}$ s.t. $\mu(E) < \delta_n$ and $\nu(E) > \epsilon$, then set $A_n = E$.  Otherwise, set $A_n = \emptyset \in \mathcal{B}$. Suppose for sake of contradiction that $|\{A_n\}| = \infty$, so that no matter the $\delta > 0$, we could find a $\delta_n = \frac{1}{n^2}  < \delta$ which has associated with it a measurable $A_n \ne \emptyset$ with $\mu(A_n) < \delta_n < \delta$ and $\nu(A_n) > \epsilon$. Now if we let $\underset{n \rightarrow \infty}{\text{limsup}}$ $A_n = S$, we have (from a prior problem) that $\mu(S) = 0$ since $\mu$ is a finite measure and $\sum_{n=1}^\infty \mu(A_n) \le \sum_{n=1}^\infty \delta_n = \sum_{n=1}^\infty \frac{1}{n^2} < \infty$.  Since $\nu \ll \mu$ we therefore have $\nu(S) = 0$ as well. Yet $\nu(S) = \nu(\bigcap_{n=1}^\infty \bigcup_{n=m}^\infty A_m) \ge \epsilon > 0$ since... and it's here where I'm stuck in the proof.","I am stuck on what I think may be the very last line of the proof I am seeking. Let $(X, \mathcal{B})$ be a measurable space which has associated with it the finite measures $\mu$ and $\nu$ s.t. $\nu \ll \mu$.  I aim to show that $\forall \epsilon > 0$, $\exists \delta > 0$ s.t. $\forall A \in \mathcal{B}$, $$\mu(A) < \delta \implies \nu(A) < \epsilon$$ Fix $\epsilon > 0$. For all $n \in \mathbb{N}$, let $\delta_n = \frac{1}{n^2}$. For all $n \in \mathbb{N}$, let $A_n \in \mathcal{B}$ s.t. if $\exists E \in \mathcal{B}$ s.t. $\mu(E) < \delta_n$ and $\nu(E) > \epsilon$, then set $A_n = E$.  Otherwise, set $A_n = \emptyset \in \mathcal{B}$. Suppose for sake of contradiction that $|\{A_n\}| = \infty$, so that no matter the $\delta > 0$, we could find a $\delta_n = \frac{1}{n^2}  < \delta$ which has associated with it a measurable $A_n \ne \emptyset$ with $\mu(A_n) < \delta_n < \delta$ and $\nu(A_n) > \epsilon$. Now if we let $\underset{n \rightarrow \infty}{\text{limsup}}$ $A_n = S$, we have (from a prior problem) that $\mu(S) = 0$ since $\mu$ is a finite measure and $\sum_{n=1}^\infty \mu(A_n) \le \sum_{n=1}^\infty \delta_n = \sum_{n=1}^\infty \frac{1}{n^2} < \infty$.  Since $\nu \ll \mu$ we therefore have $\nu(S) = 0$ as well. Yet $\nu(S) = \nu(\bigcap_{n=1}^\infty \bigcup_{n=m}^\infty A_m) \ge \epsilon > 0$ since... and it's here where I'm stuck in the proof.",,['measure-theory']
