,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability of drawing two cards such that one is a spade and other one is a heart.,Probability of drawing two cards such that one is a spade and other one is a heart.,,"I got the answer of this question via two methods $(13÷52)*(13÷51)*2............(i)$ And the second is $(13C1*13C1)÷(52C2).........(ii)$ I know that both will give same numerical correct answer, but I'm confused from the fact that in first equation we multiplied by $2$ which means that either spade or heart can be drawn first so why can't we multiply second equation using same logic? Please help if I'm missing something really important. Thanks in advance.","I got the answer of this question via two methods And the second is I know that both will give same numerical correct answer, but I'm confused from the fact that in first equation we multiplied by which means that either spade or heart can be drawn first so why can't we multiply second equation using same logic? Please help if I'm missing something really important. Thanks in advance.",(13÷52)*(13÷51)*2............(i) (13C1*13C1)÷(52C2).........(ii) 2,"['probability', 'combinatorics', 'permutations']"
1,Law of total expectation with conditional expectations,Law of total expectation with conditional expectations,,"I am confused between these two equations which use the law of total expectation: $$E(X|Y)=E(X|Y,Z)P(Z)+E(X|Y,Z')P(Z')$$ $$E(X|Y)=E(X|Y,Z)P(Z|Y)+E(X|Y,Z')P(Z'|Y)$$ where Z' is the complement of Z. The first one makes sense to me because if one defines the random variable $A=X|Y$ , then it is simply using the law of total expectation. The other also makes sense as it is as if we are applying the law of total probability on $X$ but then reducing the universe to the ""given Y"" subspace. Which one is right? In general, is thinking of X given Y and Z the same as X given Y, given Z? $$P(X|Y,Z)=P((X|Y)|Z)$$","I am confused between these two equations which use the law of total expectation: where Z' is the complement of Z. The first one makes sense to me because if one defines the random variable , then it is simply using the law of total expectation. The other also makes sense as it is as if we are applying the law of total probability on but then reducing the universe to the ""given Y"" subspace. Which one is right? In general, is thinking of X given Y and Z the same as X given Y, given Z?","E(X|Y)=E(X|Y,Z)P(Z)+E(X|Y,Z')P(Z') E(X|Y)=E(X|Y,Z)P(Z|Y)+E(X|Y,Z')P(Z'|Y) A=X|Y X P(X|Y,Z)=P((X|Y)|Z)","['probability', 'conditional-expectation', 'conditional-probability', 'expected-value']"
2,Mean value of the determinant of a $2n \times 2n$ skew-symmetric matrix with random entries,Mean value of the determinant of a  skew-symmetric matrix with random entries,2n \times 2n,"Let $A$ be a $2n \times 2n$ matrix with entries chosen independently at random. Each entry is chosen to be $0$ or $1$ , each with probability $1/2$ . Find the expected value of $\det(A - A^T)$ as a function of $n$ . Appeared in a class that prepares students for the Putnam exam, but we did not get to it.","Let be a matrix with entries chosen independently at random. Each entry is chosen to be or , each with probability . Find the expected value of as a function of . Appeared in a class that prepares students for the Putnam exam, but we did not get to it.",A 2n \times 2n 0 1 1/2 \det(A - A^T) n,"['probability', 'matrices', 'contest-math', 'determinant', 'random-matrices']"
3,Probability Doubt about selection,Probability Doubt about selection,,"A bus contain 10 tickets 5 printed with 'I' and 5 printed with 'T', 3 tickets are drawn without Replacement and arrange in the same Order in which they are drawn on the table. Find the Probability that IIT is formed. 1st approach: $\frac{5}{10} \times\frac{4}{9}\times\frac{5}{8}= \frac{5}{36}$ 2nd Approach: $\left (\binom{5}{2}\times\binom{5}{1}  \right )/ \binom{10}{3}$ which is equal to 5/12 My doubt is why they aren't equal can you please explain the concept I missed in this question?","A bus contain 10 tickets 5 printed with 'I' and 5 printed with 'T', 3 tickets are drawn without Replacement and arrange in the same Order in which they are drawn on the table. Find the Probability that IIT is formed. 1st approach: 2nd Approach: which is equal to 5/12 My doubt is why they aren't equal can you please explain the concept I missed in this question?",\frac{5}{10} \times\frac{4}{9}\times\frac{5}{8}= \frac{5}{36} \left (\binom{5}{2}\times\binom{5}{1}  \right )/ \binom{10}{3},"['probability', 'combinations']"
4,Sum of three independent random variables,Sum of three independent random variables,,"Let $X$ , $Y$ , and $Z$ be independently and identically distributed variables, each uniformly distributed between $0$ and $2$ . What is the probability that $X+Y+Z\leq2$ ? All the other answers on similar questions refer to various things like ""convolutions"" that I've never heard of or use integrals and change the limits from $[-\infty,+\infty]$ to other things etc. so I'm very confused and don't understand any of it. In particular, I thought we could just work out $P(X+Y\leq2-Z)=\frac{1}{8}(2-Z)^2$ and thus do $\int_{0}^{2}\frac{1}{8}(2-Z)^2 \text{d}Z$ , and I don't understand why this doesn't give the right answer of $\frac{1}{6}$ . Please would someone take the time to write out all the steps with full explanation for someone who has only basic knowledge of probability.","Let , , and be independently and identically distributed variables, each uniformly distributed between and . What is the probability that ? All the other answers on similar questions refer to various things like ""convolutions"" that I've never heard of or use integrals and change the limits from to other things etc. so I'm very confused and don't understand any of it. In particular, I thought we could just work out and thus do , and I don't understand why this doesn't give the right answer of . Please would someone take the time to write out all the steps with full explanation for someone who has only basic knowledge of probability.","X Y Z 0 2 X+Y+Z\leq2 [-\infty,+\infty] P(X+Y\leq2-Z)=\frac{1}{8}(2-Z)^2 \int_{0}^{2}\frac{1}{8}(2-Z)^2 \text{d}Z \frac{1}{6}",['probability']
5,Conditional Probability --- Card Question,Conditional Probability --- Card Question,,"Suppose you have two cards: one is painted black on both sides and the other is painted black on one side and orange on the other You select a card at random and view one side. You notice it is black. What is the probability the other side is orange? What I have done is following: Card 1: $B_{1}$ , $B_{2}$ Card 2: $B_{1}$ , $O_{2}$ Now, we want to calculate $P(O_{2}|B_{1})$ , which is $$P(O_{2}|B_{1})=\dfrac{P(B_{1}\cap O_{2})}{P(B_{1})}$$ $P(B_{1}\cap O_{2})=\dfrac{1}{2}$ as there is only $1$ card (out of $2$ ) giving us black and orange. $P(B_{1})=\dfrac{3}{4}$ . Therefore, the resulting conditional probability is $\dfrac{2}{3}$ However, the solution of this question telling me $\dfrac{1}{3}$ is the correct answer (without explanation, just a number). What's wrong here? Thank you!","Suppose you have two cards: one is painted black on both sides and the other is painted black on one side and orange on the other You select a card at random and view one side. You notice it is black. What is the probability the other side is orange? What I have done is following: Card 1: , Card 2: , Now, we want to calculate , which is as there is only card (out of ) giving us black and orange. . Therefore, the resulting conditional probability is However, the solution of this question telling me is the correct answer (without explanation, just a number). What's wrong here? Thank you!",B_{1} B_{2} B_{1} O_{2} P(O_{2}|B_{1}) P(O_{2}|B_{1})=\dfrac{P(B_{1}\cap O_{2})}{P(B_{1})} P(B_{1}\cap O_{2})=\dfrac{1}{2} 1 2 P(B_{1})=\dfrac{3}{4} \dfrac{2}{3} \dfrac{1}{3},"['probability', 'conditional-probability']"
6,Understanding Conditional Probability (Math is Fun),Understanding Conditional Probability (Math is Fun),,"I have trouble understanding a simple concept from Math is Fun . STATEMENT: 70% of your friends like Chocolate, and 35% like Chocolate AND like Strawberry. What percent of those who like Chocolate also like Strawberry? SOLUTION: P(Strawberry|Chocolate) = P(Chocolate and Strawberry) / P(Chocolate) 0.35 / 0.7 = 50% . Hence 50% of your friends who like Chocolate also like Strawberry WHAT I CAN'T UNDERSTAND: What is the difference between the statements that ""35% of friends like both Chocolate and Strawberry"" and ""friends who like Chocolate also like Strawberry"". Just a play of words, practically they seem exact same to me. Am I missing something ?","I have trouble understanding a simple concept from Math is Fun . STATEMENT: 70% of your friends like Chocolate, and 35% like Chocolate AND like Strawberry. What percent of those who like Chocolate also like Strawberry? SOLUTION: P(Strawberry|Chocolate) = P(Chocolate and Strawberry) / P(Chocolate) 0.35 / 0.7 = 50% . Hence 50% of your friends who like Chocolate also like Strawberry WHAT I CAN'T UNDERSTAND: What is the difference between the statements that ""35% of friends like both Chocolate and Strawberry"" and ""friends who like Chocolate also like Strawberry"". Just a play of words, practically they seem exact same to me. Am I missing something ?",,['probability']
7,Maximum Entropy Distribution with Reciprocal Symmetry,Maximum Entropy Distribution with Reciprocal Symmetry,,"What is the maximum entropy distribution $F$ on $(0,\infty)$ with mean $1$ and $\Pr(x\le a)= \Pr(x\ge\frac{1}{a})$ for all $a$ ? After taking a derivative we find that the pdf $F'=f$ must satisfy $af(a)=\frac{1}{a}f(\frac{1}{a})$ . I tried using calculus of variations with lagrange multipliers, but the integrals look like they cannot be dealt with analytically. Alternatively I would also be happy simply having a pdf with mean $1$ and the given symmetry, which is not necessarily of maximum entropy. I looked at the F-distribution which has the symmetry but not the mean. One Ansatz that almost worked out is $f(x) = c\frac{1}{x} e^{-a(x+\frac{1}{x})}$ . But here $\int f\,\mathrm dx =2cK_0(2a) \overset{!}{=}1 $ and $\int x f \,\mathrm dx = 2 cK_1(2a) \overset{!}{=}1 $ leads to $K_0(x) = K_1(x)$ . But the only point where those two modified Bessel functions of the second kind agree is at $x=\infty$ , which leads to $f(x)=\delta(x-1)$ , i.e. a dirac impulse at $x=1$ . This is indeed a solution; albeit a useless one.","What is the maximum entropy distribution on with mean and for all ? After taking a derivative we find that the pdf must satisfy . I tried using calculus of variations with lagrange multipliers, but the integrals look like they cannot be dealt with analytically. Alternatively I would also be happy simply having a pdf with mean and the given symmetry, which is not necessarily of maximum entropy. I looked at the F-distribution which has the symmetry but not the mean. One Ansatz that almost worked out is . But here and leads to . But the only point where those two modified Bessel functions of the second kind agree is at , which leads to , i.e. a dirac impulse at . This is indeed a solution; albeit a useless one.","F (0,\infty) 1 \Pr(x\le a)= \Pr(x\ge\frac{1}{a}) a F'=f af(a)=\frac{1}{a}f(\frac{1}{a}) 1 f(x) = c\frac{1}{x} e^{-a(x+\frac{1}{x})} \int f\,\mathrm dx =2cK_0(2a) \overset{!}{=}1  \int x f \,\mathrm dx = 2 cK_1(2a) \overset{!}{=}1  K_0(x) = K_1(x) x=\infty f(x)=\delta(x-1) x=1","['probability', 'probability-distributions', 'entropy']"
8,"Show that $E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)]dt $",Show that,"E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)]dt ","Assume $X$, $Y$ random variables with joint distribution function $H$ and their respective marginals $F$ and $G$. I'm trying to show that: $$E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)]dt $$ My approach : So far I know that $$ E|X-Y| = \int\int_{\mathbb{R}^2}|x-y| \text{d}H(x,y)$$ from where we can straightforwardly try to reduce the integral to $$ \int_{-\infty}^{\infty}\int_{-\infty}^{x}(x-y) \text{d}H(x,y)  + \int_{-\infty}^{\infty}\int_{x}^{\infty}(y-x) \text{d}H(x,y) $$ However, I'm not sure how to proceed from here, that is, how to think about working with the $\text{d}H(x,y)$ term and how to properly take it out. Firstly, I'm not even sure if in general case we can take the $h(s,t)$ part out, where $H(x,y) = \int_{-\infty}^{x}\int_{-\infty}^{y}h(s,t)dsdt$, since $X$ and $Y$ are not necessarily continuous? Even if we could, I can't see how to properly proceed. On the other hand, by going backwards, $$ E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)] dt = \int_{-\infty}^{\infty}\left(\int_{-\infty}^{t}dF(s) + \int_{-\infty}^{t}dG(s) - 2\int_{-\infty}^{t} \int_{-\infty}^{t} dH(s,j)\right)dt$$ It also feels like something in the likes of $$ \int_{-\infty}^{t}dF(s) = \int_{-\infty}^{\infty} \int_{-\infty}^{t}dH(s,j),$$ might hold, but again, I'm not entirely sure how to work with distribution functions when they are in the integral measure part. Any hints/ideas would be appreciated!","Assume $X$, $Y$ random variables with joint distribution function $H$ and their respective marginals $F$ and $G$. I'm trying to show that: $$E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)]dt $$ My approach : So far I know that $$ E|X-Y| = \int\int_{\mathbb{R}^2}|x-y| \text{d}H(x,y)$$ from where we can straightforwardly try to reduce the integral to $$ \int_{-\infty}^{\infty}\int_{-\infty}^{x}(x-y) \text{d}H(x,y)  + \int_{-\infty}^{\infty}\int_{x}^{\infty}(y-x) \text{d}H(x,y) $$ However, I'm not sure how to proceed from here, that is, how to think about working with the $\text{d}H(x,y)$ term and how to properly take it out. Firstly, I'm not even sure if in general case we can take the $h(s,t)$ part out, where $H(x,y) = \int_{-\infty}^{x}\int_{-\infty}^{y}h(s,t)dsdt$, since $X$ and $Y$ are not necessarily continuous? Even if we could, I can't see how to properly proceed. On the other hand, by going backwards, $$ E|X-Y| = \int_{\mathbb{R}}[F(t) + G(t) - 2H(t,t)] dt = \int_{-\infty}^{\infty}\left(\int_{-\infty}^{t}dF(s) + \int_{-\infty}^{t}dG(s) - 2\int_{-\infty}^{t} \int_{-\infty}^{t} dH(s,j)\right)dt$$ It also feels like something in the likes of $$ \int_{-\infty}^{t}dF(s) = \int_{-\infty}^{\infty} \int_{-\infty}^{t}dH(s,j),$$ might hold, but again, I'm not entirely sure how to work with distribution functions when they are in the integral measure part. Any hints/ideas would be appreciated!",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'expected-value']"
9,Upper and Lower bounds on probability intersection,Upper and Lower bounds on probability intersection,,"How do I go about answering the following question. Given two events A,B with (A) = 3/4 and P(B) = 1/3, what is the smallest possible value of P(A $\cap$ B)? The largest? That is, a and b such that, $$a \leq P(A \cap B) \leq b,$$ holds and any value in the closed interval [a,b] is possible. a = ? b = ? Below is a image of what I think is the shaded area of interest. Is this correct? If so, then is the probability 1/4 x 2/3 = 1/6. In which case, a = 1/4 and b = 2/3?","How do I go about answering the following question. Given two events A,B with (A) = 3/4 and P(B) = 1/3, what is the smallest possible value of P(A $\cap$ B)? The largest? That is, a and b such that, $$a \leq P(A \cap B) \leq b,$$ holds and any value in the closed interval [a,b] is possible. a = ? b = ? Below is a image of what I think is the shaded area of interest. Is this correct? If so, then is the probability 1/4 x 2/3 = 1/6. In which case, a = 1/4 and b = 2/3?",,"['probability', 'probability-theory']"
10,A standard deck of cards is shuffled and dealt. Find the probability that the last king appears on the 48th card?,A standard deck of cards is shuffled and dealt. Find the probability that the last king appears on the 48th card?,,A standard deck of cards is shuffled and dealt. Find the probability that the last king appears on the 48th card? I would like to verify if my reasoning for the solution is correct: I attempted to use hypergeometric distribution to solve this problem. The first half of the setup deals with drawing 47 cards of which exactly 3 are Kings and 44 are non-kings. The second half of setup completes the missing conditional probability of drawing the last king on the 48th card which is $\frac {1}{5}$ $\frac {\binom {4}{3}* \binom{48}{44}}{\binom {52}{47}}* \frac {1}{5}$ Is my reasoning correct? Thank you!,A standard deck of cards is shuffled and dealt. Find the probability that the last king appears on the 48th card? I would like to verify if my reasoning for the solution is correct: I attempted to use hypergeometric distribution to solve this problem. The first half of the setup deals with drawing 47 cards of which exactly 3 are Kings and 44 are non-kings. The second half of setup completes the missing conditional probability of drawing the last king on the 48th card which is $\frac {1}{5}$ $\frac {\binom {4}{3}* \binom{48}{44}}{\binom {52}{47}}* \frac {1}{5}$ Is my reasoning correct? Thank you!,,"['probability', 'combinatorics']"
11,Ants moving from vertex to vertex on a polyhedron,Ants moving from vertex to vertex on a polyhedron,,"On a regular polyhedron, there is one ant on each vertex. In one round, every ant walks to an adjacent vertex, each adjacent vertex with equal probability. Let $P(r)$ be probability that after r rounds, each vertex still has exactly one ant. Does $P(r)$ converge as r tends to infinity? How does the function behave? Is it monotonic? For example, $P(1)$ of tetrahedron is $\frac{1}{9}$ ; $P(1)$ of octahedron is $\frac{5}{256}$ .","On a regular polyhedron, there is one ant on each vertex. In one round, every ant walks to an adjacent vertex, each adjacent vertex with equal probability. Let be probability that after r rounds, each vertex still has exactly one ant. Does converge as r tends to infinity? How does the function behave? Is it monotonic? For example, of tetrahedron is ; of octahedron is .",P(r) P(r) P(1) \frac{1}{9} P(1) \frac{5}{256},"['probability', 'recreational-mathematics']"
12,"Applying a formula like $\mathbb{E}[ X \vert \sigma(\mathcal{F},\mathcal{G}) ] = \mathbb{E}[X \vert \mathcal{G}]$",Applying a formula like,"\mathbb{E}[ X \vert \sigma(\mathcal{F},\mathcal{G}) ] = \mathbb{E}[X \vert \mathcal{G}]","Let $(Y_1, \ldots, Y_n)$ be a $[0,1]^n$-valued random vector and $U_1, \ldots, U_n$ independent random variables, uniformly distributed on $[0,1]$, and independent of $(Y_1, \ldots, Y_n)$. For some fixed $j \in \{1, \ldots, n\}$ consider the random variable $X := \mathbb{1}_{\{U_j \leq Y_j\}}$. Then I want to show that $$ \mathbb{E}[X  \vert \sigma(Y_1, \ldots, Y_n)] = \mathbb{E}[X  \vert  \sigma(Y_j)]. $$ To prove this, I thought I can use the result, that if  $\mathcal{F}$ is independent of $\sigma(\mathcal{G},\sigma(X))$, then $$ \mathbb{E}[ X   \vert  \sigma(\mathcal{F},\mathcal{G}) ] = \mathbb{E}[X  \vert  \mathcal{G}]. $$ Hence we set $\mathcal{G} : = \sigma(Y_j)$ and $\mathcal{F} : = \sigma(Y_i \colon i \in \{1, \ldots, n\} \setminus \{j\} )$. Then $\sigma(\mathcal{F},\mathcal{G}) = \sigma(Y_1, \ldots, Y_n)$. Now it remains to show that $\mathcal{F}$ is independent of  $$ \sigma(\mathcal{G},\sigma(X)) = \sigma(Y_j,\mathbb{1}_{\{ U_j \leq Y_j \}}). $$ But I only know that $U_j$ is independent of $\mathcal{F}$. I don't know anything about $Y_j$ and $Y_i$ for $i \neq j$. How can I safe this?","Let $(Y_1, \ldots, Y_n)$ be a $[0,1]^n$-valued random vector and $U_1, \ldots, U_n$ independent random variables, uniformly distributed on $[0,1]$, and independent of $(Y_1, \ldots, Y_n)$. For some fixed $j \in \{1, \ldots, n\}$ consider the random variable $X := \mathbb{1}_{\{U_j \leq Y_j\}}$. Then I want to show that $$ \mathbb{E}[X  \vert \sigma(Y_1, \ldots, Y_n)] = \mathbb{E}[X  \vert  \sigma(Y_j)]. $$ To prove this, I thought I can use the result, that if  $\mathcal{F}$ is independent of $\sigma(\mathcal{G},\sigma(X))$, then $$ \mathbb{E}[ X   \vert  \sigma(\mathcal{F},\mathcal{G}) ] = \mathbb{E}[X  \vert  \mathcal{G}]. $$ Hence we set $\mathcal{G} : = \sigma(Y_j)$ and $\mathcal{F} : = \sigma(Y_i \colon i \in \{1, \ldots, n\} \setminus \{j\} )$. Then $\sigma(\mathcal{F},\mathcal{G}) = \sigma(Y_1, \ldots, Y_n)$. Now it remains to show that $\mathcal{F}$ is independent of  $$ \sigma(\mathcal{G},\sigma(X)) = \sigma(Y_j,\mathbb{1}_{\{ U_j \leq Y_j \}}). $$ But I only know that $U_j$ is independent of $\mathcal{F}$. I don't know anything about $Y_j$ and $Y_i$ for $i \neq j$. How can I safe this?",,"['probability', 'probability-theory', 'random-variables', 'conditional-expectation']"
13,Mean return time Markov Chain,Mean return time Markov Chain,,"A Markov chain has states $0,1,2$ with transition probabilities $$P=\begin{pmatrix} 0.8 & 0.1 & 0.1 \\ 0.3 & 0.5 & 0.2 \\ 0.2 & 0.4 & 0.4 \end{pmatrix}.$$ I struggle to calculate the mean return time to state 1 given that we start at state 1. Define $T=\min{\{n\geq1 :X_n=1\}}$ and $g_i=E(T|X_0=i)$ . I seek $g_1$ . By total probability and Markov property $$g_i=\sum_{j\in {1,2,3}}E(T|X_0=i,X_1=j)P(X_0=i,X_1=j))) =\sum_{j\in {1,2,3}} E(T+1|X_0=j)P(X_0=i,X_1=j))=\sum_{j\in {1,2,3}}g_ip_{ij}+1$$ So I get the system of equations \begin{cases} g_0 = 0.8g_0+0.1g_1+0.1g_2+1 \\ g_1 = 0.3g_0+0.5g_1+0.2g_2+1 \\ g_2 = 0.2g_0+0.4g_1+0.4g_2+1 \\ \end{cases} which has no solution. What is wrong with my equations?",A Markov chain has states with transition probabilities I struggle to calculate the mean return time to state 1 given that we start at state 1. Define and . I seek . By total probability and Markov property So I get the system of equations which has no solution. What is wrong with my equations?,"0,1,2 P=\begin{pmatrix} 0.8 & 0.1 & 0.1 \\ 0.3 & 0.5 & 0.2 \\ 0.2 & 0.4 & 0.4 \end{pmatrix}. T=\min{\{n\geq1 :X_n=1\}} g_i=E(T|X_0=i) g_1 g_i=\sum_{j\in {1,2,3}}E(T|X_0=i,X_1=j)P(X_0=i,X_1=j))) =\sum_{j\in {1,2,3}} E(T+1|X_0=j)P(X_0=i,X_1=j))=\sum_{j\in {1,2,3}}g_ip_{ij}+1 \begin{cases}
g_0 = 0.8g_0+0.1g_1+0.1g_2+1 \\
g_1 = 0.3g_0+0.5g_1+0.2g_2+1 \\
g_2 = 0.2g_0+0.4g_1+0.4g_2+1 \\
\end{cases}","['probability', 'stochastic-processes', 'markov-chains']"
14,"In one roll of four standard six-sided dice, what is the probability of rolling exactly three different numbers?","In one roll of four standard six-sided dice, what is the probability of rolling exactly three different numbers?",,"In one roll of four standard six-sided dice, what is the probability of rolling exactly three different numbers? My answer: $6\cdot5\cdot4$ to get 3 numbers, then the 4th dice will have to be one of the previous 3 numbers, so it's $6\cdot5\cdot4\cdot3$; the total possibilities is $6^4$; the answer should then be $\frac{6\cdot5\cdot4\cdot3}{6^4}=\frac5{18}$. But the correct answer is $\frac59$, what did I miss? how should one think about resolving this kind of problem?","In one roll of four standard six-sided dice, what is the probability of rolling exactly three different numbers? My answer: $6\cdot5\cdot4$ to get 3 numbers, then the 4th dice will have to be one of the previous 3 numbers, so it's $6\cdot5\cdot4\cdot3$; the total possibilities is $6^4$; the answer should then be $\frac{6\cdot5\cdot4\cdot3}{6^4}=\frac5{18}$. But the correct answer is $\frac59$, what did I miss? how should one think about resolving this kind of problem?",,"['probability', 'combinatorics']"
15,"Calculating a random ""blob"" in a 10 x 10 grid","Calculating a random ""blob"" in a 10 x 10 grid",,"The problem: You have a 10 x 10 grid where each cell can be either occupied (1) or unoccupied (0). All occupied cells in the grid are part of a single ""blob"": a single shape defined by a set of occupied coordinates for which each occupied coordinate has at least one occupied coordinate to either its top, left, bottom, and/or right. (From this definition it seems the blob must occupy at least two coordinates.) How can you quickly generate a blob that is chosen randomly from the set of all possible such blobs? If it's not possible to generate such a blob quickly, why is it not possible? The (probably-wrong) method I'm using right now: I choose a random cell from the 10 x 10 grid to be the first cell of the blob. I then choose randomly from the set of cells neighboring the first cell to create the second cell of the blob (to make sure every blob is valid). I then iterate through an updated-as-it's-added-to list of all of the current cells of the blob, considering each neighboring cell once (and only once). A certain percentage of the time, I add this neighboring candidate cell to the blob. Right now I'm using 50% as the percentage. If this method of generating the blob can work (i.e. it doesn't have any fundamental problems with it), I would need to know what this certain percentage should be. My gut feelings of what the solution may look like: It seems like the blob is generally going to occupy most of the 10 x 10 grid. It seems like it might be better to first choose the size of the blob, and only then choose which cells are occupied. I suspect that the ideal way of creating the blob if I already know how big it should be would be to choose a random cell and then to repeatedly choose a random neighbor to the existing blob and make it part of the blob. I suspect it may be helpful to first create an algorithm for a simpler one-dimensional grid before trying to create one for a two-dimensional grid. Intermediate conclusions I'm coming to: It looks like for the simpler case of a one-dimensional grid, the number of possible blobs is equal to the $(n-1)th$ triangular number . See the pictures below that show a one-dimensional grid. The pattern of possible shapes as you move from $n=2$ to $n=3$ to $n=4$ is a triangular-number pattern. Clarifications: Two disconnected areas of occupied cells do not count as a single blob. Each possible blob needs to have an equal chance of being picked. Two blobs of the exact same size, shape, and orientation, but different location are considered different blobs. There are answers below which show how to generate a randomly-picked blob but where the randomly-selected blobs can't be generated quickly. I'm looking for a way to do it quickly or a proof that it's not possible to do it quickly. Some pictures I drew to wrap my head around the issue: Disclaimer: I'm dealing with an interview question where I'm allowed to use third party help as long as I disclose it. The interview question isn't to generate the blob, but by being able to correctly generate a randomly-chosen blob I can test several different possible solutions to the interview question. Some clarifications of Misha's answer: Q: Why do you say ""this method is definitely biased"" ? A: Because we already know that the unbiased method works exactly the same way except you only accept the outcome of the random selection when the rules for a blob are applied ""strictly"" (i.e. you only have a blob when there's a single connected group of occupied spaces), and so if you instead just pick an occupied space and use its connected occupied spaces as the blob, you'll at the very least be biased towards smaller blobs. Q: What do the vertical bars represent? A: They represent size / cardinality. So $B$ is the blob itself, and $|B|$ is how many cells it contains. Q: Why use the $∂$ character? A: In topology it refers to the boundary of a subset of a space. Q: How did you figure out the probability for the biased method? A: Well, $\frac{|B|}{100}$ is just the probability that you choose one of the cells of the blob, assuming it exists. So presumably the other part is the probability that it was created. To make it easier to understand, note that in the first formula you see that the odds of getting the strict blob you want (strict because you're not tolerating occupied cells not part of your blob) on any particular attempt is $2^{-100}$, because you need all 100 of those coin-flips to go exactly the way you want them. So in this less-strict situation, you need the coin-flips for your desired occupied spaces to go the way you want, and you also need the coin-flips for the unoccupied neighboring spaces to go the way you want, so that there's no chance you'll have a neighbor end up occupied and change the blob to a different one. Q: How did you figure out the lower bound? A: He just took some constraints he knew to be true and then used calculus(?) to combine those functions to determine what the lowest value could be. But to rationalize it: if you look at the formula for $p(B)$ and say ""I want to make $p(B)$ as small as possible"", you can see that you want to make the $(\frac 12)^{|B| + |∂B|}$ term as small as possible, and the way to do that is to make $|B|+|∂B|$ as big as possible. And the biggest that sum can be is 100, where the blob and its neighboring cells take up the entire grid. Then you want to make the $\frac {|B|}{100}$ term as small as possible, and the way to do that is to figure out the smallest blob that where the blob and its neighbors fill the entire grid. But since he didn't try to find an actual blob, the number he ended up with (33) may not actually correspond to a real blob (I tried creating a blob of size 33 that occupied or bordered every cell and I couldn't do it). I think the effect of that is to make it take longer for the program to run than if the number were more accurate. If the number was perfectly accurate, then you'd have a 100% chance of accepting the rarest blobs, but with the number less accurate, you have less than a 100% chance of accepting the rarest blobs, but it should still be unbiased. Q: If the goal of multiplying by the acceptance probability is to get rid of the $p(B)$ term, why use $p^*$ in the numerator? Why not use ""1""? A: Using a numerator greater than the probability of getting the rarest blobs (which is roughly $p^*$) will result in a non-uniform distribution, and using a numerator that's smaller will make the program take longer to run. The reason using a numerator greater than $p^*$ will result in a non-uniform distribution is that it will lead us to accept some not-rarest blobs with the same probability as the rarest blobs. If we have the numerator as $p^*$, then when we actually come across one of those rarest blobs, the $p(B)$ will equal $p^*$, and so the acceptance probability will be ""1"" (we'll always accept that blob). But if the numerator is larger, not only will we always accept the rarest blobs, but we will also always accept the less-rare blobs whose $p(B)$ is such that dividing the larger numerator by $p(B)$ will result in an acceptance probability of at least 1.","The problem: You have a 10 x 10 grid where each cell can be either occupied (1) or unoccupied (0). All occupied cells in the grid are part of a single ""blob"": a single shape defined by a set of occupied coordinates for which each occupied coordinate has at least one occupied coordinate to either its top, left, bottom, and/or right. (From this definition it seems the blob must occupy at least two coordinates.) How can you quickly generate a blob that is chosen randomly from the set of all possible such blobs? If it's not possible to generate such a blob quickly, why is it not possible? The (probably-wrong) method I'm using right now: I choose a random cell from the 10 x 10 grid to be the first cell of the blob. I then choose randomly from the set of cells neighboring the first cell to create the second cell of the blob (to make sure every blob is valid). I then iterate through an updated-as-it's-added-to list of all of the current cells of the blob, considering each neighboring cell once (and only once). A certain percentage of the time, I add this neighboring candidate cell to the blob. Right now I'm using 50% as the percentage. If this method of generating the blob can work (i.e. it doesn't have any fundamental problems with it), I would need to know what this certain percentage should be. My gut feelings of what the solution may look like: It seems like the blob is generally going to occupy most of the 10 x 10 grid. It seems like it might be better to first choose the size of the blob, and only then choose which cells are occupied. I suspect that the ideal way of creating the blob if I already know how big it should be would be to choose a random cell and then to repeatedly choose a random neighbor to the existing blob and make it part of the blob. I suspect it may be helpful to first create an algorithm for a simpler one-dimensional grid before trying to create one for a two-dimensional grid. Intermediate conclusions I'm coming to: It looks like for the simpler case of a one-dimensional grid, the number of possible blobs is equal to the $(n-1)th$ triangular number . See the pictures below that show a one-dimensional grid. The pattern of possible shapes as you move from $n=2$ to $n=3$ to $n=4$ is a triangular-number pattern. Clarifications: Two disconnected areas of occupied cells do not count as a single blob. Each possible blob needs to have an equal chance of being picked. Two blobs of the exact same size, shape, and orientation, but different location are considered different blobs. There are answers below which show how to generate a randomly-picked blob but where the randomly-selected blobs can't be generated quickly. I'm looking for a way to do it quickly or a proof that it's not possible to do it quickly. Some pictures I drew to wrap my head around the issue: Disclaimer: I'm dealing with an interview question where I'm allowed to use third party help as long as I disclose it. The interview question isn't to generate the blob, but by being able to correctly generate a randomly-chosen blob I can test several different possible solutions to the interview question. Some clarifications of Misha's answer: Q: Why do you say ""this method is definitely biased"" ? A: Because we already know that the unbiased method works exactly the same way except you only accept the outcome of the random selection when the rules for a blob are applied ""strictly"" (i.e. you only have a blob when there's a single connected group of occupied spaces), and so if you instead just pick an occupied space and use its connected occupied spaces as the blob, you'll at the very least be biased towards smaller blobs. Q: What do the vertical bars represent? A: They represent size / cardinality. So $B$ is the blob itself, and $|B|$ is how many cells it contains. Q: Why use the $∂$ character? A: In topology it refers to the boundary of a subset of a space. Q: How did you figure out the probability for the biased method? A: Well, $\frac{|B|}{100}$ is just the probability that you choose one of the cells of the blob, assuming it exists. So presumably the other part is the probability that it was created. To make it easier to understand, note that in the first formula you see that the odds of getting the strict blob you want (strict because you're not tolerating occupied cells not part of your blob) on any particular attempt is $2^{-100}$, because you need all 100 of those coin-flips to go exactly the way you want them. So in this less-strict situation, you need the coin-flips for your desired occupied spaces to go the way you want, and you also need the coin-flips for the unoccupied neighboring spaces to go the way you want, so that there's no chance you'll have a neighbor end up occupied and change the blob to a different one. Q: How did you figure out the lower bound? A: He just took some constraints he knew to be true and then used calculus(?) to combine those functions to determine what the lowest value could be. But to rationalize it: if you look at the formula for $p(B)$ and say ""I want to make $p(B)$ as small as possible"", you can see that you want to make the $(\frac 12)^{|B| + |∂B|}$ term as small as possible, and the way to do that is to make $|B|+|∂B|$ as big as possible. And the biggest that sum can be is 100, where the blob and its neighboring cells take up the entire grid. Then you want to make the $\frac {|B|}{100}$ term as small as possible, and the way to do that is to figure out the smallest blob that where the blob and its neighbors fill the entire grid. But since he didn't try to find an actual blob, the number he ended up with (33) may not actually correspond to a real blob (I tried creating a blob of size 33 that occupied or bordered every cell and I couldn't do it). I think the effect of that is to make it take longer for the program to run than if the number were more accurate. If the number was perfectly accurate, then you'd have a 100% chance of accepting the rarest blobs, but with the number less accurate, you have less than a 100% chance of accepting the rarest blobs, but it should still be unbiased. Q: If the goal of multiplying by the acceptance probability is to get rid of the $p(B)$ term, why use $p^*$ in the numerator? Why not use ""1""? A: Using a numerator greater than the probability of getting the rarest blobs (which is roughly $p^*$) will result in a non-uniform distribution, and using a numerator that's smaller will make the program take longer to run. The reason using a numerator greater than $p^*$ will result in a non-uniform distribution is that it will lead us to accept some not-rarest blobs with the same probability as the rarest blobs. If we have the numerator as $p^*$, then when we actually come across one of those rarest blobs, the $p(B)$ will equal $p^*$, and so the acceptance probability will be ""1"" (we'll always accept that blob). But if the numerator is larger, not only will we always accept the rarest blobs, but we will also always accept the less-rare blobs whose $p(B)$ is such that dividing the larger numerator by $p(B)$ will result in an acceptance probability of at least 1.",,"['probability', 'combinatorics', 'algorithms', 'computational-mathematics']"
16,Calculating the probability mathematically,Calculating the probability mathematically,,"A football player's performance is recorded as 'well' or 'bad'. The probability of the football player performing well after the day he performed well is $3/4$. The probability of him performing bad after the day he performed bad is $1/2$. Given that this player has performed bad on Monday, what is the probability of him performing well on Friday ? $\left(~4\ \mbox{days later}~\right)$. I was able to solve this problem using a large tree diagram. But using a tree diagram for these type of question is not the best option as it is easy to make mistakes in the middle and it takes a lot of time. How to I set this situation mathematically ?.","A football player's performance is recorded as 'well' or 'bad'. The probability of the football player performing well after the day he performed well is $3/4$. The probability of him performing bad after the day he performed bad is $1/2$. Given that this player has performed bad on Monday, what is the probability of him performing well on Friday ? $\left(~4\ \mbox{days later}~\right)$. I was able to solve this problem using a large tree diagram. But using a tree diagram for these type of question is not the best option as it is easy to make mistakes in the middle and it takes a lot of time. How to I set this situation mathematically ?.",,['probability']
17,Triangle forming probability for area,Triangle forming probability for area,,Say you have a stick which breaks randomly into three pieces (we can choose the points randomly). What is the probability that the area is greater than or equal to $0.4$? I can see it has something to do with Heron's formula but I just can't put t together.,Say you have a stick which breaks randomly into three pieces (we can choose the points randomly). What is the probability that the area is greater than or equal to $0.4$? I can see it has something to do with Heron's formula but I just can't put t together.,,['probability']
18,Applied Probability- Bayes theorem,Applied Probability- Bayes theorem,,"I need help in all things related to identifying, defining conditions and solution feed back and reasoning most importantly. 1) A blood test indicates the presence of a particular disease 95 % of the time when the diseases is actually present. The same test indicates the presence of the disease .5% of the time when the disease is not present. One percent of the population actually has the disease. Calculate the probability that a person has a disease given that the test indicates the presence of the disease. First and foremost one might think that because the word ""given"" is followed by the indication of the disease they might think that, the indication of the disease is the is the condition However my understanding is that a condition related to a mathematical definition is the state of affairs that must occur or exist before something else can happen. Well clearly one must first either have the disease or not have the disease before a test can indicate whether or not the disease is in fact present. Solution: $C=$ The individual has the disease $.01%$ $E=$ The test indicates that it is present in those with the disease $.95%$ SO we want the proportion of those that have the disease and test positive to the proportion of those that have the disease: $P(E \vert C) = \frac{P(E \cap C)}{P(E \cap C)+P(E^c \cap C)}$ $= \frac{(.01)(.95)}{(.01)(.95)+(.05)(.01)}= \frac{.0095}{.01}=.950$ My answer choices were $.324,.657,.945,.950,.995$ This one made the most sense to me? The other method I used by using the condition as the test didnt even give me anything close to 1%. Was I supposed to do it the other way and was I somehow supposed to take into account that of those that don't have the disease 50% test positive but that wouldnt make sense to me. 2) Ninety-eight percent of all babies survive delivery, However 15 percent of all births involve a c section and when they are done the baby survives 96 percent of the time. If a randomly chosen pregnant woman does not have a c section what is the probability that her baby survives? By the same logic as the previous problem the condition would only make sense to be the method of delivery because if we are talking about a baby surviving delivery then its survival is conditioned on the method of delivery. Correct? $C=$ Does not have a C-section $.85%$ $E=$ her baby survives without a c-section this is difficult to figure out: if 96% of all 15% c section births survive and since we have the percentage of the total 98 percent that survive from both non c and c section then thus 1 minus this should give us the percentage that survive when they do not have a C-section, this makes sense correct? then the probability of a baby surviving a c-section is $.98-.144=.836$ Right? Okay now we set up the question: Using this we want: $P(E \vert C)= \frac{P(EC)}{P(E \cap C)+ P(E^c \cap C)}= \frac{P(E \cap C)}{P(C)}=\frac{(.836)(.85)}{(.836)(.85)+ ?}$ ?= we want the percentage that didn't survive when they had a c-section and didn't have a c-section $(.85)(1-.836?)$ recopying and pasting we get: $P(E \vert C)= \frac{P(EC)}{P(E \cap C)+ P(E^c \cap C)}= \frac{P(E \cap C)}{P(C)}=\frac{(.836)(.85)}{(.836)(.85)+(1-.836)}=\frac{.7106}{(.7106+.164)}$ Some how this was wrong as the supposed answer is slightly above .98. I want to rant a bunch of improper things and swear at the top of my lungs who the hell does my logic not follow I used the exact definition of condition and and properly applied bayes theoreom please label every step and the reason behind each intersection obtained.","I need help in all things related to identifying, defining conditions and solution feed back and reasoning most importantly. 1) A blood test indicates the presence of a particular disease 95 % of the time when the diseases is actually present. The same test indicates the presence of the disease .5% of the time when the disease is not present. One percent of the population actually has the disease. Calculate the probability that a person has a disease given that the test indicates the presence of the disease. First and foremost one might think that because the word ""given"" is followed by the indication of the disease they might think that, the indication of the disease is the is the condition However my understanding is that a condition related to a mathematical definition is the state of affairs that must occur or exist before something else can happen. Well clearly one must first either have the disease or not have the disease before a test can indicate whether or not the disease is in fact present. Solution: $C=$ The individual has the disease $.01%$ $E=$ The test indicates that it is present in those with the disease $.95%$ SO we want the proportion of those that have the disease and test positive to the proportion of those that have the disease: $P(E \vert C) = \frac{P(E \cap C)}{P(E \cap C)+P(E^c \cap C)}$ $= \frac{(.01)(.95)}{(.01)(.95)+(.05)(.01)}= \frac{.0095}{.01}=.950$ My answer choices were $.324,.657,.945,.950,.995$ This one made the most sense to me? The other method I used by using the condition as the test didnt even give me anything close to 1%. Was I supposed to do it the other way and was I somehow supposed to take into account that of those that don't have the disease 50% test positive but that wouldnt make sense to me. 2) Ninety-eight percent of all babies survive delivery, However 15 percent of all births involve a c section and when they are done the baby survives 96 percent of the time. If a randomly chosen pregnant woman does not have a c section what is the probability that her baby survives? By the same logic as the previous problem the condition would only make sense to be the method of delivery because if we are talking about a baby surviving delivery then its survival is conditioned on the method of delivery. Correct? $C=$ Does not have a C-section $.85%$ $E=$ her baby survives without a c-section this is difficult to figure out: if 96% of all 15% c section births survive and since we have the percentage of the total 98 percent that survive from both non c and c section then thus 1 minus this should give us the percentage that survive when they do not have a C-section, this makes sense correct? then the probability of a baby surviving a c-section is $.98-.144=.836$ Right? Okay now we set up the question: Using this we want: $P(E \vert C)= \frac{P(EC)}{P(E \cap C)+ P(E^c \cap C)}= \frac{P(E \cap C)}{P(C)}=\frac{(.836)(.85)}{(.836)(.85)+ ?}$ ?= we want the percentage that didn't survive when they had a c-section and didn't have a c-section $(.85)(1-.836?)$ recopying and pasting we get: $P(E \vert C)= \frac{P(EC)}{P(E \cap C)+ P(E^c \cap C)}= \frac{P(E \cap C)}{P(C)}=\frac{(.836)(.85)}{(.836)(.85)+(1-.836)}=\frac{.7106}{(.7106+.164)}$ Some how this was wrong as the supposed answer is slightly above .98. I want to rant a bunch of improper things and swear at the top of my lungs who the hell does my logic not follow I used the exact definition of condition and and properly applied bayes theoreom please label every step and the reason behind each intersection obtained.",,['probability']
19,"A stick of length $a$ is broken in three parts. Find the probability that the length of each part is less than $b$, where $b>a/3$.","A stick of length  is broken in three parts. Find the probability that the length of each part is less than , where .",a b b>a/3,"A stick of length $a$ is broken in three parts. Find the probability that the length of each part is less than $b$, where $b>a/3$. A sample space, $\Omega$, is defined as: $$\Omega=\{(x,y): x>0,y>0,a-x-y>0\}$$ $$=\{(x,y): x>0,y>0,x+y<a\}$$ where $x,y,a-x-y$ are lenghts of broken parts. Event $A$: ""The length of every part is less than $b,b>a/3$."" $$A=\{(x,y)\in\Omega\::0<x<b,0<y<b,0<a-x-y<b\}$$ $$=\{(x,y)\in\Omega\::0<x<b,0<y<b,a-b<x+y<a\}$$ Now, what I don't understand is the following: In my book's solution it says that we consider two cases: First case $$0<\frac{a}{3}<b\le \frac{a}{2}$$ In this case, $\Omega$ is a right angled triangle with sides $a$. The problem in this case is how to determine event $A$ (I am given the geometric approach). In my book's solution it says that event $A$ is also a right angled triangle. How? Shouldn't it be quadrilateral surface? We have that $$m(A)=\int_{a-2b}^b(b-(-x+a-b))dx$$ How? Second case $$b > \frac{a}{2}$$ Here, $\Omega$ is defined as a square with side $b$, and event $A$ as a hexagonal surface. How? We have that $$m(A)=b^2-\frac{1}{2}(a-b)^2-\frac{1}{2}(2b-c)^2$$ Why do we choose $\frac{a}{2}$ as a bound in both cases?","A stick of length $a$ is broken in three parts. Find the probability that the length of each part is less than $b$, where $b>a/3$. A sample space, $\Omega$, is defined as: $$\Omega=\{(x,y): x>0,y>0,a-x-y>0\}$$ $$=\{(x,y): x>0,y>0,x+y<a\}$$ where $x,y,a-x-y$ are lenghts of broken parts. Event $A$: ""The length of every part is less than $b,b>a/3$."" $$A=\{(x,y)\in\Omega\::0<x<b,0<y<b,0<a-x-y<b\}$$ $$=\{(x,y)\in\Omega\::0<x<b,0<y<b,a-b<x+y<a\}$$ Now, what I don't understand is the following: In my book's solution it says that we consider two cases: First case $$0<\frac{a}{3}<b\le \frac{a}{2}$$ In this case, $\Omega$ is a right angled triangle with sides $a$. The problem in this case is how to determine event $A$ (I am given the geometric approach). In my book's solution it says that event $A$ is also a right angled triangle. How? Shouldn't it be quadrilateral surface? We have that $$m(A)=\int_{a-2b}^b(b-(-x+a-b))dx$$ How? Second case $$b > \frac{a}{2}$$ Here, $\Omega$ is defined as a square with side $b$, and event $A$ as a hexagonal surface. How? We have that $$m(A)=b^2-\frac{1}{2}(a-b)^2-\frac{1}{2}(2b-c)^2$$ Why do we choose $\frac{a}{2}$ as a bound in both cases?",,"['probability', 'geometric-probability']"
20,"Any counter example for $P(A|C)=P(A),P(B|C)=P(B)$ but $P(A\cap B|C)\neq P(A\cap B)$?",Any counter example for  but ?,"P(A|C)=P(A),P(B|C)=P(B) P(A\cap B|C)\neq P(A\cap B)","Let $A,B,C$ be three events, what would be an example that $P(A|C)=P(A)$ and $P(B|C)=P(B)$ do not imply $P(A\cap B|C)= P(A\cap B)$?","Let $A,B,C$ be three events, what would be an example that $P(A|C)=P(A)$ and $P(B|C)=P(B)$ do not imply $P(A\cap B|C)= P(A\cap B)$?",,"['probability', 'examples-counterexamples']"
21,Probability - Expected number of draws to get all 52 cards at least once drawing in groups of size n [duplicate],Probability - Expected number of draws to get all 52 cards at least once drawing in groups of size n [duplicate],,"This question already has an answer here : Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen (1 answer) Closed 4 years ago . Imagine you have a deck of cards and want to be fairly sure that you draw each card once (with a perfectly fair, complete, and random deck on each draw, of course). You are drawing cards in groups of size n from the deck. What is the expected number of draws such that each card has been drawn at least once? Similar to the coupon collector's problem , but not quite. How would one go about integrating the math for that algorithm with drawing multiple cards at the same time? Edit: found some duplicate questions. How to calculate the expected value of the coupon collector problem if we are collecting the coupons in groups of k? Coupon Collector Problem with Batched Selections","This question already has an answer here : Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen (1 answer) Closed 4 years ago . Imagine you have a deck of cards and want to be fairly sure that you draw each card once (with a perfectly fair, complete, and random deck on each draw, of course). You are drawing cards in groups of size n from the deck. What is the expected number of draws such that each card has been drawn at least once? Similar to the coupon collector's problem , but not quite. How would one go about integrating the math for that algorithm with drawing multiple cards at the same time? Edit: found some duplicate questions. How to calculate the expected value of the coupon collector problem if we are collecting the coupons in groups of k? Coupon Collector Problem with Batched Selections",,"['probability', 'card-games', 'coupon-collector']"
22,Feller - Question on two throws of three dice,Feller - Question on two throws of three dice,,"I am stuck at the following question. What is the probability that two throws with three dice each will show the same configuration if (a) the dice are distinguishable (b) they are not. Solution. (a) $P(\text{Two throws of three dice s.t. each show the same configuration})=6^{3}/6^{6}=1/216$. (b)Firstly from the second set of throws, the $3$ dies with the same face value as the first ones can be chosen in $3!=6$ ways. Place $r=3$ dies in $n=6$ cells, such that order does not matter with repetition, can be done in ${{3+6-1}\choose{3}}={8\choose 3}=56$ ${\displaystyle P(\text{Two throws of three indistinguishable dice show the same configuration})=\frac{56\times6}{6^{6}}}$ However, my answer to the second part of the problem is incorrect. Could someone help me think correctly about the problem.","I am stuck at the following question. What is the probability that two throws with three dice each will show the same configuration if (a) the dice are distinguishable (b) they are not. Solution. (a) $P(\text{Two throws of three dice s.t. each show the same configuration})=6^{3}/6^{6}=1/216$. (b)Firstly from the second set of throws, the $3$ dies with the same face value as the first ones can be chosen in $3!=6$ ways. Place $r=3$ dies in $n=6$ cells, such that order does not matter with repetition, can be done in ${{3+6-1}\choose{3}}={8\choose 3}=56$ ${\displaystyle P(\text{Two throws of three indistinguishable dice show the same configuration})=\frac{56\times6}{6^{6}}}$ However, my answer to the second part of the problem is incorrect. Could someone help me think correctly about the problem.",,"['probability', 'combinatorics']"
23,Moments of standard normal random variable,Moments of standard normal random variable,,"I want to show that for $n \geq 1$ we have $\mathbb{E}Z^{n+1} = n\mathbb{E}Z^{n−1}$ (where $Z$ is a standard normal RV). I've tried induction, but I'm not quite sure how to make use of the inductive hypothesis, so I am hoping someone can suggest a different approach. Thanks","I want to show that for $n \geq 1$ we have $\mathbb{E}Z^{n+1} = n\mathbb{E}Z^{n−1}$ (where $Z$ is a standard normal RV). I've tried induction, but I'm not quite sure how to make use of the inductive hypothesis, so I am hoping someone can suggest a different approach. Thanks",,"['probability', 'random-variables', 'normal-distribution', 'expectation']"
24,Why is $ Var(X)= E(Var(X|Y))+Var(E(X|Y)) $?,Why is ?, Var(X)= E(Var(X|Y))+Var(E(X|Y)) ,I see this identity but it does not make sense to me. $ Var(X)= EVar(X|Y)+Var(E(X|Y)) $ Is this something that should intuitively make sense? Is it saying the variance of $X$ is equal to the expected variance of $X$ given $Y$ plus the variance of $Y$ ? I say the second part because since $E(X|Y)$ is a function with Y as variable $Var(E(X|Y))$ would capture the variance of $Y$ .,I see this identity but it does not make sense to me. Is this something that should intuitively make sense? Is it saying the variance of is equal to the expected variance of given plus the variance of ? I say the second part because since is a function with Y as variable would capture the variance of ., Var(X)= EVar(X|Y)+Var(E(X|Y))  X X Y Y E(X|Y) Var(E(X|Y)) Y,['probability']
25,Expected vertex in a tetrahedron,Expected vertex in a tetrahedron,,"The following is taken from this problem sheet for quant interviews A bug crawls along the edges of a regular tetrahedron ABCD with edges length 1. It starts at A and at each vertex chooses its next edge at random (so it has a $1/3$ chance of going back along the edge it came on, and a $1/3$ chance of going along each of the other two). Find the probability that after it has crawled a distance 7 it is again at A. Numerical simulations suggest that the answer is $1/4$ , but I'm not sure if that's right. On the first step the distribution is $(0,1/3,1/3,1/3)$ , and on the second step it is $(1/3,2/9,2/9,2/9)$ . I can continue doing this but my interviewer would be bored out of his/her mind! Is there a slick way to do this?","The following is taken from this problem sheet for quant interviews A bug crawls along the edges of a regular tetrahedron ABCD with edges length 1. It starts at A and at each vertex chooses its next edge at random (so it has a chance of going back along the edge it came on, and a chance of going along each of the other two). Find the probability that after it has crawled a distance 7 it is again at A. Numerical simulations suggest that the answer is , but I'm not sure if that's right. On the first step the distribution is , and on the second step it is . I can continue doing this but my interviewer would be bored out of his/her mind! Is there a slick way to do this?","1/3 1/3 1/4 (0,1/3,1/3,1/3) (1/3,2/9,2/9,2/9)","['probability', 'combinatorics']"
26,Help understanding convolutions for probability?,Help understanding convolutions for probability?,,"I have been trying to do some problems in probability that use convolutions but there has not been much of an explanation of what a convolution is or the purpose of using a convolution. For example in the following problem: Let X and Y be two independent exponential distributions with mean $1$ . Find the distribution of $\frac{X}{Y}$ . So I define $U=\frac{X}{Y}$ and $V=Y$ then $$f_U(u)=\int_{-\infty}^{\infty}f_{XY}(uv,v)dv=\int_{0}^{\infty}e^{-uv}e^{-v}dv=\frac{1}{u+1}$$ Maybe one could explain a simpler problem: Let X and Y be two random variables with joint density function $f_{XY}$ . Compute the pdf of $U = Y − X$ .  So I tried the following and maybe its correct I dont know just using formulas $$f_U(u)=\int_{-\infty}^{\infty}f_{XY}(x,u+x)dx=\int_{-\infty}^{\infty}f_{XY}(y-u,y)dy$$ I was given the formula $(f*g)(z)=\int_{-\infty}^{\infty}f(z-y)g(y)dy=\int_{-\infty}^{\infty}f(x)g(z-x)dx$ I do not fully understand what I am supposed to be putting into $f(z-y)g(y)$ part of the integrals specifically for $(z-y)$ .",I have been trying to do some problems in probability that use convolutions but there has not been much of an explanation of what a convolution is or the purpose of using a convolution. For example in the following problem: Let X and Y be two independent exponential distributions with mean . Find the distribution of . So I define and then Maybe one could explain a simpler problem: Let X and Y be two random variables with joint density function . Compute the pdf of .  So I tried the following and maybe its correct I dont know just using formulas I was given the formula I do not fully understand what I am supposed to be putting into part of the integrals specifically for .,"1 \frac{X}{Y} U=\frac{X}{Y} V=Y f_U(u)=\int_{-\infty}^{\infty}f_{XY}(uv,v)dv=\int_{0}^{\infty}e^{-uv}e^{-v}dv=\frac{1}{u+1} f_{XY} U = Y − X f_U(u)=\int_{-\infty}^{\infty}f_{XY}(x,u+x)dx=\int_{-\infty}^{\infty}f_{XY}(y-u,y)dy (f*g)(z)=\int_{-\infty}^{\infty}f(z-y)g(y)dy=\int_{-\infty}^{\infty}f(x)g(z-x)dx f(z-y)g(y) (z-y)","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
27,"Variant of dominated convergence theorem, does it follow that $\int f_n \to \int f$?","Variant of dominated convergence theorem, does it follow that ?",\int f_n \to \int f,"Suppose $f_n$, $g_n$, $f$ and $g$ are integrable, $f_n \to f$ almost everywhere, $g_n \to g$ almost everywhere, $|f_n| \le g_n$ for each $n$, and $\int g_n \to \int g$. Does it follow that $\int f_n \to \int f$?","Suppose $f_n$, $g_n$, $f$ and $g$ are integrable, $f_n \to f$ almost everywhere, $g_n \to g$ almost everywhere, $|f_n| \le g_n$ for each $n$, and $\int g_n \to \int g$. Does it follow that $\int f_n \to \int f$?",,"['real-analysis', 'probability']"
28,"Consider $P(A_i) = 1,\,\forall i \in \mathbb{N}.$ Prove that $P\left(\bigcap_{i=1}^{\infty} A_i \right) = 1.$",Consider  Prove that,"P(A_i) = 1,\,\forall i \in \mathbb{N}. P\left(\bigcap_{i=1}^{\infty} A_i \right) = 1.","I have been working on some tough problems in my statistics book, and I came across a problem that I was having some difficulty with. Consider $$ P(A_i) = 1,\,\forall i \in \mathbb{N}.$$ I want to prove that $$P\left(\bigcap_{i=1}^{\infty} A_i \right) = 1.$$ I can see where the intuition comes in here, but it is difficult for me to entirely see it. I had imagined initially that I could simply create a massive conditional chain, i.e. $$P\left(\bigcap_{i=1}^{\infty} A_i | \bigcap_{i=2}^{\infty} A_i\right) P\left(\bigcap_{i=2}^{\infty} A_i | \bigcap_{i=3}^{\infty} A_i\right) ... =P\left( A_1 | \bigcap_{i=2}^{\infty} A_i\right) P\left(A_2 | \bigcap_{i=3}^{\infty} A_i\right) ...,$$ However, I am not sure what I should do to properly calculate these, nor am I entirely sure if this was logically reasonable in terms of the definitions of probability. Any suggestions?","I have been working on some tough problems in my statistics book, and I came across a problem that I was having some difficulty with. Consider $$ P(A_i) = 1,\,\forall i \in \mathbb{N}.$$ I want to prove that $$P\left(\bigcap_{i=1}^{\infty} A_i \right) = 1.$$ I can see where the intuition comes in here, but it is difficult for me to entirely see it. I had imagined initially that I could simply create a massive conditional chain, i.e. $$P\left(\bigcap_{i=1}^{\infty} A_i | \bigcap_{i=2}^{\infty} A_i\right) P\left(\bigcap_{i=2}^{\infty} A_i | \bigcap_{i=3}^{\infty} A_i\right) ... =P\left( A_1 | \bigcap_{i=2}^{\infty} A_i\right) P\left(A_2 | \bigcap_{i=3}^{\infty} A_i\right) ...,$$ However, I am not sure what I should do to properly calculate these, nor am I entirely sure if this was logically reasonable in terms of the definitions of probability. Any suggestions?",,"['probability', 'probability-theory']"
29,63% chance of event happening over repeated attempts,63% chance of event happening over repeated attempts,,"This question is of interest: If there is a $1 / x$ chance of something happening, in $x$ attempts, for   large numbers over $50$ or so, the likelihood of it happening is about   $63\%$. If there's a $1$ in $10\,000$ chance of getting hit by a meteor if you   go outside, if you go outside $10\,000$ times, you have a $63\%$ chance of   getting hit with a meteor at some point. If there's a $1$ in a million   chance of winning the lottery and you buy a million (random) lottery   tickets, you have a $63\%$ chance of winning. What is the main idea underlying this property?","This question is of interest: If there is a $1 / x$ chance of something happening, in $x$ attempts, for   large numbers over $50$ or so, the likelihood of it happening is about   $63\%$. If there's a $1$ in $10\,000$ chance of getting hit by a meteor if you   go outside, if you go outside $10\,000$ times, you have a $63\%$ chance of   getting hit with a meteor at some point. If there's a $1$ in a million   chance of winning the lottery and you buy a million (random) lottery   tickets, you have a $63\%$ chance of winning. What is the main idea underlying this property?",,"['probability', 'recreational-mathematics']"
30,Drawing cards without replacement: all kings before any jacks,Drawing cards without replacement: all kings before any jacks,,"This is a question that came up with my friends while playing a card drinking game: You draw cards without replacement from a standard 52-card shuffled deck. What is the probability that you draw all of the kings before drawing any of the jacks? I was thinking of a solution along the lines of combinations, but I'm not sure if that's the way to go. Simulation tells me the answer is ~1.4%, but I don't know how to get to this answer. Disclaimer: This is not a homework question. I'm really just curious.","This is a question that came up with my friends while playing a card drinking game: You draw cards without replacement from a standard 52-card shuffled deck. What is the probability that you draw all of the kings before drawing any of the jacks? I was thinking of a solution along the lines of combinations, but I'm not sure if that's the way to go. Simulation tells me the answer is ~1.4%, but I don't know how to get to this answer. Disclaimer: This is not a homework question. I'm really just curious.",,"['probability', 'discrete-mathematics']"
31,paired t-test vs Welch's t-test.,paired t-test vs Welch's t-test.,,Need to find a 95% confidence interval for $E(Z)$ where $Z=X-Y$ using both paired t-test and Welch's t-test. For one what is the main difference between them and for two how do you do it? Need help studying for a test so the answer can be generic.,Need to find a 95% confidence interval for $E(Z)$ where $Z=X-Y$ using both paired t-test and Welch's t-test. For one what is the main difference between them and for two how do you do it? Need help studying for a test so the answer can be generic.,,"['probability', 'probability-theory', 'confidence-interval']"
32,Basic probability : the frog riddle - what are the chances?,Basic probability : the frog riddle - what are the chances?,,"A few days ago I was watching this video The frog riddle and I have been thinking a lot about this riddle. In this riddle you are poisoned and need to lick a female frog to survive. There are 2 frogs behind you and basically, you have to find what are your chances to find a least one female in these two frogs (you can lick both of them). The only thing is  : you know one of them is a male (because your heard the croak) but you don't know witch one. The video solves the problem with conditional probability and explains that you have a 2/3 chance of getting a female. (on the four possibilities MM / MF / FM / FF, knowing there is a male eliminates FF) Here is my question : If you see which one is a male (for example the frog on the left is a male) what are your chances to survive ? Is it 1/2 ? because we only have two possibilities (MM or MF) with probability 1/2. Is it still 2/3 because the position does not matter ? Bonus question : If it is 1/2, then if close your eyes and the frogs can move, is it still 1/2 or does it comes back to 2/3 ? Similar problem : If I have two children, and I know one is a son, then I have a 67% chance to have a daughter. But if I know the oldest one is a son, then I have a 50% chance to have a daughter. Is it exactly the same problem here ? Can you please explain this to me ?","A few days ago I was watching this video The frog riddle and I have been thinking a lot about this riddle. In this riddle you are poisoned and need to lick a female frog to survive. There are 2 frogs behind you and basically, you have to find what are your chances to find a least one female in these two frogs (you can lick both of them). The only thing is  : you know one of them is a male (because your heard the croak) but you don't know witch one. The video solves the problem with conditional probability and explains that you have a 2/3 chance of getting a female. (on the four possibilities MM / MF / FM / FF, knowing there is a male eliminates FF) Here is my question : If you see which one is a male (for example the frog on the left is a male) what are your chances to survive ? Is it 1/2 ? because we only have two possibilities (MM or MF) with probability 1/2. Is it still 2/3 because the position does not matter ? Bonus question : If it is 1/2, then if close your eyes and the frogs can move, is it still 1/2 or does it comes back to 2/3 ? Similar problem : If I have two children, and I know one is a son, then I have a 67% chance to have a daughter. But if I know the oldest one is a son, then I have a 50% chance to have a daughter. Is it exactly the same problem here ? Can you please explain this to me ?",,"['probability', 'puzzle']"
33,The logic behind a sequence,The logic behind a sequence,,"I am trying to get the logic behind the sequence: for $n=2,3,\ldots$ $$\left(\frac{\log (2)}{\log \left(\frac{3}{2}\right)},\frac{\log (3)}{\log \left(\frac{17}{9}\right)},\frac{\log (4)}{\log \left(\frac{71}{32}\right)},\frac{\log (5)}{\log \left(\frac{1569}{625}\right)},\frac{\log (6)}{\log \left(\frac{899}{324}\right)},\frac{\log (7)}{\log \left(\frac{355081}{117649}\right)},\frac{\log (8)}{\log \left(\frac{425331}{131072}\right)},\frac{\log (9)}{\log \left(\frac{16541017}{4782969}\right)},\frac{\log (10)}{\log \left(\frac{5719087}{1562500}\right)},\frac{\log (11)}{\log \left(\frac{99920609601}{25937424601}\right)},\frac{\log (12)}{\log \left(\frac{144619817}{35831808}\right)},\ldots\right)$$ for $n=30$ it is $$\frac{\log (30)}{\log \left(\frac{53774416559964522337191179}{16}\right)-16 \log (3)-23 \log (5)}$$ $\textbf{Background}$: This is part of a project to figure out how slowly the errors of power law distributed sums obey the law of large numbers. So it may not be necessary to find the logic of the sequence above, but these correspond to the exponent $\left\{{\alpha:\frac{MD(n)}{MD(1)}=\left(\frac{1}{n}\right)^{1-\frac{1}{\alpha }}}\right\}$,where $MD(n)$ is the mean absolute deviation of an n-summed Student T distributed variable with tail exponent/degrees of freedom equal 3 (and a mean of $0$). Numerically we get $$\{1.70951,1.72741,1.73951,1.74855,1.7557,1.76158,1.76655,1.77084,1.7746,1.77795,1.78095,1.78367,1.78615,1.78843,1.79054,1.79249,1.79432,1.79602,1.79762,1.79913,1.80056,1.80191,1.80319,1.80441,1.80557,1.80669,1.80775,1.80877,1.80974\},$$  a slow convergence to 2, which is the case with a Normal Distribution.","I am trying to get the logic behind the sequence: for $n=2,3,\ldots$ $$\left(\frac{\log (2)}{\log \left(\frac{3}{2}\right)},\frac{\log (3)}{\log \left(\frac{17}{9}\right)},\frac{\log (4)}{\log \left(\frac{71}{32}\right)},\frac{\log (5)}{\log \left(\frac{1569}{625}\right)},\frac{\log (6)}{\log \left(\frac{899}{324}\right)},\frac{\log (7)}{\log \left(\frac{355081}{117649}\right)},\frac{\log (8)}{\log \left(\frac{425331}{131072}\right)},\frac{\log (9)}{\log \left(\frac{16541017}{4782969}\right)},\frac{\log (10)}{\log \left(\frac{5719087}{1562500}\right)},\frac{\log (11)}{\log \left(\frac{99920609601}{25937424601}\right)},\frac{\log (12)}{\log \left(\frac{144619817}{35831808}\right)},\ldots\right)$$ for $n=30$ it is $$\frac{\log (30)}{\log \left(\frac{53774416559964522337191179}{16}\right)-16 \log (3)-23 \log (5)}$$ $\textbf{Background}$: This is part of a project to figure out how slowly the errors of power law distributed sums obey the law of large numbers. So it may not be necessary to find the logic of the sequence above, but these correspond to the exponent $\left\{{\alpha:\frac{MD(n)}{MD(1)}=\left(\frac{1}{n}\right)^{1-\frac{1}{\alpha }}}\right\}$,where $MD(n)$ is the mean absolute deviation of an n-summed Student T distributed variable with tail exponent/degrees of freedom equal 3 (and a mean of $0$). Numerically we get $$\{1.70951,1.72741,1.73951,1.74855,1.7557,1.76158,1.76655,1.77084,1.7746,1.77795,1.78095,1.78367,1.78615,1.78843,1.79054,1.79249,1.79432,1.79602,1.79762,1.79913,1.80056,1.80191,1.80319,1.80441,1.80557,1.80669,1.80775,1.80877,1.80974\},$$  a slow convergence to 2, which is the case with a Normal Distribution.",,"['probability', 'sequences-and-series', 'probability-distributions', 'probability-limit-theorems', 'law-of-large-numbers']"
34,Erasing numbers from the front of the row,Erasing numbers from the front of the row,,"Numbers $1,2,\ldots,k$ are written in this order in a row. For $i=1,\ldots,k$, in the $i$th step, a random variable $V_i$ is drawn uniformly from the interval $[0,2i]$. If $V_i$ is greater than the first remaining number, that number is erased. What is the expected number of numbers that will be erased? For example, if $k=1$, then we have the number $1$ and $V_1$ drawn from $[0,2]$, so $1/2$ numbers will be erased in expectation. If $k=2$, then with probability $1/2$ we have $V_1>1$ and it is 50-50 whether the second number is erased. Otherwise $V_1<1$ and with probability $3/4$ the first number is erased. So the answer is $(1/2)(3/2)+(1/2)(3/4)=9/8$. For $k=3$, a similar case analysis shows that the answer is $85/48$ (if I calculated correctly.) It could be that no closed form can be found in general. If so, upper/lower bounds would still be interesting.","Numbers $1,2,\ldots,k$ are written in this order in a row. For $i=1,\ldots,k$, in the $i$th step, a random variable $V_i$ is drawn uniformly from the interval $[0,2i]$. If $V_i$ is greater than the first remaining number, that number is erased. What is the expected number of numbers that will be erased? For example, if $k=1$, then we have the number $1$ and $V_1$ drawn from $[0,2]$, so $1/2$ numbers will be erased in expectation. If $k=2$, then with probability $1/2$ we have $V_1>1$ and it is 50-50 whether the second number is erased. Otherwise $V_1<1$ and with probability $3/4$ the first number is erased. So the answer is $(1/2)(3/2)+(1/2)(3/4)=9/8$. For $k=3$, a similar case analysis shows that the answer is $85/48$ (if I calculated correctly.) It could be that no closed form can be found in general. If so, upper/lower bounds would still be interesting.",,"['probability', 'expectation']"
35,Expected waiting time for next train,Expected waiting time for next train,,"Let's say a train arrives at a stop in intervals of 15 or 45 minutes, each with equal probability 1/2 (so every time a train arrives, it will randomly be either 15 or 45 minutes until the next arrival). What is the expected waiting time of a passenger for the next train if this passenger arrives at the stop at any random time. This means that the passenger has no sense of time nor know when the last train left and could enter the station at any point within the interval of 2 consecutive trains. I was told 15 minutes was the wrong answer and my machine simulated answer is 18.75 minutes. I just don't know the mathematical approach for this problem and of course the exact true answer. Sincerely hope you guys can help me. Thanks!","Let's say a train arrives at a stop in intervals of 15 or 45 minutes, each with equal probability 1/2 (so every time a train arrives, it will randomly be either 15 or 45 minutes until the next arrival). What is the expected waiting time of a passenger for the next train if this passenger arrives at the stop at any random time. This means that the passenger has no sense of time nor know when the last train left and could enter the station at any point within the interval of 2 consecutive trains. I was told 15 minutes was the wrong answer and my machine simulated answer is 18.75 minutes. I just don't know the mathematical approach for this problem and of course the exact true answer. Sincerely hope you guys can help me. Thanks!",,"['probability', 'expectation']"
36,Probability of a boring afternoon,Probability of a boring afternoon,,"I am extremely bad in probabilities (as in so many other areas) and I fully understand that this question is off-topic and/or missing context (may I underline that this is not homework). Could you tell me how to compute the probability that, in a bridge tournament consisting in $n$ deals, it can happen that I never get more than $p$ points in my hand ? If needed, each player has $13$ cards in hand and the points are counted as ${Ace}=4$, $King=3$, $Queen=2$, $Jack=1$. This happened to me last week with $n=28$ and $p=8$ and this has been a very boring tournament for me (not for my opponents !). Thanks in advance.","I am extremely bad in probabilities (as in so many other areas) and I fully understand that this question is off-topic and/or missing context (may I underline that this is not homework). Could you tell me how to compute the probability that, in a bridge tournament consisting in $n$ deals, it can happen that I never get more than $p$ points in my hand ? If needed, each player has $13$ cards in hand and the points are counted as ${Ace}=4$, $King=3$, $Queen=2$, $Jack=1$. This happened to me last week with $n=28$ and $p=8$ and this has been a very boring tournament for me (not for my opponents !). Thanks in advance.",,['probability']
37,Existence of independent uniform random variables,Existence of independent uniform random variables,,"Let $\Omega = [0,1]$ equipped with the Borel $\sigma$-algebra and Lebesgue measure. Let $X:\Omega\rightarrow\mathbb{R}$ be defined by $X(\omega) = \omega$. Clearly $X$ is uniform $(0,1)$ distributed. Does there exist a random variable $Y:\Omega\rightarrow\mathbb{R}$ which is uniform $(0,1)$ distributed such that $X$ and $Y$ are independent? And if so, can we find a formula for $Y$? I'm convinced that $Y$ should exist, but I don't know how I would construct it.","Let $\Omega = [0,1]$ equipped with the Borel $\sigma$-algebra and Lebesgue measure. Let $X:\Omega\rightarrow\mathbb{R}$ be defined by $X(\omega) = \omega$. Clearly $X$ is uniform $(0,1)$ distributed. Does there exist a random variable $Y:\Omega\rightarrow\mathbb{R}$ which is uniform $(0,1)$ distributed such that $X$ and $Y$ are independent? And if so, can we find a formula for $Y$? I'm convinced that $Y$ should exist, but I don't know how I would construct it.",,"['probability', 'probability-distributions']"
38,Existence of the Brownian Motion using the Kolmogorov extension theorem,Existence of the Brownian Motion using the Kolmogorov extension theorem,,"Kolmogorov extension theorem: Let $T$ denote some interval (thought of as ""time""), and let $n \in \mathbb{N}.$ For each $k \in \mathbb{N}$ and finite sequence of times $t_{1}, \dots, t_{k} \in T$, let $\nu_{t_{1} \dots t_{k}}$ be a probability measure on $(\mathbb{R}^{n})^{k}.$ Suppose that these measures satisfy two consistency conditions: for all permutations $\pi$ of $\{ 1, \dots, k \}$ and measurable sets $F_{i} \subseteq \mathbb{R}^{n}$, $$\nu_{t_{\pi (1)} \dots t_{\pi (k)}} \left( F_{\pi (1)} \times \dots \times F_{ \pi(k)} \right) = \nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right);$$ for all measurable sets $F_{i} \subseteq \mathbb{R}^{n},m \in \mathbb{N}$ $$\nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right) = \nu_{t_{1} \dots t_{k} t_{k + 1}, \dots , t_{k+m}} \left( F_{1} \times \dots \times F_{k} \times \mathbb{R}^{n} \times \dots \times \mathbb{R}^{n} \right).$$ Then there exists a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and a stochastic process $X : T \times \Omega \to \mathbb{R}^{n}$ such that $$   \nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right) = \mathbb{P} \left( X_{t_{1}} \in F_{1}, \dots, X_{t_{k}} \in F_{k} \right) $$ for all $t_{i} \in T, k \in \mathbb{N}$ and measurable sets $F_{i} \subseteq \mathbb{R}^{n},$ i.e. $X$ has $\nu_{t_{1} \dots t_{k}}$ as its finite-dimensional distributions relative to times $t_{1} \dots t_{k}.$ Brownian motion: The Brownian motion $B_t$ is characterised by four facts: $B_0=0$ $B_t$ is almost surely continuous $B_t$ has independent increments $B_t-B_s\sim \mathcal{N}(0,t-s)$ (for $0 \leq s \le t$) $\mathcal{N}(\mu,\sigma^2)$ denotes the normal distribution with expected value $\mu$ and variance $\sigma^2.$ The condition that it has independent increments means that if $0 \leq s_1 \leq t_1 \leq s_2 \leq t_2$ then $B_{t_1}-B_{s_1}$ and $B_{t_2}-B_{s_2}$ are independent random variables. MY QUESTION : How to proof the existence of the Brownian Motion using the Kolmogorov extension theorem?","Kolmogorov extension theorem: Let $T$ denote some interval (thought of as ""time""), and let $n \in \mathbb{N}.$ For each $k \in \mathbb{N}$ and finite sequence of times $t_{1}, \dots, t_{k} \in T$, let $\nu_{t_{1} \dots t_{k}}$ be a probability measure on $(\mathbb{R}^{n})^{k}.$ Suppose that these measures satisfy two consistency conditions: for all permutations $\pi$ of $\{ 1, \dots, k \}$ and measurable sets $F_{i} \subseteq \mathbb{R}^{n}$, $$\nu_{t_{\pi (1)} \dots t_{\pi (k)}} \left( F_{\pi (1)} \times \dots \times F_{ \pi(k)} \right) = \nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right);$$ for all measurable sets $F_{i} \subseteq \mathbb{R}^{n},m \in \mathbb{N}$ $$\nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right) = \nu_{t_{1} \dots t_{k} t_{k + 1}, \dots , t_{k+m}} \left( F_{1} \times \dots \times F_{k} \times \mathbb{R}^{n} \times \dots \times \mathbb{R}^{n} \right).$$ Then there exists a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and a stochastic process $X : T \times \Omega \to \mathbb{R}^{n}$ such that $$   \nu_{t_{1} \dots t_{k}} \left( F_{1} \times \dots \times F_{k} \right) = \mathbb{P} \left( X_{t_{1}} \in F_{1}, \dots, X_{t_{k}} \in F_{k} \right) $$ for all $t_{i} \in T, k \in \mathbb{N}$ and measurable sets $F_{i} \subseteq \mathbb{R}^{n},$ i.e. $X$ has $\nu_{t_{1} \dots t_{k}}$ as its finite-dimensional distributions relative to times $t_{1} \dots t_{k}.$ Brownian motion: The Brownian motion $B_t$ is characterised by four facts: $B_0=0$ $B_t$ is almost surely continuous $B_t$ has independent increments $B_t-B_s\sim \mathcal{N}(0,t-s)$ (for $0 \leq s \le t$) $\mathcal{N}(\mu,\sigma^2)$ denotes the normal distribution with expected value $\mu$ and variance $\sigma^2.$ The condition that it has independent increments means that if $0 \leq s_1 \leq t_1 \leq s_2 \leq t_2$ then $B_{t_1}-B_{s_1}$ and $B_{t_2}-B_{s_2}$ are independent random variables. MY QUESTION : How to proof the existence of the Brownian Motion using the Kolmogorov extension theorem?",,"['probability', 'reference-request', 'stochastic-processes', 'brownian-motion']"
39,"Find $E(|X-Y|^a)$ where $X$ and $Y$ are independent uniform on $(0,1)$",Find  where  and  are independent uniform on,"E(|X-Y|^a) X Y (0,1)","Let $X,Y$ be independent $Uniform(0,1)$ random variables. Find $E(|X-Y|^a)$ where $a>0$ . My working: Define $W=1$ if $X>Y$ and $W=0$ if $X<Y$ . We seek $E(|X-Y|^a)=E[E(|X-Y|^a|W)]=E(|X-Y|^a|W=1)P(W=1)+E(|X-Y|^a|W=0)P(W=0)=E((X-Y)^a)P(X>Y)+E((Y-X)^a)P(X<Y)$ . Now $P(X<Y)=\dfrac{1}{2}$ and $P(X>Y)=\dfrac{1}{2}$ by symmetry. $E((X-Y)^a)=\int_{0}^{1}\int_{0}^{x}(x-y)^af_{X,Y}(x,y)dydx=\int_{0}^{1}\int_{0}^{x}(x-y)^adydx=\dfrac{1}{(a+1)(a+2)}$ . Similarly $E((Y-X)^a)=\dfrac{1}{(a+1)(a+2)}$ by symmetry when $Y>X$ . Required expectation= $\dfrac{1}{(a+1)(a+2)}\dfrac{1}{2}+\dfrac{1}{(a+1)(a+2)}\dfrac{1}{2}=\dfrac{1}{(a+1)(a+2)}$ But correct answer is $\dfrac{2}{(a+1)(a+2)}$ . Where am I going wrong?",Let be independent random variables. Find where . My working: Define if and if . We seek . Now and by symmetry. . Similarly by symmetry when . Required expectation= But correct answer is . Where am I going wrong?,"X,Y Uniform(0,1) E(|X-Y|^a) a>0 W=1 X>Y W=0 X<Y E(|X-Y|^a)=E[E(|X-Y|^a|W)]=E(|X-Y|^a|W=1)P(W=1)+E(|X-Y|^a|W=0)P(W=0)=E((X-Y)^a)P(X>Y)+E((Y-X)^a)P(X<Y) P(X<Y)=\dfrac{1}{2} P(X>Y)=\dfrac{1}{2} E((X-Y)^a)=\int_{0}^{1}\int_{0}^{x}(x-y)^af_{X,Y}(x,y)dydx=\int_{0}^{1}\int_{0}^{x}(x-y)^adydx=\dfrac{1}{(a+1)(a+2)} E((Y-X)^a)=\dfrac{1}{(a+1)(a+2)} Y>X \dfrac{1}{(a+1)(a+2)}\dfrac{1}{2}+\dfrac{1}{(a+1)(a+2)}\dfrac{1}{2}=\dfrac{1}{(a+1)(a+2)} \dfrac{2}{(a+1)(a+2)}","['probability', 'probability-theory', 'probability-distributions', 'uniform-distribution']"
40,Defining median for discrete distribution,Defining median for discrete distribution,,"In probability theory, a median of a probability distribution is a number $M$ such that the CDF of this distribution $F_\xi(x)$ satisfies $F_\xi(M)=\frac{1}{2} \tag1$ This works for continuous distributions, but for discrete distributions median would almost always be undefined if we were using this definition. How is it defined in the discrete case? Does it have similarity with $(1)$? To stress the difference from median of a set and illustrate my thoughts, the CDF looks something like this .","In probability theory, a median of a probability distribution is a number $M$ such that the CDF of this distribution $F_\xi(x)$ satisfies $F_\xi(M)=\frac{1}{2} \tag1$ This works for continuous distributions, but for discrete distributions median would almost always be undefined if we were using this definition. How is it defined in the discrete case? Does it have similarity with $(1)$? To stress the difference from median of a set and illustrate my thoughts, the CDF looks something like this .",,"['probability', 'statistics', 'probability-distributions', 'definition', 'median']"
41,Mean of a Cauchy Distribution,Mean of a Cauchy Distribution,,"Why is the mean of a Cauchy distribution undefined? Surely, it should be $0$ by symmetry? $$\int_{-\infty}^{\infty} {\frac{x}{\pi (1+x^2)}} dx =0?$$","Why is the mean of a Cauchy distribution undefined? Surely, it should be $0$ by symmetry? $$\int_{-\infty}^{\infty} {\frac{x}{\pi (1+x^2)}} dx =0?$$",,"['probability', 'integration', 'expectation']"
42,A linear combination of characteristic functions is a characteristic function?,A linear combination of characteristic functions is a characteristic function?,,"Let $\phi_k(t)$ be the characteristic function of a random variable $X_k$, $k = 1,2,\dots$. Consider a set of positive real numbers $\{p_1, p_2, \dots \}$, take a function:  $$\phi(t) = \sum_{k=1}^{\infty}p_k\phi_k(t)$$ What is the conditions on $\{p_1, p_2, \dots \}$ such that $\phi$ is a characteristic function? I know that a characteristic function need to satisfy following properties: $$\phi(0) = 1$$ $$\phi(-t) = \overline{\phi(t)}$$ $$|\phi(t)|=\left|E[e^{itX}]\right|\leq E|e^{itX}|=1$$ $$|\phi(t+h)-\phi(t)|\leq E|e^{ihX}-1|$$ $$E[e^{it(aX+b)}]=e^{itb}\phi(at)$$ But I think only satisfy these properties will not ensure that $\phi(t)$ is a characteristic function for some random variables. What is the direction should I approach this problem? Thank you very much for the help.","Let $\phi_k(t)$ be the characteristic function of a random variable $X_k$, $k = 1,2,\dots$. Consider a set of positive real numbers $\{p_1, p_2, \dots \}$, take a function:  $$\phi(t) = \sum_{k=1}^{\infty}p_k\phi_k(t)$$ What is the conditions on $\{p_1, p_2, \dots \}$ such that $\phi$ is a characteristic function? I know that a characteristic function need to satisfy following properties: $$\phi(0) = 1$$ $$\phi(-t) = \overline{\phi(t)}$$ $$|\phi(t)|=\left|E[e^{itX}]\right|\leq E|e^{itX}|=1$$ $$|\phi(t+h)-\phi(t)|\leq E|e^{ihX}-1|$$ $$E[e^{it(aX+b)}]=e^{itb}\phi(at)$$ But I think only satisfy these properties will not ensure that $\phi(t)$ is a characteristic function for some random variables. What is the direction should I approach this problem? Thank you very much for the help.",,"['probability', 'probability-theory', 'characteristic-functions']"
43,Expectation and best strategy for a dice game,Expectation and best strategy for a dice game,,"I am somewhat stuck on this problem, it should be straightforward but I cannot find a clearly explained solution: A single dice is rolled as many times as you want. For each throw, you receive n dollars if dice shows $n$, if $n<6$. If dice shows $6$, you lose all the money accumulated and the game stops. What is the expectation and the best strategy for this game?","I am somewhat stuck on this problem, it should be straightforward but I cannot find a clearly explained solution: A single dice is rolled as many times as you want. For each throw, you receive n dollars if dice shows $n$, if $n<6$. If dice shows $6$, you lose all the money accumulated and the game stops. What is the expectation and the best strategy for this game?",,"['probability', 'dice']"
44,Prove an inequality similar to Jensen's inequality,Prove an inequality similar to Jensen's inequality,,"Prove that  $$\mathbb{E}(\sqrt{X})\leq\sqrt{\mathbb{E}Y}$$ where random variables $X,Y>0$ and $\mathbb{E}\left[\frac{X}{Y}\right]\leq1.$ My attempt: This looks very much like Jensen's inequality. According to Jensen, $\mathbb{E}(\sqrt{X})\leq\sqrt{\mathbb{E}X},$ then the desired inequality is true if we can prove $\mathbb{E}X\leq\mathbb{E}Y.$ But this seems impossible to prove because $X$ and $Y$ are not independent. Any help will be appreciated!","Prove that  $$\mathbb{E}(\sqrt{X})\leq\sqrt{\mathbb{E}Y}$$ where random variables $X,Y>0$ and $\mathbb{E}\left[\frac{X}{Y}\right]\leq1.$ My attempt: This looks very much like Jensen's inequality. According to Jensen, $\mathbb{E}(\sqrt{X})\leq\sqrt{\mathbb{E}X},$ then the desired inequality is true if we can prove $\mathbb{E}X\leq\mathbb{E}Y.$ But this seems impossible to prove because $X$ and $Y$ are not independent. Any help will be appreciated!",,['probability']
45,Autocorrelation of a Wiener Process proof,Autocorrelation of a Wiener Process proof,,"Given a Wiener process X, how do I prove this? $R_x(s,t) = E[X(s)X(t)] = min(s,t)$ There seems to be a trick with dividing to two cases of $s<t$ and $s>t$, but I can't figure out how this would be helpful. This is what I've got so far: $R_x(s,t) = E[X(s)X(t)] = E[X(s)(X(t)-X(s)+X(s))]$ $=E[X(s)^2]+E[X(s)(X(t)-X(s)]=E[X(s)^2]+E[(X(s)-X(0))(X(t)-X(s)]$ $=E[X(s)^2]+E[(X(s)-X(0))]E[(X(t)-X(s)]$ $=E[X(s)^2]+E[(X(s))]E[(X(t)-X(s)] = E[X(s)^2] = Var[X(s)] = s$ But the same thing could be done with t instead of s... So what am I doing wrong?","Given a Wiener process X, how do I prove this? $R_x(s,t) = E[X(s)X(t)] = min(s,t)$ There seems to be a trick with dividing to two cases of $s<t$ and $s>t$, but I can't figure out how this would be helpful. This is what I've got so far: $R_x(s,t) = E[X(s)X(t)] = E[X(s)(X(t)-X(s)+X(s))]$ $=E[X(s)^2]+E[X(s)(X(t)-X(s)]=E[X(s)^2]+E[(X(s)-X(0))(X(t)-X(s)]$ $=E[X(s)^2]+E[(X(s)-X(0))]E[(X(t)-X(s)]$ $=E[X(s)^2]+E[(X(s))]E[(X(t)-X(s)] = E[X(s)^2] = Var[X(s)] = s$ But the same thing could be done with t instead of s... So what am I doing wrong?",,"['probability', 'statistics', 'stochastic-processes']"
46,Example of non continuous random variable with continuous CDF,Example of non continuous random variable with continuous CDF,,"Can someone provide an example of $X$ being a non-continuous random variable with continuous cumulative distribution function? For instance: $X$ is discrete if it takes (at most) a countable number of values. $X$ is continuous (or absolutely continuous) if its law $P^X$ admits a density $f(x)$. Note: A random variable don't have to be necessarily discrete or continuous; just take a cumulative distribution function that is non-constant and continuous except in $0$. Then $X$ is neither continuous nor discrete. I know that to ensure that $X$ is continuous, we need to ask $F_X \in C^1$, as $F_X \in C^0$ does not suffice. I would then like to see a non continuous random variable with continuous cdf","Can someone provide an example of $X$ being a non-continuous random variable with continuous cumulative distribution function? For instance: $X$ is discrete if it takes (at most) a countable number of values. $X$ is continuous (or absolutely continuous) if its law $P^X$ admits a density $f(x)$. Note: A random variable don't have to be necessarily discrete or continuous; just take a cumulative distribution function that is non-constant and continuous except in $0$. Then $X$ is neither continuous nor discrete. I know that to ensure that $X$ is continuous, we need to ask $F_X \in C^1$, as $F_X \in C^0$ does not suffice. I would then like to see a non continuous random variable with continuous cdf",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
47,Puzzle about technique of fair using of unfair coin,Puzzle about technique of fair using of unfair coin,,"There is an unfair coin. It tends to land on one side more than on the other. It is unknown which side is it. There is Mr. A and Mr. B. They argue about something and they want to use that coin to decide who is right. Is there any technique of using that unfair coin to get fair result? My solution: I can think of only that there is going to be 2 rounds. First time Mr. A chooses HEAD, than Mr. B chooses HEAD if any of them wins twice they win.","There is an unfair coin. It tends to land on one side more than on the other. It is unknown which side is it. There is Mr. A and Mr. B. They argue about something and they want to use that coin to decide who is right. Is there any technique of using that unfair coin to get fair result? My solution: I can think of only that there is going to be 2 rounds. First time Mr. A chooses HEAD, than Mr. B chooses HEAD if any of them wins twice they win.",,"['probability', 'puzzle']"
48,Show that a function is a probability generating function,Show that a function is a probability generating function,,"I'm doing past papers in order to revise for  exams in June and my university irritatingly doesn't provide any mark schemes and I'm very stuck on a question. The question says: Let $g(z)=\frac{2}{3}+(14-5z)^{-\frac{1}{2}}$. Show that exists a nonnegative integer-valued random variable whose probability generating function is $g$. Attempt: So, I thought I wanted to show that there exists $X$ such that $g(z)=\mathbb{E}(z^{X})=\sum_{k=0}^{\infty}p_{X}(k)z^{k}$.  So, first I checked that $g(1)=1$ which it does. Then I just differentiated $g$ to find a general formula for the pmf of $X$. So, I got $g(0)=\frac{2}{3}+\frac{1}{\sqrt{14}} \Rightarrow p_{X}(0)=\frac{2}{3}+\frac{1}{\sqrt{14}}$ Then $g'(z)=\frac{5/2}{(14-5z)^{\frac{3}{2}}} \Rightarrow g''(z)=\frac{75/4}{(14-5z)^{\frac{5}{2}}} \Rightarrow ... \Rightarrow g^{(k)}(z)=\frac{5^{k}(2k)!}{2^{2k}k!(14-5z)^{\frac{2k+1}{2}}}$ Therefore $p_{X}(k)=\frac{5^{k}(2k)!}{2^{2k}(k!)^{2}(14-5z)^{\frac{2k+1}{2}}}$ for $k=1,2,...$ This just seemed too messy, so I thought my method must be incorrect? Thanks in advance for your help!","I'm doing past papers in order to revise for  exams in June and my university irritatingly doesn't provide any mark schemes and I'm very stuck on a question. The question says: Let $g(z)=\frac{2}{3}+(14-5z)^{-\frac{1}{2}}$. Show that exists a nonnegative integer-valued random variable whose probability generating function is $g$. Attempt: So, I thought I wanted to show that there exists $X$ such that $g(z)=\mathbb{E}(z^{X})=\sum_{k=0}^{\infty}p_{X}(k)z^{k}$.  So, first I checked that $g(1)=1$ which it does. Then I just differentiated $g$ to find a general formula for the pmf of $X$. So, I got $g(0)=\frac{2}{3}+\frac{1}{\sqrt{14}} \Rightarrow p_{X}(0)=\frac{2}{3}+\frac{1}{\sqrt{14}}$ Then $g'(z)=\frac{5/2}{(14-5z)^{\frac{3}{2}}} \Rightarrow g''(z)=\frac{75/4}{(14-5z)^{\frac{5}{2}}} \Rightarrow ... \Rightarrow g^{(k)}(z)=\frac{5^{k}(2k)!}{2^{2k}k!(14-5z)^{\frac{2k+1}{2}}}$ Therefore $p_{X}(k)=\frac{5^{k}(2k)!}{2^{2k}(k!)^{2}(14-5z)^{\frac{2k+1}{2}}}$ for $k=1,2,...$ This just seemed too messy, so I thought my method must be incorrect? Thanks in advance for your help!",,"['probability', 'generating-functions']"
49,Conditional expectation of an exponential random variable,Conditional expectation of an exponential random variable,,"Let $X$ be an exponential random variable with rate $\lambda$ Use the identity below to solve for $E[X|X < c]$ $$E[X] = E[X|X < c]*P(X < c) + E[X|X > c]*P(X > c)$$ So right off the bat, I know I can rearrange this to find what I'm looking for as follows $$E[X|X<c] = \frac{E[X] - E[X|X > c]*P(X > c)}{P(X<c)}$$ Of course $$E[X] = \frac{1}{\lambda}$$ $$P(X<c) = F_X(c) = 1-e^{-\lambda t}$$ $$P(X>c) = 1-F_X(c) = 1-(1-e^{-\lambda t}) = e^{-\lambda t}$$ I can plug these in and solve easilly. However, I'm not entirely sure how to solve for $E[X|X>c]$. I could use the definition of conditional expectation I suppose, but I feel like that's defeating the purpose of the problem; is there another way to compute this value so I can complete the equation?","Let $X$ be an exponential random variable with rate $\lambda$ Use the identity below to solve for $E[X|X < c]$ $$E[X] = E[X|X < c]*P(X < c) + E[X|X > c]*P(X > c)$$ So right off the bat, I know I can rearrange this to find what I'm looking for as follows $$E[X|X<c] = \frac{E[X] - E[X|X > c]*P(X > c)}{P(X<c)}$$ Of course $$E[X] = \frac{1}{\lambda}$$ $$P(X<c) = F_X(c) = 1-e^{-\lambda t}$$ $$P(X>c) = 1-F_X(c) = 1-(1-e^{-\lambda t}) = e^{-\lambda t}$$ I can plug these in and solve easilly. However, I'm not entirely sure how to solve for $E[X|X>c]$. I could use the definition of conditional expectation I suppose, but I feel like that's defeating the purpose of the problem; is there another way to compute this value so I can complete the equation?",,"['probability', 'probability-theory', 'conditional-probability', 'expectation']"
50,"$A$ and $B$ are events, is $A|B$ an event?","and  are events, is  an event?",A B A|B,"$A$ and $B$ are events, is $A|B$ an event? Can I write an event in this form $A|B$ ? $Pr(A|B)$ means given $B$ happens, what is the probability of $A$ happen.  Since $Pr(\cdot)$ is a measurement, so I am wondering $A|B$ is an event too","$A$ and $B$ are events, is $A|B$ an event? Can I write an event in this form $A|B$ ? $Pr(A|B)$ means given $B$ happens, what is the probability of $A$ happen.  Since $Pr(\cdot)$ is a measurement, so I am wondering $A|B$ is an event too",,['probability']
51,Bound on the $Q$ function related to Chernoff bound,Bound on the  function related to Chernoff bound,Q,"For the function $Q(x) := \mathbb{P}(Z>x)$ where $Z \sim \mathcal{N}(0,1)$ \begin{align} Q(x) = \int_{x}^\infty \frac{1}{\sqrt{2\pi}} \exp \left(-\frac{u^2}{2} \right) \text{d}u, \end{align} for $x \geq 0$ the following bound is given in many communication systems textbooks: \begin{align} Q(x) \leq \frac{1}{2} \exp \left(-\frac{x^2}{2} \right). \end{align} The bound without the $\frac{1}{2}$ in front of the exponential can be proven directly by Chernoff bound on the Gaussian distribution. However, how do we show the case with the $\frac{1}{2}$ before the exponential?","For the function $Q(x) := \mathbb{P}(Z>x)$ where $Z \sim \mathcal{N}(0,1)$ \begin{align} Q(x) = \int_{x}^\infty \frac{1}{\sqrt{2\pi}} \exp \left(-\frac{u^2}{2} \right) \text{d}u, \end{align} for $x \geq 0$ the following bound is given in many communication systems textbooks: \begin{align} Q(x) \leq \frac{1}{2} \exp \left(-\frac{x^2}{2} \right). \end{align} The bound without the $\frac{1}{2}$ in front of the exponential can be proven directly by Chernoff bound on the Gaussian distribution. However, how do we show the case with the $\frac{1}{2}$ before the exponential?",,"['probability', 'inequality', 'normal-distribution']"
52,Mapping CDF's to each other,Mapping CDF's to each other,,"Given two CDF's on a closed interval, $F_1(x), F_2(x)$, can we find a mapping $x\to g(x)$ such that the points $x$ formerly distributed with CDF $\ F_1(x)$, will now have distribution $F_2(x)$? That is, given some data distributed in a certain manner, can we find a transformation that when applied to our data, will result in data distributed according to another (given) distribution?","Given two CDF's on a closed interval, $F_1(x), F_2(x)$, can we find a mapping $x\to g(x)$ such that the points $x$ formerly distributed with CDF $\ F_1(x)$, will now have distribution $F_2(x)$? That is, given some data distributed in a certain manner, can we find a transformation that when applied to our data, will result in data distributed according to another (given) distribution?",,"['probability', 'probability-distributions']"
53,"Intuitive explanation for $\mathbb{E}X= \int_0^\infty 1-F(x) \, dx$",Intuitive explanation for,"\mathbb{E}X= \int_0^\infty 1-F(x) \, dx","I can see by manipulating the expression why $\mathbb{E}X$ works out to be $\int_0^\infty 1-F(x)\,dx$, where $F$ is the distribution function of $X$, but what is an intuitive explanation for why that is true? If at each point we sum the probability $\mathbb{P}(X>x)$, why should we end up with the expectation? Thanks","I can see by manipulating the expression why $\mathbb{E}X$ works out to be $\int_0^\infty 1-F(x)\,dx$, where $F$ is the distribution function of $X$, but what is an intuitive explanation for why that is true? If at each point we sum the probability $\mathbb{P}(X>x)$, why should we end up with the expectation? Thanks",,"['probability', 'soft-question']"
54,"Is $\{\sin(\omega n), n \geq 1\}$ a strictly stationary process?",Is  a strictly stationary process?,"\{\sin(\omega n), n \geq 1\}","Let $X(t)=\sin(\omega t)$, where $\omega$ is is uniformly distributed R.V. on $[0,2π]$. Let $X_n=X(n)$, is $\{X_n,n \geq 1\}$ a strictly stationary process ? I've calculated that the distribution function of $X_n$ is $f_{X_n}(x)=\frac{1}{\pi\sqrt{1-x^2}}$. Can anybody help me then?","Let $X(t)=\sin(\omega t)$, where $\omega$ is is uniformly distributed R.V. on $[0,2π]$. Let $X_n=X(n)$, is $\{X_n,n \geq 1\}$ a strictly stationary process ? I've calculated that the distribution function of $X_n$ is $f_{X_n}(x)=\frac{1}{\pi\sqrt{1-x^2}}$. Can anybody help me then?",,"['probability', 'probability-theory', 'stochastic-processes', 'stationary-processes']"
55,Expected Value of Number of Tails Minus Number of Heads,Expected Value of Number of Tails Minus Number of Heads,,"I have the following problem where, given $X_n$ is a random variable that equals the number of tails minus the number of heads when n fair coins are flipped, what is the expected value of $X_n$? I am having a difficulty getting started on this problem.  Could someone offer a suggestion as to how this problem should be modeled?","I have the following problem where, given $X_n$ is a random variable that equals the number of tails minus the number of heads when n fair coins are flipped, what is the expected value of $X_n$? I am having a difficulty getting started on this problem.  Could someone offer a suggestion as to how this problem should be modeled?",,['probability']
56,Probability of winning the game 1-2-3-4-5-6-7-8-9-10-J-Q-K [duplicate],Probability of winning the game 1-2-3-4-5-6-7-8-9-10-J-Q-K [duplicate],,"This question already has an answer here : Derangements with repetitive numbers (1 answer) Closed 5 years ago . A similar question to mine was answered here on stackexchange: Probability of winning the game ""1-2-3"" However, I am unable to follow the formulas so perhaps someone could show the calculation and the way they arrived at it to answer this question. My card game is very similar, except the counting of cards goes all the way from 1 (Ace) through to King and then restarts.  If you can make it through an entire deck of cards without hitting the same ranked card you win.  So, for example, if you call out Ace - 2 -3 - 4 - 5 - 6, etc. and hit ""7"" when you've just called out ""7"", you lose. What is the chance of winning this card game?","This question already has an answer here : Derangements with repetitive numbers (1 answer) Closed 5 years ago . A similar question to mine was answered here on stackexchange: Probability of winning the game ""1-2-3"" However, I am unable to follow the formulas so perhaps someone could show the calculation and the way they arrived at it to answer this question. My card game is very similar, except the counting of cards goes all the way from 1 (Ace) through to King and then restarts.  If you can make it through an entire deck of cards without hitting the same ranked card you win.  So, for example, if you call out Ace - 2 -3 - 4 - 5 - 6, etc. and hit ""7"" when you've just called out ""7"", you lose. What is the chance of winning this card game?",,"['probability', 'combinatorics', 'problem-solving', 'card-games']"
57,Bernoulli trials required for k successes,Bernoulli trials required for k successes,,"What is the expected value of number of Bernoulli trials required for k successes? Assume probability of success in a single trial = $p$, probability of failure = $q = 1 - p$.  I managed to derive the discrete probability mass function: $P(X = n) = \binom{n - 1}{k -1} p^{k} (1 - p)^{n - k}$, for $n \geq k$. However, I could not sum the series $E(X) = \sum_{n = k}^{\infty} n\binom{n - 1}{k -1} p^{k} (1 - p)^{n - k}$. Can anybody please help?","What is the expected value of number of Bernoulli trials required for k successes? Assume probability of success in a single trial = $p$, probability of failure = $q = 1 - p$.  I managed to derive the discrete probability mass function: $P(X = n) = \binom{n - 1}{k -1} p^{k} (1 - p)^{n - k}$, for $n \geq k$. However, I could not sum the series $E(X) = \sum_{n = k}^{\infty} n\binom{n - 1}{k -1} p^{k} (1 - p)^{n - k}$. Can anybody please help?",,"['probability', 'probability-distributions']"
58,Yet Another Monty Hall Question - Please advise if alternative scenario proves the same principle,Yet Another Monty Hall Question - Please advise if alternative scenario proves the same principle,,"Okay, I'm very embarrassed that there are already 71 questions (based on search of ""monty hall"") and I'm going to post another one. I read the first 5 before succumbing to choice-overload. I'll try to keep this short and sweet. A host and contestant stand before 3 doors. The host advises the contestant that behind 1 of the 3 is a car while the other doors each have a goat. The host advises the contestant to choose 2 of the 3 doors to reveal if either has the car. The contestant chooses door 1 and door 3 . The host advises that behind one of the doors chosen is a goat and asks if the contestant wants to keep doors 1 and 3 or switch to only revealing door 2 . Big Question : Is the probability of revealing the car higher if the contestant switches or stays with the original choice? As I understand the original problem, the above has the same result, so the contestant should switch, but I can't wrap my head around the math and don't want to hurt my brain trying if I'm incorrect about the above fundamentally being the same scenario. Also, if the above is the same, how is it any different from the contestant saying ""3, no wait 2"", since no matter which 2 doors are chosen (either by the contestant alone or with the help of the host, as in the original problem), we know that at least 1 door has a goat? Last bit: If this is the same mathematical scenario, is it even less intuitive than the original or does it help clarify (to someone other than me) why the original works? Addendum Original MH problem, simplified: There are 3 marbles in a bag; 2 are boring and grey, 1 is green.  The host asks you to reach in and pull 1 out but not look at it.  After doing this, the host, who can look into the bag, pulls out 1 grey marble. He then asks if you want to keep the 1 in your clutched hand or take the 1 still in the bag. My version, simplified: There are 3 marbles in a bag; 2 are boring and grey, 1 is green.  The host asks you to reach in and pull 2 out but not look at them.  After doing this, the host asks if you want to keep the 2 in your clutched hand or take the 1 still in the bag. In both scenarios, 2 marbles are removed from the bag and 1 of those 2 is definitely grey. If we accept (and we all should at this point!) that in the first scenario the probability of the remaining door or marble being the winning choice is 2/3, shouldn't that hold true in the second scenario? If not, please explain at what point it diverges? If we know 1 of the 2   ""out of the bag"" is grey or a goat in either scenario, it shouldn't matter if we see which of the 2 it is, right? Addendum 2 Thanks to Eric T for helping me get my head around this. With either of my modified scenarios, where my logic diverged was I allow the contestant to choose 2 doors and then keep both choices or switch, whereas in the original MH problem, the contestant is given a second ""choice"" with the host-reveal but still only keeps the original (or switches). One of my goals in creating this alternative was to eliminate the host variable which is a clear source of confusion (and trickery) in the original, leading to such misassumptions as The host's knowledge of what is behind all three doors creates a mathematical bias since he won't ever choose the car at random. If MH only presents the option when the car wasn't selected (to throw the contestant off), this would not change the math when testing for when the contestant chooses the car first. If the host always chooses a goat, it's because he always has at least one goat to choose from and is supposed to reveal a goat, not choose a door at random. Showing the contestant that one of the other 2 doors has a goat gives the contestant new information that affects the outcome. it is not eliminating the goat (seeing the goat) that makes switching more likely to reveal the car, it is eliminating the door. If my variation has the  pick-2 parameter but has the ""only one door allowed"" rule reinstated , switching is still the better option. Here is the final version: A host and contestant stand before 3 doors. The host advises the contestant that 1 of the 3 doors hides a car while the other doors each hide a goat. The host advises the contestant to choose 2 of the 3 doors to check for the car. The contestant chooses door 1 and door 3 . The host asks the contestant to choose between opening 1 and 3 or switch to opening door 2 . In this scenario, the host has done nothing to interfere and the contestant knows that at least one of the two selected doors has a goat, but must still risk choosing the wrong door of his selected 2 or switching.  While the odds may still seem 1/2 at first, the possibility that the contestant chose both goats and thus may have no chance with his current subset makes the better odds in switching clearer. Last question: What would be the actual probability of choosing the car if we don't know if the car exists in the subset 1 or 0 times? Just a comment mentioning a concept or wiki page is fine. Just curious on the math and have no idea what search for.","Okay, I'm very embarrassed that there are already 71 questions (based on search of ""monty hall"") and I'm going to post another one. I read the first 5 before succumbing to choice-overload. I'll try to keep this short and sweet. A host and contestant stand before 3 doors. The host advises the contestant that behind 1 of the 3 is a car while the other doors each have a goat. The host advises the contestant to choose 2 of the 3 doors to reveal if either has the car. The contestant chooses door 1 and door 3 . The host advises that behind one of the doors chosen is a goat and asks if the contestant wants to keep doors 1 and 3 or switch to only revealing door 2 . Big Question : Is the probability of revealing the car higher if the contestant switches or stays with the original choice? As I understand the original problem, the above has the same result, so the contestant should switch, but I can't wrap my head around the math and don't want to hurt my brain trying if I'm incorrect about the above fundamentally being the same scenario. Also, if the above is the same, how is it any different from the contestant saying ""3, no wait 2"", since no matter which 2 doors are chosen (either by the contestant alone or with the help of the host, as in the original problem), we know that at least 1 door has a goat? Last bit: If this is the same mathematical scenario, is it even less intuitive than the original or does it help clarify (to someone other than me) why the original works? Addendum Original MH problem, simplified: There are 3 marbles in a bag; 2 are boring and grey, 1 is green.  The host asks you to reach in and pull 1 out but not look at it.  After doing this, the host, who can look into the bag, pulls out 1 grey marble. He then asks if you want to keep the 1 in your clutched hand or take the 1 still in the bag. My version, simplified: There are 3 marbles in a bag; 2 are boring and grey, 1 is green.  The host asks you to reach in and pull 2 out but not look at them.  After doing this, the host asks if you want to keep the 2 in your clutched hand or take the 1 still in the bag. In both scenarios, 2 marbles are removed from the bag and 1 of those 2 is definitely grey. If we accept (and we all should at this point!) that in the first scenario the probability of the remaining door or marble being the winning choice is 2/3, shouldn't that hold true in the second scenario? If not, please explain at what point it diverges? If we know 1 of the 2   ""out of the bag"" is grey or a goat in either scenario, it shouldn't matter if we see which of the 2 it is, right? Addendum 2 Thanks to Eric T for helping me get my head around this. With either of my modified scenarios, where my logic diverged was I allow the contestant to choose 2 doors and then keep both choices or switch, whereas in the original MH problem, the contestant is given a second ""choice"" with the host-reveal but still only keeps the original (or switches). One of my goals in creating this alternative was to eliminate the host variable which is a clear source of confusion (and trickery) in the original, leading to such misassumptions as The host's knowledge of what is behind all three doors creates a mathematical bias since he won't ever choose the car at random. If MH only presents the option when the car wasn't selected (to throw the contestant off), this would not change the math when testing for when the contestant chooses the car first. If the host always chooses a goat, it's because he always has at least one goat to choose from and is supposed to reveal a goat, not choose a door at random. Showing the contestant that one of the other 2 doors has a goat gives the contestant new information that affects the outcome. it is not eliminating the goat (seeing the goat) that makes switching more likely to reveal the car, it is eliminating the door. If my variation has the  pick-2 parameter but has the ""only one door allowed"" rule reinstated , switching is still the better option. Here is the final version: A host and contestant stand before 3 doors. The host advises the contestant that 1 of the 3 doors hides a car while the other doors each hide a goat. The host advises the contestant to choose 2 of the 3 doors to check for the car. The contestant chooses door 1 and door 3 . The host asks the contestant to choose between opening 1 and 3 or switch to opening door 2 . In this scenario, the host has done nothing to interfere and the contestant knows that at least one of the two selected doors has a goat, but must still risk choosing the wrong door of his selected 2 or switching.  While the odds may still seem 1/2 at first, the possibility that the contestant chose both goats and thus may have no chance with his current subset makes the better odds in switching clearer. Last question: What would be the actual probability of choosing the car if we don't know if the car exists in the subset 1 or 0 times? Just a comment mentioning a concept or wiki page is fine. Just curious on the math and have no idea what search for.",,"['probability', 'intuition', 'monty-hall']"
59,Help with conditional probability?,Help with conditional probability?,,"I've got to show that: $$\mathbb{P} (A | A \cap B) = \frac{ \mathbb{P}(A)}{ \mathbb{P} (A \cap B)}$$ I'm not sure how to get to this. Surely the probability of A occurring given A and B occurs is 1? Or, by the equation... $$\mathbb{P} (A | A \cap B) = \frac{ \mathbb{P} (A \cap A \cap B)}{\mathbb{P} (A \cap B)}$$ Thanks for your help","I've got to show that: $$\mathbb{P} (A | A \cap B) = \frac{ \mathbb{P}(A)}{ \mathbb{P} (A \cap B)}$$ I'm not sure how to get to this. Surely the probability of A occurring given A and B occurs is 1? Or, by the equation... $$\mathbb{P} (A | A \cap B) = \frac{ \mathbb{P} (A \cap A \cap B)}{\mathbb{P} (A \cap B)}$$ Thanks for your help",,['probability']
60,Expected value of joint probability density functions,Expected value of joint probability density functions,,"Quick question here. I'm trying to make sense of this problem... $$f(x_1,x_2) =\begin{cases} 8x_1x_2 & \text{for } 0 < x_1 < x_2 < 1\\ 0&\text{otherwise} \end{cases}$$ If $Y = X_1(X_2)^3$ , what is the expected value of $Y$? My thoughts: I'm not entirely sure where to start, but here is where I would start: \begin{align} E(Y) &= E\left(X_1(X_2)^3\right)\\     & = E(X_1)  E(X_2^2) \end{align} Then after this step I'm not sure of what to do. There must be a way to use the pdf to solve for the expected value but I'm not sure. I'm not looking for answers but guidance would be greatly appreciated!!","Quick question here. I'm trying to make sense of this problem... $$f(x_1,x_2) =\begin{cases} 8x_1x_2 & \text{for } 0 < x_1 < x_2 < 1\\ 0&\text{otherwise} \end{cases}$$ If $Y = X_1(X_2)^3$ , what is the expected value of $Y$? My thoughts: I'm not entirely sure where to start, but here is where I would start: \begin{align} E(Y) &= E\left(X_1(X_2)^3\right)\\     & = E(X_1)  E(X_2^2) \end{align} Then after this step I'm not sure of what to do. There must be a way to use the pdf to solve for the expected value but I'm not sure. I'm not looking for answers but guidance would be greatly appreciated!!",,['probability']
61,Expected value of a variable related to uniform r.v.,Expected value of a variable related to uniform r.v.,,"Let $X_i$ be i.i.d. uniform random variable on $[0,1]$. Let $N=\inf(n \colon \prod_{k=1}^n X_k < 10^{-3})$. What is $\mathbb{E}(N)$? I am trying to solve this but I am totally confused. How do I find an expected value for an infimum?","Let $X_i$ be i.i.d. uniform random variable on $[0,1]$. Let $N=\inf(n \colon \prod_{k=1}^n X_k < 10^{-3})$. What is $\mathbb{E}(N)$? I am trying to solve this but I am totally confused. How do I find an expected value for an infimum?",,['probability']
62,3 balls drawn from 1 urn - probability all same color (with/without replacement),3 balls drawn from 1 urn - probability all same color (with/without replacement),,"An urn contains 5 red, 6 blue and 8 green balls. 3 balls are randomly selected from the urn, find the probability that they are all of the same color if: (a) the balls are drawn without replacement; (b) the balls are drawn with replacement.","An urn contains 5 red, 6 blue and 8 green balls. 3 balls are randomly selected from the urn, find the probability that they are all of the same color if: (a) the balls are drawn without replacement; (b) the balls are drawn with replacement.",,['probability']
63,Convergence in Probability,Convergence in Probability,,"Maximum of a Sample from a Uniform Distribution: Suppose $X_1, ...  , X_n$ is a random sample for a $\mathrm{uniform}(0,\theta)$ distribution. Suppose $\theta$ is unknown. An intuitive estimate of $\theta$ is the maximum of a sample. Let $Y_n = \max\{X_1, ... , X_n\}$. Exercise 5.1.4 shows that the cdf of $Y_n$ is $F_{Y_n}(t) = 1$ if $t>\theta$, $F_{Y_n}(t) = \frac{t^n}{\theta^n}$ if $0 < t \leq \theta$, and $F_{Y_n}(t) = 0$ if $t\le0$. Then the pdf of $Y_n$ is $f_{Y_n}(t) = \frac{nt^{n-1}}{\theta^n}$ if $0 < t \leq \theta$, and $f_{Y_n}(t) = 0$ elsewhere. Based on its pdf, it is easy to show that $E(Y_n) = (n/(n+1))\theta$. Thus, $Y_n$ is a biased estimator $\theta$... Further, based on the cdf of $Y_n$, it is easily seen that $Y_n$ converges to $\theta$ in probability. MY QUESTION: How do we know that $Y_n$ converges to $\theta$ in probability? Is it because $E(Y_n) \rightarrow \theta$? Thanks in advance.","Maximum of a Sample from a Uniform Distribution: Suppose $X_1, ...  , X_n$ is a random sample for a $\mathrm{uniform}(0,\theta)$ distribution. Suppose $\theta$ is unknown. An intuitive estimate of $\theta$ is the maximum of a sample. Let $Y_n = \max\{X_1, ... , X_n\}$. Exercise 5.1.4 shows that the cdf of $Y_n$ is $F_{Y_n}(t) = 1$ if $t>\theta$, $F_{Y_n}(t) = \frac{t^n}{\theta^n}$ if $0 < t \leq \theta$, and $F_{Y_n}(t) = 0$ if $t\le0$. Then the pdf of $Y_n$ is $f_{Y_n}(t) = \frac{nt^{n-1}}{\theta^n}$ if $0 < t \leq \theta$, and $f_{Y_n}(t) = 0$ elsewhere. Based on its pdf, it is easy to show that $E(Y_n) = (n/(n+1))\theta$. Thus, $Y_n$ is a biased estimator $\theta$... Further, based on the cdf of $Y_n$, it is easily seen that $Y_n$ converges to $\theta$ in probability. MY QUESTION: How do we know that $Y_n$ converges to $\theta$ in probability? Is it because $E(Y_n) \rightarrow \theta$? Thanks in advance.",,['probability']
64,"Exercise 2.8 in Mackay's Information Theory, Inference and Learning Algorithms","Exercise 2.8 in Mackay's Information Theory, Inference and Learning Algorithms",,"[Editing question per Leon's suggestions - thanks for these!] Could someone walk me through a solution to Ex 2.8? 2.7:  Bill tosses a bent coin $N$ times, obtaining a sequence of heads and tails.  We assume that the coin has a probability $f_H$ of coming up heads; we do not know $f_H$.  If $n_H$ heads have occurred in $N$ tosses, what is the probability distribution of $f_H$? ...What is the probability that the $N+1$th outcome will be a head, given $n_H$ heads in $N$ tosses? 2.8:  Assuming a uniform prior on $f_H$, $P(f_H)=1$, solve the problem posed in 2.7.  Sketch the distribution of fH and compute the probability that the $N+1$th outcome will be a head, for (A) $N=3$ and $n_H$=0; (B) $N=3$ and $n_H=2$; (C) $N=10$ and $n_H=3$; (D) $N=300$ and $n_H=29$. {tip about the beta integral} Where I am stuck is with the switch to continuous probabilities, and using integrals rather than sums.  Had no problem with 2.4; 2.5 took some doing but was fine.  The example in 2.6 made sense walking through it. In working on 2.8, I can write down that posterior = (likelihood x prior) / evidence, and know that I am trying to solve for posterior (to find the distribution of $f_H$).  So my equation will look something like $$P(f_H |\,n_H, N) = {P(n_H|\,f_H, N) P(f_H) \over P(n_H|\,N)}$$. The left hand side of the numerator should just be the binomial probability ${N \choose n_H}$ $f_H^{n_H}$ $(1-f_H)^{N-n_H}$  Based on the statement in the question, I assume that $P(f_H) = 1$ and ignore it. The denominator is the marginal probability of $n_H$.  I believe this should be an integral - something like $\int_0^1 P(f_H) P(n_H |\,f_H, N) df_H$.  But I am not sure that this is correct, and am not sure how to solve it, even with the hints. I did notice that 2.7 is an example and the additional assumptions - but need help here too. Thank you in advance [Not technically homework as I'm not doing this as part of a course, but it's close enough to tag it]","[Editing question per Leon's suggestions - thanks for these!] Could someone walk me through a solution to Ex 2.8? 2.7:  Bill tosses a bent coin $N$ times, obtaining a sequence of heads and tails.  We assume that the coin has a probability $f_H$ of coming up heads; we do not know $f_H$.  If $n_H$ heads have occurred in $N$ tosses, what is the probability distribution of $f_H$? ...What is the probability that the $N+1$th outcome will be a head, given $n_H$ heads in $N$ tosses? 2.8:  Assuming a uniform prior on $f_H$, $P(f_H)=1$, solve the problem posed in 2.7.  Sketch the distribution of fH and compute the probability that the $N+1$th outcome will be a head, for (A) $N=3$ and $n_H$=0; (B) $N=3$ and $n_H=2$; (C) $N=10$ and $n_H=3$; (D) $N=300$ and $n_H=29$. {tip about the beta integral} Where I am stuck is with the switch to continuous probabilities, and using integrals rather than sums.  Had no problem with 2.4; 2.5 took some doing but was fine.  The example in 2.6 made sense walking through it. In working on 2.8, I can write down that posterior = (likelihood x prior) / evidence, and know that I am trying to solve for posterior (to find the distribution of $f_H$).  So my equation will look something like $$P(f_H |\,n_H, N) = {P(n_H|\,f_H, N) P(f_H) \over P(n_H|\,N)}$$. The left hand side of the numerator should just be the binomial probability ${N \choose n_H}$ $f_H^{n_H}$ $(1-f_H)^{N-n_H}$  Based on the statement in the question, I assume that $P(f_H) = 1$ and ignore it. The denominator is the marginal probability of $n_H$.  I believe this should be an integral - something like $\int_0^1 P(f_H) P(n_H |\,f_H, N) df_H$.  But I am not sure that this is correct, and am not sure how to solve it, even with the hints. I did notice that 2.7 is an example and the additional assumptions - but need help here too. Thank you in advance [Not technically homework as I'm not doing this as part of a course, but it's close enough to tag it]",,"['probability', 'bayesian']"
65,Period of linear congruential generator,Period of linear congruential generator,,"How can you calculate the probability distribution of the period length of a linear congruential generator? That is $X_{n+1} = (aX_n + c) \bmod m$ where $a$ is chosen uniformly at random from $\{1,\dots, m-1\}$ and $c$ is chosen uniformly at random from  $\{0,\dots, m-1\}$ and $m$ is a fixed prime.   Take $X_0$ to be some arbitrary value from $\{0,\dots, m-1\}$. If it is hard to do exactly, is it possible to give good bounds for the cdf?","How can you calculate the probability distribution of the period length of a linear congruential generator? That is $X_{n+1} = (aX_n + c) \bmod m$ where $a$ is chosen uniformly at random from $\{1,\dots, m-1\}$ and $c$ is chosen uniformly at random from  $\{0,\dots, m-1\}$ and $m$ is a fixed prime.   Take $X_0$ to be some arbitrary value from $\{0,\dots, m-1\}$. If it is hard to do exactly, is it possible to give good bounds for the cdf?",,"['probability', 'random']"
66,Which player is most likely to win when drawing cards?,Which player is most likely to win when drawing cards?,,"Two players each draw a single card, in turn, from a standard deck of 52 cards, without returning it to the deck. The winner is the player with the highest value on their card. If the value on both cards is equal then all cards are returned to the deck, the deck is shuffled and both players draw again with the same rules. Given that the second player is drawing from a deck that has been modified by the first player removing their card, I'm wondering if either player is more likely to win than the other? Does this change as the number of players increases?","Two players each draw a single card, in turn, from a standard deck of 52 cards, without returning it to the deck. The winner is the player with the highest value on their card. If the value on both cards is equal then all cards are returned to the deck, the deck is shuffled and both players draw again with the same rules. Given that the second player is drawing from a deck that has been modified by the first player removing their card, I'm wondering if either player is more likely to win than the other? Does this change as the number of players increases?",,['probability']
67,Probability that a family with $n$ children has exactly $k$ boys,Probability that a family with  children has exactly  boys,n k,"Let the probability $p_n$ that a family has exactly $n$ children be $\alpha p^n$ when $n\geq1$, and $$p_0=1-\alpha p(1+p+p^2+\cdots).$$ Suppose that all the sex distributions have the same probability. Show that for $k\geq1$ the probability that a family has exactly $k$ boys is $2\alpha p^k/(2-p)^{k+1}$.","Let the probability $p_n$ that a family has exactly $n$ children be $\alpha p^n$ when $n\geq1$, and $$p_0=1-\alpha p(1+p+p^2+\cdots).$$ Suppose that all the sex distributions have the same probability. Show that for $k\geq1$ the probability that a family has exactly $k$ boys is $2\alpha p^k/(2-p)^{k+1}$.",,['probability']
68,Expectation of supremum,Expectation of supremum,,"Let $x(t)$ a real valued stochastic process and $T>0$ a constant. Is it true that: $$\mathbb{E}\left[\sup_{t\in [0,T]} |x(t)|\right] \leq T \sup_{t\in [0,T]} \mathbb{E}\left[|x(t)|\right] \text{ ?}$$ Thanks for your help.","Let $x(t)$ a real valued stochastic process and $T>0$ a constant. Is it true that: $$\mathbb{E}\left[\sup_{t\in [0,T]} |x(t)|\right] \leq T \sup_{t\in [0,T]} \mathbb{E}\left[|x(t)|\right] \text{ ?}$$ Thanks for your help.",,['probability']
69,Probability that 5 different faces come up twice each if 6 side die is rolled ten times?,Probability that 5 different faces come up twice each if 6 side die is rolled ten times?,,Find the probability that 5 different faces come up twice each if 6 side die is rolled ten times? What methods should I apply here?,Find the probability that 5 different faces come up twice each if 6 side die is rolled ten times? What methods should I apply here?,,['probability']
70,The unfair subway,The unfair subway,,"This is problem 24, ""The Unfair Subway"", in Mosteller's Fifty Challenging Problems in Probability with Solutions Marvin gets off work at random times between 3 and 5 P.M. His mother lives uptown, his girl friend downtown. He takes the first subway that comes in either direction and eats dinner with the one he is first delivered to. His mother complains that he never comes to see her, but he says she has a 50-50 chance. He has had dinner with her twice in the last 20 working days. Explain. The accompanying solution says that it's because the uptown train always arrives one minute after the downtown train, which in turn arrives nine minutes after the uptown train, in this time span. So there's a nine-to-one chance that Marvin will get on the downtown train and not the uptown one. Huh? Then what happened to the ""50-50 chance"" part of the problem? The problem seemed to be posed as a probabilistic inference problem, i.e. one where the goal is to calculate: $$\binom{20}{2} (0.5)^2 (1-0.5)^{18} \approx 0.00018$$ but it turns out it was a statistical inference problem (one based on maximum likelihood estimates at that) that contradicts information in the problem itself. So my question is: is this a valid problem in probability? Am I missing something that would make this a valid problem?","This is problem 24, ""The Unfair Subway"", in Mosteller's Fifty Challenging Problems in Probability with Solutions Marvin gets off work at random times between 3 and 5 P.M. His mother lives uptown, his girl friend downtown. He takes the first subway that comes in either direction and eats dinner with the one he is first delivered to. His mother complains that he never comes to see her, but he says she has a 50-50 chance. He has had dinner with her twice in the last 20 working days. Explain. The accompanying solution says that it's because the uptown train always arrives one minute after the downtown train, which in turn arrives nine minutes after the uptown train, in this time span. So there's a nine-to-one chance that Marvin will get on the downtown train and not the uptown one. Huh? Then what happened to the ""50-50 chance"" part of the problem? The problem seemed to be posed as a probabilistic inference problem, i.e. one where the goal is to calculate: $$\binom{20}{2} (0.5)^2 (1-0.5)^{18} \approx 0.00018$$ but it turns out it was a statistical inference problem (one based on maximum likelihood estimates at that) that contradicts information in the problem itself. So my question is: is this a valid problem in probability? Am I missing something that would make this a valid problem?",,['probability']
71,Estimating population size,Estimating population size,,"Let's suppose there are $n$ real numbers $a_0 < ... < a_n$ uniformly selected from interval [0, 1). If one knows $k$ numbers on consecutive positions $a_i < ... < a_{i+k-1}$ how good is $(k - 1) / (a_{i+k-1} - a_i)$ an estimator for $n$? What other estimators are possible/better? NOTE: $n >> k$.","Let's suppose there are $n$ real numbers $a_0 < ... < a_n$ uniformly selected from interval [0, 1). If one knows $k$ numbers on consecutive positions $a_i < ... < a_{i+k-1}$ how good is $(k - 1) / (a_{i+k-1} - a_i)$ an estimator for $n$? What other estimators are possible/better? NOTE: $n >> k$.",,"['probability', 'parameter-estimation']"
72,expected winning for a lottery,expected winning for a lottery,,"You decide to make a lottery with n tickets, where each ticket is numbered between 1 and n, and each ticket is unique. Each ticket costs $5, and the lottery works in the following manner. Once all n tickets have been purchased, a number x is selected at random between 1 and n and all the money is divided equally between people with tickets less than x. That way, if 1 is selected, you(as the organizer) get to keep the prize pool. Everyone's number is randomized, the only case where the organizer wins the prize pool is if x=1, as no ticket number is less than 1, so no person wins anything and so the organizer automatically wins the prize pool. Also, the organizer does not hold the number 1, and does not win any money if the number is greater than 1.The only way where they earn the prize pool is if the chosen number is 1, other than that, there is no way they can win any money. The first part is to calculate the expected winnings per lottery as the organizer. So there is only one case where you can win the prize pool, I multiplied the case where you win and the prize pool, so I get: $$\frac{1}{n} \cdot 5n = 5$$ Now, the second part is to calculate the expected winnings if somebody purchases a ticket. I am not able to figure out the probability where somebody wins. For the prize pool, I am confused if it is 5n or 5p (where p is the person's ticket number).","You decide to make a lottery with n tickets, where each ticket is numbered between 1 and n, and each ticket is unique. Each ticket costs $5, and the lottery works in the following manner. Once all n tickets have been purchased, a number x is selected at random between 1 and n and all the money is divided equally between people with tickets less than x. That way, if 1 is selected, you(as the organizer) get to keep the prize pool. Everyone's number is randomized, the only case where the organizer wins the prize pool is if x=1, as no ticket number is less than 1, so no person wins anything and so the organizer automatically wins the prize pool. Also, the organizer does not hold the number 1, and does not win any money if the number is greater than 1.The only way where they earn the prize pool is if the chosen number is 1, other than that, there is no way they can win any money. The first part is to calculate the expected winnings per lottery as the organizer. So there is only one case where you can win the prize pool, I multiplied the case where you win and the prize pool, so I get: Now, the second part is to calculate the expected winnings if somebody purchases a ticket. I am not able to figure out the probability where somebody wins. For the prize pool, I am confused if it is 5n or 5p (where p is the person's ticket number).",\frac{1}{n} \cdot 5n = 5,"['probability', 'discrete-mathematics', 'probability-distributions', 'lotteries']"
73,Probability that a triangle inscribed in a square comprises at least $\frac{1}{4}$ of the area of the square,Probability that a triangle inscribed in a square comprises at least  of the area of the square,\frac{1}{4},"Question: Suppose that points $P_1$ , $P_2$ , and $P_3$ are chosen uniformly at random on the sides of a square $T$ . Compute the probability that $$\frac{[\triangle P_1 P_2 P_3]}{[T]}>\frac{1}{4}$$ where $[X]$ denotes the area of polygon $X$ . Without loss of generality, I assumed the side length of the square to be $1$ . Because the question mentions $\frac{1}{4}$ of the square, I considered splitting the square into quadrants. It is obvious that all three points cannot lie in the same quadrant of the square. Similarly, there cannot be two points in the same quadrant because the area must be less than $\frac{1}{2} \cdot \frac{1}{2} \cdot 1=\frac{1}{4}$ . [EDIT: This is wrong] This means that all three vertices must lie in different quadrants in the square. From here, I considered cases: Case 1: Two of the points are on the same side, which occurs with probability $\frac{9}{16}$ . Case 2: All three points are on different sides, which occurs with probability $\frac{3}{8}$ . From here, my efforts have consisted of just labeling lengths and finding the area in terms of said lengths. However, this has led me with some inequalities that I don't know how to find the probabilities of being true, namely: $x-xz+yz<\frac{1}{2}$ for $0 \leq x,y,z \leq 1$ $(x-y)z<\frac{1}{2}$ fo $0 \leq y<x \leq 1$ and $0 \leq x \leq 1$ If anyone knows how to either find the probability of these inequalities being satisfied (which I think requires multivariable calculus) or a way that circumvents these inequalities, please let me know. Here's my full attempt at the question, though I'm unsure about the accuracy of how I find the probabilities of the three-variable inequalities being satisfied. [NOTE: this method has a few errors in it, a correct version is in the answers below.] Without loss of generality, consider the square with vertices $(0,0), (0,1), (1,0), (1,1)$ . We proceed using casework: All three vertices are on different sides of the square. This occurs with probability $\frac{9}{16}$ . Let the vertices be $(x_1,0)$ , $(0,y_1)$ , and $(x_2,1)$ . Using the determinant form for the area of a triangle, the area is given by $$A=\frac{1}{2} \begin{vmatrix} x_1 & 0 & 1 \\ 0 & y_1 & 1 \\ x_2 & 1 & 1 \end{vmatrix}=\frac{1}{2}x_1-\frac{1}{2}y_1 (x_1-x_2)$$ Assume that $x_1>x_2$ . Then, $$\frac{1}{2}x_1-\frac{1}{2}y_1 (x_1-x_2)>\frac{1}{4} \implies x_1-y_1 (x_1-x_2)>\frac{1}{2}$$ For convenience, replace $x_1$ with $y$ , $x_2$ with $x$ , and $y_1$ with $z$ . We now have the system of inequalities $\begin{cases} y-yz+xz>\frac{1}{2} \\ y>x \\ 0 \leq x,y,z \leq 1 \end{cases}$ . We now consider graphing the inequality $y-yz+xz>\frac{1}{2}$ with $z$ as a constant. The $x$ -intercept is $\frac{1}{2z}$ and the $y$ -intercept is $\frac{1}{2(1-z)}$ . If $0<z \leq \frac{1}{2}$ , then the area of the region is given by $\frac{4z-1}{8z-8}$ . Therefore, the desired probability for this case is $\int^{\frac{1}{2}}_{0} \frac{4z-1}{8z-8} \, dz=\frac{1}{8}(2-\ln 2)$ . If $\frac{1}{2} \leq z<1$ , then the area of the region is given by $\frac{1}{8z}$ . Therefore, the desired probability for this case is $\int^{\frac{1}{2}}_{0} \frac{1}{8z}=\frac{1}{8} \ln 2$ . The overall probability for this case is $$\frac{9}{16} \cdot \frac{1}{2} \cdot \frac{1}{4}=\frac{9}{128}$$ Two vertices lie on the same side of the square and the third vertex lies on the opposite side. This occurs with probability $\frac{1}{8}$ . Let the vertices be $(y,1)$ , $(x,1)$ , and $(z,0)$ where $y>x$ . Then, the area is given by $\frac{1}{2}(y-x)$ , meaning we need $y-x>\frac{1}{2}$ . It is easy to find the probability for this case is $$\frac{1}{8} \cdot \frac{1}{8}=\frac{1}{64}$$ Two vertices lie on the same side of the square and the third vertex lies on an adjacent side. This occurs with probability $\frac{1}{4}$ . Let the vertices of the triangle be $(x,1)$ , $(y,1)$ , and $(1,1-z)$ where $y>x$ . Then, the area is given by $\frac{1}{2}(y-x)(z)$ , meaning we need $(y-x)z>\frac{1}{2}$ . It is easy to see that this is only possible for $\frac{1}{2} \leq z <1$ , in which case the probability is $\frac{2z-1}{8z^2}$ . The probability for this case is thus $$\frac{1}{4} \cdot \int^{1}_{\frac{1}{2}} \frac{2z-1}{8z^2} \, dz=\frac{1}{64} \ln 4-\frac{1}{64}$$ Therefore, the final answer is $$\frac{1}{64} \ln 4-\frac{1}{64}+\frac{1}{64}+\frac{9}{128}=\boxed{\frac{9+4 \ln 2}{128}}$$","Question: Suppose that points , , and are chosen uniformly at random on the sides of a square . Compute the probability that where denotes the area of polygon . Without loss of generality, I assumed the side length of the square to be . Because the question mentions of the square, I considered splitting the square into quadrants. It is obvious that all three points cannot lie in the same quadrant of the square. Similarly, there cannot be two points in the same quadrant because the area must be less than . [EDIT: This is wrong] This means that all three vertices must lie in different quadrants in the square. From here, I considered cases: Case 1: Two of the points are on the same side, which occurs with probability . Case 2: All three points are on different sides, which occurs with probability . From here, my efforts have consisted of just labeling lengths and finding the area in terms of said lengths. However, this has led me with some inequalities that I don't know how to find the probabilities of being true, namely: for fo and If anyone knows how to either find the probability of these inequalities being satisfied (which I think requires multivariable calculus) or a way that circumvents these inequalities, please let me know. Here's my full attempt at the question, though I'm unsure about the accuracy of how I find the probabilities of the three-variable inequalities being satisfied. [NOTE: this method has a few errors in it, a correct version is in the answers below.] Without loss of generality, consider the square with vertices . We proceed using casework: All three vertices are on different sides of the square. This occurs with probability . Let the vertices be , , and . Using the determinant form for the area of a triangle, the area is given by Assume that . Then, For convenience, replace with , with , and with . We now have the system of inequalities . We now consider graphing the inequality with as a constant. The -intercept is and the -intercept is . If , then the area of the region is given by . Therefore, the desired probability for this case is . If , then the area of the region is given by . Therefore, the desired probability for this case is . The overall probability for this case is Two vertices lie on the same side of the square and the third vertex lies on the opposite side. This occurs with probability . Let the vertices be , , and where . Then, the area is given by , meaning we need . It is easy to find the probability for this case is Two vertices lie on the same side of the square and the third vertex lies on an adjacent side. This occurs with probability . Let the vertices of the triangle be , , and where . Then, the area is given by , meaning we need . It is easy to see that this is only possible for , in which case the probability is . The probability for this case is thus Therefore, the final answer is","P_1 P_2 P_3 T \frac{[\triangle P_1 P_2 P_3]}{[T]}>\frac{1}{4} [X] X 1 \frac{1}{4} \frac{1}{2} \cdot \frac{1}{2} \cdot 1=\frac{1}{4} \frac{9}{16} \frac{3}{8} x-xz+yz<\frac{1}{2} 0 \leq x,y,z \leq 1 (x-y)z<\frac{1}{2} 0 \leq y<x \leq 1 0 \leq x \leq 1 (0,0), (0,1), (1,0), (1,1) \frac{9}{16} (x_1,0) (0,y_1) (x_2,1) A=\frac{1}{2} \begin{vmatrix} x_1 & 0 & 1 \\ 0 & y_1 & 1 \\ x_2 & 1 & 1 \end{vmatrix}=\frac{1}{2}x_1-\frac{1}{2}y_1 (x_1-x_2) x_1>x_2 \frac{1}{2}x_1-\frac{1}{2}y_1 (x_1-x_2)>\frac{1}{4} \implies x_1-y_1 (x_1-x_2)>\frac{1}{2} x_1 y x_2 x y_1 z \begin{cases} y-yz+xz>\frac{1}{2} \\ y>x \\ 0 \leq x,y,z \leq 1 \end{cases} y-yz+xz>\frac{1}{2} z x \frac{1}{2z} y \frac{1}{2(1-z)} 0<z \leq \frac{1}{2} \frac{4z-1}{8z-8} \int^{\frac{1}{2}}_{0} \frac{4z-1}{8z-8} \, dz=\frac{1}{8}(2-\ln 2) \frac{1}{2} \leq z<1 \frac{1}{8z} \int^{\frac{1}{2}}_{0} \frac{1}{8z}=\frac{1}{8} \ln 2 \frac{9}{16} \cdot \frac{1}{2} \cdot \frac{1}{4}=\frac{9}{128} \frac{1}{8} (y,1) (x,1) (z,0) y>x \frac{1}{2}(y-x) y-x>\frac{1}{2} \frac{1}{8} \cdot \frac{1}{8}=\frac{1}{64} \frac{1}{4} (x,1) (y,1) (1,1-z) y>x \frac{1}{2}(y-x)(z) (y-x)z>\frac{1}{2} \frac{1}{2} \leq z <1 \frac{2z-1}{8z^2} \frac{1}{4} \cdot \int^{1}_{\frac{1}{2}} \frac{2z-1}{8z^2} \, dz=\frac{1}{64} \ln 4-\frac{1}{64} \frac{1}{64} \ln 4-\frac{1}{64}+\frac{1}{64}+\frac{9}{128}=\boxed{\frac{9+4 \ln 2}{128}}","['probability', 'contest-math', 'geometric-probability']"
74,Probability of infinite coin toss where tossing stops only if the number of heads is twice the number of tails,Probability of infinite coin toss where tossing stops only if the number of heads is twice the number of tails,,"The coin is tossed until the number of heads is exactly equal to twice the number of tails. The coin lands on heads with probability 𝑝. What is the probability that a coin will be tossed forever? A similar problem (A coin lands heads with probability 𝑝. The coin is tossed until the first heads will come up. What is the probability that an even number of tosses will be made?) was solved by reducing the result to an infinite sum, which was an infinite sum of a geometric progression: $$(1-p)*p + (1-p)^3*p +\ldots = (1-p)*p*(1+(1-p)^2+(1-p)^4 + \ldots) = (1-p)*p/(1-(1-p)^2)=(1-p)/(2-p)$$ I assume, if I’m not mistaken, that there should be a similar approach here, but I’m a little confused about how exactly this should be decided: I first thought to subtract from 1 the probability of events when the coin toss stops, that is, when the number of heads becomes equal to twice the number of tails (when you get 1 tail and 2 heads, 2 tails and 4 heads, and so on), but the problem is that there are several sequences in which, for example, 2 tails and 4 heads, because tails and heads can occur in different orders: $$1 - (\binom{3}{1}*(1-p)*p^2+\binom{6}{2}*(1-p)^2*p^4+\ldots)$$ I can’t apply the formula of an infinite geometric progression here and I don’t really understand how to apply the formula of a power series here, although maybe this formula is needed here. Maybe I'm deciding in the wrong way altogether? Please tell me what to do here, because unfortunately I have no more ideas...","The coin is tossed until the number of heads is exactly equal to twice the number of tails. The coin lands on heads with probability 𝑝. What is the probability that a coin will be tossed forever? A similar problem (A coin lands heads with probability 𝑝. The coin is tossed until the first heads will come up. What is the probability that an even number of tosses will be made?) was solved by reducing the result to an infinite sum, which was an infinite sum of a geometric progression: I assume, if I’m not mistaken, that there should be a similar approach here, but I’m a little confused about how exactly this should be decided: I first thought to subtract from 1 the probability of events when the coin toss stops, that is, when the number of heads becomes equal to twice the number of tails (when you get 1 tail and 2 heads, 2 tails and 4 heads, and so on), but the problem is that there are several sequences in which, for example, 2 tails and 4 heads, because tails and heads can occur in different orders: I can’t apply the formula of an infinite geometric progression here and I don’t really understand how to apply the formula of a power series here, although maybe this formula is needed here. Maybe I'm deciding in the wrong way altogether? Please tell me what to do here, because unfortunately I have no more ideas...",(1-p)*p + (1-p)^3*p +\ldots = (1-p)*p*(1+(1-p)^2+(1-p)^4 + \ldots) = (1-p)*p/(1-(1-p)^2)=(1-p)/(2-p) 1 - (\binom{3}{1}*(1-p)*p^2+\binom{6}{2}*(1-p)^2*p^4+\ldots),['probability']
75,Prove that it exists $i \neq j$ s.t. $P(A_i \cap A_j) \geq \frac{nc^2-c}{n-1}$ with $P(A_i) \geq c $,Prove that it exists  s.t.  with,i \neq j P(A_i \cap A_j) \geq \frac{nc^2-c}{n-1} P(A_i) \geq c ,"Question: Let $A_1,A_2,...,A_n \subset \Omega $ a sequence of outcome such that $P(A_i) \geq c $ for all $i$ . Prove that it exists $i \neq j$ s.t. $P(A_i \cap A_j) \geq \frac{nc^2-c}{n-1}$ I have tried different ways including the following one but I did not succeed to conclude. 1-First note that: $\int (\sum_{1 \leq i \leq n} I_{A_i})^2dP= \sum_{i \neq j} \int I_{A_i}I_{A_j}dP + \sum_{i = j} \int I_{A_i}^2dP= \sum_{i \neq j} P(A_i \cap A_j) + \sum_{i = j}P(A_i)$ 2-Now we know that $\sum_{i = j}P(A_i)$ is the sum of $n$ element, thus $\sum_{i = j}P(A_i) \geq nc$ 3-We know too that $\sum_{i \neq j} P(A_i \cap A_j)$ is the sum of $n(n-1)$ elements. More over $\forall i \neq j$ by absurd let suppose that $P(A_i \cap A_j) < \frac{nc^2-c}{n-1}$ . But after I don't succeed to continue. Can someone help me please? Thank for your help.","Question: Let a sequence of outcome such that for all . Prove that it exists s.t. I have tried different ways including the following one but I did not succeed to conclude. 1-First note that: 2-Now we know that is the sum of element, thus 3-We know too that is the sum of elements. More over by absurd let suppose that . But after I don't succeed to continue. Can someone help me please? Thank for your help.","A_1,A_2,...,A_n \subset \Omega  P(A_i) \geq c  i i \neq j P(A_i \cap A_j) \geq \frac{nc^2-c}{n-1} \int (\sum_{1 \leq i \leq n} I_{A_i})^2dP= \sum_{i \neq j} \int I_{A_i}I_{A_j}dP + \sum_{i = j} \int I_{A_i}^2dP= \sum_{i \neq j} P(A_i \cap A_j) + \sum_{i = j}P(A_i) \sum_{i = j}P(A_i) n \sum_{i = j}P(A_i) \geq nc \sum_{i \neq j} P(A_i \cap A_j) n(n-1) \forall i \neq j P(A_i \cap A_j) < \frac{nc^2-c}{n-1}","['probability', 'probability-theory', 'measure-theory', 'inequality']"
76,Texas Hold'em Poker odds - calculating opponent's odds,Texas Hold'em Poker odds - calculating opponent's odds,,"Scenario: we have reached River, i.e. there are 5 cards on the table, and three of them are hearts. I have no heart on my hand, and there are 6 remaining players other than me. What is the probability, that (at least) one of them will have (any) two hearts on hand? Now if there was just one player other than me, the computation for him I believe would be this: $$\frac{\binom{10}2}{\binom{45}2}=\frac{1}{22} \approx 4.55 \%$$ because there are $10$ remaining hearts in the unseen cards and there are $45$ unseen cards together. Is this correct so far? Now the probability for $6$ remaining players is as simple as multiplying that previous number by $6$ ? One could argue it is, because from the combination point it doesn't matter whether unknown card is in deck or in hand. But then I get this: $$22\frac{\binom{10}2}{\binom{45}2} = 100 \%$$ , exactly. But $45$ unseen cards is $22$ and a half players. So it seems the simplified calculation is not entirely correct, though close. What matters to me is, if that simplified calculation will be always close, or are there scenarios where it will be way off?","Scenario: we have reached River, i.e. there are 5 cards on the table, and three of them are hearts. I have no heart on my hand, and there are 6 remaining players other than me. What is the probability, that (at least) one of them will have (any) two hearts on hand? Now if there was just one player other than me, the computation for him I believe would be this: because there are remaining hearts in the unseen cards and there are unseen cards together. Is this correct so far? Now the probability for remaining players is as simple as multiplying that previous number by ? One could argue it is, because from the combination point it doesn't matter whether unknown card is in deck or in hand. But then I get this: , exactly. But unseen cards is and a half players. So it seems the simplified calculation is not entirely correct, though close. What matters to me is, if that simplified calculation will be always close, or are there scenarios where it will be way off?",\frac{\binom{10}2}{\binom{45}2}=\frac{1}{22} \approx 4.55 \% 10 45 6 6 22\frac{\binom{10}2}{\binom{45}2} = 100 \% 45 22,"['probability', 'combinatorics', 'poker']"
77,Probability that two random lines intersect inside a square,Probability that two random lines intersect inside a square,,"Consider the square with vertices $(0,0),(1,0),(1,1),(0,1)$ . Choose two independent uniformly random points $P$ and $Q$ inside the square. Draw a line $l_P$ connecting $(0,0)$ and $P$ . Draw another line $l_Q$ connecting $(1,0)$ and $Q$ . What is the probability that $l_P$ and $l_Q$ intersect inside the square? I will post my answer. Alternative solutions are welcome. This question and answer serve to flesh out a comment I made at a similar question .",Consider the square with vertices . Choose two independent uniformly random points and inside the square. Draw a line connecting and . Draw another line connecting and . What is the probability that and intersect inside the square? I will post my answer. Alternative solutions are welcome. This question and answer serve to flesh out a comment I made at a similar question .,"(0,0),(1,0),(1,1),(0,1) P Q l_P (0,0) P l_Q (1,0) Q l_P l_Q","['probability', 'geometry', 'intuition', 'geometric-probability']"
78,Doubt about gaussian multivariate distribution.,Doubt about gaussian multivariate distribution.,,"I don't have any basis on multivariate gaussian distributions and amid one exercise I was solving about a non-directly related topic, the following question came to my mind: Let's say we have some random variables $X_1,\dots,X_n$ such that each $X_i$ follows a gaussian distribution of some kind. Furthermore, assume that $X_1,\dots,X_n$ are independent. Then, is it true that $(X_1,\dots,X_n)$ also follows a gaussian distribution? Also, an aditional question: in the case that the result is true, is the same statement also true if we don't require that $X_1,\dots,X_n$ are independent? I am not looking for an elaborate explanation of this facts, just a yes/no so that I can proceed with solving my exercise (again, multivariate gaussian distribution is not the main topic of the exercise and I don't have any basis on it).","I don't have any basis on multivariate gaussian distributions and amid one exercise I was solving about a non-directly related topic, the following question came to my mind: Let's say we have some random variables such that each follows a gaussian distribution of some kind. Furthermore, assume that are independent. Then, is it true that also follows a gaussian distribution? Also, an aditional question: in the case that the result is true, is the same statement also true if we don't require that are independent? I am not looking for an elaborate explanation of this facts, just a yes/no so that I can proceed with solving my exercise (again, multivariate gaussian distribution is not the main topic of the exercise and I don't have any basis on it).","X_1,\dots,X_n X_i X_1,\dots,X_n (X_1,\dots,X_n) X_1,\dots,X_n","['probability', 'statistics', 'normal-distribution']"
79,$P(X<Y<Z)$ for exponentially distributed independent random variables,for exponentially distributed independent random variables,P(X<Y<Z),"Let $X$ $Y$ $Z$ independent, exponentially distributed random variables with parameters $a$ $b$ $c$ respectively. Calculate $P(X<Y<Z)$ . One way is to compute integral of joint density. Second way which my textbook describe is: $$P(X<Y<Z)=P(X<\min(Y,Z))P(Y<Z)$$ $\min(Y,Z)$ is exponentially distributed with parameter $b+c$ and the rest is easy integration. However why is $P(X<Y<Z)=P(X<\min(Y,Z))P(Y<Z)$ true? Why not $P(X<Y<Z)=P(X<Y)P(Y<Z)$ ? (independent question)","Let independent, exponentially distributed random variables with parameters respectively. Calculate . One way is to compute integral of joint density. Second way which my textbook describe is: is exponentially distributed with parameter and the rest is easy integration. However why is true? Why not ? (independent question)","X Y Z a b c P(X<Y<Z) P(X<Y<Z)=P(X<\min(Y,Z))P(Y<Z) \min(Y,Z) b+c P(X<Y<Z)=P(X<\min(Y,Z))P(Y<Z) P(X<Y<Z)=P(X<Y)P(Y<Z)","['probability', 'probability-distributions', 'independence', 'exponential-distribution']"
80,Why is the law of large numbers defined as the probability of a limit rather than the limit of probability?,Why is the law of large numbers defined as the probability of a limit rather than the limit of probability?,,"The law of large numbers states for $X_1,...,X_n$ random variables with finite expectation, \begin{equation} \mathbb{P}\bigg(\lim_{n\to\infty}\frac{S_n}{n}=\mu\bigg) = 1 \end{equation} where $S_n = X_1+...+X_n$ . I'm struggling to understand the difference between this definition and \begin{equation} \lim_{n\to\infty} \mathbb{P}\bigg(\frac{S_n}{n}=\mu\bigg) = 1. \end{equation} Are they equivilant? Does one imply the other? I know in general that the probability of a limit and the limit of the probability are not equivilant but struggling to understand the reason in this case.","The law of large numbers states for random variables with finite expectation, where . I'm struggling to understand the difference between this definition and Are they equivilant? Does one imply the other? I know in general that the probability of a limit and the limit of the probability are not equivilant but struggling to understand the reason in this case.","X_1,...,X_n \begin{equation}
\mathbb{P}\bigg(\lim_{n\to\infty}\frac{S_n}{n}=\mu\bigg) = 1
\end{equation} S_n = X_1+...+X_n \begin{equation}
\lim_{n\to\infty} \mathbb{P}\bigg(\frac{S_n}{n}=\mu\bigg) = 1.
\end{equation}","['probability', 'probability-theory', 'limits', 'probability-limit-theorems', 'law-of-large-numbers']"
81,Spoons card game probability problem,Spoons card game probability problem,,"We have 12 cards with four different suits: hearts, diamonds, spades, and clovers. Each suit has three cards with numbers from 1 to 3. We randomly deal these cards to three people, giving each person four cards. What is the probability that at least one person has four of a kind? I came across this probability problem while playing 'Spoons' with my friend. I tried to solve the problem and got the results, but I couldn't check if this is the right answer, so I'm asking here. My answer is $$\frac{3\cdot 3{}\cdot \left({\binom{8}{4}-2}\right)+6}{\binom{12}{4}\cdot \binom{8}{4}}$$","We have 12 cards with four different suits: hearts, diamonds, spades, and clovers. Each suit has three cards with numbers from 1 to 3. We randomly deal these cards to three people, giving each person four cards. What is the probability that at least one person has four of a kind? I came across this probability problem while playing 'Spoons' with my friend. I tried to solve the problem and got the results, but I couldn't check if this is the right answer, so I'm asking here. My answer is",\frac{3\cdot 3{}\cdot \left({\binom{8}{4}-2}\right)+6}{\binom{12}{4}\cdot \binom{8}{4}},"['probability', 'card-games']"
82,Probability that one person is selected and other is not selected in a group,Probability that one person is selected and other is not selected in a group,,"There are $30000$ students, out of which only $1000$ students are selected. There are two students $A$ and $B$ , what is the probability that $A$ is selected and $B$ is not selected? The solution is given as $\frac{1000}{30000}* \frac{29000}{30000}$ , but this does not seems correct to me. The way I look at this problem, the sample space has $_{30000}C_{1000}$ elements. The event, since we need all the sets from $SS$ that has $A$ but not $B$ , we have $_{29998}C_{999}$ Since we fix $A$ in the set and exclude $B$ Both give very different results, request your help in understanding which one is correct and why, Thanks.","There are students, out of which only students are selected. There are two students and , what is the probability that is selected and is not selected? The solution is given as , but this does not seems correct to me. The way I look at this problem, the sample space has elements. The event, since we need all the sets from that has but not , we have Since we fix in the set and exclude Both give very different results, request your help in understanding which one is correct and why, Thanks.",30000 1000 A B A B \frac{1000}{30000}* \frac{29000}{30000} _{30000}C_{1000} SS A B _{29998}C_{999} A B,"['probability', 'combinatorics']"
83,Alternative Definition of Markov Property.,Alternative Definition of Markov Property.,,"currently I am trying to solve the following exercise (17.1.1) in Klenke Probability Theory, which states the following: Let $(X_t)_{t \in I}$ be a stochastic process and denote by $\mathcal{F}_{\leq t} = \sigma(X_s : s \in I, \; s \leq t)$ the sigma-algebra of the past until time $t$ , while $\mathcal{F}_{\geq t}$ denotes respectively the sigma-algebra of the future. Then one has the following equivalence: The process $(X_t)_{t \in I}$ admits the (elementary) Markov property iff both $\mathcal{F}_{\leq t}$ and $\mathcal{F}_{\geq t}$ are independent given $\sigma(X_t)$ , where the definition follows: Conditional Independence A family of sub-sigma algebras $(\mathcal{A}_i)_{i \in I} \subset \mathcal{F}$ is called independent of the sub-sigma algebra $\mathcal{A} \subset \mathcal{F}$ if for every finite $J \subset I$ one has $$ P(\cap_{j \in J} A_j \mid \mathcal{A}) = \prod_{j \in J} P(A_j \mid \mathcal{A}) \quad \text{almost surely}. $$ My try so far: For the first direction, suppose that $X$ admits the Markov Property then let $(A_j)_{j \in J} \subseteq \sigma(X_s)_{s \leq t}$ be a finite family of events from the sigma algebra of the past, observe that for $A = \cap_{j \in J} A_j$ one has almost surely $$ P(A \mid \sigma(X_t)) \stackrel{Def.}{=} E[ \mathbf{1}_A \mid \sigma(X_t) ] \stackrel{M.P}{=} E[ \mathbf{1}_A \mid \mathcal{F}_t ] = \mathbf{1}_A = \prod_{j \in J} \mathbf{1}_{A_j} = \prod_{j \in J} P(A_j \mid \mathcal{F}_t) \stackrel{M.P}{=} \prod_{j \in J} P(A_j \mid \sigma(X_t)), $$ where we used that due to the filtration property $\mathbf{1}_{A_j}$ are $\mathcal{F}_t$ -measurable. Now for the sigma algebra of the future let again $(A_j)_{j \in J}$ be a finite family of events of $\mathcal{F}_{t \geq}$ then observe first that by the Markov Property one has $$ P(A \mid \sigma(X_t) ) \stackrel{M.P}{=} P(A \mid \mathcal{F}_t) \stackrel{Def.}{=} E[\mathbf{1}_{A} \mid \mathcal{F}_t], $$ then since for all $j \in J$ one has $A_j \in \mathcal{F}_j$ where $j \geq t$ but now I am stuck since I cannot use the tower property in a good way. I am sure there is a connection with independence and conditional expectation but right now I don't see it, any hints? Thanks in advance.","currently I am trying to solve the following exercise (17.1.1) in Klenke Probability Theory, which states the following: Let be a stochastic process and denote by the sigma-algebra of the past until time , while denotes respectively the sigma-algebra of the future. Then one has the following equivalence: The process admits the (elementary) Markov property iff both and are independent given , where the definition follows: Conditional Independence A family of sub-sigma algebras is called independent of the sub-sigma algebra if for every finite one has My try so far: For the first direction, suppose that admits the Markov Property then let be a finite family of events from the sigma algebra of the past, observe that for one has almost surely where we used that due to the filtration property are -measurable. Now for the sigma algebra of the future let again be a finite family of events of then observe first that by the Markov Property one has then since for all one has where but now I am stuck since I cannot use the tower property in a good way. I am sure there is a connection with independence and conditional expectation but right now I don't see it, any hints? Thanks in advance.","(X_t)_{t \in I} \mathcal{F}_{\leq t} = \sigma(X_s : s \in I, \; s \leq t) t \mathcal{F}_{\geq t} (X_t)_{t \in I} \mathcal{F}_{\leq t} \mathcal{F}_{\geq t} \sigma(X_t) (\mathcal{A}_i)_{i \in I} \subset \mathcal{F} \mathcal{A} \subset \mathcal{F} J \subset I 
P(\cap_{j \in J} A_j \mid \mathcal{A}) = \prod_{j \in J} P(A_j \mid \mathcal{A}) \quad \text{almost surely}.
 X (A_j)_{j \in J} \subseteq \sigma(X_s)_{s \leq t} A = \cap_{j \in J} A_j 
P(A \mid \sigma(X_t)) \stackrel{Def.}{=} E[ \mathbf{1}_A \mid \sigma(X_t) ] \stackrel{M.P}{=} E[ \mathbf{1}_A \mid \mathcal{F}_t ] = \mathbf{1}_A = \prod_{j \in J} \mathbf{1}_{A_j} = \prod_{j \in J} P(A_j \mid \mathcal{F}_t) \stackrel{M.P}{=} \prod_{j \in J} P(A_j \mid \sigma(X_t)),
 \mathbf{1}_{A_j} \mathcal{F}_t (A_j)_{j \in J} \mathcal{F}_{t \geq} 
P(A \mid \sigma(X_t) ) \stackrel{M.P}{=} P(A \mid \mathcal{F}_t) \stackrel{Def.}{=} E[\mathbf{1}_{A} \mid \mathcal{F}_t],
 j \in J A_j \in \mathcal{F}_j j \geq t","['real-analysis', 'probability', 'measure-theory', 'stochastic-processes']"
84,Geometric Intuition behind Chebyshev's Inequality?,Geometric Intuition behind Chebyshev's Inequality?,,"I understand the proof behind this, and I've read a bunch of intuition behind it posts, but I don't think I completely understand what's happening. I also found a geometric intuition behind Markov's Inequality post and that made it easier to understand, so is there a geometric intuition behind this? Markov's Inequality: $P(X \ge a) \le \frac{E[X]}{a}$ where $X > 0$ Chebyshev's Inequality: $P(|X - E[X]| \ge a) \le \frac{\sigma^{2}}{a^{2}}$","I understand the proof behind this, and I've read a bunch of intuition behind it posts, but I don't think I completely understand what's happening. I also found a geometric intuition behind Markov's Inequality post and that made it easier to understand, so is there a geometric intuition behind this? Markov's Inequality: where Chebyshev's Inequality:",P(X \ge a) \le \frac{E[X]}{a} X > 0 P(|X - E[X]| \ge a) \le \frac{\sigma^{2}}{a^{2}},"['probability', 'inequality']"
85,How many expected flips before my sausage patties are all face up?,How many expected flips before my sausage patties are all face up?,,"I was in front of the stove making breakfast sausages this morning and I thought of a problem. If I have 3 patties that need to be flipped, and after every pan flick somewhere between 1 and 3 random patties flip, how many flicks should I expect before all of the patties are flipped to the right orientation? I'm sure this problem has been abstracted for coins or something, but I can't seem to think of how I put them together (especially because AT LEAST 1 patty is always flipped). I see that logically about 1/3 of the time I get it first try (not my personal experience but lets assume I'm a better chef than that). but after that it looks like a Markov chain problem (right?). My programatic trials seem to suggest at mean of around 6, but how would I work this out on pen and paper? Here is my simulation code import random as rd import seaborn as sns import matplotlib.pyplot as plt from tqdm import tqdm total_trials = 1000000 hist_data = [] for _ in tqdm(range(total_trials)):     patty_list = [False, False, False]     num_attempts = 0     while not all(patty_list):         num_flips = rd.choice([1, 2, 3])         rd.shuffle(patty_list)         for i in range(num_flips):             patty_list[i] = not patty_list[i]         num_attempts += 1     hist_data.append(num_attempts)      sns.histplot(hist_data, bins=range(1, 100)).set(title=f'trials: {total_trials:,}\nmean: {sum(hist_data)/len(hist_data)}') plt.show() resulting in: Edit: I think my code is wrong, as it does not account for the different permutations of flips. TTF = TFT = FTT despite those being 3 scenarios. Does that check out? Edit 2: Does it make sense for me to assume N flips and then assign those flips randomly to pattys? Or do I have to assume that each patty has some probability of flipping? If I do the latter, is it just magic that they never all-not-flip? Edit 3: Thanks all for the thoughtful approach to my breakfast problem. I've learned a lot about the consequences of not defining my problem well! There are a lot of great answers here and since they're all right from a different point of view (I'll define better next time) I'm going to mark the first answer given as the correct. Thanks again all!","I was in front of the stove making breakfast sausages this morning and I thought of a problem. If I have 3 patties that need to be flipped, and after every pan flick somewhere between 1 and 3 random patties flip, how many flicks should I expect before all of the patties are flipped to the right orientation? I'm sure this problem has been abstracted for coins or something, but I can't seem to think of how I put them together (especially because AT LEAST 1 patty is always flipped). I see that logically about 1/3 of the time I get it first try (not my personal experience but lets assume I'm a better chef than that). but after that it looks like a Markov chain problem (right?). My programatic trials seem to suggest at mean of around 6, but how would I work this out on pen and paper? Here is my simulation code import random as rd import seaborn as sns import matplotlib.pyplot as plt from tqdm import tqdm total_trials = 1000000 hist_data = [] for _ in tqdm(range(total_trials)):     patty_list = [False, False, False]     num_attempts = 0     while not all(patty_list):         num_flips = rd.choice([1, 2, 3])         rd.shuffle(patty_list)         for i in range(num_flips):             patty_list[i] = not patty_list[i]         num_attempts += 1     hist_data.append(num_attempts)      sns.histplot(hist_data, bins=range(1, 100)).set(title=f'trials: {total_trials:,}\nmean: {sum(hist_data)/len(hist_data)}') plt.show() resulting in: Edit: I think my code is wrong, as it does not account for the different permutations of flips. TTF = TFT = FTT despite those being 3 scenarios. Does that check out? Edit 2: Does it make sense for me to assume N flips and then assign those flips randomly to pattys? Or do I have to assume that each patty has some probability of flipping? If I do the latter, is it just magic that they never all-not-flip? Edit 3: Thanks all for the thoughtful approach to my breakfast problem. I've learned a lot about the consequences of not defining my problem well! There are a lot of great answers here and since they're all right from a different point of view (I'll define better next time) I'm going to mark the first answer given as the correct. Thanks again all!",,"['probability', 'probability-distributions', 'binomial-distribution']"
86,"In the field $No$ of surreal numbers, does $\underbrace {\frac 1 \omega + \frac 1 \omega + ...}_{\omega\text{ times}}= 1?$","In the field  of surreal numbers, does",No \underbrace {\frac 1 \omega + \frac 1 \omega + ...}_{\omega\text{ times}}= 1?,"The question is in the title.  It is known that $\omega$ $\cdot$ $\frac 1 {\omega}$ = 1, but can the expression on the left-hand side be replaced by the infinite sum in the title?  If so then by the fact that $No$ is a field suggests that $\frac 1 {\omega}$ can be thought of as a probability measure.  On the other hand, consider the following examples given by Prof. Conway (onpp.43-44 of On Numbers and Games : It is interesting to note that our definitions of infinite sums have in a certain sense to be ""global"", rather than as limits of partial sums, because limits don't seem to work. For instance, the limit of the sequence 0, $\frac 1 2$ , $\frac 2 3$ , $\frac 3 4$ ,... ( $\omega$ terms) is not 1, at least in the ordinary sense, because there are plenty of numbers in between.  A simpler, but sometimes less convincing, example of the same phenomenon is given by the sequence 0,1,2,3,... of all finite ordinals, which one would expect to tend to $\omega$ , but obviously can't, since there is a whole Host of numbers greater than every finite integer but less than $\omega [here Prof. Conway gives us his favorites of such numbers--my comment].","The question is in the title.  It is known that = 1, but can the expression on the left-hand side be replaced by the infinite sum in the title?  If so then by the fact that is a field suggests that can be thought of as a probability measure.  On the other hand, consider the following examples given by Prof. Conway (onpp.43-44 of On Numbers and Games : It is interesting to note that our definitions of infinite sums have in a certain sense to be ""global"", rather than as limits of partial sums, because limits don't seem to work. For instance, the limit of the sequence 0, , , ,... ( terms) is not 1, at least in the ordinary sense, because there are plenty of numbers in between.  A simpler, but sometimes less convincing, example of the same phenomenon is given by the sequence 0,1,2,3,... of all finite ordinals, which one would expect to tend to , but obviously can't, since there is a whole Host of numbers greater than every finite integer but less than $\omega [here Prof. Conway gives us his favorites of such numbers--my comment].",\omega \cdot \frac 1 {\omega} No \frac 1 {\omega} \frac 1 2 \frac 2 3 \frac 3 4 \omega \omega,"['probability', 'surreal-numbers']"
87,Profit maximization with Markov Chains,Profit maximization with Markov Chains,,"Problem : An opera singer is due to perform a long series of concerts. Having a bad temper, they are liable to pull out each night with probability $1/2$ . Once this has happened they will not sing again until the promoter convinces them of the promoter’s high regard. This the promoter does by sending flowers every day until the singer returns. Flowers costing $x$ thousand pounds, $0 ≤ x ≤ 1$ , bring about a reconciliation with probability $\sqrt{x}$ .The promoter stands to make $£750$ from each successful concert. How much should they spend on flowers? I'd like to have solution verification or alternative approaches . (Problem's from exercise 1.10.4 of Markov Chains by J.R. Norris) Interpretation : I suppose the singer pulls out independent of the past given that they performed last night.  Also I suppose $x$ is ""how much they[the promoter] should spend on flowers"", which is time-homogeneous. I suppose promoter wants to maximize their expected profit. Plan : I'll use a 2 state MC to track whether the singer performs or not . Then I'll find the long-run proportion of time that singer performs : $v(x)$ . Finally $x$ will be the maximizer of $f(x) = 750v(x)-x(1-v(x))$ , I think $f(x)$ should approximate the expected profit . If the MC turns out to be irreducible , then by Theorem 1.10.2 , $v(x)$ will almost surely be the inverse of expected return time of the state that the singer performs . Theorem 1.10.2  Let $P$ be irreducible and let $\lambda$ be any distribution . If $(X_n)_{n\ge 0}$ is Markov $(\lambda,P)$ then $$ \mathbb{P}\left( \frac{V_i(n)}{n} \to \frac{1}{m_i} \text{ as } n \to \infty  \right) = 1  $$ where $V_i(n) = \sum_{k=0}^{n-1} 1_{\{X_k = i\}}$ and $m_i$ is expected return time to state $i$ . Attempt : Let $(X_n)_{n\ge 0}$ be a Markov chain such that the initial distribution is uniform and $ X_n =  \left\{\begin{array}{cc} 1 & \text{if singer performs } \\ 0 & \text{else }  \end{array}\right. $ . So transition probabilities are $$ \left\{\begin{array}{cc} p_{10} = 1/2  , &  p_{11} =  1/2 \\ p_{01} = \sqrt{x} , & p_{00} = 1 - \sqrt{x} \end{array}\right. $$ with $x\in (0,1] $ . $(X_n)_{n\ge 0}$ is irreducible on state space $\{0,1\}$ . The expected return time to $1$ is $m_1 = 1 + \frac{1}{2}\frac{1}{\sqrt{x}} $ , so $v(x) = 1/m_1  $ . When $x = 0 $ , $\{0\}$ becomes the absorption state , the expected profit is $\frac{1}{2} 750 \sum_{x=1}^{\infty}  x\left(\frac{1}{2}\right)^x  = \frac{1}{2} 750(2) = 750 $ . Numerically I found the maximum of $f(x) , x\in (0,1]$ is around $500$ at $x=1$ . So should I conclude that he should spend $x=0$ GBP on her ?","Problem : An opera singer is due to perform a long series of concerts. Having a bad temper, they are liable to pull out each night with probability . Once this has happened they will not sing again until the promoter convinces them of the promoter’s high regard. This the promoter does by sending flowers every day until the singer returns. Flowers costing thousand pounds, , bring about a reconciliation with probability .The promoter stands to make from each successful concert. How much should they spend on flowers? I'd like to have solution verification or alternative approaches . (Problem's from exercise 1.10.4 of Markov Chains by J.R. Norris) Interpretation : I suppose the singer pulls out independent of the past given that they performed last night.  Also I suppose is ""how much they[the promoter] should spend on flowers"", which is time-homogeneous. I suppose promoter wants to maximize their expected profit. Plan : I'll use a 2 state MC to track whether the singer performs or not . Then I'll find the long-run proportion of time that singer performs : . Finally will be the maximizer of , I think should approximate the expected profit . If the MC turns out to be irreducible , then by Theorem 1.10.2 , will almost surely be the inverse of expected return time of the state that the singer performs . Theorem 1.10.2  Let be irreducible and let be any distribution . If is Markov then where and is expected return time to state . Attempt : Let be a Markov chain such that the initial distribution is uniform and . So transition probabilities are with . is irreducible on state space . The expected return time to is , so . When , becomes the absorption state , the expected profit is . Numerically I found the maximum of is around at . So should I conclude that he should spend GBP on her ?","1/2 x 0 ≤ x ≤ 1 \sqrt{x} £750 x v(x) x f(x) = 750v(x)-x(1-v(x)) f(x) v(x) P \lambda (X_n)_{n\ge 0} (\lambda,P) 
\mathbb{P}\left( \frac{V_i(n)}{n} \to \frac{1}{m_i} \text{ as } n \to \infty  \right) = 1 
 V_i(n) = \sum_{k=0}^{n-1} 1_{\{X_k = i\}} m_i i (X_n)_{n\ge 0} 
X_n = 
\left\{\begin{array}{cc}
1 & \text{if singer performs } \\
0 & \text{else } 
\end{array}\right.
 
\left\{\begin{array}{cc}
p_{10} = 1/2  , &  p_{11} =  1/2 \\
p_{01} = \sqrt{x} , & p_{00} = 1 - \sqrt{x}
\end{array}\right.
 x\in (0,1]  (X_n)_{n\ge 0} \{0,1\} 1 m_1 = 1 + \frac{1}{2}\frac{1}{\sqrt{x}}  v(x) = 1/m_1   x = 0  \{0\} \frac{1}{2} 750 \sum_{x=1}^{\infty}  x\left(\frac{1}{2}\right)^x  = \frac{1}{2} 750(2) = 750  f(x) , x\in (0,1] 500 x=1 x=0","['probability', 'discrete-mathematics', 'solution-verification', 'markov-chains', 'game-theory']"
88,Probability of rolling exactly 1 number exactly 3 times in 6 rolls of a fair die,Probability of rolling exactly 1 number exactly 3 times in 6 rolls of a fair die,,"I'm trying to calculate the probability based on the size of the event space divided by the size of the sample space $P=\frac{|E|}{|S|}$ I know that $|S|=6^6$ , but am not sure what exactly the event space consists. Currently my thoughts are that we have 6 choices for our favorable event(the triples) and for the remaining 3 numbers we have $5\times5\times4=100$ , $4$ because we do not want to include the possibility of having 3 same numbers two times, and to consider all possible arrangements, there are then $\frac{6!}{3!1!1!1!}$ possibilities. This leads to our final equation of : $P=\frac{|E|}{|S|}=\frac{6!}{3!1!1!1!} \times \frac{6\times100}{6^6}$ But the problem is that this exceeds 1, which is clearly wrong but I couldn't really figure out what is the fix for my equation. Thanks:)","I'm trying to calculate the probability based on the size of the event space divided by the size of the sample space I know that , but am not sure what exactly the event space consists. Currently my thoughts are that we have 6 choices for our favorable event(the triples) and for the remaining 3 numbers we have , because we do not want to include the possibility of having 3 same numbers two times, and to consider all possible arrangements, there are then possibilities. This leads to our final equation of : But the problem is that this exceeds 1, which is clearly wrong but I couldn't really figure out what is the fix for my equation. Thanks:)",P=\frac{|E|}{|S|} |S|=6^6 5\times5\times4=100 4 \frac{6!}{3!1!1!1!} P=\frac{|E|}{|S|}=\frac{6!}{3!1!1!1!} \times \frac{6\times100}{6^6},['probability']
89,Random walk with positive drift,Random walk with positive drift,,"I'm working on something where the following claim, if true, would be quite helpful: Let $S$ be a random variable distributed over $\{-1,0\}\cup\mathbb N$ with $\mathbb E[S]>0$ . Consider a one dimensional random walk with step size $S$ , starting at $1$ . Is it true that, with nonzero probability, the random walk never reaches 0? Intuitively this claim seems true (as the random walk has positive drift) but I'm not sure how to show it. If the claim does not hold in general, are there other conditions we can impose on the distribution of $S$ that would make the claim true?","I'm working on something where the following claim, if true, would be quite helpful: Let be a random variable distributed over with . Consider a one dimensional random walk with step size , starting at . Is it true that, with nonzero probability, the random walk never reaches 0? Intuitively this claim seems true (as the random walk has positive drift) but I'm not sure how to show it. If the claim does not hold in general, are there other conditions we can impose on the distribution of that would make the claim true?","S \{-1,0\}\cup\mathbb N \mathbb E[S]>0 S 1 S","['probability', 'random-walk']"
90,Determining if a die is fair or not by rolling six times and observing only the sum,Determining if a die is fair or not by rolling six times and observing only the sum,,"Suppose you have two bags and each has 6 dice. In one bag all the die are fair. In the other each die has a bias - die “1” has a probability of returning 1 of $\frac{1}{6} +\epsilon$ and $\frac{1}{6} -\frac{\epsilon}{5}$ for any of the other numbers. Die 2 has a probability of returning 2 of $\frac{1}{6} +\epsilon$ and $\frac{1}{6} - \frac{\epsilon}{5}$ for any of the other numbers and so on. Someone chooses a bag at random and one of the die out of that bag at random. They roll the same die six times and give you the sum. What is the probability that the die came from the biased bag. You can denote the number of ways to get sum S from r rolls as $N^{S}_{r}$ . This is what I got so far: From Bayes, P(bag|sum) = P(sum|bag)P(bag) / P(sum) $\propto$ P(sum|bag) For the fair bag P(sum|bag is fair) = $\frac{N^{S}_{r}}{6^{6}}$ For the unfair bag P(sum|bag is not fair) = $\frac{1}{6}$ P(sum|die biased to return 1) + $\frac{1}{6}$ P(sum|die biased to return 2) + ... + $\frac{1}{6}$ P(sum|die biased to return 6) Thanks!","Suppose you have two bags and each has 6 dice. In one bag all the die are fair. In the other each die has a bias - die “1” has a probability of returning 1 of and for any of the other numbers. Die 2 has a probability of returning 2 of and for any of the other numbers and so on. Someone chooses a bag at random and one of the die out of that bag at random. They roll the same die six times and give you the sum. What is the probability that the die came from the biased bag. You can denote the number of ways to get sum S from r rolls as . This is what I got so far: From Bayes, P(bag|sum) = P(sum|bag)P(bag) / P(sum) P(sum|bag) For the fair bag P(sum|bag is fair) = For the unfair bag P(sum|bag is not fair) = P(sum|die biased to return 1) + P(sum|die biased to return 2) + ... + P(sum|die biased to return 6) Thanks!",\frac{1}{6} +\epsilon \frac{1}{6} -\frac{\epsilon}{5} \frac{1}{6} +\epsilon \frac{1}{6} - \frac{\epsilon}{5} N^{S}_{r} \propto \frac{N^{S}_{r}}{6^{6}} \frac{1}{6} \frac{1}{6} \frac{1}{6},"['probability', 'combinatorics', 'statistics', 'combinations', 'conditional-probability']"
91,Random walks on symmetric groups,Random walks on symmetric groups,,"Let $S_n$ be the symmetric group on $n$ elements. Now, we pick a random transpositions to generate random walks on $S_n$ (also assume the probability of picking each transposition is equal of course). There are $n(n-1)/2$ transpositions. How many does is need on average (expectation) to get back to the identity $(1)$ ? Namely, what is the expectation step of a random walk on $S_n$ first hit the identity? I could compute the case for 2,3, and 4. The expectations are simply 2, 6, 24. So I guess it is $n!$ .","Let be the symmetric group on elements. Now, we pick a random transpositions to generate random walks on (also assume the probability of picking each transposition is equal of course). There are transpositions. How many does is need on average (expectation) to get back to the identity ? Namely, what is the expectation step of a random walk on first hit the identity? I could compute the case for 2,3, and 4. The expectations are simply 2, 6, 24. So I guess it is .",S_n n S_n n(n-1)/2 (1) S_n n!,"['probability', 'combinatorics', 'symmetric-groups', 'random-walk']"
92,"Why does repeatedly drawing circles around a point create a ""ring"" pattern?","Why does repeatedly drawing circles around a point create a ""ring"" pattern?",,"Define a point $P_0$ at the origin. Define an ""iteration"" by putting a circle of radius one around $P_0$ and choosing a uniformly random point on the circle. Let that new point become $P_1$ . Then repeat that process with $P_1$ , say 15 times. Then repeat the steps before a large number, say 250,000 times (view this here ). Why does the image provided produce rings of color? (By rings I mean there's areas of color) The color is defined from the number of iterations to get to that point, and the darker the color the more iterations it took. Points that occur multiple times have their color averaged, and black means no points hit that location. The white circle is the first iteration. (Also, points outside of the circle do NOT stop it iterating, they are just not drawn) Also, just some curious questions: Is there a way to calculate the average distance for $n$ iterations (without simulating it)? Is there a function that can ""smooth"" out either image (doesn't have to be perfect)? What if you could choose a random radius? (250,000 simulations here , 35px is one radii)","Define a point at the origin. Define an ""iteration"" by putting a circle of radius one around and choosing a uniformly random point on the circle. Let that new point become . Then repeat that process with , say 15 times. Then repeat the steps before a large number, say 250,000 times (view this here ). Why does the image provided produce rings of color? (By rings I mean there's areas of color) The color is defined from the number of iterations to get to that point, and the darker the color the more iterations it took. Points that occur multiple times have their color averaged, and black means no points hit that location. The white circle is the first iteration. (Also, points outside of the circle do NOT stop it iterating, they are just not drawn) Also, just some curious questions: Is there a way to calculate the average distance for iterations (without simulating it)? Is there a function that can ""smooth"" out either image (doesn't have to be perfect)? What if you could choose a random radius? (250,000 simulations here , 35px is one radii)",P_0 P_0 P_1 P_1 n,"['probability', 'circles', 'random-walk']"
93,Interesting riddle about heights [closed],Interesting riddle about heights [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Choose a person randomly on the street, $X$ . Let $N$ denote the random variable representing the number of people that you select randomly from the street before you find someone who's taller than $X$ . What is $E[N]$ ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Choose a person randomly on the street, . Let denote the random variable representing the number of people that you select randomly from the street before you find someone who's taller than . What is ?",X N X E[N],"['probability', 'expected-value', 'puzzle']"
94,"What does the efficacy of a vaccine mean, i.e. what does it model?","What does the efficacy of a vaccine mean, i.e. what does it model?",,"I am aware that the efficacy of a vaccine is calculated with $${\displaystyle VE={\frac {ARU-ARV}{ARU}}\times 100\%,} \text{with}\\ \text{VE=Vaccine efficacy}\\ \text {ARU= Attack rate of unvaccinated people}\\ \text {ARV= Attack rate of vaccinated people}$$ but besides echoing the definition of efficacy, I cannot explain even to myself what does it model. Initially I thought that the efficacy is the probability of you not getting the disease in question. However a close look at the formula reveals that efficacy cannot be a mathematical probability, since it can be a negative value: to my understanding during the pandemic negative efficacies have sometimes been reported regarding proposed vaccines. So what does efficacy model at an individual level, and what, if any, connection efficacy has to probabilities and probability theory?","I am aware that the efficacy of a vaccine is calculated with but besides echoing the definition of efficacy, I cannot explain even to myself what does it model. Initially I thought that the efficacy is the probability of you not getting the disease in question. However a close look at the formula reveals that efficacy cannot be a mathematical probability, since it can be a negative value: to my understanding during the pandemic negative efficacies have sometimes been reported regarding proposed vaccines. So what does efficacy model at an individual level, and what, if any, connection efficacy has to probabilities and probability theory?","{\displaystyle VE={\frac {ARU-ARV}{ARU}}\times 100\%,} \text{with}\\
\text{VE=Vaccine efficacy}\\
\text {ARU= Attack rate of unvaccinated people}\\
\text {ARV= Attack rate of vaccinated people}","['probability', 'mathematical-modeling']"
95,Binomial approximation,Binomial approximation,,"A fair die is rolled 800 times. Find the probability to get a 6 at least 150 times. My attempt: The probability to get exactly 150 6's is: $\binom{800}{150}\left(\frac16\right)^{150}\left(\frac56\right)^{800-150}$ The required probability is the sum of getting 150, 151 etc. I understand we must use some approximation here, because we can't do these calculations one by one. Can you please help me?","A fair die is rolled 800 times. Find the probability to get a 6 at least 150 times. My attempt: The probability to get exactly 150 6's is: The required probability is the sum of getting 150, 151 etc. I understand we must use some approximation here, because we can't do these calculations one by one. Can you please help me?",\binom{800}{150}\left(\frac16\right)^{150}\left(\frac56\right)^{800-150},"['probability', 'combinatorics', 'probability-distributions']"
96,Is there a good reason to use covariance and not correlation?,Is there a good reason to use covariance and not correlation?,,Correlation is a normalization of covariance by the standard deviation of each variable . So is there a good reason (and example) when we should (and have) to use covariance and not correlation ?,Correlation is a normalization of covariance by the standard deviation of each variable . So is there a good reason (and example) when we should (and have) to use covariance and not correlation ?,,"['probability', 'statistics', 'covariance', 'correlation']"
97,Best strategy to optimize probability of winning in card drawing game with opponent,Best strategy to optimize probability of winning in card drawing game with opponent,,"I am curious about the solution to a probability question that was asked in a trading interview: You and your opponent choose a suit (of a standard 52 cards deck). Then one card after another is drawn (without replacement) until either your suit or your opponents suit have appeared 5 times (not necessarily in a row). You win if your suit is the one which was drawn 5 times first. Now, your opponent lets you decide if you want to choose your suit before the game starts, after 1, or after 2 cards are revealed and he will choose his suit afterwards. Which strategy gives you the best chances to win? So as an example, I decide to choose after the first card, it comes hearts, I choose hearts, he chooses any of the other suits and from that point I will only need 4 more hearts whereas he still needs 5 of his suit. This makes it obvious that choosing before the game starts is not optimal, as you get an advantage by choosing the suit of the first card. But I am not sure how to determine whether choosing after the first or after the second card is better. In the scenario where I choose after the second there are two possibilities: Either the first 2 cards have the same suit, then I will only need 3 more or they have a different suit. In that case I choose one of the two suits and my opponent chooses the other and our chances will be equal again. To summarize, my chances of winning if I choose after the second card are $$ P(\textrm{first 2 cards have same suit}) P(\textrm{3 out of 11 before 5 out of 13}) \\ + \frac{1}{2}P(\textrm{first 2 cards have different suit}) \\ = \frac{12}{51}P(\textrm{3 out of 11 before 5 out of 13}) + \frac{1}{2}\frac{39}{51} $$ And if I choose after the first card my chances are simply $$ P(\textrm{4 out of 12 before 5 out of 13}) $$ But in both cases I have no idea how to come up with solutions for the missing probabilities, especially because the game is played without replacement and I can not use a binomial distribution approach as it were possible if the game was for example played with coin tosses and you can choose head or tails.","I am curious about the solution to a probability question that was asked in a trading interview: You and your opponent choose a suit (of a standard 52 cards deck). Then one card after another is drawn (without replacement) until either your suit or your opponents suit have appeared 5 times (not necessarily in a row). You win if your suit is the one which was drawn 5 times first. Now, your opponent lets you decide if you want to choose your suit before the game starts, after 1, or after 2 cards are revealed and he will choose his suit afterwards. Which strategy gives you the best chances to win? So as an example, I decide to choose after the first card, it comes hearts, I choose hearts, he chooses any of the other suits and from that point I will only need 4 more hearts whereas he still needs 5 of his suit. This makes it obvious that choosing before the game starts is not optimal, as you get an advantage by choosing the suit of the first card. But I am not sure how to determine whether choosing after the first or after the second card is better. In the scenario where I choose after the second there are two possibilities: Either the first 2 cards have the same suit, then I will only need 3 more or they have a different suit. In that case I choose one of the two suits and my opponent chooses the other and our chances will be equal again. To summarize, my chances of winning if I choose after the second card are And if I choose after the first card my chances are simply But in both cases I have no idea how to come up with solutions for the missing probabilities, especially because the game is played without replacement and I can not use a binomial distribution approach as it were possible if the game was for example played with coin tosses and you can choose head or tails."," P(\textrm{first 2 cards have same suit}) P(\textrm{3 out of 11 before 5 out of 13}) \\
+ \frac{1}{2}P(\textrm{first 2 cards have different suit}) \\
= \frac{12}{51}P(\textrm{3 out of 11 before 5 out of 13}) + \frac{1}{2}\frac{39}{51}
 
P(\textrm{4 out of 12 before 5 out of 13})
","['probability', 'game-theory', 'card-games', 'gambling']"
98,About the correct definition of a binomial random variable,About the correct definition of a binomial random variable,,"I'm having trouble with how to exactly define a binomial random variable. Let's fix a discrete probability space $(\Omega,P)$ , where $|\Omega| \le \aleph_0$ . Then, if $X\colon \Omega \to \mathbb{R}$ is a real random variable, when exactly can we say that it is binomial ( $X \sim Bi(n,p)$ )? I found two possible (non equivalent) definitions: $X$ is the sum of $n$ independent Bernoulli random variables $X_1\colon \Omega \to \{0,1\},\dots,X_n\colon \Omega \to \{0,1\}$ , where $X_1 \sim Be(p),\dots,X_n \sim Be(p)$ ; The probability distribution of $X$ is given by $p_X(k)=P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}$ when $k \in \{0,\dots,n\}$ , while $p_X(x)=0$ if $x \in \mathbb{R} \setminus \{0,\dots,n\}$ . I know that 1) implies 2), but in general it is not true the converse, so that 1) is not equivalent to 2). So maybe I should use 1) as a definition. Right? I apologize for the low level of my question. Thank you!","I'm having trouble with how to exactly define a binomial random variable. Let's fix a discrete probability space , where . Then, if is a real random variable, when exactly can we say that it is binomial ( )? I found two possible (non equivalent) definitions: is the sum of independent Bernoulli random variables , where ; The probability distribution of is given by when , while if . I know that 1) implies 2), but in general it is not true the converse, so that 1) is not equivalent to 2). So maybe I should use 1) as a definition. Right? I apologize for the low level of my question. Thank you!","(\Omega,P) |\Omega| \le \aleph_0 X\colon \Omega \to \mathbb{R} X \sim Bi(n,p) X n X_1\colon \Omega \to \{0,1\},\dots,X_n\colon \Omega \to \{0,1\} X_1 \sim Be(p),\dots,X_n \sim Be(p) X p_X(k)=P(X=k)=\binom{n}{k}p^k(1-p)^{n-k} k \in \{0,\dots,n\} p_X(x)=0 x \in \mathbb{R} \setminus \{0,\dots,n\}","['probability', 'probability-theory', 'soft-question', 'definition', 'binomial-distribution']"
99,Finding the probability that at most n events take place on any interval during a given time period,Finding the probability that at most n events take place on any interval during a given time period,,"I am interested in the general case, but let us start with a smaller example. Suppose that cars arrive to a street with intensity $\lambda$ per minute. We would like to know the probability that at least two cars have arrived on the street during any five minute interval in the next hour. How can we find this? My initial thought was to use complementary event: 1 - the probability that at most one car is on the street in any five minute period during the next hour. Hence my reasoning was something like $1 - \int_0^{55}\mathbb{P}(N(s + 5) - N(s) \leq 1)ds - \int_{55}^{60}\mathbb{P}(N(60) - N(55 + s) \leq 1)ds$ . But I quickly realized that finding this probability might not be that easy, since the intervals we are considering overlap, namely $N(5)$ and $N(5 + s)$ overlap except for the infinitesimal point $s$ . So then, is the correct way to integrate just $\mathbb{P}(N(s) \leq 1$ over the region? Moreover, I think that my line of reasoning is missing something critical, since I do not see a reason, why the summation would not end up being negative.","I am interested in the general case, but let us start with a smaller example. Suppose that cars arrive to a street with intensity per minute. We would like to know the probability that at least two cars have arrived on the street during any five minute interval in the next hour. How can we find this? My initial thought was to use complementary event: 1 - the probability that at most one car is on the street in any five minute period during the next hour. Hence my reasoning was something like . But I quickly realized that finding this probability might not be that easy, since the intervals we are considering overlap, namely and overlap except for the infinitesimal point . So then, is the correct way to integrate just over the region? Moreover, I think that my line of reasoning is missing something critical, since I do not see a reason, why the summation would not end up being negative.",\lambda 1 - \int_0^{55}\mathbb{P}(N(s + 5) - N(s) \leq 1)ds - \int_{55}^{60}\mathbb{P}(N(60) - N(55 + s) \leq 1)ds N(5) N(5 + s) s \mathbb{P}(N(s) \leq 1,"['probability', 'probability-distributions', 'conditional-probability', 'poisson-process']"
