,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Given $f \in L^2(\mathbb{R})$, exists dual function where $f \in W^{1, 2}(\mathbb{R})$ iff $\int_\mathbb{R} |\xi|^2 |\hat{f}(\xi)|^2\,d\xi < +\infty$?","Given , exists dual function where  iff ?","f \in L^2(\mathbb{R}) f \in W^{1, 2}(\mathbb{R}) \int_\mathbb{R} |\xi|^2 |\hat{f}(\xi)|^2\,d\xi < +\infty","Let$$W^{1, 2}(\mathbb{R}) := \left\{ (f, f') \in L^2(\mathbb{R}) \times L^2(\mathbb{R}): f \text{ has a continuous representative and for all }x,\,y \in \mathbb{R},\text{ }f(x) - f(y) = \int_y^x f'(z)\,dz\right\}.$$If $(f, f') \in W^{1, 2}$, then for all $x$, $y \in \mathbb{R}$, we have$$|f(x) - f(y)| \le  \|f'\|_{L^2} |x - y|^{1/2}.$$(This follows directly from Cauchy-Schwarz applied to the product of $f′$ and the function that is constant and equal to $1$.) Question. Given $f \in L^2(\mathbb{R})$, is there an $f' \in L^2(\mathbb{R})$ so that $(f, f') \in W^{1, 2}(\mathbb{R})$ if and only if$$\int_\mathbb{R} |\xi|^2 |\hat{f}(\xi)|^2\,d\xi < +\infty?$$","Let$$W^{1, 2}(\mathbb{R}) := \left\{ (f, f') \in L^2(\mathbb{R}) \times L^2(\mathbb{R}): f \text{ has a continuous representative and for all }x,\,y \in \mathbb{R},\text{ }f(x) - f(y) = \int_y^x f'(z)\,dz\right\}.$$If $(f, f') \in W^{1, 2}$, then for all $x$, $y \in \mathbb{R}$, we have$$|f(x) - f(y)| \le  \|f'\|_{L^2} |x - y|^{1/2}.$$(This follows directly from Cauchy-Schwarz applied to the product of $f′$ and the function that is constant and equal to $1$.) Question. Given $f \in L^2(\mathbb{R})$, is there an $f' \in L^2(\mathbb{R})$ so that $(f, f') \in W^{1, 2}(\mathbb{R})$ if and only if$$\int_\mathbb{R} |\xi|^2 |\hat{f}(\xi)|^2\,d\xi < +\infty?$$",,"['real-analysis', 'functional-analysis']"
1,Cauchy's integral formula with high tech methods,Cauchy's integral formula with high tech methods,,"Using Stokes theorem there is particularly nice way to prove Cauchys theorem. If $U$ is a domain in $\mathbb{C}$ with (piecewise) smooth boundary $\Gamma$, then for all differentiable functions $g: \bar U \rightarrow \mathbb{C}$ we have $$  \int_\Gamma g dz = \int_Ud(gdz)=\int_U \frac{\partial g}{\partial \bar z} d\bar z \wedge dz = 2i \int_U \frac{\partial g}{\partial \bar z} d\mathcal{L}^2 $$ (where $\mathcal{L}^2$ is the two dimensional Lebesgue measure on $\mathbb{C}$). Consequently, if $g$ is holomorphic, then the line integral over $\Gamma$ vanishes. I want to know if this reasoning also gives rise to Cauchy's integral formula. How do I want to do this? For simplicity we assume that $0 \in U$ and want to prove that $$  f(0) = \frac{1}{2\pi i} \int_\Gamma \frac{f(z)}{z} dz. $$ The function $z \mapsto \frac{1}{z}$ is locally integrable over $\mathbb{C}$ and  homogeneous of degree $-1$, hence it can be considered as a tempered distribution which is also homogeneous of degree $-1$. Since this distribution is holomorphic away from $0$, we conclude that $\frac{\partial}{\partial \bar z}\frac{1}{z}$ has its support in $\{0\}$ and is homogeneous of degree $-2$. Consequently it is a multiple of the Dirac distribution at $0$, which we denote by $\delta$. Either by a computation or in anticipation of Cauchy's formula we may assume that $$ \frac{\partial}{\partial \bar z}\frac{1}{z} = \pi \delta $$ To prove Cauchy's integral formula I want to perform the following computation: Let $f$ be holomorphic in a neighbourhood of $\bar U$, then (trusting our inner physicist) we see $$ \frac{1}{2\pi i} \int_\Gamma \frac{f(z)}{z} dz = \frac{1}{\pi} \int_U\frac{\partial }{\partial \bar z}\left(\frac{f(z)}{z}\right)  d\mathcal{L}^2 = \frac{1}{\pi} \int_U f(z) \frac{\partial}{\partial \bar z}\frac{1}{z} d\mathcal{L}^2 = \int_U f(z)  \delta d\mathcal{L}^2 = f(0) $$ Of course this is not rigorous, the main problem being that we are dealing with a tempered distribution, which we can only apply to Schwartz functions and not to holomorphic functions. My question is: Can we do this in a rigorous way, somehow using holomorphic functions as test functions? (In light of this question I read about hyperfunctions, which somehow seem to be related, but at a first glance the theory seemed to be quite extensive - too much to answer the question myself right now. So maybe if anyone is familiar with these concepts my question might be very easy to answer. Any ideas are welcome!)","Using Stokes theorem there is particularly nice way to prove Cauchys theorem. If $U$ is a domain in $\mathbb{C}$ with (piecewise) smooth boundary $\Gamma$, then for all differentiable functions $g: \bar U \rightarrow \mathbb{C}$ we have $$  \int_\Gamma g dz = \int_Ud(gdz)=\int_U \frac{\partial g}{\partial \bar z} d\bar z \wedge dz = 2i \int_U \frac{\partial g}{\partial \bar z} d\mathcal{L}^2 $$ (where $\mathcal{L}^2$ is the two dimensional Lebesgue measure on $\mathbb{C}$). Consequently, if $g$ is holomorphic, then the line integral over $\Gamma$ vanishes. I want to know if this reasoning also gives rise to Cauchy's integral formula. How do I want to do this? For simplicity we assume that $0 \in U$ and want to prove that $$  f(0) = \frac{1}{2\pi i} \int_\Gamma \frac{f(z)}{z} dz. $$ The function $z \mapsto \frac{1}{z}$ is locally integrable over $\mathbb{C}$ and  homogeneous of degree $-1$, hence it can be considered as a tempered distribution which is also homogeneous of degree $-1$. Since this distribution is holomorphic away from $0$, we conclude that $\frac{\partial}{\partial \bar z}\frac{1}{z}$ has its support in $\{0\}$ and is homogeneous of degree $-2$. Consequently it is a multiple of the Dirac distribution at $0$, which we denote by $\delta$. Either by a computation or in anticipation of Cauchy's formula we may assume that $$ \frac{\partial}{\partial \bar z}\frac{1}{z} = \pi \delta $$ To prove Cauchy's integral formula I want to perform the following computation: Let $f$ be holomorphic in a neighbourhood of $\bar U$, then (trusting our inner physicist) we see $$ \frac{1}{2\pi i} \int_\Gamma \frac{f(z)}{z} dz = \frac{1}{\pi} \int_U\frac{\partial }{\partial \bar z}\left(\frac{f(z)}{z}\right)  d\mathcal{L}^2 = \frac{1}{\pi} \int_U f(z) \frac{\partial}{\partial \bar z}\frac{1}{z} d\mathcal{L}^2 = \int_U f(z)  \delta d\mathcal{L}^2 = f(0) $$ Of course this is not rigorous, the main problem being that we are dealing with a tempered distribution, which we can only apply to Schwartz functions and not to holomorphic functions. My question is: Can we do this in a rigorous way, somehow using holomorphic functions as test functions? (In light of this question I read about hyperfunctions, which somehow seem to be related, but at a first glance the theory seemed to be quite extensive - too much to answer the question myself right now. So maybe if anyone is familiar with these concepts my question might be very easy to answer. Any ideas are welcome!)",,"['real-analysis', 'complex-analysis', 'functional-analysis']"
2,Generalization of trace and associated determinant,Generalization of trace and associated determinant,,"The standard relation between the trace and the determinant of matrices is presented in the MO-Q "" Cycling through the zeta garden "" where the log and exp functions allow one to jump between additive and multiplicative operations to relate the det and trace. The relations are easiest to understand with diagonalized matrices, i.e., in an eigenvector rep. The determinant and trace for a Fredholm kernel are defined analogously with the kernel of the Fredholm integral as the analog of a matrix and integration over a continuous variable as the analog of discrete matrix multiplications. Both the matrix and Fredholm operators have associated zeta functions, and the identities among the symmetric elementary, complete, and power polynomials, associated with the cycle index polynomials for the symmetric groups, certainly encompass these relations. What are some other generalizations of the trace and determinant (and their reciprocal characterizations)? (I'm particularly interested to learn if there are analogs in quandle algebra.) (Posted earlier on MO . A comment, but no other responses.)","The standard relation between the trace and the determinant of matrices is presented in the MO-Q "" Cycling through the zeta garden "" where the log and exp functions allow one to jump between additive and multiplicative operations to relate the det and trace. The relations are easiest to understand with diagonalized matrices, i.e., in an eigenvector rep. The determinant and trace for a Fredholm kernel are defined analogously with the kernel of the Fredholm integral as the analog of a matrix and integration over a continuous variable as the analog of discrete matrix multiplications. Both the matrix and Fredholm operators have associated zeta functions, and the identities among the symmetric elementary, complete, and power polynomials, associated with the cycle index polynomials for the symmetric groups, certainly encompass these relations. What are some other generalizations of the trace and determinant (and their reciprocal characterizations)? (I'm particularly interested to learn if there are analogs in quandle algebra.) (Posted earlier on MO . A comment, but no other responses.)",,"['linear-algebra', 'functional-analysis', 'operator-theory', 'special-functions']"
3,Weak convergence counter-example,Weak convergence counter-example,,"Given probability measures $\mu,\mu_n: \mathcal{B}(X)\to R$. Construct an example such that $$\langle f,\mu_n\rangle \rightarrow \langle f,\mu\rangle$$ for all convex function $f:X\to R$ but $\mu_n$ does not converge weakly to $\mu$. This question is from a problem in a Partially Observed Markov Decision Process. In there we can guarantee that starting from any initial prior $\pi$, for all cost function the ACOE has a bounded solution, which implies that $E[v(\pi_n)\mid\pi_0=\pi] \rightarrow C$. But the expected cost function $v(\pi)$ can only be a certain convex function of $\pi$ even if we allow all kind of cost function. So I wonder whether or not there's a counter-example saying that convex test function $f$ is not enough for weak convergence. The POMDP average cost problem is from this paper: http://epubs.siam.org/doi/abs/10.1137/0318028","Given probability measures $\mu,\mu_n: \mathcal{B}(X)\to R$. Construct an example such that $$\langle f,\mu_n\rangle \rightarrow \langle f,\mu\rangle$$ for all convex function $f:X\to R$ but $\mu_n$ does not converge weakly to $\mu$. This question is from a problem in a Partially Observed Markov Decision Process. In there we can guarantee that starting from any initial prior $\pi$, for all cost function the ACOE has a bounded solution, which implies that $E[v(\pi_n)\mid\pi_0=\pi] \rightarrow C$. But the expected cost function $v(\pi)$ can only be a certain convex function of $\pi$ even if we allow all kind of cost function. So I wonder whether or not there's a counter-example saying that convex test function $f$ is not enough for weak convergence. The POMDP average cost problem is from this paper: http://epubs.siam.org/doi/abs/10.1137/0318028",,"['functional-analysis', 'probability-theory', 'weak-convergence']"
4,$L_p$ norm of linear function,norm of linear function,L_p,"Is there a nice formula for the $L_p$ norm of $f(\vec{x}) = \sum_{i=1}^n x_i$ on the domain $[-1,1]^n$, where $\vec{x} = (x_1, \dots, x_n)$? i.e. a nice expression for $\left(\int_{\vec{x} \in [-1,1]^n}  \left|\sum_{i=1}^n x_i\right|^p dx_1 \dots dx_n\right)^\frac{1}{p}$","Is there a nice formula for the $L_p$ norm of $f(\vec{x}) = \sum_{i=1}^n x_i$ on the domain $[-1,1]^n$, where $\vec{x} = (x_1, \dots, x_n)$? i.e. a nice expression for $\left(\int_{\vec{x} \in [-1,1]^n}  \left|\sum_{i=1}^n x_i\right|^p dx_1 \dots dx_n\right)^\frac{1}{p}$",,"['calculus', 'functional-analysis', 'analysis', 'multivariable-calculus']"
5,Convergent nets and closed sets in a proof of Schechter's book,Convergent nets and closed sets in a proof of Schechter's book,,"In my current obsession to learn equivalences of the Ultrafilter Lemma, I found the Handbook of Analysis and its Foundations, by Eric Schechter - by the way, a marvelous book in my opinion. In this book (section 28.29), the proof that Banach-Alaoglu Theorem implies (in ZF) the Ultrafilter Lemma goes like this: we fix a set $\Omega$ and a proper filter $\mathcal{F}$ on $\Omega$; we set $X=\{f\colon \Omega\to\mathbb{R}|f$ is bounded$\}$ equipped with the sup norm; by Banach-Alaoglu, the closed unit ball on $X^*$ is $w^*$-compact (compact in the weak$^*$ topology), call it $V$; the map $\varphi\colon \Omega\to V$ defined as $\varphi_\omega(x)=x(\omega)$ for $\omega\in \Omega$ and $x\in X$ is an injection, so we may suppose that $\Omega\subset V$; the set $\mathcal{K}=\{w^*\text{-cl}(F): F\in\mathcal{F}\}$ is a family of $w^*$-closed subsets of $V$ with the finite intersection property, hence there exists $v\in \bigcap\mathcal{K}$; we define $\mu\colon \wp(\Omega)\to\mathbb{R}$ by setting $\mu(S)=v(1_S)$, where $1_S\colon \Omega\to \{0,1\}$ is the characteristic function of $S$; in order to see that $\mathfrak{u}=\{G\subset\Omega:\mu(G)=1\}$ is an ultrafilter that contains $\mathcal{F}$, the author uses the following fact for any fixed $F\in\mathcal{F}$, since $v\in w^*\text{-cl}(F)$, there is some net $(\omega(\alpha):\alpha\in A)$ in $F$ such that $\varphi_{\omega(\alpha)}\stackrel{w^*}{\longrightarrow}v$. My problem concerns this last step. I know that in any topological space $Y$, $y\in Y$ and $A\subset Y$, $(\dagger)$ $\quad$ $y\in\overline{A}$ if and only if there exists a net of elements in $A$ converging to $y$. However, the only proof I know about this fact uses the Axiom of Choice. Finally, my questions : There is a way to prove $(\dagger)$ without the Axiom of Choice? If not, what am I missing in order to prove the 8th step? Thank you. I am aware of this post , but my question concerns specifically about the proof in Schechter's book.","In my current obsession to learn equivalences of the Ultrafilter Lemma, I found the Handbook of Analysis and its Foundations, by Eric Schechter - by the way, a marvelous book in my opinion. In this book (section 28.29), the proof that Banach-Alaoglu Theorem implies (in ZF) the Ultrafilter Lemma goes like this: we fix a set $\Omega$ and a proper filter $\mathcal{F}$ on $\Omega$; we set $X=\{f\colon \Omega\to\mathbb{R}|f$ is bounded$\}$ equipped with the sup norm; by Banach-Alaoglu, the closed unit ball on $X^*$ is $w^*$-compact (compact in the weak$^*$ topology), call it $V$; the map $\varphi\colon \Omega\to V$ defined as $\varphi_\omega(x)=x(\omega)$ for $\omega\in \Omega$ and $x\in X$ is an injection, so we may suppose that $\Omega\subset V$; the set $\mathcal{K}=\{w^*\text{-cl}(F): F\in\mathcal{F}\}$ is a family of $w^*$-closed subsets of $V$ with the finite intersection property, hence there exists $v\in \bigcap\mathcal{K}$; we define $\mu\colon \wp(\Omega)\to\mathbb{R}$ by setting $\mu(S)=v(1_S)$, where $1_S\colon \Omega\to \{0,1\}$ is the characteristic function of $S$; in order to see that $\mathfrak{u}=\{G\subset\Omega:\mu(G)=1\}$ is an ultrafilter that contains $\mathcal{F}$, the author uses the following fact for any fixed $F\in\mathcal{F}$, since $v\in w^*\text{-cl}(F)$, there is some net $(\omega(\alpha):\alpha\in A)$ in $F$ such that $\varphi_{\omega(\alpha)}\stackrel{w^*}{\longrightarrow}v$. My problem concerns this last step. I know that in any topological space $Y$, $y\in Y$ and $A\subset Y$, $(\dagger)$ $\quad$ $y\in\overline{A}$ if and only if there exists a net of elements in $A$ converging to $y$. However, the only proof I know about this fact uses the Axiom of Choice. Finally, my questions : There is a way to prove $(\dagger)$ without the Axiom of Choice? If not, what am I missing in order to prove the 8th step? Thank you. I am aware of this post , but my question concerns specifically about the proof in Schechter's book.",,"['general-topology', 'functional-analysis', 'axiom-of-choice', 'nets']"
6,Associated C*-Categories and the reduced crossed product,Associated C*-Categories and the reduced crossed product,,"Let $G$ be a discrete group and $\mathcal{G}$ a groupoid, that is a small category in which every arrow is an isomorphism. Wolfgang Lück explains how we can construct a $C^*$-category from $\mathcal{G}$ this way . This construction is very useful because if we consider a discrete group $G$ as a groupid with one element $e$ and morphisms  $Mor_G(e,e)=G$, then $Mor_{C_r(G)}(e,e)$ agrees with the reduced group $C^*$ -algebra $C_r(G)$, as the notation implies. Now, I want to find a way to extend this principle to the reduced crossed product: Let $A$ be a $G$-$C^*$-algebra. I want to find a to construct a simililar functor $F$ as described by Lück, only that if I consider $G$ or a subgroup $H$ of $G$ to be a groupoid, I actually have $Mor_{F(H)}(e,e)$ agree with the reduced cross product of $H$ and $A$. My only idea so far is basically to exchange $\mathbb{C}$ for $A$, but that doesn't seem to work. Thank you","Let $G$ be a discrete group and $\mathcal{G}$ a groupoid, that is a small category in which every arrow is an isomorphism. Wolfgang Lück explains how we can construct a $C^*$-category from $\mathcal{G}$ this way . This construction is very useful because if we consider a discrete group $G$ as a groupid with one element $e$ and morphisms  $Mor_G(e,e)=G$, then $Mor_{C_r(G)}(e,e)$ agrees with the reduced group $C^*$ -algebra $C_r(G)$, as the notation implies. Now, I want to find a way to extend this principle to the reduced crossed product: Let $A$ be a $G$-$C^*$-algebra. I want to find a to construct a simililar functor $F$ as described by Lück, only that if I consider $G$ or a subgroup $H$ of $G$ to be a groupoid, I actually have $Mor_{F(H)}(e,e)$ agree with the reduced cross product of $H$ and $A$. My only idea so far is basically to exchange $\mathbb{C}$ for $A$, but that doesn't seem to work. Thank you",,"['functional-analysis', 'category-theory', 'operator-algebras', 'c-star-algebras']"
7,Proof that convergence almost everywhere is not topological.,Proof that convergence almost everywhere is not topological.,,"I have written the following proof that convergence almost everywhere is not topological, and I would like it checked if you guys please: Assume that $\tau$ is the topology of almost everywhere convergence. Let $f_n$ be a sequence of measurable functions dominated by an integrable function. Lemma: If $f_n\to f$ in $\tau$ then $f_n\to f$ in $L^1$. Theorem: $f_n\to f$ in $L^1$ implies $f_n\to f$ in $\tau$ Proof: $f_n\to f$ in $L^1$  implies that every subsequence of $f_n$ converges to $f$ in $L^1$. But then for every subsequence of $f_n$, we have a subsequence (of the subsequence) that converges almost everywhere to $f$. Thus, for every subsequence of $\{f_n\}$, there is a subsequence of that subsequence that converges to $f$ in $\tau$. But $\tau$ is a topology and we can thus conclude that $f_n$ converges to $f$ in $\tau$. End Of Proof. Therefore, we have proved that convergence in $L^1$ for a set of measurable dominated functions implies almost everywhere convergence. However, the typewriter sequence satisfies the hypothesis without converging almost everywhere. Thus, we have proved a wrong theorem and thus our assumption that $\tau$ exists was wrong. Thus, convergence almost everywhere is not topological.","I have written the following proof that convergence almost everywhere is not topological, and I would like it checked if you guys please: Assume that $\tau$ is the topology of almost everywhere convergence. Let $f_n$ be a sequence of measurable functions dominated by an integrable function. Lemma: If $f_n\to f$ in $\tau$ then $f_n\to f$ in $L^1$. Theorem: $f_n\to f$ in $L^1$ implies $f_n\to f$ in $\tau$ Proof: $f_n\to f$ in $L^1$  implies that every subsequence of $f_n$ converges to $f$ in $L^1$. But then for every subsequence of $f_n$, we have a subsequence (of the subsequence) that converges almost everywhere to $f$. Thus, for every subsequence of $\{f_n\}$, there is a subsequence of that subsequence that converges to $f$ in $\tau$. But $\tau$ is a topology and we can thus conclude that $f_n$ converges to $f$ in $\tau$. End Of Proof. Therefore, we have proved that convergence in $L^1$ for a set of measurable dominated functions implies almost everywhere convergence. However, the typewriter sequence satisfies the hypothesis without converging almost everywhere. Thus, we have proved a wrong theorem and thus our assumption that $\tau$ exists was wrong. Thus, convergence almost everywhere is not topological.",,"['general-topology', 'functional-analysis', 'measure-theory']"
8,Dimension: Hilbert vs. Hamel,Dimension: Hilbert vs. Hamel,,"Given two Hilbert spaces. Clearly, equal Hilbert dimension implies equal Hamel dimension. (Similarly, equal Hamel dimension implies equal cardinality.) But what about the converse? (Sadly, I couldn't find something on MSE.)","Given two Hilbert spaces. Clearly, equal Hilbert dimension implies equal Hamel dimension. (Similarly, equal Hamel dimension implies equal cardinality.) But what about the converse? (Sadly, I couldn't find something on MSE.)",,"['functional-analysis', 'hilbert-spaces', 'hamel-basis']"
9,Basic Idea Behind Riesz-Markov-Kakutani Representation Theorem,Basic Idea Behind Riesz-Markov-Kakutani Representation Theorem,,"Sorry if this seems like an overly elementary question but I've been rolling this around in my mind all day. Am I correct that the basic idea behind the Riesz-Markov-Kakutani represention theorem that I can take any (positive) linear functional $J:C_{c}(X) \to \mathbb{R}_{+}$ where $X$ is a locally compact Hausdorff space and re-write it/represent it as an integral such that (for some compact set $E \subset X$) as $$ J[f]=\int_{E}f \, d\lambda $$ where $\lambda$ is a (unique) Borel measure? One example I am very tempted to conjecture right off the bat is the ""evaluation-at-a-point functional"" which for some $a \in E$ is given by $$J_{a}[f]=\int_{E} f \, d\delta_{a}=f(a) $$ where $\delta_{a}$ is the Dirac measure. Obviously the Dirac measure is locally finite and both inner and outer regular so it is a Borel measure. So am I correct in my thinking here? I also assume that there is some unique Borel measure $\nu$ that one could ""represent"" for example the total variation functional $V_{a}^{b}: BV([a,b]) \to \mathbb{R}_{+}$ as  $$ V^{b}_{a}[f]=\int_{[a,b]} f \, d\nu $$ and that this would hold for any positive linear functional defined on the space of compactly supported continuous functions? Also, I read somewhere that measures are special cases of distributions and I've been trying to wrap my head around that idea and it seems to me that this theorem is pointing me in that direction. Can someone help me connect the dots here? I feel like I'm so close to seeing the big picture of how all of this fits together but I'm missing that key insight. Edit: Another flash of insight I just had: for $\varphi \in \mathcal{D}(\mathbb{R})$ where $\mathcal{D}(\mathbb{R})$ is the space of test functions and $f:\mathbb{R} \to \mathbb{R}$ say we have a distribution acting on a test function $\varphi$ given by $$ \langle T_{f},\varphi\rangle =\int_{\mathbb{R}} f(x) \varphi(x) \, d\mu(x) $$ and for a Borel measure $\mu$ we have a distribution acting on $\varphi$ given by $$ \langle T_{\mu},\varphi \rangle=\int_{\mathbb{R}} \varphi(x) \, d\mu(x) $$ so perhaps $\varphi$ is a ""smoothed out"" version of the indicator function?","Sorry if this seems like an overly elementary question but I've been rolling this around in my mind all day. Am I correct that the basic idea behind the Riesz-Markov-Kakutani represention theorem that I can take any (positive) linear functional $J:C_{c}(X) \to \mathbb{R}_{+}$ where $X$ is a locally compact Hausdorff space and re-write it/represent it as an integral such that (for some compact set $E \subset X$) as $$ J[f]=\int_{E}f \, d\lambda $$ where $\lambda$ is a (unique) Borel measure? One example I am very tempted to conjecture right off the bat is the ""evaluation-at-a-point functional"" which for some $a \in E$ is given by $$J_{a}[f]=\int_{E} f \, d\delta_{a}=f(a) $$ where $\delta_{a}$ is the Dirac measure. Obviously the Dirac measure is locally finite and both inner and outer regular so it is a Borel measure. So am I correct in my thinking here? I also assume that there is some unique Borel measure $\nu$ that one could ""represent"" for example the total variation functional $V_{a}^{b}: BV([a,b]) \to \mathbb{R}_{+}$ as  $$ V^{b}_{a}[f]=\int_{[a,b]} f \, d\nu $$ and that this would hold for any positive linear functional defined on the space of compactly supported continuous functions? Also, I read somewhere that measures are special cases of distributions and I've been trying to wrap my head around that idea and it seems to me that this theorem is pointing me in that direction. Can someone help me connect the dots here? I feel like I'm so close to seeing the big picture of how all of this fits together but I'm missing that key insight. Edit: Another flash of insight I just had: for $\varphi \in \mathcal{D}(\mathbb{R})$ where $\mathcal{D}(\mathbb{R})$ is the space of test functions and $f:\mathbb{R} \to \mathbb{R}$ say we have a distribution acting on a test function $\varphi$ given by $$ \langle T_{f},\varphi\rangle =\int_{\mathbb{R}} f(x) \varphi(x) \, d\mu(x) $$ and for a Borel measure $\mu$ we have a distribution acting on $\varphi$ given by $$ \langle T_{\mu},\varphi \rangle=\int_{\mathbb{R}} \varphi(x) \, d\mu(x) $$ so perhaps $\varphi$ is a ""smoothed out"" version of the indicator function?",,"['functional-analysis', 'measure-theory', 'lebesgue-integral', 'distribution-theory', 'riesz-representation-theorem']"
10,How to integrate by parts with two integrals?,How to integrate by parts with two integrals?,,"I have a problem I have been trying to integrate using by parts, but I am a bit stuck. We have that $x \geq 0$ and assume $f$ is a smooth function (so we have no issues at $0$) and compact in some interval $f \in C^{[a,b]}(R_{+})$, with $0<a<b<\infty$. The equation is the following: \begin{align} \|(Bf(x))\|_{L^2_{(R_+)}} & =\left(\int_0^\infty \left\lvert\frac{1}{x} \ \int_0^x f(t) \, dt\right\rvert^2 \ dx\right)^{1/2} \\ &\leq\left(\int_0^\infty \left\lvert\frac{1}{x}\right\rvert^{2} \ \left\lvert \int_0^x f(t) \, dt\right\rvert^2 \ dx\right)^{1/2} \\ &=\left(\int_0^\infty \frac{d}{dx} \left\lvert\dfrac{-1}{x}\right\rvert \ \left\lvert \int_0^x f(t) \ dt\right\rvert^2 \ dx\right)^{1/2} \\ &\leq \left(\int_0^\infty \frac{d}{dx}\left\lvert\dfrac{-1}{x}\right\rvert \ \int_0^x \left\lvert f(t) \right\rvert^{2} \ dt \ dx\right)^{1/2} \end{align} Now to solve this I have tried setting $dv=\dfrac{d}{dx} \dfrac{-1}{x} dt$ and $v=\dfrac{d}{dx}\dfrac{-1}{x}$ (as $x \geq 0$ we can drop the absolute values), with $u=|f(t)|^{2}$ and $du=2\lvert f(t) \rvert dt$. My other attempt was setting my $dv=\dfrac{d}{dx}\dfrac{-1}{x} dx$ and $v=\dfrac{-1}{x}$ (The dx's cancel when we integrate dv/dx) and setting $u=\int_0^x \lvert f(t) \rvert^2 dt$ and $du=2f(x)\int_0^x \lvert f(t) \rvert \ dt \ dx$. This was to try and solve the whole integral at once. This was the more promising of the two but I can't get an answer that doesn't seem to diverge/become unbounded. Can someone please tell me where I am going wrong? What should I be setting my $u, du, v$ & $dv$ parts as? The end result is to prove this is bounded, but with Holder's inequality and density arguments this part should be easy. This intermediate step I am just stuck at. Thank you for any help given!","I have a problem I have been trying to integrate using by parts, but I am a bit stuck. We have that $x \geq 0$ and assume $f$ is a smooth function (so we have no issues at $0$) and compact in some interval $f \in C^{[a,b]}(R_{+})$, with $0<a<b<\infty$. The equation is the following: \begin{align} \|(Bf(x))\|_{L^2_{(R_+)}} & =\left(\int_0^\infty \left\lvert\frac{1}{x} \ \int_0^x f(t) \, dt\right\rvert^2 \ dx\right)^{1/2} \\ &\leq\left(\int_0^\infty \left\lvert\frac{1}{x}\right\rvert^{2} \ \left\lvert \int_0^x f(t) \, dt\right\rvert^2 \ dx\right)^{1/2} \\ &=\left(\int_0^\infty \frac{d}{dx} \left\lvert\dfrac{-1}{x}\right\rvert \ \left\lvert \int_0^x f(t) \ dt\right\rvert^2 \ dx\right)^{1/2} \\ &\leq \left(\int_0^\infty \frac{d}{dx}\left\lvert\dfrac{-1}{x}\right\rvert \ \int_0^x \left\lvert f(t) \right\rvert^{2} \ dt \ dx\right)^{1/2} \end{align} Now to solve this I have tried setting $dv=\dfrac{d}{dx} \dfrac{-1}{x} dt$ and $v=\dfrac{d}{dx}\dfrac{-1}{x}$ (as $x \geq 0$ we can drop the absolute values), with $u=|f(t)|^{2}$ and $du=2\lvert f(t) \rvert dt$. My other attempt was setting my $dv=\dfrac{d}{dx}\dfrac{-1}{x} dx$ and $v=\dfrac{-1}{x}$ (The dx's cancel when we integrate dv/dx) and setting $u=\int_0^x \lvert f(t) \rvert^2 dt$ and $du=2f(x)\int_0^x \lvert f(t) \rvert \ dt \ dx$. This was to try and solve the whole integral at once. This was the more promising of the two but I can't get an answer that doesn't seem to diverge/become unbounded. Can someone please tell me where I am going wrong? What should I be setting my $u, du, v$ & $dv$ parts as? The end result is to prove this is bounded, but with Holder's inequality and density arguments this part should be easy. This intermediate step I am just stuck at. Thank you for any help given!",,"['integration', 'functional-analysis', 'analysis', 'lp-spaces', 'integration-by-parts']"
11,How to integrate the Heat Kernel?,How to integrate the Heat Kernel?,,"Let $P(x, y, t) := (4 \pi t)^{-v/2}\exp\left(\frac{-|x-y|^2}{4t}\right)$, with $x, y \in \mathbb{R}^v$ and $t \in \mathbb{R}$, denote the Heat Kernel. QUESTION: How to show that: $$Q(x, y, t) := \int^t_0 P(x, y, s)\,\mathrm ds$$ behaves like: $|x - y|^\gamma \exp\left(\frac{-|x-y|^2}{4t}\right)$ in the region: $$A :=\{(x, y) \mid |x-y| \leq 4 \sqrt{t}\}$$ for some suitably chosen $\gamma$?","Let $P(x, y, t) := (4 \pi t)^{-v/2}\exp\left(\frac{-|x-y|^2}{4t}\right)$, with $x, y \in \mathbb{R}^v$ and $t \in \mathbb{R}$, denote the Heat Kernel. QUESTION: How to show that: $$Q(x, y, t) := \int^t_0 P(x, y, s)\,\mathrm ds$$ behaves like: $|x - y|^\gamma \exp\left(\frac{-|x-y|^2}{4t}\right)$ in the region: $$A :=\{(x, y) \mid |x-y| \leq 4 \sqrt{t}\}$$ for some suitably chosen $\gamma$?",,"['real-analysis', 'integration', 'functional-analysis', 'partial-differential-equations', 'operator-theory']"
12,"Spectrum of $(Mf)(t):=tf(t)$ for $f$ is a complex-valued continuous function on $[0,1]$.",Spectrum of  for  is a complex-valued continuous function on .,"(Mf)(t):=tf(t) f [0,1]","Let $X:=C([0,1],\mathbb{C})$ be equipped with $\Vert f\Vert_{\infty}:=sup_{t\in [0,1]}\vert f(t)\vert$ and define $M:X\to X$ by $(Mf)(t):=tf(t)$. Prove that the spectrum of $M$ is $\sigma(M)=[0,1]$ I solved this exercise but my solution is completely different than the one we got in the class. Is mine still correct? My solution: Assume there is some $\tilde{\lambda}\in [0,1]$ such that $\tilde{\lambda}\mathbb{1}-M$ is bijective. Then since $X$ is a Banach space by the inverse operator theorem $(\tilde{\lambda}\mathbb{1}-M)^{-1}$ is bounded. But this is not possible since $(\tilde{\lambda}\mathbb{1}-M)f(t)=(\tilde{\lambda}-t)f(t)$ and so its inverse diverges at $t=\tilde{\lambda}$. Solution from the class: Assume $\lambda\in \mathbb{C}\backslash [0,1]$ and define $R_{\lambda}f(t):=\frac{1}{\lambda-t}f(t)$. By assumption $inf_{t\in[0,1]}\vert \lambda - t\vert >0$. Hence $C:=\sup_{t\in[0,1]}\frac{1}{\lambda-t}<\infty$ is bounded. So $\Vert R_{\lambda}f\Vert_{\infty}=sup_t \vert \frac{1}{\lambda-t}f(t)\vert\leq C \Vert f\Vert_{\infty}$ $\Longrightarrow$ $\Vert R_{\lambda}\Vert=\sup_f \frac{\Vert R_{\lambda}f\Vert_{\infty}}{\Vert f\Vert_{\infty}}\leq C$ hence $R_{\lambda}$ is bounded. Obviously $(\lambda \mathbb{1}-M)R_{\lambda}=R_{\lambda}(\lambda \mathbb{1}-M)=\mathbb{1}$ so $\forall \lambda \in \mathbb{C}\backslash [0,1]$ $\lambda\mathbb{1}-M$ has an inverse.","Let $X:=C([0,1],\mathbb{C})$ be equipped with $\Vert f\Vert_{\infty}:=sup_{t\in [0,1]}\vert f(t)\vert$ and define $M:X\to X$ by $(Mf)(t):=tf(t)$. Prove that the spectrum of $M$ is $\sigma(M)=[0,1]$ I solved this exercise but my solution is completely different than the one we got in the class. Is mine still correct? My solution: Assume there is some $\tilde{\lambda}\in [0,1]$ such that $\tilde{\lambda}\mathbb{1}-M$ is bijective. Then since $X$ is a Banach space by the inverse operator theorem $(\tilde{\lambda}\mathbb{1}-M)^{-1}$ is bounded. But this is not possible since $(\tilde{\lambda}\mathbb{1}-M)f(t)=(\tilde{\lambda}-t)f(t)$ and so its inverse diverges at $t=\tilde{\lambda}$. Solution from the class: Assume $\lambda\in \mathbb{C}\backslash [0,1]$ and define $R_{\lambda}f(t):=\frac{1}{\lambda-t}f(t)$. By assumption $inf_{t\in[0,1]}\vert \lambda - t\vert >0$. Hence $C:=\sup_{t\in[0,1]}\frac{1}{\lambda-t}<\infty$ is bounded. So $\Vert R_{\lambda}f\Vert_{\infty}=sup_t \vert \frac{1}{\lambda-t}f(t)\vert\leq C \Vert f\Vert_{\infty}$ $\Longrightarrow$ $\Vert R_{\lambda}\Vert=\sup_f \frac{\Vert R_{\lambda}f\Vert_{\infty}}{\Vert f\Vert_{\infty}}\leq C$ hence $R_{\lambda}$ is bounded. Obviously $(\lambda \mathbb{1}-M)R_{\lambda}=R_{\lambda}(\lambda \mathbb{1}-M)=\mathbb{1}$ so $\forall \lambda \in \mathbb{C}\backslash [0,1]$ $\lambda\mathbb{1}-M$ has an inverse.",,"['functional-analysis', 'spectral-theory']"
13,A necessary and sufficient condition such that product of partial isometries is a partial isometry,A necessary and sufficient condition such that product of partial isometries is a partial isometry,,"I'm reading the paper P. Halmos, L. Wallen, Powers of Partial Isometries, Indiana Univ. Math. J. 19 No. 8 (1970), 657–663 ( http://www.iumj.indiana.edu/docs/19054/19054.asp ). And I got stuck on the proof of Lemma 2, which states that $$\text{If } U_1 \text{and } U_2 \text{ are partial isometries, then a necessary and sufficient condition that } \\U_1U_2 \text{ be a partial isometry is that } E_1 \text{ and } F_2 \text{ commute, where } E_1={U_1}^*U_1 \text{and } F_2=U_2{U_2}^*.$$ Proof Put $U = U_1U_2$. Assume first that $E_1$ and $F_2$ commute. Then $$UU^*U = U_1U_2({U_2}^*{U_1}^*)U_1U_2 = U_1F_2E_1U_2 = U_1E_1F_2U_2 = U_1U_2 = U.$$ Since the equation $UU^*U=U$ is characteristic if partial isometries, this proves that the condition is sufficient. To prove necessity, assume that $UU^*U=U$. Then, as above, $U_1F_2E_1U_2=U_1U_2$, and therefore $$E_1F_2E_1F_2=({U_1}^*U_1F_2)(E_1U_2{U_2}^*)=({U_1}^*U_1)(U_2{U_2}^*)=E_1F_2,$$ so that $E_1F_2$ is idempotent. Since $||E_1F_2|| \leq 1$, it follows that $E_1F_2$ is Hermitian, and hence that $E_1F_2$ commute. I can't understand why we can conclude that $E_1F_2$ is Hermitian given that it is idempotent and bounded.","I'm reading the paper P. Halmos, L. Wallen, Powers of Partial Isometries, Indiana Univ. Math. J. 19 No. 8 (1970), 657–663 ( http://www.iumj.indiana.edu/docs/19054/19054.asp ). And I got stuck on the proof of Lemma 2, which states that $$\text{If } U_1 \text{and } U_2 \text{ are partial isometries, then a necessary and sufficient condition that } \\U_1U_2 \text{ be a partial isometry is that } E_1 \text{ and } F_2 \text{ commute, where } E_1={U_1}^*U_1 \text{and } F_2=U_2{U_2}^*.$$ Proof Put $U = U_1U_2$. Assume first that $E_1$ and $F_2$ commute. Then $$UU^*U = U_1U_2({U_2}^*{U_1}^*)U_1U_2 = U_1F_2E_1U_2 = U_1E_1F_2U_2 = U_1U_2 = U.$$ Since the equation $UU^*U=U$ is characteristic if partial isometries, this proves that the condition is sufficient. To prove necessity, assume that $UU^*U=U$. Then, as above, $U_1F_2E_1U_2=U_1U_2$, and therefore $$E_1F_2E_1F_2=({U_1}^*U_1F_2)(E_1U_2{U_2}^*)=({U_1}^*U_1)(U_2{U_2}^*)=E_1F_2,$$ so that $E_1F_2$ is idempotent. Since $||E_1F_2|| \leq 1$, it follows that $E_1F_2$ is Hermitian, and hence that $E_1F_2$ commute. I can't understand why we can conclude that $E_1F_2$ is Hermitian given that it is idempotent and bounded.",,"['functional-analysis', 'operator-theory']"
14,Lower bound on gap between consecutive eigenvalues on $L_2(\mathbb{R}^3)$,Lower bound on gap between consecutive eigenvalues on,L_2(\mathbb{R}^3),"A similar version of this question was originally posted by me in the physics community , but it was suggested that I ask the mathematicians instead. So I have tried to strip off most of the physics jargon and brush up my functional analysis-fu. Consider the stationary Schrödinger equation on $L_2(\mathbb{R}^3)$: \begin{equation} -\nabla^2\psi(\vec r)+V(\vec r)\psi(\vec r) = E\psi(\vec r)\text. \end{equation} Here $V(\vec r)$ can be assumed to be a sufficiently well-behaved function that vanishes at infinity. Assume this operator has a discrete spectrum and denote the discrete eigenvalues as $E_{n,\tau}$, where $n$ is the principal quantum number and $\tau$ represents all the other quantum numbers, if any. For a given $V(\vec r)$, is it possible to derive a lower bound on $E_{n+1,\tau}-E_{n,\tau}$, i.e. on the energy gap between consecutive levels with the same additional quantum numbers? Physical intuition tells me that long-range potentials should allow smaller gaps (cf. the Coulomb potential $V(r)=1/r$, which yields $E_n\propto 1/n^2$, with the gap getting infinitely small as $n\to\infty$), but I haven't managed to express this quantitatively.","A similar version of this question was originally posted by me in the physics community , but it was suggested that I ask the mathematicians instead. So I have tried to strip off most of the physics jargon and brush up my functional analysis-fu. Consider the stationary Schrödinger equation on $L_2(\mathbb{R}^3)$: \begin{equation} -\nabla^2\psi(\vec r)+V(\vec r)\psi(\vec r) = E\psi(\vec r)\text. \end{equation} Here $V(\vec r)$ can be assumed to be a sufficiently well-behaved function that vanishes at infinity. Assume this operator has a discrete spectrum and denote the discrete eigenvalues as $E_{n,\tau}$, where $n$ is the principal quantum number and $\tau$ represents all the other quantum numbers, if any. For a given $V(\vec r)$, is it possible to derive a lower bound on $E_{n+1,\tau}-E_{n,\tau}$, i.e. on the energy gap between consecutive levels with the same additional quantum numbers? Physical intuition tells me that long-range potentials should allow smaller gaps (cf. the Coulomb potential $V(r)=1/r$, which yields $E_n\propto 1/n^2$, with the gap getting infinitely small as $n\to\infty$), but I haven't managed to express this quantitatively.",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory']"
15,"I don't see why $W^{1, 2}(\partial D)$ being compactly embedded in $L^2(\partial D)$ lets us show an operator is Fredholm of index zero.",I don't see why  being compactly embedded in  lets us show an operator is Fredholm of index zero.,"W^{1, 2}(\partial D) L^2(\partial D)","Let $D$ be a bounded Lipschitz domain. Let $A$ be the single layer potential which maps $L^2(\partial D)$ into $W^{1, 2}(\partial D)$ boundedly. $A$ is given by: $$ A_D[\phi] = \int_{\partial D}G(x-y)\phi(y) d\sigma(y), \quad x \in \mathbb{R}^3, $$ where $G$ is the fundamental solution of the Laplacian. Now as $W^{1, 2}(\partial D)$ is compactly embedded in $L^2(\partial D)$ we have that $A$ is Fredholm of index zero. I don't see how we can say this operator is Fredholm of index zero based on the given information? To show it is Fredholm of index zero we must show that $A$ is a bounded linear operator The range of $A$ is closed in $W^{1, 2}(\partial D)$. The subspaces $\ker(A)$ and $\text{coker}(A)$ are finite-dimensional. The dimensions of $\ker(A)$ and $\text{coker}(A)$ are the same. We have point 1. by the definition of $A$, but I don't see how the statement $W^{1, 2}(\partial D)$ is compactly embedded in $L^2(\partial D)$ gives us points 2. - 4? Just to mention I am unfamiliar with compact embedding but from reading up on definitions of it I don't see how it gives us points 2. - 4.? Edit : $A$ is actually a single layer potential but I left that out to simplify the question. My question comes from the proof of Theorem 2.13 in this book on page 29.","Let $D$ be a bounded Lipschitz domain. Let $A$ be the single layer potential which maps $L^2(\partial D)$ into $W^{1, 2}(\partial D)$ boundedly. $A$ is given by: $$ A_D[\phi] = \int_{\partial D}G(x-y)\phi(y) d\sigma(y), \quad x \in \mathbb{R}^3, $$ where $G$ is the fundamental solution of the Laplacian. Now as $W^{1, 2}(\partial D)$ is compactly embedded in $L^2(\partial D)$ we have that $A$ is Fredholm of index zero. I don't see how we can say this operator is Fredholm of index zero based on the given information? To show it is Fredholm of index zero we must show that $A$ is a bounded linear operator The range of $A$ is closed in $W^{1, 2}(\partial D)$. The subspaces $\ker(A)$ and $\text{coker}(A)$ are finite-dimensional. The dimensions of $\ker(A)$ and $\text{coker}(A)$ are the same. We have point 1. by the definition of $A$, but I don't see how the statement $W^{1, 2}(\partial D)$ is compactly embedded in $L^2(\partial D)$ gives us points 2. - 4? Just to mention I am unfamiliar with compact embedding but from reading up on definitions of it I don't see how it gives us points 2. - 4.? Edit : $A$ is actually a single layer potential but I left that out to simplify the question. My question comes from the proof of Theorem 2.13 in this book on page 29.",,"['functional-analysis', 'operator-theory', 'sobolev-spaces', 'compact-operators']"
16,Commutative Banach algebra and its Gelfand spectrum,Commutative Banach algebra and its Gelfand spectrum,,"Let $A$ be the set of all functions on $\mathbb{R}^2$ of the form $$ f(t,s):=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}}, $$ with the following norm: $$ \|f\|:=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|a_{mn}|}. $$ I want to show that $A$ is a commutative Banach algebra. And, I am curious whether it is possible to show that the Gelfand spectrum of $A$ can be identified with the two-dimensional torus, i.e. $\{(e^{it},e^{is})\colon t,s\in\mathbb{R}\}$. Firstly, it is easy to show that: $A$ is commutative, since for all $f,g\in A$:  $(fg)(t,s)=f(t,s)g(t,s)=g(t,s)f(t,s)=(gf)(t,s)$; $A$ is associative, since for all $f,g,h\in A$:  $((fg)h)(t,s)=(fg)(t,s)h(t,s)=g(t,s)f(t,s)h(t,s)=f(t,s)(gh)(t,s)=(f(gh))(t,s)$; $A$ is distributive, since for all $f,g,h\in A$: $(f(g+h))(t,s)=f(t,s)(g+h)(t,s)=f(t,s)(g(t,s)+h(t,s))=f(t,s)g(t,s)+f(t,s)h(t,s)=(fg)(x)+ (fh)(t,s)=(fg+fh)(t,s)$, therefore $(g+h)f=gf+hf$; $A$ has the following property: for all $f,g\in A,\alpha\in \mathbb{R}$: $(\alpha(fg))(t,s)=\alpha(fg)(t,s)=\alpha f(t,s)g(t,s)=(\alpha f)(t,s)g(t,s)=((\alpha f)g)(t,s)= f(t,s) \alpha g(t,s)=(f(\alpha g))(t,s)$; Secondly, I want to show that the norm of the product is less than or equal to the product of the norms, i.e. $$ \|fg\|\leq\|f\|\|g\|. $$ So, let, $$ f(t,s)=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}} $$ and $$ g(t,s)=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{b_{mn}e^{i(mt+ns)}} $$ We observe that \begin{align} (fg)(t,s)&=f(t,s)g(t,s)\\          &=\left(\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}}\right)\left(\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{b_{mn}e^{i(mt+ns)}}\right) \end{align} Now, I want to conclude somehow that $f(t,s)g(t,s)$ has the following form: $$ \sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{C_{mn}e^{i(mt+ns)}}, $$ such that $$ \|fg\|\leq \sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|a_{mn}|}\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|b_{mn}|}. $$ However, I dont know how to finish this proof. How can I conclude that $\|fg\|\leq\|f\|\|g\|.$ Now, let $M$ denote the set of all multiplicative linear functionals on $A$. Then, we can define the Gelfand transform $\hat{x}$ of $x$ as $$ \hat{x}(\varphi):=\varphi(x),\qquad\quad\varphi\in M $$ We can easily see that $A(M)$ with the following norm is a Banach space $$ \|\hat{x}\|=\sup_{\varphi\in M}{|\hat{x}(\varphi)|}. $$ Now, there exists a topology on $M$ such that $M$ is compact and $\hat{x}\in C(M)$ (Gelfand topology). Finally, we call set $M$ on $A$ with the Gelfand topology the Gelfand spectrum of $A$. My question: Is it possible to identify  the Gelfand spectrum of $A$ with the two dimensional torus: $T^2:=\{(e^{it},e^{is})\colon t,s\in\mathbb{R}\}$. If so, how? Any hints are appreciated.","Let $A$ be the set of all functions on $\mathbb{R}^2$ of the form $$ f(t,s):=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}}, $$ with the following norm: $$ \|f\|:=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|a_{mn}|}. $$ I want to show that $A$ is a commutative Banach algebra. And, I am curious whether it is possible to show that the Gelfand spectrum of $A$ can be identified with the two-dimensional torus, i.e. $\{(e^{it},e^{is})\colon t,s\in\mathbb{R}\}$. Firstly, it is easy to show that: $A$ is commutative, since for all $f,g\in A$:  $(fg)(t,s)=f(t,s)g(t,s)=g(t,s)f(t,s)=(gf)(t,s)$; $A$ is associative, since for all $f,g,h\in A$:  $((fg)h)(t,s)=(fg)(t,s)h(t,s)=g(t,s)f(t,s)h(t,s)=f(t,s)(gh)(t,s)=(f(gh))(t,s)$; $A$ is distributive, since for all $f,g,h\in A$: $(f(g+h))(t,s)=f(t,s)(g+h)(t,s)=f(t,s)(g(t,s)+h(t,s))=f(t,s)g(t,s)+f(t,s)h(t,s)=(fg)(x)+ (fh)(t,s)=(fg+fh)(t,s)$, therefore $(g+h)f=gf+hf$; $A$ has the following property: for all $f,g\in A,\alpha\in \mathbb{R}$: $(\alpha(fg))(t,s)=\alpha(fg)(t,s)=\alpha f(t,s)g(t,s)=(\alpha f)(t,s)g(t,s)=((\alpha f)g)(t,s)= f(t,s) \alpha g(t,s)=(f(\alpha g))(t,s)$; Secondly, I want to show that the norm of the product is less than or equal to the product of the norms, i.e. $$ \|fg\|\leq\|f\|\|g\|. $$ So, let, $$ f(t,s)=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}} $$ and $$ g(t,s)=\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{b_{mn}e^{i(mt+ns)}} $$ We observe that \begin{align} (fg)(t,s)&=f(t,s)g(t,s)\\          &=\left(\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{a_{mn}e^{i(mt+ns)}}\right)\left(\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{b_{mn}e^{i(mt+ns)}}\right) \end{align} Now, I want to conclude somehow that $f(t,s)g(t,s)$ has the following form: $$ \sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{C_{mn}e^{i(mt+ns)}}, $$ such that $$ \|fg\|\leq \sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|a_{mn}|}\sum_{m=-\infty}^{\infty}\sum_{n=-\infty}^{\infty}{|b_{mn}|}. $$ However, I dont know how to finish this proof. How can I conclude that $\|fg\|\leq\|f\|\|g\|.$ Now, let $M$ denote the set of all multiplicative linear functionals on $A$. Then, we can define the Gelfand transform $\hat{x}$ of $x$ as $$ \hat{x}(\varphi):=\varphi(x),\qquad\quad\varphi\in M $$ We can easily see that $A(M)$ with the following norm is a Banach space $$ \|\hat{x}\|=\sup_{\varphi\in M}{|\hat{x}(\varphi)|}. $$ Now, there exists a topology on $M$ such that $M$ is compact and $\hat{x}\in C(M)$ (Gelfand topology). Finally, we call set $M$ on $A$ with the Gelfand topology the Gelfand spectrum of $A$. My question: Is it possible to identify  the Gelfand spectrum of $A$ with the two dimensional torus: $T^2:=\{(e^{it},e^{is})\colon t,s\in\mathbb{R}\}$. If so, how? Any hints are appreciated.",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'banach-algebras']"
17,Characterization of compact operators by their spectra,Characterization of compact operators by their spectra,,In any functional analysis book there is usually a section devoted to the study of the properties of the spectrum of compact operators. Is there any spectral characterization of compact (self-adjoint) operators? Here is an example of what I have in mind Suppose $T$ is a bounded self-adjoint operator whose eigenvalues have finite multiplicity and $0$ is the only limit point of its spectrum. Then (perhaps with some more spectral conditions) $T$ is a compact operator. Thanks!,In any functional analysis book there is usually a section devoted to the study of the properties of the spectrum of compact operators. Is there any spectral characterization of compact (self-adjoint) operators? Here is an example of what I have in mind Suppose $T$ is a bounded self-adjoint operator whose eigenvalues have finite multiplicity and $0$ is the only limit point of its spectrum. Then (perhaps with some more spectral conditions) $T$ is a compact operator. Thanks!,,"['functional-analysis', 'operator-theory', 'spectral-theory', 'compact-operators']"
18,"Finding ""the"" Marchenko-Pastur distribution in the original article of 1967","Finding ""the"" Marchenko-Pastur distribution in the original article of 1967",,"I am looking at distribution properties of eigenvalues of sample covariance matrices. Following the Wikipedia article on the Marchenko-Pastur distribution : Let $X$ denote a $M \times N$ random matrix whose entries are i.i.d. random variables with mean $0$ and variance $\sigma^2 < \infty$. Let   $$ Y_ N = N^{-1}XX^T, $$   (which in a statistical context I can view as a sample covariance matrix) and let $\lambda_1, \lambda_2, \ldots, \lambda_M$ be the eigenvalues of $Y_N$ (viewed as random variables). Finally consider the random measure   $$ \mu_M(A) = \frac{1}{M}\#\{\lambda_j \in A\},\, \, A \subset \mathbb{R}. $$ Theorem. Assume that $M, N \rightarrow \infty$ so that the ratio $M/N \rightarrow \lambda \in (0,+\infty)$. Then $\mu_M \rightarrow \mu$ (in distribution), where   $$ \mu(A) =\begin{cases} (1-\frac{1}{\lambda}) \mathbf{1}_{0\in A} + \nu(A),& \text{if } \lambda >1\\ \nu(A),& \text{if } 0\leq \lambda \leq 1, \end{cases} $$   and   $$d\nu(x) = \frac{1}{2\pi \sigma^2 } \frac{\sqrt{(\lambda_{+} - x)(x - \lambda_{-})}}{\lambda x} \,\mathbf{1}_{[\lambda_{-}, \lambda_{+}]}\, dx$$   with   $$ \lambda_{\pm} = \sigma^2(1 \pm \sqrt{\lambda})^2. \, $$ I then tried to align this statement with the original paper of Marchenko and Pastur (1967) . However, the setting there is far less clear to me (i.e., I do not immediately see the connection to the setting of sample covariance matrices): We shall consider as acting in $N$-dimensional unitary space $H_N$ a self-adjoint operator $B_N(n)$ of the form   $$ B(n) = A_N + \sum_{i=1}^n \tau_i q^{(i)}(\cdot, q^{(i)}). $$   Here, $A_N$ is a nonrandom self-adjoint operator; $n$ is a nonrandom number; the $\tau_i$ are i.i.d. real random variables and the $q^i$ are mutually independent random vectors in $H_N$, independent also of the $\tau_i$. $(x, q^{(i)})$ denotes the inner product in $H_N$. ($\ldots$) We shall be interested in the function $\nu(\lambda; B_N(n))$ giving the ratio of the number of eigenvalues of $B_N(n)$ lying to the left of $\lambda$ to the dimension of space. $\nu(\lambda; B_N(n))$ is called the normalized spectral function of the operator $B_N(n)$. In the paper, on p. 458, there follow four assumptions I-IV, among them: I. The limit $\lim_{N\rightarrow \infty} n/N = c$, which for brevity we call the concentration exists. One now is interested in cases of very large $N$ and $n$ and the properties of the operator that ensure convergence in probability of $\nu(\lambda; B_N(n))$ to a nonrandom number $\nu(\lambda; c)$. The main result is then contained in Theorem 1 on p. 460, where the normalized spectral function is given in terms of its Stieltjes transform. This is followed by three examples on p. 461, where the function can even be given explicitely and of which I assume the first one applies in my case: 1) The sum of random independent and equally probable projections . Let $B_N(n) = \tau\sum_{i=1}^n P_i$, where each $P_i$ is a projection operator on the random vector $q^{(i)}$, independent and uniformly distributed on the unit sphere and $\tau$ is a nonrandom number. ($\ldots$) We find that $\nu(\lambda; c) = \nu_1(\lambda; c) + \nu_2(\lambda; c)$, where   $$ \frac{d\nu_1(\lambda; c)}{d\lambda} =\begin{cases} (1-c)\delta(\lambda) & \text{for } 0 \leq c \leq 1,\\ 0 & \text{for } c > 1, \end{cases} $$   $$ \frac{d\nu_2(\lambda; c)}{d\lambda} =\begin{cases} \frac{\sqrt{4c\tau^2 - (\lambda -c\tau -\tau)^2}}{2\pi\tau\lambda} & \text{for } (\lambda-c\tau-\tau)^2 \leq 4c\tau^2,\\ 0 & \text{for } (\lambda-c\tau-\tau)^2 > 4c\tau^2, \end{cases} $$ My question now is how to relate this to the example in the Wikipedia article, i.e. how to view the sample covariance matrix in the form $B_N(n) = \tau\sum_{i=1}^n P_i$ and how the two distributions agree. Moreover, the concentration $\lambda$ in Wikipedia seems to be the reciprocal value of the $c$ in the paper? Any help is appreciated! Many thanks, P. Diaz","I am looking at distribution properties of eigenvalues of sample covariance matrices. Following the Wikipedia article on the Marchenko-Pastur distribution : Let $X$ denote a $M \times N$ random matrix whose entries are i.i.d. random variables with mean $0$ and variance $\sigma^2 < \infty$. Let   $$ Y_ N = N^{-1}XX^T, $$   (which in a statistical context I can view as a sample covariance matrix) and let $\lambda_1, \lambda_2, \ldots, \lambda_M$ be the eigenvalues of $Y_N$ (viewed as random variables). Finally consider the random measure   $$ \mu_M(A) = \frac{1}{M}\#\{\lambda_j \in A\},\, \, A \subset \mathbb{R}. $$ Theorem. Assume that $M, N \rightarrow \infty$ so that the ratio $M/N \rightarrow \lambda \in (0,+\infty)$. Then $\mu_M \rightarrow \mu$ (in distribution), where   $$ \mu(A) =\begin{cases} (1-\frac{1}{\lambda}) \mathbf{1}_{0\in A} + \nu(A),& \text{if } \lambda >1\\ \nu(A),& \text{if } 0\leq \lambda \leq 1, \end{cases} $$   and   $$d\nu(x) = \frac{1}{2\pi \sigma^2 } \frac{\sqrt{(\lambda_{+} - x)(x - \lambda_{-})}}{\lambda x} \,\mathbf{1}_{[\lambda_{-}, \lambda_{+}]}\, dx$$   with   $$ \lambda_{\pm} = \sigma^2(1 \pm \sqrt{\lambda})^2. \, $$ I then tried to align this statement with the original paper of Marchenko and Pastur (1967) . However, the setting there is far less clear to me (i.e., I do not immediately see the connection to the setting of sample covariance matrices): We shall consider as acting in $N$-dimensional unitary space $H_N$ a self-adjoint operator $B_N(n)$ of the form   $$ B(n) = A_N + \sum_{i=1}^n \tau_i q^{(i)}(\cdot, q^{(i)}). $$   Here, $A_N$ is a nonrandom self-adjoint operator; $n$ is a nonrandom number; the $\tau_i$ are i.i.d. real random variables and the $q^i$ are mutually independent random vectors in $H_N$, independent also of the $\tau_i$. $(x, q^{(i)})$ denotes the inner product in $H_N$. ($\ldots$) We shall be interested in the function $\nu(\lambda; B_N(n))$ giving the ratio of the number of eigenvalues of $B_N(n)$ lying to the left of $\lambda$ to the dimension of space. $\nu(\lambda; B_N(n))$ is called the normalized spectral function of the operator $B_N(n)$. In the paper, on p. 458, there follow four assumptions I-IV, among them: I. The limit $\lim_{N\rightarrow \infty} n/N = c$, which for brevity we call the concentration exists. One now is interested in cases of very large $N$ and $n$ and the properties of the operator that ensure convergence in probability of $\nu(\lambda; B_N(n))$ to a nonrandom number $\nu(\lambda; c)$. The main result is then contained in Theorem 1 on p. 460, where the normalized spectral function is given in terms of its Stieltjes transform. This is followed by three examples on p. 461, where the function can even be given explicitely and of which I assume the first one applies in my case: 1) The sum of random independent and equally probable projections . Let $B_N(n) = \tau\sum_{i=1}^n P_i$, where each $P_i$ is a projection operator on the random vector $q^{(i)}$, independent and uniformly distributed on the unit sphere and $\tau$ is a nonrandom number. ($\ldots$) We find that $\nu(\lambda; c) = \nu_1(\lambda; c) + \nu_2(\lambda; c)$, where   $$ \frac{d\nu_1(\lambda; c)}{d\lambda} =\begin{cases} (1-c)\delta(\lambda) & \text{for } 0 \leq c \leq 1,\\ 0 & \text{for } c > 1, \end{cases} $$   $$ \frac{d\nu_2(\lambda; c)}{d\lambda} =\begin{cases} \frac{\sqrt{4c\tau^2 - (\lambda -c\tau -\tau)^2}}{2\pi\tau\lambda} & \text{for } (\lambda-c\tau-\tau)^2 \leq 4c\tau^2,\\ 0 & \text{for } (\lambda-c\tau-\tau)^2 > 4c\tau^2, \end{cases} $$ My question now is how to relate this to the example in the Wikipedia article, i.e. how to view the sample covariance matrix in the form $B_N(n) = \tau\sum_{i=1}^n P_i$ and how the two distributions agree. Moreover, the concentration $\lambda$ in Wikipedia seems to be the reciprocal value of the $c$ in the paper? Any help is appreciated! Many thanks, P. Diaz",,"['functional-analysis', 'statistics', 'random-matrices']"
19,Elementary proof of $C^\infty_c$ is dense in $L^p (L^q)$ mixed space,Elementary proof of  is dense in  mixed space,C^\infty_c L^p (L^q),"As it well known, $C^\infty_0 (\mathbb{R}^n)$ (the space of infinitely differentiable functions with compact support) is dense in $L^p (\mathbb{R)^n}$ Here I want to consider the same result with mixed norm. The mixed norm space is defined by $$ \Vert f \Vert_{L^p_t L^q_x}:=\left(\int_{\mathbb R} \left[\int_{\mathbb{R}^n} |f(t,x)|^p dx\right]^{\frac{q}{p}}dt\right)^{\frac{1}{p}}.$$ This norm can be viewed as $$ \Vert f \Vert_{L^p_t L^q_x}:=\left(\int_{\mathbb R} \Vert f(t,\cdot) \Vert_{L^q (\mathbb{R^n})}^p dt \right)^{\frac{1}{p}}.$$ So by this point of view, I can verify that the space $L^p_t L^q_x$ is actually $L^p (\mathbb{R}; L^q(\mathbb{R}^n)$ ) space, which is a special case of Bochner space. Then in the theory of Banach-valued function space, $$ f(t) = \sum_{i=1}^n a_i \phi_i (t),$$ where $a_i$ is an element of Banach space $B$ , $\phi_i$ is a characteristic function in $\mathbb{R}$ with finite measure, is dense in $L^p (\mathbb{R};B)$ when $1\leq p <\infty$ . So by taking molification, we see that $C^\infty_0 (\mathbb{R};B)$ is dense in $L^p (\mathbb{R};B)$ . As $C^\infty_0$ is dense in $L^p(\mathbb{R}^n)$ , $C^\infty_0 (\mathbb{R}^{n+1})$ is dense in $L^p_t L^q_x$ . My question is the following: Can I proved it properly? How can prove the fact without using Bochner integral? Thank you in advance.","As it well known, (the space of infinitely differentiable functions with compact support) is dense in Here I want to consider the same result with mixed norm. The mixed norm space is defined by This norm can be viewed as So by this point of view, I can verify that the space is actually ) space, which is a special case of Bochner space. Then in the theory of Banach-valued function space, where is an element of Banach space , is a characteristic function in with finite measure, is dense in when . So by taking molification, we see that is dense in . As is dense in , is dense in . My question is the following: Can I proved it properly? How can prove the fact without using Bochner integral? Thank you in advance.","C^\infty_0 (\mathbb{R}^n) L^p (\mathbb{R)^n}  \Vert f \Vert_{L^p_t L^q_x}:=\left(\int_{\mathbb R} \left[\int_{\mathbb{R}^n} |f(t,x)|^p dx\right]^{\frac{q}{p}}dt\right)^{\frac{1}{p}}.  \Vert f \Vert_{L^p_t L^q_x}:=\left(\int_{\mathbb R} \Vert f(t,\cdot) \Vert_{L^q (\mathbb{R^n})}^p dt \right)^{\frac{1}{p}}. L^p_t L^q_x L^p (\mathbb{R}; L^q(\mathbb{R}^n)  f(t) = \sum_{i=1}^n a_i \phi_i (t), a_i B \phi_i \mathbb{R} L^p (\mathbb{R};B) 1\leq p <\infty C^\infty_0 (\mathbb{R};B) L^p (\mathbb{R};B) C^\infty_0 L^p(\mathbb{R}^n) C^\infty_0 (\mathbb{R}^{n+1}) L^p_t L^q_x","['real-analysis', 'functional-analysis', 'proof-verification', 'partial-differential-equations', 'harmonic-analysis']"
20,"Proof validation: complete set, change of variable","Proof validation: complete set, change of variable",,"Let $\phi(x) \in \mathcal{C}^1([0,1])$ be a real valued function such that: $$\begin{cases} \phi'(x) > 0 & \forall x \in [0,1] \\ \phi(0) = 0 \\ \phi(1) = 1. \end{cases}$$ I'm asked to prove that the set $$\left\lbrace{f_n(x) \equiv \sin(n\pi\phi(x)}\right\rbrace_1^{\infty}$$ is complete in $L^2([0,1])$. Here is my proof. For the sake of conciseness I'll omit some calculations, stating only their final results. My doubt concerns the legitimacy of the change of variable I perform. Can you tell me if it is right to proceed this way? Also, if there are other mistakes, please point them out. Let $f$ be a function in $L^2([0,1])$ such that    $$ 0 = \left\langle f_n, f \right\rangle_{L^2([0,1])} = \int_0^1 \sin(n\pi\phi(x)) f(x) \,dx \quad \forall n \geq 1.$$   Now, if the change of variable defined by $z(x) = \pi \phi(x)$ (which is possible for the properties of $\phi$) is performed, the former equality becomes:   $$ 0 = \int_0^\pi \sin(nz) f(x(z)) \dfrac{dx}{dz} \,dz \quad \forall n \geq 1$$   and, since (from the hypotheses on $f$ and $\phi$) it can be proven that $f(x(z)) \dfrac{dx}{dz} \in L^2([0,\pi]),$ from the completeness of the set ${\left\lbrace{\sin(nz)}\right\rbrace}_1^\infty$ in $L^2([0,\pi])$ and from the hypothesis on $\phi'$ we have:   $$f(x(z)) \dfrac{dx}{dz} = 0 \quad \Rightarrow \quad f(z) = 0 \ \text{ a. e. } \; \forall z \in [0, \pi] \qquad \Rightarrow \quad f(x) = 0 \ \text{ a.e. } \; \forall x \in [0, 1]$$   which means that the set ${\left\lbrace{\sin(n\pi\phi(x)}\right\rbrace}_1^\infty$ is complete in $L^2([0,1])$.","Let $\phi(x) \in \mathcal{C}^1([0,1])$ be a real valued function such that: $$\begin{cases} \phi'(x) > 0 & \forall x \in [0,1] \\ \phi(0) = 0 \\ \phi(1) = 1. \end{cases}$$ I'm asked to prove that the set $$\left\lbrace{f_n(x) \equiv \sin(n\pi\phi(x)}\right\rbrace_1^{\infty}$$ is complete in $L^2([0,1])$. Here is my proof. For the sake of conciseness I'll omit some calculations, stating only their final results. My doubt concerns the legitimacy of the change of variable I perform. Can you tell me if it is right to proceed this way? Also, if there are other mistakes, please point them out. Let $f$ be a function in $L^2([0,1])$ such that    $$ 0 = \left\langle f_n, f \right\rangle_{L^2([0,1])} = \int_0^1 \sin(n\pi\phi(x)) f(x) \,dx \quad \forall n \geq 1.$$   Now, if the change of variable defined by $z(x) = \pi \phi(x)$ (which is possible for the properties of $\phi$) is performed, the former equality becomes:   $$ 0 = \int_0^\pi \sin(nz) f(x(z)) \dfrac{dx}{dz} \,dz \quad \forall n \geq 1$$   and, since (from the hypotheses on $f$ and $\phi$) it can be proven that $f(x(z)) \dfrac{dx}{dz} \in L^2([0,\pi]),$ from the completeness of the set ${\left\lbrace{\sin(nz)}\right\rbrace}_1^\infty$ in $L^2([0,\pi])$ and from the hypothesis on $\phi'$ we have:   $$f(x(z)) \dfrac{dx}{dz} = 0 \quad \Rightarrow \quad f(z) = 0 \ \text{ a. e. } \; \forall z \in [0, \pi] \qquad \Rightarrow \quad f(x) = 0 \ \text{ a.e. } \; \forall x \in [0, 1]$$   which means that the set ${\left\lbrace{\sin(n\pi\phi(x)}\right\rbrace}_1^\infty$ is complete in $L^2([0,1])$.",,"['functional-analysis', 'proof-verification', 'complete-spaces']"
21,"How can we prove that $\langle\int_0^t\Phi_s{\rm d}W_s,x\rangle_H=\sum_{n\in\mathbb N}\int_0^t\langle\sqrt{λ_n}\Phi_se_n,x\rangle_H{\rm d}B_s^{(n)}$?",How can we prove that ?,"\langle\int_0^t\Phi_s{\rm d}W_s,x\rangle_H=\sum_{n\in\mathbb N}\int_0^t\langle\sqrt{λ_n}\Phi_se_n,x\rangle_H{\rm d}B_s^{(n)}","Let$^1$ $U$ and $H$ be separable $\mathbb R$-Hilbert spaces $Q\in\mathfrak L(U,H)$ be nonnegative and symmetric operator on $U$ with finite trace $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $U$ with $$Qe_n=\lambda_ne_n\;\;\;\text{for all }n\in\mathbb N$$ for some $(\lambda_n)_{n\in\mathbb N}\subseteq[0,\infty)$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space and $(\mathcal F_t)_{t\ge 0}$ be a filtration of $\mathcal A$ $W$ be a $Q$-Wiener process on $(\Omega,\mathcal A,\operatorname P)$ with respect to $\mathcal F$, $$B^{(n)}:=\begin{cases}\frac{\langle W,e_n\rangle_U}{\sqrt{\lambda_n}}&\text{, if }n\in\mathbb N\text{ with }\lambda_n>0\\0&\text{, else}\end{cases}$$ and $$W^{(n)}:=\sum_{i=1}^n\sqrt{\lambda_i}B^{(i)}e_i\;\;\;\text{for }n\in\mathbb N$$ Note that the $B^{(n)}$ are independent $\mathcal F$-Brownian motions on $(\Omega,\mathcal A,\operatorname P)$, $$\left\|W_t^{(n)}-W_t\right\|_{L^2(\operatorname P,\;U)}\stackrel{n\to\infty}\to 0\;\;\;\text{for all }t\ge 0\tag 1$$ and $$\operatorname P\left[\left\|W^{(n)}-W\right\|_{C^0([0,\;t],\;U)}\stackrel{n\to\infty}\to 0\right]=1\;\;\;\text{for all }t\ge 0\tag 2$$ Now, let $(\Phi_t)_{t\ge 0}$ be a $\mathfrak L(U,H)$-valued $\mathcal F$-adapted and locally bounded $^2$ stochastic process on $(\Omega,\mathcal A,\operatorname P)$ with $$\Phi_t=\sum_{i=1}^n\xi_{i-1}1_{(t_{i-1},t_i]}\;\;\;\text{for all }t\ge 0\tag 3$$ for some $\mathfrak L(U,H)$-valued random variables $\xi_0,\ldots,\xi_{n-1}$ on $(\Omega,\mathcal A,\operatorname P)$ and some $0=t_0<\cdots<t_n$. Moreover, let $$\int_0^t\Phi_s{\rm d}W_s:=\sum_{i=1}^n\xi_{i-1}\left(W_{t_i\wedge t}-W_{t_{i-1}\wedge t}\right)\;\;\;\text{for }t\ge 0\;.$$ Let $x\in H$. How can we prove that $$\langle\int_0^t\Phi_s{\rm d}W_s,x\rangle_H=\sum_{n\in\mathbb N}\int_0^t\langle\sqrt{\lambda_n}\Phi_se_n,x\rangle_H{\rm d}B_s^{(n)}\tag 4$$ in $L^2(\operatorname P)$, for all $t\ge 0$? Let $$X^{(n)}_t:=\langle\sqrt{\lambda_n}\Phi_te_n,x\rangle_H\;\;\;\text{for }n\in\mathbb N\text{ and }t\ge 0\;.$$ By definition of the Itō integral with respect to a Brownian motion , $$\int_0^tX^{(n)}_s{\rm d}B_s=\sqrt{\lambda_n}\sum_{i=1}^n\langle\xi_{i-1}e_n,x\rangle_H\left(B^{(n)}_{t_i\wedge t}-B^{(n)}_{t_{i-1}\wedge t}\right)\;\;\;\text{for all }n\in\mathbb N\text{ and }t\ge 0\;.\tag 5$$ $\color{red}{\text{Now comes the crucial part!}}$ In the following equation chain, why do $(6)$ and $(7)$ hold? \begin{equation} \begin{split} \langle\int_0^t\Phi_s{\rm d}W_s,x\rangle_H&=\sum_{i=1}^n\langle\xi_{i-1}\left(W_{t_i\wedge t}-W_{t_{i-1}\wedge t}\right),x\rangle_H\\ &\stackrel{(6)}{\color{red}=}\sum_{i=1}^n\langle\xi_{i-1}\sum_{k\in\mathbb N}\sqrt{\lambda_k}\left(B^{(k)}_{t_i\wedge t}-B^{(k)}_{t_{i-1}\wedge t}\right)e_k,x\rangle_H\\ &=\sum_{i=1}^n\sum_{k\in\mathbb N}\sqrt{\lambda_k}\langle\xi_{i-1}e_k,x\rangle_H\left(B^{(k)}_{t_i\wedge t}-B^{(k)}_{t_{i-1}\wedge t}\right)\\ &\stackrel{(7)}{\color{red}=}\sum_{k\in\mathbb N}\sum_{i=1}^n\sqrt{\lambda_k}\langle\xi_{i-1}e_k,x\rangle_H\left(B^{(k)}_{t_i\wedge t}-B^{(k)}_{t_{i-1}\wedge t}\right)\\ &=\sum_{k\in\mathbb N}\int_0^tX^{(k)}_s{\rm d}B^{(k)}_s \end{split}\tag 8 \end{equation} for all $t\ge 0$. In particular, I don't really understand in which sense the equation chain $(8)$ holds. In the sense of $L^2(\operatorname P)$-convergence or in the sense of $\operatorname P$-almost sure convergence? $^1$ Let $\mathfrak L(U,H)$ denote the space of bounded, linear operators from $U$ to $H$. $^2$ i.e. $$\sup_\Omega\left\|\Phi_t\right\|_{\mathfrak L(U,\;H)}<\infty\;\;\;\text{for all }t\ge 0\;.$$","Let$^1$ $U$ and $H$ be separable $\mathbb R$-Hilbert spaces $Q\in\mathfrak L(U,H)$ be nonnegative and symmetric operator on $U$ with finite trace $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $U$ with $$Qe_n=\lambda_ne_n\;\;\;\text{for all }n\in\mathbb N$$ for some $(\lambda_n)_{n\in\mathbb N}\subseteq[0,\infty)$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space and $(\mathcal F_t)_{t\ge 0}$ be a filtration of $\mathcal A$ $W$ be a $Q$-Wiener process on $(\Omega,\mathcal A,\operatorname P)$ with respect to $\mathcal F$, $$B^{(n)}:=\begin{cases}\frac{\langle W,e_n\rangle_U}{\sqrt{\lambda_n}}&\text{, if }n\in\mathbb N\text{ with }\lambda_n>0\\0&\text{, else}\end{cases}$$ and $$W^{(n)}:=\sum_{i=1}^n\sqrt{\lambda_i}B^{(i)}e_i\;\;\;\text{for }n\in\mathbb N$$ Note that the $B^{(n)}$ are independent $\mathcal F$-Brownian motions on $(\Omega,\mathcal A,\operatorname P)$, $$\left\|W_t^{(n)}-W_t\right\|_{L^2(\operatorname P,\;U)}\stackrel{n\to\infty}\to 0\;\;\;\text{for all }t\ge 0\tag 1$$ and $$\operatorname P\left[\left\|W^{(n)}-W\right\|_{C^0([0,\;t],\;U)}\stackrel{n\to\infty}\to 0\right]=1\;\;\;\text{for all }t\ge 0\tag 2$$ Now, let $(\Phi_t)_{t\ge 0}$ be a $\mathfrak L(U,H)$-valued $\mathcal F$-adapted and locally bounded $^2$ stochastic process on $(\Omega,\mathcal A,\operatorname P)$ with $$\Phi_t=\sum_{i=1}^n\xi_{i-1}1_{(t_{i-1},t_i]}\;\;\;\text{for all }t\ge 0\tag 3$$ for some $\mathfrak L(U,H)$-valued random variables $\xi_0,\ldots,\xi_{n-1}$ on $(\Omega,\mathcal A,\operatorname P)$ and some $0=t_0<\cdots<t_n$. Moreover, let $$\int_0^t\Phi_s{\rm d}W_s:=\sum_{i=1}^n\xi_{i-1}\left(W_{t_i\wedge t}-W_{t_{i-1}\wedge t}\right)\;\;\;\text{for }t\ge 0\;.$$ Let $x\in H$. How can we prove that $$\langle\int_0^t\Phi_s{\rm d}W_s,x\rangle_H=\sum_{n\in\mathbb N}\int_0^t\langle\sqrt{\lambda_n}\Phi_se_n,x\rangle_H{\rm d}B_s^{(n)}\tag 4$$ in $L^2(\operatorname P)$, for all $t\ge 0$? Let $$X^{(n)}_t:=\langle\sqrt{\lambda_n}\Phi_te_n,x\rangle_H\;\;\;\text{for }n\in\mathbb N\text{ and }t\ge 0\;.$$ By definition of the Itō integral with respect to a Brownian motion , $$\int_0^tX^{(n)}_s{\rm d}B_s=\sqrt{\lambda_n}\sum_{i=1}^n\langle\xi_{i-1}e_n,x\rangle_H\left(B^{(n)}_{t_i\wedge t}-B^{(n)}_{t_{i-1}\wedge t}\right)\;\;\;\text{for all }n\in\mathbb N\text{ and }t\ge 0\;.\tag 5$$ $\color{red}{\text{Now comes the crucial part!}}$ In the following equation chain, why do $(6)$ and $(7)$ hold? \begin{equation} \begin{split} \langle\int_0^t\Phi_s{\rm d}W_s,x\rangle_H&=\sum_{i=1}^n\langle\xi_{i-1}\left(W_{t_i\wedge t}-W_{t_{i-1}\wedge t}\right),x\rangle_H\\ &\stackrel{(6)}{\color{red}=}\sum_{i=1}^n\langle\xi_{i-1}\sum_{k\in\mathbb N}\sqrt{\lambda_k}\left(B^{(k)}_{t_i\wedge t}-B^{(k)}_{t_{i-1}\wedge t}\right)e_k,x\rangle_H\\ &=\sum_{i=1}^n\sum_{k\in\mathbb N}\sqrt{\lambda_k}\langle\xi_{i-1}e_k,x\rangle_H\left(B^{(k)}_{t_i\wedge t}-B^{(k)}_{t_{i-1}\wedge t}\right)\\ &\stackrel{(7)}{\color{red}=}\sum_{k\in\mathbb N}\sum_{i=1}^n\sqrt{\lambda_k}\langle\xi_{i-1}e_k,x\rangle_H\left(B^{(k)}_{t_i\wedge t}-B^{(k)}_{t_{i-1}\wedge t}\right)\\ &=\sum_{k\in\mathbb N}\int_0^tX^{(k)}_s{\rm d}B^{(k)}_s \end{split}\tag 8 \end{equation} for all $t\ge 0$. In particular, I don't really understand in which sense the equation chain $(8)$ holds. In the sense of $L^2(\operatorname P)$-convergence or in the sense of $\operatorname P$-almost sure convergence? $^1$ Let $\mathfrak L(U,H)$ denote the space of bounded, linear operators from $U$ to $H$. $^2$ i.e. $$\sup_\Omega\left\|\Phi_t\right\|_{\mathfrak L(U,\;H)}<\infty\;\;\;\text{for all }t\ge 0\;.$$",,"['real-analysis', 'functional-analysis', 'stochastic-processes', 'stochastic-integrals', 'stochastic-analysis']"
22,Existence of Banach Limits,Existence of Banach Limits,,"Just want to check everything is good. $\textbf{Theorem:}$ Define $T: l_{\infty}(\mathbb{R}) \to l_{\infty}(\mathbb{R})$ by $$T(x_1,x_2,x_3,...)=(x_2,x_3,x_4,...),$$ $$M=\{x-Tx:x \in l_{\infty}(\mathbb{R})\},$$ and $e=(1,1,1,...)$. Then $(a)$ $T \in \mathcal{L}(l_{\infty}(\mathbb{R}))$ ($T$ is both continuous and linear) and $\Vert T \Vert = 1$; $(b)$ $M \leq l_{\infty}$ and $d(e,M)=1$; $(c)$ There exists $f \in l_{\infty}(\mathbb{R})'$ such that $(1)$ $\Vert f \Vert = 1$, $(2)$ for each $x \in l_{\infty}(\mathbb{R})$ we have $f(x)=f(T(x))$ and $(3)$ for each $(x_n) \in c(\mathbb{R})$ we have $f((x_n))=\lim_{n \to \infty}x_n$, $(4)$ for each $(x_n) \in l_{\infty}(\mathbb{R})$ such that for each $n \in \mathbb{N}$, $x_n \geq 0$, we have $f((x_n)) \geq 0$. $\textbf{Proof}:$ It's easy to check $T \in \mathcal{L}(l_{\infty}(\mathbb{R}))$ and $M \leq l_{\infty}$. Since $0_{l_{\infty}(\mathbb{R})} \in M$, $d(e,M) \leq 1$. Let $x=(x_n) \in l_{\infty}(\mathbb{R})$. If for some $n \in \mathbb{N}$, $x_n-x_{n+1} \leq 0$, then $$1 \leq \vert 1-(x_n-x_{n+1}) \vert \leq \Vert e-(x-T(x)) \Vert;$$ if on the other hand for each $n \in \mathbb{N}$, $x_n-x_{n+1} \geq 0$, that is, $x_{n+1} \leq x_n$, then $\lim_{n \to \infty}x_n$ exists, so that $\lim_{n \to \infty}x_n-x_{n+1}=0$ and we have $$1 \leq \Vert e-(x-T(x)) \Vert.$$ We conclude $d(e,M) \geq 1$, and in fact, $d(e,M)=1$. By (a certain consequence of) the Hahn-Banach Theorem, we can find $f \in l_{\infty}(\mathbb{R})'$ such that $\Vert f \Vert = 1$, $f(e)=1$ and for each $x \in M$, $f(x)=0$, that is, for each $x \in l_{\infty}(\mathbb{R})$, $$f(x)-f(T(x))=f(x-T(x))=0.$$ Suppose now $x = (x_n) \in c_0(\mathbb{R})$. For each $n \in \mathbb{N}$ we have $$T^{n}(x)-x=[T^{n}(x)-T^{n-1}(x)]+...+[T(x)-x] \in M,$$ so that $f(x)=f(T^{n}(x))$; then if $\epsilon \in \mathbb{R}_{>0}$ and $n \in \mathbb{N}$ is such that $m \in \mathbb{N}_{>n}$ implies $\vert x_m \vert < \epsilon$ we have $$\vert f(x) \vert = \vert f(T^n(x)) \vert \leq \Vert T^n(x) \Vert < \epsilon,$$ and therefore $x \in \ker f$, that is, $$f(x)=0=\lim_{n \to \infty}x_n.$$ It follows that if $x=(x_n) \in c(\mathbb{R})$, we have $f(x)=\lim_{n \to \infty}x_n$. Finally, suppose there exists $x = (x_n) \in l_{\infty}(\mathbb{R})$ such that for each $n \in \mathbb{N}$, $x_n \geq 0$ and $f(x)<0$. Define $\overline{x} = x / \Vert x \Vert$. Then for each $n \in \mathbb{N}$ we have $$0 \leq \overline{x}_n \leq 1 \ \text{and} \ f(\overline{x})<0$$ and therefore $$\Vert e-\overline{x} \Vert \leq 1 \ \text{and} \ f(e-\overline{x})=1-f(\overline{x})>1,$$ which is absurd since $\Vert f \Vert = 1$.","Just want to check everything is good. $\textbf{Theorem:}$ Define $T: l_{\infty}(\mathbb{R}) \to l_{\infty}(\mathbb{R})$ by $$T(x_1,x_2,x_3,...)=(x_2,x_3,x_4,...),$$ $$M=\{x-Tx:x \in l_{\infty}(\mathbb{R})\},$$ and $e=(1,1,1,...)$. Then $(a)$ $T \in \mathcal{L}(l_{\infty}(\mathbb{R}))$ ($T$ is both continuous and linear) and $\Vert T \Vert = 1$; $(b)$ $M \leq l_{\infty}$ and $d(e,M)=1$; $(c)$ There exists $f \in l_{\infty}(\mathbb{R})'$ such that $(1)$ $\Vert f \Vert = 1$, $(2)$ for each $x \in l_{\infty}(\mathbb{R})$ we have $f(x)=f(T(x))$ and $(3)$ for each $(x_n) \in c(\mathbb{R})$ we have $f((x_n))=\lim_{n \to \infty}x_n$, $(4)$ for each $(x_n) \in l_{\infty}(\mathbb{R})$ such that for each $n \in \mathbb{N}$, $x_n \geq 0$, we have $f((x_n)) \geq 0$. $\textbf{Proof}:$ It's easy to check $T \in \mathcal{L}(l_{\infty}(\mathbb{R}))$ and $M \leq l_{\infty}$. Since $0_{l_{\infty}(\mathbb{R})} \in M$, $d(e,M) \leq 1$. Let $x=(x_n) \in l_{\infty}(\mathbb{R})$. If for some $n \in \mathbb{N}$, $x_n-x_{n+1} \leq 0$, then $$1 \leq \vert 1-(x_n-x_{n+1}) \vert \leq \Vert e-(x-T(x)) \Vert;$$ if on the other hand for each $n \in \mathbb{N}$, $x_n-x_{n+1} \geq 0$, that is, $x_{n+1} \leq x_n$, then $\lim_{n \to \infty}x_n$ exists, so that $\lim_{n \to \infty}x_n-x_{n+1}=0$ and we have $$1 \leq \Vert e-(x-T(x)) \Vert.$$ We conclude $d(e,M) \geq 1$, and in fact, $d(e,M)=1$. By (a certain consequence of) the Hahn-Banach Theorem, we can find $f \in l_{\infty}(\mathbb{R})'$ such that $\Vert f \Vert = 1$, $f(e)=1$ and for each $x \in M$, $f(x)=0$, that is, for each $x \in l_{\infty}(\mathbb{R})$, $$f(x)-f(T(x))=f(x-T(x))=0.$$ Suppose now $x = (x_n) \in c_0(\mathbb{R})$. For each $n \in \mathbb{N}$ we have $$T^{n}(x)-x=[T^{n}(x)-T^{n-1}(x)]+...+[T(x)-x] \in M,$$ so that $f(x)=f(T^{n}(x))$; then if $\epsilon \in \mathbb{R}_{>0}$ and $n \in \mathbb{N}$ is such that $m \in \mathbb{N}_{>n}$ implies $\vert x_m \vert < \epsilon$ we have $$\vert f(x) \vert = \vert f(T^n(x)) \vert \leq \Vert T^n(x) \Vert < \epsilon,$$ and therefore $x \in \ker f$, that is, $$f(x)=0=\lim_{n \to \infty}x_n.$$ It follows that if $x=(x_n) \in c(\mathbb{R})$, we have $f(x)=\lim_{n \to \infty}x_n$. Finally, suppose there exists $x = (x_n) \in l_{\infty}(\mathbb{R})$ such that for each $n \in \mathbb{N}$, $x_n \geq 0$ and $f(x)<0$. Define $\overline{x} = x / \Vert x \Vert$. Then for each $n \in \mathbb{N}$ we have $$0 \leq \overline{x}_n \leq 1 \ \text{and} \ f(\overline{x})<0$$ and therefore $$\Vert e-\overline{x} \Vert \leq 1 \ \text{and} \ f(e-\overline{x})=1-f(\overline{x})>1,$$ which is absurd since $\Vert f \Vert = 1$.",,['functional-analysis']
23,Reference Quest: Measure Theoretic and Functional Analytic Intro to Stochastic Processes,Reference Quest: Measure Theoretic and Functional Analytic Intro to Stochastic Processes,,"Does anyone have any recommendations for a good book which introduces and cleanly and rigorously explains the measure theory and functional analysis implicit in and relevant to stochastic processes, and then from that knowledge base proceeds to introduce stochastic processes? I elaborate unnecessarily much below if you don't understand why I would ask for that. Background: I have tried several times to understand stochastic processes (e.g. Brownian motion, semi-groups of Markov processes, continuous time martingales, SDEs, Levy processes). Seemingly it should be nothing more complicated than applying measure theory to infinite dimensional function spaces, yet no text seems to take this approach. I thought I was a very good intuitive thinker, but the approach of most texts, which seem to approach the field through a combination of seemingly unmotivated inequalities and hand-wavy appeals to ""probabilistic intuition"" instead of trying to explain the conceptual nuances required to understand probability measures/distributions on uncountable spaces, has not worked well for me. For instance, much of the study of Brownian motion or of stochastic integration seems to rely on calculations using Wiener measure, yet I still have not found a good explanation or definition of Wiener measure (somehow in my class I'm supposed to write proofs using Ito's Formula despite the fact that we never received a precise definition of Wiener measure). Or when studying semi-groups as related to Markov processes, the resolvent is clearly the ""Laplace transform of an operator"", but this is rarely if ever pointed out nor ever explicitly/rigorously defined so that I can feel confident performing calculations with the object. Every textbook I have read so far has had this problem, but the worst offender by far is Feller. I don't feel like I really ""got"" probability theory at all until I started to understand it rigorously in terms of measure theory (e.g. Borel-Cantelli, Dynkin's Pi-Lambda theorem, the motivation behind using algebras and then sigma-algebras, random variables as measurable functions, etc.). But for some reason, despite the fact that the measure theory is much more complicated (as is the analysis) for stochastic processes as compared to probability theory, no one seems to treat it with care, unlike with measure theory for probability. All of the textbook authors seem so excited about the topics that they learned twenty years ago that they just jump into discussions of them without providing the reader the machinery necessary to really understand. I don't generally understand what it means for a stochastic process to be measurable, since I usually can't figure out what the relevant sigma algebra or measure is supposed to be. I don't understand the difference between a version or a modification of a stochastic process, or why the finite dimensional distributions don't ""determine a process"" (since clearly here a more specific definition/idea of stochastic process is implied than the ""uncountable set of random variables""). I don't understand how to rigorously define Wiener measure or how to use it for any calculations, especially with regards to optional stopping or stochastic integrals. I don't understand the idea of a random measure or a probability kernel or a conditional distribution or a regular conditional distribution, or how a regular conditional distribution corresponds to a compact operator (or to a completely continuous operator). I don't understand how to apply any of my knowledge of functional analysis to the study of stochastic processes, despite the fact that it is obviously very relevant. I don't understand how to think of Markov processes in terms of operator theory or how to justify that the semigroup and the generator commute, or that the resolvent commutes with the generator, or how or why any operator commutes with another. The field seems very interesting, and I don't want to give up on it, but right now I feel that I am at an impasse, and hence would greatly appreciate any and all suggestions or ideas for help.","Does anyone have any recommendations for a good book which introduces and cleanly and rigorously explains the measure theory and functional analysis implicit in and relevant to stochastic processes, and then from that knowledge base proceeds to introduce stochastic processes? I elaborate unnecessarily much below if you don't understand why I would ask for that. Background: I have tried several times to understand stochastic processes (e.g. Brownian motion, semi-groups of Markov processes, continuous time martingales, SDEs, Levy processes). Seemingly it should be nothing more complicated than applying measure theory to infinite dimensional function spaces, yet no text seems to take this approach. I thought I was a very good intuitive thinker, but the approach of most texts, which seem to approach the field through a combination of seemingly unmotivated inequalities and hand-wavy appeals to ""probabilistic intuition"" instead of trying to explain the conceptual nuances required to understand probability measures/distributions on uncountable spaces, has not worked well for me. For instance, much of the study of Brownian motion or of stochastic integration seems to rely on calculations using Wiener measure, yet I still have not found a good explanation or definition of Wiener measure (somehow in my class I'm supposed to write proofs using Ito's Formula despite the fact that we never received a precise definition of Wiener measure). Or when studying semi-groups as related to Markov processes, the resolvent is clearly the ""Laplace transform of an operator"", but this is rarely if ever pointed out nor ever explicitly/rigorously defined so that I can feel confident performing calculations with the object. Every textbook I have read so far has had this problem, but the worst offender by far is Feller. I don't feel like I really ""got"" probability theory at all until I started to understand it rigorously in terms of measure theory (e.g. Borel-Cantelli, Dynkin's Pi-Lambda theorem, the motivation behind using algebras and then sigma-algebras, random variables as measurable functions, etc.). But for some reason, despite the fact that the measure theory is much more complicated (as is the analysis) for stochastic processes as compared to probability theory, no one seems to treat it with care, unlike with measure theory for probability. All of the textbook authors seem so excited about the topics that they learned twenty years ago that they just jump into discussions of them without providing the reader the machinery necessary to really understand. I don't generally understand what it means for a stochastic process to be measurable, since I usually can't figure out what the relevant sigma algebra or measure is supposed to be. I don't understand the difference between a version or a modification of a stochastic process, or why the finite dimensional distributions don't ""determine a process"" (since clearly here a more specific definition/idea of stochastic process is implied than the ""uncountable set of random variables""). I don't understand how to rigorously define Wiener measure or how to use it for any calculations, especially with regards to optional stopping or stochastic integrals. I don't understand the idea of a random measure or a probability kernel or a conditional distribution or a regular conditional distribution, or how a regular conditional distribution corresponds to a compact operator (or to a completely continuous operator). I don't understand how to apply any of my knowledge of functional analysis to the study of stochastic processes, despite the fact that it is obviously very relevant. I don't understand how to think of Markov processes in terms of operator theory or how to justify that the semigroup and the generator commute, or that the resolvent commutes with the generator, or how or why any operator commutes with another. The field seems very interesting, and I don't want to give up on it, but right now I feel that I am at an impasse, and hence would greatly appreciate any and all suggestions or ideas for help.",,"['functional-analysis', 'measure-theory', 'reference-request', 'soft-question', 'stochastic-analysis']"
24,Spectrum of Laplace operator with potential acting on $L^2(\mathbb R)$ is discrete,Spectrum of Laplace operator with potential acting on  is discrete,L^2(\mathbb R),"Consider an operator $H=-\Delta +U(x)$ on $L^2(\mathbb R)$ for a function $U(x): \mathbb R \to \mathbb R$ that tends to $+\infty$ as $|x|$ grows. These kinds of operators appear all over non-relativistic quantum mechanics as Hamiltonians. A statement that I have read is that such an operator has a discrete spectrum, and it was presented as being a standard result. How can this be proven? (I'm sorry if this is a lazy question, it seems to be common knowledge so one would expect proofs to abound like sand at the beach, but I couldn't find them on this website.)","Consider an operator $H=-\Delta +U(x)$ on $L^2(\mathbb R)$ for a function $U(x): \mathbb R \to \mathbb R$ that tends to $+\infty$ as $|x|$ grows. These kinds of operators appear all over non-relativistic quantum mechanics as Hamiltonians. A statement that I have read is that such an operator has a discrete spectrum, and it was presented as being a standard result. How can this be proven? (I'm sorry if this is a lazy question, it seems to be common knowledge so one would expect proofs to abound like sand at the beach, but I couldn't find them on this website.)",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory', 'laplacian']"
25,Operator continuity on Hilbert space,Operator continuity on Hilbert space,,"Let $A: H \to H$ be a linear operator on Hilbert space $H$, and let  $\{\alpha_n\}_{n = 1}^{\infty} \subset \mathbb{R}$ converges to nonzero number. Prove that if the series $\sum_{n = 1}^{\infty} \alpha_n\langle Ax_n, y\rangle $ converges for every $y \in H$ and every sequence $\{x_n\}_{n = 1}^{\infty} \subset H$ such that $\|x_n\| \leq n^{-2}, n \geq 1$ then $A$ is continuous.","Let $A: H \to H$ be a linear operator on Hilbert space $H$, and let  $\{\alpha_n\}_{n = 1}^{\infty} \subset \mathbb{R}$ converges to nonzero number. Prove that if the series $\sum_{n = 1}^{\infty} \alpha_n\langle Ax_n, y\rangle $ converges for every $y \in H$ and every sequence $\{x_n\}_{n = 1}^{\infty} \subset H$ such that $\|x_n\| \leq n^{-2}, n \geq 1$ then $A$ is continuous.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
26,Compact sets of compact-open topology,Compact sets of compact-open topology,,"Let $X$ and $Y$ be topological spaces,$X$ not compact and $Y$ metric, denote with $C(X,Y)$ the set of continuous functions between $X$ and $Y$ and put on $C(X,Y)$ the compact-open topology. My question is: which are the compact sets of this topology? My guess is that each set of the form $\mathcal{K}:=\{f\in C(X,Y)| f(K_1)\subset K_2\}$ (where $K_1\subset X$ and $K_2\subset Y$ are compact sets) is compact, due to the fact that the sets of the form $\{f\in C(X,Y)| f(K_1)\subset U\}$ ($U\subset Y$ is compact) are a subbase for the topology and so for every open cover of $\mathcal{K}$ I can find a finite subcover. Am I right? are there other types of compact sets? Thank you","Let $X$ and $Y$ be topological spaces,$X$ not compact and $Y$ metric, denote with $C(X,Y)$ the set of continuous functions between $X$ and $Y$ and put on $C(X,Y)$ the compact-open topology. My question is: which are the compact sets of this topology? My guess is that each set of the form $\mathcal{K}:=\{f\in C(X,Y)| f(K_1)\subset K_2\}$ (where $K_1\subset X$ and $K_2\subset Y$ are compact sets) is compact, due to the fact that the sets of the form $\{f\in C(X,Y)| f(K_1)\subset U\}$ ($U\subset Y$ is compact) are a subbase for the topology and so for every open cover of $\mathcal{K}$ I can find a finite subcover. Am I right? are there other types of compact sets? Thank you",,"['general-topology', 'functional-analysis', 'functions']"
27,Sobolev spaces on Riemannian manifold,Sobolev spaces on Riemannian manifold,,"I know one can define the Sobolev spaces on a Riemannian manifold as completions, but is there an equivalent definition that uses weak derivatives, like in the case of open sets in $\mathbb{R}^n$ ? Thanks","I know one can define the Sobolev spaces on a Riemannian manifold as completions, but is there an equivalent definition that uses weak derivatives, like in the case of open sets in $\mathbb{R}^n$ ? Thanks",,"['functional-analysis', 'differential-geometry', 'partial-differential-equations']"
28,open\closed and disjoint sets under R2,open\closed and disjoint sets under R2,,"I am stuck with the following question: Consider the sets in $\mathbb{R}^2$ defined by $A = \{(x,1/x)| x > 0 \}$, $B = \{(x, −1/x)| x < 0\}$. Prove that the sets are closed and disjoint, and that $d(A, B) = 0$ and that there are no $a_0 \in A$, $b_0 \in B$ for which $d(a_0, b_0) = d(A, B)$. i have a couple of issues here. for close sets i thought of proving $A$'s and $B$'s commentaries are open. but i don't know how to represent their commentaries. is this a good approach? what is the mining of disjoints and how do i prove it? I am new to metric spaces in general so please don't assume i posses any prior knowledge on the subject. Thanks","I am stuck with the following question: Consider the sets in $\mathbb{R}^2$ defined by $A = \{(x,1/x)| x > 0 \}$, $B = \{(x, −1/x)| x < 0\}$. Prove that the sets are closed and disjoint, and that $d(A, B) = 0$ and that there are no $a_0 \in A$, $b_0 \in B$ for which $d(a_0, b_0) = d(A, B)$. i have a couple of issues here. for close sets i thought of proving $A$'s and $B$'s commentaries are open. but i don't know how to represent their commentaries. is this a good approach? what is the mining of disjoints and how do i prove it? I am new to metric spaces in general so please don't assume i posses any prior knowledge on the subject. Thanks",,"['general-topology', 'functional-analysis', 'metric-spaces']"
29,How to define composition of distribution with a function correctly?,How to define composition of distribution with a function correctly?,,"Recently I've been reading some notes on distribution theory and the author makes the following definition: Let $\zeta\in \mathcal{D}'(\mathbb{R})$ be a distribution and $f$ a $C^\infty$ function, we define $\zeta\circ f$ to be the distribution: $$(\zeta\circ f, \phi)=(\zeta, |J^{-1}|\phi\circ f^{-1}),$$ where $J^{-1}$ is the jacobian of the inverse transformation $f^{-1}$ . The obvious problem is: if $f$ were not a bijection this would make no sense. This definition, thus, works just when $f$ is a invertible. Now, it is quite obvious that this is too restrictive. In this framework it is not possible, for example, to prove that: $$\delta \circ f = \sum_i \dfrac{1}{f'(x_i)}\delta_{x_i},$$ where $x_i$ are the zeroes of $f$ and $\delta_{x_i}$ is the delta centered at $x_i$ . With the presented definition $\delta \circ f$ makes no sense, because $f$ is not injective since $\# f^{-1}(0)> 1$ . This property is, though, well-known and true. In that sense, how should we correctly define the composition of distribution and a $C^\infty$ function? What is the correct definition which allows us to tackle cases in which the function is not injective?","Recently I've been reading some notes on distribution theory and the author makes the following definition: Let be a distribution and a function, we define to be the distribution: where is the jacobian of the inverse transformation . The obvious problem is: if were not a bijection this would make no sense. This definition, thus, works just when is a invertible. Now, it is quite obvious that this is too restrictive. In this framework it is not possible, for example, to prove that: where are the zeroes of and is the delta centered at . With the presented definition makes no sense, because is not injective since . This property is, though, well-known and true. In that sense, how should we correctly define the composition of distribution and a function? What is the correct definition which allows us to tackle cases in which the function is not injective?","\zeta\in \mathcal{D}'(\mathbb{R}) f C^\infty \zeta\circ f (\zeta\circ f, \phi)=(\zeta, |J^{-1}|\phi\circ f^{-1}), J^{-1} f^{-1} f f \delta \circ f = \sum_i \dfrac{1}{f'(x_i)}\delta_{x_i}, x_i f \delta_{x_i} x_i \delta \circ f f \# f^{-1}(0)> 1 C^\infty","['functional-analysis', 'definition', 'distribution-theory', 'dirac-delta', 'function-and-relation-composition']"
30,"Weak-* bounded, closed convex set is compact?","Weak-* bounded, closed convex set is compact?",,"Suppose $E$ is a Banach space, and $K\subseteq E^*$ is convex, and is closed and bounded with respect to weak-* topology. Is it true that $K$ is compact? If $E$ is reflexive, then this is the case, since weak boundedness implies norm boundedness, and it easily follows from Banach-Alaoglu theorem that $K$ is compact (even without convexity). I wonder what happens if we drop the reflexive condition. Any ideas? Thanks! As user1952009 pointed out, the preceding argument also works for non-reflexive Banach spaces, see Given a Banach space $X$, are weak$^*$ bounded subsets of the dual space $X '$ also strongly bounded (with respect to the usual norm in $X '$)? .","Suppose $E$ is a Banach space, and $K\subseteq E^*$ is convex, and is closed and bounded with respect to weak-* topology. Is it true that $K$ is compact? If $E$ is reflexive, then this is the case, since weak boundedness implies norm boundedness, and it easily follows from Banach-Alaoglu theorem that $K$ is compact (even without convexity). I wonder what happens if we drop the reflexive condition. Any ideas? Thanks! As user1952009 pointed out, the preceding argument also works for non-reflexive Banach spaces, see Given a Banach space $X$, are weak$^*$ bounded subsets of the dual space $X '$ also strongly bounded (with respect to the usual norm in $X '$)? .",,"['functional-analysis', 'banach-spaces', 'weak-convergence']"
31,"Is this how we define ""limit in the distributional sense""?","Is this how we define ""limit in the distributional sense""?",,"Consider $\mathcal{D}(\mathbb{R})$ the space of test functions and $\mathcal{D}'(\mathbb{R})$ the space of distributions, in $\mathbb{R}$ , i.e., continuous linear functionals over $\mathcal{D}(\mathbb{R})$ . I've seem some times people talking about ""taking a limit in the distributional sense"". I wondered what this meant and came up with the following: If we have a sequence $(f_n)$ with $f_n\in \mathcal{D}'(\mathbb{R})$ , we may define pointwise convergence by saying that $(f_n)$ converges to $f\in \mathcal{D}'(\mathbb{R})$ if for each $\phi\in \mathcal{D}(\mathbb{R})$ we have that $(f_n(\phi))$ converges to $f(\phi)$ as a sequence of numbers. This definition really says that $(f_n)$ converges to $f$ if $$\lim_{n\to\infty}f_n(\phi)=f(\phi), \quad \forall \phi\in \mathcal{D}(\mathbb{R}). $$ Now in analogy to that I made the following definition: Let $\psi : \mathbb{R}\to \mathcal{D}'(\mathbb{R})$ , and let $a\in \mathbb{R}$ . We say that the limit of $\psi(x)$ when $x$ goes to $a$ is $f\in \mathcal{D}'(\mathbb{R})$ if for every $\phi\in \mathcal{D}(\mathbb{R})$ we have $$\lim_{x\to a}\psi(x)(\phi)=f(\phi),$$ that is I defined the limit in a pointwise fashion. In the particular case where $\psi(x)$ is a function in the usual sense, taking the limit this way is what I believe should be that ""limit in the distributional sense"". Is that conclusion correct? Is this how we define limit of distributions and in particular how we define ""limit in the distributional sense""?","Consider the space of test functions and the space of distributions, in , i.e., continuous linear functionals over . I've seem some times people talking about ""taking a limit in the distributional sense"". I wondered what this meant and came up with the following: If we have a sequence with , we may define pointwise convergence by saying that converges to if for each we have that converges to as a sequence of numbers. This definition really says that converges to if Now in analogy to that I made the following definition: Let , and let . We say that the limit of when goes to is if for every we have that is I defined the limit in a pointwise fashion. In the particular case where is a function in the usual sense, taking the limit this way is what I believe should be that ""limit in the distributional sense"". Is that conclusion correct? Is this how we define limit of distributions and in particular how we define ""limit in the distributional sense""?","\mathcal{D}(\mathbb{R}) \mathcal{D}'(\mathbb{R}) \mathbb{R} \mathcal{D}(\mathbb{R}) (f_n) f_n\in \mathcal{D}'(\mathbb{R}) (f_n) f\in \mathcal{D}'(\mathbb{R}) \phi\in \mathcal{D}(\mathbb{R}) (f_n(\phi)) f(\phi) (f_n) f \lim_{n\to\infty}f_n(\phi)=f(\phi), \quad \forall \phi\in \mathcal{D}(\mathbb{R}).  \psi : \mathbb{R}\to \mathcal{D}'(\mathbb{R}) a\in \mathbb{R} \psi(x) x a f\in \mathcal{D}'(\mathbb{R}) \phi\in \mathcal{D}(\mathbb{R}) \lim_{x\to a}\psi(x)(\phi)=f(\phi), \psi(x)","['functional-analysis', 'limits', 'definition', 'distribution-theory']"
32,What is this operator topology?,What is this operator topology?,,"Let $X$ be a separable Banach space with (norm $1$) Schauder-Basis $\{e_n\}_{n\in\mathbb N}$. Denote for $x\in X$ with $|\cdot|_x$ the seminorm on $\mathcal L(X)$ given by $|A|_x = \|A x\|$. Consider: $$\|\cdot\|_1:=\sum_n 2^{-n} |\cdot|_{e_n} \tag{1}$$ This defines a norm and the topology of this norm is Weaker than the uniform topology: You have $\|A\|≥|A|_{e_n}$ and then $\|A\|=\sum_n 2^{-n} \|A\|≥\sum_n 2^{-n} |A|_{e_n}$. Strictly weaker than uniform topology in the case of $X$ a Hilbert space and $e_n$ ONB: Denote $\pi_n$ the orthogonal projection onto span of $e_n$, then $\sum_{n=N}^\infty \pi_n$ converges to zero in this topology but not in uniform norm. Stronger than the strong operator topology. Becomes equal to the strong operator topology upon restriction to bounded subsets. For 3 and 4 see here . I don't know the relation to the $\sigma$-strong topology (generated by seminorms $\sqrt{\sum_n |\cdot|^2_{x_n}}$ whenever $\sum_n |x_n|^2$ converges), but it looks like this is weaker than the $\sigma$-strong topology. Does this topology have a name? Is it remarkable that it has a norm? A side question, if $\{x_n\}_n$ is a dense countable subset of $X$, then $\|\cdot\|_2:=\sum_n 2^{-n} \frac{|\cdot|_{x_n}}{\|x_n\|}$ gives another norm. I think it is equivalent to the above, but calculation looks unhappy. Is there a reason to expect it to be inequivalent to $\|\cdot\|_1$? Remark: The norm is not submultiplicative, for example on a Hilbert space with $L$ the left shift, $R$ the right shift you have \begin{gather}\|L^k\|_1 = \sum_{n=k+1}^\infty 2^{-n}=2^{-k} \qquad \|R^k\|_1=\sum_{n=1}^\infty 2^{-n}=1\\ \|L^kR^k\|_1=\|\mathbb 1\|_1 =1 \not≤\|L^k\|_1\cdot\|R^k\|_1=2^{-k} \end{gather} This makes it a bit less interesting.","Let $X$ be a separable Banach space with (norm $1$) Schauder-Basis $\{e_n\}_{n\in\mathbb N}$. Denote for $x\in X$ with $|\cdot|_x$ the seminorm on $\mathcal L(X)$ given by $|A|_x = \|A x\|$. Consider: $$\|\cdot\|_1:=\sum_n 2^{-n} |\cdot|_{e_n} \tag{1}$$ This defines a norm and the topology of this norm is Weaker than the uniform topology: You have $\|A\|≥|A|_{e_n}$ and then $\|A\|=\sum_n 2^{-n} \|A\|≥\sum_n 2^{-n} |A|_{e_n}$. Strictly weaker than uniform topology in the case of $X$ a Hilbert space and $e_n$ ONB: Denote $\pi_n$ the orthogonal projection onto span of $e_n$, then $\sum_{n=N}^\infty \pi_n$ converges to zero in this topology but not in uniform norm. Stronger than the strong operator topology. Becomes equal to the strong operator topology upon restriction to bounded subsets. For 3 and 4 see here . I don't know the relation to the $\sigma$-strong topology (generated by seminorms $\sqrt{\sum_n |\cdot|^2_{x_n}}$ whenever $\sum_n |x_n|^2$ converges), but it looks like this is weaker than the $\sigma$-strong topology. Does this topology have a name? Is it remarkable that it has a norm? A side question, if $\{x_n\}_n$ is a dense countable subset of $X$, then $\|\cdot\|_2:=\sum_n 2^{-n} \frac{|\cdot|_{x_n}}{\|x_n\|}$ gives another norm. I think it is equivalent to the above, but calculation looks unhappy. Is there a reason to expect it to be inequivalent to $\|\cdot\|_1$? Remark: The norm is not submultiplicative, for example on a Hilbert space with $L$ the left shift, $R$ the right shift you have \begin{gather}\|L^k\|_1 = \sum_{n=k+1}^\infty 2^{-n}=2^{-k} \qquad \|R^k\|_1=\sum_{n=1}^\infty 2^{-n}=1\\ \|L^kR^k\|_1=\|\mathbb 1\|_1 =1 \not≤\|L^k\|_1\cdot\|R^k\|_1=2^{-k} \end{gather} This makes it a bit less interesting.",,"['general-topology', 'functional-analysis', 'operator-theory', 'normed-spaces', 'operator-algebras']"
33,How is this a Banach space?,How is this a Banach space?,,"Let $k>0$ and $X=\{u\in C([0,+\infty); \sup_{t\geq 0}e^{-kt}\|u(t)\|<\infty\}.$  It is written in the book of Brezis that ""It is easy to check that $X$ is a Banach space for the norm $\|u\|_X=\sup_{t\geq 0}e^{-kt}\|u(t)\|.$"" This is not really easy for me to check. How is this true?","Let $k>0$ and $X=\{u\in C([0,+\infty); \sup_{t\geq 0}e^{-kt}\|u(t)\|<\infty\}.$  It is written in the book of Brezis that ""It is easy to check that $X$ is a Banach space for the norm $\|u\|_X=\sup_{t\geq 0}e^{-kt}\|u(t)\|.$"" This is not really easy for me to check. How is this true?",,"['analysis', 'functional-analysis', 'partial-differential-equations']"
34,$L^{2}$ convergence of sequence $|u_{j}|^{p}\nabla u_{j}$,convergence of sequence,L^{2} |u_{j}|^{p}\nabla u_{j},"Suppose a sequence $\{u_{j}\}$ is bounded in the Sobolev space $H^{2+\epsilon}(\Omega)$, for $\epsilon>0$, where $\Omega$ is say a bounded, $C^{\infty}$ domain. Here, the fractional space $H^{s}(\Omega)$ is defined as the restriction of elements of $H^{s}(\mathbb{R}^{n})$ to $\Omega$, but this definition is equivalent to the usual definition of $W^{s,q}(\Omega)$ by the extension property. By weak* compactness, we have that there is a $u\in H^{2+\epsilon}(\Omega)$ such that (up to a subsequence) $u_{j}\rightharpoonup u$. By Rellich-Kondrachov, $u_{j}\rightarrow u$ in $H^{2}(\Omega)$. In a problem I'm considering, it is stated that $|u_{j}|^{p}\nabla u_{j}\rightarrow |u|^{p}\nabla u$ in $L^{2}(\Omega)$, for certain $p\geq 1$, leaving it to the reader a size condition on $p$ for dimension $n\geq 1$ fixed. I don't know see why this should be true for general $n$. If $n\leq 2$, then there is no issue by Sobolev embedding and Holder's inequality. Suppose $n\geq 3$. Observe that $$\nabla(|u_{j}|^{p+1})=(p+1)|u_{j}|^{p-1}u_{j}\nabla u_{j}$$ If $|u_{j}|^{p}\nabla u_{j}\in L^{2}(\Omega)$, then $\nabla(|u_{j}|^{p+1})\in L^{2}(\Omega)$, so by Poincare inequality $|u_{j}|^{p+1}\in L^{2}(\Omega)$. Suppose $p=1$, then the preceding implies that $u_{j}\in L^{4}(\Omega)$. I don't see why this should hold a priori, since if $n$ is very large then Sobolev embedding will not give that $u_{j}\in L^{4}(\Omega)$. Any thoughts? Does anyone take issue with my argument above?","Suppose a sequence $\{u_{j}\}$ is bounded in the Sobolev space $H^{2+\epsilon}(\Omega)$, for $\epsilon>0$, where $\Omega$ is say a bounded, $C^{\infty}$ domain. Here, the fractional space $H^{s}(\Omega)$ is defined as the restriction of elements of $H^{s}(\mathbb{R}^{n})$ to $\Omega$, but this definition is equivalent to the usual definition of $W^{s,q}(\Omega)$ by the extension property. By weak* compactness, we have that there is a $u\in H^{2+\epsilon}(\Omega)$ such that (up to a subsequence) $u_{j}\rightharpoonup u$. By Rellich-Kondrachov, $u_{j}\rightarrow u$ in $H^{2}(\Omega)$. In a problem I'm considering, it is stated that $|u_{j}|^{p}\nabla u_{j}\rightarrow |u|^{p}\nabla u$ in $L^{2}(\Omega)$, for certain $p\geq 1$, leaving it to the reader a size condition on $p$ for dimension $n\geq 1$ fixed. I don't know see why this should be true for general $n$. If $n\leq 2$, then there is no issue by Sobolev embedding and Holder's inequality. Suppose $n\geq 3$. Observe that $$\nabla(|u_{j}|^{p+1})=(p+1)|u_{j}|^{p-1}u_{j}\nabla u_{j}$$ If $|u_{j}|^{p}\nabla u_{j}\in L^{2}(\Omega)$, then $\nabla(|u_{j}|^{p+1})\in L^{2}(\Omega)$, so by Poincare inequality $|u_{j}|^{p+1}\in L^{2}(\Omega)$. Suppose $p=1$, then the preceding implies that $u_{j}\in L^{4}(\Omega)$. I don't see why this should hold a priori, since if $n$ is very large then Sobolev embedding will not give that $u_{j}\in L^{4}(\Omega)$. Any thoughts? Does anyone take issue with my argument above?",,"['real-analysis', 'functional-analysis', 'sobolev-spaces']"
35,The space of test-functions carries any other structure on it?,The space of test-functions carries any other structure on it?,,I'm starting to study distributions and on the lecture notes I'm reading the author defines a test-function as a function $f : U\subset \mathbb{R}^n\to \mathbb{R}$ which is infinitely differentiable and has compact support. He denotes the set of test-functions on $U$ by $\mathcal{D}(U)$. It is obvious then that the set of test-functions carries a natural structure of a vector-space when we consider the usual pointwise addition and multiplication by scalar. My question is: this space $\mathcal{D}(U)$ carries any other natural structure like that of a metric or normed vector space? Or for the purposes of distribution theory it is just always treated as a vector space without any topological or metric notions defined on it?,I'm starting to study distributions and on the lecture notes I'm reading the author defines a test-function as a function $f : U\subset \mathbb{R}^n\to \mathbb{R}$ which is infinitely differentiable and has compact support. He denotes the set of test-functions on $U$ by $\mathcal{D}(U)$. It is obvious then that the set of test-functions carries a natural structure of a vector-space when we consider the usual pointwise addition and multiplication by scalar. My question is: this space $\mathcal{D}(U)$ carries any other natural structure like that of a metric or normed vector space? Or for the purposes of distribution theory it is just always treated as a vector space without any topological or metric notions defined on it?,,"['real-analysis', 'linear-algebra', 'functional-analysis', 'distribution-theory']"
36,On the in-comparability of the Gauss-Seidel and Jacobi iteration schemes.,On the in-comparability of the Gauss-Seidel and Jacobi iteration schemes.,,Given the system $x_1 + x_2 = 2$ $-x_1 + x_2=0$ $x_1 + 2x_2 - 3x_3=0$ the Jacobi iteration converges and Gauss-Seidel iteration diverges. Is there a way we can derive these two facts using the fact that the system $x = Cx + B$ of $n$ linear equations in $n$ unknowns converges if the matrix $C$ has a spectral radius of less than $1$? Thanks for your help.,Given the system $x_1 + x_2 = 2$ $-x_1 + x_2=0$ $x_1 + 2x_2 - 3x_3=0$ the Jacobi iteration converges and Gauss-Seidel iteration diverges. Is there a way we can derive these two facts using the fact that the system $x = Cx + B$ of $n$ linear equations in $n$ unknowns converges if the matrix $C$ has a spectral radius of less than $1$? Thanks for your help.,,"['functional-analysis', 'numerical-methods', 'fixed-point-theorems']"
37,"Weak Topology: Show $\sigma(X_1 \times X_2, (X_1 \times X_2)^*) = \sigma(X_1,X_1^*) \times \sigma(X_2,X_2^*)$",Weak Topology: Show,"\sigma(X_1 \times X_2, (X_1 \times X_2)^*) = \sigma(X_1,X_1^*) \times \sigma(X_2,X_2^*)","$X_1$ and $X_2$ are Banach Spaces. As stated in the title I want to prove that $$\sigma(X_1 \times X_2, (X_1 \times X_2)^*) = \sigma(X_1,X_1^*) \times \sigma(X_2,X_2^*)$$ where $\sigma(A,A^*)$ denotes the weak topology, i.e. this is the weakest topology on $A$ s.t. every $f \in A^*$ is continuous. And $A^*$ is the dual space of $A$, i.e. in $A^*$ are all bounded linear operators from $A$ to $\mathbb{C}$. I had to prove a statement for homework and I just used this property but in the correction it was stated that I this property doesn't follow immediately. I want to give my ideas to this: (As stated in the comments this approach doesn't really work.) $\subset$ : Let $U$ be in the left hand side, i.e. $U \subset X_1 \times X_2$ s.t. $$U=f^{-1} (W)=(f_1^{-1} (W), f_2^{-1} (W))$$ for $W \subset \mathbb{C}$ open and $f \in (X_1 \times X_2)^*$. Denote $U_1:=f_1^{-1}(W)$ and $U_2:=f_2^{-1}(W)$, i.e. $U_1 \in \sigma(X_1,X_1^*)$ and $U_2 \in \sigma(X_2,X_2^*)$. By the product topology it follows $$U_1+U_2 \in \sigma(X_1,X_1^*) \times \sigma(X_2,X_2^*)$$ I don't know if this really works, this weak topology is new to me and hard to handle. Would be grateful for any help, Thanks a lot, Marvin","$X_1$ and $X_2$ are Banach Spaces. As stated in the title I want to prove that $$\sigma(X_1 \times X_2, (X_1 \times X_2)^*) = \sigma(X_1,X_1^*) \times \sigma(X_2,X_2^*)$$ where $\sigma(A,A^*)$ denotes the weak topology, i.e. this is the weakest topology on $A$ s.t. every $f \in A^*$ is continuous. And $A^*$ is the dual space of $A$, i.e. in $A^*$ are all bounded linear operators from $A$ to $\mathbb{C}$. I had to prove a statement for homework and I just used this property but in the correction it was stated that I this property doesn't follow immediately. I want to give my ideas to this: (As stated in the comments this approach doesn't really work.) $\subset$ : Let $U$ be in the left hand side, i.e. $U \subset X_1 \times X_2$ s.t. $$U=f^{-1} (W)=(f_1^{-1} (W), f_2^{-1} (W))$$ for $W \subset \mathbb{C}$ open and $f \in (X_1 \times X_2)^*$. Denote $U_1:=f_1^{-1}(W)$ and $U_2:=f_2^{-1}(W)$, i.e. $U_1 \in \sigma(X_1,X_1^*)$ and $U_2 \in \sigma(X_2,X_2^*)$. By the product topology it follows $$U_1+U_2 \in \sigma(X_1,X_1^*) \times \sigma(X_2,X_2^*)$$ I don't know if this really works, this weak topology is new to me and hard to handle. Would be grateful for any help, Thanks a lot, Marvin",,"['general-topology', 'functional-analysis']"
38,Uniqueness of weak solutions and the Riesz Representation Theorem,Uniqueness of weak solutions and the Riesz Representation Theorem,,"A common technique to show existence of weak solutions to the problem $Lu=f$ is to obtain an energy estimate of the form: $$\| u\|\leqslant\| L^{*}u\| $$ and the define the functional $$k(L^{*}v)=\int fv.$$ Then using the Hanh–Banach theorem together with the Riesz representation theorem one can find a $u$ such that $$ k(L^{*}v)=\int fv=\int uL^{*}v,$$ which shows that $u$ is a weak solution. Isn't uniqueness also immediate from the Riesz Representation Theorem? I usually see that people use again the energy inequality and show that the difference of the two solutions satisfying the same data is zero when dealing with hyperbolic system whereas when the problem is elliptic they use this argument. Why is that step needed?","A common technique to show existence of weak solutions to the problem $Lu=f$ is to obtain an energy estimate of the form: $$\| u\|\leqslant\| L^{*}u\| $$ and the define the functional $$k(L^{*}v)=\int fv.$$ Then using the Hanh–Banach theorem together with the Riesz representation theorem one can find a $u$ such that $$ k(L^{*}v)=\int fv=\int uL^{*}v,$$ which shows that $u$ is a weak solution. Isn't uniqueness also immediate from the Riesz Representation Theorem? I usually see that people use again the energy inequality and show that the difference of the two solutions satisfying the same data is zero when dealing with hyperbolic system whereas when the problem is elliptic they use this argument. Why is that step needed?",,"['functional-analysis', 'partial-differential-equations', 'riesz-representation-theorem']"
39,why dual of $l_1$ norm is $l_\infty$ and vice versa,why dual of  norm is  and vice versa,l_1 l_\infty,"This might be a very dumb question but I am having a hard time to understand why dual of $l_1$ norm is $l_\infty$ and vice versa. The dual of a norm is denoted $\lVert\cdot\rVert_*$, defined as $$ \lVert z\rVert_*=\sup\left\{z^Tx\mid\: \lVert x\rVert\leq1\right\} $$ and $l_1$ norm is, $$ \lVert x\rVert_1 = \sum(|x_i|) $$ and $l_\infty$ norm is, $$ \lVert x\rVert_\infty = \max(|x_1|,...,|x_n|) $$ I am very confused on dual norm. Any explanation would be very helpful. Thanks","This might be a very dumb question but I am having a hard time to understand why dual of $l_1$ norm is $l_\infty$ and vice versa. The dual of a norm is denoted $\lVert\cdot\rVert_*$, defined as $$ \lVert z\rVert_*=\sup\left\{z^Tx\mid\: \lVert x\rVert\leq1\right\} $$ and $l_1$ norm is, $$ \lVert x\rVert_1 = \sum(|x_i|) $$ and $l_\infty$ norm is, $$ \lVert x\rVert_\infty = \max(|x_1|,...,|x_n|) $$ I am very confused on dual norm. Any explanation would be very helpful. Thanks",,"['linear-algebra', 'functional-analysis', 'convex-analysis']"
40,Definition of essential spectrum?,Definition of essential spectrum?,,"Suppose we have a Hilbert space $\mathscr{H}$ and a bounded linear map $T\in\mathscr{B(H)}$ NOT necessarily self-adjoint. There seems to be loads of definitions of the essential spectrum of $T$. My question is, whether in the Hilbert space setting the following are equivalent: $\lambda$ is such that $T-\lambda{I}$ is not Fredholm $\lambda$ is in $\sigma(T)\backslash\sigma_{d}(T)$ where $\sigma_{d}(T)$ denotes the set of isolated points of the spectrum (discrete spectrum).","Suppose we have a Hilbert space $\mathscr{H}$ and a bounded linear map $T\in\mathscr{B(H)}$ NOT necessarily self-adjoint. There seems to be loads of definitions of the essential spectrum of $T$. My question is, whether in the Hilbert space setting the following are equivalent: $\lambda$ is such that $T-\lambda{I}$ is not Fredholm $\lambda$ is in $\sigma(T)\backslash\sigma_{d}(T)$ where $\sigma_{d}(T)$ denotes the set of isolated points of the spectrum (discrete spectrum).",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory']"
41,Riesz-Type Representation Theorems for Convex Functionals,Riesz-Type Representation Theorems for Convex Functionals,,"It is well known that any positive linear functional $L$ on the spase $C_c([a,b])$ of functions continuous on an interval $[a,b]$ with compact support can be written as  \begin{align*} L(x)=\int_a^bx(t)d\mu(t),\qquad x\in C_c([a,b]), \end{align*} where $\mu$ is some proper Radon-measure. The question for me now arises, if there are any similar results, if $L$ is only a convex functional. To be precise, my questions are (1) Let $X$ be a real vector space of measurable functions $[a,b]\to\mathbb R$, and let $L:X\to[0,\infty)$ be a convex functional. Does there exist a convex function $\varphi:\mathbb R\to[0,\infty)$ and a Borel/Radon measure $\mu$ such that \begin{align*}     L(x)=\int_a^b\varphi(x(t))\mu(t),\qquad x\in X? \end{align*} (2) What conditions on $X$ and maybe on $L$ have to be added such that a representation of the aforementioned kind is possible? (3) If equality cannot be achieved, is it possible to estimate $L$ from above and below by integrals like those in (1)? Any help is highly appreciated, and any literature recommendations are very welcome. Thanks in advance!","It is well known that any positive linear functional $L$ on the spase $C_c([a,b])$ of functions continuous on an interval $[a,b]$ with compact support can be written as  \begin{align*} L(x)=\int_a^bx(t)d\mu(t),\qquad x\in C_c([a,b]), \end{align*} where $\mu$ is some proper Radon-measure. The question for me now arises, if there are any similar results, if $L$ is only a convex functional. To be precise, my questions are (1) Let $X$ be a real vector space of measurable functions $[a,b]\to\mathbb R$, and let $L:X\to[0,\infty)$ be a convex functional. Does there exist a convex function $\varphi:\mathbb R\to[0,\infty)$ and a Borel/Radon measure $\mu$ such that \begin{align*}     L(x)=\int_a^b\varphi(x(t))\mu(t),\qquad x\in X? \end{align*} (2) What conditions on $X$ and maybe on $L$ have to be added such that a representation of the aforementioned kind is possible? (3) If equality cannot be achieved, is it possible to estimate $L$ from above and below by integrals like those in (1)? Any help is highly appreciated, and any literature recommendations are very welcome. Thanks in advance!",,"['integration', 'functional-analysis', 'measure-theory']"
42,Null Functional on $l^2$,Null Functional on,l^2,"Let $l^2$ be the hilbert space of all complex sequences $\psi= (\psi_n)_{n=0}^{\infty}$ such that $\sum_{j=0}^{\infty} |\psi_j |^2 < \infty$. Let $\phi= (\phi_n)_{n=0}^{\infty}$ be a sequence of complex numbers, and $S$ a vector subspace of $l^2$ which is dense in $l^2$. Assume that for all $\psi = (\psi_n)_{n=0}^{\infty}$ in $S$, we have  \begin{equation} \sum_{n=0}^{\infty} \bar{\phi_n} \psi_n = 0. \end{equation} Can we conclude that $\phi=0$? What if we only suppose that $S$ is a dense subset of $l^2$? Please note that I am not assuming that $\phi$ is in $l^2$, otherwise the answer to both questions is trivially yes (take a sequence $\psi^{(N)}$ in $S$ converging to $\phi$ and use the continuity of the scalar product). PS The motivation for this question is the following. Set $D= \{ \phi \in l^2 : \sum_{j=0}^{\infty} j |\phi_j |^2 < \infty \}$ and consider the operator $X$ on $D$ which associates to each $\phi \in D$ the vector $X \phi$ whose j-th component (j=0,1,2,...) is $(X \phi)_j = \sqrt{j+1} \psi_{j+1} + \sqrt{j} \psi_{j-1}$, where we set $\psi_{-1}=0$. We have for every $\phi \in l^2 , \psi \in D$  \begin{equation} \sum_{j=0}^{\infty} \bar{\phi_j} [\sqrt{j+1} \psi_{j+1} + \sqrt{j} \psi_{j-1}] = \sum_{j=0}^{\infty} \psi_j \overline{ [\sqrt{j+1} \phi_{j+1} + \sqrt{j} \phi_{j-1}]}, \end{equation}  where again we set $\phi_{-1}=0$. So in particular, $X$ is a symmetric operator. But it is not self-adjoint. To see this, consider the vector $\phi$ whose j-th component is $\phi_j = (-1)^{\lfloor j/2 \rfloor} j^{-\beta}$, where $1/2 < \beta <1$. Is is easy to see that $\phi \in l^2 \backslash D$, and that the vector whose j-th component  is $\sqrt{j+1} \phi_{j+1} + \sqrt{j} \phi_{j-1}$ is in $l^2$, so $\phi$ belongs to the domain of the adjoint. I conjectured that the domain of the adjoint $X^{*}$ is exactly the set of all vectors $\phi \in l^2$ such that $ \sum_{j=0}^{\infty}  |\sqrt{j+1} \phi_{j+1} + \sqrt{j} \phi_{j-1} |^2 < \infty$. This is the point where my question comes into play. If the answer to the question I posted were affirmative, then it would be easy, by using riesz theorem, to prove my conjecture.","Let $l^2$ be the hilbert space of all complex sequences $\psi= (\psi_n)_{n=0}^{\infty}$ such that $\sum_{j=0}^{\infty} |\psi_j |^2 < \infty$. Let $\phi= (\phi_n)_{n=0}^{\infty}$ be a sequence of complex numbers, and $S$ a vector subspace of $l^2$ which is dense in $l^2$. Assume that for all $\psi = (\psi_n)_{n=0}^{\infty}$ in $S$, we have  \begin{equation} \sum_{n=0}^{\infty} \bar{\phi_n} \psi_n = 0. \end{equation} Can we conclude that $\phi=0$? What if we only suppose that $S$ is a dense subset of $l^2$? Please note that I am not assuming that $\phi$ is in $l^2$, otherwise the answer to both questions is trivially yes (take a sequence $\psi^{(N)}$ in $S$ converging to $\phi$ and use the continuity of the scalar product). PS The motivation for this question is the following. Set $D= \{ \phi \in l^2 : \sum_{j=0}^{\infty} j |\phi_j |^2 < \infty \}$ and consider the operator $X$ on $D$ which associates to each $\phi \in D$ the vector $X \phi$ whose j-th component (j=0,1,2,...) is $(X \phi)_j = \sqrt{j+1} \psi_{j+1} + \sqrt{j} \psi_{j-1}$, where we set $\psi_{-1}=0$. We have for every $\phi \in l^2 , \psi \in D$  \begin{equation} \sum_{j=0}^{\infty} \bar{\phi_j} [\sqrt{j+1} \psi_{j+1} + \sqrt{j} \psi_{j-1}] = \sum_{j=0}^{\infty} \psi_j \overline{ [\sqrt{j+1} \phi_{j+1} + \sqrt{j} \phi_{j-1}]}, \end{equation}  where again we set $\phi_{-1}=0$. So in particular, $X$ is a symmetric operator. But it is not self-adjoint. To see this, consider the vector $\phi$ whose j-th component is $\phi_j = (-1)^{\lfloor j/2 \rfloor} j^{-\beta}$, where $1/2 < \beta <1$. Is is easy to see that $\phi \in l^2 \backslash D$, and that the vector whose j-th component  is $\sqrt{j+1} \phi_{j+1} + \sqrt{j} \phi_{j-1}$ is in $l^2$, so $\phi$ belongs to the domain of the adjoint. I conjectured that the domain of the adjoint $X^{*}$ is exactly the set of all vectors $\phi \in l^2$ such that $ \sum_{j=0}^{\infty}  |\sqrt{j+1} \phi_{j+1} + \sqrt{j} \phi_{j-1} |^2 < \infty$. This is the point where my question comes into play. If the answer to the question I posted were affirmative, then it would be easy, by using riesz theorem, to prove my conjecture.",,"['sequences-and-series', 'functional-analysis', 'hilbert-spaces']"
43,Separable Kernel in Volterra integral equation,Separable Kernel in Volterra integral equation,,"I can't get my head around why the kernel in the Volterra integral equation can't be separable.  $$u(x) = f(x) + \int_a^x K(x,s)u(s)ds, x \in [a,b]$$ A separable kernel $K(x,s)$ is the one that can be rewritten in the form of  $$K(x,s ) = \sum_{i=1}^NA_i(x)B_i(s ).$$ It's supposed to be a ""text book"" problem, and the hint is ""$K(x,s)=0$ when $s>x$"", which really doesn't help much at all. I tried to somehow use the fact that it can be rewritten as the Fredholm integral equation in a triangle area: $\hat{K}(x,s)=\begin{cases} K(x,s) & a\leq s\leq x\\ 0 & x\leq s\leq b \end{cases}$ but so far no luck. Edit: It seems that for the condition ""$K(x,s)=0$ when $s>x$"" to hold, if we assume separability, then we can't effectively make it zero. Either $A_i(x)$ will depend on s ($A_i(x)=0$ when $x<s$) or $B_i(s)$ will depend on x ($B_i(s)=0$ when $s>x$). This contradicts separability. Thoughts?","I can't get my head around why the kernel in the Volterra integral equation can't be separable.  $$u(x) = f(x) + \int_a^x K(x,s)u(s)ds, x \in [a,b]$$ A separable kernel $K(x,s)$ is the one that can be rewritten in the form of  $$K(x,s ) = \sum_{i=1}^NA_i(x)B_i(s ).$$ It's supposed to be a ""text book"" problem, and the hint is ""$K(x,s)=0$ when $s>x$"", which really doesn't help much at all. I tried to somehow use the fact that it can be rewritten as the Fredholm integral equation in a triangle area: $\hat{K}(x,s)=\begin{cases} K(x,s) & a\leq s\leq x\\ 0 & x\leq s\leq b \end{cases}$ but so far no luck. Edit: It seems that for the condition ""$K(x,s)=0$ when $s>x$"" to hold, if we assume separability, then we can't effectively make it zero. Either $A_i(x)$ will depend on s ($A_i(x)=0$ when $x<s$) or $B_i(s)$ will depend on x ($B_i(s)=0$ when $s>x$). This contradicts separability. Thoughts?",,"['linear-algebra', 'integration', 'functional-analysis', 'integral-equations']"
44,"Cesaro and Tandori sequence spaces, representations and duality","Cesaro and Tandori sequence spaces, representations and duality",,"Definitions. Fix $1\leq p\leq\infty$.  Given a scalar sequence $a=(a_n)_{n=1}^\infty$, denote by $\tilde{a}=(\tilde{a}_n)_{n=1}^\infty$, where each $\tilde{a}_n=\sup_{k\geq n}|a_k|$.  Now we define the $\boldsymbol{p}$-Tandori sequence space as the vector space $\widetilde{\ell}_p$ of scalar sequences $a$ such that \begin{equation}\|a\|_{\widetilde{p}}:=\|\tilde{a}\|_p<\infty,\end{equation} where $\|\cdot\|_p$ denotes the usual $\ell_p$ norm. We define the $\boldsymbol{p}$-Cesàro sequence space as follows.  For a scalar sequence $a=(a_n)_{n=1}^\infty$ let us define $c(a)=\left(\frac{1}{n}\sum_{k=1}^n|a_k|\right)_{n=1}^\infty$, and denote by $ces_p$ the space of all scalar sequences $a$ such that \begin{equation}\|a\|_{c(p)}:=\|c(a)\|_p<\infty.\end{equation} Note that the canonical unit vectors $(e_n)_{n=1}^\infty$ form a (nonnormalized) basic sequence in $\widetilde{\ell}_p$, and this is a basis for the space as long as $p\neq\infty$.  The same holds for $ces_p$.  Note also that these spaces are all complete, i.e. all Banach spaces. Background. The space $ces_p$ is reflexive for $1<p<\infty$.  In Corollary 3 of this paper it is shown that \begin{equation}\overline{\ell}_1\cong\left(\oplus_{n=0}^\infty\ell_\infty^{2^n}\right)_1\end{equation} and \begin{equation}ces_\infty=\overline{\ell}_1^*=\left(\oplus_{n=0}^\infty\ell_1^{2^n}\right)_\infty.\end{equation} It is also known that $ces_\infty^0$ (the closed span $[e_n]_{n=1}^\infty$ in $ces_\infty$) that \begin{equation}ces_\infty^{0*}=\widetilde{\ell}_1.\end{equation} Question 1. Is it true that $ces_\infty^0\cong\left(\oplus_{n=0}^\infty\ell_1^{2^n}\right)_{c_0}?$ Question 2. Is it true that $ces_p^*\cong\widetilde{\ell}_{p'}$, $\frac{1}{p}+\frac{1}{p'}=1$, for $1<p<\infty$? Question 3. Do $ces_p$ and $\widetilde{\ell}_p$ have similar representationss as above, i.e. something like $\left(\oplus_{n=0}^\infty\ell_{p'}^{2^n}\right)_p$ or something like that? Question 4. What is the dual and/or predual of $ces_1$? Thank you!","Definitions. Fix $1\leq p\leq\infty$.  Given a scalar sequence $a=(a_n)_{n=1}^\infty$, denote by $\tilde{a}=(\tilde{a}_n)_{n=1}^\infty$, where each $\tilde{a}_n=\sup_{k\geq n}|a_k|$.  Now we define the $\boldsymbol{p}$-Tandori sequence space as the vector space $\widetilde{\ell}_p$ of scalar sequences $a$ such that \begin{equation}\|a\|_{\widetilde{p}}:=\|\tilde{a}\|_p<\infty,\end{equation} where $\|\cdot\|_p$ denotes the usual $\ell_p$ norm. We define the $\boldsymbol{p}$-Cesàro sequence space as follows.  For a scalar sequence $a=(a_n)_{n=1}^\infty$ let us define $c(a)=\left(\frac{1}{n}\sum_{k=1}^n|a_k|\right)_{n=1}^\infty$, and denote by $ces_p$ the space of all scalar sequences $a$ such that \begin{equation}\|a\|_{c(p)}:=\|c(a)\|_p<\infty.\end{equation} Note that the canonical unit vectors $(e_n)_{n=1}^\infty$ form a (nonnormalized) basic sequence in $\widetilde{\ell}_p$, and this is a basis for the space as long as $p\neq\infty$.  The same holds for $ces_p$.  Note also that these spaces are all complete, i.e. all Banach spaces. Background. The space $ces_p$ is reflexive for $1<p<\infty$.  In Corollary 3 of this paper it is shown that \begin{equation}\overline{\ell}_1\cong\left(\oplus_{n=0}^\infty\ell_\infty^{2^n}\right)_1\end{equation} and \begin{equation}ces_\infty=\overline{\ell}_1^*=\left(\oplus_{n=0}^\infty\ell_1^{2^n}\right)_\infty.\end{equation} It is also known that $ces_\infty^0$ (the closed span $[e_n]_{n=1}^\infty$ in $ces_\infty$) that \begin{equation}ces_\infty^{0*}=\widetilde{\ell}_1.\end{equation} Question 1. Is it true that $ces_\infty^0\cong\left(\oplus_{n=0}^\infty\ell_1^{2^n}\right)_{c_0}?$ Question 2. Is it true that $ces_p^*\cong\widetilde{\ell}_{p'}$, $\frac{1}{p}+\frac{1}{p'}=1$, for $1<p<\infty$? Question 3. Do $ces_p$ and $\widetilde{\ell}_p$ have similar representationss as above, i.e. something like $\left(\oplus_{n=0}^\infty\ell_{p'}^{2^n}\right)_p$ or something like that? Question 4. What is the dual and/or predual of $ces_1$? Thank you!",,"['sequences-and-series', 'functional-analysis', 'banach-spaces', 'duality-theorems', 'cesaro-summable']"
45,Function $f:\mathbb{R}^k \rightarrow \mathbb{H}$ is differentiable if partial derivatives are continuous.,Function  is differentiable if partial derivatives are continuous.,f:\mathbb{R}^k \rightarrow \mathbb{H},"Let $f: \mathbb{R}^k \rightarrow \mathbb{H}$ be a function from the euclidean space to a Hilbert space. Is it true that if the partial derivatives are continuous, then $f$ is differentiable? (the partial derivatives are defined in the analogous manner: $\lim_{h \rightarrow 0} \frac{f(x+he_i)-f(x)}{h}$). I tried to repeat the proof of the euclidean case, but it uses the mean value theorem. Maybe we could use the mean value inequality, since its proof uses the inner product, but I wasn't able to pinpoint how to use it exactly...","Let $f: \mathbb{R}^k \rightarrow \mathbb{H}$ be a function from the euclidean space to a Hilbert space. Is it true that if the partial derivatives are continuous, then $f$ is differentiable? (the partial derivatives are defined in the analogous manner: $\lim_{h \rightarrow 0} \frac{f(x+he_i)-f(x)}{h}$). I tried to repeat the proof of the euclidean case, but it uses the mean value theorem. Maybe we could use the mean value inequality, since its proof uses the inner product, but I wasn't able to pinpoint how to use it exactly...",,"['real-analysis', 'functional-analysis']"
46,Show precompactness for not necessarily continuous functions,Show precompactness for not necessarily continuous functions,,"I know that for showing precompactness of subsets of continuous functions, Arzelà-Ascoli is the tool of choice. However, the setting I'm facing here are functions in $L^1$. More precisely: Let   $$ \begin{align} E_1 &= \{ f:(0,1)\to\mathbb{R}:\,f(x) = x^{-\alpha},\,0\leq\alpha < 1\}\\ E_2 &= \{ f:(0,1)\to\mathbb{R}:\,f(x)=x^{-\alpha},\,-\infty < \alpha\leq 1-\delta\}\text{ with fixed } \delta > 0\\ E_3 &= \{ f:(0,1)\to\mathbb{R}:\,f(x) = \sin(\omega x),\,\omega\in\mathbb{R}\} \end{align} $$   Show whether those sets are bounded and/or precompact as subsets of $L^1((0,1))$. Boundedness is clear, we can just calculate the anti-derivative for functions from $E_1$ and $E_2$ and see that they need to be bounded for functions from $E_2$ but not for functions from $E_1$. For $E_3$ just estimate $\sin(x) \leq 1$ and you see that $E_3$ is also bounded. Now how to show precompactness? I need to show that for all $\varepsilon>0$ there is a finite covering of $E_1,E_2,E_3$ using $\varepsilon$-balls (or not). In my opinion we need to somehow select a finite family of functions from $E_i$, say $f^i_1,\dots,f^i_k$ s.t. all $f^i\in E_i$ belong to some ball $$B(f_j^i,\varepsilon) =  \{g\in E_i:\, \|f_j^i - g\|_{L^1} < \varepsilon\}$$ I don't understand how to choose such a set. My intuition for this is: $$\text{bounded} \Leftrightarrow \text{Precompact}$$ which is obviously wrong. Maybe someone can show me how to start this. Thanks a lot!","I know that for showing precompactness of subsets of continuous functions, Arzelà-Ascoli is the tool of choice. However, the setting I'm facing here are functions in $L^1$. More precisely: Let   $$ \begin{align} E_1 &= \{ f:(0,1)\to\mathbb{R}:\,f(x) = x^{-\alpha},\,0\leq\alpha < 1\}\\ E_2 &= \{ f:(0,1)\to\mathbb{R}:\,f(x)=x^{-\alpha},\,-\infty < \alpha\leq 1-\delta\}\text{ with fixed } \delta > 0\\ E_3 &= \{ f:(0,1)\to\mathbb{R}:\,f(x) = \sin(\omega x),\,\omega\in\mathbb{R}\} \end{align} $$   Show whether those sets are bounded and/or precompact as subsets of $L^1((0,1))$. Boundedness is clear, we can just calculate the anti-derivative for functions from $E_1$ and $E_2$ and see that they need to be bounded for functions from $E_2$ but not for functions from $E_1$. For $E_3$ just estimate $\sin(x) \leq 1$ and you see that $E_3$ is also bounded. Now how to show precompactness? I need to show that for all $\varepsilon>0$ there is a finite covering of $E_1,E_2,E_3$ using $\varepsilon$-balls (or not). In my opinion we need to somehow select a finite family of functions from $E_i$, say $f^i_1,\dots,f^i_k$ s.t. all $f^i\in E_i$ belong to some ball $$B(f_j^i,\varepsilon) =  \{g\in E_i:\, \|f_j^i - g\|_{L^1} < \varepsilon\}$$ I don't understand how to choose such a set. My intuition for this is: $$\text{bounded} \Leftrightarrow \text{Precompact}$$ which is obviously wrong. Maybe someone can show me how to start this. Thanks a lot!",,"['complex-analysis', 'functional-analysis', 'compactness']"
47,"If $f:X \rightarrow Y$ is a linear isomorphism between $X$ and $f(X)$, then show that there exists a continuous linear map from $Y^*$ onto $X^*$","If  is a linear isomorphism between  and , then show that there exists a continuous linear map from  onto",f:X \rightarrow Y X f(X) Y^* X^*,"For any $x \in X$, define the set $\mathcal{F}(X) = \overline{\operatorname{span} \{ \delta_x : x \in X \}}$ where $\delta_x(f)=f(x)$ for all $f \in$ $\operatorname{Lip}_0(X)$. The set $\operatorname{Lip}_0(X)$ is the set of all real-valued Lipschitz functions which vanish at $0$. Note that $\delta_x$ is an evaluation functional on $\operatorname{Lip}_0(X)$ and  dual space of $\mathcal{F}(X)$ is $Lip_0(X)$. In the proof of theorem $7$ , which states that $\mathcal{F}([0,1])$ is not linearly isomorphic to $L_1(\mu)$ for every measure $\mu$, the author states the following: If there is a measure $\mu$ with $\mathcal{F}([0,1])$ linearly isomorphic to a subspace of $L_1(\mu)$, then there is a continuous linear mapping from $L_{\infty}(\mu)$ onto $Lip_0([0,1])$. Since $L_{\infty}(\mu)$ is a commutative C$^*$-algebra, there exists a compact Hausdorff space $K$ such that $L_{\infty}(\mu)$ is isometric to $C(K)$. Question: How to prove the above two statements? For first statement, I think we use adjoint mapping, but I don't know how to apply it here. For the second, it resembles the Stone-Weierstrass theorem.","For any $x \in X$, define the set $\mathcal{F}(X) = \overline{\operatorname{span} \{ \delta_x : x \in X \}}$ where $\delta_x(f)=f(x)$ for all $f \in$ $\operatorname{Lip}_0(X)$. The set $\operatorname{Lip}_0(X)$ is the set of all real-valued Lipschitz functions which vanish at $0$. Note that $\delta_x$ is an evaluation functional on $\operatorname{Lip}_0(X)$ and  dual space of $\mathcal{F}(X)$ is $Lip_0(X)$. In the proof of theorem $7$ , which states that $\mathcal{F}([0,1])$ is not linearly isomorphic to $L_1(\mu)$ for every measure $\mu$, the author states the following: If there is a measure $\mu$ with $\mathcal{F}([0,1])$ linearly isomorphic to a subspace of $L_1(\mu)$, then there is a continuous linear mapping from $L_{\infty}(\mu)$ onto $Lip_0([0,1])$. Since $L_{\infty}(\mu)$ is a commutative C$^*$-algebra, there exists a compact Hausdorff space $K$ such that $L_{\infty}(\mu)$ is isometric to $C(K)$. Question: How to prove the above two statements? For first statement, I think we use adjoint mapping, but I don't know how to apply it here. For the second, it resembles the Stone-Weierstrass theorem.",,"['functional-analysis', 'banach-spaces']"
48,What is a distribution in $H^{-1}(\Omega)$?,What is a distribution in ?,H^{-1}(\Omega),"Let $\Omega$ be an open bounded subset of $\mathbb{R}^n$ with $\partial \Omega$ being $C^2$. Suppose $u\in H^1_0(\Omega)$, $f\in L^2(\Omega)$ and $\nu>0$. It is said in the Navier-Stokes Equations by Constantin and Foias (in the chapter about weak solutions of the Stokes Equations) that $\nu \Delta u+ f$ is a distribution in $H^{-1}(\Omega)$ where $H^{-1}(\Omega)$ is defined as the continuous dual of $H^1(\Omega)$ and  $$ H_0^1(\Omega):=\overline{C_c^\infty(\Omega)}^{\|\cdot\|_{H^1(\Omega)}}. $$ I can understand that $L:=\nu \Delta u+ f$ is a distribution since $$ H_0^1(\Omega)\subset L^2(\Omega)\subset L_{\textrm{loc}}^1(\Omega) $$ and any function in $L_{\textrm{loc}}^1(\Omega)$ can be identified as a distribution , which is a function from $C_c^\infty(\Omega)$ to $\mathbb{R}.$ Here is my question : What does ""$L$ is in $H^{-1}(\Omega)$"" mean?","Let $\Omega$ be an open bounded subset of $\mathbb{R}^n$ with $\partial \Omega$ being $C^2$. Suppose $u\in H^1_0(\Omega)$, $f\in L^2(\Omega)$ and $\nu>0$. It is said in the Navier-Stokes Equations by Constantin and Foias (in the chapter about weak solutions of the Stokes Equations) that $\nu \Delta u+ f$ is a distribution in $H^{-1}(\Omega)$ where $H^{-1}(\Omega)$ is defined as the continuous dual of $H^1(\Omega)$ and  $$ H_0^1(\Omega):=\overline{C_c^\infty(\Omega)}^{\|\cdot\|_{H^1(\Omega)}}. $$ I can understand that $L:=\nu \Delta u+ f$ is a distribution since $$ H_0^1(\Omega)\subset L^2(\Omega)\subset L_{\textrm{loc}}^1(\Omega) $$ and any function in $L_{\textrm{loc}}^1(\Omega)$ can be identified as a distribution , which is a function from $C_c^\infty(\Omega)$ to $\mathbb{R}.$ Here is my question : What does ""$L$ is in $H^{-1}(\Omega)$"" mean?",,"['real-analysis', 'functional-analysis']"
49,A sufficient and necessary condition for a distribution to be tempered.,A sufficient and necessary condition for a distribution to be tempered.,,"Show that the distribution $F$ is tempered if and only if there is an integer $N$ and a constant $A$,so that for all $R\geq 1$,  $$F(\varphi)\leq AR^N sup_{|x|\leq R,0\leq |\alpha|\leq N}|\partial_x^\alpha\varphi(x)|$$ for all $\varphi\in\mathcal{D}$ supported in $|x|\leq R$. The 'only if' part is obvious by the necessary and sufficient condition that $F$ is tempered iff $F(\varphi)\leq c||\varphi||_N$ for all $\varphi\in\mathcal{S}$.But I don't know how the prove the converse.","Show that the distribution $F$ is tempered if and only if there is an integer $N$ and a constant $A$,so that for all $R\geq 1$,  $$F(\varphi)\leq AR^N sup_{|x|\leq R,0\leq |\alpha|\leq N}|\partial_x^\alpha\varphi(x)|$$ for all $\varphi\in\mathcal{D}$ supported in $|x|\leq R$. The 'only if' part is obvious by the necessary and sufficient condition that $F$ is tempered iff $F(\varphi)\leq c||\varphi||_N$ for all $\varphi\in\mathcal{S}$.But I don't know how the prove the converse.",,"['functional-analysis', 'distribution-theory']"
50,Rellich-Kondrachov compacteness theorem for the Euclidean space with Gaussian measure,Rellich-Kondrachov compacteness theorem for the Euclidean space with Gaussian measure,,"Let $\gamma_n: \mathbb{R}^n\to\mathbb{R}$ be the Gaussian distribution function defined by  $$ \gamma_n(x):=(2 \pi)^{-\frac{n}{2}} e^{-\frac{|x|^2}{2}}. $$ Let $d\gamma_n$ denote the following measure (weight) $\gamma_n(x) dx$ and consequently $L^2(\mathbb{R}^n,d\gamma_n)$ and $H^1(\mathbb{R}^n,d\gamma_n)$ be the weighted versions of the Sobolev spaces with respect to the measure $d\gamma_n$. Does the following weighted version of the Rellich-Kondrachov Theorem hold? $$ H^1(\mathbb{R}^n,d\gamma_n) \text{ is } \textbf{compactly} \text{ embedded in } L^2(\mathbb{R}^n,d\gamma_n). $$","Let $\gamma_n: \mathbb{R}^n\to\mathbb{R}$ be the Gaussian distribution function defined by  $$ \gamma_n(x):=(2 \pi)^{-\frac{n}{2}} e^{-\frac{|x|^2}{2}}. $$ Let $d\gamma_n$ denote the following measure (weight) $\gamma_n(x) dx$ and consequently $L^2(\mathbb{R}^n,d\gamma_n)$ and $H^1(\mathbb{R}^n,d\gamma_n)$ be the weighted versions of the Sobolev spaces with respect to the measure $d\gamma_n$. Does the following weighted version of the Rellich-Kondrachov Theorem hold? $$ H^1(\mathbb{R}^n,d\gamma_n) \text{ is } \textbf{compactly} \text{ embedded in } L^2(\mathbb{R}^n,d\gamma_n). $$",,"['functional-analysis', 'compactness', 'sobolev-spaces']"
51,"Weirdly defined ball compact in $C^1([0, 1])$",Weirdly defined ball compact in,"C^1([0, 1])","Consider$$B := \left\{u \in C^2([0, 1]) : \sum_{i=0}^2 \sup_{x \in [0, 1]} \left|u^{(i)}(x)\right| \le 1\right\}$$as a subset of $C^1([0, 1])$. How do I see that it is compact in $C^1([0, 1])$?","Consider$$B := \left\{u \in C^2([0, 1]) : \sum_{i=0}^2 \sup_{x \in [0, 1]} \left|u^{(i)}(x)\right| \le 1\right\}$$as a subset of $C^1([0, 1])$. How do I see that it is compact in $C^1([0, 1])$?",,"['calculus', 'real-analysis']"
52,"Exist unique $f \in C([0, 1])$ such that $f(x) = \int_0^x K(x, y)\,f(y)\,dy + g(x)?$",Exist unique  such that,"f \in C([0, 1]) f(x) = \int_0^x K(x, y)\,f(y)\,dy + g(x)?","Let $K \in C([0, 1] \times [0, 1])$ and $g \in C([0, 1])$. Does there exist a unique $f \in C([0, 1])$ such that, for all $x \in [0, 1]$, we have$$f(x) = \int_0^x K(x, y)\,f(y)\,dy + g(x)?$$","Let $K \in C([0, 1] \times [0, 1])$ and $g \in C([0, 1])$. Does there exist a unique $f \in C([0, 1])$ such that, for all $x \in [0, 1]$, we have$$f(x) = \int_0^x K(x, y)\,f(y)\,dy + g(x)?$$",,"['calculus', 'real-analysis']"
53,Rigorous proof of this limit,Rigorous proof of this limit,,"I have shown that the function $$f(x):=\int_{[-\pi,\pi]^n} \frac{e^{-i\langle k,x \rangle}}{1-\frac{1}{n} \sum_{i=1}^n \cos(k_i)}dk$$ exists everywhere for $n \ge 3$. Now, I want to show that $\lim_{x \rightarrow \infty} f(x) \|x\|^{n-2}=c$ for some non-zero constant $c.$ Here $\lim_{x \rightarrow \infty}$ means that $x_1,\ldots,x_n \rightarrow \infty.$ Does anybody know how to do this?","I have shown that the function $$f(x):=\int_{[-\pi,\pi]^n} \frac{e^{-i\langle k,x \rangle}}{1-\frac{1}{n} \sum_{i=1}^n \cos(k_i)}dk$$ exists everywhere for $n \ge 3$. Now, I want to show that $\lim_{x \rightarrow \infty} f(x) \|x\|^{n-2}=c$ for some non-zero constant $c.$ Here $\lim_{x \rightarrow \infty}$ means that $x_1,\ldots,x_n \rightarrow \infty.$ Does anybody know how to do this?",,"['calculus', 'real-analysis', 'analysis', 'functional-analysis', 'fourier-analysis']"
54,Fractional Sobolev Space Trace Inequality,Fractional Sobolev Space Trace Inequality,,"Let $\phi\in\mathcal{S}(\mathbb{R}^{n})$ be a Schwartz function, such that ${\phi}\equiv 1$ on the unit ball $|\xi|\leq 1$ and $\text{supp}({\phi})\subset B_{2}(0)$. Set $\phi_{0}=\phi$ and $\phi_{j}=\phi(2^{-j}\cdot)-\phi(2^{-j+1}\cdot)$ for $j\geq 1$. Write $P_{j}f:=(\widehat{f}{\phi}_{j})^{\vee}$. For $1<p<\infty$ and $s\in\mathbb{R}$, define the space $H^{s,p}(\mathbb{R}^{n})$ by     $$H^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \left\|\left(\sum_{j=0}^{\infty}2^{2js}|P_{j}f|^{2}\right)^{1/2}\right\|_{L^{p}}<\infty\right\}$$ One can show that $H^{s,p}$ is equivalent to the Bessel potential space $\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : ((1+|\xi|^{2})^{s/2}\widehat{f})^{\vee}\in L^{p}(\mathbb{R}^{n})\right\}$ with an equivalence of norms. $H^{s,p}$ is a special case of the Triebel-Lizorkin space $F_{p,q}^{s}$, where the $2$ above is replace by $0<q\leq\infty$. Similarly, for $0<p<\infty$, and $0<q<\infty$, we define the Besov space $B_{p,q}^{s}(\mathbb{R}^{n})$ by     $$B_{p,q}^{s}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \left(\sum_{j=0}^{\infty}2^{jqs}\|P_{j}f\|_{L^{p}}^{q}\right)^{1/q}<\infty\right\}, \quad B_{p,\infty}^{s}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \sup_{j}2^{js}\|P_{j}f\|_{L^{p}}<\infty\right\}$$ Using the following lemma, Lemma. Let $n\geq 2$. Suppose $f\in L^{p}(\mathbb{R}^{n})$ has Fourier support in the ball $|\xi|\leq R$, then $\|f\|_{L^{p}(\mathbb{R}^{n-1})}\leq R^{1/p}\|f\|_{L^{p}(\mathbb{R}^{n})}$ for $1\leq p\leq\infty$. I am trying to show that for $f\in\mathcal{S}(\mathbb{R}^{n})$, where $n>1$, the trace $f(\cdot,0)$ on $\mathbb{R}^{n-1}$ satisfies     $$\|f(\cdot,0)\|_{H^{s-\sigma,p}(\mathbb{R}^{n-1})}\lesssim_{n,p,s,}\|f\|_{H^{s,p}(\mathbb{R}^{n})}\tag{*}$$ where $1/p<\sigma\leq s$. I can establish the lemma, and by applying the lemma to the Littlewood-Paley projections $P_{k}f$, I believe that I can show that for $f\in\mathcal{S}(\mathbb{R}^{n})$, we have     $$\|f(\cdot,0)\|_{B_{p,q}^{s-1/p}(\mathbb{R}^{n-1})}\leq\|f\|_{B_{p,q}^{s}(\mathbb{R}^{n})}$$ where $1<p<\infty$, $1\leq q\leq\infty$, and $s>1/p$. Let us abuse notation, and write $f$ instead of $f(\cdot,0)$ for the trace of $f$ on the hyperplane $\mathbb{R}^{n-1}\subset\mathbb{R}^{n}$. Now we have the following embeddings, which can readily be verified from Minkowski's integral inequality and the nesting property of sequence spaces,     $$B_{p,1}^{s}({\mathbb{R}^{m}})\hookrightarrow H^{s,p}(\mathbb{R}^{m})\hookrightarrow B_{p,\max\{2,p\}}^{s}(\mathbb{R}^{m}),\quad B_{p,q}^{s+\epsilon}(\mathbb{R}^{m})\hookrightarrow B_{p,r}^{s}(\mathbb{R}^{m})$$ for $1<p<\infty$, $0<q\leq \infty$, and $0<r\leq\infty$, $\epsilon>0$, and $m\geq 1$. Combining these two facts, we obtain that for any $s>\sigma>1/p$,     $$H^{s,p}(\mathbb{R}^{n})\hookrightarrow B_{p,\max\{2,p\}}^{s}(\mathbb{R}^{n})\hookrightarrow B_{p,\max\{2,p\}}^{s-1/p}(\mathbb{R}^{n-1})\hookrightarrow B_{p,1}^{s-\sigma}(\mathbb{R}^{n-1})\hookrightarrow H^{s-\sigma,p}(\mathbb{R}^{n-1})$$ since $s-1/p>s-\sigma$. Note, implicitly I'm using the density of Schwartz functions in these spaces to obtain a bounded operator on the whole space, but this isn't an issue. I feel like there is a more direct and elegant route for establishing the trace inequality that doesn't make use of embeddings between the Sobolev space $H^{s,p}$ and the Besov spaces, which I am failing to see. Unfortunately, no one is around right now due to the holiday due to discuss the matter, so I thought I turned to Math SE for thoughts.","Let $\phi\in\mathcal{S}(\mathbb{R}^{n})$ be a Schwartz function, such that ${\phi}\equiv 1$ on the unit ball $|\xi|\leq 1$ and $\text{supp}({\phi})\subset B_{2}(0)$. Set $\phi_{0}=\phi$ and $\phi_{j}=\phi(2^{-j}\cdot)-\phi(2^{-j+1}\cdot)$ for $j\geq 1$. Write $P_{j}f:=(\widehat{f}{\phi}_{j})^{\vee}$. For $1<p<\infty$ and $s\in\mathbb{R}$, define the space $H^{s,p}(\mathbb{R}^{n})$ by     $$H^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \left\|\left(\sum_{j=0}^{\infty}2^{2js}|P_{j}f|^{2}\right)^{1/2}\right\|_{L^{p}}<\infty\right\}$$ One can show that $H^{s,p}$ is equivalent to the Bessel potential space $\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : ((1+|\xi|^{2})^{s/2}\widehat{f})^{\vee}\in L^{p}(\mathbb{R}^{n})\right\}$ with an equivalence of norms. $H^{s,p}$ is a special case of the Triebel-Lizorkin space $F_{p,q}^{s}$, where the $2$ above is replace by $0<q\leq\infty$. Similarly, for $0<p<\infty$, and $0<q<\infty$, we define the Besov space $B_{p,q}^{s}(\mathbb{R}^{n})$ by     $$B_{p,q}^{s}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \left(\sum_{j=0}^{\infty}2^{jqs}\|P_{j}f\|_{L^{p}}^{q}\right)^{1/q}<\infty\right\}, \quad B_{p,\infty}^{s}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \sup_{j}2^{js}\|P_{j}f\|_{L^{p}}<\infty\right\}$$ Using the following lemma, Lemma. Let $n\geq 2$. Suppose $f\in L^{p}(\mathbb{R}^{n})$ has Fourier support in the ball $|\xi|\leq R$, then $\|f\|_{L^{p}(\mathbb{R}^{n-1})}\leq R^{1/p}\|f\|_{L^{p}(\mathbb{R}^{n})}$ for $1\leq p\leq\infty$. I am trying to show that for $f\in\mathcal{S}(\mathbb{R}^{n})$, where $n>1$, the trace $f(\cdot,0)$ on $\mathbb{R}^{n-1}$ satisfies     $$\|f(\cdot,0)\|_{H^{s-\sigma,p}(\mathbb{R}^{n-1})}\lesssim_{n,p,s,}\|f\|_{H^{s,p}(\mathbb{R}^{n})}\tag{*}$$ where $1/p<\sigma\leq s$. I can establish the lemma, and by applying the lemma to the Littlewood-Paley projections $P_{k}f$, I believe that I can show that for $f\in\mathcal{S}(\mathbb{R}^{n})$, we have     $$\|f(\cdot,0)\|_{B_{p,q}^{s-1/p}(\mathbb{R}^{n-1})}\leq\|f\|_{B_{p,q}^{s}(\mathbb{R}^{n})}$$ where $1<p<\infty$, $1\leq q\leq\infty$, and $s>1/p$. Let us abuse notation, and write $f$ instead of $f(\cdot,0)$ for the trace of $f$ on the hyperplane $\mathbb{R}^{n-1}\subset\mathbb{R}^{n}$. Now we have the following embeddings, which can readily be verified from Minkowski's integral inequality and the nesting property of sequence spaces,     $$B_{p,1}^{s}({\mathbb{R}^{m}})\hookrightarrow H^{s,p}(\mathbb{R}^{m})\hookrightarrow B_{p,\max\{2,p\}}^{s}(\mathbb{R}^{m}),\quad B_{p,q}^{s+\epsilon}(\mathbb{R}^{m})\hookrightarrow B_{p,r}^{s}(\mathbb{R}^{m})$$ for $1<p<\infty$, $0<q\leq \infty$, and $0<r\leq\infty$, $\epsilon>0$, and $m\geq 1$. Combining these two facts, we obtain that for any $s>\sigma>1/p$,     $$H^{s,p}(\mathbb{R}^{n})\hookrightarrow B_{p,\max\{2,p\}}^{s}(\mathbb{R}^{n})\hookrightarrow B_{p,\max\{2,p\}}^{s-1/p}(\mathbb{R}^{n-1})\hookrightarrow B_{p,1}^{s-\sigma}(\mathbb{R}^{n-1})\hookrightarrow H^{s-\sigma,p}(\mathbb{R}^{n-1})$$ since $s-1/p>s-\sigma$. Note, implicitly I'm using the density of Schwartz functions in these spaces to obtain a bounded operator on the whole space, but this isn't an issue. I feel like there is a more direct and elegant route for establishing the trace inequality that doesn't make use of embeddings between the Sobolev space $H^{s,p}$ and the Besov spaces, which I am failing to see. Unfortunately, no one is around right now due to the holiday due to discuss the matter, so I thought I turned to Math SE for thoughts.",,"['functional-analysis', 'sobolev-spaces', 'harmonic-analysis', 'besov-space', 'littlewood-paley-theory']"
55,"Adjoint of the derivative operator on $C([0,1])$",Adjoint of the derivative operator on,"C([0,1])","Let $D \colon \operatorname{dom}(D) = C^1[0,1] \subseteq C[0,1] \to C[0,1]$ be the derivative unbounded operator $D(f) = f'$.  Since $C^1$ is dense in $C$ we can define the adjoint operator  $$D^* \colon \operatorname{dom}(D^*) \subseteq C[0,1]^* \to C[0,1]^*$$ We can identify $C[0,1]^*$ with the space of all bounded signed measures $M([0,1])$ and hence we can characterize $\operatorname{dom}(D^*)$ by the set of all bounded signed measures $\mu$ such that $$f \to \int_0^1 f'd\mu$$ is continuous. I want to use some kind of integration by parts but the only thing that I know is that $\mu$ is a Lebesgue-Stieltjes measure represented by the càdlàg with bounded variation function $$F(x) = \mu((0,x])$$ Any help will be appreciated.","Let $D \colon \operatorname{dom}(D) = C^1[0,1] \subseteq C[0,1] \to C[0,1]$ be the derivative unbounded operator $D(f) = f'$.  Since $C^1$ is dense in $C$ we can define the adjoint operator  $$D^* \colon \operatorname{dom}(D^*) \subseteq C[0,1]^* \to C[0,1]^*$$ We can identify $C[0,1]^*$ with the space of all bounded signed measures $M([0,1])$ and hence we can characterize $\operatorname{dom}(D^*)$ by the set of all bounded signed measures $\mu$ such that $$f \to \int_0^1 f'd\mu$$ is continuous. I want to use some kind of integration by parts but the only thing that I know is that $\mu$ is a Lebesgue-Stieltjes measure represented by the càdlàg with bounded variation function $$F(x) = \mu((0,x])$$ Any help will be appreciated.",,"['functional-analysis', 'measure-theory']"
56,Is the Laplace Beltrami operator a uniformly elliptic operator?,Is the Laplace Beltrami operator a uniformly elliptic operator?,,"The condition of uniform ellipticty for an operator $L=    (-1)^k\sum_{\alpha} a_\alpha(x)\partial^{\alpha}$  is expressed as the condition that: $$    (-1)^k\sum_{|\alpha| = 2k} a_\alpha(x) \xi^\alpha > C |\xi|^{2k},\, $$ for every non-zero $\xi$ in $\mathbb{R}^{d}$ A usual example of these type of operators is the Laplacian . A natural generalization of the Laplacian in a Rimaniann manifold is the Laplace-Beltrami operator. My question is: What are the geometrical and regularity conditions on the metric such that the Laplace Beltrami operator is a strongly elliptic operator?","The condition of uniform ellipticty for an operator $L=    (-1)^k\sum_{\alpha} a_\alpha(x)\partial^{\alpha}$  is expressed as the condition that: $$    (-1)^k\sum_{|\alpha| = 2k} a_\alpha(x) \xi^\alpha > C |\xi|^{2k},\, $$ for every non-zero $\xi$ in $\mathbb{R}^{d}$ A usual example of these type of operators is the Laplacian . A natural generalization of the Laplacian in a Rimaniann manifold is the Laplace-Beltrami operator. My question is: What are the geometrical and regularity conditions on the metric such that the Laplace Beltrami operator is a strongly elliptic operator?",,"['functional-analysis', 'partial-differential-equations']"
57,Multi-index notation confusion,Multi-index notation confusion,,"While trying to understand a proof of equivalence of norms for $H^k(\mathbb{R}^n)$ (Fourier Transforms) I came across a possible inconsistency in the multi-index notation. Can somebody please clarify it for me? It is surprisingly hard to find it explained clearly anywhere. Suppose $x \in \mathbb{R}^n$ and that $\alpha = (\alpha_1,...,\alpha_n)$ is a multi-index. In lines with the multi-index notation we have $x^{\alpha} = x_{1}^{\alpha_1}...x_{n}^{\alpha_n}$. But then what is $|x^{\alpha}|^2$? If we were to be consistent then $|x^{\alpha}|^2 = |x_{1}^{\alpha_1}...x_{n}^{\alpha_n}|^2$, but that's not what is meant in this scenario, right? Here $|x^{\alpha}|^2 = \sum_{i=1}^n (x_i^{\alpha_i})^2$ or something like this, as with $|x|^2 = \sum_{i=1}^n x_i^2 $ See this question for some reference: Sobolev spaces fourier norm equivalence or Evans book on PDEs, Theorem 8, page 297, which is exactly about proving this result. I am perhaps completely in the dark about the problem and simply there is here a mixture of a notational confusion plus me not understanding the proof. I would have commented on the referenced question to ask for some insight, but being a completely new user I am not allowed to. I would really appreciate any feedback (also about asking questions here as it is my first attempt). Thank you!","While trying to understand a proof of equivalence of norms for $H^k(\mathbb{R}^n)$ (Fourier Transforms) I came across a possible inconsistency in the multi-index notation. Can somebody please clarify it for me? It is surprisingly hard to find it explained clearly anywhere. Suppose $x \in \mathbb{R}^n$ and that $\alpha = (\alpha_1,...,\alpha_n)$ is a multi-index. In lines with the multi-index notation we have $x^{\alpha} = x_{1}^{\alpha_1}...x_{n}^{\alpha_n}$. But then what is $|x^{\alpha}|^2$? If we were to be consistent then $|x^{\alpha}|^2 = |x_{1}^{\alpha_1}...x_{n}^{\alpha_n}|^2$, but that's not what is meant in this scenario, right? Here $|x^{\alpha}|^2 = \sum_{i=1}^n (x_i^{\alpha_i})^2$ or something like this, as with $|x|^2 = \sum_{i=1}^n x_i^2 $ See this question for some reference: Sobolev spaces fourier norm equivalence or Evans book on PDEs, Theorem 8, page 297, which is exactly about proving this result. I am perhaps completely in the dark about the problem and simply there is here a mixture of a notational confusion plus me not understanding the proof. I would have commented on the referenced question to ask for some insight, but being a completely new user I am not allowed to. I would really appreciate any feedback (also about asking questions here as it is my first attempt). Thank you!",,"['functional-analysis', 'sobolev-spaces']"
58,Why are separation results important in analysis?,Why are separation results important in analysis?,,"I found in a book on real analysis in the part concerning linear functionals (and the Hahn-Banach theorem) that a relevant result – that relies on Hahn-Banach Theorem – is that for every pair of distinct vectors $x,y \in X$, with $X$ vector space, there are enough bounded linear functionals to separate the points of $X$. Thus, I have the following intertwined questions : Why all these separation results are important (beyond the fact that they are important in themselves)? What do we get from them in terms of far-reaching conclusions? What do we miss when we work with generic spaces without this property? The question goes beyond functional analysis, and it is quite general. I can see that for example separation results are important for optimization , but I am wondering if there is something more (way more) that I do not (cannot) see. Any feedback is most welcome.","I found in a book on real analysis in the part concerning linear functionals (and the Hahn-Banach theorem) that a relevant result – that relies on Hahn-Banach Theorem – is that for every pair of distinct vectors $x,y \in X$, with $X$ vector space, there are enough bounded linear functionals to separate the points of $X$. Thus, I have the following intertwined questions : Why all these separation results are important (beyond the fact that they are important in themselves)? What do we get from them in terms of far-reaching conclusions? What do we miss when we work with generic spaces without this property? The question goes beyond functional analysis, and it is quite general. I can see that for example separation results are important for optimization , but I am wondering if there is something more (way more) that I do not (cannot) see. Any feedback is most welcome.",,"['real-analysis', 'functional-analysis']"
59,"Given a function $\phi$ and the set of iterates $(\phi^t)$ under self-composition, can you construct $\phi^t $ for a real continuous parameter?","Given a function  and the set of iterates  under self-composition, can you construct  for a real continuous parameter?",\phi (\phi^t) \phi^t ,"$\phi$ is given as any function with the following properties: 1. $\phi$ is strictly increasing 2. $\phi$ is continuous 3. $\phi$ is a mapping of the interval $[0,1]$ into itself. 4. $\phi^n\circ\phi^m = \phi^{n+m} = \phi^{m+n}$ 5. $\phi^0 = x$ is the identity map. Consider the set $S$ of all $\phi$'s self-iterates, denoted $S = \{\phi^t : \forall t \in\mathbb{Z}^+\}$. In case it is unclear what I mean by $\phi^t$, or self-iterates, here are some examples: $\phi^1(x) = \phi(x)$ $\phi^2(x) = \phi^1\circ\phi^1(x)$ $\phi^3(x) = \phi^1\circ\phi^1\circ\phi^1(x) = \phi^2\circ\phi^1(x) = \phi^1\circ\phi^2(x)$ QUESTION: Given the definitions above, is it possible to construct  $\phi^t$ for a real non-negative continuous parameter $t$, such that the new set $S' = \{\phi^t : \forall t \in\mathbb{R}^+\}$ is isomorphic to the non-negative real numbers under multiplication? **Comments: I am an undergraduate and I honestly don't even feel like I understand the problem well enough to propose a strategy for proving it, let alone a formal proof. If anyone could explain the problem itself in less technical terms I would really appreciate it, but for the time being I have no clue how to proceed. My professor suggested splitting $\phi$ into piece-wise linear components, but he didn't say what to do after that. ***Final note: If at all possible I would really appreciate if you ""dumbed-down"" any explanations to an undergraduate level for me. Please assume that I don't know anything beyond undergraduate analysis and abstract algebra. This is my first question on this site, so I'm sorry if I didn't format something the right way or follow etiquette.","$\phi$ is given as any function with the following properties: 1. $\phi$ is strictly increasing 2. $\phi$ is continuous 3. $\phi$ is a mapping of the interval $[0,1]$ into itself. 4. $\phi^n\circ\phi^m = \phi^{n+m} = \phi^{m+n}$ 5. $\phi^0 = x$ is the identity map. Consider the set $S$ of all $\phi$'s self-iterates, denoted $S = \{\phi^t : \forall t \in\mathbb{Z}^+\}$. In case it is unclear what I mean by $\phi^t$, or self-iterates, here are some examples: $\phi^1(x) = \phi(x)$ $\phi^2(x) = \phi^1\circ\phi^1(x)$ $\phi^3(x) = \phi^1\circ\phi^1\circ\phi^1(x) = \phi^2\circ\phi^1(x) = \phi^1\circ\phi^2(x)$ QUESTION: Given the definitions above, is it possible to construct  $\phi^t$ for a real non-negative continuous parameter $t$, such that the new set $S' = \{\phi^t : \forall t \in\mathbb{R}^+\}$ is isomorphic to the non-negative real numbers under multiplication? **Comments: I am an undergraduate and I honestly don't even feel like I understand the problem well enough to propose a strategy for proving it, let alone a formal proof. If anyone could explain the problem itself in less technical terms I would really appreciate it, but for the time being I have no clue how to proceed. My professor suggested splitting $\phi$ into piece-wise linear components, but he didn't say what to do after that. ***Final note: If at all possible I would really appreciate if you ""dumbed-down"" any explanations to an undergraduate level for me. Please assume that I don't know anything beyond undergraduate analysis and abstract algebra. This is my first question on this site, so I'm sorry if I didn't format something the right way or follow etiquette.",,"['abstract-algebra', 'functional-analysis', 'functions']"
60,Why do these Integration-by-Parts Evaluation Terms Vanish?,Why do these Integration-by-Parts Evaluation Terms Vanish?,,"The Associated Legendre operator is $$                L_mf = -\frac{d}{dx}\left((1-x^{2})\frac{df}{dx}\right)+\frac{m^{2}}{1-x^{2}}f, $$ where $m$ is a positive integer. For the purposes here, define the domain $\mathcal{D}(L_m)$ to be the set of twice continuously differentiable real functions on $(-1,1)$ for which $f, L_m f \in L^{2}(-1,1)$. Question: Does anyone know a way to directly verify that $$     \int_{-1}^{1}\{ L_m f \}g-f\{ L_m g \} dx = (1-x^{2})\{fg'-f'g\}|_{-1}^{1} = 0, $$ for all $f,g\in\mathcal{D}(L_m)$? The integral on the left exists because the product of two square integrable functions is absolutely integrable. So the evaluation terms on the right exist as limits at $\pm 1$. The trick is to show that these limits are $0$. Background: The Associated Legendre operators show up when studying the Laplacian on the sphere. It is true that the integration by parts evaluation terms must vanish, and this can be proved indirectly by applying techniques of Functional Analysis to the operator $L_m$. It seems to me that there should be a direct way to verify such a fact using only techniques of Calculus. This is a curiosity, not some kind of homework problem, or an exercise from a text. I've tried many things and have gotten nowhere. :)","The Associated Legendre operator is $$                L_mf = -\frac{d}{dx}\left((1-x^{2})\frac{df}{dx}\right)+\frac{m^{2}}{1-x^{2}}f, $$ where $m$ is a positive integer. For the purposes here, define the domain $\mathcal{D}(L_m)$ to be the set of twice continuously differentiable real functions on $(-1,1)$ for which $f, L_m f \in L^{2}(-1,1)$. Question: Does anyone know a way to directly verify that $$     \int_{-1}^{1}\{ L_m f \}g-f\{ L_m g \} dx = (1-x^{2})\{fg'-f'g\}|_{-1}^{1} = 0, $$ for all $f,g\in\mathcal{D}(L_m)$? The integral on the left exists because the product of two square integrable functions is absolutely integrable. So the evaluation terms on the right exist as limits at $\pm 1$. The trick is to show that these limits are $0$. Background: The Associated Legendre operators show up when studying the Laplacian on the sphere. It is true that the integration by parts evaluation terms must vanish, and this can be proved indirectly by applying techniques of Functional Analysis to the operator $L_m$. It seems to me that there should be a direct way to verify such a fact using only techniques of Calculus. This is a curiosity, not some kind of homework problem, or an exercise from a text. I've tried many things and have gotten nowhere. :)",,"['real-analysis', 'functional-analysis', 'ordinary-differential-equations', 'operator-theory']"
61,Linear finite-dimensional topological vector space is closed.,Linear finite-dimensional topological vector space is closed.,,"Suppose $X$ is a topological vector space and let $Y \subset X$ be its subspace with $\dim Y < \infty$. The goal is to prove that $Y$ is closed in $X$. I know how to prove this fact when $X$ is endowed with a norm by picking up a Cauchy sequence, but could you please suggest me, how to do it when we do not have any norm?","Suppose $X$ is a topological vector space and let $Y \subset X$ be its subspace with $\dim Y < \infty$. The goal is to prove that $Y$ is closed in $X$. I know how to prove this fact when $X$ is endowed with a norm by picking up a Cauchy sequence, but could you please suggest me, how to do it when we do not have any norm?",,"['functional-analysis', 'topological-vector-spaces']"
62,Outline of Generic Separable Banach Spaces don't have a Schauder Basis,Outline of Generic Separable Banach Spaces don't have a Schauder Basis,,"So, I know P. Enflo showed that there is a separable Banach Space that doesn't satisfy the approximation property. My professor mentioned during class that in fact generic separable Banach Spaces don't have a Schauder basis where generic is in terms of Baire Category with some topology. I was hoping someone could outline how we put a topology on the space of all Banach Spaces in order to show dense $G_{\delta}$. Also, an outline of how we show density since I assume we end up showing comeagerness of our set.","So, I know P. Enflo showed that there is a separable Banach Space that doesn't satisfy the approximation property. My professor mentioned during class that in fact generic separable Banach Spaces don't have a Schauder basis where generic is in terms of Baire Category with some topology. I was hoping someone could outline how we put a topology on the space of all Banach Spaces in order to show dense $G_{\delta}$. Also, an outline of how we show density since I assume we end up showing comeagerness of our set.",,"['functional-analysis', 'banach-spaces', 'descriptive-set-theory', 'baire-category', 'schauder-basis']"
63,A reference for existence/uniqueness theorem for an ODE with Carathéodory condition,A reference for existence/uniqueness theorem for an ODE with Carathéodory condition,,"Can anyone name good reference for proof of this version of existence theorem in ODE please. I'm tired of googling and finding nothing. $$\frac{du}{dt}=f(t,u(t))\qquad\text{for a.a. }t\in I, \qquad u(0)=u_0\tag{1.65}$$ Theorem 1.45. (Existence and uniqueness) Let $T$ be fixed and $f \colon \mathbb I \times \mathbb R^k \to \mathbb R^k$ be a Carathéodory mapping satisfying the growth condition $|f(t,r)| \le \gamma(t)+C|r|$ with some $\gamma\in L^1(I)$. Then: The initial value problem (1.65) has a solution $u\in W^{1,1}(I;\mathbb R^k)$ on the interval $I=[0,T]$. If $f(t,\cdot)$ is also Lipschitz continuous in the sense $|f(t,r_1)-f(t,r_2)| \le \ell (t) |r_1-r_2|$ with some $\ell \in L^1(I)$, then the solution is unique.","Can anyone name good reference for proof of this version of existence theorem in ODE please. I'm tired of googling and finding nothing. $$\frac{du}{dt}=f(t,u(t))\qquad\text{for a.a. }t\in I, \qquad u(0)=u_0\tag{1.65}$$ Theorem 1.45. (Existence and uniqueness) Let $T$ be fixed and $f \colon \mathbb I \times \mathbb R^k \to \mathbb R^k$ be a Carathéodory mapping satisfying the growth condition $|f(t,r)| \le \gamma(t)+C|r|$ with some $\gamma\in L^1(I)$. Then: The initial value problem (1.65) has a solution $u\in W^{1,1}(I;\mathbb R^k)$ on the interval $I=[0,T]$. If $f(t,\cdot)$ is also Lipschitz continuous in the sense $|f(t,r_1)-f(t,r_2)| \le \ell (t) |r_1-r_2|$ with some $\ell \in L^1(I)$, then the solution is unique.",,"['functional-analysis', 'ordinary-differential-equations', 'reference-request']"
64,proving a quadratic form is closed,proving a quadratic form is closed,,"I'm trying to show that, given a spectral measure $d\mu_\psi(\lambda)$ for a self-adjont operator $A$, for the following quadratic form $$q_\lambda(\psi)=\int_{\mathbb R}\chi_{(-\infty,\lambda]}(\tau) d\mu_\psi (\tau)$$ there exists an operator $P(\lambda)$ such that: $$<\psi|P(\lambda)\psi>= q_\lambda(\psi)$$ In particular, $q_\lambda(\psi)$ is bounded from below and so I have just to prove that it is closed. Well, I know that in order to show closedness I should prove that the domain of the quadratic form $Q$ is complete with respect to the norm form $$||\psi||_q= q_\lambda(\psi)+||\psi||_H$$ where $H$ is our generic Hilbert space. I have some troubles proving this, since chosen a Cauchy sequence on $H$, I can't understand how $q_\lambda(\psi_n-\psi_m)$ behaves. Any help would be greatly apppreciated!","I'm trying to show that, given a spectral measure $d\mu_\psi(\lambda)$ for a self-adjont operator $A$, for the following quadratic form $$q_\lambda(\psi)=\int_{\mathbb R}\chi_{(-\infty,\lambda]}(\tau) d\mu_\psi (\tau)$$ there exists an operator $P(\lambda)$ such that: $$<\psi|P(\lambda)\psi>= q_\lambda(\psi)$$ In particular, $q_\lambda(\psi)$ is bounded from below and so I have just to prove that it is closed. Well, I know that in order to show closedness I should prove that the domain of the quadratic form $Q$ is complete with respect to the norm form $$||\psi||_q= q_\lambda(\psi)+||\psi||_H$$ where $H$ is our generic Hilbert space. I have some troubles proving this, since chosen a Cauchy sequence on $H$, I can't understand how $q_\lambda(\psi_n-\psi_m)$ behaves. Any help would be greatly apppreciated!",,"['functional-analysis', 'spectral-theory', 'quantum-mechanics']"
65,Progressed : Convergence problem in Hilbert Space and necessity of inner product,Progressed : Convergence problem in Hilbert Space and necessity of inner product,,"******** PROGRESS : so thanks to Ian's great comment I can get by the proof and that completeness is necessary but I need to know does this hold for general Banach spaces that are not Hilbert spaces? I have this assignment question from Functional Analysis class stating: Let $ \mathcal{H} $ be a Hilbert Space with a sequence $ \{x_n\}_{n=1}^{\infty} $ of elements in $ \mathcal{H} $. There is a constant $ A \in R $ such that for every sequence $ \{a_n\}_{n=1}^{\infty}  $ satisfying $ 0 \leq |a_n| \leq 1 $ all zero except a finite number of elements, we have ||$ \sum_{n} a_nx_n $|| $ \leq $ A. We are asked to prove $\lim_{N\to\infty} {\sum_{n=1}^{N} x_n}$ exists in the norm. Also, does this hold if the space H is not complete? What about a norm space where the norm is not induced from an inner product? Last part before this I proved: For all $ \{ x_n \}_{n=1}^N \in \mathcal{H} $ there are scalars $ \{ a_n \}_{n=1}^N $ on the complex unit circle such that : $||\sum_{n=1}^{N} a_nx_n ||^2 \geq \sum_{n=1}^{N} ||x_n||^2 $ I don't exactly know how to incorporate that previous part or if I even need to for that matter. I would really appreciate help. PROGRESS : so thanks to Ian's great comment I can get by the proof and that completeness is necessary but I need to know does this hold for general Banach spaces that are not Hilbert spaces?","******** PROGRESS : so thanks to Ian's great comment I can get by the proof and that completeness is necessary but I need to know does this hold for general Banach spaces that are not Hilbert spaces? I have this assignment question from Functional Analysis class stating: Let $ \mathcal{H} $ be a Hilbert Space with a sequence $ \{x_n\}_{n=1}^{\infty} $ of elements in $ \mathcal{H} $. There is a constant $ A \in R $ such that for every sequence $ \{a_n\}_{n=1}^{\infty}  $ satisfying $ 0 \leq |a_n| \leq 1 $ all zero except a finite number of elements, we have ||$ \sum_{n} a_nx_n $|| $ \leq $ A. We are asked to prove $\lim_{N\to\infty} {\sum_{n=1}^{N} x_n}$ exists in the norm. Also, does this hold if the space H is not complete? What about a norm space where the norm is not induced from an inner product? Last part before this I proved: For all $ \{ x_n \}_{n=1}^N \in \mathcal{H} $ there are scalars $ \{ a_n \}_{n=1}^N $ on the complex unit circle such that : $||\sum_{n=1}^{N} a_nx_n ||^2 \geq \sum_{n=1}^{N} ||x_n||^2 $ I don't exactly know how to incorporate that previous part or if I even need to for that matter. I would really appreciate help. PROGRESS : so thanks to Ian's great comment I can get by the proof and that completeness is necessary but I need to know does this hold for general Banach spaces that are not Hilbert spaces?",,"['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'normed-spaces', 'inner-products']"
66,Mistake in reasoning about Sobolev spaces,Mistake in reasoning about Sobolev spaces,,"I am new to Sobolev spaces and, while trying to construct a proof, I make some subtle mistake that I cannot detect. The setting: let $C \subset \Bbb R^n$ be a closed, measure-$0$ set. Let $U = \Bbb R ^n \setminus C$. Let $f : \Bbb R ^n \to \Bbb C$ be continuous, $f$ smooth of infinite order on $U$ but not derivable on $C$, and $f \in L^p (\Bbb R^n)$. 1) Clearly, $f \in W ^{\infty, p} (U) \ \forall p \ge 1$. 2) By defining $f_\alpha (x) = \left\{ \begin{array} {cc} (\partial _\alpha f) (x), & x \in U \\ 0, & x \in C \end{array} \right.$ for every multi-index $\alpha$, $f_\alpha$ is a weak derivative of $f$ on $\Bbb R^n$, so $f \in W^{\infty, p} (\Bbb R^n)$. Note that this seems to have nothing to do with Sobolev's extension theorem. 3) Localize: choose a small enough ball $B_x$ around every $x$. The restriction $f \big| _{B_x}$ will belong to $W ^{\infty, p} (B_x)$. 4) By Sobolev's embedding theorem, $f \big| _{B_x}$ will be smooth of infinite order on $B_x$. 5) Glueing these restrictions together, $f$ will be smooth of infinite order on $\Bbb R^n$, in particular on $C$, where is was supposed not to be so. Where am I wrong? (There may be several mistakes above, not just one.) (The motivation behind my question: replace $\Bbb R^n$ by a Riemannian manifold $M$, fix some $p \in M$ and let $f = d(p, \cdot)^2$ ($d$ the distance) and let $C$ be the cut locus of $p$.)","I am new to Sobolev spaces and, while trying to construct a proof, I make some subtle mistake that I cannot detect. The setting: let $C \subset \Bbb R^n$ be a closed, measure-$0$ set. Let $U = \Bbb R ^n \setminus C$. Let $f : \Bbb R ^n \to \Bbb C$ be continuous, $f$ smooth of infinite order on $U$ but not derivable on $C$, and $f \in L^p (\Bbb R^n)$. 1) Clearly, $f \in W ^{\infty, p} (U) \ \forall p \ge 1$. 2) By defining $f_\alpha (x) = \left\{ \begin{array} {cc} (\partial _\alpha f) (x), & x \in U \\ 0, & x \in C \end{array} \right.$ for every multi-index $\alpha$, $f_\alpha$ is a weak derivative of $f$ on $\Bbb R^n$, so $f \in W^{\infty, p} (\Bbb R^n)$. Note that this seems to have nothing to do with Sobolev's extension theorem. 3) Localize: choose a small enough ball $B_x$ around every $x$. The restriction $f \big| _{B_x}$ will belong to $W ^{\infty, p} (B_x)$. 4) By Sobolev's embedding theorem, $f \big| _{B_x}$ will be smooth of infinite order on $B_x$. 5) Glueing these restrictions together, $f$ will be smooth of infinite order on $\Bbb R^n$, in particular on $C$, where is was supposed not to be so. Where am I wrong? (There may be several mistakes above, not just one.) (The motivation behind my question: replace $\Bbb R^n$ by a Riemannian manifold $M$, fix some $p \in M$ and let $f = d(p, \cdot)^2$ ($d$ the distance) and let $C$ be the cut locus of $p$.)",,"['functional-analysis', 'sobolev-spaces', 'lp-spaces', 'distribution-theory', 'weak-derivatives']"
67,Eigenfunctions of the Laplacian on singular spaces,Eigenfunctions of the Laplacian on singular spaces,,"Consider a compact manifold $M$ with boundary and corner. As an example, we could have the cube $\{(x_1, x_2,..x_n) \in \mathbb{R}^n : x_i \in [0,1]\}$. We could very well define the Laplacian $\Delta$ on such an $M$ with Dirichlet or Neumann boundary conditions. In such situations, are the eigenfunctions of the Laplacian smooth? It seems to me that this requires some sort of elliptic regularity theory for singular spaces (maybe there is an elliptic regularity theory for manifolds with Lipschitz boundaries). A reference would be highly appreciated.","Consider a compact manifold $M$ with boundary and corner. As an example, we could have the cube $\{(x_1, x_2,..x_n) \in \mathbb{R}^n : x_i \in [0,1]\}$. We could very well define the Laplacian $\Delta$ on such an $M$ with Dirichlet or Neumann boundary conditions. In such situations, are the eigenfunctions of the Laplacian smooth? It seems to me that this requires some sort of elliptic regularity theory for singular spaces (maybe there is an elliptic regularity theory for manifolds with Lipschitz boundaries). A reference would be highly appreciated.",,"['functional-analysis', 'differential-geometry', 'reference-request', 'partial-differential-equations', 'regularity-theory-of-pdes']"
68,Assumption in PDE theory,Assumption in PDE theory,,"I have an exercise in PDE theory. Let $w \in C^2(U)\cap C(\overline{U})$ where $U$ is open, bounded and connected and $c \in C(\overline{U},\mathbb{R})$ with $c(x) \le 0$ everywhere. Moreover, $u\rvert_{\partial U}=0$ and $u$ solves  $$\Delta u(x) =-c(x)u(x)$$  Then, I am supposed to show that $u(x)=0$ for all $x \in \overline{U}.$ Now, I have figured out a proof, but I don't need the connectedness. This makes me suspicious, so please could anybody check my proof: Let $G:=\{x \in U; u(x) > 0\}.$ Then we have $\Delta u(x) =-c(x)u(x) \ge 0$ on $G.$ Thus, $u$ is subharmonic on $G$ and $G$ is open (as the preimage of an open interval) and bounded as $U$ is bounded. Thus, we can apply the maximum principle for subharmonic functions and get $$\max_{\overline{G}} u =  \max_{\partial G}u.$$ We show that $u$ is zero on $\partial G.$ If $x \in \partial G \cap \partial U$ then $u$ is zero by assumption in the theorem. If $x \in \partial G \backslash \partial U$ then $\,x \in \operatorname{int}\left(U\right).\,$ Thus, we have, as $\,x \notin G$ that $u(x) \le 0.\,$ But by continuity we must have $u(x)=0.$ Thus, $u$ is zero on $\partial G.$ Hence, we get that $u$ must be zero in $\overline{G}.$ Now, we can apply the same argument to $-u$ in order to see that $u$ is actually zero everywhere. Clearly, I did not mention the connectedness of $U$ anywhere and thus, I guess there is something wrong. What do you think?","I have an exercise in PDE theory. Let $w \in C^2(U)\cap C(\overline{U})$ where $U$ is open, bounded and connected and $c \in C(\overline{U},\mathbb{R})$ with $c(x) \le 0$ everywhere. Moreover, $u\rvert_{\partial U}=0$ and $u$ solves  $$\Delta u(x) =-c(x)u(x)$$  Then, I am supposed to show that $u(x)=0$ for all $x \in \overline{U}.$ Now, I have figured out a proof, but I don't need the connectedness. This makes me suspicious, so please could anybody check my proof: Let $G:=\{x \in U; u(x) > 0\}.$ Then we have $\Delta u(x) =-c(x)u(x) \ge 0$ on $G.$ Thus, $u$ is subharmonic on $G$ and $G$ is open (as the preimage of an open interval) and bounded as $U$ is bounded. Thus, we can apply the maximum principle for subharmonic functions and get $$\max_{\overline{G}} u =  \max_{\partial G}u.$$ We show that $u$ is zero on $\partial G.$ If $x \in \partial G \cap \partial U$ then $u$ is zero by assumption in the theorem. If $x \in \partial G \backslash \partial U$ then $\,x \in \operatorname{int}\left(U\right).\,$ Thus, we have, as $\,x \notin G$ that $u(x) \le 0.\,$ But by continuity we must have $u(x)=0.$ Thus, $u$ is zero on $\partial G.$ Hence, we get that $u$ must be zero in $\overline{G}.$ Now, we can apply the same argument to $-u$ in order to see that $u$ is actually zero everywhere. Clearly, I did not mention the connectedness of $U$ anywhere and thus, I guess there is something wrong. What do you think?",,"['real-analysis', 'analysis', 'functional-analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
69,Equivalent Norms for Intermediate Subspaces,Equivalent Norms for Intermediate Subspaces,,"Let $(X,\left\|\cdot\right\|)$ be a Banach space, and let $\left\{T(t) : t\geq 0\right\}$ be an equibounded strongly continuous semi-group on $X$. Define a functional $\left\|\cdot\right\|_{\alpha,r;q}:X\rightarrow[0,\infty)$ by $$\left\|f\right\|_{\alpha,r;q}:=\begin{cases} \displaystyle{\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\left\|[T(t)-I)]^{r}f\right\|^{q}\dfrac{dt}{t}\right)^{q}} & {(0<\alpha<r;1\leq q<\infty)}\\ \\ \displaystyle{\left\|f\right\|+\sup_{0<t<\infty}(t^{-\alpha}\left\|(T(t)-I)^{r}f\right\|)} & {(0\leq\alpha\leq r; q=\infty, r\in\mathbb{N})}\end{cases} $$ where for $r\in\mathbb{N}$, $[T(t)-I]^{r}f$ is the $r^{th}$ difference. Definition. We say that an element $f\in X$ belongs to the intermediate space $X_{\alpha,r;q}$ if $\left\|f\right\|_{\alpha,r;q}<\infty$. One can show that the spaces $(X_{\alpha,r;q},\left\|\cdot\right\|_{\alpha,r;q})$ are Banach space and that they are continuously embedded between $D(A^{r})$ (the domain of the $r^{th}$ power of the infinitesimal generator of the semigroup) and $X$. For $f\in X$, define the $r^{th}$ modulus of continuity $\omega_{r}(t;f)$ by $$\omega_{r}(t;f):=\sup_{0\leq h\leq t}\left\|[T(h)-I]^{r}f\right\|$$ Problem. I am trying to show that the norms $$\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\left\|[T(t)-I]^{r}f\right\|)^{q}\dfrac{dt}{t}\right)^{1/q} \tag{1}$$ and $$\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\omega_{r}(t;f))^{q}\dfrac{dt}{t}\right)^{1/q} \tag{2}$$ are equivalent for the intermediate subspace $X_{\alpha,r;q}$, where $0<\alpha<r, 1\leq q<\infty$. This problem stems from Theorem 3.4.2 in Butzer and Berens, Semi-Groups of Operators and Approximation , in which the authors assert the equivalence saying ""it is not hard to see"". I have shown the case $r=1$ (see answer below), but I am not seeing how my argument generalizes to the case $r>1$. I think I may be missing some algebraic identity. Edit 2: Generalized the formulation of the original question.","Let $(X,\left\|\cdot\right\|)$ be a Banach space, and let $\left\{T(t) : t\geq 0\right\}$ be an equibounded strongly continuous semi-group on $X$. Define a functional $\left\|\cdot\right\|_{\alpha,r;q}:X\rightarrow[0,\infty)$ by $$\left\|f\right\|_{\alpha,r;q}:=\begin{cases} \displaystyle{\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\left\|[T(t)-I)]^{r}f\right\|^{q}\dfrac{dt}{t}\right)^{q}} & {(0<\alpha<r;1\leq q<\infty)}\\ \\ \displaystyle{\left\|f\right\|+\sup_{0<t<\infty}(t^{-\alpha}\left\|(T(t)-I)^{r}f\right\|)} & {(0\leq\alpha\leq r; q=\infty, r\in\mathbb{N})}\end{cases} $$ where for $r\in\mathbb{N}$, $[T(t)-I]^{r}f$ is the $r^{th}$ difference. Definition. We say that an element $f\in X$ belongs to the intermediate space $X_{\alpha,r;q}$ if $\left\|f\right\|_{\alpha,r;q}<\infty$. One can show that the spaces $(X_{\alpha,r;q},\left\|\cdot\right\|_{\alpha,r;q})$ are Banach space and that they are continuously embedded between $D(A^{r})$ (the domain of the $r^{th}$ power of the infinitesimal generator of the semigroup) and $X$. For $f\in X$, define the $r^{th}$ modulus of continuity $\omega_{r}(t;f)$ by $$\omega_{r}(t;f):=\sup_{0\leq h\leq t}\left\|[T(h)-I]^{r}f\right\|$$ Problem. I am trying to show that the norms $$\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\left\|[T(t)-I]^{r}f\right\|)^{q}\dfrac{dt}{t}\right)^{1/q} \tag{1}$$ and $$\left\|f\right\|+\left(\int_{0}^{\infty}(t^{-\alpha}\omega_{r}(t;f))^{q}\dfrac{dt}{t}\right)^{1/q} \tag{2}$$ are equivalent for the intermediate subspace $X_{\alpha,r;q}$, where $0<\alpha<r, 1\leq q<\infty$. This problem stems from Theorem 3.4.2 in Butzer and Berens, Semi-Groups of Operators and Approximation , in which the authors assert the equivalence saying ""it is not hard to see"". I have shown the case $r=1$ (see answer below), but I am not seeing how my argument generalizes to the case $r>1$. I think I may be missing some algebraic identity. Edit 2: Generalized the formulation of the original question.",,"['functional-analysis', 'banach-spaces', 'semigroup-of-operators']"
70,"Functions Satisfying $u,\Delta u\in L^{1}(\mathbb{R}^{n})$",Functions Satisfying,"u,\Delta u\in L^{1}(\mathbb{R}^{n})","In this paper , the authors assert that ...the domain of realization of the Laplacian in $L^{1}(\mathbb{R}^{n})$ is not contained in $W^{2,1}(\mathbb{R}^{n})$ if $n>1$ . However, it is continuously embedded in $W^{1+\beta,1}(\mathbb{R}^{n})$ for each $\beta\in(0,1)$ . Therefore, if $u$ and $\Delta u$ are in $L^{1}(\mathbb{R}^{n})$ , then any first order derivative $D_{i}u$ , $i=1,\ldots,n$ , belongs to $W^{\beta,1}(\mathbb{R}^{n})$ for each $\beta$ , and by Sobolev embedding it belongs to $L^{p}(\mathbb{R}^{n})$ for each $p<n/n-1$ , with $$\left\|D_{i}u\right\|_{L^{p}}\leq C(p)\left(\left\|u\right\|_{L^{1}}+\left\|\Delta u\right\|_{L^{1}}\right)$$ Question. Could someone help me with a sketch for proving the continuous embedding into $W^{1+\beta,1}(\mathbb{R}^{n})$ ? Here's what I know. If $u\in L^{1}(\mathbb{R}^{n})$ and $\Delta u=f\in L^{1}(\mathbb{R}^{n})$ , then in the sense of (tempered) distributions $$(-2\pi i)^{2}\left|\xi\right|^{2}\widehat{u}=\widehat{\Delta u}=\widehat{f}$$ Since $u,f\in L^{1}(\mathbb{R}^{n})$ , $\widehat{u}$ , $\widehat{f}$ belong to $C_{0}(\mathbb{R}^{n})$ and away from the origin $\widehat{u}(\xi)=-4\pi^{2}\widehat{f}(\xi)\left|\xi\right|^{-2}$ . I wanted to arrive at $u=f\ast K$ , where $K$ is the fundamental solution of the Laplacian, and try to go from there; however, I hit the wall at this point.","In this paper , the authors assert that ...the domain of realization of the Laplacian in is not contained in if . However, it is continuously embedded in for each . Therefore, if and are in , then any first order derivative , , belongs to for each , and by Sobolev embedding it belongs to for each , with Question. Could someone help me with a sketch for proving the continuous embedding into ? Here's what I know. If and , then in the sense of (tempered) distributions Since , , belong to and away from the origin . I wanted to arrive at , where is the fundamental solution of the Laplacian, and try to go from there; however, I hit the wall at this point.","L^{1}(\mathbb{R}^{n}) W^{2,1}(\mathbb{R}^{n}) n>1 W^{1+\beta,1}(\mathbb{R}^{n}) \beta\in(0,1) u \Delta u L^{1}(\mathbb{R}^{n}) D_{i}u i=1,\ldots,n W^{\beta,1}(\mathbb{R}^{n}) \beta L^{p}(\mathbb{R}^{n}) p<n/n-1 \left\|D_{i}u\right\|_{L^{p}}\leq C(p)\left(\left\|u\right\|_{L^{1}}+\left\|\Delta u\right\|_{L^{1}}\right) W^{1+\beta,1}(\mathbb{R}^{n}) u\in L^{1}(\mathbb{R}^{n}) \Delta u=f\in L^{1}(\mathbb{R}^{n}) (-2\pi i)^{2}\left|\xi\right|^{2}\widehat{u}=\widehat{\Delta u}=\widehat{f} u,f\in L^{1}(\mathbb{R}^{n}) \widehat{u} \widehat{f} C_{0}(\mathbb{R}^{n}) \widehat{u}(\xi)=-4\pi^{2}\widehat{f}(\xi)\left|\xi\right|^{-2} u=f\ast K K","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'harmonic-analysis', 'regularity-theory-of-pdes']"
71,On the norm of a quotient of a Banach space.,On the norm of a quotient of a Banach space.,,"Let $E$ be a Banach space and $F$ a closed subspace. It is well known that the quotient space $E/F$ is also a Banach space with respect to the norm  $$ \left\Vert x+F\right\Vert_{E/F}=\inf\{\left\Vert y\right\Vert_E\mid y\in x+F\}. $$ Unfortunately in a set of lecture notes on (Lie) group representations (material for our study group) the author accidentally used here $\min$ instead of $\inf$. Probably a mostly harmless booboo, because at that point it was only needed to get a Banach space structure on the quotient, and we will probably be concentrating on Hilbert spaces anyway, where the problem does not arise. Namely from Rudin's Functional Analysis I could not find a proof that the minimum should always be attained. Except in the case of a Hilbert space, where an application of parallelogram law (the sum of the squared norms of the two diagonals of a parallelogram equals that of the four sides) allows us to find a Cauchy sequence among a sequence of vectors $(y_n)\subset x+F$ such that  $$\lim_{n\to\infty}\left\Vert y_n\right\Vert_E=\left\Vert x+F\right\Vert_{E/F}.$$ But anyway, the suspicion was left that the infimum is there for a reason (other than conveniently allowing us to sweep this detail under the rug at that point of the development of theory), so in the interest of serving our study group I had to come up with a specific example, where the minimum is not achieved. It's been 25 years since I really had to exercise the Banach space gland in my brain, so it has shrunk to size of a raisin. Searching this site did help, because I found this question . There we have $E=C([0,1])$, the space of continuous real functions on $[0,1]$ equipped with the sup-norm. If we denote by $\Lambda$ the continuous functional $$ \Lambda: E\to\mathbb{R},f\mapsto\int_0^{1/2}f-\int_{1/2}^1f $$ and let $F=\ker\Lambda$, then the answer to the linked question proves that there is no minimum sup-norm function in the coset $\Lambda^{-1}(1)$. So I have a (counter)example, and the main question has evolved to: When can we use minimum in place of infimum in the definition of the quotient space norm? My thinking: It seems to me that the answer is affirmative, if $F$ has a complement, i.e. we can write $E=F\oplus F'$ as a direct sum of two closed subspaces such that the norm on $E$ is equivalent to the sum of the norms on $F$ and $F'$-components. But the first point also raises the suspicion that the question may be a bit ill-defined (and uninteresting) in the sense that the answer might depend on the choice of the norm $\left\Vert\cdot\right\Vert_E$ among the set of equivalent norms. However, if we, for example, perturb the sup-norm of $C([0,1])$ in the above example by multiplying the functions with a fixed positive definite function before taking the sup-norm, the argument seems to survive, so may be replacing the norm with an equivalent one is irrelevant? So to satisfy my curiosity I also welcome ""your favorite example"" (one with a finite-dimensional $F$ would be nice to see), where we absolutely need the infimum here. Bits about any sufficient or necessary conditions for the minimum to be sufficient or (as a last resort :-) pointers to relevant literature are, of course, also appreciated.","Let $E$ be a Banach space and $F$ a closed subspace. It is well known that the quotient space $E/F$ is also a Banach space with respect to the norm  $$ \left\Vert x+F\right\Vert_{E/F}=\inf\{\left\Vert y\right\Vert_E\mid y\in x+F\}. $$ Unfortunately in a set of lecture notes on (Lie) group representations (material for our study group) the author accidentally used here $\min$ instead of $\inf$. Probably a mostly harmless booboo, because at that point it was only needed to get a Banach space structure on the quotient, and we will probably be concentrating on Hilbert spaces anyway, where the problem does not arise. Namely from Rudin's Functional Analysis I could not find a proof that the minimum should always be attained. Except in the case of a Hilbert space, where an application of parallelogram law (the sum of the squared norms of the two diagonals of a parallelogram equals that of the four sides) allows us to find a Cauchy sequence among a sequence of vectors $(y_n)\subset x+F$ such that  $$\lim_{n\to\infty}\left\Vert y_n\right\Vert_E=\left\Vert x+F\right\Vert_{E/F}.$$ But anyway, the suspicion was left that the infimum is there for a reason (other than conveniently allowing us to sweep this detail under the rug at that point of the development of theory), so in the interest of serving our study group I had to come up with a specific example, where the minimum is not achieved. It's been 25 years since I really had to exercise the Banach space gland in my brain, so it has shrunk to size of a raisin. Searching this site did help, because I found this question . There we have $E=C([0,1])$, the space of continuous real functions on $[0,1]$ equipped with the sup-norm. If we denote by $\Lambda$ the continuous functional $$ \Lambda: E\to\mathbb{R},f\mapsto\int_0^{1/2}f-\int_{1/2}^1f $$ and let $F=\ker\Lambda$, then the answer to the linked question proves that there is no minimum sup-norm function in the coset $\Lambda^{-1}(1)$. So I have a (counter)example, and the main question has evolved to: When can we use minimum in place of infimum in the definition of the quotient space norm? My thinking: It seems to me that the answer is affirmative, if $F$ has a complement, i.e. we can write $E=F\oplus F'$ as a direct sum of two closed subspaces such that the norm on $E$ is equivalent to the sum of the norms on $F$ and $F'$-components. But the first point also raises the suspicion that the question may be a bit ill-defined (and uninteresting) in the sense that the answer might depend on the choice of the norm $\left\Vert\cdot\right\Vert_E$ among the set of equivalent norms. However, if we, for example, perturb the sup-norm of $C([0,1])$ in the above example by multiplying the functions with a fixed positive definite function before taking the sup-norm, the argument seems to survive, so may be replacing the norm with an equivalent one is irrelevant? So to satisfy my curiosity I also welcome ""your favorite example"" (one with a finite-dimensional $F$ would be nice to see), where we absolutely need the infimum here. Bits about any sufficient or necessary conditions for the minimum to be sufficient or (as a last resort :-) pointers to relevant literature are, of course, also appreciated.",,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'quotient-spaces']"
72,Proof of Sobolev imbedding theorem in Adams,Proof of Sobolev imbedding theorem in Adams,,"I am struggling to understand the proof of the Sobolev embedding theorem given in Sobolev Spaces by Adams. Specifically section 4.25 (2003 edition). The aim is to prove $W^{m,1}(\Omega) \to L^{q}(\Omega_{k})$ for $1 \le q \le \frac{k}{n-m}$, where $k>n-m$, and $n \gt m$ $\Omega \subset \mathbb{R}^{n}$ is open and satisfies the cone condition and $\Omega_{k}$ is the intersection of $\Omega$ with a k-dimensional plane in $\mathbb{R}^{n}$. Lemma 4.24 gives $W^{m,1}(\Omega) \to W^{m-1,p}(\Omega)$ for $1\le p \le \frac{n}{n-1}$ Since $k \gt n-m$, we have $k \ge n-m+1 \gt n-(m-1)r$ $\forall r \gt 1$ The proof (with some obvious misprints) now claims (from previous parts of the proof) that  $W^{m-1,r}(\Omega) \to L^{q}(\Omega_{k})$ $\forall 1 \le q \le r^{*}$ But I can only see that this is true for $r \le q \le r^{*}$. Hence finally I get  $W^{m,1}(\Omega) \to L^{q}(\Omega_{k})$ for $1 \lt q \le \frac{k}{n-m}$. Am I missing something very obvious?","I am struggling to understand the proof of the Sobolev embedding theorem given in Sobolev Spaces by Adams. Specifically section 4.25 (2003 edition). The aim is to prove $W^{m,1}(\Omega) \to L^{q}(\Omega_{k})$ for $1 \le q \le \frac{k}{n-m}$, where $k>n-m$, and $n \gt m$ $\Omega \subset \mathbb{R}^{n}$ is open and satisfies the cone condition and $\Omega_{k}$ is the intersection of $\Omega$ with a k-dimensional plane in $\mathbb{R}^{n}$. Lemma 4.24 gives $W^{m,1}(\Omega) \to W^{m-1,p}(\Omega)$ for $1\le p \le \frac{n}{n-1}$ Since $k \gt n-m$, we have $k \ge n-m+1 \gt n-(m-1)r$ $\forall r \gt 1$ The proof (with some obvious misprints) now claims (from previous parts of the proof) that  $W^{m-1,r}(\Omega) \to L^{q}(\Omega_{k})$ $\forall 1 \le q \le r^{*}$ But I can only see that this is true for $r \le q \le r^{*}$. Hence finally I get  $W^{m,1}(\Omega) \to L^{q}(\Omega_{k})$ for $1 \lt q \le \frac{k}{n-m}$. Am I missing something very obvious?",,"['functional-analysis', 'sobolev-spaces']"
73,A question about equivalence of norms involving infimum,A question about equivalence of norms involving infimum,,"Let $I$ be a Banach space with norm $\lVert\cdot\rVert_I$. The norm $$\inf\{\lVert(G_i(u_i))_i\rVert_{\ell^2}\mid u=\sum_{I \geq 0}u_i\}\qquad\text{is equivalent to}\qquad \lVert{u}\rVert_{I}$$ where the series converges in a separable Hilbert space $X_0$ where $I \subset X_0$ continuously. Here $G_i$ are some given function. I have seen in papers, that this implies: $$\lVert(G(v_i))_i\rVert_{\ell^2} \leq C\lVert u\rVert_I$$ where $v_i = (u,\phi_i)_{X_0}\phi_i$ wth $\phi_i$ the o.n. eigenbasis of $X_0$. Why is this true? The inequality is the wrong way for picking a particular function in the infimum, so there must be another way to see this. For example I saw this in http://arxiv.org/pdf/1404.6195v3.pdf , on section 3.1.3, near the bottom, where they use Theorem 8.2 in that paper.","Let $I$ be a Banach space with norm $\lVert\cdot\rVert_I$. The norm $$\inf\{\lVert(G_i(u_i))_i\rVert_{\ell^2}\mid u=\sum_{I \geq 0}u_i\}\qquad\text{is equivalent to}\qquad \lVert{u}\rVert_{I}$$ where the series converges in a separable Hilbert space $X_0$ where $I \subset X_0$ continuously. Here $G_i$ are some given function. I have seen in papers, that this implies: $$\lVert(G(v_i))_i\rVert_{\ell^2} \leq C\lVert u\rVert_I$$ where $v_i = (u,\phi_i)_{X_0}\phi_i$ wth $\phi_i$ the o.n. eigenbasis of $X_0$. Why is this true? The inequality is the wrong way for picking a particular function in the infimum, so there must be another way to see this. For example I saw this in http://arxiv.org/pdf/1404.6195v3.pdf , on section 3.1.3, near the bottom, where they use Theorem 8.2 in that paper.",,"['functional-analysis', 'hilbert-spaces', 'banach-spaces']"
74,What is the derivative of the inner product norm on $L^2$ space?,What is the derivative of the inner product norm on  space?,L^2,"Let $f \in L^2(X)$ such that $f$ is generated by some arbitrary constant; that is, $f = g(a)$ with $g: \mathbb{R} \to L^2(X)$. Then what can be said about the derivative with respect to some arbitrary variable of the inner product of $f$ with itself: $$D =\frac{\partial}{\partial a}\langle f, f \rangle = \;?$$ I had the idea that $D = 2 \langle f ,  \frac{\partial f}{\partial a} \rangle$, where $I$ is the identity function, but I'm not sure. The evidence for this is as follows \begin{equation} \begin{aligned} D &=\frac{\partial}{\partial a} \int_X \left(f(x)\right)^2\ dx\\ &= 2\int_X f(x)  \frac{\partial f}{\partial a} \ dx. \end{aligned} \end{equation} My ultimate goal is to compute this for general vector spaces not just $L^2$. Thanks.","Let $f \in L^2(X)$ such that $f$ is generated by some arbitrary constant; that is, $f = g(a)$ with $g: \mathbb{R} \to L^2(X)$. Then what can be said about the derivative with respect to some arbitrary variable of the inner product of $f$ with itself: $$D =\frac{\partial}{\partial a}\langle f, f \rangle = \;?$$ I had the idea that $D = 2 \langle f ,  \frac{\partial f}{\partial a} \rangle$, where $I$ is the identity function, but I'm not sure. The evidence for this is as follows \begin{equation} \begin{aligned} D &=\frac{\partial}{\partial a} \int_X \left(f(x)\right)^2\ dx\\ &= 2\int_X f(x)  \frac{\partial f}{\partial a} \ dx. \end{aligned} \end{equation} My ultimate goal is to compute this for general vector spaces not just $L^2$. Thanks.",,"['calculus', 'linear-algebra', 'functional-analysis', 'vector-spaces']"
75,Normal Operators: Meet,Normal Operators: Meet,,"Given a Hilbert space $\mathcal{H}$ . Normal Operators: $$\mathcal{N}(\mathcal{H}):=\{N:N^*N=NN^*\}$$ Borel Calculus: $$\mathcal{B}(N):=\{\eta({N}):\eta\in\mathcal{B}(\mathbb{C},\mathbb{C})\}$$ Commutativity: $$N_\pm\in\mathcal{N}(\mathcal{H}):\quad N_+N_-=N_-N_+$$ Borel Calculus: $$\mathcal{B}(N_+)\subseteq\mathcal{B}(N_-)\lor\mathcal{B}(N_-)\subseteq\mathcal{B}(N_+)$$ Meet Operator: $$N_+\wedge N_-\in\mathcal{N}(\mathcal{H}):\quad\mathcal{B}(N_\pm)\subseteq\mathcal{B}(N_+\wedge N_-)$$ (Symbolic Meet!)",Given a Hilbert space . Normal Operators: Borel Calculus: Commutativity: Borel Calculus: Meet Operator: (Symbolic Meet!),"\mathcal{H} \mathcal{N}(\mathcal{H}):=\{N:N^*N=NN^*\} \mathcal{B}(N):=\{\eta({N}):\eta\in\mathcal{B}(\mathbb{C},\mathbb{C})\} N_\pm\in\mathcal{N}(\mathcal{H}):\quad N_+N_-=N_-N_+ \mathcal{B}(N_+)\subseteq\mathcal{B}(N_-)\lor\mathcal{B}(N_-)\subseteq\mathcal{B}(N_+) N_+\wedge N_-\in\mathcal{N}(\mathcal{H}):\quad\mathcal{B}(N_\pm)\subseteq\mathcal{B}(N_+\wedge N_-)","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
76,Linear Operators Denseness and Injectivity,Linear Operators Denseness and Injectivity,,"I'm studying for a Real Analysis prelim and have the following problem: ""Let $X$ and $Y$ be normed spaces over $\mathbb{R}$ and let $$\mathcal{L}(X, Y) = \{T: X \rightarrow Y \mid T \text{ is bounded and linear}\}.$$  Let $X^{*}$ and $Y^{*}$ be the dual spaces of $X$ and $Y$ respectively, and let $T^{+}: Y^{*} \rightarrow X^{*}$ be defined by $T^{+}f = f \circ T$.  Prove that $T^{+}$ is injective if and only if the image of $T$ is dense in $Y$."" I think I have a proof for the forward direction but for some reason the reverse direction is evading me.  Please let me know if what I have so far is correct, and if anyone can give a hint or something about the reverse direction, it would be greatly appreciated. ($\Rightarrow$) Suppose $T^{+}$ is injective but that $T(X)$ is not dense in $Y$.  Then for some $y \in Y \backslash T(X)$, there exists an $\varepsilon > 0$ such that $||Tx - y||\geq \varepsilon$ for all $x \in X$.  Let $f \in Y^{*}$ be defined by $f(z) = || z - y ||$  if $z \in Y\backslash B_{\varepsilon}(y)$ and $\varepsilon$ otherwise.  Also, let $g \in Y^{*}$ be defined by $g(z) = ||z - y ||$ for all $z \in Y$.  Then $T^{+}f = T^{+}g$ and $f(z) = g(z)$ when $z \in T(X)$ but not always when $z \in Y\backslash T(X)$, contradicting $T^{+}$ being injective. ($\Leftarrow$) For this direction, I'm thinking about showing through contraposition by assuming $T^{+}f = T^{+}g$ with $f(z) \neq g(z)$ for some $z \in Y\backslash T(X)$ and arriving at the conclusion that $T(X)$ is not dense in $Y$, but for now can't think of how to do that. P.S. This is my first post on StackExchange, so go easy on me if I made a complete fool of myself; Functional Analysis is quite new to me.","I'm studying for a Real Analysis prelim and have the following problem: ""Let $X$ and $Y$ be normed spaces over $\mathbb{R}$ and let $$\mathcal{L}(X, Y) = \{T: X \rightarrow Y \mid T \text{ is bounded and linear}\}.$$  Let $X^{*}$ and $Y^{*}$ be the dual spaces of $X$ and $Y$ respectively, and let $T^{+}: Y^{*} \rightarrow X^{*}$ be defined by $T^{+}f = f \circ T$.  Prove that $T^{+}$ is injective if and only if the image of $T$ is dense in $Y$."" I think I have a proof for the forward direction but for some reason the reverse direction is evading me.  Please let me know if what I have so far is correct, and if anyone can give a hint or something about the reverse direction, it would be greatly appreciated. ($\Rightarrow$) Suppose $T^{+}$ is injective but that $T(X)$ is not dense in $Y$.  Then for some $y \in Y \backslash T(X)$, there exists an $\varepsilon > 0$ such that $||Tx - y||\geq \varepsilon$ for all $x \in X$.  Let $f \in Y^{*}$ be defined by $f(z) = || z - y ||$  if $z \in Y\backslash B_{\varepsilon}(y)$ and $\varepsilon$ otherwise.  Also, let $g \in Y^{*}$ be defined by $g(z) = ||z - y ||$ for all $z \in Y$.  Then $T^{+}f = T^{+}g$ and $f(z) = g(z)$ when $z \in T(X)$ but not always when $z \in Y\backslash T(X)$, contradicting $T^{+}$ being injective. ($\Leftarrow$) For this direction, I'm thinking about showing through contraposition by assuming $T^{+}f = T^{+}g$ with $f(z) \neq g(z)$ for some $z \in Y\backslash T(X)$ and arriving at the conclusion that $T(X)$ is not dense in $Y$, but for now can't think of how to do that. P.S. This is my first post on StackExchange, so go easy on me if I made a complete fool of myself; Functional Analysis is quite new to me.",,"['real-analysis', 'functional-analysis']"
77,Dimension of a Hilbert space,Dimension of a Hilbert space,,"Halmos in his book (A Hilbert space problem book) says, 1- linear basis, and orthogonal basis of a Hilbert space $H$ have the same cardinality. 2- Also he proves if orthogonal dimension of Hilbert space is $N_0$ ( aleph-null ), then its linear dimension is $2^{N_0}$. My question: In this case orthogonal dimension, and linear dimension are not the same by 2, Is not it a contradiction with 1? Also if it's possible, give me more information about it. Please regard me. Thanks in advance.","Halmos in his book (A Hilbert space problem book) says, 1- linear basis, and orthogonal basis of a Hilbert space $H$ have the same cardinality. 2- Also he proves if orthogonal dimension of Hilbert space is $N_0$ ( aleph-null ), then its linear dimension is $2^{N_0}$. My question: In this case orthogonal dimension, and linear dimension are not the same by 2, Is not it a contradiction with 1? Also if it's possible, give me more information about it. Please regard me. Thanks in advance.",,"['functional-analysis', 'hilbert-spaces']"
78,Is the unitary group of a pre Hilbert space contractible?,Is the unitary group of a pre Hilbert space contractible?,,"for a separable Hilbert space $H$ it is known that the unitary group $U(H)$ is contractible, both for the norm topology (Kuiper's theorem) and for the strong operator topology (Dixmier and Douady, 1963). Note that the strong operator topology coincides with the compact open topology in this case. Does somebody know whether contractibility of the unitary group of at least some special pre Hilbert spaces equipped with the strong operator topology or the compact open topology still holds? The example I have in mind is the underlying algebraic Fock space $\bigwedge PH \oplus (PH^\perp)^*$ of the Fock space. Thanks in advance, StW","for a separable Hilbert space $H$ it is known that the unitary group $U(H)$ is contractible, both for the norm topology (Kuiper's theorem) and for the strong operator topology (Dixmier and Douady, 1963). Note that the strong operator topology coincides with the compact open topology in this case. Does somebody know whether contractibility of the unitary group of at least some special pre Hilbert spaces equipped with the strong operator topology or the compact open topology still holds? The example I have in mind is the underlying algebraic Fock space $\bigwedge PH \oplus (PH^\perp)^*$ of the Fock space. Thanks in advance, StW",,"['general-topology', 'functional-analysis', 'hilbert-spaces', 'topological-groups', 'topological-vector-spaces']"
79,"Is there a more general notion of ""absolute value"" for a field?","Is there a more general notion of ""absolute value"" for a field?",,"Is there a more general notion of absolute values/norms that applies when the field in question is not a subfield of $\mathbb{C}$? My interest is that when we have a vector space $V$ over $\mathbb{R}$, we can define a norm on $V$ based on how it plays with the absolute value on $\mathbb{R}$, and the metrics induced by these norms have a number of nice properties. However, all references I've found to normed spaces consider only spaces over $\mathbb{C}$ or $\mathbb{R}$. This is a shame, because Banach spaces are so dang nice to work with. Are there other fields on which one can define something like an ""absolute value"" which would allow the definition of a norm on a vector space over that field?","Is there a more general notion of absolute values/norms that applies when the field in question is not a subfield of $\mathbb{C}$? My interest is that when we have a vector space $V$ over $\mathbb{R}$, we can define a norm on $V$ based on how it plays with the absolute value on $\mathbb{R}$, and the metrics induced by these norms have a number of nice properties. However, all references I've found to normed spaces consider only spaces over $\mathbb{C}$ or $\mathbb{R}$. This is a shame, because Banach spaces are so dang nice to work with. Are there other fields on which one can define something like an ""absolute value"" which would allow the definition of a norm on a vector space over that field?",,"['general-topology', 'functional-analysis']"
80,The relation between the (algebraic) dimensions of a normed linear space and its dual.,The relation between the (algebraic) dimensions of a normed linear space and its dual.,,"What is the relation between the (algebraic) dimensions of a normed linear space and its dual, for example can we say $\dim X \leq \dim X^*$, for a normed linear space $X$?","What is the relation between the (algebraic) dimensions of a normed linear space and its dual, for example can we say $\dim X \leq \dim X^*$, for a normed linear space $X$?",,['functional-analysis']
81,Continuity of Translation and Dilation on $L^p$ spaces,Continuity of Translation and Dilation on  spaces,L^p,"Let us consider any $f \in L^p(U)$, where $U \subset \mathbb R^n$ is open, and $1 < p < \infty$. We know the translation operator $f(x) \mapsto f(x+a)$ and the dilation operator $f(x) \mapsto f(s x)$, where $a \in \mathbb R^n$ and $s \in \mathbb R^n$. Questions: i) Under which conditions on $U$ and $p$ are translation and dilation bounded, when $a$ and $s$ are fixed, and what is the norm? ii) Conversely, when $f$ is fixed, under what conditions are translation and dilation continuous in the parameters, and how good is that continuity (like locally Hölder)?","Let us consider any $f \in L^p(U)$, where $U \subset \mathbb R^n$ is open, and $1 < p < \infty$. We know the translation operator $f(x) \mapsto f(x+a)$ and the dilation operator $f(x) \mapsto f(s x)$, where $a \in \mathbb R^n$ and $s \in \mathbb R^n$. Questions: i) Under which conditions on $U$ and $p$ are translation and dilation bounded, when $a$ and $s$ are fixed, and what is the norm? ii) Conversely, when $f$ is fixed, under what conditions are translation and dilation continuous in the parameters, and how good is that continuity (like locally Hölder)?",,"['functional-analysis', 'reference-request', 'lp-spaces', 'harmonic-analysis']"
82,Geometrical representation of the unit ball?,Geometrical representation of the unit ball?,,"Let $E$  be the vector space of $\mathbb{R}$-valued continuous functions on $[0\ 1]$. With the norm $\| f \| = \max \{\ | f (x) |; 0 \leq x \leq 1\}$, the open ball centered at $f$ and radius $r$ has a simple graphical representation: it is a “parallel to f band”: the distance from all point on the function at each of its two edges is constant and equal to $r$; for example the closed ball of center the constant function $f(x)= 5$ and radius $1$ is the set of all functions in $E$ contained in the closed rectangle of vertices $(0,4),(1,4),(1,6),(0, 6)$. Is there a similar or analog geometrical representation when the norm on $E$ is given by $\int_{{0}}^{1}|f(x)|$?","Let $E$  be the vector space of $\mathbb{R}$-valued continuous functions on $[0\ 1]$. With the norm $\| f \| = \max \{\ | f (x) |; 0 \leq x \leq 1\}$, the open ball centered at $f$ and radius $r$ has a simple graphical representation: it is a “parallel to f band”: the distance from all point on the function at each of its two edges is constant and equal to $r$; for example the closed ball of center the constant function $f(x)= 5$ and radius $1$ is the set of all functions in $E$ contained in the closed rectangle of vertices $(0,4),(1,4),(1,6),(0, 6)$. Is there a similar or analog geometrical representation when the norm on $E$ is given by $\int_{{0}}^{1}|f(x)|$?",,['functional-analysis']
83,Convergence on Norm vector space.,Convergence on Norm vector space.,,"I am not sure if this question make sense mathematically, so please bear with my ignorance. This is an extension to the question in the link: Is complete metric space is required? It seems in many engineering problem when we look for an optimal solution we work on normed vector space and it is complete under Lp norm. My question is how to improve convergence with less or limited data? It appears to me that since our metric space is complete the convergence issue is related to the structure of space. What I mean is, we may not able to get faster convergence with limited data if we work on linear vector space. Is it possible that the problem may have a better solution in some function space which is not linear?","I am not sure if this question make sense mathematically, so please bear with my ignorance. This is an extension to the question in the link: Is complete metric space is required? It seems in many engineering problem when we look for an optimal solution we work on normed vector space and it is complete under Lp norm. My question is how to improve convergence with less or limited data? It appears to me that since our metric space is complete the convergence issue is related to the structure of space. What I mean is, we may not able to get faster convergence with limited data if we work on linear vector space. Is it possible that the problem may have a better solution in some function space which is not linear?",,"['linear-algebra', 'functional-analysis']"
84,Examples of $C^*$-algebras in Noncommutative Geometry from A. Connes,Examples of -algebras in Noncommutative Geometry from A. Connes,C^*,"Question I am working on $C^*$-algebras and I've been given Alain Connes's  book Noncommutative Geometry . I am having troubles with understanding the examples on pages 91-93 (86-88 in the printed book). Maybe the problem is, that I do not understand, how those algebras are constructed. Could somebody explain the second way of the construction (page 91 (85))? I am talking about the part starting: 2) The second is to consider the larger algebra $B \supset C(Y)$ of all $2 \times 2$ matrices: $$ f = \begin{pmatrix} f_{aa} & f_{ab} \\ f_{ba} & f_{bb} \\ \end{pmatrix}. $$ ... I do not really understand, how to construct this matrix in general. For example - what is $f_{aa}, f_{ab},\ldots$? How are those constructed/represented e.g. in the example $2.\beta$ The dual of the infinite dihedral group (pages 92-93 (87-88))? Many thanks. [Update 2] After two days of without activity I've asked the same question here . I might delete one of them later, do not want to spam . [Update 1] I would be glad to receive any tips or guesses. I am aware, that this is broad topic, I am not looking for precise and rigorous explanation (although that would be also appreciated).","Question I am working on $C^*$-algebras and I've been given Alain Connes's  book Noncommutative Geometry . I am having troubles with understanding the examples on pages 91-93 (86-88 in the printed book). Maybe the problem is, that I do not understand, how those algebras are constructed. Could somebody explain the second way of the construction (page 91 (85))? I am talking about the part starting: 2) The second is to consider the larger algebra $B \supset C(Y)$ of all $2 \times 2$ matrices: $$ f = \begin{pmatrix} f_{aa} & f_{ab} \\ f_{ba} & f_{bb} \\ \end{pmatrix}. $$ ... I do not really understand, how to construct this matrix in general. For example - what is $f_{aa}, f_{ab},\ldots$? How are those constructed/represented e.g. in the example $2.\beta$ The dual of the infinite dihedral group (pages 92-93 (87-88))? Many thanks. [Update 2] After two days of without activity I've asked the same question here . I might delete one of them later, do not want to spam . [Update 1] I would be glad to receive any tips or guesses. I am aware, that this is broad topic, I am not looking for precise and rigorous explanation (although that would be also appreciated).",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'quotient-spaces', 'noncommutative-geometry']"
85,(soft question) why do we study complex measures and complex-valued functionals in modern analysis,(soft question) why do we study complex measures and complex-valued functionals in modern analysis,,"Recently I am struggling with ""complex"" things for my ""real"" analysis class. We are using Folland's Real analysis, 2nd for text book. It seems that Folland is trying to use complex-valued functions and linear functionals and complex measures whenever it is possible. I have seen several examples in the probability theory using dominated convergence theorem for complex-valued functions to verify the limit of characteristic functions. But why is it so important for us to develop complex functionals and complex measures? Could anybody show me a few examples in which real functionals and real measures cannot serve the purpose?","Recently I am struggling with ""complex"" things for my ""real"" analysis class. We are using Folland's Real analysis, 2nd for text book. It seems that Folland is trying to use complex-valued functions and linear functionals and complex measures whenever it is possible. I have seen several examples in the probability theory using dominated convergence theorem for complex-valued functions to verify the limit of characteristic functions. But why is it so important for us to develop complex functionals and complex measures? Could anybody show me a few examples in which real functionals and real measures cannot serve the purpose?",,"['real-analysis', 'functional-analysis', 'measure-theory', 'operator-theory']"
86,Tensor products of Lipschitz functions,Tensor products of Lipschitz functions,,"I have encountered a problem on which I am sure there is some background, which unfortunately I don't know anything about (so that I don't even know where to start). Let $(M, d_M)$, $(N, d_N)$ be compact metric spaces. If needed, we can assume that they are compact Riemannian manifolds. Let $Lip (M)$ (resp. $Lip (N)$) be the Banach space of complex-valued Lipschitz functions on $M$ (resp. $N$), endowed with the norm: $$\|g\|_{Lip (M)} := \|g\|_\infty + \sup_{\substack{(x,y) \in M^2 \\ x \neq y}} \frac{|g(x)-g(y)|}{d_M (x,y)}.$$ I can endow $M \times N$ with e.g. the metric $d_M+d_N$. First question (qualitative): can we meaningfully write $Lip (M) \otimes Lip (N) \simeq Lip (M \times N)$? I am not used to working with tensor products, much less topological tensor products. That may be trivial, but I am stumped. Second question (quantitative): Let $f \in Lip (M \times N)$ be generic. Let $\varepsilon > 0$. How well can we approximate $f$ by products of Lipschitz functions on $M$ and $N$? More precisely, if $C(\varepsilon)$ is the least $C \geq 0$ such that there exist $n \geq 0$ and $(g_1, \cdots, g_n) \in Lip (M)^n$, $(h_1, \cdots, h_n) \in Lip (N)^n$ with: $$\|f-\sum_{k=1}^n g_k \otimes h_k \|_\infty \leq \varepsilon,$$ $$\sum_{k=1}^n  \|g_k\|_{Lip(M)} \|h_k\|_{Lip(N)} \leq C,$$ then what is the behaviour of $C(\varepsilon)$ as $\varepsilon$ goes to $0$? The use of the supremum norm in the first equation may seem weird, but that is what occurs in the problem I am looking at. The best case would be if $C(\varepsilon)$ were bounded, but I don't know of the approach the subject.","I have encountered a problem on which I am sure there is some background, which unfortunately I don't know anything about (so that I don't even know where to start). Let $(M, d_M)$, $(N, d_N)$ be compact metric spaces. If needed, we can assume that they are compact Riemannian manifolds. Let $Lip (M)$ (resp. $Lip (N)$) be the Banach space of complex-valued Lipschitz functions on $M$ (resp. $N$), endowed with the norm: $$\|g\|_{Lip (M)} := \|g\|_\infty + \sup_{\substack{(x,y) \in M^2 \\ x \neq y}} \frac{|g(x)-g(y)|}{d_M (x,y)}.$$ I can endow $M \times N$ with e.g. the metric $d_M+d_N$. First question (qualitative): can we meaningfully write $Lip (M) \otimes Lip (N) \simeq Lip (M \times N)$? I am not used to working with tensor products, much less topological tensor products. That may be trivial, but I am stumped. Second question (quantitative): Let $f \in Lip (M \times N)$ be generic. Let $\varepsilon > 0$. How well can we approximate $f$ by products of Lipschitz functions on $M$ and $N$? More precisely, if $C(\varepsilon)$ is the least $C \geq 0$ such that there exist $n \geq 0$ and $(g_1, \cdots, g_n) \in Lip (M)^n$, $(h_1, \cdots, h_n) \in Lip (N)^n$ with: $$\|f-\sum_{k=1}^n g_k \otimes h_k \|_\infty \leq \varepsilon,$$ $$\sum_{k=1}^n  \|g_k\|_{Lip(M)} \|h_k\|_{Lip(N)} \leq C,$$ then what is the behaviour of $C(\varepsilon)$ as $\varepsilon$ goes to $0$? The use of the supremum norm in the first equation may seem weird, but that is what occurs in the problem I am looking at. The best case would be if $C(\varepsilon)$ were bounded, but I don't know of the approach the subject.",,"['functional-analysis', 'tensor-products', 'lipschitz-functions']"
87,When do closed subspaces of a Banach space fit together nicely?,When do closed subspaces of a Banach space fit together nicely?,,"Let $E$ be a Banach space, and let $F_1, F_2, F_3, ...$ be a sequence of closed subspaces of $E$ with $F_i\cap F_j=0$ whenever $i\neq j$.  Denote by $\sum_n F_n$ the (not necessarily closed) subspace consisting of finite sums of elements from $\cup_n F_n$.  Do there exist criteria for telling when the topological closure $\overline{\sum_n F_n}$ is the Banach space sum of the $F_n$'s? By that I mean that every element of $\overline{\sum F_n}$ can be written in a unique way as an absolutely convergent sum $\sum_{n=1}^\infty f_n$ $(f_n\in F_n)$. I'm particularly interested in the case where $F_n =E_n$ in this post https://math.stackexchange.com/questions/1210693/a-question-about-a-proof-in-langs-sl-2-mathbbr .  So $$F_n = \{v\in E : \pi(r_\theta)v=e^{in\theta}v \hspace{3mm} \forall r_\theta \in SO_2(\mathbb{R})\}$$ where $\pi$ is some irreducible strongly continuous representation of $SL_2(\mathbb{R})$ in a Banach space $E$.","Let $E$ be a Banach space, and let $F_1, F_2, F_3, ...$ be a sequence of closed subspaces of $E$ with $F_i\cap F_j=0$ whenever $i\neq j$.  Denote by $\sum_n F_n$ the (not necessarily closed) subspace consisting of finite sums of elements from $\cup_n F_n$.  Do there exist criteria for telling when the topological closure $\overline{\sum_n F_n}$ is the Banach space sum of the $F_n$'s? By that I mean that every element of $\overline{\sum F_n}$ can be written in a unique way as an absolutely convergent sum $\sum_{n=1}^\infty f_n$ $(f_n\in F_n)$. I'm particularly interested in the case where $F_n =E_n$ in this post https://math.stackexchange.com/questions/1210693/a-question-about-a-proof-in-langs-sl-2-mathbbr .  So $$F_n = \{v\in E : \pi(r_\theta)v=e^{in\theta}v \hspace{3mm} \forall r_\theta \in SO_2(\mathbb{R})\}$$ where $\pi$ is some irreducible strongly continuous representation of $SL_2(\mathbb{R})$ in a Banach space $E$.",,"['analysis', 'functional-analysis', 'harmonic-analysis']"
88,How to check some topological concepts in product and direct sum spaces,How to check some topological concepts in product and direct sum spaces,,"Given $a=(a_i)_{i=1}^\infty$ with $a_i \geq 0$ and $b=(b_i)_{i=1}^\infty$ with $b_i \in \mathbb{R}$, let $$E_i = \lbrace (x_n)_{n=1}^\infty : n^{b_i}|x_n|\leq a_i, \forall n\in \mathbb{N} \rbrace$$ and $E= (E_i)_{i=1}^\infty$ The question ask for criterion for the sequences $a$ and $b$ such that $E$ to be bounded in ${\oplus}_{p=1}^\infty \ell_p$ and precompact(totally bounded) in $\Pi_{p=1}^\infty \ell_p$. My first thought was that to use Tychonoff's Theorem(The product of any collection of compact topological spaces is compact with respect to the product topology) since compactness require boundedness and precompactness. But couldn't figure it out. I am studying for the midterm which in one week, so I am grateful for any help/hints.","Given $a=(a_i)_{i=1}^\infty$ with $a_i \geq 0$ and $b=(b_i)_{i=1}^\infty$ with $b_i \in \mathbb{R}$, let $$E_i = \lbrace (x_n)_{n=1}^\infty : n^{b_i}|x_n|\leq a_i, \forall n\in \mathbb{N} \rbrace$$ and $E= (E_i)_{i=1}^\infty$ The question ask for criterion for the sequences $a$ and $b$ such that $E$ to be bounded in ${\oplus}_{p=1}^\infty \ell_p$ and precompact(totally bounded) in $\Pi_{p=1}^\infty \ell_p$. My first thought was that to use Tychonoff's Theorem(The product of any collection of compact topological spaces is compact with respect to the product topology) since compactness require boundedness and precompactness. But couldn't figure it out. I am studying for the midterm which in one week, so I am grateful for any help/hints.",,"['real-analysis', 'general-topology', 'functional-analysis', 'lp-spaces', 'topological-vector-spaces']"
89,"Prove that $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}\rightarrow g_{0}$ weakly in $L^{\overline{p}}$ for some $\overline{p}>p*'$",Prove that  weakly in  for some,"\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}\rightarrow g_{0} L^{\overline{p}} \overline{p}>p*'","Let $\Omega  \subset   \mathbb{R}^{N}$   be a smooth bounded domain , $g:\Omega\times\mathbb{R}\rightarrow\mathbb{R}$   is a Caratheodory function such that $g(x,t)=0$   for $t\leq0$  . Suppose that there exist function $a\in L^{r}$   and $d\in L^{p'}$   such that $\left|g(x,t)\right|\leq a(x)t^{p-1}+d(x)$ with $r>N/p$   if $1<p\leq N$   and $r=1$   if $p>N$  ; $p'$   is Holder conjugate of $p$ Let $\left\{ u_{n}\right\} \subset W_{0}^{1,p}$   be a sequence such that $\left\Vert u_{n}\right\Vert \rightarrow\infty$   as $n\rightarrow\infty$  . Let us define $v_{n}=u_{n}/\left\Vert u_{n}\right\Vert $  . Hence $\left\Vert v_{n}\right\Vert =1$   and we may assume that $v_{n}\rightarrow v$   weakly in $W_{0}^{1,p}$  . Prove that $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}\rightarrow g_{0}$   weakly in $L^{\overline{p}}$   for some $\overline{p}>p*'$   if $p<N$   and $\overline{p}=1$   if $p\geq N$  . Here are my efforts: Firstly consider $p<N$   , my intension is: prove that $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}$   is bounded in $L^{\overline{p}}$   for some $\overline{p}>p*'$ $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}\leq a(x)\left|v_{n}\right|^{p-1}+\dfrac{d(x)}{\left\Vert u_{n}\right\Vert ^{p-1}}$ ${\displaystyle \int_{\Omega}}\left|a(x)\left|v_{n}\right|^{p-1}\right|^{\delta}dx\leq{\displaystyle \int_{\Omega}}\left|a(x)\right|^{\delta}\left|v_{n}\right|^{(p-1)\delta}dx$ $\leq\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert \left|v_{n}\right|^{(p-1)\delta}\right\Vert _{L^{\frac{N}{N-p\delta}}}$ $\leq\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert v_{n}\right\Vert _{L^{\frac{N(p-1)\delta}{N-p\delta}}}^{(p-1)\delta}$ I expect that by Sobolev embedding, $\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert v_{n}\right\Vert _{L^{\frac{N(p-1)\delta}{N-p\delta}}}^{(p-1)\delta}\leq C\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert v_{n}\right\Vert ^{(p-1)\delta}=C\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}$  , so we are done. Thus we have to pick $\delta$   such that ${\displaystyle \frac{N(p-1)\delta}{N-p\delta}}<\dfrac{Np}{N-p}  \Longleftrightarrow\delta<\dfrac{pN}{Np-N+p}=p*'$ My trouble is when choose $\overline{p}=\delta$  , we are done that $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}$   is bounded in $L^{\overline{p}}$   with $\overline{p}<p*'$   (not $\overline{p}>p*'$   ). On the other hand if choose $\overline{p}'=\delta$  , we are done that $\overline{p}>p*'$   but $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}$   is bounded in $L^{\overline{p}'}$   , not $L^{\overline{p}}$   . Please help me to take out that trouble. I appreciate your help.","Let $\Omega  \subset   \mathbb{R}^{N}$   be a smooth bounded domain , $g:\Omega\times\mathbb{R}\rightarrow\mathbb{R}$   is a Caratheodory function such that $g(x,t)=0$   for $t\leq0$  . Suppose that there exist function $a\in L^{r}$   and $d\in L^{p'}$   such that $\left|g(x,t)\right|\leq a(x)t^{p-1}+d(x)$ with $r>N/p$   if $1<p\leq N$   and $r=1$   if $p>N$  ; $p'$   is Holder conjugate of $p$ Let $\left\{ u_{n}\right\} \subset W_{0}^{1,p}$   be a sequence such that $\left\Vert u_{n}\right\Vert \rightarrow\infty$   as $n\rightarrow\infty$  . Let us define $v_{n}=u_{n}/\left\Vert u_{n}\right\Vert $  . Hence $\left\Vert v_{n}\right\Vert =1$   and we may assume that $v_{n}\rightarrow v$   weakly in $W_{0}^{1,p}$  . Prove that $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}\rightarrow g_{0}$   weakly in $L^{\overline{p}}$   for some $\overline{p}>p*'$   if $p<N$   and $\overline{p}=1$   if $p\geq N$  . Here are my efforts: Firstly consider $p<N$   , my intension is: prove that $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}$   is bounded in $L^{\overline{p}}$   for some $\overline{p}>p*'$ $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}\leq a(x)\left|v_{n}\right|^{p-1}+\dfrac{d(x)}{\left\Vert u_{n}\right\Vert ^{p-1}}$ ${\displaystyle \int_{\Omega}}\left|a(x)\left|v_{n}\right|^{p-1}\right|^{\delta}dx\leq{\displaystyle \int_{\Omega}}\left|a(x)\right|^{\delta}\left|v_{n}\right|^{(p-1)\delta}dx$ $\leq\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert \left|v_{n}\right|^{(p-1)\delta}\right\Vert _{L^{\frac{N}{N-p\delta}}}$ $\leq\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert v_{n}\right\Vert _{L^{\frac{N(p-1)\delta}{N-p\delta}}}^{(p-1)\delta}$ I expect that by Sobolev embedding, $\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert v_{n}\right\Vert _{L^{\frac{N(p-1)\delta}{N-p\delta}}}^{(p-1)\delta}\leq C\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}\left\Vert v_{n}\right\Vert ^{(p-1)\delta}=C\left\Vert a(x)^{\delta}\right\Vert _{L^{\frac{N}{p\delta}}}$  , so we are done. Thus we have to pick $\delta$   such that ${\displaystyle \frac{N(p-1)\delta}{N-p\delta}}<\dfrac{Np}{N-p}  \Longleftrightarrow\delta<\dfrac{pN}{Np-N+p}=p*'$ My trouble is when choose $\overline{p}=\delta$  , we are done that $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}$   is bounded in $L^{\overline{p}}$   with $\overline{p}<p*'$   (not $\overline{p}>p*'$   ). On the other hand if choose $\overline{p}'=\delta$  , we are done that $\overline{p}>p*'$   but $\dfrac{g(x,u_{n})}{\left\Vert u_{n}\right\Vert ^{p-1}}$   is bounded in $L^{\overline{p}'}$   , not $L^{\overline{p}}$   . Please help me to take out that trouble. I appreciate your help.",,"['real-analysis', 'functional-analysis', 'sobolev-spaces']"
90,Proving completeness of $L^p$,Proving completeness of,L^p,"I want to make sure my understanding of the proof is correct. For a Cauchy sequence $\{f_n\}$ in $L^p$, we want to find a $f\in L^p$ such that $f_n\stackrel{L^p}\to f$ Now, skipping the technicalities of the proof, if we manage find some $f$, for which $$\forall \epsilon>0\;\exists n_0,\; m\geq n_0 \;\;\|f-f_m\|_{L^p}\leq\epsilon$$ Are we done? I'd say yes, as, $f=\underbrace{(f-f_m)}_{\in L^p}+f_m \in L^p$ and $$\epsilon \geq \|f-f_m\|\geq \Big|\|f\|-\|f_m\| \Big|$$ Implies $\|f_m\|\stackrel{L^p}\to \|f\|$ Am I correct in my reasoning? Thank you.","I want to make sure my understanding of the proof is correct. For a Cauchy sequence $\{f_n\}$ in $L^p$, we want to find a $f\in L^p$ such that $f_n\stackrel{L^p}\to f$ Now, skipping the technicalities of the proof, if we manage find some $f$, for which $$\forall \epsilon>0\;\exists n_0,\; m\geq n_0 \;\;\|f-f_m\|_{L^p}\leq\epsilon$$ Are we done? I'd say yes, as, $f=\underbrace{(f-f_m)}_{\in L^p}+f_m \in L^p$ and $$\epsilon \geq \|f-f_m\|\geq \Big|\|f\|-\|f_m\| \Big|$$ Implies $\|f_m\|\stackrel{L^p}\to \|f\|$ Am I correct in my reasoning? Thank you.",,"['sequences-and-series', 'functional-analysis', 'measure-theory', 'banach-spaces']"
91,"Are ""most"" operators on an infinite-dimensional complex Banach space ""diagonalizable""? [closed]","Are ""most"" operators on an infinite-dimensional complex Banach space ""diagonalizable""? [closed]",,"Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 9 years ago . Improve this question This is true for finite-dimensional spaces, of course. To be precise, let $T$ be an operator on a complex Banach space $X$ which is not finite-dimensional. For each $\lambda \in \mathbb{C}$, let $V_\lambda \subseteq X$ be the subspace $\mathrm{ker} (\lambda I - T)$ on which $T$ acts by the scalar $\lambda$. Say that $T$ is diagonalizable if $\sum_\lambda V_\lambda$ is dense in $X$. Or provide a better definition if this one is deficient! Are ""most"" operators diagonalizable? For instance, is the set of diagonalizable operators comeagre? Of course, there are lots of operators which are not diagonalizable, but perhaps, as in the finite-dimensional case, they form a ""small"" set. I suppose it's natural to consider just bounded operators, although I'd be interested in results about unbounded operators, too. Of course, if the answer depends on the Banach space $X$, I'd be very interested to learn about that. In a Hilbert space, we can consider the additional condition that the $V_\lambda$ be orthogonal and probably a lot more can be said; I'm interested in this, but I think I'm primarily interested in the more general notion of diagonalizability I gave. Also, the question makes perfect sense for any topological vector space; I'm interested in non-Banach spaces, too. EDIT I've asked this question on mathoverflow ; answers may fit better over there.","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 9 years ago . Improve this question This is true for finite-dimensional spaces, of course. To be precise, let $T$ be an operator on a complex Banach space $X$ which is not finite-dimensional. For each $\lambda \in \mathbb{C}$, let $V_\lambda \subseteq X$ be the subspace $\mathrm{ker} (\lambda I - T)$ on which $T$ acts by the scalar $\lambda$. Say that $T$ is diagonalizable if $\sum_\lambda V_\lambda$ is dense in $X$. Or provide a better definition if this one is deficient! Are ""most"" operators diagonalizable? For instance, is the set of diagonalizable operators comeagre? Of course, there are lots of operators which are not diagonalizable, but perhaps, as in the finite-dimensional case, they form a ""small"" set. I suppose it's natural to consider just bounded operators, although I'd be interested in results about unbounded operators, too. Of course, if the answer depends on the Banach space $X$, I'd be very interested to learn about that. In a Hilbert space, we can consider the additional condition that the $V_\lambda$ be orthogonal and probably a lot more can be said; I'm interested in this, but I think I'm primarily interested in the more general notion of diagonalizability I gave. Also, the question makes perfect sense for any topological vector space; I'm interested in non-Banach spaces, too. EDIT I've asked this question on mathoverflow ; answers may fit better over there.",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
92,duality of $L^p$ spaces with non $\sigma$ finite measure,duality of  spaces with non  finite measure,L^p \sigma,"Why is the condition that $\mu$ (measure) is $\sigma$-finite is important for the relation $(L^1)^{*} = L^{\infty}$? This condition is added while proving that $(L^p)^{*} = L^{q}$ where $p, q$ are conjugate exponents and $1 \leq p < \infty$. Could someone provide a counter example using counting measure and show that in the case of the measure being not $\sigma$-finite $(L^1)^{*} \neq L^{\infty}$.","Why is the condition that $\mu$ (measure) is $\sigma$-finite is important for the relation $(L^1)^{*} = L^{\infty}$? This condition is added while proving that $(L^p)^{*} = L^{q}$ where $p, q$ are conjugate exponents and $1 \leq p < \infty$. Could someone provide a counter example using counting measure and show that in the case of the measure being not $\sigma$-finite $(L^1)^{*} \neq L^{\infty}$.",,"['real-analysis', 'functional-analysis']"
93,Proving projection operators are bounded,Proving projection operators are bounded,,"Suppose $X$ is the direct sum of two normed linear spaces $X_1,X_2$, ($X=X_1 \dot{+} X_2$). Then I need to prove the projection operators $\Pi_1:X \to X_1$ and $\Pi_2:X \to X_2$ are bounded $\Longleftrightarrow$ both $X_1,X_2$ are closed on $X$. On proving for $\Longrightarrow$] I've tried supposing that if {$x_{1n}$} is a sequence of $X_1$ that converges to an element  $x_1\in X$ then I need to prove that $x_1\in X_1$. To do this, we have the following $\parallel\Pi_1 x_{1n}\parallel_{X_1}\leq M\parallel x_{1n}\parallel_X$ (given the boundedness of $\Pi_1$), then if I take limit as $n\to \infty$ then we have $\lim_{n\to \infty} \parallel x_{1n}\parallel_{X_1}\leq Mx$ which would mean that {$x_{1n}$} converges in $X_1$ Please  help me out on solving this and the other direction as well","Suppose $X$ is the direct sum of two normed linear spaces $X_1,X_2$, ($X=X_1 \dot{+} X_2$). Then I need to prove the projection operators $\Pi_1:X \to X_1$ and $\Pi_2:X \to X_2$ are bounded $\Longleftrightarrow$ both $X_1,X_2$ are closed on $X$. On proving for $\Longrightarrow$] I've tried supposing that if {$x_{1n}$} is a sequence of $X_1$ that converges to an element  $x_1\in X$ then I need to prove that $x_1\in X_1$. To do this, we have the following $\parallel\Pi_1 x_{1n}\parallel_{X_1}\leq M\parallel x_{1n}\parallel_X$ (given the boundedness of $\Pi_1$), then if I take limit as $n\to \infty$ then we have $\lim_{n\to \infty} \parallel x_{1n}\parallel_{X_1}\leq Mx$ which would mean that {$x_{1n}$} converges in $X_1$ Please  help me out on solving this and the other direction as well",,"['functional-analysis', 'operator-theory']"
94,A property of exponential of operators 2,A property of exponential of operators 2,,"Let $X$ be a Banach space. The other day I asked if all bounded operators $A:X\to X$ satisfy the following property: (P) : All bounded nonzero trajectories $t\mapsto e^{tA}x$ satisfy $$\inf_{t\in \mathbb{R}}|e^{tA}x|>0,$$ where $x\in X$ and $e^{tA}$  is the exponential operator defined by $$e^{tA}:=\sum_{k=0}^{+\infty}\frac{t^kA^k}{k!}.$$ If the operator $A$ is scalar ($A=a\in \mathbb{R}$) or in general $A$ is a matrix  then  the property (P) holds as explained here . In infinite dimensions, there exist operators which do not satisfy this property as explained by fedga . So later I observed that operators $A$ such that $t\mapsto e^{t A}$ is bounded on $\mathbb{R}$ satisfy this property because $$|x|=|e^{-tA}e^{tA}x|\leq\left(\sup_{t\in \mathbb{R}}|e^{-tA}|\right)|e^{tA}x|.$$ For operators such that $t\mapsto e^{tA}$ is not bounded in $t\in \mathbb{R}$, there's examples like: $A=iI$ or maybe $A$ is of finite rank (because it works for matrices). So I just feel like if $t\mapsto e^{tA}$ is not bounded in $t$ and $A$ satisfies (P) , then $A$ must be of finite rank or something. I don't know if this is true or not. I am also interested in ""exponential"" of unbounded operators or what it is known as strongly continuous groups of operators.","Let $X$ be a Banach space. The other day I asked if all bounded operators $A:X\to X$ satisfy the following property: (P) : All bounded nonzero trajectories $t\mapsto e^{tA}x$ satisfy $$\inf_{t\in \mathbb{R}}|e^{tA}x|>0,$$ where $x\in X$ and $e^{tA}$  is the exponential operator defined by $$e^{tA}:=\sum_{k=0}^{+\infty}\frac{t^kA^k}{k!}.$$ If the operator $A$ is scalar ($A=a\in \mathbb{R}$) or in general $A$ is a matrix  then  the property (P) holds as explained here . In infinite dimensions, there exist operators which do not satisfy this property as explained by fedga . So later I observed that operators $A$ such that $t\mapsto e^{t A}$ is bounded on $\mathbb{R}$ satisfy this property because $$|x|=|e^{-tA}e^{tA}x|\leq\left(\sup_{t\in \mathbb{R}}|e^{-tA}|\right)|e^{tA}x|.$$ For operators such that $t\mapsto e^{tA}$ is not bounded in $t\in \mathbb{R}$, there's examples like: $A=iI$ or maybe $A$ is of finite rank (because it works for matrices). So I just feel like if $t\mapsto e^{tA}$ is not bounded in $t$ and $A$ satisfies (P) , then $A$ must be of finite rank or something. I don't know if this is true or not. I am also interested in ""exponential"" of unbounded operators or what it is known as strongly continuous groups of operators.",,"['functional-analysis', 'operator-theory', 'exponential-function', 'semigroup-of-operators', 'functional-calculus']"
95,Interchange summation and differentiation for ONB,Interchange summation and differentiation for ONB,,"Let $f = \sum_{n=0}^{\infty} a_n e_n $ where $e_n$ are an ONB of $L^2[0,1].$ Now assume we have that $$\frac{d}{dx}e_n = \lambda_n e_n.$$ Assume $f \in H^1[0,1],$ so i.e. $||f'||_{L^2} < \infty$ I want to say now that $$\frac{d}{dx} f = \sum_{n} a_n \lambda_n e_n$$ but I am not sure how to justify the interchange of summation and differentiation. So I am trying to make rigorous here what physicists always do.","Let $f = \sum_{n=0}^{\infty} a_n e_n $ where $e_n$ are an ONB of $L^2[0,1].$ Now assume we have that $$\frac{d}{dx}e_n = \lambda_n e_n.$$ Assume $f \in H^1[0,1],$ so i.e. $||f'||_{L^2} < \infty$ I want to say now that $$\frac{d}{dx} f = \sum_{n} a_n \lambda_n e_n$$ but I am not sure how to justify the interchange of summation and differentiation. So I am trying to make rigorous here what physicists always do.",,"['real-analysis', 'analysis', 'functional-analysis', 'summation', 'orthonormal']"
96,Why $\|f-g\|=0$ if and only if $f=g$?,Why  if and only if ?,\|f-g\|=0 f=g,"I'm learning Fourier Transformation lately, and in the Course Reader page 23, it defines $\|f\|=\left(\int_0^1 \left|f(t)\right|^2 dt\right)^{1/2}$. And then $\|f-g\|=0$ if and only if $f=g$. My question is what does it mean exactly by $f=g$? Is it a new definition of $f=g$? Since, for example $f=0$ and $g(x)=1$ for $x=0.5$ and $0$ otherwise, will result $f=g$.","I'm learning Fourier Transformation lately, and in the Course Reader page 23, it defines $\|f\|=\left(\int_0^1 \left|f(t)\right|^2 dt\right)^{1/2}$. And then $\|f-g\|=0$ if and only if $f=g$. My question is what does it mean exactly by $f=g$? Is it a new definition of $f=g$? Since, for example $f=0$ and $g(x)=1$ for $x=0.5$ and $0$ otherwise, will result $f=g$.",,"['functional-analysis', 'lp-spaces']"
97,Right shift operator is not compact but is a limit of finite rank operator?,Right shift operator is not compact but is a limit of finite rank operator?,,"I'm doing a preparation for an exam, and I have a doubt concerning the right shift operator, for example in $\ell^2$, $S_d : \ell^2 \to \ell^2$ such that $(x_1,x_2,\ldots) \mapsto (0,x_1,\ldots)$ is standard to show tha $S_d$ is not compact (using the spectral values for example). But if we define $S_{dn} : \ell^2 \to \ell^2$ such that $(x_1,x_2,\ldots,x_n,\ldots) \mapsto (0,x_1,\ldots,x_n,0,0,\ldots)$ then $S_{dn} \to S_d$ and $S_{dn}$ is of finite rank, then $S_d$ should be a compact operator. I know that this affirmation is false, but I can't find why. Thank you for any help.","I'm doing a preparation for an exam, and I have a doubt concerning the right shift operator, for example in $\ell^2$, $S_d : \ell^2 \to \ell^2$ such that $(x_1,x_2,\ldots) \mapsto (0,x_1,\ldots)$ is standard to show tha $S_d$ is not compact (using the spectral values for example). But if we define $S_{dn} : \ell^2 \to \ell^2$ such that $(x_1,x_2,\ldots,x_n,\ldots) \mapsto (0,x_1,\ldots,x_n,0,0,\ldots)$ then $S_{dn} \to S_d$ and $S_{dn}$ is of finite rank, then $S_d$ should be a compact operator. I know that this affirmation is false, but I can't find why. Thank you for any help.",,"['functional-analysis', 'operator-theory']"
98,Is this proof of Schur's lemma (for a densely defined closed operator) mistaken? How to fix it?,Is this proof of Schur's lemma (for a densely defined closed operator) mistaken? How to fix it?,,"I'm trying to understand a version of Schur's lemma for a densely defined closed operator.  It is on page 17 of the book Nonabelian Harmonic Analysis by Howe and Tan. The confusing parts are underlined in red. First of all, since the image of $P_U|_{\Gamma (T)}$ is the domain of $T$ , which is a dense subspace of $U$ , it seems like the image of $U_1$ should be $U$ , not just $(\ker T)^\perp$ .  Secondly, what does $\Gamma(T) \cap V =\{0\}$ have to do with T being closed?  This should be a consequence of the fact that $T$ is a function. So it seems like what actually needs to be shown is that $U_1$ carries $(\ker P_V)^\perp$ isometrically onto $(\ker T)^\perp$ . $U_1$ looks like an isometry, so that's okay.  Also, $P_U|_{\Gamma(T)}$ clearly carries $\ker P_V|_{\Gamma(T)}$ onto $\ker T$ , so if $P_1:=   (P_U|_{\Gamma(T)}^\ast \circ P_U|_{\Gamma(T)})^{1/2}$ preserved $\ker P_V$ maybe I would be in business, but it's only evident to me that $P_U|_{\Gamma(T)}^\ast \circ P_U|_{\Gamma(T)}$ does so.","I'm trying to understand a version of Schur's lemma for a densely defined closed operator.  It is on page 17 of the book Nonabelian Harmonic Analysis by Howe and Tan. The confusing parts are underlined in red. First of all, since the image of is the domain of , which is a dense subspace of , it seems like the image of should be , not just .  Secondly, what does have to do with T being closed?  This should be a consequence of the fact that is a function. So it seems like what actually needs to be shown is that carries isometrically onto . looks like an isometry, so that's okay.  Also, clearly carries onto , so if preserved maybe I would be in business, but it's only evident to me that does so.",P_U|_{\Gamma (T)} T U U_1 U (\ker T)^\perp \Gamma(T) \cap V =\{0\} T U_1 (\ker P_V)^\perp (\ker T)^\perp U_1 P_U|_{\Gamma(T)} \ker P_V|_{\Gamma(T)} \ker T P_1:=   (P_U|_{\Gamma(T)}^\ast \circ P_U|_{\Gamma(T)})^{1/2} \ker P_V P_U|_{\Gamma(T)}^\ast \circ P_U|_{\Gamma(T)},"['functional-analysis', 'analysis', 'representation-theory']"
99,Solve integral(convolution) equation,Solve integral(convolution) equation,,"I have been trying to find a solution to the following convolution equation: \begin{align*} e^{-ax^2/2}*\ln \left(f(x)*e^{-ax^2/2}\right)+e^{-bx^2/2}*\ln \left(f(x)*e^{-bx^2/2}\right)=cx^2 \end{align*} I am trying to solve for $f(x)$ where $a,b,c$ are constants. Note,that '*' denotes convolution. We can assume that $f(x)>0$ and $f(x) \in L^1$. I have been attempting to use Fourier analysis method but so far unsuccessful. For example I have found that  \begin{align*} \mathcal{F}\left (\ln(f(t)\right)=\frac{1}{i\omega} \mathcal{F} \left( \frac{f'(t)}{f(t)}\right) \end{align*} Applying this we get  \begin{align*} \sqrt{\frac{2\pi}{a} }e^{-\omega^2/(2a)} \mathcal{F} \left(\ln \left(f(x)*e^{-ax^2/2}\right) \right)+ \sqrt{\frac{2\pi}{b} }e^{-\omega^2/(2b)} \mathcal{F} \left(\ln \left(f(x)*e^{-bx^2/2}\right) \right)=-2\pi c \delta^{(2)}(\omega) \end{align*} by using $\mathcal{F}\left (\ln(f(t)\right)=\frac{1}{i\omega} \mathcal{F} \left( \frac{f'(t)}{f(t)}\right)$ we get \begin{align*} \sqrt{\frac{2\pi}{a} }e^{-\omega^2/(2a)} \frac{1}{i\omega} \mathcal{F} \left( \frac{f(x)*(-ax)e^{-ax^2/2}}{f(x)*e^{-ax^2/2}}\right)+ \sqrt{\frac{2\pi}{b} }e^{-\omega^2/(2b)} \frac{1}{i\omega} \mathcal{F} \left( \frac{f(x)*(-bx)e^{-bx^2/2}}{f(x)*e^{-bx^2/2}}\right)=-2\pi c \delta^{(2)}(\omega) \end{align*} But how do I proceed now? I am also looking for any related reference. Is also reminds of functional equations, but I am don't know much in that area.  Thank you for any help in advance.","I have been trying to find a solution to the following convolution equation: \begin{align*} e^{-ax^2/2}*\ln \left(f(x)*e^{-ax^2/2}\right)+e^{-bx^2/2}*\ln \left(f(x)*e^{-bx^2/2}\right)=cx^2 \end{align*} I am trying to solve for $f(x)$ where $a,b,c$ are constants. Note,that '*' denotes convolution. We can assume that $f(x)>0$ and $f(x) \in L^1$. I have been attempting to use Fourier analysis method but so far unsuccessful. For example I have found that  \begin{align*} \mathcal{F}\left (\ln(f(t)\right)=\frac{1}{i\omega} \mathcal{F} \left( \frac{f'(t)}{f(t)}\right) \end{align*} Applying this we get  \begin{align*} \sqrt{\frac{2\pi}{a} }e^{-\omega^2/(2a)} \mathcal{F} \left(\ln \left(f(x)*e^{-ax^2/2}\right) \right)+ \sqrt{\frac{2\pi}{b} }e^{-\omega^2/(2b)} \mathcal{F} \left(\ln \left(f(x)*e^{-bx^2/2}\right) \right)=-2\pi c \delta^{(2)}(\omega) \end{align*} by using $\mathcal{F}\left (\ln(f(t)\right)=\frac{1}{i\omega} \mathcal{F} \left( \frac{f'(t)}{f(t)}\right)$ we get \begin{align*} \sqrt{\frac{2\pi}{a} }e^{-\omega^2/(2a)} \frac{1}{i\omega} \mathcal{F} \left( \frac{f(x)*(-ax)e^{-ax^2/2}}{f(x)*e^{-ax^2/2}}\right)+ \sqrt{\frac{2\pi}{b} }e^{-\omega^2/(2b)} \frac{1}{i\omega} \mathcal{F} \left( \frac{f(x)*(-bx)e^{-bx^2/2}}{f(x)*e^{-bx^2/2}}\right)=-2\pi c \delta^{(2)}(\omega) \end{align*} But how do I proceed now? I am also looking for any related reference. Is also reminds of functional equations, but I am don't know much in that area.  Thank you for any help in advance.",,"['real-analysis', 'functional-analysis', 'convolution', 'integral-equations']"
