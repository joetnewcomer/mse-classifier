,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"On odd perfect numbers and $x\varphi(y)=y\varphi(x)$, where $\varphi(n)$ is the Euler's totient function","On odd perfect numbers and , where  is the Euler's totient function",x\varphi(y)=y\varphi(x) \varphi(n),"Motivation. If we presume that there exists an odd perfect number $n$ , then since the Euler's totient function satisfies $$\varphi(n)=n\cdot\prod_{p\mid n}\left(1-\frac{1}{p}\right),$$ then denoting with $\operatorname{rad}(m)=\prod_{p\mid m}p$ the radical of an integer $m\geq 1$ with $\operatorname{rad}(1)=1$ , and $\sigma(m)=\sum_{d\mid m}d$ then sum of divisors function we get that our odd perfect number satisifies $$2\varphi(n)\operatorname{rad}(n)=\sigma(n)\varphi(\operatorname{rad}(n)).$$ That is, our odd perfect number satisifies $$\varphi(n)\operatorname{rad}(n)=n\varphi(\operatorname{rad}(n))\tag{1}$$ and we conclude that our odd perfect number $n$ satisfies by application of the Fermat's little theorem $$2^{n\varphi(\operatorname{rad}(n))}\equiv 1\text{ mod }n,\tag{2}$$ and $$2^{\operatorname{rad}(n)\varphi(n)}\equiv 1\text{ mod }\operatorname{rad}(n).\tag{3}$$ Question 1. Is true or false the following conjecture: If $n>1$ is an odd integer that satisfies $$m\varphi(n)=n\varphi(m)\tag{4}$$ where $m\mid n$ and $m<n$ then $n$ is an odd perfect number with $\operatorname{rad}(n)=m$ . Thus I am asking if you can provide me a proof of the statement or well a counterexample $(n,m)$ of odd integers such that satisfy $(4)$ and $m\mid n$ , but or well $n$ is not an odd perfect nunber or well $m$ is such that $m\neq\operatorname{rad}(n)$ . Question 2. Do you know odd integers $n,m\geq 1$ such that $$2^{n\varphi(m)}\equiv 1\text{ mod }n,$$ and $$2^{m\varphi(n)}\equiv 1\text{ mod }m?$$ (If there are many examples and you want help me, I am especially interested in examples of odd integers $n$ of the form $n\equiv 1\text{ mod }12$ or well of the form $n\equiv 9\text{ mod }36$ , and being $m\mid n$ with $m$ without repeated prime factors.) Thanks in advance.","Motivation. If we presume that there exists an odd perfect number , then since the Euler's totient function satisfies then denoting with the radical of an integer with , and then sum of divisors function we get that our odd perfect number satisifies That is, our odd perfect number satisifies and we conclude that our odd perfect number satisfies by application of the Fermat's little theorem and Question 1. Is true or false the following conjecture: If is an odd integer that satisfies where and then is an odd perfect number with . Thus I am asking if you can provide me a proof of the statement or well a counterexample of odd integers such that satisfy and , but or well is not an odd perfect nunber or well is such that . Question 2. Do you know odd integers such that and (If there are many examples and you want help me, I am especially interested in examples of odd integers of the form or well of the form , and being with without repeated prime factors.) Thanks in advance.","n \varphi(n)=n\cdot\prod_{p\mid n}\left(1-\frac{1}{p}\right), \operatorname{rad}(m)=\prod_{p\mid m}p m\geq 1 \operatorname{rad}(1)=1 \sigma(m)=\sum_{d\mid m}d 2\varphi(n)\operatorname{rad}(n)=\sigma(n)\varphi(\operatorname{rad}(n)). \varphi(n)\operatorname{rad}(n)=n\varphi(\operatorname{rad}(n))\tag{1} n 2^{n\varphi(\operatorname{rad}(n))}\equiv 1\text{ mod }n,\tag{2} 2^{\operatorname{rad}(n)\varphi(n)}\equiv 1\text{ mod }\operatorname{rad}(n).\tag{3} n>1 m\varphi(n)=n\varphi(m)\tag{4} m\mid n m<n n \operatorname{rad}(n)=m (n,m) (4) m\mid n n m m\neq\operatorname{rad}(n) n,m\geq 1 2^{n\varphi(m)}\equiv 1\text{ mod }n, 2^{m\varphi(n)}\equiv 1\text{ mod }m? n n\equiv 1\text{ mod }12 n\equiv 9\text{ mod }36 m\mid n m","['sequences-and-series', 'elementary-number-theory']"
1,Evaluating Sum involving binomial coefficients and powers,Evaluating Sum involving binomial coefficients and powers,,I would like to evaluate the double sum $\sum\limits_{n=1}^{\infty} \sum\limits_{m=1}^{\infty} \dfrac{(n+m)!}{n!m!n^2 m^2}\left(\dfrac{1}{2}\right)^{n+m}$. My starting point was to consider $\sum\limits_{n=1}^{\infty} \sum\limits_{m=1}^{\infty} \dfrac{(n+m)!}{n!m!}x^n y^m = \dfrac{1}{1 -x -y} - \dfrac{1}{1-x} - \dfrac{1}{1-y} + 1$ $\;\;\forall\;\; |x|+|y|<1\;\;$ All what is left is to divide by $xy$ then integrate with respect to $x$ and then with respect to $y$ (process should be repeated twice) finally set $x = y = \frac{1}{2}$. I am however stuck in evaluating the resulting integrals. I expect logarithmic and polylogarithmic functions to show up in the final result. I would appreciate if you can help me formulating the value of this sum. Thanks for your help...,I would like to evaluate the double sum $\sum\limits_{n=1}^{\infty} \sum\limits_{m=1}^{\infty} \dfrac{(n+m)!}{n!m!n^2 m^2}\left(\dfrac{1}{2}\right)^{n+m}$. My starting point was to consider $\sum\limits_{n=1}^{\infty} \sum\limits_{m=1}^{\infty} \dfrac{(n+m)!}{n!m!}x^n y^m = \dfrac{1}{1 -x -y} - \dfrac{1}{1-x} - \dfrac{1}{1-y} + 1$ $\;\;\forall\;\; |x|+|y|<1\;\;$ All what is left is to divide by $xy$ then integrate with respect to $x$ and then with respect to $y$ (process should be repeated twice) finally set $x = y = \frac{1}{2}$. I am however stuck in evaluating the resulting integrals. I expect logarithmic and polylogarithmic functions to show up in the final result. I would appreciate if you can help me formulating the value of this sum. Thanks for your help...,,"['sequences-and-series', 'combinatorics', 'binomial-coefficients', 'polylogarithm']"
2,Closed formula for some cotangent series,Closed formula for some cotangent series,,"I managed to compute some cotangent series, such as $~\displaystyle\sum\limits_{{\substack{i=1\\10~\nmid~i}}}^{\infty}\frac{\cot\left(\dfrac{9\pi}{10}\cdot i\right)}{i}=-\frac{6\pi}{5},~$ and $\displaystyle\sum\limits_{{\substack{i=1\\11~\nmid~i}}}^{\infty}\frac{\cot\left(\dfrac{4\pi}{11}\cdot i\right)}{i}=\frac{3\pi}{11}.~$ I am interested in the general case $$S_{k,~n}~=~\sum\limits_{{\substack{i=1\\n~\nmid~i}}}^{\infty}\frac{\cot\left(\dfrac{k\pi}{n}\cdot i\right)}{i}$$ where $k,~n$ are positive integers with $k<n$ and $\gcd(k,n)=1.~$ References about a closed form (if there is one) or some nice properties will be appreciated.","I managed to compute some cotangent series, such as $~\displaystyle\sum\limits_{{\substack{i=1\\10~\nmid~i}}}^{\infty}\frac{\cot\left(\dfrac{9\pi}{10}\cdot i\right)}{i}=-\frac{6\pi}{5},~$ and $\displaystyle\sum\limits_{{\substack{i=1\\11~\nmid~i}}}^{\infty}\frac{\cot\left(\dfrac{4\pi}{11}\cdot i\right)}{i}=\frac{3\pi}{11}.~$ I am interested in the general case $$S_{k,~n}~=~\sum\limits_{{\substack{i=1\\n~\nmid~i}}}^{\infty}\frac{\cot\left(\dfrac{k\pi}{n}\cdot i\right)}{i}$$ where $k,~n$ are positive integers with $k<n$ and $\gcd(k,n)=1.~$ References about a closed form (if there is one) or some nice properties will be appreciated.",,"['sequences-and-series', 'analysis']"
3,How to calculate the limit $\lim_{n\to \infty}\prod _{i = 1}^{n}\left(1+{1 \over 2^{i}\ -\ i}\right)$,How to calculate the limit,\lim_{n\to \infty}\prod _{i = 1}^{n}\left(1+{1 \over 2^{i}\ -\ i}\right),"How to calculate the limit $$\lim_{n\to \infty}\prod _{i = 1}^{n}\left(1+{1 \over 2^{i}\ -\ i}\right)\ ?$$ I can prove this limit exists by comparing it to the limit $$ \lim_{n \to \infty}\,\,\prod _{i = 1}^{n}\left(1 + {1 \over 2^{i}}\right)\,, $$ and this sequence seems to be related to q-Pochhammer, but I have no idea about the sequence in the title.","How to calculate the limit $$\lim_{n\to \infty}\prod _{i = 1}^{n}\left(1+{1 \over 2^{i}\ -\ i}\right)\ ?$$ I can prove this limit exists by comparing it to the limit $$ \lim_{n \to \infty}\,\,\prod _{i = 1}^{n}\left(1 + {1 \over 2^{i}}\right)\,, $$ and this sequence seems to be related to q-Pochhammer, but I have no idea about the sequence in the title.",,"['sequences-and-series', 'limits']"
4,Which entire functions $h(z)$ can be written as $h(z)=f(z+1)-f(z)$ for some entire function $f$? [duplicate],Which entire functions  can be written as  for some entire function ? [duplicate],h(z) h(z)=f(z+1)-f(z) f,"This question already has answers here : Existence of an holomorphic function (2 answers) Closed 7 years ago . Question : For which entire functions $h(z)$ does there exist an entire function $f(z)$ such that $h(z)=f(z+1)-f(z)$? What I have tried : Suppose that $f:\mathbb{C}\to\mathbb{C}$ is an entire function, and let $\displaystyle f(z)=\sum_{n=0}^\infty a_nz^n$ be its Taylor series expansion.  Then $$\displaystyle f(z+1)=\sum_{n=0}^\infty a_n\sum_{i=0}^n\binom{n}{i}z^i=\sum_{n=0}^\infty z^n\left[\sum_{j=n}^\infty a_j\binom{j}{n}\right].$$ Therefore $$f(z+1)-f(z)=\sum_{n=0}^\infty z^n\left[\sum_{j=n+1}^\infty a_j\binom{j}{n}\right].$$ For $\{a_n\}\in\mathbb{C}^\infty$, define $c_n=\displaystyle\sum_{j=n+1}^\infty a_j\binom{j}{n}$, if this sequence converges.  If $\{a_n\}$ is a sequence for which each $c_n$ converges, then define $\Pi(\{a_n\})=\{c_n\}$. Lets let $\mathscr{H}$ denote the collection of all sequences of complex numbers $\{a_n\}$ such that $\Pi(\{a_n\})$ is well-defined.  Let $\mathscr{H}_e$ denote the collection of sequences such that $\displaystyle\sum_{n=0}^\infty a_nz^n$ has infinite radius of convergence.  It is not hard to see from the above work that $\mathscr{H}_e\subset\mathscr{H}$.  Let $\mathscr{H}_0\subset\mathscr{H}_e$ be the collection of finite sequences (ie those corresponding to polynomials). I know that $\Pi:\mathscr{H}_0\to\mathscr{H}_0$ is surjective.  I want to know what $\Pi(\mathscr{H}_e)$ is (I now know that $\Pi:\mathscr{H}_e\to\mathscr{H}_e$ is not surjective as noted in my comment below). Bonus question : If we mod out $\mathscr{H}$ by the relation $\{a_n\}\sim\{b_n\}$ if and only if $a_k=b_k$ for each $k>0$, then $\Pi:\mathscr{H}_0\to\mathscr{H}_0$ is injective.  Is $\Pi:\mathscr{H}\to\mathscr{H}$ injective when modded out similarly?","This question already has answers here : Existence of an holomorphic function (2 answers) Closed 7 years ago . Question : For which entire functions $h(z)$ does there exist an entire function $f(z)$ such that $h(z)=f(z+1)-f(z)$? What I have tried : Suppose that $f:\mathbb{C}\to\mathbb{C}$ is an entire function, and let $\displaystyle f(z)=\sum_{n=0}^\infty a_nz^n$ be its Taylor series expansion.  Then $$\displaystyle f(z+1)=\sum_{n=0}^\infty a_n\sum_{i=0}^n\binom{n}{i}z^i=\sum_{n=0}^\infty z^n\left[\sum_{j=n}^\infty a_j\binom{j}{n}\right].$$ Therefore $$f(z+1)-f(z)=\sum_{n=0}^\infty z^n\left[\sum_{j=n+1}^\infty a_j\binom{j}{n}\right].$$ For $\{a_n\}\in\mathbb{C}^\infty$, define $c_n=\displaystyle\sum_{j=n+1}^\infty a_j\binom{j}{n}$, if this sequence converges.  If $\{a_n\}$ is a sequence for which each $c_n$ converges, then define $\Pi(\{a_n\})=\{c_n\}$. Lets let $\mathscr{H}$ denote the collection of all sequences of complex numbers $\{a_n\}$ such that $\Pi(\{a_n\})$ is well-defined.  Let $\mathscr{H}_e$ denote the collection of sequences such that $\displaystyle\sum_{n=0}^\infty a_nz^n$ has infinite radius of convergence.  It is not hard to see from the above work that $\mathscr{H}_e\subset\mathscr{H}$.  Let $\mathscr{H}_0\subset\mathscr{H}_e$ be the collection of finite sequences (ie those corresponding to polynomials). I know that $\Pi:\mathscr{H}_0\to\mathscr{H}_0$ is surjective.  I want to know what $\Pi(\mathscr{H}_e)$ is (I now know that $\Pi:\mathscr{H}_e\to\mathscr{H}_e$ is not surjective as noted in my comment below). Bonus question : If we mod out $\mathscr{H}$ by the relation $\{a_n\}\sim\{b_n\}$ if and only if $a_k=b_k$ for each $k>0$, then $\Pi:\mathscr{H}_0\to\mathscr{H}_0$ is injective.  Is $\Pi:\mathscr{H}\to\mathscr{H}$ injective when modded out similarly?",,"['sequences-and-series', 'complex-analysis', 'recurrence-relations', 'entire-functions']"
5,Is it possible to find aproximation of conformal map from sequences of complex points?,Is it possible to find aproximation of conformal map from sequences of complex points?,,"I want to find equation of conformal map (= Fatou function $\Psi : z \to u$ )  which: maps some region of complex plane ( attracting petal) to right half of complex plane in u coordinate $Re(u) > 0 $ transforms function $f(z)$   to unit translation $ F : u \to u+1$ unrolls invariant curvs ( orbits ) : maps  ""circles"" to straight lines Can I find equation which aproximates such map from sequences of points ( complex numbers) ? The easiest case is $f(z)= z^2 + z$ which has parabolic fixed point at origin ( z=0).  Then $\Psi(z) = -1/z$  and $F : u \to u+1+1/(u-1)$, where $2/(u-1)$ is error term ( Adrien Douady, Does a Julia set depend continuously on the polynomial? ) Sequences lay along curves shown inside main chessboard boxe on this image The image is not perfect near boundaries of chessboard box ( there are kinks and curves seems to cross boundary ) On this image one can see the u and z planes for th case f(z)=z^2+z. Src code","I want to find equation of conformal map (= Fatou function $\Psi : z \to u$ )  which: maps some region of complex plane ( attracting petal) to right half of complex plane in u coordinate $Re(u) > 0 $ transforms function $f(z)$   to unit translation $ F : u \to u+1$ unrolls invariant curvs ( orbits ) : maps  ""circles"" to straight lines Can I find equation which aproximates such map from sequences of points ( complex numbers) ? The easiest case is $f(z)= z^2 + z$ which has parabolic fixed point at origin ( z=0).  Then $\Psi(z) = -1/z$  and $F : u \to u+1+1/(u-1)$, where $2/(u-1)$ is error term ( Adrien Douady, Does a Julia set depend continuously on the polynomial? ) Sequences lay along curves shown inside main chessboard boxe on this image The image is not perfect near boundaries of chessboard box ( there are kinks and curves seems to cross boundary ) On this image one can see the u and z planes for th case f(z)=z^2+z. Src code",,"['sequences-and-series', 'numerical-methods', 'functional-equations', 'conformal-geometry', 'complex-dynamics']"
6,Bijective mapping between face polytopes of permutohedra and partitions of integers,Bijective mapping between face polytopes of permutohedra and partitions of integers,,"The OEIS entries A019538 , A049019 , and A133314 , relate a refinement of the face polynomials of the permutohedra (A049019) to partition polynomials (A133314) defined by multiplicative inversion of an exponential generating function (or surjections as noted in A049019 and A133314). For example, with the Taylor series expansion of an analytic function (or formal power series, or e.g.f.) $$f(x) = a_0 + a_1 x + a_2 \frac{x^2}{2!} + \ldots = \exp[a.x]$$ where $a.^n = a_n$, the series expansion of the reciprocal is formally \begin{align} \frac{1}{f(x)} &= a_0^{-1} + a_0^{-2} [-a_1] x \\  &+ a_0^{-3} [2a_1^2 - a_2a_0] \frac{x^2}{2!} + a_0^{-4}[-6 a_1^3 + 6 a_1 a_2 a_0 - a_3 a_0^2 ] \frac{x^3}{3!} \\ &+ a_0^{-5} [24 a_1^4 - 36 a_1^2 a_2 a_0 + (8 a_1 a_3 + 6 a_2^2) a_0^2 - a_4 a_0^3] \frac{x^4}{4!}+ \ldots \\  &= \exp[Pt.(a_0,a_1, \ldots )x/a_0] / a_0\; , \end{align} and the unsigned coefficients of the partition polynomial $Pt_4(a_0,a_1,a_2,a_4)$ for the fourth order term with partitions of the integer four characterize the $P_3$ permutohedron depicted in Wikipedia with 24 vertices (0-D faces), 36 edges (1-D faces), 8 hexagons (2-D faces), 6 tetragons (2-D faces),  and 1 3-D permutohedron. Summing coefficients over like dimensions gives A019538 and A090582 . Question I : Is there a bijective mapping between the integer partitions and the different polytopes of the n-D faces of the permutohedra for higher dimensions? There is a listing of the different polytopes comprising the faces of the 4-D permutohedron, the runcinated 5-cell , in Wikipedia, with such a bijection also.","The OEIS entries A019538 , A049019 , and A133314 , relate a refinement of the face polynomials of the permutohedra (A049019) to partition polynomials (A133314) defined by multiplicative inversion of an exponential generating function (or surjections as noted in A049019 and A133314). For example, with the Taylor series expansion of an analytic function (or formal power series, or e.g.f.) $$f(x) = a_0 + a_1 x + a_2 \frac{x^2}{2!} + \ldots = \exp[a.x]$$ where $a.^n = a_n$, the series expansion of the reciprocal is formally \begin{align} \frac{1}{f(x)} &= a_0^{-1} + a_0^{-2} [-a_1] x \\  &+ a_0^{-3} [2a_1^2 - a_2a_0] \frac{x^2}{2!} + a_0^{-4}[-6 a_1^3 + 6 a_1 a_2 a_0 - a_3 a_0^2 ] \frac{x^3}{3!} \\ &+ a_0^{-5} [24 a_1^4 - 36 a_1^2 a_2 a_0 + (8 a_1 a_3 + 6 a_2^2) a_0^2 - a_4 a_0^3] \frac{x^4}{4!}+ \ldots \\  &= \exp[Pt.(a_0,a_1, \ldots )x/a_0] / a_0\; , \end{align} and the unsigned coefficients of the partition polynomial $Pt_4(a_0,a_1,a_2,a_4)$ for the fourth order term with partitions of the integer four characterize the $P_3$ permutohedron depicted in Wikipedia with 24 vertices (0-D faces), 36 edges (1-D faces), 8 hexagons (2-D faces), 6 tetragons (2-D faces),  and 1 3-D permutohedron. Summing coefficients over like dimensions gives A019538 and A090582 . Question I : Is there a bijective mapping between the integer partitions and the different polytopes of the n-D faces of the permutohedra for higher dimensions? There is a listing of the different polytopes comprising the faces of the 4-D permutohedron, the runcinated 5-cell , in Wikipedia, with such a bijection also.",,"['sequences-and-series', 'combinatorics', 'polynomials', 'convex-geometry', 'oeis']"
7,Strange behavior of infinite products $\prod^{\infty}_{n=1} \ln (1+ \frac{1}{n} )^n$ and $\prod^{\infty}_{n=1} \ln (1+ \frac{1}{n} )^{n+1}$,Strange behavior of infinite products  and,\prod^{\infty}_{n=1} \ln (1+ \frac{1}{n} )^n \prod^{\infty}_{n=1} \ln (1+ \frac{1}{n} )^{n+1},"There are two expressions marking the lower and upper bounds for number $e$: $$\left(1+\frac{1}{n} \right)^n \leq e \leq \left(1+\frac{1}{n} \right)^{n+1}$$ Naturally, I wanted to know if infinite products of their logarithms converge to the same value. I was greatly surprised to find that not only do they not converge to the same value, but one of them converges to zero and the other to infinity: $$\prod^{\infty}_{n=1} \ln \left(1+ \frac{1}{n} \right)^n=0$$ $$\prod^{\infty}_{n=1} \ln \left(1+ \frac{1}{n} \right)^{n+1} \rightarrow + \infty$$ On the other hand their product (or equally, the infinite product of their geometric means) converges, but not to $1$: $$\prod^{\infty}_{n=1} \ln \left(1+ \frac{1}{n} \right)^{n} \ln \left(1+ \frac{1}{n} \right)^{n+1}=\prod^{\infty}_{n=1} n(n+1) \ln^2 \left(1+ \frac{1}{n} \right) \rightarrow P$$ Mathematica gives the following values (since $P_n$ is decreasing, it's certainly less than $1$): $$P(14999)=0.921971686261$$ $$P(15000)=0.921971685920$$ The convergence (or divergence) can be proved using the corresponding series and the integral test: $$\sum^{\infty}_{n=1} \ln \ln \left(1+ \frac{1}{n} \right)^n $$ $$\int^{\infty}_{1} \ln \left( x \ln \left(1+ \frac{1}{x} \right)\right) dx =\int^{1}_{0} \frac{1}{y^2} \ln  \left( \frac{\ln \left(1+ y \right)}{y} \right) dy\rightarrow - \infty $$ This integral does not converge (according to Wolframalpha ) $$\sum^{\infty}_{n=1} \ln \ln \left(1+ \frac{1}{n} \right)^{n+1} $$ $$\int^{\infty}_{1} \ln \left( (x+1) \ln \left(1+ \frac{1}{x} \right)\right) dx =\int^{1}_{0} \frac{1}{y^2} \ln \left( \left(1+ \frac{1}{y} \right) \ln \left(1+ y \right) \right) dy\rightarrow + \infty $$ This integral also does not converge (according to Wolframalpha ) Finally, the 'mean' infinite product gives (see Wolframalpha ): $$\int^{1}_{0} \frac{1}{y^2} \ln \left( \frac{1}{y} \left(1+ \frac{1}{y} \right) \ln^2 \left(1+ y \right) \right) dy=-0.0569274$$ So, this infinite product converges, but not to $1$ according to Mathematica. Is there any explanation for all this? Is it connected to the special    properties of $e$?","There are two expressions marking the lower and upper bounds for number $e$: $$\left(1+\frac{1}{n} \right)^n \leq e \leq \left(1+\frac{1}{n} \right)^{n+1}$$ Naturally, I wanted to know if infinite products of their logarithms converge to the same value. I was greatly surprised to find that not only do they not converge to the same value, but one of them converges to zero and the other to infinity: $$\prod^{\infty}_{n=1} \ln \left(1+ \frac{1}{n} \right)^n=0$$ $$\prod^{\infty}_{n=1} \ln \left(1+ \frac{1}{n} \right)^{n+1} \rightarrow + \infty$$ On the other hand their product (or equally, the infinite product of their geometric means) converges, but not to $1$: $$\prod^{\infty}_{n=1} \ln \left(1+ \frac{1}{n} \right)^{n} \ln \left(1+ \frac{1}{n} \right)^{n+1}=\prod^{\infty}_{n=1} n(n+1) \ln^2 \left(1+ \frac{1}{n} \right) \rightarrow P$$ Mathematica gives the following values (since $P_n$ is decreasing, it's certainly less than $1$): $$P(14999)=0.921971686261$$ $$P(15000)=0.921971685920$$ The convergence (or divergence) can be proved using the corresponding series and the integral test: $$\sum^{\infty}_{n=1} \ln \ln \left(1+ \frac{1}{n} \right)^n $$ $$\int^{\infty}_{1} \ln \left( x \ln \left(1+ \frac{1}{x} \right)\right) dx =\int^{1}_{0} \frac{1}{y^2} \ln  \left( \frac{\ln \left(1+ y \right)}{y} \right) dy\rightarrow - \infty $$ This integral does not converge (according to Wolframalpha ) $$\sum^{\infty}_{n=1} \ln \ln \left(1+ \frac{1}{n} \right)^{n+1} $$ $$\int^{\infty}_{1} \ln \left( (x+1) \ln \left(1+ \frac{1}{x} \right)\right) dx =\int^{1}_{0} \frac{1}{y^2} \ln \left( \left(1+ \frac{1}{y} \right) \ln \left(1+ y \right) \right) dy\rightarrow + \infty $$ This integral also does not converge (according to Wolframalpha ) Finally, the 'mean' infinite product gives (see Wolframalpha ): $$\int^{1}_{0} \frac{1}{y^2} \ln \left( \frac{1}{y} \left(1+ \frac{1}{y} \right) \ln^2 \left(1+ y \right) \right) dy=-0.0569274$$ So, this infinite product converges, but not to $1$ according to Mathematica. Is there any explanation for all this? Is it connected to the special    properties of $e$?",,"['sequences-and-series', 'limits', 'definite-integrals', 'infinite-product']"
8,Is the Completeness of $X$ really necessary here?,Is the Completeness of  really necessary here?,X,"From an exercise in Kreyszig's Functional Analysis, it is stated that Let $X$ be a Banach Space and $(x_n)$ be a sequence in $X$ such that the sequence $(f(x_n))$ is bounded $\forall f\in X'$, show that $(\|x_n\|)$ is bounded. I attempted to prove it by letting $g_n\in X''$ be the canonical image of $x_n$ and invoked the Uniform Boundedness Theorem to show that the sequence $(\|g_n\|)$ is bounded. Since $\|g_n\|=\|x_n\|$, the sequence $(\|x_n\|)$ is bounded so the theorem is proved. However, I noticed that nowhere in the proof did I once use the fact that $X$ is complete. The closest thing I used is the completeness of $X'$ but $X'$ is always a Banach Space regardless of $X$ so I am at lose. So, is my proof correct? If it's not, then how could I use the completeness of $X$ to fix it? Thank you in advance. Edit : It appears that $X$ being a Banach Space is really not necessary after all. Anyway, can anyone think of a way to prove it using the fact that $X$ is complete?","From an exercise in Kreyszig's Functional Analysis, it is stated that Let $X$ be a Banach Space and $(x_n)$ be a sequence in $X$ such that the sequence $(f(x_n))$ is bounded $\forall f\in X'$, show that $(\|x_n\|)$ is bounded. I attempted to prove it by letting $g_n\in X''$ be the canonical image of $x_n$ and invoked the Uniform Boundedness Theorem to show that the sequence $(\|g_n\|)$ is bounded. Since $\|g_n\|=\|x_n\|$, the sequence $(\|x_n\|)$ is bounded so the theorem is proved. However, I noticed that nowhere in the proof did I once use the fact that $X$ is complete. The closest thing I used is the completeness of $X'$ but $X'$ is always a Banach Space regardless of $X$ so I am at lose. So, is my proof correct? If it's not, then how could I use the completeness of $X$ to fix it? Thank you in advance. Edit : It appears that $X$ being a Banach Space is really not necessary after all. Anyway, can anyone think of a way to prove it using the fact that $X$ is complete?",,"['sequences-and-series', 'functional-analysis', 'metric-spaces', 'banach-spaces']"
9,If $(u_n)$ is bounded and $\lim u_n^2+u_n-u_{n+1}=0$ then $u_n \to 0$,If  is bounded and  then,(u_n) \lim u_n^2+u_n-u_{n+1}=0 u_n \to 0,"Let $(u_n)$ be a real bounded sequence. Suppose that $\lim\limits_{n \to \infty} (u_n^2+u_n-u_{n+1})=0$. Prove that $u_n \to 0$. I was able to develop a prove, looking at the map $x \mapsto x^2+x$ and proving that $0$ is the only possible limit point of $(u_n)$. But the proof has several cases... Not something very straightforward. Do your have any idea of something simple?","Let $(u_n)$ be a real bounded sequence. Suppose that $\lim\limits_{n \to \infty} (u_n^2+u_n-u_{n+1})=0$. Prove that $u_n \to 0$. I was able to develop a prove, looking at the map $x \mapsto x^2+x$ and proving that $0$ is the only possible limit point of $(u_n)$. But the proof has several cases... Not something very straightforward. Do your have any idea of something simple?",,"['sequences-and-series', 'convergence-divergence']"
10,Intriguing Poisson sum with hyperbolic function,Intriguing Poisson sum with hyperbolic function,,"I've been playing with lots of Poisson sums lately, and I thought this one to be interesting: $$\sum_{k\in\mathbb{Z}}\left(\frac{1}{(k+x)\sinh{(k+x)\pi q}}-\frac{1}{\pi q (k+x)^2}\right)$$I want to find a closed form for this sum and its derivatives over $x$ when $x=0$ and $q=1$. Since its poles are of the form $k+\frac{in}{q}\,(k,n\text { integers})$ with double-order poles at the integers, I figure its expression may include trigonometric and theta functions...but I can't figure anything beyond its singularities. Any help would be appreciated. I've managed to turn the sum into a Fourier series $\left(-4\sum_{k\ge 1}\ln(1+e^{-2k\pi / q})\cos{2k\pi x}\right)\quad\;$, but even with its simplicity, I haven't been able to crack it. (Edit) I think I have a way to evaluate the Fourier series: if I expand the cosines into Taylor series, then I just have to sum series of the form $$\sum_{k \ge 1}k^{2n}\ln(1+e^{-2k\pi/q})$$ which I can rewrite as $$\sum_{m\ge 1}\frac{(-1)^{m-1}}m\sum_{k\ge 1}k^{2n}e^{-2km\pi/q}$$and since $\displaystyle{\sum_{k\ge 1}e^{-2km\pi/q}=\frac1{e^{2m\pi/q}-1}}$, $\displaystyle{\sum_{k\ge 1}k^2e^{-2km\pi/q}=\frac14\frac{\cosh{\frac{m\pi}q}}{\sinh^3{\frac{m\pi}q}}}$ and subsequent sums consist of a hyperbolic cosine times an odd reciprocal polynomial in the hyperbolic sine, I've reduced my problem to evaluating sums of the form $$\sum_{m \ge 1}\frac{(-1)^{m-1}}m \frac{\cosh{\frac{m\pi}q}}{\sinh^{2n+1}{\frac{m\pi}q}}$$which is also $\displaystyle{\int{\sum_{k\ge 1}\frac{(-1)^{k-1}\sinh{kz}}{\sinh^{2n+1}{\frac{k\pi}q}}\, dz}}$ with $z=\frac{i\pi}q$. But here I am stuck.","I've been playing with lots of Poisson sums lately, and I thought this one to be interesting: $$\sum_{k\in\mathbb{Z}}\left(\frac{1}{(k+x)\sinh{(k+x)\pi q}}-\frac{1}{\pi q (k+x)^2}\right)$$I want to find a closed form for this sum and its derivatives over $x$ when $x=0$ and $q=1$. Since its poles are of the form $k+\frac{in}{q}\,(k,n\text { integers})$ with double-order poles at the integers, I figure its expression may include trigonometric and theta functions...but I can't figure anything beyond its singularities. Any help would be appreciated. I've managed to turn the sum into a Fourier series $\left(-4\sum_{k\ge 1}\ln(1+e^{-2k\pi / q})\cos{2k\pi x}\right)\quad\;$, but even with its simplicity, I haven't been able to crack it. (Edit) I think I have a way to evaluate the Fourier series: if I expand the cosines into Taylor series, then I just have to sum series of the form $$\sum_{k \ge 1}k^{2n}\ln(1+e^{-2k\pi/q})$$ which I can rewrite as $$\sum_{m\ge 1}\frac{(-1)^{m-1}}m\sum_{k\ge 1}k^{2n}e^{-2km\pi/q}$$and since $\displaystyle{\sum_{k\ge 1}e^{-2km\pi/q}=\frac1{e^{2m\pi/q}-1}}$, $\displaystyle{\sum_{k\ge 1}k^2e^{-2km\pi/q}=\frac14\frac{\cosh{\frac{m\pi}q}}{\sinh^3{\frac{m\pi}q}}}$ and subsequent sums consist of a hyperbolic cosine times an odd reciprocal polynomial in the hyperbolic sine, I've reduced my problem to evaluating sums of the form $$\sum_{m \ge 1}\frac{(-1)^{m-1}}m \frac{\cosh{\frac{m\pi}q}}{\sinh^{2n+1}{\frac{m\pi}q}}$$which is also $\displaystyle{\int{\sum_{k\ge 1}\frac{(-1)^{k-1}\sinh{kz}}{\sinh^{2n+1}{\frac{k\pi}q}}\, dz}}$ with $z=\frac{i\pi}q$. But here I am stuck.",,"['sequences-and-series', 'fourier-series', 'closed-form', 'hyperbolic-functions']"
11,"If $f_1(k)=\sum_{i=1}^k\frac{1}{i}$ and $f_n(k)=\sum_{i=1}^kf_{n-1}(i)$, then what is $f_n(n)$?","If  and , then what is ?",f_1(k)=\sum_{i=1}^k\frac{1}{i} f_n(k)=\sum_{i=1}^kf_{n-1}(i) f_n(n),"Let $$f_1(k)=\sum_{i=1}^k\frac{1}{i},$$ and define inductively $$f_n(k)=\sum_{i=1}^kf_{n-1}(i).$$ So, $$f_2(k)=\sum_{i_2=1}^k\sum_{i_1=1}^{i_2}\frac{1}{i_1},\quad f_2(k)=\sum_{i_3=1}^k\sum_{i_2=1}^{i_3}\sum_{i_1=1}^{i_2}\frac{1}{i_1},$$ and so on. Question: What is $f_n(n)$ for all $n\in\mathbb{N}$? The first few terms are $$1,\frac{5}{2},\frac{47}{6},\frac{319}{12},\frac{1879}{20},\ldots$$ but I find difficult to find the general pattern. Added: The numerators appear to be the coefficients in the power series of $$-\ln(1+x)\ln(1-x).$$ This is very interesting...","Let $$f_1(k)=\sum_{i=1}^k\frac{1}{i},$$ and define inductively $$f_n(k)=\sum_{i=1}^kf_{n-1}(i).$$ So, $$f_2(k)=\sum_{i_2=1}^k\sum_{i_1=1}^{i_2}\frac{1}{i_1},\quad f_2(k)=\sum_{i_3=1}^k\sum_{i_2=1}^{i_3}\sum_{i_1=1}^{i_2}\frac{1}{i_1},$$ and so on. Question: What is $f_n(n)$ for all $n\in\mathbb{N}$? The first few terms are $$1,\frac{5}{2},\frac{47}{6},\frac{319}{12},\frac{1879}{20},\ldots$$ but I find difficult to find the general pattern. Added: The numerators appear to be the coefficients in the power series of $$-\ln(1+x)\ln(1-x).$$ This is very interesting...",,"['sequences-and-series', 'recurrence-relations']"
12,Nested recurrence sequence with interesting properties,Nested recurrence sequence with interesting properties,,"This is my first post here, thanks for stopping by. The question as written below comes from the book 'A Concise Introduction To Pure Mathematics'. I've included my working (this isn't a homework problem) and points I am interested in - particularly, the thought process that you had in dealing with this problem. Critic Ivor Smallbrain has been keeping a careful account of the number of chocolate bars he has eaten during film screenings over his career. For each positive integer $n$ he denotes by $a_n$ the total number of bars he consumed during the first n films. One evening, during a screening of the Christmas epic It's a Wonderful Proof , he notices that the sequence $a_1 , a_2 , ...$ obeys the following rules for all $ n => 1$: $a_{n+1} > a_n $ $a_{a_n} = 3n$ Also $a_1 > 0$ (a) Find $a_1$ . ( Hint : Let $x=a_1$. Then what is $a_x$?) (b) Find $a_2 , a_3 , ... , a_8 , a_9$ (c) Find $a_{100}$ (d) Investigate the sequence $a_1 , a_2 , ...$ further. (a) Well, we would be good to make use of the hint, so that $a_x = a_{a_1} = 3$ by the second property. Now, let us say that x is greater than or equal to four. As the sequence is strictly increasing, the terms before $a_x$ are strictly decreasing, thus we would run out of terms if this were the case. Hence x must be less than 4, so x is 1,2 or 3, remembering that the first term of the sequence is at least one. Well, suppose that x is 1. Then we get $a_1 = a_x = a_{a_1} = 3$, an absurdity. So, we investigate if x is 3. Then $a_3 = a_x = a_{a_1} = 3$ Yet we recall x is $a_1$ and the sequence is strictly increasing, so this is an absurdity. (b) Knowing that $a_1 = 2$ we note $3 = a_{a_1} = a_2$ by the second property. Similarly, $6=a_{a_2}=a_3$ so $9 = a_{a_3} = a_6$. Now, we are looking for $a_5$ and $a_4$, but this is made easy by the first property; the sequence is increasing, and the third term is 6, the sixth term is 9. Hence the fourth is 7 and the fifth 8. So, to sum; $a_1$ = 2 $a_2$ = 3 $a_3$ = 6 $a_4$ = 7 $a_5$ = 8 $a_6$ = 9 To finish, note the seventh term is obtained from the fourth, to be 12,the eighth from the fifth, to be 15, and the ninth from the sixth, to be 18. (c) - (d) - Parts I am stuck on. Well, it sounds like if you could answer (d) with an explicit formula then obtaining the answer for (c) would be fine - you just plug in n = 100. However, I am struggling to find how you can 'skip' finding numbers. From the working above it appears to me that I need to find all terms before the hundredth. I am asking for your help in not merely a method, but in illumination - please explain to me why you are doing this or that and so forth - I am hoping to learn something here, and if you can answer this, then whatever you say will be something I and all people can learn from so do not hold back - say anything.","This is my first post here, thanks for stopping by. The question as written below comes from the book 'A Concise Introduction To Pure Mathematics'. I've included my working (this isn't a homework problem) and points I am interested in - particularly, the thought process that you had in dealing with this problem. Critic Ivor Smallbrain has been keeping a careful account of the number of chocolate bars he has eaten during film screenings over his career. For each positive integer $n$ he denotes by $a_n$ the total number of bars he consumed during the first n films. One evening, during a screening of the Christmas epic It's a Wonderful Proof , he notices that the sequence $a_1 , a_2 , ...$ obeys the following rules for all $ n => 1$: $a_{n+1} > a_n $ $a_{a_n} = 3n$ Also $a_1 > 0$ (a) Find $a_1$ . ( Hint : Let $x=a_1$. Then what is $a_x$?) (b) Find $a_2 , a_3 , ... , a_8 , a_9$ (c) Find $a_{100}$ (d) Investigate the sequence $a_1 , a_2 , ...$ further. (a) Well, we would be good to make use of the hint, so that $a_x = a_{a_1} = 3$ by the second property. Now, let us say that x is greater than or equal to four. As the sequence is strictly increasing, the terms before $a_x$ are strictly decreasing, thus we would run out of terms if this were the case. Hence x must be less than 4, so x is 1,2 or 3, remembering that the first term of the sequence is at least one. Well, suppose that x is 1. Then we get $a_1 = a_x = a_{a_1} = 3$, an absurdity. So, we investigate if x is 3. Then $a_3 = a_x = a_{a_1} = 3$ Yet we recall x is $a_1$ and the sequence is strictly increasing, so this is an absurdity. (b) Knowing that $a_1 = 2$ we note $3 = a_{a_1} = a_2$ by the second property. Similarly, $6=a_{a_2}=a_3$ so $9 = a_{a_3} = a_6$. Now, we are looking for $a_5$ and $a_4$, but this is made easy by the first property; the sequence is increasing, and the third term is 6, the sixth term is 9. Hence the fourth is 7 and the fifth 8. So, to sum; $a_1$ = 2 $a_2$ = 3 $a_3$ = 6 $a_4$ = 7 $a_5$ = 8 $a_6$ = 9 To finish, note the seventh term is obtained from the fourth, to be 12,the eighth from the fifth, to be 15, and the ninth from the sixth, to be 18. (c) - (d) - Parts I am stuck on. Well, it sounds like if you could answer (d) with an explicit formula then obtaining the answer for (c) would be fine - you just plug in n = 100. However, I am struggling to find how you can 'skip' finding numbers. From the working above it appears to me that I need to find all terms before the hundredth. I am asking for your help in not merely a method, but in illumination - please explain to me why you are doing this or that and so forth - I am hoping to learn something here, and if you can answer this, then whatever you say will be something I and all people can learn from so do not hold back - say anything.",,['sequences-and-series']
13,Euler's proof of divergence of sum of reciprocals of primes,Euler's proof of divergence of sum of reciprocals of primes,,"On Wikipedia at link currently is: \begin{align}  \ln \left( \sum_{n=1}^\infty \frac{1}{n}\right) & {} = \ln\left( \prod_p \frac{1}{1-p^{-1}}\right)   = -\sum_p \ln \left( 1-\frac{1}{p}\right) \\  & {} = \sum_p \left( \frac{1}{p} + \frac{1}{2p^2} + \frac{1}{3p^3} + \cdots \right) \\  & {} = \left( \sum_{p}\frac{1}{p} \right) + \sum_p \frac{1}{p^2} \left( \frac{1}{2} + \frac{1}{3p} + \frac{1}{4p^2} + \cdots \right) \\  & {} < \left( \sum_p \frac{1}{p} \right) + \sum_p \frac{1}{p^2} \left( 1 + \frac{1}{p} + \frac{1}{p^2} + \cdots \right) \\  & {} = \left( \sum_p \frac{1}{p} \right) + \left( \sum_p \frac{1}{p(p-1)} \right) \\  & {} = \left( \sum_p \frac{1}{p} \right) + C \end{align} and since $\sum_{n=1}^{\infty} \frac{1}{n}$ diverges, so must $\sum_{p} \frac{1}{p}.$ Currently there is language like ""audacious leaps of logic"" and ""correct result by questionable means"". Wouldn't this be a valid proof if we reversed it, though? If we assume $\sum_p \frac{1}{p}$ converges, can't we just go through the steps backwards and find $\sum_{n=1}^{\infty} \frac{1}{n}$ converges, contradiction? Euler's work seems reasonable to me.","On Wikipedia at link currently is: \begin{align}  \ln \left( \sum_{n=1}^\infty \frac{1}{n}\right) & {} = \ln\left( \prod_p \frac{1}{1-p^{-1}}\right)   = -\sum_p \ln \left( 1-\frac{1}{p}\right) \\  & {} = \sum_p \left( \frac{1}{p} + \frac{1}{2p^2} + \frac{1}{3p^3} + \cdots \right) \\  & {} = \left( \sum_{p}\frac{1}{p} \right) + \sum_p \frac{1}{p^2} \left( \frac{1}{2} + \frac{1}{3p} + \frac{1}{4p^2} + \cdots \right) \\  & {} < \left( \sum_p \frac{1}{p} \right) + \sum_p \frac{1}{p^2} \left( 1 + \frac{1}{p} + \frac{1}{p^2} + \cdots \right) \\  & {} = \left( \sum_p \frac{1}{p} \right) + \left( \sum_p \frac{1}{p(p-1)} \right) \\  & {} = \left( \sum_p \frac{1}{p} \right) + C \end{align} and since $\sum_{n=1}^{\infty} \frac{1}{n}$ diverges, so must $\sum_{p} \frac{1}{p}.$ Currently there is language like ""audacious leaps of logic"" and ""correct result by questionable means"". Wouldn't this be a valid proof if we reversed it, though? If we assume $\sum_p \frac{1}{p}$ converges, can't we just go through the steps backwards and find $\sum_{n=1}^{\infty} \frac{1}{n}$ converges, contradiction? Euler's work seems reasonable to me.",,"['sequences-and-series', 'prime-numbers', 'fake-proofs']"
14,Does the series $\sum_{i=0}^{\infty}\exp\{{-(m!)!}\}(D^m\phi)(0)$ converge for every $\phi \in C^\infty$?,Does the series  converge for every ?,\sum_{i=0}^{\infty}\exp\{{-(m!)!}\}(D^m\phi)(0) \phi \in C^\infty,"Does the series $$\sum_{m=0}^{\infty}\exp\{{-(m!)!}\}(D^m\phi)(0)$$   converge for every $\phi \in C^\infty$? For analytic function $\phi$, we can show that the series converges by using Caushy-Schwartz inequality. But I believe in general that there is an example that the series diverges. Although we have a Taylor expansion $$\phi(x)-\phi(0)=x\phi'(x)+...+\frac{x^n}{n!}\phi^{(n)}(x)+\int_0^x\frac{y^n}{n!}\phi^{(n)}(y)dy$$ it seems to be useless because we don't have any information of $\phi^{(n)}(y)$. How to make the growth of $\phi^{(n)}(0)$ fast?","Does the series $$\sum_{m=0}^{\infty}\exp\{{-(m!)!}\}(D^m\phi)(0)$$   converge for every $\phi \in C^\infty$? For analytic function $\phi$, we can show that the series converges by using Caushy-Schwartz inequality. But I believe in general that there is an example that the series diverges. Although we have a Taylor expansion $$\phi(x)-\phi(0)=x\phi'(x)+...+\frac{x^n}{n!}\phi^{(n)}(x)+\int_0^x\frac{y^n}{n!}\phi^{(n)}(y)dy$$ it seems to be useless because we don't have any information of $\phi^{(n)}(y)$. How to make the growth of $\phi^{(n)}(0)$ fast?",,"['sequences-and-series', 'analysis']"
15,"How to find the series $\sum_{n=1}^{\infty}\frac{[(n-1)!]^2}{(2n)!}(2x)^{2n},$",How to find the series,"\sum_{n=1}^{\infty}\frac{[(n-1)!]^2}{(2n)!}(2x)^{2n},","Find this sum   $$\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n)!}(2x)^{2n}.\qquad (-1\le x\le 1)$$ My idea: let $$f(x)=\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n)!}(2x)^{2n},$$ then we have $$f'(x)=2\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n-1)!}(2x)^{2n-1}$$ $$f''(x)=4\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n-2)!}(2x)^{2n-2}$$ and so on. Then I can't solve it. Thank you for your help.","Find this sum   $$\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n)!}(2x)^{2n}.\qquad (-1\le x\le 1)$$ My idea: let $$f(x)=\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n)!}(2x)^{2n},$$ then we have $$f'(x)=2\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n-1)!}(2x)^{2n-1}$$ $$f''(x)=4\sum_{n=1}^{\infty}\dfrac{[(n-1)!]^2}{(2n-2)!}(2x)^{2n-2}$$ and so on. Then I can't solve it. Thank you for your help.",,['sequences-and-series']
16,Asymptotic expansion for harmonic sum in two variables,Asymptotic expansion for harmonic sum in two variables,,"I am interested in determining an asymptotic formula for the double summation of $1/(ab)$, where $a$ is an odd integer ranging between 1 and $k/\sqrt{j}$, $b$ is an odd integer ranging between $a$ and $aj$, $j$ is a real number $>1$, and $k$ tends to infinity.  In symbols, $$ \sum_{\substack{1 \leq a \leq k/\sqrt{j} \\ a \text{ odd}}} \sum_{\substack{a \leq b \leq aj \\ b \text{ odd}}} \frac{1}{ab}. $$ For $j=1$, the result of the summation simply corresponds to the infinite harmonic sum of odd squares $1/1 + 1/9 + 1/25\ldots $, which yields $\pi^2/8$. For $j>1$, I obtained the formula $\tfrac{1}{4} \ln(k) \ln(j) + O(1)$. I am particularly interested in this $O(1)$ term. Plotting this term vs $j$ we obtain a discontinuous function, where the most evident discontinuities occur when $j$ is an odd integer.  For instance, setting $j=2$, the constant term is about $0.94$. It progressively decreases (with other discontinuities) to approximately $0.73$ as $j$ increases approaching $3$, but for $j=3$ it raises to about $1.14$. The abrupt increase observed for $j=3$ is equal to $\pi^2/24$ (and more generally, for any odd integer $j$, the term shows a discontinuity with an abrupt increase by $\pi^2/8/j$). Is there any way to express the values of this $O(1)$ term explicitly? Thank you.","I am interested in determining an asymptotic formula for the double summation of $1/(ab)$, where $a$ is an odd integer ranging between 1 and $k/\sqrt{j}$, $b$ is an odd integer ranging between $a$ and $aj$, $j$ is a real number $>1$, and $k$ tends to infinity.  In symbols, $$ \sum_{\substack{1 \leq a \leq k/\sqrt{j} \\ a \text{ odd}}} \sum_{\substack{a \leq b \leq aj \\ b \text{ odd}}} \frac{1}{ab}. $$ For $j=1$, the result of the summation simply corresponds to the infinite harmonic sum of odd squares $1/1 + 1/9 + 1/25\ldots $, which yields $\pi^2/8$. For $j>1$, I obtained the formula $\tfrac{1}{4} \ln(k) \ln(j) + O(1)$. I am particularly interested in this $O(1)$ term. Plotting this term vs $j$ we obtain a discontinuous function, where the most evident discontinuities occur when $j$ is an odd integer.  For instance, setting $j=2$, the constant term is about $0.94$. It progressively decreases (with other discontinuities) to approximately $0.73$ as $j$ increases approaching $3$, but for $j=3$ it raises to about $1.14$. The abrupt increase observed for $j=3$ is equal to $\pi^2/24$ (and more generally, for any odd integer $j$, the term shows a discontinuity with an abrupt increase by $\pi^2/8/j$). Is there any way to express the values of this $O(1)$ term explicitly? Thank you.",,"['sequences-and-series', 'number-theory', 'asymptotics']"
17,"Closed-form of $ S_n = 2^n p^2 + 2^{n-1} p^4 + 2^{n-2} p^8\cdots + 2p^{2^n}, $ where $n$ is positive integer?",Closed-form of  where  is positive integer?," S_n = 2^n p^2 + 2^{n-1} p^4 + 2^{n-2} p^8\cdots + 2p^{2^n},  n","Does, there exist some closed-form solution of the following finite-series ? $ S_n =  2^n p^2 + 2^{n-1} p^4 + 2^{n-2} p^8\cdots + 2p^{2^n}, $ where $n$ is a Positive Integer and $0<p<1$ . Note that number of terms in a series is $n$. So length of series varies according to value of $n$.","Does, there exist some closed-form solution of the following finite-series ? $ S_n =  2^n p^2 + 2^{n-1} p^4 + 2^{n-2} p^8\cdots + 2p^{2^n}, $ where $n$ is a Positive Integer and $0<p<1$ . Note that number of terms in a series is $n$. So length of series varies according to value of $n$.",,['sequences-and-series']
18,Existence of $j$ with strange sequence.,Existence of  with strange sequence.,j,"I define a sequence $(a_n)$ $$a_n= \begin{cases} 0 &\text{if $\cos{\left ( \dfrac{2^n\pi}{q}\right )}<-\dfrac12$} \\\\ 1 &\text{if $\cos{\left ( \dfrac{2^n\pi}{q}\right )}>-\dfrac12$} \end{cases}$$ where any two prime number $p$, $q$ such that $p\geq 5$, $q=2p+1$. Show that there exist $j$ such that $$a_1a_{p-j+1}+a_2a_{p-j+2}+\cdots+a_ja_p+a_{j+1}a_1+a_{j+2}a_2+\cdots+a_pa_{p-j} $$ is an even number with $0\leq j \leq p-1$. This problem is from POSTECH(POHANG UNIVERSITY OF SCIENCE AND TECHNOLOGY) mathematical contest for high school students in 2010. I tried long time but can't solve it. Please solve this problem. Thanks in advance.","I define a sequence $(a_n)$ $$a_n= \begin{cases} 0 &\text{if $\cos{\left ( \dfrac{2^n\pi}{q}\right )}<-\dfrac12$} \\\\ 1 &\text{if $\cos{\left ( \dfrac{2^n\pi}{q}\right )}>-\dfrac12$} \end{cases}$$ where any two prime number $p$, $q$ such that $p\geq 5$, $q=2p+1$. Show that there exist $j$ such that $$a_1a_{p-j+1}+a_2a_{p-j+2}+\cdots+a_ja_p+a_{j+1}a_1+a_{j+2}a_2+\cdots+a_pa_{p-j} $$ is an even number with $0\leq j \leq p-1$. This problem is from POSTECH(POHANG UNIVERSITY OF SCIENCE AND TECHNOLOGY) mathematical contest for high school students in 2010. I tried long time but can't solve it. Please solve this problem. Thanks in advance.",,['sequences-and-series']
19,An exercise about convergence of series [duplicate],An exercise about convergence of series [duplicate],,This question already has answers here : Closed 11 years ago . Possible Duplicate: Convergence/divergence of $\sum\frac{a_n}{1+na_n}$ when $\sum a_n$ diverges. Let $a_n$ be a non-negative sequence such that the series $\sum a_n$ does not converge. Could the series $\sum a_n/(1+na_n)$ be convergent?,This question already has answers here : Closed 11 years ago . Possible Duplicate: Convergence/divergence of $\sum\frac{a_n}{1+na_n}$ when $\sum a_n$ diverges. Let $a_n$ be a non-negative sequence such that the series $\sum a_n$ does not converge. Could the series $\sum a_n/(1+na_n)$ be convergent?,,['sequences-and-series']
20,tangents of sums,tangents of sums,,"In the identity $$ \cos \left( \sum_i \theta_i \right) = \sum_{\text{even }n\ge0} (-1)^{n/2} \sum_{|I|=n} \prod_{i\in I} \sin\theta_i \prod_{i\not\in I}\cos\theta_i $$ one can prove the case of finitely many values of $i$ by induction on the number of such values, and questions of convergence are easy to treat when there are infinitely many (and similarly with sines). In the identity $$ \tan \left( \sum_i \theta_i \right) = \frac{e_1-e_3+e_5-\cdots}{e_0 - e_2 + e_4 -\cdots} $$ where $e_k$ is the $k$th-degree elementary symmetric polynomial in the variables $\tan\theta_i$, the finite case is similarly routine. What is known about convergence in the infinite case? LATER EDIT: I derived this odd identity that I have not seen elsewhere (so attribute it to me if you mention it in a publication, unless you find it in something earlier): $$ \csc\left( \sum_{i=1}^n \theta_i \right) = \frac{(-1)^{\lfloor(n-1)/2\rfloor}(\csc\theta_1\cdots\cdots\csc\theta_n)}{f_{(n\operatorname{mod} 2)} - f_{(n\operatorname{mod} 2)+2} + f_{(n\operatorname{mod} 2)+4} - \cdots\cdots} $$ where $f_k$ is the $k$th-degree elemenary symmetric polynomial in the variables $\cot\theta_i$ $\lfloor a\rfloor$ is the greatest integer $\le a$ $(n\operatorname{mod} 2)$ is the remainder on division of $n$ by $2$ so that the $\pm$ in the numerator is $$ \begin{cases} + & \text{if $n=1$ or $2$} \\ - & \text{if $n=3$ or $4$} \\ + & \text{if $n=5$ or $6$} \\ - & \text{if $n=7$ or $8$} \\   & \text{etc.} \end{cases} $$ A funny thing about this is that to get the case $n-1$ from the case $n$, you would presumably just set $\theta_n=0$, but then the cosecant and the cotangent both blow up.  So you apply L'Hopital's rule, and fully half of the terms in the denominator vanish, if viewed as terms within $f_k$. Can anything sensible be said about $\csc\left(\sum_{i=1}^\infty \theta_i \right)$? And (also my own) $$ \cot\left(\sum_{i=1}^n \theta_i\right) = (-1)^{n+1} \left( \frac{f_1-f_3+f_5-\cdots}{f_0-f_2+f_4-\cdots} \right)^{(-1)^{n+1}}. $$ so we have $\text{even}\leftrightarrow\text{odd}$ alternation between the numerator and the denominator every time $n$ is incremented by $1$.  Similar remarks about L'Hopital apply, and the same question about infinite sums can be asked.","In the identity $$ \cos \left( \sum_i \theta_i \right) = \sum_{\text{even }n\ge0} (-1)^{n/2} \sum_{|I|=n} \prod_{i\in I} \sin\theta_i \prod_{i\not\in I}\cos\theta_i $$ one can prove the case of finitely many values of $i$ by induction on the number of such values, and questions of convergence are easy to treat when there are infinitely many (and similarly with sines). In the identity $$ \tan \left( \sum_i \theta_i \right) = \frac{e_1-e_3+e_5-\cdots}{e_0 - e_2 + e_4 -\cdots} $$ where $e_k$ is the $k$th-degree elementary symmetric polynomial in the variables $\tan\theta_i$, the finite case is similarly routine. What is known about convergence in the infinite case? LATER EDIT: I derived this odd identity that I have not seen elsewhere (so attribute it to me if you mention it in a publication, unless you find it in something earlier): $$ \csc\left( \sum_{i=1}^n \theta_i \right) = \frac{(-1)^{\lfloor(n-1)/2\rfloor}(\csc\theta_1\cdots\cdots\csc\theta_n)}{f_{(n\operatorname{mod} 2)} - f_{(n\operatorname{mod} 2)+2} + f_{(n\operatorname{mod} 2)+4} - \cdots\cdots} $$ where $f_k$ is the $k$th-degree elemenary symmetric polynomial in the variables $\cot\theta_i$ $\lfloor a\rfloor$ is the greatest integer $\le a$ $(n\operatorname{mod} 2)$ is the remainder on division of $n$ by $2$ so that the $\pm$ in the numerator is $$ \begin{cases} + & \text{if $n=1$ or $2$} \\ - & \text{if $n=3$ or $4$} \\ + & \text{if $n=5$ or $6$} \\ - & \text{if $n=7$ or $8$} \\   & \text{etc.} \end{cases} $$ A funny thing about this is that to get the case $n-1$ from the case $n$, you would presumably just set $\theta_n=0$, but then the cosecant and the cotangent both blow up.  So you apply L'Hopital's rule, and fully half of the terms in the denominator vanish, if viewed as terms within $f_k$. Can anything sensible be said about $\csc\left(\sum_{i=1}^\infty \theta_i \right)$? And (also my own) $$ \cot\left(\sum_{i=1}^n \theta_i\right) = (-1)^{n+1} \left( \frac{f_1-f_3+f_5-\cdots}{f_0-f_2+f_4-\cdots} \right)^{(-1)^{n+1}}. $$ so we have $\text{even}\leftrightarrow\text{odd}$ alternation between the numerator and the denominator every time $n$ is incremented by $1$.  Similar remarks about L'Hopital apply, and the same question about infinite sums can be asked.",,"['sequences-and-series', 'trigonometry']"
21,"Show that : $2, 5, 13, 17, 29, 421, 401, 53, 281,...,\rightarrow \infty$? $a_{n+1}=\operatorname{ GPF}(qa_n+p)$",Show that : ?,"2, 5, 13, 17, 29, 421, 401, 53, 281,...,\rightarrow \infty a_{n+1}=\operatorname{ GPF}(qa_n+p)","I denote by $\operatorname{ GPF}(n)$ the greatest prime factor of $n$, eg. $\operatorname{ GPF}(17)=17$, $\operatorname{ GPF}(18)=3$. Is there a way to prove that the sequence $a_{n+1}=\operatorname{ GPF}(qa_n+p)$, eventually enter a cycle for all initial values of positive integers $q,a_0,p>1$? Which my simulations seem to indicate - although the sequence $a_{n+1}=\operatorname{ GPF}(a_n^2+1)$ with $a_0=2$ appears to run off into infinity.","I denote by $\operatorname{ GPF}(n)$ the greatest prime factor of $n$, eg. $\operatorname{ GPF}(17)=17$, $\operatorname{ GPF}(18)=3$. Is there a way to prove that the sequence $a_{n+1}=\operatorname{ GPF}(qa_n+p)$, eventually enter a cycle for all initial values of positive integers $q,a_0,p>1$? Which my simulations seem to indicate - although the sequence $a_{n+1}=\operatorname{ GPF}(a_n^2+1)$ with $a_0=2$ appears to run off into infinity.",,"['number-theory', 'sequences-and-series', 'analytic-number-theory', 'recreational-mathematics']"
22,Find the $n^{th}$ term of this sequence,Find the  term of this sequence,n^{th},"Given the following sequence of numbers 1, 3, 7, 9, 13, 15, 21, 25, 27, 31, 33, 37, 43, 45, 49, 51, 55, 57, 63, 67, 69, 73, 75, 79, 85, 91, 93, 97, 99 Can anyone show me the calulation for the nth term? The sequence of first differences can be seen to repeat 2 sets of numbers 2, 4, 2, 4, 2, 6, 4, 2, 4, 2, 4 , 6, 2, 4, 2, 4, 2, 6, 4, 2, 4, 2, 4 , 6, 2, 4, 2, 4, 2 I'm mucking about with codes for my lower level students just for fun - then realised I couldn't actually $n$th sequence the code I'd created - oops! Thanks!","Given the following sequence of numbers 1, 3, 7, 9, 13, 15, 21, 25, 27, 31, 33, 37, 43, 45, 49, 51, 55, 57, 63, 67, 69, 73, 75, 79, 85, 91, 93, 97, 99 Can anyone show me the calulation for the nth term? The sequence of first differences can be seen to repeat 2 sets of numbers 2, 4, 2, 4, 2, 6, 4, 2, 4, 2, 4 , 6, 2, 4, 2, 4, 2, 6, 4, 2, 4, 2, 4 , 6, 2, 4, 2, 4, 2 I'm mucking about with codes for my lower level students just for fun - then realised I couldn't actually $n$th sequence the code I'd created - oops! Thanks!",,['sequences-and-series']
23,"Dirichlet series generating function, ordinary generating function","Dirichlet series generating function, ordinary generating function",,I am partly repeating my self here. The sequence $a_n$ generated by the Dirichlet series generating function: $\sum \limits_{n=1}^{\infty} \frac{a_n}{n^s}$ corresponding to $\zeta(s)^m$ seems to have the ordinary generating function: $\sum \limits_{n=1}^{\infty} a_nx^n = x + {m \choose 1}\sum \limits_{a=2}^{\infty} x^{a} + {m \choose 2}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} x^{ab} + {m \choose 3}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} \sum \limits_{c=2}^{\infty} x^{abc} + {m \choose 4}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} \sum \limits_{c=2}^{\infty} \sum \limits_{d=2}^{\infty} x^{abcd} +...$ Is this a true result?,I am partly repeating my self here. The sequence $a_n$ generated by the Dirichlet series generating function: $\sum \limits_{n=1}^{\infty} \frac{a_n}{n^s}$ corresponding to $\zeta(s)^m$ seems to have the ordinary generating function: $\sum \limits_{n=1}^{\infty} a_nx^n = x + {m \choose 1}\sum \limits_{a=2}^{\infty} x^{a} + {m \choose 2}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} x^{ab} + {m \choose 3}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} \sum \limits_{c=2}^{\infty} x^{abc} + {m \choose 4}\sum \limits_{a=2}^{\infty} \sum \limits_{b=2}^{\infty} \sum \limits_{c=2}^{\infty} \sum \limits_{d=2}^{\infty} x^{abcd} +...$ Is this a true result?,,"['sequences-and-series', 'reference-request', 'generating-functions']"
24,"What is the summation order when writing $\sum_{i,j=1}^\infty$?",What is the summation order when writing ?,"\sum_{i,j=1}^\infty","Especially for a conditionally convergent series where summation order matters? If it is equivalent to $\sum_{i=1}^\infty\sum_{j=1}^\infty$ , does it mean that $\sum_{i,j=1}^\infty\ne\sum_{j,i=1}^\infty$ ? Example: I saw people claiming $$\sum_{m,n=1}^\infty\frac{(-1)^{m+n}\,mn}{(m+n)^2}=\frac{\ln 2}{6}-\frac{1}{24}$$ While it is probably correct in some way, if I ""transform"" it into $$ \sum_{m,n=1}^\infty\frac{(-1)^{m+n}\,mn}{(m+n)^2}\stackrel{?}{=}\sum_{s=2}^\infty\frac{(-1)^s}{s^2}\sum_{m=1}^{s-1}m(s-m)=\sum_{s=2}^\infty\frac{(-1)^s(s+1)(s-1)}{6s}, $$ we got a divergent series. So should I take $\sum_{i,j=1}^\infty$ as $\sum_{i=1}^\infty\sum_{j=1}^\infty$ by default? Or should we not write $\sum_{i,j=1}^\infty$ for a conditionally convergent series in the first place?","Especially for a conditionally convergent series where summation order matters? If it is equivalent to , does it mean that ? Example: I saw people claiming While it is probably correct in some way, if I ""transform"" it into we got a divergent series. So should I take as by default? Or should we not write for a conditionally convergent series in the first place?","\sum_{i=1}^\infty\sum_{j=1}^\infty \sum_{i,j=1}^\infty\ne\sum_{j,i=1}^\infty \sum_{m,n=1}^\infty\frac{(-1)^{m+n}\,mn}{(m+n)^2}=\frac{\ln 2}{6}-\frac{1}{24} 
\sum_{m,n=1}^\infty\frac{(-1)^{m+n}\,mn}{(m+n)^2}\stackrel{?}{=}\sum_{s=2}^\infty\frac{(-1)^s}{s^2}\sum_{m=1}^{s-1}m(s-m)=\sum_{s=2}^\infty\frac{(-1)^s(s+1)(s-1)}{6s},
 \sum_{i,j=1}^\infty \sum_{i=1}^\infty\sum_{j=1}^\infty \sum_{i,j=1}^\infty",['sequences-and-series']
25,When does this iterated logarithm series converge / diverge?,When does this iterated logarithm series converge / diverge?,,"Question: Let $b > 1$ be a positive real, let $\ell_b(n) = \max(1, \lfloor \log_b n \rfloor)$ , and let $f_b(n) = n \ell_b(n) \ell_b^2(n) \dots $ (where we iterate $\ell_b$ until we hit $1$ ). For what values of $b$ does the series $$\sum_{n=1}^{\infty} \frac{1}{f_b(n)}$$ converge or diverge? This previous question asks about the case $b = 10$ . There I gave an argument which shows that the series diverges for all $b > e$ . I thought I had convinced myself awhile ago that this series ought to diverge for all $b > 1$ but surprisingly the argument does not show it; actually it suggests that the series converges for $b < e$ and it's unclear what happens if $b = e$ . My motivation is the same as Alan's in the linked question: this is an interesting test of the limits of common convergence tests. The integral test or Cauchy condensation shows that the analogue of this series where we only iterate $\ell_b(n)$ a fixed number of times diverges for any $b > 1$ but that argument doesn't work here. Actually Cauchy condensation produces nearly the same series again, which is basically the idea I use in my argument in the linked question.","Question: Let be a positive real, let , and let (where we iterate until we hit ). For what values of does the series converge or diverge? This previous question asks about the case . There I gave an argument which shows that the series diverges for all . I thought I had convinced myself awhile ago that this series ought to diverge for all but surprisingly the argument does not show it; actually it suggests that the series converges for and it's unclear what happens if . My motivation is the same as Alan's in the linked question: this is an interesting test of the limits of common convergence tests. The integral test or Cauchy condensation shows that the analogue of this series where we only iterate a fixed number of times diverges for any but that argument doesn't work here. Actually Cauchy condensation produces nearly the same series again, which is basically the idea I use in my argument in the linked question.","b > 1 \ell_b(n) = \max(1, \lfloor \log_b n \rfloor) f_b(n) = n \ell_b(n) \ell_b^2(n) \dots  \ell_b 1 b \sum_{n=1}^{\infty} \frac{1}{f_b(n)} b = 10 b > e b > 1 b < e b = e \ell_b(n) b > 1","['sequences-and-series', 'logarithms']"
26,Error in Solution to $\frac{1}{\phi(n)}$ Bound,Error in Solution to  Bound,\frac{1}{\phi(n)},"While proving the standard expression for $\sum_{n \le x} \frac{1}{\phi(n)}$ , my solution seems to claim  that $$\sum_{y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y} = \sum_{d = 1}^\infty \frac{\mu^2(d) \log(d)}{d\varphi(d)} + O\left(\frac{1}{x}\right)$$ with the proof \begin{align*}     &\sum_{y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y} >      \int_{1}^{x+1} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \frac{1}{y}\ dy = \\     &\sum_{d = 1}^\infty \int_{x/d}^{x+1} \frac{\mu^2(d)}{d\varphi(d)} \frac{1}{y}\ dy =     \log\left(\frac{x+1}{x}\right) \sum_{d = 1}^\infty \frac{\mu^2(d)}{d\varphi(d)} + \sum_{d = 1}^\infty \frac{\mu^2(d) \log(d)}{d\varphi(d)} \\     &> \sum_{2 \le y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y}.\end{align*} as $\sum_{d \ge x} \frac{1}{d \phi(d)} = O\left(\frac{1}{x}\right)$ and $\log\left(\frac{x+1}{x}\right) = O\left(\frac{1}{x}\right)$ as well. However, this seems to imply an extremely strong $O\left(\frac{1}{x}\right)$ error bound for the entire result, which seems to suggest the more likely fact that I've messed up in this claim somewhere. Any help is appreciated on finding exactly where that happens.","While proving the standard expression for , my solution seems to claim  that with the proof as and as well. However, this seems to imply an extremely strong error bound for the entire result, which seems to suggest the more likely fact that I've messed up in this claim somewhere. Any help is appreciated on finding exactly where that happens.","\sum_{n \le x} \frac{1}{\phi(n)} \sum_{y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y} = \sum_{d = 1}^\infty \frac{\mu^2(d) \log(d)}{d\varphi(d)} + O\left(\frac{1}{x}\right) \begin{align*}
    &\sum_{y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y} > 
    \int_{1}^{x+1} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \frac{1}{y}\ dy = \\
    &\sum_{d = 1}^\infty \int_{x/d}^{x+1} \frac{\mu^2(d)}{d\varphi(d)} \frac{1}{y}\ dy =
    \log\left(\frac{x+1}{x}\right) \sum_{d = 1}^\infty \frac{\mu^2(d)}{d\varphi(d)} + \sum_{d = 1}^\infty \frac{\mu^2(d) \log(d)}{d\varphi(d)} \\
    &> \sum_{2 \le y \le x} \sum_{d > x/y} \frac{\mu^2(d)}{d\varphi(d)} \cdot \frac{1}{y}.\end{align*} \sum_{d \ge x} \frac{1}{d \phi(d)} = O\left(\frac{1}{x}\right) \log\left(\frac{x+1}{x}\right) = O\left(\frac{1}{x}\right) O\left(\frac{1}{x}\right)","['sequences-and-series', 'number-theory', 'solution-verification']"
27,Is the series $ \sum_{n=1}^{\infty} \frac{\cos (\frac{1}{n^2})}{\sqrt{2n+1}}$ divergent or convergent?,Is the series  divergent or convergent?, \sum_{n=1}^{\infty} \frac{\cos (\frac{1}{n^2})}{\sqrt{2n+1}},"I want to know if my reasoning is correct about the divergence of the series $\displaystyle \sum_{n=1}^{\infty} \frac{\cos (\frac{1}{n^2})}{\sqrt{2n+1}}$ . First, we know that $\displaystyle \frac{1}{n^2} \in (0,1], \forall n \in \mathbb{N}$ . The function $\cos x$ is decreasing and positive on the interval $(0,1]$ and so $\cos 1 >0$ . Also, we have $\displaystyle 1 \geq \frac{1}{n^2}, \forall n \in \mathbb{N} \implies \cos 1 \leq \cos(\frac{1}{n^2}), \forall n \in \mathbb{N}$ . So, $\displaystyle a_n = \frac{\cos (\frac{1}{n^2})}{\sqrt{2n+1}} \geq \frac{\cos 1}{\sqrt{2n+1}} = b_n$ . Because, $\displaystyle \sum_{n=1}^{\infty}b_n$ diverges, then by the comparison test $\displaystyle \sum_{n=1}^{\infty}a_n$ diverges too. Thanks for any advices!","I want to know if my reasoning is correct about the divergence of the series . First, we know that . The function is decreasing and positive on the interval and so . Also, we have . So, . Because, diverges, then by the comparison test diverges too. Thanks for any advices!","\displaystyle \sum_{n=1}^{\infty} \frac{\cos (\frac{1}{n^2})}{\sqrt{2n+1}} \displaystyle \frac{1}{n^2} \in (0,1], \forall n \in \mathbb{N} \cos x (0,1] \cos 1 >0 \displaystyle 1 \geq \frac{1}{n^2}, \forall n \in \mathbb{N} \implies \cos 1 \leq \cos(\frac{1}{n^2}), \forall n \in \mathbb{N} \displaystyle a_n = \frac{\cos (\frac{1}{n^2})}{\sqrt{2n+1}} \geq \frac{\cos 1}{\sqrt{2n+1}} = b_n \displaystyle \sum_{n=1}^{\infty}b_n \displaystyle \sum_{n=1}^{\infty}a_n","['sequences-and-series', 'convergence-divergence', 'divergent-series']"
28,How to write $\frac{1}{3\ln^23} + \frac{1}{4\ln^24} + \frac{1}{5\ln^25} +\dots$ as a short expression?,How to write  as a short expression?,\frac{1}{3\ln^23} + \frac{1}{4\ln^24} + \frac{1}{5\ln^25} +\dots,"I have a snippet of series that I have to note as a short expression: $$\frac{1}{3\ln^23} + \frac{1}{4\ln^24} + \frac{1}{5\ln^25} +\dots$$ I am not sure if it would be more reasonable to write it as follows: $\displaystyle\sum_{n=1}^{\infty} \frac{1}{(n+2)\ln^2(n+2)}$ or : $\displaystyle\sum_{n=3}^{\infty} \frac{1}{n\ln^2(n)}\,.$ Would it even make a difference?",I have a snippet of series that I have to note as a short expression: I am not sure if it would be more reasonable to write it as follows: or : Would it even make a difference?,"\frac{1}{3\ln^23} + \frac{1}{4\ln^24} + \frac{1}{5\ln^25} +\dots \displaystyle\sum_{n=1}^{\infty} \frac{1}{(n+2)\ln^2(n+2)} \displaystyle\sum_{n=3}^{\infty} \frac{1}{n\ln^2(n)}\,.","['sequences-and-series', 'notation']"
29,Explosive number(s) from $x_{n+1}=\left(1+\frac{1}{x_n}\right)^n$,Explosive number(s) from,x_{n+1}=\left(1+\frac{1}{x_n}\right)^n,"I came accross a curiosity I don't fully understand. In an exam, the sequence $\left(x_n\right)$ is introduced such as for all $n \geq 1$ $$ x_{n+1}=\left(1+\frac{1}{x_n}\right)^n $$ with $x_1 = \alpha \in \left]0;+\infty\right[$ . It is argued that there exists one number $\alpha^{\ast}$ , and only one,  such that the sequence $\left(x_n\right)$ with $x_1 = \alpha^{\ast}$ diverges towards $+\infty$ . A proof is then proposed where it is shown that $\alpha^{\ast} \approx 1,1874$ . This result triggers my curiosity. I've written a small python script, and I've observed that as soon as $x_{N}$ is ""big"", then $x_{N+1} \approx 1$ . I guess all the mystery is there : how to have $x_{N}$ 'big' without having $x_{N+1} \approx 1$ . For $x_{N}$ big enough, we can write $$ x_{N+1} = e^{N\ln\left(1+\frac{1}{x_N}\right)} = e^{N\left(\frac{1}{x_{N}} - \frac{1}{2x_{N}^2} + o\left(\frac{1}{x_{N}^2}\right)\right)} $$ So my guess is that $N/x_{N}$ needs to stay low. What I see for example is : \begin{array} $x_1 & 5 & 1.1874\newline x_2 & 1.20 & 1.84\newline x_3 & 3.36 & 2.38\newline x_4 & 2.18 & 2.86\newline x_5 & 4.52 & 3.31\newline x_6 & 2.72 & 3.74\newline x_7 & 6.55 & 4.14\newline x_8 & 2.70 & 4.54\newline x_9 & 12.4 & 4.92\newline x_{10} & 2.0 & 5.29\newline \end{array} A pattern clearly emerges with $\alpha = 1.1874$ , where odd and even indexes find a kind of balance. But after some more iterations, the balance is broken : we find $x_{28} = 3.2 \cdot 10^{8}$ and $x_{29} \approx 1.0$ . Does it mean that it is not possible for a program to reproduce this pattern and just preserve it until a given rank ? Is there an equation that could be deduced for $\alpha^{\ast}$ ?","I came accross a curiosity I don't fully understand. In an exam, the sequence is introduced such as for all with . It is argued that there exists one number , and only one,  such that the sequence with diverges towards . A proof is then proposed where it is shown that . This result triggers my curiosity. I've written a small python script, and I've observed that as soon as is ""big"", then . I guess all the mystery is there : how to have 'big' without having . For big enough, we can write So my guess is that needs to stay low. What I see for example is : A pattern clearly emerges with , where odd and even indexes find a kind of balance. But after some more iterations, the balance is broken : we find and . Does it mean that it is not possible for a program to reproduce this pattern and just preserve it until a given rank ? Is there an equation that could be deduced for ?","\left(x_n\right) n \geq 1 
x_{n+1}=\left(1+\frac{1}{x_n}\right)^n
 x_1 = \alpha \in \left]0;+\infty\right[ \alpha^{\ast} \left(x_n\right) x_1 = \alpha^{\ast} +\infty \alpha^{\ast} \approx 1,1874 x_{N} x_{N+1} \approx 1 x_{N} x_{N+1} \approx 1 x_{N} 
x_{N+1} = e^{N\ln\left(1+\frac{1}{x_N}\right)} = e^{N\left(\frac{1}{x_{N}} - \frac{1}{2x_{N}^2} + o\left(\frac{1}{x_{N}^2}\right)\right)}
 N/x_{N} \begin{array}
x_1 & 5 & 1.1874\newline
x_2 & 1.20 & 1.84\newline
x_3 & 3.36 & 2.38\newline
x_4 & 2.18 & 2.86\newline
x_5 & 4.52 & 3.31\newline
x_6 & 2.72 & 3.74\newline
x_7 & 6.55 & 4.14\newline
x_8 & 2.70 & 4.54\newline
x_9 & 12.4 & 4.92\newline
x_{10} & 2.0 & 5.29\newline
\end{array} \alpha = 1.1874 x_{28} = 3.2 \cdot 10^{8} x_{29} \approx 1.0 \alpha^{\ast}",['sequences-and-series']
30,"Is $\sum_{k=1}^\infty \frac{1}{p_{p_k}}$, where $p_k$ is the $k$-th prime, irrational? transcendental?","Is , where  is the -th prime, irrational? transcendental?",\sum_{k=1}^\infty \frac{1}{p_{p_k}} p_k k,"I was reading about the reason why the reciprocals of the primes have a divergent sum. So I was thinking of changing the index to the $k$ th prime. We get: $$\sum_{k=1}^\infty \frac{1}{p_{p_k}}=S$$ When I first posted this here , I was thinking that it was a divergent series like its predecessor. But @GregMartin pointed out that this sum actually converges. So I was wondering if this number is irrational? Could it also be transcendental? I am afraid this question is as hard as proving that Euler's constant $\gamma$ is transcendental. Edit: I understand that this question is very hard to solve. So maybe is there any explanation why it might not be solvable by current methods?","I was reading about the reason why the reciprocals of the primes have a divergent sum. So I was thinking of changing the index to the th prime. We get: When I first posted this here , I was thinking that it was a divergent series like its predecessor. But @GregMartin pointed out that this sum actually converges. So I was wondering if this number is irrational? Could it also be transcendental? I am afraid this question is as hard as proving that Euler's constant is transcendental. Edit: I understand that this question is very hard to solve. So maybe is there any explanation why it might not be solvable by current methods?",k \sum_{k=1}^\infty \frac{1}{p_{p_k}}=S \gamma,"['sequences-and-series', 'irrational-numbers', 'transcendental-numbers']"
31,Sequence of polynomials given by induction,Sequence of polynomials given by induction,,"Consider a sequence of polynomials $$ \Phi_0(x)=x $$ $$ \Phi_{k+1}(x)=x+\Phi_k(x)^2\quad\quad(k\ge0). $$ It is easy to see that the equation $\Phi_k(x)=1$ has exactly one positive root. Let us denote it by $\xi_k$ . I am interested in the asymptotics of this root, as exact as possible. It is not difficult to see that $\Phi_k(\frac14) < \frac12$ for all $k$ , whence $\frac14 < \xi_k$ . On the other hand, I am able to get an upper bound of the form $\xi_k < \frac14+\frac{c}k$ for some positive constant $c$ . It is sufficient for my purposes, but numerical data suggest that $\xi_k$ is close to $\frac14+\frac{\pi^2}{k^2}$ as $k\to\infty$ . Is it possible to prove it? Or, perhaps, such a sequence of polynomials has already been discussed somewhere? An additional question for reference: consider a power series for the function $$ \frac1{1-\Phi_k(x)} $$ in a neighborhood of zero. Its nth coefficient is equivalent to $C\xi_k^{-n}$ for some $C > 0$ , which can be deduced from the standard theory of linear recurrent equations. However, I think that such statements should follow from some well-known theorems. Does anyone know any useful links (preferably in English)? P.S. It is worth noting that for large $k$ , the first terms of the power series are Catalan numbers, but after them there is a long tail with smaller coefficients.","Consider a sequence of polynomials It is easy to see that the equation has exactly one positive root. Let us denote it by . I am interested in the asymptotics of this root, as exact as possible. It is not difficult to see that for all , whence . On the other hand, I am able to get an upper bound of the form for some positive constant . It is sufficient for my purposes, but numerical data suggest that is close to as . Is it possible to prove it? Or, perhaps, such a sequence of polynomials has already been discussed somewhere? An additional question for reference: consider a power series for the function in a neighborhood of zero. Its nth coefficient is equivalent to for some , which can be deduced from the standard theory of linear recurrent equations. However, I think that such statements should follow from some well-known theorems. Does anyone know any useful links (preferably in English)? P.S. It is worth noting that for large , the first terms of the power series are Catalan numbers, but after them there is a long tail with smaller coefficients.","
\Phi_0(x)=x
 
\Phi_{k+1}(x)=x+\Phi_k(x)^2\quad\quad(k\ge0).
 \Phi_k(x)=1 \xi_k \Phi_k(\frac14) < \frac12 k \frac14 < \xi_k \xi_k < \frac14+\frac{c}k c \xi_k \frac14+\frac{\pi^2}{k^2} k\to\infty 
\frac1{1-\Phi_k(x)}
 C\xi_k^{-n} C > 0 k","['sequences-and-series', 'polynomials', 'power-series']"
32,find the smallest n such that $a_n > 2019$,find the smallest n such that,a_n > 2019,"Source: Question 11 of this problem set . I'd like to point out that I'm not cheating on any contest by posting this problem (e.g. the OTIS). It was released in the past to help students prepare for the Putnam competition. Let $a_1 = 1, a_{n+1} = a_n + \lfloor \sqrt{a_n}\rfloor$ for $n\ge 1$ . Find, with proof, the smallest $n$ such that $a_n > 2019$ ? My first instinct is to try to guess a formula for $a_n$ that can hopefully be easily proven via induction. Alternatively one may be able to prove some useful properties about the sequence using induction. We have $\lfloor \sqrt{a_n}\rfloor = k\Leftrightarrow k^2 \leq a_n \leq k^2 + 2k.$ Computing the first few terms of the sequence gives $1,2,3,4,6,8,10,13,16,20,24,28,33,38.$ But there doesn't seem to be any noticeable pattern that can lead to a general formula. However, observing the perfect squares in the sequence, we see that the only two seen so far are $4$ and $16$ . It might not just be a coincidence that these are both powers of 4 (1). Then it might be useful to consider the number of times $\lfloor \sqrt{a_n}\rfloor$ occurs. The sequence $\lfloor \sqrt{a_n}\rfloor$ is as follows: $1,1,1,2,2,2,3,3,4,4,4,5,5,6$ . Again, it may not be a coincidence that the values that occur $3$ times in this small sample are powers of 2 while all other values occur exactly twice (2). Assume that hypotheses (1) and (2) hold for all $n\leq k, k\ge 14$ . We want to show they still hold for $k+1$ . Let $4^q \leq k+1 < 4^{q+1}.$ We have for $n\ge 2$ that $a_n = 1 + \sum_{i=1}^{n-1} \lfloor \sqrt{a_n}\rfloor.$ I'm not sure how to prove the inductive step from here.","Source: Question 11 of this problem set . I'd like to point out that I'm not cheating on any contest by posting this problem (e.g. the OTIS). It was released in the past to help students prepare for the Putnam competition. Let for . Find, with proof, the smallest such that ? My first instinct is to try to guess a formula for that can hopefully be easily proven via induction. Alternatively one may be able to prove some useful properties about the sequence using induction. We have Computing the first few terms of the sequence gives But there doesn't seem to be any noticeable pattern that can lead to a general formula. However, observing the perfect squares in the sequence, we see that the only two seen so far are and . It might not just be a coincidence that these are both powers of 4 (1). Then it might be useful to consider the number of times occurs. The sequence is as follows: . Again, it may not be a coincidence that the values that occur times in this small sample are powers of 2 while all other values occur exactly twice (2). Assume that hypotheses (1) and (2) hold for all . We want to show they still hold for . Let We have for that I'm not sure how to prove the inductive step from here.","a_1 = 1, a_{n+1} = a_n + \lfloor \sqrt{a_n}\rfloor n\ge 1 n a_n > 2019 a_n \lfloor \sqrt{a_n}\rfloor = k\Leftrightarrow k^2 \leq a_n \leq k^2 + 2k. 1,2,3,4,6,8,10,13,16,20,24,28,33,38. 4 16 \lfloor \sqrt{a_n}\rfloor \lfloor \sqrt{a_n}\rfloor 1,1,1,2,2,2,3,3,4,4,4,5,5,6 3 n\leq k, k\ge 14 k+1 4^q \leq k+1 < 4^{q+1}. n\ge 2 a_n = 1 + \sum_{i=1}^{n-1} \lfloor \sqrt{a_n}\rfloor.","['sequences-and-series', 'elementary-number-theory', 'induction', 'contest-math', 'ceiling-and-floor-functions']"
33,"Strange remark in a solution: Recursion, definite integral and a duplication formula?","Strange remark in a solution: Recursion, definite integral and a duplication formula?",,"I was doing some problems in Arthur Engel's ""Problem-Solving Strategies"" when I came across this problem in the Induction section: Find a closed formula for the sequence $a_1 = 1,$ $$a_{n+1} = \frac{1}{16}(4a_n + 1 + \sqrt{24a_n + 1}).$$ Now the problem itself is not so interesting, but what I found interesting was a comment by the author at the end of his solution. He leaves the following remark: ""The sequence $a_n$ converges to $\int_0^1 x^2dx$ . The recursion is a ""duplication formula"" for the parabola $y = x^2$ . This is the way I discovered it."" Obviously the statement that the sequence converges to the same value as the integral ( $1/3$ ) is not hard to verify. But I am at a loss as to how the recursion formula is in any way related to the parabola $y=x^2$ and what the author means by ""duplication"" formula in this case. Typically I would think of a duplication formula being an expression for $f(2x)$ in terms of $f(x)$ , which in the case of the stated parabola would simply lead to the recursion $b_{n+1} = 4b_n$ . It is not clear to me how this could be reflected in a definite integral. Any insight would be greatly appreciated as I am curious how the author connected this recursive sequence to the definite integral.","I was doing some problems in Arthur Engel's ""Problem-Solving Strategies"" when I came across this problem in the Induction section: Find a closed formula for the sequence Now the problem itself is not so interesting, but what I found interesting was a comment by the author at the end of his solution. He leaves the following remark: ""The sequence converges to . The recursion is a ""duplication formula"" for the parabola . This is the way I discovered it."" Obviously the statement that the sequence converges to the same value as the integral ( ) is not hard to verify. But I am at a loss as to how the recursion formula is in any way related to the parabola and what the author means by ""duplication"" formula in this case. Typically I would think of a duplication formula being an expression for in terms of , which in the case of the stated parabola would simply lead to the recursion . It is not clear to me how this could be reflected in a definite integral. Any insight would be greatly appreciated as I am curious how the author connected this recursive sequence to the definite integral.","a_1 = 1, a_{n+1} = \frac{1}{16}(4a_n + 1 + \sqrt{24a_n + 1}). a_n \int_0^1 x^2dx y = x^2 1/3 y=x^2 f(2x) f(x) b_{n+1} = 4b_n",['sequences-and-series']
34,Is there Any Study on the Sum of $e^{-\sqrt{n}t}$?,Is there Any Study on the Sum of ?,e^{-\sqrt{n}t},"I've been messing around with some things after looking at Jacobi Theta Functions and I happened to stumble upon these unexpectedly (at least to me) nice Laurent expansion and integral representation of a curious sum: $$ \begin{split} \sum_{n=0}^\infty e^{-\sqrt{n}t} &= \frac12+\frac1{\sqrt{\pi}}\int_0^\infty\coth\left(\frac{t^2}{8x^2}\right)e^{-x^2}dx \\ &= \frac2{t^2}+\frac12-\frac1{\sqrt{\pi}}\sum_{n=1}^\infty \sin\left(\frac{\pi k}4\right) \frac{(-t)^k\zeta(1+\frac k2)}{(8\pi)^{k/2}\Gamma(\frac{1+k}{2})} \end{split} $$ Has this series been studied somewhere? Is there literature that I could possibly read on it? I don't even know what to call the thing, much less how to search for resources on it online.","I've been messing around with some things after looking at Jacobi Theta Functions and I happened to stumble upon these unexpectedly (at least to me) nice Laurent expansion and integral representation of a curious sum: Has this series been studied somewhere? Is there literature that I could possibly read on it? I don't even know what to call the thing, much less how to search for resources on it online.","
\begin{split}
\sum_{n=0}^\infty e^{-\sqrt{n}t}
&=
\frac12+\frac1{\sqrt{\pi}}\int_0^\infty\coth\left(\frac{t^2}{8x^2}\right)e^{-x^2}dx
\\
&=
\frac2{t^2}+\frac12-\frac1{\sqrt{\pi}}\sum_{n=1}^\infty \sin\left(\frac{\pi k}4\right) \frac{(-t)^k\zeta(1+\frac k2)}{(8\pi)^{k/2}\Gamma(\frac{1+k}{2})}
\end{split}
",['sequences-and-series']
35,"Minimum value of $\sum_{k=1}^n|1+z^{(2^k)}|, z\in\mathbb{C}$ in terms of $n$",Minimum value of  in terms of,"\sum_{k=1}^n|1+z^{(2^k)}|, z\in\mathbb{C} n","What is the minimum value of $S=\sum_{k=1}^n|1+z^{(2^k)}|, z\in\mathbb{C}$ in terms of $n$ ? Experimenting on desmos and wolfram suggests the following claims: $S$ is minimized when $|z|=1$ and $\arg{z}=\dfrac{\lfloor{\frac{2^n}{3}}+\frac{1}{2}\rfloor}{2^n}\pi$ (The numerator is the Jacobsthal sequence .) $S_\text{min}=n-f(n)$ where $\lim_{n\to\infty}f(n)\approx0.747771497$ I do not know how to prove any of these claims. It is easy to show that if $|z|=1$ then $S=2\sum_{k=0}^{n-1} {|\cos{(2^kx)}|}$ where $x=\arg{z}$ . This is related, but I'm not sure if it helps: $|\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}}$ . That's all I've been able to do. (This question was inspired by similar questions such as this , this , this and this .)","What is the minimum value of in terms of ? Experimenting on desmos and wolfram suggests the following claims: is minimized when and (The numerator is the Jacobsthal sequence .) where I do not know how to prove any of these claims. It is easy to show that if then where . This is related, but I'm not sure if it helps: . That's all I've been able to do. (This question was inspired by similar questions such as this , this , this and this .)","S=\sum_{k=1}^n|1+z^{(2^k)}|, z\in\mathbb{C} n S |z|=1 \arg{z}=\dfrac{\lfloor{\frac{2^n}{3}}+\frac{1}{2}\rfloor}{2^n}\pi S_\text{min}=n-f(n) \lim_{n\to\infty}f(n)\approx0.747771497 |z|=1 S=2\sum_{k=0}^{n-1} {|\cos{(2^kx)}|} x=\arg{z} |\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}}","['sequences-and-series', 'complex-analysis', 'trigonometry', 'complex-numbers', 'maxima-minima']"
36,Find summation of the series (PDE approach),Find summation of the series (PDE approach),,The summation is given as: $$ \sum _{j=1}^{\infty } \frac{a^j e^{-\frac{b}{j}}}{j!} $$ where $a>1$ and $b>1$ This question actually arises when you try to find the sum over the product of two functions: a poisson distribution $$ \frac{a^j} {j!} e^{-a} $$ a j-times convolved gaussian function $$ \underbrace{e^{-px^2}\circledast e^{-px^2}\circledast\cdots\circledast e^{-px^2} }_{\text{j times}}= e^{-\frac{p}{j}x^2}=e^{-\frac{b}{j}} $$ Can it be solved as follows: $$ y=\sum _{j=1}^{\infty } \frac{a^j e^{-\frac{b}{j}}}{j!} $$ $$ \frac{\partial y}{\partial b}=\sum _{j=1}^{\infty } \frac{a^j e^{-\frac{b}{j}}\cdot\frac{-1}{j}}{j!} $$ $$ \frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=\sum _{j=1}^{\infty } \frac{j\cdot a^{j-1} e^{-\frac{b}{j}}\cdot\frac{-1}{j}}{j!} $$ $$ \frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=-\sum _{j=1}^{\infty } \frac{a^{j-1} e^{-\frac{b}{j}}}{j!} $$ $$ \frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=-\sum _{j=1}^{\infty } \frac{a^{j-1} e^{-\frac{b}{j}}}{j!} \cdot \frac{a}{a} $$ $$ \frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=-\frac{1}{a}\sum _{j=1}^{\infty } \frac{a^{j} e^{-\frac{b}{j}}}{j!} $$ $$ \frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=\frac{-y}{a} $$ How should I solve this PDE?,The summation is given as: where and This question actually arises when you try to find the sum over the product of two functions: a poisson distribution a j-times convolved gaussian function Can it be solved as follows: How should I solve this PDE?,"
\sum _{j=1}^{\infty } \frac{a^j e^{-\frac{b}{j}}}{j!}
 a>1 b>1 
\frac{a^j} {j!} e^{-a}
 
\underbrace{e^{-px^2}\circledast e^{-px^2}\circledast\cdots\circledast e^{-px^2} }_{\text{j times}}= e^{-\frac{p}{j}x^2}=e^{-\frac{b}{j}}
 
y=\sum _{j=1}^{\infty } \frac{a^j e^{-\frac{b}{j}}}{j!}
 
\frac{\partial y}{\partial b}=\sum _{j=1}^{\infty } \frac{a^j e^{-\frac{b}{j}}\cdot\frac{-1}{j}}{j!}
 
\frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=\sum _{j=1}^{\infty } \frac{j\cdot a^{j-1} e^{-\frac{b}{j}}\cdot\frac{-1}{j}}{j!}
 
\frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=-\sum _{j=1}^{\infty } \frac{a^{j-1} e^{-\frac{b}{j}}}{j!}
 
\frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=-\sum _{j=1}^{\infty } \frac{a^{j-1} e^{-\frac{b}{j}}}{j!} \cdot \frac{a}{a}
 
\frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=-\frac{1}{a}\sum _{j=1}^{\infty } \frac{a^{j} e^{-\frac{b}{j}}}{j!}
 
\frac{\partial}{\partial a}(\frac{\partial y}{\partial b})=\frac{-y}{a}
","['sequences-and-series', 'partial-differential-equations', 'summation', 'exponential-function']"
37,"Prove that $k_{n+1}\in \left\{{Nk_{n}+1,Nk_{n}-1}\right\}$ is not a recursive prime generator",Prove that  is not a recursive prime generator,"k_{n+1}\in \left\{{Nk_{n}+1,Nk_{n}-1}\right\}","For positive $N,k_{0}$ prove that the recurrence relation does not always produce prime numbers (regardless of the recurrence choice). I have seen this claimed for $N=2$ and the proof thereof is fairly clear: you separate the recurrence choices according to divisibility of $k_{0}$ by 3 and then proceed to compare the remainders of the numbers in the sequence by the prime $k_{0}$ . It turns out the mapping from the remainder of $k_{n}$ to the remainder of the following is always injective and because the range of values is finite, the remainders have to repeat, specifically the remainder 0. I have been wondering however how to prove this holds for other $N$ (I do not believe any would produce a prime generator). The previous approach does not lend itself well to this. I have seen an old contest question claiming it isnt a generator for $N=1986$ . How to go about proving this, if not in general, at least for a specific number? Thank you!","For positive prove that the recurrence relation does not always produce prime numbers (regardless of the recurrence choice). I have seen this claimed for and the proof thereof is fairly clear: you separate the recurrence choices according to divisibility of by 3 and then proceed to compare the remainders of the numbers in the sequence by the prime . It turns out the mapping from the remainder of to the remainder of the following is always injective and because the range of values is finite, the remainders have to repeat, specifically the remainder 0. I have been wondering however how to prove this holds for other (I do not believe any would produce a prime generator). The previous approach does not lend itself well to this. I have seen an old contest question claiming it isnt a generator for . How to go about proving this, if not in general, at least for a specific number? Thank you!","N,k_{0} N=2 k_{0} k_{0} k_{n} N N=1986","['sequences-and-series', 'prime-numbers', 'recurrence-relations']"
38,"Closed form of $\sum\limits_{n=1}^\infty \frac{(n+a,bn)n^k}{(n+c)!}$ with the Lower Gamma function?",Closed form of  with the Lower Gamma function?,"\sum\limits_{n=1}^\infty \frac{(n+a,bn)n^k}{(n+c)!}","$$\Large{\text{Goal:}}$$ One goal is to find better ways of expressing: $$\sum_{n=0}^\infty \frac{(pn+q)^{rn+s}(An+B,Cn+D)}{(an+b)}$$ $$\Large{\text{Special Case:}}$$ Here are some closed form special cases using the Regularized Lower aand upper Incomplete Gamma function and Lower Incomplete  gamma function $$(a,z)=\Gamma(a)-\Gamma(a,z)\\\text P(a,z)=\frac{(a,z)}{\Gamma(a)}\\Q(a,z)=\frac{\Gamma(a,z)}{\Gamma(a)}\\\text P(a,z)+Q(a,z)=1\\\sum_{n=1}^\infty \frac{(n+a,bn)}{n! n^{a+1}}\mathop=^{0\le b\le1}\frac{b^{a+1}}{a+1}\implies\sum_{n=1}^\infty \frac{\Gamma(n+a,bn)}{n! n^{a+1}}= -\frac{b^{a+1}}{a+1}+\sum_{n=1}^\infty \frac{(n+1)_{a-1}}{ n^{a+1}} =? $$ The $\sum\limits_{n=1}^\infty \frac{(n+1)_{a-1}}{ n^{a+1}}$ seems to be a sum of Riemann Zeta function values since you can try the following for $a\in\Bbb N$ to get a closed form of the simpler sum: $$\sum_{n=1}^\infty \frac{\Gamma\left(n+4,\frac n2\right)}{n! n^{5}}=\frac{\pi^2}{6}+\frac{11\pi^4}{90}+6(3)+6(5)-\frac1{160}= 26.9781475874885318135350777164 $$ where appears the Pochhammer symbol $(A)_x$ . The restriction on $b$ is loose since: $$\sum_{n=1}^\infty \frac{\left(n+i,\frac n3\right)}{n!n^{i+1}}=\frac{3^{-1-i}}{1+i}= \frac{1-i}{6}(\cos(\ln(3))-i\sin(\ln(3)))=-0.072624103140189550674560360495022601835... - 0.2242349107490594690170820750267034298651... i$$ Conjectures: $$\sum_{n=0}^\infty \frac{Q(n+1,n)}{n^3}\mathop=^? (3)-\frac13$$ $$\sum_{n=0}^\infty \frac{Q(n+1,n)}{n^2}\mathop=^?\frac{\pi^2}6-\frac12$$ Please correct me and give me feedback! $$\Large{\text{Mini Goal:}}$$ Using the above notation, I have noticed a closed form for the following $(a,z)=\int_0^z t^{a-1} e^{-t} dt$ series: $$\sum\limits_{n=1}^\infty \frac{(n+a,bn)n^k}{(n+c)!}\\\\ \sum_{n=1}^\infty \frac{\left(n+2,\frac n5\right)n^3}{n!}=\frac{3982173}{10485760}\\ \sum_{n=1}^\infty \frac{\left(n+1,\frac n5\right)}{n!} =\frac1{32}\\ \sum_{n=1}^\infty \frac{\left(n,\frac n4\right)}{(n-3)!}=\frac{1717}{2916}\\ \sum_{n=1}^\infty \frac{\left(n,\frac n2 \right)}{n!}=\ln(2)\\ \sum_{n=1}^\infty \frac{\left(n,\frac n2 \right)}{n^3 n!}=\frac{119}{288} \\ \sum_{n=1}^\infty \frac{\left(n+2,\frac n3 \right)}{n^2 (n-2)!} =\ln\left(\frac23\right)+\frac{89}{192}$$ What is a closed form for: $\sum\limits_{n=1}^\infty \frac{(n+a,bn)n^k}{(n+c)!}$ ? The easiest cases would be those with $a,-c\in\Bbb N \text{ or } 0,\frac1b\in\Bbb N,k\in\Bbb Z$ , but these are just a suggestion if there is no closed form outside of these restrictions.","One goal is to find better ways of expressing: Here are some closed form special cases using the Regularized Lower aand upper Incomplete Gamma function and Lower Incomplete  gamma function The seems to be a sum of Riemann Zeta function values since you can try the following for to get a closed form of the simpler sum: where appears the Pochhammer symbol . The restriction on is loose since: Conjectures: Please correct me and give me feedback! Using the above notation, I have noticed a closed form for the following series: What is a closed form for: ? The easiest cases would be those with , but these are just a suggestion if there is no closed form outside of these restrictions.","\Large{\text{Goal:}} \sum_{n=0}^\infty \frac{(pn+q)^{rn+s}(An+B,Cn+D)}{(an+b)} \Large{\text{Special Case:}} (a,z)=\Gamma(a)-\Gamma(a,z)\\\text P(a,z)=\frac{(a,z)}{\Gamma(a)}\\Q(a,z)=\frac{\Gamma(a,z)}{\Gamma(a)}\\\text P(a,z)+Q(a,z)=1\\\sum_{n=1}^\infty \frac{(n+a,bn)}{n! n^{a+1}}\mathop=^{0\le b\le1}\frac{b^{a+1}}{a+1}\implies\sum_{n=1}^\infty \frac{\Gamma(n+a,bn)}{n! n^{a+1}}= -\frac{b^{a+1}}{a+1}+\sum_{n=1}^\infty \frac{(n+1)_{a-1}}{ n^{a+1}} =?  \sum\limits_{n=1}^\infty \frac{(n+1)_{a-1}}{ n^{a+1}} a\in\Bbb N \sum_{n=1}^\infty \frac{\Gamma\left(n+4,\frac n2\right)}{n! n^{5}}=\frac{\pi^2}{6}+\frac{11\pi^4}{90}+6(3)+6(5)-\frac1{160}= 26.9781475874885318135350777164  (A)_x b \sum_{n=1}^\infty \frac{\left(n+i,\frac n3\right)}{n!n^{i+1}}=\frac{3^{-1-i}}{1+i}= \frac{1-i}{6}(\cos(\ln(3))-i\sin(\ln(3)))=-0.072624103140189550674560360495022601835... -
0.2242349107490594690170820750267034298651... i \sum_{n=0}^\infty \frac{Q(n+1,n)}{n^3}\mathop=^? (3)-\frac13 \sum_{n=0}^\infty \frac{Q(n+1,n)}{n^2}\mathop=^?\frac{\pi^2}6-\frac12 \Large{\text{Mini Goal:}} (a,z)=\int_0^z t^{a-1} e^{-t} dt \sum\limits_{n=1}^\infty \frac{(n+a,bn)n^k}{(n+c)!}\\\\ \sum_{n=1}^\infty \frac{\left(n+2,\frac n5\right)n^3}{n!}=\frac{3982173}{10485760}\\ \sum_{n=1}^\infty \frac{\left(n+1,\frac n5\right)}{n!} =\frac1{32}\\ \sum_{n=1}^\infty \frac{\left(n,\frac n4\right)}{(n-3)!}=\frac{1717}{2916}\\ \sum_{n=1}^\infty \frac{\left(n,\frac n2 \right)}{n!}=\ln(2)\\ \sum_{n=1}^\infty \frac{\left(n,\frac n2 \right)}{n^3 n!}=\frac{119}{288} \\ \sum_{n=1}^\infty \frac{\left(n+2,\frac n3 \right)}{n^2 (n-2)!} =\ln\left(\frac23\right)+\frac{89}{192} \sum\limits_{n=1}^\infty \frac{(n+a,bn)n^k}{(n+c)!} a,-c\in\Bbb N \text{ or } 0,\frac1b\in\Bbb N,k\in\Bbb Z","['sequences-and-series', 'recreational-mathematics', 'special-functions', 'closed-form', 'lambert-w']"
39,What do we know about the analytic continuations of Dirichlet series?,What do we know about the analytic continuations of Dirichlet series?,,"Let $s=\sigma+it$ be a complex number and define the function: $$F(s)=\sum_{k=2}^{\infty}\frac{p_\pi(k)}{k^s}$$ Where $p_\pi(k)$ is the number of unordered factorizations of $k$ , corresponding to OEIS A001055 This is a Dirichlet series that converges for $\sigma>1$ . I know that finding the analytic continuation for any Dirichlet series is absolutely not trivial, and many of them require more knowledge about the nontrivial zeros of $\zeta(s)$ . The function above is just an example of a function I am working with. Is it possible to find the analytic continuation of the function above, with the known methods? If not, why? Do we know any other analytic continuation for the Dirichlet series out of Dirichlet's L-Functions?","Let be a complex number and define the function: Where is the number of unordered factorizations of , corresponding to OEIS A001055 This is a Dirichlet series that converges for . I know that finding the analytic continuation for any Dirichlet series is absolutely not trivial, and many of them require more knowledge about the nontrivial zeros of . The function above is just an example of a function I am working with. Is it possible to find the analytic continuation of the function above, with the known methods? If not, why? Do we know any other analytic continuation for the Dirichlet series out of Dirichlet's L-Functions?",s=\sigma+it F(s)=\sum_{k=2}^{\infty}\frac{p_\pi(k)}{k^s} p_\pi(k) k \sigma>1 \zeta(s),"['sequences-and-series', 'number-theory', 'analytic-number-theory', 'riemann-zeta', 'dirichlet-series']"
40,Convergence of $\sum_{n=1}^{\infty} \frac{1}{\lambda(n)^s}$,Convergence of,\sum_{n=1}^{\infty} \frac{1}{\lambda(n)^s},"Does there exist $s>1$ such that the infinite sum: $$\large \sum_{n=1}^{\infty} \frac{1}{\lambda(n)^s}$$ converges? $\lambda(n)$ denotes the Carmichael lambda function. There exists a lower bound for the Carmichael lambda function. $$ \large \frac{\ln(n)^{\ln\ln\ln(n)}}{\ln(2)} \ < \ \lambda(n) \ \le \ n-1 $$ Maybe there are better lower bounds, but if this inequality holds true for all $n$ , then we have a valid lower bound. This speaks for the existence of an $s$ such that the above infinite sum converges. Unlike the Euler totient function the Carmichael lambda function has lots and lots of solutions. For example $\lambda(n) = 12$ has 84 solutions. $\lambda(n) = 36$ has 480 solutions. Peter recently showed that $\lambda(n) = 2 \ 570 \ 400$ has more than $4 \cdot 10^{32}$ solutions. Which makes it difficult for determing $s$ . Or doesn't $s$ exist at all?","Does there exist such that the infinite sum: converges? denotes the Carmichael lambda function. There exists a lower bound for the Carmichael lambda function. Maybe there are better lower bounds, but if this inequality holds true for all , then we have a valid lower bound. This speaks for the existence of an such that the above infinite sum converges. Unlike the Euler totient function the Carmichael lambda function has lots and lots of solutions. For example has 84 solutions. has 480 solutions. Peter recently showed that has more than solutions. Which makes it difficult for determing . Or doesn't exist at all?",s>1 \large \sum_{n=1}^{\infty} \frac{1}{\lambda(n)^s} \lambda(n)  \large \frac{\ln(n)^{\ln\ln\ln(n)}}{\ln(2)} \ < \ \lambda(n) \ \le \ n-1  n s \lambda(n) = 12 \lambda(n) = 36 \lambda(n) = 2 \ 570 \ 400 4 \cdot 10^{32} s s,"['sequences-and-series', 'number-theory', 'elementary-number-theory']"
41,Is there a bijection of the natural numbers which swaps $\frac{1}{n}$-summable subsets with $\frac{1}{\sqrt{n}}$-summable subsets?,Is there a bijection of the natural numbers which swaps -summable subsets with -summable subsets?,\frac{1}{n} \frac{1}{\sqrt{n}},"Let me start with a precise statement of the question.  For a subset $A\subseteq \mathbb{N}$ and a series of positive real numbers $\sum_{n=0}^\infty a_n$ , I'll use the notation $\sum_A a_n$ as a shorthand for $\sum_{n\in A} a_n$ . Is there a bijection $f:\mathbb{N}\rightarrow \mathbb{N}$ with the property that for every $A\subseteq \mathbb{N}$ , $\sum_A \frac{1}{n}$ converges iff $\sum_{f(A)} \frac{1}{\sqrt{n}}$ converges? Background : Fix a series of positive terms $\sum_{n=0}^\infty a_n$ .  Given a subset $A\subseteq \mathbb{N}$ , call it $a_n$ -small if $\sum_A a_n$ converges.  The following proposition is easy to prove: Proposition :  The set $\{A\subseteq \mathbb{N}: A\text{ is } a_n\text{-small}\}\cup \{\mathbb{N}\}$ is a topology of closed sets on $\mathbb{N}$ . I will use the notation $(\mathbb{N},a_n)$ to refer to this topology.  Then one can ask how topological properties of $(\mathbb{N},a_n)$ are related to series properties of $\sum a_n$ .  For example, I can show: Proposition :  The following are equivalent. $\sum a_n$ converges. $(\mathbb{N},a_n)$ is discrete. $(\mathbb{N},a_n)$ is disconnected. $(\mathbb{N},a_n)$ is Hausdorff And there are other nice things.  For example, $(\mathbb{N},a_n)$ is compact iff $(\mathbb{N},a_n)$ is cofinite iff $\liminf a_n > 0$ . With this language, my question can be reformulated as... Are $\left(\mathbb{N}, \frac{1}{n}\right)$ and $\left(\mathbb{N}, \frac{1}{\sqrt{n}}\right)$ homeomorphic? I have made very little progress on this.  Of course, the identity function $i:(\mathbb{N}, \frac{1}{\sqrt{n}})\rightarrow (\mathbb{N}, \frac{1}{n})$ is a continuous bijection, but the inverse map is not continuous.  Also, if there is such a bijection, there there is such a bijection with agrees with $i$ on any preassigned finite set. Edit I thought I add in a slightly suprising (to me, at least) example when things work out to be homeomorphic. Begin with a convergent series $\sum c_n$ . and divergent series $\sum a_n$ with $\lim a_n = 0$ .  Create a new series $b_n$ using all the terms of $c_n$ and $a_n$ (in whatever order you wish).  Then $(\mathbb{N}, a_n)$ and $(\mathbb{N}, b_n)$ are homeomorphic.  The idea is that since $\lim a_n = 0$ , there is a convergent infinite subseries $\sum_A a_n$ .  Then we use a bijection which with $A$ and $A\cup \{\text{indices of }c_n\}$ to ""squeeze"" the $c_n$ in without changing the topology.  Of course, I am glossing over many details, but I can include them if desired.","Let me start with a precise statement of the question.  For a subset and a series of positive real numbers , I'll use the notation as a shorthand for . Is there a bijection with the property that for every , converges iff converges? Background : Fix a series of positive terms .  Given a subset , call it -small if converges.  The following proposition is easy to prove: Proposition :  The set is a topology of closed sets on . I will use the notation to refer to this topology.  Then one can ask how topological properties of are related to series properties of .  For example, I can show: Proposition :  The following are equivalent. converges. is discrete. is disconnected. is Hausdorff And there are other nice things.  For example, is compact iff is cofinite iff . With this language, my question can be reformulated as... Are and homeomorphic? I have made very little progress on this.  Of course, the identity function is a continuous bijection, but the inverse map is not continuous.  Also, if there is such a bijection, there there is such a bijection with agrees with on any preassigned finite set. Edit I thought I add in a slightly suprising (to me, at least) example when things work out to be homeomorphic. Begin with a convergent series . and divergent series with .  Create a new series using all the terms of and (in whatever order you wish).  Then and are homeomorphic.  The idea is that since , there is a convergent infinite subseries .  Then we use a bijection which with and to ""squeeze"" the in without changing the topology.  Of course, I am glossing over many details, but I can include them if desired.","A\subseteq \mathbb{N} \sum_{n=0}^\infty a_n \sum_A a_n \sum_{n\in A} a_n f:\mathbb{N}\rightarrow \mathbb{N} A\subseteq \mathbb{N} \sum_A \frac{1}{n} \sum_{f(A)} \frac{1}{\sqrt{n}} \sum_{n=0}^\infty a_n A\subseteq \mathbb{N} a_n \sum_A a_n \{A\subseteq \mathbb{N}: A\text{ is } a_n\text{-small}\}\cup \{\mathbb{N}\} \mathbb{N} (\mathbb{N},a_n) (\mathbb{N},a_n) \sum a_n \sum a_n (\mathbb{N},a_n) (\mathbb{N},a_n) (\mathbb{N},a_n) (\mathbb{N},a_n) (\mathbb{N},a_n) \liminf a_n > 0 \left(\mathbb{N}, \frac{1}{n}\right) \left(\mathbb{N}, \frac{1}{\sqrt{n}}\right) i:(\mathbb{N}, \frac{1}{\sqrt{n}})\rightarrow (\mathbb{N}, \frac{1}{n}) i \sum c_n \sum a_n \lim a_n = 0 b_n c_n a_n (\mathbb{N}, a_n) (\mathbb{N}, b_n) \lim a_n = 0 \sum_A a_n A A\cup \{\text{indices of }c_n\} c_n","['real-analysis', 'sequences-and-series', 'general-topology']"
42,Almost $\pi$: a closed form expression for $\int_0^\infty \left[ \left(1+\frac 1{x!}\right)^x-1\right] dx$,Almost : a closed form expression for,\pi \int_0^\infty \left[ \left(1+\frac 1{x!}\right)^x-1\right] dx,"A slight variation of the famous limit definition of $e$ yields $$ \lim_{n\to\infty} \left(1+\frac 1 {n!}\right)^n =1.$$ By the comparison test, you can show that the series $$ S= \sum_{n=0}^\infty \left[ \left(1+\frac 1 {n!}\right)^n -1\right]$$ converges, and by the integral test, the corresponding integral $$ I= \int_{0}^\infty \left[ \left(1+\frac 1 {\Gamma(x+1)}\right)^x-1\right] dx $$ converges as well. Are there closed-form expressions for the values of $S$ and $I$ ? Approximate values are: $$ \begin{split} S &\approx 3.06768391298,\\ I &\approx 3.12609693980. \end{split} $$ This reminds me of the Fransn-Robinson constant , the integral of $1/\Gamma$ over $[0,\infty)$ , being ""almost"" $e$ , in the following way: $$ F=\int_0^\infty \frac{1}{\Gamma(x)}dx = \sum_{n=0}^\infty \frac{1}{n!} + \int_0^\infty \frac{e^{-x}}{\pi^2+\ln^2(x)}dx.$$ I wonder whether $I-S \approx 0.05841302682$ can also be quantified as an improper integral of some sort.","A slight variation of the famous limit definition of yields By the comparison test, you can show that the series converges, and by the integral test, the corresponding integral converges as well. Are there closed-form expressions for the values of and ? Approximate values are: This reminds me of the Fransn-Robinson constant , the integral of over , being ""almost"" , in the following way: I wonder whether can also be quantified as an improper integral of some sort.","e  \lim_{n\to\infty} \left(1+\frac 1 {n!}\right)^n =1.  S= \sum_{n=0}^\infty \left[ \left(1+\frac 1 {n!}\right)^n -1\right]  I= \int_{0}^\infty \left[ \left(1+\frac 1 {\Gamma(x+1)}\right)^x-1\right] dx  S I 
\begin{split}
S &\approx 3.06768391298,\\
I &\approx 3.12609693980.
\end{split}
 1/\Gamma [0,\infty) e  F=\int_0^\infty \frac{1}{\Gamma(x)}dx = \sum_{n=0}^\infty \frac{1}{n!} + \int_0^\infty \frac{e^{-x}}{\pi^2+\ln^2(x)}dx. I-S \approx 0.05841302682","['sequences-and-series', 'definite-integrals', 'closed-form']"
43,Verify my proof that e is irrational,Verify my proof that e is irrational,,"I just want some confirmation that my proof that $e$ is irrational is valid. Please offer any comments on what I could do better/formatting tips, and point out any logical errors, no matter how small. Thanks! We need to prove that $e$ is irrational. We proceed to prove by contradiction. Assume for the sake of contradiction that there exist integers $p$ , $q$ such that $p$ and $q$ are integers. We first prove that $e$ cannot be an integer by using the fact that $$e=\sum_{n=0}^{\infty} \frac{1}{n!}$$ We see that $$1+\frac{1}{1!}<1+\frac{1}{1!}+\frac{1}{2!}+\ldots<1+\sum_{n=0}^{\infty}\frac{1}{2^n}$$ since it can be shown that $n!>2^n$ for all $n>3$ . This means that $2<e<3$ and thus $e$ cannot be an integer. This means that $q\neq 1$ . Since $e=p/q$ , we can write $$\frac{p}{q}=\sum_{n=0}^{\infty}\frac{1}{n!}$$ If we multiply both sides by $q!$ , we notice that we get $$p(q-1)!=q!\sum_{n=0}^{\infty} \frac{1}{n!}=\sum_{n=0}^{q}\frac{q!}{n!}+\sum_{n=q+1}^{\infty}\frac{q!}{n!}$$ We notice that since $p$ and $q$ are integers, the left side must be an integer. Now, looking at the right side, we see that the first term is an integer, since every factor in the denominator cancels out with some factor in $q!$ , since $n\leq q$ in the first term. However, the right sum simplifies to $$\sum_{n=q+1}^{\infty}\frac{q!}{n!}=\frac{1}{q+1}+\frac{1}{(q+1)(q+2)}+\cdots<\sum_{k=1}^{\infty}\frac{1}{(q+1)^k}$$ We see that this is an infinite geometric series with sum $$\frac{\frac{1}{q+1}}{1-\frac{1}{q+1}}=\frac{1}{q}$$ and since $q\neq 1$ , we see that this sum must be less than $1$ , so it cannot be an integer. This means we have an integer and a non-integer summing to an integer, a contradiction. This means our assumption must have been wrong, and $e$ must be irrational, completing the proof.","I just want some confirmation that my proof that is irrational is valid. Please offer any comments on what I could do better/formatting tips, and point out any logical errors, no matter how small. Thanks! We need to prove that is irrational. We proceed to prove by contradiction. Assume for the sake of contradiction that there exist integers , such that and are integers. We first prove that cannot be an integer by using the fact that We see that since it can be shown that for all . This means that and thus cannot be an integer. This means that . Since , we can write If we multiply both sides by , we notice that we get We notice that since and are integers, the left side must be an integer. Now, looking at the right side, we see that the first term is an integer, since every factor in the denominator cancels out with some factor in , since in the first term. However, the right sum simplifies to We see that this is an infinite geometric series with sum and since , we see that this sum must be less than , so it cannot be an integer. This means we have an integer and a non-integer summing to an integer, a contradiction. This means our assumption must have been wrong, and must be irrational, completing the proof.",e e p q p q e e=\sum_{n=0}^{\infty} \frac{1}{n!} 1+\frac{1}{1!}<1+\frac{1}{1!}+\frac{1}{2!}+\ldots<1+\sum_{n=0}^{\infty}\frac{1}{2^n} n!>2^n n>3 2<e<3 e q\neq 1 e=p/q \frac{p}{q}=\sum_{n=0}^{\infty}\frac{1}{n!} q! p(q-1)!=q!\sum_{n=0}^{\infty} \frac{1}{n!}=\sum_{n=0}^{q}\frac{q!}{n!}+\sum_{n=q+1}^{\infty}\frac{q!}{n!} p q q! n\leq q \sum_{n=q+1}^{\infty}\frac{q!}{n!}=\frac{1}{q+1}+\frac{1}{(q+1)(q+2)}+\cdots<\sum_{k=1}^{\infty}\frac{1}{(q+1)^k} \frac{\frac{1}{q+1}}{1-\frac{1}{q+1}}=\frac{1}{q} q\neq 1 1 e,"['sequences-and-series', 'power-series', 'solution-verification']"
44,Can the inverse of the Riemann zeta function in $s > 1$ be expressed as a series?,Can the inverse of the Riemann zeta function in  be expressed as a series?,s > 1,"In this post, we are interested in the Rimenann zeta function $\zeta(s)$ in $s > 1$ only where it is strictly decreasing rather than $s$ in the entire complex plane. We have the Stieltjes series expansion of the Riemann Zeta function. I inverted the first few terms of this series using series reversion and showed that if $s > 1$ and $\zeta(s) = a$ , then, $$ s = \zeta^{-1}(a) = 1 + \frac{1}{a - \gamma_0} - \frac{\gamma_1}{1!(a - \gamma_0)^2} + \frac{\gamma_2}{2!(a - \gamma_0)^3} - \frac{\gamma_3 - 12\gamma_1}{3!(a - \gamma_0)^4} + \mathcal O(a^{-5}) $$ It seems that $\zeta^{-1}(a)$ can be expressed in the form $$ 1 + \sum_{n=0}^{\infty} (-1)^n\frac{f(\gamma_1, \gamma_2, \ldots, \gamma_n)}{n!(a - \gamma_0)^{n+1}} $$ where $f(\gamma_1, \gamma_2, \ldots, \gamma_n)$ is some polynomial function of the Stieltjes constants $\gamma_n$ . Question : I am looking for a closed or a recurrence formula for $f$ ? Also any reference in this series in literature? Note : Posted in MO since there was no answer in MSE","In this post, we are interested in the Rimenann zeta function in only where it is strictly decreasing rather than in the entire complex plane. We have the Stieltjes series expansion of the Riemann Zeta function. I inverted the first few terms of this series using series reversion and showed that if and , then, It seems that can be expressed in the form where is some polynomial function of the Stieltjes constants . Question : I am looking for a closed or a recurrence formula for ? Also any reference in this series in literature? Note : Posted in MO since there was no answer in MSE","\zeta(s) s > 1 s s > 1 \zeta(s) = a 
s = \zeta^{-1}(a) = 1 + \frac{1}{a - \gamma_0} - \frac{\gamma_1}{1!(a - \gamma_0)^2} + \frac{\gamma_2}{2!(a - \gamma_0)^3} - \frac{\gamma_3 - 12\gamma_1}{3!(a - \gamma_0)^4} + \mathcal O(a^{-5})
 \zeta^{-1}(a) 
1 + \sum_{n=0}^{\infty} (-1)^n\frac{f(\gamma_1, \gamma_2, \ldots, \gamma_n)}{n!(a - \gamma_0)^{n+1}}
 f(\gamma_1, \gamma_2, \ldots, \gamma_n) \gamma_n f","['sequences-and-series', 'number-theory', 'prime-numbers', 'analytic-number-theory', 'riemann-zeta']"
45,Does $ \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^{|\sin(n)|}} $ converge?,Does  converge?, \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^{|\sin(n)|}} ,"I am trying to determine whether the series $ \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^{|\sin(n)|}} $ converges or not. The difficulty is in that every now and then $\sin(n)$ will be very close to zero making the corresponding term in the series close to $\pm 1$ . If I could show that these outlier terms eventually get much smaller than $1$ , or if there are about as many positive such terms as negative ones then the series would converge, but I'm not sure how to approach that. Any help is appreciated.","I am trying to determine whether the series converges or not. The difficulty is in that every now and then will be very close to zero making the corresponding term in the series close to . If I could show that these outlier terms eventually get much smaller than , or if there are about as many positive such terms as negative ones then the series would converge, but I'm not sure how to approach that. Any help is appreciated.", \sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^{|\sin(n)|}}  \sin(n) \pm 1 1,['sequences-and-series']
46,About solving $f(z) = \frac{1}{4} (f(-1-z) +2 f(-1-2z)+ 2f(-1+2z) +f(-1+z))$,About solving,f(z) = \frac{1}{4} (f(-1-z) +2 f(-1-2z)+ 2f(-1+2z) +f(-1+z)),"Final update on 11/29/2019: I have worked on this a bit more, and wrote an article summarizing all the main findings. You can read it here . I am looking for a solution where $f(z)\geq 0$ and $\int_{-\infty}^{\infty} f(z) dz = 1$ . I believe there is only one solution. That solution also satisfies $f(z) = f(-z)$ and $f(0) = f(-1) = f(1)$ . In fact $f$ is the density of $Z$ , with $$ Z= X_1 + X_1 X_2 + X_1 X_2 X_3 +\cdots $$ with the $X_i$ 's being i.i.d with the following distribution: $$P(X_i= -1) = P(X_i =-0.5) = P(X_i = 0.5) = P(X_i = 1) = 0.25.$$ We also have $$E(Z^k) = \int_{-\infty}^{\infty} z^k  f(z) dz = \frac{1}{2} \Big(1+ \frac{1}{2^k}\Big) \int_{-\infty}^{\infty} (1+z)^k f(z)dz$$ if $k$ is even, or zero otherwise. Note that the characteristic function of $Z$ satisfies $$\frac{d^k \psi_Z}{dt^k}(0) = \frac{d^k E(\exp it Z)}{dt^k}(0)= i^k E(Z^k).$$ The reason why I am interested in this problem can be found here . The empirical percentile distribution of $Z$ is pictured below: Update This is a particular case of a more general problem: solving $F_Z = F_{g(X,Z)}$ where $g$ is any function, $F$ represents the distribution associated with the density $f$ , and $X, Z$ are independent random variables. In this case, $g(X,Z) = X(1+Z)$ . Another case involving $g(X, Z) = \sqrt{X+Z}$ was discussed here . Despite the smooth appearance of $F_Z$ , it is possible that $F_Z$ is nowhere differentiable. Similar distributions have been analyzed by David Bailey in his book Experimental Mathematics in Action , published in 2007. In particular, sections 5.2 and 5.3 (pages 114-137) are very relevant to this context. One of the densities he has studied, namely $2qf(x) = f(\frac{x-1}{q}) + f(\frac{x+1}{q})$ , is very similar to the one I posted on Math.Stackexchange, here , leading to the same discussion as to when it is smooth or not, an unsolved problem in many (but not all) cases. All these problems end up in some functional equations like the one discussed in this question. A possible way to find a numerical solution is as follows. Build a sequence of densities $f_n$ that are piecewise uniform on the support domain, starting in this very particular case with $f_1(x) = \frac{1}{2}$ if $x\in [-1, 1]$ and $f_1(x) = 0$ otherwise. In fact, it's quite possible that $f$ is constant on $[-1, 1]$ based on empirical evidence. Each $f_n$ must satisfy $f_n(x) \geq 0, f_n(x) = f_n(-x)$ , and $\int_{-\infty}^{\infty} f(x) dx = 1$ . Of course this assumes that the density exists, and that the solution satisfying these constraints is unique. It also assumes that the algorithm in question converges to the solution. For instance, $f_n$ might be defined using $n$ intervals $I_{n1}, \cdots, I_{nn}$ , with $f_n(x) = c_{nk}$ constant $(k=1,\cdots,n)$ if $x\in I_{nk}$ . The intervals $I_{nk}$ 's and the constants $c_{nk}$ 's are chosen so as to minimize some error criterion $E_n$ , for instance $$E_n = \sup |F_{Z}^{(n)}(x) - F_{g(X,Z)}^{(n)}(x)| \mbox{ or } E_n = \int_{-\infty}^{\infty} |F_{Z}^{(n)}(x) - F_{g(X,Z)}^{(n)}(x)| dx.$$ Here $F^{(n)}$ is the distribution attached to $f_n$ . Techniques about how to solve this problem are described in my article New Perspectives on Statistical Distributions and Deep Learning . I will add an illustration in the next few days, if I find the time.","Final update on 11/29/2019: I have worked on this a bit more, and wrote an article summarizing all the main findings. You can read it here . I am looking for a solution where and . I believe there is only one solution. That solution also satisfies and . In fact is the density of , with with the 's being i.i.d with the following distribution: We also have if is even, or zero otherwise. Note that the characteristic function of satisfies The reason why I am interested in this problem can be found here . The empirical percentile distribution of is pictured below: Update This is a particular case of a more general problem: solving where is any function, represents the distribution associated with the density , and are independent random variables. In this case, . Another case involving was discussed here . Despite the smooth appearance of , it is possible that is nowhere differentiable. Similar distributions have been analyzed by David Bailey in his book Experimental Mathematics in Action , published in 2007. In particular, sections 5.2 and 5.3 (pages 114-137) are very relevant to this context. One of the densities he has studied, namely , is very similar to the one I posted on Math.Stackexchange, here , leading to the same discussion as to when it is smooth or not, an unsolved problem in many (but not all) cases. All these problems end up in some functional equations like the one discussed in this question. A possible way to find a numerical solution is as follows. Build a sequence of densities that are piecewise uniform on the support domain, starting in this very particular case with if and otherwise. In fact, it's quite possible that is constant on based on empirical evidence. Each must satisfy , and . Of course this assumes that the density exists, and that the solution satisfying these constraints is unique. It also assumes that the algorithm in question converges to the solution. For instance, might be defined using intervals , with constant if . The intervals 's and the constants 's are chosen so as to minimize some error criterion , for instance Here is the distribution attached to . Techniques about how to solve this problem are described in my article New Perspectives on Statistical Distributions and Deep Learning . I will add an illustration in the next few days, if I find the time.","f(z)\geq 0 \int_{-\infty}^{\infty} f(z) dz = 1 f(z) = f(-z) f(0) = f(-1) = f(1) f Z  Z= X_1 + X_1 X_2 + X_1 X_2 X_3 +\cdots  X_i P(X_i= -1) = P(X_i =-0.5) = P(X_i = 0.5) = P(X_i = 1) = 0.25. E(Z^k) = \int_{-\infty}^{\infty} z^k  f(z) dz = \frac{1}{2}
\Big(1+ \frac{1}{2^k}\Big) \int_{-\infty}^{\infty} (1+z)^k f(z)dz k Z \frac{d^k \psi_Z}{dt^k}(0) = \frac{d^k E(\exp it Z)}{dt^k}(0)= i^k E(Z^k). Z F_Z = F_{g(X,Z)} g F f X, Z g(X,Z) = X(1+Z) g(X, Z) = \sqrt{X+Z} F_Z F_Z 2qf(x) = f(\frac{x-1}{q}) + f(\frac{x+1}{q}) f_n f_1(x) = \frac{1}{2} x\in [-1, 1] f_1(x) = 0 f [-1, 1] f_n f_n(x) \geq 0, f_n(x) = f_n(-x) \int_{-\infty}^{\infty} f(x) dx = 1 f_n n I_{n1}, \cdots, I_{nn} f_n(x) = c_{nk} (k=1,\cdots,n) x\in I_{nk} I_{nk} c_{nk} E_n E_n = \sup |F_{Z}^{(n)}(x) - F_{g(X,Z)}^{(n)}(x)| \mbox{ or } E_n = \int_{-\infty}^{\infty} |F_{Z}^{(n)}(x) - F_{g(X,Z)}^{(n)}(x)| dx. F^{(n)} f_n","['sequences-and-series', 'probability-theory', 'statistics', 'probability-distributions', 'functional-equations']"
47,Irrationality of $1+1/10+1/11+1/100+...$,Irrationality of,1+1/10+1/11+1/100+...,"Let $n$ 'th smallest whole number with digits strictly $0$ or $1$ be expressed by $f(n)$ . While all of these numbers look binary, we are working in entirely base 10. Is it possible to prove that $$\sum_{n=2}^\infty f(n) =\frac{1}{1}+\frac{1}{10}+\frac{1}{11}+\frac{1}{100}+\frac{1}{101}+\text{...}\approx 1.238... $$ is irrational? I have been working on trying to move this sum into a different form, and only partially succeeded. This was done by grouping the summed numbers in differing ways. $$\sum_{n=2}^\infty f(n) = \sum_{m=1}^\infty\text{ }\text{ }\sum_{n={\lfloor \log f(m)\rfloor+1}}^\infty\frac{1}{10^{n}+f(m)}$$ While my goal with this change was to compare with various Lambert Series, I found myself a little bit lost. Any and all help is greatly appreciated.","Let 'th smallest whole number with digits strictly or be expressed by . While all of these numbers look binary, we are working in entirely base 10. Is it possible to prove that is irrational? I have been working on trying to move this sum into a different form, and only partially succeeded. This was done by grouping the summed numbers in differing ways. While my goal with this change was to compare with various Lambert Series, I found myself a little bit lost. Any and all help is greatly appreciated.",n 0 1 f(n) \sum_{n=2}^\infty f(n) =\frac{1}{1}+\frac{1}{10}+\frac{1}{11}+\frac{1}{100}+\frac{1}{101}+\text{...}\approx 1.238...  \sum_{n=2}^\infty f(n) = \sum_{m=1}^\infty\text{ }\text{ }\sum_{n={\lfloor \log f(m)\rfloor+1}}^\infty\frac{1}{10^{n}+f(m)},"['sequences-and-series', 'elementary-number-theory']"
48,What is the growth rate of the products of binomial coefficients?,What is the growth rate of the products of binomial coefficients?,,"Claim: Experimental data seems to suggest that $$ {n \choose 1^a b}{n \choose 2^a b}{n \choose 3^a b}\cdots {n \choose m^a b}  \sim \exp\bigg(\frac{2n^{1 + \frac{1}{a}}}{ab+3b}\bigg) $$ where $a$ and $b$ are a fixed positive integers and $m$ is the largest positive integer such that $m^a b \le n$ . Note that the above asymptotic are supported by the data even if we relax the condition that $a,b$ are integers and allow them to be reals $a > 0, b > 0$ and replace $k^a b$ with $\lfloor k^a b\rfloor$ . As an illustration, for $a = 3, b = 1$ , the $\%$ error between the asymptotic and the actual product is shown below. Note : Posted in MO since in it unanswered in MSE Update 19-Dec-19 : Combined the two individual claims into a single claim based on experimental data.","Claim: Experimental data seems to suggest that where and are a fixed positive integers and is the largest positive integer such that . Note that the above asymptotic are supported by the data even if we relax the condition that are integers and allow them to be reals and replace with . As an illustration, for , the error between the asymptotic and the actual product is shown below. Note : Posted in MO since in it unanswered in MSE Update 19-Dec-19 : Combined the two individual claims into a single claim based on experimental data.","
{n \choose 1^a b}{n \choose 2^a b}{n \choose 3^a b}\cdots {n \choose m^a b} 
\sim \exp\bigg(\frac{2n^{1 + \frac{1}{a}}}{ab+3b}\bigg)
 a b m m^a b \le n a,b a > 0, b > 0 k^a b \lfloor k^a b\rfloor a = 3, b = 1 \%","['sequences-and-series', 'combinatorics', 'number-theory', 'summation', 'binomial-coefficients']"
49,What does this number sieve have to do with pi?,What does this number sieve have to do with pi?,,"Playing around with numbers I stumbled upon the sequence that begins $1,3,7,13,19,27...$ Looking it up on OEIS it is $A000960$ and is also known as the Flavius Josephus sequence. It is generated by taking all the positive integers and ""sieving"" out every other number, the remaining list has every third number sieved out, after that the remaining list has every fourth number sieved out, and so on ad infinitum. $1,2,3,4,5,6,7,8,9,10,11,12,13...$ $1,3,5,7,9,11,13,...$ $1,3,7,9,13,...$ $1,3,7,13,...$ $...$ This sequence has several interesting properties, but what caught my eye was a comment left on OEIS claiming that for any number $n$ , the amount of the number of terms in the sequence less than or equal to n is $2\sqrt{\frac{n}{\pi}}+O(n^\frac{1}{6})$ which would mean that the sequence grows like $\frac{\pi n^2}{4}$ There is a paper linked in the OEIS page explaining this, I am having trouble interpreting it, mainly due to the fact that it is in German. I would appreciate any insight into why this particular sequence is connected to $\pi$ OEIS Link: https://oeis.org/A000960 German Paper: http://matwbn.icm.edu.pl/ksiazki/aa/aa85/aa8542.pdf","Playing around with numbers I stumbled upon the sequence that begins Looking it up on OEIS it is and is also known as the Flavius Josephus sequence. It is generated by taking all the positive integers and ""sieving"" out every other number, the remaining list has every third number sieved out, after that the remaining list has every fourth number sieved out, and so on ad infinitum. This sequence has several interesting properties, but what caught my eye was a comment left on OEIS claiming that for any number , the amount of the number of terms in the sequence less than or equal to n is which would mean that the sequence grows like There is a paper linked in the OEIS page explaining this, I am having trouble interpreting it, mainly due to the fact that it is in German. I would appreciate any insight into why this particular sequence is connected to OEIS Link: https://oeis.org/A000960 German Paper: http://matwbn.icm.edu.pl/ksiazki/aa/aa85/aa8542.pdf","1,3,7,13,19,27... A000960 1,2,3,4,5,6,7,8,9,10,11,12,13... 1,3,5,7,9,11,13,... 1,3,7,9,13,... 1,3,7,13,... ... n 2\sqrt{\frac{n}{\pi}}+O(n^\frac{1}{6}) \frac{\pi n^2}{4} \pi","['sequences-and-series', 'pi']"
50,concerning the coefficients of $P_n(x)=(x-1)(x-2)\cdots (x-n)$,concerning the coefficients of,P_n(x)=(x-1)(x-2)\cdots (x-n),"I am trying to find an efficient way of calculating the unsigned coefficients of $$P_n(x)=\prod_{k=1}^{n}(x-k),$$ i.e. I want to speed up the process of calculating $a_k(n)$ such that $$P_n(x)=\sum_{k=0}^{n}(-1)^ka_k(n)x^{n-k}.$$ I found a method, but for $n\ge 5$ it is very inefficient. I found it by noting that $$\prod_{a\in A}(x-a)=\sum_{k=0}^{|A|}(-1)^{k}x^{|A|-k}\sum_{P\subseteq A\\ |P|=k}\prod_{u\in P}u\ .$$ So setting $A=\{1,2,...,n\}$ for some $n\in\Bbb N$ , $$\prod_{a\in A}(x-a)=P_n(x)=\sum_{k=0}^{n}(-1)^kx^{n-k}\sum_{P\subseteq A\\ |P|=k}\prod_{u\in P}u\ .$$ So of course I defined $$a_0(n)=1$$ and $$a_k(n)=\sum_{P\subseteq\{1,...,n\}\\ \quad |P|=k}\prod_{u\in P}u\ .\tag{1}$$ If we plug in $x=0$ , $$P_n(0)=\prod_{k=1}^{n}(-k)=(-1)^n n!\ ,$$ so that $$a_n(n)=n!\ .$$ It is also fairly easy to show that $$a_1(n)=\frac{n(n+1)}{2}\ .$$ I was also able to show that $$a_2(n)=\sum_{(u,v)\in R_n}uv$$ where $$R_n=[1,n]^2\cap\left\{(x,y)\in\Bbb N^2: y-x\in[1,n-1]\right\},$$ But that isn't simpler by any stretch of the imagination. Is there a more efficient version of $(1)$ ? Thanks. Edit for context: As I said in the comments, there is no reason that I need these coefficients, I just thought it would be an interesting problem to find them. Once I found them, I wondered if there was a more efficient way of calculating them, so I asked here.","I am trying to find an efficient way of calculating the unsigned coefficients of i.e. I want to speed up the process of calculating such that I found a method, but for it is very inefficient. I found it by noting that So setting for some , So of course I defined and If we plug in , so that It is also fairly easy to show that I was also able to show that where But that isn't simpler by any stretch of the imagination. Is there a more efficient version of ? Thanks. Edit for context: As I said in the comments, there is no reason that I need these coefficients, I just thought it would be an interesting problem to find them. Once I found them, I wondered if there was a more efficient way of calculating them, so I asked here.","P_n(x)=\prod_{k=1}^{n}(x-k), a_k(n) P_n(x)=\sum_{k=0}^{n}(-1)^ka_k(n)x^{n-k}. n\ge 5 \prod_{a\in A}(x-a)=\sum_{k=0}^{|A|}(-1)^{k}x^{|A|-k}\sum_{P\subseteq A\\ |P|=k}\prod_{u\in P}u\ . A=\{1,2,...,n\} n\in\Bbb N \prod_{a\in A}(x-a)=P_n(x)=\sum_{k=0}^{n}(-1)^kx^{n-k}\sum_{P\subseteq A\\ |P|=k}\prod_{u\in P}u\ . a_0(n)=1 a_k(n)=\sum_{P\subseteq\{1,...,n\}\\ \quad |P|=k}\prod_{u\in P}u\ .\tag{1} x=0 P_n(0)=\prod_{k=1}^{n}(-k)=(-1)^n n!\ , a_n(n)=n!\ . a_1(n)=\frac{n(n+1)}{2}\ . a_2(n)=\sum_{(u,v)\in R_n}uv R_n=[1,n]^2\cap\left\{(x,y)\in\Bbb N^2: y-x\in[1,n-1]\right\}, (1)","['sequences-and-series', 'combinatorics', 'polynomials', 'products']"
51,Construction involving regular polygons inside a circle,Construction involving regular polygons inside a circle,,"Let's make a construction involving regular polygons:  First, we begin with a equilateral triangle, with side $\ell_3 = 1;$  After, we draw a square on the middle point each side of the initial triangle, with side $\ell_4 = \frac{1}{2} = \frac{\ell}{2}.$ Now, the construction continues, taking one of these steps:  If the regular polygon have an even number of sides $n$ with length $\ell_n$ , then we draw two regular polygons with $n + 1$ sides of length $\ell_{n+1} = \frac{\ell_n}{2},$ from the middle point of the extreme segments.  If the regular polygon have an odd number of sides $n$ with length $\ell_n$ , then we draw one regular polygons with $n + 1$ sides of length $\ell_{n+1} = \frac{\ell_n}{2},$ from the middle point of the unique extreme segment in this case. To clarify the explanation, we will obtain a figure like the one below: I have two questions about this: Q1 . This figure is inside a circumference with center in the incenter of the initial equilateral triangle? In affirmative case, what is the radius $R$ of the circumference? Q2 . The sequence of the lengths I adopted in the construction is $$\ell_n = \frac{1}{2^{n-3}}, \quad \forall n \ge 3 $$ If I consider other sequence $\ell_n$ , when exists a circumference with center in the incenter of the initial equilateral triangle and radius $R$ in which the figure is inside?","Let's make a construction involving regular polygons:  First, we begin with a equilateral triangle, with side  After, we draw a square on the middle point each side of the initial triangle, with side Now, the construction continues, taking one of these steps:  If the regular polygon have an even number of sides with length , then we draw two regular polygons with sides of length from the middle point of the extreme segments.  If the regular polygon have an odd number of sides with length , then we draw one regular polygons with sides of length from the middle point of the unique extreme segment in this case. To clarify the explanation, we will obtain a figure like the one below: I have two questions about this: Q1 . This figure is inside a circumference with center in the incenter of the initial equilateral triangle? In affirmative case, what is the radius of the circumference? Q2 . The sequence of the lengths I adopted in the construction is If I consider other sequence , when exists a circumference with center in the incenter of the initial equilateral triangle and radius in which the figure is inside?","\ell_3 = 1; \ell_4 = \frac{1}{2} = \frac{\ell}{2}. n \ell_n n + 1 \ell_{n+1} = \frac{\ell_n}{2}, n \ell_n n + 1 \ell_{n+1} = \frac{\ell_n}{2}, R \ell_n = \frac{1}{2^{n-3}}, \quad \forall n \ge 3  \ell_n R","['sequences-and-series', 'geometry', 'euclidean-geometry', 'circles', 'polygons']"
52,What is a common framework for these divergent sums?,What is a common framework for these divergent sums?,,"If you expand $2^x$ using a finite difference series you end up with the formula $$ 1 + x + \frac{1}{2!}x(x-1) + \frac{1}{3!}x(x-1)(x-2) ... = \sum_{n=0}^{\infty} \frac{(x)_n}{n!} $$ Now these series diverge for negative arguments, but they give some interesting results, i.e. they suggest $$1 - 1 + 1 - 1 \ ... = \frac{1}{2}$$ $$1 - 2 + 3 - 4 \ ... = \frac{1}{4}$$ $$1 - 3 + 6 - 10 \ ... =  \frac{1}{8} $$ and more generally... $$\begin{pmatrix} k \\ k  \end{pmatrix} - \begin{pmatrix} k+1 \\ k  \end{pmatrix} + \begin{pmatrix} k+2 \\ k  \end{pmatrix} ... = 2^{-n}$$ Now what's funny... is that these divergent equalities, can actually be arrived at in a totally different way, which is by differentiating the function $ \frac{1}{1-x}$ $k$ times, dividing by k! and evaluating it at $x=-1$ . These two very distinct methods of infinite series seem to agree and so that has me wondering, is there a natural divergent summation method that encapsulates all this behavior? I want to say something like $$2^x \equiv \sum_{n=0}^{\infty} \frac{(x)_n}{n!} \mod \text{summation method L }$$ $$ \frac{1}{1-x} \equiv \sum_{n=0}^{\infty} x^n \mod \text{summation method L} $$ this sort of abstract framework would be very useful and interesting to explore. But even something like Cessaro summation seems unsatisfactory, and it is not clear if Holder summation is sufficient for me. (I tried to calculate it with it and didn't end up getting the answer I expected).","If you expand using a finite difference series you end up with the formula Now these series diverge for negative arguments, but they give some interesting results, i.e. they suggest and more generally... Now what's funny... is that these divergent equalities, can actually be arrived at in a totally different way, which is by differentiating the function times, dividing by k! and evaluating it at . These two very distinct methods of infinite series seem to agree and so that has me wondering, is there a natural divergent summation method that encapsulates all this behavior? I want to say something like this sort of abstract framework would be very useful and interesting to explore. But even something like Cessaro summation seems unsatisfactory, and it is not clear if Holder summation is sufficient for me. (I tried to calculate it with it and didn't end up getting the answer I expected).",2^x  1 + x + \frac{1}{2!}x(x-1) + \frac{1}{3!}x(x-1)(x-2) ... = \sum_{n=0}^{\infty} \frac{(x)_n}{n!}  1 - 1 + 1 - 1 \ ... = \frac{1}{2} 1 - 2 + 3 - 4 \ ... = \frac{1}{4} 1 - 3 + 6 - 10 \ ... =  \frac{1}{8}  \begin{pmatrix} k \\ k  \end{pmatrix} - \begin{pmatrix} k+1 \\ k  \end{pmatrix} + \begin{pmatrix} k+2 \\ k  \end{pmatrix} ... = 2^{-n}  \frac{1}{1-x} k x=-1 2^x \equiv \sum_{n=0}^{\infty} \frac{(x)_n}{n!} \mod \text{summation method L }  \frac{1}{1-x} \equiv \sum_{n=0}^{\infty} x^n \mod \text{summation method L} ,"['sequences-and-series', 'complex-analysis', 'divergent-series', 'finite-differences', 'formal-power-series']"
53,"Proving that the sequence $1, \frac12, \frac{1/2}{3/4}, \cdots$ converges to $\frac{\sqrt 2}2$ [duplicate]",Proving that the sequence  converges to  [duplicate],"1, \frac12, \frac{1/2}{3/4}, \cdots \frac{\sqrt 2}2","This question already has answers here : Tall fraction puzzle (3 answers) What is $\cdots ((((1/2)/(3/4))/((5/6)/(7/8)))/(((9/10)/(11/12))/((13/14)/(15/16))))/\cdots$? [duplicate] (6 answers) Closed 5 years ago . I saw this on a Facebook page: \begin{align*} 1, \qquad \frac12,\qquad\frac{\frac12}{\frac34}, \qquad\frac{\frac{\frac12}{\frac34}}{\frac{\frac56}{\frac78}},\qquad \dots\to \frac{\sqrt{2}}2. \end{align*} The $n$-th term is the combination of $2^n$ consecutive integers from $1$ to $2^n$. Question: How to prove this in a both rigorous and easy way? 1st attempt Let $\{a_n\}$ be the sequence. We try to ""simplify"" $a_n$ as the form $\dfrac{1\cdot4\cdot6\cdot7\cdots}{2\cdot3\cdot5\cdot8\cdots}$, as simple fraction, to find the pattern in which some integers are numerators and others are denominators. Let $f: \Bbb N \mapsto \Bbb Z$ such that  \begin{align*} a_n=\prod_{k=1}^{2^{n-1}}k^{(-1)^{f(k)}}.\tag{*} \end{align*} However, it seems hard to find the expression / recurrence formula for $f$ and show it converges to $\dfrac{\sqrt2}2$. 2nd attempt Again we let $\{a_n\}$ be the sequence. Consider the continued fraction: \begin{align*} \sqrt2=1+\underset{i=1}{\overset{\infty}{\mathrm K}} ~ \frac{1}{2}=1+\cfrac1{2+\cfrac1{2+\cfrac1{2+\cfrac1{\ddots}}}}. \end{align*} Then, we define \begin{align*} b_m=\frac12\left(1+\underset{i=1}{\overset{m}{\mathrm K}} ~ \frac{1}{2}\right)=\frac12+\frac12\cdot\cfrac1{2+\cfrac1{\ddots+\cfrac1{2}}}. \end{align*} Obviously $b_m$ converges to $\dfrac{\sqrt2}2$. Then we just need to show that $a_n$ is between $b_m$ and $b_{m+1}$ for big $m$ and $n$ ( $m$ depends on $n$), which seems complicated.","This question already has answers here : Tall fraction puzzle (3 answers) What is $\cdots ((((1/2)/(3/4))/((5/6)/(7/8)))/(((9/10)/(11/12))/((13/14)/(15/16))))/\cdots$? [duplicate] (6 answers) Closed 5 years ago . I saw this on a Facebook page: \begin{align*} 1, \qquad \frac12,\qquad\frac{\frac12}{\frac34}, \qquad\frac{\frac{\frac12}{\frac34}}{\frac{\frac56}{\frac78}},\qquad \dots\to \frac{\sqrt{2}}2. \end{align*} The $n$-th term is the combination of $2^n$ consecutive integers from $1$ to $2^n$. Question: How to prove this in a both rigorous and easy way? 1st attempt Let $\{a_n\}$ be the sequence. We try to ""simplify"" $a_n$ as the form $\dfrac{1\cdot4\cdot6\cdot7\cdots}{2\cdot3\cdot5\cdot8\cdots}$, as simple fraction, to find the pattern in which some integers are numerators and others are denominators. Let $f: \Bbb N \mapsto \Bbb Z$ such that  \begin{align*} a_n=\prod_{k=1}^{2^{n-1}}k^{(-1)^{f(k)}}.\tag{*} \end{align*} However, it seems hard to find the expression / recurrence formula for $f$ and show it converges to $\dfrac{\sqrt2}2$. 2nd attempt Again we let $\{a_n\}$ be the sequence. Consider the continued fraction: \begin{align*} \sqrt2=1+\underset{i=1}{\overset{\infty}{\mathrm K}} ~ \frac{1}{2}=1+\cfrac1{2+\cfrac1{2+\cfrac1{2+\cfrac1{\ddots}}}}. \end{align*} Then, we define \begin{align*} b_m=\frac12\left(1+\underset{i=1}{\overset{m}{\mathrm K}} ~ \frac{1}{2}\right)=\frac12+\frac12\cdot\cfrac1{2+\cfrac1{\ddots+\cfrac1{2}}}. \end{align*} Obviously $b_m$ converges to $\dfrac{\sqrt2}2$. Then we just need to show that $a_n$ is between $b_m$ and $b_{m+1}$ for big $m$ and $n$ ( $m$ depends on $n$), which seems complicated.",,"['sequences-and-series', 'limits', 'infinite-product', 'continued-fractions']"
54,Proof on positive sequence with $\limsup_{n} a_n^{1/n}=1$ and $\liminf_{n}a_n^{1/n} <1$,Proof on positive sequence with  and,\limsup_{n} a_n^{1/n}=1 \liminf_{n}a_n^{1/n} <1,"Does a positive sequence $\{a_n\}$ with $\limsup_{n} a_n^{1/n}=1$ and $\liminf_{n}a_n^{1/n} <1$ must have a subsequence $\{a_{n_i}\}$ satisfying $\lim_{i} a_{n_i}^{1/n_i}=1$ and $\lim_{i} |a_{n_i}^2-a_{n_i-1}a_{n_i+1}|^{1/n_i}=1$. So Here are the hypothesis: \begin{equation} \limsup_{n} a_{n}^{1/n}=1 \tag1 \end{equation} and  \begin{equation} \liminf_{n} a_{n}^{1/n}<1 \tag2 \end{equation} How to derive the conclusion: there is a subsequence $\{a_{n_i}\}$ fulfilling both of \begin{equation} \lim_{i} a_{n_i}^{1/n_i}=1 \tag3 \end{equation} and \begin{equation} \lim_{i} |a_{n_i}^2-a_{n_i-1}a_{n_i+1}|^{1/n_i}=1 \tag4 \end{equation} My understanding to this problem It is obvious that $(1)$ implies $(3)$, but how $(1)$ together with $(2)$ imply $(3)$ and $(4)$ is not so clear, although trivial examples such as $$1,\delta^2,1,\delta^4,\cdots,1,\delta^{2n},\cdots$$ (where $0<\delta<1$) strongly support this proposition. Given $(3)$ holds, $(4)$ may be replaced with the equivalent \begin{equation}\lim_{i} \left|1-\frac{a_{n_i+1}}{a_{n_i}} \frac{a_{n_i-1}}{a_{n_i}}\right|^{1/n_i} =1 \end{equation} So this suggests that $\dfrac{a_{n_i+1}}{a_{n_i}} \dfrac{a_{n_i-1}}{a_{n_i}}$ must be ""small"" enough. It seems somehow related to the ratio test vs the root test in convergence of series. What I expect A proof (or a counter-example) is of course appreciated, but I also want to know the origin of this problem (in what literature did it emerge). Discussions giving an insight to this problem is welcomed as well.","Does a positive sequence $\{a_n\}$ with $\limsup_{n} a_n^{1/n}=1$ and $\liminf_{n}a_n^{1/n} <1$ must have a subsequence $\{a_{n_i}\}$ satisfying $\lim_{i} a_{n_i}^{1/n_i}=1$ and $\lim_{i} |a_{n_i}^2-a_{n_i-1}a_{n_i+1}|^{1/n_i}=1$. So Here are the hypothesis: \begin{equation} \limsup_{n} a_{n}^{1/n}=1 \tag1 \end{equation} and  \begin{equation} \liminf_{n} a_{n}^{1/n}<1 \tag2 \end{equation} How to derive the conclusion: there is a subsequence $\{a_{n_i}\}$ fulfilling both of \begin{equation} \lim_{i} a_{n_i}^{1/n_i}=1 \tag3 \end{equation} and \begin{equation} \lim_{i} |a_{n_i}^2-a_{n_i-1}a_{n_i+1}|^{1/n_i}=1 \tag4 \end{equation} My understanding to this problem It is obvious that $(1)$ implies $(3)$, but how $(1)$ together with $(2)$ imply $(3)$ and $(4)$ is not so clear, although trivial examples such as $$1,\delta^2,1,\delta^4,\cdots,1,\delta^{2n},\cdots$$ (where $0<\delta<1$) strongly support this proposition. Given $(3)$ holds, $(4)$ may be replaced with the equivalent \begin{equation}\lim_{i} \left|1-\frac{a_{n_i+1}}{a_{n_i}} \frac{a_{n_i-1}}{a_{n_i}}\right|^{1/n_i} =1 \end{equation} So this suggests that $\dfrac{a_{n_i+1}}{a_{n_i}} \dfrac{a_{n_i-1}}{a_{n_i}}$ must be ""small"" enough. It seems somehow related to the ratio test vs the root test in convergence of series. What I expect A proof (or a counter-example) is of course appreciated, but I also want to know the origin of this problem (in what literature did it emerge). Discussions giving an insight to this problem is welcomed as well.",,['sequences-and-series']
55,The $n^{th}$ root of the geometric mean of binomial coefficients. [closed],The  root of the geometric mean of binomial coefficients. [closed],n^{th},"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question $\{{C_k^n}\}_{k=0}^n$ are binomial coefficients. $G_n$ is their geometrical mean. Prove  $$\lim\limits_{n\to\infty}{G_n}^{1/n}=\sqrt{e}$$","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question $\{{C_k^n}\}_{k=0}^n$ are binomial coefficients. $G_n$ is their geometrical mean. Prove  $$\lim\limits_{n\to\infty}{G_n}^{1/n}=\sqrt{e}$$",,"['calculus', 'limits', 'binomial-coefficients']"
56,Does there exist a series with property $n\sum_{k=0}^{\infty} u_{nk}=1$?,Does there exist a series with property ?,n\sum_{k=0}^{\infty} u_{nk}=1,"Shortly, the idea is to find such series which admits ""lazy"" calculation: instead of computing all the terms, it would be enough to calculate its even terms (the case with $n=2$), and then multiply result by $2$; or calculate third of its terms (the case with $n=3$), and then multiply result by $3$; etc. It seems that we can construct such series for finite set of values $n$ (say, for $n\in\{1,2,4,8\}$ or $n \in \{1,2,3,4\}$). So, my Question is: does there exist a series  $$\sum_{k=0}^{\infty} u_{k}=1,$$ such that for each $n\in\mathbb{N}$: $$n\sum_{k=0}^{\infty} u_{nk}=1. \quad (?) \tag{1}$$","Shortly, the idea is to find such series which admits ""lazy"" calculation: instead of computing all the terms, it would be enough to calculate its even terms (the case with $n=2$), and then multiply result by $2$; or calculate third of its terms (the case with $n=3$), and then multiply result by $3$; etc. It seems that we can construct such series for finite set of values $n$ (say, for $n\in\{1,2,4,8\}$ or $n \in \{1,2,3,4\}$). So, my Question is: does there exist a series  $$\sum_{k=0}^{\infty} u_{k}=1,$$ such that for each $n\in\mathbb{N}$: $$n\sum_{k=0}^{\infty} u_{nk}=1. \quad (?) \tag{1}$$",,['sequences-and-series']
57,Disproving the existence of a specific infinite sequence of Fibonacci primes,Disproving the existence of a specific infinite sequence of Fibonacci primes,,"Consider the following sequence: $$ T_{1} = a,\: T_{i+1} = F_{T_{i}} $$ where $ a \in \mathbb{P} $ and $F_i$ is the $i$-th Fibonacci number. Is there a value of $a \neq 5$ such that this sequence generates only primes? I certainly don't expect an answer in the positiveas it would prove that there are infinitely many Fibonacci primes, which is an open problembut I would like to know if there are any straightforward/obvious reasons for which such an $a$ wouldn't exist.","Consider the following sequence: $$ T_{1} = a,\: T_{i+1} = F_{T_{i}} $$ where $ a \in \mathbb{P} $ and $F_i$ is the $i$-th Fibonacci number. Is there a value of $a \neq 5$ such that this sequence generates only primes? I certainly don't expect an answer in the positiveas it would prove that there are infinitely many Fibonacci primes, which is an open problembut I would like to know if there are any straightforward/obvious reasons for which such an $a$ wouldn't exist.",,"['sequences-and-series', 'elementary-number-theory', 'prime-numbers', 'fibonacci-numbers']"
58,Examples of when a quotient of sums is equal to the sum of quotients?,Examples of when a quotient of sums is equal to the sum of quotients?,,"I have been looking into zeta sums and whatnot lately and realised the following equality. $$\frac{\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)^{3}}}{\sum_{n=0}^{\infty}\frac{(-1)^{n}}{2n+1}} = \sum_{n=0}^{\infty}\frac{\frac{(-1)^{n}}{(2n+1)^{3}}}{\frac{(-1)^{n}}{2n+1}}$$ Note the values of the series are:  $$\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)^{3}} = \frac{\pi^3}{32},\quad\quad \sum_{n=0}^{\infty}\frac{(-1)^{n}}{2n+1} = \frac{\pi}{4}, \quad\quad \sum_{n=0}^{\infty}\frac{1}{(2n+1)^{2}} = \frac{\pi^{2}}{8}$$ I assume this is a coincidence but it would be very nice to know if it's not. Are there other examples of series with this property?","I have been looking into zeta sums and whatnot lately and realised the following equality. $$\frac{\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)^{3}}}{\sum_{n=0}^{\infty}\frac{(-1)^{n}}{2n+1}} = \sum_{n=0}^{\infty}\frac{\frac{(-1)^{n}}{(2n+1)^{3}}}{\frac{(-1)^{n}}{2n+1}}$$ Note the values of the series are:  $$\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(2n+1)^{3}} = \frac{\pi^3}{32},\quad\quad \sum_{n=0}^{\infty}\frac{(-1)^{n}}{2n+1} = \frac{\pi}{4}, \quad\quad \sum_{n=0}^{\infty}\frac{1}{(2n+1)^{2}} = \frac{\pi^{2}}{8}$$ I assume this is a coincidence but it would be very nice to know if it's not. Are there other examples of series with this property?",,['sequences-and-series']
59,A series that converges to /3 [duplicate],A series that converges to /3 [duplicate],,"This question already has answers here : Find the value of $\sum_{n=0}^\infty\frac{1}{9n^2+9n+2}$ (4 answers) Showing $ \sum_{n=0}^{\infty} \frac{1}{(3n+1)(3n+2)}=\frac{\pi}{3\sqrt{3}}$ (7 answers) Closed 6 years ago . While surfing on YouTube, I stumbled into this video which gave me a new insight about the well-known series  $$ \frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7}+ \ldots $$ The idea shown there consists of counting (in a very clever way) how many points of the 2d integer lattice lie on a generic circumference of radius $\sqrt{r}, r \in \mathbb{N}$, centered at the origin. Then, we name $N(R)$ the number of points of this kind that lie inside the circumference of radius $\sqrt{R}$: as $R$ grows, we can think of $N(R)$ as a fairly good approximation of the area $\pi R$ of the circle, since each of the $N(R)$ points can be thought as the center of a square of area $1$. From the equality $\pi R = N(R)$ we get the series above. I was fairly amazed by the way this result was obtained, and I started wondering: what if we used the hexagonal lattice (I mean $\mathbb{Z} \times \zeta_3\mathbb{Z}$, where $\zeta_3$ is a non-trivial third root of unity) instead of the integer lattice? Will I get another series to approximate $\pi$? After some work, following the same kind of argument, I came to this formula: $$ \frac{\pi}{3} = \sqrt{3} \left (1 - \frac{1}{2} + \frac{1}{4} - \frac{1}{5} + \frac{1}{7} - \frac{1}{8} + \ldots \right )  $$ or equivalently  $$ \frac{\pi}{3} = \sum_{k=0}^\infty \frac{\sqrt{3}}{9k^2+9k+2} $$ I have some questions: Can anyone give me a proof of this result which does not follow the argument I sketched above? I checked by doing some simple calculations (I also asked Wolfram) and the result seems to hold, but I'd like to be 100% sure... The $\frac{\pi}{4}$ formula relates to the expansion of $\arctan(x)$, but I couldn't find any straightforward connection between the $\frac{\pi}{3}$ formula and $\arctan(x)$. I actually couldn't find any connection to the ""pi facts"" I know or I was able to find. Do anybody know anything that can explain ""easily"" what's happening here? Thanks in advance!","This question already has answers here : Find the value of $\sum_{n=0}^\infty\frac{1}{9n^2+9n+2}$ (4 answers) Showing $ \sum_{n=0}^{\infty} \frac{1}{(3n+1)(3n+2)}=\frac{\pi}{3\sqrt{3}}$ (7 answers) Closed 6 years ago . While surfing on YouTube, I stumbled into this video which gave me a new insight about the well-known series  $$ \frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7}+ \ldots $$ The idea shown there consists of counting (in a very clever way) how many points of the 2d integer lattice lie on a generic circumference of radius $\sqrt{r}, r \in \mathbb{N}$, centered at the origin. Then, we name $N(R)$ the number of points of this kind that lie inside the circumference of radius $\sqrt{R}$: as $R$ grows, we can think of $N(R)$ as a fairly good approximation of the area $\pi R$ of the circle, since each of the $N(R)$ points can be thought as the center of a square of area $1$. From the equality $\pi R = N(R)$ we get the series above. I was fairly amazed by the way this result was obtained, and I started wondering: what if we used the hexagonal lattice (I mean $\mathbb{Z} \times \zeta_3\mathbb{Z}$, where $\zeta_3$ is a non-trivial third root of unity) instead of the integer lattice? Will I get another series to approximate $\pi$? After some work, following the same kind of argument, I came to this formula: $$ \frac{\pi}{3} = \sqrt{3} \left (1 - \frac{1}{2} + \frac{1}{4} - \frac{1}{5} + \frac{1}{7} - \frac{1}{8} + \ldots \right )  $$ or equivalently  $$ \frac{\pi}{3} = \sum_{k=0}^\infty \frac{\sqrt{3}}{9k^2+9k+2} $$ I have some questions: Can anyone give me a proof of this result which does not follow the argument I sketched above? I checked by doing some simple calculations (I also asked Wolfram) and the result seems to hold, but I'd like to be 100% sure... The $\frac{\pi}{4}$ formula relates to the expansion of $\arctan(x)$, but I couldn't find any straightforward connection between the $\frac{\pi}{3}$ formula and $\arctan(x)$. I actually couldn't find any connection to the ""pi facts"" I know or I was able to find. Do anybody know anything that can explain ""easily"" what's happening here? Thanks in advance!",,"['sequences-and-series', 'number-theory', 'complex-numbers', 'pi', 'tessellations']"
60,Possible formula for $ f(x) = \sum_{n=0}^{\infty}x^{-n!} $,Possible formula for, f(x) = \sum_{n=0}^{\infty}x^{-n!} ,"I was wondering if we have a formula for the following function: $$ f(x) = \frac{1}{x^{0!}} + \frac{1}{x^{1!}} + \frac{1}{x^{2!}} + \frac{1}{x^{3!}} + ... = \sum_{n=0}^{\infty}x^{-n!} $$ (Like we have for the geometric series): $$ \sum_{k=0}^{\infty}x^{-k} =\frac{1}{1-x} $$ Or even if we have nice values for similar functions (infinite sums that has factorials in the exponents) or if we can evaluete any value of f(x) like: $$f(e),f(2)...$$","I was wondering if we have a formula for the following function: $$ f(x) = \frac{1}{x^{0!}} + \frac{1}{x^{1!}} + \frac{1}{x^{2!}} + \frac{1}{x^{3!}} + ... = \sum_{n=0}^{\infty}x^{-n!} $$ (Like we have for the geometric series): $$ \sum_{k=0}^{\infty}x^{-k} =\frac{1}{1-x} $$ Or even if we have nice values for similar functions (infinite sums that has factorials in the exponents) or if we can evaluete any value of f(x) like: $$f(e),f(2)...$$",,"['sequences-and-series', 'factorial']"
61,Find an explicit formula for the recursive formula,Find an explicit formula for the recursive formula,,"Find an explicit formula for the recursive formula: $$a_{n+1} = 2a_n\left(a_n + 3\right); a_0 = 4$$ The first few terms in the sequence go like this: $4, 56, 6608, \dots$ After $a_2$ the sequence begins increasing at a very strong rate. Normally how we were taught to find an explicit formula, we start by defining the first few terms of the sequence in terms of the initial term, $a_0$, and then look for patterns to generalize a formula for the $n$th term. For this example, we have $a_1 = 2(a_0)^2+6(a_0)$, but it only got worse when trying to find $a_2$. $a_2 = 8(a_0)^4 + 48(a_0)^3+84(a_0)^2 + 36(a_0)$ I feel as if this isn't the most efficient method to find the explicit formula, and I imagine $a_3$ would only be a ""messier"" polynomial and won't help me give me any sort of clue as to what the explicit formula may be. Is there another way to tackle this problem? Note: although I was never taught this method, I hear generating functions may be able to be used for problems such as these.","Find an explicit formula for the recursive formula: $$a_{n+1} = 2a_n\left(a_n + 3\right); a_0 = 4$$ The first few terms in the sequence go like this: $4, 56, 6608, \dots$ After $a_2$ the sequence begins increasing at a very strong rate. Normally how we were taught to find an explicit formula, we start by defining the first few terms of the sequence in terms of the initial term, $a_0$, and then look for patterns to generalize a formula for the $n$th term. For this example, we have $a_1 = 2(a_0)^2+6(a_0)$, but it only got worse when trying to find $a_2$. $a_2 = 8(a_0)^4 + 48(a_0)^3+84(a_0)^2 + 36(a_0)$ I feel as if this isn't the most efficient method to find the explicit formula, and I imagine $a_3$ would only be a ""messier"" polynomial and won't help me give me any sort of clue as to what the explicit formula may be. Is there another way to tackle this problem? Note: although I was never taught this method, I hear generating functions may be able to be used for problems such as these.",,"['sequences-and-series', 'recurrence-relations']"
62,The fractal dimension of the Kolakoski sequence is $2-1/e$,The fractal dimension of the Kolakoski sequence is,2-1/e,"The Kolakoski sequence, which is defined as the infinite sequence of symbols {1,2} that is its own run-length encoding (Wikipedia), has been suggested to be self-similar$^{1}$. The fractral dimension of a self-similar time-series is directly related to its Hurst exponent$^{2}$. I have estimated the Hurst exponent of the Kolakoski sequence for different sequence lengths, and found that the answer converges near $1 / e$ when the sequence length increases. This suggests that the fractral dimension of the Kolakoski sequence is $D=2-H = 2-1/e.$ Here is a small subset of the data sequence length    hurst exponent 1e2                .1167 1e3                .1796 1e4                .2236 1e5                .2579 1e6                .3108 1e7                .3464 1e8                .3657 2e8                .3720 3e8                .3766 My question is: Can you find a proof for this conjecture? If yes, I would be interested to write a brief note about this to a mathematical journal. References: $^{1}$ https://maths-people.anu.edu.au/~brent/pd/Kolakoski-ACCMCC.pdf $^{2}$ https://en.wikipedia.org/wiki/Hurst_exponent#Relation_to_Fractal_Dimension","The Kolakoski sequence, which is defined as the infinite sequence of symbols {1,2} that is its own run-length encoding (Wikipedia), has been suggested to be self-similar$^{1}$. The fractral dimension of a self-similar time-series is directly related to its Hurst exponent$^{2}$. I have estimated the Hurst exponent of the Kolakoski sequence for different sequence lengths, and found that the answer converges near $1 / e$ when the sequence length increases. This suggests that the fractral dimension of the Kolakoski sequence is $D=2-H = 2-1/e.$ Here is a small subset of the data sequence length    hurst exponent 1e2                .1167 1e3                .1796 1e4                .2236 1e5                .2579 1e6                .3108 1e7                .3464 1e8                .3657 2e8                .3720 3e8                .3766 My question is: Can you find a proof for this conjecture? If yes, I would be interested to write a brief note about this to a mathematical journal. References: $^{1}$ https://maths-people.anu.edu.au/~brent/pd/Kolakoski-ACCMCC.pdf $^{2}$ https://en.wikipedia.org/wiki/Hurst_exponent#Relation_to_Fractal_Dimension",,"['sequences-and-series', 'exponential-function', 'fractals', 'conjectures']"
63,Alernative way of solving summation $5+55+555+\ldots$,Alernative way of solving summation,5+55+555+\ldots,"Question Find the summation for the series-: $$5+55+555+5555+...$$ I know it is a duplicate of this , but still, I am posting this because i was thinking of solving another way due to which I got stuck in another series. My Attempt $S=5+55+555+5555....$ $2*S=10+110+1110+11110....$ $=10*(1+11+111+1111+...)$ $=\frac{10}{9}*(9+99+999+9999+...)$ $=\frac{10}{9}*((10-1)+(10^{2}-1)+(10^{3}-1)+(10^{4}-1)+...)$ $=\frac{10}{9}*(10*\frac{10^{n}-1}{10-1}-n)$ $=\frac{10}{9}*(\frac{10^{n+1}-10}{9}-n)$ $$S=\frac{5}{9}*(\frac{10^{n+1}-10}{9}-n)$$ So i think i got my answer.But i have doubt in summation of series-: $S=10+110+1110+11110....$ I got summation (from above ) as-: $=\frac{10}{9}*(\frac{10^{n+1}-10}{9}-n)$ But here , it is different .Which one is correct? I am stuck . Please help me out !","Question Find the summation for the series-: I know it is a duplicate of this , but still, I am posting this because i was thinking of solving another way due to which I got stuck in another series. My Attempt So i think i got my answer.But i have doubt in summation of series-: I got summation (from above ) as-: But here , it is different .Which one is correct? I am stuck . Please help me out !",5+55+555+5555+... S=5+55+555+5555.... 2*S=10+110+1110+11110.... =10*(1+11+111+1111+...) =\frac{10}{9}*(9+99+999+9999+...) =\frac{10}{9}*((10-1)+(10^{2}-1)+(10^{3}-1)+(10^{4}-1)+...) =\frac{10}{9}*(10*\frac{10^{n}-1}{10-1}-n) =\frac{10}{9}*(\frac{10^{n+1}-10}{9}-n) S=\frac{5}{9}*(\frac{10^{n+1}-10}{9}-n) S=10+110+1110+11110.... =\frac{10}{9}*(\frac{10^{n+1}-10}{9}-n),"['sequences-and-series', 'summation', 'arithmetic-progressions', 'geometric-progressions']"
64,$K$-functional between $\ell_1$ and $\ell_2$ for a specific sequence,-functional between  and  for a specific sequence,K \ell_1 \ell_2,"Short version: For any $n\in\mathbb{N}$, Let $$ p_n(k) \stackrel{\rm def}{=} \frac{1}{(k+1)\ln(k+1)}, \qquad 1\leq k\leq n-1 $$ and consider $$ \kappa_{p_n}(t) = \inf\{ \lVert u\rVert_1+t\lVert v\rVert_2 : u\in\ell_1, v\in\ell_2\text{ s.t. } u+v=p_n\} $$ For a fixed small constant $\varepsilon\in(0,1)$, what is the asymptotic expression (as $n\to\infty)$ of $t=t(n,\varepsilon)$ such that $$\kappa_{p_n}(t) =(1-2\varepsilon)\sum_{k=2}^n \frac{1}{k\ln k} \tag{$\dagger$} $$? Long version: Recall that for any sequence $a\in\ell_1+\ell_2$, we can defined the K-functional (between $\ell_1$ and $\ell_2)$ as the concave, non-decreasing function $\kappa_p\colon(0,\infty)\to(0,\infty)$ $$ \kappa_p(t) = \inf\{ \lVert u\rVert_1+t\lVert v\rVert_2 : u\in\ell_1, v\in\ell_2\text{ s.t. } u+v=p\} $$ (see e.g. this previous question for more properties). It is also known (for the continuous case $L_1+L_2$, but I am pretty sure the proof extends to the discrete case) that for any given $t>0$ an optimal decomposition $(u_t,v_t)$ yiedling the value $\kappa_p(t)$ is of the form (assuming wlog that $a\geq 0$) $$ v_t = \min(a, \lambda_t), \qquad u_t = a-v $$ for some threshold $\lambda_t \geq 0$. This being said, I have been repeatedly failing to find a tight enough (possibly asymptotic with regard to $n$) expression for $\kappa_{p_n}(t)$, where $(p_n)_n$ is a sequence of probability distributions defined as $$ p_n(k) \stackrel{\rm def}{=} \frac{1}{c_n}\cdot \frac{1}{(k+1)\ln(k+1)}, \qquad 1\leq k\leq n-1 $$ and $0$ for $k\geq n$; where $c_n \stackrel{\rm def}{=}\sum_{k=2}^n \frac{1}{k\ln k}$ is a normalizing constant satisfying $c_n = \ln\ln n - K+o(1)$ for some constant $K$ (which can be found, e.g., via EulerMacLaurin). More specifically, my end goal would be to find an asymptotic equivalent (or even expansion to lower order terms) to the value $t^\ast(n,\varepsilon)$ solution of the equation   $$  \kappa_{p_n}(t) = 1-2\varepsilon \tag{1} $$   where $\varepsilon \in (0,1/2)$ is to be thought of as a small constant. I tried to tackle that by (i) finding an expression or sufficiently good asymptotic expansion of $\lVert u_\lambda\rVert_1+t\lVert v_\lambda\rVert_2$ (for fixed $t$, as a function of $\lambda$), (ii) minimizing this w.r.t. $\lambda$ to find an expression (or sufficiently good asymptotic expansion) of $\kappa_{p_n}(t)$; and (iii) solve (1) approximately using the expression of (ii) in lieu of $\kappa_{p_n}(t)$. However, I was stuck at (i) for the discrete case; trying to consider the $L_1+L_2$ analog instead (continuous case) for a start, I got stuck at either (ii) or (iii) -- I am unclear which, as repeating the computations kept giving me either different results or nonsense. Any clue, idea, or suggestion on what I could do (or what the ""right"" approach and answer are)? Additional: The answer to $(\dagger)$ (and of (1)), even though not to the more general question of the asymptotic of $\kappa_{p_n}(t)$, should satisfy $$ e^{(\ln n)^{\frac{1}{2}-c'\varepsilon}} \leq \kappa_{p_n}^{-1}(1-2\varepsilon) \leq e^{(\ln n)^{\frac{1}{2}-c\varepsilon}} \tag{2} $$ where $c,c'>0$ are absolute constants; leading me to conjecture that $\kappa_{p_n}^{-1}(1-2\varepsilon) = e^{(1+o(1))(\ln n)^{\frac{1}{2}-c\varepsilon}}$ for asome absolute constant $c>0$. The reason for (2) is rather long-winded, but basically follows from a distribution testing question. [VV14] and [BCG17] both established bounds on the complexity $\Phi$ of a specific problem (""identity testing""), which for arbitrary discrete distribution $p$ and $\varepsilon \in(0,1]$ are respectively $$ \Omega\left(\frac{\lVert p^{-\max}_{-\varepsilon}\rVert_{2/3}}{\varepsilon^2}\right)\leq \Phi(p,\varepsilon) \leq O\left(\frac{\lVert p^{-\max}_{-\varepsilon/16}\rVert_{2/3}}{\varepsilon^2}\right) \tag{3} $$ and $$ \Omega\left(\frac{\kappa_{p_n}^{-1}(1-2\varepsilon)}{\varepsilon}\right)\leq \Phi(p,\varepsilon) \leq O\left(\frac{\kappa_{p_n}^{-1}(1-\frac{\varepsilon}{9})}{\varepsilon^2}\right). \tag{4} $$  Without delving into exactly what the functional $p\mapsto \lVert p^{-\max}_{-\varepsilon}\rVert_{2/3}$ in (3) is (it is the $2/3$-norm of a vector obtained from $p$), computing its asymptotics for $(p_n)_n$ is easier than that of $\kappa_{p_n}^{-1}(1-2\varepsilon)$. By doing so (assuming I didn't make a mistake in the computation), and putting together the inequalities (3) and (4), we get the inequalities from (2). [VV14] Gregory Valiant and Paul Valiant. An automatic inequality prover and instance optimal identity testing. In Proceedings of FOCS, 2014. [BCG17] Eric Blais, Clment L. Canonne, and Tom Gur. Distribution testing lower bounds via reductions from communication complexity. In IEEE Conference on Computational Complexity (CCC), 2017.","Short version: For any $n\in\mathbb{N}$, Let $$ p_n(k) \stackrel{\rm def}{=} \frac{1}{(k+1)\ln(k+1)}, \qquad 1\leq k\leq n-1 $$ and consider $$ \kappa_{p_n}(t) = \inf\{ \lVert u\rVert_1+t\lVert v\rVert_2 : u\in\ell_1, v\in\ell_2\text{ s.t. } u+v=p_n\} $$ For a fixed small constant $\varepsilon\in(0,1)$, what is the asymptotic expression (as $n\to\infty)$ of $t=t(n,\varepsilon)$ such that $$\kappa_{p_n}(t) =(1-2\varepsilon)\sum_{k=2}^n \frac{1}{k\ln k} \tag{$\dagger$} $$? Long version: Recall that for any sequence $a\in\ell_1+\ell_2$, we can defined the K-functional (between $\ell_1$ and $\ell_2)$ as the concave, non-decreasing function $\kappa_p\colon(0,\infty)\to(0,\infty)$ $$ \kappa_p(t) = \inf\{ \lVert u\rVert_1+t\lVert v\rVert_2 : u\in\ell_1, v\in\ell_2\text{ s.t. } u+v=p\} $$ (see e.g. this previous question for more properties). It is also known (for the continuous case $L_1+L_2$, but I am pretty sure the proof extends to the discrete case) that for any given $t>0$ an optimal decomposition $(u_t,v_t)$ yiedling the value $\kappa_p(t)$ is of the form (assuming wlog that $a\geq 0$) $$ v_t = \min(a, \lambda_t), \qquad u_t = a-v $$ for some threshold $\lambda_t \geq 0$. This being said, I have been repeatedly failing to find a tight enough (possibly asymptotic with regard to $n$) expression for $\kappa_{p_n}(t)$, where $(p_n)_n$ is a sequence of probability distributions defined as $$ p_n(k) \stackrel{\rm def}{=} \frac{1}{c_n}\cdot \frac{1}{(k+1)\ln(k+1)}, \qquad 1\leq k\leq n-1 $$ and $0$ for $k\geq n$; where $c_n \stackrel{\rm def}{=}\sum_{k=2}^n \frac{1}{k\ln k}$ is a normalizing constant satisfying $c_n = \ln\ln n - K+o(1)$ for some constant $K$ (which can be found, e.g., via EulerMacLaurin). More specifically, my end goal would be to find an asymptotic equivalent (or even expansion to lower order terms) to the value $t^\ast(n,\varepsilon)$ solution of the equation   $$  \kappa_{p_n}(t) = 1-2\varepsilon \tag{1} $$   where $\varepsilon \in (0,1/2)$ is to be thought of as a small constant. I tried to tackle that by (i) finding an expression or sufficiently good asymptotic expansion of $\lVert u_\lambda\rVert_1+t\lVert v_\lambda\rVert_2$ (for fixed $t$, as a function of $\lambda$), (ii) minimizing this w.r.t. $\lambda$ to find an expression (or sufficiently good asymptotic expansion) of $\kappa_{p_n}(t)$; and (iii) solve (1) approximately using the expression of (ii) in lieu of $\kappa_{p_n}(t)$. However, I was stuck at (i) for the discrete case; trying to consider the $L_1+L_2$ analog instead (continuous case) for a start, I got stuck at either (ii) or (iii) -- I am unclear which, as repeating the computations kept giving me either different results or nonsense. Any clue, idea, or suggestion on what I could do (or what the ""right"" approach and answer are)? Additional: The answer to $(\dagger)$ (and of (1)), even though not to the more general question of the asymptotic of $\kappa_{p_n}(t)$, should satisfy $$ e^{(\ln n)^{\frac{1}{2}-c'\varepsilon}} \leq \kappa_{p_n}^{-1}(1-2\varepsilon) \leq e^{(\ln n)^{\frac{1}{2}-c\varepsilon}} \tag{2} $$ where $c,c'>0$ are absolute constants; leading me to conjecture that $\kappa_{p_n}^{-1}(1-2\varepsilon) = e^{(1+o(1))(\ln n)^{\frac{1}{2}-c\varepsilon}}$ for asome absolute constant $c>0$. The reason for (2) is rather long-winded, but basically follows from a distribution testing question. [VV14] and [BCG17] both established bounds on the complexity $\Phi$ of a specific problem (""identity testing""), which for arbitrary discrete distribution $p$ and $\varepsilon \in(0,1]$ are respectively $$ \Omega\left(\frac{\lVert p^{-\max}_{-\varepsilon}\rVert_{2/3}}{\varepsilon^2}\right)\leq \Phi(p,\varepsilon) \leq O\left(\frac{\lVert p^{-\max}_{-\varepsilon/16}\rVert_{2/3}}{\varepsilon^2}\right) \tag{3} $$ and $$ \Omega\left(\frac{\kappa_{p_n}^{-1}(1-2\varepsilon)}{\varepsilon}\right)\leq \Phi(p,\varepsilon) \leq O\left(\frac{\kappa_{p_n}^{-1}(1-\frac{\varepsilon}{9})}{\varepsilon^2}\right). \tag{4} $$  Without delving into exactly what the functional $p\mapsto \lVert p^{-\max}_{-\varepsilon}\rVert_{2/3}$ in (3) is (it is the $2/3$-norm of a vector obtained from $p$), computing its asymptotics for $(p_n)_n$ is easier than that of $\kappa_{p_n}^{-1}(1-2\varepsilon)$. By doing so (assuming I didn't make a mistake in the computation), and putting together the inequalities (3) and (4), we get the inequalities from (2). [VV14] Gregory Valiant and Paul Valiant. An automatic inequality prover and instance optimal identity testing. In Proceedings of FOCS, 2014. [BCG17] Eric Blais, Clment L. Canonne, and Tom Gur. Distribution testing lower bounds via reductions from communication complexity. In IEEE Conference on Computational Complexity (CCC), 2017.",,"['sequences-and-series', 'functional-analysis', 'asymptotics']"
65,There exists infinitely many $N$ such that $\{\sum_{n=2}^N\log(n)\}<\varepsilon$,There exists infinitely many  such that,N \{\sum_{n=2}^N\log(n)\}<\varepsilon,"I am wondering whether or not the following result is true: For all $\varepsilon>0$ , there exists infinitely many $N\in \mathbb N$ such that $$S_N:=\left\{\sum_{n=2}^N\log(n)\right\}<\varepsilon$$ where $\{\cdot\}$ denote the fractional part, i.e. $\{x\}=x-[x]$ . It seems to be true, looking at these drawing of $S_N$ for $N$ up to $100$ and $1\,000$ respectively. But I really don't think $1\,000$ is enough to forge an intuition regarding the veracity of the result. I tried a comparison series-integral, to evaluation $\sum_n \log(n)$ : $$I_-=\int_2^{N-1}\log (x)\mathrm d x\leqslant \sum_{N=2}\log (n)\leqslant \int_2^{N} \log(x)\mathrm dx=I_+.$$ And we have: \begin{align*}\int_2^k \log (x) \mathrm d x&=[(-1+\log(x))x]_2^k \\ &=(-1+\log (k))k+(1-\log 2)2,\end{align*} so we can find an equivalent of both $I_-$ and $I_+$ : $$\begin{cases} I_-\underset{N\to\infty}\sim N\log N \\ I_+\underset{N\to\infty}\sim N\log N.\end{cases}$$ I then tried to find if $N\log(N)$ was equidistributed modulo $1$ , which would prove that there is infinitely many $N$ such that $$N\log N-[N\log N]<\varepsilon.$$ It seems true looking a these images for $N\log N$ modulo $1$ up to $520$ , $5\,000$ and $30\,000$ respectively: But I don't know how to prove it. We win if we show that $$\lim_{N\to\infty}\frac 1N\sum_{n=1}^N e^{2\pi i \ell n\log n}=0$$ for all $\ell\in\mathbb Z\setminus \{0\}$ by Weil's criterion, but I can't prove it. Plus, I don't think the equivalent would actually provide a proof of the result, would it? What other approach could be taken?","I am wondering whether or not the following result is true: For all , there exists infinitely many such that where denote the fractional part, i.e. . It seems to be true, looking at these drawing of for up to and respectively. But I really don't think is enough to forge an intuition regarding the veracity of the result. I tried a comparison series-integral, to evaluation : And we have: so we can find an equivalent of both and : I then tried to find if was equidistributed modulo , which would prove that there is infinitely many such that It seems true looking a these images for modulo up to , and respectively: But I don't know how to prove it. We win if we show that for all by Weil's criterion, but I can't prove it. Plus, I don't think the equivalent would actually provide a proof of the result, would it? What other approach could be taken?","\varepsilon>0 N\in \mathbb N S_N:=\left\{\sum_{n=2}^N\log(n)\right\}<\varepsilon \{\cdot\} \{x\}=x-[x] S_N N 100 1\,000 1\,000 \sum_n \log(n) I_-=\int_2^{N-1}\log (x)\mathrm d x\leqslant \sum_{N=2}\log (n)\leqslant \int_2^{N} \log(x)\mathrm dx=I_+. \begin{align*}\int_2^k \log (x) \mathrm d x&=[(-1+\log(x))x]_2^k \\ &=(-1+\log (k))k+(1-\log 2)2,\end{align*} I_- I_+ \begin{cases} I_-\underset{N\to\infty}\sim N\log N \\ I_+\underset{N\to\infty}\sim N\log N.\end{cases} N\log(N) 1 N N\log N-[N\log N]<\varepsilon. N\log N 1 520 5\,000 30\,000 \lim_{N\to\infty}\frac 1N\sum_{n=1}^N e^{2\pi i \ell n\log n}=0 \ell\in\mathbb Z\setminus \{0\}","['sequences-and-series', 'logarithms', 'conjectures', 'fractional-part']"
66,Explicit definition of a sequence,Explicit definition of a sequence,,"Suppose there are 6 sequences $a=(a_n)_{n\geq 0}, b=(b_n)_{n\geq 0},c=(c_n)_{n\geq 0},d=(d_n)_{n\geq 0},e=(e_n)_{n\geq 0},f=(f_n)_{n\geq 0}$, the data can be seen here: Data . I found out by trial and error that $a$ is defined by \begin{align} a_n=\lceil 970\cdot1.025^{n}\rceil. \end{align} It is easy to see that  \begin{align} c_n=\lceil(b_n/2)/5\rceil\cdot5, \\ d_n=\lceil(c_n/3)/5\rceil\cdot5, \\e_n=\lceil(d_n/4)/5\rceil\cdot5, \\ f_n=\lceil(e_n/5)/5\rceil\cdot5.  \end{align} I guess $b_n$ should be as well rounded to the next integer divisibly by $5$, but i do not see the explict definition. It should have something to do with $a_n$, or at least with $970$. $b$ is growing on average relativly faster than $a$ until $n\approx 40$ then slower. How can i find $b$ without trial and error? Would it be helpful to have different examples for the sequences $a$ and $b$? I mean $a'$ with $a'_0=510$ generates a sequence $b'$ with $b'_0=55$ and $a''$ with $a''_0=700$ generates a sequence $b''$ with $b''_0=70$. I can list about the first $30$ members of those sequences as well. edit: something is not right with my formulas if $f_n=0$, but it should always mean ""round to the next integer divisibly by $5$"".","Suppose there are 6 sequences $a=(a_n)_{n\geq 0}, b=(b_n)_{n\geq 0},c=(c_n)_{n\geq 0},d=(d_n)_{n\geq 0},e=(e_n)_{n\geq 0},f=(f_n)_{n\geq 0}$, the data can be seen here: Data . I found out by trial and error that $a$ is defined by \begin{align} a_n=\lceil 970\cdot1.025^{n}\rceil. \end{align} It is easy to see that  \begin{align} c_n=\lceil(b_n/2)/5\rceil\cdot5, \\ d_n=\lceil(c_n/3)/5\rceil\cdot5, \\e_n=\lceil(d_n/4)/5\rceil\cdot5, \\ f_n=\lceil(e_n/5)/5\rceil\cdot5.  \end{align} I guess $b_n$ should be as well rounded to the next integer divisibly by $5$, but i do not see the explict definition. It should have something to do with $a_n$, or at least with $970$. $b$ is growing on average relativly faster than $a$ until $n\approx 40$ then slower. How can i find $b$ without trial and error? Would it be helpful to have different examples for the sequences $a$ and $b$? I mean $a'$ with $a'_0=510$ generates a sequence $b'$ with $b'_0=55$ and $a''$ with $a''_0=700$ generates a sequence $b''$ with $b''_0=70$. I can list about the first $30$ members of those sequences as well. edit: something is not right with my formulas if $f_n=0$, but it should always mean ""round to the next integer divisibly by $5$"".",,"['sequences-and-series', 'ceiling-and-floor-functions', 'data-analysis']"
67,Show that $e^n>\frac{(n+1)^n}{n!}$ without using induction.,Show that  without using induction.,e^n>\frac{(n+1)^n}{n!},I have got an inequality problem which is as follow: Show that $e^n>\frac{(n+1)^n}{n!}$ I can do it by induction but I have been told to prove it without induction. My Work: $$e^n=1+n+\frac{n^2}{2!}+\frac{n^3}{3!}+........$$ $$e^n>1+n+\frac{n^2}{2!}+\frac{n^3}{3!}+........+\frac{n^n}{n!}$$ $$e^n>\frac{n^n}{n!}+\frac{n^{n-1}}{(n-1)!}.......+\frac{n^2}{2!}+n+1$$ From here I can't go further. I shall be thankful if you guys can provide me a complete solution/proof of this inequality. A hint will also work. Thanks in advance.,I have got an inequality problem which is as follow: Show that $e^n>\frac{(n+1)^n}{n!}$ I can do it by induction but I have been told to prove it without induction. My Work: $$e^n=1+n+\frac{n^2}{2!}+\frac{n^3}{3!}+........$$ $$e^n>1+n+\frac{n^2}{2!}+\frac{n^3}{3!}+........+\frac{n^n}{n!}$$ $$e^n>\frac{n^n}{n!}+\frac{n^{n-1}}{(n-1)!}.......+\frac{n^2}{2!}+n+1$$ From here I can't go further. I shall be thankful if you guys can provide me a complete solution/proof of this inequality. A hint will also work. Thanks in advance.,,"['inequality', 'proof-writing', 'exponential-function', 'alternative-proof']"
68,How to compute $\prod_{n=2}^{\infty} \left(1-\frac{1}{n^n}\right)$?,How to compute ?,\prod_{n=2}^{\infty} \left(1-\frac{1}{n^n}\right),Does        $$\prod_{n=2}^{\infty} \left(1-\frac{1}{n^n}\right)$$ have any closed form in terms of known mathematical constants?,Does        $$\prod_{n=2}^{\infty} \left(1-\frac{1}{n^n}\right)$$ have any closed form in terms of known mathematical constants?,,"['sequences-and-series', 'infinite-product']"
69,Proof of these identities,Proof of these identities,,"The following is a screenshot from a paper by Daniel B. Grunberg called On asymptotics, Stirling numbers, Gamma function, and polylogs . I only offer the page as a reference to explain equation 3.1.  Don't worry about the rest of the paper, though interesting. Now for some sequence $A=\{a_1, a_2, a_3,... a_n\}$ let us define the function $$f_n(s)=\sum_{k=1}^n{\frac{1}{{a_k}^s}}$$ In equation 3.1 replace the harmonic number with $f_n(s\cdot r_j)$ and remove the alternating sign to define a new function: $$Q_{r,1,n}(s)=\sum_{\{r\}}\prod_{j=1}^l\frac{(-1)^{i_j}}{i_j!}\left(\frac{f_n(s\cdot r_j)}{r_j}\right)^{i_j}$$ $Q_{0,1,n}(s)=1$. Prove the following identities.   $$\sum_{r=0}^n Q_{r,1,n}(s)=\prod_{k=1}^n\left(1-\frac{1}{{a_k}^s}\right)$$   $$Q_{n,1,n}(s)=(-1)^{n}\frac{\sum_{k=1}^n {a_k}^s}{\prod_{k=1}^n {a_k}^s}$$   $$Q_{n-1,1,n}(s)=(-1)^{n-1}\frac{1}{\prod_{k=1}^n {a_k}^s}$$ I discovered these identities, but it's been so long I can't remember how I came to them.  Some professional proof-work would be helpful. Also how would we continue such expressions of $Q_{n-k,1,n}(s)$ for $k=2,3,...,(n-1)$?","The following is a screenshot from a paper by Daniel B. Grunberg called On asymptotics, Stirling numbers, Gamma function, and polylogs . I only offer the page as a reference to explain equation 3.1.  Don't worry about the rest of the paper, though interesting. Now for some sequence $A=\{a_1, a_2, a_3,... a_n\}$ let us define the function $$f_n(s)=\sum_{k=1}^n{\frac{1}{{a_k}^s}}$$ In equation 3.1 replace the harmonic number with $f_n(s\cdot r_j)$ and remove the alternating sign to define a new function: $$Q_{r,1,n}(s)=\sum_{\{r\}}\prod_{j=1}^l\frac{(-1)^{i_j}}{i_j!}\left(\frac{f_n(s\cdot r_j)}{r_j}\right)^{i_j}$$ $Q_{0,1,n}(s)=1$. Prove the following identities.   $$\sum_{r=0}^n Q_{r,1,n}(s)=\prod_{k=1}^n\left(1-\frac{1}{{a_k}^s}\right)$$   $$Q_{n,1,n}(s)=(-1)^{n}\frac{\sum_{k=1}^n {a_k}^s}{\prod_{k=1}^n {a_k}^s}$$   $$Q_{n-1,1,n}(s)=(-1)^{n-1}\frac{1}{\prod_{k=1}^n {a_k}^s}$$ I discovered these identities, but it's been so long I can't remember how I came to them.  Some professional proof-work would be helpful. Also how would we continue such expressions of $Q_{n-k,1,n}(s)$ for $k=2,3,...,(n-1)$?",,"['sequences-and-series', 'proof-verification', 'integer-partitions']"
70,Division of a square and value of a disk,Division of a square and value of a disk,,"I cam across this problem and I really don't know how to solve it. So you start with a square that has value 1. You divide this square in 4 so that each new square has a new value, as given by the following picture : Then you divide again each square in 4 new squares by the same process, so that you obtain the following picture and data : Now put a circle inside the square : If you repeat the process of dividing each square in 4, each new square having a new value, what is the value of the disk ? I wrote a program allowing me to compute the value of the region outside the disk : I started with a square divided by $8 \times 8$ new squares and stopped at $2^{27} \times 2^{27}$. Here is the output of the algorithm giving the approximation of the value of the disk (it is 1- approximation of the region outside the disk) 9.000000000e-01 8.144000000e-01 7.626000000e-01 7.292020000e-01 7.088800000e-01 6.973523000e-01 6.918611000e-01 6.885892690e-01 6.869197714e-01 6.859950674e-01 6.855135614e-01 6.852518648e-01 6.851172864e-01 6.850433926e-01 6.850051560e-01 6.849844363e-01 6.849737746e-01 6.849678775e-01 6.849649240e-01 6.849632929e-01 6.849624579e-01 6.849620047e-01 6.849617754e-01 6.849616479e-01 6.849615847e-01 I was not able to find an explicit formula for the limit (does it exist ?). I also tried an exponential regression on the data but I was not really satisfied. Any hint ?","I cam across this problem and I really don't know how to solve it. So you start with a square that has value 1. You divide this square in 4 so that each new square has a new value, as given by the following picture : Then you divide again each square in 4 new squares by the same process, so that you obtain the following picture and data : Now put a circle inside the square : If you repeat the process of dividing each square in 4, each new square having a new value, what is the value of the disk ? I wrote a program allowing me to compute the value of the region outside the disk : I started with a square divided by $8 \times 8$ new squares and stopped at $2^{27} \times 2^{27}$. Here is the output of the algorithm giving the approximation of the value of the disk (it is 1- approximation of the region outside the disk) 9.000000000e-01 8.144000000e-01 7.626000000e-01 7.292020000e-01 7.088800000e-01 6.973523000e-01 6.918611000e-01 6.885892690e-01 6.869197714e-01 6.859950674e-01 6.855135614e-01 6.852518648e-01 6.851172864e-01 6.850433926e-01 6.850051560e-01 6.849844363e-01 6.849737746e-01 6.849678775e-01 6.849649240e-01 6.849632929e-01 6.849624579e-01 6.849620047e-01 6.849617754e-01 6.849616479e-01 6.849615847e-01 I was not able to find an explicit formula for the limit (does it exist ?). I also tried an exponential regression on the data but I was not really satisfied. Any hint ?",,"['sequences-and-series', 'geometry', 'recreational-mathematics', 'problem-solving']"
71,"Limit and rate of convergence of the sequence $a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n},~~b_{n+1}=\frac{a_n+b_n}{2}$",Limit and rate of convergence of the sequence,"a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n},~~b_{n+1}=\frac{a_n+b_n}{2}","Define the sequence the following way for some $x,y \geq 0$ : $$a_0=x,~~~~~~~b_0=y$$ $$a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n},~~~~~~b_{n+1}=\frac{a_n+b_n}{2}$$ Obviously: $$a_n \geq b_n,~~~~n \geq 1$$ For convergence rate we have: $$a_{n+1}-b_{n+1}=\frac{(a_n-b_n)^2}{2(a_n+b_n)} \tag{1}$$ We have a weak inequality: $$\frac{(a_n-b_n)^2}{2(a_n+b_n)} \leq \frac{(a_n-b_n)^2}{2(a_n-b_n)}=\frac{a_n-b_n}{2}$$ So our convergence rate is at least linear: $$\frac{a_{n+1}-b_{n+1}}{a_n-b_n} \leq \frac{1}{2} \tag{2}$$ But shouldn't $(1)$ imply faster (quadratic) convergence? (I know we need to subtract the limit to find the convergence, but I don't know the closed form, see below). Now for the limit. We have the following relations: $$a_{n+1}b_{n+1}=\frac{a_n^2+b_n^2}{2} \geq a_nb_n$$ $$a_{n+1}b_{n+1}-a_nb_n=\frac{(a_n-b_n)^2}{2}$$ Can we find the limit of this sequence in closed form? What is the true rate of convergence for this sequence?","Define the sequence the following way for some : Obviously: For convergence rate we have: We have a weak inequality: So our convergence rate is at least linear: But shouldn't imply faster (quadratic) convergence? (I know we need to subtract the limit to find the convergence, but I don't know the closed form, see below). Now for the limit. We have the following relations: Can we find the limit of this sequence in closed form? What is the true rate of convergence for this sequence?","x,y \geq 0 a_0=x,~~~~~~~b_0=y a_{n+1}=\frac{a_n^2+b_n^2}{a_n+b_n},~~~~~~b_{n+1}=\frac{a_n+b_n}{2} a_n \geq b_n,~~~~n \geq 1 a_{n+1}-b_{n+1}=\frac{(a_n-b_n)^2}{2(a_n+b_n)} \tag{1} \frac{(a_n-b_n)^2}{2(a_n+b_n)} \leq \frac{(a_n-b_n)^2}{2(a_n-b_n)}=\frac{a_n-b_n}{2} \frac{a_{n+1}-b_{n+1}}{a_n-b_n} \leq \frac{1}{2} \tag{2} (1) a_{n+1}b_{n+1}=\frac{a_n^2+b_n^2}{2} \geq a_nb_n a_{n+1}b_{n+1}-a_nb_n=\frac{(a_n-b_n)^2}{2}","['sequences-and-series', 'recurrence-relations', 'means']"
72,Show there are only a finite number of integers with $\dfrac{\prod_{i=1}^n a_i-1}{\prod_{i=1}^n (a_i-1)} $ an integer,Show there are only a finite number of integers with  an integer,\dfrac{\prod_{i=1}^n a_i-1}{\prod_{i=1}^n (a_i-1)} ,"Show, for each $n$, there are only a finite number of integral $(a_i)_{i=1}^n$ such that $2\le a_i \le a_{i+1}$ and $\dfrac{\prod_{i=1}^n a_i-1}{\prod_{i=1}^n (a_i-1)} $ is an integer. My question is inspired by this one: Prove the fractions aren't integers I can show that $a_1 \le \dfrac1{2^{1/n}-1} $. I think there is a proof by induction of the general case, but I don't have one now. A comment: This reminds me of the Egyptian fraction problem. Here's what I have now. $\begin{array}\\ r &=\dfrac{\prod_{i=1}^n (a_i-1)+\prod_{i=1}^n a_i-\prod_{i=1}^n (a_i-1)-1}{\prod_{i=1}^n (a_i-1)}\\ &=1+\dfrac{\prod_{i=1}^n a_i-\prod_{i=1}^n (a_i-1)-1}{\prod_{i=1}^n (a_i-1)}\\ &=1+\dfrac{\prod_{i=1}^n (b_i+1)-\prod_{i=1}^n b_i-1}{\prod_{i=1}^n b_i} \quad\text{where }b_i = a_i-1\\ \end{array} $ Letting $B = \prod_{i=1}^n b_i $, the fraction is, dividing the numerator and denominator  by $B$, $r-1 =s =\prod_{i=1}^n (1+1/b_i)-1-1/B $. We have $s  \gt 1+\sum_{i=1}^n 1/b_i-1-1/B =\sum_{i=1}^n 1/b_i-1/B \gt 0 $ since $b_i \le B$ and $n \ge 2$. Therefore, if $s < 1$, $r$ is not an integer. If $c_i = 1/b_i$, $s  = \prod_{i=1}^n (1+c_i)-1-\prod_{i=1}^n c_i $, so $\dfrac{ds}{dc_j} =\prod_{i=1, i\ne j}^n (1+c_i)-\prod_{i=1,i\ne j}^n c_i $, so that $s$  is an increasing function of each $c_i$ and so is a decreasing function of each $b_i$. In particular, $s \le (1+1/b_1)^n-1-1/b_1^n $, so that if $(1+1/b_1)^n-1 \le 1$, $s$ is not an integer. This is $1+1/b_1 \le 2^{1/n} $ or $b_1 \ge \dfrac1{2^{1/n}-1} $.","Show, for each $n$, there are only a finite number of integral $(a_i)_{i=1}^n$ such that $2\le a_i \le a_{i+1}$ and $\dfrac{\prod_{i=1}^n a_i-1}{\prod_{i=1}^n (a_i-1)} $ is an integer. My question is inspired by this one: Prove the fractions aren't integers I can show that $a_1 \le \dfrac1{2^{1/n}-1} $. I think there is a proof by induction of the general case, but I don't have one now. A comment: This reminds me of the Egyptian fraction problem. Here's what I have now. $\begin{array}\\ r &=\dfrac{\prod_{i=1}^n (a_i-1)+\prod_{i=1}^n a_i-\prod_{i=1}^n (a_i-1)-1}{\prod_{i=1}^n (a_i-1)}\\ &=1+\dfrac{\prod_{i=1}^n a_i-\prod_{i=1}^n (a_i-1)-1}{\prod_{i=1}^n (a_i-1)}\\ &=1+\dfrac{\prod_{i=1}^n (b_i+1)-\prod_{i=1}^n b_i-1}{\prod_{i=1}^n b_i} \quad\text{where }b_i = a_i-1\\ \end{array} $ Letting $B = \prod_{i=1}^n b_i $, the fraction is, dividing the numerator and denominator  by $B$, $r-1 =s =\prod_{i=1}^n (1+1/b_i)-1-1/B $. We have $s  \gt 1+\sum_{i=1}^n 1/b_i-1-1/B =\sum_{i=1}^n 1/b_i-1/B \gt 0 $ since $b_i \le B$ and $n \ge 2$. Therefore, if $s < 1$, $r$ is not an integer. If $c_i = 1/b_i$, $s  = \prod_{i=1}^n (1+c_i)-1-\prod_{i=1}^n c_i $, so $\dfrac{ds}{dc_j} =\prod_{i=1, i\ne j}^n (1+c_i)-\prod_{i=1,i\ne j}^n c_i $, so that $s$  is an increasing function of each $c_i$ and so is a decreasing function of each $b_i$. In particular, $s \le (1+1/b_1)^n-1-1/b_1^n $, so that if $(1+1/b_1)^n-1 \le 1$, $s$ is not an integer. This is $1+1/b_1 \le 2^{1/n} $ or $b_1 \ge \dfrac1{2^{1/n}-1} $.",,"['sequences-and-series', 'divisibility']"
73,Estimation of a sequence related to the Stirling's formula,Estimation of a sequence related to the Stirling's formula,,I need to show that $$n!=\left(\frac{n}{e}\right)^n\sqrt{2\pi n}e^{\lambda_n}$$ where $$\frac{1}{12(n+1)}<\lambda_n$$ I calculated that $$\lambda_n=\ln n!+n-n\ln n -\frac{1}{2}\ln(2\pi n)$$ On Wikipedia I found that $$(*)\quad\ln \Gamma (x+1)+x-x\ln x -\frac{1}{2}\ln(2\pi x)=\int_0^{\infty}\frac{2\arctan\left(\frac{t}{x}\right)}{e^{2\pi t}-1}dt=\sum_{n=1}^{\infty}\frac{c_n}{(x+1)^\overline{{n}}}$$ where $$c_n=\frac{1}{n}\int_0^1x^{\overline{n}}\left(x-\frac{1}{2}\right)dx$$ and $$x^{\overline{n}}=x(x+1)(x+2)\cdot\ldots\cdot(x+n-1)$$ From all this I get $$\lambda_n=\ln n!+n-n\ln n -\frac{1}{2}\ln(2\pi n)=\sum_{k=1}^{\infty}\frac{c_k}{(n+1)^{\overline{k}}}>\frac{c_1}{n+1}=\frac{1}{12(n+1)}$$ The only problem I have is that I don't know how to prove (*) equalities which I found on Wikipedia. Here's the link to Wikipedia Stirling's approximation EDIT. I made a mistake because I missed a line over n in formulas. I changes some things because now you can't compute exact formula for $c_n$.,I need to show that $$n!=\left(\frac{n}{e}\right)^n\sqrt{2\pi n}e^{\lambda_n}$$ where $$\frac{1}{12(n+1)}<\lambda_n$$ I calculated that $$\lambda_n=\ln n!+n-n\ln n -\frac{1}{2}\ln(2\pi n)$$ On Wikipedia I found that $$(*)\quad\ln \Gamma (x+1)+x-x\ln x -\frac{1}{2}\ln(2\pi x)=\int_0^{\infty}\frac{2\arctan\left(\frac{t}{x}\right)}{e^{2\pi t}-1}dt=\sum_{n=1}^{\infty}\frac{c_n}{(x+1)^\overline{{n}}}$$ where $$c_n=\frac{1}{n}\int_0^1x^{\overline{n}}\left(x-\frac{1}{2}\right)dx$$ and $$x^{\overline{n}}=x(x+1)(x+2)\cdot\ldots\cdot(x+n-1)$$ From all this I get $$\lambda_n=\ln n!+n-n\ln n -\frac{1}{2}\ln(2\pi n)=\sum_{k=1}^{\infty}\frac{c_k}{(n+1)^{\overline{k}}}>\frac{c_1}{n+1}=\frac{1}{12(n+1)}$$ The only problem I have is that I don't know how to prove (*) equalities which I found on Wikipedia. Here's the link to Wikipedia Stirling's approximation EDIT. I made a mistake because I missed a line over n in formulas. I changes some things because now you can't compute exact formula for $c_n$.,,"['real-analysis', 'sequences-and-series']"
74,A closed form for the following Series,A closed form for the following Series,,"I was computing some calculations, when I got stuck about a possible closed form for this series: $$S = \sum_{k = 2}^{N}\ \frac{k!}{k^k - k!}$$ I proved by hands that it's absolutely convergent by using the ratio test, but now I have to find something with which to approximate that series, or a closed form if it does exist. Computing the first $50$ term of the series, the result is around $$S \approx 1.454864034404(...)$$ If I try to take the limit for large $k$ (namely for large $N$), I can use Stirling approximation $$k! \approx \sqrt{2\pi k} \frac{k^k}{e^k}$$ I will obtain: $$S(\text{large}\ k) = \frac{\sqrt{2\pi k}}{e^k - \sqrt{2\pi k}}$$ Numerical evaluation ""My"" alternative form seems good because even for $k = 5$ I got these: $$ \begin{cases} \frac{5!}{5^5 - 5!} & \approx 0.03993 \\\\ \frac{\sqrt{2\pi 5}}{e^5 - \sqrt{2\pi 5}} & \approx 0.03924 \end{cases} $$ Anyway: is there a way to obtain a closed form for a general $N$? I also tried with mathematica but it doesn't work.","I was computing some calculations, when I got stuck about a possible closed form for this series: $$S = \sum_{k = 2}^{N}\ \frac{k!}{k^k - k!}$$ I proved by hands that it's absolutely convergent by using the ratio test, but now I have to find something with which to approximate that series, or a closed form if it does exist. Computing the first $50$ term of the series, the result is around $$S \approx 1.454864034404(...)$$ If I try to take the limit for large $k$ (namely for large $N$), I can use Stirling approximation $$k! \approx \sqrt{2\pi k} \frac{k^k}{e^k}$$ I will obtain: $$S(\text{large}\ k) = \frac{\sqrt{2\pi k}}{e^k - \sqrt{2\pi k}}$$ Numerical evaluation ""My"" alternative form seems good because even for $k = 5$ I got these: $$ \begin{cases} \frac{5!}{5^5 - 5!} & \approx 0.03993 \\\\ \frac{\sqrt{2\pi 5}}{e^5 - \sqrt{2\pi 5}} & \approx 0.03924 \end{cases} $$ Anyway: is there a way to obtain a closed form for a general $N$? I also tried with mathematica but it doesn't work.",,"['sequences-and-series', 'convergence-divergence', 'summation', 'power-series']"
75,ELI5: What are pointwise and uniform convergence and what is the difference?,ELI5: What are pointwise and uniform convergence and what is the difference?,,"I have been fiddling around with some series of functions and analyzing whether they converge pointwise or uniformly. Furthermore I know that continuity and convergence of integrals does not always follow from pointwise but for uniform convergence as seen in a counterexample (of a non-uniform convergence) for $f_n:[0,1]\to\mathbb R$ with $$f_n(x)=\begin{cases}n^2x, &0\leq x\leq \frac1n,\\2n-n^2x, &\frac1n<x\leq \frac2n,\\ 0, &x>\frac2n,\end{cases}$$ which yields $\lim_{n\to\infty}f_n(x)=0$ for all $x\in[0,1]$ but $\int_0^1f_n(x)~\mathrm dx=1\neq 0$. I am having trouble finding a decent informal explanation (not just applying the definitions to test for convergence) of both terms other than referring to the ""speed of convergence"" which is different in both cases. ELI5: What are pointwise and uniform convergence and what is the difference?","I have been fiddling around with some series of functions and analyzing whether they converge pointwise or uniformly. Furthermore I know that continuity and convergence of integrals does not always follow from pointwise but for uniform convergence as seen in a counterexample (of a non-uniform convergence) for $f_n:[0,1]\to\mathbb R$ with $$f_n(x)=\begin{cases}n^2x, &0\leq x\leq \frac1n,\\2n-n^2x, &\frac1n<x\leq \frac2n,\\ 0, &x>\frac2n,\end{cases}$$ which yields $\lim_{n\to\infty}f_n(x)=0$ for all $x\in[0,1]$ but $\int_0^1f_n(x)~\mathrm dx=1\neq 0$. I am having trouble finding a decent informal explanation (not just applying the definitions to test for convergence) of both terms other than referring to the ""speed of convergence"" which is different in both cases. ELI5: What are pointwise and uniform convergence and what is the difference?",,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'education', 'uniform-convergence']"
76,"Limit superior, limit inferior and a series involging $\sum_{k\nmid n}$k, where $1\leq k\leq n$","Limit superior, limit inferior and a series involging k, where",\sum_{k\nmid n} 1\leq k\leq n,"The purpose of this post is state assertions by the use of statements and hypothesis in an expository way and after I am asking for reasonable unconditionally results that you can provide us. Using Gronwall's theorem (see for example [1]), the inequality derived for arithmetic and geometric means, we obtain without an use of Riemann hypothesis $$\limsup_{n\to \infty}\frac{(n!)^{1/n}}{n\log\log n}\leq e^{\gamma}+\limsup_{n\to \infty}\frac{\delta(n)}{n\log\log n}$$ where $\delta (n)$ is defined as the sum of integers $k$, $1\leq k\leq n$ such that $k\nmid n$; by Gauss statement $\sum_{k=1}^n k=\frac{n(n+1)}{2}$, this arithmetic function $$\delta(n)=\frac{n(n+1)}{2}-\sigma(n)$$ which isn't multiplicative since $\delta(1)=0\neq 1$, and $\gamma$ is the Euler's contant. In the other hand by Gauss statement and Gronwall we compute $$\infty\leq e^\gamma+\limsup_{n\to \infty}\frac{\delta(n)}{n\log\log n}$$ Thus I believe that there no exists this $\limsup$. Too, I know that for positive quantities $\liminf\leq \limsup$, and $\sigma(n)>n$ implies by Gauss $\delta(n)\geq \frac{(n+1)(n-2)}{2}$. The purpose of following question is refresh notions on $\limsup$ and $\liminf$ and try compute the best unconditionally statements possible, you can use Robin and Erds refined statements (see [1]) Question. Can you compute unconditionally or give bounds to $\limsup$ and $\liminf$ in these cases: a) same cited case for $\delta(n)/(n\log\log n)$ and b) same question but you scales previous quotient as $n^{\alpha}(\log\log  n)^\beta$, where $\alpha,\beta$ are the constants/functions that you desired/needs. c)(Optional question). If you can/want use Riemann hypothesis to give some statement about $\limsup,\liminf$ they are welcome. Using Robin's statement for Riemann hypothesis (see [1]) and Gauss, thus now I use the hypothesis here, it is easy to prove $$C:=\sum_{n=5041}^\infty\frac{1}{\delta(n)+e^\gamma n\log\log n}<2\sum_{n=5041}^{\infty}\frac{1}{n(n+1)}$$ which is convergent since Leibnitz said that $\sum (\frac{1}{n}-\frac{1}{n+1})$ is telescoping to first term of the sum. Question . a)Can you give the best unconditionally behaviour of previous series involving $\delta (n)$. b) (Optional question involving a computational experiment). Compute an approximation to constant $C$, with a computer. I don't know if previous exercises are in literature, yet. Thanks in advance, my goal is learn and y to encourage people, with these easy facts and computations. Of course my power is not solves, but yes learn. References: [1] http://mathworld.wolfram.com/DivisorFunction.html","The purpose of this post is state assertions by the use of statements and hypothesis in an expository way and after I am asking for reasonable unconditionally results that you can provide us. Using Gronwall's theorem (see for example [1]), the inequality derived for arithmetic and geometric means, we obtain without an use of Riemann hypothesis $$\limsup_{n\to \infty}\frac{(n!)^{1/n}}{n\log\log n}\leq e^{\gamma}+\limsup_{n\to \infty}\frac{\delta(n)}{n\log\log n}$$ where $\delta (n)$ is defined as the sum of integers $k$, $1\leq k\leq n$ such that $k\nmid n$; by Gauss statement $\sum_{k=1}^n k=\frac{n(n+1)}{2}$, this arithmetic function $$\delta(n)=\frac{n(n+1)}{2}-\sigma(n)$$ which isn't multiplicative since $\delta(1)=0\neq 1$, and $\gamma$ is the Euler's contant. In the other hand by Gauss statement and Gronwall we compute $$\infty\leq e^\gamma+\limsup_{n\to \infty}\frac{\delta(n)}{n\log\log n}$$ Thus I believe that there no exists this $\limsup$. Too, I know that for positive quantities $\liminf\leq \limsup$, and $\sigma(n)>n$ implies by Gauss $\delta(n)\geq \frac{(n+1)(n-2)}{2}$. The purpose of following question is refresh notions on $\limsup$ and $\liminf$ and try compute the best unconditionally statements possible, you can use Robin and Erds refined statements (see [1]) Question. Can you compute unconditionally or give bounds to $\limsup$ and $\liminf$ in these cases: a) same cited case for $\delta(n)/(n\log\log n)$ and b) same question but you scales previous quotient as $n^{\alpha}(\log\log  n)^\beta$, where $\alpha,\beta$ are the constants/functions that you desired/needs. c)(Optional question). If you can/want use Riemann hypothesis to give some statement about $\limsup,\liminf$ they are welcome. Using Robin's statement for Riemann hypothesis (see [1]) and Gauss, thus now I use the hypothesis here, it is easy to prove $$C:=\sum_{n=5041}^\infty\frac{1}{\delta(n)+e^\gamma n\log\log n}<2\sum_{n=5041}^{\infty}\frac{1}{n(n+1)}$$ which is convergent since Leibnitz said that $\sum (\frac{1}{n}-\frac{1}{n+1})$ is telescoping to first term of the sum. Question . a)Can you give the best unconditionally behaviour of previous series involving $\delta (n)$. b) (Optional question involving a computational experiment). Compute an approximation to constant $C$, with a computer. I don't know if previous exercises are in literature, yet. Thanks in advance, my goal is learn and y to encourage people, with these easy facts and computations. Of course my power is not solves, but yes learn. References: [1] http://mathworld.wolfram.com/DivisorFunction.html",,"['sequences-and-series', 'limsup-and-liminf']"
77,Is there a closed-form approximation to a band-limited sawtooth?,Is there a closed-form approximation to a band-limited sawtooth?,,"A partial Fourier Series with no coefficients is equal to the closed form expression: $${A \over n} \sum_{k=1}^n \cos(k\theta) = {A \over 2n} \left\{{\sin([2n + 1]\theta/2) \over \sin(\theta/2)} - 1\right\}$$ The sum of the harmonic series does not have a closed form expression, but can be approximated with the formula: $$H_n = \sum_{k=1}^n h_k = \sum_{k=1}^n \frac1k = \ln n + \gamma  +\frac1{2n} -\frac1{12n^2} + \frac1{120n^4} + ... $$ This can be done with varying accuracy, depending on how many terms are used in the approximation. A band-limited sawtooth is a partial Fourier Series with harmonic coefficients.  Given that the two parts of its Fourier series have approximations to n terms, does a band-limited sawtooth also have an approximation to n terms? Observation #1 Related might be the harmonic generating function, which is: $$\sum_{k=1}^\infty z^k H_k = {-\ln(1 - z) \over 1 - z}$$ If expressed as a partial sum, it could be used in summation by parts. $$\sum_{k=1}^n h_k \cos(k\theta) = \sum_{k=1}^n h_k {1\over 2}(e^{ik\theta} + e^{-ik\theta}) = {1 \over 2} \sum_{k=1}^n h_k e^{ik\theta} + {1 \over 2} \sum_{k=1}^n h_k e^{-ik\theta}$$ $$\sum_{k=1}^n h_k e^{ik\theta} = H_n e^{in\theta} - \sum_{k=1}^{n-1} H_k e^{i(k+1)\theta} + \sum_{k=1}^{n-1} H_k e^{ik\theta}$$ The latter two terms being the partial sums.  However, I can't find a partial sum of the generating function anywhere. Observation #2 Also related is the following: $$\sum_{k=1}^n H_k = (n + 1)H_n - n$$ Which could be used to further break up the problem through summation by parts: $$\sum_{k=1}^{n-1} H_k e^{ik\theta} = ( nH_{n-1} - n + 1)e^{i(n-1)\theta} - \sum_{j=1}^{n-2}((j + 1)H_j - j)e^{i(j+1)\theta} + \sum_{j=1}^{n-2}((j + 1)H_j - j)e^{ij\theta}$$ If I kept using summation by parts this way, I'd eventually get to a point where I could stop and ignore the new summations... right? If I were to stop here, I would get: $$nH_n\cos((n-1)\theta) - n\cos((n-1)\theta) + nH_n\cos(n\theta) - n\cos(n\theta) + H_n\cos(n\theta)$$ Or: $$(nH_n - n) * \left\{\cos([n-1]\theta) + \cos(n\theta)\right\} + H_n\cos(n\theta)$$ Graphing this does not give me a sawtooth wave, it gives me two sinusoids added together.  What this method seems to do is approximate the sawtooth with more partials each time I break up the summation, from N to 1, which has no benefit over just evaluating the Fourier Series. Observation #3 The Dirichlet Series is one way of expressing the sawtooth: $$\sum_{k=1}^\infty {a_k \over k^s}, a_k = cos(k\theta)$$ This doesn't seem to have a partial sum either. Observation #4 The Maclaurin Series for $\cos(\theta)$ is: $$\sum_{k=0}^\infty {(-1)^k \over (2k)!} \theta^{2k}$$ Each term of the Fourier Series could be represented as a Maclaurin Series. $$\sum_{k=1}^{n} h_k \cos(k\theta) = \sum_{k=1}^{n} h_k \sum_{j=0}^\infty {(-1)^j \over (2j)!} (k\theta)^{2j} = \sum_{k=1}^{n} {1 \over k} \sum_{j=0}^\infty {(-1)^j \over (2j)!} (k\theta)^{2j} = \sum_{k=1}^{n} \sum_{j=0}^\infty {(-1)^j \over (2j)! * k} (k\theta)^{2j}$$ But I'm not entirely sure where to go from there. Wolfram Alpha Well, I don't know why I didn't think of doing this before, but wolfram alpha can actually answer this, somewhat. Now if I can figure out the Lerch Transcendent... EDIT: The lerch transcendent in that equation is equivalent to the lerch-zeta function $ L(t, 1, N + 2) $, where $ t $ is the time variable.  Also, this exists.","A partial Fourier Series with no coefficients is equal to the closed form expression: $${A \over n} \sum_{k=1}^n \cos(k\theta) = {A \over 2n} \left\{{\sin([2n + 1]\theta/2) \over \sin(\theta/2)} - 1\right\}$$ The sum of the harmonic series does not have a closed form expression, but can be approximated with the formula: $$H_n = \sum_{k=1}^n h_k = \sum_{k=1}^n \frac1k = \ln n + \gamma  +\frac1{2n} -\frac1{12n^2} + \frac1{120n^4} + ... $$ This can be done with varying accuracy, depending on how many terms are used in the approximation. A band-limited sawtooth is a partial Fourier Series with harmonic coefficients.  Given that the two parts of its Fourier series have approximations to n terms, does a band-limited sawtooth also have an approximation to n terms? Observation #1 Related might be the harmonic generating function, which is: $$\sum_{k=1}^\infty z^k H_k = {-\ln(1 - z) \over 1 - z}$$ If expressed as a partial sum, it could be used in summation by parts. $$\sum_{k=1}^n h_k \cos(k\theta) = \sum_{k=1}^n h_k {1\over 2}(e^{ik\theta} + e^{-ik\theta}) = {1 \over 2} \sum_{k=1}^n h_k e^{ik\theta} + {1 \over 2} \sum_{k=1}^n h_k e^{-ik\theta}$$ $$\sum_{k=1}^n h_k e^{ik\theta} = H_n e^{in\theta} - \sum_{k=1}^{n-1} H_k e^{i(k+1)\theta} + \sum_{k=1}^{n-1} H_k e^{ik\theta}$$ The latter two terms being the partial sums.  However, I can't find a partial sum of the generating function anywhere. Observation #2 Also related is the following: $$\sum_{k=1}^n H_k = (n + 1)H_n - n$$ Which could be used to further break up the problem through summation by parts: $$\sum_{k=1}^{n-1} H_k e^{ik\theta} = ( nH_{n-1} - n + 1)e^{i(n-1)\theta} - \sum_{j=1}^{n-2}((j + 1)H_j - j)e^{i(j+1)\theta} + \sum_{j=1}^{n-2}((j + 1)H_j - j)e^{ij\theta}$$ If I kept using summation by parts this way, I'd eventually get to a point where I could stop and ignore the new summations... right? If I were to stop here, I would get: $$nH_n\cos((n-1)\theta) - n\cos((n-1)\theta) + nH_n\cos(n\theta) - n\cos(n\theta) + H_n\cos(n\theta)$$ Or: $$(nH_n - n) * \left\{\cos([n-1]\theta) + \cos(n\theta)\right\} + H_n\cos(n\theta)$$ Graphing this does not give me a sawtooth wave, it gives me two sinusoids added together.  What this method seems to do is approximate the sawtooth with more partials each time I break up the summation, from N to 1, which has no benefit over just evaluating the Fourier Series. Observation #3 The Dirichlet Series is one way of expressing the sawtooth: $$\sum_{k=1}^\infty {a_k \over k^s}, a_k = cos(k\theta)$$ This doesn't seem to have a partial sum either. Observation #4 The Maclaurin Series for $\cos(\theta)$ is: $$\sum_{k=0}^\infty {(-1)^k \over (2k)!} \theta^{2k}$$ Each term of the Fourier Series could be represented as a Maclaurin Series. $$\sum_{k=1}^{n} h_k \cos(k\theta) = \sum_{k=1}^{n} h_k \sum_{j=0}^\infty {(-1)^j \over (2j)!} (k\theta)^{2j} = \sum_{k=1}^{n} {1 \over k} \sum_{j=0}^\infty {(-1)^j \over (2j)!} (k\theta)^{2j} = \sum_{k=1}^{n} \sum_{j=0}^\infty {(-1)^j \over (2j)! * k} (k\theta)^{2j}$$ But I'm not entirely sure where to go from there. Wolfram Alpha Well, I don't know why I didn't think of doing this before, but wolfram alpha can actually answer this, somewhat. Now if I can figure out the Lerch Transcendent... EDIT: The lerch transcendent in that equation is equivalent to the lerch-zeta function $ L(t, 1, N + 2) $, where $ t $ is the time variable.  Also, this exists.",,"['sequences-and-series', 'fourier-series', 'signal-processing', 'harmonic-numbers']"
78,Long polynomial expansion with 34 roots,Long polynomial expansion with 34 roots,,"This is a very tricky problem, I just need a few hints. I think the $(-x^{17})$ is also there for a specific trick. In the end if it is $ax^{17}$, I see that $a = 17 - 1 + 1 = 17$. Also, another possible approach is: $$(1 + x + \cdots + x^{17})^2 = x^{17}$$ $$1 + x + \cdots + x^{17} = x^{17/2}$$ But that doesn't do much. Only hints please! UPDATE: $$P(x)=0\implies x\ne 1.$$ By the geometric series formula this changes to: $$\left(\sum_{n=0}^{17}  x^n \right)^2 = x^{17} \text{ where } |x| < 1.$$ $$ \left( \frac{1 - x^{18}}{1-x}  \right)^2 = x^{17}.$$ $$(1 - x^{18})^2 = (1-x)^2(x^{17}) = x^{19} - 2x^{18} + x^{17}.$$ $$x^{36} - 2x^{18} + 1 = x^{19} - 2x^{18} + x^{17}.$$ $$x^{36} - x^{19} - x^{17} + 1 = 0.$$ $$x^{19}(x^{17} - 1) - (x^{17} - 1) = 0.$$ $$(x^{19} - 1)(x^{17} - 1) = 0.$$ With zero prod. property, we have to use roots of unity. $$x^{19} = 1 = e^{2\pi i*k}.$$ $$1\ne x = e^{2\pi i \cdot k/19}.$$ $$1\ne x = e^{2\pi i \cdot k/17} \space \text{for the other case}.$$ the smallest root obviously is $a_1 = 1/19, a_2 = 1/17, a_3 = 2/19, a_4 = 2/17, a_5 = 3/19$. $$\sum a_k = \frac{6}{19} + \frac{3}{17} = \frac{102 + 57}{323} = \frac{159}{323} = \frac{m}{n}$$ $m + n = 482$.","This is a very tricky problem, I just need a few hints. I think the $(-x^{17})$ is also there for a specific trick. In the end if it is $ax^{17}$, I see that $a = 17 - 1 + 1 = 17$. Also, another possible approach is: $$(1 + x + \cdots + x^{17})^2 = x^{17}$$ $$1 + x + \cdots + x^{17} = x^{17/2}$$ But that doesn't do much. Only hints please! UPDATE: $$P(x)=0\implies x\ne 1.$$ By the geometric series formula this changes to: $$\left(\sum_{n=0}^{17}  x^n \right)^2 = x^{17} \text{ where } |x| < 1.$$ $$ \left( \frac{1 - x^{18}}{1-x}  \right)^2 = x^{17}.$$ $$(1 - x^{18})^2 = (1-x)^2(x^{17}) = x^{19} - 2x^{18} + x^{17}.$$ $$x^{36} - 2x^{18} + 1 = x^{19} - 2x^{18} + x^{17}.$$ $$x^{36} - x^{19} - x^{17} + 1 = 0.$$ $$x^{19}(x^{17} - 1) - (x^{17} - 1) = 0.$$ $$(x^{19} - 1)(x^{17} - 1) = 0.$$ With zero prod. property, we have to use roots of unity. $$x^{19} = 1 = e^{2\pi i*k}.$$ $$1\ne x = e^{2\pi i \cdot k/19}.$$ $$1\ne x = e^{2\pi i \cdot k/17} \space \text{for the other case}.$$ the smallest root obviously is $a_1 = 1/19, a_2 = 1/17, a_3 = 2/19, a_4 = 2/17, a_5 = 3/19$. $$\sum a_k = \frac{6}{19} + \frac{3}{17} = \frac{102 + 57}{323} = \frac{159}{323} = \frac{m}{n}$$ $m + n = 482$.",,"['sequences-and-series', 'complex-analysis', 'algebra-precalculus', 'complex-numbers', 'contest-math']"
79,Calculating the convex conjugate of the function $f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right)$.,Calculating the convex conjugate of the function .,f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right),"The convex conjugate also known as LegendreFenchel transformation of a convex function $f:\mathbb{R}\to\mathbb{R}\cup\{+\infty\}$ is function $f^\ast:\mathbb{R}\to\mathbb{R}\cup\{+\infty\}$ definite by  $$ f^{\ast}(x^\ast)=\sup_{x\in\mathbb{R}}\{ x\cdot x^\ast -f(x)\} $$ Let $\{a_k\}_{n\in\mathbb{N}}$ and $\{b_k\}_{n\in\mathbb{N}}$ numerical sequences such that $\sum_{k=1}^\infty e^{a_k\cdot x+b_k}<\infty$. Let the function $ f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right). $ By a simple calculations and by Holder's inequality we prove that $f(x)$ is convex. Then Legendre-Fenchel transformation is well defined. Question. What is the convex conjugate of the function $f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right)$? A more explicit way, I would calculate the supremum below \begin{align} f^{\ast}(x^\ast) = & \sup_{x\in\mathbb{R}} \left\{ x\cdot x^\ast + \lim_{n\to \infty}\left(\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right) \right\}. \\ \end{align}","The convex conjugate also known as LegendreFenchel transformation of a convex function $f:\mathbb{R}\to\mathbb{R}\cup\{+\infty\}$ is function $f^\ast:\mathbb{R}\to\mathbb{R}\cup\{+\infty\}$ definite by  $$ f^{\ast}(x^\ast)=\sup_{x\in\mathbb{R}}\{ x\cdot x^\ast -f(x)\} $$ Let $\{a_k\}_{n\in\mathbb{N}}$ and $\{b_k\}_{n\in\mathbb{N}}$ numerical sequences such that $\sum_{k=1}^\infty e^{a_k\cdot x+b_k}<\infty$. Let the function $ f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right). $ By a simple calculations and by Holder's inequality we prove that $f(x)$ is convex. Then Legendre-Fenchel transformation is well defined. Question. What is the convex conjugate of the function $f(x)=\lim_{n\to \infty}\left(-\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right)$? A more explicit way, I would calculate the supremum below \begin{align} f^{\ast}(x^\ast) = & \sup_{x\in\mathbb{R}} \left\{ x\cdot x^\ast + \lim_{n\to \infty}\left(\frac{1}{n}\log \sum_{k=1}^n e^{a_k\cdot x+b_k}\right) \right\}. \\ \end{align}",,"['real-analysis', 'sequences-and-series', 'convex-analysis', 'supremum-and-infimum']"
80,Positivity of alternating series,Positivity of alternating series,,Let $\{a_n\}_{n=0}^{\infty}$ be a sequence of positive real numbers such that $\limsup_n \frac{1}{n}\log a_n=-\infty$. Then $$ 	f(x)=\sum_{n\geq 0}a_n x^n $$ converges absolutely for all $x$. Under what conditions on $\{a_n\}$ will we have $f(x)\geq 0$ for all $x\leq 0$?,Let $\{a_n\}_{n=0}^{\infty}$ be a sequence of positive real numbers such that $\limsup_n \frac{1}{n}\log a_n=-\infty$. Then $$ 	f(x)=\sum_{n\geq 0}a_n x^n $$ converges absolutely for all $x$. Under what conditions on $\{a_n\}$ will we have $f(x)\geq 0$ for all $x\leq 0$?,,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
81,Number of squarefree numbers and the Basel problem,Number of squarefree numbers and the Basel problem,,"Who discovered/proved that there are about $$ \frac{x}{\zeta(2)} $$ squarefree numbers up to $x$, or (roughly) when was this first known? Today I think this is considered 'obvious', but I don't know if that was always the case. Was this known before the Basel problem was solved (showing that the sum is $\pi^2/6$)? Perhaps it was known in the form $$ x\cdot \prod_{n\ge2}\left(1+\frac{\mu(n)}{n^2}\right) $$ ?","Who discovered/proved that there are about $$ \frac{x}{\zeta(2)} $$ squarefree numbers up to $x$, or (roughly) when was this first known? Today I think this is considered 'obvious', but I don't know if that was always the case. Was this known before the Basel problem was solved (showing that the sum is $\pi^2/6$)? Perhaps it was known in the form $$ x\cdot \prod_{n\ge2}\left(1+\frac{\mu(n)}{n^2}\right) $$ ?",,"['sequences-and-series', 'number-theory', 'reference-request', 'prime-numbers', 'math-history']"
82,Sums like $\sum_{n=0}^{\infty}\frac{1}{a^{n}+b^{n}}$?,Sums like ?,\sum_{n=0}^{\infty}\frac{1}{a^{n}+b^{n}},"Is there a trick for calculating sums like $$ S(a,b) := \sum_{n=0}^{\infty}\frac{1}{a^{n}+b^{n}} $$ where $a$ and $b$ are constants? I've run through my usual bag of tricks: reducing it to a series I already know, telescoping, realizing the sum as a Taylor series, plugging sample answers into RIES, and even some snazzy calculus tricks. Like, I figured out that $$ \int_{a=1}^\infty \int_{b=1}^\infty \frac{S(a,b)}{ab} \ da\ db = \frac {\pi^2}{6}\log4$$ but I feel no closer to an answer. (EDIT: to be clear, I know how to get the integral above. I want to find the sum $S(a,b)$. The integral is just something I tried that doesn't seem to help.) And googling ""series of reciprocals of sums of powers"" works about as well as you'd expect.","Is there a trick for calculating sums like $$ S(a,b) := \sum_{n=0}^{\infty}\frac{1}{a^{n}+b^{n}} $$ where $a$ and $b$ are constants? I've run through my usual bag of tricks: reducing it to a series I already know, telescoping, realizing the sum as a Taylor series, plugging sample answers into RIES, and even some snazzy calculus tricks. Like, I figured out that $$ \int_{a=1}^\infty \int_{b=1}^\infty \frac{S(a,b)}{ab} \ da\ db = \frac {\pi^2}{6}\log4$$ but I feel no closer to an answer. (EDIT: to be clear, I know how to get the integral above. I want to find the sum $S(a,b)$. The integral is just something I tried that doesn't seem to help.) And googling ""series of reciprocals of sums of powers"" works about as well as you'd expect.",,['sequences-and-series']
83,About a sequence related with the complete elliptic integral of the second kind,About a sequence related with the complete elliptic integral of the second kind,,"When answering this related question I proved that if we define $B(\lambda)$ as: $$\begin{eqnarray*} B(\lambda)&=&\frac{1}{2\pi}\int_{0}^{2\pi}\sqrt{\lambda^2+1-2\lambda\cos\theta}\,d\theta=\sum_{n\geq 0}\left(\frac{\binom{2n}{n}}{(2n-1)\,4^n}\right)^2\lambda^{2n}\\&=&\phantom{}_2 F_1\left(-\frac{1}{2},-\frac{1}{2};1;\lambda^2\right)\end{eqnarray*}$$ we have: $$ \int_{0}^{1} \lambda\,B(\lambda)\,d\lambda = \frac{16}{9\pi} $$ since $B(\lambda)$ satisfies the ODE: $$ \lambda\, B = (\lambda^2+1)B'+(\lambda-\lambda^3)B''.$$ With the same technique it is not difficult to prove that, if we define $A_k$ as: $$ A_k = \int_{0}^{1}x^{2k+1}\,B(x)\,dx $$ we have $A_0=\frac{16}{9\pi}$ and: $$ (2k+3)^2\,A_k = \frac{16}{\pi}+(2k)^2\,A_{k-1}. \tag{0}$$ Now the question. Is it possible to give a nice closed form to $A_k$, given $(0)$? $A_k$ appears to be related with a partial sum of the series converging to the Catalan constant, namely: $$\frac{1}{2\pi}\sum_{j=0}^{k+1}\frac{(-1)^j}{(2j+1)^2}.$$ From the recurrence relation it follows that: $$ A_k = \frac{16}{\pi(2k+3)^2}+\frac{16}{\pi}\left(\frac{(2k)!!}{(2k+3)!!}\right)^2\sum_{j=1}^{k}\left(\frac{(2k+3-2j)!!}{(2k-2j)!!}\right)^2$$ or: $$ A_k = \frac{16}{\pi(2k+3)^2}+\frac{16}{\pi}\left(\frac{(2k)!!}{(2k+3)!!}\right)^2\sum_{j=1}^{k}\left(\frac{(2j+1)!}{2^{2j-1}(j-1)! j!}\right)^2.$$ Update: By robjohn's argument shown here , we also have: $$ A_k = \frac{1}{\pi}\int_{0}^{\pi/2}\int_{-\cos\theta}^{\cos\theta}(\rho+\cos\theta)^2(\rho^2+\sin^2\theta)^k\,d\rho\,d\theta$$ or: $$ A_k = \frac{2}{\pi}\int_{0}^{\pi/2}\int_{0}^{\cos\theta}(\rho^2+\cos^2\theta)(\rho^2+\sin^2\theta)^k\,d\rho\,d\theta.$$","When answering this related question I proved that if we define $B(\lambda)$ as: $$\begin{eqnarray*} B(\lambda)&=&\frac{1}{2\pi}\int_{0}^{2\pi}\sqrt{\lambda^2+1-2\lambda\cos\theta}\,d\theta=\sum_{n\geq 0}\left(\frac{\binom{2n}{n}}{(2n-1)\,4^n}\right)^2\lambda^{2n}\\&=&\phantom{}_2 F_1\left(-\frac{1}{2},-\frac{1}{2};1;\lambda^2\right)\end{eqnarray*}$$ we have: $$ \int_{0}^{1} \lambda\,B(\lambda)\,d\lambda = \frac{16}{9\pi} $$ since $B(\lambda)$ satisfies the ODE: $$ \lambda\, B = (\lambda^2+1)B'+(\lambda-\lambda^3)B''.$$ With the same technique it is not difficult to prove that, if we define $A_k$ as: $$ A_k = \int_{0}^{1}x^{2k+1}\,B(x)\,dx $$ we have $A_0=\frac{16}{9\pi}$ and: $$ (2k+3)^2\,A_k = \frac{16}{\pi}+(2k)^2\,A_{k-1}. \tag{0}$$ Now the question. Is it possible to give a nice closed form to $A_k$, given $(0)$? $A_k$ appears to be related with a partial sum of the series converging to the Catalan constant, namely: $$\frac{1}{2\pi}\sum_{j=0}^{k+1}\frac{(-1)^j}{(2j+1)^2}.$$ From the recurrence relation it follows that: $$ A_k = \frac{16}{\pi(2k+3)^2}+\frac{16}{\pi}\left(\frac{(2k)!!}{(2k+3)!!}\right)^2\sum_{j=1}^{k}\left(\frac{(2k+3-2j)!!}{(2k-2j)!!}\right)^2$$ or: $$ A_k = \frac{16}{\pi(2k+3)^2}+\frac{16}{\pi}\left(\frac{(2k)!!}{(2k+3)!!}\right)^2\sum_{j=1}^{k}\left(\frac{(2j+1)!}{2^{2j-1}(j-1)! j!}\right)^2.$$ Update: By robjohn's argument shown here , we also have: $$ A_k = \frac{1}{\pi}\int_{0}^{\pi/2}\int_{-\cos\theta}^{\cos\theta}(\rho+\cos\theta)^2(\rho^2+\sin^2\theta)^k\,d\rho\,d\theta$$ or: $$ A_k = \frac{2}{\pi}\int_{0}^{\pi/2}\int_{0}^{\cos\theta}(\rho^2+\cos^2\theta)(\rho^2+\sin^2\theta)^k\,d\rho\,d\theta.$$",,"['sequences-and-series', 'special-functions', 'elliptic-integrals']"
84,Proving not equicontinuity in $\Bbb R$ but equicontinuity in any other closed subset of $\Bbb R$,Proving not equicontinuity in  but equicontinuity in any other closed subset of,\Bbb R \Bbb R,"Let $F = {f_{n} | n \Bbb N }$ be an infinite collection of functions $f_{n}(x)=e^{n(xn)^2} , x  \Bbb R$. Prove that $F$ is not equicontinuous on $\Bbb R$ but equicontinuous on $[a, a]$ for any $a > 0$. I am trying a modified proof (Initially I posted a proof but didn't reach any conclusions): First proving not equicontinuous on $\Bbb R$, $f_{n}(x)=e^{n(xn)^2}$ Let $\epsilon =1/2$. let $x=n$ Then, for $|n-y|<\delta$ , we have $|f_{n}(n)-f_{n}(y)|$=$|1-e^{-n(y-n)^2}|\leq 1$. For $n$ large enough, $|f_{n}(n)-f_{n}(y)|=1>\epsilon$ . So $f_{n}$ is not equicontinuous on $\Bbb R$. Now proving equicontinuous on $[-a,a], a>0$, Here lets use the fact that on a compact set, if $f_{n}$ is continuous and if $f_{n}$ converges uniformly on the compact set, then it is equicontinuous on the compact set. So lets prove that $f_{n}$ converges uniformly on $[-a,a]$. To do this lets first look at the following: Given an interval $[-a,a]$ and  any $\epsilon>0$. The pointwise limit of $f_{n}$ is $0$. Now, what I need to show for uniform convergence is the following: $$|f_{n}(x)-0|<\epsilon \implies |e^{-n(x-n)^2}|<\epsilon \implies |{n(x-n)^2}|<ln (\epsilon) $$ $$\implies n-\sqrt(ln \epsilon/n)\leq x \leq n+\sqrt(ln \epsilon/n)$$ So for any $a>0$, I can always choose $n$ such that the above condition is satisfied, i.e., $n>a$. hence, $F_{n}$ is equicontinuous on $[-a,a]$ Please check if it is correct. Else suggest a suitable proof.","Let $F = {f_{n} | n \Bbb N }$ be an infinite collection of functions $f_{n}(x)=e^{n(xn)^2} , x  \Bbb R$. Prove that $F$ is not equicontinuous on $\Bbb R$ but equicontinuous on $[a, a]$ for any $a > 0$. I am trying a modified proof (Initially I posted a proof but didn't reach any conclusions): First proving not equicontinuous on $\Bbb R$, $f_{n}(x)=e^{n(xn)^2}$ Let $\epsilon =1/2$. let $x=n$ Then, for $|n-y|<\delta$ , we have $|f_{n}(n)-f_{n}(y)|$=$|1-e^{-n(y-n)^2}|\leq 1$. For $n$ large enough, $|f_{n}(n)-f_{n}(y)|=1>\epsilon$ . So $f_{n}$ is not equicontinuous on $\Bbb R$. Now proving equicontinuous on $[-a,a], a>0$, Here lets use the fact that on a compact set, if $f_{n}$ is continuous and if $f_{n}$ converges uniformly on the compact set, then it is equicontinuous on the compact set. So lets prove that $f_{n}$ converges uniformly on $[-a,a]$. To do this lets first look at the following: Given an interval $[-a,a]$ and  any $\epsilon>0$. The pointwise limit of $f_{n}$ is $0$. Now, what I need to show for uniform convergence is the following: $$|f_{n}(x)-0|<\epsilon \implies |e^{-n(x-n)^2}|<\epsilon \implies |{n(x-n)^2}|<ln (\epsilon) $$ $$\implies n-\sqrt(ln \epsilon/n)\leq x \leq n+\sqrt(ln \epsilon/n)$$ So for any $a>0$, I can always choose $n$ such that the above condition is satisfied, i.e., $n>a$. hence, $F_{n}$ is equicontinuous on $[-a,a]$ Please check if it is correct. Else suggest a suitable proof.",,"['real-analysis', 'sequences-and-series', 'functions', 'proof-writing']"
85,"If $(a_n)$ is such that $\sum_{n=1}^\infty a_nb_n$ converges for every $b\in\ell_2$, then $a\in\ell_2$","If  is such that  converges for every , then",(a_n) \sum_{n=1}^\infty a_nb_n b\in\ell_2 a\in\ell_2,Please help me with this question. I've been thinking about it for almost two days. Let $a_n$ a real series that have the following property: for every series $b_n$ in $l_2$: $\sum_{n=1}^\infty a_nb_n$ converges. prove that $a_n$ in $l_2$.,Please help me with this question. I've been thinking about it for almost two days. Let $a_n$ a real series that have the following property: for every series $b_n$ in $l_2$: $\sum_{n=1}^\infty a_nb_n$ converges. prove that $a_n$ in $l_2$.,,"['sequences-and-series', 'functional-analysis', 'convergence-divergence', 'lp-spaces']"
86,When do regularization methods for divergent series disagree?,When do regularization methods for divergent series disagree?,,"Sometimes, it is possible to take a divergent series (in the sense of its sequence of partial sums failing to converge) and ""regularize"" it using one of a variety of methods to assign it a meaningful finite value. For example, by observing that $\zeta(-1) = -1/12$ via analytic continuation, we can claim in some sense that $$ 1 + 2 + 3 + 4 + \cdots = \sum_{k=1}^\infty k = -\frac{1}{12}. $$ Remarkably, different methods of regularization applied to this divergent series all give the same result, suggesting that the answer $-1/12$ is no ""accidental"" consequence of the method of regularization. My question is, what are some natural examples of divergent series for which this fails to occur, i.e., for which two regularization methods give different finite answers?","Sometimes, it is possible to take a divergent series (in the sense of its sequence of partial sums failing to converge) and ""regularize"" it using one of a variety of methods to assign it a meaningful finite value. For example, by observing that $\zeta(-1) = -1/12$ via analytic continuation, we can claim in some sense that $$ 1 + 2 + 3 + 4 + \cdots = \sum_{k=1}^\infty k = -\frac{1}{12}. $$ Remarkably, different methods of regularization applied to this divergent series all give the same result, suggesting that the answer $-1/12$ is no ""accidental"" consequence of the method of regularization. My question is, what are some natural examples of divergent series for which this fails to occur, i.e., for which two regularization methods give different finite answers?",,"['sequences-and-series', 'divergent-series', 'regularization']"
87,generalization of geometric series $ \sum_{k=0}^\infty x^{p(k)} $,generalization of geometric series, \sum_{k=0}^\infty x^{p(k)} ,I have been playing around with infinite series and I wondered if it is possible to find an expression for the series: $$ \sum_{k=0}^\infty x^{p(k)} $$ as a generalization of geometric series. $p(k)$ is an arbitrary polynomial.,I have been playing around with infinite series and I wondered if it is possible to find an expression for the series: $$ \sum_{k=0}^\infty x^{p(k)} $$ as a generalization of geometric series. $p(k)$ is an arbitrary polynomial.,,"['sequences-and-series', 'polynomials', 'closed-form']"
88,Special values of the classical normalized Eisenstein series,Special values of the classical normalized Eisenstein series,,I am looking for a comprehensive list of some known special values of the classical normalized Eisenstein series $E_4(\tau)$ and $E_6(\tau)$. Does anyone know where I can find a table of some known explicit values of $E_4(\tau)$ and $E_6(\tau)$?,I am looking for a comprehensive list of some known special values of the classical normalized Eisenstein series $E_4(\tau)$ and $E_6(\tau)$. Does anyone know where I can find a table of some known explicit values of $E_4(\tau)$ and $E_6(\tau)$?,,"['sequences-and-series', 'reference-request', 'modular-forms']"
89,Continued fraction and double series.,Continued fraction and double series.,,"From Euler's continued fraction formula, we have $$x = \cfrac{1}{1 - \cfrac{r_1}{1 + r_1 - \cfrac{r_2}{1 + r_2 - \cfrac{r_3}{1 + r_3 - \ddots}}}}\,$$ and $$x = 1 + \sum_{i=1}^\infty r_1r_2\cdots r_i = 1 + \sum_{i=1}^\infty \left( \prod_{j=1}^i r_j \right)\,$$ For example: $$e^z = 1 + \sum_{n=1}^\infty \frac{z^n}{n!} = 1 + \sum_{n=1}^\infty \left(\prod_{j=1}^n \frac{z}{j}\right)=$$$$=\cfrac{1}{1 - \cfrac{z}{1 + z - \cfrac{\frac{1}{2}z}{1 + \frac{1}{2}z - \cfrac{\frac{1}{3}z} {1 + \frac{1}{3}z - \cfrac{\frac{1}{4}z}{1 + \frac{1}{4}z - \ddots}}}}}.\,$$ (by Wikipedia ). Well, my question is the following: are there any version of Euler's continued fraction for double series? Thanks.","From Euler's continued fraction formula, we have $$x = \cfrac{1}{1 - \cfrac{r_1}{1 + r_1 - \cfrac{r_2}{1 + r_2 - \cfrac{r_3}{1 + r_3 - \ddots}}}}\,$$ and $$x = 1 + \sum_{i=1}^\infty r_1r_2\cdots r_i = 1 + \sum_{i=1}^\infty \left( \prod_{j=1}^i r_j \right)\,$$ For example: $$e^z = 1 + \sum_{n=1}^\infty \frac{z^n}{n!} = 1 + \sum_{n=1}^\infty \left(\prod_{j=1}^n \frac{z}{j}\right)=$$$$=\cfrac{1}{1 - \cfrac{z}{1 + z - \cfrac{\frac{1}{2}z}{1 + \frac{1}{2}z - \cfrac{\frac{1}{3}z} {1 + \frac{1}{3}z - \cfrac{\frac{1}{4}z}{1 + \frac{1}{4}z - \ddots}}}}}.\,$$ (by Wikipedia ). Well, my question is the following: are there any version of Euler's continued fraction for double series? Thanks.",,"['sequences-and-series', 'continued-fractions']"
90,Limit of infinite product,Limit of infinite product,,Is it possible to find an analytic form for the limit of the infinite product: $$ \prod_{n=1}^\infty\frac{1+x^{\delta^n}}{2} $$ where $ x>0 $ and $0<\delta<1$?,Is it possible to find an analytic form for the limit of the infinite product: $$ \prod_{n=1}^\infty\frac{1+x^{\delta^n}}{2} $$ where $ x>0 $ and $0<\delta<1$?,,"['sequences-and-series', 'infinite-product']"
91,"Successive ratios of a sequence, is this limit true?","Successive ratios of a sequence, is this limit true?",,"The natural numbers $1,2,3,4,5....$ can be calculated as the row sums of the triangle $T(n,k)$ equal to $1$ if $n \geq k$ and $0$ otherwise: $$\displaystyle T = \left(\begin{matrix} 1&0&0&0&0&0&0&\cdots \\ 1&1&0&0&0&0&0 \\ 1&1&1&0&0&0&0 \\ 1&1&1&1&0&0&0 \\ 1&1&1&1&1&0&0 \\ 1&1&1&1&1&1&0 \\ 1&1&1&1&1&1&1 \\ \vdots&&&&&&&\ddots \end{matrix}\right)$$ This table $T$ satisfies the overly complicated recurrence: $$T(n,1) = 1$$ $$\text{If}\; n\geq k \; \text{then} \; T(n,k) = x \sum _{i=1}^{n-1} T(n-i,k-1)+y \sum _{i=1}^{n-1} T(n-i,k) \; \text{else} \; T(n,k) = 0$$ when $x=1$ and $y=-1$ The row sums of the table $T$ when $x=1$ appears to be: $$A_T(n) = \sum\limits_{k=1}^{k=n} T(n,k) = \lim_{s\to y+1} \, \frac{(s+1)^{n-1}+s-1}{s}$$ as a function of $y$. $x$ not included in the limit above since I don't know what the relationship to $x$ is here when $x$ is unequal to 1. The number of divisors of $n:$ $1, 2, 2, 3, 2, 4, 2, 4, 3, 4, 2, 6, 2, 4, 4, 5, 2, 6, 2, 6....$ can be calculated as the row sums of the triangle $t(n,k)$ equal to $1$ if $k \mid n$  and $0$ otherwise: $$\displaystyle t = \left(\begin{matrix} 1&0&0&0&0&0&0&\cdots \\ 1&1&0&0&0&0&0 \\ 1&0&1&0&0&0&0 \\ 1&1&0&1&0&0&0 \\ 1&0&0&0&1&0&0 \\ 1&1&1&0&0&1&0 \\ 1&0&0&0&0&0&1 \\ \vdots&&&&&&&\ddots \end{matrix}\right)$$ This table $t$ satisfies again an overly complicated recurrence: $$t(n,1) = 1$$ $$\text{If}\; n\geq k \; \text{then} \; t(n,k) = x \sum _{i=1}^{k-1} t(n-i,k-1)+y \sum _{i=1}^{k-1} t(n-i,k) \; \text{else} \; t(n,k) = 0$$ when $x=1$ and $y=-1$ Where the difference to the first simpler recurrence for matrix $T$ compared to matrix $t$ is that in matrix $T$ the summation index goes to $n-1$ while here in matrix $t$ it goes to $k-1$. Otherwise the same kind of recurrence. Proof given by Jeffrey Shallit via email: OK, now I see. You wrote ""k"" before when you talked about the k    previous terms, and you   really meant ""k-1"" previous terms. Just to let you know: you should have written t(n,k) = (sum from i = 1 to k-1 of t(n-i,k-1)) - (sum from i = 1 to k-1    of t(n-i,k)) Here's the proof. Now (sum from i=1 to k-1 of t(n-i,k-1)) is just the number of elements in   {n-k+1,...,n-1) that are divisible by k-1. This is always equal to 1,    because in k-1 consecutive   integers, exactly one will be divisible by k-1. On the other hand, (sum from i = 1 to k-1 of t(n-i,k)) is equal to    either 0 or 1, because in   k-1 consecutive integers, either 0 or 1 of them are divisible by k.    We get 1 except if   all are not divisible by k, which means the next integer /is/ divisible    by k, and the next integer is n. What I have found experimentally is a relationship between; $$A_T(n) = \sum\limits_{k=1}^{k=n} T(n,k)$$ and; $$a_t(n) = \sum\limits_{k=1}^{k=n} t(n,k)$$ when; $x \geq 1$ $y \geq 0$ or; $x \leq -2$ $y \leq -2$ $$a_t(n) \;\; \sim \;\; \frac{A_T(n)}{c}$$ where: $$c = \left(\prod _{n=2}^{\text{nn}} \frac{1}{1-\frac{1}{A_T(n)}}\right)$$ Put together: $$a_t(n) \;\; \sim \;\; \frac{A_T(n)}{\left(\prod _{n=2}^{\text{nn}} \frac{1}{1-\frac{1}{A_T(n)}}\right)}$$ Works also for $x$ and $y$ as some complex numbers but I have not studied for what ranges of complex number it is valid. Taking the difference between the left hand side ($a_t(n)$) and the right side (the approximation $\frac{A_T(n)}{c}$) I have found, and this is the question: Is the ratio between the consecutive terms: $$\lim_{n \to \infty} \left(\frac{a_t(n)-\frac{A_T(n)}{c}}{a_t(n-1)-\frac{A_T(n-1)}{c}}\right) = \frac{1}{2} \left((y+1)+\sqrt{(y+1)^2+4}\right)$$ when $y \geq 1$ and $x=1$? Mathematica program to demonstrate, where $x=1$ and $y=0$ giving the Pascal triangle and the Mahonian numbers: Edit 7.1.2015: Clear[t, n, k, a, b, x, y, b1, at, T, AT, at]; nn = 160; y = 1; T[n_, 1] = 1; T[n_, k_] :=    T[n, k] =     If[n >= k,      Sum[T[n - i, k - 1], {i, 1, n - 1}] +       y*Sum[T[n - i, k], {i, 1, n - 1}], 0]; A = Table[Table[Expand[T[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[A]*) a = Total[Transpose[A]]; Print[""The sequence 'a' that is the row sums of the recursively \ generated table t[n,k] above:""] a[[1 ;; 20]] Print[""appears to be equivalent to the sequence f(n, y) = \ Limit[((s+1)^(n-1)+s-1)/s,s\[Rule]y+1]:""] Table[Limit[((s + 1)^(n - 1) + s - 1)/s, s -> y + 1], {n, 1, 12}]  Clear[t]; t[n_, 1] = 1; t[n_, k_] :=    t[n, k] =     If[n >= k,      Sum[t[n - i, k - 1], {i, 1, k - 1}] +       y*Sum[t[n - i, k], {i, 1, k - 1}], 0]; B = Table[Table[Expand[t[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[B]*) b = Total[Transpose[B]]; Print[""The sequence 'b' is the row sums of the second recursively \ generated table t[n,k] above:""] b[[1 ;; 20]] Print[""Prove or disprove that the ratio between sequence a and b, \ a/b:""] N[a[[nn]]/b[[nn]], 12] Print[""converges to the constant c = \ Product[1/(1-1/a[[i]]),{i,2,nn}]:""] c = Product[1/(1 - 1/a[[i]]), {i, 2, nn}]; N[c, 12] Print[""The error (b(n)-1/c)/(b(n)-1/c*a(n)):""] N[(b[[nn - 1]] - 1/c*a[[nn - 1]])/(b[[nn]] - 1/c*a[[nn]]), 12]^-1 Print[""appears to converge to the expression \ 1/2*((y+1)+Sqrt[(y+1)^2+4]):""] N[1/2*((y + 1) + Sqrt[(y + 1)^2 + 4]), 12] Print[""Can this error size also be proven?""] Edit 22.7.2014: With this Mathematica program a relation between diagonal sums of $t$ and row sums of $t$ is arrived at in terms of the constant $c$: Clear[t, n, k, a, b, x, y, b1, at, T, AT, at]; nn = 200; x = 1; y = 0; T[n_, 1] = 1; T[n_, k_] :=    T[n, k] =     If[n >= k,      x*Sum[T[n - i, k - 1], {i, 1, n - 1}] +       y*Sum[T[n - i, k], {i, 1, n - 1}], 0]; a = Table[Table[Expand[T[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[a]*) AT = Total[Transpose[a]]; AT[[1 ;; 20]]; Table[Limit[((s + 1)^(n - 1) + s - 1)/s, s -> y + 1], {n, 1, 12}]; c = Product[1/(1 - 1/AT[[i]]), {i, 2, nn}]; N[c, 12]  Clear[t]; t[n_, 1] = 1; t[n_, k_] :=    t[n, k] =     If[n >= k,      x*Sum[t[n - i, k - 1], {i, 1, k - 1}] +       y*Sum[t[n - i, k], {i, 1, k - 1}], 0]; a = Table[Table[Expand[t[n, k]], {k, 1, nn}], {n, 1, nn}]; aa = Table[    Total[Table[t[n - k + 1, k], {k, 1, nn}]], {n, 1 + 1, nn + 1}]; (*TableForm[a]*) at = Total[Transpose[a]]; at[[1 ;; 20]]; N[AT[[nn]]/at[[nn]], 12] N[aa/(at - 1/c*AT), 30][[nn - 20 ;; nn]] (*N[1/2*((y+1)+Sqrt[(y+1)^2+4]),12]*) Second edit 22.7.2014: A relation to https://oeis.org/A092526 is found in this program: Clear[t, n, k, a, b, x, y, b1, at, T, AT, at]; nn = 300; x = 1; y = 0; T[n_, 1] = 1; T[n_, k_] :=    T[n, k] =     If[n >= k,      x*Sum[T[n - i, k - 1], {i, 1, n - 1}] +       y*Sum[T[n - i, k], {i, 1, n - 1}], 0]; a = Table[Table[Expand[T[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[a]*) AT = Total[Transpose[a]]; AT[[1 ;; 20]]; Table[Limit[((s + 1)^(n - 1) + s - 1)/s, s -> y + 1], {n, 1, 12}]; c = Product[1/(1 - 1/AT[[i]]), {i, 2, nn}]; N[c, 12]  Clear[t]; t[n_, 1] = 1; t[n_, k_] :=    t[n, k] =     If[n >= k,      x*Sum[t[n - i, k - 1], {i, 1, k - 1}] +       y*Sum[t[n - i, k], {i, 1, k - 1}], 0]; a = Table[Table[Expand[t[n, k]], {k, 1, nn}], {n, 1, nn}]; aa = Table[    Total[Table[t[n - k + 1, k], {k, 1, nn}]], {n, 1 + 1, nn + 1}]; (*TableForm[a]*) at = Total[Transpose[a]]; at[[1 ;; 20]]; N[AT[[nn]]/at[[nn]], 12] N[aa/(at - 1/c*AT), 30][[nn - 20 ;; nn]] Ratios[N[aa - (at - 1/c*AT), 30][[nn - 20 ;; nn]]] ListLinePlot[Log[N[aa - (at - 1/c*AT), 30]]] (*N[1/2*((y+1)+Sqrt[(y+1)^2+4]),12]*) Output: 1.465571230... Which is close to 1.465571231... which the only real root to the equation: N[Solve[x^3 - 1 x^2 - 1 == 0, x], 20] Edit 23.7.2014: Setting the parameter nn = 500, and y=-1 gives the only real root of N[Solve[-x^3 +0*x^2 + 1 == 0, x], 20] = 1.00000000000000000 y=0 gives the only real root of N[Solve[-x^3 + 1*x^2 + 1 == 0, x], 20] = 1.46557123187676802 y=1 gives the only real root of N[Solve[-x^3 + 2*x^2 + 1 == 0, x], 20] = 2.20556943040059031 y=2 gives the only real root of N[Solve[-x^3 + 3*x^2 + 1 == 0, x], 20] = 3.103803402735536533 y=3 gives the only real root of N[Solve[-x^3 + 4*x^2 + 1 == 0, x], 20] = 4.06064702755414245","The natural numbers $1,2,3,4,5....$ can be calculated as the row sums of the triangle $T(n,k)$ equal to $1$ if $n \geq k$ and $0$ otherwise: $$\displaystyle T = \left(\begin{matrix} 1&0&0&0&0&0&0&\cdots \\ 1&1&0&0&0&0&0 \\ 1&1&1&0&0&0&0 \\ 1&1&1&1&0&0&0 \\ 1&1&1&1&1&0&0 \\ 1&1&1&1&1&1&0 \\ 1&1&1&1&1&1&1 \\ \vdots&&&&&&&\ddots \end{matrix}\right)$$ This table $T$ satisfies the overly complicated recurrence: $$T(n,1) = 1$$ $$\text{If}\; n\geq k \; \text{then} \; T(n,k) = x \sum _{i=1}^{n-1} T(n-i,k-1)+y \sum _{i=1}^{n-1} T(n-i,k) \; \text{else} \; T(n,k) = 0$$ when $x=1$ and $y=-1$ The row sums of the table $T$ when $x=1$ appears to be: $$A_T(n) = \sum\limits_{k=1}^{k=n} T(n,k) = \lim_{s\to y+1} \, \frac{(s+1)^{n-1}+s-1}{s}$$ as a function of $y$. $x$ not included in the limit above since I don't know what the relationship to $x$ is here when $x$ is unequal to 1. The number of divisors of $n:$ $1, 2, 2, 3, 2, 4, 2, 4, 3, 4, 2, 6, 2, 4, 4, 5, 2, 6, 2, 6....$ can be calculated as the row sums of the triangle $t(n,k)$ equal to $1$ if $k \mid n$  and $0$ otherwise: $$\displaystyle t = \left(\begin{matrix} 1&0&0&0&0&0&0&\cdots \\ 1&1&0&0&0&0&0 \\ 1&0&1&0&0&0&0 \\ 1&1&0&1&0&0&0 \\ 1&0&0&0&1&0&0 \\ 1&1&1&0&0&1&0 \\ 1&0&0&0&0&0&1 \\ \vdots&&&&&&&\ddots \end{matrix}\right)$$ This table $t$ satisfies again an overly complicated recurrence: $$t(n,1) = 1$$ $$\text{If}\; n\geq k \; \text{then} \; t(n,k) = x \sum _{i=1}^{k-1} t(n-i,k-1)+y \sum _{i=1}^{k-1} t(n-i,k) \; \text{else} \; t(n,k) = 0$$ when $x=1$ and $y=-1$ Where the difference to the first simpler recurrence for matrix $T$ compared to matrix $t$ is that in matrix $T$ the summation index goes to $n-1$ while here in matrix $t$ it goes to $k-1$. Otherwise the same kind of recurrence. Proof given by Jeffrey Shallit via email: OK, now I see. You wrote ""k"" before when you talked about the k    previous terms, and you   really meant ""k-1"" previous terms. Just to let you know: you should have written t(n,k) = (sum from i = 1 to k-1 of t(n-i,k-1)) - (sum from i = 1 to k-1    of t(n-i,k)) Here's the proof. Now (sum from i=1 to k-1 of t(n-i,k-1)) is just the number of elements in   {n-k+1,...,n-1) that are divisible by k-1. This is always equal to 1,    because in k-1 consecutive   integers, exactly one will be divisible by k-1. On the other hand, (sum from i = 1 to k-1 of t(n-i,k)) is equal to    either 0 or 1, because in   k-1 consecutive integers, either 0 or 1 of them are divisible by k.    We get 1 except if   all are not divisible by k, which means the next integer /is/ divisible    by k, and the next integer is n. What I have found experimentally is a relationship between; $$A_T(n) = \sum\limits_{k=1}^{k=n} T(n,k)$$ and; $$a_t(n) = \sum\limits_{k=1}^{k=n} t(n,k)$$ when; $x \geq 1$ $y \geq 0$ or; $x \leq -2$ $y \leq -2$ $$a_t(n) \;\; \sim \;\; \frac{A_T(n)}{c}$$ where: $$c = \left(\prod _{n=2}^{\text{nn}} \frac{1}{1-\frac{1}{A_T(n)}}\right)$$ Put together: $$a_t(n) \;\; \sim \;\; \frac{A_T(n)}{\left(\prod _{n=2}^{\text{nn}} \frac{1}{1-\frac{1}{A_T(n)}}\right)}$$ Works also for $x$ and $y$ as some complex numbers but I have not studied for what ranges of complex number it is valid. Taking the difference between the left hand side ($a_t(n)$) and the right side (the approximation $\frac{A_T(n)}{c}$) I have found, and this is the question: Is the ratio between the consecutive terms: $$\lim_{n \to \infty} \left(\frac{a_t(n)-\frac{A_T(n)}{c}}{a_t(n-1)-\frac{A_T(n-1)}{c}}\right) = \frac{1}{2} \left((y+1)+\sqrt{(y+1)^2+4}\right)$$ when $y \geq 1$ and $x=1$? Mathematica program to demonstrate, where $x=1$ and $y=0$ giving the Pascal triangle and the Mahonian numbers: Edit 7.1.2015: Clear[t, n, k, a, b, x, y, b1, at, T, AT, at]; nn = 160; y = 1; T[n_, 1] = 1; T[n_, k_] :=    T[n, k] =     If[n >= k,      Sum[T[n - i, k - 1], {i, 1, n - 1}] +       y*Sum[T[n - i, k], {i, 1, n - 1}], 0]; A = Table[Table[Expand[T[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[A]*) a = Total[Transpose[A]]; Print[""The sequence 'a' that is the row sums of the recursively \ generated table t[n,k] above:""] a[[1 ;; 20]] Print[""appears to be equivalent to the sequence f(n, y) = \ Limit[((s+1)^(n-1)+s-1)/s,s\[Rule]y+1]:""] Table[Limit[((s + 1)^(n - 1) + s - 1)/s, s -> y + 1], {n, 1, 12}]  Clear[t]; t[n_, 1] = 1; t[n_, k_] :=    t[n, k] =     If[n >= k,      Sum[t[n - i, k - 1], {i, 1, k - 1}] +       y*Sum[t[n - i, k], {i, 1, k - 1}], 0]; B = Table[Table[Expand[t[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[B]*) b = Total[Transpose[B]]; Print[""The sequence 'b' is the row sums of the second recursively \ generated table t[n,k] above:""] b[[1 ;; 20]] Print[""Prove or disprove that the ratio between sequence a and b, \ a/b:""] N[a[[nn]]/b[[nn]], 12] Print[""converges to the constant c = \ Product[1/(1-1/a[[i]]),{i,2,nn}]:""] c = Product[1/(1 - 1/a[[i]]), {i, 2, nn}]; N[c, 12] Print[""The error (b(n)-1/c)/(b(n)-1/c*a(n)):""] N[(b[[nn - 1]] - 1/c*a[[nn - 1]])/(b[[nn]] - 1/c*a[[nn]]), 12]^-1 Print[""appears to converge to the expression \ 1/2*((y+1)+Sqrt[(y+1)^2+4]):""] N[1/2*((y + 1) + Sqrt[(y + 1)^2 + 4]), 12] Print[""Can this error size also be proven?""] Edit 22.7.2014: With this Mathematica program a relation between diagonal sums of $t$ and row sums of $t$ is arrived at in terms of the constant $c$: Clear[t, n, k, a, b, x, y, b1, at, T, AT, at]; nn = 200; x = 1; y = 0; T[n_, 1] = 1; T[n_, k_] :=    T[n, k] =     If[n >= k,      x*Sum[T[n - i, k - 1], {i, 1, n - 1}] +       y*Sum[T[n - i, k], {i, 1, n - 1}], 0]; a = Table[Table[Expand[T[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[a]*) AT = Total[Transpose[a]]; AT[[1 ;; 20]]; Table[Limit[((s + 1)^(n - 1) + s - 1)/s, s -> y + 1], {n, 1, 12}]; c = Product[1/(1 - 1/AT[[i]]), {i, 2, nn}]; N[c, 12]  Clear[t]; t[n_, 1] = 1; t[n_, k_] :=    t[n, k] =     If[n >= k,      x*Sum[t[n - i, k - 1], {i, 1, k - 1}] +       y*Sum[t[n - i, k], {i, 1, k - 1}], 0]; a = Table[Table[Expand[t[n, k]], {k, 1, nn}], {n, 1, nn}]; aa = Table[    Total[Table[t[n - k + 1, k], {k, 1, nn}]], {n, 1 + 1, nn + 1}]; (*TableForm[a]*) at = Total[Transpose[a]]; at[[1 ;; 20]]; N[AT[[nn]]/at[[nn]], 12] N[aa/(at - 1/c*AT), 30][[nn - 20 ;; nn]] (*N[1/2*((y+1)+Sqrt[(y+1)^2+4]),12]*) Second edit 22.7.2014: A relation to https://oeis.org/A092526 is found in this program: Clear[t, n, k, a, b, x, y, b1, at, T, AT, at]; nn = 300; x = 1; y = 0; T[n_, 1] = 1; T[n_, k_] :=    T[n, k] =     If[n >= k,      x*Sum[T[n - i, k - 1], {i, 1, n - 1}] +       y*Sum[T[n - i, k], {i, 1, n - 1}], 0]; a = Table[Table[Expand[T[n, k]], {k, 1, nn}], {n, 1, nn}]; (*TableForm[a]*) AT = Total[Transpose[a]]; AT[[1 ;; 20]]; Table[Limit[((s + 1)^(n - 1) + s - 1)/s, s -> y + 1], {n, 1, 12}]; c = Product[1/(1 - 1/AT[[i]]), {i, 2, nn}]; N[c, 12]  Clear[t]; t[n_, 1] = 1; t[n_, k_] :=    t[n, k] =     If[n >= k,      x*Sum[t[n - i, k - 1], {i, 1, k - 1}] +       y*Sum[t[n - i, k], {i, 1, k - 1}], 0]; a = Table[Table[Expand[t[n, k]], {k, 1, nn}], {n, 1, nn}]; aa = Table[    Total[Table[t[n - k + 1, k], {k, 1, nn}]], {n, 1 + 1, nn + 1}]; (*TableForm[a]*) at = Total[Transpose[a]]; at[[1 ;; 20]]; N[AT[[nn]]/at[[nn]], 12] N[aa/(at - 1/c*AT), 30][[nn - 20 ;; nn]] Ratios[N[aa - (at - 1/c*AT), 30][[nn - 20 ;; nn]]] ListLinePlot[Log[N[aa - (at - 1/c*AT), 30]]] (*N[1/2*((y+1)+Sqrt[(y+1)^2+4]),12]*) Output: 1.465571230... Which is close to 1.465571231... which the only real root to the equation: N[Solve[x^3 - 1 x^2 - 1 == 0, x], 20] Edit 23.7.2014: Setting the parameter nn = 500, and y=-1 gives the only real root of N[Solve[-x^3 +0*x^2 + 1 == 0, x], 20] = 1.00000000000000000 y=0 gives the only real root of N[Solve[-x^3 + 1*x^2 + 1 == 0, x], 20] = 1.46557123187676802 y=1 gives the only real root of N[Solve[-x^3 + 2*x^2 + 1 == 0, x], 20] = 2.20556943040059031 y=2 gives the only real root of N[Solve[-x^3 + 3*x^2 + 1 == 0, x], 20] = 3.103803402735536533 y=3 gives the only real root of N[Solve[-x^3 + 4*x^2 + 1 == 0, x], 20] = 4.06064702755414245",,"['sequences-and-series', 'number-theory', 'limits', 'experimental-mathematics']"
92,Finding a recurrence relation for a sequence not containing $0$ in the digits. Also showing $\sum\limits_{k=1}^n \dfrac{1}{a_k} < 90$,Finding a recurrence relation for a sequence not containing  in the digits. Also showing,0 \sum\limits_{k=1}^n \dfrac{1}{a_k} < 90,"Let $1,2,3,4,5,6,7,8,9,11,12,\ldots$ be the sequence of all positive integers which do not contain the digit zero. Write $\{a_n\}$ for this sequence. By comparing with a geometric series, show that $\sum\limits_{k=1}^n \dfrac{1}{a_k} < 90$. My attempts: I could not attempt the first part of the question to find a formula for generalising $\{a_n\}$ but for the second part, I tried, $$\sum_n \dfrac{1}{a_n}<1+\dfrac12+\dfrac12+\dfrac14+\dfrac14+\dfrac14+\dfrac14+\ldots$$ but could not get anything worth of mention. Please help.","Let $1,2,3,4,5,6,7,8,9,11,12,\ldots$ be the sequence of all positive integers which do not contain the digit zero. Write $\{a_n\}$ for this sequence. By comparing with a geometric series, show that $\sum\limits_{k=1}^n \dfrac{1}{a_k} < 90$. My attempts: I could not attempt the first part of the question to find a formula for generalising $\{a_n\}$ but for the second part, I tried, $$\sum_n \dfrac{1}{a_n}<1+\dfrac12+\dfrac12+\dfrac14+\dfrac14+\dfrac14+\dfrac14+\ldots$$ but could not get anything worth of mention. Please help.",,"['sequences-and-series', 'recurrence-relations']"
93,Evaluating the alternating hyperbolic series $\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k \sinh (\pi k)}$,Evaluating the alternating hyperbolic series,\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k \sinh (\pi k)},"You can evaluate the alternating hyperbolic series $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{2n-1} \sinh (\pi k)}$$ for any positive even value of $n$ by integrating the function $$\frac{\pi \csc (\pi z)}{z^{2n-1} \sinh (\pi z)}$$ around a square contour that avoids the poles on both the real and imaginary axes. For example, $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{3} \sinh (\pi k)} = - \frac{\pi^3}{360} $$ and $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{7} \sinh (\pi k)} = - \frac{13 \pi^7}{453,600}. $$ However, if you try that same thing for a positive odd value of $n$ ,  the residues inside of the contour cancel each other, and you're left with the trivial equation $0=0$ . So what would be a way to show that $$\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k \sinh (\pi k)} = \frac{\pi}{12} - \frac{\log 2}{2} \,  ?$$ Furthermore, do closed form expressions for $\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{5} \sinh (\pi k)} $ , $\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{9} \sinh (\pi k)} $ , etc. exist? It seems like the best way to evaluate the case $n=1$ is to express the series in terms of the lattice sum $$\sum_{i=-\infty}^{\infty} \sum_{j=-\infty}^{\infty}   \frac{(-1)^{i+j}}{i^{2}+j^{2}}, \quad (i,j) \ne (0,0), $$ as explained here , and then use the Lambert series $$\theta_{4}^{2}(0,q) =  1 + 4 \sum_{m=1}^{\infty} \frac{(-1)^{m}q^{m}}{1+q^{2m}} $$ to evaluate the lattice sum (as explained here ).","You can evaluate the alternating hyperbolic series for any positive even value of by integrating the function around a square contour that avoids the poles on both the real and imaginary axes. For example, and However, if you try that same thing for a positive odd value of ,  the residues inside of the contour cancel each other, and you're left with the trivial equation . So what would be a way to show that Furthermore, do closed form expressions for , , etc. exist? It seems like the best way to evaluate the case is to express the series in terms of the lattice sum as explained here , and then use the Lambert series to evaluate the lattice sum (as explained here ).","\sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{2n-1} \sinh (\pi k)} n \frac{\pi \csc (\pi z)}{z^{2n-1} \sinh (\pi z)} \sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{3} \sinh (\pi k)} = - \frac{\pi^3}{360}  \sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{7} \sinh (\pi k)} = - \frac{13 \pi^7}{453,600}.  n 0=0 \sum_{k=1}^{\infty} \frac{(-1)^{k}}{k \sinh (\pi k)} = \frac{\pi}{12} - \frac{\log 2}{2} \,  ? \sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{5} \sinh (\pi k)}  \sum_{k=1}^{\infty} \frac{(-1)^{k}}{k^{9} \sinh (\pi k)}  n=1 \sum_{i=-\infty}^{\infty} \sum_{j=-\infty}^{\infty}   \frac{(-1)^{i+j}}{i^{2}+j^{2}}, \quad (i,j) \ne (0,0),  \theta_{4}^{2}(0,q) =  1 + 4 \sum_{m=1}^{\infty} \frac{(-1)^{m}q^{m}}{1+q^{2m}} ","['sequences-and-series', 'complex-analysis', 'theta-functions']"
94,Closed form of $\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]$,Closed form of,\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}],"While working on a question , I wanted to find a limit in closed form as known numbers but I could not find a way to express it. $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]$$ $$\ln (x+1)=\frac{x}{1} -\frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4}+ ....=\sum \limits_{k=1}^{\infty} (-1)^{k+1} \frac{x^k}{k}$$ $$\frac{1}{n\ln(1+\frac{x^2}{n^2})}=\frac{1}{n(\frac{x^2}{n^2} - \frac{x^4}{2n^4} + \frac{x^6}{3n^6}+ \cdots)}=\frac{1}{\frac{x^2}{n}- \frac{x^4}{2n^3} + \frac{x^6}{3n^5}+ \cdots}=\frac{n}{x^2}(\frac{1}{1 - \frac{x^2}{2n^2} + \frac{x^4}{3n^4}+ \cdots)}=\frac{n}{x^2}.({1 + \frac{x^2}{2n^2} - \frac{x^4}{12n^4}+ \cdots)}$$ $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]=\lim_{n\to\infty}[(\sum_{k=1}^n \frac{n}{k^2}.(1 + \frac{k^2}{2n^2} - \frac{k^4}{12n^4}+ \cdots) )-\frac{{n \pi}^2}{6}]=\lim_{n\to\infty}[(n\sum_{k=1}^n \frac{1}{k^2} + \frac{1}{2n}\sum_{k=1}^n1 - \frac{1}{12n^3}\sum_{k=1}^n k^2+ \cdots) -\frac{{n \pi}^2}{6}]= \frac{1}{2} - \frac{1}{36}+ \cdots$$ The results from above we can express the requested number as $$\alpha=\sum_{k=1}^{\infty} \frac{1}{2k-1} \frac{1}{k!}\frac{d^k}{{dx}^k}(\frac{x}{\ln(1+x)})|_{x=0}$$ maybe that way can help to see the number in closed form Thanks for answers EDIT: @user8268 noticed good point.Maybe we can find the result via integral variable change. I want to share the transform from sum into integral representation. We know that $$\frac{{\pi}^2}{6}=\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}$$ Thus we can write that $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-n\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}]$$ $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n \frac{1}{n}(\frac{1}{\ln(1+\frac{k^2}{n^2})})-\lim_{n\to\infty}\sum_{k=1}^n \frac{1}{n}(\frac{1}{\frac{k^2}{n^2}})]$$ $$\alpha=\lim_{n\to\infty}[\sum_{k=1}^n \frac{1}{n}(\frac{1}{\ln(1+\frac{k^2}{n^2})}-\frac{1}{\frac{k^2}{n^2}})]$$ We can write a  sum as integral because we know a formula that  $$\int _0^x {f(t) dt}=\lim_{n\to\infty} \frac{x}{n}\sum \limits_{k=1}^n f(\frac{kx}{n})$$ Thus $$\alpha=\int _0^1 {(\frac{1}{\ln(1+t^2)}-\frac{1}{t^2}) dt}$$ Now I can focus on the variable change and try to evaluate the integral as known closed form numbers such as $\ln2, e,\gamma$,  $\pi$ , $\Gamma(\frac{1}{4})$ etc (or their combinations if it is possible )","While working on a question , I wanted to find a limit in closed form as known numbers but I could not find a way to express it. $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]$$ $$\ln (x+1)=\frac{x}{1} -\frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4}+ ....=\sum \limits_{k=1}^{\infty} (-1)^{k+1} \frac{x^k}{k}$$ $$\frac{1}{n\ln(1+\frac{x^2}{n^2})}=\frac{1}{n(\frac{x^2}{n^2} - \frac{x^4}{2n^4} + \frac{x^6}{3n^6}+ \cdots)}=\frac{1}{\frac{x^2}{n}- \frac{x^4}{2n^3} + \frac{x^6}{3n^5}+ \cdots}=\frac{n}{x^2}(\frac{1}{1 - \frac{x^2}{2n^2} + \frac{x^4}{3n^4}+ \cdots)}=\frac{n}{x^2}.({1 + \frac{x^2}{2n^2} - \frac{x^4}{12n^4}+ \cdots)}$$ $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-\frac{{n \pi}^2}{6}]=\lim_{n\to\infty}[(\sum_{k=1}^n \frac{n}{k^2}.(1 + \frac{k^2}{2n^2} - \frac{k^4}{12n^4}+ \cdots) )-\frac{{n \pi}^2}{6}]=\lim_{n\to\infty}[(n\sum_{k=1}^n \frac{1}{k^2} + \frac{1}{2n}\sum_{k=1}^n1 - \frac{1}{12n^3}\sum_{k=1}^n k^2+ \cdots) -\frac{{n \pi}^2}{6}]= \frac{1}{2} - \frac{1}{36}+ \cdots$$ The results from above we can express the requested number as $$\alpha=\sum_{k=1}^{\infty} \frac{1}{2k-1} \frac{1}{k!}\frac{d^k}{{dx}^k}(\frac{x}{\ln(1+x)})|_{x=0}$$ maybe that way can help to see the number in closed form Thanks for answers EDIT: @user8268 noticed good point.Maybe we can find the result via integral variable change. I want to share the transform from sum into integral representation. We know that $$\frac{{\pi}^2}{6}=\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}$$ Thus we can write that $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n\frac{1}{n\ln(1+\frac{k^2}{n^2})})-n\lim_{n\to\infty}\sum_{k=1}^n\frac{1}{k^2}]$$ $$\alpha=\lim_{n\to\infty}[(\sum_{k=1}^n \frac{1}{n}(\frac{1}{\ln(1+\frac{k^2}{n^2})})-\lim_{n\to\infty}\sum_{k=1}^n \frac{1}{n}(\frac{1}{\frac{k^2}{n^2}})]$$ $$\alpha=\lim_{n\to\infty}[\sum_{k=1}^n \frac{1}{n}(\frac{1}{\ln(1+\frac{k^2}{n^2})}-\frac{1}{\frac{k^2}{n^2}})]$$ We can write a  sum as integral because we know a formula that  $$\int _0^x {f(t) dt}=\lim_{n\to\infty} \frac{x}{n}\sum \limits_{k=1}^n f(\frac{kx}{n})$$ Thus $$\alpha=\int _0^1 {(\frac{1}{\ln(1+t^2)}-\frac{1}{t^2}) dt}$$ Now I can focus on the variable change and try to evaluate the integral as known closed form numbers such as $\ln2, e,\gamma$,  $\pi$ , $\Gamma(\frac{1}{4})$ etc (or their combinations if it is possible )",,"['sequences-and-series', 'limits']"
95,"If $a_{n+1}=\lfloor 1.05\times a_n\rfloor$, does there exist $N$ such that $a_N\equiv0 \ $(mod$\ $$10$)?","If , does there exist  such that (mod)?",a_{n+1}=\lfloor 1.05\times a_n\rfloor N a_N\equiv0 \  \  10,"I've known the following theorem. Theorem : Supposing that $a_{n+1}=\lfloor 1.05\times a_n\rfloor$ for any natural number $n$, there exists $N$ such that $a_N\equiv0 \ $(mod$\ $$10$) for any integer $20\le a_1\le100$. Proof : $\{a_n\}$ is a monotonic increase sequence, so let's observe the minimum $n$ such that $a_n\ge100$ for any $a_1$. The observation shows you that you'll always get any one of $100, 101, 102, 103$. Then, you get $$101\to106\to111\to116\to121\to127\to133\to139\to145\to152\to159\to166\to174\to182\to191\to200$$ $$102\to107\to112\to117\to122\to128\to134\to140$$ $$103\to108\to113\to118\to123\to129\to135\to141\to148\to155\to162\to170,$$ so the proof is completed. Then, here are my questions. As far as I know, the next question still remains unsolved. Question1 : Supposing that $a_{n+1}=\lfloor 1.05\times a_n\rfloor$ for any natural number $n$, does there exist $N$ such that $a_N\equiv0 \ $(mod$\ $$10$) for any integer $a_1\ge20\ $? It is likely that such $N$ would exist, but I'm facing difficulty. I'm also interested in the following generalization. Question2 : Supposing that $\alpha\gt1$ is a real number and that $a_{n+1}=\lfloor \alpha\times a_n\rfloor$ for any natural number $n$, does there exist $N$ such that $a_N\equiv0 \ $(mod$\ $$10$) for any integer $a_1\ge \frac{1}{\alpha-1} \ $? Any help would be appreciated.","I've known the following theorem. Theorem : Supposing that $a_{n+1}=\lfloor 1.05\times a_n\rfloor$ for any natural number $n$, there exists $N$ such that $a_N\equiv0 \ $(mod$\ $$10$) for any integer $20\le a_1\le100$. Proof : $\{a_n\}$ is a monotonic increase sequence, so let's observe the minimum $n$ such that $a_n\ge100$ for any $a_1$. The observation shows you that you'll always get any one of $100, 101, 102, 103$. Then, you get $$101\to106\to111\to116\to121\to127\to133\to139\to145\to152\to159\to166\to174\to182\to191\to200$$ $$102\to107\to112\to117\to122\to128\to134\to140$$ $$103\to108\to113\to118\to123\to129\to135\to141\to148\to155\to162\to170,$$ so the proof is completed. Then, here are my questions. As far as I know, the next question still remains unsolved. Question1 : Supposing that $a_{n+1}=\lfloor 1.05\times a_n\rfloor$ for any natural number $n$, does there exist $N$ such that $a_N\equiv0 \ $(mod$\ $$10$) for any integer $a_1\ge20\ $? It is likely that such $N$ would exist, but I'm facing difficulty. I'm also interested in the following generalization. Question2 : Supposing that $\alpha\gt1$ is a real number and that $a_{n+1}=\lfloor \alpha\times a_n\rfloor$ for any natural number $n$, does there exist $N$ such that $a_N\equiv0 \ $(mod$\ $$10$) for any integer $a_1\ge \frac{1}{\alpha-1} \ $? Any help would be appreciated.",,"['sequences-and-series', 'number-theory']"
96,"Integral of two logs and a power: $\int_0^1 u^c \log(1-au)\log(1-bu)\,\mathrm du$",Integral of two logs and a power:,"\int_0^1 u^c \log(1-au)\log(1-bu)\,\mathrm du","Does the following integral have a closed form in terms of known functions? $$ f(a,b,c) = \int_0^1 u^c \log(1-au)\log(1-bu)\,\mathrm du.$$ The parameters are possibly complex, and satisfy $$\Re(c)>-1, \qquad |a|\leq1, \qquad |b|\leq1. $$ The best I could do was $$ f(a,b,c) = \frac{1}{1+c}\frac{\partial^2}{\partial s \partial t}\Big|_{s=t=0}F_1(1+c; -s,-t; 2+c; a, b),$$ where $F_1$ is an Appell function , but this doesn't help me much. Also, when $a=b$, I know that $f$ is the second derivative of the beta function. Is it possible to get a nicer expression for $f$?","Does the following integral have a closed form in terms of known functions? $$ f(a,b,c) = \int_0^1 u^c \log(1-au)\log(1-bu)\,\mathrm du.$$ The parameters are possibly complex, and satisfy $$\Re(c)>-1, \qquad |a|\leq1, \qquad |b|\leq1. $$ The best I could do was $$ f(a,b,c) = \frac{1}{1+c}\frac{\partial^2}{\partial s \partial t}\Big|_{s=t=0}F_1(1+c; -s,-t; 2+c; a, b),$$ where $F_1$ is an Appell function , but this doesn't help me much. Also, when $a=b$, I know that $f$ is the second derivative of the beta function. Is it possible to get a nicer expression for $f$?",,"['sequences-and-series', 'special-functions', 'definite-integrals', 'closed-form']"
97,Is there always a telescopic series associated with a rational number?,Is there always a telescopic series associated with a rational number?,,"Here is something I thought up while I was bored and my, erm, fish were busy: Given a rational number $p\in(0,1)$, are there always positive integers $n$, $c_m$, and $w_m$ such that $$p=\sum_{k=1}^\infty \frac1{\prod\limits_{m=1}^n (c_m k+w_m)}?$$ If so, how do you find these integers? I got curious about this when I started playing around with telescopic series . As you know, the good thing about them is that they are easily evaluated through clever rewriting of the general term, after which there is much cancellation, leaving behind a few terms that add up to the desired result. That got me wondering on whether a rational number always has a telescopic series representation. I don't really know how this might be proven (and I'm not that good at math), so I wish somebody could enlighten me. Thanks!","Here is something I thought up while I was bored and my, erm, fish were busy: Given a rational number $p\in(0,1)$, are there always positive integers $n$, $c_m$, and $w_m$ such that $$p=\sum_{k=1}^\infty \frac1{\prod\limits_{m=1}^n (c_m k+w_m)}?$$ If so, how do you find these integers? I got curious about this when I started playing around with telescopic series . As you know, the good thing about them is that they are easily evaluated through clever rewriting of the general term, after which there is much cancellation, leaving behind a few terms that add up to the desired result. That got me wondering on whether a rational number always has a telescopic series representation. I don't really know how this might be proven (and I'm not that good at math), so I wish somebody could enlighten me. Thanks!",,"['sequences-and-series', 'diophantine-equations', 'rational-numbers']"
98,How to transform series of series into series,How to transform series of series into series,,"I need to prove this equation. $$ \sum_{k=0}^{i-2} \left( e \space (k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) = \sum_{k=0}^{i-2} \frac{(i-k)^k}{k!} \space e^{i-k} (-1)^k\space where,\space (i) = \sum_{k=0}^{i-1}\left(\frac{(i-k)^k}{k!}e^{i-k}(-1)^k\right) \space\space\space\space (1)$$ This equation holds. I have confirmed it by using a math tool, but I don't know how the left side can be transformed into the right side of the equation. I need some formulas to prove this equation. The left side of the equation includes series of series $\sum_{k=0}^{i-2} e \space (k+1) $, so it is very difficult for me to transform the series of series into the series in the right side. The equation can be rewritten as follows, $$ \sum_{k=0}^{i-2} \left( e \space (k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) = (i) - \frac{(-1)^{i+1} \space e}{(i-1)!} \space\space\space(2)$$ $$ (i) = \sum_{k=0}^{i-2} \left( e \space (k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) + \frac{(-1)^{i+1} \space e}{(i-1)!} \space\space\space(3)$$ Any hint that will lead me to the correct proof will be highly appreciated. For more information, this $(i)$ function came from my previous question .","I need to prove this equation. $$ \sum_{k=0}^{i-2} \left( e \space (k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) = \sum_{k=0}^{i-2} \frac{(i-k)^k}{k!} \space e^{i-k} (-1)^k\space where,\space (i) = \sum_{k=0}^{i-1}\left(\frac{(i-k)^k}{k!}e^{i-k}(-1)^k\right) \space\space\space\space (1)$$ This equation holds. I have confirmed it by using a math tool, but I don't know how the left side can be transformed into the right side of the equation. I need some formulas to prove this equation. The left side of the equation includes series of series $\sum_{k=0}^{i-2} e \space (k+1) $, so it is very difficult for me to transform the series of series into the series in the right side. The equation can be rewritten as follows, $$ \sum_{k=0}^{i-2} \left( e \space (k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) = (i) - \frac{(-1)^{i+1} \space e}{(i-1)!} \space\space\space(2)$$ $$ (i) = \sum_{k=0}^{i-2} \left( e \space (k+1)\space\frac{(-1)^{i+k+2}}{(i-k-2)!} \right) + \frac{(-1)^{i+1} \space e}{(i-1)!} \space\space\space(3)$$ Any hint that will lead me to the correct proof will be highly appreciated. For more information, this $(i)$ function came from my previous question .",,"['algebra-precalculus', 'sequences-and-series', 'binomial-coefficients']"
99,expansion for $1-|t|$,expansion for,1-|t|,"Let $f$ be a continuous function on $\mathbb{R}$ with compact support with exactly one maximum.  Form the functions  $$ f_{m,k}(x)=f^m\left(x-\frac{k}{2^m}\right) $$ I am wondering if one can expand function $B(t)=1-|t|$, $t \in \mathbb{R}$ (this function called $B_1$ -spline) in terms of $f_{m,k}$, i.e. something like $1-|t|=\sum_{k,m}c_kf_{m,k} $ Thank you.","Let $f$ be a continuous function on $\mathbb{R}$ with compact support with exactly one maximum.  Form the functions  $$ f_{m,k}(x)=f^m\left(x-\frac{k}{2^m}\right) $$ I am wondering if one can expand function $B(t)=1-|t|$, $t \in \mathbb{R}$ (this function called $B_1$ -spline) in terms of $f_{m,k}$, i.e. something like $1-|t|=\sum_{k,m}c_kf_{m,k} $ Thank you.",,"['sequences-and-series', 'functions', 'fourier-series', 'wavelets']"
