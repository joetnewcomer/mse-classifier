,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"is $S(n,k) = S^{*}(n,k)$?",is ?,"S(n,k) = S^{*}(n,k)","Egoroff's Theorem : If $\mu(X)<\infty$ , if $\{f_n\}$ is a sequence of complex measurable functions which converges pointwise on $X$ , and if $\epsilon >0$ , then there is some measurable $E\subset X$ with $\mu(E-X)<\epsilon$ such that $\{f_n\}$ converges uniformly on $E$ . I'm studying the proof of Egoroff's theorem and I have seen that the definition of the auxiliary set has different versions. In one of the tests they defined it as follows: $$S(n,k) = \bigcap_{i>n}\{x \in X \colon |f_{i}(x)-f(x)|<\frac{1}{k} \}$$ On the other hand, in another test they define it as follows: $$S^{*}(n,k) = \{x \in X \colon |f_{i}(x)-f(x)|<\frac{1}{k},\hspace{0.2cm} \text{for all} \hspace{0.2cm} i > n \}$$ My question is, are these two sets the same? On the other hand, in the proof of this theorem, where is the fact that $ \mu(X) <\infty $ used? Proof of Egoroff's theorem: Also, I would like to know how to show that the theorem does extend, with essentially the same proof, to the situation in which the sequence $\{f_n\}$ is replaced by a family $\{f_t\}$ , where $t$ ranges over the positive reals; the assumptions are now that, for all $x\in X$ , (i) $\hspace{0.2cm}$ $\lim_{t \to \infty}f_{t}(x) = f(x)$ and (ii) $\hspace{0.2cm}$ $t \to f_{t}(x)$ is continuous Any answer is appreciated and valued","Egoroff's Theorem : If , if is a sequence of complex measurable functions which converges pointwise on , and if , then there is some measurable with such that converges uniformly on . I'm studying the proof of Egoroff's theorem and I have seen that the definition of the auxiliary set has different versions. In one of the tests they defined it as follows: On the other hand, in another test they define it as follows: My question is, are these two sets the same? On the other hand, in the proof of this theorem, where is the fact that used? Proof of Egoroff's theorem: Also, I would like to know how to show that the theorem does extend, with essentially the same proof, to the situation in which the sequence is replaced by a family , where ranges over the positive reals; the assumptions are now that, for all , (i) and (ii) is continuous Any answer is appreciated and valued","\mu(X)<\infty \{f_n\} X \epsilon >0 E\subset X \mu(E-X)<\epsilon \{f_n\} E S(n,k) = \bigcap_{i>n}\{x \in X \colon |f_{i}(x)-f(x)|<\frac{1}{k} \} S^{*}(n,k) = \{x \in X \colon |f_{i}(x)-f(x)|<\frac{1}{k},\hspace{0.2cm} \text{for all} \hspace{0.2cm} i > n \}  \mu(X) <\infty  \{f_n\} \{f_t\} t x\in X \hspace{0.2cm} \lim_{t \to \infty}f_{t}(x) = f(x) \hspace{0.2cm} t \to f_{t}(x)","['measure-theory', 'elementary-set-theory', 'proof-explanation']"
1,How do we reduce the inversion formula for the $n$-dimensional Fourier transform to the $1$-dimensional case using Fubini's theorem?,How do we reduce the inversion formula for the -dimensional Fourier transform to the -dimensional case using Fubini's theorem?,n 1,"Please consider the following theorem from Measures, Integrals and Martingales (2nd edition) : Question 1 : The proof of the claim is straightforward, but I don't understand the remark in the ""caution"" paragraph. Isn't the right-hand side of (19.6) equal to the Bochner integral $\int\frac{e^{{\rm i}b\xi}-e^{{\rm i}a\xi}}{{\rm i}\xi}\hat\mu(\xi)\:\lambda({\rm d}\xi)$ , where $\lambda$ denotes the Lebesgue measure on $\mathcal B(\mathbb R)$ ? Moreover, I would like to understand how this identity can be generalized to the $n$ -dimensional case. In the book, there is the following corollary (without proof), but I'm not sure how we obtain it: Question 2 : How exactly do we need to apply Fubini's theorem here in order to use the former result (19.6)? Do we need to apply (19.6) somehow to the finite measures $\mu_i$ , where $$\mu_1(B):=\mu\left(B\times\times_{i=2}^n(a_i,b_i)\right)\;\;\;\text{for }B\in\mathcal B(\mathbb R)$$ and $\mu_2,\ldots,\mu_n$ are defined in the obvious analogous way?","Please consider the following theorem from Measures, Integrals and Martingales (2nd edition) : Question 1 : The proof of the claim is straightforward, but I don't understand the remark in the ""caution"" paragraph. Isn't the right-hand side of (19.6) equal to the Bochner integral , where denotes the Lebesgue measure on ? Moreover, I would like to understand how this identity can be generalized to the -dimensional case. In the book, there is the following corollary (without proof), but I'm not sure how we obtain it: Question 2 : How exactly do we need to apply Fubini's theorem here in order to use the former result (19.6)? Do we need to apply (19.6) somehow to the finite measures , where and are defined in the obvious analogous way?","\int\frac{e^{{\rm i}b\xi}-e^{{\rm i}a\xi}}{{\rm i}\xi}\hat\mu(\xi)\:\lambda({\rm d}\xi) \lambda \mathcal B(\mathbb R) n \mu_i \mu_1(B):=\mu\left(B\times\times_{i=2}^n(a_i,b_i)\right)\;\;\;\text{for }B\in\mathcal B(\mathbb R) \mu_2,\ldots,\mu_n","['real-analysis', 'measure-theory', 'fourier-transform', 'fubini-tonelli-theorems']"
2,"Is $F(x)=\int_{(-\infty,x)}f\,d\lambda$ Lipschitz continuous?",Is  Lipschitz continuous?,"F(x)=\int_{(-\infty,x)}f\,d\lambda","Let $f:\mathbb{R}\rightarrow\mathbb{R}$ Lebesgue integrable. Is $$F(x)=\int_{(-\infty,x)}f\,d\lambda$$ Lispchitz continuous? where $\lambda$ is the Lebesgue measure. I think $F$ is not necessarily Lipschitz continuous. I tried with the functions $\chi_{[1,\infty)}x^{-2/3}$ , $\chi_{(0,\infty)}x^{1/2}$ where $\chi_A$ is the characteristic function of $A$ , and other combinations but non of them gives me a counterexample. Any suggestion?","Let Lebesgue integrable. Is Lispchitz continuous? where is the Lebesgue measure. I think is not necessarily Lipschitz continuous. I tried with the functions , where is the characteristic function of , and other combinations but non of them gives me a counterexample. Any suggestion?","f:\mathbb{R}\rightarrow\mathbb{R} F(x)=\int_{(-\infty,x)}f\,d\lambda \lambda F \chi_{[1,\infty)}x^{-2/3} \chi_{(0,\infty)}x^{1/2} \chi_A A","['measure-theory', 'lebesgue-measure', 'lipschitz-functions']"
3,"Prove that $m(U(n,\epsilon)) \xrightarrow{n\to\infty} 0$ where $U(n,\epsilon) = \{x: f_n(x) > \epsilon\}$",Prove that  where,"m(U(n,\epsilon)) \xrightarrow{n\to\infty} 0 U(n,\epsilon) = \{x: f_n(x) > \epsilon\}","Suppose $(f_n)_{n\in\mathbb N}$ is a sequence of continuous functions on $[0,1]$ such that $f_n(x) \xrightarrow{n\to\infty} 0$ for every $0\le x\le 1$ , $0\le f_n\le 1$ for every $n\in\mathbb N$ . Define $U(n,\epsilon) = \{x: f_n(x) > \epsilon\}$ for $\epsilon > 0$ . Prove that $$m(U(n,\epsilon)) \xrightarrow{n\to\infty} 0$$ where $m$ is the restriction of the Lebesgue measure to $[0,1]$ . Try not to use anything fancy such as the Dominated Convergence Theorem (DCT). Try to work with the assumptions directly, such as continuity of $f_n$ and compactness of $[0,1]$ . I didn't make substantial progress, but let me collect all my thoughts here. I saw that $$\bigcap_{n=1}^\infty U(n,\epsilon) = \varnothing$$ If we could use the DCT, I would do (hope it's correct) $$\lim_{n\to\infty} m(U(n,\epsilon)) = \lim_{n\to\infty}\int_0^1 \mathbf{1}_{U(n,\epsilon)} \mathrm{d}m = \int_0^1 \lim_{n\to\infty}\mathbf{1}_{U(n,\epsilon)} \mathrm{d}m = 0$$ where $\mathbf{1}_A$ is the indicator function of set $A$ . However, I'm looking for ways to prove this without DCT. Another thing I noticed is that $(U(n,\epsilon))^c = [0,1]\setminus U(n,\epsilon)$ is compact, since it is closed and bounded. It is obviously bounded since it is contained in $[0,1]$ and it is closed since it is the continuous pull-back of a closed set, namely $[0,\epsilon]$ . Clearly, $U(n,\epsilon)$ is open. Any thoughts on what to do next? Thank you.","Suppose is a sequence of continuous functions on such that for every , for every . Define for . Prove that where is the restriction of the Lebesgue measure to . Try not to use anything fancy such as the Dominated Convergence Theorem (DCT). Try to work with the assumptions directly, such as continuity of and compactness of . I didn't make substantial progress, but let me collect all my thoughts here. I saw that If we could use the DCT, I would do (hope it's correct) where is the indicator function of set . However, I'm looking for ways to prove this without DCT. Another thing I noticed is that is compact, since it is closed and bounded. It is obviously bounded since it is contained in and it is closed since it is the continuous pull-back of a closed set, namely . Clearly, is open. Any thoughts on what to do next? Thank you.","(f_n)_{n\in\mathbb N} [0,1] f_n(x) \xrightarrow{n\to\infty} 0 0\le x\le 1 0\le f_n\le 1 n\in\mathbb N U(n,\epsilon) = \{x: f_n(x) > \epsilon\} \epsilon > 0 m(U(n,\epsilon)) \xrightarrow{n\to\infty} 0 m [0,1] f_n [0,1] \bigcap_{n=1}^\infty U(n,\epsilon) = \varnothing \lim_{n\to\infty} m(U(n,\epsilon)) = \lim_{n\to\infty}\int_0^1 \mathbf{1}_{U(n,\epsilon)} \mathrm{d}m = \int_0^1 \lim_{n\to\infty}\mathbf{1}_{U(n,\epsilon)} \mathrm{d}m = 0 \mathbf{1}_A A (U(n,\epsilon))^c = [0,1]\setminus U(n,\epsilon) [0,1] [0,\epsilon] U(n,\epsilon)","['real-analysis', 'measure-theory']"
4,"Problem $2.17$, Rudin's RCA (Dictionary Order Topology)","Problem , Rudin's RCA (Dictionary Order Topology)",2.17,"Problem $2.17$ : Define the distance between the points $(x_1,y_1)$ and $(x_2,y_2)$ in the plane to be $$|y_1-y_2| \quad \text{if }x_1 = x_2, \quad\quad 1+|y_1 - y_2|\quad \text{if } x_1\ne x_2$$ Show that this is indeed a metric, and that the resulting metric space $X$ is locally compact. If $f\in C_c(X)$ , let $x_1,\ldots,x_n$ be those values of $x$ for which $f(x,y)\ne 0$ for at least one $y$ (there are only finitely many such $x$ !), and define $$\Lambda f = \sum_{j=1}^n \int_{-\infty}^\infty f(x_j,y)\ dy$$ Let $\mu$ be the measure associated with this $\Lambda$ by Theorem $2.14$ . If $E$ is the $x$ -axis, show that $\mu(E) = \infty$ although $\mu(K) = 0$ for every compact $K\subset E$ . Theorem $2.14$ above refers to the Riesz representation theorem, which relates $\mu$ with the linear functional $\Lambda$ . I found a solution to the above problem here , which I need some help with understanding. I've reproduced it to the extent necessary below. Hereafter, the distance defined above (between points in $\mathbb R^2$ ) is represented by $d$ , and it is indeed a metric. It was also proved that $(X,\tau)$ is a LCHS (locally compact Hausdorff space), by identifying it as $(X,\tau) = (\mathbb R, \tau_1) \times (\mathbb R,\tau_2)$ where $\tau_1$ is the discrete topology on $\mathbb R$ , and $\tau_2$ is the usual one. If $d_1$ and $d_2$ are the metrics corresponding to these topologies, it is easy to see that the product metric $d = d_1 + d_2$ . Now, the real problem begins. If $f\in C_c(X)$ , why is it that there are only finitely many $x$ for which $f(x,y)\ne 0$ for at least one $y$ ? The link I've attached says: If $K$ is compact in $X$ , the first projection $\text{pr}_1(K)$ is compact in $(\mathbb R, τ_1)$ . Hence it is a finite set. Therefore $K$ is a finite union $$\{x_1\} × K_1 ∪ · · · ∪ \{x_n\} × K_n$$ where each $K_i$ , $i = 1, 2, . . . , n$ , is a compact set in $(\mathbb R, τ_2)$ . Here's my reasoning (please confirm if it is correct): Take $K = \text{supp}(f) = \overline{\{(x,y): f(x,y)\ne 0\}}$ . Since $f\in C_c(X)$ , $K$ is compact, and its projection $\text{pr}_1(K)$ is also compact. In the discrete topology, sets are compact iff they are finite, so $\text{pr}_1(K)$ is finite. Since projection maps preserve inclusion, we have $\text{pr}_1(\{(x,y): f(x,y)\ne 0\}) \subset \text{pr}_1(K)$ is finite. Now, $\text{pr}_1(\{(x,y): f(x,y)\ne 0\}) = \{x: \exists y, f(x,y)\ne 0\}$ which is finite (as the claim requires). In the very next paragraph, they mention that the support of $f\in C_c(X)$ is contained in $\{x_1,x_2,\ldots,x_n\}\times\mathbb R$ . How do we use this to deduce that $\Lambda$ is a positive linear functional on $C_c(X)$ ? How do we get $\mu(\{x\} \times K) = m(K)$ ? Let $V$ be an open set containing $\mathbb R × \{0\}$ . Then for $x ∈ \mathbb R$ , $(x, 0) ∈ V$ , so that there exists an $ε_x > 0$ with $\{x\} × [−ε_x, ε_x] ⊂ V$ . This implies that there must be an $n$ with uncountably many $ε_x \ge 1/n$ . (Otherwise, $ε_x \ge 1/n$ for at most countably many $x$ , contradicting the fact that $\mathbb R$ is uncountable.) Let $K_x = \{x\} \times [-ε_x/2,ε_x/2]$ for $ε_x \ge 1/n$ . For $K = \bigcup_{j=1}^m K_{x_j}$ , we have $\mu(K) \ge m/n$ . Hence, if $V ⊃ \mathbb R × \{0\}$ is open, then $\mu(V ) ≥ \sup_{m∈\mathbb N} m/n= ∞$ . This implies $\mu(\mathbb R × \{0\}) = ∞$ . How do we get $\{x\} × [−ε_x, ε_x] ⊂ V$ ? I know the idea is that there exists some $\epsilon_x$ such that the open ball of this radius centered at $x$ is in $V$ , but why do open balls in this topology look like this? Also, I didn't really understand what was done after this to show $\mu(\mathbb R × \{0\}) = ∞$ , and I'd appreciate if someone could explain in detail. Thank you!","Problem : Define the distance between the points and in the plane to be Show that this is indeed a metric, and that the resulting metric space is locally compact. If , let be those values of for which for at least one (there are only finitely many such !), and define Let be the measure associated with this by Theorem . If is the -axis, show that although for every compact . Theorem above refers to the Riesz representation theorem, which relates with the linear functional . I found a solution to the above problem here , which I need some help with understanding. I've reproduced it to the extent necessary below. Hereafter, the distance defined above (between points in ) is represented by , and it is indeed a metric. It was also proved that is a LCHS (locally compact Hausdorff space), by identifying it as where is the discrete topology on , and is the usual one. If and are the metrics corresponding to these topologies, it is easy to see that the product metric . Now, the real problem begins. If , why is it that there are only finitely many for which for at least one ? The link I've attached says: If is compact in , the first projection is compact in . Hence it is a finite set. Therefore is a finite union where each , , is a compact set in . Here's my reasoning (please confirm if it is correct): Take . Since , is compact, and its projection is also compact. In the discrete topology, sets are compact iff they are finite, so is finite. Since projection maps preserve inclusion, we have is finite. Now, which is finite (as the claim requires). In the very next paragraph, they mention that the support of is contained in . How do we use this to deduce that is a positive linear functional on ? How do we get ? Let be an open set containing . Then for , , so that there exists an with . This implies that there must be an with uncountably many . (Otherwise, for at most countably many , contradicting the fact that is uncountable.) Let for . For , we have . Hence, if is open, then . This implies . How do we get ? I know the idea is that there exists some such that the open ball of this radius centered at is in , but why do open balls in this topology look like this? Also, I didn't really understand what was done after this to show , and I'd appreciate if someone could explain in detail. Thank you!","2.17 (x_1,y_1) (x_2,y_2) |y_1-y_2| \quad \text{if }x_1 = x_2, \quad\quad 1+|y_1 - y_2|\quad \text{if } x_1\ne x_2 X f\in C_c(X) x_1,\ldots,x_n x f(x,y)\ne 0 y x \Lambda f = \sum_{j=1}^n \int_{-\infty}^\infty f(x_j,y)\ dy \mu \Lambda 2.14 E x \mu(E) = \infty \mu(K) = 0 K\subset E 2.14 \mu \Lambda \mathbb R^2 d (X,\tau) (X,\tau) = (\mathbb R, \tau_1) \times (\mathbb R,\tau_2) \tau_1 \mathbb R \tau_2 d_1 d_2 d = d_1 + d_2 f\in C_c(X) x f(x,y)\ne 0 y K X \text{pr}_1(K) (\mathbb R, τ_1) K \{x_1\} × K_1 ∪ · · · ∪ \{x_n\} × K_n K_i i = 1, 2, . . . , n (\mathbb R, τ_2) K = \text{supp}(f) = \overline{\{(x,y): f(x,y)\ne 0\}} f\in C_c(X) K \text{pr}_1(K) \text{pr}_1(K) \text{pr}_1(\{(x,y): f(x,y)\ne 0\}) \subset \text{pr}_1(K) \text{pr}_1(\{(x,y): f(x,y)\ne 0\}) = \{x: \exists y, f(x,y)\ne 0\} f\in C_c(X) \{x_1,x_2,\ldots,x_n\}\times\mathbb R \Lambda C_c(X) \mu(\{x\} \times K) = m(K) V \mathbb R × \{0\} x ∈ \mathbb R (x, 0) ∈ V ε_x > 0 \{x\} × [−ε_x, ε_x] ⊂ V n ε_x \ge 1/n ε_x \ge 1/n x \mathbb R K_x = \{x\} \times [-ε_x/2,ε_x/2] ε_x \ge 1/n K = \bigcup_{j=1}^m K_{x_j} \mu(K) \ge m/n V ⊃ \mathbb R × \{0\} \mu(V ) ≥ \sup_{m∈\mathbb N} m/n= ∞ \mu(\mathbb R × \{0\}) = ∞ \{x\} × [−ε_x, ε_x] ⊂ V \epsilon_x x V \mu(\mathbb R × \{0\}) = ∞","['real-analysis', 'measure-theory', 'proof-explanation', 'riesz-representation-theorem']"
5,Measurability and $\mathbb P$-a.s. or everywhere,Measurability and -a.s. or everywhere,\mathbb P,"I have two questions that are quite related: The predictable $\sigma$ -algebra $\mathcal P$ is defined as the smallest $\sigma$ -algebra making all adapted left-continuous processes measurable. Does left-continuity need to be everywhere or does $\mathbb P$ -a.s. also work? If a stochastic process $X:\Omega\times [0,\infty)\to\mathbb R$ (thus, $X(\cdot ,t)$ is a random variable for all $t$ ) is $\mathbb P$ -a.s. continuous, is it jointly measurable? I have seen many related questions like this on StackExchange, but often the usual conditions are not stated, hence my questions have not really been adressed. Therefore, assuming the usual conditions, what are the answers to 1. and 2.? Importantly note: I am aware that $X$ is indistinguishable from a jointly measurable map and that $X:\Omega'\times [0,\infty)\to \mathbb R$ , where $\Omega'=\Omega\backslash N$ with $N$ as below, is jointly measurable. A possible rephrasing of 1 and 2 (in more generality): if $X$ is $\mathcal A$ -measurable, and $Y$ is indistinguishable from $X$ , is $Y$ also $\mathcal A$ -measurable? If this does not hold in generality, then let's get back to 2. My try on 2.: I know $X$ is indistinguishable from a process $Y$ with continuous paths everywhere. Hence let $N$ be the $\mathbb P$ -null on which $X$ and $Y$ do not coincide. We can write $$X^{-1}(A)=(X^{-1}(A)\cap (N\times [0,\infty)))\cup (X^{-1}(A)\cap ((\Omega\backslash N)\times [0,\infty))),$$ where the latter is $\mathcal F\times \mathcal B$ -measurable, but the first part I do not know. Edit: Do a.s. right-continuous paths imply product measurability has a useful answer to part 2.  Then why do we even start with $\mathbb P$ -a.s. caglad and caglad processes, for instance. If I want to look at the Lebesgue-Stieltjes integral $$\int _0^tHdA,$$ then $H$ needs to be jointly measurable, so then we take the version of $H$ that is jointly measurable? Seems like an enormous detour. Also, one often shows the inclusions $$\mathcal P\subset \mathcal O\subset \mathcal M\subset \mathcal B\times \mathcal F,$$ the predictably, optional, progressively, and product sigma algebra. But these are the generating $\sigma$ -algebra where the propery then holds everywhere? Clarification regarding question 1.: What is the correct definition of $\mathcal P$ ? a. $\mathcal P=\sigma(X:X$ is an adapted processes with left-continuous paths everywhere); b. $\mathcal P=\sigma(X:X$ is an adapted processes with left-continuous paths a.e.); Or does a. and b. give the same result? (Do not think so by the way. Can you work with b. in the first place?)","I have two questions that are quite related: The predictable -algebra is defined as the smallest -algebra making all adapted left-continuous processes measurable. Does left-continuity need to be everywhere or does -a.s. also work? If a stochastic process (thus, is a random variable for all ) is -a.s. continuous, is it jointly measurable? I have seen many related questions like this on StackExchange, but often the usual conditions are not stated, hence my questions have not really been adressed. Therefore, assuming the usual conditions, what are the answers to 1. and 2.? Importantly note: I am aware that is indistinguishable from a jointly measurable map and that , where with as below, is jointly measurable. A possible rephrasing of 1 and 2 (in more generality): if is -measurable, and is indistinguishable from , is also -measurable? If this does not hold in generality, then let's get back to 2. My try on 2.: I know is indistinguishable from a process with continuous paths everywhere. Hence let be the -null on which and do not coincide. We can write where the latter is -measurable, but the first part I do not know. Edit: Do a.s. right-continuous paths imply product measurability has a useful answer to part 2.  Then why do we even start with -a.s. caglad and caglad processes, for instance. If I want to look at the Lebesgue-Stieltjes integral then needs to be jointly measurable, so then we take the version of that is jointly measurable? Seems like an enormous detour. Also, one often shows the inclusions the predictably, optional, progressively, and product sigma algebra. But these are the generating -algebra where the propery then holds everywhere? Clarification regarding question 1.: What is the correct definition of ? a. is an adapted processes with left-continuous paths everywhere); b. is an adapted processes with left-continuous paths a.e.); Or does a. and b. give the same result? (Do not think so by the way. Can you work with b. in the first place?)","\sigma \mathcal P \sigma \mathbb P X:\Omega\times [0,\infty)\to\mathbb R X(\cdot ,t) t \mathbb P X X:\Omega'\times [0,\infty)\to \mathbb R \Omega'=\Omega\backslash N N X \mathcal A Y X Y \mathcal A X Y N \mathbb P X Y X^{-1}(A)=(X^{-1}(A)\cap (N\times [0,\infty)))\cup (X^{-1}(A)\cap ((\Omega\backslash N)\times [0,\infty))), \mathcal F\times \mathcal B \mathbb P \int _0^tHdA, H H \mathcal P\subset \mathcal O\subset \mathcal M\subset \mathcal B\times \mathcal F, \sigma \mathcal P \mathcal P=\sigma(X:X \mathcal P=\sigma(X:X","['measure-theory', 'stochastic-processes', 'measurable-functions']"
6,Why is this set Lebesgue measurable?,Why is this set Lebesgue measurable?,,"$K$ : Cantor set $f$ : $[0,1] \to K$ We can write $\displaystyle x=\sum_{k=1}^\infty \frac{\varepsilon_k}{2^k} \ (\varepsilon_k = 0,1)$ for all $x \in [0,1]$ by binary expansion. Define $$ f(x)=f \left( \sum_{k=1}^\infty \frac{\varepsilon_k}{2^k} \right) = \sum_{k=1}^\infty \dfrac{2\varepsilon_k}{3^k}.$$ Then, prove that $\{f >a \}=\{x\in [0,1] \mid f(x) >a \}$ is Lebesgue measurable for all $a\in \mathbb{R}$ . If $a< 0,$ $\{ f>a \}=[0,1]$ and it is Lebesgue measurable. But what about for $0\leqq a$ ? I don't know how $\{f >a \}$ is expressed for $0\leqq a$ .",": Cantor set : We can write for all by binary expansion. Define Then, prove that is Lebesgue measurable for all . If and it is Lebesgue measurable. But what about for ? I don't know how is expressed for .","K f [0,1] \to K \displaystyle x=\sum_{k=1}^\infty \frac{\varepsilon_k}{2^k} \ (\varepsilon_k = 0,1) x \in [0,1]  f(x)=f \left( \sum_{k=1}^\infty \frac{\varepsilon_k}{2^k} \right) = \sum_{k=1}^\infty \dfrac{2\varepsilon_k}{3^k}. \{f >a \}=\{x\in [0,1] \mid f(x) >a \} a\in \mathbb{R} a< 0, \{ f>a \}=[0,1] 0\leqq a \{f >a \} 0\leqq a","['measure-theory', 'lebesgue-measure', 'measurable-functions']"
7,Show that $\frac\partial{\partial r}\int_{B_r(x)}f=\int_{\partial B_r(x)}f$,Show that,\frac\partial{\partial r}\int_{B_r(x)}f=\int_{\partial B_r(x)}f,"Let $\lambda$ denote the Lebesgue measure on $\mathbb R$ , $d\in\mathbb N$ , $f\in C(\mathbb R^d)$ , $x\in\mathbb R^d$ and $$g(r):=\int_{B_r(x)}f\:{\rm d}\lambda^{\otimes d}\;\;\;\text{for }r>0.$$ I would like to show that $^1$ $$g'(r)=\int f\:{\rm d}\sigma_{\partial B_r(x)}\tag0.$$ For clarity of exposition, let $$\tau_x:\mathbb R^d\to\mathbb R^d\;,\;\;\;y\mapsto y+x$$ and $$\theta_r:\mathbb R^d\to\mathbb R^d\;,\;\;\;x\mapsto rx.$$ We know that $\tau_x\left(\lambda^{\otimes d}\right)=\lambda^{\otimes d}$ ; $\theta_r\left(\lambda^{\otimes d}\right)=r^{-d}\lambda^{\otimes d}$ for all $r>0$ ; $B_r(x)=rB_1(0)+x=\tau_x\left(\theta_r\left(B_1(0)\right)\right)$ for all $r>0$ and $$\int_M\frac{\partial\varphi}{\partial x_i}\psi\:{\rm d}\lambda^{\otimes d}=\int\varphi\psi\left(\nu_{\partial M}\right)_i\:{\rm d}\sigma_{\partial M}-\int_M\varphi\frac{\partial\psi}{\partial x_i}\:{\rm d}\lambda^{\otimes d}\tag4$$ for every bounded $d$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ with boundary and $C^1$ -differentiable $\varphi,\psi:M\to\mathbb R$ , where $\nu_{\partial M}$ denotes the unit outward pointing normal field on $\partial M$ . So, $$g(r)=r^d\int_{B_1(0)}f\circ\tau_x\circ\theta_r\:{\rm d}\lambda^{\otimes d}\tag5$$ and $$\int f\:{\rm d}\sigma_{\partial B_r(x)}=r^{d-1}\int f\circ\tau_x\circ\theta_r\:{\rm d}\sigma_{\partial B_1(0)}\tag6.$$ However, I still don't see how we obtain $(0)$ . In order to proceed with $(5)$ , I would usually ""differentiate under the integral sign"", but in order to do that, we would need to assume that $f$ is differentiable. On the other hand, even if I do assume differentiability, this should yield $$g'(r)=dr^d\int_{B_r(x)}\langle y-x,\nabla f(y)\rangle\:\lambda^{\otimes d}({\rm d}y)\tag7$$ and applying $(4)$ , we should obtain $$\int_{B_r(x)}\langle y-x,\nabla f(y)\rangle\:\lambda^{\otimes d}({\rm d}y)=\int f(y)\langle y-x,\nu_{\partial M}(y)\rangle\:{\rm d}\sigma_{\partial B_r(x)}-d\int_{B_r(x)}f\:{\rm d}\lambda^{\otimes d},\tag8$$ which doesn't seem to be helpful. So, what am I missing and how can we prove claim without assuming differentiability of $f$ ? $^1$ Let $\sigma_M$ denote the surface measure on $\mathcal B(M)$ for every embedded $C^1$ -submanifold $M$ of $\mathbb R^d$ .","Let denote the Lebesgue measure on , , , and I would like to show that For clarity of exposition, let and We know that ; for all ; for all and for every bounded -dimensional embedded -submanifold of with boundary and -differentiable , where denotes the unit outward pointing normal field on . So, and However, I still don't see how we obtain . In order to proceed with , I would usually ""differentiate under the integral sign"", but in order to do that, we would need to assume that is differentiable. On the other hand, even if I do assume differentiability, this should yield and applying , we should obtain which doesn't seem to be helpful. So, what am I missing and how can we prove claim without assuming differentiability of ? Let denote the surface measure on for every embedded -submanifold of .","\lambda \mathbb R d\in\mathbb N f\in C(\mathbb R^d) x\in\mathbb R^d g(r):=\int_{B_r(x)}f\:{\rm d}\lambda^{\otimes d}\;\;\;\text{for }r>0. ^1 g'(r)=\int f\:{\rm d}\sigma_{\partial B_r(x)}\tag0. \tau_x:\mathbb R^d\to\mathbb R^d\;,\;\;\;y\mapsto y+x \theta_r:\mathbb R^d\to\mathbb R^d\;,\;\;\;x\mapsto rx. \tau_x\left(\lambda^{\otimes d}\right)=\lambda^{\otimes d} \theta_r\left(\lambda^{\otimes d}\right)=r^{-d}\lambda^{\otimes d} r>0 B_r(x)=rB_1(0)+x=\tau_x\left(\theta_r\left(B_1(0)\right)\right) r>0 \int_M\frac{\partial\varphi}{\partial x_i}\psi\:{\rm d}\lambda^{\otimes d}=\int\varphi\psi\left(\nu_{\partial M}\right)_i\:{\rm d}\sigma_{\partial M}-\int_M\varphi\frac{\partial\psi}{\partial x_i}\:{\rm d}\lambda^{\otimes d}\tag4 d C^1 \mathbb R^d C^1 \varphi,\psi:M\to\mathbb R \nu_{\partial M} \partial M g(r)=r^d\int_{B_1(0)}f\circ\tau_x\circ\theta_r\:{\rm d}\lambda^{\otimes d}\tag5 \int f\:{\rm d}\sigma_{\partial B_r(x)}=r^{d-1}\int f\circ\tau_x\circ\theta_r\:{\rm d}\sigma_{\partial B_1(0)}\tag6. (0) (5) f g'(r)=dr^d\int_{B_r(x)}\langle y-x,\nabla f(y)\rangle\:\lambda^{\otimes d}({\rm d}y)\tag7 (4) \int_{B_r(x)}\langle y-x,\nabla f(y)\rangle\:\lambda^{\otimes d}({\rm d}y)=\int f(y)\langle y-x,\nu_{\partial M}(y)\rangle\:{\rm d}\sigma_{\partial B_r(x)}-d\int_{B_r(x)}f\:{\rm d}\lambda^{\otimes d},\tag8 f ^1 \sigma_M \mathcal B(M) C^1 M \mathbb R^d","['real-analysis', 'measure-theory', 'differential-geometry', 'lebesgue-integral', 'divergence-theorem']"
8,Integration of function with respect to counting measure,Integration of function with respect to counting measure,,"Consider the measurable space $\left(\mathbb{N},\mathscr{P}(\mathbb{N})\right)$ with the counting measure $c$ and let $f\colon\mathbb{N}\to\mathbb{R}$ be any function. I want to show that $$\int_{\mathbb{N}}f\,dc = \sum_{n=1}^{\infty}f(n).\tag{1}$$ I've seen the proof (on StackExchange) that $(1)$ holds given that $f\colon\mathbb{N}\to[0,\infty]$ , but not for this particular problem. Further, the proof in that case uses the Monotone Convergence Theorem as $f$ is non-negative. However, how can I do the proof without the assumption that $f$ is non-negative, i.e. without the Monotone Convergence Theorem? Moreover, is there anyway to modify the proof for case that $f$ is non-negaive? To add, I know some convergence theorem needs to hold, more than likely the Dominated Convergence Theorem, but I can figure out a sequence of functions that work. For the non-negative case, the sequence of functions given by $$ f_n(k)=\begin{cases}f(k) & \text{if }1\leq k\leq n\\ 0 & \text{else}\end{cases}, $$ for $n\in\mathbb{N}$ works.","Consider the measurable space with the counting measure and let be any function. I want to show that I've seen the proof (on StackExchange) that holds given that , but not for this particular problem. Further, the proof in that case uses the Monotone Convergence Theorem as is non-negative. However, how can I do the proof without the assumption that is non-negative, i.e. without the Monotone Convergence Theorem? Moreover, is there anyway to modify the proof for case that is non-negaive? To add, I know some convergence theorem needs to hold, more than likely the Dominated Convergence Theorem, but I can figure out a sequence of functions that work. For the non-negative case, the sequence of functions given by for works.","\left(\mathbb{N},\mathscr{P}(\mathbb{N})\right) c f\colon\mathbb{N}\to\mathbb{R} \int_{\mathbb{N}}f\,dc = \sum_{n=1}^{\infty}f(n).\tag{1} (1) f\colon\mathbb{N}\to[0,\infty] f f f 
f_n(k)=\begin{cases}f(k) & \text{if }1\leq k\leq n\\ 0 & \text{else}\end{cases},
 n\in\mathbb{N}",['measure-theory']
9,Computing $n$-dimensional Lebesgue measure with Euclidean $n$-balls,Computing -dimensional Lebesgue measure with Euclidean -balls,n n,"I am studying the coarea formula proof from Evans and Gariepy's Measure Theory and Fine Properties of Functions . At the start of lemma 3.5, the authors are assuming that we can compute the $n$ -dimensional Lebesgue measure from coverings of closed balls, namely, that the Lebesgue measure of a measurable set $A\subseteq\mathbb R^n$ equals $$\text{inf}\left\{\left.\sum_{i=1}^\infty\mathcal L^n(B_i)\,\right|A\subseteq\bigcup_{i=1}^\infty B_i,\,B_i\text{ closed ball in }\mathbb R^n\,\right\}$$ I don't think this assumption is obvious at all. I have searched for a while and I have not encountered yet a justification for this. In the only answer to this question , some corollary of the Vitali covering lemma is applied. However, no-one can guarantee that the disjoint closed balls that approximate the rectangles of any covering of $A$ are going to contain, in their union, the set $A$ we are interested in... Thanks in advance for your answers.","I am studying the coarea formula proof from Evans and Gariepy's Measure Theory and Fine Properties of Functions . At the start of lemma 3.5, the authors are assuming that we can compute the -dimensional Lebesgue measure from coverings of closed balls, namely, that the Lebesgue measure of a measurable set equals I don't think this assumption is obvious at all. I have searched for a while and I have not encountered yet a justification for this. In the only answer to this question , some corollary of the Vitali covering lemma is applied. However, no-one can guarantee that the disjoint closed balls that approximate the rectangles of any covering of are going to contain, in their union, the set we are interested in... Thanks in advance for your answers.","n A\subseteq\mathbb R^n \text{inf}\left\{\left.\sum_{i=1}^\infty\mathcal L^n(B_i)\,\right|A\subseteq\bigcup_{i=1}^\infty B_i,\,B_i\text{ closed ball in }\mathbb R^n\,\right\} A A","['measure-theory', 'lebesgue-measure', 'geometric-measure-theory']"
10,Measurability and Open Sets,Measurability and Open Sets,,"I have a homework question, as follows: Can there be a Lebesgue measurable set $A$ such that $$\lambda(A\cap U)=\frac{\lambda(U)}{2}$$ for all open sets $U$ ? I’ve made two observations: If such an $A$ exists, it’s measure must be infinity, since $$\lambda(A\cap \mathbb{R})=\lambda(A)=\frac{\lambda(\mathbb{R})}{2}$$ If such an $A$ exists, it cannot contain an open subset $U$ , since $$\lambda(A\cap U)=\lambda(U)=\frac{\lambda(U)}{2} $$ which implies that an open set has nonpositive measure, a contradiction. Past these observations I’m stuck, and have no real intuition on whether this thing should exist or not. My gut says no, as it seems too convenient to let us pick among every open set and this nice equality holds, but I can’t seem to pin a contradiction. I was hoping there would be some implication that the measure of $A$ was also finite, which would imply that it couldn’t exist.","I have a homework question, as follows: Can there be a Lebesgue measurable set such that for all open sets ? I’ve made two observations: If such an exists, it’s measure must be infinity, since If such an exists, it cannot contain an open subset , since which implies that an open set has nonpositive measure, a contradiction. Past these observations I’m stuck, and have no real intuition on whether this thing should exist or not. My gut says no, as it seems too convenient to let us pick among every open set and this nice equality holds, but I can’t seem to pin a contradiction. I was hoping there would be some implication that the measure of was also finite, which would imply that it couldn’t exist.",A \lambda(A\cap U)=\frac{\lambda(U)}{2} U A \lambda(A\cap \mathbb{R})=\lambda(A)=\frac{\lambda(\mathbb{R})}{2} A U \lambda(A\cap U)=\lambda(U)=\frac{\lambda(U)}{2}  A,"['measure-theory', 'lebesgue-measure']"
11,"If $|E| = 0$, then there exists $h \in \mathbb{R}$ such that $E+h$ does not contain a rational point.","If , then there exists  such that  does not contain a rational point.",|E| = 0 h \in \mathbb{R} E+h,"Here we are trying to show that if a set $E$ has zero (Lebesgue) measure, then there is a point $h \in \mathbb{R}$ such that $E+h$ does not contain a rational point. I tried to solve this using contradiction. The argument goes as follows: Suppose that for every $h \in \mathbb{R}$ we can find a rational point in $E+h$ . From here I am trying to show that if this is the case, then the measure of $E$ would not be zero, thus proving our claim. However, I am not sure how to formulate the argument to get to the end. I already looked at the previous questions posted on here for this type of problem, but it did not make much sense to me. Any help would be appreciated!","Here we are trying to show that if a set has zero (Lebesgue) measure, then there is a point such that does not contain a rational point. I tried to solve this using contradiction. The argument goes as follows: Suppose that for every we can find a rational point in . From here I am trying to show that if this is the case, then the measure of would not be zero, thus proving our claim. However, I am not sure how to formulate the argument to get to the end. I already looked at the previous questions posted on here for this type of problem, but it did not make much sense to me. Any help would be appreciated!",E h \in \mathbb{R} E+h h \in \mathbb{R} E+h E,"['real-analysis', 'measure-theory']"
12,Completing the proof of a theorem,Completing the proof of a theorem,,"My question is about the proof of the Theorem 1.3 which is on the page 9 of the book ""Topics in Real Analysis"" , which is available electronically through the previous link. I want to demonstrate that theorem in the case $\mu (X)=\infty$ . In that book there's the following tip: To extend our result to the general case observe that the finite case implies $\mu (A\cap X_j)=\tilde \mu (A\cap X_j)$ ( just restrict $\mu,\tilde\mu$ to $X_j$ ). Hence $$\mu (A)=\lim_{j\to\infty}\mu (A\cap X_j)=\lim_{j\to \infty}\tilde \mu(A\cap X_j)=\tilde \mu (A)$$ Below is my attempt to use that tip to prove that theorem in the case $\mu (X)=\infty$ . Let $j\in\mathbb{N}$ be any element and define $S_j:=\big\{E\cap X_j:E\in S\big\}$ . It's trivial to verify that $S_j$ is a $\pi$ -system (because $S$ is by hypothesis a $\pi$ -system). Besides, since $X_j\in S$ , then $S_j\subseteq S$ which implies that $\Sigma (S_j)\subseteq\Sigma (S)=\Sigma $ in which $\Sigma (S_j)$ means the $\sigma$ -algebra generated by $S_j$ . Let $\mu _{S_j}$ and $\tilde \mu _{S_j}$ , respectively, be the restrictions of $\mu$ and $\tilde \mu$ to $\Sigma(S_j)$ . It's easy to see that $(X_j,\Sigma (S_j),\mu_{S_j})$ is a measure space. The elements of $\{X_j\cap X_n\}_{n\in\mathbb{N}}$ belongs to $S_j$ and satisfy $(X_j\cap X_n)\nearrow X_j$ and $\mu_{X_j}(X_j\cap X_n)<\infty $ for all $n\in\mathbb{N}$ . Because of the above considerations and $\mu_{S_j}(X_j)<\infty$ , we can use the first part of the proof of the Theorem 1.3 which is in the book mentioned above to prove that $\mu_{S_j}(E)=\tilde \mu_{S_j}(E)\,\,\color{red}{(1)}$ for all $E\in \Sigma (S_j)$ . Let $A\in\Sigma $ be any element. If there's a $j\in\mathbb{N}$ such that $A\cap X_j\in \Sigma (S_j)$ , then I can use $(1)$ and that tip above to prove that $\mu (A)=\tilde \mu (A)$ . However, if $A\cap X_j\,\,{\color{red}{\notin}} \,\,\Sigma (S_j)$ for all $j\in\mathbb{N}$ , then I can't use $(1)$ and, therefore, that tip is useless. Please help me to finish the proof. At least indicate some reference that contains the proof of that theorem. Thank you for your attention!","My question is about the proof of the Theorem 1.3 which is on the page 9 of the book ""Topics in Real Analysis"" , which is available electronically through the previous link. I want to demonstrate that theorem in the case . In that book there's the following tip: To extend our result to the general case observe that the finite case implies ( just restrict to ). Hence Below is my attempt to use that tip to prove that theorem in the case . Let be any element and define . It's trivial to verify that is a -system (because is by hypothesis a -system). Besides, since , then which implies that in which means the -algebra generated by . Let and , respectively, be the restrictions of and to . It's easy to see that is a measure space. The elements of belongs to and satisfy and for all . Because of the above considerations and , we can use the first part of the proof of the Theorem 1.3 which is in the book mentioned above to prove that for all . Let be any element. If there's a such that , then I can use and that tip above to prove that . However, if for all , then I can't use and, therefore, that tip is useless. Please help me to finish the proof. At least indicate some reference that contains the proof of that theorem. Thank you for your attention!","\mu (X)=\infty \mu (A\cap X_j)=\tilde \mu (A\cap X_j) \mu,\tilde\mu X_j \mu (A)=\lim_{j\to\infty}\mu (A\cap X_j)=\lim_{j\to \infty}\tilde \mu(A\cap X_j)=\tilde \mu (A) \mu (X)=\infty j\in\mathbb{N} S_j:=\big\{E\cap X_j:E\in S\big\} S_j \pi S \pi X_j\in S S_j\subseteq S \Sigma (S_j)\subseteq\Sigma (S)=\Sigma  \Sigma (S_j) \sigma S_j \mu _{S_j} \tilde \mu _{S_j} \mu \tilde \mu \Sigma(S_j) (X_j,\Sigma (S_j),\mu_{S_j}) \{X_j\cap X_n\}_{n\in\mathbb{N}} S_j (X_j\cap X_n)\nearrow X_j \mu_{X_j}(X_j\cap X_n)<\infty  n\in\mathbb{N} \mu_{S_j}(X_j)<\infty \mu_{S_j}(E)=\tilde \mu_{S_j}(E)\,\,\color{red}{(1)} E\in \Sigma (S_j) A\in\Sigma  j\in\mathbb{N} A\cap X_j\in \Sigma (S_j) (1) \mu (A)=\tilde \mu (A) A\cap X_j\,\,{\color{red}{\notin}} \,\,\Sigma (S_j) j\in\mathbb{N} (1)",['measure-theory']
13,"identifying the measure $\lambda f^{-1}$ on the interval $[0,1]$",identifying the measure  on the interval,"\lambda f^{-1} [0,1]","Let $X_i=\{0,1\}$ be the space equipped with the measure $\mu$ s.t. $\mu(\{0\})=\mu(\{1\})=\frac{1}{2}$ . Now define $\Omega$ to be the product space of $X_i$ 's with the product $\sigma$ -field and the product measure $\lambda$ . Consider the map $$f:\Omega\to[0,1]$$ $$\omega=(x_1,\ldots,x_n,...)\mapsto\sum_{j=1}^{\infty}\frac{x_j}{2^j}\in[0,1]$$ My aim is to identify the measure $\lambda f^{-1}$ on the interval $[0,1]$ . First, I take an example. I take $E=(\frac{3}{4},\frac{7}{8})$ , which is a dyadic interval. With the binary expansion defined, we see that $f^{-1}(E)=\{1\}\times\{1\}\times\{0\}\times\ldots$ , a cylinder with volume $\frac{1}{8}$ . Hence, $(\lambda f^{-1})(E)=\lambda(f^{-1}(E))=\frac{1}{8}$ . We can say $\lambda f^{-1}(E)=m(E)$ , where $m$ is the Lebesgue/Borel measure, for every dyadic interval. We can conclude that $\lambda f^{-1}$ is just the standard Borel measure on $[0,1]$ . Details added: Let $E=\left(\frac{k}{2^j},\frac{k+1}{2^j}\right)$ with $n\in\mathbb{N}$ and $0\leq k<2^j$ . Let $x=x_1\ldots x_j$ be the binary expansion, with two exceptions $x=\frac{k}{j}$ and $x=\frac{k+1}{j}$ . Hence $f^{-1}(E)=F\setminus\{p,q\}$ , where $F$ consists of all sequences that start with $x$ and $p=(x,0,0,\ldots)$ and $q=(x,1,1,\ldots)$ . It is clear that $\lambda(F)=2^{-j}$ by definition of the product measure, and $\lambda(\{p\})=\lambda(\{q\})=0$ . Hence $\lambda\left(f^{-1}(E)\right)=2^{-j}$ , which is the Borel measure of $E$ . Since the dyadic intervals generate $\mathcal{B}$ , $\lambda\left(f^{-1}(E)\right)=m(E)$ for any measurable $E$ , and $m$ is the Borel measure on $[0,1]$ . Does this complete the proof for dyadic intervals? I think my statement is correct, but I need a proof to generalize it, instead of just taking dyadic intervals. Here is a post regarding a similar problem as mine: identify the interval $[0, 1]$ with the Lebesgue measure to the probability space for tossing a fair coin . The result is that $f(\omega)$ is almost bijective, meaning that $f(\omega)$ is a bijection except at countably many points $x\in[0,1]$ that have two inverse images; $f(\omega)$ is measure-preserving. Are these two results from this post helpful for writing a rigorous proof regarding my statement? And how can I do that? Thank you.","Let be the space equipped with the measure s.t. . Now define to be the product space of 's with the product -field and the product measure . Consider the map My aim is to identify the measure on the interval . First, I take an example. I take , which is a dyadic interval. With the binary expansion defined, we see that , a cylinder with volume . Hence, . We can say , where is the Lebesgue/Borel measure, for every dyadic interval. We can conclude that is just the standard Borel measure on . Details added: Let with and . Let be the binary expansion, with two exceptions and . Hence , where consists of all sequences that start with and and . It is clear that by definition of the product measure, and . Hence , which is the Borel measure of . Since the dyadic intervals generate , for any measurable , and is the Borel measure on . Does this complete the proof for dyadic intervals? I think my statement is correct, but I need a proof to generalize it, instead of just taking dyadic intervals. Here is a post regarding a similar problem as mine: identify the interval $[0, 1]$ with the Lebesgue measure to the probability space for tossing a fair coin . The result is that is almost bijective, meaning that is a bijection except at countably many points that have two inverse images; is measure-preserving. Are these two results from this post helpful for writing a rigorous proof regarding my statement? And how can I do that? Thank you.","X_i=\{0,1\} \mu \mu(\{0\})=\mu(\{1\})=\frac{1}{2} \Omega X_i \sigma \lambda f:\Omega\to[0,1] \omega=(x_1,\ldots,x_n,...)\mapsto\sum_{j=1}^{\infty}\frac{x_j}{2^j}\in[0,1] \lambda f^{-1} [0,1] E=(\frac{3}{4},\frac{7}{8}) f^{-1}(E)=\{1\}\times\{1\}\times\{0\}\times\ldots \frac{1}{8} (\lambda f^{-1})(E)=\lambda(f^{-1}(E))=\frac{1}{8} \lambda f^{-1}(E)=m(E) m \lambda f^{-1} [0,1] E=\left(\frac{k}{2^j},\frac{k+1}{2^j}\right) n\in\mathbb{N} 0\leq k<2^j x=x_1\ldots x_j x=\frac{k}{j} x=\frac{k+1}{j} f^{-1}(E)=F\setminus\{p,q\} F x p=(x,0,0,\ldots) q=(x,1,1,\ldots) \lambda(F)=2^{-j} \lambda(\{p\})=\lambda(\{q\})=0 \lambda\left(f^{-1}(E)\right)=2^{-j} E \mathcal{B} \lambda\left(f^{-1}(E)\right)=m(E) E m [0,1] f(\omega) f(\omega) x\in[0,1] f(\omega)","['real-analysis', 'measure-theory']"
14,Verification that the Borel $\sigma$-algebra on $\mathbb{R}$ is not atomic.,Verification that the Borel -algebra on  is not atomic.,\sigma \mathbb{R},"Let $X$ be a set, and let $\mathcal{A} = (A_n)_{n=1}^{\infty}$ be a sequence of disjoint, nonempty subsets whose union is $X$ . Then the set $\mathcal{M}$ of all finite or countable unions of elements of $\mathcal{A}$ together with $\emptyset$ is a $\sigma$ -algebra. A $\sigma$ -algebra of this form is called atomic. Then the Borel $\sigma$ -algebra $\mathcal{B}_{\mathbb{R}}$ on $\mathbb{R}$ is not atomic. $\text{Proof.}$ Suppose for sake of contradiction that $\mathcal{B}_{\mathbb{R}}$ is the collection of all finite or countable unions of sets in $\mathcal{A} = (A_n)_{n=1}^{\infty} $ , where the $A_i$ are mutually disjoint, non-empty subsets of $\mathbb{R}$ whose union is $\mathbb{R}$ . In particular it follows from this that each set in $\mathcal{A}$ is itself a Borel-set in $\mathbb{R}$ . Now let $\mathcal{U}= \left\{\left\{p\right\}:0<p<1\right\}$ . Then each singleton in $\mathcal{U}$ is a Borel-set, being closed with respect to the standard topology on $\mathbb{R}$ . Hence, for each $p\in (0,1)$ , it follows that $\left\{p \right\}$ is a union of a finite or countable sub-collection of the $A_i$ . But since the $A_i$ are each nonempty, $\left\{p\right\}$ cannot be a union of more than one $A_i$ , since otherwise $\left\{p\right\}$ would have more than one element. Thus, for each $p\in (0,1)$ , we can injectively associate a set $A_i\in\mathcal{A}$ with $\left\{p\right\} = A_i$ . But this is absurd because $\mathcal{U}$ is uncountable and $\mathcal{A}$ is countable. I'd appreciate if anyone here could check for the accuracy of the above proof. Thanks.","Let be a set, and let be a sequence of disjoint, nonempty subsets whose union is . Then the set of all finite or countable unions of elements of together with is a -algebra. A -algebra of this form is called atomic. Then the Borel -algebra on is not atomic. Suppose for sake of contradiction that is the collection of all finite or countable unions of sets in , where the are mutually disjoint, non-empty subsets of whose union is . In particular it follows from this that each set in is itself a Borel-set in . Now let . Then each singleton in is a Borel-set, being closed with respect to the standard topology on . Hence, for each , it follows that is a union of a finite or countable sub-collection of the . But since the are each nonempty, cannot be a union of more than one , since otherwise would have more than one element. Thus, for each , we can injectively associate a set with . But this is absurd because is uncountable and is countable. I'd appreciate if anyone here could check for the accuracy of the above proof. Thanks.","X \mathcal{A} = (A_n)_{n=1}^{\infty} X \mathcal{M} \mathcal{A} \emptyset \sigma \sigma \sigma \mathcal{B}_{\mathbb{R}} \mathbb{R} \text{Proof.} \mathcal{B}_{\mathbb{R}} \mathcal{A} = (A_n)_{n=1}^{\infty}  A_i \mathbb{R} \mathbb{R} \mathcal{A} \mathbb{R} \mathcal{U}= \left\{\left\{p\right\}:0<p<1\right\} \mathcal{U} \mathbb{R} p\in (0,1) \left\{p \right\} A_i A_i \left\{p\right\} A_i \left\{p\right\} p\in (0,1) A_i\in\mathcal{A} \left\{p\right\} = A_i \mathcal{U} \mathcal{A}","['real-analysis', 'measure-theory']"
15,Limit of sequence of Lebesgue integrals over symmetric domains,Limit of sequence of Lebesgue integrals over symmetric domains,,"I'm trying to show the following: If $f \in L^1(\mathbb{R})$ with $f$ nonnegative, then $$\lim_{n \to \infty}\frac{1}{n}\int_{-n}^{n}tf(t)dt=0$$ I""ve shown that for every $n≥0$ we have $$ \frac{1}{n}\int_{-n}^{n}tf(t)dt≤\int_{-n}^{n}f(t)dt$$ but I'm not sure if that's useful or not. My aim is to employ one of the standard convergence theorems, but I'm not sure how to set it up so far.","I'm trying to show the following: If with nonnegative, then I""ve shown that for every we have but I'm not sure if that's useful or not. My aim is to employ one of the standard convergence theorems, but I'm not sure how to set it up so far.","f \in L^1(\mathbb{R}) f \lim_{n \to \infty}\frac{1}{n}\int_{-n}^{n}tf(t)dt=0 n≥0 
\frac{1}{n}\int_{-n}^{n}tf(t)dt≤\int_{-n}^{n}f(t)dt","['real-analysis', 'measure-theory', 'lebesgue-integral']"
16,"Prove that $L^1\cap L^{\infty }\subseteq L^p$ for all $p\in [1,\infty]$",Prove that  for all,"L^1\cap L^{\infty }\subseteq L^p p\in [1,\infty]","My work: Let $f\in L^1\cap L^{\infty }$ then $\left \| f \right \|_1,\left \| f \right \|_{\infty}$$<\infty$ $\left ( \int _X\left | f \right |^pd\mu  \right )^{1/p}=\left ( \int _X\left | f \right |^{p-1}\left | f \right |d\mu  \right )^{1/p}\leq \left ( \left \| f \right \|_{\infty}^{p-1}\left \| f \right \|_1 \right )^{1/p}< \infty$ Then $f\in L^p$ Correct ? ( $(X,A,\mu)$ is the given measure space)",My work: Let then Then Correct ? ( is the given measure space),"f\in L^1\cap L^{\infty } \left \| f \right \|_1,\left \| f \right \|_{\infty}<\infty \left ( \int _X\left | f \right |^pd\mu  \right )^{1/p}=\left ( \int _X\left | f \right |^{p-1}\left | f \right |d\mu  \right )^{1/p}\leq \left ( \left \| f \right \|_{\infty}^{p-1}\left \| f \right \|_1 \right )^{1/p}< \infty f\in L^p (X,A,\mu)","['measure-theory', 'lp-spaces']"
17,Define $X_n=\sum_{k=1}^n kx_k$ and $Y_n=\sum_{k=1}^n ky_k$. Prove that there exists an $n$ such that $X_n<Y_n$.,Define  and . Prove that there exists an  such that .,X_n=\sum_{k=1}^n kx_k Y_n=\sum_{k=1}^n ky_k n X_n<Y_n,"Question: Let $x_k, y_k\geq 0$ .  Suppose that $\sum_{k=1}^\infty x_k<\infty$ and $\sum_{k=1}^\infty y_k=\infty$ .  Define $X_n=\sum_{k=1}^n kx_k$ and $Y_n=\sum_{k=1}^n ky_k$ .  Prove that there exists an $n$ such that $X_n<Y_n$ . My thoughts: So, $x_k$ is a convergent sum and $y_k$ is a divergent sum both of non-negative terms.  Since $\sum_{k=1}^\infty x_k<\infty$ , we know that $S_{x_k}=\sum_{k=1}^n x_k$ , the sequence of partial sums is convergent, and since $\sum_{k=1}^\infty y_k=\infty$ , we know that $S_{y_k}=\sum_{k=1}^\infty y_k$ is also divergent (to $\infty$ since all terms are non-negative).  But here is where I get stuck.  I'm a bit stuck on how to deal with the $k$ in $X_n$ and $Y_n$ , because I can't just pull it out of each series since it's value depends on the sum.  I was thinking that maybe there was a more measure-theoretic way of dealing with this, but I'm not sure.  Maybe it can just be salvaged by dealing with the series and their partial sums?","Question: Let .  Suppose that and .  Define and .  Prove that there exists an such that . My thoughts: So, is a convergent sum and is a divergent sum both of non-negative terms.  Since , we know that , the sequence of partial sums is convergent, and since , we know that is also divergent (to since all terms are non-negative).  But here is where I get stuck.  I'm a bit stuck on how to deal with the in and , because I can't just pull it out of each series since it's value depends on the sum.  I was thinking that maybe there was a more measure-theoretic way of dealing with this, but I'm not sure.  Maybe it can just be salvaged by dealing with the series and their partial sums?","x_k, y_k\geq 0 \sum_{k=1}^\infty x_k<\infty \sum_{k=1}^\infty y_k=\infty X_n=\sum_{k=1}^n kx_k Y_n=\sum_{k=1}^n ky_k n X_n<Y_n x_k y_k \sum_{k=1}^\infty x_k<\infty S_{x_k}=\sum_{k=1}^n x_k \sum_{k=1}^\infty y_k=\infty S_{y_k}=\sum_{k=1}^\infty y_k \infty k X_n Y_n","['real-analysis', 'measure-theory', 'convergence-divergence']"
18,Convergence of a sequence of measures.,Convergence of a sequence of measures.,,"On a measure space $(E,\mathcal{E},\mu)$ , let $(\mathcal{F}_n)$ a filtration on $\mathcal{E}$ , with $\mathcal{F}_n \uparrow \mathcal{E}$ , and let $(\mu_n)$ be a sequence of finite measures defined on $\mathcal{E}$ such that $$ \mu_n(A) = \mu(A) \qquad \text{for all $A \in \mathcal{F}_n$}. $$ Is it true that the sequence $(\mu_n)$ converges towards $\mu$ ? Which kind of convergence is expected? Is $(\mu_n)$ a Cauchy sequence?","On a measure space , let a filtration on , with , and let be a sequence of finite measures defined on such that Is it true that the sequence converges towards ? Which kind of convergence is expected? Is a Cauchy sequence?","(E,\mathcal{E},\mu) (\mathcal{F}_n) \mathcal{E} \mathcal{F}_n \uparrow \mathcal{E} (\mu_n) \mathcal{E}  \mu_n(A) = \mu(A) \qquad \text{for all A \in \mathcal{F}_n}.  (\mu_n) \mu (\mu_n)","['measure-theory', 'convergence-divergence', 'cauchy-sequences']"
19,Comparing the sizes of null sets,Comparing the sizes of null sets,,"This question is about comparing the relative sizes of null sets by switching from open covers to open cover ing sequences (a la strong measure zero sets or microscopic sets ). The main question is whether the most obvious preorder is in fact linear, and the secondary question is whether this preorder coincides with a related ""game-theoretic"" preorder I know is linear. Below we either work in $\mathsf{ZF}+\mathsf{DC}+\mathsf{AD_\mathbb{R}}$ or restrict attention to appropriately tame sets of reals. Main question For $X\subseteq\mathbb{R}$ of measure zero, say that the efficiency of $X$ is the set $\mathsf{Eff}(X)$ of all sequences of positive reals $\alpha=(a_i)_{i\in\mathbb{N}}$ such that there is some sequence of nonempty rational open intervals $(U_i)_{i\in\mathbb{N}}$ with $m(U_i)\le a_i$ for each $i$ and $\bigcup_{i\in\mathbb{N}}U_i\supseteq X$ . We get a natural preorder from this notion, $\trianglelefteq$ , via $$X\trianglelefteq Y\iff \mathsf{Eff}(X)\supseteq\mathsf{Eff}(Y)$$ (that's not a typo - the idea is that $X\trianglelefteq Y$ means that $X$ is smaller than $Y$ , which is to say that it's more efficient). I would like to understand this preorder better, and in particular: Is $\trianglelefteq$ a linear preorder? Secondary question There is a different relation, of similar ""flavor"" to $\trianglelefteq$ , which I can prove is a linear preorder. Namely, given null $X,Y$ consider the game $E(X,Y)$ defined as follows: Players $1$ and $2$ alternately play individual nonempty rational open intervals building a sequence $U_0,V_0,U_1,V_1,...$ , with $m(U_i)\ge m(V_i)\ge m(U_{i+1})$ . Player $1$ wins a given play iff for each $n$ we have $\bigcup_{i>n}U_i\supseteq Y$ , but there is some $n$ such that $\bigcup_{i>n}V_i\not\supseteq X$ . (The win condition can be rephrased as a kind of redundancy property: "" $(U_i)_{i\in\mathbb{N}}$ covers $X$ with infinite repetition but $(V_i)_{i\in\mathbb{N}}$ does not cover $Y$ with infinite repetition."") Consider the relation $\sqsubseteq$ given by $$X\sqsubseteq Y\iff \mbox{player $2$ has a winning strategy in $E(X,Y)$}.$$ Like $\trianglelefteq$ this is clearly reflexive and transitive, and linearity follows from determinacy. If $X\not\sqsubseteq Y$ then player $1$ has a winning strategy $\Sigma$ in $E(X,Y)$ , and we can turn that into a winning strategy $\hat{\Sigma}$ for player $2$ in $E(Y,X)$ . This is where the redundancy part of the win condition comes in: $\hat{\Sigma}$ 's first move will be essentially useless, but this won't affect the ultimate outcome. So one natural way to get a positive answer to the main question would be to prove $\sqsubseteq$ is the same as $\trianglelefteq$ . However, I don't see how to do this: Do $\trianglelefteq$ and $\sqsubseteq$ coincide? I suspect that the answer is no, and in fact that $\trianglelefteq$ is not linear. (As an aside, the ""non-redundant-covering"" version of $\sqsubseteq$ is more similar to $\trianglelefteq$ so would make the secondary question more interesting, but I don't know that that relation is linear either so it's not obviously useful to the main question.)","This question is about comparing the relative sizes of null sets by switching from open covers to open cover ing sequences (a la strong measure zero sets or microscopic sets ). The main question is whether the most obvious preorder is in fact linear, and the secondary question is whether this preorder coincides with a related ""game-theoretic"" preorder I know is linear. Below we either work in or restrict attention to appropriately tame sets of reals. Main question For of measure zero, say that the efficiency of is the set of all sequences of positive reals such that there is some sequence of nonempty rational open intervals with for each and . We get a natural preorder from this notion, , via (that's not a typo - the idea is that means that is smaller than , which is to say that it's more efficient). I would like to understand this preorder better, and in particular: Is a linear preorder? Secondary question There is a different relation, of similar ""flavor"" to , which I can prove is a linear preorder. Namely, given null consider the game defined as follows: Players and alternately play individual nonempty rational open intervals building a sequence , with . Player wins a given play iff for each we have , but there is some such that . (The win condition can be rephrased as a kind of redundancy property: "" covers with infinite repetition but does not cover with infinite repetition."") Consider the relation given by Like this is clearly reflexive and transitive, and linearity follows from determinacy. If then player has a winning strategy in , and we can turn that into a winning strategy for player in . This is where the redundancy part of the win condition comes in: 's first move will be essentially useless, but this won't affect the ultimate outcome. So one natural way to get a positive answer to the main question would be to prove is the same as . However, I don't see how to do this: Do and coincide? I suspect that the answer is no, and in fact that is not linear. (As an aside, the ""non-redundant-covering"" version of is more similar to so would make the secondary question more interesting, but I don't know that that relation is linear either so it's not obviously useful to the main question.)","\mathsf{ZF}+\mathsf{DC}+\mathsf{AD_\mathbb{R}} X\subseteq\mathbb{R} X \mathsf{Eff}(X) \alpha=(a_i)_{i\in\mathbb{N}} (U_i)_{i\in\mathbb{N}} m(U_i)\le a_i i \bigcup_{i\in\mathbb{N}}U_i\supseteq X \trianglelefteq X\trianglelefteq Y\iff \mathsf{Eff}(X)\supseteq\mathsf{Eff}(Y) X\trianglelefteq Y X Y \trianglelefteq \trianglelefteq X,Y E(X,Y) 1 2 U_0,V_0,U_1,V_1,... m(U_i)\ge m(V_i)\ge m(U_{i+1}) 1 n \bigcup_{i>n}U_i\supseteq Y n \bigcup_{i>n}V_i\not\supseteq X (U_i)_{i\in\mathbb{N}} X (V_i)_{i\in\mathbb{N}} Y \sqsubseteq X\sqsubseteq Y\iff \mbox{player 2 has a winning strategy in E(X,Y)}. \trianglelefteq X\not\sqsubseteq Y 1 \Sigma E(X,Y) \hat{\Sigma} 2 E(Y,X) \hat{\Sigma} \sqsubseteq \trianglelefteq \trianglelefteq \sqsubseteq \trianglelefteq \sqsubseteq \trianglelefteq","['real-analysis', 'measure-theory', 'logic', 'descriptive-set-theory', 'infinite-games']"
20,Strong convergence and convergence of integral,Strong convergence and convergence of integral,,"A sequence of probability measures $\{\mu_n\}$ converges strongly if for each measurable set $A$ $$\mu_{n}(A) \rightarrow \mu(A)$$ (notice that this convergence is different than the total variation) when does this convergence imply $$\int f \,d\mu_n\to \int f \,d\mu $$ for every bounded measurable function? I'm interested in the case in which the space is not Polish.",A sequence of probability measures converges strongly if for each measurable set (notice that this convergence is different than the total variation) when does this convergence imply for every bounded measurable function? I'm interested in the case in which the space is not Polish.,"\{\mu_n\} A \mu_{n}(A) \rightarrow \mu(A) \int f \,d\mu_n\to \int f \,d\mu ",['measure-theory']
21,Square-integrable functions tend to zero at $\pm \infty$,Square-integrable functions tend to zero at,\pm \infty,Is it true that all differentiable square-integrable functions tend to zero at $\pm \infty$ ? If that is not true could you give a counterexample?,Is it true that all differentiable square-integrable functions tend to zero at ? If that is not true could you give a counterexample?,\pm \infty,"['integration', 'measure-theory', 'hilbert-spaces']"
22,Is the group of elements $t \in \mathbb{R}$ such that $A +t = A$ up to measure $0$ closed?,Is the group of elements  such that  up to measure  closed?,t \in \mathbb{R} A +t = A 0,"My question: If $A \subset \mathbb{R}$ is a measurable subset and $t_n \rightarrow t$ is a convergent sequence such that $A +t_n = A$ mod $\mu$ , does $A+t=A$ mod $\mu$ hold? Here $A = B$ mod $\mu$ means that $\mu(A \Delta B)=0$ where $A \Delta B$ is the symmetric difference between $A$ and $B$ and $\mu$ is the Lebesgue measure on $\mathbb{R}$ .","My question: If is a measurable subset and is a convergent sequence such that mod , does mod hold? Here mod means that where is the symmetric difference between and and is the Lebesgue measure on .",A \subset \mathbb{R} t_n \rightarrow t A +t_n = A \mu A+t=A \mu A = B \mu \mu(A \Delta B)=0 A \Delta B A B \mu \mathbb{R},"['real-analysis', 'measure-theory', 'lebesgue-measure', 'group-actions']"
23,"Prove that if $f : M → M$ preserves a probability $\mu$, then for any $k \geq 2 $ $f^k$ preserves $\mu$","Prove that if  preserves a probability , then for any   preserves",f : M → M \mu k \geq 2  f^k \mu,"Prove that if $f : M → M$ preserves a probability $\mu$ , then for any $k \geq 2$ , $f^k$ also preserves $\mu$ . Is the converse true? Attempt:  The first part did induction in $k$ . The case $k = 1$ holds because $f$ preserves probability. assuming that the result holds for $k$ , for $k + 1$ we have: $\mu(f^{-k-1}(A))=\mu(f^{-k}(f^{-1}(A)))=\mu(f^{-1}(A))=\mu(A)$ .  Is this part correct? Apparently for the converse, use only that $\mu(f^{-1}(A))=\mu(f^{-2}(f^{-1}(A)))=\mu(f^{-3}(A))=\mu(A)$ .","Prove that if preserves a probability , then for any , also preserves . Is the converse true? Attempt:  The first part did induction in . The case holds because preserves probability. assuming that the result holds for , for we have: .  Is this part correct? Apparently for the converse, use only that .",f : M → M \mu k \geq 2 f^k \mu k k = 1 f k k + 1 \mu(f^{-k-1}(A))=\mu(f^{-k}(f^{-1}(A)))=\mu(f^{-1}(A))=\mu(A) \mu(f^{-1}(A))=\mu(f^{-2}(f^{-1}(A)))=\mu(f^{-3}(A))=\mu(A),"['measure-theory', 'ergodic-theory']"
24,What does it mean to have a subsequence of a random variable?,What does it mean to have a subsequence of a random variable?,,"For example, I have a random variable $X$ such that $X_n = \sum_{k=1}^n I_k$ where $I_n = 1$ if $A_n$ occurs and $I_n=0$ otherwise. I am looking at a proof that says that we should be able to find a subsequence $X_{n_k} (X_{n_1} < X_{n_2} < ...) $ such that ... I don't understand what this statement means, can someone please clarify More specifically I want to find a subsequence such that $\sum_{k=1}^\infty \frac{\sigma^2(X_{n_k})}{\epsilon^2E^2(X_{n_k})}<\infty$ What would a subsequence like that look like? This is the proof I am looking at:","For example, I have a random variable such that where if occurs and otherwise. I am looking at a proof that says that we should be able to find a subsequence such that ... I don't understand what this statement means, can someone please clarify More specifically I want to find a subsequence such that What would a subsequence like that look like? This is the proof I am looking at:",X X_n = \sum_{k=1}^n I_k I_n = 1 A_n I_n=0 X_{n_k} (X_{n_1} < X_{n_2} < ...)  \sum_{k=1}^\infty \frac{\sigma^2(X_{n_k})}{\epsilon^2E^2(X_{n_k})}<\infty,['measure-theory']
25,why is the Lebesgue-Stieltjes integral well-defined?,why is the Lebesgue-Stieltjes integral well-defined?,,"A function $g: [a,b] \rightarrow \mathbb{R}$ a said to be of bounded variation on the interval $[a,b]$ if $$  \sup_{P: a=x_0 < x_1 \ldots < x_i < \ldots < x_{n_P}=b}   \sum_{i=1}^{n_P} |g(x_{i}) -g(x_{i-1}))| < \infty,  $$ where the supremum if taken over all partitions $P$ of the interval $[a,b]$ . One can show that a (right-continous) function $g: [a,b] \rightarrow \mathbb{R}$ is of bounded variation if and only if there exist two monotone non-decreasing (right-continuous) functions $g^+$ and $g^-$ such that $g= g^+ -g^-$ . (However, this decomposition is not unique, as one can for example add any monotone non-decreasing (right-continuous) function to both $g^+$ and $g^-$ ). This is called a Jordan decomposition of $g$ . Moreover, given any $g: [a,b] \rightarrow \mathbb{R}$ which is monotone, non-decreasing and right-continuous function, there exists a unique measure $dg$ on $[a,b]$ such that $$    dg((c,d])=g(d)-g(c)   $$ for all $(c,d] \in [a,b]$ and $dg(\{a\})=0$ . This measure is called the Lebesgue-Stieltjes measure of $g$ . Given a bounded function $f: [a,b] \rightarrow \mathbb{R}$ and a right-continuous function of bounded variation $g : [a,b] \rightarrow \mathbb{R}$ , one can define $$     \int_{[a,b]} f\,dg :=   \int_{[a,b]} f\,dg^+  -  \int_{[a,b]} f\,dg^-,     $$ where $g= g^+ -g^-$ is a Jordan decomposition as above. This is called the Lebesgue-Stieltjes integral of $f$ w.r.t. $g$ . My question is, why is $\int_{[a,b]} f\,dg$ well-defined, i.e. independent of the chosen Jordan decomposition?","A function a said to be of bounded variation on the interval if where the supremum if taken over all partitions of the interval . One can show that a (right-continous) function is of bounded variation if and only if there exist two monotone non-decreasing (right-continuous) functions and such that . (However, this decomposition is not unique, as one can for example add any monotone non-decreasing (right-continuous) function to both and ). This is called a Jordan decomposition of . Moreover, given any which is monotone, non-decreasing and right-continuous function, there exists a unique measure on such that for all and . This measure is called the Lebesgue-Stieltjes measure of . Given a bounded function and a right-continuous function of bounded variation , one can define where is a Jordan decomposition as above. This is called the Lebesgue-Stieltjes integral of w.r.t. . My question is, why is well-defined, i.e. independent of the chosen Jordan decomposition?","g: [a,b] \rightarrow \mathbb{R} [a,b]   \sup_{P: a=x_0 < x_1 \ldots < x_i < \ldots < x_{n_P}=b}   \sum_{i=1}^{n_P} |g(x_{i}) -g(x_{i-1}))| < \infty,   P [a,b] g: [a,b] \rightarrow \mathbb{R} g^+ g^- g= g^+ -g^- g^+ g^- g g: [a,b] \rightarrow \mathbb{R} dg [a,b]     dg((c,d])=g(d)-g(c)    (c,d] \in [a,b] dg(\{a\})=0 g f: [a,b] \rightarrow \mathbb{R} g : [a,b] \rightarrow \mathbb{R}      \int_{[a,b]} f\,dg :=   \int_{[a,b]} f\,dg^+  -  \int_{[a,b]} f\,dg^-,      g= g^+ -g^- f g \int_{[a,b]} f\,dg","['measure-theory', 'bounded-variation', 'stieltjes-integral']"
26,"For $p\in(1,\infty)$, why does $||f||_p=||g||_p=\left|\left|\frac{f+g}{2}\right|\right|_p$ imply that $f=g$?","For , why does  imply that ?","p\in(1,\infty) ||f||_p=||g||_p=\left|\left|\frac{f+g}{2}\right|\right|_p f=g","Problem Statement. I am working on the following exercise: Prove that if $\mu$ is a measure, $p\in(1,\infty)$ and $f,g\in  L^p(\mu)$ are such that $$||f||_p=||g||_p=\left|\left|\frac{f+g}{2}\right|\right|_p,$$ then $f=g$ . Notation. For a measure space $(X,\mathcal{S},\mu)$ and $p\in(0,\infty]$ (where $\mathbf{F}$ is taken to be either $\mathbf{R}$ or $\mathbf{C}$ ): $L^p(\mu)=\{\tilde{f}: f\in\mathcal{L}^p(\mu)\}$ $\mathcal{L}^p(\mu)=\{f:X\rightarrow\mathbf{F}: f \text{ is } \mathcal{S}\text{-measurable and } \int f\,d\mu<\infty\}$ $\tilde{f}=\{f+z: z\in\mathcal{Z}(\mu)\}$ where $\mathcal{Z}(\mu)$ is the set of $\mathcal{S}$ -measurable functions from $X$ to $\mathbf{F}$ that equal $0$ almost everywhere. My Thoughts. I am a bit confused as to how this is even an exercise, and here is why.  We define $$||\tilde{f}||_p=||f||_p$$ for $p\in (0,\infty].$ Thus even though the $f$ and $g$ given are actually $\tilde{f}$ and $\tilde{g}$ , it doesn't matter since $||\tilde{f}||_p=||f||_p$ and $||\tilde{g}||_p=||g||_p$ , thus implying that $||f||_p=||g||_p$ .  But if this is the case then $$\left(\int |f|^p\,d\mu \right)^{1/p}=\left(\int |g|^p\,d\mu \right)^{1/p}.$$ How could that possibly be the case if $f\neq g$ ?  I would say I'm done at this point, but clearly I am missing something.  I didn't even use the last equality, i.e. $$\left|\left|\frac{f+g}{2}\right|\right|_p.$$ So what am I missing here?  There must be something I am misunderstanding! Thanks in advance for your help!","Problem Statement. I am working on the following exercise: Prove that if is a measure, and are such that then . Notation. For a measure space and (where is taken to be either or ): where is the set of -measurable functions from to that equal almost everywhere. My Thoughts. I am a bit confused as to how this is even an exercise, and here is why.  We define for Thus even though the and given are actually and , it doesn't matter since and , thus implying that .  But if this is the case then How could that possibly be the case if ?  I would say I'm done at this point, but clearly I am missing something.  I didn't even use the last equality, i.e. So what am I missing here?  There must be something I am misunderstanding! Thanks in advance for your help!","\mu p\in(1,\infty) f,g\in
 L^p(\mu) ||f||_p=||g||_p=\left|\left|\frac{f+g}{2}\right|\right|_p, f=g (X,\mathcal{S},\mu) p\in(0,\infty] \mathbf{F} \mathbf{R} \mathbf{C} L^p(\mu)=\{\tilde{f}: f\in\mathcal{L}^p(\mu)\} \mathcal{L}^p(\mu)=\{f:X\rightarrow\mathbf{F}: f \text{ is } \mathcal{S}\text{-measurable and } \int f\,d\mu<\infty\} \tilde{f}=\{f+z: z\in\mathcal{Z}(\mu)\} \mathcal{Z}(\mu) \mathcal{S} X \mathbf{F} 0 ||\tilde{f}||_p=||f||_p p\in (0,\infty]. f g \tilde{f} \tilde{g} ||\tilde{f}||_p=||f||_p ||\tilde{g}||_p=||g||_p ||f||_p=||g||_p \left(\int |f|^p\,d\mu \right)^{1/p}=\left(\int |g|^p\,d\mu \right)^{1/p}. f\neq g \left|\left|\frac{f+g}{2}\right|\right|_p.","['real-analysis', 'measure-theory', 'normed-spaces', 'lp-spaces']"
27,"Strong convergence in $L^1$, $\mathbb{R}^d$ with $d>1$","Strong convergence in ,  with",L^1 \mathbb{R}^d d>1,"A sequence of positive function $f_n(x)\rightarrow f(x)$ pointwise on the unit ball $B:=\{x:|x|\leq 1\}\subset \mathbb{R}^d$ as $n\rightarrow \infty$ . Suppose the sets $\Lambda_t^n=\{x:f_n(x)\geq t\}$ satisfy the following two properties. The Lebesgue measure of their boundary is zero $\mu(\partial \Lambda_t^n)=0$ for all $n\in \mathbb{N}$ and $t\in \mathbb{Q}$ , and for all $n,m\in \mathbb{N}$ we have $\Lambda_m^n\subset \{x:|x-x^n_m|\leq 1/m\}$ for some $x^n_m\in B_1(0)$ . Prove that $f_n\rightarrow f$ strongly in $L^1(B_1)$ if the dimension $d>1$ . I managed to show that $f_n$ and $f$ are measurable, but I have no idea how to proceed. I don't know what is special about $\mathbb{R}$ that makes it different from $\mathbb{R}^d$ with $d>1$ . Any help would be appreciated.","A sequence of positive function pointwise on the unit ball as . Suppose the sets satisfy the following two properties. The Lebesgue measure of their boundary is zero for all and , and for all we have for some . Prove that strongly in if the dimension . I managed to show that and are measurable, but I have no idea how to proceed. I don't know what is special about that makes it different from with . Any help would be appreciated.","f_n(x)\rightarrow f(x) B:=\{x:|x|\leq 1\}\subset \mathbb{R}^d n\rightarrow \infty \Lambda_t^n=\{x:f_n(x)\geq t\} \mu(\partial \Lambda_t^n)=0 n\in \mathbb{N} t\in \mathbb{Q} n,m\in \mathbb{N} \Lambda_m^n\subset \{x:|x-x^n_m|\leq 1/m\} x^n_m\in B_1(0) f_n\rightarrow f L^1(B_1) d>1 f_n f \mathbb{R} \mathbb{R}^d d>1","['real-analysis', 'measure-theory', 'lebesgue-measure', 'product-measure']"
28,Examples about bounded variation function,Examples about bounded variation function,,"Problem. Give an example of a function with bounded variation $f:[0,1] →\mathbb R$ with $f'$ integrable in $[0,1]$ , and such that the function $g:[0,1]→\mathbb R$ defined by $$g(x)=f(x)-f(0)-\int_0^xf'(s)\,\mathrm ds$$ vanishes at the points $\displaystyle x_n = \sum_{j=1}^n\frac{1}{2^j}$ , $g$ is positive on $(x_n,x_{n+1})$ if $n$ is odd and is negative if $n$ is even. This example does not seem intuitive for me. How can I try to build this function? Is there any strategy for this? In addition to the assumptions, the unique other restriction that I saw clearly: $$\int_0^xf'(s)\,\mathrm ds ≠ f(x) - f(0).$$ The only non-trivial function that I know that satisfies this is the Cantor-Lebesgue function, but this function does not work for this problem. So, I tried to start with a function that was not absolutely continuous, but I could not get an example.","Problem. Give an example of a function with bounded variation with integrable in , and such that the function defined by vanishes at the points , is positive on if is odd and is negative if is even. This example does not seem intuitive for me. How can I try to build this function? Is there any strategy for this? In addition to the assumptions, the unique other restriction that I saw clearly: The only non-trivial function that I know that satisfies this is the Cantor-Lebesgue function, but this function does not work for this problem. So, I tried to start with a function that was not absolutely continuous, but I could not get an example.","f:[0,1] →\mathbb R f' [0,1] g:[0,1]→\mathbb R g(x)=f(x)-f(0)-\int_0^xf'(s)\,\mathrm ds \displaystyle x_n = \sum_{j=1}^n\frac{1}{2^j} g (x_n,x_{n+1}) n n \int_0^xf'(s)\,\mathrm ds ≠ f(x) - f(0).","['measure-theory', 'lebesgue-integral', 'examples-counterexamples', 'bounded-variation']"
29,Exercise 4.6 in Richard Bass' ''Real Analysis for Graduate Students'',Exercise 4.6 in Richard Bass' ''Real Analysis for Graduate Students'',,"I am really unsure about my solution to question 2 in 4.6 and have nobody to talk about it. So may be someone in here can help me out. I'll just recall the setting of the exercise. We work on the measure space ([0,1], $\mathcal{B}([0,1]),m)$ , where $\mathcal{B}$ is the Borel $\sigma$ -algebra and $m$ the Lebesgue measure. Assume that for each $n \geq 1$ , $A_n \subset [0,1]$ is measurable. Let $B$ be $\lim \sup$ of the $A_n$ . Questions 1 asks us to show that $B$ is measurable. That is the case because the collection of measurable subsets form a $\sigma$ -algebra and $B$ is a countable intersection of a countable union of measurable sets. Now question 2 wants us to prove the following:  If $m(A_n) > \delta > 0$ , for each $n$ , then $m(B) \geq \delta$ . I did the following. Let $B_n := \cup_{j \geq n} A_j$ . Note that $\{B_n\}_{n \geq 1}$ is a decreasing sequence of sets.  Thus: $$m(B)=m(\cap_{n \geq 1} B_n) = \lim_{n \rightarrow +\infty} m(B_n)=\lim_{n \rightarrow +\infty}m(\cup_{j\geq n}A_j)$$ Now since $A_n \subset \cup_{j\geq n} A_j$ , we have that $m(A_n) \leq m(\cup_{j\geq n} A_j)$ and thus: $$m(B) = \lim_{n \rightarrow +\infty}m(\cup_{j\geq n}A_j) \geq \lim_{n \rightarrow +\infty}m(A_n) \geq \delta$$ Now, I don't see why we need to have the strict inequalities $m(A_n) > \delta > 0$ . I feel like my argument also works if $m(A_n) \geq \delta \geq 0$ ... There's probably an error in my whole arguement and I would appreciate your help :)","I am really unsure about my solution to question 2 in 4.6 and have nobody to talk about it. So may be someone in here can help me out. I'll just recall the setting of the exercise. We work on the measure space ([0,1], , where is the Borel -algebra and the Lebesgue measure. Assume that for each , is measurable. Let be of the . Questions 1 asks us to show that is measurable. That is the case because the collection of measurable subsets form a -algebra and is a countable intersection of a countable union of measurable sets. Now question 2 wants us to prove the following:  If , for each , then . I did the following. Let . Note that is a decreasing sequence of sets.  Thus: Now since , we have that and thus: Now, I don't see why we need to have the strict inequalities . I feel like my argument also works if ... There's probably an error in my whole arguement and I would appreciate your help :)","\mathcal{B}([0,1]),m) \mathcal{B} \sigma m n \geq 1 A_n \subset [0,1] B \lim \sup A_n B \sigma B m(A_n) > \delta > 0 n m(B) \geq \delta B_n := \cup_{j \geq n} A_j \{B_n\}_{n \geq 1} m(B)=m(\cap_{n \geq 1} B_n) = \lim_{n \rightarrow +\infty} m(B_n)=\lim_{n \rightarrow +\infty}m(\cup_{j\geq n}A_j) A_n \subset \cup_{j\geq n} A_j m(A_n) \leq m(\cup_{j\geq n} A_j) m(B) = \lim_{n \rightarrow +\infty}m(\cup_{j\geq n}A_j) \geq \lim_{n \rightarrow +\infty}m(A_n) \geq \delta m(A_n) > \delta > 0 m(A_n) \geq \delta \geq 0","['real-analysis', 'measure-theory', 'lebesgue-measure']"
30,Measure of a set invariant under translations with rational numbers,Measure of a set invariant under translations with rational numbers,,Suppose $E\subset\mathbb{R}$ is measurable and $E=E+\frac{1}{n}$ for every natural number $n\geq1$. Show that either $m(E)=0$ or $m(\mathbb{R}\setminus E)=0$.,Suppose $E\subset\mathbb{R}$ is measurable and $E=E+\frac{1}{n}$ for every natural number $n\geq1$. Show that either $m(E)=0$ or $m(\mathbb{R}\setminus E)=0$.,,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
31,"Cohn, Exercise 2.4.11, Intuition behind my solution?","Cohn, Exercise 2.4.11, Intuition behind my solution?",,"Here's the problem. Let $(X, \mathscr{A}, \mu)$ be a measure space, and let $f,f_n$ be nonnegative functions that belong to $\mathscr{L}^1(X, \mathscr{A}, \mu, \mathbb{R})$. Prove that if $f_n \to f$ $\mu$-almost everywhere and $\int f_n \to \int f$, then $\int |f_n - f| \to 0$. Note that $|f_n - f| \leq f_n + f$, so $g_n := f_n + f - |f_n -f| \geq 0$. Fatou gives $\int \liminf_n g_n \leq \liminf_n \int g_n$.  Notice that $g_n \to 2f$, almost everywhere. Since the limit inferior is sub-additive, this means: $$ \int 2f = \int \liminf_n g_n \leq \liminf_n \int g_n \leq \int 2f + \liminf_n - \int |f_n - f| $$ Since $\liminf -a_n = -\limsup a_n$, we have $\limsup_n \int |f_n -f| \leq 0$, which implies the claim. It took me a while to find this solution. Assuming it is correct, can someone help me understand why the definition of $g_n$ is natural in some sense here? I think this proof mechanically works, but isn't very intuitive to me.","Here's the problem. Let $(X, \mathscr{A}, \mu)$ be a measure space, and let $f,f_n$ be nonnegative functions that belong to $\mathscr{L}^1(X, \mathscr{A}, \mu, \mathbb{R})$. Prove that if $f_n \to f$ $\mu$-almost everywhere and $\int f_n \to \int f$, then $\int |f_n - f| \to 0$. Note that $|f_n - f| \leq f_n + f$, so $g_n := f_n + f - |f_n -f| \geq 0$. Fatou gives $\int \liminf_n g_n \leq \liminf_n \int g_n$.  Notice that $g_n \to 2f$, almost everywhere. Since the limit inferior is sub-additive, this means: $$ \int 2f = \int \liminf_n g_n \leq \liminf_n \int g_n \leq \int 2f + \liminf_n - \int |f_n - f| $$ Since $\liminf -a_n = -\limsup a_n$, we have $\limsup_n \int |f_n -f| \leq 0$, which implies the claim. It took me a while to find this solution. Assuming it is correct, can someone help me understand why the definition of $g_n$ is natural in some sense here? I think this proof mechanically works, but isn't very intuitive to me.",,"['measure-theory', 'proof-verification', 'proof-explanation']"
32,Schwarz symmetrization is equimeasurable,Schwarz symmetrization is equimeasurable,,"Suppose $\Omega\subset\mathbb{R^2}$ is open and bounded, and let $f:\Omega\rightarrow [0,\infty)$ be measurable. Moreover, let $\Omega^{\ast}$ denote the closed disk with midpoint $0\in\mathbb{R}^2$ and the same area as $\Omega$ (i.e. $\vert\Omega\vert=\vert \Omega^{\ast} \vert$). The Schwarz symmetrization is defined as the function  $$f^{\ast}:\Omega^{\ast}\rightarrow[0,\infty),\quad f(x):=\sup\lbrace{ c\geq 0:x\in \Omega_c^{\ast} \rbrace},$$ where $\Omega_c:=f^{-1}([c,\infty))\subset\Omega$ and $\Omega_c^{\ast} $ denotes the closed disk with midpoint $0\in\mathbb{R}^2$ and $\vert\Omega_c^{\ast} \vert= \vert\Omega_c \vert$. I would like to understand the following two problems: 1) Why are $f$ and $f^{\ast}$ equimeasurable , i.e. $\vert \lbrace x\in\Omega^{\ast}: f^{\ast}(x)\geq c\rbrace \vert=\vert \Omega_{c} \vert$ for all $c\geq 0$ ? 2) Sometimes, the function $f^{\ast}$ is defined alternatively as $$f^{\ast}(x):=\int_{0}^{\infty} \chi_{ {\lbrace f \geq t \rbrace}^{\ast} }(x) dt.$$ I am wondering if that definition is equivalent to the first one ? Unfortunately, I do not know how to answer 1) or 2). I think that if we use $\vert\Omega_c^{\ast} \vert= \vert\Omega_c \vert$, it might be helpful. Then it remains to show: $$\vert \lbrace x\in\Omega^{\ast}: f^{\ast}(x)\geq c\rbrace \vert = \vert \lbrace x\in\Omega: f(x)\geq c\rbrace ^{\ast} \vert$$ Are both sets within $\vert\cdots \vert$ in the last equation the same? That is, do we have : $$\lbrace x\in\Omega^{\ast}: f^{\ast}(x)\geq c\rbrace = \lbrace x\in\Omega: f(x)\geq c\rbrace ^{\ast}$$ If the last statement is true, then 1) and 2) becomes trivial. But I do not know how to prove any of the three statements.","Suppose $\Omega\subset\mathbb{R^2}$ is open and bounded, and let $f:\Omega\rightarrow [0,\infty)$ be measurable. Moreover, let $\Omega^{\ast}$ denote the closed disk with midpoint $0\in\mathbb{R}^2$ and the same area as $\Omega$ (i.e. $\vert\Omega\vert=\vert \Omega^{\ast} \vert$). The Schwarz symmetrization is defined as the function  $$f^{\ast}:\Omega^{\ast}\rightarrow[0,\infty),\quad f(x):=\sup\lbrace{ c\geq 0:x\in \Omega_c^{\ast} \rbrace},$$ where $\Omega_c:=f^{-1}([c,\infty))\subset\Omega$ and $\Omega_c^{\ast} $ denotes the closed disk with midpoint $0\in\mathbb{R}^2$ and $\vert\Omega_c^{\ast} \vert= \vert\Omega_c \vert$. I would like to understand the following two problems: 1) Why are $f$ and $f^{\ast}$ equimeasurable , i.e. $\vert \lbrace x\in\Omega^{\ast}: f^{\ast}(x)\geq c\rbrace \vert=\vert \Omega_{c} \vert$ for all $c\geq 0$ ? 2) Sometimes, the function $f^{\ast}$ is defined alternatively as $$f^{\ast}(x):=\int_{0}^{\infty} \chi_{ {\lbrace f \geq t \rbrace}^{\ast} }(x) dt.$$ I am wondering if that definition is equivalent to the first one ? Unfortunately, I do not know how to answer 1) or 2). I think that if we use $\vert\Omega_c^{\ast} \vert= \vert\Omega_c \vert$, it might be helpful. Then it remains to show: $$\vert \lbrace x\in\Omega^{\ast}: f^{\ast}(x)\geq c\rbrace \vert = \vert \lbrace x\in\Omega: f(x)\geq c\rbrace ^{\ast} \vert$$ Are both sets within $\vert\cdots \vert$ in the last equation the same? That is, do we have : $$\lbrace x\in\Omega^{\ast}: f^{\ast}(x)\geq c\rbrace = \lbrace x\in\Omega: f(x)\geq c\rbrace ^{\ast}$$ If the last statement is true, then 1) and 2) becomes trivial. But I do not know how to prove any of the three statements.",,"['real-analysis', 'measure-theory', 'geometric-measure-theory', 'decreasing-rearrangements']"
33,"Prove that $E \subset [0,1] \times [0,1]$ is not a Borel set.",Prove that  is not a Borel set.,"E \subset [0,1] \times [0,1]","Suppose $E$ is a subset of the unit square $[0,1] \times [0,1]$ such that each vertical line through the square intersects $E$ in a countable set and each horizontal line through the square intersects the complement of $E$ in a countable set. Prove that $E$ is not a Borel set. This problem comes from a practice exam. I've been given the hint to use Fubini's theorem. I've thought that I should assume that $E$ is a Borel set and look at the characteristic function of $E$, but I don't know how t fill in the details.","Suppose $E$ is a subset of the unit square $[0,1] \times [0,1]$ such that each vertical line through the square intersects $E$ in a countable set and each horizontal line through the square intersects the complement of $E$ in a countable set. Prove that $E$ is not a Borel set. This problem comes from a practice exam. I've been given the hint to use Fubini's theorem. I've thought that I should assume that $E$ is a Borel set and look at the characteristic function of $E$, but I don't know how t fill in the details.",,['measure-theory']
34,"If $T$ has continuous spectrum and $(f, 1)=0$ then $\mu_{f}$ has no atoms.",If  has continuous spectrum and  then  has no atoms.,"T (f, 1)=0 \mu_{f}","I'm reading Peter Walters' An Introduction to Ergodic Theory , and I don't understand his remark. Following is a sort of lemma, called Spectral Theorem for Unitary Operators , to prove the equivalence of weak-mixing and having continuous spectrum: Theorem 1.25 (Spectral Theorem for Unitary Operators) in above book Suppose $U$ is a unitary operator on a complex Hilbert space $\mathcal{H}$ . Then for each $f \in \mathcal{H}$ there exists a unique finite Borel measure $\mu_{f}$ on $K = \{ z \in \mathbb{C} \ : \ |z| = 1\}$ such that $$(U^{n}f, f) = \int _{K} \lambda ^{n} d\mu_{f}(\lambda) \ \ \ \ \ \ \ \forall n \in \mathbb{Z}.$$ Then he remark that: If $T$ is an invertible measure-preserving transformation then $U_{T}$ is unitary, and if $T$ has continuous spectrum and $(f, 1) = 0$ then $\mu_{f}$ has no atoms. This is what I don't understand. How can we show that under such conditions, $\mu_{f}$ has no atoms? I found a related reference , and here Theorem 1.4 is related to what I want to know. And he left my question as an easy(?) exercise. Can somebody help me please?","I'm reading Peter Walters' An Introduction to Ergodic Theory , and I don't understand his remark. Following is a sort of lemma, called Spectral Theorem for Unitary Operators , to prove the equivalence of weak-mixing and having continuous spectrum: Theorem 1.25 (Spectral Theorem for Unitary Operators) in above book Suppose is a unitary operator on a complex Hilbert space . Then for each there exists a unique finite Borel measure on such that Then he remark that: If is an invertible measure-preserving transformation then is unitary, and if has continuous spectrum and then has no atoms. This is what I don't understand. How can we show that under such conditions, has no atoms? I found a related reference , and here Theorem 1.4 is related to what I want to know. And he left my question as an easy(?) exercise. Can somebody help me please?","U \mathcal{H} f \in \mathcal{H} \mu_{f} K = \{ z \in \mathbb{C} \ : \ |z| = 1\} (U^{n}f, f) = \int _{K} \lambda ^{n} d\mu_{f}(\lambda) \ \ \ \ \ \ \ \forall n \in \mathbb{Z}. T U_{T} T (f, 1) = 0 \mu_{f} \mu_{f}","['measure-theory', 'operator-theory']"
35,"Helly's Theorem Doesn't Hold for $L^\infty[0,1]$",Helly's Theorem Doesn't Hold for,"L^\infty[0,1]","Problem: Show that the conclusion is not true for $X=L^\infty[0,1]$. Here is my attempt, which I now realize is incorrect: Consider $f_n \in L^1[0,1] = Y$ defined by $f_n = n \cdot 1_{[0,1/n]}$. I already showed that no subsequence of $\{f_n\}$ converges weakly in $Y$. Let $T_n : X \to \Bbb{R}$ be defined by $T_n(f) = \int_X f \cdot f_n$. It's not hard to show $\{T_n\}$ is a bounded sequence. Hence, if Helly's theorem were true, there would exist a subsequence $\{T_{n_k}\}$ and $T \in X^*$ s.t. $T(f) = \lim_{k \to \infty} T_{n_k}(f)$. But $T(f) = \int_X f g$ for some $g \in Y$ and therefore $$\lim_{k \to \infty} \int_X f \cdot f_{n_k} = \int_X fg$$ for every $f \in X$. This means that $f_{n_k} \to g$ weakly in $Y$, which is a contradiction. As you may have noticed, I wrongly thought that the Riesz Representation theorem holds for $L^\infty[0,1]$...such a nice, quick solution, too...Is there anyway of fixing it? I found this question asked elsewhere on MSE, but the proposed solution uses the Hahn-Banach theorem, which is currently not at my disposal.","Problem: Show that the conclusion is not true for $X=L^\infty[0,1]$. Here is my attempt, which I now realize is incorrect: Consider $f_n \in L^1[0,1] = Y$ defined by $f_n = n \cdot 1_{[0,1/n]}$. I already showed that no subsequence of $\{f_n\}$ converges weakly in $Y$. Let $T_n : X \to \Bbb{R}$ be defined by $T_n(f) = \int_X f \cdot f_n$. It's not hard to show $\{T_n\}$ is a bounded sequence. Hence, if Helly's theorem were true, there would exist a subsequence $\{T_{n_k}\}$ and $T \in X^*$ s.t. $T(f) = \lim_{k \to \infty} T_{n_k}(f)$. But $T(f) = \int_X f g$ for some $g \in Y$ and therefore $$\lim_{k \to \infty} \int_X f \cdot f_{n_k} = \int_X fg$$ for every $f \in X$. This means that $f_{n_k} \to g$ weakly in $Y$, which is a contradiction. As you may have noticed, I wrongly thought that the Riesz Representation theorem holds for $L^\infty[0,1]$...such a nice, quick solution, too...Is there anyway of fixing it? I found this question asked elsewhere on MSE, but the proposed solution uses the Hahn-Banach theorem, which is currently not at my disposal.",,"['real-analysis', 'measure-theory', 'weak-convergence']"
36,"If $|f(x+y) - f(x)| \leq g(x)|y|$ for some $g \in L^1(\mathbb{R})$, then $\int_a^b f'(x) dx = f(b) - f(a)$ if $f'(a)$ and $f'(b)$ exist","If  for some , then  if  and  exist",|f(x+y) - f(x)| \leq g(x)|y| g \in L^1(\mathbb{R}) \int_a^b f'(x) dx = f(b) - f(a) f'(a) f'(b),"If $f$ is measurable and differentiable almost everywhere and if there is some $g \in L^1(\mathbb{R})$ such that $|f(x+y)-f(x)| \leq g(x)|y|$ for almost all $x \in \mathbb{R}$ and all $y \in \mathbb{R}$, then $f' \in L^1(\mathbb{R})$ and   $$\int_a^b f'(x)dx = f(b) - f(a)$$   if $f'(a)$ and $f'(b)$ exist. $f' \in L^1$ is obvious since $|f'| \leq g \in L^1$ almost everywhere, so I need advice on the second part. I have not found any way to make use of the hypotheses of $f'(a)$ and $f'(b)$ existing.  All of the relevant theorems I've reviewed for when $\int_a^b f'(x)dx = f(b) - f(a)$ hold for all $a$ and $b$ require stronger assumptions that do not seem to hold here.  So, the assumption that $f'(a)$ and $f'(b)$ exist must be vitally important, I presume. If we define $F(x) = \int_{-\infty}^x f'(t)dt$, then $F' = f'$ almost everywhere so $\int_a^b F' = \int_a^b f'$, but this doesn't seem to get me anywhere.  Any advice is appreciated.","If $f$ is measurable and differentiable almost everywhere and if there is some $g \in L^1(\mathbb{R})$ such that $|f(x+y)-f(x)| \leq g(x)|y|$ for almost all $x \in \mathbb{R}$ and all $y \in \mathbb{R}$, then $f' \in L^1(\mathbb{R})$ and   $$\int_a^b f'(x)dx = f(b) - f(a)$$   if $f'(a)$ and $f'(b)$ exist. $f' \in L^1$ is obvious since $|f'| \leq g \in L^1$ almost everywhere, so I need advice on the second part. I have not found any way to make use of the hypotheses of $f'(a)$ and $f'(b)$ existing.  All of the relevant theorems I've reviewed for when $\int_a^b f'(x)dx = f(b) - f(a)$ hold for all $a$ and $b$ require stronger assumptions that do not seem to hold here.  So, the assumption that $f'(a)$ and $f'(b)$ exist must be vitally important, I presume. If we define $F(x) = \int_{-\infty}^x f'(t)dt$, then $F' = f'$ almost everywhere so $\int_a^b F' = \int_a^b f'$, but this doesn't seem to get me anywhere.  Any advice is appreciated.",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
37,"Intuition behind ""surface measure"" in integration formula for polar coordinates","Intuition behind ""surface measure"" in integration formula for polar coordinates",,"In ""Real Analysis"" by Stein & Shakarchi, the polar coordinates of a point $x \in \mathbb{R}^d - \{0\}$ are the pair $(r,\gamma)$ where $0 < r < \infty$ and $\gamma$ belongs to the unit sphere $S^{d-1} = \{x \in \mathbb{R}^d : |x| =1\}$, determined by  $$r = |x|, \quad \gamma = \frac{x}{|x|}.$$ Furthermore, polar integration is defined as  $$\int_{\mathbb{R}^d} f(x)\,dx = \int_{S^{d-1}} \int_0^\infty f(r\gamma) r^{d-1}\,drd\sigma(\gamma).$$ This is explained in the text as the result of defining two measure spaces $(X_1,\mathcal{M}_1,\mu_1)$ and $(X_2,\mathcal{M}_2,\mu_2)$, where $\mathcal{M}_1$ is the collection of Lebesgue measurable sets in $X_1 =  (0,\infty)$ and $d\mu_1(r) = r^{d-1}\,dr$. Regarding the second measure space, we take $X_2 = S^{d-1}$ and the authors say that when $E \subseteq S^{d-1}$, to consider the set $\tilde{E} = \{x \in \mathbb{R}^d : x/|x| \in E, 0 < |x| < 1\}$ to be the subset of the unit ball. If $\tilde{E}$ is Lebesgue measurable, we say that $E \in \mathcal{M}_2$ and define $\mu_2(E) = \sigma(E) = d\cdot m(\tilde{E})$, where $m$ is the Lebesgue measure in $\mathbb{R}^d$. I am seeking intuition behind the ""surface measure."" How should I interpret the set $\tilde{E}$; that is, what does this set look like ? Furthermore, if the measure $\mu_2 = \sigma$ is defined in terms of the Lebesgue measure in $\mathbb{R}^d$, what is the significance of the factor of $d$? Why not define $\sigma(E) = m(\tilde{E})$?","In ""Real Analysis"" by Stein & Shakarchi, the polar coordinates of a point $x \in \mathbb{R}^d - \{0\}$ are the pair $(r,\gamma)$ where $0 < r < \infty$ and $\gamma$ belongs to the unit sphere $S^{d-1} = \{x \in \mathbb{R}^d : |x| =1\}$, determined by  $$r = |x|, \quad \gamma = \frac{x}{|x|}.$$ Furthermore, polar integration is defined as  $$\int_{\mathbb{R}^d} f(x)\,dx = \int_{S^{d-1}} \int_0^\infty f(r\gamma) r^{d-1}\,drd\sigma(\gamma).$$ This is explained in the text as the result of defining two measure spaces $(X_1,\mathcal{M}_1,\mu_1)$ and $(X_2,\mathcal{M}_2,\mu_2)$, where $\mathcal{M}_1$ is the collection of Lebesgue measurable sets in $X_1 =  (0,\infty)$ and $d\mu_1(r) = r^{d-1}\,dr$. Regarding the second measure space, we take $X_2 = S^{d-1}$ and the authors say that when $E \subseteq S^{d-1}$, to consider the set $\tilde{E} = \{x \in \mathbb{R}^d : x/|x| \in E, 0 < |x| < 1\}$ to be the subset of the unit ball. If $\tilde{E}$ is Lebesgue measurable, we say that $E \in \mathcal{M}_2$ and define $\mu_2(E) = \sigma(E) = d\cdot m(\tilde{E})$, where $m$ is the Lebesgue measure in $\mathbb{R}^d$. I am seeking intuition behind the ""surface measure."" How should I interpret the set $\tilde{E}$; that is, what does this set look like ? Furthermore, if the measure $\mu_2 = \sigma$ is defined in terms of the Lebesgue measure in $\mathbb{R}^d$, what is the significance of the factor of $d$? Why not define $\sigma(E) = m(\tilde{E})$?",,['measure-theory']
38,Proving a.e surjectivity of suggested factor map in Natural extension of Standard Borel dynamical system,Proving a.e surjectivity of suggested factor map in Natural extension of Standard Borel dynamical system,,"Let $(X,\mathcal B,\mu, T)$ be a measure preserving dynamical system on a standard Borel space. I'm trying to follow the construction of the natural extension by Michael Hochman on page 53 of his notes . This is very similar to the construction mentioned in this post, which unfortunately fails to answer the one question I have about the construction. For convenience let me repeat the essentials of the construction: We consider $X^\mathbb{Z}$, with the normal product $\sigma$ algebra $\tilde{\mathcal{B}}$, ensuring that each projection $\pi_n$ is measurable. The Kolmogorov extension theorem guarantees the existence of a probability measure $\tilde\mu$ on $\tilde{\mathcal{B}}$, such that the pushforward $\pi_{n*}\tilde\mu=\mu$ for all $n\in\mathbb Z$. The left shift $\tilde T$ is invertible, measurable, and measure preserving on $(X^\mathbb{Z},\tilde{\mathcal{B}},\tilde\mu)$. Now let us define  $$\tilde X=\{(x_n)\in X^\mathbb{Z}:Tx_n=x_{n+1},~n\in\mathbb Z\},$$ and redefine $\tilde{\mathcal{B}},\tilde\mu,$ and $\tilde T$ to be the relevant restrictions to $\tilde X^~$. Finally let us define $\pi:\tilde X\to X$ by $\pi=\pi_0|_{\tilde X}$. The goal is to show that $\pi$ is a factor map. I am happy with showing that $\pi$ is measurable, measure preserving, and that $\pi\circ \tilde T=T\circ \pi$, but what I have been unable to do is prove that $\mu(\operatorname{im}\pi)=1$, which we need if we want to call $\pi$ a factor map. My idea is to show that the set $A$ consisting of all $x\in X$ for which there is an infinite chain in the graph of all preimages of $x$ has full measure. To be more precise: $A$ consists of all $x\in X$ such there exists a sequence $(x_n)_{n\in\mathbb N_0}$ in $X$ such that $Tx_{n+1}=x_n$ for all $n$, and $x_0=x$. If $A$ does have full measure then we would be done, because for every $x\in A$ it would follow that $(\dots,x_2,x_1,x,Tx,T^2x,\dots)\in \tilde X$. Now I believe that we could construct $A$ as a clever countable intersection of sets of full measure, but I am currently not clever enough to see it. If anyone can see it I'd be much obliged. From scouring the interwebs I know that the existence of a natural extension of a dynamical system is closely related to the notion of the categorical inverse limit. Unfortunately category theory is one of the many need to be familiar with area of mathematics that I am not familiar with. I would still appreciate an answer phrased in terms of inverse limits (if it was explained in a gentle manner), because that can only help my familiarity with category theory. Any help is appreciated.","Let $(X,\mathcal B,\mu, T)$ be a measure preserving dynamical system on a standard Borel space. I'm trying to follow the construction of the natural extension by Michael Hochman on page 53 of his notes . This is very similar to the construction mentioned in this post, which unfortunately fails to answer the one question I have about the construction. For convenience let me repeat the essentials of the construction: We consider $X^\mathbb{Z}$, with the normal product $\sigma$ algebra $\tilde{\mathcal{B}}$, ensuring that each projection $\pi_n$ is measurable. The Kolmogorov extension theorem guarantees the existence of a probability measure $\tilde\mu$ on $\tilde{\mathcal{B}}$, such that the pushforward $\pi_{n*}\tilde\mu=\mu$ for all $n\in\mathbb Z$. The left shift $\tilde T$ is invertible, measurable, and measure preserving on $(X^\mathbb{Z},\tilde{\mathcal{B}},\tilde\mu)$. Now let us define  $$\tilde X=\{(x_n)\in X^\mathbb{Z}:Tx_n=x_{n+1},~n\in\mathbb Z\},$$ and redefine $\tilde{\mathcal{B}},\tilde\mu,$ and $\tilde T$ to be the relevant restrictions to $\tilde X^~$. Finally let us define $\pi:\tilde X\to X$ by $\pi=\pi_0|_{\tilde X}$. The goal is to show that $\pi$ is a factor map. I am happy with showing that $\pi$ is measurable, measure preserving, and that $\pi\circ \tilde T=T\circ \pi$, but what I have been unable to do is prove that $\mu(\operatorname{im}\pi)=1$, which we need if we want to call $\pi$ a factor map. My idea is to show that the set $A$ consisting of all $x\in X$ for which there is an infinite chain in the graph of all preimages of $x$ has full measure. To be more precise: $A$ consists of all $x\in X$ such there exists a sequence $(x_n)_{n\in\mathbb N_0}$ in $X$ such that $Tx_{n+1}=x_n$ for all $n$, and $x_0=x$. If $A$ does have full measure then we would be done, because for every $x\in A$ it would follow that $(\dots,x_2,x_1,x,Tx,T^2x,\dots)\in \tilde X$. Now I believe that we could construct $A$ as a clever countable intersection of sets of full measure, but I am currently not clever enough to see it. If anyone can see it I'd be much obliged. From scouring the interwebs I know that the existence of a natural extension of a dynamical system is closely related to the notion of the categorical inverse limit. Unfortunately category theory is one of the many need to be familiar with area of mathematics that I am not familiar with. I would still appreciate an answer phrased in terms of inverse limits (if it was explained in a gentle manner), because that can only help my familiarity with category theory. Any help is appreciated.",,"['measure-theory', 'dynamical-systems', 'ergodic-theory']"
39,"Proof verification that $\mu_f$($E$) $=$ $\int_E f\,d\lambda$ is a measure on $\mathcal M$.",Proof verification that ()   is a measure on .,"\mu_f E = \int_E f\,d\lambda \mathcal M","I was wondering if I had correctly proved this problem:  Let $f$ be a nonnegative $\mathcal M$-measurable function.  Define $\mu_f$ on $\mathcal M$ by $\mu_f$($E$) $=$ $\int_E f\,d\lambda$.  Prove that $\mu_f$ is a measure on $\mathcal M$. Here is my solution: Condition (1): Since $f$ is nonnegative, $f$ $\ge$ $0$.  Also since $f$ is $\mathcal M$-measurable function, we get for each $E$ $\in$ $\mathcal M$ that $\int_E f\,d\lambda$$\ge$ $0$.  Hence, $\mu_f$($E$) $\ge$ $0$ for each $E$ $\in$ $\mathcal M$. Condition(2):  Let $E$ $=$ $\emptyset$.  Since $\lambda$($E$) $=$ $0$, we have that $\int_E f\,d\lambda$ $=$ $0$.  So, $\mu_f$($\emptyset$) = $0$. Condition (3):  Let $\{E_n\}_{n=1}^{\infty}$ be a sequence of pairwise disjoint sets in $\mathcal M$.   Now because we also have that $E_n$ $\in$ $\mathcal M$ for each $n$ $\in$ $\Bbb N$, and $f$ is a nonnegative $\mathcal M$-measurable function, we have that $\int_{\bigcup_{n=1}^{\infty}E_n}f{\rm d}\lambda$ $=$ $\sum_{n=1}^{\infty}\int_{E_n}f$.  Hence, $\mu_f$(${\bigcup_{n=1}^{\infty}E_n}$) $=$  $\sum_{n=1}^{\infty}$($\mu_f$($E_n$))","I was wondering if I had correctly proved this problem:  Let $f$ be a nonnegative $\mathcal M$-measurable function.  Define $\mu_f$ on $\mathcal M$ by $\mu_f$($E$) $=$ $\int_E f\,d\lambda$.  Prove that $\mu_f$ is a measure on $\mathcal M$. Here is my solution: Condition (1): Since $f$ is nonnegative, $f$ $\ge$ $0$.  Also since $f$ is $\mathcal M$-measurable function, we get for each $E$ $\in$ $\mathcal M$ that $\int_E f\,d\lambda$$\ge$ $0$.  Hence, $\mu_f$($E$) $\ge$ $0$ for each $E$ $\in$ $\mathcal M$. Condition(2):  Let $E$ $=$ $\emptyset$.  Since $\lambda$($E$) $=$ $0$, we have that $\int_E f\,d\lambda$ $=$ $0$.  So, $\mu_f$($\emptyset$) = $0$. Condition (3):  Let $\{E_n\}_{n=1}^{\infty}$ be a sequence of pairwise disjoint sets in $\mathcal M$.   Now because we also have that $E_n$ $\in$ $\mathcal M$ for each $n$ $\in$ $\Bbb N$, and $f$ is a nonnegative $\mathcal M$-measurable function, we have that $\int_{\bigcup_{n=1}^{\infty}E_n}f{\rm d}\lambda$ $=$ $\sum_{n=1}^{\infty}\int_{E_n}f$.  Hence, $\mu_f$(${\bigcup_{n=1}^{\infty}E_n}$) $=$  $\sum_{n=1}^{\infty}$($\mu_f$($E_n$))",,['measure-theory']
40,"Measure of a subset of $[0,1]$",Measure of a subset of,"[0,1]","$A\subset[0,1]$ is set of all numbers with binary representation $0.c_1c_2c_3...$ where $c_i=0,1$ for all $i$ and $c_{i-1}c_{i+1}=0$ for all even $i$. How do I show that $A$ is zero measure set?","$A\subset[0,1]$ is set of all numbers with binary representation $0.c_1c_2c_3...$ where $c_i=0,1$ for all $i$ and $c_{i-1}c_{i+1}=0$ for all even $i$. How do I show that $A$ is zero measure set?",,"['real-analysis', 'measure-theory']"
41,Measurability of set of points where a measurable function sequence is strictly increasing pointwise,Measurability of set of points where a measurable function sequence is strictly increasing pointwise,,"Let $\{f_n\}$ be a sequence of measurable functions from $\mathbb{R}$ to itself. How do we show that the set $S=\{x\in\mathbb{R} \,\, |\,\, \{f_n(x)\} \,\text{is strictly increasing}\}$ is a measurable set? I think we need to write the set as a union and intersection of inverse images of $f_n$'s but I have no idea how to proceed. Please drop some hints!","Let $\{f_n\}$ be a sequence of measurable functions from $\mathbb{R}$ to itself. How do we show that the set $S=\{x\in\mathbb{R} \,\, |\,\, \{f_n(x)\} \,\text{is strictly increasing}\}$ is a measurable set? I think we need to write the set as a union and intersection of inverse images of $f_n$'s but I have no idea how to proceed. Please drop some hints!",,"['measure-theory', 'lebesgue-measure']"
42,Application Radon - Nikodym,Application Radon - Nikodym,,"I just learned about Radon-Nikodym theorem. However, I do not seem to have any intuition on how to apply it... For example : Let $(X,\mathscr{M},\lambda)$ be a $\sigma-$finite measure. Let $f$ be $\mathscr{M}$ measurable. Let $\mathscr{N} \subset \mathscr{M}$ be a $\sigma-$algebra. Prove that there exists an $\mathscr{N}$ measurable function $g$ such that  $$ \int_B f d\lambda = \int_B g d\lambda $$ for every $B\in \mathscr{N}$ Clearly this question feels like an application for the Radon-Nikodym theorem. However how can I find all the ingredients ? I have to find some signed measure $\mu$ which is absolutely continuous with respect to $\lambda$. Maybe $\mu(B) = \int_B f d\lambda$ is simply the answer.","I just learned about Radon-Nikodym theorem. However, I do not seem to have any intuition on how to apply it... For example : Let $(X,\mathscr{M},\lambda)$ be a $\sigma-$finite measure. Let $f$ be $\mathscr{M}$ measurable. Let $\mathscr{N} \subset \mathscr{M}$ be a $\sigma-$algebra. Prove that there exists an $\mathscr{N}$ measurable function $g$ such that  $$ \int_B f d\lambda = \int_B g d\lambda $$ for every $B\in \mathscr{N}$ Clearly this question feels like an application for the Radon-Nikodym theorem. However how can I find all the ingredients ? I have to find some signed measure $\mu$ which is absolutely continuous with respect to $\lambda$. Maybe $\mu(B) = \int_B f d\lambda$ is simply the answer.",,"['measure-theory', 'radon-nikodym']"
43,Inequality of means for functions,Inequality of means for functions,,"According to Wikipedia one can define the arithmetic mean of an integrable function $f: M \to \mathbb{R}$ over a relatively compact domain $M$ as: $$A(f) = \frac{1}{\mu(M)}\int_M f$$ where $\mu(M)$ is the measure of $M$. Moreover, if $f > 0$ one can also define its geometric mean as: $$G(f) = \exp\left(\frac{1}{\mu(M)}\int_M \log f\right)$$ The inequality of the arithmetic and geometric means is a well-known result in the discrete case. ¿Is it also true in this context? That is, is it true that : $$A(f) \geq G(f)$$ for every positive integrable function $f$?","According to Wikipedia one can define the arithmetic mean of an integrable function $f: M \to \mathbb{R}$ over a relatively compact domain $M$ as: $$A(f) = \frac{1}{\mu(M)}\int_M f$$ where $\mu(M)$ is the measure of $M$. Moreover, if $f > 0$ one can also define its geometric mean as: $$G(f) = \exp\left(\frac{1}{\mu(M)}\int_M \log f\right)$$ The inequality of the arithmetic and geometric means is a well-known result in the discrete case. ¿Is it also true in this context? That is, is it true that : $$A(f) \geq G(f)$$ for every positive integrable function $f$?",,"['measure-theory', 'lebesgue-integral', 'means']"
44,Probability space,Probability space,,"Let $(X,\mathcal{M})$ be a $\sigma$-algebra where $\mathcal{M}:=\{A\subset X: A \hspace{0.2cm}\mbox{or} \hspace{0.2cm} X\setminus A \hspace{0.2cm}\mbox{is countable} \}$. I want to find all the $\mu\colon \mathcal{M} \longrightarrow [0,1]$ measures that turn $(X,\mathcal{M},\mu)$ into a probability space.","Let $(X,\mathcal{M})$ be a $\sigma$-algebra where $\mathcal{M}:=\{A\subset X: A \hspace{0.2cm}\mbox{or} \hspace{0.2cm} X\setminus A \hspace{0.2cm}\mbox{is countable} \}$. I want to find all the $\mu\colon \mathcal{M} \longrightarrow [0,1]$ measures that turn $(X,\mathcal{M},\mu)$ into a probability space.",,['measure-theory']
45,For measurable function with $h(x+a)=h(x)$ almost everywhere exists $g=h$ where it holds for all $x$,For measurable function with  almost everywhere exists  where it holds for all,h(x+a)=h(x) g=h x,"Excuse the question, I found it hard to word it compactly. Say I have $a \in \mathbb{R}^n\backslash \{0\}$ and  $h:  \mathbb{R}^n \rightarrow  \mathbb{R} $ and $$h(x+a)=h(x)$$ for almost all $x$ ( i.e. up until a zero measure set ) and where h is measurable. I want to show then, that there exists $ g:  \mathbb{R}^n \rightarrow  \mathbb{R} $ and $g(x+a)=g(x)$ for ALL $x$ and also $h=g$ almost everywhere. I'm not looking for a solution , but I've never done such an exercise before and I'm not sure how to approach it. So I'm thinking we just have to define a set first, i.e. $A:= \{x \in\mathbb{R}^n | h(x) \neq h(x+a)\}$ and then a function $$ g(x)=  \begin{cases} h(x) &x \not\in A \\ h(x+a) &x \in A \end{cases} $$ and actually, shouldn't $g$ have all the wanted properties now? I don't think the exercise is that simple and I do think I need to use the measurability of $f$ somewhere, but I don't see why or how. Is my approach correct? If not,  how can I approach it?","Excuse the question, I found it hard to word it compactly. Say I have $a \in \mathbb{R}^n\backslash \{0\}$ and  $h:  \mathbb{R}^n \rightarrow  \mathbb{R} $ and $$h(x+a)=h(x)$$ for almost all $x$ ( i.e. up until a zero measure set ) and where h is measurable. I want to show then, that there exists $ g:  \mathbb{R}^n \rightarrow  \mathbb{R} $ and $g(x+a)=g(x)$ for ALL $x$ and also $h=g$ almost everywhere. I'm not looking for a solution , but I've never done such an exercise before and I'm not sure how to approach it. So I'm thinking we just have to define a set first, i.e. $A:= \{x \in\mathbb{R}^n | h(x) \neq h(x+a)\}$ and then a function $$ g(x)=  \begin{cases} h(x) &x \not\in A \\ h(x+a) &x \in A \end{cases} $$ and actually, shouldn't $g$ have all the wanted properties now? I don't think the exercise is that simple and I do think I need to use the measurability of $f$ somewhere, but I don't see why or how. Is my approach correct? If not,  how can I approach it?",,"['real-analysis', 'measure-theory']"
46,Is the essential derivative of a convex function continuous?,Is the essential derivative of a convex function continuous?,,"Suppose that $f:\mathbb{R}\rightarrow\mathbb{R}$ is convex on $\mathbb{R}$, but not necessarily differentiable everywhere. We know, though, that such a function will be differentiable almost everywhere, and that the set of points where $f$ is nondifferentiable, call this $\cal{A}$, is at most countable, and of Lebesgue measure zero. Then, the derivative of $f$, call it $f'$, exists on $\mathbb{R}\setminus\cal{A}$. Question #1: Is $f'$ continuous on $\mathbb{R}\setminus\cal{A}$? Question #2: Does the result change if $f$ is nondecreasing? I ask these questions because we know that a convex, differentiable function on $\mathbb{R}$ has a continuous derivative; I am just wondering if this proposition can be extended as described above. Thanks!","Suppose that $f:\mathbb{R}\rightarrow\mathbb{R}$ is convex on $\mathbb{R}$, but not necessarily differentiable everywhere. We know, though, that such a function will be differentiable almost everywhere, and that the set of points where $f$ is nondifferentiable, call this $\cal{A}$, is at most countable, and of Lebesgue measure zero. Then, the derivative of $f$, call it $f'$, exists on $\mathbb{R}\setminus\cal{A}$. Question #1: Is $f'$ continuous on $\mathbb{R}\setminus\cal{A}$? Question #2: Does the result change if $f$ is nondecreasing? I ask these questions because we know that a convex, differentiable function on $\mathbb{R}$ has a continuous derivative; I am just wondering if this proposition can be extended as described above. Thanks!",,"['real-analysis', 'measure-theory', 'convex-analysis', 'convex-optimization']"
47,Minimum over Probability Measures,Minimum over Probability Measures,,"Let $f$ and $g$ be polynomials in $\mathbf x \in \mathbb R^n$.  Let $X$ be a compact subset of $\mathbb R^n$.  Finally, Let $\mathcal M(X)$ be the set of probability measures over $X$. Can the optimization problem \begin{equation} \inf_{P\in \mathcal M(X)} \left ( \int f \ dP\right )^2 - \left ( \int g \ dP\right )^2 \end{equation} be expressed exclusively in terms of the polynomials $f$ and $g$, without reference to the measure $P$? For example, my hunch is that the above optimization problem is equivalent to \begin{equation} \min_{\mathbf x \in X} f(\mathbf x)^2 - g(\mathbf x)^2, \end{equation} but I don't know how to prove this.  Anyone have any ideas?","Let $f$ and $g$ be polynomials in $\mathbf x \in \mathbb R^n$.  Let $X$ be a compact subset of $\mathbb R^n$.  Finally, Let $\mathcal M(X)$ be the set of probability measures over $X$. Can the optimization problem \begin{equation} \inf_{P\in \mathcal M(X)} \left ( \int f \ dP\right )^2 - \left ( \int g \ dP\right )^2 \end{equation} be expressed exclusively in terms of the polynomials $f$ and $g$, without reference to the measure $P$? For example, my hunch is that the above optimization problem is equivalent to \begin{equation} \min_{\mathbf x \in X} f(\mathbf x)^2 - g(\mathbf x)^2, \end{equation} but I don't know how to prove this.  Anyone have any ideas?",,"['measure-theory', 'polynomials', 'probability-distributions', 'optimization', 'sums-of-squares']"
48,Is there a translation $\tau:\mathbb R\to \mathbb R$ for which $\tau(A_1)\cap A_2$ has positive Lebesgue measure?,Is there a translation  for which  has positive Lebesgue measure?,\tau:\mathbb R\to \mathbb R \tau(A_1)\cap A_2,"Let $A_1, A_2$ be bounded disjoint Lebesgue measurable subsets of $\mathbb R$, each of which has positive measure. Is there a translation $\tau:\mathbb R\to \mathbb R$ for which $\tau(A_1)\cap A_2$ has positive Lebesgue measure? The question I'm actually interested in is the following: Let $A_1, A_2\subset \mathbb S^n$ be disjoint measurable subsets, each of which has positive measure. Is there a rotation $R$ of the sphere for which the measure of $R(A_1)\cap A_2$ is positive? I think I may be able to answer it if I can get some insight to the simpler question posed above.","Let $A_1, A_2$ be bounded disjoint Lebesgue measurable subsets of $\mathbb R$, each of which has positive measure. Is there a translation $\tau:\mathbb R\to \mathbb R$ for which $\tau(A_1)\cap A_2$ has positive Lebesgue measure? The question I'm actually interested in is the following: Let $A_1, A_2\subset \mathbb S^n$ be disjoint measurable subsets, each of which has positive measure. Is there a rotation $R$ of the sphere for which the measure of $R(A_1)\cap A_2$ is positive? I think I may be able to answer it if I can get some insight to the simpler question posed above.",,['measure-theory']
49,"Measure theory, notation question, a.e.","Measure theory, notation question, a.e.",,I have in my notes $$\|f\|_\infty := \inf\{c\in \mathbb{R} : |f(\omega)|\leq c \quad a.e. \}$$ Can I take that to mean $$\|f\|_\infty := \inf\{c\in \mathbb{R} : |f(\omega)|\leq c \quad \forall \omega \in A \; st\; \mu(A^c)=0 \}$$,I have in my notes $$\|f\|_\infty := \inf\{c\in \mathbb{R} : |f(\omega)|\leq c \quad a.e. \}$$ Can I take that to mean $$\|f\|_\infty := \inf\{c\in \mathbb{R} : |f(\omega)|\leq c \quad \forall \omega \in A \; st\; \mu(A^c)=0 \}$$,,"['measure-theory', 'notation']"
50,On the example of the The Hahn decomposition,On the example of the The Hahn decomposition,,"Suppose $d\nu = fdm$ is the measure for the following function $f$, $$ f(x)= \begin{cases} x& \text{if}~x\geq 1;\\ 0& \text{if}~-1<x\leq 1; \\ -x^2& \text{if}~x\leq -1;\\ \end{cases}  $$  I am trying to construct an elaborative example to understand the Hahn decomposition and the Jordan decomposition of $\nu$ in the following manner: The positive set $P=\{x\in\mathbb{R}; \nu(E)=\int_1^{+\infty}xdx\}=+\infty>0$ The negative set $N=\{x\in\mathbb{R}; \nu(E)=\int_{-\infty}^{-1}-x^2dx\}=-\infty<0$ and the null set $M=\{x\in\mathbb{R}; \nu(E)=\int_{-1}^{1}0dx\}=0$ The Jordan decomposition of $\nu$ is the set $\{-\nu,+\nu\}$ I thought The Hahn decomposition is the set $\{P,N\}$ since $P\cap N=\emptyset$. However, $\mathbb{R}\neq P\cup N$. Please, help me rectify all the shortcomings in my attempt on the  Hahn decomposition, Jordan decomposition and compute the total variation of $\nu$.","Suppose $d\nu = fdm$ is the measure for the following function $f$, $$ f(x)= \begin{cases} x& \text{if}~x\geq 1;\\ 0& \text{if}~-1<x\leq 1; \\ -x^2& \text{if}~x\leq -1;\\ \end{cases}  $$  I am trying to construct an elaborative example to understand the Hahn decomposition and the Jordan decomposition of $\nu$ in the following manner: The positive set $P=\{x\in\mathbb{R}; \nu(E)=\int_1^{+\infty}xdx\}=+\infty>0$ The negative set $N=\{x\in\mathbb{R}; \nu(E)=\int_{-\infty}^{-1}-x^2dx\}=-\infty<0$ and the null set $M=\{x\in\mathbb{R}; \nu(E)=\int_{-1}^{1}0dx\}=0$ The Jordan decomposition of $\nu$ is the set $\{-\nu,+\nu\}$ I thought The Hahn decomposition is the set $\{P,N\}$ since $P\cap N=\emptyset$. However, $\mathbb{R}\neq P\cup N$. Please, help me rectify all the shortcomings in my attempt on the  Hahn decomposition, Jordan decomposition and compute the total variation of $\nu$.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
51,find the limit of a measure,find the limit of a measure,,"Suppose $E$ is a Lebesgue measurable set of finite measure. Find $$\lim_{h\to 0^+} \frac{m(E\cap[x,x+h])}{h}$$.  It seems to me that this limit is the indicator function over E, if we consider it into two cases: x in E and x not in E. In the case when x is in E, I want to have the fraction equal to 1 when h is sufficiently small, but I got stuck. Please help me, thank you","Suppose $E$ is a Lebesgue measurable set of finite measure. Find $$\lim_{h\to 0^+} \frac{m(E\cap[x,x+h])}{h}$$.  It seems to me that this limit is the indicator function over E, if we consider it into two cases: x in E and x not in E. In the case when x is in E, I want to have the fraction equal to 1 when h is sufficiently small, but I got stuck. Please help me, thank you",,['measure-theory']
52,Smallest sigma-algebra on which difference of measurable functions is measurable?,Smallest sigma-algebra on which difference of measurable functions is measurable?,,"Let's assume that $f,g$ are $\mathcal{A},\mathcal{B}(\mathbb{R}^n)$ measurable. Then we know by the usual theorem that $f-g$ is also $\mathcal{A},\mathcal{B}(\mathbb{R}^n)$ measurable. But what's the smallest sigma-algebra $\mathcal{A}$ on which the $f-g$ is measurable? Motivation: This question comes from reading on book an example of a random variable $Y_n:=X_{2n}-X_{2n-1}$. The author states that $Y_n$ is $\sigma(X_{2n},X_{2n-1}),\mathcal{B}(\mathbb{R}^n)$ measurable. And I wondered why... Also have another question, related to this. Is $(f-g)^{-1}(\mathcal{B}(\mathbb{R}^n)) \subset \sigma\{f^{-1}(\mathcal{B}(\mathbb{R}^n))\cup g^{-1}(\mathcal{B}(\mathbb{R}^n))\}$?","Let's assume that $f,g$ are $\mathcal{A},\mathcal{B}(\mathbb{R}^n)$ measurable. Then we know by the usual theorem that $f-g$ is also $\mathcal{A},\mathcal{B}(\mathbb{R}^n)$ measurable. But what's the smallest sigma-algebra $\mathcal{A}$ on which the $f-g$ is measurable? Motivation: This question comes from reading on book an example of a random variable $Y_n:=X_{2n}-X_{2n-1}$. The author states that $Y_n$ is $\sigma(X_{2n},X_{2n-1}),\mathcal{B}(\mathbb{R}^n)$ measurable. And I wondered why... Also have another question, related to this. Is $(f-g)^{-1}(\mathcal{B}(\mathbb{R}^n)) \subset \sigma\{f^{-1}(\mathcal{B}(\mathbb{R}^n))\cup g^{-1}(\mathcal{B}(\mathbb{R}^n))\}$?",,['measure-theory']
53,Decompose a simple function into the sum of two simple functions,Decompose a simple function into the sum of two simple functions,,"Let $(\Omega, \mathscr F)$ be a measurable space and let $f,g : \Omega \to \mathbb R$ be non-negative Borel functions. Suppose that $\psi$ is a non-negative simple function, i.e. $\psi = \sum_{i=1}^n a_i \mathbf 1_{A_i}$ for some partition $\{A_i\}$ of $\Omega$ and some non-negative real numbers $\{a_i\}$, and that $\forall \omega \in \Omega$ $0 \leq \psi(\omega) \leq f(\omega) + g(\omega)$. By $\mathbf 1_{A}$ I mean the indicator function for the set $A$. I want to decompose $\psi$ into the sum of two simple functions $\varphi$ and $\varphi'$ where $0 \leq \varphi \leq f$ and $0 \leq \varphi' \leq g$. I believe this to be possible but I'm finding it difficult to prove. One example that I've been thinking about is taking $\Omega = [0, \pi/2]$, $f(x) = \sin(x) + 1$, and $g(x) = -\sin(x) + 1$. This means that $f + g = 2$, so I can take $\psi(x) = 1.99 \cdot \mathbf 1_{[0,\pi/2]}$. I can split this $\psi$ up, but I end up needing $\varphi$ and $\varphi'$ to be Riemann sum-like functions involving a large number of steps. This suggests that a constructive proof will be very difficult since $f + g$ and $\psi$ may be very simple, yet $f$ and $g$ separately can be extremely complicated. I've considered trying to show that we can find $\varphi$ and $\varphi'$ such that their sum is arbitrarily close to $\psi$, but that would require some kind of norm on my simple functions and I haven't introduced that yet. I haven't even mentioned a measure. I'm hoping there's a proof that doesn't require introducing new machinery like that. Update @Hagen von Eitzen has pointed out that this is not generally true if $\psi \leq f + g$ is allowed, so I will require $\psi < f + g$.","Let $(\Omega, \mathscr F)$ be a measurable space and let $f,g : \Omega \to \mathbb R$ be non-negative Borel functions. Suppose that $\psi$ is a non-negative simple function, i.e. $\psi = \sum_{i=1}^n a_i \mathbf 1_{A_i}$ for some partition $\{A_i\}$ of $\Omega$ and some non-negative real numbers $\{a_i\}$, and that $\forall \omega \in \Omega$ $0 \leq \psi(\omega) \leq f(\omega) + g(\omega)$. By $\mathbf 1_{A}$ I mean the indicator function for the set $A$. I want to decompose $\psi$ into the sum of two simple functions $\varphi$ and $\varphi'$ where $0 \leq \varphi \leq f$ and $0 \leq \varphi' \leq g$. I believe this to be possible but I'm finding it difficult to prove. One example that I've been thinking about is taking $\Omega = [0, \pi/2]$, $f(x) = \sin(x) + 1$, and $g(x) = -\sin(x) + 1$. This means that $f + g = 2$, so I can take $\psi(x) = 1.99 \cdot \mathbf 1_{[0,\pi/2]}$. I can split this $\psi$ up, but I end up needing $\varphi$ and $\varphi'$ to be Riemann sum-like functions involving a large number of steps. This suggests that a constructive proof will be very difficult since $f + g$ and $\psi$ may be very simple, yet $f$ and $g$ separately can be extremely complicated. I've considered trying to show that we can find $\varphi$ and $\varphi'$ such that their sum is arbitrarily close to $\psi$, but that would require some kind of norm on my simple functions and I haven't introduced that yet. I haven't even mentioned a measure. I'm hoping there's a proof that doesn't require introducing new machinery like that. Update @Hagen von Eitzen has pointed out that this is not generally true if $\psi \leq f + g$ is allowed, so I will require $\psi < f + g$.",,"['real-analysis', 'measure-theory']"
54,Rotation Invariance of measure,Rotation Invariance of measure,,"i know that lebesgue measure is rotation invariant but can anyone please tell me that why $\sigma$ on $S^{n-1}$ is invariant under rotation where $$\sigma (E)=n\mu_n(E_1)$$ where $\mu_n$ is the lebesgue measure on $\mathbb R^n$ and $E_1=\{rx' : ~r\in (0,1] ~\And~x'\in E\}$ and $E\in \mathbb B(S^{n-1})$. as i was able to think it may be due to dependency of $\sigma$ on $\mu_n$ and the property that $\mu_n$ is rotation invariant but i am not sure about my argument. Any type of help will be appreciated.Thanks in advance.","i know that lebesgue measure is rotation invariant but can anyone please tell me that why $\sigma$ on $S^{n-1}$ is invariant under rotation where $$\sigma (E)=n\mu_n(E_1)$$ where $\mu_n$ is the lebesgue measure on $\mathbb R^n$ and $E_1=\{rx' : ~r\in (0,1] ~\And~x'\in E\}$ and $E\in \mathbb B(S^{n-1})$. as i was able to think it may be due to dependency of $\sigma$ on $\mu_n$ and the property that $\mu_n$ is rotation invariant but i am not sure about my argument. Any type of help will be appreciated.Thanks in advance.",,['measure-theory']
55,Equivalent definitions of purely finitely additive measures,Equivalent definitions of purely finitely additive measures,,"I'm studying finitely additive measures and have come across the following definition. A finitely additive measure $\mu$ on $(\Omega, \mathcal{F})$ is purely finitely additive if for all countably additive measures $\nu$ on $(\Omega, \mathcal{F})$ and all $A \in \mathcal{F}$, $0 \leq \nu(A) \leq \mu(A)$ implies $\nu = 0$. Formally, I'm fine with this definition, but I feel I'm lacking intuition about it. I had expected a purely finitely additive measure to be a finitely additive measure that is not countably additive. That is, if $\mu$ is purely finitely additive, I expected that there exists a countably infinite disjoint sequence $\{ A_n: n \in \mathbb{N}\}$ in $\mathcal{F}$ such that $\sum_{n \in \mathbb{N}}\mu(A_n) < \mu(A)$, where $A = \cup_{n \in \mathbb{N}}A_n$. I am unable to prove or disprove that this latter assertion is equivalent to the definition above. Could someone give me some hints or guidance?","I'm studying finitely additive measures and have come across the following definition. A finitely additive measure $\mu$ on $(\Omega, \mathcal{F})$ is purely finitely additive if for all countably additive measures $\nu$ on $(\Omega, \mathcal{F})$ and all $A \in \mathcal{F}$, $0 \leq \nu(A) \leq \mu(A)$ implies $\nu = 0$. Formally, I'm fine with this definition, but I feel I'm lacking intuition about it. I had expected a purely finitely additive measure to be a finitely additive measure that is not countably additive. That is, if $\mu$ is purely finitely additive, I expected that there exists a countably infinite disjoint sequence $\{ A_n: n \in \mathbb{N}\}$ in $\mathcal{F}$ such that $\sum_{n \in \mathbb{N}}\mu(A_n) < \mu(A)$, where $A = \cup_{n \in \mathbb{N}}A_n$. I am unable to prove or disprove that this latter assertion is equivalent to the definition above. Could someone give me some hints or guidance?",,['measure-theory']
56,Does $A$ contain a set of positive measure that is symmetric about $(a+b)/2$?,Does  contain a set of positive measure that is symmetric about ?,A (a+b)/2,"Let $A \subset [a,b]$ with $m(A)>\dfrac 12 (b-a)$ , where $m$ is the Lebesgue measure . Then is it true that $A$ contains a subset of positive measure which is symmetric about $(a+b)/2$ ? ( we say that a subset $S$ of real line is symmetric about a real number $c$ if $c+x \in S \iff c-x \in S$ ) My idea was like to take $T:=\{x \in [a,b] : x+(a+b)/2 , (a+b)/2-x \in A\}$ and then take $B:=(\dfrac {a+b}2 +T) \cup (\dfrac {a+b}2 -T)$ ; definitely $B$ is the largest symmetric set about $(a+b)/2$ in $A$ . But I don't know how  to get the required set from here . Please help . Thanks in advance","Let $A \subset [a,b]$ with $m(A)>\dfrac 12 (b-a)$ , where $m$ is the Lebesgue measure . Then is it true that $A$ contains a subset of positive measure which is symmetric about $(a+b)/2$ ? ( we say that a subset $S$ of real line is symmetric about a real number $c$ if $c+x \in S \iff c-x \in S$ ) My idea was like to take $T:=\{x \in [a,b] : x+(a+b)/2 , (a+b)/2-x \in A\}$ and then take $B:=(\dfrac {a+b}2 +T) \cup (\dfrac {a+b}2 -T)$ ; definitely $B$ is the largest symmetric set about $(a+b)/2$ in $A$ . But I don't know how  to get the required set from here . Please help . Thanks in advance",,['real-analysis']
57,Bartle's Theorem 6.14 Completeness of $L^p$ (Riesz Representation)- need explanation,Bartle's Theorem 6.14 Completeness of  (Riesz Representation)- need explanation,L^p,"Note: There are 4 parts to my questions, I have labelled (and colored them, sorry if that is irritating) with (1), (2), (3) and (4) of the proof. Any answer to parts is great. Thanks! Completeness Theorem. If $1 \le p < \infty$, then the space $L_p$ is a complete normed linear space under the norm    $$ ||f ||_p = \Big \{ \int |f|^p \, d \mu \Big \} ^{1/p}. $$ Proof: Let $(f_n)$ be a Cauchy sequence relative to the norm $|| \, \, || _p$. There exists a sub-sequence $(g_k)$ of $(f_n)$ such that $||g_{k+1} - g_k || _p < 2^{-k}$ for $k \in \mathbb{N}$. Define $g$ by    $$ g(x) = |g_1(x) | + \sum_{k=1}^{\infty} |g_{k+1}(x) - g_k(x) |$$   so $g : X \rightarrow \bar{ \mathbb{R}}^{+}$ is measurable. By Fatou's Lemma, we have    $$ \color{blue}{ \int |g|^p \, d \mu \le \lim \inf _{n \rightarrow \infty} \int \Big \{ |g_1| + \sum_{k=1}^n |g_{k+1}- g_k| \Big \}^p \, d \mu \quad \quad (1) } $$   Taking the $p^{th}$ root of both sides and apply Minkowski's Inequality to obtain,    $$ \color{blue} { \Big \{ \int |g|^p \, d \mu \Big \} ^{1/p } \le \lim \inf_{n \rightarrow \infty} \Big \{ ||g_1||_p + \sum_{k=1}^n ||g_{k+1} - g_k||_p \Big \} \quad (2) } $$   $$ \le ||g_1||_p + 1. $$    Hence, if $E = \{x \in X:g(x) < + \infty \},$ then $\color{blue}{ \text{  $E$ is a measurable set and $\mu(X \setminus E) = 0$. } \quad (3) } $ Therefore, $\color{blue}{ \text{ the series in $g(x)$ converges almost everywhere and $g\, \chi_E$ belongs to $L_p$. } \quad (4) } $ My questions regarding (1) : By construction $$g(x) = |g_1(x)| + \lim \sum_{k=1}^n |g_{k+1}(x) -  g_k(x)| $$ $$ =  |g_1(x) | + \lim \inf \sum_{k=1}^n |g_{k+1}(x) - g_k(x) |. $$ Is this right? (2) : If we take the $p^{th}$ root we would obtain, an exponent of $1/p$ outside of the $\lim \inf $. That is, from (1) we should obtain $$ \Big( \lim \inf _{n \rightarrow \infty} \int \Big \{ |g_1| + \sum_{k=1}^n |g_{k+1}- g_k| \Big \}^p \, d \mu \Big) ^{1/p} $$  so we could not directly apply Minkowski's. Does this mean it's true, for a sequence $a_n$ and continuous function $f$ that $f ( \lim \inf a_n) \le \lim \inf f(a_n)$? (3) & (4) : It is unclear why these statements are true. Thanks in advance. Minkowski's Inequality. If $f$ and $h$ belong to $L_p$, $p \ge 1 $ then $f+h$ belongs to $L_p$ and    $$ ||f+h||_p \le ||f||_p + ||h||_p $$","Note: There are 4 parts to my questions, I have labelled (and colored them, sorry if that is irritating) with (1), (2), (3) and (4) of the proof. Any answer to parts is great. Thanks! Completeness Theorem. If $1 \le p < \infty$, then the space $L_p$ is a complete normed linear space under the norm    $$ ||f ||_p = \Big \{ \int |f|^p \, d \mu \Big \} ^{1/p}. $$ Proof: Let $(f_n)$ be a Cauchy sequence relative to the norm $|| \, \, || _p$. There exists a sub-sequence $(g_k)$ of $(f_n)$ such that $||g_{k+1} - g_k || _p < 2^{-k}$ for $k \in \mathbb{N}$. Define $g$ by    $$ g(x) = |g_1(x) | + \sum_{k=1}^{\infty} |g_{k+1}(x) - g_k(x) |$$   so $g : X \rightarrow \bar{ \mathbb{R}}^{+}$ is measurable. By Fatou's Lemma, we have    $$ \color{blue}{ \int |g|^p \, d \mu \le \lim \inf _{n \rightarrow \infty} \int \Big \{ |g_1| + \sum_{k=1}^n |g_{k+1}- g_k| \Big \}^p \, d \mu \quad \quad (1) } $$   Taking the $p^{th}$ root of both sides and apply Minkowski's Inequality to obtain,    $$ \color{blue} { \Big \{ \int |g|^p \, d \mu \Big \} ^{1/p } \le \lim \inf_{n \rightarrow \infty} \Big \{ ||g_1||_p + \sum_{k=1}^n ||g_{k+1} - g_k||_p \Big \} \quad (2) } $$   $$ \le ||g_1||_p + 1. $$    Hence, if $E = \{x \in X:g(x) < + \infty \},$ then $\color{blue}{ \text{  $E$ is a measurable set and $\mu(X \setminus E) = 0$. } \quad (3) } $ Therefore, $\color{blue}{ \text{ the series in $g(x)$ converges almost everywhere and $g\, \chi_E$ belongs to $L_p$. } \quad (4) } $ My questions regarding (1) : By construction $$g(x) = |g_1(x)| + \lim \sum_{k=1}^n |g_{k+1}(x) -  g_k(x)| $$ $$ =  |g_1(x) | + \lim \inf \sum_{k=1}^n |g_{k+1}(x) - g_k(x) |. $$ Is this right? (2) : If we take the $p^{th}$ root we would obtain, an exponent of $1/p$ outside of the $\lim \inf $. That is, from (1) we should obtain $$ \Big( \lim \inf _{n \rightarrow \infty} \int \Big \{ |g_1| + \sum_{k=1}^n |g_{k+1}- g_k| \Big \}^p \, d \mu \Big) ^{1/p} $$  so we could not directly apply Minkowski's. Does this mean it's true, for a sequence $a_n$ and continuous function $f$ that $f ( \lim \inf a_n) \le \lim \inf f(a_n)$? (3) & (4) : It is unclear why these statements are true. Thanks in advance. Minkowski's Inequality. If $f$ and $h$ belong to $L_p$, $p \ge 1 $ then $f+h$ belongs to $L_p$ and    $$ ||f+h||_p \le ||f||_p + ||h||_p $$",,"['measure-theory', 'inequality', 'proof-verification', 'lebesgue-measure', 'proof-explanation']"
58,"Prove that union, intersection and difference of measurable sets is measurable using specific definition of measurability","Prove that union, intersection and difference of measurable sets is measurable using specific definition of measurability",,"I found a lot of questions with the similar title on the forum, but not all of them are properly answered and those, which are, differ significantly from mine. I work in the closed interval $[0,1]$. I use the following definition of Lebesgue measurability: $\mathbf{Def. 1}$ The set E is called measurable iff $$\lambda^{*}(E)+\lambda^{*}([0,1]\backslash E)=1,$$ where $\lambda^{*}$ is the outer lebesgue measure, i.e. $\lambda^{*}(E)=\inf_{U\supset E}\lambda(U)$, where $U$ is an open set. I can prove that this definition is equivalent to the following: $\mathbf{Def. 2}$ The set E is called measurable iff $\forall \epsilon >0 \ \exists U_{\epsilon} ,F_{\epsilon}$ - open and closed sets respectively, such that $F_{\epsilon} \subset E \subset U_{\epsilon}\ \lambda^{*}(U_{\epsilon})-\lambda^{*}(F_{\epsilon})<\epsilon$. $\sigma$-additivity for $\lambda$ is also proven (for a measurable set $E$: $\lambda(E)=\lambda^{*}(E))$ : If $\{E_n\}$ - a collection of measurable sets and $E_k\cap E_l = \varnothing$ then $\lambda \left (\bigcup_{n=1}^{\infty}E_n \right)=\sum_{n=1}^\infty{\lambda(E_n)}$. And here is my question: a) If $A$ and $B$ are measurable sets (they may intersect) prove that $A\cup B, A\cap B, A\backslash B$ are measurable using $\mathbf{ Def. 1}$ or $\mathbf{ Def. 2}$. b) Prove that countable intersection and countable union of the measurable sets is measurable. I'd appreciate your help, guys.","I found a lot of questions with the similar title on the forum, but not all of them are properly answered and those, which are, differ significantly from mine. I work in the closed interval $[0,1]$. I use the following definition of Lebesgue measurability: $\mathbf{Def. 1}$ The set E is called measurable iff $$\lambda^{*}(E)+\lambda^{*}([0,1]\backslash E)=1,$$ where $\lambda^{*}$ is the outer lebesgue measure, i.e. $\lambda^{*}(E)=\inf_{U\supset E}\lambda(U)$, where $U$ is an open set. I can prove that this definition is equivalent to the following: $\mathbf{Def. 2}$ The set E is called measurable iff $\forall \epsilon >0 \ \exists U_{\epsilon} ,F_{\epsilon}$ - open and closed sets respectively, such that $F_{\epsilon} \subset E \subset U_{\epsilon}\ \lambda^{*}(U_{\epsilon})-\lambda^{*}(F_{\epsilon})<\epsilon$. $\sigma$-additivity for $\lambda$ is also proven (for a measurable set $E$: $\lambda(E)=\lambda^{*}(E))$ : If $\{E_n\}$ - a collection of measurable sets and $E_k\cap E_l = \varnothing$ then $\lambda \left (\bigcup_{n=1}^{\infty}E_n \right)=\sum_{n=1}^\infty{\lambda(E_n)}$. And here is my question: a) If $A$ and $B$ are measurable sets (they may intersect) prove that $A\cup B, A\cap B, A\backslash B$ are measurable using $\mathbf{ Def. 1}$ or $\mathbf{ Def. 2}$. b) Prove that countable intersection and countable union of the measurable sets is measurable. I'd appreciate your help, guys.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
59,Outer measure and trace sigma algebra,Outer measure and trace sigma algebra,,"This question is from Donald Cohn measure theory textbook. Let $\mu$ be a finite measure, and $\left(X, \mathcal{A}, \mu\right)$ a measurable space.$C \in X$ , $C_1 \in \mathcal{A},C\subseteq C_1$ with $\mu(C_1)=\mu^*(C)$. Show that if $A_1,A_2 \in \mathcal{A}$ are such that $A_1\cap C=A_2\cap C$ then $\mu(A_1\cap C_1)=\mu(A_2\cap C_1)$ I rewrite $A_1\cap C_1=(A_1\cap C) \cup (A_1\cap (C_1 - C))=(A_2\cap C) \cup (A_1\cap (C_1 - C))$. Now the second term is such that $\mu^*(A_1\cap (C_1 - C))\leq \mu^*(C_1 - C) < \epsilon$, so that $\mu^*(A_1\cap C_1) = \mu^*(A_2\cap C)$ I can also rewrite $A_2\cap C_1=(A_2\cap C) \cup (A_2\cap (C_1 - C))$ and similarly in the end obtain $\mu^*(A_2\cap C_1) = \mu^*(A_2\cap C)$ We have then $\mu(A_1\cap C_1)=\mu^*(A_1\cap C_1) = \mu^*(A_2\cap C_1)=\mu(A_2\cap C_1)$ since the sets on the end sides of the equality are in $\mathcal{A}$ and then the measure and the outer measure agree (If I remember correctly)... Now I am sure that this is vastly wrong, since I barely used any assumptions, so if you would be kind enough to point out where everything goes wrong , that would be much appreciated ! Thanks","This question is from Donald Cohn measure theory textbook. Let $\mu$ be a finite measure, and $\left(X, \mathcal{A}, \mu\right)$ a measurable space.$C \in X$ , $C_1 \in \mathcal{A},C\subseteq C_1$ with $\mu(C_1)=\mu^*(C)$. Show that if $A_1,A_2 \in \mathcal{A}$ are such that $A_1\cap C=A_2\cap C$ then $\mu(A_1\cap C_1)=\mu(A_2\cap C_1)$ I rewrite $A_1\cap C_1=(A_1\cap C) \cup (A_1\cap (C_1 - C))=(A_2\cap C) \cup (A_1\cap (C_1 - C))$. Now the second term is such that $\mu^*(A_1\cap (C_1 - C))\leq \mu^*(C_1 - C) < \epsilon$, so that $\mu^*(A_1\cap C_1) = \mu^*(A_2\cap C)$ I can also rewrite $A_2\cap C_1=(A_2\cap C) \cup (A_2\cap (C_1 - C))$ and similarly in the end obtain $\mu^*(A_2\cap C_1) = \mu^*(A_2\cap C)$ We have then $\mu(A_1\cap C_1)=\mu^*(A_1\cap C_1) = \mu^*(A_2\cap C_1)=\mu(A_2\cap C_1)$ since the sets on the end sides of the equality are in $\mathcal{A}$ and then the measure and the outer measure agree (If I remember correctly)... Now I am sure that this is vastly wrong, since I barely used any assumptions, so if you would be kind enough to point out where everything goes wrong , that would be much appreciated ! Thanks",,"['real-analysis', 'measure-theory']"
60,Intuition behind proof of bounded convergence theorem in Stein-Shakarchi,Intuition behind proof of bounded convergence theorem in Stein-Shakarchi,,"Theorem 1.4 (Bounded convergence theorem) Suppose that $\{f_n\}$ is a sequence of measurable functions that are all bounded by $M$ , are supported on a set $E$ of finite measure, and $f_n(x) \to f(x)$ a.e. $x$ as $n \to \infty$ . Then $f$ is measurable, bounded, supported on $E$ for a.e. $x$ , and $$\int |f_n \to f| \to 0 \text{ as } n \to \infty.$$ Consequently, $$\int f_n \to \int f \text{ as } n \to \infty.$$ Proof. From the assumptions one sees at once that $f$ is bounded by $M$ almost everywhere and vanishes outside $E$ , except for possibly on a set of measure zero. Clearly, the triangle inequality for the integral implies that it suffices to prove that $\int |f_n  - f| \to 0$ as $n$ tends to infinity. The proof is a reprise of the argument in Lemma 1.2. Given $\epsilon > 0$ , we may find, by Egorov's theorem, a measurable subset $A_\epsilon$ of $E$ such that $m(E - A_\epsilon) \le \epsilon$ and $f_n \to f$ uniformly on $A_\epsilon$ . Then, we know that for all sufficiently large $n$ we have $|f_n(x) - f(x)| \le \epsilon$ for all $x \in A_\epsilon$ . Putting these facts together yields \begin{align*} \int |f_n - f(x)|\,dx & \le \int_{A_\epsilon} |f_n(x) - f(x)|\,dx + \int_{E - A_\epsilon} |f_n(x) - f(x)|\,dx \\ & \le \epsilon m(E) + 2M\,m(E - A_\epsilon)\end{align*} for all large $n$ . Since $\epsilon$ is arbitrary, the proof of the theorem is complete. $$\tag*{$\square$}$$ For reference, we include the statement of Lemma 1.2 here. Lemma 1.2 Let $f$ be a bounded function supported on a set $E$ of finite measure. If $\{\varphi_n\}_{n = 1}^\infty$ is any sequence of simple functions bounded by $M$ , supported on $E$ , and with $\varphi_n(x) \to f(x)$ for a.e. $x$ , then: (i) The limit $\lim_{n \to \infty} \int \varphi_n$ exists. (ii) If $f = 0$ a.e., then the limit $\lim_{n \to \infty} \int \varphi_n$ equals $0$ . My question is, could anybody supply me their intuitions behind the proof of the bounded convergence theorem here? What are the key steps I should distill the proof into as to be able to recreate it from scratch?","Theorem 1.4 (Bounded convergence theorem) Suppose that is a sequence of measurable functions that are all bounded by , are supported on a set of finite measure, and a.e. as . Then is measurable, bounded, supported on for a.e. , and Consequently, Proof. From the assumptions one sees at once that is bounded by almost everywhere and vanishes outside , except for possibly on a set of measure zero. Clearly, the triangle inequality for the integral implies that it suffices to prove that as tends to infinity. The proof is a reprise of the argument in Lemma 1.2. Given , we may find, by Egorov's theorem, a measurable subset of such that and uniformly on . Then, we know that for all sufficiently large we have for all . Putting these facts together yields for all large . Since is arbitrary, the proof of the theorem is complete. For reference, we include the statement of Lemma 1.2 here. Lemma 1.2 Let be a bounded function supported on a set of finite measure. If is any sequence of simple functions bounded by , supported on , and with for a.e. , then: (i) The limit exists. (ii) If a.e., then the limit equals . My question is, could anybody supply me their intuitions behind the proof of the bounded convergence theorem here? What are the key steps I should distill the proof into as to be able to recreate it from scratch?","\{f_n\} M E f_n(x) \to f(x) x n \to \infty f E x \int |f_n \to f| \to 0 \text{ as } n \to \infty. \int f_n \to \int f \text{ as } n \to \infty. f M E \int |f_n  - f| \to 0 n \epsilon > 0 A_\epsilon E m(E - A_\epsilon) \le \epsilon f_n \to f A_\epsilon n |f_n(x) - f(x)| \le \epsilon x \in A_\epsilon \begin{align*} \int |f_n - f(x)|\,dx & \le \int_{A_\epsilon} |f_n(x) - f(x)|\,dx + \int_{E - A_\epsilon} |f_n(x) - f(x)|\,dx \\ & \le \epsilon m(E) + 2M\,m(E - A_\epsilon)\end{align*} n \epsilon \tag*{\square} f E \{\varphi_n\}_{n = 1}^\infty M E \varphi_n(x) \to f(x) x \lim_{n \to \infty} \int \varphi_n f = 0 \lim_{n \to \infty} \int \varphi_n 0","['real-analysis', 'sequences-and-series']"
61,How can I prove that an ultrafilter induces a finitely additive measure?,How can I prove that an ultrafilter induces a finitely additive measure?,,"If $\mathcal{U}$ is an ultrafilter on a set $X$, it can be defined a function $\mu_{\mathcal{U}}\colon\mathcal{P}(X)\to\{0,1\}$ such that, for all $A\subseteq X$ it holds $\mu_{\mathcal{U}}(A)=1$ iff $A\in\mathcal{U}$. Are $\mu_{\mathcal{U}}(\emptyset)=0$ and finite additivity enough to prove that $\mu_{\mathcal{U}}$ is well-defined? Of course, given a subset $E$ of $X$, we can split $E$ into disjoint sets $E_1,\dots,E_n$.  If $\mu_{\mathcal{U}}(E)=1$, then exactly one $E_i$ belongs to $\mathcal{U}$, so $\mu_{\mathcal{U}}(E_1)+\dots+\mu_{\mathcal{U}}(E_n)=1$. If $\mu_{\mathcal{U}}(E)=0$, then none of the $E_i$'s belongs to $\mathcal{U}$, so $\mu_{\mathcal{U}}(E_1)+\dots+\mu_{\mathcal{U}}(E_n)=0$. Did I prove that $\mu_{\mathcal{U}}$ is actually a function, hence a finitely additive measure?","If $\mathcal{U}$ is an ultrafilter on a set $X$, it can be defined a function $\mu_{\mathcal{U}}\colon\mathcal{P}(X)\to\{0,1\}$ such that, for all $A\subseteq X$ it holds $\mu_{\mathcal{U}}(A)=1$ iff $A\in\mathcal{U}$. Are $\mu_{\mathcal{U}}(\emptyset)=0$ and finite additivity enough to prove that $\mu_{\mathcal{U}}$ is well-defined? Of course, given a subset $E$ of $X$, we can split $E$ into disjoint sets $E_1,\dots,E_n$.  If $\mu_{\mathcal{U}}(E)=1$, then exactly one $E_i$ belongs to $\mathcal{U}$, so $\mu_{\mathcal{U}}(E_1)+\dots+\mu_{\mathcal{U}}(E_n)=1$. If $\mu_{\mathcal{U}}(E)=0$, then none of the $E_i$'s belongs to $\mathcal{U}$, so $\mu_{\mathcal{U}}(E_1)+\dots+\mu_{\mathcal{U}}(E_n)=0$. Did I prove that $\mu_{\mathcal{U}}$ is actually a function, hence a finitely additive measure?",,"['measure-theory', 'elementary-set-theory', 'filters']"
62,Real Analysis Folland Problem 1.5.28 Borel Measures,Real Analysis Folland Problem 1.5.28 Borel Measures,,"Problem 1.5.28 - Let $F$ be increasing and right continuous, and let $\mu_F$ be the associated measure. Then $\mu_F(\{a\}) = F(a) - F(a-)$, $\mu_F([a,b)) = F(b-) - F(a-)$,$\mu_F([a,b]) = F(b) - F(a-)$, and $\mu_F((a,b)) = F(b-)- F(a)$ Proof - $\mu_F$ has been constructed on the algebra of h-intervals that takes the values $$\mu_F((a,b]) = F(b) - F(a) \forall a,b$$ So $\mu_F$ is a finite bounded set on $\mathbb{R}$ We can represent $\{a\}$ as $$\{a\} = \bigcap_{n=1}^{\infty}(a - 1/n, a]$$ The interval $(a - 1/n, a]$ forms a decreasing sequence of sets so by theorem 1.8d we have $$\mu_F(\{a\}) = \lim_{n\rightarrow \infty}\mu_F((a - 1/n, a]) = \lim_{n\rightarrow \infty}\left[ F(a) - F(a - 1/n)\right]$$ Since $F$ is increasing $$\lim_{n\rightarrow \infty}\mu_F(a - 1/n) = \lim_{x\rightarrow a-}F(x) = \sup\left\lbrace F(x):x < a\right\rbrace  = F(a-)$$ Thus $$\mu_F(\{a\}) = F(a) - F(a-)$$ Now, consider the $\mu_F([a,b))$, where $b$ might be $\infty$. We can represent $[a,b) = \{a\} \cup (a,b)$ (disjoint union) so $$mu_F([a,b)) = \mu_F(\{a\}) + \mu_F(a,b) = F(a) - F(a-) + F(b-) + F(a) = F(b-) - F(a-)$$ Note this is valid if $F(b-) = F(\infty) = \infty$ Next, consider $\mu_F([a,b])$ We can represent $[a,b] = \{a\} \cup (a,b]$ (disjoint union) so $$mu_F([a,b]) = \mu_F(\{a\}) + \mu_F([a,b]) = F(a) - F(a-) + F(b) - F(a) = F(b) - F(a-)$$ Finally, consider $\mu_F((a,b))$ so either $a$ or $b$ will be $\infty$ in the interval. If $b$ is $\infty$ then $(a,\infty)$ is an h-interval and the definition of $\mu_F$ yields $$\mu_F((a,\infty)) = F(\infty) - F(a)$$ so the proposed formula $$\mu_F((a,b)) = F(b-)- F(a)$$ is correct because $F(\infty) = \lim_{x\rightarrow \infty}F(x)$ The part I don't understand is why $$\lim_{n\rightarrow \infty}F(a-1/n) = F(a-)$$ Try to explain this as simply as possible.","Problem 1.5.28 - Let $F$ be increasing and right continuous, and let $\mu_F$ be the associated measure. Then $\mu_F(\{a\}) = F(a) - F(a-)$, $\mu_F([a,b)) = F(b-) - F(a-)$,$\mu_F([a,b]) = F(b) - F(a-)$, and $\mu_F((a,b)) = F(b-)- F(a)$ Proof - $\mu_F$ has been constructed on the algebra of h-intervals that takes the values $$\mu_F((a,b]) = F(b) - F(a) \forall a,b$$ So $\mu_F$ is a finite bounded set on $\mathbb{R}$ We can represent $\{a\}$ as $$\{a\} = \bigcap_{n=1}^{\infty}(a - 1/n, a]$$ The interval $(a - 1/n, a]$ forms a decreasing sequence of sets so by theorem 1.8d we have $$\mu_F(\{a\}) = \lim_{n\rightarrow \infty}\mu_F((a - 1/n, a]) = \lim_{n\rightarrow \infty}\left[ F(a) - F(a - 1/n)\right]$$ Since $F$ is increasing $$\lim_{n\rightarrow \infty}\mu_F(a - 1/n) = \lim_{x\rightarrow a-}F(x) = \sup\left\lbrace F(x):x < a\right\rbrace  = F(a-)$$ Thus $$\mu_F(\{a\}) = F(a) - F(a-)$$ Now, consider the $\mu_F([a,b))$, where $b$ might be $\infty$. We can represent $[a,b) = \{a\} \cup (a,b)$ (disjoint union) so $$mu_F([a,b)) = \mu_F(\{a\}) + \mu_F(a,b) = F(a) - F(a-) + F(b-) + F(a) = F(b-) - F(a-)$$ Note this is valid if $F(b-) = F(\infty) = \infty$ Next, consider $\mu_F([a,b])$ We can represent $[a,b] = \{a\} \cup (a,b]$ (disjoint union) so $$mu_F([a,b]) = \mu_F(\{a\}) + \mu_F([a,b]) = F(a) - F(a-) + F(b) - F(a) = F(b) - F(a-)$$ Finally, consider $\mu_F((a,b))$ so either $a$ or $b$ will be $\infty$ in the interval. If $b$ is $\infty$ then $(a,\infty)$ is an h-interval and the definition of $\mu_F$ yields $$\mu_F((a,\infty)) = F(\infty) - F(a)$$ so the proposed formula $$\mu_F((a,b)) = F(b-)- F(a)$$ is correct because $F(\infty) = \lim_{x\rightarrow \infty}F(x)$ The part I don't understand is why $$\lim_{n\rightarrow \infty}F(a-1/n) = F(a-)$$ Try to explain this as simply as possible.",,"['real-analysis', 'measure-theory']"
63,Lebesgue-$\sigma$-algebras $\mathfrak L^{p+q}\neq\mathfrak L^p \otimes\mathfrak L^q$,Lebesgue--algebras,\sigma \mathfrak L^{p+q}\neq\mathfrak L^p \otimes\mathfrak L^q,"I already know that for Borel-$\sigma$-algebras it holds that $\mathfrak B^{p+q}=\mathfrak B^p \otimes\mathfrak B^q$. Now I want to show that this is not the case for Lebesgue-$\sigma$-algebras $\mathfrak L$. So first of all, given a zero Lebesgue-null-set $N$ in $\mathbb R^p$, I have proven that $N\times B$ is a Lebesgue-null-set in $\mathbb R^{p+q}$ for arbitrary $B\subseteq \mathbb R^q$. Now, how can I show that $$\mathfrak B^p \otimes\mathfrak B^q\subsetneq \mathfrak L^p \otimes\mathfrak L^q \subsetneq \mathfrak L^{p+q} $$ My work for the first part of the proof: So if we chose $B$ where $\mu(B)<\infty$, it is obvious that we obtain $$\lambda(N\times B)=\nu(N)\mu(B)=0\times M=0$$ where $M\in\mathbb R$ is an upper bound of $\mu(B)$. Thus I considered the case $\mu(B)≥\infty$. Since $\mu$ is $\sigma$ -additive, we can find a sequence $B_n\subseteq B$ such that $\bigcup_{n=1}^\infty B_n = B$ and $\mu(B_n)<\infty$ for all $n$. It follows that $$\lambda(N\times B)= \lambda(N\times \bigcup_{n=1}^\infty B_n )=\nu(N)\mu(\bigcup_{n=1}^\infty B_n) = \nu(N)\lim_{n\to\infty}\mu( B_n)=0\times S=0$$ where $S$ is the upper bound of $B_n$.","I already know that for Borel-$\sigma$-algebras it holds that $\mathfrak B^{p+q}=\mathfrak B^p \otimes\mathfrak B^q$. Now I want to show that this is not the case for Lebesgue-$\sigma$-algebras $\mathfrak L$. So first of all, given a zero Lebesgue-null-set $N$ in $\mathbb R^p$, I have proven that $N\times B$ is a Lebesgue-null-set in $\mathbb R^{p+q}$ for arbitrary $B\subseteq \mathbb R^q$. Now, how can I show that $$\mathfrak B^p \otimes\mathfrak B^q\subsetneq \mathfrak L^p \otimes\mathfrak L^q \subsetneq \mathfrak L^{p+q} $$ My work for the first part of the proof: So if we chose $B$ where $\mu(B)<\infty$, it is obvious that we obtain $$\lambda(N\times B)=\nu(N)\mu(B)=0\times M=0$$ where $M\in\mathbb R$ is an upper bound of $\mu(B)$. Thus I considered the case $\mu(B)≥\infty$. Since $\mu$ is $\sigma$ -additive, we can find a sequence $B_n\subseteq B$ such that $\bigcup_{n=1}^\infty B_n = B$ and $\mu(B_n)<\infty$ for all $n$. It follows that $$\lambda(N\times B)= \lambda(N\times \bigcup_{n=1}^\infty B_n )=\nu(N)\mu(\bigcup_{n=1}^\infty B_n) = \nu(N)\lim_{n\to\infty}\mu( B_n)=0\times S=0$$ where $S$ is the upper bound of $B_n$.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'algebras']"
64,"Prove that $F(x,y)=f(x-y)$ is Borel measurable",Prove that  is Borel measurable,"F(x,y)=f(x-y)","Suppose $A$ is a subset of $\Bbb R$, let $s(A)=\{ (x,y)\in \Bbb R \times \Bbb R :x-y\in A\}$. I already showed: If $A\in \Bbb B$ (Borel measurable set), then $s(A)\in \Bbb B \times \Bbb B$. I want to use this to prove that if $f$ is a Borel measurable function on $\Bbb R$ to $\Bbb R$, then the function $F$ defined by $F(x,y)=f(x-y)$ is measurable with respect to $\Bbb B \times \Bbb B$. Could someone help to provide a proof please? Thanks.","Suppose $A$ is a subset of $\Bbb R$, let $s(A)=\{ (x,y)\in \Bbb R \times \Bbb R :x-y\in A\}$. I already showed: If $A\in \Bbb B$ (Borel measurable set), then $s(A)\in \Bbb B \times \Bbb B$. I want to use this to prove that if $f$ is a Borel measurable function on $\Bbb R$ to $\Bbb R$, then the function $F$ defined by $F(x,y)=f(x-y)$ is measurable with respect to $\Bbb B \times \Bbb B$. Could someone help to provide a proof please? Thanks.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
65,Differentiation under integral sign?,Differentiation under integral sign?,,"I am trying to understand the following argument given in a text book: Suppose $f \in L^1(\mathbb R^n)$ , consider the function $\hat{f}(\zeta)= \int_{\mathbb R^n} \exp(-2\pi i X.\zeta)f(X)dX$ . Suppose $x_j f(X) \in L^1(\mathbb R^n)$ for $1 \leq j \leq n$ then $$\delta_j (\hat{f}(\zeta))=-2\pi i \int_{\mathbb R^n} \exp(-2\pi i X.\zeta)x_j f(X)dX $$ where $\delta_j$ denote partial derivative w.r.t. $\zeta_j$ Why can we interchange differentiation and integration as is done in the above argument?","I am trying to understand the following argument given in a text book: Suppose , consider the function . Suppose for then where denote partial derivative w.r.t. Why can we interchange differentiation and integration as is done in the above argument?",f \in L^1(\mathbb R^n) \hat{f}(\zeta)= \int_{\mathbb R^n} \exp(-2\pi i X.\zeta)f(X)dX x_j f(X) \in L^1(\mathbb R^n) 1 \leq j \leq n \delta_j (\hat{f}(\zeta))=-2\pi i \int_{\mathbb R^n} \exp(-2\pi i X.\zeta)x_j f(X)dX  \delta_j \zeta_j,"['measure-theory', 'multivariable-calculus', 'integral-transforms', 'fourier-transform']"
66,How to proof that $f^{-1}(\sigma(\mathcal C))\subseteq\sigma(f^{-1}(\mathcal C))$?,How to proof that ?,f^{-1}(\sigma(\mathcal C))\subseteq\sigma(f^{-1}(\mathcal C)),"Let $f:X\to Y$ be a function, $\mathcal C$ be a family of subsets of $Y$. I am convinced that $f^{-1}(\sigma(\mathcal C))=\sigma(f^{-1}(\mathcal C))$, where $\sigma(\mathcal A)$ is the $\sigma$-algebra generated by $\mathcal A$. The part $\sigma(f^{-1}(\mathcal C))\subseteq f^{-1}(\sigma(\mathcal C))$ is quite straight forward since $f^{-1}$ behave nicely with set-theoretic operations but I cannot see how to prove its converse. I tried to characterize $\sigma(\mathcal A)$ by seeing how it can be constructively define but my effort was not very fruitful. (From this post by Mr.Asaf, it seems that I must use higher cardinal.) So how should I prove $f^{-1}(\sigma(\mathcal C))\subseteq\sigma(f^{-1}(\mathcal C))$ ? It is really hard or perhaps I missed something silly? Any hint would be appreciate. Thank you in advance.","Let $f:X\to Y$ be a function, $\mathcal C$ be a family of subsets of $Y$. I am convinced that $f^{-1}(\sigma(\mathcal C))=\sigma(f^{-1}(\mathcal C))$, where $\sigma(\mathcal A)$ is the $\sigma$-algebra generated by $\mathcal A$. The part $\sigma(f^{-1}(\mathcal C))\subseteq f^{-1}(\sigma(\mathcal C))$ is quite straight forward since $f^{-1}$ behave nicely with set-theoretic operations but I cannot see how to prove its converse. I tried to characterize $\sigma(\mathcal A)$ by seeing how it can be constructively define but my effort was not very fruitful. (From this post by Mr.Asaf, it seems that I must use higher cardinal.) So how should I prove $f^{-1}(\sigma(\mathcal C))\subseteq\sigma(f^{-1}(\mathcal C))$ ? It is really hard or perhaps I missed something silly? Any hint would be appreciate. Thank you in advance.",,"['real-analysis', 'measure-theory', 'elementary-set-theory']"
67,Why does (finite) $\sigma$-algebra work in powers of 2?,Why does (finite) -algebra work in powers of 2?,\sigma,"The cardinality of a (finite) $\sigma$-algebra is $2^k$ for some $k \in \mathbb{N}$. There are some proofs ( like this ) around, but how is it claimed in the proofs that ""every element of $\sigma$-algebra is the (disjoint) union of members"", i.e. works in powers of 2.","The cardinality of a (finite) $\sigma$-algebra is $2^k$ for some $k \in \mathbb{N}$. There are some proofs ( like this ) around, but how is it claimed in the proofs that ""every element of $\sigma$-algebra is the (disjoint) union of members"", i.e. works in powers of 2.",,['measure-theory']
68,"Compute Lebesgue measure of set of all real numbers in $[0,1]$ whose decimal representations don't contain the number 7 [duplicate]",Compute Lebesgue measure of set of all real numbers in  whose decimal representations don't contain the number 7 [duplicate],"[0,1]","This question already has answers here : What is the measure of the set of numbers in $[0,1]$ whose decimal expansions do not contain $5$? (3 answers) Closed 3 years ago . Consider measure space $(S, \Sigma, \mu) = (\mathbb R, \mathscr B(\mathbb R), \lambda)$. Let $V^C \subseteq S$ denote the set of all numbers in $[0,1]$ whose decimal representations don't contain the number 7. Prove that $V^C \in \Sigma$. Compute $\lambda(V^C)$. What I tried: I think we have $$V = \bigcup_{n=1}^{\infty} V_n$$ where $v_n \in V_n$ can be written $v_n = 0.s_1s_2...$ where $s_1 \ne 7, ..., s_{n-1} \ne 7, s_n = 7$ $$V_n = \bigcup_{s_1, ..., s_{n-1} \ne 7} [0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8)$$ $V$ is a finite union of pairwise disjoint $9^{n-1}$ intervals and hence is a Borel set, which is Lebesgue measurable. $V$ is a countable union of  pairwise disjoint Borel sets and hence is a Borel set, which is Lebesgue measurable. Thus, $V^C$ is Lebesgue measurable. 2. $$\lambda(V) = \lambda(\bigcup_{n=1}^{\infty} V_n) = \sum_{n=1}^{\infty} \lambda(V_n)$$ $$\lambda(V_n) = \lambda \left(\bigcup_{s_1, ..., s_{n-1} \ne 7} [0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8)\right)$$ $$= \sum_{i=1}^{9^{n-1}} \lambda ([0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8))$$ $$= \sum_{i=1}^{9^{n-1}} \frac{1}{10^n} = \frac{1}{10^n} \sum_{i=1}^{9^{n-1}} (1) = \frac{1}{10^n} (9^{n-1} - 1 + 1) = \frac{9^{n-1}}{10^n}$$ $$\to \lambda(V) = \sum_{n=1}^{\infty} \lambda(V_n) = \sum_{n=1}^{\infty} \frac{9^{n-1}}{10^n} = 1$$ $$\therefore, \lambda(V^C) = 0$$","This question already has answers here : What is the measure of the set of numbers in $[0,1]$ whose decimal expansions do not contain $5$? (3 answers) Closed 3 years ago . Consider measure space $(S, \Sigma, \mu) = (\mathbb R, \mathscr B(\mathbb R), \lambda)$. Let $V^C \subseteq S$ denote the set of all numbers in $[0,1]$ whose decimal representations don't contain the number 7. Prove that $V^C \in \Sigma$. Compute $\lambda(V^C)$. What I tried: I think we have $$V = \bigcup_{n=1}^{\infty} V_n$$ where $v_n \in V_n$ can be written $v_n = 0.s_1s_2...$ where $s_1 \ne 7, ..., s_{n-1} \ne 7, s_n = 7$ $$V_n = \bigcup_{s_1, ..., s_{n-1} \ne 7} [0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8)$$ $V$ is a finite union of pairwise disjoint $9^{n-1}$ intervals and hence is a Borel set, which is Lebesgue measurable. $V$ is a countable union of  pairwise disjoint Borel sets and hence is a Borel set, which is Lebesgue measurable. Thus, $V^C$ is Lebesgue measurable. 2. $$\lambda(V) = \lambda(\bigcup_{n=1}^{\infty} V_n) = \sum_{n=1}^{\infty} \lambda(V_n)$$ $$\lambda(V_n) = \lambda \left(\bigcup_{s_1, ..., s_{n-1} \ne 7} [0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8)\right)$$ $$= \sum_{i=1}^{9^{n-1}} \lambda ([0.s_1...s_{n-1}7, 0.s_1...s_{n-1}8))$$ $$= \sum_{i=1}^{9^{n-1}} \frac{1}{10^n} = \frac{1}{10^n} \sum_{i=1}^{9^{n-1}} (1) = \frac{1}{10^n} (9^{n-1} - 1 + 1) = \frac{9^{n-1}}{10^n}$$ $$\to \lambda(V) = \sum_{n=1}^{\infty} \lambda(V_n) = \sum_{n=1}^{\infty} \frac{9^{n-1}}{10^n} = 1$$ $$\therefore, \lambda(V^C) = 0$$",,"['real-analysis', 'measure-theory', 'elementary-set-theory', 'lebesgue-measure', 'decimal-expansion']"
69,Is the set $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)$ exist$\}$ measurable?,Is the set  exist measurable?,\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y) \},Let $f$ be a Lebesgue Measurable Function on $\mathbb{R}$.    Is the set $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)$ exist$\}$ always measurable? I can prove if $a\in \mathbb{R}$ is given $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)=a\}$ is measurable by showing the $\epsilon-\delta$ definition of limit only requires $\frac{1}{n}$ values($n\in \mathbb{N}$) for $\epsilon$ and $\delta$ and write the set as countable union/intersection of measurable sets. However I don't think we can do the same thing for $a$ becuase it has uncountably many possibilities.,Let $f$ be a Lebesgue Measurable Function on $\mathbb{R}$.    Is the set $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)$ exist$\}$ always measurable? I can prove if $a\in \mathbb{R}$ is given $\{x\in \mathbb{R}: \lim_{y\rightarrow x}f(y)=a\}$ is measurable by showing the $\epsilon-\delta$ definition of limit only requires $\frac{1}{n}$ values($n\in \mathbb{N}$) for $\epsilon$ and $\delta$ and write the set as countable union/intersection of measurable sets. However I don't think we can do the same thing for $a$ becuase it has uncountably many possibilities.,,"['real-analysis', 'measure-theory']"
70,Improper Riemann integral versus Lebesgue,Improper Riemann integral versus Lebesgue,,"What is the relationship between the improper Riemann-integral and Lebesgue integrability? There's a very sloppy section of it in my book with about 4-5 known mistakes found so far, so I fear I have a completely wrong idea of what's what now. My question is, what must be true for some $u$ and its improper Riemann-integral for it to be Lebesgue-integrable, and what must be true for the Lebesgue-integrability of $u$ for it to have finite or infinite improper Riemann-integrable? I know for example that $\sin(x) / x$, $x \in (0,\infty)$ is improperly Riemann-integrable but not Lebesgue integrable. What's gone wrong here?","What is the relationship between the improper Riemann-integral and Lebesgue integrability? There's a very sloppy section of it in my book with about 4-5 known mistakes found so far, so I fear I have a completely wrong idea of what's what now. My question is, what must be true for some $u$ and its improper Riemann-integral for it to be Lebesgue-integrable, and what must be true for the Lebesgue-integrability of $u$ for it to have finite or infinite improper Riemann-integrable? I know for example that $\sin(x) / x$, $x \in (0,\infty)$ is improperly Riemann-integrable but not Lebesgue integrable. What's gone wrong here?",,"['integration', 'measure-theory', 'lebesgue-integral', 'riemann-integration']"
71,Does every Lebesgue measurable set $A$ with $m(A)>0$ contain at least an open subset?,Does every Lebesgue measurable set  with  contain at least an open subset?,A m(A)>0,"Does every Lebesgue measurable set $A$ with $m(A)>0$ contain at least a non-empty open subset? I came across this question when I was reading the Stein and Shakarchi's Real Analysis book. Is that true? If yes, how can we prove that, otherwise, what is the counter example? I was thinking of solving it as follows: Since set $A$ is measurable , for any $\epsilon$ we should be able to find $F_{\epsilon} \subset A$ that $m(A - F)<\epsilon$. If we remove the boundary points of $F_{\epsilon}$, we obtain an open set. Is that valid?","Does every Lebesgue measurable set $A$ with $m(A)>0$ contain at least a non-empty open subset? I came across this question when I was reading the Stein and Shakarchi's Real Analysis book. Is that true? If yes, how can we prove that, otherwise, what is the counter example? I was thinking of solving it as follows: Since set $A$ is measurable , for any $\epsilon$ we should be able to find $F_{\epsilon} \subset A$ that $m(A - F)<\epsilon$. If we remove the boundary points of $F_{\epsilon}$, we obtain an open set. Is that valid?",,"['real-analysis', 'measure-theory']"
72,$E \subset \{ x | f \text{ is differentiable at }x\}$. Then $|E|=0 \Rightarrow |f(E)|=0$.,. Then .,E \subset \{ x | f \text{ is differentiable at }x\} |E|=0 \Rightarrow |f(E)|=0,"For $f:[0,1]\to \mathbb{R}$ let $E\subset\left\{x \mid f'(x) \text{exists}\right\}$. Prove that if $|E|=0$, then $|f(E)|=0$. My attempt: Let $E_{nk}=\left\{x\in [0,1]|\frac{|f(x+h)-f(x)|}{h}\leq n, |h|< \frac{1}{k} \right\}$. I am not sure where to go from here, but  I think that $E\subset \bigcup E_{nk}$, but I am not sure. Any hints? Thank you.","For $f:[0,1]\to \mathbb{R}$ let $E\subset\left\{x \mid f'(x) \text{exists}\right\}$. Prove that if $|E|=0$, then $|f(E)|=0$. My attempt: Let $E_{nk}=\left\{x\in [0,1]|\frac{|f(x+h)-f(x)|}{h}\leq n, |h|< \frac{1}{k} \right\}$. I am not sure where to go from here, but  I think that $E\subset \bigcup E_{nk}$, but I am not sure. Any hints? Thank you.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
73,a proof that $\mathscr{B}(\mathbb{R})$ is generated by compact subsets of $\mathscr{R}$,a proof that  is generated by compact subsets of,\mathscr{B}(\mathbb{R}) \mathscr{R},"Is my argument correct? Let $\mathscr{B}(\mathbb{R})$ be the Borel subsets of $\mathbb{R}$,and let $\mathscr{A}$ be the $\sigma-algebra$ generated by the collection of all compact subsets of $\mathbb{R}$. It is know that $\mathscr{B}(\mathbb{R})$ is generated by the collection of all closed subsets of $\mathbb{R}$, so that $\mathscr{B}(\mathbb{R}) \supset \mathscr{A}$. If $C$ is an unbounded closed subset of $\mathbb{R}$,then $C$ is equal to the union of the countable collection of all sets of the form $\bar{B_n}\cap C$ where $B_n$ is a ball of radius $n$. Each such set is closed and bounded so that it is compact. It follows that $\mathscr{B}(\mathbb{R})\subset \mathscr{A}$. Hence $\mathscr{B}(\mathbb{R})=\mathscr{A}$.","Is my argument correct? Let $\mathscr{B}(\mathbb{R})$ be the Borel subsets of $\mathbb{R}$,and let $\mathscr{A}$ be the $\sigma-algebra$ generated by the collection of all compact subsets of $\mathbb{R}$. It is know that $\mathscr{B}(\mathbb{R})$ is generated by the collection of all closed subsets of $\mathbb{R}$, so that $\mathscr{B}(\mathbb{R}) \supset \mathscr{A}$. If $C$ is an unbounded closed subset of $\mathbb{R}$,then $C$ is equal to the union of the countable collection of all sets of the form $\bar{B_n}\cap C$ where $B_n$ is a ball of radius $n$. Each such set is closed and bounded so that it is compact. It follows that $\mathscr{B}(\mathbb{R})\subset \mathscr{A}$. Hence $\mathscr{B}(\mathbb{R})=\mathscr{A}$.",,['measure-theory']
74,the $\sigma$-algebra on $\mathbb{R}$ generated by the collection of all one-point subsets,the -algebra on  generated by the collection of all one-point subsets,\sigma \mathbb{R},"Is my proof correct? Let $\mathscr{A}$ be the collection of all subsets $A$ of $\mathbb{R}$ such that either $A$ or $A^{c}$ is countable, and let $\mathscr{B}$ be the collection of all singleton subsets of $\mathbb{R}$. It is clear that $\mathscr{B}$ is a subcollection of $\mathscr{A}$, so that the $\sigma$-algebra $\sigma(\mathscr{B})$ generated by $\mathscr{B}$ is contained in $\mathscr{A}$, since $\mathscr{A}$ is a $\sigma$-algebra. Now any $A\in \mathscr{A}$ is either countable in which case $A$ will be a member of $\sigma(\mathscr{B})$, or its complement $A^{c}$ is countable in which case $A^{c}$ will be a member of $\sigma(\mathscr{B})$,and since $\sigma$-algebras are closed under complementation it follows that $A$ will be a member of $\sigma(\mathscr{B})$. Hence $\mathscr{A}$ is a subcollection of $\sigma(\mathscr{B})$, and we conclude that $\sigma(\mathscr{B})=\mathscr{A}$.","Is my proof correct? Let $\mathscr{A}$ be the collection of all subsets $A$ of $\mathbb{R}$ such that either $A$ or $A^{c}$ is countable, and let $\mathscr{B}$ be the collection of all singleton subsets of $\mathbb{R}$. It is clear that $\mathscr{B}$ is a subcollection of $\mathscr{A}$, so that the $\sigma$-algebra $\sigma(\mathscr{B})$ generated by $\mathscr{B}$ is contained in $\mathscr{A}$, since $\mathscr{A}$ is a $\sigma$-algebra. Now any $A\in \mathscr{A}$ is either countable in which case $A$ will be a member of $\sigma(\mathscr{B})$, or its complement $A^{c}$ is countable in which case $A^{c}$ will be a member of $\sigma(\mathscr{B})$,and since $\sigma$-algebras are closed under complementation it follows that $A$ will be a member of $\sigma(\mathscr{B})$. Hence $\mathscr{A}$ is a subcollection of $\sigma(\mathscr{B})$, and we conclude that $\sigma(\mathscr{B})=\mathscr{A}$.",,"['real-analysis', 'measure-theory', 'proof-verification']"
75,"Prove that $\sigma$-algebra of subsets of $\mathbb{R}$ of the form $(a,\infty)$ contains all the intervals.",Prove that -algebra of subsets of  of the form  contains all the intervals.,"\sigma \mathbb{R} (a,\infty)","I want to prove that if a $\sigma$-algebra of subsets of $\mathbb{R}$ contains intervals of the form $(a,\infty)$, then it contains all the intervals. Proof: Let $\mathscr{B}$ to denote the $\sigma$-algebra defined above. We have that since $(a,\infty) \in \mathscr{B}$, then since it contains the complement, we have that it also contains the intervals of the form $(-\infty,b]$, i.e. $$(-\infty,b] \in \mathscr{B}$$ In particular, we have that $(a,b) \in \mathscr{B}$. It's enough to prove that: $$[b, \infty) \in \mathscr{B}$$ $$[a,b] \in \mathscr{B}$$ $$[a,b) \in \mathscr{B}$$ $$(a,b) \in \mathscr{B}$$ This is clear, since:  $$[b, \infty) = \bigcap_{k=1}^{\infty} (b-\frac{1}{n}, \infty)$$ $$[a,b] = \bigcap_{n=1}^{\infty} (a-\frac{1}{n},b+\frac{1}{n})$$ $$[a,b) = \bigcap_{n=1}^{\infty} (a,b+\frac{1}{n})$$ $$(a,b) = \mathscr{B} \backslash [(-\infty,a]\cup[b,\infty)]$$ Is this proof correct?","I want to prove that if a $\sigma$-algebra of subsets of $\mathbb{R}$ contains intervals of the form $(a,\infty)$, then it contains all the intervals. Proof: Let $\mathscr{B}$ to denote the $\sigma$-algebra defined above. We have that since $(a,\infty) \in \mathscr{B}$, then since it contains the complement, we have that it also contains the intervals of the form $(-\infty,b]$, i.e. $$(-\infty,b] \in \mathscr{B}$$ In particular, we have that $(a,b) \in \mathscr{B}$. It's enough to prove that: $$[b, \infty) \in \mathscr{B}$$ $$[a,b] \in \mathscr{B}$$ $$[a,b) \in \mathscr{B}$$ $$(a,b) \in \mathscr{B}$$ This is clear, since:  $$[b, \infty) = \bigcap_{k=1}^{\infty} (b-\frac{1}{n}, \infty)$$ $$[a,b] = \bigcap_{n=1}^{\infty} (a-\frac{1}{n},b+\frac{1}{n})$$ $$[a,b) = \bigcap_{n=1}^{\infty} (a,b+\frac{1}{n})$$ $$(a,b) = \mathscr{B} \backslash [(-\infty,a]\cup[b,\infty)]$$ Is this proof correct?",,"['real-analysis', 'measure-theory', 'proof-verification', 'lebesgue-measure']"
76,What's special about measurable functions?,What's special about measurable functions?,,"Non-mathematician here, trying to grasp theory of integration. Why is it that the integral (or the $\mu$-integral) in, say, a measure theory book, is defined for measurable functions? The definition itself is first given for a simple function, which makes sense, and then we define the general integral of a positive integrand $g$ as $$ \sup\{ \int f \ d \mu : f \le g, f \ \text{is simple and positive}\}$$ and then further we define the integral of any $g$ in terms of $g^+$ and $g^-$ which are positive. But $g$ is always required to be measurable...where does measurability come into play here? Why is that important? Where does the theory fall apart when $g$ is non-measurable?","Non-mathematician here, trying to grasp theory of integration. Why is it that the integral (or the $\mu$-integral) in, say, a measure theory book, is defined for measurable functions? The definition itself is first given for a simple function, which makes sense, and then we define the general integral of a positive integrand $g$ as $$ \sup\{ \int f \ d \mu : f \le g, f \ \text{is simple and positive}\}$$ and then further we define the integral of any $g$ in terms of $g^+$ and $g^-$ which are positive. But $g$ is always required to be measurable...where does measurability come into play here? Why is that important? Where does the theory fall apart when $g$ is non-measurable?",,"['integration', 'measure-theory']"
77,"Subset of $[0,1] \times [0,1]$ with finite vertical cross sections and cofinite horizontal cross sections",Subset of  with finite vertical cross sections and cofinite horizontal cross sections,"[0,1] \times [0,1]","Does there exist a set $S \subseteq [0,1] \times [0,1]$ (in $\mathbb{R}^2$) such that: for all $x$, $\{y : (x,y) \in S\}$ is finite; and for all $y$, $\{x : (x,y) \notin S\}$ is finite? In other words, the vertical cross section at any $x$-coordinate is finite, while the horizontal cross section at any $y$-coordinate is cofinite. This question is purely set-theoretic, as $[0,1]$ could be replaced by any set of cardinality $\mathfrak{c} = 2^{\aleph_0}$. I am just using $[0,1]$ to aid with intuition. The total cardinality is the same counting in the horizontal or vertical direction first, so I can't think of an easy reason why such an $S$ would not exist. $S$ necessarily has outer (Lebesgue) measure $1$ and inner (Lebesgue) measure $0$. In particular $S$ is not measurable. Since $S$ is not measurable I believe the answer to this will depend on some form of the axiom of choice. What I would most like to see is a construction of $S$ assuming choice, or a proof that $S$ cannot exist.","Does there exist a set $S \subseteq [0,1] \times [0,1]$ (in $\mathbb{R}^2$) such that: for all $x$, $\{y : (x,y) \in S\}$ is finite; and for all $y$, $\{x : (x,y) \notin S\}$ is finite? In other words, the vertical cross section at any $x$-coordinate is finite, while the horizontal cross section at any $y$-coordinate is cofinite. This question is purely set-theoretic, as $[0,1]$ could be replaced by any set of cardinality $\mathfrak{c} = 2^{\aleph_0}$. I am just using $[0,1]$ to aid with intuition. The total cardinality is the same counting in the horizontal or vertical direction first, so I can't think of an easy reason why such an $S$ would not exist. $S$ necessarily has outer (Lebesgue) measure $1$ and inner (Lebesgue) measure $0$. In particular $S$ is not measurable. Since $S$ is not measurable I believe the answer to this will depend on some form of the axiom of choice. What I would most like to see is a construction of $S$ assuming choice, or a proof that $S$ cannot exist.",,"['measure-theory', 'set-theory']"
78,Tightness and Inner Regularity,Tightness and Inner Regularity,,"Let $P$ be a probability measure on a Borel $\sigma$-algebra (on some metric space, $\Omega$). It is called tight if for every $\epsilon >0$, there exists a compact $K$ such that $P(X \in K) \geq 1 - \epsilon$. It is called inner regular if $P(A) = \sup \{P(K) | K \subset A, K \text{ compact}\}$ for every $A$ in the Borel $\sigma$-algebra. It is clear that inner regularity implies tightness if we choose $A=\Omega$. For an arbitrary set $A$, using tightness we can obtain a compact $K(\epsilon)$ such that $P(A\cap K(\epsilon)) \geq P(A) - \epsilon$. If $A$ is closed then $K \cap A$ is compact and hence we get inner regularity for closed sets $A$. How can I prove this for general $A$? Thanks.","Let $P$ be a probability measure on a Borel $\sigma$-algebra (on some metric space, $\Omega$). It is called tight if for every $\epsilon >0$, there exists a compact $K$ such that $P(X \in K) \geq 1 - \epsilon$. It is called inner regular if $P(A) = \sup \{P(K) | K \subset A, K \text{ compact}\}$ for every $A$ in the Borel $\sigma$-algebra. It is clear that inner regularity implies tightness if we choose $A=\Omega$. For an arbitrary set $A$, using tightness we can obtain a compact $K(\epsilon)$ such that $P(A\cap K(\epsilon)) \geq P(A) - \epsilon$. If $A$ is closed then $K \cap A$ is compact and hence we get inner regularity for closed sets $A$. How can I prove this for general $A$? Thanks.",,['measure-theory']
79,Strong convergence of total variation of signed measure,Strong convergence of total variation of signed measure,,"Let $\nu_n$ be a sequence of finite signed radon measure such that $\nu_n\to \nu$ strongly for a finite signed radon measure $\nu$. Let $|\nu_n|$ denote the total variation measure of $\nu_n$. We know that $|\nu_n|$ is a positive Radon measure. My question: do I have $|\nu_n|\to |\nu|$ strongly? and do I have $||\nu|-|\mu||\leq |\nu-\mu|$ for two arbitrary finite signed measure $\nu$ and $\mu$? I know the above statement is absolutely false if $\nu_n\to \nu$ only in weak star sense. But I somehow remembered for strong convergence it is true but I can not find the source. So, if it is true, please confirm it for me and directly me to a reference, if not... maybe a counter example? Thank you!","Let $\nu_n$ be a sequence of finite signed radon measure such that $\nu_n\to \nu$ strongly for a finite signed radon measure $\nu$. Let $|\nu_n|$ denote the total variation measure of $\nu_n$. We know that $|\nu_n|$ is a positive Radon measure. My question: do I have $|\nu_n|\to |\nu|$ strongly? and do I have $||\nu|-|\mu||\leq |\nu-\mu|$ for two arbitrary finite signed measure $\nu$ and $\mu$? I know the above statement is absolutely false if $\nu_n\to \nu$ only in weak star sense. But I somehow remembered for strong convergence it is true but I can not find the source. So, if it is true, please confirm it for me and directly me to a reference, if not... maybe a counter example? Thank you!",,"['real-analysis', 'measure-theory']"
80,Example: outer measure is sub-additive but not countable additive,Example: outer measure is sub-additive but not countable additive,,"I am looking for an explicit example, but cannot find one. Any help would be great. Thanks a lot!","I am looking for an explicit example, but cannot find one. Any help would be great. Thanks a lot!",,[]
81,roots of polynomial with measurable coefficients,roots of polynomial with measurable coefficients,,If I have polynomial: $$a_n(\omega) x^n+\cdots+a_0(\omega)$$ $a_i:\Omega\to\mathbb R$ are measurable functions Assume that for every $\omega$ there are $n$ real roots to the polynomial (including multiplicity) given in order $\xi_1(\omega)\leq\xi_2(\omega)\leq\cdots\leq\xi_n(\omega)$ Are these roots measurable functions? my attempt: $f:\Omega \times \mathbb R\to \mathbb R$ is continuous in the second slot (fixed $\omega$) and measurable in the first slot so it is measurable hence $f^{-1}(0)$ is measurable set $A$. But now I want to project this $A$ to $\Omega $ and I don't know whether it is still measurable. thank you,If I have polynomial: $$a_n(\omega) x^n+\cdots+a_0(\omega)$$ $a_i:\Omega\to\mathbb R$ are measurable functions Assume that for every $\omega$ there are $n$ real roots to the polynomial (including multiplicity) given in order $\xi_1(\omega)\leq\xi_2(\omega)\leq\cdots\leq\xi_n(\omega)$ Are these roots measurable functions? my attempt: $f:\Omega \times \mathbb R\to \mathbb R$ is continuous in the second slot (fixed $\omega$) and measurable in the first slot so it is measurable hence $f^{-1}(0)$ is measurable set $A$. But now I want to project this $A$ to $\Omega $ and I don't know whether it is still measurable. thank you,,['measure-theory']
82,What is the interpretation of $\mu(dx)$ in Lebesgue integral?,What is the interpretation of  in Lebesgue integral?,\mu(dx),"For estimating the integral $\int_a^b f(x)dx$ we calculate the area of rectangles of height $f(x)$ and base $dx$ (Riemann sums). Therefore, we go from $a$ to $b$ with steps of $dx$. what 's the interpretation of $\mu(dx)$ in $\int f(x)\mu(dx)$ and how can we relate it to Lebesgue integral interpretation ? I already Know Lebesgue integral basics.","For estimating the integral $\int_a^b f(x)dx$ we calculate the area of rectangles of height $f(x)$ and base $dx$ (Riemann sums). Therefore, we go from $a$ to $b$ with steps of $dx$. what 's the interpretation of $\mu(dx)$ in $\int f(x)\mu(dx)$ and how can we relate it to Lebesgue integral interpretation ? I already Know Lebesgue integral basics.",,"['integration', 'measure-theory']"
83,Incomplete measure space that is not sigma-finite,Incomplete measure space that is not sigma-finite,,"I am looking for an example of an incomplete measure space with a measure that is not sigma-finite. All the measures which are not sigma-finite which I have come across so far are the following: counting measure on a set that is not countable (e.g. on the measurable space $(\mathbb{R},\mathcal{P}(\mathbb{R}))$ or the measure $\mu$ on the trivial sigma algebra $\Sigma = \{\emptyset,X \}$ with $\mu(X) = \infty$ were complete. Suppose $(\Omega, \Sigma, \mu)$ would be such a measure space. Let $\eta$ denote the induced outer measure and $\Sigma_\eta$ the $\sigma$-algebra of the $\eta$-measurable sets. Furthermore let $(\Omega,\tilde{\Sigma},\tilde{\mu})$ denote the completion of $(\Omega,\Sigma,\mu)$. Will in this case the inclusion $\tilde{\Sigma} \subset \Sigma_\eta$ be strict?","I am looking for an example of an incomplete measure space with a measure that is not sigma-finite. All the measures which are not sigma-finite which I have come across so far are the following: counting measure on a set that is not countable (e.g. on the measurable space $(\mathbb{R},\mathcal{P}(\mathbb{R}))$ or the measure $\mu$ on the trivial sigma algebra $\Sigma = \{\emptyset,X \}$ with $\mu(X) = \infty$ were complete. Suppose $(\Omega, \Sigma, \mu)$ would be such a measure space. Let $\eta$ denote the induced outer measure and $\Sigma_\eta$ the $\sigma$-algebra of the $\eta$-measurable sets. Furthermore let $(\Omega,\tilde{\Sigma},\tilde{\mu})$ denote the completion of $(\Omega,\Sigma,\mu)$. Will in this case the inclusion $\tilde{\Sigma} \subset \Sigma_\eta$ be strict?",,['measure-theory']
84,Specific problem on distribution theory.,Specific problem on distribution theory.,,"*****Note: Parts A, C and D I managed. Only need help on part B now would really would appreciate the help on B Hi, in my summer real analysis (or measures and real analysis as my instructor refers to it) I was presented with this question from Folland's real analysis second edition on distribution theory which has been slowly killing me. I really have no idea how to tackle it. It is question 9.11 which is: By support of a distribution they obviously mean the complement of the maximal open set on which the distribution is identically zero. My problem is how to use the support being zero in order to proceed I cannot really see how to relate any parts of this question to something I already know Thank you all helpers PROGRESS: After breaking my teeth I can figure all out except part b (really tough for me). Parts A, C and D I managed. Only need help on part B now would really appreciate answer on B EDIT: Lastly I only require help on part B of this question as thanks to the helpful comments I can now solve everything but part B as I cannot incorporate the clue and express the indexed derivative","*****Note: Parts A, C and D I managed. Only need help on part B now would really would appreciate the help on B Hi, in my summer real analysis (or measures and real analysis as my instructor refers to it) I was presented with this question from Folland's real analysis second edition on distribution theory which has been slowly killing me. I really have no idea how to tackle it. It is question 9.11 which is: By support of a distribution they obviously mean the complement of the maximal open set on which the distribution is identically zero. My problem is how to use the support being zero in order to proceed I cannot really see how to relate any parts of this question to something I already know Thank you all helpers PROGRESS: After breaking my teeth I can figure all out except part b (really tough for me). Parts A, C and D I managed. Only need help on part B now would really appreciate answer on B EDIT: Lastly I only require help on part B of this question as thanks to the helpful comments I can now solve everything but part B as I cannot incorporate the clue and express the indexed derivative",,"['real-analysis', 'measure-theory', 'distribution-theory', 'schwartz-space']"
85,"If the weak derivative $\nabla u$ of $u\in L^2(\Omega)$ exists, then $\int_\Omega|\nabla u|^2=\int_\Omega|\nabla u^+|^2+\int_\Omega|\nabla u^-|^2$","If the weak derivative  of  exists, then",\nabla u u\in L^2(\Omega) \int_\Omega|\nabla u|^2=\int_\Omega|\nabla u^+|^2+\int_\Omega|\nabla u^-|^2,"Let $\Omega\subseteq\mathbb{R}^n$ be bounded $u\in \mathcal{L}^2(\Omega)$ be weakly differentiable , i.e. $$\int_\Omega u\nabla\psi\;d\lambda^n=-\int\psi\nabla u\;d\lambda^n\;\;\;\text{for all }\psi\in C_0^\infty(\Omega)$$ (where we carefully denote the weak derivative of $u$ by $\nabla u$) $x^+:=\max(x,0)$ and $x^-:=\max(-x,0)$ for $x\in\mathbb{R}$ How can we show, that $$\int_\Omega\left|\nabla u\right|^2\;d\lambda^n=\int_\Omega\left|\nabla u^+\right|^2\;d\lambda^n+\int_\Omega\left|\nabla u^-\right|^2\;d\lambda^n\tag{1}$$ and what can we derive for $\nabla u^\pm$? (e.g. $\nabla u^\pm=\nabla u$ almost everywhere in $\left\{u^\pm >0\right\}$ or even $\nabla u=\nabla u^+-\nabla u^-$ almost everywhere).","Let $\Omega\subseteq\mathbb{R}^n$ be bounded $u\in \mathcal{L}^2(\Omega)$ be weakly differentiable , i.e. $$\int_\Omega u\nabla\psi\;d\lambda^n=-\int\psi\nabla u\;d\lambda^n\;\;\;\text{for all }\psi\in C_0^\infty(\Omega)$$ (where we carefully denote the weak derivative of $u$ by $\nabla u$) $x^+:=\max(x,0)$ and $x^-:=\max(-x,0)$ for $x\in\mathbb{R}$ How can we show, that $$\int_\Omega\left|\nabla u\right|^2\;d\lambda^n=\int_\Omega\left|\nabla u^+\right|^2\;d\lambda^n+\int_\Omega\left|\nabla u^-\right|^2\;d\lambda^n\tag{1}$$ and what can we derive for $\nabla u^\pm$? (e.g. $\nabla u^\pm=\nabla u$ almost everywhere in $\left\{u^\pm >0\right\}$ or even $\nabla u=\nabla u^+-\nabla u^-$ almost everywhere).",,"['real-analysis', 'measure-theory', 'multivariable-calculus', 'partial-differential-equations', 'sobolev-spaces']"
86,Lebesgue integrable function $g$ equals characteristic function,Lebesgue integrable function  equals characteristic function,g,"I am trying to solve this problem: Let $g:[0,1] \to \mathbb R$ be a non negative integrable function over $[0,1]$. Prove that if there is $\alpha \in \mathbb R$ such that for all $n \in \mathbb N$, $$\int_0^1 g(x)^ndx=\alpha,$$ then $g=\mathcal X_E$ a.e. for some measurable subset $E \subset [0,1]$. I am pretty lost with this problem. First of all note that since $g$ is non negative, then $\alpha \in \mathbb R_{\geq 0}$. I would like to show that $g(x)=1$ for all $x$ in some measurable set $E$ (or at least almost for all $x$ in $E$ and that $g(x)=0$ almost everywhere else. We have the equality $$\lim_{n \to \infty} \int_0^1 g(x)^ndx=\alpha$$ I thought of writing $[0,1]=\{x:g(x) \in [0,1)\} \cup \{g(x) \geq 1\}$. If I call $S=\{x:g(x) \in [0,1)\}$, then $$\int_0^1 g(x)^ndx=\int_S g(x)^ndx+\int_{S^c} g(x)^ndx$$ Since $g(x)^n \leq g(x)$ for all $x \in S$, then here I can apply the dominated convergence theorem, so $\lim_n \int_S g(x)^ndx=0$. I got stuck here, I don't know what else to do, I would appreciate some help. Thanks in advance.","I am trying to solve this problem: Let $g:[0,1] \to \mathbb R$ be a non negative integrable function over $[0,1]$. Prove that if there is $\alpha \in \mathbb R$ such that for all $n \in \mathbb N$, $$\int_0^1 g(x)^ndx=\alpha,$$ then $g=\mathcal X_E$ a.e. for some measurable subset $E \subset [0,1]$. I am pretty lost with this problem. First of all note that since $g$ is non negative, then $\alpha \in \mathbb R_{\geq 0}$. I would like to show that $g(x)=1$ for all $x$ in some measurable set $E$ (or at least almost for all $x$ in $E$ and that $g(x)=0$ almost everywhere else. We have the equality $$\lim_{n \to \infty} \int_0^1 g(x)^ndx=\alpha$$ I thought of writing $[0,1]=\{x:g(x) \in [0,1)\} \cup \{g(x) \geq 1\}$. If I call $S=\{x:g(x) \in [0,1)\}$, then $$\int_0^1 g(x)^ndx=\int_S g(x)^ndx+\int_{S^c} g(x)^ndx$$ Since $g(x)^n \leq g(x)$ for all $x \in S$, then here I can apply the dominated convergence theorem, so $\lim_n \int_S g(x)^ndx=0$. I got stuck here, I don't know what else to do, I would appreciate some help. Thanks in advance.",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
87,A Fourier Transform Which Is Cartesian Separable,A Fourier Transform Which Is Cartesian Separable,,"We say that the Fourier transform of a complex-valued function $f\in L^{1}(\mathbb{R}^{n})$ is separable if there exist single-variable functions $g_{1},\ldots,g_{n}$ such that $$g_{1}(\xi_{1})\cdots g_{n}(\xi_{n})=\widehat{f}(\xi), \text{   $\forall \xi=(\xi_{1},\ldots,\forall\xi_{n})\in\mathbb{R}^{n}$}$$ If $g_{1}(0)\cdots g_{n}(0)=\int_{\mathbb{R}^{n}}f(y)dy\neq 0$, then it is not hard to verify from Fubini's theorem that $$g_{j}(\xi_{j})=\widehat{f_{j}}(\xi_{j}), \forall \xi_{j}\in\mathbb{R}$$ where $$f_{j}(y_{j})=\dfrac{1}{g_{1}(0)\cdots g_{j-1}(0)g_{j+1}(0)\cdots g_{n}(0)}\int_{\mathbb{R}^{n-1}}f(y)dy_{1}\cdots dy_{j-1}dy_{j+1}\cdots dy_{n},$$ for $j=1,\ldots,n$. Whence by the injectivity of the Fourier transform, $f_{1}\cdots f_{n}=f$ a.e. What happens, though, if we drop the assumption that $\int_{\mathbb{R}^{n}}f\neq 0$? If $\widehat{f}\in L^{1}(\mathbb{R}^{n})$, then it follows from Fubini's theorem that each $g_{j}\in L^{1}(\mathbb{R})$, whence $f=g_{j}^{\vee}\cdots g_{n}^{\vee}$ a.e. (i.e. the product of the inverse Fourier transforms). This seems like an unnecessarily strong assumption. Question If the Fourier transform of $f\in L^{1}(\mathbb{R}^{n})$ is separable, is $f$ almost everywhere equal to a separable function? I tried reducing the problem to the case $f\neq 0$ by writing in terms of positive and negative parts ($f=f_{+}-f_{-}$), but I couldn't get anywhere with this approach.","We say that the Fourier transform of a complex-valued function $f\in L^{1}(\mathbb{R}^{n})$ is separable if there exist single-variable functions $g_{1},\ldots,g_{n}$ such that $$g_{1}(\xi_{1})\cdots g_{n}(\xi_{n})=\widehat{f}(\xi), \text{   $\forall \xi=(\xi_{1},\ldots,\forall\xi_{n})\in\mathbb{R}^{n}$}$$ If $g_{1}(0)\cdots g_{n}(0)=\int_{\mathbb{R}^{n}}f(y)dy\neq 0$, then it is not hard to verify from Fubini's theorem that $$g_{j}(\xi_{j})=\widehat{f_{j}}(\xi_{j}), \forall \xi_{j}\in\mathbb{R}$$ where $$f_{j}(y_{j})=\dfrac{1}{g_{1}(0)\cdots g_{j-1}(0)g_{j+1}(0)\cdots g_{n}(0)}\int_{\mathbb{R}^{n-1}}f(y)dy_{1}\cdots dy_{j-1}dy_{j+1}\cdots dy_{n},$$ for $j=1,\ldots,n$. Whence by the injectivity of the Fourier transform, $f_{1}\cdots f_{n}=f$ a.e. What happens, though, if we drop the assumption that $\int_{\mathbb{R}^{n}}f\neq 0$? If $\widehat{f}\in L^{1}(\mathbb{R}^{n})$, then it follows from Fubini's theorem that each $g_{j}\in L^{1}(\mathbb{R})$, whence $f=g_{j}^{\vee}\cdots g_{n}^{\vee}$ a.e. (i.e. the product of the inverse Fourier transforms). This seems like an unnecessarily strong assumption. Question If the Fourier transform of $f\in L^{1}(\mathbb{R}^{n})$ is separable, is $f$ almost everywhere equal to a separable function? I tried reducing the problem to the case $f\neq 0$ by writing in terms of positive and negative parts ($f=f_{+}-f_{-}$), but I couldn't get anywhere with this approach.",,"['real-analysis', 'measure-theory', 'fourier-analysis', 'harmonic-analysis']"
88,An inequality for a maximal function on an $n$-ball.,An inequality for a maximal function on an -ball.,n,"We have $Mf(x) = \sup_{r>0} \frac{c_n}{r^n} \int_{|y|\le r} |f(x-y)| dy$ the maximal function, where $r^n/c_n$ is the volume of the n-dimensional ball of radius $r$, $|y|\le r$. I want to show that for $f_j=\chi_{(2^{j-1},2^j)}$, where $\chi$ is the charactersitic function, and $j=1,2,3,\ldots$, that: $Mf_j(x) \geq 1/8$ if $|x|\le 2^j$. Here's, what I have done: $2^{j-1} \le |x-y| \le 2^j$, so we get that $|y|<2^{j+1}$ and $|y|\le r$. So we have that $Mf_j(x) \ge c_n/r^n \cdot r^n/(c_n\cdot 2^{(j+1)n})$  I don't see how to get the eighth there, anyone can help me with this? It appears in Stein's real variable methods, orthogonality, and oscillatory integrals, 1993 edition pages 50-51.","We have $Mf(x) = \sup_{r>0} \frac{c_n}{r^n} \int_{|y|\le r} |f(x-y)| dy$ the maximal function, where $r^n/c_n$ is the volume of the n-dimensional ball of radius $r$, $|y|\le r$. I want to show that for $f_j=\chi_{(2^{j-1},2^j)}$, where $\chi$ is the charactersitic function, and $j=1,2,3,\ldots$, that: $Mf_j(x) \geq 1/8$ if $|x|\le 2^j$. Here's, what I have done: $2^{j-1} \le |x-y| \le 2^j$, so we get that $|y|<2^{j+1}$ and $|y|\le r$. So we have that $Mf_j(x) \ge c_n/r^n \cdot r^n/(c_n\cdot 2^{(j+1)n})$  I don't see how to get the eighth there, anyone can help me with this? It appears in Stein's real variable methods, orthogonality, and oscillatory integrals, 1993 edition pages 50-51.",,"['real-analysis', 'measure-theory', 'harmonic-analysis']"
89,"Prove $\{ (x,y) \in [0,1]^2: x-y\in \mathbb{Q}\}$ is measurable.",Prove  is measurable.,"\{ (x,y) \in [0,1]^2: x-y\in \mathbb{Q}\}","Let $T:=\{ (x,y) \in [0,1]^2\ :\ x-y\in \mathbb{Q} \}$. Show that $T$ has measure zero, but it meets every set of the form $A \times B$ , where $A$ and $B$ are measurable sets of positive measure in $[0,1]$. T is measurable since it will be countable union of lines in $[0,1]^2$ and thus will be of measure zero, but why does it intersect every $A \times B$ ?","Let $T:=\{ (x,y) \in [0,1]^2\ :\ x-y\in \mathbb{Q} \}$. Show that $T$ has measure zero, but it meets every set of the form $A \times B$ , where $A$ and $B$ are measurable sets of positive measure in $[0,1]$. T is measurable since it will be countable union of lines in $[0,1]^2$ and thus will be of measure zero, but why does it intersect every $A \times B$ ?",,['measure-theory']
90,Lebesgue integral and iterated integral,Lebesgue integral and iterated integral,,"I am learning lebesgue integral at the moment, and come across a question in homework, but find it really confused. The question states: I first tried to compute the iterated integral by Riemann integral, and find that the iterated integral is infinite no matter which order I used. So I think probably here the result of Lebesgue integral is different. But how to compute the iterated integral using Lebesgue integral? The domain are split equally into 2 squares in the unit box if using Riemann integral. Do we still have this in Lebesgue integral? Maybe some sequence of simple functions is needed, but I am not sure how to construct that in an iterated case. I think the double integral does not exist as the 2 functions are not measurable, and if we compute the integral we will probably find the 2 iterated integral different.","I am learning lebesgue integral at the moment, and come across a question in homework, but find it really confused. The question states: I first tried to compute the iterated integral by Riemann integral, and find that the iterated integral is infinite no matter which order I used. So I think probably here the result of Lebesgue integral is different. But how to compute the iterated integral using Lebesgue integral? The domain are split equally into 2 squares in the unit box if using Riemann integral. Do we still have this in Lebesgue integral? Maybe some sequence of simple functions is needed, but I am not sure how to construct that in an iterated case. I think the double integral does not exist as the 2 functions are not measurable, and if we compute the integral we will probably find the 2 iterated integral different.",,"['measure-theory', 'lebesgue-integral']"
91,Complex Measure Agreeing on Certain Balls,Complex Measure Agreeing on Certain Balls,,"I came across this problem and am lost as to how to solve it. Let $r>0$ be fixed. Suppose $\mu, \nu$ are complex Borel measures on $\mathbb{R}^d$ such that for each open ball B of radius $r$, $\mu(B)=\nu(B)$. Then $\mu=\nu$. I thought this might be an application of $\pi-\lambda$ theorem, but I realized we wouldn't have a $\pi$-system with the collection of open balls $B$ since intersecting such balls might not necessarily be open or have radius $r$ still. Any help would be greatly appreciated.","I came across this problem and am lost as to how to solve it. Let $r>0$ be fixed. Suppose $\mu, \nu$ are complex Borel measures on $\mathbb{R}^d$ such that for each open ball B of radius $r$, $\mu(B)=\nu(B)$. Then $\mu=\nu$. I thought this might be an application of $\pi-\lambda$ theorem, but I realized we wouldn't have a $\pi$-system with the collection of open balls $B$ since intersecting such balls might not necessarily be open or have radius $r$ still. Any help would be greatly appreciated.",,"['measure-theory', 'fourier-analysis']"
92,Borel sets and absolutely continuous functions,Borel sets and absolutely continuous functions,,"Let $A\subset [0,1]$ be a Borel set such that $0<m(A\cap I)<m(I)$ for any subinterval $I$ of $[0,1]$. Let $F(x)=m([0,x]\cap A)$. Show that $F$ is absolutely continuous and strictly increasing on $[0,1]$, but $F'=0$ on a set of positive measure. My Work: Let $\epsilon>0$. Then we can find a finite set of disjoint intervals $(a_1,b_1),(a_2,b_2),...,(a_N,b_N)$ of $[0,1]$ such that $\displaystyle (b_i-a_i)<\frac{\epsilon}{N}$ . Then  we have $\displaystyle \sum_{i=1}^N (b_i-a_i)<\epsilon$. Now $F(b_i)=m([0,b_i]\cap A)<m([0,b_i])=b_i$ and $F(a_i)=m([0,a_i]\cap A)<m([0,a_i])=a_i$. If I can show that $F(b_i)-F(a_i)<(b_i-a_i)$ for all $i$ then I can show that $F$ is absolutely continuous. But now I am stuck in proving this. Can anyone please give me a hint?","Let $A\subset [0,1]$ be a Borel set such that $0<m(A\cap I)<m(I)$ for any subinterval $I$ of $[0,1]$. Let $F(x)=m([0,x]\cap A)$. Show that $F$ is absolutely continuous and strictly increasing on $[0,1]$, but $F'=0$ on a set of positive measure. My Work: Let $\epsilon>0$. Then we can find a finite set of disjoint intervals $(a_1,b_1),(a_2,b_2),...,(a_N,b_N)$ of $[0,1]$ such that $\displaystyle (b_i-a_i)<\frac{\epsilon}{N}$ . Then  we have $\displaystyle \sum_{i=1}^N (b_i-a_i)<\epsilon$. Now $F(b_i)=m([0,b_i]\cap A)<m([0,b_i])=b_i$ and $F(a_i)=m([0,a_i]\cap A)<m([0,a_i])=a_i$. If I can show that $F(b_i)-F(a_i)<(b_i-a_i)$ for all $i$ then I can show that $F$ is absolutely continuous. But now I am stuck in proving this. Can anyone please give me a hint?",,"['real-analysis', 'measure-theory']"
93,The measure of the boundary being zero implies the set is measurable.,The measure of the boundary being zero implies the set is measurable.,,"Assuming our set, $E\subset\mathbb{R}^2$ such that $m(\partial E)=0$ (where $m$ is Lebesgue measure), why does this imply that $E$ is Lebesgue measurable?","Assuming our set, $E\subset\mathbb{R}^2$ such that $m(\partial E)=0$ (where $m$ is Lebesgue measure), why does this imply that $E$ is Lebesgue measurable?",,"['real-analysis', 'measure-theory']"
94,Characterization of the Haar measure in terms of the integrals of characters,Characterization of the Haar measure in terms of the integrals of characters,,I was reading a paper and I think that they used the following theorem: Let $G$ compact group and $\mu$ a probability measure on $G$. If  $$\hat{\mu}(\xi)= \int_G \overline{\xi(x)} d\mu(x) = \begin{cases} 0 & \text{ if }\xi = 0 \\ 1 & \text{ if } \xi\neq 0\end{cases} \quad \xi \in \hat{G}$$ then $\mu$ is the Haar measure. Is this theorem true? I looked on the book An Introduction to Harmonic Analysis of Katznelson that my teacher recommended and I only found the converse of the theorem on a exercise. Any help will be appreciated.,I was reading a paper and I think that they used the following theorem: Let $G$ compact group and $\mu$ a probability measure on $G$. If  $$\hat{\mu}(\xi)= \int_G \overline{\xi(x)} d\mu(x) = \begin{cases} 0 & \text{ if }\xi = 0 \\ 1 & \text{ if } \xi\neq 0\end{cases} \quad \xi \in \hat{G}$$ then $\mu$ is the Haar measure. Is this theorem true? I looked on the book An Introduction to Harmonic Analysis of Katznelson that my teacher recommended and I only found the converse of the theorem on a exercise. Any help will be appreciated.,,"['measure-theory', 'reference-request', 'harmonic-analysis']"
95,Determining Measurability given property of symmetric difference,Determining Measurability given property of symmetric difference,,"I came across this statement and I am not sure why it is true. If $\mu$ is sub-additive and $\mu(E\bigtriangleup F)$ is in the null set (where $E \bigtriangleup F$ denotes the symmetric difference of $E$ and $F$), and $F$ is $\mu$-measurable, then $ E$ is necessarily $\mu$-measurable as well. Any ideas on how the proof would go would be appreciated.","I came across this statement and I am not sure why it is true. If $\mu$ is sub-additive and $\mu(E\bigtriangleup F)$ is in the null set (where $E \bigtriangleup F$ denotes the symmetric difference of $E$ and $F$), and $F$ is $\mu$-measurable, then $ E$ is necessarily $\mu$-measurable as well. Any ideas on how the proof would go would be appreciated.",,['measure-theory']
96,Measures: Sequential Continuity,Measures: Sequential Continuity,,"Disclaimer: This thread is meant as record and written in Q&A style. Let $\Omega$ be a measure space. It is well known that a measure is continuous from below as well as from above: $$E_n\uparrow E\implies\mu(E_n)\uparrow\mu(E)$$ $$E_n\downarrow E\implies\mu(E_n)\downarrow\mu(E)\quad(\mu(E_n)<\infty)$$ On the other hand this fails in general if one replaces sequences by nets: $$E_M\uparrow[0,1],\lambda(E_M)\equiv 0\quad(E_{M\subseteq[0,1]:\lambda(M)=0}:=M)$$ $$E_N\downarrow\varnothing,\lambda(E_N)\equiv 1\quad(E_{N\subseteq[0,1]:\lambda(N)=1}:=N)$$ with the ordering being given by inclusion respectively containement. What about sequential continuity: $$E_n\to E\implies \mu(E_n)\to\mu(E)$$ Here convergence of sets is meant as: $$A_\lambda\to A:\iff\forall\omega\in\Omega\exists \lambda_\omega\in\Lambda\forall\lambda\geq\lambda_\omega:\omega\in A_\lambda\text{ if }\omega\in A\text{ and }\omega\notin A_\lambda\text{ if }\omega\notin A$$","Disclaimer: This thread is meant as record and written in Q&A style. Let $\Omega$ be a measure space. It is well known that a measure is continuous from below as well as from above: $$E_n\uparrow E\implies\mu(E_n)\uparrow\mu(E)$$ $$E_n\downarrow E\implies\mu(E_n)\downarrow\mu(E)\quad(\mu(E_n)<\infty)$$ On the other hand this fails in general if one replaces sequences by nets: $$E_M\uparrow[0,1],\lambda(E_M)\equiv 0\quad(E_{M\subseteq[0,1]:\lambda(M)=0}:=M)$$ $$E_N\downarrow\varnothing,\lambda(E_N)\equiv 1\quad(E_{N\subseteq[0,1]:\lambda(N)=1}:=N)$$ with the ordering being given by inclusion respectively containement. What about sequential continuity: $$E_n\to E\implies \mu(E_n)\to\mu(E)$$ Here convergence of sets is meant as: $$A_\lambda\to A:\iff\forall\omega\in\Omega\exists \lambda_\omega\in\Lambda\forall\lambda\geq\lambda_\omega:\omega\in A_\lambda\text{ if }\omega\in A\text{ and }\omega\notin A_\lambda\text{ if }\omega\notin A$$",,"['measure-theory', 'elementary-set-theory', 'convergence-divergence']"
97,Uncountable $\sigma$-algebra,Uncountable -algebra,\sigma,"I'm stuck on the following problem (Source: Real Analysis for Graduate Students; Exercise 2.6; Bass ): Suppose $\mathcal A$ is a $\sigma$-algebra with the property that whenever $A \in \mathcal A$, there exists $B, C \in \mathcal A$ with $B \cap C = \emptyset$, $B \cup C = A$, and neither $B$ nor $C$ is empty. Prove that $\mathcal A$ is uncountable. I think there is the added assumption that this is only true for $A \in \mathcal A$ having at least two elements, so it doesn't hold for singletons and the emptyset? I tried to show this by way of contradiction and say that $\mathcal A = \{A_k\}$ is countable, but I didn't see how this could get me to a contradiction. The other approach I tried was to look at $X = B_1 \cup C_1$ where $B_1 \cap C_1 = \emptyset$, then look at $B_1 = B_2 \cup C_2$ where $B_2 \cap C_2 = \emptyset$ and so on. If I look at the $C_k$'s they are pairwise disjoint and I either have a finite number of them or an infinite number of them in which case I've created a countable sequence of pairwise disjoint nonempty elements of $\mathcal A$. This path looked promising, but I couldn't see what to do next. Any ideas? As a secondary question: I think this result is supposed to be used to show that if $\mathcal A$ is a $\sigma$-algebra with infinitely many elements, then it's uncountable, but I wasn't able to show that the property mentioned above (the one I'm trying to show) was satisfied in this case.","I'm stuck on the following problem (Source: Real Analysis for Graduate Students; Exercise 2.6; Bass ): Suppose $\mathcal A$ is a $\sigma$-algebra with the property that whenever $A \in \mathcal A$, there exists $B, C \in \mathcal A$ with $B \cap C = \emptyset$, $B \cup C = A$, and neither $B$ nor $C$ is empty. Prove that $\mathcal A$ is uncountable. I think there is the added assumption that this is only true for $A \in \mathcal A$ having at least two elements, so it doesn't hold for singletons and the emptyset? I tried to show this by way of contradiction and say that $\mathcal A = \{A_k\}$ is countable, but I didn't see how this could get me to a contradiction. The other approach I tried was to look at $X = B_1 \cup C_1$ where $B_1 \cap C_1 = \emptyset$, then look at $B_1 = B_2 \cup C_2$ where $B_2 \cap C_2 = \emptyset$ and so on. If I look at the $C_k$'s they are pairwise disjoint and I either have a finite number of them or an infinite number of them in which case I've created a countable sequence of pairwise disjoint nonempty elements of $\mathcal A$. This path looked promising, but I couldn't see what to do next. Any ideas? As a secondary question: I think this result is supposed to be used to show that if $\mathcal A$ is a $\sigma$-algebra with infinitely many elements, then it's uncountable, but I wasn't able to show that the property mentioned above (the one I'm trying to show) was satisfied in this case.",,['measure-theory']
98,Every Lipschitz function is the primitive of a measurable function,Every Lipschitz function is the primitive of a measurable function,,"I was doing exercise 5 of this exercise sheet and I don't know how to conclude. I need to prove that if $f \colon [0,1]\to \mathbb{R}$ is Lipshitz, $X$ is a uniform$(0,1)$ random variable and $$X_n=\frac{\lfloor 2^nX \rfloor }{2^n}$$ then $$f(X_n + 2^{-n})-f(X_n)=\int_{X_n}^{X_n+2^{-n}}g(u)du$$ implies that $$f(x)-f(0)=\int_0^xg(u)du$$ for every $x \in [0,1]$ Any help will be appriciated.","I was doing exercise 5 of this exercise sheet and I don't know how to conclude. I need to prove that if $f \colon [0,1]\to \mathbb{R}$ is Lipshitz, $X$ is a uniform$(0,1)$ random variable and $$X_n=\frac{\lfloor 2^nX \rfloor }{2^n}$$ then $$f(X_n + 2^{-n})-f(X_n)=\int_{X_n}^{X_n+2^{-n}}g(u)du$$ implies that $$f(x)-f(0)=\int_0^xg(u)du$$ for every $x \in [0,1]$ Any help will be appriciated.",,"['measure-theory', 'stochastic-processes', 'martingales']"
99,Variation of a strongly bounded measure is strongly bounded too,Variation of a strongly bounded measure is strongly bounded too,,"Let $\mathcal{A}$ be a field of subsets of a set $\Omega$, $X$ a Banach space and $\mu:\mathcal{A}\rightarrow X$ a finitely additive vector measure. The variation of $\mu$ is the extended nonnegative function $|\mu|$ whose value  on a set $E\in\mathcal{A}$ is given by $$|\mu|(E)=\sup_\pi\sum_{A\in\pi}\|\mu(A)\|,$$ where the supremum is taken over all partitions $\pi$ of $E$ into a finite number of pairwise disjoint members of $\mathcal{A}$. It can be shown that $|\mu|$ is also a finitely additive measure. A finitely additive measure $\mu$ is said to be exhaustive ( or strongly bounded ) if for every $(E_n)$ sequence of pairwise disjoint members of $\mathcal{A}$, then $\lim_n\mu(E_n) = 0$. It is easy to show that $|\mu|$ exhaustive implies $\mu$ exhaustive for every $X-$valued finitely additive measure. If $\mu$ is real-valued or complex-valued and bounded, it can be shown that $\mu$ exhaustive implies $|\mu|$ exhaustive. Does a bounded $\mu$ that is exhaustive imply $|\mu|$ exhaustive for an $X-$valued finitely additive measure? I am unsure of how to prove this and I was wondering if I could get a hint. Thanks!","Let $\mathcal{A}$ be a field of subsets of a set $\Omega$, $X$ a Banach space and $\mu:\mathcal{A}\rightarrow X$ a finitely additive vector measure. The variation of $\mu$ is the extended nonnegative function $|\mu|$ whose value  on a set $E\in\mathcal{A}$ is given by $$|\mu|(E)=\sup_\pi\sum_{A\in\pi}\|\mu(A)\|,$$ where the supremum is taken over all partitions $\pi$ of $E$ into a finite number of pairwise disjoint members of $\mathcal{A}$. It can be shown that $|\mu|$ is also a finitely additive measure. A finitely additive measure $\mu$ is said to be exhaustive ( or strongly bounded ) if for every $(E_n)$ sequence of pairwise disjoint members of $\mathcal{A}$, then $\lim_n\mu(E_n) = 0$. It is easy to show that $|\mu|$ exhaustive implies $\mu$ exhaustive for every $X-$valued finitely additive measure. If $\mu$ is real-valued or complex-valued and bounded, it can be shown that $\mu$ exhaustive implies $|\mu|$ exhaustive. Does a bounded $\mu$ that is exhaustive imply $|\mu|$ exhaustive for an $X-$valued finitely additive measure? I am unsure of how to prove this and I was wondering if I could get a hint. Thanks!",,['measure-theory']
